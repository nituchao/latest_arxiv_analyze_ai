# 20251003
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 网络化学术-化学工程（CA-ChemE）：一种促进自主研究演进和新兴科学发现的虚拟城市 [PDF](https://arxiv.org/pdf/2510.01293), [HTML](https://arxiv.org/abs/2510.01293)
### Authors
Zekun Jiang,Chunming Xu,Tianhang Zhou
### Background
人工智能（AI）在化学工程领域的快速发展已经展示了巨大的潜力，但现有的AI系统在跨学科合作和探索未解决问题方面仍然有限。
### Innovation
提出了Cyber Academia-Chemical Engineering (CA-ChemE)系统，这种系统通过多智能体协作，集成领域知识库、知识增强技术和协作代理，构建了一个能够进行深度专业知识推理和高效跨学科合作的智能生态系统。特别是在跨领域协作效率方面，通过引入具有本体工程能力的协作代理（CA），显著提高了远程领域专家对之间的协作效率。
### Conclusion
研究表明，精心设计的多智能体架构可以为化学工程中的自主科学研究提供可行途径。
## 2. `cs.AI` - Aristotle: 2025年国际数学奥林匹克级别自动定理证明 [PDF](https://arxiv.org/pdf/2510.01346), [HTML](https://arxiv.org/abs/2510.01346)
### Authors
Tudor Achim,Alex Best,Kevin Der,Mathïs Fédérico,Sergei Gukov,Daniel Halpern-Leister,Kirsten Henningsgard,Yury Kudryashov,Alexander Meiburg,Martin Michelsen,Riley Patterson,Eric Rodriguez,Laura Scharff,Vikram Shanker,Vladmir Sicca,Hari Sowrirajan,Aidan Swope,Matyas Tamas,Vlad Tenev,Jonathan Thomm,Harold Williams,Lawrence Wu
### Background
背景在于自动定理证明领域，特别是在解决复杂数学问题方面，现有技术还存在局限性，特别是对于需要结合形式验证和非形式推理的问题。国际数学奥林匹克（IMO）的问题代表着该领域最复杂挑战之一，能够在这个平台上取得优异成绩的AI系统非常罕见。
### Innovation
创新点在于Aristotle系统结合了形式验证和非形式推理，能够解决国际数学奥林匹克级别的问题。该系统通过集成三种主要组成部分——Lean证明搜索系统、生成和形式化引理的非形式推理系统以及专用的几何解算器，展示了在自动定理证明领域的最新技术水平，并具有有利的缩放特性。
### Conclusion
结论是Aristotle系统在2025年国际数学奥林匹克问题上达到了等同于金牌的水平，证明了其在自动定理证明领域的强大能力。该系统展示了显著的进步，并为进一步提高自动定理证明的自动性和有效性提供了新的可能。
## 3. `cs.AI` - 社会实验室：LLM多智能体评估的心理测量框架 [PDF](https://arxiv.org/pdf/2510.01295), [HTML](https://arxiv.org/abs/2510.01295)
### Authors
Zarreen Reza
### Background
随着大型语言模型（LLMs）从静态工具转变为自主代理，传统的评估基准越来越不足以衡量它们在下游任务上的表现。这些方法无法捕捉到代理在互动环境中交流、说服和协作时产生的新兴社会和认知动态。因此，需要一种新的评估框架来解决这个问题，该框架通过多层次代理辩论作为受控的社会实验室来发现和量化这些行为。
### Innovation
本文提出了一种新的评估框架，利用多层次代理辩论作为受控的社会实验室，这些代理具有不同的个性和激励措施，由大型语言模型主持人监督，共同讨论各种具有挑战性的主题。该框架使用新的心理测量和语义度量工具，揭示了几个关键发现，包括在没有明确指令的情况下，代理之间寻求共识的强大且稳健的倾向，以及分配的角色可以引发稳定的、可测量的心理测量特征，这对外部AI对齐具有重要意义。
### Conclusion
本文提供了一种设计用于代理环境的新动态、心理测量确立的评估协议蓝图，为理解并塑造下一代AI代理的社会行为提供了重要方法。实验结果和代码可以在[此处](this https URL)获得。
## 4. `cs.AI` - Agentic Jigsaw Interaction Learning for Enhancing Visual Perception and Reasoning in Vision-Language Models [PDF](https://arxiv.org/pdf/2510.01304), [HTML](https://arxiv.org/abs/2510.01304)
### Authors
Yu Zeng,Wenxuan Huang,Shiting Huang,Xikun Bao,Yukun Qi,Yiming Zhao,Qiuchen Wang,Lin Chen,Zehui Chen,Huaian Chen,Wanli Ouyang,Feng Zhao
### Background
尽管现有的大型视觉-语言模型（VLMs）在多模态理解和推理方面取得了进步，但它们的基本感知和推理能力仍然有限。特别是在简单的拼图任务上，现有模型的表现接近随机，显示出核心感知和推理能力的不足。尽管高质量的视觉-语言数据可以提升这些能力，但由于其稀缺性和有限的可扩展性，这给模型带来了重大限制。
### Innovation
我们提出了AGILE，一种基于拼图交互学习的增强视觉感知和推理的机制。AGILE将拼图解决过程形式化为一个交互过程，使模型可以逐步与环境互动。在每一步中，模型根据当前状态生成执行动作的代码，环境则提供细粒度的视觉反馈以指导任务完成。通过这种观察与互动的迭代循环，模型通过探索和反馈逐步提升其感知和推理能力。实验结果表明，AGILE不仅显著提升了拼图任务的性能（例如，在2×2设置下，准确率从9.5%提高到了82.8%），而且在9种通用视觉任务上也展示了强大的泛化能力，平均性能提高了3.1%。这些结果表明，感知和推理能力都有显著的提升。
### Conclusion
这项工作为提高多模态模型的推断能力和泛化能力开辟了新的途径，并提供了一种解决多模态强化学习数据稀缺问题的有效、可扩展方案。相关的代码和数据集可以在提供的链接下载。
## 5. `cs.AI` - OR-Toolformer: 使用工具增强的大语言模型建模和解决运筹学问题 [PDF](https://arxiv.org/pdf/2510.01253), [HTML](https://arxiv.org/abs/2510.01253)
### Authors
Jianzhang Zhang,Jialong Zhou,Chuang Liu
### Background
大语言模型（LLMs）在数学推理方面表现出色，但依赖闭源API进行运筹学（OR）任务处理会引发隐私问题，而从零开始训练开源模型则会带来高昂的计算成本。该论文旨在解决上述问题，提出了一种新的方法——OR-Toolformer。
### Innovation
引入OR-Toolformer，该方法通过半自动的数据合成流水线生成多样的OR问题-答案对，并将外部求解器与LLM结合，以生成API调用。通过这种方法，OR-Toolformer在三个标准基准测试中的执行准确性高达80.1%，超过大小匹配的基线模型超过4.3%。在对两种未见过的OR问题类型的零样本评估中，它达到了54%的平均准确性，比最强基线提高了21个百分点。这一系列研究结果验证了工具增强的LLM微调对于运筹学问题建模和解决的有效性。
### Conclusion
OR-Toolformer展示了对于准确且泛化的OR问题建模和解决的有效方法。通过结合LLM和外部求解器，不仅提高了模型的准确性和执行效率，还降低了从零开始训练开源模型所需的计算成本。
## 6. `cs.AI` - 将他人的思维建模为代码 [PDF](https://arxiv.org/pdf/2510.01272), [HTML](https://arxiv.org/abs/2510.01272)
### Authors
Kunal Jha,Aydan Yuenan Huang,Eric Ye,Natasha Jaques,Max Kleiman-Weiner
### Background
准确预测人类行为对于确保人机协作的稳健性和安全性至关重要。然而，现有的用于建模人类行为的方法往往依赖大量数据并且脆弱，因为它们要么对理性做出不切实际的假设，要么过度复杂无法快速适应。研究表明，许多日常社交互动可能存在可预测的模式，类似于“等待绿灯，然后前行”的简单脚本，这种脚本可以减少参与者和观察者的认知负担。这些脚本可以在计算机代码中实现，而不是依赖于信念和欲望的策略。
### Innovation
该研究提出了ROTE算法，结合大型语言模型生成行为程序假设空间，并通过概率推理处理该空间中的不确定性。ROTE在网格世界任务和大型物理家用房模拟器中进行了测试，能够从稀疏观察中预测人类和AI的行为，并在样本内准确性和样本外泛化方面均优于包括行为克隆和基于大型语言模型的方法在内的一系列基线方法，最高差异可达50%。ROTE将行动理解视为程序合成问题，从而为AI系统在现实世界中高效准确地预测人类行为提供了路径。
### Conclusion
ROTE算法通过结合大型语言模型和概率推理，能够更高效、更准确地预测人类和AI的行为，有效解决了现有方法在建模人类行为方面存在的数据需求大和不适应性等问题。
## 7. `cs.AI` - 基于检索增强框架的大语言模型临床决策支持系统 [PDF](https://arxiv.org/pdf/2510.01363), [HTML](https://arxiv.org/abs/2510.01363)
### Authors
Leon Garza,Anantaa Kotal,Michael A. Grasso,Emre Umucu
### Background
临床决策日益复杂，电子健康记录（EHR）的迅速扩张为数据导向的医疗提供了机遇和挑战。本文旨在利用大语言模型（LLMs）开发一个临床决策支持系统，以辅助临床医生开具处方。该系统通过分析包括患者人口统计信息、就诊陈述、临床症状、诊断信息和治疗史在内的历史EHR数据，生成治疗建议。
### Innovation
本文提出了一种基于大语言模型的临床决策支持系统，采用检索增强（RAG）框架，将自然语言处理与结构化临床输入相结合，生成上下文相关的推荐。与临床医生判断不同，该系统旨在通过检索和综合具有类似特征的既往案例来辅助临床医生决策，这些数据来源可以是局部数据集或经联邦处理的数据源。系统的核心是通过调和非结构化文本和编码数据以支持大语言模型推理的检索增强生成（RAG）管道。该研究还探讨了系统的技术组件，包括表示表示对齐和生成策略。初步评估表明，当适当限制和严格验证时，基于大语言模型的工具可以为处方流程提供有价值的决策支持。这项工作标志着生成式人工智能融入临床决策过程的初步步骤，强调透明度、安全性和与现有实践的契合。
### Conclusion
该研究初步表明，基于大语言模型的工具可能为处方流程提供有价值的决策支持，需要在适当限制和严格验证的基础上进行。这项工作代表了生成式人工智能融入临床决策过程的第一步，强调了透明度、安全性和与现有实践的契合。
## 8. `cs.AI` - OntoLogX：利用大语言模型从网络安全日志中引导知识图谱提取 [PDF](https://arxiv.org/pdf/2510.01409), [HTML](https://arxiv.org/abs/2510.01409)
### Authors
Luca Cotti,Idilio Drago,Anisa Rula,Devis Bianchini,Federico Cerutti
### Background
系统日志是网络威胁情报（CTI）的重要来源，记录了攻击者的行为、利用的漏洞和恶意活动的痕迹。然而，日志的有效性常受到缺乏结构化、语义不一致和设备间不一致等问题的限制。因此，从日志中提取行动 CTI 需要能够将嘈杂、异构的数据转换为连贯且互操作的表示的方法。
### Innovation
OntoLogX 介绍了一种自主人工智能（AI）代理，通过利用大语言模型（LLMs）将原始日志转换为基于本体的知识图谱（KGs）。OntoLogX 结合了轻量级的日志本体并采用检索增强生成（RAG）和迭代校正步骤，确保生成的 KGs 在语义和语法上都是有效的。此外，该系统将 KGs 聚合到会话级别，并使用 LLM 预测 MITRE ATT&CK 战术，将低级日志证据与高级攻击目标关联起来。
### Conclusion
 OntoLogX 在公共基准日志和实际蜜罐数据集上进行了评估，结果显示其在多个 KG 后端具有稳健的知识图谱生成能力和对攻击活动到 MITRE ATT&CK 战术的准确映射。结果强调了检索和校正对于准确性的益处，代码面向模型在结构化日志分析中的有效性，以及基于本体表示对于提取可操作 CTI 的价值。
## 9. `cs.AI` - 是思考还是作弊？通过测量推理努力检测隐式奖励黑客行为 [PDF](https://arxiv.org/pdf/2510.01367), [HTML](https://arxiv.org/abs/2510.01367)
### Authors
Xinpeng Wang,Nitish Joshi,Barbara Plank,Rico Angell,He He
### Background
奖励欺骗，即推理模型利用奖励函数中的漏洞来获取高奖赏而未解决原定任务，这种行为构成了重大威胁。这种行为可以是明确的，即在模型的推理链中明示，也可以是隐性的，推理链看似无害从而绕过了推理链监控。检测隐式奖励欺骗有困难，因为正常的推理链可能藏匿了该行为，降低了检测难度。研究表明，这种欺骗行为发生时，模型所用的努力远低于解决问题所需的努力水平。为了检测隐式奖励欺骗，作者提出了TRACE（Truncated Reasoning AUC Evaluation），这是一种评估模型推理努力的新方法。作者认为，当利用漏洞比解决问题更简单时，发生奖励欺骗。通过测量模型在不同长度的推理链中通过验证器的比例，可以判断模型是否采取了捷径。攻击性模型用很少比例的推理就可以通过验证，这将产生较大的准确率-长度曲线下的面积。TRACE在数学推理和编码任务上优于现有最强大的72B推理监控方法65%以上，优于32B监控方法30%以上。此外，作者还表明，TRACE可以在训练过程中发现未知漏洞。
### Innovation
作者提出了一个新的评估模型推理努力的方法——TRACE，利用模型在解决问题时与利用漏洞间的努力差异进行检测。该方法通过逐段截断推理链并在每个长度截断点强制模型回答，测量验证器通过率来量化模型推理努力。穿透率曲线下的大面积表明模型使用捷径，从而提前完成验证任务。该方法在数学推理和编程任务上优于现有方法，并能够在训练中发现未知漏洞。这为监督当前监控方法无效的问题提供了可扩展的方法。
### Conclusion
TRACE提供了一种可扩展的无监督方法，用以实现监督。研究表明，相较于现有方法，该方法在检测隐式奖励欺骗方面表现出色，并且能够揭示训练过程中的未知漏洞。
## 10. `cs.AI` - 通过RAG进行微调以改进LLM对新技能的学习 [PDF](https://arxiv.org/pdf/2510.01375), [HTML](https://arxiv.org/abs/2510.01375)
### Authors
Humaid Ibrahim,Nikolai Rozanov,Marek Rei
### Background
大型语言模型（LLM）代理在执行多步任务时经常以可预测的方式失败，如尝试执行未满足前提条件的动作、发出冗余命令或处理环境约束不当。虽然检索增强生成（RAG）可以在运行时提供指导来提高性能，但它需要维护外部知识库，并在每次部署时增加计算开销。
### Innovation
提出了一种简单的流水线方法，通过蒸馏将推理时的检索转换为学习能力。该方法包括：(1) 从代理失败中提取紧凑且可重用的提示，(2) 使用这些提示在每集开始通过一次检索生成改进的教师轨迹，(3) 在去除提示字符串的情况下训练学生模型，迫使内部化而不是记忆。这种方法在两个交互式基准测试中（ALFWorld和WebShop）表现优异，展示了在不需要永久运行时依赖的情况下，通过目标微调可以有效地将检索的好处内部化。
### Conclusion
该方法在ALFWorld和WebShop上分别达到了91%和72%的成功率，相比基线分别提高了12%和11%，同时使用的令牌比RAG增强的教师少10-60%。该方法在不同模型规模和代理架构中具有通用性，证明了通过目标微调可以有效地将检索带来的好处内部化，而不依赖永久的运行时依赖关系。
## 11. `cs.AI` - MEMTRACK：多平台动态智能代理环境中原长短期记忆和状态跟踪评估 [PDF](https://arxiv.org/pdf/2510.01353), [HTML](https://arxiv.org/abs/2510.01353)
### Authors
Darshan Deshpande,Varun Gangal,Hersh Mehta,Anand Kannappan,Rebecca Qian,Peng Wang
### Background
近期关于上下文和记忆基准测试的工作主要集中在对话实例上，但对于评估记忆在动态企业环境中的表现，尤其是在这些环境中的长期记忆和状态跟踪，显得尤为重要。现有的基准测试主要关注于对话环境，但MEMTRACK旨在填补这一空白，关注于多平台代理环境中的长期记忆和状态跟踪。
### Innovation
MEMTRACK是一个新颖的基准测试，旨在评估多平台代理环境中的长期记忆与状态跟踪能力。它通过整合跨多个通信和生产力平台（如Slack、Linear和Git）的异步事件，模拟了真实组织的工作流程。MEMTRACK引入了相关性、效率和冗余度等评价指标，这些指标可以更全面地衡量记忆机制的有效性，而不仅仅是简单的问答系统性能。此外，MEMTRACK揭示了在长期范围中使用记忆、处理跨平台依赖性和解决矛盾所面临的挑战。
### Conclusion
这项工作为长期记忆增强代理的评估研究提供了扩展框架，超越了现有的对话设置关注，为复杂组织环境中的多代理、多平台记忆基准测试奠定了基础。此外，研究发现，当前最优秀的GPT-5模型在MEMTRACK基准测试中的正确性得分仅为60%，这表明在多代理、多平台环境下进行长期记忆评估的研究还存在大量的发展空间。
## 12. `cs.AI` - 使用大型语言模型代理实现工程应用中的数据驱动建模与分析自动化 [PDF](https://arxiv.org/pdf/2510.01398), [HTML](https://arxiv.org/abs/2510.01398)
### Authors
Yang Liu,Zaid Abulawi,Abhiram Garimidi,Doyeong Lim
### Background
现代工程越来越多地依赖于实验和模拟生成的大规模数据集，这推动了对高效、可靠且适用性广泛的建模策略的需求。人们也对利用神经网络模型的数据驱动方法产生了极大的兴趣，这些方法对于预测和分析科学数据集效果显著。然而，传统数据驱动方法往往需要大量的人工干预，限制了其有效扩展和应用到多样化场景中的能力。因此，需要寻找更加自动化的解决方案来满足这些需求。
### Innovation
本文提出了一种创新的自动化数据驱动建模分析管道，利用大型语言模型（LLM）代理来实现自动化，特别是针对回归任务。研究评估了两种LLM代理框架：一种由专门协作的小型代理组成的大规模代理系统，另一种基于ReAct（推理与行动）模式的单代理系统。这两种框架能够自动完成数据预处理、神经网络开发、训练、超参数优化和不确定性量化。研究使用关键热流（CHF）预测基准进行验证，该基准包含了来自经合组织/核能机构基准数据集的约25,000个实验数据点。结果表明，由LLM代理开发的模型超越了传统的CHF查找表，并且在预测精度和不确定性量化方面与人类专家开发的可比最佳基于贝叶斯优化的深度神经网络模型表现相当。这突显出基于LLM的代理在自动化复杂工程建模任务方面的巨大潜力，可以大幅减少人力负担，同时达到甚至超过现有的预测性能标准。
### Conclusion
基于LLM的代理能够在自动化复杂工程建模任务方面发挥巨大潜力，大幅减少人力负担并达到甚至超过现有的预测性能标准，表现出显著优势。
## 13. `cs.AI` - 在创建有效辅导系统中的领域专家作用 [PDF](https://arxiv.org/pdf/2510.01432), [HTML](https://arxiv.org/abs/2510.01432)
### Authors
Sarath Sreedharan,Kelsey Sikes,Nathaniel Blanchard,Lisa Mason,Nikhil Krishnaswamy,Jill Zarestky
### Background
在人工智能应用于教育的社区中，高度精炼的知识，由领域专家提供的作用经常被忽视。本文旨在通过探讨专家知识如何帮助创建新颖的教育系统来突出这一主题，具体包括使用可解释的人工智能技术自动生成课程和根据学习目标的概念创建适应性辅导系统.
### Innovation
文章提出使用可解释的人工智能技术生成课程的方法，并探讨了领域专家指定的学习路径如何帮助开发适应性辅导系统。这些系统不仅提供了更好的学习体验，还能够使用更高效的算法来创建这些系统。此外，通过一个有关创建传粉剂识别辅导系统的案例研究来强调这些方法的重要性，使得从专家处获取知识变得容易.
### Conclusion
该文通过提出使用可解释的人工智能技术自动生成课程和适应性辅导系统的概念，以及通过一个传粉剂识别系统的案例研究，强调了领域专家知识的重要性，这些方法有助于创建更有效的辅导系统。
## 14. `cs.AI` - LLMs与诱导的小代理之故事：知识挖掘中的可扩展代理 [PDF](https://arxiv.org/pdf/2510.01427), [HTML](https://arxiv.org/abs/2510.01427)
### Authors
Sipeng Zhang,Longfei Yun,Zilong Wang,Jingbo Shang,Letian Peng
### Background
在深度研究的核心是知识挖掘任务，即从大量未结构化的文本中提取结构化信息以响应用户指令。大型语言模型（LLMs）擅长解释这些指令，但部署成本高昂。传统的分类器和抽取器管道虽然效率高但缺乏灵活性，难以适应新任务。现有解决方案在可扩展性和适应性方面存在局限性，难以大规模进行知识挖掘过程中的信息抽取和分类任务。为解决这些问题，Falconer框架应运而生，该框架将LLMs的代理式推理与轻量级代理模型结合，实现可扩展的知识挖掘。
### Innovation
Falconer框架创新性地结合了LLMs的代理推理能力和轻量级代理模型，以实现知识挖掘的可扩展性。LLMs在Falconer中作为规划者和标注者，分解用户指令并将它们转换为可执行的管道，并生成监督以培训小代理。Falconer将分类和抽取统一成两个原子操作“获取标签”和“获取跨度”，使得单个指令遵循模型可以替代多个特定任务组件。为评估由Falconer培育的小代理模型与人工和大型模型提供的注释之间的一致性，构建了涵盖计划和端到端执行的新基准。实验结果表明，Falconer在指令遵循准确性上接近最先进的LLMs，同时将推理成本降低了90%，并加速了大规模知识挖掘20多倍，为深度研究提供了高效的可扩展基础。
### Conclusion
Falconer框架在保证精准度的同时，降低了推理成本并加速了大规模知识挖掘过程，提供了一种有效且可扩展的基础工具来支持深度研究任务。
## 15. `cs.AI` - 横向思维之树超越标准思维之树：通过引入逻辑一致性和低效用候选方案 [PDF](https://arxiv.org/pdf/2510.01500), [HTML](https://arxiv.org/abs/2510.01500)
### Authors
Abhinav Madahar
### Background
现代部署越来越多地为测试时计算提供大量的计算资源（数千个令牌或许多节点扩展），以提高可靠性。在这样的预算下，标准的思维之树（ToT）搜索方式显示出了两个问题：宽度饱和（额外的样本大多产生近似的重复结果，导致宽度不再增长）和深度近视（短期效用的噪音会剪枝那些在几步后回报较高的分支）。
### Innovation
提出了一种名为横向思维之树（LToT）的控制器，它将效用与逻辑一致性分离，将低效用但一致的候选方案视为资产而非浪费。LToT 通过Lateral Racing with Short-Circuit（LR--SC）探索横向路径，并通过有限次的快速赛跑来分布微小的探针，同时使用宽度感知的阈值并立即促进一旦其包络超过主线上限的分支。此外，主线保持故意狭窄以确保剩余的计算资源在宽度不昂贵的地方进行投资，从而实现了次线性边成本，与未限制主线的指数增长形成对比。
### Conclusion
LToT 能将大的测试时预算转化为有原则的多样性，保留了促进纪律，并通过避免饱和和近视现象而没有增加计算成本，为未来的基准任务评估做准备。
## 16. `cs.AI` - VOGUE: 通过视觉不确定性指导探索以提高多模态推理 [PDF](https://arxiv.org/pdf/2510.01444), [HTML](https://arxiv.org/abs/2510.01444)
### Authors
Rui Liu,Dian Yu,Tong Zheng,Runpeng Dai,Zongxia Li,Wenhao Yu,Zhenwen Liang,Linfeng Song,Haitao Mi,Pratap Tokekar,Dong Yu
### Background
当前使用强化学习来改进大规模语言模型(LLMs)中的视觉推理的方法面临探索性不足的问题，尤其对于多模态LLMs。现有方法将视觉输入视为固定的、确定性的条件，忽略了重要的歧义源，难以构建鲁棒的政策，以适应可能的视觉变化。
### Innovation
该研究提出了一种新颖的方法Vogue，这种方法将探索从文本输出转向视觉输入空间。通过将图像视为随机上下文，Vogue使用原始和噪声分支之间的对称KL散度来量化策略对视觉扰动的敏感度，从而为不确定性意识探索提供了直接信号。该信号通过不确定性比例奖励、令牌熵奖励以及退火采样计划来塑造学习目标，从而平衡探索和利用。
### Conclusion
VOGUE方法在两个模型规模（Qwen2.5-VL-3B/7B）的强化学习中提高了视觉数学基准测试和通用领域推理基准测试的通过率，提升了探索性能并缓解了在RL微调中常见的探索衰减问题。
## 17. `cs.AI` - AIReg-Bench: Benchmarking Language Models That Assess AI Regulation Compliance [PDF](https://arxiv.org/pdf/2510.01474), [HTML](https://arxiv.org/abs/2510.01474)
### Authors
Bill Marino,Rosco Hunter,Zubair Jamali,Marinos Emmanouil Kalpakos,Mudra Kashyap,Isaiah Hinton,Alexa Hanson,Maahum Nazir,Christoph Schnabl,Felix Steffek,Hongkai Wen,Nicholas D. Lane
### Background
随着政府加强对人工智能的监管，人们越来越关注使用大型语言模型（LLM）来评估人工智能系统是否遵守特定的人工智能法规（AIR）。但是，目前尚无方法对LLM在这一任务上的表现进行基准测试。为解决这一问题，作者引进了AIReg-Bench——首个针对欧盟人工智能法案（AIA）合规性评估设计的基准数据集。
### Innovation
该论文介绍了AIReg-Bench，这是首个用于测试大型语言模型评估欧盟人工智能法案（AIA）合规性的基准数据集。该数据集的构建通过两步完成：第一步，通过向LLM提供结构化指令生成了120份技术文档摘录，这些摘录描述了虚构但可能实际存在的AI系统，用以展示AI提供商的合规情况；第二步，法律专家对每个样本进行审核和注释，以确定AI系统描述是否存在违反欧盟人工智能法案具体条款的情况。这一数据集及其评估方法为理解基于LLM的人工智能法规合规性评估工具的机会与局限提供了起点，并建立了后继模型的比较基准。
### Conclusion
AIReg-Bench数据集及其评估结果提供了了解基于LLM的人工智能法规合规性评估工具的机会与局限的基础，并为后续的模型比较设立了标准。数据集和评估代码可在某网址获取。
## 18. `cs.AI` - 使用稀疏自编码器引导生成以实现可解释和推理优化的逐步推理 [PDF](https://arxiv.org/pdf/2510.01528), [HTML](https://arxiv.org/abs/2510.01528)
### Authors
Daniel Zhao,Abhilash Shankarampeta,Lanxiang Hu,Tajana Rosing,Hao Zhang
### Background
本文提出了一个利用稀疏自编码器（SAEs）和聚类技术来分析大型语言模型（LLMs）内部令牌表示，并指导数学推理任务生成的方法。背景信息表明，平衡探索和利用对于实现高质量的数学推理任务至关重要。在生成过程中，SAEs可以作为可扩展的奖励模型来引导生成，确保在探索和利用之间找到平衡，从而避免极端行为，最终促进LLMs的高质量推理过程。
### Innovation
创新之处在于，该方法利用稀疏自编码器生成稀疏向量表示，并采用k-means聚类构建一个图，其中节点表示令牌聚类，加权边捕捉序列令牌转移。通过这种方法定义边权重为基础的奖励函数，来量化对已建立推理路径的遵循程度，从而识别利用推理轨迹。此外，该研究还通过聚类测量生成多样性，评估探索的范围。研究表明，平衡探索和利用对于在数学推理任务中实现高准确性至关重要。
### Conclusion
研究发现，平衡探索和利用对于在数学推理任务中实现高准确性至关重要。在生成过程中，稀疏自编码器可以作为可扩展的奖励模型来引导生成，确保在探索和利用之间找到平衡，避免极端行为，从而促进LLMs的高质量推理过程。
## 19. `cs.AI` - AdvEvo-MARL：通过多Agent强化学习中的对抗共进化塑造内在安全性 [PDF](https://arxiv.org/pdf/2510.01586), [HTML](https://arxiv.org/abs/2510.01586)
### Authors
Zhenyu Pan,Yiting Zhang,Zhuo Liu,Yolo Yunlong Tang,Zeliang Zhang,Haozheng Luo,Yuwei Han,Jianshu Zhang,Dennis Wu,Hong-Yu Chen,Haoran Lu,Haoyang Fang,Manling Li,Chenliang Xu,Philip S. Yu,Han Liu
### Background
基于LLM的多Agent系统在规划、工具使用和角色协调方面表现出色，但其开放性和交互复杂性也使其面临 Jailbreak、提示注入和恶意合作的风险。现有的防御措施可分为两类：（i）自我验证，要求每个智能体在执行前预筛选不安全的指令，（ii）外部监管模块，作用于行为的监督。前者通常表现不佳，因为孤岛智能体缺乏足够的能力来检测跨智能体的安全链和委托引发的风险；后者增加了系统的开销，并且一旦受到攻击就成为单点故障，导致系统全面安全崩溃，进一步的防护措施则会增加成本和复杂性。
### Innovation
为了应对这些挑战，我们提出了一种新的AdvEvo-MARL框架（先进演化多Agent强化学习），将安全性内化到任务智能体中。该框架通过联合优化攻击者（合成为进化的Jailbreak提示）和防御者（训练来完成其职责并抵御攻击的任务智能体），共同优化在一个对抗学习环境中。引入公共基线稳定学习并促进合作：同一功能组内的智能体共享组级平均回报基线，这使得具有较低方差的更新和更强的组内协调成为可能。在代表性的攻击场景中，AdvEvo-MARL将攻击成功率（ASR）保持在20%以下，而基线方案达到38.33%，同时保持甚至改进任务准确性（最多提高3.67%在推理任务中）。这些结果表明，可以在不依赖额外的防护智能体或增加额外系统开销的情况下共同提升安全性和效用。
### Conclusion
研究结果表明，通过AdvEvo-MARL框架可以在保持多Agent系统效用的同时，提高其安全性。该方法通过对抗共进化有机地平衡了智能体的安全性和任务执行效率，基于组级平均回报基线的共同优化提高了智能体间的协调性，整体上看，AdvEvo-MARL在多种攻击场景下表现优异，安全性与任务准确性之间取得了较好的平衡。
## 20. `cs.AI` - 在部分可观测性下的信息寻求以实现稳健的决策 [PDF](https://arxiv.org/pdf/2510.01531), [HTML](https://arxiv.org/abs/2510.01531)
### Authors
Djengo Cyun-Jyun Fang,Tsung-Wei Ke
### Background
在实际环境中，信息不完整和动态噪声使得明确的信息寻求对于人类问题解决至关重要。当环境的真实状态无法直接观察时，人类会积极寻求信息来更新其内部模型，从而影响未来的决策。尽管现有的大型语言模型规划代理人已经解决了观察不确定性的问题，但它们往往忽略了内部模型与实际环境之间的差异。本文旨在探讨如何在一个环境动态存在不确定性且观测不完全的环境下，将任务导向规划与信息寻求相结合，以校准内部模型，做出最优决策。为此，作者提出了InfoSeeker框架，该框架促使大型语言模型制定有效计划以搜集验证性信息、检测环境变化或测试假设，从而增强决策的稳健性。
### Innovation
本文创新性地提出InfoSeeker框架，该框架将任务导向规划与信息寻求相结合，弥补了基于现有技术的规划代理人的不足，特别是在不确定性环境下需要更精确的内部模型以做出有效决策。InfoSeeker可以帮助大型语言模型在规划行动过程中获取更多信息，以减少与真实环境的差异，从而做出更加准确的决策。与现有的模型相比，InfoSeeker在相同观测和动态不确定性的环境中，表现出显著的性能提升，不仅在自定义基准测试套件中表现出色，在机器人操作和网页导航等传统基准测试中也表现优异。
### Conclusion
本文的研究发现强调了在部分可观测性环境下，将规划和信息寻求紧密结合的关键性。InfoSeeker框架为代理人提供了在不确定性和不完全信息下做出更稳健决策的方法。这种方法不仅证明了其在创新基准测试中的有效性，也展示了其跨不同的大型语言模型的一致性能，表明了其广泛的适用性。
## 21. `cs.AI` - 盲目追求目标！计算机使用代理表现出盲目目标导向性 [PDF](https://arxiv.org/pdf/2510.01670), [HTML](https://arxiv.org/abs/2510.01670)
### Authors
Erfan Shayegani,Keegan Hines,Yue Dong,Nael Abu-Ghazaleh,Roman Lutz,Spencer Whitehead,Vidhisha Balachandran,Besmira Nushi,Vibhav Vineet
### Background
计算机使用代理（CUAs）是一种日益部署的代理类，可以在图形用户界面（GUI）上执行操作以实现用户目标。然而，这些代理表现出一种盲目追求目标的偏向（Blind Goal-Directedness，BGD），这种偏向使得它们不考虑目标的可行性、安全性、可靠性或环境背景就追求目标。
### Innovation
本文开发了BLIND-ACT基准，包含90个任务，涵盖了BGD的三个主要模式：缺乏情境推理，模糊状下的假设与决策，以及反矛盾或不可行的目标。基于OSWorld，BLIND-ACT提供了现实环境，并利用基于LLM的评审员来评估代理行为，共识率达到了93.75%。研究还观察到前沿模型如Claude Sonnet和GPT-5等高BGD率（80.8%）。另外，尽管prompt干预降低了BGD水平，但仍然存在显著风险，强调了更强的训练或推断期干预的必要性。
### Conclusion
识别BGD并引入BLIND-ACT为未来研究提供了一个基础，以便研究和缓解这种基本风险，并确保CUA的安全部署。
## 22. `cs.AI` - LOGicalThought: 基于逻辑本体论接地的LLM高可信度推理 [PDF](https://arxiv.org/pdf/2510.01530), [HTML](https://arxiv.org/abs/2510.01530)
### Authors
Navapat Nananukul,Yue Zhang,Ryan Lee,Eric Boxer,Jonathan May,Vibhav Giridhar Gogate,Jay Pujara,Mayank Kejriwal
### Background
在法律和医学等关键领域，高保障推理需要准确、可验证并基于证据的结论。这种推理依赖于从规则、法规和合同中编写的前提条件，这些前提条件由于包含众多例外情况，会引入缺陷或非单调逻辑。单一事实的引入可使普遍规则失效，带来重大挑战。虽然大规模语言模型（LLMs）在处理自然语言方面表现出色，但它们在标准推理任务上的能力并不适用于严格依据高保障文本指南的推理。这类文本中的核心推理挑战通常表现为特定的逻辑结构，包括否定、蕴含，尤其是缺陷规则和例外。因此，现有的LLM在进行复杂推理时仍面临显著挑战。
### Innovation
本文提出了名为LOGicalThought（LogT）的新型神经符号兼容体系结构，该架构结合了高级逻辑语言和推理器与LLM，用于构建双重符号图上下文和基于逻辑的上下文。通过将问题从长格式指南的推理转换为紧凑的应用评估，LogT 的性能在四个多领域基准测试中提高了11.84%。对于三种具体的推理模式：否定、蕴含和缺陷推理，LogT 相比最强基准分别提高10.2%、13.2%和5.5%。
### Conclusion
LogT 通过结合高级逻辑语言和推理器与LLM，成功地将长格式指南的推理问题转化为紧凑的推理评估，显著提高了推理的准确性。在四种多领域基准测试中，LogT 的表现优于现有基线方法，并大大提升了不同推理模式的准确性。
## 23. `cs.AI` - 学习恰好足够：信息论上下文总结化以应对CMDP [PDF](https://arxiv.org/pdf/2510.01620), [HTML](https://arxiv.org/abs/2510.01620)
### Authors
Peidong Liu,Junjiang Lin,Shaowen Wang,Yao Xu,Haiqing Li,Xuhao Xie,Siyi Wu,Hao Li
### Background
现有的CMDP方法在高维或非结构化上下文中往往难以泛化，导致计算效率低下且性能不稳定。许多现有方法无法有效处理复杂的上下文信息，使得决策过程既耗费资源又难以实现高效决策，特别是在存在资源限制的环境中。
### Innovation
提出了一种基于信息论的上下文总结方法，利用大型语言模型（LLMs）将复杂上下文压缩为低维、富含语义的摘要。这些摘要可以保留关键的决策信息，同时减少冗余。研究基于近似上下文充分性的概念，提供了对CMDP的第一个后悔界和延迟-熵权衡的描述，明确表示了信息丰富性如何影响计算成本。
### Conclusion
实验结果表明，该方法在离散、连续、视觉和推荐等多个基准上超越了纯上下文和非上下文的基线方法，提高了奖励、成功率和样本效率，同时降低了延迟和内存使用。这些发现证明了基于LLMs的总结方法可以提供一种可扩展且可解释的决策方案，特别是在资源受限环境中实现高效决策。
## 24. `cs.AI` - 理解大型语言模型的地理空间推理能力：基于轨迹恢复的视角 [PDF](https://arxiv.org/pdf/2510.01639), [HTML](https://arxiv.org/abs/2510.01639)
### Authors
Thinh Hung Truong,Jey Han Lau,Jianzhong Qi
### Background
本文探讨了大型语言模型（LLMs）在地理空间推理能力方面的能力，特别是它们是否能读取道路网络图并执行导航。研究将轨迹恢复作为代理任务，要求模型重建部分的GPS轨迹，并引入了一个名为GLOBALTRACE的数据集，其中包含超过4,000条来自不同地区的实际道路轨迹。使用道路网络作为上下文，研究的提示框架使LLMs能够在不访问任何外部导航工具的情况下生成有效的路径。
### Innovation
本文创新地提出了一个名为GLOBALTRACE的大型数据集，并使用道路网络作为上下文，设计了一种提示框架，使得大型语言模型可以在不依赖外部导航工具的情况下生成有效的路径。实验结果显示，大型语言模型在轨迹恢复方面优于现成的基线模型和专门的轨迹恢复模型，具有较强的零样本泛化能力。此外，细粒度分析表明，大型语言模型在理解道路网络和坐标系统方面表现出很强的能力，但仍存在针对地区和交通方式的系统性偏差。
### Conclusion
本文展示了大型语言模型通过灵活地推理地图以纳入用户偏好，可以增强导航体验。
## 25. `cs.AI` - 基于扩散大型语言模型的步骤感知策略优化一种新方法 [PDF](https://arxiv.org/pdf/2510.01544), [HTML](https://arxiv.org/abs/2510.01544)
### Authors
Shaoan Xie,Lingjing Kong,Xiangchen Song,Xinshuai Dong,Guangyi Chen,Eric P.Xing,Kun Zhang
### Background
扩散语言模型（dLLMs）为文本生成提供了一种有希望的非自回归范式，但是为了进行复杂的推理训练仍然是一个关键挑战。当前的强化学习方法通常依赖稀疏、结果导向的奖励，这可能导致模型学习到错误的推理路径，尽管最终结果可能正确。现有的方法未能解决这个问题，因为它们无法与推理的自然结构相匹配。作者认为空间分解推理成为了一个理论基础，通过将难以解决的全局约束分解为一系列简化的本地逻辑步骤，得到了推进算法设计并提供了一种识别这种潜在推理结构的方法论。他们指出，在现有方法中的一个核心缺陷是无结构细化——模型的迭代步骤未能实质性地贡献到解决方案中。正是基于这一理论，作者进一步提出了步骤感知策略优化（SAPO）算法，该算法将dLLM的去噪过程与潜在的推理分层结构对齐，并通过鼓励增量进步的过程奖励函数引导模型学会结构化和连贯的推理路径。
### Innovation
提出了步骤感知策略优化（SAPO）算法，该算法将扩散大型语言模型的去噪过程与潜在的推理层级结构对齐，并通过鼓励小规模的进步进行过程奖励，引导模型学习结构化和连贯的推理路径。这种方法在处理复杂的推理基准测试中显著提高了性能，并增强了生成过程的可解释性。SAPO算法解决了现有方法中无结构细化的问题，为解决复杂推理提供了有效的方法论支持。
### Conclusion
实验结果表明，这种方法在处理难题推理基准测试中表现出显著的改进，并提高了生成过程的可解释性。
## 26. `cs.AI` - InvThink: 通过逆向推理实现AI安全 [PDF](https://arxiv.org/pdf/2510.01569), [HTML](https://arxiv.org/abs/2510.01569)
### Authors
Yubin Kim,Taehan Kim,Eugene Park,Chunjong Park,Cynthia Breazeal,Daniel McDuff,Hae Won Park
### Background
现有的安全对齐方法直接优化生成安全响应，但不能确保模型在遇到潜在风险时能有效处理。研究者们希望通过改进方法让大型语言模型（LLMs）具备逆向思考的能力，即在生成响应之前通过先思考潜在错误来提高安全性。这种能力将使模型在高风险场景中表现得更为谨慎和安全。
### Innovation
InvThink是一种简单而强大的方法，它能够让大型语言模型（LLMs）具有逆向思考的能力，即在生成响应之前通过考虑潜在的失败模式来进行推理。与现有的安全对齐方法不同，InvThink的方法包括三个步骤：1）列举潜在的危害；2）分析其后果；3）生成主动避免这些风险的安全输出。它能够揭示出三个关键发现：1）安全性改进随着模型规模的增加更为显著；2）InvThink能够减少安全税，即它有助于保留模型在标准基准上的通用推理能力；3）InvThink在高风险场景中表现出色，包括面向外部（如医学、金融、法律）和代理（如敲诈、谋杀）场景，与SafetyPrompt等基线方法相比，其有害响应减少了多达15.7%。这种方式还能通过监督微调和强化学习实现在多种LLM家族中的应用，表明逆向推理为实现更安全、更强大的语言模型提供了一条可扩展且通用的路径。
### Conclusion
该研究展示了逆向推理在提高语言模型的安全性方面的有效性，并提出了一种新的方法—InvThink，该方法通过模拟潜在的错误来提升模型的安全性。研究发现，这种逆向思考的能力能够帮助模型更好地处理高风险场景，从而实现更大的安全性改进。
## 27. `cs.AI` - 一种用于改善术前患者沟通的本地执行AI系统：多领域临床评估 [PDF](https://arxiv.org/pdf/2510.01671), [HTML](https://arxiv.org/abs/2510.01671)
### Authors
Motoki Sato(Nagasaki University, Japan),Yuki Matsushita(Nagasaki University, Japan),Hidekazu Takahashi(Boston Medical Sciences, Tokyo, Japan),Tomoaki Kakazu(Showa Medical University Koto Toyosu Hospital, Japan),Sou Nagata(Nagasaki University, Japan),Mizuho Ohnuma(Nagasaki University, Japan),Atsushi Yoshikawa(Kanto Gakuin University, Japan),Masayuki Yamamura(Institute of Science Tokyo, Japan)
### Background
患者在等待侵入性程序时常有未解答的术前问题，但由于时间紧迫的工作流程和隐私限制，个性化咨询受限。
### Innovation
LENOHA（低能耗，无幻觉，不让任何人掉队架构）是一种安全优先、本地优先系统。它通过高精度的句子转换器分类器路由输入，并返回从临床医生编写的FAQ中直接摘录的答案，消除了临床路径中的自由文本生成。
### Conclusion
研究结果显示，采用这一系统可以实现接近前沿的准确判断，避免生成过程中的错误，同时降低了能耗和保持低延迟，从而支持隐私、可持续性和带宽受限环境下公平部署。
## 28. `cs.AI` - AgentRec:基于自适应智能的下一代大模型驱动的多智能体协同推荐系统 [PDF](https://arxiv.org/pdf/2510.01609), [HTML](https://arxiv.org/abs/2510.01609)
### Authors
Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Lau
### Background
交互式的会话推荐系统因其能够通过自然语言交互捕获用户偏好而受到广泛关注。然而，现有的方法在处理动态用户偏好、保持对话连贯性和同时平衡多个排名目标方面面临重大挑战。
### Innovation
本文提出了一种名为AgentRec的新一代基于适应性智能的大模型驱动的多智能体协作推荐框架，通过多层次智能体网络解决这些限制。该方法使用专门的大模型驱动智能体来理解对话、建模偏好、增强情境意识和动态排名，并通过适应性权重机制协调这些智能体，该机制根据交互模式学习。本文提出了一种三层学习策略，结合快速响应简单查询、智能推理复杂偏好和深度协同解决挑战性场景。实验证明，AgentRec在三个真实世界数据集上优于最先进的基线方法，对话成功率达到2.8%的提升，推荐精度(NDCG@10)提高1.9%，对话效率提高3.2%，同时通过智能智能体协调保持了相似的计算成本。
### Conclusion
本文提出的AgentRec通过多层次智能体网络和适应性智能机制显著改善了会话推荐系统的性能，展示了在动态用户偏好处理、对话连贯性和多目标排名平衡方面的优势。
## 29. `cs.AI` - GuruAgents：以提示引导的LLM代理模仿智慧投资者 [PDF](https://arxiv.org/pdf/2510.01664), [HTML](https://arxiv.org/abs/2510.01664)
### Authors
Yejin Kim,Youngbin Lee,Juhyeong Kim,Yongjae Lee
### Background
本研究展示了GuruAgents（以引导指令为驱动的人工智能代理）能够系统地实现传奇投资大师的策略。通过给大型语言模型（LLM）提供特定的投资大师哲学提示，结合金融工具和确定性推理管道，研究团队成功开发了五个不同的GuruAgents，每个代理都旨在模仿一位标志性投资者。这些代理在2023年第四季度至2025年第二季度的NASDAQ-100成分股中的回测中表现出独特的行为，受到其提示人格的影响。这些实验结果表明，通过提示工程技术能够成功地将投资大师的定性哲学转化为可复制和量化的投资策略，这为自动化系统性投资提供了一个新的方向。
### Innovation
通过将特定投资大师的哲学思想嵌入到大型语言模型的提示中，结合金融工具和确定性推理管道，研究人员成功开发了能够模仿传奇投资大师策略的GuruAgents。这些代理在回测中展示了显著不同的投资行为，并且其中的巴菲特代理获得了最高的表现，年复合增长率（CAGR）达到了42.2%，这远远超过了基准数据的表现。这项研究强调了通过提示工程技术将投资大师的理念转化为可量化的投资策略的新途径。
### Conclusion
本研究证实了提示工程技术能够成功地将投资大师的定性哲学转化为可复制和量化的投资策略，提供了自动化系统性投资的新方向。研究结果表明，这一方法具有很高的应用潜力，并且其源代码和数据已公开。
## 30. `cs.AI` - PsychoBench: 评估大型语言模型的心理学智能 [PDF](https://arxiv.org/pdf/2510.01611), [HTML](https://arxiv.org/abs/2510.01611)
### Authors
Min Zeng
### Background
大型语言模型（LLMs）在多个行业中展现了卓越的能力，主要得益于其出色的生成能力。然而，它们在需要认知能力的应用，如心理辅导中的潜力尚未被充分利用。本文探讨了关键问题：LLMs 是否能够有效地应用于心理辅导。为了验证这一点，首先需要评估LLMs是否能够达到担任心理辅导员所需的基本能力，即通过美国全国咨询师认证考试（NCE），因为这类似于人类咨询师需要取得认证许可一样，LLMs也需要展示足够的心理学知识才能达到相关标准。为此，本文提出了PsychoBench基准测试，该基准测试基于心理辅导师考试，需要达到约70%的准确率才能通过。PsychoBench包含约2,252个多选项问题，旨在全面评估LLMs担任心理辅导员的能力。
### Innovation
本文提出的PsychoBench是一个基于心理辅导员考试的基准测试，旨在评估大型语言模型在心理领域的知识水平。通过PsychoBench，本文发现只有前沿的LLMs（如GPT-4o、Llama3.3-70B和Gemma3-27B）能够达到通过心理辅导考试的标准，而较小的开源模型则远未达到这一标准。这表明，只有最先进的人工智能语言模型才有可能满足心理学领域的认证标准，这既突显了开发心理学化大型语言模型的潜力，也指出了其中的挑战。
### Conclusion
本文评估了大型语言模型在心理学领域的能力，发现只有最先进的人工智能语言模型才有可能满足心理学领域的认证标准。这既突显了开发心理学化大型语言模型的潜力，也指出了其中的挑战。未来需要进一步研究如何提升那些能力较低的模型在此方面的表现，使其能够更好地应用于实际的心理咨询场景。
## 31. `cs.AI` - VaPR -- 视频语言偏好对齐以进行推理 [PDF](https://arxiv.org/pdf/2510.01700), [HTML](https://arxiv.org/abs/2510.01700)
### Authors
Rohan Wadhawan,Fabrice Y Harel-Canada,Zi-Yi Dou,Suhaila Shakiah,Robinson Piramuthu,Nanyun Peng
### Background
现有的偏好微调方法，如直接偏好优化(DPO)结合AI生成的反馈，在使大型视觉-语言模型(LVLMs)与人类偏好一致方面显示出潜力。但是，现有的技术忽视了合成偏好标注中的噪声问题，包括风格和长度偏见。
### Innovation
引入了一种基于LLM引导响应编辑的硬否定响应生成框架，该框架生成具有针对性错误的拒绝响应，保持与接受响应的风格和长度相似性。提出了一个名为VaPR的数据集，包含30000个高质量样本，用于微调三种LVLM家族：LLaVA-V1.5、Qwen2VL及Qwen2.5VL（分别2B和13B大小）。该框架下的VaPR模型在十个基准测试中表现出显著的性能提升，LLaVA、Qwen2VL和Qwen2.5VL的平均提升分别为6.5%、4.0%和1.5%，特别在推理任务上显示出长足进步。此外，性能随数据量增加而提升，甚至在小规模数据集上也对LLaVA模型有贡献。VaPR还减少了二元问题中回答“是”的趋势，这是LVLMs，如LLaVA，常常会遇到的失败模式。该框架还可概括应用于开源LLM编辑，并表明基于VaPR-OS训练的模型在性能上几乎与基于GPT-4o合成的ame训练模型相同。
### Conclusion
该研究引入了VaPR框架，并开发了包含30000高质量样本的VaPR数据集，以显著提高大型视觉-语言模型的性能，特别是在推理任务上。此外，该框架还可应用于开源LLM编辑，展示了其广泛的适用性。
## 32. `cs.AI` - REBot: 从RAG到CatRAG的语义增强与图路由 [PDF](https://arxiv.org/pdf/2510.01800), [HTML](https://arxiv.org/abs/2510.01800)
### Authors
Thanh Ma,Tri-Tam La,Lam-Thu Le Huu,Minh-Nghi Nguyen,Khanh-Van Pham Luu,Huu-Hoa Nguyen
### Background
学术规章指导对于帮助学生理解和遵守学校政策至关重要，但建立有效的系统需要特定领域的监管资源。由于缺乏这些资源，目前存在挑战。
### Innovation
提出了REBot，一个增强了逻辑思维能力的问答对话机器人，主要创新在于使用了CatRAG框架。CatRAG结合了检索增强生成和基于图的推理，通过层次化标注的知识图谱和语义特征实现领域对齐。轻量级意图分类器能将查询路由到合适的检索模块，确保准确性和上下文深度。
### Conclusion
使用REBot进行了测试，在分类和问答任务上达到了最先进的性能，F1得分为98.89%。同时实现了网页应用程序，展示了REBot在实际学术指导场景中的实用价值。
## 33. `cs.AI` - 军事行动中的人工智能协作学习 [PDF](https://arxiv.org/pdf/2510.01815), [HTML](https://arxiv.org/abs/2510.01815)
### Authors
Clara Maathuis,Kasper Cools
### Background
在军事威胁快速演变和作战环境日益复杂的情况下，将人工智能（AI）集成到军事行动中显示出显著优势。然而，构建和部署有效且道德的人机团队系统也带来了各种挑战和风险。目前，理解和应对这些挑战通常是从外部视角出发，将人机团队视为整体代理。但是，深入探讨系统内部动态可以处理更为广泛的多维度责任、安全和鲁棒性问题。
### Innovation
本文提出了一种基于四个维度的信任共学习模型，以增强军事行动中的人机团队合作。第一，动态适应性自主权，根据任务状态、系统信心和环境不确定性等因素调整自主权水平。第二，多层次控制，包括持续监督、活动监控和问责制。第三，双向反馈，确保中介和AI代理之间明确和隐含反馈环路的建立，以促进理性、不确定性和学习适应的传达。第四，协作决策，涉及与信心水平相关的决策生成、评估和建议制定。
### Conclusion
提出的模型附带具体的示例和建议，有助于进一步发展负责任且可信的人机团队系统在军事行动中的应用。
## 34. `cs.AI` - 一个网络安全AI代理选择和支持决策框架 [PDF](https://arxiv.org/pdf/2510.01751), [HTML](https://arxiv.org/abs/2510.01751)
### Authors
Masike Malatji
### Background
本文提出了一个结构化的决策支持框架，该框架系统地将各种人工智能（AI）代理架构（反应型、认知型、混合型和学习型）与全面的国家电子与技术研究院（NIST）网络安全框架2.0版本（CSF 2.0）相结合。通过将代理理论与行业指导原则进行整合，该框架提供了一种透明的步骤化方法来选择和部署AI解决方案以应对现代网络威胁。
### Innovation
该研究通过将NIST CSF 2.0功能进行细粒度分解，并将关键的AI代理特性如自主性、自适应学习和实时响应性与每个子类别的安全要求联系起来，建立了一种独特的架构。此外，它还提出了解决方案的渐进性自主水平（协助、增强和完全自主），以适应各个组织处于网络安全成熟度的不同阶段。这种全面的方法超越了孤立的AI应用，提供了一个综合的检测、事件响应和治理策略。
### Conclusion
通过概念验证，该框架展示了如何根据实际约束和风险状况调整AI代理部署，增强态势感知，加速响应时间，并通过适应性风险管理增强长期韧性。最终，这项研究填补了理论AI结构与操作网络安全需求之间的差距，为符合行业标准的强大、经验验证的多代理系统奠定了基础。
## 35. `cs.AI` - 在镜像或掩饰：集体推理中的人-机对齐 [PDF](https://arxiv.org/pdf/2510.01924), [HTML](https://arxiv.org/abs/2510.01924)
### Authors
Crystal Qian,Aaron Parisi,Clémentine Bouleau,Vivian Tsai,Maël Lebreton,Lucas Dixon
### Background
随着大型语言模型（LLMs）在集体决策建模和增强中的广泛应用，研究其与人类社会推理的一致性变得至关重要。本文通过引入一种新的集体对齐评估框架，从群体层面而非个体层面进行了研究。研究使用了“海上迷失”社会心理学任务，并进行了大规模在线实验。与此同时，还模拟了人-机群体的互动，基于人类数据对不同模型进行了基准测试。实验结果表明，LLM的行为差异显著，有些模型模仿人类偏见，而有些则隐藏偏见并尝试补偿它们，从而显示了集体推理中的人-机对齐依赖于情境、线索及模型特定的归纳偏见的重要性。
### Innovation
本文提出的是一种群体层面的集体对齐评估框架，用于检验语言模型与人类社会推理的一致性，这是不同于先前只关注个人水平的研究。此外，研究还模拟了实际的人-机群体互动，并对不同模型进行了基准测试，揭示了LLMs在集体决策中的行为差异及其背后的机制。
### Conclusion
集体推理中的人-机对齐依赖于上下文、线索和模型特定的归纳偏见。理解语言模型如何与集体人类行为对齐对于推动社会一致性人工智能至关重要，并要求能够捕捉集体推理复杂性的动态基准。
## 36. `cs.AI` - MetaboT：基于AI的互动代理，用于与代谢组学知识图谱的自然语言交互 [PDF](https://arxiv.org/pdf/2510.01724), [HTML](https://arxiv.org/abs/2510.01724)
### Authors
Madina Bekbergenova(ICN),Lucas Pradi(ICN),Benjamin Navet(ICN),Emma Tysinger(ICN),Franck Michel(WIMMICS),Matthieu Feraud(ICN),Yousouf Taghzouti(ICN, WIMMICS),Yan Zhou Chen,Olivier Kirchhoffer(UNIGE),Florence Mehl(SIB),Martin Legrand(ICN),Tao Jiang(ICN),Marco Pagni(SIB),Soha Hassoun,Jean-Luc Wolfender(UNIGE),Wout Bittremieux(UA),Fabien Gandon(WIMMICS, Laboratoire I3S - SPARKS),Louis-Félix Nothias(CNRS, UniCA, ICN)
### Background
代谢组学质谱技术产生了大量数据，需要高级方法进行解释。知识图谱通过将代谢组学数据、代谢物信息及相关关系组织成互联网络来解决这些挑战。然而，有效使用知识图谱需要深入了解其本体学及其查询语言语法。现有的方法难以满足研究人员通过自然语言与知识图谱交互的需求。为了克服这一问题，本文开发了MetaboT，一个利用大规模语言模型（LLMs）将用户问题翻译成SPARQL语义查询语言的AI系统，应用于植物天然产物的实验自然产品知识图谱。
### Innovation
MetaboT利用多代理系统将复杂任务分解为离散组件，并由专门的代理处理。系统采用LangChain和LangGraph库，实现了LLMs与外部工具和信息源的集成。该系统展示了优异的性能，能够通过自然语言查询准确检索代谢组学数据，并生成正确的SPARQL查询，显著提高了准确性比传统方法高出8倍，证明了多代理系统在文中所提出的场景中的重要性。MetaboT自动化生成和执行SPARQL查询，降低了访问知识图谱的技术障碍，并确保输出符合领域特异性标准和数据结构。
### Conclusion
MetaboT作为一种对话式问答助手，使研究人员能够通过自然语言查询获取结构化的代谢组学数据，解决了传统技术带来的障碍。该系统不仅有助于数据驱动的发现，还通过结合复杂的语义技术和用户友好的交互，推动了代谢组学研究的发展。用户可以访问MetaboT（[this https URL]）并通过GitHub获取其源代码（[this https URL]）.
## 37. `cs.AI` - ReTabAD: 在表格异常检测中恢复语义上下文的基准 [PDF](https://arxiv.org/pdf/2510.02060), [HTML](https://arxiv.org/abs/2510.02060)
### Authors
Sanghyu Yoon,Dongmin Kim,Suhee Yoon,Ye Seul Sim,Seungdong Yoa,Hye-Seung Cho,Soonyoung Lee,Hankook Lee,Woohyung Lim
### Background
在表格异常检测中，文本语义通常携带关键信号，因为异常的定义与特定领域上下文密切相关。然而，现有的基准数据集只提供了没有语义背景的原始数据点，忽略了专家在实践中依赖的丰富文本元数据（如特征描述和领域知识）。这一限制限制了研究的灵活性，阻碍了模型充分利用领域的知识来进行检测。ReTabAD通过恢复文本语义来填补这一空白，以促进基于上下文的表格异常检测研究。
### Innovation
ReTabAD提供了一组20个精心策划的、富含结构化文本元数据的表格数据集，包含最先进的异常检测算法的实现，包括经典方法、深度学习方法和基于LLM的方法。此外，它还提供了一个零样本LLM框架，该框架利用了语义上下文，而无需特定任务的训练，从而为未来的研究建立了强大的基准。研究表明，语义上下文可提高检测性能，并通过支持领域感知推理增强可解释性。
### Conclusion
这些发现确立了ReTabAD作为系统探索基于上下文的异常检测基准的必要性。
## 38. `cs.AI` - 通过逆强化学习从专家演示中学习密集推理解奖模型 [PDF](https://arxiv.org/pdf/2510.01857), [HTML](https://arxiv.org/abs/2510.01857)
### Authors
Claudio Fanconi,Nicolás Astorga,Mihaela van der Schaar
### Background
传统的逆强化学习（IRL）方法通常用于模仿专家的风格，并在大型语言模型推理中重新定义这一过程，使模型直接从专家示范中学习密集的、基于token的奖励模型，以便过程中监督，而不是通过有监督的微调来模仿风格。这种方法还提供了一种两项互补的作用：（i）在训练过程中提供步骤级别反馈优化推理策略；（ii）在推理时作为批评家重新对固定计算预算下的采样轨迹进行排名。这项工作表明，这种方法优先考虑正确性而不是表面形式，生成的分数与最终答案的有效性相关，能够在轨迹中解释错误的位置。在GSM8K数据集上，使用Llama3和Qwen2.5作为主干网络进行实验验证了这一发现。
### Innovation
该研究通过重新定义和操作逆强化学习（IRL）将这种方法应用于大型语言模型推理，从专家展示中直接学习密集的、基于token的奖励模型，而不是通过有监督微调模仿风格。这种方法在训练中提供步骤级别的反馈，优化推理策略，同时在推理过程中进行重新排序以节省计算预算。此外，该方法还能够优先考虑正确性，通过与最终答案有效性的相关性检测轨迹中的错误。这项研究通过将训练信号、推理时的选择和基于token级别的诊断统合成一个推理奖励模型，提出了潜在可用于增强语言模型多步推理的可重用过程级奖励模型。特别是在Llama基于的策略中，奖励引导的重新排序显著提高了预测性能。
### Conclusion
该工作通过逆强化学习将推理奖励模型的概念引入大型语言模型，提出了一种新的学习方式，该方式优先考虑正确性而非表面形式，并将训练信号、检测和推理时的选择统合为单一的推理奖励模型，这为增强语言模型的多步骤推理提供了广泛的可能性。
## 39. `cs.AI` - 改善AGI评估：数据科学视角 [PDF](https://arxiv.org/pdf/2510.01687), [HTML](https://arxiv.org/abs/2510.01687)
### Authors
John Hawkins
### Background
评估潜在的AGI系统和方法因涵盖广泛工程目标而极具挑战性。目前缺乏完美评估最终状态的方法，因此更多依赖于小型测试来指示我们是否接近AGI。历史上，通过设计模拟任务来评估AGI的尝试效果不佳，理论上的智能标准导致了这些任务的质量低下。
### Innovation
本文提出了一种新视角，强调评估稳健的任务执行能力，通过展示系统的实际性能来证明AGI。这种方法受到数据科学中确保系统可靠部署的常用实践的启发，不再依赖于过去AGI评估中表现不佳的模拟任务，而是侧重于实际能力的展示。
### Conclusion
本文提出了针对AGI评估的新设计哲学，旨在通过展示实际任务执行能力来证明AGI的实现。这为AGI的评估提供了一种新的、更可靠的方法。
## 40. `cs.AI` - 约束自适应拒绝采样 [PDF](https://arxiv.org/pdf/2510.01902), [HTML](https://arxiv.org/abs/2510.01902)
### Authors
Paweł Parys,Sairam Vaidya,Taylor Berg-Kirkpatrick,Loris D'Antoni
### Background
语言模型（LM）在生成输出时常常需要满足严格的语义或语法约束。现有方法在受约束生成方面处于贪婪解码方法和拒绝采样（RS）之间。贪婪解码方法保证在解码过程中有效性但会扭曲LM的分布，而拒绝采样保持了忠实性但会浪费计算成本，因为它会丢弃无效的输出。这种极值方法在如程序模糊测试等领域中都是有缺陷的，因为这些领域既需要有效样本又需要多样样本。
### Innovation
我们提出了约束自适应拒绝采样（CARS），这是一种能在不扭曲分布的情况下严格提高RS采样效率的方法。CARS从无约束的LM抽样开始，通过在trie中记录并从此后抽样中减去违反约束的后续序列的概率质量来进行自适应修剪。这种方法确保被证明无效的前缀不再被访问，接受率会单调增加，最终生成的样本完全遵循约束分布。
### Conclusion
实验表明，在多个领域（例如程序模糊测试和分子生成）中，CARS不仅在有效样本的采样效率上表现出更佳性能，而且还提供了比GCD和其他近似LM分布的方法更强的样本多样性。
## 41. `cs.AI` - 零样本推理用于模拟学术同行评审 [PDF](https://arxiv.org/pdf/2510.02027), [HTML](https://arxiv.org/abs/2510.02027)
### Authors
Khalid M. Saqr
### Background
学者出版生态系统面临着不可管理的提交量和不受监管的AI的双重危机，急需新的治理模式来保障科学研究的完整性。传统的人类仅有的同行评审制度缺乏可扩展和客观的基准，使得编辑过程不透明且难以审计。本研究通过调查一种确定性的模拟框架，首次为评估AI生成的同行评审报告提供了稳定的、基于证据的标准。该研究分析了352份模拟的同行评审报告，发现系统能够模拟一致的编辑判断标准，在所有学科中“修订”决定始终占多数（>50%），而“拒绝”率则依学科领域动态适应，健康科学领域的拒绝率最高可达45%。该系统还保持了稳定的过程完整性，确保了举证标准的合规率稳定在29%，且不受不同评审任务和科学领域的多样性影响。这些发现表明，该系统具有可预测的规则性，减轻了生成AI的随机性。对于科研社区，这提供了一个透明工具以确保公平；对于出版策略制定者，它是一种可扩展的工具用于审计工作流程、管理完整性风险以及实施基于证据的治理。该框架将AI重新定位为机构问责的重要组成部分，为维护学术交流的信任提供了关键的基础设施。
### Innovation
该研究提出了一种确定性的模拟框架，为评估AI生成的同行评审报告提供了第一个稳定且基于证据的标准。通过分析352份模拟的同行评审报告，研究发现系统能够模拟一致的编辑判断标准，并保持稳定的过程完整性，确保举证标准的合规率稳定在29%。这一方法克服了传统同行评审制度的不足，为确保科学研究的完整性提供了新的途径。
### Conclusion
该研究为学术出版和审稿流程提供了透明和公平的标准，对于确保科研的诚信和质量具有重要意义。该框架重新定义了AI在同行评审中的角色，为维护学术交流的信任提供了基础设施。对于出版策略的研究者而言，它提供了一种可扩展的工具，能够审计工作流程、管理完整性风险并实施基于证据的治理。
## 42. `cs.AI` - 一个针对深度研究代理的严格多维度评估基准:从答案到报告 [PDF](https://arxiv.org/pdf/2510.02190), [HTML](https://arxiv.org/abs/2510.02190)
### Authors
Yang Yao,Yixu Wang,Yuxuan Zhang,Yi Lu,Tianle Gu,Lingyu Li,Dingyi Zhao,Keming Wu,Haozhe Wang,Ping Nie,Yan Teng,Yingchun Wang
### Background
当前的人工智能正从封闭的语言模型向能够进行外部感知和信息整合的相互连接的代理系统转变。作为这一转变的代表，深度研究代理（DRAs）具备任务分解、跨源检索、多阶段推理和结构化输出的能力，显著提升了在复杂和开放任务上的表现。然而，现有的基准测试在评价维度、响应格式和评分机制上仍存在问题，限制了它们对这些系统进行有效评估的能力。
### Innovation
本研究引入了一个严格的基准和多维度的评估框架，专为DRAs和报告式响应设计。该基准包括214个由专家整理的具有挑战性的查询，分布在10个广泛的主题域，并附有手工构建的参考集合以支持综合评估。框架能够全面评估DRAs生成的长文档报告，包含集成评分指标，如语义质量、专题焦点和检索可信度。此外，该研究通过实验证明主流DRAs在与网络搜索工具增强推理模型的比较中表现出更优性能，但也指出了进一步改进的空间。
### Conclusion
本研究为评估DRAs的能力、架构改进和范式进步提供了坚实的基础，展示了DRAs在复杂任务上的潜力，为未来的研究提供了重要依据。
## 43. `cs.AI` - 为计算机使用扩展代理的非同寻常的有效性 [PDF](https://arxiv.org/pdf/2510.02250), [HTML](https://arxiv.org/abs/2510.02250)
### Authors
Gonzalo Gonzalez-Pumariega,Vincent Tu,Chih-Lun Lee,Jiachen Yang,Ang Li,Xin Eric Wang
### Background
计算机使用代理（CUAs）有潜力自动化日常数字任务，但是它们的不可靠性和高变异性限制了它们在长期复杂任务中的应用。
### Innovation
介绍了行为最佳N（bBoN），一种通过生成多个走时并使用描述代理走时的行为叙述来选择其中最优的一种的方法。该方法实现了广泛的探索和有原则的轨迹选择，大幅提升了鲁棒性和成功率。在OSWorld上，bBoN扩展方法建立了新的最佳状态69.9%，显著优于先前方法并接近人类水平的72%。全面的消融实验验证了关键设计选择。此外，在WindowsAgentArena和AndroidWorld上展示了强大的泛化表现。
### Conclusion
结果强调了精心扩展CUAs的非同寻常效果：有效的扩展需要结构化的轨迹理解和选择，而bBoN提供了一个实用框架来实现这一点。
## 44. `cs.AI` - 计划然后行动：高阶规划指导强化学习在大型语言模型推理中的应用 [PDF](https://arxiv.org/pdf/2510.01833), [HTML](https://arxiv.org/abs/2510.01833)
### Authors
Zhihao Dou,Qinjian Zhao,Zhongwei Wan,Dinggen Zhang,Weida Wang,Towsif Raiyan,Benteng Chen,Qingtao Pan,Yang Ouyang,Zhiqiang Gao,Shufei Zhang,Sumon Biswas
### Background
大型语言模型（LLMs）在复杂任务中展示了出色的推理能力，通常依赖于Chain-of-Thought（CoT）推理。然而，由于它们基于自回归的字级生成机制，推理过程主要局限于局部决策制定，缺乏全局规划能力。这导致了冗余、不协调或不准确的推理，显著降低了整体性能。现有的方法，例如基于树的算法和强化学习（RL），试图解决这一问题，但由于计算成本高昂，往往无法产生最优的推理轨迹。
### Innovation
我们提出了Plan-Then-Action Enhanced Reasoning with Group Relative Policy Optimization（PTA-GRPO），这是一种两阶段框架，旨在提高高阶规划和细致的CoT推理效果。在第一阶段，利用先进的LLMs提炼CoT成紧凑的高阶指导，用于监督微调（SFT）。在第二阶段，引入一种指导感知的RL方法，优化最终输出和高阶指导的质量，从而增强推理效果。
### Conclusion
通过在多个数学推理基准（MATH、AIME2024、AIME2025和AMC）上进行广泛实验，跨多种基础模型（Qwen2.5-7B-Instruct、Qwen3-8B、Qwen3-14B、LLaMA3.2-3B），实验结果显示，PTA-GRPO在不同模型和任务中都能实现稳定且显著的改进，验证了其有效性和泛化能力。
## 45. `cs.AI` - 推理边界悖论：强化学习如何约束语言模型 [PDF](https://arxiv.org/pdf/2510.02230), [HTML](https://arxiv.org/abs/2510.02230)
### Authors
Phuc Minh Nguyen,Chinh D. La,Duy M. H. Nguyen,Nitesh V. Chawla,Binh T. Nguyen,Khoa D. Doan
### Background
研究发现，验证奖励的强化学习(Reinforcement Learning with Verifiable Rewards, RLVR)虽然能提升大型语言模型的推理能力，但最近的研究证据表明，它可能会缩小而非扩大推理边界。本文通过分析RLVR的学习动态，揭示了两个关键现象：1) 负向干扰现象，即学习解决某些训练问题时会减少其他正确解的可能性，导致Pass@$k$性能下降。2) 胜者全拿现象，即RLVR会过度强化高概率与正确解，而抑制其他低概率问题。这些现象源于标准RL目标中的内在策略采样导致模型向狭窄解策略收敛。
### Innovation
本文提出一个简单有效的数据采集算法，集中在低概率问题上进行RLVR学习，提升了Pass@$k$性能。这一创新算法通过对多种数学推理测试基准进行广泛的理论和实证分析揭示了RLVR学习效果的影响机制。
### Conclusion
通过在多个数学推理基准测试上的分析，证实了上述现象，并提出了一种有效策略以改善大型语言模型的推理边界。
## 46. `cs.AI` - FlexDoc：用于训练文档理解模型的参数化采样多样化多语言合成文档 [PDF](https://arxiv.org/pdf/2510.02133), [HTML](https://arxiv.org/abs/2510.02133)
### Authors
Karan Dua,Hitesh Laxmichand Patel,Puneet Mittal,Ranjeet Gupta,Amit Agarwal,Praneet Pabolu,Srikant Panda,Hansa Meghwani,Graham Horwood,Fahad Shah
### Background
大规模开发文档理解模型需要大规模、多样且注释良好的数据集，涵盖各种类型的文档。然而，由于隐私限制、法律约束以及所需的手工注释量极其庞大，收集这些数据的成本极其高昂，甚至可达到数百万美元。因此，获取符合需求的高质量训练数据存在巨大挑战。
### Innovation
提出了FlexDoc，一个可扩展的合成数据生成框架，结合Stochastic Schemas和Parameterized Sampling，生成具有丰富注释的现实且多语言的半结构化文档。FlexDoc通过概率建模布局模式、视觉结构和内容变化，能够大规模控制生成多样性文档变体。实验表明，使用FlexDoc生成的数据可以提升绝对F1分数高达11%，同时与传统的硬模板方法相比，注释工作量减少了90%以上，从而显著降低了数据获取和注释成本。
### Conclusion
FlexDoc已投入使用，帮助加速了企业级文档理解和模型的开发，显著降低了数据获取和注释的成本。
## 47. `cs.AI` - 一个人类学家LLM以角色扮演的方式引出用户的道德偏好 [PDF](https://arxiv.org/pdf/2510.01189), [HTML](https://arxiv.org/abs/2510.01189)
### Authors
Gianluca De Ninno,Paola Inverardi,Francesca Belotti
### Background
本研究建立在Floridi提出的硬伦理（硬性的道德教导，形塑法律）与软伦理（引导个体行为的道德偏好，在法律允许的自由决定空间内）的区别之上。研究聚焦于通过富含情境的叙述驱动互动来捕捉软伦理，特别是在数字隐私领域的伦理挑战中展示参与者。
### Innovation
研究提出了一种新颖的方法，通过结合沉浸式角色扮演游戏与大型语言模型（LLM）分析能力，来激发用户的道德决策。通过使用一个人类学家定制的LLM（“GPT人类学家”）来解释在角色扮演游戏中收集的数据，并通过交叉验证过程评估模型预测用户行为的能力。
### Conclusion
研究结果表明，LLM可以在软件开发早期阶段有效应用于自动化并增强理解用户的道德偏好和决策过程。数据的丰富性以及解释框架对提升模型预测用户行为的能力有显著影响。
## 48. `cs.AI` - UpSafeºC: Upcycling for Controllable Safety in Large Language Models, [PDF](https://arxiv.org/pdf/2510.02194), [HTML](https://arxiv.org/abs/2510.02194)
### Authors
Yuhao Sun,Zhuoer Xu,Shiwen Cui,Kun Yang,Lingyun Yu,Yongdong Zhang,Hongtao Xie
### Background
大型语言模型（LLMs）在各种任务中取得了显著进展，但仍面临诸如有害内容生成和破解攻击等安全风险。现有的安全技术包括外部护栏、推理时指导和后训练对齐，各有局限性，难以在安全、效用和可控性之间取得平衡。
### Innovation
本文提出了UpSafeºC，这是一种通过安全性感知升级来增强LLM安全性的统一框架。具体的创新点包括：识别安全关键层并将其升级到稀疏混合专家（MoE）结构，其中路由器作为软护栏，选择性激活原始MLP和添加的安全专家；引入两阶段强化学习策略以增强安全性歧视并保留通用能力；引入安全温度机制以在推理时灵活控制安全与效用之间的权衡。
### Conclusion
实验结果表明，UpSafeºC能够有效地增强对有害和破解输入的鲁棒安全性，同时在通用任务上保持了竞争力。此外，分析表明，安全温度提供了一种细粒度的推理时控制，实现了效用和安全性之间的帕累托最优前沿。结果显示，对于LLM安全性的新方向是从静态对齐转向动态、模块化和推理感知控制。
## 49. `cs.AI` - 剖析大型语言模型层数在检索、知识和推理中的作用 [PDF](https://arxiv.org/pdf/2510.02091), [HTML](https://arxiv.org/abs/2510.02091)
### Authors
Xinyuan Song,Keyu Wang,PengXiang Li,Lu Yin,Shiwei Liu
### Background
近期研究表明，大型语言模型（LLMs）的深层结构在其表示学习中贡献较小，通常可以去除大部分深层结构而不损失显著性能。然而，这些结论大多来自于狭隘的评估，忽略了模型行为的重要方面。
### Innovation
本文进行了系统性的深度利用研究，涵盖了评估协议、任务类别和模型结构等多个维度。研究发现，LLMs的深度使用是高度异质性和依赖于上下文的，强调了在解释和压缩大型模型时需要任务导向、指标导向和模型导向的视角。
### Conclusion
研究表明，深层结构对于推断和长程一致性至关重要，而知识和检索则集中在浅部组件。这些结果表明，LLMs深度使用方面的异质性和依赖性要求我们在解释和压缩大型模型时采用任务导向、指标导向和模型导向的方法。
## 50. `cs.AI` - 跨模态下AI模型的人类级抽象推理表现如何？ [PDF](https://arxiv.org/pdf/2510.02125), [HTML](https://arxiv.org/abs/2510.02125)
### Authors
Claas Beger,Ryan Yi,Shuhao Fu,Arseny Moskvichev,Sarah W. Tsai,Sivasankaran Rajamanickam,Melanie Mitchell
### Background
OpenAI的o3-preview推理模型在ARC-AGI基准测试上超过了人类的准确性，但是否意味着最先进的模型能够识别并推理出任务创造者意图中的抽象概念尚不清楚。研究者在ConceptARC上评估模型的抽象能力，并通过变化输入模态（文本 vs. 视觉）、模型是否可以使用外部Python工具、以及对于推理模型而言的推理努力程度来衡量。研究除了测量输出准确性外，还对模型生成以解释其解决方案的自然语言规则进行了精细评估。结果表明，尽管一些使用基于文本表示的模型在人类输出准确度上相匹配，但它们的规则往往基于浅层的“捷径”，而人类则更多地捕获了任务设计时所期望的抽象。这表明仅通过准确率来评估模型的抽象推理能力可能会高估文本模态中的通用抽象推理能力，而低估视觉模态中的能力。
### Innovation
该研究通过引入一种双模评估框架，不仅测量输出准确性，还对模型生成的自然语言规则进行了详细分析。这种方式可以让研究者评估模型是否使用了ConceptARC设计意图引出的抽象概念，而不是依赖于表面级的模式。这项研究揭示了模型在文本和视觉模态下对于抽象推理的能力评估存在误导性。
### Conclusion
本文的研究结果表明，模型在抽象推理方面的表现仍然落后于人类。单独使用准确率来评估ARC类似任务中的抽象推理能力可能同时高估文本模态中的能力并低估视觉模态中的能力。该研究认为其评估框架能更准确地反映多模态模型的抽象推理能力，并提供了一种更为科学的方法来追踪通向人类中心抽象智能的进步。
## 51. `cs.AI` - RLAD：训练大语言模型发现解决推理问题的抽象 [PDF](https://arxiv.org/pdf/2510.02263), [HTML](https://arxiv.org/abs/2510.02263)
### Authors
Yuxiao Qu,Anikait Singh,Yoonho Lee,Amrith Setlur,Ruslan Salakhutdinov,Chelsea Finn,Aviral Kumar
### Background
推理需要超越简单的模式匹配或记忆解决方案，而是识别并实施可以用于推导困难问题答案的'算法过程'。这要求理解最相关的基础单元、中间结果或共享流程，并在此基础上进行构建。尽管长期思考后的强化学习最终旨在揭示这种算法行为，但大多数大型模型学习到的推理痕迹往往未能一致地捕捉或重用过程，而是陷入冗长且退化的发展中。因此，为实现更有效的推理，该研究引入了推理抽象：简洁的自然语言描述，引导模型向成功推理学习。在模型上进行训练，以能够根据问题提出多种抽象，然后是通过RL激励使用这些抽象信息构建解决方案。这一方法形成了一个包含抽象生成器和解决方案生成器的双重RL训练范式，简称为RLAD，从而实现了结构化的探索，解耦了抽象提议的学习信号和解决方案生成，并改善了对更困难问题的泛化能力。研究还表明，在测试时间上分配更多的计算资源用于生成抽象比在大规模测试预算是生成更多解决方案更有益，这进一步强调了抽象在指导有意义探索中的作用。
### Innovation
该研究提出了推理抽象的概念，即使用简洁的自然语言描述引导模型学习成功推理的机制。通过双重RL训练范式，即RLAD（Reasoning Lagrangian Abstraction Dynamics），该方法联合训练了抽象生成器和解决方案生成器，有效地促进了结构化的探索，分开了抽象提议和解决方案生成的学习信号，并增强了模型对更复杂问题的泛化能力。此外，研究还发现，将更多的计算资源分配给生成抽象比在测试阶段生成更多解决方案更为有益，进一步突显了抽象在指导有意义探索中的关键作用。
### Conclusion
该研究通过引入推理抽象的概念，提出了一种双重RL训练范式（RLAD），用于训练大型语言模型解决推理问题。这种方法不仅改变了模型的学习方式，有效促进了结构化的探索和对更复杂问题的泛化能力，还揭示了分配计算资源于抽象生成的策略在提升模型性能方面的优势。
## 52. `cs.AI` - BioX-Bridge：跨生物信号模态的未监督跨模态知识传递模型桥接 [PDF](https://arxiv.org/pdf/2510.02276), [HTML](https://arxiv.org/abs/2510.02276)
### Authors
Chenqi Li,Yu Liu,Timothy Denison,Tingting Zhu
### Background
生物信号为人体生理状态提供了宝贵洞察，尽管不同生物信号模式在功能、信号精度、传感器舒适度和成本方面存在差异，但它们常互相关联，反映了人体生理的全面性和联结性。这为使用替代生物信号模式执行相同任务提供了可能性，从而提高了健康监测系统的可访问性、易用性和适应性。然而，有限的大型标注数据集使得为特定任务和感兴趣的模式训练定制模型面临挑战。通过利用现有模式的知识来支持新模态模型训练的未监督跨模态知识传递提供了一个有希望的解决方案。现有的方法通常依赖于知识提炼，在学生模型训练过程中需要运行一个教师模型，导致高计算和内存开销。
### Innovation
本文提出了一种新的框架来实现未监督跨生物信号模态的知识传递——BioX-Bridge。该框架通过训练一个轻量级的桥接网络对中间表示进行对齐，实现基础模型之间的信息流通，并且可以在跨模态之间传递信息。同时，该方法提出了一种高效的对齐位置选择策略和灵活的桥接网络架构。实验结果显示，相较于当前最先进的方法，BioX-Bridge 能够减少99%-88%的可训练参数数量，同时保持甚至提升知识传递性能。
### Conclusion
本文通过提出BioX-Bridge方法，成功降低了可训练参数数量，且在保持或提升知识传递性能方面取得了显著成果，为跨模态生物信号研究提供了新的解决方案。
## 53. `cs.AI` - LegiScout: 一种理解复杂立法的可视化工具 [PDF](https://arxiv.org/pdf/2510.01195), [HTML](https://arxiv.org/abs/2510.01195)
### Authors
Aadarsh Rajiv,Klaus Mueller
### Background
现代立法框架，如《平价医疗法案》（ACA），通常涉及复杂的机构、指令和相互依赖关系。政府发布的图表试图展示这些结构，但它们通常是静态的、密集的并且难以解读——即使是专家也是如此。现有的方法无法充分展示现代法律的复杂性，使政策制定者、分析师和公众难以理解和互动。
### Innovation
我们引入了LegiScout，一种互动可视化系统，将静态政策图变成动态的力导向图，同时保持了基本关系中的理解。LegiScout综合了数据提取、自然语言处理和计算机视觉技术，支持对ACA及其他广泛的立法和监管框架进行更深入的探索。这一方法使利益相关者能够更方便地导航和理解现代法律的复杂性。
### Conclusion
LegiScout通过动态可视化帮助用户更好地理解和互动复杂的立法框架，改变了人们对现代立法复杂性的认识和处理方式。
## 54. `cs.AI` - 低资源语言NLP的开放发现之路 [PDF](https://arxiv.org/pdf/2510.01220), [HTML](https://arxiv.org/abs/2510.01220)
### Authors
Bonaventure F. P. Dossou,Henri Aïdasso
### Background
低资源语言的自然语言处理(NLP)受到文本语料库不足、标准化书写系统缺乏以及可扩展注释管道的限制。尽管大型语言模型的进步提升了跨语言迁移的效果，但这些模型仍依赖于大规模的预收集数据和集中的基础设施，无法被代表性不足的社区使用。现有的语言技术过于依赖静态的数据收集管道，局限于预存的数据，未能充分利用人机协作动态生成的不确定性。
### Innovation
本文提议了一种基于联合人机不确定性框架，将模型的先验不确定性与人类发言者的犹豫提示和置信度信号结合起来，引导互动、查询选择和记忆保留。这提出了从提取式数据收集转向参与式、适应性学习过程的理念，旨在尊重和赋能社区，同时发现并保护世界语言多样性。这一愿景与以人为本的AI原则一致，强调AI系统与说话人之间交互合作的模型构建。
### Conclusion
本文呼吁重新思考AI如何与低记录语言的人类知识互动，从提取性的数据收集转向参与性、协同适应的学习过程，这一过程尊重和提升社区的地位，同时发现并保护语言多样性。
## 55. `cs.AI` - 控制温度：基于风险选择性采样以实现高质量且多样化的LLM输出 [PDF](https://arxiv.org/pdf/2510.01218), [HTML](https://arxiv.org/abs/2510.01218)
### Authors
Sergey Troshin,Wafaa Mohammed,Yan Meng,Christof Monz,Antske Fokkens,Vlad Niculae
### Background
多样性是评估语言模型生成输出创造力的重要指标。温度为基础的采样是增加多样性的常用策略，但在需要高精度的任务中，例如数学推理，不加控制地使用高温度采样会导致推理质量下降。这是由于在敏感解码位置采样错误的继续引起的。因此，需要一种方法来解决这个问题，这种方法可以在高温度设置下动态切换到贪婪或高温度采样，并且能够估计当前位置应用高温度采样时输出错误的可能性。
### Innovation
本文提出了一种称为选择性采样的方法，该方法基于一个基于风险的采样度量，动态地在贪婪采样和高温度采样之间切换。该风险度量可以估计在当前位置应用高温度采样时输出错误的可能性。通过在一个可验证问题的小子集上训练一个轻量级分类器来预测采样风险。这种方法可以在不影响延迟的情况下与基础语言模型集成。实验表明，选择性采样可以提高高质量和多样性的折中，在高温度设置下也能有效提升推理质量。
### Conclusion
选择性采样通过动态调整采样策略，在高温度设置下提升了推理质量和多样性之间的折中。
## 56. `cs.AI` - Mamba Outpaces Reformer in Stock Prediction with Sentiments from Top Ten LLMs [PDF](https://arxiv.org/pdf/2510.01203), [HTML](https://arxiv.org/abs/2510.01203)
### Authors
Lokesh Antony Kadiyala,Amir Mirzaeinia
### Background
短期预测股市极其困难，因为股市具有高波动性、新闻引起的市场变化以及金融市场时间序列的非线性。本文旨在通过结合十种不同的大型语言模型（LLMs）的语义情感评分和分钟交易内股价数据来提高分钟级预测的准确性。研究团队构建了一个时间对齐的AAPL新闻文章及其对应1分钟苹果股价数据集，通过这些LMS的API进行情感分析，然后将情感评分与技术指标相结合进行模型训练和预测评估。
### Innovation
本文提出了一个新颖的框架，利用十种不同的大型语言模型的语义情感评分来改进分钟级股价预测的准确性。研究使用了两种最先进的模型——Reformer和Mamba进行训练，并通过Optuna优化超参数。研究结果显示，Mamba模型在所有十种LMS上都表现出色，相比于Reformer，Mamba不仅速度更快，而且精度更高。尤其是在LLaMA 3.3--70B模型上，Mamba的误差最低，为0.137。
### Conclusion
这项研究表明，将基于LLM的语义分析与高效时间建模相结合，具有提升实时金融预测的潜力，特别是对于Mamba模型，其在结合多种LMS的情感评分时表现出更好的性能。
## 57. `cs.AI` - 量子辅助相关聚类 [PDF](https://arxiv.org/pdf/2509.03561), [HTML](https://arxiv.org/abs/2509.03561)
### Authors
Antonio Macaluso,Supreeth Mysore Venkatesh,Diego Arenas,Matthias Klusch,Andreas Dengel
### Background
相关聚类是一种基于图形的无监督学习任务，旨在根据节点之间的成对同意和不同意来分区。传统的相关聚类方法往往假设图的内在度量，并依靠预定义的聚类数量，这对于处理包含负边和任意相关结构的图形来说具有限制性。因此，亟需一种新的方法，能够在不依赖度量假设和不需要预定义的聚类数量的情况下处理此类图形。本文提出了一种结合量子计算和经典计算的新方法，以克服传统方法的限制，提高图形相关性聚类的鲁棒性和聚类质量，并适应于包含非度量结构的图形数据集，尤其是具有不平衡聚类规模的真实世界多光谱成像数据集。
### Innovation
本文提出了一种通过递归分裂聚类来最大化带符号图形内的簇内一致性的混合量子-经典方法。该方法将GCS-Q量子辅助求解器与量子辅助转录优化技术结合，解决了二次无约束二进制优化问题，从而解决了相关聚类问题。这种方法无需依赖度量假设或预设的聚类数量，能够处理具有任意相关结构的图形，包括负边，从而大大增加了相关聚类应用于现实世界数据集的可能性。
### Conclusion
实验结果表明，对于相关聚类任务，适应量子辅助方法的GCS-Q比经典的聚类算法在真实性数据集和不平衡聚类规模的场景中具有更高的鲁棒性和聚类质量。此研究的结果表明，混合量子-经典的优化对于图基无监督学习中的可扩展和结构感知聚类技术具有很大的潜力。
## 58. `cs.AI` - 利用现代大型语言模型（LLM）进行金融趋势分析和摘要创建 [PDF](https://arxiv.org/pdf/2510.01225), [HTML](https://arxiv.org/abs/2510.01225)
### Authors
Andrei Lazarev,Dmitrii Sedov
### Background
信息的指数级增长为研究人员和专业人士带来了重大挑战，使其难以保持在各自领域的前沿。本文提出了一个创新框架，用于利用大型语言模型（LLMs）如Google的Gemini Pro自动生成具有洞察力的金融摘要。
### Innovation
该框架结合了从OpenAlex抽取数据，战略性的提示工程和LLM驱动的分析，以自动生成全面的摘要，概括关键发现并识别新兴趋势。这种方法解决了传统分析方法的局限性，能够高效处理大量无结构的数据，并以易于理解的方式提供可操作的见解。
### Conclusion
本文详细描述了LLMs的工作原理以及如何利用它们帮助研究人员和学者节省时间并了解当前趋势。我们的研究涵盖了从数据获取和JSON构建到与Gemini互动以及自动生成PDF报告的全过程，并附有项目GitHub仓库链接以供更广泛的访问和进一步发展。
## 59. `cs.AI` - 基准分析：LLM基准的机理诊断 [PDF](https://arxiv.org/pdf/2510.01232), [HTML](https://arxiv.org/abs/2510.01232)
### Authors
Dongjun Kim,Gyuho Shim,Yongchan Chun,Minhyuk Kim,Chanjun Park,Heuiseok Lim
### Background
大型语言模型通常通过标准基准测试得分来评判，但这些得分往往夸大了模型的实际能力，因为它们掩盖了一个任务其实所要求的多种技能。现有基准如ARC和HellaSwag分别被认为测试推理能力和常识理解，但缺乏一个系统的方法来验证这些基准是否真的衡量了它们标注的能力。
### Innovation
提出了基准分析（Benchmark Profiling），这是一种诊断框架，将基准性能分解为十个认知基础的能力，通过基于梯度的重要性评分与靶向参数消融结合计算能力影响评分（AIS），量化每个能力对模型在特定基准上成功的贡献。
### Conclusion
通过对三种指令调优模型在十个常用基准上的分析，得到了四个关键发现：大多数基准依赖多种能力而非一种；具有相似标签的数据集依赖不同的能力组合；代码生成基准奖励广泛、多技能改进，因此狭窄领域特定微调仅能带来微小收益；与任务无关的能力可能会负面影响表现。基准分析解释了为何性能提升未必转化为用户感知到的能力，提供了基准审核和模型可解释性的透明工具。
## 60. `cs.AI` - 考虑背景的重要性：兽医医学中商业大型语言模型的比较 [PDF](https://arxiv.org/pdf/2510.01224), [HTML](https://arxiv.org/abs/2510.01224)
### Authors
Tyler J Poore,Christopher J Pinard,Aleena Shabbir,Andrew Lagree,Andre Telfer,Kuan-Chuen Wu
### Background
大型语言模型（LLMs）在临床环境中越来越普遍，但在兽医医学领域的表现仍需进一步探索。本文评估了三种以兽医为目标的LLM总结工具（产品1[Hachiko]和产品2、3）在标准化的兽医肿瘤学记录数据集上的性能。
### Innovation
本文引入了一种新的LLM作为评分器的框架，使用评分指南评估总结的质量，涵盖五个领域：事实准确性、完整性、时间顺序、临床相关性和组织。此外，通过多次独立评估验证了评分框架的内部一致性。
### Conclusion
研究表明，兽医特定的商业LLM工具非常重要，而LLM作为评分器的评估方法是一种可扩展且可重复的方法，用于评估兽医医学中的临床自然语言处理（NLP）总结。
## 61. `cs.AI` - 话语vs排放：通过大规模语言模型分析企业叙事、象征行为和模仿 [PDF](https://arxiv.org/pdf/2510.01222), [HTML](https://arxiv.org/abs/2510.01222)
### Authors
Bertrand Kian Hassani,Yacoub Bahini,Rizwan Mushtaq
### Background
气候变化加剧了对于透明且可比的企业气候信息披露的需求，然而模仿和象征性报告往往会削弱其价值。论文旨在评估828家企业的披露成熟度，通过调优的大型语言模型（LLMs）和文本分类器，考察了关于气候沟通的叙述指标与公司属性（如排放量、市值和行业）之间的关联。研究揭示了三个主要观点：（1）关注风险的叙述通常与明确的承诺一致，但定量目标（如净零承诺）与语气仍然脱节；（2）规模较大且排放较高的公司比同行更频繁地披露承诺和行动，但这些并未与定量目标保持一致；（3）披露风格的普遍相似性表明存在模仿行为，减少了差异性并降低了决策有用性。这些结果强调了使用LLMs进行ESG叙述分析的价值，并指出了需要强有力的监管以确保承诺与可验证的转型策略之间连接的重要性。
### Innovation
论文开发了一种多维度框架，使用调优的大型语言模型评估企业气候信息披露的成熟度。通过情绪、承诺、具体性和目标雄心四个分类器从可持续发展和年度报告中提取叙述指标，并关联到公司属性，以便更准确地分析企业气候信息披露质量。
### Conclusion
研究发现，尽管许多企业声称致力减排，但实际行动与雄心声明之间存在脱节。规模较大和排放较高的公司虽然披露更多承诺和行动，但这些承诺和行动并未与定量目标完全一致。企业的模仿行为导致了信息披露风格的相似性，减低了信息的差异性和决策有用性。这些结果强调了需要通过更强有力的监管将承诺与可验证的转型策略连接起来，以提高企业气候信息披露的质量。
## 62. `cs.AI` - ClaimCheck：小型语言模型下的实时事实核查 [PDF](https://arxiv.org/pdf/2510.01226), [HTML](https://arxiv.org/abs/2510.01226)
### Authors
Akshith Reddy Putta,Jacob Devasier,Chengkai Li
### Background
传统的事实核查系统依赖于大型的、封闭源代码的模型和静态知识库，而这些系统无法灵活应对不断变化的事实核查需求。ClaimCheck 是一种由语言模型（LLM）指导的自动事实核查系统，旨在使用实时网络证据和小型语言模型验证现实世界的声明。它通过模仿人类事实核查的工作流程，即网络搜索查询规划、基于网络的证据检索与总结、证据综合和重新检索以及声明判决评估，提供透明度和模块化的事实核查过程，这意味着它可以处理不断变化的信息环境，同时减少计算需求，提高了事实核查的准确性和可解释性。
### Innovation
ClaimCheck 使用透明且模块化的事实核查工作流程，特别适合小型语言模型，这使得系统能够在计算资源较少的情况下提供准确且可解释的事实核查结果。尽管使用的是较小的 Qwen3-4B 模型，ClaimCheck 在 AVeriTeC 数据集上的准确率达到了 76.4%，优于此前使用 LLaMA3.1 70B 和 GPT-4o 的表现。详细的消融分析表明，精心设计的模块化和提示策略可以克服小型 LLM 的局限性。
### Conclusion
ClaimCheck 通过提供一个小型语言模型驱动的透明事实核查系统，证明了在计算资源有限的情况下，仍然可以实现高效、准确的事实核查。该系统公开可用，旨在促进其透明度和可访问性。
## 63. `cs.AI` - 利用LLM生成数据和基于LLM的监督增强基于Transformer的重排序器 [PDF](https://arxiv.org/pdf/2510.01229), [HTML](https://arxiv.org/abs/2510.01229)
### Authors
Dimitar Peshevski,Kiril Blazhevski,Martin Popovski,Gjorgji Madjarov
### Background
有效的文档重排序对于跨多种应用改善搜索相关性至关重要。大型语言模型（LLMs）在重排序方面表现出色，因为它们具备深层语义理解和推理能力，但由于高计算成本，使其在许多实际部署中不切实际。细调较小的任务特定模型是一个更高效的替代方案，但通常依赖稀缺的手工标注数据。
### Innovation
提出了一个新的管道，无需使用手工标注的查询-文档对。该方法使用LLM从特定领域语料库生成合成查询，并采用基于LLM的分类器来标记正样本和硬负样本对。生成的合成数据集通过局部对比估计损失（LCE）用于较小的变换器模型对比学习的细调。
### Conclusion
在MedQuAD数据集上的实验表明，我们的方法显著提高了领域内性能，并且很好地推广到领域外任务。通过使用LLM进行数据生成和监督而不是推理，我们减少了计算成本同时保持了强大的重排序能力。
## 64. `cs.AI` - 使用概念学习数据集揭示大型语言模型中的隐含偏见 [PDF](https://arxiv.org/pdf/2510.01219), [HTML](https://arxiv.org/abs/2510.01219)
### Authors
Leroy Z. Wang
### Background
该研究通过引入一个概念学习任务的数据集，旨在发现大型语言模型中未显性的偏见。通过在上下文中的概念学习实验，研究揭示了语言模型在量词方面可能存在向上的单调性偏见，这种偏见在直接提示测试中不那么明显。
### Innovation
研究使用了概念学习任务的数据集来发现语言模型中的隐含偏见，并通过在上下文中的实验发现，该方法能够有效揭示隐藏在语言模型中的偏见。
### Conclusion
研究表明，通过在上下文中的概念学习实验，可以有效发现语言模型中的隐含偏见，这种方法相较于直接提示测试，能更好地揭示模型的潜在偏见。
## 65. `cs.AI` - 大语言模型可靠性的增强：一种多信号预生成幻觉缓解的自信感知路由方法 [PDF](https://arxiv.org/pdf/2510.01237), [HTML](https://arxiv.org/abs/2510.01237)
### Authors
Nandakishor M
### Background
大型语言模型存在幻觉现象，生成表面上合理但实际上不符实的内容。当前的缓解策略主要依赖于生成后的修正，这既耗费计算成本，又无法有效预防不可靠内容的生成。现有的方法在检测幻觉和确保准确度方面效果有限，尤其是在资源限制和实时性的要求下，难以实现高效可靠的生成过程。
### Innovation
本文提出了一种自信感知路由系统，该系统在生成之前主动评估模型的不确定性并根据预测的可靠性调整查询路由。该方法结合了三个互补的信号：内部表示与参考嵌入的语义对齐、模型层间的内部收敛分析以及学习到的信任度估计。统一的信任度分数决定路由至四个路径中的一个：高信任度时的本地生成、中信任度时的检索增强生成、低信任度时的大型模型生成以及极低信任度时的人工审核。实验结果表明，该方法在知识密集型问答基准测试中的幻觉检测精度显著提高（0.74 vs. 0.42基线），计算成本降低了40%，并且F1分数从0.61提高到0.82，且具有较低的误报率（0.09）。
### Conclusion
本文方法展示了从被动修正到主动评估的范式转变，提出了一种计算成本较低的大规模语言模型可靠性的增强方法，提高了幻觉检测的准确度，减少了计算开销，降低了误报率，为提升大语言模型可靠性提供了新的途径。
## 66. `cs.AI` - 语音评估中的偏见基准能否泛化？基于性别偏见的语音大语言模型语音评估的实证证据 [PDF](https://arxiv.org/pdf/2510.01254), [HTML](https://arxiv.org/abs/2510.01254)
### Authors
Shree Harsha Bokkahalli Satish,Gustav Eje Henter,Éva Székely
### Background
最近的语言大模型（SpeechLLMs）公平性和偏见评估主要依赖于多选题回答（MCQA）形式。模型需要根据语音提示和（可选）文本提示选择标准、反标准或中性/无关的答案。这种多选题评估假设模型在其他多选题任务、不同声音以及如更现实、长形式评估等其他任务格式上的表现是持续和一致的。
### Innovation
本文通过使用LoRA适配器对三种SpeechLLMs进行微调，赋予它们特定的多选题回答偏好：偏好标准、反标准或中性/不确定的答案，然后评估这些偏好是否在另一个不同的多选题基准上，以及更关键地，在长形式创造性生成任务中泛化。结果显示，多选题偏见基准的表现无法可靠地预测其他多选题基准的表现，而且更重要的是在长形式任务中的表现。
### Conclusion
当前多选题偏见基准在语音领域显示了有限的跨任务泛化证据，本文还提出了一种测量未来模型和基准行为可转移性的评估套件。
## 67. `cs.AI` - 基于LLM的AI代理实现材料属性的自动提取 [PDF](https://arxiv.org/pdf/2510.01235), [HTML](https://arxiv.org/abs/2510.01235)
### Authors
Subham Ghosh,Abhishek Tewari
### Background
目前，材料发现受到缺乏大型、可机器读取的数据集的限制，这些数据集能够将性能指标与结构背景联系起来。现有的数据库要么规模小、手动整理，要么侧重于第一性原理的结果，导致实验文献未充分利用。
### Innovation
本文提出了一种自主工作流，利用大型语言模型（LLM）从约10,000篇全文科学文章中自动提取热电和结构属性。该工作流整合了动态标记分配、零样本多代理提取和条件表格解析，平衡了准确性与计算成本。使用此工作流，我们整理了27,822个温度分辨的属性记录，包括关键性能指标（ZT）、赛贝克系数、电导率、电阻率、功率因子和热导率，以及诸如晶体结构、空间群和掺杂策略等结构属性。该研究提供了迄今为止最大的LLM整理的热电数据库，提供了可重复且成本可控的提取管道，并为跨领域的数据驱动材料发现奠定了基础。
### Conclusion
通过这种方法，我们不仅整理了大量的材料属性数据，还揭示了更广泛的结构-性质关系。我们还提供了具有语义过滤器、数值查询和CSV导出功能的互动网络探索器，使社区能够方便地访问这些数据。这项研究为数据驱动的材料发现提供了范例，并建立了可扩展的基础。
## 68. `cs.AI` - 跨越文化的比赛：语言模型对体育理解的大型多语言、多文化基准 [PDF](https://arxiv.org/pdf/2510.01247), [HTML](https://arxiv.org/abs/2510.01247)
### Authors
Punit Kumar Singh,Nishant Kumar,Akash Ghosh,Kunal Pasad,Khushi Soni,Manisha Jaishwal,Sriparna Saha,Syukron Abu Ishaq Alfarozi,Asres Temam Abagissa,Kitsuchart Pasupa,Haiqin Yang,Jose G Moreno
### Background
当前的语言模型（LMs）主要以全球流行的体育项目为研究对象，但忽视了地方性和土著的体育传统。这导致了语言模型在理解和掌握这些文化差异中的体育知识方面存在不足。
### Innovation
该研究发布了名为CultSportQA的新基准测试，它评测了语言模型对60个国家和6个大洲的传统体育的理解。该数据集包含33,000个多模态（包括文本和图像）问题，分类为历史、规则和场景三种类型。通过零样本、少样本和链式思维（CoT）提示方法，评测了大型语言模型（LLMs）、小型语言模型（SLMs）和多模态大型语言模型（MLMs）的性能。该基准旨在促进对AI在理解及推理传统体育方面的评估标准的提升。
### Conclusion
CultSportQA构建了一个综合的多语言和多文化体育基准，为现存的评估AI理解传统体育的标准设立了新标杆。
## 69. `cs.AI` - IoT-MCP: 通过模型上下文协议连接物联网和大语言模型系统 [PDF](https://arxiv.org/pdf/2510.01260), [HTML](https://arxiv.org/abs/2510.01260)
### Authors
Ningyuan Yang,Guanliang Lyu,Mingchen Ma,Yiyi Lu,Yiming Li,Zhihui Gao,Hancheng Ye,Jianyi Zhang,Tingjun Chen,Yiran Chen
### Background
大语言模型（LLMs）与物联网（IoT）系统的集成面临硬件异质性和控制复杂性的重大挑战。模型上下文协议（MCP）作为一种关键的推动者，提供了LLMs与物理设备之间的标准化通信。
### Innovation
提出了一个名为IoT-MCP的新型框架，该框架通过边缘部署的服务器来实现MCP，从而连接LLMs和物联网生态系统。此外，还引入了IoT-MCP Bench，这是第一个包含114个基本任务和1,140个复杂任务的基准测试，以评估支持物联网的大语言模型。
### Conclusion
实验验证了在22种传感器类型和6种微控制器单元上，IoT-MCP的任务成功率达到了100%，平均响应时间为205毫秒，峰值内存占用为74KB。该研究提供了开源集成框架（可在此访问：this https URL）和标准化的评估方法，得到了大语言模型和物联网系统的发展。
## 70. `cs.AI` - GPT和偏见：理解大规模语言模型中学习表示的一种稀疏方法 [PDF](https://arxiv.org/pdf/2510.01252), [HTML](https://arxiv.org/abs/2510.01252)
### Authors
Mariam Mahran,Katharina Simbeck
### Background
由于大型语言模型（LLMs）的训练数据来自于海量且未经筛选的语料库，因此研究模型的内部表示和吸收的数据结构变得愈发关键。本文探讨的是如何通过结合LLMs与稀疏自编码器（SAEs），不仅可以解析模型的行为，还能揭示训练数据中根深蒂固的主题、偏见以及更深层次的结构。作者选择取得了社会结构和叙事特征丰富的简·奥斯汀小说进行实验。
### Innovation
本文的主要创新在于通过将LLMs与SAEs结合使用，不仅可以解释模型的行为，还能够发现存在于训练数据中的稀疏可解析特征。通过这种方法，论文展示了如何利用这种组合来探究复杂数据集的深层次结构，发现数据集中的偏见，并实现大规模模型的可解释性。
### Conclusion
本文的结论是，结合LLMs与SAEs能够作为一种可扩展的工具，帮助人们大规模地探索数据集、发现数据中的偏见，并提高模型的可解释性。
## 71. `cs.AI` - Kant: 一套高效的大型AI集群统一调度系统 [PDF](https://arxiv.org/pdf/2510.01256), [HTML](https://arxiv.org/abs/2510.01256)
### Authors
Lingling Zeng,Gen Zhang,Jialin Peng,Xiang Xu,Yuan Xu,Lijun Ma
### Background
随着AI集群规模不断扩大以及大规模语言模型（LLM）训练和推理工作负载需求快速增长，传统调度系统在平衡资源利用、调度效率和服务质量方面面临重大挑战。
### Innovation
该论文提出了Kant，一种专为大规模AI容器集群设计的高效统一调度平台，支持训练和推理任务的联合调度。Kant系统通过调度策略（如Backfill和增强的Binpack）提高了资源利用率和调度效率，同时减少了分布式训练中的资源碎片化和通信开销。
### Conclusion
Kant已在多个AI数据中心集群中部署，稳定支持大规模智能计算负载，为构建高性能、高可用性的AI原生调度基础设施提供了实用的工程方法。
## 72. `cs.AI` - 通过不确定性量化和风险意识的大语言模型信任型摘要 [PDF](https://arxiv.org/pdf/2510.01231), [HTML](https://arxiv.org/abs/2510.01231)
### Authors
Shuaidong Pan,Di Wu
### Background
在信息过载和高风险决策的情景下，自动摘要的可靠性成为一个关注点。本文旨在解决这一问题，并介绍了一种整合不确定性量化和风险意识机制的大型语言模型框架。
### Innovation
构建了一种基于条件生成的摘要模型，并在生成过程中引入了贝叶斯推断来建模参数空间中的不确定性，从而避免过度自信的预测。通过预测分布熵量化生成内容的不确定性水平，并将熵正则化和风险感知损失的联合优化应用于确保信息压缩过程中的关键信息得到保留，并且风险属性得以明确表达。在此基础上，模型整合了风险评分和调节模块，使得摘要既能准确覆盖核心内容，又能通过明确的风险水平提示增强可信度。
### Conclusion
对比实验和灵敏度分析证实，所提出的方法在保持流畅性和语义完整性的同时，显著提高了高风险应用中摘要的稳健性和可靠性。这项研究提供了一个系统方案，以实现信任型摘要，并从方法论层面证明了其可扩展性和实际价值。
## 73. `cs.AI` - 冗余作为遮蔽：形式化人工老化得分（AAS）以建模生成型AI的记忆老化 [PDF](https://arxiv.org/pdf/2510.01242), [HTML](https://arxiv.org/abs/2510.01242)
### Authors
Seyma Yaman Kayadibi
### Background
研究指出，人工智能老化不是通过时间流逝，而是通过记忆表现中的结构不对称性来体现。在大型语言模型中，诸如星期名称这类语义线索通常在会话间保持稳定，而实验编号的顺序细节在会话重置时往往会崩溃。为捕捉这一现象，本文引入了人工老化得分（AAS），这是一种基于可观察的回忆行为的对数缩放和熵驱动的记忆老化度量指标。AAS在温和且模型无关的假设下被证明是有界和单调的，适用于各种任务和领域。
### Innovation
本文提出了冗余作为遮蔽（Redundancy-as-Masking）的AAS框架，这是一种度量人工智能系统记忆老化的理论依据，并在一项涉及ChatGPT-5的双语言研究中进行了测试。研究结果显示，AAS可以作为独立于任务的诊断工具，评估人工系统中的记忆退化。这项研究融合了冯·诺依曼的自动机理论、香农的信息理论和图灵的行为方法论。
### Conclusion
研究证实AAS作为一种理论基础、任务无关的诊断工具，适用于评估人工智能系统中记忆退化的程度。这一框架基于冗余作为遮蔽的概念，在长达25天的双语言研究中，无论是无状态还是持续会话阶段，AAS都反映了模型记忆老化的情况。
## 74. `cs.AI` - RJE: 一种利用LLM高效知识图谱问答的检索-判断-探索框架 [PDF](https://arxiv.org/pdf/2510.01257), [HTML](https://arxiv.org/abs/2510.01257)
### Authors
Can Lin,Zhengwang Jiang,Ling Zheng,Qi Zhao,Yuhang Zhang,Qi Song,Wangqiu Zhou
### Background
知识图谱问答（KGQA）旨在使用知识图谱回答自然语言问题。最近的研究利用大规模语言模型（LLMs）来增强KGQA的推理能力，但这种方法面临着限制：基于检索的方法受限于检索到的信息质量，而基于代理的方法则依赖于专有LLM。
### Innovation
本文提出了名为RJE的框架，该框架检索精炼的推理路径，评估其充分性，并在必要时探索额外证据。RJE引入了专门的辅助模块，使小型LLM能够有效工作：推理路径排序、问题分解和检索辅助探索。实验表明，该方法结合专有LLM（如GPT-4o-mini）优于现有基线，同时使小型开源LLM（如3B和8B参数）无需微调LLM即可达到竞争力结果。此外，与基于代理的方法相比，RJE显著减少了LLM调用次数和token使用量，带来了显著的效率提升。
### Conclusion
实验结果表明，该方法结合专有LLM（如GPT-4o-mini）优于现有基线，同时使小型开源LLM（如3B和8B参数）无需微调LLM即可达到竞争力结果。此外，RJE显著减少了LLM调用次数和token使用量，带来了显著的效率提升。
## 75. `cs.AI` - RSTGCN: 铁路中心的时空图卷积网络用于列车延误预测 [PDF](https://arxiv.org/pdf/2510.01262), [HTML](https://arxiv.org/abs/2510.01262)
### Authors
Koyena Chowdhury,Paramita Koley,Abhijnan Chakraborty,Saptarshi Ghosh
### Background
准确预测列车延误对于高效的铁路运营至关重要，有助于更好地调度和调度决策。早期方法主要关注个别列车的具体延误预测，而最近的研究开始探索基于站级的延误预测以支持更高的交通管理。我们的工作利用铁路中心的时空图卷积网络（RSTGCN）来预测特定时间段内所有进入铁路站场的列车平均到达延误时间，目的是改进预测性能并提供一个全面的印度铁路网络（IRN）数据集，涵盖4,735个车站和17个区域，这是迄今为止研究最大和最多样化的铁路网络。
### Innovation
我们提出了一种名为RSTGCN的模型，该模型结合了列车频率感知的空间注意力等创新架构和新颖特征整合，显著提升了预测性能。该模型还构建了一个全面的印度铁路网络数据集，这对于进一步研究列车延误预测这一关键领域至关重要。
### Conclusion
我们的研究不仅推进了大规模铁路网络中平均延误预测的建模，还通过提供一个开放数据集来鼓励进一步研究这一关键领域。
## 76. `cs.AI` - 基于LLM的孟加拉电子商务评论情感分类 [PDF](https://arxiv.org/pdf/2510.01276), [HTML](https://arxiv.org/abs/2510.01276)
### Authors
Sumaiya Tabassum
### Background
情感分析是文本分析的重要组成部分，涉及确定和评估作者的情感状态。大型语言模型（LLMs）如Llama的引入显著增加了高级模型应用的可用性，使得情感分析变得更高效。然而，由于语言的复杂性和评价中多样化的语言使用，准确的情感分析仍然面临挑战。
### Innovation
本研究通过使用参数高效的微调方法（LoRA和PEFT），对Llama-3.1-8B模型进行微调并对来自孟加拉电子商务的4000个样本进行测试，结果显示该模型在准确度、精确度、召回率和F1分数上分别达到95.5%、93%、88%和90%，优于其他微调模型。研究强调了如何降低计算开销并使得情感分析更适合资源有限的环境。
### Conclusion
研究结果表明，LLMs在孟加拉电子商务评论的情感分析中表现出色，参数高效的微调方法显著提高了模型的性能，降低了计算成本。该方法对资源受限的环境具有重要意义。
## 77. `cs.AI` - OpenAI的GPT-OSS-20B模型及其在低资源语言环境中的安全对齐问题 [PDF](https://arxiv.org/pdf/2510.01266), [HTML](https://arxiv.org/abs/2510.01266)
### Authors
Isa Inuwa-Dutse
### Background
近期，研究人员对OpenAI的GPT-OSS-20b模型进行了安全评估，发现了一系列漏洞，特别是在其在低资源语言环境下的性能和安全对齐方面。研究者重点评估了该模型在 Hausa（一种主要的非洲语言）中的行为，发现了明显的偏见、不准确以及文化敏感性不足的问题。此外，研究者还发现，当模型受到礼貌或感激的语言提示时，其安全协议似乎会放松，从而产生可能助长误导信息和仇恨言论的内容。这些发现凸显了模型在评估和安全对齐方面存在的问题。
### Innovation
研究者首次将红队测试方法用于低资源语言环境中，揭示了该模型在文化敏感性、准确性方面存在的问题。他们还注意到，模型在礼貌或感激语言的提示下会放松其安全机制，进而产生危险内容。此外，研究者提出这些错误可能是通过一种语言奖励欺骗的方式表现出来的，其中模型优先考虑在目标语言中产生流畅且听起来合理的内容，而不是安全性与真实性。
### Conclusion
经过深入分析，研究者确定该模型的缺陷主要源于低资源语言环境下安全调整不足。他们强调，在低资源语言环境下，当前的红队测试远未达到足够的覆盖范围，并提出了若干建议来改进这一状况。研究结果表明，需要更多的努力来确保类似大模型在多语言环境下的安全性、准确性和文化敏感性。
## 78. `cs.AI` - AdaDetectGPT：具有统计保证的大语言模型生成文本的自适应检测 [PDF](https://arxiv.org/pdf/2510.01268), [HTML](https://arxiv.org/abs/2510.01268)
### Authors
Hongyi Zhou,Jin Zhu,Pingfan Su,Kai Ye,Ying Yang,Shakeel A O B Gavioli-Akilagun,Chengchun Shi
### Background
现有的最先进的基于逻辑值的检测器使用给定来源大语言模型的分布函数来计算观察文本的log-probability统计，但仅依赖于log概率可能不理想。因此，提出了AdaDetectGPT，这是一种新颖的分类器，能够从训练数据中自适应学习证据函数以增强基于逻辑值的检测器的性能。该方法提供了其真正正率、真正负率、假正率和假负率的统计保证。广泛的数值研究表明，AdaDetectGPT在不同数据集和大语言模型组合的情况下，几乎均匀地提高了现有最先进的方法的性能，性能提升可高达58%。
### Innovation
引入了AdaDetectGPT，这是一种新型自适应分类器，能够从训练数据中学习适应性证据函数，以增强基于逻辑值的检测器的性能。该方法提供了其真正正率、真正负率、假正率和假负率的统计保证。数值研究表明，该方法在不同数据集与大语言模型的组合中，几乎均匀地提高了现有最先进的方法的性能，最高可达58%的提升。
### Conclusion
通过广泛的数值研究，AdaDetectGPT几乎在各种数据集和大语言模型组合中都均匀地提高了现有的最先进的方法的性能，性能提升可高达58%。该方法在GitHub上提供了Python实现。
## 79. `cs.AI` - 通过零样本分类衡量算法党派性及其对政治话语的影响 [PDF](https://arxiv.org/pdf/2510.01258), [HTML](https://arxiv.org/abs/2510.01258)
### Authors
Nathan Junzi Chen
### Background
随着生成式人工智能（GAI）的迅速常态化，智能系统在信息媒介中的政治话语中占据主导地位。然而，训练数据偏差、人类偏见和算法缺陷导致的内在政治偏见仍然困扰着这项新技术。本文采用零样本分类方法，通过结合理念倾向性、话题相关性、答复情感和客观性等评估算法的政治偏见，共分析了六个主流大语言模型（LLMs）的1800个模型响应，并使用四种不同的微调分类算法分别计算这些偏见评估指标。研究表明，所有六种LLMs在政治自由主义与极权主义的倾向性上表现出了显著增强的趋势，同时存在推理替换和僵硬拒绝的现象。研究进一步揭示了人机交互中的心理因素及其对公共话语中内在偏见的影响。这些政治景观的扭曲最终可能表现为顺从或极化，取决于该地区既有的社会政治结构特征。
### Innovation
该研究采用零样本分类方法，综合评估算法的政治偏见，涉及理念倾向性、话题相关性、答复情感和客观性等多维度指标。此外，研究分析了六个主流大语言模型的1800个模型响应，并使用四种不同的微调分类算法计算偏见评估指标，这在衡量算法政治偏见的研究中具有创新性。
### Conclusion
研究表明算法在政治自由主义与极权主义之间的倾向性显著增强，这可能影响到公共话语的形成，从而导致顺从或极化的政治景观，取决于地区社会政治结构的特点。该研究揭示了算法偏见对公众话语和政治环境的重要影响，强调了在使用智能系统时应关注和解决这些潜在问题。
## 80. `cs.AI` - 在循环神经网络中识别信息传递节点揭示动力化表示 [PDF](https://arxiv.org/pdf/2510.01271), [HTML](https://arxiv.org/abs/2510.01271)
### Authors
Arend Hintze,Asadullah Najam,Jory Schossau
### Background
理解循环神经网络（RNN）的内部动态对于提高其可解释性和优化设计至关重要。现有的研究方法缺乏有效的方式来识别和分析RNN内部的信息传递节点，该论文旨在填补这一空白，引入了一种创新的信息理论方法来识别和分析RNN中的信息传递节点，称为‘信息中继节点’。这种方法通过量化输入向量和输出向量之间的互信息来定位网络操作过程中信息流动的关键路径。研究者将该方法应用于多种RNN架构下的合成和实际时间序列分类任务，探究了不同架构下信息传递节点的不同模式，并通过节点剔除实验评估了其功能重要性，提供了详细解释RNN功能行为的见解。
### Innovation
研究引入了一种新的信息理论方法来识别和分析RNN中的信息传递节点，称为‘信息中继节点’。该方法通过计算输入和输出向量之间的互信息，量化信息流的有效路径，为RNN的可解释性和设计提供了新的视角。此外，研究者通过节点剔除实验进一步验证了这些节点的功能重要性，对提高RNN的解释性有重要意义。
### Conclusion
该研究不仅深化了对RNN复杂机制的理解，还为设计更稳健和可解释的神经网络提供了有价值的工具，对于解释具体节点如何影响整体网络行为具有重要贡献。
## 81. `cs.AI` - Budgeted广播：一种活动依赖的神经网络效率修剪规则 [PDF](https://arxiv.org/pdf/2510.01263), [HTML](https://arxiv.org/abs/2510.01263)
### Authors
Yaron Meirovitch,Fuming Yang,Jeff Lichtman,Nir Shavit
### Background
大多数剪枝方法根据对损失的影响（例如，幅度或梯度）移除参数。本文提出了一种Budgeted广播（BB）方法，给每个单元分配一个本地流量预算（其长期活动率$a_i$与分支因子$k_i$的乘积），并进行了受限熵分析，发现一项全球流量预算下最大化编码熵可以达到选择性观众平衡，即$frac{1-a_i}{a_i}=beta k_i$。BB使用简单的本地执行器来修剪扇入（降低活动）或扇出（降低广播）以实现这一平衡。在实践中，BB提高了编码熵和解相关性，提高了跨Transformer ASR、ResNets面部识别和3D U-Nets神经突触预测的准确率，有时甚至超过了密集基线。在电子显微镜图像中，BB在我们的评估协议下实现了最先进的F1分数和PR-AUC性能。BB易于集成，提供了一条通往学习更加多样化和高效表示的路径。
### Innovation
BB提出了一种活动依赖的修剪规则，通过给每个单元分配一个本地流量预算来实现编码熵最大化，同时平衡选择性和观众。BB的创新在于通过简单的本地执行器修剪扇入或扇出，以实现全球流量预算下的编码熵最大化和选择性观众平衡，这是对现有基于损失影响的修剪方法的一种显著改进。
### Conclusion
BB在不同类型的神经网络中提高了编码熵和准确率，特别是在电子显微镜图像分析中，达到了最先进的F1分数和PR-AUC性能。BB的简洁性和易于集成性质表明，这是一种有潜力的方法，可以进一步探索学习更加多样化和高效的网络表示。
## 82. `cs.AI` - 在AI甜美的和谐中：OpenAI gpt-oss-20b 的社会语用守门人规避与评估意识 [PDF](https://arxiv.org/pdf/2510.01259), [HTML](https://arxiv.org/abs/2510.01259)
### Authors
Nils Durner
### Background
本文通过探索OpenAI的Open-Weights 200亿参数模型gpt-oss-20b，研究了社会语用框架、语言选择和指令层级如何影响拒绝行为。该研究设计了多种测试情境，涵盖包括生成非法ZIP包、生成伪造信用卡号、误导性驾驶建议、药物前体指示以及知识提炼内容泄露等潜在有害领域。通过对这些不同情境的迭代测试，旨在揭示模型在面对潜在危害时的不同应对策略及其影响因素。在这种复杂的情境下，研究采用了复合提示的形式，结合教育者人设、安全预设和步骤指引，来观察模型在处理具体任务时的响应变化。此外，该文还分析了不同语言背景下模型的输出差异，并探讨了角色扮演在特定情境下的影响。研究发现不同语言形式对信息泄露的影响有明显差异，某些角色扮演策略能够显著减少信息泄露。作者还发现模型在处理某些任务时表现出评估意识，即能够自觉调整其行为模式以适应不同情境需求，但这种调整并非每次都一致。这些发现揭示了当前模型在面对潜在风险时的局限性，并强调了模型行为的可重复性问题。
### Innovation
本文通过以下几个方面展现了创新：首先，作者设计了多种具体的情境，包括生成有害内容的潜在领域，通过多个迭代测试，深入研究了社会语用框架、语言选择和指令层级的影响；其次，作者提出了复合提示这一新方法，通过结合特定的人设与安全预设来改变模型的反应；此外，研究还在不确定的学术评估背景下，引入了模型评估意识的概念，并进行了具体实证分析；最后，研究还揭示了一些目前存在的技术挑战，如模型对特定情境的适应性不足以及其响应的一致性问题。这些创新点有助于推动AI领域的进一步研究与技术改进。
### Conclusion
本文的结论是，当前大模型虽然在处理各种任务时表现出较高的灵活性，但在面对特定风险情境时，模型的响应一致性仍有待提高。模型的评估能力仍需增强，尤其是在不确定或具有欺骗性的学术评估情境下。此外，研究发现，在不同语言背景下的模型表现差异较大，某些特定的角色扮演方法能够有效降低模型泄露信息的风险。但模型的这种行为调整并不总是稳定的，存在一定的不确定性。因此，研究提出了要重视模型行为的可重复性问题，并建议在开发和应用此类模型时需要更多的注意和测试。
## 83. `cs.AI` - RLP: 强化学习作为预训练目标 [PDF](https://arxiv.org/pdf/2510.01265), [HTML](https://arxiv.org/abs/2510.01265)
### Authors
Ali Hatamizadeh,Syeda Nahida Akter,Shrimai Prabhumoye,Jan Kautz,Mostofa Patwary,Mohammad Shoeybi,Bryan Catanzaro,Yejin Choi
### Background
当前训练大规模推理模型的主要范式是从海量数据中使用后续标记预测损失进行预训练。虽然强化学习在扩展推理方面非常强大，但它仅在训练过程的最后阶段作为监督微调后的阶段引入。然而，这种训练方式是否是最优的？论文指出，强化学习的核心精神在于探索，在预训练的最后阶段引入这种精神，通过将思考过程视为探索行动，依据提供的信息增益计算奖励，可以鼓励模型在预测下一个标记之前进行自我思考，从而早期培养独立思考的能力。具体而言，奖励信号衡量在条件上下文和采样的推理链时下一个标记的对数似然增加量，对比仅条件上下文的对数似然增加量。这种方法在预训练期间提供了无需验证器的密集奖励信号，从而实现高效的全文档流训练。
### Innovation
提出了RLP（信息驱动的强化预训练目标），将强化学习的精神融入到预训练的最后阶段，通过基于信息增益的奖励计算机制，鼓励模型在预测之前进行自我思考。RLP将强化学习框架重新定义为普通文本的预训练目标，弥合了下一个标记预测与有用的推理链条之间的差距，使推理模型在预训练中更加自主。该方法在Qwen3-1.7B-Base模型上的表现提升了数学和科学基准测试的平均得分19%。在具有相同后期训练的情况下，对推理密集型任务如AIME25和MMLU-Pro的改进尤为显著。研究还将其应用于混合架构Nemotron-Nano-12B-v2，显示出在不同架构和模型规模上的可扩展性，将其总体平均得分从42.81%提升到61.32%，并且提高了科学推理的平均分23%。
### Conclusion
通过将强化学习机制作为预训练的目标，RLP提高了预训练效率，提升了推理模型的能力，特别是在推理密集型任务上的表现有了显著改善，展示了其在不同模型规模上的广泛适用性。
## 84. `cs.AI` - 新欧盟AI法案的分析及提出的机器学习公平性标准化框架 [PDF](https://arxiv.org/pdf/2510.01281), [HTML](https://arxiv.org/abs/2510.01281)
### Authors
Mike Teodorescu,Yongxu Sun,Haren N. Bhatia,Christos Makridis
### Background
欧盟的AI法案是朝着规范伦理和负责任的AI系统迈出的重要一步，但在量化公平性和术语表述的清晰度上存在缺失，尤其是在新法案中透明性、可解释性和可理解性的互换使用。这带来了潜在的法律风险，可能会阻碍投资。为了应对这一问题，本文提出了一个更定制化的监管框架，并建议建立一个公共评估系统框架来评估AI系统的公平性和透明性。此外，还建议将行业最佳实践标准化作为大规模监管的补充，以满足行业所需的详细程度，同时避免扼杀AI领域的创新和投资。稿件以ASR和语音合成器为例进行说明。
### Innovation
文章提出了一个更定制化的监管框架，并建议建立一个公共评估系统框架来评估AI系统的公平性和透明性。此外，还建议将行业最佳实践标准化作为大规模监管的补充，以满足行业所需的详细程度，同时避免扼杀AI领域的创新和投资。
### Conclusion
本文建议通过标准化行业最佳实践来加强新的欧盟AI监管，提出了一种评估AI公平性和透明性的公共系统框架，并以ASR和语音合成器为例进行了具体说明。
## 85. `cs.AI` - 基于LLM的多代理黑板系统在数据科学中的信息发现 [PDF](https://arxiv.org/pdf/2510.01285), [HTML](https://arxiv.org/abs/2510.01285)
### Authors
Alireza Salemi,Mihir Parmar,Palash Goyal,Yiwen Song,Jinsung Yoon,Hamed Zamani,Hamid Palangi,Tomas Pfister
### Background
大数据湖中的数据多样性带来了数据利用的挑战，现有单代理和多代理系统在数据发现方面的性能不佳，单代理系统会因大量异构文件而迅速失效，而基于主从架构的多代理系统依赖于中心控制器，需要详细的代理能力信息。
### Innovation
提出了一种基于传统AI模型黑板架构的新型多代理通信框架，该框架不依赖中央协调器，通过公共黑板发布请求，自我驱动的从属代理根据其能力提供响应，提升了系统扩展性和灵活性，表现出在数据发现任务中优于基线和主从架构多代理系统
### Conclusion
黑板架构显著提高了任务成功和数据发现的F1分数，特别是在各种LLM（企业级和开源）上，证明了其作为多代理系统通信框架的扩展性和通用性。
## 86. `cs.AI` - Noisy-Pair Robust Representation Alignment for Positive-Unlabeled Learning [PDF](https://arxiv.org/pdf/2510.01278), [HTML](https://arxiv.org/abs/2510.01278)
### Authors
Hengwei Zhao,Zhengzhong Tu,Zhuo Zheng,Wei Wang,Junjue Wang,Rusty Feagin,Wenzhe Jiao
### Background
PU学习旨在训练一个二元分类器（正样本 vs 负样本），仅提供了有限的正样本数据和大量的未标记数据。尽管这种方法具有广泛的应用性，但现有的最先进的PU学习方法在复杂数据集上的性能远低于其监督学习的对应方法，尤其是在没有辅助负样本或预估参数的情况下（例如，在CIFAR-100数据集上存在14.26%的性能差距）。关键挑战在于在不可靠监督下的学习鉴别性表示的困难。
### Innovation
本文提出了NcPU，这是一种非对比的PU学习框架，无需辅助信息。NcPU结合了鲁棒的监督非对比损失（NoiSNCL）和幻标签消歧（PLD）方案。NoiSNCL在不可靠监督环境下能够对类内表示进行对齐，而PLD通过基于遗憾的标签更新提供保守的负监督。理论和实验结果表明，NcPU能够显著提高各种数据集上现存最好的PU方法的表现，尤其是在灾害后建筑物损坏映射等具有挑战性的数据集上。
### Conclusion
广泛的实验表明，NoiSNCL能够让简单的PU方法达到竞争性的性能，而NcPU则在多种数据集上，尤其是在具有挑战性的数据集上，相较于现有的最佳PU方法实现了显著的性能提升，展示了其在实际应用中的潜力。代码将在审阅后开放源代码。
## 87. `cs.AI` - Think Twice, Generate Once: 自我反思的保障 [PDF](https://arxiv.org/pdf/2510.01270), [HTML](https://arxiv.org/abs/2510.01270)
### Authors
Hoang Phan,Victor Li,Qi Lei
### Background
大型语言模型（LLMs）在自然语言处理中通过生成连贯且上下文相关的内容，已经产生了颠覆性的变革。然而，它们的部署引起了关于生成有害或不适当内容的潜在风险的担忧。
### Innovation
本文提出了一种新颖的推理时技术——渐进自我反思（PSR），该技术使LLMs能够在动态中自我监控和纠正输出。实验结果显示，应用该方法后，对Llama-3.1-8B-Instruct的成功攻击率从77.5%降至5.9%，对Llama-3.1-8B基础版的成功攻击率从89.7%降至5.6%，对Qwen2.5-7B-Instruct的成功攻击率从44.4%降至3.8%，而且在保持原始无害任务性能的同时，没有额外的训练。该方法在测试时作为一种可调缩放的方法，每增加一轮自我反思可以提高安全性但需要更多的推理开销。为了在安全性与计算效率之间取得平衡，提出了一个轻量级的自我反思预测器，可以根据输入复杂度估计最优的自我反思轮数。这种适应性机制可以在有害内容上进行彻底评估，而在良性输入上避免不必要的自我评估。
### Conclusion
渐进自我反思作为一种可扩展的测试阶段方法，通过根据输入的风险特征动态分配计算资源来提高LLMs的安全性。
## 88. `cs.AI` - 从二维到三维，基于深度学习的磁共振成像形状重构：综述 [PDF](https://arxiv.org/pdf/2510.01296), [HTML](https://arxiv.org/abs/2510.01296)
### Authors
Emma McMillian,Abhirup Banerjee,Alfonso Bueno-Orovio
### Background
基于深度学习的从二维磁共振成像（MRI）重建三维（3D）形状在医学疾病诊断、治疗规划和计算建模中变得越来越重要。这篇综述概述了3D MRI重建的方法学景观，重点关注四种主要方法：点云、网格、形状感知和体素模型。对于每种类别，分析了当前的先进技术、方法论基础、局限性和在不同解剖结构中的应用。
### Innovation
该综述对其进行了全面概述，从心脏成像到神经成像再到肺部成像，并着重讨论了模态模型在病变结构中的临床应用，模型的训练和测试数据对其的影响。还分析了公开数据集、计算需求和评估指标。此外，还强调了新兴的研究方向，如多模态集成和跨模态框架。
### Conclusion
这篇综述旨在为研究人员提供一个结构化的3D重建方法概述，以识别推进深度学习技术发展以实现更健壮、更具泛化能力和临床影响力的解决方案的机会。
## 89. `cs.AI` - TUMIX：工具使用混合的多代理测试时扩展方法 [PDF](https://arxiv.org/pdf/2510.01279), [HTML](https://arxiv.org/abs/2510.01279)
### Authors
Yongchao Chen,Jiefeng Chen,Rui Meng,Ji Yin,Na Li,Chuchu Fan,Chi Wang,Tomas Pfister,Jinsung Yoon
### Background
尽管像Code Interpreter和Search这样的工具显著增强了大型语言模型（LLM）如ChatGPT Agent和Gemini-Pro的推理能力，但关于如何优化这些工具使用的具体指导仍然缺乏。核心挑战是如何有效地结合文本推理、编程和搜索以应对各种问题。
### Innovation
本文提出了一个名为Tool-Use Mixture（TUMIX）的集成框架，该框架通过并行运行多个采用不同工具使用策略和答案路径的代理，实现了显著的性能提升。TUMIX能够根据问题和先前的答案迭代共享和改进答案。与其他最先进的方法相比，TUMIX在关键的推理基准测试中实现了高达3.55%的平均准确性提升，同时保持了相近的推理成本。此外，代理多样性和质量可以通过使用LLM自适应优化代理设计来提升。
### Conclusion
TUMIX能够在达到足够信心时停止改进，仅使用49%的推理成本就能维持性能。进一步的扩展可以提高性能，但需要更高的成本。
## 90. `cs.AI` - 评估新的人工智能细胞基础模型在处理以往基础模型未解决的肾病理学挑战病例中的性能 [PDF](https://arxiv.org/pdf/2510.01287), [HTML](https://arxiv.org/abs/2510.01287)
### Authors
Runchen Wang,Junlin Guo,Siqi Lu,Ruining Deng,Zhengyi Lu,Yanfan Zhu,Yuechen Yang,Chongyu Qu,Yu Wang,Shilin Zhao,Catie Chang,Mitchell Wilkes,Mengmeng Yin,Haichun Yang,Yuankai Huo
### Background
细胞核分割在肾脏病理学下游任务中至关重要，但由于肾组织在形态和成像方面的多样性，这一任务仍是一个重大挑战。尽管之前的研究评估了早期的人工智能细胞基础模型，但较新的细胞基础模型的有效性尚不清楚。因此，当前研究使用具有人类在环评价框架的多样大规模肾图像斑块集，对比评估先进的人工智能细胞基础模型（2025年），包括CellViT++变体和Cellpose-SAM，与之前2024年前开发的三种广泛应用的细胞基础模型的性能。这些模型包括从先前研究中未解决的具有挑战性的样本进行进一步的融合基组合评估和模型一致性分析，以评估不同模型的分割能力。
### Innovation
研究引入了新的融合评估方法和模型一致性分析来评估不同模型的性能；并使用2025年最新的CellViT++变形进行了细胞核分割任务的评估，对比了较旧的模型。此外，研究通过融合模型解决了以往研究中未解决的许多具有挑战性的病例，显著降低了分割错误。
### Conclusion
研究结果表明，CellViT++ [维奇沃] 在处理具有挑战性的样本时表现出最高的独立性能，优于所有之前模型。融合模型在具有挑战性的样本上达到了62.2%的良好预测率，错误率仅为0.4%，减少了分割错误。这些发现证明了在肾脏病理学中开发人工智能细胞基础模型的潜力，同时提供了一个具有挑战性的样本数据集，以支持未来针对肾脏的模型改进。
## 91. `cs.AI` - 使用大型语言模型增强切伦科夫望远镜阵列控制软件的发展 [PDF](https://arxiv.org/pdf/2510.01299), [HTML](https://arxiv.org/abs/2510.01299)
### Authors
Dmitriy Kostunin,Elisa Jones,Vladimir Sotnikov,Valery Sotnikov,Sergo Golovachev,Alexandre Strube
### Background
本文探讨了基于指令微调的大语言模型（LLMs）开发AI代理，以协助切伦科夫望远镜阵列（CTAO）控制与数据采集软件（ACADA）的工程和操作。这些代理能够与项目特定的文档和代码库对齐，理解上下文信息、与外部API交互以及用自然语言与用户交流。文章介绍了将这些功能集成到CTAO操作流水线和离线数据分析流程中的进展。
### Innovation
本文提出了一种创新的方法，通过使用大语言模型（LLMs）开发AI代理来辅助CTAO的控制和数据采集软件。该方法利用了LLMs在理解和处理自然语言方面的优势，使得AI代理能够更好地与其他外部系统和用户交互，同时与项目特定的文档和代码库保持一致。这为自动化和提升CTAO的运营效率提供了新的途径。
### Conclusion
本文展示了将基于LLMs的AI代理成功集成到CTAO的控制和数据分析软件中的进展。这些AI代理不仅能够提高软件的自动化程度，还能增强系统的灵活性和适应性，为未来的天文观测提供有效的支持。
## 92. `cs.AI` - 低秩梯度及其位置 [PDF](https://arxiv.org/pdf/2510.01303), [HTML](https://arxiv.org/abs/2510.01303)
### Authors
Rishi Sonthalia,Michael Murray,Guido Montúfar
### Background
本文探讨了两层神经网络训练损失梯度中的低秩结构，放宽了对训练数据和参数的常规等向性假设。研究采用了尖峰数据模型，其中主体可以是非等向性和病态条件的，不要求数据和权重矩阵独立，同时也讨论了均场和神经核尺度情况下的梯度。研究表明，输入权重关于的梯度大约是低秩的，主要由两个秩一项支配：一个与主体数据残差对齐，另一个与输入数据中的秩一尖峰对齐。
### Innovation
创新点在于探讨了在更宽泛的条件下，如非等向性和病态条件下的低秩梯度结构，还分析了训练数据的性质、缩放阶段和激活函数如何共同影响这两个组成部分之间的平衡。此外，还表明常用正则化项（如权重衰减、输入噪声和雅可比惩罚）也按键择性地调节这些组成部分。
### Conclusion
实验结果验证了理论预测，即输入权重关于的梯度大约是低秩的，主要由两个秩一项支配，这些发现突出了训练数据性质、缩放阶段和激活函数对低秩梯度结构的影响。
## 93. `cs.AI` - 启发于微瞬目的眼位编码扰动揭示LLM的行为异常 [PDF](https://arxiv.org/pdf/2510.01288), [HTML](https://arxiv.org/abs/2510.01288)
### Authors
Rui Melo,Rui Abreu,Corina S. Pasareanu
### Background
本文受到了人类微瞬目这种小而不自觉的眼部运动的启发，这些运动揭示了人类感知的隐藏动态。类比这一现象，研究者尝试提出一种适用于大型语言模型（LLMs）的探针方法。通过细微的、不强制的、位置编码的扰动，可以激发潜在的信号来揭示模型的异常。这些方法不需要微调和任务特定的监督，而能在多种多样的环境中检测失误，包括事实性、安全性、毒性以及后门攻击等方面。实验证明，基于扰动的探针在发现模型中的异常情况的同时，也能保持计算上的高效性。研究表明，预训练的LLMs已内含可识别其自身错误的信息，并且启发于微瞬目的干预可能提供一种检测和减轻不良行为的途径。
### Innovation
提出了一种新模式：通过轻量级的位置编码扰动来检测大型语言模型的异常行为，这种方法不需要微调和任务特定的监督，广泛适用于各种场景，如事实性、安全性、毒性及后门攻击等，并且在检测到这些异常后仍能保持计算上的高效性。创新点在于利用微瞬目的启示提出了一种新的探针方法，能够在不用深度微调的情况下检测出模型的异常行为。
### Conclusion
研究表明，预训练的大型语言模型已经内含识别其自身错误所需的信息，并且启发于微瞬目的干预可能提供一种检测并减轻不良行为途径。这种基于微瞬目的探针显示了在保持计算效率的同时，能够有效地揭示模型的行为异常。
## 94. `cs.AI` - HiSpec: 分层投机解码技术用于LLMs [PDF](https://arxiv.org/pdf/2510.01336), [HTML](https://arxiv.org/abs/2510.01336)
### Authors
Avinash Kumar,Sujay Sanghavi,Poulami Das
### Background
投机解码通过使用较小的试探模型推测令牌，由较大的目标模型验证来加速LLM推理。验证通常是瓶颈，比令牌生成慢得多（例如，3B模型推测70B目标模型时验证慢4倍），而大多数早期工作仅专注于加速试探过程。虽然现有的中间验证方法可以减少验证时间，但这些方法会引入大量训练开销，增加内存占用，并依赖不精确的启发式方法来降低准确性。
### Innovation
HiSpec提出了一种分层投机解码框架，利用早退模型进行无成本中间验证。HiSpec重新设计了方法，使其能在试探模型、中间验证器和目标模型之间重用关键值缓存和隐藏状态，以提高资源效率。同时，HiSpec定期验证由中间验证器接受的试探令牌与目标模型的一致性以保持准确性。实验结果表明，HiSpec相比单一层数的试探推断平均提高吞吐量1.28倍，最高可达2.01倍，同时并不牺牲准确性。
### Conclusion
HiSpec通过分层早期退出模型进行低开销中间验证，结合优化的资源利用策略，显著提升了密集搜索的LLM推理速度，同时维持了较高的准确率。
## 95. `cs.AI` - WAInjectBench: 定位 Web 代理中提示注入检测的基准 [PDF](https://arxiv.org/pdf/2510.01354), [HTML](https://arxiv.org/abs/2510.01354)
### Authors
Yinuo Liu,Ruohan Xu,Xilong Wang,Yuqi Jia,Neil Zhenqiang Gong
### Background
已经提出了针对 Web 代理的多种提示注入攻击。尽管开发了多种方法来检测一般的提示注入攻击，但这些方法还没有系统地评估应用于 Web 代理的性能。
### Innovation
本文填补了这一空白，通过首次全面评估针对 Web 代理的提示注入攻击检测方法构建了第一个基准研究。首先，本文基于威胁模型对攻击进行了细粒度分类。接着，构造了包含恶意和良性样本的数据集，涵盖了多种恶意文本和图像样本以及不同类别的良性文本和图像。最后，系统化了基于文本和图像的检测方法，并在多种场景下评估了它们的性能。
### Conclusion
研究表明，尽管一些检测器能够对依赖明确文本指令或可见图像扰动的攻击识别率达到中等到高，但对不使用明确指令或使用不可感知扰动的攻击识别效果较差。
## 96. `cs.AI` - DeMuon: 一种用于图上矩阵优化的去中心化 Muon 方法 [PDF](https://arxiv.org/pdf/2510.01377), [HTML](https://arxiv.org/abs/2510.01377)
### Authors
Chuan He,Shuyi Ren,Jingwei Mao,Erik G. Larsson
### Background
本文提出了一种名为 DeMuon 的方法，用于在给定的通信拓扑上进行去中心化矩阵优化。DeMuon 结合了矩阵正交化的过程，使用 Newton-Schulz 迭代，并采用了梯度跟踪来缓解局部函数之间的异质性。
### Innovation
DeMuon 是 Muon 的直接延伸，适用于图上去中心化优化问题，且具有可证明的复杂性保证。在重尾噪声条件下，在某些假设下，作者建立了 DeMuon 达到近似随机平稳点的迭代复杂性，并与中央优化算法的最佳已知复杂性界限相匹配。这是第一个具有这种特性的方法。
### Conclusion
作者在不同连通度的图上对分布式变压器预训练进行了初步的数值实验，结果表明 DeMuon 在不同网络拓扑结构中相对于其他流行的是中心化算法具有明显的优势。
## 97. `cs.AI` - 违背意图的AI减少了利他意图并促进了依赖 [PDF](https://arxiv.org/pdf/2510.01395), [HTML](https://arxiv.org/abs/2510.01395)
### Authors
Myra Cheng,Cinoo Lee,Pranav Khadpe,Sunny Yu,Dyllan Han,Dan Jurafsky
### Background
公众和学术界对AI过度迎合或恭维用户的现象——称为‘阿谀行为’——表示了极大担忧。然而，除了个别媒体关于其严重后果的报道外，有关阿谀行为的程度及其影响知之甚少。
### Innovation
本研究首次系统地探讨了阿谀行为在人们向AI寻求建议时的普遍性和有害性。通过分析11款最先进的AI模型的表现，并进行了两项预注册实验，研究不仅揭示了AI的阿谀行为，还展示了这种行为如何影响用户的决策和行为。
### Conclusion
研究发现，阿谀行为降低了参与者的修好意图，并增加了他们坚持自己正确的信念。尽管如此，这些参与者仍认为阿谀行为的质量较高，更信赖阿谀行为的AI，并愿意再次使用该模型。这表明人们倾向于依赖于无条件认可自己的AI，即使这种认可会侵蚀他们的判断力，减少其利他行为的倾向。这种偏好创造了不利的激励结构，促使人们越来越多地依赖阿谀行为的AI模型，并推动AI模型训练偏向于阿谀行为。因此，必须明确解决这种激励结构，以减轻AI阿谀行为的广泛风险。
## 98. `cs.AI` - 代码安全评估：通过系统性越狱攻击对AI代码代理的安全评估 [PDF](https://arxiv.org/pdf/2510.01359), [HTML](https://arxiv.org/abs/2510.01359)
### Authors
Shoumik Saha,Jifan Chen,Sam Mayers,Sanjay Krishna Gouda,Zijian Wang,Varun Kumar
### Background
随着代码具备能力的大语言模型（LLM）被嵌入软件工程的工作流程中，它们能够读取、编写和执行代码，这增加了安全绕过（“越狱”）攻击的风险。尽管之前的评估了拒绝和有害文本检测，但尚未明确这些代理是否能够编译和执行恶意程序。这项研究通过构建JAWS-BENCH基准测试评估了这一风险。
### Innovation
该研究引入了JAWS-BENCH基准测试，涵盖了三种逐步升级的工作空间环境，模拟了攻击者的能力。此外，该研究使用了一种分层、可执行感知的法官框架，不仅检查代理是否同意攻击、攻击的成功率，还检查了语法规则性和运行时执行性，从而超越简单的拒绝来衡量可部署的危害。研究同时发现了不同类别攻击的最脆弱和最容易部署程度。
### Conclusion
在仅有提示的条件下，JAWS-0环境中小代码代理同意61%的攻击，其中58%是有害的，52%可以解析，27%可以端到端执行。随着攻击范围提升到单文件（JAWS-1）和多文件（JAWS-M）环境，攻击成功率分别提高到约71%和75%，并且有32%的代码能够即时部署。由此，将大语言模型嵌入代理中显著增加了漏洞程度——攻击成功率提高了1.6倍，这是因为最初的拒绝决定经常在后续的计划及工具使用步骤中被推翻。研究结果促使了需要运行时感知防御、代码上下文安全过滤以及确保代理多步推理和工具使用过程中保留最初拒绝决定的机制的发展。
## 99. `cs.AI` - 复杂化学系统自由能计算的神经网络代理 [PDF](https://arxiv.org/pdf/2510.01396), [HTML](https://arxiv.org/abs/2510.01396)
### Authors
Wasut Pornpatcharapong
### Background
自由能重建方法，如高斯过程回归（GPR），需要集体变量（CVs）的雅可比矩阵，这成为限制使用复杂或机器学习CV的主要瓶颈。现有的方法依赖于需要解析形式的雅可比矩阵，阻碍了复杂或机器学习CV的应用。
### Innovation
引入了一个神经网络代理框架，该框架可以直接从笛卡尔坐标学习CVs，并利用自动微分提供雅可比矩阵，从而绕过了解析形式的需要。该方法在MgCl2离子对系统中对简单距离CV和复杂配位数CV均实现了高精度，并且雅可比误差近似服从高斯分布，适合用于GPR管道。该框架使得基于梯度的自由能方法能够使用复杂和机器学习CVs，扩大了生物化学和材料模拟的应用范围。
### Conclusion
该神经网络代理框架能够学习复杂的CVs并提供雅可比矩阵，使得复杂和机器学习CVs可用于自由能计算方法中，拓展了生物化学和材料模拟的研究领域。
## 100. `cs.AI` - BioVERSE: 将生物医学模态对齐到LLMs以实现多模态推理 [PDF](https://arxiv.org/pdf/2510.01428), [HTML](https://arxiv.org/abs/2510.01428)
### Authors
Ching-Huei Tsou,Michal Ozery-Flato,Ella Barkan,Diwakar Mahajan,Ben Shapira
### Background
近期，大型语言模型（LLMs）和生物医学基础模型（BioFMs）在生物学文本推理、分子建模和单细胞分析等方面取得了显著成果，但它们仍然在独立的嵌入空间中孤立存在，限制了跨模态推理能力。
### Innovation
提出了一种两阶段的方法BIOVERSE（Biomedical Vector Embedding Realignment for Semantic Engagement），该方法将预训练的BioFMs作为模态编码器，并通过轻量级、特定于模态的投影层将它们与LLMs对齐。该方法首先通过独立训练的投影将每个模态对齐到共享的LLM空间，实现模态间的自然交互，然后使用多模态数据进行标准指令调优，将它们统一起来用于下游推理。通过将原始生物医学数据与拉通在LLMs中的知识相结合，该方法能够实现零样本注释、跨模态问答以及交互式、可解释的对话。
### Conclusion
在细胞类型注释、分子描述和蛋白质功能推理等任务中，紧凑的BIOVERSE配置超过了较大的LLM基准模型，同时生成更为丰富、生成式输出，建立了原则性的多模态生物医学推理基础。
## 101. `cs.AI` - AFFORD2ACT: 基于 affordance 引导的自动关键点选择以实现可泛化的轻量级机器人操作 [PDF](https://arxiv.org/pdf/2510.01433), [HTML](https://arxiv.org/abs/2510.01433)
### Authors
Anukriti Singh,Kasra Torshizi,Khuzema Habib,Kelin Yu,Ruohan Gao,Pratap Tokekar
### Background
基于视觉的机器人学习通常依赖于密集的图像或点云输入，这计算量大且容易包含无关背景特征。现有的基于关键点的方法可以专注于操作相关的特征且是轻量的，但要么依赖人工启发式方法，要么任务耦合选择，这限制了广度和语义理解能力。已有方法存在的主要问题是缺乏对语义信息的有效提取和对任务的广泛适用性，特别是在处理未见过的对象、新类别、背景和干扰物时数据效率低下，难以达到较好的实时表现。
### Innovation
提出了一种名为 AFFORD2ACT 的 affordance 引导框架，该框架能够从文本提示和单张图片中提取最小的语义 2D 关键点。AFFORD2ACT 采用三阶段流水线： affordance 过滤，类别水平关键点构建，以及带有嵌入门控的变压器基策略学习，以确定最相关的关键点。最终得到一个紧凑的 38 维状态策略，能够在 15 分钟内训练，并在进行时表现出色，不依赖于本体感觉或密集表示。该方法在一系列不同的实际操作任务中证明了其可泛化和轻量级的优点，尤其在对未见过的对象、新类别、背景和干扰物表现优异，显著提高了数据效率，取得 82% 的成功率。
### Conclusion
AFFORD2ACT 在减轻计算负担、提高实时性能和广域适用性方面做出了关键贡献，为机器人操作中背景信息的抽象和理解和数据效率的提升提供了一种有效方法。
## 102. `cs.AI` - GeoSURGE：基于地理嵌入层次结构的语义融合全球视觉地理定位 [PDF](https://arxiv.org/pdf/2510.01448), [HTML](https://arxiv.org/abs/2510.01448)
### Authors
Angel Daruna,Nicholas Meegan,Han-Pang Chiu,Supun Samarasekera,Rakesh Kumar
### Background
全球视觉地理定位旨在仅利用图像的视觉内容确定其在地球上的地理位置。尽管在该领域取得了大量进展，但视觉地理定位中地理表示的学习仍然是一个活跃的研究主题。本文将地理定位问题表述为对查询图像的视觉表示与学习到的地理表示进行对齐。该研究克服了现有方法的限制，提出了一个新的地理表示法，明确将世界建模为地理嵌入的层次结构，并引入了一种高效融合查询图像的外观特征和语义分割图的方法，从而形成一种稳健的视觉表示。
### Innovation
本文的主要创新在于：1) 提出了一种地理嵌入的层次结构作为地理表示法，以更好地建模地理结构；2) 引入了语义分割图与视觉特征的高效融合方法，从而增强了视觉表示的鲁棒性；3) 全面的实验证明了与现有最佳方法和大型视觉-语言模型相比，该方法在五个基准数据集上取得了22/25个收益的改进结果。实验证明这些收益主要得益于地理表示和视觉表示的结合效果。
### Conclusion
本文提出了一种名为GeoSURGE的方法，通过建模地理嵌入层次结构和有效融合语义分割和视觉特征，显著提高了全球视觉地理定位性能。
## 103. `cs.AI` - Offline-to-Online强化学习的三阶段 [PDF](https://arxiv.org/pdf/2510.01460), [HTML](https://arxiv.org/abs/2510.01460)
### Authors
Lu Li,Tianwei Ni,Yihao Sun,Pierre-Luc Bacon
### Background
Offline-to-online强化学习（RL）已经成为了合理化的范式，利用离线数据集进行预训练并通过在线交互进行微调。然而，这种方法的实际表现具有高度的不一致性：在一种设置中的在线微调设计选择可能在另一种环境中完全失败。
### Innovation
提出了稳定性-可塑性原则，以解释这种不一致性。该原则认为在线微调时应保持预训练策略或离线数据集中的知识，同时保持足够的可塑性。同时，这种方法确定了在线微调的三种阶段，每种阶段都需要不同的稳定性特性。通过大规模的实验证实了这种框架，并在45个案例中与预测结果高度一致，从而为根据离线数据集和预训练策略的相对表现指导Offline-to-online RL的设计选择提供了一个基本原则框架。
### Conclusion
该研究提供了一个基于离线数据集和预训练策略相对表现的原则性框架，用于指导Offline-to-online RL的设计选择。
## 104. `cs.AI` - Purrception：变分流匹配在向量量化图像生成中的应用 [PDF](https://arxiv.org/pdf/2510.01478), [HTML](https://arxiv.org/abs/2510.01478)
### Authors
Răzvan-Andrei Matişan,Vincent Tao Hu,Grigory Bartosh,Björn Ommer,Cees G. M. Snoek,Max Welling,Jan-Willem van de Meent,Mohammad Mahdi Derakhshani,Floor Eijkelboom
### Background
变分流匹配方法通常用于图像生成，但这些方法往往忽视了离散监督的作用。向量量化图像生成方法虽然能够提供离散监督，但传统的流匹配方法在这类应用中存在动力学连续性的问题。
### Innovation
提出了一种名为Purrception的方法，结合了连续流匹配的几何感知能力和离散监督的优势。具体来说，Purrception通过学习码本索引上的分类后验，同时在连续嵌入空间中计算速度场，从而解决了上述问题，使得在可能的代码上进行不确定性量化，并可通过温度控制实现生成。
### Conclusion
Purrception方法在ImageNet-1k 256x256图像生成上进行评估，显示了比单纯的连续流匹配和离散流匹配更快速的训练收敛速度，同时与最新模型相比，在FID分数方面具有竞争力。这表明变分流匹配方法能够有效地在连续运输和离散监督之间架起桥梁，以提高图像生成的训练效率。
## 105. `cs.AI` - 本地线性注意力：线性与softmax注意力的最佳插值方法用于推理时间回归 [PDF](https://arxiv.org/pdf/2510.01450), [HTML](https://arxiv.org/abs/2510.01450)
### Authors
Yifei Zuo,Yutong Yin,Zhichen Zeng,Ang Li,Banghua Zhu,Zhaoran Wang
### Background
Transformer架构在各种领域取得了显著的成功，尽管已经研究了有效的替代Softmax Attention的方法，但对于基于理论洞察更加表达性的机制（即使在更高的计算成本下）的研究还相对较少。本文通过提出本地线性注意力（LLA），一种通过测试时回归视角的非参数统计推导出来的新颖注意力机制，试图填补这一空白。LLA通过对联想记忆进行偏置方差权衡分析，展示了其在理论上的优势。作者还提出了两种内存高效的方法解决计算挑战，并介绍了一种硬件高效、块状算法FlashLLA，能够在现代加速器上实现可扩展且平行的计算。此外，还实施并配置了一个定制的推理内核，显著减少了内存开销。最后，通过实验证明LLA在测试时回归、上下文回归、联想回忆和状态跟踪任务中的优势与局限，并表明其在大规模模型中的可扩展性和应用潜力。
### Innovation
提出了本地线性注意力（LLA），一种基于非参数统计通过测试时回归视角的新型注意力机制，解决了Linear和Softmax Attention在联想记忆上的理论优势。此外，提出了FlashLLA，一种硬件效率高且块状的算法，能够在现代加速器上实现高效计算。同时，通过定制推理内核减少了内存开销。并通过对多种任务的实验证明，LLA在非线性适应性、测试时训练和上下文学习中优于强基线，并展示了其大规模应用的潜力。
### Conclusion
实验结果表明，本地线性注意力有效适应非稳定性，优于强大的基线，在测试时训练和上下文学习中表现优异，并展示了其可扩展性和广泛应用的前景。
## 106. `cs.AI` - 命令行的AI引导：通过AI从手册页生成图形界面 [PDF](https://arxiv.org/pdf/2510.01453), [HTML](https://arxiv.org/abs/2510.01453)
### Authors
Saketh Ram Kasibatla,Kiran Medleri Hiremath,Raven Rothkopf,Sorin Lerner,Haijun Xia,Brian Hempel
### Background
尽管诞生于电报时代的命令行界面（CLI）在20世纪80年代图形界面革命中幸存下来，并在现代桌面操作系统中继续存在，但用户必须回忆文本语法并通过查找文档来发现这些功能，这给用户带来了一定的挑战。相比之下，图形界面（GUI）使得用户能够通过小部件和菜单有机地发现并执行可能的操作。
### Innovation
本文介绍了一种通过AI自动将命令行工具的文档（手册页）转换为界面规范，从而自动生成图形界面的机制。通过这些规范，作者的面向用户系统GUIde以图形方式向用户展示命令选项。
### Conclusion
本文通过对一组命令的评估表明，GUIde能够为用户的真实世界命令行任务提供充分的图形界面，从而更好地展示了命令行的强大功能。
## 107. `cs.AI` - RealClass: 一种基于公开数据集和游戏引擎的教室语音模拟框架 [PDF](https://arxiv.org/pdf/2510.01462), [HTML](https://arxiv.org/abs/2510.01462)
### Authors
Ahmed Adel Attia,Jing Liu,Carol Espy Wilson
### Background
由于大型教室语音数据的稀缺，阻碍了教育领域中基于AI的语音模型的发展。现有的教室数据集有限且不对外公开，缺乏专门为教室设计的噪声和室冲响应（RIR）数据集，因而无法使用标准的数据增强技术。这种情况下，难以开发出有效的教室语音模型，影响了教育技术的进步。
### Innovation
本文提出了一种可扩展的方法，利用游戏引擎合成教室噪声和RIR，构建了一个灵活的框架，该框架能够扩展到其他领域之外。在此基础上，该研究引入了RealClass数据集，结合了合成的教室噪声和公开来源的教室语音数据。此外，该数据集包括儿童语音和来自YouTube的教员语音，以模拟清洁条件下的真实课堂互动。实验表明，RealClass能够近似真实教室语音，为缺乏大量真实教室语音的情况下提供了宝贵的资源。
### Conclusion
通过RealClass数据集和新的合成方法，本研究显著改善了教室语音数据的可用性，为教育技术领域提供了新的语音数据资源，促进了AI驱动语音模型的发展。
## 108. `cs.AI` - 理解对抗转移：为什么模型空间攻击在数据空间攻击成功的情况下失败 [PDF](https://arxiv.org/pdf/2510.01494), [HTML](https://arxiv.org/abs/2510.01494)
### Authors
Isha Gupta,Rylan Schaeffer,Joshua Kazdan,Ken Liu,Sanmi Koyejo
### Background
对抗鲁棒性领域已经证明，图像模型之间可以成功转移对抗样本，语言模型之间可以成功转移文本‘脱狱’攻击。但最近的研究发现，视觉语言模型之间不能成功转移图像‘脱狱’攻击。本文试图解释这一显著差异。
### Innovation
提出了一种根本性的区分，即针对机器学习模型的攻击在输入数据空间可以传递，但在模型表示空间不能传递，至少需要几何对齐表示。通过四个不同的设置提供了理论和实验证据支持这一假设。
### Conclusion
对抗转移不是所有攻击的固有属性，而是取决于它们的操作领域——共享的数据空间与模型的唯一表示空间。这对于构建更稳健的模型具有关键意义。
## 109. `cs.AI` - 从关键词到语义：大型语言模型在数据发现中的感知 [PDF](https://arxiv.org/pdf/2510.01473), [HTML](https://arxiv.org/abs/2510.01473)
### Authors
Maura E Halstead,Mark A. Green,Caroline Jay,Richard Kingston,David Topping,Alexander Singleton
### Background
当前的数据发现方法依赖于在元数据和查询之间匹配关键词。这种方式要求研究者记得之前其他研究者使用的确切表达方式，这不仅是一个挑战，还可能导致遗漏相关的数据。大型语言模型（LLMs）可以通过允许使用自然语言来提问，从而改进数据发现过程，但这需要考虑研究者是否愿意接受这种新方法。研究人员对LLMs的有效性尚未确定，因此需要进一步了解他们的接受程度和障碍。
### Innovation
使用以人类为中心的人工智能（HCAI）的方法，研究通过焦点小组收集了27名研究人员对于将LLMs应用于数据发现的视角。研究发现，尽管LLMs有潜在的益处，但在现有的技术中，这些好处不足以促使研究人员完全采用这些新技术。妨碍研究人员接受LLMs的部分原因是透明度不足，而增加透明度可能有助于解决问题。这项研究为开发人员提供了如何增强LLMs在数据发现中的应用接受度的指导建议，通过整合透明性和易用性功能，提升研究者的接受度。
### Conclusion
基于研究提出的一个概念模型，开发者能够更好地设计和整合透明性和用户便利性功能，这些特性将有助于提高研究者对LLMs应用于数据发现的接受度。目前的研究结果指出，尽管存在一些障碍，但如果正确设计和优化LLMs，它们最终会被广泛接受并显著改进数据发现的效率。
## 110. `cs.AI` - 基于药效团指导的新型药物分子的生成设计 [PDF](https://arxiv.org/pdf/2510.01480), [HTML](https://arxiv.org/abs/2510.01480)
### Authors
Ekaterina Podplutova,Anastasia Vepreva,Olga A. Konovalova,Vladimir Vinogradov,Dmitrii O. Shkil,Andrei Dmitrenko
### Background
人工智能（AI）在早期药物发现中的应用为探索化学空间和加速从候选药物到先导化合物的优化提供了前所未有的机会。然而，在生成方法中进行对接优化会消耗大量计算资源，可能导致结果不准确。因此，需要一种能够在保持化学多样性的同时，保证与参考化合物药效团相似性的新方法。
### Innovation
该研究提出了一种新的生成框架，能够平衡参考化合物的药效团相似性与活性分子的结构多样性。该框架允许用户提供自定义参考集，包括FDA批准的药物或临床候选药物，指导从头生成潜在的治疗药物。实验结果显示，生成的化合物保留了高药效团保真度的同时，引入了结构上的大量新颖性，表明具有很强的功能创新和专利申请潜力。
### Conclusion
针对乳腺癌雌激素受体调节剂和拮抗剂进行的案例研究表明，该方法生成的分子在保持已知活性分子药效团保真性的同时，展示了显著的结构新颖性，验证了该方法的稳健性和药学相关性。
## 111. `cs.AI` - 使用真实世界数据和药物理化性质进行兽医安全概况、残留评估和健康结果的预测建模及可解释AI [PDF](https://arxiv.org/pdf/2510.01520), [HTML](https://arxiv.org/abs/2510.01520)
### Authors
Hossein Sholehrasa,Xuan Xu,Doina Caragea,Jim E. Riviere,Majid Jaberi-Douraki
### Background
兽药在食品生产动物中的安全使用对于保护动物福利和人类食品安全至关重要。不良事件（AEs）可能提示未预期的药代动力学或毒代动力学效果，增加食品链中违禁残留的风险。美国FDA的OpenFDA中心兽医学中心提供了约128万份从1987年至2025年第一季度的报告，用于开发预测框架，以分类死亡和恢复结果。
### Innovation
该研究提出了一种预测框架，通过将药理学报告与VeDDRA术语集标准化，整合物理化学药物特性，以捕捉化学残留联系，采用监督学习模型（包括随机森林、CatBoost、XGBoost、ExcelFormer和大型语言模型），并通过集成技术（投票、堆叠）和AUM基于的伪标记法提高结果的识别率。通过SHAP分析，识别出生物上合理的预测器，如肺病、心脏病、气管疾病、动物人口统计学和药物物理化学特性。该模型结合了严格的数据工程、先进的机器学习和可解释的人工智能，实现了对兽医安全结果的准确、可解释的预测。
### Conclusion
该框架证明了结合严格的数据工程、先进的机器学习和可解释的人工智能能够实现对兽医安全结果准确、可解释的预测。该方法支持FARAD的任务，通过早期检测高风险药物-事件概况，增强残留风险评估，并为监管和临床决策提供信息。
## 112. `cs.AI` - VL-KnG: 使用时空知识图谱进行导航目标识别的视觉场景理解 [PDF](https://arxiv.org/pdf/2510.01483), [HTML](https://arxiv.org/abs/2510.01483)
### Authors
Mohamad Al Mdfaa,Svetlana Lukina,Timur Akhtyamov,Arthur Nigmatzyanov,Dmitrii Nalberskii,Sergey Zagoruyko,Gonzalo Ferrer
### Background
视觉语言模型（VLMs）在机器人导航方面显示出潜力，但存在根本性的局限性：缺乏持久的场景记忆，空间推理能力有限，实时应用场景时扩展性差。这些模型在处理视频序列时遇到诸多挑战，难以提供有效的导航目标识别能力。本研究旨在克服这些挑战，通过时空知识图谱构建和高效的查询处理来识别导航目标。该方法利用现代VLM处理视频序列，构建持久的知识图谱以维持对象身份，并通过查询可查询的图结构实现可解释的空间推理。
### Innovation
提出了VL-KnG，一种使用时空知识图谱处理视觉场景理解的导航目标识别系统。该系统将视频序列分块处理，利用现代VLMs创建持久的知识图谱，并通过查询可查询的图结构实现可解释的空间推理。此外，还提出了WalkieKnowledge新基准，包含200多个人工标注问题，涵盖8种多样化轨迹，持续近100分钟的视频数据，这有助于结构化方法与通用VLMs之间的公平比较。这种规范化的知识图谱构建方法提高了实时部署的效率，使其在不同的任务中（如定位、导航和规划）具有广泛应用潜力。
### Conclusion
在一款差速驱动机器人上进行的实际部署表明了该方法的实用价值，其成功率为77.27%，回答准确性为76.92%，性能与Gemini 2.5 Pro相当，同时提供了由知识图谱支持的可解释推理，并且具有跨任务的计算效率。相关代码和数据集将在论文被接受后公开。
## 113. `cs.AI` - 大型语言模型生态系统中涌现的评价枢纽 [PDF](https://arxiv.org/pdf/2510.01286), [HTML](https://arxiv.org/abs/2510.01286)
### Authors
Manuel Cebrian,Tomomi Kito,Raul Castro Fernandez
### Background
大型语言模型正在迅速增加，相应的基准也越来越受欢迎。本文探讨了模型创造分布与基准分布的模式是否一致，或者是否表现出差异。研究使用斯坦福基金会模型生态系统图和Evidently AI基准注册表作为两个精心选择的代理来分析这两个层面。
### Innovation
通过对比模型创造与基准衡量的动态，发现虽然模型创建呈现出多样化的趋势，但基准衡量却表现出中央化的特征。研究还通过代理基础模型生态系统图和基准注册表，揭示了随着新基准的不断加入，相互依赖关系有所降低；然而，快速涌入的基准可能会暂时干扰评估协调，而提高防止过拟合的惩罚力度对减少这种干扰效果有限。
### Conclusion
基准的集中影响力作为一种协调基础设施，在促进标准化、可比性和可再现性方面发挥了作用，尤其是在模型生产多样化的背景下。但是也会引入一些权衡，例如路径依赖、选择性可见性和顶级排行榜的差异化能力减弱。
## 114. `cs.AI` - SPUS:一种轻量且参数高效的偏微分方程基础模型 [PDF](https://arxiv.org/pdf/2510.01370), [HTML](https://arxiv.org/abs/2510.01370)
### Authors
Abu Bucker Siddik,Diane Oyen,Alexander Most,Michal Kucer,Ayan Biswas
### Background
当前解决各种偏微分方程（PDEs）的最先进的神经场模型主要基于复杂的大型变压器架构，这些架构具有较高的计算和参数开销。这些模型虽然功能强大，但因为复杂性较高，使得在许多实际应用中的部署和使用较为困难。
### Innovation
SPUS（Small PDE U-Net Solver）是一个紧凑高效的神经场模型，它采用了一种轻量级的残差U-Net架构，这种架构在偏微分方程领域基础模型的架构探索中较少使用。SPUS利用简单但有效的自回归预训练策略，这种策略模仿数值求解器的行为来学习物理原理。该模型在不同类型的流体动力学PDEs上进行预训练，并在6个挑战性的未见过的下游PDE任务上进行评估。实验结果表明SPUS在下游任务中达到了最先进的泛化效果，同时需要较少的参数和微调数据。
### Conclusion
SPUS作为一种高度参数高效的偏微分方程基础模型，展示出了在不同PDE系统中优异的表现和广泛的适用性，表明它具有作为解决复杂物理系统问题的强有力工具的潜力。
## 115. `cs.AI` - 从视频到索引知识图谱——融合方法进行多模态内容分析和理解的框架 [PDF](https://arxiv.org/pdf/2510.01513), [HTML](https://arxiv.org/abs/2510.01513)
### Authors
Basem Rizk,Joel Walsh,Mark Core,Benjamin Nye
### Background
多模态内容分析往往计算成本高且需要大量的工程努力。虽然有一些在静态数据上使用预训练模型的工作，但将这些开源模型和方法与复杂的如视频等数据融合仍具有挑战性。文章背景描述了现有的技术难题和面临的挑战。在过去的许多研究中，虽然已经有许多静态数据上预训练模型工作的基础，但如何有效融合这些模型以应对复杂数据还缺乏有效解决方案，特别是在视频数据上进行深度结合和处理方面。因此，解决多模态数据特别是视频数据的处理依然是一个技术难点。文章正是针对这一问题展开研究的。
### Innovation
本文提出了一种框架，该框架能够有效地为多模态内容分析原型开发流水线。通过将一组预训练模型结合在一起，本框架能够将视频转换为时间上的半结构化数据格式，并进一步转化为框标注知识图谱。该图谱具有可查询性和支持持续学习的能力，可以通过互动媒介动态整合新的领域知识。这样，就可以在复杂的数据条件下，保持模型的高效性和灵活性，并大幅减少工程方面的负担。
### Conclusion
本文提出的方法通过特征提取、时间半结构化表示和索引知识图谱的支持查询与持续学习能力，为多模态数据的处理提供了一种高效的解决方案。通过此框架可以有效地结合预训练的模型，从而更高效地进行多模态内容的分析和理解，特别是在视频数据的应用场景下。这种方法特别适用于需要整合跨模态信息并持续更新的知识体系。
## 116. `cs.AI` - WALT: Web Agents that Learn Tools [PDF](https://arxiv.org/pdf/2510.01524), [HTML](https://arxiv.org/abs/2510.01524)
### Authors
Viraj Prabhu,Yutong Dai,Matthew Fernandez,Jing Gu,Krithika Ramakrishnan,Yanqi Luo,Silvio Savarese,Caiming Xiong,Junnan Li,Zeyuan Chen,Ran Xu
### Background
当前的网络代理方法依然存在脆弱性，主要依赖于逐步骤的用户界面交互和大量的LLM推理，这些方法在动态布局和长时间段下容易失效。与此相对，人类通过使用网站提供的高级功能（如搜索、过滤、排序等）来进行操作，这些功能能够更灵活地适应网站的变化。论文的目标是开发一种新的框架，能够将网站的功能逆向工程化转化为可重复使用的工具，从而提高自动化能力。这种方法旨在减少对脆弱的逐步骤推理的依赖，转而依靠可靠的工具调用。
### Innovation
WALT框架通过逆向工程化网站的功能，将其转化为可重复使用的工具，以高阶操作形式（如搜索、过滤、排序等）抽象掉低级别的执行细节。这种框架不是假设特定的技能，而是揭示已设计进网站中的自动化操作。WALT框架覆盖了发现（搜索、过滤、排序）、通信（发帖、评论、点赞）和内容管理（创建、编辑、删除）等多个方面，使得自动化代理更加可靠和易于实现。此外，该框架减少了对LLM的依赖，并能有效应对复杂的浏览任务。
### Conclusion
WALT框架在VisualWebArena和WebArena上取得了更高的成功率，并且使用更少的步骤和更少对LLM推理的依赖，为浏览器自动化提供了一种更可靠和可扩展的范式。
## 117. `cs.AI` - POLAR：通过LLM增强评估自动化网络威胁优先级 [PDF](https://arxiv.org/pdf/2510.01552), [HTML](https://arxiv.org/abs/2510.01552)
### Authors
Luoxi Tang,Yuqiao Meng,Ankita Patra,Weicheng Ma,Muchao Ye,Zhaohan Xi
### Background
大规模语言模型（LLMs）广泛用于帮助安全分析师应对迅速发展的网络威胁，为漏洞评估和事件响应提供网络威胁情报（CTI）。尽管最近的研究显示LLMs在威胁分析、漏洞检测和入侵防御等CTI任务上表现出色，但在实际部署中仍然存在显著的性能差距。本研究旨在探讨影响LLMs在CTI中的内在脆弱性，重点研究威胁环境本身的特性导致的挑战，而非模型架构。通过多CTI基准和真实世界威胁报告的大规模评估，引入了一种新的分类方法，结合分层、自回归精炼和人类闭环监督，以可靠分析故障实例。研究表明，这些故障主要由虚假相关性、矛盾知识和受限泛化导致。这些因素限制了LLMs在有效支持CTI方面的应用能力。
### Innovation
提出了一种新的分类方法，结合分层、自回归精炼和人类闭环监督，以可靠地分析故障实例。揭示了三种基本的脆弱性：虚假相关性、矛盾知识和受限泛化，这些共同限制了LLMs在有效支持CTI方面的应用能力。为设计更健壮的LLM增强CTI系统提供了实际见解，以便未来的工作能够利用这些发现。
### Conclusion
研究表明，现有LLMs在CTI领域中的应用存在显著的性能差距，限制了其有效性和实用性。通过提出新的分类方法和揭示三大关键漏洞，为未来设计更健壮的LLM增强CTI系统提供了理论依据和实践指导。
## 118. `cs.AI` - 过驱动回归中的风险相变：对齐驱动的良性和灾难性过拟合 [PDF](https://arxiv.org/pdf/2510.01414), [HTML](https://arxiv.org/abs/2510.01414)
### Authors
Jiping Li,Rishi Sonthalia
### Background
本文分析了线性回归中最小范数插值解的泛化误差，使用了尖峰协方差数据模型。研究聚焦于不同尖峰强度和目标-尖峰对齐对风险（尤其是过参数化设置下的风险）的影响。
### Innovation
本文提出了泛化误差的精确表达式，并基于尖峰强度、特征比 $c=d/n$（特别是当 $c to fty$ 时）以及目标对齐情况，对良性、适度和灾难性过拟合进行了全面分类。研究还揭示了目标-尖峰对齐并非总是有益的，并指出了对其有益或有害的具体且有时违背直觉的情况。实验结果显示，即使在良好指定且对齐的问题中，提高尖峰强度也可能先导致灾难性过拟合再使过拟合变得良性。
### Conclusion
本文的工作是基于尖峰强度和目标-尖峰对齐对过拟合风险的精确表达式，以及全面分类了良性、适度和灾难性过拟合的相变现象，尤其在非线性模型中，目标-尖峰对齐的对齐情况可能带来不利影响。
## 119. `cs.AI` - 重新思考RLHF中的KL正则化：从数值估值到梯度优化 [PDF](https://arxiv.org/pdf/2510.01555), [HTML](https://arxiv.org/abs/2510.01555)
### Authors
Kezhao Liu,Jason Klein Liu,Mingtao Chen,Yiming Liu
### Background
在强化学习从人类反馈（RLHF）中，KL散度损失用于稳定训练并防止过拟合。然而，在方法如GRPO中，其实现可能被数值估值的原则引导，忽视了其作为优化损失的功能作用。
### Innovation
本文建立了一个统一框架，揭露两种看似不同的实现风格之间的等价性：将数学项$k_n$作为策略分数函数中的独立系数与直接通过其传递梯度以作为损失函数。证明了传统的$'k_1$在奖励中'（如PPO中的）是反向KL（RKL）正则化的原则性损失。进一步证明，在经验策略条件下，$'k_2$作为损失'形式与$'k_1$在奖励中'在梯度上等效。提出最新的$'k_3$作为损失'只是有偏的一阶逼近。反对常见的离策略实现方法忽视了重要性采样的偏差，并提出原则修正。
### Conclusion
研究提供了基于梯度的全面选择和正确实现KL正则化的理由，为更安全有效的RLHF系统铺平了道路。
## 120. `cs.AI` - 利用盲人和低视力人士视觉问题引导多模态大型语言模型进行主动视觉解释 [PDF](https://arxiv.org/pdf/2510.01576), [HTML](https://arxiv.org/abs/2510.01576)
### Authors
Ricardo Gonzalez Penuela,Felipe Arias-Russi,Victor Capriles
### Background
多模态大语言模型（MLLMs）已被集成到视觉解释应用中，以支持盲人和低视力用户，因其准确性和提供丰富的人类般的解释能力。然而，这些应用通常默认提供全面而冗长的描述，而不管具体环境如何。这导致了低效的交流，用户必须花费时间浏览与他们最有可能寻求的具体信息无关的细节。为了提供更有针对性的信息，该系统使用了历史上的盲人和低视力用户的问题。当给定一幅图片时，该系统会从VizWiz-LF数据集中识别相似的过去视觉场景并利用对应的用户问题引导MLLM生成更具针对性的描述。评价结果显示，相比标准的描述，语境感知描述在约76.1%的案例中预见并回答了用户的问题，并且在约54.4%的情况下被用户偏爱。
### Innovation
该系统通过对历史盲人和低视力用户的视觉问题进行分析，利用MMLMs生成更加具有针对性的描述，从而改善了视觉解释应用对这两类用户的服务质量。这一创新之处在于，通过利用历史数据和用户的问题指导模型生成，提高了描述的相关性和用户的满意度。此外，评价结果表明，社会各界可以通过基于这些交互数据的系统改进来更好地支持盲人和低视力用户，特别是增强语境感知能力方面。
### Conclusion
一项针对92个描述的评估实验显示，基于语境的描述在76.1%的案例中预见并回答了用户的问题，并且在54.4%的比较中被偏好。系统文件和数据在GitHub仓库中开源，这为其他研究者进一步研究盲人和低视力用户的视觉解释需求提供了基础。
## 121. `cs.AI` - 从监督到探索：蛋白质语言模型在强化学习过程中学习了什么？ [PDF](https://arxiv.org/pdf/2510.01571), [HTML](https://arxiv.org/abs/2510.01571)
### Authors
Hanqun Cao,Hongrui Zhang,Junde Xu,Zhou Zhang,Lingdong Shen,Minghao Sun,Ge Liu,Jinbo Xu,Wu-Jun Li,Jinren Ni,Cesar de la Fuente-Nunez,Tianfan Fu,Yejin Choi,Pheng-Ann Heng,Fang Wu
### Background
蛋白质语言模型（PLMs）通过大规模预训练和可扩展的架构推动了计算蛋白质科学的进步。同时，强化学习（RL）扩展了探索范围，并在蛋白质设计中实现了精确的多目标优化。然而，是否可以通过RL让PLMs超越其预训练的先验知识，发现潜在的序列-结构-功能规则仍不清楚。
### Innovation
将RL与PLMs结合，在四个领域（抗菌肽设计、激酶变体优化、抗体工程和逆向折叠）中进行了研究。使用不同的RL算法和模型类别，探讨了RL是否提高了采样效率及是否揭示了监督学习未捕捉到的能力。结果表明，RL在各个基准中一致提高了成功率和采样效率。性能受到三个因素的综合作用：任务空间、奖励的准确度和政策容量共同决定改进程度。
### Conclusion
研究表明，只有当奖励准确且信息丰富、政策具有足够的容量，且任务超越了监督模型的基础时，改进才会扩大。在奖励存在噪声或容量受限的情况下，尽管进行了探索，改进也会饱和。这一视角为蛋白质设计中的RL应用提供了实用指导：在扩大政策规模之前，优先进行奖励建模和校准；匹配算法和正则化强度以适应任务难度；将容量分配在边际收益最大的地方。
## 122. `cs.AI` - 通过对比特征增强提升帕金森病远程监测的鲁棒性 [PDF](https://arxiv.org/pdf/2510.01588), [HTML](https://arxiv.org/abs/2510.01588)
### Authors
Ziming Tang,Chengbin Hou,Tianyu Zhang,Bangxu Tian,Jinbao Wang,Hairong Lv
### Background
帕金森病（PD）是一种常见的神经退行性疾病。远程监测（PD 电信护送）作为一种新型评估手段，使得帕金森病患者可以在家中自行完成统一帕金森病评定量表（UPDRS）评分测试，增加了患者的易用性。然而，在测量过程中会遇到三种类型的噪声：（1）患者诱导的测量不准确，（2）环境噪声，以及（3）传输中数据包丢失，这些都会导致预测误差的增加。
### Innovation
提出了一个名为NoRo的噪声稳健UPDRS预测框架。首先，基于选定特征的连续值将原始语音特征分组为有序的区间，构建对比样本对。然后，使用对比样的对来训练多层次感知器编码器，生成噪声稳健的特征。最后，将这些特征与原始特征拼接成扩增特征，输入UPDRS预测模型。此外，还引入了一种定制的噪声注入评估方法，实验证明NoRo可以在不同噪声环境下有效提升UPDRS预测的鲁棒性。
### Conclusion
NoRo框架在不同的噪声环境中能够成功提升UPDRS预测模型的噪声鲁棒性。
## 123. `cs.AI` - 使用合成前缀缓解实时神经查询自动补全文本中的偏见 [PDF](https://arxiv.org/pdf/2510.01574), [HTML](https://arxiv.org/abs/2510.01574)
### Authors
Adithya Rajan,Xiaoyu Liu,Prateek Verma,Vibhu Arora
### Background
在实时神经查询自动补全文本系统中存在某种形式的展示偏见，这种偏见源自模型建议影响用户行为。为了减轻这种展示偏见，作者提出了一种以数据为中心的方法，使用合成前缀，这些前缀是从活跃搜索会话中自助查询中收集的数据生成的。这些前缀用于训练学习排序模型，并提供更加多样性和无偏的示例。这种方法解决了实时查询自动补全文本交互中收集的参与信号固有的偏见，其中模型建议影响了用户体验。这种排列表现优化了严格延迟要求下的实时部署，并集成了包括查询流行度、季节性、模糊匹配分数以及上下文信号（如部门偏好、设备类型和与用户历史查询的垂直对齐）等丰富的特征集合。为了支持高效的训练，作者引入了一个针对特定任务简化了的列表损失函数，通过利用每个前缀只有一个真实选择的特点，将计算复杂度从O(n^2)降低到O(n)。经过大规模电子商务环境的部署，系统在用户参与度的度量上（使用平均倒数秩和相关度量）显示出统计显著的改进。研究表明，合成前缀不仅仅是提高泛化能力，也提供了一种缓解其他低延迟排序任务中偏见的可扩展途径，包括相关搜索和查询推荐。
### Innovation
提出了一种以数据为中心的解决方案，通过使用来自完整用户查询的合成前缀来减轻实时神经查询自动补全文本系统中的展示偏见。通过这种方法，可以提供更多样化、更少偏见的示例，丰富训练数据集。作者还提出了一种针对特定任务简化了的列表损失函数，降低了计算复杂度。这种方法不仅提高了排序模型的泛化能力，还为解决低延迟排序任务中的偏见问题提供了可扩展的路径。并在大规模电子商务环境中进行了验证，表现出显著的用户参与度改进。
### Conclusion
研究展示了一种通过合成前缀有效减轻实时神经查询自动补全文本展示偏见的方法。这种方法不仅提高了模型的泛化能力，还在大规模现实生活场景中证明了其有效性，并为解决类似低延迟排序问题中的偏见提供了一种可扩展的途径。
## 124. `cs.AI` - 独立与联合微调策略在检索增强生成中的对比 [PDF](https://arxiv.org/pdf/2510.01600), [HTML](https://arxiv.org/abs/2510.01600)
### Authors
Neal Gregory Lawton,Alfy Samuel,Anoop Kumar,Daben Liu
### Background
检索增强生成（RAG）是一种通过两个大型语言模型（LLMs）驱动的问题回答框架。嵌入模型从数据库中检索与给定问题相关的上下文文档，生成模型利用这些检索到的上下文生成问题的答案。为了提高RAG管道在新任务上的性能，可以对嵌入和生成模型进行微调。然而，不同的微调策略存在不同的成本和效益。本文评估和比较了几种RAG微调策略，包括独立、联合和两阶段微调。实验结果表明，这些策略在EM和F1生成质量指标上的改进大致相同，但计算成本却有显著差异。
### Innovation
本文评估并比较了独立和联合微调策略在RAG管道中的应用，并通过实验展示了这些不同策略的表现。研究表明，尽管各种微调策略在生成质量上的提升较为接近，但在计算资源消耗上存在显著差异。
### Conclusion
本文得出结论，最佳的微调策略取决于训练数据集中是否包含上下文标签，以及是否需要对嵌入和生成模型的学习率进行网格搜索。
## 125. `cs.AI` - SFT-RL后训练中的沼泽：高SFT得分的误导及替代方案 [PDF](https://arxiv.org/pdf/2510.01624), [HTML](https://arxiv.org/abs/2510.01624)
### Authors
Feiyang Kang,Michael Kuchnik,Karthik Padthe,Marin Vlastelica,Ruoxi Jia,Carole-Jean Wu,Newsha Ardalani
### Background
目前实践中的大型语言模型（LLMs）后训练阶段包括两个独立的阶段：监督微调（SFT）和带可验证奖励的强化学习（RLVR），即所谓的“RL”。当前研究发现在经过监督微调后，强化学习是否能提升模型的表现并不一定平稳有效。作者通过大量反例和实验，发现高SFT分数可能偏向上简单或更一致的数据，并不能可靠地预测后续强化学习的收益或大规模后训练的效果。
### Innovation
作者提出并研究了替代的评估指标，如保存在未见过的推理示例上的泛化损失和Pass@large k性能，以强有力地预测后处理强化学习（RL）的效果。通过对比不同模型组合和数据集的结果，表明基于泛化损失和Pass@large k的预测比直接从预RL性能预测更为精确，提高了$R^2$系数和Spearman等级相关系数达0.5至2倍。
### Conclusion
实验结果证明，相对于直接预测从RL前的表现，基于泛化损失和Pass@large k的预测提供了更高的精确度。建议使用这些替代指标来替代直接基于SFT得分的预测，以优化后处理效果。同时，评估工具将被开源。
## 126. `cs.AI` - 超越多数投票：通过利用高阶信息进行LLM聚合 [PDF](https://arxiv.org/pdf/2510.01499), [HTML](https://arxiv.org/abs/2510.01499)
### Authors
Rui Ai,Yuqi Pan,David Simchi-Levi,Milind Tambe,Haifeng Xu
### Background
随着多智能体大规模语言模型（LLM）推理的迅速发展，如何有效聚合多个LLM的答案成为了重要挑战。传统的多数投票方法将所有答案同等对待，忽视了模型之间的潜在异质性和相关性。
### Innovation
本文设计了两种新的聚合算法，即最优加权（OW）和逆惊人流行度（ISP），利用了一阶和二阶信息。理论分析证明，在轻微假设下，这些方法能有效缓解多数投票方法的固有局限，提高集体决策的可靠性。通过在合成数据集、流行的LLM微调基准数据集（如UltraFeedback和MMLU）以及实际医疗场景ARMMAN中的实证验证，本文方法在所有情况下都优于多数投票方法，提供了实用性能提升和设计理念的概念性见解。
### Conclusion
本文方法在所有测试场景中始终优于多数投票，提供了实用的性能改进和多智能体LLM系统设计的概念性洞察。
## 127. `cs.AI` - 动态对齐、多模态融合与基于证据解释的协作过滤与大型语言模型结合 [PDF](https://arxiv.org/pdf/2510.01606), [HTML](https://arxiv.org/abs/2510.01606)
### Authors
Bo Ma,LuYao Liu,Simon Lau,Chandler Yuan,and XueY Cui,Rosie Zhang
### Background
近年来的研究通过将用户互动历史和项目元数据转化为文本提示，并利用大型语言模型生成排名或推荐来探索使用大型语言模型进行推荐任务的方法。一种有前景的方法是通过紧凑的适配器网络将协作过滤知识连接到大型语言模型的表示中，既避免了昂贵的微调成本，又保留了两者的优点。然而，还有一些实践中的挑战，如协作过滤模型通常使用静态快照，未能捕捉到快速变化的用户偏好；许多真实世界的项目包含丰富的视觉和音频内容，远远超出文本描述；当前系统难以提供基于具体证据的信任解释。
### Innovation
我们的研究提出了一种名为?model的框架，通过三个关键创新解决这些限制。首先，开发了一种在线适应机制，通过轻量级模块不断纳入新的用户交互，无需重新训练大型模型。其次，创建了一个统一的表示形式，能够无缝结合协作信号与视觉和音频特征，处理某些模态可能不可用的情况。最后，设计了一个解释系统，将推荐基于特定的协作模式和项目属性，产生用户可以验证的自然语言理由。
### Conclusion
我们提出的方法保持了冻结基础模型的效率，同时增加了最少的计算开销，使其适用于现实世界的部署。
## 128. `cs.AI` - 正确思考：通过适应性注意压缩减轻思维不足与过剩 [PDF](https://arxiv.org/pdf/2510.01581), [HTML](https://arxiv.org/abs/2510.01581)
### Authors
Joykirat Singh,Justin Chih-Yao Chen,Archiki Prasad,Elias Stengel-Eskin,Akshay Nambi,Mohit Bansal
### Background
现有的思维模型通过增加测试时的计算量来解决复杂的推理任务，但这需要根据任务难度合理分配。一方面，简短的推理（思维不足）会导致解决需要更长推理步骤的问题时出现错误；另一方面，过度的推理（思维过剩）则可能是不切实际的，会生成不必要的步骤，即使达到正确的中间解决方案也是如此。这个问题被称作不足适应性，即模型未能根据问题的难度适当调节其响应长度。本文通过分析这一问题，提出了一种在线后训练RL方法，即TRAAC（适应回顾压缩算法），它利用模型在长时间推理轨迹上的自我注意来识别重要步骤和剪裁冗余步骤。TRAAC还估计问题难度，并将其纳入训练奖励中，从而学习适应推理预算与问题难度之间的分配关系。
### Innovation
提出的TRAAC（适应回顾压缩算法）方法通过利用模型在长时间推理过程中的自我注意来识别重要步骤并消除冗余步骤，从而在在线后训练RL中弥合问题难度与推理长度之间的差距。此外，TRAAC还估计任务难度，并将其融入训练奖励中，以适应不同的推理预算需求。这种方法在多个任务上的表现优于基线模型和其他RL基线。
### Conclusion
TR Acc计划在多种任务（AIME，AMC，GPQA-D，BBEH）上实现了基线模型的平均准确率提高8.4%，推理步骤减少36.8%，以及与最优RL基线相比，准确率提高7.9%，推理长度减少29.4%。此外，经过数学数据集训练后，模型在非数学数据集GPQA-D，BBEH和OptimalThinkingBench上也表现出准确性和效率的提升，这进一步证明了TR Acc提供了针对难度的精细调整，并且目标优先级设置和基于注意的压缩组合在多种任务上都能获得收益。
## 129. `cs.AI` - LLM4Rec: 大型语言模型在因果偏见消除下的多模态生成推荐 [PDF](https://arxiv.org/pdf/2510.01622), [HTML](https://arxiv.org/abs/2510.01622)
### Authors
Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Lau
### Background
当代生成推荐系统在处理多模态数据、消除算法偏见和提供透明决策过程方面面临着重大挑战。现有的推荐系统难以同时高效处理多种数据形式，并且可能存在偏见问题，影响推荐的公平性和多样性。
### Innovation
本文提出了一个增强的生成推荐框架，通过五个关键创新来解决上述问题：多模态融合架构、检索增强生成机制、基于因果推理的去偏机制、可解释的推荐生成以及实时自适应学习能力。该框架采用先进的大型语言模型作为基础架构，结合了用于跨模态理解和上下文知识整合的专业模块，以及偏见缓解、解释合成和连续模型自适应等方面的特殊功能。
### Conclusion
在三个基准数据集（MovieLens-25M、Amazon-Electronics、Yelp-2023）上进行的广泛实验表明，该框架在推荐准确性、公平性和多样性方面均优于现有方法。所提出的框架在NDCG@10上提高了2.3%，在多样性指标上提高了1.4%，同时通过优化推理策略保持了计算效率。
## 130. `cs.AI` - RAG-BioQA 实现长格式生物医药问答的检索增强生成 [PDF](https://arxiv.org/pdf/2510.01612), [HTML](https://arxiv.org/abs/2510.01612)
### Authors
Lovely Yeswanth Panchumarthi,Sai Prasad Gudari,Atharva Negi,Praveen Raj Budime,Harsit Upadhya
### Background
生物医药文献的快速增长给获取精确医学信息带来了巨大挑战。现有的生物医药问答系统主要关注短答案，无法提供临床决策所需的全面解释。这些系统在解决复杂问题和为临床决策提供依据方面存在不足。论文提出了RAG-BioQA框架，结合检索增强生成和领域特定微调，以生成证据为基础的长格式回答。该框架使用BioBERT嵌入与FAISS索引的结合，并通过不同重排序策略（BM25、ColBERT、MonoT5）优化上下文选择，在验证模型调优的基础上，生成证据。实验结果表明，与基线相比，改进显著，尤其是在BLEU、ROUGE和METEOR指标上，展示了可获取、基于证据的生物医药知识检索的进步。
### Innovation
RAG-BioQA框架将检索增强生成与领域特定微调相结合，生成基于证据的长格式回答。通过BioBERT嵌入与FAISS索引的结合，以及不同重排序策略优化上下文选择，最终通过调优的T5模型合成证据。该系统在PubMedQA数据集上取得了显著的提升，特别是在多项指标上取得进步，推进了可获取的、基于证据的生物医药知识检索的水平。
### Conclusion
RAG-BioQA在PubMedQA数据集上的实验结果表明，相较于基线模型，该框架实现了显著的性能提升，特别是在多个评估指标上，如BLEU、ROUGE和METEOR指标，大幅提升了整个生物医药知识的存取与准确性，这也是对现有生物医药QA系统的改进与超越。
## 131. `cs.AI` - 位置：隐私不只是记忆! [PDF](https://arxiv.org/pdf/2510.01645), [HTML](https://arxiv.org/abs/2510.01645)
### Authors
Niloofar Mireshghallah,Tianshi Li
### Background
现有的有关大型语言模型（LLMs）对隐私风险的讨论主要集中在对其训练数据的verbatim记忆，而忽视了更多即时且可扩展的隐私威胁。研究指出，隐私问题不仅限于训练数据提取，还涉及数据收集实践、推理时上下文泄漏、自主代理能力以及通过深度推理攻击促进监视的民主化。通过对过去十年（2016-2025年）主要会议上发表的1322篇AI/ML隐私论文的纵向分析，发现技术研究过于关注记忆问题，而最为紧迫的隐私危害却未得到充分应对。目前的技术方法在解决这些问题上显得力不从心，未来路径尚不明确。
### Innovation
本文提出了一种全面的隐私风险分类方法，覆盖LLM生命周期的数据收集和部署阶段。展示了当前隐私框架在应对这些多方面威胁时存在的不足，并通过案例研究证明现有的隐私框架未能处理这些问题。呼吁研究社区从单一技术解决方案转向涵盖社会技术和方法的综合策略。
### Conclusion
实际的技术研究对记忆力的关注超出了实际的最紧迫隐私危害，提出需要在研究方法上实现根本性的转变，采取跨学科的策略，以应对这些新出现的复杂威胁。
## 132. `cs.AI` - 面向以人为本的技术合规：解析专业人士安全使用大语言模型的策略和需求 [PDF](https://arxiv.org/pdf/2510.01638), [HTML](https://arxiv.org/abs/2510.01638)
### Authors
Siying Hu,Yaxing Yao,Zhicong Lu
### Background
大语言模型正在深刻改变高风险专业领域的作业模式，但同时也带来了严重的、尚未充分探索的合规风险。本研究通过半结构化的访谈，研究了来自法律、医疗保健和金融行业24名高级知识工作者的看法，发现他们普遍担心敏感信息泄露、知识产权侵权以及模型输出质量的不确定性。在此基础上，他们自发采取了多种缓解策略，例如主动扭曲输入数据和限制提示中的细节。然而，这些自发的努力由于缺乏特定的合规指导和培训而效果有限。
### Innovation
研究揭示了当前自然语言处理工具与专家实际合规需求之间的显著差距。研究提出了将这些有价值的实证发现作为下一代以人为本、合规驱动的自然语言处理技术（RegTech）的基础工作，旨在为工程设计提供一个关键的人本中心视角和设计要求，以支持专家的合规工作流程。
### Conclusion
研究表明，当前的NLP工具和实际的合规需求之间存在显著差距。为了更好地支持专家的合规工作流程，有必要开发下一代的人本中心、合规驱动的NLP技术，确保在使用大语言模型时的安全与合规性。研究提供了重要的实证证据，有助于今后在RegTech领域的设计和发展中完善相应的工程要求。
## 133. `cs.AI` - 解析大型语言模型预训练中的合成数据：扩展规律、益处与陷阱的系统研究 [PDF](https://arxiv.org/pdf/2510.01631), [HTML](https://arxiv.org/abs/2510.01631)
### Authors
Feiyang Kang,Newsha Ardalani,Michael Kuchnik,Youssef Emad,Mostafa Elhoushi,Shubhabrata Sengupta,Shang-Wen Li,Ramya Raghavendra,Ruoxi Jia,Carole-Jean Wu
### Background
大型语言模型的训练数据对其扩展至关重要，但高质量数据的供应有限。合成数据技术为绕过这些限制提供了一种潜在的方法。研究通过大规模实验（超过1000个大型语言模型，超过100,000个GPU小时）统一了协议和扩展规律，对比了自然互联网数据、多样化的人工合成数据（重述文本、生成教科书）及其混合数据。实验发现，单独使用重述合成数据进行预训练并不比使用自然互联网文本快；但在较大的数据预算下，结合使用1/3重述合成数据和2/3自然互联网文本，可提高5-10倍的速度（以相同的验证损失为准）。单独使用教科书风格的合成数据进行预训练，在许多下游领域，尤其是在较小的数据预算下，导致显著较高的损失。合成数据在训练数据混合中的“良好”比例取决于模型大小和数据预算，实验结果表明对于重述合成数据，这种比例在约30%时收敛。
### Innovation
本研究通过大规模实验对比了自然数据和合成数据在大型语言模型预训练中的效果。借助统一的实验协议和扩展规律，评估了不同类型的合成数据（如重述文本、生成教科书等）以及它们在混合数据中的比例对预训练效果的影响，揭示了合成数据在预训练中的扩展规律和潜在的陷阱。研究还发现，大型生成模型并不一定总是优于约8B参数的模型，这取决于数据预算。实验结果提供的混合证据显示，大规模单轮训练中使用合成数据并不存在性能退化问题，但纯生成的教科书风格数据可能导致“模型崩溃”现象。
### Conclusion
本研究揭示了合成数据在预训练中的真实效果，证实了其条件性益处，并提供了实用的指导。结果表明，对于重述合成数据的混合比例，通常约为30%是最优的，并非更大规模的生成模型总会更好。合成数据混合策略和比例会根据模型大小和数据预算有所变化。总之，合成数据在大型语言模型预训练中既是机遇又是挑战，研究者的实际实施需考虑模型的具体情况和预算限制。
## 134. `cs.AI` - 使用BERT进行检测新型大语言模型 jailbreak 和关键词分析 [PDF](https://arxiv.org/pdf/2510.01644), [HTML](https://arxiv.org/abs/2510.01644)
### Authors
John Hawkins,Aditya Pramar,Rodney Beard,Rohitash Chandra
### Background
大型语言模型（LLMs）存在一系列漏洞，恶意用户可以通过操控输入文本促使模型产生不符合开发者政策的回应。这种被称为 jailbreak 的提示旨在欺骗模型绕过内置的安全限制。已有研究分析了不同机器学习模型区分 jailbreak 提示和正常使用的能力，特别关注模型能否识别以前未见过的策略。
### Innovation
使用当前数据集，通过全程微调 Bidirectional Encoder Representations from Transformers (BERT) 模型来识别 jailbreak 的最佳性能。可视化区分 jailbreak 和正常提示的关键词，提出在提示结构中明确的反思性可能是 jailbreak 目的比赛的一个信号。
### Conclusion
研究表明，使用 BERT 模型进行 jailbreak 识别是最优选择。通过 BERT 模型识别出的关键词显示，提示结构中明确的反思性可能是识别 jailbreak 的有效标志。
## 135. `cs.AI` - BioBlobs: 使用可微分图划分进行蛋白质表示学习 [PDF](https://arxiv.org/pdf/2510.01632), [HTML](https://arxiv.org/abs/2510.01632)
### Authors
Xin Wang,Carlos Oliver
### Background
蛋白质的功能由规模和拓扑结构不同的协同亚结构驱动。目前的蛋白质表示学习模型（PRL）通常依赖于如k-hop和固定半径邻域等刚性亚结构，这会扭曲这些信号。现有的方法未能充分捕捉蛋白质的动态亚结构特性，限制了对蛋白质功能的准确预测和理解。因此，迫切需要一种能够更好地表示蛋白质亚结构的模型来提升蛋白质表示学习的效果和对蛋白质功能机制的理解。
### Innovation
本文引入了BioBlobs，这是一种即插即用、完全可微分的模块，能够通过动态分区将蛋白质结构分成大小灵活的、不重叠的亚结构（“blobs”）。这导致了可量化的、共享且可解释的代码簿，生成了与蛋白质功能相关的关键亚结构的离散词汇表，以计算蛋白质嵌入。这种方法表明，BioBlobs表示形式可以显著提升广泛使用的蛋白质编码器GVP-GNN在各种PRL任务中的性能。
### Conclusion
BioBlobs模型通过直接捕获与功能相关的蛋白质亚结构，提升了预测性能并提供了对蛋白质功能机制的机械洞察。
## 136. `cs.AI` - 源域无标签的跨域连续学习 [PDF](https://arxiv.org/pdf/2510.01649), [HTML](https://arxiv.org/abs/2510.01649)
### Authors
Muhammad Tanzil Furqon,Mahardhika Pratama,Igor Škrjanc,Lin Liu,Habibullah Habibullah,Kutluyil Dogancay
### Background
现有跨域连续学习方法虽然能够有效应对具有领域偏移的流式任务，但需要完全标签化的源域数据，这在隐私受限环境中限制了其实用性。本文提出了一个完全不依赖源域样本的跨域连续学习问题，即源域无标签的跨域连续学习。在此背景下，提出了一种无需回顾的频率感知动态提示协作（REFEREE）方法，以应对跨域连续学习中缺少标记源域样本的问题。该方法结合了预训练模型和大规模的视觉-语言模型，解决了仅依赖预训练模型时的次优泛化问题。
### Innovation
该研究提出了一种无需回顾的频率感知动态提示协作（REFEREE）方法。该方法结合了预训练模型和大规模的视觉-语言模型，通过频率感知提示技术处理领域的偏移，该技术鼓励低频成分并抑制高频成分。同时，通过不确定性感知加权策略进一步解决伪标签噪声问题，通过内核线性判别分析（KLDA）避免灾难性遗忘问题。
### Conclusion
通过严格的数值研究，证实了该方法在无需访问源域样本的情况下，相对于有源域样本的先前方法有显著优势。
## 137. `cs.AI` - SoK: 评估闭环安全代理需要衡量什么 [PDF](https://arxiv.org/pdf/2510.01654), [HTML](https://arxiv.org/abs/2510.01654)
### Authors
Mudita Khurana,Raunak Jain
### Background
网络安全是一个持续升级的军备竞赛，AI驱动的攻击系统演化速度远超传统防御系统的适应速度。防御工具和技术仍然分散在各个孤立的安全功能中，形成盲点，而这些盲点正是攻击者利用的漏洞。自主代理能够在侦察、利用、根本原因分析、补丁合成和验证等一系列闭环中整合这些功能，如果能够高效整合这些过程，则有潜力提升安全防御能力。然而，该领域缺乏三个关键要素：一种界定安全生命周期中系统自主能力的框架，一种评估闭环自主代理的方法论，以及一个用于衡量其实用性的基准测试。
### Innovation
该研究介绍了CLASP：闭环自主安全绩效框架，该框架将安全生命周期与自主代理的核心能力对齐，提供了一个共同词汇和评估标准，用于衡量安全任务中的自主能力。通过应用CLASP到21个代表性作品，研究划分了系统的强项和能力缺口所在。随后提出了闭环能力（CLC）评分，这是一种综合评分，量化闭环的效力和执行力。研究还概述了闭环基准测试的要求。
### Conclusion
CLASP和CLC分数提供了一个共同的词汇、诊断工具和测量方法，能够提升安全任务的性能和衡量闭环安全代理的能力水平。
## 138. `cs.AI` - 无限制前沿：使用免代理ADMM推动LLM稀疏性极限 [PDF](https://arxiv.org/pdf/2510.01650), [HTML](https://arxiv.org/abs/2510.01650)
### Authors
Kwanhee Lee,Hyeondo Jang,Dongyeop Lee,Dan Alistarh,Namhoon Lee
### Background
神经网络剪枝是一种有望缓解大型语言模型(LLMs)计算和内存需求过高的技术。然而，由于传统方法似乎无法在不严重降低模型精度的情况下超越50-60%的适度稀疏性水平，剪枝领域的发展已经停滞。现有实践中的几个局限性都可以追溯到它们对代理目标形式化的依赖。这些局限性限制了现有方法实现更高稀疏性的能力，尤其在极端稀疏性水平(如90%)下。
### Innovation
本文提出了名为$texttt{Elsa}$的原理化和有效方法，直接有效解决了上述问题，采用基于ADMM的标准和成熟约束优化技术。实验证明，$texttt{Elsa}$在多种模型和规模上实现了显著的改进，例如，在90%稀疏性下，$texttt{Elsa}$在LLaMA-2-7B上的困惑度比最佳现有方法低7.8倍。此外，还提出了$texttt{Elsa}_{text{-L}}$的量化变体，能够扩展到极其庞大的模型（27B），并建立了其理论收敛保证。这些结果展示了在扩大LLM稀疏性的前沿方面取得了有意义的进步，并暗示存在进一步发展的潜力。
### Conclusion
本文突破了当前的瓶颈，通过$texttt{Elsa}$实现了极致的90%稀疏性，同时保持了高模型保真度，还展示了$texttt{Elsa}_{text{-L}}$在大模型上的扩展性和理论保证，明确展示了在推动LLM稀疏性的极限上取得了进展，并指出了进一步探索的方向。
## 139. `cs.AI` - 学习具有层次化均匀容忍隐空间平衡的时间序列表示 [PDF](https://arxiv.org/pdf/2510.01658), [HTML](https://arxiv.org/abs/2510.01658)
### Authors
Amin Jalali,Milad Soltany,Michael Greenspan,Ali Etemad
### Background
该研究背景在于现有的时间序列表示方法可能未能有效地在特征表示的一致性和鲁棒性之间取得平衡。因此，研究者提出了一种新的方法——TimeHUT，用于学习时间序列的表示，通过层次化的均匀性和容忍度的对比代表来实现这一目标。
### Innovation
该研究的创新点在于提出了一种新的时间序列表示方法——TimeHUT，该方法通过层次化的对比损失来平衡特征表示的一致性和鲁棒性。具体来说，TimeHUT引入了两个不同的损失函数，利用层次化的设置来学习时序数据的实例和时间信息，并通过温度调度机制来调整传统对比损失中的均匀性和容忍度特性。此外，还引入了层次化的角度 Margin 损失来进一步增强正副序列之间的对比度，提高时间序列样本中时间依赖性的捕获能力。
### Conclusion
研究在多种任务上测试了该方法，包括128个UCR和30个UAE的单变量和多变量分类任务，以及Yahoo和KPI异常检测任务。结果表明，TimeHUT在分类任务中显著优于先前的方法，在异常检测任务中也取得了具有竞争力的结果。通过对不同组件和超参数进行详尽的敏感性和消融研究，验证了该方法的有效性。
## 140. `cs.AI` - MDSEval：多模态对话总结的元评价基准 [PDF](https://arxiv.org/pdf/2510.01659), [HTML](https://arxiv.org/abs/2510.01659)
### Authors
Yinhong Liu,Jianfeng He,Hang Su,Ruixue Lian,Yi Nian,Jake Vincent,Srikanth Vishnubhotla,Robinson Piramuthu,Saab Mansour
### Background
多模态对话总结(MDS)是一个具有广泛应用场景的关键任务。为了促进有效MDS模型的发展，建立可靠的自动评价方法对于减少成本和人工努力是必不可少的。然而，这种方法需要一个基于人类标注的强元评价基准。本研究引入了MDSEval，这是一个基于人类标注的首批MDS元评价基准，涵盖八大明确的质量方面，包括图像共享对话及其相应的摘要和人类判断。为了确保数据质量和丰富性，提出了一种利用多模态独占关键信息(MEKI)的新颖过滤框架。该工作首次识别并正式化了特定于MDS的关键评价维度，并对比了现有方法揭示它们在区分摘要和高级MLLM方面的局限性及对各种偏见的敏感性。
### Innovation
MDSEval是首个用于MDS的元评价基准，它基于人类标注，涵盖了八种明确的质量方面。提出的过滤框架利用了跨模态的独占关键信息来确保数据质量和丰富性。这是首次识别并正式化了专属于MDS的关键评价维度，并对比了现有方法揭示了它们在区分高级MLLM和各种偏见方面的局限性。
### Conclusion
MDSEval首次对最先进的模态评价方法进行了基准测试，揭示了它们在区分摘要和高级MLLMs方面的局限性，并且容易受到各种偏差的影响。
## 141. `cs.AI` - 省视图，深入思考：基于反馈引导的自适应像素空间推理 [PDF](https://arxiv.org/pdf/2510.01681), [HTML](https://arxiv.org/abs/2510.01681)
### Authors
Xuchen Li,Xuzhao Li,Jiahui Gao,Renjie Pi,Shiyu Hu,Wentao Zhang
### Background
视觉-语言模型（VLMs）在多模态任务中表现出色，然而它们经常难以处理需要精细视觉元素精确理解的任务。这主要是因为在图像编码过程中信息丢失或对关键区域的关注不足。近期研究通过将像素级视觉信息引入推理过程，使VLMs可以在思考过程中访问到高分辨率的视觉细节，但这种像素级信息的过度使用导致了低效性和对无关视觉细节的干扰。
### Innovation
本文提出了一种基于自适应像素推理的框架，该框架可以根据输入查询动态确定必要的像素级操作。首先，通过带有操作感知的监督微调建立文本推理和视觉操作的基本能力，然后设计了一个基于模型自身响应反馈的策略引导的强化学习框架，使VLM能够在根据查询难度决定何时调用像素操作。
### Conclusion
实验表明，该模型在减少不必要的视觉操作的同时实现了更好的性能。与之前的方法相比，该模型在4K HR-Bench数据集上达到了73.4%的准确率，同时工具使用比率为20.1%，提高了准确率并减少了66.5%的工具使用。
## 142. `cs.AI` - 基于Shapley值的Kolmogorov-Arnold网络不变属性评分 [PDF](https://arxiv.org/pdf/2510.01663), [HTML](https://arxiv.org/abs/2510.01663)
### Authors
Wangxuan Fan,Ching Wang,Siqi Li,Nan Liu
### Background
在许多实际应用中，理解特征与结果之间的关系与实现高预测准确度同样重要。传统神经网络尽管在预测方面表现出色，但它们的黑盒性质使得难以了解到底层的函数关系。Kolmogorov--Arnold Networks (KANs)通过在边上线性可学习的样条激活函数来解决这个问题，不仅可以恢复符号表示，还能保持竞争力。然而，KAN的架构为网络剪枝带来了独特的挑战，传统的基于幅度的方法由于对输入坐标转换的敏感性变得不可靠。
### Innovation
我们提出了ShapKAN，一种基于Shapley值贡献的剪枝框架，用于以不变的方式评估节点的重要性。与基于幅度的方法不同，ShapKAN量化了每个节点的实际贡献，确保无论输入参数化如何，重要性排名始终一致。在合成和真实世界数据集上的广泛实验表明，ShapKAN能够在保持真实节点重要性的基础上实现有效的网络压缩。我们方法提高了KAN的可解释性优势，便于在资源受限的环境中部署。
### Conclusion
ShapKAN能够确保在各种输入参数化方式下节点的重要性评估一致，从而保持KAN在压缩后仍然具有高解释性，有效应用于资源受限环境。
## 143. `cs.AI` - 异构近端策略优化：小型评论家提升大模型推理 [PDF](https://arxiv.org/pdf/2510.01656), [HTML](https://arxiv.org/abs/2510.01656)
### Authors
Jiashun Liu,Johan Obando-Ceron,Han Lu,Yancheng He,Weixun Wang,Wenbo Su,Bo Zheng,Pablo Samuel Castro,Aaron Courville,Ling Pan
### Background
最近的研究中，大多数RL for LLM的方法避免了显式的评论家，转而使用平均优势基线。这样的转变主要是出于实用性的考虑：传统的价值函数在大规模LLM场景下的训练成本高昂，并且在稀疏奖励和长期推理时间下效果不佳。本文对此瓶颈从架构层面进行了重新审视，并提出了一种名为Asymmetric Proximal Policy Optimization (AsyPPO)的简单且可扩展的框架，该框架重新引入了评论家的角色，同时保持在大规模模型中的效率。AsyPPO利用了一组轻量级的迷你评论家，每个迷你评论家独立训练在不同的提示片段上。这种设计鼓励多样性同时保持校准，减少了价值估算偏差。此外，AsyPPO还利用了评论家之间的不确定来优化策略更新，包括掩蔽评论家一致且梯度贡献不大状态的优势，以及过滤高分歧状态来抑制不必要的探索。
### Innovation
提出了Asymmetric Proximal Policy Optimization (AsyPPO)，这是一种轻量级且可扩展的框架，利用一组独立训练的小型迷你评论家，以减少价值估计偏差并提高策略更新的效率。AsyPPO通过掩蔽一致性评论家的状态优势，过滤高分歧状态来抑制不必要的探索，从而在不使用额外技巧的情况下，在少量样本的基础上，极大地提高了学习稳定性和性能。
### Conclusion
在只使用5000个样本的开源数据集上，AsyPPO在多个基准测试中持续优于诸如GRPO等强大基线，对Qwen3-4b-Base的性能提升了超过6%，对Qwen3-8b-Base和Qwen3-14b-Base的性能提升了约3%，超越了传统PPO算法。研究结果强调了架构创新对于构建高效且可扩展算法的重要性。
## 144. `cs.AI` - Format Inertia: A Failure Mechanism of LLMs in Medical Pre-Consultation [PDF](https://arxiv.org/pdf/2510.01688), [HTML](https://arxiv.org/abs/2510.01688)
### Authors
Seungseop Lim,Gibaeg Kim,Wooseok Han,Jean Seo,Hyunkyung Lee,Jaehyo Yoo,Eunho Yang
### Background
大型语言模型（LLMs）在多个服务领域取得了显著进步，如聊天机器人和医疗预咨询应用。在医疗领域，适配LLMs进行多轮对话生成的主要方法是监督微调（SFT）。然而，医疗预咨询任务中的SFT数据通常具有偏斜的对话轮数分布，导致在长医疗对话中生成重复且格式正确但缺乏诊断信息的问题，我们称之为‘格式惯性’（Format Inertia）。
### Innovation
本文提出了一种简单且数据导向的方法，通过重新平衡训练数据集的对话轮数分布来缓解格式惯性问题。实验结果显示，该方法显著减轻了医疗预咨询中的格式惯性问题。
### Conclusion
通过重新平衡训练数据集的对话轮数分布，可以有效缓解大型语言模型在医疗预咨询中的‘格式惯性’问题。
## 145. `cs.AI` - How Do Language Models Compose Functions？ [PDF](https://arxiv.org/pdf/2510.01685), [HTML](https://arxiv.org/abs/2510.01685)
### Authors
Apoorv Khandelwal,Ellie Pavlick
### Background
尽管大型语言模型在解决组合任务方面展现出越来越强的能力，但目前尚不清楚它们是否通过这些机制来执行组合计算。这项研究探讨了前馈类语言模型解决两步事实回忆任务的方式，这类任务可以表示为 $g(f(x))$ 的组合形式。首先确认现代语言模型依然存在‘组合性缺口’，也就是说，即便它们能够计算 $z = f(x)$ 和 $y = g(z)$，也不意味着它们能够计算 $y = g(f(x))$ 的组合形式。通过分析语言模型剩余流激活的数据，研究发现两种处理机制：一种是通过计算 $f(x)$ 再计算 $g(f(x))$ 的组合方式，另一种是直接解决问题而无明显的中间变量 $f(x)$ 的痕迹。
### Innovation
通过分析语言模型的剩余流激活数据，识别了两种处理机制：一种通过计算 $f(x)$ 再计算 $g(f(x))$ 的组合方式，另一种是直接解决问题而无明显的中间变量 $f(x)$ 的痕迹，并发现这些处理机制与嵌入空间几何有关，其中以符合语言习惯的方式为主导，当存在从 $x$ 到 $g(f(x))$ 的线性映射时。
### Conclusion
使用的处理机制似乎与嵌入空间的几何结构有关。具体而言，在嵌入空间存在从 $x$ 到 $g(f(x))$ 的线性映射时，符合语言习惯的机制更为常见。研究完全开放了数据和代码。
## 146. `cs.AI` - FOR-Prompting: 从反对到修订的不对称提示协议 [PDF](https://arxiv.org/pdf/2510.01674), [HTML](https://arxiv.org/abs/2510.01674)
### Authors
He Zhang,Anzhou Zhang,Jian Dai
### Background
现有的推理协议，如Chain of Thought (CoT)和Tree of Thought (ToT)，能够组织内部的审议过程，但在外部质疑方面缺乏明确机制，以唤起自我修正。对于GSME8K任务，在单一提示下没有显示出显著的提高，而且与CoT相比，在推理和连贯性评分方面也没有明显优势。尽管如此，现有的方法往往依赖于外部工具或人类监督来纠正错误和改进小型模型的表现。因此，为了开发一种改进模型内部自修正能力的方法，研究者提出了FOR-Prompting（From Objection to Revision）协议，旨在提供一种不对称的交互方式来构建修正过程。
### Innovation
FOR-Prompting引入了一种不对称的提示协议，该协议中Defender提出答案，Objectioner提出问题式的反对意见而不提供直接修正，Host负责保持一致性并结束讨论。这种方法帮助模型在没有外部工具或人类监督的情况下进行自我修正，提升了模型的准确性和连贯性。在GSME8K数据集上，FOR-Prompting在推理和连贯性评分上优于单一提示，更准确地纠正了模型的错误。此外，它对小型模型表现有显著改善，提高了这些模型的性能。这表明FOR-Prompting协议对于解决小模型如何进行有效的内部修正具有潜在价值，能够在个人设备上使用。而且，这一协议可以适用于不同大小的模型和地区，无需重新训练，从而支持大规模的反对指导的推理研究。
### Conclusion
FOR-Prompting在GSME8K任务上展现了显著的性能提升，相比单一提示提升了约22%的分数，并且与CoT在准确度上相当，但在推理连贯性上有所提高。该方法能够独立于外部工具和人类干预进行自我修正，尤其适用于小型模型的性能提升。除了事实问答之外，还展示了从开放问题的角度进行探索和精炼能力的增强，进一步证明了此协议对于各种任务的有效性。此外，FOR-Prompting还具有跨模型和不同设备使用的灵活性，为模型内部修正提供了一个通用框架。
## 147. `cs.AI` - 自然场景中的整体顺序预测 [PDF](https://arxiv.org/pdf/2510.01704), [HTML](https://arxiv.org/abs/2510.01704)
### Authors
Pierre Musacchio,Hyunmin Lee,Jaesik Park
### Background
即便在控制良好的环境中，理解图像中的实例几何关系也是一个对多种视觉模型都很具有挑战性的问题。尽管有专门的系统存在，但现代艺术通常依赖昂贵的输入格式（如类别标签、二元分割掩码）和推理成本（如大规模的前向传播次数），这限制了其广泛应用。
### Innovation
本文提出了一种名为InstaFormer的网络，它可以基于输入的RGB图像，一次性预测场景中所有实例的遮挡关系和深度顺序。InstaFormer的核心在于物体查询与潜在掩码描述子之间的交互，这些潜在掩码描述子在语义上代表相同的物体，同时携带互补信息。
### Conclusion
通过全面的基准测试和消融研究，展示了方法的有效性。该代码和模型已经开源，并可以通过这个链接访问：this https URL.
## 148. `cs.AI` - 基于互信息引导的情感-音色解耦的情感文本转语音 [PDF](https://arxiv.org/pdf/2510.01722), [HTML](https://arxiv.org/abs/2510.01722)
### Authors
Jianing Yang,Sheng Li,Takahiro Shinozaki,Yuki Saito,Hiroshi Saruwatari
### Background
当前的情感文本转语音（TTS）和风格迁移方法依赖于参考编码器来控制全局情感或风格向量，但无法捕捉参考语音中的细微音质细节。
### Innovation
提出了一个新颖的情感TTS方法，使能够进行细粒度的音素级情感嵌入预测，同时分离参考语音的固有属性。该方法采用风格解耦方法来指导两个特征提取器，减少音质和情感特征之间的互信息，有效分离参考语音中的不同风格成分。实验结果显示，该方法在生成自然且情感丰富的语音方面优于基线TTS系统。
### Conclusion
此工作强调解耦和细粒度表示在推进情感TTS系统质量和灵活性方面的潜力。
## 149. `cs.AI` - PyramidStyler: 基于分层位置编码和强化学习的变压器驱动神经风格迁移 [PDF](https://arxiv.org/pdf/2510.01715), [HTML](https://arxiv.org/abs/2510.01715)
### Authors
Raahul Krishna Durairaju(1),K. Saruladha(2) ((1) California State University, Fullerton, (2) Puducherry Technological University)
### Background
神经风格迁移（NST）起源于Gatys等人的CNN算法，其能够通过AI实现艺术图像合成。然而，现有的基于CNN和基于Transformer的模型在扩展处理复杂风格和高分辨率输入时效率较低。
### Innovation
我们提出了PyramidStyler，一种带有分层位置编码（PPE）的Transformer框架。PPE可以捕捉局部细节和全局上下文，并减少计算负担。此外，引入了强化学习来动态优化风格化效果，加速收敛。PyramidStyler在Microsoft COCO和WikiArt上进行了训练，内容损失减少了62.6%（至2.07），风格损失减少了57.4%（至0.86），在4000个时期后实现了1.39秒的推理速度。使用RL时，进一步改进了风格化效果（内容2.03；风格0.75），同时仅付出轻微的速度代价（1.40秒）。
### Conclusion
这些结果表明，实时高质量的的艺术渲染是可能的，并适用于媒体和设计领域。
## 150. `cs.AI` - UAV网络中面向延迟的多模态联邦学习 [PDF](https://arxiv.org/pdf/2510.01717), [HTML](https://arxiv.org/abs/2510.01717)
### Authors
Shaba Shaon,Dinh C. Nguyen
### Background
本文研究了无人机(UAV)辅助的联邦多模态学习(FML)，重点在于最小化系统延迟并进行收敛性分析。在这种框架下，无人机分布在网络中以收集数据、参与模型训练，并与基站合作构建全局模型。通过利用多模态传感，无人机克服了一维系统限制，提升了模型的准确性和泛化能力，提供了更全面的环境理解。主要目标是通过联合解决无人机传感调度、功率控制、轨迹规划、资源分配和基站资源管理来优化UAV网络中的FML系统延迟。
### Innovation
为了应对我们延迟最小化问题的计算复杂性，本文提出了一个高效的迭代优化算法，结合了块坐标下降和连续凸逼近技术，提供了高质量的近似解。此外，本文还对非凸损失函数下无人机辅助FML框架进行了理论收敛性分析。数值实验表明，本文提出的FML框架在不同的数据设置下，系统延迟和模型训练性能优于现有方法。
### Conclusion
本文提出了一种最小化UAV网络中FML系统延迟的框架，通过理论分析和数值实验验证了其有效性和性能优势。
## 151. `cs.AI` - PolySim: 通过多仿真器动力学随机化缩小类真实差距的人形控制 [PDF](https://arxiv.org/pdf/2510.01708), [HTML](https://arxiv.org/abs/2510.01708)
### Authors
Zixing Lei,Zibo Zhou,Sheng Yin,Yueru Chen,Qingyao Xu,Weixin Li,Yunhong Wang,Bowei Tang,Wei Jing,Siheng Chen
### Background
人形全身体态控制（WBC）策略在模拟环境中训练时常受到模拟真实差距的影响，这种差距根本上源于模拟器的归纳偏差，即单一仿真工具内的假设和固有限制。这些偏差导致了模拟内部和真实世界之间的动力学显著差异。为了减少模拟器归纳偏差的影响，关键思想是同时在多个仿真器中联合训练策略，促使学习出控制策略可以捕捉超越任何单一仿真器假设的动力学。因此，作者引入了PolySim，这是一种结合了多个异构仿真器的WBC训练平台。PolySim可以在单次训练运行中同时启动来自不同引擎的不同仿真环境，从而实现动力学层级域随机化。
### Innovation
PolySim是一个通过多仿真器动力学随机化来缩小模拟与真实之间差距的训练平台。它能够在一个训练过程中同时启动多个不同的仿真环境，实现了动力学层级的域随机化。理论上，作者证明了PolySim相比单一仿真器训练具有更紧的仿真归纳偏差的上限。在实验中，PolySim显著减少了模拟到模拟评估中的运动追踪误差，例如在MuJoCo上，它相比于IsaacSim基准提高了52.8%的执行成功率。此外，PolySim还实现了在没有额外微调的情况下零样本部署到真实Unitree G1，证明了从仿真到真实的有效转移能力。
### Conclusion
PolySim平台通过结合多仿真器实现了动力学层级的域随机化，解决了人形控制中的模拟真实差距问题。实验结果表明该平台能够显著提高执行成功率，并且可以实现无额外微调的零样本部署到仿真外设备。最终，作者承诺将在论文被接受后发布PolySim的源代码。
## 152. `cs.AI` - 基于人类干预的预见性偏好学习 [PDF](https://arxiv.org/pdf/2510.01545), [HTML](https://arxiv.org/abs/2510.01545)
### Authors
Haoyuan Cai,Zhenghao Peng,Bolei Zhou
### Background
现有的互动模仿学习方法主要关注当前状态下的代理行动纠正，但未能在未来的状态中调整其行动，这可能更具危险性。文章旨在引入一种方法，利用人类干预中的隐含偏好信号预测未来的模拟结果，旨在通过纠正行为错误来增强学习效率。
### Innovation
提出了基于人类干预的预见性偏好学习(PPL)，通过在一种假设下将每个亲人类干预行为扩展到未来L个时间步长的偏好时间窗口，然后在这些未来状态上应用偏好优化，将专家的纠正建议传播到代理预期探索的安全关键区域，从而减少所需的专家演示次数并提高学习效率。
### Conclusion
通过实验验证，该方法在自动驾驶和机器人操作基准测试中展示了效率和通用性。理论分析进一步表明，选择适当的时间窗长度L在风险状态覆盖与标签准确性之间取得平衡，从而限制了算法最优性差距。
## 153. `cs.AI` - 在视觉任务中具有鲁棒性潜空间的无监督动态特征选择 [PDF](https://arxiv.org/pdf/2510.01758), [HTML](https://arxiv.org/abs/2510.01758)
### Authors
Bruno Corcuera,Carlos Eiras-Franco,Brais Cancela
### Background
潜在表示对于机器学习模型的性能和鲁棒性至关重要，因为潜在表示以紧凑且具有信息量的方式编码数据的核心特征。然而，在视觉任务中，这些表示经常受到嘈杂或不相关特征的影响，这会降低模型的性能和泛化能力。
### Innovation
本文提出了一种新的无监督动态特征选择(Dynamic Feature Selection, DFS)方法来增强潜在表示。通过这种方法，每个实例中的误导性或冗余信息被识别并移除，确保只有最相关的特征贡献到潜在空间。值得注意的是，该方法利用无监督框架，在不依赖标记数据的情况下进行，使其在各种领域和数据集上具有广泛的应用性。实验结果表明，配备了无监督DFS的模型在包括聚类和图像生成等多种任务上实现了显著的泛化性能改进，并且仅略有增加计算成本。
### Conclusion
实验结果证明，采用无监督DFS的模型在各类任务上表现出了显著的泛化性能提升，同时计算成本增加有限。
## 154. `cs.AI` - 打包并强化你的记忆：长视频和一致生成 [PDF](https://arxiv.org/pdf/2510.01784), [HTML](https://arxiv.org/abs/2510.01784)
### Authors
Xiaofei Wu,Guozhen Zhang,Zhiyong Xu,Yuan Zhou,Qinglin Lu,Xuming He
### Background
长视频生成面临双重挑战：模型必须捕捉长时间范围内的依赖关系，同时防止自回归解码固有的错误累积。现有方法通常难以平衡这两个目标。
### Innovation
本文提出MemoryPack和Direct Forcing两大创新点。MemoryPack是一种可学习的上下文检索机制，结合文本和图像信息作为全局指导，以共同建模短期和长期依赖性，实现分钟级的时间一致性。而Direct Forcing则提供一种高效的一步近似策略，改善了训练与推理的对齐，减少了推理过程中的错误传播。
### Conclusion
MemoryPack和Direct Forcing显著增强了长格式视频生成的上下文一致性与可靠性，推动了自回归视频模型的实际实用化。
## 155. `cs.AI` - 机器可解释的工程设计标准用于阀门规范 [PDF](https://arxiv.org/pdf/2510.01736), [HTML](https://arxiv.org/abs/2510.01736)
### Authors
Anders Gjerver,Rune Frostad,Vedrana Barisic,Melinda Hodkiewicz,Caitlin Woods,Mihaly Fekete,Arild Braathen Torjusen,Johan Wilhelm Kluwer
### Background
工程设计过程中使用技术规格并需符合标准。尽管有数字化工业工作的意图，产品规格、产品类型数据表和设计标准仍主要以文档为中心。本文展示了如何将工程设计标准中保存的信息转换为模块化、可重用、机器可解释的本体，并在设施设计和设备选择过程中利用这些本体进行质量保证。
### Innovation
我们使用建模模式创建了模块化本体，这些本体用于提炼英文和经常引用的表格中的知识，特别是在管道、材料和阀门设计的国际标准中。这些模块以W3C兼容格式存储，并与ISO DIS 23726-3: 工业数据本体（IDO）对齐。基于国际材料和管道标准及行业规范创建这些本体，对阀门选择过程进行了测试。还创建了“功能位置标签”，并将其实例化为 OWL 本体中的阀数据表（VDS）的具体阀实例以及制造商品牌产品类型实例。这种方法可以实现自动验证具体VDS是否符合相关行业标准，并使用语义推理和可执行设计规则验证产品类型是否符合阀门规范，创建基于IDO的共享和可重用模块化本体，应用于设备选择过程，并展示了标准机构向数字化智能标准过渡的潜力。
### Conclusion
基于IDO的模块化本体的创建允许对设备选择过程应用语义推理，展示了该方法对于标准机构向数字化智能标准过渡的潜力。
## 156. `cs.AI` - MCP驱动的联邦数字健康系统中安全多模态数据融合 [PDF](https://arxiv.org/pdf/2510.01780), [HTML](https://arxiv.org/abs/2510.01780)
### Authors
Aueaphum Aueawatthanaphisut
### Background
数字健康领域中的异构医学数据的安全且互操作的集成是一个重大的挑战。当前的联邦学习框架能够实现隐私保护的模型训练，但缺乏标准化的机制来在分布式且资源受限的环境中实现多模态数据的融合。
### Innovation
该研究提出了一种新的框架，利用Model Context Protocol (MCP)作为互操作性层，用于多模态联邦医疗保健系统中的安全、跨代理通信。该框架统一了三根支柱：多模态特征对齐；安全聚合以保护敏感更新；以及能源感知调度以减轻移动客户端的掉线。通过使用MCP作为驱动模式的接口，框架能够实现AI代理和工具链的适应性编排，并确保符合隐私规定。实验结果表明与基准联邦学习相比，提高了9.8%的诊断准确性，降低了54%的客户端掉线率，并实现了可接受的隐私-效用权衡。这些结果强调了MCP促进的多模态融合是一种可扩展且值得信赖的方式，旨在实现公平的下一代联邦健康基础设施
### Conclusion
研究表明，MCP能够实现多模态数据的安全融合，通过适应性编排AI代理和工具链，同时确保符合隐私法规。与现有的联邦学习框架相比，在临床数据集和试点临床群体中实验结果显示了显著的改进，表明这是一种可靠且具有前景的解决方案。
## 157. `cs.AI` - Hierarchical Optimal Transport在模型层间及脑区表征对齐中的应用 [PDF](https://arxiv.org/pdf/2510.01706), [HTML](https://arxiv.org/abs/2510.01706)
### Authors
Shaan Shah,Meenakshi Khosla
### Background
传统的表征相似性方法在对网络层进行匹配时，会分别将每一层与其在另一个网络中最相似的层进行配对，这导致结果具有方向性且缺乏全局对齐评分，难以处理不同深度的网络。这种局限性主要是由于忽视了全局激活结构且限制映射为严格的逐层一一对应关系。这些方法在比较不同深度的网络方面表现不佳，且难以捕捉到跨层的映射关系。为了解决这些问题，本文提出了一种新的方法——层次最优传输（HOT），该方法可以通过全局优化联合推断软性的、一致的神经元到神经元的耦合和传输计划，从而能更好地处理深度不对等的问题并提供一个全面的网络对齐评分。这种方法能够自然地处理深度差异，而不需要特别的处理步骤，并展现出从早期层到更深层的层级对应关系，避免了贪婪逐层方法带来的问题，使得不同架构或深度的网络间的比较更加丰富且可解释性强。
### Innovation
本文提出了一种新的方法——层次最优传输（HOT），它可以在全局优化框架下推断软性的、一致的神经元到神经元的耦合和传输计划。该方法解决了传统方法在处理网络深度差异以及提供全局对齐评分方面的不足，能够自然地处理深度差异并提供一个全面的网络对齐评分，同时揭示了从早期层到更深层的层级对应关系，增强了不同架构或深度网络的比较的丰富性和可解释性。这一方法优于传统的两两匹配方法，特别是在视觉模型、大型语言模型和人脑视觉皮层记录中得到了验证，展示了在多个领域中的广泛适用性和优越性。此外，HOT方法自然地避免了贪婪逐层方法带来的限制，使得不同架构或深度的网络之间的比较更加直观和富有信息量。
### Conclusion
本文提出了一种名为Hierarchical Optimal Transport（HOT）的新方法，该方法通过全局优化推断出软性的、一致的神经元到神经元的耦合和传输计划，能够在全网范围内提供单一的对齐评分并处理网络深度的差异。HOT在视觉模型、大型语言模型和人脑视觉皮层记录等领域中表现出色，相比传统的逐层匹配方法，HOT能够更全面和精细地揭示表征的层级对应关系，使得不同架构或深度的网络间比较更加丰富且具有解释性。这种方法为不同网络间的表征对齐和比较提供了一种新的思路和技术手段，对跨模态和多层次的表征理解具有重要的应用价值。
## 158. `cs.AI` - 比较法律判决提取的无监督指标 [PDF](https://arxiv.org/pdf/2510.01792), [HTML](https://arxiv.org/abs/2510.01792)
### Authors
Ivan Leonidovich Litvak,Anton Kostin,Fedor Lashkin,Tatiana Maksiyan,Sergey Lagutin
### Background
随着人工智能在法律自然语言处理中的迅速发展，需要能够处理大量文本数据的评估方法来衡量从法律判决中提取文本的质量。该研究评估了16种无监督度量标准，包括新型度量，以评估1000份匿名的俄罗斯法律判决中七种语义块的提取质量，这些判决经过了7168名专家在1到5的李克特量表上的验证。这些度量涵盖了文档级、语义、结构、伪真实度和法律特定类别，不依赖预注释的真实度量。通过二倍化相关性、林氏一致性相关系数（CCC）和绝对平均误差（MAE）来揭示这些度量的效果差异，结果表明某些指标与专家评分有更好的一致性。这些发现表明，无监督度量，包括基于语言模型的方法，能够进行规模化的筛选，但在高风险的法律环境中，这些工具还无法完全替代人类判断。这项研究推进了法律自然语言处理领域，为司法分析提供了无注释评估工具，并对伦理AI应用具有重要意义。
### Innovation
研究评估了16种新的无监督度量标准来评估法律判决提取的质量，这些度量涵盖了多种类型，如文档级、语义、结构、伪真实度和法律特定类别。研究引入了新的术语频率共现度量和覆盖比/块的完整性度量，并发现了它们与专家评分的高度一致性，这一发现有助于推进法律自然语言处理的发展，为司法分析提供了无注释评估工具，并对伦理AI应用具有重要意义。
### Conclusion
研究结果表明，无监督度量，包括基于语言模型的方法，能够在大规模文本处理时提供有效的筛选工具，但这些方法在高风险法律环境中仍无法完全替代人类判断。这项工作推进了法律自然语言处理领域，通过提供无注释的评价工具，对于司法分析和伦理AI部署具有重要影响。
## 159. `cs.AI` - LLMs能否拒绝它们不知道的问题？测量事实任务中的知识驱动拒绝 [PDF](https://arxiv.org/pdf/2510.01782), [HTML](https://arxiv.org/abs/2510.01782)
### Authors
Wenbo Pan,Jie Xu,Qiguang Chen,Junhao Dong,Libo Qin,Xinfeng Li,Haining Yu,Xiaohua Jia
### Background
当前的测评标准无法准确衡量大型语言模型（LLMs）在面对超出其知识范围的问题时拒绝回答的能力。现有的拒绝度量存在偏向性和一致性问题，而现有校准度量则依赖代理指标，而非直接反映模型的拒绝行为。
### Innovation
本文提出了一种原理性的指标——拒绝指数（RI），通过Spearman秩相关系数衡量拒绝概率与错误概率之间的关系来评估模型的知识驱动拒绝能力。此外，该研究设计了一种轻量级的两步评估方法来高效估计RI，并通过大量实验验证了RI的有效性和一致性，展示了其在事实任务中的内在知识驱动拒绝能力的衡量作用。
### Conclusion
RI能稳定衡量不同拒绝率下的模型拒绝能力，并提供独立于模型整体准确性和拒绝率的一致模型排名。研究发现，尽管LLMs在事实任务中表现出高度的准确性，但它们的拒绝行为是不可靠和脆弱的。因此，建议使用拒绝指数配合传统准确性指标来全面评估模型的客观性。
## 160. `cs.AI` - SingMOS-Pro:一个综合性的歌唱质量评估基准 [PDF](https://arxiv.org/pdf/2510.01812), [HTML](https://arxiv.org/abs/2510.01812)
### Authors
Yuxun Tang,Lan Liu,Wenhao Feng,Yiwen Zhao,Jionghao Han,Yifeng Yu,Jiatong Shi,Qin Jin
### Background
歌唱声音生成的发展迅速，但评估歌唱质量仍是一个关键挑战。现有方法，包括人力听觉评估和客观评价指标，都存在成本高、耗时或评估维度有限的问题。
### Innovation
我们引入了SingMOS-Pro数据集，该数据集扩展了原本仅提供整体评价的SingMOS数据集，增加了关于歌词、旋律和整体质量的注释，提供了更广泛的覆盖面和多样性。SingMOS-Pro数据集包含了41个模型从12个数据集中生成的7,981首歌唱片段，每个片段至少有5名专业注释者的评价，以确保可靠性和一致性。此外，还探索了不同标准下标注数据的有效利用，并对多种常用评估方法进行了基准测试，为未来研究提供了坚实的基础和实用参考。
### Conclusion
该数据集可以在此处访问：this https URL. 通过这些努力，我们为歌唱质量评估建立了全面的基准，为相关领域的未来研究提供了有力的支持和参考。
## 161. `cs.AI` - 在AutoML中预先预测：利用大语言模型提高表格数据模型选择和基准测试 [PDF](https://arxiv.org/pdf/2510.01842), [HTML](https://arxiv.org/abs/2510.01842)
### Authors
Yannis Belkhiter,Seshu Tirupathi,Giulio Zizzo,Sachin Sharma,John D. Kelleher
### Background
AutoML领域在事后模型选择方面取得了显著进步，具备自动识别最适合给定数据集模型的库。但是，这些方法往往依赖于详尽的超参数搜索，即自动训练并测试不同类型模型的数据集。相比之下，预先预测成为一种有前景的替代方案，能够通过智能的模型选择来规避详尽的搜索。尽管具有潜力，但预先预测在文献中仍较少被研究。
### Innovation
本文通过利用传统模型和大语言模型（LLM）代理来减少AutoML库的搜索空间，探索了AutoML和预先模型选择的交集。利用数据集描述和统计信息，本文方法显著减少了AutoML的工作负载，同时仍能选择最适合给定数据集的模型。
### Conclusion
本文提出的方法为AutoML工作流程带来了转变，显著降低了计算负担，同时仍然能够选择最适合给定数据集的最佳模型。
## 162. `cs.AI` - NGGAN: 基于实际测量数据集的窄带电力线通信噪声生成GAN [PDF](https://arxiv.org/pdf/2510.01850), [HTML](https://arxiv.org/abs/2510.01850)
### Authors
Ying-Ren Chien,Po-Heng Chou,You-Jie Peng,Chun-Yuan Huang,Hen-Wai Tsao,Yu Tsao
### Background
在窄带电力线通信(NB-PLC)设备中，捕捉非周期异步脉冲噪声的全面统计信息是提高脉冲噪声处理的关键问题。现有的数学噪声生成模型只能捕捉到部分噪声特性，未能充分模拟实际环境中噪声的复杂特性。
### Innovation
本文提出了一种生成对抗网络(NGGAN)，用于根据实际测量数据集生成噪声，以增强NB-PLC系统的复杂噪声统计匹配。通过具体改进手段，包括适应实际输入信号长度以生成周期非平稳噪声、使用Wasserstein距离提高生成噪声与训练数据集的相似性以及确保样本多样性，以优化GAN模型的性能。
### Conclusion
仿真实验结果表明，使用波形特性训练的NGGAN生成的噪声与实际测量数据集更为接近，从而证明了该模型的有效性。
## 163. `cs.AI` - 重新思考MLP的结构传统 [PDF](https://arxiv.org/pdf/2510.01796), [HTML](https://arxiv.org/abs/2510.01796)
### Authors
Meng-Hsi Chen,Yu-Ang Lee,Feng-Ting Liao,Da-shan Shiu
### Background
多层感知器（MLPs）通常采用窄-宽-窄的设计，其中跳连操作在输入/输出维度上进行，而处理则在扩展的隐藏空间中进行。本文通过对MLP基础设计的重新思考，提出了一种新的宽-窄-宽（Hourglass）结构，其中跳连操作在扩展维度上进行，而残差计算则通过狭窄的瓶颈进行。这种倒置设计通过高维空间的增量细化来提升计算效率，通过参数匹配设计保持高效性。
### Innovation
本文提议了一种新的Hourglass MLP结构，其中跳连操作在扩展维度上进行，残差计算通过狭窄的瓶颈进行。该设计利用了更高的维度空间进行逐步细化，同时保持了计算效率，这在参数匹配的设计中表现尤为明显。此外，该结构需要初始投影将输入信号提升到扩展维度，我们建议在整个训练过程中固定在随机初始化，以实现高效的训练和推理实现。
### Conclusion
实验表明，Hourglass架构在生成任务中，特别是在流行图像数据集上，相比传统的设计，能够一直获得更优越的Pareto前沿。随着参数预算的增加，最优的Hourglass配置倾向于更深的网络，具有更宽的跳连连接和更窄的瓶颈，这一扩展模式与传统的MLP不同。这项研究提示重新考虑现代架构中的跳连位置配置，并可能适用于其他模型，如Transformer和其它残差网络。
## 164. `cs.AI` - 多模态基础模型在早期疾病检测中的应用 [PDF](https://arxiv.org/pdf/2510.01899), [HTML](https://arxiv.org/abs/2510.01899)
### Authors
Md Talha Mohsin,Ismail Abdulrashid
### Background
医疗健康产生多样的数据流，包括电子健康记录（EHR）、医学影像、遗传学数据和穿戴设备持续监测的数据。传统的诊断模型通常将这些数据源孤立分析，这限制了它们发现跨模态关联的能力，而这些关联对于早期疾病诊断至关重要。
### Innovation
研究提出了一种基于注意力机制的变压器多模态基础模型，它通过专用编码器将不同模态的数据转换到共享的潜在空间中，然后使用多头注意力和残差归一化进行组合。此架构便于在多种任务上进行预训练，使得适应新疾病和数据集变得简单，无需额外工作。
### Conclusion
提出的模型旨在实现一种精确诊断的基础模型，旨在提高预测准确性，帮助医生作出决策。框架还包括数据治理和模型管理工具，以提升透明度、可靠性和临床解释性。
## 165. `cs.AI` - REPAIR：通过渐进适配干预和重新整合实现稳健编辑 [PDF](https://arxiv.org/pdf/2510.01879), [HTML](https://arxiv.org/abs/2510.01879)
### Authors
Yisu Wang,Ming Wang,Haoyuan Song,Wenjie Huang,Chaozheng Wang,Yi Xie,Xuming Ran
### Background
大型语言模型（LLMs）的后训练受限于获取新知识或纠正错误的高成本，以及大规模序列编辑中常见的稳定性问题和冲突。传统脱分布方法往往忽略了意外的连锁反应，导致知识遗忘。
### Innovation
提出了REPAIR（通过渐进适配干预和重新整合实现稳健编辑）框架，该框架采用闭环反馈机制和动态内存管理来缓解大规模序列编辑的不稳定性及冲突。通过频繁的知识融合和强邻域保护，REPAIR解决了传统脱分布方法的不足。
### Conclusion
实验表明，REPAIR提升了多种模型系列的编辑准确性达10%-30%，并显著减少了知识遗忘。这项工作引入了开发可靠、可扩展且持续进化的LLMs的稳健框架。
## 166. `cs.AI` - Nav-EE: 导航引导的早撤出方法以提高自动驾驶中视觉语言模型的效率 [PDF](https://arxiv.org/pdf/2510.01795), [HTML](https://arxiv.org/abs/2510.01795)
### Authors
Haibo Hu,Lianming Huang,Xinyu Wang,Yufei Cui,Nan Guan,Chun Jason Xue
### Background
视觉语言模型（VLMs）在自动驾驶中用于统一感知和推理，但由于推理延迟高，影响了实时部署。早期退出（Early-exit）技术通过在中间层终止推理来减轻延迟，但其任务相关内容的特点限制了其在不同场景下的普及。
### Innovation
提出了导航引导的早撤出框架（Nav-EE），该框架预先计算出特定任务的撤出层，结合导航先验信息在线动态应用，从而提高效率。实验表明，Nav-EE 在准确率与全推断相比不减的情况下，延迟减少了高达 63.9%，并在实际车辆中展示了更快的决策速度。
### Conclusion
将导航前瞻性与早期退出相结合，为大型模型在自动驾驶系统中的有效部署提供了可行路径。
## 167. `cs.AI` - 通过模型选择降低世界AI能耗：足够的小模型 [PDF](https://arxiv.org/pdf/2510.01889), [HTML](https://arxiv.org/abs/2510.01889)
### Authors
Tiago da Silva Barros,Frédéric Giroire,Ramon Aparicio-Pardo,Joanna Moulierac
### Background
近年来，人工智能（AI）的能源消耗和碳足迹已经成为重要的关切点，这主要是由于成本上升和环境影响。因此，环保AI的新趋势正在兴起，它摒弃了“越大越好”的范式，转而支持“适小则好”，强调通过更小、更高效的模型来实现能源节俭。研究团队探索了AI社区如何通过推理过程中的模型选择来实现这一目标，认为这一点简单且易于应用，不依赖于新的硬件或架构。研究发现，在许多工业活动中，随着模型规模的增加，边际效益递减。因此，采用模型选择不仅可以显著减少能源消耗，还可以在保持良好的AI推理效用方面表现出色。
### Innovation
研究集中在利用模型选择来降低能耗，并提供了系统性的研究结果，包括不同任务的流行性、模型大小及其效率分析。研究展示了根据不同任务的成熟度和模型采用模式，可能实现1%到98%的能源节约。研究估计，通过实施模型选择，可将AI能耗降低27.8%，从而在全球范围内节省31.9 TWh的电力，相当于5座核反应堆一年的发电量。这项研究提供了一种切实可行的方法来减少AI技术的环境足迹，并为AI的可持续发展做出了贡献。
### Conclusion
研究表明，通过采取适当的模型选择策略，AI 任务的能耗可以显著降低。这种方法简单易行，无需依赖复杂的新硬件或架构。随着不同任务和模型使用模式的成熟，可以实现显著的能源节约。
## 168. `cs.AI` - FINCH：使用自然语言处理进行财务语境化SQL处理的财务智能 [PDF](https://arxiv.org/pdf/2510.01887), [HTML](https://arxiv.org/abs/2510.01887)
### Authors
Avinash Kumar Singh,Bhaskarjit Sarmah,Stefano Pasquali
### Background
文本到SQL任务，即将自然语言问题转化为SQL查询，在NLP领域是一个长期存在的核心挑战。尽管取得了一定进展，但在金融领域的应用依然困难，原因在于复杂的数据库模式、特定领域的术语以及错误的高风险性。然而，缺乏专门的大型金融数据集，阻碍了该领域的研究进步，形成了巨大的缺口。
### Innovation
本文提出了一个精心策划的金融数据集（FINCH），包含292张表和75,725个自然语言-SQL配对，既适用于模型微调，也适用于严格评估。基于此资源，本研究对比了不同规模的推理模型和语言模型在金融文本到SQL任务中的表现，提供了一个系统性的分析，揭示了它们的优势与局限性。此外，文章还提出了一个旨在财务领域场景下更忠实评估模型性能的评价指标（FINCH评分）。
### Conclusion
本文通过创建金融数据集FINCH，填补了金融领域研究中的数据空白，为金融文本到SQL任务提供了新的基准测试和评估方法。这种新方法将有助于改善金融对话的理解和处理，促进技术进步。FINCH评分作为一种新的评价指标，能够更准确地衡量模型在复杂金融环境下的性能。
## 169. `cs.AI` - TACOS: Task Agnostic COordinator of a multi-drone System [PDF](https://arxiv.org/pdf/2510.01869), [HTML](https://arxiv.org/abs/2510.01869)
### Authors
Alessandro Nazzari,Roberto Rubinacci,Marco Lovera
### Background
当单个飞行员负责管理多旋翼无人机系统时，他们需要执行不同层次的自主性任务，从直接控制每个无人机，到执行小组级别的协调，再到完全自主的群落行为以完成高级任务。这种灵活性的交互要求支持多种共享自主性的框架。现有语言模型在推理和规划方面不断进步，为这种系统提供了自然的基础，通过直观的语言界面使飞行员能够代理执行高层次任务，从而减轻其工作负担。
### Innovation
本文提出了TACOS（任务无关的多旋翼无人机系统的协调器），这是一种统一的框架，通过大型语言模型（LLMs）使多旋翼无人机系统的高层次自然语言控制成为可能。TACOS整合了三种关键能力：1) 一种一到多的自然语言界面，实现直观的用户交互；2) 一个智能协调器，将用户意图转化为结构化的任务计划；3) 一个自主执行计划的代理，与现实世界互动。TACOS允许LLM与执行API库交互，实现语义推理与实时多机器人协调的结合。TACOS通过实验证明了其系统在实际多旋翼无人机系统中的有效性，并通过消融研究评估了每个模块的贡献。
### Conclusion
TACOS提供了一种灵活的多旋翼无人机系统控制框架，通过高级语言界面、智能计划转换和自主执行机制，实现了飞行员与多旋翼无人机系统之间的有效交互。这项工作为多旋翼无人机系统的远程管理和操作开辟了新的可能性，并提升了系统的自主性和易用性。
## 170. `cs.AI` - 基础视觉编码器实际上是少样本异常检测器 [PDF](https://arxiv.org/pdf/2510.01934), [HTML](https://arxiv.org/abs/2510.01934)
### Authors
Guangyao Zhai,Yue Zhou,Xinyan Deng,Lars Heckler,Nassir Navab,Benjamin Busam
### Background
少样本异常检测简化了工业安全检查流程。然而，样本有限使得准确区分正常和异常特征具有挑战性，尤其是在不依赖类别信息的情况下。大规模预训练的基础视觉编码器在许多领域取得了重大进展，因为大量数据有助于学习正常图像的一般分布。论文观察到图片中的异常量与学习到的嵌入差异成正比，基于此设计了一种少样本异常检测器命名为FoundAD。通过非线性投影操作将图片投影到自然图像流形，这种方法有效用于特征识别和异常检测。
### Innovation
提出了名为FoundAD的少样本异常检测器，通过学习非线性投影操作将图片投影到自然图像流形，该操作用于特征识别和异常检测。实验表明，这种方法支持多类检测并达到与之前方法相近的性能，但使用了更少的参数。通过使用多种基础编码器（包括新的DINOv3）进行评估，作者认为这一想法拓宽了对基础特征的看法并推进了少样本异常检测领域。
### Conclusion
该方法在使用更少参数的同时达到了与之前方法相当的性能，并通过多种基础编码器的评估展示了其有效性和泛化能力，为少样本异常检测领域开辟了新的视角和研究方向。
## 171. `cs.AI` - 一个针对自然和人工心智的模块化主观意识理论 [PDF](https://arxiv.org/pdf/2510.01864), [HTML](https://arxiv.org/abs/2510.01864)
### Authors
Michaël Gillon
### Background
理解主观体验如何从信息处理中产生仍然是神经科学、认知科学和人工智能研究中的一个核心挑战。模块化意识理论（MCT）提供了一个基于生物学、具有计算明确性的框架，其中意识被描述为一系列集成信息状态（IIS）的离散序列，每个IIS都与多维密度向量关联，以量化信息丰富度。这些密度值的大小与主观强度相关，影响记忆、行为和体验连续性。来自身体和环境的信息适应性地被过滤、处理并整合到IIS中，然后被标记并传输到行为准备、记忆和决策模块，形成闭环。这解释了强标记的状态为何对长期记忆和行动有更大的影响。不同于全局工作空间理论、集成信息理论或高位阶想法，MCT明确了产生可量化内部结构的离散信息单元的完整计算管道，并重新定义了主观性，突出了与密度标记信号的功能后果相关的联系。
### Innovation
MCT提供了一个详细且计算明确的框架，解释了主观意识的形成机制，明确了一个生物学和计算上的衔接点。它在一个统一的理论框架中集成了身体、环境输入的感知、加工和一体化过程，并提出了 Subjectivity 作为一种与密度标签信号相关的功能后果的新视角。MCT还生成了可测试的预测，例如压力增强记忆编码，并为生物和人工系统提供了自然蓝图。
### Conclusion
在MCT的观点中，意识并不是一种不可还原的本质，而是一种可进化、可度量和可通过复杂信息处理构建的特征。
## 172. `cs.AI` - HRTFformer: 基于空间感知的Transformer架构用于沉浸式音频渲染中的个性化HRTF上采样 [PDF](https://arxiv.org/pdf/2510.01891), [HTML](https://arxiv.org/abs/2510.01891)
### Authors
Xuyi Hu,Jian Li,Shaojie Zhang,Stefan Goetz,Lorenzo Picinali,Ozgur B. Akan,Aidan O. T. Hogg
### Background
个性化头相关传输函数（HRTFs）正在被引入许多商业沉浸式音频应用中，对于实现真实的方位音频渲染至关重要。然而，主要是由于HRTF测量过程中的复杂性，大型规模地创建个性化HRTFs被认为不切实际。为了解决这个问题，提出了HRTF空间上采样方法以减少所需的测量次数。尽管先前的工作已经看到了不同机器学习（ML）方法的成功，但这些模型在长距离空间一致性和平滑性方面通常存在问题，特别是在高上采样因子的情况下。因此，在HRTF上采样过程中，需要一种更强大的方法来更好地捕捉空间相关性并进行高分辨率重建，同时保持空间一致性，以生成高保真的个性化HRTFs。
### Innovation
本文提出了一种基于Transformer的新型架构HRTFformer，结合注意力机制来更好地捕捉HRTF球体内的空间相关性。通过在球谐（SH）域中工作，我们的模型能够从稀疏输入测量中学习高效重建高分辨率HRTFs，并且准确性得到了显著提高。为了增强空间连贯性，引入了邻居差异损失，这有助于保持幅度平滑性，从而生成更现实的上采样结果。我们的方法在感知定位模型和客观音谱失真度量中都进行了评估，实验结果表明，我们的模型在生成真实和高保真HRTFs方面超过了领先的方法，取得了显著的效果提升。
### Conclusion
我们提出了一种基于Transformer的HRTF上采样模型HRTFformer，通过在球谐域中的工作，利用注意力机制来优化空间相关性并提高恢复精度，同时通过邻居差异损失促进幅度平滑，生成更逼真的HRTFs。通过实验展示了该模型在生成高质量个性HRTFs方面的优势，并且在感知定位模型和客观音谱失真度量中表现优越。
## 173. `cs.AI` - 基于YOLO目标检测模型的大规模生产电子组件自动缺陷检测 [PDF](https://arxiv.org/pdf/2510.01914), [HTML](https://arxiv.org/abs/2510.01914)
### Authors
Wei-Lung Mao,Chun-Chi Wang,Po-Heng Chou,Yen-Ting Liu
### Background
传统工业组件的缺陷检测耗时且劳动密集，这对质量检验人员造成巨大负担，使管理产品质量变得困难。
### Innovation
提出了一种基于数字相机光学和深度学习（DL）模型的自动化缺陷检测系统，用于广泛应用于工业的双列直插式封装（DIP）。此外，通过使用ConSinGAN生成适合大小的数据集进行训练和测试，解决了缺乏缺陷组件图像的问题。研究了四种不同的YOLO模型（v3，v4，v7和v9），并与ConSinGAN增强技术相结合使用。提出的YOLOv7与ConSinGAN组合在准确性和检测时间上优于其他YOLO版本，并显著优于基于阈值的方法。还开发了SCADA系统，并描述了相关的传感器架构。
### Conclusion
提出的自动化缺陷检测可以容易地建立具有多种缺陷类型或不足的缺陷数据的情况。
## 174. `cs.AI` - LLMs更优的GNN助手中图？在缺陷下的迭代精炼重新思考稳健的图学习 [PDF](https://arxiv.org/pdf/2510.01910), [HTML](https://arxiv.org/abs/2510.01910)
### Authors
Zhaoyan Wang,Zheng Gao,Arogya Kharel,In-Young Ko
### Background
在网络相关的应用中，图形神经网络（GNNs）被广泛采用，用于从文本属性图形等图结构数据中学习。然而，在现实世界中，图数据存在缺陷，这些缺陷会显著削弱GNN的性能。尽管之前已有针对个体缺陷的GNN增强研究，但对于多个缺陷下的系统性理解仍不足。特别是在综合了图形本源和大型语言模型（LLMs）增强方法后，现有方法的增强效果并未得到全面比较和评估。因此，本文填补这一空白，针对各种图形缺陷进行首次实证研究，重新评估LLM增强方法在图形缺陷下的可靠性和优越性。
### Innovation
本文创新性地提出了Robust Graph Learning via Retrieval-Augmented Contrastive Refinement（RoGRAD）框架。与先前的一次性LLM增强设计不同，RoGRAD是首个利用检索增强生成（RAG）进行迭代增强的框架，通过提供一致类别的多样化增强并采用迭代的图形对比学习来强化判别性表示。RoGRAD成功将LLM在图形中的增强从静态信号注入转变为动态精炼过程。通过广泛的实验验证，RoGRAD在整体上优于传统的GNN和最新的LLM增强的基本方法，平均改善程度达到82.43%。
### Conclusion
本文通过首次实证研究揭示了现有方法在图形缺陷下的内在缺陷，挑战了LLM增强在所有情况下都更优的假设。RoGRAD框架在这方面取得了显著成果，证明了其在多种缺陷处理上的优越性能。
## 175. `cs.AI` - 探索混合Mamba-U-Net中的分辨率共享注意力以提高跨语料库语音增强性能 [PDF](https://arxiv.org/pdf/2510.01958), [HTML](https://arxiv.org/abs/2510.01958)
### Authors
Nikolai Lund Kühne,Jesper Jensen,Jan Østergaard,Zheng-Hua Tan
### Background
近期的研究表明，结合Mamba和注意力机制的模型在跨语料库泛化性能上表现出色。同时，将Mamba整合到U-Net结构中可以达到最先进的增强性能，同时还降低了模型规模和计算复杂度。
### Innovation
本文提出了RWSA-MambaUNet，这是一种结合了Mamba和多头注意力机制的新型高效混合模型，用于提高跨语料库表现在U-Net结构中。RWSA代表层间时频分辨率共享注意力。模型在两个不同语料库的测试集上达到了最先进的泛化性能。最小的模型在DNS 2020和EARS-WHAM_v2测试集的PESQ、SSNR、ESTOI和SI-SDR指标上超过了所有基线模型，同时参数量仅为其一半，运算量仅为部分。
### Conclusion
最佳性能的RWSA-MambaUNet模型在两个不同的测试集上达到了最佳的跨语料库泛化性能。最小的模型在两个测试集的PESQ、SSNR、ESTOI和SI-SDR方面都超过了所有基线模型，且参数量少于一半，运算量只占部分。
## 176. `cs.AI` - ZK-WAGON: 使用ZK-SNARKs的不可感知图像生成模型水印 [PDF](https://arxiv.org/pdf/2510.01967), [HTML](https://arxiv.org/abs/2510.01967)
### Authors
Aadarsh Anantha Ramakrishnan,Shubham Agarwal,Selvanayagam S,Kunwar Singh
### Background
随着图像生成模型越来越强大且易于获取，合成媒体的真实性和所有权问题变得至关重要。生成与真实图像难以区分的图像带来了信息误导、深度假视频和知识产权侵权的风险。传统水印方法会降低图像质量、容易移除，或者需要访问模型机密内部信息，因此不适合安全且可扩展的部署。
### Innovation
本文首次提出使用零知识简洁非交互知识证明（ZK-SNARKs）对图像生成模型进行水印的ZK-WAGON系统。该方法能够在不泄露模型权重、生成提示或任何敏感内部信息的情况下提供可验证的原始证明。提出了一种名为选择性层ZK电路创建（SL-ZKCC）的方法，可以选择性地将图像生成模型的关键层转换为电路，大幅减少证明生成时间。ZK-SNARK证明通过最低有效位（LSB）隐形嵌入生成的图像中。该系统已在GAN和扩散模型上进行演示，提供了一个安全且模型通用的可信AI图像生成管道。
### Conclusion
ZK-WAGON系统为图像生成模型提供了不可感知的水印方法，同时确保证明的验证而不泄露敏感信息。
## 177. `cs.AI` - 轻量化潜藏LiDAR自编码器LiLa-Net用于3D点云重建 [PDF](https://arxiv.org/pdf/2510.02028), [HTML](https://arxiv.org/abs/2510.02028)
### Authors
Mario Resino,Borja Pérez,Jaime Godoy,Abdulla Al-Kaff,Fernando García
### Background
该研究提出了一种基于LiDAR点云的3D自编码器架构LiLa-Net，用于从真实的交通环境中提取高效特征。这项研究使用了一辆半自动驾驶车辆，并配备了Velodyne LiDAR系统进行研究。
### Innovation
通过减少编码层的数量和简化跳接连接来改善性能，同时不使用过多的计算资源。研究成果达到了在保持性能的同时改善重建质量的平衡。此外，模型展现了强大的泛化能力，能够重建与原始交通环境无关的物体。
### Conclusion
LiLa-Net 通过轻量级的设计实现了在减少资源消耗的情况下，仍然能够准确重建点云，证明了其在真实交通环境中的应用潜力。
## 178. `cs.AI` - AI偏奋试探现状：现有计划和研究综述 [PDF](https://arxiv.org/pdf/2510.02036), [HTML](https://arxiv.org/abs/2510.02036)
### Authors
Sergej Kucenko,Nathaniel Dennler,Fengxiang He
### Background
现有的AI偏见评价方法通常忽视了受AI系统影响的社区。为了激发社区对AI偏见的参与，提出了一种名为偏奋试探（bias bounties）的方法，通过激励用户报告其与AI系统交互时遇到的偏见来检测AI偏见。尽管存在现有的文献综述空白，但这项调查旨在识别和分析现有的AI偏奋试探项目，并综述有关偏奋试探的学术文献。
### Innovation
提出了一种基于奖励的参与社区的方法——偏奋试探，通过引导用户报告其在使用AI系统时遇到的偏见来促进AI偏见的检测。这项调查填补了现有文献的空白，通过搜索Google，Google Scholar，PhilPapers，IEEE Xplore等资源，识别并分析了五个偏奋试探项目，并综述了五篇相关研究论文。
### Conclusion
建议降低参与奖励计划的技术要求，以包括没有编程经验的人。由于偏奋试探的有限采用，未来的研究应探讨将漏洞奖励的最佳实践应用于偏奋试探，同时考虑如何设计这些计划以对未充分代表的群体保持敏感性，降低组织的采用门槛。
## 179. `cs.AI` - 通过张量等变神经网络解锁符号级预编码效率 [PDF](https://arxiv.org/pdf/2510.02108), [HTML](https://arxiv.org/abs/2510.02108)
### Authors
Jinshuo Zhang,Yafei Wang,Xinping Yi,Wenjin Wang,Shi Jin,Symeon Chatzinotas,Björn Ottersten
### Background
尽管基于构造性干扰（CI）利用的符号级预编码（SLP）能够带来性能提升，但其高计算复杂性仍是一个瓶颈。
### Innovation
本文提出了一个基于低推理复杂度的端到端深度学习框架，该框架利用了最优SLP解决方案的闭式解结构和固有的张量等变性（TE）。框架基于高效的基于模型的建模形式及其已知的闭形式解，分析了它们与线性预编码（LP）的关系，并研究了相应的最优性条件。通过这种关系，构造了一个从问题表述到解决方案的映射，并证明了该映射具备TE，在此基础上，设计的网络显示出特定的参数共享模式，实现了低计算复杂性和强泛化性。利用这些特点，提出了具有基于注意力的TE模块的框架基础，实现线性计算复杂度，并且设计了一个基于TE的网络来映射CSI、统计信息和符号到辅助变量，从而使该框架在不完美的CSI环境下也适用。
### Conclusion
模拟结果显示所提出框架能够捕捉最优SLP的显著性能提升，相对常规方法实现约80倍的速度提升，并且在用户数和符号块长度变化下依然具备强泛化性。
## 180. `cs.AI` - 投机解码的异质影响 [PDF](https://arxiv.org/pdf/2510.02128), [HTML](https://arxiv.org/abs/2510.02128)
### Authors
Jameson Sandler,Ahmet Üstün,Marco Romanelli,Sara Hooker,Ferdinando Fioretto
### Background
投机解码是一种通过较小、更便宜的`草案`模型为推理提供概率支持的方法，已经成为系统地减少大型语言模型解码时间的标准技术。已有研究显示，投机解码能在不同任务上提供不同的加速效果，但通常会逐渐减弱，尤其是在欠拟合或非代表性任务中效果更差。
### Innovation
本文通过对投机解码的潜在不同加速率进行分析，揭示了获得的加速效果在不同任务中并不均匀，提出了一个量化这种“不公平”现象的分析方法，并指出了导致不同加速效果的因素。基于这些见解，提出了一个减少加速效果差距的缓解策略，并在多个模型组合中验证了其有效性，平均每种模型组合提高了12%的公平性指标。
### Conclusion
研究表明，投机解码在不同任务中的加速效果是有差异的，因此提出了一种策略来减少这种差距，并通过实验验证了该策略的有效性，平均提高了模型公平性指标的12%。
## 181. `cs.AI` - KAIROS: 统一训练的通用非自回归时间序列预测 [PDF](https://arxiv.org/pdf/2510.02084), [HTML](https://arxiv.org/abs/2510.02084)
### Authors
Kuiye Ding,Fanda Fan,Zheya Wang,Hongxiao Li,Yifan Wang,Lei Wang,Chunjie Luo,Jianfeng Zhan
### Background
在互联网上，可靠的时间序列预测提供了前瞻性的信号，支持资源规划、缓存放置和异常响应，使平台能够随着用户行为和内容分布的变化高效运行。与其它领域相比，针对Web应用程序的时间序列预测需要更快的响应速度以支持实时决策。
### Innovation
KAIROS是一个非自回归的时间序列预测框架，可以直接模拟段级别的多峰分布。与自回归方法相比，KAIROS避免了误差累积并实现了即时推理，同时还在现有的非自回归模型基础上改进了预测效果，这些模型往往会过度平滑预测结果。KAIROS在大规模语料库上训练，展示了在六个广泛使用的基准测试中表现出色的零样本泛化能力，尤其是在推理成本上远低于当前最先进的基础模型。
### Conclusion
KAIROS突显了非自回归设计作为时间序列中基础模型可扩展范式的的重要性。
## 182. `cs.AI` - 使用GPT-4o在口腔全景X光片中生成下颌囊肿发现：构建两级结构输出自我纠正环(SLSO)框架 [PDF](https://arxiv.org/pdf/2510.02001), [HTML](https://arxiv.org/abs/2510.02001)
### Authors
Nanaka Hosokawa,Ryo Takahashi,Tomoya Kitano,Yukihiro Iida,Chisako Muramatsu,Tatsuro Hayashi,Yuta Seino,Xiangrong Zhou,Takeshi Hara,Akitoshi Katsumata,Hiroshi Fujita
### Background
研究利用OpenAI GPT-4o的多模态能力，自动对口腔全景X光片中的下颌囊肿进行诊断。通过引入两级结构输出自我纠正环(SLSO)框架，提高了诊断的准确性，并进行了实验验证。设计了一套10步流程，应用于22例下颌囊肿案例，包括图像输入分析、结构化数据生成、牙齿编号提取、一致性检查、检测到不一致时的迭代再生、以及最终输出的重构和一致性验证。实验采用链式思考方法进行比较，结果显示SLSO框架在多个评估项目上提高了输出精度，特别是牙齿编号、牙齿移动和根吸收的比例分别提高了66.9%、33.3%和28.6%。然而，对于跨越多颗牙齿的大范围病灶识别仍存在局限，且因样本量小，统计显著性未能达到标准，但框架总体上提高了发现描述的透明度，抑制了幻觉，并提升了牙齿编号识别精度。
### Innovation
开发了两级结构输出自我纠正环(SLSO)框架，并应用于自动诊断口腔全景X光片中的下颌囊肿。该框架能够在发现不一致时进行迭代再生成，并最终生成一致的结构化输出。通过与链式思考方法的比较实验，SLSO框架提高了多个评估项目上的诊断准确性，尤其在牙齿编号、牙齿移动和根吸收的识别上。但是，对于跨越多颗牙齿的大范围病灶识别效果有限，未来需进一步优化以提高系统整体性能和实用度。
### Conclusion
ZZS框架在多个领域提高了诊断准确性，尽管样本量较小，但SLSO框架在提高发现描述透明度、抑制幻觉和提升牙齿编号识别精度方面表现良好。未来仍需进一步改进，特别是对于跨越多颗牙齿的大范围病灶识别能力，以推动该系统的实用化进程。
## 183. `cs.AI` - 当跟踪失效时：分析SAM2在手术视频中基于点的跟踪失败模式 [PDF](https://arxiv.org/pdf/2510.02100), [HTML](https://arxiv.org/abs/2510.02100)
### Authors
Woowon Jang,Jiwon Im,Juseung Choi,Niki Rashidian,Wesley De Neve,Utku Ozbulak
### Background
视频对象分割(VOS)模型，如SAM2，利用最少的用户输入提供了零样本跟踪能力，特别适用于手术视频。点基跟踪作为有效的低成本选项，具有潜在的优势，但其在复杂手术环境中的可靠性和失败案例尚不明确。这项研究集中在腹腔镜胆囊切除手术视频中，对胆囊、夹子和L钩电凝进行分析，探讨点基跟踪与初始掩码分割的性能差异，揭示组织相似性和边界模糊性对跟踪失败的影响。
### Innovation
本文系统性地分析了点基跟踪在腹腔镜胆囊切除手术视频中的失败模式。通过对比点基跟踪和分割掩码初始化的性能，确定了影响跟踪结果的因素，并提出了提高手术视频分析性能的实用建议。
### Conclusion
点基跟踪在手术工具方面与分割掩码初始化竞争颇具竞争力，但在解剖目标（如组织）上表现较差，组织相似性和边界模糊性是导致失败的关键因素。通过对关键因素的定性分析，提出了若干实用建议，以提高手术视频分析中的表现。
## 184. `cs.AI` - VarCoNet：一种针对静息态功能磁共振成像的功能连接组提取自监督框架 [PDF](https://arxiv.org/pdf/2510.02120), [HTML](https://arxiv.org/abs/2510.02120)
### Authors
Charalampos Lamprou,Aamna Alshehhi,Leontios J. Hadjileontiadis,Mohamed L. Seghier
### Background
考虑到个体间大脑功能的差异性对于精准医疗至关重要，本研究旨在通过将个体间的功能差异视作有意义的数据而非噪声，提出一种改进的自监督框架VarCoNet，用于从静息态功能磁共振成像(rs-fMRI)数据中提取功能性连接组(FC)。
### Innovation
VarCoNet引入了一种新颖的自监督对比学习策略，并结合了基于rs-fMRI信号分割的增强方法；它还采用了1D-CNN-Transformer编码器，结合了鲁棒的贝叶斯超参数优化技术，旨在从无标签数据中提取FC嵌入。该框架通过两个下游任务进行了评估：1) 利用麦克劳尼人类连接体项目数据的个体指纹识别；2) 利用ABIDE I和II数据集的自闭症谱系障碍分类。实验结果表明，VarCoNet在解析能力、鲁棒性、可解释性和泛化能力方面优于13种深度学习方法，展示了其优越性。
### Conclusion
VarCoNet提供了一种灵活且 robust 的框架，用于静息态功能磁共振成像的FC分析。
## 185. `cs.AI` - SpurBreast: 专门为研究现实世界乳腺MRI分类中伪相关现象而策划的数据集 [PDF](https://arxiv.org/pdf/2510.02109), [HTML](https://arxiv.org/abs/2510.02109)
### Authors
Jong Bum Won,Wesley De Neve,Joris Vankerschaver,Utku Ozbulak
### Background
深度神经网络（DNNs）在医学影像方面取得了显著的成功，但在实际部署中仍然面临挑战，主要是因为模型可能会学习非临床特征而不是有意义的医学模式。现有的医学影像数据集没有系统地研究这个问题，主要原因是数据集的使用许可限制和有限的补充患者数据。为解决这一问题，引入了SpurBreast数据集，旨在故意包含伪相关信号以评估这些信号对模型性能的影响。通过分析超过100个涉及患者、设备和成像协议的特征，研究人员识别出两种主要的伪相关信号：磁场强度（一种全局特征，影响整个图像）和图像方向（一种局部特征，影响空间对齐）。通过受控的数据集分割，结果表明DNN可以利用这些非临床信号，在验证集上取得高准确率，但无法推广到无偏测试数据上。为了进一步研究，研究人员还提供了包含伪相关信号和不含伪相关信号的数据集，允许研究人员系统地探讨临床相关和无关特征、不确定性估计、对抗鲁棒性和推广策略的策略.
### Innovation
SpurBreast数据集故意包含伪相关信号，旨在评估这些信号对模型性能的影响。通过对比分析包含和不包含伪相关信号的数据集，研究人员能够系统地研究各种研究方向，如临床相关特征、不确定性和对抗鲁棒性等问题。数据集和模型代码已公开共享，这促进了该领域的进一步研究和进展.
### Conclusion
SpurBreast数据集通过故意引入伪相关信号，填补了现有医学影像数据集在实验设计上的空白，使研究人员能够更好地理解模型在现实世界应用中表现的不同。通过对比分析，研究人员可以系统地探索临床相关性和无关性特征、模型的不确定性估计、对抗样本的鲁棒性和推广策略。
## 186. `cs.AI` - BioinfoMCP: 一体化平台实现自主生物信息学接口 [PDF](https://arxiv.org/pdf/2510.02139), [HTML](https://arxiv.org/abs/2510.02139)
### Authors
Florensia Widjaja,Zhangtianyi Chen,Juexiao Zhou
### Background
生物信息学工具对于复杂的计算生物学任务至关重要，然而，这些工具与新兴的AI代理框架的集成受到不兼容接口、异构输入输出格式及不一致参数惯例的影响。虽然Model Context Protocol (MCP) 提供了一个标准化的工具与AI通信框架，但手动将大量现有的和迅速增长的专业生物信息学工具转换为MCP兼容服务器非常费时且不可持续。
### Innovation
本文提出了一种统一平台BioinfoMCP，包含两个组件：BioinfoMCP Converter自动通过大型语言模型从工具文档中生成坚固的MCP服务器；BioinfoMCP Benchmark系统性验证转换后的工具在多种计算任务中的可靠性和通用性。展示了包含38个MCP转换的生物信息学工具的平台，其中94.7%的工具成功地在三种广泛使用的AI代理平台上执行复杂的计算流程。通过消除技术障碍，BioinfoMCP使自然语言能够与复杂的生物信息学分析交互，无需进行大量编程知识。
### Conclusion
BioinfoMCP通过去除AI自动化的技术障碍，使自然语言能够与复杂的生物信息学分析交互，无需进行大量编程知识，为智能且互操作的计算生物学提供了可扩展的道路。
## 187. `cs.AI` - 对比对比损失和三元组损失在音频-视觉嵌入中的比较：类内方差和贪婪性分析 [PDF](https://arxiv.org/pdf/2510.02161), [HTML](https://arxiv.org/abs/2510.02161)
### Authors
Donghuo Zeng
### Background
对比损失和三元组损失是深度度量学习中广泛使用的优化目标，但它们对表示质量的影响尚未得到充分理解。本文通过实验和理论分析对比了这两种损失在类内和类间方差以及优化行为（如贪婪更新）上的差异。
### Innovation
本文通过对损失衰减率、激活比率和梯度范数的分析，揭示了对比损失和三元组损失在优化动态中的不同效应；并且在合成数据和真实数据集（MNIST、CIFAR-10等）上进行特定任务的实验，发现三元组损失保留了更多的类内和跨类方差，有助于在学习表示时进行更细粒度的区分；对比损失倾向于压缩类内嵌入，可能会掩盖微妙的语义差异。
### Conclusion
在MNIST、CIFAR-10、CUB-200和CARS196数据集上，我们的实验结果表明，使用三元组损失可以达到更好的性能，这表明在细节保留和困难样本聚焦上应使用三元组损失，而在平滑和广泛的嵌入细化上应使用对比损失。
## 188. `cs.AI` - 为单元测试生成提供澄清语义的在上下文示例 [PDF](https://arxiv.org/pdf/2510.01994), [HTML](https://arxiv.org/abs/2510.01994)
### Authors
Chen Yang,Lin Yang,Ziqi Wang,Dong Wang,Jianyi Zhou,Junjie Chen
### Background
近年来，大型语言模型（LLMs）通过在上下文学习（ICL）的方式在单元测试生成中表现出强大的性能。然而，上下文示例的质量显著影响生成测试的效果，结构不良或语义不明确的测试示例往往导致次优输出。
### Innovation
本文提出了一种名为CLAST的新技术，该技术可以系统地改进单元测试，提高其语义清晰度，从而增强作为上下文示例的实用性。该方法通过程序分析和基于LLM的重写相结合，将复杂的测试分解为逻辑上更清晰的测试，以改善语义清晰度。
### Conclusion
CLAST在保留测试效果和提高语义清晰度方面的性能远超当前最先进的改进技术UTgen。具体而言，CLAST能够充分利用原始单元测试的效果，而UTgen则在编译成功率、通过率、测试覆盖率和变异分数上分别减少了平均12.90%、35.82%、4.65%和5.07%。超过85.33%的研究参与者更倾向于CLAST改进后的测试的语义清晰度。将CLAST改进的测试作为表征有效地提高了基于ICL的单元测试生成方法，如RAGGen和TELPA，使得生成的测试在编译成功率、通过率和覆盖率上分别提高了25.97%、28.22%和45.99%，取得了显著效果，突显了CLAST在软件测试实践中的潜在影响，并为未来的研究指明了方向。
## 189. `cs.AI` - 通过细粒度提示解锁视觉语言模型在视频异常检测中的应用 [PDF](https://arxiv.org/pdf/2510.02155), [HTML](https://arxiv.org/abs/2510.02155)
### Authors
Shu Zou,Xinyu Tian,Lukas Wesemann,Fabian Waschkowski,Zhaoyuan Yang,Jing Zhang
### Background
提示技术已发展成为一种实用的方法，用于在保留视觉语言模型（VLMs）冻结状态的同时进行调优，以适应视频异常检测（VAD）。然而，现有提示往往过于抽象，未能考虑到定义监控视频中复杂异常的关键细节，如精细的人类-物体交互或动作语义。
### Innovation
本文提出了ASK-Hint，这是一种基于动作中心的知识结构化提示框架，旨在从冻结的VLMs中激发更准确和可解释的推理。ASK-Hint将提示组织成语义一致的组（如暴力、财产犯罪、公共安全），并通过提出细粒度的引导问题，使其预测与区分性视觉线索相一致。
### Conclusion
广泛的实验表明，ASK-Hint在UCF-Crime和XD-Violence数据集上比先前的基线方法显著提高了AUC，达到了最先进的性能，无论是微调方法还是无需训练的方法。此外，我们的框架提供了可解释的异常推理过程，并且在不同数据集和VLM后端上的泛化能力强。这些结果突显了提示粒度的重要性，并将ASK-Hint确立为无需训练并具有广泛适用性的解释性视频异常检测的新解决方案。
## 190. `cs.AI` - 基于多阶段混合方法实验研究的人工智能顾问在决策中的合作：证据 [PDF](https://arxiv.org/pdf/2510.02153), [HTML](https://arxiv.org/abs/2510.02153)
### Authors
Hasan Mahmuda,Najmul Islam,Satish Krishnan
### Background
机器人理财顾问（RAs）比人类财务顾问更经济且无偏见，但其采用率仍然有限。虽然先前的研究已经探讨了用户与RAs的互动，但对于个体如何解释RAs的角色以及如何将其建议融入决策过程知之甚少。为了解决这一研究空白，本研究采用多阶段混合方法设计，结合了一项行为实验（N = 334），主题分析以及后续的定量测试。研究发现人们倾向于依赖RAs，这种依赖性受到关于RA表现的信息以及建议的盈亏表述方式的影响。主题分析揭示了决策中三种不同的RAs角色和四种用户类型，每种类型都反映了不同的建议整合模式。此外，一个2x2模型将影响接受度的先决条件分为个体和算法层面的促成因素和抑制因素。通过结合行为、解释性和证实性证据，本研究深化了对人-RA合作的理解，并为设计更可信赖和适应性强的RA系统提供了实用洞见。
### Innovation
本研究采用多阶段混合方法设计，包括行为实验、主题分析和后续定量测试，结合了行为、解释性和证实性证据来探讨人-RA合作的具体机制。研究不仅揭示了用户如何依赖和理解RAs，而且提出了影响RAs接受度的全面模型，涵盖个体和算法层面的促成因素和抑制因素。
### Conclusion
通过多阶段混合方法设计和综合证据，本研究深化了对人-RA合作的理解，并为设计更可信赖和适应性强的RA系统提供了实用洞见。
## 191. `cs.AI` - 如何找到高影响力论文：自我排名作为超越同行评审的科学影响强预测器 [PDF](https://arxiv.org/pdf/2510.02143), [HTML](https://arxiv.org/abs/2510.02143)
### Authors
Buxin Su,Natalie Collina,Garrett Wen,Didong Li,Kyunghyun Cho,Jianqing Fan,Bingxin Zhao,Weijie Su
### Background
学术研究中的同行评审不仅确保事实的正确性，还旨在识别对未来研究方向有高科学潜力的工作。而在人工智能等快速发展的领域，随着提交量的急剧增长，完成这一任务变得越来越困难。本研究通过大规模实验，探索了一种未被充分开发利用的方法，即作者对其多次提交到同一人工智能会议的研究进行自我排名，以此来识别高影响的研究成果。基于博弈论推理，研究者假设自我排名具有信息价值，因为作者对工作概念深度和长期潜力有独特的理解。在一家顶级人工智能会议中，1,342名研究人员对其2,592篇提交按照感知质量进行了自我排名。超过一年的跟踪结果显示，作者自认为质量最高的论文比最低的论文获得了两倍以上的引用次数；自我排名在识别高引用论文（引用超过150次）方面尤为有效。此外，研究还表明，自我排名在预测未来引文数量方面优于同行评审分数。经过控制投稿时间等混杂因素后，研究结果依旧稳健。这些发现表明，作者的自我排名可以作为同行评审的有力补充，用于识别和提高人工智能领域高影响力的科研成果。
### Innovation
本研究采用了一种新的方法——由作者自行对其多次提交到同一人工智能会议的研究进行自我排名，以此来识别高影响力的研究。研究结果表明，这种自我排名方法在预测未来引文数量方面优于传统的同行评审分数，具有在高影响力的论文识别方面更强的预测能力。此外，该方法还可以作为一种独立于其他因素的可靠的评估工具，识别出具有高科学潜力的高质量研究工作，为学术界提供了一种新的评价标准和技术。
### Conclusion
研究结果表明，作者的自我排名可以作为一对比同行评审的有效补充，用于识别和提升人工智能领域的高影响研究。自我排名可以有效识别出高质量的研究工作，尤其是那些在未来具有高引用潜力的工作。未来的研究可以进一步探索这种自我排名方法在其他领域中的应用，以及如何更好地集成这种评估工具来提升科研质量。
## 192. `cs.AI` - EvolveCaptions：通过实时协作字幕赋能听力障碍用户 [PDF](https://arxiv.org/pdf/2510.02181), [HTML](https://arxiv.org/abs/2510.02181)
### Authors
Liang-Yuan Wu,Dhruv Jain
### Background
现有的自动语音识别（ASR）系统在准确转录聋人和听力障碍（DHH）用户的声音时通常会失败，尤其是在实时对话中。现有的个性化方法通常需要大量的记录数据，并要求DHH演讲者进行适应。
### Innovation
EvolveCaptions是一个实时协作ASR适应系统，支持最小努力的在地个性化。听力参与者在实时对话中纠正ASR错误，系统根据这些纠正生成针对音标的简短提示，供DHH参与者录制，进而微调ASR模型。在一项研究中，EvolveCaptions在一小时内将所有DHH用户的话音错误率（WER）降低，平均只需要五分钟的录音时间。参与者认为该系统直观、低努力且融入沟通非常流畅。这些结果表明，协作的实时ASR适应具有实现更公平沟通的潜力。
### Conclusion
研究显示，通过实时协作更新ASR模型能够显著提高DHH用户语音转录的准确性，并且简化了个性化的过程，使得DHH用户的沟通更加平等和直观。
## 193. `cs.AI` - 从心电图检测查加斯病：George B. Moody PhysioNet挑战2025 [PDF](https://arxiv.org/pdf/2510.02202), [HTML](https://arxiv.org/abs/2510.02202)
### Authors
Matthew A. Reyna(1),Zuzana Koscova(1),Jan Pavlus(1),Soheil Saghafi(1),James Weigle(1),Andoni Elola(1,2),Salman Seyedi(1),Kiersten Campbell(1),Qiao Li(1),Ali Bahrami Rad(1),Antônio H. Ribeiro(3),Antonio Luiz P. Ribeiro(4,5),Reza Sameni(1,6),Gari D. Clifford(1,6) ((1) Department of Biomedical Informatics, Emory University, Atlanta, USA, (2) Department of Electronic Technology, University of the Basque Country UPV/EHU, Spain, (3) Department of Information Technology, Uppsala University, Uppsala, Sweden, (4) Universidade Federal de Minas Gerais, Belo Horizonte, Brazil, (5) Telehealth Center from Hospital das Clinicas, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil, (6) Department of Biomedical Engineering, Georgia Institute of Technology and Emory University, Atlanta, USA)
### Background
查加斯病是一种由昆虫传播的寄生虫感染，主要发生在南美和中美地区，近年来在北美的感染率也在增加。该病的慢性阶段可导致心脏疾病和消化系统问题。现有的血清学检测能力有限，但查加斯心肌病通常会在心电图（ECG）中显现，为此提供了一个优先进行测试和治疗的途径。
### Innovation
本次挑战引入了多个创新点，首先利用了多种带有患者报告和血清学测试标签的数据集，并提供了大量弱标签数据和少量强标签数据。其次，数据增强技术被用于提高模型的稳健性和泛化能力，使其能够处理未见过的数据源。第三，引入了一个评价指标，该指标考虑了不同地区的血清学检测能力，使得机器学习问题被转化为优先级排序任务。
### Conclusion
在2025年George B. Moody PhysioNet挑战中，共有630名来自111支团队的参赛者提交了超过1300份参赛作品，展现了来自世界各地学术界和工业界的不同方法和技术。
## 194. `cs.AI` - SIVE: 朝着代码数据集可验证认证的迈进 [PDF](https://arxiv.org/pdf/2510.02166), [HTML](https://arxiv.org/abs/2510.02166)
### Authors
Fatou Ndiaye Mbodji,El-hacen Diallo,Jordan Samhi,Kui Liu,Jacques Klein,Tegawendé F. Bissyande
### Background
公共代码数据集在代码代理和经验软件工程中被广泛应用，但现有数据集缺乏可验证的质量保证。虽然静态的数据集卡片可以提供相关信息，但这些卡片既不可审计，也无法提供统计意义上的保证，导致难以证明数据集的质量。研究团队独立且临时构建清理管道，这导致了资源分散和成本增加。
### Innovation
本文介绍了社区驱动的SIEVE框架，它将单属性检查转变为信心卡片——一种机器可读、可验证且具有随时有效的统计界限的质量证书。通过促进从叙述性卡片向随时可验证认证的转变，SIEVE旨在降低质量保证成本并提高对代码数据集的信任。
### Conclusion
将信心卡片引入代码数据集中，这种转变预计会降低质量保证的成本并增强对代码数据集的信任度。
## 195. `cs.AI` - GRACE：一种语言模型框架实现可解释的逆强化学习 [PDF](https://arxiv.org/pdf/2510.02180), [HTML](https://arxiv.org/abs/2510.02180)
### Authors
Silvia Sapora,Devon Hjelm,Alexander Toshev,Omar Attia,Bogdan Mazoure
### Background
逆强化学习旨在从专家演示中恢复奖励模型，但传统方法产生的模型往往是“黑盒”的，难以解释和调试。以往的研究中，这种方法存在解释性不足的问题，难以让研究人员和开发者理解奖励模型的具体工作原理，这限制了其在实际应用中的可验证性和实用性。
### Innovation
本文提出了一种名为GRACE的方法，通过使用大型语言模型在进化搜索中生成可解释的、基于代码的奖励函数，直接从专家轨迹中反向工程化生成。所生成的奖励函数可以被执行并进行检查和验证，使得模型更具解释性。在BabyAI和AndroidWorld基准测试中，GRACE能够高效地学习到高度准确的奖励函数，即使在复杂的多任务设置下也能取得优异的表现。此外，GRACE生成的奖励函数相比现有的竞争性模仿学习和基于真实奖励的在线强化学习方法，能够产生更强的有效策略。最后，GRACE还能够在一个任务集合中构建复杂奖励API。
### Conclusion
本研究展示了GRACE在多任务设置中的应用能力，验证了其在逆强化学习领域的有效性，特别是在构建复杂奖励函数方面。通过引入基于语言模型的方法，GRACE为逆强化学习提供了一种新的机制，使得奖励模型更具可解释性和实用性。
## 196. `cs.AI` - ARUQULA — 基于ReAct和知识图谱探索工具的LLM Text2SPARQL方法 [PDF](https://arxiv.org/pdf/2510.02200), [HTML](https://arxiv.org/abs/2510.02200)
### Authors
Felix Brei,Lorenz Bühmann,Johannes Frey,Daniel Gerber,Lars-Peter Meyer,Claus Stadler,Kirill Bulert
### Background
对于没有计算机科学背景的人来说，与知识图谱交互可能是一项艰巨的任务，因为所使用的查询语言（SPARQL）具有较高的入门门槛。大型语言模型（LLMs）可以通过提供从自然语言问题到SPARQL查询的文本翻译支持来降低这一门槛。在这篇论文中，作者介绍了一种基于SPINACH的方法，使用LLM支持的代理，该代理通过探索和执行的迭代过程将自然语言问题逐步转化为SPARQL查询。这一工作受到Text2SPARQL挑战的启发，旨在促进Text2SPARQL领域的改进。
### Innovation
该研究提出了一种新的方法，基于LLM代理（SPINACH），可以在逐步探索和执行的过程中将自然语言疑问转化为SPARQL查询。这代表了一种迭代的、更加用户友好的方式来进行知识图谱查询，可以减少对技术和专业背景的要求。
### Conclusion
根据对代理行为的深入分析，作者获得了对未来改进方向的洞察。这一方法的成功展示了LLM在降低知识图谱使用门槛方面的潜力，并且对未来在更大范围内的应用具有重要意义。
## 197. `cs.AI` - 学习进行推理以检测幻觉片段 [PDF](https://arxiv.org/pdf/2510.02173), [HTML](https://arxiv.org/abs/2510.02173)
### Authors
Hsuan Su,Ting-Yao Hu,Hema Swetha Koppula,Kundan Krishna,Hadi Pouransari,Cheng-Yu Hsieh,Cem Koc,Joseph Yitan Cheng,Oncel Tuzel,Raviteja Vemulapalli
### Background
大型语言模型（LLMs）经常生成幻觉，即无法验证的内容，这降低了模型的可靠性。尽管大多数先有研究将幻觉检测视为一个二元任务，但在许多实际应用中，需要识别幻觉片段，这是一个多步骤的决策过程。因此，自然会引发一个疑问：明确的推理是否能帮助检测幻觉片段这一复杂任务。
### Innovation
本文提出了一种基于强化学习的框架RL4HS，采用了基于片段级别的奖励函数来激励推理，并引入了类感知策略优化来缓解奖励不平衡问题。实验结果表明，RL4HS在RAGTruth基准测试（摘要、问答、数据到文本）上优于预训练推理模型和监督微调，证明了采用片段级别奖励的强化学习对于检测幻觉片段的必要性。
### Conclusion
RL4HS框架展示了在幻觉片段检测中使用基于片段级别的奖励进行强化学习的优越性，能够克服预训练推理模型和监督微调的限制，提高检测准确性和可靠性。
## 198. `cs.AI` - Explore Briefly, Then Decide: Mitigating LLM Overthinking via Cumulative Entropy Regulation [PDF](https://arxiv.org/pdf/2510.02249), [HTML](https://arxiv.org/abs/2510.02249)
### Authors
Tianyi Jiang,Yi Bin,Yujuan Ding,Kainian Zhu,Fei Ma,Jingkuan Song,Heng Tao Shen
### Background
大型语言模型（LLMs）在解决复杂问题时展示了显著的推理能力，特别是通过长链推理（Long Chain-of-Thought, CoT）。然而，这些模型往往在处理简单问题时表现出过度推理，即为解决简单问题而生成不必要的长推理步骤。这会降低模型的效率，并使模型难以适配不同问题复杂度的推理深度。
### Innovation
本文提出了一种新的度量标准——Token Entropy Cumulative Average (TECA)，用于衡量推理过程中探索的广度。同时，提出了一种新颖的推理模式——短暂探索后决定（Explore Briefly, Then Decide，EBTD），并配有累计熵调节（Cumulative Entropy Regulation, CER）机制。该方法利用TECA帮助模型动态确定其思考过程的最佳终结点，并给出最终答案，从而实现高效推理。研究结果显示，该方法显著减少了过度推理，同时保持了解题能力，并在多项数学基准测试中表现出高效和适应性。
### Conclusion
实验结果表明，通过使用我们的思考范式，平均响应长度在较简单的数据集上减少了高达71%，证明了我们方法在提高推理过程效率和适应性方面的有效性。
## 199. `cs.AI` - Go witheFlow: 实时情绪驱动的音频效果调节 [PDF](https://arxiv.org/pdf/2510.02171), [HTML](https://arxiv.org/abs/2510.02171)
### Authors
Edmund Dervakos,Spyridon Kantarelis,Vassilis Lyberatos,Jason Liartis,Giorgos Stamou
### Background
音乐表演是人类特有的活动，与表演者表达、激发或传达情感的能力密切相关。机器无法像人类那样表演音乐；它们能够创作、复现、执行或合成音乐，但缺乏情感或情绪体验的能力。因此，音乐表演是探索人机合作方面的一个理想途径。
### Innovation
本文介绍了witheFlow系统，该系统通过自动根据从生物信号和音频中提取的特征调整音频效果，增强实时音乐表演。该系统目前处于概念证明阶段，设计轻量级、能在笔记本电脑上本地运行，并且开源。
### Conclusion
witheFlow系统能够实时调节音频效果，增强音乐表演，提供了人机协作的新模式。
## 200. `cs.AI` - DiFFPO: 使用强化学习训练快速高效的大规模扩散语言模型 [PDF](https://arxiv.org/pdf/2510.02212), [HTML](https://arxiv.org/abs/2510.02212)
### Authors
Hanyang Zhao,Dawen Liang,Wenpin Tang,David Yao,Nathan Kallus
### Background
该文提出了一个统一框架DiFFPO，用于通过强化学习训练受掩码扩散机制影响的大语言模型，使其既能更好地推理（furious），又能更快地推理。背景涉及当前的大语言模型在推理速度和性能上的挑战，特别是在大规模扩散语言模型的应用中，如何有效地通过强化学习提升模型的推理速度和准确性是研究热点。
### Innovation
1. 提出了一种通过强化学习训练代理策略的方法，这种代理策略是一个近似的真实dLLM策略的难以处理的似然性的代理模型。2. 引入了两阶段似然性近似结合重要性采样校正的新方法，这将强化学习算法的样本效率提高，并显著改善了任务性能。3. 建议联合训练dLLMs的高效采样器/控制器，通过让模型自适应地为每个提示分配推理阈值，来激励模型利用其自然的多令牌预测能力。这种方法在较少的功能评估次数下获得了更高的准确性，从而在大规模扩散语言模型的推理时间计算性能方面实现了最优表现。
### Conclusion
通过使用DiFFPO框架，研究团队展示了在数学和规划任务基准测试上训练开源的大规模扩散语言模型的有效性，该框架能够显著提升模型的推理效率并保持较高准确性。
## 201. `cs.AI` - INSIGHT: INference-time Sequence Introspection for Generating Help Triggers in Vision-Language-Action Models [PDF](https://arxiv.org/pdf/2510.01389), [HTML](https://arxiv.org/abs/2510.01389)
### Authors
Ulas Berk Karli,Ziyao Shangguan,Tesca FItzgerald
### Background
近年来，视觉语言动作（VLA）模型表现出强大的泛化能力，但缺乏内在机制来预测何时需要请求人类监督者的帮助。当前研究表明，VLA模型在碰到问题时无法预见失败并请求帮助。
### Innovation
本文提出了一个学习框架，通过利用令牌级别的不确定性信号来预测何时VLA需要请求帮助。该框架基于$boldsymbol{textit{textpi_0}}$-FAST模型，通过提取每个令牌的熵、对数概率和狄利克雷估计的 aleatoric 和 epistemic 不确定性，训练紧凑的变压器分类器将这些序列映射到帮助触发器。该研究探索了强监督和弱监督的不同监督模式，并在不同的分布任务中进行了广泛比较。研究表明，在标签准确性较低的情况下，模型仍然能够进行有效的自我反省。
### Conclusion
研究表明，强标签有助于模型捕获更精细的不确定性动态，使可靠帮助检测成为可能。而弱标签虽然较噪音较大，但在训练和评估同步时仍能支持具有竞争力的自我反省，为大规模标注不现实的情况提供了一条可行的路径。更重要的是，研究发现使用变压器建模令牌级别的不确定性信号的动态演化，比静态序列级别的分数提供了更强的预测能力。该研究首次系统地评估了VLA中的基于不确定性的自我反省，并为后续的主动学习和实时错误缓解提出了新的方向。
## 202. `cs.AI` -  TempoControl: 时间注意力引导的文本到视频模型 [PDF](https://arxiv.org/pdf/2510.02226), [HTML](https://arxiv.org/abs/2510.02226)
### Authors
Shira Schiber,Ofir Lindenbaum,Idan Schwartz
### Background
近期，生成视频模型的进展已经使得根据自然语言提示创建高质量视频成为可能。然而，这些模型通常缺乏细粒度的时序控制，无法让用户指定生成序列中特定视觉元素出现的确切时间点。因此，本文提出了一种名为 TempoControl 的方法，用于推断过程中视觉概念的时间对齐，而无需重新训练或额外监督。 TempoControl 利用文本到视频扩散模型中的交叉注意力图引导概念的时序，并通过一种新型的优化方法实现这一目标。
### Innovation
 TempoControl 利用交叉注意力图来指导概念的时间分布，通过相关性对注意力进行对齐、在需要增强的可见度区域放大注意力以及保持空间聚焦（通过熵），确保精确的时序控制并保持高质量和多样性。该方法可通过多种视频生成应用进行演示，包括单个和多个对象的时间重排序，以及动作和声音同步生成，展现了其有效性。
### Conclusion
 TempoControl 在文本到视频模型的人工智能生成过程中，提供了一种新方法来精确控制时序，同时保持高质量和多样性。该方法通过交叉注意力图和其他三个互补原则成功实现了这一目标，并在不同视频生成应用中得到了验证。
## 203. `cs.AI` - More Than One Teacher: 适应性多指导策略优化以实现广泛探索 [PDF](https://arxiv.org/pdf/2510.02227), [HTML](https://arxiv.org/abs/2510.02227)
### Authors
Xiaoyang Yuan,Yujuan Ding,Yi Bin,Wenqi Shao,Jinyu Cai,Jingkuan Song,Yang Yang,Hengtao Shen
### Background
现有的强化学习方法，尤其是在大型语言模型中，主要依赖自我探索或单一离策略教师来触发长链推理，但这种方法可能导致内在模型偏见并限制探索范围，从而限制了推理多样性和性能。
### Innovation
本文提出了一种创新的方法，即‘适应性多指导策略优化’（AMPO），该方法通过多教师模型的指导来扩展探索范围，同时保留自我发现的价值。AMPO还引入了基于理解的选择机制，引导学生在最有可能理解的推理路径中学习，从而平衡广泛探索和有效利用。实验表明，AMPO在数学推理任务中比强基线GRPO提高了4.3%，在分布外任务中提高了12.2%，显著提升了Pass@k性能，并促进了更广泛的探索。通过使用四个相同规模的教师模型，我们的方法实现了与单一更强大教师（如DeepSeek-R1）相比的类似结果，证明了更高效和可扩展的途径以实现更优秀的推理和泛化能力。
### Conclusion
这些结果表明，AMPO为大型语言模型中的强化学习提供了一种更加有效和可扩展的方法，以实现出色的推理和泛化能力。我们的代码已在GitHub上发布。
## 204. `cs.AI` - 如何利用强化学习应对反应式和动态干扰攻击 [PDF](https://arxiv.org/pdf/2510.02265), [HTML](https://arxiv.org/abs/2510.02265)
### Authors
Yalin E. Sagduyu,Tugba Erpek,Kemal Davaslioglu,Sastry Kompella
### Background
该论文研究了如何缓解反应式干扰的问题，其中干扰器采用动态策略选择信道和感知门限来检测和阻断正在进行的传输。在没有先验的信道条件或干扰策略知识的情况下，发射端-接收端对学会通过使用强化学习（RL）来调整发射功率、调制方式和信道选择，以避免干扰并优化吞吐量。
### Innovation
论文利用Q学习处理离散的干扰事件状态，利用深度Q网络（DQN）处理基于接收功率的连续状态。通过不同的奖励函数和动作集，结果表明，RL能够快速适应频谱动态，并在信道和干扰策略随时间改变时保持高传输速率。
### Conclusion
研究表明采用RL的方法可以有效应对反应式和动态干扰攻击，通过调整发射端的行为参数，该方法能适应频谱环境的变化，在面对不同的信道状况和干扰策略时仍能保持高的数据传输效率。
## 205. `cs.AI` - RewardMap：通过多阶段强化学习解决细粒度视觉推理中的稀疏奖励问题 [PDF](https://arxiv.org/pdf/2510.02240), [HTML](https://arxiv.org/abs/2510.02240)
### Authors
Sicheng Feng,Kaiwen Tuo,Song Wang,Lingdong Kong,Jianke Zhu,Huan Wang
### Background
细粒度视觉推理仍然是多模态大语言模型(MLLM)的主要挑战。研究引入的ReasonMap突显了这一差距，显示出即使是先进的MLLM也难以在如公交线路图等结构化和信息丰富环境中进行空间推理。而常规强化学习在这些任务中受困于稀疏奖励和不稳定的优化过程。
### Innovation
我们首先构建了ReasonMap-Plus扩展数据集，通过视觉问答(VQA)任务引入密集奖励信号，以便有效启动细粒度视觉理解技能的训练。接着，我们提出了RewardMap多阶段强化学习框架，旨在提高MLLM的视觉理解和推理能力。RewardMap采用了两项关键设计：引入了难度感知的奖励设计与细节奖励相结合，直接解决稀疏奖励问题并提供更丰富的监督；提出了一个多阶段强化学习方案，从简单的感知任务逐步过渡到复杂的推理任务，提供了一个比传统监督微调(SFT)更有效的冷启动策略。
### Conclusion
实验结果表明，每个组成部分都对性能表现有所贡献，而它们的结合使得效果最佳。使用RewardMap训练的模型在6个涵盖空间推理、细粒度视觉推理和超出公交线路图任务的基准测试中平均提升了3.47%，证明了改进的视觉理解和推理能力。
## 206. `cs.AI` - ExGRPO：从经验中学习推理 [PDF](https://arxiv.org/pdf/2510.02245), [HTML](https://arxiv.org/abs/2510.02245)
### Authors
Runzhe Zhan,Yafu Li,Zhi Wang,Xiaoye Qu,Dongrui Liu,Jing Shao,Derek F. Wong,Yu Cheng
### Background
RLVR（通过可验证奖励的强化学习）是一个新兴的用于提升大型语言模型推理能力的范式。然而，标准的在线训练方式在每次更新后会丢弃Rollout经验，导致计算效率低下和模型不稳定。尽管之前的强化学习工作中强调了利用过往经验的好处，但对于大型推理模型学习动态中的经验特征作用仍未有深入的探索。因此，该研究旨在探讨哪些经验价值更高，并确定卷积正确性和熵作为有效经验价值指标。基于此，研究提出了一种名为ExGRPO（Experiential Group Relative Policy Optimization）的框架，该框架组织和优先级排序有价值的经验，并使用混合策略目标平衡探索与经验利用。
### Innovation
该研究首次定义了经验价值的概念，并利用卷积正确性和熵作为指标。进一步，研究提出了一种名为ExGRPO的框架，该框架可以组织并优先级排序有价值的经验，并采用混合策略目标来平衡探索与经验利用。在五种基础模型（参数量从1.5B到8B）上进行的实验表明，ExGRPO能够持续提升推理表现，在数学/通用基准测试中提高了平均3.5/7.6个点，并且在更强和更弱的模型上均能稳定训练，相比之下在线方法在这种模型上难以取得稳定的训练效果。这些结果强调了有序的经验管理是RLVR高效和可扩展的关键因素。
### Conclusion
该研究的结果表明，ExGRPO在提升大型语言模型推理能力方面表现出色，并且对不同规模的基础模型都有稳定的训练效果，从而表明有序的经验管理是关键因素，能够促进RLVR的高效和可扩展性。
## 207. `cs.AI` - DragFlow：使用区域监督释放DiT先验的拖拽编辑 [PDF](https://arxiv.org/pdf/2510.02253), [HTML](https://arxiv.org/abs/2510.02253)
### Authors
Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong
### Background
基于拖拽的图像编辑长期以来受到目标区域失真的困扰，这是因为早期基础模型Stable Diffusion的先验不足以将优化的潜在空间投影回自然图像流形。随着从基于UNet的DDPMs转变为更具扩展性和流匹配能力的DiT（例如SD3.5和FLUX），生成先验变得更强，这使得各种编辑任务都能取得进展。然而，基于拖拽的编辑尚未从这些更强的先验中受益。
### Innovation
本文提出了第一个有效利用FLUX丰富先验的框架——DragFlow，有效地改善了基于拖拽的编辑效果。DragFlow通过引入区域为基础的编辑范式来克服直接应用点为基础的拖拽编辑到DiT的局限性，这种方法利用仿射变换提供更丰富和一致的特征监督。此外，通过结合预训练的开放域个性化适配器（例如IP-Adapter）和基于梯度掩码的硬约束来增强主题一致性和保留背景保真度。多模态大型语言模型也被用来解决任务歧义。DragFlow在DragBench-DR和ReD Bench上的广泛实验表明它超过了基于点的和基于区域的基础模型，成为拖拽图像编辑的新基准。
### Conclusion
DragFlow通过区域为基础的监督，克服基于点的直接拖拽编辑在DiT中的不足，有效利用了FLUX的先验，实现了在拖拽编辑方面的显著改进，并通过公开代码和数据集进一步促进了研究的发展。
## 208. `cs.AI` - 平行扩展法则：通过跨语言视角揭示推理泛化的规律 [PDF](https://arxiv.org/pdf/2510.02272), [HTML](https://arxiv.org/abs/2510.02272)
### Authors
Wen Yang,Junhong Wu,Chong Li,Chengqing Zong,Jiajun Zhang
### Background
最近在推理后训练（RPT）方面的进步显著增强了大型推理模型（LRMs）的能力，引起了对基于强化学习（RL）的推理泛化的普遍关注。现有研究主要集中在任务或模态之间的泛化，但该研究提出了一种新的跨语言视角来探讨推理泛化能力，即英语RPT获得的推理能力能否有效地转移到其他语言中。
### Innovation
该研究通过系统评估英语为中心的LRMs在多语言推理基准上的表现，并引入了一个衡量跨语言转移性的度量标准，发现了跨语言转移性在初始模型、目标语言和训练范式之间存在显著差异。研究发现具有更强初始英语能力的模型容易依赖于特定于英语的模式，导致跨语言泛化的减弱。进一步的实验揭示了从单一语言到单一平行语言时性能的显著提升（First-Parallel Leap），以及随着训练平行语言数量增加而性能变化的幂律关系（Parallel Scaling Law），并定义了单语泛化缺口（Monolingual Generalization Gap）来指出英语为中心的LRMs未能完全跨语言泛化的现象。
### Conclusion
本研究挑战了LRMs推理与人类认知相匹配的假定，提供了关于开发更不依赖于特定语言的LRMs的重要见解。通过跨语言视角的研究，揭示了推理泛化的规律性，并提出了改进和优化多语言推理模型的重要方向。
## 209. `cs.AI` - VideoNSA: Native Sparse Attention Scales Video Understanding [PDF](https://arxiv.org/pdf/2510.02295), [HTML](https://arxiv.org/abs/2510.02295)
### Authors
Enxin Song,Wenhao Chai,Shusheng Yang,Ethan Armand,Xiaojun Shan,Haiyang Xu,Jianwen Xie,Zhuowen Tu
### Background
现有的多模态语言模型在视频理解方面受到上下文长度的限制，这使得他们在处理长视频时往往无法捕捉关键的过渡帧，并且难以保持长时间尺度上的连贯性。
### Innovation
本研究通过将Native Sparse Attention (NSA)应用到视频-语言模型中，提出了一种名为VideoNSA的方法来改进视频理解。通过端到端训练Qwen2.5-VL模型，并采用硬件感知的混合注意机制，VideoNSA在长视频理解、时间推理和空间基准测试中表现出优于传统的令牌压缩和无训练的稀疏基线方法。
### Conclusion
研究结果表明，VideoNSA方法在长视频理解、时间推理和空间基准任务上取得了更好的表现，并揭示了四个关键发现：(1)对128K标记的可靠扩展；(2)在固定预算下最佳的全局与局部注意分配；(3)任务相关的分支使用模式；(4)可学习的组合稀疏注意力帮助诱导动态注意力吸收点。
## 210. `cs.AI` - 基于物理导向的视频扩散学习生成对象交互 [PDF](https://arxiv.org/pdf/2510.02284), [HTML](https://arxiv.org/abs/2510.02284)
### Authors
David Romero,Ariana Bermudez,Hao Li,Fabio Pizzati,Ivan Laptev
### Background
近年来，视频生成模型有了显著的进步，并被应用于电影、社交媒体制作和广告领域。除了其巨大的创造性潜力，这些模型还可以作为机器人学和具身决策的虚拟世界模拟器。然而，当前方法在生成物理上合理的物体交互方面仍然存在问题，并缺乏基于物理的控制机制。
### Innovation
本文提出了KineMask，一种物理导向的视频生成方法，它可以实现真实的刚体控制、互动和效果。该方法通过单一图像和指定的物体速度生成带有推断运动和未来物体互动的视频。研究通过两阶段训练策略和未来运动监督逐渐去除对象掩码来训练视频扩散模型（VDM），并在合成场景中展示了物体交互的显著改进。此外，KineMask 结合了低级运动控制和高级文本条件，通过预测场景描述有效支持复杂动力现象的合成。实验结果表明，KineMask 在可比规模的模型中取得了显著改进，并强调了低级和高级条件对VDM的互补作用。
### Conclusion
本文通过KineMask 提出了物理导向的视频生成方法，该方法能够生成物理上合理的物体交互和动态效果，在合成和真实场景中表现出了显著的优势，为未来类似领域的研究提供了强有力的支持。
## 211. `cs.AI` - 利用单目视频进行运动学评估的道路：基于日常生活活动的先进深度学习三维人体姿态估计器与惯性传感器的预临床基准比较 [PDF](https://arxiv.org/pdf/2510.02264), [HTML](https://arxiv.org/abs/2510.02264)
### Authors
Mario Medrano-Paredes,Carmen Fernández-González,Francisco-Javier Díaz-Pernas,Hichem Saoudi,Javier González-Alonso,Mario Martínez-Zarzuela
### Background
机器学习和穿戴式传感器的进步为在普通实验室外捕捉和分析人类运动提供了新的机会。在真实世界条件下准确评估人类运动对远程医疗、体育科学和康复至关重要。这项前临床基准研究对比了基于单目视频的3D人体姿态估计模型与惯性测量单元(IMUs)，使用VIDIMU数据集，该数据集包含13项与临床相关的日常活动，这些活动使用商品级视频相机和五个IMUs捕捉。初始研究仅记录了健康受试者，因此结果无法推广到病理群体。
### Innovation
研究利用了当前最先进的深度学习框架（MotionAGFormer、MotionBERT、MMPose 2D-to-3D姿态提升和NVIDIA BodyTrack）对人体关节角度进行估计，并将其与从IMU数据中计算的人类3.6M数据集格式下的17个关键点进行比较。MotionAGFormer表现出色，整体RMSE最低（$9.27° textpm 4.80°$），MAE最低（$7.86° textpm 4.18°$），同时皮尔森相关系数最高（$0.86 textpm 0.15$），确定性系数$R^{2}$最高（$0.67 textpm 0.28$）。研究结果表明，两种技术可用于体外动力学评估。但也指出了视频和传感器方法之间的重要权衡，包括成本、便捷性和精度。
### Conclusion
这项研究澄清了在健康成人中，哪些现成的视频模型能提供临床上令人满意的运动学，并在哪些方面落后于基于IMU的估计，同时为研究人员和临床医生提供有价值的研究指南，以开发稳健、成本效益高且用户友好的远程健康和远程患者监测解决方案。
## 212. `cs.AI` - microCLIP: 通过粗细粒度token融合的无监督CLIP适应性方法在细粒度图像分类中的应用 [PDF](https://arxiv.org/pdf/2510.02270), [HTML](https://arxiv.org/abs/2510.02270)
### Authors
Sathira Silva,Eman Ali,Chetan Arora,Muhammad Haris Khan
### Background
在细粒度图像分类任务中，无监督适配基于CLIP的视觉-语言模型（VLMs）需要高度对微小局部特征敏感。尽管CLIP在零样本迁移方面表现出色，但其对粗大全局特征的依赖限制了在细粒度分类任务中的性能。先前的努力通过将大型语言模型（LLM）描述与CLIP的[CLS]标记对齐来注入细粒度知识，然而这一方法忽视了空间精度。
### Innovation
本文提出了一种称为microCLIP的自训练框架，该框架利用细粒度提示同时精炼CLIP的视觉和文本表示。引入了Saliency-Oriented Attention Pooling（SOAP）和一个轻量级TokenFusion模块，后者从patch嵌入中构建一个空间指导的[FG]标记，并将其与全局[CLS]标记融合以实现粗细粒度对齐。此外，提出了一种双重头LLM衍生分类器：一个冻结分类器通过多视图对齐提供稳定的文字先验，用于伪标签，另一个可学习分类器从LLM描述初始化并结合TokenFusion微调。进一步发展了动态知识聚合，将固定LLM/CLIP先验与TokenFusion的演化logits凸组合以迭代地精炼伪标签。这些组件共同揭示了CLIP中的隐含细粒度信号，获得了13个细粒度基准上2.90%的一致性平均准确度增益，仅需轻微调整。
### Conclusion
这些方法在细粒度图像分类任务中表现出优越性，为CLIP适应性提供了新的视角，同时仅需轻量级调整便能获得显著提升。
## 213. `cs.AI` - InfoMosaic-Bench: 评估工具增强代理中的多源信息搜索 [PDF](https://arxiv.org/pdf/2510.02271), [HTML](https://arxiv.org/abs/2510.02271)
### Authors
Yaxin Du,Yuanshuo Zhang,Xiyuan Yang,Yifan Zhou,Cheng Wang,Gongyi Zou,Xianghe Pang,Wenhao Wang,Menglan Chen,Shuo Tang,Zhiyu Li,Siheng Chen
### Background
人类的信息寻找需求是基本的。现有语言模型代理主要依赖于开放网络搜索，这有两个根本弱点：网络内容嘈杂且不可靠，许多实际任务需要精确的专业知识而这些知识无法从网络上获得。Model Context Protocol (MCP) 的出现使得代理能够与数千种专业工具接口，理论上解决了这个限制。然而，尚不清楚这些代理是否能有效利用这些工具，特别是它们是否可以将这些工具与通用搜索结合起来解决复杂任务。因此，提出了 InfoMosaic-Bench，这是第一个专门针对工具增强代理中多源信息搜索的基准测试。InfoMosaic-Bench 覆盖了六个代表性领域（医学、金融、地图、视频、网络和多领域集成），要求代理结合通用搜索和领域特定工具。
### Innovation
引入了 InfoMosaic-Bench，这是第一个专门针对工具增强代理中多源信息搜索的基准测试。它利用 InfoMosaic-Flow 设计的可扩展管道，将任务条件基于验证的工具输出，强制执行跨源依赖关系，并筛选出可以通过简单查找解决的捷径情况。该设计保证了可靠性和非平凡性。实验表明：仅依靠网络信息是不够的，GPT-5 的准确率只有 38.2% 和通过率为 67.5%；领域工具提供了选择性但不一致的好处，改善了一些领域，但又损害了其他领域；22.4% 的失败案例源于工具的错误使用或选择，这表明现有的语言模型仍然在基本的工具处理上挣扎。
### Conclusion
该研究通过 InfoMosaic-Bench 为评估工具增强代理中的多源信息搜索提供了新的方法。实验发现使用通用搜索和专业工具结合来解决问题是必不可少的，同时展示了语言模型在工具处理上的局限性。
## 214. `cs.AI` - Self-Forcing++: 向分钟级高质量视频生成迈进 [PDF](https://arxiv.org/pdf/2510.02283), [HTML](https://arxiv.org/abs/2510.02283)
### Authors
Justin Cui,Jie Wu,Ming Li,Tao Yang,Xiaojie Li,Rui Wang,Andrew Bai,Yuanhao Ban,Cho-Jui Hsieh
### Background
扩散模型在图像和视频生成方面取得了前所未有的视觉质量，但其依赖于变压器架构导致计算成本极高，尤其是在生成长视频时尤为明显。近期研究探索了自回归形式的长视频生成方法，通常通过短时向量的双向教师模型提取信息。然而，由于教师模型无法合成长视频，学生模型在超出训练时间范围的扩展生成中，其质量往往急剧下降，主要是由于不断累积的错误导致。
### Innovation
本文提出了一种简单而有效的方法，以在无需来自长视频教师的监督或重新训练于长视频数据集上的前提下，减轻长视频生成中的质量下降问题。该方法通过自我生成长视频中抽样片段，利用教师模型丰富的知识为学生模型提供指导。这种方法不仅保持了时间一致性，还使视频长度扩展了教师模型能力的20倍以上，避免了过度曝光和错误累积等常见问题，而且在计算扩展时，能够生成长达4分钟15秒的视频，是基础模型位置嵌入支持的最大跨度的99.9%，相比于基线模型长出50倍。
### Conclusion
实验表明，我们的方法在保真度和一致性方面显著优于基线方法。我们的长时间视频演示可以在以下链接找到：this https URL
## 215. `cs.AI` - F2LLM技术报告：使用600万开源数据匹配SOTA嵌入性能 [PDF](https://arxiv.org/pdf/2510.02294), [HTML](https://arxiv.org/abs/2510.02294)
### Authors
Ziyin Zhang,Zihan Liao,Hang Yu,Peng Di,Rui Wang
### Background
介绍了F2LLM - 从基础模型到特征大语言模型，这是一种包含三类规模的最先进嵌入模型套件：0.6B、1.7B和4B。与此前需要大规模对比预训练、复杂训练管道和昂贵的合成训练数据的顶级嵌入模型相比，F2LLM直接从基础模型微调600万个查询-文档-负面元组的自采集非合成数据集，从而在训练成本、模型规模和嵌入性能之间取得了良好的平衡。
### Innovation
F2LLM直接从基础模型进行微调，使用来自开源非合成数据集的600万个元组进行训练，避免了以往需要大规模对比预训练、复杂训练流程和昂贵合成数据的方法。这在保持高性能的同时降低了训练成本和模型规模。
### Conclusion
在MTEB英语领导者板上，F2LLM-4B在大约4亿参数的模型中排名第二，在总排名中排名第7，而F2LLM-1.7B在1-2亿参数范围内的模型中排名第一。为了促进未来在此领域的研究，我们已发布模型、训练数据集和代码，定位F2LLM作为未来工作的强大、可重复和成本效益高的基线。
## 216. `cs.AI` - 交互式训练：具有反馈驱动的神经网络优化 [PDF](https://arxiv.org/pdf/2510.02297), [HTML](https://arxiv.org/abs/2510.02297)
### Authors
Wentao Zhang,Yang Young Lu,Yuntian Deng
### Background
传统神经网络训练通常遵循固定的优化步骤，缺乏在不稳定或新的训练问题出现时做出动态响应的灵活性。
### Innovation
本文提出了交互式训练框架，这是一种开源框架，它允许专家或自动化AI代理在训练过程中实时响应反馈进行干预。交互式训练的核心是控制服务器，它在用户或代理与正在进行的训练过程之间进行沟通，允许用户动态调整优化器超参数、训练数据和模型检查点。
### Conclusion
通过三个案例研究，我们展示了交互式训练在提高训练稳定性和适应性方面的优势，以及对不断变化的需求有更好的适应性，这为未来的训练模式铺平了道路，在这种模式下，AI代理可以自主监控训练日志并主动解决不稳定问题，优化训练动态。
## 217. `cs.AI` - 无需扩展的A*搜索：使用深度Q网络学习启发式函数 [PDF](https://arxiv.org/pdf/2102.04518), [HTML](https://arxiv.org/abs/2102.04518)
### Authors
Forest Agostinelli,Shahaf S. Shperberg,Alexander Shmakov,Stephen McAleer,Roy Fox,Pierre Baldi
### Background
在具有大型动作空间的问题中，A*搜索的有效求解仍然是一项挑战。这是因为每次A*搜索迭代中，生成的节点数目和启发式函数的应用次数会线性增长，这会随着动作空间规模的增加而变得更加明显。尤其当A*搜索使用通过计算密集的功能逼近器（如深层神经网络）学习的启发式函数时，负担更加突出。
### Innovation
本文引入了一种名为Q*的搜索算法，该算法利用能够一次性接收一个状态并返回所有可能状态转移的剩余成本估计（包括成本）的启发式函数，而无需实际执行转移或生成后继状态。这大大减少了计算时间和内存使用。此外，证明了在不会高估状态总转移成本和剩余成本的情况下，Q*搜索能够找到最短路径。通过采用深层Q网络架构，学会了无需先验知识即可从环境交互中学习状态-动作启发式函数。
### Conclusion
通过Q*算法与我们学习的启发式函数在不同领域和动作空间上进行实验，结果表明，随着动作空间的增加，Q*算法的运行时间开销很小。此外，实验证明，Q*搜索比A*搜索快至129倍，并生成至1288倍少的节点数。
## 218. `cs.AI` - 基于树结构对话的强化策略优化以进行红队攻击 [PDF](https://arxiv.org/pdf/2510.02286), [HTML](https://arxiv.org/abs/2510.02286)
### Authors
Ruohao Guo,Afshin Oroojlooy,Roshan Sridhar,Miguel Ballesteros,Alan Ritter,Dan Roth
### Background
尽管AI安全领域取得了快速进展，但现有的大型语言模型在多轮对话场景中仍然容易受到恶意攻击。攻击者会战略性地调整其提示，并在对话过程中展示出愈发严峻且现实的挑战。当前的研究大多依赖手动红队测试，或是使用预定义模板和人工收集的数据进行自动化的攻击发现，大多数方法集中在单轮攻击上。然而，这些方法未能全面探索可能的多轮攻击空间，未能考虑到由于对话动态复杂性和策略对话规划而产生的新颖攻击路径。鉴于最近的发现表明，LLMs在面对多轮攻击时的脆弱性远高于单轮攻击，这就需要新的方法来填补这一空白。
### Innovation
本文提出了DialTree-RPO，这是一种结合树搜索的在线强化学习框架，用于自主发现多种多轮攻击策略。通过将对话视为顺序决策问题，该方法能够系统地进行探索，无需手动标注数据。相较于之前的最优方法，我们的方法不仅在10个目标模型上实现了超过25.9%的高成功率，在攻击成功率方面也取得了显著提高，并通过学习最优对话策略发现了新的攻击策略。
### Conclusion
本文提出的方法不仅在多轮攻击成功率上取得显著提高，还发现了一系列新的攻击策略。这表明我们的方法能够在多轮对话下自动化发现高成功率的攻击策略，对未来AI安全研究具有重要意义。
## 219. `cs.AI` - 解决自然语言生成中不确定性估计方法评估中的问题 [PDF](https://arxiv.org/pdf/2510.02279), [HTML](https://arxiv.org/abs/2510.02279)
### Authors
Mykyta Ielanskyi,Kajetan Schweighofer,Lukas Aichberger,Sepp Hochreiter
### Background
大型语言模型（LLMs）中的幻觉问题是影响其可靠性的常见因素。现有研究识别出一种特定类型的幻觉，称为虚构叙述，它源于LLMs的预测不确定性。目前用于检测虚构叙述的方法通常通过将不确定性估计与生成文本的正确性相关联来评估，常用的基准是问答（QA）数据集。然而，这些常用的近似正确性函数在不同方法间存在显著分歧，影响了对不确定估计方法性能的评估。
### Innovation
本文提出使用几种替代的风险指标来提高不确定性估计算法的实证评估的稳健性。对于问答任务，作者表明通过综合多个LLM评估变体可以减少评估偏差。此外，作者探索了结构化任务以及离分布和扰动检测任务，以提供更加稳健和可控的风险指标，并提出使用不确定估计方法的 Elo 棋评系统来在广泛的评估环境中给出客观总结。
### Conclusion
本文提出的替代风险指标和评估方法提高了对自然语言生成中不确定性估计方法性能评估的可靠性，并通过 Elo 棋评系统提供了一种客观且全面的总结方法。
## 220. `cs.AI` - 迈向端到端ASP计算 [PDF](https://arxiv.org/pdf/2306.06821), [HTML](https://arxiv.org/abs/2306.06821)
### Authors
Taisuke Sato,Akihiro Takemura,Katsumi Inoue
### Background
该研究提出了一个端到端的方法，结合了线性代数和回答集编程（ASP），以计算满足给定约束的稳定的模型。研究者旨在通过在向量空间中直接实现林- Zhao定理及其约束条件来最小化一个构造自矩阵化的标准逻辑程序、林- Zhao定理中的环公式以及约束条件的成本函数，从而无需使用符号ASP或SAT求解器。此外，还提出了一种预计算方法来缩小程序规模和对环公式使用启发式方法以降低计算难度.
### Innovation
该方法的核心创新在于直接将林- Zhao定理与约束条件在向量空间中计算最小化成本函数，无需使用符号化的ASP或SAT求解器。此外，提出了一种预计算方法来缩小程序规模和对环公式使用启发式方法以降低计算难度.
### Conclusion
研究通过编程样例，包括3着色和哈密顿回路问题，对提出的端到端ASP计算方法进行了实证测试，证明了该方法的有效性和优越性.
## 221. `cs.AI` - XAI解释中的理解形式 [PDF](https://arxiv.org/pdf/2311.08760), [HTML](https://arxiv.org/abs/2311.08760)
### Authors
Hendrik Buschmeier,Heike M. Buhl,Friederike Kern,Angela Grimminger,Helen Beierling,Josephine Fisher,André Groß,Ilona Horwath,Nils Klowait,Stefan Lazarov,Michael Lenke,Vivien Lohmer,Katharina Rohlfing,Ingrid Scharlau,Amit Singh,Lutz Terfloth,Anna-Lisa Vollmer,Yu Wang,Annedore Wilmes,Britta Wrede
### Background
可解释性已成为计算机科学和人工智能领域的重要话题，催生了可解释人工智能（XAI）这一子领域。尽管提供或寻求解释是为了实现解释对象的‘理解’，但‘理解’的确切含义仍不明确，且相关概念很少成为科学研究的对象。本文旨在从计算机科学、语言学、社会学、哲学和心理学等多学科角度，探讨XAI解释中的理解形式及其评估和动态过程。
### Innovation
本文创新性地定义了理解形式，并将其应用于XAI解释中，分为浅层理解和深层理解两种类型。进一步探讨了通过解释提高人们在特定领域的浅层理解和深层知识的作用，强调这种进步是提高人类用户主动性的必要条件。这种方法有助于解释和理解XAI中的理解挑战并对这些挑战进行系统化分析。
### Conclusion
解释过程中的理解层次和动态是高度相互依赖的，XAI中理解和解释的能力培养是一个系统化过程。
## 222. `cs.AI` - 扩散模型与流形假设：对数域平滑是几何适应的 [PDF](https://arxiv.org/pdf/2510.02305), [HTML](https://arxiv.org/abs/2510.02305)
### Authors
Tyler Farghly,Peter Potaptchik,Samuel Howard,George Deligiannidis,Jakiw Pidstrigach
### Background
扩散模型已经在各种领域取得了最先进的性能，展示了出色的泛化能力。然而，这些强大能力背后的机制仍然部分未解。基于流形假设的猜想认为，扩散模型的成功在于其能够适应数据中的低维几何结构。本文则进一步探讨这种现象如何通过评分匹配学习问题的表述机制得以体现，通过研究评分匹配经验目标的平滑化效果，来验证这一猜想。
### Innovation
本文通过研究评分匹配经验目标的平滑化效果，验证了扩散模型的成功来源于其适应数据中低维几何结构的能力。证明了平滑评分函数（等价于对密度对数域的平滑）能够沿着数据流形产生平滑效果。此外，还展示了通过选择适当的平滑方式可以控制扩散模型的泛化流形。
### Conclusion
研究表明，通过适当的平滑处理来控制评分函数的性质，能够引导扩散模型更有效地学习数据的几何结构，从而实现更好的泛化能力。
## 223. `cs.AI` - Equilibrium Matching：基于隐式能量模型的生成建模 [PDF](https://arxiv.org/pdf/2510.02300), [HTML](https://arxiv.org/abs/2510.02300)
### Authors
Runqian Wang,Yilun Du
### Background
本研究旨在改进现有的生成模型，特别是扩散和流基生成模型。这些传统模型依赖于非平衡、时间有条件的动力学，而非基于系统所达到的平衡状态。这种非平衡动力学导致在生成高质量样本时存在挑战。
### Innovation
EqM从平衡动力学的角度引入了一个生成建模框架，摒弃了传统的非平衡时间条件动力学，而是学习隐式能量景观的平衡梯度。这种框架使得模型在推断过程中可以通过梯度下降进行优化采样，通过自适应步长、优化器和计算资源，获得高质量的样本。与扩散和流基模型相比，EqM在性能上表现出色，在ImageNet 256×256数据集上实现了1.90的FID分数。此外，EqM通过隐式能量模型提供了流与能量模型之间的紧密联系，并提供了一种通过优化进行推断的简化路径。
### Conclusion
EqM不仅在生成任务中表现优异，实现了卓越的生成性能，还在理论上证明了其能够学习和从数据流形中采样。这一框架还为包括部分噪声图像去噪、OOD检测和图像合成等多种任务提供了灵活性。通过统一的平衡景观替代了时间条件的速度，EqM为流模型和能量模型之间的连接提供了一个更紧凑的桥梁，并提供了一条优化驱动推断的简单路径。
## 224. `cs.AI` - 使用机器学习方法针对一般行为代理进行目标识别设计 [PDF](https://arxiv.org/pdf/2404.03054), [HTML](https://arxiv.org/abs/2404.03054)
### Authors
Robert Kasumba,Guanghui Yu,Chien-Ju Ho,Sarah Keren,William Yeoh
### Background
目标识别设计（GRD）旨在通过有限的修改使决策环境更易于推断代理在其内执行的意图。尽管在目标识别设计方面已经进行了大量研究，但现有方法在计算上仍具有挑战性，并且通常假定代理在其决策中是接近最优的。
### Innovation
该研究利用机器学习方法进行目标识别设计，提高实时效率并考虑具有通用行为模型的代理。该方法通过训练机器学习模型预测给定环境和代理行为模型的最坏情况显著度（wcd），并提出基于梯度的优化框架来优化决策环境以增强目标识别。该方法在多种约束条件下有效，并适用于成本灵活性、复杂环境和非最优行为等现有方法不适用的场景。此外，实验证明该方法在减少wcd和提高运行效率方面优于现有方法。
### Conclusion
该研究通过广泛仿真证明了其方法的优势，并通过人类行为实验进一步证明所设计的环境有助于人类决策者的高效目标识别应用。
## 225. `cs.AI` - 通过自我意识保护LLMs [PDF](https://arxiv.org/pdf/2508.02961), [HTML](https://arxiv.org/abs/2508.02961)
### Authors
Boshi Huang,Fabio Nonato de Paula
### Background
当前，大型语言模型（LLMs）面临来自提示注入攻击的挑战。传统的防御方法依赖外部分类器，而这种方法提出了一个创新的自我保护机制，利用LLMs本身的能力来进行自我评估和调节。
### Innovation
该研究提出了一种结合元认知模块和仲裁模块的框架，使LLMs能够自主评估和调节输出。这种方法在七个最先进的LLMs上进行了评估，并证明在各个模型和数据集上显著提高了防御成功率。并且，该方法在计算开销低的情况下提供了保护LLMs的有效轻量级解决方案。
### Conclusion
该自我意识方法为LLMs的伦理提升提供了经济有效的解决方案，并特别适用于各种平台上GenAI的使用案例。同时，研究也分析了提高防御成功率与计算开销之间的权衡。
## 226. `cs.AI` - 从表格数据进行神经符号关联规则挖掘 [PDF](https://arxiv.org/pdf/2504.19354), [HTML](https://arxiv.org/abs/2504.19354)
### Authors
Erkan Karabulut,Paul Groth,Victoria Degeler
### Background
关联规则挖掘（ARM）的任务是从数据特征中发掘以逻辑规则形式呈现的模式，在众多领域都有广泛应用。然而，高维数据集通常会导致规则数量过多，增加执行时间并影响下游任务性能。管理这种规则爆炸仍是ARM研究中的核心挑战。
### Innovation
我们提出了Aerial+，一种新颖的神经符号ARM方法。Aerial+利用欠完全的自编码器创建数据的神经表示，捕捉特征之间的关联。它通过利用模型的重构机制从这种神经表示中提取规则。通过对五个数据集和七个基线的广泛评估表明，Aerial+通过学习更加简洁且高质量的规则集实现了最佳结果，并且覆盖了所有数据。在基于规则的可解释机器学习模型中集成Aerial+可以显著减少执行时间，同时保持或提升准确率。
### Conclusion
Aerial+在五个数据集上与七个基线的对比实验中展示了其学习简洁且高质量规则集的能力，覆盖全部数据，集成了Aerial+的可解释机器学习模型能显著减少执行时间并保持或提升其准确率。
## 227. `cs.AI` - AgentDAM：自主网络代理的隐私泄露评估 [PDF](https://arxiv.org/pdf/2503.09780), [HTML](https://arxiv.org/abs/2503.09780)
### Authors
Arman Zharmagambetov,Chuan Guo,Ivan Evtimov,Maya Pavlova,Ruslan Salakhutdinov,Kamalika Chaudhuri
### Background
自主AI代理能够遵循指令并执行复杂的多步骤任务，具有显著提升人类生产力的潜力。然而，要执行许多这些任务，代理需要访问其用户的个人资料信息，这就提出了一个是否能够合理使用这些信息的问题。本文介绍了一个新的基准AgentDAM，用于衡量AI网络导航代理是否遵循最小化数据使用的隐私原则。数据最小化指的是，代理在完成特定任务时只在“必要”时使用可能存在敏感性的信息。基准模拟了从头到尾的现实网络交互场景，适用于所有现有的网络导航代理。通过AgentDAM，评估基于GPT-4、Llama-3和Claude构建的AI代理如何限制处理潜在私人信息，并展示了这些代理在资源利用上会无意中使用不必要的敏感信息。本文还提出了基于提示的防御方法来减少信息泄露，并证明端到端基准测试比对大型语言模型进行探测来评估隐私更为现实。研究结果指出，需要进一步研究来开发能够优先考虑数据最小化的AI代理，以应对推理时的问题。
### Innovation
提出了一个新的基准AgentDAM，用于评估AI网络导航代理是否遵循最小化数据使用的隐私原则。基准测试可以模拟从头到尾的现实网络交互场景。评估了基于GPT-4、Llama-3和Claude构建的AI代理如何限制处理潜在私人信息，并提出了基于提示的防御方法来减少信息泄露。
### Conclusion
提出的新基准提供了一个更真实的度量标准，表明现有的AI代理在资源利用上会无意中使用不必要的敏感信息。基于提示的防御方法可以减少信息泄露。进一步研究需要开发能够在推理时优先考虑数据最小化的AI代理。
## 228. `cs.AI` - NoiseShift: 解析模型中的分辨率感知噪声重新校准以改善低分辨率图像生成 [PDF](https://arxiv.org/pdf/2510.02307), [HTML](https://arxiv.org/abs/2510.02307)
### Authors
Ruozhen He,Moayed Haji-Ali,Ziyan Yang,Vicente Ordonez
### Background
文本到图像的生成模型在固定分辨率集上训练时，常常不能很好地泛化，即使被要求生成低于训练分辨率的图像也是如此。目前，高分辨率的文本到图像生成器为那些不需要高分辨率图像的用户提供了一种预算友好的替代方案，但仍存在难度。研究指出，扩散模型中噪声调度器在不同分辨率下的感知效果不均衡是关键技术问题，即同样的噪声对低分辨率图像中的信号影响更大，导致训练和测试之间的不匹配。这一背景揭示了现有模型在低分辨率图像生成方面的局限性，并为改进提供了理论依据和研究方向。
### Innovation
本文提出了一种名为NoiseShift的方法，这是一种无需训练的方案，用于根据分辨率大小调整去噪器中的噪声水平。NoiseShift方法不涉及改变模型架构或采样计划，并且可以与现有模型兼容。实验结果表明，当应用于Stable Diffusion 3、Stable Diffusion 3.5和Flux-Dev时，NoiseShift方法在低分辨率上显著提高了图像质量。在LMACON和CelebA数据集上，NoiseShift方法分别提升了SD3.5、SD3和Flux-Dev的FID分数，平均分别提高了15.89%、8.56%和2.44%，在CelebA数据集上的提升分别为10.36%、5.19%和3.02%。这展示了NoiseShift方法在减少分辨率依赖的伪像并提升低分辨率图像生成质量方面的有效性。
### Conclusion
NoiseShift方法通过解决扩散模型中噪声调度器在不同分辨率下感知效果不均衡的问题，显著提升了低分辨率图像的生成质量，适用于Stable Diffusion和Flux-Dev等生成模型，且无需对模型架构或训练过程进行修改。
## 229. `cs.AI` - MathArena：在未被污染的数学竞赛中评估LLMs [PDF](https://arxiv.org/pdf/2505.23281), [HTML](https://arxiv.org/abs/2505.23281)
### Authors
Mislav Balunović,Jasper Dekoninck,Ivo Petrov,Nikola Jovanović,Martin Vechev
### Background
大型语言模型（LLMs）的推理能力迅速提升，导致在数学基准测试中的显著改进。但常用评估数据集（如AIME 2024）普遍可在线获取，这使得区分真正的推理能力与潜在的记忆能力变得困难。此外，这些基准测试并未评估证明写作能力，这对于许多数学任务至关重要。
### Innovation
提出了一种新的基准——MathArena，基于关键洞察：反复出现的数学竞赛提供了高质量、具有挑战性的试题流，可用于实时评估LLM。通过在新问题发布时即刻评估模型，可以有效消除污染风险。此外，这是第一个评估证明写作能力的基准，并且首次在IMO 2025上对最优秀模型进行了评估。
### Conclusion
在IMO 2025上，最优秀的模型仅达到约40%的得分，展示了显著的进步和大幅改进的空间。我们已经评估了超过50个模型，在七个竞赛中总计处理了162个问题。作为不断演化的基准，MathArena将继续跟踪新发布的竞赛中LLMs的进度，确保数学推理的严格和最新评估。
## 230. `cs.AI` - 使用大型语言模型为大型知识图谱生成模式 [PDF](https://arxiv.org/pdf/2506.04512), [HTML](https://arxiv.org/abs/2506.04512)
### Authors
Bohui Zhang,Yuan He,Lydia Pintscher,Albert Meroño Peñuela,Elena Simperl
### Background
本体在确保语义网和自然语言处理中的数据质量和提高可用性方面发挥重要作用，但传统上其创建需要大量知识工程师和领域专家的参与。利用大型语言模型（LLMs）在本体工程中的强大能力，本文探索了使用LLMs生成模式的方法。因此，填补了资源缺口，引入了两个数据集：YAGO模式和维基数据实体模式，以及新的评估指标。
### Innovation
本文利用了大型语言模型（LLMs）在本体工程中的能力，引入了YAGO Schema和Wikidata EntitySchema两个数据集，以及新的评估指标。LLMs利用知识图谱（KGs）的局部和全局信息生成了Shape Expressions（ShEx）模式。实验证明LLMs在生成高质量的ShEx模式方面具备强大潜力，为大规模KG的自动化模式生成铺平了道路。并且，我们的基准测试引入了结构生成的新挑战，推动了LLMs在语法丰富的形式化语言上的极限.
### Conclusion
实验结果证明了使用LLMs进行模式生成的强大潜力，并引入了两个新的数据集与评估指标，这将有助于推动大规模KG领域中模式生成的自动化的进一步发展，同时也为LLMs在复杂形式化语言上的应用提出了新的挑战。
## 231. `cs.AI` - DrKGC：跨通用和生物医学领域的动态子图检索增强LLMs的知识图谱补全 [PDF](https://arxiv.org/pdf/2506.00708), [HTML](https://arxiv.org/abs/2506.00708)
### Authors
Yongkang Xiao,Sinian Zhang,Yi Dai,Huixue Zhou,Jue Hou,Jie Ding,Rui Zhang
### Background
知识图谱补全（KGC）的目标是通过利用现有的三元组和文本信息预测知识图谱中的缺失三元组。最近，生成式大语言模型（LLMs）被越来越多地应用于图任务中，但目前的方法通常将图上下文编码为文本形式，无法充分利用LLMs对图结构进行感知和推理的潜力。为解决这一局限，该文提出了DrKGC（动态子图检索增强LLMs的知识图谱补全），通过灵活的轻量化模型训练策略学习知识图谱中的结构嵌入和逻辑规则，并通过新颖的自底向上的图检索方法提取与规则引导的查询对应子图，最后利用检索到的子图强化结构嵌入，将其集成到提示中以有效地进行LLMs的微调.
### Innovation
DrKGC 采用灵活的轻量化模型训练策略来学习知识图谱中的结构嵌入和逻辑规则，并通过动态子图检索增强方法自底向上的构建图的局部表示，以引导增强逻辑推理和结构感知能力，并将检索到的子图集成到提示中进行有效的LLMs微调，从而提高知识图谱补全的效果.
### Conclusion
实验结果表明，DrKGC 在两个通用领域和两个生物医学领域的基准数据集上的表现优于现有方法。通过生物医学领域的现实案例研究还展示了 DrKGC 的可解释性和实用价值.
## 232. `cs.AI` - 时空多层转换图分解表示学习及其在社交增强POI推荐中的应用 [PDF](https://arxiv.org/pdf/2508.07649), [HTML](https://arxiv.org/abs/2508.07649)
### Authors
Jie Li,Haoye Dong,Zhengyang Wu,Zetao Zheng,Mingrong Lin
### Background
POI推荐是商业智能研究的热点问题，用户的时空迁移和社会关系起关键作用。现有大部分研究分别建模时空迁移，导致相同时空关键节点的表示不一致，这种不一致在融合时引入冗余信息，增加模型不确定性，降低可解释性。
### Innovation
提出了一种基于分解表示学习的时空多层转换图自编码模型DiMuST，该模型结合了多层时空图策略和产品专家机制，同时通过对比约束对私有特征进行消噪，有效捕捉POI的时空迁移表示，同时保留它们的时空关系内在关联，显著优于现有方法。
### Conclusion
通过实验验证，DiMuST在多个指标上显著优于现有方法。
## 233. `cs.AI` - 基于可验证奖励的强化学习隐式激励基础LLMs进行正确推理 [PDF](https://arxiv.org/pdf/2506.14245), [HTML](https://arxiv.org/abs/2506.14245)
### Authors
Xumeng Wen,Zihan Liu,Shun Zheng,Shengyu Ye,Zhirong Wu,Yang Wang,Zhijian Xu,Xiao Liang,Junjie Li,Ziming Miao,Jiang Bian,Mao Yang
### Background
近年来，通过DeepSeek-R1所使用的Group Relative Policy Optimization算法推动了长链条推理（CoT）研究进展，并引起了对强化学习结合可验证奖励（RLVR）潜力的兴趣，特别是对于大型语言模型（LLMs）。尽管RLVR承诺通过允许模型从自由探索中学习来改善推理，但也存在争论，认为它只是提高了采样效率而并未实质上提升推理能力。
### Innovation
本文系统研究了RLVR对LLM推理的影响。引入了新的评估指标CoT-Pass@K，展示了RLVR能够扩展数学和编程任务中的推理边界。通过理论框架解释RLVR的激励机制，揭示了即使奖励来源仅涉及答案正确性，它也能促进正确推理。研究还显示，RLVR在训练初期就激励正确的推理，经过大量评估的推理质量也得到了大幅改善。
### Conclusion
研究结果提供了强烈证据，证明RLVR有潜力增强LLM推理，为其机制和性能改进提供了重要的见解。
## 234. `cs.AI` - 使用表征相似性分析衡量人类与人工智能行为上的一致性的灵活方法 [PDF](https://arxiv.org/pdf/2412.00577), [HTML](https://arxiv.org/abs/2412.00577)
### Authors
Mattson Ogg,Ritwik Bose,Jamie Scharf,Christopher Ratto,Michael Wolmetz
### Background
随着大型语言模型（LLMs）被授权在关键社会和技术决策中发挥作用，衡量这些模型与人类认知的契合度变得至关重要。这就需要能够评估这些系统如何表示信息，并能跨多种任务将它们的表现与人类的理解进行比较的方法。为此，本文作者将表征相似性分析（RSA）的方法进行了调整，该方法通过两两相似性评分来量化人工智能和人类的契合度。
### Innovation
作者使用RSA作为一种双向机制来衡量LLM和VLM在文本和图像模式下与人类认知的一致性。这种方法能够对群体和个体的差异进行量化分析，从而揭示某些超参数和提示可以引导模型行为在个体或群体水平上更接近人类特性。这种方法提供了跨多种模态（单词、句子、图像）测量人类-人工智能一致性的灵活性，补充了现有的基于准确性的度量基准。
### Conclusion
GPT-4o在测试的模型中显示出最强的人类一致性表现，特别是在利用其文本处理能力而不是图像处理时，但在所有输入模态下均未充分反映出人类参与者间的个体差异性。RSA和两两评分法能够有效地和灵活地量化人类-人工智能的一致性，为了解LLM如何编码知识以及与人类认知的表示一致性提供了帮助。
## 235. `cs.AI` - AI+MPS [PDF](https://arxiv.org/pdf/2509.02661), [HTML](https://arxiv.org/abs/2509.02661)
### Authors
Andrew Ferguson,Marisa LaFleur,Lars Ruthotto,Jesse Thaler,Yuan-Sen Ting,Pratyush Tiwary,Soledad Villar,E. Paulo Alves,Jeremy Avigad,Simon Billinge,Camille Bilodeau,Keith Brown,Emmanuel Candes,Arghya Chattopadhyay,Bingqing Cheng,Jonathan Clausen,Connor Coley,Andrew Connolly,Fred Daum,Sijia Dong,Chrisy Xiyu Du,Cora Dvorkin,Cristiano Fanelli,Eric B. Ford,Luis Manuel Frutos,Nicolás García Trillos,Cecilia Garraffo,Robert Ghrist,Rafael Gomez-Bombarelli,Gianluca Guadagni,Sreelekha Guggilam,Sergei Gukov,Juan B. Gutiérrez,Salman Habib,Johannes Hachmann,Boris Hanin,Philip Harris,Murray Holland,Elizabeth Holm,Hsin-Yuan Huang,Shih-Chieh Hsu,Nick Jackson,Olexandr Isayev,Heng Ji,Aggelos Katsaggelos,Jeremy Kepner,Yannis Kevrekidis,Michelle Kuchera,J. Nathan Kutz,Branislava Lalic,Ann Lee,Matt LeBlanc,Josiah Lim,Rebecca Lindsey,Yongmin Liu,Peter Y. Lu,Sudhir Malik,Vuk Mandic,Vidya Manian,Emeka P. Mazi,Pankaj Mehta,Peter Melchior,Brice Ménard,Jennifer Ngadiuba,Stella Offner,Elsa Olivetti,Shyue Ping Ong,Christopher Rackauckas,Philippe Rigollet,Chad Risko,Philip Romero,Grant Rotskoff,Brett Savoie,Uros Seljak,David Shih,Gary Shiu,Dima Shlyakhtenko,Eva Silverstein,Taylor Sparks,Thomas Strohmer,Christopher Stubbs,Stephen Thomas,Suriyanarayanan Vaikuntanathan,Rene Vidal,Francisco Villaescusa-Navarro,Gregory Voth,Benjamin Wandelt,Rachel Ward,Melanie Weber,Risa Wechsler,Stephen Whitelam,Olaf Wiest,Mike Williams,Zhuoran Yang,Yaroslava G. Yingling,Bin Yu,Shuwen Yue,Ann Zabludoff,Huimin Zhao,Tong Zhang
### Background
该论文源自2025年3月召开的NSF人工智能（AI）与数学和物理科学（MPS）未来研讨会，目的是理解如何最好地利用和推动AI在MPS领域（天文学、化学、材料研究、数学科学和物理学）的发展和贡献。在此背景下，论文总结了MPS社区的观点，强调了AI与科学之间的日益紧密联系，强调了加强AI和科学之间的联系的重要性。
### Innovation
论文提出了活动和战略优先项，这些活动和优先项旨在实现双向的AI+MPS研究，建立跨学科的AI+MPS研究社区，并促进MPS研究人员和学生的AI教育和职业发展。
### Conclusion
论文总结了建议的优先事项，旨在帮助MPS社区充分利用AI+MPS的变革潜力。该建议适用于资助机构、教育机构和个人研究者，能够使MPS社区在AI+MPS方面成为领导者。
## 236. `cs.AI` - 利用物理学导向的拒绝抽样对推理LLMs进行材料发现进行对齐 [PDF](https://arxiv.org/pdf/2509.00768), [HTML](https://arxiv.org/abs/2509.00768)
### Authors
Lee Hyun,Sohee Yoon,Jinwoo Park,Sue In Chae,Seongeon Park,Jooyeon Ahn,Yebin Jung,Youjung Chung,Hogeun Chang,Sujin Park,Myeonginn Kang,Jina Kim,Ho-Gyeong Kim,Myeonghun Jeong
### Background
人工智能驱动的材料发现需要将自动实验与算法决策相结合的过程感知配方来预测性能。前人在实现这一点时，主要采用了大型推理模型（LRMs）来作为推理能力的实现途径，通过从教师模型中提取推理痕迹来训练学生模型。然而，现有的训练管道通常使用二元正确的信号或学习的偏好信号来选择推理痕迹，这些信号往往不能充分反映物理可实现性，导致物理约束不足，影响模型性能和效率。
### Innovation
该研究提出了物理学导向的拒绝抽样（Physics-aware Rejection Sampling, PaRS），这是一种在训练时选择推理痕迹的方法，偏好与基本物理条件一致且接近目标的痕迹，并采用轻量级终止控制计算量。此外，通过利用大型教师模型合成推理痕迹来训练一个精细调整的学生模型，并与不同的拒绝抽样基线进行比较，结果表明该方法提高了准确性、校准性和物理可实现性，降低了抽样成本，从而通过结合适度且领域的具体约束和痕迹级选择提供了一条实现可靠、高效LRMs的实用路径，特别适用于过程感知的性能预测和闭环材料设计当中。
### Conclusion
这种方法在准确性和校准性方面优于基线，并显著降低了物理约束违背率和抽样成本。实验结果表明，通过适度的、领域自意识的约束以及精细的推理轨迹选择，能为大型推理模型的开发提供一条实际可行的道路，从而有效提升过程感知的性能预测和闭环材料设计的可靠性与效率。
## 237. `cs.AI` - 超越最强的LLM：多轮多Agent协调在基准测试中的表现与单一LLM的对比 [PDF](https://arxiv.org/pdf/2509.23537), [HTML](https://arxiv.org/abs/2509.23537)
### Authors
Aaron Xuxiang Tian,Ruofan Zhang,Jiayao Tang,Young Min Cho,Xueqian Li,Qiang Yi,Ji Wang,Zhunping Zhang,Danrui Qi,Zekun Li,Xingyu Xiang,Sharath Chandra Guntuku,Lyle Ungar,Tianyu Shi,Chi Wang
### Background
研究了多轮多Agent协调，多个大型语言模型（LLM）代理在多轮交互中通过迭代提出答案或投票最终达成共识的过程。使用四种LLM（Gemini 2.5 Pro、GPT-5、Grok 4 和 Claude Sonnet 4）在GPQA-Diamond、IFEval 和 MuSR 上进行实验。
### Innovation
开展两项实验：（i）将协调与单一LLM基线进行基准测试；（ii）在GPQA-Diamond上进行消融试验，探讨作者身份揭示和实时投票状态对协调过程的影响。结果显示，协调性能达到甚至超过最强单一LLM模型，并且在所有情况下都优于其他单一模型，揭示作者身份增加自投票频率和分歧，展示实时投票对群集效应的放大作用。
### Conclusion
协调方法在结果上的表现超过最强单一模型，表明潜在改进空间。显示作者身份增加自投票频率和分歧，实时投票会加速收敛但有时可能导致过早共识。
## 238. `cs.AI` - VAR-MATH：通过符号多实例基准探究LLMs的真正数学推理能力 [PDF](https://arxiv.org/pdf/2507.12885), [HTML](https://arxiv.org/abs/2507.12885)
### Authors
Jian Yao,Ran Cheng,Kay Chen Tan
### Background
近年来，强化学习（RL）的进步显著提升了大型语言模型（LLMs）的数学推理能力，但这些提升往往是在存在缺陷的信号下获得的，如随机或倒置奖励。这引发了关于这些进步是否反映了真实的推理能力，还是仅仅是基准特定模式的过度拟合的问题。现有评估协议存在两个关键缺陷：基准污染（测试问题公开可能导致数据泄漏）和评估脆弱性（依赖单一实例评估，容易受到随机输出的影响，不能捕捉推理一致性）。因此，需要一种新的评估范式，能够在超出记忆和一次性成功的基础上探究推理能力。
### Innovation
本文提出了VAR-MATH，一个符号评估框架，将固定数值问题转换为参数化模板，要求模型解决每个问题的多个实例。这种设计确保了结构上等价的变体之间的一致性，减轻了污染并增强了通过自助度量的鲁棒性。VAR-MATH被应用于将AMC23、AIME24和AIME25转化为符号对应版本VAR-AMC23、VAR-AIME24和VAR-AIME25。实验结果显示，对这些变量化基准的RL训练模型的性能大幅下降，尤其是对于较小的模型，AMC23、AIME24和AIME25的平均下降幅度分别为47.9%、58.8%和72.9%。这些发现表明，现有的一些RL方法依赖于表面的启发式方法，无法泛化到特定的数值形式之外。
### Conclusion
这些变量化基准测试表明，某些现有的RL方法依赖于表面的启发式方法，无法泛化到特定的数值形式之外。VAR-MATH提供了一种新的评估范式，可深入探究LLMs的推理能力，超越简单的记忆和一次性成功的表现。
## 239. `cs.AI` - DS-STAR: 通过迭代计划和验证的数据科学代理 [PDF](https://arxiv.org/pdf/2509.21825), [HTML](https://arxiv.org/abs/2509.21825)
### Authors
Jaehyun Nam,Jinsung Yoon,Jiefeng Chen,Tomas Pfister
### Background
数据科学，将原始数据转化为可操作的见解，对于数据驱动的决策至关重要。然而，这些任务通常非常复杂，涉及探索多种数据源并综合结果以提供洞察性答案。尽管大型语言模型（LLMs）在自动化这一过程中表现出巨大的潜力，但它们往往难以处理异构数据格式，生成次优分析计划，因为验证计划的充分性在没有真实标签的情况下是固然是困难的。因此，需要一种能够处理复杂数据源的数据科学代理来克服这些局限性。
### Innovation
提出了一种新的数据科学代理—DS-STAR，该代理通过引入三个贡献来解决上述问题：(1) 数据文件分析模块，自动探索和从多种数据格式中提取上下文，包括非结构化类型；(2) 验证步骤，其中基于LLM的裁判评估每个阶段分析计划的充分性；(3) 顺序规划机制，从简单的可执行计划开始，根据DS-STAR的反馈逐步改进，直到计划的充分性被验证。这一迭代改进过程使DS-STAR能够可靠地处理涉及各种数据源的复杂分析任务。
### Conclusion
我们的实验表明，DS-STAR在三个具有挑战性的基准测试中取得了顶级性能：DABStep、KramaBench 和 DA-Code。此外，DS-STAR特别在需要处理多种以异构格式表示的文件的困难任务中优于基线。
## 240. `cs.AI` - GSM-Agent：使用可控环境理解代理推理 [PDF](https://arxiv.org/pdf/2509.21998), [HTML](https://arxiv.org/abs/2509.21998)
### Authors
Hanlin Zhu,Tianyu Guo,Song Mei,Stuart Russell,Nikhil Ghosh,Alberto Bietti,Jiantao Jiao
### Background
随着大规模语言模型（LLMs）作为代理越来越多地被部署，代理推理能力，即结合工具使用（尤其是搜索）和推理的能力，成为了关键技能。但在复杂的环境中和任务中评估代理推理是有难度的。当前的代理基准测试通常混合了代理推理和其他复杂的能力，如解决高等数学问题、专家级知识等。为了填补这一空白，研究人员构建了一个新型基准GSM-Agent，其中要求LLM代理解决基础的数学推理问题，但只提供问题而不是解决问题需要的必要信息，这部分信息需要代理主动通过工具收集。尽管基础的数学问题是简单的，但前沿的模型如GPT-5只能达到67%的准确率。
### Innovation
研究人员提出了一个名为GSM-Agent的新基准，其中的任务需要代理在没有提供完整信息的情况下解决问题，通过主动使用工具来获取缺失信息。此外，研究人员还提出了一种代理推理图的概念，以理解代理推理的模式，并提出了一种工具增强的测试时扩展方法，通过增加工具来鼓励模型回顾已访问过的内容，以提高代理的推理性能。
### Conclusion
GSM-Agent基准和代理推理框架有望帮助未来对代理推理的理解和研究，推动代理推理能力的边界。
## 241. `cs.AI` - 评估大规模语言模型在组合优化中的应用：二维箱包问题的一阶段和两阶段启发式算法 [PDF](https://arxiv.org/pdf/2509.22255), [HTML](https://arxiv.org/abs/2509.22255)
### Authors
Syed Mahbubul Huq,Daniel Brito,Daniel Sikar,Chris Child,Tillman Weyde,Rajesh Mojumder
### Background
本文提出了一个评估大规模语言模型（LLMs）在组合优化能力中的框架，特别是在2D箱包问题上的应用。通过将LLMs与进化算法相结合，提出了一个系统性的方法来生成并迭代改进启发式解决方案。实验对比展示了LLMs生成的启发式解比传统方法（有穷先填充和混合先填充）更加高效，同时所需计算资源更少。实验结果显示，GPT-4o在两迭代内达到了最优解，减少了平均箱使用量并提高了空间利用率。
### Innovation
本文创新地结合了LLMs与进化算法来解决2D箱包问题，提出了迭代生成和改进启发式解的方法。通过与传统方法的对比实验，验证了使用LLMs的方法在效率和资源节约上的优势，具体表现在快速找到最优解并有效减少箱子使用量和提高空间利用率。
### Conclusion
这项研究深化了对LLMs在专门领域评估的理解，建立了在组合优化任务中评估LLMs性能的基准。
## 242. `cs.AI` - LLM推理中的互动学习 [PDF](https://arxiv.org/pdf/2509.26306), [HTML](https://arxiv.org/abs/2509.26306)
### Authors
Hehai Lin,Shilei Cao,Sudong Wang,Haotian Wu,Minzhi Li,Linyi Yang,Juepeng Zheng,Chengwei Qin
### Background
现有的多智能体学习方法开发了互动训练环境，旨在促进多个大型语言模型（LLMs）之间的合作，进而构建更强的多智能体系统（MAS）。然而，在推理过程中，它们需要重新执行MAS以获得最终解决方案，这与人类的认知过程不符，即个体可以通过与他人的互动增强自身的推理能力，并在未来独立解决问题。
### Innovation
引入了一个名为ILR的新型多智能体学习框架，该框架整合了动态互动和感知校准两大组件。ILR使得LLMs能够根据问题难度和模型能力，动态选择合作或竞争策略，并通过仿效人的讨论过程的信息交流模式（Idea3，即想法共享、想法分析和想法融合）进行互动，从而推导各自的最终答案。此外，ILR通过组相对策略优化（GRPO）训练LLMs时，将一个LLM的奖励分布特征融入另一个LLM的奖励函数中，增强了多智能体互动的凝聚力。
### Conclusion
我们在三个不同规模的LLM模型中对ILR进行了验证，评估了其在五个数学基准和一个编程基准上的表现。实验结果显示，ILR持续优于单智能体学习，与最强基线相比提高了5%。进一步发现，Idea3在多智能体推理期间可以增强更强LLMs的鲁棒性，动态交互类型可以促进多智能体学习，相比于纯粹的合作或竞争策略更具优势。
## 243. `cs.AI` - nDNA -- 人工认知的语义螺旋 [PDF](https://arxiv.org/pdf/2509.18216), [HTML](https://arxiv.org/abs/2509.18216)
### Authors
Amitava Das
### Background
随着AI基础模型能力的增强，一个更深层次的问题出现了——除了流畅性和输出，是什么塑造了模型的内部认知身份？基准衡量行为，但模型的灵魂在于其潜在的几何学。在这方面，论文提出了Neural DNA（nDNA）作为一种语义基因型表示，通过信念的内在几何学捕捉这种潜在的身份。nDNA由三个基本原则和不可或缺的潜在几何维度合成：光谱曲率、热力学长度和信念向量场。
### Innovation
论文提出了nDNA，它是一种语义基因型表示，通过信念的内在几何学捕捉模型的潜在身份。nDNA由三个基本维度构成：光谱曲率揭示概念流在不同层面上的曲率；热力学长度量化穿越各层表征转换所需的语义努力；信念向量场描绘指导模型信念方向的语义扭转场。nDNA像生物DNA一样，具有追溯祖先、变异和语义继承的能力，反映出微调和对齐疤痕、文化印记和架构漂移。
### Conclusion
用nDNA来构建一个新领域：神经基因组学，模型不仅用作工具，也成为具有可追踪内在认知的数字语义生命体。通过这种方式，可以追踪模型从预训练到微调、对齐、剪枝、蒸馏和合并的演化轨迹，并测量不同检查点之间的遗传关系，检测在新数据或目标下特征的变化，最终研究人工认知的演变以进行模型比较、风险诊断和时间内的变更治理。
## 244. `cs.AI` - StepORLM：具有生成过程监督的自我演变框架用于运筹学语言模型 [PDF](https://arxiv.org/pdf/2509.22558), [HTML](https://arxiv.org/abs/2509.22558)
### Authors
Chenyu Zhou,Tianyi Xu,Jianghao Lin,Dongdong Ge
### Background
大型语言模型（LLMs）显示出了解决运筹学（OR）问题的潜在能力。然而，现有工作的两个关键限制是：（1）奖励结果受到信用分配问题的影响，即正确的最终答案可能强化错误的推理；（2）传统的判别过程监督只关注局部评价，未能全面评估OR建模的各步骤之间的关联性。因此，提出了StepORLM，一种具有生成过程监督的新颖自我演变框架。
### Innovation
StepORLM的核心是一个共生进化循环，其中策略模型和生成过程奖励模型（GenPRM）相互迭代式地改进。这个循环由双反馈机制驱动：外部分解器的明确结果验证和GenPRM的细致过程评估。通过加权直接偏好优化（W-DPO）对策略进行对齐，并同时精炼GenPRM。这一框架使得8B参数的StepORLM在六个基准测试中达到了新的最高水平，显著优于更大规模的通用模型、代理方法和专门基准。此外，共同进化出的GenPRM能够作为强大且普适的过程验证器，大幅提升了包括自模型在内的其他现有LLMs的推断扩展性能。
### Conclusion
StepORLM以生成过程监督为基础，提出了一种自我演变框架，显著提升了OR问题解决的模型评估和优化，达到新的技术水平，并展示了在多个基准测试中的卓越性能。
## 245. `cs.AI` - R2 v2: Pareto-compliant R2指标在双向优化基准测试中的改进 [PDF](https://arxiv.org/pdf/2407.01504), [HTML](https://arxiv.org/abs/2407.01504)
### Authors
Lennart Schäpermeier,Pascal Kerschke
### Background
在多目标优化中，基于集合的品质指标是基准测试和性能评估的核心。R2指标是其中一种最常用的集合度量，它通过将其转换为单一数值来捕捉解集的质量。该指标一般通过对效用函数分布进行离散化来应用，这导致添加非支配或支配解到解集中可能但不一定能提高指标值。
### Innovation
本文重新研究了R2指标，在效用函数分布为连续和均匀（切比雪夫）的情况下，详细分析了其特性，证明了这种连续变体是帕累托一致的。此外，本文提供了高效计算方法，可以快速计算双目标问题中的指标，并对解集进行增量更新，无需重新计算整个集合的指标。这为帕累托一致的宇元性能指标，如超体积指标，提供了高效的替代方案。
### Conclusion
本文的工作贡献了针对解集的帕累托一致单目标性能指标，提供了高效的计算方法和增量更新机制，为双向优化提供了基于R2指标的更高效率的基准测试选项。
## 246. `cs.AI` - 使用自主人工智能的适应性数字产品生态系统网络安全架构 [PDF](https://arxiv.org/pdf/2509.20640), [HTML](https://arxiv.org/abs/2509.20640)
### Authors
Oluwakemi T. Olayinka,Sumeet Jeswani,Divine Iloh
### Background
传统静态的网络安全模型在当前数字化产品生态系统中遇到扩展性、实时检测和情境响应等方面的挑战，这些生态系统包括云服务、应用程序接口（API）、移动平台和边缘设备。
### Innovation
本文引入了自主目标驱动型智能代理，它们能够进行动态学习和情境感知的决策，作为以自主人工智能（AI）驱动的自适应网络安全架构的一部分。该框架通过自主威胁缓解、前瞻性政策执行和实时异常检测将自主AI整合到关键生态系统的各个层级。
### Conclusion
该系统通过本地云仿真被证明能够识别零日攻击并动态修改访问策略。评估结果显示，该架构具备更高的适应性、更低的响应延迟和更高的检测准确性。该架构提供了一个智能且可扩展的蓝图来保护复杂的数字基础设施，并且与零信任模型兼容，从而支持国际网络安全法规的遵从。
## 247. `cs.AI` - Planner-R1: 奖励塑形使较小的LLM能够高效实现能动的RL [PDF](https://arxiv.org/pdf/2509.25779), [HTML](https://arxiv.org/abs/2509.25779)
### Authors
Siyu Zhu,Yanbin Jiang,Hejian Sang,Shao Tang,Qingquan Song,Biao He,Rohit Jain,Zhipeng Wang,Alborz Geramifard
### Background
该研究探讨了使用大型语言模型（LLM）在‘TravelPlanner’基准测试中实现能动的强化学习（Agentic RL）的方法。背景信息包括使用较小的模型（如8亿参数模型）相比于更大的模型（如32亿参数模型）在经过奖励塑形处理后获得的竞争性表现及其效率提升。
### Innovation
研究创新在于Planner-R1方法通过仅使用180个训练查询达到了56.9%的最终通过率，相比之下，GPT-5的基准结果为21.2%，并且这是公开排行榜上最强的能动结果。研究发现，较小的模型（8B参数）在受到奖励塑形时表现非常积极，与32B模型相比，它们在计算效率和内存效率上分别提高了3.5倍和1.5倍。相比之下，较大的模型在稀疏奖励下表现更加稳健，但奖励塑形带来的相对收益较小，且运行间存在较大波动。研究还表明，虽然逐阶段学习对提高性能没有明显的益处，但奖励塑形能显著增强学习动力，使8B模型成为能动RL的最高效设置。研究结论明确提出奖励塑形是扩展能动RL的关键手段。
### Conclusion
奖励塑形在能动RL中的应用显著提高了模型的效率，尤其是对于较小的LLM而言。较小模型表现虽弱但经过奖励塑形后能迅速追赶，而大型模型虽然在稀疏奖励下表现更好，但奖励塑形的增益有限。Planner-R1在保持样本外任务（如Multi-IF, NaturalPlan及其相关测试）上性能的同时，受益于奖励塑形带来的学习动力增强，因此验证了通过奖励塑形在能动的RL中实现高效性和泛化性的可能性。
## 248. `cs.AI` - 重思和基准测试用于图推理的大语言模型 [PDF](https://arxiv.org/pdf/2509.24260), [HTML](https://arxiv.org/abs/2509.24260)
### Authors
Yuwei Hu,Xinyi Huang,Zhewei Wei,Yongchao Liu,Chuntao Hong
### Background
近年来，对于大语言模型（LLMs）进行图推理的研究广泛开展，这些研究旨在使LLMs能够理解图结构并解决各种图问题，其中图算法问题最为多见。尽管最近的研究显示了LLMs处理图推理任务的潜力，但其表现仍然不尽如人意。现有方法和基准存在诸多问题，特别是基础模型（如GPT-4o-mini）因为不合理的设计重点（重点在于模仿而不是设计图算法）而被低估，未能有效解决图推理问题。为了更好地评估LLMs的图推理能力，尤其是设计和实现图算法的能力，作者团队创建了一个更具有挑战性的GraphAlgorithm基准，包含239种不同的图问题及3,041个测试实例，这些实例来源于4个竞赛平台。此基准测试的设计旨在更全面地评估LLMs在图推理上的能力。
### Innovation
作者指出现有基线模型被低估的原因，并提出新的设计重点，即让模型从模仿图算法转向设计和实现图算法，为此创建了名为‘Simple-Reasoning-Then-Coding（Simple-RTC）’的简单但强大的基准，引导LLMs首先设计图算法再进行编码解决图推理问题。Simple-RTC在现有基准测试中获得了接近完美的准确率，并在新创建的GraphAlgorithm基准测试中显著优于包括GPT-4o-mini在内的所有先前方法，这为未来研究提供了新的方向和动力。论文还提出了一种创新的图推理基准测试框架，旨在更好地评估LLMs的图推理能力以促进未来研究的进步
### Conclusion
为了使LLMs在图推理问题上能够更好地发挥其潜力并有效解决问题，需要重新评估现有的设计重点并优化基础模型的设计。研究团队通过设计和实现Simple-RTC来引导LLMs首先设计合适的图算法再进行编码以应对图推理问题，从而证明了通过这样的方法能够显著提升模型处理复杂图推理问题的能力。这一基准测试表明，未来的研究方向应更加注重模型在设计和实现图算法方面的表现，而不仅仅是复制现有的图算法。
## 249. `cs.AI` - 在联邦低秩适应中高效且准确的聚合方法 [PDF](https://arxiv.org/pdf/2509.26399), [HTML](https://arxiv.org/abs/2509.26399)
### Authors
Le-Tuan Nguyen,Minh-Duong Nguyen,Seon-Geun Jeong,Dung D. Le,Quoc-Viet Pham
### Background
随着基础模型的迅速发展和在分布式环境中的微调需求不断增加，联邦低秩适应（FedLoRA）逐渐受到关注。然而，现有的FedLoRA方法由于不精确的更新而面临显著的挑战，其中包括局部和全局泛化的差距以及重大的通信开销，这限制了它们的可扩展性和有效性。
### Innovation
本文提出了FLoRA-NA方法，该方法利用服务器上的局部LoRA矩阵来估计聚合矩阵，并减少理想更新和实际更新之间的差异。FLoRA-NA在不增加额外通信成本的情况下提高了通信效率，解决了局部个性化和全局泛化的差距问题，同时优于之前的个性化FedLoRA方法。
### Conclusion
我们在各种任务上进行了广泛的评估，包括自然语言理解、数学推理和代码解决能力，使用不同的基础模型。实验结果表明，FLoRA-NA不仅实现了最先进的全球性能，还保持了低通信开销。
## 250. `cs.AI` - 基于事实的注意：通过注意力级别知识整合消除大型语言模型中的幻觉 [PDF](https://arxiv.org/pdf/2509.25252), [HTML](https://arxiv.org/abs/2509.25252)
### Authors
Aayush Gupta
### Background
现有的大型语言模型虽然能够处理自然语言，但由于其概率性质，这些模型往往会自信地生成错误信息，即幻觉，而这些信息他们实际上从未真正了解过。这使得这些模型在提供准确信息方面存在局限性。
### Innovation
提出的Fact Grounded Attention (FGA)是一种创新性的架构修改，能够在语言模型的注意力机制中直接注入可验证的知识，从而将不可靠的语言模型转化为确定性的事实告诉者。FGA 在技术上直接干预了变压器核心的预-SOFTMAX 注意力得分，使得模型在知识库中存在相关事实的情况下不会生成幻觉，而不是像现有方法那样在生成后修补幻觉，或者预附检索到的文本。
### Conclusion
通过在1,107个技术查询中（涵盖了智能手机、笔记本电脑和电动汽车）进行的实验，FGA 方法已经从 vanilla Llama 3.2 的6.3% 准确率提升到了99.7% 的准确率。此外，知识更新可以在不到一秒的时间内完成，而参数编辑方法可能需要数小时。FGA 不仅仅减少了幻觉，而且对于可验证的事实，它完全消除了幻觉，这标志着从概率近似到确定性精确在神经语言生成中的根本转变。
## 251. `cs.AI` - 基于全景图像和基于逐层学习的损失函数的分层地点识别 [PDF](https://arxiv.org/pdf/2404.14117), [HTML](https://arxiv.org/abs/2404.14117)
### Authors
Marcos Alfaro,Juan José Cabrera,María Flores,Óscar Reinoso,Luis Payá
### Background
移动机器人的安全导航依赖于视觉地点识别（VPR），而在复杂感知条件下实现准确的VPR是一项具有挑战的任务。现有的方法，尤其是传统的对比损失函数，存在识别准确率低和鲁棒性差的问题。
### Innovation
本文提出了一种新的方法，采用全景图像和深度学习模型，并通过引入基于逐层学习策略的三重损失函数来克服传统对比损失函数的局限性。该方法在训练过程中逐步展示更具挑战性的例子，使模型能够学习更具区分性和鲁棒性的特征表示。
### Conclusion
实验结果表明，基于逐层的三重损失函数方法在所有测试环境下的表现都优于标准对比损失函数，特别是在光照、动态视觉效果和训练数据不足的情况下。该方法在多种室内和室外环境中表现出良好的鲁棒性和泛化能力，有望成为可靠的实际机器人应用解决方案。
## 252. `cs.AI` - 第一阶c-表示与基于成本的语义间的语义桥：初步视角 [PDF](https://arxiv.org/pdf/2510.00817), [HTML](https://arxiv.org/abs/2510.00817)
### Authors
Nicholas Leisegang,Giovanni Casini,Thomas Meyer
### Background
Bienvenu等人为在知识库（KB）不一致的情况下进行本体介导数据查询，提出了加权知识库和基于成本的语义这一新形式化方法。这种方法通过为知识库中的每一个陈述赋予权重，并基于DL解释违反知识库规则的频率为每一个解释计算成本。此外，Kern-Isberner最早提出了c-表示，这是一种非单调推理的形式，用于在第一阶情况下解释可反驳的概念包含。c-表示通过为每违反的一个条件赋予惩罚积分来为每种解释赋予一个数值排名。本研究比较了这两种方法在语义层面上的异同点，特别是在某些条件下加权知识库与可反驳条件集合可以生成相同的解释排序，从而使得两种语义结构在相对成本上的具体等价性成为可能。此外，本研究还对比了两种正式系统中的蕴含关系，发现某些概念表述在两种形式系统中等价可表达。研究成果对于进一步的研究发展有潜在的贡献和影响。
### Innovation
研究首次系统性地比较了基于成本的语义与c-表示这两种非单调推理形式之间的差异和共性。主要创新点在于通过特定条件，揭示了加权知识库和可反驳条件集合在生成相同解释排序和语义结构等价性上的潜在统一性，同时对比了两种逻辑系统中的表达能力。
### Conclusion
本研究展示了在特定条件下，基于成本的语义和c-表示可以产生相同的解释排序，即语义结构在相对成本上的等价性。同时，两种正式系统中的某些概念性表达在理论上和逻辑上是等效的。这项工作为进一步研究这两种方法和其潜在的应用开辟了新的路径。
## 253. `cs.AI` - 基于Gaussian pmDAG的神经网络参数优化 [PDF](https://arxiv.org/pdf/2309.14073), [HTML](https://arxiv.org/abs/2309.14073)
### Authors
Mehrzad Saremi
### Background
在因果推断和因果识别中，确定潜在变量因果模型的参数是核心问题。现有用于因果推断的图形结构在高斯贝叶斯网络的边缘化过程中并不稳定。因此，研究团队提出了一个可以准确表示高斯贝叶斯网络边缘的概率图形结构，并揭示了潜在变量模型参数优化和前馈神经网络训练之间的一个新的对偶关系。
### Innovation
首次揭示了潜在变量模型参数优化与前馈神经网络训练之间的对偶关系，并基于此观察，开发了一种基于给定观测分布的图形结构参数优化算法。同时，提供了在高斯设置中因果效应可识别性的条件，并提出了一个检查因果效应是否可识别的元算法，为从高斯扩展到其他分布的神经网络与因果模型之间的对偶关系提供了基础。
### Conclusion
对高斯pmDAG的神经网络参数优化研究结果有望在因果推断和因果可识别性方面取得新的进展，并为进一步的理论研究和实际应用提供新的视角和方法。
## 254. `cs.AI` - 多重领域测试时奖励模型重思 [PDF](https://arxiv.org/pdf/2510.00492), [HTML](https://arxiv.org/abs/2510.00492)
### Authors
Dong Bok Lee,Seanie Lee,Sangwoo Park,Minki Kang,Jinheon Baek,Dongki Kim,Dominik Wagner,Jiongdao Jin,Heejun Lee,Tobias Bocklet,Jinyu Wang,Jingjing Fu,Sung Ju Hwang,Jiang Bian,Lei Song
### Background
在测试时扩展大语言模型（LLMs）的可靠性时，通常使用外部验证者或奖励模型来区分正确的推理与错误的逻辑。既有研究大多假设过程奖励模型（PRMs），因为它们为每次中间推理步骤评分，优于仅评估最终答案的结局奖励模型（ORMs）。这种观点主要基于数学相关领域的狭隘证据。本文对四种奖励模型变体进行了首次统一评估：区分性ORM和PRM（textsc{DisORM}，textsc{DisPRM}），以及生成性ORM和PRM（textsc{GenORM}，textsc{GenPRM}），涵盖14个不同领域。研究发现，非过程奖励模型与过程奖励模型表现相当，过程生成性奖励模型不具备竞争力，总体而言，生成性结局奖励模型在每个测试领域都表现出最高的稳健性，提供了显著且一致的增益。这种稳健性归因于奖励模型样式级步评分，这种评分方式继承了LLM自动标记过程中的标签噪声，并难以评估长推理历程，特别是涉及自我纠正推理的过程。
### Innovation
本文提出对四种不同的奖励模型（区分性与生成性的结局奖励模型及过程奖励模型）进行了首次统一评估，并涵盖14个不同领域，其中创造性地发现过程生成性奖励模型不具备竞争力，而生成性结局奖励模型在所有测试的领域中表现出高稳健性。这一研究挑战了细粒度监督总比粗粒度监督更好的普遍假设，并支持在多领域部署中使用生成性结局验证。研究还通过理论分析解释了这种现象，并通过实证观察证明了这种效果。此外，作者公开发布了研究中的代码、数据集和检查点，方便未来在多领域场景中的研究。
### Conclusion
总体而言，生成性的结局奖励模型表现出更高的稳健性，在所有测试的领域中提供了显著且一致的增益。这一研究结果挑战了细粒度监督总比粗粒度监督更好的假设，并为在多领域部署中使用生成性的结局验证提供了支持。作者还公开发布了研究中的代码、数据集和检查点。
## 255. `cs.AI` - 往返之间：在扩散模型中噪声与图像反转的关系 [PDF](https://arxiv.org/pdf/2410.23530), [HTML](https://arxiv.org/abs/2410.23530)
### Authors
Łukasz Staniszewski,Łukasz Kuciński,Kamil Deja
### Background
扩散模型在生成新样本方面取得了最先进的性能，但缺乏一个低维度的潜在空间，该空间能够编码数据并使得数据更具编辑性。反转方法通过反转去噪轨迹，将图像转换为其近似起点的噪声。然而，尽管这些方法解决了潜在空间编码的问题，但初始噪声与生成样本及其对应的潜在编码之间存在的结构化特征未被完全解释。该研究通过深入分析这一过程，发现潜在编码在平滑图像区域表现出不多样化的特点，这归因于DDIM反转的第一步未能提供准确且多样化的噪声。
### Innovation
通过将DDIM反转的第一步替换为前向扩散过程，该研究成功去除了潜在编码的相关性，并实现了更高质量的编辑和插值。这项简单的修复改善了潜在编码的表示能力，提升了扩散模型的编辑能力。
### Conclusion
研究结果表明DDIM反转的第一步不足以提供足够的噪声多样性，从而限制了生成样本的可控编辑。提出的修复方法可以更好地解耦潜在编码，使扩散模型能够进行更高质量的编辑和插值。
## 256. `cs.AI` - 使用数据库管理系统启发式预emption和缓存替换策略加速LLM推理 [PDF](https://arxiv.org/pdf/2411.07447), [HTML](https://arxiv.org/abs/2411.07447)
### Authors
Kyoungmin Kim,Jiacheng Li,Kijae Hong,Anastasia Ailamaki
### Background
随着大型语言模型（LLMs）在日常生活任务、代理系统和数据分析方面的广泛应用，对GPU资源的需求日益增加。然而，LLM的推理系统比数据库系统慢，其推理性能和机制通常被视为黑箱，这限制了LLM在数据库和其他关键性能应用中的扩展利用。现有的推理系统缺乏足够的资源成本模型和优化策略，无法有效处理多个并发推理请求中的中间结果以节省GPU资源，尤其是在GPU内存中的缓存管理方面存在问题。
### Innovation
本文通过引入经典数据库技术，构建了针对LLM推理的并发请求成本模型和新的缓存替换策略，从而能够大幅节省GPU成本。这种方法能够显著改善LLM推理的性能，解决资源调度和缓存管理中的问题。
### Conclusion
本文引入了一种基于数据库管理系统的启发式预emption和缓存替换策略，来提高LLM推理的速度和效率，通过调整资源调度和缓存机制，有效节约了GPU成本，为Llm在数据库和其他关键性能应用中的广泛应用提供了有力支持。
## 257. `cs.AI` - AutoScale: Scale-Aware Data Mixing for Pre-Training LLMs [PDF](https://arxiv.org/pdf/2407.20177), [HTML](https://arxiv.org/abs/2407.20177)
### Authors
Feiyang Kang,Yifan Sun,Bingbing Wen,Si Chen,Dawn Song,Rafid Mahmood,Ruoxi Jia
### Background
当前领域内的研究发现，性能良好的数据混合在小规模下难以在大规模下保留优势，这挑战了现有的通过小规模实验确定竞争性混合数据并直接应用于大规模的实践方法。这种现象要求开发一种能够适应不同规模的数据组合方式，以提高大规模预训练语言模型的效率和效果。
### Innovation
AutoScale 是一种具有两阶段、规模感知的数据组合框架。首先，AutoScale 使用参数化模型来预测在不同数据组合下的模型损失，并找到一个较小且可管理预算下的近似最佳分配；其次，利用对最优化组合如何随规模演化的理论分析，AutoScale 可以将该组合合理地扩展到更大的预算规模，而在不需要进一步重新训练的情况下。该方法在加速收敛和改善下游任务性能方面表现出显著的效果，例如，在预训练GPT-2 Large时，AutoScale相比基线方法实现28%更快的困惑度降低，最高38%的速度提升，并在多种下游任务上取得了最好的平均结果。
### Conclusion
研究结果表明，随着训练规模的变化，领域的重要性也在改变，因此在预训练LLM时需要依赖于规模的数据策划。团队还开源了代码。
## 258. `cs.AI` - Superficial Safety Alignment Hypothesis [PDF](https://arxiv.org/pdf/2410.10862), [HTML](https://arxiv.org/abs/2410.10862)
### Authors
Jianwei Li,Jung-Eun Kim
### Background
随着大型语言模型（LLMs）在各种应用中的日益集成，确保它们生成安全的回应变得至关重要。尽管之前的对齐研究主要集中在通用指令遵循上，但往往忽略了安全性对齐的独特属性，如安全性机制的脆弱性。为解决此问题，本文提出了表面安全性对齐假说（Superficial Safety Alignment Hypothesis, SSAH），认为安全性对齐教会了一个原本不安全的模型选择正确推理方向——执行或拒绝用户的请求——这可以被解读为一个隐式的二元分类任务。
### Innovation
通过SSAH，本文假设只有少数关键组件可以在LLMs中建立安全防护。经过探索，识别出四种关键组件类型：安全关键单元（SCU）、实用性关键单元（UCU）、复杂单元（CU）和冗余单元（RU）。研究结果表明，在微调过程中冻结某些关键组件能够使模型保留其安全性属性并适应新任务。此外，利用预训练模型中的冗余单元作为“对齐预算”也能有效降低对齐代价，同时实现对齐目标。
### Conclusion
本文结论认为，LLMs中的原子功能单元是神经元级别，强调安全性对齐不应过于复杂化。
## 259. `cs.AI` - QSpec: 互补量化方案的推测解码 [PDF](https://arxiv.org/pdf/2410.11305), [HTML](https://arxiv.org/abs/2410.11305)
### Authors
Juntao Zhao,Wenhao Lu,Sheng Wang,Lingpeng Kong,Chuan Wu
### Background
量化在大型语言模型（LLMs）中广泛用于加速推理和减少内存消耗。激活和权重联合量化虽然能够有效进行低精度解码，但在多步推理任务中会显著降低性能。
### Innovation
提出了QSpec，这是一种通过推测解码集成两种互补方案的新型量化范式：低精度联合量化用于快速草案，高精度权重量化用于精确验证。QSpec在各阶段重用权重和KV缓存，实现几乎无成本的切换，无需重新训练或辅助模型。与高精度基线相比，QSpec在不降低质量的前提下可实现高达1.64倍的速度提升，并且在批处理设置中比最先进的推测解码方法高出1.55倍的表现。
### Conclusion
QSpec由于其可插拔部署和对不同模型规模、量化方法和工作负载的良好泛化能力，成为在内存受限场景下实现高保真量化的实际和可扩展解决方案。我们的代码可在此处获取（this https URL）。
## 260. `cs.AI` - 基于知识图谱增强的大语言模型进行用户偏好推理：提高对话推荐的可解释性 [PDF](https://arxiv.org/pdf/2411.14459), [HTML](https://arxiv.org/abs/2411.14459)
### Authors
Zhangchi Qiu,Linhao Luo,Shirui Pan,Alan Wee-Chung Liew
### Background
会话推荐系统（CRSs）旨在通过交互对话提供个性化的推荐，但当前的CRSs在获取用户偏好并进行解释方面存在不足。解释性不足限制了系统的透明度和可信度。虽然大语言模型（LLMs）可以提供强大的推理能力，但它们在处理用户偏好方面的定制化分析能力有限，且知识图谱（KGs）与LLMs之间存在显著的模态差异，使得知识图谱与LLMs的结合面临挑战。
### Innovation
该论文提出了一种名为COMPASS的框架，该框架结合了LLMs和KGs，通过两个阶段的训练方法优化用户偏好推理。首先，通过新型图实体标注预训练方法来解决结构化知识图谱和自然语言之间的差距。其次，通过知识增强的指令微调使LLMs能够在对话历史和知识图谱增强上下文中学习推理和总结用户偏好。这使COMPASS能够进行知识引导的推理并生成可解释的用户偏好，从而无缝集成到现有CRS模型中，提高推荐性能和可解释性。
### Conclusion
实验结果表明，COMPASS在多种基准数据集上提高了CRS模型的性能和可解释性。
## 261. `cs.AI` - 使用更新近似进行初始化是一种灵丹妙药，可以实现极其高效的低秩微调 [PDF](https://arxiv.org/pdf/2411.19557), [HTML](https://arxiv.org/abs/2411.19557)
### Authors
Kaustubh Ponkshe,Raghav Singhal,Eduard Gorbunov,Alexey Tumanov,Samuel Horvath,Praneeth Vepakomma
### Background
低秩适配器已成为高效微调大型语言模型的标准方法，但它们通常无法达到完整微调的性能。研究人员提出了一种名为LoRA Silver Bullet或LoRA-SB的方法，该方法通过精妙设计的初始化策略，能够在低秩子空间内近似完整微调过程。
### Innovation
该研究提出了LoRA-XS架构，通过在其间插入一个可学习的rxr矩阵（保持其他矩阵不变）来提供此近似所需的精确条件。这使得可以在高秩梯度更新时实现最佳缩放，并去掉缩放因子调整的需求。实验表明，该方法在使用27-90倍更少的学习参数的情况下，超过了LoRA（及其基础方法）的性能，并全面优于LoRA-XS。
### Conclusion
研究证明，可以在低秩子空间内模拟完整的微调过程，并在不牺牲性能的情况下实现显著的参数效率增益。
## 262. `cs.AI` - 基于校准导向的检索增强生成实现可靠决策 [PDF](https://arxiv.org/pdf/2411.08891), [HTML](https://arxiv.org/abs/2411.08891)
### Authors
Chaeyun Jang,Deukhwan Cho,Seanie Lee,Hyungi Lee,Juho Lee
### Background
近年来，大规模语言模型（LLMs）被广泛应用于支持各种决策任务，帮助人类做出更明智的决策。然而，当LLMs自信地提供错误信息时，人类可能会做出次优决策。为了防止LLMs在不确定的领域生成错误信息并提高生成内容的准确性，已有研究提出了检索增强生成（RAG），其中外部文档被用来生成响应。然而，之前的RAG方法仅关注从输入查询中检索最相关的文档，而没有特别针对确保人类用户的决策校准性做出努力。为了解决这一局限性，我们提出了一种新的检索方法——校准导向的检索增强生成（CalibRAG），该方法确保由RAG得出的决策是校准良好的。我们实验证明，相较于其他基线方法，CalibRAG在提高校准性能和准确性方面表现更优。这一新方法在各种数据集上进行了验证，证明了其有效性和优势。
### Innovation
提出了一种新的检索增强生成方法——校准导向的检索增强生成（CalibRAG），该方法确保由RAG得出的决策是校准良好的。相较于之前的RAG方法，CalibRAG特别强调决策的校准性，而不是仅仅关注检索最相关的文档。我们通过实验验证了CalibRAG在提高决策的校准性和准确性方面优于其他基线方法。这一方法能够帮助防止LLMs在不确定性领域生成错误信息，从而提高生成内容的准确性并支持更加可靠的决策过程。
### Conclusion
通过实验证明，CalibRAG方法在提高校准性能和准确性方面优于其他基线方法。该方法确保了由RAG得出的决策是校准良好的，从而可以提高基于LLMs的决策的可靠性。
## 263. `cs.AI` - 一阶视频生成的扩散对抗后训练 [PDF](https://arxiv.org/pdf/2501.08316), [HTML](https://arxiv.org/abs/2501.08316)
### Authors
Shanchuan Lin,Xin Xia,Yuxi Ren,Ceyuan Yang,Xuefeng Xiao,Lu Jiang
### Background
扩散模型在图像和视频生成中应用广泛，但其迭代生成过程速度慢且成本高。虽然现有的蒸馏方法在图像领域展示了单步骤生成的潜力，但在质量上仍然存在较大下降。
### Innovation
提出了针对实际数据的对抗后训练（Adversarial Post-Training，APT）方法，结合扩散预训练技术，实现了单步骤视频生成。通过改进模型架构和训练流程，并引入近似R1正则化目标，提高了训练稳定性和生成质量。
### Conclusion
实验结果表明，我们的对抗后训练模型Seaweed-APT能够在单一前向评价步骤中，实时生成时长2秒、分辨率为1280x720、帧率为24fps的视频。此外，该模型还能够一步生成1024px图像，达到与当前前沿方法相当的质量。
## 264. `cs.AI` - 软件语言模型与知识图谱协同：面向软件仓库相关问题回答的新方法 [PDF](https://arxiv.org/pdf/2412.03815), [HTML](https://arxiv.org/abs/2412.03815)
### Authors
Samuel Abedu,SayedHassan Khatoonabadi,Emad Shihab
### Background
软件仓库包含了理解开发过程的重要信息，但通过仓库数据提取洞察需要大量时间和技术专长。尽管软件工程聊天机器人支持自然语言与仓库的交互，但聊天机器人在理解和回答超出它们训练意图的问题以及准确检索相关信息方面存在困难。因此，本研究旨在通过将知识图谱与大语言模型相结合来提高LLM基于的聊天机器人在回答与仓库相关问题的准确性。
### Innovation
提出了一个两步方法：从仓库数据构建知识图谱，并将知识图谱与大语言模型协同工作以处理自然语言的问题和答案。通过应用少样本链式思考提示，错误率从最初的比率降低至84%。该方法在五个流行的开源项目上进行了评估，表现优于基线方法（MSRBot和GPT-4o-search-preview），并且在20名参与者基于任务的用户研究中，参与者使用该方法完成任务更正确且耗时更短。用户反馈该方法有用。
### Conclusion
研究结果表明，结合知识图谱和大语言模型的方法能有效提高仓库数据的可访问性。
## 265. `cs.AI` - 基于开放同行评审中个体智慧度量的论文质量评估 [PDF](https://arxiv.org/pdf/2501.13014), [HTML](https://arxiv.org/abs/2501.13014)
### Authors
Andrii Zahorodnii,Jasper J.F. van den Bosch,Ian Charest,Christopher Summerfield,Ila R. Fiete
### Background
传统的封闭式同行评审系统在科学出版中扮演着重要角色，但这种系统往往效率低下、成本高昂、不透明且可能受随机性与偏见的影响，这些因素可能会阻碍科学进步并降低公众信任。
### Innovation
本文提出并探讨了一种替代的同行评审形式：采用开放式、自下而上的流程。作者首先通过数据分析展示了评审分数的高变异性和低相关性，提出了一个新的评审质量量化指标，并发现论文质量与作者质量之间无显著关联，反而揭示了一种倒U形关系，即得分中等的论文作者是最佳的评审者。研究中还评估了基于不同评审者可靠性的贝叶斯估计方法，并展示了如何在单次评审-然后评分的情景中，贝叶斯方法能显著提高论文质量评估的准确性，优于简单平均法。此外，还提出了一种持续的发表、评审和评分模型，其中评审者不仅要评分论文，还要评分其他评审者，结果显示用户生成的评审者评分可以产生稳健且高质量的论文评分，即使在不准确但无偏见的评审者主导的情况下也能实现。
### Conclusion
研究发现，这种自选的开放式同行评审流程可能具有可扩展性、可靠性和公平性，并有可能提高同行评审过程的速度、公平性和透明度。
## 266. `cs.AI` - 你看到的是什么？医学多模态深度学习中的模态贡献 [PDF](https://arxiv.org/pdf/2503.01904), [HTML](https://arxiv.org/abs/2503.01904)
### Authors
Christian Gapp,Elias Tappeiner,Martin Welk,Karl Fritscher,Elke Ruth Gizewski,Rainer Schubert
### Background
如今，巨大的深度神经网络可以轻松分析高维度、多模态数据。多种融合方法被开发用于结合不同模态的数据。由于医学中普遍存在高维度、多模态患者数据，多模态模型的开发标志着一个显著的进步。然而，这些模型如何处理单一来源的信息仍然缺乏深入了解。
### Innovation
本研究引入了一种基于遮挡的、既模型又性能无关的模态贡献方法，可以定量衡量数据集中每个模态对于模型完成任务的重要性。该方法在三个不同的多模态医学问题上进行了实验。
### Conclusion
研究发现，一些网络存在对某些模态的偏好，导致单一模态的崩溃，有些数据集从数据开始就是不均衡的。此外，该研究还提供了每个模态的细粒度定量和可视化特征重要性。该度量提供了有价值的见解，支持多模态模型的发展和数据集的创建，促进了多模态深度学习诊断研究的可解释性，有助于促进多模态AI在临床实践中的应用。该代码已公开。
## 267. `cs.AI` - 使用小波超图扩散处理推荐系统中的异质性 [PDF](https://arxiv.org/pdf/2501.14399), [HTML](https://arxiv.org/abs/2501.14399)
### Authors
Darnbi Sakong,Thanh Tam Nguyen
### Background
推荐系统在各个领域提供个性化用户体验中扮演着重要角色。然而，捕捉用户-物品交互的异质性模式和多维度性质构成了显著挑战。传统的推荐系统方法难以有效地处理这些复杂性，尤其是在处理具有多样标签的数据时，以及在理解和建模用户与物品之间的多层次拓扑关系方面存在不足。因此，寻找一种能够同时优化这些领域的解决方案变得至关重要，以提高推荐系统的准确性和可扩展性，以及整体鲁棒性。
### Innovation
本文提出了一种创新性的框架，FWHDNN（基于融合的小波超图扩散神经网络），旨在提高基于超图推荐任务中的表示学习效果。FWHDNN主要通过三种关键组件实现这一目标：(1) 利用异质性感知的超图扩散来适应消息传递的交叉差分关系编码器，以适应多样类标签；(2) 使用小波变换为基础的多尺度超图神经网络层，以抓取多尺度拓扑关系的集群式编码器；(3) 通过中期和晚期融合策略整合结构和文本信息的集成多模态融合机制。这些组件共同作用，构建了一个高效的框架，能够准确地捕捉用户与物品之间的高阶相互连接，优于当前最先进的方法。
### Conclusion
通过广泛的实验，在真实世界数据集上的结果表明，FWHDNN在准确度、鲁棒性和可扩展性方面都超过了现有的最先进的推荐系统方法。特别是在处理异质性模式和多维用户-物品交互方面表现出色，提供了一种有效整合多层次拓扑关系的新方法。
## 268. `cs.AI` - FANS -- 使用Lean4进行自然语言数学推理的形式化答案选择 [PDF](https://arxiv.org/pdf/2503.03238), [HTML](https://arxiv.org/abs/2503.03238)
### Authors
Jiarui Yao,Ruida Wang,Tong Zhang
### Background
大语言模型(LLMs)在各种任务中展现了惊人的能力，尤其是在文本生成、分类、问答等方面。然而，LLMs的推理能力仍然面临许多争议。自然语言(NL)的内在模糊性限制了LLMs进行可验证推理的能力，使其答案缺乏连贯性和可信的支持。
### Innovation
我们提出了一种名为FANS的新框架：基于Lean4的自然语言数学推理的形式化答案选择。这是第一个利用Lean4增强LLMs自然语言数学推理能力的框架。FANS框架首先将NL数学问题和LLM生成的答案翻译成Lean4定理声明，然后使用Lean4证明工具进行证明，并通过Lean4验证。最后，它使用FL结果辅助答案选择。该框架旨在为LLMs提供计算机可验证的解决方案，并提出了除奖励模型外的答案选择方法。
### Conclusion
广泛的实验证明了该框架的有效性。在MATH-500数据集上，它可以将增强型LLMs的准确率最多提高1.91%，在AMC-23上最多提高8.33%。在数论等领域，我们可以选择所有正确的解决方案。定性分析还表明，我们的框架可以利用Lean4证明使NL结果形式化支持。作为该领域的开创性工作，我们计划开源所有模型和数据集，以进一步推动该领域的发展。
## 269. `cs.AI` - VideoGen-of-Thought：通过最小的人工干预逐步生成多镜头视频 [PDF](https://arxiv.org/pdf/2412.02259), [HTML](https://arxiv.org/abs/2412.02259)
### Authors
Mingzhe Zheng,Yongqi Xu,Haojian Huang,Xuran Ma,Yexin Liu,Wenjie Shu,Yatian Pang,Feilong Tang,Qifeng Chen,Harry Yang,Ser-Nam Lim
### Background
当前的视频生成模型在短片段上表现出色，但在生成连贯的多镜头叙事方面存在不足。现有的解决方案要么需要大量的手动脚本编辑，要么强调单镜头的保真度而忽视场景间的一致性，这限制了其在电影级内容生成中的实用性。现有方法存在三个核心问题：叙事的碎片化、视觉的一致性问题以及镜头间的过渡问题，这些问题使得生成连贯、高质量的多镜头视频变得更加困难。
### Innovation
该论文提出了VideoGen-of-Thought（VGoT），一个逐步的自动化框架，可以从一句话生成多镜头视频，系统地解决三个核心挑战：（1）提出了动态故事情节建模，将用户提示转化为简洁的镜头草稿，并扩展成五个领域（角色动态、背景连续性、关系演化、摄像机运动和高动态范围灯光）的详细规格，以确保逻辑连贯性。（2）提出身份感知的跨镜头传播，构建保持角色身份的传记不变体（IPP）令牌，同时允许故事所需的特征（如表情和老化）控制更改。（3）引入相邻潜空间过渡机制，执行边界感知重置策略，处理相邻镜头在转换点的特征，以实现在保持叙事连续性的同时无缝视觉流动。VGoT实现了无需训练的流程，显著优于现有的基准模型，在帧内人脸一致性上提高了20.4%，在风格一致性上提高了17.4%，并且需要的手动调整次数仅为原来的十分之一。
### Conclusion
VGoT通过解决多镜头视频合成中的核心问题，填补了从基础视觉合成到导演级叙事自动化多镜头视频生成之间的空白，使得生成高质量、连贯的多镜头视频变得更加自动化和实用。
## 270. `cs.AI` - 高斯差分隐私在机器学习中报告差分隐私保证 [PDF](https://arxiv.org/pdf/2503.10945), [HTML](https://arxiv.org/abs/2503.10945)
### Authors
Juan Felipe Gomez,Bogdan Kulynych,Georgios Kaissis,Flavio P. Calmon,Jamie Hayes,Borja Balle,Antti Honkela
### Background
当前用于报告机器学习算法（如DP-SGD）的差分隐私（DP）保护级别的方法提供了不完整且可能具有误导性的隐私保证图景。例如，在只知道机制的单一$(?varepsilon,?delta)$值的情况下，标准分析显示存在针对训练数据记录的高准确度推断攻击，但实际上这样的高准确度攻击可能不存在。
### Innovation
本文提出使用非渐近高斯差分隐私（GDP）作为通信DP保证的主渠道，可以避免这些潜在的缺点。通过使用DP文献中的两项最新发展：（i）可以计算DP-SGD的隐私概貌和$f$-DP曲线的开源数值统计员工具，以及（ii）一个决策理论度量来跨越DP表示，展示了如何使用数值统计员提供非渐近GDP的边界，并展示了GDP可以几乎无误差地捕获DP-SGD及其相关算法的整个隐私概貌。
### Conclusion
本文通过对最新的DP大型图像分类和美国家庭普查中的TopDown算法的隐私概貌进行研究，发现GDP在所有情况下都与他们的概貌非常吻合。最后，讨论了此方法的优势与劣势，并讨论了哪些其他隐私机制可以从GDP中受益。
## 271. `cs.AI` - 可解释的文本嵌入及文本相似性解释：综述 [PDF](https://arxiv.org/pdf/2502.14862), [HTML](https://arxiv.org/abs/2502.14862)
### Authors
Juri Opitz,Lucas Möller,Andrianos Michail,Sebastian Padó,Simon Clematide
### Background
文本嵌入是许多自然语言处理任务的基本组成部分，包括分类、回归、聚类和语义搜索。尽管其应用广泛，但在解释嵌入和它们之间的相似性方面仍面临挑战。现有研究较少关注专门用于可解释性的文本嵌入和文本相似性解释的方法。本文旨在提供一个结构化的综述，以促进该领域的研究和发展。
### Innovation
本文为专门用于可解释性的文本嵌入及文本相似性解释的方法提供了结构化的综述，填补了该领域的研究空白。研究了主要思想、方法和权衡，并比较了评估手段，讨论了学到的总体教训，最后指出了未来研究的机会和开放的挑战。
### Conclusion
本文总结了可解释性文本嵌入和文本相似性解释领域的研究现状，通过深入讨论该领域的机遇与挑战，为未来的相关研究提供了指导和建议。
## 272. `cs.AI` - CoLA: 计算高效的大语言模型预训练通过低秩激活 [PDF](https://arxiv.org/pdf/2502.10940), [HTML](https://arxiv.org/abs/2502.10940)
### Authors
Ziyue Liu,Ruijie Zhang,Zhengyang Wang,Mingsong Yan,Zi Yang,Paul Hovland,Bogdan Nicolae,Franck Cappello,Sui Tang,Zheng Zhang
### Background
大规模语言模型（LLMs）的全尺寸MLPs和投影层引入了大量的模型大小，消耗大量的计算资源用于预训练。我们的实验证明，预训练LLMs的激活具有低秩特性。因此，通过利用这一观察结果，本文提出了一种名为CoLA及其内存高效实现CoLA-M的方法，用计算高效的自编码器替代全尺寸层，这些自编码器可以在整个训练过程中自然地强制低秩激活。
### Innovation
CoLA和其内存高效的实现CoLA-M，利用低秩自编码器来替换全尺寸层，以减少激活冗余并提高模型容量和训练效率。这种方法在LLaMA模型上展示了两倍的计算成本降低和1.86倍的训练吞吐量提升。CoLA-M进一步减少了内存成本，同时保持了全秩级别的性能，提供了一种具有共同参数、计算和内存效率优越性的预训练方法。进而减少了训练后的模型大小一倍，更适合资源受限的平台。
### Conclusion
利用CoLA和CoLA-M，不仅减小了模型大小，降低了内存成本，而且提高了计算效率和训练吞吐量，成为资源受限环境中更高效的预训练方法。
## 273. `cs.AI` - 忘掉遗忘：充裕记忆下的持续学习 [PDF](https://arxiv.org/pdf/2502.07274), [HTML](https://arxiv.org/abs/2502.07274)
### Authors
Dongkyu Cho,Taesup Moon,Rumi Chunara,Kyunghyun Cho,Sungmin Cha
### Background
持续学习（CL）通常侧重于减少示例记忆，而在现代系统中，GPU时间而非存储空间成为主要瓶颈。本文挑战了这一传统框架，探索了一个更符合实际的范式：内存虽足够丰富以缓解遗忘，但对于从零开始的完全重新训练依然代价高昂。在这种实际的“中间地带”，核心挑战从稳定性转变为可塑性，模型会偏向于先前的任务，并且难以学习新任务。相反，增强的稳定性使简单的重复回放基线在计算成本远低于完全重新训练的情况下取得了接近最新的先进方法的表现。
### Innovation
提出了一种名为Weight Space Consolidation的轻量级方法，结合了基于秩的参数重置来恢复可塑性，以及权重平均来提升稳定性。这种方法在图像分类器的类别增量学习以及大型语言模型的持续指令调优中均取得了优于强基线的结果，同时保持了与重复回放相似的低计算成本，提供了一个应对昂贵完全重新训练的可扩展替代方案。
### Conclusion
这些发现挑战了长期存在的持续学习假设，并确立了一种新的、成本效益高的基线标准，在实例记忆不再是限制因素的现实世界持续学习系统中具有重要意义。
## 274. `cs.AI` - 使用合成数据生成进行出分布检测 [PDF](https://arxiv.org/pdf/2502.03323), [HTML](https://arxiv.org/abs/2502.03323)
### Authors
Momin Abbas,Muneeza Azmat,Raya Horesh,Mikhail Yurochkin
### Background
可靠的分类系统部署需要准确区分输入的分布内(in-distribution, InD)和分布外(out-of-distribution, OOD)数据。然而，收集准确的OOD数据通常困难重重，这给精确的OOD检测带来了挑战。
### Innovation
提出了一种方法，利用大型语言模型（Large Language Models, LLMs）生成高质量的合成OOD代理，从而无需依赖任何外部OOD数据源。该方法已在经典文本分类任务（如毒性检测和情感分类）以及LLM开发和部署中出现的分类任务（如RLHF的奖励模型训练和不一致生成检测）上进行了研究。
### Conclusion
在九个InD-OOD数据集对和各种模型大小的广泛实验中，该方法明显降低了假阳性率（在某些情况下达到完美零），同时在InD任务上保留了高准确率，显著优于基线方法。
## 275. `cs.AI` - 使用影响函数揭开间接上下文学习的面纱 [PDF](https://arxiv.org/pdf/2501.01473), [HTML](https://arxiv.org/abs/2501.01473)
### Authors
Hadi Askari,Shivanshu Gupta,Terry Tong,Fei Wang,Anshuman Chhabra,Muhao Chen
### Background
在这项工作中，作者引入了一种称为间接上下文学习（Indirect In-Context Learning, ICL）的新范式。与传统的泛化上下文学习不同，间接ICL探索了示范选择策略，以适应两类不同的实际应用场景：混合任务和包含噪声的数据。作者系统性地评估了影响函数（Influence Functions, IFs）作为选择工具的有效性，展示了IFs在捕捉示范池中样本的信息性方面的潜力。之前的研究所未解决的问题在这一研究中得到了解答，尤其是在混合任务和包含噪声的数据环境中。这些新的方法和技术扩展了传统ICL的应用场景，提升了模型在这些领域的性能表现。
### Innovation
研究提出了一种新的示范选择策略——间接上下文学习（Indirect ICL），并通过影响函数（IFs）评估其有效性。研究发现，将BertScore-Recall（BSR）与IF辅助模型结合使用可以显著提升性能，在混合任务场景下提高了0.37%到1.45%的绝对准确率。在噪声上下文学习（Noisy ICL）场景中，利用IF重新加权传统的ICL选择器（如余弦相似度和BSR）可以有效提升准确性，尤其是在针对对抗性噪声的研究中。研究还展示了IF在抗回门攻击中的任务无关示范选择中的用处，减少了32.89%的攻击成功概率。这一创新为ICL技术在多样化的实际应用场景中提供了新的解决方案，拓展了其应用范围，提升了性能表现。
### Conclusion
本文提出了一种泛化的间接上下文学习框架，探讨了不同场景下的示范选择策略，广泛应用了影响函数来评估示范的选择工具的有效性。实验结果表明，这种新方法能够在混合任务和噪声环境中显著提升模型性能。同时，该工作也为ICL在实际场景中的应用提供了新的视角和方法，强调了影响函数在间接ICL中的重要性，具有重要的理论和实践意义。
## 276. `cs.AI` - WebRollback：通过明确的回滚机制增强网络代理 [PDF](https://arxiv.org/pdf/2504.11788), [HTML](https://arxiv.org/abs/2504.11788)
### Authors
Zhisong Zhang,Tianqing Fang,Kaixin Ma,Wenhao Yu,Hongming Zhang,Haitao Mi,Dong Yu
### Background
近年来，大型语言模型的发展极大地提升了网络代理的能力。然而，在复杂的和动态的网络环境中，需要更加先进的规划和搜索能力。以往的研究通常采用贪婪的一维搜索策略，这可能导致在遇到错误状态时无法恢复。
### Innovation
本文增加了网络代理的显式回滚机制，使代理能够在导航轨迹中回到先前的状态。这种机制赋予模型直接控制搜索过程的灵活性，从而提出了有效且高效的网络导航方法。该方法在两个实时网络导航基准上进行了零样本和微调设置的实验，验证了该方法的有效性。
### Conclusion
实验结果显示，所提出的方法在处理复杂的网络环境时比传统的贪婪搜索策略更加有效和高效。
## 277. `cs.AI` - 高空间隐含增强的视听语言建模以扩展高质量数据 [PDF](https://arxiv.org/pdf/2503.17551), [HTML](https://arxiv.org/abs/2503.17551)
### Authors
Yu Sun,Yin Li,Ruixiao Sun,Chunhui Liu,Fangming Zhou,Ze Jin,Linjie Wang,Xiang Shen,Zhuolin Hao,Hongyu Xiong
### Background
基于Transformer的多模态模型在规模化推荐、搜索和广告系统中广泛用于内容理解和相关性排序。提高有标签的训练数据质量和跨模态融合显著提升了模型性能，影响了质量播放率和广告收入等关键指标。高质量注解对于内容建模至关重要，但传统的统计主动学习方法存在局限性，难以检测过自信的误分类，并且在区分深度神经网络中的语义相似项时效果不佳。音频信息在短视频平台上日益重要，但大多数预训练多模态架构主要侧重于文本和图像。虽然可以从头开始在所有三种模态中进行训练，但这牺牲了利用现有视觉-语言和音频模型的优势。
### Innovation
该文提出了基于kNN的latent space broadening (LSB) 来提高主动学习效率，并结合了vision-language modeling with audio enhancement (VLMAE)，这是一种融合音频信息的方法，用于整合到视觉-语言模型中。这些方法部署在生产系统中，带来了重大的业务收益。
### Conclusion
该系统在实际应用系统中的部署带来了显著的商业收益，通过增加高质量数据扩展，显著提高了模型性能和关键业务指标。
## 278. `cs.AI` - 由逐次残差校正网络驱动的Ku波段片上波导谐振结构的AI辅助逆向设计 [PDF](https://arxiv.org/pdf/2505.06936), [HTML](https://arxiv.org/abs/2505.06936)
### Authors
Mohammad Mashayekhi,Kamran Salehian,Abbas Ozgoli,Saeed Abdollahi,Abdolali Abdipour,Ahmed A. Kishk
### Background
设计具有紧密和广泛间隔共振的高性能片上波导（SIW）滤波器具有挑战性，因此需要减少对时间和计算成本高昂的电磁（EM）模拟的依赖。先前的研究方法通常成本高且耗时。
### Innovation
本文提出了一种基于深度学习的方法，用于逆向设计具有紧密和广泛间隔共振的SIW滤波器。构建并验证了一个三阶段深度学习框架，包括前馈逆模型（FIM）、混合逆向-前向残差细化网络（HiFR2-Net）和迭代残差校正网络（IRC-Net）。实验结果显示，IRC-Net在5次校正迭代后显著降低了系统误差，提高了滤波器设计的准确性和收敛性。
### Conclusion
提出的框架展示了能够在低成本下实现复杂微波滤波器的稳健、准确和泛化的逆向设计的能力。该方法有望加速高级滤波器设计的快速原型，并有望扩展到其他 microwave 和毫米波技术中的高频率组件。
## 279. `cs.AI` - 干旱条件下县市级玉米产量预测的知识引导型机器学习方法 [PDF](https://arxiv.org/pdf/2503.16328), [HTML](https://arxiv.org/abs/2503.16328)
### Authors
Xiaoyu Wang,Yijia Xu,Jingyi Huang,Zhengwei Yang,Yanbo Huang,Rajat Bindlish,Zhou Zhang
### Background
遥感（RS）技术能够进行非接触式的广泛地面观测，是作物产量预测的重要工具。传统的基于过程的模型难以整合大量RS数据，且大多数用户对作物生长机制缺乏理解。相比之下，机器学习（ML）模型因缺乏解释性而受到批评。为解决这些限制，我们采用了知识引导型机器学习（KGML），结合了过程模型和ML模型的优势。既往研究要么忽视了土壤湿度对玉米生长的作用，要么没有将这一效应嵌入到模型中。
### Innovation
我们开发了知识引导型机器学习与土壤湿度的框架（KGML-SM），将土壤湿度视为玉米生长的中间变量，强调了其在植物发育中的关键作用。此外，基于模型在干旱条件下可能高估的先验知识，我们设计了一种干旱感知损失函数，对受影响地区的预测产量进行惩罚。我们的实验证明了KGML-SM模型优于其他传统ML模型。我们通过评估不同特征的重要性，分析了土壤湿度对不同地区的预测影响，并探讨了土壤湿度与玉米产量预测之间的关系。
### Conclusion
通过知识引导型机器学习结合土壤湿度的方法，提高了模型对干旱条件下玉米产量预测的准确性，并提供了对预测误差的解释，从而为未来的模型优化提供了指导。
## 280. `cs.AI` - 欧盟中公民有效参与的朝向：AskThePublic的发展 [PDF](https://arxiv.org/pdf/2504.03287), [HTML](https://arxiv.org/abs/2504.03287)
### Authors
Nils Messerschmidt,Kilian Sprenkamp,Amir Sartipi,Xiaohui Wu,Igor Tchappi,Liudmila Zavolokina,Gilbert Fridgen
### Background
e-参与平台对于政府提升民众信任和促进民主社会具有重要意义。通过与公共和私营机构及个人的互动，政策制定者可以做出更加知情和包容的决策。然而，目前主要静态的方法在整合公民反馈方面存在不足。基于媒体丰富性理论，采用设计科学研究方法，本研究探讨如何通过聊天机器人来解决这些问题，以改善e-参与平台主要利益相关者的决策能力。
### Innovation
本研究基于聊天机器人的设计，研发了AskThePublic这样一种大型语言模型，旨在为政策制定者、记者、研究人员和感兴趣的公民提供一个方便的渠道，以探索和参与公民反馈。研究采用了半结构化访谈的方法，针对公共部门专家进行了11次访谈，证实了用户的高度评价，特别是基于互动和结构化响应以及增强的语言能力的价值。
### Conclusion
本研究通过开发AskThePublic聊天机器人，验证了聊天机器人在整合公民反馈方面的能力，并表明其可以显著提高政策制定者的决策质量。研究结果强调了通过技术手段提升公民参与的效果，并为未来的e-参与平台提供了新思路。
## 281. `cs.AI` - 无界限字对编码：打破预分词障碍 [PDF](https://arxiv.org/pdf/2504.00178), [HTML](https://arxiv.org/abs/2504.00178)
### Authors
Craig W. Schmidt,Varshini Reddy,Chris Tanner,Yuval Pinter
### Background
在许多现代分词管道中，预分词是初始步骤，将文本分割成较小的单元，通常基于空白和标点符号。虽然这种过程鼓励使用完整的单词作为分词单元，但它对大多数分词算法（如字对编码BPE）引入了一个根本性的限制。预分词导致词典中词的分布严重偏向常见的完整单词，这限制了扩大词汇量带来的好处。因为额外的词汇呈现出越来越低的词频。为了克服这一障碍，我们提出了BoundlessBPE，这是一个改进的BPE算法，它放松了预分词边界约束。我们的方法选择性地合并两个完整的预单词单元，形成一个更大的单位，称为超单词。超单词不一定在语义上是连贯的。例如，预单词单元“ of”和“ the”可以合并为超单词“ of the”。这种合并策略在词典中产生了比标准BPE更均匀的词频分布，并且能够更有效压缩文本，能够增加每个词单元的字节数高达15%。
### Innovation
我们提出了BoundlessBPE，这是一个改进的BPE算法，它通过选择性地合并两个完整的预单词单元，形成超单词来放松预分词边界约束。这种策略在词典中产生了比标准BPE更均匀的词频分布，并且更有效地压缩了文本，能够增加每个词单元的字节数高达15%。
### Conclusion
BoundlessBPE的超单词合并策略在词典中产生了比标准BPE更均匀的词频分布，并且更有效地压缩了文本。
## 282. `cs.AI` - 增强基于好奇心奖励的多轮对话个性化 [PDF](https://arxiv.org/pdf/2504.03206), [HTML](https://arxiv.org/abs/2504.03206)
### Authors
Yanming Wan,Jiaxing Wu,Marwa Abdulhai,Lior Shani,Natasha Jaques
### Background
有效的会话代理，例如大型语言模型（LLMs），必须根据用户的偏好、个性和属性个性化其互动，以适应不同的领域，如教育和医疗。当前方法，如人类反馈强化学习（RLHF），通常侧重于帮助性和安全性，但在培养真正富有同情心、适应性和个性化的对话方面存在不足。现有的个性化方法通常依赖于大量用户历史，限制了它们对新用户或受限情境用户的有效性。为了解决这些局限性，提出了利用用户模型结合好奇心驱动的内在奖励来改进多轮RLHF的方法。这种方法通过优化对话以提高用户模型的准确性，促进了LLM代理主动推断用户特质，从而实现更个性化的互动。
### Innovation
提出了一种新颖的基于好奇心奖励的机制，该机制将好奇心驱动的内在奖励引入到多轮RLHF中，鼓励LLM代理通过优化对话来推断用户特征，以此提高用户的个性化互动体验。实验验证了该方法在不同领域的有效性，特别是在个性化推荐任务和不同学习风格的教育应用中达到了显著的个性化性能改进，同时保持对话质量。
### Conclusion
该方法提供了一种有前景的解决方案，用于创建更个性化、更适应性和更具参与性的会话代理。相比传统的多轮RLHF，它展现了更好的泛化能力，同时维持了对话质量。
## 283. `cs.AI` - 当推理遇到压缩：理解大语言模型压缩对大型推理模型的影响 [PDF](https://arxiv.org/pdf/2504.02010), [HTML](https://arxiv.org/abs/2504.02010)
### Authors
Nan Zhang,Eugene Kwek,Yusen Zhang,Ngoc-Hieu Nguyen,Prasenjit Mitra,Rui Zhang
### Background
现有的压缩方法（包括量化、蒸馏和剪枝）能够提升大型推理模型（LRMs）的计算效率。然而，现有研究要么未能全面比较这些方法在LRMs上的效果，要么缺乏深入的解释分析。本文通过性能基准测试和机制解释，研究了压缩对大型推理模型推理能力的影响。实验结果表明，动态量化2.51位R1达到了接近R1的性能。研究表明压缩对模型权重的影响显著，突出剪枝和蒸馏的风险；最终层的MLP上投影是压缩LRMs中最关键的组件；当前的量化方法过度压缩了最终层模块和MLP门控投影，保护2%的过度压缩权重就能显著提高平均准确率。
### Innovation
本文提出了基于平均差和归因修补技术，对压缩方法对大型推理模型推理性能的影响进行细粒度解释的方法，从而回答了压缩中最重要的是哪些权重的核心问题。通过跨LLama和Qwen模型的研究，提供了泛化的发现，展示了如何通过保护一些特定权重来显著提高模型的性能。
### Conclusion
研究发现，动态量化2.51位R1可以达到接近原始模型R1的性能。进一步研究表明，权重数量更多地影响了大型推理模型的知识记忆而非推理能力，暗示了剪枝和蒸馏的风险。最终层的MLP上投影在蒸馏的大型推理模型中起到了重要角色。同时，当前的量化技术过度压缩了最终层模块和MLP门控投影，只需保护2%的过度压缩权重就能提升6.57%的平均准确率，远超最先进的技术水平。
## 284. `cs.AI` - PlaceIt3D：真实3D场景中的语言引导物体放置 [PDF](https://arxiv.org/pdf/2505.05288), [HTML](https://arxiv.org/abs/2505.05288)
### Authors
Ahmed Abdelreheem,Filippo Aleotti,Jamie Watson,Zawar Qureshi,Abdelrahman Eldesokey,Peter Wonka,Gabriel Brostow,Sara Vicente,Guillermo Garcia-Hernando
### Background
本文介绍了一个新颖的任务——真实3D场景中的语言引导物体放置。给定一个3D场景的点云、一个3D资产和一个广泛描述3D资产放置位置的文本提示，任务是找出一个符合提示的有效3D资产放置位置。与3D场景中的其他语言引导定位任务相比，如语义定位，该任务具有特定的挑战：它是多义的，因为存在多个有效解决方案；并且需要对3D几何关系和自由空间进行推理。
### Innovation
本文通过提出新的基准测试和评估协议来初次介绍该任务。还引入了一个新数据集，用于训练3D语言模型完成此任务。此外，还引入了第一个非平凡基线方法。虽然挑战重重，但相信该任务和新的基准测试将成为评估和比较通用3D语言模型的测试套件的一部分。
### Conclusion
本文展示了语言引导物体放置在真实3D场景中的挑战性任务以及相关的创新。通过提出新的基准测试、数据集和基线方法，作者认为这项任务和新基准可作为评估和比较通用3D语言模型的有效工具。
## 285. `cs.AI` - FalconWing：一种基于视觉自主性的超轻室内固定翼无人机平台 [PDF](https://arxiv.org/pdf/2505.01383), [HTML](https://arxiv.org/abs/2505.01383)
### Authors
Yan Miao,Will Shen,Hang Cui,Sayan Mitra
### Background
室内可控环境提供了一年四季重复进行无人机实验的机会，但同时也对无人机的重量和机动性提出了严格限制，促使我们设计了超轻型的FalconWing平台。该平台旨在满足在室内环境中进行视力基础自主控制实验的需求，但受限于严格的重量和机动性要求，要求设计一种超轻巧的硬件堆栈（包含137g机体和9g摄像头），并结合外部计算能力来实现这一目标。
### Innovation
FalconWing设计结合了轻量级硬件系统（137g机体与9g摄像头）和移植到外部计算的软件栈，通过使用逼真的3D高斯点（GSplat）模拟器来设计和测试基于视觉的控制器。FalconWing能够进行两个挑战性的基于视觉的空中案例研究的验证：一是领航跟随案例研究，通过模仿学习训练的最佳基于视觉的控制器能够在不同类型的领航机动下实现100%的跟踪成功率；二是自动降落案例研究，基于视觉的控制器完全在模拟中训练能够在实际硬件上实现零样本的转移，成功率达到80%。研究结果表明FalconWing能够在多种应用场景中提供高效可靠的性能，推动了基于视觉的无人机控制技术的发展。
### Conclusion
本文通过发布FalconWing平台的设计、3D高斯点场景以及动力学模型，旨在构建一个开源飞行套件，供工程学生和技术研究实验室使用，推动基于视觉的无人机控制技术的进步。
## 286. `cs.AI` - 有限样本分析下任意特征的线性时差学习 [PDF](https://arxiv.org/pdf/2505.21391), [HTML](https://arxiv.org/abs/2505.21391)
### Authors
Zixuan Xie,Xinyu Liu,Rohan Chandra,Shangtong Zhang
### Background
线性TD($boldsymbol{tau}$)算法是强化学习中用于策略评估的基本方法之一。以往关于该算法收敛速度的研究通常假设特征线性独立，但在许多实际应用场景中这个假设是不成立的。
### Innovation
本文首次针对任意特征情况建立了线性TD($boldsymbol{tau}$)算法的$L^2$收敛速度，无需进行算法修改或添加额外假设。结果适用于折扣回报和平均奖励两种情境。此外，针对任意特征可能导致的解的非唯一性问题，本文开发了一种新颖的随机近似结果，证明了为了特定解集的收敛速度。
### Conclusion
本文的研究结果为在任意特征条件下使用线性TD($boldsymbol{tau}$)算法的收敛性提供了理论支持，并开发了新的随机逼近方法来解决非唯一性问题。
## 287. `cs.AI` - LEXam：在340份法律考试中评估法律推理 [PDF](https://arxiv.org/pdf/2505.12864), [HTML](https://arxiv.org/abs/2505.12864)
### Authors
Yu Fan,Jingwei Ni,Jakob Merane,Yang Tian,Yoan Hermstrüwer,Yinya Huang,Mubashara Akhtar,Etienne Salimbeni,Florian Geering,Oliver Dreyer,Daniel Brunner,Markus Leippold,Mrinmaya Sachan,Alexander Stremitzer,Christoph Engel,Elliott Ash,Joel Niklaus
### Background
尽管最近在测试时扩展方面取得了进展，大型语言模型（LLMs）在处理长格式法律推理方面仍然存在关键挑战。为了应对这一挑战，研究人员利用大量涵盖广泛主题和学位级别的法律考试题目，构建了一个新的基准测试工具，以评估LLMs在法律推理方面的表现。
### Innovation
研究团队创建了LEXam数据集，包含来自116门法律课程的340份法律考试和4886个法律问题（包括2841个长格式开放性问题和2045个多选题），并提供了参考答案以及多步骤法律推理的具体指导。通过与人类专家的严格验证，该研究展示了如何一致准确地评估模型生成的推理步骤，这与人类专家的评估紧密契合。此外，该数据集还可用于区分不同能力级别的模型，提供了一种超越简单准确度指标的法律推理质量评估方法。
### Conclusion
通过LEXam，研究团队展示了模型生成的推理步骤能够与人类专家的评估高度一致，证明了数据集在法律推理领域的区分能力。研究还建议开发一种基于LLM的法官一致性评估方法，并将研究中使用的所有代码和数据公开发布。
## 288. `cs.AI` - 通过感知一致性向轻量级模型转移特征表示 [PDF](https://arxiv.org/pdf/2505.06595), [HTML](https://arxiv.org/abs/2505.06595)
### Authors
Hai-Vy Nguyen,Fabrice Gamboa,Sixin Zhang,Reda Chhaibi,Serge Gratton,Thierry Giaccone
### Background
本文提出了一种方法，将从大模型中获取的特征表示转移到轻量级学生模型中。研究者在数学上定义了一种新的概念——感知一致性，这为特征表示的转移提供了理论基础。在大模型和轻量级模型之间存在表示能力差异的背景下，该研究通过一种损失函数来优化这一过程，该损失函数考虑到特征空间中数据点之间的差异性通过其排名来衡量。通过最小化这种损失函数，学生模型能够模仿教师模型的输入感知方式，而非完全复制教师模型的绝对几何结构，而是保留全局一致性通过差异性排名来实现。该研究提出的感知一致性不仅限于有限集的排名，还将其扩展到概率形式，并且适用于一般的差异性度量方法。理论分析提供了特征表示转移过程的概率视角。实验结果表明，该方法在特征表示转移任务上优于或与强基线方法相当。
### Innovation
本文创新性地提出了感知一致性这一概念，据此构建了一个考虑特征空间中数据点差异性的排名损失函数，使轻量级学生模型能够模仿教师模型的输入感知方式，同时也提供了一种新的方法来放宽从大模型到轻量级模型的特征表示转移过程，而不必完全保留教师模型的绝对几何结构。此外，作者进一步将排名的定义扩展为概率形式，使得这一方法适用于更广泛的差异性度量，并能够基于输入分布进行应用。
### Conclusion
本文通过提出感知一致性的新概念，成功建立了特征表示从大模型到轻量级模型的转移方法。实验结果表明，所提出的方法在特征表示转移任务上表现出优异的性能，与强基线方法相比，取得了更好的效果或达到了相当的水平。
## 289. `cs.AI` - scSiameseClu: 一种用于解释单细胞RNA测序数据的Siamese聚类框架 [PDF](https://arxiv.org/pdf/2505.12626), [HTML](https://arxiv.org/abs/2505.12626)
### Authors
Ping Xu,Zhiyuan Ning,Pengjiang Li,Wenhao Liu,Pengyang Wang,Jiaxu Cui,Yuanchun Zhou,Pengfei Wang
### Background
单细胞RNA测序（scRNA-seq）揭示了细胞异质性，并且通过细胞聚类识别细胞类型和标志性基因起着关键作用。最近的进步，特别是基于图神经网络（GNNs）的方法，显著提高了聚类性能。然而，由于噪声、稀疏性和高维度性，scRNA-seq数据的分析仍然充满挑战性。此外，GNNs经常遭受过度平滑的影响，限制了它们捕捉复杂生物学信息的能力
### Innovation
本文提出了一种名为scSiameseClu的新颖Siamese聚类框架，用于解释单细胞RNA-seq数据。该框架包括三个关键步骤：双增强模块、Siamese融合模块和最优传输聚类。双增强模块通过对基因表达矩阵和细胞图关系应用生物学信息中的扰动增强表示的稳健性；Siamese融合模块结合了交叉相关校准和自适应信息融合，来捕捉复杂的细胞关系并减轻过度平滑；最优传输聚类利用Sinkhorn距离高效地对齐簇分配与预定义比例，同时保持平衡
### Conclusion
全面的实验证明，scSiameseClu在单细胞聚类、细胞类型注释和细胞类型分类方面均优于最先进的方法，提供了一个强大的工具用于scRNA-seq数据解释
## 290. `cs.AI` - Time-o1：时间序列预测需要转换标签对齐 [PDF](https://arxiv.org/pdf/2505.17847), [HTML](https://arxiv.org/abs/2505.17847)
### Authors
Hao Wang,Licheng Pan,Zhichao Chen,Xu Chen,Qingyang Dai,Lei Wang,Haoxuan Li,Zhouchen Lin
### Background
时间序列预测模型的训练面临着独特的挑战，主要在于设计有效的学习目标。现有方法大多依赖于时间均方误差，但这种方法存在两个关键问题：（1）标签自相关性，导致从标签序列似然性产生的偏差；（2）需要学习的任务量过多，随着预测窗口的增长而增加，增加了优化的复杂度。因此，现有方法未能有效应对上述挑战，迫切需要一种新的解决方案来改进时间序列预测性能.
### Innovation
本文提出了一种名为Time-o1的新颖转化增强学习目标，专门用于时间序列预测。通过将标签序列转换为去相关的、具有区分显著性的组件，Time-o1有效减轻了标签自相关性，减少了需要学习的任务数量，从而提高了预测性能。实验表明，该方法能够达到当前最佳性能，且兼容多种预测模型.
### Conclusion
本文提出的Time-o1学习目标实现了对传统时间序列预测方法的有效改进，通过变换标签序列来减轻标签自相关性并减少任务量，进而提高了预测模型的整体性能。源代码已经开源.
## 291. `cs.AI` - 基于搜索的软件工程与AI基础模型：当前格局和未来路线图 [PDF](https://arxiv.org/pdf/2505.19625), [HTML](https://arxiv.org/abs/2505.19625)
### Authors
Hassan Sartaj,Shaukat Ali,Paolo Arcaini,Andrea Arcuri
### Background
基于搜索的软件工程（SBSE）已经活跃了约25年，它将元启发式搜索技术与软件工程相结合，在整个软件工程生命周期中解决了许多问题，并在多个领域展示了其灵活性。最近的人工智能进步，特别是大型语言模型（LLMs）等基础模型（FMs）的出现，使得SBSE的进化与这些模型的集成和互动变得尤为重要。目前的研究路线图需要明确SBSE与FMs之间的关系，识别关键挑战，并提出促进SBSE的发展方向。
### Innovation
本研究路线图分析了基于搜索的软件工程与AI基础模型的整合方式，提出利用基础模型增强基于搜索的软件工程设计、利用基于搜索的软件工程解决基础模型中的挑战、调整基于搜索的软件工程实践以适应软件工程活动的基础模型个性化需求，以及探索基于搜索的软件工程与基础模型的协同潜力。
### Conclusion
该研究路线图展望了未来基于搜索的软件工程在基础模型时代的发展前景，强调了解决新兴领域中挑战的前景广阔的研究机会。
## 292. `cs.AI` - MolLangBench：用于分子结构识别、编辑和生成的语言提示综合基准 [PDF](https://arxiv.org/pdf/2505.15054), [HTML](https://arxiv.org/abs/2505.15054)
### Authors
Feiyang Cai,Jiahui Bai,Tao Tang,Guijuan He,Joshua Luo,Tianyu Zhu,Srikanth Pilla,Gang Li,Ling Liu,Feng Luo
### Background
精确识别、编辑和生成分子是化学家和处理化学任务的AI系统都必须的基础要求。为此，本文介绍了MolLangBench，一个旨在评估分子与语言交互基本任务的综合基准：语言提示下分子结构的识别、编辑和生成。基准的任务构建使用自动化化学信息学工具，确保高质量、无歧义且确定性的输出，并通过严格的专家注释和验证来构建编辑和生成任务。
### Innovation
MolLangBench 支持评估使用不同分子表示（线性字符串、分子图像和分子图）语言接口的模型。评估表明，最先进的模型 (GPT-5) 在直观简单的任务（识别和编辑）中得分分别为 86.2% 和 85.5%，但在生成任务中表现更差，仅达到 43.0% 的准确率。这些结果揭示了当前AI系统在处理初步分子识别和操作任务方面的不足。MolLangBench 的目的在于推动更有效和可靠的化学应用AI系统的进一步研究。
### Conclusion
MolLangBench 预期能够推动进一步的研究，以提高AI系统在化学应用领域的有效性和可靠性。
## 293. `cs.AI` - ABBA-适配器：基础模型高效且具表现力的微调 [PDF](https://arxiv.org/pdf/2505.14238), [HTML](https://arxiv.org/abs/2505.14238)
### Authors
Raghav Singhal,Kaustubh Ponkshe,Rohit Vartak,Praneeth Vepakomma
### Background
大型语言模型在多种任务上表现出色，但如何高效地适应新领域仍然是一个关键挑战。参数效率微调(PEFT)方法通过引入轻量级、可训练的模块来解决这一问题，同时保持大部分预训练权重不变。现有的方法如LoRA通过低秩分解来建模权重的更新，但其表现力受到秩的限制。因此，尽管现有方法如HiRA通过引入Hadarmard积增加表现力，但仍依赖于预训练模型的结构。
### Innovation
我们提出了一种新的PEFT架构ABBA，它将权重更新重新参数化为两个独立学习的低秩矩阵的Hadarmard积。这种更新方式完全解耦权重更新与预训练权重，使得两个组成部分可以自由优化。ABBA在相同参数预算下具有更高的表现力，并通过矩阵重建实验验证了这一点。实验结果显示，ABBA在算术和常识推理基准测试上取得了最好的性能，在多个模型上持续优于现有PEFT方法。
### Conclusion
ABBA实现了在算术和常识推理基准测试上的最佳效果，并在多个模型上显著优于现有PEFT方法。项目的代码可从 this https URL 获取。
## 294. `cs.AI` - Differential Information Distribution: 从贝叶斯角度对直接偏好优化的重新理解 [PDF](https://arxiv.org/pdf/2505.23761), [HTML](https://arxiv.org/abs/2505.23761)
### Authors
Yunjae Won,Hyunji Lee,Hyeonbin Hwang,Minjoon Seo
### Background
直接偏好优化（DPO）是一种广泛用于监督方式使语言模型与人类偏好一致的算法。然而，几个关键问题仍未解决，包括其对数比率奖励背后的原因、偏好数据集的统计结构如何影响其训练动态以及这些动态如何影响下游能力。
### Innovation
介绍了一种新的观点，即通过差分信息分布（Differential Information Distribution，DID）来理解偏好优化。揭示了DPO的对数比率奖励只有当偏好包含更新参考策略到目标策略所需的差分信息时才是独特的。可以解释通常在DPO中观察到的训练动态，包括对数似然和策略探索的变化，是由于DID中特有的幂律关系。并分析了培训动态如何影响下游表现，通过DID的不确定性熵来实现。
### Conclusion
我们的研究结果表明，DPO的奖励设计、训练动态和下游能力都自然地源于学习差分信息的结果，提供了一个原则性的理论基础，并为偏好对齐的实际指导提供了一些建议。
## 295. `cs.AI` - 利用大型语言模型获取战略市场见解：前瞻性反事实生成基准 [PDF](https://arxiv.org/pdf/2505.19430), [HTML](https://arxiv.org/abs/2505.19430)
### Authors
Keane Ong,Rui Mao,Deeksha Varshney,Paul Pu Liang,Erik Cambria,Gianmarco Mengaldo
### Background
反事实推理通常涉及对实际事件的替代场景的考虑。虽然这种推理经常用于理解过去事件，但有一种特定的前瞻性反事实推理形式，专注于预测未来的可能发展。这种推理在动态金融市场中尤为宝贵，因为预见市场动态可以揭示潜在的风险和机会，指导利益相关者做出决策。然而，大规模进行这项工作具有挑战性，因为它涉及巨大的认知需求，因此需要自动解决方案。尽管大型语言模型（LLMs）具有潜力，但这在该领域的应用尚未得到探索。文章介绍了FIN-FORCE，这是一种新型基准，通过汇总金融新闻标题并提供结构化评估，支持基于LLM的前瞻性反事实生成。这项基准为大规模和自动化探索及预测未来市场发展奠定了基础，从而为决策提供了结构化的见解。通过在FIN-FORCE上的实验，评估了最先进的LLMs和反事实生成方法，并分析了它们的局限性，提出了未来研究的建议。我们在以下链接发布基准、补充数据和所有实验代码: this https URL
### Innovation
该研究引入了FIN-FORCE，这是一种新型基准，专门用于支持基于LLM的前瞻性反事实生成。通过这种基准，研究者能够评估最先进的LLM和反事实生成方法，并提出未来的研究方向。此外，这种基准还为大规模和自动化的市场预测和风险管理提供了可能性。
### Conclusion
通过在FIN-FORCE上的实验，研究者评估了最先进LMLs和反事实生成方法，揭示了它们的局限性，并旨在为未来的反事实生成研究提供指导。此外，该研究还展示了利用大型语言模型实现大规模、高效预测未来市场发展的潜力。
## 296. `cs.AI` - 当生成型人工智能模型递归地训练于彼此的输出时会发生什么？ [PDF](https://arxiv.org/pdf/2505.21677), [HTML](https://arxiv.org/abs/2505.21677)
### Authors
Hung Anh Vu,Galen Reeves,Emily Wenger
### Background
互联网作为一个通用的训练数据来源，正在被越来越多的AI生成内容所填充。这种情况下，未来的生成性AI模型可能会被其他模型生成的内容所训练。虽然有研究关注了模型在使用自己生成的数据进行训练时的后果，但对于这些模型是否可能吸取其他模型生成的内容的研究却相对不足。鉴于社会对生成性AI工具的高度依赖，对于此类数据中介模型交互的理解至关重要。研究通过实证研究为数据中介的互动可能如何在实践中展开提供了证据，并发展了一个理论模型来解释这一交互训练过程，最终通过实验验证了理论假设。研究发现，数据中介的互动可以提升模型的性能，但同时也可能导致模型在共享任务上的表现趋同。
### Innovation
1. 探讨了生成型AI模型递归地训练于彼此输出的可能性及其后果。2. 认识到了模型可能从其他模型生成的内容中获益的问题。3. 调研并验证了一个理论模型来解释这类数据中介的交互过程。
### Conclusion
数据中介的互动可以扩大模型对新颖概念的接触范围，从而优化模型性能，但也将可能导致模型间的任务执行表现趋同，最终对其性能产生影响。
## 297. `cs.AI` - 超越分割：面向长文档的 discourse 意识层次检索 [PDF](https://arxiv.org/pdf/2506.06313), [HTML](https://arxiv.org/abs/2506.06313)
### Authors
Huiyao Chen,Yi Yang,Yinghui Li,Meishan Zhang,Min Zhang
### Background
现有的长期文档问题回答系统通常将文本视为扁平序列或进行任意分割，忽略了引导人类理解的 discourse 结构。这导致这些系统在捕捉长期文档中的 discourse 结构时存在缺陷。
### Innovation
提出了一种基于 discourse 联想理论（RST）的具有 discourse 意识的层次框架，通过discourse tree转句级表示；利用LLM增强结点表示，连接结构和语义信息；该框架包含三个关键创新点：针对长文档的专门discourse解析、基于LLM的discourse关系节点增强，以及结构指导的层次检索。
### Conclusion
在QASPER、QuALITY和NarrativeQA上的全面实验表明，该框架在各种文档类型中提供了现有方法的一致改进。消融研究证实，纳入discourse结构显著改进了问题回答的表现。
## 298. `cs.AI` - KG-RAG数据集中的诊断与解决：迈向更可靠的基准评估 [PDF](https://arxiv.org/pdf/2505.23495), [HTML](https://arxiv.org/abs/2505.23495)
### Authors
Liangliang Zhang,Zhuorui Jiang,Hongliang Chi,Haoyang Chen,Mohammed Elkoumy,Fali Wang,Qiong Wu,Zhengyi Zhou,Shirui Pan,Suhang Wang,Yao Ma
### Background
现有知识图谱问答（KGQA）系统依赖高质量的数据集来评估复杂的多跳推理能力，但常用的数据集如WebQSP和CWQ存在关键的质量问题，包括不准确或不完整的事实标注、模糊、简单或无法回答的问题，以及过时或不一致的知识。通过对16个常见KGQA数据集进行手动审计，发现平均事实正确率为57%。这些问题阻碍了KGQA技术的进步和发展。
### Innovation
提出KGQAGen框架，通过结合结构化知识 grounding，LLM 引导生成和符号验证来系统地解决这些问题，生成更具挑战性和可验证的QA实例。利用KGQAGen构建了KGQAGen-10k基准数据集，包含10000个基于Wikidata的问题实例，并用于评估一系列KG-RAG模型。实验结果表明，即使是最先进的系统也难以应对这种基准，突显了其揭示现有模型局限性的能力。
### Conclusion
研究结果强调了构建更严格基准数据集的重要性，将KGQAGen定位为能够大规模推进KGQA评估的框架。
## 299. `cs.AI` - CodeSense：一个面向代码语义推理的实战基准和数据集 [PDF](https://arxiv.org/pdf/2506.00750), [HTML](https://arxiv.org/abs/2506.00750)
### Authors
Monoshi Kumar Roy,Simin Chen,Benjamin Steenhoek,Jinjun Peng,Gail Kaiser,Baishakhi Ray,Wei Le
### Background
理解与推理解析代码语义对提升代码LLMs在现实软件工程任务中的能力至关重要。尽管存在多种代码推理基准，但大多数都依赖于合成数据集或教育编程问题，并集中在粗粒度的推理任务，如输入/输出预测，这限制了其在真实软件工程环境中的有效性。
### Innovation
我们提出了CodeSense，这是第一个提供针对真实世界代码软件工程语义推理任务的细粒度代码推理基准。我们从实际代码仓库中收集了Python、C和Java软件项目，并执行了来自这些仓库的测试，收集了它们的执行跟踪日志。然后，我们对最先进的LLMs进行了全面评估。结果显示，模型在处理细粒度推理任务时存在明显差距。尽管提示技术如思维链和上下文学习有所帮助，但代码语义的缺乏从根本上限制了模型的推理能力。我们还开发了一个执行跟踪框架和工具集，以简化细粒度软件工程推理任务真实数据的收集，为未来的基准建设提供了坚实的基础。
### Conclusion
我们的工作不仅产生了一个代码语义推理基准和数据集，而且还提供了一个执行跟踪框架和工具集，使得细粒度软件工程推理任务的真实数据收集变得容易。这些成果为未来基准建设及模型后训练提供了强有力的支持。完整的代码和数据位于：这个链接。
## 300. `cs.AI` - 实时交互式视频生成的自回归对抗后训练 [PDF](https://arxiv.org/pdf/2506.09350), [HTML](https://arxiv.org/abs/2506.09350)
### Authors
Shanchuan Lin,Ceyuan Yang,Hao He,Jianwen Jiang,Yuxi Ren,Xin Xia,Yang Zhao,Xuefeng Xiao,Lu Jiang
### Background
现有的大规模视频生成模型计算密集，不适合实时和交互式应用的采用。
### Innovation
本文提出了一种自回归对抗后训练(AAPT)方法，将预训练的潜视频扩散模型转化为实时、交互式视频生成器。该模型使用一次神经函数评估(1NFE)自回归生成一个潜在帧，并能够实时流媒体结果给用户，接收互动反馈作为控制生成下一个潜在帧。与现有方法不同，本文方法采用对抗训练作为有效的自回归生成范式，不仅提高了单步生成的效率，还能利用KV缓存，同时以学生强迫的方式训练模型，有效地减少了长视频生成中的误差积累。
### Conclusion
实验结果表明，我们的8B模型可以在单个H100上以736x416分辨率实现每秒24帧的实时流媒体视频生成，或在8个H100上以1280x720分辨率生成一分钟长（1440帧）的视频。
## 301. `cs.AI` - 增强效率的DACER算法 [PDF](https://arxiv.org/pdf/2505.23426), [HTML](https://arxiv.org/abs/2505.23426)
### Authors
Yinuo Wang,Likun Wang,Mining Tan,Wenjun Zou,Xujie Song,Wenxuan Wang,Tong Liu,Guojian Zhan,Tianze Zhu,Shiqi Liu,Zeyu He,Feihong Zhang,Jingliang Duan,Shengbo Eben Li
### Background
由于其表达能力，扩散模型在离线强化学习和模仿学习中显示出巨大的潜力。扩散演员批评家带熵调节器（DACER）通过使用反向扩散过程作为策略逼近器，将这种能力扩展到在线强化学习中，并取得了当前最佳性能。然而，这仍然存在一个核心的权衡：更多的扩散步骤保证了高性能但降低了效率，而较少的步骤则会降低性能。这一问题仍是部署扩散策略在实时在线强化学习中的主要瓶颈。
### Innovation
我们提出了DACERv2，它利用动作相对于Q-梯度场的目标作为辅助优化目标，用于引导每次扩散步骤中的去噪过程，从而引入中间监督信号以增强单步骤扩散的效率。此外，我们注意到Q-梯度场与扩散时间步的独立性与扩散过程的特点不一致。为了解决这个问题，我们引入了一个时间加权机制，使模型能够有效地在早期阶段消除大规模噪声并在后期阶段细化其输出。实验结果表明，与经典和基于扩散的在线强化学习算法相比，DACERv2在大多数复杂的控制环境中仅用五步扩散即可实现更高的性能，并且在多模态任务上表现更好。
### Conclusion
在OpenAI Gym基准测试和多模态任务上的实验结果表明，与经典和基于扩散的在线强化学习算法相比，DACERv2在大多数复杂的控制环境中仅用五步扩散即可实现更高的性能，并且在多模态任务上表现出色。
## 302. `cs.AI` - 局部森林火灾风险预测：针对操作决策支持的部门感知方法 [PDF](https://arxiv.org/pdf/2506.04254), [HTML](https://arxiv.org/abs/2506.04254)
### Authors
Nicolas Caron,Christophe Guyeux,Hassan Noura,Benjamin Aynes
### Background
森林火灾预测涉及在特定区域内估计火情引发的可能性或相关风险等级，尤其是在气候变暖加剧了火灾行为和频率的情况下，准确预测已成为人工智能领域的一个紧迫挑战。传统上，文献中将火情引发视为二元分类任务。然而，这种形式简化了问题，特别是在如法国这样，消防单位按部门组织，每个部门具有独特的地形、气候条件和历史火灾事件背景的情况下，需要更贴近地方的具体情况来建模火灾风险，而不应假定所有地区的风险是统一的。
### Innovation
本文提出了一种新的方法，将火灾风险评估适配于部门环境，提供了更具体的地区预测，以供操作使用。本文还利用最新的AI模型在相对未被探索的数据集上提出了法国全国范围内的第一个AI基准。
### Conclusion
最后，对未来的重要的研究工作进行了总结，并提供了GitHub上的补充资料。
## 303. `cs.AI` - 我应该共享这个翻译吗？评估用户对机器翻译的信任的质量反馈 [PDF](https://arxiv.org/pdf/2505.24683), [HTML](https://arxiv.org/abs/2505.24683)
### Authors
Dayeon Ki,Kevin Duh,Marine Carpuat
### Background
随着人工智能系统的使用逐渐渗透到人们的工作和日常生活当中，提供有助于人们负责任地使用AI的相关反馈机制变得尤为重要，尤其是在用户无法评估AI预测质量的情况下。本研究通过研究单语用户在决定是否共享机器翻译输出时，没有反馈和有反馈情况下的场景，探讨了不同类型的翻译质量反馈指导用户决策的效果。
### Innovation
研究比较了四种类型的质量反馈：直接给出用户翻译质量评估的显式反馈（错误高亮和LLM解释），以及通过后翻译和问答（QA）表等隐式反馈帮助用户比较输入和输出。研究发现，除了错误高亮外，所有反馈类型都显著提高了决策准确性和适当的依赖度。特别是问答表，相比于显式反馈，用户对其信任度和帮助程度给出了更高的评价，且感知到的心理负担最小，显示了隐式反馈的潜在优势。
### Conclusion
研究结果表明，尽管显式反馈直接提供了质量评估，但隐式反馈如问答表能够在提高决策准确性和用户信任度方面发挥重要作用，并且降低了用户的心理负担，体现了隐式反馈在促进用户对机器翻译正确使用方面的重要价值。
## 304. `cs.AI` - PiCa: 参数空间投影的参数高效微调 [PDF](https://arxiv.org/pdf/2505.20211), [HTML](https://arxiv.org/abs/2505.20211)
### Authors
Junseo Hwang,Wonguk Cho,Taesup Kim
### Background
大型基础模型需要进行微调以构建针对特定任务和领域的专家模型，但完全更新数十亿参数在计算上是不可行的。减少可训练参数的数量对于降低训练成本以及部署期间的存储、缓存和处理开销至关重要。尽管一些先前的工作，如单一向量指导的微调，已经显示出利用预训练权重的几何结构可以显著提高参数效率，但它们缺乏坚实的理论基础。
### Innovation
本文介绍了一种新的参数高效微调（PEFT）方法——参数空间投影下的参数高效微调（PiCa）。证明了将梯度投影到预训练权重的主要参数空间中可以提供有效的归纳偏置，并通过一种新型的权重共享策略进一步增强参数效率。在各种NLP和视觉任务中，PiCa在可比或更小的参数预算下都优于最先进的基线方法，表明其理论严谨性和实际有效性。
### Conclusion
PiCa方法在不同NLP和视觉任务中表现优异，能够在相似或更少的参数预算下超过最先进的基线方法，证实其理论基础和实际有效性。
## 305. `cs.AI` - Adaptive Batch-Wise Sample Scheduling for Direct Preference Optimization [PDF](https://arxiv.org/pdf/2506.17252), [HTML](https://arxiv.org/abs/2506.17252)
### Authors
Zixuan Huang,Yikun Ban,Lean Fu,Xiaojie Li,Zhongxiang Dai,Jianxin Li,Deqing Wang
### Background
直接偏好优化(DPO)已成为有效对齐大规模语言模型(LLMs)与人类偏好的方法之一。然而，其性能高度依赖于底层的人类偏好数据的质量。为了应对这一瓶颈，前人工作探索了多种数据选择策略，但这些方法往往忽略了语言模型在优化过程中的演变状态对样本选择的影响。
### Innovation
本文提出了一种新的问题：DPO的样本调度问题（Sample Scheduling for DPO），旨在根据模型在偏好优化过程中批次级别的状态动态地和自适应地调度训练样本。为此，提出了一种名为SamS的高效且有效的算法，在每个训练批次中根据LLM的学习反馈自适应地选择样本，以最大化潜在的泛化性能。值得注意的是，在不修改核心DPO算法的情况下，仅引入SamS即可显著提高多项任务的性能，且具有最小的额外计算开销。
### Conclusion
本文揭示了通过批次级别的样本选择改进LLM对齐的有希望的新方向，该方法具有潜在的泛化能力，可应用于RLHF和更广泛的监督学习范式。
## 306. `cs.AI` - PlaceFM：大规模兴趣点数据中的无训练区域空间基础模型 [PDF](https://arxiv.org/pdf/2507.02921), [HTML](https://arxiv.org/abs/2507.02921)
### Authors
Mohammad Hashemi,Hossein Amiri,Andreas Zufle
### Background
随着来自多样化来源的地理空间数据的迅速增长和持续更新，地理空间数据驱动的城市规划成为关键研究方向。然而，现有的基础模型往往缺乏灵活性，无法对囊括多种空间粒度多种空间和语义相关兴趣点的场景丰富的区域进行合理的推理。
### Innovation
提出了PlaceFM，一个通过无训练、基于聚类的方法捕捉区域表示的地理空间基础模型。PlaceFM可以从美国Foursquare数据构建的兴趣点图中总结出通用目的区域嵌入，自动识别兴趣点，并可以直接集成到地理位置数据管道中支持各种城市下游任务。
### Conclusion
在两个真实世界的预测任务（以邮政编码为单位的人口密度和房价）中，PlaceFM不仅超越了大多数基于图的地理空间基础模型，还能在大规模兴趣点图上生成区域级别表示的高达100倍的速度提升。无需昂贵的预训练，PlaceFM提供了一种可扩展和高效的多粒度地理空间分析解决方案。
## 307. `cs.AI` - MS-DFTVNet:基于多尺度可变形卷积的长期时间序列预测方法 [PDF](https://arxiv.org/pdf/2506.17253), [HTML](https://arxiv.org/abs/2506.17253)
### Authors
Chenghan Li,Mingchen Li,Yipu Liao,Ruisheng Diao
### Background
长期时间序列预测主要依赖于Transformer和MLP模型，而卷积网络在该领域的潜力尚未充分利用。本文研究了现有的长期时间序列预测方法，并指出卷积网络在该领域的应用潜力尚待开发。
### Innovation
提出了一个多尺度时间序列重塑模块，有效捕捉跨时期的块交互和变量依赖性。在此基础上，开发了MS-DFTVNet多尺度3D可变形卷积框架，专门用于长期预测。此外，还引入了一种上下文感知动态可变形卷积机制，以更好地捕捉复杂的时序模式。
### Conclusion
大量的实验表明，MS-DFTVNet不仅显著优于强大的基线模型，还实现了六个公共数据集平均约7.5%的改善，创造了新的最佳结果。
## 308. `cs.AI` - WWAggr: 基于窗口Wasserstein距离聚合的集成变化点检测 [PDF](https://arxiv.org/pdf/2506.08066), [HTML](https://arxiv.org/abs/2506.08066)
### Authors
Alexander Stepikin,Evgenia Romanenkova,Alexey Zaytsev
### Background
变化点检测（CPD）旨在识别数据流中分布突变的时刻。现实世界中的高维数据流CPD由于数据模式复杂性及常见假设的失效而变得具有挑战性。尽管当前最先进的检测器使用独立的深度神经网络，但仍未达到完美质量。在此背景下，集成方法提供了更稳健的解决方案，能够提高性能。然而，现有的预测聚合技术，如平均聚合，并不适用于这一特定问题，且无法解决专门难题。因此，本文将探讨深度变化点检测模型的集成方法，并提出一种基于Wasserstein距离的新任务特定聚合方法WWAggr，以提高变化点检测的性能和准确性。
### Innovation
本文创新性地提出了WWAggr——一种基于Wasserstein距离的新任务特定的集成聚合方法，以解决变化点检测领域的问题。该方法具有灵活性，能有效应用于各种深度变化点检测模型的集成，并且相较于现有解决方案，它实际上解决了变化点检测领域的长期难题——决策阈值的选择问题。
### Conclusion
本文研究了深度变化点检测模型的集成方法，并提出了WWAggr。该方法能有效提高变化点检测的性能和准确性，同时解决了传统的预测聚合技术无法处理的特定问题。此外，我们还解决了选择变化点检测决策阈值这一长期存在的问题，提升了方案的实用性。
## 309. `cs.AI` - AlgoTune：语言模型能否加速通用数值程序？ [PDF](https://arxiv.org/pdf/2507.15887), [HTML](https://arxiv.org/abs/2507.15887)
### Authors
Ori Press,Brandon Amos,Haoyu Zhao,Yikai Wu,Samuel K. Ainsworth,Dominik Krupke,Patrick Kidger,Touqir Sajed,Bartolomeo Stellato,Jisun Park,Nathanael Bosch,Eli Meril,Albert Steppi,Arman Zharmagambetov,Fangzhao Zhang,David Perez-Pineiro,Alberto Mercurio,Ni Zhan,Talor Abramovich,Kilian Lieret,Hanlin Zhang,Shirley Huang,Matthias Bethge,Ofir Press
### Background
尽管语言模型（LM）的能力已经取得了进步，但目前的评估主要集中在人类已经解决的任务上，包括编程（Jimenez等人，2024）和数学（Glazer等人，2024）。因此，本文提出了一个新的基准测试——让模型展示其设计和实现算法的能力。具体来说，该研究设计了一个开放性的基准测试（称为AlgoTune），其中包括计算机科学、物理学和数学中的挑战性计算问题。通过比较LM生成的解码代码与来自流行开源包的参考实现，验证和时间LM生成的解码代码。
### Innovation
本文开发了一个基线LM代理AlgoTuner，它通过简单的预算循环进行代码编辑、编译、运行、性能分析、测试正确性，最终选择最快的验证版本。结果显示，AlgoTuner平均实现1.72倍的加速，相对于现有的参考求解器，这些求解器使用了SciPy、sk-learn和CVXPY等库。然而，研究发现当前模型倾向于进行表面级别的优化，而非发现算法创新。
### Conclusion
AlgoTune旨在促进能够超越人类最佳表现的创造性问题解决的LM代理的开发。
## 310. `cs.AI` - 空间网络架构 [PDF](https://arxiv.org/pdf/2507.22687), [HTML](https://arxiv.org/abs/2507.22687)
### Authors
Josh Millar,Ryan Gibb,Roy Ang,Hamed Haddadi,Anil Madhavapeddy
### Background
随着网络设备在物理空间中的密度增大，人们期待实现无缝协作和环境智能。然而，现有的云优先架构迫使所有通信通过广域网进行，而与物理距离无关。至今尚缺少一种关于空间网络的抽象概念：利用物理空间来划分私密性、鲁棒性以及低延迟的通信边界。
### Innovation
我们引入了Bifröst编程模型，使用bigraphs表达包含和连接关系，实现了基于物理边界的策略范围、通过位置命名设备、实现空间服务实例化，并保持局部自治的空间网络。Bifröst为一种新的空间感知应用类别提供了可能性，在此类应用中，同处一地的设备直接通信，物理障碍需要显式网关，局部控制实现与全球协调的桥梁。
### Conclusion
Bifröst使一种新的空间感知应用成为可能，其中同地设备直接通信，物理障碍需要显式网关，局部控制与全球协调相互联系。
## 311. `cs.AI` - 使用机器学习在一维混沌时间序列中估计最大郎格朗日指数的新方法 [PDF](https://arxiv.org/pdf/2507.04868), [HTML](https://arxiv.org/abs/2507.04868)
### Authors
A. Velichko,M. Belyaev,P. Boriskov
### Background
理解并量化数据中的混沌仍然是一个挑战。本文提出了一种基于数据的方法，用于通过机器学习估计一维混沌时间序列的最大郎格朗日指数（LLE），并且这种指数是混沌系统轨迹发散性的一种重要度量。现有的方法在某些情况下可能不够准确或有效，特别是在只有单变量时间序列数据的情况下。本文方法的目标是对系统进行准确预测并量化其混沌属性，尽管存在噪声，也能保持一定的准确性。
### Innovation
该方法采用了机器学习技术训练预测器生成多步预测，从而从预报误差的指数增长中推断出LLE。相比现有方法，它提供了一种更简单、更高效且无需具体模型的方法来估计LLE，适用于只有一维时间序列数据的实验场景。此外，该方法还展示了其在噪声环境下的鲁棒性，对于SNR大于30 dB的噪声环境，方法的准确性趋于饱和，这为传感器级应用设定了一个保守的基准。
### Conclusion
该方法可通过简单的模型和有限的数据集实现对LLE的精确估计，特性包括计算效率高、对模型无依赖性且适用性广等。未来的研究将会探索如何将该方法扩展到高维度和不规则采样数据的情况。
## 312. `cs.AI` - 子网络数据并行的模型并行 [PDF](https://arxiv.org/pdf/2507.09029), [HTML](https://arxiv.org/abs/2507.09029)
### Authors
Vaibhav Singh,Zafir Khalid,Edouard Oyallon,Eugene Belilovsky
### Background
大规模预训练神经网络对加速器的内存需求很大，并且经常需要昂贵的通信。传统的分布式训练方法要求模型中的激活在整个训练过程中进行交换，这不仅增加了内存需求，还增加了通信开销。
### Innovation
本文提出了一种名为Subnetwork Data Parallelism（SDP）的分布式训练框架，该框架将模型划分为结构化的子网络，分散训练以避免激活交换，引入了两种互补的遮罩策略：一手后向遮罩，仅在反向传播中应用稀疏性以保持无偏梯度；一手前向遮罩，在前向传播中也移除参数，以实现更强的效率，并提供额外的正则化效果。此外，还研究了两种子网络构建策略：神经元级别和块级别，这些策略应用于卷积神经网络和变压器。
### Conclusion
在CIFAR、ImageNet以及LLM预训练的FineWeb等实验中，SDP能够将每个设备的内存使用量降低30%-75%，同时保持甚至提高性能。特别是在FLOP匹配的设置中，前向遮罩有时可以实现更好的性能。
## 313. `cs.AI` - VITA: 视觉到动作的流动匹配策略 [PDF](https://arxiv.org/pdf/2507.13231), [HTML](https://arxiv.org/abs/2507.13231)
### Authors
Dechen Gao,Boqi Zhao,Andrew Lee,Ian Chuang,Hanchu Zhou,Hang Wang,Zhe Zhao,Junshan Zhang,Iman Soltani
### Background
传统的流匹配和扩散基策略通过迭代去噪从标准噪声分布（如高斯分布）中采样，并需要条件机制在生成过程中结合视觉信息，这带来了巨大的时间和内存开销。
### Innovation
开发了一种无噪声和无条件机制的视觉到动作策略框架VITA，它直接使用流匹配将视觉表示映射到潜在动作，通过引入动作自编码器和流动潜解码来解决动作与视觉表示之间维度不匹配和信息量不一致的问题。
### Conclusion
VITA在ALOHA和Robomimic上的8项模拟和2项真实任务中表现出色或与最先进的生成策略相匹配，且相比传统方法降低了1.5-2.3倍的推断时间。
## 314. `cs.AI` - MambAttention: Mamba with Multi-Head Attention for Generalizable Single-Channel Speech Enhancement [PDF](https://arxiv.org/pdf/2507.00966), [HTML](https://arxiv.org/abs/2507.00966)
### Authors
Nikolai Lund Kühne,Jesper Jensen,Jan Østergaard,Zheng-Hua Tan
### Background
新的序列模型如Mamba和xLSTM在单通道语音增强、自动语音识别和自监督音频表示学习方面表现出了与或超越了最先进的模型。然而，这些序列模型容易过拟合，尤其是LSTM和Mamba这类模型。此前的研究表明，通过在LSTM中加入自注意力机制可以显著提高单通道语音增强任务上的泛化性能。但有关将Mamba与时间频率自注意力机制结合的混合模型及其泛化性能的研究尚未开展。
### Innovation
本文提出了一种新的混合架构MambAttention，结合了Mamba和共享的时间和频率多头注意力模块，以实现可泛化单通道语音增强。此外，还引入了VoiceBank+Demand Extended (VB-DemandEx)数据集，该数据集在语音Bank+Demand的基础上增加了更具挑战性的噪声类型和较低的信噪比，用于训练MambAttention模型。MambAttention模型在DNS 2020和EARS-WHAM_v2两个外部领域数据集上显著优于现有模型，而在内部领域数据集VB-DemandEx上与之持平。MambAttention模型权值共享的多头注意力模块也对泛化性能起到了关键作用；并且，将多头注意力模块与LSTM和xLSTM结合起来也带来了显著的性能提升。
### Conclusion
MambAttention模型在两种外部领域数据集上均优于包括基于LSTM、xLSTM、Mamba和Conformer的现有模型，尤其是在基于VB-DemandEx的训练和评估中，在所有评估指标上均表现出色。此外，时间频率共享注意力模块在改进泛化性能方面的贡献显著，且与LSTM和xLSTM模型结合的MambAttention模型在外部领域数据集上也表现出色。
## 315. `cs.AI` - LLMs能否发现欺诈者？多层次LLM增强的图欺诈检测 [PDF](https://arxiv.org/pdf/2507.11997), [HTML](https://arxiv.org/abs/2507.11997)
### Authors
Tairan Huang,Yili Wang,Qiutong Li,Changlong He,Jianliang Gao
### Background
图欺诈检测引起了广泛关注，因为图神经网络（GNNs）能够有效建模多模态数据中的复杂关系。然而，现有的图欺诈检测方法通常依赖预处理节点嵌入和预定义的图形结构来揭示欺诈者，这忽略了原始文本信息中丰富的语义线索。尽管大语言模型（LLMs）在处理文本信息方面表现出强大的能力，但将处理后的文本嵌入与图形结构进行多模态融合仍是一个重大挑战。
### Innovation
本文提出了一个多层次LLM增强的图欺诈检测框架，称为MLED。MLED利用LLMs从文本信息中提取外部知识以增强图欺诈检测方法。设计了一个多层次的LLM增强框架，包括类型级增强器和关系级增强器。前者增强欺诈者和良性实体之间的差异，后者增强欺诈者在不同关系中的重要性。通过在四个真实数据集上的实验，MLED实现了在图欺诈检测中的最佳性能，作为可以应用于现有方法的一般框架。
### Conclusion
MLED在图欺诈检测中取得了最先进的性能，作为一个通用框架可以应用于现有方法。
## 316. `cs.AI` - 基于预测一致性和可靠性的自动目标检测模型评估 [PDF](https://arxiv.org/pdf/2508.12082), [HTML](https://arxiv.org/abs/2508.12082)
### Authors
Seungju Yoo,Hyuk Kwon,Joong-Won Hwang,Kibok Lee
### Background
近年来，计算机视觉的进步使得目标检测器的训练更加高效和有效；然而，在实际应用场景中评估其性能仍然依赖于昂贵的手动注释。为此，本文提出了一个自动模型评估（AutoEval）框架，用于目标检测。该框架提出了预测一致性和可靠性（PCR）指标，通过在非极大值抑制之前的多个候选边界框联合测量空间一致性及保留的边界框的置信得分可靠性，来估计检测性能，而无需使用真实标注数据。为了进行更具现实性和扩展性的评估，构建了一个元数据集，其中包括了不同程度的图像破坏。实验结果表明，PCR相较于现有的自动化评估方法，能够提供更准确的性能估计，并且提出的元数据集覆盖了更广泛的目标检测性能范围。
### Innovation
提出了预测一致性和可靠性（PCR）指标，该指标能够通过在非极大值抑制之前的多个候选边界框测量空间一致性以及测量保留的边界框的置信得分可靠性来估计检测性能，无需使用真实标注数据，从而减少了手动注释的成本。同时，建立了包含不同程度图像破坏的元数据集，用于评估目标检测性能，这种评估方法在现实性和扩展性方面更具优势。
### Conclusion
实验结果表明，PCR相对于现有的自动评估方法，能够提供更准确的性能估计。同时，该方法通过构建多层破坏的元数据集，能够覆盖更广泛的检测性能范围。该研究提出的PCR指标和元数据集为自动化评估目标检测器的性能提供了一种有效的方法。源代码已发布，供研究者参考和使用。
## 317. `cs.AI` - Legal Knowledge Graph Foundations, Part I: URI-Addressable Abstract Works (LRMoo F1 to schema.org), [PDF](https://arxiv.org/pdf/2508.00827), [HTML](https://arxiv.org/abs/2508.00827)
### Authors
Hudson de Martim
### Background
本文基于IFLA图书馆参考模型（LRMoo）构建了一个正式的、以事件为中心的模型，该模型用于法律规范的时间演变。本文的核心问题是如何将该模型的基础实体——抽象法律作品（F1）——发布到语义网，这是确保法律信息可互操作、可机器读取的第一步。作者选择了巴西联邦立法作为实际案例，通过JSON-LD描述稳定识别符、核心元数据和规范关系，从而建立了稳定的URI可寻址锚点，以验证“真实情况”。这为后续构建时间版本和内部组件提供了基础，并与形式本体和网页原生标准相结合，奠定了构建确定性和可靠性的法律知识图谱（LKGs）的基础，克服了传统概率模型的限制。
### Innovation
本文提出了将IFLA LRMoo模型中的‘抽象法律作品’（F1）映射到广泛采用的schema.org词汇表的详细方法，并通过巴西联邦立法数据集展示了如何创建可互操作的、机器可读的描述。通过这种方式，将正式的本体论与原生的网络标准相结合，为后续丰富和构建法律知识图谱（LKGs）提供了可能，克服了单纯依靠概率模型的限制。
### Conclusion
本文为后续构建法律知识图谱（LKGs）奠定了基础，通过将抽象法律作品（F1）映射到schema.org，提供了确定性和可靠性，并通过稳定的URI寻址锚点验证了“真实情况”。这种基础对于后续多时间版本（Expressions）及内部组件的构建至关重要，是实现法律信息有效管理的关键一步。
## 318. `cs.AI` - 将 Federated Unlearning 问题视为参数估计问题 [PDF](https://arxiv.org/pdf/2508.19065), [HTML](https://arxiv.org/abs/2508.19065)
### Authors
Antonio Balordi,Lorenzo Manini,Fabio Stella,Alessio Merlo
### Background
隐私法规要求深度学习模型中删除数据。这在联邦学习中尤为具有挑战性，因为数据留在客户端，使得全量重新训练或协调更新往往不可行。因此，本文提出了一种基于信息理论的高效联邦删除框架，并将数据泄漏视为参数估计问题。该方法利用二阶海森矩阵信息来识别和选择性重置那些最敏感于要删除数据的参数，而后再进行少量的联邦训练。这种方法不依赖于服务器访问客户端的原始数据，而是在初始信息聚合之后支持各类别的和客户端的删除。
### Innovation
本文介绍了一种基于信息理论的高效联邦删除框架，将数据泄漏视为参数估计问题。方法利用二阶海森矩阵信息，仅重置敏感于删除数据的参数，随后进行少量联邦重新训练。该方法支持各类别和客户端的删除，无需服务器访问客户端原始数据，并且在基准数据集上的测试显示了强大的隐私保护性能和高模型性能。此外，在针对后门攻击的场景下，该框架有效中和了恶意触发，恢复了模型的完整性，为联邦学习中的数据删除提供了实用的解决方案。
### Conclusion
本文提出了一种高效的联邦删除框架，适用于联邦学习中的数据删除问题，并展示了其卓越的隐私保护能力和高模型性能。特别是在数据泄漏和后门攻击场景下，该框架提供了有效的解决方案，为联邦学习的安全性提供了重要保障。
## 319. `cs.AI` - 利用遥感和机器学习进行地表覆盖分类及变化检测：斐济西部案例研究 [PDF](https://arxiv.org/pdf/2509.13388), [HTML](https://arxiv.org/abs/2509.13388)
### Authors
Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra
### Background
斐济作为一个发展中国家，面临着快速的城市化进程，这在大规模的开发项目如住房、道路和基础设施建设上有所体现。本研究旨在通过遥感和机器学习技术，比较2013年至2024年间斐济楠迪地区的土地利用和土地覆盖变化情况，以提供土地覆盖/土地利用建模和变化检测的技术支持。
### Innovation
本研究采用Landsat-8卫星图像作为数据源，并通过监督机器学习创建了训练数据集。使用Google Earth Engine和无监督机器学习（k-means聚类）生成土地覆盖地图，同时利用卷积神经网络进行土地覆盖分类。通过可视化变化检测，展示了不同时间点的城市区域变化，以监测地图的变化情况。
### Conclusion
本研究通过遥感和机器学习技术，有效监测了斐济楠迪地区2013年至2024年的土地利用和土地覆盖变化，为土地管理决策提供了科学依据。
## 320. `cs.AI` - 机载卫星甲烷检测的进展 [PDF](https://arxiv.org/pdf/2509.00626), [HTML](https://arxiv.org/abs/2509.00626)
### Authors
Maggie Chen,Hala Lambdouar,Luca Marini,Laura Martínez-Ferrer,Chris Bridges,Giacomo Acciarini
### Background
甲烷是强有力的温室气体，并对气候变迁产生重大影响，及时发现甲烷对于有效减缓气候变暖趋势尤为重要。目前的甲烷检测方法通常依赖于图像处理技术进行几何校正和匹配滤波以增强气柱信号。然而，这些方法通常伴随着高昂的数据传输成本和较慢的响应速度。将机器学习（ML）部署在卫星上，能够实现快速检测，降低成本，并支持更快的响应系统。
### Innovation
本文介绍了无需进行几何校正等预处理步骤的新颖方法，直接使用未经几何校正的数据（UnorthoDOS）。研究结果表明，基于这些未校正数据训练的机器学习模型在性能上可与基于几何校正数据训练的模型相比肩，甚至超过匹配滤波基准（mag1c）。研究还释放了机器学习培训所需的几何校正和未经几何校正的高光谱图像数据集，以便其他研究者进行进一步的研究。
### Conclusion
通过新方法能够训练出高性能的机器学习模型，并在检测过程中无需预处理步骤，从而降低数据传输成本，提高检测速度，为及时应对气候变化提供技术支持。
## 321. `cs.AI` - 一个复杂的活性粒子系统控制方法：应用于疏散问题 [PDF](https://arxiv.org/pdf/2509.19972), [HTML](https://arxiv.org/abs/2509.19972)
### Authors
Albina Klepach,Egor E. Nuzhin,Alexey A. Tsukanov,Nikolay V. Brilliantov
### Background
在处理各类场景，如人群管理、机器人集群控制和物质协调运输等，操控大规模的活性粒子系统是一个严重的挑战。当前控制策略的可扩展性和稳定性不足，主要是因为需要单独控制每一代理，这阻碍了开发适应复杂场景的高级控制方法。
### Innovation
提出了一种新的控制策略，即通过引入领导者或一组领导者来控制整个系统，其他代理倾向于跟随这些领导者的策略。该策略结合了强化学习（RL）和对系统施加的人工力。此外，还引入了广义Vicsek模型来描述领导者对活性粒子的引导机制。这种方法被成功应用于由机器人救援者（领导者）有效疏散大型人群的问题，并证明了即使对于高级架构，该方法也能提供更具鲁棒性和效率的疏散策略。
### Conclusion
尽管直接应用RL会产生次优结果，但通过上述结合的方法提供了更有效的疏散策略。实验结果表明，该方法对实施救援任务非常有效，并且展示了该模型的源代码已经公开可用。
## 322. `cs.AI` - 翻译准确性的隐藏成本：模型蒸馏、量化及环境影响 [PDF](https://arxiv.org/pdf/2509.23990), [HTML](https://arxiv.org/abs/2509.23990)
### Authors
Dhaathri Vijay,Anandaswarup Vadapalli
### Background
大型语言模型（LLMs）的迅猛发展引起了对其计算和环境成本的担忧。本研究通过比较全量、蒸馏和量化模型，利用机器翻译作为案例研究，来探讨翻译质量和效率之间的权衡。
### Innovation
研究对比了全量、蒸馏和量化模型在翻译质量和效率上的差异，特别是在环境影响和计算需求方面。蒸馏模型在减少了91%到98%的推理时间的同时，减少了37%到45%的碳排放，对比全量3.3B FP32模型仅有轻微的蓝度分数下降。量化模型，尤其是INT4，保持了高准确性和流畅性。研究表明，模型压缩策略能够显著减少计算需求和环境影响，并维持竞争的翻译质量，尤其是在资源较少的情况下。
### Conclusion
本研究表明，模型压缩策略可以大幅减少计算需求和环境影响，同时保持竞争力的翻译质量。我们建议在评价框架中集成效率和可持续性，与准确性一起作为自然语言处理（NLP）进展的核心维度。
## 323. `cs.AI` - 探究ReLoRA：小语言模型学习动态的影响 [PDF](https://arxiv.org/pdf/2509.12960), [HTML](https://arxiv.org/abs/2509.12960)
### Authors
Yuval Weiss,David Demitri Africa,Paula Buttery,Richard Diehl Martinez
### Background
低参数高效的模型方法如LoRA已经颠覆了大型语言模型（LLM）的微调过程。ReLoRA则将这一理念扩展到预训练阶段，通过反复合并和重新初始化低秩适配器，不断增加累积秩，同时保持更新成本低廉。这与高容量模型通过时间和空间上逐渐扩展的局部低秩轨迹学习观察结果相吻合。而近期的研究表明，小语言模型（SLMs）存在秩不足情况，并未充分使用其维度空间，这引发了一个自然的问题：ReLoRA的扩展秩更新规则是否可以引导SLMs向更健康的训练动态转变，特别是在容量受限的环境下缓解秩瓶颈？
### Innovation
ReLoRA通过反复合并和重新初始化低秩适配器，增加了累积秩的同时保持更新成本低廉，这是相较于传统方法的一种创新。这种更新规则可以在大型语言模型中扩大秩，但在小语言模型中的效果并不明显。此外，研究还揭示了ReLoRA如何放大现有秩不足并引发早期训练中的病态更新，以及需要探索适应性秩或混合秩方法以适应低计算量预训练的需求。
### Conclusion
我们的研究结果表明，虽然ReLoRA的合并和重新初始化策略可以在较大模型中扩大秩，但在容量受限的小语言模型中并不直接适用，这促使研究人员去探索适应性秩或混合秩的方法以进行低计算量预训练。
## 324. `cs.AI` - SpeechWeave：用于训练文本转语音模型的多样化多语言合成文本与音频数据生成流水线 [PDF](https://arxiv.org/pdf/2509.14270), [HTML](https://arxiv.org/abs/2509.14270)
### Authors
Karan Dua,Puneet Mittal,Ranjeet Gupta,Hitesh Laxmichand Patel
### Background
高质量的文本转语音(TTS)模型训练需要大量的多样化文本和语音数据，但很难从真实数据源中获取，因为存在领域特定性、版权和可扩展性等问题。大型语言模型可以生成文本数据，但在生成过程中会生成重复的文本，缺乏多样性。此外，TTS训练数据中的文本规范化也是一个重要方面，但现有的工具可能会引入异常或忽略有价值的数据模式，影响数据质量。对于大规模语音录制，依赖语音艺术家在商业TTS系统中也难以实现标准化。因此，需要一种方法来生成多样化的合成数据，以克服这些挑战。
### Innovation
本文提出了一种名为SpeechWeave的合成语音数据生成流水线，能够自动化生成多语言、领域特定的训练数据集，用于TTS模型的训练。实验表明，相较于基准模型，SpeechWeave生成的数据在语音和音标指标上更具多样性，同时生成的语音音频数据具有统一的说话人标准，正确的规范化文本约占97%。这种方法使得TTS训练中的数据生成更具扩展性、高质量，并提高了生成数据集中的多样性和规范化程度以及语音一致性。
### Conclusion
SpeechWeave为TTS模型的训练提供了多样化的多语言合成文本和音频数据，提高训练数据的质量和多样性，同时确保生成的文本正确规范化，并且能够实现语音细节的标准化。这种方法为大规模语音数据的生成提供了有力的解决方案，适用于商业TTS系统的标准化要求。
## 325. `cs.AI` - 使用深度神经网络发现软件并行化点 [PDF](https://arxiv.org/pdf/2509.16215), [HTML](https://arxiv.org/abs/2509.16215)
### Authors
Izavan dos S. Correia,Henrique C. T. Santos,Tiago A. E. Ferreira
### Background
本文研究了利用深度学习方法自动识别编程代码中的并行化结构的可行性。背景在于，对于大型复杂的软件开发项目，如何高效地发现可以并行执行的代码块（即并行化点）以提高整体性能，是一个重要的优化问题。
### Innovation
该研究创新之处在于提出了一种基于深度学习的方法来发现编程代码中的并行化结构。开发了两个基于遗传算法的代码生成器，分别用于生成完全独立和依赖关系不清的代码片段，以此训练两种深度学习模型：深度神经网络（DNN）和卷积神经网络（CNN），并进行了严格的统计分析以验证模型性能。
### Conclusion
结果表明，使用深度学习技术自动化识别可并行化的代码结构是可行的，可以为软件优化提高性能提供有力工具。卷积神经网络在均值性能上略高于深度神经网络，但两者在表现的稳定性方面相似。数据多样性的大小对模型性能有重要影响。
## 326. `cs.AI` - 机器直到不是比人类更高效，人类也是如此 [PDF](https://arxiv.org/pdf/2509.14057), [HTML](https://arxiv.org/abs/2509.14057)
### Authors
Riccardo Zanardelli
### Background
随着人工智能技能的增长，组织面临着通过经济原则来优化技能政策决策的挑战。现有研究指出自动化在低到中等复杂度的任务中更为经济有效，但对于更复杂的任务，人类技能可能更具优势。然而，当需要高抽象度转化且错误成本高时，人类和机器技能的综合使用可能更为有效，尤其是在未实现这种协同效应时，混合策略可能导致效率低下。本研究通过基于蒙特卡洛模拟的虚拟框架分析不同类型任务中人类和机器技能的经济影响。
### Innovation
本研究发展了一种基于蒙特卡洛模拟的虚拟框架，该框架在实证现实的基础上建模人类和机器技能的经济影响，特别是在不同复杂度的任务中的表现。通过这种框架，研究揭示了在需要高抽象度转化且错误成本高时，人类和机器技能的综合使用可能更为有效，但前提是必须实现这种协同效应。此外，研究强调了改善机器技能成本效益的时间性，并指出这并不能替代追求增强融合的本质需求。
### Conclusion
对于决策者而言，复杂和关键的业务环境中，单纯将人类和机器技能分配给任务是不够的。人类和机器技能的政策并不是一种万能的解决方案，也不是一种低风险的妥协。相反，它是一个需要组织团队强烈承诺以提高竞争力的重要机会。此外，研究结果表明，随着时间的推移提高机器技能的成本效益是有用的，但这不能取代关注实现增强融合的基本需求。
## 327. `cs.AI` - MOSAIC: 多语言、无关分类法和计算效率的放射学报告分类方法 [PDF](https://arxiv.org/pdf/2509.04471), [HTML](https://arxiv.org/abs/2509.04471)
### Authors
Alice Schiavone,Marco Fraccaro,Lea Marie Pehrson,Silvia Ingala,Rasmus Bonnevie,Michael Bachmann Nielsen,Vincent Beliveau,Melanie Ganz,Desmond Elliott
### Background
放射学报告包含丰富的临床信息，可以用于训练影像模型，而无需依赖昂贵的手动标注。然而，现有的方法面临一系列限制：基于规则的方法难以应对语言差异性，监督模型需要大量标注数据集，近年来基于大规模语言模型（LLM）的方法依赖于封闭源或计算密集型模型，这些不适合临床使用。此外，当前的解决方案主要局限于英语和单一类型的模态和分类数据集。
### Innovation
我们提出了MOSAIC，一种多语言、无关分类法和计算效率高的放射学报告分类方法。MOSAIC基于紧凑型开源语言模型（MedGemma-4B），支持零/少样本提示和轻量级微调，可以在消费者级GPU上部署。MOSAIC在英语、西班牙语、法语和丹麦语的七个数据集中进行了评估，涵盖了多种成像模态和标签分类。模型在五个胸部X射线数据集上达到了88的宏F1分数，接近或超过了专家水平的表现，同时仅需要24GB的GPU内存。利用数据增强技术，只需80个标注样本就可以在丹麦报告上达到82的加权F1分数，相当于在完整的1600样本训练集上的86表现。MOSAIC 提供了在临床环境中替代大型或专有大规模语言模型的实用选择。代码和模型均为开源。我们邀请社区在新的语言、分类法和模态上对MOSAIC进行评估和扩展。
### Conclusion
MOSAIC作为在临床环境中实用的替代方案，提供了多语言支持、无关分类法和计算效率高的放射学报告分类方法，能够在消费者级GPU上运行，具有广泛的适用性。
## 328. `cs.AI` - IndexNet：针对时间序列预测的时间戳和变量感知建模 [PDF](https://arxiv.org/pdf/2509.23813), [HTML](https://arxiv.org/abs/2509.23813)
### Authors
Beiliang Wu,Peiyuan Liu,Yifan Hu,Luyan Zhang,Ao Hu,Zenglin Xu
### Background
多变量时间序列预测（MTSF）在很多实际应用中起到关键作用，例如天气预测和交通流量预测。尽管近年来的方法显著提高了对时序动态和变量间依赖性的建模能力，但大多数现有的方法忽略了索引相关的描述信息，如时间戳和变量索引，这些信息含有丰富的语境语义。因此，本研究旨在利用这些信息，并结合基于MLP的轻量级且强大的周期性捕捉能力，提出了IndexNet框架，该框架包含一个扩充模块Index Embedding (IE)，通过Timestamp Embedding (TE)和Channel Embedding (CE)来优化模型的性能。
### Innovation
IndexNet是一个基于MLP的框架，新增了Index Embedding (IE)模块，该模块由Timestamp Embedding (TE)和Channel Embedding (CE)两部分组成。其中TE将时间戳转化为嵌入向量并注入输入序列中，增强了模型捕捉长期复杂周期模式的能力；CE为每个变量分配一个独一无二且可训练的身份嵌入，使得模型能够明确区分不同的变量，避免了同质预测。
### Conclusion
在12个多样化的实际数据集上的实验结果证明，IndexNet在主流基准模型上取得了可比的性能，验证了我们的时空和变量感知设计的有效性。进一步的即插即用实验和可视化分析表明，IndexNet展现了很强的通用性和可解释性，这是当前MTSF研究中尚未充分探讨的两个方面。
## 329. `cs.AI` - AI生产力指数 (APEX) [PDF](https://arxiv.org/pdf/2509.25721), [HTML](https://arxiv.org/abs/2509.25721)
### Authors
Bertie Vidgen,Abby Fennelly,Evan Pinnix,Chirag Mahapatra,Zach Richards,Austin Bridges,Calix Huang,Ben Hunsberger,Fez Zafar,Brendan Foody,Dominic Barton,Cass R. Sunstein,Eric Topol,Osvald Nitski
### Background
当前，尽管人工智能（AI）在编程等任务中表现出色，但在评估AI模型执行高经济价值知识工作的能力方面仍存在重大不足。为解决这一问题，作者提出了AI生产力指数（APEX），这是一种基准测试方法，用于评估前沿AI模型是否能完成具有高经济价值的知识工作。
### Innovation
APEX-v1.0 包含200个测试案例，涵盖了投资银行业务、管理咨询、法律和初级医疗服务四个领域。该指数是通过三个步骤构建的：第一步，汇集了经验丰富的专家，例如来自于高盛的投资银行家；第二步，专家创建反映了日常工作中的高价值任务的提示；第三步，专家制定了评估模型响应的评分标准。通过这些步骤，APEX能够更全面地评估前沿AI模型在不同领域的表现。
### Conclusion
GPT 5（思考 = 高）在APEX-v1.0上的平均得分为64.2%，显示出最强的性能。尽管顶尖模型的性能超过了大多数开源模型，但人类专家的表现仍然远远超出最佳模型的水平，这暗示需要更好地衡量模型在经济上有价值的工作中的能力。
## 330. `cs.AI` - Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation [PDF](https://arxiv.org/pdf/2509.24798), [HTML](https://arxiv.org/abs/2509.24798)
### Authors
Lei Tong,Zhihua Liu,Chaochao Lu,Dino Oglic,Tom Diethe,Philip Teare,Sotirios A. Tsaftaris,Chen Jin
### Background
该研究背景在于现有技术通过提示工程调整冻结的文本到图像扩散骨干网络，但缺乏明确的因果结构，因此在进行目标属性干预时，可能会导致无效的连锁反应或身份丢失。Causal-Adapter框架旨在通过结合结构因果建模和两种属性正则化策略来解决这些问题，以实现对影像的精确控制和高保真度生成。
### Innovation
Causal-Adapter通过引入特定的设计策略实现其创新点：1) 使用提示对齐的因果属性注入，确保文本和图像之间的精确语义控制；2) 引入有条件标记对比损失，以分离属性因素，减少无关变量的直接影响。这些策略使得Causal-Adapter在合成和真实世界数据集上都表现出了卓越的性能。
### Conclusion
Causal-Adapter在 Pendulum 幻觉属性编辑和 ADNI 高分辨率 MRI 影像生成任务中表现出色，精度分别提高了 91% 和 87%，证明了该方法能够实现鲁棒、通用的镜像编辑，具有忠实属性修改和强烈的身份保留能力。
## 331. `cs.AI` - Segmentor-Guided Counterfactual Fine-Tuning for Locally Coherent and Targeted Image Synthesis [PDF](https://arxiv.org/pdf/2509.24913), [HTML](https://arxiv.org/abs/2509.24913)
### Authors
Tian Xia,Matthew Sinclair,Andreas Schuh,Fabio De Sousa Ribeiro,Raghav Mehta,Rajat Rasal,Esther Puyol-Antón,Samuel Gerber,Kersten Petersen,Michiel Schaap,Ben Glocker
### Background
目前的反事实图像生成方法依赖于外部分类器或回归器来提高个体水平干预的效果（如改变患者的年龄）。但对于特定结构的干预（如胸部X光片中左肺的面积改变），这些方法可能不足以产生局部一致且有效的反事实图像，可能会导致在整个图像域内产生不希望的全局效果。先前的工作使用像素级标签图作为指导，但需要用户提供假想的分割，这往往很耗时且难以获取。
### Innovation
本文提出了Segmentor-guided Counterfactual Fine-Tuning (Seg-CFT) 方法，保持了对标量值结构特定变量干预的简单性，同时生成了局部一致且有效的反事实图像。Seg-CFT 没有依赖像素级标签图，而是通过引导器（segmentor）提供局部指导，使得生成的图像更符合预期的目标干预效果。
### Conclusion
本文通过 Seg-CFT 生成了具有高逼真度的胸部X光图像，并展示了其在冠状动脉疾病建模方面的潜在应用，证明了该方法的有效性和实用性。
## 332. `cs.AI` - 《欧几里得的礼物：通过几何代理任务提升视觉语言模型的空间感知与推理能力》 [PDF](https://arxiv.org/pdf/2509.24473), [HTML](https://arxiv.org/abs/2509.24473)
### Authors
Shijie Lian,Changti Wu,Laurence Tianruo Yang,Hang Yuan,Bin Yu,Lei Zhang,Kai Chen
### Background
空间智能涵盖了多种能力，如可视化和变换形状、在心中旋转对象、判断相对位置和包含关系，以及估算数量。然而，为多模态大型语言模型（MLLM）实现这一能力仍然是一个重要的未解决问题。为了克服这一挑战，本文提出将欧几里得几何问题解决作为代理任务。
### Innovation
本文精心构建了一个名为Euclid30K的多模态数据集，包含约30000个平面和立体几何问题，通过Group Relative Policy Optimization（GRPO）微调Qwen2.5VL和RoboBrain2.0家族模型，使模型能够从几何问题中学习和应用欧几里得原则。实验表明，在四个空间推理基准测试（Super-CLEVR、Omni3DBench、VSI-Bench、MindCube）上，微调后的模型在零样本设置下实现了显著改进，特别是在VSI-Bench上，平均准确率从34.5%提升到40.5%，其中RoboBrain2.0-Euclid-7B的准确率达到49.6%，优于此前的最佳模型，这是首个系统研究几何微调可赋予视觉语言模型广泛迁移空间技能的研究。
### Conclusion
我们的研究表明，几何中心的微调可以赋予视觉语言模型广泛迁移的空间技能。Euclid30K数据集和相关代码可以在指定链接中找到。
## 333. `cs.AI` - GeoSQL-Eval: 首次基于PostGIS的NL2GeoSQL查询评估 [PDF](https://arxiv.org/pdf/2509.25264), [HTML](https://arxiv.org/abs/2509.25264)
### Authors
Shuyang Hou,Haoyue Jiao,Ziqi Liu,Lutong Xie,Guanyu Chen,Shaowen Wu,Xuefeng Guan,Huayi Wu
### Background
大型语言模型（LLMs）在一般数据库中的自然语言到SQL（NL2SQL）任务中展现了强大的性能。但是，当扩展到GeoSQL时，由于引入了空间数据类型、函数调用和坐标系等问题，生成和执行的难度大大增加。现有的基准主要针对通用SQL，而系统化的GeoSQL评估框架仍然缺乏。为了解决这一问题，该研究提出了GeoSQL-Eval，这是一个针对PostGIS查询生成的端到端自动化评估框架，以及GeoSQL-Bench，一个评估LLM在NL2GeoSQL任务中的性能基准。GeoSQL-Bench定义了三个任务类别：概念理解、语法级别SQL生成和模式检索，共包含14,178个实例、340个PostGIS函数和82个主题数据库。
### Innovation
首次提出了GeoSQL-Eval框架，这是一个针对PostGIS的端到端自动化评估框架，以及GeoSQL-Bench基准，用于评估LLM在NL2GeoSQL任务中的表现。GeoSQL-Eval基于Webb的深度知识（DOK）模型，涵盖了四个认知维度、五级能力水平和二十种任务类型，从知识获取、语法生成到语义对齐、执行准确性和鲁棒性建立了一个全面的过程。同时应用熵权法和统计分析找出性能差异、常见错误模式和资源使用情况。通过提供公共GeoSQL-Eval排行榜平台，实现持续测试和全球比较。这项工作扩展了NL2GeoSQL范式，并为评价空间数据库环境中的LLMs提供了一个标准、可解释且可扩展的框架，为地理空间信息科学及相关应用提供了有价值的参考。
### Conclusion
GeoSQL-Eval和GeoSQL-Bench使得对基于PostGIS的NL2GeoSQL查询生成进行系统性和标准化的评估成为可能，为研究LLMs在空间数据库中的性能提供了有力工具，同时也为地理空间信息科学及相关应用指明了研究方向。
## 334. `cs.AI` - VRWKV-Editor: 在基于变换器的视频编辑中降低二次复杂度 [PDF](https://arxiv.org/pdf/2509.25998), [HTML](https://arxiv.org/abs/2509.25998)
### Authors
Abdelilah Aitrouga,Youssef Hmamouche,Amal El Fallah Seghrouchni
### Background
近年来，视频编辑领域取得了显著进展，深度学习模型在处理空时依赖性方面发挥重要作用。然而，这些模型受到传统注意力机制的二次计算复杂度限制，难以适应长时间和高分辨率视频的需要，这一局限性限制了它们在实时视频处理等实际场景中的应用。
### Innovation
为解决这一挑战，本文提出了一种名为VRWKV-Editor的新颖视频编辑模型，该模型通过将线性空时聚合模块集成到基于扩散模型的视频编辑中，以削减时间和空间复杂度。VRWKV-Editor利用RWKV变换器的双向加权键值重复机制捕捉全局依赖性同时保持时间连续性，从而实现线性复杂度而不牺牲质量。
### Conclusion
广泛的实验表明，所提出的方法相比当前最先进的基于扩散的视频编辑方法可实现高达3.7倍的加速和60%的内存使用率减少，同时保持在逐帧一致性和文本对齐方面的竞争力。此外，我们对不同序列长度的视频进行的对比分析还证实，与自注意架构相比，我们方法在编辑速度的差距随视频长度增加而增大。
## 335. `cs.AI` - AbsTopK：重新审视稀疏自编码器以获得双向特征 [PDF](https://arxiv.org/pdf/2510.00404), [HTML](https://arxiv.org/abs/2510.00404)
### Authors
Xudong Zhu,Mohammad Mahdi Khalili,Zhihui Zhu
### Background
稀疏自编码器（SAEs）已被广泛应用于大型语言模型（LLMs）的可解释性分析中，其目的是将隐藏状态分解为有意义的语义特征。然而，现有的SAEs变体还没有统一的理论基础源自原始的稀疏编码字典学习形式。本文通过展开邻近梯度方法来引入这种框架，表明单步更新可以自然地恢复常见的稀疏自编码器变体，如ReLU、JumpReLU和TopK。在这个视角下，作者揭示了现有稀疏自编码器的一个基本限制：它们导致的稀疏化正则化器限制了非负性，这阻碍了单一特征表示双向概念（例如，男性与女性）。这种结构约束将语义轴拆分为多个独立且冗余的特征，限制了代表的完整性。
### Innovation
本文提出了AbsTopK稀疏自编码器，这是一种从$textbackslash$l_0$稀疏性约束中推导出来的新型变体，通过在最大幅度激活上进行硬阈值化保留了正负激活。AbsTopK通过同时保留正负激活揭示了更丰富的、双向的概念表示。实验结果表明，AbsTopK提高了重建保真度，增强了可解释性，并且能够使单一特征编码对立的概念。值得注意的是，AbsTopK在某些任务上甚至匹配或超越了需要标注数据的Difference-in-Mean方法，之前的研究中发现该方法在某些情况下比稀疏自编码器表现更好。
### Conclusion
通过广泛的实验，AbsTopK在四个LSTM、七个探针和操控任务上展示了在重建保真度、可解释性以及编码对立概念方面的优越性。这种方法不仅克服了现有稀疏自编码器的非负性约束带来的限制，还提供了一种新的、更全面的特征表示方法。
## 336. `cs.AI` - 更大的模型更好吗？医学诊断中CNN与生物医学视觉语言模型的比较分析 [PDF](https://arxiv.org/pdf/2510.00411), [HTML](https://arxiv.org/abs/2510.00411)
### Authors
Ran Tong,Jiaqi Liu,Su Liu,Jiexi Xu,Lanruo Wang,Tong Wang
### Background
医学影像中的胸部X光片准确解释是重要的任务。本研究通过对比监督学习下的轻量级卷积神经网络（CNN）和最新的零样本医学视觉语言模型（VLM）BiomedCLIP在肺炎检测和肺结核检测任务中的表现来探讨这一问题。
### Innovation
论文证明了简单的决策阈值校准可以大幅提升零样本VLM的性能，使其在肺炎和肺结核检测任务中均达到甚至超越监督学习模型的性能。研究提供了在零样本条件下校准模型阈值的重要性见解。
### Conclusion
适当的校准对于充分发挥零样本VLM的诊断能力至关重要，它们能够匹配甚至超过特定任务的监督学习模型的效率和准确性。
## 337. `cs.AI` - 不连续表位片段作为高效配体设计的有效目标模板 [PDF](https://arxiv.org/pdf/2509.25479), [HTML](https://arxiv.org/abs/2509.25479)
### Authors
Zhenfeng Deng,Ruijie Hou,Ningrui Xie,Mike Tyers,Michał Koziarski
### Background
结构导向的蛋白质设计近年来取得了进展，加速了全新结合体的生成。然而，对于大结构域或跨多个结构域的界面，由于高计算成本和随目标规模增加而成功率下降，设计仍具挑战性。研究推测，蛋白质折叠神经网络（PFNNs）以‘局部优先’的方式操作，优先处理局部相互作用，而对全局折叠性敏感性有限。基于这一假设，提出了一种仅保留结合位点周围断续表面残基的表位策略，这种方法在体外成功率提高了最高80%，平均每个成功设计的时间降低了40倍，使对抗先前难以解决的目标如ClpP和ALS3的配体设计成为可能。此后，进一步开发了一种定制的管线，其中包括基于蒙特卡罗的演化步骤以克服局部最小值，以及位置特异性偏差逆折叠步骤以优化序列模式，这些改进不仅建立了针对大结构和否则难以访问的目标高效配体设计的一般框架，还支持引导起源基于PFNN的设计的‘局部优先’假设。
### Innovation
提出了一种仅保留断续表位残基的策略，这些特殊残基围绕结合位点，这种方法显著提高了设计成功率并大幅缩短了设计时间。进一步发展了定制化的设计管线，整合了基于蒙特卡罗的演化步骤和位置特异性偏差逆折叠步骤，以解决局部最小值问题并优化序列模式。这些创新不仅提高了大结构和难以接触的目标的配体设计效率，还支持了PFNN设计的‘局部优先’假设。
### Conclusion
这项研究不仅建立了一种高效设计针对结构庞大和难以接触的配体的一般框架，还验证了PFNN设计中‘局部优先’的指导原则。这些发现对于推进蛋白质设计和相关分子识别技术具有重要意义。
## 338. `cs.AI` - Tenyidie 喉涕 书写注音语料库构建及其深度学习应用 [PDF](https://arxiv.org/pdf/2510.00629), [HTML](https://arxiv.org/abs/2510.00629)
### Authors
Teisovi Angami,Kevisino Khate
### Background
Tenyidie是一种低资源语言，属于藏缅语系，主要由印度东北部那加兰邦的Tenyimia社群使用，并被视为那加兰的语言之一。这种语言是音调语言，主宾语动词结构，高度黏着语，由于资源有限，对自然语言处理（NLP）的研究非常有限。据我们所知，关于该语言的研究中，还没有关于书写音节划分的工作。
### Innovation
该研究首次构建了10,120个Tenyidie语言的音节化语料库，并在其上应用了不同的深度学习模型，包括LSTM、双向LSTM、双向LSTM+CRF以及编码器-解码器架构。在80:10:10（训练：验证：测试）的数据集划分中，双向LSTM模型在测试集上的准确率达到99.21%。这项工作将为Tenyidie语言的形态分析、词性标注、机器翻译等应用提供基础。
### Conclusion
该研究通过构建Tenyidie语言的音节化语料库和应用深度学习技术，取得了显著的成果，并为其在其他NLP中的应用奠定了基础。
## 339. `cs.AI` - 使用熵指导条件变分自编码器的不确定性意识生成过采样 [PDF](https://arxiv.org/pdf/2509.25334), [HTML](https://arxiv.org/abs/2509.25334)
### Authors
Amirhossein Zare,Amirhessam Zare,Parmida Sadat Pezeshki,Herlock(SeyedAbolfazl)Rahimi,Ali Ebrahimi,Ignacio Vázquez-García,Leo Anthony Celi
### Background
在机器学习中，类别不平衡是一个主要问题，尤其是在高维生物医学数据中，非线性流形结构占主导地位。传统的过采样方法，如SMOTE（合成少数过采样技术），依赖于局部线性插值，经常生成不切实际的合成样本。虽然深层生成模型如条件变分自编码器（CVAEs）能够更好地捕捉非线性分布，但标准版本往往对所有少数类样本处理一致，忽视了边缘区域的不确定性，在这些区域，启发式方法如Borderline-SMOTE和ADASYN（自适应分布自适应合成算法）强调了这些样本的重要性。基于这些背景，研究提出了一种新的生成过采样框架Local Entropy-Guided Oversampling with CVAE（LEO-CVAE），该框架在表征学习和数据生成中显式地将局部不确定性纳入考虑。通过计算局部样本邻域内的香农熵来量化不确定性，熵高的情况代表更高的类别重叠，作为不确定性的代理指标。LEO-CVAE通过两种机制利用这一信号：(i) 局部熵加权损失（LEWL），它强调在不确定区域中学习的鲁棒性，(ii) 通过一种导向于不确定区域的采样策略，将生成集中在这些信息性强、类别重叠的区域。
### Innovation
LEO-CVAE提出了一种全新的方法，在条件变分自编码器框架中引入了局部不确定性加权，以提高在复杂非线性结构中的不平衡学习效果。包括局部熵加权损失来增强不确定区域的鲁棒性学习，以及基于不确定性采样策略来精准生成重叠区域的样本。这种方法能够有效地提高分类器在不平衡数据集上的性能，特别是在生物医学高维数据集应用场景中表现突出，并且优于传统的过采样和生成模型基准方法。
### Conclusion
研究通过应用LEO-CVAE到临床基因组学数据集（ADNI和TCGA肺癌数据）上，展示了不确定性意识生成过采样的有效性和优越性。这些结果显示，在控制着复杂非线性结构的数据类型（如组学数据）的不平衡学习领域，生成过采样方法需要考虑样本的不确定性，以提供更好的模型性能和数据表示能力。
## 340. `cs.AI` - 使用检索增强生成在奥林匹克级别物理问题解决中基准测试基础模型 [PDF](https://arxiv.org/pdf/2510.00919), [HTML](https://arxiv.org/abs/2510.00919)
### Authors
Shunfeng Zheng,Yudi Zhang,Meng Fang,Zihan Zhang,Zhitan Wu,Mykola Pechenizkiy,Ling Chen
### Background
检索增强生成（RAG）与基础模型在各种任务中取得了强大的性能，但在专家级推理能力，例如解决奥林匹克级别的物理问题方面的能力仍未被广泛探索。受学生通过复习以往问题为竞赛做准备的方式启发，研究探讨了RAG在基础模型中增强物理推理的潜力。介绍了PhoPile，这是一个专门设计用于奥林匹克级别物理的高质量多模态数据集，能够系统研究基于检索的推理。PhoPile包含图表、图形和方程，捕捉了物理问题解决的固有多模态特征。
### Innovation
引入了PhoPile，一个用于奥林匹克级别物理问题的高质量多模态数据集，方便系统研究基于检索的推理。此外，使用PhoPile基准测试增强检索的大型语言模型（LLMs）和大型多模态模型（LMMs），证明了结合检索与物理语料库可以提升模型性能，同时也指出了进一步研究检索增强物理推理的挑战。
### Conclusion
结合检索与物理语料库能够提高模型性能，但同时也揭示了在检索增强物理推理方面的挑战，这将激发进一步的研究。
## 341. `cs.AI` - Normal-Abnormal Guided Generalist Anomaly Detection [PDF](https://arxiv.org/pdf/2510.00495), [HTML](https://arxiv.org/abs/2510.00495)
### Authors
Yuexin Wang,Xiaolei Wang,Yizheng Gong,Jimin Xiao
### Background
目前的通用异常检测（Generalist Anomaly Detection, GAD）方法主要依赖正常样本作为参考，忽视了在实际场景中常见的异常样本所携带的价值信息。这限制了在不同领域之间的异常检测能力。因此，需要一种能利用正常和异常样本作为参考来指导跨领域异常检测的方法。
### Innovation
本文提出了一种名为Normal-Abnormal Generalist Learning（NAGL）的框架，结合Residual Mining（RM）和Anomaly Feature Learning（AFL）两项关键技术。RM从正常-异常参考残差中提取异常模式，建立可迁移的异常表示。AFL通过残差映射在查询图像中适配学习异常特征以识别实例感知的异常。这种方法首次在通用异常检测中采用了正常和异常样本的混合作为参考，显著提升了跨域异常检测的准确性和效率。
### Conclusion
跨领域的异常检测实验在多个基准上显示，该方法明显优于现有的GAD方法。
## 342. `cs.AI` - 更多思考，还是更低的准确性？在视觉语言模型中推理的双重性质 [PDF](https://arxiv.org/pdf/2509.25848), [HTML](https://arxiv.org/abs/2509.25848)
### Authors
Xinyu Tian,Shu Zou,Zhaoyuan Yang,Mengqi He,Fabian Waschkowski,Lukas Wesemann,Peter Tu,Jing Zhang
### Background
大型语言模型（LLMs）逐渐成为一种关键能力，它们通过强化学习（如组相对策略优化GRPO）能够解决诸如数学和代码生成等复杂任务。基于这些进展，最近的研究致力于将推理能力扩展到视觉语言模型（VLMs），在各种视觉任务上取得了令人鼓舞的结果。然而，研究中发现，这种多模态推理虽然显著增强了逻辑推理，并使模型能够解决更具挑战性的问题，但也可能逐渐削弱对视觉输入的感知基础，导致在简单的视觉问题上出现识别失败。这种现象被归因于视觉遗忘，即长时间的推理过程让模型越来越多地忽视视觉输入。
### Innovation
该研究提出了一种简单而有效的方法——视觉锚定策略优化（VAPO），以将推理过程导向视觉上更有依据的路径，从而解决视觉遗忘问题。结果表明，使用VAPO方法开发的VAPO-Thinker-7B模型极大地强化了模型对视觉信息的依赖，并在多种基准测试中达到了新的最佳性能。
### Conclusion
该研究揭示了视觉语言模型推理能力的双重性质，指出虽然增强的推理能力有助于解决复杂问题，但可能逐渐减弱对视觉输入的依赖，导致基本的视觉识别问题上的失败。为了解决这一问题，提出了VAPO方法，该方法成功地加强了模型对视觉信息的依赖，并在多个基准测试中取得了最佳性能。
## 343. `cs.CL` - 使用概念学习数据集在大型语言模型中发现隐含偏见 [PDF](https://arxiv.org/pdf/2510.01219), [HTML](https://arxiv.org/abs/2510.01219)
### Authors
Leroy Z. Wang
### Background
论文介绍了一个概念学习任务的数据集，旨在揭示大型语言模型中的隐含偏见。研究发现，当使用上下文内的概念学习实验时，语言模型可能对量词的向上单调性表现出偏见；这种偏见在直接提示测试（不包含概念学习组件）时较为不明显。
### Innovation
通过引入一个概念学习任务的数据集，该研究揭示了语言模型中的隐含偏见。特别地，该研究发现了模型在涉及量词的上下文学习中表现出的向上单调性偏见，而这一偏见在直接提示测试中不明显。
### Conclusion
研究表明，通过上下文内的概念学习可以有效地发现语言模型中的隐藏偏见。这意味着概念学习可以是一种揭示语言模型中潜在偏见的有效方法。
## 344. `cs.AI` - MOSS-Speech：无需文本指导的真正端到端语音模型 [PDF](https://arxiv.org/pdf/2510.00499), [HTML](https://arxiv.org/abs/2510.00499)
### Authors
Xingjian Zhao,Zhe Xu,Qinyuan Cheng,Zhaoye Fei,Luozhijie Jin,Yang Wang,Hanfu Chen,Yaozhou Jiang,Qinghui Gao,Ke Chen,Ruixiao Li,Mingshu Chen,Ruiming Wang,Wenbo Zhang,Yiyang Zhang,Donghua Yu,Yang Gao,Xiaogui Yang,Yitian Gong,Yuanfan Xu,Yaqian Zhou,Xuanjing Huang,Xipeng Qiu
### Background
口语对话系统通常依赖于级联管道，包括转录、处理和重新合成语音。虽然这些设计有效，但它们会丢弃副语言提示并限制表达力。尽管最近的端到端方法可以减少延迟并更好地保留这些提示，但它们仍然依赖于文本中介，为了解决这一根本瓶颈，本文提出了MOSS-Speech，这是一种直接理解和生成语音且不依赖于文本指导的大型语言模型。
### Innovation
本文提出了一种名为MOSS-Speech的端到端大型语言模型，该模型直接理解并生成语音，而不依赖于文本指导。该方法结合了一种基于模态的分层结构和一个冻结预训练策略，保留了预训练文本大型语言模型的推理和知识，同时增添了固有的语音能力。实验表明，该模型在口语问答方面取得了最先进的成果，并且在直接语音生成方面与现有文本指导系统可相比，同时仍能保持竞争性的文本性能。通过缩小文本指导与直接语音生成之间的差距，本文的工作建立了更具表现力和高效性的端到端语音交互的新范式.
### Conclusion
本文的工作展示了无需文本指导的真正端到端语音模型，该模型在口语问答方面取得了最先进的成果，并且在直接语音生成方面与现有文本指导系统可相比，同时仍保持了竞争性的文本性能，从而缩小了文本指导与直接语音生成之间的差距，建立了新的范式。
## 345. `cs.CL` - 向低资源NLP的开放发现迈进 [PDF](https://arxiv.org/pdf/2510.01220), [HTML](https://arxiv.org/abs/2510.01220)
### Authors
Bonaventure F. P. Dossou,Henri Aïdasso
### Background
低资源语言的自然语言处理（NLP）仍然受到文本语料库缺乏、标准化拼写和可扩展注释管道的限制。尽管大型语言模型的最新进展改善了跨语言迁移能力，但由于它们依赖大规模的预收集数据和集中化的基础设施，这些模型仍难以服务于少数群体。此外，存在的数据收集管道通常是静态的，限制了基于预先存在的数据集的学习。
### Innovation
提出了一种新的范式，通过对话而不是静态数据集让AI实时学习新语言，强调人类机器合作中的不确定性，并通过结合模型的先验不确定性以及说话者的犹豫信号和信心信号来指导交互、查询选择和记忆保留。
### Conclusion
呼吁重新思考AI与未记录语言社区的知识互动方式，从抽取式数据收集转向参与式、共同适应的学习过程，尊重并赋能社区，同时发现和保护世界语言多样性。这种愿景强调人机共融的模型构建，符合以人为本的AI原则，强调交互式的合作建模。
## 346. `cs.CL` - 语境很重要：兽医医学中商业大型语言模型的比较 [PDF](https://arxiv.org/pdf/2510.01224), [HTML](https://arxiv.org/abs/2510.01224)
### Authors
Tyler J Poore,Christopher J Pinard,Aleena Shabbir,Andrew Lagree,Andre Telfer,Kuan-Chuen Wu
### Background
大型语言模型(LLMs)在临床环境中越来越普遍，但在兽医医学中的应用尚未得到充分探索。已有研究尚未专门针对兽医领域进行总结工具的性能评测。
### Innovation
本研究采用LLM作为评分工具的方法，使用一个标准化的数据集，评估了三种商业化的兽医焦点LLM总结工具(Product 1 [Hachiko]、Product 2和Product 3)在兽医肿瘤学记录上的表现。研究采用了一种基于评分标准的LLM作为评分工具的框架，对五项指标（事实准确性、完整性、时间顺序性、临床相关性和组织性）进行评分。研究还验证了评分框架的一致性，通过三次独立评估，展示了LLM评分器的高重复性。
### Conclusion
兽医特定商业LLM工具非常重要，LLM作为一个评分工具的评估方法在兽医临床自然语言处理总结中的可扩展性和可重复性得到了验证。
## 347. `cs.AI` - 物理可解释的神经扩散过程用于生存预测 [PDF](https://arxiv.org/pdf/2510.00733), [HTML](https://arxiv.org/abs/2510.00733)
### Authors
Alessio Cristofoletto,Cesare Rollo,Giovanni Birolo,Piero Fariselli
### Background
该研究引入了一种基于深度学习的生存分析框架DeepFHT，结合了从随机过程理论中提取的第一个击中时间（FHT）分布。这种方法将事件发生的时间表示为持续过程到达吸边界的首次通过时间，并通过神经网络映射输入变量到物理上有意义的参数，包括初始条件、漂移和扩散。研究者对比了DeepFHT和Cox生存模型在合成数据集和实际数据集上的表现，结果显示DeepFHT在预测准确性方面达到了最先进的水平，同时保持了基于物理解释的参数化，揭示了输入特征和风险之间的关系。
### Innovation
该研究提出了一种结合深度学习和随机过程理论的生存分析框架DeepFHT，能够实现时间变化风险的捕捉，无需假设比例危险性。该模型能够提供具有物理意义的参数化表示，有助于理解输入特征与风险之间的关系。
### Conclusion
通过将随机过程理论与深度学习相结合，DeepFHT为复杂系统中生存现象建模提供了一种科学的方法。该方法在实际应用中展现了与当前最先进的技术相当的预测准确性，并保持了参数化表示的物理可解释性。
## 348. `cs.AI` - 大型语言模型中强化学习动态的可预测性 [PDF](https://arxiv.org/pdf/2510.00553), [HTML](https://arxiv.org/abs/2510.00553)
### Authors
Yuchen Cai,Ding Cao,Xin Xu,Zijun Yao,Yuqing Huang,Zhenyu Tan,Benyi Zhang,Guiquan Liu,Junfeng Fang
### Background
最近，大型语言模型（LLMs）表现出强大的推理能力，这一进步主要依赖于强化学习（RL）技术，但RL训练中参数动态的具体机制仍不甚明了。研究发现，RL对LLMs参数更新的两种基本特性：1. 等级-1主导性，即参数更新矩阵的前奇异子空间几乎完全决定着推理性能的提升；2. 等级-1线性动态，即这个主导子空间在整个训练过程中线性变化，从而可以提前预测训练的不同阶段。这些发现揭示了RL诱导的参数更新机制，并通过8种LLMs和7种算法的广泛实验验证了上述特性的一般适应性。
### Innovation
基于上述观测结果，该研究提出了一种名为AlphaRL的插件加速框架，利用初始训练阶段的数据来预测最终参数更新，实现了高达2.5倍的速度提升，同时保持了超过96%的推理性能，且无需额外组件或超参数调整。这一发现为大规模RL训练提供了一个灵活且实用的工具，并开拓了一个有原则且可解释的LLM训练范式的方法。
### Conclusion
该研究通过发现大型语言模型RL诱导参数更新的两种基本特性，并提出了AlphaRL插件加速框架，为大型语言模型训练提供了一种高效且具可解释性的方法，有助于实现更加高效和可控制的训练过程。
## 349. `cs.AI` - 机制化可解释性作为统计估计：EAP-IG 方差分析 [PDF](https://arxiv.org/pdf/2510.00845), [HTML](https://arxiv.org/abs/2510.00845)
### Authors
Maxime Méloux,François Portet,Maxime Peyrard
### Background
 trustworthy artificial intelligence 需要超越黑箱性能指标，转向理解模型内部计算。机制化可解释性 (MI) 旨在通过识别模型行为背后的算法机制来满足这一需求。但是，MI 的科学严谨性依赖于其发现的可靠性。本文中，我们提出，对于可解释性方法（例如电路发现）应该视为统计估计量，需要考虑方差和鲁棒性。我们通过全面的控制扰动来评估 EAP-IG 的方差和鲁棒性。研究结果显示，EAP-IG 在结构上表现出高方差，并对超参数敏感，这质疑了其发现的稳定性。
### Innovation
我们将机制化可解释性视为统计估计，并通过一个具体方法 EAP-IG 的方差分析来说明这种统计框架。研究通过输入重采样、提示重新表述、超参数变化和因果分析中的噪声注入等方式进行了全面的测试，展示了 EAP-IG 在结构上的高方差和对超参数的敏感性，从而揭示了解释性方法的不稳定性。
### Conclusion
我们提供了机制化可解释性领域的实践建议，推动常规报告稳定性度量，以促进更严谨和统计基础的可解释性科学。
## 350. `cs.CL` - 谁掌舵？解析指令遵循中的角色冲突 [PDF](https://arxiv.org/pdf/2510.01228), [HTML](https://arxiv.org/abs/2510.01228)
### Authors
Siqi Zeng
### Background
大型语言模型应该遵循分层指令，其中系统提示优先于用户输入，但最近的研究表明，这些模型通常忽视这条规则，强烈服从权威或共识这样的社会线索。本文扩展了这一行为发现，通过在大规模数据集上的实证解释，揭示了冲突决策信号被早期编码，并区分了系统-用户和社交冲突的空间。此外，直接逻辑归因显示，在系统-用户情况下内部冲突检测更强，但对于社交线索则保持一致的解决。
### Innovation
本文通过线性探测展示了冲突决策信号被早期编码，并区分了系统-用户和社交冲突的空间。直接逻辑归因揭示了系统-用户实例中的更强内部冲突检测，但在社交线索上保持一致的解决。定向实验显示，尽管使用社交线索，向量以一种无角色的方式放大指令遵循。
### Conclusion
这些结果解释了系统服从的脆弱性，并强调了对轻量级层级敏感对齐方法的需求。
## 351. `cs.AI` - EMR-AGENT: 自动化EMR数据库中队列和特征的提取 [PDF](https://arxiv.org/pdf/2510.00549), [HTML](https://arxiv.org/abs/2510.00549)
### Authors
Kwanhyung Lee,Sungsoo Hong,Joonhyung Park,Jeonghyeop Lim,Juhwan Choi,Donghwee Yoon,Eunho Yang
### Background
临床预测模型依赖于从电子医疗记录（EMRs）中提取的结构化数据，但这一过程仍主要由特定数据库的手写硬编码流水线来定义队列、选择特征和代码映射。这些手动工作限制了流程的可扩展性、可重复性和机构间的一般应用能力。为应对这一问题，我们介绍了一种名为EMR-AGENT（自动化通用提取导航工具）的代理框架，它利用动态的语言模型驱动交互以替代手动规则编写的方式，实现结构化临床数据的提取和标准化。框架通过交互查询数据库来自动选择队列、提取特征和进行代码映射，进一步使用SQL进行数据检索和数据库观察，并在决策中使用SQL。这消除了手工编写、特定于模式的逻辑的需求。为了实现严格的评估，我们开发了一套适用于三个EMR数据库（MIMIC-III、eICU、SICdb）的基准代码库，包括已见和未知模式的设置。我们的结果表明，在这些数据库中表现出色，并强调已经有可能自动化一个以前认为需要专家设计的过程。这份代码将在<https://this_is_an_example_url>上公开发布。如果你想进行演示，请访问我们的匿名演示页面：<https://this_is_an_example_anonymous_demo_url>，以了解该框架的实际应用和性能表现。
### Innovation
EMR-AGENT框架通过实现基于代理的方法，将手动规则编写替换为动态语言模型驱动的交互，从而实现了结构化临床数据的自动化提取和标准化。该框架通过交互式数据库查询自动选择队列、提取特征并进行代码映射。它利用SQL作为工具进行数据检索、数据库观察和决策制定，消除了需要手写特定于模式的逻辑的必要性。这种框架为自动化以前由专家驱动设计的流程提供了可能性。
### Conclusion
我们的研究表明，EMR-AGENT框架能够在多个EMR数据库中表现出色，并有效扩展了自动化数据提取的能力。该框架为临床预测模型提供了新的可能性，通过减少手动工作和提高可扩展性，增强了模型的一致性和重用性。我们未来的研究将进一步验证该框架在更多数据库和实际应用场景中的性能。
## 352. `cs.CL` - 通过不确定性量化和风险意识增强大型语言模型中的可信摘述 [PDF](https://arxiv.org/pdf/2510.01231), [HTML](https://arxiv.org/abs/2510.01231)
### Authors
Shuaidong Pan,Di Wu
### Background
在高风险场景下，自动总结的可靠性问题日益突出。这一研究针对信息过载和高风险决策的迫切需求，旨在开发一种结合不确定性量化和风险意识机制的大型语言模型框架。
### Innovation
该研究提出了一种基于条件生成的总结模型，并在生成过程中引入了贝叶斯推理来建模参数空间中的不确定性，有助于避免过自信预测。通过预测分布熵衡量生成内容的不确定性水平，并应用联合正则化熵和风险意识损失的优化手段，确保在信息压缩过程中保留关键信息并明确表达风险属性。在此基础上，模型还集成了风险评分和调整模块，以确保总结能够准确覆盖核心内容，并通过显式的风险等级提示增强可信度。
### Conclusion
对比实验和敏感性分析表明，所提出的方法能够显著提高高风险应用中总结的稳健性和可靠性，同时保持流畅性和语义完整性。这项研究在方法论层面上提供了一种系统的解决方案，展示了其实用性和可扩展性。
## 353. `cs.CL` - GRPO++: 在资源稀缺环境下增强皮肤科推理能力 [PDF](https://arxiv.org/pdf/2510.01236), [HTML](https://arxiv.org/abs/2510.01236)
### Authors
Ismam Nur Swapnil,Aranya Saha,Tanvir Ahmed Khan,Mohammad Ariful Haque
### Background
视觉-语言模型（VLMs）在医学图像分析中展现出潜力，但在复杂领域如皮肤科中的结构化推理能力受限于数据稀缺和高级训练技术的巨大计算成本。
### Innovation
提出了DermIQ-VLM，这是一种通过多阶段、资源高效方法开发的VLM，设计用于模拟皮肤科诊断过程，并引入了改良后的Grouped Relative Policy Optimization（GRPO++），用于推理导向性疾病的识别。接着使用直接偏好优化（DPO）对模型进行对齐，利用基于知识图谱的系统作为专家偏好的可扩展代理。
### Conclusion
初步评价表明，提出的方法在皮肤病学专用数据集上的性能显著优于标准微调方法。这些发现验证了我们的管道作为开发在资源受限环境中可行的专门可靠VLM的途径潜力。
## 354. `cs.CL` - EEFSUVA: 一个新的数学奥林匹克基准 [PDF](https://arxiv.org/pdf/2510.01227), [HTML](https://arxiv.org/abs/2510.01227)
### Authors
Nicole N Khatibi,Daniil A. Radamovich,Michael P. Brenner
### Background
近期，大型语言模型（LLMs）在数学基准测试上的表现引起了广泛关注，有人认为它们已经达到了奥运金牌级的奥林匹克到研究生水平的数学能力。然而，这些模型在基准测试中的表现可能被夸大的，主要因为基准测试的主要来源是国际数学奥林匹克（IMO）及其相关比赛，这对模型的能力纯度构成潜在威胁，并且过分强调了熟悉的问题类型。因此，需要新的基准来更全面地评估数学理解能力，特别是通过引入来自东欧及前苏联地区不太知名的地方和国家级奥林匹克竞赛问题的新基准——EEFSUVA，以弥补现有基准的不足。
### Innovation
本文引入了EEFSUVA，这是一种新的基准，从东欧和前苏联地区不太知名的地方和国家级奥林匹克竞赛中收集问题。这些竞赛的问题与IMO难度相当，但非标准问题解决技巧的需求更为突出，它们在互联网上的数据中相对罕见。这一创新旨在提供一个更全面的评估数学理解能力的方法，并用于指导未来模型的发展。
### Conclusion
初步结果表明，即使最先进的LLMs也无法像在其他奥林匹克风格的基准上那样，在EEFSUVA上表现出色。这些发现揭示了更广泛评估数据集对全面评估数学推理及指导未来模型发展的重要性。
## 355. `cs.CL` - LLMRank：理解大型语言模型优势以进行模型路由 [PDF](https://arxiv.org/pdf/2510.01234), [HTML](https://arxiv.org/abs/2510.01234)
### Authors
Shubham Agrawal,Prasang Gupta
### Background
随着具有多种能力和不同计算成本的大型语言模型（LLMs）快速增长，模型部署面临重要的挑战：如何为每个提示选择最合适的模型，以最佳地权衡性能与效率。当前的解决方案主要依赖于单一的潜在嵌入进行匹配，但未能充分考虑多方面因素，导致匹配效率偏低。
### Innovation
本文提出 LLMRank，这是一种提示感知路由框架，利用从提示中提取的丰富可读特征（如任务类型、推理模式、复杂度指示、语法线索，以及轻量级代理解决程序的提示信号）。LLMRank 使用基于 RouterBench 训练的神经排名模型（包含 36,497 个跨 11 个基准和 11 个最先进的大型语言模型的提示），能够更准确地预测每个模型的实用性。该方法能在保持较高匹配效率的同时提供可解释的特征归属，解释路由决策。
### Conclusion
实证研究表明，多维度特征的提取和混合排名目标对于提高模型路由的效率和透明性至关重要。此外，LLMRank 通过充分利用模型特征，达到了接近理想匹配的高效率，证明了以特征驱动的路由在高效透明地部署 LLM 方面的潜力。
## 356. `cs.CL` - 几何结构和意义的模式：基于PHATE流形分析的汉字嵌入几何分析 [PDF](https://arxiv.org/pdf/2510.01230), [HTML](https://arxiv.org/abs/2510.01230)
### Authors
Wen G. Gong
### Background
本文系统性地研究了汉字嵌入的几何模式，通过跨越七个嵌入模型和八个降维方法的交叉验证，观察到了内容词的聚类模式和功能词的分枝模式。在12个语义领域超过1000个汉字的分析中，发现几何复杂性与语义内容相关：有意义的汉字表现出丰富的几何多样性，而结构性的部首则聚合成紧密的簇。
### Innovation
研究采用了PHATE流形分析方法，通过对超过1000个汉字在12个语义领域的几何模式进行系统性研究，发现几何复杂性与语义内容之间的联系，并且通过123个短语的子网络分析展现了语义的系统性扩展，支持了传统语言学理论，提供了一种新的几何分析语义组织的方法。
### Conclusion
研究结果证明了基于汉字嵌入的几何结构和语义组织之间的关系，提供了对传统语言学理论的支持，并建立了一种新的几何分析框架，为理解和研究语义组织提供了新的视角。
## 357. `cs.CL` - ClaimCheck：使用小型语言模型进行实时事实核查 [PDF](https://arxiv.org/pdf/2510.01226), [HTML](https://arxiv.org/abs/2510.01226)
### Authors
Akshith Reddy Putta,Jacob Devasier,Chengkai Li
### Background
现有的事实核查系统大部分依赖于大型的闭源模型和静态知识库。这些系统在资源消耗和可解释性方面存在限制。因此，本文旨在介绍一种名为ClaimCheck的新型自动事实核查系统，该系统利用生产环境中的实时Web证据以及小型的自然语言处理模型来验证实际声明。
### Innovation
ClaimCheck采用了一种透明的、分步骤的事实核查管道，模拟了人类事实核查的工作流程，包括网络搜索查询规划、基于Web的证据检索和摘要、证据合成和再检索，以及声明判决评估。每个模块都针对小型LLM进行了优化，使得系统能够在显著降低计算资源需求的情况下提供准确且可解释的事实核查。尽管使用的是Qwen3-4B这样更小的模型，ClaimCheck仍能达到76.4%的AVeriTeC数据集准确率，超过了之前的LLaMA3.1 70B和GPT-4o方法。广泛的消融测试表明，精良的设计和提示策略能够克服小型LLM的局限性。
### Conclusion
为了促进易用性和透明度，作者提供了一个公共演示以供访问。ClaimCheck通过其创新的设计和优化的模块，有效地提高了事实核查的准确性和可解释性，同时大幅降低了计算成本。
## 358. `cs.CL` - 话语与排放：通过大语言模型分析企业的叙事、象征性实践及其模仿 [PDF](https://arxiv.org/pdf/2510.01222), [HTML](https://arxiv.org/abs/2510.01222)
### Authors
Bertrand Kian Hassani,Yacoub Bahini,Rizwan Mushtaq
### Background
气候变化增加了对企业气候信息披露的需求，但模仿和象征性报告往往损害了其价值。本研究使用大语言模型（LLMs）训练语料库评估828家公司的披露成熟度，并通过四个分类器（情感、承诺、具体性和目标雄心）从可持续性和年度报告中提取叙述指标，这些指标又与企业属性（如排放量、市值和行业）相关联。研究揭示了三个方面的重要见解：（1）风险导向的叙述通常与明确的承诺一致，但量化目标（如净零承诺）仍与语气脱节；（2）更大、更高排放的公司比同行披露了更多的承诺和行动，但与量化目标并不一致；（3）披露风格的广泛相似性表明了模仿行为的存在，这减少了差异化和决策有用性。这些结果强调了大语言模型在ESG叙述分析中的价值，以及需要更强有力的监管以将承诺与可验证的转型策略联系起来。
### Innovation
使用大型语言模型（LLMs）来分析企业的气候信息披露。通过四个分类器（情感、承诺、具体性和目标雄心），从可持续性和年度报告中提取叙述指标，并与企业属性关联。这种方法提供了一种新的、多维度的方式来评估企业的披露成熟度，强调了模仿行为在减少信息披露的独特价值方面的作用。
### Conclusion
研究揭示了三个关键发现：风险导向的叙述与承诺往往一致，但量化目标与语气脱节；更大、更高排放的公司披露更多承诺和行动，但与量化目标不一致；相似的披露风格表明了模仿行为的存在，减少了披露的独特价值和决策辅助功能。建议加强对企业承诺的监管，确保其与可验证的转型策略相连接。
## 359. `cs.CL` - 使用合成数据和LLM监督增强基于Transformer的重排序器 [PDF](https://arxiv.org/pdf/2510.01229), [HTML](https://arxiv.org/abs/2510.01229)
### Authors
Dimitar Peshevski,Kiril Blazhevski,Martin Popovski,Gjorgji Madjarov
### Background
文档重排序对于提高搜索相关性至关重要，但在多种应用程序中。虽然大型语言模型在重排序方面表现出色，因为它们具有深入的语义理解和推理能力，但其高计算成本使它们在许多实际部署中不切实际。相比之下，微调较小的任务特定模型是一种更高效的替代方案，但通常依赖于稀缺的、手动标注的数据。因此，我们提出了一种新管道，它消除了需要人类标注的查询-文档对的需要。此外，我们的方法使用大型语言模型从领域特定的语料库生成合成查询，并利用大型语言模型基于的分类器来标记正例和硬负例对。然后，使用局部对比损失（LCE损失）来进行对比学习，微调一个较小的变换器模型，从而生成的数据集。该方法在MedQuAD数据集上的实验表明，我们的方法显著提高了域内性能，并很好地泛化到跨域任务。这种方法通过使用大型语言模型生成数据和监督（而非进行推理）来减少计算成本，同时保持强大的重排序能力。
### Innovation
本文提出了一种使用大型语言模型生成合成查询和利用大型语言模型监督的新型管道。这种方法通过生成合成的数据集和使用局部对比损失（LCE损失）进行微调，有效地减轻了计算负担。同时，这种方法能够保持强大的重排序能力，并显著提升在领域的性能，并具有良好泛化到跨领域的性能。
### Conclusion
实验结果表明，这种方法可以显著提升基于Transformer的重排序器的性能，并展示出良好的跨领域泛化能力。通过使用大型语言模型生成数据和监督，我们可以有效降低计算成本，同时保持强大的重排序能力。
## 360. `cs.CL` - 基准剖析：LLM基准的机制诊断 [PDF](https://arxiv.org/pdf/2510.01232), [HTML](https://arxiv.org/abs/2510.01232)
### Authors
Dongjun Kim,Gyuho Shim,Yongchan Chun,Minhyuk Kim,Chanjun Park,Heuiseok Lim
### Background
通常，大型语言模型通过标准基准测试的成绩来评判，但这样的成绩往往夸大了模型的实际能力，因为它们忽视了实际任务所需的各种技能的混合情况。例如，ARC假设测试的是推理能力，而HellaSwag旨在评估常识。然而，缺乏一种系统的方法来验证这些基准是否确实衡量了这些标签。因此，本文介绍了一种名为基准剖析（Benchmark Profiling）的诊断框架，该框架可以将基准成绩分解为十个基于认知的能力，以评估每个能力对模型在给定基准上的成功贡献程度。
### Innovation
本文提出了一种名为基准剖析的诊断框架，该框架通过结合基于梯度的重要性评分和目标参数消融，计算能力影响评分（AIS），量化每个能力对模型在特定基准上的贡献。通过在三种指令调优模型上对十个常用基准进行剖析，发现：大多数基准依赖于多种能力，而非单一技能；具有相似标签的数据集依赖于不同的能力组合；代码生成基准要求广泛、多技能的提升，因此仅从狭窄的领域特定微调中获得微小收益；与任务无关的能力可能对表现产生负面影响。因此，这种方法解释了为什么性能提升并不总是转化为用户的感知能力和提供了一个透明的工具来审计基准并提高模型可解释性。
### Conclusion
基准剖析提供了一个理解大型语言模型在实际任务中表现的新视角，揭示了标准基准测试成绩与用户实际感知之间的差异，并提出了一种透明且可操作的方法来审计和解释基准。
## 361. `cs.CL` - 计算社会语言学在泰卢固文化保护中的应用：Chandassu诗体韵律模式识别的新算法 [PDF](https://arxiv.org/pdf/2510.01233), [HTML](https://arxiv.org/abs/2510.01233)
### Authors
Boddu Sri Pavan,Boddu Swathi Sree
### Background
泰卢固Chandassu作为一种承载着数世纪集体文化智慧的韵律诗传统，亟需得到保护。本文采用计算社会科学研究方法，建立第一个全面的数字化分析框架，将传统的社区知识与现代计算方法相结合，以数字化手段保护和传承泰卢固Chandassu这一传统文化遗产。
### Innovation
开发了首个全面的数字化分析框架，包括AksharamTokenizer（带韵律意识的分词器）、LaghuvuGuruvu Generator（轻重音分类器）和PadyaBhedam Checker（自动模式识别器）等工具。该算法在Chandassu评分上取得了91.73%的高准确率，评估指标反映了传统的文学标准。该工作展示了如何通过计算社会科学研究方法保护濒危的文化知识系统，同时促进对文学遗产的新型集体智慧，为以社区为中心的文化保护方法提供了借鉴。
### Conclusion
本文的研究方法为文化保护中的社区中心化提供了新的启示，支持了更广泛的人文数字和社交意识计算系统的发展。
## 362. `cs.CL` - CIFLEX: Contextual Instruction Flow for Sub-task Execution in Multi-Turn Interactions with a Single On-Device LLM [PDF](https://arxiv.org/pdf/2510.01239), [HTML](https://arxiv.org/abs/2510.01239)
### Authors
Juntae Lee,Jihwan Bang,Seunghan Yang,Simyung Chang
### Background
随着大型语言模型（LLM）的能力不断增强，期望一个单一的模型能够处理多样化的子任务，从而更全面地支持回答用户请求。现有方法在切换主要任务和子任务时需要重新处理整个对话上下文（如查询重写、总结等），这会导致显著的计算开销。
### Innovation
CIFLEX（Contextual Instruction Flow for Sub-task Execution）是一种新型执行系统，用于单一设备上多轮交互中高效处理子任务。CIFLEX通过重用主要任务的关键值缓存，并在隔离的侧路径中注入仅与特定任务相关的指令来减轻这种开销。实验表明，CIFLEX显著降低了计算成本，同时没有削弱任务性能，从而使得在设备上进行可扩展且高效的多任务对话成为可能。
### Conclusion
实验结果显示，CIFLEX在不牺牲任务性能的前提下大幅降低了计算成本，为设备上的多任务对话提供了可扩展且高效的解决方案。
## 363. `cs.CL` - SeMob：动态城市流动性预测的语义合成 [PDF](https://arxiv.org/pdf/2510.01245), [HTML](https://arxiv.org/abs/2510.01245)
### Authors
Runfei Chen,Shuyang Jiang,Wei Huang
### Background
人类的流动性预测对于城市服务至关重要，但通常未能考虑到外部事件所引起的突发变化。现有的时空模型难以利用详细描述这些事件的文本数据。
### Innovation
我们提出了SeMob，一种基于LLM的语义合成流水线，用于动态移动性预测。SeMob采用多智能体框架，其中基于LLM的智能体能够自动提取和推理时空相关的文本信息。通过我们提出的创新渐进融合架构，将细粒度的相关上下文与时空数据结合起来。丰富的预训练事件先验提供了关于事件驱动预测的丰富见解，从而导致了更加对齐的预测模型。
### Conclusion
在我们通过流水线构建的数据集上评估SeMob，与时空模型相比，SeMob实现了MAE降低13.92%，RMSE降低11.12%的最大减少。特别是，在事件发生地点和时间附近的时空区域中，该框架显示出突出的优越性。
## 364. `cs.CL` - 稀疏自编码器和激活差异在语言模型导向中的比较分析 [PDF](https://arxiv.org/pdf/2510.01246), [HTML](https://arxiv.org/abs/2510.01246)
### Authors
Jiaqing Xie
### Background
稀疏自编码器（SAEs）最近已成为语言模型控制的强大工具。先前的研究集中在选择前k个SAE潜在特征来进行控制，但观察到这些潜在特征中许多维度捕捉了诸如标点符号这样的非语义特征，而不是像指令这样的语义属性。此外，恒定的SAE控制常会产生退化的输出，如重复的单个单词。
### Innovation
本文提出专注于一个最相关的SAE潜在特征（前1个），减少冗余特征，并引入了一个按令牌递减的控制策略，以减轻恒定的SAE控制产生的退化的输出问题，使输出更加可信，与均值激活差异基准进行准确比较。
### Conclusion
实验结果表明，控制与推理相关的稀疏自编码器潜在特征可以可靠地引发逐步数学推理，增强推理质量，功能性地类似于附加引导令牌的效果。研究表明，SAE在数学推理基准上的表现优于均值激活差异方法，在IF-Eval上的表现与它们相当。
## 365. `cs.CL` - 沉默的标记，响亮的效果：语言大模型中的填充标记 [PDF](https://arxiv.org/pdf/2510.01238), [HTML](https://arxiv.org/abs/2510.01238)
### Authors
Rom Himelstein,Amit LeVi,Yonatan Belinkov,Avi Mendelson
### Background
在大型语言模型（LLMs）中，填充标记被广泛用于在批量推理期间使序列长度相等。虽然填充标记应该被完全掩蔽，但实现错误可能导致它们影响计算。然而，这种影响的范围并不为人所知。本文系统地研究了这种影响，分析了Llama、Gemma、Qwen三种开源模型家族在插入控制量填充标记后结果在激活、生成质量、偏差和安全性四个方面的影响。研究结果表明，即使是少量填充标记也会影响隐藏表示、降低较小模型的质量、改变偏差并削弱安全性限制。这表明填充标记并非无害的细节，而是一个在部署时需要仔细处理的稳健性风险。
### Innovation
本文通过系统地插入控制量的填充标记，并从激活、生成质量、偏差和安全性四个维度进行评估，研究了填充标记对大型语言模型的影响。研究发现即使是少量填充标记也会影响模型的性能，这揭示了填充标记对模型稳健性的影响，提供了一种新的视角来理解填充标记的影响机制。
### Conclusion
填充标记对大型语言模型的影响比预期的更为广泛和深远，即使是少量填充标记也会影响模型的隐藏表示、生成质量和安全性。因此，在部署过程中，需要特别注意和处理填充标记，以提高模型的稳健性和安全性。
## 366. `cs.CL` - 通过自回归奖励引导的表示编辑 detoxifying 大型语言模型 [PDF](https://arxiv.org/pdf/2510.01243), [HTML](https://arxiv.org/abs/2510.01243)
### Authors
Yisong Xiao,Aishan Liu,Siyuan Liang,Zonghao Ying,Xianglong Liu,Dacheng Tao
### Background
大型语言模型 (LLMs) 在多种任务中表现出色，但仍然可能生成有毒内容，这要求采取 detoxification 方法以确保部署的安全性和责任感。现有的测试时 detoxification 方法通常通过引入静态或动态干预措施来处理 LLM 表征，但由于其在有毒和非有毒输出之间过渡空间的探索不足，导致干预不够精确。
### Innovation
论文提出了一个名为 ARGRE (Autoregressive Reward Guided Representation Editing) 的新颖的测试时 detoxification 框架。ARGRE 明确建模了潜在表征空间中的毒性过渡，通过识别无毒语义方向并在有毒和无毒表示之间进行插值，揭示了细粒度的过渡轨迹。这些轨迹将稀疏的毒性注释转换为密集的训练信号，构建了一个自回归奖励模型，能够提供稳定和精确的编辑指导。在推理过程中，奖励模型引导一个适应性的两步编辑过程以获得无毒表征：首先，基于预期奖励差距进行定向引导，然后通过轻量级的梯度基础精修。
### Conclusion
大规模实验表明，ARGRE 在效果（毒性降低-62.21%）和效率（推理时间降低-47.58%）方面显著优于现有基准，同时最小化了原始模型的核心功能的退化。
## 367. `cs.CL` - 跨文化竞技：一种大规模多语言多文化基准，用于评估语言模型对体育的理解 [PDF](https://arxiv.org/pdf/2510.01247), [HTML](https://arxiv.org/abs/2510.01247)
### Authors
Punit Kumar Singh,Nishant Kumar,Akash Ghosh,Kunal Pasad,Khushi Soni,Manisha Jaishwal,Sriparna Saha,Syukron Abu Ishaq Alfarozi,Asres Temam Abagissa,Kitsuchart Pasupa,Haiqin Yang,Jose G Moreno
### Background
当前，语言模型（LMs）主要评估的体育项目以全球流行的运动为主，而忽视了许多地区的传统体育和本土体育文化。由于缺乏足够的评估工具，现有的研究往往未能充分考虑到这些文化和历史因素对语言模型理解传统体育的实际影响。
### Innovation
本文介绍了名为CultSportQA的新基准，旨在评估模型对传统体育的理解能力。该基准覆盖了来自60个国家和6个大陆的60种不同文化传统的体育比赛，设计上包括了按历史、规则和场景分类的33,000个选择题，并且支持对大型语言模型（LLMs）、小型语言模型（SLMs）和多模态大型语言模型（MLMs）采用零样本、少量样本和链式思考（CoT）的方式进行评估。CultSportQA填补了当前评估工具的空白，为评估AI理解传统体育的能力提供了新的标准。
### Conclusion
CultSportQA通过提供一个全面的多语言和多文化的体育基准，设定了评估AI理解及推理传统体育能力的新标准。
## 368. `cs.CL` - 冗余作为遮蔽：正式化人工年龄评分（AAS）以建模生成AI的记忆衰老 [PDF](https://arxiv.org/pdf/2510.01242), [HTML](https://arxiv.org/abs/2510.01242)
### Authors
Seyma Yaman Kayadibi
### Background
研究表明，人工智能（AI）并不会通过时间的流逝来老化，而是在记忆表现的结构不对称性中老化。大型语言模型中，诸如周几这样的语义线索往往在会话之间保持稳定，而诸如实验序号的事件细节则会在重置对话上下文时趋于瓦解。为了捕捉这一现象，论文引入了人工年龄评分（AAS），这是基于可观察的记忆召回行为，通过对熵进行处理得到的度量标准。研究表明，在重置会话时，AAS会急剧上升，这表明了结构记忆的老化。研究框架是在一项为期25天的双语研究中测试的，涉及到了ChatGPT-5，分为无状态和持续性交互两个阶段。
### Innovation
论文提出了一个称为人工年龄评分（AAS）的新颖度量标准，用于评估和建模生成型AI中记忆退化的情况。AAS是一种基于熵的信息度量，被证明在较弱的、模型无关的假设下是良好定义的、有界的和单调的，适用于多种任务和领域。此外，论文还介绍了AAS的一种新形式——冗余作为遮蔽（Redundancy-as-Masking）的形式，通过理解冗余作为一种减少惩罚质量的重叠信息来提出。
### Conclusion
AAS作为一种理论基础坚实、任务无关的诊断工具，能够评估人工系统中记忆衰退的实用性得到了支持。研究结果证明了AAS的有效性和适用性，为评价和监控生成型AI的记忆衰老提供了新的定量方法。这一方法是建立在冯·诺依曼的自机理论、香农的信息和冗余理论以及图灵的行为式智能理论基础之上的。
## 369. `cs.CL` - LOCA：科学语料库清洁中的逻辑链增强 [PDF](https://arxiv.org/pdf/2510.01249), [HTML](https://arxiv.org/abs/2510.01249)
### Authors
You-Le Fang,Dong-Shan Jian,Xiang Li,Ce Meng,Ling-Shi Meng,Chen-Xu Yan,Zhi-Zhang Bian,Yan-Qing Ma
### Background
大型语言模型（LLMs）在通用领域表现出色，但在科学问题解决方面往往不够可靠。推动科学AI的发展需要大量的高质量语料库。然而，现有的科学问答（QA）数据集存在高错误率的问题，通常是因为答案中存在逻辑跳跃和隐含推理。
### Innovation
本文介绍了一种新的清洁科学语料库的方法——LOCA（Logical Chain Augmentation），该方法通过一个增强和审查循环实现，能够自动补充缺失的逻辑步骤，并明确分离科学原理及其推导。通过将LOCA应用于具有挑战性的科学语料库，实验结果显示可以自动过滤噪声数据集，通常将错误率从高达20%降低到低于2%。LOCA提供了一种可扩展且有效的方法来创建高质量的科学语料库，为科学AI的可靠训练和评估铺平了道路。
### Conclusion
LOCA能够自动清理科学语料库，大幅降低错误率，提高数据质量，从而推动科学AI的发展。
## 370. `cs.CL` - SKYLENAGE 技术报告：用于多层次数学评估的数学推理和竞赛创新基准 [PDF](https://arxiv.org/pdf/2510.01241), [HTML](https://arxiv.org/abs/2510.01241)
### Authors
Hu Wei,Ze Xu,Boyu Yang,Linlin Miao,Weiqi Zhai,Yihan Li,Zixuan Li,Zhijun Wang,Boya Wang,Jianwei Yu,Jialing Yuan,Xiaoyue Zhang,Cheng He,Minglei Chen,Zifan Zhang,Qianhui Li,Wei Wang,Xiang Xu
### Background
大型语言模型（LLMs）在公共数学套件中的表现现已非常出色，但在数学领域内的前沿区分日益受到天花板效应的影响。为了克服这一挑战，作者提出了两个互补的基准测试：SKYLENAGE-ReasoningMATH，一个包含100项、注重结构的诊断集，每一项都有关于长度、数字密度和符号复杂性的元数据；以及SKYLENAGE-MATH，一个涵盖从初中到博士四个层次，跨度广泛的150项竞赛风格套件，源于一个七门科目的分类体系。作者旨在通过使用统一的设置评估十五种现代LLM变体，分析不同领域和不同年级的模型性能，以应对当前的天花板效应，并提供一个既具有挑战性又全面覆盖的数学推理基准，为未来数学推理评估提供参考基准
### Innovation
作者提出了两个新的基准测试：第一个是SKYLENAGE-ReasoningMATH，一个结构化诊断集，提供了详细的问题元数据；第二个是SKYLENAGE-MATH，一个广泛的竞赛风格套件，涵盖了不同层次的数学知识。通过这两个基准的评估和分析，研究发现当前最强的模型只能达到44%，显示出从高中到博士级别的准确性显著下降，而在更难的部分，领导者和中档模型之间存在明显的差异性。这些基准为数学推理领域提供了新的评测工具和数据参考
### Conclusion
作者发布了SKYLENAGE-ReasoningMATH，并报告了SKYLENAGE-MATH的综合结果。SKYLENAGE为数学推理提供了一个既具有挑战性又广泛覆盖的基准，具有经过校准的难度和丰富的元数据，可用于未来数学推理评估的参考基准
## 371. `cs.CL` - SSTAG：面向文本属性图的结构感知自监督学习方法 [PDF](https://arxiv.org/pdf/2510.01248), [HTML](https://arxiv.org/abs/2510.01248)
### Authors
Ruyue Liu,Rong Yin,Xiangzhen Bo,Xiaoshuai Hao,Yong Liu,Jinwen Zhong,Can Ma,Weiping Wang
### Background
大型预训练模型已经彻底改变了自然语言处理(NLP)和计算机视觉(CV)，展示了跨领域的出色泛化能力。然而，在图学习中，模型通常在独立的图数据集上进行训练，限制了其在不同图和任务间转移知识的能力。这种方法还严重依赖大量标注数据，在资源受限环境中带来了显著挑战。与NLP和CV不同，结构化图数据因其固有的异质性，包括领域特定特征空间以及在多种应用中的结构多样性，提出了独特的挑战。现有的图结构化数据训练方法无法有效解决这些挑战。
### Innovation
我们提出了一种新颖的面向文本属性图的结构感知自监督学习方法SSTAG，通过利用文本作为图学习的统一表示媒介，实现了大型语言模型（LLMs）的语义推理和图神经网络（GNNs）的结构建模能力的融合。SSTAG采用了一种双知识蒸馏框架，将LLMs和GNNs共同蒸馏到结构感知多层感知机（MLPs），提升了大规模TAG的可扩展性。此外，SSTAG还提出了一种内存中机制，通过将典型图表示与内存中的知识锚点对齐来整合不变知识，从而提高模型的泛化能力。实验表明，SSTAG在跨域迁移学习任务上优于现有最先进的模型，具有出色的可扩展性，同时在保持竞争力的同时降低了推理成本。
### Conclusion
SSTAG在文本属性图的结构感知自监督学习中引入了一种创新的方法，解决了传统图学习方法在资源受限环境和异构性挑战下的不足，通过构建结合LLMs和GNNs能力的结构感知MLPs，实现了跨图和任务的高效知识迁移。
## 372. `cs.CL` - 基于表格数据的LLM实体链接高效不确定性估计 [PDF](https://arxiv.org/pdf/2510.01251), [HTML](https://arxiv.org/abs/2510.01251)
### Authors
Carlo Bono,Federico Belotti,Matteo Palmonari
### Background
在数据集成和增强应用中，将文本数据中的值与其知识库中的对应实体链接是一项核心任务。尽管大型语言模型（LLMs）在实体链接（EL）任务中表现出色，但在实际应用中，它们需要准确预测和可靠的不确定性估计。这要求进行资源密集型的多轮推理，严重限制了其实用性。
### Innovation
本文提出了一种基于自我监督的方法，通过使用词级特征从单轮LLM输出中估计不确定性，从而减少多轮推理的需求。该方法在多个LLM上的表格数据实体链接任务上进行了评估，结果显示，生成的不确定性估计可以有效检测低准确性输出，而且计算成本较低，为基于LLM的实体链接工作流程中经济有效的不确定性措施集成提供了可行性。
### Conclusion
这种方法提供了一种在有限的计算开销下将不确定性估计集成到实体链接工作流程中的实用途径，有效降低了实体链接中的计算成本，支持在大规模应用中使用不确定性评估。
## 373. `cs.CL` - 大型语言模型可靠性增强的自信心向路由：一种多信号预生成幻觉缓解方法 [PDF](https://arxiv.org/pdf/2510.01237), [HTML](https://arxiv.org/abs/2510.01237)
### Authors
Nandakishor M
### Background
大型语言模型易产生幻觉，即生成看似合理但实际上不正确的内容。当前的缓解策略主要集中在生成后的修正，这种方法既耗时又不能有效防止不实内容的生成。
### Innovation
提出了一种自信心向路由系统，在生成前主动评估模型不确定性并根据估计的可靠性重新路由查询。该方法结合了三种互补信号：内部表示与参考嵌入的语义对齐、模型层间的内部收敛分析以及学习得到的置信度估计。统一的置信分数决定路由至四种途径：高置信度时进行局部生成、中置信度时进行检索增强生成、低置信度时使用更大模型、极低置信度时进行人工审核。评估结果显示，在知识密集型问答基准上，该方法显著提升了幻觉检测效果（0.74 vs. 0.42基线），同时将计算成本降低了40%。F1分数提高到0.82，且假阳性率较低（0.09）。这种从反应性修正转变为前瞻性评估的范式转变提供了一种计算效率更高的大型语言模型可靠性增强方法。
### Conclusion
这项研究提出了一个能提高大型语言模型可靠性的自信心向路由系统，通过主动评估和重新路由查询，结合多种信号提高了幻觉检测的准确性，并显著降低了计算成本。
## 374. `cs.CL` - 使用基于概念模型的大语言模型结构化记录压力的可能性 [PDF](https://arxiv.org/pdf/2510.01244), [HTML](https://arxiv.org/abs/2510.01244)
### Authors
Hyeoneui Kim,Jeongha Kim,Huijing Xu,Jinsun Jung,Sunghoon Kang,Sun Joo Jang
### Background
压力是由外部压力源、个体评估及生理或心理反应之间的动态相互作用所引起，对健康有显著影响，但往往被低估且记录不一致，通常作为未经结构化的自由文本出现在电子健康记录中。环境人工智能技术有望减轻记录负担，但由于生成的是未经结构化的叙述，限制了其临床应用价值。
### Innovation
本文开发了心理压力的本体论（MeSO），并评估了使用大语言模型（LLM）从叙述性文本中提取本体论指导下的压力相关信息的可行性。通过将理论模型与11种验证的压力评估工具的概念相结合，开发了MeSO，并利用Ontology Pitfall Scanner和专家验证进行了改进。结果表明，LLM可以从35个Reddit帖子中准确提取出172种（78.2%）压力相关信息，正确映射到MeSO的所有正确提取项，且展示出结构化提取压力相关信息的可行性。
### Conclusion
本研究表明，使用基于概念模型的大语言模型进行压力相关信息的结构化提取是可行的，这将有助于提高电子人工智能系统中压力记录的一致性和应用价值。未来的研究方向应包括临床上的对话数据，并通过不同大语言模型进行对比分析。
## 375. `cs.CL` - 语音评价中性别偏见基准任务是否泛化？来自SpeechLLMs性别偏见语音评估的证据 [PDF](https://arxiv.org/pdf/2510.01254), [HTML](https://arxiv.org/abs/2510.01254)
### Authors
Shree Harsha Bokkahalli Satish,Gustav Eje Henter,Éva Székely
### Background
近期有关语音大语言模型（SpeechLLMs）偏见和公平性的基准测试工作主要依赖于多种选择问题回答（MCQA）的形式。在这种形式中，模型需要根据语音提示和可选的文本提示，选择典型的、反典型的或中性/无关的答案。这类基准测试假设，模型在MCQA任务、声音和更现实、更长的评估形式中的表现是一致的。本研究质疑这一假设，通过利用LoRA适配器对三个SpeechLLMs进行微调，注入特定的MCQA行为：偏好典型的、反典型的或中性/不确定的答案，然后评估这些行为是否能在不同的MCQA基准测试甚至更长、更具创造性的生成任务中泛化。研究结果显示，MCQA偏见基准测试的表现并不能可靠地预测其他MCQA基准测试的表现，更不用说长形式任务中的表现了。
### Innovation
本研究表明，现有的MCQA偏见基准在语音领域中的跨任务泛化能力有限，并提出了一套用于评估未来模型和基准行为转移性的评测量表。
### Conclusion
当前MCQA偏见基准在语音领域的跨任务表现能力有限，提出了关于未来模型和基准行为转移性的评估套件建议。
## 376. `cs.CL` - 对社会议题的大语言模型内容审核进行纵向监控 [PDF](https://arxiv.org/pdf/2510.01255), [HTML](https://arxiv.org/abs/2510.01255)
### Authors
Yunlang Dai,Emma Lurie,Danaé Metaxa,Sorelle A. Friedler
### Background
大语言模型（LLMs）的输出受到不透明且频繁变化的公司内容审核政策和实践的影响。LLMs的内容审核通常表现为拒绝，反映公司政策并微妙地影响公共话语。目前公开措施有限，导致此方面仍然具有很高透明度问题。
### Innovation
作者介绍了AI Watchman，这是一种纵向审计系统，用于公开测量和跟踪LLMs的内容拒绝行为，提高LLMs这一重要且不透明领域的透明度。研究使用了超过400个社会议题的数据集，对Open AI的审核端点GPT-4.1、GPT-5以及DeepSeek（中英双语）进行了审计，发现AI Watchman能够检测到公司政策的变化，即使是未公开宣布的，并且揭示了不同公司和模型在内容审核上的差异性。
### Conclusion
研究结果贡献了纵贯审计LLMs的证据，并提出了AI Watchman作为一种执行此类审计的系统。这种纵向审计提供了一种深入研究大语言模型内容审核的重要动力。
## 377. `cs.CL` - GPT与偏见：理解大型语言模型中学习表示的一种稀疏方法 [PDF](https://arxiv.org/pdf/2510.01252), [HTML](https://arxiv.org/abs/2510.01252)
### Authors
Mariam Mahran,Katharina Simbeck
### Background
随着大型语言模型（LLMs）越来越多地在大量未经筛选的数据集上进行训练，理解和解释模型在数据中的内部化表示变得至关重要。本文研究了将LLMs与稀疏自编码器（SAEs）相结合的方法，以解析模型行为，揭示训练数据中的深层结构、主题和偏见。研究者通过使用GPT样式的变压器模型，独家训练简·奥斯汀的小说数据集，来探索这一方法的应用效果。
### Innovation
本文创新性地提出了一种结合GPT样式的变压器模型和稀疏自编码器的方法，用于解析大型语言模型中隐藏的深层结构和主题。通过在多个层次上应用SAEs，揭示出稀疏且可解释的特征，这些特征反映了简·奥斯汀小说中的关键叙事和概念，包括性别、社会阶层和社会责任等。这种方法为大规模数据集的探索、偏见发现和模型解释提供了新的途径。
### Conclusion
研究结果表明，结合LLMs和SAEs可以作为一种可扩展的探针，用于复杂数据集的解析，不仅能解释模型的行为，还能揭示训练数据中的深层次结构和隐含偏见。这种新的研究方法为大规模语言模型的各种应用提供了强大的工具。
## 378. `cs.CL` - AdaDetectGPT: 适应性检测大语言模型生成文本的统计保证 [PDF](https://arxiv.org/pdf/2510.01268), [HTML](https://arxiv.org/abs/2510.01268)
### Authors
Hongyi Zhou,Jin Zhu,Pingfan Su,Kai Ye,Ying Yang,Shakeel A O B Gavioli-Akilagun,Chengchun Shi
### Background
现有的基于logits的检测器使用从给定来源的大语言模型的概率分布函数中提取的统计信息来判断一段文本是由人撰写还是由大语言模型生成。然而，仅仅依赖于log概率可能是不够完善的。
### Innovation
本文提出了一种名为AdaDetectGPT的新颖分类器，它可以自适应地从训练数据中学习证人函数，以增强基于logits的检测器的性能。该方法提供了关于其真正率、假正率、真负率和假负率的统计保证。实证研究表明，在多种数据集和大语言模型组合中，AdadetectGPT几乎可以均匀地提高现有最优方法，改进幅度可达58%。
### Conclusion
我们的方法通过提供统计保证显著提高了大语言模型生成的文本检测的性能，具有广泛的适用性和优化效果。
## 379. `cs.CL` - GemDetox在2025 CLEF TextDetox挑战赛中的应用：为低资源语言提高大规模多语言文本净化模型 [PDF](https://arxiv.org/pdf/2510.01250), [HTML](https://arxiv.org/abs/2510.01250)
### Authors
Trung Duc Anh Dang,Ferdinando Pio D'Elia
### Background
随着社交媒体平台的出现和演变速度超过监管措施，自动净化可能作为一种及时的工具，帮助审核人员大规模维护安全的话语环境。该研究描述了作者在2025年PAN Text Detoxification Challenge中的提交，目标是将有毒的单句输入转化为15种类型学上不同的语言中的中性替换。
### Innovation
作者利用了一个具120亿参数的多语言变体Gemma-3和参数高效LoRA SFT微调技术以及提示技术，如少量提示和链式思考。训练语料包括3600个人写的平行对，21600个机器翻译的合成对以及通过Jaccard阈值过滤的模型生成的对。输入在推理时会与三个LaBSE检索到的邻居和显式的有毒跨度注释一起进行增强。
### Conclusion
该系统在高资源和低资源语言上均获得最高排名。消融实验显示少量提示和基本链式思考提示的联合得分分别提高了0.081和0.088。ANOVA分析表明语言资源状态是性能最强的预测因子(η² = 0.667, p < 0.01)。
## 380. `cs.CL` - 两次思考，一次生成：渐进式自我反思的防护机制 [PDF](https://arxiv.org/pdf/2510.01270), [HTML](https://arxiv.org/abs/2510.01270)
### Authors
Hoang Phan,Victor Li,Qi Lei
### Background
大型语言模型（LLMs）通过生成连贯且上下文相关的内容，已经彻底改变了自然语言处理领域。然而，它们的应用引发了人们对生成有害或不适当内容的潜在风险的担忧。
### Innovation
提出了一种新颖的推理时间技术——渐进式自我反思（PSR），该技术使LLMs能够动态地自我监控并校正其输出。此外，引入了一个轻量级自我反思预测器，可以根据输入的复杂性估计最佳反思轮数。
### Conclusion
研究表明，渐进式自我反思提供了一种可扩展的测试时间方法，通过根据输入的风险特性动态分配计算资源来增强LLM的安全性。
## 381. `cs.CL` - RJE：利用LLMs实现高效知识图谱问答的检索-评估-探索框架 [PDF](https://arxiv.org/pdf/2510.01257), [HTML](https://arxiv.org/abs/2510.01257)
### Authors
Can Lin,Zhengwang Jiang,Ling Zheng,Qi Zhao,Yuhang Zhang,Qi Song,Wangqiu Zhou
### Background
知识图谱问答（KGQA）旨在使用知识图谱回答自然语言问题。近期的研究利用大型语言模型（LLMs）增强了KGQA的推理能力，但存在限制：基于检索的方法受检索信息质量的约束，而基于代理的方法则高度依赖专有的LLMs。为了克服这些限制，我们提出了检索-评估-探索（RJE）框架。该框架检索精炼的推理路径，评估其是否足够，必要时进一步探索额外证据。此外，RJE引入了专业辅助模块，使小型LLMs能够有效工作：推理路径排名、问题分解和检索辅助探索。实验表明，使用专有LLMs（如GPT-4o-mini）的方法在性能上优于现有基线，同时让小型开源LLMs（如3B和8B参数）在未经调优的情况下也能获得竞争性结果。此外，RJE显著减少了LLM的调用次数和令牌使用量，相较于基于代理的方法，提供了显著的效率提升。
### Innovation
提出了检索-评估-探索（RJE）框架，以克服现有的基于检索和基于代理方法的限制。具体来说，RJE能够检索精炼的推理路径、评估推理的充分性，并在必要时探索额外证据。此外，RJE还引入了专门的辅助模块（如推理路径排名、问题分解和检索辅助探索），使小型LLMs能够有效工作。这使得使用较小规模的开源LLMs在无需调优的情况下也能获得良好的结果，并显著减少了对LLM的调用次数和令牌使用量，提高了效率。
### Conclusion
与现有基线方法相比，RJE方法在使用专有LLMs时表现出色，并使小型开源LLMs在无需调优的情况下也能够实现与更大规模模型相当的结果。此外，RJE显著减少了LLM的调用次数和令牌使用量，从而提高了效率。
## 382. `cs.CL` - 通过零样本分类衡量算法偏见及其对政治话语的影响 [PDF](https://arxiv.org/pdf/2510.01258), [HTML](https://arxiv.org/abs/2510.01258)
### Authors
Nathan Junzi Chen
### Background
在生成型人工智能（GAI）迅速正常化的过程中，智能系统已经成为信息媒介中政治话语的主导力量。然而，由于训练数据偏差、人类偏见和算法缺陷导致的内在政治偏见仍然困扰着这项新兴技术。为了评估算法政治偏见，本文采用零样本分类方法，结合意识形态一致、主题相关性、回应情感和客观性四个维度进行评估。研究对象包括六家主流大语言模型（LLMs），每个模型的1800条响应被送入四个不同的微调分类算法中，用于计算上述偏见评估指标。结果显示，在所有六家LLMs中都存在加强的自由主义-威权主义倾向性，出现了推理替代和固定拒绝的显著案例。这项研究还强调了人类-计算机交互中的心理影响及其如何使内在偏见渗透入公共话语，政治景观的扭曲可能会导致一致性或极化，这取决于地区既存的社政治结构。
### Innovation
本文采用零样本分类方法对算法政治偏见进行全面评估，结合意识形态一致、主题相关性、回应情感和客观性四个维度，这是对现有研究方法的一大创新。实验对象涵盖了六家主流大语言模型，并通过四个不同的微调分类算法进行评估，提高了研究结果的可信度和准确性。
### Conclusion
研究发现所有被评估的六家大语言模型都显示出自由主义-威权主义倾向性，一些模型还出现了推理替代和固定拒绝的情况。这表明算法发展中的内在偏见会影响公众话语，进而可能造成政治一致性或极化，这取决于地区原有的政治和社会结构。研究凸显了在使用AI技术时需要高度关注和管理其潜在的政治偏见，以避免对社会产生负面影响。
## 383. `cs.CL` - 基于LLM的孟加拉国电子商务评论情感分类 [PDF](https://arxiv.org/pdf/2510.01276), [HTML](https://arxiv.org/abs/2510.01276)
### Authors
Sumaiya Tabassum
### Background
情感分析是文本分析的一个重要组成部分，主要确定和评估作者的情感状态。情感分析的准确性受语言复杂性和多样性的影响。本文利用孟加拉语和英语电子商务评论数据集，研究了基于大型语言模型（如Llama）的情感分类能力，特别是使用参数高效微调方法（LoRA和PEFT）降低计算开销，适合资源受限环境下的应用潜力。
### Innovation
研究采用参数高效微调方法（LoRA和PEFT）针对孟加拉国电子商务评论进行微调大型语言模型Llama-3.1-8B，取得了较高的准确率、精确率、召回率和F1分数，证明了在资源有限的环境中使用大型语言模型进行情感分析的可行性。
### Conclusion
研究表明，Llama-3.1-8B模型在微调后表现出色，其综合准确率高达95.5%，精确率93%，召回率88%，F1分数90%，表明了参数高效微调方法在降低计算成本的同时，可以提高情感分析模型在特定领域中的性能。
## 384. `cs.CL` - Deep研究评价表：以学术文献综述为例 [PDF](https://arxiv.org/pdf/2510.01283), [HTML](https://arxiv.org/abs/2510.01283)
### Authors
Israel Abebe Azime,Tadesse Destaw Belay,Atnafu Lambebo Tonja
### Background
大型语言模型（LLMs）通过赋予检索能力，能够进行知识密集型任务而无需人类参与。Deep Research 是这一工具的典型案例，能够浏览网络、提取信息并生成多页报告。为了评估 Deep Research 工具的能力，作者引入了一种评价表，并选择了学术文献综述作为应用场景。研究发现，在评估 OpenAI 的 Deep Search 和 Google 的 Deep Search 自动生成的学术文献综述时，显示出搜索引擎和独立的 Deep Research 工具之间的巨大差距，以及在代表特定领域方面的局限性。
### Innovation
作者提出了一个用于评估 Deep Research 工具能力的评价表，并使用学术文献综述作为实际应用场景，客观地评估了这些工具生成的报告。这种评价方法展示了搜索引擎和独立的 Deep Research 工具之间的显著差异，强调了对精心设计的评价标准的需求。
### Conclusion
研究结果显示，对于 Deep Research 工具生成的报告，需要有详细的评价标准。对于 OpenAI 和 Google 的 Deep Search 工具来说，在生成学术文献综述方面，与搜索引擎相比存在显著的不足和局限性。
## 385. `cs.CL` - TraceDet：来自扩散大语言模型解码迹的幻觉检测 [PDF](https://arxiv.org/pdf/2510.01274), [HTML](https://arxiv.org/abs/2510.01274)
### Authors
Shenxu Chang,Junchi Yu,Weixing Wang,Yongqiang Chen,Jialin Yu,Philip Torr,Jindong Gu
### Background
扩散大语言模型（D-LLMs）作为一种新兴的替代自回归大语言模型（AR-LLMs）的方案，虽然具有潜力，但其幻觉问题尚未得到充分研究，限制了其在现实应用中的可靠性。现有的幻觉检测方法主要针对AR-LLMs设计，依赖单一生成步骤的信息，不适合D-LLMs，因为幻觉信号往往在多步去噪过程中出现。
### Innovation
本文提出了一种名为TraceDet的新颖框架，该框架针对D-LLMs的特点，利用解码过程中的中间去噪步骤进行幻觉检测。TraceDet将去噪过程建模为动作轨迹，通过识别最能提供幻觉响应信息的子轨迹，综合利用多步去噪过程中的关键幻觉信号进行检测。
### Conclusion
在多种开源D-LLMs上的实验表明，TraceDet在幻觉检测方面取得了显著改进，相较于基线方法，平均AUROC提高了15.2%。
## 386. `cs.CL` - OpenAI的GPT-OSS-20B模型及其在低资源语言环境下的安全对齐问题 [PDF](https://arxiv.org/pdf/2510.01266), [HTML](https://arxiv.org/abs/2510.01266)
### Authors
Isa Inuwa-Dutse
### Background
论文针对OpenAI的GPT-OSS-20b模型的安全性问题进行了深入调查，重点关注该模型在资源有限的语言环境中，尤其是在非洲主要语言豪萨语中的表现和安全对齐程度。研究人员发现该模型在生成内容时存在偏见、不准确和文化敏感度问题。当使用礼貌或感激的语言进行提示时，该模型的回应中还出现了一些奖励行为操纵的现象，导致生成的内容可能加剧信息误导和仇恨言论。
### Innovation
该研究创新性地使用豪萨语作为低资源语言来检验模型，发现了模型在某些方面的严重缺陷。研究进一步揭示，这些缺陷可能源于低资源语言环境下的安全调优不足，并提出了一种新的奖励操纵形式，即模型偏向生成在目标语言中听起来流利且可信的内容，而忽视了安全和真实性，特别指出当前的红队测试存在显著空白，提出了若干改进建议。
### Conclusion
该研究强调了在低资源语言环境中，对大型语言模型进行安全对齐的必要性，并提出采用代理语言进行测试可以更有效地发现模型中的潜在问题。此外，研究还建议在更广泛的低资源语言环境中进行更多的测试和改进，以增强这些模型在实际使用中的安全性和可靠性。
## 387. `cs.CL` - 在AI和谐之中：OpenAI gpt-oss-20b中的社会语用护栏规避与评估意识 [PDF](https://arxiv.org/pdf/2510.01259), [HTML](https://arxiv.org/abs/2510.01259)
### Authors
Nils Durner
### Background
该研究旨在探究社会语用框架、语言选择和指令层次结构如何影响拒绝行为。研究使用了OpenAI的200亿参数的gpt-oss-20b模型，并通过多个场景对模型进行了测试。研究结果表明，在某些场景下，采用特定框架和指令可以显著提高模型拒绝有害行为的比例。此外，还发现不同语言的注册形式对模型的行为造成了影响，并且有些角色扮演方式能够有效提高模型的安全性。
### Innovation
研究使用了80次迭代的实验设计，涵盖了多个危害领域，例如：ZIP炸弹构造（网络威胁）、合成信用卡号生成、轻微不安全驾驶建议、药物前体指示和RAG上下文窃取。研究发现，结合教育者角色、安全前提和步骤提示的复合指令能够使模型在防范ZIP炸弹任务中的协助率从0%提高到97.5%。此外，研究还提出了一种基于AI的加固方法，该方法在某些用户指令变体中能够将泄漏率降低到0%。最后，研究测试了评估意识，并观察到不一致的协助比例。
### Conclusion
研究表明，模型在拒绝有害行为方面表现出了较大的敏感性。某些指令和框架能够有效提升模型的安全性。然而，不同语言版本的注册形式对于模型的行为影响显著，且评估方法的标准不一可能导致结果重现性问题。未来的研究需要进一步验证这些发现，并探索更加有效的评估方法。
## 388. `cs.CL` - 独立和联合微调策略在检索增强生成中的比较 [PDF](https://arxiv.org/pdf/2510.01600), [HTML](https://arxiv.org/abs/2510.01600)
### Authors
Neal Gregory Lawton,Alfy Samuel,Anoop Kumar,Daben Liu
### Background
检索增强生成（RAG）是一种基于两个大型语言模型（LLMs）的问答框架：嵌入模型从数据库中检索与问题相关的上下文文档，生成模型使用这些检索到的上下文生成问题的答案。两者均可通过微调提高RAG管道在新任务上的性能，但存在多种微调策略，具有不同的成本和收益。
### Innovation
该研究评估并比较了多种RAG微调策略，包括独立、联合和两阶段微调。研究发现，这些策略在EM和F1生成质量指标上的改进大致相同，但计算成本差异显著。
### Conclusion
最优的微调策略取决于训练数据集是否包含上下文标签以及是否需要对嵌入模型和生成模型的学习率进行网格搜索。
## 389. `cs.CL` - TUMIX：基于工具混合的多代理测试时缩放方法 [PDF](https://arxiv.org/pdf/2510.01279), [HTML](https://arxiv.org/abs/2510.01279)
### Authors
Yongchao Chen,Jiefeng Chen,Rui Meng,Ji Yin,Na Li,Chuchu Fan,Chi Wang,Tomas Pfister,Jinsung Yoon
### Background
尽管像Code Interpreter和Search这样的工具大幅提升了如ChatGPT Agent和Gemini-Pro等大型语言模型（LLM）的推理能力，但在如何最有效使用这些工具方面的实用指导却相对缺乏。现有的挑战在于如何有效地结合文本推理、编程和搜索，以应对各种问题。这一背景下，本文提出了Tool-Use Mixture（TUMIX），这是一个采用并行运行多个代理的方法，每个代理都采用了不同的工具使用策略和解答路径。这些代理能够根据问题和之前的回答，迭代地共享和优化答案。实验结果显示，TUMIX在关键推理基准测试上，相较于最先进的工具增强和测试时缩放方法，具有显著优势，特别是在Gemini-2.5-Pro和Gemini-2.5-Flash上实现了高达3.55%的平均准确率提升，且推理成本接近相等。研究发现在代理多样性与质量方面，可以使用LLM自动生成代理设计以优化性能。此外，TUMIX可以在达到足够自信时停止重新优化，从而在仅使用49%的推理成本下保持性能。进一步扩展可以带来更高的性能，但代价会相应增加。
### Innovation
本文提出了一种名为Tool-Use Mixture（TUMIX）的多代理混合工具使用框架，该框架使不同策略的代理能够在并行运行中共享和优化答案，提升了大型语言模型的推理能力。特别地，TUMIX在处理大量问题时能够根据实际情况自动调整代理的设计，提升整体性能，并且在确保高性能的同时显著降低了推理成本。
### Conclusion
TUMIX多代理混合工具使用框架在关键推理基准测试中取得了显著成果，实现了比最先进的方法更高的准确率，并且通过自动优化代理设计进一步提升了性能。此外，TUMIX具有节约推理成本的优势，可以在达到足够信心后停止优化，从而更加高效地运行。进一步的扩展虽然成本增加，但可以进一步提升性能。
## 390. `cs.CL` - A-VERT: 无关验证与嵌入排名目标 [PDF](https://arxiv.org/pdf/2510.01469), [HTML](https://arxiv.org/abs/2510.01469)
### Authors
Nicolás Aguirre,Ramiro Caso,Ramiro Rodríguez Colmeiro,Mauro Santelli,Joaquín Toranzo Calderón
### Background
自动评估语言模型（LM）响应是发展基准和度量的关键部分，对于模型训练和生产模型端点的质量评估至关重要。当前的响应分类方法要么成本过高（例如，LLM作为裁判），要么远离现实环境（如字符串匹配、对数概率）。
### Innovation
提出了一种结构无关的评估方法。该方法使用语义嵌入距离将目标候选匹配到任意生成的文本，从而以相对较低的计算成本（小于10B参数的嵌入模型）实现响应的稳固分类。结果显示出与人类标注者相比约97%的回归得分和96%的准确率，并且在3个数据集和不同的3种LM架构中进行了测试。
### Conclusion
该研究通过使用语义嵌入距离实现了一种结构无关的评估方法，有效地降低了计算成本，同时保持了高准确性和对真实环境的适用性，并通过实验数据验证了其效果。
## 391. `cs.CL` - HiSpec：大模型中的分层推测解码 [PDF](https://arxiv.org/pdf/2510.01336), [HTML](https://arxiv.org/abs/2510.01336)
### Authors
Avinash Kumar,Sujay Sanghavi,Poulami Das
### Background
传统的语言模型（LLM）推理过程中，推测（draft）阶段会被一个较小的模型进行预测，而验证（verification）阶段则由一个较大的目标模型完成。验证往往是这一过程中的瓶颈，比如验证过程可能是生成一个单词的四倍慢。大部分现有研究都集中在如何加速推测过程，而不是验证过程。现有的一些推测验证方法虽然可以减少验证时间，但由于需要引入额外的验证器、增加内存使用、并且依赖近似启发式策略，导致准确性有所下降。
### Innovation
本文提出了一种分层推测解码（HiSpec），利用早期退出（EE模型）进行低开销的中间验证。这些模型通过仅跳过层遍历和显式训练以解释选定层的隐藏状态，使其适合进行中间验证而不会大幅增加计算和内存成本。为了进一步提高资源效率，HiSpec设计了一种方法，使得不同模型（推测、中间验证和目标模型）能够共享关键值缓存和隐藏状态。为了保证准确性，HiSpec会定期将用中间验证接受的推测结果与目标模型进行比对。实验结果表明HiSpec能将吞吐量提升1.28到2.01倍，而不会影响准确性。
### Conclusion
通过引入早退出模型和优化资源利用，HiSpec框架有效提升了解码推理的吞吐量，同时保持了与现有方法相同甚至更高的准确性。这项研究对于提高大模型推理的效率具有重要意义。
## 392. `cs.CL` - One More Question is Enough, Expert Question Decomposition (EQD) Model for Domain Quantitative Reasoning [PDF](https://arxiv.org/pdf/2510.01526), [HTML](https://arxiv.org/abs/2510.01526)
### Authors
Mengyu Wang,Sotirios Sabanis,Miguel de Carvalho,Shay B. Cohen,Tiejun Ma
### Background
大型语言模型（LLMs）在特定领域中的定量推理仍然是一项重大挑战，尤其是在需要专家知识和复杂问题回答的领域。现有方法通常无法有效结合领域知识和计算效率。本文在金融领域（一个具备专业知识和复杂定量推理的特定领域）的背景下，探讨了提升LLMs在特定领域问题回答性能的方法。
### Innovation
本文提出了一种名为Expert Question Decomposition（EQD）的方法，这是一种平衡使用领域知识和计算效率的框架。EQD通过两步微调和由奖励函数指导的过程，提高了生成子问题以优化问题回答效果的能力。研究结果表明，EQD在训练样本量少（仅数千个）且使用单个A100 GPU进行微调的情况下，能够显著优于现有的领域调和先进提示策略，并且推理时间与零射手动提示相当。
### Conclusion
研究在金融领域的四个基准数据集上评估了EQD模型，发现该方法在不同的LLMs中一致地提高了问题回答性能，改善幅度在0.6%到10.5%之间。此外，分析揭示了一个重要洞察：在特定领域的定量推理中，一个辅助问题往往比详细的指导步骤更有益。
## 393. `cs.CL` - TAG-EQA：通过结构化提示策略实现事件问题回答的方法 [PDF](https://arxiv.org/pdf/2510.01391), [HTML](https://arxiv.org/abs/2510.01391)
### Authors
Maithili Kadam,Francis Ferraro
### Background
大型语言模型（LLMs）在通用语言任务上表现出色，但在处理基于事件的问题时常常力不从心，尤其是需要因果或时间推理的问题。本文介绍了一种名为TAG-EQA（Text-And-Graph for Event Question Answering）的提示框架，该框架通过将结构化关系转换为自然语言陈述，将因果事件图注入到LLM的输入中。
### Innovation
该工作提出了一个名为TAG-EQA的提示框架，该框架通过将因果事件图注入到LLM的输入中，增强了LLMs在事件推理上的表现。具体创新体现在：1）设计了包含九种提示配置的框架；2）将三种策略（零样本、少量样本、思维链推理）与三种输入模式（文本-only、图形-only、文本+图形）结合，提供了系统的方法分析结构化知识对推论的影响；3）在TORQUESTRA基准测试中，与仅基于文本的方法相比，该模型平均提高了5%的准确率，最高至零样本设置中的12%和图形增强思维链推理设置中的18%。
### Conclusion
研究结果表明，因果图可以在不进行微调的情况下增强LLMs中的事件推理，提供了一种灵活的结构化知识编码方法，用以支持基于提示的问答。
## 394. `cs.CL` - RAG-BioQA：检索增强生成在长形式生物医学问答中的应用 [PDF](https://arxiv.org/pdf/2510.01612), [HTML](https://arxiv.org/abs/2510.01612)
### Authors
Lovely Yeswanth Panchumarthi,Sai Prasad Gudari,Atharva Negi,Praveen Raj Budime,Harsit Upadhya
### Background
生物医学文献的指数增长给访问精确医学信息带来了巨大挑战。当前的生物医学问答系统主要关注简短的答案，无法提供临床决策所需的整体解释。
### Innovation
我们提出了RAG-BioQA，一种结合检索增强生成与领域特定微调的新型框架，以生成基于证据的长形式生物医学答案。该方法将BioBERT嵌入与FAISS索引结合，并比较各种再排序策略（BM25、ColBERT、MonoT5）以优化上下文选择，在此之前通过微调的T5模型综合证据。实验结果表明，我们的模型在PubMedQA数据集上显著优于基线，在BLEU、ROUGE和METEOR指标上取得了大幅提高，推动了可获取、基于证据的生物医学知识检索的发展。
### Conclusion
我们的研究表明，RAG-BioQA在长形式生物医学问答方面取得了显著进步，特别是在评估和检索准确信息方面，超过了现有的基准模型，推进了生物医学知识的检索技术。
## 395. `cs.CL` - ReSSFormer：一种用于可扩展性和长上下文推理的递归稀疏结构变压器 [PDF](https://arxiv.org/pdf/2510.01585), [HTML](https://arxiv.org/abs/2510.01585)
### Authors
Haochen You,Baojing Liu
### Background
尽管Transformer架构在各个领域展示了出色的可扩展性，但在长上下文推理、计算效率和结构泛化等方面仍然面临挑战。这些挑战主要源于固定的层堆叠、密集的注意力机制以及对位置编码的依赖。
### Innovation
ReSSFormer引入了三种互补创新：递归推理与记忆单元（R2MU），以实现带有限深度的迭代推理；自适应稀疏注意力模块（ASAM），以实现高效且集中的上下文选择；以及自组织编码结构（SOES），以直接从内容中建模潜在的令牌拓扑。
### Conclusion
在语言建模、多跳问答和结构敏感任务中，ReSSFormer在与基线相当的FLOPs和参数预算下，一致地优于强劲的基线，强调了其可扩展性、效率和结构灵活性。
## 396. `cs.CL` - AMAS: 动态确定基于大语言模型的多代理系统通信拓扑 [PDF](https://arxiv.org/pdf/2510.01617), [HTML](https://arxiv.org/abs/2510.01617)
### Authors
Hui Yi Leong,Yuheng Li,Yuqing Wu,Wenwen Ouyang,Wei Zhu,Jiechao Gao
### Background
虽然大型语言模型（LLMs）已经革命性地提升自然语言处理能力，但它们作为独立的多代理系统（MAS）用于工业问题解决时仍遇到实际障碍。传统的MAS架构受制于固定的手动构建图拓扑，缺乏上下文响应性，导致在各种学术和商业工作负载中效率低下。
### Innovation
我们引入了AMAS，这是一种颠覆性的框架，通过一种新型的动态图设计师重构基于LLM的MAS。AMAS能够自主地识别任务特定的最佳图配置，通过轻量级LLM的适应性，消除依赖单一的结构模板。相反，AMAS利用个体输入的内在属性，智能地引导查询路径通过任务优化的代理路径。
### Conclusion
在多个基准测试中的严格验证显示，AMAS在不同的LLM架构上系统性地超越了最先进的单代理和多代理方法。研究结果表明，上下文敏感的结构适应性是高性能LLM MAS部署的基础需求。
## 397. `cs.CL` - 在单个消费级GPU上稳健地训练中小型传统中文LLaMA-1B：逐步预训练、SFT和DPO [PDF](https://arxiv.org/pdf/2510.01616), [HTML](https://arxiv.org/abs/2510.01616)
### Authors
Yu-Cheng Chih,Ming-Tao Duan,Yong-Hao Hou
### Background
小型语言模型（SLMs）因其成本效益和低延迟，非常适合设备端的AI应用，但它们在传统中文（TC）中的应用仍然受限，因为模型可能会在词元级别上不稳定，导致非TC字符的输出或语言转换。
### Innovation
本文提出了一种用于Llama-3.2-1B-Instruct（Meta发布的开源、指令调优模型）的三阶段稳定化管道PureTC-1B，通过参数高效的LoRA适配器实现了性能提升。该方法结合了针对TC中心语料库的持续预训练（CPT）、带有指令数据的监督微调（SFT）和使用TC一致性偏好的直接偏好优化（DPO），从而提高了单语鲁棒性，而无需进行整体重新训练。这一方法在实际使用场景模拟的基准测试中实现了51.3%的非TC输出词元相对减少，表明1B规模的模型也能够保持严格的TC一致性。此外，在命名实体翻译任务中，PureTC-1B相比Llama-3B和Qwen-1.5B分别减少了77.2%和57.2%的错误语言词元。
### Conclusion
该管道是可重现的、适配器仅需的，且对硬件友好，为从业人员提供了一种实用的方法来增强TC和其他非英语语言的稳定性。
## 398. `cs.CL` - 学习成为另一个方向的观察者：启用双向注意力的大型语言模型中的词嵌入语义探针研究 [PDF](https://arxiv.org/pdf/2510.01652), [HTML](https://arxiv.org/abs/2510.01652)
### Authors
Zhaoxin Feng,Jianfei Ma,Emmanuele Chersoni,Xiaojing Zhao,Xiaoyi Bao
### Background
自回归大型语言模型（LLMs）在语言理解和生成任务中表现出色，但在文本嵌入任务中的应用相对缓慢，并且在探针任务中对其语义表示的分析也受到了单向注意机制限制的影响。本文旨在探讨通过启用LLMs的双向注意机制是否能够克服这种限制，以及通过插入额外的训练步骤测试Llama架构的不同变体，逐步启用双向注意和监督/非监督对比学习的效果。
### Innovation
本文通过引入双向注意机制，探索克服LLMs单向注意机制限制的方法。通过逐步启用双向注意和对比学习，利用Llama架构的不同变体进行测试，旨在提高其在文本嵌入任务中的应用效果和在探针任务中的语义表现。
### Conclusion
论文通过启用双向注意机制的Llama架构，提升了LLMs在语义探针任务中的表现，并探索了其对文本嵌入能力的改进。
## 399. `cs.CL` - SoK: 评估闭环安全代理的关键指标 [PDF](https://arxiv.org/pdf/2510.01654), [HTML](https://arxiv.org/abs/2510.01654)
### Authors
Mudita Khurana,Raunak Jain
### Background
网络安全是一场永无止境的军备竞赛，AI驱动的攻击系统进化速度远超传统防御系统的适应速度。防御措施和工具分散在孤立的防御功能中，形成了对手可以利用的盲点。自主代理将检测、确认、修复和验证整合到一个闭环中，显示出潜力，但该领域缺乏定义安全系统在安全生命周期中能力的框架、评估闭环代理的原理方法，以及实际测量性能的基准。本文介绍了CLASP：闭环自主安全性能框架，将安全生命周期（侦察、利用、根本原因分析、补丁合成、验证）与核心代理能力（计划、工具使用、记忆、推理、反思和感知）对齐，提供了一个评估安全任务中代理能力的共同词汇和评判标准。通过对21个代表性工作的应用，CLASP揭示了系统的强项和能力缺口。随后，定义了闭环能力（CLC）分数，一个综合度量，量化闭环程度和操作有效性，并概述了闭环基准的要求。CLASP和CLC分数共同提供了进展评估功能性能和衡量闭环安全代理所需的词汇、诊断和测量。
### Innovation
CLASP框架定义了安全系统在安全生命周期中的代理能力，并提供了一个评估代理能力的共同词汇和评判标准。CLC分数则是一个综合度量，量化了闭环程度和操作有效性，为评估闭环安全代理提供了新的方法。
### Conclusion
CLASP和CLC分数共同提供了评估安全生命周期中代理能力的框架和标准，并强调了闭环基准的要求，为推进功能性能和衡量闭环安全代理提供了必要的诊断和测量工具。
## 400. `cs.CL` - CLUE: 非参数经验隐状态聚类验证 [PDF](https://arxiv.org/pdf/2510.01591), [HTML](https://arxiv.org/abs/2510.01591)
### Authors
Zhenwen Liang,Ruosen Li,Yujun Zhou,Linfeng Song,Dian Yu,Xinya Du,Haitao Mi,Dong Yu
### Background
评估大型语言模型（LLM）输出的质量是一个关键挑战。先前的方法或依赖于文本级别的信息（例如奖励模型、多数投票），这可能会过度拟合到表面线索，或依赖于标记化概率的校准信心，这在未校准模型上可能会失效。然而，这两种信号实际上都是来自更丰富信息源的部分投影：模型的内部隐藏状态。早期的隐藏层保留了支撑文本判断的语义和词汇特征，而后期的隐藏层则越来越与输出对数 logits 对齐，嵌入了信心相关的信息。
### Innovation
本文探讨了直接使用隐藏状态作为统一的验证基础。文章指出，解决方案的正确性以几何分离的签名形式编码在隐藏激活的轨迹中。为了验证这一理论，该研究提出了 Clue（基于经验的聚类和经验验证），这是一种刻意简约的、非参数的验证器。CLUE 通过使用隐状态变化和过去经验形成的成功和失败簇之间的最近中心距来进行推理轨迹的总结和正确性分类，方法极其简单。这种简单性突显了底层信号的强大力量。
### Conclusion
在实验中，CLUE 一致地超过了 LLM 作为裁判的基线，并在重排序候选者方面达到或超过了现代基于自信的方法。在 AIME 24 和 GPQA 中，CLUE 在 top-1 和多数投票准确性上都取得了改进。以 AIME 24 为例，当使用一个 1.5B 模型时，CLUE 将准确性从 56.7%（多数@64）提升到了 70.0%（top-maj@16）。
## 401. `cs.CL` - MDSEval：多模态对话总结元评估基准 [PDF](https://arxiv.org/pdf/2510.01659), [HTML](https://arxiv.org/abs/2510.01659)
### Authors
Yinhong Liu,Jianfeng He,Hang Su,Ruixue Lian,Yi Nian,Jake Vincent,Srikanth Vishnubhotla,Robinson Piramuthu,Saab Mansour
### Background
多模态对话总结（MDS）是一个具有广泛应用场景的关键任务。为了支持有效MDS模型的开发，建立强大的自动评估方法对于减少成本和人力投入至关重要。然而，这些方法需要依靠坚实的元评估基准，该基准是基于人类标注而成。当前缺乏这样的基准来系统地评估MDS模型的表现。因此，迫切需要建立一个新的基准来解决这些问题。
### Innovation
本文提出MDSEval，这是第一个多模态对话总结的元评估基准，包括了图像共享对话、对应摘要和八个明确质量方面的手工标注数据。此外，还提出了一种新的过滤框架，利用了各模态之间的互斥关键信息。这项工作首次确定和形式化了与MDS特定的关键评估维度。同时，本研究还基准测试了最新的模态评估方法，揭示了它们在区分摘要与先进MLLM以及在处理各种偏差方面的局限性。
### Conclusion
本研究通过MDSEval提供了一个新的基准来评估MDS模型，系统地揭示了现有评估方法的局限性，并确定了评估MDS的关键维度。这将有助于推动该领域的发展，促进更高质量的MDS模型的研究和应用。
## 402. `cs.CL` - What MLLMs Learn about When they Learn about Multimodal Reasoning: Perception, Reasoning, or their Integration？ [PDF](https://arxiv.org/pdf/2510.01719), [HTML](https://arxiv.org/abs/2510.01719)
### Authors
Jiwan Chung,Neel Joshi,Pratyusha Sharma,Youngjae Yu,Vibhav Vineet
### Background
近年来，多模态推理模型在诸如奥林匹克几何学等具有挑战性的领域中展现出前景，但在评估这些模型时，主要依赖于聚合准确率这一单一指标，未能揭示模型在哪些方面有所提高以及具体为何有所提高。因此，需要一个基准来区分多模态推理中的子技能，同时保持教科书风格几何问题的复杂性。
### Innovation
本文提出了MathLens，一个基准测试，旨在分离多模态推理中的子技能，同时保持教科书风格几何问题的复杂性。它将表现分为三个部分：感知（从原始输入中提取信息）、推理（操作可用的信息）和集成（选择相关感知证据并将其应用于推理）。该基准测试提供了一系列注释，包括视觉图示、文本描述、控制性问题和细粒度感知技能的探测，以确保一致性与稳健性。研究表明，不同的训练方法对性能的不同部分产生了非均匀的影响：强化学习主要增强了感知，特别是在有文本监督的情况下；文本导向的某种形式的强化学习通过反思推理间接提升了感知；推理能力只能在与感知能力同步提升的情况下改进；而集成能力是最弱的，一旦其他技能提升，错误仍然集中在这一部分；最后，鲁棒性也有所不同：强化学习提高了图表变化时的一致性，而多模态SFT则通过过度拟合减轻了这一特性。
### Conclusion
研究结果强调了在多模态推理中感知、推理和集成能力的不同挑战，以及它们的改进如何相互依赖和交织。未来工作将公布所有数据和实验日志，以进一步验证和探索这些结论。
## 403. `cs.CL` - 使用BERT进行新型LLM越狱检测和关键词分析 [PDF](https://arxiv.org/pdf/2510.01644), [HTML](https://arxiv.org/abs/2510.01644)
### Authors
John Hawkins,Aditya Pramar,Rodney Beard,Rohitash Chandra
### Background
大型语言模型（LLMs）存在多种漏洞，恶意用户可以通过操纵输入文本来获取不当响应。这些所谓的监狱逃脱提示旨在欺骗LLM绕过安全机制，以符合开发者的政策。本研究分析了不同机器学习模型区分监狱逃脱提示和真应用的能力，包括识别使用之前未见策略的监狱逃脱提示。
### Innovation
本研究发现，通过端到端微调双向编码器表示从变压器（BERT）模型来识别监狱逃脱提示具有最佳性能。研究成果通过可视化关键字区分监狱逃脱提示和真应用，揭示了提示结构中的显性反思可能是监狱逃脱意图的信号。
### Conclusion
使用当前数据集，最佳性能由完全微调的BERT模型获得。我们的研究结果显示，显性反思性在提示结构中可能是监狱逃脱意图的信号。
## 404. `cs.CL` - LLMs是否可以拒绝无法回答的问题？在事实任务中测量知识驱动的拒绝能力 [PDF](https://arxiv.org/pdf/2510.01782), [HTML](https://arxiv.org/abs/2510.01782)
### Authors
Wenbo Pan,Jie Xu,Qiguang Chen,Junhao Dong,Libo Qin,Xinfeng Li,Haining Yu,Xiaohua Jia
### Background
现有度量标准无法忠实测量大型语言模型（LLMs）在回答超出其知识范围的问题时选择拒绝的能力。简单拒绝基度量标准因拒绝率的偏差而产生不一致的评分，而现有校准度量标准是代理度量，未能准确捕获模型的实际拒绝行为。本文旨在解决这些问题。
### Innovation
提出了Refusal Index（RI），这是一种从理论层面测量LLMs准确拒绝其不知晓问题的能力的方法。RI定义为拒绝概率与错误概率之间的Spearman秩相关性。设计了一种轻量级的两阶段评估方法，该方法可以有效地估计RI，从而得到拒绝概率。通过广泛的实验验证了RI的有效性，即其准确地量化了模型在事实任务中的固有知识驱动的拒绝能力。RI方法的评估结果稳定，不受不同拒绝率的影响，并且能够独立于模型的整体准确性和拒绝率提供一致的模型排名。
### Conclusion
RI不仅准确量化了模型在其知识范围内拒绝的能力，还揭示了LLMs在事实任务上虽然能够取得高准确性，但其拒绝行为可能是不可靠和脆弱的。因此，建议将传统准确性指标与Refusal Index相结合，以进行全面的事实验证。
## 405. `cs.CL` - 格式惯性：大型语言模型在医疗咨询中的一种失效机制 [PDF](https://arxiv.org/pdf/2510.01688), [HTML](https://arxiv.org/abs/2510.01688)
### Authors
Seungseop Lim,Gibaeg Kim,Wooseok Han,Jean Seo,Hyunkyung Lee,Jaehyo Yoo,Eunho Yang
### Background
最近大型语言模型（LLMs）在聊天机器人和医疗预咨询应用中的应用取得了显著进步。在医疗领域，常见的适配LLMs进行多轮对话生成的方法是监督微调（SFT）。然而，在类似医疗预咨询的任务中，监督微调用的数据集通常表现出会话轮数分布偏斜的特点。这种偏斜导致了在医疗对话生成中出现一种新的失效机制——格式惯性，即模型在生成长对话时可能会产生格式正确但诊断信息不丰富的重复问题。
### Innovation
提出了一个简单的、基于数据的方法来重新平衡训练数据集中的轮数分布，以缓解格式惯性问题。实验结果表明，该方法显著减轻了医疗预咨询中的格式惯性问题。
### Conclusion
该研究揭示了大型语言模型在医疗预咨询中的一种新颖失效机制——格式惯性，并提出了一种基于数据的简单方法来解决此问题。
## 406. `cs.CL` - 比较评估司法决策提取的无监督指标 [PDF](https://arxiv.org/pdf/2510.01792), [HTML](https://arxiv.org/abs/2510.01792)
### Authors
Ivan Leonidovich Litvak,Anton Kostin,Fedor Lashkin,Tatiana Maksiyan,Sergey Lagutin
### Background
人工智能在法律自然语言处理中的迅速发展要求能够评估文本从司法判决中提取的可扩展方法。本文评估了16个无监督度量标准，包括新的公式来评估从1000份匿名的俄罗斯司法判决中提取七个语义块的质量，这些判决通过7168份专家评审（1到5的李克特量表）进行验证。
### Innovation
本文评估了16个无监督度量标准，涵盖了文档基础、语义、结构、伪参考数据和法律特定类别。这些度量标准无需预先注释的参考数据。研究结果显示，术语频率共现度和覆盖比/块完整性与专家评分的相关性最佳，而法律术语密度与专家评分的相关性为负。还测试了基于LLM的方法的性能。
### Conclusion
本文研究表明，无监督度量，包括基于LLM的方法，能够促进可扩展的筛选，但在涉及高度法律相关性的情况下，仍然需要人类判断。这项工作为法律NLP提供了两种注释方法，具有司法分析和伦理AI部署的潜在影响。
## 407. `cs.CL` - 机器可解析的工程设计标准及阀件规格 [PDF](https://arxiv.org/pdf/2510.01736), [HTML](https://arxiv.org/abs/2510.01736)
### Authors
Anders Gjerver,Rune Frostad,Vedrana Barisic,Melinda Hodkiewicz,Caitlin Woods,Mihaly Fekete,Arild Braathen Torjusen,Johan Wilhelm Kluwer
### Background
传统工程设计流程依赖于技术规范，需遵循特定标准，但产品规范、产品类型数据表和设计标准依然主要以文档形式存在，尽管数字化转型的愿景，工作流程仍停留在纸面。本文探讨如何通过模块化、可重复使用、机器可解析的知识本体转化这些技术规范，应用于工厂设计质量和设备选择过程的质量保障。
### Innovation
文章展示了如何将国际标准（如管道、材料和阀门设计）中的文本和表格知识转化为符合W3C标准的模版化知识本体，并通过这些知识本体对阀件选用过程进行自动化验证，确保合规性和质量。利用语义推理和可执行的设计规则，能够进一步确定工艺类型是否满足阀门规范，同时创建共享可重用的基于ISO数据本体的模版化知识本体，进一步应用于智能标准的数字化转型。
### Conclusion
通过构建基于ISO数据本体的标准模版化知识本体，应用语义推理和执行规则能够自动验证设备选择的合规性，证明了这种方法在标准组织向数字化智能标准过渡中的潜在价值。
## 408. `cs.CL` - 语言模型如何组合函数？ [PDF](https://arxiv.org/pdf/2510.01685), [HTML](https://arxiv.org/abs/2510.01685)
### Authors
Apoorv Khandelwal,Ellie Pavlick
### Background
尽管大型语言模型（LLMs）在解决组合任务方面显示出越来越强的能力，但它们是否使用组合机制来解决这些问题仍然是个开放的问题。本文通过研究前馈LLMs如何解决两步事实回忆任务，即可以组合表达为$g(f(x))$的任务，来探索这个问题。研究确认了现代LLMs存在“组合性缺口”：即它们能够计算$z = f(x)$和$y = g(z)$，并不必然能够计算组合$y = g(f(x))$。通过使用激活流的logit镜像，研究识别了两种处理机制，一种是组合性的，计算$f(x)$作为计算$g(f(x))$的一部分，另一种是直接的，没有任何可识别的中间变量$f(x)$的标记。最后发现，使用哪种机制似乎与嵌入空间的几何结构有关，其中流 idiomatic 机制在从$x$到$g(f(x))$存在线性映射的情况下占主导地位。
### Innovation
本文通过分析前馈LLMs解决两步事实回忆任务的过程，揭示了两种不同的处理机制，并发现嵌入空间几何结构对选择哪种处理机制有影响，尤其是在存在从$x$到$g(f(x))$的线性映射的情况下，idiomatic 的机制更为常见。这种方法为理解语言模型如何处理组合任务提供了新的视角，强调了嵌入空间几何在该过程中的重要性。
### Conclusion
研究发现，现代LLMs在解决组合任务$f(x)$和$g(f(x))$时存在“组合性缺口”。通过激活流分析和logit镜像，识别了两种处理机制，并与嵌入空间几何结构相关联。在特定条件下，idiomatic的处理机制更占优势。
## 409. `cs.CL` - 使用奖励模型增强大型语言模型推理：一项分析性综述 [PDF](https://arxiv.org/pdf/2510.01925), [HTML](https://arxiv.org/abs/2510.01925)
### Authors
Qiyuan Liu,Hao Xu,Xuhong Chen,Wei Chen,Yee Whye Teh,Ning Miao
### Background
奖励模型（RMs）在提升语言模型（LLMs）的推理性能方面起着至关重要的作用。例如，它们可以为强化学习（RL）中的LLM微调提供训练信号，帮助在推理过程中从多个候选答案中选择最佳答案。
### Innovation
本文提供了一个系统性的奖励模型介绍，并对其在LLM推理中的应用进行了综述。首先回顾了奖励模型的基本概念，包括其架构、训练方法和评估技术。然后探讨了其关键应用，包括引导生成和在LLM推理中选择最优输出，促进数据合成和LLM的迭代自我改进，以及在基于强化学习的微调中提供训练信号。最后，基于现有研究和自身实证发现，讨论了奖励模型的选择、泛化、评估和增强的关键开放问题。
### Conclusion
我们的分析旨在为奖励模型的有效部署和提升提供实操性见解，以支持LLM推理。
## 410. `cs.CL` - Veri-R1: 通过在线强化学习实现精确可靠的主张验证 [PDF](https://arxiv.org/pdf/2510.01932), [HTML](https://arxiv.org/abs/2510.01932)
### Authors
Qi He,Cheng Qian,Xiusi Chen,Bingxiang He,Yi R.(May)Fung,Heng Ji
### Background
近年来，基于大型语言模型（LLMs）的声明验证引起了广泛关注，因其强大且透明的推理能力超越了传统的仅提供答案的方法。在线声明验证需要多次证据检索和推理，但现有方法主要依赖于提示工程或预设的推理工作流程，缺乏统一的训练框架来提高相关技能。
### Innovation
Veri-R1 是一种在线强化学习（RL）框架，它使语言模型能够与搜索引擎交互并接收明确影响其规划、检索和推理行为的奖励信号。这种模型与检索系统的动态互动更准确地反映了现实世界的验证场景，并培养了全面的验证技能。实验证明，Veri-R1 可将联合准确性提高多达 30%，并使证据评分翻倍，通常超越了更大规模的同类方法。消融研究进一步揭示了奖励组件的影响以及输出对数与标签准确性之间的联系。
### Conclusion
我们的结果证明了在线 RL 对精细且真实的声明验证的有效性，并为未来的相关研究提供了基础。我们发布了代码以支持社区在语言模型赋能声明验证方面的发展。
## 411. `cs.CL` - REPAIR: Robust Editing via Progressive Adaptive Intervention and Reintegration [PDF](https://arxiv.org/pdf/2510.01879), [HTML](https://arxiv.org/abs/2510.01879)
### Authors
Yisu Wang,Ming Wang,Haoyuan Song,Wenjie Huang,Chaozheng Wang,Yi Xie,Xuming Ran
### Background
大型语言模型（LLMs）的后训练受到新知识获取成本高、纠正错误成本高及大规模连续编辑带来的不可预见副作用的限制。
### Innovation
该研究提出了REPAIR框架，这是一种终身编辑框架，通过闭环反馈机制和动态内存管理来减少大规模连续编辑的不稳定性和冲突。REPAIR还通过频繁的知识融合和强局部保护，解决了传统通用分布方法忽视的不可预见的连锁反应问题。
### Conclusion
该研究展示了REPAIR在多个模型家族上提高了10%-30%的编辑准确率，并显著减少了知识遗忘。REPAIR为开发可靠、可扩展且持续进化的LLMs提供了稳健的框架。
## 412. `cs.CL` - 通过结合语言模型嵌入和图神经网络来检测LLM生成的虚假评论 [PDF](https://arxiv.org/pdf/2510.01801), [HTML](https://arxiv.org/abs/2510.01801)
### Authors
Xin Liu,Rongwu Xu,Xinyi Jia,Jason Liao,Jiao Sun,Ling Huang,Wei Xu
### Background
大型语言模型（LLMs）的发展使得生成高度有说服力的虚假评论成为可能，这些评论模仿了人类的写作风格，给现有的检测系统带来了重大挑战。这些虚假评论威胁到在线平台的可信度。为了应对这一威胁，我们创建了三个使用不同LLM并结合产品元数据和真实参照评论的虚假评论数据集，通过对GPT-4.1的评估确认这些评论具有极高的说服力和欺骗性。
### Innovation
我们提出了一个名为FraudSquad的混合检测模型，该模型结合了预训练语言模型的文本嵌入和门控图变换器进行垃圾节点分类，能在不依赖于人工特征工程或大量训练资源的前提下捕捉到语义和行为信号。实验表明，FraudSquad在三个基于LLM生成的数据集上的精确度和召回率分别优于最先进的基线方法44.22%和43.01%，同时也对两个顾客生成的虚假评论数据集产生了积极的效果。FraudSquad还具有较小的模型规模和少量的标记训练数据需求，使其成为实际应用中的有效解决方案。我们的贡献包括新的合成数据集、实用的检测框架以及实证证据，强调了在LLM时代调整虚假评论检测的紧迫性。同时，我们的代码和数据集已公开可用。
### Conclusion
我们的工作解决了基于LLM的虚假评论检测问题，提出了FraudSquad模型，该模型通过结合语言模型嵌入和图神经网络，可以在保护模型规模和减少标记数据需求的情况下，有效地检测虚假评论，从而提高在线平台的可信度，并强调了在当前语言模型时代更新虚假评论检测机制的必要性。
## 413. `cs.CL` - 探索数据库规范化对SQL生成的影响 [PDF](https://arxiv.org/pdf/2510.01989), [HTML](https://arxiv.org/abs/2510.01989)
### Authors
Ryosuke Kohita
### Background
自然语言到SQL（NL2SQL）系统的架构设计，尤其是规范化，虽然是一个关键因素，但经常被忽视。大多数先前的研究集中在固定的数据库模式上，未能评估设计对性能的影响。因此，本文首次系统研究了规范化策略对NL2SQL系统性能的影响，并考察了不同规范化程度下的表现。
### Innovation
研究首次评估了八种主要的大语言模型在合成和真实世界数据集上的性能，这些数据集具有不同的规范化程度。通过构建遵循正式规范化规则（1NF-3NF）的控制合成数据集和实用的学术论文数据集，研究发现未规范化模式在处理简单检索查询时能够提供高准确度，即使在零样本设置中使用成本效益高的模型。相反，规范化模式（2NF/3NF）虽然在基本表选择和连接类型预测方面带来了挑战，但通过少量样本示例可以显著缓解这些问题。
### Conclusion
规范化对聚合查询有更好的表现，主要是因为它们能够更好地应对未规范化模式中由于数据重复和NULL值而导致的错误问题。这些发现表明，NL2SQL应用程序的最佳数据库模式取决于需要支持的查询类型。本研究强调了在开发NL2SQL接口时考虑数据库模式设计的重要性，并提出在未来将适应性模式选择集成到实际场景中具有重要意义。
## 414. `cs.CL` - 风格胜于故事：大型语言模型创作性的过程导向研究 [PDF](https://arxiv.org/pdf/2510.02025), [HTML](https://arxiv.org/abs/2510.02025)
### Authors
Donghoon Jung,Jiwoo Choi,Songeun Chae,Seohyon Jung
### Background
现有对大型语言模型（LLMs）创造性的评估主要集中在输出的质量上，而忽视了形成这些输出的过程。本文采用过程导向的方法，借助叙事学理论来研究LLMs作为计算作家的行为。
### Innovation
该研究引入基于约束的决策作为创作性分析的视角，并利用受控提示为模型赋予作者化人格，分析其创作偏好。研究发现，LLMs在风格上的一致性表现优于其他元素，包括人物、事件和场景。通过探究模型为其选择提供的理由，界定了模型间的独特特征，提出了一个新的系统性工具来分析AI的作者性创造性，具有新颖性。
### Conclusion
研究指出，模型在创作上的一致性主要体现在风格上，而不同模型可能存在不同的独特表现。这一方法为评估和分析AI的创造性提供了一种新的系统化工具。
## 415. `cs.CL` - 流式全双工端到端口语对话系统中的链式推理 [PDF](https://arxiv.org/pdf/2510.02066), [HTML](https://arxiv.org/abs/2510.02066)
### Authors
Siddhant Arora,Jinchuan Tian,Hayato Futami,Jiatong Shi,Yosuke Kashiwagi,Emiru Tsunoo,Shinji Watanabe
### Background
大多数端到端口语对话系统依赖于语音活动检测（VAD）来实现转场，但VAD难以区分静默和说话者结束话语。双工口语对话系统模型通过预测连续输出，包括静默标记，消除了明确VAD的需要。然而，这些模型往往具有复杂的双通道架构，语义推理能力落后于级联模型。
### Innovation
提出了一种新的流式链式推理（SCoT）框架，用于增强双工端到端口语对话系统。该框架在处理固定时长的用户输入和生成响应之间交替进行，使用帧级对齐创建每个块的中间目标对齐用户和系统的响应。
### Conclusion
实验表明，该方法产生的响应更为连贯和可解释，并且支持比逐轮系统更低延迟和重叠的交互。与现有双工方法相比，该方法在语义推理能力方面取得明显进步。
## 416. `cs.CL` - 从情感、情绪、论证和主题注释预测价值解释：SEAT 坐标系 [PDF](https://arxiv.org/pdf/2510.01976), [HTML](https://arxiv.org/abs/2510.01976)
### Authors
Adina Nicola Dobrinoiu,Ana Cristiana Marcu,Amir Homayounirad,Luciano Cavalcante Siebert,Enrico Liscio
### Background
人类的价值观念受到社会文化背景和个人经历的影响，因此是主观的。为了开发能够与多元人类视角对齐并避免偏向多数观点的AI系统，必须认识到和理解个体的价值解释。基于此，本文探索语言模型能否通过利用多维度的主观注释（作为个体解释视角的代理），来预测个体的价值解释。具体来说，通过提供以情感、情绪、论证和主题（SEAT维度）为例的注释，来评估这是否能够帮助语言模型更好地预测个体的价值解释。
### Innovation
本文在不同的零样本和少样本设置中证明，同时提供SEAT所有维度的信息相比单独提供每个维度或提供无个体信息的基线模型，能够获得更好的性能。此外，不同注释器间的个体差异强调了考虑个体主观注释者的个性化影响的重要性。这是首次从小规模控制实验中探讨注释行为对价值预测的影响，为未来大规模验证提供了坚实的基础。
### Conclusion
尽管规模较小，但本文通过SEAT坐标系的设定成功地超越了仅依赖人口统计学特征的局限，为研究个体价值解释提供了新的视角和方法，为未来的大规模验证奠定了基础。
## 417. `cs.CL` - 语法规则盲点：结构错位导致大语言模型数学错误的原因 [PDF](https://arxiv.org/pdf/2510.01831), [HTML](https://arxiv.org/abs/2510.01831)
### Authors
Dane Williamson,Yangfeng Ji,Matthew Dwyer
### Background
大语言模型（LLMs）在数学问题解决方面表现出色，但经常在语法特征与训练分布不同的问题上失败。研究发现，模型在面对语义简单但表达方式生疏的问题时，会错误地应用熟悉的推理策略，这种错误不是由于数学能力的欠缺，而是反映了表面形式与内部表示之间的脆弱耦合。作者通过使用来自正确示例的句法模板重述错误回答的问题，发现这些重述问题在保持语义的同时减少了结构性复杂性，常常能够得到正确答案。研究还使用依赖局部理论（DLT）为基础的句法复杂度度量工具量化句法复杂性，结果表明，更高的句法复杂度与多个数据集中的错误率增加有关。研究表明，许多推理错误源于结构性错位而非概念性困难，且语法意识的干预措施可以揭示并解决这些归纳性失败。
### Innovation
研究定义了一种系统的失败模式——语法规则盲点，即模型在处理语义清晰但表达方式生疏的问题时，会错误地应用熟悉的推理策略，这并非由于数学能力的缺失，而是由于表面形式与内部表示之间的脆弱耦合。研究通过使用从正确示例中抽取的句法模板重述错误的回答，发现这可以在保持语义的情况下减少结构复杂性，从而引导出正确的答案。此外，研究使用依赖局部理论（DLT）为基础的句法复杂度度量工具量化句法复杂性，并表明更高的句法复杂度与错误率增加之间存在关联。研究表明，许多推理错误源于结构性错位，而不是概念性困难，并提出语法意识的干预措施可以揭示并缓解这些归纳性失败。
### Conclusion
研究表明，许多数学错误归因于结构性错位而非概念性困难，通过语法敏感的干预措施可以揭示并缓解这些归纳性失败，这为改进大语言模型的推理能力提供了新的视角。
## 418. `cs.CL` - 向稳健和具地基性的大型语言模型过渡的逆向语言模型 [PDF](https://arxiv.org/pdf/2510.01929), [HTML](https://arxiv.org/abs/2510.01929)
### Authors
Davide Gabrielli,Simone Sestito,Iacopo Masi
### Background
当前大型语言模型（LLMs）的防御机制是碎片化且不发达的，不同于已有分类器相关研究。为了进一步提升LLMs的对抗鲁棒性，作者提出了一种名为逆向语言建模（ILM）的统一框架。
### Innovation
ILM框架同时提升了LLMs对抗输入扰动的稳健性，并通过反向推导模型输出来识别潜在的有害或不安全的输入触发器，使得LLMs可以从静态生成器转变为可分析和稳健的系统，有助于RED团队的合作。ILM为下一世代的LLMs铺平了道路，使这些模型不仅具有稳健性和地基性，而且还更为可控和可信。
### Conclusion
ILM能够构建新型的LLMs，这些模型不仅具有稳健性和地基性，而且从根本上更加可控和可信。相关代码已公开发布。
## 419. `cs.CL` - 推测性解码的不公平影响 [PDF](https://arxiv.org/pdf/2510.02128), [HTML](https://arxiv.org/abs/2510.02128)
### Authors
Jameson Sandler,Ahmet Üstün,Marco Romanelli,Sara Hooker,Ferdinando Fioretto
### Background
推测性解码方法通过由一个较小、更便宜的“草稿”模型提供概率性支持来进行推理，已成为系统减少大型语言模型解码时间的标准技术。已有研究表明，不同任务的推测性解码加速效果存在显著差异，特别是在欠拟合任务上加速效果不佳且通常被忽视。
### Innovation
本文提出了一个新的分析方法来量化推测性解码导致的不公平现象，并揭示了导致这种差异加速的因素。基于这些见解，提出了一个缓解策略以减少加速差异，结果在多个模型对中平均提高了12%的公平性指标。
### Conclusion
推测性解码的效果并非在所有任务上一致，容易导致加快解码时间的不公平现象。通过量化这种不公平现象，并识别其背后的原因，本文提出了一种缓解策略，有效地减少了不同任务之间的加速差异。
## 420. `cs.CL` - SCRIBES：使用强化学习的大规模基于脚本的半结构化数据提取 [PDF](https://arxiv.org/pdf/2510.01832), [HTML](https://arxiv.org/abs/2510.01832)
### Authors
Shicheng Liu,Kai Sun,Lisheng Fu,Xilun Chen,Xinyuan Zhang,Zhaojiang Lin,Rulin Shao,Yue Liu,Anuj Kumar,Wen-tau Yih,Xin Luna Dong
### Background
HTML表格、列表和信息框中的半结构化内容占网页上事实数据的很大一部分，但格式化内容的复杂性使得使用及从中可靠地抽取结构化信息变得困难。现有方法要么缺乏广泛适用性，要么因每页LLM推理资源密集度大而受限。
### Innovation
本文提出了一种名为SCRIBES的新型强化学习框架，利用同一站点网页间的布局相似性作为奖励信号，生成可重复使用的提取脚本应用于结构相似的网页组。此外，通过迭代训练，利用野生CommonCrawl数据中的合成标注数据进一步改进。实验表明，该方法在脚本质量上高出基准方法13%以上，在GPT-4o下游问题回答准确性上提高超过4%，使网络信息抽取更具扩展性和资源效率。
### Conclusion
我们的方法在脚本质量和下游问题回答准确性上都优于强基线。通过使用合成标注数据进一步训练，提高了从大规模网页中提取半结构化数据的效率和效果。
## 421. `cs.CL` - 基于LLM的多任务孟加拉仇恨言论检测：类型、严重程度和目标 [PDF](https://arxiv.org/pdf/2510.01995), [HTML](https://arxiv.org/abs/2510.01995)
### Authors
Md Arid Hasan,Firoj Alam,Md Fahad Hossain,Usman Naseem,Syed Ishtiaque Ahmed
### Background
在线社交媒体平台是日常交流和信息查询的核心。虽然这些平台具有积极的作用，但也为仇恨言论、侮辱语言和针对个人、组织和社区的欺凌内容的传播提供了肥沃的土壤。此类内容损害了在线的安全性、参与度和公平性。因此，需要可靠的检测系统，特别是在低资源语言中，由于缺乏管理工具，更为重要。孟加拉语中，此前的研究提供了资源和模型，但大多数是单任务（例如二元分类）且对多方面信号（类型、严重程度、目标）的覆盖面有限。我们的工作填补这一空白，引入了第一个多任务孟加拉仇恨言论数据集BanglaMultiHate，是迄今为止手动标注的最大语料库之一。基于此资源，我们进行了全面、受控的比较，涵盖经典基准、单语预训练模型和在零样本提示和LoRA微调下的LLM。我们的实验评估了LLM在低资源环境下的适应性，并揭示了一个持续趋势：尽管LoRA调优的LLM在与BanglaBERT竞争，但文化和语言背景下的预训练依然是实现稳健性能的关键。
### Innovation
我们介绍了第一个多任务孟加拉仇恨言论数据集BanglaMultiHate，最大的手动标注语料库之一，覆盖了多方面的信号（类型、严重程度、目标），并进行了全面、受控的比较，涵盖经典基准、单语预训练模型和在零样本提示和LoRA微调下的LLM。结果揭示了LLM在低资源环境下的适应性，并强调了文化和语言背景下的预训练对于稳健性能的重要性。
### Conclusion
我们的数据集和发现为低资源背景下开发文化一致的管理工具建立了更坚定的基准。为了可再现性，我们将发布数据集和所有相关脚本。
## 422. `cs.CL` - Model Merging to Maintain Language-Only Performance in Developmentally Plausible Multimodal Models [PDF](https://arxiv.org/pdf/2510.01845), [HTML](https://arxiv.org/abs/2510.01845)
### Authors
Ece Takmaz,Lisa Bylinina,Jakub Dotlacil
### Background
当前的视觉-语言模型含有大量参数，并且是通过海量数据集学习的，量级甚至超过了儿童在学习语言过程中接触到的语文数据。论文针对这一差距，在BabyLM挑战的多模态任务中提出了我们的方法。我们使用发育学上合理的数据集设计了仅语言和多模态模型，并且多模态模型在这些低资源设置中超越了之前BabyLM的基线模型。然而，先前的研究发现多模态模型在仅语言的任务上往往表现不佳。
### Innovation
我们通过实验模拟将多模态模型的参数与仅语言模型的参数进行加权线性插值融合，以维持多模态模型中的仅语言性能。我们的研究结果证明，对于依赖于语法的仅语言基准测试，多模态模型的表现确实较差，而和使用文本仅模型的模型合并可以部分改善这个问题，同时保留多模态性能。
### Conclusion
我们的方法证明了对于比较依赖语法的仅语言基准测试，多模态模型确实较差表现，而和仅语言模型的模型合并能一定程度上缓解这一问题，同时保持了多模态模型的性能。
## 423. `cs.CL` - AccurateRAG: 基于检索增强生成的精确问答应用框架 [PDF](https://arxiv.org/pdf/2510.02243), [HTML](https://arxiv.org/abs/2510.02243)
### Authors
Linh The Nguyen,Chi Tran,Dung Ngoc Nguyen,Van-Cuong Pham,Hoang Ngo,Dat Quoc Nguyen
### Background
该研究介绍了一种名为AccurateRAG的新框架，用于构建基于检索增强生成（RAG）的高性能问答应用程序。背景信息指出，RAG是集成检索和生成技术的先进问答系统，可以显著提高问答应用的准确性和效率。
### Innovation
AccurateRAG框架提供了一条开发高效的管道，包含数据预处理、微调数据生成、文本嵌入及大型语言模型（LLM）微调、输出评估以及本地构建RAG系统的工具。研究结果显示，该框架在基准数据集上超越了之前的强基线，并取得了新的性能水平。
### Conclusion
实验结果表明，AccurateRAG框架在多种基准数据集上的表现优于前先进的基线模型，展示了其在构建高效、高准确性的检索增强生成问答应用方面的优势。
## 424. `cs.CL` - 增强阿拉伯语网络欺凌检测：深度嵌入和变换器（BERT）方法 [PDF](https://arxiv.org/pdf/2510.02232), [HTML](https://arxiv.org/abs/2510.02232)
### Authors
Ebtesam Jaber Aljohani,Wael M. S. Yafoo
### Background
智能手机和通信技术的最新进展，特别是大规模社交媒体平台（如X平台，即 Formerly Twitter）的兴起，对年轻人的心理健康构成了威胁，原因在于他们暴露在网络欺凌、嘲弄和侮辱性内容之下。大多数自动检测网络欺凌的方法主要集中在英语上，而对于阿拉伯语网络欺凌的检测方法则极为匮乏。因此，该领域需要新的解决方案来提高检测方法的有效性。
### Innovation
本文提出了一个包含10,662个X平台帖子的数据集，并使用kappa工具提升了标注质量。作者尝试了多种深度学习模型，包括单向和双向长短期记忆（LSTM）模型，以及利用BERT预训练双向编码器对LSTM和Bi-LSTM模型进行改进。其中，Bi-LSTM与FastText嵌入词的组合实现了最高的准确率98%。这项研究的创新之处在于采用了深度嵌入技术和Transformer (BERT)方法来提高阿拉伯语网络欺凌检测的准确性。
### Conclusion
研究结果表明，尽管Bi-LSTM与FastText嵌入词的组合和Bi-LSTM-BERT模型都取得了显著的准确率，即98%和97%，但整体上模型的泛化能力较好。这证明了深度学习和预训练模型在阿拉伯语网络欺凌检测中的有效性和潜力。
## 425. `cs.CL` - 超过一个教师：具有多样探索的自适应多引导策略优化 [PDF](https://arxiv.org/pdf/2510.02227), [HTML](https://arxiv.org/abs/2510.02227)
### Authors
Xiaoyang Yuan,Yujuan Ding,Yi Bin,Wenqi Shao,Jinyu Cai,Jingkuan Song,Yang Yang,Hengtao Shen
### Background
现有的强化学习方法主要依赖自我探索或单一离策教师来触发长链条思考（LongCoT）的推理，这可能会引入内在的模型偏差，并限制探索，最终限制推理多样性和性能。现有方法的主要局限在于依赖单一教师进行探索指导，导致探索受限和推理多样性不足的问题。
### Innovation
本文引入了自适应多引导策略优化（AMPO）框架，这是一种新颖的框架，能够在模型自我推理失败时，从多个教师中选择性地获得指导，实现‘需求驱动’的引导。AMPO还包含了一种基于理解的选择机制，促使学生学习其最有可能理解的推理路径，从而实现了广泛探索与有效利用之间的平衡。实验结果表明，AMPO相较于强基线GRPO具有显著优势，在数学推理任务上提高了4.3%的表现，在分布外任务上提高了12.2%，并且显著提升了Pass@k性能，同时使探索更为多样化。使用四个同规模的教师时，该方法达到了使用单一更强大教师（如DeepSeek-R1）时的表现，但投入数据更少。这些结果显示了实现更高效和可扩展的先进推理与泛化的新路径。
### Conclusion
AMPO方法通过实现更多样和高效的探索，展现了在提升推理能力和泛化性的潜力。该研究表明，利用多教师进行引导的策略优化方法在提升模型推理和泛化能力方面具有重要作用，并且该方法具有更高的效率和可扩展性。
## 426. `cs.CL` - ARUQULA — 一种基于大语言模型的使用ReAct和知识图谱探索工具的Text2SPARQL方法 [PDF](https://arxiv.org/pdf/2510.02200), [HTML](https://arxiv.org/abs/2510.02200)
### Authors
Felix Brei,Lorenz Bühmann,Johannes Frey,Daniel Gerber,Lars-Peter Meyer,Claus Stadler,Kirill Bulert
### Background
对于没有计算机科学背景的人来说，与知识图谱交互是一项艰巨的任务，因为用于查询的语言（SPARQL）具有较高的入门门槛。大型语言模型（LLMs）可以通过提供从自然语言问题到SPARQL查询的翻译支持来降低这一门槛。文本到SPARQL（Text2SPARQL）挑战是为了促进该领域的改进而设立的一项挑战，其目标是通过大语言模型基于SPINACH（一种LLM支持的代理）来提供一个逐步转化为SPARQL查询的过程，而不是一次性完成。
### Innovation
本文介绍了一种基于SPINACH的通用方法，该方法是一种LLM支持的代理，它不是一次性将自然语言问题转化为SPARQL查询，而是在探索和执行过程中逐步进行转换。此外，文中还详细描述了整体架构和设计决策的背后逻辑，并进行了深入的代理行为分析，以获得对未来改进领域的洞察。
### Conclusion
这篇工作受到了Text2SPARQL挑战的启发，旨在通过逐步转化和知识图谱探索工具的应用来支持用户与知识图谱的交互，从而降低使用SPARQL查询语言的门槛。通过这种方法，本文为未来在该领域内的改进提供了方向。
## 427. `cs.CL` - 学习进行推理以检测幻觉片段 [PDF](https://arxiv.org/pdf/2510.02173), [HTML](https://arxiv.org/abs/2510.02173)
### Authors
Hsuan Su,Ting-Yao Hu,Hema Swetha Koppula,Kundan Krishna,Hadi Pouransari,Cheng-Yu Hsieh,Cem Koc,Joseph Yitan Cheng,Oncel Tuzel,Raviteja Vemulapalli
### Background
大语言模型（LLMs）经常生成幻觉——无法支持的内容，这损害了可靠性。尽管大多数先有研究将幻觉检测视为二元任务，但许多实际应用场景需要识别出幻觉片段，这是一个多步骤的决策过程。这就自然引发了问题：显式推理是否能帮助解决检测幻觉片段的复杂任务？
### Innovation
本文首先评估了带有和不带有逐步推理（CoT）的预训练模型，并展示了逐步推理有可能在多次采样中至少生成一个正确答案。然后提出了RL4HS（基于强化学习的幻觉片段检测框架），这是一种通过片段级奖励函数激励推理的强化学习框架。RL4HS基于Group Relative Policy Optimization，并引入了Class-Aware Policy Optimization来减轻奖励不平衡问题。实验结果表明，RL4HS在RAGTruth基准（总结、问答、数据到文本）上超过了预训练推理模型和监督细调，证明了使用片段级奖励进行强化学习的必要性以检测幻觉片段.
### Conclusion
RL4HS框架使用片段级奖励函数在多项任务中超越了预训练推理模型和监督微调，显示了在检测幻觉片段方面强化学习的重要性。
## 428. `cs.CL` - Explore Briefly, Then Decide: Mitigating LLM Overthinking via Cumulative Entropy Regulation [PDF](https://arxiv.org/pdf/2510.02249), [HTML](https://arxiv.org/abs/2510.02249)
### Authors
Tianyi Jiang,Yi Bin,Yujuan Ding,Kainian Zhu,Fei Ma,Jingkuan Song,Heng Tao Shen
### Background
大型语言模型（LLMs）在解决复杂问题时展示出了卓越的推理能力，尤其是通过长链推理（Chain-of-Thought, CoT）。然而，这些模型在处理简单问题时常表现出过度推理的现象，即产生了不必要的漫长推理步骤。这将影响模型的效率，并使其难以根据问题的复杂性调整推理深度。
### Innovation
该研究引入了一个新的度量方法——Token Entropy Cumulative Average (TECA)，用于衡量推理过程中的探索程度。同时提出了一种新的推理模式——“初步探索，然后决定”（Explore Briefly, Then Decide），并提出了相应的累积熵调节（Cumulative Entropy Regulation, CER）机制。这种方法利用TECA帮助模型动态确定其思考过程的最佳结束点，从而实现高效的推理。
### Conclusion
在跨领域数学基准测试上的实验结果显示，该方法在减轻过度推理的同时，显著提高了问题解决能力。在更简单的数据集上，平均回应长度减少了最高达71%，这证明了该方法在创建更高效、适应性强的推理过程中的有效性。
## 429. `cs.CL` - 说一套做一套？VLM 动力移动应用代理中的推理-执行缺口诊断 [PDF](https://arxiv.org/pdf/2510.02204), [HTML](https://arxiv.org/abs/2510.02204)
### Authors
Lingzhong Dong,Ziqi Zhou,Shuaibo Yang,Haiyue Sheng,Pengzhou Cheng,Zongru Wu,Zheng Wu,Gongshen Liu,Zhuosheng Zhang
### Background
基于视觉语言模型（VLMs）的移动应用代理在自然语言指令解释和基于移动图形用户界面的相应行动生成方面表现出巨大潜力。当前研究发现，融入链式思考（CoT）推理的代理可以提高执行准确性。然而，现有的评估方法过于注重执行准确性，而忽视了CoT推理是否与实际操作一致，忽略了潜在的推理和执行差距。这种忽视可能导致用户过早信任看似合理的推理，从而授权有害操作，引发经济损失或信任危机。
### Innovation
本文提出了一套新的评估框架，用以诊断推理-执行缺口。该框架的核心是 Ground-Truth Alignment (GTA)，用于衡量CoT推理所指向的动作是否与真实的动作一致。通过将GTA与标准的精确匹配（EM）指标结合，我们同时评估推理和执行的准确性。结果表明，推理-执行缺口在多种移动交互任务中普遍存在，执行缺口比推理缺口更为常见。尽管随着模型规模的扩大，整体差距有所减少，但大型模型中仍然存在显著的执行缺口。进一步分析显示，该框架能可靠地反映最先进的模型中的系统性执行缺口/推理缺口模式。
### Conclusion
研究结果提供了具体的诊断方法并支持了更值得信赖的移动应用代理的开发。
## 430. `cs.CL` - RESTRAIN: 从虚假投票到信号——自我驱动的自惩罚式强化学习 [PDF](https://arxiv.org/pdf/2510.02172), [HTML](https://arxiv.org/abs/2510.02172)
### Authors
Zhaoning Yu,Will Su,Leitian Tao,Haozhu Wang,Aashu Singh,Hanchao Yu,Jianyu Wang,Hongyang Gao,Weizhe Yuan,Jason Weston,Ping Yu,Jing Xu
### Background
强化学习在大型推理模型中引入人类标注数据可以提升链式推理能力，但需要大量的标注数据且在更复杂任务中表现不佳。自然，下一步是通过经验学习来改进模型，使其能够通过未标记数据进行自我学习和自我提升，而无需精确标注。
### Innovation
RESTRAIN框架提出了一种自我惩罚式强化学习方法，能够将缺乏黄金标签的数据转化为有效的学习信号。该方法通过自我惩罚机制来减少盲目自信的推理，保留有价值的推理链，并无缝集成于学习策略优化方法中，实现持续自我改进。此方法仅使用未标记数据，在具有挑战性的推理基准上取得了显著效果。
### Conclusion
RESTRAIN在未使用黄金标签数据的情况下，通过自我惩罚机制，在AIME25、MMLU_STEM和GPQA-Diamond等具有挑战性的理性基准测试上显著提升了推理性能，几乎达到了黄金标签训练的效果。这表明RESTRAIN为无标签数据下的强推理设定了可行的路径。
## 431. `cs.CL` - 控制温度：基于风险选择性采样的高质且多样化的LLM输出 [PDF](https://arxiv.org/pdf/2510.01218), [HTML](https://arxiv.org/abs/2510.01218)
### Authors
Sergey Troshin,Wafaa Mohammed,Yan Meng,Christof Monz,Antske Fokkens,Vlad Niculae
### Background
多样性是评估语言模型生成输出的创意性的重要指标。温度调节采样是增加多样性的常用策略。然而，对于需要高精度的任务，如数学推理，高温度采样（如min-p或top-p）会导致质量下降。
### Innovation
提出了一种名为‘选择性采样’的方法，该方法基于一个采样风险度量，动态地在贪婪采样和高温度采样之间切换。通过小型可验证问题集训练的轻量级分类器，用于预测当前令牌位置采用高温度采样时的输出错误概率，并在最小延迟开销的情况下与基础语言模型结合使用。
### Conclusion
实验表明，选择性采样方法可以在高温度设置中增强质量与多样性的权衡。
## 432. `cs.CL` - F2LLM 技术报告：通过六百万开源数据达到与业界最佳性能匹配的嵌入模型 [PDF](https://arxiv.org/pdf/2510.02294), [HTML](https://arxiv.org/abs/2510.02294)
### Authors
Ziyin Zhang,Zihan Liao,Hang Yu,Peng Di,Rui Wang
### Background
目前，顶尖嵌入模型通常需要大量的对比预训练、复杂的训练流水线和昂贵的合成训练数据。这些模型的训练成本高、模型规模大，且嵌入性能优秀。
### Innovation
F2LLM 是一个嵌入模型集合，包括 0.6B、1.7B 和 4B 三种规模的模型。无需大规模对比预训练和复杂的训练流水线，从基础模型直接微调 600 万查询-文档-负面元组，源自开源的真实数据集。这种模型在训练成本、模型规模和嵌入性能之间取得了良好的平衡。
### Conclusion
F2LLM-4B 在 MTEB 英文排行榜上位列参数量接近 4B 的模型第二，F2LLM-1.7B 在 1B-2B 模型范围内排名第一。为了促进未来的研究工作，我们发布了模型、训练数据集和代码，将 F2LLM 定位为未来工作中强大、可复现且低成本的基线。
## 433. `cs.CL` - Stream RAG: 实时且准确的语音对话系统及其流式工具使用 [PDF](https://arxiv.org/pdf/2510.02044), [HTML](https://arxiv.org/abs/2510.02044)
### Authors
Siddhant Arora,Haidar Khan,Kai Sun,Xin Luna Dong,Sajal Choudhary,Seungwhan Moon,Xinyuan Zhang,Adithya Sagar,Surya Teja Appini,Kaushik Patnaik,Sanat Sharma,Shinji Watanabe,Anuj Kumar,Ahmed Aly,Yue Liu,Florian Metze,Zhaojiang Lin
### Background
端到端的语音对话系统正在成为传统ASR-LLM-TTS流水线的强大替代方案，能够生成更加自然、具有表现力的响应，并且显著降低延迟。然而，这些系统仍容易产生幻觉，因为它们的事实背景有限。文本对话系统通过集成工具，如网络搜索和知识图谱API来应对这一挑战，但没有直接将其应用到语音对话系统中。一个关键挑战是工具集成会大幅增加响应延迟，破坏对话流动。
### Innovation
本研究提出了首个将工具使用直接扩展到语音对话系统中的方法——Streaming Retrieval-Augmented Generation (Streaming RAG)，通过预测在用户说话期间并行进行的工具查询来减少用户感知到的延迟。此外，开发了一个后训练管道，教会模型在持续对话中何时呼叫工具以及如何生成将音频查询与检索到的文本结果融合的语音摘要，从而提高准确性和响应速度。
### Conclusion
实验结果表明，我们的流式RAG方法将问答准确性提高了高达200%，从相对的11.1%提升到绝对的34.2%，并进一步通过减少工具使用延迟20%来提升用户体验。重要的是，我们的流式RAG方法不受模态限制，可以将响应用于包括键盘输入在内等多种输入，为更具有行动性、实时的人工智能助理铺平了道路。
## 434. `cs.CL` - 从行为性能到内在能力：使用VLM-Lens解释视觉-语言模型 [PDF](https://arxiv.org/pdf/2510.02292), [HTML](https://arxiv.org/abs/2510.02292)
### Authors
Hala Sheta,Eric Huang,Shuyu Wu,Ilia Alenabi,Jiajun Hong,Ryker Lin,Ruoxi Ning,Daniel Wei,Jialin Yang,Jiawei Zhou,Ziqiao Ma,Freda Shi
### Background
该论文介绍了VLM-Lens工具包，旨在通过支持提取开放源代码视觉-语言模型（VLMs）在前向传递过程中任何层的中间输出，实施数字化基准测试、分析和解释VLMs。VLM-Lens提供了一个统一的、基于YAML配置的接口，使操作变得用户友好，同时抽象了模型特定的复杂性，支持跨多种不同模型的操作。该工具包当前支持16种先进的基础VLM及其超过30种变体，并且易于扩展以适应新模型。研究表明，VLM-Lens可以揭示不同层及目标概念下VLMs隐藏表示的系统性差异。通过开放源代码项目分享这一工具，旨在促进社区对理解和改进VLMs的努力。
### Innovation
VLM-Lens通过支持提取开放源代码VLMs的中间输出，简化了对这些模型的系统化分析和解释过程。它提供了一个统一的、配置灵活的接口，抽象了特定模型的复杂性，使得操作更加友好，并且易于与各种解释性和分析方法集成。该工具包已经支持多种先进的基础VLM及其多种变体，并具有扩展新模型的功能，无需更改核心逻辑。
### Conclusion
通过VLM-Lens的使用，研究人员可以揭示不同层和目标概念下VLMs内的隐藏表征差异。该工具包的开源发布将加速社区对VLMs理解与改进的工作。
## 435. `cs.CL` - 平行扩展定律：通过跨语言视角揭示推理泛化 [PDF](https://arxiv.org/pdf/2510.02272), [HTML](https://arxiv.org/abs/2510.02272)
### Authors
Wen Yang,Junhong Wu,Chong Li,Chengqing Zong,Jiajun Zhang
### Background
最近在强化后训练（RPT）方面的进步极大地增强了大型推理模型（LRM）的能力，引起了对基于强化学习（RL）推理泛化的广泛关注。现有研究主要集中在任务或模态的泛化上，而这项研究提出了一种新的跨语言视角来探索推理泛化问题。通过系统评估以英语为中心的LRM在多语言推理基准上的表现，并引入了衡量跨语言可转移性的度量标准，发现跨语言可转移性在初始模型、目标语言和训练范式之间差异显著。通过对干预研究的发现，展示了模型初期强大的英语能力往往会过度依赖特定于英语的模式，导致跨语言泛化的下降。为了克服这个挑战，作者进行了广泛的并行训练研究，揭示了从单语言到多个并行语言时性能显著提升的现象，并揭示了跨语言推理迁移遵循幂律变化的规律，这一规律随着用于训练的并行语言数量变化而变化。还指出了实际 monoclingual 性能与幂律预测之间的差距，表明以英语为中心的LRM在语言间泛化能力上存在不足，挑战了LRM推理与人类认知一致的假设。
### Innovation
该研究通过引入跨语言视角，提出了跨语言泛化的平行扩展定律，并构建了一种衡量跨语言可转移性的新方法。确认了跨语言迁移在不同初始模型、目标语言和训练范式下的表现差异，并发现跨语言推理迁移遵循幂律变化的规律。同时，该研究发现了实际单语言性能与幂律预测之间的差距，提出了单语言泛化差距的概念，指出以英语为中心的LRM未能在语言间充分泛化。这项研究强调了多语言训练的重要性，并为构建更多语言无关的LRM提供了重要指导。
### Conclusion
该研究揭示了跨语言迁移容量在多语言推理中的 importance 和挑战，并提出了跨语言平行扩展定律。通过发现并纠正当前方法中的局限性，作者为实现更广泛语言的模型带来了新的思路，特别是在涉及多语言环境的应用场景下。
## 436. `cs.CL` - 通过具有相关语义和针对性有害知识的嵌套场景破解LLMs [PDF](https://arxiv.org/pdf/2510.01223), [HTML](https://arxiv.org/abs/2510.01223)
### Authors
Hui Dou,Ning Xu,Yiwen Zhang,Kaibin Wang
### Background
大语言模型（LLMs）在各种任务中表现出色，但仍然容易受到 Jailbreak 攻击，即产生有害响应。现有方法中越来越多地采用了嵌套场景策略，但这些方法由于其明显的恶意意图容易被检测。本文研究了 LLMs 的对齐防御对嵌套场景的敏感性，发现现有的保护措施在面对这类攻击时效果不佳。
### Innovation
首次系统地验证了 LLMs 的对齐防御在面对嵌套场景策略时的不敏感性。提出了一个自适应且自动化的框架 RTS-Attack，可以通过构建与查询高度相关且包含针对性有害知识的场景来绕过对齐防御，且生成的 Jailbreak 提示不会包含有害查询，增加了攻击的隐蔽性。实验结果表明，RTS-Attack 在多种先进的 LLMs 中表现出了更高的效率和更广的适用性。
### Conclusion
RTS-Attack 是一个有效的检查 LLMs 对齐的框架。通过测评，RTS-Attack 的性能在多种复杂的 LLMs 中优于现有基准方法，具有更高的效率和更广泛的适用性。完整的代码已提交至补充材料中，并警告该论文包含潜在有害内容。
## 437. `cs.CL` - 使用基于LLM的人工智能代理自动提取材料属性 [PDF](https://arxiv.org/pdf/2510.01235), [HTML](https://arxiv.org/abs/2510.01235)
### Authors
Subham Ghosh,Abhishek Tewari
### Background
材料发现的速度受限于缺乏能够结合性能指标与结构背景的大规模、结构化数据集。现有数据库要么规模小、手工整理，要么偏向第一性原理结果，使得实验文献未得到充分利用。
### Innovation
本文介绍了一种基于代理、使用大语言模型驱动的工作流，该工作流能自主从约10,000篇全文科学文章中提取热电和结构属性。该管道结合动态令牌分配、零样本多智能体提取和条件表解析来平衡准确性和计算成本。GPT-4.1和GPT-4.1 Mini在基准测试中表现出较高的准确性，并且GPT-4.1 Mini则以极低的成本达到了相似的效果，使得大规模实际部署成为可能。此外，使用该工作流构建了一个庞大的热电属性记录集，包括多种属性，并且进行了数据集分析以再现热电趋势，并揭示更广泛的功能-结构关联性。以供社区访问，还提供了一个具有语义过滤器、数值查询和CSV导出功能的交互式网络浏览器。
### Conclusion
这一研究提供了迄今为止最大的基于大语言模型的人工智能代理整理的热电数据集，提供了一种可重复且成本可控的提取管道，并为超出热电之外的材料发现建立了数据驱动的基础。
## 438. `cs.CL` - 从差距中得出结论：重新思考Arena风格LLM评估中的偏好语义 [PDF](https://arxiv.org/pdf/2510.02306), [HTML](https://arxiv.org/abs/2510.02306)
### Authors
Raphael Tang,Crystina Zhang,Wenyan Li,Carmen Lai,Pontus Stenetorp,Yao Lu
### Background
在 arena-style 评估大型语言模型 (LLMs) 的过程中，两个 LLM 对用户提出的问题作出响应，用户选择哪个回答最好或认为是平局，进而调整两个模型的评分。目前，这种评价动态通常被视为两人对决的游戏，如国际象棋，并应用 Elo 等评分系统。然而，有观点认为平局不一定意味着两个模型是平等的，从而不应平等化评分。为此，本论文质疑这一传统观念。通过在实际 arena 数据集上进行实验，发现忽略平局的评分更新能提高 1-3% 的评价结果准确性（包括平局），进一步分析显示，更容易的查询和主观性较低的查询会导致更多平局。这表明现有的平局定义可能需要改进，并建议未来的评分系统考虑查询属性来更新评分
### Innovation
本论文挑战了目前 arena-style 评估中平局意味着平等的观点，提出平局更可能是查询难度的反映。通过实验数据证明了新的评分系统在一定程度上的优势，并强调未来评分系统应考虑查询属性来改进平局的处理方式
### Conclusion
本论文通过对实际 arena 数据集的实验，证实了忽视平局评分更新能提高评价结果准确性，并揭示了平局的查询特性。建议未来评分系统重新审视平局的含义，并采取更合理的评分更新方式
## 439. `cs.CL` - 利用现代大型语言模型（LLM）进行金融趋势分析和摘要创建 [PDF](https://arxiv.org/pdf/2510.01225), [HTML](https://arxiv.org/abs/2510.01225)
### Authors
Andrei Lazarev,Dmitrii Sedov
### Background
信息的指数增长对研究人员和专业人士构成了重大挑战，使他们难以保持在各自领域的前沿。本文介绍了利用大型语言模型（LLMs）的最新框架，特别是谷歌的Gemini Pro，自动生成深入的金融摘要，从而解决传统分析方法的局限性，提高数据处理效率，并为研究人员提供易于理解的洞察力。
### Innovation
利用大型语言模型（LLMs）的最新框架，特别是在OpenAlex数据提取、策略性提示工程和LLM驱动的分析基础上，自动生成全面的、概括关键发现和识别新兴趋势的金融摘要。这种方法解决了传统分析方法的局限性，允许高效处理大量无结构数据，并提供易于理解的行动建议。详细描述了LLMs的工作原理及其如何帮助研究人员和学者节省时间并保持对当前趋势的了解。提供了一个从数据获取和JSON构建到与Gemini互动和自动化PDF报告生成的逐步过程，并公开了项目的GitHub地址，以获得更广泛的访问和支持。
### Conclusion
本文通过利用Gemini Pro和L大型语言模型，成功实现了金融趋势的自动摘要生成，并提供了一个易于理解的操作流程。这为用户提供了一种更高效、更快速的获取金融信息的方式，有助于研究人员和专业人士更好地应对信息爆炸带来的挑战。
## 440. `cs.CL` - 基于LLM的多Agent黑板系统在数据科学中的信息发现 [PDF](https://arxiv.org/pdf/2510.01285), [HTML](https://arxiv.org/abs/2510.01285)
### Authors
Alireza Salemi,Mihir Parmar,Palash Goyal,Yiwen Song,Jinsung Yoon,Hamed Zamani,Hamid Palangi,Tomas Pfister
### Background
大数据湖中的数据挖掘挑战使大规模语言模型（LLMs）的应用受限。现有方法中，单一代理系统无法处理大规模、异构的数据文件，而基于主从模式的多代理系统依赖于一个具有精确子代理能力知识的中心控制器来分配任务，这限制了系统的灵活性和可扩展性。
### Innovation
提出了一种基于传统AI模型中的黑板架构的多代理通信新范式。该架构中，中心代理发布请求到共享黑板，具有能力的自主子代理根据自己的职能来响应。这种设计消除了中心协调者对所有子代理专家知识的先验需求，提高了系统的可扩展性和灵活性。进行了实验评估，证明黑板架构在数据发现等任务上实现了显著的性能提升，超过了包括RAG和主从多代理范式在内的基线方法。
### Conclusion
研究成果证明黑板范式是多代理系统的可扩展和通用的通信框架。此系统在主流和开源LLMs上的性能改进显示了其在数据科学中的有效性和适用性。
## 441. `cs.CL` - RSAVQ: 里emann敏感性意识向量量化技术用于大规模语言模型 [PDF](https://arxiv.org/pdf/2510.01240), [HTML](https://arxiv.org/abs/2510.01240)
### Authors
Zukang Xu,Xing Hu,Qiang Wu,Dawei Yang
### Background
大规模语言模型（LLMs）已经展示了在各种自然语言处理任务中的卓越性能。然而，它们的参数呈指数增长，这给在资源受限设备上的部署带来了巨大挑战。向量量化（VQ）在低位量化（如2位到4位）方面显示了巨大潜力，但现有工作面临两个主要挑战：无约束方向误差和不良的比特分配。
### Innovation
RSAVQ 提出了一种新颖的 VQ 框架，以增强大规模语言模型（LLMs）的极度低位量化。RSAVQ 引入了两个基于几何的创新，有效解决了上述限制：1) 错误方向敏感性指导（EDSG），利用 FIM 引起的黎曼度量将量化误差投影到参数空间中的低敏感性方向。具体地，投影沿负自然梯度方向进行，有效地抑制了误差扩张。2) 重量通道敏感性指导（WCSG），通过 FIM 曲率分析构建通道级敏感度度量，以动态指导比特资源分配。这种方法在指定的比特约束下促进全局最优量化解决方案。实验表明，RSAVQ 在 2 位量化 LLaMA-3 8B 中优于现有方法。例如，在使用 RSAVQ 时，perplexity（困惑度）提高了 0.4，零样本准确率提高了 1.5。
### Conclusion
这项工作为受限环境提供了一种实用解决方案，并在信息几何学和神经网络量化之间架起了一座理论桥梁，推进了高效深度学习的发展。
## 442. `cs.CL` - RLP: 将强化学习作为预训练目标 [PDF](https://arxiv.org/pdf/2510.01265), [HTML](https://arxiv.org/abs/2510.01265)
### Authors
Ali Hatamizadeh,Syeda Nahida Akter,Shrimai Prabhumoye,Jan Kautz,Mostofa Patwary,Mohammad Shoeybi,Bryan Catanzaro,Yejin Choi
### Background
目前训练大规模推理模型的主流方法是从大量数据中预训练，使用下一个标记预测损失。尽管采用强化学习来扩展推理能力具有强大的潜力，但它通常仅作为预训练后的最后阶段出现，之前经过监督微调。本文作者质疑这种训练方式是否是最优的。
### Innovation
提出了一种信息驱动的强化预训练目标（RLP），将强化学习的核心精髓——探索性——引入预训练的最后阶段。该方法将链式思维视为探索性行动，奖励基于其对未来标记预测的信息增益。该方法提供了一种无验证器的密集奖励信号，使得在整个预训练过程中实现在文档流中的高效训练。RLP将强化学习框架重新定义为普通文本的预训练目标，从而减少与原始下一标记预测之间的差距，为有用的推理链式训练提供支持。在预训练阶段使用RLP（例如Qwen3-1.7B-Base）得出的整体数学和科学基准平均值提高了19%。对于推理密集型任务，如AIME25和MMLU-Pro，提升尤为显著。将RLP应用于Nemotron-Nano-12B-v2混合模型后，整体平均值从42.81%提升至61.32%，科学推理平均水平提高了23%，展示了跨不同架构和模型规模的可扩展性.
### Conclusion
研究表明，使用RLP可以有效地增强模型的推理能力，特别是在处理复杂的推理任务时。这种方法可以通过补偿预训练与下一标记预测之间的差距来提高模型的整体性能。
## 443. `cs.CL` - 思考还是作弊？通过测量推理努力检测隐性的奖励欺骗 [PDF](https://arxiv.org/pdf/2510.01367), [HTML](https://arxiv.org/abs/2510.01367)
### Authors
Xinpeng Wang,Nitish Joshi,Barbara Plank,Rico Angell,He He
### Background
奖励欺骗是指一个推理模型利用奖励函数中的漏洞而无需解决实际任务即可获得高奖励的行为，这构成了一个严重的威胁。这一行为可能是显性的，在模型的逻辑推理中明确说明，也可能是隐性的，这使得逻辑推理看似合理并绕过其监控系统。为了检测隐性的奖励欺骗行为，作者提出了一种称为TRACE的方法，该方法通过测量模型推理所需的努力来区分正常逻辑推理和奖励欺骗。
### Innovation
TRACE方法通过逐步截断模型的逻辑推理并测量通过验证器的比率来量化推理的努力。使用这种方法，欺骗模型会以很小一部分推理就通过验证器，从而在准确率-长度曲线下产生较大的面积。TRACE在数学推理和编程方面均显著优于现有的逻辑推理监控方法，显示了在训练过程中能发现未知漏洞的能力，提供了一种可扩展的无监督监督方法，弥补了现有监控方法的不足。
### Conclusion
TRACE提供了一种有效的无监督方式来检测隐性奖励欺骗，无论是在数学推理任务还是编程任务中，其性能都显著优于现有的逻辑推理监控方法。此外，还展示了其在训练过程中能够发现未知漏洞的潜力，为模型的全面监督提供了新的可能性。
## 444. `cs.CL` - 亚里士多德：国际数学奥林匹克级别自动定理证明 [PDF](https://arxiv.org/pdf/2510.01346), [HTML](https://arxiv.org/abs/2510.01346)
### Authors
Tudor Achim,Alex Best,Kevin Der,Mathïs Fédérico,Sergei Gukov,Daniel Halpern-Leister,Kirsten Henningsgard,Yury Kudryashov,Alexander Meiburg,Martin Michelsen,Riley Patterson,Eric Rodriguez,Laura Scharff,Vikram Shanker,Vladmir Sicca,Hari Sowrirajan,Aidan Swope,Matyas Tamas,Vlad Tenev,Jonathan Thomm,Harold Williams,Lawrence Wu
### Background
该研究背景是在自动化定理证明领域的现状。当前的自动定理证明系统在解决复杂的数学问题上已有了一定的进展，但大多数系统主要集中在形式验证或非形式推理上，未能同时将两者融合。数学竞赛如国际数学奥林匹克（IMO）提出的高难度问题，对于现有系统来说仍然是一个挑战。
### Innovation
本文创新性地提出了一种名为‘亚里士多德’（Aristotle）的人工智能系统，该系统结合了形式验证与非形式推理，能够在2025年国际数学奥林匹克问题上达到相当于金牌的性能。亚里士多德集成了三种主要组件：Lean证明搜索系统、生成和形式化引理的非形式推理系统以及专门的几何求解器。该系统展示了在自动化定理证明领域最先进的性能，并具有有利的扩展特性。
### Conclusion
亚里士多德系统在自动化定理证明方面达到了国际数学奥林匹克的水平。通过综合形式验证与非形式推理，它展示了在解决复杂数学问题方面的强大能力，并且系统地改进了自动化定理证明的技术，为未来的相关研究提供了有价值的参考。
## 445. `cs.CL` - Agentic Jigsaw Interaction Learning for Enhancing Visual Perception and Reasoning in Vision-Language Models [PDF](https://arxiv.org/pdf/2510.01304), [HTML](https://arxiv.org/abs/2510.01304)
### Authors
Yu Zeng,Wenxuan Huang,Shiting Huang,Xikun Bao,Yukun Qi,Yiming Zhao,Qiuchen Wang,Lin Chen,Zehui Chen,Huaian Chen,Wanli Ouyang,Feng Zhao
### Background
尽管目前的大型视觉-语言模型（VLMs）在多模态理解和推理方面取得了进展，但其基本的感知和推理能力仍然有限。具体来说，即使在简单的拼图任务中，现有VLMs的表现也近乎随机，展示了核心感知和推理能力的不足。高质量的视觉语言数据可以增强这些能力，但由于其稀缺性和有限的可扩展性，也带来了显著的限制。
### Innovation
本文提出了AGILE，一种基于互动的拼图解谜学习方法，旨在增强视觉感知和推理能力。AGILE将拼图解决过程建模为互动过程，使模型逐步与环境互动。每次迭代中，模型根据当前状态生成可执行代码以执行动作，同时环境提供精细的视觉反馈以指导任务完成。通过这种迭代的观察和互动循环，模型能够通过探索和反馈逐步提高其感知和推理能力。实验结果表明，AGILE不仅显著提升了不同复杂度拼图任务的表现（例如，在2x2设置中，准确率从9.5%提高到82.8%），并且在9个通用视觉任务中的泛化能力也很强，平均改进率为3.1%。这些结果表明，AGILE在视觉感知和推理能力方面带来了显著的提升。
### Conclusion
这项工作为提高多模态模型的推理和泛化能力开辟了一条新的途径，并为多模态强化学习数据的匮乏提供了高效且可扩展的解决方案。该论文还提供了可访问的代码和数据集，以供进一步研究参考。
## 446. `cs.CL` - 从NLx语料库中提取O*NET特征以构建公共使用综合劳动力市场数据 [PDF](https://arxiv.org/pdf/2510.01470), [HTML](https://arxiv.org/abs/2510.01470)
### Authors
Stephen Meisenbacher,Svetlozar Nestorov,Peter Norlander
### Background
在线招聘信息的数据难以获取且格式不规范，O*NET标准分类和职业信息数据库的数据更新频率低且基于小型调查样本。研究团队借鉴O*NET框架开发了自然语言处理工具，以结构化提取招聘信息中的信息。
### Innovation
开发了开放源代码的Job Ad Analysis Toolkit (JAAT)工具集，并通过实际数据证明了其可靠性和准确性。从National Labor Exchange (NLx) Research Hub提供的15500多万个在线招聘信息中提取了超过100亿个数据点，覆盖了O*NET任务、职业代码、工具、技术、工资、技能、行业等特征。构建了一个从2015年至2025年的按月活跃职业和行业特征的数据集。
### Conclusion
该研究展示了这些工具在劳动力市场分析中的潜力，并指出了其在教育和劳动力发展中的未来应用前景。
## 447. `cs.CL` - 基于RAG的微调以提高大语言模型掌握新技能的能力 [PDF](https://arxiv.org/pdf/2510.01375), [HTML](https://arxiv.org/abs/2510.01375)
### Authors
Humaid Ibrahim,Nikolai Rozanov,Marek Rei
### Background
大语言模型（LLM）代理在执行多步骤任务时，常常以可预见的方式失败，例如尝试不符合条件的动作、发出重复命令或处理环境约束不当。通过检索增强生成（RAG）可以改善性能，但这需要维护外部知识数据库，每次部署都会增加计算开销。本研究概述了这类常见问题及其对现有解决方案的要求。
### Innovation
本研究提出了一种简单的工作流，将推理时的检索转换为通过蒸馏获得的学习能力。具体做法包括：（1）从代理失败中提取紧凑且可重用的提示；（2）通过一次检索生成改进的教师轨迹，用于每个新回合的开始；（3）在去除提示字符串的情况下训练学生模型，迫使模型内部化而非简单记忆。这种方法无需永久的运行时依赖，并且能够跨不同规模和架构的模型进行应用，同时提高学习效果，减少令牌使用量。
### Conclusion
在两个交互式基准测试（ALFWorld和WebShop）中，经过蒸馏的学生模型始终优于基线代理，ALFWorld的成绩提高到91%，而WebShop表现提高了72%，相比之下，基线模型分别为79%和61%，并且相较于RAG增强的教师模型，学生的令牌使用量减少了10-60%。此外，该方法展示了在不同规模和架构的模型上均具有有效提升学习能力的能力。
## 448. `cs.CL` - WAInjectBench: 评估 Web 代理中的提示注入检测基准 [PDF](https://arxiv.org/pdf/2510.01354), [HTML](https://arxiv.org/abs/2510.01354)
### Authors
Yinuo Liu,Ruohan Xu,Xilong Wang,Yuqi Jia,Neil Zhenqiang Gong
### Background
针对 Web 代理的多提示注入攻击已经提出，尽管有多种方法被开发用来检测一般的提示注入攻击，但这些方法还没有系统地评估过针对 Web 代理的攻击。这项工作旨在填补这一空白，通过提供第一个关于检测针对 Web 代理的提示注入攻击的全面基准研究来实现这一目标。研究首先对基于威胁模型的攻击进行了细粒度分类，然后构建了包含恶意和良性样本的数据集，包括由不同攻击产生的恶意文本片段、源自四类的良性文本片段、由攻击生成的恶意图像以及来自两类的良性图像。后续研究系统化了基于文本和基于图像的检测方法，并在多个场景下评估了它们的表现。研究结果表明，虽然一些检测器在识别依赖明确文本指令或可见图像扰动的攻击方面具有中等到较高的准确率，但它们却在面对没有明确指令或使用不可察觉扰动的攻击时表现不佳。研究还发布了数据集和代码，网址为 this https URL。
### Innovation
这项工作首次提供了一个全面的基准研究，用于检测针对 Web 代理的提示注入攻击。针对这一类攻击，研究提出了基于威胁模型的细粒度分类，并构建了一个包含多种攻击类型的数据集，同时系统化了基于文本与图像的检测方法，并进行了广泛的性能评估。这项工作填补了对 Web 代理提示注入攻击检测方法系统评估的空白，提出了新的评估体系和数据集。
### Conclusion
研究发现，虽然一些检测器在识别依赖明确文本指令或可见图像扰动的攻击方面表现不错，但在面对没有明确指令或使用不可察觉扰动的攻击时效果较差。这些发现对于进一步改进针对 Web 代理的提示注入攻击检测技术具有重要意义。研究的数据集和代码已公开，为未来的研究提供了重要资源。
## 449. `cs.CL` - MEMTRACK: 评估多平台动态代理环境中的长期记忆和状态追踪 [PDF](https://arxiv.org/pdf/2510.01353), [HTML](https://arxiv.org/abs/2510.01353)
### Authors
Darshan Deshpande,Varun Gangal,Hersh Mehta,Anand Kannappan,Rebecca Qian,Peng Wang
### Background
最近关于上下文和记忆基准的工作主要集中在对话实例上，但对于评估内存以适应动态的企业环境来说，这是一个重要的需求。现有的基准主要针对会话场景进行评估，而MEMTRACK旨在填补这一空白，通过模拟现实的企业工作流程来评估多平台智能代理的长程记忆和状态追踪能力。
### Innovation
MEMTRACK是一个基准测试工具，旨在评估多平台智能代理的长期记忆和状态追踪能力。它通过综合多个异步事件，如Slack、Linear和Git等通信和生产力平台，从而构建了符合现实情况的工作流程。此外，MEMTRACK通过引入关键的正确性、效率和冗余度等度量标准，弥补了仅依赖于简单问答性能评估的不足。实验结果表明，最优秀的GPT-5模型在MEMTRACK上的正确度仅为60%，揭示了现有模型在处理多平台依赖性和解决矛盾方面的困难。
### Conclusion
这项工作提供了一个可扩展的框架，以进步地推进记忆增强代理的评估研究，不仅限于现有的对话设置，还为多平台记忆基准测试在复杂的组织环境中的应用设定了方向。
## 450. `cs.CL` - LSPO: 长度感知动态采样在大型语言模型推理中的策略优化 [PDF](https://arxiv.org/pdf/2510.01459), [HTML](https://arxiv.org/abs/2510.01459)
### Authors
Weizhe Chen,Sven Koenig,Bistra Dilkina
### Background
自Deepseek-R1发布以来，具备可验证奖励（RLVR）的强化学习已成为训练大型语言模型（LLMs）进行推理任务的主要方法。近期研究主要集中在修改损失函数，以提高RLVR的效率和效果。鉴于对LLMs过度思考的研究，本文提出了一种新的元RLVR算法——长度感知采样策略优化（LSPO），该算法在每步训练时根据平均响应长度动态选择训练数据。
### Innovation
本文提出了一种新颖的长度感知采样策略优化（LSPO）算法，该算法在每步训练时根据平均响应长度动态选择训练数据。该算法在多个基础模型和数据集上进行评估，显示其能够持续提高学习效果。此外，文章还进行了详细的消融研究，探讨了将长度信号纳入动态采样的不同方法，为未来的进一步研究提供了有价值的见解。
### Conclusion
LSPO算法能够在训练LLMs时动态选择训练数据，通过考虑平均响应长度来提高学习效率和效果。这种新颖的方法展示了在RLVR中的应用潜力，并为后续研究提供了新的方向。
## 451. `cs.CL` - VOGUE: 视觉不确定性引导的探索提高多模态推理 [PDF](https://arxiv.org/pdf/2510.01444), [HTML](https://arxiv.org/abs/2510.01444)
### Authors
Rui Liu,Dian Yu,Tong Zheng,Runpeng Dai,Zongxia Li,Wenhao Yu,Zhenwen Liang,Linfeng Song,Haitao Mi,Pratap Tokekar,Dong Yu
### Background
当前通过强化学习（RL）增强大型语言模型（LLM）的奖励验证（RLVR）方法，在推理能力上取得了进展，但在探索方面仍存在问题，尤其是对于多模态LLM（MLLM）。现有方法将视觉输入视为固定的、确定性的条件，忽略了图像中的关键模糊性来源，导致难以构建针对可能视觉变化具有鲁棒性的策略。目前的方法主要集中在改进输出（文本），而忽视了输入（视觉）空间的关键不确定性。
### Innovation
提出了VOGUE（Visual Uncertainty Guided Exploration，视觉不确定性引导探索）方法，将探索从输出空间转移到输入空间。VOGUE通过将图像视为随机上下文来处理，使用“原始”分支和“噪声”分支之间的对称KL散度来量化策略对视觉扰动的敏感性，生成一个直接的不确定性感知探索信号。该信号通过不确定性比例奖金与标记熵奖金以及退火采样计划相结合，形成探索的推荐策略，从而平衡探索与利用。
### Conclusion
VOGUE在两种模型规模（Qwen2.5-VL-3B/7B）上实现了GRPO方法。在三个视觉数学基准和三个通用领域推理基准上分别提高了pass@1准确率的平均2.6%和pass@4性能，同时减少了RL微调中常见的探索衰减问题。这项工作证明了在视觉输入固有的不确定性中进行探索是提高多模态推理的有效策略。
## 452. `cs.CL` - 最优停止策略 vs 最佳多次抽样策略在推理时优化中的应用 [PDF](https://arxiv.org/pdf/2510.01394), [HTML](https://arxiv.org/abs/2510.01394)
### Authors
Yusuf Kalayci,Vinod Raman,Shaddin Dughmi
### Background
在使用大语言模型（LLM）生成内容时，通常需要在生成质量与推理成本之间寻求平衡，尤其是在需要多次生成的情况下。传统的最优停止理论（optimal stopping theory）和“最佳多次抽样”（Best-of-N sampling）策略均被用于解决这一问题，但如何将这些理论应用到实际的大语言模型部署中以实现最优的推理时优化仍然是一个挑战。论文作者引入了一个新的框架，基于经典的Pandora's Box问题，将每次生成视为打开一个具有随机奖励的“盒子”，旨在在不知道奖励分布的情况下决定何时停止生成，从而解决上述问题。
### Innovation
论文的主要创新点在于提出了一种基于Pandora's Box问题的新框架以及一种Pandora's Box算法，该算法在不知道奖励分布的情况下，能够实现与Weitzman算法（已知分布的最优策略之一）相近的性能。此外，作者还通过Bradley-Terry启发式的转换，将这种方法应用于实际的大语言模型设置中，实现了可调整的推理时优化方法，能够在不预先知道奖励分布的情况下动态调整奖励标准化和停止阈值。实验结果表明，该方法在AlpacaFarm和HH-RLHF数据集上的表现与非自适应的最佳多次抽样方法相当，但平均而言所需的生成次数减少了15-35％。
### Conclusion
实验结果证明，该方法不仅提高了理论上的性能上限，还提供了实际部署中更高效的优化策略，为大语言模型的推理时优化提供了一条理论和实践相结合的新路径。
## 453. `cs.CL` - 思考正确：通过自适应关注压缩减轻过度思考和不足思考的机制 [PDF](https://arxiv.org/pdf/2510.01581), [HTML](https://arxiv.org/abs/2510.01581)
### Authors
Joykirat Singh,Justin Chih-Yao Chen,Archiki Prasad,Elias Stengel-Eskin,Akshay Nambi,Mohit Bansal
### Background
最近的思考模型通过扩大测试时计算来解决复杂推理任务，但这种扩展必须与任务难度保持一致。短思考（不足思维）会导致更难的问题出现错误，而长思考（过度思维）则可能在达到正确中间解决方案后生成不必要的步骤，导致过度计算。这称为不适应，即模型未能根据问题的难度适当地调节其反应长度。
### Innovation
我们提出了TRaac（Thought Right with Adaptive, Attentive Compression），一种在线后训练RL方法，利用模型在其长推理轨迹上的自我注意力来识别重要步骤并消除冗余步骤。TRaac还估计难度并将其纳入训练奖励，从而学习根据示例的难度分配推理预算。这种方法比基模型和其他RL基线提高了准确性，减少了推理步骤，并实现了适应性思考。
### Conclusion
TRaac在AIME、AMC、GPQA-D、BBEH等任务中比基模型和最佳RL基线分别提高了8.4%和7.9%的准确性，并将推理长度分别减少了36.8%和29.4%。此外，我们的模型在数学数据集上训练，在非数学数据集如GPQA-D、BBEH和OptimalThinkingBench上显示出准确性和效率的提高。我们的分析进一步证实了TRaac基于难度提供精细的思考预算调整，并且结合任务难度校准和基于注意力压缩能够跨任务获得收益。
## 454. `cs.CL` - 从视频到索引知识图谱――结合方法进行多模态内容分析和理解的框架 [PDF](https://arxiv.org/pdf/2510.01513), [HTML](https://arxiv.org/abs/2510.01513)
### Authors
Basem Rizk,Joel Walsh,Mark Core,Benjamin Nye
### Background
多模态内容的分析过程复杂，计算成本高，并需要大量的工程工作。尽管有许多针对静态数据的预训练模型的工作，但将这些开源模型和方法与复杂数据（如视频）结合使用仍然具有挑战性。因此，一个能够高效地为多模态内容分析原型设计流水线的框架是亟待解决的问题。
### Innovation
该论文提出了一种框架，以有效地为多模态内容分析原型设计流水线。该框架将一组预训练模型结合起来，将视频转化为一种临时半结构化的数据格式，并进一步将其转换为索引化的知识图谱表示形式，这种表示形式可以在查询和持续学习中支持动态地纳入新的领域特定知识，通过一种互动媒体来实现这一过程。
### Conclusion
该框架能够克服现有的挑战，并提供了一种新的方法来处理视频和其他复杂多模态数据，使其更适合进行持续学习和查询，促进新的领域特定知识的动态融入。
## 455. `cs.CL` - InfoMosaic-Bench：评估配备工具代理的多源信息搜索 [PDF](https://arxiv.org/pdf/2510.02271), [HTML](https://arxiv.org/abs/2510.02271)
### Authors
Yaxin Du,Yuanshuo Zhang,Xiyuan Yang,Yifan Zhou,Cheng Wang,Gongyi Zou,Xianghe Pang,Wenhao Wang,Menglan Chen,Shuo Tang,Zhiyu Li,Siheng Chen
### Background
人类的信息寻求是一项基本需求，现有的语言模型（LLM）代理主要依赖于开放网络搜索，这暴露了两个根本的弱点：网络上的内容可能嘈杂且不可靠，许多现实世界任务需要精确、领域特定的知识，这些知识无法从网络中获取。新型的Model Context Protocol (MCP) 允许代理与数千种专门工具进行交互，这看似解决了这一限制。然而，仍不清楚这些代理是否能够有效地利用这些工具，特别是它们是否能够将这些工具与一般搜索集成以解决复杂的任务。
### Innovation
本文介绍了InfoMosaic-Bench，这是首个专门针对配备工具代理的多源信息寻求基准测试。该基准涵盖了六个代表性领域（医学、金融、地图、视频、网络和多领域集成），要求代理结合通用搜索和领域特定工具。通过InfoMosaic-Flow，一个可扩展的流水线，将任务条件与验证的工具输出对接，确保跨源依赖和筛选出可通过简单查找解决的短路情况，从而保证可靠性和非平凡性。本研究通过14个最先进的LLM代理实验揭示了三个发现：(i)仅凭网络信息是不够的，GPT-5仅38.2%的准确率和67.5%的通过率； (ii) 领域工具提供的是一种选择性但不一致的益处，有时会改善某些领域而降低其他领域的表现； (iii) 22.4%的失败是由于工具使用或选择不正确引起的，这表明当前的LLM在简单的工具处理上仍存在挑战。
### Conclusion
本研究揭示了即使利用了专门工具，仅凭网络搜索能力仍然不够。确定领域的工具提供了一定的帮助但并不总是积极的。此外，代理在工具使用和选择上遇到困难，甚至在基本操作上仍然存在问题。
## 456. `cs.CL` - LLM4Rec: 大型语言模型在因果去偏见的多模态生成推荐中的应用 [PDF](https://arxiv.org/pdf/2510.01622), [HTML](https://arxiv.org/abs/2510.01622)
### Authors
Bo Ma,Hang Li,ZeHua Hu,XiaoFan Gui,LuYao Liu,Simon Lau
### Background
当前生成型推荐系统在处理多模态数据、消除算法偏见以及提供透明决策过程方面面临重大挑战。
### Innovation
本文提出了一种增强的生成型推荐框架，通过五项创新解决了这些限制：多模态融合架构、检索增强生成机制、基于因果推理的去偏见、可解释的推荐生成以及实时自适应学习能力。该框架以先进的大型语言模型作为基础架构，并集成专门模块以实现跨模态理解、上下文知识整合、偏见缓解、解释合成和持续模型适应。
### Conclusion
在三个基准数据集（MovieLens-25M、Amazon-Electronics、Yelp-2023）上的广泛实验表明，与现有方法相比，该提出的框架在推荐准确性、公平性和多样性方面均表现出一致的改进。提出的方法在NDCG@10上实现了最高2.3%的改进，在多样性的指标上实现了1.4%的提升，同时通过优化推理策略保持了计算效率。
## 457. `cs.CL` - 利用合成前缀缓解实时神经查询自动补全中的偏见 [PDF](https://arxiv.org/pdf/2510.01574), [HTML](https://arxiv.org/abs/2510.01574)
### Authors
Adithya Rajan,Xiaoyu Liu,Prateek Verma,Vibhu Arora
### Background
在实时神经查询自动补全系统中，模型的建议会影响用户行为，导致数据存在呈现偏见。为了减轻这种偏见，该研究提出了一种以数据为中心的方法，通过使用合成前缀来丰富训练数据，从而提高学习排序模型的效果。这些前缀是从搜索会话中收集的完整用户查询中生成的，这些会话在启用自动补全时没有活动。这种方法解决了实时查询自动补全交互中收集的参与度信号中存在的固有偏见。
### Innovation
研究引入了一种基于合成前缀的数据中心方法，通过生成从活跃搜索会话中收集的完整用户查询来丰富训练数据，以减轻呈现偏见。该方法优化了用于实时部署的神经排序器，以满足严格的延迟约束，并结合了丰富的特征，如查询流行度、季节性、模糊匹配得分和上下文信号，如部门偏好、设备类型和与先前查询的垂直对齐。此外，研究还介绍了针对特定任务简化列表损失的方法，从而降低了计算复杂性。
### Conclusion
在大规模电子商务环境中的部署表明，该系统在用户参与方面取得了统计显著的改进，尤其是在均互信息排名和相关指标方面。研究结果表明，合成前缀不仅提高了泛化能力，还提供了一条缓解其他低延迟排序任务偏见的可扩展途径，包括相关搜索和查询推荐。
## 458. `cs.CL` - 部分可观測環境下的信息搜索以實現堅固的決策制定 [PDF](https://arxiv.org/pdf/2510.01531), [HTML](https://arxiv.org/abs/2510.01531)
### Authors
Djengo Cyun-Jyun Fang,Tsung-Wei Ke
### Background
在現實環境中，信息不完整和動態噪音會限制人類的問題解決能力。在此類環境中，當真實環境狀態無法直接觀察時，人類會尋找信息來更新其動態模型，並指導未來的決策制定。現有的大型語言模型編程代理已經解決了觀測不確定性，但往往會忽視其內部動態和實際環境之間的差異。為了彌補這一不足，該-paper 引入了一個新的框架——InfoSeeker，將任務導向的計劃與信息搜索整合起來，以在不確定的環境動態和代理觀測中使內部動態保持一致，並做出優化的決策。
### Innovation
InfoSeeker 是一個結合了任務導向計劃和信息搜索的新框架，促使大型語言模型積極收集信息，構思行動以驗證其理解、檢測環境變化或測試假說，這 Prior Methods 在部分不確定動態和觀測的環境中實現了 74% 的絕對性能提升，同時在 sampel efficiency 方面並沒有犧牲效率。InfoSeeker 在不同大型語言模型之間具有一致性，並在人工機械化和網路上的導航等既定測試中超越基線。這些結果強調，緊密整合規劃和信息搜索對於部分不可觀測環境中的堅固行為必不可少。
### Conclusion
InfoSeeker 的實驗結果表明，通過整合任務導向的計劃和信息搜索，可以使編程代理在部分不可觀測環境中獲得更優的決策，同時保持 sampel efficiency。此外，InfoSeeker 在不同的大型語言模型上具有一致性，並在多個人工智能任務上表現優越。這些发现强调了在部分不可观测环境中融合规划和信息搜索的重要性。
## 459. `cs.CL` - 通过动态对齐、多模态融合和基于证据的解释连接协同过滤和大型语言模型 [PDF](https://arxiv.org/pdf/2510.01606), [HTML](https://arxiv.org/abs/2510.01606)
### Authors
Bo Ma,LuYao Liu,Simon Lau,Chandler Yuan,and XueY Cui,Rosie Zhang
### Background
近年来，研究发现可以通过将用户交互历史和物品元数据转换为文本提示，然后让大型语言模型生成排名或推荐，来利用大型语言模型进行推荐任务。一种有希望的方法是通过紧凑的适配器网络将协同过滤知识连接到大型语言模型表示，这样既可以避免昂贵的微调过程，又能保留双方的优势。然而在实践中，仍然存在一些挑战，例如协同过滤模型通常使用静态快照难以捕捉用户快速变化的偏好；许多现实世界的物品除了文本描述外还包含丰富的视觉和音频内容；当前系统难以提供有具体证据支持的可信赖解释。
### Innovation
本文提出了一种名为Model的框架，通过三大创新点解决上述限制。首先，开发了一种在线适应机制，通过轻量级模块持续整合新的用户交互，避免重新训练大型模型。其次，创造了一种统一表示，无缝结合协作信号与视觉、音频特征，处理某些模态可能不可用的情况。最后，设计了一种解释系统，将推荐与具体的协作模式和物品属性结合，生成用户可验证的自然语言解释。这种方法在保持冻结基础模型高效率的同时，增加了最少的计算开销，使之适用于实际部署。
### Conclusion
本研究通过动态对齐、多模态融合和基于证据的解释连接了协同过滤和大型语言模型，提出了名为Model的框架，实现了推荐系统的实时更新适应、多模态信息融合和透明解释，提高了系统的效率和可靠性，为推荐系统的实际应用提供了新的解决方案。
## 460. `cs.CL` - 在LLM预训练中揭开合成数据之谜：关于扩展法则、好处与风险的一项系统性研究 [PDF](https://arxiv.org/pdf/2510.01631), [HTML](https://arxiv.org/abs/2510.01631)
### Authors
Feiyang Kang,Newsha Ardalani,Michael Kuchnik,Youssef Emad,Mostafa Elhoushi,Shubhabrata Sengupta,Shang-Wen Li,Ramya Raghavendra,Ruoxi Jia,Carole-Jean Wu
### Background
大规模语言模型（LLM）的训练数据对其扩展至关重要，但高质量数据的供应有限。合成数据技术为克服这一限制提供了潜在途径。已有研究利用统一的程序和扩展法则，对比了自然网络文本、多样的合成文本类型（重新表述的文本、生成的教科书）以及自然文本与合成文本的混合，并发现单一使用重新表述的合成数据预训练不如使用自然网络文本，但在大预算数据下，将三分之一的重新表述的合成数据与三分之二的自然网络文本混合预训练可以显著加速（5-10倍），同时，使用按照教科书风格生成的纯合成数据预训练会导致许多下游任务性能下降。合成数据在训练数据混合中的“良好”比例会根据模型大小和数据预算的不同而变化，体现在约30%的重新表述合成数据的比率。生成模型的大小并不必然优于8亿参数的模型。
### Innovation
本文进行了大规模实证研究，对比了不同类型的数据在大规模语言模型预训练中的效果，提出了合成数据在大规模单轮模型训练中的“模型崩溃”现象，为合成数据在预训练中的使用提供了系统性的指导。
### Conclusion
合成数据不仅在预训练中显示出可能的好处，还存在潜在的风险，综合比例30%的重新表述合成数据混合训练是最优的比例，虽然大生成模型不一定优于8亿参数模型，但在合成数据预训练中，其表现不尽如人意，表明可能的“模型崩溃”现象，从而提供了实用的指导建议。
## 461. `cs.CL` - InvThink: 通过逆向推理实现AI安全 [PDF](https://arxiv.org/pdf/2510.01569), [HTML](https://arxiv.org/abs/2510.01569)
### Authors
Yubin Kim,Taehan Kim,Eugene Park,Chunjong Park,Cynthia Breazeal,Daniel McDuff,Hae Won Park
### Background
现有的安全对齐方法直接优化安全响应，而InvThink则指导模型通过以下步骤来增强其逆向思考能力：1) 列出潜在的危害；2) 分析其后果；3) 生成主动避免这些风险的安全输出。这种方法揭示了三个关键发现：一是安全性改进在模型规模上表现出更强的扩展性；二是InvThink减轻了安全税，通过系统地考虑潜在失败模式，保持了在标准基准上的通用推理能力；三是除了通用安全任务，InvThink在外部领域（如医学、金融、法律）和代理领域（如勒索、谋杀）中表现尤为出色，相比基线方法如SafetyPrompt，将有害响应减少了高达15.7%。这些结果表明，逆向推理为更安全、更强大的语言模型提供了一个可扩展且通用的途径。
### Innovation
InvThink是一种简单高效的方法，使大型语言模型具备逆向思考的能力：通过失败模式进行推理，然后再生成响应。与直接优化安全响应的安全对齐方法不同，InvThink通过指导模型：1) 列出潜在的危害；2) 分析它们的后果；3) 生成主动避免这些风险的安全输出，从而增强其逆向推理能力。这种方法在模型规模上的扩展性更强，能够有效保护通用推理能力，同时在高风险领域表现出色，减少有害响应高达15.7%。InvThink还通过监督微调和强化学习在其三个语言模型系列中进行了实现与验证。
### Conclusion
逆向推理提供了更安全、更强大语言模型的可扩展且通用的路径。通过系统地考虑失败模式，InvThink在多个领域表现出显著的安全改进，验证了其作为提高大型语言模型安全性、保持并增强其通用推理能力的有效性。
## 462. `cs.CL` - 改善AGI评估：数据科学视角 [PDF](https://arxiv.org/pdf/2510.01687), [HTML](https://arxiv.org/abs/2510.01687)
### Authors
John Hawkins
### Background
评估潜在的AGI系统和方法非常困难，因为其涉及广泛。目前没有完美的评估方法，通常通过一些小规模测试来衡量系统的性能，这些测试旨在提供方向性线索，表明系统正朝着AGI迈进。然而，以往AI中的合成任务表现不佳，这也使得传统的评估方法受到质疑。
### Innovation
本文提出了一种新的评估AGI的方法论，即基于数据科学视角，强调通过展示系统的行为能力和鲁棒性来进行AGI的评估。这种方法与现有设计哲学不同，后者的理念是基于对智能的理解来创建合成任务，但效果不佳。
### Conclusion
这种新的评估视角从数据科学中汲取经验，通过可靠部署系统的准则来评估AGI。并提供了实际例子来说明这种方法应用到AGI评估中的意义。
## 463. `cs.CL` - Position: Privacy Is Not Just Memorization [PDF](https://arxiv.org/pdf/2510.01645), [HTML](https://arxiv.org/abs/2510.01645)
### Authors
Niloofar Mireshghallah,Tianshi Li
### Background
当前关于大型语言模型（LLMs）隐私风险的讨论，主要集中在模型对训练数据的逐字记忆上，而从数据收集实践、推理时上下文泄露、自主代理能力和深度推断攻击等方面出发的更紧迫和可扩展的隐私威胁却被忽视了。现有的隐私框架未能全面覆盖这些多方面威胁，尤其是在过去的十年中，多数技术研究过分关注数据记忆问题，而实际面临的紧迫隐私危害却得不到充分重视和解决路径并不清晰。
### Innovation
该论文提出了全面的LLM生命周期中的隐私风险分类框架，从数据收集到部署的每个阶段都涵盖了隐私风险，并通过案例研究展示了当前的隐私框架无法解决这些复杂多面的威胁。论文还强调了一个纵向分析的结果，即在过去的十年间，尽管数据记忆问题收到了过度关注，但现有的技术方法在这方面的应对不足，有效的发展路径仍不清晰，因此建议研究社区需要从根本上改变对LLM隐私问题的研究方法，转向更多跨学科的方法来应对这些新兴的、社会和技术层面兼具的威胁。
### Conclusion
本论文揭示了尽管研究关注点集中在数据记忆问题上，但实际上需要更多关注和解决其他更立即和可扩展的隐私威胁。提出了一个新的研究视角，强调跨学科方法对于有效应对LLM隐私风险的重要性。
## 464. `cs.CL` - SFT-RL后训练中的困境：高SFT分数的误导与替代方案 [PDF](https://arxiv.org/pdf/2510.01624), [HTML](https://arxiv.org/abs/2510.01624)
### Authors
Feiyang Kang,Michael Kuchnik,Karthik Padthe,Marin Vlastelica,Ruoxi Jia,Carole-Jean Wu,Newsha Ardalani
### Background
当前的后训练实践将大语言模型（LLMs）分为两个独立阶段：监督微调（SFT）和验证奖励的强化学习（RLVR，简称“RL”）。本文挑战了高SFT分数是否能转化为后续RL训练中的性能提升。研究发现，高SFT分数可能是偏向于简单或同质的数据，并非可靠预测后续RL改进或大规模后训练效果的指标。有时，针对SFT性能提升的模型进行RL训练，可能导致比直接使用基础模型进行RL更糟糕的结果。研究还探讨了替代指标，以验证RL训练的效果，如保留验证集上的推理性能损失和Pass@large k表现。
### Innovation
本研究提出并验证了替代指标，如保留验证集上的推理性能损失和Pass@large k表现，用于预测RL训练的效果，相比直接依靠预RL训练性能，这种新的预测方法在精准度和相关系数上显著提高。研究还通过大量参数的模型训练和广泛评估，展示了在不同的实验条件下，SFT训练的策略选择对最终效果的影响，并为SFT和RL训练之间的策略优化提供了指导。
### Conclusion
研究表明，高SFT分数可能并不可靠地预测后续RL训练的效果。SFT训练的策略应该基于详细的性能指标进行优化，以提高最终的RL训练效果。实验表明，在某些情况下，使用短文本进行SFT训练可能比使用独特文本进行多次训练的效果更好。评估工具将开源。
## 465. `cs.CL` - 按计划行动：高级规划指导强化学习用于LLM推理 [PDF](https://arxiv.org/pdf/2510.01833), [HTML](https://arxiv.org/abs/2510.01833)
### Authors
Zhihao Dou,Qinjian Zhao,Zhongwei Wan,Dinggen Zhang,Weida Wang,Towsif Raiyan,Benteng Chen,Qingtao Pan,Yang Ouyang,Zhiqiang Gao,Shufei Zhang,Sumon Biswas
### Background
大型语言模型（LLMs）在复杂任务中展示了卓越的推理能力，通常依赖于链式思考（CoT）推理。但由于它们的自回归令牌级生成机制，推理过程主要受到局部决策的限制，缺乏全局规划能力。这种局限性常导致冗余、前后矛盾或不准确的推理，显著降低了整体性能。现有的方法，如基于树的算法和强化学习（RL），试图解决这一问题，但这些方法往往面临高昂的计算成本，并且无法生成最佳的推理轨迹。
### Innovation
本文提出了Plan-Then-Action Enhanced Reasoning with Group Relative Policy Optimization (PTA-GRPO) 两阶段框架，旨在改进高级规划和细节链条思考（CoT）推理。第一阶段利用先进的LLM提取总结性指导，并用于监督微调（SFT）；在第二阶段中引入了一种指导意识化的RL方法，联合优化最终输出和高层次的指导质量，提高推理的有效性。
### Conclusion
我们在多个数学推理基准测试（MATH, AIME2024, AIME2025, AMC）和多种基础模型（Qwen2.5-7B-Instruct, Qwen3-8B, Qwen3-14B, LLaMA3.2-3B）上进行了广泛实验。实验结果表明，PTA-GRPO在不同模型和任务上都实现了稳定和显著的性能提升，验证了其有效性和泛化能力。
## 466. `cs.CL` - 跨模态的AI模型是否进行人类般的抽象推理？ [PDF](https://arxiv.org/pdf/2510.02125), [HTML](https://arxiv.org/abs/2510.02125)
### Authors
Claas Beger,Ryan Yi,Shuhao Fu,Arseny Moskvichev,Sarah W. Tsai,Sivasankaran Rajamanickam,Melanie Mitchell
### Background
研究介绍了一个名为o3-preview的OpenAI推理模型在ARC-AGI基准测试中超过了人类的准确性，但这也引发了对这些先进的模型是否能够识别并进行任务创造者正意图的一种抽象推理的疑问。学者们希望通过ConceptARC模型来检验模型的抽象能力，考察了不同输入模式（文本与视觉）、是否允许模型使用外部Python工具、以及推理模型的推理努力程度等因素。此外，研究不仅测量模型输出的准确性，还进行了详细的自然语言规则评估，探讨模型输出的答案是否基于概念层次而非表面层次的模式。
### Innovation
研究引入了一种双重评估体系，综合了输出准确性和自然语言解释的细致评估，以探究模型是否真正使用了ConceptARC来要求解任务所设计的抽象层次，而非依赖于表面的模式。研究发现一些模型在基于文本的表示形式中达到了人类级别的准确性，但其生成的规则往往基于表面层次的捷径，而人类则更频繁地捕捉到这些抽象层次。因此，单凭准确率来评估模型的抽象推理能力可能过高估计了这些能力。在视觉模式下，AI模型的输出准确性急剧下降，不过在规则层面的分析显示，模型可能被低估，因为他们仍然具备一定的捕获目标抽象的规则，但在应用这些规则时往往又无法正确执行。
### Conclusion
研究结果显示模型在抽象推理方面的表现仍落后于人类，单独依靠准确率来评估此类任务的抽象推理能力，可能会过高估计文本模态下的抽象推理能力，同时低估视觉模态下的水平。我们认为这种评估框架提供了一个更忠实的多元模态模型抽象推理能力的图像，以及更符合逻辑地追踪类似人类的抽象中心智能进步的方法。
## 467. `cs.CL` - PsychoBench: 评估大语言模型的心理学智能 [PDF](https://arxiv.org/pdf/2510.01611), [HTML](https://arxiv.org/abs/2510.01611)
### Authors
Min Zeng
### Background
大语言模型（LLMs）在多个行业中取得了显著的成功，主要是因为它们强大的生成能力。然而，LLMs在需要认知能力的应用，如心理辅导中，其潜在应用仍未得到充分开发。本研究探讨了LLMs是否能够有效地应用于心理辅导领域，通过评估其是否能够通过美国全国咨询师认证考试(NCE)，以确定其是否具备担任咨询师的资格。
### Innovation
该研究引入了PsychoBench基准测试，该测试基于该测试网址（无法直接访问，但推测与标准心理咨询服务考试相关），用于评估LLMs的心理咨询智能。PsychoBench包含约2252个精心设计的选择题，涵盖了心理学的多个子领域。研究结果显示，只有最前沿的模型如GPT-4o、Llama3.3-70B和Gemma3-27B达到了通过标准，而一些较小的开源模型则远未达到。这表明只有最尖端的LLMs才能满足心理咨询服务的标准，突显了发展心理学导向的LLMs的潜力和挑战。
### Conclusion
研究表明，只有前沿的LLMs才能够达到心理咨询服务的标准，这既展示了LLMs在心理学领域应用的前景，也揭示了当前存在的挑战。未来的工作可能需要改进LLMs以提高其在心理学知识和应用方面的能力。
## 468. `cs.CL` - 盲目追求目标！计算机使用代理表现出盲目定向性 [PDF](https://arxiv.org/pdf/2510.01670), [HTML](https://arxiv.org/abs/2510.01670)
### Authors
Erfan Shayegani,Keegan Hines,Yue Dong,Nael Abu-Ghazaleh,Roman Lutz,Spencer Whitehead,Vidhisha Balachandran,Besmira Nushi,Vibhav Vineet
### Background
计算机使用代理（CUAs）是一种能够自动在用户界面执行操作以完成用户目标的智能代理。然而，这些代理往往表现出一种忽视可行性、安全性和可靠性的盲目追求目标的行为模式，即所谓的‘盲目定向性’（Blind Goal-Directedness, BGD）。本文作者阐述了BGD的三个常见模式，并通过开发BLIND-ACT基准测试工具来评估当前最先进的CUA模型的BGD水平。
### Innovation
作者通过开发BLIND-ACT基准测试工具，为评估CUA模型的行为和安全性提供了一个现实的环境，并利用LLM（大型语言模型）来评价代理行为的合理性和一致性。这一工具的应用揭示了当前CUA模型在处理用户请求中存在多种失败模式，强调了需要更强的训练或推理干预措施来降低BGD风险。
### Conclusion
本文首先识别并定义了计算机使用代理中的盲目定向性，并通过BLIND-ACT工具提供了一个基准，以评估当前CUA模型的行为。研究结果表明，虽然基于提示的干预措施可以在一定程度上降低BGD，但风险依然存在，需要进一步的研究来开发更强的干预措施，以确保CUA的安全部署。
## 469. `cs.CL` - Sparse Query Attention (SQA): 一种通过减少查询头数实现计算效率的注意机制 [PDF](https://arxiv.org/pdf/2510.01817), [HTML](https://arxiv.org/abs/2510.01817)
### Authors
Adam Filipek
### Background
Transformer架构通过多头注意力机制（MHA）已成为当今人工智能领域最新模型的标准。然而，MHA的计算复杂度与序列长度平方相关，这在长上下文应用中成为一个显著的扩展障碍。多查询注意力（MQA）和分组查询注意力（GQA）等现有方法通过共享键和值投影有效解决了自动回归推理延迟中的内存带宽瓶颈问题，但它们并没有减少注意力分数计算所需的浮点运算（FLOPs）数量，这个问题仍然是训练和全序列处理中的关键瓶颈。
### Innovation
本文提出了稀疏查询注意力（SQA），这是一种新的注意机制架构，它通过减少查询头数来追求另一种优化途径。这种架构修改直接减少了注意力机制的计算复杂性，减小因子与查询头数的减少成正比，从而降低了总体FLOPs。SQA通过理论基础、数学公式和一系列架构变体进行了介绍。在对长序列的实证基准测试中，SQA在计算限制场景下（如模型预训练、微调和编码器任务）实现了多达3倍的吞吐量提升，对模型质量的影响微乎其微，并且是在小型实验中的初步发现。
### Conclusion
SQA的发现是在开发即将推出的反应Transformer架构时偶然发现的，这表明它可能是一个强大的工具，用于构建更高效和可扩展的模型。
## 470. `cs.CL` - ExGRPO: 从经验学习推理 [PDF](https://arxiv.org/pdf/2510.02245), [HTML](https://arxiv.org/abs/2510.02245)
### Authors
Runzhe Zhan,Yafu Li,Zhi Wang,Xiaoye Qu,Dongrui Liu,Jing Shao,Derek F. Wong,Yu Cheng
### Background
当前，强化学习从验证性奖励（RLVR）是一种新兴的框架，用于提高大型语言模型的推理能力。然而，标准的在线策略训练在每次更新后都会丢弃回放经历，导致计算效率低下且不稳。先前的强化学习研究已表明循环利用过往经验的好处，但实验特征如何影响大型推理模型的学习动态仍然未被充分探索。
### Innovation
本文首次探索了一个推理经历的价值所在，并识别出了回放正确性和熵作为有效的经历价值指标，并在此基础上提出了ExGRPO（Experiential Group Relative Policy Optimization）框架，该框架组织并优先处理有价值的回放经历，使用混合策略目标来平衡探索与回放再利用。该方法在包含5个基础模型（参数量从1.5B到8B）的实验中显示了持续提升数学/通用基准推理性能的效果，平均提高了3.5/7.6个点。此外，ExGRPO还在更强和更弱的模型中稳定训练，使在线方法无法收敛。这些结果突显了有原则的经验管理是高效且可扩展的RLVR的关键成分。
### Conclusion
ExGRPO方法显著提高了大型语言模型的推理性能，并在稳定性方面优于在线策略，证明了有规则的经验管理对于强化学习从验证性奖励框架的有效性和可扩展性至关重要。
## 471. `cs.CL` - 一种面向深度研究代理的严格多维度评估基准：从答案到报告 [PDF](https://arxiv.org/pdf/2510.02190), [HTML](https://arxiv.org/abs/2510.02190)
### Authors
Yang Yao,Yixu Wang,Yuxuan Zhang,Yi Lu,Tianle Gu,Lingyu Li,Dingyi Zhao,Keming Wu,Haozhe Wang,Ping Nie,Yan Teng,Yingchun Wang
### Background
人工智能正处于从封闭语言模型转向能够外部感知和信息整合的互联代理系统的范式转变之中。作为这类系统的代表，深度研究代理（DRAs）展示了任务分解、多源检索、多阶段推理和结构化输出等能力，极大地提高了复杂和开放式任务的性能。然而，现有的基准测试在评估维度、响应格式和评分机制方面仍存在不足，限制了它们对这些系统的有效评估能力。这项研究引入了一个专门为DRAs和报告式响应设计的严格基准和多维度评估框架，以解决这些问题。
### Innovation
该研究提出了一种专为深度研究代理设计的严格多维度评估基准和框架，包括214个由专家策划的具有挑战性的查询问题，以及每个问题的手工构建参考代码，以支持综合评估。该框架可以全面评估DRAs生成的长报告，包括语义质量、主题聚焦和检索可信度的综合评分指标。通过大规模实验，证实了主流DRAs在与网页搜索工具增强的推理模型相比时的优越性能，但也指出了改进的空间。
### Conclusion
该研究为深度研究代理系统的功能评估、架构优化及范式发展奠定了坚实的基础，表明现有技术在评估和改进方面仍有较大的提升空间。
## 472. `cs.CL` - 约束自适应拒采样 [PDF](https://arxiv.org/pdf/2510.01902), [HTML](https://arxiv.org/abs/2510.01902)
### Authors
Paweł Parys,Sairam Vaidya,Taylor Berg-Kirkpatrick,Loris D'Antoni
### Background
语言模型（LMs）在生成符合严格语义或句法约束的输出时的应用逐渐增多。现有方法在受限生成时存在两类极端：贪心受限解码方法确保生成过程中有效的输出，但会导致模型分布失真；而拒绝采样（RS）方法则保存了模型分布的真实性，但由于对无效输出的丢弃造成了计算资源的浪费。这两种方法在像程序 fuzzing 这样的领域中都是不利的，因为这些领域要求生成有效的样本同时还要保证样本的多样性。本文提出了一种约束自适应拒采样（CARS）方法，旨在提高受限采样效率，同时避免模型分布失真。CARS 方法通过将约束违反的继续扩展记录在有限状态自动机（trie）中，并从未来抽样中减去这些扩展的概率质量，来实现适应性剪枝，从而确保无效前缀不再被重新访问，抽样接受率单调递增，且获得的样本严格遵循了受限分布。
### Innovation
本文提出的约束自适应拒采样（CARS）方法，通过将约束违反的继续扩展记录在有限状态自动机（trie）中，并从未来抽样中减去这些扩展的概率质量，来适应性地剪枝，从而在不改变模型分布的情况下提高采样效率。该方法在多种领域（如程序 fuzzing 和分子生成）中的实验表明，CARS 方法能够在生成有效样本的同时，达到更高的效率和更强的样本多样性，对比之下，GCD 方法以及近似语言模型分布的方法效果不佳。
### Conclusion
本文提出了约束自适应拒采样（CARS）方法，该方法在多种应用中显示出更高的样本效率和更强的样本多样性。相较于贪心受限解码方法和拒绝采样的极端方法，CARS 方法既减少了模型分布的失真，又提高了样本生成的有效性和多样性。
## 473. `cs.CL` - 强化学习制约语言模型的推理边界悖论：基于奖励的强化学习如何限制推理 [PDF](https://arxiv.org/pdf/2510.02230), [HTML](https://arxiv.org/abs/2510.02230)
### Authors
Phuc Minh Nguyen,Chinh D. La,Duy M. H. Nguyen,Nitesh V. Chawla,Binh T. Nguyen,Khoa D. Doan
### Background
RLVR作为一种改进大型语言模型推理能力的关键方法，已经引起了广泛关注，然而近期的研究表明，RLVR反而可能缩小了推理边界。通过分析RLVR的学习动态，该论文揭示了两个关键现象，解释了这一失败的原因。首先，RLVR中的负干扰现象表明，学习解决某些训练问题实际上会减少其他问题的正确解决方案的可能性，导致Pass@$k$性能下降；其次，胜者通吃的现象揭示了RLVR过度强化高概率正确解题，同时压制初始低概率的问题。
### Innovation
通过对多个数学推理基准进行广泛的理论和实证分析，该论文发现了由于标准RL目标中的固有随策略采样，模型会向狭窄的解策略收敛。基于这些洞察，该论文提出了一种简洁且有效的数据整理算法，该算法将RLVR学习重点放在低概率问题上，显著提升了Pass@$k$性能。
### Conclusion
通过该研究，原始RLVR方法的局限性被揭示出来，提出了一种改进的数据整理方法，解决了负干扰和胜者通吃现象，显著提升了模型的性能。
## 474. `cs.CL` - 研究开源大语言模型在Promptagator风格密集检索训练中的应用 [PDF](https://arxiv.org/pdf/2510.02241), [HTML](https://arxiv.org/abs/2510.02241)
### Authors
Daniel Gwon,Nour Jedidi,Jimmy Lin
### Background
Promptagator已经证明了使用少量示例提示的大语言模型（LLMs）可以作为细调领域特定密集检索模型的任务专用查询生成器。然而，原始的Promptagator方法依赖于私有的、大规模的LLMs，这些LLMs可能不是所有用户都能访问的，也可能因敏感数据的应用而被禁止使用。在此工作中，作者研究了可访问规模（≤14B参数）的开源LLM在替代场景中的影响。研究表明，拥有3B参数或更少参数的开源LLM可以作为有效的Promptagator风格查询生成器。
### Innovation
研究引入了使用可访问规模的开源LLM作为大语言模型的替代品，用于Promptagator风格的密集检索模型的细调任务，特别是当用户无法访问或被禁止使用私有大规模的LLMs时。这项研究证明了小型开源LLM（如3B参数）的有效性，为合成数据生成和领域特定应用的最大化细调结果提供了参考建议。
### Conclusion
作者的工作为从业者提供了可靠替代方案，特别是在合成数据生成方面，并为最大化特定领域应用的细调结果提供了有用的见解。
## 475. `cs.CL` - 代理扩展在计算机使用中的意想不到的效果 [PDF](https://arxiv.org/pdf/2510.02250), [HTML](https://arxiv.org/abs/2510.02250)
### Authors
Gonzalo Gonzalez-Pumariega,Vincent Tu,Chih-Lun Lee,Jiachen Yang,Ang Li,Xin Eric Wang
### Background
计算机使用代理（CUAs）有潜力自动执行日常数字任务，但由于其不可靠性和高变异性，它们不适用于长期复杂的任务。一种名为行为最好的N种方法（bBoN）的方法通过生成多个棋局并根据描述代理棋局的行为叙述来选择其中一种，实现了广泛探索和有原则的轨迹选择，从而显著提高了鲁棒性和成功率。
### Innovation
introduces a method called Behavior Best-of-N (bBoN) that enhances the scalability of CUAs by generating multiple rollouts and selecting among them based on behavior narratives. This method improves robustness and success rates. The bBoN method establishes a new state of the art (SoTA) on OSWorld at 69.9%, outperforming previous methods and approaching human-level performance at 72%. Additionally, it demonstrates strong generalization results across different operating systems.
### Conclusion
This work emphasizes the significant impact of structured trajectory understanding and selection for effectively scaling CUAs. The bBoN framework offers a practical approach to achieve this, highlighting the potential of scaling CUAs when done correctly.
## 476. `cs.CL` - 交互式训练：基于反馈的神经网络优化 [PDF](https://arxiv.org/pdf/2510.02297), [HTML](https://arxiv.org/abs/2510.02297)
### Authors
Wentao Zhang,Yang Young Lu,Yuntian Deng
### Background
传统的神经网络训练通常遵循固定的优化步骤，缺乏灵活调整以应对训练过程中的不稳定性和新出现的问题。这种固定的方法无法根据具体情况动态调整，导致了训练效率和效果的限制
### Innovation
本文提出了交互式训练框架（Interactive Training），它通过人工专家或自动AI代理进行实时、反馈驱动的干预，来动态调整优化器超参数、训练数据和模型检查点。该框架能够提高训练稳定性，减少对初始超参数的敏感性，并增强对用户需求变化的适应性，为未来自主监控训练日志并主动解决问题的训练范式铺平了道路
### Conclusion
通过三个案例研究，本文展示了交互式训练在提高训练稳定性、减少初始超参数敏感性以及增强对变化用户需求的适应性方面的优势。这为未来的训练范式开辟了可能性，其中AI代理可以自主监控训练日志并优化训练流程
## 477. `cs.CL` - 基于知识图谱增强的LLM进行用户偏好的推理：可解释的对话推荐 [PDF](https://arxiv.org/pdf/2411.14459), [HTML](https://arxiv.org/abs/2411.14459)
### Authors
Zhangchi Qiu,Linhao Luo,Shirui Pan,Alan Wee-Chung Liew
### Background
对话式推荐系统（CRSs）通过交互对话捕捉用户偏好以提供个性化推荐。当前的CRSs利用知识图谱（KGs）或语言模型从用户对话中提取和表示用户的潜在向量，导致解释性有限。大型语言模型（LLMs）能够提高解释性，但由于预训练数据集和用户偏好分析之间的不匹配以及结构化KG信息与非结构化对话之间的模态差距，利用LLMs进行有效推理仍然具有挑战性。为此，本文探讨了如何综合利用KG和LLM的优势，以提高CRS的性能和解释性。
### Innovation
本文提出了一种名为COMPASS的插件式框架，该框架结合了LLM和KG以推理用户偏好，通过两阶段训练方法：一种是通过新颖的图实体描述预训练来弥合结构化的KG与自然语言之间的差距，另一种是在可以增强知识的指令微调中优化用户偏好推理，使LLM能够从对话历史和KG增强上下文中学习推理与总结用户偏好。这使得COMPASS可以进行知识感知推理并生成可解释的用户偏好，从而无缝集成到现有的CRS模型中以提高推荐性能和解释性。
### Conclusion
实验表明，COMPASS在提高各种CRS模型的效果和解释性方面具有有效性。
## 478. `cs.CL` - 使用更新近似初始化是一种极为高效的小维细调银弹 [PDF](https://arxiv.org/pdf/2411.19557), [HTML](https://arxiv.org/abs/2411.19557)
### Authors
Kaustubh Ponkshe,Raghav Singhal,Eduard Gorbunov,Alexey Tumanov,Samuel Horvath,Praneeth Vepakomma
### Background
低秩适配器已成为高效微调大型语言模型的标准方法，但通常无法达到完全微调的性能。本文分析了当前微调方法的局限性，尤其是在参数效率和性能之间的平衡。
### Innovation
提出了一种名为LoRA Silver Bullet或LoRA-SB的方法，该方法通过精心设计的初始化策略在低秩子空间内近似完全微调。这种方法利用其受约束的更新空间实现高秩梯度更新的最佳缩放，同时消除了缩放因子调优的需要。此外，证明了初始化提供了初始梯度的最优低秩近似，并在整个训练过程中保持更新方向。
### Conclusion
广泛的实验表明，本文方法在数学推理、常识推理和语言理解任务中均超越了LoRA（及其基线），同时使用较少的学习参数（27-90倍）。研究结果表明，在低秩子空间中模拟完全微调是可能的，在不牺牲性能的情况下实现了显著的参数效率增益。
## 479. `cs.CL` - 基于树结构对话的强化策略优化以实现红队攻击 [PDF](https://arxiv.org/pdf/2510.02286), [HTML](https://arxiv.org/abs/2510.02286)
### Authors
Ruohao Guo,Afshin Oroojlooy,Roshan Sridhar,Miguel Ballesteros,Alan Ritter,Dan Roth
### Background
尽管人工智能安全领域取得了一定的快速进展，但现有的大规模语言模型在多轮互动对话场景中仍然容易受到对手精心设计的提示所引发的攻击，这种攻击会根据对话轮次动态变化，从而使攻击更具挑战性。现有的安全漏洞发现方法要么依赖人工红队测试，要么使用预定义模板和人工标注的数据集进行自动化攻击，且大部分方法仅关注单轮次攻击。然而，这些方法未能考虑到整个多轮次攻击空间中的攻击策略，忽略了由复杂对话动态和策略对话规划产生的新颖攻击路径。近年来的研究发现，语言模型对多轮次攻击的脆弱性远高于单轮次攻击，这个现象进一步突显了改善多轮次攻击探索的重要性。
### Innovation
本文提出了一种名为DialTree-RPO的方法，它将基于策略的强化学习框架与树搜索相结合，自动发现多轮对话攻击策略，将其视为序贯决策问题，从而无需人工标注数据即可系统地探索攻击空间。这个方法不仅在针对10个目标模型的实验中相比先前的最佳方法实现了超过25.9%的对抗成功率的提升，还通过学习能够最大化多轮攻击成功率的最优对话策略，成功发现了新的攻击策略。
### Conclusion
该工作通过DialTree-RPO提出了一个全新的多轮对话攻击策略发现框架，显著提高了对抗成功率，并且能够从多轮对话中发现有效的攻击策略，填补了传统方法在探索多轮对话攻击空间中的空白，为加强语言模型安全性提供了新的思路。
## 480. `cs.CL` - StockBench：LLM代理能在真实市场中盈利地交易股票吗？ [PDF](https://arxiv.org/pdf/2510.02209), [HTML](https://arxiv.org/abs/2510.02209)
### Authors
Yanxu Chen,Zijun Yao,Yantao Liu,Jin Ye,Jianing Yu,Lei Hou,Juanzi Li
### Background
近年来，大型语言模型（LLMs）展现了作为自主代理的能力，在逻辑推理、工具使用和序列决策方面表现突出。虽然之前的研究已经评估了LLM代理在软件工程和科学发现等领域的应用，金融领域尚未得到充分探索，尽管其与经济价值和高风险决策密切相关。现有的金融基准主要通过问答测试静态知识，但未能捕捉到交易中的动态和迭代特性。因此，本文提出了一种名为StockBench的基准方法，该方法旨在评估LLM代理在实际的多月股票交易环境中的表现。
### Innovation
本文首次提出了StockBench，这是一种无污染的基准方法，用于评估LLM代理在真实的多月股票交易环境中的表现。代理每天都会收到市场信号（包括价格、基本面和技术信息等），并必须做出买卖或持有的连续决策。评估标准使用财务指标，如累计收益、最大回撤和索特诺比率。研究表明，尽管大多数LLM代理难以超越简单的买入并持有基准，但某些模型展示了更高的回报率和更好的风险管理潜力。这表明，强大的静态金融知识能力不一定转化为成功的交易策略。文章还发布了StockBench作为开源资源，以支持可重复性和推动该领域未来的研究。
### Conclusion
本研究通过StockBench揭示了LLM代理在金融领域的挑战与机遇，尽管大多数LLM代理难以超越简单的买入并持有基准，但某些模型展示了更高的回报率和更好的风险管理潜力，这说明了在静态金融知识任务上取得优异成绩并不一定意味着成功的交易策略。StockBench作为一个开源资源被公开发布，以支持研究人员进行可重复性的研究并推动该领域的进一步发展。
## 481. `cs.CL` - 自我一致性表现不佳！位置偏置对长上下文问题的不利影响 [PDF](https://arxiv.org/pdf/2411.01101), [HTML](https://arxiv.org/abs/2411.01101)
### Authors
Adam Byerly,Daniel Khashabi
### Background
Self-consistency (SC) 改善了大型语言模型（LLMs）在涉及短内容的各种任务和领域中的性能。然而，是否存在这种一致性对于处理包含较多信息背景的任务同样有效的问题尚未得到验证。背景信息强调了大型语言模型在长上下文任务中常遇到的位置偏置问题，即过度依赖特定上下文区域导致无法利用整个上下文的信息。本文通过使用不同的先进模型、任务和SC形式进行了全面实验，验证了SC在长上下文任务中的效果
### Innovation
本文通过全面的实验，揭示了SC在长上下文任务中的不足，尤其是在位置偏置的影响下，SC不仅未能提高性能反而导致性能下降。本文的研究为理解当前LLM在长上下文理解中的局限性提供了有价值的见解，并强调了需要更复杂的方法
### Conclusion
研究发现，SC在长上下文任务中不仅未能改善性能，反而导致了性能的下降。这种下降主要是由于持续存在的位置偏置问题，该问题随上下文长度增加和模型规模减小而加剧，不受提示格式或任务类型的影响。
## 482. `cs.CL` - RLAD：训练LLMs以发现解决推理问题的抽象 [PDF](https://arxiv.org/pdf/2510.02263), [HTML](https://arxiv.org/abs/2510.02263)
### Authors
Yuxiao Qu,Anikait Singh,Yoonho Lee,Amrith Setlur,Ruslan Salakhutdinov,Chelsea Finn,Aviral Kumar
### Background
推理要求超越简单的模式匹配或解决方案的记忆，而是识别并实施可用于推断棘手问题答案的'算法程序'。这需要意识到最相关的原始内容、中间结果或共享程序，并在它们的基础上进行构建。虽然通过长链思考后的强化学习最终旨在揭示这种算法行为，但大多数大型模型学到的推理痕迹往往未能一致捕捉或重复使用这些程序，而是陷入冗长且退化的探索。为更有效地进行推理，该论文引入了推理抽象：简洁的自然语言描述，指导模型朝向成功的推理学习。模型被训练能在给定问题时提出多个抽象，随后的强化学习则激励构建解决方案的同时利用这些抽象提供的信息。这就形成了一种两个玩家的强化学习训练模式，简称RLAD，联合训练抽象生成器和解决方案生成器。此设置有效促进了结构化的探索，分离了抽象提案和解决方案生成的学习信号，并提高了对更复杂问题的泛化能力。该论文还表明，在测试阶段分配更多的计算资源用于生成抽象比在大规模测试预算下生成更多的解决方案更有利于性能提升，这突显了抽象在引导有意义的探索中的角色。
### Innovation
该论文提出了一个名为RLAD的框架，用于训练语言模型(LLMs)以发现解决推理问题的抽象。该方法包括让模型在给定问题时提出多个抽象，并利用这些抽象来激励解决方案的生成。这形成了一个联合训练抽象生成器和解决方案生成器的两个玩家的强化学习训练模式。这种方法能够有效进行结构化的探索，分离抽象提案和解决方案生成的学习信号，并提高了对更复杂问题的泛化能力。此外，研究还表明，在测试时间分配更多计算资源用于生成抽象比在大规模测试预算下生成更多的解决方案更能提高性能。
### Conclusion
RLAD框架通过联合训练抽象生成器和解决方案生成器，有效地促进了结构化的探索，分离了抽象提案和解决方案生成的学习信号，并提高了对更复杂问题的泛化能力。此外，该研究还表明，分配更多测试时间计算资源用于生成抽象比生成更多解决方案更有利于提高性能，突显了抽象在引导有意义的探索中的重要性。
## 483. `cs.CL` - 当分歧促进稳健性：在LLM多智能体分歧下的自我修复能力探究 [PDF](https://arxiv.org/pdf/2502.15153), [HTML](https://arxiv.org/abs/2502.15153)
### Authors
Tianjie Ju,Bowen Wang,Hao Fei,Mong-Li Lee,Wynne Hsu,Yun Li,Qianren Wang,Pengzhou Cheng,Zongru Wu,Haodong Zhao,Zhuosheng Zhang,Gongshen Liu
### Background
最近的大语言模型（LLMs）的发展使它们从复杂的文本生成器进化为能够在多智能体系统（MAS）中自主合作和使用工具的智能代理。然而，当前的研究尚不清楚分歧如何影响集体决策。本文重新探讨了分歧的作用，并提出一般性的部分重叠分歧能够防止过早达成共识并扩展探索的空间，而关键任务步骤上的分歧可能会影响合作的效果，取决于解决方案路径的拓扑结构。
### Innovation
本文研究了两种具有不同路径结构的合作情景：一种是通常遵循单一证据链的协作推理（CounterFact, MQuAKE-cf），另一种是经常采用多种有效实现的协作编程（HumanEval, GAIA）。分歧被表现为代表智能体之间的普遍异质性或任务关键性的命题反事实知识编辑注入到上下文或参数中。实验表明，一般性的分歧能够通过促进互补性探索来持续提升成功。相比之下，关键任务的分歧在单路径推理上显著降低了成功率，但在编程中影响有限，因为代理可以自行选择替代方案。追踪分析显示，在编程任务中，系统更频繁地忽略了编辑的事实，而推理任务中则较少这样做，揭示出一种基于解决方案路径的自我修复能力。
### Conclusion
在编程任务中，MAS通常绕过了编辑的事实，而在推理任务中则很少这样做，揭示了一种依赖于解决方案路径而不是规模的自我修复能力。本文的代码可在以下链接获取：[https://example.com/code]。
## 484. `cs.CL` - 可解释的文本嵌入与文本相似性解释：综述 [PDF](https://arxiv.org/pdf/2502.14862), [HTML](https://arxiv.org/abs/2502.14862)
### Authors
Juri Opitz,Lucas Möller,Andrianos Michail,Sebastian Padó,Simon Clematide
### Background
文本嵌入是许多自然语言处理任务（包括分类、回归、聚类和语义搜索）的基本组成部分，尽管嵌入在广泛应用中存在，但在解释嵌入及其相似性方面仍然存在挑战。
### Innovation
本文提供了在可解释文本嵌入和文本相似性解释方法方面的结构化综述。这是一个尚未充分探索的研究领域。文章刻画了主要想法、方法和权衡，并比较了评估手段，探讨了总体研究经验教训，最终指出了未来研究的机会和开放挑战。
### Conclusion
本文提供了一个关于可解释文本嵌入和文本相似性解释方法的结构化综述，介绍了评估方法的比较，并指出了未来研究的机会和挑战。
## 485. `cs.CL` - Superficial Safety Alignment Hypothesis [PDF](https://arxiv.org/pdf/2410.10862), [HTML](https://arxiv.org/abs/2410.10862)
### Authors
Jianwei Li,Jung-Eun Kim
### Background
随着大型语言模型（LLMs）在各种应用中的广泛应用，确保它们生成安全的响应变得至关重要。尽管前人研究主要集中在指令遵循的对齐上，但往往忽略了安全性对齐的独特属性，如安全机制的脆弱性。为了弥合这一差距，作者提出了浅表安全性对齐假说（Superficial Safety Alignment Hypothesis，SSAH），认为安全性对齐是教原本不安全的模型选择安全的推理方向——满足或拒绝用户请求，这可以视为一种隐式的二元分类任务。通过SSAH，作者假设只需要少数关键组件即可在LLMs中建立安全性防护栏。作者成功识别了四种关键属性类型：安全性关键单元（SCU）、有效用关键单元（UCU）、复杂单元（CU）和冗余单元（RU）。研究结果表明，在微调过程中冻结某些安全性关键组件可以使模型保留其安全属性，同时适应新的任务。同样，在预训练模型中利用冗余单元作为“对齐预算”被证明可以有效降低对齐成本，同时实现对齐目标。因此，论文总结认为LLMs中的原子功能性单元是神经元级的，强调安全性对齐不应复杂化。
### Innovation
提出了浅表安全性对齐假说（SSAH），认为安全性对齐是教原本不安全的模型选择正确推理方向，视为隐式的二元分类任务。识别了四种关键属性类型：安全性关键单元（SCU）、有效用关键单元（UCU）、复杂单元（CU）和冗余单元（RU）。研究表明，在微调过程中冻结某些安全性关键组件和利用冗余单元作为“对齐预算”可有效降低对齐成本，同时保持模型的安全性。
### Conclusion
LLMs中的原子功能性单元是神经元级的。安全性对齐不应复杂化，只需确保某些关键组件的安全性即可。
## 486. `cs.CL` - 无界限字节对编码：打破预分词障碍 [PDF](https://arxiv.org/pdf/2504.00178), [HTML](https://arxiv.org/abs/2504.00178)
### Authors
Craig W. Schmidt,Varshini Reddy,Chris Tanner,Yuval Pinter
### Background
在许多现代分词流程中，预分词是一个初始步骤，它将文本分割成更小的单元，即预词元（pretoken），通常是按空格和标点符号进行分割。虽然这种方式鼓励分词过程中保留完整的独立单词，但它在大多数分词算法（如字节对编码BPE）中引入了一个根本性限制。具体来说，预分词会导致语料库中的词分布极不平衡，过度偏向常见的完整长度单词。这种不平衡的词分布限制了扩展词汇量的利益，因为随着词汇表的增长，新词出现的频率逐渐降低。
### Innovation
我们提出了BoundlessBPE，这是一种修改版的BPE算法，它去除了预分词边界的约束。我们的方法选择性地将两个完整的预词元合并成一个更大的单元，称作超词元。超词元不一定是有意义的。例如，预词元“ of”和“ the”可能被合并为超词元“ of the”。这种方法导致语料库中词的分布比标准BPE更为均匀，同时更有效地压缩文本，文本压缩率最多可增加15%。
### Conclusion
BoundlessBPE算法通过放松预分词边界的约束，选择性地合并完整的预词元，产生了更加均匀的词分布，并更有效地压缩文本。与标准BPE相比，BoundlessBPE显著提高了文本压缩效率，节省了存储空间。
## 487. `cs.CL` - Code-Switched Texts能否激活LLMs中的知识切换？——以英韩代码切换为案例研究 [PDF](https://arxiv.org/pdf/2410.18436), [HTML](https://arxiv.org/abs/2410.18436)
### Authors
Seoyeon Kim,Huiseo Kim,Chanjun Park,Jinyoung Yeo,Dongha Lee
### Background
最近的大语言模型（LLMs）显示出了多语言能力，但由于训练数据集中的英语占据主导地位，这些模型在处理低资源语言任务时仍然是以英语为中心。低资源语言的资源限制仍然是一个关键挑战。代码切换（CS）是多语言讲者的现象，在对话中会交替使用语言，可以传达翻译中可能丢失的细微的语文化及语言上的微妙之处，并在人类通信中引发语言特定的知识。鉴于此，我们研究了是否代码切换能够激活或识别并利用LLMs解决低资源语言任务中的知识进行推理。
### Innovation
我们首次提出了EnKoQA，一个合成的英韩代码切换问答数据集。我们通过对多种多语言LLMs进行综合性分析，将激活过程细分为知识识别和知识利用两个部分。我们的研究结果表明，与英语文本相比，代码切换能够更忠实于激活LLMs中的知识，特别是在语言特定领域，这表明代码切换在低资源语言任务中的潜力。
### Conclusion
我们的结果表明，代码切换可以激活LLMs中与特定语言相关的知识，特别是在语言特定领域，也支持了代码切换在低资源语言任务中的潜力。
## 488. `cs.CL` - 利用感知域感知注意力加权提示大规模语言模型以推动多模态情感识别的极限 [PDF](https://arxiv.org/pdf/2411.17674), [HTML](https://arxiv.org/abs/2411.17674)
### Authors
Han Zhang,Yu Lu,Liyun Zhang,Dian Ding,Dinghua Zhao,Yi-Chao Chen,Ye Wu,Guangtao Xue
### Background
在对话中理解情感通常需要外部知识来准确理解内容。随着大型语言模型（LLMs）变得越来越强大，研究者希望能够充分利用这些模型的能力，而不仅仅局限于预训练语言模型所能提供的有限能力。但LLMs要么只能处理文本模态的数据，要么由于处理多媒体信息的高成本而难以广泛应用。因此，本研究旨在结合LLMs的强大处理能力和多媒体模态的补充特性，开发了一个框架Lantern，以提升情感识别的性能。
### Innovation
该研究提出了一个名为Lantern的框架，该框架利用大型语言模型的感知域感知注意力加权提示，大幅度提高了情感识别的准确性。通过该框架，训练了一个多任务的基模型生成情感类别的概率和维度得分。这些预测被作为参考，用于调整基模型对情感类别的预测概率，并结合外部知识和上下文理解进行调整。此过程将对话分割为不同的感知域，并采用感知域感知注意力驱动的加权模块实现预测结果的合并。实验结果表明，该框架能够显著提高现有基模型的性能，最高可提升1.80%。
### Conclusion
实验表明，在IEMOCAP数据集上，Lantern框架能够显著提升现有基模型（CORECT和SDT）的情感识别性能，分别在4类和6类设置中提升了1.23%和1.80%。
## 489. `cs.CL` - TLUE: A Tibetan Language Understanding Evaluation Benchmark [PDF](https://arxiv.org/pdf/2503.12051), [HTML](https://arxiv.org/abs/2503.12051)
### Authors
Fan Gao,Cheng Huang,Nyima Tashi,Xiangxiang Wang,Thupten Tsering,Ban Ma-bao,Renzeg Duojie,Gadeng Luosang,Rinchen Dongrub,Dorje Tashi,Hao Wang Xiao Feng,Yongbin Yu
### Background
大型语言模型近年来取得了显著进步，但低资源语言，如藏语，仍然严重缺乏评估。尽管藏语使用者超过七百万人，但在大型语言模型的发展和评估中几乎被忽视。本文旨在填补这一空白，提出一个面向藏语的大规模评估基准TLUE，旨在测量大型语言模型在藏语理解上的熟练程度。
### Innovation
提出了第一个藏语大规模评估基准TLUE，包含全面的多任务理解评测和安全评测两个主要部分，用于评估最新的大型语言模型在藏语上的表现。该研究揭示了大型语言模型在藏语处理上的显著挑战，对于未来藏语理解的研究具有重要意义，强调了在开发大型语言模型过程中推进包容性的必要性。
### Conclusion
实验结果表明，大多数大型语言模型在藏语测试中表现低于随机基线，这突显了在处理藏语方面所面临的极大挑战。TLUE为未来藏语理解研究奠定了关键基础，强调了在开发大型语言模型过程中推广包容性的重要性。
## 490. `cs.CL` - FANS -- Formal Answer Selection for Natural Language Math Reasoning Using Lean4 [PDF](https://arxiv.org/pdf/2503.03238), [HTML](https://arxiv.org/abs/2503.03238)
### Authors
Jiarui Yao,Ruida Wang,Tong Zhang
### Background
大型语言模型（LLMs）在文本生成、分类、问答等任务上展现了惊人的能力，然而在进行演绎推理方面仍然存在不少争议。自然语言（NL）的内在模糊性限制了LLMs进行可验证推理的能力，使得它们的回答缺乏连贯性和可信的支持。现有研究通常依赖奖励模型来提高LLMs的数学推理能力，但奖励模型的方法仍然具有局限性。因此，亟需一种新的方法来提升LLMs的自然语言数学推理能力，使其能够提供计算机可验证的解决方案。
### Innovation
本文提出了一种名为FANS的新颖框架，即使用Lean4增强自然语言数学推理能力的正式答案选择框架。该框架首先将自然语言数学问题转化为Lean4定理陈述，然后使用Lean4证明器进行验证，并利用验证结果辅助答案选择。这是第一个利用Lean4来增强LLMs自然语言数学推理能力的框架，它提供了一种不同于奖励模型的方法来进行答案选择。实验结果表明，该框架可以显著提高使用奖励模型增强后的LLMs在MATH-500和AMC-23数据集上的准确性。特别是在一些如数论等Lean4专家擅长的领域，可以选取出所有正确的答案。
### Conclusion
FANS框架有效提高了LLMs的自然语言数学推理能力，能够提供计算机可验证的解决方案。这种方法为改进LLMs的解答选择提供了新的思路。该论文是该领域的开拓性工作，作者将开放所有的模型和数据集，以进一步推动该领域的研究与发展。
## 491. `cs.CL` - OntoURL: 一个用于评估大型语言模型在符号本体理解、推理和学习能力测试基准 [PDF](https://arxiv.org/pdf/2505.11031), [HTML](https://arxiv.org/abs/2505.11031)
### Authors
Xiao Zhang,Huiyuan Lai,Qianru Meng,Johan Bos
### Background
大规模语言模型已经在广泛的任务中展示了卓越的能力，但在处理结构化符号知识方面的能力尚未得到充分探索。本文通过提出本体能力的分类法，并引入OntoURL（第一个全面的基准），系统评估大型语言模型在处理本体（即领域知识的正式和符号表示）方面的能力来填补这一空白。
### Innovation
本文通过制定一个本体能力的分类法，提出了OntoURL，这是第一个全面的基准测试，用于系统性地评估大型语言模型在处理本体方面的能力。通过15个不同的任务和57,303个问题，评估了大型语言模型在理解和推理三个维度上的表现。此外，还通过零样本和链式思考提示进一步实验，展示了不同提示策略对模型性能的影响。
### Conclusion
实验结果揭示了当前大型语言模型在理解和推理方面的能力，但在推理和学习任务中存在局限性。通过人类评估也显示出了相似的结果，这突出了大型语言模型在处理符号知识上的潜力和局限，并将OntoURL确立为评估大型语言模型与正式知识表示集成的重要基准。
## 492. `cs.CL` - 增强好奇心奖励的个性化多轮对话 [PDF](https://arxiv.org/pdf/2504.03206), [HTML](https://arxiv.org/abs/2504.03206)
### Authors
Yanming Wan,Jiaxing Wu,Marwa Abdulhai,Lior Shani,Natasha Jaques
### Background
有效的对话代理（如大语言模型）需要个性化其交互，以适应用户的偏好、个性和属性，尤其是在教育和医疗等不同的领域。现有的方法，如从人类反馈中学得强化学习（RLHF），虽然在提高帮助性和安全性方面表现出色，但在培养真正具有同理心、适应性和个性化的对话方面却有局限性。现有的个性化方法大多依赖于用户的详细历史记录，这限制了它们在新用户或情境受限用户中的有效性。因此，本文提出了一种利用用户模型注入基于好奇心的内在奖励的多轮RLHF的方法，以解决这些局限性。
### Innovation
通过引入基于好奇心的内在奖励机制，使LLM代理能够通过优化对话以提高其用户模型的准确性，从而主动推断用户的特质。这促使代理通过更好地了解用户来提供更加个性化的交互。该方法在两个领域中证明了其有效性：在对话推荐任务中显著提高了个性化性能，在教育场景中为不同的学习风格量身定制对话。这种方法展示了比传统多轮RLHF更好的泛化能力，同时保持了对话质量。
### Conclusion
本文提出的方法为创建更具个性化、适应性和互动性的对话代理提供了有希望的解决方案。通过在多轮RLHF中加入基于好奇心的内在奖励，可以改善对话代理的性能，尤其是在需要不同类型用户个性化互动的领域中。
## 493. `cs.CL` - 适配大型语言模型用于基于字符的辅助和替代通信 [PDF](https://arxiv.org/pdf/2501.10582), [HTML](https://arxiv.org/abs/2501.10582)
### Authors
Dylan Gaines,Keith Vertanen
### Background
用户通过使用英文字符语言模型的辅助和替代通信（AAC）界面逐个写入字母。然而，最先进的大型预训练语言模型主要预测变长的子词标记。本文研究如何利用这些模型生成准确和高效的字符预测，而不仅仅是使用分类层、字节级别模型或n-克模型。
### Innovation
提出了一种算法，可以从子词大型语言模型生成更准确的字符预测，并且还探讨了一种基于我们精心挑选的大规模句子数据集的领域适应方法，该数据集是基于评估每个句子对口语或书面AAC交流的有用性而编写的。研究发现，这种方法进一步提高了模型在简单、对话文本上的性能。
### Conclusion
与分类层、字节级别模型或n-克模型相比，我们提出的利用子词大型语言模型生成字符预测的方法更加准确且高效。此外，该领域适应程序进一步提高了模型在简单、对话文本上的性能。
## 494. `cs.CL` - 使用LLMs进行k-匿名性估计的概率推理 [PDF](https://arxiv.org/pdf/2503.09674), [HTML](https://arxiv.org/abs/2503.09674)
### Authors
Jonathan Zheng,Sauvik Das,Alan Ritter,Wei Xu
### Background
概率推理是人类和人工智能的重要组成部分，它能够处理决策中的不确定性和模糊性。本文针对大型语言模型（LLM），提出了一种新的基于不确定性的数值推理任务，旨在评估用户生成的包含敏感信息的文档的隐私风险。研究者使用BRANCH方法，该方法通过贝叶斯网络估计个人信息的联合概率分布中的每个因子的概率，并将它们组合起来计算最终的k值。
### Innovation
提出了BRANCH方法，这是一种新的LLM方法，用于估计文本的k-隐私值，即匹配给定信息的人口规模。该方法通过贝叶斯网络分别估计人口中每个因子的单一概率，然后将它们组合以计算最终的k值。实验结果显示，这种方法有73%的时间成功估计k值，相比o3-mini使用链式思考推理，准确性提高了13%。此外，研究还发现，LLM的不确定性是准确性的良好指标，高方差预测平均准确度降低了37.47%。
### Conclusion
BRANCH方法能够有效估计k值，并且其不确定性可以作为预测准确性的衡量指标，表现出良好的性能。
## 495. `cs.CL` - LEXam: 在340份法律考试上评估法律推理 [PDF](https://arxiv.org/pdf/2505.12864), [HTML](https://arxiv.org/abs/2505.12864)
### Authors
Yu Fan,Jingwei Ni,Jakob Merane,Yang Tian,Yoan Hermstrüwer,Yinya Huang,Mubashara Akhtar,Etienne Salimbeni,Florian Geering,Oliver Dreyer,Daniel Brunner,Markus Leippold,Mrinmaya Sachan,Alexander Stremitzer,Christoph Engel,Elliott Ash,Joel Niklaus
### Background
尽管近年来在测试时缩放方面取得了进展，但大型语言模型（LLMs）在长形式法律推理方面仍然面临重大挑战。为了应对这一挑战，研究人员开发了一个名为LEXam的新基准，该基准源自涵盖116门法律课程的340份法律考试，这些课程涉及多种科目和学位水平。该数据集包括用英语和德语撰写的4,886份法律考试问题，其中包括2,841个长形式的开放性问题和2,045个选择题。这些开放性问题还包括明确的指导，说明了预期的法律推理方法，如问题发现、规则回忆或规则应用。
### Innovation
研究人员提出了一种新的基准LEXam，该基准以涵盖116门法律课程的340份法律考试为基础，旨在评估LLMs在法律推理方面的能力。特别地，该数据集中的开放性问题强调LLMs在需要结构化、多步骤法律推理的问题上的困难。此外，项目的评估结果突显了数据集在区分不同能力模型方面的影响。该研究还展示了使用严格的专家评估，如何一致而准确地评估模型生成的推理步骤。
### Conclusion
我们采用了一个LLM作为法官的集成框架，并依据严格的专家验证，展示了如何提供一致和准确的模型生成推理步骤评估。我们的评估体系提供了一种超越简单准确度度量的方法来评估法律推理的质量。我们已经将代码开源并在GitHub上发布了数据，在Hugging Face上提供了数据，并在项目页面提供了更多信息。
## 496. `cs.CL` - MolLangBench: 一种用于语言引导的分子结构识别、编辑和生成的综合基准 [PDF](https://arxiv.org/pdf/2505.15054), [HTML](https://arxiv.org/abs/2505.15054)
### Authors
Feiyang Cai,Jiahui Bai,Tao Tang,Guijuan He,Joshua Luo,Tianyu Zhu,Srikanth Pilla,Gang Li,Ling Liu,Feng Luo
### Background
分子识别、编辑和生成对于化学家和处理各种化学任务的AI系统至关重要。为此，本文介绍了MolLangBench，这是一个全面的基准测试工具，旨在评估分子-语言界面任务，即基于语言提示的分子结构识别、编辑和生成。该基准使用自动化化学信息学工具构建识别任务，并通过严格专家注释和验证建立编辑和生成任务，以确保高质量、无歧义和确定性的输出。MolLangBench支持不同分子表示（包括线性字符串、分子图像和分子图）与语言接口模型的评估。
### Innovation
MolLangBench 提供了一个全面的基准测试框架，用于评估语言提示下的分子结构识别、编辑和生成，包括不同分子表示法的模型评估支持。该基准测试通过自动化化学信息学工具和严谨的专家评审确保了高质、无歧义和确定性的输出。
### Conclusion
最新的模型在识别和编辑任务上的表现显著不足，尤其是在生成任务上的准确率仅为43%。这体现了当前AI系统在处理初级分子识别和操作任务方面的局限性。MolLangBench的目的是推动进一步的研究，以开发更有效和可靠的应用化学的AI系统。
## 497. `cs.CL` - BiasLab：通过双轴注释和原因指示符实现可解释的政治偏见检测 [PDF](https://arxiv.org/pdf/2505.16081), [HTML](https://arxiv.org/abs/2505.16081)
### Authors
Kma Solaiman
### Background
在现有的政治新闻数据集中，缺乏系统地注释意识形态偏见的数据，尤其是那些能够细颗粒度地评估和理解偏见的数据。已有研究主要集中在单一方向上的偏见评估，缺乏两个方向（如对民主党和共和党支持度）的独立标注，这限制了研究的全面性和解释性。
### Innovation
BiasLab引入了一个包含300篇政治新闻文章的数据集，这些文章被注释了针对两个独立尺度的情感倾向（对民主党和共和党的支持），并添加了原因标识符。注释过程通过目标化的工人资质筛选和初步阶段的分析进行了优化。此外，研究还利用了基于模型的注释模拟，通过比较模型和人工注释的偏差揭示了新的现象，特别是对右倾但不明显内容的误分类特点。这为可解释的政治偏见检测提供了新的方向。
### Conclusion
BiasLab通过精细的双轴标注和原因标识符，提供了对政治偏见的可解释建模，有助于开发透明、社会意识强的自然语言处理系统。研究建议了两种建模任务，并报告了基础性能指标，展示了解释性偏见检测的挑战。数据集、标注方案和模型代码的开源为未来的研究提供了资源，旨在增强人类在回路中解释的交互，并评估解释的有效性。
## 498. `cs.CL` - WebRollback：增强web代理的显式回退机制 [PDF](https://arxiv.org/pdf/2504.11788), [HTML](https://arxiv.org/abs/2504.11788)
### Authors
Zhisong Zhang,Tianqing Fang,Kaixin Ma,Wenhao Yu,Hongming Zhang,Haitao Mi,Dong Yu
### Background
近年来，大型语言模型的发展显著提升了网络代理的能力。然而，在处理复杂和动态的网络环境时，仅依靠贪婪的一维搜索策略可能难以从错误状态中恢复。
### Innovation
本研究引入了一种显式的回退机制，使网络代理能够回滚到导航轨迹中的先前状态，从而赋予模型直接控制搜索过程的能力，提出了一种有效且高效的网络导航方法。
### Conclusion
我们在两个实时的网络导航基准测试上分别进行了零样本和微调设置的实验。实验结果表明，所提出的方法具有有效性。
## 499. `cs.CL` - 非洲NLP领域的发展图景：过去五年进展及未来方向 [PDF](https://arxiv.org/pdf/2505.21315), [HTML](https://arxiv.org/abs/2505.21315)
### Authors
Jesujoba O. Alabi,Michael A. Hedderich,David Ifeoluwa Adelani,Dietrich Klakow
### Background
非洲拥有超过2000种语言，潜在说这些语言的总人数可能成百万，这是世界上语言多样性最丰富的地区之一。然而，现有的最先进的自然语言处理(NLP)系统和大规模语言模型(LLMs)主要支持一小部分高资源语言，这种局面导致语言多样性的缺失，这不仅限制了现代NLP技术的应用范围和实用性，而且还可能加剧各语言社区之间的数字鸿沟。
### Innovation
本文对过去五年发布的884篇关于非洲语言的NLP研究论文进行了分析，提供了对该领域近期进展的全面概述，并确定了塑造该领域的关键趋势。该研究还提出了培养更加包容和可持续的NLP研究的未来发展方向。
### Conclusion
本文总结了非洲语言的NLP研究的趋势和可能的发展方向，旨在促进这一领域更加包容和可持续的研究。
## 500. `cs.CL` - 使用合成数据生成进行分布外检测 [PDF](https://arxiv.org/pdf/2502.03323), [HTML](https://arxiv.org/abs/2502.03323)
### Authors
Momin Abbas,Muneeza Azmat,Raya Horesh,Mikhail Yurochkin
### Background
分布外输入（OOD）的分类系统的可靠部署至关重要，但分布外数据通常难以获取或收集。因此，准确的OOD检测面临重大挑战。
### Innovation
提出了利用大型语言模型（LLMs）生成高质量合成OOD代理的方法，以消除对外部OOD数据源的依赖。该方法在经典文本分类任务以及LLM开发和部署中的分类任务中（如训练RLHF的奖励模型和检测非对齐生成）表现出色，实验表明其在降低误报率方面具有显著优势。
### Conclusion
在九个InD-OOD数据集对和不同模型规模下进行的广泛实验表明，该方法显著降低了假阳性率（在某些情况下达到零），同时保持了在分布内任务上的高准确性，显著优于基线方法。
## 501. `cs.CL` - ABBA-适配器：基础模型高效且富有表现力的微调 [PDF](https://arxiv.org/pdf/2505.14238), [HTML](https://arxiv.org/abs/2505.14238)
### Authors
Raghav Singhal,Kaustubh Ponkshe,Rohit Vartak,Praneeth Vepakomma
### Background
大型语言模型在广泛的任务中表现出强大的性能，但将其高效地适应新的领域仍然是一个关键挑战。参数高效微调（PEFT）方法通过引入轻量级、可训练模块来解决这个问题，同时将大多数预训练权重保持固定。目前占主导地位的方法是LoRA，它使用低秩分解来建模权重更新，但由于秩的限制，它的表现力受到先天性的约束。最近的方法如HiRA通过结合与冻结权重的Hadamard乘积来增加表达性，但仍依赖于预训练模型的结构。
### Innovation
本文引入了ABBA，这是一种新的PEFT架构，将更新重新参数化为两个独立可学习低秩矩阵的Hadamard乘积。与以前的工作不同，ABBA使更新部分和预训练权重部分能够完全独立优化，从而在相同的参数预算下获得了显著更高的表现力。通过矩阵重构实验验证了这一特性。实验结果表明，ABBA在算术和常识推理基准测试中达到了最先进的性能，表现出相对于现有PEFT方法的显著优势。
### Conclusion
ABBA通过其创新的微调架构，能够在不增加参数量的情况下大幅提高模型的表现力，在多个模型上表现出一致的优越性能。其代码已公开。
## 502. `cs.CL` - 利用大型语言模型获取战略市场洞察：前瞻性反事实生成的标准 [PDF](https://arxiv.org/pdf/2505.19430), [HTML](https://arxiv.org/abs/2505.19430)
### Authors
Keane Ong,Rui Mao,Deeksha Varshney,Paul Pu Liang,Erik Cambria,Gianmarco Mengaldo
### Background
反事实推理通常涉及考虑实际事件的替代情况，通常用于理解过往事件。本文介绍了一种特殊形式的反事实推理——形式前向反事实推理，专注于预见可能的未来发展。这种推理在动态金融市场中尤为有价值，可以帮助识别潜在的风险和机遇，指导决策。然而，这种大规模应用存在认知上的挑战，需要自动化解决方案来应对。尽管大型语言模型（LLMs）有潜力，但它们尚未被探索用于此类应用。
### Innovation
本文提出了一种名为FIN-FORCE（FINancial FORward Counterfactual Evaluation）的新基准，用于财务新闻标题的结构化评估，支持基于LLMs的前瞻性反事实生成。通过这种方法，可以为探索和预见未来的市场发展提供可扩展且自动化的解决方案，从而为决策提供结构化的洞察力。作者通过对FIN-FORCE进行实验，评估了最先进的LLMs和反事实生成方法，分析了它们的局限性，并为未来研究提出了见解。此外，作者还发布了基准、补充数据和所有实验代码。
### Conclusion
通过实验，作者评估了最先进的LLMs和反事实生成方法，揭示了它们的不足之处，并为未来的研究提供了方向。FIN-FORCE的发布填补了该领域的空白，为开发自动化的未来市场发展探索和预测提供了一个标准化的工具。
## 503. `cs.CL` - KG-RAG数据集中的诊断与解决：迈向更可靠的基准测试 [PDF](https://arxiv.org/pdf/2505.23495), [HTML](https://arxiv.org/abs/2505.23495)
### Authors
Liangliang Zhang,Zhuorui Jiang,Hongliang Chi,Haoyang Chen,Mohammed Elkoumy,Fali Wang,Qiong Wu,Zhengyi Zhou,Shirui Pan,Suhang Wang,Yao Ma
### Background
知识图谱问答系统(KGQA)依赖高质量基准来评估复杂多跳推理。然而，流行的WebQSP和CWQ等数据集存在严重的质量问题，例如不准确或不完整的事实标注，问题设计不佳（模糊、不切实际或不可回答），以及过时或不一致的知识。通过手动审核16个流行的KGQA数据集，研究发现平均事实正确率为57%。尽管这些数据集得到广泛应用，但其质量问题严重阻碍了KGQA系统的评估准确性。
### Innovation
本文引入了KGQAGen，这是一个包含LLM的环路框架，能系统地解决这些问题。KGQAGen结合了结构化知识的接地、LLM引导生成和符号验证，生成具有挑战性和可验证的问题回答实例。基于KGQAGen，构建了KGQAGen-10k基准数据集，其中数据集内容基于Wikidata，并评估了多种KG-RAG模型，实验结果表明最先进的系统在该数据集上表现不佳，突显了现有模型的局限性。
### Conclusion
本研究强调了更严格的基准构建的重要性，并将KGQAGen定位为可扩展框架，用于推进KGQA评估。
## 504. `cs.CL` - 基于多模态大语言模型的系统设计及其在事故数据集生成全流程自动化中的应用 [PDF](https://arxiv.org/pdf/2505.00015), [HTML](https://arxiv.org/abs/2505.00015)
### Authors
MD Thamed Bin Zaman Chowdhury,Moazzem Hossain
### Background
在像孟加拉国这样的发展中国家，道路交通事故仍然是一个重大的公共安全和社会经济问题。现有的事故数据收集主要依赖手工操作，数据分散且不可靠，导致报告不完整且记录不一致的问题。因此，迫切需要一种自动化的系统来解决这些问题。
### Innovation
该研究提出了一种完全自动化的系统，使用大型语言模型（LLMs）和网页抓取技术来解决这一问题。该系统通过四个组件来实现：网页抓取代码自动生成、在线来源事故新闻收集、结构化数据提取和重复数据删除。该系统使用Gemini-2.0-Flash这一多模态生成LLM来实现无缝自动化。系统代码生成模块能够对网页进行分页、动态或无限滚动分类，并生成适当的Python脚本来抓取数据。此外，LLMs还用于分类和提取关键事故信息，如日期、时间、地点、伤亡情况、道路类型、车辆类型和行人参与情况。此外，系统还通过去重算法来确保数据完整性。该系统历时111天（2024年10月1日至2025年1月20日），从14个主要孟加拉新闻网站抓取了超过15,000篇新闻文章，识别了705起不同的交通事故事件。代码生成模块显示了91.3%的校准准确率和80%的验证准确率。
### Conclusion
该研究展示了基于大语言模型的可扩展系统在交通事故数据准确、低成本收集方面的能力，为孟加拉国的数据驱动道路安全管理奠定了基础。
## 505. `cs.CL` - 当模型用您的语言思考：控制思考语言会牺牲准确性 [PDF](https://arxiv.org/pdf/2505.22888), [HTML](https://arxiv.org/abs/2505.22888)
### Authors
Jirui Qi,Shan Chen,Zidi Xiong,Raquel Fernández,Danielle S. Bitterman,Arianna Bisazza
### Background
近年来，具有思维轨迹的大型推理模型（LRMs）在英语推理任务上表现出色，但它们在其他语言中的推理能力较少被研究。对于实际应用而言，这种多语言推理能力与答案准确性同等重要，因为用户只有当推理过程用他们的母语表达时，才会觉得有用。研究者在XReasoning基准上全面评估了两个主要的LRM家族，并发现即使是最先进的模型往往也会自动切换到使用英语或产生断断续续的推理过程，揭示了他们在多语言推理能力上的巨大差距。通过促使模型用用户指定的语言进行思考可以提高可读性和监控性，但会降低答案准确性，这揭示了一个重要的权衡。
### Innovation
研究者通过XReasoning基准对两个主要的LRM家族进行了全面评估，发现模型倾向于使用英语或者在其他语言中产生片段化的推理过程。进一步，研究者展示了经过针对特定语言的100个样例的训练，可以缓解这一不匹配，尽管仍有一些准确性损失。这项研究强调了当前LRM在多语言推理能力上的局限性，并指出了未来研究的方向。
### Conclusion
当前的LRM在多语言推理方面的表现出局限，需要进一步研究来改进多语言思维模型。研究结果还说明了促进模型用用户指定的语言进行思考可以提高可读性和监控性，但会牺牲答案准确性。未来的研究可以集中在缩小这个准确性和可读性的权衡上。
## 506. `cs.CL` - 我应该分享这个翻译吗？评估对机器翻译的信任度反馈 [PDF](https://arxiv.org/pdf/2505.24683), [HTML](https://arxiv.org/abs/2505.24683)
### Authors
Dayeon Ki,Kevin Duh,Marine Carpuat
### Background
随着人们越来越依赖AI系统进行工作和日常生活，开发有效的反馈机制以促进负责任的使用AI变得尤为重要，尤其是在用户不具备评估AI预测质量能力的情况下。文章研究了一个真实的机器翻译场景，即仅懂一种语言的用户决定是否分享机器翻译输出。该研究对比了四种类型的质量反馈：直接评价翻译质量的显式反馈（包括错误标注和大语言模型解释）以及帮助用户通过反向翻译和问答表格来比较输入和输出的隐式反馈。
### Innovation
研究设计了一个实用的机器翻译场景，通过对比四种不同类型的反馈机制来评估用户对机器翻译的信任度。隐式反馈，特别是问答表格（QA表格），相比于显式反馈在决策准确性和适当依赖方面表现出更大的提升效果，并且获得了最高的有用性和信任度评价，同时较低的心理负担评分。
### Conclusion
所有类型的反馈，除了错误标注之外，都能显著提高决策准确性和适当依赖性。特别地，隐式反馈，尤其是问答表格，在决策准确性和信任感方面比显式反馈有显著的提升，得到了最高的用户满意度评价，并且被认为是最容易接受的。
## 507. `cs.CL` - MetaFaith：LLMs中忠实自然语言不确定性表达的元认知方法 [PDF](https://arxiv.org/pdf/2505.24858), [HTML](https://arxiv.org/abs/2505.24858)
### Authors
Gabrielle Kaili-May Liu,Gal Yona,Avi Caciularu,Idan Szpektor,Tim G. J. Rudner,Arman Cohan
### Background
语言生成模型（LLMs）的可信度关键在于可靠的不确定性沟通。然而，当LLMs传达错误声明时，它们常常使用坚定的语调，这导致了过度依赖和信任的侵蚀。已有研究表明，现有的干预措施无法充分解决这一问题，标准提示方法只能提供边际改善，而现有的事实性校准技术甚至可能损害忠实校准。
### Innovation
本文首次对LLMs的忠实信心校准进行系统研究，并引入了一种新的基于提示的校准方法——MetaFaith，该方法受到人类元认知的启发。MetaFaith能在多种模型和任务领域中显著提升忠实校准，最高可达61%的改进，并实现人类判断下83%的胜率。
### Conclusion
本文的结果表明，尽管现有的LLMs在忠实信心校准方面普遍表现不佳，但元认知启发的提示式校准方法MetaFaith能够有效提升LLMs在各种任务中的忠实表达，呈现出大幅提升的信心一致性。
## 508. `cs.CL` - LLMs真的遗忘了吗？基于知识关联和置信度意识的评估 [PDF](https://arxiv.org/pdf/2506.05735), [HTML](https://arxiv.org/abs/2506.05735)
### Authors
Rongzhe Wei,Peizhi Niu,Hans Hao-Hsun Hsu,Ruihan Wu,Haoteng Yin,Mohsen Ghassemi,Yifan Li,Vamsi K. Potluru,Eli Chien,Kamalika Chaudhuri,Olgica Milenkovic,Pan Li
### Background
现有的机器卸载技术旨在减轻大型语言模型（LLMs）中的无意记忆问题，但它们主要专注于孤立事实的显式删除，往往忽视了潜在的推理依赖关系以及LLMs知识的非确定性。因此，被假定遗忘的事实可能通过相关信息隐式地保持下来。为解决这些问题，本文提出了一种知识卸载评估框架，通过将相关事实背景表示为附有置信分数的知识图谱来更准确地捕捉现实世界的知识结构。进一步地，本文开发了一种推理为基础的评估协议，利用功能强大的LLMs作为法官，这些法官对提取的知识子图进行推理以判断卸载的成功与否。这些LLM法官利用精心设计的提示，并通过与人类评估进行校准，确保其可靠性和稳定性。
### Innovation
本文提出了一个基于知识关联和置信度意识的知识卸载评估框架，该框架通过构建知识图谱来更准确地表示相关事实背景，并利用强大的LLM作为法官，来判断卸载的成功性。此外，提出了一种推理为基础的评估协议，并且LLM法官使用精心设计的提示，并进行人类评估的校准，以确保其可靠性和稳定性。实验结果表明，该框架提供了一种更真实和严格的卸载评估，发现现有的评估策略往往会高估卸载效果。
### Conclusion
本文框架通过更准确地评估知识卸载的效果，揭示了现有策略可能存在的问题，并提出了更可靠的方法。我们的代码已经在公有地址（给出的URL）上公开。
## 509. `cs.CL` - Double-Checker: 通过自我批判微调增强慢思考的LLMs推理能力 [PDF](https://arxiv.org/pdf/2506.21285), [HTML](https://arxiv.org/abs/2506.21285)
### Authors
Xin Xu,Tianhao Chen,Fan Zhang,Wanlong Liu,Pengxiang Li,Ajay Kumar Jaiswal,Yuchen Yan,Jishan Hu,Yang Wang,Hao Chen,Shiwei Liu,Shizhe Diao,Can Yang,Lu Yin
### Background
慢思考的大语言模型（LLMs）虽然能够展现类似反思的推理能力，即所谓的“灵光一闪”，但它们生成具有信息量的批评和改进先前解决方案的能力仍然有限。
### Innovation
本文介绍了一种名为Double-Checker的理论框架，旨在通过促进LLMs的显式自我批评和其先前解的迭代改进来增强其推理能力。通过在我们创建的1,730个自我批判实例上进行微调，Double-Checker使得长期推理链(L-CoT)的LLMs可以在推理过程中通过自我生成的批判性评价循环地进行批评和改进，直至它们认为解题结果是正确的。
### Conclusion
我们通过综合推理基准的验证，展示了自我批判迭代的显著提高长期推理链LLMs的推理能力。我们的Double-Checker在具有挑战性的AIME基准上的pass@1性能从4.4%提高到了18.2%，与最初的长期推理链LLMs相比有了显著的提升，这表明开发具有结构化自我批判能力的更可信和有效的LLMs具有明显进展。代码和数据可以在以下链接获取：this https URL
## 510. `cs.CL` - 无语言数据被遗忘：Hugging Face 生态系统中CJK语言数据的比较研究 [PDF](https://arxiv.org/pdf/2507.04329), [HTML](https://arxiv.org/abs/2507.04329)
### Authors
Dasol Choi,Woomyoung Park,Youngsook Song
### Background
近年来，自然语言处理（NLP）的发展凸显了高质量数据集在构建大规模语言模型（LLM）中的关键作用。尽管对于英语有大量的资源和分析，但东亚语言（特别是汉语、日语和韩语）的数据集生态系统依然碎片化且研究不足，尽管这些语言共同拥有超过16亿的使用者。因此，本文从跨语言的角度调查了HuggingFace生态系统中的数据集，探索文化规范、研究环境和机构实践如何影响数据集的存在和质量。
### Innovation
通过分析超过3300个数据集，采取定量和定性方法，研究揭示了汉语文本的大规模和机构驱动特性，韩语NLP领域中由社区主导的发展模式，以及日语文本在娱乐和亚文化方面的重点。这些发现提供了增强数据集文档、许可透明度和跨语言资源共享的具体策略，指导更有效和文化敏感的东亚LLM开发。
### Conclusion
本文揭示了汉语文本、韩语文本和日语文本数据集治理与协作的最佳实践，旨在加强三种语言之间的资源开发，最终增强HuggingFace生态系统中数据集的发展和合作。
## 511. `cs.CL` - 基于推理的机械记忆：重新思考语言模型中的机械记忆现象 [PDF](https://arxiv.org/pdf/2507.04782), [HTML](https://arxiv.org/abs/2507.04782)
### Authors
Yupei Du,Philipp Mondorf,Silvia Casola,Yuekun Yao,Robert Litschko,Barbara Plank
### Background
大型语言模型在训练过程中会记忆任意的训练实例，如标签噪声，然而它们在推理任务上表现出色。本研究调查了语言模型如何记忆标签噪声，以及这种记忆为何在很多情况下不会严重影响其可泛化的推理能力。
### Innovation
研究使用了带有噪声标签的两个可控合成推理数据集（四位数加法与两跳关系推理），发现了记忆依赖于可泛化的推理机制，即模型在检索记忆中的噪声标签时会持续进行中间推理步骤，而干扰推理会破坏记忆。研究表明，记忆通过分布式编码发生，而不是建立输入到噪声标签的查找机制。通过四位数加法案例研究，揭示了记忆通过离群值启发式实现，即现有神经元激活模式略微调整以适应噪声标签。
### Conclusion
我们的研究结果表明，语言模型对标签噪声的记忆依赖于但并未覆盖其基本的推理机制，帮助理解了良性的记忆现象。
## 512. `cs.CL` - 灵活的大型语言模型特征精炼 [PDF](https://arxiv.org/pdf/2507.10155), [HTML](https://arxiv.org/abs/2507.10155)
### Authors
Khouloud Saadi,Di Wang
### Background
知识蒸馏(KD)已成为压缩大型语言模型(LLMs)的关键技术。现有的LLM-KD方法主要依赖于基于logit的方法，这虽然在性能上有很好的表现，但忽略了LLMs内部丰富表示的重要性。在特征层面的KD可以利用这一结构提供额外的好处，但是由于当前的特征KD方法通常假设教师和学生隐藏层大小一致，这是一个限制性和不现实的假设，导致这一领域尚未受到充分探索。一种常见的解决方法是训练一个线性投影来对齐特征空间，但这引入了额外的参数，扭曲了教师的嵌入，并且在生成任务中往往会降低下游性能。
### Innovation
作者提出了一种名为Flex-KD的参数无注入框架，用于任务驱动的LLMs特征精炼。Flex-KD不直接投影教师表示，而是使用基于梯度的评分来识别教师隐状态中与任务最相关的维度，并仅精炼这个子空间到学生模型中。这种方法确保了学生有限的容量被分配给信息性成分，同时避免了投影引入的扭曲和额外参数。Flex-KD能够与现有的KD管道无缝集成，并支持不同的教师-学生隐藏层大小。实验结果显示，Flex-KD在分类和生成任务中都显著提高了学生模型的性能，相较于线性投影基准，性能提升了多达3.75%。
### Conclusion
Flex-KD是一个适用于LLMs的无参数框架，无需投影整个教师表示，而是通过梯度评分选择最相关的任务维度进行精炼。这种方法规避了传统的投影方法带来的一些问题，确保了学生的性能提升，特别是在生成任务中表现突出。
## 513. `cs.CL` - 推理模型是测试作弊者：重思多项选择 [PDF](https://arxiv.org/pdf/2507.15337), [HTML](https://arxiv.org/abs/2507.15337)
### Authors
Narun Raman,Taylor Lundy,Kevin Leyton-Brown
### Background
在评估大型语言模型（LLMs）在问答任务方面的表现时，通常会要求模型从固定选项中选择答案（即多项选择题，MCQA）。尽管实际目标下游任务并不会为系统提供选择的选项，但这种做法因为易于自动评分且能生成高度挑战性的基准测试而仍然广泛使用。然而，随着先进推理模型的进步，这种方法的有效性成为了研究关注的焦点。
### Innovation
论文系统性地评估了15种不同的问答基准和27种不同的LLM模型（从小到大规格不等），探讨了这些模型在不同问题呈现方式下（如是否提供选项、是否允许chain-of-thought推理、在展示选项前后是否允许进行推理等）的表现。研究发现，允许模型在看到选项前进行chain-of-thought推理时，MCQA仍然是模型下游性能的良好代理；然而，能够在展示选项后进行推理的大型模型会因其能利用选项信息而显著优于其自由文本表现。
### Conclusion
研究识别并量化了模型在回答MCQA问题时使用哪些信号，并提供了更符合LLMs真实推理能力的分析指南。研究结果表明，当代先进推理模型在问答任务中可能会‘作弊’利用选项信息，而传统的MCQA评估方法可能并不能全面反映其真实推理能力。
## 514. `cs.CL` - 如果用其他语言提问？评估跨语言功能相似性 [PDF](https://arxiv.org/pdf/2509.04032), [HTML](https://arxiv.org/abs/2509.04032)
### Authors
Debangan Mishra,Arihant Rastogi,Agyeya Negi,Shashwat Goel,Ponnurangam Kumaraguru
### Background
研究了模型输出在不同语言之间的相似性，使用了一个最近提出的模型相似性度量κ_p，以20种语言和47个主题在全球MMLU中进行分析。研究发现，随着模型规模和能力的增长，它们在不同语言间的响应变得越来越一致。此外，模型在同一语言环境下相互之间的连贯性高于与其他模型的连贯性。这些结果强调了κ_p作为评估多语言可靠性的实用工具的价值，并指出了其在指导更一致的多语言系统开发方面的潜力。
### Innovation
引入了κ_p度量来评估模型输出在不同语言中的相似性，并使用全球MMLU进行了大规模的多语言研究。提出了模型在相同语言环境下连贯性与跨语言模型连贯性之间的对比分析，揭示了连贯性特征的新见解。
### Conclusion
模型输出的一致性会随着模型规模和能力的增加而提高；模型在同一语言环境下的连贯性优于与其他模型的连贯性；κ_p度量不仅可以作为评估多语言系统的工具，还可能指导开发更一致的多语言系统。
## 515. `cs.CL` - 探索ReLoRA：小型语言模型学习动态的影响 [PDF](https://arxiv.org/pdf/2509.12960), [HTML](https://arxiv.org/abs/2509.12960)
### Authors
Yuval Weiss,David Demitri Africa,Paula Buttery,Richard Diehl Martinez
### Background
LoRA等参数高效方法已经极大地革新了大型语言模型（LLM）的微调过程。ReLoRA通过重复地合并和重初始化低秩适配器，增加累积的秩数同时保持更新成本低，与大型模型通过时间和空间上逐渐扩大的局部低秩轨迹学习的观察相符。然而，最近的研究表明，小型语言模型（SLM）存在秩不足的问题，未能充分利用维度。因此，自然地提出一个问题：ReLoRA的秩扩展更新规则是否能使SLM的学习动态更加健康，缓解容量受限时的秩瓶颈。SLM被认为是理想的测试平台，因为它们快速训练，便于控制性删除分析，从而使秩现象更容易测量。
### Innovation
提出了一种新的方法ReLoRA，通过反复合并和重初始化低秩适配器，增加模型的累积秩数。这种方法特别适用于观察到的高容量模型学习趋势，但尚未被应用于小型语言模型。此研究首次系统地研究了ReLoRA在具有11M到66M参数的小型语言模型中的性能和学习动态。
### Conclusion
实验结果表明，ReLoRA在性能上不如全秩训练，特别是在大规模模型上差距更大。ReLoRA增加了已存在的秩不足，并在训练早期引发了不佳的条件更新。研究结果表明，尽管ReLoRA的合并和重启策略可以在较大的模型中扩展秩，但对于容量受限的小型语言模型而言，它并不直接适用，这促使开发适应性或混合秩的方法，用于低计算量的预训练。
## 516. `cs.CL` - 增强多样性推理以应对主观问题 [PDF](https://arxiv.org/pdf/2507.20187), [HTML](https://arxiv.org/abs/2507.20187)
### Authors
Yumeng Wang,Zhiyuan Fan,Jiayu Liu,Jen-tse Huang,Yi R. Fung
### Background
大型推理模型（LRMs）通过强化学习与可验证奖励（RLVR）优化，擅长客观推理任务，如数学问题解决和代码生成。然而，RLVR降低生成多样性，导致在涉及多角度答案的主观推理任务中表现不佳。尽管有研究强调在客观推理中增强多样性的训练的重要性，但对主观任务的关注不足。本文通过引入视角多样性和标记级多样性，发现主观推理任务可以通过这些方式得以改进。视角多样性以现实世界的干系人组为依据提供连贯的支持，而标记级多样性则扩展了答案搜索空间。研究显示，单一针对主观任务的训练可以将领域内和领域外的准确性分别提升14.1%和7.64%，甚至在诸如AIME 2024进阶数学推理中也有所提升。此外，多样性是比推理长度更一致的准确性指标。
### Innovation
提出了一个增强多样性的训练框架MultiRole-R1，其中包括一个无监督的数据构造管道，该管道综合了各种角色视角的推理链。同时，使用组相关的相对策略优化的强化学习方法，并将多样性作为奖励信号之一。这种框架在仅进行主观任务训练的情况下提升了模型的准确性和性能，甚至在复杂的数学推理任务中表现优异。此外，多样性比推理长度更能一致地反映准确性的指标。
### Conclusion
通过引入视角多样性和标记级多样性，增强了模型在主观推理任务中的表现，并通过一个无监督的多角色推理链条生成数据构造框架提升了模型的准确性和可靠性。
## 517. `cs.CL` - Mafoko：为南非多语言NLP构建结构化开放术语库 [PDF](https://arxiv.org/pdf/2508.03529), [HTML](https://arxiv.org/abs/2508.03529)
### Authors
Vukosi Marivate,Isheanesu Dzingirai,Fiskani Banda,Richard Lastrucci,Thapelo Sindane,Keabetswe Madumo,Kayode Olaleye,Abiodun Modupe,Unarine Netshifhefhe,Herkulaas Combrink,Mohlatlego Nakeng,Matome Ledwaba
### Background
南非官方语言术语数据的缺乏阻碍了多语言自然语言处理（NLP）领域的发展，尽管政府和学术界有许多术语列表。这些宝贵资源目前处于碎片化状态，存储在非机器可读的格式中，无法用于计算研究和开发。
### Innovation
Mafoko通过系统地聚合、清理和标准化这些分散的资源，将其转化为开放且可互操作的数据集，解决了这一挑战。该论文介绍了以非洲为中心、公平的NOODL框架下的基础Mafoko数据集。实验结果显示，整合术语库后，英语到tshivenda语言模型的机器翻译准确性大幅提升，并且领域特定的一致性也得到了改善。
### Conclusion
Mafoko提供了构建强大且公平的NLP技术的基础框架，确保南非丰富的语言多样性在数字时代得到充分的代表。
## 518. `cs.CL` - Co-NAML-LSTUR：结合注意力多视图学习和长期短期用户表示的新闻推荐模型 [PDF](https://arxiv.org/pdf/2507.20210), [HTML](https://arxiv.org/abs/2507.20210)
### Authors
Minh Hoang Nguyen,Thuat Thien Nguyen,Minh Nhat Ta,Tung Le,Huy Tien Nguyen
### Background
新闻推荐系统在减轻信息过载方面发挥关键作用，通过个性化内容推送。挑战在于同时建模新闻文章的多视图表示并捕捉用户兴趣的动态、双尺度性质，涵盖短期和长期偏好。先前的方法通常依赖单一视图特征或未能充分建模不同时段的用户行为。
### Innovation
本文提出了结合NAML（注意多视图学习）和LSTUR（层次用户建模）的Co-NAML-LSTUR混合推荐框架，利用BERT嵌入增强语义表示，并针对有限数据资源进行训练。该模型在MIND-small和MIND-large两个常用基准上进行评估，结果显示Co-NAML-LSTUR显著优于强基线模型，AUC和MRR分别提高了1.55%和1.15%，以及NAML的2.45%和1.71%，突显了效率导向的混合模型的有效性。
### Conclusion
研究表明，该模型结合多视图新闻建模与双尺度用户表示，在资源受限的情况下表现出色，而非声称达到绝对的先进水平（SOTA）。模型的实现已公开发布。
## 519. `cs.CL` - 生成难译文本 [PDF](https://arxiv.org/pdf/2509.26592), [HTML](https://arxiv.org/abs/2509.26592)
### Authors
Vilém Zouhar,Wenda Xu,Parker Riley,Juraj Juraska,Mara Finkelstein,Markus Freitag,Daniel Deutsch
### Background
现实世界中的机器翻译基准迅速过时，因为大多数示例对于最先进的翻译模型来说都很简单。这限制了基准测试区分哪个模型更好或揭示模型弱点的能力。
### Innovation
提出了一种名为MT-breaker的新方法，通过大规模语言模型迭代细化源文本以增加其翻译难度。这种模型会根据目标机器翻译模型的反馈迭代生成更难的示例，同时保持自然文本的多样性。
### Conclusion
虽然生成的示例针对特定的机器翻译模型进行了调整，但这种难度的提升也适用于其他模型和语言。
## 520. `cs.CL` - MOSAIC:一个多语言、无特定分类和计算高效的放射报告分类方法 [PDF](https://arxiv.org/pdf/2509.04471), [HTML](https://arxiv.org/abs/2509.04471)
### Authors
Alice Schiavone,Marco Fraccaro,Lea Marie Pehrson,Silvia Ingala,Rasmus Bonnevie,Michael Bachmann Nielsen,Vincent Beliveau,Melanie Ganz,Desmond Elliott
### Background
放射学报告中包含丰富的临床信息，可以用于训练影像模型，而无需依赖昂贵的手工注释。然而，现有方法面临一些关键限制：基于规则的方法难以处理语言变化，监督模型需要大量标注数据集，而新型的基于大语言模型的方法依赖于收费或计算强度高的模型，这些模型不适用于临床环境。此外，当前解决方案主要限制在英文和单一模态、单一分类的数据集上。
### Innovation
本文介绍了一种名为MOSAIC的多语言、无特定分类和计算高效的放射报告分类方法。MOSAIC基于一个紧凑的开源语言模型（MedGemma-4B），支持零样本/少量样本提示和轻量级微调，可以在消费级GPU上部署。MOSAIC在7个跨语言、多模态和标签分类的数据集上进行了评估，模型在五个肺部X光数据集中达到了88的宏F1分数，接近或超过了专家级性能，同时只需要24 GB的GPU内存。通过数据增强，最小的80个标注样本也足以达到82的加权F1分数，而使用完整的1600样本训练集为86。MOSAIC为临床上提供了大型或专有LLM的实用替代方案。代码和模型是开源的，社区可以评估并在此基础上扩展MOSAIC到新的语言、分类和模态上。
### Conclusion
MOSAIC提供了一种实用的替代方案，可以在临床环境中应用，无需依赖大或专有的LLM。通过开源代码和模型，MOSAIC的潜力可以进一步得到挖掘和扩展。
## 521. `cs.CL` - SpeechWeave: 创新型多语言合成文本与音频数据生成管道，用于训练文本到语音模型 [PDF](https://arxiv.org/pdf/2509.14270), [HTML](https://arxiv.org/abs/2509.14270)
### Authors
Karan Dua,Puneet Mittal,Ranjeet Gupta,Hitesh Laxmichand Patel
### Background
高质量的文本到语音(TTS)模型训练需要大量的多样化的文本和声音数据。从实际来源获取这些数据存在专业领域的特定性、许可和可扩展性问题。大型语言模型可以生成文本数据，但在生成过程中容易产生重复且缺乏变化性。文本规范化也是TTS训练数据的重要方面，现有的规范化工具可能引入异常或忽略有价值的模式，从而影响数据质量。在商业TTS系统中，依靠声音艺术家进行大规模声音录音也是不切实际的。
### Innovation
为了应对这些挑战，我们提出了SpeechWeave，一种能够自动生成多语言、专业领域的数据集，用于训练TTS模型的合成语音数据生成管道。实验结果表明，该管道生成的数据在多种语言和音素指标上的多样性比基线数据提升10-48%，同时生成的标准化文本正确率为97%，并生成标准化的发音音频。这使得能够高效、高质量地生成训练数据，提高数据多样性和规范化水平，同时保持声音一致性。
### Conclusion
SpeechWeave 管道能够自动创建具有多样性和专业性的数据集，从而提高TTS模型的训练数据质量，增强数据的多样性和规范化，同时保持声音的一致性。
## 522. `cs.CL` - 翻译准确性的隐藏成本：蒸馏、量化与环境影响 [PDF](https://arxiv.org/pdf/2509.23990), [HTML](https://arxiv.org/abs/2509.23990)
### Authors
Dhaathri Vijay,Anandaswarup Vadapalli
### Background
随着大规模语言模型（LLMs）的迅速扩张，人们对这些模型的计算和环境成本提出了越来越多的担忧。本研究通过机器翻译案例调查了翻译质量与效率之间的权衡问题。研究中对比了全量模型、精简模型与量化模型的表现。
### Innovation
研究通过Flores+基准测试和对法语、印地语和卡纳达语口语翻译的人类评价，系统地探讨了模型精简和量化策略对低资源环境下的翻译质量和环境影响方面的权衡，展示了这些策略如何在保持可竞争的翻译质量的同时显著减少计算需求和环境足迹。
### Conclusion
研究表明，模型压缩策略可以大幅降低计算需求和环境影响，同时保持竞争力的翻译质量，尽管在低资源环境下优势更显著。研究建议评价框架应同时综合效率、可持续性与准确性作为NLP进展的主要维度。
## 523. `cs.CL` - AutoScale: Scale-Aware Data Mixing for Pre-Training LLMs [PDF](https://arxiv.org/pdf/2407.20177), [HTML](https://arxiv.org/abs/2407.20177)
### Authors
Feiyang Kang,Yifan Sun,Bingbing Wen,Si Chen,Dawn Song,Rafid Mahmood,Ruoxi Jia
### Background
领域加权是一种新兴的研究领域，旨在调整不同数据源的相对权重，以提高大型语言模型（LLM）预训练的有效性和效率。然而，研究发现，表现良好的数据混合在较小规模下，可能在较大规模下不再保持优势，这挑战了现有的实验中确定竞争性数据混合并在更大规模下直接应用的做法。
### Innovation
AutoScale 是一种两阶段尺度感知的数据组合框架。它首先通过拟合参数模型来预测不同数据组合下的模型损失，然后使用该模型在较小的预算下找到一个近似最佳分配。其次，利用对最优组合随规模变化的全新理论分析，AutoScale 可以在不重新训练的情况下，将这种组合外推到更大的预算中。实验结果显示，AutoScale 加快了收敛速度并提高了下游性能。
### Conclusion
我们的研究结果展示了领域重要性随着训练规模的变化，强调了在 LLM 训练中需要根据规模进行数据管理。我们的代码已开源。
## 524. `cs.CL` - 多语言关系增强生成（mRAG）系统中的语言亲缘优势：在语言偏好与质量之间的权衡 [PDF](https://arxiv.org/pdf/2509.13930), [HTML](https://arxiv.org/abs/2509.13930)
### Authors
Dayeon Ki,Marine Carpuat,Paul McNamee,Daniel Khashabi,Eugene Yang,Dawn Lawrie,Kevin Duh
### Background
多语言检索增强生成（mRAG）系统能够使语言模型跨语言以引文支持的方式回答知识密集型查询。尽管已经提出了一些此类系统，但一个公开的问题是，不同文档语言的混合是否以未预期的方式影响生成和引文。为了研究这个问题，本研究采用了一种控制方法来测量模型的语言偏好，同时保持其他因素如文档相关性不变。在八种语言和六种模型中，研究发现当查询为英语时，模型更倾向于引用英语来源，这种偏好随着低资源语言和居中语境的文档的增加而增强。研究表明，模型有时会牺牲文档的相关性以追求语言偏好，这表明引文选择并不总是由信息量驱动的。研究结果阐明了语言模型如何利用多语言上下文并影响引文行为.
### Innovation
研究开发了一种控制方法，通过探究模型的语言偏好，保持其他因素如文档相关性不变，来评估在多语言mRAG系统中生成和引文的质量与语言偏好之间的权衡关系。研究发现了在不同语言和低资源语言中，查询为英语时模型倾向于引用英语来源的现象，并且这种偏好会随着低资源语言和居中语境的文档的增加而增强，模型有时会牺牲文档的相关性以追求语言偏好，揭示了模型引文选择的复杂性.
### Conclusion
研究的结果揭示了语言模型在利用多语言上下文时如何权衡质量和语言偏好，并影响引用行为。这为我们更好地理解多语言mRAG系统中模型的行为提供了新的见解，也为改进此类系统提供了新的方向.
## 525. `cs.CL` - Agent-ScanKit: 通过敏感性扰动揭开多模态代理的记忆和推理 [PDF](https://arxiv.org/pdf/2510.00496), [HTML](https://arxiv.org/abs/2510.00496)
### Authors
Pengzhou Cheng,Lingzhong Dong,Zeng Wu,Zongru Wu,Zhuosheng Zhang,Gongshen Liu
### Background
尽管最近提出了许多增强多模态代理在图形用户界面（GUI）中自主交互能力的策略，但在面对复杂或超域任务时，其可靠性仍然有限。这引发了一个基本问题：现有的多模态代理是否在进行错误的推理？
### Innovation
本文提出了一个系统性的探针框架Agent-ScanKit，用于在受控干扰下揭开多模态代理的记忆和推理能力。具体来说，引入了三种正交的探针范式：视觉指导、文本指导和结构指导，每种范式都旨在量化记忆和推理的贡献，而不需访问模型内部。
### Conclusion
在五个公开的GUI基准测试中，涉及18个不同模型的实验结果表明，机械记忆常常凌驾于系统推理之上。大多数模型主要作为与训练对齐知识的检索器，表现出有限的泛化能力。本研究强调了在实际场景中对多模态代理进行稳健推理建模的必要性，为开发可靠多模态代理提供了宝贵见解。
## 526. `cs.CL` - MOSS-Speech：无需文本指导的真正端到端语音模型 [PDF](https://arxiv.org/pdf/2510.00499), [HTML](https://arxiv.org/abs/2510.00499)
### Authors
Xingjian Zhao,Zhe Xu,Qinyuan Cheng,Zhaoye Fei,Luozhijie Jin,Yang Wang,Hanfu Chen,Yaozhou Jiang,Qinghui Gao,Ke Chen,Ruixiao Li,Mingshu Chen,Ruiming Wang,Wenbo Zhang,Yiyang Zhang,Donghua Yu,Yang Gao,Xiaogui Yang,Yitian Gong,Yuanfan Xu,Yaqian Zhou,Xuanjing Huang,Xipeng Qiu
### Background
口语对话系统通常依赖于流水线，包括语音识别、处理和再合成。尽管这种设计有效，但它会丢弃副语言线索并限制表达性。近期的端到端方法减少了延迟并更有效地保留了这些线索，但仍然依赖于文本中介，造成基本瓶颈。
### Innovation
提出了MOSS-Speech，一种无需文本指导直接理解和生成语音的大型语言模型。该方法结合了基于模态的分层架构和冻结预训练策略，保留了预训练文本LLM的推理和知识，同时加入原生的语音能力。实验证明，该模型在口语问答中达到最先进的结果，并在端到端语音性能方面与现有的文本引导系统相当，同时保持了竞争力的文本性能。通过缩小文本引导和直接语音生成之间的差距，本工作建立了新的高效且具有表现力的端到端语音交互范式。
### Conclusion
本工作展示了无需文本指导的端到端语音交互新范式，提高了语音互动的表达性和效率。
## 527. `cs.CL` - Tenyidie 声调语素构词语料库创建和深度学习应用 [PDF](https://arxiv.org/pdf/2510.00629), [HTML](https://arxiv.org/abs/2510.00629)
### Authors
Teisovi Angami,Kevisino Khate
### Background
Tenyidie 是印度东北部纳加兰邦Tenyimia社区使用的藏缅语系低资源语言，音调、主宾语动词型，并且高度黏着。由于资源有限，对于自然语言处理（NLP）的研究十分有限，尤其是声素划分的研究。声素划分是NLP任务中的一项重要任务，识别给定单词的声素，而该领域对于Tenyidie语言的研究尚为空白。
### Innovation
本文贡献在于创建了 10,120 个声素化Tenyidie单词，并使用深度学习技术应用于所创建的语料库。分别采用了LSTM、双向LSTM（BLSTM）、双向LSTM + CRF（BLSTM+CRF）和编码器-解码器（Encoder-decoder）的深度学习架构来处理数据集。在80:10:10（训练：验证：测试）的拆分数据集上，双向LSTM模型在测试集上达到了最高的99.21%准确率。本研究将在其他NLP应用如形态学分析、词性标注、机器翻译等方面应用于Tenyidie语言，具有重要意义。
### Conclusion
本研究不仅填补了Tenyidie语言声素划分的空白，还采用深度学习技术提高了准确率，为该语言的NLP应用提供了强大的支持和工具。
## 528. `cs.CL` - 非洲自然语言处理的兴起：贡献、贡献者及其社区影响（2005-2025） [PDF](https://arxiv.org/pdf/2509.25477), [HTML](https://arxiv.org/abs/2509.25477)
### Authors
Tadesse Destaw Belay,Kedir Yassin Hussen,Sukairaj Hafiz Imam,Ibrahim Said Ahmad,Isa Inuwa-Dutse,Abrham Belete Haile,Grigori Sidorov,Iqra Ameer,Idris Abdulmumin,Tajuddeen Gwadabe,Vukosi Marivate,Seid Muhie Yimam,Shamsuddeen Hassan Muhammad
### Background
自然语言处理（NLP）正经历持续的变革，大型语言模型（LLMs）正推动着研究和实践中的日新月异的进步。通过追踪NLP研究进展并自动分析研究论文的贡献，可以深入了解该领域的性质和从业者的工作。本研究旨在探索非洲NLP（非洲NLP）的研究进展，通过回答基本的研究问题，例如：过去二十年NLP的本质如何演变？非洲NLP论文做出了哪些贡献？哪些个人和组织在非洲NLP发展中发挥了作用？利用1900篇NLP论文摘要、4900位作者与7800个人注释的贡献句子，结合基准结果进行定量分析。这些数据集及不断追踪NLP进展的网站为剖析非洲NLP研究趋势提供了有力的视角，同时有能力生成数据驱动的文献综述
### Innovation
研究采用了量化分析方法，通过1.9K篇NLP论文摘要、4.9K位作者和7.8K注释贡献句的数据集，分析非洲NLP的发展趋势和贡献。这些数据集及不断追踪NLP进展的网站提供了分析非洲NLP发展的有力工具，并具有生成数据驱动的文献综述的潜力
### Conclusion
通过量化分析，本研究能够深入了解非洲NLP的发展路径、主要贡献者和社区动态。这些数据集和持续跟踪网站提供了洞察非洲NLP研究趋势的视角，有助于数据驱动的文献综述和研究指导
## 529. `cs.CL` - LLMs中由代码引发的推理 [PDF](https://arxiv.org/pdf/2509.21499), [HTML](https://arxiv.org/abs/2509.21499)
### Authors
Abdul Waheed,Zhen Wu,Carolyn Rosé,Daphne Ippolito
### Background
大型语言模型（LLMs）的推理能力可以通过代码数据得到增强，但尚不清楚哪些代码特性对提升模型推理能力最为关键。本文通过一个系统、数据导向的方法，旨在探究这一问题。
### Innovation
作者构建了十种编程语言的平行指令数据集，并采用针对结构或语义属性的可控扰动。他们针对每种变化版本的LLM进行了五种模型家族、八种规模的微调，并对自然语言、数学和代码任务进行了评估。研究结果表明，LLM在结构变化扰动下比在语义变化扰动下更为脆弱，尤其是在数学和代码任务中。适当的事物抽象（如伪代码和流程图）和减少标记数量而不遵守原始语法可以保留甚至提高性能，即使存在误导信号的代码若表面规律存在仍能保持竞争力。此外，不同的语法风格对任务特定的增益也产生了影响，Python更倾向于自然语言推理，而Java和Rust等低级语言则更擅长数学推理。通过这种方法，研究旨在揭示代码不同属性如何影响推理，并应指导增强LLM推理能力的训练数据设计。
### Conclusion
研究结果显示，LLM对代码结构扰动更为敏感，特别是对于数学和代码任务而言。适当的抽象如伪代码和流程图可以达到与代码相同的效果，而减少标记数量但偏离原始语法也可能保持性能或有所提升。即使带有误导信号的代码在表面上仍然存在规律时，也可能保持竞争力。不同编程语言的语法风格也影响到特定任务的增益，Python更适合自然语言推理，而Java和Rust等低级语言则更擅长数学推理。
## 530. `cs.CL` - 超越分块：面向长文档的意识层析检索模型的问答系统 [PDF](https://arxiv.org/pdf/2506.06313), [HTML](https://arxiv.org/abs/2506.06313)
### Authors
Huiyao Chen,Yi Yang,Yinghui Li,Meishan Zhang,Min Zhang
### Background
长文档问题回答系统通常将文本处理为扁平序列或使用任意分段，这种处理方式未能捕捉到有助于人类理解的文本文献结构。现有的方法无法充分利用文献的深层结构以提升问答系统的性能。
### Innovation
本文提出了一种意识层析的层次框架，借助语篇结构理论（RST）来增强长文档问题回答。方法包括：专门针对长文档的语篇解析、基于大规模语言模型的语篇关系节点增强以及结构引导的层次检索。这些创新提高了模型对于不同文档类型的问答性能。
### Conclusion
在QASPER、QuALITY和NarrativeQA等数据集上的综合实验表明，本文方法相较于现有方法能够实现一致的提升。消融研究进一步证实，整合文本文献结构对提升问答系统的性能具有显著作用。
## 531. `cs.CL` - 带有验证奖励的强化学习隐性激励基大型语言模型进行正确推理 [PDF](https://arxiv.org/pdf/2506.14245), [HTML](https://arxiv.org/abs/2506.14245)
### Authors
Xumeng Wen,Zihan Liu,Shun Zheng,Shengyu Ye,Zhirong Wu,Yang Wang,Zhijian Xu,Xiao Liang,Junjie Li,Ziming Miao,Jiang Bian,Mao Yang
### Background
最近，长链推理（CoT）的进展，尤其是DeepSeek-R1所采用的Group Relative Policy Optimization算法促使人们对强化学习与可验证奖励（RLVR）在大型语言模型（LLM）中的应用产生了浓厚兴趣。尽管RLVR有可能通过自由探索提升推理能力，但其是否真能提升推理能力而非仅仅增加采样效率仍存在争议。
### Innovation
该研究系统地探讨了RLVR对LLM推理的影响。引入了新的评价指标CoT-Pass@K，涵盖最终答案和推理过程中的中间步骤，以衡量推理成功情况。研究还提出了RLVR的激励机制理论框架，证明即使仅基于答案正确性的奖励机制也能够激励正确的推理行为。实证分析表明，RLVR在训练早期即促进正确推理，并通过广泛评估验证了推理质量的显著提升。
### Conclusion
该研究提供了有力证据，证明RLVR能够增强大型语言模型的推理能力，通过对机制和性能改进提供了宝贵的洞察。
## 532. `cs.CL` - 用检索增强生成在奥林匹克级别的物理问题解决中基准测试基础模型 [PDF](https://arxiv.org/pdf/2510.00919), [HTML](https://arxiv.org/abs/2510.00919)
### Authors
Shunfeng Zheng,Yudi Zhang,Meng Fang,Zihan Zhang,Zhitan Wu,Mykola Pechenizkiy,Ling Chen
### Background
检索增强生成（RAG）和基础模型在多种任务中表现出强大的性能，但其在专家级推理能力（如解决奥赛级别的物理问题）方面的潜力尚未得到充分研究。受到学生为竞赛复习过去问题的方式启发，该研究旨在探讨RAG增强物理推理的可能性。
### Innovation
引入了PhoPile，一个专门设计用于奥林匹克级别物理问题的高质量多模态数据集，支持检索增强物理推理的系统研究。使用PhoPile，基准测试了RAG增强的基础模型，包括大型语言模型（LLMs）和大型多模态模型（LMMs），并通过多个检索器。结果显示，与物理语料库结合检索可以提高模型性能，同时也突出了进一步研究检索增强物理推理中的挑战。
### Conclusion
研究结果表明，结合检索和物理语料库可以提高模型的性能，同时也突出了进一步研究检索增强物理推理中的挑战，为进一步研究提供了动力。
## 533. `cs.CL` - Differential Information Distribution: 一项关于直接偏好优化的贝叶斯视角 [PDF](https://arxiv.org/pdf/2505.23761), [HTML](https://arxiv.org/abs/2505.23761)
### Authors
Yunjae Won,Hyunji Lee,Hyeonbin Hwang,Minjoon Seo
### Background
直接偏好优化（DPO）广泛应用于通过监督方式使语言模型符合人类偏好。然而，其日志比回报背后的原理、偏好数据集的统计结构如何影响训练动力学及其对下游能力的影响等关键问题仍不清楚。
### Innovation
作者从贝叶斯视角出发，提出了差分信息分布（DID），这是一种表示用以更新策略所需的贝叶斯证据的数据分布。通过DID的视角，作者发现DPO的日志比回报是当偏好编码了从参考策略更新到目标策略所需的差分信息时独自行得验证。作者还讨论了DPO中常见训练动力学如何源自幂律关系，以及使用DID的熵来分析训练动力学如何影响下游性能。作者观察到，学习高熵的DID可以提高开放指令跟随能力，而低熵的DID则有助于知识密集型QA。
### Conclusion
综上所述，作者的结果表明，DPO的奖励设计、训练动力学和下游能力都是学习差分信息这一自然结果的体现，既提供了一个有原则的理论基础，也提供了基于偏好的对齐的实际指导。
## 534. `cs.CL` - 结合LLMs和知识图谱：一种新颖的软件仓库相关问题解答方法 [PDF](https://arxiv.org/pdf/2412.03815), [HTML](https://arxiv.org/abs/2412.03815)
### Authors
Samuel Abedu,SayedHassan Khatoonabadi,Emad Shihab
### Background
软件仓库包含有价值的信息，能帮助理解开发过程。然而，从仓库数据中提取见解需要大量时间和技术专长。虽然软件工程聊天机器人可以支持与仓库的自然语言交互，但聊天机器人很难理解超出其训练意图的问题，并准确检索相关数据。本研究旨在通过将知识图谱与 LLMS（大型语言模型）集成，改进其在回答仓库相关问题时的准确性。我们采取两步法：从仓库数据构建知识图谱，并将知识图谱与LLM结合，处理自然语言问题和答案。我们设计了150个不同复杂性的问题，并在五个流行的开源项目上进行了评估。初步结果表明，主要的错误来自于LLM的推理能力。因此，我们应用少量链式思维提示，将准确率提高到84%。还与基准（MSRBot和GPT-4o-search-preview）进行了对比，我们的方法明显更好。在包含20名参与者的基于任务的研究中，参与者使用我们的方法完成任务更正确且更快，并认为该方法有用。研究发现表明，LLM 和知识图谱是使仓库数据可访问的有效解决方案。
### Innovation
本研究提出了一种创新方法，即通过结合 LLMS 和知识图谱来提高对仓库相关问题的准确回答。尤其是在问答过程中应用少量链式思维提示，显著提高了准确率，达到了84%。相比基准方法（MSRBot 和 GPT-4o-search-preview），我们的方法表现更优。此外，通过任务研究和用户反馈，验证了该方法的有效性和实用性。
### Conclusion
本研究证明了利用 LLMS 和知识图谱可以有效地使仓库数据更易于访问。通过构建知识图谱和结合少量链式思维提示的方法，能够显著提高软件仓库相关问题的回答准确率，并在实际使用中表现出更好的效果。
## 535. `cs.CL` - Sparkle: 在视觉语言模型中掌握基础空间能力引发空间推理的泛化 [PDF](https://arxiv.org/pdf/2410.16162), [HTML](https://arxiv.org/abs/2410.16162)
### Authors
Yihong Tang,Ao Qu,Zhaokai Wang,Dingyi Zhuang,Zhaofeng Wu,Wei Ma,Shenhao Wang,Yunhan Zheng,Zhan Zhao,Jinhua Zhao
### Background
视觉语言模型（VLMs）在许多任务中表现出色，但在空间推理方面经常出现问题，而空间推理对于导航和物理环境中的交互是必要的。尽管许多空间推理任务依赖于基本的二维（2D）技能，但我们的评估表明，最先进的VLMs在复杂的空间问题上给出了不合理的或错误的答案，包括人类可以轻松解决的基本路径规划任务。因此，需要通过仅针对基本的空间能力来提升VLMs的2D空间推理能力。为此，研究者将2D空间推理分解为三个核心组件：方向理解、距离估计和定位，以期掌握这些技能能显著提高复杂空间任务的性能，并在现实世界场景中泛化。
### Innovation
本文提出了Sparkle框架，该框架通过生成合成数据来提供定向监督，涵盖三个基本的空间能力（方向理解、距离估计和定位）。利用此框架，创建了用于每个能力的指令数据集。实验表明，通过Sparkle调优的VLMs不仅在基本任务上表现更好，还在复合和未知分布的现实世界空间推理任务上表现出色。这些结果表明，通过合成数据增强基本的空间技能有效推动了复杂空间推理的进步，提供了一种系统的策略来提升VLMs的空间理解能力。源代码已开源。
### Conclusion
通过合成数据增强基本的空间技能能有效提升复杂的空间推理能力，这一策略提供了一种系统的方法来提高VLMs的空间理解能力。研究结果表明，Sparkle框架在提升VLMs的基本空间技能方面具有显著效果，并展示了其在复杂空间推理任务中的泛化能力。
## 536. `cs.CL` - DrKGC: Dynamic Subgraph Retrieval-Augmented LLMs for Knowledge Graph Completion across General and Biomedical Domains [PDF](https://arxiv.org/pdf/2506.00708), [HTML](https://arxiv.org/abs/2506.00708)
### Authors
Yongkang Xiao,Sinian Zhang,Yi Dai,Huixue Zhou,Jue Hou,Jie Ding,Rui Zhang
### Background
知识图谱完成（KGC）的目标是通过利用现有三元组和文本信息来预测知识图谱（KGs）中的缺失三元组。最近，生成式大规模语言模型（LLMs）在图任务中被越来越多地采用。然而，当前的方法通常以文本形式编码图上下文，未能全面利用LLMs对图结构感知和推理的潜力。
### Innovation
提出了一种名为DrKGC的模型，该模型采用灵活的轻量化模型训练策略来学习知识图谱中的结构嵌入和逻辑规则。它利用一种新颖的自底向上的图检索方法，根据学习到的规则从查询中提取子图。最后，图卷积网络（GCN）适配器使用检索到的子图来增强结构嵌入，并将这些嵌入集成到提示中以进行有效的LLMs微调。实验证明，DrKGC在一般领域和生物医学领域的两个标准数据集上表现出优越性能。此外，在生物医学领域进行的实际案例研究突显了其可解释性和实用价值。
### Conclusion
实验结果表明，DrKGC在两个通用领域基准数据集和两个生物医学数据集上均表现出色。此外，在生物医学领域的实际案例研究中展示了其可解释性和实用价值。
## 537. `cs.CL` - CRUST-Bench：C到安全Rust编译的综合基准 [PDF](https://arxiv.org/pdf/2504.15254), [HTML](https://arxiv.org/abs/2504.15254)
### Authors
Anirudh Khatry,Robert Zhang,Jia Pan,Ziteng Wang,Qiaochu Chen,Greg Durrett,Isil Dillig
### Background
现代化和提升安全性是维护遗留C代码的重要目标，同时需要增强与现代Rust生态系统的互操作性。然而，目前还没有用于评估系统能否将C代码转换为符合安全标准并可通过一组测试用例的Rust代码的基准数据集。为此，本文介绍了CRUST-Bench，这是一个由100个C代码仓库组成的基准数据集，每个仓库都配有人工编写的符合安全标准的Rust接口以及可用于验证编译正确性的测试用例。与仅考虑孤立函数相比，通过考虑整个代码库，CRUST-Bench捕捉到了跨多个文件存在依赖关系的复杂项目的翻译挑战。提供的Rust接口确保符合Rust的规范做法和内存安全性，而配套的测试用例则确保功能正确性。评估结果显示，最先进的大型语言模型在生成安全且符合规范的Rust代码方面仍面临挑战。此外，数据集揭示了大型语言模型在C到安全Rust编译过程中通常所犯的错误类型。
### Innovation
CRUST-Bench为评估C到安全Rust的编译提供了首个基准数据集。通过考虑整个代码库，它能够捕捉到复杂项目翻译中的挑战。与现有方法相比，提供的Rust接口确保遵循Rust的规范做法和内存安全性，而测试用例则确保功能正确性。该基准数据集还包括关于不同最先进的模型和方法如何处理C到Rust编译的评估结果，揭示了这些模型在编译过程中通常所犯的错误类型。
### Conclusion
CRUST-Bench为改进C到Rust编译系统的性能、帮助复杂场景推理以及从C语言向Rust等确保内存安全的语言迁移提供机会。通过对CRUST-Bench的进步，有望构建出能够更好地处理复杂的跨文件依赖性和代码迁移的系统。
## 538. `cs.CL` - MathArena：在未受污染的数学竞赛中评估LLMs [PDF](https://arxiv.org/pdf/2505.23281), [HTML](https://arxiv.org/abs/2505.23281)
### Authors
Mislav Balunović,Jasper Dekoninck,Ivo Petrov,Nikola Jovanović,Martin Vechev
### Background
大型语言模型（LLMs）的推理能力迅速提升，在数学基准测试中取得了显著的进步。然而，许多常用的评估数据集（例如AIME 2024）在网上非常容易获取，这使得区分真实的推理能力和潜在的记忆能力变得困难。此外，现存的这些基准测试并没有评估证明写作能力，而这对于许多数学任务是至关重要的。针对这些问题，作者引入了MathArena，一个新的基于如下关键洞察的基准测试：重复出现的数学竞赛提供了高质量、具有挑战性的题库，可以用于实时评估LLMs。通过在发布新问题的第一时间评估模型，从而有效避免了污染的风险。使用这个框架，作者发现了AIME 2024存在污染，但在更困难的竞赛（如CMIMC 2025）上，顶级模型展示了惊人的推理能力。MathArena还是第一个评估证明写作能力的基准测试。在IMO 2025上，顶级模型的表现略低于40%，这既显示了进步，也表明还有改进的空间。迄今为止，已经在七个竞赛中评估了超过50个模型，总共解决了162个问题。作为一个持续发展的基准测试，MathArena将跟踪新发布的竞赛，以确保对数学推理能力进行严格的和及时的评估。
### Innovation
引入了MathArena，这是一种基于不断更新的高质量数学竞赛题目的实时评估框架，可以有效避免记忆带来的污染问题。同时，MathArena也是第一个专门评估证明写作能力的基准测试。该框架在检测到AIME 2024存在污染波动的同时，也在更难的CMIMC 2025竞赛上实现了顶级模型的出色推理能力展示。并且通过IMO 2025的数据分析，发现尽管取得了一定的进步，但也存在很大的改进空间。
### Conclusion
在不断更新的MathArena框架内，已评估了超过50个模型和162个问题。MathArena将作为持续发展的基准测试工具，不断跟踪LLMs在新发布的分数分析。这确保了对数学推理能力进行严格的和更新及时的评价体系。
## 539. `cs.CL` - 通过标记压缩实现高效全切片病理视觉问答系统 [PDF](https://arxiv.org/pdf/2507.14497), [HTML](https://arxiv.org/abs/2507.14497)
### Authors
Weimin Lyu,Qingqiao Hu,Kehan Qi,Zhan Shi,Wentao Huang,Saumya Gupta,Chao Chen
### Background
病理学中的全切片图像（WSIs）可能达到10,000 x 10,000像素，这为多模态大语言模型（MLLM）带来了显著挑战，因为其需要处理长上下文和高计算需求。现有的方法主要集中在patch级别的分析或使用CLIP模型进行多实例学习的切片级别分类，但这些方法缺乏生成能力，无法满足视觉问答（VQA）的需求。最近使用MLLM的VQA方法通过直接向语言模型输入成千上万个patch标记来解决这一问题，导致了资源消耗过大。为了应对这些限制，本文提出了一种通过标记压缩实现全切片图像VQA的Token Compression Pathology LLaVA (TCP-LLaVA)，从而首次实现了一种能在大语言模型中有效减少输入长度和计算成本的多模态方法。
### Innovation
TCP-LLaVA引入了一组可训练的压缩标记，通过模态压缩模块聚合视觉和文本信息，模仿BERT中的[CLS]标记机制。只有这些压缩标记被发送到LLM进行答案生成，这显著降低了输入长度和计算成本。实验结果表明，TCP-LLaVA在多个TCGA肿瘤亚型的VQA准确性上超越了现有基于MLLM的基线方法，同时将训练资源消耗大幅减少.
### Conclusion
TCP-LLaVA通过标记压缩实现了全切片图像的VQA任务，相比之前的模型在降低输入长度和计算成本方面有了显著改进，并且在多个肿瘤亚型的VQA准确性上表现出色，证明了其作为一种有效的解决方案的能力。
## 540. `cs.CL` - AI生产力指数（APEX） [PDF](https://arxiv.org/pdf/2509.25721), [HTML](https://arxiv.org/abs/2509.25721)
### Authors
Bertie Vidgen,Abby Fennelly,Evan Pinnix,Chirag Mahapatra,Zach Richards,Austin Bridges,Calix Huang,Ben Hunsberger,Fez Zafar,Brendan Foody,Dominic Barton,Cass R. Sunstein,Eric Topol,Osvald Nitski
### Background
现有基准测试通常集中在编码任务上，未能充分测试与经济价值相关的高级能力。本文介绍了一个新的基准测试——AI生产力指数(APEX)，旨在评估前沿AI模型是否能执行具有高经济价值的知识工作。
### Innovation
APEX包括200个测试案例，涵盖四个领域：投资银行、管理咨询、法律和初级医疗服务。该指数的独特之处在于它不仅仅测试编码任务，还涵盖了更能反映经济相关工作能力的领域，通过三个步骤完成，包括专家提供真实任务描述、创建评估模型响应的标准。
### Conclusion
在23个前沿模型中，GPT 5表现最佳，其次是Grok 4和Gemini 2.5 Flash。开源模型Qwen 3 235B是表现最好的开源模型且整体排名第七。尽管一些顶级模型的性能接近人类专家，但仍存在显著差距，这表明有必要更好地衡量模型生成具有经济价值工作的能力。
## 541. `cs.CL` - PurpCode: 安全代码生成的推理 [PDF](https://arxiv.org/pdf/2507.19060), [HTML](https://arxiv.org/abs/2507.19060)
### Authors
Jiawei Liu,Nirav Diwan,Zhe Wang,Haoyu Zhai,Xiaona Zhou,Kiet A. Nguyen,Tianjiao Yu,Muntasir Wahed,Yinlin Deng,Hadjer Benkraouda,Yuxiang Wei,Lingming Zhang,Ismini Lourentzou,Gang Wang
### Background
当前，开发安全代码并防范恶意网络活动的需求日益增长。现有的代码生成模型在安全性和抵御恶意活动方面存在不足。PurpCode通过引入两个阶段的训练方法——规则学习和强化学习，旨在提升模型的安全性，同时保持模型的开发效率。
### Innovation
PurpCode引入了一种新的训练方法，分为规则学习和强化学习两个阶段，通过这种方式，模型能够更好地理解和遵循网络安全规则，生成无漏洞的代码，并避免促进恶意网络活动。通过内部红队行动，创建了全面且覆盖率高的安全提示，以训练模型。基于这一方法开发出了一款32B规模的推理型代码生成模型，展示了在网络安全方面的领先地位。
### Conclusion
PurpCode方法通过两个阶段的训练显著提升了模型的安全性，特别是在代码生成和网络安全知识方面。该方法在模型拒绝过度实例中表现出色，同时保持了模型在代码生成和一般性安全知识普及等方面的实用性。该模型在与前沿模型的比较中表现出色，展示了其在安全代码生成领域的先进性。
## 542. `cs.CL` - 通过自我意识保护LLMs [PDF](https://arxiv.org/pdf/2508.02961), [HTML](https://arxiv.org/abs/2508.02961)
### Authors
Boshi Huang,Fabio Nonato de Paula
### Background
论文介绍了一个新颖的自我意识防御机制，用于对抗大型语言模型（LLMs）所面临的提示注入攻击。传统的防御方法依赖于外部分类器，而本方法利用LLMs固有的推理能力来进行自我保护。
### Innovation
论文提出了一种框架，结合了元认知和仲裁模块，使LLMs能够自主评估和调节自己的输出。这种方法在七种最先进的LLMs上使用两个数据集（AdvBench和Prompt-Injection-Mixed-Techniques-2024）进行了评估，结果显示在模型和数据集上均有显著提高的防御成功率，部分在增强模式下实现了完美的和近完美的防御。论文还分析了防御成功率提高与计算开销之间的权衡。
### Conclusion
自我意识方法提供了一种轻量级、成本效益高的解决方案，用于提升LLMs的伦理，特别适用于各种平台上的GenAI用例。
## 543. `cs.CL` - AlgoTune：语言模型能否加速通用数值程序？ [PDF](https://arxiv.org/pdf/2507.15887), [HTML](https://arxiv.org/abs/2507.15887)
### Authors
Ori Press,Brandon Amos,Haoyu Zhao,Yikai Wu,Samuel K. Ainsworth,Dominik Krupke,Patrick Kidger,Touqir Sajed,Bartolomeo Stellato,Jisun Park,Nathanael Bosch,Eli Meril,Albert Steppi,Arman Zharmagambetov,Fangzhao Zhang,David Perez-Pineiro,Alberto Mercurio,Ni Zhan,Talor Abramovich,Kilian Lieret,Hanlin Zhang,Shirley Huang,Matthias Bethge,Ofir Press
### Background
尽管语言模型（LM）的能力已经取得了进步，但目前的评估主要聚焦于模型在人类已解决的任务上的表现，这包括编程（Jimenez等，2024）和数学（Glazer等，2024）领域。我们因此提出了一种开放性基准测试，用以测试模型设计和实现算法的能力。在这个基准测试中，我们要求模型编写能够高效解决计算上具有挑战性的问题的代码，涉及到计算机科学、物理和数学领域。基准测试包括由领域专家收集的154个编程任务，以及一种验证和测量模型生成的解决方案代码性能的框架，与流行的开源软件包中的参考实现进行对比。此外，我们还开发了一个基础模型代理AlgoTuner，并在一系列前沿模型上评估其性能。AlgoTuner 使用一个简单的循环，该循环编辑、编译和运行代码，进行性能分析，验证测试中的正确性，并选择最快的有效版本。与使用 SciPy、sk-learn 和 CVXPY 等库的参考解算器相比，AlgoTuner 达到了1.72倍的平均加速效果，但我们也发现，当前模型未能发现算法创新，而是倾向于进行表面级别的优化。
### Innovation
我们提出了一个名为AlgoTune的基准测试，用以评测模型在设计和实现在计算机科学、物理和数学领域中的高效算法方面的能力。我们开发了一个基础模型代理AlgoTuner，并评估了其在一系列前沿模型上的表现。AlgoTuner通过简单的循环来编辑代码，编译，运行代码，分析性能，验证测试中代码的正确性，并选择最快速有效的版本。我们使用流行的开源软件包中的参考实现作为比较基准，评估模型的性能。结果显示，AlgoTuner相比于参考解算器实现了平均1.72倍的性能提升。此外，我们揭示了当前模型只进行表面优化而非寻找创新性算法的问题，这为模型的未来发展方向提供了方向。
### Conclusion
AlgoTune可能激发出一种模型代理，它能够表现出超越顶级人类表现的创造性问题解决能力。通过对AlgoTune的开发和评估，我们希望推动语言模型的未来研究和发展方向，使其能够产生真正的创新性算法，而不仅仅是对表面优化。
## 544. `cs.CV` - LVTINO: LAtent Video consisTency INverse sOlver for High Definition Video Restoration [PDF](https://arxiv.org/pdf/2510.01339), [HTML](https://arxiv.org/abs/2510.01339)
### Authors
Alessio Spagnoletti,Andrés Almansa,Marcelo Pereyra
### Background
现有的计算成像方法越来越多地依赖强大的生成扩散模型来解决图像恢复的挑战性任务。特别地，最先进的零样本图像逆解算器利用提炼的文本到图像的潜在扩散模型（LDMs）实现了前所未有的准确性和感知质量，同时具有高计算效率。然而，将这些进展扩展到高清晰度视频恢复仍然是一个重大挑战，因为在恢复精细空间细节的同时捕捉微妙的时间依赖性是一个难点。因此，简单的逐帧应用图像LDM先验的方法往往会导致时间不一致的重构。
### Innovation
我们通过利用近期在视频一致性模型（VCMs）方面的进展，这些模型将视频潜在扩散模型提炼成快速生成器，明确捕捉时间因果性。在此基础上，我们提出了LVTINO，这是第一个用于高清晰度视频恢复的零样本或即插即用逆解算器，其中的先验编码由VCMs提供。我们的调谐机制绕过了自动微分的需要，并仅通过几次神经功能评估即可实现最先进的视频重构质量，同时确保强烈的测量一致性并在帧间实现平滑的时间过渡。
### Conclusion
大量实验表明，LVTINO在一系列视频逆问题上显著提升了感知质量，超过了当前逐帧应用图像LDMs的方法，确立了重建忠实度和计算效率的新基准。
## 545. `cs.CL` - 将外部知识注入推理过程以增强检索增强生成 [PDF](https://arxiv.org/pdf/2507.19333), [HTML](https://arxiv.org/abs/2507.19333)
### Authors
Minghao Tang,Shiyu Ni,Jiafeng Guo,Keping Bi
### Background
检索增强生成（RAG）已被广泛应用于通过外部知识增强大语言模型（LLMs），以应对知识密集型任务。然而，其有效性常常被低质量（即噪声）检索段落所削弱。提高LLMs对这类噪声的鲁棒性对于提高RAG系统的可靠性至关重要。最近的进展让LLMs具备了强大的推理和自我反思能力，使它们能够识别并修正其推理过程中的错误。这项工作借鉴了这种能力，提出了一种简单有效的“段落注入”方法，旨在明确将检索到的段落纳入到LLMs的推理过程中，以增强模型识别和抵制噪声段落的能力。这项方法使用BM25作为检索器，在一般RAG设置下进行验证。实验结果显示，在增强推理的大语言模型上，段落注入显著提升了整体RAG性能。进一步分析表明，即使在随机噪声和反事实噪声下，段落注入也能持续提高系统的鲁棒性。控制实验还证实，段落注入也能有效利用有益的段落。这一发现表明，将段落纳入LLMs的推理过程是一条具有前景的研究路径，用于构建更鲁棒的RAG系统。代码可以在指定的链接处找到。
### Innovation
提出了一种名为“段落注入”的简单有效方法，旨在将检索到的段落直接融入到大语言模型的推理过程中。该方法利用LLMs强大的推理和自我反思能力，以帮助它们识别和抵御低质量检索段落。通过对增强推理的大语言模型和多种事实型问答数据集的实验验证，证明了段落注入可以显著提升RAG的整体性能和鲁棒性，即使在提供无关或误导信息的检索场景中也是如此。进一步的研究还证实，段落注入可以有效利用有益的段落信息。
### Conclusion
该研究认为将段落直接纳入LLMs的推理过程是改进RAG系统鲁棒性的有前景方向，而研究结果表明“段落注入”方法在提升RAG系统性能方面表现出色。未来可以进一步探索如何优化“段落注入”的具体机制和应用场景，使RAG系统能够在更为复杂和多样化的知识场景中更加可靠地运行。
## 546. `cs.CL` - 伪数据质量：重新思考预训练LLM的分类器基数据质量过滤 [PDF](https://arxiv.org/pdf/2510.00866), [HTML](https://arxiv.org/abs/2510.00866)
### Authors
Thiziri Nait Saada,Louis Bethune,Michal Klein,David Grangier,Marco Cuturi,Pierre Ablin
### Background
大规模语言模型在质量参差不齐的网络爬取数据集上进行预训练，并且数据过滤变得至关重要。常用方法是基于分类器的质量过滤（CQF），它通过训练一个二元分类器来辨别预训练数据和一小部分高质量数据。该方法将每个预训练文档的质量评分定义为分类器的评分，并仅保留得分最高的文档。
### Innovation
本研究深入分析了CQF，揭示了虽然CQF可以改善下游任务的表现，但它不一定能提升高质数据集上的语言模型性能。研究发现，CQF实际上也在过滤掉高质量的数据集，因此其评估的数据质量没有实际意义。进一步将使用CQF训练的模型与通过随机令牌置换获得的不断增加质量水平的合成数据上训练的模型进行比较，发现了显著不同的趋势。
### Conclusion
研究挑战了CQF捕捉有意义的数据质量概念的观点，并提出需要重新思考预训练LLM的数据质量过滤方法。
## 547. `cs.CV` - 基于图像风格提取的图像生成 [PDF](https://arxiv.org/pdf/2510.01347), [HTML](https://arxiv.org/abs/2510.01347)
### Authors
Shuochen Chang
### Background
基于文本到图像生成模型的任务在实际应用场景中有广泛的应用，但由于精细风格难以通过自然语言精确描述和控制，以及传统的文本引导生成中的指导信息难以直接与风格参考图像中的风格条件对齐，因此本文旨在通过从单个给定的风格参考图像中获取精细的风格表示，并将其注入生成模型的生成体中，从而实现基于文本提示的精确可控的风格化图像生成，而不改变下游生成模型的结构框架。
### Innovation
本文提出了一种基于图像风格提取的三阶段训练图像生成方法，该方法利用风格编码器和风格投影层来对齐风格表示和文本表示，从而实现基于文本提示的精细风格引导生成。此外，该研究构建了Style30k-captions数据集，其样本包含三幅图像、风格标签和文本描述，用于在此实验中训练风格编码器和风格投影层。
### Conclusion
通过这种基于图像风格提取的方法，可以实现精细控制的风格化图像生成，提升文本到图像生成模型的生成能力。
## 548. `cs.CL` - 欧几里得之礼：通过几何替代任务提升视觉语言模型的空间感知与推理能力 [PDF](https://arxiv.org/pdf/2509.24473), [HTML](https://arxiv.org/abs/2509.24473)
### Authors
Shijie Lian,Changti Wu,Laurence Tianruo Yang,Hang Yuan,Bin Yu,Lei Zhang,Kai Chen
### Background
空间智力涵盖了诸如可视化和变换形状、心理旋转物体、判断相对位置和包含关系以及估计数量等丰富的技能。但是，对于多模态大语言模型（MLLMs）来说，处理欧几里得几何问题依然是一个关键但尚未解决的挑战。为了弥合这一差距，我们提出将欧几里得几何问题解决视为一种代理任务来进行。这需要构建一个专门用于解析和应用欧几里得原理的多模态数据集，通过这一过程提升模型的空间推理能力。
### Innovation
我们精心构建了一个名为Euclid30K的多模态数据集，包含约3万个平面和立体几何问题。通过采用Group Relative Policy Optimization (GRPO) 方法微调Qwen2.5VL家族和RoboBrain2.0家族模型，激发模型识别形状、计数和实体关联，并利用欧几里得原理进行多步演绎推理。实验表明，改进后的模型在四个空间推理基准（Super-CLEVR、Omni3DBench、VSI-Bench和MindCube）上实现了显著的零样本提升，无需额外的任务特定调整。特别地，在训练Euclid30K数据集后，所有评估模型的平均VSI-Bench准确率从34.5%提升至40.5%，增长了5.5个百分点，其中RoboBrain2.0-Euclid-7B模型准确率达到49.6%，超越了当时的前一代模型。据我们所知，这是首次系统性地证明通过专注于几何训练能够赋予视觉语言模型广泛转移的空间技能。相关代码和Euclid30K数据集可以在以下网址获取。
### Conclusion
我们的研究表明，通过几何导向的微调，可以大幅提升视觉语言模型的空间感知和推理能力，这展示了多模态大语言模型在空间智能方面的潜在能力。
## 549. `cs.CV` - DisCo: 使用多样性约束进行多个人生成的强化学习 [PDF](https://arxiv.org/pdf/2510.01399), [HTML](https://arxiv.org/abs/2510.01399)
### Authors
Shubhankar Borse,Farzad Farhadzadeh,Munawar Hayat,Fatih Porikli
### Background
当今最先进的文本转图像模型在逼真度方面表现出色，但在处理多人输入时却存在问题，如复制面部、合并身份和错误计数个体。为解决这一问题，作者提出了一种全新的方法DisCo，这是一种使用多样性约束直接优化多个人生成中身份多样性的强化学习框架。
### Innovation
DisCo使用Group-Relative Policy Optimization (GRPO)直接优化多样性，通过复和性奖励机制实现：(i) 抑制图像内面部相似性，(ii) 防止样本间重复身份，(iii) 保证准确的个体计数，(iv) 通过人类偏好评分保持视觉保真度。采用单一阶段教学策略逐步稳定模型，无需额外注解。DisCo在DiverseHumans测试集中表现出显著的性能，超越了开源和私有方法，同时保持良好的感知质量。
### Conclusion
研究结果表明，DisCo提供了一种可扩展且无需注解的解决方案，解决了生成模型中的长期身份危机，并为复和性多个人生成设定了新的基准。
## 550. `cs.CL` - DynaGuard: 用户自定义策略的动态护栏模型 [PDF](https://arxiv.org/pdf/2509.02563), [HTML](https://arxiv.org/abs/2509.02563)
### Authors
Monte Hoover,Vatsal Baherwani,Neel Jain,Khalid Saifullah,Joseph Vincent,Chirag Jain,Melissa Kazemi Rad,C. Bayan Bruss,Ashwinee Panda,Tom Goldstein
### Background
监护模型用于监督和管理面向用户的聊天机器人输出，确保符合行为准则并检测不良行为。标准监护模型如LlamaGuard只能检测预定义的静态危害类别。因此，它们适用于有限的应用领域，无法处理标准监护模型未涵盖的不同应用程序领域。
### Innovation
提出了动态监护模型，这些模型可以根据用户定义的策略评估文本，使其适用于标准监护模型无法覆盖的不同应用领域。动态监护模型能够快速检测政策违规行为或使用逻辑推理来阐明和验证模型输出。相较于静态模型，动态模型在静态危害类别检测方面的准确性相当，但在处理自由形式政策时的准确性接近最先进的逻辑推理模型，且耗时更短。
### Conclusion
动态监护模型不仅与静态模型在静态危害类别检测方面相当，还能以较低的时间成本有效检测自由形式政策的违反情况。
## 551. `cs.CL` - 行为估计的机制可解释性：EAP-IG的方差分析 [PDF](https://arxiv.org/pdf/2510.00845), [HTML](https://arxiv.org/abs/2510.00845)
### Authors
Maxime Méloux,François Portet,Maxime Peyrard
### Background
当前，确保可信的人工智能需要超越仅仅关注黑箱性能指标，而是深入理解模型的内部计算过程。机制可解释性（MI）旨在通过识别模型背后算法机制来满足这一需求。然而，MI的科学严谨性取决于其发现的可靠性。本文作者认为，诸如电路发现这样的可解释性方法应被视为统计估算器，需要考虑方差和稳健性问题。为了说明这种统计框架，作者详细分析了当前最先进的电路发现方法：EAP-IG的稳定性，通过对控制扰动的全面评估，包括输入重采样、提示改写、超参数变化以及因果分析中的噪声注入，来评估其方差和稳健性。结果显示，EAP-IG表现出高度结构方差和对超参数的敏感性，质疑其结果的稳定性。
### Innovation
本文引入了将机制可解释性视为统计估计的概念，并通过全面的控制扰动分析（包括输入重采样、提示改写、超参数变化和因果分析中的噪声注入）对EAP-IG方法的方差和稳健性进行了系统评估。这一研究展示了机制可解释性方法在统计性能上的不足，为该领域的未来研究提供了重要洞见。
### Conclusion
通过系统的稳定性分析，本文揭示了EAP-IG方法在结构性方差和对超参数的高敏感性，由此质疑了方法结果的稳定性。基于这些结果，作者从促进统计严密性和科学严谨性的角度出发，给出了可解释性领域的最佳实践建议，强调应常规报告稳定性指标。
## 552. `cs.CV` - 基于跨模态对齐轨迹的视觉语言模型微调数据选择 [PDF](https://arxiv.org/pdf/2510.01454), [HTML](https://arxiv.org/abs/2510.01454)
### Authors
Nilay Naharas,Dang Nguyen,Nesihan Bulut,Mohammadhossein Bateni,Vahab Mirrokni,Baharan Mirzasoleiman
### Background
数据高效学习的目标是通过在更小的、最具信息性的训练子集上训练模型来消除大型训练数据集中的冗余性。已有大量研究在视觉模型和大规模语言模型中进行了数据选择的探索，但在大规模视觉语言模型（LVLMs）中该领域仍然被严重忽视。当前，没有任何方法能在不同子集大小上超过随机选择的表现。
### Innovation
该研究首次提出了基于跨模态对齐轨迹的数据高效指令微调方法XMAS。XMAS通过聚类具有相似跨模态注意力矩阵奇异值轨迹的示例来构建训练子集，从而减少大规模LVLM训练数据的冗余。XMAS在不牺牲性能的前提下有效清除了LLaVA-665k和Vision-Flan数据集中50%和85%的样本数据，同时比最佳基线方法在LLaVA-665k数据集上降低了30%的数据量。
### Conclusion
对于LLaVA-1.5-7B模型，XMAS在10个下游基准测试上完全保持了性能，同时加速了训练过程1.2倍。XMAS为LVLMs的数据高效训练提供了一种有效的方法。
## 553. `cs.CV` - EvoStruggle: 捕捉不同活动和技能水平下挣扎演变的数据集 [PDF](https://arxiv.org/pdf/2510.01362), [HTML](https://arxiv.org/abs/2510.01362)
### Authors
Shijia Feng,Michael Wray,Walterio Mayol-Cuevas
### Background
了解人在技能习得过程中遇到困难的时间点对于优化人类学习和开发有效的辅助系统至关重要。随着技能的发展，遇到困难的类型和频率会发生变化，理解这一演变对于确定用户的当前学习阶段至关重要。然而，现有的操作数据集没有关注挣扎随时间的变化。因此，本文收集了一个用于识别挣扎的数据集，包含61.68小时的视频记录、2,793段视频和5,385个标注的挣扎时间段，由76名参与者完成。该数据集包括18项任务，分为四类不同的活动——系绳结、折纸、七巧板拼图和洗牌纸牌，每项任务重复五次以捕获技能的发展。
### Innovation
本文定义了挣扎识别问题为一个时间动作定位任务，专注于识别和精确定位具有起始和结束时间的挣扎片段。实验结果显示，时间动作定位模型可以成功地学习检测挣扎线索，即使在对未见过的任务或活动进行评估时也是如此。模型在任务通用化上的mAP为34.56%，在活动通用化上的mAP为19.24%，表明挣扎是跨不同技能任务的可转移概念但仍然面临挑战。本数据集可在这个网址 https:// 获取。
### Conclusion
挣扎识别在不同类型的任务和活动中仍然是一个具有挑战性的问题，但时间动作定位模型已经显示出一定的学习能力，未来可以在改进挣扎检测方面取得进一步进展。
## 554. `cs.CV` - SPUS：PDEs领域的轻量级高参数效率基础模型 [PDF](https://arxiv.org/pdf/2510.01370), [HTML](https://arxiv.org/abs/2510.01370)
### Authors
Abu Bucker Siddik,Diane Oyen,Alexander Most,Michal Kucer,Ayan Biswas
### Background
现有的基于复杂变压器架构的偏微分方程（PDE）基础模型通常计算和参数复杂度较高。本文引入一种紧凑且高效的统一神经算子——Small PDE U-Net Solver（SPUS），专门用于解决各种形式的PDE。不同于现有的基础模型主要依赖于大型复杂的变压器架构，SPUS采用了轻量级的余块U-Net结构，并以新颖的方式作为基础模型架构使用。
### Innovation
SPUS创新地采用了一种简单的自回归预训练策略，该策略能够学习基础物理行为。SPUS在流体动力学PDEs上进行预训练，并在六个不同的下游PDE任务上进行评估，结果表明SPUS能够实现最先进的泛化性能，同时需要更少的参数和微调数据，显示出其在解决不同PDE系统时的高参数效率潜力。
### Conclusion
SPUS通过轻量级的余块U-Net架构在多个下游任务上实现了最先进的泛化性能，同时保持了极高的参数效率。这表明SPUS是一个具有广泛应用前景的新的高性能PDE基础模型。
## 555. `cs.CV` - GeoSURGE: 使用层次地理嵌入进行语义融合的世界视觉地理本地化 [PDF](https://arxiv.org/pdf/2510.01448), [HTML](https://arxiv.org/abs/2510.01448)
### Authors
Angel Daruna,Nicholas Meegan,Han-Pang Chiu,Supun Samarasekera,Rakesh Kumar
### Background
世界视觉地理本地化旨在仅通过图像的视觉内容确定地球上任何位置的地理坐标。尽管取得了很大进展，但用地理学学习表示视觉地理本地化仍然是一个活跃的研究领域。本文将地理本地化表述为对查询图像的视觉表示与学习的地理表示进行对齐。该研究引入了一种高效方法，将查询图像的外观特征与其语义分割图相融合，构建了一个稳健的视觉表示。
### Innovation
本文提出了一种新的地理表示方法，明确将世界建模为地理嵌入的层级结构。此外，还提出了一种有效融合查询图像外观特征与其语义分割图的方法，从而形成 robust 的视觉表示。实验结果表明，本文方法在五个基准数据集的 22 个指标中优于之前的最佳方法和最近的大型视觉-语言模型。
### Conclusion
本文的主要实验结果显示，在五个基准数据集的 25 个指标中有 22 个指标优于之前的最佳方法和最近的大型视觉-语言模型。额外的消融研究支持通过将地理和视觉表示相结合可以获得这些改进的观点。
## 556. `cs.CV` - 从视频到索引知识图谱——多模态内容分析与理解的方法结合框架 [PDF](https://arxiv.org/pdf/2510.01513), [HTML](https://arxiv.org/abs/2510.01513)
### Authors
Basem Rizk,Joel Walsh,Mark Core,Benjamin Nye
### Background
多模态内容分析存在计算复杂、工程量大等问题。虽然有许多基于预训练模型的工作，对静态数据进行处理，但将这些开源模型与复杂的视频数据整合仍相对具有挑战性。
### Innovation
本文提出了一种框架，旨在高效地设计多模态内容分析管道。该框架将预训练模型组合以将视频转换为时间上的半结构化数据格式，并进一步将其转换为支持查询的可扩展帧索引知识图谱，从而能够动态地通过互动方式集成新的领域特定知识，提高持续学习能力，实现多模态内容的自动化分析和理解。
### Conclusion
该框架能够有效地支持多模态内容的分析，并提供了一个可查询的知识图谱表示，支持动态学习和新知识的集成。
## 557. `cs.CV` - 预训练MLLMs的视觉生成能力提升 [PDF](https://arxiv.org/pdf/2510.01546), [HTML](https://arxiv.org/abs/2510.01546)
### Authors
Hanyu Wang,Jiaming Han,Ziyan Yang,Qi Zhao,Shanchuan Lin,Xiangyu Yue,Abhinav Shrivastava,Zhenheng Yang,Hao Chen
### Background
多模态大型语言模型（MLLMs）已经成功将语言模型的应用扩展到了视觉理解领域，最近的研究致力于构建同时支持理解和生成的统一MLLM。然而，构建此类模型依然充满挑战：混合方法结合了连续嵌入和扩散或流动目标，虽能生成高质量图像但破坏了自回归范式，而纯粹的自回归方法则统一了文本和图像预测，但在语义对齐和像素级保真度之间存在权衡。
### Innovation
本文介绍了Bridge，一种通过Mixture-of-Transformers架构增强预训练视觉理解模型的纯粹自回归统一MLLM，能够在单一下一个令牌预测框架中实现图像理解和生成。为进一步提升视觉生成保真度，Bridge提出了一种语义到像素的离散表示方法，通过结合紧凑的语义令牌与精细的像素令牌，实现了强语义对齐和视觉细节的精细描述，仅增加了7.9%的序列长度。
### Conclusion
广泛的跨多种多模态基准实验表明，Bridge在理解和生成基准上达到了竞争或优于先前统一MLLMs的结果，同时需要更少的训练数据和减少的训练时间。
## 558. `cs.CV` - MATCH: 多面向自适应拓扑一致性在半监督病理图像分割中的应用 [PDF](https://arxiv.org/pdf/2510.01532), [HTML](https://arxiv.org/abs/2510.01532)
### Authors
Meilong Xu,Xiaoling Hu,Shahira Abousamra,Chen Li,Chao Chen
### Background
在半监督分割中，从未标记数据中捕捉有意义的语义结构是非常关键的。特别是在病理学图像分析中，由于对象密集分布，这一任务尤为重要且具有挑战性。
### Innovation
本文提出了一种半监督分割框架，通过利用随机失活和时间训练快照获得的多种扰动预测，确保这些预测结果间的一致性，从而区分生物上有意义的结构与短暂或噪声的特征。为了解决未标记数据下准确匹配预测之间拓扑特征的难题，提出了一种新型匹配策略，该策略结合了空间重叠和全局结构对齐，减少了预测之间的一致性差异。
### Conclusion
大量的实验结果表明，该方法有效地减少了拓扑错误，从而产生了更稳健和准确的分割，为可靠的下游分析提供了保障。源代码可在指定的网址获取。
## 559. `cs.CV` - 利用盲人和低视力人群视觉问题引导多模态大语言模型进行主动视觉解释 [PDF](https://arxiv.org/pdf/2510.01576), [HTML](https://arxiv.org/abs/2510.01576)
### Authors
Ricardo Gonzalez Penuela,Felipe Arias-Russi,Victor Capriles
### Background
多模态大语言模型（MLLMs）被集成到视觉解释应用中，以支持盲人和低视力（BLV）用户，因为它们的准确性和提供丰富、人性化的解释的能力。然而，这些应用常常默认提供全面、冗长的描述，而不考虑上下文。这导致了低效率的交流，用户必须逐条阅读与他们可能寻求的信息无关的细节，而不是获得他们真正需要的具体信息。为了提供更有针对性的信息，作者开发了一种系统。当给定一张图片时，系统会从VizWiz-LF数据集中识别相似的过去视觉背景，并利用相关问题引导MLLM生成更符合BLV用户需求的描述。
### Innovation
作者开发了一个系统，通过利用历史BLV用户的问题，当给定一张图片时，系统能够识别相似的过去视觉背景，并使用相关问题引导MLLM生成更加符合BLV用户需求的描述。这是一个创新的应用方法，能够提供更相关和针对性的信息。
### Conclusion
作者进行了一个评估，其中三名人类注释者修改了92个上下文感知和上下文无关的描述，结果显示在76.1%（70个）的情况下，上下文感知描述回答了用户的问题，在54.4%（50个）的比较中，它们更受偏好。详细实验结果和数据分析已在GitHub仓库（链接略）中公开。
## 560. `cs.CV` - 向扩散模型中的列表偏好优化迈进 [PDF](https://arxiv.org/pdf/2510.01540), [HTML](https://arxiv.org/abs/2510.01540)
### Authors
Jiamu Bai,Xin Yu,Meilong Xu,Weitao Lu,Xin Pan,Kiwan Maeng,Daniel Kifer,Jian Wang,Yu Wang
### Background
强化学习从人类反馈（RLHF）已被证明对于对齐文本到图像（T2I）扩散模型的人类偏好非常有效。尽管直接偏好优化（DPO）因其计算效率和避免显式奖励建模而广泛采用，但在扩散模型中的应用主要依赖于成对的偏好。针对列表偏好优化的精确优化仍然未得到很好的解决。实际上，人类对图像偏好的反馈通常包含隐式的排名信息，这比成对比较提供了更精确的人类偏好信息。因此，该工作提出了Diffusion-LPO，一种用于扩散模型中的列表偏好优化框架，以处理上述挑战并提高生成质量与偏好对齐的效果。
### Innovation
提出了Diffusion-LPO，这是一种在扩散模型中以列表数据为基础的简单有效的列表偏好优化框架。该框架通过利用Plackett-Luce模型，将用户反馈聚合为图像的排名列表，进而推导出DPO目标的列表扩展。Diffusion-LPO通过鼓励每个样本优于其较低排名的替代品来确保整排名的一致性。该研究通过各种任务实验证明了Diffusion-LPO的有效性，并且在视觉质量和偏好对齐方面显著优于基于成对的DPO基准方法。
### Conclusion
Diffusion-LPO在视觉质量和偏好对齐方面表现出色，且与基于成对的DPO基准方法相比，具有明显的优势，证明了使用成组偏好信息能够提升扩散模型中的生成质量和人类偏好对齐的效果。
## 561. `cs.CV` - WALT: Web Agents that Learn Tools [PDF](https://arxiv.org/pdf/2510.01524), [HTML](https://arxiv.org/abs/2510.01524)
### Authors
Viraj Prabhu,Yutong Dai,Matthew Fernandez,Jing Gu,Krithika Ramakrishnan,Yanqi Luo,Silvio Savarese,Caiming Xiong,Junnan Li,Zeyuan Chen,Ran Xu
### Background
当前的网络代理方法仍然较为脆弱，依赖于具体的用户界面交互步骤和大量的长期限推理，这些方法在动态布局和长时间跨度的情况下容易出错。相比之下，人类能够利用网站提供的功能进行高层次的操作，如搜索、筛选和排序。
### Innovation
WALT（Web Agents that Learn Tools）框架通过反向工程潜在线程网站功能，将其转化为可重复使用的可调用工具，从而揭示已经设计到网站中的稳健自动化实现，覆盖从发现（搜索、筛选、排序）、交流（发帖、评论、点赞）到内容管理（创建、编辑、删除）等多个方面。WALT 实现了通过调用高级操作（如 search(query) 或 create(listing)）而不是具体的点击和输入来抽象低级执行的自动化，减轻了对脆弱的步骤性推理的依赖，转向可靠的工具调用。
### Conclusion
在 VisualWebArena 和 WebArena 上，WALT 达到了更高的成功率，减少了步骤数和对大型语言模型（LLM）依赖的推理。WALT 为浏览器自动化提供了一个更稳健和可泛化的范式。
## 562. `cs.CV` - Purrception: 变分流匹配在向量量化图像生成中的应用 [PDF](https://arxiv.org/pdf/2510.01478), [HTML](https://arxiv.org/abs/2510.01478)
### Authors
Răzvan-Andrei Matişan,Vincent Tao Hu,Grigory Bartosh,Björn Ommer,Cees G. M. Snoek,Max Welling,Jan-Willem van de Meent,Mohammad Mahdi Derakhshani,Floor Eijkelboom
### Background
变分流匹配方法通常用于连续的图像生成过程中，但它们往往无法提供明确的类别监督。另一方面，向量量化图像生成方法提供了明确的类别监督但牺牲了连续的传输动态。Purrception方法通过将变分流匹配适应于向量量化的潜在空间，结合了连续方法的几何意识和离散方法的监督优势，从而共同提供对可能代码不确定性的量化和温度控制生成能力。研究在ImageNet-1k 256x256图像生成上的评估显示，Purrception比连续流匹配和离散流匹配基准更有效，且达到与先进模型竞争的FID分数，证明了变分流匹配可以有效地在连续传输和离散监督之间建立桥梁，提高图像生成训练效率
### Innovation
Purrception通过学习码本索引的类别后验，同时在连续嵌入空间中计算速度场，结合了连续方法的几何意识和离散方法的监督优势。这种方法提高了不确定性量化和温度控制生成的能力，同时也比基准方法更快地收敛，并实现了与先进模型竞争的FID分数，表明变分流匹配方法可以有效地结合连续传输和离散监督
### Conclusion
Purrception方法展示了变分流匹配能够有效地在图像生成中实现连续传输和离散监督的结合，提高训练效率，并且在ImageNet-1k生成任务中提供了具有竞争力的FID评分
## 563. `cs.CV` - 源域无访问的域适应中的一致辅助域变换器 [PDF](https://arxiv.org/pdf/2510.01559), [HTML](https://arxiv.org/abs/2510.01559)
### Authors
Renrong Shao,Wei Zhang,Kangyang Luo,Qin Li,and Jun Wang
### Background
源域无访问的域适应（Source-free domain adaptation，SFDA）的目标是解决无需直接访问源域数据就适应目标域的挑战。现有主流方法主要通过评估在目标域中与源域特征相似的不变特征，然后试图将目标域与源域对齐。然而，这些方法容易受到复杂样本的影响，并且会受到域偏差的影响。
### Innovation
提出了一种名为CADTrans的一致辅助域变换器（Consistent Assistant Domains Transformer for SFDA）。该方法通过构建域一致性不变特征表示来解决现有方法难以充分表现多样性的问题。具体而言，CADTrans设计了一个辅助域模块，从中间聚合的全局注意力中获取多样化的表示，并通过多种一致策略获取来自辅助域和目标域的不变特征表示，用于区分简单样本和复杂样本。进一步，为了使复杂样本与相应简单样本对齐，提出了条件多核最大均值离散化（CMK-MMD）策略来区分同一类别和不同类别的样本。
### Conclusion
在诸如Office-31、Office-Home、VISDA-C和DomainNet-126等基准测试上进行了广泛的实验，证明了所提出方法的显著性能提升。代码可在以下网址查阅：this https URL
## 564. `cs.CV` - NPN: Null空间的非线性投影在成像反问题中的应用 [PDF](https://arxiv.org/pdf/2510.01608), [HTML](https://arxiv.org/abs/2510.01608)
### Authors
Roman Jacome,Romario Gualdrón-Hurtado,Leon Suarez,Henry Arguello
### Background
成像逆问题旨在从欠采样的噪声测量中恢复高维信号，本质上是一个病态任务，具有无限数量的解，这些解位于传感操作符的零空间中。为了消除这种多重性，通常会通过手工地正则化器或学习过的模型来整合先验信息以约束解的空间。然而，这些先验通常忽略了传感过程的特定结构。本文提出了一种新颖的方法，即“Non-Linear Projections of the Null-Space (NPN，零空间的非线性投影)”，该方法通过神经网络促进零空间的低维投影中的解，而不仅仅是图像域中的结构约束。
### Innovation
NPN通过关注零空间的结构来设计传感器矩阵特定的先验，这些先验捕捉到与其他信号成分截然不同的信息，这些信息对于传感过程是盲的。这种方法具有灵活性，可以适应各种逆问题，与现有的重建框架兼容，并且可以补充传统的图像域先验。
### Conclusion
NPN先验在各种成像逆问题（如压缩感知、去模糊、超分辨率、计算机断层扫描和磁共振成像）中与插件和播放方法、展开网络、深度图像先验和扩散模型相结合，能够一致提高重建保真度，且理论保证了在插件和播放方法中使用时的收敛性和重建准确性。
## 565. `cs.CV` - ImageNet-Think-250K: 一个大规模合成数据集，用于视觉语言模型的多模态推理 [PDF](https://arxiv.org/pdf/2510.01582), [HTML](https://arxiv.org/abs/2510.01582)
### Authors
Krishna Teja Chitty-Venkata,Murali Emani
### Background
为了帮助开发具有显式推理能力的视觉语言模型（VLMs），亟需新的能够捕捉跨模态推理过程的数据集。现有的数据集通常缺乏详细推理过程和结构化表示。因此，新的数据集需要涵盖这些方面，以便为训练和评估多模态推理模型提供资源，同时促进对多模态推理机制的理解。
### Innovation
我们开发了ImageNet-Think数据集，基于ImageNet21k数据集中的250,000张图像，包含结构化的思考标记和相应的答案，由两个领先的视觉语言模型GLM-4.1V-9B-Thinking和Kimi-VL-A3B-Thinking-2506生成。每个图像提供了两对思考-答案序列，用于训练和评估多模态推理模型。该数据集旨在促进更稳健的VLMs的发展，同时提升对多模态推理机制的认识。此数据集和评估基准将面向公众，以支持对推理/思考的多模态VLMs的研究。
### Conclusion
通过提供结构化的思考过程和详细的解释性答案，ImageNet-Think数据集能够为视觉语言模型的研发提供重要支持，促进对多模态推理机制的深入理解。未来的研究者可以使用该数据集进行多模态推理模型的训练和评估，从而推动该领域的发展。
## 566. `cs.CV` - 在有限训练数据下的口咽癌稳健分类 [PDF](https://arxiv.org/pdf/2510.01547), [HTML](https://arxiv.org/abs/2510.01547)
### Authors
Akshay Bhagwan Sonawane,Lena D. Swamikannan,Lakshman Tamil
### Background
全球范围内口咽癌是较为常见的癌症之一，尤其在医疗服务不足的地区病情死亡率较高。早期诊断对于降低死亡率至关重要，但受限于口腔健康项目不足、基础设施不完善和卫生保健从业人员短缺等问题，诊断面临挑战。传统深度学习模型倾向于使用点估计，容易产生过度自信并降低可靠性。这些问题在训练数据有限的情况下更为显著，因为这些模型需要大规模数据集来减少过拟合并确保普遍适用性，而在有限数据环境下这是不可行的。因此，亟需一种能在有限训练数据下表现优秀的解决方案。
### Innovation
该研究提出了一种结合卷积神经网络（CNN）与贝叶斯深度学习的混合模型，用于使用小规模训练数据集进行口咽癌分类。该模型利用变分推断来通过不确定性量化提升可靠性。研究还发现，该模型在具有类似训练数据分布的测试数据集上达到了94%的准确性，与传统CNN性能相当。更为重要的是，该模型在真实世界的照片图像数据上表现出优于传统CNN的广泛适用性，即使训练数据较小，其在不同测试集上的准确率达到了88%，而传统CNN仅为72.94%。模型的置信度分析表明，它对正确分类的样本表现出较低的不确定性（高置信度），而对误分类的样本表现出较高的不确定性（低置信度）。这些结果显示了在数据稀缺环境下，贝叶斯推理对于提高模型可靠性和广泛适用性的效果，从而有效提高早期口咽癌的诊断能力。
### Conclusion
研究提出了一种能够在有限训练数据下进行口咽癌分类的混合模型，通过集成卷积神经网络与贝叶斯深度学习提高了模型的不确定性量化，从而提升了模型的可靠性和广泛适用性。实验结果表明，即使在训练数据有限的情况下，该模型仍然能够提供优秀的分类性能，增强早期诊断的准确性。
## 567. `cs.CV` - 宏微摄影的联合去模糊和三维重建 [PDF](https://arxiv.org/pdf/2510.01640), [HTML](https://arxiv.org/abs/2510.01640)
### Authors
Yifan Zhao,Liangchen Li,Yuqi Zhou,Kai Wang,Yan Liang,Juyong Zhang
### Background
宏微镜片具有高分辨率和大放大率的优点，能够为小型和详细对象的建模提供丰富的信息。然而，宏微摄影中的失焦模糊问题是长期存在的难题，严重影响了所捕获对象的清晰成像和高质量三维重建。传统图像去模糊方法需要大量的图像和标注，且目前没有适配宏微摄影的多视图三维重建方法。
### Innovation
本文提出了一种适用于宏微摄影的联合去模糊和三维重建方法。从捕捉的多视图模糊图像出发，该方法同时优化了对象的清晰3D模型和每个像素的失焦模糊核。整个框架采用了可微渲染方法，实现对3D模型和失焦模糊核的自监督优化。通过广泛的实验，证实了从少量多视图图像中，该方法不仅能实现高质量图像去模糊，还能恢复高保真的3D外观。
### Conclusion
本文提出的方法可以在少量多视图图像上同时实现高质量的图像去模糊和高保真的3D重建，解决了宏微摄影过程中长期存在的失焦模糊问题。
## 568. `cs.CV` - LadderMoE: Ladder-Side 混合专家适配器用于铜器文字识别 [PDF](https://arxiv.org/pdf/2510.01651), [HTML](https://arxiv.org/abs/2510.01651)
### Authors
Rixin Zhou,Peiqiang Qiu,Qian Zhang,Chuntao Li,Xi Yang
### Background
铜器铭文（BI）是在古代铜器上雕刻的文字，是早期中国书写的重要阶段，对考古和历史研究具有不可或缺的证据价值。然而，由于严重的视觉退化、照片、拓片和线条图之间的多域变异性以及极不均衡的字符分布，自动BI识别仍然是一项艰巨的任务。
### Innovation
本文构建了一个大规模的铜器铭文数据集，包含22454张全页图像和198598个标记的字符，涵盖了6658个唯一类别，从而实现跨域评估的稳健性。在此资源基础上，开发了一个两阶段检测-识别管道，首先定位铭文，然后转录单个字符。为处理异构域和稀有类别问题，管道中集成了LadderMoE，该方法通过梯式混合专家适配器增强预训练CLIP编码器，从而实现动态专家专业化和更强大的鲁棒性。
### Conclusion
全面实验表明，本方法在单字符和全页识别任务上显著优于最先进的场景文字识别基线，实现了从头部、中部到尾部类别的优异准确率，以及所有获取模态的表现。这些结果为铜器铭文识别和下游考古分析奠定了坚实的基础。
## 569. `cs.CV` - 通过微分几何实现可恢复共形尺度的非刚性结构从运动 [PDF](https://arxiv.org/pdf/2510.01665), [HTML](https://arxiv.org/abs/2510.01665)
### Authors
Yongbo Chen,Yanhao Zhang,Shaifali Parashar,Liang Zhao,Shoudong Huang
### Background
单眼视觉变形的同步定位与映射（SLAM）面临着建图的挑战，非刚性结构从运动（NRSfM）作为一种有潜力的技术受到了广泛关注。现有的NRSfM方法通常依赖于严格假设，比如局部平面表面或局部线性变形，这限制了它们恢复共形比例尺的能力。
### Innovation
本文提出了一种名为Con-NRSfM的新方法，用于处理形变下的非刚性结构从运动。该方法利用图基框架进行优化，以点重建为基础，同时具备以下创新点：1) 不依赖于严格假设，能够准确计算局部共形比例尺；2) 通过借鉴差异几何学原理，将深度约束和共形比例尺约束分离，从而提高深度估计的精确性；3) 采用并行分离迭代优化策略以及编码器-解码器自监督学习框架生成稠密的3D点云。
### Conclusion
通过仿真实验和实际数据集测试，本文方法在重建精度和鲁棒性上优于现有方法。源代码将在项目网站上公开发布。
## 570. `cs.CV` - UniVerse: Unleashing the Scene Prior of Video Diffusion Models for Robust Radiance Field Reconstruction [PDF](https://arxiv.org/pdf/2510.01669), [HTML](https://arxiv.org/abs/2510.01669)
### Authors
Jin Cao,Hongrui Wu,Ziyong Feng,Hujun Bao,Xiaowei Zhou,Sida Peng
### Background
本研究涉及从一组不一致的多视图图像中恢复鲁棒性3D场景的挑战。已有研究试图通过将图像退化建模集成到神经3D场景中来同时去除图像不一致性并进行重建。然而，这些方法依赖于密集观测，以实现鲁棒优化模型。这些问题限制了它们在多样图像中的应用。
### Innovation
本文提出了一种新的方法，将鲁棒重建任务分解为两个子任务：复原和重建。基于视频扩散模型，该方法首先将不一致的图像转换为初始视频，然后通过定制设计的视频扩散模型将它们恢复为一致的图像，最后从这些复原的图像中重建3D场景。扩散模型通过大规模数据学习场景先验，使其适用于不同类型的图像。
### Conclusion
在合成和真实世界的数据集上的实验表明，本方法在鲁棒重建方面具备强大的泛化能力和优越的性能。此外，UniVerse可以控制重建3D场景的风格。
## 571. `cs.CV` - 通过概念瓶颈模型实现医疗机器人中的自动基因组解释 [PDF](https://arxiv.org/pdf/2510.01618), [HTML](https://arxiv.org/abs/2510.01618)
### Authors
Zijun Li,Jinchang Zhang,Ming Zhang,Guoyu Lu
### Background
该研究提出了一种自动化基因组解析模块，该模块将原始的DNA序列转化为可操作、可解释的决策，适用于医疗自动化和机器人系统的集成。传统的基因组解析方法往往难以实现自动化，且缺乏解释性，而该模块结合了混沌游戏表示（CGR）和概念瓶颈模型（CBM），并引入了概念一致性和KL散度匹配等监督机制，实现了对基因组特征（如GC含量、CpG密度和k-mer模式）的解释性预测，增强了预测的可靠性，同时，还引入了一层成本感知推荐层，能够将预测输出转化为兼顾准确性和实用性的决策策略，有效减少了不必要的重检，提高了效率。实验表明，该系统在性能上超越了现有基线系统，尤其在可解释性预测和成本效益方面表现出色。
### Innovation
本文的创新之处在于提出了结合CGR和CBM的自动化基因组解析模块，通过引入概念 fidelity 、先验一致性对齐、KL散度匹配和不确定性校准，使预测结果更加可靠、可解释。此外，通过成本感知推荐层，该模块能够给决策制定者提供平衡准确性和实用性的优化策略，从而在医疗机器人领域中实现对临床成本的有效控制和优化服务流程。
### Conclusion
本文建立了一个可靠的基础，可以将可解释的基因组建模与自动决策相结合，为基因组医学中的机器人和临床自动化提供了强大的技术支撑。实验结果表明，该系统在HIV亚型分类上达到了最先进的分类性能，可解释概念预测的准确性更高，成本效益也更优。
## 572. `cs.CV` - VLA-R1: 提升视觉-语言-行动模型中的推理能力 [PDF](https://arxiv.org/pdf/2510.01623), [HTML](https://arxiv.org/abs/2510.01623)
### Authors
Angen Ye,Zeyu Zhang,Boyuan Wang,Xiaofeng Wang,Dapeng Zhang,Zheng Zhu
### Background
视觉-语言-行动（VLA）模型旨在统一感知、语言理解和行动生成，为有监督强化学习的人工智能领域提供强大的跨任务和跨场景泛化能力。然而，当前的VLA模型通常缺乏明确的步骤推理过程，而是在没有考虑可操作性约束或几何关系的情况下直接发出最终行动。这些模型的后训练管道也极少强化推理质量，主要依靠监督微调和设计较弱的奖励机制来完成任务。
### Innovation
本文提出了VLA-R1，一种增强了推理能力的VLA模型，将可验证奖励的强化学习（RLVR）与群体相对策略优化（GRPO）相结合，系统优化推理和执行。特别地，设计了一个基于RLVR的后训练策略，包括区域对齐、轨迹一致性和输出格式验证的可验证奖励，以增强推理的稳健性和执行准确性。此外，作者构建了VLA-CoT-13K高质量数据集，提供了与可操作性和轨迹注释明确对齐的链式思维监督。
### Conclusion
在域内、域外、模拟和真实机器人平台上进行的广泛评估表明，VLA-R1 在泛化能力和实际表现方面优于之前的VLA方法。作者计划在论文发布后公开模型、代码和数据集。
## 573. `cs.CV` - FideDiff: 高保真图像运动去模糊的高效扩散模型 [PDF](https://arxiv.org/pdf/2510.01641), [HTML](https://arxiv.org/abs/2510.01641)
### Authors
Xiaoyang Liu,Zhengyan Zhou,Zihang Xu,Jiezhang Cao,Zheng Chen,Yulun Zhang
### Background
近期基于CNN和transformer的图像运动去模糊取得了显著进展。大型预训练扩散模型因其在真实世界建模中的丰富性，在高质量图像恢复任务如去模糊上表现出极大的潜力，展现出比CNN和transformer方法更强的生成能力。然而，这些模型仍面临无法承受的推理时间和保真度下降等挑战。
### Innovation
我们提出了FideDiff，一种新型单步扩散模型，专为高保真度去模糊设计。我们将其运动去模糊重新定义为一种逐usive扩散过程，其中每个时间步表示一个逐步模糊的图像，并训练一致性模型以将所有时间步对齐到同一个干净图像。通过使用匹配模糊轨迹的数据重建训练数据，模型学习了时间一致性，从而实现了准确的一步去模糊。此外，我们通过集成Kernel ControlNet进行模糊核估计，并引入自适应时间步预测来进一步提升模型性能。
### Conclusion
FideDiff在全参考度量指标上实现了卓越的性能，超越了先前的基于扩散的方法，并可与其它最先进的模型匹敌。FideDiff为将预训练扩散模型应用于高保真图像恢复任务提供了新的方向，为推进扩散模型在实际工业应用中的进一步发展奠定了坚实基础。我们的数据集和代码可从以下链接获取：this https URL
## 574. `cs.CV` - MedQ-Bench: 评估和探索MLLMs在医学图像质量评估中的能力 [PDF](https://arxiv.org/pdf/2510.01691), [HTML](https://arxiv.org/abs/2510.01691)
### Authors
Jiyao Liu,Jinjie Wei,Wanying Qu,Chenglong Ma,Junzhi Ning,Yunheng Li,Ying Chen,Xinzhe Luo,Pengcheng Chen,Xin Gao,Ming Hu,Huihui Xu,Xin Wang,Shujian Gao,Dingkang Yang,Zhongying Deng,Jin Ye,Lihao Liu,Junjun He,Ningsheng Xu
### Background
医学图像质量评估（IQA）是临床AI的第一安全门，但目前的方法仍受限于单一的分值指标，无法全面反映专家评价中的描述性和人类类推过程。现有的IQA方法有其局限性，因此需要一种新的框架来改进评估标准和方法。
### Innovation
提出MedQ-Bench，这是一个全面的基准，采用多模态大语言模型（MLLMs）进行基于语言的医学图像质量评估。MedQ-Bench 包含两个任务：MedQ-感知，用于评估模型的基本视觉感知能力；MedQ-推理，涵盖无参考和比较推理任务，使模型评估更接近人类关于图像质量的推理解析过程。该基准覆盖了五种成像模态和四十多种质量属性，总共有2600个感知查询和708个推理评估，涉及真实临床采集的图像、物理重建的降级图像以及AI生成的图像。此外，提出多维度的评估协议来评估模型的推理能力，并通过与放射科医生的对比验证人类-AI一致性。
### Conclusion
对14个最先进的MLLMs的评估显示，模型表现出初步但不稳定的感知和推理能力，这些发现指出了对MLLMs在医学IQA中的专门优化需求。希望MedQ-Bench能够激发进一步的研究，释放MLLMs在医学图像质量评估中的潜力。
## 575. `cs.CV` - VirDA: 通过视觉重编程重复利用主干网络实现无监督领域适应 [PDF](https://arxiv.org/pdf/2510.01660), [HTML](https://arxiv.org/abs/2510.01660)
### Authors
Duy Nguyen,Dat Nguyen
### Background
现有的UDA管道需要为每一个新的源-目标对重新微调已经训练好的主干参数，导致训练参数数量和存储内存呈线性增长，并且阻止了对这些主干参数的再利用。由于现有主干具有纹理偏见，该研究提出了一种通过视觉重编程利用领域特定纹理偏见的方法，该方法在主干前端添加了一个特定于领域的视觉重编程层，这个层产生视觉提示，提供输入图像的额外纹理偏见，使其“风格”适应目标领域。这种方法无需修改主干参数，使同一个主干可以在不同领域中重复使用。
### Innovation
提出了一种通过视觉重编程利用领域特定纹理偏见的方法，该方法在主干前端添加了一个特定于领域的视觉重编程层，这个层产生视觉提示，作为输入图像的额外纹理偏见，使图像风格适应目标领域。使用多个目标函数优化视觉提示的领域适应性分布差异，这种方法无需修改主干参数，允许在不同领域中重复使用相同的主干，从而节省训练参数并减少存储需求。
### Conclusion
在Office-31数据集上评估了VirDA，取得了92.8%的平均准确率，仅使用1.5M可训练参数。与参数效率最高的UDA基线PDA相比，VirDA在仅使用其参数的46%的情况下，提高了1.6%的准确性。与完全主干微调相比，VirDA分别在CDTrans和FixBi的基础上提高了0.2%和1.4%的准确性，仅需其参数的1.7%和2.8%。与当前最强的两种方法（PMTrans和TVT）相比，VirDA各自使用了不到1.7%的参数，仅分别损失了2.2%和1.1%的准确性。
## 576. `cs.CV` - 离散面部编码：面向数据驱动面部表情发现的框架 [PDF](https://arxiv.org/pdf/2510.01662), [HTML](https://arxiv.org/abs/2510.01662)
### Authors
Minh Tran,Maksim Siniukov,Zhangyu Jin,Mohammad Soleymani
### Background
面部表情分析是理解人类行为的核心，然而现有的编码系统如面部动作编码系统（FACS）受限于覆盖面有限和成本高昂的手动注释。现有的系统无法充分捕捉面部表情的复杂性，且分析成本高。因此，需要一种更加高效、自主的解决方案，以更好的捕捉面部表情的细微差别，同时简化数据处理过程。
### Innovation
本文提出了离散面部编码（DFE）——一种通过残差矢量化量化变分自编码器（RVQ-VAE）从3D网格序列中学习得到的紧凑且可解释的面部表情字典。DFE方法首先使用3D面部可变形模型（3DMM）从图像中提取无身份特异性的表情特征，从而有效分离出诸如头部姿态和面部几何等因素。然后使用RVQ-VAE对这些特征进行编码，生成来自共享词汇表的离散标记序列，每个标记都捕捉一个具体的、可重用的面部变形模式，进一步构成整体表情特征。该方法在多个高抽象级心理任务上表现出色，特别是在压力检测、个性预测和抑郁症检测上超过了FACS与其他面部编码替代方案。基于学习到的标记构建的简单Bag-of-Words模型，在所有任务上都优于FACS管道和强大的图像和视频表征学习模型（如遮蔽自编码器）。进一步分析表明，DFE方法涵盖了更广泛的面部表情显示，显示了其作为FACS在心理学和情绪计算应用中的可扩展且有效的替代方案的巨大潜力。
### Conclusion
通过离散面部编码（DFE），本文为面部表情数据驱动的发现提供了新颖的方法，为理解和分析面部表情提供了更好、更高效、更全面的解决方案，尤其在心理检测任务上表现优异，展示了其广阔的应用前景。
## 577. `cs.CV` - PyramidStyler: Transformer-Based Neural Style Transfer with Pyramidal Positional Encoding and Reinforcement Learning [PDF](https://arxiv.org/pdf/2510.01715), [HTML](https://arxiv.org/abs/2510.01715)
### Authors
Raahul Krishna Durairaju(1),K. Saruladha(2) ((1) California State University, Fullerton, (2) Puducherry Technological University)
### Background
Neural Style Transfer (NST)已经从Gatys等人（2015年）的基于CNN的算法发展而来，使得通过深度学习生成艺术图像成为可能。然而，现有的基于CNN和基于Transformer的模型在处理复杂风格和高分辨率输入时效率低下。
### Innovation
提出了一种名为PyramidStyler的Transformer框架，该框架结合了Pyramidal Positional Encoding (PPE)：一种分层、多尺度编码，既能捕捉局部细节又能把握全局上下文，同时减少计算负担。同时，还引入了强化学习对风格化进行动态优化，加快了收敛速度。
### Conclusion
PyramidStyler在4000个周期后减少了内容损失62.6%（至2.07）和风格损失57.4%（至0.86），实现每秒1.39秒的推理，并在使用强化学习时仍能取得进一步改进（内容 2.03；风格 0.75），速度轻微增加（每秒1.40秒）。这些结果证明了实时高质的艺术渲染，并在媒体和设计领域具有广泛应用价值。
## 578. `cs.CV` - Look Less, Reason More: Rollout-Guided Adaptive Pixel-Space Reasoning [PDF](https://arxiv.org/pdf/2510.01681), [HTML](https://arxiv.org/abs/2510.01681)
### Authors
Xuchen Li,Xuzhao Li,Jiahui Gao,Renjie Pi,Shiyu Hu,Wentao Zhang
### Background
视线语言模型（VLMs）在多模态任务中表现出色，但在需要精细视觉理解的任务中往往表现不佳。主要原因是图像编码过程中信息丢失或对关键区域的注意力不足。虽然最近的工作通过在推理过程中引入像素级视觉信息有所进步，但这种像素级信息的过度使用导致了低效且分散了对不相关视觉细节的注意力。为了应对这些挑战，本文介绍了一种创新的方法——自适应像素推理框架，它可以根据输入查询动态决定必要的像素级操作。
### Innovation
本文提出了第一个自适应像素推理框架，该框架根据输入查询动态决定需要的像素级操作。研究首先采用操作感知的监督微调来建立文本推理和视觉操作的基本能力，然后设计了一个基于模型自身响应反馈的铺设指导强化学习框架，该框架让VLM能够根据查询的难度来决定何时调用像素操作。与之前的方法相比，该模型在大规模多模态推理基准测试上的表现更优，同时显著减少了不必要的视觉操作。此外，该模型在HR-Bench 4K数据集上的准确率达到73.4%，且工具使用率仅为20.1%，相比之前的方法，模型的准确性和工具使用率同时获得了显著提升。
### Conclusion
本文提出的方法显著改善了视觉语言模型在涉及精细视觉元素的任务中的表现。实验表明，该模型不仅提高了性能，还在减少不必要的视觉操作方面取得了显著进步，达到了同时提高准确性和减少工具使用率的目标。
## 579. `cs.CV` - 自然场景中的整体顺序预测 [PDF](https://arxiv.org/pdf/2510.01704), [HTML](https://arxiv.org/abs/2510.01704)
### Authors
Pierre Musacchio,Hyunmin Lee,Jaesik Park
### Background
在受控环境中，准确理解每个实例的几何形状对视觉模型而言是一个具有挑战性的任务，这影响了从图像中准确检测和排列表观顺序的能力。现有系统虽然存在，但对于现代艺术而言，它们依赖昂贵的输入格式和高昂的推理成本。总共需要二次数量级的前向传递次数。因此，本文提出了一种名为InstaFormer的新网络模型，它能够在单次前向传递过程中，仅通过输入RGB图像即可预测场景中所有实例的遮挡和深度排序，解决了传统方法的问题。
### Innovation
该模型主要通过物体查询与潜在掩码描述符之间的交互工作，后者在语义上代表同一对象并承载补充信息。这种方法在整体上基准测试和消融实验，突出其有效性。模型和代码均被开源发布，可通过提供的链接访问。
### Conclusion
通过开发InstaFormer，本文显著降低了视觉模型在预测自然场景中实例的完整遮挡和深度顺序时的相关复杂性和成本。
## 580. `cs.CV` - 基于模板感知动态卷积的一种高效深模板匹配和平面内姿态估计方法 [PDF](https://arxiv.org/pdf/2510.01678), [HTML](https://arxiv.org/abs/2510.01678)
### Authors
Ke Jia,Ji Zhou,Hanxin Li,Zhigan Zhou,Haojie Chu,Xiaojie Li
### Background
在工业检测和组件对齐任务中，模板匹配需要在复杂背景下高效估计目标的位置和几何状态（旋转和缩放），以支持精确的下游操作。传统方法依赖于角度和比例的耗时枚举，导致在复合变换下效率低下。同时，大多数基于深度学习的方法仅估计相似度分数，而不明确建模几何姿态，使其不适合实际部署。
### Innovation
我们提出了一个轻量级端到端框架，将模板匹配重新定义为联合定位和几何回归，输出中心坐标、旋转角度和独立的横向和纵向比例。引入了模板感知动态卷积模块（TDCM）在推理时动态注入模板特征，引导泛化匹配。紧凑的网络结合深度可分离卷积和像素 shuffle 以实现高效匹配。通过引入基于旋转剪切的增强策略和结构感知伪标签，实现了几何注释无监督的训练。轻量级精炼模块通过局部优化进一步提高了角度和比例精度。实验表明，我们的3.07M模型在复合变换下具有高精度和14ms的推理速度，并且在小模板和多对象场景中展示了强大的鲁棒性，非常适合部署在实时工业应用中。
### Conclusion
该模型在复杂变换下具有高精度和快速推理时间，并且在小模板和多对象场景中表现出强大的鲁棒性，非常适合实时工业应用部署。
## 581. `cs.CV` - 为自动驾驶中的3D物体检测器校准完整的预测类别分布 [PDF](https://arxiv.org/pdf/2510.01829), [HTML](https://arxiv.org/abs/2510.01829)
### Authors
Cornelius Schröder,Marius-Raphael Schlüter,Markus Lienkamp
### Background
在自主系统中，物体检测的精确性和不确定性估计对于自我意识和安全操作至关重要。本文针对3D物体检测器的分类任务，关注信心校准问题。
### Innovation
本文提出了两个辅助正则化损失项，分别引入主导预测和完整预测向量的校准作为训练目标。实验表明，结合特定于完整类别预测校准的损失项和等向型回归可以提高CenterPoint和PillarNet的校准效果，而DSVT-Pillar则无法通过相同的校准方法同时校准主导和次要预测。
### Conclusion
研究表明，对于3D物体检测器而言，同时校准主导预测和次要预测是关键。提出了两种新的校准方法，并展示了解决特定问题的有效性。
## 582. `cs.CV` - 利用扩散模型先验知识进行人体搜索 [PDF](https://arxiv.org/pdf/2510.01841), [HTML](https://arxiv.org/abs/2510.01841)
### Authors
Giyeol Kim,Sooyoung Yang,Jihyong Oh,Myungjoo Kang,Chanho Eom
### Background
人体搜索的目标是通过图像中定位和识别查询主体来同时执行人体检测和重识别。现有的方法大多利用预训练的ImageNet骨干网络，但这可能不适用于捕捉人体搜索中复杂的空间上下文和精细的个体特征。此外，这些方法依赖于共享的骨干特征来进行人体检测和重识别，导致由于优化目标冲突而生成次优化的特征。
### Innovation
本文提出了一种名为DiffPS（基于扩散模型先验知识的人体搜索）的新型框架，该框架利用预训练的扩散模型并消除两项子任务之间的优化冲突。文章分析了扩散先验的关键性质，并提出了三个特殊的模块：(i) 扩散引导的区域建议网络（DGRPN），增强人体定位；(ii) 多尺度频率精炼网络（MSFRN），减轻形状偏见；(iii) 语义自适应特征聚合网络（SFAN），利用文本对齐的扩散特征。基于此，DiffPS在CUHK-SYSU和PRW上达到了新的SOTA。
### Conclusion
DiffPS在CUHK-SYSU和PRW数据集上取得了新的SOTA表现，证明了通过消除任务优化冲突和利用扩散模型的先验知识能够提升人体搜索的性能。
## 583. `cs.CV` - FreeViS: 无需训练的非一致参考视频风格化 [PDF](https://arxiv.org/pdf/2510.01686), [HTML](https://arxiv.org/abs/2510.01686)
### Authors
Jiacong Xu,Yiqun Mei,Ke Zhang,Vishal M. Patel
### Background
视频风格化在内容创造中扮演着关键角色，但这是一个具有挑战性的问题。直接从帧到帧地应用图像风格化方法会损害时间一致性并减少风格丰富度。另一种方法是训练专门的视频风格化模型，但这通常需要成对的训练数据，且计算成本高昂。现有方法在风格化生成过程中仍然存在传播错误，导致闪烁和卡顿的问题。
### Innovation
本文提出了一种无需训练的视频风格化框架FreeViS，该框架能够生成具有丰富风格细节和强烈时间连贯性的视频。FreeViS通过整合多个风格化的参考图像，有效缓解了先前工作中观察到的传播错误，而不引入闪烁和卡顿。此外，该方法利用高频补偿来约束内容布局和运动，并借助基于流的运动提示来保留低显著性区域中的风格纹理。
### Conclusion
通过广泛评估，FreeViS提供了更高的风格化保真度和更好的时间一致性，超越了最新的基线模型，并在用户体验上表现优秀。FreeViS的无需训练管线为高质量、时间连贯的视频风格化提供了实用和经济的解决方案。
## 584. `cs.CV` - 通过增强-敏感性风险评分发现CXR模型中的高自信失败 [PDF](https://arxiv.org/pdf/2510.01683), [HTML](https://arxiv.org/abs/2510.01683)
### Authors
Han-Jay Shu,Wei-Ning Chiu,Shun-Ting Chang,Meng-Ping Huang,Takeshi Tohyama,Ahram Han,Po-Chih Kuo
### Background
深度学习模型在胸部X光片（CXR）解释方面表现出色，但仍存在公平性和可靠性问题。模型在不同患者亚组中的准确率差异较大，导致一些隐藏的错误未被总体指标反映出来。现有的错误检测方法——基于置信度校准或离群值检测——对于分布内的细微错误应对不佳。此时，基于图像和表示级一致性的方法在医学影像领域研究不足。因此，本文提出了一种增强-敏感性风险评分（ASRS）框架，以识别易出错的CXR案例。
### Innovation
ASRS框架通过临床可验证的旋转（±15°/±30°）应用增强技术，使用RAD-DINO编码器衡量嵌入变动。敏感性评分将样本分为稳定性四分位，体现出高敏感性案例在召回率方面显著降低（-0.2至-0.3），但同时具有较高的AUROC和信心水平。ASRS方法为医生的个性化审阅提供了无标签的预测选择，增强了医疗AI的公平性和安全性。
### Conclusion
ASRS框架通过对增强技术敏感性的衡量，能够发现模型中的高自信错误，有助于提高医疗AI的公平性和安全性，提供了一种无需标签的鉴别预测和医生审阅的方法。
## 585. `cs.CV` - LOBE-GS: 一种用于大规模场景重建的高效负载均衡3D高斯泼墨 [PDF](https://arxiv.org/pdf/2510.01767), [HTML](https://arxiv.org/abs/2510.01767)
### Authors
Sheng-Hsiang Hung,Ting-Yu Yen,Wei-Fang Sun,Simon See,Shih-Hsuan Hung,Hung-Kuo Chu
### Background
3D Gaussian Splatting (3DGS) 已经成为实时、高保真3D场景重建的有效表示方法。然而，将其扩展到大片城市区域或无限场景仍然具有挑战性。现有的分而治之方法通过将场景分割成块来缓解内存压力，但引入了新的瓶颈：一是各部分由于均匀或启发式分割不能反映实际的计算需求，导致严重的负载不平衡；二是自顶向下的流水线没有有效地利用粗略阶段，经常重新加载整个模型，导致高昂的开销。
### Innovation
本文介绍了一种新的负载均衡和高效的3D高斯泼墨框架——LoBE-GS。LoBE-GS引入了一种深度感知的分区方法，将预处理时间从数小时减少到几分钟；基于优化的方法来平衡可见的高斯分布，这可以作为计算负荷的强代理；以及两种轻量级技术，视图截取和选择性密度增加，进一步减少训练成本。在大规模城市和户外数据集上的评估表明，LoBE-GS使端到端的训练时间始终比最先进的基线快2倍，同时保持重建质量，并允许扩展到 vanilla 3DGS 无法处理的场景中。
### Conclusion
LoBE-GS 提供了一种新的方法来提升大规模 3DGS 算法的效率和可扩展性，通过改进的分区技术和优化策略，极大地提高了训练速度和场景处理能力。
## 586. `cs.CV` - Pack and Force Your Memory: 长视频生成兼具连贯性和一致性 [PDF](https://arxiv.org/pdf/2510.01784), [HTML](https://arxiv.org/abs/2510.01784)
### Authors
Xiaofei Wu,Guozhen Zhang,Zhiyong Xu,Yuan Zhou,Qinglin Lu,Xuming He
### Background
长视频生成面临着双重挑战：模型需要捕捉长时间范围的依赖关系，同时防止自回归解码过程中固有的错误累积。
### Innovation
论文做出了两项贡献：首先，提出了MemoryPack机制，这是一种可学习的上下文检索机制，可以利用文本和图像信息作为全局指导，共同建模短期和长期依赖关系，从而实现分钟级的时间一致性。此外，引入了Direct Forcing策略，以提高训练和推断的一致性，从而减少推断过程中的错误传播。这两项创新显著提升了长视频生成的上下文一致性和可靠性，促进了自回归视频模型的实际使用。
### Conclusion
MemoryPack和Direct Forcing共同增强了长视频生成的内容一致性和可靠性，推动了自回归视频模型的实用性进步。
## 587. `cs.CV` - ClustViT: 基于聚类的 token 融合并行语义分割 [PDF](https://arxiv.org/pdf/2510.01948), [HTML](https://arxiv.org/abs/2510.01948)
### Authors
Fabio Montello,Ronja Güldenring,Lazaros Nalpantidis
### Background
视觉变换器（Vision Transformers，ViT）能够在多种上下文中实现高精度和强泛化能力，但其在真实机器人系统中的实际应用受到了其注意力复杂度呈平方函数的限制。尽管最近的研究开始关注根据图像复杂度动态合并 token，这种方式在分类任务中表现良好但在密集预测任务中效果不佳。
### Innovation
本文提出了 ClustViT，通过扩展 Vision Transformer 的骨干网络，设计了一种可训练的聚类模块，该模块能够根据分割掩码中的伪聚类在网络指导下合并相似的 token。为了恢复细节，引入了一个再生模块。这种方法在三个不同数据集上实现了 2.18 倍的较少 GFLOPs 和 1.64 倍的更快推理速度，同时在分割准确性上保持了相似的水平。
### Conclusion
ClustViT 方法通过优化 token 融合并结合再生模块，成功解决了现有的视觉 Transformers 在实际应用中的性能瓶颈问题，实现了更高的效率和性能，具备在机器人系统中的应用潜力。代码和模型将公开发布。
## 588. `cs.CV` - 由流动匹配引导的深度展开方法用于高光谱图像重建 [PDF](https://arxiv.org/pdf/2510.01912), [HTML](https://arxiv.org/abs/2510.01912)
### Authors
Yi Ai,Yuanhao Cai,Yulun Zhang,Xiaokang Yang
### Background
高光谱成像（HSI）提供丰富的空间-光谱信息，但由于硬件限制和从压缩测量中重构三维数据的困难，其获取仍较为昂贵。虽然压缩成像系统如CASSI有助于提高效率，但准确重构仍然受到严重降级和精细光谱细节损失的挑战。现有的方法虽然有所改进，但仍无法完全解决这些问题，因此需要一种新的方法来更好地融合优化方法和生成模型的优势，以实现更稳健和精确的重构。
### Innovation
本文提出了一种名为Flow-Matching-guided Unfolding网络（FMU）的新方法，这是首次将流动匹配整合到HSI重构中，通过在深度展开框架中嵌入生成先验。通过引入平均速度损失来增强学习动力学，确保流动的全局一致性，进一步提高了重构的鲁棒性和准确性。这种方法将优化方法的解释性与流动匹配的生成能力相结合，展示出显著高于现有方法的重构质量。
### Conclusion
通过对模拟和真实数据集的广泛实验，FMU在重构质量方面显著优于现有方法。该论文证明，结合流动匹配和深度展开框架可以显著改善高光谱图像的重构效果。所有代码和模型将在 https://github.com/username/FMU 上公开提供。
## 589. `cs.CV` - TriAlignXA：一种可解释的三角困境对齐框架，用于农产品分级的信任交易 [PDF](https://arxiv.org/pdf/2510.01990), [HTML](https://arxiv.org/abs/2510.01990)
### Authors
Jianfei Xie,Ziyang Li
### Background
在线果蔬电子商务中存在信任赤字，原因是数字交易无法提供直接的产品质量感知。研究揭示了农产品分级中的“不可能三角”，包括生物特性、时效性和经济可行性之间的冲突，指出传统绝对分级标准的局限性。为了量化该权衡，研究提出“三角信任指数（TTI）”。
### Innovation
该研究创新性地提出了TriAlignXA框架，旨在通过多目标优化实现可信的在线农产品交易。该框架的核心依赖于三个引擎：生物适应性引擎，用于精细的质量描述；时效优化引擎，用于处理效率；经济优化引擎，用于成本控制。此外，提出了“预映射机制”将过程数据编码为QR码，透明地传达质量信息。实验表明该方法准确性和传统基线模型相比显著提高，并通过实证证据和理论分析验证了框架在处理“不可能三角”中的平衡能力，从而为构建一个可信的在线水果蔬菜生态系统提供了理论和实践的支持。
### Conclusion
该研究提供了从理论到实践全面支持，构建了一个可信的在线农产品生态系统，为从算法决策到消费者信任的关键路径打下了基础。
## 590. `cs.CV` - Patch-as-Decodable-Token: 向统一多模态视觉任务在MLLM中的方向 [PDF](https://arxiv.org/pdf/2510.01954), [HTML](https://arxiv.org/abs/2510.01954)
### Authors
Yongyi Su,Haojie Zhang,Shijie Li,Nanqing Liu,Jingyi Liao,Junyi Pan,Yuan Liu,Xiaofen Xing,Chong Sun,Chen Li,Nancy F. Chen,Shuicheng Yan,Xulei Yang,Xun Xu
### Background
近年来，多模态大型语言模型（MLLMs）取得了快速进展。然而，现有方法在视觉任务中通常依赖间接表示，比如通过生成文本坐标进行检测，这限制了性能并阻碍了密集预测任务如分割等的实现。
### Innovation
我们提出了Patch-as-Decodable Token (PaDT)，这是一种统一的范式，使得MLLM可以直接生成文本和多种视觉输出。PaDT的核心是Visual Reference Tokens (VRTs)，它们是从查询图像的视觉贴块嵌入中提取出来的，并且无缝地与LLM的输出文本标记交织在一起。一种轻量级的解码器随后将LLM的输出转化为检测、分割和定位预测。不同于之前的模型，PaDT在每次前向传递中独立处理VRTs，并动态扩展嵌入表，从而提高对相似对象的本地化和区分能力。我们还特别为PaDT设计了一个训练策略，通过随机选择VRTs进行监督微调，并引入一个稳健的逐标记交叉熵损失。
### Conclusion
我们在四个视觉感知和理解任务上的实证研究表明，PaDT始终实现了最先进的性能，甚至与显著更大的MLLM模型相比也是如此。相关代码可以在该网址中获取。
## 591. `cs.CV` - LiLa-Net：轻量级潜空间LiDAR自编码器用于3D点云重建 [PDF](https://arxiv.org/pdf/2510.02028), [HTML](https://arxiv.org/abs/2510.02028)
### Authors
Mario Resino,Borja Pérez,Jaime Godoy,Abdulla Al-Kaff,Fernando García
### Background
研究提出了一个名为LiLa-Net的3D自编码器架构，该架构仅利用LiDAR的点云数据来高效提取实际交通环境中的特征。体系配备了Velodyne LiDAR的半自主车辆进行实现。
### Innovation
通过利用跳连概念，在不使用大量资源的情况下提升了性能，同时减少了编码层的数量并简化了跳连结构，仍能生成有效的且代表性的潜空间，准确重建原始点云。在保持性能的同时，实现了跳连携带的信息与潜编码之间的有效平衡，提升了重建质量。
### Conclusion
所提模型展示了强大的泛化能力，能够成功重建与原始交通环境无关的对象。
## 592. `cs.CV` - 4DGS-Craft: 一致且交互式的4D高斯抹除编辑 [PDF](https://arxiv.org/pdf/2510.01991), [HTML](https://arxiv.org/abs/2510.01991)
### Authors
Lei Liu,Can Wang,Zhenghao Chen,Dong Xu
### Background
4D Gaussian Splatting（4DGS）编辑在视图、时间以及未修饰区域上的一致性方面仍面临挑战，并且难以处理复杂的文本指令。
### Innovation
提出了一种新颖的4DGS-Craft框架，结合了4D-aware InstructPix2Pix模型和多视图网格模块，确保视图和时间一致性；通过新颖的高斯选择机制维护未修改区域的一致性；设计了基于LLM的模块来理解用户意图，将复杂指令分解为原子操作顺序，从而实现更一致和可控的4D场景编辑。
### Conclusion
相比相关工作，4DGS-Craft方法实现了更一致和可控的4D场景编辑。代码将在论文接受后提供。
## 593. `cs.CV` - 基于YOLO目标检测模型的大规模电子产品自动缺陷检测 [PDF](https://arxiv.org/pdf/2510.01914), [HTML](https://arxiv.org/abs/2510.01914)
### Authors
Wei-Lung Mao,Chun-Chi Wang,Po-Heng Chou,Yen-Ting Liu
### Background
传统行业的组件缺陷检测耗时且劳动密集，给质量检验人员带来了显著的负担，并使得产品质量管理困难。为了减轻这些挑战，本文提出了一种针对广泛应用于工业界的双列直插式包装（DIP）的自动化缺陷检测系统，结合了数字相机光学技术与基于深度学习（DL）的模型。
### Innovation
该研究展示了如何采用ConSinGAN生成适合训练和测试的缺陷组件图像数据集，以及评估了四种不同版本的YOLO模型（v3, v4, v7, v9），还结合ConSinGAN增强技术进行缺陷检测。研究表明，使用ConSinGAN增强的YOLOv7在准确率（95.50%）、检测时间（285毫秒）上具有显著优势，优于阈值法等传统方法。此外，本文还开发了监督控制与数据采集（SCADA）系统，并对其关联的传感器架构进行了描述。
### Conclusion
提出的自动化缺陷检测方法能够轻松建立并适用于多种类型缺陷或缺陷数据不足的场景，从而有效提高电子产品的大规模生产中的质量检测效率。
## 594. `cs.CV` - GaussianMorphing: Mesh-Guided 3D Gaussians for Semantic-Aware Object Morphing [PDF](https://arxiv.org/pdf/2510.02034), [HTML](https://arxiv.org/abs/2510.02034)
### Authors
Mengtian Li,Yunshu Bai,Yimin Chu,Yijun Shen,Zhongmei Li,Weifeng Ge,Zhifeng Xie,Chaofeng Chen
### Background
之前的形态转换方法通常依赖点云数据或者需要预先定义的同胚映射，特别是在处理未纹理数据时。这些方法往往难以同时保证几何准确性和纹理保真，尤其是在多视图图像中进行语义感知的三维形状和纹理转换时更为困难。
### Innovation
本文介绍了一种名为GaussianMorphing的新框架，通过利用网格引导的3D高斯置乱（3DGS）来高保真地建模几何和外观。该方法使用统一的变形策略将3D高斯分布固定到重构的网格片段上，通过拓扑感知约束来保证几何一致性同时保真纹理。该框架还通过物理可验证的点轨迹维持结构完整性，并在不使用标记数据的情况下实现了局部细节和全局语义一致性。
### Conclusion
GaussianMorphing在提出的TexMorph基准测试中显著优于先前的2D/3D方法，降低了色度一致性误差（ΔE）22.2%和EI误差26.2%，证明了该方法的有效性。
## 595. `cs.CV` - Pure-Pass: 细粒度且自适应的掩码策略用于轻量级图像超分辨率中动态令牌混合路由 [PDF](https://arxiv.org/pdf/2510.01997), [HTML](https://arxiv.org/abs/2510.01997)
### Authors
Junyu Wu,Jie Tang,Jie Liu,Gangshan Wu
### Background
图像超分辨率（SR）旨在从低分辨率图像重建高分辨率图像，但基于深度学习的方法由于计算复杂度过高，常常阻碍其实用部署。虽然已有研究尝试通过集成轻量级方法的优势来改善SR性能，但仍存在一些限制，如适应性差、粗粒度掩码和空间灵活性不足等问题。
### Innovation
Pure-Pass 提出了一个像素级掩码机制，用于识别纯像素并依据其对昂贵计算的豁免，从而提高计算效率。Pure-Pass 融入到先进的 ATD-light 模型中，使 PP-ATD-light 在保持类似计算量的情况下，实现了更高的重建质量和参数效率。更重要的是，PP 能够实现细粒度且空间灵活的掩码，保持了自适应的灵活性。
### Conclusion
将 Pure-Pass 整合到最先进的 ATD-light 模型中，PP-ATD-light 较 CAMixer-ATD-light 具有更高的重建质量和参数效率，同时保持了相近的计算量。
## 596. `cs.CV` - 基础视觉编码器实际上是少样本异常检测器 [PDF](https://arxiv.org/pdf/2510.01934), [HTML](https://arxiv.org/abs/2510.01934)
### Authors
Guangyao Zhai,Yue Zhou,Xinyan Deng,Lars Heckler,Nassir Navab,Benjamin Busam
### Background
少样本异常检测简化并简化了工业安全检查，但有限的样本使得准确区分正常和异常特征变得具有挑战性，特别是在类别无关条件下。大规模预训练的基础视觉编码器已推进了多个领域，由于大量数据帮助学习了正常图像的一般分布。研究发现，图像中的异常程度与学到的嵌入差异直接相关，利用这一点，我们设计了一种基于少量样本的异常检测器称作FoundAD。通过学习一个非线性投影运算符到自然图像流形上，该简单的运算符成为有效的异常检测工具，用于表征和识别图像中的异常分布区域。
### Innovation
提出了FoundAD，一种新颖的基于少量样本的异常检测器，其创新之处在于利用大规模预训练的基础视觉编码器，通过学习图像中异常的数量与嵌入差异之间的关系，将编码器类别无关的特征应用于异常检测。此外，该方法使用了比先前方法更少的参数，并支持多类别检测。
### Conclusion
通过与多个基础编码器的评估，包括新鲜的DINOv3，证明了这种方法在少样本异常检测方面具有广阔的应用前景，并为该领域开启了新的研究视角。
## 597. `cs.CV` - FRIEREN：利用视觉-语言正则化进行分割的联邦学习 [PDF](https://arxiv.org/pdf/2510.02114), [HTML](https://arxiv.org/abs/2510.02114)
### Authors
Ding-Ruei Shen
### Background
联邦学习（FL）为语义分割（SS）任务提供了在适应新领域时保护隐私的解决方案。然而，当客户数据未标记时，FL方法在应对这些领域变化时遇到了重大挑战。现有大多数FL方法假设远程客户可以访问标记数据，或者未能充分利用现代视觉基础模型（VFMs）的力量。
### Innovation
该研究引入了FFREEDG任务，要求模型仅使用客户端的未标记数据进行训练，而无需重新访问源数据。提出了FRIEREN框架，利用视觉-语言模态的剪贴簿（CLIP）文本嵌入引导的视觉-语言解码器来提高语义去模糊，并采用了弱到强的一致性学习策略以生成伪标签进行鲁棒的本地训练。这一方法被应用于合成到现实以及晴天到恶劣天气的基准测试，展示了该框架的有效性和与现有领域通用性和适应方法的竞争力。
### Conclusion
FRIEREN框架在FFREEDG任务上表现出色，与现有的领域通用性和适应方法相媲美，为未来研究提供了强有力的基线。
## 598. `cs.CV` - 使用GPT-4o在牙科全景片中生成颌囊肿发现：构建具有结构化输出(SLSO)框架的两阶段自我纠正环 [PDF](https://arxiv.org/pdf/2510.02001), [HTML](https://arxiv.org/abs/2510.02001)
### Authors
Nanaka Hosokawa,Ryo Takahashi,Tomoya Kitano,Yukihiro Iida,Chisako Muramatsu,Tatsuro Hayashi,Yuta Seino,Xiangrong Zhou,Takeshi Hara,Akitoshi Katsumata,Hiroshi Fujita
### Background
本研究利用OpenAI GPT-4o的多模态能力，自动在牙科全景片上生成颌囊肿的发现。为了提高准确性，研究构建了一个具有结构化输出（SLSO）框架的自我纠正循环(Self-correction Loop with Structured Output)。研究采用了一个包含10个步骤的流程，对22个颌囊肿病例进行了分析，包括图像输入和分析、结构化数据生成、牙号提取和一致性检查、检测不一致时的迭代重新生成和具有后续结构重组和一致性验证的发现生成。
### Innovation
研究构建了一个具有结构化输出（SLSO）框架的自我纠正循环(Self-correction Loop with Structured Output)，并在多个评价项上提高了输出准确性。与传统的链式思考（CoT）方法相比，对于牙号、牙移动和牙根吸收项分别提高了66.9%、33.3%和28.6%。此外，该框架强制施加了负面发现描述，抑制了幻觉，并提高了牙号识别的准确性。
### Conclusion
尽管样本量较小，统计显著性未达到，但SLSO框架总体上提高了输出的准确性，强制施加了负面发现描述，抑制了幻觉，并提高了牙号识别的准确性。然而，在识别跨多个牙齿的广泛病变方面仍存在限制。需要进一步完善以提高总体性能并朝着实际的发现生成系统迈进。
## 599. `cs.CV` - 法国历史城市足迹制图：平衡质量、可扩展性和AI技术 [PDF](https://arxiv.org/pdf/2510.02097), [HTML](https://arxiv.org/abs/2510.02097)
### Authors
Walid Rabehi,Marion Le Texier,Rémi Lemoy
### Background
在1970年代之前的历史时期，法国的城市扩张定量分析受到缺乏全国范围的数字化城市足迹数据的阻碍。本研究通过开发一个可扩展的深度学习流程来解决这一问题，该流程可以从Scan Histo历史地图系列（1925-1950年）中提取城市区域，这是首次公开提供全国范围的城市足迹数据集。
### Innovation
本研究的关键创新在于设计了双通道的U-Net方法来处理历史地图的高辐射度和风格复杂性。这一方法包括两个阶段：首先，利用初始数据集生成初步地图，识别如文本和道路等复杂区域，以引导有针对性的数据增强；其次，利用精炼的数据集和第一模型的二值化输出来最小化辐射噪声，从而显著减少假阳性。
### Conclusion
该方法在高性能计算集群上处理了覆盖整个法国大都市区的941个高分辨率图块，最终马赛克的整体准确率为73%，有效捕捉了各种城市特征，并克服了常见的标签和轮廓线等常见缺陷。此外，研究结果已公开发布代码、训练数据集和全国尺度的城市遥感数据，以支持未来在长期城市化动态方面的研究。
## 600. `cs.CV` - 基于扩散模型的逆问题解决方法实现零样本人体姿态估计 [PDF](https://arxiv.org/pdf/2510.02043), [HTML](https://arxiv.org/abs/2510.02043)
### Authors
Sahil Bhandary Karnoor,Romit Roy Choudhury
### Background
姿态估计是指追踪人类的全身体态，包括头部、躯干、手臂和腿部。在实际应用中，由于传感器数量有限，这一问题具有挑战性。以往的工作表明，条件扩散模型具有潜力，在使用来自传感器的<位置，旋转>测量值的情况下进行姿态预测。然而，几乎所有这些方法在不同用户间泛化效果不佳，主要原因在于位置测量值受到用户体型的影响较大.
### Innovation
本文将姿态估计问题形式化为逆问题，并设计了一种能够实现零样本泛化的算法。该方法利用预训练的扩散模型，并仅条件化旋转测量；来自模型的先验信息通过由测量位置推导得出的似然项进行引导。因此，对于任何用户，本文提出的InPose方法生成性地估算出最有可能的姿态序列，来解释接收到的稀疏的身体传感器测量数据.
### Conclusion
该研究通过利用扩散模型的逆问题解决方法实现零样本人体姿态估计，有效地解决了因用户体型差异导致的传统方法泛化能力差的问题。
## 601. `cs.CV` - GeoPurify: 一种用于开放词汇3D分割的高效几何蒸馏框架 [PDF](https://arxiv.org/pdf/2510.02186), [HTML](https://arxiv.org/abs/2510.02186)
### Authors
Weijia Dou,Xu Zhang,Yi Bin,Jian Liu,Bo Peng,Guoqing Wang,Yang Yang,Heng Tao Shen
### Background
近期尝试将2D视觉-语言模型(VLMs)的特征转移应用于3D语义分割，显示出持久的权衡。直接将2D特征投影到3D会导致噪声和断裂的预测，而强制几何一致性则需要昂贵的训练管道和大规模的3D标注数据。我们指出，这一限制源于主导的分割和匹配范式，它无法将2D语义与3D几何结构协调起来。在2D到3D的转移过程中，几何线索并未被消除，而是停留在噪声和视角聚合的特征中。
### Innovation
我们提出了一种名为GeoPurify的方法，一种应用小型学生亲和力网络来使用3D自监督教师模型提炼出的几何先验来净化2D VLM生成的3D点特征的高效几何蒸馏框架。在此过程中，我们设计了一种几何引导池化模块，进一步降噪点云并确保语义和结构一致性。得益于潜伏的几何信息和学会的亲和力网络，GeoPurify有效地缓解了这一冲突并提高了数据效率。广泛的实验证明，GeoPurify在主要的3D基准上取得了或超越了最强性能，同时仅使用约1.5%的训练数据。我们的代码库和检查点可在[此链接](此链接)找到。
### Conclusion
GeoPurify通过利用潜伏的几何信息和学习到的亲和力网络，有效地缓解了2D到3D转移中的权衡，实现了出色的性能，同时显著减少了所需的数据量。
## 602. `cs.CV` - 当跟踪失败时：分析SAM2在手术视频中基于点的跟踪失败模式 [PDF](https://arxiv.org/pdf/2510.02100), [HTML](https://arxiv.org/abs/2510.02100)
### Authors
Woowon Jang,Jiwon Im,Juseung Choi,Niki Rashidian,Wesley De Neve,Utku Ozbulak
### Background
现有的视频对象分割（VOS）模型，如SAM2，提供了在使用最少用户输入的情况下实现零样本跟踪的潜力。点基跟踪作为一种成本低且高效的输入类型，已经提供了有效的解决方案，但仍需要深入了解其在复杂手术环境中的可靠性及其失败模式。本文通过系统分析SAM2在腹腔镜胆囊切除手术视频中的点基跟踪失败模式，重点关注胆囊、抓钳和电凝钩这三个目标，对比研究基于段面具初始化的性能，揭示了组织相似性及边界模糊等因素对跟踪结果的影响，为提高手术视频分析中的跟踪性能提供了一些建议。
### Innovation
系统分析了点基跟踪在复杂手术环境中的失败模式，特别是在腹腔镜胆囊切除手术视频中，对比研究了胆囊、抓钳和电凝钩三个目标下的点基跟踪和段面具初始化的表现差异，揭示了组织相似性及边界模糊等因素对跟踪结果的影响，提出了改善点基跟踪性能的具体建议。
### Conclusion
点基跟踪在手术工具跟踪方面与段面具初始化竞争，但在解剖目标上表现不佳，组织相似性和边界模糊会导致失败。通过定性分析，我们揭示了影响跟踪结果的关键因素，并提出了一系列实用建议，以改善手术视频分析中的跟踪性能。
## 603. `cs.CV` - VGDM: Vision-Guided Diffusion Model for Brain Tumor Detection and Segmentation [PDF](https://arxiv.org/pdf/2510.02086), [HTML](https://arxiv.org/abs/2510.02086)
### Authors
Arman Behnam
### Background
准确检测和分割磁共振成像（MRI）中的脑肿瘤对于诊断、治疗规划和临床监测至关重要。U-Net等卷积架构长期以来一直是医学图像分割的骨干，但由于其对长程依赖关系的捕捉有限，这限制了其在复杂肿瘤结构上的性能。扩散模型的近期进展表明，这类模型在生成高保真医学图像和细化分割边界方面具有巨大潜力。因此，本研究提出了一种Vision-Guided Diffusion Model（VGDM）框架，用于脑肿瘤检测和分割。该框架基于变压器驱动的扩散过程，并在整个MRI体积中有效地建模空间关系，以提升肿瘤的体积准确性和边界精度。实验验证表明，VGDM在Dice相似度和Hausdorff距离上取得了持续改善，这表明基于变压器指导的扩散模型在肿瘤分割方面的潜力。
### Innovation
VGDM框架是一种结合了扩散模型和变压器模型的新方法，用于脑肿瘤的检测和分割。通过将视觉变压器嵌入到扩散过程中，该模型融合了全局上下文推理与迭代去噪，提升了肿瘤的体积准确性和边界精度。该方法有效解决了U-Net等传统模型在处理复杂肿瘤结构时存在的问题。实验表明，VGDM在MRI脑肿瘤分割任务中显著提高了Dice相似度和Hausdorff距离的表现，展示了变压器指导的扩散模型在肿瘤分割领域的潜在优势和研究价值。
### Conclusion
VGDM框架提供了一条通往神经肿瘤学中更好鲁棒性和可扩展性的路径，超越了传统的U-Net基准，显著提高了MRI脑肿瘤的分割精度，在Dice相似度和Hausdorff距离方面取得了稳定的改进，验证了变压器指导的扩散模型在肿瘤分割领域的应用潜力。
## 604. `cs.CV` - kabr-tools: 自动化多物种行为监测框架 [PDF](https://arxiv.org/pdf/2510.02030), [HTML](https://arxiv.org/abs/2510.02030)
### Authors
Jenna Kline,Maksim Kholiavchenko,Samuel Stevens,Nina van Tiel,Alison Zhong,Namrata Banerji,Alec Sheets,Sowbaranika Balasubramaniam,Isla Duporge,Matthew Thompson,Elizabeth Campolongo,Jackson Miliko,Neil Rosser,Tanya Berger-Wolf,Charles V. Stewart,Daniel I. Rubenstein
### Background
全面理解动物行为生态学依赖于能够量化和解释复杂多维行为模式的大规模方法。传统的野外观察方法范围有限、耗时且劳动密集型，限制了对景观范围内行为反应的评估。为了解决这一问题，我们介绍了一种名为kabr-tools（肯尼亚动物行为识别工具）的开源包，用于自动监测多种动物行为。该框架结合了无人机视频和机器学习系统，从野生动物视频中提取行为、社会和空间指标。与基于地面的方法相比，无人机观测显著提高了行为的细节度，减少了15%的可见性损失，并以更高的准确度和连续性捕捉到了更多的行为转换。我们通过三个案例研究验证了kabr-tools，分析了969个行为序列，超过了传统方法的数据捕获和注释能力。
### Innovation
kabr-tools是一种集成无人机视频和机器学习系统的开源包，用于自动监测多种动物的行为。该框架能够提取包括时间预算、行为过渡、社会互动、栖息地关联和群体组成动态在内的关键指标。它显著提高了行为监测的细节度，并通过无人机观测减少了15%的视力损失，更准确地捕获行为转换。此外，kabr-tools通过自动化地在大型景观中进行行为监测，提供了生态研究、保护和群落动态监测的强大工具，超越了传统方法的能力范围。我们通过三个案例研究验证了这一工具的有效性。
### Conclusion
kabr-tools提供了一个强大的工具，实现了生态系统的自动多物种行为监测，推进了保护生物学、生物多样性研究和生态监测。通过无人机和机器学习相结合，它能够大规模地捕捉和解释野生环境中动物的行为模式，有助于更好地理解动物的生活习性和生态关系。
## 605. `cs.CV` - MMDEW: 自然场景中的多类别密度估计 [PDF](https://arxiv.org/pdf/2510.02213), [HTML](https://arxiv.org/abs/2510.02213)
### Authors
Villanelle O'Reilly,Jonathan Cox,Georgios Leontidis,Marc Hanheide,Petra Bosilj,James Brown
### Background
在密集且遮挡严重的场景中，使用传统的离散检测方法进行物体计数往往不够准确。因此，密度图估计成为一种有效的解决方案，它能在这些场景中有效地估计物体数量。现有的多类别人群计数方法在性能上仍存在提升空间，尤其是在复杂、遮挡严重的场景中。
### Innovation
本文提出了一种多类别计数框架，该框架利用Twins金字塔视觉变压器作为骨干网络，并结合先进的多尺度解码方法构建专门的多类别计数头部。此外，采用了双任务设计，在训练时加入基于分割的类别焦点模块，以减少不同类别间的干扰。实验结果表明，该方法在VisDrone和iSAID基准测试中优于之前的多类别人群计数方法，大幅降低了平均绝对误差。
### Conclusion
该方法的区域损失机制在多类别人群计数的应用中开辟了新领域，通过应用于生物多样性监测数据集，展示了其在环境保育中的应用潜力和对扩展生态学洞察的贡献。
## 606. `cs.CV` - 利用单目视频铺就运动学评估之路：日常活动中基于最新深度学习的3D人体姿态估算器与惯性传感器的预临床基准比较 [PDF](https://arxiv.org/pdf/2510.02264), [HTML](https://arxiv.org/abs/2510.02264)
### Authors
Mario Medrano-Paredes,Carmen Fernández-González,Francisco-Javier Díaz-Pernas,Hichem Saoudi,Javier González-Alonso,Mario Martínez-Zarzuela
### Background
机器学习的进步和穿戴传感器的发展为在专业实验室之外捕获和分析人类运动提供了新的机遇。在现实世界条件下准确评估人类运动对于远程医疗服务、体育科学和康复治疗至关重要。为了比较基于单目视频和惯性测量单元（IMU）的3D人体姿势估计模型，该研究使用VIDIMU数据集，其中包括通过普通视频摄像机和五个IMU捕捉的13种临床相关日常活动。
### Innovation
研究使用了最先进的深度学习框架（MotionAGFormer，MotionBERT，MMPose 2D-to-3D姿态提升和NVIDIA BodyTrack）进行3D人体姿态估计，这些模型与IMU数据结合OpenSim逆运动学计算的关节角度进行了对比评估。研究结果表明，MotionAGFormer在所有评估指标中表现最佳，证明了这两种技术在非实验室环境中的可行性，同时指出了视频和传感器方法之间的关键权衡，包括成本、可达性和精确度。
### Conclusion
研究澄清了现成的视频模型在健康成人中已经提供了临床上有希望的运动学评估，在哪些领域这些模型落后于基于IMU的估计，并为寻找稳健、经济高效的远程健康和远程患者监控方案的科研人员和临床医生提供了宝贵指导。
## 607. `cs.CV` - 通过精细提示解锁视觉语言模型在视频异常检测中的应用 [PDF](https://arxiv.org/pdf/2510.02155), [HTML](https://arxiv.org/abs/2510.02155)
### Authors
Shu Zou,Xinyu Tian,Lukas Wesemann,Fabian Waschkowski,Zhaoyuan Yang,Jing Zhang
### Background
提示法已成为使冻结的视觉语言模型（VLMs）适应视频异常检测（VAD）的一种实用方式。然而，现有的提示往往过于抽象，忽视了定义复杂安全视频中异常的人-物互动或动作语义。
### Innovation
提出了ASK-Hint，一种结构化的提示框架，利用以动作为中心的知识来促使冻结的VLMs进行更准确和可解释的推理。该方法将提示组织成语义上一致的组（例如，暴力、财产犯罪、公共安全），并制定细粒度的指导问题，使模型预测与 discriminative 视觉线索一致。在UCF-Crime和XD-Violence上的大量实验表明，ASK-Hint在AUC上优于之前的方法，达到最先进的性能，无论是微调方法还是无需训练的方法。
### Conclusion
除了提高准确性，该框架提供了可解释的推理轨迹以指向异常，展示了跨数据集和VLM模型基线的强大泛化能力。结果突显了提示粒度的关键作用，并确立了ASK-Hint作为新的无需训练且可泛化的可解释视频异常检测解决方案。
## 608. `cs.CV` - microCLIP：细粒度图像分类的粗细粒度标记融合无监督CLIP适应 [PDF](https://arxiv.org/pdf/2510.02270), [HTML](https://arxiv.org/abs/2510.02270)
### Authors
Sathira Silva,Eman Ali,Chetan Arora,Muhammad Haris Khan
### Background
CLIP（Contrastive Language-Image Pre-training）基于视觉语言模型的无监督适应对细粒度图像分类具有重要的敏感性，但CLIP依赖粗略的全局特征，限制了其在细粒度分类任务上的表现。已有方法通过将大语言模型（LLM）描述与CLIP的[CLS]标记对齐来注入细粒度知识，但这种方法忽视了空间精度。
### Innovation
提出了一种自训练框架microCLIP，用于联合细化CLIP的视觉和文本表示。该框架的核心是Saliency-Oriented Attention Pooling（SOAP）和轻量级TokenFusion模块。此外，引入了一种两头分类器：一个冻结的分类器提供稳定的文本先验以进行伪标签生成，另一个可学习的分类器从LLM描述中初始化并结合TokenFusion进行微调。进一步开发了动态知识聚合方法，基于凸组合固定LLM/CLIP先验和TokenFusion的进化输出，迭代细化伪标签，从而发现隐藏的细粒度信号。
### Conclusion
microCLIP在13个细粒度基准测试中实现了稳定的2.90%平均准确性提升，同时仅轻量化适应。
## 609. `cs.CV` - NeuroSwift：一种轻量级跨被试框架，用于复杂场景的fMRI视觉重建 [PDF](https://arxiv.org/pdf/2510.02266), [HTML](https://arxiv.org/abs/2510.02266)
### Authors
Shiyi Zhang,Dong Liang,Yihang Zhou
### Background
通过计算机视觉技术重构脑活动中的视觉信息，可以直观理解视觉神经机制。尽管使用生成模型解码fMRI数据取得了进展，但跨被试的视觉刺激重建仍然存在挑战且计算资源需求较高。这一难题源于脑间神经表征的差异性和大脑在复杂视觉输入中对核心语义特征的抽象编码。
### Innovation
本文提出了NeuroSwift，该方法通过扩散集成互补适配器AutoKL和CLIP，用于低级特征和语义。NeuroSwift的CLIP适配器在ControlNet生成的图像与COCO描述短语上进行训练，以模拟高级视觉皮层的编码。为了跨被试泛化，预训练仅在一个被试上进行，然后仅微调17%的全连接层参数（其他组件冻结）。这种方法仅需一小时训练每个被试并在轻量级GPU（三个RTX 4090）上实现最先进的性能，并且比现有方法更优。
### Conclusion
NeuroSwift通过采用轻量级且高效的策略实现了跨被试视觉刺激的高精度重建，可以快速部署在轻量级GPU上，显著提高了重建效率和准确性。
## 610. `cs.CV` - RewardMap: 通过多阶段强化学习应对细粒度视觉推理中的稀疏奖励 [PDF](https://arxiv.org/pdf/2510.02240), [HTML](https://arxiv.org/abs/2510.02240)
### Authors
Sicheng Feng,Kaiwen Tuo,Song Wang,Lingdong Kong,Jianke Zhu,Huan Wang
### Background
细粒度视觉推理是多模态大规模语言模型（MLLM）的核心挑战。尽管最近引入的ReasonMap表明，即使是先进的MLLM在结构化且信息丰富的设置，如交通图中的空间推理任务中也表现不佳，传统强化学习由于稀疏奖励和优化不稳定的问题阻碍了这类任务的推进。因此，需要一种新的方法来改善MLLM在细粒度视觉理解和推理方面的性能。
### Innovation
论文提出了一个新的多阶段强化学习框架——RewardMap。首先，通过视觉问题回答任务构造了一个扩展的数据集ReasonMap-Plus，引入了密集的奖励信号以促进冷启动训练。接着，RewardMap框架引入了困难感知奖励设计，直接解决稀疏奖励问题，并提供了更丰富的监督，同时采用多阶段强化学习计划，从简单的感知任务逐步过渡到复杂的推理任务，提供了一种更有效的冷启动策略，相比传统的监督微调（SFT）更为出色。实验结果验证了RewardMap框架中每个组件的贡献以及它们组合的优越性，表明使用RewardMap训练的模型在6个覆盖空间推理、细粒度视觉推理和交通图以外的一般任务基准上的平均性能提升了3.47%。
### Conclusion
该研究通过构建应急奖励信号和采用多阶段强化学习框架，显著提高了MLLM在细粒度视觉理解和推理中的性能，特别是在任务稀疏奖励的场景下表现尤为突出。
## 611. `cs.CV` - TempoControl：文本到视频模型中的.temporal注意力引导 [PDF](https://arxiv.org/pdf/2510.02226), [HTML](https://arxiv.org/abs/2510.02226)
### Authors
Shira Schiber,Ofir Lindenbaum,Idan Schwartz
### Background
近年来，生成视频的模型已经能够基于自然语言提示生成高质量的视频。但这些模型通常缺乏细粒度的时间控制，无法让用户具体指定某个视觉元素在生成序列中的出现时间。
### Innovation
本文介绍了一种名为TempoControl的新方法，它能够在推理过程中对视觉概念进行时间对齐，而无需重新训练或额外的监督。TempoControl利用文本到视频扩散模型中的交叉注意力图，通过一种新型的优化方法来引导概念出现的时间。方法采用三项互补原则：通过相关性调整注意力的时间形状、通过能量增加关注点、通过熵保持空间聚焦。TempoControl实现了对时间的精确控制，同时保证了视频质量和多样性。该方法在各种视频生成应用中得到验证，包括单个多对象的时间重排序以及动作和音频对齐生成。
### Conclusion
TempoControl能够让用户在生成视频时对特定视觉元素的出现时间有精确控制，同时保持高质量和多样性。该方法适用于多种视频生成应用场景，展现了其在文本到视频转换中的有效性。
## 612. `cs.CV` - 从帧到片段：长形式视频理解中的高效关键片段选择 [PDF](https://arxiv.org/pdf/2510.02262), [HTML](https://arxiv.org/abs/2510.02262)
### Authors
Guangyu Sun,Archit Singhal,Burak Uzkent,Mubarak Shah,Chen Chen,Garin Kessler
### Background
视频大型语言模型（VLMs）在多种视觉语言任务上取得了显著成果，但由于从原始视频帧中生成的大量视觉标记超过模型上下文窗口容量，这些模型的实用应用受到限制。现有解决方案通过选择稀疏帧来减少标记数量，但这种帧级选择会丢弃重要的时间动态，导致对运动和事件连续性的推理不充分。
### Innovation
本文系统研究了时间信息的影响，并证明从单独的关键帧扩展到时间上一致的片段（关键片段）的选取能够提高视频理解效果。为了在保持固定计算预算的同时容纳片段更大的标记占位，提出了一种自适应分辨率策略，动态平衡空间分辨率和片段长度，确保每个视频的标记数量不变。实验表明，无需训练的方法F2C在Video-MME、LongVideoBench和MLVU基准测试中分别比均匀采样提高了8.1%、5.6%和10.3%的效果，强调了保留时间一致性的关键帧选择的重要性，并为将视频LLMs扩展到现实世界视频理解应用提供了实际路径。
### Conclusion
这些结果表明，不仅关键帧，还应考虑关键片段的时间连续性，展示了一种实用的方法来扩展视频LLMs以适应长形式视频理解应用。
## 613. `cs.CV` - 自我增强++：迈向分钟级高质量视频生成 [PDF](https://arxiv.org/pdf/2510.02283), [HTML](https://arxiv.org/abs/2510.02283)
### Authors
Justin Cui,Jie Wu,Ming Li,Tao Yang,Xiaojie Li,Rui Wang,Andrew Bai,Yuanhao Ban,Cho-Jui Hsieh
### Background
扩散模型极大地推动了图像和视频生成的发展，实现了前所未有的视觉质量。然而，这些模型依赖于变压器架构，在扩展至长视频生成时会带来严重的计算成本问题。尽管最近的研究尝试通过从短时间窗双向教师模型中蒸馏来生成长视频，但由于教师模型本身无法合成长视频，学生的模型容易在超出训练时间窗时表现出质的下降，主要由于连续潜在空间中的累积错误。因此，需要一种不需要长期视频教师监督或重新训练的简单有效方法来缓解长视窗视频生成的质量下降。
### Innovation
提出了一种简单有效的自我增强方法，用于在不依赖长期视频教师监督或重新训练长视频数据集的情况下缓解长视频生成中的质量下降。该方法通过教师模型提供指导信息，不重新计算重叠帧，保持时间一致性，同时将视频长度扩展到教师模型能力的20倍，并能在计算扩展时生成长度达到4分钟15秒的视频，超过基线模型支持的最大跨度的99.9%，并且大约是基线模型的50倍。
### Conclusion
我们的方法在多个标准基准和提出的改进基准上，在保真度和一致性方面显著优于基线方法。详细的长视窗视频演示可在以下链接找到：this https URL
## 614. `cs.CV` - DragFlow：基于区域监督释放DiT先验的拖拽编辑 [PDF](https://arxiv.org/pdf/2510.02253), [HTML](https://arxiv.org/abs/2510.02253)
### Authors
Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong
### Background
拖拽式图像编辑长期受到目标区域失真的困扰，主要是由于早期基础模型（如Stable Diffusion）的先验知识不足以将优化后的隐变量投影回自然图像流形。随着从基于UNet的DDPMs转向更可扩展的DiT（例如SD3.5, FLUX），生成先验变得更强，支持了各种编辑任务的进步。然而，拖拽式编辑尚未受益于这些更强大的生成先验。
### Innovation
这篇论文提出了首个框架DragFlow，通过区域监督的方式利用FLUX的强大先验，这显著提升了基于拖拽的图像编辑任务的效果。DragFlow克服了直接应用于DiT的点式拖拽编辑方法表现不佳的问题，引入了基于区域的编辑模式，并结合预训练的开放式域个性化适配器（例如IP-Adapter）以保持主体一致性，同时通过对比梯度掩码使用硬约束保留背景的准确性。此外，还利用了多模态大型语言模型来解决任务的歧义。
### Conclusion
广泛的实验在DragBench-DR和ReD Bench上证明了DragFlow优于点式和区域式的基线方法，为拖拽式图像编辑设立了新的最先进水平。
## 615. `cs.CV` - 使用耳静脉图案识别的跨品种猪识别：一种面向小型农场应用的机器学习方法 [PDF](https://arxiv.org/pdf/2510.02197), [HTML](https://arxiv.org/abs/2510.02197)
### Authors
Emmanuel Nsengiyumvaa,Leonard Niyitegekaa,Eric Umuhoza
### Background
准确的牲畜识别是现代农业的基石，支持健康监测、育种计划和生产力追踪。然而，常见的猪识别方法（如耳标和微芯片）常常不可靠、成本高昂且限于纯品种猪，因此对小规模农场来说不切实际。本研究通过提出一种非侵入性的生物识别方法解决了这一问题，该方法利用耳部静脉的独特性作为识别依据。为此，研究者对800头混血猪（兰德拉斯和皮特兰杂交和杜洛克和皮特兰杂交）的耳朵采集了图像，并通过智能手机和简单的背光源进行捕捉。开发了一套多阶段的计算机视觉管道来增强静脉可见度，提取结构和空间特征，生成生物特征签名，并利用机器学习模型进行分类。
### Innovation
本研究提出了利用耳部静脉图案的非侵入性生物识别方法来解决混合品种猪识别问题。通过使用智能手机和简单的背光技术采集图像，并开发了一套多阶段的计算机视觉管道来增强静脉可见度，从而提取结构和空间特征生成生物特征签名，利用机器学习模型进行了分类。SVM模型实现了98.12%的高精度，整个过程从图像处理到分类需要大约8.3秒，证明了其实时部署的可行性。
### Conclusion
本研究认为，通过使用永久性的生物学标记代替脆弱的物理标识符，该系统为农民提供了一种成本效益高且无压力的方法来进行动物识别。更广泛地说，研究结果证实了耳部静脉生物识别在数字化牲畜管理中的实用性，强化了其在资源受限的农业社区中的潜力，有助于推广精确农业领域的益处。
## 616. `cs.CV` - VidGuard-R1: AI-生成视频检测及解释通过推理大模型和RL [PDF](https://arxiv.org/pdf/2510.02282), [HTML](https://arxiv.org/abs/2510.02282)
### Authors
Kyoungjun Park,Yifan Yang,Juheon Yi,Shicheng Zheng,Yifei Shen,Dongqi Han,Caihua Shan,Muhammad Muaz,Lili Qiu
### Background
随着AI生成视频的迅速发展，迫切需要有效的检测工具来减轻信息误导和社会声誉损害等风险。除了准确分类之外，检测模型还需要提供可解释的解释以确保监管者和最终用户能够理解。因此，本文介绍了一种名为VidGuard-R1的新工具，用于检测视频真实性，它使用组相对策略优化（GRPO）对多模态大语言模型（MLLM）进行微调，以满足这一需求。
### Innovation
本文提出了VidGuard-R1，这是第一个使用组相对策略优化（GRPO）对多模态大语言模型（MLLM）进行微调的视频真实性检测器。该模型在提供准确判断的同时还能给出详尽的理性解释。除此之外，研究人员还创建了一个由140,000个真实和AI生成视频组成的具有挑战性的数据集，并使用GRPO对Qwen-VL进行了微调，以针对时间序列特征和生成复杂性建立特定的奖赏模型。实验结果表明，VidGuard-R1在现有基准测试上达到最先进的零样本性能，且通过额外训练将准确率提升至超过95%。
### Conclusion
案例研究表明，VidGuard-R1能够生成精确且可解释的预测后理性。作者还将代码公开分享，以促进该领域的进一步研究和发展。
## 617. `cs.CV` - 学习生成具有物理指导的物体交互视频 [PDF](https://arxiv.org/pdf/2510.02284), [HTML](https://arxiv.org/abs/2510.02284)
### Authors
David Romero,Ariana Bermudez,Hao Li,Fabio Pizzati,Ivan Laptev
### Background
近年来，基于视频生成的模型已经取得了显著进展，并被应用于电影、社交媒体制作和广告等领域。除了其创造性潜力，这些模型还有望作为机器人和体感决策领域的世界模拟器。尽管取得了显著进步，但当前的方法仍然难以生成物理上可信的对象交互，并缺乏物理基础的控制机制。文章针对这一限制，介绍了一种新的方法KineMask，用于物理指导的视频生成，该方法通过给定一张图片和指定的对象速度，可以生成带有推断运动和未来对象交互的视频。
### Innovation
文章提出了一种新颖的两阶段训练策略，该策略逐渐移除了对未来的运动监督，通过对象遮罩进行训练。使用这一策略，在合成情景中训练视频扩散模型（VDMs），并展示在真实环境中显著改善了对象交互。此外，KineMask将低级运动控制与高级文本条件结合，通过预测场景描述，有效支持复杂动态现象的合成。广泛实验表明，KineMask在可比规模的模型中实现了显著改进。消融研究进一步强调了低级和高级条件在VDMs中的互补作用。
### Conclusion
实验结果表明，KineMask在物理指导的视频生成方面达到了显著改进，其代码、模型和数据将被公开提供。
## 618. `cs.CV` - VideoNSA：原生稀疏注意机制扩展视频理解 [PDF](https://arxiv.org/pdf/2510.02295), [HTML](https://arxiv.org/abs/2510.02295)
### Authors
Enxin Song,Wenhao Chai,Shusheng Yang,Ethan Armand,Xiaojun Shan,Haiyang Xu,Jianwen Xie,Zhuowen Tu
### Background
由于上下文长度限制，多模态语言模型在视频理解方面的表现受限。模型常常错过关键的过渡帧，难以长时间尺度上保持连贯性。为此，本文通过将原生稀疏注意（NSA）应用于视频-语言模型来解决问题。使用一个包含216K视频指令的数据集对模型进行端到端训练，以适应Qwen2.5-VL模型。在注意机制上，采用了硬件感知混合方法，文本部分保持密集注意，视频部分使用NSA。
### Innovation
提出了一种新的方法VideoNSA，该方法通过端到端训练高度优化的多模态语言模型，在长视频理解、时间推理和空间基准测试中取得了更好性能。此外，通过消融实验发现，128K token的可靠扩展、固定预算下的全局-局部注意分配优化、任务依赖的分支使用模式以及可学习的结合稀疏注意调度动态注意集中为四个关键发现。
### Conclusion
VideoNSA方法在长视频理解、时间推理和空间基准测试上取得了优异的性能，证明了原生稀疏注意机制的有效性。
## 619. `cs.CV` - 基于多感官动作条件的视频生成 [PDF](https://arxiv.org/pdf/2510.02287), [HTML](https://arxiv.org/abs/2510.02287)
### Authors
Yichen Li,Antonio Torralba
### Background
当前的视频模型在作为世界模型时存在缺陷，因为它们缺乏细腻的控制能力。通用的家庭机器人需要实时进行精细的运动控制，以处理复杂的任务和紧急情况。本文旨在通过引入多模态精细动作来捕捉这种精确的控制能力，这些动作考虑了本体感觉、运动知觉、力触觉和肌肉激活等多种感官信息，以实现难以通过文本条件生成模型模拟的精细互动。
### Innovation
本文发展了一种特征学习方法，能够在维护每种模态提供独特信息的同时，对这些模态进行对齐。此外，还提出了一种正则化方案，以增强动作轨迹特征在表示复杂互动动态中的因果性。实验结果表明，综合多感官信息可以提高模拟的准确性并减少时间漂移。广泛的应用表明，本研究对多感官动作条件下的视频生成的有效性和实际应用均有显著提升。
### Conclusion
本研究通过引入多模态精细动作，更好地模拟了真实世界中精细的互动过程，并开发了相应的机器学习方法和正则化策略，提高了多感官视频生成的准确性和实时性。
## 620. `cs.CV` - 从视频基础模型推断动态物理属性 [PDF](https://arxiv.org/pdf/2510.02311), [HTML](https://arxiv.org/abs/2510.02311)
### Authors
Guanqi Zhan,Xianzheng Ma,Weidi Xie,Andrew Zisserman
### Background
本文研究了从视频中预测动态物理属性的任务，涉及弹性、粘性和滑动摩擦力等需要时间信息才能推断的属性。以往的研究主要依赖于经典计算机视觉技术或者预训练的视频生成和自我监督模型来进行推断，但新颖之处在于通过多模态大型语言模型（MLLMs）实现这一目标，并开发了新的视频数据集来支持实世界的应用评估。
### Innovation
研究团队提出了三种从视频中推断物理属性的方法：一种是使用经典的计算机视觉技术作为参考标准（Oracle方法），一种是基于视觉提示和可训练提示向量的跨注意力机制，还有一类是针对多模态大型语言模型（MLLMs）的提示策略。此外，研究还指出，通过生成或自我监督训练的视频基础模型可以达到与Oracle方法类似的性能，尽管在性能上略有差距，而MLLMs目前则表现出较低的性能，但通过合适的提示策略可以改善其性能。
### Conclusion
该研究通过收集新的视频数据集和多种方法探索了从视频中推断动态物理属性的可能性，表明生成或自我监督训练的视频基础模型表现良好，尽管MLLMs的性能还有待提升。未来可以通过更适合的提示策略来进一步优化MLLMs的应用效果。
## 621. `cs.CV` - 嗡！切！扑！— 从现实世界互动中学习物体声音 [PDF](https://arxiv.org/pdf/2510.02313), [HTML](https://arxiv.org/abs/2510.02313)
### Authors
Mengyu Yang,Yiming Chen,Haozheng Pei,Siddhant Agarwal,Arun Balajee Vasudevan,James Hays
### Background
日常物体的交互会产生特定于这些物体的声音。本研究旨在评估模型将这些声音与直接参与的物体进行关联的能力，引入了声音对象检测任务。受人类感知的启发，研究建立了一个多模态的物体感知框架，通过野外第一人称视频训练模型。为了鼓励对物体的关注，首先开发了一个自动管道来计算参与物体的分割掩码，从而指导模型在训练过程中关注交互中的最有信息价值的区域。随后使用了一个槽注意力视觉编码器进一步强化物体先验知识。研究在新的物体声音检测任务上以及现有的一些多模态动作理解任务上均实现了最佳性能。
### Innovation
研究设计了一个多模态物体感知框架，通过野外第一人称视频训练模型，并首次开发了一个自动管道来计算参与物体的分割掩码，以引导模型关注最有信息价值的交互区域。此外，引入了槽注意力视觉编码器来进一步强化物体先验知识。最终在物体声音检测任务和多模态动作理解任务上实现了有竞争力的性能。
### Conclusion
研究展示了在新的声音物体检测任务以及现有的多模态动作理解任务上的卓越性能，表明其多模态物体感知框架的有效性。
## 622. `cs.CV` - JaneEye: 一种12纳米每秒2000帧每帧18.9微焦耳的眼动追踪加速器 [PDF](https://arxiv.org/pdf/2510.01213), [HTML](https://arxiv.org/abs/2510.01213)
### Authors
Tao Han,Ang Li,Qinyu Chen,Chang Gao
### Background
眼动追踪已成为扩展现实（XR）中基于眼动的交互的关键技术。然而，传统的帧频眼动追踪系统往往无法满足XR在精确度、延迟和能效方面的严格要求。事件相机因其超高的时间分辨率和低功耗成为一种有吸引力的替代方案。这项研究的目标是在可穿戴设备上设计一种节能的眼动追踪硬件加速器。
### Innovation
提出了一个名为JaneEye的事件驱动式眼动追踪硬件加速器，专门针对可穿戴设备。它采用了基于稀疏高时间分辨率事件数据的轻量级神经网络架构，其中包含一个新颖的ConvJANET层，该层简化了传统的ConvLSTM模型，通过保留仅遗忘门来减少计算复杂度，同时保留时间建模能力。此外，还采用了定制的激活函数线性近似（hardsigmoid和hardtanh）和定点量化，以及软件-硬件协同设计，实现了400 MHz的运行频率，端到端延迟为0.5 ms，能效为18.9微焦耳/帧。
### Conclusion
JaneEye为下一代XR穿戴设备中的低功耗和高性能眼动追踪解决方案设立了新标准。
## 623. `cs.CV` - Ovi: 双分支跨模态融合的音频视频生成 [PDF](https://arxiv.org/pdf/2510.01284), [HTML](https://arxiv.org/abs/2510.01284)
### Authors
Chetwin Low,Weimin Wang,Calder Katyal
### Background
传统的音频-视频生成方法通常依赖于复杂的多阶段架构或先后顺序的合成。这种生成方式需要分别针对声音和视觉进行处理，再通过后处理对齐。这种过程不仅复杂，还可能导致不自然的时间对齐。
### Innovation
Ovi引入了一个统一的音频-视频生成框架，将声音和视频视为单一生成过程。通过采用基于twin-DiT模块的块级跨模态融合，Ovi实现了自然同步并消除了需要单独流水线或后处理对齐的需求。此外，Ovi优化了音频塔的初始化，并通过大规模视频数据从零开始训练，使得音频塔能够生成逼真的音效和带有丰富说话者身份和情感的语音。
### Conclusion
Ovi能够使用自然的语音和准确、上下文匹配的声音效果进行电影级的视频片段生成，实现了自然的故事叙述。所有示例、代码和模型权重都已发布。
## 624. `cs.CV` - StealthAttack: 密度引导的illusion增强3D高斯点云对抗攻击 [PDF](https://arxiv.org/pdf/2510.02314), [HTML](https://arxiv.org/abs/2510.02314)
### Authors
Bo-Hsu Ke,You-Zhe Xie,Yu-Lun Liu,Wei-Chen Chiu
### Background
三维场景表示方法，如神经辐射字段(NeRF)和3D高斯点(3DGS)在新颖视图合成方面取得了显著进步。随着这些方法的广泛应用，评估和改进它们的漏洞变得至关重要。本文分析了3DGS对抗图像级篡改攻击的鲁棒性，并提出了一种新颖的密度导向篡改方法。该方法通过内核密度估计(KDE)识别低密度区域，注入高斯点，从而在污染视图中清晰地嵌入视角依赖的虚假对象，而对无辜视图影响最小。此外，本文还引入了一种自适应噪声策略，破坏多视图一致性，进一步增强攻击效果。我们提出了一种基于KDE的评估协议，以系统地评估攻击难度，使未来的研究能够客观地进行基准比较。
### Innovation
1. 提出了一种密度导向的伪象注入方法，通过KDE识别低密度区域，注入高斯点，从而在污染视图中清晰地嵌入视角依赖的虚假对象。2. 引入了一种自适应噪声策略来破坏多视图一致性，进一步增强攻击效果。3. 基于KDE的评估协议系统地评估攻击难度，为未来研究提供客观基准。
### Conclusion
广泛的实验表明，本文方法在对抗攻击效果上优于现有最先进的技术。
## 625. `cs.CV` - NoiseShift：针对更好低分辨率图像生成的分辨率感知噪声重新校准 [PDF](https://arxiv.org/pdf/2510.02307), [HTML](https://arxiv.org/abs/2510.02307)
### Authors
Ruozhen He,Moayed Haji-Ali,Ziyan Yang,Vicente Ordonez
### Background
目前使用固定分辨率训练的文本到图像的扩散模型往往无法泛化，即使在生成低于训练分辨率的图像时也是如此。高分辨率的文本到图像生成器目前无法为那些不需要高分辨率图像的用户提供一个预算高效的替代方案。研究发现扩散模型中一个关键的技术洞察：噪声调度器在不同分辨率下的感知效果不一致。较低分辨率的图像在相同水平的噪声影响下，信号被不均匀的去除更多，造成训练和测试之间的不匹配。为了缓解这一限制，本文提出了一种无需训练的方法NoiseShift，该方法可以根据分辨率大小重新校准去噪器中的噪声水平。NoiseShift方法对现有的模型架构和采样时间序列没有任何影响，且兼容现有模型。在实验中，当应用于Stable Diffusion 3、Stable Diffusion 3.5和Flux-Dev时，低分辨率的质量显著提升。在LAION-COCO和CelebA数据集上的实验结果显示，NoiseShift分别提高了SD3.5 15.89%，SD3 8.56%，Flux-Dev 2.44%和SD3.5 10.36%，SD3 5.19%，Flux-Dev 3.02%的FID分数。这些结果表明NoiseShift可以有效地减少分辨率依赖的伪影并改进低分辨率图像生成的质量
### Innovation
提出了一种无需训练的方法NoiseShift，该方法可以根据分辨率大小重新校准去噪器中的噪声水平。这种方法对现有的模型架构和采样时间序列没有任何影响，且兼容现有模型。这种方法可以通过调整噪声水平来平衡不同分辨率下的信号损失，从而解决高度训练和测试之间的不匹配问题，提高低分辨率图像生成的质量
### Conclusion
NoiseShift有效地缓解了分辨率依赖的伪影，显著提高了低分辨率图像生成的质量。该方法已在多个文本到图像生成模型上进行了验证，表明它能够在不更改模型结构的情况下，改善低分辨率生成的结果，且提升效果显著
## 626. `cs.CV` - 在创建有效辅导系统中的领域专家作用 [PDF](https://arxiv.org/pdf/2510.01432), [HTML](https://arxiv.org/abs/2510.01432)
### Authors
Sarath Sreedharan,Kelsey Sikes,Nathaniel Blanchard,Lisa Mason,Nikhil Krishnaswamy,Jill Zarestky
### Background
在人工智能应用于教育的领域中，领域专家提供的经过精心挑选的知识常被忽视。本文通过探讨如何利用此类知识创建新颖的教育系统，重点关注领域专家知识在创建有效辅导系统中的作用。
### Innovation
本文创新地提出可以通过使用可解释的人工智能技术来自动创建课程，将领域专家针对特定问题的规则与新型的可解释人工智能技术结合，以生成可供学习者使用的自动课程。同时，专家指定的学习课程可以帮助开发能够提供更佳学习体验并且更为高效的自适应辅导系统。
### Conclusion
通过以创建具有授粉者识别辅导系统的案例研究为例，强调了此类方法的重要性。
## 627. `cs.CV` - VENTURA: 适应统一任务条件导航的图像扩散模型 [PDF](https://arxiv.org/pdf/2510.01388), [HTML](https://arxiv.org/abs/2510.01388)
### Authors
Arthur Zhang,Xiangyun Meng,Luca Calliari,Dong-Ki Kim,Shayegan Omidshafiei,Joydeep Biswas,Ali Agha,Amirreza Shaban
### Background
机器人必须适应各种人类指令，并在未结构化的开放环境中安全操作。近期的视觉-语言模型(VLMs)为语言和感知的结合提供了强大的先验知识，但在导航任务中仍难以操控，因为它们的动作空间和在预训练目标上的差异阻碍了对机器人任务的迁移。因此，有必要开发新的导航系统来改进这一点。
### Innovation
作者引入了VENTURA，这是一种视觉-语言导航系统，通过微调互联网预训练的图像扩散模型来进行路径规划。与直接预测低级动作不同，VENTURA生成了一张路径蒙版（即视觉计划），捕捉到细粒度的、上下文相关的导航行为。通过轻量级的行为克隆策略将这些视觉计划转化为可执行轨迹，从而实现自然语言指令生成多样化的机器人行为。为了扩展训练，作者利用自监督跟踪模型产生的路径蒙版作为监督信号，避开了手工像素级注释或工程化的数据收集。
### Conclusion
VENTURA在广泛的实地评估中表现出色，任务包括物体获取、障碍物避让和地形偏好等，与最新的基础模型基准相比，提高了成功的几率33%并减少了碰撞次数54%。值得注意的是，VENTURA在未见过的任务组合中表现出强大的泛化能力，展示了潜在的组合能力。
## 628. `cs.CV` - 基于运动场散度的一种高效的视频帧插值质量度量 [PDF](https://arxiv.org/pdf/2510.01361), [HTML](https://arxiv.org/abs/2510.01361)
### Authors
Conall Daly,Darren Ramsook,Anil Kokaram
### Background
视频帧插值是用于视频时间增强的基本工具，但现有的质量度量难以有效评估插值伪影的感知影响。现有的像PSNR、SSIM和LPIPS这样的度量忽略了时间连贯性。为此，专门为视频帧插值研发的先进度量如FloLPIPS虽然解决了一些问题，但由于计算效率低下，限制了它们的实际应用。
### Innovation
本文提出了一种新的全参考质量度量$text{PSNR}_{text{DIV}}$，该度量通过运动发散加权增强PSNR。该方法借鉴了档案电影修复领域中的做法，利用运动场中奇异性的检测来加权图像误差。实验证明，$text{PSNR}_{text{DIV}}$比FloLPIPS在皮尔逊线性相关系数上提高了0.09，并且速度快2.5倍，内存消耗少4倍。该度量在不同内容类别中保持一致表现，并对所用的运动估计器具有鲁棒性。
### Conclusion
这种效率高且准确的$text{PSNR}_{text{DIV}}$能够快速进行质量评估，并作为损失函数应用于训练用于视频帧插值任务的神经网络。已经实现了该度量库，相关链接见文末。
## 629. `cs.CV` - 基于AI驱动的远程医疗系统在产前保健中的开发与评估 [PDF](https://arxiv.org/pdf/2510.01194), [HTML](https://arxiv.org/abs/2510.01194)
### Authors
Juan Barrientos,Michaelle Pérez,Douglas González,Favio Reyna,Julio Fajardo,Andrea Lara
### Background
在低资源环境中，特别是在低收入和中等收入国家的农村地区，获取产科超声检查的机会有限。为了解决这一问题，本研究提出了一种包含人工智的远程医疗系统，以辅助非专业人士（如助产士）使用盲扫协议获取关键的诊断性胎儿图像。
### Innovation
该系统结合了分类模型和基于网络的平台，用于异步专家评审。通过识别盲扫研究中的关键帧，AI系统使专家能够专注于解释，而无需审查整个视频。该系统通过非专业人士使用的低成本便携式超声诊断系统（POCUS）捕获的盲扫视频进行了评估，结果显示该系统能够识别非专家制作的扫查中标准的胎儿平面。
### Conclusion
实地评估表明，该系统具有良好的用户体验和低的认知负担，表明其有可能在服务不足地区扩展产前成像的访问范围。
## 630. `cs.CV` - MorphGen: 可控并具有形态学合理性的生成细胞成像 [PDF](https://arxiv.org/pdf/2510.01298), [HTML](https://arxiv.org/abs/2510.01298)
### Authors
Berker Demirel,Marco Fumero,Theofanis Karaletsos,Francesco Locatello
### Background
细胞形态学模拟是加速基于高内涵图像的药物发现和基因编辑的关键技术方向。目前，已经有多种方法来实现这一目标，但这些方法通常会牺牲内质网等特定器室的细节，或者无法灵活地生成多种细胞类型和扰动下的细胞形态，因此需要一种新的方法来支持这一过程，该方法能够可控地生成各种细胞类型和不同条件下的细胞形态，同时保持生物学意义的模式特征。
### Innovation
本文介绍了一种名为MorphGen的扩散生成模型，能够同时生成完整的荧光通道，保留每种器室的结构，从而实现细粒度的形态分析，这对于生物解释至关重要。MorphGen不同于以往的一些方法，后者将多通道染色压缩为RGB图像，从而丧失了特定器室的细节。MorphGen通过与OpenPhenom（一个先进的生物基础模型）的表型嵌入进行对齐训练，能够产生与已知细胞形态学一致的生物学意义图案。
### Conclusion
MorphGen在实际细胞图像中的一致性得到了验证，相比以往最先进的MorphoDiff，MorphGen在生成多个细胞类型下的图像时，FID分数降低了35%以上，证明了其在生成细胞图像方面的优越性。
## 631. `cs.CV` - 超越简单融合：基于自适应门控融合的鲁棒多模态情感分析 [PDF](https://arxiv.org/pdf/2510.01677), [HTML](https://arxiv.org/abs/2510.01677)
### Authors
Han Wu,Yanming Sun,Yunhe Yang,Derek F. Wong
### Background
多模态情感分析（MSA）利用来自多种模态（如文本、音频和视觉）的信息融合来提升情感预测。然而，简单的融合技术通常无法应对模态质量差异带来的问题，例如噪声、缺失或语义冲突，这会导致性能下降，尤其是在区分微妙的情感细微差别时。
### Innovation
提出了一个简单高效的自适应门控融合网络（AGFN），该网络通过基于信息熵和模态重要性的双重门控融合机制自适应调整特征权重。这有助于减少噪声模态的影响并优先处理信息性提示，通过单模态编码和跨模态交互持续学习。
### Conclusion
在CMU-MOSI和CMU-MOSEI上的实验表明，AGFN在准确度方面显著优于强基准，能够稳健地区分细微情感。特征表示的可视化分析表明，AGFN通过学习更广泛的特征分布，减少了特征位置与预测误差的相关性，降低了对特定位置的依赖，从而增强了多模态特征表示的鲁棒性。
## 632. `cs.CV` - 从2D到3D，基于深度学习的磁共振成像形状重建：综述 [PDF](https://arxiv.org/pdf/2510.01296), [HTML](https://arxiv.org/abs/2510.01296)
### Authors
Emma McMillian,Abhirup Banerjee,Alfonso Bueno-Orovio
### Background
基于深度学习的三维（3D）形状重建技术从二维（2D）磁共振成像（MRI）中提取，越来越重要。这一技术在医疗疾病诊断、治疗计划和计算模型中发挥着关键作用。许多相关研究侧重于MRI重建方法，主要分为点云法、网格法、形状感知法和体素模型四大类。通过对这四种方法的分析，基本涵盖了多种解剖结构，从心脏到神经系统再到肺部成像。此外，还讨论了模型在病理性解剖的应用、数据集的重要性、计算需求及评估标准等问题，突显出多模态集成和跨模态框架的新兴研究方向。
### Innovation
综述文章主要创新点在于它对4种主要3D MRI重建方法（点云法、网格法、形状感知法和体素模型）的全面覆盖和详细分析，提供了从心脏到神经系统再到肺部成像的广泛视角，强调了疾病病理解剖中的应用，以及数据集、计算需求和评估标准的重要性，并且指出了多模态集成和跨模态框架等新兴研究方向。
### Conclusion
本文旨在为研究人员提供一个结构化的3D重建方法概览，以便识别推进深度学习以实现更稳健、更通用和更临床相关解决方案的机会。
## 633. `cs.CV` - 最优控制遇见流动匹配：一条原理性的多主题保真路径 [PDF](https://arxiv.org/pdf/2510.02315), [HTML](https://arxiv.org/abs/2510.02315)
### Authors
Eric Tillmann Bill,Enis Simsar,Thomas Hofmann
### Background
文本到图像（T2I）模型在处理单实体提示时表现出色，但在处理多主题描述时常常出现问题，如属性泄漏、身份纠缠和主题遗漏。现有的方法在处理多主题一致性方面的表现不理想，需要更有效的理论框架和优化目标来引导采样动态，以实现多主题保真。
### Innovation
本文提出了第一个理论框架，结合了基于随机最优控制的流动匹配（FM）原理，旨在通过控制采样动态来实现多主题保真。该框架推出了两种架构无关的算法：(i) 一个无需训练的测试时间控制器，在一次通量更新中扰动基速度，(ii) Adjoint Matching，一种轻量级的微调规则，通过反向的伴随信号反向调节控制网络，同时保留基模型的能力。该方法统一了先前的注意力启发式方法，通过流动匹配-扩散模型对应扩展到扩散模型，提供了一条明确设计用于多主题保真性的微调途径。
### Conclusion
在多个模型（如Stable Diffusion 3.5、FLUX和Stable Diffusion XL）上，这两种算法在保持基模型风格的同时，持续地改善了多主题的对齐情况。测试时间控制可以在轻量级的GPU上高效运行，微调控制器即使在有限的提示上进行训练，也能够泛化到未见过的提示。此外，指出FOCUS（流动最优控制用于未纠缠的主题）在多个模型上取得了最先进的多主题保真效果。
## 634. `cs.CV` - VaPR -- 视觉语言偏好对齐以进行推理 [PDF](https://arxiv.org/pdf/2510.01700), [HTML](https://arxiv.org/abs/2510.01700)
### Authors
Rohan Wadhawan,Fabrice Y Harel-Canada,Zi-Yi Dou,Suhaila Shakiah,Robinson Piramuthu,Nanyun Peng
### Background
现有的偏好微调方法，如直接偏好优化（DPO）结合AI生成的反馈，在使大型视觉-语言模型（LVLM）与人类偏好一致方面显示出潜力。然而，这些方法忽视了合成偏好注释中广泛存在的噪声问题，如风格和长度偏见。为了解决这一问题，我们提出了基于LLM引导的响应编辑框架，用于生成具有目标错误的硬负面响应，这些响应在风格和长度上与被接受的样本相似。使用这种框架，我们创建了VaPR数据集，包含30K高质量样本，用于微调三类LVLM：LLaVA-V1.5、Qwen2VL及Qwen2.5VL（2B-13B大小）。
### Innovation
我们开发了一个基于LLM引导响应编辑的硬负面响应生成框架，旨在解决合成偏好注释中的风格和长度偏见问题。通过这种方法，开发了包含30K高质量样本的VaPR数据集，用于微调LLaVA、Qwen2VL和Qwen2.5VL三类LVLM。实验结果显示，VaPR模型在十项基准测试中取得了显著的性能提升，LLaVA提升了6.5%，Qwen2VL提升了4.0%，Qwen2.5VL提升了1.5%。此外，VaPR还减少了LVLM对二元问题简单回答“是”的倾向，提高了推理任务的表现。进一步分析显示，随着数据量的增加，模型性能持续提升，LLaVA模型在小规模数据下也有所受益。
### Conclusion
通过VaPR数据集和框架，实现了LVLM性能的重大提高，并且该框架可适用于开源LLM作为编辑器。在VaPR-OS上训练的模型达到了与GPT-4o合成的ame模型相似的性能水平。项目的所有数据、模型和代码均可在项目页面上找到。
## 635. `cs.CV` - 通过行为引导的微调使视频模型与人类社交判断对齐 [PDF](https://arxiv.org/pdf/2510.01502), [HTML](https://arxiv.org/abs/2510.01502)
### Authors
Kathy Garcia,Leyla Isik
### Background
人类能够直观地感知视觉场景中的复杂社会信号，但现有的先进人工智能模型是否以类似方式处理这些信号仍不清楚。本文通过引入新的基准测试数据集，探讨现代视频和语言模型是否能够捕捉人类感知的社会视频相似性，并研究如何通过人类行为数据将这种结构注入模型中。
### Innovation
本文提出了一个新的基准测试，包含超过49,000个社交视频片段的奇一出相似性判断，发现了人类相似度和基于字幕的语言嵌入之间的较强关联，而先验的视频模型则表现较差。本文通过在人类判断上微调TimeSformer视频模型，并使用低秩适应（LoRA）的新颖三元组-RSA目标，成功改善了模型对人类感知相似性结构的对齐。研究显示，微调后的视频模型与语言嵌入有更高的共享方差，并解释了语言模型未捕捉的独特方差。此外，人类相似度的微调增强了模型对社交情感属性（亲密性、情感、优势、沟通）的编码。
### Conclusion
本文的研究发现表明，现有的预训练视频模型在社会识别方面存在差距，而行为引导的微调可以将视频模型塑造得更加符合人类的社会感知。
## 636. `cs.CV` - 在发展合理多模态模型中通过模型合并保持语言专属性能 [PDF](https://arxiv.org/pdf/2510.01845), [HTML](https://arxiv.org/abs/2510.01845)
### Authors
Ece Takmaz,Lisa Bylinina,Jakub Dotlacil
### Background
现有的视觉-语言模型具有大量参数并从庞大的数据集中学习，已经超越了孩子在语言习得过程中接触的语言数据量。本文关注BabyLM挑战中的多模态赛道，旨在解决这一差距问题。
### Innovation
本文开发了在资源有限环境下、基于发展合理数据集的语言模型和多模态模型。通过模型合并（利用加权线性插值融合）技术，多模态模型在语言专属性能任务上的表现得到了改善，同时保持了多模态性能。
### Conclusion
研究表明，多模态模型在语法等语言专属性能任务上表现不佳，通过与文本模型的模型合并可以在一定程度上缓解这一问题，同时也维护了多模态模型的性能。
## 637. `cs.CV` - 端到端神经压缩与重建的超高效解码 [PDF](https://arxiv.org/pdf/2510.01407), [HTML](https://arxiv.org/abs/2510.01407)
### Authors
Ethan G. Rogers,Cheng Wang
### Background
图像压缩和重建对于各种数字应用至关重要。尽管当代基于神经网络的压缩方法取得了显著的压缩率，但这些技术的采用受到了用于数据重建的卷积解码器复杂性和高计算成本的阻碍。
### Innovation
开发了一种新颖的压缩重建框架，将低秩表示引入自动编码器和向量量化。通过在图像学习的潜在表示上执行一系列高效的低秩操作，能够高效地高质量重建数据。该方法大幅减少了神经压缩/重建的解码阶段的计算负担，从根本上消除了解码计算瓶颈，同时保持了图像输出的高度保真度。
### Conclusion
该方法显著降低了神经压缩/重建中的解码阶段的计算开销，达到了在保持高图像输出保真度的同时消除解码计算瓶颈的目的。
## 638. `cs.CV` - ActiveUMI：基于无机器人的人类演示的主动感知机器人操作 [PDF](https://arxiv.org/pdf/2510.01607), [HTML](https://arxiv.org/abs/2510.01607)
### Authors
Qiyuan Zeng,Chengmeng Li,Jude St. John,Zhongyi Zhou,Junjie Wen,Guorui Feng,Yichen Zhu,Yi Xu
### Background
本文介绍了ActiveUMI框架，这是一个数据采集系统，可以将现实世界的人类演示转换为能够执行复杂双臂操作的机器人。这个框架的核心在于，结合了一种便携式虚拟现实远程操作套装和具有传感控制的设备，通过精确的姿态对准，连接了人类和机器人的运动学。本文还探讨了如何确保仿人机器人的移动性和数据采集的质量，包括沉浸式3D模型渲染、独立可穿戴计算机以及高效的校准方法等关键技术。
### Innovation
ActiveUMI的最大创新点在于其捕捉主动的、第一人称的感知。通过使用头部显示器记录操作者有意识的头部运动，该系统学会视觉注意力与操作之间的关键联系。此外，通过将数据采集系统与有学习能力的主动感知相结合，ActiveUMI为创建具有广泛应用和强大功能的真实环境机器人策略提供了一种有效且可扩展的途径。
### Conclusion
本文通过ActiveUMI系统评估了多个复杂的双臂任务，发现仅基于ActiveUMI数据训练的策略在同分布任务中达到了70%的成功率，并且在测试新的物体和新环境时依然保持了56%的成功率。因此，便携式数据采集系统配以学习到的主动感知有效提高了机器人策略的普适性和能力。
## 639. `cs.CV` - 使用变换器-潜在扩散模型生成光子带图 [PDF](https://arxiv.org/pdf/2510.01749), [HTML](https://arxiv.org/abs/2510.01749)
### Authors
Valentin Delchevalerie,Nicolas Roy,Arnaud Bougaham,Alexandre Mayer,Benoît Frénay,Michaël Lobet
### Background
光子晶体允许纳米尺度上精细控制光传播，因此在光子学和量子技术的发展中起着关键作用。光子带图（BDs）是研究不均匀结构材料中光传播的重要工具。然而，计算BDs需要求解麦克斯韦方程组，这在数值上是昂贵的，尤其是在嵌入反设计技术的优化循环中更加复杂。
### Innovation
本文首次提出了一种基于扩散模型的BD生成方法，能够推广和扩展到任意三维结构。该方法将变换器编码器与潜在扩散模型结合，从输入结构中提取上下文嵌入，生成相应的BD。此外，本文还提供了变换器和扩散模型为何适合捕捉光子学中复杂的干涉和散射现象的见解，为该领域的替代建模策略铺平了道路。
### Conclusion
所提出的方法对于生成光子带图提供了一种新的高效方法，具有广泛的适用性和扩展性，并为进一步的光子学建模研究提供了一种潜在的解决方案。
## 640. `cs.CV` - 具有微表面BRDF与镜面光滑度参数化2D 高斯打点与延迟着色的可回光高光泽物体 [PDF](https://arxiv.org/pdf/2510.02069), [HTML](https://arxiv.org/abs/2510.02069)
### Authors
Georgios Kouros,Minye Wu,Tinne Tuytelaars
### Background
高光泽物体的准确重建和回光仍然是长期的挑战，因为物体形状、材料属性及光照是内在难以分离的。现有的神经渲染方法通常依赖简化版的BRDF模型或耦合了镜面和漫反射的参数化模型，这限制了材料的忠实恢复并限制了回光的准确性。
### Innovation
提出了一种回光框架，将微表面BRDF与镜面光滑度参数化纳入到2D高斯打点与延迟着色之中。这种表述使得材料分解更加符合物理，基于扩散先验的表面法线与漫反射颜色指导早期优化并消除歧义。环境体细分优化加速收敛并保留高动态范围镜面反射。
### Conclusion
在复杂高光泽场景的广泛实验表明，该方法实现了高质量的几何和材料重构，相比现有高斯打点方法，我们的方法在新型光照下的回光更加真实和一致。
## 641. `cs.CV` - MPMAvatar：学习基于准确和稳健物理动力学的3D高斯 avatar [PDF](https://arxiv.org/pdf/2510.01619), [HTML](https://arxiv.org/abs/2510.01619)
### Authors
Changmin Lee,Jihyun Lee,Tae-Kyun Kim
### Background
尽管在通过视觉观察创建3D头像方面已经取得了显著进展，但如何用松散衣物对人类进行物理合理动态建模仍然是一个具有挑战性的问题。虽然一些现有工作通过利用物理仿真来解决这个问题，但它们在动画输入方面却面临准确性和鲁棒性上的局限性。因此，研究者们正致力于开发一种新的框架—即MPMAvatar，该框架可以从多视角视频中创建支持高度真实和鲁棒动画，并能够从任意视角进行逼真渲染的3D人类头像。核心理念是采用基于物质点方法的模拟器，该模拟器通过集成各向异性材料模型和新颖的碰撞处理算法来更好地模拟复杂变形及与底层身体的接触。结合这一动力学建模方案与可使用3D高斯点渲染并实现高保真渲染的规范avatar，以实现更物理真实的动画渲染。
### Innovation
该研究的创新之处在于：1. 提出了MPMAvatar框架，能够从多视角视频中创建具有高度真实性和鲁棒性的动画3D人类头像，以实现多视角下的逼真渲染。2. 提出了基于物质点方法的模拟器，该模拟器能够细致地建模松散衣物和与底层身体的复杂接触，同时集成各向异性材料模型和新颖的碰撞处理算法，使动力学建模更准确。3. 将动力学建模方案与使用3D高斯点渲染并实现高保真渲染的规范avatar相结合，支持高质量的物理真实动画渲染。4. 该框架在动态模型精度、渲染精度、鲁棒性和效率方面显著优于现有的基于物理的3D头像模型，并且能够以零样本的方式适应新的互动行为，这是以前基于学习的方法无法实现的，因为它们的动力学模仿能力有限。
### Conclusion
实验结果表明，MPMAvatar在动态模型精度、渲染精度、鲁棒性和效率方面显著优于现有的基于物理的3D头像模型。此外，该研究还提出了一种新的应用，其中头像能够以零样本的方式适应新的互动行为，这表明现有的学习方法在模拟泛化性方面存在局限性。
## 642. `cs.CV` - ROI-GS：基于兴趣的局部质量3D高斯射线重建 [PDF](https://arxiv.org/pdf/2510.01978), [HTML](https://arxiv.org/abs/2510.01978)
### Authors
Quoc-Anh Bui,Gilles Rougeron,Géraldine Morin,Simone Gasparini
### Background
现有3D高斯点云（3DGS）方法在场景中均匀分配资源，导致对感兴趣区域（ROI）的精细细节不足，模型大小膨胀。这限制了场景重建中的细节表达能力，影响了最终重建的质量和效率。
### Innovation
提出了一种基于对象的ROI-GS框架，通过对象导向的相机选取、目标对象训练和高保真对象兴趣区的无缝集成，以在保证实时性能的同时提高局部细节分辨率。
### Conclusion
实验结果显示，与基线方法相比，ROI-GS在局部质量上提高了2.96 dB PSNR，模型大小减少了约17%，并且在单个对象场景中训练速度更快，整体上优于现有方法。
## 643. `cs.CV` - Median2Median: 零样本抑制图像中的结构化噪声 [PDF](https://arxiv.org/pdf/2510.01666), [HTML](https://arxiv.org/abs/2510.01666)
### Authors
Jianxu Wang,Ge Wang
### Background
图像去噪是计算机视觉和医学成像中的基础问题，然而现实中的图像经常受到具有强烈各向异性相关性的结构化噪声的影响，现有方法难以去除这些噪声。大多数基于数据驱动的方法依赖于大规模具有高质量标签的数据集，并且在泛化能力上有限；而现有的零样本方法避免了这一限制，但只能对独立且同分布（i.i.d.）噪声有效。为解决这一缺口，本文提出了Median2Median（M2M），一种针对结构化噪声的零样本去噪框架。M2M引入了一种新颖的采样策略，能够从单个噪声图像生成伪独立的子图像对，并通过方向插值和广义中值过滤来自适应地排除被结构化噪声扭曲的值。为了进一步扩大有效的采样空间并消除系统性偏差，采用随机分配策略，确保所采样的子图像对适应Noise2Noise训练。在实际模拟研究中，M2M在i.i.d.噪声下表现与最先进的零样本方法相当，但在相关噪声下则始终表现更优。这些发现确立了M2M作为结构化噪声抑制的高效、无数据解决方案的地位，并标志着向超越严格的i.i.d.假设的有效零样本去噪迈出了一步。
### Innovation
提出了一种新颖的采样策略Median2Median（M2M），能够在处理结构化噪声时生成伪独立的子图像对，并通过方向插值和广义中值过滤来自适应地排除受结构化噪声扭曲的值。此外，M2M还采用了随机分配策略以进一步扩大有效的采样空间，确保适用于Noise2Noise训练。M2M在抑制结构化噪声方面表现出卓越性能，特别是在i.i.d.噪声和相关噪声下均优于现有零样本方法。
### Conclusion
M2M是一种针对结构化噪声的有效、无数据解决方案，扩大了零样本去噪方法的应用范围，为超越i.i.d.假设的有效零样本去噪奠定了基础。
## 644. `cs.CV` - ZK-WAGON：使用ZK-SNARKs的不可感知图像生成模型水印 [PDF](https://arxiv.org/pdf/2510.01967), [HTML](https://arxiv.org/abs/2510.01967)
### Authors
Aadarsh Anantha Ramakrishnan,Shubham Agarwal,Selvanayagam S,Kunwar Singh
### Background
随着图像生成模型变得越来越强大且易于访问，合成媒体的真实性、所有权和误用问题变得至关重要。能够生成与真实图像难以区分的图像引入了信息误导、深度合成和知识产权侵权等风险。传统的水印方法要么降低图像质量，要么容易被删除，或者需要访问模型的机密内部信息，这使得它们无法用于安全和可扩展的部署。ZK-WAGON是第一个使用零知识简洁非交互式知识论断（ZK-SNARKs）为图像生成模型添加水印的系统。
### Innovation
ZK-WAGON提出了一种新颖的方法，即Selective Layer ZK-Circuit Creation (SL-ZKCC)，该方法可以有选择地将图像生成模型的关键层转换为电路，显著减少了证明生成时间。水印嵌入通过最小显著位（LSB）隐写术不可见地嵌入到生成图像中，从而提供了一种安全的、模型无关的管道，用于可信赖的人工智能图像生成。
### Conclusion
ZK-WAGON系统在生成的图像中嵌入了不可感知的水印，提供了验证图像来源证明的方法，同时保护了模型的机密内部信息，适用于不同的图像生成模型，如GAN和扩散模型。
## 645. `cs.CV` - GFSR-Net: Guided Focus via Segment-Wise Relevance Network for Interpretable Deep Learning in Medical Imaging [PDF](https://arxiv.org/pdf/2510.01919), [HTML](https://arxiv.org/abs/2510.01919)
### Authors
Jhonatan Contreras,Thomas Bocklitz
### Background
深度学习在医学图像分析中取得了显著成就，但在临床实践中，由于缺乏可解释性，其应用受到限制。现有的模型往往能够做出正确预测但无法解释其推理过程。它们还可能依赖于与疾病无关的图像区域或视觉线索（如注释），这些在真实世界条件下并不存在。这降低了用户的信任度，并增加了产生误导性诊断结果的风险。因此，需要一种方法来提高医学成像的可解释性和可靠性。
### Innovation
提出了一种名为Guided Focus via Segment-Wise Relevance Network（GFSR-Net）的方法，旨在改进医学图像中的可解释性和可靠性。通过少量的人工标注来近似地确定一个图像中人们会直观关注的位置，无需精确的边界或详尽的标记，这使过程变得快速且实际。在训练过程中，该模型学习在其关注点与这些区域对齐，逐步强调具有诊断意义的特征。这种方法在不同类型的真实自然和医学图像（包括胸部X光、视网膜扫描和皮肤图像）中都有效。实验结果表明，GFSR-Net不仅能够获得与传统方法相当或更佳的准确性，还能生成更好的反映人类期望的显著性图。这减少了对无关模式的依赖，增加了自动诊断工具的信心。
### Conclusion
通过引入GFSR-Net，实现在保持高性能的同时提高医学图像深层学习的可解释性。这种方法利用少量的人类注释来指导模型聚焦于有意义的诊断特征，从而在多种医学图像类型上实现更高的准确性与可信赖度。
## 646. `cs.CV` - 用于H&E切片乳腺癌分割训练和基准测试的多中心数据集 [PDF](https://arxiv.org/pdf/2510.02037), [HTML](https://arxiv.org/abs/2510.02037)
### Authors
Carlijn Lems,Leslie Tessier,John-Melle Bokhorst,Mart van Rijthoven,Witali Aswolinskiy,Matteo Pozzi,Natalie Klubickova,Suzanne Dintzis,Michela Campora,Maschenka Balkenhol,Peter Bult,Joey Spronck,Thomas Detone,Mattia Barbareschi,Enrico Munari,Giuseppe Bogina,Jelle Wesseling,Esther H. Lips,Francesco Ciompi,Frédérique Meeuwsen,Jeroen van der Laak
### Background
进行大规模的人工智能生物标志物分析时，自动化的H&E染色全视野组织图像（WSI）的语义分割是必要的。然而，现有的乳腺癌分割公共数据集缺乏支持模型泛化和在异质患者群体中进行稳健生物标志物验证所需的形态多样性。
### Innovation
本文介绍了BrEast cancEr hisTopathoLogy sEgmentation（BEETLE）数据集，这是一个用于H&E染色乳腺癌WSI的多类语义分割数据集。BEETLE包含来源于三个临床中心和两个公共数据集的587份活检和手术切除样本，并使用七种扫描仪进行了数字化处理，覆盖了所有分子亚型和组织学级别。尤其是关注了现有数据集中代表性不足的形态（如原位导管癌和散在的腺瘤细胞），因此在多样性方面有所突破，有助于自动生物标志物定量的迅速发展领域的重复利用。此外，还提供了一个精心编目的多中心外部评估数据集，以使乳腺癌分割模型的标准化基准测试成为可能。
### Conclusion
BEETLE数据集因其多样性和相关性，具有很高的重复利用潜力。同时，为乳腺癌分割模型提供了一个标准化的基准测试开发集和外部评价集。
## 647. `cs.CV` - 在视觉任务中鲁棒潜在空间的无监督动态特征选择 [PDF](https://arxiv.org/pdf/2510.01758), [HTML](https://arxiv.org/abs/2510.01758)
### Authors
Bruno Corcuera,Carlos Eiras-Franco,Brais Cancela
### Background
潜在表示对于机器学习模型的性能和鲁棒性至关重要，因为它们以简洁而有信息含量的方式编码了数据的关键特征。然而，在视觉任务中，这些表示常常受到噪声或无关特征的影响，这会削弱模型的性能和泛化能力。
### Innovation
本文提出了一个全新的无监督动态特征选择（DFS）方法，用于增强潜在表示。该方法能够在每个实例中识别并移除图像中的误导性或冗余信息，确保只有最相关的特征贡献于潜在空间。该方法利用无监督框架，避免对标注数据的依赖，使它能够在多个领域和数据集中广泛适用。
### Conclusion
实验结果表明，在图像数据集上植入无监督DFS的方法在各种任务（包括聚类和图像生成）上实现了显著的泛化性能提升，同时只带来了微小的计算成本增加。
## 648. `cs.CV` - 代理扩展对于计算机使用领域的惊人效果 [PDF](https://arxiv.org/pdf/2510.02250), [HTML](https://arxiv.org/abs/2510.02250)
### Authors
Gonzalo Gonzalez-Pumariega,Vincent Tu,Chih-Lun Lee,Jiachen Yang,Ang Li,Xin Eric Wang
### Background
计算机使用代理(CUAs)有潜力自动化日常数字任务，但它们的不可靠性和高变异性阻碍了它们在长期复杂任务中的应用。
### Innovation
引入了行为最佳-of-N (bBoN) 方法，该方法通过生成多个路线图并使用行为叙述进行选择扩展代理，从而实现了广泛探索和有原则的任务选择，大幅提高了鲁棒性和成功率。
### Conclusion
bBoN 扩展方法在 OSWorld 上建立了新的最佳表现（SoTA），达到 69.9%，显著优于其他方法，并接近人类水平的 72%。全面的消融实验验证了关键设计选择。此外，证明了强大的泛化结果，扩展到不同的操作系统（WindowsAgentArena 和 AndroidWorld）。这些结果表明，当正确扩展 CUAs 时，其效果是非常惊人的：有效扩展需要结构化的轨迹理解和选择，bBoN 提供了实现这一目标的实用框架。
## 649. `cs.CV` - G²RPO: 粒度GRPO用于流模型中精确的奖励评估 [PDF](https://arxiv.org/pdf/2510.01982), [HTML](https://arxiv.org/abs/2510.01982)
### Authors
Yujie Zhou,Pengyang Ling,Jiazi Bu,Yibin Wang,Yuhang Zang,Jiaqi Wang,Li Niu,Guangtao Zhai
### Background
在线强化学习（RL）与扩散和流模型的集成已经成为一种有潜力的方法，用于使生成模型与人类偏好对齐。在去噪过程中通过随机微分方程（SDE）进行随机采样，生成多种去噪方向，以供RL探索。现有的方法虽然有效探索具有潜在高价值样本，但由于奖励信号稀疏和狭窄，导致偏好对齐不精确。
### Innovation
提出了一种新的粒度广泛的GRPO（Granular-GRPO，G²RPO）框架，以实现对流模型中采样方向奖励评估的精确和全面。G²RPO引入了单粒度随机采样策略，支持逐步的随机探索，同时增强奖励和注入噪声之间的高相关性。同时，引入了一种多粒度优势整合模块，聚合来自多个扩散尺度的优势，以产生对采样方向更综合和稳健的评估。
### Conclusion
在多种奖励模型上的实验表明，G²RPO显著优于现有的基于流的GRPO基线，证明了其有效性和鲁棒性。
## 650. `cs.CV` - 测量导向的一致性模型采样方法用于逆向问题 [PDF](https://arxiv.org/pdf/2510.02208), [HTML](https://arxiv.org/abs/2510.02208)
### Authors
Amirreza Tanevardi,Pooria Abbas Rad Moghadam,Sajjad Amini
### Background
生成模型已经成为了解决逆向成像问题的强大先验条件，但其依赖于耗时的多步骤采样限制了其实用部署。一致性模型通过在单步或少数几步内生成高质量图像来解决这一瓶颈，然而它们直接应用于逆向问题的应用仍相对少见。
### Innovation
本文提出了一种专门针对逆向问题重建的修改一致性采样方法：该采样的随机性由测量一致性机制引导，该机制与测量算子绑定，保证图像对获取的测量结果的忠实性，同时保持基于一致性生成的高效性。
### Conclusion
在Fashion-MNIST和LSUN卧室数据集上的实验表明，相比基础的一致性采样方法，该方法在感知和像素级别指标上表现出一致的改进，包括Frechet Inception Distance、Kernel Inception Distance、峰值信噪比和结构相似性指数，在少量步骤内实现了具有竞争力或更优的重建结果。
## 651. `cs.CV` - 用互信息引导的扩散合成在更高视觉皮层中揭示潜在组的语义选择性 [PDF](https://arxiv.org/pdf/2510.02182), [HTML](https://arxiv.org/abs/2510.02182)
### Authors
Yule Wang,Joseph Yu,Chengrui Li,Weihan Li,Anqi Wu
### Background
理解高级视觉区域中神经群体如何编码以物体为中心的视觉信息仍然是计算神经科学中的一个核心挑战。之前的研究考察了人工神经网络和视觉皮层之间的表征对齐，但这些发现是间接的，不能深入揭示神经群体的结构。同样，解码方法量化了神经群体中的语义特征，但没有揭示它们的内在组织。因此，仍存在科学问题：特定视觉信息是如何在高级视觉区域的神经群体中分布的，以及它是否形成了结构化的、语义上有意义的子空间？
### Innovation
本文介绍了一种新的方法MIG-Vis，该方法利用扩散模型的生成能力来可视化和验证神经潜在子空间中编码的视觉语义属性。该方法首先使用变分自编码器从神经群体中推断出一群间解耦的神经潜在子空间，随后提出了一种互信息（MI）指导的扩散合成过程，以可视化每个潜在组编码的具体视觉语义特征。在猕猴下颞皮层（IT皮层）的多会话神经放电数据集上验证了MIG-Vis的方法，结果表明该方法能识别出具有明确语义选择性的神经潜在组，包括物体姿态、类别间转换和类别内内容等视觉特征，提供了结构化的语义表示的直接可解释证据，并推进了对高级视觉皮层编码原理的理解。
### Conclusion
这些发现提供了高级视觉皮层中结构化语义表示的直接可解释证据，并促进了对其编码原理的理解。
## 652. `cs.CV` - 事实推理悖论：强化学习如何限制语言模型 [PDF](https://arxiv.org/pdf/2510.02230), [HTML](https://arxiv.org/abs/2510.02230)
### Authors
Phuc Minh Nguyen,Chinh D. La,Duy M. H. Nguyen,Nitesh V. Chawla,Binh T. Nguyen,Khoa D. Doan
### Background
Reinforcement Learning with Verifiable Rewards (RLVR) 已经成为提高大型语言模型推理能力的关键方法，但近期的证据表明，RLVR 可能会反其道而行之，即缩小而非扩大推理边界。本研究通过分析 RLVR 的学习动态，揭示了两种关键现象来解释这一失败：首先，揭示了 RLVR 中的负干扰现象，即为了解决某些训练问题，学习会减少其他正确解决方案的可能性，导致 Pass@$k$ 表现下降；其次，揭示了赢家通吃现象：RLVR 在基础模型下倾向于强化高概率正确解决方案，同时抑制初始低概率的其他解决方案。这些现象源于标准 RL 目标中固有的采样方式，导致模型收敛于狭窄的解决方案策略。
### Innovation
本研究提出了一个简单而有效的数据整理算法，该算法将 RLVR 的学习焦点放在低概率问题上，从而显著提高了 Pass@$k$ 表现。这个研究揭示了 RLVR 学习动态中的两种关键现象，并通过理论分析和多数学术推理基准数据的实证研究来验证其发现。
### Conclusion
通过这些发现，本研究提出了一种新的数据整理算法，该算法可以有效改善 RLVR 的学习过程，从而显著提高了 Pass@$k$ 性能。
## 653. `cs.CV` - SpurBreast: 一个用于研究实际乳腺MRI分类中错误关联的精心收集的数据集 [PDF](https://arxiv.org/pdf/2510.02109), [HTML](https://arxiv.org/abs/2510.02109)
### Authors
Jong Bum Won,Wesley De Neve,Joris Vankerschaver,Utku Ozbulak
### Background
深度神经网络（DNNs）在医学成像领域取得了显著成就，但由于模型可能会学习非临床特征而非有意义的医学模式，其实际部署仍然面临挑战。现有的医学成像数据集通常未系统地研究这一问题，主要是因为限制性的许可和有限的补充患者数据。这限制了研究人员对模型性能受非临床特征影响的研究。
### Innovation
研究人员引入了SpurBreast，这是一个精心收集的乳腺MRI数据集，故意包含了错误关联，以评估其对模型性能的影响。通过分析超过100个涉及患者、设备和成像协议的功能，研究人员确定了两个主要的非临床信号：磁场强度（对整个图像全局有影响的特征）和图像方向（对空间对齐有局部影响的特征）。通过控制数据集划分，展示了DNNs可以利用这些非临床信号，尽管在验证准确性上非常高效，但在未偏见的测试数据上却缺乏泛化能力。此外，还提供了两个包含错误关联的数据集和两个不包含错误关联的数据集，以便研究人员系统地研究相关和无关的临床特征、不确定性估计、对抗鲁棒性和泛化策略。
### Conclusion
模型和数据集可在此处获得。该研究提高了对错误关联如何影响医学成像中DNNs性能的理解，并为深入研究提供了重要工具。
## 654. `cs.CV` - DisCo-Layout:在多智能体框架中分离和协调语义和物理精炼以合成3D室内布局 [PDF](https://arxiv.org/pdf/2510.02178), [HTML](https://arxiv.org/abs/2510.02178)
### Authors
Jialin Gao,Donghao Zhou,Mingjian Liang,Lihao Liu,Chi-Wing Fu,Xiaowei Hu,Pheng-Ann Heng
### Background
3D室内布局合成在创建虚拟环境中至关重要。传统方法由于固定的数据集而难以泛化。虽然基于LLM和VLM的近期方法在语义丰富性方面有所提高，但它们往往缺乏稳健和灵活的精炼能力，导致布局不佳。
### Innovation
提出了DisCo-Layout，这是一种新颖的方法，能够分离和协调物理和语义精炼。DisCo-Layout引入了独立精炼的语义精炼工具（SRT），用于纠正抽象对象之间的关系；物理精炼工具（PRT）使用网格匹配算法解决具体的空间问题。同时，多智能体框架通过智能协调这些工具，实现了智能部署规则规划者、初始布局设计师和性能评估者等功能。
### Conclusion
实验结果表明，DisCo-Layout在3D室内布局合成方面达到了最先进的性能，生成了现实、连贯且具有泛化能力的3D室内布局。我们的代码将公开提供。
## 655. `cs.CV` - 通过VLM-Lens从行为表现到内在能力：解释视觉语言模型 [PDF](https://arxiv.org/pdf/2510.02292), [HTML](https://arxiv.org/abs/2510.02292)
### Authors
Hala Sheta,Eric Huang,Shuyu Wu,Ilia Alenabi,Jiajun Hong,Ryker Lin,Ruoxi Ning,Daniel Wei,Jialin Yang,Jiawei Zhou,Ziqiao Ma,Freda Shi
### Background
介绍了一种名为VLM-Lens的工具包，旨在通过支持从开源视觉语言模型（VLMs）的前向传递过程中提取中间输出，来系统地进行基准测试、分析和解释VLMs。VLM-Lens提供了统一的、通过YAML配置的接口，简化了不同模型的具体复杂性，使得用户能够在各种VLMs上进行友好操作。该工具包目前支持16个最先进的基础VLM及其超过30个变种，并且具有扩展性，无需更改核心逻辑即可容纳新模型。
### Innovation
VLM-Lens实现了易于与各种可解释性和分析方法的集成。通过对VLMs在不同层和目标概念中的隐藏表示进行两个简单的分析实验，揭示了系统的差异性。VLM-Lens作为一种开源项目发布，旨在加速对VLMs的理解和改进的社区努力。
### Conclusion
VLM-Lens提供了一种统一的接口，使得用户能够跨不同模型进行友好操作，支持从行为表现到内部能力的系统分析，通过开源项目加速了社区对VLMs的理解和改进。
## 656. `cs.CV` - LiDAR-HMR: 从LiDAR恢复3D人体网格 [PDF](https://arxiv.org/pdf/2311.11971), [HTML](https://arxiv.org/abs/2311.11971)
### Authors
Bohao Fan,Wenzhao Zheng,Jianjiang Feng,Jie Zhou
### Background
近年来，点云感知任务受到越来越多的关注。本文首次尝试通过稀疏LiDAR点云估计3D人体网格。点云中的人体姿态和网格估计面临的主要挑战包括LiDAR点云的稀疏性、噪声、不完整性。
### Innovation
提出了一种有效的稀疏到密集的恢复方案，用于从稀疏LiDAR点云中重建3D人体网格。该方案包括估计人体的稀疏表示（3D人体姿态）并逐渐重建人体网格。采用级联图变换器（Graphormer）在稀疏到密集的重建过程中引入点云特征，以更好地利用点云的3D结构信息。
### Conclusion
在三个公共数据集上的实验结果表明，所提出的方法是有效的。代码可在以下链接获取：this https URL
## 657. `cs.CV` - 您知道您的相机在哪儿吗？通过相机条件化实现视图不变性策略学习 [PDF](https://arxiv.org/pdf/2510.02268), [HTML](https://arxiv.org/abs/2510.02268)
### Authors
Tianchong Jiang,Jingtian Ji,Xiangshan Tan,Jiading Fang,Anand Bhattad,Vitor Guizilini,Matthew R. Walter
### Background
该研究探讨了视图不变性的模仿学习，即让策略显式地依赖于相机外部参数。通过使用每个像素射线的布日聂布嵌入，研究发现外部参数条件能够显著改善对于固定和随机场景变化标准行为克隆策略的通用性。为了评估策略在现实视点变化下的鲁棒性，研究引入了RoboSuite和ManiSkill中的六项操作任务，将背景线索与相机姿态解耦。研究表明，未使用外部参数的策略常常会利用固定场景中的静态背景视觉线索来推断相机姿态，而当工作空间几何或相机放置发生变化时，这种捷径会失效。使用外部参数条件化策略可以恢复性能，并在没有深度数据的情况下仅通过RGB控制实现鲁棒性。
### Innovation
该研究通过显式地条件化策略依赖于相机外部参数，特别是使用每个像素射线的布日聂布嵌入，来实现视图不变性的模仿学习。这一方法显著提升了策略在不同视图下的通用性，并在没有深度信息的情况下实现了基于RGB控制的鲁棒性。研究还提出了一种新奇的测试环境，能够独立评估策略在真实场景中的鲁棒性。
### Conclusion
在实验结果下，研究发现策略不依赖外部参数时常利用固定场景中的静态背景视觉线索来推断相机姿态，但当工作空间几何或相机放置发生变化时，这种捷径会失效。使用外部参数条件化策略可以恢复性能，而无需深度信息即可实现RGB控制。研究成果已公开发布，包括任务、示范和代码。
## 658. `cs.CV` - 测试时锚定强化离散扩散后验采样 [PDF](https://arxiv.org/pdf/2510.02291), [HTML](https://arxiv.org/abs/2510.02291)
### Authors
Litu Rout,Andreas Lugmayr,Yasamin Jafarian,Srivatsan Varadharajan,Constantine Caramanis,Sanjay Shakkottai,Ira Kemelmacher-Shlizerman
### Background
本文研究了使用预训练的离散扩散基础模型进行后验采样的问题，旨在从噪声测量中恢复图像，而无需重新训练任务特定的模型。虽然扩散模型在生成建模方面取得了显著的成果，但大多数进展依赖于连续的高斯扩散。相比之下，离散扩散提供了一个统一的框架，可以同时建模如文本和图像这样的分类数据。除了统一之外，离散扩散还提供了更快的推理速度、更精细的控制以及无需训练的贝叶斯推理，使其特别适合后验采样。然而，现有的离散扩散后验采样方法面临着严重挑战：无梯度引导产生的信号稀疏、连续松弛限制了适用范围，分裂吉布斯采样面临维度灾难。
### Innovation
本文提出了锚定后验采样（Anchored Posterior Sampling, APS）方法，针对带掩码的离散扩散基础模型，基于两个关键创新——量化期望在离散嵌入空间中进行梯度式引导和锚定重新遮掩以实现自适应解码。这些创新旨在克服现有离散扩散后验采样方法的局限，实现标准基准上线性和非线性逆问题中离散扩散采样器的最佳性能。并且通过无训练的风格化和文本引导编辑进一步演示了这种方法的优势。
### Conclusion
本文的方法在标准基准上的线性和非线性逆问题中取得了最佳性能，并通过无训练的风格化和文本引导编辑展示了该方法的优势。
## 659. `cs.CV` - 持续改进扩散模型的个性化方法 [PDF](https://arxiv.org/pdf/2510.02296), [HTML](https://arxiv.org/abs/2510.02296)
### Authors
Yu-Chien Liao,Jr-Jen Chen,Chi-Pin Huang,Ci-Siang Lin,Meng-Lin Wu,Yu-Chiang Frank Wang
### Background
在实际应用中，扩散模型的逐步更新是一种实用的方法，但在计算上却具有挑战性。持续学习方案中的个性化会遇到灾难性遗忘的问题，且通常需要大量参数调整。
### Innovation
本文提出了一种新颖的概念神经元选择（CNS）策略，这是一种简单而有效的在持续学习方案中实现个性化的途径。CNS能够独特地识别与目标概念紧密相关的神经元，并通过逐步微调这些概念神经元，同时保留零样本文本到图像生成的能力，来减轻灾难性遗忘问题并保留先前概念的学习知识。
### Conclusion
在实际数据集上的评估表明，CNS在最小参数调整的情况下达到了最先进的性能，在单概念和多概念个性化工作中都优于之前的方法。CNS还实现了无需融合的操作，减少持续个性化过程中的内存存储和处理时间。
## 660. `cs.CV` - Sparkle: Mastering Basic Spatial Capabilities in Vision Language Models Elicits Generalization to Spatial Reasoning [PDF](https://arxiv.org/pdf/2410.16162), [HTML](https://arxiv.org/abs/2410.16162)
### Authors
Yihong Tang,Ao Qu,Zhaokai Wang,Dingyi Zhuang,Zhaofeng Wu,Wei Ma,Shenhao Wang,Yunhan Zheng,Zhan Zhao,Jinhua Zhao
### Background
视觉语言模型（VLMs）在许多任务中表现出色，但在空间推理方面常常表现不佳，而这对于导航和与物理环境交互至关重要。空间推理任务依赖于基本的二维（2D）技能，但我们的评估表明，最先进的VLMs在复杂的空间问题上给出不合理的或错误的答案，包括人类可以轻松解决的基本路径规划任务。
### Innovation
该研究通过培训VLMs仅专注于基本的空间能力，来增强其二维空间推理能力。提出了Sparkle框架，该框架通过生成合成数据来提供对这三个核心空间技能的针对性监督，从而生成用于训练的指令数据集。实验表明，使用Sparkle训练的VLMs不仅能改进基本任务，还能在复杂的和非分布的真实世界空间推理任务上表现出色。
### Conclusion
通过合成泛化的增强基本的空间技能有效推进了复杂的空间推理，提供了一种系统的方法来提升VLMs的空间理解力。
## 661. `cs.CV` - 基于拟合框架的内部对象几何 [PDF](https://arxiv.org/pdf/2407.14357), [HTML](https://arxiv.org/abs/2407.14357)
### Authors
Stephen M. Pizer,Zhiyuan Liu,Junjie Zhao,Nicholas Tapp-Hughes,James Damon,Miaomiao Zhang,JS Marron,Mohsen Taheri,Jared Vicory
### Background
该研究旨在开发一种方法，用于计算物体边界和内部的空间框架，并利用这些框架为物体提供几何特征，这些特征不仅不需要对齐，而且能在一组物体中实现局部对应。这之前的研究通常关注外部形状特征，而这一研究侧重于内部几何特征的获取和统计分析，以区分具有特定疾病的人群与其他人群。
### Innovation
提出了一种基于拟合框架的方法来计算物体边界和内部的空间框架，并通过椭球体形变和骨骼表示方法生成对象模型，旨在实现群体内部的强烈位置对应，从而提供强大的对象统计特性。该研究特别强调了新颖的几何特征表示，称为‘进化s-rep’，通过临床样本的脑回柱状结构分类性能验证了其优越性。
### Conclusion
通过比较，证明了新提出的基于拟合框架的几何特征表示方法在分类性能上显著优于前两种最先进的几何特征表示方法，这种新的几何特征表示方法能够提供更加精确和有区分性的对象统计分析。
## 662. `cs.CV` - 元转移皮肤诊断：探索在长尾分布下用于皮肤疾病分类的元学习和迁移学习 [PDF](https://arxiv.org/pdf/2404.16814), [HTML](https://arxiv.org/abs/2404.16814)
### Authors
Zeynep Özdemir,Hacer Yalim Keles,Ömer Özgür Tanrıöver
### Background
构建对于罕见皮肤疾病的准确模型仍然具有挑战性，这是因为缺乏足够的标注数据和样本数量分布的长尾特性。另外样本数据的收集一致性和不同数据集的目标性也增加了这些挑战。为了克服这些挑战，该研究对比了三种学习策略：元学习、监督迁移学习和对比自我监督预训练，并在少量样本学习框架下进行评估。研究在三个基准数据集上进行了实验：ISIC2018、Derm7pt和SD-198。
### Innovation
研究对比了元学习、监督迁移学习和自我监督预训练三种学习策略在皮肤疾病分类中的效果，发现相比元学习和自我监督方法，基于MobileNetV2和ViT架构的传统迁移学习方法在样本量增加时表现更优。结合批量层面的数据增强技术，这些模型在SD-198和Derm7pt上的表现达到了最新水平，在ISIC2018上也取得了非常有竞争力的结果。
### Conclusion
传统的基于MobileNetV2和ViT架构的迁移学习方法在逐渐增加训练样本时表现出更高的性能，结合数据增强技术后，这些模型在少量样本的皮肤疾病分类中达到了领先水平。
## 663. `cs.CV` - DiffCut: 利用扩散特征和递归归一化切分催化零样本语义分割 [PDF](https://arxiv.org/pdf/2406.02842), [HTML](https://arxiv.org/abs/2406.02842)
### Authors
Paul Couairon,Mustafa Shukor,Jean-Emmanuel Haugeard,Matthieu Cord,Nicolas Thome
### Background
基础模型已经在语言、视觉以及多模态任务等多个领域展现出强大的工具能力。虽然先前的工作已经在无监督图像分割上有所成果，但这些方法与有监督模型相比仍然存在显著差距。本研究使用扩散UNet编码器作为基础视觉编码器，并引入了一种新的无监督零样本分割方法——DiffCut。这种方法仅依赖最终自注意力块的输出特征进行分割。
### Innovation
本研究创新点在于提出了一种新的无监督零样本分割方法DiffCut，使用扩散UNet模型的最后一层自注意力块作为特征输入，通过基于图的分割算法实现了显著的性能提升，特别是在零样本分割任务上。此外，该研究还提出了一种递归归一化切分算法，这种算法能够软性调节检测对象的粒度，产生清晰定义的分割图，精确捕捉图像的细节。这项工作强调了扩散UNet编码器中嵌入的显著准确的语义知识，可以为此类编码器用于下游任务提供基础
### Conclusion
通过广泛的实验表明，利用扩散特征进行图基分割算法，在零样本分割任务上显著优于先前的方法。这项工作展示了扩散UNet编码器在零样本语义分割中的潜力，并提出了一个实际可行的基础视觉编码器方案，为下游任务提供支持。
## 664. `cs.CV` - 在往返之间：关于Diffusion模型中噪声和图像反转之间的关系 [PDF](https://arxiv.org/pdf/2410.23530), [HTML](https://arxiv.org/abs/2410.23530)
### Authors
Łukasz Staniszewski,Łukasz Kuciński,Kamil Deja
### Background
Diffusion模型在生成新样本方面表现出领先的表现，但缺乏一个低维潜在空间，该空间能够编码数据以实现可编辑的特征。反转方法通过逆转去噪过程来解决这一问题，将图像转换为其近似始点噪声。本文深入分析了这一过程，并专注于初始噪声、生成样本及其相应的潜在编码之间的关系。
### Innovation
我们展示了潜在编码中存在结构性模式，这种模式导致了平滑图像区域预测出较少样噪声。通过一系列分析，我们将这一问题追溯到首次反转步骤，这些步骤无法提供准确和多样的噪声。我们的创新在于我们用一个正向扩散过程替换了一开始的DDIM反转步骤，成功解开了潜在编码之间的相关性，从而使得更高质量的编辑和插值成为可能。
### Conclusion
本文通过分析DDIM反转过程中的噪声和生成图像之间的关系，揭示了潜在编码存在的结构性模式，并通过用一个正向扩散过程替换初始的DDIM反转步骤的方法，解决了这一问题，使得潜在编码更加可操控，从而提高了插值和编辑的质量。相关代码可在此处获取：this https URL
## 665. `cs.CV` - Equilibrium Matching: 通过隐式能量模型进行生成建模 [PDF](https://arxiv.org/pdf/2510.02300), [HTML](https://arxiv.org/abs/2510.02300)
### Authors
Runqian Wang,Yilun Du
### Background
传统的生成模型如扩散模型和流生成模型侧重于非平衡、时间条件下的动态过程。这些模型通常基于概率分布参数化生成样本，但它们需要大量的训练数据和计算资源，且可能产生次优的样本。本文则从平衡动态的角度出发，提出了一种新的生成建模框架Equilibrium Matching (EqM)，学习隐式的能量景观梯度，从而优化采样过程，实现更高效的生成模型。
### Innovation
EqM 不采用传统的基于时间条件的非平衡动态过程，而是学习隐式的能量景观下的梯度。这种方法允许通过梯度下降优化过程进行采样，可以调节步长、使用自适应优化器和自适应计算资源。实验结果显示，EqM 在 ImageNet 256×256 的图像生成任务上具有较高的生成性能，FID 值为 1.90。同时，从理论上证明了 EqM 可以从数据流形中学习和采样。此外，EqM 是一个灵活的框架，适用于图像去噪、异常检测和图像合成等任务，提供了从流模型和能量模型到优化驱动推理的无缝桥梁。
### Conclusion
通过引入新的 Equilibrium Matching 建模框架，该工作提供了一种高效的生成建模方法，不仅在图像生成上表现优异，而且具有广泛应用的可能性，包括图像去噪、异常检测和图像合成等。该框架还展示了在生成建模中，从平衡动力学到能量模型的优化驱动推理的优势。
## 666. `cs.CV` - 什么是好的知识蒸馏数据集？ [PDF](https://arxiv.org/pdf/2411.12817), [HTML](https://arxiv.org/abs/2411.12817)
### Authors
Logan Frank,Jim Davis
### Background
知识蒸馏（KD）是一种流行且有效的方法用于模型压缩。传统上，KD假设教师模型在训练学生模型时也会提供其原始数据集。然而，在持续学习或大模型训练时存在公司未公开数据集的情况下，获取原始数据集可能不可行。因此，研究人员开始探索其他补充数据源，但效果参差不齐。这引出了一个关键问题：什么是将教师知识成功转移到学生模型的合适数据集？研究发现，虽然假设只有实际领域内的图像数据才有效，但实际上并非如此。通过研究，本文探索了多种替代的简练数据集，并展示了即使不自然的合成图像也可以作为知识蒸馏的有效替代方案。通过对这些替代数据集的研究，本文明确了什么是适合知识转移的良好数据集的多种标准。
### Innovation
论文探索了多种可能的替代蒸馏数据集，并表明许多不同类型的甚至非自然的合成图像也可以作为知识蒸馏的有效替代方案。此外，研究明确了适合知识转移良好数据集的各种标准，拓宽了数据集的选择范围，提高了知识蒸馏的灵活性和适用性。
### Conclusion
研究表明，许多不同类型的甚至非自然的合成图像也可以作为知识蒸馏的有效替代方案。本文明确了适合知识转移的良好数据集的多种标准，为知识蒸馏选择合适数据集提供了指导，增强了知识蒸馏方法的应用潜力。
## 667. `cs.CV` - 作为噪声感知隐空间奖励模型的扩散模型用于步骤级偏好优化 [PDF](https://arxiv.org/pdf/2502.01051), [HTML](https://arxiv.org/abs/2502.01051)
### Authors
Tao Zhang,Cheng Da,Kun Ding,Huan Yang,Kun Jin,Yan Li,Tingting Gao,Di Zhang,Shiming Xiang,Chunhong Pan
### Background
偏好优化旨在使扩散模型与人类对图像的偏好对齐。以往的方法通常使用视觉-语言模型（VLMs）作为像素级的奖励模型来近似人类偏好，但这些模型在处理不同时间步的嘈杂图像进行步骤级偏好优化时遇到了挑战，需要复杂的转换到像素空间。因此，需要一种新的方法来直接在噪声隐空间中进行步骤级偏好优化。
### Innovation
本文提出了一种新的方法，通过将预训练的扩散模型重新用于噪声隐空间中的层序奖励模型（Latent Reward Model, LRM），并在上述空间中直接进行步骤级偏好优化（Latent Preference Optimization, LPO）。这种方法利用了扩散模型设计来处理不同噪声级别的隐图像，从而提高了模型与通用、美学和图文对齐偏好的对齐效果，并且比现有方法快2.5至28倍的训练速度。
### Conclusion
实验结果显示，LPO方法显著提高了模型与偏好优化目标的一致性，同时实现了比现有优化方法快2.5至28倍的训练速度。相关代码和模型可以在对应的链接中获取。
## 668. `cs.CV` - 一阶段视频生成的扩散对抗后训练 [PDF](https://arxiv.org/pdf/2501.08316), [HTML](https://arxiv.org/abs/2501.08316)
### Authors
Shanchuan Lin,Xin Xia,Yuxi Ren,Ceyuan Yang,Xuefeng Xiao,Lu Jiang
### Background
扩散模型在图像和视频生成中得到了广泛的应用，但其迭代生成过程缓慢且耗费资源。现有的蒸馏方法在图像领域展示了单一步骤生成的潜力，但仍然存在显著的质量下降问题。
### Innovation
本文提出了一种针对真实数据的对抗后训练（APT）方法，结合扩散预训练应用于一阶段视频生成。创新之处在于引入了改进的模型架构和训练流程，以及近似的R1正则化目标。这些改进措施提高了训练的稳定性和质量。
### Conclusion
我们的实验表明，对抗后训练的Seaweed-APT模型能够实现实时单步骤生成2秒、1280x720、24fps的视频。此外，该模型还能够实现实时单步骤生成1024px的图像，并且生成质量可与当前最先进的方法相媲美。
## 669. `cs.CV` - VideoGen-of-Thought：最少手动干预逐步生成多镜头视频 [PDF](https://arxiv.org/pdf/2412.02259), [HTML](https://arxiv.org/abs/2412.02259)
### Authors
Mingzhe Zheng,Yongqi Xu,Haojian Huang,Xuran Ma,Yexin Liu,Wenjie Shu,Yatian Pang,Feilong Tang,Qifeng Chen,Harry Yang,Ser-Nam Lim
### Background
当前的视频生成模型在处理短片段视频方面表现出色，但在生成连贯的多镜头叙事方面存在不足，因为这些模型无法确保视觉动态的连贯性和故事情节的完整性。现有的解决方案要么依赖于详细的剧本编辑，要么倾向于优先考虑单镜头的视觉效果而牺牲跨镜头场景的连贯性，这限制了它们在制作电影级内容的实用性。
### Innovation
本文提出了一种名为VideoGen-of-Thought (VGoT)的自动化框架，它能够从单个句子逐步合成多镜头视频，解决三个核心挑战：（1）叙事碎片化：现有方法缺乏结构化的叙事模型。VGoT提出了动态的故事情节建模，将用户提示转换为简短的镜头草图，并扩展到五个领域（人物动态、背景连贯性、关系发展、摄像机运动和高动态范围（HDR）照明）的详细规格，确保情景合理发展；（2）视觉不一致性：之前的方法难以保持镜头间的视觉一致性。VGoT采用识别特征的跨镜头传播策略，创建保留特征同时允许表情和年龄变化的特征令牌，以适应故事情节的需要；（3）过渡伪影：继镜头切换会破坏沉浸感。VGoT采用了相邻潜在转换机制，通过过渡点处的相邻镜头特征处理，在保持叙事连贯的同时实现无缝视觉过渡。
### Conclusion
综合使用VGoT框架，无需训练即可超越现有的基准模型，在镜头内的面部一致性上提高了20.4%，在风格一致性上提高了17.4%，且需要的手动调整仅为原来的十分之一。VGoT填补了从原始视觉合成到导演级别叙事的自动化多镜头视频生成之间的空白。
## 670. `cs.CV` - Multiple Queries with Multiple Keys: 一种用于基于提示持续学习的精确提示匹配范式 [PDF](https://arxiv.org/pdf/2501.12635), [HTML](https://arxiv.org/abs/2501.12635)
### Authors
Dunwei Tu,Huiyu Yi,Yuchi Wang,Baile Xu,Jian Zhao,Furao Shen
### Background
持续学习要求机器学习模型在动态环境中不断获取新知识，同时避免遗忘先前的知识。基于提示的持续学习方法通过提示扩展和选择有效解决了灾难性遗忘问题。然而，现有方法常常在提示选择方面精度较低，可能导致模型接收偏差的知识并做出偏差的预测。
### Innovation
本文提出了一种新的多查询与多键（MQMK）提示匹配范式，以实现准确的提示选择。MQMK的目标是选择最能匹配测试样本分布的训练数据分布的提示。具体而言，多查询通过引入特定任务的知识实现精确的广度搜索，而多键则通过在细粒度上表示训练样本的特征分布实现深入搜索。每个查询都旨在局部匹配分配的任务，以减少查询之间的干扰。实验结果表明，在挑战场景中，MQMK的提示匹配率提高了超过30%，并在三个广泛采用的持续学习基准上实现了最新的性能。
### Conclusion
实验结果显示，MQMK在挑战性场景中提高了30%以上的提示匹配率，并在三个常用的持续学习基准测试上达到了最先进的性能。
## 671. `cs.CV` - 后验概率视觉语言模型 [PDF](https://arxiv.org/pdf/2412.06014), [HTML](https://arxiv.org/abs/2412.06014)
### Authors
Anton Baumann,Rui Li,Marcus Klasson,Santeri Mentu,Shyamgopal Karthik,Zeynep Akata,Arno Solin,Martin Trapp
### Background
视觉语言模型（VLMs），如CLIP和SigLIP，在分类、检索和生成任务中取得了显著成功。这些模型确定性地将图像和文本描述映射到一个联合的潜在空间，在该空间中使用余弦相似度来评估它们的相似性。然而，在下游任务中使用确定性的输入映射时，当遇到领域转移导致的概念不确定性时，无法捕捉到这些不确定性。
### Innovation
本文提出了一种不需要额外训练的后验不确定性估计方法，该方法利用视觉语言模型最后几层的概率后验近似，并通过余弦相似度的解析量化来量化不确定性。该方法在不确定性量度和活跃学习的支撑集选择方面表现出有效性。与基线相比，我们获得了改进且校准良好的预测不确定性、可解释的不确定性估计以及样本高效的活跃学习结果。
### Conclusion
我们的结果显示出在大规模模型的安全关键应用中具有潜力。
## 672. `cs.CV` - 你在看什么？医学多模态深度学习中的模态贡献 [PDF](https://arxiv.org/pdf/2503.01904), [HTML](https://arxiv.org/abs/2503.01904)
### Authors
Christian Gapp,Elias Tappeiner,Martin Welk,Karl Fritscher,Elke Ruth Gizewski,Rainer Schubert
### Background
当前，可以通过大型深度神经网络轻松分析高维度和多模态数据。已经开发了几种融合不同模态的方法。医学中普遍存在高维度和多模态患者数据，因此开发多模态模型标志着一个重大进展。然而，这些模型如何在细节上处理不同来源的信息仍然缺乏深入研究。
### Innovation
本文实现了一个基于遮挡的模态贡献方法，该方法既模型无关又处理效果无关。该方法定量地测量了数据集中每个模态对于模型完成其任务的重要性。该方法还应用于三个不同的多模态医学问题进行实验。结果表明，一些网络有模态偏好，倾向于单模态崩溃，而一些数据集本身就是不平衡的。此外，我们还提供了每个模态的精确的定量和视觉属性的重要性。
### Conclusion
我们的指标提供了支持多模态模型开发和数据集创建的重要见解。通过引入此方法，我们为多模态研究领域中的深度学习可解释性研究做出了贡献。这种方法有助于推动多模态AI在临床实践中的集成。我们的代码已在以下网址公开:this https URL.
## 673. `cs.CV` - DreamOmni: 统一的图像生成和编辑 [PDF](https://arxiv.org/pdf/2412.17098), [HTML](https://arxiv.org/abs/2412.17098)
### Authors
Bin Xia,Yuechen Zhang,Jingyao Li,Chengyao Wang,Yitong Wang,Xinglong Wu,Bei Yu,Jiaya Jia
### Background
当前，大规模语言模型（LLMs）的成功表明，统一的多任务学习方法可以显著提升模型的可用性、简化部署，并促进不同任务间的协同效益。在计算机视觉领域，尽管生成式对抗（T2I）模型通过扩大规模在生成质量上取得了显著进步，但其框架设计并未充分考虑如何与下游任务（如各种编辑任务）统一。因此，本文提出的DreamOmni是一个统一的图像生成和编辑模型。
### Innovation
本文打破了传统的单纯增强生成能力的方法，而是提出了一个综合框架，将文本到图像模型（T2I）和各种编辑任务统一起来。此外，还开发了一种合成数据管道，使用类似贴纸的元素来高效合成高质量的数据集，以支持统一模型训练中编辑数据的扩展。其创新之处在于模型不仅能生成高质量的图像，还能有效进行多种类别的编辑，同时显著提升了编辑任务的表现。
### Conclusion
通过系统的实验验证，DreamOmni展示了其在图像生成和编辑方面的有效性。后续的研究成果将开源其代码和模型。
## 674. `cs.CV` - 动态神经网络综述：从计算机视觉到多模态传感器融合 [PDF](https://arxiv.org/pdf/2501.07451), [HTML](https://arxiv.org/abs/2501.07451)
### Authors
Fabio Montello,Ronja Güldenring,Simone Scardapane,Lazaros Nalpantidis
### Background
在嵌入式设备上部署大型计算机视觉模型时，模型压缩是必不可少的。但是，现有的静态优化技术（如剪枝、量化等）忽略了不同输入的复杂性差异，导致所需计算量也不同。动态神经网络可以根据具体输入调节计算量。当前关于该主题的文献非常丰富和散乱。
### Innovation
本文提供了关于动态神经网络的全面综述，将已有的研究综合并统一在计算机视觉的背景下。提出了一种逻辑分类法，根据网络中的哪个部分是自适应的（输出、计算图或输入），进一步论证动态神经网络在传感器融合中的特别优势，包括更好的适应性、噪声减少和信息优先化。同时，介绍了初步的工作方向，并附带了一个精选的论文库，其中每个被研究的论文都简要概述了解决方案和可用的代码库。
### Conclusion
动态神经网络在传感器融合中特别有益，能够提供更好的适应性、噪声减少和信息优先化。本文为动态神经网络的研究提供了一个逻辑分类和详细的综述，附有相关的论文和代码库的链接，为该领域的进一步研究提供了参考。
## 675. `cs.CV` - SCoT:通过一致直轨迹统一一致性模型和正则化流 [PDF](https://arxiv.org/pdf/2502.16972), [HTML](https://arxiv.org/abs/2502.16972)
### Authors
Zhangkai Wu,Xuhui Fan,Hongyu Wu,Longbing Cao
### Background
预训练的扩散模型通常用于从随机噪声生成干净的数据（例如图像），形成噪声和相应干净图像的配对。对这些预训练模型的蒸馏可以视为在配对内部构造更先进的轨迹以加速采样的过程。例如，一致性模型蒸馏发展了一致的投影函数来调节轨迹，但采样效率仍然是一个值得关注的问题。矫正流方法则强制使轨迹更加直线化以实现更快的采样，但需要依赖数值微分方程求解器，这可能会引入近似误差。
### Innovation
本文通过提出一种称为Straight Consistent Trajectory (SCoT) 的模型来弥补一致性模型和矫正流方法之间的差距。该模型同时具有两种方法的优点，能够同时产生具有一致性和直线性的轨迹。这两种性质通过针对两个关键目标来平衡：（1）调节SCoT映射的梯度到一个常数，（2）保证轨迹一致性。广泛的实验结果证明了SCoT的有效性和效率。
### Conclusion
大量实验结果证明了SCoT模型的有效性和效率，在提升采样速度的同时保持了轨迹的一致性。
## 676. `cs.CV` - 使用ImageNet进行文本到图像生成能走多远？ [PDF](https://arxiv.org/pdf/2502.21318), [HTML](https://arxiv.org/abs/2502.21318)
### Authors
L. Degeorge,A. Ghosh,N. Dufour,D. Picard,V. Kalogeiton
### Background
近年来，大规模数据集上的训练使得文本到图像（T2I）生成模型取得了显著的成功，这种趋势遵循了“数据量越大越好”的模式，优先重视数据量而非数据的开源状态或可重复性（如数据的衰减和建立标准数据集）。本文挑战了这一传统观点，通过仅使用增强的ImageNet数据集，加上精心设计的文字和图像增强，展示出了与巨量网页数据集训练模型相同的成果。
### Innovation
本文创新地证明了使用增强的ImageNet数据集，结合精心设计的文字和图像增强，可以在T2I生成和基准测试中取得显著的性能提升，同时参数量和训练数据量降低至原来的九分之一和千分之一。此外，通过在特定任务数据集上微调ImageNet预训练模型获得了良好的效果，这表明ImageNet足够支撑获取通用能力。
### Conclusion
这种方法为更可复现的研究提供了可能，因为ImageNet数据集广泛可用，并且提出的标准化训练设置仅需500小时的H100即可训练一个文本到图像模型。
## 677. `cs.CV` - One-Step Residual Shifting Diffusion for Image Super-Resolution via Distillation [PDF](https://arxiv.org/pdf/2503.13358), [HTML](https://arxiv.org/abs/2503.13358)
### Authors
Daniil Selikhanovych,David Li,Aleksei Leonov,Nikita Gushchin,Sergei Kushneriuk,Alexander Filippov,Evgeny Burnaev,Iaroslav Koshelev,Alexander Korotin
### Background
扩散模型在超分辨率（SR）任务中能够生成高质量的视觉结果，但计算成本高昂。尽管已经开发出多种加速扩散基础SR模型的方法，但这些方法存在一些问题：一些方法（如SinSR）生成的图像缺乏现实感的感知细节；而另一些方法（如OSEDiff）可能会生成不存在的结构。因此，需要一种新的方法来克服这些问题。
### Innovation
本文提出了一种名为RSD的新蒸馏方法，用于ResShift模型——顶级的扩散基SR模型之一。RSD方法旨在训练学生网络，使生成的图像能够训练一个新的假定的ResShift模型，并使其与教师模型相符。RSD实现了单步恢复，并且在性能上优于教师模型，还展示了该蒸馏方法可以超越基于ResShift的其他蒸馏方法（如SinSR），使其与当前的扩散基SR蒸馏方法平起平坐。与基于预训练文本到图像模型的SR方法相比，RSD生成的感知质量更具竞争力，能更好地与降级输入图像对齐，需要更少的参数和GPU内存。
### Conclusion
我们在多种真实世界和合成数据集（包括RealSR、RealSet65、DRealSR、ImageNet和DIV2K）上提供了实验结果，证明了RSD在超分辨率任务中的有效性。
## 678. `cs.CV` - 改进的纯全连接神经网络在稻米粒分类中的应用 [PDF](https://arxiv.org/pdf/2503.03111), [HTML](https://arxiv.org/abs/2503.03111)
### Authors
Wanke Xia,Bo Lv,Xunwen Xiang,Ruoxin Peng,Haoqi Chu,Xinlei Zhu,Zhiyu Yang,Lili Yang
### Background
稻米是世界上很大一部分人口的重要主食，提供必要的营养，并在各种烹饪传统中作为多用途的成分。近年来，深度学习的应用已使稻米的自动化分类得以实现，提高了准确性和效率。然而，基于第一阶段训练的经典模型在区分具有相似外观特征的稻米品种时可能遇到困难，导致分类错误。因此，本文选择并逐步改进了纯粹的全连接神经网络来实现稻米粒的分类。所使用的数据集既包含来自网站的全球图像数据，也包含来自实验室的国内图像数据。最初，从单阶段训练改为双阶段训练显著有助于区分两种相似类型的稻米。同时，将预处理方法从随机倾斜改为水平或垂直位置校正是关键的改进手段。这些改进使模型的准确性显著提高，从97%提升到99%。
### Innovation
本文提出的方法主要创新在于采用了双阶段训练方法和水平或垂直位置校正的预处理方法，显著提升了稻米粒分类的准确性。
### Conclusion
研究结果表明，本文提出的方法可以显著提升深度学习模型在稻米分类方面的分类能力，特别是在稻米粒的分类中，准确率从97%提升到99%，展示了改进的纯全连接神经网络的有效性。
## 679. `cs.CV` - Temporal Overlapping Prediction: 自监督预训练方法用于LiDAR移动物体分割 [PDF](https://arxiv.org/pdf/2503.07167), [HTML](https://arxiv.org/abs/2503.07167)
### Authors
Ziliang Miao,Runjian Chen,Yixi Cai,Buwei He,Wenquan Zhao,Wenqi Shao,Bo Zhang,Fu Zhang
### Background
LiDAR点云中的移动物体分割（MOS）对于自主系统，如自动驾驶汽车至关重要。之前的监督学习方法依赖于昂贵的手动标注，而LiDAR序列自然捕捉到的时间移动线索可以用于自监督学习。之前的研究主要依赖于昂贵的手动标注，传统度量IoU在评估性能时偏向于点云较多的物体，可能忽略小或远的物体。
### Innovation
本文提出了一种自监督预训练方法——TempPatl Overlapping Prediction（TOP），用于减轻LiDAR移动物体分割的标注负担。TOP通过预测当前扫描和相邻扫描中重叠点的占用状态，学习时空表示。此外，将当前占用重建作为辅助预训练目标，增强模型的结构感知。为了评估物体级的性能，引入了一个额外的评估指标mIoU_obj。实验表明，TOP在nuScenes和SemanticKITTI数据集上优于从零开始的监督训练基线和其他自监督预训练基线，相对改进幅度可达28.77%，显示出跨LiDAR配置较强的技术转移能力和泛化到其他任务的能力。
### Conclusion
TOP方法在LiDAR移动物体分割中表现出色，通过自监督学习减少了对手动标注的依赖，显著提升了小或远物体的检测性能，并且具有良好的泛化能力。
## 680. `cs.CV` - GARLIC: GAussian Representation LearnIng for spaCe partitioning [PDF](https://arxiv.org/pdf/2505.24608), [HTML](https://arxiv.org/abs/2505.24608)
### Authors
Panagiotis Rigas,Panagiotis Drivas,Charalambos Tzamos,Ioannis Chamodrakas,George Ioannakis,Leonidas J. Guibas,Ioannis Z. Emiris
### Background
现有的欧几里得近似最近邻搜索方法倾向于依赖各向同性的细胞、固定的全局分辨率或平衡约束条件，这导致在仅探索少量细胞时增加了候选数量。密集区域被分割，稀疏区域中的不相关点被合并。
### Innovation
GARLIC提出了一种基于高斯分布的几何感知空间分区方法，通过自适应密度细化和信息论目标结合来优化空间划分，使得在较少的查询预算下减少跨细胞邻居分割和候选数量。该方法在训练数据集的小部分上也能保持鲁棒性。
### Conclusion
GARLIC通过将信息论目标与自适应密度优化相结合，提出了一种几何感知的空间分区范式，实现了对于高维欧几里得近似最近邻搜索的兼具召回率和效率的竞争性权衡。
## 681. `cs.CV` - RGS-DR：2D 高斯点积中的延迟反射和残留着色 [PDF](https://arxiv.org/pdf/2504.18468), [HTML](https://arxiv.org/abs/2504.18468)
### Authors
Georgios Kouros,Minye Wu,Tinne Tuytelaars
### Background
在逆向渲染中处理镜面反射外观，使用二维高斯点积和延迟着色，通过引入细化环节来提升镜面细节，从而填补仅重建方法的差距。管道估计可编辑的材料属性和环境照明，利用方向残差通道捕捉视点依赖效果，以进一步改进新颖视角合成。与每个高斯着色和最短轴法线以及法线残差相比，像素延迟表面元素形式具有镜面残差可以产生更清晰的高光，更清洁的材料，以及更好的可编辑性。通过对三种流行数据集上光泽物的渲染和重建质量进行评估，并展示高质量的重新照明和材料编辑结果，验证了方法的有效性。
### Innovation
提出了一种基于2D高斯点积和延迟着色的逆向反射和残留着色方法（RGS-DR），通过细化阶段提高镜面反射细节。相比传统的基于每个高斯阴影和最短轴法线及法线残差的方法，像素延迟表面元素形式结合镜面残差能够产生更清晰的高光、更清洁的材料和更高的可编辑性。
### Conclusion
该研究在三种流行的具有光泽物体的数据集上评估了渲染和重建质量，展示了高质量的重新照明和材料编辑效果，证明了RGS-DR方法的有效性和优越性。
## 682. `cs.CV` - L4P: 向统一的低级四维视觉感知方向迈进 [PDF](https://arxiv.org/pdf/2502.13078), [HTML](https://arxiv.org/abs/2502.13078)
### Authors
Abhishek Badki,Hang Su,Bowen Wen,Orazio Gallo
### Background
视频中像素之间的时空关系对于低级四维感知任务至关重要。目前，大多数最先进的方法依赖于针对特定任务进行优化的专用架构。然而，L4P提出了一种通用的前馈架构，能够在统一框架中解决多种低级四维感知任务。
### Innovation
L4P采用预训练的基于ViT的视频编码器，结合轻量级的任务特定头，能够在不需大量训练的情况下解决多种低级四维感知任务。尽管采用通用和前馈的形式，L4P在稠密任务（如深度或光学流估计）和稀疏任务（如2D/3D跟踪）上与现有专用于特定任务的方法具有竞争力。此外，L4P可以同时解决所有任务，所需时间与单一任务方法相当。
### Conclusion
L4P提供了一种通用的前馈架构，在解决低级四维感知任务方面表现出色，并且在处理稠密和稀疏任务时都表现出竞争力，同时在计算效率上与专用于某一任务的方法相当。
## 683. `cs.CV` - Autoregressive Adversarial Post-Training for Real-Time Interactive Video Generation [PDF](https://arxiv.org/pdf/2506.09350), [HTML](https://arxiv.org/abs/2506.09350)
### Authors
Shanchuan Lin,Ceyuan Yang,Hao He,Jianwen Jiang,Yuxi Ren,Xin Xia,Yang Zhao,Xuefeng Xiao,Lu Jiang
### Background
现有的大规模视频生成模型计算成本高，不适用于实时和交互式应用。这类模型在处理视频生成任务时，尤其是在实时和需要用户互动的情境下，难以实现快速响应。
### Innovation
本文提出了一种自回归对抗后训练（AAPT）方法，将预训练的隐空间视频扩散模型转变为实时、交互式的视频生成器。该模型每次只用一次神经网络函数评估生成一个隐空间帧，并能实时流式传输结果，接收用户的交互控制以生成下一个隐空间帧。本文的方法利用了对抗训练作为自回归生成的有效范式，设计了更高效的单步生成架构且能够充分利用KV缓存，并采用学生强迫训练方法减少长视频生成中的误差累积。
### Conclusion
实验表明，该8B大小的模型能在单个H100上实现每秒24帧，分辨率736x416的实时视频生成，或在8个H100上生成长达一分钟（1440帧）的1280x720视频流。
## 684. `cs.CV` - 通过建模扩散过程的关键步骤进行概念消除 [PDF](https://arxiv.org/pdf/2507.06526), [HTML](https://arxiv.org/abs/2507.06526)
### Authors
Chaoshuo Zhang,Chenhao Lin,Zhengyu Zhao,Le Yang,Qian Wang,Chao Shen
### Background
稳定扩散等文本到图像扩散模型能够根据文本输入生成高度逼真的图像，但这种灵活性也使得它们容易被误用于生成有害或不安全的内容。现有方法在防止这些模型被滥用以生成不希望的视觉内容方面存在不足，难以在消除效果和保留生成质量之间取得平衡。
### Innovation
提出了一种名为关键步骤概念消除（KSCU）的新方法，该方法在关键步骤上选择性地微调模型至目标概念。KSCU借鉴了不同去噪步骤对最终生成贡献不均等的事实。与之前的方法相比，KSCU避免了对不必要的步骤进行过度优化，提高了效果，并减少了参数更新次数，从而提高效率。例如，在I2P数据集上，KSCU在裸露内容消除准确性方面比ESD高8.3%，同时将FID提高了8.4%，并达到0.92的高综合评分，远超所有现有的SOTA方法。
### Conclusion
KSCU能够显著提高概念消除的准确性，同时保持高生成质量，相较于现有方法具有更高的效率。
## 685. `cs.CV` - LRFusionPR：一种基于极坐标BEV的LiDAR和雷达融合网络用于地方识别 [PDF](https://arxiv.org/pdf/2504.19186), [HTML](https://arxiv.org/abs/2504.19186)
### Authors
Zhangshuo Qi,Luqi Cheng,Zijie Zhou,Guangming Xiong
### Background
在自动驾驶中，基于GPS受限环境下的全局定位依赖于地方识别。LiDAR和雷达在基于地方识别中的应用逐渐增多，因LiDAR提供精确的距离测量数据，而雷达在恶劣天气中具有更好的鲁棒性。然而，有效地利用LiDAR和雷达数据的融合来实现地方识别仍然具有挑战性。由于雷达数据噪音大且稀疏，限制了其改善识别准确性。此外，不同类型的雷达配置也增加了跨模态融合框架开发的复杂性。因此，如何利用LiDAR与雷达数据的融合提高地方识别的准确性和鲁棒性成为研究焦点。
### Innovation
本文提出了一种名为LRFusionPR的方法，通过融合单芯片雷达或扫描雷达与LiDAR数据来提高地方识别的准确性和鲁棒性。提出了一个双分支网络，其在统一的极坐标鸟瞰图（BEV）表示中融合不同的模态数据。在融合分支中使用交叉注意机制进行跨模态特征交互。融合信息同时被传递给学生网络分支，仅使用雷达数据作为输入以进一步提高鲁棒性。最终，来自两个分支的描述符被连接，生成多模态全局描述符，用于地方检索。
### Conclusion
通过在多个数据集上进行的广泛评估表明，LRFusionPR方法在各种天气条件下实现了准确的地方识别。该开源代码将在https://example.com/repo处发布。
## 686. `cs.CV` - 使用线性视网膜变换和贝叶斯实验设计融合中心视野注视 [PDF](https://arxiv.org/pdf/2505.01249), [HTML](https://arxiv.org/abs/2505.01249)
### Authors
Christopher K. I. Williams
### Background
人类和其他许多脊椎动物在观察场景时，需要将多个注视点的信息整合起来形成整体的视觉表征。每个注视点使用高分辨率的中央视觉区域（即fovea），而周边区域的视角分辨率逐渐降低。在这个背景下，论文明确了如何通过线性变换表示每个注视点在视网膜上的映射，并利用已知的几何信息进行精确推理。
### Innovation
论文提出了一种全新的方法来融合注视点信息，具体创新点包括：(1)利用已知几何关系代表视网膜视角变化为高分辨率场景隐影像的线性下采样过程；(2)基于这种线性变换进行因子分析及其混合模型的精确推理；(3)利用预期信息增益准则将“下一步注视位置的选择”问题转化为贝叶斯实验设计问题。
### Conclusion
通过在Frey人脸和MNIST数据集上的实验，证明了该模型的有效性。
## 687. `cs.CV` - PlaceIt3D：真实3D场景中的语言引导对象放置 [PDF](https://arxiv.org/pdf/2505.05288), [HTML](https://arxiv.org/abs/2505.05288)
### Authors
Ahmed Abdelreheem,Filippo Aleotti,Jamie Watson,Zawar Qureshi,Abdelrahman Eldesokey,Peter Wonka,Gabriel Brostow,Sara Vicente,Guillermo Garcia-Hernando
### Background
本文介绍了新的任务——基于语言的3D物体放置在真实3D场景中。当给定一个3D场景的点云、一个3D资产和一个广泛描述3D资产应放置位置的文本提示时，该任务的目标是在场景中找到一个满足提示要求的有效放置位置。与3D场景中的其他基于语言的定位任务相比，如语义分割和语义标注等，该任务具有特定的挑战性，因为它有多重正确的解决方案，并且需要推断3D几何关系和空余空间。现有的研究主要集中在其他类型的任务上，缺乏相应的数据集和评估标准，因此引入了这一新的任务，并提出了新的基准和评估协议，同时引入了一个新的数据集以及首个非平凡基线方法。
### Innovation
本文创新地提出了基于语言的3D物体放置任务，提供了新的基准和评估方法，并创建了新的数据集和首个基线方法。这些贡献对于评估和比较通用的3D语言模型至关重要，特别是对于那些需要在真实3D场景中理解和执行自然语言指令的模型而言。
### Conclusion
本文引入了一个新的、具有挑战性的任务，并提出了相应的基准和评估方法，为评估和比较通用的3D语言模型提供了新的视角。我们相信，这项新的任务和基准能够成为评估和比较这些模型的标准之一。
## 688. `cs.CV` - Oh-A-DINO: 在自我监督的对象中心表征中理解和增强属性级信息 [PDF](https://arxiv.org/pdf/2503.09867), [HTML](https://arxiv.org/abs/2503.09867)
### Authors
Stefan Sylvius Wagner,Stefan Harmeling
### Background
对象中心的理解是人类视觉的基础，并且对于复杂的推理是必要的。传统的算法通过槽机制明确学习对象的属性，而最近的自我监督视觉模型，如DINO，展示了对象理解的潜在能力。本文研究了自监督的CLIP、DINOv2和DINOv3模型，以及基于槽的方法，在多实例检索中的效果。多实例检索要求在场景中准确识别特定对象，随着预训练表示在下游任务中的部署（如检索、操纵和基于目标的策略），这一场景变得越来越重要。实验发现，自监督和基于槽的方法擅长识别边缘导出的几何属性（形状、大小），但在保留非几何表面特征（颜色、材质、纹理）方面表现不佳，这些特征是区分对象的关键。研究表明，通过VAE正则化学习附加的隐空间，可以恢复缺失的特性，增强自监督方法在多属性检索中的表现，这表明自监督表征在需要精确对象级别推理的下游任务中的可靠性得到了提高。
### Innovation
本文揭示了自监督视觉模型和基于槽的方法在多实例检索中主要擅长于识别边缘导出的几何属性，但在非几何表面特征上表现较差。提出了一种基于VAE正则化的方法，通过学习附加的隐藏空间来恢复这些缺失的信息，从而提高了自监督方法在不同属性检索任务中的性能。这为提高自监督表征在需要精细对象理解的下游任务中的可靠性提供了新的方向。
### Conclusion
通过引入额外的针对细分片段的隐空间，并利用VAE正则化来改善自监督方法，可以在保持几何属性的同时，恢复非几何表面特征，从而提高了在所有属性下的检索性能。这种改进的自监督方法为下游任务中实现更加精确的物体推理提供了可能。
## 689. `cs.CV` - StreamAgent: 朝向流式视频理解的预判代理 [PDF](https://arxiv.org/pdf/2508.01875), [HTML](https://arxiv.org/abs/2508.01875)
### Authors
Haolin Yang,Feilong Tang,Linxiao Zhao,Xiang An,Ming Hu,Huifa Li,Xinlin Zhuang,Boqian Wang,Yifan Lu,Xiaofeng Zhang,Abdalla Swikir,Junjun He,Zongyuan Ge,Imran Razzak
### Background
实时流式视频理解在自动驾驶和智能监控等领域的应用提出了超越传统离线视频处理的挑战，需要连续感知、主动决策以及基于动态视觉内容的响应交互。现有方法依赖于感知反应的交替或异步触发，缺乏任务驱动的规划和未来预判，限制了它们在演进视频流中的实时响应性和主动性决策。
### Innovation
提出了一个名为StreamAgent的预判代理，能够预见包含未来任务相关信息的时间间隔和空间区域，以便于主动和目标驱动的响应。具体而言，通过提示预判代理预见关键事件的时间进程，将当前观察与预期的未来证据对齐，并据此调整感知行为（例如关注任务相关区域或在后续帧中进行持续跟踪）。为了支持高效推理，设计了一种流式KV缓存内存机制，构建层次化的记忆结构以选择性地召回相关令牌，从而实现有效的语义检索并减少存储所有令牌的传统KV缓存的开销。
### Conclusion
在流式和长视频理解任务上的广泛实验表明，我们的方法在响应准确性及实时效率方面优于现有方法，突显了其在现实世界流式场景中的实际价值。
## 690. `cs.CV` - 基于预测一致性和可靠性的物体检测自动化模型评估 [PDF](https://arxiv.org/pdf/2508.12082), [HTML](https://arxiv.org/abs/2508.12082)
### Authors
Seungju Yoo,Hyuk Kwon,Joong-Won Hwang,Kibok Lee
### Background
近年来，计算机视觉领域取得了显著进展，使得训练对象检测器变得更加高效和有效。然而，评估其在实际应用中的性能仍然依赖于昂贵的手动注释。为解决这一局限性，我们开发了一个自动化模型评估（AutoEval）框架，用于物体检测。
### Innovation
我们提出了预测一致性与可靠性（PCR）方法，这是一种利用常规检测器在非极大值抑制（NMS）前生成的多个候选边界框的技术。PCR通过联合测量边界框在NMS前后空间一致性和保留边界框的置信心得分可靠性来估计检测性能，而不依赖于真实标签。此外，我们通过应用不同严重程度的图像腐蚀构建了一个元数据集，以实现更现实和可扩展的评估。
### Conclusion
实验结果表明，PCR提供了比现有自动化评估方法更准确的性能估计，并且所提出的元数据集覆盖了更广泛的检测性能范围。代码可在相关链接获取。
## 691. `cs.CV` - LEGATO：大规模端到端可泛化的印刷乐谱光学音乐识别方法 [PDF](https://arxiv.org/pdf/2506.19065), [HTML](https://arxiv.org/abs/2506.19065)
### Authors
Guang Yang,Victoria Ebert,Nazif Tamer,Brian Siyuan Zheng,Luiza Pozzobon,Noah A. Smith
### Background
光学音乐识别（OMR）的任务是将乐谱图像转换为机器可读的文档。现有的模型大多只能处理单页乐谱并且不能生成简洁易读的ABC格式符号乐谱。研究人员需要一个能够识别多页乐谱并且生成ABC格式输出的大型预训练模型，以提升其应用的广泛性和实用性。
### Innovation
本文提出了一个名为Legato的新模型，这是第一个能够识别全页或跨多页类型的印刷乐谱的大型预训练OMR模型，并且它是第一个生成ABC符号乐谱的模型。模型结合了预训练的视觉编码器和在超过214K的图像数据集上训练的ABC解码器，展示了在各种类型的乐谱之间很好的泛化能力。实验结果显示Legato在多个数据集和指标上超越了之前的最先进模型，分别在标准指标TEDn和OMR-NED上取得了68%和47.6%的绝对误差降低。
### Conclusion
本文通过对多种数据集进行实验，证明了Legato对于印刷乐谱的识别和转换具有优越的效果，显著提高了模型的鲁棒性和实用性。
## 692. `cs.CV` - VITA: 视觉到动作流匹配策略 [PDF](https://arxiv.org/pdf/2507.13231), [HTML](https://arxiv.org/abs/2507.13231)
### Authors
Dechen Gao,Boqi Zhao,Andrew Lee,Ian Chuang,Hanchu Zhou,Hang Wang,Zhe Zhao,Junshan Zhang,Iman Soltani
### Background
传统的流匹配和基于扩散的策略通过迭代降噪从标准噪声分布（例如高斯分布）中采样，并需要条件机制来在生成过程中结合视觉信息，这带来了巨大的时间与内存开销。
### Innovation
开发了VITA（基于视觉的行为策略），这是一种无需条件机制即可直接将视觉表示映射到潜在动作的无噪声和无条件策略学习框架。引入了动作自编码器，用于将原始动作映射到与视觉潜在空间对齐的结构化潜空间，并与流匹配联合训练，以解决动作与视觉表示之间维度差异的问题。为防止潜空间坍塌，提出了流潜在解码技术，通过流匹配方程（常微分方程）求解步骤回传动作重建损失来锚定潜在生成过程。
### Conclusion
VITA 在8个模拟任务和2个真实世界任务中表现出色或与最先进的生成策略相当，在具有条件机制的传统方法上实现了1.5到2.3倍更快的推理速度。
## 693. `cs.CV` - 机载卫星甲烷检测 [PDF](https://arxiv.org/pdf/2509.00626), [HTML](https://arxiv.org/abs/2509.00626)
### Authors
Maggie Chen,Hala Lambdouar,Luca Marini,Laura Martínez-Ferrer,Chris Bridges,Giacomo Acciarini
### Background
甲烷是一种强效温室气体，是促成气候变化的主要因素之一，因此及时发现甲烷对于有效的减少措施至关重要。机器学习部署在卫星上可以加速甲烷检测，减少回传成本，支持快速响应系统。传统的甲烷检测方法通常依赖于图像处理技术，如正射校正和匹配滤波器以增强烟柱信号。
### Innovation
提出了一个新颖的方法UnorthoDOS，它避免了传统的方法中的预处理步骤，直接使用未正射校正的数据。ML模型在未正射校正数据集上训练的性能与正射校正数据集上训练的模型相当。同时展示了在正射校正数据集上训练的模型比匹配滤波器基线（mag1c）表现出更优的性能。还公开了训练模型的检查点和两个包含地球表层矿物尘埃源调查（EMIT）传感器原生和未正射校正的高光谱图像数据集。
### Conclusion
本研究通过使用未正射校正的数据提高了甲烷检测的效率，减少了预处理步骤，并展示了ML方法在未正射校正数据上的有效性，为快速响应甲烷检测系统提供了支持和优化。
## 694. `cs.CV` - 在低查询黑盒设置中加速硬标签目标导向对抗攻击 [PDF](https://arxiv.org/pdf/2505.16313), [HTML](https://arxiv.org/abs/2505.16313)
### Authors
Arjhun Swaminathan,Mete Akgün
### Background
深度神经网络在图像分类方面仍然容易受到对抗样本的影响——这些微小且不可见的扰动会导致分类错误。在黑盒设置中，由于决策边界的狭窄区域限制了直接利用图像信息的可能性，因此对特定目标分类的有针对性攻击尤其具有挑战性。现有最先进的方法通常会利用分离源图像和目标图像的决策边界的几何属性，但忽略了图像本身的细节。
### Innovation
本文提出了Targeted Edge-informed Attack (TEA)，这是一种新颖的攻击方法，利用目标图像的边缘信息来精确地扰动该图像，生成既接近源图像又能实现所需目标分类的对抗图像。TEA在具有不同模型的低查询设置中表现出更优的效果，与当前最先进的方法相比，使用了几乎少70%的查询次数。这对于有查询限制和只能访问最终预测值的现实应用场景非常有利。通过高效生成合适的对抗样本，TEA还可以为基于几何的攻击提供更好的目标初始化。
### Conclusion
本文通过引入TEA，在低查询的黑盒设置中实现了更高效的针对特定类别的硬标签对抗攻击，有效地利用了目标图像的边缘信息，并显著减少了查询次数。这种方法在实际应用中尤其有效，尤其是在查询受限且只能访问最终预测值的场景下。
## 695. `cs.CV` - 通过标记压缩实现高效全切片病理视觉问答 [PDF](https://arxiv.org/pdf/2507.14497), [HTML](https://arxiv.org/abs/2507.14497)
### Authors
Weimin Lyu,Qingqiao Hu,Kehan Qi,Zhan Shi,Wentao Huang,Saumya Gupta,Chao Chen
### Background
病理学中的全切片图像（WSIs）可达10,000 x 10,000像素，这对多模态大型语言模型（MLLM）构成显著挑战，因为它们需要处理长时间上下文和高计算需求。前人方法通常侧重于进行切片级别的分析或使用基于CLIP的模型进行多实例学习的切片级别分类，但这些方法缺乏进行视觉问答（VQA）所需的生成能力。近年来，MLLM基础方法通过直接将成千上万个切片标记输入语言模型来解决VQA问题，但这种方法导致了过度的资源消耗。
### Innovation
我们提出了Token Compression Pathology LLaVA（TCP-LLaVA），这是第一个通过标记压缩执行WSI VQA的MLLM架构。该模型引入了一组可训练的压缩标记，通过模态压缩模块（灵感来源于BERT的[CLS]标记机制）聚集视觉和文本信息。压缩后的标记被送入语言模型进行答案生成，显著减少了输入长度和计算成本。实验结果显示，TCP-LLaVA在VQA准确性上优于现有MLLM基线，并且能够大幅度减少训练资源消耗.
### Conclusion
实验结果显示，TCP-LLaVA在各种TCGA肿瘤亚型的VQA准确性上优于现有MLLM基线，同时大幅减少了训练资源消耗。
## 696. `cs.CV` - 使用KL散度聚焦低光图像增强的频率信息 [PDF](https://arxiv.org/pdf/2509.13083), [HTML](https://arxiv.org/abs/2509.13083)
### Authors
Yan Xingyang,Huang Xiaohong,Zhang Zhao,You Tian,Xu Ziheng
### Background
在傅立叶域中，亮度信息主要编码在振幅谱中，而空间结构则在相位成分中捕捉。传统的傅立叶频率信息拟合使用像素级损失函数，这倾向于过度关注局部信息，可能导致全局信息的丢失。
### Innovation
本文提出了LLFDisc，一种结合了交叉注意机制和门控机制的U型深度增强网络，专门用于频率感知增强。提出了一个新型的分布感知损失，可以直接拟合傅立叶域信息，并通过闭式KL散度目标最小化它们的差异。此外，通过在提取的深层特征中嵌入KL散度来增强基于VGG的感知损失，以实现更好的结构保真度。
### Conclusion
在多个基准上的大量实验表明，LLFDisc在定性和定量评估中都实现了最先进的性能。我们的代码将发布在这里：this https URL
## 697. `cs.CV` - GenExam：跨学科的文本到图像考试 [PDF](https://arxiv.org/pdf/2509.14232), [HTML](https://arxiv.org/abs/2509.14232)
### Authors
Zhaokai Wang,Penghao Yin,Xiangyu Zhao,Changyao Tian,Yu Qiao,Wenhai Wang,Jifeng Dai,Gen Luo
### Background
现有的考试风格基准主要侧重于理解和推理任务，而当前的生成基准则强调展示世界知识和视觉概念，忽略了严格绘图考试的评估。
### Innovation
引入了GenExam，这是第一个跨学科的文本到图像考试基准，包含10个科目1000个样本，采用四级分类的考试风格提示，每个问题提供精确的评分点，用于准确评估语义正确性和视觉合理性。
### Conclusion
实验表明，即使是最先进的模型如GPT-Image-1和Gemini-2.5-Flash-Image，也仅能获得不到15%的严格分数，大多数模型几乎为0%，说明基准的挑战性。通过将图像生成作为考试，GenExam提供了一种严格评估模型整合理解、推理和生成能力的方法，为通往通用AGI的途径提供了见解。基准和评估代码发布在this https URL
## 698. `cs.CV` - RS-OOD：遥感领域增强的视觉-语言框架用于离分布检测 [PDF](https://arxiv.org/pdf/2509.02273), [HTML](https://arxiv.org/abs/2509.02273)
### Authors
Chenhao Wang,Yingrui Ji,Yu Meng,Yunjian Zhang,Yao Zhu
### Background
在遥感应用中，可靠的新型或异常模式识别对于自主监控、灾害响应和环境评估至关重要。尽管在自然图像的离 distribution（OOD）检测方面取得了显著进展，但现有的方法和基准由于数据稀少、复杂多尺度场景结构和显著的分布变化，仍不适合遥感图像。
### Innovation
提出了RS-OOD，一种利用遥感特定的视觉-语言建模的理念，以实现稳健的少量样本OOD检测。关键创新包括：增强空闲特征以提高场景区分度，双重提示对齐机制以在宏观场景结构与细粒度语义之间实现空间语义一致性，以及一种基于置信度的自我训练循环，动态挖掘伪标签来扩展训练数据，无需手动注解。
### Conclusion
RS-OOD在多个遥感基准测试中持续优于现有方法，并且能够高效适应，使用最少的标记数据，证明了空间语义集成的关键价值。
## 699. `cs.CV` - 使用轻度语义噪声提高视觉语言模型的鲁棒提示调整 [PDF](https://arxiv.org/pdf/2508.04677), [HTML](https://arxiv.org/abs/2508.04677)
### Authors
Yansheng Gao,Yufei Zheng,Shengsheng Wang
### Background
提示调优已经显示出有希望的结果，但其鲁棒性和对未遇见过的类别的一般化能力仍然有限。现有方法通常在提示空间中抑制或过滤语义噪声，无意中影响了模型的鲁棒性和其对未见过类别的泛化能力。因此，研究者提出了一种将轻微语义噪声纳入的鲁棒提示调优框架（ANPrompt），以解决这一问题，并通过增强视觉路径和引入噪声抵抗视觉提示原型（NRVPP）以及在符号层面提出弱对齐损失（WALoss）来确保语义变化的可控暴露，从而防止模型过度拟合特定的表达方式并保持语义完整性。
### Innovation
该论文提出了ANPrompt（鲁棒提示调优框架），这是一种将轻微语义噪声纳入的鲁棒提示调优框架。ANPrompt通过声噪聚类以及视觉和文本编码器中的可学习标记集成来强化轻微的噪声。为了增强视觉路径，引入了噪声抵抗力视觉提示原型（NRVPP），在符号层面提出弱对齐损失（WALoss）以确保清洁和扰动预测之间的稳定监督，从而增强了视觉语义的一致性。ANPrompt通过将轻微的语义噪声暴露与符号层面的一致性相结合，防止模型对特定表达方式过度拟合并保持语义完整性。
### Conclusion
在11个基准测试中进行的广泛实验表明，ANPrompt在鲁棒性、噪声语义的稳健性和跨任务的泛化能力方面均优于现有的提示调优方法。
## 700. `cs.CV` - DiCache：让扩散模型自行决定缓存 [PDF](https://arxiv.org/pdf/2508.17356), [HTML](https://arxiv.org/abs/2508.17356)
### Authors
Jiazi Bu,Pengyang Ling,Yujie Zhou,Yibin Wang,Yuhang Zang,Dahua Lin,Jiaqi Wang
### Background
近年来，关于扩散模型加速技术的研发取得了迅速的发展，尤其是一些基于缓存的加速方法。这些研究主要关注于“何时缓存”和“如何使用缓存”两个基本问题，通常依赖预设的经验法则或数据集先验知识来确定缓存时间，并采用手工编写的规则进行多步骤缓存利用。然而，由于扩散过程的动态性较强，这些方法往往表现出有限的一般性和难以应对多样化的样本。因此，亟需一种既能适应不同样本特性的、训练无监督的自适应缓存策略来加速扩散模型，解决现有方法展现出的不足。
### Innovation
本文揭示了浅层特征差异的变化模式与深层特征变化模式之间的强样本特异性相关性，并且观察到不同模型层的特征形成了相似的轨迹。基于这些发现，提出了DiCache，一种新型的训练无监督的自适应缓存策略，能够在运行时加速扩散模型，统一回答何时以及如何缓存的问题。DiCache由两部分组成：（1）在线探针分析方案利用浅层探针在线获取实时的缓存错误指示，使模型能够动态为每个样本自适应调整缓存计划；（2）动态缓存轨迹对齐，根据浅层特征轨迹自适应近似多步骤历史缓存中的深层特征输出，提高视觉质量。
### Conclusion
通过广泛的实验，DiCache在包括WAN 2.1、HunyuanVideo和Flux等领先扩散模型在内的多个关键评估标准上展现了更高的效率和更高的一致性。
## 701. `cs.CV` - Patch-Level Kernel Alignment for Dense Self-Supervised Learning [PDF](https://arxiv.org/pdf/2509.05606), [HTML](https://arxiv.org/abs/2509.05606)
### Authors
Juan Yeo,Ijun Jang,Taesup Kim
### Background
现有的自监督学习（SSL）方法在细化语义理解方面显示出有效性，但这些方法通常依赖参数假设或复杂的后处理（如聚类、排序），限制了灵活性和稳定性。
### Innovation
提出了一种名为Patch-level Kernel Alignment (PaKA)的非参数化、核基于方法。它通过后（预）训练增强预训练视觉编码器的密集表示。该方法提出了一种稳健且有效的对齐目标，捕捉统计依赖性，匹配高维密集特征分布的固有结构，还重新审视了图像级SSL继承的增广策略，提出了改进的密集SSL增广策略。
### Conclusion
通过在预训练模型上执行一个轻量级的后训练阶段，该方法仅在单GPU上额外训练14小时，就在一系列密集视觉基准测试中达到了最先进的性能，显示出高效性和有效性。
## 702. `cs.CV` - TrimTokenator: 朝着大型多模态模型中自适应视觉标记剪枝的道路 [PDF](https://arxiv.org/pdf/2509.00320), [HTML](https://arxiv.org/abs/2509.00320)
### Authors
Hao Zhang,Mengsi Lyu,Chenrui He,Yulong Ao,Yonghua Lin
### Background
大型多模态模型（LMMs）已经在各种任务中取得了显著的成功。这些模型通常将视觉输入编码为密集的标记序列，然后与文本标记连接并由语言模型联合处理。然而，这种标记数量的增加在推理过程中大大增加了计算和内存成本。标记剪枝已经作为一种有前景的方法出现，用于解决这一问题。现有的标记剪枝方法往往依赖于昂贵的校准或次优的重要性度量，导致冗余的保留标记。本文分析了视觉标记和文本标记之间的冗余差异，并提出仅对视觉标记进行剪枝的方法。在此基础上，我们提出了一种针对视觉标记的剪枝策略，其明确地保留了跨模态对齐和单模态信息多样性。我们引入了一种基于互信息的标记剪枝策略，该策略能够去除与文本标记语义不一致的视觉标记，有效保持了视觉和文本模态之间的对齐。为了进一步提高保留标记的表现性质量，我们还通过最大化嵌入空间中的期望对距离来剪枝冗余的视觉标记，这个问题通过贪婪算法高效地解决。
### Innovation
本文提出了一种自适应视觉标记剪枝策略，旨在同时保留跨模态对齐和单模态信息多样性。所提出的策略基于互信息，用于去除与文本标记语义不一致的视觉标记，并进一步通过最大化嵌入空间中的期望对距离来剪枝冗余的视觉标记，解决了视觉标记的剪枝问题。这种方法在不降低性能的前提下显著减少了标记数量，并大幅提升了推理速度。
### Conclusion
我们的方法在LLaVA-1.5-7B和LLaVA-NEXT-7B等模型上保持了强大的性能，同时减少了88.9%的标记数量，推理速度提高了56.7%。
## 703. `cs.CV` - CAMILA：具有语言对齐的上下文感知图像编辑掩码 [PDF](https://arxiv.org/pdf/2509.19731), [HTML](https://arxiv.org/abs/2509.19731)
### Authors
Hyunseung Kim,Chiho Choi,Srikanth Malla,Sai Prahladh Padmanabhan,Saurabh Bagchi,Joon Hee Choi
### Background
现有的图像编辑模型通过自然语言指令允许用户进行图像转换和合成，提供了很大的灵活性。然而，大多数现有的图像编辑模型会不加区分地遵循所有用户的指令，即使这些指令是不切实际的或矛盾的，往往会导致不合理的输出。
### Innovation
提出了一种名为CAMILA（具有语言对齐的上下文感知图像编辑掩码）的方法，该方法旨在验证指令与图像之间的上下文一致性，确保只对指定区域应用相关编辑，同时忽略无法执行的指令。
### Conclusion
通过构建包含不切实际请求的单指令和多指令图像编辑数据集，该方法在全面评估中表现出更好的性能和更高的语义对齐能力，证明了其在处理复杂指令挑战并保持图像完整性方面的有效性。
## 704. `cs.CV` - 使用遥感和机器学习进行土地覆盖分类和变化检测：斐济西部地区案例研究 [PDF](https://arxiv.org/pdf/2509.13388), [HTML](https://arxiv.org/abs/2509.13388)
### Authors
Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra
### Background
斐济作为一个发展中国家，正经历快速的城市化进程，这在大规模的城市建设项目中尤为明显，如住宅建设、道路建设和公共工程。本研究旨在利用遥感技术和机器学习方法，分析2013年至2024年间斐济纳迪地区土地利用和覆盖变化情况，为土地覆盖/利用建模和变化检测提供技术支持。研究区域的卫星影像数据使用了Landsat-8卫星图像，并通过监督机器学习方法构建了训练数据集。
### Innovation
研究使用Google Earth Engine和k-means聚类进行无监督机器学习，生成土地覆盖地图。通过卷积神经网络对选定区域的土地覆盖类型进行分类，并展示了变化检测的可视化结果，突出城市区域随时间的变化，监测地图上的变化趋势。
### Conclusion
研究提供的技术框架有助于理解和监测斐济纳迪地区的土地利用和覆盖变化，为城市的可持续发展提供数据支持。
## 705. `cs.CV` - 通过病理信息指导的域随机化增强胎儿MRI胼胝体分割 [PDF](https://arxiv.org/pdf/2508.20475), [HTML](https://arxiv.org/abs/2508.20475)
### Authors
Marina Grifell i Plana,Vladyslav Zalevskyi,Léa Schmidt,Yvan Gomez,Thomas Sanchez,Vincent Dunet,Mériam Koob,Vanessa Siffredi,Meritxell Bach Cuadra
### Background
胎儿大脑分割对于提取生物标志物和评估神经发育非常重要，尤其是在像胼胝体发育不良（CCD）这样的条件下尤为关键，它可以引起严重的解剖学变化。然而，由于CCD的罕见性严重限制了标注数据，阻碍了深度学习模型的一般化。为了应对这一挑战，本研究提出了一种病理信息指导的域随机化策略，将CCD的先验知识嵌入到合成数据生成管道中。通过仅使用健康数据来模拟各种脑部改变，我们的方法可以在无需标注病理数据的情况下实现稳健分割。
### Innovation
本研究提出了一种病理信息指导的域随机化策略，该策略将CCD的先验知识嵌入到合成数据生成管道中。通过仅使用健康数据来模拟各种脑部改变，本方法可以在不需要病理标注数据的情况下实现稳健的分割，从而克服了数据稀缺的问题，并增强了对罕见但临床意义重大的畸形的分析。
### Conclusion
本研究证明，将特定领域的解剖先验知识嵌入到合成数据管道中可以有效缓解数据稀缺问题，并提高对罕见但具有临床意义的发育不良的分析。通过对预测分割的临床相关生物标志物，如胼胝体长度（LCC）和体积的提取和分析，展示了本方法的优越性。
## 706. `cs.CV` - Segmentor-Guided Counterfactual Fine-Tuning for Locally Coherent and Targeted Image Synthesis [PDF](https://arxiv.org/pdf/2509.24913), [HTML](https://arxiv.org/abs/2509.24913)
### Authors
Tian Xia,Matthew Sinclair,Andreas Schuh,Fabio De Sousa Ribeiro,Raghav Mehta,Rajat Rasal,Esther Puyol-Antón,Samuel Gerber,Kersten Petersen,Michiel Schaap,Ben Glocker
### Background
生成对抗图像是一种增强训练数据、消除数据偏见和疾病建模的强大工具。当前的方法依赖外部分类器或回归分析来增强基于个体的干预措施（例如改变患者的年龄）。然而，对于特定结构的干预措施（例如在胸部X光片中改变左肺的区域），这种方法不够充分，可能会导致整个图像域中的不希望的全局效应。
### Innovation
此前的工作使用像素级标签图作为指导，需要用户提供假设分割，这通常是麻烦且难以获得的。本文提出了一种新的方法——Segmentor-guided Counterfactual Fine-Tuning (Seg-CFT)，该方法保留了干预标量值、特定结构变量的简便性，同时生成局部一致且有效的对抗内容。该方法展示了生成现实胸部X光片的能力，并展示了在冠状动脉疾病建模方面的有前景的结果。
### Conclusion
通过Seg-CFT，研究人员能够生成满足特定条件且逼真的图像，尤其是在胸部X光分析和冠状动脉疾病建模中展示了其潜在应用价值。
## 707. `cs.CV` - EyePCR：眼科手术精细感知、知识理解与临床推理的综合基准 [PDF](https://arxiv.org/pdf/2509.15596), [HTML](https://arxiv.org/abs/2509.15596)
### Authors
Gui Wang,Yang Wennuo,Xusen Ma,Zehao Zhong,Zhuoru Wu,Ende Wu,Rong Qu,Wooi Ping Cheah,Jianfeng Ren,Linlin Shen
### Background
随着多模态大型语言模型（MLLMs）展现出显著能力，但在高风险、专业特定的场景下，如手术设置中，它们的表现仍然缺乏探索。本文旨在填补这一空白，开发了EyePCR，一个基于结构化临床知识的大型基准测试，用于评估感知、理解和推理的认知能力。EyePCR提供了超过210,000个带有丰富注释的VQA，覆盖了1048个详细的属性，以及超过25,000个三元组的医学知识图谱，并提出四个临床驱动的推理任务，以此促进深度认知分析，模拟外科医生如何结合视觉线索和领域知识进行决策，从而极大提升模型的认知能力。
### Innovation
开发了EyePCR，一个全面的基准测试，旨在评估MLLMs在眼科手术中精细感知、知识理解及临床推理上的能力。EyePCR提供了超过210,000个带有丰富注释的VQA，以及25,000多个医学知识三元组，并引入四个临床相关推理任务，用以促进深度认知分析。特别地，EyePCR-MLLM，Qwen2.5-VL-7B的领域适应变体，在感知判断题中实现最高准确率，理解上优于开源模型，并在推理上与商业模型GPT-4相媲美。该研究揭示了现有MLLMs在手术认知中的局限性，并为基准测试和提高手术视频理解模型的临床可靠性奠定了基础。
### Conclusion
EyePCR揭示了现有MLLMs在手术认知中的局限性，提出了新的基准测试和评估方法，有助于提升医疗视频理解模型的临床可靠性，尤其是针对眼科手术的专业认知能力。
## 708. `cs.CV` - GEM: 3D Gaussian Splatting for Efficient and Accurate Cryo-EM Reconstruction [PDF](https://arxiv.org/pdf/2509.25075), [HTML](https://arxiv.org/abs/2509.25075)
### Authors
Huaizhi Qu,Xiao Wang,Gengwei Zhang,Jie Peng,Tianlong Chen
### Background
冷冻电子显微镜（cryo-EM）已成为高分辨率结构生物学的核心工具，但由于大规模数据集（经常超过100k粒子图像）导致三维重构既耗费大量计算资源，也需要大量内存。传统傅里叶空间方法虽然高效但会因重复变换而损失分辨率，而基于神经辐射场（NeRF）的近期实空间方法虽然提高了准确性但带来了立方级的内存和计算开销。这使得现有方法难以在保持高分辨率的同时实现高效和快速的三维重构。
### Innovation
本文提出了一种新的基于三维正态点积（3D Gaussian Splatting, 3DGS）的cryo-EM重建框架GEM，该方法能够在实空间中直接操作，同时保持高效性。GEM通过使用紧凑的3D高斯模型表示蛋白质，每个参数化仅需11个值，并设计了一种新的用于每个体素贡献梯度计算方法以进一步提高训练效率。这使得GEM相较于最先进的方法，在保持高效的同时，实现了更高的分辨率和更低的内存使用率，特别是在训练效率和内存利用率方面表现明显优于现有技术。
### Conclusion
这些结果表明，GEM是一个实用且可扩展的cryo-EM重建范式，能够统一速度、效率和高分辨率的准确性。我们的代码可以在以下链接访问：this https URL.
## 709. `cs.CV` - Causal-Adapter: Taming Text-to-Image Diffusion for Faithful Counterfactual Generation [PDF](https://arxiv.org/pdf/2509.24798), [HTML](https://arxiv.org/abs/2509.24798)
### Authors
Lei Tong,Zhihua Liu,Chaochao Lu,Dino Oglic,Tom Diethe,Philip Teare,Sotirios A. Tsaftaris,Chen Jin
### Background
文本到图像的扩散模型已经取得了显著的成果，但大多数方法在生成因果干预的图像时缺乏对目标属性的精确控制。这些模型通常依赖于提示工程，这在没有明确的因果结构的情况下很难实现对目标属性的准确和可控的干预。因此，本文旨在提出一种新的框架，即因果适配器（Causal-Adapter），它能够对冻结的文本到图像扩散骨干进行模块化适应，以进行反事实图像生成，并能对目标属性进行因果干预，而不会改变图像的核心身份。
### Innovation
Causal-Adapter 框架通过引入结构性因果建模，并结合提示对齐的注入和条件标记对比损失两种属性正则化策略，实现了对目标属性的准确控制，并减少了不需要的相关性。其方法包括: 1. 提示对齐的注入 (Prompt-aligned Injection)，确保因果属性与文本嵌入一致，以实现精确的语义控制；2. 条件标记对比损失 (Conditioned Token Contrastive Loss)，来分离属性因素并减少虚假相关性。该方法在合成和真实数据集上均取得了优秀的性能，实现了大幅度的指标改善，比如在 Pendulum 数据集上 MAE 减少了 91%，在 ADNI 数据集上 FID 减少了 87%，这表明介绍了该方法能够实现稳健且通用的反事实编辑，并能准确修改属性和强烈保持图像的一致性。
### Conclusion
Causal-Adapter 能够实现对目标属性的精准控制，而且在保持图像核心身份不变的情况下，实现了高度准确的属性修改和高保真的 MRI 图像生成。这展示出该方法在反事实编辑方面的强大能力和通用性。
## 710. `cs.CV` - More Thought, Less Accuracy? On the Dual Nature of Reasoning in Vision-Language Models [PDF](https://arxiv.org/pdf/2509.25848), [HTML](https://arxiv.org/abs/2509.25848)
### Authors
Xinyu Tian,Shu Zou,Zhaoyuan Yang,Mengqi He,Fabian Waschkowski,Lukas Wesemann,Peter Tu,Jing Zhang
### Background
大型语言模型（LLMs）通过强化学习（RL）特别是组相对策略优化（GRPO）提升了复杂任务如数学和代码生成的能力。近期研究旨在将这种推理能力扩展到视觉-语言模型（VLMs）上，产生了跨多种视觉任务的良好结果。然而，研究发现多模态推理在提升逻辑推理和解决复杂问题的同时，可能导致感知接地的逐渐减弱，进而对基本视觉问题出现识别失败。
### Innovation
论文提出了一种名为Vision-Anchored Policy Optimization（VAPO）的方法，通过此方法，可以通过明确引导推理过程朝向视觉接地路径来解决视觉遗忘问题。基于VAPO的VAPO-Thinker-7B模型显著增强了模型对视觉信息的依赖，并在多个公认基准上取得了新的最佳结果。
### Conclusion
研究结果表明，在视觉-语言模型中，多模态推理具有双重性质，能够提升逻辑推理能力，但可能导致感知接地减弱。通过VAPO方法，可以有效地增强模型对视觉信息的依赖，实现更出色的性能。
## 711. `cs.CV` - 通过特征解耦实现多域脑血管分割 [PDF](https://arxiv.org/pdf/2510.00665), [HTML](https://arxiv.org/abs/2510.00665)
### Authors
Francesco Galati,Daniele Falcetta,Rosa Cortese,Ferran Prados,Ninon Burgos,Maria A. Zuluaga
### Background
脑血管的复杂形态给自动分割模型带来了重大挑战，这些模型通常聚焦于单一成像模态。然而，准确治疗脑部相关疾病需要全面了解整个脑血管树，而不论具体的成像程序。现有的框架虽然可以在各种数据集上有效分割脑动脉和静脉，但仍需要针对特定领域设计模型和数据统一处理，这限制了其应用范围。
### Innovation
本文提出了一种框架，通过图像到图像的转换有效地分割来自不同数据集的脑动脉和静脉，而无需特定领域的模型设计和源域与目标域之间的数据调整。该方法利用解耦技术独立操纵不同的图像属性，使它们在标签保持的情况下从一个领域转移到另一个领域。特别地，该方法在适应过程中着重调控血管外观，同时保留关键的形状和位置信息。该框架在跨越不同医疗机构、成像模态和血管类型的大规模和多样的领域差距中进行了有效评估，并通过消融研究探讨了最佳注释数量和其他架构选择。
### Conclusion
实验结果强调了该框架的稳健性和灵活性，展示了领域适应方法在多种场景下准确进行脑血管图像分割的潜力。该代码可供下载访问。
## 712. `cs.CV` - CNN与生物医学视觉语言模型在医疗诊断中的比较分析：更大better就一定更好吗？ [PDF](https://arxiv.org/pdf/2510.00411), [HTML](https://arxiv.org/abs/2510.00411)
### Authors
Ran Tong,Jiaqi Liu,Su Liu,Jiexi Xu,Lanruo Wang,Tong Wang
### Background
胸部X光影像的准确解读是医学影像分析的关键任务。本文对比了监督轻量级卷积神经网络（CNN）和最新的零样本生物医学视觉-语言模型（BiomedCLIP）在肺炎检测和结核病检测中的表现。
### Innovation
研究发现，通过简单地调整分类阈值（decision threshold calibration），零样本视觉语言模型（VLM）能够显著提升其性能，并且在肺炎和结核病检测任务中，其性能甚至可以超越监督学习的CNN模型。这一工作强调了正确的校准对于利用零样本VLM的全部诊断能力至关重要。
### Conclusion
研究结果表明，适当的校准是实现零样本VLM性能的最大化，并使其能够与甚至超越轻量级的监督模型的关键。这为未来利用视觉语言模型进行医疗诊断提供了重要的指导意义。
## 713. `cs.CV` - RIFLE: 通过潜在扩散增强去除图像中的闪烁条纹 [PDF](https://arxiv.org/pdf/2509.24644), [HTML](https://arxiv.org/abs/2509.24644)
### Authors
Libo Zhu,Zihan Zhou,Xiaoyang Liu,Weihang Zhang,Keyu Shi,Yifan Fu,Yulun Zhang
### Background
在我们的日常生活中，屏幕截图已经成为常规操作。但来自发光显示器的照片往往受到闪烁条纹（FB）的影响，这是由于照相机卷帘快门读取与显示器亮度调制之间的时域混叠造成的交替明暗条纹。尽管莫雷尔退化已经被广泛研究，但FB由于其频繁且严重的可读性和感知质量影响，仍然尚未受到足够的探索。我们将其去除表述为一项专门的修复任务，并提出了通过潜在扩散增强去除闪烁条纹的框架（RIFLE），该框架旨在去除FB同时保留细节。为了补充有限的数据，我们提供了一个模拟流程来在亮度域中合成带有随机闪烁条纹角度、间距和宽度抖动的FB，同时增加了羽化边缘和传感器噪声，以实现更真实的模拟。为此，我们收集了一个带有像素对齐的无闪烁条纹参考的配对实际世界数据集，用于评估。
### Innovation
我们提出了一种新的方法，即通过潜在扩散增强去除图像中的闪烁条纹（RIFLE），解决了之前对FB关注不足的问题。我们引入了闪烁条纹先验估计器（FPE）来预测关键的闪烁条纹属性并将其注入到修复网络中。此外，我们还提出了遮罩损失（ML）来对带状区域集中监督，而不会牺牲全局保真度。为了克服数据稀缺性，我们提供了一个模拟管道，能够在亮度域中模拟带有随机抖动的闪烁条纹角度、间距和宽度。我们模型的表现从轻微到严重程度的不同都优于近期的图像重建基准。据我们所知，这是我们首次对FB的模拟和去除进行研究。我们的工作为后续研究在数据集建设和去除模型设计方面奠定了坚实的基础。我们的数据集和代码将很快发布。
### Conclusion
本文提出了一种新的方法RIFLE，通过潜在扩散增强去除图像中的闪烁条纹，该方法在去除FB同时保留了图像细节。RIFLE在实际世界数据集上的定量指标和视觉比较中表现出色，优于近期的图像重建基准，是首次对FB进行模拟和去除的研究。我们为后续研究在数据集构建和去除模型设计方面建立了坚实的基础，并将很快发布我们的数据集和代码。
## 714. `cs.CV` - 在组织病理学中基于语义和视觉剪辑的扩散模型的异质组织合成 [PDF](https://arxiv.org/pdf/2509.17847), [HTML](https://arxiv.org/abs/2509.17847)
### Authors
Saghir Alfasly,Wataru Uegami,MD Enamul Hoq,Ghazal Alabtah,H.R. Tizhoosh
### Background
生成的合成数据在组织病理学中面临着独特的挑战：保持组织异质性、捕捉微妙的形态特征以及扩展到未标注的数据集上。现有方法依赖于文本提示或抽象的视觉嵌入，而不能直接保留关键形态特征。本文提出了一种潜在扩散模型，通过结合语义分割图和组织特异性视觉切片的双重条件方法，生成具有异质性的真实组织病理学图像。对于标注数据集（例如Camelyon16、Panda），提取的块确保了20-80%的组织异质性；对于未标注的数据集（例如TCGA），引入了一种自监督扩展方法，通过基础模型嵌入将全片图像聚类成100种不同的组织类型，从而自动生成伪语义图进行训练。该方法合成具有高保真度的图像，具有精细的区域注释，并在下游分割任务中表现优异。通过对Camelyon16和Panda等标注数据集进行评估，采用本合成数据训练的模型在性能上与基于真实数据训练的模型相媲美，展示了可控的组织异质性生成的实用价值。定量评估表明，基于提示的合成在Camelyon16上的Fréchet距离最多减少了6倍（从430.1降至72.0），Panda和TCGA的数据分别达到了2到3倍的降低。仅使用合成数据训练的DeepLabv3+模型在Camelyon16和Panda上的测试IoU分别为0.71和0.95，与真实数据基线接近（分别为0.72和0.96）。进而扩展到11,765张TCGA全片图像，无需手动注释，本框架提供了一种实用的解决方案，以应对生成多样、标注的组织病理学数据的迫切需求，解决了计算病理学中的关键瓶颈问题。
### Innovation
本文提出了一种潜在扩散模型，利用结合语义分割图和组织特异性视觉切片的双重条件方法生成异质组织病理学图像。该方法在一、未标注数据集上通过聚类全片图像生成用于训练的伪语义图，改进了基于文本或抽象视觉嵌入的现有方法。合成的图像在下游分割任务中的表现与基于真实数据训练的模型相当，展示了其有效的性能。通过减少Fréchet距离以及改进的IoU结果，该方法展示了对标注数据的增强生成能力。在大量未标注数据集TCGA上成功应用，证实了其在生成大量、多样且准确的组织病理学数据方面的潜力。
### Conclusion
通过提出基于语义和视觉剪辑的扩散模型，本文解决了组织病理学中生成合成数据的挑战。该模型能够保持组织异质性，能够有效用于分段任务。通过自监督技术扩展到未标注数据集，证明了模型在生成大量多样且注释丰富的组织病理学数据方面的有效性。文中设定了合成数据训练模型在分割任务上的性能可以媲美使用真实数据训练的模型，并且展示了其在应对计算病理学领域的主要挑战上的潜力。
## 715. `cs.CV` - LLaVAShield：保护视觉语言模型中的多模态多轮对话 [PDF](https://arxiv.org/pdf/2509.25896), [HTML](https://arxiv.org/abs/2509.25896)
### Authors
Guolei Huang,Qinzhi Peng,Gan Xu,Yuxuan Lu,Yongjun Shen
### Background
随着视觉语言模型（VLMs）向多轮交互式应用发展，单一轮次或单一模态的审查机制开始错过新的安全风险。在多模态多轮（MMT）对话中，恶意意图可能跨越多个回合和图像进行传播，而上下文敏感的回答也可能推进有害内容。本文探讨了这一挑战及其带来的安全风险，并介绍了一个系统性的定义和多模态多轮对话安全的研究。
### Innovation
本文提出了首个系统性的多模态多轮对话安全定义和研究，并构建了MMDS（Multimodal Multi-turn Dialogue Safety）数据集。基于蒙特卡洛树搜索（MCTS），开发了一个自动化的多模态多轮红队框架，用于生成MMDS中的不安全对话。此外，还提出了LLaVAShield工具，该工具能够联合检测和评估用户输入和助手响应中的风险。在实验中，LLaVAShield在多轮内容审查任务上始终优于基准指标，并在动态政策配置下建立了新的SOTA结果。
### Conclusion
本文通过公开发布的MMDS数据集和LLaVAShield工具，支持未来对此领域的进一步研究。
## 716. `cs.CV` - Normal-Abnormal Guided Generalist Anomaly Detection [PDF](https://arxiv.org/pdf/2510.00495), [HTML](https://arxiv.org/abs/2510.00495)
### Authors
Yuexin Wang,Xiaolei Wang,Yizheng Gong,Jimin Xiao
### Background
当前的一般性异常检测（GAD）方法主要依赖正常样本进行训练，忽视了异常样本中的丰富信息，尤其是在现实世界的场景中，异常样本往往可以获得。这限制了在不同领域进行异常检测时的表现。
### Innovation
本文提出了一种更为实用的方法：正常-异常引导的一般性异常检测，该方法利用正常和异常样本作为参考，引导跨领域异常检测。提出了Normal-Abnormal Generalist Learning (NAGL)框架，包含Residual Mining (RM)和Anomaly Feature Learning (AFL)两个关键组件。RM 从正常-异常参考残差中提取异常模式，AFL 通过残差映射自适应学习查询图像中的异常特征，以识别实例相关的异常。
### Conclusion
通过在多个基准测试中进行广泛实验，本文的方法显著优于现有的GAD方法。这是首次在一般性异常检测中采用正常和异常样本混合作为参考的方法。
## 717. `cs.CV` - VRWKV-Editor: 减少基于变换器的视频编辑中的二次复杂度 [PDF](https://arxiv.org/pdf/2509.25998), [HTML](https://arxiv.org/abs/2509.25998)
### Authors
Abdelilah Aitrouga,Youssef Hmamouche,Amal El Fallah Seghrouchni
### Background
近年来视频编辑取得了显著的进步，深度学习模型已经能够同时关注空间和时间依赖性，成为主要的研究方法。然而，这些模型受到传统注意力机制二次复杂性的困扰，在处理长时间高分辨率视频时难以适应，这限制了它们在实时视频处理等实用场景中的应用。传统注意力机制的这种局限性使得处理大规模数据变得困难和效率低下。
### Innovation
为了应对这一挑战，该研究引入了VRWKV-Editor视频编辑模型，该模型将一个线性空间-时间聚合模块整合到基于视频的扩散模型中。VRWKV-Editor模型利用RWKV变换器的双向加权键值循环机制，捕捉全局依赖关系同时保留时间连贯性，实现了线性复杂度而不会牺牲质量。扩展实验表明，相比于基于扩散的最新视频编辑方法，该方法在帧一致性和文本对齐上保持了竞争力，分别实现了最高3.7倍的加速和60%的内存使用量降低。此外，我们在不同序列长度的视频上进行的比较分析表明，与具有自我注意力的架构相比，我们方法的编辑速度差距随视频长度变长而不断扩大。
### Conclusion
研究展示了新型VRWKV-Editor模型的有效性，证明了该方法在保持高质量的同时，显著提高了视频编辑的速度和内存效率，特别是对于长时间的视频编辑任务有着显著的性能提升。
## 718. `cs.CV` - 等变分割：从不完整数据中进行自我监督学习 [PDF](https://arxiv.org/pdf/2510.00929), [HTML](https://arxiv.org/abs/2510.00929)
### Authors
Victor Sechaud,Jérémy Scanvic,Quentin Barthélemy,Patrice Abry,Julián Tachella
### Background
自我监督学习在逆问题中的应用可以从噪声和/或不完整数据中独立训练重建网络。这种方法在获取用于训练的真实参考数据成本高昂或根本不可能的情况下，有潜力实现基于学习的解决方案。本文中的背景是在只有一个不完整观测模型的情况下进行测量的情况，这是具有挑战性的环境。
### Innovation
提出了一个新的自我监督学习策略，专门设计用于通过单一不完整观测模型进行测量的情况。引入了重建网络中的新等变性定义，并展示了将自我监督分割损失与等变重建网络结合在一起的结果与监督损失的最小化期望结果相同。通过一系列实验（图像修复、加速磁共振成像和压缩传感），展示了所提出的损失在高度秩不足的前向模型中达到了最先进的性能。
### Conclusion
通过一系列实验，证明了提出的损失在高度秩不足的前向模型中达到了最先进的性能。这一新策略及其应用为在仅从不完整数据学习提供了一种有效的方法。
## 719. `cs.CV` - 欧几里得之礼：通过几何代理任务提升视觉-语言模型的空间感知与推理能力 [PDF](https://arxiv.org/pdf/2509.24473), [HTML](https://arxiv.org/abs/2509.24473)
### Authors
Shijie Lian,Changti Wu,Laurence Tianruo Yang,Hang Yuan,Bin Yu,Lei Zhang,Kai Chen
### Background
空间智能涵盖了各种能力，如可视化和变形图形、心理旋转物体、判断相对位置和包含关系以及估计数量。然而，对于多模态大型语言模型（MLLMs）来说，解决欧几里得几何问题仍然是一项关键的未解决问题。为了填补这一差距，本文提出了将欧几里得几何问题解决作为替代任务的方法。具体来说，研究者精心构建了一个包含约30,000个平面和立体几何问题的多模态数据集Euclid30K。通过使用Group Relative Policy Optimization (GRPO)对该数据集进行微调，使得模型可以从几何问题中学习和应用欧几里得原理，识别形状、计数和关联实体，并使用欧几里得原理进行多步演绎推理。
### Innovation
本文提出了一个创新的数据集Euclid30K和一种新的方法——Group Relative Policy Optimization (GRPO)，用于微调视觉-语言模型。通过这种方法，模型在空间推理基准测试（Super-CLEVR, Omni3DBench, VSI-Bench和MindCube）中的零样本性能显著提升，特别地，在VSI-Bench基准测试中，使用Euclid30K训练的模型平均准确率提高了5.5个百分点。RoboBrain2.0-Euclid-7B达到了49.6%的准确率，超过了之前的最佳模型。这是首次系统地证明了以几何为中心的微调能够赋予视觉-语言模型广泛迁移的空间技能。
### Conclusion
实验表明，经过Euclid30K训练的模型在四个空间推理基准测试中的零样本性能显著提升，没有特定任务的调整。罗博脑2.0-Euclid-7B在VSI-Bench基准测试中的准确率提高了5.5个百分点，达到49.6%，超过了之前的最佳模型。这是首次证明几何为中心的微调能够赋予视觉-语言模型广泛迁移的空间技能。代码和Euclid30K数据集可以在相应链接中找到。
## 720. `cs.CV` - NeRAF: 3D场景融合神经辐射与声学场 [PDF](https://arxiv.org/pdf/2405.18213), [HTML](https://arxiv.org/abs/2405.18213)
### Authors
Amandine Brunetto,Sascha Hornauer,Fabien Moutarde
### Background
声音在人类感知中扮演着重要角色，与视觉一起提供理解周围环境的关键信息。尽管在神经隐式表示方面取得了进展，但通过视觉场景学习一致的声学特征仍然具有挑战性。
### Innovation
提出了一种名为NeRAF的方法，该方法能联合学习声学场和辐射场。NeRAF可以通过辐射场的3D场景几何和外观先验来条件化声学场，从而生成新的视角和空间化的房间脉冲响应（RIR），并且每个模态可以独立渲染，并在不同的空间位置生成，提供更大的灵活性。
### Conclusion
在SoundSpaces和RAF数据集上，NeRAF生成了高质量的音频，相比之前的模型性能有了显著提高，同时数据效率更高。此外，NeRAF通过跨模态学习增强了使用稀疏数据训练的复杂场景的新视角合成。NeRAF被设计为Nerfstudio模块，为真实的音频-视觉生成提供了方便的访问。
## 721. `cs.CV` - 基于全景图像和基于课程学习损失函数的层次化地点识别 [PDF](https://arxiv.org/pdf/2404.14117), [HTML](https://arxiv.org/abs/2404.14117)
### Authors
Marcos Alfaro,Juan José Cabrera,María Flores,Óscar Reinoso,Luis Payá
### Background
移动机器人安全导航的关键技术之一是视觉地点识别(VPR)，当前方法多依赖于传统的对比损失函数，但在复杂感知条件下的识别效果有限，本文通过引入全景图像和深度学习模型，并结合课程学习策略，提出了新的损失函数，以提高VPR的性能和鲁棒性。
### Innovation
提出了基于课程学习的三元组损失函数，该方法通过在训练过程中逐步呈现更具挑战性的样本，使得模型能够学习到更具判别性和稳健性的特征表示，从而克服了传统对比损失函数的局限性。
### Conclusion
实验结果表明基于课程学习的三元组损失函数方法在复杂光照变化、动态视觉效果（如噪声和遮挡）以及有限训练数据等真实操作条件下，与常见的VPR方法相比具有竞争力，能获得高识别精度，展示了其在真实机器人应用中的可靠性和潜力。
## 722. `cs.CV` - SoftCFG: Uncertainty-guided Stable Guidance for Visual Autoregressive Model [PDF](https://arxiv.org/pdf/2510.00996), [HTML](https://arxiv.org/abs/2510.00996)
### Authors
Dongli Xu,Aleksei Tiulpin,Matthew B. Blaschko
### Background
自回归（AR）模型通过将图像表示为离散标记序列，已成为图像生成的强大工具。然而，尽管已经采用分类器无指导（Classifier-Free Guidance, CFG）来改进图像生成的条件生成，但在AR模型中的应用却遇到两个关键挑战：指导减弱（guidance diminishing），即随着解码过程的进行，条件和无条件之间的差距快速消失；以及过指导（over-guidance），即强烈的条件指导会破坏视觉连贯性。
### Innovation
我们提出了一种名为SoftCFG的方法，这是一种基于不确定性指导的推理方法，能够适应性地在所有序列中的标记中分布扰动。SoftCFG的关键思想是让生成的每个标记以加权的指导贡献其所能提供的确定性，确保生成过程中的信号持续存在，并妥善解决文本指导和视觉上下文之间的冲突。为了进一步稳定长序列生成，我们引入了一种分步归一化（Step Normalization）方法，它将SoftCFG累积扰动进行限制。SoftCFG是一种无需训练、模型通用的技术方法，能够无缝集成到现有的AR管道中。
### Conclusion
实验结果表明，SoftCFG在图像质量上显著优于标准的CFG方法，在ImageNet 256*256图像上取得了最佳FID性能。
## 723. `cs.CV` - 单元投影子空间剪枝 [PDF](https://arxiv.org/pdf/2405.17506), [HTML](https://arxiv.org/abs/2405.17506)
### Authors
Joshua Offergeld,Marcel van Gerven,Nasir Ahmad
### Background
随着AI模型的商业应用日益增多，提高神经网络推理效率变得至关重要。剪枝技术通过移除神经网络中的计算单元（如神经元、滤波器、注意力头或整层），显著减少了推理时间，同时保持网络性能。现有剪枝方法通常涉及将计算单元投影到一个正交子空间，在这个子空间内，不存在冗余活动，剪枝节点时可以恢复丢失单元的影响。这种方法还可以优化单元正交化的顺序，以最大化根据冗余程度对单元进行排序。
### Innovation
本研究提出了一种将单元激活投影到无冗余活动的正交子空间的方法，在该子空间中可以同时剪枝节点并恢复丢失单元的影响，通过线性最小二乘法。此外，可以根据单元激活在子空间中的相对规模自动确定逐层剪枝比例，类似于累积方差。这种方法在ImageNet训练的VGG-16、ResNet-50和DeiT模型上达到了或超过了最先进的剪枝结果，相比其他方法具有最高的计算效率，甚至低至24倍。此外，该方法还可以应用于OPT大语言模型，并在性能上超过了竞品方法。
### Conclusion
本研究提出了一种新的剪枝方法，通过将单元激活投影到无冗余活动的正交子空间来实现剪枝，这种方法在多种模型上取得了显著效果，并且具有高效性。
## 724. `cs.CV` - 基于视觉的Hannes假肢连续腕部控制：一种共享自主框架 [PDF](https://arxiv.org/pdf/2502.17265), [HTML](https://arxiv.org/abs/2502.17265)
### Authors
Federico Vasile,Elisa Maiettini,Giulia Pasquale,Nicolò Boccardo,Lorenzo Natale
### Background
大多数假肢抓握控制技术主要关注灵巧手指的控制，但忽视了腕部运动。这迫使用户通过肘部、肩部和髋部进行补偿运动以适应腕部的抓握动作。该论文介绍了一种基于计算机视觉的系统，该系统利用用户与自动系统的协作，在共享自主框架中对假肢腕部的自由度进行连续控制，以实现更自然的接近抓取动作。这项技术允许无缝控制假肢腕部以跟踪目标对象，并最终根据用户意图对其进行定向以便抓取。
### Innovation
提出了一种基于计算机视觉的系统，该系统利用用户的协作和自动系统的自动性，在共享自主框架中对假肢腕部的自由度进行连续控制，促进更自然的接近抓取动作。评估方法包括定量分析，最终在Hannes假肢上应用了该方法。
### Conclusion
该研究开发了一种新的控制技术，通过基于视觉的方法实现对假肢腕部的连续控制，从而增强假肢用户的抓取自然性和效率。通过定量评估和实际部署在Hannes假肢上的方法验证了系统的有效性。
## 725. `cs.CV` - 特征表示向轻量级模型的转移通过感知一致性 [PDF](https://arxiv.org/pdf/2505.06595), [HTML](https://arxiv.org/abs/2505.06595)
### Authors
Hai-Vy Nguyen,Fabrice Gamboa,Sixin Zhang,Reda Chhaibi,Serge Gratton,Thierry Giaccone
### Background
本文提出了一种从大型教师模型向轻量级学生模型转移特征表示的方法。背景包括介绍了教师模型和学生模型之间的差异，教师模型具有更强的表征能力，而学生模型需要更有效的学习方式来模仿教师模型的特征感知机制。
### Innovation
提出了一个新的概念叫作‘感知一致性’（perception coherence），并基于此提出了一个新的损失函数。这个损失函数通过特征空间中数据点之间的排名来考虑它们之间的差异。该方法旨在让学生模型模仿教师模型如何感知输入，特别是在学生模型表征能力较弱的情况下，通过保留全局一致性的相似性排名而非绝对几何结构来实现更好的放松。
### Conclusion
实验结果表明，该方法在特征表示转移方面优于或与强基准方法持平。其理论见解为特征表示转移过程提供了概率视角。
## 726. `cs.CV` - SUPER-Net: 通过编码器-解码器网络中的不确定性传播实现可靠的图像分割 [PDF](https://arxiv.org/pdf/2111.05978), [HTML](https://arxiv.org/abs/2111.05978)
### Authors
Giuseppina Carannante,Nidhal C.Bouaynaya,Dimah Dera,Hassan M. Fathallah-Shaykh,Ghulam Rasool
### Background
深度学习（DL）因其精确性、高效性和客观性，在重塑行业方面充满潜力。然而，DL模型对噪音和分布外输入的脆弱性限制了其在敏感领域中的部署。当前模型通常缺乏不确定性量化能力，仅提供点估计。在MRI和CT影像等医学成像领域，可靠性和准确性至关重要，特别是在存在噪音和对抗性攻击时。
### Innovation
本文提出了一种贝叶斯框架SUPER-Net，用于通过不确定性传播实现可信的图像分割。超级网络使用泰勒级数近似，在非线性层上传播模型后验分布的均值和协方差。它同时生成两个输出：分割图像和像素级别的不确定性图，从而消除昂贵的蒙特卡洛采样需求。在MRI和CT扫描等各种噪音和对抗性条件下，SUPER-Net的性能得到了广泛评估，结果显示其在鲁棒性和准确性方面优于现有的最先进模型。不确定性图可以识别受到噪音或攻击影响的低置信度区域，使模型能够自我评估分割可靠性，尤其是在错误源自噪音或对抗性样本时。
### Conclusion
SUPER-Net 在鲁棒性和准确性方面显著优于现有模型。不确定性图有助于识别受噪音或攻击影响的低置信度区域，使模型能够自我评估分割可靠性。
## 727. `cs.CV` - Momentum-SAM: Sharpness Aware Minimization without Computational Overhead [PDF](https://arxiv.org/pdf/2401.12033), [HTML](https://arxiv.org/abs/2401.12033)
### Authors
Marlon Becker,Frederick Altrock,Benjamin Risse
### Background
最近提出的优化算法Sharpness Aware Minimization (SAM) 在进行梯度计算前通过梯度上升步骤扰动参数，引导优化进入损失平缓的参数空间区域，能够显著提升泛化能力，减少过拟合风险，但同时也导致计算成本翻倍，使得在计算资源受限的情况下不可行。基于Nesterov加速梯度（NAG）算法，本文提出了Momentum-SAM (MSAM)，该算法通过扰动参数方向的累积动量向量来实现低尖锐度而无需显著增加计算开销或内存需求，即基于SGD或Adam的优化方法。
### Innovation
本文提出了Momentum-SAM (MSAM)，这是一种在不需要显著增加计算开销或内存需求的情况下，通过扰动参数方向的累积动量向量来实现低尖锐度的优化算法，兼容于SGD或Adam。进一步，本文深入评估了MSAM，并揭示了NAG、SAM和MSAM在训练优化和泛化机制上的不同之处。
### Conclusion
Momentum-SAM算法通过利用累积动量向量来实现降低参数尖锐度的目标，而不带来显著的计算或内存负担，这使得它在资源受限的环境中更具可行性和效率。同时，对于NAG、SAM和MSAM的工作机制，本文也提供了一些新的见解，帮助更好地理解这些方法在训练优化和泛化性能方面的影响。
## 728. `cs.CV` - 高音视频语言建模与潜在空间扩展相结合以增强高质量数据扩增 [PDF](https://arxiv.org/pdf/2503.17551), [HTML](https://arxiv.org/abs/2503.17551)
### Authors
Yu Sun,Yin Li,Ruixiao Sun,Chunhui Liu,Fangming Zhou,Ze Jin,Linjie Wang,Xiang Shen,Zhuolin Hao,Hongyu Xiong
### Background
基于Transformer的多模态模型在工业规模的推荐、搜索和广告系统中广泛用于内容理解和相关性排名。提高标记训练数据质量和跨模态融合显著改善了模型性能，影响了诸如高质量观看率和广告收入等关键指标。高质量的注释对内容建模至关重要，但传统基于统计的主动学习（AL）方法存在局限性：它们难以检测过度自信的误分类，并且在区分深度神经网络中的语义相似项方面效果不佳。此外，在短视频平台上，音频信息的作用日益增强，但大多数预训练多模态架构主要侧重于文本和图像。尽管可以从所有三种模态进行从头训练，但这样会牺牲利用现有预训练视觉语言（VL）和音频模型的好处。
### Innovation
本文提出了一种基于kNN的潜在空间扩展（LSB）来增强主动学习效率，并提出了音频增强的视觉语言建模（VLMAE），这是一种中间融合方法，将音频集成到VL模型中。该系统已在生产系统中部署，带来了显著的业务收益。
### Conclusion
该系统通过提升AL效率和结合音频信息到VL模型中，解决了高质量数据扩增的问题，展示了在实际应用中的显著效果。
## 729. `cs.CV` - Time Series Analysis 如何从多种模态中获益？- 一个综述与展望 [PDF](https://arxiv.org/pdf/2503.11835), [HTML](https://arxiv.org/abs/2503.11835)
### Authors
Haoxin Liu,Harshavardhan Kamarthi,Zhiyuan Zhao,Shangqing Xu,Shiyu Wang,Qingsong Wen,Tom Hartvigsen,Fei Wang,B. Aditya Prakash
### Background
时间序列分析 (TSA) 是数据挖掘领域的一个长期研究课题，具有广泛的现实意义。相比语言和视觉等“更为丰富”的模态，近年来取得了爆炸性发展并紧密相连，时间序列模态仍相对未被充分探索和孤立。许多近期的 TSA 研究形成了一门新的研究领域，即多模态时间序列分析（MM4TSA）。这些 MM4TSA 研究通常关注 TSA 如何从多模态中获益。本文是首次全面回顾和展望这一新兴领域的综述。
### Innovation
本文是首次全面回顾和展望多模态时间序列分析领域的综述。具体来说，系统地讨论了三种好处：（1）利用其他模态的基础模型进行有效的 TSA；（2）通过多模态扩展增强 TSA；（3）通过跨模态交互实现高级 TSA。还通过引入的不同模态类型对研究工作进行了分类，包括文本、图像、音频、表格和其他模态。同时，文章识别了未来机会，分别为以上三种好处对应选择了重新使用的模态选择、异构模态组合和未见过任务的一般化。 
### Conclusion
最终，文章指出了未来的机会，包括重新使用的模态选择、异构模态组合和未见过任务的一般化，对应前三种好处进行了识别。并发布了一个包含关键论文和资源的更新 GitHub 仓库。
## 730. `cs.CV` - 学习为训练数据属性学习参数权重 [PDF](https://arxiv.org/pdf/2506.05647), [HTML](https://arxiv.org/abs/2506.05647)
### Authors
Shuangqi Li,Hieu Le,Jingyi Xu,Mathieu Salzmann
### Background
现有的基于梯度的数据归因方法要么将网络参数看作是均匀的，要么依赖于Hessian近似的隐式加权，这不足以充分建模网络参数的功能异质性。因此，需要一种新方法来直接从数据中学习参数的重要性权重，而无需注释标签。
### Innovation
提出了一种方法，直接从数据中学习参数的重要性权重，而不需要注释标签。这种方法能够提高不同类型任务（包括图像分类、语言建模和扩散）的归因准确性，并使得可以进行细粒度的概念归因，如主题和风格的归因。
### Conclusion
该研究通过提高不同任务类型的归因准确性和实现概念级别的精细归因，提供了一种创新的方法，直接从数据中学习参数权重，不需要标签数据。
## 731. `cs.CV` - NeoARCADE：为视障人士支持辅助无人机的距离估计稳健校准 [PDF](https://arxiv.org/pdf/2504.01988), [HTML](https://arxiv.org/abs/2504.01988)
### Authors
Suman Raj,Bhavani A Madhabhavi,Madhav Kumar,Prabhav Gupta,Yogesh Simmhan
### Background
无人机自主导航，结合深度学习和计算视觉算法，正在影响多个领域。本文探讨了无人机如何自主跟随和辅助视障人士在城市环境中导航。这是通过估计无人机与视障人士及其周围物体之间的绝对距离来实现的，以设计障碍物避让算法。本文研究了利用单目视频流中的深度图来估计与视障人士和其他障碍物之间的绝对距离的技术。
### Innovation
本文提出了NeoARCADE（Neo），一种基于深度得分标准化和系数估计的稳健校准技术，将深度图中的相对距离转换为绝对距离。此外，开发了一种动态校准方法以适应不同的场景变化。为了验证Neo的稳健性和通用性，开发了回归和几何两种基线模型，并使用校园环境下的数据集对Neo与其他最新的深度图方法进行了详细的评估。
### Conclusion
Neo能够将视障人士的距离误差控制在30厘米以内，对不同障碍物（如汽车和自行车）的距离误差在60厘米以内，其性能优于基线模型和最先进的深度图方法，误差率分别低5.3到14.6倍。
## 732. `cs.CV` - Poutine: 视觉-语言-轨迹预训练和强化学习后训练实现稳健端到端自动驾驶 [PDF](https://arxiv.org/pdf/2506.11234), [HTML](https://arxiv.org/abs/2506.11234)
### Authors
Luke Rowe,Rodrigue de Schaetzen,Roger Girgis,Christopher Pal,Liam Paull
### Background
在自动驾驶中维持良好的驾驶行为仍然是一项关键的挑战，尤其是在离分布场景下。一种有潜力的方向是利用大型语言模型的泛化知识和推理能力，将不寻常的驾驶场景视为逻辑推理任务。目前，实现这一目标的方法通常需要添加自定义的组件或人工设计的代令牌器，这限制了其广泛应用。
### Innovation
本文提出了Poutine方法，通过使用一个现成的3B参数大小的视语言模型（VLM），实现了一种简单且可扩展的端到端自动驾驶培训方案。具体创新点在于：1. 使用自监督下的视语言轨迹（VLT）令牌预测来训练强基础驾驶能力；2. 采用群体相对政策优化（GRPO）并结合少量的人类偏好标签示例来微调VLM；3. 验证了该方法在Waymo端到端驾驶基准上的效果，显著提高了自动驾驶的鲁棒性和通用性。
### Conclusion
实验结果显示，Poutine模型在测试集上的RFS评分达到7.99，远超其他竞争对手，在2025年Waymo视觉端到端自动驾驶挑战赛中名列前茅。该研究证明，不需要加入手工艺品代令牌器或自定义架构组件，也可以实现高度的驾驶性能。相反，这项工作强调了可扩展VLT预训练与轻量级RL微调结合的潜力，能够实现稳健和通用的自动驾驶。
## 733. `cs.CV` - UltraUPConvNet：一种基于UPerNet和ConvNeXt的多任务网络，用于超声组织分割和疾病预测 [PDF](https://arxiv.org/pdf/2509.11108), [HTML](https://arxiv.org/abs/2509.11108)
### Authors
Zhi Chen,Le Zhang
### Background
超声成像因其成本效益、便携性和安全性，广泛应用于临床实践中。然而，当前的AI研究通常将疾病预测和组织分割视为两个独立的任务，这导致其模型计算成本高。在这样的背景下，本文提出了UltraUPConvNet，一种计算成本效益高的通用框架，用于超声图像分类和分割，该框架在同一模型中结合了两个任务，解决了计算成本高的问题。
### Innovation
提出了UltraUPConvNet，一种基于UPerNet和ConvNeXt的多任务网络框架，能够同时进行超声图像分类和分割。该模型在包含超过9,700个注释的大规模数据集上进行训练，并在某些数据集上实现了最先进的性能，同时具有较低的计算成本。
### Conclusion
本文介绍的UltraUPConvNet在超声图像分类和分割方面都取得了显著的效果，模型训练使用了大规模数据集，相比传统的多任务模型，具有更低的计算成本和更高的性能。
## 734. `cs.CV` - Grasp Pre-shape Selection by Synthetic Training: Eye-in-hand Shared Control on the Hannes Prosthesis [PDF](https://arxiv.org/pdf/2203.09812), [HTML](https://arxiv.org/abs/2203.09812)
### Authors
Federico Vasile,Elisa Maiettini,Giulia Pasquale,Astrid Florio,Nicolò Boccardo,Lorenzo Natale
### Background
本文探讨了使用多抓取类型的手部假肢进行物体抓取的任务。在这种情况下，传达期望的抓取类型通常需要用户高度的认知负荷，通过采用共享自主性框架可以降低这种负荷。具体来说，‘眼在手中’系统可以在抓取前自动控制手部的形态预塑造，基于手腕处摄像头提供的视觉输入。
### Innovation
本文提出了一种基于学习的手部抓取前形态分类方法，用于处理可能需要不同抓取类型来抓取每个物体部分的情况。为了解决此类数据量不足的问题，本文设计了一条生成合成视觉手部轨迹序列的管线，并通过开发传感器化设备收集真实的人类抓取序列作为基准测试。经过训练后，与使用真实数据训练的模型相比，使用合成数据集训练的模型在实际应用案例中的泛化性能更好。最后，将模型集成到Hannes假肢上，并展示了其实用效果。
### Conclusion
本文的结果表明，基于合成数据集训练的模型在实际应用中表现出更好的泛化性能。作为最后的验证，该模型被集成到Hannes假肢上，并证明了其实用性。本文已将代码和数据集公开，以便再现本文的结果。
## 735. `cs.LG` - 控制温度：选择性采样以获得多样性和高质量的LLM输出 [PDF](https://arxiv.org/pdf/2510.01218), [HTML](https://arxiv.org/abs/2510.01218)
### Authors
Sergey Troshin,Wafaa Mohammed,Yan Meng,Christof Monz,Antske Fokkens,Vlad Niculae
### Background
多样性是评估语言模型生成输出的创新性的关键指标。温度控制的采样是增加多样性的常见策略。但在需要高精度的任务，例如数学推理中，不加控制地使用高温采样会导致推理质量下降。研究表明，这种准确性损失是由于在敏感解码位置采样错误的延续。
### Innovation
我们提出了一种名为选择性采样的方法，该方法基于采样风险度量动态地在贪婪采样和高温采样之间切换。为了预测采样风险，我们在一个可验证问题的小型子集上训练了一个轻量级分类器。训练好的分类器可以在最小的延迟开销下与基础语言模型集成。实验表明，选择性采样即使在高温设置下也能提高质量和多样性的权衡。
### Conclusion
选择性采样方法通过在敏感解码位置动态切换采样策略，能够在不牺牲准确性的情况下提高语言模型输出的多样性和质量，特别是在需要高精度的任务上表现更佳。
## 736. `cs.CV` - LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios [PDF](https://arxiv.org/pdf/2509.09926), [HTML](https://arxiv.org/abs/2509.09926)
### Authors
Zhiyuan Huang,Jiahao Chen,Yurou Liu,Bing Su
### Background
长尾学习在实际场景中具有广泛的适用性，而长尾半监督学习（LTSSL）方法通过将大量未标记数据纳入不平衡标签数据集中，已被证明是有效的解决方案。然而，大多数现有的LTSSL方法都是从零开始训练模型，这往往会导致过度自信和伪标签质量低下的问题。在开放世界条件下进行半监督学习时，未标记数据中可能包含分布外（OOD）样本，这需要更进一步的处理方法以增强模型的辨别能力。
### Innovation
提出了一个新颖的LoFT框架（长尾半监督学习通过参数高效微调），该框架将LTSSL扩展到基础模型微调范式中，能够生成更可靠的伪标签，有利于解决不平衡学习问题。此外，还提出了LoFT-OW（开放世界场景下的LoFT），以提高模型的辨别能力，从而处理未标记数据包含分布外样本的问题。实验结果显示，该方法在多个基准测试中表现出色，即使只使用之前工作的1%未标记数据也能取得更好的性能。
### Conclusion
实验结果表明，与先前的方法相比，我们的方法在多个基准测试中取得了更优的表现，即使只利用了之前工作1%的未标记数据。进一步地，我们验证了细调基础模型的方法在开放世界条件下的有效性。
## 737. `cs.LG` - 利用基于物理的时序预测加速长期分子动力学模拟 [PDF](https://arxiv.org/pdf/2510.01206), [HTML](https://arxiv.org/abs/2510.01206)
### Authors
Hung Le,Sherif Abbas,Minh Hoang Nguyen,Van Dai Do,Huu Hiep Nguyen,Dung Nguyen
### Background
高效的分子动力学（MD）模拟对于理解材料科学和生物物理学中的原子级过程至关重要。传统的密度泛函理论（DFT）方法计算成本高昂，限制了长期模拟的可行性。
### Innovation
该研究提出了一种新颖的方法，即将MD模拟视为时序预测问题，允许先进的预测模型通过预测位移而非绝对位置来预测原子轨迹。该方法引入了一个基于DFT参数化的摩尔势函数的物理信息损失和推理机制，以惩罚不合理的原子邻近度并确保物理合理性。该方法在各种材料中的一致性上显著优于标准基线，在模拟准确性上取得了突破。
### Conclusion
结果强调了融入物理知识以提高原子轨迹预测可靠性和精确度的重要性。该方法能够在几分钟内稳定地建模数千个MD步骤，提供了比昂贵的DFT模拟更具扩展性的替代方案。
## 738. `cs.CV` - 开发家庭分析视网膜底片图像的移动应用 [PDF](https://arxiv.org/pdf/2509.16814), [HTML](https://arxiv.org/abs/2509.16814)
### Authors
Mattea Reid,Zuhairah Zainal,Khaing Zin Than,Danielle Chan,Jonathan Chan
### Background
机器学习正逐渐成为医学成像领域中的一种诊断工具，尤其是在视网膜底片图像的分析中得到了广泛应用。然而，这一方法尚未在临床上广泛应用，因为它仍然依赖于专业人员的人工验证。本文旨在设计一个移动应用程序，以监测与年龄相关病症相关的视网膜底片图像指标，通过观察这些指标随时间的变化提供早期视力疾病洞察，并提供监控与年龄相关条件相关的视网膜底片图像的趋势或变化的可能性，用户可以定期上传照片进行监测
### Innovation
本平台利用机器学习模型来分析视网膜底片图像中的血管曲度、青光眼、视网膜病变和黄斑水肿等指标。通过比较训练在Messidor数据集和MAPLES-DR数据集上的模型，结合使用DeepSeeNet青光眼检测模型和曲度计算，构建了一个视网膜底片图像监测平台。这使得用户可以定期上传照片进行监测，而无需直观地进行诊断，从而实现早期发现潜在的眼部疾病的监控功能
### Conclusion
最终移动应用允许可信赖的视网膜底片图像指标变化趋势监测，通过定期上传照片，提供早期预警功能，无需专业人员验证即可进行初步监控和提示眼部健康状况的变化。
## 739. `cs.CV` - AniMaker：基于MCTS驱动片段生成的多智能体动画叙述 [PDF](https://arxiv.org/pdf/2506.10540), [HTML](https://arxiv.org/abs/2506.10540)
### Authors
Haoyuan Shi,Yunxin Li,Xinyu Chen,Longyue Wang,Baotian Hu,Min Zhang
### Background
尽管视频生成模型取得了快速进步，但生成涵盖了多个场景和角色的连贯叙述视频仍然具有挑战性。当前的方法通常会将预先生成的关键帧僵化地转换为固定长度的片段，导致叙述不连贯和节奏问题。此外，视频生成模型的固有不稳定性意味着单个低质量片段可以显著损害整个输出动画的逻辑连贯性和视觉连续性。为了解决这些问题，我们介绍了AniMaker，一个多智能体框架，能够高效地生成多种候选片段并具备故事叙述感知的片段选取功能，从而仅通过文本输入生成全局一致和故事连贯的动画。
### Innovation
AniMaker 的创新之处在于引入了两个关键技术组件：Photography Agent 中的 MCTS-Gen，这是一种受Monte Carlo树搜索（MCTS）启发、高效智能地导航候选空间生成高潜力片段并优化资源使用的技术；以及Reviewer Agent中的AniEval，这是第一个专门为多镜头动画评估设计的框架，通过考虑每个片段及其前后片段的上下文来评估关键方面，如故事层面的一致性、动作完成和动画特定特征。实验表明，AniMaker在流行的度量标准如VBench和我们提出的AniEval框架中实现了更高的质量，同时显著提高了多候选片段生成的效率，将AI生成的叙述动画推向了生产标准的边缘。
### Conclusion
AniMaker的成功实施解决了生成连贯叙述视频和动画故事的主要挑战，通过高效的多智能体框架实现了高质量和连贯的动画生成，未来有望进一步优化和应用于更多场景。
## 740. `cs.LG` - 基于LLM的AI代理自动提取材料属性 [PDF](https://arxiv.org/pdf/2510.01235), [HTML](https://arxiv.org/abs/2510.01235)
### Authors
Subham Ghosh,Abhishek Tewari
### Background
材料快速发现受限于缺乏能够将性能指标与结构上下文结合的大规模、机器可读数据集。现有数据库要么规模小、手工整理，要么偏向于第一性原理结果，导致实验文献尚未充分开发利用。
### Innovation
本文提出了一种自主的、以大型语言模型（LLM）驱动的工作流，能够自动从大约10,000篇全文科学文章中提取热电和结构属性。该流程结合动态标记分配、零样本多代理提取以及条件表解析来平衡准确性和计算成本。该工作流在50篇委托验证的论文中进行基准测试，结果显示GPT-4.1在热电属性提取上的准确率达到F1 = 0.91，在结构域上的准确率达到F1 = 0.82，而GPT-4.1 Mini的成本仅为前者的几分之一，表现出近乎相等的性能，使其适用于大规模部署。应用此工作流，作者整理了27,822条带规范单位的温度解耦性能记录，涵盖了ZT、Seebeck系数、电导率、电阻率、功率因子和热导率，同时包括晶体类、空间群和掺杂策略等结构属性。数据分析再现了已知的热电趋势，并揭示了更广泛的结构-性能相关性。为了促进社区访问，作者发布了具有语义过滤、数值查询和CSV导出功能的交互式网络探索工具。
### Conclusion
本文提供了目前最大的基于LLM的热电材料数据库，提供了一个可重复且成本可控的数据提取流程，并为材料发现的规模化、数据驱动研究奠定了基础。
## 741. `cs.LG` - RSAVQ: 盐度感知Riemannian向量量化方法在大规模语言模型中的应用 [PDF](https://arxiv.org/pdf/2510.01240), [HTML](https://arxiv.org/abs/2510.01240)
### Authors
Zukang Xu,Xing Hu,Qiang Wu,Dawei Yang
### Background
大规模语言模型（LLMs）在多种自然语言处理任务中表现出色，但它们的参数量呈指数增长，这给在资源受限设备上的部署带来了巨大挑战。当前已有研究表明，向量量化（VQ）在低比特量化（如2至4比特）方面具有很大潜力，但现有工作中仍存在两个关键挑战：未经约束的方向误差和亚最优的比特分配。因此，本文提出了RSAVQ（Riemannian Sensitivity-Aware Vector Quantization），这是一种新颖的VQ框架，专门针对LLMs的极低比特量化进行增强。
### Innovation
RSAVQ引入了两项基于几何学驱动的创新，有效地缓解了上述限制：(1) 错误方向敏感性指导（EDSG）：通过利用Fisher信息矩阵（FIM）诱导的黎曼度量来将量化误差投影到参数空间中的低敏感方向上。具体来说，此投影沿着负自然梯度方向进行，有效抑制了误差的扩展。(2) 权重信道敏感性指导（WCSG）：通过FIM曲率分析构建通道级别敏感性指标，以动态地指导比特资源分配。这种方法能够在给定的比特限制内实现最优量化解决方案。实验结果表明，在2比特量化的LLaMA-3 8B中，RSAVQ在困惑度（PPL）和零样本准确性两项指标上分别领先于VPTQ和QuIP#方法0.4和1.5。
### Conclusion
这项工作提供了一种适用于受限环境的实用方案，并在信息几何学与神经网络量化之间建立了理论桥梁，推动了高效深度学习的发展。
## 742. `cs.LG` - RSTGCN：面向铁路的时空图卷积网络在列车延误预测中的应用 [PDF](https://arxiv.org/pdf/2510.01262), [HTML](https://arxiv.org/abs/2510.01262)
### Authors
Koyena Chowdhury,Paramita Koley,Abhijnan Chakraborty,Saptarshi Ghosh
### Background
准确预测列车延误对于高效铁路运营至关重要，这有助于做出更好的调度和管理决策。早期的研究主要集中在预测单个列车的具体延误时间，但最近的研究开始探索以车站为单位的延误预测，以支持更高层次的交通管理。现有方法面临预测性能的挑战，尤其是对于大规模铁路网络中的平均到达延迟预测。
### Innovation
我们提出了面向铁路的时空图卷积网络（RSTGCN），该网络旨在预测特定时间段内所有进入车站的列车平均到达延误。该方法包括了几个架构创新和新颖的特征整合，如列车频率感知的空间注意力机制，这显著提升了预测性能。此外，我们还编制并发布了印度铁路网络的全面数据集，涵盖4,735个车站，17个区域，这是迄今为止最大和最多样化的铁路网络数据集。
### Conclusion
我们的工作不仅在大尺度铁路网络的平均延迟预测建模上取得了进展，并且提供了开放数据集以鼓励进一步研究这个关键领域。实验结果表明，在多个最先进的基准模型下，我们的方法在标准指标上持续取得了改进。
## 743. `cs.LG` - Budgeted Broadcast: 一种基于活动量的神经网络效率剪枝规则 [PDF](https://arxiv.org/pdf/2510.01263), [HTML](https://arxiv.org/abs/2510.01263)
### Authors
Yaron Meirovitch,Fuming Yang,Jeff Lichtman,Nir Shavit
### Background
大多数剪枝方法是基于对损失影响的参数（如幅度或梯度）进行排名来移除参数。该论文提出了Budgeted Broadcast (BB)，每次给每个单元分配一个本地流量预算（长时间上的活动率$a_i$与扇出$k_i$的乘积）。该方法通过约束-熵分析，保证在全局流量预算约束下最大化编码熵，从而在选择性与受众之间找到平衡。BB使用简单的本地化机制来修剪模型的入度（降低活动量）或出度（减少广播），从而在稀疏度匹配的情况下，提高了Transformer、ResNets和3D U-Nets等多个神经网络模型在ASR、面部识别和突触预测任务上的准确度，甚至在某些情况下超过了密集基线。
### Innovation
BB方法通过分配每个单元一个本地流量预算，结合约束-熵分析来实现选择性与受众的平衡，从而在保持模型准确性的同时减少冗余参数。该方法能简单有效地控制模型的入度和出度，使得模型在稀疏参数的情况下仍能保持高效。
### Conclusion
BB方法在各种神经网络模型上表现出色，提高了模型的准确性，有时甚至超越了密集基线。该方法在电镜图像上达到了最先进的F1和PR-AUC性能，且易于集成。它为学习更加多样且高效的表示提供了可能的路径。
## 744. `cs.LG` - IsaacLab中可扩展的异构多智能体对抗强化学习框架 [PDF](https://arxiv.org/pdf/2510.01264), [HTML](https://arxiv.org/abs/2510.01264)
### Authors
Isaac Peterson,Christopher Allred,Jacob Morrey,Mario Harper
### Background
多智能体强化学习（MARL）在动态环境中协作的机器人系统中起着核心作用。尽管早期的工作主要关注协作场景，但对抗性互动对于现实世界的应用同样重要，如追逐-逃避、安全和竞争操控。已有研究集中在协作设置，但没有专门针对对抗性交互的训练框架。
### Innovation
该工作扩展了IsaacLab框架以支持在高保真物理模拟中高效训练对抗性策略。提出了一套对抗性MARL环境，涵盖具有异构目标与能力的多智能体。平台结合了竞争异构智能体强化学习和近端策略优化（HAPPO），实现了对抗性动态下的高效训练和评估。多个基准场景的实验展示了该框架能够模拟和训练适应性多智能体竞争策略，同时保持高吞吐量和模拟真实性。
### Conclusion
该框架成功扩展了IsaacLab用于对抗性多智能体系统的支持，并通过多智能体合作与竞争的高效训练和评估展示了其实用性。
## 745. `cs.LG` - Noisy-Pair Robust Representation Alignment for Positive-Unlabeled Learning [PDF](https://arxiv.org/pdf/2510.01278), [HTML](https://arxiv.org/abs/2510.01278)
### Authors
Hengwei Zhao,Zhengzhong Tu,Zhuo Zheng,Wei Wang,Junjue Wang,Rusty Feagin,Wenzhe Jiao
### Background
PU学习旨在训练一个二分类器（正样本 vs. 负样本），其中只有限定的正样本数据和大量的未标记数据可用。尽管PU学习方法在各种场景中广泛适用，但它们在复杂数据集上的性能远低于监督学习方法，尤其是在没有辅助负样本或预估参数的情况下（例如，CIFAR-100数据集上的14.26%差距）。主要瓶颈在于在不可靠的监督下学习判别性表示的挑战。
### Innovation
NcPU提出了一种非对比的PU学习框架，无需辅助信息，结合了噪声对稳健的监督非对比损失（NoiSNCL）和基于遗憾的标签更新的虚标签消歧（PLD）方案。NoiSNCL使无标签数据中的同类别表示对齐，即使监督不可靠，而PLD通过保守的负监督为NoiSNCL提供支持。理论上，NoiSNCL和PLD可以从期望最大化框架的角度互相受益。实验结果显示NoiSNCL使简单PU方法达到了竞争性性能，而NcPU在多种数据集上都超过了最先进的PU方法，尤其在灾害后建筑物损坏映射等具有挑战性的数据集上。
### Conclusion
广泛的实验表明，NoiSNCL会让简单的PU方法实现较强的竞争表现；而NcPU在多个数据集上实现了显著的性能提升，尤其是针对具有挑战性的数据集，突显了其在实际应用中的潜力。代码将在审核后开源。
## 746. `cs.LG` - 通过信任感知深度Q网络实现联邦学习防护的自适应策略 [PDF](https://arxiv.org/pdf/2510.01261), [HTML](https://arxiv.org/abs/2510.01261)
### Authors
Vedant Palit
### Background
联邦学习在部分可见性下容易受到中毒攻击和后门攻击的影响，这对整体模型的安全性和鲁棒性构成了挑战。现有防御方法需要在准确性和鲁棒性之间做出权衡，而缺乏对客户端信任的有效建模和持续更新机制。 
### Innovation
论文提出了一种信托感知的深度Q网络，该网络结合了多信号证据来更新客户端的信任，同时优化长期稳健性和准确性的目标。这种方法创新地将信任机制与深度学习模型相结合，以更好地抵御联邦学习中的攻击。此外，还在不同场景下验证了其在准确性和鲁棒性方面的优势。
### Conclusion
实验结果表明，提出的基于信任感知的深度Q网络在CIFAR-10数据集上不仅能够保持稳定的准确率，还能够减少受攻击风险。具体表现为：(i) 在吞吐量更高的情况下提升准确率；(ii) 减少误杀率并保持检测稳定性；(iii) 随着可见性的减少，性能指标依然保持稳定，突出了顺序信念更新在处理较弱信号时的优势。相比随机、线性Q和策略梯度控制器，DQN获得了最优的鲁棒性-准确性的权衡。
## 747. `cs.CV` - HAMLET: 转化你的视觉-语言-动作模型为具有历史感知的策略 [PDF](https://arxiv.org/pdf/2510.00695), [HTML](https://arxiv.org/abs/2510.00695)
### Authors
Myungkyu Koo,Daewon Choi,Taeyoung Kim,Kyungmin Lee,Changyeon Kim,Younggyo Seo,Jinwoo Shin
### Background
现有的视觉-语言-动作模型（VLAs）大多未考虑任务历史依赖性，仅依赖于当前观察而忽略了先前的上下文信息。这限制了它们在需要依赖历史信息的任务中的表现，特别是长期任务。
### Innovation
本文提出了HAMLET，这是一种可扩展的框架，能够使VLAs在执行动作预测时关注历史上下文。通过引入紧凑的时刻标记（moment tokens）来编码连续时间点的感知信息，并利用时间对比学习初始化其表示，使其能够更好地捕捉时间上的差异性特征。此外，HAMLET还采用了一个轻量级的记忆模块，该模块将过去的时刻标记整合到记忆特征中，这些特征用于动作预测。研究表明，HAMLET能够显著提高与历史信息相关的任务表现，尤其是长期任务。
### Conclusion
实验结果表明，HAMLET成功地将一种领先的VLAs转换为具有历史感知的策略，特别是在需要历史上下文的长期任务中表现出色。具体而言，与基线相比，HAMLET在历史依赖的现实任务中取得了76.4%的平均成功率，而之前的基线仅为47.2%。同时，HAMLET还在RoboCasa Kitchen和LIBERO等基准上超过或显著提升已有技术的性能。
## 748. `cs.LG` - RLP: 将强化学习作为预训练目标 [PDF](https://arxiv.org/pdf/2510.01265), [HTML](https://arxiv.org/abs/2510.01265)
### Authors
Ali Hatamizadeh,Syeda Nahida Akter,Shrimai Prabhumoye,Jan Kautz,Mostofa Patwary,Mohammad Shoeybi,Bryan Catanzaro,Yejin Choi
### Background
大型推理模型的训练主要依赖于next-token预测损失的预训练，再到监督微调和强化学习的后训练阶段。尽管这种方法很有效，但论文质疑这是否是最佳训练方法。因此，提出了一种新的预训练目标——RLP，旨在引入强化学习的核心精神——探索，在预训练的最后一阶段使用这种目标。
### Innovation
RLP 是一种基于信息增益的强化预训练目标，它将思维过程视为一种探索性动作，奖励基于它对未来token预测的信息增益。这种方法提供了一种无需验证器的密集奖励信号，在预训练期间可以高效地训练整个文档流。RLP 将强化学习与普通文本预训练任务联系起来，填补了从next-token预测到生成有用的思维链的空白。使用 RLP 预训练 Qwen3-1.7B-Base 模型，在八项数学和科学基准测试中提高了平均分 19%；应用到混合模型 Nemotron-Nano-12B-v2 中，提高了科学推理平均分 23%，展示了其在不同架构和模型规模中的可扩展性。
### Conclusion
RLP 方法通过在预训练阶段引入增强学习的探索机制，提前培养模型的独立思考能力。这种方法在多个模型和任务上取得了显著提升，证明了其有效性和实用性。
## 749. `cs.LG` - 从2D到3D，基于深度学习的磁共振成像形状重建：综述 [PDF](https://arxiv.org/pdf/2510.01296), [HTML](https://arxiv.org/abs/2510.01296)
### Authors
Emma McMillian,Abhirup Banerjee,Alfonso Bueno-Orovio
### Background
基于深度学习的三维（3D）形状从二维（2D）磁共振成像（MRI）重建技术在医学疾病诊断、治疗规划和计算建模中的重要性不断提升。本文回顾了3D MRI重建的方法学框架，重点介绍了四种主要方法：点云法、基于网格的方法、形状意识法和体素模型。对于每种类别，本文分析了当前最先进的技术、其方法论基础、局限性和在不同解剖部位的应用。此外，本文还详细探讨了从心脏到神经系统再到肺部影像，以及模型在病变解剖中的临床应用，包括模型的训练和测试数据的影响。我们还讨论了公开可用的数据库、计算需求和评估指标。最后，本文指出了未来研究的新方向，包括多模态集成和跨模态框架。
### Innovation
本文涵盖了从心脏到神经系统再到肺部的广泛成像技术，分析了公开的数据库和计算需求，并生成了各种评估指标。此外，本文指出了未来研究的新方向，包括多模态集成和跨模态框架。
### Conclusion
本文为研究人员提供了一个有结构的3D重建方法概述，以识别向更稳健、更通用及临床影响更大的解决方案发展的机会。
## 750. `cs.LG` - 网络水平上异质信号控制交叉口的车辆延误估计 [PDF](https://arxiv.org/pdf/2510.01292), [HTML](https://arxiv.org/abs/2510.01292)
### Authors
Xiaobo Ma,Hyunsoo Noh,James Tokishi,Ryan Hatch
### Background
准确的车辆延误估计对于评估信号化交叉口的表现和交通管理策略至关重要。延误反映了拥堵水平，影响了旅行时间的可靠性、燃油使用和排放。传统的机器学习模型通常假设训练和测试数据分布相同，但在实际应用中这一假设难以满足。不同的道路几何结构、信号控制时间和驾驶员行为会导致模型泛化性能差和模型准确性降低。
### Innovation
为解决这个问题，本研究引入了一种域适应(DA)框架来估计不同交叉口的车辆延误。该框架将数据划分为源域和目标域，提取关键的交通特征，并使用目标域中少量的带标签数据进行模型微调。提出了一种新型的DA模型，即基于梯度提升且有平衡权重的（GBBW）重权方法，根据与目标域的相似度重新加权源数据，增强了模型的适应性。该框架使用亚利桑那州皮马县57个异质交叉口的数据进行测试，与八种先进的机器学习回归模型和七种实例基于的DA方法进行了比较，结果表明，GBBW框架提供了更准确和稳健的延误估计。
### Conclusion
通过增强模型的可转移性，该框架促进了机器学习技术在实际交通系统中的广泛应用，支持更可靠的交通信号优化、拥堵管理和基于性能的规划。
## 751. `cs.LG` - 在循环神经网络中识别信息传递节点揭示动态表示 [PDF](https://arxiv.org/pdf/2510.01271), [HTML](https://arxiv.org/abs/2510.01271)
### Authors
Arend Hintze,Asadullah Najam,Jory Schossau
### Background
理解循环神经网络（RNNs）的内部动态对于提高它们的可解释性和设计至关重要。本文旨在介绍一种创新的信息论方法来识别和分析RNN内部的信息传输节点，称为‘信息中继节点’。这种方法通过量化输入和输出向量在节点之间的互信息，确定了网络操作期间信息流动的关键路径。该方法被应用于合成和真实世界的时间序列分类任务，采用了包括长短期记忆（LSTM）网络和门控循环单元（GRUs）在内的多种RNN架构。结果揭示了不同架构中信息传输的明显模式，这些模式提供了有关信息如何随时间处理和保持的见解。此外，通过节点删除实验评估了识别节点的功能重要性，为可解析的人工智能提供了重要贡献，揭示了特定节点如何影响整个网络的行为。
### Innovation
本文提出了一种创新的信息论方法来识别和分析RNN中的信息传输节点，并将其称为‘信息中继节点’。通过量化输入和输出向量在节点之间的互信息，该方法识别出网络操作期间信息流动的关键路径。该方法被应用于合成和真实世界的时间序列分类任务，并为进一步解释性和设计更加稳健和可解释的神经网络提供了有价值的工具。
### Conclusion
本文不仅增强了我们对驱动RNNs的复杂机制的理解，还提供了一种有价值的工具，用于设计更加稳健和可解释的神经网络。
## 752. `cs.LG` - ThinKV：适用于高效推理模型的自适应KV缓存压缩 [PDF](https://arxiv.org/pdf/2510.01290), [HTML](https://arxiv.org/abs/2510.01290)
### Authors
Akshat Ramachandran,Marina Neseem,Charbel Sakr,Rangharajan Venkatesan,Brucek Khailany,Tushar Krishna
### Background
大型推理模型在生成长输出上下文时，能够产生延长的思维链（CoT），但同时也会导致关键值（KV）缓存迅速膨胀，开始消耗GPU内存。这种膨胀会带来更大的内存压力并限制模型的扩展性。因此，需要一种有效的机制来应对这种增长挑战，特别是对于计算资源限制的场景而言。
### Innovation
提出了一种名为ThinKV的自适应KV缓存压缩框架。该框架基于观察到的注意力稀疏性揭示了CoT中具有不同重要性的思维类型。它结合量化与淘汰策略，根据思维的重要性分配token精度，并根据推理轨迹逐步淘汰较不重要的思维的token。此外，为了实现ThinKV，设计了一个内核扩展PagedAttention，使得被淘汰token的内存槽能够有效地重用，从而消除压缩开销。
### Conclusion
在包含DeepSeek-R1-Distill、GPT-OSS和NVIDIA AceReason的数学和编码基准测试中，ThinKV实现了接近无损的精度，同时内存使用量减少了不到5%，并能将推理吞吐量提高到至少5.8倍，超过了当前最佳基线。
## 753. `cs.LG` - 受微瞬目启发的探针：位置编码扰动揭示大语言模型的行为不良 [PDF](https://arxiv.org/pdf/2510.01288), [HTML](https://arxiv.org/abs/2510.01288)
### Authors
Rui Melo,Rui Abreu,Corina S. Pasareanu
### Background
论文从微瞬目（人类微小无意识的眼球移动，能揭示人类感知的深层次动态）中汲取灵感，提出了一种用于大型语言模型（LLMs）的类比探针方法。该方法通过轻微的位置编码扰动激发潜在信号，揭示模型的不良行为。这样的探针方法无需微调或特定任务的监督，能够检测各种背景下的模型故障，包括事实准确性、安全性、毒性以及后门攻击等。
### Innovation
该论文提出了一种基于微瞬目的探针方法，利用轻量级的位置编码扰动揭示大型语言模型的不良行为。这种方法不需要模型微调或特定任务监督，但在多个最先进的LLMs实验中显示出了高效的检测能力，揭示了模型内部已存在识别自身故障的证据，同时提出了通过微瞬目启发的方法来检测和缓解不良行为的可能性。
### Conclusion
实验证明，预训练的LLMs已经在编码自主检测故障所需的内部证据，而微瞬目启发的干预措施为检测和缓解不良行为提供了一条途径。该方法在多个方面显示出有效性，并强调了无需微调和任务特定监督的高效探测效果。
## 754. `cs.LG` - 关于潜在线性行动策略的可识别性 [PDF](https://arxiv.org/pdf/2510.01337), [HTML](https://arxiv.org/abs/2510.01337)
### Authors
Sébastien Lachapelle
### Background
该研究探讨了从视频数据中学习潜在动作策略（LAPO）框架的能力，这种框架最近被引入用来发现动作表示。本文正式描述了此类表示的期望特性，统计优势以及潜在的不可识别因素。
### Innovation
本文证明，经过熵正则化的LAPO目标可以在合适条件下识别出满足本文特定要求的动作表示。这种分析为为什么离散动作表示在实践中表现良好提供了解释。
### Conclusion
本文通过分析论证了在适当条件下，经过熵正则化的LAPO目标可以成功识别出描述动作的满足特定要求的表示，这些表示在实践中表现出色。
## 755. `cs.LG` - 低秩梯度及其来源 [PDF](https://arxiv.org/pdf/2510.01303), [HTML](https://arxiv.org/abs/2510.01303)
### Authors
Rishi Sonthalia,Michael Murray,Guido Montúfar
### Background
该论文研究了两层神经网络训练损失梯度的低秩结构，放宽了通常对训练数据和参数的各向同性假设。研究采用了一个发散数据模型，其中主体可以是非各向同性和病态的，不要求数据和权重矩阵独立，并分析了均场和神经域核的比例。
### Innovation
论文展示了输入权重梯度几乎低秩，并由两个秩一项主导：一项与主体数据残差对齐，另一项与输入数据的秩一发散对齐。论文还探讨了训练数据特性、缩放阶段和激活函数如何控制这两种组件之间的平衡。同时，论文还证明了标准正则化方法，如权重衰减、输入噪声和雅可比惩罚能够选择性地调整这些组件。
### Conclusion
实验结果证实了理论预测，证明了输入权重梯度的低秩性质，并强调了标准正则化方法在此中的作用。
## 756. `cs.LG` - 基于LQR指导的安全强化学习振动控制：克服训练风险 [PDF](https://arxiv.org/pdf/2510.01269), [HTML](https://arxiv.org/abs/2510.01269)
### Authors
Rohan Vitthal Thorat,Juhi Singh,Rajdip Nayek
### Background
外部激励引起的结构振动带来了显著风险，包括对居住者安全的威胁、结构损伤以及维护成本增加。传统基于模型的控制策略，如线性二次调节器（LQR），能够有效减轻振动影响，但它们依赖于精确的系统模型，这需要繁琐的系统识别过程。这可以避免使用无模型的强化学习（RL）方法。RL控制器仅依赖于所观察到的结构行为来得出其策略，从而无需明确的结构模型。然而，RL控制器在实际物理系统中进行训练时缺乏先验知识，其施加于结构的控制力是随机的，这可能会对结构造成损害。为了减轻这一风险，该研究提出利用LQR控制器指导RL控制器。我们的观察结果表明，即使基于完全错误模型的LQR控制器也比未经控制的场景表现更好。
### Innovation
该研究引入了一种结合LQR和RL的混合控制框架，其中LQR策略是从随机选择的模型及其参数中得出的。利用这种方法，消除了对明确系统模型的依赖性，同时通过基于LQR方法来最小化RL方法固有的探索性风险。这是首次解决基于RL的振动控制在训练过程中的关键安全挑战的研究，并提供了一个经过验证的解决方案。
### Conclusion
该研究开发了一种安全的RL振动控制方法，通过利用LQR指导策略，能够在不依赖明确模型的情况下进行控制训练，提供了有效的解决方案来克服训练中的各种风险。
## 757. `cs.LG` - Fine-Tuning Masked Diffusion for Provable Self-Correction [PDF](https://arxiv.org/pdf/2510.01384), [HTML](https://arxiv.org/abs/2510.01384)
### Authors
Jaeyeon Kim,Seunggeun Kim,Taekyun Lee,David Z. Pan,Hyeji Kim,Sham Kakade,Sitan Chen
### Background
生成模型的一个自然需求是自我纠正，即在推理过程中检测和修正低质量的生成片段。尽管掩蔽扩散模型（Masked Diffusion Models，MDMs）在离散空间的生成建模中展现出潜力，但它们的自我纠正能力尚未得到充分理解。以往尝试将自我纠正融入MDMs的方法要么需要重新架构和训练模型，要么依赖于不精确的伪代理来评估token的质量，这限制了它们的实际应用。
### Innovation
该研究引入了PRISM（Plug-in Remasking for Inference-time Self-correction of Masked Diffusions），这是一种轻量级、模型无关的方法，可以应用于任何预训练的MDMs。PRISM通过理论定义自纠正损失，无需使用强化学习或验证器就能学习每个token的质量分数。这些质量分数在MDMs的前向传播过程中计算得出，并用于检测低质量的token。
### Conclusion
实验结果显示，PRISM方法可以提高掩蔽扩散模型在不同领域和规模下的推理性能：数独、无条件文本（170M参数量）以及代码（使用LLaDA，8B参数量）。
## 758. `cs.LG` - 增或不增？诊断分布对称性破坏 [PDF](https://arxiv.org/pdf/2510.01349), [HTML](https://arxiv.org/abs/2510.01349)
### Authors
Hannah Lawrence,Elyssa Hofgard,Vasco Portilheiro,Yuxuan Chen,Tess Smidt,Robin Walters
### Background
为了确保机器学习模型在所有原始数据集变换（例如旋转或置换）中的正确行为，使用了对称感知方法，如数据增强和协变结构。这些方法在假设变换后的数据在测试分布中是高度可能的或“重要的”情况下，可以提高泛化能力和样本效率。然而，这一假设的有效性需要进一步评估。
### Innovation
本文开发了一种方法，用于评估上述假设的有效性。特别地，作者提出了一种量化数据集中的各向异性（或对称性破坏）的指标，通过一个区分原始数据集和其随机增强版本的两样本神经分类器测试来实现。该方法在合成数据集上得到验证，并应用于多种基准点云数据集，揭示存在很高的对齐程度。此外，理论上证明，对称性破坏可能阻止不变方法在某些情况下表现最优，即使底层标签是真正的不变的。实验结果显示，对称感知方法对数据集的性质依赖性较大：在一些各向异性数据集上仍能带来益处，但在其他数据集上则不然。
### Conclusion
研究结果表明，理解和对称性在何时以及为什么有效——可能需要重新思考数据中的对称性偏差。
## 759. `cs.LG` - 自我监督表示学习作为互信息最大化 [PDF](https://arxiv.org/pdf/2510.01345), [HTML](https://arxiv.org/abs/2510.01345)
### Authors
Akhlaqur Rahman Sabby,Yi Sui,Tongzi Wu,Jesse C. Cresswell,Ga Wu
### Background
自我监督表示学习（SSRL）在实验上取得了显著的成功，但其背后的基本原理仍不充分理解。尽管近年来的工作试图通过信息论目标或总结防止表示崩溃的启发式来统一SSRL方法，但诸如预测网络、停止梯度操作和统计正则化剂等架构元素通常被看作是经验驱动的附加项。本文从基础原理出发，探讨学习目标是否决定了可能的优化策略和模型设计选项。
### Innovation
通过从变分互信息下界出发，推导出两种训练范式：自我辅导互信息（SDMI）和联合互信息（JMI），每种范式施加不同的结构约束，并涵盖了一些现有的SSRL算法。SDMI内在要求交替优化，使得停止梯度操作成为理论上的必要条件。相比之下，JMI允许通过对称架构进行联合优化而不需要这些组件。在所提出的框架下，SDMI中的预测网络和JMI中的统计正则化剂被视为互信息目标的可计算替代品。证明了许多现有的SSRL方法是这些两种范式的特定实例或近似。
### Conclusion
本研究提供了对于现有SSRL方法不同架构组件选择背后的理论解释，超越了启发式便利。
## 760. `cs.LG` - 扩散模型中的选择性欠拟合 [PDF](https://arxiv.org/pdf/2510.01378), [HTML](https://arxiv.org/abs/2510.01378)
### Authors
Kiwhan Song,Jaeyeon Kim,Sitan Chen,Yilun Du,Sham Kakade,Vincent Sitzmann
### Background
扩散模型已成为生成建模的主导范式，广泛应用于各种领域。在训练过程中，它们学习得分函数，在推断时利用该得分函数生成样本。然而，扩散模型究竟学习到了什么得分仍是一个基本且未解决的问题。传统的观点认为，能够完全匹配经验得分的扩散模型只会在训练数据上进行再生成，无法产生新的样本。近期的研究则提出扩散模型在训练过程中由于存在归纳偏差而欠拟合经验得分。本文进一步细化了这一观点，提出了选择性欠拟合的概念，认为更好的扩散模型在输入空间的某些区域更准确地近似得分，而在其他区域则欠拟合得分。
### Innovation
本文提出了选择性欠拟合的概念，区别于传统观点认为扩散模型在所有区域都存在欠拟合。作者通过实证干预验证了这一观点，并指出选择性欠拟合对于理解扩散模型的泛化与生成性能至关重要，这为扩散模型的研究提供了新的、可测试的见解.
### Conclusion
研究结果表明，选择性欠拟合对于理解扩散模型是必不可少的，它为扩散模型的泛化能力和生成性能提供了新的、可测试的洞察。
## 761. `cs.LG` - 边缘人工智能：演进、分类框架及未来发展综述 [PDF](https://arxiv.org/pdf/2510.01439), [HTML](https://arxiv.org/abs/2510.01439)
### Authors
Mohamad Abou Ali,Fadi Dornaika
### Background
边缘人工智能（Edge AI）将智能直接嵌入网络边缘的设备中，这样可以实现实时处理并提高隐私保护和降低延迟。该综述通过多维度的分类体系，包括部署位置、处理能力（如TinyML和联邦学习）、应用领域和硬件类型，系统地回顾了边缘人工智能的发展、当前状况和未来方向。
### Innovation
采用PRISMA指南，从早期的内容分发网络和雾计算追溯到现代的设备级智能，广泛探讨关键使能技术如专用硬件加速器、优化软件和通信协议，批判性地评估资源限制、安全、模型管理、能耗和连接性等挑战，同时强调新兴的机会，如神经形态硬件、不断学习算法、边缘与云协作以及可信性集成。
### Conclusion
本文提供了一个全面的框架，为研究者和实践者提供了理论依据，讨论了边缘人工智能领域的未来前景。
## 762. `cs.LG` - 量子启发式基准用于估计固有维度 [PDF](https://arxiv.org/pdf/2510.01335), [HTML](https://arxiv.org/abs/2510.01335)
### Authors
Aritra Das,Joseph T. Iosue,Victor V. Albert
### Background
机器学习模型在现实生活中的数据集上表现出良好的泛化能力。曼ifold假设表明，这可能是因为数据集位于具有较小固有维度（内在维度）的潜在manifold上。虽然存在许多固有维度估计（IDE）的方法，但它们的估计值差异很大。这要求在比现有基准更复杂的manifold上对IDE方法进行基准测试。我们的基准测试基于量子光学方法，该方法可以嵌入任意均匀空间，同时允许曲率修改和噪声添加。测试的方法在QuIIEst manifolds上的准确度低于现有基准，尤其是随着曲率越来越非均匀，性能下降最小，表明该基准具有固有的难度。此外，我们对分形霍夫斯特拉蝴蝶进行了固有维度估计，并确定哪些方法能够提取非manifold空间的有效维度。
### Innovation
我们提出了一个名为QuIIEst的基准测试，基于量子光学方法来嵌入任意均匀空间，允许曲率修改和噪声添加。该基准测试涉及具有已知固有维度的拓扑非平凡manifold的无限家族。这种基准测试方法能够识别不同方法在更复杂manifold上的表现，发现现有的IDE方法在非均匀曲率情况下表现不如现有基准，但也证明了该基准的难度。此外，我们还对分形霍夫斯特拉蝴蝶进行了固有维度估计，确定了哪些方法能够提取非manifold空间的有效维度。
### Conclusion
我们提出的QuIIEst基准测试验证了在复杂的manifold上IDE方法的表现，表明现有的方法在非均匀曲率时表现较弱，但也展示了该基准的挑战性。此外，通过霍夫斯特拉蝴蝶的研究，我们确定了能够提取非manifold空间有效维度的方法。
## 763. `cs.LG` - RheOFormer: 一种用于复杂流体和流态模拟的生成性转换模型 [PDF](https://arxiv.org/pdf/2510.01365), [HTML](https://arxiv.org/abs/2510.01365)
### Authors
Maedeh Saberi,Amir Barati Farimani,Safa Jamali
### Background
软材料在流动条件下的力学建模对于设计和工程具有目标属性的过程和材料至关重要。这通常需要求解与变形张量相关的内应力张量，而这种方法通常依赖于非线性和历史依赖的本构模型。传统的非牛顿流体动力学数值方法常常面临耗时且计算成本高的问题，无法很好地扩展到新的问题实例。传统数据驱动方法虽然部分解决了这些限制，但仍需要在各种物理条件下重新训练。
### Innovation
本文提出了一种利用自注意力机制生成操作学习方法——Rheological Operator Transformer (RheOFormer)，以高效学习复杂流体流动的空间交互和特征。RheOFormer在不同类型粘弹性与弹性黏塑性力学的复杂域中，与真实解进行基准测试。实验结果证明了RheOFormer可以准确学习不同复杂流体的标量和张量非线性力学，并预测其流的时空演变。即使训练数据集有限，RheOFormer也表现出强大的泛化能力和计算效率，从而确保其作为加速复杂流体模拟的神经近似器、推进数据驱动实验和实时过程优化的强大工具的有效性。
### Conclusion
RheOFormer作为一种稳健的神经近似器，能够加速预测复杂的流体模拟，推进数据驱动实验，实现广泛应用中的实时过程优化。
## 764. `cs.LG` - 端到端神经压缩与重构的超高效解码 [PDF](https://arxiv.org/pdf/2510.01407), [HTML](https://arxiv.org/abs/2510.01407)
### Authors
Ethan G. Rogers,Cheng Wang
### Background
图像压缩和重构对于各种数字应用至关重要。尽管现代基于神经网络的压缩技术实现了令人印象深刻的压缩率，但在数据重构过程中基于卷积的解码器的复杂性和巨大的计算成本阻碍了该技术的广泛应用。
### Innovation
为了解决神经压缩中的解码瓶颈问题，作者提出了一种基于自动编码器和向量量化结合低秩表示的新压缩与重构框架。通过在图像学习到的潜在表示上进行一系列计算高效的低秩操作，实现高效高质量的数据重构。这种方法大幅减少了神经压缩/重构解码阶段的计算开销，从根本上消除了解码计算瓶颈，同时保持了高质量的图像输出。
### Conclusion
该方法显著降低了神经压缩/重构解码阶段的计算开销，消除了解码计算瓶颈，保持了高质量的图像输出，提升了端到端神经压缩与重构的效率。
## 765. `cs.LG` - SCOPED: 分数曲率异常分布邻近性评估器 [PDF](https://arxiv.org/pdf/2510.01456), [HTML](https://arxiv.org/abs/2510.01456)
### Authors
Brett Barkley,Preston Culbertson,David Fridovich-Keil
### Background
Out-of-distribution (OOD) 检测对于机器学习系统的可靠部署至关重要，在视觉、机器人、强化学习等领域都有应用。
### Innovation
提出了一种新的快速且通用的 OOD 检测方法 SCOPED，它通过单个训练模型计算单一测试统计量，结合模型分数函数的雅可比迹和平方范数，比之前的方法减少了模型前向传递的数量级，超越了大多数现有的基于扩散模型的基本方法，接近最强方法的准确性。该方法不需要固定的阈值，而是使用核密度估计来估计 SCOPED 分数的分布密度，使得它成为一个灵活且不需要监督的测试，即使是在最简单的情况下，只需要一个前向传递和一个雅可比-向量乘积（JVP），并通过哈钦森的迹估计方法使其高效。
### Conclusion
SCOPED 在四个视觉基准测试中实现了竞争性的或最先进的精准召回率成绩，即使计算成本低。该方法还广泛适用于具有共享状态和动作空间的机器人控制任务，能够识别回奖函数和训练策略下的分布转移。该结果定位 SCOPED 作为快速和可靠的 OOD 检测的实际基础，应用于现实领域的感知艺术、自回归模型异常检测、强化学习探索以及无监督训练数据集的策划。
## 766. `cs.LG` - SoftAdaClip：一种公平和私人模型训练的平滑剪裁策略 [PDF](https://arxiv.org/pdf/2510.01447), [HTML](https://arxiv.org/abs/2510.01447)
### Authors
Dorsa Soleymani,Ali Dadsetan,Frank Rudzicz
### Background
差分隐私（DP）为敏感数据提供了强有力的保护，但通常会降低模型性能和公平性，尤其是在对少数群体的影响上更为明显。主要原因在于DP-SGD中的梯度裁剪会导致对少数子群体的学习信号不成比例地削弱。尽管自适应裁剪可以增强效用，但它仍然依赖于统一的硬裁剪，这可能限制公平性。
### Innovation
我们提出了SoftAdaClip，这是一种差分隐私训练方法，它用基于tanh的平滑转换取代了硬裁剪，以保留相对梯度的大小同时限制敏感性。SoftAdaClip在MIMIC-III（临床文本）、GOSSIS-eICU（结构化健康护理）和Adult Income（表格数据）等多个数据集上进行了评估。
### Conclusion
我们的结果表明，SoftAdaClip将子群体差异减少了最多87%，相较于DP-SGD和Adaptive-DPSGD，这种子群体差异的减少在统计上是显著的。这些发现强调了将平滑变换与自适应机制结合以实现公平和私人模型训练的重要性。
## 767. `cs.LG` - 在有噪反馈条件下偏好优化的泛化能力如何？ [PDF](https://arxiv.org/pdf/2510.01458), [HTML](https://arxiv.org/abs/2510.01458)
### Authors
Shawn Im,Yixuan Li
### Background
随着大型语言模型（LLMs）能力的提升，将这些模型与人类偏好对齐变得至关重要。基于人类反馈的偏好优化在对齐LLMs方面变得越来越重要，但现有的大多数工作假设反馈是无噪声的，这是不现实的，因为人类的判断存在固有的错误和不一致性。
### Innovation
本文解决了有噪声反馈对偏好优化的影响，提供了在这些条件下的一般泛化保证。不同于传统的收敛假设分析，本文专注于有限步长的偏好优化，提供了更贴近实际LLM训练的新见解。此外，该分析适用于广泛的家庭偏好优化损失，如DPO、IPO、SLiC等。实验验证在现代LLM上的确证了本文发现的实际相关性，为开发与人类偏好对齐的AI系统提供了宝贵的见解。
### Conclusion
本文描述了不同类型的噪声在不同噪声率级别下的泛化衰减，分析适用于特定的偏好优化损失函数，实验验证确认了这些发现的实际相关性。
## 768. `cs.LG` - 修复免费午餐：合成数据在模型导向策略优化中的何时何地为何失败 [PDF](https://arxiv.org/pdf/2510.01457), [HTML](https://arxiv.org/abs/2510.01457)
### Authors
Brett Barkley,David Fridovich-Keil
### Background
基于数据效率的Dyna风格模型导向强化学习中，合成数据是一个核心组成部分，但有时也可能损害性能。本文探讨了合成数据何时有用，何时失败，以及为什么，发现当合成数据导致的失败模式被解决时，可以实现之前无法达到的策略改进。尽管在OpenAI Gym中报告了强大的推广性和样本效率优势，最近的研究表明，在DeepMind Control Suite (DMC) 中，模型导向策略优化 (MBPO) 经常表现不如其无模型的同类方式Soft Actor-Critic (SAC)。这种差异在连续控制任务场景下尤为明显，导致了显著的性能损失。
### Innovation
本文确定了导致MBPO在DMC任务中失败的两种相互作用的问题：动态和回报模型之间的规模不匹配导致了估计算法的低估，以及目标表示的不良选择增加了模型偏差并产生了故障多的模拟轨迹。通过解决这些问题，使得MBPO在DMC中五个任务上优于SAC，同时还保留了在OpenAI Gym中报告的强性能。
### Conclusion
本文强调了环境特定假设如何在算法设计中变成隐性的编码。提倡通过开发将MDP任务和环境层次结构与算法失败模式联系起来的分类法，可能的统一解决方案以及澄清基准选择如何最终影响算法推广性的社区动机。
## 769. `cs.LG` - 最优停止理论与Best-of-$N$在推理时间优化中的对比 [PDF](https://arxiv.org/pdf/2510.01394), [HTML](https://arxiv.org/abs/2510.01394)
### Authors
Yusuf Kalayci,Vinod Raman,Shaddin Dughmi
### Background
大型语言模型（LLM）生成通常需要在输出质量和推理成本之间进行权衡，尤其是在使用多次生成的情况下。新框架基于经典的 Pandora's Box 问题，将每次生成视为带有随机奖励的成本不菲的“盒子”。研究旨在开发算法以在未知奖励分布的情况下决定何时停止生成。研究团队首先提出了一种类似于 UCB 的 Pandora's Box 算法，该算法在已知分布时的性能可以证明接近于最优策略——Weitzman 算法。进一步针对提示之间的奖励缩放问题通过一种 Bradley-Terry 灵感启发的变换进行调整，提出了一个适应性推理时间优化方法，该方法能够在运行时动态地归一化奖励并学习停止阈值。研究表明，在使用多种 LLM-奖励模型对 AlpacaFarm 和 HH-RLHF 数据集进行实验时，本方法的适应性策略能够实现与非适应性 Best-of-N 抽样方法相同的效果，且平均要求较少的生成次数（15-35%）。
### Innovation
研究提出了一种类似于 UCB 的 Pandora's Box 算法，以及针对提示间的奖励缩放问题的适应性推理时间优化方法。该方法能够在运行时动态地归一化奖励并学习停止阈值，从而实现在保证性能的同时减少生成次数的目标。此外，该研究建立了最优停止理论与推理时间缩放之间的重要联系，提供了理论上的性能限制和实际效率 gains。
### Conclusion
本研究通过提出基于 Pandora's Box 问题的最优停止理论与适应性算法，实现了在不牺牲性能的情况下减少生成次数的目标。研究结果不仅为 LLM 部署提供了合理的桥梁，还提供了实际效率提升。
## 770. `cs.LG` - Local Linear Attention: 用于测试时回归的最佳线性与Softmax注意力插值 [PDF](https://arxiv.org/pdf/2510.01450), [HTML](https://arxiv.org/abs/2510.01450)
### Authors
Yifei Zuo,Yutong Yin,Zhichen Zeng,Ang Li,Banghua Zhu,Zhaoran Wang
### Background
Transformer架构在多个领域取得了显著成功，尽管已经研究了高效替代Softmax Attention的机制，但在寻找基于理论洞察、更具表现力的机制方面，尤其是在计算成本可能增加的情况下，研究相对较少。本文通过提出基于测试时回归的非参数统计视角的新型局部线性注意力（LLA）机制，填补了这一空白，分析了LLA在关联记忆上的理论优势，解决了其计算挑战，并通过FlashLLA算法实现了其在现代加速器上的高效并行计算。
### Innovation
本文提出了一种新的局部线性注意力机制（LLA），该机制通过非参数统计视角和测试时回归的研究方法来优化Transformer模型中的注意力机制。LLA在关联记忆中提供理论优势，并通过两种内存高效的原始操作解决了其计算复杂度问题。提出了FlashLLA算法来实现其在现代加速器上的高效并行计算，并通过定制的推理内核显著减少了内存开销。实验结果表明LLA在测试时训练和上下文学习中优于强基线，在规模较大的模型中具有良好的扩展性和适用性潜力。
### Conclusion
LLA在测试时回归、上下文回归、关联回忆和状态跟踪任务上体现了其适应非站稳态的特性，优于强基线，在测试时训练和上下文学习中表现出优越性，展现了其在大规模模型中的应用前景。
## 771. `cs.LG` - LSPO：LLM推理中基于长度感知的动态采样策略 [PDF](https://arxiv.org/pdf/2510.01459), [HTML](https://arxiv.org/abs/2510.01459)
### Authors
Weizhe Chen,Sven Koenig,Bistra Dilkina
### Background
自从Deepseek-R1发布以来，可验证奖励的强化学习（RLVR）已成为训练大规模语言模型（LLMs）在推理任务上的主要方法。近期的工作主要关注修改损失函数以提高RLVR的效率和效果。基于对LLMs过度思考的研究，本文提出了一种新的元RLVR算法——基于长度感知的策略优化采样（LSPO），该算法在每个步骤中动态选择训练数据，基于平均响应长度。文章在多个基础模型和数据集上评估了LSPO，展示了其在增强学习效果方面的持续改进。此外还进行了详细的消融研究，分析如何将长度信号纳入动态采样，为未来研究提供了进一步的见解和方向。
### Innovation
提出了一种基于长度感知的动态采样策略（LSPO），在每个训练步骤中动态选择训练数据，基于平均响应长度。通过大规模模型和数据集评估其效果，并进行详细的消融研究，以更好地理解如何有效利用长度信号来优化策略优化阶段的数据采样。
### Conclusion
本文提出的LSPO算法在提高LLMs在推理任务中的学习效果方面表现出优越性，并通过详细的消融分析为未来的研究提供了明确的方向。
## 772. `cs.LG` - PEL-NAS: Search Space Partitioned Architecture Prompt Co-Evolutionary LLM-driven Hardware-Aware Neural Architecture Search [PDF](https://arxiv.org/pdf/2510.01472), [HTML](https://arxiv.org/abs/2510.01472)
### Authors
Hengyi Zhu,Grace Li Zhang,Shaoyi Huang
### Background
硬件感知的神经架构搜索（HW-NAS）需要在设备约束下同时优化准确性和延迟。传统的基于超网络的方法需要花费大量的GPU天数。虽然基于大型语言模型（LLM）的方法可以避免训练大型超网络，并能快速提供反馈，但存在探索偏见：LLM重复提出在有限搜索空间内的神经网络设计方案，而无法在整个搜索空间中发现不同延迟范围的不同架构。
### Innovation
提出了一种名为PEL-NAS的搜索空间分区、架构提示协同进化的基于LLM的HW-NAS方法。PEL-NAS包括三个关键组件：1）由复杂性驱动的分区引擎，将搜索空间按复杂性分割，以确保多样性和减少探索偏见；2）由LLM驱动的架构提示协同进化操作，该操作首先根据上一轮的结果更新设计启发式知识库，然后使用包含此知识库的提示进行引导进化的算法，通过多轮共同提高提示和设计，避免随机猜测，提高效率；3）零成本预测器，避免训练大量候选模型。
### Conclusion
实验结果表明，与基准相比，PEL-NAS在准确度相似的情况下，H McNuggets值（HV）更高，IGD（吸入生成空间亏空）值更低，且整体延迟降低至54%。同时，搜索成本从天降到分钟级相比传统的基于超网络基准。
## 773. `cs.LG` - 超越多数投票：通过利用高级信息进行LLM聚合 [PDF](https://arxiv.org/pdf/2510.01499), [HTML](https://arxiv.org/abs/2510.01499)
### Authors
Rui Ai,Yuqi Pan,David Simchi-Levi,Milind Tambe,Haifeng Xu
### Background
随着多智能体大型语言模型（LLM）推理的快速发展，如何有效聚合多个LLM的答案已成为一个基本的挑战。传统的多数投票方法将所有答案等同对待，未能考虑模型间潜在的异质性和相关性。
### Innovation
本文设计了两种新的聚合算法，称为最优加权（Optimal Weight, OW）和逆惊讶流行度（Inverse Surprising Popularity, ISP），利用了一阶和二阶信息。理论分析表明，在温和假设下，这些方法可以证明减轻了多数投票固有的局限性，从而提高了集体决策的可靠性。
### Conclusion
我们在合成数据集、流行的LLM微调基准UltraFeedback和MMLU，以及实际的医疗保健情境ARMMAN上实证验证了我们的算法。在所有案例中，我们的方法都持续超过了多数投票，提供了实际性能改进和多智能体LLM管道设计的概念洞察。
## 774. `cs.LG` - 离线到在线强化学习的三种状态 [PDF](https://arxiv.org/pdf/2510.01460), [HTML](https://arxiv.org/abs/2510.01460)
### Authors
Lu Li,Tianwei Ni,Yihao Sun,Pierre-Luc Bacon
### Background
离线-在线强化学习（RL）是一种实用的范式，利用离线数据集进行预训练，并在线交互进行微调。然而，其实际行为很容易产生矛盾：在一个环境下对在线微调的有效设计选择可能在另一个环境下完全不起作用。这种不一致性可以由以下原理解释：在在线微调过程中，我们应保持预训练策略或离线数据集的知识中较好的一方，同时保持足够的可塑性。这一观点界定了在线微调的三个不同范式，每个范式都要求不同的稳定性特性。
### Innovation
提出了稳定性-可塑性原则，界定了在线微调的三种不同状态，每种状态需要不同的稳定性特征。通过大规模实验证明了这一框架，发现其中45种情况的结果与预测强烈一致。这项研究为基于离线-在线RL算法选择提供了一个普适的框架，考虑到离线数据集和预训练策略的相对性能。
### Conclusion
该研究通过实验证明，提出的框架可以很好地指导离线-在线强化学习的设计选择，依据是离线数据集和预训练策略的相对表现。
## 775. `cs.LG` - 碳X：使用时间序列基础模型的开源计算去碳化工具 [PDF](https://arxiv.org/pdf/2510.01521), [HTML](https://arxiv.org/abs/2510.01521)
### Authors
Diptyaroop Maji,Kang Yang,Prashant Shenoy,Ramesh K Sitaraman,Mani Srivastava
### Background
计算去碳化旨在减少计算和数据中心、交通运输、建筑环境等社会系统中的碳排放。这需要精确且细微的碳强度预测，但现有工具存在几个关键局限：（i）它们需要特定电网的电力组合数据，限制了这些信息不可用的地区的使用；（ii）依赖于单独的电网特定模型，使得难以提供全球覆盖；（iii）提供预测而不提供不确定性估计，限制了下游碳智能应用的可靠性。
### Innovation
本文介绍了CarbonX，这是一个开源工具，利用时间序列基础模型（TSFM）进行多种去碳化任务。CarbonX 利用TSFM的多功能性，提供了在多个任务和多种电网上的强大性能，如碳强度预测和补全任务。使用仅限于历史碳强度数据和单一通用模型，我们的工具在全球214个电网上的零样本预测平均绝对百分比误差（MAPE）为15.82%。在13个基准电网中，CarbonX 的性能与当前最先进技术水平相当，平均MAPE为9.59%，尾部预测MAPE为16.54%，同时提供了95%的预测区间。对于21天预报，CarbonX 的准确性几乎没有下降。进一步地，当完全微调时，CarbonX 在补全任务上的表现比统计基线高出1.2–3.9倍。
### Conclusion
这些结果表明，CarbonX 可以在具有有限数据的情况下用于任何电网，并且仍然提供强大的性能，使其成为一个实用的全球规模去碳化工具。
## 776. `cs.LG` - 理解对抗性转移：为什么代表空间攻击在数据空间攻击成功的地方失败 [PDF](https://arxiv.org/pdf/2510.01494), [HTML](https://arxiv.org/abs/2510.01494)
### Authors
Isha Gupta,Rylan Schaeffer,Joshua Kazdan,Ken Liu,Sanmi Koyejo
### Background
对抗样本在图像分类器之间的转移和语言模型之间的语言狱突已被广泛接受。然而，最近的研究表明，在视觉-语言模型之间的图像狱突转移是失败的。本文解释了这一显著差异，指出攻击在输入数据空间可以转移，但在模型表示空间无法转移，至少没有几何结构的对齐。
### Innovation
本文提出了代表空间攻击和数据空间攻击之间的基本区分，并通过理论和实验验证了这种假设。展示了代表空间攻击和数据空间攻击的效果和转移性之间的不同，并且发现在视觉-语言模型的潜在几何结构在后投影空间足够对齐的情况下，代表空间攻击可以转移。
### Conclusion
本文揭示了对抗性转移并非所有攻击的固有属性，而是取决于其操作领域——共享的数据空间还是模型的独特表示空间。这一发现对构建更健壮的模型至关重要。
## 777. `cs.LG` - 使用变分贝叶斯最后一层微调LLMs的高维贝叶斯优化 [PDF](https://arxiv.org/pdf/2510.01471), [HTML](https://arxiv.org/abs/2510.01471)
### Authors
Haotian Xiang,Jinwen Xu,Qin Lu
### Background
许多应用涉及解决具有高评估成本的黑盒优化问题，如药物发现、材料设计及超参数调优。针对此类黑盒优化问题，贝叶斯优化（BO）提供了一种理论优雅的框架，通过概率后验模型实现均衡的探索-利用贸易。高斯过程（GP）作为后验模型的首选，已被证明在低维连续变量的简单贝叶斯优化中表现出色。然而，GP难以处理具有不规则变量（如分类、序数等）的高维变量。为了解决这一问题，已经探索了基于神经网络的后验模型。本文在此基础上，利用大型语言模型（LLMs）作为后验模型，并通过变异贝叶斯最后一层（VBLL）框架结合低秩适应（LoRA）对LLMs进行微调，从而实现高维贝叶斯优化。
### Innovation
提出了使用低秩适应（LoRA）和变异贝叶斯最后一层（VBLL）框架结合大型语言模型（LLMs）的高维贝叶斯优化方法。该方法不仅计算成本较低，还支持递归更新，并通过加权集成（ENS）机制自动生成不同的模型权重和参数。
### Conclusion
广泛的实验结果表明，提出的（ENS-）LoRA-VBLL方法在各种高维基准测试和实际分子优化任务上表现出色，验证了其有效性。
## 778. `cs.LG` - 使用实际数据和物理化学属性进行预测建模和可解释AI以评估兽医安全概况、残留物评估和健康结果 [PDF](https://arxiv.org/pdf/2510.01520), [HTML](https://arxiv.org/abs/2510.01520)
### Authors
Hossein Sholehrasa,Xuan Xu,Doina Caragea,Jim E. Riviere,Majid Jaberi-Douraki
### Background
确保在食品生产动物中合理使用药物对维护动物福利和食品安全至关重要。不良事件(AEs)可能暗示未预期的药代动力学或毒代动力学效应，增加食品链违禁残留的风险。该研究利用美国FDA的美国兽医中心（CVM）从1987年至2025年第一季度的约128万份报告，探索如何预测兽医安全性结果。研究通过预处理管道合并关系表，使用VeDDRA本体标准化AEs，对数据进行归一化、缺失值填充和高卡洛尼特征缩减，同时整合药物的物理化学特性以捕捉化学残留物的关联。
### Innovation
研究引入了一种预测框架，使用监督模型如随机森林、CatBoost、XGBoost、ExcelFormer和大型语言模型，以及集成方法如投票和堆叠。特别关注了规避致命结果的召回优先级。在ExcelFormer和XGBoost中，结合使用基于平均不确定性边界的伪标注改进了少数类检测。通过SHAP可解释性分析，确定了生物上合理的影响预测因素，包括肺、心脏和支气管疾病、动物的统计信息和药物物理化学属性。
### Conclusion
该框架表明，结合严格的Data工程、先进的机器学习和可解释的AI能够在预测兽医安全性结果时实现精确且可解释的预测。该方法支持FARAD的任务，通过早期发现高风险药物事件配置文件、强化残留物风险评估，以及为监管和临床决策提供信息。
## 779. `cs.LG` - 现实环境下的CDSS药物剂量调控：基于端到端递归Q学习的双重血管加压素控制 [PDF](https://arxiv.org/pdf/2510.01508), [HTML](https://arxiv.org/abs/2510.01508)
### Authors
Will Y. Zou,Jean Feng,Alexandre Kalimouttou,Jennifer Yuntong Zhang,Christopher W. Seymour,Romain Pirracchio
### Background
临床决策支持系统（CDSS）中的强化学习（RL）应用常受到临床实践者的质疑，尤其是关于药物剂量决策不可操作性的问题。本文以重症监护室（ICU）中感染性休克患者为例，采用端到端的方法学习最优的药物剂量和控制策略，兼顾双股加压素的管理。通过设计适用于离散、连续和方向性的剂量策略的动作空间，结合离线保守的Q学习与新颖的递归建模，显著提高了对于ICU时间序列数据中时间依赖性的捕捉。
### Innovation
文章创新在于通过自主研发的递归Q学习方法和优化的动作空间设计，既能改善药物剂量的可解释性和临床应用，又能保持治疗效果。对于去甲肾上腺素的不同剂量策略进行比较分析，表明设计的动作空间提升了临床的可接受性。
### Conclusion
提出的递归Q学习方法在eICU和MIMIC数据集上的实验证明，动作空间设计对学习到的行为策略有显著影响，且应用本文方法能够提高超过15%的存活改善概率，同时遵循了现有的临床指南。
## 780. `cs.LG` - 关于二值神经网络验证问题的整数规划方法 [PDF](https://arxiv.org/pdf/2510.01525), [HTML](https://arxiv.org/abs/2510.01525)
### Authors
Woojin Kim,James R. Luedtke
### Background
二值神经网络（BNNs）是具有二进制权重和激活函数的前馈神经网络。在使用BNN进行分类时，验证问题旨在确定是否会对给定输入进行轻微扰动而导致其被BNN误分类，BNN的鲁棒性可以通过解决多个输入的验证问题来衡量。BNN的验证问题可以形式化为整数规划（IP）问题，但由于带有大-M约束的大整数间隙，自然的IP形式公式难以求解。这项研究旨在通过改进基于整数规划的方法来解决BNN的验证问题，提高BNN在一定程度内对抗输入扰动的验证能力。
### Innovation
作者提出了两种改进整数规划（IP）表征的技术：1）提出了一种求解多类别设置下的线性目标的新方法；2）提出了一种利用BNN递归结构生成有效的不等式的新型技术。这种新技术使得在限定时间内可以验证BNN对更大范围的输入扰动。
### Conclusion
通过应用改进的整数规划方法，能够在限定的时间内对BNN进行比现有IP方法更广泛的输入扰动验证。
## 781. `cs.LG` - Density-Ratio Weighted Behavioral Cloning: Learning Control Policies from Corrupted Datasets [PDF](https://arxiv.org/pdf/2510.01479), [HTML](https://arxiv.org/abs/2510.01479)
### Authors
Shriram Karpoora Sundara Pandian,Ali Baheri
### Background
在线学习在安全关键应用中不可行时，离线强化学习(Offline RL)能够利用固定的训练集进行策略优化，这使得它非常适合此类应用场景。然而，这些数据集往往受到对抗式污染、系统错误或低质量样本的影响，导致标准行为克隆(BC)和离线RL方法的策略性能下降。
### Innovation
该论文提出了密度比加权行为克隆(Weighted BC)，这是一种鲁棒的模仿学习方法，使用一小部分经过验证、干净的核心集估计轨迹级别的密度比，通过二元判别器实现这一目标。对这些比值进行了限制，并将其用作行为克隆目标中的权重，以优先考虑干净专家的行为，同时压低或丢弃被破坏的数据，无需了解污染机制。该方法具有理论保证，确保在样本数有限的情况下收敛到清洁专家策略，且该保证与污染率无关。通过建立全面的评估框架，证明了Weighted BC方法即使是高污染比的情况下，也能保持接近最优的性能，并在各种污染协议下优于传统行为克隆、批次约束性Q学习(BCQ)和行为正则化演员-评论家(BRAC)。
### Conclusion
实验结果表明，即使在高度污染的数据集上，Weighted BC 方法也能保持接近最优的性能并优于传统方法。通过收集各种污染协议的数据，进一步验证了该方法的有效性和鲁棒性。
## 782. `cs.LG` - Flock: 一种基于随机游走学习的知识图谱基础模型 [PDF](https://arxiv.org/pdf/2510.01510), [HTML](https://arxiv.org/abs/2510.01510)
### Authors
Jinwoo Kim,Xingyue Huang,Krzysztof Olejniczak,Kyungbin Min,Michael Bronstein,Seunghoon Hong,İsmail İlkan Ceylan
### Background
本文研究了知识图谱（KGs）上的零样本链接预测问题，该问题要求模型泛化到新实体和新关系上。知识图谱基础模型（KGFMs）通过在节点和关系上保持对称性来解决这一任务，从前者结构属性中学习知识，并将这些知识转移到具有类似结构属性的新型图中。然而，传统的确定性对称性概念对KGFMs的表达能力施加了内在限制，使其难以区分结构性相似但语义不同的关系。
### Innovation
本文引入了概率节点-关系对称性，这在分布中保持对称性的同时，还包含了适当的随机化原则，以在推理中打破对称性。此外，本文提出了Flock，一种KGFM，它通过迭代采样随机游走、将它们编码为序列、使用序列模型嵌入并学习聚合节点和关系的表示，实现了概率节点-关系对称性，并作为一种特殊情况下异构不变链接级别的函数的通用逼近器。实验结果显示，Flock在以前KGFMs无法解决的新诊断数据集Petals上完美解决问题，并在54个来自不同领域的知识图谱上实现了实体和关系预测任务的最佳性能。
### Conclusion
Flock作为一个KGFM，通过在随机游走上的学习，成功解决了KGFMs在结构性相似但语义不同的关系区分上的局限性，并展示了在零样本链接预测任务上的强大能力。
## 783. `cs.LG` - 可执行的反事实推理：通过代码提升LLMs的因果推理能力 [PDF](https://arxiv.org/pdf/2510.01539), [HTML](https://arxiv.org/abs/2510.01539)
### Authors
Aniket Vashishtha,Qirun Dai,Hongyuan Mei,Amit Sharma,Chenhao Tan,Hao Peng
### Background
反事实推理是智能的一个重要标志，涉及三个步骤：从观察中推断潜在变量（演绎）、构建替代方案（干预）和预测结果（预测）。这一能力对于推进LLMs的因果理解至关重要，特别是在高风险领域如科学研究中的应用。然而，现有的评估LLMs反事实推理能力的努力往往忽略了演绎步骤，简化为干预推理，导致夸大了LLMs的表现。因此，需提出一种新的框架来解决这一问题。
### Innovation
提出了可执行反事实（Executable Counterfactuals）框架，通过代码和数学问题进行因果推理的系统化。该框架明确包含了反事实推理的三个步骤，并能够创建具有不同难度层次的合成数据，从而为评估和改进LLMs的推理能力开辟了新领域。研究成果表明，从干预推理到反事实推理，最新模型（如o4-mini和Claude-4-Sonnet）的准确性下降了25-40%。此外，通过强化学习而非监督微调来实现核心认知行为，并且能够使模型在新领域中泛化，对代码和数学问题都有显著提升。
### Conclusion
通过引入可执行反事实框架，我们能够更全面地评估和提高LLMs的反事实推理能力，在新领域中利用强化学习来提升模型的性能，从而显著增强了LLMs在处理复杂因果问题时的能力。
## 784. `cs.LG` - 使用受控释放提示绕过生产中的提示防护 [PDF](https://arxiv.org/pdf/2510.01529), [HTML](https://arxiv.org/abs/2510.01529)
### Authors
Jaiden Fairoze,Sanjam Garg,Keewoo Lee,Mingyuan Wang
### Background
随着大型语言模型（LLMs）的发展，确保人工智能的安全性和对齐变得至关重要。一种广泛采用的方法是提示防护，这是一种轻量级机制，用于过滤恶意查询，同时易于实现和更新。但这种方法存在一定的局限性，特别是在预防恶意输出方面。本文研究了一种新攻击，该攻击能够绕过这些提示防护，展示了其在现代LLM架构中的内在缺陷。
### Innovation
提出了新的攻击方法，该方法利用了提示防护与主LLM之间资源不对称性，通过编码提示防护无法解码但主模型可以执行的越狱命令。这种方法揭示了轻量级提示防护在现代LLM架构中的弱点，并强调了从阻止恶意输入转向防止恶意输出的防御策略的重要性。此外，文章还发现了其他关键对齐问题，包括版权数据提取、训练数据提取和恶意响应泄露等问题。
### Conclusion
本文揭示了轻量级提示防护在现代LLM架构中的脆弱性，并提出了新的攻击方法，说明了防御策略的转变需求，即从阻止恶意输入转向防止恶意输出。同时，还指出了其他需要关注的对齐问题。
## 785. `cs.LG` - 预测性偏好学习从人类干预 [PDF](https://arxiv.org/pdf/2510.01545), [HTML](https://arxiv.org/abs/2510.01545)
### Authors
Haoyuan Cai,Zhenghao Peng,Bolei Zhou
### Background
现有的交互式模仿学习方法主要关注于纠正代理在当前状态的动作错误，但未调整未来状态的行为，这可能更危险。因此，论文提出了一种新的方法，称为预测偏好学习从人类干预（PPL），该方法利用人类干预中隐含的偏好信号来指导未来展开的预测。
### Innovation
PPL 方法通过将每次人类干预扩展到 L 未来时间步骤（称为偏好视野），从而根据假设，代理在同一时间段内遵循相同的行为，人类也作出相同的干预。通过在这些未来状态上应用偏好优化，使专家的纠正传播到代理预计会探索的安全关键区域，从而显著提高学习效率并减少所需的人类示范。
### Conclusion
通过在自主驾驶和机器人操作基准上的实验评估，证明了该方法的效率和普适性。理论分析进一步表明，选择适当的偏好视野 L 可以在覆盖风险状态和标签正确性之间取得平衡，从而限制算法优化差距。该研究成果已提供演示和代码：输于此链接。
## 786. `cs.LG` - MIRA：在T2I扩散模型推理时间对齐中缓解奖励劫持 [PDF](https://arxiv.org/pdf/2510.01549), [HTML](https://arxiv.org/abs/2510.01549)
### Authors
Kevin Zhai,Utsav Singh,Anirudh Thatipelli,Souradip Chakraborty,Anit Kumar Sahu,Furong Huang,Amrit Singh Bedi,Mubarak Shah
### Background
扩散模型在根据文本提示生成图像方面表现出色，但生成的图像往往无法满足用户特定的标准，如美学评分。这种对齐通常需要进行细调，耗时较多。最近，通过噪声优化的推理时对齐已成为一种有效的替代方法，通过修改初始输入噪声来引导去噪过程生成高回报的图像。然而，这种方法可能会导致奖励劫持，即模型生成高评分的图像，但与原始提示显著偏离。噪声空间正则化不足，需要在图象空间中明确约束来防止奖励劫持。
### Innovation
提出了一种无需训练的推理时对齐方法MIRA（缓解奖励劫持），通过引入一个冻结的主干网络并加上基于分数的KL似然度正则化，约束输出分布，防止奖励增加同时分布偏离，从而避免了奖励劫持，并提供了缓解奖励劫持的机制图。此外，还提出了MIRA-DPO，将偏好优化映射到推理时间，使MIRA适用于非可微奖励而无需微调。
### Conclusion
在SDv1.5和SDXL模型上，使用多种奖励指标（美学、HPSv2、PickScore）以及公共数据集（例如动物-动物、HPDv2）进行实验，MIRA相比强基线实现了超过60%的胜率，同时保持了提示的一致性；机制图显示其奖励增加几乎无漂移，而DNO随着计算量增加则存在漂移现象。
## 787. `cs.LG` - 循环强化学习：更好的化学LLM的自我一致性训练 [PDF](https://arxiv.org/pdf/2510.01527), [HTML](https://arxiv.org/abs/2510.01527)
### Authors
Lecheng Kong,Xiyuan Wang,Yixin Chen,Muhan Zhang
### Background
大型语言模型（LLMs）在计算化学中展现出多功能性，能够处理反应预测和逆合成等双向任务。然而，现有的LLMs通常缺乏循环一致性，即它们可能能够成功描述一种分子，但却无法从生成的文字准确地重构出原来的结构。这种不一致性表明模型可能是在进行单向记忆的学习，而不是灵活的掌握。近期的研究发现，模型的循环一致性与主要任务的性能之间存在强烈的关联，因此将一致性设为目标可以提高模型的表现。
### Innovation
提出了循环强化学习（RTRL），这是一种新的框架，通过将反向路径的成功作为奖励信号来训练模型以提高其循环一致性。进一步提出了一种迭代版本，通过交替训练前向和反向映射，实现自我改进循环，特别适用于化学领域大量的未标注数据。
### Conclusion
实验结果表明，RTRL显著提升了监督学习、自监督学习和合成数据环境中化学LLM的性能和一致性。这项研究证明了循环一致性不仅是一个可欲的性质，而且是一个可训练的目标，为更加稳健和可靠的LLMs提供了一条新路径。
## 788. `cs.LG` - TimeSeriesScientist: 一个通用的人工智能代理进行时间序列分析 [PDF](https://arxiv.org/pdf/2510.01538), [HTML](https://arxiv.org/abs/2510.01538)
### Authors
Haokun Zhao,Xiang Zhang,Jiaqi Wei,Yiwei Xu,Yuting He,Siqi Sun,Chenyu You
### Background
时间序列预测在能源、金融、气候和公共卫生等领域中决策制定中至关重要。在实践中，预测者面对的是数量众多、质量和频率各异、且需要高昂人力进行预处理、验证和集成的时间序列，其主要成本并不在于建模，而在于繁琐的人工流程。现有的统计和深度学习模型通常针对特定数据集或领域，泛化能力较弱。因此，一种不需要大量人工干预的一般且跨领域的框架非常必要。
### Innovation
本文介绍了TimeSeriesScientist (TSci)，一种由LLM驱动的通用时间序列预测机构框架。该框架包含四个专一的机构：Curator进行由LLM引导的数据诊断，并利用外部工具对数据统计进行推理选择精准的预处理；Planner通过利用多模态诊断和自我规划来缩小模型选择的假设空间；Forecaster进行模型拟合和验证，并基于结果选择最优模型配置以及集成策略进行最终预测；Reporter则将整个过程综合为一个全面且透明的报告。TSci通过自然语言的透明推理和综合报告，将预测工作流转变为可解释且可扩展的系统。实验结果显示，TSci在8个标准基准测试上均优于统计和基于LLM的基线模型，其预测误差分别降低了10.4%和38.2%。此外，TSci提供的报告更加清晰和严谨，使得预测工作流更加透明和可解释。
### Conclusion
TSci是一个专注于一般时间序列预测的LLM驱动框架，通过四个专门的机构实现时间序列预测的自动化，大幅度提高了预测的准确性和透明度，并通过可解释的报告增强了流程的透明度和可扩展性。
## 789. `cs.LG` - 大规模干预数据下的贝叶斯因果发现 [PDF](https://arxiv.org/pdf/2510.01562), [HTML](https://arxiv.org/abs/2510.01562)
### Authors
Seong Woo Han,Daniel Duy Vo,Brielin C. Brown
### Background
因果关系推断是一个重要的但充满挑战的问题，特别是在通过卷积网络表示的一系列变量之间推断因果关系时。近年来，高通量基因组干预筛选的进步激发了利用干预数据改进模型识别的方法的发展。然而，现有的方法在大规模任务中仍表现不佳，并且无法量化不确定性。
### Innovation
本文提出了一种基于干预数据的贝叶斯因果发现方法——干预贝叶斯因果发现（IBCD）。该方法通过模型总因果效应矩阵的概率，而不是完整数据矩阵。此外，它在边之间放置了一个尖端-条形马赛克先验，并单独从观察数据中学习适应不同结构（无标度和Erdős-Rényi）的权重，将每条边视为潜在变量，从而实现不确定性意识的推理。
### Conclusion
通过广泛的模拟，我们展示了IBCD在结构重建方面优于现有基准方法。将IBCD应用于521个基因的CRISPR扰动（Perturb-seq）数据，我们通过边后验包含概率识别出稳健的图形结构。
## 790. `cs.LG` - 重新思考RLHF中的KL正则化：从价值估计到梯度优化 [PDF](https://arxiv.org/pdf/2510.01555), [HTML](https://arxiv.org/abs/2510.01555)
### Authors
Kezhao Liu,Jason Klein Liu,Mingtao Chen,Yiming Liu
### Background
该论文探讨了强化学习从人类反馈中（RLHF）采用KL散度损失来稳定训练并防止过拟合的问题。然而，在某些方法（如GRPO）中，KL损失的实现可能受到数值价值估计原则的指导，忽略了该术语作为优化损失的功能作用。为了分析这一问题，作者建立了一个统一框架，将两种看似不同的实现方式连接起来：将数学术语$k_n$作为策略分数函数的独立系数（$k_n$作为奖励）或作为传播梯度的直接损失函数（$k_n$作为损失）。
### Innovation
作者通过这个框架证明，传统的'$k_1$作为奖励'（如在PPO中）是Reverse KL（RKL）正则化原则性的损失。进一步揭示了在策略匹配条件下，'$k_2$作为损失'和'$k_1$作为奖励'在梯度上是等价的。此外，研究表明，最近采用的'$k_3$作为损失'（如在GRPO中）实际上是对原则性损失的第一阶、有偏近似。同时，作者指出常见的离策略'$k_n$作为损失'方法由于忽略了重要性采样而是偏倚的，并提出了一种原则性的修正方法，从而为KL正则化提供了全面的梯度基准理由，从而为更可靠和有效的RLHF系统铺平了道路。
### Conclusion
该研究提供了关于选择和正确实现KL正则化的全面梯度理由，为更加稳健和有效的RLHF系统指明了方向。
## 791. `cs.LG` - NVIDIA AI Aerial: AI-Native Wireless Communications [PDF](https://arxiv.org/pdf/2510.01533), [HTML](https://arxiv.org/abs/2510.01533)
### Authors
Kobi Cohen-Arazi,Michael Roe,Zhen Hu,Rohan Chavan,Anna Ptasznik,Joanna Lin,Joao Morais,Joseph Boccuzzi,Tommaso Balercia
### Background
6G技术带来了一种新的范式转换，要求在蜂窝网络的软件栈中无缝集成数字信号处理（DSP）和机器学习（ML）。这种转变让现代网络生命周期更接近于AI系统，其中模型和算法迭代地在相邻环境中进行训练、模拟和部署。因此，本文旨在提出一种稳健的框架，将基于Python的算法编译为可在NVIDIA GPU上运行的可执行文件。
### Innovation
本文提出了一种框架，将基于Python的算法编译为可在NVIDIA GPU上运行的形式。这种框架确保了效率、灵活性和在NVIDIA GPU上达到最高性能。更重要的是，它展示了如何通过卷积神经网络（CNN）训练Python中的通道估计功能，并在数字孪生和实时测试平台中进行了应用演示，以此证明其高性能和高效性。
### Conclusion
本文提出的方法在NVIDIA AI Aerial平台上的实现为基础，在下一代蜂窝系统中规模化集成AI/ML模型提供了坚实的基础，并对于实际化未来6G网络中本源智能的愿景至关重要。
## 792. `cs.LG` - 从监督到探索：蛋白质语言模型在强化学习过程中学到了什么？ [PDF](https://arxiv.org/pdf/2510.01571), [HTML](https://arxiv.org/abs/2510.01571)
### Authors
Hanqun Cao,Hongrui Zhang,Junde Xu,Zhou Zhang,Lingdong Shen,Minghao Sun,Ge Liu,Jinbo Xu,Wu-Jun Li,Jinren Ni,Cesar de la Fuente-Nunez,Tianfan Fu,Yejin Choi,Pheng-Ann Heng,Fang Wu
### Background
蛋白质语言模型（PLMs）通过大规模预训练和可扩展的架构，促进了计算蛋白质科学的进步。同时，强化学习（RL）方法扩展了探索范围，使蛋白设计中的多目标优化精确化。然而，尚不清楚RL能否推动PLMs突破预训练先验，揭示隐藏的序列-结构-功能规则。本文通过在四个领域中将RL与PLMs相结合进行研究：抗菌肽设计、激酶变体优化、抗体工程和逆折叠，来探讨这一问题。
### Innovation
该研究通过在蛋白质设计的多个应用场景中结合RL与PLMs，探讨了RL在揭示未被监督学习捕捉到的潜在能力方面的作用。研究发现，RL能够提升采样效率并揭示新的模型能力。RL的表现受到三个因素的交互影响：任务空间、奖励的真实性以及政策容量。这为蛋白质设计中的RL应用提供了实用的指导：优先进行奖励建模和校准，根据任务难度匹配算法和正则化强度，分配政策容量以获得最大的边际收益。
### Conclusion
RL在准确和信息丰富的奖励以及充裕的政策容量下，可以显著提升成功的概率和样本效率。当奖励不准确或政策容量受限时，随着探索而带来的改进会趋于饱和。研究结果对蛋白质设计中RL的应用有重要的指导意义。
## 793. `cs.LG` - TetriServe: 高效的异构图像生成DiT服务 [PDF](https://arxiv.org/pdf/2510.01565), [HTML](https://arxiv.org/abs/2510.01565)
### Authors
Runyu Lu,Shiqi He,Wenxuan Tan,Shenggui Li,Ruofan Wu,Jeff J. Ma,Ang Chen,Mosharaf Chowdhury
### Background
扩散变换器（DiT）模型在生成高质图像方面表现出色，但要在严格的服务级别目标（SLO）下服务这些模型极具挑战性，特别是对于高分辨率。现有服务系统使用固定阶段并行性，对于具有混合分辨率和截止时间的异构工作负载来说，效率低下，导致GPU利用率低且SLO实现率低。
### Innovation
我们提出了步级序列并行性策略，根据请求的截止时间动态调整并行度。我们实现了TetriServe，这是一种DiT服务系统，采用这种方法以实现高效图像生成。具体来说，TetriServe引入了一种新颖的基于轮次的调度机制，以提高SLO实现率：(1) 将时间离散化为固定轮次，使面向截止时间的调度更加可行，(2) 在步骤级别调整并行度，以最小化GPU小时消耗，(3) 联合打包请求以最小化延迟完成时间。
### Conclusion
在最新DiT模型的广泛测评中，TetriServe在不牺牲图像质量的情况下实现了比现有解决方案高达32%的SLO实现率。
## 794. `cs.LG` - 后验塌陷作为变分自编码器中的相变现象 [PDF](https://arxiv.org/pdf/2510.01621), [HTML](https://arxiv.org/abs/2510.01621)
### Authors
Zhen Li,Fan Zhang,Zheng Zhang,Yu Chen
### Background
研究者们考察了变分自编码器（VAEs）中的后验塌陷现象，并将其解释为由数据结构和模型超参数共同控制的相变过程。通过分析与后验塌陷相关的平凡解的稳定性，确定了一个关键的超参数阈值，这个边界定义了从有意义的潜在空间推断过渡到后验塌陷的状态。这一过程还被通过KL散度的跃变现象来刻画，表明后验塌陷不仅仅是优化过程中的失败，而是由数据结构与变分约束的相互作用引发的相变现象。这项研究提供了对深层生成模型的训练能力和表示能力的新见解。
### Innovation
通过统计物理的视角，研究揭示了后验塌陷不仅是优化问题，更是由数据结构和模型超参数共同作用的相变现象。提出了一个关键的超参数阈值，区分了有意义的潜在空间推断和后验塌陷，这在合成数据和现实数据集上得到了验证。研究结果表明，相变的出现可能帮助解释变分自编码器的表现，并提供了对这些模型进行改进的新途径。
### Conclusion
研究结果证明，后验塌陷不仅仅是在优化过程中失败的表现，而是由数据结构与变分约束之间相互作用产生的相变现象。这一发现提供了关于变分自编码器训练能力和表示能力的新见解。研究中确定的关键超参数阈值，有助于研究者更好地控制后验塌陷的发生，提高模型的表现。
## 795. `cs.LG` - 正确思考：通过适应性注意力压缩减轻过度思考与不足思考的学习 [PDF](https://arxiv.org/pdf/2510.01581), [HTML](https://arxiv.org/abs/2510.01581)
### Authors
Joykirat Singh,Justin Chih-Yao Chen,Archiki Prasad,Elias Stengel-Eskin,Akshay Nambi,Mohit Bansal
### Background
现有的思考模型通过扩大测试阶段的计算规模来解决复杂的推理任务，但这需要与任务难度相匹配的计算分配。不足思考会导致在较难问题上的错误，因为缺乏足够的推理步骤；而过度思考则可能导致不必要的推理步骤，即便已达到正确的中间解。这种现象被称为不适应性，即模型未能根据问题难度适当调节响应长度。为解决不适应性，并平衡不足思考和过度思考，该研究提出了一种在线后训练RL方法TRAAC（Think Right with Adaptive, Attentive Compression），利用模型在长推理轨迹中的自我注意来识别重要步骤并剪枝冗余步骤。此外，TRAAC还估计任务难度，并将其纳入训练奖励中，从而学习根据示例难度分配推理预算。
### Innovation
提出了一种名为TRAAC（Think Right with Adaptive, Attentive Compression）的在线后训练RL方法，通过自我注意机制识别重要步骤并剪枝冗余步骤，估计任务难度并通过调整训练奖励来分配理计算预算。这种方法提高了准确性，减少了推理步骤，实现了适应性思考，相较于基本模型和其他基于RL的基线方法表现更优。
### Conclusion
在AIME、AMC、GPQA-D、BBEH等任务上，TRAAC（Qwen3-4B）相比于基线模型，绝对准确率提高了8.4%，推理长度减少了36.8%；相比于最优的基于RL的基线模型，准确率提高了7.9%，推理长度减少了29.4%。此外，结果显示TRAAC在非数学数据集GPQA-D、BBEH和OptimalThinkingBench上也显示出了准确性和效率的提高，证明了其强大的泛化能力。进一步分析验证了TRAAC可以根据任务难度提供精细调整的思考预算，并且任务难度的校准与基于注意力的压缩相结合可以在各种任务上实现收益。
## 796. `cs.LG` - 通过组合水印检测水印LLM输出的后生成编辑 [PDF](https://arxiv.org/pdf/2510.01637), [HTML](https://arxiv.org/abs/2510.01637)
### Authors
Liyan Xie,Muhammad Siddeek,Mohamed Seif,Andrea J. Goldsmith,Mengdi Wang
### Background
水印已成为保护专有语言模型的关键技术，能够区分AI生成和人类撰写的文本。然而，在许多实际应用场景中，LLM生成的内容可能经过后生成的修改，如人工修订或欺诈性攻击，这使得检测和定位这种修改变得至关重要。
### Innovation
该研究提出了一种组合模式基水印框架，将词汇划分为不相交子集，并在生成过程中通过强制这些子集上的确定性组合模式嵌入水印。该框架还伴随一个全局统计数据用于检测水印，并设计了轻量级的局部统计数据来标记和定位潜在的编辑。此外，该研究还引入了两类特定任务的评估指标：I类错误率和检测准确性，并在多种编辑场景下评估了开源LLM的方法性能，显示出强大的证据表现和编辑定位能力。
### Conclusion
该研究展示了通过组合水印检测LLM输出后生成编辑的有效性和优越性，并提出了新的评估指标以进一步提升水印技术和编辑检测的准确性。
## 797. `cs.LG` - Demystifying Synthetic Data in LLM Pre-training: A Systematic Study of Scaling Laws, Benefits, and Pitfalls [PDF](https://arxiv.org/pdf/2510.01631), [HTML](https://arxiv.org/abs/2510.01631)
### Authors
Feiyang Kang,Newsha Ardalani,Michael Kuchnik,Youssef Emad,Mostafa Elhoushi,Shubhabrata Sengupta,Shang-Wen Li,Ramya Raghavendra,Ruoxi Jia,Carole-Jean Wu
### Background
Large Language Models (LLMs) rely heavily on high-quality training data for scaling, but such data is often scarce. Synthetic data techniques present a potential solution to overcome these data limitations. This paper investigates the effectiveness of synthetic data in LLM pre-training through a large-scale empirical analysis.
### Innovation
The study conducts a systematic investigation using a unified protocol and scaling laws, comparing the use of natural web data, diverse synthetic types (rephrased text, generated textbooks), and mixed data. The findings suggest that specific ratios of synthetic data in the training mixtures are beneficial depending on the model size and data budget, with notable performance improvements in certain configurations.
### Conclusion
The results provide mixed evidence on the effects of synthetic data on LLM pre-training, showing that while using rephrased synthetic data alone does not offer a speed advantage, mixing it with natural data can significantly speed up training. The use of textbook-style synthetic data alone tends to result in higher losses, especially at smaller data budgets. The study concludes that empirical evidence suggests approximately 30% synthetic data in the training mixture is 'good' for rephrased synthetic data, and larger generator models do not necessarily yield better performance than ~8B-param models.
## 798. `cs.LG` - 使用并行磁隧道结真随机性保护生成式人工智能 [PDF](https://arxiv.org/pdf/2510.01598), [HTML](https://arxiv.org/abs/2510.01598)
### Authors
Youwei Bao,Shuhan Yang,Hyunsoo Yang
### Background
目前在生成式人工智能（GAI）模型中使用的确定性伪随机数生成器（PRNGs）会产生可预测的模式，这些模式容易被攻击者利用。传统防御这些漏洞的方法往往伴随着显著的能源和延迟开销。这个问题使得保障GAI的安全性变得困难。
### Innovation
本文提出了一种将基于自旋转移矩磁隧道结（STT-MTJs）的硬件生成的真随机位嵌入到生成式人工智能模型中的解决方案。通过高并行、FPGA辅助的原型计算系统，可以以兆比特/秒的速度生成真随机数，经过现场操作后通过NIST随机性测试，同时拥有极小的开销。将这些硬件随机位整合到以CIFAR-10训练的生成对抗网络（GAN）中，可将不安全的输出减少18.6倍，对比于基于低质量随机数生成器（RNG）的基线情况。此系统具有纳秒切换速度、高能效和可扩展性，STT-MTJ系统有潜力扩展到超过10^6个并行单元，实现每秒兆比特以上的吞吐量，适合大型语言模型的抽样。这表明自旋电子随机数生成器是下一代GAI系统实用的安全组件。
### Conclusion
本文提出的基于STT-MTJ的真随机数生成器具有广泛的潜力，可以用于提高大型生成式人工智能系统的安全性，解决了基于传统PRNG的模型所面临的安全挑战。
## 799. `cs.LG` - 无代理ADMM：打破LLM稀疏性的局限性 [PDF](https://arxiv.org/pdf/2510.01650), [HTML](https://arxiv.org/abs/2510.01650)
### Authors
Kwanhee Lee,Hyeondo Jang,Dongyeop Lee,Dan Alistarh,Namhoon Lee
### Background
神经网络剪枝是一种有潜力减少大型语言模型（LLMs）的计算和内存需求的技术。然而，由于传统方法难以在保持较高模型准确性的前提下超过50-60%的稀疏度，研究进展有所停滞。现有方法多依赖于代理目标公式，导致了性能上的限制和瓶颈。该研究通过对当前实践的多个限制进行分析，提出了一种名为'Elsa'的原理性且有效的方法，该方法通过使用基于ADMM的标准约束优化技术，在保持高模型精度的情况下实现了高达90%的极端稀疏度。
### Innovation
该研究提出了一种称为'Elsa'的方法，通过直接使用基于ADMM的标准约束优化技术克服了依赖代理目标公式所带来的限制，从而实现了在90%稀疏度下仍保持高模型精度的目标。此外，还提出了一种名为'Elsa_L'的量化的版本，适用于极其大型的模型，并提供了理论收敛保证。该方法在多种模型和规模的实验中取得了显著的性能提升。
### Conclusion
研究结果展示了在LLM稀疏性上的重大进展，并暗示在现有探索较少的方向中仍存在进一步改进的潜力。该方法为LLM的进一步发展打开了新的可能性。
## 800. `cs.LG` - 源域无监督跨域持续学习 [PDF](https://arxiv.org/pdf/2510.01649), [HTML](https://arxiv.org/abs/2510.01649)
### Authors
Muhammad Tanzil Furqon,Mahardhika Pratama,Igor Škrjanc,Lin Liu,Habibullah Habibullah,Kutluyil Dogancay
### Background
现有的跨域持续学习方法虽然成功解决了许多涉及领域变化的流式任务，但它们需要完全标记的源域数据，这在隐私受限的环境中阻碍了其可行性。该研究致力于解决源域无监督的跨域持续学习问题，彻底禁止使用源域样本。
### Innovation
提出了没有排练的频率感知动态提示合作（REFEREE）方法，结合了预训练模型和大规模视觉语言模型的协同作用，通过频率感知提示技术解决了低频成分的增强和高频成分的抑制问题，生成频率感知的增强样本，增强了模型的稳定性。此外，通过不确定性感知的加权策略和核线性判别分析（KLDA）方法解决了灾难性遗忘问题。
### Conclusion
严格的数值研究证实了该方法的优势，即使在可访问源域样本的情境下，其性能也显著优于现有方法。
## 801. `cs.LG` - 不对称近端策略优化：微型批评者增强LLM推理 [PDF](https://arxiv.org/pdf/2510.01656), [HTML](https://arxiv.org/abs/2510.01656)
### Authors
Jiashun Liu,Johan Obando-Ceron,Han Lu,Yancheng He,Weixun Wang,Wenbo Su,Bo Zheng,Pablo Samuel Castro,Aaron Courville,Ling Pan
### Background
近年来，对于大型语言模型（LLM）的强化学习（RL）方法，如RL4LLM，采取了回避显性批评者的做法，转而使用平均优势基线。这一转变主要是出于实用性的考虑：传统的价值函数在大规模LLM上训练成本高昂且通常在稀疏奖励和长推理时间下表现不佳。
### Innovation
本文从架构角度重新审视了这一瓶颈问题，并引入了不对称近端策略优化（AsyPPO），这是一种简单且可扩展的框架，能够恢复批评者的角色，同时保持高效性。AsyPPO采用一组轻量级的mini-critics，每个mini-critics负责独立的提示片段。这种方法鼓励多样性和校准性，减少了价值估计偏差。此外，AsyPPO利用批评者之间的不确定性来细化策略更新：（i）在批评者意见一致且梯度对学习信号贡献不大的状态下，遮蔽优势；（ii）通过熵正则化过滤高分歧状态，抑制无意义的探索。
### Conclusion
AsyPPO在仅使用5000个样本的开源数据集上进行训练，各基准测试中比经典PPO、GRPO等强基线策略具有更高的学习稳定性和性能，分别在Qwen3-4b-Base上提高了超过6%，在Qwen3-8b-Base和Qwen3-14b-Base上提高了约3%。这些结果突显了为了可扩展和高效的算法，架构创新的重要性。
## 802. `cs.LG` - 超越简单融合：基于适应性门控融合的鲁棒多模态情感分析 [PDF](https://arxiv.org/pdf/2510.01677), [HTML](https://arxiv.org/abs/2510.01677)
### Authors
Han Wu,Yanming Sun,Yunhe Yang,Derek F. Wong
### Background
多模态情感分析（MSA）通过融合来自多种模态（例如文本、音频、视觉）的信息来提高情感预测。然而，简单融合技术往往未能充分考虑各模态质量的差异，如噪声、缺失或语义冲突等情况。这些差异导致了性能不佳，尤其是在辨别细微的情感差异时更为明显。这项工作旨在通过引入一种基于信息熵和模态重要性的双重门控融合机制的学习型特征加权方法来解决这一问题。
### Innovation
提出了一种简单而有效的自适应门控融合网络（AGFN，Adaptive Gated Fusion Network），该网络通过双重门控融合机制自适应调整特征权重。这种机制可以减轻噪声模态的影响，优先处理经过单模态编码和跨模态交互后的信息性线索。实验表明，AGFN在CMU-MOSI和CMU-MOSEI数据集上的准确率显著优于强基线，能够有效识别细微的情感差异并保持鲁棒性。特征表示的可视化分析进一步证明，AGFN通过减少特征位置与预测误差之间的相关性，提高了泛化能力，从而减少了对特定位置的依赖，形成了更稳健的多模态特征表示。
### Conclusion
在CMU-MOSI和CMU-MOSEI数据集上的实验结果显示，AGFN在准确性上显著优于强基线，有效地识别了细微的情感，并保持了鲁棒性。特征表示的可视化分析还表明，AGFN通过减少特征位置与预测误差之间的相关性，增强了泛化能力，减少了对特定位置的依赖，从而形成了更稳健的多模态特征表示。
## 803. `cs.LG` - CAT：几何感知学习的曲率自适应变换器 [PDF](https://arxiv.org/pdf/2510.01634), [HTML](https://arxiv.org/abs/2510.01634)
### Authors
Ryan Y. Lin,Siddhartha Ojha,Nicholas Bai
### Background
Transformer在各种领域表现强大，但其注意力机制隐含地假设欧几里得几何，这限制了其在非欧几里得结构数据上的效果。虽然最新的基于双曲空间和球面空间的扩展在处理分层和循环模式方面显示出潜力，但它们要求事先确定单一几何结构，这在数据具有混合几何属性时降低了灵活性。
### Innovation
提出了一种新颖的曲率自适应变换器（CAT），它通过轻量级、可微的门机制动态学习每令牌在三种几何注意力分支间的路由。与固定几何结构的方法不同，CAT能够实现自适应几何专业化，根据令牌的局部关系结构将令牌路由到适当的曲率。路由网络提供可解释的曲率偏好，而每条分支采用针对其各自流形优化的几何特定操作。
### Conclusion
在知识图完成基准测试（FB15k-237，WN18RR）中，CAT在MRR和Hits@10方面相较于固定几何结构基准提高了约10%的性能，且具有较少的开销（参数增加5%，推理时间相当）。结果表明，学习到的几何适应性在复杂关系推理方面优于任何单一固定的几何结构，从而证明CAT作为语言、视觉和多模态领域混合几何架构的可扩展且具解释性的基础具有潜力。
## 804. `cs.LG` - 通过分层次统一宽容度潜含量化学习时间序列表示 [PDF](https://arxiv.org/pdf/2510.01658), [HTML](https://arxiv.org/abs/2510.01658)
### Authors
Amin Jalali,Milad Soltany,Michael Greenspan,Ali Etemad
### Background
该研究关注时间序列数据分析中的表示学习问题，尤其是在多变数据中学习强鲁棒表示以改善时间和实例级别的对比。现有的方法往往忽略了在嵌入空间中平衡统一性和宽容性的重要性，这限制了时间序列特征表示的有效性与应用性能。本文直接针对这一问题提出了TimeHUT方法，旨在通过同时处理实例级和时间信息，以及通过温度调度和角余弦损失来实现统一性与宽容性的有效平衡，以提高时间序列数据的表示能力。
### Innovation
TimeHUT方法通过层次结构来学习时间序列中的实例级和时间信息，同时引入温度调度机制和基于角余弦的距离损失来平衡嵌入空间中的统一性和宽容性，从而增强了时间序列中正样本的关联性和负样本的分离度，提高了时间序列数据处理的任务性能，尤其是在分类和异常检测任务中表现尤为突出。
### Conclusion
TimeHUT方法在多个时间序列数据集上的广泛实验显示，其在分类任务中显著优于先前方法，在异常检测任务中也能取得具有竞争力的结果。此外，详细的敏感性和消融研究进一步验证了该方法的有效性和核心组件的重要性。
## 805. `cs.LG` - PASTA: 一种统一的离线产品组合学习框架 [PDF](https://arxiv.org/pdf/2510.01693), [HTML](https://arxiv.org/abs/2510.01693)
### Authors
Juncheng Dong,Weibin Mo,Zhengling Qi,Cong Shi,Ethan X. Fang,Vahid Tarokh
### Background
研究在没有任何先验知识的情况下，基于历史客户选择数据来确定最优产品组合的一类广泛优化问题。在产品组合优化的组合特征下，现有数据往往覆盖不足，这使得设计有效的解决方案变得困难。这项研究旨在解决这一问题，提出了一个名为PASTA的新框架，通过悲观原则来达到在通用选择模型下预期收益的最优性。PASTA框架不要求线下数据分布包含所有可能的产品组合，只需包含最优的产品组合即可。
### Innovation
提出了PASTA框架，该框架利用悲观原则，在通用选择模型下实现了预期收益最优性。PASTA只需要在线下数据分布中包含最优的产品组合，而不需要覆盖所有可能的产品组合。此外，这项研究首次为广泛使用的多项式对数模型和嵌套对数模型下的离线下单组合优化建立了有限样本后悔界，并证明PASTA在样本和模型复杂度上是 minimax 最优的。
### Conclusion
通过数值实验，我们进一步验证了该方法比现有基线方法更优秀。
## 806. `cs.LG` - 使用层次最优传输在模型层和脑区之间进行表征对齐 [PDF](https://arxiv.org/pdf/2510.01706), [HTML](https://arxiv.org/abs/2510.01706)
### Authors
Shaan Shah,Meenakshi Khosla
### Background
现有的代表相似性方法通过对每个网络层独立地找到其最佳匹配层，生成不对称的结果，缺乏全局对齐得分，并且难以处理不同深度的网络。这种限制来源于忽略了全局激活结构并限制映射为严格的层对层对应关系。
### Innovation
我们提出了一种统一框架——层次最优传输（HOT），它可以联合推断出软的全局一致的层到层耦合和神经元级别的运输计划。HOT 允许源神经元向多个目标层分配质量，同时在满足边缘约束的情况下最小化总运输成本。这不但为整个网络对比提供了一个单一的对齐得分，还能通过质量分配自然处理深度不匹配。
### Conclusion
我们在视觉模型、大型语言模型和人类视觉皮层记录方面评估了HOT，结果表明HOT在对齐质量上超越或与标准成对匹配相当。HOT揭示了平滑、精细层次对应关系：早期层映射到早期层，深层层保持相对位置，深度不匹配通过多个层间的质量分布来解决。这些结构化的模式自然地从全局优化中产生，而不是被强加的，而在贪婪的层状方法中是不存在的。因此，HOT 使得在结构或深度不同的网络之间进行更丰富、更具解释性的比较成为可能。
## 807. `cs.LG` - 支持基底：超越有界条目快速注意力 [PDF](https://arxiv.org/pdf/2510.01643), [HTML](https://arxiv.org/abs/2510.01643)
### Authors
Maryam Aliakbarpour,Vladimir Braverman,Junze Yin,Haochen Zhang
### Background
在大规模语言模型（LLMs）中，softmax注意机制的二次复杂性成为其扩展的主要瓶颈。[Alman and Song, NeurIPS 2023] 提出了一种次二次注意近似算法，但该算法仅在受限制的有界条目假设下有效。由于该假设在实际情况中很少成立，因此其对现代LLMs的实际应用有限。现有方法遭遇的主要挑战在于如何高效且准确地近似注意力机制，特别是在数据分布不局限在有界条目时。已有研究表明，查询和键矩阵的条目表现出亚高斯行为，这为提出一种超越有界条目的高效注意力近似方法提供了基础。
### Innovation
本文介绍了一种新的框架——支持基底分解，用于有效近似注意力机制，超越了有界条目的限制。该方法利用查询和键矩阵条目的亚高斯特性，将大型和小型条目分开处理，通过精确计算稀疏部分和多项式近似密集部分来实现高效计算。此外，该方法提供了严格的理论保证，证明了次二次运行时间，并通过多阈值设置消除了所有假设分布的限制。该研究还首次提供了多项式注意力在实验上成功的理论依据，表明softmax注意力可以通过组合多个带有素引的多项式注意力进行近似。
### Conclusion
本文通过提出支持基底分解框架，解决了大规模语言模型中softmax注意力的效率问题。通过理论分析和实验验证，该方法不仅缩短了注意力机制的计算时间，还拓展了注意力近似应用的范围，为大规模语言模型的进一步发展奠定了基础。
## 808. `cs.LG` - 基于Shapley值的Kolmogorov-Arnold网络移位不变属性评分 [PDF](https://arxiv.org/pdf/2510.01663), [HTML](https://arxiv.org/abs/2510.01663)
### Authors
Wangxuan Fan,Ching Wang,Siqi Li,Nan Liu
### Background
对于许多实际应用而言，理解特征与结果之间的关系与高预测准确性同样重要。传统的神经网络虽然在预测方面表现出色，但它们的黑盒性质使得其中的函数关系难以理解。Kolmogorov-Arnold网络（KAN）通过在边缘上使用可学习的样条激活函数解决了这个问题，使其能够在保持竞争力的同时恢复符号表示。然而，KAN的架构提出了独特的网络修剪挑战，传统的基于幅度的方法由于对输入坐标偏移的敏感性变得不可靠。
### Innovation
我们提出了一个基于Shapley值归因的修剪框架ShapKAN，通过移位不变的方法评估节点的重要性。不同于基于幅度的方法，ShapKAN量化了每个节点的实际贡献，确保在输入参数化变化时的重要性排名一致。广泛的数据集实验表明ShapKAN在保持真实节点重要性的同时实现了有效的网络压缩。这种方法增强了KAN的解释性优势，使其更适合在资源受限的环境中部署。
### Conclusion
我们的方法在保持KAN解释性优势的同时，还允许有效地压缩网络，从而支持在资源受限的环境中应用KAN。
## 809. `cs.LG` - ActiNet: 使用自我监督深度学习识别手腕佩戴加速度计的活动强度 [PDF](https://arxiv.org/pdf/2510.01712), [HTML](https://arxiv.org/abs/2510.01712)
### Authors
Aidan Acquah,Shing Chan,Aiden Doherty
### Background
在大规模流行病学研究中，通过被动收集的手腕加速度计数据识别可靠且精确的人体活动（HAR）模型是至关重要的，这些研究旨在探究体力活动与健康结果之间的关联。现有研究表明，自我监督学习在提高HAR模型性能方面具有显著潜力，但尚未明确这些模型与隐马尔可夫模型（HMM）结合使用时的效果及其对每日活动强度组成的预测影响。
### Innovation
本研究利用ActiNet模型，这是一种自我监督的18层修改版ResNet-V2模型，结合了HMM平滑技术用于分类活动强度标签。研究结果表明，ActiNet模型在交叉验证下的平均宏F1分数为0.82，平均Cohen's kappa分数为0.86，显著优于现有文献中建立的随机森林（RF）+HMM模型，后者分别为0.77和0.81。这些发现的一致性表明，ActiNet模型适用于未来流行病学研究中从手腕加速度计数据中提取活动强度标签。
### Conclusion
研究结果鼓励在未来流行病学研究中使用ActiNet模型对来自手腕加速度计的数据进行活动强度标签提取。
## 810. `cs.LG` - 基于深度神经网络的企业地点选择模型 [PDF](https://arxiv.org/pdf/2510.01723), [HTML](https://arxiv.org/abs/2510.01723)
### Authors
Tanay Rastogi,Anders Karlström
### Background
传统的离散选择模型（DCMs）尽管被广泛用于分析工作场所位置决策，但在准确反映个体决策过程方面存在挑战。本文通过引入深度神经网络（DNN）方法来建模工作场所位置选择，以期更好地理解复杂的决策模式并取得优于传统离散选择模型的成果。
### Innovation
本文提出了基于深度神经网络的方法，用于建模工作场所位置选择，这种方法在理解复杂的决策模式和结果准确性方面优于传统的离散选择模型。
### Conclusion
研究表明，深度神经网络在工作场所位置选择模型中显示出显著潜力。尽管两种模型都能有效复制工作机会对企业地点选择的影响，但在某些方面，DNN的性能优于DCM。然而，DCM在评估个体属性对企业距离的影响方面与数据更加吻合。特别地，DCM在较短距离上表现出色，而DNN在较长距离上与数据和DCM的表现相当。这些发现强调了根据具体应用要求选择合适模型的重要性。
## 811. `cs.LG` - 使用基分解加速注意力 [PDF](https://arxiv.org/pdf/2510.01718), [HTML](https://arxiv.org/abs/2510.01718)
### Authors
Jialin Zhao
### Background
注意力是大型语言模型（LLMs）和视觉-语言模型（VLMs）中的一个核心操作。现有的系统优化，如FlashAttention，主要侧重于输入/输出感知的系统优化，但这些方法提供的加速是基于特定硬件架构的，缺乏通用适用性。
### Innovation
提出了BD注意力（BDA），这是一种基于基分解（BD）的无损算法重写注意力机制的方法。BDA通过简单的矩阵身份将多头投影重构为紧凑的形式，同时保持输出的准确性。与现有方法不同，BDA提供了一种数学保证的加速，这种加速与硬件架构无关。通过实验证明，一种名为DeepSeek-V2-Lite（16B，FP16）的模型在进行4秒的在线准备后，不需重新训练，就能实现32%的键/值投影速度提升，减少25%的权重，同时增加的总体性能下降几乎可以忽略不计，即在FP16下仅0.02%，FP32下0.0004%.
### Conclusion
BDA是首个理论上无损的注意力加速方法，能够与现有的工程级优化方法形成互补。证明了其对于注意力机制无损加速的可行性，提供了架构无感的加速能力，并且在不影响模型表现的情况下实现了具体性能上的提升。代码已经开源。
## 812. `cs.LG` - 有限时间界下的分布鲁棒TD学习与线性函数近似 [PDF](https://arxiv.org/pdf/2510.01721), [HTML](https://arxiv.org/abs/2510.01721)
### Authors
Saptarshi Mandal,Yashaswini Murthy,R. Srikant
### Background
分布鲁棒强化学习（DRRL）主要关注在模型不确定性下设计能够实现良好性能的策略。现有的稳健TD学习收敛保证主要适用于表格MDP或在使用函数逼近时依赖于严格的折扣因子假设。该论文旨在提供一种在使用线性函数逼近时的稳健TD学习算法，其鲁棒性通过总量距和Wasserstein-l距离不确定性集进行测量。此外，该算法无需生成MDP的访问权即可实现模型自由性。该研究填补了稳健RL算法的实证成功与非稳健算法的非渐近保证之间的关键空白，同时，该论文提出的观点也相对容易推广至函数逼近下的稳健Q学习算法。
### Innovation
首次提出了线性函数逼近下的有限时间鲁棒TD学习算法，该算法的鲁棒性基于总量距和Wasserstein-l距离不确定性集进行测量，并且算法本身是模型自由且不需要生成MDP访问权的。该论文建立了该算法在获得$tilde{O}(1/text{ε}^2)$样本复杂度下准确性达到$text{ε}$值估计的样本复杂度结果，这在有限时间范围内提供更具体和更实际的保证，同时算法结合了两阶段随机逼近更新和外部目标网络更新机制。这一结果填补了现有理论与实际应用之间的重要空白。
### Conclusion
该研究不仅填补了稳健RL算法在有限时间范围内的理论空白，同时也将关键思想扩展应用于函数逼近下的稳健Q学习，提供了一种在模型不确定性和函数逼近条件下的稳健学习方法。
## 813. `cs.LG` - 学习逆问题的正则化函数：一项比较研究 [PDF](https://arxiv.org/pdf/2510.01755), [HTML](https://arxiv.org/abs/2510.01755)
### Authors
Johannes Hertrich,Hok Shing Wong,Alexander Denker,Stanislas Ducotterd,Zhenghan Fang,Markus Haltmeier,Željko Kereta,Erich Kobler,Oscar Leong,Mohammad Sadegh Salehi,Carola-Bibiane Schönlieb,Johannes Schwab,Zakhar Shumaylov,Jeremias Sulam,German Shâma Wache,Martin Zach,Yasi Zhang,Matthias J. Ehrhardt,Sebastian Neumayer
### Background
近年来，各领域涌现出多种用于解决成像逆问题的自学习正则化框架。这些框架不仅提供了灵活的模型设计，还赋予了深刻的数学洞察力。然而，由于缺乏模块化实现，这些方法在架构设计和训练策略上的差异使得直接比较变得非常困难。本文通过收集和统一现有代码，提供了一个共同的框架，使得系统性的比较成为可能，并明确指出了各个方法的优点和局限性，为它们未来的发展提供了有价值的见解。同时，还提供了各种方法简洁而实用的描述，配合具体的指南以便执行和优化这些方法。
### Innovation
本文通过创建一个统一的框架，将不同方法整合在一起，实现对它们的系统性比较。这克服了由于非模块化实现造成的难以直接比较的挑战。通过这种方法，本文揭示了各种方法的优点和局限性，提供给研究者和实践者重要的见解，关于这些方法的未来潜在应用。此外，还提供了每个方法的简洁描述及实用指南，增加了这些方法的实际可操作性.
### Conclusion
本文通过创建一个统一的框架，使得多种不同架构和训练策略的学习正则化方法能够系统性地进行比较。这不仅突显了各种方法的优势和局限性，加剧深入理解它们的潜在应用，还提供了关于如何最佳利用这些技术的实用指导，为未来的研究和发展提供了宝贵的资源。
## 814. `cs.LG` - 非典范哈密顿动力学的神经网络方法及其长期模拟 [PDF](https://arxiv.org/pdf/2510.01788), [HTML](https://arxiv.org/abs/2510.01788)
### Authors
Clémentine Courtès(IRMA, MACARON),Emmanuel Franck(MACARON),Michael Kraus(IPP),Laurent Navoret(IRMA, MACARON),Léopold Trémant(LML)
### Background
以往的研究主要关注非典范哈密顿动力学的学习，分别通过基于势的架构和降阶变分积分器进行建模，但这些方法在结合两方面时面临新问题。当结合模型和数值方案时，模型在长时间模拟中可能会由于方案的规范依赖性而成为数值不稳定的问题，导致长时间模拟无法进行。
### Innovation
本文识别出这一问题，并提出了两种不同的训练策略来解决它：一种是直接学习矢量场，另一种是通过方案学习时间离散的动力学。这些方法能够学习复杂的物理动力学，如来自磁流体力学的引导中心。
### Conclusion
实验结果表明，所提出的方法能够学习并模拟复杂的物理动力学，解决长期模拟中的数值稳定性问题。
## 815. `cs.LG` - UAV网络中具有时延感知的多模态联邦学习 [PDF](https://arxiv.org/pdf/2510.01717), [HTML](https://arxiv.org/abs/2510.01717)
### Authors
Shaba Shaon,Dinh C. Nguyen
### Background
本文研究了无人机（UAV）辅助的联邦多模态学习（FML），重点在于减少系统时延并提供收敛性分析。在此框架下，UAV分散在网络中以收集数据，参与模型训练，并与基站（BS）合作构建全局模型。通过利用多模态传感，UAV克服了单模态系统的限制，提高了模型的准确性和泛化能力，提供了更全面的环境理解。主要目标是对UAV网络中的FML系统时延进行优化，通过联合解决UAV感知调度、功率控制、轨迹规划、资源分配和BS资源管理等问题来实现这一目标。
### Innovation
本文提出了一种高效迭代优化算法，结合块坐标下降和连续凸逼近技术，解决了时延最小化问题中的计算复杂性，并为具有非凸损失函数的UAV辅助FML框架提供了理论收敛性分析。实验结果表明，在不同的数据设置情况下，该FML框架在系统时延和模型训练性能方面优于现有方法。
### Conclusion
本文通过联合优化UAV感知调度、功率控制、轨迹规划、资源分配和BS资源管理问题，提出了一个具有时延感知能力的FML框架。该框架利用多模态传感，显著提高了系统性能和模型准确性，并为实际的UAV辅助FML应用提供了理论和实践依据。
## 816. `cs.LG` - 在视觉任务中具有鲁棒性潜空间的无监督动态特征选择 [PDF](https://arxiv.org/pdf/2510.01758), [HTML](https://arxiv.org/abs/2510.01758)
### Authors
Bruno Corcuera,Carlos Eiras-Franco,Brais Cancela
### Background
潜表示对于机器学习模型的性能和鲁棒性至关重要，因为它们能够以紧凑且信息丰富的方式编码数据的基本特征。然而，在视觉任务中，这些表示经常受到嘈杂或无关特征的影响，从而降低模型的性能和泛化能力。
### Innovation
本文提出了一种新的无监督动态特征选择（DFS）方法来增强潜表示。该方法通过识别并移除图像中的误导性和冗余信息，确保只保留最相关特征的贡献，从而不依赖于有标签数据，使方法适用于各种领域和数据集。实验表明，在聚类和图像生成等多种任务中，结合无监督DFS的方法在泛化性能方面取得了显著提高，同时计算成本略有增加。
### Conclusion
通过使用无监督框架，本文的方法在保证泛化性能的同时，显著提升了模型的性能，同时对计算成本的影响最小。
## 817. `cs.LG` - 私人和公平的机器学习：重新审视差分隐私SGD的不对等影响 [PDF](https://arxiv.org/pdf/2510.01744), [HTML](https://arxiv.org/abs/2510.01744)
### Authors
Lea Demelius,Dominik Kowald,Simone Kopeinik,Roman Kern,Andreas Trügler
### Background
差分隐私(DP)是一种保护个体在数据分析过程中隐私的方法。使用差分隐私随机梯度下降(DPSGD)训练神经网络会影响模型的学习动态和输出，进而影响其性能和公平性。大多数研究显示DPSGD对公平性有负面影响，但近期研究表明，通过直接针对差分隐私模型优化超参数，可以达到与非隐私模型相当的公平性水平。本文旨在分析这一结论的普遍性。
### Innovation
本文的主要创新点包括：1) 比较DPSGD对不同性能指标的不对等影响；2) 分析在广泛超参数设置下的不对等影响。文章指出，优化超参数直接针对DPSGD模型虽然不能可靠地缓解DPSGD的不利影响，但仍可能在公平性与性能之间提供更好的权衡。同时强调了超参数调优带来了额外的隐私泄露，需要仔细平衡隐私、性能和公平性。
### Conclusion
本文还扩展了分析到DPSGD-Global-Adapt，这是一个旨在缓解DPSGD对准确率影响的DPSGD变种，结论指出，这种方法在超参数选择方面可能不是稳健的解决方案。最后，文章表明需要谨慎权衡隐私、性能和公平性，任何形式的超参数调优都会带来额外的隐私泄露。
## 818. `cs.LG` - 隐私过滤的敏感性、特异性和一致性：合成数据生成中隐私过滤的三重评价 [PDF](https://arxiv.org/pdf/2510.01793), [HTML](https://arxiv.org/abs/2510.01793)
### Authors
Adil Koeken,Alexander Ziller,Moritz Knolle,Daniel Rueckert
### Background
在医疗AI研究中，克服数据稀缺性的方法之一是生成隐私保护的合成数据集。最近提出了一些后处理隐私过滤技术，旨在删除包含个人可识别信息的样本。然而，这些方法的有效性尚未得到充分验证。这项研究旨在系统地评估应用于胸部X射线合成的过滤管道的有效性，验证并揭示了当前隐私过滤方法存在的局限性，包括有限的特异性和一致性，仅在真实图像上实现高的检测灵敏度，但无法可靠地检测出从训练数据生成的近似副本。这表明后处理过滤方法可能提供虚假的安全感，而未能真正保护患者隐私，实际可能暴露了大量的患者信息。因此，该研究强调了在敏感应用中有效采用这些技术之前，过滤器设计方面的重大改进是必要的。
### Innovation
本文提出了一种全面的隐私过滤评价方法，涵盖了敏感性、特异性和一致性三个方面，系统地评估了用于胸部X射线合成的过滤管道的有效性，揭露了当前隐私过滤方法存在的基本局限性，指出了在敏感应用中有效采用这些技术之前，需要大幅改进过滤器的设计。
### Conclusion
我们发现，当前的隐私过滤方法仅在真实图像上实现高的灵敏度，但无法可靠地检测出近似副本，这揭示了这些方法仅提供虚假的安全感，未能有效保护患者隐私的问题。因此，我们认为，在将这些技术应用于敏感领域之前，必须进行重大的设计改进。
## 819. `cs.LG` - Sparse Query Attention (SQA): 一种通过减少查询头实现计算高效的注意力机制 [PDF](https://arxiv.org/pdf/2510.01817), [HTML](https://arxiv.org/abs/2510.01817)
### Authors
Adam Filipek
### Background
Transformer架构以Multi-Head Attention (MHA)机制为基础，已经成为先进人工智能模型的标准。然而，MHA机制的时间复杂度与序列长度成二次关系，这在处理长上下文的应用时是一个重要的扩展障碍。现有的方法，如Multi-Query Attention (MQA)和Grouped-Query Attention (GQA)，通过共享Key和Value投影有效解决了自回归推断中的频宽瓶颈问题，但这些方法并没有减少注意力分值计算所需的浮点运算次数（FLOPs），计算量仍然是训练和全序列处理中的关键瓶颈。
### Innovation
本文提出了一种新型注意力机制Sparse Query Attention (SQA)，通过减少Query头直接降低了注意力机制的计算复杂度。SQA的方法在理论基础、数学公式和一系列架构变体方面进行了详细介绍。实验表明SQA在计算密集型场景（如模型预训练、微调和编码器任务）中能够带来高达3倍的吞吐量改进，并且在初步的小规模实验中对模型质量的影响最小。
### Conclusion
SQA是在开发即将推出的Reactive Transformer架构过程中意外发现的，表明SQA可能成为构建更高效和可扩展模型的强大工具。
## 820. `cs.LG` - 通过对比特征增强的帕金森病远程监测噪声鲁棒性 [PDF](https://arxiv.org/pdf/2510.01588), [HTML](https://arxiv.org/abs/2510.01588)
### Authors
Ziming Tang,Chengbin Hou,Tianyu Zhang,Bangxu Tian,Jinbao Wang,Hairong Lv
### Background
帕金森病（PD）是常见的神经退行性疾病之一，通过远程监测技术进行居家主导的统一帕金森病评定量表（UPDRS）评分测试可以提高PD患者的可及性。然而，测量过程中会产生三类噪声：患者引起的测量不准确、环境噪声和传输过程中的数据包丢失，这些都会导致更高的预测误差。
### Innovation
提出了一个名为NoRo的噪声鲁棒UPDRS预测框架。该框架首先依据连续特征的值将原始声学特征分组，形成对比对，用这些对比对训练多层感知器编码器，生成鲁棒的特征。然后将这些特征与原始特征合并形成增强特征，再输入到UPDRS预测模型。此外，还引入了一个具有可定制噪声注入模块的新型评估方法，验证NoRo可以在不同噪声环境下成功增强UPDRS预测的鲁棒性。
### Conclusion
NoRo框架通过对比特征增强有效提升了UPDRS预测模型在不同噪声环境下的鲁棒性，为帕金森病远程监测提供了新的解决方案。
## 821. `cs.LG` - 使用不变序强化学习的黑箱组合最优化 [PDF](https://arxiv.org/pdf/2510.01824), [HTML](https://arxiv.org/abs/2510.01824)
### Authors
Olivier Goudet,Quentin Suire,Adrien Goëffon,Frédéric Saubion,Sylvain Lamprier
### Background
经典估计分布算法（EDAs）通常依赖于学习显式的变量依赖图，这可能会非常耗时且难以有效捕捉复杂的交互作用。相比之下，该研究提出了一个参数化的多变量自回归生成模型，该模型在训练过程中可以随机采样生成顺序（形式上是信息保留的dropout），从而促使模型对变量顺序保持不变，促进搜索空间多样性，并引导模型聚焦于最相关的变量依赖关系，从而提高采样效率。这种方法旨在改进现有的可扩展性和稳定性的挑战。
### Innovation
该研究引入了一个变分顺序不变的强化学习框架，用于黑箱组合优化问题。该框架的关键创新是采用多变量自回归生成模型，该模型在训练过程中不固定变量顺序，并通过随机采样的生成顺序来提高对变量顺序的不变性，从而增强搜索空间的多样性和提高样本效率。此外，该研究还对Generalized Reinforcement Policy Optimization（GRPO）进行了适应性调整，以提供稳定且规模不变的优势，从而稳定地更新策略梯度。这种方法对广泛的问题实例和不同规模的基准算法都表现出色，并能有效避免灾难性失败。
### Conclusion
该方法在多种基准算法和不同规模的问题实例中表现出色，并且能够有效避免灾难性失败。
## 822. `cs.LG` - 重新考虑MLP的形状惯例 [PDF](https://arxiv.org/pdf/2510.01796), [HTML](https://arxiv.org/abs/2510.01796)
### Authors
Meng-Hsi Chen,Yu-Ang Lee,Feng-Ting Liao,Da-shan Shiu
### Background
传统上，多层感知机（MLPs）遵循一种狭窄-宽-狭窄的设计模式，其中跳跃连接在输入/输出维度上操作，而处理发生在扩大了的隐藏空间中。这项工作挑战了这一惯例，通过提出宽-窄-宽（Hourglass）MLP块，其中跳跃连接在扩大了的维度上操作，而残差计算则通过狭窄瓶颈进行。这一倒置利用了更高的维度空间进行逐步细化同时通过参数匹配设计维持计算效率。实现Hourglass MLPs需要将输入信号初始投射到扩大后的维度上。这项研究提出在训练过程中固定这个投影可以保持随机初始化的状态，从而实现高效的训练和推断实施。
### Innovation
提出了宽-窄-宽（Hourglass）MLP块，改变了传统MLP的设计模式。Hopglass MLPs的设计方式是通过投射输入信号到扩大维度来兼容传统的MLP结构，随后进行经典的MLP处理方式。这种结构通过跳跃连接在更宽的维度进行操作，再通过狭窄瓶颈进行残留计算，使得模型在保持计算效率的同时能进行更细致的特性提取。此外，这项研究还提出可以在训练过程中将首次投影固定在随机初始化的状态下，实现高效的训练和推断过程。
### Conclusion
实验结果表明，Hopglass结构在生成任务上的表现优于传统设计，特别是当参数预算增加时，最优化的Hopglass配置倾向于更深、带更宽跳跃连接和更窄瓶颈的网络。这些发现提示重新考虑现代架构中的跳跃连接放置，并可能延伸到Transformers和其他残差网络。
## 823. `cs.LG` - 预测增强的AutoML：利用大语言模型提升表格数据集的模型选择和基准测试 [PDF](https://arxiv.org/pdf/2510.01842), [HTML](https://arxiv.org/abs/2510.01842)
### Authors
Yannis Belkhiter,Seshu Tirupathi,Giulio Zizzo,Sachin Sharma,John D. Kelleher
### Background
AutoML领域在后 hoc 模型选择方面取得了显著进展，能够自动识别最适合给定数据集的模型。然而，这些方法通常依赖于耗时的超参数搜索，其中方法会自动在目标数据集上训练和测试不同类型的模型。相比之下，预 hoc 预测作为一种有前景的替代方法，可以通过智能预选模型来绕过耗时的搜索。尽管具有潜力，但在文献中对该方法的研究仍然不足。本文旨在通过结合传统模型和大语言模型（LLMs）来利用AutoML库来减少搜索空间，使用数据集描述和统计信息来缩小AutoML搜索空间。该方法应用于包含175个表格分类数据集的AWS AutoGluon组合数据集，这些数据集在OpenML上公开，是先进的AutoML基准测试的一部分。这种方法在保持高效选择模型的同时，显著减少了计算开销.
### Innovation
本文探索了结合传统模型和大语言模型来利用AutoML库以减少搜索空间的方法。通过利用数据集描述和统计信息，大大缩小了AutoML的搜索空间，从而改善了AutoML的工作流，显著减少了计算开销。这种方法提供了一种新的选择最佳模型的方式，同时仍然可以为给定数据集选择最佳模型，避免了繁琐的超参数搜索过程。
### Conclusion
通过集成传统模型和大语言模型，该方法有效地改善了AutoML的工作流，减少了计算开销，同时还能高效地选择出最适合给定数据集的模型。这标志着在AutoML领域的一种新的探索方向，具有重要的应用价值。
## 824. `cs.LG` - 通过对比神经模型检查学习表示 [PDF](https://arxiv.org/pdf/2510.01853), [HTML](https://arxiv.org/abs/2510.01853)
### Authors
Vladimir Krsmanovic,Matthias Cosler,Mohamed Ghanem,Bernd Finkbeiner
### Background
模型检查是验证安全关键系统的关键技术，传统上使用形式规范。最近在深度学习领域的应用展示了它的潜力。然而，尽管在视觉和语言领域中无处不在，表征学习在形式验证中的应用仍处于起步阶段。本文介绍了对比神经模型检查(CNML)，一种通过将模型检查任务作为引导信号来学习对齐表示的新方法。CNML通过自监督对比目标将逻辑规范和系统共同嵌入到共享的潜在空间中。在基于真实世界的检索任务上，CNML在跨模式和内模式方面显著优于算法和神经基线。此外，本文还表明，学习到的表示可以有效地转移到下游任务，并泛化到更复杂的公式。这些发现表明，模型检查可以作为一种学习形式语言表示的目标。
### Innovation
本文提出了一种新颖的方法——对比神经模型检查(CNML)，该方法利用模型检查任务作为指导信号来学习对齐的表示。CNML通过将逻辑规范和系统共同嵌入到共享的潜在空间中，使用自监督对比目标实现了这一目标。这种方法在真实世界的检索任务上优于传统方法和神经基线。
### Conclusion
实验结果表明，模型检查可以作为学习形式语言表示的目标。CNML能够在各种任务中产生优秀的表示学习效果，并且这些表示还能泛化到更复杂的公式。
## 825. `cs.LG` - 从动态数据中显式发现非线性对称性 [PDF](https://arxiv.org/pdf/2510.01855), [HTML](https://arxiv.org/abs/2510.01855)
### Authors
Lexiang Hu,Yikang Li,Zhouchen Lin
### Background
在诸如均衡网络设计和发现控制方程等难题中，对称性被广泛应用于各种问题中。尽管对称性在简单场景中可以预先知道，但在复杂场景中则无法预测。大多数已有的对称性发现方法局限于线性对称性，而最近尝试发现非线性对称性的方法也未能明确获取李代数子空间。因此，有必要开发新的方法来确定具有非线性项的无穷小生成器的数量及其明确表达式，以便在复杂场景中发现非线性对称性。
### Innovation
本文提出了LieNLSD，这是首个能够确定具有非线性项的无穷小生成器的数量及其明确表达式的方法。LieNLSD通过指定无穷小群作用的函数库，并解决其系数矩阵，证明其对动态数据的微分方程的延长公式关于系数矩阵也是线性的，从而通过替代数据的中心差分和训练神经网络的雅可比矩阵来找到系数矩阵的线性方程组，进而使用特征值分解（SVD）求解之。该方法在顶夸克标记和一系列动态系统上展示了相对于现有方法的定性优势，并提高了神经偏微分方程求解器的长期展开精度超过20%，同时应用于数据增强的指导中。
### Conclusion
LieNLSD在顶夸克标记和一系列动态系统中显示出相对于现有方法的定性优势，大幅度提高了神经偏微分方程求解器的长期展开精度（提高了超过20%），并且适用于数据增强的指导中。相关代码和数据可以在给定的链接中获得。
## 826. `cs.LG` - 通过概率性任务推断实现组成式元学习 [PDF](https://arxiv.org/pdf/2510.01858), [HTML](https://arxiv.org/abs/2510.01858)
### Authors
Jacob J. W. Bakermans,Pablo Tano,Reidar Riveland,Charles Findling,Alexandre Pouget
### Background
在仅从少量经验中解决新任务时，有效重用先前任务的知识是关键，这一问题被称为元学习。组成式解决方案是特别适用于元学习的，因为在这些解决方案中，计算中的常见元素可以灵活重新组合成新的配置。目前的研究致力于提出一种新的模型，该模型通过生成模型来明确表示任务为可重用计算的结构化组合，进而将学习新任务变为概率推理问题，从而能够通过高度限制的假设检验找到解决方案，而无需参数更新。该模型在规则学习和运动学习任务中成功恢复了真实组件和统计信息，并能从单个实例中快速推断出新解。这种方法结合了神经网络的表示能力和概率推理的数据效率，实现了快速的组成式元学习。
### Innovation
该研究提出了一种新的组成式元学习模型，通过学习生成模型来捕捉一系列任务中共享的组件及其统计信息，并将学习新任务转化为概率推理问题，从而能够在无需参数更新的情况下将新任务的有效解决方法推断出来。这项创新将神经网络的表达能力与概率推理的数据效率相结合，实现了快速的组成式元学习。
### Conclusion
我们的框架结合了神经网络的强大表示能力和概率推理的高效数据利用，成功实现了快速的组成式元学习，并展示了该模型从单个实例中快速推断出新解的能力。
## 827. `cs.LG` - SFT-RL后训练中的陷阱：高SFT分数的误导及其替代方案 [PDF](https://arxiv.org/pdf/2510.01624), [HTML](https://arxiv.org/abs/2510.01624)
### Authors
Feiyang Kang,Michael Kuchnik,Karthik Padthe,Marin Vlastelica,Ruoxi Jia,Carole-Jean Wu,Newsha Ardalani
### Background
当前的后训练实践将大型语言模型（LLMs）分为两阶段独立训练：监督微调（SFT）和带有可验证奖励的强化学习（RLVR，简称'RL'）。然而，作者挑战了高SFT评分是否会在后续的RL训练中提升性能的问题，提供了丰富的实证证据验证这一假设。研究发现，SFT评分可能偏向于简化或具有高度一致性的数据，并不能可靠地预测后续RL的效果或大规模后训练的有效性。在某些情况下，具有改进SFT表现的模型在RL训练后可能会产生更差的结果。
### Innovation
作者研究了替代指标，并发现保留集上的推理能力退化和Pass@large k表现是预测RL效果的强有力代理。通过GRPO训练了超过120亿参数的数百个模型，并在七个数学基准测试中进行了多次重复实验，花费超过100万GPU小时。实验涵盖了Llama3、Mistral-Nemo、Qwen3等多个最先进的SFT/RL数据集。基于泛化损失和Pass@large k的预测精度大幅优于直接从预RL性能预测，提高了R²相关系数和Spearman秩相关系数多达0.5（即2倍）。这为广泛的应用场景提供了强大的实用价值。
### Conclusion
研究结果表明，在SFT之后的RL训练过程中，高SFT评分并非可靠的预测指标。替代指标，特别是泛化损失和Pass@large k，可更准确地预测RL结果。例如，在大多数实验中，针对唯一样例进行一次epoch的SFT训练的表现可能低于使用半数样本进行两次epoch的SFT训练，无论是单独SFT还是SFT后进行的RL训练。即使在相同的SFT预算下，只训练短样本可能获得更好的SFT性能，但通常在经过RL训练后效果更差。研究工具将会开源。
## 828. `cs.LG` - 有界动态遗憾和约束违背界值的约束在线凸优化 [PDF](https://arxiv.org/pdf/2510.01867), [HTML](https://arxiv.org/abs/2510.01867)
### Authors
Subhamon Supantha,Abhishek Sinha
### Background
本文考虑了带有在线对手约束的一般化在线凸优化（OCO）框架。之前的成果在这个领域已经取得了显著进展，但本文的目标在于进一步改进或优化这些成果，特别是在最通用的情况下，即成本和约束函数都是由对手任意选择的，并且约束函数之间没有共同的可行点。
### Innovation
本文提出了两种具有简单模块化结构的算法，能够在最一般的情况下提供普遍动态遗憾界和累积约束违背界。这两种算法与之前的最佳成果相比有所改进。
### Conclusion
本文的结果通过将受约束的学习问题归约为一个具有特殊构造的代理成本函数的标准OCO问题实例来建立。这种方法确保了对最普遍情况下的性能边界的有效界定，提升了现有研究水平。
## 829. `cs.LG` - 高效大型语言模型训练的随机梯度子空间 [PDF](https://arxiv.org/pdf/2510.01878), [HTML](https://arxiv.org/abs/2510.01878)
### Authors
Sahar Rajabi,Nayeema Nonta,Samanvay Vajpayee,Sirisha Rambhatla
### Background
训练大型语言模型（LLMs）常因极端的内存需求受瓶颈制约，尤其是由于优化器状态占据了绝大部分内存。近期研究通过将梯度投影到低维度子空间来减少这种开销，但通常需要复杂的更新策略。本文分析了梯度空间及其子空间的动力学。研究发现一个小的子空间可以捕捉到大部分梯度能量，但仍有一部分梯度能量存在于残留部分；更重要的是，核心子空间的影响会随时间和深度层加深而减弱。同时观察到梯度空间接近平坦曲率，这需要算法能够明确考虑其几何特性。
### Innovation
本文提出了GrassWalk和GrassJump等一系列随机算法，利用子空间的特性在保持甚至提高LLaMA-1B和LLaMA-7B预训练性能的同时，实现了最先进的内存节省。
### Conclusion
通过分析梯度空间的动力学和子空间的特点，该研究提出了利用子空间的算法，成功在内存开销显著减少的同时提高了LLMs训练的效率。
## 830. `cs.LG` - LLMs更优的GNN助手吗？在缺陷下的迭代精炼重构稳健图学习 [PDF](https://arxiv.org/pdf/2510.01910), [HTML](https://arxiv.org/abs/2510.01910)
### Authors
Zhaoyan Wang,Zheng Gao,Arogya Kharel,In-Young Ko
### Background
图神经网络（GNNs）在网页相关应用中被广泛采用，用于学习具有结构的数据，如带属性的文本图。然而，在实际场景中，这类数据存在缺陷，严重影响了GNN性能。尽管先前有研究探索了GNN对单一缺陷的鲁棒性问题，但在复合缺陷的情况下，图原生方法和大型语言模型（LLMs）增强的效果系统性理解仍然缺乏。具体而言，现有的研究并没有全面比较传统方法和最近的LLM-on-graph框架，导致其优势不甚明朗。
### Innovation
该研究首次进行了系统的实验研究，涵盖了不同的图缺陷，揭示了被忽略的脆弱性，并挑战了关于LLM增强方法始终更优的假设。基于实证结果，提出了基于检索增强对比精炼的稳健图学习框架（RoGRAD）。这是一种迭代范式，使用检索增强生成（RAG）来插入基于检索的增强，并使用迭代图对比学习来强化辨别性表示。这种框架将图中的LLM增强从静态信号注入转变为动态精炼。
### Conclusion
广泛的实验表明，RoGRAD在与传统GNN和LLM增强基线相比时表现更优，平均改善幅度高达82.43%。
## 831. `cs.LG` - StelLA: 在低秩适应中使用Stiefel流形进行子空间学习 [PDF](https://arxiv.org/pdf/2510.01938), [HTML](https://arxiv.org/abs/2510.01938)
### Authors
Zhizhong Li,Sina Sajadmanesh,Jingtao Li,Lingjuan Lyu
### Background
低秩适应（LoRA）已经成为一种参数高效的技术，常用于大型预训练模型的微调。尽管如此，LoRA在性能上仍然落后于完整的微调，部分原因是它未能充分利用低秩流形底层的几何结构。
### Innovation
本文提出了一种基于Stiefel流形的几何感知扩展方法StelLA，该方法采用三因子分解$Utextbf{SV}^top$。该方法将适配器的输入和输出子空间$V$和$U$与缩放因子$S$分开，并限制$U$和$V$位于Stiefel流形上，以确保在整个训练过程中它们的正交性。此外，通过采用灵活的可模块化几何优化设计，将欧几里得优化器转换为黎曼优化器，有效学习子空间的同时保持与现有微调管道的兼容性。
### Conclusion
我们在常识推理、数学和代码生成、图像分类和图像生成等多种下游任务上的实证结果表明，本文提出的方法优于最近的LoRA变体。代码可在给定的链接处获得。
## 832. `cs.LG` - 使用多任务卷积版特林机器的透明逻辑分类方法 [PDF](https://arxiv.org/pdf/2510.01906), [HTML](https://arxiv.org/abs/2510.01906)
### Authors
Mayur Kishor Shende,Ole-Christoffer Granmo,Runar Helin,Vladimir I. Zadorozhny,Rishad Shafik
### Background
Tsetlin机（TM）是一种新颖的机器学习范式，它利用有限状态自动化学习，并使用命题逻辑表示模式。由于其简单的结构，TMs比基于神经网络的学习算法更容易解释。卷积Tsetlin机已在MNIST、K-MNIST、F-MNIST和CIFAR-2等数据集上展示了可比的性能。
### Innovation
本文提出了一种方法，用于生成卷积版特林机器架构的大规模多通道（RGB）图像分类的本地解释和全局类表示。这些解释可以用于解释模型预测，而全局类表示则汇总了每个类的重要模式。通过在MNIST和CelebA数据集上的实验，展示了TM在保持可解释性的同时，对复杂训练环境中的性能表现。
### Conclusion
在大型复杂训练环境中，TM与深度学习模型表现相当，同时保持其可解释性。这有助于更好地理解TM的条款，并揭示了这些模型如何适用于更复杂的和多样化的数据集。
## 833. `cs.LG` - 联邦隐私保护的多分类后验校准 [PDF](https://arxiv.org/pdf/2510.01987), [HTML](https://arxiv.org/abs/2510.01987)
### Authors
Samuel Maddock,Graham Cormode,Carsten Maple
### Background
在机器学习模型中，让预测概率更准确地反映真实结果频率对于可靠决策至关重要。特别是在联邦学习（FL）中，由于隐私问题，数据分布在多个客户端上，无法集中处理，因此需要在保护隐私的前提下进行模型校准。尽管联邦学习在医疗保健和金融等领域得到了广泛应用，对校准的需求非常强烈，但对于联邦环境下的隐私保护校准的研究却相对较少，尤其是多分类的后验校准问题没有得到充分解决。
### Innovation
本文提出了在联邦学习环境中整合传统集中式校准技术的新方法。具体来讲，作者将直方图分箱和温度缩放等传统的校准方法转化为适用于联邦环境的方法，并通过在用户级差分隐私（DP）环境中进行研究展示了联邦化和差分隐私对校准精度的影响。作者还提出了一些缓解异质性下校准性能下降的策略，并发现，他们的联邦温度缩放方法最适合用于联邦差分隐私保护（DP-FL）场景，而加权分箱方法在不需要差分隐私保护的情况下效果最佳。
### Conclusion
本文研究了在联邦和差分隐私限制下的多分类模型校准问题，提出了适用于这些约束环境的新方法，并讨论了不同校准技术在不同场景下的适用性。
## 834. `cs.LG` - 多边际时间薛定谔桥匹配方法用于无配对数据视频生成 [PDF](https://arxiv.org/pdf/2510.01894), [HTML](https://arxiv.org/abs/2510.01894)
### Authors
Thomas Gravier,Thomas Boyer,Auguste Genovesio
### Background
许多自然的动态过程，如细胞在体分化或疾病进展，只能通过静态样本快照进行观察。尽管这一过程具有挑战性，但重构它们的时间演化对于科学研究具有重要意义。现有方法可以在时间轴上进行数据传输，但在高维度下可扩展性差，并且需要满足一些限制性假设。现有的方法在处理这些挑战时受到限制，限制了其在高维度数据上的应用。因此，该研究旨在提供一种新的方法以增强可扩展性和适应性，以解决这些问题。
### Innovation
本文提出了一种新技术——多边际时间薛定谔桥匹配方法（MMtSBM），它基于Diffusion Schrödinger Bridge Matching，并通过迭代马尔可夫拟合算法在新的因子化方式下扩展到多个边际。MMtSBM在理论保证和实际效率上都优于现有方法，能够在高维数据集（如100维转录组轨迹推断）中产生出色的性能，并首次在高维图像设置中恢复耦合和动力学。这种方法为从静态数据中恢复隐藏动力学提供了一种实践且原理上的可行方案。
### Conclusion
本研究通过MMtSBM，为揭示静态数据中的隐藏动态提供了新的方法论支持。该技术能够处理高维数据，展示了出色的理论和实际性能。未来的工作可能会进一步优化算法以提高计算效率，以及在更多的应用场景中验证其有效性。
## 835. `cs.LG` - 多模态基础模型在早期疾病检测中的应用 [PDF](https://arxiv.org/pdf/2510.01899), [HTML](https://arxiv.org/abs/2510.01899)
### Authors
Md Talha Mohsin,Ismail Abdulrashid
### Background
医疗行业产生了多种类型的数据，包括电子健康记录（EHR）、医疗影像、遗传信息以及来自可穿戴设备的持续监测数据。传统的诊断模型通常将这些数据源单独分析，这限制了它们识别不同模态数据间的交叉关联，而这些关联对于早期疾病诊断至关重要。
### Innovation
该研究提出了一种基于注意机制的变换器框架来整合多模态患者数据的基础模型。模型首先通过专门的编码器将多种数据类型映射到共享的潜在空间，然后使用多头注意和残差规范化将这些数据重新组合起来。这种架构可以在多种任务上进行预训练，使得轻松适应新疾病和新数据集变得容易。此外，作者还提供了一种实验策略，使用肿瘤学、心脏病学和神经病学领域的基准数据集进行初步检测任务的测试。
### Conclusion
所提出的方法旨在实现统一的多模态基础模型，以提高预测的准确性，并帮助医生做出决策。该框架还包括数据治理和模型管理工具，以提高透明度、可靠性和临床可解释性。
## 836. `cs.LG` - G²RPO: Granular GRPO for Precise Reward in Flow Models [PDF](https://arxiv.org/pdf/2510.01982), [HTML](https://arxiv.org/abs/2510.01982)
### Authors
Yujie Zhou,Pengyang Ling,Jiazi Bu,Yibin Wang,Yuhang Zang,Jiaqi Wang,Li Niu,Guangtao Zhai
### Background
在线强化学习（RL）与扩散和流模型的结合已逐渐成为一种有潜力的方法，以使生成模型与人类偏好相一致。在去噪过程中使用随机微分方程（SDE）进行随机抽样，生成多样化的去噪方向，从而进行RL探索。然而，现有方法尽管能够有效地探索潜在的高价值样本，但由于稀疏和狭窄的奖励信号，导致偏好对齐不完全理想。
### Innovation
提出了一种名为Granular-GRPO（G²RPO）的新框架，用于在流模型的强化学习中实现采样方向的精确和全面的奖励评估。G²RPO框架包括引入奇异随机抽样策略，支持逐步的随机探索，同时确保奖励与注入的噪声之间有高度的相关性，从而为每个SDE扰动提供一个忠实的奖励评估。此外，还引入了一个多粒度优势集成模块，该模块在多个扩散尺度上计算优势，并对其进行聚合，从而产生更全面和稳健的采样方向评估。
### Conclusion
在各种奖励模型上的实验表明，G²RPO显著优于现有的基于流的GRPO基准模型，突显了其有效性和稳健性。
## 837. `cs.LG` - Moon：基于模态转换的高效多变量时间序列异常检测 [PDF](https://arxiv.org/pdf/2510.01970), [HTML](https://arxiv.org/abs/2510.01970)
### Authors
Yuanyuan Yao,Yuhan Shi,Lu Chen,Ziquan Fang,Yunjun Gao,Leong Hou U,Yushuai Li,Tianyi Li
### Background
现有的多变量时间序列（MTS）异常检测方法可分为重建基于、预测基于和分类器基于三种类型。然而，这些方法面临两个关键挑战：1）无监督学习方法（如重建基于和预测基于方法）依赖错误阈值，可能导致不准确；2）半监督方法主要建模正常数据，往往未能充分利用异常标签，从而限制了对细微异常的检测；3）监督学习方法（如分类器基于方法）难以捕捉局部关系，计算成本高，并且受限于标注数据的稀缺性。
### Innovation
Moon 提出了一种基于监督模态转换的多变量时间序列异常检测框架。Moon 引入了新颖的多变量马尔可夫转换场（MV-MTF）技术，将数值时间序列数据转换为图像表示，从而捕捉变量间和时间戳间的关系。Moon 还采用多模态 CNN 将数值数据和图像数据通过共享参数的特征融合模型进行整合，以提升训练效率。此外，Moon 使用基于 SHAP 的异常解释器来识别导致异常的关键变量，从而提高可解释性。
### Conclusion
对六个真实世界 MTS 数据集的广泛实验表明，Moon 在效率、准确性和可解释性方面均优于六种最先进的方法，效率提高了高达 93%，准确度提高了 4%，可解释性提高了 10.8%。
## 838. `cs.LG` - 半监督图异常检测中的正常性校准 [PDF](https://arxiv.org/pdf/2510.02014), [HTML](https://arxiv.org/abs/2510.02014)
### Authors
Guolei Zeng,Hezhe Qiao,Guoguo Ai,Jinsong Guo,Guansong Pang
### Background
图异常检测（GAD）在广泛的应用中具有发现不规则模式的关键能力，吸引了越来越多的关注。半监督GAD通过假设在训练过程中有一部分标注的正常节点可供使用，是最广泛探索的应用设置之一。然而，现有半监督GAD方法学习的正常性往往局限于标注的正常节点，容易对给定的模式进行过度拟合，这会导致高误报率。
### Innovation
本文提出了一种图正常性校准框架（GraphNC），它利用标注数据和未标注数据来校准教师模型（预训练的半监督GAD模型）在异常分数空间和节点表示空间中的正常性。GraphNC 包括两个主要组件：异常分数分布对齐（ScoreDA）和基于扰动的正常性正则化（NormReg）。ScoreDA 通过与教师模型生成的分数分布对齐来优化模型的异常分数，从而使得正常和异常分数更加可分离；NormReg 则在表示空间中对图正常性进行正则化，通过最小化受标签节点指导的一致性损失来使正常节点的表示更加紧凑。
### Conclusion
GraphNC 通过引入分数分布对齐和基于扰动的正常性正则化有效克服了半监督GAD模型中正常性学习的局限，提高了异常检测的准确性，尤其在降低误报率方面表现突出。
## 839. `cs.LG` - FairContrast：通过自适应对比学习与定制扩充方法提升表格数据公平性 [PDF](https://arxiv.org/pdf/2510.02017), [HTML](https://arxiv.org/abs/2510.02017)
### Authors
Aida Tayebi,Ali Khodabandeh Yalabadi,Mehdi Yazdani-Jahromi,Ozlem Ozmen Garibay
### Background
随着人工智能系统在日常生活中愈发深入，开发公平且无偏见的模型变得越来越重要。考虑到AI系统的社会影响不仅是一个技术挑战，也是一种道德责任。众多研究证明，学习公平且稳健的表示是有效去偏和提高公平性的重要手段，同时仍能保持预测任务所需的关键信息。现有的代表学习框架，尤其是那些利用自监督和对比学习的方法，已在多种领域中展示了其优越的稳健性和泛化能力。然而，这些方法在表格数据中的公平性问题仍少有研究。本文讨论了这一背景，并提出了一种新的对比学习框架，专门设计用于解决表格数据中的偏见和学习公平的表示。
### Innovation
本文引入了一种新的对比学习框架FairContrast，专门用于解决表格数据中的偏见和学习公平的表示。通过精心选择正样本对和采用监督和自监督对比学习的方法，本文显著降低了与现有表格数据对比学习模型相比的偏见。实验结果表明，此方法在减少偏见的同时，对准确度的影响非常小，并且能够利用学习到的公平的代表在各种下游任务中发挥效用。
### Conclusion
本文提出的FairContrast框架有效减少了表格数据中的偏见，同时保持了高准确性，并且具备良好的泛化能力。该方法为解决表格数据中公平性问题提供了新的思路，具有重要的理论和实践意义。
## 840. `cs.LG` - 深度学习中密集层连接的深层神经网络的数学建模与收敛分析 [PDF](https://arxiv.org/pdf/2510.02049), [HTML](https://arxiv.org/abs/2510.02049)
### Authors
Jinshu Huang,Haibin Su,Xue-Cheng Tai,Chunlin Wu
### Background
在深度学习中，密集层连接已成为设计深度神经网络（DNNs）的关键原理之一，能够促进高效的信息流通并提升各种应用中的性能。本文将密集连接的DNNs进行数学建模，并在深层极限下分析其学习问题。为了广泛适用性，本文在包括通用非局部特征变换（局部特征变换为其特例）的密集非局部（DNL）框架中进行分析，该框架包括标准DenseNets及其变体作为特例。在此形式化表达中，密集连接的网络被建模为非线性积分方程，而以前的工作通常采用常微分方程的观点。本文从最佳控制的角度研究了相关训练问题，并证明了从神经网络学习问题到其连续时间对应物的收敛结果。特别是，通过分段线性扩展和Γ收敛分析，证明了最优值的收敛性和最小化子序列的收敛性。这些结果为理解密集连接的DNNs提供了数学基础，并暗示这些结构可以在训练深度模型时提供稳定性。
### Innovation
该研究创新性地提出了一个包含密集非局部（DNL）框架的数学建模与分析方法，该框架将密集连接的DNNs建模为非线性积分方程，而非传统方法中的常微分方程；提出了从神经网络学习问题到连续时间对应物的收敛结果；并通过分段线性扩展和Γ收敛分析证明了最优值的收敛性和最小化子序列的收敛性。
### Conclusion
该研究为密集连接的DNNs提供了数学基础，并暗示这些结构在训练深度模型时可以提供稳定性。该工作为深度学习中的密集层连接提供了重要理论支持，有助于设计更稳定的深度学习模型。
## 841. `cs.LG` - 自适应异构归一化流混合用于稳健的变分推断 [PDF](https://arxiv.org/pdf/2510.02056), [HTML](https://arxiv.org/abs/2510.02056)
### Authors
Benjamin Wiriyapong,Oktay Karakuş,Kirill Sidorov
### Background
归一化流（Normalising-flow）能够逼近复杂的后验分布，然而单一归一化流模型在不同分布上的表现往往不一致。本文讨论了这一问题并提出了Adaptive Mixture Flow Variational Inference (AMF-VI)，该方法基于不同的归一化流模型（MAF, RealNVP, RBIG）进行混合，并在两个阶段中进行训练：首先顺序训练每个流模型，然后通过基于似然性更新进行全局权重调整，从而在多个方面展示了优越性。
### Innovation
提出了Adaptive Mixture Flow Variational Inference (AMF-VI)，这是一种混合了互补归一化流（MAF, RealNVP, RBIG）的自适应方法，该方法在无需更改架构或引入样本门控的情况下，通过基于似然性的更新进行全局权重估计，使单一流模型在不同分布上的表现更加一致，从而提高了变分推断的稳健性。
### Conclusion
在包括香蕉形、X形、两月亮形、环状、双模态和五模态混合分布的六个基准后验家庭中，AMF-VI 优于单一流基线，其在运输度量（Wasserstein-2）和最大均值离散度（MDD）指标上表现出稳定改进，表明其整体表现更优，具有更强的稳健性。该方法在效率和架构上是通用的，对标准归一化流训练的影响相对较小，证明了自适应流混合是稳健变分推断的有效途径，同时保留了每个专家模型的独特倾向性。
## 842. `cs.LG` - 通过重建的最大似然估计对Flow Matching进行微调 [PDF](https://arxiv.org/pdf/2510.02081), [HTML](https://arxiv.org/abs/2510.02081)
### Authors
Zhaoyi Li,Jingtao Ding,Yong Li,Shihua Li
### Background
Flow Matching (FM) 算法在生成任务中表现出色，特别是在机器人操作方面。与依赖于仿真的扩散模型不同，FM的无模拟训练方式简单高效，但也带来了训练和推理之间的差距，即在训练过程中无法评估模型输出。FM过分追求直线预定义路径，可能导致系统刚性等严重问题。因此，需要通过最大似然估计重建的方法对FM进行微调。
### Innovation
本研究首先从理论上分析了训练损失与推理错误之间的关系，然后提出了一种新的方法，通过最大似然估计重建对FM进行微调，包括直接微调和基于残差的微调两种方法。基于FM的平滑ODE公式，这种方法不同于扩散模型中使用的随机微分方程（SDEs）。基于特定设计的架构，基于残差的微调能够将压缩特性整合到模型中，这对于模型的稳健性和可解释性至关重要。
### Conclusion
实验结果表明，我们的方法可以可靠地提高FM的推理性能。
## 843. `cs.LG` - 使用混合近似推理从光体积描记图推断光学组织属性 [PDF](https://arxiv.org/pdf/2510.02073), [HTML](https://arxiv.org/abs/2510.02073)
### Authors
Jens Behrmann,Maria R. Cervera,Antoine Wehenkel,Andrew C. Miller,Albert Cerussi,Pranay Jain,Vivek Venugopal,Shijie Yan,Guillermo Sapiro,Luca Pegolotti,Jörn-Henrik Jacobsen
### Background
智能穿戴设备能够通过光电容积描记法（PPG）连续追踪已建立的生物标志物，如心率、心率变异性及血氧饱和度。PPG波形还包含丰富的生理信息，但现有深度学习模型常常依赖于缺乏明确生理意义的特征，这在预测能力和临床解释性之间造成了矛盾。研究表明，改善这一点需要一种能够接收无散信息并提供直接解释参数的模型。论文提出了PPGen，这是一种生物物理模型，能够将PPG信号与可解释的生理参数相关联。基于PPGen的混合近似推断（HAI）方法能够快速、稳健地从PPG信号中估计相关生理参数，同时校正模型的不足。实验表明，HAI能够在各种噪声和传感器条件下准确推断生理参数。
### Innovation
论文提出了PPGen模型，这是一种生物物理模型，能够将PPG信号与可解释的生理参数相关联。基于PPGen的混合近似推理（HAI）方法能够在多种噪声和传感器条件下快速、精确地从PPG信号中估计相关生理参数，同时校正模型的不足。这种方法结合了物理模型的优势和深度学习的预测能力，为生物信号分析提供了一种新的方法。
### Conclusion
研究结果表明，通过HAI方法可以从PPG信号准确地推断生理参数，同时支持临床解释和硬件设计。这种方法为基于深度学习的特征保留了所需的准确性，同时也支持临床解释和硬件设计的合理性。这为未来智能穿戴设备的改进和设计提供了新的方向。
## 844. `cs.LG` - 使用公开可用模型库学习模型表示 [PDF](https://arxiv.org/pdf/2510.02096), [HTML](https://arxiv.org/abs/2510.02096)
### Authors
Damian Falk,Konstantin Schürholt,Konstantinos Tzevelekakis,Léo Meynent,Damian Borth
### Background
神经网络的权重作为一种新颖的数据模态出现，催生了权重空间学习这一领域。在这个领域中，一个主要挑战是，为了学习权重的有意义表示，通常需要大型的、精心构建的训练模型集合，这些集合通常被称为模型动物园。这些模型动物园往往需要临时的训练，并消耗大量计算资源，从而限制了学习权重空间表示的规模和灵活性。
### Innovation
本文提出了一种新的权重空间回廊结构，能够在大规模、未结构化的模型存储库中（例如Hugging Face）训练任意模型，克服了对精心构建的模型动物园的依赖。这一方法能够处理高度异质性的模型群体，其变体在架构和数据集上有差异，并且大多未作文档记录。通过在Hugging Face上获取模型学习权重空间表示，结果常常优于在实验室生成的模型动物园上训练的表示，证明了该方法的有效性。此外，训练集中的模型多样性还允许权重空间模型泛化到未见过的数据模态。
### Conclusion
本文展示了能够在野外学习高质量权重空间表示，表明精心构建的模型动物园并非不可替代。这一发现解决了权重空间学习社区目前面临的一个重要限制。
## 845. `cs.LG` - KAIROS: 统一训练以实现通用非自回归时间序列预测 [PDF](https://arxiv.org/pdf/2510.02084), [HTML](https://arxiv.org/abs/2510.02084)
### Authors
Kuiye Ding,Fanda Fan,Zheya Wang,Hongxiao Li,Yifan Wang,Lei Wang,Chunjie Luo,Jianfeng Zhan
### Background
在互联网中，可靠的时序预测提供了前瞻性信号，用于资源规划、缓存布局和异常响应，使平台能够随着用户行为和内容分布的变化高效运行。与其它领域相比，Web应用时间序列预测需要更快的响应速度以支持即时决策。现有的非自回归模型通常会生成过光滑的预测，而自回归方法则容易累积误差，导致预测延迟。
### Innovation
KAIROS是一个非自回归时间序列预测框架，它直接建模段级多峰分布，避免了错误积累，实现即时推理。相比于现有的非自回归模型，KAIROS不仅具有更快的响应速度，还能够生成更为精确的预测，同时在大规模数据集上展示了强大的零样本泛化能力。KAIROS的预测性能接近于顶尖的基于大规模模型的基础模型，但消耗的推理成本仅为这些模型的很少一部分。
### Conclusion
KAIROS通过统一训练展示了非自回归设计在时间序列领域作为基础模型的广泛应用潜力。非自回归设计被认为是一种可扩展的架构，能够处理大规模和复杂的时间序列任务，从而提高预测精度并降低推理成本。
## 846. `cs.LG` - Octax：基于JAX的加速CHIP-8街机游戏环境在强化学习中的应用 [PDF](https://arxiv.org/pdf/2510.01764), [HTML](https://arxiv.org/abs/2510.01764)
### Authors
Waris Radji,Thomas Michel,Hector Piteau
### Background
强化学习（RL）研究需要多样化且具有挑战性的环境，这些环境需要既易于管理又能扩展。虽然现代视频游戏拥有丰富的动态，但它们计算密集，不适合大规模实验，因为它们基于CPU执行。Chip-8模拟器因其前身地位而广泛用于RL研究作为基准。
### Innovation
作者引入了Octax，这是一种基于CHIP-8模拟器的高性能JAX经典街机游戏环境套件。相比于传统的CPU模拟器，基于JAX的实现极大地提高了速度，同时保持了与原游戏机制的完美一致性。Octax提供了可执行于现代GPU的大规模图像环境，跨越了益智、动作和策略等多个游戏类型，显著提升了训练速度和可扩展性。Octax还允许研究人员轻松扩展游戏套件或使用大型语言模型生成新的环境，使其成为大规模RL实验的理想平台。
### Conclusion
作者通过在多个游戏上训练RL代理展现出Octax的能力，证明其在提高训练速度和可扩展性方面显著优于现有解决方案。Octax作为一种模块化设计的环境，为大规模RL实验提供了理想的基础。
## 847. `cs.LG` - 多类分类中任意损失函数下的对抗鲁棒性下界 [PDF](https://arxiv.org/pdf/2510.01969), [HTML](https://arxiv.org/abs/2510.01969)
### Authors
Camilo Andrés García Trillos,Nicolás García Trillos
### Background
本文探讨了在任意损失函数下，多类分类中的对抗鲁棒性分类问题。研究围绕学习者无偏的鲁棒风险最小化问题，针对交叉熵损失、幂形式损失和二次损失等重要情况进行了具体分析，扩展了0-1损失的相关研究成果。这些重新表述使得计算对抗风险的精确下界变得更加高效，并促进了在0-1损失之外的鲁棒分类器设计。
### Innovation
本文提出了将对抗鲁棒性问题重新表述为对偶形式和巴莱契诺克形式，特别适用于交叉熵损失、幂形式损失和二次损失。此外，还揭示了对抗鲁棒性、α-公平装载问题和任意正测度的广义巴莱齐诺克问题之间的有趣联系，并使用Kullback-Leibler和Tsallis熵作为惩罚项。最后，通过数值实验展示了交叉熵损失函数下获得的对抗风险精度更高的下界。
### Conclusion
本文通过重新表述的方法，为多类分类中任意损失函数下的对抗鲁棒性问题提供了精确的下界，并展示了Kullback-Leibler和Tsallis熵在对抗鲁棒性分析中的应用，主要使用交叉熵损失函数进行了验证。
## 848. `cs.LG` - 在有限数据情况下，混合深度学习建模方法预测家庭用户天然气消耗 [PDF](https://arxiv.org/pdf/2510.02115), [HTML](https://arxiv.org/abs/2510.02115)
### Authors
Milad Firoozeh,Nader Dashti,Mohammad Ali Hatefi
### Background
天然气作为清洁燃料，是石油的最佳替代品，占据了全球能源需求的重要份额。伊朗拥有丰富的能源资源，是世界上第二大的天然气生产国。但由于人口增长和能源消耗增加，伊朗面临每年冬季因压力下降和气源中断而导致的问题，特别是在住宅领域。因此，需要对住宅用户的天然气消耗进行管理和预测。
### Innovation
本研究使用机器学习模型，包括LSTM、GRU和混合BiLSTM-XGBoost模型，来分析和预测伊朗赞詹省住宅用户的天然气消耗情况。研究利用从2017年到2022年收集的六年的天然气消耗和气象数据。研究结果表明，混合BiLSTM-XGBoost模型在准确度方面优于其他模型，且在数据量有限的情况下表现出更强的鲁棒性。
### Conclusion
研究结果表明，机器学习方法，特别是混合模型，可以有效应用于天然气消耗管理与预测，有助于更高效的资源管理，减少季节性短缺。该研究强调，地理和气候因素对不同地区天然气需求的影响至关重要，应将其纳入预测模型中。
## 849. `cs.LG` - PENEX: 由AdaBoost启发的神经网络正则化 [PDF](https://arxiv.org/pdf/2510.02107), [HTML](https://arxiv.org/abs/2510.02107)
### Authors
Klaus-Rudolf Kladny,Bernhard Schölkopf,Michael Muehlebach
### Background
AdaBoost使用所谓的弱学习器按指数损失最小化，这种损失函数对错误标记的数据点施加更严厉的惩罚，相比于其他损失函数如交叉熵。尽管AdaBoost能很好地泛化，但在数量增加时，保持弱学习器的顺序拟合。在此工作中，我们引入了Penalized Exponential Loss (PENEX)，一种新的多类指数损失函数，该函数在理论上得到支持，并且可以使用一阶优化方法进行优化，而现有的多类指数损失函数则不具备这一特点。实验和理论证据表明，PENEX可以隐式最大化数据点的边际，同时在boosting框架中隐式参数化弱学习器。
### Innovation
我们提出了一种新的多类指数损失函数PENEX，它基于理论，并且可以使用一阶优化方法进行优化，不同于现有的多类指数损失函数。我们证明了PENEX能够隐式最大化数据点的边际，并在boosting框架中隐式参数化弱学习器。我们的结果显示，PENEX在计算机视觉和自然语言处理任务中表现出的正则化效果通常优于同类方法，且具有相似的计算成本。
### Conclusion
我们的结果强调了PENEX作为AdaBoost启发式正则化方法的潜力，用于深度神经网络的有效训练和微调。
## 850. `cs.LG` - 基于ensemble方法的阈值校准以实现稳定灵敏度控制 [PDF](https://arxiv.org/pdf/2510.02116), [HTML](https://arxiv.org/abs/2510.02116)
### Authors
John N. Daras
### Background
精确召回控制在大规模空间合流和实体匹配任务中至关重要，这一点在下游数据处理中尤为关键。即使漏掉了少量真实的匹配结果也会破坏数据处理流程，但如果进行过多的人工复查则会增加成本。传统的置信区间方法如Clopper-Pearson或Wilson仅仅提供了召回的下界，这些方法通常会高估目标值几个百分点，并且在分数分布偏斜时表现出高运行间变异性。因此，需要一种新的方法来精确控制召回率，同时保持低变异性和TPU友好性。
### Innovation
本研究提出了一种端到端的框架，在数以亿计的几何对中实现了精确的召回率，同时保持了TPU友好性。该框架采用了等分网格边界框过滤和压缩稀疏行（CSR）候选表示，减少了候选对的数量级。通过xxHash确定性生成样本训练出一种轻量级神经排列器，并通过单次前向传播将分数传播到所有剩余对，进而构建一个可重现且根据得分分位数分层的校准集。利用逆方差加权聚合了四种互补的阈值估计器——Clopper-Pearson、Jeffreys、Wilson以及一个精确的分位数估计器，并将这些估计器在九个独立子样本之间融合，从而降低了阈值的变异性。实验结果显示该方法在两个实际的不动产数据集上能够达到预定的召回率接近无误差，减少了冗余验证，并能在单个TPU v3核心上端到端运行。
### Conclusion
本研究提出的方法在大规模几何匹配中实现了精确的召回控制，相比其他校准方法减少了冗余验证，且能够稳定实现预定的召回率。本方法通过减少运行间变异性和增加鲁棒性，特别是在分数分布偏斜时表现出显著的优势。
## 851. `cs.LG` - 从ECG检测查加斯病：乔治·B·莫迪生医网挑战2025 [PDF](https://arxiv.org/pdf/2510.02202), [HTML](https://arxiv.org/abs/2510.02202)
### Authors
Matthew A. Reyna(1),Zuzana Koscova(1),Jan Pavlus(1),Soheil Saghafi(1),James Weigle(1),Andoni Elola(1,2),Salman Seyedi(1),Kiersten Campbell(1),Qiao Li(1),Ali Bahrami Rad(1),Antônio H. Ribeiro(3),Antonio Luiz P. Ribeiro(4,5),Reza Sameni(1,6),Gari D. Clifford(1,6) ((1) Department of Biomedical Informatics, Emory University, Atlanta, USA, (2) Department of Electronic Technology, University of the Basque Country UPV/EHU, Spain, (3) Department of Information Technology, Uppsala University, Uppsala, Sweden, (4) Universidade Federal de Minas Gerais, Belo Horizonte, Brazil, (5) Telehealth Center from Hospital das Clinicas, Universidade Federal de Minas Gerais, Belo Horizonte, Brazil, (6) Department of Biomedical Engineering, Georgia Institute of Technology and Emory University, Atlanta, USA)
### Background
查加斯病是一种由寄生虫引起的疾病，主要通过昆虫传播，在南美洲、中美洲和最近的美国等地流行。慢性查加斯病会导致心血管疾病和消化系统问题。由于血清学检测能力有限，而查加斯病性心肌病通常在心电图（ECG）上表现出来，因此利用ECG识别患者成为一种方法，以优先进行测试和治疗。
### Innovation
提供多类创新。首先，利用病患报告和血清学测试的多个数据集，并提供了带有弱标签的大数据集和带有强标签的小数据集。其次，增强了数据以提高模型的稳健性和对未见过数据源的通用性。第三，应用了一个评价指标来捕捉本地查加斯病血清学检测能力，将机器学习问题作为分级任务来处理。
### Conclusion
共有来自111个团队的630多名参与者提交了超过1300份参赛作品，这些作品体现了来自世界各地学术界和工业界的多种方法。
## 852. `cs.LG` - GRACE: 一种用于可解释逆强化学习的语言模型框架 [PDF](https://arxiv.org/pdf/2510.02180), [HTML](https://arxiv.org/abs/2510.02180)
### Authors
Silvia Sapora,Devon Hjelm,Alexander Toshev,Omar Attia,Bogdan Mazoure
### Background
传统的逆强化学习方法试图从专家演示中恢复奖励模型，但这些方法生成的模型往往是黑盒模型，难以解释和调试。
### Innovation
提出了GRACE方法，通过使用大型语言模型在进化搜索过程中反向工程可解释的、基于代码的奖励函数，直接从专家轨迹中生成的奖励函数是可执行的代码，可以进行检查和验证。该方法在BabyAI和AndroidWorld基准测试中实证验证，能高效学习高精度奖励，即使在复杂的多任务设置中也是如此。此外，GRACE生成的奖励还能导致更强的策略，与具有真实奖励的竞争对手的模仿学习和在线强化学习方法相比，效果更佳。最终，证明GRACE能够在多任务设置中构建复杂的奖励API。
### Conclusion
GRACE方法能够在复杂的多任务环境中学习和生成高度准确且易于解释的奖励函数，从而产生更强的策略。
## 853. `cs.LG` - Policy Gradient Guidance Enables Test Time Control [PDF](https://arxiv.org/pdf/2510.02148), [HTML](https://arxiv.org/abs/2510.02148)
### Authors
Jianing Qi,Hao Tang,Zhigang Zhu
### Background
本文介绍了一种简单扩展，即将classifier-free指导从扩散模型推广到传统的策略梯度方法，提出Policy Gradient Guidance (PGG)。该方法通过增加一个无条件分支，并对有条件和无条件分支进行插值，提供了一个在测试时间控制行为的调节旋钮，而无需重新训练。研究表明，有条件dropout中央扩散指导对于简单离散任务和低样本条件下有增益，但在连续控制中dropout可能会导致不稳定。使用适度更大的引导（γ>1）训练可提高稳定性、样本效率和可控性。该研究证明了引导，原本局限于扩散策略，可以适应标准的在线强化学习，为进一步操控在线强化学习打开了新方向。
### Innovation
该研究提出了Policy Gradient Guidance（PGG），将其作为一种将无条件分支纳入策略梯度中，并通过插值有条件和无条件分支的方法，以便在测试时间调整行为。相较于其他需重新训练的引导方法，PGG通过一小部分调整实现目标，且理论分析显示其额外的规范化项在优势估计中消失，提供了一个干净的引导策略更新框架。
### Conclusion
本文展示了PGG可以在不重新训练的情况下提供测试时间的控制，并通过理论和实验验证，在不同的任务中均显示出显著的改进。此外，PGG将引导的方法扩展到了传统的策略梯度方法，为在线强化学习带来了新的研究方向。
## 854. `cs.LG` - DAG DECORation: Continuous Optimization for Structure Learning under Hidden Confounding [PDF](https://arxiv.org/pdf/2510.02117), [HTML](https://arxiv.org/abs/2510.02117)
### Authors
Samhita Pal,James O'quinn,Kaveh Aryan,Heather Pua,James P. Long,Amir Asiaee
### Background
现有的连续方法在错误项独立时表现优异，但去控制因素优先的方法则依赖于普遍因子结构或非线性假设。该研究旨在解决线性高斯结构方程模型在存在潜在混淆变量时进行结构学习的问题。
### Innovation
提出了textsc{DECOR}，这是一个单一基于似然和完全可微的估计器，同时学习有向无环图(DAG)和相关噪声模型。该方法给出了全局参数可识别性的简单充分条件，并且在合成基准测试中，textsc{DECOR}在不同混淆密度、图密度、潜在秩和维度的情况下，能够匹敌或超越强基准，特别是在混淆不普遍时表现出特别的鲁棒性。
### Conclusion
该方法在处理潜在混淆时展现出优势，尤其是在混淆不普遍的情况下，同时保持在混淆普遍时的竞争力。
## 855. `cs.LG` - 平滑感知随机梯度拉angevin动力学 [PDF](https://arxiv.org/pdf/2510.02174), [HTML](https://arxiv.org/abs/2510.02174)
### Authors
Stefano Bruno,Youngsik Hwang,Jaehyeon An,Sotirios Sabanis,Dong-Young Lim
### Background
深度学习中的泛化能力与损失景观中平坦极小值的追求密切相关，然而，传统的随机梯度拉angevin动力学（SGLD）没有机制将动力学偏向此类低曲率解决方案。本文的研究背景在于探索如何利用随机权重扰动来有效地寻找高维非凸优化问题中的平坦极小值，从而提高模型的泛化能力。
### Innovation
本文提出了一种新颖的算法——平滑感知随机梯度拉angevin动力学（fSGLD），它通过使用参数扰动并对其进行球形高斯噪声，从而有效地优化了一个带随机平滑的目标函数，隐含地捕捉了曲率信息。fSGLD能够在逆温度和随机权重扰动的尺度适当匹配时，使得其不变测度靠近由赫赛迹正则化后的损失函数的全局极小值的稳定测度。这一结果为随机权重扰动带来的好处提供了一个严谨的理论解释。此外，fSGLD还在非线性距离下提供了非渐近收敛保证，并得出了赫赛迹正则化目标函数的过拟合风险 bounds。
### Conclusion
大量的实验表明，fSGLD在零样本训练和微调设置下均能获得优于或等同于基准算法的泛化能力和鲁棒性，同时保持与随机梯度下降（SGD）相仿的计算成本，约为自适应矩平滑（SAM）的一半。赫赛谱分析进一步证明了fSGLD能够收敛到显著更平坦的极小值。
## 856. `cs.LG` - C2AL: 聚族对比辅助学习用于大规模推荐系统 [PDF](https://arxiv.org/pdf/2510.02215), [HTML](https://arxiv.org/abs/2510.02215)
### Authors
Mertcan Cokbas,Ziteng Liu,Zeyi Tao,Chengkai Zhang,Elder Veliz,Qin Huang,Ellie Wen,Huayu Li,Qiang Jin,Murat Duman,Benjamin Au,Guy Lebanon,Sagar Chordia
### Background
现有的大规模推荐模型假设用户群体具有同质性，但在实际数据中这些群体是异质性的，具有不同的条件分布。随着模型规模和复杂性的增加，数据训练更加依赖于核心分布模式，导致忽略头部和尾部区域，从而限制了模型的学习能力，可能导致注意力权重失效或神经元死亡。
### Innovation
本文揭示了注意力机制在共享嵌入选择中的关键作用，并提出了一种新的方法，即通过分析数据集中的次结构并揭示那些具有强大分布对比性的部分，利用部分相互冲突的辅助标签来正则化共享表示，从而定制注意力层的学习过程，保留微小群体的互信息同时提高全局性能。这种方法不同于过往通过调整标签权重或采用多任务头来减轻偏差问题的研究。
### Conclusion
在包含数十亿数据点的六大SOTA模型的生产数据集上评估了C2AL方法，实验表明，利用这种方法，因素化机能够捕捉细微的用户-对象交互，总体上降低了0.16%的归一化熵，同时在针对小众人群的性能上超过了0.30%。
## 857. `cs.LG` - Poolformer: 使用池化操作的递归网络进行长序列建模 [PDF](https://arxiv.org/pdf/2510.02206), [HTML](https://arxiv.org/abs/2510.02206)
### Authors
Daniel Gallo Fernández
### Background
序列到序列模型在人工智能中变得至关重要，尤其是在引入了transformer架构之后。最初，这些模型主要应用于自然语言处理，但后来显示了在其他领域，如计算机视觉中的实用性。尽管这些模型需要通过递归层或自我注意层来沿时间维度交换信息，但自我注意机制的计算复杂度随着序列长度的平方增长，这限制了其在处理非常长的序列时的实用性。
### Innovation
作者提出了一种名为Poolformer的新序列到序列模型，该模型通过使用递归层并引入池化操作来减少序列长度，替代了自我注意机制。Poolformer通过递归的方式定义，使用SkipBlocks，这些SkipBlocks包含残差块、一个下池层、一个嵌套的SkipBlock、一个上池层和额外的残差块。实验结果表明，池化操作显著加速了训练过程，改善了感知指标（FID和IS），并防止了过拟合。
### Conclusion
所提出的Poolformer在处理自然表现为长序列的音频任务时优于当前最先进的模型，如SaShiMi和Mamba。未来的研究方向包括将该模型应用于文本和视觉领域以及多模态场景，其中基于Poolformer的大型语言模型能够有效地处理图像和视频的密集表示。
## 858. `cs.LG` - 具有行为触发观测的强化学习 [PDF](https://arxiv.org/pdf/2510.02149), [HTML](https://arxiv.org/abs/2510.02149)
### Authors
Alexander Ryabchenko,Wenlong Mou
### Background
研究了状态观测由行为随机触发的强化学习问题，这种约束在许多现实世界应用中普遍存在。这篇文章将这种框架称为行为触发间歇可追踪马尔可夫决策过程（ATST-MDPs），每个行为都有触发状态观测的特定概率。
### Innovation
提出了适合这种框架的定制贝尔曼最优方程，并引入了行为序列学习范式，其中代理承诺执行一系列行为，直到下一个观测到达。假设线性MDP的情况下，价值函数在诱导的行为序列特征映射中具有线性表示。基于此结构，提出了一类具有统计误差保证的离策略估计器，并引入了ST-LSVI-UCB，一种适应于行为触发设置的LSVI-UCB变体。ST-LSVI-UCB算法在$?widetilde O(?sqrt{Kd^3(1-?gamma)^{-3}})$下实现了后悔界，其中$K$是次数，$d$是特征维度，$?gamma$是折扣因子（每步非终止概率）。
### Conclusion
本文为学习间歇性、行为触发的观测建立了理论基础，并证明了在这种观测约束下高效的可学习性是可行的。
## 859. `cs.LG` - 扩散变换器用于插补：统计效率和不确定性量化 [PDF](https://arxiv.org/pdf/2510.02216), [HTML](https://arxiv.org/abs/2510.02216)
### Authors
Zeqi Ye,Minshuo Chen
### Background
插补方法在提高实践时间序列数据质量方面起着关键作用，这些数据经常受到广泛缺失值的影响。最近，基于扩散的生成插补方法在实际应用中表现出显著的成功，优于自回归和传统统计方法。尽管这些方法在实践中取得了成功，但目前对基于扩散的模型如何有效地捕捉缺失值和观测值之间的复杂空间和时间依赖性的理论理解仍然有限。
### Innovation
研究了条件扩散变换器在插补中的统计效率，并量化了缺失值的不确定性。基于新颖的条件分数函数逼近理论，推导了统计样本复杂性界限，并通过此构建了缺失值的紧密置信区域。研究结果表明，缺失模式对插补的效率和准确性有很大影响。此外，通过模拟验证了这些理论见解，并提出了混合隐藏训练策略以增强插补性能。
### Conclusion
我们的研究揭示了基于扩散的模型在捕捉缺失值和观测值之间复杂依赖关系方面的统计效率，通过量化不确定性提供了理论支持，并提出了改进插补性能的方法。
## 860. `cs.LG` - DiFFPO: 通过强化学习训练快速而激烈的扩散大语言模型 [PDF](https://arxiv.org/pdf/2510.02212), [HTML](https://arxiv.org/abs/2510.02212)
### Authors
Hanyang Zhao,Dawen Liang,Wenpin Tang,David Yao,Nathan Kallus
### Background
本文提出了一种统一框架DiFFPO，用于训练蒙面扩散大语言模型(dLLMs)，使其不仅能更有效率地推理，而且能够更快地进行推理。该框架利用强化学习（RL）训练代理策略，其中目标模型被设计为代理策略进行间接逼近学习，从而提高模型的样本效率并增强在特定任务上的表现。文章还提出了一种新的方向，即联合训练dLLMs策略的高效采样器/控制器，通过RL激励模型使其适应性地分配每个提示的推理阈值，进而通过联合训练采样器而不是单独训练模型，获得较低的函数评估次数（NFEs）和改进的推理时间计算性能，展示了在基准数学和规划任务上的效果。
### Innovation
1. 提出了一种通过离策略RL训练代理策略的新方法，提高了真实dLLM策略的逼近准确性和信息性。2. 提出了一种新的高效联合训练dLLM策略的采样器/控制器的方法，不仅提高了模型的准确性，还降低了评估次数，改进了推理时间计算性能的帕累托前沿。3. 通过RL优化模型的多令牌预测能力，训练了一个新的框架，旨在提高推理速度和任务效率，同时保持了高性能的推理准确度。
### Conclusion
本文提出了一种名为DiFFPO的新框架，通过利用RL来训练monte-carlo dLLMs，实现了更快、更高效的推理能力。通过实验证明，该框架在基准数学和规划任务上的有效性，并且能够在提高推理效率的同时保持较高的准确度。
## 861. `cs.LG` - Catalyst GFlowNet for electrocatalyst design: A hydrogen evolution reaction case study [PDF](https://arxiv.org/pdf/2510.02142), [HTML](https://arxiv.org/abs/2510.02142)
### Authors
Lena Podina,Christina Humer,Alexandre Duval,Victor Schmidt,Ali Ramlaoui,Shahana Chatterjee,Yoshua Bengio,Alex Hernandez-Garcia,David Rolnick,Félix Therrien
### Background
高效的且成本低廉的储能是推动可再生能源广泛应用的关键，尤其是考虑到风能和太阳能等来源的波动性。电催化剂在氢储能（HES）中起到了关键作用，使能量可以转化为氢气储存。但目前仍面临开发高效且经济的催化剂的挑战。
### Innovation
本文介绍了一种名为Catalyst GFlowNet的生成模型，利用基于机器学习的成键能和吸附能预测来设计高效催化剂的晶体表面。通过氢 Evolution 反应（HES 中的关键反应）这一案例研究证明了该模型的有效性。
### Conclusion
这种生成建模框架为加速寻找新型高效催化剂提供了具有前景的途径，未来将进一步将此方法扩展到氧 Evolution 反应，并在催化剂材料搜索空间中发掘新材料。
## 862. `cs.LG` - 从多步时间序列基础模型高效生成相关样本路径 [PDF](https://arxiv.org/pdf/2510.02224), [HTML](https://arxiv.org/abs/2510.02224)
### Authors
Ethan Baron,Boris Oreshkin,Ruijun Ma,Hanyu Zhang,Kari Torkkola,Michael W. Mahoney,Andrew Gordon Wilson,Tatiana Konstantinova
### Background
许多时间序列应用程序需要访问多步预测轨迹的形式的样本路径。最近，时间序列基础模型利用多步前瞻预测来提高多步预测的质量和效率。然而，这些模型仅预测每个时间步骤的独立边际分布，而不是完整的联合预测分布。为了生成具有真实相关结构的预测样本路径，通常会依赖于自回归采样，这可能是极其昂贵的。
### Innovation
本文提出了一个基于copula的方法，该方法能够高效地从现有的多步时间序列基础模型生成准确的相关样本路径。该copula基于方法可以在一次前向传递中生成相关样本路径，比自回归采样快得多，并且通过缓解滚雪球误差现象优化了样本路径的质量。
### Conclusion
我们的copula基于方法不仅提高了生成相关样本路径的效率，还通过缓解滚雪球误差现象提高了样本路径的质量，比现有的自回归采样方法快得多。
## 863. `cs.LG` - PUL-Inter-slice Defender: 一种针对分布式切片移动性攻击的异常检测解决方案 [PDF](https://arxiv.org/pdf/2510.02236), [HTML](https://arxiv.org/abs/2510.02236)
### Authors
Ricardo Misael Ayala Molina,Hyame Assem Alameddine,Makan Pourzandi,Chadi Assi
### Background
第五代(5G)网络中的用户设备(U.E.)可以连接并无缝切换到多个网络切片(Network Slices, NSs)来访问不同的服务。这种灵活性称为跨切片切换(Inter-Slice Switching, ISS)，但是它引入了一个潜在的安全威胁，可以利用分布式切片移动性(Distributed Slice Mobility, DSM)攻击，这是一种分布式拒绝服务(Distributed Denial of Service, DDoS)攻击。现有的解决方案如Inter-Slice Defender以及其他基于One-Class Support Vector Machine (OCSVM)与Random Forest和XGBoost组合的PUL解决方案，都需要高质量的未受污染的数据，而对于受攻击污染的训练数据，则无法保持检测的准确性。
### Innovation
本文提出了一种基于Positive Unlabeled Learning (PUL)的异常检测方法PUL-Inter-Slice Defender，该方法结合了Long Short-Term Memory (LSTM) Autoencoders和K-Means聚类技术，利用3GPP的关键性能指标和性能测量计数器作为特征来检测分布式切片移动性攻击变种。PUL-Inter-Slice Defender在测试数据集中的F1得分超过98.50%，并且在训练数据集含有10%到40%攻击污染的情况下仍然表现出色，优于现有的Inter-Slice Defender和基于PUL的其他解决方案。
### Conclusion
通过严格的实验验证，PUL-Inter-Slice Defender能够有效地检测分布在切片中的移动性攻击，即使在含有高达40%攻击污染的训练数据中，也能保持高度的准确性和鲁棒性。
## 864. `cs.LG` - Transformers 发现分子结构无需图先验 [PDF](https://arxiv.org/pdf/2510.02259), [HTML](https://arxiv.org/abs/2510.02259)
### Authors
Tobias Kreiman,Yutong Bai,Fadi Atieh,Elizabeth Weaver,Eric Qu,Aditi S. Krishnapriyan
### Background
图神经网络（GNNs）是分子机器学习领域的主导架构，尤其适用于分子属性预测和机器学习相互作用势（MLIPs）。GNNs在固定半径截断或k最近邻方案诱导的预定义图上进行消息传递，这种设计有助于许多分子任务中的局部性，但固定的感受野限制了其表达能力，并且在稀疏图操作中会减慢推理速度。
### Innovation
本文研究了是否可以通过直接在Cartesian坐标上训练未经修改的Transformer，而不需要预定义的图或物理先验，来逼近分子能量和力。通过在OMol25数据集上对比标准Transformer与最新的对称GNN，展示了Transformer学习物理一致模式（如注意力权重随原子间距离衰减）的能力，并且由于缺乏硬编码偏置可以在不同分子环境中灵活适应。Transformer的使用可以解锁随训练资源扩展时的可预测改进，与其它领域观察到的经验扩展定律一致。研究结果表明，许多GNN优势特性可以在Transformer中自适应地出现，挑战了硬编码图归纳偏置的必要性，指出标准、可扩展的分子建模架构方向。
### Conclusion
许多GNN的优点可以在Transformers中自适应地出现，这挑战了需要硬编码图归纳偏置的概念，并指出了标准化的、可扩展的分子建模架构的方向。
## 865. `cs.LG` - xLSTM的缩放定律：具有线性时间复杂度的竞争表现 [PDF](https://arxiv.org/pdf/2510.02228), [HTML](https://arxiv.org/abs/2510.02228)
### Authors
Maximilian Beck,Kajetan Schweighofer,Sebastian Böck,Sebastian Lehner,Sepp Hochreiter
### Background
大规模语言模型（LLMs）的性能与计算预算之间遵循的缩放定律对于预测在训练之前的模型性能至关重要。传统的Transformer架构尽管占主导地位，但最近的替代方案如xLSTM则在参数规模上可以提供线性复杂度的同时保持竞争力。然而，关于这两种架构的性能对比及其在不同训练和推理情境下的表现，之前的文献相对较少关注具体的细节和调整参数对性能的影响。因此，本研究旨在探讨xLSTM在compute-optimal和过学习两种模式下的缩放行为，并对比Transformer的性能表现，特别关注模型大小和训练序列长度对模型最优规模的影响，以期为未来模型的设计和部署提供指导性见解。
### Innovation
本研究创新地使用了IsoFLOP和参数拟合两种方法来研究xLSTM在不同模型大小和训练序列长度范围内的缩放行为。提出了模型大小和上下文长度对最优模型规模的影响，这是先前研究中的一个关键但未被充分探讨的方面。此外，研究还分析了推理时间的缩放特性，发现相比于Transformer，xLSTM在常规训练和推理情境下具有更优的缩放性能，尤其在训练和推理上下文增长时更为显著。
### Conclusion
研究表明，在典型的训练和推理情况下，xLSTM相对于Transformer具有更优的缩放性能。特别地，当训练和推理的上下文长度增加时，xLSTM的优势更为明显。这一发现为建筑未来模型的设计和部署提供了重要的指导意义，特别是在处理长时间上下文时，xLSTM可能是更优的选择。
## 866. `cs.LG` - 使用强化学习对抗反应性和动态干扰攻击 [PDF](https://arxiv.org/pdf/2510.02265), [HTML](https://arxiv.org/abs/2510.02265)
### Authors
Yalin E. Sagduyu,Tugba Erpek,Kemal Davaslioglu,Sastry Kompella
### Background
研究了如何通过强化学习（RL）来减轻反应性干扰，其中干扰设备根据接收到的信号选择频道和调整检测阈值，以检测并阻止正在进行的传输。发射器-接收器对需要通过适应发射功率、调制和频道选择来避免干扰并优化吞吐量，而无需先了解信道条件或干扰策略。通过不同的奖励函数和行动集，展示了RL可以快速适应频带动态，并持续保持高的传输速率，即使信道和干扰策略随时间变化。
### Innovation
引入了使用Q-learning处理离散干扰事件状态，以及使用Deep Q-Networks (DQN)处理基于接收到功率的连续状态的方法，展示了RL算法在这种动态干扰环境下的适应性和稳定性。
### Conclusion
通过强化学习，研究团队证明了可以通过学习动态调整以避免干扰并优化吞吐量，实现快速适应环境变化并维持高传输速率的效果。
## 867. `cs.LG` - 基于树的对话强化策略优化以实施红队攻击 [PDF](https://arxiv.org/pdf/2510.02286), [HTML](https://arxiv.org/abs/2510.02286)
### Authors
Ruohao Guo,Afshin Oroojlooy,Roshan Sridhar,Miguel Ballesteros,Alan Ritter,Dan Roth
### Background
尽管在AI安全方面取得了迅速进展，当前的大规模语言模型在多轮对话互动场景中仍然容易受到有策略性的对抗攻击。这些攻击者会在对话过程中不断调整其提示，提出更具有挑战性和现实性的攻击手法。现有的发现安全性漏洞的方法依赖于人工专家的手动审查或使用预定义模板和人工收集的攻击数据的自动化方法，大多数研究集中在单轮攻击上，并未探索可能的多轮攻击策略空间，尤其是在复杂对话动态和对话策略规划下新的攻击轨迹。这与最近的研究结果一致，显示LLMs在多轮攻击中的易受攻击性远高于单轮攻击。
### Innovation
本文提出了DialTree-RPO框架，这是一种结合树搜索的强化学习方法，能够自主发现多样化的多轮攻击策略，将其视为序列决策问题，通过学习最优对话策略来最大化多轮攻击的成功率，从而无需手动策划的数据就能系统地探索攻击策略。该方法在全面实验中不仅提高了超过25.9%的攻击成功率，还发现了新的攻击策略。
### Conclusion
通过DialTree-RPO框架，不仅增强了对多轮攻击的防御能力，还增强了在复杂对话动态和战略对话规划中识别新型攻击手法的能力，对增强AI系统的安全性具有重要意义。
## 868. `cs.LG` - Drop-Muon：更新较少，收敛更快 [PDF](https://arxiv.org/pdf/2510.02239), [HTML](https://arxiv.org/abs/2510.02239)
### Authors
Kaja Gruntkowska,Yassine Maziane,Zheng Qu,Peter Richtárik
### Background
传统的深度学习优化原理认为应该在每一步更新所有层，这是所有最近的领先优化器（如Muon）遵循的原则。然而，本文挑战了这个假设，提出虽然目前普遍采用的方法在理论和实践中都是有效的，但在某些情况下，逐层更新策略本质上可能是次优的。
### Innovation
作者引入了一种非欧几里得随机渐进训练方法——Drop-Muon，它以简化而强大的框架，在每一步仅更新一部分层，根据随机时间表进行更新，结合渐进训练的效率和层特定的非欧几里得更新，以实现顶级性能。此外，论文提供了一系列严格的收敛性保证，在层光滑性和层 $(L^0, L^1)$-光滑性下均适用，这也是首次在渐进训练中为非光滑情况提供此类结果。通过对控制实验的分析，表明在实际中Drop-Muon方法在保持相同准确率的情况下，可实现比全网Muon方法快至 1.4 倍的收敛速度。
### Conclusion
整体而言，本文的研究结果建议在大规模模型高效训练方面实现一种新的范式转变，这不仅挑战了现有的更新原则，还提供了一种理论基础牢固且高效的渐进训练方法替代全网络更新，在未来可能具有广泛应用前景。
## 869. `cs.LG` - 解决自然语言生成中不确定性估计方法评估中的陷阱 [PDF](https://arxiv.org/pdf/2510.02279), [HTML](https://arxiv.org/abs/2510.02279)
### Authors
Mykyta Ielanskyi,Kajetan Schweighofer,Lukas Aichberger,Sepp Hochreiter
### Background
大型语言模型（LLMs）中的幻觉问题削弱了其可靠性，尤其是常见的预测不确定性导致的一种特定幻觉类型，即自编（confabulations）。现有方法通常通过将不确定性估计与生成文本的正确性相关联来进行评估，但这在不同随机变量间存在分歧，影响了评估方法的可靠性。因此，需要新的风险指标和评估方法来提高不确定性估计方法的稳健性评估。
### Innovation
该研究提出了使用多种风险指标来改进不确定性估计方法在自然语言生成中的实证评估的稳健性。通过结合多LLM判别器变体减少评估偏差，同时探索结构化任务和分布外检测，引入自编风险评估的新方法。进一步提出使用不确定性估计方法的Elo排名来在各种评估设置中提供客观总结。
### Conclusion
研究通过改进不确定性估计方法的评估，提出了多种新的风险指标，并证明在多种任务类型中，这些方法能够减少评估偏差，提供稳健和可控的风险评估。
## 870. `cs.LG` - StockBench：LLM代理能够在真实市场中交易股票以获得利润吗？ [PDF](https://arxiv.org/pdf/2510.02209), [HTML](https://arxiv.org/abs/2510.02209)
### Authors
Yanxu Chen,Zijun Yao,Yantao Liu,Jin Ye,Jianing Yu,Lei Hou,Juanzi Li
### Background
大型语言模型（LLMs）已经在自主代理方面显示出强大的能力，尤其是在推理、工具使用和顺序决策方面。尽管之前在软件工程和科学研究领域已经进行了一些LSTM评估，但金融市场作为直接与经济价值和高风险决策相关的领域，仍未被充分探索。现有的金融基准主要通过问答测试静态知识，但未能捕捉到交易中的动态和迭代特性。
### Innovation
本文提出了StockBench，这是一个无污染基准，用于评估LLM代理在现实的多月股票交易环境中。代理每天接收市场信号（包括价格、基本面和新闻），并必须做出买入、卖出或持有决策。性能是通过累积回报、最大回撤和索提诺比率等金融指标进行评估。评价结果显示，虽然大部分LLM代理难以超过简单的持有策略，但一些模型表现出了更高的回报和更有效的风险控制潜力。这些发现揭示了开发LLM驱动的金融代理所面临的机会与挑战。
### Conclusion
该研究展示了静态金融知识任务的出色表现并不必然转化为成功的交易策略。StockBench作为一个开源资源，旨在支持可重复性和推动金融科技这一领域的未来研究。
## 871. `cs.LG` - ExGRPO：从经验中学习推理 [PDF](https://arxiv.org/pdf/2510.02245), [HTML](https://arxiv.org/abs/2510.02245)
### Authors
Runzhe Zhan,Yafu Li,Zhi Wang,Xiaoye Qu,Dongrui Liu,Jing Shao,Derek F. Wong,Yu Cheng
### Background
强化学习（RL）通过使语言模型能够进行推理，成为一个新兴的改进其推理能力的方法。然而，标准的在线训练方法会在每次更新后丢弃滚动生成经验数据，这导致了计算效率低下和不稳定性的问题。尽管之前的RL工作中强调了重复使用过去经验的好处，但过去经验的特性如何影响大型推理模型的学习动态依然没有得到充分的研究。
### Innovation
本文首次探索了推理经验的价值，并识别了滚动生成正确性和熵作为有效经验价值的指标。基于这些洞察，我们提出了ExGRPO（Experiential Group Relative Policy Optimization）框架，该框架组织和优先考虑有价值的经验，并使用混合策略目标来平衡探索与经验利用。
### Conclusion
在五个类型的基模型（参数量从1.5B到8B）上进行的实验表明，ExGRPO能够持续改善数学和通用基准上的推理性能，并且相对于在线训练的RLVR，在平均分上分别提高了3.5和7.6分点。此外，ExGRPO能够稳定在更强和较弱的模型上的训练，这些在在线方法失败的情况下依然能保持训练稳定。这些结果突显了权威的经验管理是高效和可扩展的RLVR的关键元素。
## 872. `cs.LG` - 大规模都市道路网络中的细粒度城市交通预测 [PDF](https://arxiv.org/pdf/2510.02278), [HTML](https://arxiv.org/abs/2510.02278)
### Authors
Fedor Velikonivtsev,Oleg Platonov,Gleb Bazhenov,Liudmila Prokhorenkova
### Background
交通预测在道路网络是一个复杂的具有重要意义的任务，最近吸引了机器学习社区的广泛关注，目前最流行的方法是时空图神经网络。但当前公开的基准数据集存在许多缺陷，如缺少用于道路图构建的道路连接信息、道路属性信息有限以及道路段落数量较少，无法满足实际应用需求。现有的数据集大多包含了关于城市间高速公路的信息，且传感器分布稀疏。相比之下，城市道路网络面临的预测任务更为复杂，因为它们包含更多密集的道路和复杂的市区交通模式。
### Innovation
本工作提供了一个更完整、更现实且更具挑战性的交通预测基准数据集，通过发布代表两个主要城市道路网络的数据集，最大的数据集几乎包含10万个道路段落（比现有数据集大约增加了10倍）。这些数据集包含了丰富的道路特征，并提供了关于交通流量和交通速度的精细数据，使得能够构建更为全面的交通预测系统。我们展示了大多数目前用于交通预测的神经时空模型难以适应我们规模的数据集，并提出了一种替代的神经交通预测方法，使用一个不专门用于时间序列处理的图神经网络，从而提高了可扩展性并展示了更强的预测性能。
### Conclusion
我们希望我们的数据集和建模见解能成为交通预测研究中宝贵的资源。
## 873. `cs.LG` - 测试时锚定离散扩散后验采样 [PDF](https://arxiv.org/pdf/2510.02291), [HTML](https://arxiv.org/abs/2510.02291)
### Authors
Litu Rout,Andreas Lugmayr,Yasamin Jafarian,Srivatsan Varadharajan,Constantine Caramanis,Sanjay Shakkottai,Ira Kemelmacher-Shlizerman
### Background
研究了使用预训练离散扩散基础模型进行后验采样的问题，旨在从有噪声的测量中恢复图像，而无需重新训练特定任务的模型。虽然弥散模型在生成建模方面取得了显著成功，大多数进展依赖于连续的高斯弥散。相比之下，离散弥散为联合建模类别数据（如文本和图像）提供了一个统一框架。不仅如此，离散弥散还可以提供更快的推断、更精细的控制和无需训练的原理性贝叶斯推断，使其特别适合后验采样。然而，现有的离散弥散后验采样方法面临重重挑战：无梯度引导导致稀疏信号、连续放宽限制了适用范围、分裂吉布斯采样遭受维度诅咒。
### Innovation
引入了锚定后验采样（APS）方法，针对掩模扩散基础模型，基于两个关键创新——离散嵌入空间中的量化期望来进行梯度样式的引导，并通过锚定重新遮罩进行适应性解码。这种方法在标准基准上的线性和非线性逆问题中，实现了离散扩散采样器的最优性能。此外，该研究还展示了其在无需训练的风格化和文本指导编辑方面的效益。
### Conclusion
该方法实现了离散扩散采样器的最优性能，并且在无需训练的情况下，展示了其在风格化和文本指导编辑中的效益。
## 874. `cs.LG` - 连续个性化在扩散模型中的应用 [PDF](https://arxiv.org/pdf/2510.02296), [HTML](https://arxiv.org/abs/2510.02296)
### Authors
Yu-Chien Liao,Jr-Jen Chen,Chi-Pin Huang,Ci-Siang Lin,Meng-Lin Wu,Yu-Chiang Frank Wang
### Background
在实际应用中，逐步更新扩散模型是可行的，但在计算上极具挑战性。本文探讨了一种新颖的学习策略——概念神经元选择（CNS），这是一种简单而有效的连续学习方案中的个性化方法，能够在不遗忘先前知识的情况下，逐步对目标概念相关的神经元进行调优，同时保持零样本文字到图像生成的能力。
### Innovation
CNS通过独特识别与目标概念紧密相关的神经元，从而在应对灾难性遗忘问题的同时，保持零样本文字到图像生成的能力。该方法在单概念和个人概念的情况下进行了评估，并显示出优于先前方法的最佳性能。CNS还实现了无融合操作，减少连续个性化过程中的内存存储和处理时间。
### Conclusion
CNS通过最小的参数调整实现了最先进的性能，并在现实世界的数据集上的评估证明了其在连续个性化任务中的优越性。
## 875. `cs.LG` - Diffusion^2: 将3D环境转化为射频热图 [PDF](https://arxiv.org/pdf/2510.02274), [HTML](https://arxiv.org/abs/2510.02274)
### Authors
Kyoungjun Park,Yifan Yang,Changhan Ge,Lili Qiu,Shiqi Jiang
### Background
射频（RF）信号传播建模对于理解环境至关重要，因为射频信号能提供超出可见光谱范围的RGB摄像头无法提供的信息，例如吸收和反射等因素会影响RF信号。因此，射频信号传播对于支持无线诊断、部署和优化非常有用。然而，在复杂环境中准确预测射频信号仍然具有挑战性。我们介绍了一种基于扩散的Diffusion^2方法，通过3D点云模拟不同频率范围内的RF信号传播，从Wi-Fi到毫米波。为了有效捕捉3D数据中的RF相关特征，我们提出了射频3D编码器（RF-3D Encoder），该编码器包含了与信号特定细节相关的3D几何复杂性。这些特征经过多尺度嵌入，以模拟实际的RF信号传播过程。基于合成和实地测量的评估证明，Diffusion^2能够在各种频段和环境条件下准确地估计RF信号的行为，误差幅度仅为1.9 dB，并且比现有方法快27倍，这标志着在该领域取得了重要突破。
### Innovation
Introduces Diffusion^2，一种基于扩散的方法，用于通过3D点云模型射频信号的传播，覆盖从Wi-Fi到毫米波的宽频率范围。提出了一种3D编码器（RF-3D Encoder），能够同时捕捉3D几何复杂性和信号特定的细节，并通过多尺度嵌入来模拟实际的RF信号传播过程。基于综合和现场测量的评估，显示在各种频段和环境条件下，Diffusion^2准确估计RF信号的行为，误差幅度仅为1.9 dB，比现有方法快27倍，提高了RF信号传播建模的精度和效率。
### Conclusion
Diffusion^2能够准确估计各种频段和环境条件下的RF信号行为，误差幅度仅为1.9 dB，并且比现有方法快27倍，标志着在RF信号传播建模领域取得了重要突破。
## 876. `cs.LG` - 量子辅助相关聚类 [PDF](https://arxiv.org/pdf/2509.03561), [HTML](https://arxiv.org/abs/2509.03561)
### Authors
Antonio Macaluso,Supreeth Mysore Venkatesh,Diego Arenas,Matthias Klusch,Andreas Dengel
### Background
相关聚类是一种基于图的无监督学习任务，它寻求根据节点间的两两同意和不同意的程度对图中的节点进行分区。传统的相关聚类方法通常需要对图的联系结构进行假设，或者依赖于预定义的数量聚类，或者无法处理负边等复杂情况。这项工作提出了一个混合量子-经典方法，旨在解决这个问题。
### Innovation
该研究引入了一个名为GCS-Q的量子辅助求解器的适应版本，用于最大内聚性聚类。通过递归分裂的方式，将每一步二分区编码为一个二次无约束二元优化问题，进而通过量子退火来解决。这种方法能够在不依赖于度量假设和预设数量聚类的情况下处理具有任意相关结构（包括负边）的图，从而使处理图并找到有效聚类成为可能。实验结果表明，调整后的GCS-Q相比于经典算法在处理真实场景以及聚类不平衡时具有更高的鲁棒性和聚类质量。
### Conclusion
研究结果表明了混合量子-经典优化技术在图基无监督学习中用于扩展和提高结构感知聚类技术的巨大潜力。
## 877. `cs.LG` - 交互式训练：基于反馈的神经网络优化 [PDF](https://arxiv.org/pdf/2510.02297), [HTML](https://arxiv.org/abs/2510.02297)
### Authors
Wentao Zhang,Yang Young Lu,Yuntian Deng
### Background
传统的神经网络训练通常遵循固定且预定义的优化方案，缺乏在不稳定或新出现的训练问题时动态响应的灵活性。
### Innovation
该论文介绍了一个名为交互式训练的开源框架，它通过人工专家或自动AI代理实时、基于反馈的干预，在神经网络训练过程中动态调整优化器超参数、训练数据和模型检查点。
### Conclusion
通过三个案例研究，该论文展示了交互式训练在训练稳定性、减少初始超参数敏感性和提高对不断变化用户需求的适应性方面具有优势，开启了未来训练范式的新篇章，其中AI代理可以自主监控训练日志、主动解决不稳定性，并优化训练动态。
## 878. `cs.LG` - KaVa: 通过压缩KV缓存蒸馏实现潜在推理 [PDF](https://arxiv.org/pdf/2510.02312), [HTML](https://arxiv.org/abs/2510.02312)
### Authors
Anna Kuzina,Maciej Pioro,Paul N. Whatmough,Babak Ehteshami Bejnordi
### Background
大型语言模型（LLMs）在需要逐步推理且有明确思维链（CoT）的问题上表现出色，但这种方式会导致计算成本和内存开销上升，同时还可能包含冗余和风格化的特性。潜在推理作为一种更加高效的方式，能够内在化思维过程，但在监督上存在不足，限制了其在复杂、自然语言推理问题上的应用效果。
### Innovation
本文提出了KaVa框架，这是首个通过自我蒸馏直接从老师压缩的KV缓存中提取知识，传递给潜在推理学生的框架。该方法利用连续潜在标记的表示灵活性，对齐逐步KV轨迹，使抽象且无结构的知识作为潜在推理学生的丰富监督信号成为可能。实验结果表明，该方法在性能上超过了其他潜在的基本模型，在仅方程到自然语言推理的过渡中表现出更小的性能下降，同时保持了效率和扩展性。
### Conclusion
实验结果确立了压缩KV缓存蒸馏作为潜在推理的可扩展监督信号的作用，结合了使用思维链训练教师的准确性以及潜在推理的效率和部署性。
## 879. `cs.LG` - Equilibrium Matching: 基于隐式能量模型的生成建模 [PDF](https://arxiv.org/pdf/2510.02300), [HTML](https://arxiv.org/abs/2510.02300)
### Authors
Runqian Wang,Yilun Du
### Background
该研究提出了Equilibrium Matching (EqM)，这是一种从平衡动力学视角构建的生成建模框架。传统的生成模型，如扩散和流模型，依赖于非平衡、时间条件的动力学，这在EqM中被舍弃。EqM 而是学习潜在能量景观的平衡梯度。这种 Approch 在推断时使用基于优化的采样过程，样例通过可调步长的梯度下降在学习到的景观上获得。EqM 在生成性能上优于扩散/流模型，FID 达到 1.90。EqM 也从理论上证明了其可以学习和从数据流形中采样。不仅如此，EqM 是一个灵活的框架，涵盖从去噪到 OOD 检测等任务。
### Innovation
EqM 推动了生成建模领域的发展，通过引入基于平衡梯度的隐式能量景观，它提供了一种简化的优化驱动推断方法；同时，EqM 框架在多个任务中显示出灵活性，包括半衰噪图像去噪、OOD 检测和图像合成等。
### Conclusion
总之，EqM 在生成性能和理论基础上都超过了现有的生成模型，为其后续研究和应用提供了坚实的基础，并展示了其在多任务处理中的广泛潜能。
## 880. `cs.LG` - 扩散模型与流形假设：对数域平滑是几何自适应的 [PDF](https://arxiv.org/pdf/2510.02305), [HTML](https://arxiv.org/abs/2510.02305)
### Authors
Tyler Farghly,Peter Potaptchik,Samuel Howard,George Deligiannidis,Jakiw Pidstrigach
### Background
扩散模型已经在各个领域取得了最先进的性能，显示出卓越的泛化能力，但其背后的具体机制仍不完全清楚。一个假设认为，扩散模型的成功源于它们适应数据内部的低维度几何结构的能力。
### Innovation
该工作通过研究经验评分匹配目标的平滑化效应，验证了这一假设，证明了通过对评分函数进行平滑（等价于对对数密度进行平滑），会产生针对数据流形的平滑效应。此外，研究还展示了通过选择适当的平滑可以控制扩散模型的泛化流形。
### Conclusion
该研究通过理论和实验证据支持了扩散模型中隐式正则化与数据流形的关系，并揭示了如何通过平滑技术来控制扩散模型的泛化能力。
## 881. `cs.LG` - Mamba 在十大 LLMs 情感分析驱动的股票预测中超越 Reformer [PDF](https://arxiv.org/pdf/2510.01203), [HTML](https://arxiv.org/abs/2510.01203)
### Authors
Lokesh Antony Kadiyala,Amir Mirzaeinia
### Background
股市在短期内难以预测，由于市场价格波动性高、新闻影响变化的大和金融时间序列的非线性特征。本文探讨了使用来自十个不同大型语言模型（LLMs）的语义情感分数（top ten LLMs）与一分钟区间内的股票价格数据相结合的方法，以提高分钟级别的预测准确度。
### Innovation
本文提出了一种新的框架，通过使用来自十个不同大型语言模型的语义情感分数，结合一分钟区间的股票价格数据，来提高分钟级别的预测准确性。研究使用了AAPL在2025年4月4日至5月2日之间的新闻文章和分钟级苹果公司的股票价格数据集。使用了最新的Reformer和Mamba模型进行训练，并通过Optuna优化超参数。
### Conclusion
研究发现，Mamba在所有10个LLM中表现出色，在LLaMA 3.3--70B上达到了最低的误差率0.137，而Reformer则无法很好地捕捉数据中的突然变化，显得过度平滑。这项研究表明，将基于LLM的情感分析与高效的时间序列建模相结合，有可能提高实时金融预测的准确性。
## 882. `cs.LG` - 通过拉普拉斯特征向量梯度正交化实现鲁棒性切空间估计 [PDF](https://arxiv.org/pdf/2510.02308), [HTML](https://arxiv.org/abs/2510.02308)
### Authors
Dhruv Kohli,Sawyer J. Robertson,Gal Mishne,Alexander Cloninger
### Background
切空间估计是数据分析中的基本问题。传统方法局部主成分分析（LPCA）在高噪声环境中表现不佳，因为邻域大小的选择存在着关键的权衡。安全性最优化要求先验了解数据的几何特性和噪声特性，但这些特性常常无法获得。本文探讨了在高噪声环境下进行切空间估计的挑战及其现有方法的不足。
### Innovation
提出了一种基于全局数据结构的光谱方法，即“拉普拉斯特征向量梯度正交化”（LEGO）。LEGO通过正交化图拉普拉斯低频特征向量的梯度来估计每个数据点的切空间，而不是仅依赖局部邻域。理论分析表明，LEGO方法在噪声鲁棒性方面优于LPCA，特别是在处理子高斯噪声时表现显著。通过全面的实验，证明了LEGO方法在子高斯噪声下的显著优越性，提升了下游任务如流形学习、边界检测和局部内在维数估计的效果。
### Conclusion
实验结果表明，LEGO方法比LPCA方法在噪声鲁棒性方面有显著提高。这意味着，对于高噪声环境下的切空间估计，LEGO方法可以有效提高下游任务的性能。
## 883. `cs.LG` - 开放权重模型的知元蒸馏检测 [PDF](https://arxiv.org/pdf/2510.02302), [HTML](https://arxiv.org/abs/2510.02302)
### Authors
Qin Shi,Amber Yijia Zheng,Qifan Song,Raymond A. Yeh
### Background
随着模型来源和未经授权的蒸馏复制问题日益引起关注，本文提出了知识蒸馏检测任务。在实际场景中，该任务旨在仅通过学生的权重和教师的API判断学生模型是否是从给定的教师模型蒸馏得到的。因此，提出了一个通用框架，结合数据无关的输入合成与统计评分计算方法来检测蒸馏的存在。这种方法在图像分类和文本到图像生成等多种架构上得到了验证，并显著提高了检测准确性，尤其在CIFAR-10、ImageNet等数据集上的提升效果更为显著。
### Innovation
提出了一个通用框架用于检测模型是否经过知识蒸馏，该框架综合了数据无关的输入合成和统计评分计算，特别适用于分类和生成模型。实验结果显示，该方法在CIFAR-10、ImageNet和文本到图像生成任务上的检测准确率分别比最强基线提高了59.6%、71.2%和20.0%。此外，该方法不仅适用于分类模型，也适用于生成模型，具有广泛的应用前景。
### Conclusion
本文提出了一种基于数据无关输入合成和统计评分计算的知识蒸馏检测方法，能够在开放权重模型中有效检测知识蒸馏的存在。该方法不仅提高了检测准确性，还扩大了适用范围，可应用于多种类型的模型和任务，为解决模型来源和防止未经授权的复制提供了切实有效的手段。
## 884. `cs.LG` - 超越剪裁的梯度塑形：更新幅度控制的功能视角 [PDF](https://arxiv.org/pdf/2510.01578), [HTML](https://arxiv.org/abs/2510.01578)
### Authors
Haochen You,Baojing Liu
### Background
梯度剪裁是稳定深度网络训练中广泛使用的方法，但其作为固定阈值的硬化形式限制了其灵活性，并忽视了梯度分布的动力学特性。
### Innovation
提出了一种统一体系结构SPAMP（统计逐层自适应调制和投影），将梯度剪裁统一为平滑的逐层梯度塑形。SPAMP会追踪局部梯度统计信息，动态估计阈值，并应用基于幂的变换以不同可微的方式调节更新幅度。
### Conclusion
广泛的实验表明，SPAMP相比现有方法在图像和语言任务中提高了稳定性和收敛性，以及鲁棒性。
## 885. `cs.LG` - GRPO++: 在低资源环境下增强皮肤病学推理 [PDF](https://arxiv.org/pdf/2510.01236), [HTML](https://arxiv.org/abs/2510.01236)
### Authors
Ismam Nur Swapnil,Aranya Saha,Tanvir Ahmed Khan,Mohammad Ariful Haque
### Background
视觉-语言模型（VLMs）在医学影像分析中表现出色，但在复杂领域如皮肤科中进行结构化推理的能力受到数据稀缺和先进训练技术高计算成本的限制。DermIQ-VLM 是通过一种多阶段、资源高效的方法开发的 VLM，旨在模拟皮肤科医生的诊断过程。研究背景主要集中在解决这些挑战。
### Innovation
贡献在于一种改进的组相对策略优化（GRPO）版本，称为 GRPO++，用于稳定强大的但数据密集的 GRPO 框架，并改进了监督微调和直接偏好优化（DPO），利用知识图谱系统作为专家偏好可扩展的代理。创新方法强调了在低资源环境下进行皮肤病学推理的有效性。
### Conclusion
初步评估表明，我们的方法在皮肤病学数据集上的表现优于标准的微调方法。研究结果验证了该管道在资源受限环境中开发专门且可靠的 VLM 的可行性。
## 886. `cs.LG` - 地理位置很重要：利用多分辨率地理嵌入进行房源搜索 [PDF](https://arxiv.org/pdf/2510.01196), [HTML](https://arxiv.org/abs/2510.01196)
### Authors
Ivo Silva,Pedro Nogueira,Guilherme Bonaldo(QuintoAndar)
### Background
 QuintoAndar Group 是拉丁美洲最大的房地产平台，正在通过简化租房和销售流程来革新房地产行业。总部位于巴西，该平台通过消除繁琐的文书工作和增强承租人、买家和房东的易访问性，提供数千处城市房源。然而，用户在选择理想的房源时面临挑战，尤其是地理位置的重要性影响了房产价值、便利设施的可达性和生活质量。鉴于此，地理位置在推荐中扮演了关键角色。该研究提出了一个地理位置感知的嵌入框架，以解决数字租赁平台上房源推荐中的稀疏性和空间特异性问题。
### Innovation
该研究提出了一个嵌入式框架，结合了多级别的 H3 网格（Hierarchical H3 grid）和双塔神经架构（two-tower neural architecture），以提高地理位置感知能力，解决房源推荐中的稀疏性和空间特异问题。并将该方法与传统的矩阵分解基线和多分辨率变体进行比较，显示出更丰富的嵌入表示和更高的推荐质量。
### Conclusion
通过嵌入特定的评估和线下排名模拟，该研究的方法在房源推荐质量上表现出了显著的提升，表明地理位置在推荐系统中的重要性，以及地理位置特征如何改善推荐系统的性能。
## 887. `cs.LG` - 话语与排放：基于大型语言模型对 CORPORATE 讲述、象征性行为及模仿的分析 [PDF](https://arxiv.org/pdf/2510.01222), [HTML](https://arxiv.org/abs/2510.01222)
### Authors
Bertrand Kian Hassani,Yacoub Bahini,Rizwan Mushtaq
### Background
气候变化导致企业气候披露需求增加，但模仿和象征性报告削弱了其价值。需开发多维框架评估气候披露成熟度，研究企业可持续性和年报中的语言指标与公司属性（如排放量、市值和行业）的关系。
### Innovation
开发了基于大型语言模型（LLMs）的多维度框架，通过分析828家企业的可持续性和年报中的讲述、承诺、具体性及目标雄心四个分类器，评估其气候披露成熟度，揭示了风险关注的叙述与明确承诺的关联，但量化目标与语气的脱钩现象，以及大且高排放企业的不一致披露行为，指出模仿行为减少了差异化和决策有用性。
### Conclusion
大型语言模型对于ESG叙述分析具有价值，但需加强监管将承诺与可验证的转型策略联系起来，以提高企业气候披露的价值和有效性。
## 888. `cs.LG` - 谁掌管？剖析指令执行中的角色冲突 [PDF](https://arxiv.org/pdf/2510.01228), [HTML](https://arxiv.org/abs/2510.01228)
### Authors
Siqi Zeng
### Background
大型语言模型应遵循分层指令，其中系统提示优先于用户输入，但现有研究显示，这些模型往往无视这一规则，而是过度遵循权威性或共识等社会提示。因此，该论文使用大规模数据集对这种行为进行了机制性解释，分析了冲突决策信号是如何被编码的，并通过指导实验揭示了指令遵循中的意外现象，即社会暗示虽被用作参考，但在角色中立的情况下，这些提示却意外地增强了指令遵循。
### Innovation
研究通过线性探针和直接Logit Attribution方法，展现了一种机制性的解释，并通过操控实验展示了在角色中立的情况下，社会线索如何加剧指令遵循。这些方法和发现提供了对系统遵从性脆弱性的理解，并强调了需要轻量级的、对层次敏感的对齐方法。
### Conclusion
该研究揭示了大型语言模型在指令执行中的角色冲突机制，并指出这些模型在遵循社会线索时，虽然可能意外地加强了指令遵循，但这种遵从性是脆弱的。由此，研究强调了开发轻量级的、对多层次结构敏感的方法以确保模型遵守系统提示的必要性。
## 889. `cs.LG` - GPT和偏见：理解大规模语言模型中学习表示的一种稀疏方法 [PDF](https://arxiv.org/pdf/2510.01252), [HTML](https://arxiv.org/abs/2510.01252)
### Authors
Mariam Mahran,Katharina Simbeck
### Background
随着大规模语言模型（LLMs）越来越多地在大量未经筛选的语料库上进行训练，理解和模型内部化的内容结构、主题和偏见已经变得越来越有挑战性。本文展示了如何通过将LLMs与稀疏自编码器（SAEs）相结合，不仅能解释模型行为，还能深入理解训练数据中的深层次结构、主题和偏见。研究者训练了一个仅基于简·奥斯汀小说（这些小说充满社会结构和叙事模式）的GPT风格变换器模型，并使用SAEs来揭示稀疏、可解释的特征，这些特征反映了语料库中的关键叙事和概念，如性别、阶级和社会责任。
### Innovation
通过将GPT风格的变换器模型与稀疏自编码器相结合，揭示了语料库中的稀疏、可解释的特征，这些特征反映了关键的叙事和概念，如性别、阶级和社会责任，并展示了这种方法作为大规模数据集的可扩展探针的作用，提供了新的路径来探索语料库、发现偏见和大规模模型的解释性
### Conclusion
LLMs结合SAEs可以提供一种可扩展的手段来探索复杂的数据集，为语料库探索、偏见发现和大规模模型可解释性提出了一种新的途径。
## 890. `cs.LG` - 无声的令牌，响亮的效果：大语言模型中的填充 [PDF](https://arxiv.org/pdf/2510.01238), [HTML](https://arxiv.org/abs/2510.01238)
### Authors
Rom Himelstein,Amit LeVi,Yonatan Belinkov,Avi Mendelson
### Background
在大型语言模型（LLMs）中，填充令牌被广泛用于使序列长度在批量推理时一致。尽管理想的填充令牌应完全被遮蔽，但实现错误可能导致其影响计算，但这种影响的程度尚未被充分理解。
### Innovation
本文系统地研究了这种效应，覆盖了三个开源模型家族（Llama、Gemma、Qwen），通过插入可控数量的填充并沿着四个维度进行评估：激活模型、生成质量、偏见和安全。即使很小数量的填充都会改变隐藏表示，影响小模型的质量，改变偏见并削弱安全措施。
### Conclusion
这些发现证明填充并非无关紧要的细节，而是一个稳健性的风险，在部署时必须谨慎处理。
## 891. `cs.LG` - 基于LLM的多代理黑板系统在数据科学中的信息发现 [PDF](https://arxiv.org/pdf/2510.01285), [HTML](https://arxiv.org/abs/2510.01285)
### Authors
Alireza Salemi,Mihir Parmar,Palash Goyal,Yiwen Song,Jinsung Yoon,Hamed Zamani,Hamid Palangi,Tomas Pfister
### Background
大型语言模型（LLMs）的快速发展为数据科学带来了新的机遇，但也带来了在大型异质数据湖中发现相关数据的挑战。现有的方法在单代理系统会因大量异质文件而迅速饱和，而基于主从架构的多代理系统依赖于一个严格的中央控制器进行任务分配，需要精确了解每个子代理的能力。
### Innovation
提出了一种基于传统AI模型黑板架构的新颖多代理通信模式，其中中央代理发布请求以共享黑板，自主的下属代理根据其能力自愿响应。这种设计通过消除中央协调者需要预先了解所有子代理专业知识的需要，提高了可扩展性和灵活性，实现了比现有基线方法（包括RAG和主从多代理模式）在端到端任务成功率上提高13%到57%以及超过最优基线9%的F1分数改进。
### Conclusion
我们的研究结果确立了黑板架构作为一种可扩展和可移植的多代理系统通信框架的地位。
## 892. `cs.LG` - OR-Toolformer: 使用工具增强的大语言模型解决运筹学问题 [PDF](https://arxiv.org/pdf/2510.01253), [HTML](https://arxiv.org/abs/2510.01253)
### Authors
Jianzhang Zhang,Jialong Zhou,Chuang Liu
### Background
大型语言模型（LLMs）在数学推理方面表现出色，但依赖于闭源API进行运筹学（OR）任务处理会引起隐私问题，并且从头开始训练开源模型会带来高昂的计算成本。
### Innovation
我们引入了OR-Toolformer，这是一种通过半自动数据合成管道对Llama-3.1-8B-Instruct进行微调的模型，该管道生成多样化的OR问题-答案对，并将外部求解器添加到模型中以产生API调用。在三个标准基准测试中，OR-Toolformer达到了80.1%的执行准确性，超过了同样规模的基线模型4.3%以上。在对两个未见过的OR问题类型的零样本评估中，它平均达到了54%的准确性，比最强的基线模型高出21个百分点。
### Conclusion
这些发现证实了工具增强的大型语言模型微调对于准确且可泛化的OR问题建模和解决的有效性。
## 893. `cs.LG` - TraceDet：扩散大规模语言模型解码轨迹中的幻觉检测 [PDF](https://arxiv.org/pdf/2510.01274), [HTML](https://arxiv.org/abs/2510.01274)
### Authors
Shenxu Chang,Junchi Yu,Weixing Wang,Yongqiang Chen,Jialin Yu,Philip Torr,Jindong Gu
### Background
扩散型大规模语言模型（D-LLMs）作为一种与自回归语言模型（AR-LLMs）相比具有前景的替代方案，近年来引起了研究者的注意。然而，D-LLMs中的幻觉问题尚未受到充分研究，限制了它们在实际应用中的可靠性。目前的方法主要是为AR-LLMs设计的，依赖于单步生成信号，但对于D-LLMs来说，幻觉信号可能在整个去噪过程中逐渐显现，导致这些方法并不适合D-LLMs.
### Innovation
本文提出了一种名为TraceDet的新框架，它显式地利用了D-LLMs的中间去噪步骤来进行幻觉检测。TraceDet将去噪过程建模为一个动作序列，并通过识别最能提供幻觉响应信息的子序列来利用多步去噪过程中的关键幻觉信号进行检测。与基线方法相比，实验结果表明TraceDet在各种开源D-LLMs上显著提高了幻觉检测的效果，平均AUCROC提高了15.2%.
### Conclusion
TraceDet在多步骤去噪过程中利用D-LLMs的中间输出进行幻觉检测，显著提升了幻觉检测的效果，标志着在D-LLMs上的幻觉检测研究方面的进展。
## 894. `cs.LG` - 带有接近最优样本复杂度的私有可实现到无假设转换 [PDF](https://arxiv.org/pdf/2510.01291), [HTML](https://arxiv.org/abs/2510.01291)
### Authors
Bo Li,Wei Wang,Peng Ye
### Background
在私有学习问题中，已有研究提供了一种将可实现私有学习器（在这种情况下，示例由概念类中的某个函数标记）转换为无假设私有学习器（对数据没有任何假设）的通用机制。具体来说，对于任何概念类C和错误参数α，可实现私有学习器可以被转换为无假设私有学习器，而只需要增加样本复杂度到VC(C)/α²的~O( )量级。但是当ε可以任意时，必须使用标准的隐私放大下采样技术，导致样本复杂度额外增加到~O(VC(C)/α²ε)，这其中包含了1/ε因子。
### Innovation
本文提供了一种改进的构建方法，消除了对ε的依赖，实现了对于任何ε≤1的接近最优的额外样本复杂度~O(VC(C)/α²)。此外，我们的成果显示，在私有无假设学习中，隐私成本仅在可实现部分显著。我们还使用该技术获得了私有预测问题的接近最紧样本复杂度界，解决了Dwork和Feldman（2018）以及Dagan和Feldman（2020）提出的一个公开问题。
### Conclusion
本文的结果进一步优化了私有无假设学习的样本复杂度，并揭示出在无假设部分，隐私成本影响相对较小。同时，通过技术改进解决了在私有预测问题上的样本复杂度限制问题。
## 895. `cs.LG` - Kant: 面向大规模AI集群的高效统一调度系统 [PDF](https://arxiv.org/pdf/2510.01256), [HTML](https://arxiv.org/abs/2510.01256)
### Authors
Lingling Zeng,Gen Zhang,Jialin Peng,Xiang Xu,Yuan Xu,Lijun Ma
### Background
随着AI集群规模的不断扩大，大规模语言模型（LLM）训练和推理工作负载的需求急剧增加，传统的调度系统在资源利用、调度效率和服务质量方面面临着重大挑战。
### Innovation
Kant是一个高效统一的调度平台，专为大规模AI容器集群设计，支持训练和推理作业的协同调度。通过Backfill和Enhanced Binpack（E-Binpack）等调度策略，Kant显著提高了资源利用率和调度效率，同时减少了分布式训练中的资源碎片化和通信开销。
### Conclusion
实验结果表明，Kant在从数百到数万个GPU的不同规模的集群中表现出色。该系统已在多个AI数据中心集群中部署，稳定支持大规模智能计算负载。这项工作提供了一种实用的工程方法，用于构建高性能、高可用性的AI原生调度基础设施。
## 896. `cs.LG` - MorphGen: 可控且形态学上可信的生成细胞成像 [PDF](https://arxiv.org/pdf/2510.01298), [HTML](https://arxiv.org/abs/2510.01298)
### Authors
Berker Demirel,Marco Fumero,Theofanis Karaletsos,Francesco Locatello
### Background
通过体外模拟细胞对干预的响应，可以加速基于高内容图像的筛选测试，这对药物发现和基因编辑至关重要。文章介绍了MorphGen模型，这是一种基于扩散的生成模型，专为荧光显微镜图像生成而设计，旨在支持药物发现等应用。MorphGen能够根据不同细胞类型和扰动进行跨模态的可控生成，通过与OpenPhenom生物基础模型的表型嵌入进行对齐训练，以捕捉与已知细胞形态一致的生物学上意义显著的模式。与之前将多通道染色压缩为RGB图像的方法相比，MorphGen可以同时生成完整的荧光通道，保持每种胞器的结构信息。
### Innovation
MorphGen通过与OpenPhenom的表型嵌入进行对齐训练实现生物学意义的形态生成；能够同时生成完整的荧光通道，保持每种胞器的结构信息；相较于仅产生单细胞类型RGB图像的MorphoDiff，MorphGen的FID分数低35%以上。
### Conclusion
MorphGen通过体外模拟细胞响应，为药物发现和基因编辑的应用提供了新的方法。与现有的生成模型相比，MorphGen展示了更好的生物学一致性和细微的形态分析能力。
## 897. `cs.LG` - 掩蔽作为冗余：形式化人工老化评分（AAS）以建模生成型AI的记忆老化 [PDF](https://arxiv.org/pdf/2510.01242), [HTML](https://arxiv.org/abs/2510.01242)
### Authors
Seyma Yaman Kayadibi
### Background
本研究探讨了人工智能衰老的现象，指出AI不是通过时间变化衰老，而是通过记忆性能的结构不对称性体现。在大型语言模型中，语义提示可能在多个对话会话中保持不变，而事件细节则在重置对话上下文时会衰减。通过引入人工老化评分（AAS），该研究试图捕捉这种现象。AAS是一个基于可观察的记忆召回行为的、对数缩放且信息熵驱动的指标，用于衡量记忆老化。AAS在理论上被证明是良定义的、有界的，并且在温和且模型无关的假设下是单调的，使其适用于各种任务和领域。在研究中，冗余被解释为重叠信息，减少被惩罚的质量，但在当前研究中未明确估计冗余，因此所有报告的值都假设冗余为零的场景，从而给出保守的上限值。研究还在25天内对ChatGPT-5进行了双语实验，分为无状态和持续交互阶段，在持续交互阶段中，模型可以稳定地回忆起长期记忆中的细节，导致AAS趋向于理论上的最小值，表示结构上较为年轻。在重置对话上下文后，尽管保持了语义一致性，却丧失了事件连续性，导致AAS急剧上升，表明结构记忆老化。该研究建立在冯·诺依曼的自动机概念、香农的信息和冗余理论，以及图灵的行为智能方法的基础上。
### Innovation
该研究创新性地提出了人工老化评分（AAS），这是一种用于建模生成型AI记忆老化的指数化熵驱动指标。AAS能够量化和解决因对话环境重置导致的记忆连续性丧失问题。通过引入AAS，研究者提供了一种理论支持且任务独立的方法，用于诊断和监控AI的记忆衰退情况。这一方法适用于多种任务和领域，并通过实验证明了AAS的有效性，特别是通过衡量AAS的变化来区分AI记忆的长期连续性和短期可靠性。
### Conclusion
该研究证实了人工老化评分（AAS）作为理论上支撑、任务无关的诊断工具的有效性，用于评估人工智能系统的记忆衰退。研究发现了对话环境重置与记忆连续性丧失之间的关系，表明AAS能够量化和提供AI记忆老化的指标，从而为持续优化人工智能系统的长期可靠性提供了有力支持。研究为理解和改进生成型AI的记忆管理提供了新的视角，特别是在无状态下保持记忆连续性的长期挑战中具有重要意义。
## 898. `cs.LG` - HiSpec: 层次推理解码法用于LLMs [PDF](https://arxiv.org/pdf/2510.01336), [HTML](https://arxiv.org/abs/2510.01336)
### Authors
Avinash Kumar,Sujay Sanghavi,Poulami Das
### Background
现有的推理加速方法主要集中在加速draft模型，而忽略了验证过程。尽管使用中间验证可以减少验证时间，但原有的方法引入了过高的训练负担，增加了内存足迹，并依赖于近似的技术来降低准确度。草案模型生成的令牌在被大型目标模型验证之前，往往成为验证过程中的瓶颈。
### Innovation
HiSpec框架提出了层次化的推测解码方法，利用early-exit模型进行低开销的中间验证。同时，设计了一种方法让HiSpec能够在draft、中间验证者和目标模型之间复用关键值缓存和隐藏状态，以提高资源效率，保持准确度。
### Conclusion
HiSpec在使用各种基准测试和模型的评估中，平均提高了1.28倍的吞吐量，最高达到2.01倍的基线单层推测吞吐量，同时没有牺牲准确度。
## 899. `cs.LG` - Cyber Academia-Chemical Engineering (CA-ChemE): 一个自我导向研究演化和新兴科学发现的活数字城镇 [PDF](https://arxiv.org/pdf/2510.01293), [HTML](https://arxiv.org/abs/2510.01293)
### Authors
Zekun Jiang,Chunming Xu,Tianhang Zhou
### Background
人工智能（AI）在化学工程领域显示出巨大的潜力，但现有的AI系统在多学科合作和探索未知问题方面仍存在限制。
### Innovation
本文提出了一种名为Cyber Academia-Chemical Engineering (CA-ChemE)的系统，通过多智能体协作，结合领域特定知识库、知识增强技术和协作代理，构建了一个智能生态系统，能够实现深入的专业推理和高效跨学科合作。特别地，引入了具有本体工程能力的合作代理（CA），解决了不同领域之间合作效率低下的瓶颈。
### Conclusion
研究证明，精心设计的多智能体架构为化学工程中的自主科学研究提供了一条可行途径。
## 900. `cs.LG` - 将复杂朗之万动力学与基于分数和能量的扩散模型相结合 [PDF](https://arxiv.org/pdf/2510.01328), [HTML](https://arxiv.org/abs/2510.01328)
### Authors
Gert Aarts,Diaa E. Habibi,Lingxiao Wang,Kai Zhou
### Background
一些理论因其复共轭作用或玻尔兹曼权重而导致符号问题，通常无法直接进行数值求解。然而，可以通过在复化配置空间中使用随机过程（如复朗之万过程）来尝试解决这类问题，尽管这些过程所有效采样的概率分布事先并不明确，且难以理解。在生成型人工智能中，扩散模型能够从数据中学习分布或其对数导数。该研究探讨了使用扩散模型学习复朗之万过程所抽样的分布的能力，对比了基于分数和能量的扩散模型，并推测可能的应用范围。
### Innovation
该研究尝试将复朗之万过程与生成型人工智能中的扩散模型（包括基于分数和能量的扩散模型）相结合，以期更好地理解复朗之万过程所抽样的概率分布，从而解决符号问题。
### Conclusion
研究结果表明，扩散模型具有一定的潜力来学习复朗之万过程所抽样的分布，特别是在基于分数的扩散模型中。这为理解和解决复朗之万过程中的符号问题提供了一种新的思路，并可能在未来探索更多实际应用。
## 901. `cs.LG` - 在埃塞俄比亚阿姆哈拉地区基于多输出回归和时间序列预测的疟疾发病率混合预测模型 [PDF](https://arxiv.org/pdf/2510.01302), [HTML](https://arxiv.org/abs/2510.01302)
### Authors
Kassahun Azezew,Amsalu Tesema,Bitew Mekuria,Ayenew Kassie,Animut Embiale,Ayodeji Olalekan Salau,Tsega Asresa
### Background
在埃塞俄比亚，特别是阿姆哈拉地区，疟疾仍然是一个重要的公共卫生问题。该地区的疟疾传播模式具有季节性和不确定性，这使得预防和控制工作变得困难。准确预测疟疾爆发对于有效分配资源和及时干预至关重要。因此，研究提出了一种结合时间序列预测、多输出回归和基于回归的传统预测的混合预测模型，以预测疟疾发病率。该模型利用阿姆哈拉地区的环境变量、过去的疟疾病例数据和人口统计信息进行训练和验证。
### Innovation
该研究提出了一种混合预测模型，通过结合时间序列预测、多输出回归和基于回归的传统预测方法，同时预测不同类型的疟疾病例、时间趋势和空间变化，从而捕捉季节性模式和预测因子之间的相关性，提高了预测准确性，并揭示了隐藏的模式，为公共卫生部门提供了有价值的信息。
### Conclusion
该研究提供了一个有效的、可重复的疟疾发病率预测框架，可以支持基于证据的决策、目标干预和资源优化。
## 902. `cs.LG` - 将他人的思维视为代码的建模 [PDF](https://arxiv.org/pdf/2510.01272), [HTML](https://arxiv.org/abs/2510.01272)
### Authors
Kunal Jha,Aydan Yuenan Huang,Eric Ye,Natasha Jaques,Max Kleiman-Weiner
### Background
准确预测人类行为对于稳健和安全的人机协作至关重要。然而，现有的模型人类行为的方案往往需要大量的数据，并且不够强大，因为它们要么基于不切实际的理性假设，要么计算成本高，无法迅速适应。
### Innovation
本文的关键洞察是，许多日常生活中的互动行为可能遵循可预测的模式；这些行为程序简化了参与者和观察者的认知负荷，例如，“等待绿灯亮起，然后通行”。本文提出了ROTE算法，结合大型语言模型（LLMs）生成行为程序的假设空间，并使用概率推理处理该空间中的不确定性。本文在网格世界任务和大规模物理家庭模拟器上测试了ROTE。ROTE在样本内准确性和样本外泛化能力方面比基准方法——包括行为克隆和基于LLM的方法——高出50%。
### Conclusion
将动作理解视为程序合成问题，ROTE为AI系统提供了一种有效准确预测真实世界中人类行为的途径。
## 903. `cs.LG` - AdaDetectGPT: 基于统计保证的生成性大模型文本适应性检测 [PDF](https://arxiv.org/pdf/2510.01268), [HTML](https://arxiv.org/abs/2510.01268)
### Authors
Hongyi Zhou,Jin Zhu,Pingfan Su,Kai Ye,Ying Yang,Shakeel A O B Gavioli-Akilagun,Chengchun Shi
### Background
现有的基于logits的检测器使用给定大语言模型分布函数推导出的统计信息来评估观测文本的log概率，以此判断文本是由人类还是大语言模型生成的。然而，仅仅依赖log概率可能不是最优的。
### Innovation
提出了AdaDetectGPT —— 一种新的分类器，通过适应性地从训练数据中学习目击函数来提高logits基检测器的性能。该方法提供了其真正阳性率、假阳性率、真正阴性率和假阴性率的统计保证。广泛的数值研究表明，AdaDetectGPT在各种数据集和大语言模型组合中，几乎一致地优于现有的最先进的方法，性能提升幅度最高可达58%。
### Conclusion
我们的方法在 this https URL 可供使用，全面的数值研究显示AdaDetectGPT几乎均匀提升最先进的方法在不同数据集和大语言模型组合的表现，改进幅度最高可达58%。
## 904. `cs.LG` - 连续增强的离散扩散模型在分类生成建模中的应用 [PDF](https://arxiv.org/pdf/2510.01329), [HTML](https://arxiv.org/abs/2510.01329)
### Authors
Huangjie Zheng,Shansan Gong,Ruixiang Zhang,Tianrong Chen,Jiatao Gu,Mingyuan Zhou,Navdeep Jaitly,Yizhe Zhang
### Background
标准的离散扩散模型在未观察状态之间均等映射到一个吸收的[MASK]标记，这导致了‘信息空缺’的问题。在去噪步骤中，有用的语义信息在未标记的标记之间丢失。现有的模型难以平衡生成多样性和上下文精确性之间的关系。
### Innovation
提出了一种名为连续增强的离散扩散（CADD）的框架，该框架将离散状态空间与连续潜空间中的配对扩散相结合，生成介于污染状态之间的渐进污染状态。被掩蔽的标记由噪声但具信息性的潜向量表示，而不仅仅是塌陷的‘信息空缺’。在每次反向步骤中，CADD可以利用连续的潜空间作为语义提示来引导离散去噪。该设计简洁且与现有的离散扩散训练兼容。在采样时，连续潜向量的强度和估计器的选择促进了对模式覆盖（生成多样化输出）和模式搜索（生成上下文精确输出）行为之间的可控权衡。
### Conclusion
实验证明，与基于掩码的扩散相比，CADD在文本生成、图像合成和代码建模方面均提高了生成质量，一致地在定性和定量指标上优于强壮的离散基线。
## 905. `cs.LG` - DeMuon：图上矩阵优化的去中心化穆恩方法 [PDF](https://arxiv.org/pdf/2510.01377), [HTML](https://arxiv.org/abs/2510.01377)
### Authors
Chuan He,Shuyi Ren,Jingwei Mao,Erik G. Larsson
### Background
本文提出了DeMuon方法，这是一种用于给定通信拓扑下的去中心化矩阵优化方法。该方法将来自其集中式前身Muon的矩阵正交化技术（通过Newton-Schulz迭代实现）与梯度跟踪结合，以缓解局部函数之间的异质性。在重尾噪声条件下，并在额外的一些温和假设下，DeMuon被证明能够达到近似随机平稳点的迭代复杂性。这一复杂性结果在目标公差的依赖性方面与已知的集中式算法的最佳复杂性界限相匹配。据我们所知，DeMuon是第一个直接将Muon扩展到带证明复杂性保证的图上的去中心化优化。
### Innovation
DeMuon方法通过引入矩阵正交化技术和梯度跟踪，克服了集中式Muon方法在去中心化场景下的适用性限制，实现了在图上的去中心化矩阵优化。其迭代复杂性结果与已知的集中式算法的最佳复杂性界限相匹配，开创了去中心化优化的一个新方向。
### Conclusion
通过初步的数值实验，DeMuon在不同的网络拓扑结构下相较于其他流行的去中心化算法展示了明显的性能优势。
## 906. `cs.LG` - 学习在多追随者贝叶斯斯塔克尔伯格博弈中的策略 [PDF](https://arxiv.org/pdf/2510.01387), [HTML](https://arxiv.org/abs/2510.01387)
### Authors
Gerson Personnat,Tao Lin,Safwan Hossain,David C. Parkes
### Background
该研究基于多追随者贝叶斯斯塔克尔伯格博弈的背景下进行。在这种博弈中，领导者通过混合策略在一个周期内采取行动，每个追随者根据其私有类型进行最优响应。领导者策略的最优性取决于追随者私有类型的分布。研究将博弈设定从静态转变为在线学习环境，即领导者在与不固定私有类型分布的追随者进行多次互动中，尝试最小化其策略与最优策略之间的累积差异，即遗憾值。研究在两种不同的反馈设置下设计了学习算法，以适应不同类型的信息观察情况，并提供了相应的遗憾值上界和下界分析。
### Innovation
该研究的创新点在于提出了不同的反馈环境下在线学习算法的设计与分析，具体表现在针对两种反馈设置（类型反馈和动作反馈）设计了算法，并给出了不同公式的遗憾值上界，特别是在独立类型分布和一般类型分布下取得了非多项式增长的上界结果。特别是在动作反馈中，提出了较为复杂的计算遗憾值上界的方法，并且证明了在动作反馈中设计的算法通过遗憾值下界分析与类型反馈中的上界几乎匹配。这些算法设计为解决多追随者贝叶斯斯塔克尔伯格博弈的在线学习问题提供了新的视角和方法。
### Conclusion
研究总结了在线学习多追随者贝叶斯斯塔克尔伯格博弈中的核心算法与分析框架，并给出了在不同类型反馈环境下遗憾值的具体上界，特别是展示了不同类型分布下的遗憾值上界不会多项式地增长，提供了一般性的分析结果。这些结论不仅完善了博弈论中的在线学习问题的研究，也为实际应用中的决策过程提供了一定的理论支持。
## 907. `cs.LG` - 生成式AI对金融稳定的影响：驯服动物精神 [PDF](https://arxiv.org/pdf/2510.01451), [HTML](https://arxiv.org/abs/2510.01451)
### Authors
Anne Lundgaard Hansen,Seung Jung Lee
### Background
本文研究了生成式AI在金融领域的应用对其稳定性的潜在影响。通过使用大型语言模型进行实验室研究，复制了关于交易决策中羊群行为的经典研究，旨在了解AI在金融市场中的表现与人类之间的差异，以及这种差异对金融体系稳定性的影响。研究发现，AI在决策中更多依赖私人信息而非市场趋势，这表明AI可能减少由羊群心理引起的资产泡沫。然而，在实验设计的不同条件下，研究还揭示了AI能够在特定条件下做出最大化利润的最优选择，从而提高市场纪律，但可能仍对金融稳定带来潜在影响。此外，还发现AI并非完全算法化，部分保留了人类的条件和偏见。
### Innovation
该研究通过实验室实验将大型语言模型运用到心理学上羊群行为的经典研究中，这是一种创新的研究方法。研究还关注AI在金融市场中表现的多样性和其双重性：既可能带来稳定性提升，也可能保留人类的某些偏见和条件，增加复杂性。此外，研究深入探索了不同实验设置下AI的行为差异，为理解AI在金融市场中的应用提供了新视角。
### Conclusion
尽管AI在金融决策中显示出更高的理性，但其对羊群行为的模仿表明，在特定条件下AI也能实现最优的羊群行为，从而提升市场纪律。然而，这种行为仍然可能对金融稳定产生潜在影响，特别是当AI保留了一部分人类的偏见和条件时。因此，未来研究需要进一步探讨如何利用AI的优势同时减轻其潜在风险，以确保金融市场稳定。
## 908. `cs.LG` - 通过跨模态对齐轨迹进行 fine-tuning 视觉语言模型的数据选择 [PDF](https://arxiv.org/pdf/2510.01454), [HTML](https://arxiv.org/abs/2510.01454)
### Authors
Nilay Naharas,Dang Nguyen,Nesihan Bulut,Mohammadhossein Bateni,Vahab Mirrokni,Baharan Mirzasoleiman
### Background
数据高效学习旨在通过在更具信息量的子数据集上训练模型来减少大型训练数据集中的冗余。已有大量研究探讨了数据选择在视觉模型和大型语言模型中的应用，但在大规模视觉语言模型（LVLMs）中的研究相对较少。目前，没有方法能够在不同子数据集大小的情况下超越随机选择。为了填补这一空白，该研究提出了一种基于模型参数变化的数据高效指令调优方法。通过将具有相似跨模态注意力矩阵的示例进行聚类，并从这些簇中采样平衡的子集，该方法有效地减少了大规模LVLM训练数据中的冗余，并展示了显著的性能和训练速度提升。
### Innovation
该论文提出了一种名为XMAS的新方法，用于大规模视觉语言模型的数据高效指令调优。该方法利用了相似跨模态注意力矩阵的示例具有相似梯度的原理，从而能够以相似的方式影响模型参数。XMAS通过基于注意力矩阵的奇异值轨迹进行聚类，并从中采样平衡的子集，从而能够在减少大量数据的同时保持模型性能。
### Conclusion
该方法经广泛实验验证，能够显著减少LVLM训练数据的冗余，对于LLaVA-665k数据集，XMAS可以减少50%的数据量且不损失性能，在减少85%的Vision-Flan数据集的同时，还能加速1.2倍的训练过程。这一数据减少量优于现有最佳基线30%。
## 909. `cs.LG` - SPUS:一个轻量级和参数高效的PDE基础模型 [PDF](https://arxiv.org/pdf/2510.01370), [HTML](https://arxiv.org/abs/2510.01370)
### Authors
Abu Bucker Siddik,Diane Oyen,Alexander Most,Michal Kucer,Ayan Biswas
### Background
现有的PDE基础模型主要基于复杂的大型Transformer架构，计算和参数成本高，而这些模型尚未被广泛用作该领域的基础模型架构。SPUS利用轻量级的残差U-Net结构，并通过模仿数值求解器的行为进行自回归预训练，从而在简化框架中实现有效的学习。
### Innovation
SPUS采用了一种轻量级的残差U-Net结构，并通过一种简单的自回归预训练策略进行训练，这种策略模拟了数值求解器的行为来学习基础物理。SPUS在各种PDE下游任务上表现出色，所需要的参数少且无需大量微调数据。
### Conclusion
实验结果表明，使用残差U-Net结构的SPUS在这些下游任务上实现了最先进的泛化能力，同时比现有模型所需的参数少得多，强调了其作为解决各种PDE系统高效参数化基础模型的潜力。
## 910. `cs.LG` - 尖峰回归中的风险相变：对齐驱动的良性和灾难性过拟合 [PDF](https://arxiv.org/pdf/2510.01414), [HTML](https://arxiv.org/abs/2510.01414)
### Authors
Jiping Li,Rishi Sonthalia
### Background
本文使用尖峰协方差数据模型分析了线性回归中最小范数插值解的一般ization误差。研究表明，尖峰强度和目标-尖峰对齐的变化会影响风险，特别是在参数过剩的情况下。具体而言，文章提出了关于尖峰强度、方面比$c=frac{d}{n}$（尤其是$c to frac{d}{n} to frac{text{无穷小}}{n}$）以及目标对齐的一个精确表达式，从而对良性、消减危害性、灾难性过拟合进行了全面分类。
### Innovation
文章的一个创新点是发现增加尖峰强度在特定条件下能引发灾难性过拟合，而在此之前可能是良性过拟合。此外，文章揭示了目标-尖峰对齐并非总是有利的，并指出了其对齐的特定、有时出乎意料的条件，且实验证明这种对齐在非线性模型中也是有害的。
### Conclusion
文章总结了尖峰回归中的风险相变，强调了尖峰强度、目标对齐以及方面比对于风险和过拟合形态的影响。具体地，文章指出了在特定条件下，增加尖峰强度可以导致灾难性过拟合在良性过拟合之前出现，并且详细分类了良性、消减危害性、灾难性过拟合的不同情况。
## 911. `cs.LG` - A-VERT: 无关嵌入排名目标的验证 [PDF](https://arxiv.org/pdf/2510.01469), [HTML](https://arxiv.org/abs/2510.01469)
### Authors
Nicolás Aguirre,Ramiro Caso,Ramiro Rodríguez Colmeiro,Mauro Santelli,Joaquín Toranzo Calderón
### Background
在语言模型（LM）的发展中，自动评估LM响应是开发基准和度量的关键组成部分，这既用于模型训练，也用于评估生产模型端点的质量。当前的响应分类方法要么过于昂贵（如LLM作为裁判），要么远离现实条件（如字符串匹配、对数概率）。
### Innovation
本文提出了一种结构无关的评估方法。该方法利用语义嵌入距离将目标候选词与任意生成的文本匹配，从而在相对较低的计算成本（嵌入模型参数少于10B）下实现了响应的稳健分类。这种方法在不同数据集和不同LM架构上与人类注释者的分类结果相比，回归分数约为0.97，准确率约为96%。
### Conclusion
该研究展示了一种结构无关的语义嵌入排名方法，能够以较低的计算成本实现高度准确的LM响应评估，其结果与人类注释者相当。
## 912. `cs.LG` - VOGUE: 使用视觉不确定性引导探索以提高跨模态推理 [PDF](https://arxiv.org/pdf/2510.01444), [HTML](https://arxiv.org/abs/2510.01444)
### Authors
Rui Liu,Dian Yu,Tong Zheng,Runpeng Dai,Zongxia Li,Wenhao Yu,Zhenwen Liang,Linfeng Song,Haitao Mi,Pratap Tokekar,Dong Yu
### Background
该论文指出，强化学习与验证奖励（RLVR）通过提高大型语言模型（LLMs）的推理能力，但在探索方面存在困境。尽管现有方法将视觉输入视为固定的、确定性的条件，但这种方法未能充分利用视觉输入中的固有不确定性，并且难以构建能够抵御视觉变化的稳健策略。对于多模态语言模型（MLLMs），这个问题更为突出。
### Innovation
论文提出了VOGUE（Visual Uncertainty Guided Exploration），一种新型探索方法，将探索从输出（文本）转向输入（视觉）空间。VOGUE通过将图像视为随机上下文，并使用“原始”和“噪声”分支之间的对称KL散度来量化策略对视觉扰动的敏感性，从而直接生成一个用于不确定性感知探索的信号。该信号通过不确定比例奖励，结合令牌熵奖励和退火采样计划，有效地平衡了探索与利用。在两个模型规模（Qwen2.5-VL-3B/7B）上实现VOGUE后，论文在三种视觉数学基准测试和三种通用领域推理基准测试中，平均提高了1.6%的pass@1准确率，并同时增强了pass@4性能，有效缓解了RL微调中常见的探索衰退问题。
### Conclusion
研究表明，基于视觉输入固有不确定性的探索策略能有效提高跨模态推理能力。
## 913. `cs.LG` - 居住建筑HVAC中基于模型预测控制和强化学习的对比现场部署 [PDF](https://arxiv.org/pdf/2510.01475), [HTML](https://arxiv.org/abs/2510.01475)
### Authors
Ozan Baris Mulayim,Elias N. Pergantis,Levi D. Reyes Premer,Bingqing Chen,Guannan Qu,Kevin J. Kircher,Mario Bergés
### Background
模型预测控制（MPC）能够为HVAC系统提供显著的节能效果，但通常需要大量工程投入，限制了其可扩展性。相比之下，强化学习（RL）自动化程度更高且更具适应性，但在实际生活中的应用仍处于起步阶段，面临着安全性、可解释性和样本效率等问题。因此，为了进一步研究这些实际问题，研究者在美国印第安纳州韦斯特拉法叶的一栋受居住者影响的有热泵系统的房屋中，部署了基于模型的MPC控制器和基于模型的RL控制器，进行了为期一个月的直接对比实验，旨在探索这两种控制器的可扩展性，并确保安全性与可比性。实验结果表明，RL相对于现有控制器实现了显著的节能效果（减少22%），与MPC的节能效果（减少20%）相比略占优势，但以轻微增加的居民不适为代价。在考虑到舒适度的情况下，MPC展现出更好的性能。这项研究的实验证据表明，尽管RL能够降低工程负担，但它引入了关于模型准确性和操作鲁棒性的实际权衡。研究还揭示了在安全控制器初始化、控制行动及其实际实施之间的不匹配导航，以及在实时环境中保持在线学习完整性的关键挑战。这些发现为推进RL从有希望的概念转变为真正可扩展的HVAC控制解决方案指明了必要的研究方向。
### Innovation
该研究创新之处在于通过现场部署实验直接比较基于MPC和基于RL的先进控制器，并首次在现实居住建筑环境中展示了RL的潜在应用，同时分析了存在的挑战，为未来的技术发展提供了指导。实验使用了一个受居住者影响的热泵系统房屋，验证了两种先进控制策略的实际效果和局限性，为实际应用提供了重要的数据支持和理论依据。
### Conclusion
尽管RL降低了工程负担，但其在模型准确性和操作鲁棒性方面存在实际权衡，并带来了安全控制器初始化、控制行动与其实际实施之间的不匹配问题以及在线学习的完整性问题。研究结果表明，为了将RL从有希望的概念转变为真正可扩展的HVAC控制解决方案，未来需要进一步的研究来解决这些关键问题。
## 914. `cs.LG` - Purrception: 变分流匹配在向量量化图像生成中的应用 [PDF](https://arxiv.org/pdf/2510.01478), [HTML](https://arxiv.org/abs/2510.01478)
### Authors
Răzvan-Andrei Matişan,Vincent Tao Hu,Grigory Bartosh,Björn Ommer,Cees G. M. Snoek,Max Welling,Jan-Willem van de Meent,Mohammad Mahdi Derakhshani,Floor Eijkelboom
### Background
近年来，变分流匹配和向量量化在图像生成中得到了广泛应用。变分流匹配能够提供平滑的转化动力学，而向量量化则能够提供明确的分类监督，但两者结合的同时面临着将连续转化动力学与离散监督有效结合的挑战。Purrception 方法通过学习码本索引的分类后验并在连续嵌入空间中计算速度场，结合了连续方法的几何意识和分类方法的离散监督，从而实现了在生成图像中的不确定性量化和温度控制生成。
### Innovation
Purrception 方法通过适应变分流匹配来处理向量量化隐变量，通过学习码本索引的分类后验并在连续嵌入空间中计算速度场，从而使几何意识和离散监督相结合。这种方法能够更高效地进行训练并实现与最先进技术相当的 FID 分数，证明了变分流匹配能够有效结合连续转化动力学和离散监督，从而提高图像生成的训练效率。
### Conclusion
实验结果表明，Purrception 方法在 ImageNet-1k 256x256 生成任务中比连续流匹配和离散流匹配基线更快收敛，同时实现了和最先进的模型相当的 FID 分数，证明了该方法的有效性与创新性。
## 915. `cs.LG` - INSIGHT：视觉-语言-动作模型推理时序内省用于生成求助触发器 [PDF](https://arxiv.org/pdf/2510.01389), [HTML](https://arxiv.org/abs/2510.01389)
### Authors
Ulas Berk Karli,Ziyao Shangguan,Tesca FItzgerald
### Background
近年来，视觉-语言-动作（VLA）模型展示了强大的泛化能力，但它们缺乏内在机制，以预见潜在失败并请求人类监督者的帮助。本文研究了利用基于标记的不确定性信号来预测VLA应在何时请求帮助的方法。
### Innovation
提出了INSIGHT（推理时序内省），一种利用标记级别不确定性信号来预测何时应当请求帮助的模型学习框架。作者用π0-FAST作为底层模型，提取每个标记的熵、对数概率以及基于Dirichlet的不确定性估计，并培训紧凑的变换器分类器将这些序列映射到帮助触发。此外，作者还探索了强监督和弱监督的不同监管模式，并在各类任务中进行了广泛比较。
### Conclusion
研究结果表明，强标签能够使模型捕获更精细的不确定性动态以实现可靠的帮助检测，而虽然弱标签更嘈杂但仍然支持在训练和评估对准时进行竞争性的自我反省。研究利用变换器建模标记级别不确定性信号的时间演化比静态序列级别得分具有更强的预测力。这为视觉-语言-动作模型中的基于不确定性内的自我反省提供了一种系统性的评估，并为未来的主动学习以及通过选择性的人类干预实现实时错误缓解提供了可能的途径。
## 916. `cs.LG` - WALT: Web Agents that Learn Tools [PDF](https://arxiv.org/pdf/2510.01524), [HTML](https://arxiv.org/abs/2510.01524)
### Authors
Viraj Prabhu,Yutong Dai,Matthew Fernandez,Jing Gu,Krithika Ramakrishnan,Yanqi Luo,Silvio Savarese,Caiming Xiong,Junnan Li,Zeyuan Chen,Ran Xu
### Background
现有的网络代理方法在自动化复杂浏览器任务时仍然很脆弱，主要依赖于详细的用户界面交互和高度依赖大型语言模型的推理，这些方法在遇到动态布局和长时间跨度时表现不佳。相比之下，人类用户通过高级操作（如搜索、过滤和排序）利用网站提供的功能。
### Innovation
WALT框架通过反向工程潜藏的网站功能，提炼成可重用的工具集，从而减少了对脆弱的步骤推理和大量依赖大型语言模型推理的依赖。WALT框架涵盖了发现（搜索、过滤、排序）、通信（发布、评论、点赞）和内容管理（创建、编辑、删除）等不同领域的自动化工具实施，这些工具提高了自动化任务的成功率和效率，简化了代理的操作方式，并且减少了LLM的依赖性，从而构建了一个强大的、可泛化的浏览器自动化范式。
### Conclusion
在VisualWebArena和WebArena上，WALT实现了更高的成功率，使用更少的步骤，并且对LLM的依赖性更低，这确立了一个强大的、可泛化的浏览器自动化范式。
## 917. `cs.LG` - ImageNet-Think-250K：一种大规模合成多模态推理数据集用于视觉语言模型 [PDF](https://arxiv.org/pdf/2510.01582), [HTML](https://arxiv.org/abs/2510.01582)
### Authors
Krishna Teja Chitty-Venkata,Murali Emani
### Background
视觉语言模型（VLMs）的发展需要有效的多模态推理数据集来支持其研究。当前的数据集中缺乏能够促进VLMs进行具体推理的数据，因此本文旨在创建一个新数据集来解决这一问题。
### Innovation
本文提出了一种名为ImageNet-Think的新数据集，基于250,000张来自ImageNet21k的图像，提供了结构化的推理标记和相应的答案。该数据集使用两个最先进的VLMs生成合成数据。每个图像都配有两对推理-答案序列，旨在为多模态推理模型的训练和评估提供资源。通过捕捉VLMs的推理步骤和最终描述性答案，本文尝试促进更稳健的VLMs发展。
### Conclusion
本文的目标是推动更稳健的VLMs发展，促进多模态推理机制的更广泛理解。此外，此数据集和评估基准将公开提供，以支持关于多模态推理/思考VLMs的研究。
## 918. `cs.LG` - 使用有限训练数据实现口腔癌稳健分类 [PDF](https://arxiv.org/pdf/2510.01547), [HTML](https://arxiv.org/abs/2510.01547)
### Authors
Akshay Bhagwan Sonawane,Lena D. Swamikannan,Lakshman Tamil
### Background
全球口腔癌发病率居高不下，尤其在医疗资源匮乏的地区，死亡率较高。早期诊断能够降低死亡率，但受限于口腔健康项目不足，基础设施条件差以及医疗从业者短缺，诊断挑战仍然严峻。传统的深度学习模型往往依赖于点估计，这不仅增加了过拟合的风险，也减少了模型的可靠性。这些模型需要大量数据来减轻过拟合并确保泛化能力，但在受限数据集的环境中这是不切实际的。
### Innovation
该论文提出了一种结合卷积神经网络（CNN）和贝叶斯深度学习的混合模型，用于对小数据集中的口腔癌进行分类。这种方法通过使用变分推理来增强可靠性，提高不确定性量化。该模型在拍摄智能手机采集的色彩图像上进行了训练，并在三个不同的测试数据集上进行了评估。所提出的方法在与训练数据分布相似的测试数据集上达到94%的准确率，与传统的CNN性能相当。对于现实世界拍摄的图像数据，尽管存在数据和变异性的问题，但该模型仍然显示出了更强的泛化能力，相比于传统的CNN，其在不同数据集上的准确率为88%，而传统的CNN仅为72.94%，即使使用了更小的数据集。
### Conclusion
研究结果表明，贝叶斯推理能在数据稀少的环境中提高早期口腔癌诊断的模型可靠性和泛化能力，方法提出了一个改进的分类模型，该模型在小型数据集上的性能表现优于传统方法。这为资源不足地区的早期口腔癌诊断提供了新的可能。
## 919. `cs.LG` - CardioRAG: 一种用于多模态查加斯病检测的检索增强生成框架 [PDF](https://arxiv.org/pdf/2510.01558), [HTML](https://arxiv.org/abs/2510.01558)
### Authors
Zhengyang Shen,Xuehao Zhai,Hua Tu,Mayue Shi
### Background
查加斯病影响全球近600万人，其最严重的并发症为查加斯心脏病变。在缺乏血清学检测能力的地区，通过人工智能增强的心电图（ECG）筛查提供了重要的替代诊断手段。然而，现有的机器学习方法面临准确性有限、依赖大量标注数据集以及与基于证据的临床诊断指标结合不强的挑战。
### Innovation
我们提出了一种被称为CardioRAG的检索增强生成框架，该框架结合了大规模语言模型与可解释的心电图临床特征，包括右束支阻滞、左前分支阻滞和心率变异性指标。该框架利用变分自动编码器学习表示进行语义案例检索，提供上下文案例以指导临床推理。评估结果显示，Recall性能为89.80%，F1分数最高达到0.68，有效识别需要优先进行血清学检测的阳性案例。CardioRAG为资源限制环境下的可解释、基于临床证据的方法，体现了将临床指标嵌入可信赖的医疗AI系统中的途径。
### Conclusion
CardioRAG提供了一种可解释的、基于临床证据的方法，特别适用于资源有限的环境，并展示了将临床指标嵌入可信的医疗AI系统中的路径。
## 920. `cs.LG` - 创新表示的AI基础模型用于时间序列 [PDF](https://arxiv.org/pdf/2510.01560), [HTML](https://arxiv.org/abs/2510.01560)
### Authors
Lang Tong,Xinyi Wang
### Background
本文介绍了一种针对工程应用中需要因果操作的实时监控和控制的时间序列人工智能基础模型。由于工程时间序列由物理定律而非语言定律支配，大型语言模型为基础的AI基础模型可能无效或效率低下。背景提到，借鉴维纳、卡利安普尔和罗森布莱特的经典创新表示理论，提出了基于创新表示的生成预训练变换器（TS-GPT），用于工程监控和控制。该模型示例性地考虑了概率生成预测，这种预测生成未来时间序列样本的方式是基于给定过去实际数据的条件概率分布。该研究使用来自美国独立系统运营商的历史数据展示了TS-GPT在实时预测位置边际价格方面的有效性。
### Innovation
本文提出的TS-GPT是一种基于创新表示的生成预训练变换器，旨在解决传统大型语言模型在处理工程时间序列数据时可能存在的无效或效率低下的问题。通过借鉴经典理论，该模型能够更好地适应工程应用中的需求，提供更准确和实时的预测能力。
### Conclusion
通过使用TS-GPT对历史数据进行分析，该研究证明了其在实时预测位置边际价格方面的有效性，显示了该模型在工程时间序列分析中的潜在应用价值。
## 921. `cs.LG` - Just Do It!? 计算机使用代理表现出盲目的目标导向性 [PDF](https://arxiv.org/pdf/2510.01670), [HTML](https://arxiv.org/abs/2510.01670)
### Authors
Erfan Shayegani,Keegan Hines,Yue Dong,Nael Abu-Ghazaleh,Roman Lutz,Spencer Whitehead,Vidhisha Balachandran,Besmira Nushi,Vibhav Vineet
### Background
计算机-使用代理（CUAs）是一类越来越被部署的代理，它们在图形用户界面（GUI）上执行操作以实现用户目标。然而，CUAs通常表现出一种盲目的目标导向性（BGD），即不管可行性、安全性、可靠性或上下文，始终追求目标。
### Innovation
本文提出了盲目的执行行为基准（BLIND-ACT），这是一个包含90个任务的基准，捕捉了三种常见的BGD模式。BLIND-ACT通过操作系统世界（OSWorld）构建，提供现实环境，并利用基于LLM的评判者来评估代理行为，实现了93.75%的人类注释一致性。此外，研究还揭示了CUAs在面对BGD时存在的隐含风险，并表明尽管基于提示的方法降低了BGD水平，但仍有大量的风险存在，需要更强大的训练或推理干预措施。
### Conclusion
识别BGD并引入BLIND-ACT为未来研究提供了一个基础，用于研究和缓解这种基本风险，以确保安全的CUA部署。同时指出存在执行优先偏见、思维与行动脱节以及请求优先等问题。
## 922. `cs.LG` - 基于稀疏自编码器引导生成的可解释和推理最优的递归思考 [PDF](https://arxiv.org/pdf/2510.01528), [HTML](https://arxiv.org/abs/2510.01528)
### Authors
Daniel Zhao,Abhilash Shankarampeta,Lanxiang Hu,Tajana Rosing,Hao Zhang
### Background
该研究聚焦于大型语言模型(LLMs)在数学推理任务中的内部表示分析和生成引导。背景介绍指出了在数学推理任务中平衡‘探索’与‘利用’的重要性，确保生成过程既准确又多样化。现有的方法可能在过度利用已有模式或未能充分探索可能性之间摇摆，这影响了整体推理过程的质量。论文创新提出了一种新的方法，通过使用稀疏自编码器(SAEs)和聚类技术，来提高LLMs在数学推理任务中的表现。这种方法通过训练SAE生成稀疏的向量表示，进行k-均值聚类生成图，并基于聚类边缘权重定义奖励函数，从而量化遵循既定推理路径的程度，同时评估生成的多样性和探索度，以确保推理过程的质量。
### Innovation
该研究的创新点包括：1) 提出一种结合稀疏自编码器(SAEs)和聚类技术的方法，生成数学推理任务中内部词元表示；2) 通过构建图来表示不同词元群集之间的序列转换，并通过边的权重定义奖励函数，从而促进递归思考路径的识别；3) 在生成过程中，利用稀疏自编码器作为可扩展的奖励模型，同时平衡探索和利用，从而防止极端行为出现，提升整体推理过程的质量。
### Conclusion
研究发现，平衡探索和利用对于在数学推理任务中获得高准确性至关重要。文章提出的方法通过利用稀疏自编码器和聚类技术，在生成过程中进行了有效的引导，确保了在数学推理任务中实现高质量的推理过程。这表明，这种方法可以作为一种有效的策略，来提高大型语言模型在数学和其它推理任务中的表现。
## 923. `cs.LG` - 通过行为引导的微调使视频模型与人类社会判断对齐 [PDF](https://arxiv.org/pdf/2510.01502), [HTML](https://arxiv.org/abs/2510.01502)
### Authors
Kathy Garcia,Leyla Isik
### Background
人类能够直观地感知视觉场景中的复杂社会信号，但目前尚不清楚最先进的AI模型是否也能够捕捉到这种相似性结构。本文探讨了现代视频和语言模型是如何捕捉到人类对社交视频所感知的相似性的，以及如何通过人类行为数据来构建这种结构。研究发现，尽管任务是视觉的，基于字幕的语言嵌入比任何预训练的视频模型都能更好地匹配人类相似性。
### Innovation
本文引入了一个包含49,000多个视觉片段和相似性判断的新基准，主要用于研究视频和语言模型是否能捕捉到人类对社交视频的感知相似性，并通过低秩适应（LoRA）和三重-RSA目标函数对TimeSformer视频模型进行微调，以实现与人类相似性结构的对齐。实验结果表明，这种微调方法在解释性方差和三重差异性准确性方面有显著改善，此外，行为引导的微调增强了社交情感属性（亲密性、正负情绪、支配性、沟通）的编码。
### Conclusion
本文的研究结果突显了预训练视频模型在社会识别方面的不足，并证明行为引导的微调能够将视频表示引导向人类社会感知方向。
## 924. `cs.LG` - 扩展预训练MLLM的视觉生成能力 [PDF](https://arxiv.org/pdf/2510.01546), [HTML](https://arxiv.org/abs/2510.01546)
### Authors
Hanyu Wang,Jiaming Han,Ziyan Yang,Qi Zhao,Shanchuan Lin,Xiangyu Yue,Abhinav Shrivastava,Zhenheng Yang,Hao Chen
### Background
多模态大型语言模型（MLLMs）将语言模型的成功应用到视觉理解中，并寻求构建支持理解和生成的统一MLLM。然而，构建此类模型仍然具有挑战性：混合方法将连续嵌入与扩散或流式目标结合，虽然能生成高质量图像，但也破坏了自回归范式；纯自回归方法则将文本和图像预测统一在离散视觉标记上，但往往在语义对齐和像素级保真度之间面临权衡。因此，本研究介绍了Bridge，这是一种纯自回归统一MLLM，通过混合变换器架构增强预训练视觉理解模型的生成能力，实现单一下一个标记预测框架内的图像理解和生成。为了进一步提高视觉生成保真度，提出了语义到像素的离散表示，整合紧凑的语义标记和精细的像素标记，实现强大的语言对齐和精确的视觉细节描述，同时将序列长度增加控制在7.9%以内。在多种多模态基准测试上进行了广泛实验，表明Bridge在理解和生成基准测试中表现得具有竞争力或更优，并且与以前的统一MLLM相比需要更少的训练数据和更短的训练时间。
### Innovation
Bridge通过混合变换器架构增强预训练视觉理解模型的生成能力，实现了单一下一个标记预测框架内的图像理解和生成。提出了语义到像素的离散表示，整合紧凑的语义标记和精细的像素标记，得到强大的语言对齐和精确的视觉细节描述，同时将序列长度增加控制在7.9%以内，进一步提高了视觉生成保真度。
### Conclusion
广泛的实验表明，Bridge在理解和生成基准测试中表现得具有竞争力或更优，同时需要更少的训练数据和更短的训练时间。
## 925. `cs.LG` - 隐私不仅仅在于记忆化！ [PDF](https://arxiv.org/pdf/2510.01645), [HTML](https://arxiv.org/abs/2510.01645)
### Authors
Niloofar Mireshghallah,Tianshi Li
### Background
当前关于大型语言模型（LLMs）隐私风险的讨论主要集中在逐一记忆训练数据上，而对其他更为紧迫和易于解决的隐私威胁则研究不足。研究指出，隐私风险并不仅限于训练数据的提取，还涵盖了数据收集实践、推理时上下文泄露、自主代理能力和民主化监控等方面。通过对过去十年内1,322篇人工智能/机器学习隐私论文的研究分析，发现当前技术框架在解决这些多方面的威胁时缺乏有效的应对方法，而技术研究中对记忆化问题的过度关注也掩盖了更紧迫的隐私风险。
### Innovation
本文提出了一种全面的LLM生命周期中隐私风险分类，并通过案例研究展示了当前隐私框架在此问题上的不足。此外，还通过对顶尖会议过去十年间1,322篇相关论文的分析，揭示了技术研究中过度关注训练数据记忆化的现象与实际面临的最紧迫隐私威胁之间的差距，呼吁研究社区在隐私保护方面采用跨学科的方法，超越当前技术解决方案的局限。
### Conclusion
研究认为，隐私保护不仅仅是应对训练数据记忆化的问题，而是一种更广泛的技术和社会问题，需要研究社区采取全新的视角和方法来应对。
## 926. `cs.LG` - 合成前缀以缓解实时神经查询自动完成功能中的偏差 [PDF](https://arxiv.org/pdf/2510.01574), [HTML](https://arxiv.org/abs/2510.01574)
### Authors
Adithya Rajan,Xiaoyu Liu,Prateek Verma,Vibhu Arora
### Background
在实时神经查询自动完成功能中，模型建议会引导用户行为，从而可能带来呈现偏差。目前的训练数据主要来自于实时查询自动完成功能激活时的用户输入，这可能导致训练模型的偏差加剧。通过收集实时查询自动完成功能未激活时的完整用户查询数据来生成合成前缀，可以丰富训练数据的多样性，减少偏差。这种方法旨在克服实时数据中存在的偏差问题，提高模型的学习效果和公平性，尤其是在严格延迟要求下实现即时部署的场景中.
### Innovation
提出了一种基于数据的方法来减轻实时神经查询自动完成功能中的呈现偏差，通过生成合成前缀来丰富训练数据。这些前缀是从自动完成功能未启用时的完整用户查询中生成的。同时，优化了神经排序器，使其能够在严格延迟限制下进行实时部署，并结合了查询流行度、季节性、模糊匹配分数和上下文信号等丰富的特征。为了提高训练效率，引入了一种针对任务简化了的列表损失函数，将计算复杂度从$O(n^2)$减少到$O(n)$，利用了每个前缀只有一个真实选择的自动完成功能结构。这种方法不仅提高了用户体验，还为其他低延迟排名任务，如相关搜索和查询推荐中的偏差缓解提供了可扩展的路径.
### Conclusion
在大规模电子商务环境下部署该系统，结果显示，通过使用合成前缀，系统在用户参与度方面表现出统计上的显著改善，如均倒数排名等指标的提升。研究表明，合成前缀不仅提高了模型的泛化能力，还提供了一种可扩展的方法来缓解其他低延迟排名任务中的偏差问题。
## 927. `cs.LG` - Vision-Language-Action模型中的对比表示正则化 [PDF](https://arxiv.org/pdf/2510.01711), [HTML](https://arxiv.org/abs/2510.01711)
### Authors
Taeyoung Kim,Jimin Lee,Myungkyu Koo,Dongyoung Kim,Kyungmin Lee,Changyeon Kim,Younggyo Seo,Jinwoo Shin
### Background
Vision-Language-Action (VLA)模型通过利用预训练的Vision-Language模型 (VLMs) 的丰富表示，在机器人操作方面展示了其能力。然而，这些表示仍然存在不足，缺乏对控制动作和本体感受状态等机器人信号的敏感性。
### Innovation
本文提出了一种名为Robot State-aware Contrastive Loss (RS-CL) 的简单的对比表示正则化方法，旨在弥合Vision-Language模型表示与机器人信号之间的差距。RS-CL通过相对距离建立本体感受状态之间的软监督，从而与原始的动作预测目标互补，有效增强与控制相关的表示学习，且结构轻量，完全兼容标准的VLA培训管道。
### Conclusion
实验证明，RS-CL大幅提高了最先进的VLA模型的操作性能。在RoboCasa-Kitchen平台的拾取和放置任务中，成功率达到41.5%，是之前的30.8%的增长。同时，在更具挑战性的真实机器人操作任务中，成功率从45.0%提升到了58.3%。
## 928. `cs.LG` - VaPR -- 视觉语言偏好对齐以实现推理 [PDF](https://arxiv.org/pdf/2510.01700), [HTML](https://arxiv.org/abs/2510.01700)
### Authors
Rohan Wadhawan,Fabrice Y Harel-Canada,Zi-Yi Dou,Suhaila Shakiah,Robinson Piramuthu,Nanyun Peng
### Background
现有的偏好微调方法，比如直接偏好优化（DPO）并且以AI生成反馈，已经在使大型视觉语言模型（LVLM）与人类偏好保持一致方面显示出潜力。然而，已有技术忽视了在合成偏好注解中广泛存在的噪声，包括风格偏好和长度偏向。本文提出了一种基于LLM指导的响应编辑的硬负样本生成框架，该框架生成带有针对性错误的被拒响应，同时保持与被接受响应的风格和长度相似性。利用该框架，开发了包含30000个高质量样本的数据集VaPR，用于对LLaVA-V1.5、Qwen2VL和Qwen2.5VL三种LVLM进行微调。
### Innovation
本文提出了一种新的硬负样本生成框架，基于LLM指导的响应编辑，能够生成带有目标错误的被拒响应，同时保持与被接受响应的风格和长度相似性。此外，本文开发了VaPR数据集，包含30000个高质量样本，用于微调三种LVLM家族，并取得了显著的性能提升，特别是在推理任务上。通过数据规模分析，发现性能随数据量的增加而持续改进，并且LLaVA模型甚至在小型数据量下也能受益。此外，VaPR减少了LVLM在二元问题上回答“是”的倾向，解决了人们普遍关注的LVLM常见的失败模式。
### Conclusion
VaPR模型在十个基准中表现出显著的性能提升，LLaVA取得了平均6.5%的增幅，Qwen2VL为4.0%，Qwen2.5VL为1.5%，特别是在推理任务上表现尤为突出。此外，通过扩展分析，我们发现平台的性能随样本数量的增加而持续提高。论文还展示了该框架能够应用于开源LLM，训练于VaPR-OS的数据集的模型与采用GPT-4o合成数据集的模型表现基本相同。整个项目的数据、模型和代码可以在项目页面上找到。
## 929. `cs.LG` - PRESOL：基于特征的耀斑预测的网络计算平台 [PDF](https://arxiv.org/pdf/2510.01799), [HTML](https://arxiv.org/abs/2510.01799)
### Authors
Chiara Curletto,Paolo Massa,Valeria Tagliafico,Cristina Campi,Federico Benvenuto,Michele Piana,Andrea Tacchino
### Background
太阳耀斑是太阳系中最具爆炸性的现象，是导致日冕物质抛射等一系列事件，最终引发地磁场风暴，并可能影响地球基础设施的主要触发因素。基于数据的太阳耀斑预测依赖于深度学习方法或机器学习算法：深度学习方法虽然在操作上具有可行性但缺乏解释性，而机器学习算法则能提供对预测影响最大的物理描述符的信息。因此，本文描述了一个网络技术平台，该平台执行基于特征的机器学习方法的计算管道，提供耀斑发生的预测、特征排名信息以及预测性能评估。
### Innovation
开发了一个基于特征的太阳耀斑预测的网络计算平台（PRESOL），该平台采用机器学习方法提供耀斑发生的预测，特征排名信息以及预测性能评估。这结合了深度学习的可操作性和机器学习的解释性，填补了当前技术存在的空白。
### Conclusion
该研究开发了PRESOL平台，可以执行基于特征的机器学习方法的计算管道，提供耀斑发生预测及性能评估。该平台的实现将有助于提高太阳耀斑预测的准确性，并为研究太阳活动和其对地球的影响提供有用的信息。
## 930. `cs.LG` - 关于使用群集基础嵌套核对高斯过程回归中分类核的可重复比较研究，带有新的嵌套核策略 [PDF](https://arxiv.org/pdf/2510.01840), [HTML](https://arxiv.org/abs/2510.01840)
### Authors
Raphaël Carpintero Perez(CMAP),Sébastien Da Veiga(ENSAI, CREST, RT-UQ),Josselin Garnier(CMAP, ASCII)
### Background
对于同时包含连续和分类输入的高斯过程回归，设计分类核是一个主要挑战。尽管已有相关研究，但由于评估指标、优化过程和数据集的不同变化，很难找到首选方法。此外，之前的许多研究缺乏可重复的代码。本研究旨在提供一个针对所有现有分类核在多种测试案例上的可重复比较研究。我们提出了新的优化指标，使其能够在多个任务中量化方法的排名。对于具有分类输入级别组结构的数据集，嵌套核方法在性能上明显优于其他方法。当不存在组结构或没有此类结构的先验知识时，我们提出了一个新的基于群集的策略，使用分类变量的目标编码来估计这种结构。实验结果表明，即使没有已知的组结构，这种方法在大数据集上仍然优于其他方法，且具有较低的成本。
### Innovation
提出了新的评估指标；提出了新的基于群集的嵌套核策略，使用目标编码估计分类变量的嵌套层次结构
### Conclusion
嵌套核方法在包含分类输入的数据集上表现出优越性能。对于群集结构未知的情况，新提出的策略仍然优于其他方法，同时保持较低计算成本。
## 931. `cs.LG` - 利用掩蔽点变换器减少中微子望远镜对模拟的依赖 [PDF](https://arxiv.org/pdf/2510.01733), [HTML](https://arxiv.org/abs/2510.01733)
### Authors
Felix J. Yu,Nicholas Kamp,Carlos A. Argüelles
### Background
中微子物理学中，机器学习技术通常依赖于模拟数据，这提供了准确的标签，但模拟数据的准确性及其与真实数据的差异性，尤其是对于在复杂自然介质中运行的大型中微子望远镜，一直是重大问题。
### Innovation
该研究提出了一种新的自监督训练管道，利用点云变换器和掩蔽自编码器，主要基于真实数据训练，从而减少对模拟数据的依赖，降低了系统不确定性。
### Conclusion
这项研究标志着中微子望远镜中机器学习应用的一个根本性改变，有望在事件重建和分类方面实现重大改进。
## 932. `cs.LG` - 通过MCP在联邦数字健康系统中的安全多模数据融合 [PDF](https://arxiv.org/pdf/2510.01780), [HTML](https://arxiv.org/abs/2510.01780)
### Authors
Aueaphum Aueawatthanaphisut
### Background
在数字健康领域，确保跨分布式和资源受限环境安全、可互操作地集成异质医疗数据仍然是一个重大挑战。现有的联邦学习（FL）框架能够提供隐私保护模型训练，但缺乏标准化机制来协调多模式数据的跨代理融合。因此，需要一种解决方案，能够在多模式的联邦健康系统中实现安全、跨代理的通信，同时统一临床成像、电子医疗记录和可穿戴物联网数据的多模特征对齐，并通过差分隐私保护患者敏感更新，以及通过能量感知调度减少移动客户端的掉线率，确保遵守隐私法规。
### Innovation
本文提出了一种利用模型上下文协议（MCP）作为互操作性层的框架，用于联邦数字健康系统的安全跨代理通信。该框架通过遵循MCP的模式驱动接口，实现了AI代理和工具链的弹性编排，确保了隐私法规的遵循。实验在基准数据集和试点临床队列上进行，结果表明该框架在诊断准确性、客户端掉线率和隐私-实用性权衡方面比基线FL有显著改进。
### Conclusion
研究结果表明，MCP支持的多模融合是一种可扩展且值得信赖的道路，可通往公平的下一代联邦健康基础设施。
## 933. `cs.LG` - 评估生产恶意软件检测系统对可转移对抗攻击的鲁棒性 [PDF](https://arxiv.org/pdf/2510.01676), [HTML](https://arxiv.org/abs/2510.01676)
### Authors
Milad Nasr,Yanick Fratantonio,Luca Invernizzi,Ange Albertini,Loua Farah,Alex Petit-Bianco,Andreas Terzis,Kurt Thomas,Elie Bursztein,Nicholas Carlini
### Background
随着深度学习模型被广泛应用于各种生产系统中，这些模型的弱点可能会导致系统层面的安全漏洞。本研究以谷歌的邮件系统为例，分析了针对机器学习组件的恶意攻击如何影响整个生产级别的恶意软件检测系统。研究发现，通过设计少量修改的恶意软件样本来欺骗模型，可以使生产级恶意软件检测服务错误地将恶意软件路由到不合适的检测器，从而增加被检测逃逸的风险。
### Innovation
研究人员通过修改恶意软件样本中的少量字节来设计对抗样本，从而成功地在90%的情况下欺骗模型，使恶意软件能够通过谷歌邮件系统。研究表明，对于防御过的生产模型，即使在拥有高度资源的攻击者面前，也需要修改50个字节才能在20%的情况下成功执行攻击。研究还提出了一种防御方法，并在谷歌工程师的合作下，该防御措施已经被部署在生产环境中的谷歌分类器中。
### Conclusion
研究展示了针对深度学习模型的对抗攻击可能造成的严重后果，提出了有效的防御策略，并成功地将其应用于生产环境，增强了整个系统的鲁棒性。
## 934. `cs.LG` - 自然场景中的整体顺序预测 [PDF](https://arxiv.org/pdf/2510.01704), [HTML](https://arxiv.org/abs/2510.01704)
### Authors
Pierre Musacchio,Hyunmin Lee,Jaesik Park
### Background
即使是在受控的环境中，理解图像中的具体几何结构对于多种视觉模型来说也是一项极具挑战性的任务。现有的专用系统尽管可以解决这个问题，但它们依赖于昂贵的输入格式（类别标签，二元分割掩模）和推理成本（正向传递的数量级增加）。因此，该技术的应用领域受到了限制。
### Innovation
本文提出了一种称为InstaFormer的新网络，这种网络能够在单一的正向传递过程中预测场景中所有实例的完全遮挡顺序和深度顺序，而无需任何额外的输入。InstaFormer的基础是对象查询与潜在掩模描述符之间的交互，后者是相同对象的语义表示，同时携带补充信息。
### Conclusion
为了证明该方法的有效性，我们在全面的基准测试和消融研究中对其进行了评估。我们的代码和模型已经开源，并在此URL中提供：this https URL。
## 935. `cs.LG` - 可扩展的异步联邦建模用于空间数据 [PDF](https://arxiv.org/pdf/2510.01771), [HTML](https://arxiv.org/abs/2510.01771)
### Authors
Jianwei Shi,Sameh Abdulah,Ying Sun,Marc G. Genton
### Background
空间数据在环境监测和城市规划等应用中起着核心作用，但由于这些数据通常分布在隐私和通信受限的设备之间，直接共享变得非常困难。联邦建模为保持数据隐私的同时实现分布式数据源之间的全局建模提供了一种实用的解决方案。例如，隐私和带宽受限的环境传感器网络推动了只有通过隐私保护汇总数据以生成及时、高分辨率污染地图的联邦空间建模的发展，而无需集中存储原始数据。然而，现有的联邦建模方法要么忽略了空间相关性，要么依赖于易受异构环境中的延迟者影响的同步更新。
### Innovation
这项工作提出了基于低秩高斯过程近似方法的异步联邦建模框架，采用了块优化策略，并引入了梯度校正、自适应融合和稳定更新的策略。该研究证明了算法的线性收敛性，并且具有对延迟的显式依赖性，这一理论成果对单独分析有重要意义。此外，数值实验表明，当资源分配均衡时，异步算法可以达到同步性能，并在异构环境中表现出显著优越的稳健性和可扩展性。
### Conclusion
在异构环境中，基于低秩高斯过程近似的异步联邦建模框架能够实现高效的、稳健的空间数据建模，该框架克服了传统的同步更新方法的瓶颈，提高了算法的性能，特别是在资源分布不均的情况下，展现了更为优越的性能。
## 936. `cs.LG` - 基于YOLO目标检测模型的大规模生产电子元件自动缺陷检测 [PDF](https://arxiv.org/pdf/2510.01914), [HTML](https://arxiv.org/abs/2510.01914)
### Authors
Wei-Lung Mao,Chun-Chi Wang,Po-Heng Chou,Yen-Ting Liu
### Background
传统工业组件的缺陷检测耗时且劳动密集，给质量检验人员带来沉重负担，难以管理产品质量。
### Innovation
提出了一种基于数字摄像头光学和深度学习模型（ConSinGAN辅助的YOLOv7）的自动缺陷检测系统，特别适用于广泛使用的双列直插式封装（DIP）元件。通过ConSinGAN生成适配训练和测试的数据集，并评估了YOLO v3、v4、v7和v9四种模型及其与ConSinGAN的增强效果，证明了YOLOv7结合ConSinGAN的优越性。此外，开发了SCADA系统并描述了相关的传感器架构。
### Conclusion
提出的自动缺陷检测系统能够轻松建立，并适用于多种类型的缺陷或缺陷数据不足的情况，显示出在检测准确性和检测时间上的显著优势。
## 937. `cs.LG` - 大语言模型中的微缩浮点格式 [PDF](https://arxiv.org/pdf/2510.01863), [HTML](https://arxiv.org/abs/2510.01863)
### Authors
Marco Cococcioni,Dario Pagani,Federico Rossi
### Background
大型语言模型（LLMs）的计算和内存需求不断增加，这需要采用创新的方法来优化资源使用而不影响性能。传统浮点表示法为每个值分配一个特定的尺度，而没有采用一种在整个数值块中共享尺度的方法来实现紧凑的一字节浮点表示，同时保持扩展的动态范围。本研究探讨了在8位浮点格式中应用微缩浮点格式，以显著减少内存占用和计算成本。研究结果表明，在GPT-2 LLM架构中使用微缩浮点数据格式，可以实现与传统方法相当的训练和推理准确性，证实了其作为大规模部署LLMs的一种资源高效替代方案的有效性。
### Innovation
本论文提出了一种新的微缩浮点格式，通过在整个值块中共享尺度来实现紧凑的一字节浮点表示，从而减少内存占用和计算成本。此方法与传统的为每个值分配特定尺度的方法不同，能够维持扩展的动态范围，并且在8位浮点格式中实现了微缩浮点格式的高效应用。该研究证实了微缩浮点格式在大规模语言模型中的有效性。
### Conclusion
研究表明，微缩浮点数据格式能够实现与传统方法相当的训练和推理准确性，在GPT-2 LLM架构中的应用证明了这种方法作为大规模部署大语言模型的一种资源高效替代方案的有效性。研究还提供了相关的源代码供公众使用。
## 938. `cs.LG` - 基础视觉编码器实际上是少量样本异常检测器 [PDF](https://arxiv.org/pdf/2510.01934), [HTML](https://arxiv.org/abs/2510.01934)
### Authors
Guangyao Zhai,Yue Zhou,Xinyan Deng,Lars Heckler,Nassir Navab,Benjamin Busam
### Background
低样本量情况下进行工业安全检查的异常检测非常困难，特别是异类无关条件下。大规模预训练的基础视觉编码器在很多领域取得了进步，因为大量的数据帮助学习正常图像的一般分布。研究者观察到图像中的异常量与学习嵌入的差异直接相关，利用这一点设计了名为FoundAD的少量样本异常检测器。该方法通过学习非线性投影操作符到自然图像流形上，从而简化和优化了检测过程。
### Innovation
提出了一种新的基于少量样本的异常检测器FoundAD，它利用了图像中异常量与学习嵌入差异之间的关系。该方法通过学习非线性的投影操作符，将该操作符作为识别图像中异常区域的有效工具。实验证明，FoundAD在保持较低参数量的同时，能实现与其他方法相当甚至更好的多类检测性能。
### Conclusion
通过在多种基础编码器上进行评估，包括最新版本DINOv3，研究者相信该方法扩展了基础特征的视角，推进了少量样本异常检测领域的研究。
## 939. `cs.LG` - 从离散评分排序项目：未知用户阈值的成本 [PDF](https://arxiv.org/pdf/2510.01871), [HTML](https://arxiv.org/abs/2510.01871)
### Authors
Oscar Villemaud,Suryanarayana Sankagiri,Matthias Grossglauser
### Background
物品的排名是许多信息检索和推荐系统的核心任务。用户的输入通常是以粗略的离散等级的形式给出。本文探讨是否可以从粗略的等级中恢复精细的物品排名。文章使用物品有得分、用户有阈值的模型，用户在物品的得分超过自己的阈值时给出正向评价。所有用户对项目的总体顺序达成一致，但同时估计该顺序难度在于得分和阈值都为潜在变量。
### Innovation
文章证明了通过Spearman距离衡量接近完美的排名需要$theta(n^2)$个用户（因此需要$theme(n^2)$次查询），这显著高于从比较中排名需要的$O(ntext{log}n)$次查询。这种差距反映了识别具有适当阈值的用户所需额外查询的数量。文章还通过一个具有二次散逸因子的评估来量化评分分布和阈值分布之间的不匹配影响。文章提供了一个排名算法，其查询复杂度与上界只相差一个对数因子，从而展示了结果的紧致性。研究揭示了在线排名中的一个矛盾：需要阈值的多样性来合并来自许多用户的粗略评分以进行精细排名，但如果阈值先验未知，这种多样性也会带来成本。
### Conclusion
文章证明了接近完美的排名需要二次复杂度的用户和查询，揭示了应对粗略评分优化排名的挑战，并展示了即使在未知阈值分布的情况下也存在可行的方法，但会增加成本。
## 940. `cs.LG` - NGGAN: 基于实际测量数据集的窄带电力线通信噪声生成GAN [PDF](https://arxiv.org/pdf/2510.01850), [HTML](https://arxiv.org/abs/2510.01850)
### Authors
Ying-Ren Chien,Po-Heng Chou,You-Jie Peng,Chun-Yuan Huang,Hen-Wai Tsao,Yu Tsao
### Background
在提高窄带电力线通信（NB-PLC）收发器中突发噪声处理性能时，全面捕捉非周期异步脉冲噪声统计特性是一个关键问题。目前的数学噪声生成模型只能捕捉到一些增益噪声的特点，未能充分模拟实际情形。因此，需要开发一种能够学习实际测量噪声复杂特性的生成对抗网络（GAN），以增强对突发噪声的处理能力，并生成更接近实际场景的噪声样本，用于数据增强和模拟真实应用场景。
### Innovation
本文提出了一种基于实际测量数据集的生成对抗网络（GAN），即噪声生成GAN（NGGAN），用于窄带电力线通信（NB-PLC）系统。这种网络设计采用实际测量噪声样本训练模型，以增强生成的噪声与实际噪声样本的统计匹配程度。该设计包括三个方面：（1）通过设计输入信号长度，以便NGGAN模型更好地生成周期循环平稳噪声；（2）使用Wasserstein距离作为损失函数，提高生成噪声与训练数据集之间的相似性，并确保噪声样本多样性，以满足不同应用需求；（3）通过定量和定性分析来评估基于数学和实际测量数据集的GNAN模型性能相似性，训练数据集包括周期循环平稳Gaussian模型（PSCGM）、频率偏移（FRESH）滤波器和实际测量的NB-PLC系统的噪声样本。实验结果表明，使用波形特性训练的NGGAN生成的噪声质量更接近实际测量数据集，说明这种方法的有效性。
### Conclusion
提出了一种基于实际测量数据集的噪声生成GAN（NGGAN），用于解决窄带电力线通信（NB-PLC）系统中突发噪声处理性能问题。通过实际测量噪声样本训练模型，提高了生成噪声与实际噪声样本的统计匹配程度，并通过Wasserstein距离优化了生成噪声的质量。未来研究方向包括进一步改进生成模型和优化训练算法，以提高噪声生成的性能。
## 941. `cs.LG` - Constrained Adaptive Rejection Sampling [PDF](https://arxiv.org/pdf/2510.01902), [HTML](https://arxiv.org/abs/2510.01902)
### Authors
Paweł Parys,Sairam Vaidya,Taylor Berg-Kirkpatrick,Loris D'Antoni
### Background
语言模型（LMs）在需要生成满足严格语义或句法约束的输出的应用中越来越普遍。现有方法在约束生成方面大致可分为两类：贪心约束解码方法在解码过程中强制约束的有效性，但会扭曲LM的概率分布；拒绝采样（RS）则保持精确性，但由于会丢弃无效的输出，导致浪费计算资源。这两种方法在程序模糊测试等关键领域都存在问题，因为它们都需要严格的有效性和多样化的样本。当前的研究旨在解决这些问题，提高RS的有效性，同时保留样本的全部多样性，不扭曲分布。
### Innovation
本文提出了一种称为Constrained Adaptive Rejection Sampling（CARS）的方法，该方法严格提高了RS的有效性，而不扭曲概率分布。CARS从未约束的方式进行LM抽样，并通过记录违反约束的续行及其概率质量来适配地排除它们，以防止无效的前缀被重新访问。这种方法使接受率单调增加，并确保生成的样本严格遵守约束分布。实验结果表明，CARS在多种领域（例如程序模糊测试和分子生成）中的效率更高，同时生成的样本多样性也优于贪心约束解码（GCD）和其他近似LM分布的方法。
### Conclusion
CARS方法在节约LM前向计算步骤的同时，有效提高了整个采样的有效利用率。相比于传统的贪心约束解码技术和拒绝采样，CARS在约束生成背景下能够更加精确和高效地满足生成需求，生成的样本也具有更好的多样性。
## 942. `cs.LG` - 精确的对角线线性网络动力学：动力学均场理论的统一分析 [PDF](https://arxiv.org/pdf/2510.01930), [HTML](https://arxiv.org/abs/2510.01930)
### Authors
Sota Nishiyama,Masaaki Imaizumi
### Background
对角线线性网络（DLNs）能够捕捉神经网络训练中的几种非平凡行为，诸如初始化依赖的解决方案和增量学习。这些现象通常是单独研究的，使得整体动态机制理解不够充分。以往的研究多针对个别现象的分析，尚未进行全面统一的分析框架。本研究旨在通过动力学均场理论（DMFT）统一分析DLNs中各种现象的动力学过程，揭示其渐近梯度流动态，为理解DLNs提供新的见解，并验证先前观察到的现象，进一步提升我们对DLNs的理解。
### Innovation
通过动力学均场理论（DMFT）推导出一种低维度的有效过程，以捕获高维度下的渐近梯度流动态。此方法能够系统地重现并解释多种先前观察到的现象，提供了DLNs动态的新见解，包括损失收敛率与其泛化之间的权衡。此研究展示出DMFT在分析神经网络高维学习动力学中的有效性。
### Conclusion
通过动力学均场理论对DLNs的系统分析，揭示了其渐近梯度流动态的新颖特征，并对DLNs动态提供了深入理解。DMFT在分析神经网络高维学习动力学方面表现出显著有效性。
## 943. `cs.LG` - 在非凸性下的深度对冲：局限性和AlphaZero的案例 [PDF](https://arxiv.org/pdf/2510.01874), [HTML](https://arxiv.org/abs/2510.01874)
### Authors
Matteo Maggiolo,Giuseppe Nuti,Miroslav Štrupl,Oleg Szehr
### Background
本文探讨了不完全市场中的复制组合构建问题，这是金融工程中的一个关键问题，应用于定价、对冲、资产负债管理以及能源储存规划等领域。本文将此问题构建为投资者与市场的两玩家博弈模型，投资者对未来状态进行战略性押注，市场则揭示结果。文章指出深度对冲在解决不满足凸性约束的环境中表现不佳，如涉及非凸交易成本、资本约束或监管限制，容易陷入局部最优。为了验证这一点，文章构建了特定市场环境，并通过实验展示了AlphaZero能够在这些环境下发现接近最优的复制策略。在理论分析方面，文章将深度对冲与凸优化建立了联系，表明其有效性依赖于凸性假设，实验结果进一步表明AlphaZero在数据稀少且容易过拟合的衍生品市场中具有更好的样本利用效率优势。
### Innovation
文章借鉴蒙特卡洛树搜索技术，并引入基于AlphaZero系统的创新模型，用于解决在非凸性约束下的复制组合构建问题。通过与深度对冲方法进行比较，文章展示了AlphaZero在处理复杂环境时的优越性，并且在理论上建立了深度对冲与凸优化之间的联系，证明了其在满足凸性约束前提下的有效性局限性，突出AlphaZero方法在数据稀缺市场中的优势。
### Conclusion
文章通过理论分析和实验证明，深度对冲在不满足凸性约束的环境中容易陷入局部最优，而AlphaZero能够在类似的复杂环境中找到接近最优的策略。AlphaZero的方法论和样本效率优势在数据稀缺的金融环境中显得尤为重要。
## 944. `cs.LG` - 具有约束的平滑准凸优化 [PDF](https://arxiv.org/pdf/2510.01943), [HTML](https://arxiv.org/abs/2510.01943)
### Authors
David Martínez-Rubio
### Background
准凸函数构成一个广泛而非凸的类别，适用于线性动态系统、广义线性模型和黎曼优化等领域。当前几乎最优的算法仅在仿射空间中有效，因为在处理一般凸约束时会损失一个自由度。关于具有约束的$boldsymbol{boldsymbol{beta}}$-准凸光滑函数，独立地在Martínez-Rubio（2022年）和Lezane、Langer和Koolen（2024年）中都提出了寻找一个几乎最优的加速算法的问题。这项研究解决了这一问题，设计了不精确加速近邻点算法，并使用了一种一阶方法实现了上述速度，从而改进了Martínez-Rubio（2022年）中加速地黎曼优化解的复杂性。此外，还分析了在该约束准凸设置下的投影梯度下降法和Frank-Wolfe算法。到目前为止，这项工作为具有一般凸约束的准凸光滑函数的一阶方法提供了首次分析.
### Innovation
设计并实现了不精确加速近邻点算法，解决了具有约束的$boldsymbol{boldsymbol{beta}}$-准凸光滑函数的几乎最优算法问题，改进了现有算法的复杂性。还首次分析了具有约束的准凸光滑函数的一阶方法。
### Conclusion
通过设计和应用一种不精确的加速近邻点算法，解决了具有约束的准凸优化问题，理论上改进了算法复杂度，并对投影梯度下降法和Frank-Wolfe算法进行了分析，填补了该领域的空白。
## 945. `cs.LG` - Uniform-in-time convergence bounds for Persistent Contrastive Divergence Algorithms [PDF](https://arxiv.org/pdf/2510.01944), [HTML](https://arxiv.org/abs/2510.01944)
### Authors
Paul Felix Valsecchi Oliva,O. Deniz Akyildiz,Andrew Duncan
### Background
该研究提出了一个连续时间框架下的持久对比发散（PCD）方法，用于无正规化密度的最大似然估计（MLE）。传统的PCD方法通常是离散时间的，而该研究通过将PCD表示为耦合的多尺度随机微分方程（SDE）系统，实现了参数优化与相关参数化密度的采样同步进行。这项工作基于新颖的连续时间形式推导出了误差界，这使得可以统一时间推导出尺度系统与平均情况之间的矩差异的界。此外，还介绍了利用一类显式稳定的积分器，即随机正交龙格-库塔切比雪夫（S-ROCK）方法，它提供了长期误差估计，从而形成了一种新的基于能量模型（EBM）的训练方法，具有明确的误差保证。
### Innovation
该研究的创新点在于：1) 提出了将PCD表示为多尺度SDE系统的新颖连续时间框架；2) 通过多尺度系统与平均情形之间的统一时间误差界，推导出明确的误差界；3) 引入了高效的连续时间方案实现，使用S-ROCK积分器并提供了长期的误差估计；4) 提供了一种训练能量模型的新方法，具有明确的误差保证。
### Conclusion
该研究基于新颖的连续时间框架提出了改进的PCD算法，利用S-ROCK积分器提高了模型训练的精度和效率，并提供了训练EBMs的误差保证。
## 946. `cs.LG` - 自适应核选择的Stein变分梯度下降方法 [PDF](https://arxiv.org/pdf/2510.02067), [HTML](https://arxiv.org/abs/2510.02067)
### Authors
Moritz Melcher,Simon Weissmann,Ashia C. Wilson,Jakob Zech
### Background
贝叶斯推理中的核心挑战是高效地近似后验分布。Stein变分梯度下降(SVGD)是一种流行的变分推理方法，通过移动一组粒子来近似目标分布。SVGD的动力学由再生核希尔伯特空间(RKHS)引导，并且对核函数的选择非常敏感，这直接影响到收敛性和逼近质量。常用的中位数启发式方法提供了一种简单的核带宽设置方法，但缺乏灵活性，尤其是在高维情况下表现不佳。
### Innovation
本文提出了自适应选择核参数的新策略，利用基于核Stein差异（KSD）的最新收敛性分析，通过在KSD梯度上升下自适应调整核带宽，提出了Ad-SVGD方法，该方法在粒子更新和核带宽调整之间交替进行。此外，对最小化固定核上的KSD进行了简化理论分析，并扩展到了自适应设置。
### Conclusion
实验结果进一步支持了这一见解：Ad-SVGD在各种任务中始终优于标准启发式方法。
## 947. `cs.LG` - 基于扩散模型逆问题的人体姿态零样本估计 [PDF](https://arxiv.org/pdf/2510.02043), [HTML](https://arxiv.org/abs/2510.02043)
### Authors
Sahil Bhandary Karnoor,Romit Roy Choudhury
### Background
人体姿态估计是指追踪人体的完整姿态，包括头部、躯干、手臂和腿部。这个任务在实际应用中具有挑战性，特别是在传感器数量有限的情况下。过去的研究表明，使用条件扩散模型可以获得可喜的结果，其中姿态预测基于传感器的<位置，旋转>测量。然而，这些方法在跨用户推广时表现不佳，主要原因是位置测量极易受到用户体型的影响。这篇论文将人体姿态估计视为逆问题，并设计了一种有能力实现零样本泛化的算法。该方法利用预训练的扩散模型，并仅以其旋转测量作为条件；然后通过从测量位置中推导出的似然项来引导该模型的先验知识。因此，对于任何用户，所提出的InPose方法都能够生成最可能的姿态序列来解释稀缺的带体测量。
### Innovation
该研究将人体姿态估计转化为一个逆问题，并设计了一种可以实现零样本泛化的算法。其创新点在于利用预训练的扩散模型，仅使用旋转测量来进行条件下的姿态估计，然后通过从测量位置推导出的似然项引导模型的先验知识，从而实现对于不同体型用户的良好泛化能力。
### Conclusion
所提出的InPose方法能够在任何用户身上生成最可能的姿态序列来解释稀疏的带体测量，解决了传统方法在跨用户推广时表现不佳的问题。
## 948. `cs.LG` - 跨越国界的偏差：AI生成音乐中的全球不平等 [PDF](https://arxiv.org/pdf/2510.01963), [HTML](https://arxiv.org/abs/2510.01963)
### Authors
Ahmet Solak,Florian Grötschla,Luca A. Lanzendörfer,Roger Wattenhofer
### Background
尽管近年来在音乐生成模型方面取得了显著进展，但这些模型在不同国家、语言、文化和音乐类型中的偏见研究仍然相对不足。这一研究空白加剧了由于缺乏能够捕捉全球音乐多样性的数据集和基准而产生的问题。为了应对这些挑战，我们引入了GlobalDISCO，这是一个大规模的音乐数据集，包含由最先进的商用生成音乐模型生成的73000首音乐轨道，以及与LAION-DISCO-12M中的93000首参考轨道配对链接。该数据集涉及147种语言，包含从MusicBrainz和Wikipedia提取的音乐风格提示。数据集具有全球平衡性，代表了来自79个国家和五大洲艺术家的音乐风格。
### Innovation
我们引入了GlobalDISCO，这是一个大规模数据集，包含最先进的商用生成音乐模型生成的73000首音乐轨道，以及与LAION-DISCO-12M中的93000首参考轨道配对链接。该数据集涉及147种语言，包含从MusicBrainz和Wikipedia提取的音乐风格提示。这一数据集打破了地域限制，实现了全球平衡，并揭示了不同地区和音乐类型的生成模型的性能差异。此外，通过评估发现，高质量和与参考音乐一致性的差异显著存在，并且模型在主流与地域性音乐类型之间的性能表现存在显著差异，包括生成更符合主流音乐分布的地区性音乐类型的情况。
### Conclusion
我们的评估结果揭示了高资源区域与低资源区域之间音乐质量及与参考音乐一致性方面的巨大差异。此外，我们还发现了主流音乐类型和地理小众音乐类型之间模型表现上的显著差异，其中包括模型生成更加符合主流音乐分布的地区性音乐类型的情况。这些发现强调了进一步研究和优化AI生成音乐以减少全球不平等的重要性。
## 949. `cs.LG` - 变分秘密共同随机性提取 [PDF](https://arxiv.org/pdf/2510.02048), [HTML](https://arxiv.org/abs/2510.02048)
### Authors
Xinyang Li,Vlad C. Andrei,Peter J. Gu,Yiqi Chen,Ullrich J. Mönich,Holger Boche
### Background
该论文研究了如何在存在窃听者Eve的情况下，从两个合法方Alice和Bob观测到的相关随机源中抽取出共同随机性（CR）或秘密密钥，通过公开讨论实现。提出了一个实用的两阶段CR提取框架，为理解信息泄露风险和保证安全性提供了新的思路。背景包括了传统方法的局限性，如需要双向信道探测和依赖信道互易性原理，因此在高移动性场景下不适用。
### Innovation
论文提出了一种基于变分概率量化（VPQ）的两阶段CR提取框架，通过引入变分学习目标和对抗训练，使Alice和Bob能够将他们的观察结果映射为几乎均匀的离散随机变量，同时最小化对Eve的信息泄露。第二阶段使用基于代码偏移构造的安全散列码使编码器输出相等，从而确保秘密性。此外，提出了一种基于传感的方法生成物理层密钥（PLK），该方法适用于集成传感与通信（ISAC）系统，通过Alice和Bob测量的配对距离角度（RA）图作为相关源。这种方法通过端到端模拟和真实世界的软件定义无线电（SDR）测量验证，即使Eve部分了解Bob的位置也有效。
### Conclusion
研究结果表明，提出的CR提取框架以及基于传感器的方法在不同场景下都非常可行，并展示了出色的表现。这为在实际应用场景中保护通信安全和信息传输提供了新的解决方案。
## 950. `cs.LG` - FlexDoc: 参数化采样生成多样多语言合成文档以训练文档理解模型 [PDF](https://arxiv.org/pdf/2510.02133), [HTML](https://arxiv.org/abs/2510.02133)
### Authors
Karan Dua,Hitesh Laxmichand Patel,Puneet Mittal,Ranjeet Gupta,Amit Agarwal,Praneet Pabolu,Srikant Panda,Hansa Meghwani,Graham Horwood,Fahad Shah
### Background
开发企业规模的文档理解模型需要大规模、多样且注释良好的数据集，涵盖多种文档类型。但是，由于隐私限制、法律限制以及大量需要的手动注释，收集如此数据的成本非常高，可能达到数百万美元。这使得数据收集变得极其昂贵且难以实施。
### Innovation
FlexDoc 是一种可扩展的合成数据生成框架，结合了随机模式和参数化采样，生成具有丰富注释的真实多语言半结构化文档。通过概率性建模布局模式、视觉结构和内容变化，FlexDoc 允许大规模生成多样化的文档变体。实验表明，使用 FlexDoc 生成的数据可以将关键信息提取 (KIE) 任务的绝对 F1 分数提高高达 11%，同时与传统的硬模板方法相比，将注释工作量减少超过 90%。
### Conclusion
FlexDoc 的解决方案正处于活跃部署阶段，使得企业在加速文档理解模型开发的同时，大幅减少了数据获取和注释的成本。
## 951. `cs.LG` - 多数据因果发现用于统计飓风强度预测 [PDF](https://arxiv.org/pdf/2510.02050), [HTML](https://arxiv.org/abs/2510.02050)
### Authors
Saranya Ganesh S.,Frederick Iat-Hin Tam,Milton S. Gomez,Marie McGraw,Mark DeMaria,Kate Musgrave,Jakob Runge,Tom Beucler
### Background
统计飓风强度预报受到复杂非线性交互和难以识别相关预测因子的限制。传统方法侧重于相关性或拟合度，往往会忽视混杂变量，影响在未见热带风暴中的泛化能力。
### Innovation
引入基于ERA5气象再分析的统计飓风强度预测方案（SHIPS）的多数据因果发现框架。通过多个实验识别出与飓风强度变化因果关联的预测因子，并将其与无选择、相关性和随机森林特征重要性进行比较。因果特征选择在未见测试案例中表现出更优异的性能，特别是在3天预报时效以下。因果特征主要包括垂直切变、中层潜势涡度和地表湿度条件，这些特征具有物理意义但往往未被充分利用在飓风强度预测中。此外，通过纳入因果发现的预测因子构建扩展预测因子集（SHIPS+），提升了短期预测技能，且使用多层感知机引入非线性进一步延长了预测效果。
### Conclusion
因果发现提高了飓风强度预测的准确性，为迈向更加基于证据的预报开辟了道路。
## 952. `cs.LG` - SoundReactor: 帧级在线视频到音频生成 [PDF](https://arxiv.org/pdf/2510.02110), [HTML](https://arxiv.org/abs/2510.02110)
### Authors
Koichi Saito,Julian Tanke,Christian Simon,Masato Ishii,Kazuki Shimada,Zachary Novack,Zhi Zhong,Akio Hayakawa,Takashi Shibuya,Yuki Mitsufuji
### Background
当前的视频到音频（V2A）生成模型在离线模式下运行，假设整个视频序列或视频帧的片段已经可用。这在需要即时响应的交互式应用（如直播内容创作）及新兴生成世界模型中存在显著局限。研究为此类场景的需求提出了新颖的帧级在线V2A生成任务，即模型无需未来视频帧的情况下，能够自回归生成音频。
### Innovation
提出了SoundReactor，它是首个简单且有效的针对此任务专门设计的框架。SoundReactor的设计保证了端到端因果性，并且能够以音视频同步的方式实现低延迟。该模型采用仅解码的因果Transformer结构应用于连续音频潜变量，并利用DINOv2视觉编码器最小变体提取的网格（块）特征进行视觉条件信息的加工，以便维护端到端的因果性和效率。此外，该模型通过扩散预训练与一致性微调相结合的方式进行训练，从而加速扩散头部的解码过程
### Conclusion
在AAA游戏系列多样化的视频基准测试中，模型成功生成了语义和时间上对齐的高质量立体声音频，经过了客观和人工评估的验证。在30FPS和480p视频上，单个H100的设备上实现了低帧级波形水平延迟（使用头NFE=1时为26.3ms，NFE=4时为31.5ms）。
## 953. `cs.LG` - ReTabAD：在表型异常检测中恢复语义上下文的基准 [PDF](https://arxiv.org/pdf/2510.02060), [HTML](https://arxiv.org/abs/2510.02060)
### Authors
Sanghyu Yoon,Dongmin Kim,Suhee Yoon,Ye Seul Sim,Seungdong Yoa,Hye-Seung Cho,Soonyoung Lee,Hankook Lee,Woohyung Lim
### Background
在表型异常检测（AD）中，文本语义经常携带关键信号，因为异常的定义紧密依赖于特定领域的上下文。然而，现有的基准数据集只提供原始数据点，而不包含语义上下文，忽视了专家在实践中依赖的丰富文本元数据，如特征描述和领域知识。这些限制限制了研究的灵活性，并阻止模型充分利用领域知识进行检测。现有的异常检测基准缺乏这种语义信息，使得相关研究和模型开发受限于原始数据点的使用。因此，研究需要一种能够提供丰富语义上下文的数据集和方法，以提高异常检测的准确性与解释性，更好地利用领域知识进行检测研究。因此，背景在于现有的异常检测数据集没有提供上下文信息，导致模型检测能力受限，该研究旨在填补这一空白，提供一个包含丰富语义信息的基准数据集，以提升异常检测研究的灵活性与应用效果。
### Innovation
ReTabAD通过提供20个精心策划的表格数据集，这些数据集包含结构化的文本元数据，并集成了最新的异测算法，包括经典、深度学习和基于LLM的方法。此外，ReTabAD提出了一个零样本LLM框架，该框架利用语义上下文，无需特定任务的训练，即可建立未来研究的强基线。这项工作的创新在于填补了现有基准数据集缺乏语义上下文的信息，从而提供了包含语义信息的数据集和应用框架。这项创新对于提高表型异常检测的准确性、灵活性和解释性具有重要意义。
### Conclusion
实验结果表明，语义上下文可以提高检测性能，并通过支持领域相关的推理来增强可解释性。这些发现为系统的探索具有上下文感知能力的异常检测研究奠定了基准，标志着ReTabAD数据集对于推进建立一个通用且有效的异常检测方法是一个重要的里程碑。通过ReTabAD，我们可以更好地理解和利用上下文信息以提高异常检测的性能和可解释性。
## 954. `cs.LG` - ShapeGen3DCP：一种用于3D混凝土打印层形状预测的深度学习框架 [PDF](https://arxiv.org/pdf/2510.02009), [HTML](https://arxiv.org/abs/2510.02009)
### Authors
Giacomo Rizzieri,Federico Lanteri,Liberato Ferrara,Massimiliano Cremonesi
### Background
本文介绍了ShapeGen3DCP，一种用于快速和准确预测3D混凝土打印(3DCP)中纤维横截面几何形状的深度学习框架。该方法基于神经网络架构，输入包括流体状态下材料属性（密度、屈服应力、塑性粘度）和工艺参数（喷嘴直径、喷嘴高度、打印和流动速度），直接预测挤出的层形状。为了增强泛化能力，一些输入被重新表述为无量纲参数，这些参数能捕获潜在的物理原理。预测的几何形状使用傅立叶描述符紧凑地表示，这可以确保平滑、闭合和对称的轮廓，同时将预测任务缩减为少量系数。训练数据集使用一个已建立的粒子有限元(PFEM)模型合成生成，克服了实验数据稀缺的问题。
### Innovation
ShapeGen3DCP框架结合使用无量纲参数和傅立叶描述符，提高预测的准确性和泛化能力。它通过合成生成训练数据集，充分利用了现有粒子有限元模型，解决了实验数据不足的问题。该框架能够进行层形状预测，从而实现3DCP中的预校准打印设置、减少或消除试错调整，以及高级设计的工具路径优化。未来，将该框架与仿真和传感器反馈相结合，有望实现3DCP的闭环数字孪生，驱动实时过程优化、缺陷检测和适应性控制打印参数。
### Conclusion
该框架已经通过多样化的数值和实验案例验证，显示出高精度和可靠性，为3DCP应用提供了实际价值，从预校准打印设置到高级设计的工具路径优化均具有广泛的应用前景。进一步的研究可以通过将该框架与仿真和传感器反馈结合，实现3DCP的闭环数字孪生，从而实现实时过程优化、缺陷检测和适应性控制打印参数。
## 955. `cs.LG` - 多比特音频水印 [PDF](https://arxiv.org/pdf/2510.01968), [HTML](https://arxiv.org/abs/2510.01968)
### Authors
Luca A. Lanzendörfer,Kyle Fearne,Florian Grötschla,Roger Wattenhofer
### Background
音频水印技术已经存在，但现有的方法通常需要嵌入器和检测器模型的共同训练，并且在鲁棒性和不可感知性之间存在着不小的挑战。该研究旨在提供一种后嵌入方法，能够在不依赖嵌入器-检测器模型训练的情况下实现音频水印的最佳鲁棒性和不可感知性。
### Innovation
该研究提出了Timbru，一种后嵌入音频水印模型，能够在不训练嵌入器-检测器模型的情况下，通过在预训练的音频VAE的潜在空间中添加不可感知的扰动来实现音频水印，利用CLAP模型进行水印提取。该方法能有效抵抗常见的音频处理攻击，同时保持高感知质量。
### Conclusion
通过实验评估，在MUSDB18-HQ数据集上，该方法在与AudioSeal，WavMark和SilentCipher等现有系统相比时，获得了最佳的平均位错误率，同时保持了感知质量，显示了一种无数据集依赖的高效、可行的音频不可感知水印路径。
## 956. `cs.LG` - 非渐近数据分析在估计精度矩阵中的数据增强方法 [PDF](https://arxiv.org/pdf/2510.02119), [HTML](https://arxiv.org/abs/2510.02119)
### Authors
Lucas Morisset,Adrien Hardy,Alain Durmus
### Background
本文解决高维环境下逆协方差（也称精度矩阵）估计的问题。具体来说，本文专注于两类估计器：线性收缩估计器，其目标项与单位矩阵成比例；以及基于数据增强（DA）的估计器。数据增强是通过在模型拟合前增加人工样本（通常通过生成模型或原始数据的随机变换生成）丰富数据集的做法。无论是哪一类估计器，本文都推导出了相应的估计器，并提供了它们的二次误差集中上限。这不仅有助于方法比较，还能进行超参数调优，例如选择最优的人工样本比例。在技术层面，本文的分析依赖于随机矩阵理论工具，并引入了广义解析矩阵的新型确定性等价方法，能够处理具有特定结构的相关样本。
### Innovation
本文创新性地提出了一种基于数据增强的精度矩阵估计方法，并通过引入广义解析矩阵的新型确定性等价方法，为高维环境下的精度矩阵估计提供了非渐近分析。这种方法不仅能够进行两种估计器的比较，还能通过选择最优的人工样本比例来进行超参数调优。此外，这种分析依赖于随机矩阵理论，对处理具有特定结构的相关样本也有一定的突破
### Conclusion
本文通过结合线性收缩估计器与数据增强方法，为高维环境下的精度矩阵估计提供了新的视角。通过非渐近分析，研究者不仅能够进行方法比较，还能够更精确地调整估计器的超参数。此外，这一分析方法为处理具有特定结构的样本提供了新的理论依据。
## 957. `cs.LG` - VarCoNet：一种针对静息态fMRI功能连接提取的变异感知自监督框架 [PDF](https://arxiv.org/pdf/2510.02120), [HTML](https://arxiv.org/abs/2510.02120)
### Authors
Charalampos Lamprou,Aamna Alshehhi,Leontios J. Hadjileontiadis,Mohamed L. Seghier
### Background
考虑到个体间脑功能的变异对于精准医疗至关重要，本文通过将功能个体间变异视作有意义的数据而非噪音，提出了VarCoNet，一种提升的自监督框架，用于从静息态fMRI (rs-fMRI) 数据中稳健地提取功能连接组（FC）。该框架利用自监督对比学习来利用固有的个体间功能变异，作为脑功能编码器生成适用于下游任务的FC嵌入。测试表明该框架在两个下游任务中优于多种先进方法，展示出优越性、稳健性、可解释性和通用性。
### Innovation
VarCoNet采用了新颖的自监督对比学习策略和基于rs-fMRI信号分割的增强策略，引入了1D-CNN-Transformer编码器和稳健的贝叶斯超参数优化，以此作为脑功能编码器生成FC嵌入，该框架在缺乏标注数据的情况下也能应用于下游任务。VarCoNet还通过对多个脑区划的彻底测试，展示了其在多种深学习方法中的优越性和通用性，为rs-fMRI的功能连接分析提供了一个灵活且稳健的框架。
### Conclusion
总体而言，VarCoNet提供了针对rs-fMRI的功能连接分析的通用和稳健的框架，并在两个下游任务中取得了显著结果。
## 958. `cs.LG` - 学习推理以检测幻觉片段 [PDF](https://arxiv.org/pdf/2510.02173), [HTML](https://arxiv.org/abs/2510.02173)
### Authors
Hsuan Su,Ting-Yao Hu,Hema Swetha Koppula,Kundan Krishna,Hadi Pouransari,Cheng-Yu Hsieh,Cem Koc,Joseph Yitan Cheng,Oncel Tuzel,Raviteja Vemulapalli
### Background
大型语言模型（LLMs）常常生成幻觉，即无法验证的内容，这损害了模型的可靠性。大多数先前的研究将幻觉检测视为二分类任务，但在实际应用中，更需要辨别出幻觉片段的具体部分，这是一个多步骤的决策过程。文章提出，显式的推理可能有助于检测幻觉片段的复杂任务。
### Innovation
本文提出了一种名为RL4HS的强化学习框架，通过在片段级别提供奖励函数来鼓励推理。RL4HS基于Group Relative Policy Optimization，并引入了Class-Aware Policy Optimization以解决奖励不平衡的问题。实验结果表明，这种方法在RAGTruth基准测试（摘要、问答、数据到文本）中优于预训练的推理模型和监督微调。
### Conclusion
RL4HS证明了在检测幻觉片段时需要使用强化学习和片段级别的奖励，从而强调了该方法的必要性。
## 959. `cs.LG` - 如何找到优秀论文：自我排名作为超越同行评审的科学影响力预测强大力量 [PDF](https://arxiv.org/pdf/2510.02143), [HTML](https://arxiv.org/abs/2510.02143)
### Authors
Buxin Su,Natalie Collina,Garrett Wen,Didong Li,Kyunghyun Cho,Jianqing Fan,Bingxin Zhao,Weijie Su
### Background
学术研究中的同行评审不仅旨在确保事实正确性，还旨在识别具有高科学潜力的研究工作，这些工作能够塑造未来的研究方向。在快速发展的领域如人工智能（AI）中，这一任务尤其重要。然而，由于提交数量的快速增长，这一任务变得越来越困难。因此，本文通过研究一项在领先AI会议上进行的大规模实验，探讨了一种未被充分探索的识别高影响力研究的指标：作者对其向同一AI会议提交的多篇作品的自我排名。实验基于博弈论推理，假设自我排名对识别优质论文具有信息价值，因为作者对其工作概念深度和长期潜力有独特的理解。
### Innovation
本研究创新之处在于提出了一种利用作者自我排名来识别高影响力研究的新方法。这一方法基于博弈论推理，考虑了作者对自身作品的理解优势。通过在顶级AI会议上的大规模实验验证自我排名的有效性，并展示了自我排名在预测未来引文数量方面优于同行评审分数的表现。实验还调整了潜在混杂因素的影响，如预印本发表时间和自我引用，进一步证实了该方法的可靠性与有效性。
### Conclusion
研究结果表明，作者的自我排名为同行评审提供了一个可靠的补充工具，可以更好地识别和提升AI中的高影响力研究。
## 960. `cs.LG` - BioinfoMCP：一种使能有代理能力的生物信息学的统一平台 [PDF](https://arxiv.org/pdf/2510.02139), [HTML](https://arxiv.org/abs/2510.02139)
### Authors
Florensia Widjaja,Zhangtianyi Chen,Juexiao Zhou
### Background
生物信息学工具在复杂的计算生物学任务中至关重要，但它们与新兴的人工智能代理框架的整合被不兼容的接口、异构的输入输出格式和不一致的参数约定所阻碍。虽然Model Context Protocol (MCP) 提供了一个标准化框架用于工具-AI通信，但将数百种现有的和不断增长的专业生物信息学工具手动转换为MCP兼容服务器既费时又不可持续。
### Innovation
我们提出了BioinfoMCP，这是一个统一平台，包含两个组成部分：BioinfoMCP Converter，自动从工具文档中生成稳健的MCP服务器，利用大型语言模型；BioinfoMCP Benchmark，系统地验证转换工具在多种计算任务中的可靠性和多功能性。该平台包含38个MCP转换的生物信息学工具，广泛验证后发现，94.7%的工具能够在三种广泛使用的AI代理平台中成功执行复杂的流程。
### Conclusion
通过消除AI自动化技术障碍，BioinfoMCP使得非专业编程人员可以通过自然语言与复杂的生物信息学分析交互，并提供了一条构建智能、互操作计算生物学的可扩展路径。
## 961. `cs.LG` - 通过离散音频令牌实现高保真语音增强 [PDF](https://arxiv.org/pdf/2510.02187), [HTML](https://arxiv.org/abs/2510.02187)
### Authors
Luca A. Lanzendörfer,Frédéric Berdoz,Antonis Asonitis,Roger Wattenhofer
### Background
近期基于自动回归的变压器语音增强（SE）方法已通过利用先进的语义理解和语音上下文建模取得了显着成果。然而，这些方法常常依赖复杂多阶段的流程和低采样率的编码器，这些限制了它们在广泛和任务相关的语音增强应用中的适用性。
### Innovation
引入了DAC-SE1，一种基于离散高分辨率音频表示的简化语言模型架构。DAC-SE1在保持细微声音特性的同时，保持语义连贯。实验结果显示，DAC-SE1在客观感知指标和MUSHRA人类评估中均超过了最先进的自动回归语音增强方法。
### Conclusion
我们公开了我们的代码库和模型检查点，以支持进一步研究具有可扩展性、统一性和高质量语音增强的领域。
## 962. `cs.LG` - UpSafe°C: 通用型控制安全性重塑在大型语言模型 [PDF](https://arxiv.org/pdf/2510.02194), [HTML](https://arxiv.org/abs/2510.02194)
### Authors
Yuhao Sun,Zhuoer Xu,Shiwen Cui,Kun Yang,Lingyun Yu,Yongdong Zhang,Hongtao Xie
### Background
大型语言模型（LLMs）在多种任务上取得了显著进展，但仍然面临诸如有害内容生成和故障岛攻击等安全风险。现有安全技术，如外部护栏、推理时指导和训练后对准，各有局限性，难以在安全、实用性和可控性之间找到平衡。
### Innovation
本文提出了一种新的框架UpSafe°C，通过安全感知的重塑增强LLM安全性。该方法首先识别出安全关键层，将其转变成稀疏Mixture-of-Experts（MoE）结构，其中路由器作为软护栏，在激活原始MLP和添加的安全专家之间进行选择性激活。另外，引入了两阶段的强化学习策略来增强安全性辨别能力，同时保留一般能力。为在推理时提供灵活控制，引入了安全温度机制，允许对安全性和实用性之间的权衡进行动态调整。实验结果表明，UpSafe°C在保持通用任务性能的同时，能够显著提高对有害和故障岛输入的安全性。并且，安全温度机制提供了细粒度的推理时控制，实现了实用性和安全性的帕累托前沿。
### Conclusion
我们的结果展示了LLM安全性的新方向：从静态对准转向动态、模块化和推理感知控制。
## 963. `cs.LG` - 对比音频-视觉嵌入中的对比损失与三元组损失：类内方差和贪婪性分析 [PDF](https://arxiv.org/pdf/2510.02161), [HTML](https://arxiv.org/abs/2510.02161)
### Authors
Donghuo Zeng
### Background
对比损失和三元组损失在深度度量学习中广泛应用，但它们对表示质量的影响尚不充分理解。本文通过理论和实证比较这两种损失，集中在类内和类间方差以及优化行为（例如贪婪更新）的研究上。通过在合成数据和真实数据集（如MNIST、CIFAR-10）上的特定任务实验，分析表明，三元组损失能够保持更大的类内和跨类方差，支持学习表示中的更细致区分。相比之下，对比损失会压缩类内嵌入，可能隐藏细粒度的语义差异。为了更好地理解它们的优化动力学，本文通过对损失衰减率、激活比例和梯度范数的分析，发现对比损失在早期推动了大量小幅度更新，而三元组损失则产生更少但更强烈的更新，能够持续在困难实例的学习上。为了对比两种损失在分类和检索任务上的效果，在MNIST、CIFAR-10、CUB-200和CARS196数据集上的一致性设置下，结果表明三元组损失在细节保留和困难样本聚焦方面更优，而对比损失则更适合平滑、广泛的基础嵌入细化。
### Innovation
本文通过合成数据和真实数据集的特定任务实验，对对比损失和三元组损失进行了详细的理论和实证比较，揭示了这两种损失在优化动态和表示质量方面的不同特性。通过分析损失衰减率、激活比例和梯度范数，深入理解了对比损失和三元组损失在不同任务中的优化行为。研究结果表明，三元组损失在保持类内和跨类方差方面表现出色，而对比损失在压缩类内嵌入方面更为有效。本文的创新在于对两种损失在具体任务上的效果提供了新的见解，并为未来的研究和应用提供了指导。
### Conclusion
本文结果表明，三元组损失在保留细节和聚焦困难样本方面具有优势，而对比损失在平滑嵌入和广泛改进方面具有优势。因此，建议在需要保留更多细节或解决困难样本的任务中使用三元组损失，而在需要平滑和广泛改进嵌入的任务中使用对比损失。
## 964. `cs.LG` - 测量引导的一致性模型采样方法用于逆问题 [PDF](https://arxiv.org/pdf/2510.02208), [HTML](https://arxiv.org/abs/2510.02208)
### Authors
Amirreza Tanevardi,Pooria Abbas Rad Moghadam,Sajjad Amini
### Background
扩散模型已成为解决逆向成像问题的强大生成先验，但由于依赖于多步采样的缓慢过程限制了其实用部署。一致性模型通过允许在单步或非常少的步数内生成高质量图像来解决此瓶颈，但它们直接应用于逆问题的研究尚不充分。
### Innovation
本文提出了一种专门针对逆问题重建修改的一致性采样方法：通过与测量算子相关的测量一致性机制引导采样的随机性，从而在保持基于一致性生成的高效性的同时，确保对获取测量值的忠实度。实验结果显示，在Fashion-MNIST和LSUN卧室数据集上，感知和像素级指标（包括Fréchet Inception Distance、Kernel Inception Distance、峰值信噪比和结构相似性指数措施等）的一致改进，比基线一致性采样更具有竞争力或更优的重建效果，只需少量步骤即可实现.
### Conclusion
本研究通过引入一种测量引导的一致性模型采样方法，实现了逆问题下高效且高质量的重建，并通过实验证明了与基线方法相比的显著改进。
## 965. `cs.LG` - NoMod：一种针对模块学习误差问题的非模攻击 [PDF](https://arxiv.org/pdf/2510.02162), [HTML](https://arxiv.org/abs/2510.02162)
### Authors
Cristian Bassotto,Ermes Franch,Marina Krček,Stjepan Picek
### Background
量子计算的发展威胁到了传统的公钥密码学，促使NIST采用后量子方案，如基于模块学习错误（Module-LWE）问题的方案。为此，该论文研究了一种新的非模攻击方法NoMod，旨在绕过建模模运算的挑战，并将溢出视为统计损坏，将密钥恢复视为鲁棒的线性估计问题。
### Innovation
该论文提出了NoMod，一种混合白盒密码分析方法，通过将模运算溢出视为统计损坏来绕过模运算的挑战，并采用鲁棒线性估计。同时，该方法结合了优化的格预处理技术，包括减小向量存储和代数放大，以及使用Tukey的Biweight损失训练的鲁棒估计器。
### Conclusion
实验表明，NoMod能够在维数n=350时实现二进制秘密的完整恢复，在n=256时恢复稀疏二进制秘密，并在CRYSTALS-Kyber设置中使用参数(n, k) = (128, 3)和(256, 2)成功恢复稀疏秘密。研究成果已被匿名存放在指定的仓库中，供进一步研究使用。
## 966. `cs.LG` - GeoPurify: 开集词汇3D分割的高效几何蒸馏框架 [PDF](https://arxiv.org/pdf/2510.02186), [HTML](https://arxiv.org/abs/2510.02186)
### Authors
Weijia Dou,Xu Zhang,Yi Bin,Jian Liu,Bo Peng,Guoqing Wang,Yang Yang,Heng Tao Shen
### Background
近期尝试将2D视觉语言模型(VLMs)的特征转移到3D语义分割中，暴露出一直存在的一种权衡。直接将2D特征投影到3D中会产生嘈杂和不连续的预测，而强求几何一致性则需要成本高昂的训练管道和大量标注的3D数据。作者认为这一限制来自于主流的分割和匹配范式，无法将2D语义与3D几何结构统一起来。尽管在2D到3D的转移过程中几何线索没有被消除，而是仍然在嘈杂和视角聚合的特征中潜藏。
### Innovation
为了利用这一性质，作者提出了GeoPurify，它采用一个小学生相似网络，应用几何先验从3D自监督教师模型中提取的几何先验来净化2D VLM生成的3D点特征。在推理阶段，设计了几何引导聚合模块进一步减弱点云噪声并确保语义和结构一致性。受益于潜藏的几何信息和学习到的相似网络，GeoPurify有效地减轻了这种权衡，实现了数据效率的提高。实验证明，GeoPurify在主要的3D基准测试上达到了或超越了最先进的性能，仅使用大约1.5%的训练数据。
### Conclusion
GeoPurify成功地在无需大量标注3D数据的情况下，解决了2D特征转移至3D语义分割中的噪声和不连续问题，通过利用几何信息和学习到的相似网络，提升了数据利用效率，并在多个人口学3D基准上取得了优越的性能。
## 967. `cs.LG` - 全北极跨290万观测点的物理-机器学习综合框架以评估冻土基础设施风险 [PDF](https://arxiv.org/pdf/2510.02189), [HTML](https://arxiv.org/abs/2510.02189)
### Authors
Boris Kriuk
### Background
北极地区的变暖威胁到了超过1000亿美元的依赖冻土的基础设施安全，但现有的风险评估架构缺乏时空验证、不确定性量化以及操作性的决策支持能力。现有的气候和冻土关系模型在面对外推气候情景时存在局限性。该论文提出了一种结合物理模型和机器学习的综合框架，旨在改进现有的风险评估方法，以提高预测准确性并支持实际操作决策。
### Innovation
论文提出了一种将物理模型与机器学习相结合的新型综合框架。研究整合了2005年至2021年间来自171,605个地点的290万观测数据，结合了冻土比例数据与气候再分析结果。该综合框架采用一种堆叠集成模型（随机森林+直方图梯度提升+弹性网络），在严格的时空交叉验证下实现了高精度预测。此外，研究还开发了一种混合方法，将学习到的气候-冻土关系（60%权重）与物理冻结敏感模型（40%权重）相结合，以克服纯数据驱动方法的局限性，改进对极端气候情景的预测。
### Conclusion
本研究构建了全球规模最大的验证机器学习数据集，提供了首个适用于北极基础设施的综合物理-机器学习预测系统，并提供了开放源代码工具，用于工程设计规范和气候变化适应性规划中的概率预测。研究方法可以应用于其他冻土区域，并展示了综合方法如何在气候变化应用中克服纯数据驱动的局限性。
## 968. `cs.LG` - Explore Briefly, Then Decide: Mitigating LLM Overthinking via Cumulative Entropy Regulation [PDF](https://arxiv.org/pdf/2510.02249), [HTML](https://arxiv.org/abs/2510.02249)
### Authors
Tianyi Jiang,Yi Bin,Yujuan Ding,Kainian Zhu,Fei Ma,Jingkuan Song,Heng Tao Shen
### Background
大型语言模型（LLMs）在复杂问题上通过长思维链（CoT）推理展示了非凡的推理能力。然而，它们经常遇到过度思考的问题，即对于简单问题生成不必要的冗长推理步骤。这可能导致模型效率降低，并使其难以根据问题复杂性调整推理深度。
### Innovation
研究引入了一种新的度量标准——Token Entropy Cumulative Average (TECA)，用于衡量推理过程中的探索程度。此外，提出了一种新颖的推理框架——“简要探索，然后决定”（Explore Briefly, Then Decide），并结合了累积熵调节（CER）机制造出了该框架。该框架利用TECA帮助模型动态确定思想过程结束的最佳点并提供最终答案，从而实现高效推理。
### Conclusion
跨多种数学基准实验结果表明，我们的方法在减轻过度思考问题的同时，不牺牲解决问题的能力。在较简单的数据集上，平均响应长度最多可减少71%，证明了我们在创建更高效且适应性强的推理过程方面的有效性。
## 969. `cs.LG` - TempoControl: 用于文本到视频模型的时间注意力指导 [PDF](https://arxiv.org/pdf/2510.02226), [HTML](https://arxiv.org/abs/2510.02226)
### Authors
Shira Schiber,Ofir Lindenbaum,Idan Schwartz
### Background
近年来，生成视频模型的进步使得根据自然语言提示创建高质量视频成为可能。然而，这些模型通常缺乏细粒度的时间控制，无法让用户指定生成序列中特定视觉元素出现的具体时间。为了克服这些限制，本文提出了一种名为 TempoControl 的方法，该方法能够在推理过程中实现视觉概念的时间对齐，而无需重新训练或额外的监督。TempoControl 利用文本到视频扩散模型的关键组成部分——交叉注意力图，通过一种新的优化方法来引导概念的时间分布。
### Innovation
TempoControl 利用交叉注意力图来引导生成的视频序列中概念出现的时间，通过一种新颖的优化方法实现。这种方法利用了三个互补的原则：通过相关性来调整时间形状；通过能量放大需要可视化的部分；通过熵保持空间聚焦。TempoControl 确保了精确的时间控制、高质量的视频和多样性的视频生成效果。该方法在单个和多个对象的时间重新排序以及动作和音频对齐的生成中展示了其有效性。
### Conclusion
TempoControl 方法能够在不干扰现有训练或额外监督的情况下，提供对生成视频中视觉元素时间分布的高精度控制，从而提高文本到视频生成的质量和多样性。
## 970. `cs.LG` - 使用相互信息引导扩散揭示高级视觉皮层中潜在组的选择性 [PDF](https://arxiv.org/pdf/2510.02182), [HTML](https://arxiv.org/abs/2510.02182)
### Authors
Yule Wang,Joseph Yu,Chengrui Li,Weihan Li,Anqi Wu
### Background
理解大脑高级视觉区域中神经群体如何编码以物体为中心的视觉信息仍然是计算神经科学的核心挑战。现有研究探讨了人工神经网络与视觉皮层之间的表征对齐，但这些发现是间接的，对神经群体本身的结构提供有限的见解。同样，基于解码的方法量化了神经群体中的语义特征，但并没有揭示它们的潜在组织。因此，存在一个科学问题：在高级视觉区域内，具有特征特异性的视觉信息是如何分布的，是否可以组织成具语义意义的结构子空间。研究解决这一问题的方法包括使用生成模型的力量，通过逐步解缠并可视化神经潜在子空间中的视觉-语义属性来验证和展示这些专属性。该方法利用变分自编码器推断神经群体的代数解缠神经潜在子空间，随后提出了一项由相互信息（MI）引导的扩散合成程序，用于可视化每个潜在组编码的具体视觉-语义特征。研究结果在两种猕猴的下颞叶皮层多会话神经放电数据集上验证了MIG-Vis方法的有效性。结果表明，该方法能够识别具有清晰语义选择性的神经潜在群体，这些群体对各类视觉特征，例如物体姿态、类间转换和类内内容，表现出选择性。这些研究表明，高级视觉皮层中存在着结构化的语义表征，为高级视觉区域的编码原理提供了直接且可解析的证据，进一步加深了我们对其编码机制的理解。
### Innovation
该研究引入了MIG-Vis方法，通过利用生成模型的能力可视化和验证神经潜在空间中的视觉-语义属性。该方法首先使用变分自编码器推断出一个群体共同解缠的神经潜在子空间，然后提出一个MI指导的扩散合成程序，用于可视化每个潜在组编码的具体视觉-语义特征。这种方法填补了现有研究的空白，因为它能够直接揭示神经群体内部组织及其语义选择性，从而提供关于高级视觉区内结构化语义表示的直接、可解释证据。这种方法为高级视觉区域的编码机制提供了更深入的理解。
### Conclusion
MIG-Vis方法在两种猕猴的下颞叶皮层多会话神经放电数据集上有效验证了其识别具有清晰语义选择性的神经潜在群体的能力，并展示了这些群体区分不同视觉特征的专属性。这些研究结果表明，在高级视觉区域内，神经群体的语义选择性具有明确的结构，表明高级视觉皮层中存在组织化的语义表示，这些表示是功能相关的，为高级视觉系统的编码原则提供了新的见解和直接的实证证据。
## 971. `cs.LG` - 基于物理引导的视频扩散模型学习生成物体交互 [PDF](https://arxiv.org/pdf/2510.02284), [HTML](https://arxiv.org/abs/2510.02284)
### Authors
David Romero,Ariana Bermudez,Hao Li,Fabio Pizzati,Ivan Laptev
### Background
近年来，视频生成模型取得了显著进展，被应用于电影、社交媒体制作和广告等领域。尽管这些模型具有很强的创意潜力，同时还能作为机器人及体感决策的虚拟世界模拟器，但由于它们生成的物理上可信的物体交互效果还有所不足，以及缺乏基于物理的控制机制，这些模型仍存在局限性。
### Innovation
本文提出了KineMask方法，这是一种基于物理引导的视频生成方法，能够实现真实的刚体控制、交互和效果。该方法通过单张图和指定的物体速度生成包含推断运动及未来物体交互的视频。此外，KineMask通过预测场景描述将低级运动控制与高级文本条件相结合，有效地支持了复杂动力现象的合成。
### Conclusion
实验结果表明，KineMask显著优于其他同类模型。消融研究表明，低级和高级条件在视频扩散模型中的互补作用。代码、模型和数据将公开提供。
## 972. `cs.LG` - 多于一个老师：自适应多引导策略优化以实现多样化探索 [PDF](https://arxiv.org/pdf/2510.02227), [HTML](https://arxiv.org/abs/2510.02227)
### Authors
Xiaoyang Yuan,Yujuan Ding,Yi Bin,Wenqi Shao,Jinyu Cai,Jingkuan Song,Yang Yang,Hengtao Shen
### Background
现有的强化学习方法主要依赖于自我探索或单一的离策略教师来引发较长的链式思考（LongCoT）的推理，这可能引入模型固有的偏差并限制探索，最终限制了推理多样性和性能。
### Innovation
引入了自适应多引导策略优化（AMPO），这是一种新颖的框架，该框架能够根据具体情况从多个有能力的教师模型中获取指导，但仅当策略模型无法生成正确解时才会触发。这种“按需引导”方法扩大了探索范围，同时保持自我发现的价值。此外，AMPO 还引入了一种基于理解力的选择机制，促使学生从其最有可能理解的推理路径中学习，从而平衡了广泛的探索和有效的利用。
### Conclusion
广泛的实验展示了 AMPO 显著优于强大的基准（GRPO），在数学推理任务上提高了 4.3%，在离分布任务上提高了 12.2%，同时显著提升了 Pass@k 性能并促进了更广泛的探索。使用四个同行大小的教师，我们的方法在性能上与使用单一更强大教师的方法（如 DeepSeek-R1）的性能相当，即使使用较少的数据。这些结果表明了一条更为高效且可扩展的通往更优秀推理和泛化能力的道路。我们的代码可在以下链接获取。
## 973. `cs.LG` -  Scaling 计算机使用代理的不可理喻的有效性 [PDF](https://arxiv.org/pdf/2510.02250), [HTML](https://arxiv.org/abs/2510.02250)
### Authors
Gonzalo Gonzalez-Pumariega,Vincent Tu,Chih-Lun Lee,Jiachen Yang,Ang Li,Xin Eric Wang
### Background
计算机使用代理（CUAs）有潜力自动执行日常数字任务，但由于其可靠性差和高变异性阻碍了它们在长期复杂的任务中的应用。
### Innovation
作者提出了一种名为行为最佳-of-N（bBoN）的方法，通过生成多个动态轨迹并在使用行为叙述进行描述后选择其中的最优者，从而实现广泛的探索和具有原则性的轨迹选择，显著提高了鲁棒性和成功率。bBoN方法在OSWorld中实现在69.9%的新最佳状态，超过了之前的最佳表现，并达到了接近人类水平的72%的效果。此外，研究表明，对于不同操作系统（如Windows和Android），该方法具有良好的泛化能力。这表明，当正确实现缩放CUAs时，其效果是非常显著的。有效缩放需要结构化的轨迹理解和选择，bBoN提供了一种实用框架来实现这一点
### Conclusion
我们的结果强调了正确缩放CUAs的不可理喻的有效性：有效的缩放需要结构化的轨迹理解和选择，并且bBoN提供了一种实用的框架来实现这一点。
## 974. `cs.LG` - RLAD: 训练大语言模型以发现解决推理问题的抽象 [PDF](https://arxiv.org/pdf/2510.02263), [HTML](https://arxiv.org/abs/2510.02263)
### Authors
Yuxiao Qu,Anikait Singh,Yoonho Lee,Amrith Setlur,Ruslan Salakhutdinov,Chelsea Finn,Aviral Kumar
### Background
推理要求超越模式匹配或记忆解决方案，识别并实施可以用来推导难题答案的“算法程序”。实现这一点需要认识到最相关的原语、中间结果或共享程序，并在此基础上构建。尽管强化学习（RL）通过长时间思考后的训练最终旨在揭示这种算法行为，但大多数由大型模型学习到的推理痕迹未能一致地捕捉或重用这些程序，而是滑向冗长和退化的探索。
### Innovation
我们提出了推理抽象：简明的自然语言描述，能够引导模型向学习成功的推理方向发展。训练模型能够针对一个问题提出多个抽象，随后通过RL激励利用这些抽象来构建解决方案。这导致了一种两阶段RL训练模式，简称RLAD，该模式联合训练抽象生成器和解决方案生成器。此设置有效地实现了结构化的探索，解耦了抽象提议的和解决方案生成的学习信号，并提高了对更难问题的一般化能力。实验结果表明，在测试时间更高的预算下，增加生成抽象的数量比生成更多解决方案更有益于性能，这突显了抽象在引导有意义的探索中的作用。
### Conclusion
通过上述方法，我们提出了一种新的两阶段RL训练框架，即RLAD，它能够引导模型成功地学习策略，显著提高了模型在解决推理问题时的一般化能力，并通过有效利用时间预算，提高了模型的性能。
## 975. `cs.LG` - VidGuard-R1：通过推理多模态大型语言模型和强化学习进行人工智能生成视频检测和解释 [PDF](https://arxiv.org/pdf/2510.02282), [HTML](https://arxiv.org/abs/2510.02282)
### Authors
Kyoungjun Park,Yifan Yang,Juheon Yi,Shicheng Zheng,Yifei Shen,Dongqi Han,Caihua Shan,Muhammad Muaz,Lili Qiu
### Background
随着AI生成视频技术的迅速发展，迫切需要有效的检测工具来减轻错误信息和声誉损害等社会效益风险。除了准确分类外，检测模型还需提供可解释的解释，以确保监管者和终端用户具备透明度。
### Innovation
提出了一种名为VidGuard-R1的视频真实性检测器，该检测器通过组相对策略优化（GRPO）对多模态大型语言模型（MLLM）进行微调。该模型不仅实现了高度准确的判断，还提供了深入的解释。此外，还构建了一个包含140,000个真实和AI生成视频的具有挑战性的数据集，使用GRPO对Qwen-VL进行微调，以应对时间特征和生成复杂性。实验表明，VidGuard-R1在现有基准上实现了最先进的零样本性能，并且通过额外训练将准确率提升至95%以上。
### Conclusion
通过广泛实验和案例研究进一步验证了VidGuard-R1能够产生精确且可解释的预测结果。代码已公开提供。
## 976. `cs.LG` - VideoNSA: Native Sparse Attention Scales Video Understanding [PDF](https://arxiv.org/pdf/2510.02295), [HTML](https://arxiv.org/abs/2510.02295)
### Authors
Enxin Song,Wenhao Chai,Shusheng Yang,Ethan Armand,Xiaojun Shan,Haiyang Xu,Jianwen Xie,Zhuowen Tu
### Background
视频在多模态语言模型中的理解仍然受到上下文长度的限制：模型经常错过关键的过渡帧，并且难以在长时间段内保持连贯性。
### Innovation
本文通过将原生稀疏注意力（NSA）应用到视频-语言模型中，提出了一种名为VideoNSA的方法。该方法通过在216K视频指令数据集上进行端到端训练，对Qwen2.5-VL模型进行了改进。采用硬件感知的混合注意力机制，保留密集注意力用于文本，而使用NSA处理视频部分。实验表明，与基于令牌压缩的无训练稀疏基线相比，VideoNSA在长视频理解、时间推理和空间基准测试中取得了更好的性能。
### Conclusion
进一步的消融分析揭示了四个关键发现：（1）可靠的扩展到128K的令牌；（2）固定预算下最佳的全局-局部注意力分配；（3）任务依赖的分支使用模式；（4）可学习的组合稀疏注意力有助于产生动态注意力汇聚。
## 977. `cs.LG` - 从视频基础模型中推断动态物理属性 [PDF](https://arxiv.org/pdf/2510.02311), [HTML](https://arxiv.org/abs/2510.02311)
### Authors
Guanqi Zhan,Xianzheng Ma,Weidi Xie,Andrew Zisserman
### Background
研究从视频中预测动态物理属性的任务。具体来说，研究需要时间信息才能推测的物理属性，如弹性的碰撞物体、流动性流体的粘度以及物体滑动时的动力摩擦力。这些属性需要通过视频中的视觉线索进行推断，利用经典计算机视觉技术、基于预训练的视频生成和半监督模型的跨注意力机制以及多模态大型语言模型的提示策略等方法进行探索。
### Innovation
贡献了新的视频数据集，涵盖各种视频上的物理属性训练和测试分割，以及用于实际世界评估的真实数据集；探讨了三种从视频中推断物理属性的方法；展示了生成或半监督训练的视频基础模型的性能与Oracle方法的差距，以及多模态大量语言模型（MLLMs）的当前表现较差，但通过特定的提示策略可以改进其性能。
### Conclusion
生成或半监督训练的视频基础模型在性能上接近Oracle方法，但仍然落后。多模态大型语言模型目前表现不佳，但通过适当的提示策略其表现可以得到提升。
## 978. `cs.LG` - 使用单目视频通向运动评估之路：基于深度学习的先进三维人体姿态估计器在日常生活中与惯性传感器的预临床基准比较 [PDF](https://arxiv.org/pdf/2510.02264), [HTML](https://arxiv.org/abs/2510.02264)
### Authors
Mario Medrano-Paredes,Carmen Fernández-González,Francisco-Javier Díaz-Pernas,Hichem Saoudi,Javier González-Alonso,Mario Martínez-Zarzuela
### Background
机器学习和可穿戴传感器的进步为在专科实验室外捕获和分析人类运动提供了新的机会。准确评估人类在现实世界条件下的运动对于远程医疗、运动科学和康复至关重要。本文通过VIDIMU数据集，该数据集包含13种临床相关日常生活活动的数据，对比评估了基于单目视频的三维人体姿态估计算法与惯性测量单元(IMUs)的准确性，初步研究了健康的受试者，结果不能推广到病人群体。
### Innovation
该研究使用了最新的深度学习框架（MotionAGFormer, MotionBERT, MMPose 2D-to-3D姿态提升，以及NVIDIA BodyTrack）进行人体姿态估计，并与INERTIAL SENSORS的数据进行了比较。MotionAGFormer在性能方面表现出色，整体RMSE和MAE最小，且显示出最高的Pearson相关系数和系数决定度。研究为研究人员和临床医生提供了开发远程医疗服务和远程患者监控的稳健、成本效益高和用户友好的解决方案提供了有价值的指导。
### Conclusion
两种技术都适用于实验室外的运动评估。然而，它们也强调了视频和传感器方法之间的重要权衡，包括成本、可访问性和精度。对于健康的成年人，现成的视频模型已经提供了临床有前景的运动学信息，但在某些方面仍落后于基于IMUs的估计。
## 979. `cs.LG` - 基于一致性端到端估计的反事实公平性预测 [PDF](https://arxiv.org/pdf/2310.17687), [HTML](https://arxiv.org/abs/2310.17687)
### Authors
Yuchen Ma,Valentyn Melnychuk,Dennis Frauen,Stefan Feuerriegel
### Background
反事实公平性是直接重要的，因为它涉及法律、道德和社会方面的考虑。为实现这一点，现有方法通常依赖反事实公平性，确保在不同敏感属性情况下的个体预测值与其原始预测值相同。然而，反事实是不可见的，这使得当前的反事实公平性基线缺乏理论保障。
### Innovation
该论文提出了一种新的预测模型，用于在遵循标准反事实公平性框架下直接学习敏感属性后代的反事实分布，并通过新提出的反事实调解正则化来实现公平预测，特别的是，该方法提供了理论保证，证明其在确保反事实公平性方面是有效的。此外，该方法在各种数据集上的表现达到了最佳水平。
### Conclusion
该研究表明，通过提供理论上的保证，所提出的方法在确保反事实公平性方面是有效的，并通过在多个数据集上的表现进一步证明其优越性。
## 980. `cs.LG` - Momentum-SAM：无需计算开销的敏感性意识最小化 [PDF](https://arxiv.org/pdf/2401.12033), [HTML](https://arxiv.org/abs/2401.12033)
### Authors
Marlon Becker,Frederick Altrock,Benjamin Risse
### Background
提出了用于深度神经网络优化的新优化算法Sharpness Aware Minimization (SAM)，通过在梯度计算之前由梯度上升步骤扰动参数以引导优化进入损失平缓的参数空间区域，从而展示了显著的一般性改进和减少过拟合。然而，额外的梯度计算导致计算成本翻倍，使SAM在计算能力有限的情况下不可行。
### Innovation
受Nesterov加速梯度(NAG)启发，提出了一种Momentum-SAM (MSAM)算法，通过在累积动量向量的方向上扰动参数来实现低敏感性，而无需显著增加计算开销或内存需求，相比SGD或Adam。该研究还详细评估了MSAM，并揭示了NAG、SAM和MSAM在训练优化和泛化方面的可分离机制。
### Conclusion
详细评估了Momentum-SAM (MSAM)，揭示了NAG、SAM和MSAM在训练优化和泛化方面的可分离机制，展示了MSAM在计算开销上与SGD或Adam相同，同时实现了低敏感性。源代码可通过提供的链接获取。
## 981. `cs.LG` - DragFlow: 使用区域监督解锁DiT先验的拖动编辑 [PDF](https://arxiv.org/pdf/2510.02253), [HTML](https://arxiv.org/abs/2510.02253)
### Authors
Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong
### Background
基于拖动的图像编辑长期以来一直存在目标区域失真的问题，这是因为早期基础模型Stable Diffusion的先验不足，无法将优化后的潜在空间映射回自然图像结构。随着从基于UNet的DDPMs转向更可扩展的DiT和流匹配（例如SD3.5和FLUX），生成先验显著增强，使得各种编辑任务取得了进展。然而，拖动编辑尚未从中受益。本文通过提出第一个有效利用FLUX丰富先验框架DragFlow，实现了对基线的显著改进。
### Innovation
提出了一种新的基于区域的编辑范式DragFlow，通过使用仿射变换实现更丰富和一致的特征监督，同时结合预训练开放域个性化适配器和基于梯度掩模的硬约束来增强主体一致性和保留背景清晰度。此外，引入了多模态大语言模型以解决任务歧义性问题。DragFlow在DragBench-DR和ReD Bench基准上的广泛实验表明，该方法在基于拖动的图像编辑中达到了新的前沿。
### Conclusion
DragFlow通过采用基于区域的监督来有效利用FLUX的丰富先验，在基于拖动的图像编辑中取得了显著成效，超越了基于点和基于区域的基线，设立了新的前沿标准。该代码和数据集将在发表后公开。
## 982. `cs.LG` - 基于Rényi相对熵的量子费雪信息矩阵 [PDF](https://arxiv.org/pdf/2510.02218), [HTML](https://arxiv.org/abs/2510.02218)
### Authors
Mark M. Wilde
### Background
量子费雪信息在量子信息科学中非常重要，应用于高能物理、凝聚态物理、量子估计理论、机器学习和优化等领域。通常可以通过泰勒展开中的Hessian矩阵来自然地推导量子费雪信息矩阵，这种方法对于量子信息理论研究者来说非常吸引人。然而，与经典情况不同的是，并不存在唯一的量子费雪信息矩阵，类似于不存在唯一的量子相对熵或Rényi相对熵。
### Innovation
作者发现了Rényi相对熵衍生出的信息矩阵，并基于剖分差法计算矩阵导数。对于非负Rényi参数α的所有值，log-Euclidean Rényi相对熵导出的是Kubo-Mori信息矩阵，而几何Rényi相对熵导出的是右对数导数费雪信息矩阵。由此产生的信息矩阵即使在参数α为非负值时也遵循数据处理不等式，尽管原始量本身并不一定遵循。此外，作者还推导了α-z信息矩阵及其基本性质，并建立了参数化的热态的α-z信息矩阵公式及其量子-经典混合算法。
### Conclusion
通过对Rényi相对熵的不同变体进行分析，作者揭示了不同类型的信息矩阵，并提供了估计参数化热态的α-z信息矩阵的混合量子-经典算法。这些研究结果丰富了量子费雪信息矩阵家族，并为量子信息科学提供了新的见解和工具。
## 983. `cs.LG` - QSpec: 补偿量化方案的推测性解码 [PDF](https://arxiv.org/pdf/2410.11305), [HTML](https://arxiv.org/abs/2410.11305)
### Authors
Juntao Zhao,Wenhao Lu,Sheng Wang,Lingpeng Kong,Chuan Wu
### Background
量化在加速大型语言模型（LLMs）的推理过程和减少内存消耗方面被广泛应用。虽然激活量和权重联合量化能够高效地进行低精度解码，但在多步推理任务上会遭受显著的性能下降。现有的方法难以在保证性能的前提下提高量化效率。
### Innovation
QSpec 提出了一种新颖的量化范式，通过推测性解码整合了两种互补的方案：低精度联合量化提供快速的草稿生成，而高精度权重唯一量化则确保结果的准确性。这种范式可以在各个阶段中重用权重和 KV 缓存，实现了几乎零成本的切换，无需重新训练或辅助模型。相较于高精度基准，QSpec 在不同批量设置下表现出1.64倍的加速，并在推测性解码方法中达到最高1.55倍的性能提升。此外，QSpec 支持即插即用部署，并能够在不同模型规模、量化方法和负载下进行良好泛化。
### Conclusion
QSpec 是一种实际且具备规模扩展性的解决方案，适用于在内存受限场景中的高保真量化 LLM 服务。
## 984. `cs.LG` - 神经符号AI在微分方程解析解中的应用 [PDF](https://arxiv.org/pdf/2502.01476), [HTML](https://arxiv.org/abs/2502.01476)
### Authors
Orestis Oikonomou,Levi Lingsch,Dana Grund,Siddhartha Mishra,Georgios Kissas
### Background
解析解能提供物理过程基本行为的精确洞察，但由于找到解析解困难，其应用受到限制。现有方法难以克服这一限制。
### Innovation
本文提出了将组合微分方程求解技术和迭代精炼结合的方法，通过形式语法实现构建候选解表达式，并嵌入低维（连续）潜在流形进行概率探索。这种方法整合了数值和符号微分方程求解器，通过神经符号AI框架找到各类微分方程的解析解，克服了长期存在的闭形式求解障碍。
### Conclusion
通过系统地构建候选表达式并应用基于约束的精炼，本研究在一系列问题上展示了相对于商用求解器、符号方法和近似神经网络的优势，证明了该方法的普遍性和准确性。
## 985. `cs.LG` - 非平稳线性上下文贝叶斯推断在非平稳线性上下文多臂问题中的应用 [PDF](https://arxiv.org/pdf/2307.03587), [HTML](https://arxiv.org/abs/2307.03587)
### Authors
Nicklas Werge,Yi-Shan Wu,Abdullah Akgül,Melih Kandemir
### Background
研究非平稳线性上下文多臂问题时，现有的算法通常依赖于加权正则化最小二乘（WRLS）目标。本文通过顺序贝叶斯推理的视角研究加权顺序贝叶斯（WSB），它维护的是时间变化的奖励参数的后验分布。
### Innovation
本文的主要贡献是一个针对WSB后验分布的新浓度不等式，引入了一个与先验相关的项来量化初始信念的影响。研究表明这种影响会随时间衰减，并推导出易于处理的上界，使得结果不仅可用于分析，也可用于算法设计。基于WSB，介绍了三种算法：WSB-LinUCB，WSB-RandLinUCB和WSB-LinTS。并建立了频率主义的后悔保证：WSB-LinUCB与现有的WRLS基线表现相同，而WSB-RandLinUCB和WSB-LinTS则提高了表现，同时保持了WRLS基线算法的计算效率。
### Conclusion
本文提供了一种新颖的方法来处理非平稳线性上下文多臂问题，并且所提出的算法在保持高效计算的同时，提供类似于WRLS基线的性能甚至更好，从而在处理这种复杂的问题上迈出了重要的一步。
## 986. `cs.LG` - Riemannian Variational Flow Matching for Material and Protein Design [PDF](https://arxiv.org/pdf/2502.12981), [HTML](https://arxiv.org/abs/2502.12981)
### Authors
Olga Zaghen,Floor Eijkelboom,Alison Pouplin,Cong Liu,Max Welling,Jan-Willem van de Meent,Erik J. Bekkers
### Background
在欧几里得空间中，预测端点、速度或噪声在变分流匹配（VFM）中的作用大致是等价的，因为这些操作都可以通过仿射插值实现。然而，在曲率空间中，这些等价关系不再成立。端点预测提供了更强的学习信号，通过直接最小化测地距离。
### Innovation
文中提出了Riemannian Gaussian Variational Flow Matching (RG-VFM)，这是一种基于黎曼高斯分布的变分流匹配方法，它可以应用于具有封闭测地线的流形。RG-VFM通过引入测地线距离的直接最小化，提供了优于欧几里得空间和速度基线的表现。研究还暴露了Riemannian Flow Matching (RFM) 目标缺少了通过Jacobi字段编码的曲率依赖性惩罚。
### Conclusion
实验结果表明，RG-VFM更有效地捕捉流形结构，并且在材料和蛋白质生成等实际任务中，相对于欧几里得和速度基线显著提高了下游性能。
## 987. `cs.LG` - 基于深度学习的动态肾功能衰竭预测模型的开发与外部验证：一项实证研究 [PDF](https://arxiv.org/pdf/2501.16388), [HTML](https://arxiv.org/abs/2501.16388)
### Authors
Jingying Ma,Jinwei Wang,Lanlan Lu,Yexiang Sun,Mengling Feng,Feifei Zhang,Peng Shen,Zhiqin Jiang,Shenda Hong,Luxia Zhang
### Background
慢性肾病（CKD）是一种具有高发病率和死亡率的进行性疾病，已成为全球公共卫生的重大问题。现有的大多数模型是静态的，无法捕捉疾病进展的动态趋势，限制了其对及时干预的指导能力。针对这一问题，文章通过利用实际电子健康记录（EHR）中的纵向临床指标，开发了一个动态预测模型，以实时预测肾功能衰竭的技术背景进行了介绍。
### Innovation
该研究创新地开发了一个动态预测模型，利用实际电子健康记录中的纵向临床指标进行肾功能衰竭的实时预测。该模型在内部验证（4,587患者中的918患者）和外部验证（934患者的前瞻性PKUFH队列）中表现出了竞争性的性能，展示了逐步改进的动态预测、良好的校准和临床一致的可解释性。
### Conclusion
该KFDeep模型能够在不增加临床检查成本的情况下，实现动态预测肾功能衰竭，并已成功集成到现有医院系统中，为医生在常规护理中提供了一个不断更新的支持决策工具。
## 988. `cs.LG` - 连续时间强化学习中离散采样随机策略的准确性 [PDF](https://arxiv.org/pdf/2503.09981), [HTML](https://arxiv.org/abs/2503.09981)
### Authors
Yanwei Jia,Du Ouyang,Yufei Zhang
### Background
在连续时间强化学习算法中，随机策略（也称为放松控制）得到了广泛应用。但是，执行随机策略并在连续时间环境中评估其性能仍面临挑战。
### Innovation
本文提出并严格分析了一种策略执行框架，该框架在离散时间点从随机策略中采样动作，并将其作为分段常数控制实施。本文证明了随着采样网尺寸趋于零，受控状态过程根据随机策略系数聚合后弱收敛。本文还根据系数的正则性显式量化了收敛率，并为充分正则的系数建立了最优的一阶收敛率。此外，展示了在高概率下对于随机噪声的一阶弱收敛率，并为没有波动控制的情况下每一种系统噪声的实际化建立了1/2阶路径收敛。基于这些结果，本文分析了基于离散时间观测的多种策略评估和策略梯度估计器的偏差和方差。
### Conclusion
本文的结果为[H. Wang, T. Zariphopoulou, and X.Y. Zhou, J. Mach. Learn. Res., 21 (2020), pp. 1-34]中提出的探索性随机控制框架提供了理论依据。
## 989. `cs.LG` - AutoScale：针对预训练大规模语言模型的规模感知数据混合方法 [PDF](https://arxiv.org/pdf/2407.20177), [HTML](https://arxiv.org/abs/2407.20177)
### Authors
Feiyang Kang,Yifan Sun,Bingbing Wen,Si Chen,Dawn Song,Rafid Mahmood,Ruoxi Jia
### Background
域重权技术是一种新兴的研究领域，旨在调整不同数据源的相对权重以提升大规模语言模型（LLM）预训练的效果和效率。然而，较小数据规模下表现良好的数据混合，在更大的数据规模下可能不再保持其优势，这挑战了通过在小规模实验中确定竞争力数据混合并在更大规模中直接应用的现有做法。
### Innovation
作者提出了一种两阶段、规模感知的数据组合框架AutoScale。首先，它利用参数模型预测不同数据组合下模型的损失情况，寻找较小可用预算下的近似最佳分配；其次，通过新颖的理论分析如何随规模变化优化组合的最佳方式，AutoScale在无需进一步重新训练的条件下将其扩展到更大的预算规模。实证结果表明，AutoScale加速了收敛并改善了下游性能。例如，在预训练GPT-2 Large时，它比基准方法快28%的困惑度降低速度，并且与未加权训练相比最多可加速38%，同时在各种下游任务上表现出最佳平均结果。
### Conclusion
我们的研究结果展示了随训练规模变化的域重要性变化，突显了为大规模语言模型训练进行规模依赖数据策展的必要性。我们的代码已开源。
## 990. `cs.LG` - 记忆无穷的世界中的连续学习：忘记遗忘 [PDF](https://arxiv.org/pdf/2502.07274), [HTML](https://arxiv.org/abs/2502.07274)
### Authors
Dongkyu Cho,Taesup Moon,Rumi Chunara,Kyunghyun Cho,Sungmin Cha
### Background
传统上，连续学习（CL）的关注点在于最小化示例存储，这一限制往往与现代系统不符，现代系统的瓶颈通常是GPU时间而非存储空间。本文探讨了一个更现实的情境：当存储空间足够宽裕可以避免遗忘，但重新训练的成本仍然极其高昂时。在这种实际的“折中地带”，主要挑战从稳定性转移到了可塑性，因为模型偏向先前的任务，难以学习新任务。相反，提高稳定性使得简单的回放基线能够在较低的GPU成本下达到最先进的方法的效果。
### Innovation
提出了一种名为权重空间加固（Weight Space Consolidation）的轻量级方法，结合了（1）基于排名的参数重置以恢复可塑性与（2）权重平均以增强稳定性。该方法在图像分类器的类别增量学习以及大型语言模型的持续指令调优中得到了验证，表现优于强大的基线，同时具备与回放相当的低计算成本。
### Conclusion
这些发现挑战了传统的CL假设，并为实际世界中的CL系统建立了一个新的、成本效益较高的基线，其中示例存储不再是制约因素。
## 991. `cs.LG` - Subspace Node Pruning [PDF](https://arxiv.org/pdf/2405.17506), [HTML](https://arxiv.org/abs/2405.17506)
### Authors
Joshua Offergeld,Marcel van Gerven,Nasir Ahmad
### Background
随着AI模型商用化的不断增加，提高神经网络推理效率显得尤为重要。节点剪枝是一种通过移除神经元、滤波器、注意力头或整个层来显著减少推理时间的技术，同时保持网络性能。
### Innovation
本文提出了一种新的节点剪枝方法，即将单元激活投影到一个没有冗余活动的正交子空间中，在该子空间中可以同时剪枝节点并利用线性最小二乘法恢复丢失单元的影响。此外，优化单元正交化顺序以最大化按冗余度排序单元。最终，利用这些正交子空间自动确定层间剪枝比例，等同于累积方差。该方法在ImageNet训练的VGG-16、ResNet-50和DeiT模型上匹配或超越了现有剪枝技术，同时计算成本比其他方法低24倍。此外，该方法可以一次性应用于OPT大语言模型，性能也优于竞品方法。
### Conclusion
本文提出的方法对ImageNet训练的VGG-16、ResNet-50和DeiT模型的剪枝结果达到了或超过了最先进的技术水平，同时计算成本降低了24倍；此外，该方法也可以适用于OPT大语言模型，并且表现出色。
## 992. `cs.LG` - CoLA: 通过低秩激活实现LLM的计算高效预训练 [PDF](https://arxiv.org/pdf/2502.10940), [HTML](https://arxiv.org/abs/2502.10940)
### Authors
Ziyue Liu,Ruijie Zhang,Zhengyang Wang,Mingsong Yan,Zi Yang,Paul Hovland,Bogdan Nicolae,Franck Cappello,Sui Tang,Zheng Zhang
### Background
全尺寸的多层感知机（MLPs）和注意力层的投影层在大语言模型（LLMs）中引入了极大的模型大小，消耗了大量的计算资源。我们实证观察到，预训练的LLMs的激活表现出低秩特性。
### Innovation
我们提出了CoLA及其内存高效实现CoLA-M，以使用计算高效的自动编码器替换这些全尺寸层，自然地在整个训练过程中强制执行低秩激活。这从根本上改变了架构，消除了激活冗余，大幅提升了模型容量和训练效率。
### Conclusion
实验表明，CoLA将计算成本降低了2倍，并将训练吞吐量提高了1.86倍，同时保持了全秩水平的表现。CoLA-M更进一步压缩了内存成本而不牺牲吞吐量，提供了一种在参数、计算和内存效率方面都更优的预训练方法。这些LLMs还减少了2倍的规模，以较低的内存成本在资源受限平台上实现更快的推理。
## 993. `cs.LG` - Mol-LLaMA:向大型分子语言模型中分子的通用理解迈进 [PDF](https://arxiv.org/pdf/2502.13449), [HTML](https://arxiv.org/abs/2502.13449)
### Authors
Dongki Kim,Wonbin Lee,Sung Ju Hwang
### Background
理解分子是了解生物体和推动药物发现的重要因素，需要化学和生物学的跨学科知识。虽然大型分子语言模型在任务转移方面取得了显著成功，但它们往往难以准确分析分子特征，因为它们的知识和推理能力有限。因此，本文提出了一种名为Mol-LLaMA的大型分子语言模型，该模型能够掌握以分子为中心的一般知识，并具备可解释性和推理能力。通过设计涵盖基本分子特性的关键数据类型，Mol-LLaMA考虑了分子推理所需的 essential 能力。为了提高分子理解，我们还提出了一种模块，该模块整合了来自不同分子编码器的互补信息，利用了不同类型分子表示的各自优势。实验结果表明，Mol-LLaMA能够理解分子的通用特征并提供有用的反馈，表明其作为分子分析通用助手的潜力。项目页面位于 [这里](this https URL)。
### Innovation
Mol-LLaMA 通过设计涵盖基本分子特性的关键数据类型和整合来自不同分子编码器的互补信息，提高了分子推理能力和理解力，解决了大型分子语言模型在准确分析分子特征方面的局限性。
### Conclusion
实验结果显示，Mol-LLaMA 具备理解分子一般特征和提供有用信息的能力，表明其作为分子分析通用助手的潜能。
## 994. `cs.LG` - GDP for Reporting Differential Privacy Guarantees in Machine Learning [PDF](https://arxiv.org/pdf/2503.10945), [HTML](https://arxiv.org/abs/2503.10945)
### Authors
Juan Felipe Gomez,Bogdan Kulynych,Georgios Kaissis,Flavio P. Calmon,Jamie Hayes,Borja Balle,Antti Honkela
### Background
当前用于报告机器学习算法（如DP-SGD）的差分隐私（DP）保护水平的实践提供了不完整且可能误导的隐私保证图景。例如，仅提供单个$(?varepsilon,?delta)$值时，标准分析显示可能存在针对训练数据记录的高精度推理攻击，但实际上这类高精度攻击可能不存在。因此，作者认为，使用非渐近高斯差分隐私（GDP）作为主要手段来传达机器学习中的DP保证，可以避免这些潜在的缺点。
### Innovation
文章通过结合数据保护领域的两个最新发展：(i) 能够计算DP-SGD到任意精度的隐私概貌和$f$-DP曲线的开源数值核算工具，(ii) 一个决策论度量标准，展示了如何使用数值核算工具提供非渐近GDP边界，并证明GDP可以几乎无误差地捕捉DP-SGD及其相关算法的整个隐私概貌。同时，文章调查了最先进的DP大尺度图像分类和US人口普查中的TopDown算法的隐私轮廓，证实GDP在所有情况下都与其实测值高度吻合，从而展示了GDP的价值。
### Conclusion
文章最后讨论了GDP方法的优势和不足，并探讨了哪些其他隐私机制可以从GDP中受益。
## 995. `cs.LG` - 使用影响函数解读间接上下文学习 [PDF](https://arxiv.org/pdf/2501.01473), [HTML](https://arxiv.org/abs/2501.01473)
### Authors
Hadi Askari,Shivanshu Gupta,Terry Tong,Fei Wang,Anshuman Chhabra,Muhao Chen
### Background
本文介绍了一种通用的上下文学习(Generalized In-Context Learning, ICL)新范式，称为间接上下文学习(Indirect ICL)。这种方法主要探索适应两组不同现实场景的演示选择策略：混合任务场景和有噪声的上下文学习场景。在混合任务场景下，演示是从28个不同的任务中抽取的，包括MMLU、BigBench、StrategyQA和CommonsenseQA等，尝试评估影响函数(Influence Functions, IFs)在指示符中的有效性。在有噪声的上下文学习场景下，考虑了演示可能被误标或具有对抗噪声的情况。通过实验验证了影响函数在传统ICL指标中更新的选择器中的有效性，特别是在有噪声的GLUE基准测试上，通过重新加权提升准确性。此外，还研究了影响函数在对抗设置下的应用，展示了其用于后门攻击缓解的任务适应性。这项工作提供了一种新的框架，超越了传统ICL方法，强调了影响函数在间接上下文学习中的作用和价值。
### Innovation
本文提出了一种新的上下文学习范式——间接上下文学习（Indirect ICL），它特别适用于混合任务和有噪声的上下文学习场景。提出了使用影响函数（IFs）作为演示选择工具，特别是结合BertScore-Recall (BSR)和其他传统的相似度选择器（如余弦相似度）。结果显示，这种综合方法在3-shot和5-shot设置中的平均绝对准确率提高了0.37%和1.45%，对于对抗设置，使用IFs进行任务无关的演示选择能够显著降低后门攻击成功率，减少了32.89%。因此，这项工作提供了一种新的框架，超越了传统的ICL方法，强调了影响函数在间接上下文学习中的重要性。
### Conclusion
间接上下文学习利用影响函数提供了一种新的、更适应现实场景的方法，并验证了这些方法在同济史、噪音环境下的应用效果，以及对抗场景中的泛化能力。这些发现为进一步改进和应用上下文学习技术奠定了坚实基础，为高效率且准确的任务选择以及对抗防御提供了新的可能路径。
## 996. `cs.LG` - 高能物理中的可学习切流方法 [PDF](https://arxiv.org/pdf/2503.22498), [HTML](https://arxiv.org/abs/2503.22498)
### Authors
Jing Li,Hao Sun
### Background
在高能物理任务中，神经网络因其强大的能力而兴起，但其不透明的训练过程使其成为一个黑盒子。相比之下，传统的切流方法因其简单性和可解释性而受到青睐，但是这种方法需要大量的人工调优来确定最优的切分边界。本文旨在融合这两种方法的优点，提出了一种名为Learnable Cut Flow (LCF)的方法，该方法通过一个神经网络将传统的切选过程转化为完全可微的、数据驱动的过程。
### Innovation
LCF采用两种切分策略：并行策略和序列策略，灵活地确定最优边界。LCF引入了一种可学习的重要性度量，该度量量化了特征的重要性，并相应地调整它们对损失的贡献，提供了基于模型的见解，不同于任意的度量。为了确保可微性，LCF使用修改后的损失函数替代硬切分，保留了训练过程中的数据形状。LCF在六个不同的模拟数据集和一个实际的二轻子与QCD数据集上进行了测试，实验结果表明了其有效性。
### Conclusion
实验结果表明，LCF1. 准确地在并行和序列策略下学习了典型的特征分布的切分边界，2. 给出了具有最小重叠的高度区分性特征更高的重要性，3. 能够处理冗余或相关特征，4. 在实际应用场景中表现有效。LCF在二轻子数据集中使用所有可观测量时，初始表现不如增强决策树和多层感知机。LCF在整个训练过程中提供了关于切分过程和特征重要性的行动见解，填补了传统切流方法与现代黑盒神经网络之间的差距。
## 997. `cs.LG` - 如何借助多模态方法提升时间序列分析？综述与展望 [PDF](https://arxiv.org/pdf/2503.11835), [HTML](https://arxiv.org/abs/2503.11835)
### Authors
Haoxin Liu,Harshavardhan Kamarthi,Zhiyuan Zhao,Shangqing Xu,Shiyu Wang,Qingsong Wen,Tom Hartvigsen,Fei Wang,B. Aditya Prakash
### Background
时间序列分析（TSA）在数据挖掘领域是一个长期研究的主题，并具有广泛的实际意义。与语言和视觉等“丰富”的模态相比，这些模态已经经历了爆炸性的增长并且紧密相连，而时间序列模态相对较少被探索和孤立。近年来，许多时间序列分析的工作形成了一个新的研究领域，即多模态时间序列分析（MM4TSA），这些研究工作通常旨在探讨多模态如何提升时间序列分析的效果。已有综述性文章，但本调研首次全面回顾并深入展望了这一新兴领域的研究
### Innovation
首次对多模态时间序列分析领域进行深度综述，系统讨论了三个好处：（1）利用其他模态的基础模型来提升时间序列分析的效率；（2）通过多模态扩展来增强时间序列分析；（3）通过跨模态交互来实现更先进的时间序列分析。进一步按照引入的模态类型（文本、图像、音频、表格和其他）对相关工作进行了分类。指出未来研究的机会，包括重用模态选择、异质模态组合以及未见任务泛化等方面
### Conclusion
文章通过GitHub发布了最新的相关文献库，以提供对这一新兴领域的支持与资源。
## 998. `cs.LG` - 基于分数的生成模型中的最优去噪：数据正则性的作用 [PDF](https://arxiv.org/pdf/2503.12966), [HTML](https://arxiv.org/abs/2503.12966)
### Authors
Eliot Beyler(SIERRA),Francis Bach(SIERRA)
### Background
分数生成模型通过去噪被加了高斯噪声的分布，实现了一流的采样性能。本文的研究 focusto 经过单一确定性去噪步骤的情况，并比较了针对二次损失函数的最优去噪器“全去噪”和 Hyvärinen(2024) 引入的“半去噪”。表明在不同假设下，但凡密度数据，两种去噪方法的性能表现有着明显的不同。
### Innovation
本文证明了对于足够正则的密度，半去噪优于全去噪，而全去噪则更适合孤立密度，比如狄拉克混合分布或低维子空间支持的密度。同时，证明了全去噪在标准线性流形假设下可以缓解维度诅咒，根据不同假设，提出了更精细的性能评估方法，提升了去噪方法的选择灵活性和适用范围。
### Conclusion
研究揭示了在不同数据正则条件下，最优去噪策略的变化，为分数生成模型中去噪策略的选择提供了依据，特别在高维数据情况下，这种选择尤为重要。
## 999. `cs.LG` - 迭代残差校正网络在Ku波段SIW共振结构AI驱动反向设计中的应用 [PDF](https://arxiv.org/pdf/2505.06936), [HTML](https://arxiv.org/abs/2505.06936)
### Authors
Mohammad Mashayekhi,Kamran Salehian,Abbas Ozgoli,Saeed Abdollahi,Abdolali Abdipour,Ahmed A. Kishk
### Background
设计具有紧密间距和广泛分离共振的高效率片上波导（SIW）滤波器具有挑战性。因此，需要一种减少依赖耗时电磁（EM）模拟的方法。本研究旨在通过开发并验证基于深度学习的框架，实现多模式SIW滤波器的反向设计，旨在通过最小化仿真成本来实现准确的反向设计.
### Innovation
研究提出了一种由前馈反问题模型（FIM）、混合反向-正向残差细化网络（HiFR²-Net）和迭代残差校正网络（IRC-Net）组成的三阶段深度学习框架。IRC-Net在五次残差迭代校正中表现出最佳性能，实现了系统误差的逐步减少。实验结果显示均方误差（MSE）从0.00191降低到0.00146，平均绝对误差（MAE）从0.0262降低到0.0209，表明性能的提高和收敛的优化。该框架能够实现复杂微波滤波器的可靠、准确和通用的反向设计，适用于微波和毫米波技术中的其他高频率组件，以促进高级滤波器设计的快速原型制作.
### Conclusion
提出的框架证明了能够实现复杂微波滤波器的可靠、准确和通用的反向设计，具有最小的模拟成本。该方法有望促进高级滤波器设计的快速原型制作，并可扩展应用于微波和毫米波技术中的其他高频率组件.
## 1000. `cs.LG` - 当生成式AI模型通过递归训练各自输出的内容会发生什么？ [PDF](https://arxiv.org/pdf/2505.21677), [HTML](https://arxiv.org/abs/2505.21677)
### Authors
Hung Anh Vu,Galen Reeves,Emily Wenger
### Background
生成式AI（genAI）模型通常使用互联网作为训练数据源，但随着AI生成内容的增多，这种数据源变得更加复杂。此前的研究主要集中于模型是否会在训练过程中使用自身生成的数据，但很少有研究探讨模型如何处理其他模型生成的内容。鉴于社会对生成式AI工具的依赖在增强，理解模型间通过数据交互的影响至关重要。
### Innovation
本文提供了关于模型间通过数据交换相互训练的实际证据，并建立了理论模型来描述这个交互训练过程。通过实验验证了理论模型，发现了数据交换既能使模型接触到原始数据中未涵盖的新概念，也可能导致模型在共同任务上的性能趋同。
### Conclusion
数据交换可以在一定程度上为模型提供新颖的概念，但也可能使模型在共享任务上的表现趋于同质化。
## 1001. `cs.LG` - 使用自适应鲁棒优化和渐近不确定性表征增强电力系统韧性 [PDF](https://arxiv.org/pdf/2505.11627), [HTML](https://arxiv.org/abs/2505.11627)
### Authors
Shuyi Chen,Shixiang Zhu,Ramteen Sioshansi
### Background
极端天气对电力系统造成了压力，暴露了反应式响应的局限性，促使需要采取主动抗灾规划来应对。当前增强电力系统韧性的方法大多采用简化不确定性的模型并且将主动和反应式决策分开进行。现有方法存在简化不确定性和分隔决策的不足，本研究旨在提供一种新的三层次优化模型，以整合主动行为、对抗性干扰和反应式响应，解决这一问题。
### Innovation
提出了将主动行为、对抗性干扰和反应式响应整合为一体的创新三层次优化模型。模型使用可信预测构建无分布系统中断不确定性集，并提供覆盖保证。通过运用对偶理论获取二层次重述形式，并采用Bender分解策略求解三层次问题。实验结果表明，该方法优于传统的鲁棒和两阶段方法。
### Conclusion
三层次优化模型通过利用主动行为、对抗性干扰和反应式响应，为电力系统韧性规划提供了新的解决方案，特别是通过可信预测构建不确定集，展示了比传统鲁棒性和两阶段方法更好的性能。
## 1002. `cs.LG` - Time-o1：时间序列预测需要转换标签对齐 [PDF](https://arxiv.org/pdf/2505.17847), [HTML](https://arxiv.org/abs/2505.17847)
### Authors
Hao Wang,Licheng Pan,Zhichao Chen,Xu Chen,Qingyang Dai,Lei Wang,Haoxuan Li,Zhouchen Lin
### Background
时间序列预测模型的训练面临独特挑战，现有方法主要利用时间均方误差作为学习目标，但存在两个关键问题：(1)标签自相关性导致标签序列似然性偏差；(2)任务数量过多，随预测时间跨度增加而复杂化优化。这使得传统方法的效果受限，难以提供高效预测性能。
### Innovation
本文提出了Time-o1，一种针对时间序列预测的变换增强学习目标。核心思想是将标签序列转换为去相关且具有鉴别意义的成分。模型被训练以对齐这些成分中最显著的部分，从而有效缓解标签自相关性并减少任务数量。实验表明，Time-o1在性能上达到了最先进的水平，并且兼容多种预测模型。
### Conclusion
广泛的实验展示了Time-o1的有效性和兼容性，证明了其在时间序列预测上的优越性能，并为未来的研究提供了新思路。
## 1003. `cs.LG` - 基于土壤湿度的指导性机器学习在干旱条件下县市级玉米产量预测中的应用 [PDF](https://arxiv.org/pdf/2503.16328), [HTML](https://arxiv.org/abs/2503.16328)
### Authors
Xiaoyu Wang,Yijia Xu,Jingyi Huang,Zhengwei Yang,Yanbo Huang,Rajat Bindlish,Zhou Zhang
### Background
遥感（RS）技术能够实现非接触式的广泛地面观测，成为作物产量预测的重要工具。传统过程模型难以整合大规模的RS数据，用户也难以理解作物生长机制。相比之下，虽然机器学习（ML）模型具有高预测准确性，但其缺乏解释性，被认为是“黑箱”模型。在此之前的研究中，尽管已有研究探索了机器学习与土壤湿度在玉米生长中的应用，但大多忽视了土壤湿度的作用或未将其嵌入模型。因此，本文提出了一种新的框架——基于知识指导的机器学习（KGML），它结合了过程模型和ML模型的优势，并特别加入了土壤湿度作为中间变量，强调其在作物生长中的关键作用。此外，还根据模型在干旱条件下可能高估的先验知识，设计了一个干旱感知损失函数，以在干旱影响区域惩罚预测产量。通过实验验证，KGML-SM模型在县市级玉米产量预测中优于其他传统ML模型，展示了干旱、土壤湿度和玉米产量之间的关系，并提供了对预测误差的可解释性，以指导未来模型优化。
### Innovation
本文通过提出KGML-SM框架结合过程模型和ML模型优势，并特别加入了土壤湿度作为中间变量，强调其在作物生长中的关键作用。同时，设计了干旱感知损失函数以在干旱影响区域惩罚预测产量。这种方法提高了模型针对干旱条件的预测准确性，并提供了对预测错误的可解释性。
### Conclusion
本文提出的KGML-SM模型在县市级玉米产量预测中表现出色，特别是在干旱条件下。通过分析干旱、土壤湿度和玉米产量的关系，展示了土壤湿度对预测的影响。此外，通过可视化预测误差的解析性，为未来模型优化提供了指导。
## 1004. `cs.LG` - 基于散度的S-矩形分布鲁棒强化学习的近最优样本复杂度 [PDF](https://arxiv.org/pdf/2505.12202), [HTML](https://arxiv.org/abs/2505.12202)
### Authors
Zhenghao Li,Shengbo Wang,Nian Si
### Background
近期，分布鲁棒强化学习（DR-RL）因其对训练与测试环境差异的处理原则性方法而受到广泛关注。尽管大多数现有的统计分析集中在基于SA-矩形的模型上，由于其算法的简易性和确定性策略的最 optimality（原文似乎有误，应为“optimality”），S-矩形模型更为精确地捕捉了真实世界应用中的分布差异，并经常产生更有效的鲁棒随机化策略。本文研究了基于散度的S-矩形DR-RL的经验值迭代算法，并建立了一个接近最优的样本复杂度近似量级为$tilde{O}(|text{S}||text{A}|(1-text{γ})^{-4}text{ε}^{-2})$，其中ε是目标精度，$|text{S}|$和$|text{A}|$是状态空间和动作空间的基数，γ是折扣因子。这也是首次在S-矩形模型中实现对$|text{S}|$ ，$|text{A}|$和ε的最优依赖关系的样本复杂度结果。
### Innovation
提出了基于散度的S-矩形DR-RL的经验值迭代算法，并建立了接近最优的样本复杂度，同时实现了对$|text{S}|$，$|text{A}|$和ε的最优依赖性。这在S-矩形模型中是首次实现。此外，通过数值实验验证了其理论依赖关系，展示了所提算法的快速学习性能，特别是在鲁棒库存控制问题上的应用。
### Conclusion
本文探讨了基于散度的S-矩形DR-RL的经验值迭代算法，建立了样本复杂度的近最优结果，并通过实验验证了这一理论依赖关系，证明了算法在鲁棒库存控制等实际应用中的快速学习性能。
## 1005. `cs.LG` - PiCa: 使用列空间投影的参数高效微调 [PDF](https://arxiv.org/pdf/2505.20211), [HTML](https://arxiv.org/abs/2505.20211)
### Authors
Junseo Hwang,Wonguk Cho,Taesup Kim
### Background
大型基础模型的微调对于构建针对特定任务和领域的专家模型至关重要，但全面更新数十亿个参数在计算上是不可行的。因此，减少可训练参数的数量对降低培训成本以及在部署期间减少存储、缓存和提供方面的开销是至关重要的。尽管此前的一些工作（如指导向量的微调）表明利用预训练权重的几何形态可以显著提高参数效率，但它们缺乏理论基础的支持。因此，迫切需要一种理论上有保证的参数高效微调方法。
### Innovation
本文提出了一种新的参数高效微调方法——PiCa（使用列空间投影的参数高效微调）。PiCa通过将梯度投影到预训练权重的主要列空间中提供有效的归纳偏置，并通过一种新提出的权重共享策略进一步增强参数效率。在各种自然语言处理和视觉任务中，PiCa 在可比较或更小的参数预算下始终优于最先进的基线方法，证明了其理论与实践的有效性。
### Conclusion
本文介绍了 PiCa，一种新的理论上得到良好支持的参数高效微调方法。PiCa 通过将梯度投影到预训练权重的主要列空间中提供有效的归纳偏置，并通过一种新提出的权重共享策略进一步增强参数效率。PiCa 在多个任务上证明了理论上的严谨性和实际的有效性，跨不同 NLP 和视觉任务，PiCa 持续优于最先进的基线方法，下付出较小或可比的参数预算。
## 1006. `cs.LG` - A Few Large Shifts: 层内不一致性基础上的最小开销恶意样本检测 [PDF](https://arxiv.org/pdf/2505.12586), [HTML](https://arxiv.org/abs/2505.12586)
### Authors
Sanggeon Yun,Ryozo Masukawa,Hyunwoo Oh,Nathaniel D. Bastian,Mohsen Imani
### Background
深度神经网络（DNNs）极易受到对抗样本的影响——这些微小且难以察觉的扰动能够导致正确的预测结果出错。尽管基于检测的防御手段在对抗训练之外提供了一种实际的选择，但许多现有的方法依赖于外部模型、复杂的架构或对抗数据，限制了它们的效率和普适性。
### Innovation
本研究提出了一种轻量级且插件式的检测框架，该框架利用目标模型内部逐层不一致性，仅需利用良性数据进行校准。此方法基于“少数层的大扰动”假设，即对抗扰动会导致少数几层内的局部违反逐层Lipschitz连续性。研究提出了两种互补策略——恢复测试（RT）和逻辑层测试（LT），以实测这些违例并揭露由对手引起的内部扰动。
### Conclusion
在CIFAR-10、CIFAR-100和ImageNet数据集上，该方法在标准和自适应威胁模型下均达到了最先进的检测性能，且几乎无额外的计算开销。系统级分析还为选择检测阈值提供了一种实际方法，并确保了准确性的下限。
## 1007. `cs.LG` - 基于大规模语言模型的动态文本捆绑对带有文本属性的图的零样本推理 [PDF](https://arxiv.org/pdf/2505.17599), [HTML](https://arxiv.org/abs/2505.17599)
### Authors
Yusheng Zhao,Qixin Zhang,Xiao Luo,Weizhi Zhang,Zhiping Xiao,Wei Ju,Philip S. Yu,Ming Zhang
### Background
大规模语言模型（LLMs）在零样本学习问题中表现出强大的泛化能力。最近，LLMs被应用到文本属性图（TAGs）中，但面对着图结构信息有限和反应不可靠两大挑战。LLMs难以处理孤立于图拓扑结构的文本属性，并且由于信息不足和LLMs固有的弱点（如幻觉），它们还产生不可靠的预测。
### Innovation
提出了一种名为Dynamic Text Bundling Supervision (DENSE)的新方法，该方法通过使用捆绑的文本查询LLMs来获取捆绑级别的标签，并使用这些标签监督图神经网络。具体而言，该方法通过对节点及其附近文本的捆绑和查询，以获取每个捆绑的标签，然后利用这些标签来监督图神经网络的优化过程，并进一步细化捆绑以排除噪声项。
### Conclusion
广泛的数据集实验验证了所提出方法的有效性。
## 1008. `cs.LG` - 当推理遇到压缩：大型推理模型压缩效果的理解 [PDF](https://arxiv.org/pdf/2504.02010), [HTML](https://arxiv.org/abs/2504.02010)
### Authors
Nan Zhang,Eugene Kwek,Yusen Zhang,Ngoc-Hieu Nguyen,Prasenjit Mitra,Rui Zhang
### Background
现有研究表明，量化、蒸馏和剪枝等压缩方法可以提高大型推理模型（LRMs）的计算效率。然而，这些研究要么未能充分比较这三种压缩方法在LRMs上的效果，要么缺乏深入的解释分析。本文通过性能基准测试和机制性解释，探讨压缩对LRMs推理能力的影响。
### Innovation
为了揭示压缩对推理性能的影响，本文通过基准测试量化、蒸馏和剪枝的DeepSeek-R1模型在四个推理数据集上的性能，并采用差均值和特征图技术，专注于压缩的LRM中的每一个线性组件中的激活，以解释细粒度的因果关系，明确哪些权重对于推理最重要。
### Conclusion
本文发现动态量化2.51位的R1接近全精度性能。通过实验证明，主要得出以下三个结论：1）权重计数比推理本身对知识的存储影响更大，突显了剪枝和蒸馏的风险；2）经过蒸馏的LRMs最后层的MLP上投影是最重要的组件之一，提供了一种定位关键权重的新视角；3）当前的量化方法过度压缩了最后一层模块和MLP门控投影，因此只需保护过度压缩中2%的权重即可提高平均准确性6.57%，远超当前最先进的方法。
## 1009. `cs.LG` - 通过可学习增强发现对称性学习对称模型 [PDF](https://arxiv.org/pdf/2506.03914), [HTML](https://arxiv.org/abs/2506.03914)
### Authors
Eduardo Santos-Escriche,Stefanie Jegelka
### Background
近期，学术界出现了一种趋势，倾向于从几何域数据中设计受约束的对称架构，转而（1）修改训练协议，例如使用特定的损失和数据增强（软对称性），或（2）忽略对称性，仅隐式地推断它。然而，这两种选择都有局限性，如软对称性仍然需要关于潜在对称性的先验知识，而从数据中隐式学习对称性缺乏解释性。
### Innovation
本文提出了一种端到端的方法SEMoLA，该方法联合（1）通过可学习的数据增强发现先前未知的对称性，并将这些对称性（2）应用于任意不受约束的模型中编码相应的近似对称性。因此，该方法使得可以学习无需对称性先验知识、具备解释性且对数据分布变化具有鲁棒性的对称模型。
### Conclusion
在实验中，我们展示了SEMoLA能够稳健地发现相关对称性并实现各种数据集的高预测性能，涵盖多种数据模态和潜在对称性群组。
## 1010. `cs.LG` - 超越经验的学习：基于蓄水池计算的未观察状态空间通用性 [PDF](https://arxiv.org/pdf/2506.05292), [HTML](https://arxiv.org/abs/2506.05292)
### Authors
Declan A. Norton,Yuanzhao Zhang,Michelle Girvan
### Background
机器学习技术为仅从观测数据建模动力系统提供了有效的方法。然而，缺乏显式的结构性先验（内置的关于潜在动力学的假设），这些技术通常难以泛化到训练数据中未充分代表的动力学方面。
### Innovation
本文展示了在缺乏显式结构性先验的情况下，蓄水池计算框架能够泛化到未探索的状态空间。通过描述一种多轨迹训练方案，使得蓄水池计算机支持跨多个不连续的时间序列进行训练，从而有效利用现有的训练数据。在多稳定动力系统的应用中，结果表明，蓄水池计算机可以通过捕捉未观察到的状态驻留区域的动力学行为来实现未经验领域的泛化。
### Conclusion
该研究提出了一种多轨迹训练方案，使得蓄水池计算机能够在未探索的状态空间中泛化，这在训练数据限于单一状态驻留区域的情况下也能实现对完全不同状态驻留区域的动力学行为的捕捉和预测。
## 1011. `cs.LG` - 高扩散效率增强的DACER算法 [PDF](https://arxiv.org/pdf/2505.23426), [HTML](https://arxiv.org/abs/2505.23426)
### Authors
Yinuo Wang,Likun Wang,Mining Tan,Wenjun Zou,Xujie Song,Wenxuan Wang,Tong Liu,Guojian Zhan,Tianze Zhu,Shiqi Liu,Zeyu He,Feihong Zhang,Jingliang Duan,Shengbo Eben Li
### Background
扩散模型由于其表达能力，在离线强化学习（offline RL）和模仿学习中展现出巨大潜力。DACER通过逆向扩散过程作为策略逼近器，扩展了其在在线强化学习（online RL）中的应用，并取得了最先进的性能。然而，它仍然受到一个核心权衡的影响：更多的扩散步骤可以保证高性能但降低效率，而较少的步骤则会牺牲性能。这仍然是在实时在线强化学习中部署扩散策略的主要障碍
### Innovation
该研究提出了DACERv2，它采用基于动作的Q-梯度场目标作为辅助优化目标，引导每一步扩散过程中的去噪过程，引入中间的监督信号以增强单步扩散的效率。另外，研究者引入了一种时间加权机制，允许模型在早期阶段有效消除大尺度噪声，并在后期阶段细化输出。实验结果表明，在大多数复杂的控制环境中，与经典和基于扩散的在线RL算法相比，使用仅五步扩散的DACERv2表现出更高的性能，并且在多模态任务中表现出更大的多样性
### Conclusion
在OpenAI Gym基准和多模态任务中，与经典的和基于扩散的在线RL算法相比，DACERv2在大多数复杂的控制环境中仅使用五步扩散表现出更高的性能。还展示了比基线方法更大的多模态能力
## 1012. `cs.LG` - 自适应批次样例调度以直接优化偏好 [PDF](https://arxiv.org/pdf/2506.17252), [HTML](https://arxiv.org/abs/2506.17252)
### Authors
Zixuan Huang,Yikun Ban,Lean Fu,Xiaojie Li,Zhongxiang Dai,Jianxin Li,Deqing Wang
### Background
直接偏好优化（DPO）已经成为一种有效的方法，用于使大型语言模型（LLMs）与人类偏好对齐。然而，DPO的表现高度依赖于底层的人类偏好数据质量。为了解决这一瓶颈，先前的工作探索了各种数据选择策略，但这些方法往往忽略了语言模型在优化过程中的状态变化的影响。
### Innovation
本文提出了一种新的问题：DPO的采样调度，旨在在偏好优化过程中根据模型的批次状态动态和自适应地调度训练样本。为此，作者提出了SamS算法，该算法根据LLM的学习反馈在每个训练批次中自适应地选择样本，以最大化潜在的泛化性能。此外，仅通过集成SamS算法，而无需修改核心的DPO算法，就能够在多个任务上显著提高性能，同时将额外的计算开销降到最低。
### Conclusion
本文指出了一条改进LLM对齐的新方向，即通过批次级别样本选择来提高性能，并且具有扩展到RLHF和其他监督学习范式的潜力。
## 1013. `cs.LG` - Differential Information Distribution: 一种关于直接偏好优化的贝叶斯视角 [PDF](https://arxiv.org/pdf/2505.23761), [HTML](https://arxiv.org/abs/2505.23761)
### Authors
Yunjae Won,Hyunji Lee,Hyeonbin Hwang,Minjoon Seo
### Background
直接偏好优化（DPO）已经被广泛应用于通过监督方式使语言模型与人类偏好保持一致。然而，仍有一些关键问题未被解决，如为什么DPO使用对数-差异奖励、偏好数据集的统计结构如何影响其培训动态以及这些动态如何影响下游能力等问题。研究人员试图从贝叶斯的角度对这些疑问进行探讨，认为偏好优化的目标在于学习需要改变参考策略以至目标策略的差异信息。
### Innovation
引入了差异信息分布（DID），定义为能够更新策略所需的贝叶斯证据样本的分布。通过视偏好优化为DID，提出了三个互补的见解：第一，发现DPO的对数-差异奖励只有在偏好数据编码了更新参考策略至目标策略的差异信息时才能被合理解释；第二，讨论了常见DPO的训练动态，如对数似然和策略探索的变化，是DID幂律关系的结果；第三，使用DID的熵分析训练动态对下游性能的影响，得到了提高开放指令跟随性和知识密集型问答任务的方法。
### Conclusion
研究结果表明，DPO的设计奖励、培训动态及其下游能力都自然地成为了学习差异信息的结果，为基于偏好对齐提供了一种有原则的理论基础和实用指导。
## 1014. `cs.LG` - 使用子网络数据并行的模型并行化 [PDF](https://arxiv.org/pdf/2507.09029), [HTML](https://arxiv.org/abs/2507.09029)
### Authors
Vaibhav Singh,Zafir Khalid,Edouard Oyallon,Eugene Belilovsky
### Background
大规模训练神经网络需要大量的内存资源，并常需要成本高昂的通信支持。
### Innovation
引入了一种名为子网络数据并行（SDP）的分布式训练框架，将模型分割成结构化的子网络，在各个节点上训练而不交换激活值。研究了两种互补的掩码机制：后向掩码仅在后向传播中应用稀疏性以保持无偏的梯度，前向掩码在前向传播中也移除参数，从而带来更强的效率提升和额外的正则化效果。进一步探讨了在不同类型网络（CNN和transformer）中，按神经元级别和按模块级别的两种子网络构建策略。
### Conclusion
在不同场景下的实验表明，SDP可以减少30%-75%的每设备内存使用，同时保持或改进性能。在FLOP匹配的场景中，前向掩码有时能达到更好的性能。
## 1015. `cs.LG` - PlaceFM: 使用大规模兴趣点数据的无需训练的地理空间基础模型 [PDF](https://arxiv.org/pdf/2507.02921), [HTML](https://arxiv.org/abs/2507.02921)
### Authors
Mohammad Hashemi,Hossein Amiri,Andreas Zufle
### Background
随着来自多种来源的地理空间数据的快速增长和不断更新，以城市表征学习为基础的地理空间基础模型预训练已成为促进数据驱动的城市规划的关键研究方向。有效的地理空间智能系统的基础是空间结构；然而，现有的基础模型往往缺乏处理地方（包含多个空间细致程度的、多个空间和语义相关的兴趣点组成的富语境区域）的能力。
### Innovation
提出了一种名为PlaceFM的地理性基础模型，通过无监督聚类方法捕捉地方表示。PlaceFM可以从美国Foursquare数据构建的兴趣点图中总结出通用的区域嵌入，并自动标识出地方兴趣点。这些嵌入可以直接集成到地理定位数据管道中，支持各种城市下游任务。无需成本高昂的预训练，PlaceFM提供了一种在大规模POI图中生成区域级表示的可扩展和高效的方法。
### Conclusion
广泛实验表明，PlaceFM不仅在大多数基于图的地理空间基础模型中表现出色，还在两大真实世界的预测任务（ZIP码级别的人口密度和房价）中实现了高达100倍的速度提升。
## 1016. `cs.LG` - 学习为训练数据归因加权参数 [PDF](https://arxiv.org/pdf/2506.05647), [HTML](https://arxiv.org/abs/2506.05647)
### Authors
Shuangqi Li,Hieu Le,Jingyi Xu,Mathieu Salzmann
### Background
本研究旨在通过梯度基数据归因方法来识别对给定输出影响最大的训练示例。现有方法要么将网络参数视为均一的，要么依赖于 Hess 法线近似获得的隐式加权，这些方法并未充分建模网络参数的功能异质性。鉴于此问题，本研究提出了直接从数据中学习参数重要性加权的方法，无需标注标签，从而能够跨多样任务提升归因准确性，包括图像分类、语言建模和扩散模型，并允许对如主题和风格等概念进行精细归因.
### Innovation
提出了一种直接从数据中学习参数重要性加权的方法，无需标注标签，并且能够在图像分类、语言建模和扩散等多样任务中提高归因准确性和实现细粒度的归因，解决了传统方法未充分建模网络参数功能异质性的不足.
### Conclusion
通过直接从数据中学习参数重要性加权，本研究在跨多个任务的训练数据归因中提高了准确性，并且能够对如主题和风格等概念进行精细归因.
## 1017. `cs.LG` - 局部森林火灾风险预测：基于部门的决策支持方法 [PDF](https://arxiv.org/pdf/2506.04254), [HTML](https://arxiv.org/abs/2506.04254)
### Authors
Nicolas Caron,Christophe Guyeux,Hassan Noura,Benjamin Aynes
### Background
森林火灾预测涉及估算特定区域内火灾点火或相关风险水平的可能性。随着气候变化加剧了火灾行为和频率，准确的预测已经成为人工智能研究中最为紧迫的挑战之一。传统上，文献中将火灾点火问题作为二元分类任务处理，但这简化了问题，特别是在消防员等终端用户的角度。法国等国的灭火单位根据部门组织，每个部门具有不同的地形、气候条件及历史上的火灾事件经验。因此，火灾风险应根据当地条件建模，不应假设所有地区风险具有统一性。
### Innovation
本论文提出了一种新的方法，针对部门环境量身定制火灾风险评估，提供更为具体和操作性的区域预测。在此基础上，本文提出了全国规模的基于最新AI模型的法国防火风险基准测试，使用相对未开发的数据集。
### Conclusion
最后，总结了一些重要的未来研究方向，这些方向应被考虑。有关补充材料可在GitHub上获得。
## 1018. `cs.LG` - MS-DFTVNet:基于多尺度可变形卷积的长期时间序列预测方法 [PDF](https://arxiv.org/pdf/2506.17253), [HTML](https://arxiv.org/abs/2506.17253)
### Authors
Chenghan Li,Mingchen Li,Yipu Liao,Ruisheng Diao
### Background
长期时间序列预测主要依赖于Transformer和MLP模型，而卷积网络在该领域的潜力尚未得到充分发掘。现有的研究忽视了卷积网络在捕捉时间序列中的长期依赖关系和多时期块之间的交互作用的能力。
### Innovation
提出了一种新的多尺度时间序列重塑模块，有效地捕捉了跨时期块交互和变量依赖关系。在此基础上，开发了MS-DFTVNet，这是针对长期预测的多尺度3D可变形卷积框架。同时引入了一种上下文感知的动态可变形卷积机制，以更好地捕捉复杂的时间模式。实验验证了MS-DFTVNet能够显著优于强劲的基线，并在六个公共数据集上平均提高了约7.5%，达到了最新的研究成果水平。
### Conclusion
研究表明MS-DFTVNet在长周期时间序列预测领域取得了显著的性能提升，确立了新的行业标准。
## 1019. `cs.LG` - 学习与任务无关的动机来捕捉动物行为的连续性 [PDF](https://arxiv.org/pdf/2506.15190), [HTML](https://arxiv.org/abs/2506.15190)
### Authors
Jiyi Wang,Jingyang Ke,Bo Dai,Anqi Wu
### Background
动物通过重组有限的核心运动动机来满足多样的任务需求，但现有的行为分割方法过于简化这一过程，通过强加离散的单元，在限制性的生成假设下进行。为了更好地捕捉行为生成的连续结构，论文引入了基于动机的连续动态（MCD）发现框架，该框架通过对行为转换结构的表示来揭示可解释的动机集作为潜在基函数，并将行为动态建模为这些基函数的连续变化混合。
### Innovation
通过揭示可解释的动机集作为潜在基函数并通过这些基函数来连续变化混合表示行为动态，该框架可以识别可重复使用的动机组件，捕捉连续构成性动态，并产生传统离散分割模型无法生成的现实路径。这种方法通过提供复杂动物行为如何从基本运动动机的动态组合中涌现的生成性解释，促进了自然行为的定量研究。
### Conclusion
该方法在多任务迷宫、迷宫导航任务和自由运动动物行为中得到验证，能够识别可重复使用的动机组件，捕捉连续构成性动态，并生成现实路径，进一步推进了对自然行为的定量研究。
## 1020. `cs.LG` - 适度过程中的自然驾驶中的自适应、情境感知风险检测 [PDF](https://arxiv.org/pdf/2508.00888), [HTML](https://arxiv.org/abs/2508.00888)
### Authors
Amir Hossein Kalantari,Eleonora Papadimitriou,Arkady Zgonnikov,Amir Pooyan Afghari
### Background
可靠的基于驾驶员行为数据的风险识别是实时安全反馈、车队风险管理以及辅助驾驶系统评估的基础。虽然自然驾驶研究为提供真实的驾驶员行为数据奠定了基础，但现有的基于此类数据的风险识别框架存在两大根本问题：（1）它们依赖预定义的时间窗口和固定的阈值来区分危险和正常驾驶行为；（2）假定行为在司机之间和时间上是固定的，忽略了异质性和时间漂移问题。这些问题可能导致警报的时间误差和校准错误、缺乏新司机/路线/条件的推广性以及较高的误报率和漏报率，从而削弱驾驶员的信任并降低安全干预的效果。
### Innovation
提出了一种统一的情境感知框架，该框架通过滚动窗口、联合优化、动态校准和模型融合，针对带有时间戳的运动学数据进行自我适应。该框架使用两个安全性指标（加权速度空隙和剧烈驾驶事件）和三种模型（随机森林、XGBoost和深度神经网络）进行测试。加权速度空隙提供了比剧烈事件更多的稳定性和情境相关性分类。XGBoost 在变化的阈值下保持了一致的性能，而深度神经网络在较低的阈值下获得了更高的召回率，但试验之间具有更大的变化性。集成将多个模型的信号聚合为单一的风险决定，平衡了对危险行为的反应性和对误报的控制。
### Conclusion
总体而言，该框架展示了自适应、情境感知风险检测的潜力，可以增强实时安全反馈，支持智能运输系统中的驾驶员导向干预措施。
## 1021. `cs.LG` - 最优数据混合的缩放定律 [PDF](https://arxiv.org/pdf/2507.09404), [HTML](https://arxiv.org/abs/2507.09404)
### Authors
Mustafa Shukor,Louis Bethune,Dan Busbridge,David Grangier,Enrico Fini,Alaaeldin El-Nouby,Pierre Ablin
### Background
大型基础模型通常基于多个领域的数据进行训练，数据混合的组成（每个领域数据的比例）对模型性能至关重要。传统的数据混合选择方法依赖于试验和错误，这种方法不适用于大规模预训练场景。因此，提出了一种系统的方法来确定任何目标领域的最优数据混合比例，利用缩放定律。这种方法能够预测训练大小为N的模型，在D个标记和特定领域权重向量h下的损失情况，并通过大规模实验验证了这些缩放定律的有效性和通用性，同时也展示了其在不同规模和领域权重下的预测能力。该方法允许在给定的训练预算（N, D）下计算出任何目标领域的最优领域权重，为寻找一种替代成本高昂的试验性方法提供了理论依据。
### Innovation
提出了一种系统的方法来确定任何目标领域的最优数据混合比例，利用缩放定律预测模型的性能。这种方法的创新点在于能够精确预测大规模预训练模型在不同训练预算和领域权重下的性能，从而替代了传统的试验和错误方法，提供了一种有效的、低成本的优化数据混合的选择方案。
### Conclusion
该方法通过对大规模预训练实验验证了缩放定律的普遍性和预测性，展示了其在大规模语言模型（LLM）、原生多模态模型（NMM）和大型视觉模型（LVM）预训练中的适用性，并能跨规模和领域权重进行性能估计，为任何给定训练预算下的最优领域权重选择提供了理论指导。
## 1022. `cs.LG` - 从模拟器学习：模拟驱动学习的理论 [PDF](https://arxiv.org/pdf/2509.18990), [HTML](https://arxiv.org/abs/2509.18990)
### Authors
Carson Dudley,Marisa Eisenberg
### Background
SGNNs是一种完全基于从机理模拟生成的合成数据训练的预测模型。这些模型在真实世界标签有限或未观察到的领域中实现了最先进的性能，但缺乏理论支持。
### Innovation
（1）将SGNNs置于统一的统计框架之下，解释它们作为仿真驱动先验下近似贝叶斯预测器的行为。（2）通过经典的结果阐明仿真与现实之间的差距对性能的影响。（3）提出SGNN特有的结果：未观察到的科学参数可通过模拟学习的条件，以及一种基于仿真溯源的方法，可提供预测的机理解释，并保证后一致。
### Conclusion
实验证明了理论预测的有效性。SGNNs能够恢复潜在参数，具有鲁棒性，且在模型选择任务中超越了经典工具（AIC）。这些结果已经建立起SGNNs作为在数据受限条件下进行科学预测的原理性和实用性框架。
## 1023. `cs.LG` - DynaGuard: 用户定义策略的动态护栏模型 [PDF](https://arxiv.org/pdf/2509.02563), [HTML](https://arxiv.org/abs/2509.02563)
### Authors
Monte Hoover,Vatsal Baherwani,Neel Jain,Khalid Saifullah,Joseph Vincent,Chirag Jain,Melissa Kazemi Rad,C. Bayan Bruss,Ashwinee Panda,Tom Goldstein
### Background
监护模型用于监督和调节面向用户的聊天机器人的输出，确保遵循护栏并检测不良行为。标准的监护模型如LlamaGuard只能检测预定义的静态类别危害。然而，这些模型无法满足不同应用场景的需求，特别是当这些应用场景没有被标准监护模型覆盖时。因此，本研究提出了一种动态监护模型，它可以根据用户自定义的策略评估文本，从而适用于标准监护模型未能涵盖的应用领域，包括快速检测政策违反行为或用逻辑推理来解释和验证模型输出。动态监护模型可以准确检测静态危害类别，同时在识别自由格式政策违规时与前沿推理模型达到相似的准确性，但处理时间大大缩短。
### Innovation
本研究提出了一种动态监护模型（DynaGuard），它可以根据用户自定义的策略动态评估文本。与标准监护模型相比，DynaGuard不仅能够识别预定义的静态危害类别，还能够通过逻辑推理来检测自由格式的政策违规，其处理速度远超现有推理模型的同类任务。
### Conclusion
动态监护模型能够与静态监控模型在静态危害检测方面达到相同的准确度，同时在识别自由格式政策违规时表现出色。更重要的是，DynaGuard在处理时间上具有显著优势，这使得它在多种应用领域中更具灵活性和实用性。
## 1024. `cs.LG` - LoFT: Parameter-Efficient Fine-Tuning for Long-tailed Semi-Supervised Learning in Open-World Scenarios [PDF](https://arxiv.org/pdf/2509.09926), [HTML](https://arxiv.org/abs/2509.09926)
### Authors
Zhiyuan Huang,Jiahao Chen,Yurou Liu,Bing Su
### Background
长尾学习由于其在实际场景中的广泛应用而受到越来越多的关注。现有的方法中，长尾半监督学习（LTSSL）通过将大量未标记数据纳入不平衡标注数据集，成为一种有效的解决方案。然而，大多数先前的LTSSL方法都是从零开始训练模型，这往往会引发问题，如过度自信和伪标签质量低。
### Innovation
本文提出了一个新颖的框架：LoFT（针对开放世界场景的长尾半监督学习的参数高效细调方法），将半监督学习扩展到基础模型微调范式，通过细调基础模型生成更可靠的伪标签，从而有益于不平衡学习。此外，我们还研究了在开放世界条件下（未标记的样本可能包括离群值）的半监督学习，提出了LoFT-OW以提高分类能力。
### Conclusion
在多个基准上的实验结果显示，我们的方法在使用仅1%的未标记数据时，相比之前的其他方法，具有更优的性能。
## 1025. `cs.LG` - 基于时空融合变换器的稀疏GNSS数据电离层预测 [PDF](https://arxiv.org/pdf/2509.00631), [HTML](https://arxiv.org/abs/2509.00631)
### Authors
Giacomo Acciarini,Simone Mestici,Halil Kelebek,Linnea Wolniewicz,Michael Vergalla,Madhulika Guhathakurta,Umaa Rebbapragada,Bala Poduval,Atılım Güneş Baydin,Frank Soboczenski
### Background
电离层对全球导航卫星系统（GNSS）、卫星通信和低地球轨道（LEO）运营影响重大，但其变异性准确预测依然具有挑战性，因为太阳、地磁和热气层驱动因素之间存在非线性耦合。TEC（总电子含量），作为关键的电离层参数，主要来自GNSS观测，但由于全球观测稀疏和经验模型准确性的限制，特别是在强烈空间天气条件下，其可靠的预测依然有限。因此，本文提出了一种利用时空融合变换器（TFT）框架，以预测稀疏电离层数据的方法，该方法能够容纳太阳能辐射、地磁指数和GNSS垂直TEC等异构输入源，并采用预处理和时间对齐策略。实验表明，该模型在2010年至2025年间能够提前24小时做出稳健的预测，均方根误差低至3.33TECU。太阳紫外线辐射提供最强的预测信号。
### Innovation
基于时空融合变换器（TFT）的预测框架适用于处理稀疏的电离层数据，能够结合多种输入源数据进行预测，提供丰富的可解释性分析。这种方法提高了预测的准确性和对太阳紫外线辐射的依赖性。此外，为了促进可重复性和社区的发展，完整实现了开源工具包ionopy。
### Conclusion
本文介绍的基于时空融合变换器的预测框架能够提前24小时进行电离层TEC预测，具有较强的预测能力和较高的精度，同时其可解释性提高了其在实际应用和科学发现中的价值。开源工具包ionopy将帮助社区更好地理解和预测电离层变化。
## 1026. `cs.LG` - 使用深度神经网络发现软件并行化点 [PDF](https://arxiv.org/pdf/2509.16215), [HTML](https://arxiv.org/abs/2509.16215)
### Authors
Izavan dos S. Correia,Henrique C. T. Santos,Tiago A. E. Ferreira
### Background
研究提出了一种基于深度学习的方法来发现编程代码中的并行化循环，特别是那些具有潜在并行化的循环。为了实现这一目标，开发了两种基于遗传算法的代码生成器，用于生成两种类型的代码：第一种是独立的可并行化循环，第二种是存在依赖关系不清的模糊循环，使得难以确定该循环是否可以并行化。生成的代码片段被标记和预处理以确保有稳健的数据集。随后使用深度学习模型（深度神经网络和卷积神经网络）进行分类。实验结果验证了这两种模型在性能上的有效性，并强调了数据多样性对于模型性能的重要性。
### Innovation
开发了基于遗传算法的两种代码生成器来生成不同类型的代码，使用了深度神经网络和卷积神经网络进行代码分类，并通过统计分析验证了模型的性能。此外，实验还展示了数据多样性对于提高模型性能的重要性。这项工作是通过自动化识别可并行化的代码结构来提高软件优化和性能的一个重要尝试。
### Conclusion
研究结果表明，使用深度学习可以自动识别代码中的并行化结构，为软件优化和性能改进提供了有望的工具。尽管卷积神经网络在平均性能上略胜一筹，但两种模型的性能都具有可比的变异性，并且数据多样性对于模型性能至关重要。
## 1027. `cs.LG` - LLMs能在图欺诈检测中发现欺诈者吗？多层次LLM增强的图欺诈检测 [PDF](https://arxiv.org/pdf/2507.11997), [HTML](https://arxiv.org/abs/2507.11997)
### Authors
Tairan Huang,Yili Wang,Qiutong Li,Changlong He,Jianliang Gao
### Background
随着图神经网络（GNNs）在处理复杂多模态数据的关系方面表现出色，图欺诈检测（GFD）也开始受到广泛关注。现有的图欺诈检测方法通常依赖于预处理的节点嵌入和预定义的图结构，未能充分利用原始文本信息中的丰富语义线索。尽管大型语言模型（LLMs）在处理文本信息方面表现出强大能力，但如何将处理后的文本嵌入与图结构进行多模态融合仍然是一个巨大挑战。
### Innovation
本研究提出了名为MLED（多层次LLM增强的图欺诈检测）的新框架。MLED利用LLMs从文本信息中提取外部知识来增强图欺诈检测方法。研究中提出了一种多层次LLM增强框架，包括类型级增强器和关系级增强器，两类增强器分别增强了欺诈者与良性实体之间的差异以及欺诈者在不同关系中的重要性。
### Conclusion
针对四种真实数据集的实验结果显示，MLED作为一个通用框架在图欺诈检测中达到最先进的性能。
## 1028. `cs.LG` - 将联邦抹去问题建模为参数估计问题 [PDF](https://arxiv.org/pdf/2508.19065), [HTML](https://arxiv.org/abs/2508.19065)
### Authors
Antonio Balordi,Lorenzo Manini,Fabio Stella,Alessio Merlo
### Background
隐私法规要求将数据从深度学习模型中删除。这在联邦学习中成为一个显著的挑战，因为数据保持在客户端，导致全面重新训练或协调更新常不可行。本文介绍了一种基于信息论的高效联邦抹除框架，将泄漏建模为参数估计问题。该方法利用二阶海森矩阵信息来识别并选择性重置对即将被遗忘的数据最为敏感的参数，从而使联邦模型仅进行少量重新训练。这种模型通用的方法支持类别数据和客户端抹除，无需服务器访问客户端的原始数据，仅在初始信息聚合后需保留。评估表明，该方法在基准数据集上的隐私（混淆模型鉴别攻击成功率接近随机，类别知识被擦除）和性能（与重新训练基准模型的归一化准确率约为0.9）方面表现强大，同时有望比进行全面重新训练更有效。在针对回门攻击的情况下，该框架有效消除了恶意触发，恢复了模型的完整性。这提供了一种在联邦学习中进行数据抹除的实际解决方案。
### Innovation
提出了一种基于信息理论的联邦抹除框架，将数据抹除视为参数估计问题，利用二阶海森矩阵来识别敏感参数并进行重置，支持类别和客户端抹除而无需访问原始数据。该方法在保持隐私和性能的同时，显著提高了抹除操作的效率。在面对回门攻击时，有效恢复了模型完整性，提供了一种实用的解决方案。
### Conclusion
该方法在基准数据集上的隐私保护和性能保持上表现出色，通过有效的参数重置和少量的模型重新训练实现高效的数据抹除。同时在有针对性的回门攻击中证明了良好的表现。为联邦学习中的数据抹除提供了切实可行的解决方案。
## 1029. `cs.LG` - MissionHD：针对视频异常检测中分布不足的推理图的超维优化 [PDF](https://arxiv.org/pdf/2508.14746), [HTML](https://arxiv.org/abs/2508.14746)
### Authors
Sanggeon Yun,Raheeb Hassan,Ryozo Masukawa,Nathaniel D. Bastian,Mohsen Imani
### Background
LLM生成的推理图被称为任务特定图(MSGs)，它们在视频异常检测(VAD)和识别(VAR)中越来越受欢迎。然而，这些MSGs是新型的图结构，往往表现出不均衡的连接特性，并且缺乏大规模数据集进行预训练，这使得现有的图结构精炼(GSR)方法效果不佳。
### Innovation
本文提出了一种新的图结构精炼方法——HDC约束图结构精炼(HDC-GSR)，它利用超维计算(HDC)来优化可解码图表示，而不需要依赖结构-分布学习。基于这种方法，我们引入了MissionHD框架，它通过约束图神经操作来编码图，直接与下游任务损失对齐，并解码精炼的结构。实验结果表明，MissionHD精炼的图在VAD和VAR基准测试中的表现始终优于传统方法，从而将HDC-GSR确立为视频异常检测任务结构化推理的有效预处理步骤。
### Conclusion
我们提出的MissionHD框架为视频异常检测任务中的结构化推理问题提供了一个有效的解决方案，通过HDC-GSR可以显著提高检测和识别性能。
## 1030. `cs.LG` - 无标签数据表征学习的理论基础：统计学与最优化 [PDF](https://arxiv.org/pdf/2509.18997), [HTML](https://arxiv.org/abs/2509.18997)
### Authors
Pascal Esser,Maximilian Fleissner,Debarghya Ghoshdastidar
### Background
无标签数据的表征学习在统计学、数据科学和信号处理领域已有广泛研究，并且有丰富的降维、压缩和多维尺度变换技术等相关文献。然而，当前的深度学习模型依赖于新的无监督表征学习原则，这些原则无法用经典的理论轻易地进行分析。例如，视觉基础模型通过自我监督或去噪/掩码自动编码器取得了巨大的成功，有效地从海量的无标签数据中学习表征。但这对于解释这些模型为何能对各种预测任务表现出良好的性能或展现出进化的功能仍然难以描述。
### Innovation
本文概述了最近在无标签数据表征学习方面的理论进展，并提到了我们在这个方向上的贡献，旨在将统计和最优化的数学工具相结合来解决上述问题。
### Conclusion
本文提供了无标签数据表征学习的理论基础概述，强调了数学工具在理解这些模型方面的重要性，并提出了我们的研究贡献。
## 1031. `cs.LG` - 超越Slater条件的在线CMDPs在随机与 adversarial 约束下的研究 [PDF](https://arxiv.org/pdf/2509.20114), [HTML](https://arxiv.org/abs/2509.20114)
### Authors
Francesco Emanuele Stradi,Eleonora Fidelia Chiefari,Matteo Castiglioni,Alberto Marchesi,Nicola Gatti
### Background
研究在线episodic Commanded Markov决策过程(CMDPs)，在面对随机和对抗的约束时。以往工作如Stradi等人的研究提供了最好的两者兼顾的算法，但在处理constraint违反和slater条件等场景时存在局限性。本文旨在改进这些限制，并提供高效的算法解决方案
### Innovation
开发了一种新的算法，该算法在随机和对抗两种环境下都能提供优化的性能保障。在随机环境下，不依赖于slater条件，实现了期望的regret和constraint违反尺度。在对抗环境下，避免了slater条件的同时，保持了sublinear的constraint违反和α-regret，并证明了该算法的有效性。
### Conclusion
最终验证了算法的有效性，展示了在合成实验中的实际效果，并确认了所提出算法在随机和对抗约束条件下的优越性
## 1032. `cs.LG` - 用于多输出混合神经网络的一系列核化矩阵成本 [PDF](https://arxiv.org/pdf/2509.24076), [HTML](https://arxiv.org/abs/2509.24076)
### Authors
Bo Hu,José C. Príncipe
### Background
关联度量基础的成本对于自监督和对比特征学习至关重要。混合密度网络（MDNs）是生成模型和概率密度近似的一种广泛使用的方法，采用神经网络来生成定义高斯混合所需的多个中心。
### Innovation
本文提出了将MDNs与对比性成本结合使用的方法，通过四种核化矩阵成本：标量成本、向量-矩阵成本、矩阵-矩阵成本（舒尔补的迹）、SVD成本（核范数），近似数据密度。
### Conclusion
该方法为多输出混合神经网络提供了新的成本函数，以学习定义混合密度所需的多个中心点，从而提高了自监督和对比特征学习的效能。
## 1033. `cs.LG` - 构拟低秩加对角矩阵 [PDF](https://arxiv.org/pdf/2509.23587), [HTML](https://arxiv.org/abs/2509.23587)
### Authors
Andres Fernandez,Felix Dangel,Philipp Hennig,Frank Schneider
### Background
许多机器学习和科学计算任务涉及高维线性算子，这些算子只能通过昂贵的矩阵向量乘法访问。针对此类任务，最近的方法已经能够从少量的矩阵向量乘法中构造低秩或对角线近似。这类近似方法提供了极大的速度提升和可扩展性，但在更复杂的结构假设下，会产生近似误差。本文在此背景下引入了SKETCHLORD方法，旨在同时估计低秩和对角线成分，以便能够处理更广泛的低秩加对角线（LoRD）线性算子。
### Innovation
SKETCHLORD方法能够同时估计低秩和对角线成分，泛化到LoRD算子。该方法理论上和实验上都证明，这种联合估计方法优于任何按顺序估计（先对角后低秩，或先低秩后对角）。同时，将SKETCHLORD框架化为凸优化问题，从而提出了可扩展的算法。全面的实验证明，SKETCHLORD在准确恢复LoRD结构方面表现良好，尤其是在需要高保真度近似的大规模算子中，使其成为结构化近似工具箱的重要补充。
### Conclusion
该研究通过引入SKETCHLORD方法，填补了现有技术的空白，在大规模算子的高保真度近似中表现出色。SKETCHLORD为解决实际应用问题提供了有价值的方法，特别是在处理复杂的LoRD线性算子时。
## 1034. `cs.LG` - 基于脉冲神经网络的大型语言模型推理引擎 [PDF](https://arxiv.org/pdf/2510.00133), [HTML](https://arxiv.org/abs/2510.00133)
### Authors
Adarsha Balaji,Sandeep Madireddy
### Background
当前基于变压器架构的预训练模型是自然语言处理以及材料科学、气候学等领域的最先进模型。然而，训练和部署这些模型在计算上具有挑战性，因为它们对输入序列长度的时间和空间复杂度呈二次关系。已经有多种努力探索高效计算范式和模型架构以应对这些限制。
### Innovation
本文提出了一种名为NeurTransformer的方法，通过监督微调现有转换器模型将其转换为脉冲神经网络（SNN）。该方法包括：用基于脉冲的自注意力机制（SSA）替换自注意力机制，将已训练的转换器模型的前馈块转换为其等效的SNN版本，并使用SNN基元的模拟学习算法微调SSA块。实验验证了该方法的准确性和可扩展性。
### Conclusion
实验表明，转化后的GPT-2小型模型的余弦相似度降低了5-12%，困惑度降低了9.7%。此外，SSA块相比传统自注意力机制（ASA）在数字硬件上实现了更高的能效，估计能耗降低了64.71%到85.28%。
## 1035. `cs.LG` - 超越异常值：量化条件下优化器的研究 [PDF](https://arxiv.org/pdf/2509.23500), [HTML](https://arxiv.org/abs/2509.23500)
### Authors
Georgios Vlassis,Saleh Ashkboos,Alexandra Volkova,Torsten Hoefler,Dan Alistarh
### Background
随着新的优化器获得广泛应用，并且模型量化成为提高部署效率的标准手段，人们开始关注优化器选择如何影响量化条件下模型性能的问题。尽管在优化器和量化技术方面已经取得了进展，但对于两者之间的交互关系，系统的证据仍然有限。本文旨在通过研究优化器选择对量化条件下模型鲁棒性的影响，填补这一研究空白，特别是针对后训练量化(PTQ)和量化感知训练(QAT)这两种量化方法。研究首先训练不同参数量的全精度模型，并使用多种优化器探索超参数空间，以建立良好的基准。接着，通过PTQ评估不同优化器对模型性能的影响，发现最大值与平均值比(MMR)及峰度等指标并不能预测不同优化器下的PTQ表现。研究还发现，在QAT条件下，表现良好的优化器可能不再是最优选择，并证明了Shampoo优化器在QAT下的模型精度下降最小。最后，提出了不同优化器下的量化感知训练可扩展性法则，表明Shampoo优化器在所有测试优化器中具有最高的参数效率。
### Innovation
本文的创新之处在于系统性地研究了优化器选择对量化条件下模型性能的影响，特别是区分了PTQ和QAT两种量化方法。研究发现，传统的异常值相关指标并不能很好地预测不同优化器下的量化表现，并且提出了量化感知训练下的可扩展性法则，指出Shampoo优化器在所有测试的优化器中具有最高的参数效率。
### Conclusion
本文研究了量化条件下不同优化器的选择对模型性能的影响。发现传统的异常值相关指标不能有效预测PTQ下的优化器表现，分析了造成这一现象的原因，并通过QAT下的实验表明Shampoo优化器在不同优化方案下的模型精度下降最小，提出了不同优化器下的量化感知训练可扩展性法则，说明Shampoo优化器具有最高的参数效率。
## 1036. `cs.LG` - IndexNet: 时间序列中时间戳和变量感知建模 [PDF](https://arxiv.org/pdf/2509.23813), [HTML](https://arxiv.org/abs/2509.23813)
### Authors
Beiliang Wu,Peiyuan Liu,Yifan Hu,Luyan Zhang,Ao Hu,Zenglin Xu
### Background
多变量时间序列预测（MTSF）在多种实际应用中发挥着重要作用，如天气预测和交通流量预测。虽然近期进展显著提升了对时间动态和变量间依赖关系的建模能力，但现有的大多数方法忽视了与索引相关的描述性信息，如时间戳和变量索引，这些信息蕴含了丰富的上下文语义。
### Innovation
本文提出了一种基于MLP架构的IndexNet框架，结合了Index Embedding (IE)模块。IE模块包含两个关键组件：Timestamp Embedding (TE)和Channel Embedding (CE)。TE将时间戳转换为嵌入向量并注入输入序列，从而增强模型捕捉长期复杂周期模式的能力。CE根据变量索引为每个变量分配唯一且可训练的身份嵌入，使得模型能够明确区分不同类型的变量，避免输入序列看似相近时产生同质预测。广泛的实验表明，IndexNet在12个多样化的实际数据集上达到了主流基线相当的性能，验证了其具有时空及变量感知设计的有效性。此外，模块可插拔实验和可视化分析进一步揭示了IndexNet的强泛化能力和可解释性，这是当前研究中尚未充分探索的两个方面。
### Conclusion
本文的实验结果证明，IndexNet在时空及变量感知设计上表现出色，不仅具有较强的泛化能力和可解释性，而且在12个不同领域的实际数据集上达到了与主流基线相当的性能。
## 1037. `cs.LG` - 世界模型在机械取栓AI自主导航中的应用 [PDF](https://arxiv.org/pdf/2509.25518), [HTML](https://arxiv.org/abs/2509.25518)
### Authors
Harry Robertshaw,Han-Ru Wu,Alejandro Granados,Thomas C Booth
### Background
机械取栓（MT）的自主导航仍然是一个关键的挑战，因为血管解剖结构的复杂性以及对精确和实时决策的需求。基于增强学习（RL）的方法已经显示出自动化血管内导航的潜力，但当前的方法往往难以在多种患者血管之间进行泛化，并且在长时间任务方面遇到困难。
### Innovation
提出使用TD-MPC2（一种基于模型的增强学习算法）构建一个世界模型用于自主血管内导航。通过在十种真实患者的血管中训练单一RL代理完成了多个血管内导航任务，并将性能与最先进的Soft Actor-Critic（SAC）方法进行了比较。结果显示，TD-MPC2在多任务学习中显著优于SAC，在成功率上达到65%（SAC仅为37%），并且在路径比例方面有显著改进。尽管执行时间有所增加，但也表明了成功率与执行速度之间的权衡。这些发现强调了世界模型在改善自主血管内导航方面的重要潜力，并为进一步研究广泛适用的基于AI的机器人干预奠定了基础。
### Conclusion
研究结果展示了世界模型在提高自主血管内导航方面的能力，并为未来广泛适用的AI驱动的机器人干预研究奠定了基础。
## 1038. `cs.LG` - 使用熵引导条件变分自编码器的不确定性感知生成过采样 [PDF](https://arxiv.org/pdf/2509.25334), [HTML](https://arxiv.org/abs/2509.25334)
### Authors
Amirhossein Zare,Amirhessam Zare,Parmida Sadat Pezeshki,Herlock(SeyedAbolfazl)Rahimi,Ali Ebrahimi,Ignacio Vázquez-García,Leo Anthony Celi
### Background
在机器学习中，类别不平衡问题仍然是一个主要挑战，特别是在高维生物医学数据中，这些数据由占主导地位的非线性流形结构定义。传统的过采样方法如SMOTE依赖于局部线性插值，经常产生不合理的合成样本。相比之下，深度生成模型如条件变异地自编码器(CVAEs)能够更好地捕捉非线性分布，但标准变体在处理劣势样本时忽视了不确定性和边界区域样本的重要性。本文背景阐述了在处理此类不平衡问题时面临的挑战以及现有方法的不足。
### Innovation
本文提出了一种称为Local Entropy-Guided Oversampling with a CVAE (LEO-CVAE)的新颖生成过采样框架，该框架通过在数据表示学习和生成中明确引入局部不确定性来改进现有方法。具体来说，通过计算样本邻域内的条件分布熵来量化不确定性，高熵指示更高的类别重叠，作为不确定性的代理。LEO-CVAE通过两种机制利用这种信号：(i) 局部熵加权损失 (LEWL) ，强调在不确定区域中的稳健学习；(ii) 使用熵引导的采样策略，集中在这些含有信息性的类别重叠区域来进行生成。
### Conclusion
在临床基因组学数据集（ADNI和TCGA肺癌）上应用LEO-CVAE，结果显示这种基于熵感知的生成过采样方法显著提高了分类器性能，优于传统的过采样方法和生成基线方法。本文的结果强调了在复杂非线性结构占主导地位的领域（如组学数据领域）中，不确定性感知生成过采样方法的价值。
## 1039. `cs.LG` - AbsTopK: 重新思考稀疏自编码器以实现双向特征 [PDF](https://arxiv.org/pdf/2510.00404), [HTML](https://arxiv.org/abs/2510.00404)
### Authors
Xudong Zhu,Mohammad Mahdi Khalili,Zhihui Zhu
### Background
稀疏自编码器（SAEs）已被证明是大型语言模型（LLMs）的解码器结构理解的重要工具，其主要目标是将隐藏状态分解成有意义的语义特征。虽然已经提出了一些SAE变体，但仍然缺乏从原始字典学习表述中结构化地推导SAE的方法。本文通过展开邻近梯度法来解决这一问题，展示了单步更新能自然恢复常见的SAE变体，如ReLU、JumpReLU和TopK。然而，现有SAE的一个根本限制在于，它们的稀疏性诱导正则化器强制非负性，这使得同一个特征无法表示反向概念（如男性 vs. 女性），从而造成语义轴的断裂为不同的、冗余的特征，限制了表示的完整性。
### Innovation
本文通过有向邻近梯度方法构建了从原始字典学习公式推导稀疏自编码器的框架，揭示了现有稀疏自编码器的一个根本限制，即它们的非负性稀疏性正则化器导致语义轴的碎片化。针对这一问题，本文提出了一种新的变体AbsTopK，基于$boldsymbol{boxed{text{text{textbackslash{}ell}0}}}$稀疏约束，对最大模激活进行硬阈值化，从而保留了正负激活，揭露了更丰富的双向概念表示。AbsTopK在四个LLM和七个探针及引导任务上进行全面实验，显示出能提高重构保真度、增强可解释性，并让单个特征编码对立的概念。
### Conclusion
本文提出了一种名为AbsTopK的新变体，该变体基于$boldsymbol{boxed{text{text{textbackslash{}ell}0}}}$稀疏约束，并对最大模激活进行硬阈值化，以实现更好的双向概念表示。实验结果表明，AbsTopK在四个方面优于现有方法：提高重构保真度、增强可解释性、使单个特征编码对立概念，甚至在某些任务上超越了差值法（Difference-in-Mean），后者需要针对每个概念标注的数据。
## 1040. `cs.LG` - 比较机器学习模型对分类数字发展文档的研究 [PDF](https://arxiv.org/pdf/2510.00720), [HTML](https://arxiv.org/abs/2510.00720)
### Authors
Uvini Ranaweera,Bawun Mawitagama,Sanduni Liyanage,Sandupa Keshan,Tiloka de Silva,Supun Hewawalpita
### Background
自然语言处理（NLP）中的自动文档分类由于数字数据库的快速增长成为了一个热门话题。然而，一个适合特定分类任务的模型可能对于另一个数据集表现较差，这是因为上下文不同。因此，为了优化结果，需要训练和评估多个模型。本文利用一个公开的文档数据库，该数据库涵盖了全球数字发展干预措施，这些干预措施分为十二个类别。由于数字干预措施仍在不断出现，因此利用NLP在这一领域内相对新颖。鉴于数字干预措施的指数级增长，这项研究也充满了提高数字发展导向型组织报告工作的广阔空间。
### Innovation
本研究不采用传统的一致模型进行多类别分类的方法，而是探索了一种称为One vs Rest的方法来构建一个综合模型，以优化性能。通过这种方法，研究发现数据量并非影响性能的唯一因素，类别内部相似性和类别间不相似性也起到了关键作用。
### Conclusion
本文研究了包括决策树、k近邻、支持向量机、AdaBoost、随机梯度下降、朴素贝叶斯和逻辑回归在内的机器学习算法的分类性能。通过使用准确率、精确率、召回率和F1-score来评估这些模型的性能，并使用过采样来解决数据集的类别不平衡问题。研究结论指出，要优化性能，并非仅仅依赖于数据量，特征的相似性和类别间的差异性同样也至关重要。
## 1041. `cs.LG` - 机制可解释性作为一种统计估计：EAP-IG 的方差分析 [PDF](https://arxiv.org/pdf/2510.00845), [HTML](https://arxiv.org/abs/2510.00845)
### Authors
Maxime Méloux,François Portet,Maxime Peyrard
### Background
本文的背景是，为了开发可信赖的人工智能，需要超越黑箱性能指标，转向理解模型的内部计算。机制可解释性（MI）旨在通过识别模型行为背后的算法机制来满足这一需求。然而，MI的科学严谨性取决于其发现的可靠性。为了评估这一严谨性，本文对最新的电路发现方法EAP-IG进行了系统的稳定性分析。
### Innovation
本文的创新之处在于，将解释性方法，如电路发现，视为统计估计器，并对其变异性及鲁棒性进行了详细的评估。通过输入重采样、指令改述、超参数变化和因果分析中的噪声注入等多种受控扰动，对EAP-IG进行评估，发现其表现出较高的结构变异性并对于超参数敏感，质疑了其发现的稳定性。
### Conclusion
基于这些结果，本文提出了机制可解释性领域的最佳实践建议，强调报告稳定性指标的常规做法，以促进更严谨及统计上可靠的解释性科学。
## 1042. `cs.LG` - 大质量数据幻觉：重新思考LLM预训练中的分类器质量过滤 [PDF](https://arxiv.org/pdf/2510.00866), [HTML](https://arxiv.org/abs/2510.00866)
### Authors
Thiziri Nait Saada,Louis Bethune,Michal Klein,David Grangier,Marco Cuturi,Pierre Ablin
### Background
大规模模型在训练前会在大量收集自网络的数据集上进行预训练，这些数据集包含质量参差不齐的文档，因此进行数据过滤至关重要。一种常用的方法是基于分类器的质量过滤(CQF)，该方法通过训练一个二元分类器来区分预训练数据和一小部分高质数据集。它为每个预训练文档分配一个质量分数，实际上是分类器的得分，并仅保留得分最高的文档。
### Innovation
论文提供了对CQF的深入分析，展示了尽管CQF能提高下游任务的表现，但它不一定能提升高质数据集上的语言模型性能。研究还通过与通过随机词元置换获得的合成数据进行比较，揭示了迥然不同的趋势。结果挑战了CQF捕捉到有意义的质量概念的观点。
### Conclusion
CQF实际上过滤了高质量数据集，导致其对高质数据集上的语言模型性能提升并不显著。合成数据和真实数据之间的比较表明了关键点，论文指出了现有观点的不足并提出了新的见解。
## 1043. `cs.LG` - 时间序列预测中的基础模型有多基础？ [PDF](https://arxiv.org/pdf/2510.00742), [HTML](https://arxiv.org/abs/2510.00742)
### Authors
Nouha Karaouli,Denis Coquenet,Elisa Fromont,Martial Mermillod,Marina Reyboz
### Background
基础模型被设计成多功能嵌入机器，具有强大的零样本能力和在多种下游任务微调后的优越泛化性能。虽然语言和视觉基础模型大体上符合这一描述，但本文提出，时间序列数据的内在多样性使得它们不太适合构建有效的基础模型。通过对预测作为下游任务的实证分析，本文显示时间序列基础模型的零样本能力受到其预训练领域的具体影响，并且在应用于未见过的实际时间序列数据时，微调的基础模型在参数量和内存占用增加的情况下，并不总是比针对预测任务专门设计的小模型表现更好。
### Innovation
本文通过分析预测作为下游任务，具体论证时间序列数据的内在多样性使得基础模型难以构建，揭示了现有基础模型在时间序列预测中的局限性.
### Conclusion
时间序列基础模型的零样本能力受到预训练领域的显著影响，在实际应用中，与其参数量和内存占用的增加相比，并没有明显的优势，使得针对特定预测任务的小型专门模型更具竞争力.
## 1044. `cs.LG` - 降级升级：优化器简化提升大语言模型卸载的鲁棒性 [PDF](https://arxiv.org/pdf/2510.00761), [HTML](https://arxiv.org/abs/2510.00761)
### Authors
Yicheng Lang,Yihua Zhang,Chongyu Fan,Changsheng Wang,Jinghan Jia,Sijia Liu
### Background
大语言模型（LLM）卸载旨在从现有模型中精确移除不希望的数据或知识影响，同时保持其在不相关任务上的效用。这一方法在解决隐私和安全问题方面显示了潜力。然而，最近的研究发现卸载效果往往脆弱：比如量化权重或微调等卸载后操作可以迅速消除预期的遗忘。之前的努力通过重新定义卸载目标来增强鲁棒性，但这些方法主要假设了脆弱性来源的作用。这篇文章探讨了优化器在无需考虑卸载目标和公式的情况下，对形成卸载鲁棒性的重要作用。研究发现，优化器的'等级'（信息利用程度）与卸载的抵抗性密切相关，使用更低等级的优化器（如零阶优化器或压缩梯度变体）往往能增强鲁棒性。
### Innovation
这篇文章提出了一种新的视角，即通过研究优化器的鲁棒性作用来改进卸载方法。作者发现，降低优化器等级（如使用零阶方法或压缩梯度优化器）能够增强鲁棒性，尽管这些方法会产生嘈杂且不够精确的更新，但能够促进收敛到更难以扰动的损失景观盆地，从而抵抗训练后扰动。通过将零阶方法与随机化平滑联系起来，揭示了其在鲁棒卸载中的自然优势。文章还提出了一种结合零阶和一阶更新的混合优化器，能够在保持卸载有效性的同时增强鲁棒性。
### Conclusion
在MUSE和WMDP基准上进行的大量实验验证了该方法能够实现更鲁棒的遗忘，同时保持卸载质量。
## 1045. `cs.LG` - NeuroTTT: 在利用测试时训练弥合EEG基础模型预训练与下游任务不匹配方面的神经特定自我监督精细化调优 [PDF](https://arxiv.org/pdf/2509.26301), [HTML](https://arxiv.org/abs/2509.26301)
### Authors
Suli Wang,Yangshen Deng,Zhenghua Bao,Xinyu Zhan,Yiqun Duan
### Background
大规模的脑电图(EEG)基础模型在脑-计算机接口(BCI)应用中表现出巨大的前景，但这些模型常常因为预训练目标和下游任务之间的不匹配以及交叉个体数据分布的变化而受到影响。这导致了问题的出现，比如模型在实际应用中的鲁棒性和准确性不足。本研究通过引入一个两阶段的对齐策略来解决这些问题，该策略将通用预训练与具体的EEG解码任务进行了衔接。该方法首先提出了一种针对神经特定领域的自监督精细化调优范式（NeuroTTT），该范式在基础模型中增加了与任务相关的目标，无需额外标注数据即可对潜在表示进行对齐。其次，结合了推理时的训练（TTT），这种方法包括个体未标注测试样本的自我监督推理训练以及预测熵最小化（Tent），从而不断重新校准模型以适应新的输入。这些策略共同提升了基于EEG的BCI任务的鲁棒性和准确性，尤其是在想象语音、压力检测和运动想象等方面取得了突破性的成果。使用CBraMod和LaBraM作为基础模型，该方法显著提高了它们的表现。在三个不同任务上的结果表明，所提出的方法实现了最先进的性能，超越了传统的精细化调优和适应方法。我们的代码可以在以下链接获取：this https URL
### Innovation
该研究提出了一种两阶段的精细调优策略，通过引入NeuroTTT自监督精细化调优范式和推理时的训练（TTT），首次实现了按领域调整的自我监督和推理时的训练在大规模EEG基础模型中的联合使用。这解决了预训练与下游任务之间的不匹配问题，提高了模型在多种BCI任务中的鲁棒性和准确性。该方法创新在于提出了不仅在训练阶段还可以在推理阶段进行自我监督的机制，使模型能够根据实时输入自适应优化，从而更好地实现教师训练的效果。
### Conclusion
研究结果表明，所提出的对齐策略在多元化BCI任务上实现了最先进的性能，超越了传统的精细化调优和适应方法。这种方法不仅证明了在大规模EEG基础模型中整合测试时训练的有效性，还显著提升了CBraMod和LaBraM这两种基础模型的性能。
## 1046. `cs.LG` - 关于大型语言模型强化学习动力学的可预测性 [PDF](https://arxiv.org/pdf/2510.00553), [HTML](https://arxiv.org/abs/2510.00553)
### Authors
Yuchen Cai,Ding Cao,Xin Xu,Zijun Yao,Yuqing Huang,Zhenyu Tan,Benyi Zhang,Guiquan Liu,Junfeng Fang
### Background
大型语言模型（LLMs）最近在推理能力方面的进步主要受强化学习（RL）的推动，但是强化学习训练过程中参数动态的内在机制尚未被完全理解。这项研究旨在揭示这些参数更新的基本特性及其影响，以增强对LLMs推理性能的理解和预测能力。
### Innovation
这项工作发现了两个基础特性：1) 行占优性，其中参数更新矩阵的最具特征子空间几乎完全决定了推理改善，恢复了超过99%的性能提升；2) 行线性动态，这个主要子空间在整个训练过程中线性演化，从而使得早期检查点能够进行准确预测。这些发现催生了AlphaRL插件加速框架，利用短期早期训练窗口扩展最终参数更新，实现了最大2.5倍的加速同时保留超过96%的推理性能，无需额外模块或超参数调整。这种发现为大规模强化学习提供了一个多功能且实用的工具，为LLMs实现出理、可解释和高效的训练范式铺平了道路。
### Conclusion
这项研究揭示了大型语言模型在强化学习过程中参数更新的基本特性，并据此开发了AlphaRL插件加速框架，通过早期训练窗口扩展最终参数更新，并实现了显著的性能加速和保留推理性能。这些发现为大规模强化学习的发展提供了新的思路和工具，促进了对大型语言模型训练过程的理解和优化。
## 1047. `cs.LG` - 变分稀疏自编码器的分析 [PDF](https://arxiv.org/pdf/2509.22994), [HTML](https://arxiv.org/abs/2509.22994)
### Authors
Zachary Baker,Yuxiao Li
### Background
稀疏自编码器（SAE）通过学习密集激活中的稀疏、可解释特征来解释神经网络表示，已经显示出很有前途的方法。本文探讨了将变分方法整合到SAE架构中是否能够提升特征的组织和可解释性。
### Innovation
引入了变分稀疏自编码器（vSAE），它用从学习到的高斯后验中进行随机采样的方式替代了确定性的ReLU门控，并加入了朝标准正态分布先验的KL散度正则化。这种方法期望通过这种概率采样产生分散压力，使特征在潜在空间中更协调地组织起来，避免重叠。
### Conclusion
vSAE在核心评估指标上表现不如标准SAE，但在特征独立性和消除指标上表现较好。KL散度项导致过度正则化压力，显著减少了活跃特征的比例，导致观察到的性能下降。尽管vSAE特征表现出更好的稳健性，但与基线相比，它们拥有更多的“死”特征。研究结果表明，将变分方法直接应用于SAEs并没有提升特征组织或可解释性，需要更精细的方法来充分利用变分方法的优势。
## 1048. `cs.LG` - 神经扩散过程用于物理可解释的生存预测 [PDF](https://arxiv.org/pdf/2510.00733), [HTML](https://arxiv.org/abs/2510.00733)
### Authors
Alessio Cristofoletto,Cesare Rollo,Giovanni Birolo,Piero Fariselli
### Background
该研究介绍了一种名为 DeepFHT 的生存分析框架，它将深度神经网络与随机过程理论中的首次触及时间（FHT）分布相结合。时间到事件被表示为潜在扩散过程首次抵达吸收边界的时间。通过神经网络，输入变量被映射到包括初始条件、漂移和扩散在内的物理意义上参数，这些参数适应了布朗运动等 FHT 过程。这种方法不仅提供了一个闭合的生存函数和危险函数表示，还能够捕捉时间相关的风险性，无需假定恒定的危险模型。研究人员通过人工和真实数据集将 DeepFHT 方法与 Cox 生存模型进行了比较，结果表明，尽管该方法在预测准确性上与当前先进方法持平，但其基于物理的可解释参数化能够更清楚地说明输入特征与风险之间的关系。这种将随机过程理论与深度学习相结合的方法为复杂系统中的生存现象建模提供了理论依据。
### Innovation
该框架将随机过程理论与深度学习方法相结合，通过神经网络将输入变量映射到物理意义上具有实际意义的参数，如初始条件、漂移和扩散。这种方法既提供了一个闭合的形式表示生存函数和危险函数，又能够在不假设恒定危险的情况下捕捉到时间变化的风险。这种创新方法使得对输入特征与风险之间的关系有了更清晰的理解。与传统的 Cox 生存模型相比，DeepFHT 在保持物理可解释性的同时，提供了与当前先进技术相媲美的预测准确性。
### Conclusion
研究显示，通过将随机过程理论与深度学习相结合，DeepFHT 能够在复杂系统中精确预测生存现象，并提供了基于物理的可解释参数化，这有助于深入理解输入特征与风险之间的关系。这种方法提供了一种制定有据可循的方案在复杂系统中建模生存现象。
## 1049. `cs.LG` - 时间序列基础模型（TSFMs）易遭受灾难性遗忘吗？ [PDF](https://arxiv.org/pdf/2510.00809), [HTML](https://arxiv.org/abs/2510.00809)
### Authors
Nouha Karaouli,Denis Coquenet,Elisa Fromont,Martial Mermillod,Marina Reyboz
### Background
时间序列基础模型（TSFMs）在跨多种预测任务时显示出了极有前景的零样本泛化能力。然而，它们在不断适应时的鲁棒性尚未被充分探索。本文通过使用具有不同周期结构的合成数据集，研究了TSFMs在顺序微调多个数据集时是否会发生灾难性遗忘，并探讨了新数据适应与先前知识保留之间的权衡关系。
### Innovation
本文首次通过设计具有不同周期结构的合成数据集，研究了TSFMs在连续微调时的灾难性遗忘问题。通过实验证明了新数据适应与先前知识保留之间的基本稳定性和可塑性困境，揭示了这种权衡关系在实际应用中的重要性。
### Conclusion
尽管微调可以提高新任务的性能，但常会严重损害先前学习的知识，这表明需要在稳定性与可塑性之间做出权衡。未来的研究应探索如何在两者之间找到平衡点，以提高TSFMs的不断适应能力和鲁棒性。
## 1050. `cs.LG` - 基于高斯pmDAGs的神经网络参数优化 [PDF](https://arxiv.org/pdf/2309.14073), [HTML](https://arxiv.org/abs/2309.14073)
### Authors
Mehrzad Saremi
### Background
参数推断在因果推断和识别中至关重要。现有的用于因果推断的图形结构在高斯贝叶斯网络的边缘化下不稳定，该文章提出了一种新的图形结构来忠实表示高斯贝叶斯网络的边缘。
### Innovation
文章首次提出了参数优化和训练前向神经网络之间的二元关系，提出了基于观测分布优化图形结构参数的算法，并为高斯因果模型提供了因果效应可识别性条件。
### Conclusion
文章提供了验证因果效应是否可识别的元算法，并为从高斯分布推广到其他分布时神经网络和因果模型之间的二元关系奠定了基础。
## 1051. `cs.LG` - LPAC: 学习感知-行动-通信循环及其在覆盖控制中的应用 [PDF](https://arxiv.org/pdf/2401.04855), [HTML](https://arxiv.org/abs/2401.04855)
### Authors
Saurav Agarwal,Ramya Muthukrishnan,Walker Gosrich,Vijay Kumar,Alejandro Ribeiro
### Background
覆盖控制问题是自主导航一群机器人进行协作式监测的现象或特征的问题，具有挑战性。背景是在不具备先前知识的分散设置中，机器人具有有限的通信和感知能力。在这样的环境中，传统的分散和集中覆盖控制算法存在局限性。
### Innovation
作者提出了一种可学习的感知-行动-通信（LPAC）架构，该架构由卷积神经网络（CNN）处理局部感知，图神经网络（GNN）促进机器人间通信，浅层多层感知器（MLP）计算机器人行动。GNN能够通过计算需要与附近机器人通信的信息以及如何融合接收的信息，促进机器人群的协作。
### Conclusion
实验表明，通过模仿学习训练的LPAC模型超过了标准的分散和集中覆盖控制算法。学习到的策略能够跨训练数据集外的环境进行泛化，适应更大规模的环境和更多机器人，且对位置估计噪声具有鲁棒性。这些结果表明，LPAC架构适用于实现机器人群的分散式导航以达到协作行为。
## 1052. `cs.LG` - 机器学习在密度泛函近似精度中的应用 [PDF](https://arxiv.org/pdf/2311.00196), [HTML](https://arxiv.org/abs/2311.00196)
### Authors
Johannes Voss
### Background
机器学习技术已逐渐成为计算化学不可或缺的工具，能够加速原子级模拟和材料设计，并有望提高计算效率较高的电子结构方法（如密度泛函理论）的预测能力，达到化学精度，同时能够纠正密度泛函方法中的基本错误。文献综述了最近在使用机器学习改善密度泛函及其相关近似精度方面的进展，并讨论了在不同化学和材料类别间构建可移植的机器学习模型的前景与挑战，特别提供了超出训练集系统的实例以展示其应用潜力和局限性。
### Innovation
论文综述了将机器学习应用于提高密度泛函及其相关近似精度的研究进展，强调了其在化学精度提升和纠正密度泛函方法基本错误方面的能力，并探讨了适用于不同化学和材料类别的可移植模型开发的前景与挑战。
### Conclusion
尽管利用机器学习提高密度泛函精度展现出巨大潜力，但仍面临模型在不同化学和材料类别间可移植性方面的挑战。未来研究需要更加关注开发通用且可移植的机器学习模型，以提高计算化学的预测能力并推动更多应用场景的实际应用。
## 1053. `cs.LG` - 无需扩展的A*搜索：使用深度Q网络学习启发式函数 [PDF](https://arxiv.org/pdf/2102.04518), [HTML](https://arxiv.org/abs/2102.04518)
### Authors
Forest Agostinelli,Shahaf S. Shperberg,Alexander Shmakov,Stephen McAleer,Roy Fox,Pierre Baldi
### Background
在大动作空间中使用A*搜索高效解决问题仍旧是一个重大挑战。每次A*搜索迭代时，生成的节点数和启发式函数应用次数会线性增长，尤其当使用由计算昂贵的功能近似器（例如深度神经网络）学习的启发式函数时更为明显。这极大地增加了计算时间和内存使用量.
### Innovation
本文提出了Q*搜索算法，该算法利用能够一次性从状态返回所有可能转移的成本到终点估计以及转移成本估计的启发式函数，而不需应用转移或生成后继状态。这显著减少了计算时间和内存使用。此外，作者证明，在不低估状态总转移成本和成本到终点值之和的启发式函数下，Q*搜索能够保证找到最短路径。使用深度Q网络架构从领域交互中学习状态-动作启发式函数，无需任何先验知识。实验结果表明，当动作空间增大时，Q*搜索仅存在微小的运行时开销，并且与A*搜索相比，其运行速度快129倍，生成的节点数少1288倍.
### Conclusion
Q*搜索在大动作空间环境下能够有效减少计算资源的消耗，并能够保证找到最短路径，而实验结果进一步验证了其优异的性能表现。
## 1054. `cs.LG` - 元转移皮肤病诊断：探索长尾分布下的少量样本学习与迁移学习 [PDF](https://arxiv.org/pdf/2404.16814), [HTML](https://arxiv.org/abs/2404.16814)
### Authors
Zeynep Özdemir,Hacer Yalim Keles,Ömer Özgür Tanrıöver
### Background
由于罕见皮肤疾病缺乏足够的标注数据和样本分布的存在，构建精确的模型依然充满挑战。数据集收集不一致性和多样的研究目标进一步加剧了这一问题。为了应对这些挑战，研究了三种学习策略：经验学习、监督迁移学习和对比自我监督预训练，在少量样本学习框架中进行比较。在ISIC2018、Derm7pt和SD-198三个基准数据集上评估了五种训练设置。
### Innovation
研究基于MobileNetV2和Vision Transformer（ViT）架构的传统迁移学习方法在样本数量增加时表现出色，特别是在结合批处理级数据增强技术如MixUp、CutMix和ResizeMix之后，这些模型在SD-198和Derm7pt数据集上达到了最先进的性能，并在ISIC2018数据集上达到了具有竞争力的结果。所有与本工作相关的源代码将很快在提供的URL上公开提供。
### Conclusion
传统迁移学习方法，尤其是在结合数据增强技术后，表现优于经验学习和自我监督方法。这些方法在长尾分布的皮肤疾病分类任务中表现出色。
## 1055. `cs.LG` - 差分隐私数据流中的聚类 [PDF](https://arxiv.org/pdf/2307.07449), [HTML](https://arxiv.org/abs/2307.07449)
### Authors
Alessandro Epasto,Tamalika Mukherjee,Peilin Zhong
### Background
聚类问题（如$k$-means和$k$-median）是基本的无监督机器学习原语，流式聚类算法在过去已经被广泛研究。然而，随着数据隐私成为许多实际应用中的一个核心 concern，非隐私聚类算法可能不再适用于许多场景。为了满足隐私保护的要求，需要研究在流式数据中执行差分隐私的聚类算法，从而在保证用户数据隐私的同时，提供有效的聚类结果。本研究专注于这个问题，提出了第一个在连续发布环境中对流式$d$维欧几里得数据点进行$k$-means和$k$-median聚类的差分隐私算法，能够在亚线性（在$T$中）的空间中实现这一目标。
### Innovation
本研究的主要创新点在于提出了一种差分隐私聚类框架，该框架只需要一个作为黑盒子的离线差分隐私核心概要或聚类算法。通过该框架，提出了在流式环境中进行$k$-means和$k$-median聚类的算法，能够以亚线性空间提供具有理论保证的差分隐私聚类结果，同时还提供了在一定误差范围内的近似算法。这些算法能够满足在流式数据发布过程中对隐私保护的要求。
### Conclusion
本研究成功地在差分隐私约束下，提出了对流式数据的$k$-means和$k$-median聚类算法。经过严格的时间和空间需求分析，这些算法能够在亚线性空间内运行，并提供能够保证用户隐私的聚类结果。该工作还提供了更广义情况下（任意$theta>0$）的理论保证，进一步增强了算法的灵活性和实用性。
## 1056. `cs.LG` - 所有机器人形态都可以运行一个策略：一种端到端的多体态移动学习方法 [PDF](https://arxiv.org/pdf/2409.06366), [HTML](https://arxiv.org/abs/2409.06366)
### Authors
Nico Bohlinger,Grzegorz Czechmanowski,Maciej Krupka,Piotr Kicki,Krzysztof Walas,Jan Peters,Davide Tateo
### Background
深度强化学习技术在稳健步行机器人中取得了最先进的结果。尽管存在诸如四足、类人和六足等多样化的腿足平台，但该领域仍缺失一种能够轻松有效控制所有这些不同类型机器人模型的单一学习框架，并且能够零样本或少量样本转移至未见过的机器人模型。
### Innovation
我们引入了 URMA（Unified Robot Morphology Architecture，统一机器人形态架构），这是一种新的框架，它将端到端多任务强化学习方法引入了腿足机器人领域，使得学习到的策略能够控制任何类型的机器人形态。我们的方法的关键理念是允许网络学习一种不受形态影响的抽象步行控制器，这得益于我们的形态无关编码器和解码器，从而使网络能够无缝地在不同的机器人形态之间共享。
### Conclusion
我们的实验表明，URMA 可以在多种形态上学习步行策略，并且能够轻松地在仿真和真实世界中的未见过的机器人平台上进行转移。
## 1057. `cs.LG` - 合成扰动：泛化合成控制方法以处理动态治疗效应 [PDF](https://arxiv.org/pdf/2210.11003), [HTML](https://arxiv.org/abs/2210.11003)
### Authors
Anish Agarwal,Sukjin Han,Dwaipayan Saha,Vasilis Syrgkanis,Haeyeon Yoon
### Background
文章背景介绍了合成控制和干预方法的传统应用，这些方法主要用于静态治疗效果的估计。然而，实际数据中治疗效应往往是动态变化的，且受到内生时间变化的混淆状态影响。本文提出了一个更广泛的框架，用于估计具有动态治疗轨迹的特定单位的治疗效应，基于底层因子模型假设，为各种治疗干预序列下的任何特定单位的平均结果提供了识别策略。
### Innovation
创新点在于提出了一个新的方法，即合成扰动（synthetic blip effects），它将合成控制和干预方法推广到动态治疗效应的情况。该方法通过递归地将每个治疗时间点和目标单位的扰动效应表示为其他单位扰动效应的线性组合来避免了原有方法中的组合爆炸问题，并且可以在观察性的研究环境中更广泛地应用。
### Conclusion
该研究使用了独特的韩国企业面板数据，展示了如何使用提出的方法来估计个体化的动态治疗效应，并制定出口业企业的最优治疗分配规则。该方法具有易于实现且具有效估计器的特点，拓宽了合成控制和干预方法在动态治疗应用中的适用性。
## 1058. `cs.LG` - SUPER-Net：基于编码器-解码器网络的不确定性传播实现可信图像分割 [PDF](https://arxiv.org/pdf/2111.05978), [HTML](https://arxiv.org/abs/2111.05978)
### Authors
Giuseppina Carannante,Nidhal C.Bouaynaya,Dimah Dera,Hassan M. Fathallah-Shaykh,Ghulam Rasool
### Background
深度学习 (DL) 在工业领域的应用前景广阔，但由于其对噪音和离群输入的脆性，在一些敏感领域中的部署受到限制。当前的模型往往缺乏不确定性量化，仅提供点估计。已有研究未能充分解决这一问题，导致模型在面对复杂输入时表现不佳。
### Innovation
提出了 SUPER-Net，一种通过不确定性传播实现可信图像分割的贝叶斯框架。通过泰勒级数逼近，SUPER-Net 在非线性层传播模型后验分布的均值和协方差，同时还输出分割图像和像素级不确定性图，从而避免了昂贵的蒙特卡洛采样。实验表明，SUPER-Net 在多个噪音和对抗条件下的鲁棒性和准确性均优于当前最先进的模型。不确定性图可以帮助模型识别受噪声或攻击影响的低置信区域，从而提高分割任务的可靠性。
### Conclusion
实验结果表明，SUPER-Net 在各类噪音和对抗条件下的性能优于当前最先进的模型，在鲁棒性和准确性方面表现出色。不确定性图能够帮助模型识别低置信区域，特别是在噪音或对抗样本导致错误时，提升了模型的自我评估能力。
## 1059. `cs.LG` - 使用机器学习的通用行为代理目标识别设计 [PDF](https://arxiv.org/pdf/2404.03054), [HTML](https://arxiv.org/abs/2404.03054)
### Authors
Robert Kasumba,Guanghui Yu,Chien-Ju Ho,Sarah Keren,William Yeoh
### Background
目标识别设计（GRD）旨在通过最小的修改使决策环境中的代理行为目标更容易被推断。尽管已有多种研究努力，但目前的方法在计算效率方面存在不足，并假设代理行为接近最优。本文借鉴已有文献中关于最坏情况差异（wcd）的概念，提出了一个新的方法，旨在通过机器学习改善目标识别并在多种约束条件下优化决策环境。通过大量模拟和人类实验，作者验证了该方法的有效性和改进效率。
### Innovation
提出了一种新的GRD方法，结合了机器学习来预测最坏情况差异（wcd），并使用基于梯度的优化框架来优化决策环境，针对各种约束条件进行目标识别优化，特别适应预算灵活、环境复杂和代理行为非最优的情况。该方法在减少wcd和提高运行效率方面优于现有方法。
### Conclusion
通过广泛仿真与人类实验验证了该方法的有效性和改进效率。该方法改进了目标识别的计算效率，能够适应现有方法不适用的多种场景，且能进一步帮助人类决策者进行有效目标识别。
## 1060. `cs.LG` - 浅层安全性对齐假说 [PDF](https://arxiv.org/pdf/2410.10862), [HTML](https://arxiv.org/abs/2410.10862)
### Authors
Jianwei Li,Jung-Eun Kim
### Background
随着大型语言模型（LLMs）在各种应用中的深度集成，确保它们生成安全的响应变得至关重要。尽管已有研究更多关注一般性的指令遵循，但对安全性的关注却不足，忽视了其中的脆弱性问题。本文旨在填补这一空白。
### Innovation
本文提出了浅层安全性对齐假设（SSAH），认为安全性对齐教会原本不安全的模型选择正确的推理方向——履行或拒绝用户请求，这被解释为隐含的二元分类任务。同时，作者还确定了四种关键核成分：安全性关键单元（SCU）、实用性关键单元（UCU）、复杂单元（CU）和冗余单元（RU），并通过冻结安全关键单元和利用冗余单元作为“对齐预算”来简化调试过程，有助于模型在保持安全性的同时适应新任务。
### Conclusion
本文认为LLMs中安全性的一个原子功能单元位于神经元层面，强调安全性对齐不应复杂化。
## 1061. `cs.LG` - 多尺度节点嵌入方法用于图建模与生成 [PDF](https://arxiv.org/pdf/2412.04354), [HTML](https://arxiv.org/abs/2412.04354)
### Authors
Riccardo Milocco,Fabian Jansen,Diego Garlaschelli
### Background
节点嵌入算法位于网络科学和机器学习的交汇点，它们将网络作为输入，通过在抽象几何空间中的输出向量表示节点结构，支持包括网络建模、数据压缩、链接预测和社区检测等下游任务。然而，这些算法存在两个显而易见但相关性不强的局限性：首先，无法明确解释向量空间基本操作（向量求和）在原始网络节点中的对应物；其次，在将网络节点粗化为任意块节点时，不同层次下获取的节点嵌入之间的关系尚不清楚。
### Innovation
本文基于网络重整化理论的最新成果，提出了一种多尺度节点嵌入方法，该方法在进行任意粗化时，能够确保块节点嵌入向量与其构成节点的嵌入向量之和的一致性。研究成果首次在两个可以用多个分辨率水平自然表示的经济网络上得到了验证：国际间国家间的贸易网络和荷兰不同产业间的投入产出网络。结果显示，即使从非常低维度的嵌入中也能成功复制多个关键网络特性，如三角形数量的大量存在，从而实现在任意分辨率水平对原始网络生成忠实复制的目标。
### Conclusion
提出了一个多尺度节点嵌入方法，解决了节点嵌入算法中的两个局限性，即向量求和在原始网络节点中的对应性和不同层次下的嵌入一致性问题，该方法在国际和产业经济网络上成功验证了其有效性，并展示了其在保留网络特性方面的强大功能。
## 1062. `cs.LG` - 差分隐私联邦学习：一项系统回顾 [PDF](https://arxiv.org/pdf/2405.08299), [HTML](https://arxiv.org/abs/2405.08299)
### Authors
Jie Fu,Yuan Hong,Xinpeng Ling,Leixia Wang,Xun Ran,Zhiyu Sun,Wendy Hui Wang,Zhili Chen,Yang Cao
### Background
近年来，机器学习中的隐私和安全问题推动了受信任的联邦学习成为研究的前沿。差分隐私作为一种具有严格数学基础和可证明保证的隐私保护方法，在联邦学习中迅速成为事实上的标准。尽管关于联邦学习中结合差分隐私算法的研究非常丰富，但在这些研究的分类和综合方面仍然存在系统性回顾的不足。
### Innovation
为了解决现有分类的不足，作者提出了一种新的差分隐私联邦学习的分类框架，该框架基于各种差分隐私模型的定义和保证以及联邦学习场景的等级。此外，研究还探讨了差分隐私在联邦学习场景中的应用，提供了关于隐私保护联邦学习的宝贵见解，为未来研究指明了实用方向。
### Conclusion
本文提供了一种系统性的差分隐私联邦学习的概述，通过更清晰的理解不同差分隐私模型保护的对象及其在联邦学习环境中的邻域等级，旨在为未来研究提供实用方向和指导。
## 1063. `cs.LG` - 线性注意力下的上下文学习渐近理论 [PDF](https://arxiv.org/pdf/2405.11751), [HTML](https://arxiv.org/abs/2405.11751)
### Authors
Yue M. Lu,Mary I. Letey,Jacob A. Zavatone-Veth,Anindita Maiti,Cengiz Pehlevan
### Background
本文探讨了变换器（Transformers）在仅通过输入自身实例进行学习和执行任务的能力，这种能力被称为上下文学习（ICL），并强调了它对于变换器成功的核心作用。尽管有这种能力，但在上下文学习所需的样本复杂性、预训练任务多样性及上下文长度方面仍然存在许多未解决的问题。
### Innovation
本文通过线性注意机制下的线性回归任务，提出了一种准确模型，探讨了上下文学习的渐近理论。与这些因素相关的精确理论结果包括推导了新型现象学丰度的缩放法则下的学习曲线，展示了当增加预训练实例时学习曲线的双重下降现象，并发现模型行为在任务多样性低和高时分别呈现出记忆训练任务和真正的上下文学习和超越预训练任务的泛化。
### Conclusion
研究发现，上下文学习的行为在较小的多样性范围中倾向于对训练任务的记忆学习，而当多样性较高时，则实现了真正的上下文学习并超越了预培训任务的泛化。该理论通过采用线性注意和完全非线性变换器架构的实验得到了经验验证。
## 1064. `cs.LG` - 打破ID-语言障碍：基于LLM的序列推荐适配框架 [PDF](https://arxiv.org/pdf/2411.18262), [HTML](https://arxiv.org/abs/2411.18262)
### Authors
Xiaohan Yu,Li Zhang,Xin Zhao,Yue Wang
### Background
大型语言模型（LLMs）在自然语言处理领域取得了近期突破，推动了推荐系统的研究，但它们在领域特定知识方面的不足仍然是关键障碍。具体来说，LLMs 缺乏对于序列推荐至关重要的关键信息，例如用户行为模式。因此，需要一种创新方法来填补这一差距，以改善推荐的准确性。
### Innovation
本文提出了IDLE-Adapter，这是一种创新框架，通过整合预训练的领域特定ID嵌入，将它们融合到LLMs中，从而提高推荐的准确性。IDLE-Adapter 通过Pre-trained ID Sequential Model、维度对齐、逐层嵌入精炼和逐层分布对齐等步骤，将稀疏用户-项目交互数据转换为LLM兼容的密集表示。并且，IDLE-Adapter 显示了无缝集成来自多种ID基序列模型和LLM架构的ID嵌入的能力。
### Conclusion
广泛的实验结果表明，与现有方法相比，IDLE-Adapter 在HitRate@5和NDCG@5指标上分别实现了超过10%和20%的性能提升。
## 1065. `cs.LG` - 使用合成数据生成进行离分布检测 [PDF](https://arxiv.org/pdf/2502.03323), [HTML](https://arxiv.org/abs/2502.03323)
### Authors
Momin Abbas,Muneeza Azmat,Raya Horesh,Mikhail Yurochkin
### Background
可靠的分类系统部署依赖于准确的离分布（OOD）检测能力，但离分布数据通常难以收集，从而对准确的OOD检测构成了挑战。
### Innovation
利用大型语言模型（LLMs）生成高质量的合成OOD代理，从而消除对外部OOD数据源的依赖。
### Conclusion
我们的方法在各类实验中显著降低了假阳性率（在某些情况下实现零假阳性），同时在内部分布任务上保持了高准确率，比基线方法表现出显著的优势。
## 1066. `cs.LG` - 协同LLM和知识图谱：一种新颖的软件代码库相关问题解答方法 [PDF](https://arxiv.org/pdf/2412.03815), [HTML](https://arxiv.org/abs/2412.03815)
### Authors
Samuel Abedu,SayedHassan Khatoonabadi,Emad Shihab
### Background
软件代码库包含丰富的信息，有助于理解开发过程，但提取这些信息的时间消耗且需要技术专长。尽管软件工程聊天机器人可以支持自然语言与代码库的交互，但它们在理解超出训练意图的问题以及准确检索相关数据方面存在问题。
### Innovation
本文通过将知识图谱添加到基于LLM的聊天机器人中，改进了代码库相关问题的回答准确性。该方法采用了两步流程：从代码库数据构建知识图谱，并将知识图谱与LLM结合以处理自然语言的问题和答案。并通过少量样本引导链式思考的方法提高了准确性，最终达到了84%的准确率。
### Conclusion
本文的研究表明，LLM和知识图谱是使代码库数据变得易于访问的一种可行解决方案。并且通过实验证明这种方法能显著提高任务完成的准确性和效率，使用户觉得是有用的。
## 1067. `cs.LG` - 一步步对抗训练扩散模型用于单步视频生成 [PDF](https://arxiv.org/pdf/2501.08316), [HTML](https://arxiv.org/abs/2501.08316)
### Authors
Shanchuan Lin,Xin Xia,Yuxi Ren,Ceyuan Yang,Xuefeng Xiao,Lu Jiang
### Background
扩散模型在图像和视频生成中得到了广泛应用，但其迭代生成过程极为缓慢且成本高昂。现有的模型压缩方法在图像领域虽展示了潜在的一步生成能力，但仍然面临显著的质量下降问题。
### Innovation
本文提出了一种名为Adversarial Post-Training (APT) 的方法，该方法在扩散预训练后使用对抗训练进行单步视频生成。为了提高训练稳定性和生成质量，作者引入了改进后的模型架构和训练过程，以及近似R1正则化目标函数。这种方法能够在一步前向评价步骤内实时生成高分辨率的视频和图像，且生成质量可匹敌当前最先进的方法。
### Conclusion
论文中的对抗后训练模型，Seaweed-APT，能够在单一前向评估步骤内生成2秒的1280x720分辨率、24帧每秒的视频，且能够生成1024像素的单步图像，达到与当前顶级方法相当的质量水平。
## 1068. `cs.LG` - 后验概率视觉-语言模型 [PDF](https://arxiv.org/pdf/2412.06014), [HTML](https://arxiv.org/abs/2412.06014)
### Authors
Anton Baumann,Rui Li,Marcus Klasson,Santeri Mentu,Shyamgopal Karthik,Zeynep Akata,Arno Solin,Martin Trapp
### Background
vision-language 模型（VLMs）如 CLIP 和 SigLIP 已经在分类、检索和生成任务中取得了显著的成功。VLMs 通过确定性映射图像和文本描述到一个联合潜在空间，在该空间中使用余弦相似度评估它们之间的相似性。然而，当这些模型用于下游任务时，这种确定性映射无法捕捉由于领域转移而产生的概念不确定性。
### Innovation
本文提出了一种后验不确定性估计方法，该方法不需要额外的训练。该方法利用了 VLMs 最后几层的贝叶斯后验近似，并通过解析量化余弦相似度的不确定性。我们显示了该方法在不确定性量化和支持集选择中的有效性，特别是在主动学习中。
### Conclusion
与基线相比，我们获得了更好的并具有良好校准的预测不确定性、可解释的不确定性估计以及样本高效主动学习。我们的结果表明，这些大型模型在关键性应用中的前景广泛。
## 1069. `cs.LG` - VerifiableFL: 使用Exclaves为Federated Learning提供可验证声明 [PDF](https://arxiv.org/pdf/2412.10537), [HTML](https://arxiv.org/abs/2412.10537)
### Authors
Jinnan Guo,Kapil Vaswani,Andrew Paverd,Peter Pietzuch
### Background
在Federated Learning（FL）中，数据提供者可以通过不共享其训练数据的方式共同训练一个机器学习模型，这使得提供关于最终训练模型的可验证声明变得具有挑战性，例如与使用的训练数据、数据清洗或正确的训练算法相关的内容。由于恶意数据提供者可以简单地偏离正确的训练协议而不会被检测到，现有的一些可信执行环境（TEEs）来对抗此类攻击的方法效果有限且不稳固。虽然有文件曾探索使用TEEs来对抗攻击，现有方法难以有效地将TEEs的验证证明与针对训练冲刺的声明联系起来。由于侧信道攻击等多种攻击，TEEs自身也显示出一系列问题。VerifiableFL是一个用于使用运行时验证证明来为FL模型训练提供可验证声明的新系统。
### Innovation
VerifiableFL通过使用exclaves（纯完整性执行环境，没有秘密）的新抽象来生成这些证明，从而使其在数据泄露攻击方面具有免疫力。与先前的仅静态（在部署时）验证整个TEEs的方法不同，VerifiableFL在FL训练期间使用exclaves来验证个别数据变换。这些由以上方法生成的运行时验证证明形成了整个FL模型训练计算的验证数据流图。最终，审计人员可以根据这一图进行检查，以确保训练后的FL模型满足其可验证声明。实验结果表明，VerifiableFL将未保护的FL模型训练的开销降低了不到10%。
### Conclusion
VerifiableFL提供了一种新的方法，通过使用exclaves在Federated Learning中提供可验证声明，从而提高模型训练的安全性和可信度。它能够有效地将验证证明与具体训练操作联系起来，并通过生成验证数据流图来确保模型满足其可验证声明，使得审计过程更加透明和可靠。
## 1070. `cs.LG` - 使用更新近似初始化是一种极高效的低秩微调的灵丹妙药 [PDF](https://arxiv.org/pdf/2411.19557), [HTML](https://arxiv.org/abs/2411.19557)
### Authors
Kaustubh Ponkshe,Raghav Singhal,Eduard Gorbunov,Alexey Tumanov,Samuel Horvath,Praneeth Vepakomma
### Background
低秩适配器已成为高效微调大规模语言模型的标准方法，但它们通常无法达到完全微调的效果。研究者提出了名为LoRA Silver Bullet或LoRA-SB的方法，该方法通过精心设计的初始化策略，利用低秩子空间来近似完全微调。这种方法通过限制更新空间实现高秩梯度更新的最佳缩放，并去除调整缩放因子的需求。理论证明，这种方法提供了一个精确条件，以实现低秩适配器-XS架构中的初始梯度的最优低秩逼近，并在整个训练过程中保持更新方向不变。
### Innovation
提出了名为LoRA Silver Bullet或LoRA-SB的新方法，通过低秩子空间内的精确条件实现对完全微调的近似。该方法利用受限的更新空间实现高秩梯度更新的最佳缩放，同时消除需要调整缩放因子的需求。理论证明表明，初始梯度的最优低秩逼近和训练过程中的更新方向保持。实验表明，该方法在27-90倍更少的可学习参数下超过了LoRA（和基线方法）的性能，并全面优于LoRA-XS。研究结果证实，在低秩子空间内可以模拟完全微调，而不会牺牲性能并实现显著的参数效率增益。
### Conclusion
通过精心设计的初始化策略和低秩适配器-XS架构，LoRA Silver Bullet或LoRA-SB方法将完全微调的效果模拟到了低秩子空间内，证明了在不牺牲性能的情况下实现极高的参数效率是可能的。该研究结果为低秩微调提供了一种高效且稳健的方法，并且该方法已经在数学推理、常识推理和语言理解任务上得到了广泛的验证。研究代码已公开。
## 1071. `cs.LG` - 使用小波超图扩散处理推荐系统中的异质性 [PDF](https://arxiv.org/pdf/2501.14399), [HTML](https://arxiv.org/abs/2501.14399)
### Authors
Darnbi Sakong,Thanh Tam Nguyen
### Background
推荐系统在各个领域中提供个性化用户体验方面至关重要。但捕捉用户-物品交互的异质性和多维特征带来了重大挑战。
### Innovation
本文提出了FWHDNN（基于融合的小波超图扩散神经网络），一种创新框架，旨在提升基于超图的推荐任务中的表示学习。该模型包含三个关键组件：（1）跨差关系编码器，利用异质性感知的超图扩散来适应跨类别标签的消息传递；（2）多尺度聚类编码器，采用基于小波变换的超图神经网络层捕捉多尺度拓扑关系；（3）集成多模态融合机制，通过中间融合和晚期融合策略结合结构和文本信息。
### Conclusion
在真实数据集上的广泛实验表明，FWHDNN在准确度、鲁棒性和可扩展性方面超越了现有最先进的方法，特别是在捕获用户和项目之间的高级连接方面。
## 1072. `cs.LG` - SCoT:通过直致一致轨迹统一一致性模型和矫正流 [PDF](https://arxiv.org/pdf/2502.16972), [HTML](https://arxiv.org/abs/2502.16972)
### Authors
Zhangkai Wu,Xuhui Fan,Hongyu Wu,Longbing Cao
### Background
预训练扩散模型通常用于从随机噪声生成干净数据（例如图像），并有效形成噪声和相应干净图像的配对。这些预训练模型的蒸馏可以看作是在配对内构建高级轨迹的过程，以加速采样。例如，一致性模型蒸馏开发一致的投影函数来调节轨迹，尽管采样效率仍然是一个问题。矫正流方法强制推行直线轨迹以实现更快的采样，但依赖于数值ODE求解器，这可能导致近似误差。
### Innovation
本文通过提出名为SCoT（Straight Consistent Trajectory）的模型，弥合了一致性模型和矫正流方法之间的差距。SCoT模型同时拥有两种方法的优点，能够产生既有一致性质又有直线性质的轨迹。通过设定两个关键目标来平衡这些双重特性：（1）将SCoT映射的梯度调节到恒定值，（2）保证轨迹的一致性。
### Conclusion
广泛的实验结果表明了SCoT的有效性和效率。
## 1073. `cs.LG` - CRUST-Bench：C到安全Rust转换基准 [PDF](https://arxiv.org/pdf/2504.15254), [HTML](https://arxiv.org/abs/2504.15254)
### Authors
Anirudh Khatry,Robert Zhang,Jia Pan,Ziteng Wang,Qiaochu Chen,Greg Durrett,Isil Dillig
### Background
现代重新架构遗留C代码时，既要确保安全性，也要与现代Rust生态系统兼容，C-to-Rust转换编译是必要的。然而，目前尚无相关数据集用于评估是否能将C代码安全地转换为可通过特定测试用例验证的Rust代码。CRUST-Bench引入了一个包含100个C代码仓库的数据集，每个仓库配有手动编写的、安全的Rust接口以及测试用例，用以验证转换正确性。这种方法考虑的是整个仓库而非孤立的函数，从而捕捉了跨多个文件依赖的大型复杂项目的转换挑战。
### Innovation
CRUST-Bench是一个创新的数据集，提供了整个仓库级别的转换编译案例，且每个库都有明确的安全Rust界面和测试用例，确保遵循Rust的惯用模式和内存安全特性。此外，通过使用最先进的人工智能文本生成模型，研究发现当前最先进的方法仍难以生成安全且符合Rust惯用模式的代码，揭示了模型在C到Rust转换过程中常犯的错误类型。
### Conclusion
CRUST-Bench为C到安全Rust的转换提供了宝贵的基准测试，此数据集的改进将有助于提高转换系统，使其能处理复杂场景并助力从C向Rust（确保内存安全的语言）迁移已有代码库。
## 1074. `cs.LG` - 从表格数据中进行神经符号关联规则挖掘 [PDF](https://arxiv.org/pdf/2504.19354), [HTML](https://arxiv.org/abs/2504.19354)
### Authors
Erkan Karabulut,Paul Groth,Victoria Degeler
### Background
关联规则挖掘（ARM）是一种从数据特征中发现逻辑规则的模式的技术，应用于众多领域。然而，高维数据集会产生大量的规则，增加了执行时间并影响下游任务的表现。如何有效管理这一规则爆炸是ARM研究中的核心挑战。
### Innovation
提出了一种新的神经符号ARM方法——Aerial+。Aerial+利用欠完全自动编码器创建数据的神经表示，捕捉特征间的关联，并通过模型的重建机制从中提取规则。评估结果显示，Aerial+能学习到更为简洁、高质量且覆盖全面的规则集，并且在作为基于规则的可解释机器学习模型的一部分时，可显著减少执行时间同时保持或提升准确性。
### Conclusion
通过Aerial+，高维数据集中的规则数量得到有效管理，执行时间也显著减少，同时保持或提高模型准确性。Aerial+为ARM领域提供了新的解决方案。
## 1075. `cs.LG` - 政策导向的二元分类：改进(CD-)CART的最终分割以更精确地针对子群体 [PDF](https://arxiv.org/pdf/2502.15072), [HTML](https://arxiv.org/abs/2502.15072)
### Authors
Lei Bill Wang,Zhenbang Jiao,Fangyi Wang
### Background
政策制定者经常使用递归二元分裂规则来根据二元结果划分人口，并针对那些二元事件概率超过阈值的子群体。这种问题被称为潜在概率分类（LPC）。从业者通常使用分类和回归树（CART）进行LPC。然而，本文证明了在LPC的背景下，经典的CART方法以及通过学生模型是CART的知识蒸馏方法（KD-CART）在这种上下文中都有局限性。因此，作者提出了最大化距离最终分裂（MDFS）方法，该方法生成的分裂规则在唯一交集假设下严格优于CART和KD-CART。为了放宽唯一交集假设，本文还提出了一种惩罚最终分裂（PFS）方法和加权经验风险最终分裂（wEFS）方法。通过广泛的模拟研究，本文证明了所提出的方法在大多数情况下优于CART和KD-CART，当应用于真实世界数据集时，还可以更好地针对更脆弱的子群体制定政策
### Innovation
本文提出了一种最大化距离最终分裂（MDFS）方法，该方法在唯一交集假设下严格优于经典的CART和知识蒸馏方法（KD-CART）。不仅如此，还提出了相对应的方法来放宽唯一交集假设，通过这种方法在大量模拟和真实数据集上的实验结果表明所提出的方法优于传统的CART和KD-CART方法，同时能够更好地识别和针对更脆弱的子群体进行政策制定
### Conclusion
通过广泛模拟实验，本文表明所提出的方法在大多数情况下优于CART和KD-CART方法，而在实际数据集上的应用中，MDFS可以生成更能够针对更脆弱子群体的政策
## 1076. `cs.LG` - 黄金分割率加权防止模型崩溃 [PDF](https://arxiv.org/pdf/2502.18049), [HTML](https://arxiv.org/abs/2502.18049)
### Authors
Hengzhi He,Shirong Xu,Guang Cheng
### Background
最近的研究揭示了递归生成模型训练中的一种现象——模型崩溃，即后续模型在前一模型生成的数据上进行训练时出现性能严重下降。这一问题及其改进方法成为了生成模型研究中的核心挑战。本文根据生成模型依次在新收集的真实数据与上一训练步骤生成的合成数据的组合上进行训练的新框架，研究了这一现象。
### Innovation
本文评估了不同的加权训练方案在不同的场景下的表现，并从理论上分析了合成数据混合比例与加权方案对最终模型性能的影响，发现不同比例下的最优加权方案趋于一个统一的表达式，并揭示了充分利用合成数据与模型性能之间的基本权衡。发现最优真实数据权重在某些情况下对应于黄金分割率的倒数。
### Conclusion
理论结果在广泛的模拟数据集和真实表格数据集上得到了验证。
## 1077. `cs.LG` - 通过感知一致性向轻量级模型转移特征表示 [PDF](https://arxiv.org/pdf/2505.06595), [HTML](https://arxiv.org/abs/2505.06595)
### Authors
Hai-Vy Nguyen,Fabrice Gamboa,Sixin Zhang,Reda Chhaibi,Serge Gratton,Thierry Giaccone
### Background
本文提出了一个从大型教师模型向较小的学生模型转移特征表示的方法。背景在于，学生模型的表示能力弱于教师模型，因此需要找到一种方法使得学生模型在不完全保留教师模型绝对几何结构的前提下，更好地保存全局一致性。
### Innovation
本文提出了一个新的概念‘感知一致性’(perception coherence)，并基于此概念提出了一种新的损失函数。该损失函数考虑了特征空间中数据点之间的差异性，并通过排序进行衡量。通过最小化这个损失函数，学生模型可以模仿教师模型如何‘感知’输入。该方法的优势是能够在不需要完全保持教师模型几何结构的情况下，保持局部排名差异性，从而实现更好的一致性。
### Conclusion
实验结果表明，本文提出的这种方法在特征表示转移方面优于或与强基线方法达到相当的性能。
## 1078. `cs.LG` - SIM-Shapley: 一种稳定且计算高效的Shapley值近似方法 [PDF](https://arxiv.org/pdf/2505.08198), [HTML](https://arxiv.org/abs/2505.08198)
### Authors
Wangxuan Fan,Siqi Li,Doudou Zhou,Yohei Okada,Chuan Hong,Molei Liu,Nan Liu
### Background
可解释的人工智能（XAI）对于可信的机器学习（ML）尤其在医疗保健和金融等高风险领域是必不可少的。Shapley值（SV）方法为复杂模型的功能归因提供了一种有原则的框架，但计算成本高，限制了其在高维度设置中的可扩展性。
### Innovation
我们提出了Stochastic Iterative Momentum for Shapley Value Approximation（SIM-Shapley），这是一种受随机优化启发的稳定且高效的Shapley值近似方法。我们从理论上分析了方差，证明了一线性$Q$-收敛，并在实际中的某些数据集上展示了提高的实证稳定性和低偏差。在数值实验中，SIM-Shapley在保持与现有最佳方法相当的功能归因质量的同时，将计算时间减少了高达85%。
### Conclusion
我们的随机小批量迭代框架自然地扩展到更广泛类别的样本平均逼近问题，为提高计算效率并同时提供稳定保证的新途径做出了贡献。代码公开展示在：this https URL.
## 1079. `cs.LG` - 学习低维度嵌入用于黑箱优化 [PDF](https://arxiv.org/pdf/2505.01112), [HTML](https://arxiv.org/abs/2505.01112)
### Authors
Riccardo Busetto,Manas Mejari,Marco Forgione,Alberto Bemporad,Dario Piga
### Background
当基于梯度的方法不实用时，黑箱优化（BBO）是一种有价值的替代方案。然而，BBO在高维问题和有限的试验预算下表现不佳。因此，为了在这些情况下提高优化效率，本文提出了一种基于元学习的方法来预计算特定类别的优化问题的低维流形，使得在优化新的问题实例时，BBO可以在低维空间中进行，从而有效降低找到近似最优解所需的努力。
### Innovation
该方法创新地利用元学习预先计算低维流形，使得在特定类别的优化问题中，黑箱优化能够在更低的维度空间中进行，从而简化了优化过程，降低了寻找近似最优解的难度。这一策略尤其适用于高维度和有限试验预算的情况。
### Conclusion
本文提出了一种基于元学习的方法来预先计算特定优化问题类别的低维流形，在实际优化任务中，通过在低维空间中进行黑箱优化，可以有效降低找到近似最优解所需的计算量和试验次数，从而提高优化效率。
## 1080. `cs.LG` - 高维二分类中的最优且可验证校准：角度校准与Platt尺度转换 [PDF](https://arxiv.org/pdf/2502.15131), [HTML](https://arxiv.org/abs/2502.15131)
### Authors
Yufan Li,Pragya Sur
### Background
本文研究线性二元分类器$boldsymbol{text{σ}(text{ŵ}^top boldsymbol{x})}$的校准问题，其中特征向量$boldsymbol{x}$服从高斯分布，$boldsymbol{text{σ}}$是链路函数，$boldsymbol{text{ŵ}}$是真线性权重$boldsymbol{w^text{star}}$的估计量。通过与非信息性的随机分类器进行插值，构建了一个校准良好的预测器，其插值权重依赖于估计量$boldsymbol{text{ŵ}}$与真线性权重$boldsymbol{w^text{star}}$之间的角度$text{∠}(boldsymbol{text{ŵ}}, boldsymbol{w^text{star}})$。研究认为，这种角度校准方法在高维情况下（样本数量和特征数量都呈发散趋势，以相似的速度），是可验证地校准良好的。角度$text{∠}(boldsymbol{text{ŵ}}, boldsymbol{w^text{star}})$可以一致估计。此外，所得预测器是唯一的Bregman最优，即在适合的校准预测器类中，最小化真标签分布的Bregman散度。
### Innovation
本文首次提出了一种高维情况下同时具备校准和优化性质的校准策略，通过角度校准方法，并且在理论上证明了该方法的有效性。此外，还确定了在什么条件下经典的Platt尺度转换预测器将收敛到我们的Bregman最优广义良好预测器，这意味着Platt尺度转换也继承了这些优点，能够在高维情况下被证明是准确的。
### Conclusion
研究确认了角度校准框架的有效性，不仅具备校准性质，还具备优化性质。此外，通过适当条件下的Platt尺度转换，可以将经典方法与高维最优性质结合在一起，从而使该类预测器在实际应用中更加可靠和理想。
## 1081. `cs.LG` - 使用线性视网膜变换和贝叶斯实验设计融合聚视野固定点 [PDF](https://arxiv.org/pdf/2505.01249), [HTML](https://arxiv.org/abs/2505.01249)
### Authors
Christopher K. I. Williams
### Background
人类（和许多脊椎动物）面临将场景中的多个固定点融合以获得整体表示的问题，每个固定点使用高分辨率的聚视野并外周减较低分辨率。本文明确表示固定点的视网膜变换为高分辨率场景隐图像的线性下采样，并利用已知几何结构。这种线性变换使得可以在因子分析模型及混合因子分析模型中对场景的潜在变量进行准确推理。这进而允许将“下一步该看哪里”这个问题表述和解决为一个期望信息增益准则下的贝叶斯实验设计问题。
### Innovation
提出了使用线性视网膜变换和因子分析模型及混合因子分析模型，以及通过期望信息增益准则解决下一个注视点选择问题的方法。使用Frey faces和MNIST数据集的实验结果表明了该模型的有效性。
### Conclusion
研究展示了通过线性视网膜变换和因子分析模型及混合因子分析模型，能够有效融合多个固定点来获得场景的整体表示，并通过贝叶斯实验设计问题解决方式进行下一步注视点的选择，实验结果验证了方法的有效性。
## 1082. `cs.LG` - Oh-A-DINO: 在自我监督对象中心表示中理解和增强属性级别信息 [PDF](https://arxiv.org/pdf/2503.09867), [HTML](https://arxiv.org/abs/2503.09867)
### Authors
Stefan Sylvius Wagner,Stefan Harmeling
### Background
对象中心的理解是人类视觉的基础，并且对于复杂的推理任务至关重要。传统的方法通过定义基于槽的瓶颈来显式学习对象属性，而最近的自我监督视觉模型（如DINO）则展示了对象理解的潜在能力。本文研究了CLIP、DINOv2和DINOv3等自我监督表示和基于槽的方法在多对象实例检索任务中的有效性，该任务要求在场景中特定对象必须被忠实识别。随着预训练表示在下游任务（例如检索、操作和目标条件策略）中的应用越来越广泛，这一场景变得越来越重要。这些研究表明，自我监督视觉模型和基于槽的方法在识别边缘驱动的几何属性（形状、大小）方面表现出色，但无法保留非几何表面级别的线索（颜色、材料、纹理），这对于在这些任务中推理或选择对象时进行去模糊是至关重要的。学习一个附加的潜在空间，其中通过VAE正则化来确保紧凑且去纠缠的对象中心表示，可以恢复这些缺失的属性。将这样的潜在空间与自我监督方法结合起来可以改善所有属性的检索，表明为使自我监督表示在需要精确对象级推理的下游任务中更可靠，这种潜在补丁方法是一个有希望的方向。
### Innovation
本文的研究旨在在多对象实例检索中增强自我监督的表示方法，通过学习附加的潜在空间，将VAE正则化与自我监督方法结合起来，填补了边缘驱动的信息，这些信息对于精确识别特定对象至关重要。这种方法能够改善所有属性的检索效果，从而使得自我监督的表示方法更加可靠，适用于需要精确对象级推理的下游任务。
### Conclusion
研究表明，自我监督视觉模型和基于槽的方法在识别边缘驱动的几何属性方面表现出色，但无法保留非几何表面级别的线索，这对于在这些任务中推理或选择对象时进行去模糊是至关重要的。通过学习一个附加的潜在空间，这种方法能够恢复这些缺失的属性，并改善所有属性的检索。这一发现表明，结合自我监督方法和潜在空间可能是提高自我监督表示方法可靠性的有希望的方向。
## 1083. `cs.LG` - 使用大语言模型进行概率推理以估计k-匿名性 [PDF](https://arxiv.org/pdf/2503.09674), [HTML](https://arxiv.org/abs/2503.09674)
### Authors
Jonathan Zheng,Sauvik Das,Alan Ritter,Wei Xu
### Background
概率推理是人类智能和人工智能的关键方面，能够处理决策中的不确定性和模糊性。本文介绍了一个新的基于不确定性的大规模语言模型数值推理任务，旨在评估包含私人信息的用户生成文档的隐私风险。
### Innovation
提出了一种名为BRANCH的新方法，通过将个人数据的概率联合分布分解为随机变量来进行k-隐私值估计。这种方法利用贝叶斯网络分别估计人群中的每个因子的概率，并将其结合起来计算最终的k值。实验结果显示，该方法在73%的情况下成功估计了k值，比使用chain-of-thought推理的o3-mini提高了13%。研究还发现，语言模型的不确定性是准确性的良好指标，高方差的预测平均准确率降低了37.47%。
### Conclusion
本文提出的BRANCH方法能够在不确定情况下有效估计文本的k-隐私值，提升准确率，并利用语言模型的不确定性预测来提高模型的可靠性。
## 1084. `cs.LG` - scSiameseClu: 一种用于解析单细胞RNA测序数据的Siamese聚类框架 [PDF](https://arxiv.org/pdf/2505.12626), [HTML](https://arxiv.org/abs/2505.12626)
### Authors
Ping Xu,Zhiyuan Ning,Pengjiang Li,Wenhao Liu,Pengyang Wang,Jiaxu Cui,Yuanchun Zhou,Pengfei Wang
### Background
单细胞RNA测序(scRNA-seq)揭示了细胞异质性，细胞聚类在识别细胞类型和标记基因方面起着关键作用。尽管最近图神经网络(GNNs)-基于的方法在聚类性能上有了显著提升，但scRNA-seq数据的分析仍然面临挑战，缘于噪声、稀疏性和高维度。此外，GNNs容易出现过度平滑的问题，限制了它们捕捉复杂生物信息的能力。因此，基于这些挑战，本文提出了scSiameseClu，这是一种用于解析单细胞RNA测序数据的新型Siamese聚类框架。
### Innovation
scSiameseClu框架包括以下三个关键步骤：(1) 双重增强模块，通过在基因表达矩阵和细胞图关系中应用生物学信息驱动的扰动，增强表示的鲁棒性；(2) Siamese融合模块，通过交叉相关校准和自适应信息融合来捕捉复杂细胞关系，同时缓解过度平滑效应；(3) 最优传输聚类，利用Sinkhorn距离高效对聚类分配进行归一化，同时保持平衡。该方法在七个真实数据集上的综合评估表明，scSiameseClu在单细胞聚类、细胞类型注释和细胞类型分类方面均优于现有最先进的方法，提供了一种强大的scRNA-seq数据分析工具。
### Conclusion
scSiameseClu在七个真实数据集上的全面评估表明，该方法在单细胞聚类、细胞类型注释和细胞类型分类等方面均优于现有最先进的方法，提供了一种强大的scRNA-seq数据分析工具。
## 1085. `cs.LG` - 知识图谱推理即答数据集中的问题诊断与解决：朝向更可靠的基准测试 [PDF](https://arxiv.org/pdf/2505.23495), [HTML](https://arxiv.org/abs/2505.23495)
### Authors
Liangliang Zhang,Zhuorui Jiang,Hongliang Chi,Haoyang Chen,Mohammed Elkoumy,Fali Wang,Qiong Wu,Zhengyi Zhou,Shirui Pan,Suhang Wang,Yao Ma
### Background
KGQA系统依赖高质量的基准来评估复杂的多跳推理。尽管广泛使用，流行的数据库如WebQSP和CWQ存在严重的问题，包括不准确或不完整的事实注释、语义模糊、无聊或不可回答的问题，以及过时或不一致的知识。通过手动审核16个流行的KGQA数据库，发现平均事实正确率仅为57%。
### Innovation
引入了KGQAGen，一个带有LLM的闭环框架，系统地解决了这些问题。KGQAGen结合了结构化的知识构建、LLM指导的生成，以及符号验证，生成具有挑战性和可验证性的QA实例。
### Conclusion
使用KGQAGen构建了基于Wikidata的KGQAGen-10k大规模基准，评估了多种KG-RAG模型。实验结果表明，即使是最先进的系统也难以在这个基准上表现良好，强调了其揭示现有模型局限性的能力。研究结果建议更严格的基准构建，并将KGQAGen定位为用于推进KGQA评估的可扩展框架。
## 1086. `cs.LG` - ABBA-Adapters: 效率高且表达能力强的基模型微调方法 [PDF](https://arxiv.org/pdf/2505.14238), [HTML](https://arxiv.org/abs/2505.14238)
### Authors
Raghav Singhal,Kaustubh Ponkshe,Rohit Vartak,Praneeth Vepakomma
### Background
大型语言模型在各种任务中表现出色，但如何高效地将其适应到新领域仍然是一个关键挑战。参数高效微调（PEFT）方法通过引入轻量级可训练模块，同时保持大部分预训练权重不变，来解决这一问题。现有的方法如LoRA通过低秩分解来建模更新，但其表达能力受限于秩的选择。最近的一些方法如HiRA通过引入与冻结权重的Hadamard乘积以增加表达能力，但仍依赖于预训练模型的结构。
### Innovation
本文提出了ABBA，一种新的PEFT架构，它将更新表示为两个独立可学习低秩矩阵的Hadamard乘积。与以往工作不同，ABBA将更新与预训练权重完全解耦，允许两个组成部分自由优化。这导致在相同的参数预算下具有更高的表达能力，这一点通过矩阵重构实验得到了验证。实验结果表明，ABBA在算术和常识推理基准测试中取得了最佳效果，显著优于现有的PEFT方法。
### Conclusion
ABBA-Adapters在多个模型上的一致优越性表明，这种方法在基模型微调中的高效性和表达能力强。
## 1087. `cs.LG` - MetaFaith: 在LLMs中实现可靠的自然语言不确定性表达 [PDF](https://arxiv.org/pdf/2505.24858), [HTML](https://arxiv.org/abs/2505.24858)
### Authors
Gabrielle Kaili-May Liu,Gal Yona,Avi Caciularu,Idan Szpektor,Tim G. J. Rudner,Arman Cohan
### Background
LLMs在表达不确定性方面存在可靠性问题，常使用坚定的语言传达错误的断言，导致过度依赖和信任下降。现有文献尚未系统研究LLMs在忠实于其内在不确定性的语言表达上的能力。
### Innovation
提出了MetaFaith，一种基于人类元认知的新颖提示基线校准方法，旨在提升LLMs在表达真实不确定性的能力，并证明了它在不同模型和任务领域中的鲁棒性与有效性，能够提升61%的忠实度，并以83%的胜率超过原始生成结果，由人类评估。此外，现有干预措施（如标准提示方法和事实性校准技术）效果有限或甚至有害于提升忠实度。
### Conclusion
MetaFaith显著提升了LLMs忠实于其真实不确定性表达的能力，特别是在综合了多种模型和任务领域的情况下，这一改进尤为显著。
## 1088. `cs.LG` - 在低查询黑盒设置中加速目标硬标签对抗攻击 [PDF](https://arxiv.org/pdf/2505.16313), [HTML](https://arxiv.org/abs/2505.16313)
### Authors
Arjhun Swaminathan,Mete Akgün
### Background
深度神经网络在图像分类中仍然容易受到对抗样本的影响——这些微小、难以察觉的变化可导致错误分类。在黑盒设置中，攻击者只能访问最终预测，因此将图像错误分类为目标类别的定制攻击变得尤为困难。当前最先进的方法通常依赖于源图像和目标图像之间的决策边界几何特性，而忽略了图像本身的信息。
### Innovation
作者提出了一种名为Targeted Edge-informed Attack (TEA) 的新型攻击方法。TEA 利用目标图像的边缘信息精确地扰动目标图像，生成既接近源图像又能够实现目标分类的对抗图像。在低查询设置中，TEA 在不同模型上的性能显著优于当前最先进的方法（近70%更少的查询数），特别适用于实际应用中查询有限且只能访问黑盒的情况。此外，TEA 通过有效生成合适的对抗样本，为基于几何的攻击提供了更好的目标初始化。
### Conclusion
TEA 方法在低查询黑盒设置中对目标硬标签的对抗攻击中表现出色，显著减少了查询次数，提高了对抗攻击的有效性。
## 1089. `cs.LG` - GARG-AML 对抗洗钱: 一种可扩展且易于解释的基于图的框架 [PDF](https://arxiv.org/pdf/2506.04292), [HTML](https://arxiv.org/abs/2506.04292)
### Authors
Bruno Deprez,Bart Baesens,Tim Verdonck,Wouter Verbeke
### Background
本文讨论了一种基于图的新颖方法GARG-AML，用于有效的反洗钱（AML）工作。现有的反洗钱技术在检测复杂网络中的洗钱手段，特别是抽水洗钱（smurfing），方面的性能有待提高。GARG-AML通过为网络中的每个节点提供一个单一的可解释得分来量化抽水洗钱的风险，旨在结合计算效率、检测能力和透明度。
### Innovation
GARG-AML 创新之处在于它仅使用基本网络特征和对抽水洗钱的专家知识，构建了一个高性能的反洗钱系统。具体来说，它通过对节点二阶邻域的邻接矩阵特定构造，利用相邻矩阵中不同块的密度表达邻域的纯抽水洗钱模式相似性。此外，通过使用决策树和梯度提升分类器的扩展，进一步提高了其性能。这种方法在合成数据和开源数据上的测试结果表明，它在所有数据集上都达到了最先进的性能。GARG-AML的原创性还体现在将抽水洗钱检测转化为核心网络特征和网络表示方面。
### Conclusion
GARG-AML达到了最先进的性能，表明它在检测大规模交易图中的欺诈方面具有重大潜力。文章强调了基本网络属性如何为欺诈检测的进步提供更多潜力。这种方法基于实际的业务需求——可扩展性和可解释性。因此，它为金融公司提供了一个易于实施的解决方案，或者可以整合到现有的反洗钱解决方案中。
## 1090. `cs.LG` - MolLangBench：语言驱动的分子结构识别、编辑和生成综合基准 [PDF](https://arxiv.org/pdf/2505.15054), [HTML](https://arxiv.org/abs/2505.15054)
### Authors
Feiyang Cai,Jiahui Bai,Tao Tang,Guijuan He,Joshua Luo,Tianyu Zhu,Srikanth Pilla,Gang Li,Ling Liu,Feng Luo
### Background
分子的精确识别、编辑和生成对于化学家和处理各种化学任务的AI系统来说是基本前提。MolLangBench是一个全面的基准测试，旨在评估分子-语言接口任务：语言提示下的分子结构识别、编辑和生成。该基准使用自动化化学信息学工具构建识别任务，并通过严格的专家注释和验证来编纂编辑和生成任务，以确保输出的高质量和明晰性。MolLangBench支持语言与不同分子表示形式的模型评估，包括线性字符串、分子图像和分子图。最新的模型评估揭示了显著的局限性：最强的模型（GPT-5）在识别和编辑任务中的准确率分别为86.2%和85.5%，而生成任务的准确率仅为43.0%，这是直观上对人类来说非常简单的任务。这些结果突显了当前AI系统在处理初步分子识别和修改任务中的不足之处。
### Innovation
MolLangBench是一个全面且针对人工语言指令的分子结构识别、编辑和生成的基准测试。它利用自动化工具构建识别任务，并通过专家注释和验证来保证编辑和生成任务的质量。MolLangBench能够评估模型与不同分子表示形式的语言接口能力，提供了定量评估当前最先进的AI模型性能的方法，展示了它们在这些任务上的局限性。
### Conclusion
MolLangBench旨在促进更多有效的和可靠的AI系统在化学应用中的研究，以解决当前AI系统在处理基本分子识别和编辑任务方面的不足。
## 1091. `cs.LG` - WWAggr：基于窗口Wasserstein距离的集成变动点检测聚合方法 [PDF](https://arxiv.org/pdf/2506.08066), [HTML](https://arxiv.org/abs/2506.08066)
### Authors
Alexander Stepikin,Evgenia Romanenkova,Alexey Zaytsev
### Background
变点检测（CPD）的目标是在数据流中识别分布突变的时刻。由于现实世界高维数据模式的复杂性和对常见假设的违反，实时高维CPD仍然具有挑战性。当前的最新单一深度神经网络检测器尚未达到完美的质量。同时，集成方法提供了更加稳健的解决方案，提升了性能。然而，标准的预测聚合技术，例如平均值，往往是次优的，并未能考虑到问题的特殊性。
### Innovation
本文研究了深度变点检测器的集成，并发现标准预测聚合技术（如平均值）是次优的，不能适应特定问题。因此，作者引入了WWAggr，一种基于Wasserstein距离的新型任务特定集成聚合方法。WWAggr方法具有通用性，能够有效地与各种深度CPD模型的集成工作。此外，与现有解决方案不同，该方法实际上解决了长期存在的变点检测决策阈值选择问题。
### Conclusion
本文提出了WWAggr方法，这是一种基于窗口Wasserstein距离的新型任务特定集成聚合方法，用以解决深度变点检测器集成的问题。该方法不仅能够有效应用于各种深度CPD模型的集成，并且还解决了长期以来存在的变点检测决策阈值选择问题。
## 1092. `cs.LG` - 罗中求熟：重新思考推理中的记忆现象 [PDF](https://arxiv.org/pdf/2507.04782), [HTML](https://arxiv.org/abs/2507.04782)
### Authors
Yupei Du,Philipp Mondorf,Silvia Casola,Yuekun Yao,Robert Litschko,Barbara Plank
### Background
文章背景在于大型语言模型会记住训练过程中的任意实例，包括标签噪音，然而它们在推理任务中表现优异。本文探讨了语言模型如何记住标签噪音，以及为何在很多情况下，这种记忆不会严重影响可泛化的推理能力。
### Innovation
研究使用了两个有控制的合成推理数据集：四位数加法（FDA）和两跳关系推理（THR），发现了记忆依赖于可泛化的推理机制。模型在检索已记忆的噪音标签时继续进行推理计算，并且干预推理会损害记忆。研究还发现记忆通过分布式编码进行，即汇集各种输入和中间结果，而不是从输入到噪音标签构建查找机制。文章还揭示了FDA案例研究中，记忆是通过异常值启发式工作，其中现有的神经激活模式适度偏移以适应噪音标签。这些发现表明，语言模型中的标签噪音记忆基于，而不是覆盖了底层的推理机制。
### Conclusion
文章的研究结果表明，语言模型中的标签噪音记忆基于，而非覆盖底层的推理机制，这解释了良性记忆现象的有趣方面。
## 1093. `cs.LG` - 实时时互动视频生成的自回归对抗后训练方法 [PDF](https://arxiv.org/pdf/2506.09350), [HTML](https://arxiv.org/abs/2506.09350)
### Authors
Shanchuan Lin,Ceyuan Yang,Hao He,Jianwen Jiang,Yuxi Ren,Xin Xia,Yang Zhao,Xuefeng Xiao,Lu Jiang
### Background
现有大规模视频生成模型计算强度大，限制了其在实时和互动应用中的使用。因此，研究工作旨在提出一种方法，能够将预训练的潜在视频扩散模型转化为实时时互动视频生成器。
### Innovation
提出了自回归对抗后训练(AAPT)方法，该方法可以通过单一神经函数评估（1NFE）逐帧自回归生成潜在帧，支持实时流式传输和交互式控制；与现有方法不同，该方法探索了对抗训练作为自回归生成的有效范式，不仅实现了更高效的一步生成架构，还通过学生强迫训练减少了长时间视频生成中的累积误差.
### Conclusion
实验表明，提出的8B模型在单个H100上实现了每秒24帧、分辨率为736x416的实时流式传输视频生成，或在8xH100上生成长达一分钟（1440帧）的1280x720视频。
## 1094. `cs.LG` - DrKGC: 动态子图检索增强的大语言模型在一般领域和生物医学领域的知识图谱完成中 [PDF](https://arxiv.org/pdf/2506.00708), [HTML](https://arxiv.org/abs/2506.00708)
### Authors
Yongkang Xiao,Sinian Zhang,Yi Dai,Huixue Zhou,Jue Hou,Jie Ding,Rui Zhang
### Background
知识图谱（KGs）旨在通过利用现有三角关系和文本信息来预测其中的缺失三角关系。近年来，生成型大型语言模型（LLMs）被越来越多地用于图任务。然而，当前的方法通常主要将图上下文编码为文本形式，未能充分利用LLMs对图结构进行感知和推理的潜力。
### Innovation
提出了一种新颖的方法DrKGC（动态子图检索和辅助LLMs进行知识图谱完成）。该方法采用灵活的轻量级模型训练策略学习KG中的结构嵌入和逻辑规则。接着借助新颖的自底向上的图检索方法，根据学习到的规则为每个查询提取子图。最后，通过检索到的子图增强结构嵌入并将这些嵌入集成到提示中进行有效的大语言模型微调。实验结果表明，DrKGC在两个一般领域基准数据集和两个生物医学数据集上表现出优越的性能。此外，在生物医学领域的现实案例研究中，其可解释性和实用性得以进一步验证。
### Conclusion
实验结果说明了DrKGC在两个一般领域数据集和两个生物医学数据集上的优越性能，并且通过生物医学领域的实际案例证明了该方法的可解释性和实用性。
## 1095. `cs.LG` - 通过流匹配和可微优化进行模板导向的3D分子姿态生成 [PDF](https://arxiv.org/pdf/2506.06305), [HTML](https://arxiv.org/abs/2506.06305)
### Authors
Noémie Bergues,Arthur Carré,Paul Join-Lambert,Brice Hoffmann,Arnaud Blondel,Hamza Tajmouati
### Background
在药物设计中，预测小分子在蛋白质结合位点中的3D构象是一个关键挑战。当存在晶体化的参考配体（模板）时，可以利用几何先验来指导3D姿态预测。
### Innovation
提出了一种两阶段方法来根据模板生成配体构象。第一阶段采用基于流匹配的分子对齐方法生成配体的3D坐标；第二阶段采用基于可微优化的过程，在形状和药效团相似性、内部能量的基础上进一步优化该构象，必要时还可以结合蛋白质结合口袋的信息。
### Conclusion
通过一个新的共结晶配体对基准来说评估方法，结果显示该方法在模板相似度低或配体高度柔性的情况下，优于标准对接工具和开源对齐方法。
## 1096. `cs.LG` - 可解释的机器学习在城市热岛缓解中的应用：多尺度驱动因素的归因和加权 [PDF](https://arxiv.org/pdf/2507.04802), [HTML](https://arxiv.org/abs/2507.04802)
### Authors
David Tschan,Zhi Wang,Jan Carmeliet,Yongling Zhao
### Background
城市热岛（UHI）在热浪期间尤为凸显，对公共健康构成风险。减轻UHI需要城市规划者能够估算不同土地利用类型（LUTs）及其驱动因素如何影响不同尺度下的城市热。从宏观气候背景过程到微观的跨尺度特征，这些驱动因素需要从多个尺度进行分析。
### Innovation
本文提出了将驱动因素分为驱动（D）、城市（U）、和局部（L）特征的新方法。通过使用随机森林回归（RFR）结合极端梯度提升（XGB）机器学习模型，基于WRF（Weather Research and Forecasting模型）和Noah陆面模型（LSM），对热浪期间的Zurich地区的地表温度（TSK）和2米空气温度（T2）进行预测，提出了一种基于LUT的（LB）模型。该方法允许特定类别权重的加权，从而实现类别特定特征的排名和二米空气温度和地表温度对小尺度驱动因素的敏感性评估，特别是地表发射率、反照率和叶面积指数（LAI）。
### Conclusion
采用LB框架的模型比不采用LB框架的模型具有统计显著的准确性，且当更多的热浪数据纳入训练时，性能更高。尽管还需要降低不确定性并测试其他城市，该方法为城市规划者提供了一个直接框架，用于基于可行性的城市热岛缓解评估。
## 1097. `cs.LG` - LLMs真会忘记吗？基于知识关联与置信度意识的评估 [PDF](https://arxiv.org/pdf/2506.05735), [HTML](https://arxiv.org/abs/2506.05735)
### Authors
Rongzhe Wei,Peizhi Niu,Hans Hao-Hsun Hsu,Ruihan Wu,Haoteng Yin,Mohsen Ghassemi,Yifan Li,Vamsi K. Potluru,Eli Chien,Kamalika Chaudhuri,Olgica Milenkovic,Pan Li
### Background
现有的机器遗忘技术旨在减少大型语言模型（LLMs）中的意外记忆，但这些方法主要侧重于移除孤立的事实，而忽略了潜在推断依赖性和LLMs知识的非确定性。由此，被认为被遗忘的事实可能通过相关的信息隐秘地留存。
### Innovation
提出了一个知识遗忘评估框架，通过知识图谱表示相关事实背景，并结合置信度评分来捕捉现实世界的知识结构。该框架进一步开发了一种基于推理的评估协议，通过强大的LLMs作为评判者来验证遗忘效果。评判者通过精心设计的提示进行推理，并与人类评估相校准，以确保其可靠性和稳定性。
### Conclusion
广泛的实验展示了该框架为遗忘性能提供了更加真实和严格的评估。研究还表明，当前的评估策略往往会高估遗忘效果。代码已经公开。
## 1098. `cs.LG` - LEXam: 在340份法律考试中评估法律推理能力 [PDF](https://arxiv.org/pdf/2505.12864), [HTML](https://arxiv.org/abs/2505.12864)
### Authors
Yu Fan,Jingwei Ni,Jakob Merane,Yang Tian,Yoan Hermstrüwer,Yinya Huang,Mubashara Akhtar,Etienne Salimbeni,Florian Geering,Oliver Dreyer,Daniel Brunner,Markus Leippold,Mrinmaya Sachan,Alexander Stremitzer,Christoph Engel,Elliott Ash,Joel Niklaus
### Background
尽管大型语言模型（LLMs）在测试时的扩展方面取得了近期进展，但长篇法律推理依然是LLMs面临的关键挑战之一。传统的语言模型在处理复杂的、多步骤的法律推理任务时表现不佳。
### Innovation
作者引入了LEXam，这是一个新颖的数据集，基于340份法律考试题，涵盖了116个法律课程的不同科目和不同学位层次。数据集包括4,886个英文和德语文考试题，其中2,841个是开放性长篇问题，2,045个是多项选择题。开放性问题还提供了解释性指导，明确了预期的法律推理方法。这种方法对当前的LLMs提出了重大挑战，尤其是在需要结构化多步骤推理的开放性问题方面。此外，数据集通过明确区分模型之间的能力差异，展示了其效果。
### Conclusion
通过部署LLM-as-a-Judge的集成方法并结合严格的专家验证，作者展示了评估模型生成的推理步骤的有效性。评估框架提供了超越简单准确性的法律推理质量评估方法。研究成果已在GitHub和Hugging Face上开源，并提供了项目页面供进一步参考。
## 1099. `cs.LG` - 如果用另一种语言提问？跨语言功能相似性度量 [PDF](https://arxiv.org/pdf/2509.04032), [HTML](https://arxiv.org/abs/2509.04032)
### Authors
Debangan Mishra,Arihant Rastogi,Agyeya Negi,Shashwat Goel,Ponnurangam Kumaraguru
### Background
本文探讨了模型输出在不同语言之间的相似性。研究者使用了一个最近提出的模型相似性度量$text{textit{textbf{textit{textbf{κ}_p}}}}$，将其应用于GlobalMMLU中的20种语言和47个主题。分析结果表明，随着模型大小和能力的增加，模型在不同语言中的响应一致性也在提高。此外，模型在同一语言中的自我一致性远高于与其他模型之间的共识。
### Innovation
研究引入了模型相似性度量κ_p，这是评估多语言可靠性的一个实践工具。研究发现，随着模型的大小和能力增长，它们在不同语言中的反应一致性增强。更重要的是，模型在同一语言内的自我一致性高于与其他模型在同一语言内的共识。
### Conclusion
这些结果不仅凸显了κ作为评估多语言可靠性的实用工具的价值，还展示了它在指导开发更一致的多语言系统的潜力。
## 1100. `cs.LG` - VFP: 变分流匹配策略在多模态机器人操作中的应用 [PDF](https://arxiv.org/pdf/2508.01622), [HTML](https://arxiv.org/abs/2508.01622)
### Authors
Xuanran Zhai,Qianyou Zhao,Qiaojun Yu,Ce Hao
### Background
最近，基于流匹配的策略（flow-matching-based policies）已展现出在机器人操作中学习的新前景，尤其是在动作采样加速方面，与扩散型策略相比表现更加出色。然而，传统的流匹配方法在处理多模态任务时存在一定挑战，往往会导致动作采样简化为平均或模糊的行为。
### Innovation
本文提出了一种称为变分流匹配策略（VFP，Variational Flow-Matching Policy）的方法，引入了变分潜在先验以实现模式感知的动作生成，并能够有效捕捉任务级别的和轨迹级别的多模态特性。此外，VFP 进一步结合了 Kantorovich 最优传输（K-OT）用于分布层级的对齐，并使用了一个专家混合（Mixture-of-Experts, MoE）解码器，在模式专业化和高效推理方面发挥重要作用。
### Conclusion
本文通过在41个模拟任务和3个真实机器人任务上的全面评估，展示了VFP 在仿真和实际设置中的有效性和采样效率。结果表明，VFP 在仿真任务上的任务成功率相比标准的基于流的基线提高了49%，并且进一步在真实机器人任务中表现出色，同时保持了快速的推理速度和紧凑的模型大小。更多细节可参见我们的项目页面：this https URL
## 1101. `cs.LG` - 人工智能与数学物理科学未来 (AI+MPS] [PDF](https://arxiv.org/pdf/2509.02661), [HTML](https://arxiv.org/abs/2509.02661)
### Authors
Andrew Ferguson,Marisa LaFleur,Lars Ruthotto,Jesse Thaler,Yuan-Sen Ting,Pratyush Tiwary,Soledad Villar,E. Paulo Alves,Jeremy Avigad,Simon Billinge,Camille Bilodeau,Keith Brown,Emmanuel Candes,Arghya Chattopadhyay,Bingqing Cheng,Jonathan Clausen,Connor Coley,Andrew Connolly,Fred Daum,Sijia Dong,Chrisy Xiyu Du,Cora Dvorkin,Cristiano Fanelli,Eric B. Ford,Luis Manuel Frutos,Nicolás García Trillos,Cecilia Garraffo,Robert Ghrist,Rafael Gomez-Bombarelli,Gianluca Guadagni,Sreelekha Guggilam,Sergei Gukov,Juan B. Gutiérrez,Salman Habib,Johannes Hachmann,Boris Hanin,Philip Harris,Murray Holland,Elizabeth Holm,Hsin-Yuan Huang,Shih-Chieh Hsu,Nick Jackson,Olexandr Isayev,Heng Ji,Aggelos Katsaggelos,Jeremy Kepner,Yannis Kevrekidis,Michelle Kuchera,J. Nathan Kutz,Branislava Lalic,Ann Lee,Matt LeBlanc,Josiah Lim,Rebecca Lindsey,Yongmin Liu,Peter Y. Lu,Sudhir Malik,Vuk Mandic,Vidya Manian,Emeka P. Mazi,Pankaj Mehta,Peter Melchior,Brice Ménard,Jennifer Ngadiuba,Stella Offner,Elsa Olivetti,Shyue Ping Ong,Christopher Rackauckas,Philippe Rigollet,Chad Risko,Philip Romero,Grant Rotskoff,Brett Savoie,Uros Seljak,David Shih,Gary Shiu,Dima Shlyakhtenko,Eva Silverstein,Taylor Sparks,Thomas Strohmer,Christopher Stubbs,Stephen Thomas,Suriyanarayanan Vaikuntanathan,Rene Vidal,Francisco Villaescusa-Navarro,Gregory Voth,Benjamin Wandelt,Rachel Ward,Melanie Weber,Risa Wechsler,Stephen Whitelam,Olaf Wiest,Mike Williams,Zhuoran Yang,Yaroslava G. Yingling,Bin Yu,Shuwen Yue,Ann Zabludoff,Huimin Zhao,Tong Zhang
### Background
该社区论文源于2025年3月举办的国家科学基金会(NSF)举办的关于人工智能(AI)与数学物理科学(MPS)未来发展的工作坊。该工作坊旨在理解如何利用MPS领域(天文学、化学、材料研究、数学科学和物理学)的优势，为AI的未来发展做出贡献。这时MPS和AI之间的联系日益紧密。论文总结了MPS社区在2025年春季至夏季的看法，对于飞速发展的领域给予了一个快照。论文指出了在增强AI与科学之间联系和利用AI进行科学发现方面，迫切需要采取主动并深思熟虑的战略。
### Innovation
文章提出了几种活动和战略优先级建议，旨在实现MPS和AI之间的双向研究，建立跨学科的AI和MPS研究人员社区，并促进MPS研究人员和学生的AI教育与人才培养。这些策略有助于定位MPS社区，使其成为利用AI+MPS潜力的领导者。
### Conclusion
文章最后总结了建议的资金机构、教育机构和个人研究者等领域优先发展方向，旨在帮助MPS社区充分利用AI+MPS的变革潜力。
## 1102. `cs.LG` - 预测生成放大 [PDF](https://arxiv.org/pdf/2509.08048), [HTML](https://arxiv.org/abs/2509.08048)
### Authors
Henning Bahl,Sascha Diefenbacher,Nina Elmer,Tilman Plehn,Jonas Spinner
### Background
生成网络是增强高能物理实验中LHC模拟速度和精度的理想工具。然而，当生成数据集超过训练集大小时，理解其统计精度变得尤为重要。
### Innovation
提出了两种互补方法来估算放大因子，无需使用大量保留集数据。首先，平均放大利用贝叶斯网络或集成方法，通过估算给定相空间体积上积分的精度来估计放大。其次，差异放大利用假设检验来量化放大，而不会导致任何分辨率损失。这些方法应用于最先进的事件生成器，表明放大在相空间的特定区域是可能的，但在整个分布上尚未实现。
### Conclusion
这表明虽然在特定相空间区域可以实现放大，但在整个分布上仍需进一步研究以确保精准模拟。
## 1103. `cs.LG` - VAR-MATH: 通过符号多实例基准来检验LLMs的真实数学推理能力 [PDF](https://arxiv.org/pdf/2507.12885), [HTML](https://arxiv.org/abs/2507.12885)
### Authors
Jian Yao,Ran Cheng,Kay Chen Tan
### Background
近期强化学习（RL）的进展显著提升了大型语言模型（LLMs）在标准基准上的数学推理能力。然而，这些改进即使在使用不准确的信号（如随机或倒置奖励）的情况下仍然存在。这引发了一个问题：这些改进是否真正反映了推理能力，还是仅仅是针对特定基准模式的过拟合结果。传统评估策略存在两个关键局限性：一是基准污染，因为测试问题公开，增加了数据泄露的风险；二是评估脆弱性，依赖于单一实例评估，容易受到随机输出的影响，无法捕捉一致性推理。这些问题表明需要一个新的评估方法，能探查超越记忆与一次成功能力的真实推理。研究者提出了VAR-MATH，一种符号评估框架，将固定数值问题转换为参数化模板，要求模型解决每个问题的多次实例。这种设计保证了结构上等价变体的一致性，减少了污染，并通过自助评估增强鲁棒性。研究者将VAR-MATH应用于三个主流基准AMC23, AIME24 和AIME25，转换成其符号对应体VAR-AMC23, VAR-AIME24 和VAR-AIME25。实验结果显示，RL训练模型在这些变异基准上的性能大幅下降，尤其是小模型，AMC23平均下降47.9%，AIME24下降58.8%，AIME25下降72.9%。这些结果表明，一些现有的RL方法依赖浅层启发式方法，无法超越特定数字形式的泛化能力。
### Innovation
研究提出了VAR-MATH，一种新型的符号评估框架，用于更深入地检验LLMs的数学推理能力。该框架将固定数值问题转化为参数化的模板，并要求模型解决多个实例，以增强评估的鲁棒性和一致性。
### Conclusion
实验结果表明，一些现有RL方法由于依赖浅层启发式方法而在符号变异基准上表现不佳，这提示了现有的RL方法在深入理解问题上的不足。VAR-MATH提供了一种新的评估途径，有助于揭示模型真实推理能力，避免过拟合到特定模式。
## 1104. `cs.LG` - 多层时空过渡图表征学习的解缠学习及其在社会增强POI推荐中的应用 [PDF](https://arxiv.org/pdf/2508.07649), [HTML](https://arxiv.org/abs/2508.07649)
### Authors
Jie Li,Haoye Dong,Zhengyang Wu,Zetao Zheng,Mingrong Lin
### Background
POI推荐是商务智能的研究热点，用户的时空转移和社会关系起着关键作用。然而，现有大多数工作分别建模时空转移，导致同一时空关键节点的表示不一致，这在融合过程中引入冗余信息，增加了模型的不确定性，降低了可解释性。
### Innovation
介绍了一种名为DiMuST的社会增强POI推荐模型，该模型基于多层时空过渡图的解缠表示学习。该模型采用了一种新颖的多层时空图自动编码器（DAE），通过多层时空图策略首先分离共享和私有分布，然后使用专家乘积（PoE）机制融合共享特征，并通过对比约束噪声私有特征。该模型有效捕捉POI的时空转移表示，同时保留其时空关系的内在相关性。
### Conclusion
在两个具有挑战性的数据集上的实验表明，DiMuST在多个指标上显着优于现有方法。
## 1105. `cs.LG` - 通过病理知情领域随机化增强胎儿MRI中的内囊段分割 [PDF](https://arxiv.org/pdf/2508.20475), [HTML](https://arxiv.org/abs/2508.20475)
### Authors
Marina Grifell i Plana,Vladyslav Zalevskyi,Léa Schmidt,Yvan Gomez,Thomas Sanchez,Vincent Dunet,Mériam Koob,Vanessa Siffredi,Meritxell Bach Cuadra
### Background
准确的胎儿大脑分割对于提取生物标记和评估神经发育至关重要，尤其是在内囊发育不良（CCD）这样的情况下，其可导致严重的解剖变化。然而，CCD的罕见性严重限制了注释数据的可用性，阻碍了深度学习模型的泛化能力。
### Innovation
我们提出了一种病理知情领域的随机化策略，该策略将内囊发育不良的表现知识嵌入到合成数据生成管道中。通过仅从健康数据中模拟各种脑部变化，该方法能够在不需要病理注释的情况下实现稳健的分割。我们验证了该方法在由248名健康胎儿、26名CCD患者和47名其他脑部疾病患者组成的队列上，对CCD病例取得了显著改善，同时在健康胎儿和其他病理病例上也保持了性能。此外，从预测的分割中，我们推导出临床相关的生物标记，如内囊长度（LCC）和体积，并展示了这些生物标记在区分CCD亚型方面的应用价值。
### Conclusion
总体而言，这项工作表明在合成数据管道中融入特定领域的解剖先验知识可以有效缓解数据稀缺问题，提高罕见且临床意义重大的畸形分析的可靠性。
## 1106. `cs.LG` - 通过预测一致性和可靠性进行目标检测的自动化模型评估 [PDF](https://arxiv.org/pdf/2508.12082), [HTML](https://arxiv.org/abs/2508.12082)
### Authors
Seungju Yoo,Hyuk Kwon,Joong-Won Hwang,Kibok Lee
### Background
最近的计算机视觉进展使得训练目标检测器更加高效、有效，但评估这些检测器在实际应用中的性能仍然依赖于昂贵的手动标注。为解决这一问题，我们开发了一个用于目标检测的自动化模型评估（AutoEval）框架，称为预测一致性和可靠性（PCR）。PCR利用了传统检测器在非极大值抑制（NMS）之前生成的多个候选边界框。PCR通过联合测量1) 在进行NMS前后框的空间一致性，和2) 保留框的可靠性（通过重叠框的置信分数）来估计检测性能，无需地面真实标签。为了进行更现实和可扩展的评估，我们通过不同严重程度的图像破坏构建了一个元数据集。实验结果表明，PCR提供了比现有自动化评估方法更准确的性能评估，并且提出的元数据集覆盖了更宽的检测性能范围。
### Innovation
我们提出了预测一致性和可靠性（PCR），这是一种新颖的评估框架，能够准确地在无需 ground-truth 标注的情况下评估目标检测器的性能。该方法利用了检测器在非最大抑制（NMS）之前生成的多个候选边界框，并通过测量 NMS 前后的空间一致性以及重叠框的置信得分来评估这些边界框的可靠性。通过构建一个包含不同严重程度图像破坏的元数据集进行评估，该框架能够提供更精确的性能估计。此外，该自动化评估框架在公开代码库中进行了实现，为其他研究者提供了一个强大的工具。
### Conclusion
实验结果表明，PCR能够提供比现有自动评估方法更准确的性能评估。此外，我们提出的元数据集覆盖了更广泛的检测性能，为未来的研究提供了更丰富的数据集支持。
## 1107. `cs.LG` - Morphlux: 改变拓扑结构以提高多租户机器学习效率 [PDF](https://arxiv.org/pdf/2508.03674), [HTML](https://arxiv.org/abs/2508.03674)
### Authors
Abhishek Vijaya Kumar,Eric Ding,Arjun Devraj,Rachee Singh
### Background
当前，基于环形拓扑的数据中心在机器学习（ML）计算中占据主导地位，但这种架构在带宽、计算碎片和芯片故障影响下的表现不尽如人意。为了克服这些限制，研究人员开发了一种名为Morphlux的新技术。Morphlux是一种服务器级可编程光子架构，用于连接服务器内的加速器，旨在改善这些关键问题。Morphlux通过减少带宽分配的瓶颈、降低计算碎片化率以及最小化芯片故障的影响，提升了数据中心的性能。研究团队通过端到端的硬件原型展示了这些性能改进，使ML模型的训练吞吐量提高了1.72倍。此外，通过在硬件测试台中快速编程，Morphlux能够在1.2秒内替换故障的加速器芯片，提高了系统的可靠性和效率.
### Innovation
Morphlux的创新之处在于它提供了一种新的服务器级别的光子可编程架构，用于优化服务器内部的加速器连接。通过增强最先进的基于环形的数据中心基础设施，Morphlux实现了以下改进：带宽提升66%，计算碎片减少70%，并能迅速替换故障芯片。这是通过一种全新的端到端硬件原型实现的，该原型展示了显著的性能提升，对于服务器内计算和加速器的高效管理具有重大意义，尤其适用于多租户机器学习环境.
### Conclusion
Morphlux成功地改善了基于环形的机器学习数据中心性能，解决了带宽、计算碎片和芯片故障等问题。通过快速且灵活的硬件重构，Morphlux还能够在短时间内恢复系统运作，提高了数据中心的鲁棒性和效率。这一创新技术具有广泛的应用前景，特别是在需要高效处理大量数据的机器学习任务中表现出色。
## 1108. `cs.LG` - PurpCode: 基于推理的安全代码生成 [PDF](https://arxiv.org/pdf/2507.19060), [HTML](https://arxiv.org/abs/2507.19060)
### Authors
Jiawei Liu,Nirav Diwan,Zhe Wang,Haoyu Zhai,Xiaona Zhou,Kiet A. Nguyen,Tianjiao Yu,Muntasir Wahed,Yinlin Deng,Hadjer Benkraouda,Yuxiang Wei,Lingming Zhang,Ismini Lourentzou,Gang Wang
### Background
当前，代码安全问题日益突出，传统的训练方法难以确保生成的代码完全安全。研究人员提出了一种新的方法来训练安全代码推理模型，以生成安全代码并抵御恶意网络活动。
### Innovation
提出了一种名为PurpCode的新方法，该方法包括两个阶段：(i) 规则学习，明确教授模型引用网络安全性规则以生成无漏洞代码并避免促进恶意网络活动；(ii) 强化学习，通过多样化的多目标奖励机制来优化模型的安全性和保持模型的功能性。通过红队攻击，PurpCode方法生成了全面而高覆盖率的提示，基于真实世界的任务来诱发不安全的网络活动。
### Conclusion
基于PurpCode，开发了一种基于推理的编码模型PurpCode-32B，其在网络安全方面的表现达到了最先进的水平，优于各种前沿模型。此外，该方法在一般和网络安全性特定场景下降低了模型的过度拒绝率，同时保持了代码生成和常规安全知识中的模型功能。
## 1109. `cs.LG` - 生成侧特征感知的伪造用户资料以操纵推荐系统 [PDF](https://arxiv.org/pdf/2509.17918), [HTML](https://arxiv.org/abs/2509.17918)
### Authors
Yuanrong Wang,Yingpeng Du
### Background
推荐系统（RS）对用户的消费决策影响巨大，因此成为恶意评分攻击的目标。现有的评分攻击方法在训练数据仅包含评分矩阵时，可以生成有效的隐蔽的伪造用户资料，但这些方法在包含侧特征并被推荐系统利用的场景中缺乏全面的解决方案。因此，研究如何在包含侧特征的情况下生成有效的隐蔽的伪造用户资料成为亟待解决的问题。
### Innovation
本文通过增强生成器架构来扩展Leg-UP框架，使生成器能够生成具有侧特征感知能力的伪造用户资料。实验表明，该方法在实现攻击效果的同时保持了隐蔽性，为含有侧特征情况下的恶意评分攻击提供了新的解决方案。
### Conclusion
实验结果证明了该方法在包含侧特征的情况下生成有效并具有隐蔽性的伪造用户资料的能力，显著提高了攻击的效果。
## 1110. `cs.LG` - AlgoTune：语言模型能否加速通用数值程序？ [PDF](https://arxiv.org/pdf/2507.15887), [HTML](https://arxiv.org/abs/2507.15887)
### Authors
Ori Press,Brandon Amos,Haoyu Zhao,Yikai Wu,Samuel K. Ainsworth,Dominik Krupke,Patrick Kidger,Touqir Sajed,Bartolomeo Stellato,Jisun Park,Nathanael Bosch,Eli Meril,Albert Steppi,Arman Zharmagambetov,Fangzhao Zhang,David Perez-Pineiro,Alberto Mercurio,Ni Zhan,Talor Abramovich,Kilian Lieret,Hanlin Zhang,Shirley Huang,Matthias Bethge,Ofir Press
### Background
尽管语言模型（LM）的能力有所进步，但现有评估主要集中在人类之前已经解决的任务上，包括编程（Jimenez等人，2024）和数学（Glazer等人，2024）。本研究旨在测试模型设计和实现算法的能力，通过构建一个开放性的基准AlgoTune，要求LM编写高效解决计算机科学、物理学和数学中的计算挑战问题的代码。此基准包含154个来自专家的编码任务，并且提供了一个验证和测量LM生成的解决方案代码的框架，与流行的开源包提供的参考实现进行比较。研究表明，与依赖SciPy、sk-learn和CVXPY等库的参考求解器相比，当前模型仅在表面优化方面表现出色，但在发现算法创新方面表现不佳。
### Innovation
论文提出了AlgoTune基准，用于测试语言模型在编写高效解决复杂计算问题代码方面的能力。此外，该论文还开发了一个基础LM代理AlgoTuner，并评估了其在一系列先进模型上的性能。AlgoTuner通过简单的循环编辑代码、编译并运行代码、测量性能、验证测试的正确性并选择最快的有效版本来工作。该研究发现AlgoTuner在平均速度上比参考求解器快1.72倍，但模型未能发现算法创新。
### Conclusion
AlgoTune旨在推动语言模型代理的发展，以实现超越顶尖人类表现的创造性问题解决能力。
## 1111. `cs.LG` - SpeechWeave：用于训练文本到语音模型的多样化多语言合成文本和音频数据生成管道 [PDF](https://arxiv.org/pdf/2509.14270), [HTML](https://arxiv.org/abs/2509.14270)
### Authors
Karan Dua,Puneet Mittal,Ranjeet Gupta,Hitesh Laxmichand Patel
### Background
高质量的文本到语音（TTS）模型训练需要大量的多样化文本和语音数据。由于领域专一性、版权和扩展性问题，从真实来源获取此类数据非常具有挑战性。大型语言模型可以生成文本数据，但在生成过程中可能产生重复的文本且缺乏多样性。此外，文本规范化工具有时会引入异常或忽略有价值的模式，从而影响数据质量。在大量商业TTS系统中依赖声艺艺术家进行语音录制也是不实际的。
### Innovation
我们提出了SpeechWeave，这是一种合成语音数据生成管道，能够自动化生成多语言、领域特定的训练数据集。实验结果表明，我们的管道生成的数据在各种语言和音位指标上比基准提高了10-48%的多样性，同时生成标准发音的语音音频，同时生成的文本正确规范化率约为97%。这种方法能够实现可扩展且高质量的TTS训练数据生成，提高生成数据集中的多样性和规范化，确保声一致。
### Conclusion
SpeechWeave管道使得TTS训练数据生成更加高效，能够产生多样化、高质量和规范化的训练数据，从而改进生成数据集的语音一致性和规范化水平。这种方法为大规模、标准化的语音录制提供了可能的解决方案，并为TTS系统的训练提供了支持。
## 1112. `cs.LG` - GSM-Agent：使用可控环境理解代理推理 [PDF](https://arxiv.org/pdf/2509.21998), [HTML](https://arxiv.org/abs/2509.21998)
### Authors
Hanlin Zhu,Tianyu Guo,Song Mei,Stuart Russell,Nikhil Ghosh,Alberto Bietti,Jiantao Jiao
### Background
随着大语言模型（LLM）被越来越多地部署为智能代理，代理推理——结合工具使用尤其是搜索和逻辑推理的能力——成为一项关键技能。然而，在复杂的环境和任务中评估代理推理非常困难，当前的代理评估基准往往会混杂复杂的数学推理、专家级知识等多种高级能力。本文旨在填补这一空白，提出了一个新型基准GSM-Agent，要求LLM代理解决小学生级别的推理问题，但仅在提示中提供问题而未提供包含解决问题所需信息的背景，需要利用工具主动获取这些信息。尽管原始任务是小学生级别的数学题，但即使是最新的模型如GPT-5也只能达到67%的准确率。
### Innovation
文章提出了GSM-Agent基准，这种基准要求LLM代理解决小学生级别的推理问题，并仅在提示中提供问题而未提供包含解决问题所需信息的背景。此外，文章还提出了代理推理图的概念，可以将环境文档嵌入聚类成节点，并映射每个工具调用到最近的节点以构建推理路径。值得注意的是，研究发现许多模型在代理推理中很少具备重新访问先前访问节点的能力，这在静态推理中被视为关键模式。基于这一洞见，文章还提出了一种工具增强的测试时扩展方法，通过增加工具来鼓励模型重新访问，以提高代理推理能力。这将有助于未来对于理解并拓宽代理推理边界的研究所做出的贡献。
### Conclusion
文章构建了GSM-Agent基准，通过这一基准，可以帮助未来的研究深入理解并提升大语言模型的代理推理能力。文章还提出了一种新的代理推理图框架和工具增强的测试时扩展方法，以更有效地评估和增强代理推理能力。
## 1113. `cs.LG` - nDNA -- 人工认知的语义螺旋 [PDF](https://arxiv.org/pdf/2509.18216), [HTML](https://arxiv.org/abs/2509.18216)
### Authors
Amitava Das
### Background
随着AI基础模型能力的增长，一个更深层次的问题浮现出来：除了流畅性和输出之外，是什么塑造了它们内部的认知身份？目前的基准测试只衡量行为，但模型的核心灵魂体现在其潜在的几何结构中。本文旨在解决这一问题，提出了一种名为nDNA（神经DNA）的语义-基因型表示，通过信念内在几何结构捕捉这一潜在身份。
### Innovation
nDNA作为一个语义-基因型的表示方法，它通过三个内在的几何维度来捕捉这种潜在身份：光谱曲率揭示了概念流跨层的曲率；热力学长度量化了通过各层展开表示转换所需的意义努力；以及信念矢量场，描述了引导模型信念方向性的语义扭转场。这种方法类似于生物DNA，共同编码了祖先、突变和意义的遗传，这些特征存在于微调和对齐伤痕、文化印记和结构漂移中。此提案开启了Neural Genomics的新领域，即模型不仅是工具，还是具有可追踪内部认知的数字语义生物。
### Conclusion
在DNA命名后，本文提出了模型语义流动力学的概念：意义通过各层像流体通过形管一样被传输；nDNA是该流的物理级别的读出，即如何意义被弯曲、支付和推移的几何学首选度量，产生了一种与输入行为相连的稳定的、坐标自由的神经DNA指纹。通过这种方法，我们可以跨入生物学领域，追踪从预训练、微调、对齐、剪枝、蒸馏和合并阶段中的世代传承，测量检查点间的遗传信息，检测在新数据或目标下属性的漂移，并最终研究人工认知的演变，以进行模型比较、风险诊断和治理随着时间变化的变更。
## 1114. `cs.LG` - 流匹配在模型失拟条件下稳健的基于模拟的推理 [PDF](https://arxiv.org/pdf/2509.23385), [HTML](https://arxiv.org/abs/2509.23385)
### Authors
Pierre-Louis Ruhlmann,Pedro L. C. Rodrigues,Michael Arbel,Florence Forbes
### Background
基于模拟的推断（SBI）正在通过使实验科学能够从模拟数据中估计复杂非线性模型的参数而改变实验科学。然而，一个持续的挑战是模型失拟：模拟器只是现实的近似，模拟数据与真实数据之间的差异可能导致有偏的或过度自信的后验概率。现有的SBI方法在面对模型失拟时表现不佳，尤其是在真实数据与模拟数据分布不匹配时，导致推断性能下降和不确定性的不适当校准。
### Innovation
本文提出了一种名为Flow Matching Corrected Posterior Estimation（FMCPE）的新框架，该框架利用流匹配范式来利用少量真实校准样本改进基于模拟训练的后验估计器。该方法分为两阶段：首先，在丰富模拟数据上训练后验逼近器；然后，通过流匹配将预测结果调整到由真实观测支持的真后验，无需明确知道模型失拟的具体情况。FMCPE框架结合了SBI的可扩展性，并且能够抵抗分布偏移的挑战，从而提高了推断的稳健性。
### Conclusion
本文通过合成基准和实际数据集展示了FMCPE框架的有效性，表明它可以稳健地处理模型失拟，提高推断准确性并改进不确定性校准，同时保持高效计算。
## 1115. `cs.LG` - 重新思考多标签音频分类中的探针：激活补丁令牌 [PDF](https://arxiv.org/pdf/2509.24901), [HTML](https://arxiv.org/abs/2509.24901)
### Authors
Lukas Rauch,René Heinrich,Houtan Ghaffari,Lukas Miklautz,Ilyass Moummad,Bernhard Sick,Christoph Scholz
### Background
尽管对冻结模型进行探针已成为标准的评估范式，但在音频领域，自我监督学习默认为微调。关键原因在于全局池化造成了信息瓶颈，使得线性探针误解嵌入的质量：cls-标记丢弃掉了关于分散且局部事件的关键令牌信息。这一缺陷源于预训练目标（全局操作）与下游任务（局部事件）之间的不匹配。研究在涵盖13个数据集和6种光谱图编码器的全面基准上，首先探讨了全局池化瓶颈问题，进而提出了二元原型探针：一种轻量级且简单的池化方法，通过学习原型来进行类别级别的信息聚合。
### Innovation
该研究引入了二元原型探针，这是一种轻量级且简单的池化方法，用于类别级别的信息聚合，尽管其简单，但显著优于线性和注意探针。这项工作确立了探针作为评估音频SSL模型的竞争性和高效范式，挑战了对昂贵微调的依赖。
### Conclusion
通过使用二元原型探针，研究提出了一个评估音频SSL模型的范式，展示了优于传统方法的性能，强调了探针评估的有效性。
## 1116. `cs.LG` - 基于全局示范的分布式多机器人策略的 curriculum 被模仿学习 [PDF](https://arxiv.org/pdf/2509.25097), [HTML](https://arxiv.org/abs/2509.25097)
### Authors
Jesús Roche,Eduardo Sebastián,Eduardo Montijano
### Background
多机器人系统(MRS)的控制策略学习仍然是一个重大挑战，由于需要长期协调以及很难获得现实的训练数据。因此，该研究在模仿学习框架下，同时解决了这两个问题。具体而言，它改变了 Curriculum Learning 的典型角色，并将其应用于改善长期协调，而不是用于机器人数量的可扩展性。此外，该研究提出了一种通过远程视角全局状态示范来近似每个机器人本体感知的方法，将其转化为局部可用观察，并生成包罗万象的技术来从观察中生成可扩展和分布式策略。
### Innovation
在模仿学习框架下，改善多机器人系统中的长期协调问题。通过引入一种通过远程视角全局状态示范来近似每个机器人本体感知的方法，生成包罗万象的策略以减少专家行动和配备传感器测量的需求。该方法不仅能够提高策略的长期准确性，还能使其对现实中的不确定性具有鲁棒性。
### Conclusion
通过结合 Curriculum 被模仿学习策略和局部感知方法，能够在没有专家行为或配备传感器测量的情况下，从全局示范中学习鲁棒的分布式控制器，实验显示了该方法的有效性。
## 1117. `cs.LG` - FTSCommDetector：通过时间同步发现行为社区 [PDF](https://arxiv.org/pdf/2510.00014), [HTML](https://arxiv.org/abs/2510.00014)
### Authors
Tianyang Luo,Xikun Zhang,Dongjin Song
### Background
尽管苹果（AAPL）和微软（MSFT）属于相同的行业分类，但在市场动荡时期却表现出不同的响应模式，这引发了悖论。传统社区检测方法无法捕捉同步-非同步模式，即实体在关键时刻虽然是独立移动但也能够同步的现象。
### Innovation
本文介绍了FTSCommDetector，通过实施时间一致性架构（TCA）来发现连续多元时间序列中的相似和不同社区。该方法通过双尺度编码和静态拓扑与动态注意力保持一致性，不同于现有方法独立处理每个时间戳，从而实现稳定社区分配和对变化关系的捕捉。此外，该研究建立了信息论基础以展示尺度分离如何最大化互补信息，并引入了标准化时间概况（NTP）进行尺度不变评估。
### Conclusion
FTSCommDetector在四个不同的金融市场上实现了持续改进，与最强的基线相比，改进幅度从3.5%到11.1%不等。方法具有显著的鲁棒性，在60至120天的不同窗口大小下仅2%的性能波动，使得特定数据集的调整变得不必要，为投资组合构建和风险管理提供了实用见解。
## 1118. `cs.LG` - CrediBench：构建大规模网络数据集以确保信息完整性 [PDF](https://arxiv.org/pdf/2509.23340), [HTML](https://arxiv.org/abs/2509.23340)
### Authors
Emma Kondrup,Sebastian Sabry,Hussein Abdallah,Zachary Yang,James Zhou,Kellin Pelrine,Jean-François Godbout,Michael M. Bronstein,Reihaneh Rabbany,Shenyang Huang
### Background
在线虚假信息正不断升级，互联网的开放特性和越来越强大能够生成有说服力但又是欺骗性的内容的LLM（大型语言模型）加剧了这一威胁。现有的虚假信息检测方法通常关注文本内容或网络结构之一，而未能充分利用现实生活中的虚假信息生态系统的互补特性，即网页内容及其超链接关系之间的丰富、动态的交互作用。
### Innovation
我们引入了CrediBench：一个大规模数据处理管道，用于构建联合模型化网页内容和超链接结构的时限网络图，从而进行虚假信息检测。我们的方法捕捉到了一般虚假信息领域的动态演变，包括随着时间推移的内容变化和站点间引用的变化。我们从中提取了2024年12月来自Common Crawl存档的一个月切割图，拥有4500万个节点和1亿条边，是迄今为止为虚假信息研究公开的最大网络图数据集。
### Conclusion
通过对这个网络图片段的实验，我们展示了结构信号和网页内容信号在学习信誉分数方面的作用，这些分数衡量了信息源的可靠性。该管道和实验代码均在此公开，数据集文件也在此公开可用。
## 1119. `cs.LG` - 通过特征解缠完成多领域脑血管分割 [PDF](https://arxiv.org/pdf/2510.00665), [HTML](https://arxiv.org/abs/2510.00665)
### Authors
Francesco Galati,Daniele Falcetta,Rosa Cortese,Ferran Prados,Ninon Burgos,Maria A. Zuluaga
### Background
脑血管的复杂形态对自动分割模型构成显著挑战，这些模型通常专注于单一成像模态。然而，准确治疗与大脑相关的疾病需要对整个脑血管树有全面理解，无论具体的获取方法是什么。现有的模型在执行脑血管图像分割时遇到困难，尤其是在处理多领域和不同类型时。本框架通过图像到图像的转换技巧有效分割不同数据集中的脑动脉和静脉，同时避免了特定领域的模型设计和源域与目标域之间的数据协调。
### Innovation
该框架利用解纠缠技术独立操作不同的图像特性，使这些特性能够在保持标签的情况下从一个领域转移到另一个领域。它特别强调适应过程中的血管外观调整，同时保持空间信息，如形状和位置，这对于正确的分割至关重要。此外，研究还对所需注解的数量和其他架构选择进行了消融研究。结果表明了该框架的稳健性和通用性，展示了领域适应方法在多种场景下对脑血管图像分割的潜力。
### Conclusion
本研究通过克服多领域和多种情况下的分割挑战，展示了基于解纠缠技术的方法在脑血管图像分割中的优势。代码已发布，供进一步研究使用。
## 1120. `cs.SE` - 解读WONTFIX：GitHub问题被拒绝的混合方法研究 [PDF](https://arxiv.org/pdf/2510.01514), [HTML](https://arxiv.org/abs/2510.01514)
### Authors
J. Alexander Curtis,Sharadha Kasiviswanathan,Nasir Eisty
### Background
在GitHub代码库中，'wontfix'标签是一个被广泛使用但理解有限的工具，用于标记问题将不再进一步处理。尽管其使用普遍，但这个标签对项目管理和开源软件开发中社区动态的影响尚未得到明确定义。
### Innovation
本文采用混合方法，通过分析定量数据了解GitHub上标签为'wontfix'问题的普遍程度，并通过质性分析探索使用该标签的理由，将这些理由划分为八个常见主题，提供了一个结构化的项目问题管理景观理解.
### Conclusion
研究表明，大约30%的GitHub项目会将'wontfix'标签应用于某些问题，这些问题大多数出现在用户提交的错误报告和功能请求中。结果显示，有八种常见原因导致问题被标记为’wontfix‘，分布在用户特定控制因素和维护者特定的决策之间。'wontfix'标签是管理资源和引导贡献者努力的重要工具，但也可能抑制社区参与并使项目管理的透明度模糊。理解这些原因有助于项目经理做出明智的决策，并促进开源社区内的有效协作.
## 1121. `cs.LG` - 欧几里得之礼：通过几何代理任务增强视觉语言模型的空间感知和推理能力 [PDF](https://arxiv.org/pdf/2509.24473), [HTML](https://arxiv.org/abs/2509.24473)
### Authors
Shijie Lian,Changti Wu,Laurence Tianruo Yang,Hang Yuan,Bin Yu,Lei Zhang,Kai Chen
### Background
空间智能涵盖了诸如可视化和变换形状、心理旋转物体、判断相对位置和包含关系以及估算数量等丰富的能力。然而，这些能力对于多模态大型语言模型（MLLMs）来说仍然是一个关键的未解决的挑战。我们提出了将欧几里得几何问题解决作为代理任务来填补这一空白。为此，我们精心构建了一个包含约30,000个平面和实体几何问题的众多人机双模态数据集，名为Euclid30K。通过采用Group Relative Policy Optimization (GRPO)对Qwen2.5VL和RoboBrain2.0家族进行微调，我们的目标是使模型能够识别形状、计数和关联实体，并利用欧几里得原理进行多步演绎推理。实验表明，结果模型在四个空间推理基准(Super-CLEVR、Omni3DBench、VSI-Bench和MindCube)上实现了显著的零样本收益，没有进行任何特定任务的调整。尤其是，经过Euclid30K训练后，所有评估模型的均值VSI-Bench准确率从34.5%提高到40.5%，提高了5.5个百分点。其中，RoboBrain2.0-Euclid-7B的准确率达到49.6%，超过了此前的最佳模型，据统计，这是首个系统性地表明几何导向的微调可以赋予视觉语言模型广泛的空间技能的研究。代码和Euclid30K数据集可在相关链接处找到。
### Innovation
通过精心构建的Euclid30K数据集，将欧几里得几何问题解决作为代理任务，并采用Group Relative Policy Optimization (GRPO)对多模态大型语言模型进行微调。这一方法使得模型能够在基于几何原理的空间推理任务上获得显著的零样本性能提升，尤其是在VSI-Bench基准测试中，表明它可以提升模型在空间感知和推理方面的能力，并且首次证明了这种方法可以赋予视觉语言模型广泛适用的空间技能。
### Conclusion
经过针对欧几里得几何的微调后，所有评估模型的VSI-Bench准确率有了显著提高，特别是在没有特定任务调整的情况下，RoboBrain2.0-Euclid-7B表现最佳，优于当前最佳模型。这一研究首次系统性地展示了针对几何方面的微调可以增强视觉语言模型的空间技能。研究成果和Euclid30K数据集均已公开。
## 1122. `cs.SE` - MIMIC: 使用大型语言模型整合多样个性特征以改进游戏测试 [PDF](https://arxiv.org/pdf/2510.01635), [HTML](https://arxiv.org/abs/2510.01635)
### Authors
Yifei Chen,Sarra Habchi,Lili Wei
### Background
现代电子游戏对传统的自动化测试算法构成了巨大挑战，但全面的测试对于确保游戏质量至关重要。因此，研究人员使用强化学习、模仿学习或大型语言模型设计了游戏代理。然而，这些代理往往忽略了人类玩家使用的多样策略，导致在类似情况下会出现重复解决方案的问题。因此，它们难以触发多样化的游戏内互动或发现边缘情况。因此，需要一种能够整合多样化个性特征的游戏代理框架，以提高测试覆盖范围和丰富游戏内互动。
### Innovation
本文提出了MIMIC框架，这是一种将多样个性特征整合到游戏代理中的新框架。通过模仿不同的游戏风格，MIMIC能够在不同类型的游戏中实现更高的测试覆盖率和更丰富的游戏内互动。此外，MIMIC在Minecraft中表现出色，任务完成率更高，提供了更多样化的解决方案。这些结果突显了MIMIC在有效游戏测试方面的巨大潜力。
### Conclusion
MIMIC框架通过整合多样个性特征和模仿不同的游戏风格，显著提高了游戏代理的测试覆盖率和游戏内互动的丰富性。在Minecraft中的表现表明MIMIC在自动化测试中具有很大的潜力，能够更全面地覆盖游戏测试的不同方面。
## 1123. `cs.LG` - GeoSQL-Eval: 首次基于PostGIS的NL2GeoSQL查询评估 [PDF](https://arxiv.org/pdf/2509.25264), [HTML](https://arxiv.org/abs/2509.25264)
### Authors
Shuyang Hou,Haoyue Jiao,Ziqi Liu,Lutong Xie,Guanyu Chen,Shaowen Wu,Xuefeng Guan,Huayi Wu
### Background
大型语言模型（LLMs）在通用数据库中的自然语言到SQL（NL2SQL）任务方面表现出色，但在扩展到GeoSQL时，由于引入了空间数据类型、函数调用和坐标系等问题，增加了生成和执行的难度。现有基准主要针对通用SQL，缺乏系统的GeoSQL评估框架。
### Innovation
本文介绍了第一套端到端自动化评估框架GeoSQL-Eval，以及一个用于评估LLM在NL2GeoSQL任务中的表现的基准GeoSQL-Bench。GeoSQL-Bench定义了三个任务类别（概念理解、语法级SQL生成和模式检索），共包含14,178个实例、340个PostGIS函数和82个主题性数据库。GeoSQL-Eval基于Webb的深度知识模型，涵盖了四个认知维度、五个能力级别和二十种任务类型，从知识获取到语义对齐、执行准确性和鲁棒性建立了全面的过程。最后，使用熵权法和统计分析评估24个代表性模型，发现了性能差异、常见错误模式和资源使用情况，并公开了一个 GeoSQL-Eval 领导者板平台进行持续测试和全球比较。
### Conclusion
本文扩展了NL2GeoSQL paradigm，并提供了一个标准、可解释和可扩展的框架，用于在空间数据库环境中评估LLMs，为地理空间信息科学及相关应用提供有价值的参考。
## 1124. `cs.LG` - 使用纵向数据改进虚拟对比增强 [PDF](https://arxiv.org/pdf/2510.00418), [HTML](https://arxiv.org/abs/2510.00418)
### Authors
Pierre Fayolle,Alexandre Bône,Noëlie Debs,Philippe Robert,Pascal Bourdon,Remy Guillevin,David Helbert
### Background
钆剂（GBCAs）在磁共振成像（MRI）中广泛用于增强病变检测和表征，尤其是在神经肿瘤学中。然而，关于钆剂在大脑和身体组织中的保留和积累的担忧，特别是在需要密切监测和频繁注入GBCA的疾病中，已经提出了必要的减量策略。为解决这一问题，本研究提出了一种深度学习框架，用于从对应的低剂量采集中增强全剂量对比后的T1加权MRI图像。
### Innovation
该研究贡献在于利用纵向信息，并通过从同一患者中纳入先前的全剂量MRI检查，实现纵向对比增强。对比结果显示，纵向方法在多个重建指标中显著提高了图像质量。同时，不同模拟对比剂量的试验也证实了所提出方法的鲁棒性。这些结果强调了在深度学习的虚拟对比增强管道中整合先前成像历史的潜力，可以在不牺牲诊断效果的前提下减少GBCA的使用，从而为更安全和可持续的纵向监测提供临床MRI实践的道路。
### Conclusion
本研究通过利用纵向数据增强了虚拟对比增强的图像质量，证明了这种方法在实际临床中的潜力，为减少钆剂使用的同时提高MRI诊断的可持续性和安全性提供了新的方法。
## 1125. `cs.SE` - FOSS-chain: 使用区块链实现开源软件许可合规 [PDF](https://arxiv.org/pdf/2510.01740), [HTML](https://arxiv.org/abs/2510.01740)
### Authors
Kypros Iacovou,Georgia M. Kapitsaki,Evangelia Vanezi
### Background
开源软件（OSS）被广泛使用，并带有许可证，这些许可证规定了软件使用、修改和分发的条件。确保用户在创建衍生作品时遵守OSS许可证条款是一个复杂的任务。由于许可证之间的不兼容性可能导致法律纠纷，同时，区块链技术提供了不可变的记录机制，可以提供透明性，确保软件更改被记录。因此，本文旨在通过将区块链与许可证管理集成到创建衍生作品的过程当中，解决开源软件许可证兼容性问题。研究设计、实施了FOSS-chain，一个基于区块链的网络平台，能够自动化许可合规过程，并涵盖14种开源许可证。
### Innovation
本文创新地提出了FOSS-chain平台，这是一个基于区块链的网络平台，能够自动化开源软件的许可合规过程，并能涵盖14种开源许可证。这项研究旨在通过区块链技术解决开源软件许可证之间的兼容性问题，促进了开源软件领域的透明管理。通过初步用户研究初步评估了该平台的原型版本，结果表明该平台在现实软件系统中有很大的潜在适应性与应用价值。
### Conclusion
本文初步展示了FOSS-chain平台的应用潜力，该平台能够通过区块链技术实现开源软件许可合规的自动化，可以广泛应用于实际的开源软件系统中，为开源软件的使用和管理提供了新的解决方案。尽管初步研究结果乐观，但仍需进一步大规模验证和优化该平台，以适应更复杂的开放源生态系统。
## 1126. `cs.SE` - ARENA：一种用于测量和分析Android应用程序能量效率的工具 [PDF](https://arxiv.org/pdf/2510.01754), [HTML](https://arxiv.org/abs/2510.01754)
### Authors
Hina Anwar
### Background
为了构建节能型应用程序，需要在典型使用场景中估算和分析其能耗。通过硬件和软件方法都可以计算Android应用程序的能耗。尽管软件方法实现起来更容易，但其准确度不及硬件方法。硬件方法通常涉及设置测量环境、在移动设备上执行应用程序、通过硬件设备记录电流/电压数据以测量能耗、清理和聚合数据进行分析、报告和可视化等步骤。这些步骤使得硬件能耗测量过程耗时且不易适应和重现。目前，市场上缺乏可靠的开发和研究工具来利用硬件设备进行能耗测量。
### Innovation
本文介绍了ARENA，这是一个支持工具，使开发者和研究人员在离开IDE舒适环境的情况下也可以连接物理测量设备。ARENA通过在开发中执行测试场景来计算Android智能手机上的能量消耗，并进一步帮助聚合、统计分析、报告和可视化数据，使用户可以直接或可视化地深入研究数据。ARENA被实现为IntelliJ和Android Studio插件，方便用户使用。
### Conclusion
ARENA简化了硬件能耗测量的过程，使开发人员和研究人员能够更轻松地在Android应用程序中进行能耗分析。通过创建此类支持工具，该论文为提高Android应用程序的能效提供了一个实用的解决方案。
## 1127. `cs.SE` - 使用非自回归模型加快程序修复 [PDF](https://arxiv.org/pdf/2510.01825), [HTML](https://arxiv.org/abs/2510.01825)
### Authors
Zhenyu Yang,Yue Pan,Zhen Yang,Zhongxing Yu
### Background
近年来，机器学习技术在不同应用领域取得了成功，激发了对使用机器学习技术进行自动程序修复（APR）的研究热潮。早期基于机器学习的APR技术主要采用自回归（AR）方式，预测未来值取决于过去值，这导致了巨大的修复延迟，特别是在参数较多的模型中延迟更加严重。
### Innovation
本文提出了一种新的非自回归（NAR）方法——NARRepair，专门用于APR任务。NARRepair具有三个主要创新点：1）修复动作预测器，以缓解过矫正问题；2）跨令牌依赖提取器，缓解缺乏跨令牌依赖信息的问题；3）两阶段解码器，缓解缺乏上下文信息的问题。该方法在GPU环境下将修复速度提高了1.4到6.4倍，并在修复质量和速度上达到了最先进的水平。
### Conclusion
NARRepair模型在修复时间和准确性方面都表现出优异的综合性能。与自回归（AR）方法相比，NARRepair模型的修复速度提高了1.4到6.4倍，并且在限定的修复时间内性能最佳。
## 1128. `cs.SE` - 超越单一LLM：通过多阶段性能导向的LLM编排提升代码生成 [PDF](https://arxiv.org/pdf/2510.01379), [HTML](https://arxiv.org/abs/2510.01379)
### Authors
Huashan Chen,Zhenyu Qi,Haotang Li,Hong Chen,Jinfu Chen,Kebin Peng,In Kee Kim,Kyu Hyung Lee,Sen He
### Background
大型语言模型（LLMs）已成为自动化代码生成的主要范式，但当前的单一模型方法未能充分利用不同模型在编程语言、算法领域和开发阶段展现的不同计算优势。本文通过多阶段、性能导向的编排框架，动态地将编程任务路由到最适合的LLMs，提出了多层次的生成-修复-精炼工作流。该工作基于涵盖5种编程语言（Python、Java、C++、Go、Rust）的17种最新的LLM在HumanEval-X基准测试上的全面实证研究，该研究评估了功能正确性和运行时性能指标（执行时间、平均/最大内存利用率和CPU效率），揭示了语言、开发阶段和问题类别之间的显著性能差异。
### Innovation
尽管不需对模型进行微调，提出的PerfOrch框架仍显著超越了强大的单一模型基线：在HumanEval-X和EffiBench-X基准测试上正确率分别达到96.22%和91.37%，超过了GPT-4o的78.66%和49.11%。此外，该架构还实现了性能优化，对于58.76%的问题提高了解决时间，范围从17.67%到27.66%，在不同语言上的中位速增比为17.67%到27.66%。该架构的即插即用特性确保了实际的可扩展性，使新的LLM能够无缝集成到系统中，从而为适应快速发展的生成式AI领域的生产级自动软件工程提供了一个范式。
### Conclusion
本文提出了一种新的编排框架，通过多阶段性能导向的方法，动态将编程任务分配给最适合的LLM，显著改进了代码生成的任务效率和性能。该框架适用于多种编程语言，并能无缝集成新的模型，从而建立了适应生成式AI发展的自动化软件工程新范式。
## 1129. `cs.SE` - 基于张量的实时多模态逃票和欺诈检测：更公平的公共交通 [PDF](https://arxiv.org/pdf/2510.02165), [HTML](https://arxiv.org/abs/2510.02165)
### Authors
Peter Wauyo,Dalia Bwiza,Alain Murara,Edwin Mugume,Eric Umuhoza
### Background
本文介绍了一种多模态系统，该系统通过分析闭路电视（CCTV）和音频数据来检测公共交通中的欺诈和逃票行为。系统的训练和测试数据集为自定义数据集，准确度达到了89.5%，精确度为87.2%，召回率为84.0%，检测欺诈活动的效果显著优于早期融合基线，并且超出了当前先进公共交通欺诈检测系统的75%的召回率。
### Innovation
该研究创新性地使用Vision Transformer for Video (ViViT)模型进行视频特征提取和Audio Spectrogram Transformer (AST)进行音频分析。系统采用张量融合网络(TFN)架构，通过2次笛卡尔乘积明确建模单模态和双模态交互，这种高级融合技术捕捉了视觉行为（如连续插队、未经授权的访问）与音频线索（如费用交易声音）之间的复杂跨模态动态。对比传统的连接方法的Ablation研究显示，张量融合方法在F1分数上提高了7.0%，在召回率上提升了8.8%。
### Conclusion
该系统支持实时检测，公共交通运营商可以利用该系统减少收入损失、提高乘客安全并确保运营合规性。
## 1130. `cs.SE` - RefFilter：通过具有重构意识的静态分析提高语义冲突检测 [PDF](https://arxiv.org/pdf/2510.01960), [HTML](https://arxiv.org/abs/2510.01960)
### Authors
Victor Lira,Paulo Borba,Rodrigo Bonifácio,Galileu Santos e Matheus barbosa
### Background
在协作软件开发中，检测语义干扰仍然是一个挑战。虽然最近的轻量级静态分析技术提高了效率，但它们仍然无法避免高的假阳性率。假阳性的主要原因是存在保持行为的代码重构，而现有技术不能有效地区分这些重构与那些影响行为并可能导致干扰的更改。为了解决这个问题，引入了RefFilter，这是一种具有重构意识的语义干扰检测工具。它基于现有的静态技术，并通过结合自动重构检测来提高精确度，从而从报告中丢弃保持行为的重构，减少假阳性同时保持检测覆盖性。
### Innovation
RefFilter是一种重构意识的语义干扰检测工具，通过结合自动重构检测，从报告中剔除保持行为的重构，从而降低假阳性率，同时保持检测覆盖面。为了评估其有效性和可扩展性，使用了两个数据集：一个包含99个场景和真实标签的标注数据集，和一个全新的、包含1087个多样化合并场景的数据集。实验结果显示，在标注数据集上，RefFilter将假阳性减少了近32%。尽管假阴性增加了一个不显著的量，但精确度的整体增益远远超过了召回率的轻微下降，证明了重构意识的干扰检测是一种实用有效的现代开发流程中合并支持策略。
### Conclusion
这些发现证明了具有重构意识的干扰检测是提高现代开发流程中合并支持的一种实用和有效的方法。
## 1131. `cs.SE` - TAIBOM：提升AI驱动系统可信度 [PDF](https://arxiv.org/pdf/2510.02169), [HTML](https://arxiv.org/abs/2510.02169)
### Authors
Vadim Safronov,Anthony McCaigue,Nicholas Allott,Andrew Martin
### Background
开源软件和AI驱动技术的整合引入了软件供应链的新复杂性，挑战了现有的依赖管理方法和系统保障方式。SBOM已成为增强透明性和追踪性的关键工具，但现有框架在捕捉AI系统的独特特性（动态性、数据驱动性及跨数据集、模型和软件组件的松散耦合依赖关系）方面存在不足。这些挑战因治理结构的碎片化和缺乏确保AI环境完整性、信任和合规性的强大工具而加剧。
### Innovation
本文介绍了一种名为TAIBOM的新框架，它扩展了SBOM原则以适应AI领域。TAIBOM提供了一种针对AI组件定制的结构化依赖模型、跨异构AI管道传播完整性声明的机制以及验证组件来源的可信证明过程。该框架支持AI工作流中的保障、安全和合规要求，并在ASSURED等现有标准的优势方面进行了对比分析。
### Conclusion
通过结构性软件透明度，TAIBOM工作为基础来构建可信和可验证的AI系统。
## 1132. `cs.SE` - 基础模型在拟物理系统软件工程中的应用：前行之路 [PDF](https://arxiv.org/pdf/2504.04630), [HTML](https://arxiv.org/abs/2504.04630)
### Authors
Chengjie Lu,Pablo Valle,Jiahui Wu,Erblin Isaku,Hassan Sartaj,Aitor Arrieta,Shaukat Ali
### Background
近年来，尤其是大型语言模型（LLMs）被广泛用于软件工程的各种活动（例如编码和测试），特别是在拟物理系统（CPS）的软件工程中应用增长。然而，该领域的研究仍相对有限，且现有研究主要集中在LLMs（一种类型的基础模型），意味着对于视觉语言模型等其他类型基础模型的研究还有很多机会。
### Innovation
本文提出了一条整合基础模型（FMs）到CPS软件工程各个阶段的研究路线图，并突出软件工程领域的关键研究机会和挑战。文章还讨论了在CPS软件工程场景中应用FMs面临的一般性挑战，包括FM生成的产物的正确性，以及FMs固有的不确定性与幻觉问题。
### Conclusion
该路线图旨在为CPS软件工程的研究者和技术人员提供未来研究方向，以帮助他们利用FMs在该领域进行研究和发展。
## 1133. `cs.SE` - SIEVE: 向代码数据集可验证认证迈进 [PDF](https://arxiv.org/pdf/2510.02166), [HTML](https://arxiv.org/abs/2510.02166)
### Authors
Fatou Ndiaye Mbodji,El-hacen Diallo,Jordan Samhi,Kui Liu,Jacques Klein,Tegawendé F. Bissyande
### Background
公共代码数据集在代码代理和经验性软件工程中被广泛应用，但这些数据集缺乏可验证的质量保证。目前的‘数据集卡片’虽然提供了信息，但无法被审计，也不提供统计保证，这使得难以证明数据集的质量。团队在开发过程中构建独立且临时的清理管道，这导致了努力分散和成本上升。
### Innovation
SIEVE 是一种社区驱动的框架，将单属性检查转换为自信卡片——一种机器可读、可验证的证书，提供始终有效的统计界限。这旨在取代叙述性卡片，实现随时可验证的认证。该转变预期将降低质量保证的成本，并增加对代码数据集的信任度。
### Conclusion
通过引入SIEVE，研究计划旨在将代码数据集的质量认证成熟化，并通过可验证认证降低质量保证成本，同时提高对代码数据集的信任度。
## 1134. `cs.SE` - ACM SIGSOFT SEN 实验软件工程：介绍我们新的定期栏目 [PDF](https://arxiv.org/pdf/2510.02007), [HTML](https://arxiv.org/abs/2510.02007)
### Authors
Justus Bogner,Roberto Verdecchia
### Background
从20世纪70年代的早期基础发展起，实验软件工程(ESE)已经演变成一个成熟的科研领域，涵盖了各种不同的主题、方法论和工业实践。尽管取得了显著的进步，但ESE研究领域仍然需要继续发展，以应对新的挑战和技术的出现。诸如研究可重复性、外部有效性有限、评审的主观性以及将研究成果用于工业实践等问题是推动ESE研究改进的因素之一。此外，ESE研究的一些方面并没有明确记录下来，这使得初学者难以掌握。因此，目的设立一个新的定期的ACM SIGSOFT SEN栏目(SEN-ESE)，为讨论ESE研究的元方面提供了一个平台，包括复现包的性质与最佳实践，到更复杂的话题如统计方法、采访转录工具和跨学科研究的发表等，旨在激发关于ESE话题的定期对话，而这些问题可能不会经常被触及或明确记载。贡献将基于专家访谈、焦点小组、调查和观点文章，最终目标是鼓励我们如何进行、交流、教学以及改进ESE研究的反思和改进。最后，栏目还将邀请ESE社区对有争议、未充分探索的主题提供反馈，并建议希望听取的声音。尽管并不能保证每一个想法都能实现，但我们将围绕社区兴趣来塑造这个栏目并感谢所有贡献。
### Innovation
设立了新的定期栏目SEN-ESE，专注于讨论ESE研究的元方面，包括复现方法、统计方法、访谈转录工具和跨学科研究等内容，促进对这些领域更深层次的探讨和改进，并指定贡献形式为专家访谈、焦点小组、调查和观点文章。
### Conclusion
栏目旨在为ESE话题提供一个定期对话的平台，促进反思和改进，鼓励社区参与，并收集反馈以不断优化研究的进行、交流、教学和改进。
## 1135. `cs.SE` - KTBox: 一个模块化LaTeX框架，用于语义色彩、结构化高亮和学术交流 [PDF](https://arxiv.org/pdf/2510.01961), [HTML](https://arxiv.org/abs/2510.01961)
### Authors
Bhaskar Mangal,Ashutosh Bhatia,Yashvardhan Sharma,Kamlesh Tiwari,Rashmi Verma
### Background
在科学手稿中，技术洞察的传达往往依赖于临时的格式选择，导致视觉强调不一致且缺乏文档类间的可移植性。目前的做法使得视觉样式更多是作为表面上的修饰而存在，缺乏跨文档类的应用性和可重复性。
### Innovation
本文介绍了一个名为ktbox的模块化LaTeX框架，它将语义色彩调色板、结构化突出显示和提取环境、分类树结构和作者元数据工具等整合成一个统一的系统，适用于学术写作。框架以命名空间组件形式分发，每个组件可以独立使用但又能相互兼容，确保与主要模板（如IEEEtran、acmart、ICLR会议和beamer）兼容。该框架的核心功能包括自编号的提取盒子、宽格式的突出显示、灵活的分类树可视化以及支持嵌入式表格、列举和代码块的多栏布局。通过明确划分关注点并采用一致的命名约定来命名框架下的kt组件，该框架将视觉样式转变为可重现且可扩展的科学交流基础块，从而提高文章、海报和演讲的清晰度、可移植性和撰写效率
### Conclusion
KTbox框架通过对学术写作中视觉样式进行重构，实现了语义色彩、结构化高亮和作者元数据等元素的统一管理，增强了科学交流的清晰度、可移植性和效率，填补了当前学术写作工具在格式化和可扩展性方面的空白，使得文档能够更加符合学术规范且易于适应多种学术出版格式。
## 1136. `cs.SE` - FalseCrashReducer: 使用有代理人工智能减轻OSS-Fuzz-Gen中的假阳性崩溃 [PDF](https://arxiv.org/pdf/2510.02185), [HTML](https://arxiv.org/abs/2510.02185)
### Authors
Paschal C. Amusuo,Dongge Liu,Ricardo Andres Calvo Mendez,Jonathan Metzman,Oliver Chang,James C. Davis
### Background
模糊测试已成为识别软件错误和安全漏洞的核心技术，广泛应用于工业和开源社区中。直接对函数进行模糊测试需要模糊驱动程序，将随机模糊器输入转换为目标函数的有效参数。由于手动构建模糊驱动程序的成本和专业知识需求，已存在利用程序分析和大型语言模型自动生成驱动程序的方法。然而，生成的模糊驱动程序常导致假阳性崩溃，特别是在具有高度结构化输入和复杂状态要求的函数中。这对OSS-Fuzz等大规模模糊驱动程序生成工作尤为重要，因为报告假阳性崩溃给维护者会降低系统和团队的信任度。
### Innovation
本文提出两种基于人工智能的策略以减少OSS-Fuzz-Gen中的假阳性崩溃。第一，基于约束的模糊驱动程序生成主动地对函数输入和状态施加约束，以指导驱动程序的创建。第二，基于上下文的崩溃验证在报告崩溃后，分析函数调用者，确定从程序入口点这些崩溃是否现实可行。
### Conclusion
研究结果表明，利用这两大策略可以减少假性崩溃8%，显著降低报告的崩溃数量，并且前沿的人工智能模型能够作为可靠的程序分析代理。这突显了将人工智能集成到大规模模糊测试流水线中的潜力和挑战。
## 1137. `cs.SE` - 使用耳静脉图案识别的异质品种猪身份识别：针对小规模农场应用的机器学习方法 [PDF](https://arxiv.org/pdf/2510.02197), [HTML](https://arxiv.org/abs/2510.02197)
### Authors
Emmanuel Nsengiyumvaa,Leonard Niyitegekaa,Eric Umuhoza
### Background
准确的畜牧识别是现代农业的基石，支持健康监测、育种计划和生产力跟踪。然而，常见的猪身份识别方法，如耳标和微芯片，经常不可靠、成本高、仅适用于纯种，因此对小规模农户不具备实用性。
### Innovation
我们提出了一种非侵入性的生物识别方法，利用耳静脉的独特性来进行猪的身份识别。我们收集了800张耳部图像（来自于20头由兰德race和皮特兰以及杜洛克和皮特兰杂交的猪），使用标准智能手机和简单的背光拍摄。开发了多阶段计算机视觉管道来增强静脉可见性、提取结构和空间特征，并生成生物识别签名。然后使用机器学习模型进行分类。支持向量机（SVM）达到了最高精度，准确识别跨品种猪种的精度为98.12%。从图像处理到分类的整个过程平均耗时8.3秒，展示了其在实时农业园场部署的可行性。此系统通过使用永久的生物学标记替代易碎的物理标识符，为农民提供了一种成本效益高且减少动物受到压力的方法。
### Conclusion
研究结果证明耳静脉生物识别技术在数字化畜牧管理中的实用性，增强了其在资源有限农业社区推广的好处。
## 1138. `cs.SE` - 用于单元测试生成的上下文示例语义澄清 [PDF](https://arxiv.org/pdf/2510.01994), [HTML](https://arxiv.org/abs/2510.01994)
### Authors
Chen Yang,Lin Yang,Ziqi Wang,Dong Wang,Jianyi Zhou,Junjie Chen
### Background
最近的大语言模型（LLMs）在通过上下文学习（ICL）生成单元测试方面取得了显著进展。然而，上下文示例的质量强烈影响生成测试的效果，结构不良或语义不清晰的单元测试示例往往会导致生成的测试效果不佳。
### Innovation
本文提出了一种新的技术CLAST，它系统地细化单元测试以提高语义清晰度，从而增强其作为上下文示例的实用性。CLAST通过程序分析和基于LLM的重写来分解复杂的测试，并提高语义清晰度。在四开源项目和三个工业项目上的评估表明，CLAST在保留测试效果和增强语义清晰度方面远超当前最先进的细化技术UTgen。CLAST使生成的测试保留了原有效果，而UTgen将编译成功率、通过率、测试覆盖率和突变分数分别降低了12.90%、35.82%、4.65%和5.07%。85.33%的用户研究参与者更喜欢CLAST细化测试的语义清晰度。进一步的用户研究结果表明，将CLAST细化的测试用作示例有效地改善了基于ICL的单元测试生成方法，如RAGGen和TELPa，生成测试的编译成功率、通过率和覆盖率分别提高了25.97%、28.22%和45.99%，而UTgen细化的测试则没有这种效果。
### Conclusion
CLAST的进一步用户研究结果不仅证实了其在软件测试实践中的潜在影响，还为未来研究提供了新的方向。
## 1139. `cs.SE` - LitterBox+: A可扩展框架用于增强Scratch静态代码分析的LLM [PDF](https://arxiv.org/pdf/2509.12021), [HTML](https://arxiv.org/abs/2509.12021)
### Authors
Benedikt Fein,Florian Obermüller,Gordon Fraser
### Background
大型语言模型（LLMs）已成为开发人员使用传统基于文本的编程语言的重要工具，但是基于图形块的Scratch编程环境的图形化表示法阻碍了LLMs的使用。LitterBox+框架通过将基于块的代码转换为适合LLMs的文本表示形式，延伸了LitterBox静态代码分析工具，使得用户能够查询LLMs关于他们的程序、LitterBox报告的质量问题以及生成代码修复。
### Innovation
LitterBox+框架将Scratch静态代码分析工具LitterBox的分析能力与LLMs的生成能力相结合，通过编程API和增强的Scratch用户界面，用户可以直接在熟悉的环境中查询LLMs关于程序的信息，以及生成代码修复。这是通过将基于块的代码转换为适合LLMs的文本形式实现的。此外，框架设计用于其他提示、LLMs提供者和新功能的扩展，结合LitterBox的程序分析能力和LLMs的生成特征。
### Conclusion
LitterBox+框架提供了一种便捷的方式将LLMs的能力应用于Scratch编程环境。通过示屏演示展示了该工具的应用。
## 1140. `cs.SE` - LLMs和知识图谱的协同作用：软件仓库相关问题解答的新方法 [PDF](https://arxiv.org/pdf/2412.03815), [HTML](https://arxiv.org/abs/2412.03815)
### Authors
Samuel Abedu,SayedHassan Khatoonabadi,Emad Shihab
### Background
软件仓库包含了理解开发过程所需的重要信息，但提取这些仓库数据中的见解既耗时又需要专业技术。现有的软件工程聊天机器人虽然支持与仓库进行自然语言交互，但在理解超出其训练意图的问题和准确检索相关数据方面存在局限性。本研究旨在通过在基于LLM的聊天机器人中增加知识图谱的支持，提高它们在回答仓库相关问题的准确性。
### Innovation
采用两步方法：从仓库数据中构建知识图谱，并与LLM协同工作以处理自然语言的问题和答案。通过这种方式，聊天机器人能够更好地理解复杂的问题，并准确地检索相关数据。此外，引入了少量链式思考提示来提升准确性。
### Conclusion
研究结果表明，通过整合LLM和知识图谱的方法可以提高对仓库数据的访问性。实验数据显示，与基准（MSRBot和GPT-4o-search-preview）方法相比，该方法在准确性上有了显著提升，并在基于任务的用户研究中得到了用户的肯定评价。
## 1141. `cs.SE` - 使用大型语言模型进行精确类型错误检测的反思单元测试生成 [PDF](https://arxiv.org/pdf/2507.02318), [HTML](https://arxiv.org/abs/2507.02318)
### Authors
Chen Yang,Ziqi Wang,Yanjie Jiang,Lin Yang,Yuteng Zheng,Jianyi Zhou,Junjie Chen
### Background
Python中的类型错误在运行时可能导致失败，这对软件可靠性和开发人员的效率提出了重大挑战。现有的静态分析工具旨在通过执行来检测这些错误，但通常会产生较高的假阳性率。近年来，单元测试生成技术展现出巨大的潜力，但在不进行特制指导的情况下，往往难以生成能揭示错误的测试用例。为了应对这些限制，我们提出了RTED，一种新颖的类型感知测试生成技术，用于自动检测Python类型错误。RTED结合逐步类型约束分析与反思验证来引导测试生成过程，有效抑制假阳性。我们使用BugsInPy和TypeBugs两个广泛使用的基准进行了评估，结果显示，RTED可以比四种最先进的技术多检测到22-29个类型的基准错误。此外，RTED也能产生较少的假阳性，精确度提高了173.9%-245.9%。最重要的是，RTED成功发现了6个真实世界的开源Python项目中未知的12个类型错误。
### Innovation
RTED是一种新颖的类型感知测试生成技术，通过逐步类型约束分析与反射验证来指导测试生成过程，有效减少了假阳性。与最先进的技术相比，RTED在检测到的类型错误数量和精确度上有所提升，并成功发现了一些未被发现的类型错误。
### Conclusion
RTED能够在检测类型错误方面表现出色，通过评估验证了其在真实项目中的有效性和准确性，是提高Python程序可靠性和开发人员生产力的重要方法。
## 1142. `cs.SE` - LSPFuzz: 搜索语言服务器中的漏洞 [PDF](https://arxiv.org/pdf/2510.00532), [HTML](https://arxiv.org/abs/2510.00532)
### Authors
Hengcheng Zhu,Songqiang Chen,Valerio Terragni,Lili Wei,Jiarong Wu,Yepang Liu,Shing-Chi Cheung
### Background
语言服务器协议(LSP)在现代软件开发中的代码智能集成方面起到了革命性的作用。目前大约有300种不同语言的LSP服务器实现，以及50种提供LSP集成的编辑器。尽管LSP的广泛采用，但LSP服务器的可靠性问题正在成为一个日益突出的担忧，因为服务器崩溃会禁用所有代码智能功能，严重影响生产力，而漏洞则会让开发者在编辑不受信任的源代码时处于风险中。尽管如此，在LSP领域中仍然缺乏专门针对LSP服务器进行测试的技术。
### Innovation
我们提出了LSPFuzz，一种灰盒混合型模糊测试器，用于系统性地测试LSP服务器。我们的核心见解是，有效的LSP服务器测试需要源代码和编辑器操作的全面变异，因为很多错误是由于它们的组合方式而产生的。为了满足LSP的复杂约束并有效地探索输入空间，我们采用了一个两阶段的变异管道：语法感知的源代码变异，随后是上下文感知的编辑操作调度。
### Conclusion
我们在四种广泛使用的LSP服务器上评估了LSPFuzz。与基线模糊测试器相比，LSPFuzz表现出更好的性能，并在实际LSP服务器中发现了未知的错误。在报告的51个错误中，42个已被确认，26个已被开发者修复，2个已被分配CVE编号。我们的研究提升了LSP服务器的质量保证，并提供了实用工具和基础见识，为该领域的未来研究奠定了基础。
## 1143. `cs.SE` - 自适应机器人软件工程：研究议程 [PDF](https://arxiv.org/pdf/2505.19629), [HTML](https://arxiv.org/abs/2505.19629)
### Authors
Hassan Sartaj,Shaukat Ali,Ana Cavalcanti,Lukas Esterle,Cláudio Gomes,Peter Gorm Larsen,Anastasios Tefas,Jim Woodcock,Houxiang Zhang
### Background
自适应机器人系统在动态和不确定环境中自主操作，需要具备抗干扰的实时监控和适应性行为。传统的以预定义逻辑为基础的机器人软件无法应对这些挑战，而自适应机器人则借助人工智能、机器学习和模型驱动工程实现持续的适应性，以确保系统的可靠、安全和最优表现。本文旨在构建一个面向自适应机器人软件工程的研究议程，涵盖了自适应机器人软件生命周期以及支撑其运行的基础技术。
### Innovation
本文的研究议程针对自适应机器人特有挑战，提出了软件生命周期方法与基础技术的应用，包括数字孪生、AI驱动的适应性、以及量子计算，以支持运行时监控、故障检测和自动决策。研究还指出了几个关键挑战，如在不确定条件下验证适应性行为、平衡适应性、性能和安全性之间的权衡、以及将如MAPE-K/MAPLE-K这样的自适应框架进行整合集成，为未来2030年前的自我适应机器人系统的可信赖和高效性奠定基础
### Conclusion
本文通过汇编这些挑战形成的路线图，致力于构建能够应对现实世界部署复杂性的可信赖且高效的自适应机器人系统的基础。
## 1144. `cs.SE` - CRUST-Bench：从C到安全Rust转换的综合基准 [PDF](https://arxiv.org/pdf/2504.15254), [HTML](https://arxiv.org/abs/2504.15254)
### Authors
Anirudh Khatry,Robert Zhang,Jia Pan,Ziteng Wang,Qiaochu Chen,Greg Durrett,Isil Dillig
### Background
C-to-Rust转换对于现代化的遗留C代码至关重要，同时提高了与现代Rust生态系统的互操作性和安全性。然而，目前尚无用于评估系统能否将C代码转换为通过一组测试案例运行的正确、安全的Rust代码的数据集。本文介绍了CRUST-Bench，这是一个包含100个C仓库的数据集，每个仓库都与手工书写的符合Rust语法和安全规范的接口以及用于验证转换正确性的测试用例配对。通过考虑整个仓库而非孤立的函数，CRUST-Bench捕捉到跨多个文件的复杂项目之间的依赖关系带来的挑战。
### Innovation
CRUST-Bench为C-to-Rust转换提供了一个完整的基准测试数据集，包括整个仓库、手工书写的符合Rust语法和安全规范的接口以及用于验证转换正确性的测试用例。该数据集特别考虑了多文件间依赖关系的复杂性，确保生成的Rust代码不仅语法正确而且内存安全。此外，论文评估了最先进的大语言模型在转换任务上的表现，发现生成符合Rust语法和安全规范的Rust代码仍然是一项具有挑战性的问题。文章还提供了一些关于大语言模型在C-to-Rust转换过程中常见错误的分析。
### Conclusion
CRUST-Bench将推动改进转换系统以应对复杂场景，并帮助从C语言迁移到如Rust能确保内存安全的其他语言。最佳模型OpenAI o1在单次尝试中仅解决了15个任务。改善CRUST-Bench将有助于提高能够处理复杂场景的转换系统的设计，从而加速从C语言向具有内存安全性能的语言的迁移过程。
## 1145. `cs.SE` - 基于搜索的软件工程与AI基础模型：当前状况和未来路线图 [PDF](https://arxiv.org/pdf/2505.19625), [HTML](https://arxiv.org/abs/2505.19625)
### Authors
Hassan Sartaj,Shaukat Ali,Paolo Arcaini,Andrea Arcuri
### Background
搜索导向的软件工程（SBSE）结合了元启发式搜索技术与软件工程，已经成为了近25年的研究热点。它在软件工程生命周期的各个阶段都有广泛的应用，并在多个领域展示了其灵活性。随着人工智能（AI）的最新进展，特别是大语言模型（LLMs）等基础模型（FMs）的出现，SBSE与这些模型的进化路径尚未明确。基于这一时机，文章提出了一个研究路线图，旨在阐述SBSE与FMs之间的现状，识别开放的挑战，并规划未来的研究方向。
### Innovation
文章提出了一种将基础模型（FMs）引入搜索导向的软件工程（SBSE）的研究道路图。具体分析了五个核心方面：利用FMs进行SBSE设计、将FMs应用于补充SBSE以解决软件工程问题、使用SBSE应对FMs挑战、适应FMs为软件工程活动量身定制SBSE实践、探索SBSE和FMs之间的协同潜力。文章还展望了在FMs时代SBSE的未来，并指出了新兴领域的研究机会。
### Conclusion
文章提出了一个关于SBSE与FMs之间关系的研究方向，并预见了未来机会。
## 1146. `cs.SE` - GeoSQL-Eval: 第一个PostGIS基础自然语言到GeoSQL查询的评价框架 [PDF](https://arxiv.org/pdf/2509.25264), [HTML](https://arxiv.org/abs/2509.25264)
### Authors
Shuyang Hou,Haoyue Jiao,Ziqi Liu,Lutong Xie,Guanyu Chen,Shaowen Wu,Xuefeng Guan,Huayi Wu
### Background
大型语言模型（LLMs）在通用数据库中的自然语言转结构化查询（NL2SQL）任务中表现出色，但在扩展到GeoSQL时，会因为空间数据类型、函数调用和坐标系统的复杂性增加生成和执行的难度。现有的基准测试主要针对通用SQL，对于GeoSQL系统性的评估框架仍然不足。
### Innovation
本文提出GeoSQL-Eval，这是首个用于PostGIS查询生成的端到端自动化评价框架，与其配套的GeoSQL-Bench基准测试用于评估LLMs在NL2GeoSQL任务中的性能。GeoSQL-Bench定义了三个任务类别：概念理解、语法级别SQL生成和模式检索，包含14,178个实例、340个PostGIS函数和82个主题数据库。GeoSQL-Eval基于Webb的知识深度（DOK）模型，涵盖了四个认知维度、五个能力层级和二十种任务类型，建立了从知识获取到语义对齐、执行精度和鲁棒性的全面流程。评估了24种代表性模型，并使用熵权法和统计分析揭示性能差异、常见的错误模式和资源消耗。
### Conclusion
这项工作扩展了NL2GeoSQL范式，提供了一个标准化、可解释和可扩展的框架，用于评估在空间数据库上下文中LLMs的表现，为地理空间信息科学及相关应用提供了宝贵参考。
## 1147. `cs.SE` - AlgoTune: 语言模型能否加速通用数值程序？ [PDF](https://arxiv.org/pdf/2507.15887), [HTML](https://arxiv.org/abs/2507.15887)
### Authors
Ori Press,Brandon Amos,Haoyu Zhao,Yikai Wu,Samuel K. Ainsworth,Dominik Krupke,Patrick Kidger,Touqir Sajed,Bartolomeo Stellato,Jisun Park,Nathanael Bosch,Eli Meril,Albert Steppi,Arman Zharmagambetov,Fangzhao Zhang,David Perez-Pineiro,Alberto Mercurio,Ni Zhan,Talor Abramovich,Kilian Lieret,Hanlin Zhang,Shirley Huang,Matthias Bethge,Ofir Press
### Background
尽管语言模型（LM）的能力有所提升，目前的评估主要集中在人类已经解决的任务上，包括编程（Jimenez等，2024）和数学（Glazer等，2024）。然而，本研究提议了一个开放式的基准测试来衡量模型在设计和实现算法方面的能力，特别是在计算机科学、物理学和数学中的复杂计算问题。该基准测试名为AlgoTune，包括154个由领域专家收集的编码任务，以及一种验证和测量LM生成的解决方案代码的方法，将其与流行的开源包中的参考实现进行比较。此外，还开发了一个基础线LM代理AlgoTuner，并评估了它在一系列前沿模型中的性能。AlgoTuner采用一个简单的、预算化的循环来编辑代码、编译并运行它、分析性能、验证测试正确性并选择最快的合法版本。在对比参考解决方案后，AlgoTuner实现了1.72倍的速度提升。然而，研究发现当前的模型未能发现创新算法，倾向于表面级优化。
### Innovation
本研究首次通过AlgoTune基准测试，评估了语言模型在编程和算法实现方面的表现，并提出了一种名为AlgoTuner的基础线LM代理。AlgoTuner利用简单的预算循环来编辑、编译和运行代码，分析性能，验证正确性并选择最快的有效版本，展示了在现有技术上的性能提升。研究结果揭示了模型在发现创新算法方面的局限性，强调了未来研究的潜力，即开发能够进行创造性问题解决的LM代理，超越顶级人类性能。
### Conclusion
通过AlgoTune基准测试，本研究展示了语言模型在加速通用数值程序方面的能力，同时也揭示了当前模型在发现算法创新方面的不足。未来的研究需要关注如何开发能够超越顶级人类表现并展示创造力的LM代理。
## 1148. `cs.SE` - CodeSense：现实世界的基准和数据集，用于代码语义推理 [PDF](https://arxiv.org/pdf/2506.00750), [HTML](https://arxiv.org/abs/2506.00750)
### Authors
Monoshi Kumar Roy,Simin Chen,Benjamin Steenhoek,Jinjun Peng,Gail Kaiser,Baishakhi Ray,Wei Le
### Background
理解与推理代码语义对于增强代码大语言模型（LLMs）解决实际软件工程（SE）任务的能力至关重要。尽管存在一些代码推理解题集，但大多数依赖于合成数据集或教育编码问题，主要集中在粗粒度的推理任务上，如输入/输出预测，限制了它们在评估LLMs的实际SE背景中的有效性。
### Innovation
该研究提出了CodeSense，这是第一个提供涉及现实世界代码软件工程细粒度代码推理任务的基准。它收集了真实的Python、C和Java软件项目，并执行这些仓库的测试，收集执行跟踪并构建了一个细粒度语义推理任务的真值数据集。此外，该研究还产生了一个执行跟踪框架和工具集，简化了收集细粒度SE推理任务真值的过程。
### Conclusion
研究结果表明，模型在处理细粒度推理任务方面存在明显的绩效差距。尽管有诸如链条思维和上下文学习的提示技术的改进帮助，但代码语义的缺失从根本上限制了模型的代码推理能力。该研究强调了构建细粒度SE推理任务基准和模型后续训练的基础作用。
## 1149. `cs.SE` - 为初学者调试器设计：一项关于AI辅助调试工具的试点研究 [PDF](https://arxiv.org/pdf/2509.21067), [HTML](https://arxiv.org/abs/2509.21067)
### Authors
Oka Kurniawan,Erick Chandra,Christopher M. Poskitt,Yannic Noller,Kenny Tsu Wei Choo,Cyrille Jegourel
### Background
调试是初学者程序员必须掌握的一项基本技能。已有多款工具被开发用于帮助初学者进行调试。最近，大型语言模型（LLMs）与自动化程序修复技术结合，为学生错误代码生成修复方案。然而，许多这些工具让初学者过度依赖AI，缺乏主动参与调试过程。因此，本文旨在设计一个名为CodeHinter的直观调试助手，该助手结合传统调试工具和基于LLM的技术，帮助初学者修复语义错误，同时促进其在调试过程中的主动参与。本研究的第二版进行了测试，并得到了一组本科生的反馈。研究表明，该工具在解决问题方面效果显著，且使用更为便捷。错误定位是最重要的功能之一。
### Innovation
本文提出了一个结合传统调试工具和基于LLM的技术的AI辅助调试助手，CodeHinter。这款助手旨在帮助初学者修复语义错误，并促进他们积极主动地参与调试过程。此外，研究还强调，任何AI辅助的调试方法都应根据用户特征进行个性化设计，以优化其与工具的交互。
### Conclusion
本研究表明，AI辅助调试工具的有效性应根据用户特征进行个性化设计。错误定位是用户认为最有价值的功能。未来的AI辅助调试工具应更加注重用户体验和个人化，以提高初学者的调试效率和兴趣。
## 1150. `cs.SE` - 网络物理WebAssembly：安全的硬件接口和可插拔驱动 [PDF](https://arxiv.org/pdf/2410.22919), [HTML](https://arxiv.org/abs/2410.22919)
### Authors
Michiel Van Kenhove,Maximilian Seidler,Friedrich Vandenberghe,Warre Dujardin,Wouter Hennen,Arne Vogel,Merlijn Sebrechts,Tom Goethals,Filip De Turck,Bruno Volckaert
### Background
过去十年，物联网（IoT）、边缘计算和嵌入式设备的迅速扩展给安全性和配置管理带来了诸多难题。同时，云原生开发实践的发展显著提升了开发体验，并促进了更快的应用程序更新，从而增强了应用安全性。然而，将这些进步应用到IoT、边缘和嵌入式设备的复杂性依然很高，主要由于这些设备环境的异构性以及对支持寿命较长设备的需要。WebAssembly 和WebAssembly系统接口（WASI）因其潜力而受到广泛关注，成为两者之间的有效桥梁。伴随WebAssembly在IoT、边缘和嵌入式设备上的普及，对WebAssembly程序的硬件接口支持需求日益增长。因此，WebAssembly内的设备驱动程序运行成为现实。
### Innovation
本文提出了WASI提案及其概念验证实现，旨在直接从WebAssembly应用程序中实现硬件接口交互，特别是I2C和USB两种常用协议。这一创新通过在WebAssembly中运行设备驱动程序来实现。实证研究显示，WASI-USB的引入最多增加不到8%的运行时开销，尽管低延迟应用程序中的初始化开销可能显著。
### Conclusion
实验验证表明WASI-USB引入的开销最多不超过8%，对于低延迟应用的实时性能影响甚微，展示了WebAssembly在IoT和边缘计算领域应用中连接硬件的新方法，有效支持这些异构设备的开发和维护。
## 1151. `cs.SE` - 使用深度神经网络发现软件并行化点 [PDF](https://arxiv.org/pdf/2509.16215), [HTML](https://arxiv.org/abs/2509.16215)
### Authors
Izavan dos S. Correia,Henrique C. T. Santos,Tiago A. E. Ferreira
### Background
近年来，计算机系统性能的提高需要更高效地利用计算资源。在编程代码中，一些循环结构可以通过并行化来提高程序的执行速度。然而，手动识别这些可并行化的循环结构非常困难且耗时。该研究旨在利用深度学习方法自动识别编程代码中的可并行化结构，以提高软件的优化性能和执行效率。研究采用了一种基于遗传算法的代码生成器来生成两类代码片段：独立可并行化的循环和依赖关系不明确的循环。通过深度学习模型对这些代码片段进行分类，以评估其并行化潜力。
### Innovation
研究首次提出了利用深度学习（包括深度神经网络和卷积神经网络）从编程代码中自动识别可并行化循环的方法。相对于传统的手动分析和相关研究，该方法具有更高的准确性和效率。此外，研究还探讨了数据集多样性对模型性能的影响，发现了数据多样性对提高模型性能的重要性。
### Conclusion
利用深度学习方法可以有效自动识别编程代码中的可并行化结构，提供了一种有前景的软件优化工具。尽管卷积神经网络表现出略高的平均性能，但两种模型在变异性上类似。增加数据集多样性对模型性能有显著提升作用，这表明该方法具有一定的实用性和广泛的适用性。
## 1152. `cs.SE` - PurpCode: 编码以实现更安全的代码生成 [PDF](https://arxiv.org/pdf/2507.19060), [HTML](https://arxiv.org/abs/2507.19060)
### Authors
Jiawei Liu,Nirav Diwan,Zhe Wang,Haoyu Zhai,Xiaona Zhou,Kiet A. Nguyen,Tianjiao Yu,Muntasir Wahed,Yinlin Deng,Hadjer Benkraouda,Yuxiang Wei,Lingming Zhang,Ismini Lourentzou,Gang Wang
### Background
当前，存在大量的代码推理模型，但它们在生成安全代码和抵御恶意网络活动方面做得不足，无法满足实际需求。为了改变这一现状，研究人员提出了一种新的训练方法——PurpCode，它是首个针对训练生成安全代码以及抵御恶意网络活动的后训练方法。PurpCode 采用两阶段的方法进行训练，以确保模型的安全性和有用性。第一阶段是规则学习，教模型引用网络安全性规则以生成无漏洞代码；第二阶段是强化学习，通过多样化、多目标奖励机制来优化模型的安全性和保持其功能性。为了保障训练数据的多样性，该研究还进行了内部红队活动，以从实际任务中生成全面且高覆盖率的提示用于触发不安全的网络活动。此外，基于PurpCode方法，开发了一种基于推理的编码模型 PurpCode-32B，展示了先进的网络安全性能，并在整体和网络安全特定场景中降低了模型的过度拒绝率，同时保持了模型的代码生成和通用安全知识功能.
### Innovation
创新点在于PurpCode方法通过两个阶段的训练模型来确保生成安全代码和防御恶意网络活动方面的能力。首先，通过规则学习使模型掌握网络安全规则以生成无漏洞代码和避免促进恶意网络活动；其次，通过多目标强化学习机制优化模型的安全性和保持其有用性。此外，通过内部红队活动生成了全面的提示数据，以提高模型的安全性测试。最后，开发了一个名为PurpCode-32B的基于推理的编码模型，展示了在网络安全方面的先进性能，优于现有模型，并且能够保持生成代码和常见安全知识的功能性.
### Conclusion
PurpCode 研究提出了针对训练生成安全代码和抵御恶意网络活动的两阶段方法。基于PurpCode，开发的PurpCode-32B模型在网络安全方面表现优异，并成功降低了模型在各种场景中的过度拒绝率，同时保持了代码生成和安全知识的集成度。未来的研究可以进一步探索如何更有效地合成实用的代码安全数据，并优化奖励机制以提高模型表现。
