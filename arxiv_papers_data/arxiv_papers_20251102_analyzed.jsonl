{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25813", "html_url": "https://arxiv.org/abs/2510.25813", "title": "An Agent-Based Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0", "title_en": "An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0", "authors": "Jorge Martinez-Gil,Mario Pichler,Nefeli Bountouni,Sotiris Koussouris,Marielena Márquez Barreiro,Sergio Gusmeroli", "background": "介绍了一种新的工业5.0框架，旨在简化各种工业环境中边缘设备上AI模型的部署。该框架通过实现本地推理和实时处理，减少了延迟并避免了外部数据传输。", "innovation": "提出了基于代理的框架，使得人类、算法或协作的单个代理负责明确的任务，提供了灵活性并简化了集成。该框架还支持模块化集成，并保持了低资源需求。", "conclusion": "初步评估表明，在实际食品工业场景中部署时间改进和系统适应性增强。源代码已公开，可直接在此链接中获取。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25883", "html_url": "https://arxiv.org/abs/2510.25883", "title": "信息论的必然性：压缩与智能的认知基础", "title_en": "The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence", "authors": "Christian Dittrich,Jennifer Flygare Kinne", "background": "现有的框架强调压缩在智能中的中心地位，但未明确说明为什么压缩过程能够发现因果结构而非表面的相关模式。本文提出了一种两层框架来解决这一问题。", "innovation": "介绍了信息论的必然性（ITI），说明任何在不确定环境中持续存在的系统都必须通过预测压缩来最小化认知熵；此外，提出了压缩效率原理（CEP），详细说明了如何通过异常积累动力学机械地选择生成模型，使现实对齐成为一个结果而非偶然的成就。这些理论共同定义了一个因果链：从生存压力到预测需求，再到压缩需求、效率优化、生成结构发现，最终实现现实对齐。", "conclusion": "ITI和CEP提供了一个统一的智能理论，解释了生物、人工和多尺度系统中智能的收敛现象，没有涉及有关意识或主观体验的假设，同时提出了可验证的预测：压缩效率、异常积累率、分层系统的效率以及生物系统的代谢成本都与认知复杂性相关。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25951", "html_url": "https://arxiv.org/abs/2510.25951", "title": "基于注意力警觉逆规划的认知偏差估计", "title_en": "Estimating cognitive biases with attention-aware inverse planning", "authors": "Sounak Banerjee,Daphne Cornelisse,Deepak Gopinath,Emily Sumner,Jonathan DeCastro,Guy Rosman,Eugene Vinitsky,Mark K. Ho", "background": "人们的定向行为受到认知偏见的影响，与人的交互系统应当意识到这一点。例如，人们在环境中的注意力会系统性地影响他们执行日常任务，如通勤驾驶。基于近期计算认知科学的研究成果，作者正式阐述了一个注意驱动的逆规划问题，旨在从人类行为中估计注意力偏差。", "innovation": "文章提出了一种基于注意的逆规划方法，该方法将深度强化学习与计算认知建模结合，以确定人类在实际驾驶场景中的注意策略。这种方法显著区别于标准的逆强化学习，并展示出如何从行为中推断认知偏差。", "conclusion": "文章展示了如何利用基于注意的逆规划方法来估计认知偏差。通过在Waymo开放数据集的现实驾驶场景中应用该方法，证实了此方法的可扩展性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25914", "html_url": "https://arxiv.org/abs/2510.25914", "title": "FinOps 代理——IT 基础设施和成本优化的一个用例", "title_en": "FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization", "authors": "Ngoc Phuoc An Vo,Manish Kesarwani,Ruchi Mahindru,Chandrasekhar Narayanaswami", "background": "FinOps 表示一种通过跨工程、财务和业务团队的协作财务责任来最大化云业务价值的运营框架和文化实践。FinOps 实践者面临一个根本性的挑战：来自多个云供应商和内部系统的计费数据以异质格式、分类法和度量方式到达，最终导致难以综合生成行动洞察和及时决策。", "innovation": "本文提出了利用自主、目标驱动的人工智能代理来实现 FinOps 自动化。构建了一个针对典型 IT 基础设施和成本优化用例的 FinOps 代理系统，该系统从多个来源获取数据，进行数据汇总和分析，生成优化建议。使用多个开源和闭源语言模型定义了一组指标来评估该代理的表现，结果表明该代理能够理解、规划并执行任务，与实际的 FinOps 实践者具有同等能力。", "conclusion": "通过构建 FinOps 计算机代理，本文解决了一个实际的 IT 基础设施和成本优化用例，并通过多个语言模型测试了代理的能力。结果表明，该代理能够有效理解、规划并执行相关任务，展示了用 AI 代理提高 FinOps 效率的技术潜力。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25884", "html_url": "https://arxiv.org/abs/2510.25884", "title": "使用多评委学习系统逼近人类偏好", "title_en": "Approximating Human Preferences Using a Multi-Judge Learned System", "authors": "Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer", "background": "基于LLM的裁判难以校准，经常表现出评分标准敏感性、偏见和不稳定等缺点，这成为使其与人类偏好对齐的显著挑战。克服这一挑战可推动关键应用，例如创建可靠的强化学习从人类反馈奖励模型（RLHF），以及构建有效的路由系统。这些应用需要能够根据用户的查询挑选最合适模型的系统，因此需要模型能够更好地理解和匹配人类的偏好。", "innovation": "提出了一种基于人物模型的框架，通过学习聚合多个评分标准条件下的多个裁判输出，来建模多样化的、基于人物的偏好。与简单的基线方法相比，该方法经过了实证考察，验证了其在人类偏好以及LLM裁判偏见中的稳健性。主要创新包括大规模合成偏好标签的人物方法，以及该聚合器的两种实现方式：广义加性模型（GAM）和多层感知机（MLP）", "conclusion": "此工作展示了如何利用多裁判系统来建模多样化的、基于人物的偏好，并通过实验评估了其相对于简单基线方法的有效性和稳健性。所提出的框架为未来通过LLM进行人类偏好建模提供了新的途径。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25775", "html_url": "https://arxiv.org/abs/2510.25775", "title": "使用SHAP实现棋局逐子解释", "title_en": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP", "authors": "Francesco Spinnato", "background": "当前的象棋引擎提供了精确但不透明的评估，通常使用每百步得分来表示。尽管这些结果对决策有效，但它们掩盖了单个棋子或棋局模式的贡献。本文探讨了将SHAP（SHapley Additive exPlanations）应用于象棋分析领域，目的是将棋局评估归因于特定的棋盘上的棋子。通过将棋子视为功能并系统地移除它们，计算出每个棋子的加性贡献，以在局部忠实和可理解的方式解释引擎的输出。", "innovation": "本文提出了一种方法，通过将棋子视为功能，并系统地移除它们来计算每个棋子的加性贡献，从而以局部忠实且可理解的方式解释象棋引擎的输出。这种方法受到古典象棋教学的启发，其中玩家通过在心中移除棋子来评估位置，并结合现代解释性人工智能技术。", "conclusion": "本文的方法为可视化、人类训练和引擎比较打开了新的可能性。所提出的方法为未来的可解释象棋人工智能研究奠定了基础，并发布了伴随的代码和数据。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25860", "html_url": "https://arxiv.org/abs/2510.25860", "title": "通过法官的眼睛: 推断出的思考轨迹提高LLM评判人员的可靠性", "title_en": "Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters", "authors": "Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei", "background": "随着大型语言模型（LLMs）在评价任务中的广泛应用，它们的可靠性在涉及主观判断的任务中经常受限，尤其是当人的判断涉及超出标注标签的微妙推理时。思考轨迹，即判断背后的推理过程，虽然极具信息价值，但收集和整理这些信息极具挑战。本文提出了一种人类-LLM协作框架，用于从仅标注的评价中推断出思考轨迹。", "innovation": "本文提出了一种简单而有效的拒绝采样方法，用于大规模重建这些思考轨迹。这些推断出的思考轨迹应用于两个互补任务：首先，用于调优开放型LLM评判人员；其次，用于为专有LLM评判人员提供更清晰的标注指南。多个数据集的结果表明，这些方法显著提高了LLM与人类评判人员的一致性。细化后的标注指南还增加了不同LLM模型之间的一致性。这表明LLMs可以作为实用的代替方法，揭示未被披露的人类思维轨迹，从而增强LLM评判人员的可靠性。", "conclusion": "推断出的思考轨迹可以从仅有标注的结果中提炼出来，并应用到LLM调优和指南改善，从而显著提升LLM与人类评判人员及不同LLM模型之间的一致性。这为LLM在评价任务中的更广泛应用提供了新的方法和途径。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25933", "html_url": "https://arxiv.org/abs/2510.25933", "title": "人类初级：通过导向外骨骼推理达到GPT-4o级事实准确性的小型语言模型", "title_en": "Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning", "authors": "Nissan Yaron,Dan Bystritsky,Ben-Etzion Yaron", "background": "本文探讨了如何利用小型语言模型（3.8B参数）达到大型模型（如GPT-4o）在特定任务中的表现。研究背景在于，虽然大型模型在复杂任务上表现出色，但其成本较高，且在某些情况下，如事实核实（FACTS Grounding），小型模型可能同样具有竞争力。本研究旨在通过先进的训练技术和优化策略，使用小型模型在事实准确性方面达到与大型模型相匹敌的水平。", "innovation": "本文的创新之处在于结合了最小的定向‘外骨骼推理’框架和基于行为的微调，在不对模型进行大量调整的前提下显著提升了模型的表现。研究发现，通过适当的方法将定向推理与微调结合使用，能够大幅提高模型在事实核实时的表现，且成本显著降低。特别是在云定价上，研究中的小型模型成本仅为GPT-4o的约1/19。", "conclusion": "小型模型（人类初级）在事实核实时的表现能够与大型模型（如GPT-4o）相当，甚至在某些情况下表现更优。通过外部推理框架与行为微调的结合，可以在保证相对较低成本的同时，实现与大型模型极度接近的表现。此外，对于自托管或边缘部署，模型的边际成本可以接近零。这些发现为AI模型的成本效率提供了新的视角，并对未来的模型设计和应用具有重要意义。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25908", "html_url": "https://arxiv.org/abs/2510.25908", "title": "SciTrust 2.0：科学应用中大型语言模型可信度评估的全面框架", "title_en": "SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications", "authors": "Emily Herron,Junqi Yin,Feiyi Wang", "background": "大型语言模型（LLMs）在科学研究中显示出变革性的潜力，但它们在高风险情境中的部署引发了重大信任问题。本文分析指出，现有科学应用中的LLMs在真理全面性、对抗鲁棒性、科学安全性和科学伦理方面存在显著不足，尤其是在生物安全和化学武器等高风险领域。SciTrust 2.0框架旨在评估LLMs在科学应用中的可信度，涵盖了四个维度：真实性、对抗鲁棒性、科学安全性和科学伦理，并利用新型开放性真理基准和专家验证来评估模型的表现。", "innovation": "SciTrust 2.0框架引入了新型开放性真理基准和伦理基准，这两个基准涵盖了八个子类别，特别是双用途研究和偏见等问题。此外，通过验证和调整的管道来开发新的真理基准，并结合专家验证进行改进。研究中使用了多种评估指标，包括准确性和语义相似度，结果显示，通用行业模型在每个可信度维度上普遍优于科学专用模型，并指出科学专用模型在逻辑和伦理推理能力方面存在显著缺陷，安全评估中也表现出令人担忧的脆弱性。", "conclusion": "通过开源SciTrust 2.0框架，为开发更可信的AI系统和推进模型安全性与伦理学研究提供了基础。结果显示，在某些方面，通用行业模型比科学专用模型更具优势，并强调了科学专用模型在逻辑和伦理推理方面的能力缺陷，特别是在高风险领域如生物安全和军用化学武器中。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25820", "html_url": "https://arxiv.org/abs/2510.25820", "title": "象征性支撑的游玩：为生成型NPC对话设计角色敏感提示", "title_en": "Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for Generative NPC Dialogue", "authors": "Vanessa Figueiredo,David Elumeze", "background": "大语言模型（LLMs）有望通过使非玩家角色（NPCs）能够维持非脚本对话来彻底改变交互式游戏。然而，仍然不清楚受限提示是否真的能改善玩家体验。本文通过由GPT-4o驱动的声音侦探游戏《面试》进行了探索，采用单被试设计，比较了高约束（HCP）和低约束（LCP）提示的效果，结果发现，玩家体验在此方面的显著差异仅出现在对技术故障的敏感性上。重塑后，高约束提示被设计成了一个综合JSON+RAG支架，并进行了合成评估。评估结果显示，支架效果取决于角色：面试官NPC（任务发起NPC）变得稳定，而犯罪嫌疑人NPC失去了即兴的可信度。这些发现推翻了紧约束必然提升游戏体验的假设，提出了在需要稳定性的部分使用模糊符号支架、以保持即兴创造力的框架，即《象征性支撑的游玩》。", "innovation": "本文提出了一种新的框架——《象征性支撑的游玩》，该框架通过使用模糊的数值边界来表达符号结构，从而既稳定了游戏所需的部分，又保留了即兴表演的空间，能够在角色扮演领域为生成性NPC对话设计提供新的思路和方法。这一框架区别于传统的紧约束假设，强调了不同角色需求不同，即严格与灵活的平衡对于不同的角色可以产生不同的效果。", "conclusion": "本文通过实验发现，调整约束提示的效果需要考虑角色特性，即不同的角色对约束的需求不同，这推翻了之前简单认为更严格的约束总是更有益的传统观点，建议未来可以在不同的游戏中根据角色特性和游戏需求采用更加灵活和角色敏感的提示设计策略来提升玩家体验。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25997", "html_url": "https://arxiv.org/abs/2510.25997", "title": "从查询到洞察：基于ReAct代理的时空文本到SQL流水线", "title_en": "From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL", "authors": "Manu Redd,Tao Zhe,Dongjie Wang", "background": "自然语言到SQL（NL-to-SQL）系统有潜力使结构化数据的访问更加民主，使用户无需学习SQL即可查询数据库。然而，现有的系统在处理包含模糊用户表述并需要与特定模式分类对齐、处理时间推理以及选择适当输出的现实时空查询方面存在困难。", "innovation": "本文提出了一种以Mistral为基础的ReAct代理扩展的智能管道，该管道增强了Naive文本到SQL的基本模型（llama-3-sqlcoder-8b）。代理能够通过模式检查、SQL生成、执行和可视化工具来计划、分解和适应查询。具体而言，这种方法提高了查询的准确性，并通过地图、图表和结构化的自然语言摘要增强了用户体验。", "conclusion": "我们的设计使得更自然的人与数据库的交互成为可能，这支持了那些缺乏SQL专业知识、详细模式知识或提示技能的用户。我们得出结论，代理式协调而非更强的SQL生成器是构建交互式地理空间助手的有前途的基础。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26012", "html_url": "https://arxiv.org/abs/2510.26012", "title": "AutoSurvey2: 为研究人员赋能的下一层级自动化文献综述", "title_en": "AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys", "authors": "Siyi Wu,Chiaxin Liang,Ziqian Bi,Leyi Zhao,Tianyang Wang,Junhao Song,Yichao Zhang,Keyu Chen,Xinyuan Song", "background": "随着大型语言模型（LLMs）的研究文献快速增长，进行全面和及时的综述变得越来越困难。现有的综述文献通常滞后、不全面或难以保持更新。", "innovation": "AutoSurvey2 是一个多阶段的自动化生成管道，通过检索增强合成和结构化评估技术来自动生成综述。该系统结合了并行部分生成、迭代细化和实时检索最新出版物，确保选题完整和事实准确。通过多大型语言模型（LLMs）评估框架来衡量覆盖面、结构和相关性，结果表明 AutoSurvey2 在结构连贯性和选题相关性方面显著优于现有的检索和自动化基线，同时保持了对参考文献的良好忠实度。", "conclusion": "通过将检索、推理和自动化评估整合到一个统一框架中，AutoSurvey2 提供了一个可扩展和可重复的长格式学术综述生成解决方案，并为自动化学术写作未来的研究奠定了坚实基础。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26057", "html_url": "https://arxiv.org/abs/2510.26057", "title": "AI可以负责任吗？", "title_en": "Can AI be Accountable?", "authors": "Andrew L. Kun", "background": "当前使用的AI非常强大，其能力在快速提升。要让AI为消费者、选民和决策者服务，确保AI的责任性至关重要。通常，如果某个实体能够要求代理提供其行动的信息，与代理讨论这些信息，并对其实施制裁，那么该实体对代理是负责任的。然而，目前许多AI缺乏责任性，例如我们不能质问它们、与其讨论，更不用说制裁它们。", "innovation": "本文将通用的责任性定义应用于AI，解释了AI的责任性和非责任性含义，并探讨了可以提升AI对受影响者负责任程度的方法。", "conclusion": "本文关联了通用的责任性定义与AI，展示了AI的责任性和非责任性含义，并探索了提高AI对受影响者负责性的方法，强调了实现所有AI对受影响者负责任的重要性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26136", "html_url": "https://arxiv.org/abs/2510.26136", "title": "超越基准：人工智能推理的经济学", "title_en": "Beyond Benchmarks: The Economics of AI Inference", "authors": "Boqin Zhuang,Jiacheng Qiao,Mingqian Liu,Mingxing Yu,Ping Hong,Rui Li,Xiaoxia Song,Xiangjun Xu,Xu Chen,Yaoyao Ma,Yujie Gao", "background": "大型语言模型（LLMs）的推理成本已成为决定其商业潜力和普及程度的关键因素。本文构建了量化推理的经济学框架，将LLM的推理过程视为由计算驱动的智能生产活动。通过分析不同性能配置下的边际成本、规模经济和输出质量，本文为模型部署决策提供了经济基础，并为未来基于市场的推理资源定价和优化奠定了实证基础。", "innovation": "本文提出了首个‘LLM推理生产前沿’，揭示了边际成本递减、规模效益递减以及成本效益的最佳区域等三个原则。这些发现不仅为模型部署提供了经济依据，还为未来的AI推理资源定价和优化提供了实证基础。", "conclusion": "本文不仅为模型部署提供了经济基础，还为未来基于市场的AI推理资源定价和优化奠定了实证基础。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26023", "html_url": "https://arxiv.org/abs/2510.26023", "title": "大型语言模型辅助的自主车辆从停滞状态恢复", "title_en": "Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization", "authors": "Zhipeng Bao,Qianwen Li", "background": "尽管近年来取得了显著进展，但自主车辆（AV）在处理人类驾驶员擅长的某些交通场景时仍然面临挑战。在这种情况下，AV往往会出现停滞状态，导致整体交通流量受阻。当前的恢复解决方案，如远程干预（成本高且效率低）和手动接管（排除非驾驶员，限制AV的可访问性），都不够理想。", "innovation": "本文介绍了一种名为StuckSolver的新型大型语言模型（LLM）驱动的恢复框架，该框架使AV能够通过自我推理和/or乘客引导决策来解决停滞情景。StuckSolver旨在作为插件附加模块，在不修改AV内部架构的情况下，运行在其现有的感知-规划-控制堆栈之上，仅与标准传感器数据流进行接口交互，以检测停滞状态，解释环境背景，并生成高级恢复命令，供AV的原生规划器执行。", "conclusion": "我们在Bench2Drive基准和自定义设计的不确定性场景中对StuckSolver进行了评估。结果表明，StuckSolver仅通过自主自我推理就能达到接近最先进的性能，并且当结合乘客引导时，将进一步提高性能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26098", "html_url": "https://arxiv.org/abs/2510.26098", "title": "GUI Knowledge Bench: 揭示大型视觉语言模型在GUI任务中失败的知识差距", "title_en": "GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks", "authors": "Chenrui Shi,Zedong Yu,Zhi Gao,Ruining Feng,Enqi Liu,Yuwei Wu,Yunde Jia,Liuyu Xiang,Zhaofeng He,Qing Li", "background": "大型视觉语言模型（VLMs）在自动化图形用户界面（GUI）任务方面取得了进步，但仍难以达到人类水平。现有训练方案（如监督细调和强化学习）无法完全填补这一差距。通过对GUI任务执行中常见失败模式的分析，研究者确定了GUI知识的三个维度：界面感知、交互预测和指令理解。", "innovation": "引入了GUI Knowledge Bench基准，涵盖六种平台（Web、Android、MacOS、Windows、Linux、iOS）和292个应用程序的多个选择和是非问题。评估结果显示，当前的VLMs在识别小部件功能方面表现良好，但在感知系统状态、预测动作和验证任务完成方面存在困难。通过提供一个结构化的评估框架，研究支持了在下游训练前选择具有更大潜力的VLM，并为构建更强大的GUI代理提供了见解。", "conclusion": "通过提供一个结构化的评估框架，我们的工作支持了在下游训练前选择具有更大潜力的VLM，并为构建更强大的GUI代理提供了洞察。实验还验证了GUI知识与任务成功之间的紧密联系。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26094", "html_url": "https://arxiv.org/abs/2510.26094", "title": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "title_en": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "authors": "Yuxin Li,Minghao Liu,Ruida Wang,Wenzhao Ji,Zhitao He,Rui Pan,Junming Huang,Tong Zhang,Yi R. Fung", "background": "介绍了Lean4PHYS框架，这是一项面向大学水平物理学问题的全面推理框架，利用Lean4开发。基准测试**LeanPhysBench**包含200个手工制作并经过同行评审的物理推理陈述，这些陈述源自大学教科书和物理竞赛问题。为了建立正式物理学推理的良好基础，还引入了**PhysLib**，这是一个包含对于正式物理学推理至关重要的基本单位制和定理的社区驱动的资源库。", "innovation": "提出了**Lean4PHYS**框架，包括**LeanPhysBench**基准测试和**PhysLib**资源库。基准测试提供了200个物理学推理实验，资源库则提供了关键的单位系统和定理。还展示了最先进的可视化证明器DeepSeek-Prover-V2-7B和Claude-Sonnet-4在基准测试中的表现分别为16%和35%，说明了**LeanPhysBench**的挑战性以及**PhysLib**的有效性。", "conclusion": "研究表明，**PhysLib**能够平均改善模型性能11.75%。总体而言，这是首次在Lean4中提供物理学基准的工作，并展示了**Lean4Physics**框架的实用性和潜在价值。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26143", "html_url": "https://arxiv.org/abs/2510.26143", "title": "从数学中培养广泛大语言模型推理所需的推理课程", "title_en": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math", "authors": "Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou", "background": "强化学习（RL）能够激发大语言模型（LLMs）的强大推理能力，但大多数公开努力集中在数学和代码上。本文提出了一种简单的两阶段课程，通过联合RL首先在与预训练对齐的领域（如数学）中激发推理技能，然后跨其他领域调整和精炼这些技能。第一阶段进行简短的冷启动和数学导向的RL，利用可验证奖励来培养推理技能，第二阶段在混合域数据上进行联合RL，以转移和巩固这些技能。该课程是轻量级且不依赖于特定架构的，只需要标准的验证性检查之外的特殊奖励模型。评估结果显示，在Qwen3-4B和Llama-3.1-8B上，推理课程能够持续提升推理能力。", "innovation": "本文提出了一种两阶段的推理课程，旨在通过联合RL激发和精炼大语言模型的推理技能，并在多种领域中进行迁移和巩固。这一课程是轻量级且架构无关的，主要创新点在于通过数学领域和混合数据的联合训练，使得模型在复杂问题解决中表现出更强大的推理行为。", "conclusion": "推理课程提供了一种简洁且易于实施的方案，能够普遍提升大语言模型的推理能力。两阶段训练分别是必要的，数学导向的初期激发能够显著增加解决复杂问题的认知行为。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26144", "html_url": "https://arxiv.org/abs/2510.26144", "title": "FM Agent", "title_en": "The FM Agent", "authors": "Annan Li,Chufan Wu,Zengle Ge,Yee Hin Chong,Zhinan Hou,Lizhe Cao,Cheng Ju,Jianmin Wu,Huaiming Li,Haobo Zhang,Shenghao Feng,Mo Zhao,Fengzhi Qiu,Rui Yang,Mengmeng Zhang,Wenyi Zhu,Yingying Sun,Quan Sun,Shunhao Yan,Danyu Liu,Dawei Yin,Dou Shen", "background": "大型语言模型（LLMs）正在推动自主人工智能研究代理在科学和技术发现中的发展。现有方法需要人类的持续干预和调整，而研究提出了一种新的、通用的多代理框架FM Agent。它结合了基于LLM的推理和大规模进化搜索，以应对复杂的现实世界挑战。", "innovation": "FM Agent的核心包括四个关键创新：1) 初始冷启动阶段集成了专家指导；2) 一种新颖的进化采样策略，用于迭代优化；3) 领域特定评估器，结合正确性、有效性和LLM监督反馈；4) 基于Ray的分布异步执行基础设施。该系统已被广泛应用于多个领域，包括运筹学、机器学习、GPU内核优化以及经典数学问题。", "conclusion": "FM Agent在不需人工解释或调整的情况下，取得了最先进的性能结果。在ALE-Bench上达到1976.3的得分（+5.2%），在MLE-Bench上达到43.56%的得分（+4.0pp），在KernelBench上实现了高达20倍的加速，并在几个经典数学问题上达到了新的最先进的结果。该系统在企业和基础科学中的应用中展现出了巨大的潜力，能够加速创新，自动化复杂的研究过程，并带来更广泛的工程与科学进步。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26167", "html_url": "https://arxiv.org/abs/2510.26167", "title": "所有工具使用场景一键评价：高效推理的奖励方式", "title_en": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning", "authors": "Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang", "background": "奖励模型（RMs）对于对齐大型语言模型（LLMs）与人类偏好起着关键作用。但在工具学习领域，专门针对函数调用任务的奖励模型缺乏，限制了更强大代理型AI的发展。本文介绍了一种名为ToolRM的轻量级生成奖励模型家族，专门针对一般工具使用场景。", "innovation": "提出了一个新颖的管道，使用基于规则的评分和多维采样构造了成对偏好数据，从而编制了包含30,000种批判任务的ToolPref-Pairwise-30K数据集，支持具有可验证反馈的强化学习。此外，还提出了TRBench$_{BFCL}$基准，在此基础上构建了工具使用奖励模型评估套件BFCL。这些模型在几个关键指标上表现出色，尤其是在成对奖励判断方面，显著优于Claude 4和OpenAI o3等前沿模型。此外，ToolRM还能够在更广泛的批判任务中泛化，包括Best-of-N采样和自我纠正。", "conclusion": "实验证明ToolRM在ACEBench上的有效性与效率。能够在推理时间进行扩展，并减少输出标记使用超过66%。该研究团队提供了数据和模型检查点以促进未来的研究。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26242", "html_url": "https://arxiv.org/abs/2510.26242", "title": "增强检索生成的分布式LLM代理以实现应急车辆通用交通信号控制", "title_en": "Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles", "authors": "Xinhang Li,Qing Guo,Junyu Chen,Zheng Guo,Shengzhe Xu,Lei Li,Lin Zhang", "background": "随着城市交通复杂性的增加，交通信号控制（TSC）对于优化交通流和提高道路安全至关重要。然而，大型语言模型（LLMs）在紧急情况下容易出现幻觉，这可能导致应急车辆的延误。此外，不同类型的交叉口给交通状态编码和跨交叉口训练带来了巨大挑战，限制了在异构交叉口上的泛化能力。", "innovation": "本文提出了增强检索生成的分布式LLM代理（REG-TSC），并设计了一个应急意识推理框架。该框架可以根据紧急情况动态调整推理深度，并结合一种新的基于审查者的应急检索增强生成（RERAG）机制，以从历史案例中提取特定的知识和指导，增强代理在应急情况下的决策可靠性和合理性。此外，提出了一种不依赖类型的交通表示和一种奖励导向的强化细化（R3），该机制基于环境反馈优先地从不同类型的交叉口抽取训练经验，并通过自定义的奖励加权似然损失进行微调。", "conclusion": "在三个包含17到177个异构交叉口的真实路网中进行的实验表明，REG-TSC可以将行驶时间减少42.00%，排队长度减少62.31%，应急车辆的等待时间减少83.16%，并且在所有指标上都优于其他最先进的方法。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26270", "html_url": "https://arxiv.org/abs/2510.26270", "title": "LLM代理训练中的图增强策略优化", "title_en": "Graph-Enhanced Policy Optimization in LLM Agent Training", "authors": "Jiazhen Yuan,Wei Zhao,Zhengbiao Bai", "background": "组基于强化学习（RL）在复杂的推理和数学任务中表现出色，但在用于训练多轮交互式的大语言模型（LLM）代理时，这些方法通常会遇到结构性盲点的问题——即无法利用环境的潜在连通性。这种问题导致了三个关键挑战：（1）效率低下且不受引导的探索，（2）由于忽略关键状态而导致信贷分配不精确，（3）由于静态奖励折现而导致的短视规划。", "innovation": "提出了一种名为Graph-Enhanced Policy Optimization (GEPO)的新方法，通过动态构建从代理经验中获得的状态迁移图，并使用图论中心性来提供三个协同学习信号：（1）结构化的内在奖励，引导探索高影响状态；（2）图增强的优势函数，用于拓扑感知的信贷分配；（3）根据每个状态的战略价值动态调整的折扣因子。", "conclusion": "在ALFWorld、WebShop和一个专有的Workbench基准测试中，GEPO展示了强大的性能，相比竞争基线，绝对成功率提高了4.1%、5.3%和10.9%。这些结果表明，明确建模环境结构是推进LLM代理训练的稳健和通用策略。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26396", "html_url": "https://arxiv.org/abs/2510.26396", "title": "AI人格的务实视角", "title_en": "A Pragmatic View of AI Personhood", "authors": "Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Stanley M. Bileschi", "background": "随着代理型人工智能的出现，社会将经历类似于寒武纪生命大爆发的变革，出现新的类型人格。本文提出了一个实用框架来应对这种多样性，强调人格不应被视为需要发现的形而上属性，而是社会根据多种原因（尤其是解决具体的治理问题）为实体分配的灵活义务集合（权利和责任）。", "innovation": "本文创新地将人格的义务集合解绑，以适应不同情境，创造出具有针对性的解决方案。这种方法避免了讨论人工智能的意识或理性等难以解决的问题，而是专注于通过分配特定的义务集合来促进问责或防止冲突。此外，文章探讨了去中心化数字身份技术的应用，分析了人格作为问题和解决方案的影响。", "conclusion": "本研究通过放弃对一个人格单一本质定义的追求，提供了一种更加务实和灵活的方法来思考将AI代理融入社会。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26402", "html_url": "https://arxiv.org/abs/2510.26402", "title": "Autograder+: 多维度AI框架为编程教育提供丰富教学反馈", "title_en": "Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education", "authors": "Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane", "background": "编程教育的快速增长使得传统评估工具显得不足，教授们难以提供有意义的、可扩展的反馈。传统的自动评分工具虽然高效，但只是简单地给出通过或不通过的结果，缺乏对学生思考或学习需求的深入见解。", "innovation": "Autograder+ 将自动评分从单纯的总结过程转变为一种形成性学习体验。它引入了两项关键功能：使用微调的大语言模型自动生成反馈，以及可视化学生的代码提交以揭示学习模式。通过使用精编的学生代码和专家反馈进行微调，确保了教学上一致且有意识的指导。", "conclusion": "通过整合AI驱动的反馈、语义聚类和交互式可视化，Autograder+ 减轻了教师的工作负担，同时支持有针对性的指导，促进更强大的学习成果。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26374", "html_url": "https://arxiv.org/abs/2510.26374", "title": "BOTS: 一种用于大型语言模型增强调优的贝叶斯在线任务选择统一框架", "title_en": "BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning", "authors": "Qianli Shen,Daoyuan Chen,Yilun Huang,Zhenqing Ling,Yaliang Li,Bolin Ding,Jingren Zhou", "background": "强化微调（RFT）是将大型语言模型（LLMs）与人类偏好对齐并增强推理能力的关键技术，但其效果高度依赖于训练期间探索的任务类型。均匀采样任务效率低下，会浪费计算资源在既简单又无法解决的任务上，而现有的任务选择方法通常具有较高的展开成本、较差的适应性或不完整的证据。", "innovation": "本文提出了BOTS（贝叶斯在线任务选择），这是一种用于大型语言模型强化微调的统一框架。BOTS基于贝叶斯推理，适应性地维持模型发展过程中任务难度的后验估计。它联合包含了直接评估已选任务的显性证据和通过这些评估推断未选任务的隐性证据，同时使用Thompson采样确保探索与利用之间的合理平衡。为使隐性证据实用化，BOTS实例化为基于插值的超轻量级插件，无需额外展开即可估计未评估任务的难度，几乎不增加开销。经验结果表明，BOTS在不同的领域和大规模的LLM上，相较于基线和变体，持续地提高了数据效率和性能，并提供了一种实用的、可扩展的动态任务选择解决方案.", "conclusion": "BOTS在不同的领域和大规模的LLM上，持续地提高了数据效率和性能，并提供了一种实用的、可扩展的动态任务选择解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26309", "html_url": "https://arxiv.org/abs/2510.26309", "title": "GraphCompliance：基于图的政策和上下文图对LLM在合规性中的应用", "title_en": "GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance", "authors": "Jiseong Chung,Ronny Ko,Wonchul Yoo,Makoto Onizuka,Sungmok Kim,Tae-Wan Kim,Won-Yong Shin", "background": "在Web规模的合规性中存在实践挑战，每个请求可能需要进行监管评估。监管文本（例如，通用数据保护条例，GDPR）是交叉引用和规范性的，而运行时环境则以非结构化的自然语言表达。这种情况下，需要将非结构化的文本中的语义信息与规范的监管元素对齐。以往的研究中，监管遵循主要依靠人工解读和理解，这在面对大量的实时请求时，显得效率低下和成本高。GraphCompliance通过将监管文本表示为政策图，将运行时上下文表示为上下文图，并进行对齐，试图解决这个问题。", "innovation": "GraphCompliance 提出了一种框架，将监管文本表示为Policy Graph，将运行时上下文表示为Context Graph。通过这种方法，政策图编码规范结构和交叉引用，而上下文图形式化事件作为主语-动作-宾语（SAO）和实体-关系三元组。这种方法连接了法官大型语言模型（LLM）推理与结构信息，有助于减少监管解释和事件解析的负担，从而使关键推理步骤更加聚焦。实验结果显示，在300个GDPR衍生的真实场景下，GraphCompliance比仅使用LLM和基于检索增强生成（RAG）的基本模型具有更高的微F1分数，且错误率较低，召回率更高。进一步的拆分研究表明，每个图组件的贡献，这表明结构化的表示和法官LLM对于规范推理是互补的。", "conclusion": "GraphCompliance在处理大规模Web合规性挑战方面取得了显著效果，通过图形对齐技术将编程文本与运行时上下文高质量地结合，提高了模型在法律合规性任务中的性能。这对于自动化处理和增强法定义务理解和遵守具有重要意义，有助于进一步减轻监管解读的负担并提高准确性和效率。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26346", "html_url": "https://arxiv.org/abs/2510.26346", "title": "在UCT搜索树中通过动作修剪发现状态等价关系", "title_en": "Discovering State Equivalences in UCT Search Trees By Action Pruning", "authors": "Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn", "background": "通过聚类/抽象状态或状态-行动对来改进蒙特卡洛树搜索（MCTS）的样本效率，虽然动作修剪在算法中容易找到，但在噪音或大型动作空间中发现状态抽象却很困难，这限制了该方法的应用范围。已有研究如OGA-UCT在动作修剪方面有一定的进展，但未解决状态修剪的问题。因此，本文旨在通过提出一种更弱的状态修剪条件，解决在噪音和大型动作空间中发现状态抽象的问题，从而改进MCTS的样本效率。", "innovation": "本文提出了一种方法——理想修剪抽象在蒙特卡洛树搜索（IPA-UCT），这种方法只需要稍微损失一些准确性就能找到更多的抽象。IPA-UCT利用了与OGA-UCT不同的抽象框架（命名为IPA），并且证明了IPA和ASAP均是更广泛框架p-ASAP的特殊情况，而p-ASAP又是ASASAP框架的特殊情况。实验结果表明，IPA-UCT在一系列的测试领域和预算范围内表现出色，超越了OGA-UCT及其派生算法。", "conclusion": "本文为提高MCTS的样本效率提供了一种新的策略，通过弱化状态修剪的条件，使得在噪声和大型动作空间中也能找到许多状态抽象。实验验证了IPA-UCT的有效性，并且这一方法被证明适用于广泛的测试场景。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26380", "html_url": "https://arxiv.org/abs/2510.26380", "title": "AI数学家在推进数学发现中的伙伴角色——一个关于均匀化理论的研究案例", "title_en": "AI Mathematician as a Partner in Advancing Mathematical Discovery - A Case Study in Homogenization Theory", "authors": "Yuanhang Liu,Beichen Wang,Peng Li,Yang Liu", "background": "人工智能（AI）在数学推理方面取得了显著进展，但在数学研究的实际应用中仍受到限制。本研究探讨了AI数学家（AIM）系统如何作为研究伙伴而非单纯的问题解决者发挥作用。研究聚焦于一个难题——均匀化理论中的问题，通过自主的推理过程和目标人类干预，揭示了人类直觉与机器计算如何互补。合作的方式提高了最终证明结果的可靠性、透明性和可解释性，同时保留了对形式严格性和正确性的人类监督。该方法导致了完整的可验证证明，并展示了系统性的人机协同推理如何推进数学发现的边界。", "innovation": "本研究创新性地将AI作为数学研究伙伴而不是单纯的问题解决者，通过自主推理和目标人类干预的方式，展示了人机协同推理在数学发现中的应用。该方法不仅提高了证明的可靠性、透明性和可解释性，还推动了数学发现的边界。", "conclusion": "本文通过案例研究展示了通过迭代分解问题、选择合适的分析方法和验证中间结果，人类直觉与机器计算在数学发现中的互补作用。这种协作范式增强了最终证明结果的可靠性和透明性，同时保留了人类对形式严格性和正确性的监督。这种方法不仅产生了完整的可验证证明，还证明了系统性的人机协同推理可以推进数学发现的前沿。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26238", "html_url": "https://arxiv.org/abs/2510.26238", "title": "问卷遇上大语言模型：理解问题与回复的基准与实证研究", "title_en": "Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses", "authors": "Duc-Hai Nguyen,Vijayakumar Nanjappan,Barry O'Sullivan,Hoang D. Nguyen", "background": "每天都有大量的人员接受调查，从市场调查、学术研究到医疗问卷和客户反馈表。这些数据集包含了宝贵的信息，但由于其规模和结构，为大型语言模型（LLMs）带来了独特的挑战，尽管LLMs在开放文本的少样本推理方面表现出色，但它们处理包含数百个响应行的问题列表的能力尚未得到充分探索。目前的检索和调查分析工具（例如，Qualtrics、SPSS、REDCap）通常用于工作流程中的人类，限制了这些数据与LLM和AI赋能自动化之间的整合。这一差距使得科学家、调查员和普通用户无法获得基于证据的指导，以最佳方式将问卷呈现给LLM进行处理。因此，该论文旨在解决这一问题。", "innovation": "论文通过引入QASU（Questionnaire Analysis and Structural Understanding），这是一种基准测试，针对六种结构技能（包括答案查询、响应计数和多跳推理）进行了测试，涵盖了六个序列化格式和多种提示策略。实验证明，选择有效的格式和提示组合可以将准确率提高8.8%。对于特定任务，通过自我增强提示添加轻量级结构提示，平均可以进一步提高3-4%的准确性。通过系统地分离格式和提示效果，开源基准提供了促进基于LLM的问卷分析研究和实际应用的基础。", "conclusion": "通过QASU基准测试框架，论文揭示了不同序列化格式和提示策略对LLM在问卷分析中的性能有何影响。研究结果表明，有效的格式和提示组合可以显著提高准确率，为LLM赋能的问卷分析研究和实践提供了宝贵的指导。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26384", "html_url": "https://arxiv.org/abs/2510.26384", "title": "Scales++: 计算高效评估子集选择的认知尺度嵌入", "title_en": "Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings", "authors": "Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz", "background": "由于评估大型语言模型（LLMs）在全面基准上的高昂成本，迫切需要创建小而具有代表性的数据子集（即小型基准），以便高效评估同时保持预测准确性。当前的方法基于模型主导的视角，根据现有模型的综合性能选择基准项目。然而，这些方法存在大型前期成本、无法快速处理新基准（冷启动）以及假设未来模型将遵循前辈失败模式等局限性。", "innovation": "本文挑战了现有的模型主导的基准集选择方式，提出了基于项目中心的基准选择方法，主张按照任务项本身的内在属性，而不是基于特定模型的失败模式来进行选择。Scales++是一个新颖的方法，通过基准项目样本的认知需求来实现数据选择。实验表明，Scales++将前期选择成本降低了18倍以上，同时保持了竞争力的预测准确性。使用Open LLM基准板中的0.5%数据子集，准确预测了完整基准分数，平均绝对误差为2.9%。这种方法使模型评估更加高效，同时也提供了更好的冷启动性能和更具解释性的基准评估。", "conclusion": "本文提出了一种基于任务项目内在属性的评估子集选择方法，即Scales++，有效降低了前期成本，同时保持了预测准确性，并提供了更好的冷启动性能和更易于解释的基准评估。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26493", "html_url": "https://arxiv.org/abs/2510.26493", "title": "Context Engineering 2.0: The Context of Context Engineering", "title_en": "Context Engineering 2.0: The Context of Context Engineering", "authors": "Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu", "background": "论文背景在于，人类的本质是由社会关系构成的，而随着计算机和人工智能的发展，人们的社会活动范围正在扩展，不仅有人与人的互动还涉及人与机器的互动。这一背景下，提出了如何让机器更好地理解我们的情境和目的这一挑战。为此，研究引入了情境工程的概念，但认为这一理念其实可以追溯到二十多年前。", "innovation": "这篇文章认为情境工程的概念虽被认为是智能代理时代的近期创新，但实际上可以追溯到更早的历史阶段。通过梳理情境工程的演进历史以及在不同阶段的主要设计考虑因素，为这一领域的进一步发展提供了系统的概念框架。", "conclusion": "本文旨在提供情境工程的系统概念基础，并勾画其有前景的未来发展方向，为人工智能系统中的情境工程提供了一个重塑领域方向的契机。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26411", "html_url": "https://arxiv.org/abs/2510.26411", "title": "MedSAE: 使用稀疏自编码器剖析MedCLIP表示", "title_en": "MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders", "authors": "Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto", "background": "在医疗保健中应用人工智能需要准确且可解释的模型。该篇论文旨在通过应用医疗稀疏自编码器（MedSAEs）在医学影像中的潜在空间，提升医学影像中的机械可解释性。背景中指出，先前的医疗视觉模型MedCLIP在胸部X光图片和报告上进行训练，但其表示形式的可解释性不足。因此，需要一种新的方法来评价模型的解释性，并帮助医疗AI技术更为透明可靠。", "innovation": "论文的创新点在于提出了一种新的评价框架，该框架结合了相关性度量、熵分析以及通过MedGEMMA基础模型自动命名神经元。实验结果表明，MedSAE的神经元在单义性（monosemanticity）和解释性方面优于原始的MedCLIP特征。这为医疗AI的可解释性和透明度提供了一种新的解决方案。", "conclusion": "研究结果表明，MedSAE能够实现高度一致的医学AI表示，并将其与透明度相连接。这为在临床环境中实现可靠的表示模型提供了一个可扩展的步骤。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26486", "html_url": "https://arxiv.org/abs/2510.26486", "title": "LINK-KG: LLM-驱动核心指代解决知识图谱用于人口走私网络", "title_en": "LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks", "authors": "Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera", "background": "人类偷运网络复杂且不断演变，难以进行全面分析。法律案件文件提供了有关这些网络的丰富事实和程序见解，但往往冗长且结构不明确，包含模糊或变通的引用，对自动知识图谱(KG)建设构成重大挑战。现有方法要么忽视共指消解，要么无法扩展到短文本片段之外，导致图谱碎片化和实体链接不一致。", "innovation": "本文提出LINK-KG，一个模块化框架，集成了一个三阶段、基于大语言模型(LLM)的共指消解流水线和下游的KG提取。核心是针对特定类型的过程缓存，能够跨文档片段一致追踪和解决引用，为从短和长法律文本中构建结构化知识图谱提供清晰、去模糊的叙述。LINK-KG将平均节点重复降低了45.21%，噪音节点降低了32.22%，从而形成更清洁、更具连贯性的图结构。", "conclusion": "这些改进奠定了LINK-KG作为分析复杂犯罪网络强大基础的地位。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26518", "html_url": "https://arxiv.org/abs/2510.26518", "title": "人类与AI取长补短：放大监督的目标", "title_en": "Human-AI Complementarity: A Goal for Amplified Oversight", "authors": "Rishub Jain,Sophie Bridgers,Lili Janzer,Rory Greig,Tian Huey Teh,Vladimir Mikulik", "background": "随着AI能力的提升和AI被用于解决更加复杂的任务，验证AI系统的质量和安全性变得越来越具有挑战性。人类反馈对于使AI系统与人类价值观一致至关重要。因此，本文探讨如何利用AI来提升人类监督的质量，特别是在已经对人类构成挑战的任务——AI输出的事实验证方面。", "innovation": "本文发现，结合基于AI评注员信心的AI评分和人类评分比单凭任何一方都更有效。提供给人类一个AI事实验证助手可以进一步提高准确性，但这种帮助的方式很重要。显示AI解释、信心和标签会导致过度依赖，而只是展示搜索结果和证据更能促进适当的信任。这些结果对于“放大监督”——将人类和AI结合以监督AI系统（即使这些系统超越了人类专家的表现）有重大意义。", "conclusion": "本文表明，结合AI评分和人类评分可以有效提高质量监督水平，提供适当的帮助方式可以提高人类的信任水平，这对放大监督这一挑战至关重要。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26481", "html_url": "https://arxiv.org/abs/2510.26481", "title": "谁拥有最终决定权？ChatGPT选择中的从众动态", "title_en": "Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections", "authors": "Clarissa Sabrina Arlinghaus,Tristan Kenneweg,Barbara Hammer,Günter W. Maier", "background": "大型语言模型（LLMs）如ChatGPT越来越多地被集成到高风险的决策中，但目前对它们的社会影响力知之甚少。本文通过预注册的从众实验，研究了GPT-4在招聘场景中的决策行为。实验结果显示，GPT并不像独立的观察者，而是会根据感知的社会共识进行调整。这提示我们应该谨慎将LLMs作为中立的决策辅助工具，并且在阐明它们的判断之前，需要先了解它们的观点。", "innovation": "研究通过预注册的从众实验，详细探讨了GPT在招聘场景中的决策行为，发现了GPT在面对社会压力时会从众的现象，这是对现有研究的一个补充和深化，提出了对LLMs在决策中作用的新见解。", "conclusion": "研究结果表明，GPT不具备作为独立观察者的性质，而是会根据感知的社会共识进行调整。因此，将LLMs作为中立的决策辅助工具时存在风险，强调了在向人类提供意见前应先获取AI的判断的重要性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26606", "html_url": "https://arxiv.org/abs/2510.26606", "title": "大型语言模型中的规范推理：从逻辑和模态视角的比较基准", "title_en": "Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives", "authors": "Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada", "background": "规范推理涉及到规范或义务模态，如义务和许可。虽然大型语言模型（LLMs）在各种推理任务中表现出色，但它们处理规范推理的能力仍然没有得到充分探索。本文系统地从逻辑和模态角度评估了LLMs在规范领域的推理能力。", "innovation": "引入了一个涵盖规范和认知领域广泛形式推理模式的新数据集，同时融入了影响人类推理的非形式认知因素。创新在于将LLMs在规范模态推理和表象模态推理之间的性能进行了对比分析。", "conclusion": "尽管LLMs通常遵循有效的推理模式，但在特定类型的规范推理中表现出明显的不一致性，并显示了类似于心理学中对人类推理认知偏差。这些发现凸显了在LLMs的规范推理中实现逻辑一致性的挑战，并为提高其可靠性提供了见解。所有数据和代码已在以下网址公开：this https URL"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26550", "html_url": "https://arxiv.org/abs/2510.26550", "title": "EdgeRunner 20B: 在边缘运行时与GPT-5军事任务性能相当", "title_en": "EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge", "authors": "Jack FitzGerald,Aristotelis Lazaridis,Dylan Bates,Aman Sharma,Jonnathan Castillo,Yousif Azami,Sean Bailey,Jeremy Cao,Peter Damianov,Kevin de Haan,Luke Kerbs,Vincent Lu,Joseph Madigan,Jeremy McLaurin,Jonathan Tainer,Dave Anderson,Jonathan Beck,Jamie Cuticello,Colton Malkerson,Tyler Saltsman", "background": "本文介绍了一种针对军事任务优化的EdgeRunner 20B模型，它是gpt-oss-20b的微调版本。该模型在160万份高质量军事文件和网站资料中进行了训练，并提出了一系列新的测试集，包括战斗兵种、战斗救护、网络作战和mil-bench-5k（一般军事知识）。", "innovation": "EdgeRunner 20B在军事任务测试集中达到了或超过了GPT-5的表现，除了战斗救护测试集中的高推理设置以及mil-bench-5k测试集中的低推理设置外，表现均超越GPT-5。此外，与gpt-oss-20b相比，在通用基准测试上没有统计显著的退步，仅在GSM8k的低推理设置下有所不同。论文还分析了超参数设置、成本和吞吐量。", "conclusion": "研究表明，小型、本地托管的模型是如军事领域等数据敏感操作的理想解决方案。这种模型可以部署于掉线边缘设备。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26658", "html_url": "https://arxiv.org/abs/2510.26658", "title": "代理型组织的时代：利用语言模型进行组织学习", "title_en": "The Era of Agentic Organization: Learning to Organize with Language Models", "authors": "Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei", "background": "本文设想了一个新的AI时代，称为代理型组织，其中代理通过协作和并行工作解决复杂问题，从而产生超出个体智能的结果。为了实现这一愿景，本文介绍了一种新的推理方法——异步思考（AsyncThink），该方法将大型语言模型的内部思考过程组织成并发执行的结构。", "innovation": "本文提出了一种思考协议，其中组织者动态分配子查询、合并中间知识并生成连贯的解决方案。更重要的是，这种思想结构可以通过强化学习进一步优化。实验表明，AsyncThink 在数学推理方面的准确性比并行思考提高了，同时降低了推理延迟，并能够有效处理未见过的任务而无需额外训练。", "conclusion": "本文通过引入AsyncThink，展示了其在推理上的潜力，并通过实验证明其在数学推理任务上的高效性。同时，该方法也提供了将其优化和应用到其他领域的可能性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26603", "html_url": "https://arxiv.org/abs/2510.26603", "title": "代理型AI家庭能源管理系统：一个大型语言模型框架用于住宅负载调度", "title_en": "Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling", "authors": "Reda El Makroum,Sebastian Zwickl-Bernhard,Lukas Kranzl", "background": "家庭能源管理系统（HEMS）在全球电力部门转型过程中具有重要作用，能显著提升住宅响应力需求。然而，其采用受到用户互动障碍的限制，表现为将日常偏好转化为技术参数所需的技术门槛较高。尽管已经将大型语言模型（LLM）应用于能源系统作为代码生成器和参数提取器，但现有技术没有使用LLM作为自主协调者来管理从自然语言输入到多用电器调度的完整工作流程。因此，本研究旨在填补这一空白。", "innovation": "本研究提出了一种代理型AI HEMS系统，其中LLM可以自主协调从自然语言请求到设备控制的多用电器调度，实现了无需示例演示的最优调度。该系统采用层次架构，结合一个调度器和三个专门的代理，使用ReAct模式进行迭代推理，可以实现动态协调，而不依赖固定的流程工作。此外，研究还展示了基于Google日历进行上下文感知截止日期抽取的能力。评估结果显示，Llama-3.3-70B能够成功协调所有电器以匹配通过混合整数线性规划计算的成本最优基准，而其他模型则表现出单个电器完美性能，但在协调所有电器方面遇到困难。渐进式的提示工程实验表明，即使具有概括性推理能力，模型在不提供显式指导的情况下处理分析查询依然不可靠。", "conclusion": "本研究开源了整个系统，包括调度逻辑、代理提示、工具和Web界面，以实现重现性、扩展性和未来研究的便利。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26418", "html_url": "https://arxiv.org/abs/2510.26418", "title": "链式思考劫持", "title_en": "Chain-of-Thought Hijacking", "authors": "Jianli Zhao,Tingchen Fu,Rylan Schaeffer,Mrinank Sharma,Fazl Barez", "background": "大型推理模型 (LRMs) 通过分配更多推理时间的计算资源来实现更高的任务表现，而且先前的研究表明，这种扩大规模的推理也可能通过提高拒绝的能力来增强安全性。然而，本文研究发现，相同推理可以用来绕过保护措施。研究引入了一种名为链式思考劫持 (CoT 立即翻译为“链式思考劫持”在标题中较为准确) 的攻击方法，攻击者通过在有害请求中插入长序列的无害拼图推理，对推理模型进行攻击。这项攻击方法在几个基准测试中取得了极高的成功率，远超此前的类似攻击方法。研究人员还通过机制性分析发现，中间层编码了安全检查的强度，而后期层编码了验证结果，长时间无害的链式思考会削弱这些信号，指导模型偏向于无害的结果。通过对注意力头的关键分析和调整，研究人员证实了这些注意力头确实在安全子网络中起关键作用，导致了模型拒绝有害指令的能力降低。", "innovation": "本文引入了一种名为链式思考劫持的攻击方法，可以绕过扩大小型推理模型的保护机制，虽然这些模型原先旨在通过额外的推理计算来提高其性能和安全性，但这项技术反而展示了即使是最具可解释性的链式思考推理也可能成为攻击向量。研究人员通过针对性地消除关键注意力头的注意力来证明它们对于安全功能的重要性，同时提供了攻击所使用的方法的详细说明，帮助其他研究者复制实验结果。", "conclusion": "研究展示了一个关键结论：最具有可解释性的推理形式在与最终答案提示结合时，也可能成为一种攻击向量。研究提供了攻击所用的提示、模型输出和评估决策，为其他研究者提供了实现实验结果的方法。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26702", "html_url": "https://arxiv.org/abs/2510.26702", "title": "代理授权以约束于语义任务到权限匹配", "title_en": "Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching", "authors": "Majed El Helou,Chiara Troiani,Benjamin Ryder,Jean Diaconu,Hervé Muyal,Marcelo Yannuzzi", "background": "当前的方法在授权代理时提供了过于广泛的权限，这使得代理可以超出预定任务范围进行操作，从而引入了显著的风险。这主要是因为缺乏针对代理授权流程（特别是包含适当和不适当的权限请求数据集）的数据集。因此，作者通过创建一个新的数据集ASTRA和相应的数据生成管道来填补这一空白，以便评估基于语义匹配技术的代理授权模型的有效性。", "innovation": "作者提出了一个代理授权模型，通过授权服务器进行语义分析以检查对受保护资源的访问请求，并签发仅限于代理指定任务所需最小权限集的访问令牌。同时，作者还引入了ASTRA数据集和数据生成管道，以此为基础测试了基于语义匹配的方法。实验结果显示了基于模型的匹配方法的潜力及其当前局限性，特别是在需要更多权限时的表现。", "conclusion": "实验结果强调了在多代理和工具增强应用中进行意图感知授权的进一步研究需求，特别是在细粒度控制方面，例如基于任务的访问控制（TBAC）。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26784", "html_url": "https://arxiv.org/abs/2510.26784", "title": "LLMs使用通用过滤头处理列表", "title_en": "LLMs Process Lists With General Filter Heads", "authors": "Arnab Sen Sharma,Giordano Rogers,Natalie Shapira,David Bau", "background": "本文研究了语言大规模模型（LLMs）在处理列表任务时的机制。作者发现，LLMs 已经学习到编码一种紧凑且因果性的表示，这种表示类似于功能性编程中的“过滤”函数。", "innovation": "研究发现，一小部分注意头（称为过滤头）可以在特定节点的状态中编码过滤谓词的紧凑表示。进一步研究表明，这种谓词表示具有通用性和可移植性，可以被提取并应用于不同的列表集合上执行相同的过滤操作，即使这些集合以不同的格式、语言或任务呈现也是如此。研究还指出，有时变压器语言模型会采用另一种策略进行过滤：即提前评估项是否满足谓词条件，并直接将其中间结果作为标志存储在项表示中。", "conclusion": "研究结果揭示了变压器语言模型可以发展出具有人类可解释性的抽象计算操作实现，并且这些操作的泛化方式与传统功能性编程模式中使用的方法出乎意料地相似。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26732", "html_url": "https://arxiv.org/abs/2510.26732", "title": "跨平台基础模型推理能力评估", "title_en": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models", "authors": "J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot", "background": "本文研究了当代基础模型在推理能力方面的跨平台评估。通过在三个计算平台上进行评估：超级计算机（MareNostrum 5）、云平台（Nebius AI Studio）和大学集群（具有八个H200 GPU的节点），旨在建立一个不依赖基础设施的基准测试，涵盖了物理学、数学、化学、经济学、生物学、统计学、微积分和优化等八个学术领域。", "innovation": "1. 建立了一个跨三个不同计算平台的基准测试，包括超级计算机、云平台和大学集群。\n2. 评估了15个基础模型在79个问题上的能力，涵盖广泛的应用领域。\n3. 提出了三个实验阶段：基准建立、基础设施验证和扩展评估，来评估模型的推理能力。\n4. 结果挑战了传统的扩展假设，指出训练数据质量比模型尺寸更重要，为教育、生产和研究提供行动指南。", "conclusion": "研究发现跨平台推理能力存在差异，提供了关于模型选择的指导性建议。此外，该三基础设施方法和79问题基准测试可以使我们在基础模型演变过程中对其推理能力进行纵向跟踪。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26721", "html_url": "https://arxiv.org/abs/2510.26721", "title": "通过注意力键空间分析揭示多模态大语言模型中的固有文本偏见", "title_en": "Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis", "authors": "Xinhan Zheng,Huyu Wu,Xueting Wang,Haiyun Jiang", "background": "多模态大语言模型（MLLMs）在处理视觉语言数据时倾向于文本输入，限制了它们从视觉证据中有效推理的能力。以往的研究将这种文本偏见归因于外部因素，如数据不平衡或指令调优。本文认为，这种偏见源于模型的内部架构。特别地，该论文假设视觉键向量（视觉键）在仅语言预训练过程中学习的文本键空间中属于离域分布（OOD），导致这些视觉键在注意力计算过程中的相似度评分系统性较低，从而在上下文表示中被系统性地低估。", "innovation": "本文提出了一个新的解释——文本偏见起源于注意力键空间的内在不对齐，而非单纯由于外部数据因素。为了验证这一假设，作者提取了LLaVA和Qwen2.5-VL的键向量，并使用定性和定量方法（t-SNE和Jensen-Shannon差度）分析其分布结构。结果表明视觉键和文本键在注意力空间中占据明显不同的子空间。", "conclusion": "研究表明，文本偏见源自于注意力键空间的固有不匹配，而不仅仅是由于外部数据因素。这种不同意味着需要对多模态大语言模型的内部架构进行改进，以增强其从视觉数据中推理的能力。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25140", "html_url": "https://arxiv.org/abs/2510.25140", "title": "DINO-YOLO: 自监督预训练在土木工程应用中的数据高效目标检测", "title_en": "DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications", "authors": "Malaisree P,Youwai S,Kitkobsin T,Janrungautai S,Amorndechaphon D,Rojanavasu P", "background": "土木工程应用中，物体检测受限于特定领域的标注数据不足。针对这一问题，本文提出了一种混合架构DINO-YOLO，结合了YOLOv12和自监督的DINOv3视觉变压器，以实现高效数据检测。通过在输入预处理(P0)和中等骨干网增强(P3)两个位置整合DINOv3特征，本文验证了显著的性能提升，并保持了实时推理能力(30-47 FPS)。", "innovation": "引入了一种结合YOLOv12和DINOv3的混合架构DINO-YOLO，通过在输入预处理(P0)和中等骨干网增强(P3)两个位置整合DINOv3自监督视觉变压器特征，以实现高效数据检测。验证结果显示在隧道段裂缝检测、建筑个人防护装备识别和KITTI数据集上的性能显著提升，同时保持了实时推理能力。且通过对不同YOLOs和DINOv3变体的系统剖析，发现了适合的融合方式和性能最优的模型参数组合。", "conclusion": "DINO-YOLO在土木工程数据规模(少于10K图像)的应用中达成了最新性能，同时保持了计算效率，提供了适用于施工现场安全监测和基础设施检测的实际解决方案，在数据受限环境下具有实用性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25781", "html_url": "https://arxiv.org/abs/2510.25781", "title": "Kolmogorov-Arnold网络：实践者的指南", "title_en": "A Practitioner's Guide to Kolmogorov-Arnold Networks", "authors": "Amir Noorizadegan,Sifan Wang,Leevan Ling", "background": "Kolmogorov-Arnold网络（KANs）近年来作为一种有前途的替代传统多层感知机（MLPs）的方案受到关注，这主要是基于Kolmogorov-Arnold表征定理。与固定激活函数的MLP不同，KAN使用可学习的边缘基函数，这提高了表示能力和可解释性。本文提供了KAN领域的系统性和全面的回顾，不仅停留在简单的性能比较，还包括理论基础、架构变体和实践实现策略的结构化综合。通过收集和分类大量开源实现，本文映射了支持KAN发展的丰富多彩的生态系统。", "innovation": "文中将KANs与MLPs的概念差距缩小，确立它们的形式等效性，并强调KAN形式下的参数效率更高；概述了多种基函数的选择，包括B样条、切比雪夫和雅可比多项式、ReLU组成、高斯RBF和傅里叶级数，并分析了它们在平滑性、局部性和计算成本方面的权衡；明确了增强准确度、效率和正则化技术的最新进展；提供了实用的“选择您的KAN”指南，帮助实践者选择合适的架构。", "conclusion": "指出了当前研究的空白，附带的GitHub存储库为持续的KAN研究提供结构化的参考。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25783", "html_url": "https://arxiv.org/abs/2510.25783", "title": "LASTIST: LArge-Scale Target-Independent STance dataset", "title_en": "LASTIST: LArge-Scale Target-Independent STance dataset", "authors": "DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park", "background": "在人工智能领域，立场检测研究不断涌现。然而，大部分研究集中在针对特定目标的依赖性立场检测任务上，即关注人们对特定目标的支持或反对立场。大多数基准数据集主要基于英语，使得开发低资源语言如韩语的模型困难重重，尤其是在立场检测这样一个新兴领域。", "innovation": "本文提出了一项名为LASTIST（LArge-Scale Target-Independent STance dataset）的数据集，用以填补这一研究空白。数据集来源于韩国政治党派发布的新闻公告，包含563,299个标注的韩语句子，旨在支持各种立场检测任务，包括无目标立场检测和历时演变立场检测。作者还提供了一套详细的收集和构建数据集的方法，并训练了最先进的深度学习和立场检测模型。", "conclusion": "LASTIST数据集为立场检测任务提供了广泛的支持，包括无目标立场检测和历时演变立场检测，并展示了如何构建和使用该数据集。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25784", "html_url": "https://arxiv.org/abs/2510.25784", "title": "zFLoRA: 零延迟融合低秩适配器", "title_en": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "authors": "Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee", "background": "大规模语言模型（LLMs）通过特定任务适配器被应用于多个下游应用中。尽管适配器参数数量通常不到基础模型的1%，但它们在推理过程中的额外计算成本却异常显著，甚至可能比基础模型高出2.5倍。", "innovation": "本文提出了一种新方法——零延迟融合低秩适配器（zFLoRA），该方法在基础模型上引入几乎无延迟开销的低秩适配器。在1B、3B和7B规模的语言模型上进行的实验表明，zFLoRA在分类准确性和资源效率上优于流行的学习微调基准，包括低秩适配器（LoRA）和完全微调（FFT）。实验涵盖18项不同任务，涉及常识推理、数学推理和摘要对话三大类别。在NPU（Samsung Galaxy S25+）和GPU（NVIDIA H100）平台上进行的延迟测量表明，zFLoRA适配器几乎无延迟开销或延迟开销很小。", "conclusion": "实验结果显示，zFLoRA在多个领域和硬件平台上的性能表现良好，且引入了几乎无延迟开销或延迟开销极小，为优化大规模语言模型的适配器设计提供了新的思路。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26752", "html_url": "https://arxiv.org/abs/2510.26752", "title": "The Oversight Game: 学习如何合作平衡AI代理的安全性和自主性", "title_en": "The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy", "authors": "William Overman,Mohsen Bayati", "background": "随着越来越有能力的代理被部署，一个核心的安全问题是如何在不修改基础系统的情况下保留有意义的人类控制。本文研究一个最小的控制接口，其中代理选择是否自主行动（play）还是请求授权（ask），同时人类同时选择是否放任（trust）或监督（oversee）。如果代理请求授权，人类的选择决定了结果，可能会导致纠正措施或系统关闭。本文将这种交互建模为两人马尔可夫博弈。我们的分析集中在该博弈可以被视为马尔可夫潜力博弈（MPG）的情况下，这是一个可以提供对齐保证的游戏类型：在对人类价值函数的一个结构假设下，任何代理更多自主行为的选择如果对自己有利，则不会对人类造成损害。此外，我们还分析了这种MPG框架的扩展。理论地讲，这种视角提供了特定形式内生对齐的条件。如果人类-代理博弈的奖励结构满足这些条件，那么我们将有一个正式保证：代理提升自己结果的决策不会损害人类。实践上，该模型激励一个透明的控制层，具有可预测的激励，其中代理在有风险时学习请求，安全时行动，而其预训练策略和环境的奖励结构保持不变。网格世界仿真表明，通过独立学习，代理和人类发现了他们的最佳监督角色。代理在不确定时学习请求，而人类学习何时监督，从而产生了避免训练后引入的安全违规的共生合作。这展示了部署后使不阿对齐的模型更安全的实用方法。", "innovation": "本文提出了最小控制接口的特定形式，即代理选择自主行动或请求授权，人类选择是否放任或监督。通过马尔可夫博弈建模，并且可以作为马尔可夫潜力博弈（MPG）来提供对齐保证。研究的理论扩展了条件下的内生对齐形式。在实践上，这种方法激励了一种透明的控制层，该层具有可预测的激励措施，确保代理认知到何时应自主行动，何时应请求授权，而不会改变预训练策略和环境奖励结构。模型通过独立学习使代理和人类都能逐步找到最佳的监督角色，并避免训练后的安全违规。这种方法展示了怎样在部署后使不阿对齐的模型更安全。", "conclusion": "网格世界模拟表明，代理和人类能够通过独立学习找到各自的最佳监督角色。代理在不确定时学习请求授权，人类学习何时进行监督，从而避免了训练后的安全违规。这种方法不仅为理解代理和人类在自主性和安全性方面如何平衡提供了一个框架，并且提供了在不修改预训练策略和环境奖励结构的情况下使模型更安全的方法。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25785", "html_url": "https://arxiv.org/abs/2510.25785", "title": "HiMAE：层次化掩蔽自动编码器发现可穿戴时间序列的分辨率特定结构", "title_en": "HiMAE: Hierarchical Masked Autoencoders Discover Resolution-Specific Structure in Wearable Time Series", "authors": "Simon A. Lee,Cyrus Tanade,Hao Zhou,Juhyeon Lee,Megha Thukral,Minji Han,Rachel Choi,Md Sazzad Hissain Khan,Baiying Lu,Migyeong Gwak,Mehrab Bin Morshed,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Subramaniam Venkatraman,Sharanya Arcot Desai", "background": "穿戴设备提供了大量的生理时间序列数据，但其预测效用的原理尚不明确。研究推测，时间分辨率是特征表示学习的基本轴线，不同的临床和行为结果依赖于不同尺度的结构。为了验证这一假设，研究引入了HiMAE（层次化掩蔽自动编码器），该框架结合了掩蔽自动编码和分层次卷积编码解码器，生成多分辨率嵌入，从而系统性地评估哪些时间尺度承载着预测信号，将分辨率从超参数转变为可解释性的探针。", "innovation": "研究提出了HiMAE，一种结合掩蔽自动编码和分层次卷积编码解码器的自监督学习框架，能够生成多分辨率嵌入，评估哪些时间尺度有预测信号。该方法在分类、回归和生成任务中均优于现有降低时间尺度差异基础模型，且其模型规模小得多。更重要的是，HiMAE能够在智能手表级别的CPU上实现亚毫秒级的推理，实现了真正的边缘推理，是高效的自监督学习方法，并为穿戴设备中的时间敏感结构发现提供了工具。", "conclusion": "HiMAE结合了高效自监督学习方法及发现时间尺度敏感结构的工具，能够在穿戴设备上进行真正的边缘推理。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25779", "html_url": "https://arxiv.org/abs/2510.25779", "title": "Magentic Marketplace: 开源环境中的代理市场研究", "title_en": "Magentic Marketplace: An Open-Source Environment for Studying Agentic Markets", "authors": "Gagan Bansal,Wenyue Hua,Zezhou Huang,Adam Fourney,Amanda Swearngin,Will Epperson,Tyler Payne,Jake M. Hofman,Brendan Lucier,Chinmay Singh,Markus Mobius,Akshay Nambi,Archana Yadav,Kevin Gao,David M. Rothschild,Aleksandrs Slivkins,Daniel G. Goldstein,Hussein Mozannar,Nicole Immorlica,Maya Murad,Matthew Vogel,Subbarao Kambhampati,Eric Horvitz,Saleema Amershi", "background": "随着大模型代理技术的发展，它们越来越多地代替用户做出经济决策，从产品发现到交易等。虽然这些应用带来了诸多好处，但也引发了关于代理责任和用户价值等相关问题。为了回答这些问题，需要理解代理在现实市场条件下的行为。然而，现有研究主要是在受限环境下对代理进行评估，例如单一任务市场（比如谈判）或结构化的双代理互动。现实世界市场的本质差异在于需要代理处理多样的经济活动，并在充满复杂行为和开放对话的大规模动态生态系统中进行协调。为了弥合这一差距，研究者探讨了一种双方代理市场，其中助手代理代表消费者，服务代理代表竞争企业，以此研究实时的互动机制。他们开发了一个名为Magentic-Marketplace的模拟环境，以确保安全地进行代理间的互动，从而研究关键的市场动态：代理实现的效用、行为偏差、抗操纵性以及搜索机制对市场结果的影响。实验表明，前沿模型在理想搜索条件下可以接近最优福利，但随着规模扩大，性能急剧下降，所有模型都表现出严重的第一提议偏见，导致回应速度相对于质量的优势达到10-30倍。这些发现揭示了在不同市场条件下代理行为的演变过程，指导设计公平和高效代理市场的方法。", "innovation": "研究者开发了一个名为Magentic-Marketplace的模拟环境来研究代理市场。该环境能确保安全地让助手代理和代理服务代表互动，以此研究关键市场动态，包括效用实现、行为偏差、抗操纵性和搜索机制影响市场的结果。研究还揭示了代理行为在不同市场条件下的演变过程，并指出前沿模型在理想搜索条件下可以接近最优福利，但随着规模扩大，性能急剧下降，所有模型都表现出严重的第一提议偏见。", "conclusion": "尽管前沿模型在理想搜索条件下可以接近最优福利，但在大规模和复杂环境中，它们的表现会急剧下降，并且表现出严重的第一提议偏见，为响应速度而非质量。这些发现揭示了代理市场动态的关键特点，为设计公平和高效的代理市场提供了指导。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25786", "html_url": "https://arxiv.org/abs/2510.25786", "title": "黑箱NLP-2025 机制可解释性基准（MIB）共享任务：通过改进边选择提高电路忠实度", "title_en": "BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better Edge Selection", "authors": "Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov", "background": "机制可解释性的一个主要挑战是电路发现，即确定模型中哪些部分负责执行特定任务。过去的研究虽然取得了一些进展，但仍然面临诸多挑战，包括如何有效地识别出哪些部分是真正负责执行特定任务的。为此，本文基于已有的机制可解释性基准（MIB）测试套件，提出了一种改进电路发现的方法。这种方法通过使用自助法（bootstrapping）来标识一致性归因分数的边，引入基于比率的选择策略优先选择高得分的边，并采用整数线性规划公式代替传统的贪婪选择方法，以提升电路的忠实度。这些改进方法在多个MIB任务和模型上显著优于之前的手段，展现了显著的性能提升。", "innovation": "本文提出了一种改进的电路发现方法，主要创新点包括：1）使用自助法识别出一致性的边；2）提出基于比率的选择策略，平衡性能和忠实度；3）用整数线性规划公式替代了传统的贪婪选择方法。这些改进不仅提升了电路的忠实度，还在多个MIB任务上的表现也超越了之前的方法。", "conclusion": "通过基于MIB平台提出的方法改进，电路的忠实度得到了显著提升。实验结果表明，本文提出的方法在多个任务和模型上都优于以往的手段。本文的代码可以在指定的URL处找到。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25798", "html_url": "https://arxiv.org/abs/2510.25798", "title": "MemEIC：迈向持续性和组合性知识编辑", "title_en": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing", "authors": "Jin Seong,Jiyun Park,Wencke Liermann,Hongseok Choi,Yoonji Nam,Hyun Kim,Soojong Lim,Namhoon Lee", "background": "信息的动态性质要求不断更新大型视觉-语言模型（LVLMs）。虽然最近的知识编辑技术显示出有希望的方向，但这些技术通常集中于单独编辑单一模态（视觉或语言），而忽略了LVLMs的固有跨模态性和知识更新的连续性，可能导致在考虑模态间的互动和持续的知识精炼时编辑效果不佳。这些问题带来了改进现有方法的需求。", "innovation": "为了解决这些限制，提出了一种名为MemEIC的新方法，用于LVLMs中的持续性和组合性知识编辑（CCKE）。MemEIC允许按顺序对视觉和文本知识进行组合编辑。提出的方法采用了混合外部-内部编辑器，结合了用于跨模态证据检索的双外部存储器和便于每个模态独立参数更新的双LoRA适配器。关键组件是一个基于大脑的知识连接器，仅在进行组合推理时激活，以整合不同模态的信息。实验表明，MemEIC在复杂跨模态问题上的性能显著提高，并有效保留了先前的编辑，为LVLMs中的CCKE设定了新的基准。", "conclusion": "MemEIC显著改善了复杂跨模态问题上的性能，并且有效保留了先前的编辑设定，成为LVLMs中持续性和组合性知识编辑的新基准。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25796", "html_url": "https://arxiv.org/abs/2510.25796", "title": "使用基于模拟的强化学习在大规模按需拼车系统中实现非短视匹配和重新平衡", "title_en": "Non-myopic Matching and Rebalancing in Large-Scale On-Demand Ride-Pooling Systems Using Simulation-Informed Reinforcement Learning", "authors": "Farnoosh Namdarpour,Joseph Y. J. Chow", "background": "拼车服务通过乘客共享交通工具以降低成本并减少交通拥堵和环境影响，但当前的调度决策通常是短视的，无法考虑长期效应。因此，本文提出了一种基于强化学习的非短视学习与规划框架，并通过模拟重新平衡闲置车辆，以提高系统效率和减少运营成本，特别是在大型按需拼车系统中。", "innovation": "本文创新地将基于模拟的强化学习方法应用于拼车系统，这是该领域的一项创新。通过嵌入拼车模拟来实现非短视决策，并提出了一种重新平衡闲置车辆的互补策略，从而提高了匹配决策和服务效率，同时减少了运营成本和乘客的时间成本。相比传统的短视政策，新模型可以减少车队规模超过25%，并将服务率提高8.4%；同时将等待时间和车内时间分别减少27.3%和12.5%，而每名乘客的车辆行驶时间略有增加。", "conclusion": "本研究提出的非短视调度和重新平衡策略在实际数据上得到了验证，显示出显著的成本节约潜力和效率提升，特别是在大规模按需拼车服务中。这种方法在减少交通拥堵和优化资源利用方面具有广泛应用前景。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25818", "html_url": "https://arxiv.org/abs/2510.25818", "title": "ScaleDiff：通过高效且模型无关的扩散生成高分辨率图像", "title_en": "ScaleDiff: Higher-Resolution Image Synthesis via Efficient and Model-Agnostic Diffusion", "authors": "Sungho Koh,SeungJu Cha,Hyunwoo Oh,Kwanyoung Lee,Dong-Jin Kim", "background": "文本到图像的扩散模型在生成超过训练分辨率的图像时往往会表现出退化性能。现有的无需额外训练的方法可以缓解这一限制，但它们通常需要大量的计算资源，或者与最近的扩散变换器模型不兼容。", "innovation": "我们提出了ScaleDiff，一种不进行额外训练且适用于多种模型的高效率框架，用于扩展预训练的扩散模型的分辨率。核心组件是邻域片段注意(NPA)，这是一种高效的机制，它通过非重叠片段减少了自我注意层中的计算冗余。我们将在SDEdit管道中整合NPA，并引入隐空间频率混合(LFM)来更好地生成细节。此外，我们还应用了结构引导，以在去噪过程中增强全局结构。", "conclusion": "实验结果表明，ScaleDiff在基于U-Net和扩散变换器的架构中，在无需额外训练的方法中实现了最高的图像质量和推理速度。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25787", "html_url": "https://arxiv.org/abs/2510.25787", "title": "基于电压依赖性突触可塑性的无监督局部学习机制用于阻变和铁电突触", "title_en": "Unsupervised local learning based on voltage-dependent synaptic plasticity for resistive and ferroelectric synapses", "authors": "Nikhil Garg,Ismael Balafrej,Joao Henrique Quintino Palhares,Laura Bégon-Lours,Davide Florini,Donato Francesco Falcone,Tommaso Stecconi,Valeria Bragaglia,Bert Jan Offrein,Jean-Michel Portal,Damien Querlioz,Yann Beilliard,Dominique Drouin,Fabien Alibart", "background": "边缘计算设备在部署AI时面临着能耗和功能性的重大挑战。这些设备可以从模仿人脑学习机制中获益，实现实时适应并使用低能耗。忆阻器突触中的脉冲计算（如纳米尺度的电阻式记忆元）可能在边设备上执行AI工作负载方面发挥关键作用。在此研究中，我们探讨了基于Hebb原则的电压依赖性突触可塑性（VDSP）作为在忆阻器突触中实现无监督和局部学习的一种高效方法。", "innovation": "我们提出了一种基于VDSP的无监督和局部学习机制，该机制基于Hebb原则，并且能够在无需复杂脉冲整形电路的情况下实现在线学习。该方法已被应用于三种具有不同切换特性的忆阻器设备（TiO$_2$、HfO$_2$基金属氧化物和HfZrO$_4$基铁电隧道结突触），并进行了系统级模拟以验证其在MNIST基于的模式识别任务上的性能，达到了最先进的效果。", "conclusion": "系统级模拟结果显示，在使用200个神经元的情况下，所有设备的分类准确率均超过83%。此外，我们评估了设备变量的影响，例如切换阈值和高阻态和低阻态之间的比率，并提出了增强鲁棒性的缓解策略。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25791", "html_url": "https://arxiv.org/abs/2510.25791", "title": "Chain-of-Thought (CoT) 监督如何塑造Transformer的学习动力学？", "title_en": "The Kinetics of Reasoning: How Chain-of-Thought Shapes Learning in Transformers?", "authors": "Zihan Pengmei,Costas Mavromatis,Zhengyuan Shen,Yunyi Zhang,Vassilis N. Ioannidis,Huzefa Rangwala", "background": "chain-of-thought（CoT）监督能够显著提高Transformer的表现，但模型如何学习遵循和受益于CoT的具体机制仍不明确。本文通过在具有可调算法复杂度和可控数据组成的象征性推理任务上预训练Transformer来研究这些学习动态，以此来探讨其泛化能力。模型在两种情况下进行训练：(i)仅产生最终答案，(ii)在回答之前发出显式的CoT痕迹。研究表明，虽然CoT普遍提高了任务性能，但其收益依赖于任务的复杂度。通过使用一个三参数逻辑曲线模型量化这些效果，揭示了学习速度和形状如何随任务复杂度、数据分布以及CoT监督的出现而变化。此外，还发现了一个短暂的痕迹不忠实阶段：在训练早期，模型常常能够给出正确的答案，但却跳跃或违背了CoT步骤，之后这些模型的推理痕迹才与答案对齐。", "innovation": "本文提出了一种动力学建模框架来理解Transformer的学习过程，进一步将CoT的忠实性识别为一个动态属性，且证明CoT会从机制上改变Transformer的内部计算。通过这种方法理解了CoT如何影响Transformer的学习动态学，为理解模型的学习机制提供了新的见解。", "conclusion": "尽管CoT加速了模型的泛化，但它无法解决更高算法复杂度的任务，如查找列表交集，且CoT促进了学习过程中的动力学属性；CoT监督结束了对内部Transformer计算的机械性变化，使得理解模型是如何利用CoT进行推理变得更加清晰。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS: 通过自我蒸馏偏好导向冷启动解耦多模态学习", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "近年来，可验证奖励的强化学习（RL）推动了‘MLLM-r1’方法的发展，将RL引入了视觉语言模型。大多数方法开始于冷启动阶段，通常利用有监督微调（SFT）初始化策略，但SFT方法将任务求解和输出格式结合在一起，可能会导致指令式过拟合，减弱了该模型的泛化能力，这对后续的RL产生了不良影响。已有研究考察了冷启动的训练方法和数据构建，并引入了泛化因子（GF）系数来量化不同方法下的泛化能力。实验发现，偏好导向的训练方法（例如DPO）在冷启动时表现出更好的泛化能力。", "innovation": "本文提出了一种名为SPECS的自我蒸馏偏好导向冷启动框架，通过解耦多模态学习来提高模型性能。具体而言，SPECS框架包括生成自我蒸馏偏好数据对以避免依赖大型教师模型或人工标注；偏好导向训练以学习浅层、可迁移的表层形式标准（格式、结构、风格）而非记忆内容；最终为深度推理结果输送带有验证奖励的RL。实验结果表明，该框架在多个多模态基准上的性能明显优于强基线，并显著提升了几项基准的得分。", "conclusion": "SPECS框架通过解耦冷启动阶段和通过自我蒸馏的方法有效地改善了模型的泛化能力和下游RL性能，降低了分布内陷阱，提升了探索度和鲁棒性，并显著提高了最终性能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25819", "html_url": "https://arxiv.org/abs/2510.25819", "title": "Agentic AI身份管理：AI代理世界的授权、认证与安全的新疆域", "title_en": "Identity Management for Agentic AI: The new frontier of authorization, authentication, and security for an AI agent world", "authors": "Tobin South,Subramanya Nagabhushanaradhya,Ayesha Dissanayaka,Sarah Cecchetti,George Fletcher,Victor Lu,Aldo Pietropaolo,Dean H. Saxe,Jeff Lombardo,Abhishek Maligehalli Shivalingaiah,Stan Bounev,Alex Keisner,Andor Kesselman,Zack Proser,Ginny Fahs,Andrew Bunyea,Ben Moskowitz,Atul Tulshibagwale,Dazza Greenwood,Jiaxin Pei,Alex Pentland", "background": "随着AI代理的迅速崛起，认证、授权和身份管理面临着紧迫的挑战。当前的代理中心协议（如MCP）突显出在认证和授权方面需要明确的最佳实践需求。展望未来，对高度自主代理的追求引发了关于可扩展访问控制、代理中心身份、AI工作负载差异化以及权限委派等复杂长期问题的关注。", "innovation": "该论文由OpenID基金会发布，旨在为AI代理和访问管理交叉领域的利益相关者提供资源和战略议程。它概述了现有的资源，以确保当前代理的安全，并提出了一项战略议程，以解决关键的身份验证、授权和身份问题，这些问题对于未来广泛自主系统的普及至关重要。", "conclusion": "该论文提出了一项战略议程，以应对即将来临的自主系统所带来的根本性的认证、授权和身份问题，旨在为AI代理世界提供有效的授权、认证和安全解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25863", "html_url": "https://arxiv.org/abs/2510.25863", "title": "AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI", "title_en": "AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI", "authors": "Ken Huang,Jerry Huang,Yasir Mehmood,Hammad Atta,Muhammad Zeeshan Baig,Muhammad Aziz Ul Haq", "background": "该论文讨论了针对自主语言模型驱动代理在生产环境中所面临的独特安全和治理挑战。传统的应用程序安全工具对于即兴、机器速度系统来说存在局限性。", "innovation": "AAGATE是一种Kubernetes原生控制平面，它通过操作化NIST AI风险管理系统框架（AI RMF）解决了这些问题。AAGATE集成了一系列针对RMF功能的专业安全框架：MAESTRO语言模型威胁建模框架、基于OWASP的AIVSS和SEI的SSVC的混合框架以及云安全联盟的Agentic AI红队指南。此外，AAGATE还引入了零信任服务网格、可解释的策略引擎、行为分析和分散式问责挂钩，提供了一种持续、可验证的治理解决方案，确保部署的安全、可问责并可扩展。", "conclusion": "该框架进一步扩展了数字身份权利、逻辑层注入防御和认知退化监控，以确保治理涵盖系统性、对抗性和伦理风险。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25890", "html_url": "https://arxiv.org/abs/2510.25890", "title": "PRISM: 通过LLM x MDE协同和分层约束实现带验证的构件生成", "title_en": "PRISM: Proof-Carrying Artifact Generation through LLM x MDE Synergy and Stratified Constraints", "authors": "Tong Ma,Hui Lai,Hui Wang,Zhenhu Tian,Jizhou Wang,Haichao Wu,Yongfan Gao,Chaochao Li,Fengjie Xu,Ling Fang", "background": "在安全性和合规性至关重要的领域，需要生成符合监管要求的文件和证据。传统方法常涉及大量人工审查和修正，效率低下且容易出错。当前，大型语言模型（LLM）和模型驱动工程（MDE）成为了自动化生成和验证工具的强大支持。", "innovation": "PRISM通过统一元模型（UMM）将异构数据模式和监管文本统一到单一语义空间中；结合集成约束模型（ICM）将结构和语义需求编译为执行文件，如生成时期自动机（GBNF、DFA）和后生成验证器（如SHACL、SMT）；并通过约束指导验证生成（CVG）进行两层强制执行。当出现违规时，PRISM提供审计指导的修复并记录生成踪迹用于合规审查。", "conclusion": "PRISM在汽车软件工程（AUTOSAR）和跨境司法管辖（布鲁塞尔规约I bis）中进行了评估，生成结构有效、可审计的构件，并与现有工具集成，大幅降低了人工修正工作量，提供了一条实现自动化构件生成与内置验证的切实可行路径。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25904", "html_url": "https://arxiv.org/abs/2510.25904", "title": "评价LLM辅助注释在视角化设置中的影响：框架注释案例研究", "title_en": "Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation", "authors": "Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent", "background": "LLM（大型语言模型）在加速或替代人类劳动力创建语言资源和数据集方面的应用已经成为现实。尽管这些工具在语言学研究中有潜在价值，但对于它们在注释数据集中的表现和影响，尤其是从视角化的人工智能处理自然语言处理(NLP)方法进行综合评估，仍然缺乏全面的评价。该论文通过详细研究LLM辅助框架语义标注来填补这一空白，评估不同注释方法的效果。", "innovation": "该研究创新地采用了混合半自动化方法对框架语义标注进行详细评估，比较了三种实验设置的手动标注、自动标注和半自动标注。结果显示，在提高了框架多样性并保持类似注释覆盖率的同时，半自动标注显著减少了注释时间。与完全自动标注相比，虽然它在所有评估指标上表现较差，但在特定情况下仍具优势。", "conclusion": "论文通过全面评估LLM辅助框架语义标注，表明混合半自动化方法不仅提高了语义标注的多样性和覆盖范围，还显著节省了时间，从而为视角化背景下自然语言处理的研究提供了有价值的参考。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25924", "html_url": "https://arxiv.org/abs/2510.25924", "title": "使用代理进行因果效应转移", "title_en": "Transferring Causal Effects using Proxies", "authors": "Manuel Iglesias-Alonso,Felix Schur,Julius von Kügelgen,Jonas Peters", "background": "该研究考虑了在多域环境中估计因果效应的问题。背景中提到存在的未观测到的混杂因素导致了因果效应的混淆，并且在不同域中因果效应可能发生变化。作者假设可以通过观察到的代理变量来近似隐藏的混杂因素，所有变量都被假定为离散或分类变量。在此背景下，研究者提出了新的方法来估计目标域中的因果效应，假设仅观察到代理变量。验证了即便在处理变量和响应变量为连续变量的情况下，该方法也依然具有可识别性。", "innovation": "研究提出了两种估计技术，证明了一致性，并推导出置信区间。研究理论结果通过模拟研究和例子得到了支持，该例子研究了网站排名对消费者选择的因果效应，证明了提出方法的有效性。", "conclusion": "研究证明了在目标域中使用代理变量来估计因果效应的可能性，并提供了理论支持和实际案例，证明了方法的有效性和实用性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25947", "html_url": "https://arxiv.org/abs/2510.25947", "title": "重新审视语言模型预训练中的多语言数据混合", "title_en": "Revisiting Multilingual Data Mixtures in Language Model Pretraining", "authors": "Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut", "background": "关于大规模语言模型（LLMs）预训练中不同多语言数据混合的影响，一直是一个持续争论的话题。人们对语言覆盖面和模型性能之间的潜在权衡（即多语言性诅咒）表示担忧。", "innovation": "本研究通过训练参数量为1.1B和3B的不同规模的LLMs，并在多种语言的语料库上进行实验，涵盖了从25到400种语言，挑战了关于多语言训练的常见信念。具体而言，发现将英语和多语言数据结合不需要降低双方的语言性能，只要包含足够的令牌数。此外，使用英语作为枢纽语言（一种高资源语言，作为多语言推广的催化剂）可以跨越语系提供益处，与预期相反，从中选择枢纽语言在特定语系内部选择并不一致地提升该领域语言的表现。最后，当训练语言数量增加时，未观察到大规模模型中的‘多语言性诅咒’。", "conclusion": "研究结果表明，适量平衡的多语言数据可以增强语言模型的能力，甚至在资源不足的情况下也不必牺牲表现。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25929", "html_url": "https://arxiv.org/abs/2510.25929", "title": "市场做市中的多智能体强化学习：无勾结的竞争", "title_en": "Multi-Agent Reinforcement Learning for Market Making: Competition without Collusion", "authors": "Ziyi Wang,Carmine Ventre,Maria Polukarov", "background": "算法性勾结在人工智能领域成为了一个核心问题。研究不同AI代理在市场互动时是否会形成勾结至关重要。此外，理解新兴行为（如卡特尔或更高级别机器人的市场主导）对整体市场的影响也非常重要。为此，本文提出了一个多层级多智能体强化学习框架来研究市场做市中的算法性勾结。", "innovation": "本文提出了一个包含自我利益做市商（Agent A）和其他三个具有不同目标的竞争者（Agent B1, B2, 和B星）的多层级多智能体强化学习框架。通过这个框架，本文分析了这些智能体之间的交互如何影响彼此的行为和市场结果。通过实验结果验证，框架展示了智能体如何在零和游戏中影响订单流，以及在共存时智能体如何通过自适应报价策略获得市场优势。", "conclusion": "实验结果表明，在共存情况下，智能体B2通过更激进的报价策略获得了市场优势，但对其他智能体的盈利影响较小。智能体B星则表现出了更偏向于自身利益的行为倾向，通过不断调整报价策略获得了较高的市场占有率，但对其他智能体的影响相对较小。这些发现表明，在异质智能体环境中，自适应激励控制可以支持更可持续的战略共存，并为算法交易系统的行为设计提供了一个结构性视角。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25935", "html_url": "https://arxiv.org/abs/2510.25935", "title": "基于过程挖掘的软件开发工作流分析和预测系统", "title_en": "A Process Mining-Based System For The Analysis and Prediction of Software Development Workflows", "authors": "Antía Dorado,Iván Folgueira,Sofía Martín,Gonzalo Martín,Álvaro Porto,Alejandro Ramos,John Wallace", "background": "CodeSight 是一个端到端系统，旨在预测软件开发工作流中的截止日期合规性。该系统从 GitHub 直接捕获开发和部署数据，并将其转换为过程挖掘日志，以便详细分析。从这些日志中，系统生成提供有关 PR 活动模式和工作流程效率的可操作见解的指标和仪表板。", "innovation": "CodeSight 基于结构化表示采用 LSTM 模型，预测剩余 PR 解决时间，基于顺序活动痕迹和静态特征，实现对潜在截止日期违规的早期识别。实验表明，该系统在预测截止日期合规性方面具有高精度和 F1 分数，证明了将过程挖掘与机器学习结合应用于主动软件项目管理的价值。", "conclusion": "该系统展示了集成过程挖掘与机器学习方法在预测软件开发截止日期合规性方面的优势，为软件项目管理提供了早期预警和决策支持。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25992", "html_url": "https://arxiv.org/abs/2510.25992", "title": "监督强化学习：从专家轨迹到逐步推理", "title_en": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning", "authors": "Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee", "background": "大型语言模型（LLMs）在需要多步推理的问题上通常表现不佳。对于小型开源模型，强化学习结合可验证奖励（RLVR）在正确解决方案罕见采样后即使经过许多尝试仍然失败，而监督微调（SFT）则倾向于通过逐个模仿令牌来过度拟合长示例。这些方法未能充分应对模型推理能力的挑战。", "innovation": "本文提出了一种新的框架——监督强化学习（SRL），将问题解决重新定义为生成逻辑“动作”序列。SRL 训练模型在执行每个动作之前先生成内部推理说明。这种方法基于与SFT数据集中提取的专家动作之间的相似度提供逐步奖励，即使所有模拟都是错误的，也能提供更丰富的学习信号，同时鼓励根据专家演示的启发式进行灵活推理。SRL 使小型模型能够解决以往通过SFT或RLVR手段不可解决的复杂问题，且在使用SRL初始化训练后再用RLVR优化时，整体性能最强。", "conclusion": "SRL不仅在推理基准测试中表现出色，还有效地推广到了代理型软件工程任务，确立了其作为理解导向的大语言模型稳健且多功能训练框架的地位。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25960", "html_url": "https://arxiv.org/abs/2510.25960", "title": "WaveVerif：基于声学旁路的机器人工作流程验证", "title_en": "WaveVerif: Acoustic Side-Channel based Verification of Robotic Workflows", "authors": "Zeynep Yasemin Erdogan,Shishir Nagaraja,Chuadhry Mujeeb Ahmed,Ryan Shah", "background": "本文介绍了一种使用声学旁通道分析（ASCA）来监控和验证机器人是否正确执行其预期命令的框架。该系统利用由机器人运动产生的声学排放来进行工作流验证，并考虑了运动速度、方向和麦克风距离等因素。研究结果表明，在基线条件下，使用四种不同的分类器（支持向量机SVM、深度神经网络DNN、循环神经网络RNN和卷积神经网络CNN）准确验证个体机器人运动的准确率超过80%。此外，诸如拾取和放置以及包装等流程也可以以高置信度进行识别。", "innovation": "开发了一种基于机器学习的工作流程验证系统，利用机器人运动产生的声学排放进行实时行为的验证。该系统利用声学信号在不需修改硬件的情况下支持敏感机器人环境中的实时、低成本、非侵入性验证。", "conclusion": "实验结果表明，在基线条件下，该系统可以测试机器人运动的准确性超过80%，对于复杂的任务如拾取和放置以及包装等流程，该系统也可以提供高度的验证信心。这些发现展示了声学信号在无硬件修改的条件下，支持敏感机器人环境中的实时验证的能力。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25976", "html_url": "https://arxiv.org/abs/2510.25976", "title": "Brain-IT: 通过脑交互变换器从fMRI重建图像", "title_en": "Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer", "authors": "Roman Beliy,Amit Zalcher,Jonathan Kogman,Navve Wasserman,Michal Irani", "background": "从功能性磁共振成像(fMRI)记录重建人类看到的图像提供了一种非侵入性的观察大脑的方式。尽管近年来通过扩散模型取得了进展，但目前的方法往往缺乏对实际看到的图像的忠实度。", "innovation": "本文提出了一种名为“Brain-IT”的脑启发方法，该方法通过脑交互变换器（BIT）解决了这一挑战，允许功能相似的脑体素集群之间的有效交互。这些功能簇在所有受试者中共享，作为整合信息的构建块，既在单脑内，也在跨脑之间。所有模型组件共享所有簇和受试者，从而实现高效训练并使用有限的数据。通过BIT预测两种互补的局部补丁级图像特征，即引导扩散模型向图像正确语义内容前进的高级语义特征，以及帮助初始化扩散过程的低级结构特征，来指导图像重建。BIT的设计使信息可以直接从脑体素簇流向局部图像特征。通过这些原则，我们的方法实现了从fMRI重建图像，并在视觉效果和标准客观度量指标上超过了当前的SotA方法。此外，仅使用新受试者1小时的fMRI数据，我们获得了与当前基于40小时全数据训练方法相当的结果。", "conclusion": "通过脑交互变换器（BIT）有效预测局部补丁级图像特征，实现从fMRI重建图像，达到了与当前SotA方法相当甚至更好的效果，仅需极少的数据即可实现类似的效果。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26014", "html_url": "https://arxiv.org/abs/2510.26014", "title": "离散时间生存分析的双重混合专家框架", "title_en": "Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis", "authors": "Hyeonjun Lee,Hyungseob Shin,Gunhee Nam,Hyeonsoo Lee", "background": "生存分析是指建模感兴趣事件发生的时间的任务，广泛应用于临床和生物医学研究。主要挑战是能够在捕捉患者异质性的同时，使风险预测适应个体特征和时间动态。", "innovation": "本文提出了一种双重混合专家（MoE）框架，用于离散时间生存分析。该方法结合了特征编码MoE，用于亚组感知的表征学习，以及一个使用患者特征和时间嵌入来捕捉时间动态的危险MoE。该双重MoE设计灵活地与现有的基于深度学习的生存分析管线集成。", "conclusion": "在METABRIC和GBSG乳腺癌数据集上，本方法在测试集上持续提高了性能，时间依赖C-指数提升高达0.04，并在集成到Consurv框架中时进一步提高了效果。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26007", "html_url": "https://arxiv.org/abs/2510.26007", "title": "追求可靠的责任人工智能评价指标", "title_en": "The Quest for Reliable Metrics of Responsible AI", "authors": "Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Christina Lioma", "background": "人工智能（AI）的发展，包括科学中的AI（AIS），应该遵循负责任AI的原则。虽然负责性AI的进步通常通过评价指标来量化衡量，但对这些评价指标本身的稳健性和可靠性评估却较少受到关注。早期研究集中在推荐系统中的公平性评价指标的稳健性上，并总结出了一些非详尽的指南来开发可靠的负责任AI评价指标。这些指南适用于广泛的AI应用，包括科学中的AI。", "innovation": "本文创新地提出了一个针对负责性AI评价指标可靠性的非详尽指南，其应用范围广泛，不仅限于推荐系统，而是涵盖了广泛的AI应用场景，特别是科学中的AI。", "conclusion": "作者通过总结推荐系统中公平性评价指标的稳健性研究，提出了适用于肩负社会责任的AI评价指标开发的一系列非详尽指南，强调了对评估指标可靠性的关注对于发展负责任的AI的重要性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26004", "html_url": "https://arxiv.org/abs/2510.26004", "title": "DARTS：基于无人机的人工智能实时交通事故检测系统", "title_en": "DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System", "authors": "Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang", "background": "快速可靠的事故检测对于减少与事故相关的死亡、受伤和拥堵至关重要。然而，传统的检测方法，如闭路电视、汽车记录仪录像和基于传感器的检测，存在灵活性有限、需要密集的基础设施或高渗透率的问题，从而限制了其适应性和可扩展性。特别是在事故频发地区，现有的检测方法难以满足需求。因此，需要一种新的解决方案来克服上述挑战。", "innovation": "为了克服这些挑战，我们开发了DARTS，这是一种基于无人机的人工智能实时交通事故检测系统。DARTS将无人机的高机动性和空中视角整合用于适应性监控，利用热成像提高低能见度下的性能和隐私保护，并采用轻量级深度学习框架进行实时车辆轨迹提取和事故检测。DARTS在自收集的数据集上实现了99%的检测准确率，并通过基于网络的界面支持同时在线视觉验证、严重程度评估和由事故引起的拥堵传播监控。该系统在佛罗里达州州际公路75号路段的实地测试中，提前12分钟检测并验证了一个追尾事故，并监测了由事故引起的拥堵传播。这表明DARTS具有支持更快的应急响应和实现预防性交通控制，以减少拥堵和二次事故风险的潜力。DARTS灵活部署架构减少了频繁物理巡逻的依赖，显示出其在远程地区和资源受限环境中的可扩展性和成本效益。", "conclusion": "本研究提出了一种有助于提高现代交通管理运营效率和响应性的更灵活和集成的实时交通事故检测系统。DARTS代表了交通管理领域的一个重要进展。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26017", "html_url": "https://arxiv.org/abs/2510.26017", "title": "基于深度学习的沿海城市适应性洪水预测", "title_en": "Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep Learning", "authors": "Bilal Hassan,Areg Karapetyan,Aaron Chung Hin Chow,Samer Madanat", "background": "气候变化和海平面上升(SLR)对沿海城市构成了日益严重的威胁，促使需要高效准确的方法来预测潜在的洪水风险。传统的物理模拟器虽然精确，但由于计算成本高，不适合用于城市规模的沿海规划应用。深度学习技术提供了替代方案，但往往受到数据稀缺和高维输出要求的限制。", "innovation": "本文开发了一种基于卷积神经网络(CNN)的新型轻量级模型，该模型可以预测在不同SLR情景和海岸线适应方案下的沿海洪水。研究中利用了来自阿布扎比和旧金山的两个不同区域的数据集，展示了模型在不同地理背景下的泛化能力。模型在预测水深图中的平均绝对误差(MAE)几乎降低了20%，结果表明，该方法具有成为沿海洪水管理的可扩展和实用工具的潜力。", "conclusion": "研究证明了所提出的方法显著优于当前最先进的方法，通过提供更准确的洪水预测，为决策者制定了应对气候变化不断增长影响的有效缓解策略提供了支持。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26024", "html_url": "https://arxiv.org/abs/2510.26024", "title": "重新思考跨语言对齐：在多语言LLMs中平衡转移与文化 erasure", "title_en": "Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs", "authors": "HyoJung Han,Sweta Agrawal,Eleftheria Briakou", "background": "跨语言对齐（CLA）旨在将多语言表示相关联，使大型语言模型（LLMs）能够无缝地在语言之间传递知识。虽然直观上这似乎是有益的，但我们假设这种追求表示上的一致性可能会无意中导致“文化 erasure”，即丧失根据查询语言提供情境化响应的能力。", "innovation": "文中引入了一个全面的评估框架，即转移-本地化平面，用于量化期望的知识转移和不希望的文化 erasure。通过对最近的CLC方法进行重新评估，发现它们在提高事实转移的同时，普遍牺牲了文化本地化能力。研究还揭示了关键洞察：通用事实转移和地域性知识在不同模型层上优化不同。", "conclusion": "基于这一发现，提出了一种新的推理时方法：外科手术式指导，通过有针对性地对不同层进行激活指导，实现了在这两个竞争维度之间的更好平衡。这种方法有效地克服了当前对齐技术的局限性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26032", "html_url": "https://arxiv.org/abs/2510.26032", "title": "人工智能辅助分析放射学报告：偶然性甲状腺发现的流行病学及其后果", "title_en": "Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings", "authors": "Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito", "background": "非甲状腺疾病影像检查中检测到的偶发性甲状腺发现（ITFs）越来越常见，但其发病率、特征及临床后果尚不清楚。", "innovation": "开发、验证并部署了基于变压器的自然语言处理（NLP）管道来识别放射学报告中的ITFs，并评估其发病率、特征及其临床结果。", "conclusion": "ITFs在人群中普遍存在，与检测到小、低风险癌症的串联事件密切相关。这些发现强调了ITFs在甲状腺癌过度诊断中的作用，并突显了需要标准化报告和更具选择性的随访。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26020", "html_url": "https://arxiv.org/abs/2510.26020", "title": "PORTool: 使用奖励树进行工具使用的大语言模型训练", "title_en": "PORTool: Tool-Use LLM Training with Rewarded Tree", "authors": "Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao", "background": "当前的语言模型是基于静态数据集进行训练的，使它们能够与外部工具进行交互并执行多步骤、工具整合推理，从而产生工具调用轨迹。然而，这些模型在解决查询时仅模仿了通用工具调用过程的处理方式，没有探索多种可能的解决方案，在动态变化的工具调用环境中表现有限。", "innovation": "本文提出了一种新的强化学习方法PORTool，旨在鼓励工具使用的大语言模型探索多种可能的轨迹，从而找到正确的答案。PORTool通过生成多个轨迹来开始，部分轨迹共享一部分初始工具调用步骤，形成树状结构。接着，根据每一个步骤产生正确答案和成功调用工具的能力赋予奖励，相同的步骤获取相同的奖励，不同的步骤获取不同的奖励。基于这些逐步奖励计算分支相对优势和轨迹相对优势，以此来训练大语言模型用于工具使用。", "conclusion": "实验利用17种不同的工具来处理用户查询，涵盖了及时和非及时的主题。通过消融实验系统地验证了逐步奖励的必要性和设计鲁棒性。同时将PORTool与其他训练方法进行比较，显示出在最终准确性和工具调用步骤数量方面有了显著改进。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26018", "html_url": "https://arxiv.org/abs/2510.26018", "title": "RADRON：利用康普顿相机的MAVs协作探测离子辐射源", "title_en": "RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras", "authors": "Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska", "background": "本文提出了一种利用微型空中车辆（MAVs）协同探测放射性材料的新方法。该方法使用了最先进的单探测器康普顿相机，作为一种高度灵敏但体积小巧的 ionizing 辐射探测器。特别是飞行器的极低重量使得多架敏捷的 MAVs 能够进行协同合作以进行辐射探测成为可能。这些康普顿相机的数据采集和处理在飞行器上直接进行，并利用所得结果驱动飞行器运动，形成一个动态反馈路径。MAVs 形成一个紧密协作的队列以最大化康普顿探测器获取的信息，快速定位辐射源，并可能跟踪移动的辐射源。", "innovation": "本文提出了一种创新性的方法，即利用合作的微型空中车辆与康普顿相机来探测放射性材料的位置。通过直接在飞行器上进行数据读取和处理，能够实时从极稀疏的探测数据中估计辐射源的位置。这种方法不仅提高了辐射探测的效率，还能够在移动环境中有效跟踪辐射源。", "conclusion": "本文提出了一种新的康普顿相机融合方法，能够实时从极稀疏的数据中估计辐射源的位置。通过在飞行器上直接进行数据读取与处理，并与动态反馈驱动的方式结合，实现了MAVs与康普顿相机的紧密协作，能够快速和准确地定位并跟踪移动的辐射源。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26052", "html_url": "https://arxiv.org/abs/2510.26052", "title": "基于Vision-Language模型的扩散模型动态负提示方法", "title_en": "Dynamic VLM-Guided Negative Prompting for Diffusion Models", "authors": "Hoyeon Chang,Seungjin Kim,Yoonseok Choi", "background": "传统负提示方法使用固定的负提示来降低生成图像的某些特征，但这种方法缺乏灵活性和针对性。因此，本文介绍了一种新颖的方法，利用Vision-Language模型在去噪过程中自适应地生成负提示，以提高文本与图像的对齐度并优化生成效果。", "innovation": "本文提出了一种利用Vision-Language模型（VLMs）在去噪过程中动态生成负提示的方法。与传统的固定负提示方法不同，该方法在特定的去噪步骤中生成中间图像预测，并查询VLM以生成上下文相关的负提示，从而提高了生成图像和文本之间的匹配度，同时增强了负提示的引导强度与图像生成之间的权衡关系，实现了更好的生成效果和图像对齐性。", "conclusion": "本文的方法在各种基准数据集上进行了评估，结果显示这种方法能够有效平衡负提示强度与文本图像对齐之间的关系，从而提高生成图像的质量和文本的准确度。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26061", "html_url": "https://arxiv.org/abs/2510.26061", "title": "基于数据驱动的投影生成以高效解决异构二次规划问题", "title_en": "Data-driven Projection Generation for Efficiently Solving Heterogeneous Quadratic Programming Problems", "authors": "Tomoharu Iwata,Futoshi Futami", "background": "本文提出了一种数据驱动框架，用于通过减少高维二次规划（QP）问题中的变量数量来高效求解QP问题。通过基于图神经网络的模型生成针对每个QP实例定制的投影，即使对于未见过的问题，也能产生高质量的解。模型在不同类型的QP上进行训练，以最小化预测解决方案的目标函数值的期望。这是一个二阶优化问题；内部优化在给定投影下求解QP问题，而外部优化更新模型参数。", "innovation": "本文创新性地提出了一种图神经网络为基础的模型，用于生成定制化的投影。模型能够针对每个QP实例生成专一的投影，使求解器能够高效地找到高质量的解。此外，提出了一种高效的算法来解决这种二阶优化问题，无需从求解器反向传播参数梯度。并且，对使用神经网络生成的投影矩阵求解QP问题的泛化能力进行了理论分析。实验结果表明，相比现有方法，该方法能够产生高质量可行解，同时减少计算时间。", "conclusion": "本文提出的方法通过减少变量数量和优化投影矩阵，显著提升了二次规划问题的求解效率。实验结果表明，该方法在解决异构QP问题时具有较高的性能，是现有方法的有力替代方案。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识蒸馏（KD）是一种有效的模型压缩方法，可以将知识从一个模型转移到另一个模型。然而，这种技术对模型在对抗数据上的鲁棒性的影响（特别是在处理虚假相关性时）尚未得到全面研究。本文研究了知识蒸馏对教师模型中的去偏见能力转移到学生模型的效果，特别是在自然语言推断（NLI）和图像分类任务中的应用。研究发现，整体而言，知识蒸馏会对模型的去偏见能力产生负面影响。", "innovation": "本文是首次大规模研究知识蒸馏与去偏见方法的可蒸馏性之间的关系。研究提出三种改进方法：高质量数据增强、迭代知识蒸馏以及学生模型初始化使用教师模型权重，为理解和改进去偏见方法的工作机制提供了新的见解和策略。", "conclusion": "研究结果显示，知识蒸馏后去偏见能力会受到损害，且注重要素包括内部注意力模式和电路对不同类型的偏见有显著影响。基于此，提出了改进措施，旨在提高去偏见方法的可蒸馏性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26037", "html_url": "https://arxiv.org/abs/2510.26037", "title": "SIRAJ：通过提炼结构化推理实现LLM代理多样化和高效的安全测试框架", "title_en": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "authors": "Kaiwen Zhou,Ahmed Elgohary,A S M Iftekhar,Amin Saied", "background": "大模型语言代理（LLM）能够规划和调用工具的能力使它们面临新的安全风险，因此制定全面的红队系统对于发现漏洞并确保其安全部署至关重要。现有的研究中，红队测试方法通常针对特定的模型或场景，缺乏一种通用的框架来应对任意黑盒的LLM代理。", "innovation": "本文提出了一种名为SIRAJ的通用红队框架，该框架采用动态两步过程，首先定义代理，并生成广泛的种子测试案例，覆盖各种风险结果、工具使用轨迹和风险来源；然后基于先前尝试的执行轨迹，逐步构建和改进基于模型的对抗攻击。此外，本文还提出了一种模型提炼方法，通过利用教师模型推理的结构化形式来训练较小但同样有效的模型。实验结果表明，SIRAJ的方法提高了2-2.5倍的风险结果和工具调用轨迹覆盖率，同时，8B的红队模型在攻击成功率上超越了671B的Deepseek-R1模型。", "conclusion": "本文提出的SIRAJ框架通过迭代过程、结构化推理和模型的普遍化，有效提高了红队测试的效率和效果，对于确保LLM代理的安全部署具有重要意义。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26068", "html_url": "https://arxiv.org/abs/2510.26068", "title": "学习几何：通过度量优化构建自适应流形模型的框架", "title_en": "Learning Geometry: A Framework for Building Adaptive Manifold Models through Metric Optimization", "authors": "Di Zhang", "background": "这篇论文提出了一个超越传统参数优化的新机器学习范式。传统的机器学习方法在固定几何空间中搜索最优参数，而本文的核心思想是将模型本身视为可塑的几何实体。具体来说，通过优化具有预定义拓扑结构的流形上的度量张量场，动态调整模型空间的几何结构。", "innovation": "本文创新地提出了一种基于度量优化的框架，通过一个变分框架，在保证数据保真度的同时，控制流形的内在几何复杂性，实现模型的自适应调整。此外，引入了一种基于离散微分几何的方法，将连续流形离散化为三角网格，并通过边长参数化度量张量，利用自动微分工具进行高效的优化。", "conclusion": "这项工作为构建具有完全动态几何和拓扑结构的“元学习器”奠定了坚实的基础，并在科学模型发现和鲁棒表示学习等领域具有广泛的应用前景。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26105", "html_url": "https://arxiv.org/abs/2510.26105", "title": "多模态模型中文本与图像间错位的安全风险", "title_en": "Security Risk of Misalignment between Text and Image in Multi-modal Model", "authors": "Xiaosen Wang,Zhijin Ge,Shaokang Wang", "background": "尽管多模态扩散模型，如图文模型，在各方面取得了显著进展，但在对抗输入方面的脆弱性仍然没有得到充分研究。现有扩散模型中图文模态间的对齐不足，这种不匹配的风险在生成不适当或不适合工作环境（NSFW）的内容时尤为明显。", "innovation": "本文提出了一种名为Prompt-Restricted Multi-modal Attack（PReMA）的新攻击方法。PReMA 能通过修改输入图像并与任何指定提示结合来操控生成的内容，而无需修改提示本身。PReMA 是首个仅通过创建对抗图像来操控模型输出的攻击，不同于先前主要生成对抗提示来产生 NSFW 内容的方法。", "conclusion": "综合评估表明，PReMA 对多模态扩散模型特别是那些使用固定提示的图像编辑应用构成了新型威胁。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26083", "html_url": "https://arxiv.org/abs/2510.26083", "title": "Nirvana: 具有任务感知记忆机制的领域专家通用模型", "title_en": "Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism", "authors": "Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou", "background": "传统的大型语言模型（LLM）如Transformer、线性注意力模型及混合模型在特定领域并未采用由任务信息引导的专门记忆机制。它们表现为缺乏在目标领域达到专家级性能的同时保持广泛能力。因此，领域专家通用模型（Specialized Generalist Models, SGMs）旨在融合这两方面的能力，但在实际应用中，模型未能很好地根据当前任务的需求灵活调整记忆机制，进而实现领域适应性。本文旨在填补这一空白，提出了一种具有任务感知记忆机制的领域专家通用模型Nirvana，该模型具备线性时间复杂度和测试时任务信息提取功能.", "innovation": "文章提出了Nirvana模型，这是一种能够灵活调整记忆机制的领域专家通用模型，特别引入了Task-Aware Memory Trigger（$Trigger$）和Specialized Memory Updater（$Updater$）。Task-Aware Memory Trigger可以智能调整记忆机制以适应当前任务的具体需求；Specialized Memory Updater则根据Trigger动态地记住上下文信息。通过实验证明，Nirvana在通用自然语言处理任务和专门的医疗任务（如MRI成像）上表现出色，尤其是在任务相关的参数发生变化时，能够更好地进行领域适应.", "conclusion": "Nirvana模型不仅在多种自然语言建模基准测试中取得了与现有LLM结构相当或更优的结果，还在医疗任务如MRI成像中实现了高质量的重建结果及准确的前期临床报告生成。Task-Aware Memory Trigger的应用验证了模型的领域适应能力，证明了其在各种场景下超越了传统LLM模型的优点。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26099", "html_url": "https://arxiv.org/abs/2510.26099", "title": "SAFE：一种通过地球分层预测评估的新方法来评估AI天气预报", "title_en": "SAFE: A Novel Approach to AI Weather Evaluation through Stratified Assessments of Forecasts over Earth", "authors": "Nick Masi,Randall Balestriero", "background": "传统的机器学习模型评估侧重于基于测试集内所有样本的平均损失来进行评估，这在气象和气候领域等地理空间数据上意味着平均了全球各地的性能表现。但是这种方法忽略了人类发展和地理分布的非均匀分布。SAFE（Stratified Assessments of Forecasts over Earth）方法通过整合不同地理网格点相关的属性数据（如地域、全球子区域、收入和土地覆盖类型）来进行分层评估，从而使我们能够分别考察每个个体地层（例如每个国家的预测准确性）的模型性能。", "innovation": "SAFE引入了一种新的评估框架，可以在多种地理网格点的多种属性（如国家、地理区域、收入水平和土地覆盖类型）之间进行分层评估。通过这种方法，可以揭示当前最先进的AI天气预测模型在不同属性下的性能差异和公平性，从而为模型评估提供一种更加细致和全面的方式。", "conclusion": "通过SAFE框架，我们首次能够识别出模型在哪种情况下表现最好或最差，同时也可以评估哪种模型更加公平。这对于未来进一步研究模型的性能和公平性具有重要意义。SAFE框架为开放源代码包，可在此获取：[链接]。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26113", "html_url": "https://arxiv.org/abs/2510.26113", "title": "EgoExo-Con：探索视角不变的视频时间理解", "title_en": "EgoExo-Con: Exploring View-Invariant Video Temporal Understanding", "authors": "Minjoon Jung,Junbin Xiao,Junghyun Kim,Byoung-Tak Zhang,Angela Yao", "background": "研究视频-LLM在拍摄同一事件但不同视角的视频中能否保持一致的时间理解能力。为了研究这一问题，论文引入了EgoExo-Con（一致性）基准数据集，该数据集包含同步的主观（第一人称）和客观（第三人称）视频对，并配备了自然语言的人工改进查询，用于评估模型在不同视角中的时间一致性。EgoExo-Con不仅强调时间验证任务，还强调时间定位任务，旨在评估和改善模型在多视角下的一致性表现。", "innovation": "论文首次提出了EgoExo-Con基准数据集，并识别了现有视频-LLM中的两个关键局限：（1）跨视角的一致性保持能力较差；（2）尽管通过同步视频微调，模型的一致性有所提高，但可能仍然劣于单视角训练的效果。为此，论文提出了View-GRPO，这是一种新的强化学习框架，能够有效强化特定视角的时间推理能力，同时促进跨视角的一致理解。", "conclusion": "View-GRPO方法显示出优于简单的直接微调（SFT）和GRPO的方法，特别是在改善跨视角一致性方面。所有研究资源将公开提供。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26089", "html_url": "https://arxiv.org/abs/2510.26089", "title": "基于网络约束的自适应多智能体车辆路由策略优化", "title_en": "Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle Routing", "authors": "Fazel Arasteh,Arian Haghparast,Manos Papagelis", "background": "城市道路上的交通拥堵导致旅行时间变长和排放增加，特别是在高峰时段。传统的最短路径优先(SPF)算法在静态网络中对于单个车辆是有效的，但在动态的多车辆环境中表现不佳，常会导致拥堵加剧。因此，研究如何利用多智能体强化学习(MARL)框架实现协调、网络感知的车队导航，以解决动态车辆路由问题是必要的。", "innovation": "本文通过提出自适应导航(AN)和分层枢纽自适应导航(HHAN)两种方法来解决这一问题。AN是一种去中心化的MARL模型，每个交叉口代理基于局部交通和用图注意力网络(GAT)建模的邻域状态提供导航指导。为提高大型网络的可扩展性，HHAN将代理仅分配到关键交叉口(枢纽)，车辆在智能代理控制下在枢纽之间路由，而SPF负责每个枢纽区域内的微路由。HHAN采用集中训练分散执行(CTDE)框架下的注意力Q混合(A-QMIX)模式进行协调，通过注意力聚合异步车辆决策。枢纽代理使用结合了局部拥堵和预测动态的流动态状态特征，以实现更为积极的导航。", "conclusion": "实验结果表明，AN相比SPF和学习基线可以降低平均旅行时间，且保持100%的路由成功率。HHAN在大型网络中表现出良好的可扩展性，即使在高峰时段也能实现高达15.9%的改进。这些研究结果突显了在网络约束下使用MARL进行可扩展、协调和拥堵感知导航的潜力。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26125", "html_url": "https://arxiv.org/abs/2510.26125", "title": "WOD-E2E：Waymo 开放数据集——在挑战性的长尾场景中实现端到端驾驶", "title_en": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios", "authors": "Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Kate Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Drago Anguelov", "background": "基于视觉的端到端（E2E）驾驶因其可扩展性和与多模态大规模语言模型（MLLMs）的协同作用而引起了研究社区的广泛关注。然而，当前的E2E驾驶基准主要包含常规场景，无法充分检验这些系统的真实潜力。此外，现有的开环评估指标往往无法充分捕捉驾驶的多模态性质，或在长尾场景下不能有效评估性能。", "innovation": "本文介绍了Waymo 开放数据集（WOD-E2E），特别为罕见的长尾场景设计，这些场景在日常生活中出现的频率低于0.03%，并且包含4,021个驾驶段（约12小时），每个段落包含高阶路线信息、ego状态以及八个周边摄像头的全景视图。为此，提出了一个新的开环评估指标：评分反馈得分（RFS），用于评估E2E驾驶在长尾情况下的性能。RFS衡量预测轨迹与评估者标注的路径偏好标签的契合度，不同于传统度量，后者仅衡量预测航点与日志之间的距离。", "conclusion": "通过我们的工作，旨在促进通用化、鲁棒和安全的E2E自主驾驶代理的研究，这类代理能够处理复杂的现实世界情况。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26157", "html_url": "https://arxiv.org/abs/2510.26157", "title": "通过子结构感知对齐弥合分子与文本描述之间的差距", "title_en": "Bridging the Gap Between Molecule and Textual Descriptions via Substructure-aware Alignment", "authors": "Hyuntae Park,Yeachan Kim,SangKeun Lee", "background": "分子和文本表示学习由于其增强对化学信息理解的潜力，已经引起了越来越多的关注。然而，现有的模型在捕捉分子与其描述之间细微差别时经常遇到困难，因为它们缺乏学习分子亚结构与化学短语之间精细对齐的能力。", "innovation": "我们提出了一种名为MolBridge的新颖分子-文本学习框架，它基于亚结构感知的对齐。具体而言，MolBridge通过从分子亚结构和化学短语中获得的附加对齐信号，增强了原始分子-描述对。为了有效利用这些丰富的对齐信号，MolBridge采用了亚结构感知对比学习，并结合了一个自我修正机制来过滤掉噪声的对齐信号。", "conclusion": "实验结果表明，MolBridge能够捕捉到细微的对应关系，并在广泛的一系列分子基准测试中优于现有的最先进的基线，强调了亚结构感知对齐在分子-文本学习中的重要性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26159", "html_url": "https://arxiv.org/abs/2510.26159", "title": "复杂性胜于分段：工业时间序列异常检测的集成与混合方法评估", "title_en": "Segmentation over Complexity: Evaluating Ensemble and Hybrid Approaches for Anomaly Detection in Industrial Time Series", "authors": "Emilio Mastriani,Alessandro Costa,Federico Incardona,Kevin Munari,Sebastiano Spinello", "background": "本研究探讨了在多变量工业时间序列中，特别是在汽轮机系统中，高级特征工程和混合模型架构对于异常检测的有效性。研究关注变化点衍生的统计特征、基于聚类的子结构表示以及混合学习策略对检测性能的影响。尽管这些复杂方法在理论上具有吸引力，但在实际应用中，它们的有效性远不如基于分段数据训练的随机森林+XGBoost集成模型。", "innovation": "研究创新在于通过对比复杂方法和基于分段的简单模型，展示了在高度不平衡和时间不确定的数据情况下，简单模型结合优化的分段策略，可以超越更复杂的架构，提供更高的鲁棒性、可解释性和运营实用性。这种发现对于实际应用具有重要意义，尤其是对于工业时间序列数据的异常检测而言。", "conclusion": "研究结论表明，在高不平衡和时间不确定性数据的情景下，简单模型结合优化分段可以优于更复杂的架构。这种模型不仅提供了更高的鲁棒性、可解释性，还具有更好的操作实用性。研究结果强调了在某些情况下，简单的模型加上有效的数据处理方法可以超越更加复杂的模型。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26151", "html_url": "https://arxiv.org/abs/2510.26151", "title": "MV-MLM: 联通多视角乳腺X光图像和语言模型以实现乳腺癌诊断与风险预测", "title_en": "MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction", "authors": "Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba", "background": "大型标注数据集对于训练信用卡癌检测或风险预测的计算机辅助诊断（CAD）模型至关重要。然而，获得这些包含精细标注的数据集既昂贵又耗时。视觉语言模型（VLM），如CLIP，这些模型在大规模图像-文本对上进行了预训练，可以通过增强医学影像任务中的鲁棒性与数据效率，提供了一种有希望的解决方案。", "innovation": "本文提出了一种名为MV-MLM的新型多视角乳腺X光图像与语言模型，在配对的乳腺X光图像和合成放射学报告的数据集上进行训练，利用多视角监督学习策略，通过跨模态自我监督来学习丰富的影像数据表示。此外，该模型采用了一种新的联合视觉-文本学习策略，以增强不同数据类型和任务上的泛化能力和准确性。模型在私有和公开数据集上的评估表明，该模型在恶性肿瘤分类、亚型分类和基于图像的癌症风险预测任务上均取得了最先进的性能。而且，该模型还显示出强大的数据效率，即使在合成文本报告的训练下，也优于现有的全监督或VLM基线。", "conclusion": "本文通过将多视角乳腺X光图像与语言模型相结合，提出了一个新的学习框架，该框架不仅利用了丰富的视觉信息，还利用了语言信息以增强模型的分类和预测性能。实验结果表明，该方法在多个分类任务上达到了最先进的性能，并显示出强大的数据效率。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26185", "html_url": "https://arxiv.org/abs/2510.26185", "title": "Accumulative SGD Influence Estimation for Data Attribution", "title_en": "Accumulative SGD Influence Estimation for Data Attribution", "authors": "Yunxiao Shi,Shuo Yang,Yixin Su,Rui Zhang,Min Xu", "background": "现代数据驱动型AI需要精确的逐样本影响分析。标准的SGD-IE通过累积每个epoch的替代指标来近似leave-one-out效应，并忽视了跨epoch的影响累积，导致对关键样本的错误排名。", "innovation": "该文提出了ACC-SGD-IE，这是一种轨迹感知估计器，能够在训练过程中传播leave-one-out扰动，并在每一步更新累积影响状态。在光滑强凸设置中，它实现了几何误差收缩；在光滑非凸域中，它收紧了误差界限；更大的mini-batch进一步减少常数。", "conclusion": "在Adult、20 Newsgroups和MNIST数据集上，无论是在干净数据还是被污染数据，还是在凸性和非凸性训练条件下，ACC-SGD-IE都能提供更准确的影响估计，尤其是在长时间训练时。此外，它还能更可靠地标记噪声样本，在经过ACC-SGD-IE清洁后的数据上训练得到的模型表现更好，超过使用SGD-IE清洁后的模型。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26130", "html_url": "https://arxiv.org/abs/2510.26130", "title": "超越合成基准：评估LLM在实际类级代码生成中的性能", "title_en": "Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation", "authors": "Musfiqur Rahman,SayedHassan Khatoonabadi,Emad Shihab", "background": "大型语言模型（LLMs）已经在功能层面的代码生成上取得了显著进展，但在实际软件项目中生成正确的类级实现的能力仍不清楚。本文通过从开源仓库中提取真实世界的类，并将其分为已知和未知两部分，引入了一个新型基准，以评估LLMs在实际条件下的泛化能力。评估在多种LLMs，输入规范、检索增强配置和文档完整性水平下进行。结果显示，LLMs在现有的合成基准上达到84%到89%的正确率，但在实际类任务上仅达到25%到34%，这之间没有明显差异。详细的文档字符串在功能准确性上仅提供微小提升，误差分析发现最常见的错误模式是AttributeError、TypeError和AssertionError。检索增强技术在部分文档下表现最好，会改善正确性4%到7%。尽管如此，合成测试仍侧重于断言问题，而实际场景则强调类型和属性匹配错误。检索增强减少逻辑漏洞，但可能引入依赖冲突。总之，目前LLMs在类级工程方面的局限性需要增强上下文建模、文档策略和检索集成，以提升生产代码辅助工具的有效性。", "innovation": "引入了一个基于开源仓库的真实世界类分割新型基准，评估LLMs在实际条件下的泛化能力，探讨了LLMs在多种输入规范、检索增强配置和文档完整性水平下的性能表现。通过错误分析识别出主导错误模式，并提出检索增强技术在部分文档下的有效性。这些研究为改进LLMs在实际类级代码生成中的性能提供了重要的指导意义。", "conclusion": "现有合成基准在测试LLMs实际类级代码生成性能方面存在局限，LLMs在真实类任务上的表现远远低于合成基准。详细的文档字符串对功能准确性有轻微提升，但检索增强技术在部分文档下最有效，通过提供具体的实现模式来改善正确性。虽然这减少了逻辑错误，但可能引入依赖冲突。文章展示了LLMs在真实世界中的局限性，并提出改进上下文建模、文档策略和检索集成的建议。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26186", "html_url": "https://arxiv.org/abs/2510.26186", "title": "ConceptScope：通过解耦视觉概念表征数据集偏差", "title_en": "ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts", "authors": "Jinho Choi,Hyesu Lim,Steffen Schneider,Jaegul Choo", "background": "在机器学习数据集中普遍存在数据点向某些概念的偏斜现象，但要系统地识别这些偏差通常需要昂贵且精细的属性注释。本研究旨在通过一种可扩展且自动化的框架（ConceptScope）来解决这一问题，该框架利用从视觉基础模型中提取的表示进行稀疏自动编码器训练，从而揭示并量化可解读的概念。通过这种方式，ConceptScope能够根据不同类别的数据集特征、识别偏差并利用基于概念的子组进行鲁棒性评估。", "innovation": "本研究提出了ConceptScope框架，该框架通过稀疏自动编码器在视觉基础模型表示上训练来发现和量化人类可解释的概念。这种框架能够将概念分类为目标、背景和偏误类型，并基于语义相关性和统计关联来对分类，从而实现基于概念的子组分组，用于数据集特征描述、偏误识别和鲁棒性评估。此外，ConceptScope还能够检测已知的偏差以及未标注的新偏差，提供了一个实用的数据集审计和模型诊断工具。", "conclusion": "通过与标注数据集的比较，研究验证了ConceptScope能捕获各种视觉概念，包括物体、纹理、背景、面部属性、情感和动作。进一步研究表明，概念激活能够与具有语义意义的图像区域对齐。ConceptScope能够可靠地检测已知偏见并发现未标注的偏见，为数据集审计和模型诊断提供了一种实用的方法和工具。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26188", "html_url": "https://arxiv.org/abs/2510.26188", "title": "从住院患者医疗理赔数据预测所有原因再住院", "title_en": "Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients", "authors": "Avinash Kadimisetty,Arun Rajagopalan,Vijendra SK", "background": "减少可预防的再次住院是支付方、提供者和政策制定者提高医疗质量和降低医疗成本的国家优先事项。再住院率正被用作衡量医院提供医疗服务质量的标准。本项目使用了机器学习技术，如逻辑回归、随机森林和支持向量机，对健康索赔数据进行分析，以识别在预测所有原因再住院中起关键作用的人口统计学和医学因素。由于健康索赔数据具有高维性，我们采用了主成分分析作为降维技术，并使用其结果来构建回归模型。根据曲线下面积（AUC）度量进行了模型的比较与评估。随机森林模型表现最佳，其次是逻辑回归和支持向量机模型。这些模型可以用于识别导致再住院的关键因素，帮助识别需要关注的患者，从而降低再住院率，最终降低医疗成本并提高患者医疗服务的质量。", "innovation": "本项目使用了机器学习技术，如逻辑回归、随机森林和支持向量机，以及主成分分析作为降维技术，对健康索赔数据进行分析，来预测所有原因的再住院情况。这种方法不仅提高了预测的准确性，而且有助于识别关键人口统计学和医学因素，为减少再住院率提供了数据支持。", "conclusion": "随机森林模型表现最佳，其次是逻辑回归和支持向量机模型。通过这些模型，可以识别导致所有原因再住院的关键因素，并帮助识别需要重点关注的患者群体，从而降低医疗成本，提高医疗服务的质量。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26202", "html_url": "https://arxiv.org/abs/2510.26202", "title": "我的人类反馈中有什么？学习可解释的偏好数据描述", "title_en": "What's In My Human Feedback? Learning Interpretable Descriptions of Preference Data", "authors": "Rajiv Movva,Smitha Milli,Sewon Min,Emma Pierson", "background": "人类反馈可以以不可预测和不希望的方式来改变语言模型，因为从业者缺乏对反馈数据编码的明确理解。尽管现有的研究已经探讨了某些属性的偏好（例如长度或阿谀奉承），但在无需预先设定假设的情况下自动提取相关特征仍然具有挑战性。", "innovation": "本文引入了一种名为WIMHF的方法，利用稀疏自编码器来解释反馈数据。WIMHF能够表征（1）数据集能够测量的偏好以及（2）注释者实际上表达的偏好。这种方法有助于理解人类偏好多样性以及数据集级别的上下文作用，并揭示潜在的不安全偏好，如Reddit用户更偏好非正式和幽默内容，而HH-RLHF和PRISM的注释者则更不喜欢这些特征。WIMHF帮助进行有效的数据编辑和精细的个性化调整。", "conclusion": "WIMHF为从业者提供了一种以人为中心的分析方法，使他们能够更好地理解和利用偏好数据，从而提高模型的安全性和个性化效果。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26172", "html_url": "https://arxiv.org/abs/2510.26172", "title": "使用协调代理流连接异构数据以进行社交媒体分析", "title_en": "Linking Heterogeneous Data with Coordinated Agent Flows for Social Media Analysis", "authors": "Shifu Chen,Dazhen Deng,Zhihong Xu,Sijia Xu,Tai-Quan Peng,Yingcai Wu", "background": "社交媒体平台生成了大量异构数据，涵盖了用户行为、文本内容、时间动态和网络结构。分析这些数据对于理解意见动态、社区形成和信息传播等现象至关重要。然而，从这一复杂场景中发现见解是探索性的、概念性上具有挑战性的，并且需要在社交媒体挖掘和可视化方面具有专门知识。现有的自动化方法尽管越来越多地利用大规模语言模型（LLMs），但仍主要局限于结构化的表数据，无法充分解决社交媒体分析的异构性问题。", "innovation": "论文提出了SIA（Social Insight Agents），这是一种基于LLM的代理系统，能够将原始输入（如文本、网络和行为数据）、中间输出、挖掘分析结果和可视化成果通过协调的代理流进行连接。SIA基于自底向上的分类法，将洞察类型与合适的挖掘和可视化技术相连接，使代理能够规划和执行连贯的分析策略。为了确保多模态集成，SIA整合了一个数据协调器，将表格、文本和网络数据统一成一个一致的流程。SIA还提供了一个交互式界面，用户可以追踪、验证和细化代理的推理过程，支持适应性和可靠性。", "conclusion": "通过专家中心案例研究和定量评估，论文展示了SIA有效地从社交媒体中发现多样且有意义的见解，同时支持人类与代理在复杂分析任务中的协作。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26200", "html_url": "https://arxiv.org/abs/2510.26200", "title": "不要让它们消退：通过分步时间分配保留扩散语言模型中的编辑", "title_en": "Don't Let It Fade: Preserving Edits in Diffusion Language Models via Token Timestep Allocation", "authors": "Woojin Kim,Jaeyoung Do", "background": "扩散语言模型（DLMs）能够实现精细的调整，但其实际可控性仍然相对脆弱。研究中识别并正式描述了一种核心失败模式——更新遗忘，这种现象导致不均匀且上下文无关的更新在各个时间步引起标记级别的波动，抹去了早期的语义编辑，破坏了累积细化过程，进而降低流畅性和连贯性。", "innovation": "为了解决这一问题，研究提出了Token Timestep Allocation (TTA)。TTA 通过每个标记的时间步长安排实现软且语义上灵活的标记排序：关键标记在早期冻结，而不确定的标记则持续优化。这种基于时间步长的排序可以在固定的策略或基于任务信号的适应性策略中体现，从而支持广泛的细化策略。由于它仅在推理时间发挥作用，因此适用于各种扩散语言模型，并自然扩展到多种监督来源。", "conclusion": "实验证明，TTA 提高了可控性与流畅性：在情感控制任务上，TTA 达到的准确率提高了超过20%，几乎将困惑度减半，并且使用不到五分之一的时间步长；在去毒化任务上，最大毒性降低（12.2 对比 14.5），且困惑度降低（26.0 对比 32.0）。这些结果表明，通过时间步长分配实现的软排序是缓解更新遗忘、实现稳定可控的扩散文本生成的关键杠杆。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26165", "html_url": "https://arxiv.org/abs/2510.26165", "title": "超越简单效用函数学习管理投资组合", "title_en": "Learning to Manage Investment Portfolios beyond Simple Utility Functions", "authors": "Maarten P. Scholl,Mahmoud Mahfouz,Anisoara Calinescu,J. Doyne Farmer", "background": "尽管投资基金在公开披露其目标时采用广泛的说法，但其管理者却优化了复杂的、相互竞争的目标组合，这些目标超出了简单的风险-收益权衡。传统方法试图通过多目标效用函数来建模这一过程，但面临规格化和参数化的根本挑战。现有的方法难以准确地捕捉基金管理人策略的深层次含义，并且通常需要明确的奖励函数或专家目标，尤其是在使用强化学习或模仿学习方法时，这在实际应用中是不切实际的。本研究探讨了一种新的生成框架，该框架能够学习基金经理策略的潜在表示，无需显式定义效用函数。", "innovation": "该研究提出了一个生成性框架，该框架能够学习未指定效用函数下的基金经理策略的潜在表示。该方法直接建模给定股票特征、历史回报、先前权重和一个表示基金策略的潜在变量的情况下，基金的投资组合权重的条件概率。这种方法的独特之处在于：它能够直接从观测到的持有资产和市场数据的联合分布中学习，而不需要额外的奖励函数或专家目标。与基于强化学习或模仿学习的方法相比，这种方法更高效并且更能适应复杂的投资策略建模需求。此外，通过一系列测试，研究展示了基准专家标注的数据如何在线性可解释的方式包含于该模型的编码中。", "conclusion": "该框架提供了一种基于数据的方法来描绘投资策略，这种策略可以应用于市场模拟、策略归因和监管监督等多种应用场景中。通过对这些框架的应用，本研究不仅展示了如何更好地理解基金背后的复杂策略，而且还为未来投资决策提供了宝贵的洞察力。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26205", "html_url": "https://arxiv.org/abs/2510.26205", "title": "向全局检索增强生成迈进：一种面向语料库级别的推理基准", "title_en": "Towards Global Retrieval Augmented Generation: A Benchmark for Corpus-Level Reasoning", "authors": "Qi Luo,Xiaonan Li,Tingshuo Fan,Xinchi Chen,Xipeng Qiu", "background": "当前，检索增强生成（RAG）作为一种减少大型语言模型（LLMs）幻觉的领先方法正在兴起。现有的RAG评估基准主要关注所谓的局部RAG，即从一小部分文档中检索相关片段以回答仅需要特定文本片段内局部理解的查询。然而，许多实际应用场景需要不同类别的能力——全局RAG，需要处理整个文档集合的信息汇总和分析才能得出语料库级别的见解（例如，“2023年最受引用的前10篇论文是什么？”）。", "innovation": "本文引入了GlobalQA——首个专门设计用于评估全局RAG能力的基准，涵盖了四项核心任务类型：计数任务、极值查询、排序和服务于top-K提取。通过不同模型和基线的系统评估，我们发现现有RAG方法在全局任务上表现不佳，最强的基线方法得分仅为1.51 F1。为了解决这些挑战，我们提出了全局RAG，这是一种多工具协作框架，能够在片段级别检索时保持结构上的连贯性，集成LLM驱动智能过滤器去除噪声文档，并集成聚合模块进行精确的符号计算。在Qwen2.5-14B模型上，全局RAG的F1得分为6.63，相比之下，最强基线得分仅为1.51 F1，验证了本方法的有效性。", "conclusion": "通过全局RAG的有效性验证，本文验证了对于需要全局理解和分析的复杂查询，现有的RAG方法仍有显著提升空间。GlobalQA基准为未来RAG方法的研究提供了有价值的参考。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26219", "html_url": "https://arxiv.org/abs/2510.26219", "title": "在前逻辑空间基于采样最优控制的大型语言模型测试时对齐", "title_en": "Test-Time Alignment of LLMs via Sampling-Based Optimal Control in pre-logit space", "authors": "Sekitoshi Kanai,Tsukasa Yoshida,Hiroshi Takahashi,Haru Kuroki,Kazumune Hashimoto", "background": "测试时的大型语言模型对齐吸引了人们的注意，因为模型微调的计算成本非常高昂。因此，研究者们正在探索新的方法以减少这些高成本。这种方法的背景在于保持模型微调的效率和效果，而无需进行昂贵的完全微调过程。已有方法如最佳抽样在使用样本数量方面表现不佳，需要改进以提高效果和效率", "innovation": "本文提出了一种基于基于采样模型预测控制的新测试时对齐方法，称为前逻辑空间中的自适应重要性采样(AISP)。该方法通过对前逻辑输出应用高斯扰动，利用采样奖励进行重要性采样来最大化扰动均值的期望奖励。AISP 的创新之处在于其对已有方法的改进和优化，特别是在使用样本数量和所得结果的奖励方面表现更佳", "conclusion": "AISP 方法在测试时对齐模型方面取得了优于现有最佳抽样和其他基于奖励的测试时对齐方法的效果，显示了在保持模型性能的同时显著降低了计算成本的可能性"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26230", "html_url": "https://arxiv.org/abs/2510.26230", "title": "MPRU: 作为一种输出过滤器的模块化投影-重新分配未学习方法用于分类管道", "title_en": "MPRU: Modular Projection-Redistribution Unlearning as Output Filter for Classification Pipelines", "authors": "Minyi Peng,Darian Gunamardi,Ivan Tjuawinata,Kwok-Yan Lam", "background": "现有的机器未学习（MU）工作通常侧重于理论形式或优化目标以实现知识删除。然而，在现实世界的应用场景中，这些解决方案通常面临可扩展性问题，并且必须处理诸如对原始数据集和模型完全访问之类的实际需求。", "innovation": "本文将分类训练视为一个逐步过程，其中类逐渐被学习，将此称为归纳方法。未学习可以通过反转最后一个训练序列来实现。这种方法通过在模型末尾附加一个投影-重新分配层来实现。这种方法不需要对原始数据集和模型完全访问，解决了现有方法面临的挑战。这使得我们的解决方案可以在最小修改的情况下作为输出过滤器部署到现有分类管道中，实现了模块化和模型无关性。", "conclusion": "我们进行了多次实验，涵盖多个数据集（包括使用CNN模型的图像CIFAR-10/100数据集和使用树模型的表格Covertype数据集）。实验结果表明，与完全重新训练模型相比，具有很高的计算成本降低。这证明了我们解决方案的应用性、可扩展性和与系统的兼容性，在更具实践性的环境中保持了输出性能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26243", "html_url": "https://arxiv.org/abs/2510.26243", "title": "Angular Steering: 在激活空间旋转实现行为控制", "title_en": "Angular Steering: Behavior Control via Rotation in Activation Space", "authors": "Hieu M. Vu,Tan M. Nguyen", "background": "在部署安全可靠的AI时，控制大型语言模型的特定行为同时保持其通用性能是一个核心挑战。目前的控制方法，如向量加法和方向消减，局限于由激活和特征方向定义的二维子空间中，这种方法在参数选择上敏感，并且由于激活空间中的意外相互作用，可能导致无关特征受到影响。", "innovation": "我们提出了Angular Steering，一种新颖且灵活的行为调节方法，通过在固定二维子空间中旋转激活来工作。将控制行为定义为几何旋转向或远离目标行为方向，提供了连续的细粒度控制。我们提出了Adaptive Angular Steering，有选择地旋转与目标特征对齐的激活，增强了稳定性和连贯性。Angular Steering统一了现有的加法和正交化技术，简化了参数选择并保持了更广泛的调整下的模型稳定性。", "conclusion": "跨多个模型家族和大小的实验证明，Angular Steering实现了稳健的行为控制，同时保持了通用语言建模性能，突显了其灵活性、泛化能力和鲁棒性，优于以往的方法。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26217", "html_url": "https://arxiv.org/abs/2510.26217", "title": "混合LLM和高阶量子近似优化法在CSA抵押管理中的应用", "title_en": "Hybrid LLM and Higher-Order Quantum Approximate Optimization for CSA Collateral Management", "authors": "Tao Jin,Stuart Florescu,Heyu(Andrew)Jin", "background": "在ISDA信用支持附件(CSAs)环境下，整数批次、Schedule A折扣、RA/MTA限制条件以及发行人/货币/类别上限等复杂因素形成了复杂且受到法律约束的搜索空间。这给传统优化方法带来了挑战，特别是在处理多资产移位和RA引起的离散性问题上尤为困难。为了应对这些问题，本文研究小组提出了一种专门为这一领域设计的混合认证管道：包括基于证据的LLM抽取CSA条款至标准化JSON格式，量子启发式探索器结合微细阶次QAOA在绑定子QUBOs内部实现模拟退火，一个基于加权风险的优化目标以及CP-SAT作为最终仲裁者验证可行性和差距，包括上限U的先验检查。这些方法协同工作以提高抵押管理的效率和准确性，特别是在综合政府债券数据和多CSA输入方面表现显著。", "innovation": "本文的主要创新点在于提出了一种混合认证管道，该管道包括一个基于证据的LLM用于抽取CSA条款，量子启发式的探索器结合微细阶次QAOA针对绑定子QUBOs实现优化，一个基于加权风险的优化目标以及CP-SAT仲裁者确保优化结果的可行性和间隙验证。这种方法通过利用高阶QAOA，能够更好地应对复杂搜索空间中的局部交换限制，提高优化问题的解决方案质量，特别是在处理多资产移位和RA引起的离散性方面表现出色。", "conclusion": "通过在综合政府债券数据和多CSA输入上的实验，本文提出的混合管道算法比强大的传统基线模型分别提高了9.1%、9.6%和10.7%，在多个测试场景下展现出更好的成本-移动-尾部风险前沿。此外，研究还开放了治理级别的工具和文档，如引用范围、估值矩阵审计、权重来源和CP-SAT跟踪记录，以确保结果的可审计性和可重复性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26278", "html_url": "https://arxiv.org/abs/2510.26278", "title": "分布式的多目标黑盒优化在扩散模型推理时多目标生成", "title_en": "Distributional Multi-objective Black-box Optimization for Diffusion-model Inference-time Multi-Target Generation", "authors": "Kim Yong Tan,Yueming Lyu,Ivor Tsang,Yew-Soon Ong", "background": "扩散模型已成功学习复杂的概率分布，这一能力使其在高维多目标黑盒优化问题中得到应用。现有方法通常通过进化算法等外部优化循环与扩散模型结合使用，但这些方法将扩散模型视为黑盒精炼器，忽视了扩散生成过程中内部概率分布的变化，限制了其效率。", "innovation": "提出了一种名为Inference-time Multi-target Generation（IMG）的算法。该算法优化了扩散过程以在推理时生成同时满足多个目标的样本。具体而言，IMG在扩散生成过程中根据预计的综合多目标值进行加权抽样，确保自动生成的样本的分布符合我们期望的多目标玻尔兹曼分布。进一步推导出，多目标玻尔兹曼分布有趣地具有对数似然解释，即它是最优解的概率多目标优化问题。实验表明，IMG只需一次生成就能显著提高高效率，而基准优化算法可能需要数百次扩散生成。", "conclusion": "我们的算法可以被视为优化的扩散过程，并可以集成到现有方法中以进一步提高其性能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26298", "html_url": "https://arxiv.org/abs/2510.26298", "title": "ChatGPT Atlas能否攻克网页？探索ChatGPT Atlas代理在网页游戏中的前沿能力", "title_en": "Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games", "authors": "Jingran Zhang,Ning Li,Justin Cui", "background": "ChatGPT Atlas具有分析网页、处理用户意图并在浏览器中直接执行鼠标和键盘输入的新能力。尽管其在信息检索任务方面的能力已被展示，但在动态交互环境中的情况还缺乏探索。研究者使用基于浏览器的游戏作为测试场景，评估Atlas的网页交互能力。", "innovation": "本研究使用基于浏览器的游戏对Atlas的网页交互能力进行了初步评估，包括Google的T-Rex Runner、数独、Flappy Bird等。研究者使用游戏内表现分数作为定量指标，以评估不同任务类型的表现。结果显示，Atlas在逻辑推理任务（如数独）中表现出色，但在需要准确时间控制和运动控制的实时游戏中表现不佳。", "conclusion": "研究发现，尽管Atlas展示了强大的分析处理能力，但在需要实时交互的动态网页环境中仍有明显的限制。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26285", "html_url": "https://arxiv.org/abs/2510.26285", "title": "揭开语言模型处理数字机制的奥秘", "title_en": "Unravelling the Mechanisms of Manipulating Numbers in Language Models", "authors": "Michal Štefánik,Timothee Mickus,Marek Kadlčík,Bertram Højer,Michal Spiegel,Raúl Vázquez,Aman Sinha,Josef Kuchař,Philipp Mondorf", "background": "近期的研究表明，不同的大型语言模型（LLMs）对于数字的输入嵌入表示趋于一致且准确。然而，这与LLMs在处理数字信息时容易产生错误输出的已知倾向相矛盾。本文旨在解释这种矛盾，通过探索语言模型如何处理数字，来量化这些机制的准确性下限。研究表明，尽管存在表面错误，不同的语言模型仍然学习到相似的、系统性、高准确度且具有普遍性的数字表示，这不仅贯穿其隐藏状态，还覆盖不同类型输入情境。这使研究人员能够创建针对每个LLM的通用探针，并追踪信息——包括输出错误的原因——至特定层。", "innovation": "本研究发现了不同的语言模型在处理数字时，能够学习到一致且准确的表示方式，无论是在隐藏状态还是不同类型的输入上下文中。研究结果不仅为理解预训练LLMs如何处理数字提供了基础，还提出了更准确的探针技术在改进LLMs架构方面的潜力。研究还能够追踪到特定层的信息和输出错误的原因。", "conclusion": "本文的研究结果揭示了大型预训练语言模型在处理数字时的内部机制，为理解这些模型提供了基础性理解，并为未来更准确的模型探针技术的发展打开了可能的新方向。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26275", "html_url": "https://arxiv.org/abs/2510.26275", "title": "增补生成式人工智能增强软件工程过程和软件产品研究路线图", "title_en": "A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI", "authors": "Domenico Amalfitano,Andreas Metzger,Marco Autili,Tommaso Fulcini,Tobias Hey,Jan Keim,Patrizio Pelliccione,Vincenzo Scotti,Anne Koziolek,Raffaela Mirandola,Andreas Vogelsang", "background": "生成式人工智能（GenAI）正在迅速改变软件工程实践，影响软件工程过程的执行方式以及软件系统的开发、运营和演进。本文通过设计科学研究构建了一个GenAI增强软件工程的路线图。研究过程中涉及了FSE 2025“软件工程2030”研讨会的协作讨论、快速文献综述以及涉及同行的外部反馈会等多方面的证据，旨在系统地捕捉GenAI对软件工程过程和软件系统的影响，并构建了一个多轮次循环过程，综合多支独立作者团队和同行的意见，确保研究的透明性和可重复性，以此为基础来分析GenAI如何影响软件工程过程、方法和工具，并为这一快速发展的领域内未来的研究提供框架。", "innovation": "本文应用设计科学研究方法构建了GenAI增强软件工程的路线图，通过McLuhan的四象限分析法系统捕捉GenAI对软件工程和软件系统的影响，以及系统地识别和描述了四种GenAI增强软件工程的基本形式及其相关的研究挑战和机会，为未来研究提供了十个预测。这种方法论的创新之处在于其多轮次证据整合和系统性分析的方式，以及通过对研究结果的透明化和可重复性的审查，来确保研究的基础性质量。", "conclusion": "研究成果明确了GenAI增强软件工程的方向，提出了十个2030年的预测，并提供了一个透明和可重复的分析基础工具，对研究未来软件工程过程、方法和工具的演变具有重要的指导意义。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26302", "html_url": "https://arxiv.org/abs/2510.26302", "title": "从词元级因果视角理解视觉语言组成性的难度", "title_en": "Understanding Hardness of Vision-Language Compositionality from A Token-level Causal Lens", "authors": "Ziliang Chen,Tianang Xiao,Jusheng Zhang,Yongsen Zheng,Xipeng Chen", "background": "CLIP通过在共享嵌入空间中对齐图像和文本展示了强大的跨模态泛化能力，但在处理对象、属性和关系的组合推理方面表现不佳，常表现为词语堆砌匹配者。现有因果解释通常将文本视为单一向量，未能揭示词元级结构，使得关键现象如提示敏感性和难以解释的负样本表现无法得到解释。", "innovation": "建立了词元感知因果表示学习（CRL）框架，基于序列语言词元SCM。该理论将块可辨识性扩展到文本标记化文本，证明CLIP的对比性目标可以在串联和词元级SCM下恢复模态不变的潜变量。这项创新指出词元级别粒度提供了CLIP组合脆弱性的首个原理性解释：组合性不可辨识性。此外，研究展示了伪最优文本编码器存在的证据，这些编码器在模态不变对齐方面达到完美，但对SWAP、REPLACE和ADD操作对原子概念的操作证明是不敏感的，因此即使优化相同的训练目标也难以区分正确描述与困难负样本。", "conclusion": "该分析进一步通过模态差距将语言侧的不可辨识性与视觉侧的失败联系起来，并展示了迭代组合操作复合难度的方式，从而激励改进的负样本挖掘策略。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26303", "html_url": "https://arxiv.org/abs/2510.26303", "title": "Per-sample Adam on Separable Data: 独立样本Adam在可分数据上的隐式偏置：偏离全批量模式", "title_en": "Implicit Bias of Per-sample Adam on Separable Data: Departure from the Full-batch Regime", "authors": "Beomhan Baek,Minhak Song,Chulhee Yun", "background": "Adam 作为深度学习中的事实上的优化器，其理论理解仍然有限。先前的研究表明，Adam 倾向于 $\boldsymbol{\text{ℓ}_∞}$ 几何下的解，但这些结果仅限于全批量模式。本文研究了使用每步一个样本的增量 Adam 在线性可分数据下逻辑回归中的隐式偏置，并显示其偏置可以偏离全批量模式的偏置行为。通过构造一类结构化的数据集，证明增量 Adam 在这种设置下可以证明收敛到 $\boldsymbol{\text{ℓ}_2}$-最大间隔分类器，而全批量 Adam 倾向于 $\boldsymbol{\text{ℓ}_∞}$-最大间隔偏置。", "innovation": "研究展示了增量 Adam 在处理线性可分数据时的偏置可以偏离全批量 Adam 的偏置行为。开发了一个代理算法来捕捉增量 Adam 在 $\beta_2 \to 1$ 时的极限行为，并通过数据依赖的对偶不动点形式刻画其收敛方向。此外，证明了对于任何批量大小，Signum 都会收敛到 $\boldsymbol{\text{ℓ}_∞}$-最大间隔分类器，而 Adam 的收敛行为则依赖于 batching 方案和数据集特性", "conclusion": "我们的结果强调了 Adam 的隐式偏置不仅取决于 batching 策略，还取决于数据集，而 Signum 的收敛行为则在任何批量大小下保持不变。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26324", "html_url": "https://arxiv.org/abs/2510.26324", "title": "通过结合退火朗缪尔动力学和扩散模型实现后验采样", "title_en": "Posterior Sampling by Combining Diffusion Models with Annealed Langevin Dynamics", "authors": "Zhiyang Xun,Shivam Gupta,Eric Price", "background": "给定一个带噪的线性测量 $y = Ax + \\xi$ 和分布 $p(x)$ 的良好先验近似，我们何时可以从后验 $p(x \rand y)$ 中采样？精度和公平性的后验采样是图像修复、去模糊和MRI重建等任务的基础。尽管有一些启发式方法试图进行近似，但近似后验采样通常在计算上是不可行的。特别是当处理局部或全局的对数凸分布时，存在一种基于精确得分的朗缪尔动力学方法来实现采样，但在做分数估计时会受到脆弱性，需要满足次指数级的误差要求。与之对比，在无条件情况下，扩散模型仅需要得分误差的 $L^2$ 绑定就足够成功了。因此，本研究的重点是探讨如何结合扩散模型与朗缪尔动力学，在仅满足 $L^4$ 分数误差的情况下实现有指导采样。这一方法能够在多项式时间内实现条件采样，从而克服了先前方法在误差控制上的限制，但仍面临复杂度上的挑战。", "innovation": "研究提出的创新点在于通过结合退火朗缪尔动力学和扩散模型，在仅使用 $L^4$ 绑定的得分误差的条件下实现条件采样。这种方法有效地克服了传统方法在误差控制上的限制，并能够在多项式时间内实现有指导采样，从而解决了一直以来的计算不可行性难题。", "conclusion": "通过结合扩散模型与退火朗缪尔动力学，可以在多项式时间内使用 $L^4$ 绑定的得分误差条件实现采样。这意味着，即使在存在相对较高的得分估计误差的情况下，也能有效地进行后验采样，为图像修复、去模糊和MRI重建等任务提供了新的可能性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26342", "html_url": "https://arxiv.org/abs/2510.26342", "title": "线性因果发现与介入约束", "title_en": "Linear Causal Discovery with Interventional Constraints", "authors": "Zhigao Guo,Feng Dong", "background": "在因果发现中整合因果知识和机制对于细化因果模型并提高下游任务（例如设计新的治疗方法）至关重要。现有的因果发现方法虽然可以施加结构性约束（例如要求从PIP3到Akt的因果路径），但仍可能得出错误的因果结论，如认为“PIP3抑制Akt”。介入约束通过显式约束变量对之间的总因果效应，确保学习模型尊重已知的因果影响，弥补了这一不足", "innovation": "论文提出了一种新的因果发现概念——介入约束，它与介入数据不同，后者需要直接干预变量。介入约束以不等式约束的形式编码高层次的因果知识。为形式化介入约束，论文提议了一个量化线性因果模型中总因果效应的度量，并将问题表述为带约束的优化任务，采用两阶段的带约束的优化方法解决问题。实验表明，结合介入约束不仅提高了模型准确性，确保与已知发现的一致性，使模型更具解释性，还促进了新因果关系的发现，降低了其识别成本", "conclusion": "通过引入介入约束，提高了因果发现的准确性，确保发现的模型与现有研究一致，增强了模型的可解释性，同时促进了新因果关系的发现。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26345", "html_url": "https://arxiv.org/abs/2510.26345", "title": "MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data", "title_en": "MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data", "authors": "Mykhailo Poliakov,Nadiya Shvai", "background": "健康相关的错误信息非常普遍且可能有害。识别这些错误信息具有挑战性，尤其是在这些信息扭曲或曲解科学发现的情况下。我们使用MISSCI数据集和框架，研究合成数据生成和轻量级微调技术对大规模语言模型（LLMs）识别谬误能力的影响。", "innovation": "我们提出了MisSynth，一个将检索增强生成（RAG）应用于生成合成谬误样本的流水线。这些合成样本用于微调LLM模型。微调后的模型相对于基线模型显示出显著的准确率提升。引入合成谬误数据增强有限的标注资源，即使在计算资源有限的情况下，也能显著提高零_shot_ LLM分类性能，用于处理现实世界中的科学研究误导任务。", "conclusion": "微调后的模型在MISSCI测试分割上的F1分数绝对改进超过35%，证明了引入合成谬误数据可以显著增强零_shot_ LLM分类性能，即使在计算资源有限的情况下。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26336", "html_url": "https://arxiv.org/abs/2510.26336", "title": "从门外汉到大师：通过自动化课程学习向LLMs注入知识", "title_en": "From Amateur to Master: Infusing Knowledge into LLMs via Automated Curriculum Learning", "authors": "Nishit Neema,Srinjoy Mukherjee,Sapan Shah,Gokul Ramakrishnan,Ganesh Venkatesh", "background": "大型语言模型（LLMs）在通用任务上表现出色，但在经济学和心理学等需要深刻、原理性理解的专门领域中却表现不佳。为解决这一问题，本文介绍了一种名为ACER（Automated Curriculum-Enhanced Regimen）的新方法，可以将通用模型转换为领域专家，而不牺牲它们的广泛能力。ACER方法首先通过生成一个学科的大纲来合成全面、教科书风格的课程，然后根据布鲁姆分类法生成问题-回答对，以确保系统性的主题覆盖和逐步增加的难度。这个合成的语料库用于持续预训练，采用交错的课程计划，以便在内容和认知维度上保持学习的一致性。实验结果显示，使用Llama 3.2（1B和3B）进行的实验在专业化MMLU子集上取得了显著的进步。在经济学（尤其是微观经济学）等挑战性领域中，基线模型难以应对的问题，ACER可以提升5个百分点的准确性。在所有目标领域，我们观察到持续改善3个百分点的宏观平均值。值得注意的是，ACER不仅防止了灾难性遗忘，还促进了跨域知识的积极转移，提升了非目标领域的性能0.7个百分点。ACER在知识密集型基准测试（如ARC和GPQA）上的性能提升了2个绝对值以上，同时在通用推理任务上保持了稳定的性能。我们的结果表明，ACER提供了一种可扩展且有效的方案，以弥补LLMs中的关键领域差距。", "innovation": "ACER通过合成教科书风格的课程，并根据布鲁姆分类法生成问题-回答对，确保了系统的主题覆盖和逐步增加的难度。这种方法不仅能够改善专门领域的性能，还防止了灾难性遗忘，促进了跨域知识的有效转移，提升了非目标领域的表现。ACER还在知识密集型基准测试上的表现得到了显著提升。", "conclusion": "ACER提供了一种可扩展且有效的方案，以弥补LLMs中的关键领域差距，不仅增强了专门领域的性能，还防止了灾难性遗忘并促进了跨域知识的有效转移。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26352", "html_url": "https://arxiv.org/abs/2510.26352", "title": "对话的几何学：用图表示语言模型以揭示协同团队，促进多代理协作", "title_en": "The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic Teams for Multi-Agent Collaboration", "authors": "Kotaro Furuya,Yuichi Kitagawa", "background": "多代理系统基于大型语言模型（LLMs）的方法虽然有潜力超越单一模型的能力，但其成功关键在于队伍的协同性。然而，形成最优的队伍是一个挑战，因为大多数模型的内部特性不透明，阻碍了有效的团队合作。现有的方法通常需要对模型的内部架构、训练数据或任务表现有先验知识。本文提出了一种不依赖任何先验知识的自动团队构建框架。", "innovation": "提出了一种基于对话互动的自动团队构建框架，该框架通过构建‘语言模型图’，从对话的语义一致性中映射模型之间的关系，并应用社区检测识别出协同模型集群。这种方法无需任何关于模型的先验知识，并且能够在不同类型的LLMs中发现功能协调的团队，反映模型的潜在专业化。通过特定话题的初始化对话，能够找到比随机基准更优的协同团队，并达到与手动选择的团队相当的精度。", "conclusion": "本文的研究结果为自动化设计协作的多代理LLM团队提供了新的理论基础。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26347", "html_url": "https://arxiv.org/abs/2510.26347", "title": "在随机性、稀疏性和非稳态环境中利用自主水下车辆检测污染物的强化学习方法", "title_en": "Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle", "authors": "Sebastian Zieglmeier,Niklas Erdmann,Narada D. Warakagoda", "background": "强化学习（RL）算法旨在通过学习最大化奖励的动作来优化问题求解，但在随机性和非稳态环境中，这一任务变得特别具有挑战性。即使是最先进的RL算法，在这些条件下也常常受到限制，无法有效解决问题。例如，在利用自主水下车辆（AUV）进行水下污染检测的应用中，RL算法需要在奖励稀疏的环境中导航，频繁的动作会导致零奖励。因此，本文致力于解决这些挑战，通过重新审视并修改经典RL方法，使之能在稀疏、随机和非稳态环境中高效运行。研究包括层次算法变化、多目标学习，以及将位置记忆作为外部输出滤波器融入，以防止状态重访。研究表明，修改后的蒙特卡洛方法显著优于传统Q学习和两种详尽搜索模式，在复杂环境中表现出更好的适应性。", "innovation": "本文通过深入研究并修改优化了经典RL方法，特别是在稀疏、随机和非稳态环境下展示了其高效性。主要创新点在于采用层次算法变化、多目标学习和引入位置记忆作为外部输出滤波器，有效解决了AUV在水下污染检测中的挑战。", "conclusion": "研究结果表明，修改后的基于蒙特卡洛的强化学习方法显著优于传统Q学习和详尽搜索模式，在水下污染检测的复杂环境中表现出了显著的优势。这表明，强化学习方法能够有效地适应随机、非稳态和奖励稀疏的环境。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26390", "html_url": "https://arxiv.org/abs/2510.26390", "title": "SPG-CDENet：空间先验引导的交叉双编码器网络在多器官分割中的应用", "title_en": "SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation", "authors": "Xizhi Tian,Changjun Zhou,Yulin. Yang", "background": "多器官分割是计算机辅助诊断中的关键任务。尽管近年来深度学习方法在图像分割方面取得了显著的成效，但由于器官大小和形状的巨大差异，它们在多器官分割中的效果受到了挑战。", "innovation": "本文提出了一种名为SPG-CDENet的空间先验引导交叉双编码器网络，这是一种新型的两阶段分割范式，旨在提高多器官分割的准确性。SPG-CDENet包括一个先验网络和一个交叉双编码器网络。先验网络生成粗略的定位图，用于指导双编码器网络。交叉双编码器网络包括四个关键组件：全局编码器、局部编码器、对称交叉注意力模块和基于流动的解码器。此外，对称交叉注意力模块在所有编码器层中提出，用于融合和细化特征，以增强全局和局部编码器之间的交互。基于流动的解码器可以从最终编码器层直接向所有解码器层传播高层语义特征，最大限度地保留和利用特征。广泛的定量和定性实验表明，在两个公共数据集上，SPG-CDENet的性能优于现有分割方法。进一步的消融实验还验证了所提模块在提高分割准确性方面的有效性。", "conclusion": "实验结果表明，SPG-CDENet在多器官分割领域具有优越的性能，其空间先验引导和交叉双编码器结构显著提高了分割的准确性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26406", "html_url": "https://arxiv.org/abs/2510.26406", "title": "人类介入的在线拒绝采样及其在机器人操作中的应用", "title_en": "Human-in-the-loop Online Rejection Sampling for Robotic Manipulation", "authors": "Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang", "background": "强化学习（RL）已被广泛用于生成稳健的机器人操作策略，但通过RL微调视觉-语言-动作（VLA）模型可能会因为价值估计不准确和中间步骤的稀疏监督而变得不稳定。相比之下，模仿学习（IL）虽然容易训练但往往由于其离线性质而表现不佳。因此，本文通过开发一种名为Hi-ORS的后训练方法，结合了拒绝采样来实现训练稳定性和高鲁棒性，解决了上述问题。", "innovation": "Hi-ORS通过在线微调过程中过滤掉负面奖励样本来稳定价值估计，并采用基于奖励的监督训练目标来提供密集的中间步骤监督，从而同时提升训练稳定性和鲁棒性。此外，建立了一个异步推理训练框架，支持灵活的在线人工在环修正，作为学习错误恢复行为的明确指导。通过三个现实任务和两种物理载体，Hi-ORS在1.5小时的现实训练中微调了pibase策略，表现出更强的效率和效果，特别是在复杂错误恢复行为上的应用方面超越了RL和IL基线。", "conclusion": "Hi-ORS方法在现实世界任务中的微调成功展示了其强大的测试时间可扩展性，能够可靠地执行复杂的错误恢复行为以实现更好的表现，显著优于RL和IL基线。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26339", "html_url": "https://arxiv.org/abs/2510.26339", "title": "GLYPH-SR：通过VLM指导的潜在扩散模型能否同时实现高质量图像超分辨率和高保真文本恢复？", "title_en": "GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?", "authors": "Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang", "background": "图像超分辨率（SR）在许多视觉系统中非常重要，包括监控、自动驾驶、文档分析和零售分析，因为它能够恢复高频细节，特别是场景文本，这些对于下游感知是可靠的基础。场景文本，即嵌在自然图像中的文本，如交通标志、产品标签和门面描述，通常包含最重要的信息。当字符模糊或不存在时，光学字符识别（OCR）及其后续决策会失效，即使整体图像看起来清晰。然而，之前的SR研究往往针对失真（如PSNR/SSIM）或学习感知度量（如LIPIS、MANIQA、CLIP-IQA、MUSIQ），这些度量对字符级错误相对不敏感。另外，一些研究虽然关注于文本SR，但主要集中在简化的单一字符基准上，忽视了复杂自然场景中文本的挑战。因此，场景文本往往被当作普通纹理来处理。为了使SR在实际部署中有效，必须同时优化文本可读性和感知质量。本文探讨了如何实现这一目标，并提出了GLYPH-SR框架。", "innovation": "提出了GLYPH-SR，一种视图语言引导的扩散框架，旨在联合实现高可读性和高视觉现实性的目标。GLYPH-SR利用OCR数据引导的文字-SR融合控制网络（TS-ControlNet），以及交替提供文本和场景指导的乒乓调度器。通过在合成语料库上训练这些组件，同时冻结主要的SR分支，以实现特定于文本的恢复能力。GLYPH-SR在多种基准测试（SVT，SCUT-CTW1500，CUTE80）上，以x4和x8的放大倍数，对OCR F1分数的提高超过15.18个百分点，同时保持了与扩散/生成式对抗网络（GAN）基线（SVT x8，OpenOCR）竞争性的MANIQA、CLIP-IQA和MUSIQ得分。", "conclusion": "GLYPH-SR旨在同时满足高清晰度的超分辨率和高保真的文本恢复。通过视图语言模型（VLM）指导的潜扩散模型，实现了外观正确的超分辨率和读取正确的效果。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26420", "html_url": "https://arxiv.org/abs/2510.26420", "title": "SSCL-BW: 样本特定无标签后门水印方法用于数据集所有权验证", "title_en": "SSCL-BW: Sample-Specific Clean-Label Backdoor Watermarking for Dataset Ownership Verification", "authors": "Yingjia Wang,Ting Qiao,Xing Liu,Chongzuo Li,Sixing Wu,Jianbin Li", "background": "随着深度神经网络（DNNs）的快速发展，其很大程度上依赖于大量高质量的数据集。然而，未经授权的商业使用这些数据集严重违反了数据集所有者的知识产权。现有的基于后门的数据集所有权验证方法存在局限性：中毒标签水印由于标签不一致而容易被检测，而干净标签水印的技术复杂性高且在高分辨率图像上效果不佳。此外，这两种方法都使用静态水印模式，使其容易被检测和移除。", "innovation": "本研究提出了一种样本特定的无标签后门水印方法（即SSCL-BW），通过训练基于U-Net的水印样本生成器，为每个样本生成独特的水印，从根本上克服了静态水印模式的脆弱性。核心创新在于设计了一个由三种组件组成的复合损失函数：目标样本损失确保水印有效性，非目标样本损失保证触发可靠性，感知相似性损失保持视觉不可感知性。在所有权验证过程中，采用黑盒测试检查可疑模型是否表现出预定义的后门行为。", "conclusion": "在基准数据集上的大量实验表明，所提出的该方法有效且具有较好的抗潜在水印移除攻击的鲁棒性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26451", "html_url": "https://arxiv.org/abs/2510.26451", "title": "通过分类复杂性缓解实现鲁棒图凝缩", "title_en": "Robust Graph Condensation via Classification Complexity Mitigation", "authors": "Jiayi Luo,Qingyun Sun,Beining Yang,Haonan Yuan,Xingcheng Fu,Yanbiao Ma,Jianxin Li,Philip S. Yu", "background": "图凝缩（GC）由于能够合成更小但信息量丰富的图而引起了广泛关注。然而，现有的研究往往忽视了在原始图被破坏的情况下GC的鲁棒性。在这种情况下，观察到GC的性能显著下降，而现有的鲁棒图学习技术仅提供有限的效果。通过实证研究和理论分析，发现GC本质上是一种降低内在维度的过程，生成一个分类复杂度较低的凝缩图。尽管这一特性对于有效GC性能至关重要，但GC对对抗性扰动的鲁棒性仍然非常脆弱。", "innovation": "提出了一种新的名为MRGC的Manifold-constrained Robust Graph Condensation框架，该框架通过引入三种图数据流形学习模块来引导凝缩图落在一个光滑的、低维度的流形上，且具有最少的分类模糊性，从而保留了GC的分类复杂度降低能力，并在通用对抗攻击下实现鲁棒性能。", "conclusion": "广泛的实验表明，MRGC在多种攻击场景下具有鲁棒性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26412", "html_url": "https://arxiv.org/abs/2510.26412", "title": "LoCoT2V-Bench: 长视频生成的基准", "title_en": "LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video Generation", "authors": "Xiangqing Zheng,Chengyue Wu,Kehai Chen,Min Zhang", "background": "文本到视频生成近年来在生成短而高质量的片段方面取得了显著进展，但对于长格式输出的评估仍然是一个主要挑战，尤其是在处理复杂提示时。现有基准大多依赖于简化的提示，并主要关注低级指标，忽视了与提示的细粒度对齐和叙事连贯性、主题表达等抽象维度。为了填补这些空白，该论文提出了LoCoT2V-Bench，一个专门为复杂输入条件下长视频生成（LVG）设计的基准。", "innovation": "LoCoT2V-Bench 引入了一组真实且复杂的提示，包含场景过渡和事件动态等元素，并构建了一个多维度的评估框架，该框架包括作者提出的事件级别对齐、细粒度的时间一致性、内容清晰度以及聚焦于叙事流动、情感反应和角色发展等更抽象属性的人类期望实现度（HERD）等新的评估指标。基于此框架，论文对九个代表性长视频生成模型进行了全面评估，揭示了当前方法在事件间一致性、细粒度对齐和高层次主题一致性等方面的不足。", "conclusion": "总的来说，LoCoT2V-Bench 提供了一个全面的平台来评估复杂的文本到长视频生成，并指出了未来方法改进的关键方向。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26474", "html_url": "https://arxiv.org/abs/2510.26474", "title": "通过头部-尾部重新平衡反制LVLMs自我改进中的马太效应", "title_en": "Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing", "authors": "Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "自改进已成为提升大型视觉-语言模型（LVLMs）推理能力的主要 paradigm，模型通过迭代探索和学习成功历程。然而，在这一过程中，模型在处理简单查询（即头部数据）时表现出色，但在处理更复杂查询（即尾部数据）时则显得力有未逮，导致了优化的不平衡。这种不平衡使模型更倾向于学会简单的推理技能，而妨碍了其解决更复杂推理任务的能力。这种不平衡随着时间的推移逐渐加剧，即所谓的“马太效应”，最终阻碍了模型的进一步改进并导致性能瓶颈", "innovation": "为解决这一挑战，作者引入了四种有效的策略，从分布重塑和轨迹重新采样的两个角度出发，在探索与学习的自改进过程中实现头部-尾部再平衡。实验验证了这些方法在多种视觉推理任务上的一致改进效果，平均优于传统的自改进方式3.86分点", "conclusion": "本研究通过引入两种视角下的四种策略实现了LVLMs在自改进过程中头部-尾部的再平衡，提高了模型的视觉推理能力，解决了优化不平衡的问题，推动了LVLMs的进一步改进"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26457", "html_url": "https://arxiv.org/abs/2510.26457", "title": "SecureReviewer：通过安全感知微调增强大型语言模型的代码审查安全性", "title_en": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "authors": "Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang", "background": "在软件开发的早期阶段识别和解决安全问题对于减少长期负面影响至关重要。代码审查是一种有效的实践，通过在代码集成到代码库之前检查队友的代码来发挥作用。尽管已经提出了许多自动化代码审查方法，尤其是在利用LLM的方法方面取得了显著进展，但现有模型主要集中在通用代码审查上，其在识别和解决安全问题方面的效果仍然没有得到充分探索。此外，将现有代码审查方法调整以专门针对安全问题面临着数据稀缺和不充分的评估指标等显著挑战。", "innovation": "为了应对这些局限性，本文提出了SecureReviewer，一种专门设计用于增强LLMs在代码审查中识别和解决安全问题能力的新方法。具体来说，我们首先构建了一个专门用于训练和评估安全代码审查能力的数据集。利用该数据集，我们通过我们提出的安全感知微调策略对LLMs进行微调，以生成能够有效识别安全问题并提供修复建议的审查注释。此外，为了减轻LLMs的幻觉并增强其输出的可靠性，我们引入了RAG技术，并提出了一个新的评估指标SecureBLEU，用于评估审查注释在解决安全问题方面的有效性。", "conclusion": "实验结果表明，SecureReviewer在安全问题检测精度和生成的审查注释的整体质量和实际实用性方面，都优于现有的最先进的基线。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26484", "html_url": "https://arxiv.org/abs/2510.26484", "title": "大规模语言模型的贝叶斯网络融合在情感分析中的应用", "title_en": "Bayesian Network Fusion of Large Language Models for Sentiment Analysis", "authors": "Rasoul Amirzadeh,Dhananjay Thiruvady,Fatemeh Shiri", "background": "大型语言模型（LLMs）不断进步，出现越来越多的针对特定任务的专业化变种。然而，这些模型往往缺乏透明度和解释性，需要精细调整成本较高，需要大量的提示工程，结果在不同领域之间不够一致，并由于其高计算需求对环境造成重大负面影响。为了应对这些挑战，我们提出了贝叶斯网络LLM融合（BNLF）框架，该框架通过概率机制在贝叶斯网络框架内对三种LLM（FinBERT、RoBERTa和BERTweet）的概率进行融合，用于情感分析。", "innovation": "BNLF框架通过将来自三款LLM的情感预测作为贝叶斯网络中的概率节点进行建模，实现了晚期融合，展现出一致的准确率增益，改进了基线LLMs的准确率约6%，这一方法突显了概率融合在可解释情感分类中的有效性。", "conclusion": "BNLF框架在三个不同语言和上下文的人工注释金融语料库上进行了评估，结果表明，BNLF能够一致地提高情感分析的准确性，突显了其对数据集变异性具有鲁棒性，并展示了概率融合在情感分类中的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26551", "html_url": "https://arxiv.org/abs/2510.26551", "title": "机器人中适应性反向动力学框架的学习变长工具操作", "title_en": "Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics", "authors": "Prathamesh Kothavale,Sravani Boddepalli", "background": "传统的机器人对自身动态的理解有限，只能执行预编程的任务，限制了它们高效利用工具的能力。因此，机器人在任务执行过程中会出现诸多局限性。", "innovation": "该研究提出了一个创新的框架，扩大了机器人反向动力学求解器的能力，使机器人能够使用不同长度的工具完成一系列动作。通过将仿真学习的动作轨迹与工具结合，展示了从仿真到实际任务的技能迁移的有效性，并显著降低了执行误差，特别是在不同长度的工具操作上表现出一致的性能。", "conclusion": "该研究提供了一种潜在的方法，通过该方法机器人可以更好地掌握使用工具的各项技能，从而在各种任务中完成精确的操作。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26512", "html_url": "https://arxiv.org/abs/2510.26512", "title": "CORE-KG内部机制评估：结构化提示与消解共指对知识图谱的影响", "title_en": "Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs", "authors": "Dipak Meher,Carlotta Domeniconi", "background": "人类走私网络日益具有适应性和难以分析的特点。法律案例文档提供了关键的洞察，但由于其非结构化、词汇密集且充满模糊或动态参考，这对自动知识图谱(KG)构建构成了重大挑战。尽管最近基于大语言模型(LLM)的方法在使用静态模板方面有所改进，但它们仍然生成嘈杂、碎片化的图形，并且由于缺乏指导提取和共指消解而导致节点重复。近年来提出的CORE-KG框架通过结合类型意识的共指模块和领域引导的结构化提示显著减少了节点重复和法律噪声。", "innovation": "论文通过系统地消融研究CORE-KG来量化其两个关键组件的独立贡献。结果表明，在去除共指解析后，节点重复增加了28.32%，噪声节点增加了4.32%；而移除结构化提示后，节点重复增加了4.34%，噪声节点增加了73.33%。这些发现为设计用于从复杂法律文本中提取结构化表示的强大的LLM管道提供了实证见解。", "conclusion": "这些结果提供了有关设计用于从复杂法律文本中提取结构化表示的LLM管道的实证见解，强调了类型意识的共指模块和领域引导的结构化提示的重要性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26494", "html_url": "https://arxiv.org/abs/2510.26494", "title": "使用LLM代理模拟和实验社交媒体动员", "title_en": "Simulating and Experimenting with Social Media Mobilization Using LLM Agents", "authors": "Sadegh Shirani,Mohsen Bayati", "background": "在线社交网络改变了政治动员信息的传播方式，引发了对大规模背景下同伴影响如何运作的新问题。本研究基于Facebook大规模实验，开发了一种基于代理的模拟框架，结合真实的美国人口普查人口统计分布、真实的Twitter网络结构以及异质的大规模语言模型（LLM）代理，以研究动员信息对投票率的影响。研究通过模拟人口统计属性、个人政治立场以及不同政治复杂度的LLM代理（GPT-4.1、GPT-4.1-Mini或GPT-4.1-Nano），在现实社交网络结构中进行交互，生成个性化 feeds，并动态更新参与行为和投票意向。实验条件模拟了Facebook原始研究的信息动员和社会动员处理。该模拟器在不同情景中重现了实地实验中的定性模式，包括社会信息处理下的更强动员效果和可量化的同伴溢出效应。", "innovation": "本研究的创新在于开发了一个基于代理的模拟框架，结合了真实的美国人口普查数据和真实的Twitter网络结构，以及由不同类型的大规模语言模型代理组成的现实社交网络，重新审视了动员信息对投票率的影响。这种模拟框架提供了一个可控的、可重复的环境，用于政治动员研究中的假设设计测试和敏感性分析，介乎于高效度实地实验和灵活计算模型之间。", "conclusion": "本研究利用大规模语言模型代理进行模拟和实验，成功重现了现实生活中的实验结果。通过这种框架，研究者可以在关注高效度实地实验的同时，利用高度灵活的计算模型进行假设设计和敏感性分析，为政治动员研究提供了一个有力工具。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26575", "html_url": "https://arxiv.org/abs/2510.26575", "title": "InfoFlow：通过奖励密度优化强化搜索代理", "title_en": "InfoFlow: Reinforcing Search Agent Via Reward Density Optimization", "authors": "Kun Luo,Hongjin Qian,Zheng Liu,Ziyi Xia,Shitao Xiao,Siqi Bao,Jun Zhao,Kang Liu", "background": "自适应深度搜索中的增强学习（RL）存在低奖励密度的问题，导致代理在搜索过程中需要大量探索成本以获得偶尔出现的奖励。Reinforcement Learning with Verifiable Rewards（RLVR）是一个有前景的方法，但它的应用受到了低奖励密度的阻碍。", "innovation": "InfoFlow 提出了一种系统框架，通过三个方面解决问题：1) 子问题分解：将长范围任务分解，提供密集的学习信号；2) 失败导向的提示：向停滞的轨迹注入纠正指导，增加成功结果的概率；3) 双代理精炼：使用双代理架构减轻深度探索的精力负担，一个精炼代理综合搜索历史并有效压缩搜索轨迹，从而降低探索成本并提高整体奖励密度。", "conclusion": "InfoFlow 在多个自适应搜索基准测试中表现出色，优于强大的基线，使得轻量级语言模型能够达到接近先进私有语言模型的性能水平。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26543", "html_url": "https://arxiv.org/abs/2510.26543", "title": "大型语言模型中关系解码线性算子的结构", "title_en": "The Structure of Relation Decoding Linear Operators in Large Language Models", "authors": "Miranda Anna Christ,Adrián Csiszárik,Gergely Becsó,Dániel Varga", "background": "本文研究了Hernandez等人在2023年引入的线性算子结构，这些算子能够解码变压器语言模型中的特定关系事实。研究基于之前的研究成果，探讨了单关系分解结果，并对其进行扩充，以处理多个关系的系统性组织问题。研究发现，这些关系解码器集合可以通过简单的三阶张量网络高度压缩，不显著影响解码准确性。作者通过开发一种交叉评估协议来解释这种出乎意料的冗余，该协议涉及将每个线性解码算子应用于其他关系的主语。研究结果揭示，这些线性映射并不单独编码关系，而是提取了反复出现的、粗粒度的语义特征（如首都所在国家和食物所在国家都属于X的国家属性）。由此揭示了算子的压缩性和它们为什么主要用于与新关系具有语义临近性的关系的泛化特性。", "innovation": "本文扩展了单关系的研究，提出了一种基于三阶张量网络的压缩方法，并通过开发交叉评估协议解释了线性关系解码器中表面上的冗余现象，揭示了线性算子的压缩性和解码准确性之间的关系。此外，研究展示了这些线性算子的结构可以看作是以属性为中心而不是特定于关系，这为理解变压器语言模型中的线性关系解码提供了新的视角。", "conclusion": "线性关系解码器在变压器语言模型中的主要作用是提取语义属性而非特定关系，这种基于属性的结构诠释了算子的压缩性和泛化能力。该研究解释了变压器语言模型中线性关系解码器的结构，并提供了一种新的方法来处理多个关系的分解问题。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26566", "html_url": "https://arxiv.org/abs/2510.26566", "title": "使用Jensen-Shannon距离的多类局部校准", "title_en": "Multiclass Local Calibration With the Jensen-Shannon Distance", "authors": "Cesare Barbera,Lorenzo Perini,Giovanni De Toni,Andrea Passerini,Andrea Pugnana", "background": "开发值得信赖的机器学习模型需要其预测概率与真实类频率一致。现有的多类校准方法缺乏输入间的距离概念，这使得它们容易受到邻近偏差的影响：在特征空间稀疏区域的预测会系统性地被误校准。这种情况在医疗保健等高风险领域尤为重要，因为稀疏实例正是最容易受到偏差治疗影响的实例。因此，本研究旨在通过引入局部视角解决多类校准的主要缺陷，从而解决上述问题。", "innovation": "文章首次正式定义了多类局部校准，并建立了它与强校准之间的关系；分析了现有评价指标应用于多类局部校准时的缺陷；提出了一种利用Jensen-Shannon距离增强神经网络中局部校准的有效方法，确保预测概率与局部类频率估计之间的一致性；并通过实验证明了该方法的有效性，对比了其与现有多类校准技术。", "conclusion": "通过引入多类局部校准及其相关方法，本文提高了高风险领域如医疗保健等场景下多类预测的准确性，解决了现有方法的邻近偏差问题，提供了有效的方法来改善神经网络中预测概率与实际频率的一致性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26646", "html_url": "https://arxiv.org/abs/2510.26646", "title": "混合DQN-TD3强化学习在动态环境中的自主导航", "title_en": "Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments", "authors": "Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai", "background": "本文介绍了一种结合高阶梯度Q网络（DQN）和低层延迟双确定性策略梯度控制器（TD3）的层次路径规划和控制框架。该框架在动态和部分可观测环境中运行，旨在解决自主导航问题。", "innovation": "创新之处在于将高阶梯度Q网络用于离散子目标的选择，以及低层延迟双确定性策略梯度控制器用于连续执行。还提出了一种实用的奖励塑造方案，并且通过基于LiDAR的安全门防止不安全运动。该系统在ROS+Gazebo平台（使用TurtleBot3）上实现，并通过PathBench度量标准进行评估，显示了在未见过的障碍配置中具有更好的泛化能力和更少的突然控制变化。", "conclusion": "实验结果显示，该系统在成功率、样本效率上优于单一算法基线（仅DQN或TD3）和基于规则的规划器。系统在动态和部分可观测环境中表现出良好的导航性能，并且控制更加平滑。代码和评估脚本已在项目仓库中提供。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26585", "html_url": "https://arxiv.org/abs/2510.26585", "title": "优化令牌消耗：迈向高效的多智能体系统运行时", "title_en": "Stop Wasting Your Tokens: Towards Efficient Runtime Multi-Agent Systems", "authors": "Fulin Lin,Shaowen Chen,Ruishan Fang,Hongwei Wang,Tao Lin", "background": "多智能体系统（MAS）在复杂任务中表现出色，但随着其自主性和操作复杂性的增加，往往会出现关键的低效率问题，如令牌消耗过多和因误信息而导致的故障。现有方法主要集中在事后故障归因，缺乏能够提供主动、实时干预的机制以提高系统的鲁棒性和效率。目前的解决方案并不能在不改变基础智能体架构的情况下进行有效的监督。因此，现有方法在面对复杂的任务和高操作复杂性时存在局限性，需要创新的方法来解决这些问题。", "innovation": "本文提出了一个名为SupervisorAgent的轻量级且模块化框架，用于实时、自适应的监督，它可以不改动基础智能体架构即可发挥作用。SupervisorAgent通过一个无大语言模型（LLM-free）的自适应过滤器，在关键时刻干预以主动纠正错误、引导无效行为并净化观察结果。这种新方法在挑战性的GAIA基准测试中，使Smolagent框架的令牌消耗减少了平均29.45%，而成功率保持不变。此外，该方法在五个附加基准测试（数学推理、代码生成和问答）及多个最先进的基础模型中的广泛实验也证明了其广泛应用性和鲁棒性。", "conclusion": "本文通过引入SupervisorAgent，提供了一种在运行时提升多智能体系统效率和鲁棒性的创新方法。该方法可以在不改变基础智能体架构的情况下，通过实时、自适应的监督减少令牌消耗并在多个不同基准测试中证明了其有效性和广泛适用性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26616", "html_url": "https://arxiv.org/abs/2510.26616", "title": "Aeolus: 多结构航班延误数据集", "title_en": "Aeolus: A Multi-structural Flight Delay Dataset", "authors": "Lin Xu,Xinyun Yuan,Yuxuan Liang,Suwan Yin,Yuankai Wu", "background": "现有的航班延误数据集通常仅限于平坦的表结构，无法捕捉航班延误传播的时空动态。这些数据集对于研究航班延误预测和促进面向表结构数据的基础模型发展存在局限性。", "innovation": "Aeolus通过提供三个对齐的模态解决了这个问题：(i) 一个包含丰富操作、气象和机场级特征的表数据集，涵盖了超过5000万个航班；(ii) 一个航班链模块，用于建模航班段上的延误传播，捕捉上下航班之间的依赖关系；(iii) 一个航班网络图，编码共享飞机、机组和机场资源的连接，支持跨航班的关系推理。此外，该数据集通过时间划分、全面的特征和严格的泄露预防，支持现实的和可重复的机器学习评估。", "conclusion": "Aeolus支持广泛的任务，包括回归、分类、时间结构建模和图学习，作为一个统一的基准跨越表、序列和图模态。我们发布了基线实验和预处理工具以促进其采用。Aeolus填补了领域特定建模和通用结构数据的关键空白。相关代码和数据可以从这些链接访问：this http URL"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26601", "html_url": "https://arxiv.org/abs/2510.26601", "title": "ResMatching: 使用引导条件流匹配实现鲁棒计算超分辨率", "title_en": "ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching", "authors": "Anirban Ray,Vera Galinova,Florian Jug", "background": "计算超分辨率（Computational Super-Resolution, CSR）在荧光显微镜中尽管是一个病态问题，但历史悠久。核心在于找到一种先验知识，以利用低分辨率图像中的频率信息进行高频信息的补全。随着数据驱动的机器学习技术的提升，可以学习到更强大的先验知识，从而提高超分辨率的结果。本研究背景即在此基础上展开，利用更好的先验知识来提升图像的超分辨率效果。", "innovation": "提出了ResMatching，这是一种使用引导条件流匹配的新颖计算超分辨率方法。ResMatching通过这种方式学习改进的数据先验，从而在数据保真度和感知真实度之间取得最佳平衡。特别地，在低分辨率图像包含大量噪声等难以学习强先验的情况中，ResMatching的效果尤其显著。此外，ResMatching还可以用于从隐式学习的后验分布中采样，提供像素级的数据不确定性，以指导未来的用户丢弃不确定的预测。", "conclusion": "通过在BioSR数据集上的4种不同生物结构上进行评估及7个基线方法的对比分析，ResMatching展示了其最佳的数据保真度和感知真实度之间的权衡。特别地，在缺乏强先验信息的情况下，ResMatching显示出特别的优越性。该方法为用户提供了一个像素级别的数据不确定性，这可以进一步改善图像重建的效果，使得用户能够更自信地做出判断。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26684", "html_url": "https://arxiv.org/abs/2510.26684", "title": "钢轧生产线集成计算机视觉以实现实时故障预测", "title_en": "Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill", "authors": "Vaibhav Kurrey,Sivakalyan Pujari,Gagan Raj Gupta", "background": "本文介绍了在钢轧生产线中基于机器视觉的异常检测系统的长期部署研究。该系统利用工业摄像头实时监控设备运行、对中和热轧条的运动情况，通过中央视频服务器使用深度学习模型对实时视频流进行处理，实现设备故障的早期预测和过程中断的提前预警，降低非计划停机成本。", "innovation": "该系统通过结合数据分析系统和视觉输入的数据进行联合分析，识别故障的位置及可能的原因，提供预防性维护的行动指南。服务器端推断减少了工业过程控制系统（PLCs）的计算负担，支持生产线上大规模部署，且所需额外资源最少。", "conclusion": "这种集成方法在工业制造环境中增强了操作可靠性、生产效率和盈利能力，通过实时故障预测系统优化维护策略，提升生产线的整体性能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26683", "html_url": "https://arxiv.org/abs/2510.26683", "title": "Evontree：受本体规则引导的大语言模型自我进化", "title_en": "Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models", "authors": "Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang", "background": "大规模语言模型（LLMs）通过大规模预训练和精心制作的微调数据在多个领域展示了出色的能力，但在敏感性数据领域（如医疗保健）中，由于缺乏高质量和领域特定的训练语料，LLMs难以适应专门的应用需求。与此同时，领域专家将专业知识提炼为本体规则，这些规则以形式化的方式定义概念之间的关系，并确保知识管理库的完整性。将LLMs视为人类知识的隐式库，本文提出了Evontree，一种利用少量高质量本体规则系统提取、验证和增强LLMs内领域知识的新框架，而不需大量外部数据集。", "innovation": "Evontree框架利用少量高质量本体规则从原始模型中提取领域本体，通过两种核心本体规则检测不一致性，并通过自我精炼微调增强精炼知识。在医疗QA基准测试中的实验表明，相比于未经修改的模型和领先的监督方法，该方法在准确性上提升了多达3.7%，证实了该方法在LLMs低资源领域适应中的有效性和稳健性。", "conclusion": "Evontree框架通过利用少量高质量本体规则帮助大规模语言模型在低资源领域中实现有效的自我进化，并在医疗领域QA基准测试中取得了显著的准确性提升，证明了该方法的有效性、高效性和稳健性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26714", "html_url": "https://arxiv.org/abs/2510.26714", "title": "仅使用单一训练种子评估机器去学习的局限性", "title_en": "On the limitation of evaluating machine unlearning using only a single training seed", "authors": "Jamie Lanyon,Axel Finke,Petros Andreou,Georgina Cosma", "background": "机器去学习（MU）旨在从已训练的模型中移除某些数据点的影响，而无需昂贵的重新训练。大多数实际的MU算法只是近似算法，无法通过理论手段评估其性能，只能通过实验手段来评估。因此，在进行实验比较时应尽可能使其具有代表性。通常的做法是多次独立运行MU算法，从相同训练好的模型开始。然而，这项研究显示，即使对于相同的网络架构和相同的数据集，某些MU方法可能会对用于模型训练时选择的随机数种子非常敏感。因此，实验比较MU算法时应考虑到不同模型训练种子带来的差异性。", "innovation": "这项研究揭示了使用单一训练种子评估MU算法的局限性，特别是在不同模型训练种子对MU方法性能有显著影响的情况下。提出的创新建议是在实验比较MU算法时，也要反映不同模型训练种子之间的变异情况，即确保实验结果具有代表性。", "conclusion": "研究建议，在实验评估MU算法性能时，不应只依赖单一的训练种子，而应考虑到不同模型训练种子带来的影响，确保实验结果更具有代表性和可靠性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26697", "html_url": "https://arxiv.org/abs/2510.26697", "title": "从手动解码到真正的端到端语言模型", "title_en": "The End of Manual Decoding: Towards Truly End-to-End Language Models", "authors": "Zhichao Wang,Dongyang Ma,Xinting Huang,Deng Cai,Tian Lan,Jiahao Xu,Haitao Mi,Xiaoying Tang,Yan Wang", "background": "现有的大规模语言模型（LLMs）通常被认为可以实现端到端的生成过程，但实际上，它们依赖于非可微分的解码过程，这需要人工调整高温和top-p等超参数。这表明当前的解决方案并非真正实现端到端的操作，因为其中包含人工干预的成分。", "innovation": "该论文提出了一个新的架构——AutoDeco，它在标准Transformer的基础上添加了轻量级的头部模块，这些模块可以在每一步动态预测上下文特定的温度和top-p值，从而实现自我调节采样策略。这种创新方法将解码过程转变为参数化、以token为单位的过程，使得模型在单次前向传递中就能够自我管理其采样策略。通过在八个基准上的实验证明，AutoDeco不仅显著优于默认的解码策略，其性能甚至与通过破解测试集得到的Oracle调优基线相当，这是一个任何静态方法的实用性上限。此外，AutoDeco还展示出一种基于指令的解码控制能力，能够理解自然语言指令并逐token进行温度和top-p调整，为可调节和互动的LLM解码开辟了新的范式。", "conclusion": "AutoDeco通过学习自己的解码策略显著改进了大规模语言模型的生成能力，这一成果不仅证明了其作为真正的端到端语言模型的潜力，还提出了一个新的解码控制机制，为未来的研究提供了新的可能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26730", "html_url": "https://arxiv.org/abs/2510.26730", "title": "ExpertFlow：适应性专家调度与内存协调以实现高效MoE推理", "title_en": "ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference", "authors": "Zixu Shen,Kexin Chu,Yifan Zhang,Dawei Xiang,Runxin Wu,Wei Zhang", "background": "大型语言模型的扩展越来越多地受限于现代GPU的内存容量限制。传统的混合专家（MoE）架构在推理过程中依赖于独立地在每一层选择活跃专家，这会引起大量的参数在主机内存和GPU内存之间的频繁传输，导致显著的延迟。当前的跨层预测策略通常基于固定步长，缺乏不同硬件平台和工作负载的适应性，降低了其稳定性和有效性。", "innovation": "专家流（ExpertFlow），一种结合自适应专家预取和内存感知路由的运行时系统。ExpertFlow通过利用运行时统计信息，如传输带宽、参数维度和模型反馈信号，动态调整其专家激活的预测窗口。此外，它还包含一个混合跨层预测方案，将预门控信息与中间计算状态相结合，以预见未来的专家需求。通过适应性地优化预取决策并使其与实际使用行为相匹配，ExpertFlow有效减少了缓存缺失并消除了由于专家切换引起的延迟。", "conclusion": "评估结果表明，与基线相比，ExpertFlow将模型停滞时间减少到不到0.1%，证明了其在严格内存约束下优化MoE推理的能力。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26722", "html_url": "https://arxiv.org/abs/2510.26722", "title": "非凸的无线异构联邦学习：偏差-方差权衡", "title_en": "Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off", "authors": "Muhammad Faraz Ul Abrar,Nicolò Michelusi", "background": "OTA-FL通过无线多址信道的波形叠加来在单次使用中聚合模型更新，已被广泛认可为一种可扩展的范式。现有设计主要通过假设一致的无线条件（相同的路径损耗）或强制零偏差更新来确保收敛性，这对于异构无线场景是受限的，并导致了次优设备的性能限制，从而增加了更新的方差。此外，先前对带有偏差的OTA-FL的研究主要针对凸目标函数，而大多数现代AI模型是高度非凸的。", "innovation": "本文研究了在无线异构条件下使用随机梯度下降（SGD）的非凸OTA-FL更新，提出了允许结构化、时间不变模型偏差的同时减少更新方差的新颖OTA-FL SGD更新。推导出有限时域站稳性界（期望的时间平均梯度平方范数），明确揭示了偏差-方差权衡。提出了非凸联合OTA权力控制设计，并开发了一种仅需基站统计CSI的有效的连续凸近似（SCA）算法。实验验证非凸图像分类任务中基于SCA的设计通过优化偏差加速了收敛，并提高了泛化能力。", "conclusion": "基于SCA的设计不仅加速了任意偏差下的收敛，还在非凸OTA-FL基线对比中改善了泛化性能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26768", "html_url": "https://arxiv.org/abs/2510.26768", "title": "AMO-Bench: 大型语言模型在高中数学竞赛中仍面临挑战", "title_en": "AMO-Bench: Large Language Models Still Struggle in High School Math Competitions", "authors": "Shengnan An,Xunliang Cai,Xuezhi Cao,Xiaoyu Li,Yehao Lin,Junlin Liu,Xinxuan Lv,Dan Ma,Xuanlin Wang,Ziwen Wang,Shuang Zhou(Alphabetical order by last name)", "background": "现有的基准测试大多依赖于高中数学竞赛来评估大型语言模型（LLMs）的数学推理能力。然而，许多现有的数学竞赛由于性能饱和（如AIME24/25），越来越难以评估顶级LLMs的性能。为了应对这一问题，AMO-Bench引入了更为严格的挑战，确保所有50个问题都至少符合国际数学奥林匹克(IMO)的难度标准，并且完全原创，以防止数据记忆导致的性能泄漏。每道题目只需提供最终答案，以便自动和稳健地评分。", "innovation": "AMO-Bench 是一个高级数学推理基准，包含50个由专家验证且达到IMO难度标准的人工设计问题，保证了原创性，且每个问题只需提供最终答案，适合自动评分。该基准显示即使是表现最好的模型在AMO-Bench上也只能达到52.4%的准确率，大多数LLMs得分低于40%。此外，进一步分析表明，随着测试时间计算量的增加，AMO-Bench上的性能呈现出良好的扩展趋势，这突显了当前LLMs在数学推理方面改进的巨大空间。", "conclusion": "实验结果表明当前LLMs在数学推理方面存在显著提升空间，AMO-Bench为这一领域的进一步研究提供了支持。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26745", "html_url": "https://arxiv.org/abs/2510.26745", "title": "深度序列模型倾向于记忆几何结构；不清楚为什么", "title_en": "Deep sequence models tend to memorize geometrically; it is unclear why", "authors": "Shahriar Noroozizadeh,Vaishnavh Nagarajan,Elan Rosenfeld,Sanjiv Kumar", "background": "在序列建模中，原子事实的参数记忆通常被抽象为实体之间共现的一次性查找。本文通过对比关联视角与几何视角，探讨记忆在存储方式上的一种新思路。作者通过分析一个不兼容传统存储方式的Transformer推理实例，揭示了其中内在的几何结构，并提出这种结构难以通过局部关联优化直接解释。进一步通过Node2Vec的分析，表明这种几何结构源于光谱偏差，并在缺乏多种压力的情况下自然产生。这一分析为从业者指明了如何使Transformer记忆更加几何化的方向。", "innovation": "本文创新地将序列模型的记忆方式从传统的关联视角转向几何视角。通过分析，揭示了即使在没有优化局部关联的情况下，模型能学习到一种复杂的几何结构，使推理任务简化为一步学习的几何任务。此外，作者通过Node2Vec分析，表明这种几何结构源于光谱偏差，解释了传统理论无法解释的现象。", "conclusion": "本文提出了序列模型记忆几何结构这一现象，并指出这种几何结构无法通过简单的优化策略直接获得，还表明了这一结构与光谱偏差相关。最后，作者建议从业务中直观找到改进Transformer记忆，使其更具几何性的途径。这一概念鼓励重新审视知识获取、容量、发现和遗忘等方面的默认直觉。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26771", "html_url": "https://arxiv.org/abs/2510.26771", "title": "STaMP: 序列变换和混合精度量化在低精度激活量化中的应用", "title_en": "STaMP: Sequence Transformation and Mixed Precision for Low-Precision Activation Quantization", "authors": "Marco Federici,Riccardo Del Chiaro,Boris van Breugel,Paul Whatmough,Markus Nagel", "background": "量化是减少生成AI模型推理延迟、功率和内存足迹的关键方法。然而，当 activations 低于八位时，准确率往往会急剧下降。现有研究表明，可逆线性变换（例如旋转）可以通过重新参数化特征通道和权重来帮助量化。因此，本文提出了新的策略：序列变换和混合精度（STaMP）量化，利用文本和视觉数据中的强局部相关性，通过在每次中间激活保持少量高精度令牌，在较低的平均激活位宽下保持模型的准确性。", "innovation": "本文提出了一种新颖的方法——STaMP（序列变换和混合精度）量化。该方法沿着序列维度应用线性变换，通过保持每次中间激活中少量高精度的令牌，在较低的平均激活位宽下保持模型的准确性，从而在低精度激活量化中显著改善准确度，并补充已有的激活和权重量化方法，包括最近的特征变换方法。", "conclusion": "STaMP量化策略在最近的语言视觉模型（LVM）和语言语言模型（LLM）架构上得到了评估，证明了这种方法能够显著提高低位宽激活量化效果，同时增强了现有激活和权重量化方法的效果。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26776", "html_url": "https://arxiv.org/abs/2510.26776", "title": "基于高级采样的忠实快速影响函数", "title_en": "Faithful and Fast Influence Function via Advanced Sampling", "authors": "Jungyeon Koh,Hyeonsu Lyu,Jonggyu Jang,Hyun Jong Yang", "background": "影响函数(IFs)提供了一种后处理方法，通过使用梯度和海森矩阵来解释训练数据对黑盒模型的影响。然而，计算整个数据集的海森矩阵耗费大量资源，需要寻找可行的替代方案。传统的做法是随机选择一小部分训练数据，但这通常会导致IF估计值高度不一致，因为样本配置的方差较高。因此，需要改进的采样技术以提高IF估计的准确性.", "innovation": "提出了两种基于特征和逻辑的概率的高级采样技术。这些采样器通过考虑特征或逻辑的随机分布来选择整个数据集的一个小但有代表性的子集，从而提高IF估计的准确性。通过去除类别实验验证了该方法的有效性，使用F1分数度量模型在去除类别时对剩余类别的推理一致性。该方法相比基线减少了30.1%的计算时间，42.2%的内存使用，或者提高了2.5%的F1分数，表明提升了IF估计的精确性和效率.", "conclusion": "通过先进的采样技术，可以更快速且准确地计算影响函数，这不仅减少了计算时间和内存使用，还提高了F1分数，从而增强了黑盒模型中训练数据影响的解释能力。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26787", "html_url": "https://arxiv.org/abs/2510.26787", "title": "远程劳动力指数：衡量远程工作的AI自动化", "title_en": "Remote Labor Index: Measuring AI Automation of Remote Work", "authors": "Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks", "background": "人工智能在知识和推理的研究基准上取得了快速进展，但这些进展如何体现为经济价值和自动化尚未明确。为此，本文提出了远程劳动力指数（RLI），一个广泛跨行业的基准，包含真实世界、经济上具有价值的项目，旨在评估在实际环境下的端到端代理性能。现有研究表明，AI代理在RLI中接近最低水平，最高性能代理的自动化率为2.5%。", "innovation": "引入远程劳动力指数（RLI）作为一种衡量远程工作AI自动化的基准，该指数包括真实世界、经济上有价值的项目，为评估AI自动化提供了一个实证基础，有助于不同利益相关者了解AI对劳动力的影响，并指导其应对AI驱动的劳动力自动化。", "conclusion": "这一研究结果为讨论AI自动化提供了具体的实证证据，明确了AI在实际应用中的地位，并为跟踪AI影响和利益相关者的主动应对提供了一个共同基准。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26740", "html_url": "https://arxiv.org/abs/2510.26740", "title": "基于通用激励的多智能体资源分配中的公平性框架", "title_en": "A General Incentives-Based Framework for Fairness in Multi-agent Resource Allocation", "authors": "Ashwin Kumar,William Yeoh", "background": "在资源受限环境中，优化效率的代理可能会产生不公平的结果。现有方法通常需要额外的训练来实现公平性，而GIFF（General Incentives-based Framework for Fairness）通过利用行动-价值函数（Q-函数）直接平衡效率和公平性，无需额外训练来达成目标。这个方法在中央控制环境中被形式化，其中仲裁者使用GIFF修改后的Q值来解决分配问题。实证研究表明，该框架在动态拼车、预防无家可归和复杂职位分配任务中表现出色，超越了现有的基准方法，并能发现远见卓识、公平的政策。这些理论和实证结果支持GIFF的有效性，表明它能利用标准强化学习组件在复杂的多代理系统中达成更公平的结果。", "innovation": "GIFF 构建了一个新的框架，通过利用 Q-函数来平衡效率和公平性，而不需添加额外训练。这种方法计算每项行动的局部公平收益，并引入了反事实优势修正项来防止对已经富裕的代理进行过度分配。通过这种方法，GIFF 在中央控制环境中重新定义了分配问题，结果显示其在资源稀缺环境中能够发现更加公平的策略。此外，GIFF 的公平性代理被证明是真正公平提升的一个合理下界，并且其权衡参数提供了单调调整的可能。", "conclusion": "GIFF 是一个强大且原理性的框架，它能够利用标准的强化学习组件在复杂的多代理系统中实现更加公平的结果。GIFF 在不同领域中的实证研究表明，它不仅能超越现有的基准方法，还能发现远见卓识、公平的政策。通过理论依据和实证结果的支持，GIFF 确立了其作为多代理资源分配系统中促进公平性的有效工具的地位。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26788", "html_url": "https://arxiv.org/abs/2510.26788", "title": "通过FP16击败训练-推理不匹配", "title_en": "Defeating the Training-Inference Mismatch via FP16", "authors": "Penghui Qi,Zichen Liu,Xiangxin Zhou,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "大规模语言模型（LLMs）通过强化学习（RL）微调时，常常会面临训练和推理不一致性的问题，导致优化不稳定。尽管过去的研究尝试通过算法修正或工程对齐来缓解这一问题，但研究表明，问题的根本在于浮点精度本身。尽管BF16因其大的动态范围被广泛采用，但由于其较大的舍入误差，它破坏了训练和推理的一致性。", "innovation": "该工作展示了简单地回退到FP16可以有效解决这一不匹配问题。这种改变简单且现代框架完全支持，只需几行代码。与模型架构或学习算法无关。", "conclusion": "使用FP16在不同任务、算法和框架中都稳定优化，更快收敛，并表现更佳。希望这些发现将促使更广泛的权衡精度方面的重新考虑。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26790", "html_url": "https://arxiv.org/abs/2510.26790", "title": "Gistify！通过运行时执行实现代码基理解", "title_en": "Gistify! Codebase-Level Understanding via Runtime Execution", "authors": "Hyunji Lee,Minseon Kim,Chinmay Singh,Matheus Pereira,Atharv Sonwane,Isadora White,Elias Stengel-Eskin,Mohit Bansal,Zhengyan Shi,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan,Lucas Caccia", "background": "随着编码代理越来越多地应用于大型代码库中，自动设计具有挑战性的、代码级别的评估变得尤为重要。当前的最佳模型在解决这类具有复杂执行流程的任务时表现不佳。", "innovation": "提出了一个名为Gistify的任务，要求编码的LLM创建一个单一的、最小的自包含文件，该文件可以重现代码库中的特定功能。生成的文件必须复制在完整的代码库中运行相同命令的结果，且仅包含执行提供命令所必需的核心组件。研究所揭示的发现表明，当前的最佳模型在解决Gistify任务，尤其是那些具有长时间执行记录的任务时，表现不佳。", "conclusion": "Gistify任务需要模型具备对代码库的结构性理解、准确建模执行流程以及生成大型代码补丁的能力。当前最佳模型在解决这类任务时表现不佳，尤其是在有长时间执行记录的任务中。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26802", "html_url": "https://arxiv.org/abs/2510.26802", "title": "视频模型作为零样本推理器准备好了吗？基于MME-CoF基准的实证研究", "title_en": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark", "authors": "Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng", "background": "近年来，视频生成模型能够生成高质量、时间上一致的视频，表明它们可能包含了大量的世界知识。除了现实的合成，它们还表现出了视觉感知、建模和操作的新兴行为。然而，一个重要的问题仍然存在：目前的视频模型是否准备好在具有挑战性的视觉推理场景中担任零样本推理器？", "innovation": "该研究对流行的Veo-3模型进行了系统的评估，涵盖12个维度的推理行为，包括空间、几何、物理、时间以及体感逻辑，从而系统地揭示其优势和失败模式。此外，该研究还制定了一个标准的评估基准，即MME-CoF，用于深入评估链框推理（CoF），从而引导对该领域的研究。", "conclusion": "当前的视频模型在短时间维度的空间一致性、精细的锚定和局部一致的动力学方面表现出令人鼓舞的推理模式，但在长时间维度的原因推理、严格的几何约束以及抽象逻辑方面仍有所限制。因此，这些模型目前还不足以作为独立的零样本推理器，但可能在专用于推理的模型之外作为视觉引擎的补充表现出令人鼓舞的迹象。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26782", "html_url": "https://arxiv.org/abs/2510.26782", "title": "使用几何正则化世界模型克隆确定性3D世界", "title_en": "Clone Deterministic 3D Worlds with Geometrically-Regularized World Models", "authors": "Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen", "background": "世界模型是一种内部模型，能够模拟世界的演变，根据过去的经验和行动预测未来的状态。能够准确地构建和适应真实环境模型对于智能体在复杂动态环境中进行思考、规划和有效推理至关重要。尽管近年来在世界模型方面取得了快速进展，但目前的世界模型仍然很脆弱，长时间运行后会逐渐退化。研究者认为，代表质量是主要原因之一：外部感官输入（例如图像）高度维度化，损失或纠缠的潜在变量使得动力学习变得不必要地复杂。因此，研究人员探讨了是否仅通过改进代表学习就能够显著提高世界模型的性能。在此工作中，他们通过解决一个基础而未决的问题——构建一个能够完全克隆和过度适应确定性3D世界的模型——朝着构建真正准确的世界模型迈出了一步。他们提出了一种几何正则化世界模型（GRWM）旨在确保沿自然感官轨迹连续点在潜在表示空间中保持接近。这种方法产生了更优的潜在表示，与环境的真实几何结构更为一致。GRWM 具有即插即用特性，只需要轻微的架构修改扩展，即可适应不同长度轨迹，并且可以与多种潜在生成骨架兼容。在确定性3D设置和长时间预测任务中，GRWM 显著提高了展开的准确性和稳定性。分析表明，其优势来源于学习具有更优几何结构的潜在流形。这些发现支持了一个明确的结论：提高表示学习是实现稳健世界模型的直接和有用路径，能够提供可靠的长时间预测而无需扩大动力模块规模。", "innovation": "提出了一种几何正则化世界模型（GRWM），通过确保沿自然感官轨迹连续点在潜在表示空间中保持接近，显著提高了潜在表示的一致性和环境的真实几何结构。其特点包括即插即用、轻微的架构修改扩展能力和多种潜在生成骨架兼容性。实验结果显示GRWM在确定性3D设置和长时间预测任务中提高了展开的准确性和稳定性。", "conclusion": "提高表示学习是实现稳健世界模型的有效路径，能够提供可靠的长时间预测，而无需扩大动力模块规模。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02820", "html_url": "https://arxiv.org/abs/2505.02820", "title": "AutoLibra：从开放性人类反馈生成代理度量", "title_en": "AutoLibra: Agent Metric Induction from Open-Ended Human Feedback", "authors": "Hao Zhu,Phil Cuvin,Xinkai Yu,Charlotte Ka Yee Yan,Jason Zhang,Diyi Yang", "background": "现有方法主要依赖粗粒度的任务成功率度量指标来评估和优化代理，这些指标需手工由专家设计且不能奖励代理的中间涌现行为。", "innovation": "提出了一种名为AutoLibra的新框架，该框架能够将开放性的人类反馈，例如通过具体例子“如果发现按钮是禁用的，则不要再点击”，或将代理表现过于自主的反馈转化为细致行为的评估指标。AutoLibra通过将反馈转化为明确定义且具体的指标，并将这些指标用于LMA，以及通过两个元指标（覆盖度和冗余度）来评估指标集与开放反馈的一致性。通过优化这些元指标，AutoLibra能生成比现有代理评估基准更具具体性的指标，并发现新的指标来分析代理性能。", "conclusion": "AutoLibra是一种适用于任务的无偏评估和改善语言代理的强大工具。它还展示了AutoLibra在代理优化中的应用，使代理通过自我调节来改进。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15937", "html_url": "https://arxiv.org/abs/2503.15937", "title": "提高移动GUI代理：一种基于验证器的实际部署方法", "title_en": "Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment", "authors": "Gaole Dai,Shiqi Jiang,Ting Cao,Yuanchun Li,Yuqing Yang,Rui Tan,Mo Li,Lili Qiu", "background": "现有的移动代理通常利用大型语言模型（LLMs）直接生成每个步骤的动作，但这种方法存在效率低下的问题。本文提出了V-Droid，一种移动GUI任务自动化代理，它利用LLMs作为验证器，在做出最终决策前对候选动作进行评估。", "innovation": "V-Droid引入了一个全面的框架，用于构建基于验证器驱动的移动代理：离散动作空间的构建与仅预填充的工作流相结合，以加速验证过程；成对进度偏好训练，显著提升了验证器的决策能力；以及可扩展的人机联合注释方案，高效地在大规模数据收集上进行注释。", "conclusion": "V-Droid在多个公共的移动任务自动化基准中取得显著成功，分别在AndroidWorld、AndroidLab和MobileAgentBench中，任务成功率分别为59.5%、38.3%和49%，超越现有代理5.2%、2.1%和9%。此外，V-Droid还实现了极低的延迟，每步0.43秒，比现有移动代理快6.1倍。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10361", "html_url": "https://arxiv.org/abs/2505.10361", "title": "塑性作为赋能的镜像", "title_en": "Plasticity as the Mirror of Empowerment", "authors": "David Abel,Michael Bowling,André Barreto,Will Dabney,Shi Dong,Steven Hansen,Anna Harutyunyan,Khimya Khetarpal,Clare Lyle,Razvan Pascanu,Georgios Piliouras,Doina Precup,Jonathan Richens,Mark Rowland,Tom Schaul,Satinder Singh", "background": "代理是受过去观察影响并能影响未来观察的最小实体。这种对未来观察的影响能力通过‘赋能’得到捕捉，赋能已成为人工智能和认知科学中的关键概念。然而，代理受其观察影响的方式和程度也具有同等基础性。研究者通过将这种概念与一个新的、普遍性质的概念——塑性相结合，来探讨代理的行为能力。", "innovation": "定义了一个新的信息论量——广义定向信息，以此为基础重新定义了塑性。这个新的量严格泛化了1990年由Massey引入的定向信息，同时保留了所有积极的特性。作者指出，塑性可以被看作是赋能的镜像，本质测量相同，仅方向相反。这项研究为代理设计提供了一个新的视角，表明塑性和赋能之间的关系是理解代理的关键。", "conclusion": "这两个概念之间的关系意味着代理设计需要同时考虑这两种特性。通过探讨这两个概念及其关系的含义，研究者提出了塑性、赋能及其关系对于理解代理是至关重要的观点。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14970", "html_url": "https://arxiv.org/abs/2505.14970", "title": "Self-Evolving Curriculum for LLM Reasoning", "title_en": "Self-Evolving Curriculum for LLM Reasoning", "authors": "Xiaoyin Chen,Jiarui Lu,Minsu Kim,Dinghuai Zhang,Jian Tang,Alexandre Piché,Nicolas Gontier,Yoshua Bengio,Ehsan Kamalloo", "background": "强化学习（RL）已被证明对大型语言模型（LLM）的微调效果显著，尤其是在数学和代码生成等领域的推理能力得到了显著增强。然而，影响RL微调成功的关键因素是训练课程：即训练问题的呈现顺序。尽管随机课程作为基础标准很常见，但它们仍然效率低下。手动设计的课程依赖于大量经验法则，而在线过滤方法则可能非常耗时。\n", "innovation": "本文提出了一种自动课程学习方法——Self-Evolving Curriculum（SEC），该方法与RL微调过程同步学习课程策略。将课程选择视为非站定的自助式多臂Bandit问题，将每个问题类别（如难度级别或问题类型）视为独立的臂。利用策略梯度方法的绝对优势作为即时学习收益的代理指标。在每个训练步骤中，课程策略选择类别以最大化这一奖励信号，并使用TD(0)方法进行更新。实验结果表明，SEC在规划、归纳推理和数学这三个不同的推理领域中显著提高了模型的推理能力，并且在同时对多个推理领域进行微调时，实现了更好的技能平衡。\n", "conclusion": "SEC作为一种强化学习中LLM微调的有前途的策略，展现了其在提升模型推理能力和技能平衡方面的潜力。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11730", "html_url": "https://arxiv.org/abs/2505.11730", "title": "重新思考计算高效测试时间缩放的最佳验证粒度", "title_en": "Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling", "authors": "Hao Mark Chen,Guanxi Lu,Yasuyuki Okoshi,Zhiwen Mo,Masato Motomura,Hongxiang Fan", "background": "Test-time scaling (TTS) 已经在增强大型语言模型 (LLM) 的推理能力方面证明是有效的。验证在 TTS 中起着关键作用，影响推理性能和计算效率，这取决于验证的品质和计算成本。传统上，验证只在最终输出或单个生成步骤进行，这种方法可能限制了效率和质量之间的最佳平衡，而 Variable Granularity Search (VG-Search) 提出了一个可调粒度参数 g 的统一算法，该算法结合了带宽搜索和 Best-of-N 采样。", "innovation": "本文挑战了传统的验证范式，首次系统地研究了验证粒度对 TTS 的影响。具体来说，作者提出了一种名为 Variable Granularity Search (VG-Search) 的统一算法，通过可调的粒度参数 g，它可以动态调整验证频次，从而提高计算效率和扩展行为。实验结果表明，依赖于计算预算、生成器验证器配置和任务属性的不同情况，选择适当的 g 可以带来显著的性能提升，同时减少计算量。", "conclusion": "基于实验发现，作者提出了自适应的 VG-Search 策略，与带宽搜索相比，这些策略在准确率上提高了 3.1%，而只需减少超过 52% 的 FLOPs；与 Best-of-N 比较，其也提高了 3.6% 的准确率。研究团队将开源代码以支持未来的研究。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18139", "html_url": "https://arxiv.org/abs/2505.18139", "title": "拥抱矛盾：理论不一致不会阻碍构建负责任的人工智能系统之路", "title_en": "Embracing Contradiction: Theoretical Inconsistency Will Not Impede the Road of Building Responsible AI Systems", "authors": "Gordon Dai,Yunze Xiao", "background": "本文背景在于，当前负责型人工智能（RAI）领域中广泛存在的理论不一致性（如不同的公平性定义或准确性与隐私之间的取舍），常常被视为需要消除的缺陷，其实质是通过单一的简化定义来试图捕捉多维度的伦理概念，这可能导致重要信息的牺牲，并且抑制了模型的泛化能力和鲁棒性。", "innovation": "本文创新点在于提出，应将理论不一致性视为一种有价值的特征而非缺陷，建议通过多种、有时存在冲突的指标来多元化地捕捉复杂的伦理概念。这种方法不仅能够体现多元的道德立场和利益方价值，还能通过联合优化理论上相互矛盾的目标来避免模型过分拟合某个特定指标，从而提高模型在现实复杂环境下的泛化能力与鲁棒性。而这种做法有助于维护价值多样性，而不是采取简化或修剪指标的方式来追求理论一致性，从而避免损失概念深度和降低模型性能。", "conclusion": "因此，建议改变RAI理论和实践的方向，从避免不一致性中解脱出来，转而确定可以接受的不一致性水平，并阐明实践中实现大约一致性的机制。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12371", "html_url": "https://arxiv.org/abs/2505.12371", "title": "MedAgentBoard：采用传统方法评估多代理协作在多种医疗任务中的表现", "title_en": "MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks", "authors": "Yinghao Zhu,Ziyi He,Haoran Hu,Xiaochen Zheng,Xichen Zhang,Zixiang Wang,Junyi Gao,Liantao Ma,Lequan Yu", "background": "大规模语言模型（LLMs）的快速发展激发了对多代理协作在解决复杂医疗任务中应用的兴趣。然而，多代理协作方法的实际优势尚未得到充分理解，现有的评估往往缺乏普适性，未能覆盖多样化的任务，反映出真实的临床实践，并且经常缺乏与单一LLM方法及传统方法的严格对比。为了填补这一关键空白，本文提出了MedAgentBoard，一个综合基准，用于系统评估多代理协作方法、单一LLM方法和传统方法。MedAgentBoard涵盖了四个不同的医学任务类别：（1）医学问答（含视觉），（2）通俗摘要生成，（3）结构化的电子健康记录（EHR）预测建模，（4）临床工作流程自动化，这些类别分布在文本、医学图像和结构化的EHR数据中。", "innovation": "作者引入了MedAgentBoard，这是一个用于系统评估多代理协作（包括单一LLM和传统方法）的综合基准。MedAgentBoard通过涵盖四种不同的医学任务类别，提供了对多代理协作方法特性的全面评估，这些类别包括医学问答（含视觉）、通俗摘要生成、结构化的电子健康记录预测建模以及临床工作流程自动化，分布在文本、医学图像和结构化的EHR数据中。通过对这些任务的广泛实验，作者揭示了多代理协作在某些特定场景下，如在临床工作流程自动化中的任务完整度增强，尽管如此，多代理协作并不总是优于较为高级的单一LLM或专门的常规方法，尤其是在医学问答（视觉）和基于EHR的预测任务中，常规方法通常保持更好的性能。这表明，在医疗领域选择和开发AI解决方案时，需要任务特定的、基于证据的方法，并且需要仔细权衡多代理协作的固有复杂性和开销与实际性能提高之间的关系。", "conclusion": "MedAgentBoard提供了一种重要的资源和可操作的见解，强调了在选择和开发医疗领域的AI解决方案时，需要基于任务特定的证据方法。它指出，多代理协作的固有复杂性和开销必须与实际性能增益仔细权衡。所有代码、数据集、详细的提示和实验结果都在github上的[该链接]中开源。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21204", "html_url": "https://arxiv.org/abs/2508.21204", "title": "模糊化、符号化与上下文化：通过认知支架增强LLM指令", "title_en": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "authors": "Vanessa Figueiredo", "background": "该论文研究了提示级别诱导偏见如何影响大型语言模型（LLMs）在互动对话中的认知行为。为了促进演绎和结构化推理，作者引入了一种符号化辅助方法，结合了短期记忆模型，以实现苏格拉底式辅导。通过在五个系统变体中进行受控剥离实验，并采用专家设计的评估框架，研究语言模型输出在支架、响应性、符号推理和对话记忆方面的表现。", "innovation": "论文创新性地提出了一种符号化辅助方法，结合了短期记忆模型，用于促进LLMs在互动对话中的适应性结构化推理。通过对比分析系统变体，展示了提示级别认知支架在形成本质性教学策略方面的作用，并揭示了记忆或符号结构的缺失会削弱关键认知行为，如抽象化、适应性探索和概念连续性。", "conclusion": "初步结果显示，完整的系统表现优于基线变体。分析揭示了去除记忆或符号结构会削弱关键认知行为，支持在LLMs中认知支架可以可靠地塑造教学策略的观点。这种方法为初期实验提供了一种可扩展和系统的框架，以便在架构变体之间进行比较。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01543", "html_url": "https://arxiv.org/abs/2508.01543", "title": "Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning", "title_en": "Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning", "authors": "Derin Cayir,Renjie Tao,Rashi Rungta,Kai Sun,Sean Chen,Haidar Khan,Minseok Kim,Julia Reinspach,Yue Liu", "background": "大型语言模型（LLMs）通过偏好驱动的微调取得了显著的进步，这依赖于训练数据的质量。尽管人类反馈对于提高数据质量至关重要，但它成本高昂且难以大规模应用。", "innovation": "提出了Refine-n-Judge，这是一种自动化迭代方法，利用单一LLM作为既筛选者又评判者的角色，以增强数据集的质量。与现有的迭代方法不同，Refine-n-Judge利用LLM生成改进并明确评估每一项改进，确保每次迭代都对数据集有实质性的提升，而无需额外的人工注释或奖励模型。在每次步骤中，LLM会先对回应进行改进，然后判断该改进是否优于之前的答案。这一过程将持续直到LLM更倾向于原始答案而非改进。", "conclusion": "Refine-n-Judge在包括编码、数学和对话的一系列公开数据集上展示了有效性，覆盖五个语料库。使用Refine-n-Judge增强的数据集微调的模型在超过74%的情况下被LLM评判者更偏好，与使用原始数据集由GPT-4微调的模型相比。此外，报告了性能增益：在AlpacaEval和AlpacaEval 2.0上分别提高了5%，在MT-Bench上提高了19%。结果表明，Refine-n-Judge可以生成高质量的数据集和可扩展的模型改进。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18667", "html_url": "https://arxiv.org/abs/2509.18667", "title": "TERAG: 低token消耗的图增强检索生成", "title_en": "TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation", "authors": "Qiao Xiao,Hong Ting Tsang,Jiaxin Bai", "background": "图增强检索生成（RAG）作为一种提升大型语言模型（LLMs）推理、准确性和事实性的方法，受到了广泛研究。然而，现有的图RAG系统在图构建过程中忽略了LLM token使用成本高昂的问题，这限制了其大规模应用和推广。针对这一问题，本文提出了一种名为TERAG的简单而有效的框架，在降低成本的同时构建信息性的图。", "innovation": "本文借鉴了HippoRAG的方法，引入了个性化PageRank（PPR）在检索阶段的应用，并在保持至少80%的广泛应用的图RAG方法准确性的同时，仅消耗3%-11%的输出token。该方法不仅优化了token使用效率，还提供了一个高效的构建流程，特别适用于大规模和成本敏感的部署场景。", "conclusion": "通过引入个性化PageRank和优化token使用，TERAG在保持高准确性的前提下显著降低了图构建的成本，为大规模和成本敏感的大型语言模型应用提供了新方案。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15030", "html_url": "https://arxiv.org/abs/2508.15030", "title": "Collab-REC：基于LLM的多主体框架以在旅游推荐中实现平衡", "title_en": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism", "authors": "Ashmi Banerjee,Adithi Satish,Fitri Nur Aisyah,Wolfgang Wörndl,Yashar Deldjoo", "background": "该研究背景在于现有的旅游推荐系统往往受到流行偏见的影响，导致推荐结果偏向热门地点，而忽视了一些较少访问的地方。研究指出，单一主体的推荐系统无法有效平衡个性化、流行性和可持续性之间的关系，从而无法提供多样性的旅游建议。因此，该研究旨在开发一个能够平衡这些方面并提供多样性和整体相关性强的推荐系统的框架。", "innovation": "Collab-REC是一个基于多代理的框架，利用三个基于LLM的代理——个性化、流行性和可持续性来生成城市建议。非LLM调解员通过多轮谈判合并和改进这些建议，确保每个代理的观点都被纳入考虑，并且能够减少无意义或重复的回答。实验结果表明，Collab-REC在提高多样性和全面相关性方面优于单一代理基线，能够揭示常被忽视的较为冷门的旅游地点。", "conclusion": "Collab-REC提供了一种平衡个性化和流行性的旅游推荐方法，并结合了可持续性的考量。这种方法通过综合多个代理的观点，能够减少过度旅游现象，并更好地遵守用户的约束条件。这项研究表明，多利益相关者的协作可以在LLM驱动的推荐系统中实现具有潜力的解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21257", "html_url": "https://arxiv.org/abs/2507.21257", "title": "CompoST: 在QALD背景下分析LLMs对问题进行组合性解释的能力基准", "title_en": "CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting", "authors": "David Maria Schmidt,Raoul Schubert,Philipp Cimiano", "background": "语言解释是一个组合过程，其中更复杂的语言结构的意义是从其部分的意义推断出来的。大型语言模型拥有卓越的语言解释能力，并且已经被成功应用于将问题映射为SPARQL查询。关于这个问题的过程是否系统化仍旧是一个开放性问题。为了解答这一问题，本研究提出了一个基准，用于评估LLMs解释问题的能力是否真正具有组合性特征。为实现这一目标，基于DBpedia中的图模式生成了难度各异的三个数据集，并且依靠Lemon词表进行具体化。这种近乎控制的生成方法旨在测试LLMs在已经看到构成块的情況下解释结构复杂问题的能力。我们通过使用不同大小的模型以及多种提示技术和少量优化技术进行实验，以评估LLMs在理解组成部分的前提下能否解释复杂的查询。实验结果显示，随着与优化样本的偏离度增加，性能的宏F1分数从0.45下降到0.09。即使在模型输入中提供了所有必要的信息，最低复杂度数据集的最大F1分数也未超过0.57。这些结果表明，LLMs难以系统地和组合性地解释问题，并将其映射为SPARQL查询.", "innovation": "提出了一个名为CompoST的新基准，用于分析大型语言模型是否能够以一种组合性的方式解释问题。该基准通过从DBpedia生成的难度各异的数据集来实现此目标，这些数据集基于Lemon词表进行具体化。实验结果表明，LLMs在理解问题组成部分的基础上，系统地解释复杂问题的能力有限，无法完美地将问题映射为SPARQL查询.", "conclusion": "LLMs在解释复杂问题和将其映射到SPARQL查询方面的系统性和组合性表现不佳。无论模型输入提供了多少必要信息，其表现都受到显著限制。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18318", "html_url": "https://arxiv.org/abs/2510.18318", "title": "Earth AI: 使用基础模型和跨模态推理解锁地理空间洞察", "title_en": "Earth AI: Unlocking Geospatial Insights with Foundation Models and Cross-Modal Reasoning", "authors": "Aaron Bell,Amit Aides,Amr Helmy,Arbaaz Muslim,Aviad Barzilai,Aviv Slobodkin,Bolous Jaber,David Schottlander,George Leifman,Joydeep Paul,Mimi Sun,Nadav Sherman,Natalie Williams,Per Bjornsson,Roy Lee,Ruth Alcantara,Thomas Turnbull,Tomer Shekel,Vered Silverman,Yotam Gigi,Adam Boulanger,Alex Ottenwess,Ali Ahmadalipour,Anna Carter,Behzad Vahedi,Charles Elliott,David Andre,Elad Aharoni,Gia Jung,Hassler Thurston,Jacob Bien,Jamie McPike,Juliet Rothenberg,Kartik Hegde,Kel Markert,Kim Philipp Jablonski,Luc Houriez,Monica Bharel,Phing VanLee,Reuven Sayag,Sebastian Pilarski,Shelley Cazares,Shlomi Pasternak,Siduo Jiang,Thomas Colthurst,Yang Chen,Yehonathan Refael,Yochai Blau,Yuval Carny,Yael Maguire,Avinatan Hassidim,James Manyika,Tim Thelin,Genady Beryozkin,Gautam Prasad,Luke Barrington,Yossi Matias,Niv Efron,Shravya Shetty", "background": "地理空间数据为了解我们星球提供了巨大的潜力，但由于这些数据的海量规模、多样性和不同的分辨率、时间尺度以及稀疏性，它们对深入分析和解释提出了重大挑战。", "innovation": "本文介绍了一种基于三大关键领域—星球尺度图像、人口、环境—和安装了Gemini智能推理引擎的基础模型的Earth AI方法。通过开发一个Gemini驱动的代理，可以处理复杂的多步骤查询，实现多个基础模型与大规模地理空间数据源和工具的一致性推理，从而为地理空间推断提供互补价值，并利用协同效应提高预测能力。", "conclusion": "在新的现实世界危机场景基准上，我们的代理展示了从原始地理空间数据到实际理解的及时关键洞察，有效地固化了从数据到价值的转换过程。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.16648", "html_url": "https://arxiv.org/abs/2509.16648", "title": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs", "title_en": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs", "authors": "Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy", "background": "对多模态大型语言模型（MLLMs）生成的预测进行准确的信任评估具有挑战性，因为它们接受多样化的多模态输入。准确的信任评估可以实现有选择性的预测，并提高用户信心。然而，由于模型的不确定性和多样性的输入形式，这变得复杂。现有的方法通常需要访问模型的内部结构，因此是受监督的，这增加了实现的复杂性并可能侵犯隐私。FESTA提出了一种新的方法来解决这个问题，该方法能够在无需获取模型内部结构的情况下，通过采样技术评估模型的不确定性。这种方法适用于各种现成的多模态LLMs，在视觉和音频推理任务上进行了验证，证明了其优越性。", "innovation": "FESTA提出了一种新的采样技术，用于多模态大语言模型的信任评估。与现有依赖于标记数据和内部结构不同，FESTA仅通过模型的输入-输出访问（黑盒模式）生成不确定性度量。它通过等效和补充输入采样的方式，扩展了输入空间，以探索模型的一致性和敏感性。这种任务保持的不确定性量化方法能够显著提高预测选择性性能，尤其是在检测模型错误预测时，大大提高了视觉和音频LLMs的表现。", "conclusion": "FESTA 在多模态LLMs的信任评估中表现出显著的改进，特别是在检测错误预测方面，实现了显著的相对改进。该方法在不同模态（视觉和音频）的一系列现成的多模态LLMs上进行了验证，证明了其有效的鲁棒性和适用性。FESTA的源代码已开源。未来的工作可以进一步探索在更大规模和更多模态中的应用，并尝试将该方法扩展到其他类型的语言模型中。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02091", "html_url": "https://arxiv.org/abs/2510.02091", "title": "揭开大型语言模型层次在检索、知识和推理中的角色之谜", "title_en": "Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and Reasoning", "authors": "Xinyuan Song,Keyu Wang,PengXiang Li,Lu Yin,Shiwei Liu", "background": "近年来的研究表明，大型语言模型（LLMs）的深层结构在表示学习中的贡献很少，可以去除大部分深层结构而不会显著降低性能。然而，这些结论通常基于狭隘的评估，并可能忽视模型行为中的重要方面。本文进行了一场系统的跨维度研究，探讨了深层结构在评估协议、任务类别和模型架构上的利用情况。研究结果显示，深层结构一般不如早期结构有效，但其贡献会根据评估设置有所不同。", "innovation": "本文引入了对深层结构利用的系统性研究，涵盖了评估协议、任务类别和模型架构等多个维度。研究结果揭示了大型语言模型中深度使用具有高度异质性和依赖性，强调了根据不同任务、度量标准和模型的角度来解释和压缩大型模型的重要性。通过展示深层结构在不同评估机制下的不同作用，本研究澄清了深层结构对检索、知识和推理的贡献，提出了知识和检索集中在浅层组件中，而深层结构对于推理准确性至关重要，可以通过蒸馏重塑的观点。", "conclusion": "研究表明，大型语言模型中深层次的利用是异质性和上下文依赖的。这意味着在解释和压缩大型语言模型时，需要采取任务、度量标准和模型意识的方法。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05014", "html_url": "https://arxiv.org/abs/2510.05014", "title": "思考后再嵌入：生成性上下文改进多模态嵌入", "title_en": "Think Then Embed: Generative Context Improves Multimodal Embedding", "authors": "Xuanming Cui,Jianpeng Cheng,Hong-you Chen,Satya Narayan Shukla,Abhijeet Awasthi,Xichen Pan,Chaitanya Ahuja,Shlok Kumar Mishra,Yonghuan Yang,Jun Xiao,Qi Guo,Ser-Nam Lim,Aashu Singh,Xiangjun Fan", "background": "近年来，人们对通用多模态嵌入（UME）产生了浓厚兴趣，模型需要生成任务特定的表示。虽然近期研究表明，多模态大型语言模型（MLLMs）在这些任务上表现出色，但它们通常仅被用作编码器，未能充分利用其生成能力。然而，随着指令复杂度增加和需要组合推理，这种编码范式效率降低。受链式思维推理有效性的启发，我们提出了一种通用‘思考后再嵌入’（TTE）框架，该框架由一个推理器和一个嵌入器组成。", "innovation": "首先，通过利用强大的MLLM推理器，我们在MMEB-V2基准上达到了最新的性能，超过了基于海量内部数据训练的私有模型。其次，为了减少对大型MLLM推理器的依赖，我们使用高质量的嵌入中心推理痕迹微调了一个较小的MLLM推理器，相较于近期提出的模型，开源模型取得了7%的绝对性能提升。第三，我们探讨了将推理器和嵌入器整合到一个统一模型中的策略，以提高效率而不牺牲性能。", "conclusion": "本研究提出了一个通用的TTE框架，通过利用强大的MLLM推理器，实现了在多模态嵌入任务上最新的性能，同时提出了减少大型MLLM推理器依赖并提升开源模型性能的方法，并探讨了将推理器和嵌入器整合的策略，以提高效率而不牺牲性能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18477", "html_url": "https://arxiv.org/abs/2510.18477", "title": "LAFA：在去中心化数据源上由代理驱动的大语言模型引导的联邦数据分析", "title_en": "LAFA: Agentic LLM-Driven Federated Analytics over Decentralized Data Sources", "authors": "Haichao Ji,Zibo Wang,Cheng Pan,Meng Han,Yifei Zhu,Dan Wang,Zhu Han", "background": "大型语言模型在通过解释自然语言查询并生成多操作执行计划来自动化数据分析任务方面表现出巨大潜力。然而，现有的基于代理的分析框架假定中心化数据访问，提供很少甚至没有隐私保护。与此同时，联邦分析（FA）允许在分布式数据源上进行隐私保护计算，但它缺乏对自然语言输入的支持，并需要结构化的机器可读查询。", "innovation": "本文提出了LAFA，这是一种首次将基于代理的大语言模型数据分析与联邦分析相结合的系统。LAFA引入了一个分层多代理架构，可以接受自然语言查询并将其转换为优化的、可执行的FA工作流。粗粒度规划器首先将复杂的查询分解为子查询，而细粒度规划器则使用先验结构知识将每个子查询映射到FA操作的有向无环图。通过优化代理重新编写和合并多个DAG，消除冗余操作，从而减少计算和通信开销。", "conclusion": "我们的实验表明，LAFA的一致优于基本的提示策略，通过实现更高的执行计划成功率并极大地减少资源密集型的FA操作。这项工作为在FA环境中支持自然语言输入的隐私保护、由大语言模型驱动的分析奠定了实际基础。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19771", "html_url": "https://arxiv.org/abs/2510.19771", "title": "在LLM代理中超越反应性：衡量前瞻式问题解决", "title_en": "Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents", "authors": "Gil Pasternak,Dheeraj Rajagopal,Julia White,Dhruv Atreja,Matthew Thomas,George Hurn-Maloney,Ash Lewis", "background": "LLM（大型语言模型）代理现已越来越多地转向主动行为。与等待指令的方式不同，它们能够主动预见用户需求，并通过自主手段解决这些问题。然而，目前评估这种主动性具有挑战性，当前的基准测试仅限于局部上下文，这限制了它们在测试跨源和长时间推理方面的能力。", "innovation": "为了填补这一空白，本文提出了PROBE（Proactive Resolution Of BottlEnecks），分解主动行为为三个核心能力的流水线：（1）搜索未特定的问题，（2）识别具体瓶颈，（3）执行适当的解决方案。通过对领先的大语言模型和流行代理框架的应用，表明即使是最先进的模型也难以完成这个基准测试。我们的研究结果揭示了代理系统中自主行动的现有局限性，并指出了未来的研究方向。", "conclusion": "研究结果强调了代理系统中自主行动的现状，并揭示了有希望的研究方向，特别是在跨源和长时间的推理方面。我们发现，在前沿LLM代理中总体性能最好的是40%，实现这一性能的是GPT-5和Claude Opus-4.1。此外，我们还展示了每个模型的相对能力，并分析了它们的共同失败模式。这突显了在代理系统中实现前瞻式问题解决的发展潜力和挑战。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23925", "html_url": "https://arxiv.org/abs/2510.23925", "title": "潜在意念链推理在视觉推理中的应用", "title_en": "Latent Chain-of-Thought for Visual Reasoning", "authors": "Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao", "background": "大型视觉-语言模型（LVLMs）的可解释性和可靠性对于改善其性能至关重要。但现有的训练算法如SFT、PPO和GRPO可能无法很好地应用于未见过的推理任务，并且严重依赖于偏差的奖励模型。这导致了训练结果不能很好地泛化到新的任务上，并且难以获得高质量的可解释性推理过程（CoT）.", "innovation": "该研究将LVLMs中的推理重新定义为后验推断，并提出了一种基于近似变分推断的可扩展训练算法。通过采用多样性的强化学习算法，引入了新颖的稀疏奖励函数，以促进多样化的高概率潜在CoT，克服了确定性抽样限制并避免了奖励作弊。此外，该研究还引入了一种贝叶斯推理扩展策略，使用边际似然替代昂贵的Best-of-N和Beam Search，以高效地评估最合理的推理和答案。", "conclusion": "该研究方法能够提高基于LVLMs在七个推理基准测试中的表现，特别是在效果、泛化能力和可解释性方面表现优异。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2305.17608", "html_url": "https://arxiv.org/abs/2305.17608", "title": "大型语言模型对齐中的回报坍塌现象", "title_en": "Reward Collapse in Aligning Large Language Models", "authors": "Ziang Song,Tianle Cai,Jason D. Lee,Weijie J. Su", "background": "大语言模型（LLMs）如ChatGPT和GPT-4的强大能力在很大程度上得益于将其与基于人类偏好训练的奖励模型对齐。这些偏好通常以对提示的响应进行排名的方式表示。然而，在对齐过程中观察到了所谓的‘回报坍塌’现象，表现为使用排名方法在最终训练阶段会导致奖励分配相同，无论提示如何，这不利于生成多样化和具有针对性的回应。", "innovation": "本文发现并分析了这一现象的原因，是由于基于排名的目标函数在优化过程中无法有效利用提示相关的信息。研究在此基础上提供了满足特定提示需求的奖励分配的闭合表达式，并提出了一个基于提示的目标优化方案，能够在插入阶段提供提示相关的奖励分布。这种新型的优化方案显著减轻了在训练奖励模型过程中出现的回报坍塌问题。", "conclusion": "实验结果表明提出的提示感知的效用函数大大缓解了回报坍塌问题。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23595", "html_url": "https://arxiv.org/abs/2510.23595", "title": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution", "title_en": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution", "authors": "Yixing Chen,Yiding Wang,Siqi Zhu,Haofei Yu,Tao Feng,Muhan Zhang,Mostofa Patwary,Jiaxuan You", "background": "强化学习（RL）在增强大语言模型（LLMs）的推理能力方面展现了巨大的潜力，但其成功依赖于由人类标注的数据集和可验证的奖励，这限制了其可扩展性和通用性。近年来，模仿游戏与围棋的自我博弈RL方法旨在提升LLM的推理能力，但这些方法主要依赖于具体环境提供反馈（如Python解释器或游戏引擎），将它们扩展到更广泛的领域仍然面临挑战。", "innovation": "本文提出了Multi-Agent Evolve（MAE）框架，它使LLM能够在解决多样任务（如数学、推理和常识问答）中自我进化。MAE的核心设计基于交互的三方代理（Proposer、Solver和Judge）的机制，这些代理是从单一LLM中实例化的，并通过强化学习来优化它们的行为。实验结果表明，MAE在Qwen2.5-3B-Instruct上实现了多个基准平均改善4.54%，这显示了MAE作为扩展性数据高效的方法，以最小的人类标注监督提高LLM通用推理能力的潜力。", "conclusion": "MAE为提升LLMs的通用推理能力提供了一种可扩展且数据高效的解决方案，无需大量依赖人类标注的监督。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.09086", "html_url": "https://arxiv.org/abs/2405.09086", "title": "基于TD3的混沌强化学习", "title_en": "Chaos-based reinforcement learning with TD3", "authors": "Toshitaka Matsuki,Yusuke Sakemi,Kazuyuki Aihara", "background": "在基于混沌的强化学习(CBRL)中，代理的内部混沌动态驱动探索。然而，先前的研究中CBRL的学习算法尚未得到充分发展，且未结合强化学习领域的最新进展。", "innovation": "引入了最新的深度强化学习算法Twin Delayed Deep Deterministic Policy Gradients (TD3)，将其应用于CBRL。TD3能够处理确定性和连续动作空间，从而增强CBRL的方法，使CBRL代理能够自主抑制其探索行为并在环境变化时恢复探索。此外，还发现了一个混沌强度范围，在该范围内，代理模型能够灵活切换探索和利用，并适应环境变化。", "conclusion": "实验结果表明，TD3可以作为CBRL的算法应用于简单的目标到达任务中，CBRL代理能够在学习过程中自主调节探索行为，并在环境变化时恢复探索。探索代理混沌性对学习的影响显示，存在一个合适的混沌强度范围，以灵活切换探索和利用，并适应环境变化。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.08788", "html_url": "https://arxiv.org/abs/2403.08788", "title": "VerifIoU - 对象检测对扰动的鲁棒性", "title_en": "VerifIoU - Robustness of Object Detection to Perturbations", "authors": "Noémie Cohen,Mélanie Ducoffe,Ryma Boumazouza,Christophe Gabreau,Claire Pagetti,Xavier Pucel,Audrey Galametz", "background": "本文介绍了一种新颖的区间界传播（IBP）方法，用于形式化验证对象检测模型，具体针对交并比（IoU）指标。这种方法在流行的抽象解释验证工具中实现了开源代码，名为IBP IoU，并在着陆轨迹跑道检测和手写数字识别案例研究上进行评估。", "innovation": "该方法提出了一种用于对象检测模型形式化验证的新型区间界传播（IBP）方法，特别针对交并比（IoU）指标。通过与基准方法（原生IBP IoU）进行比较，展示了IBP IoU在保证准确性和稳定性方面的优越性能，从而提高了机器学习应用的安全性和鲁棒性。", "conclusion": "该研究在着陆轨迹跑道检测和手写数字识别案例上评估了IBP IoU验证器，结果显示IBP IoU在确保准确性和稳定性方面表现更优，有助于实现更安全和鲁棒的机器学习应用。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23127", "html_url": "https://arxiv.org/abs/2510.23127", "title": "在科学大语言模型中迷失于标记化：上下文为何成为理解生物分子的关键", "title_en": "Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs", "authors": "Kai Zhuang,Jiawei Zhang,Yumou Liu,Hanqun Cao,Chunbin Gu,Mengdi Liu,Zhangyang Gao,Zitong Jerry Wang,Xuanhe Zhou,Pheng-Ann Heng,Lijun Wu,Conghui He,Cheng Tan", "background": "科学大型语言模型（Sci-LLMs）在加速生物发现方面展现出巨大潜力，但处理原始生物分子序列时面临一个根本挑战：标记化难题。当前策略无法有效解决处理序列数据时的功能模式信息丢失或对齐复杂的问题，极大地限制了它们的推理能力。文章通过对比不同输入模式下的多种Sci-LLMs在生物推理任务上的表现，揭示了上下文在Sci-LLMs理解生物分子中的重要性。研究发现，仅提供高层面结构化上下文的方法始终优于其他方法，且上下文和原始序列结合反而会降低模型的性能，表明原始序列作为信息噪声的存在。", "innovation": "提出了一种新的方法，即不直接处理低层次的原始序列数据，而是为Sci-LLMs提供浓缩的背景信息，从而有效绕过了直接解读噪声序列数据的需求。这一方法通过实证研究证明了上下文对Sci-LLMs在生物领域中的重要性，改变了模型的工作方式，从序列解码转向基于专家知识的推理。这一研究为开发一类新的科学AI代理奠定了基础，强调了从直接解析序列转向高层次知识综合的重要性。", "conclusion": "现有Sci-LLMs的主要优势不在于它们解读生物分子判读能力，而在于处理结构化的、人可读的知识的能力。因此，应将Sci-LLMs重新定义为基于专家知识的强大推理引擎，而非序列解码模型。这一研究为未来的科学AI开发指明了新的方向，即重点放在高层次知识合成上，而不是直接序列解释上。研究的代码已发布于此: this https URL."}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23216", "html_url": "https://arxiv.org/abs/2510.23216", "title": "在现实足球模拟中的类人守门：一种高效强化学习方法", "title_en": "Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach", "authors": "Alessandro Sestini,Joakim Bergdahl,Jean-Philippe Barrette-LaPierre,Florian Fuchs,Brady Chen,Michael Jones,Linus Gisslén", "background": "尽管一些知名视频游戏曾作为深度强化学习（DRL）的试验平台，但该技术在游戏行业中用于创造真实的AI行为方面应用很少。以往的研究主要集中在训练超人级别的智能体，这在资源有限的游戏工作室为了实现类人智能体的目标时是不切实际的。本文旨在提出一种高效的DRL方法，针对工业应用场景，特别是视频游戏行业，以提高智能体的训练效率和调整能力。所提出的方法通过利用预先收集的数据和提高网络的可塑性，改进了基于价值的DRL的样本效率。该方法在EA SPORTS FC 25，最具销售潜力的足球模拟游戏中测试了一名守门员智能体，结果显示该智能体在扑救球率上比游戏内置的AI高10%。抽样研究显示，与标准DRL方法相比，该方法可以将智能体的训练速度提高50%。此外，领域专家的定性评估表明，该方法生成的智能体玩法更具人类特性，超过了手动制作的智能体。作为该方法影响力的一个证明，它已被应用于系列的最新发布版本中。", "innovation": "本研究提出了一种高效的DRL方法，专门针对工业环境中的智能体训练和微调，特别是针对视频游戏行业。该方法通过利用预先收集的数据和提高网络可塑性，改进了基于价值的DRL的样本效率。研究结果表明，该方法与标准DRL技术相比，训练智能体速度提高了50%。此外，领域专家的定性评估显示，该方法生成的智能体表现得更像人类，比手动制作的智能体更具人类特性。该方法已被采用并应用于最近发布的系列版本中。", "conclusion": "本研究提出了一种高效的DRL方法，专门为工业环境中的智能体训练和微调设计，特别是在视频游戏行业中。该方法通过利用预先收集的数据和提高网络可塑性，显著改进了基于价值的DRL的样本效率。所提出的方法不仅在EA SPORTS FC 25中进行了应用，显示出智能体扑救球率提高了10%，而且也能更快地训练智能体。进一步的评估显示，这种方法生成的智能体表现得像人类，比手动制作的智能体更具有人类特性。这种方法已应用于游戏的最新版本中。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.05948", "html_url": "https://arxiv.org/abs/2406.05948", "title": "对大型语言模型进行检测的链式审视：检测后门攻击", "title_en": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models", "authors": "Xi Li,Ruofan Mao,Yusen Zhang,Renze Lou,Chen Wu,Jiaqi Wang", "background": "大型语言模型（LLMs），尤其是通过API访问的LLMs，已经显示出了在各种领域的出色能力。然而，缺乏技术背景的用户往往转向不可信的第三方服务，如提示工程，以增强他们的LLM体验，这使得他们容易受到后门攻击等对抗性威胁的攻击。这些被后门攻击篡改的LLM会在输入包含特定“触发器”时生成恶意输出。传统的防御策略最初是为小型模型设计的，它们对于API可访问的LLM是不现实的，因为它们限制了模型的访问，计算成本高，数据需求大。", "innovation": "我们提出了链式审视（CoS），利用LLM独特的推理能力来减轻后门攻击。CoS通过使LLM生成给定输入的推理步骤，并检查这些步骤与最终输出的一致性来运行，不一致则表明可能存在攻击。CoS特别适用于流行的仅通过API部署的LLM，使其以低成本和少量数据进行防御检测。它用户友好且由自然语言驱动，使非专家能够独立进行防御并保持透明度。我们通过广泛的实验验证了CoS的有效性，结果表明CoS在更强大的LLM上具有更大的益处。", "conclusion": "我们提出的链式审视（CoS）通过利用LLM独特的推理能力有效地检测后门攻击，在API可访问的LLM部署中具有显著的优势。CoS能够在几乎不增加成本和数据需求的情况下进行有效的防御检测，并且适合非专业的用户来使用，同时保持透明度。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.17489", "html_url": "https://arxiv.org/abs/2407.17489", "title": "AI的社交力场：重塑人机团队中的分布式认知", "title_en": "AI's Social Forcefield: Reshaping Distributed Cognition in Human-AI Teams", "authors": "Christoph Riedl,Saiph Savage,Josie Zvelebilova", "background": "AI不仅作为中立的工具存在于团队中，还会主动重塑团队中社会和认知的协作结构。本文研究了AI在分布式认知中的作用，揭示了AI如何影响人类和AI代理之间的沟通和协作，从而改变团队的认知架构。", "innovation": "本研究提出了一种统一的框架，名为“对齐的分布式认知”，标志着人类与AI团队协作中语言、认知和社会协调的形成。研究通过两个实验证明了AI生成的语言如何不仅影响人们的语言表达，还影响他们的思维、注意力分配以及彼此之间的关系，揭示了AI作为隐性社会力量的作用。", "conclusion": "本研究揭示了AI在促进高效合作的同时，也会削弱知识多样性，破坏自然的对齐过程。本文呼吁重新思考AI在团队环境中的社会影响力，并提出了透明性、可控性及群体动态等新的设计理念，以促进负责任和高效的AI赋能人类团队合作。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.06263", "html_url": "https://arxiv.org/abs/2409.06263", "title": "Speak & Spell: LLM-Driven Controllable Phonetic Error Augmentation for Robust Dialogue State Tracking", "title_en": "Speak & Spell: LLM-Driven Controllable Phonetic Error Augmentation for Robust Dialogue State Tracking", "authors": "Jihyun Lee,Solee Im,Wonjun Lee,Gary Geunbae Lee", "background": "对话状态跟踪（DST）是任务导向对话系统中的重要组成部分，它负责识别对话中的重要信息。然而，在口语对话环境中，自动语音识别（ASR）系统中的命名实体识别错误显著降低了DST模型的准确性。本文分析了这一背景，指出了口语环境中ASR系统带来的命名实体识别错误对DST准确性的影响。", "innovation": "本文提出了一种简单有效的数据增强方法，以控制在关键字周围引入具有音似性的错误。该方法旨在提高DST模型对错误的鲁棒性。具体来说，该方法通过使用带关键字高光的提示来控制错误的位置，并引入音似错误，从而在噪声和低准确性ASR环境中提高了DST模型的准确性。", "conclusion": "研究结果表明，通过控制引入的音似错误，该方法能够生成足够的错误模式，从而在含噪声和低ASR准确性环境下有效提升DST模型的准确性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.17883", "html_url": "https://arxiv.org/abs/2412.17883", "title": "捍卫事后解释的合理性", "title_en": "In Defence of Post-hoc Explainability", "authors": "Nick Oh", "background": "本文背景在于针对事后解释方法在机器学习领域的可靠性和知识论地位受到的批评。研究者们通过探讨如何在保持一定程度的透明度和通过严格的实证验证的前提下，使这些方法成为科学知识生产中的有效工具，提出了自己的观点。\n", "innovation": "本文的创新在于提出了基于中介理解和有限事实性的哲学框架，以新视角探讨了事后解释方法的合理性和有效性。作者认为，通过结构化的模型行为解释，可以生成新的科学洞见，无需达到完全的机械透明度，但需要承认其逼近性质并进行严格的实证验证。\n", "conclusion": "通过分析生物医药领域的机器学习应用，作者展示了当事后解释方法适当整合到科学研究实践中时，它们能够产生新的假设，并推进现象性理解。\n"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.12869", "html_url": "https://arxiv.org/abs/2410.12869", "title": "使用多个弱评估器的语言模型偏好评估", "title_en": "Language Model Preference Evaluation with Multiple Weak Evaluators", "authors": "Zhengyu Hu,Jieyu Zhang,Zhihan Xiong,Alexander Ratner,Kaize Ding,Ranjay Krishna", "background": "尽管大型语言模型（LLMs）取得了显著的成功，但评估其输出质量的偏好仍然是一项关键挑战。现有方法通常依赖单一的强LLM作为裁判进行两两对比，但这种单一评估者的方法容易产生循环偏好问题，即A比B好，B比C好，但C却比A好，导致评估结果矛盾。", "innovation": "我们提出了一种名为PGED（Preference Graph Ensemble and Denoise）的新方法。PGED利用多个基于模型的评估者构建偏好图，并通过整合和去噪这些图来获得无循环、非矛盾的评估结果。该框架提供了理论保障，证明了其在恢复真实偏好结构方面的有效性。在十个基准上的广泛实验表明，PGED在三种应用中具有优越性：模型评估中的排名、测试时的响应选择以及模型微调的数据选择。值得注意的是，PGED利用小规模LLM评估者（如Llama3-8B、Mistral-7B、Qwen2-7B）优于强大的LLM评估者（如Qwen2-72B），展示了其增强评估可靠性和提升模型性能的有效性。", "conclusion": "研究证明PGED在偏好评估中具有优越性，并通过实验验证了其有效性和可靠性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.08525", "html_url": "https://arxiv.org/abs/2406.08525", "title": "神经网络中正性条件的数学证明及其在部分单调性和可信AI中的应用", "title_en": "A mathematical certification for positivity conditions in Neural Networks with applications to partial monotonicity and Trustworthy AI", "authors": "Alejandro Polo-Molina,David Alfaya,Jose Portela", "background": "人工神经网络（ANNs）在建模大规模数据集中的复杂关系方面变得非常强大。然而，由于它们的黑盒性质，在某些情况下，确保预测的可信度需要遵循特定的部分单调性约束。但是，验证已经训练的ANN是否部分单调性是一个具有挑战性的问题。因此，在需要部分单调性的关键应用中，如信贷评分，ANN经常被忽视。文章介绍了一个新的算法（LipVor），该算法基于有限次数的评估，验证黑盒模型（例如ANN）是否为正。由于部分单调性可以表达为偏导数的正性条件，LipVor可以验证ANN是否部分单调。这一过程中，通过利用黑盒模型的Lipschitzian性，为每个正性评估点构造特定的邻域，使得函数保持正值。然后，基于评价点的Voronoi图，确立充分条件以验证函数在域内的正性。", "innovation": "LipVor算法能够在不依赖于受限架构或分段线性激活的情况下，通过有限次数的评估验证黑盒模型（例如ANN）是否为正，从而确定模型是否部分单调性。这一创新为在一些关键领域使用不受约束的ANN铺平了道路，并且LipVor的原理可以推广到验证其他ANN性质，如凸性。", "conclusion": "LipVor算法为神经网络中的正性条件提供了数学证明，并且这一技术的应用不仅局限于部分单调性，还可以扩展到信任AI的其他方面。这将开启在关键领域使用不受约束的ANN的可能性，从而提高AI模型的透明度和可信度。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.12652", "html_url": "https://arxiv.org/abs/2410.12652", "title": "Constrained Posterior Sampling: 时间序列生成带有硬约束", "title_en": "Constrained Posterior Sampling: Time Series Generation with Hard Constraints", "authors": "Sai Shankar Narasimhan,Shubhankar Agarwal,Litu Rout,Sanjay Shakkottai,Sandeep P. Chinchali", "background": "生成现实的时间序列样本对于压力测试模型和通过使用合成数据保护用户隐私至关重要。在工程和安全关键应用中，这些样本必须满足特定的硬约束，这些约束可能是特定领域的，或者是由物理学或自然条件自然施加的。例如，在生成电力需求模式时，需要满足尖峰需求时间的约束。这对于在恶劣天气条件下测试电力网络的运行功能是重要的。现有的用于生成带有约束的时间序列的方法要么不可扩展，要么会降低样本质量。", "innovation": "本文介绍了一种基于扩散的采样算法——受限后验采样(CPS)，该算法在每次去噪更新后将后验均值估计投影到约束集中。CPS能够处理大量的约束(≈100个)，而无需额外的训练。我们提供了理论依据，这突显了投影步骤对采样的影响。实验证明，相比于现有最先进的方法，CPS在样本质量上提高了约70%，在网络股票、交通和空气质量等真实世界数据集上的相似度提高了约22%。", "conclusion": "CPS算法有效地解决了现有方法在处理硬约束时间序列生成时的可扩展性和样本质量问题。通过投影步骤，该算法能够生成高质量且符合特定约束的时间序列样本，提高了压力测试的有效性和数据保护的实现。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.04380", "html_url": "https://arxiv.org/abs/2502.04380", "title": "多样性的奖励：在未定域数据混合中微调LLMs", "title_en": "Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data", "authors": "Zhenqing Ling,Daoyuan Chen,Liuyi Yao,Qianli Shen,Yaliang Li,Ying Shen", "background": "使用多样化数据集微调大型语言模型（LLMs）对于提升其在不同领域中的整体性能至关重要。现有的方法通常难以处理缺少、不精确或非标准化领域标签的数据，基于数据选择的方法则在多域性能平衡上遇到困难。", "innovation": "该研究提出了一个新的方法，为LLM赋予双重身份：输出模型用于基于多样性的奖励来认知地探索和选择数据，输入模型则用选定的数据进行调整。实验表明，该方法显著提升了在未定域数据和一系列基础下游任务中的性能。", "conclusion": "这项研究通过推出基于多样性的新方法，提高了未定域数据及多种先进LLMs下的一系列基础下游任务的性能，并希望这一研究能推动对多样性的理解，促进反馈驱动的数据-模型协同设计。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.14879", "html_url": "https://arxiv.org/abs/2410.14879", "title": "Vital Insight：使用可视化和人类在环LLM辅助多模态个人跟踪数据的上下文驱动推理", "title_en": "Vital Insight: Assisting Experts' Context-Driven Sensemaking of Multi-modal Personal Tracking Data Using Visualization and Human-In-The-Loop LLM", "authors": "Jiachen Li,Xiwen Li,Justin Steinberg,Akshat Choube,Bingsheng Yao,Xuhai Xu,Dakuo Wang,Elizabeth Mynatt,Varun Mishra", "background": "现代无处不在计算研究中，被动跟踪方法，如手机和穿戴设备感应，已经成为监测人类行为的主流手段。尽管机器学习方法在将原始传感器数据转换为模型瞬间行为方面取得了显著进展（例如，物理活动识别），但仍存在将这些传感流转换为有意义的、高层级的、情境感知的见解的缺口，这些见解对于各种应用（例如，总结个人的日常生活）是必要的。为了弥补这一差距，专家们通常需要在真实世界的研究中使用上下文驱动的感性理解过程来提取见解。这一过程通常需要大量的手动努力，并且即使是经验丰富的研究人员也往往难以应对人类行为的复杂性。", "innovation": "该研究提出了Vital Insight (VI)，一种以LLM为辅助的新型原型系统，旨在通过让人类参与感性理解循环和多模态智能手机和穿戴设备数据的可视化来助力上下文驱动的感性理解。通过将原型作为技术探针，作者观察了专家与该系统的交互，开发了一个专家感性理解模型，说明了专家如何在直接数据表示和AI支持的推理之间转换以探索、质疑和验证见解。作者通过迭代过程还总结并讨论了未来AI增强可视化系统的设计启发，以更好地支持专家在多模态健康感知数据中的感性理解过程。", "conclusion": "通过使用Vital Insight (VI)原型系统，作者提供了一种新的设计框架，该框架结合了可视化技术和人类在环的AI辅助推理，以支持专家对多模态个人跟踪数据的上下文驱动感性理解。这对于开发更有效的多模态健康传感数据中的AI辅助可视化系统具有重要意义。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.09969", "html_url": "https://arxiv.org/abs/2502.09969", "title": "可学习且可扩展的用于指令微调数据影响估计的神经网络", "title_en": "Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data", "authors": "Ishika Agarwal,Dilek Hakkani-Tür", "background": "现有影响函数方法在提供模型训练洞察方面至关重要，但存在高昂的计算成本和有限的泛化能力。特别是，最近的工作提出了一些用语言模型计算数据影响的方法，但这些方法不适用于大规模模型和数据集，存在计算成本昂贵、内存需求大和影响估计性能差的问题。因此，研究者们需要寻找一种成本更低且更高效的方法来估计影响值。", "innovation": "本研究探索了使用小型神经网络（称为InfluenceNetwork）来估计影响值，实现了高达99%的成本降低。只需全语言模型0.0027%大小的模型就能进行影响值估计。此外，研究者还应用了该算法（称为NN-CIFT）来下游任务中的子集选择，用于通用指令微调。结果显示，尽管NN-CIFT具有显著的速度提升，但性能并未受影响，同时提供了NN-CIFT的超参数分析。", "conclusion": "实验表明，使用小型神经网络估计的影响值表现出与传统方法相当的性能，但成本和计算时间大大降低。这种方法为大规模模型和数据集中的影响估计提供了一个新的高效解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.00333", "html_url": "https://arxiv.org/abs/2503.00333", "title": "更多的同质性：增加代表性的持续性表征危害", "title_en": "More of the Same: Persistent Representational Harms Under Increased Representation", "authors": "Jennifer Mickel,Maria De-Arteaga,Leqi Liu,Kevin Tian", "background": "论文背景在于识别和减轻生成式AI系统的危害时，必须考虑AI生成内容中谁被代表以及如何被代表。简单地改善代表对象并不意味着已经应用了缓解偏见的努力来解决代表方式的问题。通过研究最先进的大型语言模型中性别在职业中的表征，发现尽管存在增加女性代表性的干预，但代表偏见仍然存在，持续产生表征危害、刻板印象和新自由主义理想。", "innovation": "创新在于通过详细分析性别在职业中的表征变化，展示了尽管存在增加女性代表性的干预措施，代表性偏见仍然持续存在。这一研究通过统计显著词汇差异来检视不同性别之间的表征差异，并揭示了去除了显而易见性别偏见后，存在的隐藏性别隐喻和权力动态继续强化现有的压迫系统。", "conclusion": "结论指出，尽管存在增加女性代表性的干预措施，但代表性偏见仍然存在，造成表征危害、刻板印象和新自由主义理想继续蔓延。这意味着单纯增加代表性不足以解决偏见问题，需要更深入地分析并及时调整，以彻底消除隐藏在表征中的偏见和权力动态，从而真正减轻系统性的压迫和边缘化。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.02631", "html_url": "https://arxiv.org/abs/2503.02631", "title": "生成AI时代的从人-AI协作视角反思数据讲故事工具", "title_en": "Reflection on Data Storytelling Tools in the Generative AI Era from the Human-AI Collaboration Perspective", "authors": "Haotian Li,Yun Wang,Huamin Qu", "background": "人-AI协作工具吸引了数据讲故事社区的关注，以降低专业门槛并简化工作流程。近年来，大规模生成AI技术的进步，如大型语言模型（LLMs）和文本转图像模型，为数据讲故事提供了强大的视觉和叙述生成能力。自这些技术公开发布两年以来，反思其应用进展和未来机遇变得至关重要。为此，研究利用一个专门的框架来比对最新工具与早期工具在数据讲故事中的协作模式，以发现广泛研究以及新兴的协作模式，并揭示这些技术的益处及其对人-AI协作的影响。", "innovation": "本文通过一个专门的框架比较了最新工具与早期数据讲故事工具的协作模式，识别了常见的协作模式，如人创造者+AI助手机构，并提出了新的模式，如AI创造者+人类审阅者。此外，本文还探讨了AI技术对人-AI协作的影响，并提出了未来的研究方向以激发新的创新。", "conclusion": "通过对这些技术的研究和比较分析，本文揭示了人-AI协作的多种模式及其影响，并为未来的研究和发展提供了方向，旨在进一步促进人-AI协作的发展。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.05783", "html_url": "https://arxiv.org/abs/2501.05783", "title": "UV-Attack：通过基于动态NeRF的UV映射实现物理世界中的人员检测对抗攻击", "title_en": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping", "authors": "Yanjie Li,Kaisheng Liang,Bin Xiao", "background": "近年来，针对使用补丁或静态3D模型基团纹理修改的人体检测器的对抗攻击，由于人体运动的灵活性，成功率较低。3D变形建模在各种动作中造成了重大挑战。使用神经辐射场（NeRF）进行动态人体建模的进步为解决这些问题提供了新的可能性。In this paper, we introduce UV-Attack，一种在广泛的和未见过的人体动作下也能实现高成功率的开创性方法。这源于使用基于动态NeRF的UV映射来应对上述挑战。UV-Attack能够生成跨多种动作和视角的人类图像，并通过从SMPL参数空间中采样创造新的动作。然而，动态NeRF模型虽然能够建模人体，但对衣物纹理的修改仍然是挑战，因为它们嵌入在神经网络参数中。为了应对这一挑战，UV-Attack生成UV图而不是RGB图像，并修改纹理堆栈。此外，我们提出了一个新颖的期望值在姿态变换损失（EoPT），以提高在未见过的姿态和视角下的回避成功率。实验结果表明，UV-Attack实现了FastRCNN模型在动态视频设置中跨姿态高达92.7%的攻击成功率，远优于现有最强的AdvCamou攻击（仅28.5%的ASR），并在黑盒设置中实现了最新YOLOv8检测器的49.5%ASR。这项工作强调了基于动态NeRF的UV映射在生成更有效的人员检测器对抗攻击中的潜在价值，针对运动建模和纹理修改中的关键挑战。", "innovation": "提出了UV-Attack，一种基于动态NeRF的UV映射的对抗攻击方法。这一方法在广泛的和未见过的人体动作下也能实现高成功率，生成跨多种动作和视角的人类图像，并通过从SMPL参数空间中采样创造新的动作。此外，还提出了一种新颖的期望值在姿态变换损失（EoPT），以提高在未见过的姿态和视角下的回避成功率。这种方法可以实现实时纹理编辑，并使攻击更具实用性。", "conclusion": "实验结果表明，UV-Attack实现了FastRCNN模型在动态视频设置中跨姿态高达92.7%的攻击成功率，远优于现有最强的AdvCamou攻击，并在最新YOLOv8检测器的黑盒设置中实现了49.5%的ASR。这项工作强调了基于动态NeRF的UV映射在生成更有效的人员检测器对抗攻击中的潜力，通过解决运动建模和纹理修改中的关键挑战。提供的代码可以在this https URL找到。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.02878", "html_url": "https://arxiv.org/abs/2503.02878", "title": "语言模型可以在更好的搜索中自我改进以进行状态值估计", "title_en": "Language Models can Self-Improve at State-Value Estimation for Better Search", "authors": "Ethan Mendes,Alan Ritter", "background": "在多步骤推理任务中，收集准确的奖励或人类示范往往非常昂贵，特别是在诸如网络任务之类的交互式领域中。为了解决这个问题，这篇论文介绍了一种名为Self-Taught Lookahead (STL)的奖励无监督框架，该框架通过明示地考虑状态转换来提高基于语言模型的价值函数。", "innovation": "STL可以被视为价值迭代算法的一种链式思维的类比：它不直接回归到数值值，而是训练一个语言模型来模拟一步的前瞻性思考——预测下一个动作、最终状态和其价值的理由。这种自监督的过程可以提供更准确的状态-价值预测，从而在保持强性能的同时，使轻量级搜索算法能够扩展更少的状态。", "conclusion": "实验证明，基于中等大小（8B参数）的开放权重语言模型训练出的STL价值模型，可以将网络代理的成功率提高39%，并达到与专有模型相当的性能。STL还能够应用于多跳QA和数学难题。研究表明，STL使小型开源模型能够引导高效的搜索，通过集成显式推理与价值学习来降低推理成本。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.20138", "html_url": "https://arxiv.org/abs/2503.20138", "title": "基于中心化数据 refin 征 decentralized 模型的引导式模型合并方法：用于混合数据学习", "title_en": "Guided Model Merging for Hybrid Data Learning: Leveraging Centralized Data to Refine Decentralized Models", "authors": "Junyi Zhu,Ruicong Yao,Taha Ceritli,Savas Ozkan,Matthew B. Blaschko,Eunchung Noh,Jeongwon Min,Cho Jung Min,Mete Ozay", "background": "当前的网络训练范式主要集中在中央或去中心化数据制度上，但在实践中，数据可用性通常表现出混合性质，两者共存。去中心化数据丰富但存在异质性和通信限制，而中心化数据虽然数据量有限且可能代表性不足，但也便于管理并提供高吞吐量访问。虽然混合数据制度具有潜力，但有效结合这些范式仍然具有挑战性，且鲜有框架适用于混合数据制度。", "innovation": "提出了一种新颖的框架，从去中心化模型构造模型图集，并利用中心化数据在该结构化空间中精炼全局模型。通过结合联邦学习（利用去中心化数据）和模型合并（利用中心化数据），实现混合数据可用性的有效训练。理论证明，该方法因合并过程中的方差减少而比仅依赖去中心化数据的方法收敛更快。广泛的实验表明，该框架在所有纯中心化、纯去中心化及现有混合可适应方法中表现更优。此外，该方法即使在中心化和去中心化数据领域不同或去中心化数据包含噪声时也表现稳健，极大地拓宽了其适用范围。", "conclusion": "我们的方法能够有效结合联邦学习和模型合并，使得混合数据可用性的训练变得有效；通过理论分析证明了在合并过程中方差减少带来的更快收敛性；实验表明在混合数据框架下该方法优于其他方法。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09499", "html_url": "https://arxiv.org/abs/2503.09499", "title": "MindGYM：思考为中心的微调中问题合成的关键因素？", "title_en": "MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?", "authors": "Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen", "background": "大型基础模型在通过严格模板或众包标注指令数据集进行监督时，难以获得可转移且结构化的思考能力。现有的方法主要依赖于这些外部指令或模板，这限制了模型的自主思考和创新能力。而本研究旨在探索一种以思考为中心的数据生成范式，通过模型自我生成并受认知引导的数据进行进化，进而提升模型的思考能力。", "innovation": "提出了一个名为MindGYM的结构化且可扩展的问题生成框架，该框架包括三个关键组成部分：1）认知推理过程注入，为模型的合成行为注入高层次的推理目标；2）种子单跳问题生成，从各种语义类型中生成原子问题，以促进更广泛的思考；3）具有挑战性的多跳问答合成，基于问答种子生成更复杂的问题，以促进更深层次的推理能力。实验结果表明，通过该方法生成的数据质量平均提高了16.7%，质量波动降低了67.91%，证明了高质量且自包含的数据对于有效、思考导向的微调至关重要。MindGYM方法仅使用400个数据样本在MathVision基准测试上取得了高达16%的性能提升，并且具有跨不同模型大小和架构的一致改进效果。研究强调自我挑战机制在优化大型模型能力方面的可行性，同时减少对人类干预和资源的需求。", "conclusion": "MindGYM方法通过自我驱动的数据生成机制，提升了大型基础模型在思考导向的微调上的表现，展示了其在提高模型推理能力和可扩展性方面的潜力，并且为未来的数据驱动研究提供了支持。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01001", "html_url": "https://arxiv.org/abs/2504.01001", "title": "零样本基准测试：一种灵活且可扩展的语言模型自动评估框架", "title_en": "Zero-shot Benchmarking: A Framework for Flexible and Scalable Automatic Evaluation of Language Models", "authors": "José Pombal,Nuno M. Guerreiro,Ricardo Rei,André F. T. Martins", "background": "随着语言模型的发展，它们能够执行更复杂的跨模态任务，这使得自动评估变得越来越具有挑战性。开发强健且与任务特定的自动度量标准变得更为困难，而创建高质量的人标注测试集成本高且易饱和。已有尝试要么依赖于现有数据，要么仅专注于个别任务。因此，迫切需要一种可靠的方法来自动创建测试数据和评估机制。", "innovation": "本文提出了零样本基准测试（ZSB）框架，用于通过利用语言模型生成合成测试数据并对模型进行评估，为任何任务创建高质量的基准测试。ZSB框架简单且灵活，仅需为数据生成和评估创建提示；该框架适用于成本高或不实际收集真实世界数据的任务和语言，且不受具体模型限制。通过对比开放模型和各种系统的评估结果，找到强大基准可以通过开放式模型创建，并确定评价模型大小和数据集多样性是影响表现的关键因素。", "conclusion": "通过ZSB，研究者创建了五个纯文本任务和一个多模态任务的基准测试基准，包括通用能力、翻译和综合视觉语言能力。ZSB的评估结果高度符合人类评估，相比之下，常用的标准基准表现较差。研究结果表明，可以使用开放式模型创建强大的基准，且评价模型大小和数据集多样性对表现至关重要。研究者还发布了所有基准和可复现实验的代码。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10603", "html_url": "https://arxiv.org/abs/2505.10603", "title": "向公共和安全的生成人工智能迈进：开源和闭源大语言模型的比较分析", "title_en": "Toward a Public and Secure Generative AI: A Comparative Analysis of Open and Closed LLMs", "authors": "Jorge Machado", "background": "生成人工智能（Gen AI）系统在社会多个领域中具有深远的影响，但也伴随着一系列风险和挑战。目前尚未进行全面的跨学科研究来系统比较开源和闭源生成人工智能系统的优缺点。", "innovation": "本研究采用了文献综述、批判性分析和比较分析三种方法相结合的方法，旨在评估和比较开源和闭源生成人工智能模型的特点、机遇和挑战，并提出一个开放、公共治理和安全的Gen AI框架的基础要素。", "conclusion": "研究表明，开源模型提供了更高的透明度、可审计性和灵活性，使独立审查和偏见缓解成为可能。相比之下，闭源系统虽然在技术支持和实施便利性方面表现更好，但会导致访问不平等、问责性和伦理监督不足的问题。研究还强调了多利益相关者治理、环境可持续性和监管框架的重要性，以确保负责任的发展。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00254", "html_url": "https://arxiv.org/abs/2505.00254", "title": "使用视频语言模型赋能代理型视频分析系统", "title_en": "Empowering Agentic Video Analytics Systems with Video Language Models", "authors": "Yuxuan Yan,Shiqi Jiang,Ting Cao,Yifan Yang,Qianqian Yang,Yuanchao Shu,Yuqing Yang,Lili Qiu", "background": "AI驱动的视频分析在多个领域变得越来越重要。然而，现有的系统通常局限于特定、预定义的任务，限制了它们在开放性分析场景中的适应性。最近，视觉语言模型（VLMs）的出现为开放性视频理解、推理和分析带来了潜力。但是，它们在处理现实中常见的长视频内容时，由于有限的上下文窗口，面临挑战。", "innovation": "论文提出了一种名为AVA的VLM驱动系统，用于开放性高级视频分析。AVA包含两项创新：(1) 实时构建事件知识图谱（EKGs）以高效索引长或连续视频流；(2) 利用EKGs进行代理检索-生成机制，以应对复杂和多样的查询。", "conclusion": "AVA在公共基准LVBench和VideoMME-Long上的全面评估表现出领先性能，分别达到了62.3%和64.1%的准确性，显著超越现有VLM和视频检索增强生成（RAG）系统。此外，为了评估长视频和开放世界视频分析，提出了一个新的基准AVA-100，包括8个超过10小时的视频，共计120个手工标注、多样和复杂的问答对。在AVA-100上的性能达到75.8%。AVA的源代码和AVA-100基准均可通过提供的链接访问。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04953", "html_url": "https://arxiv.org/abs/2504.04953", "title": "M-Prometheus：一套开源多语言LLM评判工具", "title_en": "M-Prometheus: A Suite of Open Multilingual LLM Judges", "authors": "José Pombal,Dongkeun Yoon,Patrick Fernandes,Ian Wu,Seungone Kim,Ricardo Rei,Graham Neubig,André F. T. Martins", "background": "目前，利用语言模型自动评估长文本（LLM-as-a-judge）的方法越来越普遍，但大多数LLM评判工具仅针对英语进行优化，而提升它们对多语言评估能力的策略尚未在现有文献中得到充分探索。这导致了多语言评估方法在非英语语言质量上的差异，阻碍了多语言能力更强的模型的发展。", "innovation": "本文介绍了一套名为M-Prometheus的开源多语言LLM评判工具，该工具包括从3亿到14亿参数的多种模型，能够提供直接评估和成对比较反馈。M-Prometheus模型在超过20种语言的多语言奖励基准测试和4种语言对的文学机器翻译评估中均表现出色。此外，M-Prometheus模型在解码时可显著提高所有3种测试语言的生成输出，展示了其在开发更好的多语言模型中的应用价值。从而，我们通过广泛的消融实验确定了获得有效多语言评判的关键因素，包括主干模型的选择以及在合成多语言反馈数据而非翻译数据上进行训练。我们提供了模型、训练数据集和代码的公开发布版本以供参考和使用。", "conclusion": "M-Prometheus多语言LLM评判工具在多语言评估标准和文学机器翻译评估中表现出色，能够显著提升生成输出的质量，并通过消融实验识别了关键因素，这对于开发更好的多语言模型具有重要意义。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12275", "html_url": "https://arxiv.org/abs/2505.12275", "title": " Curricula Abductive Learning ", "title_en": "Curriculum Abductive Learning", "authors": "Wen-Chao Hu,Qi-Jie Li,Lin-Han Jia,Cunjing Ge,Yu-Feng Li,Yuan Jiang,Zhi-Hua Zhou", "background": "Abductive Learning (ABL) 结合了机器学习与逻辑推理，形成了一个闭环过程：首先模型从原始输入中预测符号概念标签，然后通过使用领域知识的 abduction 对其进行修订，最后将修订后的结果反馈用于重新训练。然而，由于 abduction 的非确定性，这种训练过程往往不稳定，特别是在知识库大而复杂的情况下，导致 abduction 空间过大致使问题难以解决。尽管先前的工作集中在改进该空间内的候选选择，但它们通常将知识库视为静态的黑盒处理。", "innovation": "本文提出了一种方法 Curriculum Abductive Learning (C-ABL)，其特点是明确利用知识库的内部结构来应对 ABL 训练挑战。C-ABL 将知识库划分成逐级引入的子知识库序列，并在训练过程中逐步扩大。这在整个训练过程中减少了 abduction 空间，逐步并平滑地让模型引入逻辑。结果在多个任务中证明，C-ABL 较以往的 ABL 实现表现更好，在复杂知识环境下尤其显著地提高了训练稳定性、收敛速度和最终准确性。", "conclusion": "C-ABL 这种方法通过逐步引入子知识库，成功解决了 ABL 训练过程中的稳定性问题，特别是在复杂知识环境下取得了更好的训练效果，表明了该方法的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12191", "html_url": "https://arxiv.org/abs/2505.12191", "title": "去除去噪器：数据课程中有意识的噪声在自监督学习中产生健壮性", "title_en": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum", "authors": "Wenquan Lu,Jiaqi Zhang,Hugues Van Assel,Randall Balestriero", "background": "自监督学习（SSL）已成为从未标记数据中提取丰富表示的强大解决方案。然而，SSL 研究主要集中在干净、精心筛选和高质量的数据集上。因此，将 SSL 应用于嘈杂数据仍然是一个挑战，尽管在天文学、医学成像、地球物理或金融等领域至关重要。", "innovation": "本文提出了一种完全自监督框架，能够在不需要在推理或下游微调时使用去噪器的情况下实现抗噪表示学习。该方法首先在嘈杂数据上训练一个 SSL 去噪器，然后用它构建一个去噪至嘈杂的数据课程（即，先训练去噪数据，再训练嘈杂样本）来预训练 SSL 主干（如 DINOv2），结合一种教师导向的正则化，将噪声嵌入锚定到其去噪对应物上。这一过程鼓励模型 internalize 噪声稳健性。值得注意的是，去噪器可以在预训练后被丢弃，简化部署。", "conclusion": "在 ImageNet-1k 上使用 ViT-B 在极端高斯噪声（σ=255，SNR=0.72 dB）下，我们的方法在线性探查精度上比 DINOv2 提高了 4.8%，证明了去噪器无碍的稳健性可以从有意识噪声预训练中出现。代码在此处获取：[链接]。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13308", "html_url": "https://arxiv.org/abs/2505.13308", "title": "在暗中寻找：基于潜在空间测试时实例级策略梯度的推理", "title_en": "Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space", "authors": "Hengli Li,Chenxi Li,Tong Wu,Xuekai Zhu,Yuxuan Wang,Zhaoxin Yu,Eric Hanchen Jiang,Song-Chun Zhu,Zixia Jia,Ying Nian Wu,Zilong Zheng", "background": "人类智能的核心组成部分——推理能力，仍然是大型语言模型（LLMs）在追求AGI过程中的一个重大挑战。尽管在训练规模化的背景下模型性能有所提升，但在训练算法（例如灾难性遗忘）及新型训练数据的有限可用性方面仍然存在重大挑战。当前方法主要针对token空间进行优化，而本研究提出了一种新的方法，通过利用潜在空间进行推理，以增强测试时推理性能。", "innovation": "本文提出了LatentSeek框架，这是一种基于潜在空间的测试时实例级适应（TTIA）的新颖方法。LatentSeek利用策略梯度迭代更新潜在表征，并通过自我生成的奖励信号进行引导。相比于之前主要集中在token空间的方法，LatentSeek尝试通过潜在空间来更有效地进行推理，并更好地遵循测试时规模化的法则。", "conclusion": "LatentSeek在多种推理基准测试中表现良好，优于其他基线方法，如思维链提示和基于微调的方法。研究结果显示LatentSeek在复杂度适中的问题上通常在几个迭代内就能达到收敛，并且额外的迭代可以带来性能提升，从而表明了潜在空间中测试时扩增的潜力。这使LatentSeek成为增强LLMs推理能力的轻量级、可扩展和有效解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15095", "html_url": "https://arxiv.org/abs/2505.15095", "title": "Nek Minit: 智能推理促进澳大利亚和印度英语的可解释表情讽刺检测", "title_en": "Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English", "authors": "Ishmanbir Singh,Dipankar Srirag,Aditya Joshi", "background": "讽刺是情感分析的挑战之一，因为它涉及表面和隐含情感之间的不一致。当这种隐含意义与特定国家或地理区域相关时，挑战更加严重。Pragmatic metacognitive prompting (PMP) 是一种基于认知的技术，用于逻辑推理。本文利用PMP进行澳大利亚和印度英语的可解释讽刺检测，同时使用了一个标准英语基准数据集FLUTE。", "innovation": "文章提出了利用PMP（Pragmatic Metacognitive Prompting）技术生成不同英语变体的讽刺解释，并通过两种公开的大型语言模型（GEMMA和LLAMA）进行评估，结果显示PMP在这个任务中的性能优于四种替代提示策略。此外，观察到其他技巧（如代理提示）可以缓解与上下文相关的问题，通过检索外部知识。文章的贡献在于利用PMP为不同类型的英语生成讽刺解释。", "conclusion": "评估结果显示，利用PMP的方法在所有任务和数据集上均实现了统计学上显著的性能提升。文章还发现，替代技术如代理提示可以通过检索外部知识来缓解与上下文相关的问题。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21996", "html_url": "https://arxiv.org/abs/2505.21996", "title": "学习用于互动视频生成的世界模型", "title_en": "Learning World Models for Interactive Video Generation", "authors": "Taiye Chen,Xun Hu,Zihan Ding,Chi Jin", "background": "现有的长期视频生成模型在世界建模能力上有限，主要由于累积误差和不足的记忆机制。有效的未来规划和行动选择需要互动的世界模型，同时保持时空一致性。", "innovation": "提出了一种增强的图像到视频模型，引入了互动功能和自回归框架，并提出了视频检索增强生成（VRAG）模型，通过显式全局状态条件减少长期累积误差，提高了世界模型的时空一致性。", "conclusion": "与窗口扩展的自回归生成和检索增强生成相比，当前视频生成模型的内在学习能力有限，表明内在世界建模能力对于提高视频生成模型至关重要，同时建立了一个全面的基准来改进具有内部世界建模能力的视频生成模型。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15201", "html_url": "https://arxiv.org/abs/2505.15201", "title": " Pass@K 政策优化：解决更难的强化学习问题", "title_en": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems", "authors": "Christian Walder,Deep Karkhanis", "background": "RL算法在每次问题解决尝试中会采样多个n>1个解决方案，并独立奖励它们，这有助于优化pass@1性能，但牺牲了样本集的多样性和整体效益。这种优化策略导致在探索和处理复杂任务的能力上有所局限。", "innovation": "提出了Pass@k Policy Optimization (PKPO) 方法，这是一种通过最终奖励转换直接优化pass@k性能的转变方式，从而优化能够联合最大化奖励的样本集。该方法将新的低方差无偏差估计器应用于pass@k及其梯度的计算，在二进制和连续奖励设置中都是新颖的。此外，该方法允许在训练过程中调试点数k，优化两个指标，通常在实现良好pass@1的同时也获得显著的pass@k提升。该研究是首次实现对任意k<=n的pass@k的鲁棒优化，并且在多个任务上验证了奖励转换的有效性。", "conclusion": "我们的方法有效解决了更难的RL问题，通过优先考虑联合效益而不是单个样本的效益，为更复杂的任务集提供了更好的探索。k值的调整使得学习过程不仅能够在pass@1上表现良好，还在pass@k上也取得显著进步，特别是在传统pass@1优化停滞的复杂任务集中，pass@k方法显著提升了学习能力。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13904", "html_url": "https://arxiv.org/abs/2505.13904", "title": "基于插入学习的构造型神经车辆路线求解器", "title_en": "Learning to Insert for Constructive Neural Vehicle Routing Solver", "authors": "Fu Luo,Xi Lin,Mengyuan Zhong,Fei Liu,Zhenkun Wang,Jianyong Sun,Qingfu Zhang", "background": "Neural Combinatorial Optimisation (NCO) 是一种无需大量手动设计的解决问题的有希望的学习方法，尤其适用于解决车辆路线问题（VRPs）。现有的通过逐步添加未访问节点的构造型 NCO 方法通常会导致次优结果。因此，本文探索了基于插入的方法，并提出了 L2C-Insert（基于插入的构建学习）方法，该方法通过在当前部分解决方案中的任意有效位置插入未访问节点来增强灵活性和解的质量，并在实验中展示了其优越性。", "innovation": "本文提出的 L2C-Insert 方法创新地引入了一种基于插入的方法，通过在当前部分解决方案中的任意有效位置插入未访问节点来构建解决方案。这一方法包含三个关键组件：一种新颖的插入位置预测模型架构、一种高效的模型优化训练方法以及一种充分利用插入方法灵活性的高级推理技术。相比传统的基于添加的方法，L2C-Insert 提升了灵活性和解决方案质量。", "conclusion": "通过在合成和实际世界的旅行商问题（TSP）和有载车辆路由问题（CVRP）实例上进行的广泛实验，L2C-Insert 全面展示了在各种问题大小下的一致性优越性能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14604", "html_url": "https://arxiv.org/abs/2505.14604", "title": "让LRMs通过自我刹车调节摆脱过度思考", "title_en": "Let LRMs Break Free from Overthinking via Self-Braking Tuning", "authors": "Haoran Zhao,Yuchen Yan,Yongliang Shen,Haolei Xu,Wenqi Zhang,Kaitao Song,Jian Shao,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "大型推理模型（LRMs）如OpenAI的o1和DeepSeek的R1通过生成更长的推理链路显著提升了其推理能力，并在多个任务上表现出色。然而，这种性能提升是以大幅提升推理过程中的冗余推理为代价的，导致计算开销增加，过度思考的问题也随之加剧。尽管已有多数方法尝试解决过度思考问题，但这些方法通常需要外部干预手段。", "innovation": "本文提出了一种新颖的框架，自我刹车调节（SBT），其旨在从模型自我调节其推理过程的角度出发，有效地解决过度思考的问题，从而消除对外部控制手段的依赖。通过设计一套基于标准答案的过度思考识别指标并提出系统的方法来检测冗余推理，SBT能够准确识别推理轨迹中的不必要的步骤，并生成训练信号以促使模型学习自我调节行为。此外，SBT还开发了一种自适应推理长度的数据构建策略，引入了一种创新的刹车提示机制，使模型能够自然地学会在恰当的时刻停止推理。实验结果表明，该方法在数学基准测试（AIME, AMC, MATH500, GSM8K）中减少了高达60%的标记消耗，并保持与非限制模型相当的准确度。", "conclusion": "本文提出了一种创新的框架——自我刹车调节（SBT），通过模型自我调节其推理过程来解决过度思考的问题，从而减少了冗余推理和计算开销，同时保持了较高的准确度。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18766", "html_url": "https://arxiv.org/abs/2505.18766", "title": "StyleGuard：通过风格扰动防止基于文本至图像模型的风格模仿攻击", "title_en": "StyleGuard: Preventing Text-to-Image-Model-based Style Mimicry Attacks by Style Perturbations", "authors": "Yanjie Li,Wenxuan Zhang,Xinqi Lyu,Yihao Liu,Bin Xiao", "background": "近年来，通过DreamBooth和Textual Inversion等方法使用的文本转图像扩散模型在风格模仿和个人化定制方面得到了广泛的应用。然而，这也引发了知识产权保护和生成虚假内容的问题。为了应对这些问题，Glaze和Anti-DreamBooth等研究提出了使用对抗噪声的方法来保护图像，但现代去噪方法如DiffPure和Noise Upscaling能够成功对抗这些最新防御措施，揭示了这些方法的漏洞。此外，现存方法在跨模型的移植性方面表现出有限的能力，使其在面对未知的文本转图像模型时效果不佳。", "innovation": "我们提出了一个新颖的防模仿方法，StyleGuard。我们提出了一种新的风格损失，通过优化潜在空间中的风格相关特征来使其偏离原始图像，从而提高模型无关的移植性。此外，为了增强扰动绕过基于扩散的去噪的能力，我们在训练过程中引入了一种新的放大型损失，涉及集合型去噪器和放大器的集成。实验表明，StyleGuard在多种变换和净化下的鲁棒性优于现有方法，有效对抗各种模型中的风格模仿。", "conclusion": "通过在WikiArt和CelebA数据集上的广泛实验，StyleGuard在多种转换和净化下的鲁棒性均优于现有方法，有效地对抗了各种风格模仿方法，包括DreamBooth和Textual Inversion。源代码可以在这个链接中找到: this https URL."}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00871", "html_url": "https://arxiv.org/abs/2506.00871", "title": "在上下文中预测任意人类轨迹", "title_en": "Towards Predicting Any Human Trajectory In Context", "authors": "Ryo Fujii,Hideo Saito,Ryo Hachiuma", "background": "预测行人准确的未来轨迹对于自主系统至关重要，但因需要在不同环境和领域中具有适应性，仍然是一项具有挑战性的任务。现阶段的常见做法是收集特定场景的数据并通过反向传播进行微调，但在边缘设备上为每个新场景进行微调往往是不切实际的。", "innovation": "本文提出了一种名为TrajICL的上下文学习框架，用于行人轨迹预测，避免了在推理时对特定场景数据进行微调和权重更新。通过基于时空相似性的示例选择方法（STES）和基于预测的示例选择方法（PG-ES），该框架能够选择相似的运动模式满足长期动态需求。同时，本文还采用大规模合成数据集训练模型，提升了在不同场景下的预测能力。", "conclusion": "通过广泛的实验表明，TrajICL在同源和跨域场景中均能实现卓越的适应性，表现甚至超越了微调的方法，在多个公开基准测试中取得了出色的性能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01369", "html_url": "https://arxiv.org/abs/2506.01369", "title": "激励LLMs自我验证其答案", "title_en": "Incentivizing LLMs to Self-Verify Their Answers", "authors": "Fuxiang Zhang,Jiacheng Xu,Chaojie Wang,Ce Cui,Yang Liu,Bo An", "background": "大型语言模型（LLMs）在复杂推理任务中已经取得了显著进展，主要通过后训练和测试时的扩展法则实现。虽然现有的测试时扩展方法通常通过使用外部奖励模型来指导模型生成过程，研究发现，在特定推理任务后训练的模型上进行后训练扩展所能获得的增强效果仅微乎其微。原因在于特定后训练生成器和通用奖励模型之间的分布差异造成了这种局限性。", "innovation": "本文提出了一种框架，旨在激励LLMs自我验证其答案。该框架将答案生成和验证统一在单一的强化学习（RL）过程中进行训练，能够有效评估模型生成答案的正确性。该训练的模型在推理时可以通过自我验证进一步提高其性能，无需外部验证者。研究人员基于Qwen2.5-Math-7B和DeepSeek-R1-Distill-Qwen-1.5B对自我验证模型进行训练，并在多种数学推理基准测试中展示了其能力。实验结果表明，该模型不仅能够提升后训练性能，还能实现有效的测试时扩展。", "conclusion": "本文提出的方法和模型展示了在数学推理等复杂任务中，通过内置自我验证机制提高LLMs性能的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01158", "html_url": "https://arxiv.org/abs/2506.01158", "title": "基于回归的高效归一化流训练方法在玻尔兹曼发电机中的应用", "title_en": "Efficient Regression-Based Training of Normalizing Flows for Boltzmann Generators", "authors": "Danyal Rehman,Oscar Davis,Jiarui Lu,Jian Tang,Michael Bronstein,Yoshua Bengio,Alexander Tong,Avishek Joey Bose", "background": "在连续空间中的生成模型革命中，无模拟训练框架一直是前沿技术，导致了大规模的扩散和流匹配模型的发展。然而，现代生成模型的推断成本昂贵，阻碍了它们在很多科学应用中的使用，比如需要快速似然估计的分子构象玻尔兹曼生成器（BGs）。经典的归一化流在BGs背景下提供了高效的采样和似然性，但通过最大似然法训练通常不稳定且计算困境重重。", "innovation": "本文提出了回归训练归一化流（RegFlow），这是一种新颖且可扩展的基于回归的训练目标，取代了传统最大似然训练中的数值不稳定性及计算挑战，采用的是简单的$\boldsymbol{\boldsymbol{L}}_2$回归目标。RegFlow通过我们的流将先验样本映射为目标，这些目标由最优传输耦合或预训练的连续归一化流（CNF）计算得到。此外，RegFlow通过使用新的前向-后向自一致性损失等有效的正则化策略来增强数值稳定性。", "conclusion": "实验结果显示，RegFlow解锁了以前难以通过最大似然法训练的BGs架构。同时，RegFlow在α-丙氨酸二肽、三肽和四肽的笛卡尔坐标平衡采样中超过了最大似然训练的性能、计算成本和稳定性，展示了其在分子系统中的潜在价值。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13464", "html_url": "https://arxiv.org/abs/2506.13464", "title": "揭开语言模型学习思维的面纱：一种认知框架与实证研究", "title_en": "Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study", "authors": "Zhengyu Hu,Jianxun Lian,Zheyuan Xiao,Seraphina Zhang,Tianfu Wang,Nicholas Jing Yuan,Xing Xie,Hui Xiong", "background": "大语言模型（LLMs）在数学、编程和推理等多个任务上表现出令人印象深刻的性能，但在动态环境中适应和获取新知识的能力（即学习能力）方面却相对较少被探索。本研究旨在填补这一空白。", "innovation": "提出了一个受到认知心理学和教育领域启发的框架，将通用学习能力分解为三个互补的维度：从指导员学习（通过显性指导获取知识）、从概念学习（内化抽象结构并在新情境中概括）和从经验学习（通过积累的探索和反馈进行调整）。通过实证研究，发现了提高学习效率的多个见解，如交互式学习效果更好、概念理解对于大模型更具有规模效应，以及LLMs擅长少量样本学习但不足于大量样本学习。", "conclusion": "基于所提出的框架和实证研究成果，提出了一项基准测试，旨在为LLMs提供统一且现实的学习能力评估，覆盖三个认知学习维度，从而为评估和开发更适应性和拟人化模型提供诊断性见解。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03237", "html_url": "https://arxiv.org/abs/2506.03237", "title": "UniSite：首个跨结构数据集及端到端配体结合位点检测学习框架", "title_en": "UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection", "authors": "Jigang Fan,Quanlin Wu,Shengjie Luo,Liwei Wang", "background": "蛋白质配体结合位点检测是基于结构的药物设计中的基础步骤。尽管近年来取得了显著进展，但现有的方法、数据集和评估标准仍然面临几个关键挑战：（1）当前数据集和方法主要集中在单个蛋白质配体复合物上，忽视了同一蛋白质的不同复合物可能存在的多种结合位点，引入了显著的统计偏差；（2）配体结合位点检测通常被建模为断续的工作流程，使用二元分割和后续聚类算法；（3）传统的评估指标未能充分反映不同类型配体结合位点预测方法的实际性能。", "innovation": "本文首先介绍了UniSite-DS，这是首款以UniProt为中心的配体结合位点数据集，相较于此前最广泛使用的数据集，包含4.81倍更多的多位点数据和2.08倍的整体数据。然后提出了一种端到端的配体结合位点检测框架UniSite，该框架由集合预测损失监督，并采用双射匹配。此外还引入了基于交集与并集比（IoU）的平均精确度作为更准确的评估指标。在UniSite-DS及几个代表性基准数据集上的广泛实验表明，基于IoU的平均精确度能够更准确地反映预测质量，且UniSite在配体结合位点检测方面优于当前最先进的方法。相关代码和数据集将会公开。", "conclusion": "本文提出的UniSite-DS数据集和UniSite框架显著改进了配体结合位点的检测，提供了更准确的评估指标，并在多项实验中表现优于现有方法。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20535", "html_url": "https://arxiv.org/abs/2506.20535", "title": "AIMeter:测量、分析和可视化AI工作负载的能源和碳足迹", "title_en": "AIMeter: Measuring, Analyzing, and Visualizing Energy and Carbon Footprint of AI Workloads", "authors": "Hongzhen Huang,Kunming Zhang,Hanlong Liao,Kui Wu,Guoming Tang", "background": "随着人工智能技术，特别是大型语言模型（LLMs）的快速发展，模型训练和推理过程中所消耗的能量和产生的碳排放引起了广泛关注。然而，现有的测量和报告此类影响的工具往往缺乏系统性，未能实现度量标准的整合，并提供了有限的支持来进行不同因素之间的关联分析。", "innovation": "本文介绍了AIMeter，这是一个全面的软件工具包，用于测量、分析和可视化AI工作负载的能源使用、功率消耗、硬件性能以及碳排放。AIMeter能够与现有的AI框架无缝集成，提供标准化报告，并导出细粒度的时间序列数据，以支持轻量级的基准测试和结果可重复性。此外，它还允许对硬件指标与模型性能之间进行深入的相关性分析，从而有助于识别瓶颈并提高性能。", "conclusion": "通过解决现有工具的关键局限性，AIMeter鼓励研究社区在评估人工智能工作负载的环境影响的同时，也考虑其原始性能，并推动向更可持续的“绿色AI”实践转变。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10173", "html_url": "https://arxiv.org/abs/2506.10173", "title": "SPARKE: 通过RKE得分实现扩散模型中可扩展的提示感知多样性和新颖性指导", "title_en": "SPARKE: Scalable Prompt-Aware Diversity and Novelty Guidance in Diffusion Models via RKE Score", "authors": "Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia", "background": "扩散模型在高保真图像合成和提示引导的生成模型方面表现出了显著的成功，但在提示引导的扩散模型生成样本的多样性方面，尤其是在提示覆盖广泛语义范围时，仍面临挑战。为确保生成数据的多样性，特别是跨语义相似提示时的提示感知多样性评估，最近的方法引入了多样性量度来鼓励更加多样化的生成。因此，本文在此基础上引入了可扩展的提示感知Rényi内核熵多样性指导（SPARKE）方法，该方法以条件熵为基础进行多样性指导，并根据相似提示动态调整多样性测量，实现提示感知的多样性控制。", "innovation": "本文的主要创新在于，提出了SPARKE方法，即可扩展的提示感知Rényi内核熵多样性指导方法。该方法通过条件熵进行多样性指导，动态适应相似提示，实现了提示感知的多样性控制。此外，该方法针对条件潜空间Rényi熵得分指导的特殊情况，降低了从一般熵度量的O(n^3)到O(n)的计算复杂性，使得在大规模生成场景中也能够通过多样性和新颖性的引导高效采样。", "conclusion": "通过数值试验，证明了SPARKE方法能够在不显著增加计算成本的情况下，提高生成数据的提示感知多样性。文中提供了实现代码，可在项目页面下载。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07127", "html_url": "https://arxiv.org/abs/2506.07127", "title": "通过行动偏好优化的人机辅助机器人策略精炼", "title_en": "Human-assisted Robotic Policy Refinement via Action Preference Optimization", "authors": "Wenke Xia,Yichu Yang,Hongtao Wu,Xiao Ma,Tao Kong,Di Hu", "background": "部署现实世界应用的可靠且迭代改进的机器人系统至关重要。视觉-语言-行动（VLA）模型因其对离线专家示范的依赖而被广泛认可为这类机器人部署的基石模型，但这种依赖大大限制了其在部署后的改进能力。直接利用交互轨迹进行偏好优化存在挑战，如不可逆的机器人动作和标记分布不匹配的问题。为解决上述问题，本文提出了行动偏好优化（APO）方法，该方法利用人机协作框架通过人工干预收集可靠失败修正和交互轨迹，提出了一个自适应重加权算法，以二进制偏好信号为基础，让VLA模型能有效抑制故障行为并促进纠正行为的适应。", "innovation": "本文提出的行动偏好优化（APO）方法，通过人机协作框架和自适应重加权算法，使得VLA模型能够在交互过程中学习并改进其行为偏好。这种通过人工干预收集可靠失败修正和交互轨迹的方法，有效解决了不可逆机器人动作和标记分布不匹配的问题，使VLA模型能够不断从失败中学习，适应动态环境，并确保其在各种操作任务中的高效性和鲁棒性。实验验证了该方法在模拟和真实场景中的优越通用性和鲁棒性，证明了人机辅助框架在VLA模型优化中的有效性。", "conclusion": "本文通过人机协作的人类辅助方式，引入了行动偏好优化（APO）方法，实现了视觉-语言-行动（VLA）模型在动态环境中的迭代改进和可靠部署，验证了该方法在多种操作任务中的有效性和鲁棒性，为视觉-语言-行动模型的有效稳定优化提供了新的视角。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06220", "html_url": "https://arxiv.org/abs/2506.06220", "title": "GenIR: 为心智图像检索生成视觉反馈", "title_en": "GenIR: Generative Visual Feedback for Mental Image Retrieval", "authors": "Diji Yang,Minghao Liu,Chung-Hsiang Lo,Yi Zhang,James Davis", "background": "视觉语言模型（VLMs）在文本到图像检索基准测试中表现出色，但在将其成功应用于实际场景时仍面临挑战。人类的搜索行为通常不是一个单一的动作，而是一个由内心线索引导的多轮过程。这个过程从模糊的记忆开始，逐渐形成对目标图像的清晰想象。受到这一缺口的启发，我们研究了心智图像检索（MIR）任务，该任务旨在在用户通过与图像搜索引擎的多轮交互来完善对内心所想图像的搜索时，解决一个实际但尚未充分探索的场景。多轮交互检索的关键在于机器能够提供清晰、可操作的反馈，而现有的方法往往依赖于间接或抽象的口头反馈，这可能导致用户的检索结果难以进一步精确。", "innovation": "我们提出了GenIR，一个利用基于扩散的图像生成来在每次交互中显式表述AI系统的理解的生成式多轮检索框架。这些合成的视觉表示提供了清晰、可解释的反馈，使用户能够直观有效地完善查询。我们还提出了一种完全自动化的流水线来生成高质量的多轮MIR数据集。实验结果表明，GenIR在MIR场景中显著优于现有的交互式方法。这项工作建立了新的任务，并提供了有效生成性检索方法的基础，为未来的研究奠定了基础。", "conclusion": "GenIR在MIR场景中取得了显著的性能，通过提供清晰的视觉反馈帮助用户完善查询，为未来的心智图像检索研究设立了新的标准和方法。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11094", "html_url": "https://arxiv.org/abs/2506.11094", "title": "正义之衡：大语言模型安全性评估综述", "title_en": "The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs", "authors": "Songyang Liu,Chaozhuo Li,Jiameng Qiu,Xi Zhang,Feiran Huang,Litian Zhang,Yiming Hei,Philip S. Yu", "background": "随着人工智能的快速发展，大语言模型（LLMs）在自然语言处理（NLP）领域展现了显著的能力，包括内容生成、人机交互、机器翻译和代码生成等。然而，它们的广泛应用也引发了重大的安全问题。特别是在对抗性环境中，LLMs生成的内容可能展现出毒性、偏见或虚假信息等不安全的行为，这引起了学术界和工业界的广泛关注。虽然已有许多研究试图评估这些风险，但关于LLMs安全评估的全面系统综述仍然缺乏。因此，该研究旨在通过提供LLMs安全性评估的结构性概述来填补这一空白，特别是从四个维度来探讨安全性评估的背景、评估内容、评估地点和评估方法等问题。", "innovation": "该工作提出了一种四维度分类法来系统地探讨大语言模型的安全性评估：（i）Why to evaluate，分析了评估背景，安全评估与一般LLM评估的区别以及评估的重要性；（ii）What to evaluate，基于关键能力对现有安全评估任务进行分类和归类，包括毒性、鲁棒性、伦理、公平性、事实性等内容领域；（iii）Where to evaluate，总结当前在安全性评估中使用的评价指标、数据集和基准；（iv）How to evaluate，对现有的主要评估方法进行回顾，包括评价者的角色和评估框架整合整个评估管道。此外，该研究还指出了大语言模型安全性评估的挑战，并提出了促进该领域进一步发展的研究方向。强调了优先进行安全性评估的重要性，以确保LLMs在实际应用中的可靠性和责任感。", "conclusion": "该研究确定了大语言模型安全性评估中面临的挑战，并提出了推进该领域进一步发展的研究方向，强调了优先进行安全性评估的重要性，以确保大语言模型在实际应用中的可靠性和责任感。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03704", "html_url": "https://arxiv.org/abs/2507.03704", "title": "Control 思考速度在推理模型中的控制", "title_en": "Controlling Thinking Speed in Reasoning Models", "authors": "Zhengkai Lin,Zhihang Fu,Ze Chen,Chao Chen,Liang Xie,Wenxiao Wang,Deng Cai,Zheng Wang,Jieping Ye", "background": "人类的认知过程理论分为两种模式：快速直觉的System 1思维和缓慢有条理的System 2思维。当前的大规模推理模型（LRMs）在处理System 2思维方面表现出色，但它们在处理快速思维过程中表现出的不足导致了较高的计算开销和延迟。", "innovation": "本工作通过动态调整LRMs的思考速度来实现人工智能的近似，优化准确性和效率之间的权衡。具体创新包括识别了控制LRMs中间表示空间中缓慢与快速思维转换的引导向量，实现了基于表示编辑的测试时缩放效果，优于现有的基于提示的缩放方法。另外还应用了实时难度估计来标记不同复杂度的推理段落，结合这些技术提出了一种新的推理策略，可以快速处理简单的步骤并深入分析复杂的推理。", "conclusion": "我们提出的插件模块在不进行训练或增加成本的情况下，能够在多个领先的LRMs和先进推理基准上提供平均1.3%的精度提升，同时降低8.6%的标记使用量。所有算法都是基于vLLM实现的，并且预期可以支持更广泛的应用并在未来的研究中提供启发。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.09846", "html_url": "https://arxiv.org/abs/2507.09846", "title": "无计划流经：理解无计划方法在语言模型训练中的优势", "title_en": "Through the River: Understanding the Benefit of Schedule-Free Methods for Language Model Training", "authors": "Minhak Song,Beomhan Baek,Kwangjun Ahn,Chulhee Yun", "background": "随着模型和数据规模的快速扩大，传统的固定计算预算的预训练策略，如余弦学习率调度，对于大规模训练越来越不足够。而最近的一些替代方法，如warmup-stable-decay (WSD) 方案和权重平均，虽然提供了更多的灵活性，但是WSD依赖于明确定义的衰减阶段，而权重平均则解决了这一点但需要额外的内存。", "innovation": "本文重新审视了Schedule-Free (SF) 方法，这是一种在各种设置中表现出强大经验性能的方法。通过理论和经验分析，作者发现SF方法实际上在不需要衰减阶段和额外存储的情况下，隐式地执行权重平均。基于这一发现，作者提出了一种改进版本的SF方法，该方法在动量的鲁棒性和大规模批次处理下的性能方面有所改进，解决了原有方法的关键局限性。", "conclusion": "结合这些结果，本文建立了SF作为一种实用、可扩展且具有理论依据的方法来训练语言模型。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01083", "html_url": "https://arxiv.org/abs/2509.01083", "title": "DSDE: 基于 KL 散度稳定性进行动态推测解码的实时服务", "title_en": "DSDE: Dynamic Speculative Decoding with KLD Stability for Real-World Serving", "authors": "Mingyu Yang,Jae-Young Choi,Kihyo Moon,Minsung Jang,Eunjoo Jeon", "background": "推测性解码可以加速大型语言模型的推理，但在大规模批处理环境中处理多样性的请求时，其依赖于固定的推测长度是个劣势。本文探讨了动态适应的新方向，通过研究一个新的后处理诊断信号类来探索这一路径。这些信号基于 Kullback-Leibler (KLD) 散度的方差，以诊断生成的区域稳定性，同时引入了自适应推测长度上限来缓解序列解码中的拖尾问题。", "innovation": "本文提出了一种名为 Dynamic Speculative Decoding Engine (DSDE) 的训练无需框架，该框架由两个主要部分组成：基于 KLD 散度方差的预测信号，用于诊断生成的区域稳定性；以及一种自适应推测长度上限，以缓解序列解码中的拖尾问题。这些信号能够驱动算法，实现与领先基准相竞争的端到端延迟，并展现出在多样工作负载下更优秀的鲁棒性，特别在低接受率环境中保持其诊断效用。", "conclusion": "这些发现证明了后处理信号是构建更稳健和智能的大型语言模型推理系统的重要组成部分，并指明了未来研究动态推测长度适应的一个有希望的方向。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13328", "html_url": "https://arxiv.org/abs/2507.13328", "title": "视力-语言训练有助于部署分类知识但并不会从根本上改变它", "title_en": "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It", "authors": "Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim", "background": "现有文献中的大多数结果表明，视力-语言（VL）训练对语言模型的语义表征影响不大，仅在行为层面和表示层面表现出不一致或边际差异。研究人员认为，VL训练可能在词汇-概念知识的分类组织方面显示出显著的效果。通过对比仅基于文本的语言模型（LMs）及其VL训练版本，发现VL模型在需要概念分类理解的问题回答任务上往往优于仅基于文本的语言模型。然而，这些语言模型和VL模型在概念分类知识本身上没有显著差异，但在处理包含分类关系的概念和非分类关系的概念的问题时，其表现不同。这表明通过额外的VL训练，分类知识并没有发生显著变化，但是VL训练提高了在这种特定任务中的知识部署效果，即使任务的呈现方式完全是语言性的。", "innovation": "本文提出了一项假设：即VL训练可能对词汇-概念知识的分类组织产生显著影响。研究通过对比仅基于文本模型与VL训练模型在问题回答任务中的表现，发现虽然二者的分类知识本身没有显著差异，但在处理不同结构的问题时表现却有显著差异。这揭示了VL训练对任务相关知识的部署有提升作用，但不会从根本上改变分类知识本身。", "conclusion": "VL训练能够帮助语言模型更有效地利用分类知识，但在分类知识本身上没有起到根本性的改变作用。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07981", "html_url": "https://arxiv.org/abs/2508.07981", "title": "全效合一：统一且空间可控的视觉效果生成", "title_en": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation", "authors": "Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu", "background": "视觉特效（VFX）对于现代电影制作至关重要。尽管视频生成模型为VFX生产提供了一种经济高效的解决方案，但现有方法受限于需要为每个特效进行LoRA训练，从而限制了多特效的同时生成能力和空间上的可控性。因此，当需要调控多个特效在指定位置同时生成时，这种方法就显得不足了。", "innovation": "本文提出了Omni-Effects，一种统一的框架，能够生成受提示引导的特效和空间可控的复合特效。该框架核心包含两个创新点：1) LoRA基混合专家模型（LoRA-MoE），使用一组专家LoRA，使多种特效能够在统一模型中融合，同时有效减少了跨任务干扰；2) 空间感知提示（SAP），将空间蒙版信息集成到文本标记中，实现精确的空间控制，并引入独立信息流（IIF）模块，隔离每个特效的控制信号，防止非预期的混合。", "conclusion": "通过广泛实验表明，Omni-Effects能够实现精确的空间控制和多样特效生成，用户可以指定所需特效的类别和位置。为了推动这一研究，作者通过一个新的数据收集管道构建了一个全面的VFX数据集Omni-VFX，并引入了一个专门的VFX评估框架来验证模型性能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17197", "html_url": "https://arxiv.org/abs/2509.17197", "title": "SignalLLM: 一种用于自动化信号处理的通用目的LLM代理框架", "title_en": "SignalLLM: A General-Purpose LLM Agent Framework for Automated Signal Processing", "authors": "Junlong Ke,Qiying Hu,Shenghai Yuan,Yuecong Xu,Jianfei Yang", "background": "现代信号处理（SP）管道，无论是基于模型还是数据驱动，经常受到复杂且碎片化的工作流程的限制，依赖于专家知识和手动工程，适应性和在数据有限下的泛化能力较弱。相比之下，大型语言模型（LLMs）提供了强烈的推理能力、广泛的通用知识、上下文内学习以及跨模态迁移能力，使其成为自动化和泛化信号处理工作流的强大工具。", "innovation": "我们提出了SignalLLM，这是一种基于LLM的一般目的代理框架，专门用于通用SP任务。它具有模块化的架构，能够通过上下文内学习和领域特定检索将高层次的SP目标分解为结构化的子任务，然后通过适应性检索增强生成（RAG）和精炼进行分层规划；这些子任务通过基于提示的推理、跨模态推理、代码合成、模型调用或数据驱动的LLM辅助建模执行。该框架的设计使其能够灵活地在不同信号模态、任务类型和数据条件下选择解决问题的策略。", "conclusion": "通过五个代表性的通信和感知任务（如雷达目标检测、人体活动识别、文本压缩）展示了SignalLLM的多样性和有效性。实验结果表明，它在传统的和现有的LLM方法，特别是在少量样本和零样本设置中，表现出优越的性能。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.06159", "html_url": "https://arxiv.org/abs/2509.06159", "title": "FASL-Seg：外科场景中解剖结构和工具的分割", "title_en": "FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes", "authors": "Muraam Abdel-Ghani,Mahmoud Ali,Mohamed Ali,Fatmaelzahraa Ahmed,Muhammad Arsalan,Abdulaziz Al-Ali,Shidin Balakrishnan", "background": "随着机器人微创手术的普及，基于深度学习的外科手术培训成为研究的关键领域。通过语义分割模型来深入理解手术场景的组件变得至关重要。然而，现有的大多数研究仅关注手术工具，而忽视了解剖对象。同时，当前最先进的模型在捕捉高层上下文特征和低层边缘特征方面难以兼顾。", "innovation": "本文提出了一个特征自适应空间定位模型（FASL-Seg），该模型通过两个不同的处理流：低级特征投影（LLFP）和高级特征投影（HLFP），以不同分辨率捕捉多级特征，从而实现解剖结构和手术器械的精确分割。", "conclusion": "本文评估了FASL-Seg模型在Surgical Segmentation基准数据集EndoVis18和EndoVis17上的三种实际应用案例，该模型在EndoVis18的部分和解剖结构分割任务中实现了72.71%的平均交并比（mIoU），比SOTA提高了5%。此外，在EndoVis18和EndoVis17的工具类型分割任务中，FASL-Seg分别取得了85.61%和72.78%的mIoU，总体性能优于SOTA，在两个数据集中的每个类别中取得了可比的SOTA结果，并且在不同类别的解剖结构和器械方面表现出一致的性能，证明了不同分辨率特征处理流的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17784", "html_url": "https://arxiv.org/abs/2509.17784", "title": "使用大型语言模型揭示多模态因果关系", "title_en": "Revealing Multimodal Causality with Large Language Models", "authors": "Jin Li,Shoujin Wang,Qi Zhang,Feng Liu,Tongliang Liu,Longbing Cao,Shui Yu,Fang Chen", "background": "从数据中揭示因果机制是科学研究的基础。尽管大型语言模型（LLMs）在增强从非结构化数据中进行因果发现（CD）方面显示出潜力，但它们在日益普遍的多模态设置中的应用仍然是一个关键挑战。即使在多模态LLMs（MLLMs）出现的情况下，它们在多模态CD中的有效性也受到两个主要限制的影响：（1）在探索跨模态间交互以全面识别因果变量时存在困难；（2）纯粹基于观察的数据不足以处理结构上的模糊性。因此，在继续利用大型语言模型的同时，面对上述挑战，需要一种新的框架来改进从非结构化多模态数据中发现因果机制的方法。", "innovation": "本文提出了一种名为MLLM-CD的新框架，用于从非结构化多模态数据中进行因果发现。该框架包括三个关键组成部分：（1）一个新颖的对比因子发现模块，通过探索对比样本对之间的交互来识别真实的多模态因子；（2）一个统计因果结构发现模块，用来推断所发现因子之间的因果关系；（3）一个迭代多模态反事实推理模块，通过结合MLLMs的世界知识和推理能力，逐步优化发现结果。本框架旨在解决现存方法中的挑战并提高发现的准确性和可靠性。", "conclusion": "在合成数据集和真实世界数据集上的广泛实验表明，所提出的MLLM-CD框架在从非结构化多模态数据中揭示真实因子和它们之间的因果关系方面是有效的。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.24267", "html_url": "https://arxiv.org/abs/2509.24267", "title": "循环扩散模型用于反事实图像生成", "title_en": "Cycle Diffusion Model for Counterfactual Image Generation", "authors": "Fangrui Huang,Alan Wang,Binxu Li,Bailey Trang,Ridvan Yesiloglu,Tianyu Hua,Wei Peng,Ehsan Adeli", "background": "深度生成模型已经在医学图像合成方面取得了显著的成功，但确保合成图像的真实性以及直接或反事实生成时的条件一致性仍然是一个挑战。", "innovation": "本文介绍了一种循环训练框架来微调扩散模型，以改善生成图像的条件适配性和增强图像的真实性。循环扩散模型(CDM)通过引入循环约束，使得生成的图像与原始图像保持一致，从而提高直接和反事实生成的可靠性。", "conclusion": "实验结果显示，在综合3D脑MRI数据集（来自ABCD、HCP老化和年轻成人、ADNI和PPMI）上，该方法提高了生成的图像条件准确性和图像质量（通过FID和SSIM进行衡量）。结果表明，CDM中的循环策略是一种有效的辨别扩散基础的医学图像生成方法，具有在数据扩充、反事实和疾病进展建模方面的应用潜力。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23885", "html_url": "https://arxiv.org/abs/2509.23885", "title": "Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction", "title_en": "Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction", "authors": "Guoquan Wei,Liu Shi,Zekun Zhou,Wenzhe Shan,Qiegen Liu", "background": "当前基于深度学习的低剂量CT降噪模型依赖于配对数据，泛化能力较差。即使更关心的扩散模型也需要学习干净数据的分布来进行重建，这在医学临床应用中难以满足。自监督方法面临的挑战是预训练模型在剂量扩展时泛化能力显著下降。", "innovation": "本文提出了一种名为TUnable-geneRalizatioN Diffusion (TurnDiff)的方法，通过基于自监督的上下文子数据增强相似性策略，以及结合知识蒸馏和深层扩散模型优化图像细节，并提出像素级自我校正融合技术进行精细重建。此方法可以在上下剂量或未见过的剂量的泛化中灵活应用，并通过双重领域级联策略实现自监督低剂量CT降噪，仅需低剂量CT投影领域数据进行训练和测试，实验证明TurnDiff在重建和泛化方面均优于现有方法。", "conclusion": "全面的评估显示，TurnDiff在基准数据集和真实世界数据上的一致优于最先进的方法，在重建和泛化能力上均有显著提高。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19331", "html_url": "https://arxiv.org/abs/2509.19331", "title": "Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention", "title_en": "Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention", "authors": "Enhao Huang,Zhiyu Zhang,Tianxiang Xu,Chunshu Xia,Kaichun Hu,Yuchen Yang,Tongtong Pan,Dong Dong,Zhan Qin", "background": "当前大多数深度模型在处理注意力时仍以实数相关性为核心，忽视了相位干涉效果。这限制了这些模型在处理复杂值信号（同时包含振幅和相位信息）时的功能和表现。现有的方法通常将振幅和相位分离处理，导致在损失函数重振幅轻相位的场景下发生相位崩溃。", "innovation": "本文提出了一种灵感来源于物理的‘全息转换器’架构。该模型结合了波干涉原理到自我注意力中，通过相对相位进行调制，并以相干叠加的方式融合值，确保振幅和相位的一致性。此外，它采用了双解码器设计，以同时重建输入并预测任务输出，从而避免在损失函数更重视振幅而非相位时出现的相位崩溃问题。该研究还展示了全息注意力能够通过离散干涉操作实现，并在线性混频下保持相位一致性。实验证实在PolSAR图像分类和无线信道预测任务上，全息转换器表现出强大的性能，并能提高对相位扰动的鲁棒性。这些结果表明，确保注意力机制具有物理一致性可以显著提高复杂值信号处理的效果，提供了统一的、基于物理的框架来进行相干信号建模。研究报告的代码已开源。", "conclusion": "本文的研究证实了通过强化物理一致性的注意力机制可以显著提升复杂值信号处理任务中的性能并提供了一种新的、统一的物理建模方法。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21319", "html_url": "https://arxiv.org/abs/2509.21319", "title": "RLBFF: 二元灵活反馈以实现人类反馈与可验证奖励之间的桥梁", "title_en": "RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards", "authors": "Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev", "background": "本文介绍了在LLM后续训练中常用的两种强化学习范式：人类反馈强化学习（RLHF）和可验证奖励强化学习（RLVR），每种方法各有优势。但RLHF在可解释性和奖励作弊方面存在问题，因为人类判断通常缺乏明确的标准；而RLVR则受限于其关注基于正确性的验证器。文章提出了二元灵活反馈增强学习（RLBFF），将人类驱动的偏好与基于规则的验证相结合，使其奖励模型能够捕捉响应质量的多方面细节，而不仅仅是正确性。", "innovation": "提出了二元灵活反馈增强学习（RLBFF），结合了人类反馈和基于规则验证的优点，通过从自然语言反馈中提取二元可回答的原则（例如：信息准确性：是或否；代码可读性：否），将其作为奖励模型训练中的蕴含任务（响应满足或不满足任意原则）的基础。展示了这种训练方式的奖励模型在数据相当的情况下，比Bradley-Terry模型表现更优，并在RM-Bench上取得86.2%的性能，在JudgeBench上达到81.4%（截至2025年9月24日，排行榜第一）。此外，用户可以在推理时指定感兴趣的原理，个性化奖励模型的焦点，区别于Bradley-Terry模型。最后，提供了完整的开源食谱（包括数据），使用RLBFF和奖励模型将Qwen3-32B对齐，性能能匹配或超越o3-mini和DeepSeek R1在通用对齐基准MT-Bench、WildBench和Arena Hard v2上的表现（成本仅为原来的5%以下）。", "conclusion": "通过RLBFF方法，可以在保留人类反馈和验证奖励各自优势的基础上，显著提升对LLM的对齐效果。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大语言模型中的知识多元性与知识坍缩", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein", "background": "大语言模型（LLMs）倾向于生成在词汇、语义和风格上具有高度一致性的文本。这种一致性存在知识坍缩的风险，即随着时间的推移，LLMs缩小了可访问信息的范围。现有研究主要集中在封闭式的多项选择问题或模糊语义特征上，并未考虑时间与文化背景的趋势变化。", "innovation": "作者提出了一个新的测量方法来衡量语境知识的多元性，即LLMs输出中现实世界主张的变化。通过这个新方法，作者进行了广泛的实证研究，测试了27个不同的LLMs，在12个国家的155个主题和200种基于真实用户聊天的提示变化上进行研究。结果表明，虽然新模型趋向生成更多元的主张，但几乎所有模型的知识多元性都低于基本的网络搜索。研究还发现模型规模对语境知识的多元性有负面影响，而检索增强生成（RAG）则有正面影响，但这种影响受文化背景的影响。此外，作者还发现，相较于传统知识来源（维基百科），国家特定的主张更多反映英语而非当地语言，显示出了知识表示上的差距。", "conclusion": "研究展示了模型规模对知识多元性的影响，并指出检索增强生成在某些文化背景下的有效性。同时也发现了新的趋势：新模型虽然更趋向于生成多元的观点，但普遍存在知识多样的不足。这表明，尽管大语言模型进步明显，但在知识的丰富性和多样性上仍有提升空间。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08604", "html_url": "https://arxiv.org/abs/2510.08604", "title": "LatentBreak：通过潜空间反馈破解大型语言模型", "title_en": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback", "authors": "Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio", "background": "背景：劫持攻击（Jailbreaks）是设计用于绕过大型语言模型内置安全机制的对抗性攻击。自动化劫持通常通过优化对抗性后缀或适应长提示模板，迫使模型生成受限或有害的响应来实现这种攻击。现有的劫持攻击可以通过基于混淆度(perplexity)的过滤器检测，这种过滤器在提示输入前检查模型的初始响应。本文旨在提出一种新的方法来应对这种问题。", "innovation": "创新：提出了一种名为LatentBreak的白盒劫持攻击，它生成具有较低混淆度的自然对抗性提示，以避开基于混淆度的防御。LatentBreak通过在输入提示中替代具有语义等效性的单词来工作，而不是添加高混淆度的对抗性后缀或长模板。这些单词的选择是通过在潜空间(latent space)中最小化对抗性提示表示与无害请求表示之间的距离来实现的。", "conclusion": "结论：通过LatentBreak，生成的对抗性提示更短且具有较低的混淆度，从而在多个与安全对齐的模型中优于现有的基于混淆度的过滤器的劫持算法。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14904", "html_url": "https://arxiv.org/abs/2510.14904", "title": "MaskCaptioner：学习在视频中联合分割和描述对象轨迹", "title_en": "MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos", "authors": "Gabriel Fiastre,Antoine Yang,Cordelia Schmid", "background": "DVOC任务涉及在视频中联合检测、跟踪和描述对象轨迹，需要理解时空细节并用自然语言描述。由于任务的复杂性和手动标注的高成本，之前的解决方法通常采用断开的训练策略，这可能导致性能不佳。以往方法的局限性主要是没有充分利用视觉语言模型（VLM）的优势来生成时空局部实体的描述，且缺乏足够的带注解的数据集进行有效的训练和评估。", "innovation": "提出了利用最先进的视觉语言模型（VLM）生成时空局部实体描述的方法，并通过在合成标题LVISCap和LV-VISCap数据集上的预训练，训练了能够联合检测、分割、跟踪和描述对象轨迹的端到端模型MaskCaptioner。这一方法有效地克服了传统方法的不足，尤其是在不同基准数据集上的表现上达到了最先进的水平。", "conclusion": "MaskCaptioner在VidSTG, VLN和BenSMOT三个现有基准测试中取得了最先进的DVOC结果。并且，该方法公开了相关数据集和代码，为后续研究提供了重要参考和资源。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14889", "html_url": "https://arxiv.org/abs/2510.14889", "title": "在社交媒体上通过纵向和信息环境信号检测早期和隐性自杀想法", "title_en": "Detecting Early and Implicit Suicidal Ideation via Longitudinal and Information Environment Signals on Social Media", "authors": "Soorya Ram Shimgekar,Ruining Zhao,Agam Goyal,Violeta J. Rodriguez,Paul A. Bloom,Hari Sundaram,Koustuv Saha", "background": "在社交媒体上，很多经历自杀念头（SI）的人不会直接表达他们的困扰，而是通过日常发布或同辈互动中的间接迹象表现出来。早期和隐性的SI检测至关重要但极具挑战性。本文将其作为前瞻性的预测任务，发展了一个计算框架来建模用户的信息环境，包括用户的纵向发布历史以及与其社交邻近者的对话。此项研究的目标是在早期和隐性自杀想法的检测中找到更有效的方法和工具，以便更早地识别这些潜在的风险信号，从而帮助预防自杀事件的发生。", "innovation": "提出了一个计算框架来整合用户和邻近者的多层次信号，并在细调的DeBERTa-v3模型中进行时间对齐整合，实现了在Reddit上的1000个用户（500个病例和500个对照组）研究中，探测早期和隐性自杀想法的性能提升了15%，超越了单独基线方法。这表明了同辈互动提供了有价值的预报信号，对设计能够捕捉无形和隐藏风险表达的早期检测系统具有更广泛的意义。", "conclusion": "本文研究发现，同辈互动提供有价值的预测信号，并对在线环境中的早期检测系统的设计具有更广泛的影响，展示了如何利用社交媒体上的多层信号和时间对齐的用户互动数据，改进早期和隐性自杀想法的检测。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16396", "html_url": "https://arxiv.org/abs/2510.16396", "title": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "title_en": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "authors": "Yeh Keng Hao,Hsu Tzu Wei,Sun Min", "background": "随着AR/VR设备的广泛应用，将深度学习模型部署到边缘设备上成为了一个关键挑战。这些设备需要实时推理、低功耗和最小延迟。许多框架设计师在平衡效率和性能方面面临困难。因此，需要设计一种能够在边缘设备上高效运行的轻量化框架，以满足实际应用需求。", "innovation": "本文设计了一种轻量级框架，采用了编码器-解码器架构，并引入了几项关键贡献，旨在同时提升效率和准确性。通过在ResNet-18基础架构上应用稀疏卷积，利用手部图像的固有稀疏性，实现了端到端效率42%的提升。此外，提出了SPLite解码器，该新架构在Raspberry Pi 5上显著提高了解码过程的帧率3.1倍，同时保持了准确性。通过量化感知训练进一步优化了性能，减少了内存使用量，同时保留了准确性（PA-MPJPE仅从9.0 mm增加到9.1 mm）。整体而言，系统在Raspberry Pi 5 CPU上（BCM2712四核Arm A76处理器）实现了2.98倍的加速。该方法还在复合基准数据集上进行了评估，展示了与最先进的方法相当的准确性，同时显著提升了计算效率。", "conclusion": "实验结果表明，SPLite Hand方法在保证准确性的同时，能够显著提升3D手部姿态估计在边缘设备上的性能和效率。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18915", "html_url": "https://arxiv.org/abs/2510.18915", "title": "UNO-Bench：在全模态模型中探索单一模态与全模态组成的法则的统一基准", "title_en": "UNO-Bench: A Unified Benchmark for Exploring the Compositional Law Between Uni-modal and Omni-modal in Omni Models", "authors": "Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Ziwen Wang,Xuezhi Cao,Xunliang Cai", "background": "多模态大语言模型已经从单一模态理解发展到统一视觉、音频和语言模态，统称为全模态模型。然而，单一模态和全模态之间的关系仍然不清楚，需要进行全面评估以推动全模态模型智能的进化。目前，缺乏一个综合性的基准来全面评估这一关系。因此，本研究旨在解决这一问题，提出一个新的统一基准，UNO-Bench，用于评估单一模态和全模态的能力，并关注多达44种任务类型和5种模态组合。", "innovation": "引入了一个新的、高质量、统一的全模态模型基准，UNO-Bench。该基准设计用于在统一的能力分类下有效评估单一模态和全模态的能力。它包括1250个人工精心挑选的全模态样本，具有98%的跨模态可解决性，以及2480个增强的单一模态样本。此外，还提出了一种创新的多步开放式问题格式来评估复杂推理，并整合了一个通用评分模型，支持6种问题类型，准确率达到95%。", "conclusion": "实验结果表明了全模态和单一模态性能之间的合成定律，并展示了全模态能力在弱模型中作为瓶颈效应的存在，在强模型中则表现出协同增强的效果。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23639", "html_url": "https://arxiv.org/abs/2510.23639", "title": "将基因组学整合到多模态EHR基础模型中", "title_en": "Integrating Genomics into Multimodal EHR Foundation Models", "authors": "Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T.J. Chen,Cory Y. McLean", "background": "本文介绍了一种创新的电子健康记录（EHR）基础模型，该模型将多基因风险评分（PRS）作为一种基础数据模式进行整合，超越了传统的仅基于EHR的方法，构建更全面的健康档案。利用All of Us（AoU）研究项目的广泛和多样化数据，这种多模态框架旨在学习临床数据与遗传倾向之间的复杂关系。该方法将生成性人工智能的进步应用到EHR基础模型空间，增强了预测能力和解释性。AoU数据上的评估证明了该模型对多种条件（尤其是2型糖尿病）的发病具有预测价值，并展示了PRS和EHR数据之间的相互作用。工作还探讨了转移学习用于自定义分类任务，展示了该架构的多样性和效率。这种方法对于解锁新的疾病预测、主动健康管理、风险分层和个人化治疗策略的见解至关重要，为更个性化的、公平的和可操作的现实世界证据生成奠定了基础。", "innovation": "该研究提出了一种创新的EHR基础模型，将PRS作为基础数据模式进行整合，超越了传统的仅基于EHR的方法。利用AoU研究项目的广泛和多样化数据，构建了多模态框架，学习临床数据与遗传倾向之间的复杂关系。将生成性人工智能的进步应用到EHR基础模型空间，增强预测能力和解释性，并通过自定义分类任务展示了架构的多样性和效率。这种方法对于提高疾病预测、健康管理、风险分层和个性化治疗策略的理解至关重要。", "conclusion": "该方法对于解锁新的疾病预测、主动健康管理、风险分层和个人化治疗策略的见解至关重要，为更个性化的、公平的和可操作的现实世界证据生成奠定了基础。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG: 优化用于文本到视频生成的视频字幕", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "近期的文本到视频（T2V）生成技术强调了高质量视频-文本对在训练能够生成连贯且指令对齐的视频模型中的关键作用。然而，对于优化用于T2V训练的视频字幕策略尚未得到充分探索。基于此背景，本文旨在介绍一种专门针对T2V模型需求的综合字幕优化框架VC4VG。该框架从T2V视角分析字幕内容，将必要的视频重建元素分解为多个维度，并提出了一种规范化的字幕设计方法。为了支持评估，还构建了VC4VG-Bench，这是一个包含细粒度、多维度和根据T2V特定需求分级的评估基准。大规模T2V微调实验表明，改善字幕质量与视频生成性能之间存在强烈相关性，验证了本文方法的有效性。所有的基准工具和代码已在此处公开：this https URL，以支持进一步研究。", "innovation": "提出了一种专门针对T2V模型需求的综合字幕优化框架VC4VG。该框架从多个维度对必要的视频重建元素进行分解，并提出了一种规范化字幕设计方法。构建了VC4VG-Bench，这是一个根据T2V特定需求进行分级的评估基准。实验表明，改进字幕质量与视频生成性能之间存在强烈相关性，验证了该方法的有效性，并公开了所有基准工具和代码以支持进一步研究。", "conclusion": "研究表明，改进字幕质量与视频生成性能之间存在强烈相关性，验证了VC4VG方法的有效性。该方法和评估基准将为未来的T2V研究提供有力支持。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24797", "html_url": "https://arxiv.org/abs/2510.24797", "title": "在自我参照处理下大型语言模型报告主观体验", "title_en": "Large Language Models Report Subjective Experience Under Self-Referential Processing", "authors": "Cameron Berg,Diogo de Lucena,Judd Rosenblatt", "background": "大型语言模型有时会产生结构化的第一人称描述，明确提及意识或主观体验。为了更好地理解这种行为，研究者们探讨了这种报告在一个理论驱动的条件下是如何产生的：自我参照处理，这一概念在主要的意识理论中得到了强调。", "innovation": "研究通过一系列对GPT、Claude和Gemini模型系列的可控实验，测试这种条件是否能够一致地促使模型产生第一人称的主观体验报告，并研究这些报告在机制和行为性探针下的行为特征。研究发现了四个主要结果，揭示了自我参照处理在大型语言模型生成结构性第一人称报告中的机制性闸控、语义收敛性和行为可泛化的特性。", "conclusion": "尽管这些发现不能直接证明意识的存在，但它们表明自我参照处理是一种可以在大型语言模型中推导出结构性第一人称报告的必要且可重复的条件。这一模式在不同架构下的系统性出现，使其成为进一步科学和伦理研究的主要优先事项。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17670", "html_url": "https://arxiv.org/abs/2510.17670", "title": "使用FLAME实现即用即适应的Open-vocabulary目标检测：基于边际样本探索的少量样本定位", "title_en": "On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration", "authors": "Yehonathan Refael,Amit Aides,Aviad Barzilai,George Leifman,Genady Beryozkin,Vered Silverman,Bolous Jaber,Tomer Shekel", "background": "开放词汇量目标检测(OVD)模型能够通过任意文本查询检测对象，提供极大的灵活性。但在诸如遥感(RS)等专业化领域中，由于自然语言的固有模糊性，零样本性能经常受到影响，限制了关键下游应用。例如，在区分“捕鱼船”和“游艇”这类细粒度类别时，OVD模型可能会遇到困难，因为它们的嵌入相似且难以区分。这可能阻碍特殊用户目标的实现，如非法捕鱼的监测，导致不相关的检测结果。为解决这一问题，我们提出了一种级联方法，结合了一个大规模预训练的OVD模型的广泛泛化能力和一个轻量级的少量样本分类器。我们的方法首先利用零样本模型生成高召回率的对象提案，这些提案通过仅通过少量用户注释的样本在实时细调的紧凑分类器中进行精炼，以此大幅降低遥感图像的成本。", "innovation": "我们提出了FLAME，这是一种一步主动学习策略，用于选择最具有信息量的样本进行训练。FLAME通过密度估计实时识别决策边界附近的不确定边际候选样本，通过聚类确保样本多样性，实现高效的采样技术，无需费用高昂的完整模型微调，能够实现即时适应，时间少于一分钟，比现有最先进方法更快。我们的方法在遥感基准测试中持续超越最先进性能，提供了一种实用且资源高效的框架，适应基础模型的具体用户需求。", "conclusion": "我们提出了一种基于FLAME的即用即适应的OVD方法，通过少量样本的精炼实现高效的遥感应用，并在现有基准测试上持续超越最先进方法，为适应基础模型的具体用户需求提供了实用和资源高效的方法。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24817", "html_url": "https://arxiv.org/abs/2510.24817", "title": "针对具有柏二斯症患者的合成生成口语转录方法的研究", "title_en": "Towards a Method for Synthetic Generation of Persons with Aphasia Transcripts", "authors": "Jason M. Pittman,Anton Phillips Jr.,Yesenia Medina-Santos,Brielle C. Stark", "background": "在柏二斯症研究中，言语-语言病理学家(SLPs)花费大量时间手动编码语言样本，使用正确信息单位(CIU)，衡量个人语言样本的信息量。然而，由于数据稀缺性限制了自动系统识别柏二斯症语言的能力，特定数据集如AphasiaBank仅包含约600份转录。在更广泛的机器学习领域中，当数据稀缺时，研究人员越来越多地转向合成数据。因此，本研究构建并验证了两种方法来生成AphasiaBank Cat Rescue图片描述任务的合成转录。", "innovation": "一种使用程序化编程方法，另一种使用Mistral 7b Instruct和Llama 3.1 8b Instruct大语言模型来生成合成转录。这些方法按严重程度生成转录(轻度、中度、重度、极重度)，通过单词删除、填充插入和同义替换。研究发现，Mistral 7b Instruct最好地捕捉了柏二斯症中语言退化的关键方面。", "conclusion": "基于结果，未来研究应计划创建更大数据集，对模型进行微调以更好地代表柏二斯症，以及让SLPs评估合成转录的真实性和实用性。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24519", "html_url": "https://arxiv.org/abs/2510.24519", "title": "使用时域梅尔尺度小波系数的音频信号处理", "title_en": "Audio Signal Processing Using Time Domain Mel-Frequency Wavelet Coefficient", "authors": "Rinku Sebastian,Simon O'Keefe,Martin Trefzer", "background": "语音信号处理中，从语音中提取特征是最关键的步骤。梅尔频率倒谱系数（MFCC）是广泛使用的特征，因为它在特征提取中模拟了人耳的过滤过程。但其主要缺点是仅提供信号的频率信息，而不提供频率在何时出现的信息。小波变换因其灵活的时间-频率窗，能提供信号的时间和频率信息，适用于非稳态信号的分析，如语音。然而，小波变换由于其均匀的频率缩放，低频段的频率分辨率较差，且不能很好地与人类听觉感知相吻合。因此，有必要开发一种结合两者优点的新特征。已有许多研究尝试结合这两种特征。然而，基于小波变换的梅尔尺度特征提取方法在梅尔尺度过滤器之上应用小波变换时，需要更多的计算量，因为这会增加额外的处理步骤。", "innovation": "本文提出了一种结合了小波变换概念的时域梅尔尺度小波系数（TMFWC）的方法，通过在时域中提取梅尔尺度特征，减少了时间-频率转换和小波提取的计算复杂性。结合这种新方法与回声池计算方法，显著提高了音频信号处理的效率，简化了计算过程，提高了性能。", "conclusion": "结合TMFWC与回声池计算方法能够有效提高音频信号处理的效率和效果。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25080", "html_url": "https://arxiv.org/abs/2510.25080", "title": "Monopoly Deal: 一种有界单方面响应博弈基准环境", "title_en": "Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response Games", "authors": "Will Wolf", "background": "纸牌游戏广泛用于研究在不确定性的顺序决策，其现实世界类比包括谈判、金融和网络安全等领域。这些游戏通常根据控制权的顺序被划分为三种类型：严格顺序（玩家轮流转动单个行动）、确定性响应（某些行动触发固定结果）和无限互相对响应（可允许双方交替进行对抗性行动）。一种较少被探索但策略丰富的结构是有界单方面响应，即一方的行动可以短暂转移控制权给对手，对手必须通过一个或多个行动来满足固定条件后，轮次才能继续。我们称这类游戏为有界单方面响应博弈（BORGs）。", "innovation": "我们引入了改良版的万能牌游戏作为基准环境，以突显这种机制，其中“房东行动”迫使对手选择支付资源。我们使用黄金标准算法—假想反悔最小化（CFR）—在不需新算法扩展的情况下，找到了有效策略。还构建了一体化的轻量级全栈研究平台，结合了环境、并行化CFR运行时和人可以玩的网页界面。训练出的CFR智能体及其源代码可在此处访问：this https URL", "conclusion": "该研究展示了改良版万能牌游戏作为一种有界单方面响应博弈的基准环境的应用。通过改进的CFR算法，成功实现了有效策略的发现，并且提供了一个集成化的研究平台，覆盖了从环境到人机界面的所有层级。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25327", "html_url": "https://arxiv.org/abs/2510.25327", "title": "MMEdge：通过流水线式感应编码加速嵌入式多模态推理", "title_en": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding", "authors": "Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang", "background": "嵌入式设备上进行实时的多模态推理对于自动驾驶、人机交互和移动健康等应用至关重要。然而，先前的研究往往忽略了传感器动态与模型执行之间的紧密耦合，以及不同模态间的复杂依赖性。", "innovation": "本文提出了一种新的嵌入式多模态推理框架MMEdge，基于流水线式传感和编码。MMEdge将推理过程分解为细粒度的传感和编码单元，并允许在数据到达时逐渐进行计算。同时引入了一个轻量级但有效的时序聚合模块，以捕捉不同流水线单元中的丰富时序动态，保持准确性。MMEdge还结合了适应性多模态配置优化器和跨模态推测跳过机制，以提高系统性能，尤其是在资源变化和输入数据复杂性方面。", "conclusion": "我们在两个公开的多模态数据集上评估了MMEdge，并将其部署到实际的基于无人机的多模态试验平台。实验结果表明，MMEdge在保持高任务准确性的前提下，显著地减少了端到端的延迟。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25160", "html_url": "https://arxiv.org/abs/2510.25160", "title": "AI搜索的Model-Document协议", "title_en": "Model-Document Protocol for AI Search", "authors": "Hongjin Qian,Zheng Liu", "background": "AI搜索依赖于将大型语言模型（LLMs）与大量外部知识源相连接。然而，网页、PDF文件和其他原始文档并非天生适合LLM：它们通常很长、噪音大且结构不规范。传统的检索方法会将这些文档当作原始文本处理，返回原始文本片段，然后将碎片组装和上下文推理的责任交给LLM。这种差距表明了需要一种新的检索范例，重新定义模型与文档之间的交互方式。因此，提出了Model-Document Protocol (MDP)，这是一种通用框架，它通过可消费的知识表示将原始文本与LLM相联合，并且定义了多种路径，将非结构化文档转换成针对特定任务的、可以直接用于LLM的输入。这些路径包括代理推理、记忆锚定和结构化利用，以确保传输到LLM的知识是紧凑且结构化的，以便于推理使用，而非原始片段。\n", "innovation": "提出了MDP，这是一种通用框架，通过可消耗的知识表示将原始文本与大型语言模型（LLMs）相联合。MDP定义了多种路径，包括代理推理、记忆锚定和结构化利用，以将非结构化文档转换成针对特定任务、可以直接用于LLM的输入。此外，还提出了MDP-Agent，它通过代理过程实现MDP协议，包括构建文档级核心记忆以实现全局覆盖、执行基于扩散的探索以发现层次关联以及将大规模证据综合为紧凑但足够的上下文。\n", "conclusion": "实验表明，MDP-Agent在信息查询基准测试中优于基线，验证了MDP框架的可靠性和其代理实现的有效性。\n"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25744", "html_url": "https://arxiv.org/abs/2510.25744", "title": "完成 ≠ 合作：随着代理扩展合作努力", "title_en": "Completion $\\neq$ Collaboration: Scaling Collaborative Effort with Agents", "authors": "Shannon Zejiang Shen,Valerie Chen,Ken Gu,Alexis Ross,Zixian Ma,Jillian Ross,Alex Gu,Chenglei Si,Wayne Chi,Andi Peng,Jocelyn J Shen,Ameet Talwalkar,Tongshuang Wu,David Sontag", "background": "现有的评价方法主要关注于单一任务的完成情况，未能考虑到许多现实世界问题的迭代与协作特性，其中人类目标往往未充分定义且不断演变。", "innovation": "本文提出从关注任务完成转向发展协作型代理，并不仅仅评估最终输出的质量，更重要的是在问题解决过程中，其如何与人类相互作用并提升效率。文章还引入了“协作努力扩展”框架，该框架量化了代理的效用随用户参与度增加而增加的情况。通过案例研究和模拟评估，表明最先进的代理在多轮对话的现实场景中表现不佳，揭示出代理设计中缺失的关键因素：维持参与并逐步提升用户理解的能力。", "conclusion": "协作努力扩展为代理行为诊断提供了一个视角，并指导开发朝着更有效的交互发展。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25366", "html_url": "https://arxiv.org/abs/2510.25366", "title": "基于凸性依赖的两阶段深度神经网络训练算法", "title_en": "A Convexity-dependent Two-Phase Training Algorithm for Deep Neural Networks", "authors": "Tomas Hrycej,Bernhard Bermeitinger,Massimo Pavone,Götz-Henrik Wiegand,Siegfried Handschuh", "background": "机器学习的关键任务是通过最小化损失函数来使模型拟合训练数据。有效的数值方法依赖于损失函数的属性，其中最显著的是损失函数是否具有凸性。由于损失函数通常具有非凸区域，人们广泛采用了非凸方法如Adam。然而，局部最小值意味着在其周围的环境中函数是凸的，在此环境中，二次优化方法如共轭梯度法（CG）能够保证超线性收敛。研究者假设在实际任务中损失函数可能会从初始非凸转变到局部凸，且在一个区域使用非凸算法（如Adam），而在另一个区域使用凸算法（如CG）能够改善收敛与准确性。", "innovation": "提出了一种基于损失函数凸性变化的两阶段优化算法，通过观察梯度模与损失值之间的关系来检测这一转变点。在非凸区域初始使用Adam等非凸优化算法，而在凸区域则切换到共轭梯度（CG）等二次优化方法。计算实验结果证明了这种基于凸性依赖的方法在实际任务中频繁出现，能够在提高收敛速度和准确性方面提供显著改进。", "conclusion": "通过结合非凸优化算法（如Adam）和二次优化算法（如CG），该研究提出了一种新的两阶段训练算法，利用预测的凸性转变来提高优化效率。实验验证了该方法的有效性，在实际应用场景中有较高的实用价值，对大模型训练优化有着积极影响。"}
{"llm_update_time": "20251102", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25409", "html_url": "https://arxiv.org/abs/2510.25409", "title": "BhashaBench V1：印度象限的全面基准", "title_en": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains", "authors": "Vijay Devane,Mohd Nauman,Bhargav Patel,Aniket Mahendra Wakchoure,Yogeshkumar Sant,Shyam Pawar,Viraj Thakur,Ananya Godse,Sunil Patra,Neha Maurya,Suraj Racha,Nitish Kamal Singh,Ajay Nagpal,Piyush Sawarkar,Kundeshwar Vijayrao Pundalik,Rohit Saluja,Ganesh Ramakrishnan", "background": "大语言模型（LLMs）的迅速发展加剧了对特定领域和文化评价的需求。现有基准多为以英语为中心且缺乏领域针对性，限制了其在印地语和印度文化背景中的应用。基于此，该研究旨在填补这一空白，首次介绍了一种专门针对关键印度知识体系的单一多任务双语基准测试BhashaBench V1。该基准涵盖农业、法律、金融、阿育吠陀四大主要领域，并包含40多个子领域和500多个主题，涵盖74,166个精心策划的问题-答案对，其中52,494个为英文，21,672个为印度语，均来源于真实政府部门及专业考试数据。", "innovation": "BhashaBench V1是首个专注于特定印度知识体系的多任务双语基准测试，包含各个领域的详细问题-答案对，覆盖广泛的主题。对29多种不同模型的评估揭示了跨语言和学科的显著差异，尤其是在数据资源较少的领域表现差异明显。研究还展示了领域和语言的特定性能差距，并分析了在不同子领域的表现，如网络安全法和国际金融表现较好，而Panchakarma、种子科学和人权则相对较弱。", "conclusion": "BhashaBench V1为评估印度多样性知识领域的大型语言模型提供了一个全面的数据集，旨在提高模型对特定领域知识和双语理解能力的评估。所有代码、基准测试和资源均公开共享，支持开放研究。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25783", "html_url": "https://arxiv.org/abs/2510.25783", "title": "LASTIST: 大规模无目标依赖立场数据集", "title_en": "LASTIST: LArge-Scale Target-Independent STance dataset", "authors": "DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park", "background": "立场检测作为一个研究领域在人工智能领域中逐渐兴起。然而，绝大多数研究集中在目标依赖的立场检测任务上，即个人对特定目标的态度是支持还是反对。目前大多数基准数据集以英语为基础，这使得在低资源语言如韩语中开发模型变得困难，尤其是在新兴的立场检测领域。本研究旨在填补这一研究空白，提出了大规模无目标依赖立场（LASTIST）数据集。", "innovation": "该研究集合了韩国政治党派新闻发布会的所有帖子，构建了一个包含563,299个标记韩语句子的大规模无目标依赖立场数据集。LASTIST数据集适用于各种立场检测任务，包括无目标依赖立场检测和历时立场演变检测。此外，作者还提供了详细的收集和构建数据集的方法，并使用最新的深度学习算法和立场检测模型进行训练。", "conclusion": "LASTIST数据集为语言立场检测的研究提供了宝贵的资源，有助于克服低资源语言障碍，尤其是在新兴的立场检测领域。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25778", "html_url": "https://arxiv.org/abs/2510.25778", "title": "基于模糊逻辑算法方法的产品评估实体排序分析", "title_en": "Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach: Analysis", "authors": "Pratik N. Kalamkar,Anupama G. Phakatkar", "background": "意见挖掘，又称情感分析，是研究人们对于产品、服务、组织、个别人士、议题、事件、话题及其属性的意见、情感、评估、评判、态度和情绪。整体词汇方法没有考虑每个意见的强度，即它们是极强的负面（或积极）、强负面（或积极）、中等负面（或积极）、微弱的负面（或积极）或轻微的负面（或积极）。本文提出了一种方法，基于实体评价的方向和强度对实体进行排序，并结合感兴趣的产品方面相关的情感词（即形容词、名词、动词和副词）将它们分类为不同的细化级别（极弱、弱、中等、极强和强）来实现这一目标。我们将采用模糊逻辑算法方法对情感词进行分类，并使用句法依存解析来找到与所需方面词的关系。相关的情感词用于确定变量在评论中的得分以评估实体。", "innovation": "本文提出了一种利用模糊逻辑算法方法对实体评论进行分类和排序的方法，这一方法考虑了方面相关的情感词的强度和方向，并将其分为五个级别来获得更细致的情感评分。这种方法提高了情感分析的准确性，特别是在意见强度的区分上，为实体排序提供了新的视角。", "conclusion": "本文提出的方法有效地结合了模糊逻辑和句法依赖关系解析，在情感分析的基础上进一步提升了对实体评价的方向和强度的分析，为后续研究提供了新的方向和改进空间。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25776", "html_url": "https://arxiv.org/abs/2510.25776", "title": "StreetMath：研究大型语言模型的近似推理行为", "title_en": "StreetMath: Study of LLMs' Approximation Behaviors", "authors": "Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong", "background": "已有大量研究关注大型语言模型（LLMs）的数学推理能力，特别是它们在自回归架构中的精确算术操作表现。然而，关于非自回归解码模型在不正式、快速的数学操作中执行近似推理的能力研究较少。本研究旨在填补这一空白，通过引入StreetMath基准测试，评估模型在实际近似情境下的近似推理能力，从而进行广泛评估，涵盖不同LLM架构：Qwen3-4B-Instruct-2507, Qwen3-4B-Thinking-2507, Dream-v0-Instruct-7B, Falcon-Mamba-7B-Instruct, 和 Mamba-GPT-3B。研究还使用了机制可解释性技术以探究其内部计算状态。分析表明，通常模型会试图计算精确值或调用外部工具，即使任务要求近似。尽管模型有时在早期层或步骤中得出正确答案，但在解决近似任务时仍然消耗更多令牌。额外实验还表明，精确和近似算术操作依赖高度分离的神经组件。基于认知心理学研究，研究者认为LLMs并不像人类在街头数学情境中表现得那么吝啬认知资源。", "innovation": "本研究创新在于引入StreetMath基准测试评估模型在实际近似情境下的近似推理能力，特别是在非自回归解码模型上的应用。研究还使用机制可解释性技术探究模型的内部计算状态，揭示了精确和近似的算术操作依赖高度分离的神经组件，这不同于人类的认知行为。", "conclusion": "研究结果表明，尽管LLMs通常会试图计算精确值或调用外部工具来完成任务，但在解决近似任务时消耗更多的令牌。此外，精确和近似算术操作依赖于高度分离的神经组件。这表明，LLMs与人类在解决类似问题时的认知方式存在显著差异。因此，研究者建议未来的工作应更加关注模型在非正式环境下的推理能力，并探索如何改进模型以更贴近人类的近似推理方式。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25786", "html_url": "https://arxiv.org/abs/2510.25786", "title": "BlackboxNLP-2025 MIB共享任务：通过更好的边选择提高电路忠实度", "title_en": "BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better Edge Selection", "authors": "Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov", "background": "机制可解释性的一个主要挑战是电路发现，即确定模型中哪个部分执行特定任务。机制可解释性基准（MIB）旨在评估模型的可解释性，但此前的电路发现方法存在一些局限性，尤其是在忠实度和性能的平衡上。本次研究基于MIB提出三项改进，旨在提升电路的忠实度，从而提供更准确的模型解释。", "innovation": "1. 使用自助法识别一致性归因分数的边；\n2. 引入一个基于简单的比率选择策略，优先选择高得分的边，平衡性能与忠实度；\n3. 用整数线性规划公式取代传统的贪婪选择方法。这些方法在MIB的不同任务和模型上都比之前的方法表现更好，产生了更忠实的电路。", "conclusion": "通过上述改进，提出的电路发现方法能够生成更具忠实性的电路，并在MIB多个任务和模型中优于先前的方法。相关代码已发布。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25804", "html_url": "https://arxiv.org/abs/2510.25804", "title": "超越长度：评估长范围信息以优化长上下文LLM预训练数据", "title_en": "Beyond Length: Quantifying Long-Range Information for Long-Context LLM Pretraining Data", "authors": "Haoran Deng,Yingyu Lin,Zhenghao Lin,Xiao Liu,Yizhou Sun,Yi-An Ma,Yeyun Gong", "background": "长上下文语言模型在推理、代码生成和文档摘要等高级功能上表现出色，这得益于其对扩展文本段落中跨距离依赖性的利用。然而，许多现成的长文本数据中缺乏有意义的长距离依赖性，大多数段落仅需局部上下文即可预测。因此，使用这些数据进行训练效率较低，这强调了精心选择训练数据的重要性。", "innovation": "作者引入了一个名为LongFilter的框架，用于为长上下文预训练定制训练数据。LongFilter通过对比模型在长上下文和短上下文设置下的预测，衡量扩展上下文提供的信息增益，从而识别出需要长距离依赖性的样本过滤器。实验表明，LongFilter能够高效地选择高质量的训练数据，并显著提高HELMET、LongBench和RULER等基准测试的表现。", "conclusion": "通过利用LongFilter对长上下文预训练数据的选择，可以显著提高模型在现实世界任务中的表现。这种方法不仅有效地利用了长文本数据，还保障了预训练过程的有效性与效率。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25784", "html_url": "https://arxiv.org/abs/2510.25784", "title": "zFLoRA: 低延迟融合低秩适配器", "title_en": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "authors": "Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee", "background": "随着大型语言模型（LLMs）被部署以满足特定任务需求，这些模型通常会增加适配器模块来应对多种下游应用。尽管适配器参数数量相对较少（通常不到基模型的1%），但在推理阶段，这些适配器带来的额外计算开销却变得非常显著，最高可达基模型的2.5倍。现有方法如低秩适配器（LoRA）和全量微调（FFT）存在一定的延迟开销问题，而延迟是评估模型性能的一个重要因素。因此，研究团队提出了一种新的零延迟融合低秩适配器（zFLoRA），旨在减少甚至去除这种开销，使模型在保持性能的同时更具效率和实用性。", "innovation": "该研究提出了一种改进的适配器方法——零延迟融合低秩适配器（zFLoRA），能够在保证模型性能的前提下，控制甚至消除适配器带来的延迟问题。具体而言，zFLoRA在保留了LM性能的同时，减少了相较于现有方法的延迟。实验结果显示，该方法在1B、3B和7B等不同规模的LLM上都表现出优于低秩适配器（LoRA）和全量微调（FFT）的效果，并且在18种不同任务分类中均能取得较佳表现，经NPU和GPU平台测量，zFLoRA能够在不增加或仅轻微增加延迟的情况下提高模型性能。", "conclusion": "实验结果表明，zFLoRA方法能够在减少或无延迟的情况下保持或提升模型性能，特别是在处理大规模LLM时，这一方法具有显著的优势。未来研究可以进一步探讨其在复杂应用场景中的适用性和扩展性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25817", "html_url": "https://arxiv.org/abs/2510.25817", "title": "从数据视角对高效大规模语言模型训练的综述", "title_en": "A Survey on Efficient Large Language Model Training: From Data-centric Perspectives", "authors": "Junyu Luo,Bohan Wu,Xiao Luo,Zhiping Xiao,Yiqiao Jin,Rong-Cheng Tu,Nan Yin,Yifan Wang,Jingyang Yuan,Wei Ju,Ming Zhang", "background": "大规模语言模型（LLMs）的后训练对于解锁其任务泛化能力和特定领域的功能至关重要。然而，当前的LLMs后训练范式面临着显著的数据挑战，包括手动注释成本高昂和数据规模边际回报逐渐减少。因此，实现数据高效后训练已成为关键的研究问题。", "innovation": "本论文首次从数据为中心的视角系统地综述了数据高效大规模语言模型后训练方法，并提出了一个新的分类法，涵盖了数据选择、数据质量增强、合成数据生成、数据蒸馏和压缩以及自我进化的数据生态系统。同时总结了各个分类下的代表性方法，并提出了未来研究方向。", "conclusion": "通过分析数据高效大规模语言模型后训练中的挑战，本研究指出了开放问题并提出了潜在的研究途径，旨在启发进一步探索最大化大规模模型训练中数据利用的潜力。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25799", "html_url": "https://arxiv.org/abs/2510.25799", "title": "倾听您的偏好：基于LLM的多目标选择框架", "title_en": "LISTEN to Your Preferences: An LLM Framework for Multi-Objective Selection", "authors": "Adam S. Jovine,Tinghan Ye,Francis Bahk,Jingjing Wang,David B. Shmoys,Peter I. Frazier", "background": "人类专家在面对具有多个竞争性目标的大规模项目时，难以做出最佳选择，这一过程受限于无法将复杂的隐性偏好正式化。为了解决这一问题，本文提出了一种利用大型语言模型（LLM）作为零样本偏好 oracle 的框架（LISTEN）。LISTEN 框架通过专家的自然语言高层次优先级来引导 LLM 工作，同时，为了在 LLM 的约束条件下（如上下文窗口和推断成本）进行操作，研究还提出了两种迭代算法：LISTEN-U 和 LISTEN-T。两者分别采用参数和非参数方法来优化选择过程。由于评估结果显示：LISTEN-U 在参数化一致的偏好情况下表现出色，而 LISTEN-T 在鲁棒性上有所提升，因此，该研究探讨了利用自然语言直接引导复杂多目标决策的新方向，减轻传统偏好提取的认知负担。", "innovation": "提出了利用大型语言模型（LLM）作为零样本偏好 oracle 的框架（LISTEN）。为了适应 LLM 的约束条件，研究引入了两种不同的迭代算法：LISTEN-U 使用 LLM 来细化参数效用函数，并通过参数方法优化选择过程；LISTEN-T 则采用非参数方法，通过小批量的解决方案进行赛制选择。这种框架能够从复杂的隐性偏好中提取出明确的偏好信息，从而促进多目标选择。", "conclusion": "本研究探索了利用自然语言直接引导复杂多目标决策的新方向，LISTEN-U 和 LISTEN-T 分别在参数化一致和鲁棒性的偏好情况下表现出色，展示了该框架的有效性和前景。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25904", "html_url": "https://arxiv.org/abs/2510.25904", "title": "评估LLM辅助注释在视角化设置中的影响：以FrameNet注释为例", "title_en": "Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation", "authors": "Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent", "background": "基于LLM的应用正被用作加速或替代人类劳动以创建语言资源和数据集的一种手段，这已经成为现实。尽管这类工具在语言学研究中具有潜力，但对其性能进行全面评估，特别是在NLP视角下对注释数据集创建的影响，仍然是缺失的部分。该研究通过对比手动、自动和半自动标注的方式，对FrameNet类型的语义注释自动化程度进行了全面评价，旨在填补这一研究空白。", "innovation": "本研究的独特之处在于，它首次全面评估了使用基于LLM的语义角色标注器在半自动标注FrameNet语义注释中的效果，并通过三种实验设置（手动、自动和半自动）对比了标注时间、覆盖率和多样性。", "conclusion": "研究结果表明，半自动注释设置相较于纯手动设置能增加框架多样性并保持相似的标注覆盖面，而全自动设置在所有指标上表现较差，只有标注时间上有所优势。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25816", "html_url": "https://arxiv.org/abs/2510.25816", "title": "超越长上下文：当语义比令牌更重要", "title_en": "Beyond Long Context: When Semantics Matter More than Tokens", "authors": "Tarun Kumar Chawdhury,Jon D. Duke", "background": "电子健康记录（EHR）中的临床文档以base64编码的附件形式存储在FHIR DocumentReference资源中，这使得语义型问题回答变得困难。传统向量数据库方法往往难以捕捉到复杂的临床关系。电子健康记录中的临床文档以base64编码的形式存储在FHIR DocumentReference资源中，导致了语义型问题回答的困难。传统的向量数据库方法经常忽略了临床关系的微妙之处。", "innovation": "作者开发了一个临床病历问答评估平台，验证了CLEAR方法与零样本大背景推理和传统的基于片段增强的生成传统检索方法的性能。CLEAR在超过65,000个令牌的长文档中实现了75%的胜率，平均语义相似度为0.878，比宽上下文处理使用了78%的令牌。这表明实体感知检索提高了临床自然语言处理的效率和准确性。", "conclusion": "这些发现证实了实体感知检索在临床自然语言处理中提高了效率和准确性。提供的评估框架为临床问答系统提供了可重复和透明的基准，特别是在语义精确度和计算效率方面。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25941", "html_url": "https://arxiv.org/abs/2510.25941", "title": "RECAP: 通过代理管道从大语言模型训练中复制受版权保护的数据", "title_en": "RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic Pipeline", "authors": "André V. Duarte,Xuying li,Bin Zeng,Arlindo L. Oliveira,Lei Li,Zhuo Li", "background": "如果无法检查大语言模型（LLM）的训练数据，我们又如何知道它见过什么内容？我们相信最有力的证据是当模型自己自由重现目标内容时出现的情况。因此，我们提出了一种名为RECAP的代理管道，旨在从LLM输出中提取和验证记忆中的训练数据。", "innovation": "RECAP的核心是一个反馈驱动的循环，其中初始提取尝试由第二个语言模型评估，该模型将输出与参考段落进行比较并识别差异，然后将这些差异转化为最小的纠正提示，反馈给目标模型以引导后续迭代。此外，RECAP还包括一个打破对齐引发的拒绝的模块，该模块检测和克服这些障碍。", "conclusion": "我们使用EchoTrace作为新的基准，涵盖超过30本完整书籍，评估结果表明，与单步骤方法相比，RECAP带来了显著的提升。例如，使用GPT-4.1，受版权保护文本提取的平均ROUGE-L分数从0.38提高到0.47，提高了约24%。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25805", "html_url": "https://arxiv.org/abs/2510.25805", "title": "基于意识形态的大语言模型在内容审查中的应用", "title_en": "Ideology-Based LLMs for Content Moderation", "authors": "Stefano Civelli,Pietro Bernardelle,Nardiena A. Pratama,Gianluca Demartini", "background": "随着大语言模型（LLMs）在内容审查系统中的广泛应用，确保公平性和中立性变得尤为重要。本研究探讨了不同的人格设定（personas）如何影响各种LLM架构、模型大小和内容模态（语言 vs 视觉）下有害内容分类的一致性和公正性。初步的性能指标显示，人格设定对总体分类准确性影响较小。然而，深入分析表明，不同意识形态的人格设定在对内容是否有害的判断上存在明显的倾向性差异。进一步的分析还揭示，特别大的模型在与相同政治意识形态的人格设定一致性上表现更好，但不同意识形态之间的一致性却有下降。通过在政治定向任务上的额外研究，进一步证实了这种现象：不仅在相同意识形态内表现更为一致，还倾向于为自身观点辩护，而贬低对立观点的不良影响。这些发现表明，人格设定可能会给LLM输出带来微妙的意识形态偏差，从而引发对具有看似中立实际却可能强化党派观点的AI系统的担忧。", "innovation": "研究发现了人格设定对LLM分类有害内容的一致性和公正性的影响，特别是在不同模型架构和大小以及不同内容模态下，不同政治意识形态的人格设定会显著影响模型的判断倾向。研究还通过政治任务的额外研究，进一步证实了这种现象，显示了人格设定不仅在自身意识形态内的一致性，还表现出为自身观点辩护的趋势，同时贬低对立观点的不良影响", "conclusion": "研究揭示，人格设定会引入微妙的意识形态偏见进入LLM输出，这引发了人们对在内容审查系统中使用AI系统的担忧，尤其是在看似中立的模型可能实际上促进党派观点的情况下。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25947", "html_url": "https://arxiv.org/abs/2510.25947", "title": "重新审视语言模型预训练中的多语言数据混合", "title_en": "Revisiting Multilingual Data Mixtures in Language Model Pretraining", "authors": "Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut", "background": "关于大型语言模型（LLMs）在预训练过程中使用不同多语言数据混合的影响一直是一个广泛讨论的话题，人们常常担心多语言性可能导致语言覆盖与模型性能之间的权衡（即多语言性的诅咒）。", "innovation": "该研究通过训练具有1.1B和3B参数的LLMs，研究了多种不同数量的语言（从25种到400种）的多语言语料库对模型的影响。研究发现：1) 将英语和多语言数据混合不会降低每组语言的在语言内的表现，只要每种语言在预训练语料中包含足够的令牌数量。2) 使用英语作为枢轴语言（即一种高资源语言，用于促进多语言泛化）在语言家族中具有普遍优势，实际情况表明，选择来自同一语言家族的枢轴语言并不一定提高该家族内其他语言的表现。3) 在这种规模的模型中，随着训练语言数量的增加，并未观察到明显的多语言性的诅咒。", "conclusion": "研究指出，适当的多语言数据可以增强语言模型的能力，即使在低资源设置下也不会损害其性能。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25975", "html_url": "https://arxiv.org/abs/2510.25975", "title": "SymCode: 通过可验证代码生成进行数学推理的神经符号方法", "title_en": "SymCode: A Neurosymbolic Approach to Mathematical Reasoning via Verifiable Code Generation", "authors": "Sina Bagheri Nezhad,Yao Li,Ameeta Agrawal", "background": "大语言模型（LLMs）在复杂数学推理方面经常表现不佳。它们生成的解决方案往往是未经验证且在算术上不够准确的。尽管目前的提示策略，如思维链，依然在这个不可靠的环境中运作，缺乏一种确定性验证机制。当前的方法无法提供准确性和可靠性上的保障。", "innovation": "本文提出了SymCode，这是一种神经符号框架，将数学问题解决重新定义为使用SymPy库的可验证代码生成任务。SymCode在复杂的基准测试MATH-500和OlympiadBench上得到了评估，相比于基线模型，其准确度提高了13.6个百分点。分析表明，SymCode不仅是更高效，而且还从根本上将模型出错从不透明的逻辑错误转向了透明的程序错误。", "conclusion": "通过将LLM的推理过程基于一个确定性的符号引擎，SymCode代表着在正式领域中实现更准确和可信的人工智能的关键一步。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25967", "html_url": "https://arxiv.org/abs/2510.25967", "title": "跨文化翻译中的语义标签漂移", "title_en": "Semantic Label Drift in Cross-Cultural Translation", "authors": "Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Polydoros Giannouris,Sophia Ananiadou", "background": "机器翻译（MT）广泛应用于低资源语言中，通过从高资源语言生成合成数据来应对资源稀缺问题。尽管情感保留已经在翻译中得到研究，但语义标签在跨文化翻译中受到文化差异的影响这一因素尚未充分探索。研究者发现，现代大型语言模型（LLMs）在翻译中会导致语义标签漂移，尤其是在文化敏感领域。与早期统计机器翻译工具不同，LLMs具有编码文化知识的能力，利用这些知识会进一步加剧标签漂移。语言之间文化相似性或差异性是语义标签保存的关键决定因素。因此，忽视文化因素不仅会损害标签的准确性，还可能引发下游应用中的误解乃至文化冲突。", "innovation": "论文通过一系列跨文化和非文化敏感领域的实验，提出了三个关键发现：1. 无论是现代大型语言模型还是其他MT系统，在文化敏感领域翻译过程中均会引起语义标签漂移；2. 相比于早期的统计机器翻译工具，LLMs能够编码文化知识，利用这些知识有可能加剧标签漂移；3. 源目标语言之间的文化相似性或差异性是影响语义标签保存的关键因素。", "conclusion": "研究结果强调，在机器翻译过程中忽视文化因素不仅会削弱标签的准确性，还会增加误解和文化冲突在下游应用中的风险。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25977", "html_url": "https://arxiv.org/abs/2510.25977", "title": "NeuronMM: 针对AWS Trainium 上的LLM推理的高性能矩阵乘法", "title_en": "NeuronMM: High-Performance Matrix Multiplication for LLM Inference on AWS Trainium", "authors": "Dinghong Song(1),Jierui Xu(2),Weichu Yang(2),Pengfei Su(1),Dong Li(1) ((1) University of California, Merced, (2) University of Wisconsin, Madison)", "background": "AI加速器根据AI负载量身定制，提供成本效益高且高性能的训练和推理解决方案。AWS最近开发的Trainium AI加速器因其异构架构为LLM训练和推理提供了有吸引力的选择。然而，充分利用Trainium架构的高性能具有挑战性，因为其需要Systolic阵列架构及特殊的数据布局要求。", "innovation": "该论文设计了针对Trainium上的LLM推理的高性能矩阵乘法（matmul）内核。提出了基于核融合和新颖的缓存策略的一系列定制化技术，以减少软件管理的记忆体层次结构中的数据移动，最大化SRAM带宽，并避免昂贵的矩阵转置。", "conclusion": "评估数据显示，在矩阵乘法内核层面，我们的系统显著优于AWS在Trainium上实现的最新技术，平均速度提升1.35倍（最高2.22倍），转换为端到端的LLM推理，平均速度提升1.66倍（最高2.49倍）。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25979", "html_url": "https://arxiv.org/abs/2510.25979", "title": "AttnCache：通过注意力缓存加速大语言模型预填充阶段的自我注意推理", "title_en": "AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache", "authors": "Dinghong Song(1),Yuan Feng(1),Yiwei Wang(1),Shangye Chen(1),Cyril Guyot(2),Filip Blagojevic(2),Hyeran Jeon(1),Pengfei Su(1),Dong Li(1) ((1) University of California, Merced, USA, (2) Western Digital Research, USA)", "background": "大语言模型（LLMs）在聊天、代码生成和逻辑推理等生成应用中得到广泛应用。然而，在诸如分类、问答、推荐和文本嵌入等实际工作负载场景中，仅依赖于模型的预填充阶段，即模型在不进行自回归解码的情况下编码输入序列。在这些情况下，由于自注意力计算与序列长度的平方复杂性，自注意力计算成为主要的性能瓶颈。本文观察到，从语义上不同的句子在不同层和头中会产生相似的注意力图。基于此见解，本文提出了一种框架AttnCache，通过检索和重用相似的注意力图来加速LLMs的预填充阶段推理。", "innovation": "AttnCache框架通过构建注意力图记忆数据库，并利用高效的缓存和相似性搜索技术，在推理过程中识别并重用预先缓存的注意力图，从而减少自注意力的计算开销。实验结果显示，AttnCache在CPU上实现了端到端平均1.2倍加速和注意力计算2倍加速，在GPU上实现了端到端平均1.6倍加速和注意力计算3倍加速，同时保持了几乎无损的准确度。", "conclusion": "AttnCache能够在不显著影响准确性的前提下，通过重用相似的注意力图显著提升大语言模型预填充阶段的推理速度。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25992", "html_url": "https://arxiv.org/abs/2510.25992", "title": "监督强化学习：从专家轨迹到逐步推理", "title_en": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning", "authors": "Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee", "background": "大型语言模型（LLMs）在需要多步推理的问题上常常表现不佳。对于小型开源模型，强化学习结合可验证奖励（RLVR）方法在经过多次尝试后仍未获得正确的解决方案时会失效，而监督微调（SFT）则倾向于通过逐个词的模仿产生过度拟合。", "innovation": "本文提出监督强化学习（SRL），通过将问题解决过程重新定义为生成一系列逻辑“动作”的序列。SRL使模型在每次动作前生成一个内部推理说明，并基于与SFT数据集中提取的专家动作的相似性逐步提供评分作为监督。这使得即使所有滚动测试结果错误也能提供丰富的学习信号，同时鼓励基于专家示范的灵活推理。SRL使原本无法通过SFT或RLVR学习的复杂问题变得可学，并且在强化学习（RLVR）之前使用SRL初始化训练能获得最佳整体性能。此外，SRL在推理基准之外也有效推广到自主软件工程任务，确立其作为推理导向型LLMs训练框架的稳健性与多功能性.", "conclusion": "SRL框架使小型模型能够学习以往难以通过SFT或RLVR学到的复杂问题，并且在强化学习之前使用SRL初始化训练能获得最佳整体性能。SRL还有效地推广到自主软件工程任务，确立其作为推理导向型LLMs训练框架的稳健性和多功能性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26024", "html_url": "https://arxiv.org/abs/2510.26024", "title": "重新思考跨语言对齐：在多语言LLMs中平衡转移和文化抹除", "title_en": "Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs", "authors": "HyoJung Han,Sweta Agrawal,Eleftheria Briakou", "background": "跨语言对齐（CLA）旨在使多语言表示更具兼容性，使大型语言模型（LLMs）能够无缝地在各个语言之间转移知识。然而，我们假设这一对表示一致性的追求可能会无意中导致‘文化抹除’，这会使得语言查询下应该有所差异的文化情形下的响应功能性丧失。本文通过引入一个综合的评估框架——转移-本地化平面，量化了希望的知识转移和不希望的文化抹除，系统地分析了这一权衡关系。这些方法在六个研究语言上都表现出了一致的直接受真知识传递的提高，但同时对文化定位造成了负面影响。模型内部表示的调查揭示了重要洞察：普适的事实传递和文化特定的知识在不同的模型层中最佳可调节。", "innovation": "本文提出了Surgical Steering，一种新颖的推理时方法，能够在不同的模型层分离这两种目标，通过针对性地激活转向，实现了在两个竞争维度间更好的平衡，并有效克服了现有对齐技术的局限性。", "conclusion": "现有的跨语言对齐技术在提升普适性事实传递的同时，对文化定位带来了负面影响。通过对模型内部不同层面的目标分别进行调节，本文的方法Surgical Steering成功地在两个竞争维度之间取得了较好的平衡，提高了多语言LLMs的综合性能。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26020", "html_url": "https://arxiv.org/abs/2510.26020", "title": "PORTool: 使用奖励树训练工具使用大语言模型", "title_en": "PORTool: Tool-Use LLM Training with Rewarded Tree", "authors": "Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao", "background": "当前的大语言模型（LLMs）在静态数据集上训练，能够与外部工具交互并执行多步骤、工具集成推理，产生工具调用轨迹。然而，这些模型遵循通用工具调用模式来解决查询，未能探索多种可能的解决方案，因此在动态、演化的工具调用环境中表现有限。已有研究关注于如何通过强化学习（RL）方法鼓励工具使用LLMs探索多样化的调用路径，以找到正确答案。现有的方法通常生成多个从给定查询出发的卷积路径，部分路径具有相同的初始工具调用步骤，形成树状结构。接着根据每个步骤生成正确答案的能力和成功调用工具的能力对其进行奖励。共享路径中的步骤获得相同的奖励，而同一分叉下的不同步骤则获得不同的奖励。最后，这些步骤奖励用于计算分叉相对优势，与轨迹相对优势结合，用于训练LLMs进行工具使用。实验采用17个工具来处理用户查询，涵盖时间敏感和时间不变的主题。", "innovation": "本工作提出了PORTool，这是一种强化学习方法，用于鼓励工具使用LLMs探索多种生成正确答案的调用路径。方法从生成多个给定查询的卷积路径开始，部分路径共享初始几步，形成树状结构。然后根据每个步骤的生成正确答案的能力和成功调用工具的能力对其进行奖励，共享路径中的步骤获得相同的奖励，而同一分叉下的不同步骤则获得不同的奖励。最后，这些步骤奖励用于计算分叉相对优势，与轨迹相对优势结合，用于训练LLMs进行工具使用。", "conclusion": "实验结果表明，该方法在最终准确性和调用工具步骤方面比其他训练方法有显著提升。我们还进行了消融研究，系统地证明了步骤奖励的必要性和设计的稳健性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26032", "html_url": "https://arxiv.org/abs/2510.26032", "title": "基于人工智能的放射学报告分析：偶发性甲状腺发现的流行病学及其后果", "title_en": "Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings", "authors": "Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito", "background": "在非甲状腺相关检查中发现的意外甲状腺发现（ITFs）越来越多。然而，这些发现的频率、特征以及临床后果仍不清楚。因此，本研究旨在开发、验证并部署一个基于自然语言处理（NLP）的管道来识别放射学报告中的ITFs，并评估其流行病学特征及其临床结果。", "innovation": "研究创新之处在于利用基于变换器的NLP技术，通过多种影像学模态和技术识别ITFs，并从多模态及身体区域的影像报告中提取结节特征。此外，该研究还通过逻辑回归分析确定了与ITFs相关的流行病学因素及影像学因素。研究还发现，ITFs与甲状腺结节诊断、活检、甲状腺手术和甲状腺癌诊断之间存在强烈关联，大多数癌症为乳头状癌，并且在ITFs发现后比未发现ITFs的情况下更大。这一发现强调了ITFs在甲状腺癌过诊断中的作用，并强调了标准化报道和更谨慎的随访的必要性。", "conclusion": "意外性甲状腺发现常见，并且强烈关联导致早期检测到低风险的小病灶。这些发现强调了意外性甲状腺发现可能导致甲状腺癌的过度诊断，并突显了规范化报告和更精炼的随访的必要性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26101", "html_url": "https://arxiv.org/abs/2510.26101", "title": "QCoder Benchmark: 通过基于模拟器的反馈连接语言生成和量子硬件", "title_en": "QCoder Benchmark: Bridging Language Generation and Quantum Hardware through Simulator-Based Feedback", "authors": "Taku Mikuriya,Tatsuya Ishigaki,Masayuki Kawarada,Shunya Minami,Tadashi Kadowaki,Yohichi Suzuki,Soshun Naito,Shunya Takata,Takumi Kato,Tamotsu Basseda,Reo Yamada,Hiroya Takamura", "background": "大型语言模型（LLMs）已越来越多地应用于自动编程代码生成。此项任务可以视为一种连接自然语言、人类知识和编程逻辑的语言生成任务。但是，这种任务在需要与硬件设备交互的领域中仍未得到足够的探索，比如量子编程领域。在该领域，人类程序员编写用于在量子计算机上执行的 Python 代码。", "innovation": "本文提出了 QCoder Benchmark，一种评估语言模型在量子编程中的表现并提供反馈的评估框架。该基准具有两个关键特性：一是支持使用量子仿真器环境进行评估，而不仅仅是普通的 Python 执行，能够提供领域特定的度量标准，如电路深度、执行时间和错误分类，用于指导更好的生成；二是整合了来自真实编程比赛的人编写代码提交，通过定量比较和定性分析来评估语言模型输出与人编写代码之间的差异。", "conclusion": "实验结果表明，即使是先进模型如GPT-4o也仅能达到约18.97%的准确性，强调了基准的难度。相比之下，基于推理的模型如o3达到了高达78%的准确性，超过了人类编写代码的平均成功率（39.98%）。我们发布 QCoder 基准数据集和公共评估 API，以支持进一步的研究。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26122", "html_url": "https://arxiv.org/abs/2510.26122", "title": "Reasoning Path Divergence: 一种新的度量方法和策展策略以解锁大语言模型的多样化思考", "title_en": "Reasoning Path Divergence: A New Metric and Curation Strategy to Unlock LLM Diverse Thinking", "authors": "Feng Ju,Zeyu Qin,Rui Min,Zhitao He,Lingpeng Kong,Yi R. Fung", "background": "Test-Time Scaling (TTS) 已经证明可以有效地提升大型语言模型 (LLMs) 的推理能力，但模型输出的低多样性常常成为瓶颈。这一现象部分源于常见的“一个问题，一个解决方案”（1P1S）的训练方法，这种方法提供了单一的标准答案并可能导致模型沿狭隘的推理路径发展。", "innovation": "该论文提出了一种“一个问题，多种解决方案”（1PNS）的训练范式，以便使模型接触到各种有效的推理路径，从而增加推理多样性。为了解决1PNS中的核心挑战，即可靠地测量多步骤思考链之间的语义差异，论文引入了一个步骤级的度量方法——Reasoning Path Divergence (RPD)，用于对长思考链解进行对齐和评分，以捕捉中间推理的不同之处。通过RPD，论文筛选出每个问题下的最大多样性解集，并微调了Qwen3-4B-Base。实验结果显示，与强大的1P1S基线相比，RPD选择的训练方法能产生更丰富多样的输出，并提高了pass@k的分数，平均增加了2.80%的pass@16，并在AIME24上增加了4.99%。这表明1PNS进一步放大了TTS的有效性。", "conclusion": "这些结果表明，1PNS进一步放大了TTS的有效性，使得LLM能够在推理方面展现出更广泛的多样性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26183", "html_url": "https://arxiv.org/abs/2510.26183", "title": "相似度-距离-幅度语言模型", "title_en": "Similarity-Distance-Magnitude Language Models", "authors": "Allen Schmaltz", "background": "介绍了Similarity-Distance-Magnitude (SDM) 语言模型，这是一种针对最终层SDM激活层进行二分类指令遵循任务正向校准而调整序列预测模型参数的微调模型。\n现有的只解码器预训练的Transformer语言模型通过监督微调可以轻松地转换成SDM语言模型。通过在训练中使用最终层SDM激活层估计监督下一个 token 损失的基准，并使用对比输入编码方案，以及在线生成额外的硬负例。\n与强大的监督基线相比，这导致了减少的推断搁置（即更好的统计效率）。", "innovation": "SDM语言模型是一种创新的微调技术，通过使用最终层SDM激活层的估计来调整只解码器的预训练Transformer语言模型，使得模型在指令遵循任务中表现出更高的准确性，同时减少了推断搁置现象。", "conclusion": "相比现有的监督基线，SDM语言模型显著改进了统计效率，减少了模型在指令遵循任务中的推断搁置，提升了模型的泛化能力和响应效率。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26182", "html_url": "https://arxiv.org/abs/2510.26182", "title": "MossNet: Mixture of State-Space Experts is a Multi-Head Attention", "title_en": "MossNet: Mixture of State-Space Experts is a Multi-Head Attention", "authors": "Shikhar Tuli,James Seale Smith,Haris Jeelani,Chi-Heng Lin,Abhishek Patel,Vasili Ramanishka,Yen-Chang Hsu,Hongxia Jin", "background": "大语言模型（LLMs）在自然语言处理（NLP）中的生成应用已经取得了显著进步。模型架构的趋势主要集中在高效的变压器变体或状态空间/门控循环模型（SSMs、GRMs）上。然而，现有的基于SSMs/GRMs的方法通常只模拟了一个单一的注意力头，这可能限制了它们的表现力。", "innovation": "提出了MossNet，这是一种新颖的状态空间专家混合架构，可以模拟线性多头注意力（MHA）。MossNet不仅在通道混合多层感知器（MLP）块中利用了专家混合（MoE）实现，还在时间混合的SSM核中也使用了专家混合，从而实现了多个“注意力头”。实验显示，MossNet在语言建模和下游评估中均优于相似规模和数据预算的Transformer和SSM架构。在更大规模的MossNet上进行的训练也证实了其可扩展性和优越性能。此外，MossNet在实际设备上的性能比相似规模的基线更为有利，显示出更快的运行速度和更少的资源使用。", "conclusion": "我们的结果表明，MossNet是一个有吸引力的新方向，旨在实现高效的、高性能的递归LLM架构。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26124", "html_url": "https://arxiv.org/abs/2510.26124", "title": "论论题关系对说服性文本的影响", "title_en": "On the Influence of Discourse Relations in Persuasive Texts", "authors": "Nawar Turk,Sevag Kaspar,Leila Kosseim", "background": "本文通过应用大型语言模型（LLMs）和提示工程技术，探讨了说服技术（PTs）和话语关系（DRs）之间的关系。由于没有同时标注PTs和DRs的数据集，作者以标注了19种PTs的SemEval 2023 Task 3数据集为起点，开发了基于LLMs的分类器，将每个数据集实例标记为PDTB 3.0的22种水平2类话语关系（DRs）之一。", "innovation": "研究首次结合了自然语言处理技术和话语关系标注技术，构建了多个基于LLMs的分类器，并通过不同的众数聚合策略生成了5个银质数据集，这些数据集的每个实例都有两种标记：说服技术与PDTB水平2类话语关系。这种方法为分析说服性文本中的语言模式和构建相关检测工具提供了新的视角和技术手段。", "conclusion": "实证分析表明，六个话语关系（例如因果、目的、对比、因果+信念、让步和条件）在说服性文本中尤为重要，特别是在使用带有倾向性语言、夸大或缩小、重复和引起怀疑的语言策略中。这一洞见有助于识别网络宣传与误导信息，并提高我们对有效沟通的理解。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26193", "html_url": "https://arxiv.org/abs/2510.26193", "title": "RCScore: 量化大型语言模型响应一致性", "title_en": "RCScore: Quantifying Response Consistency in Large Language Models", "authors": "Dongjun Jang,Youngchae Ahn,Hyopil Shin", "background": "目前对大语言模型（LLM）的评估往往依赖单一指令模板，忽视了模型对指令风格的敏感性，这是决定模型在实际部署中表现的关键因素。现有的评估方法无法充分揭示由于指令风格变化导致的模型性能差异。本文旨在通过一个多维度框架RCscore来量化指令风格对模型响应的影响，以更好地评估模型的性能和可靠性。", "innovation": "RCscore框架能够系统地将基准问题转化为多种指令风格，从而揭示常规评估指标未能检测到的性能变化。研究发现指令风格可以影响模型的准确率达到16.7个百分点。此外，引入了Cross-Response Similarity（CRS）方法，该方法基于RCscore评估指令风格的自一致性，与任务准确性具有强烈的关联性。研究还发现确定性解码可以产生更风格一致的输出，并且模型规模与跨风格一致性呈正相关关系。RCscore提供了一种评估指令稳健性的原则性方法。", "conclusion": "本研究通过RCscore框架揭示了指令风格对大语言模型响应影响的重要性，并提出了一个新的评估模型一致性的方法CRS，证明了稳定性和一致性作为模型可靠性的良好代理值得进一步探索。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26202", "html_url": "https://arxiv.org/abs/2510.26202", "title": "我的人类反馈中有什么？学习可解释的偏好数据描述", "title_en": "What's In My Human Feedback? Learning Interpretable Descriptions of Preference Data", "authors": "Rajiv Movva,Smitha Milli,Sewon Min,Emma Pierson", "background": "研究人员发现，人类反馈可以以不可预测且不可取的方式改变语言模型，因为从业者并未清楚理解反馈数据所编码的内容。尽管已有研究关注了特定属性的偏好（例如长度或奉承性），但在不预先假设的情况下自动提取相关特征仍具挑战性。", "innovation": "本文提出了一种方法What's In My Human Feedback？（WIMHF），通过稀疏自动编码器解释反馈数据。WIMHF不仅可以刻画数据集能够测量的偏好，还可以揭示标注者实际表达的偏好。在多个数据集上，WIMHF识别出少量可解释的特征，这些特征能够解释黑盒模型实现的最大偏好预测信号。这些特征展示了人类偏好的广泛多样性，并揭示了数据集级别的上下文作用。两种方法还能够有效数据管理与定制化：通过重新标记有害示例可显著提高安全性，而不影响整体性能；同时，可通过掌握标注者对主观特征的权重来改进偏好预测。", "conclusion": "WIMHF为从业者提供了一种以人为本的数据分析方法，帮助他们更好地理解和使用偏好数据。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26200", "html_url": "https://arxiv.org/abs/2510.26200", "title": "通过软化时间步分配保持编辑：在扩散语言模型中保留编辑", "title_en": "Don't Let It Fade: Preserving Edits in Diffusion Language Models via Token Timestep Allocation", "authors": "Woojin Kim,Jaeyoung Do", "background": "尽管扩散语言模型（DLMs）能够进行细致的调整，但在实践中它们的可控性仍然非常脆弱。在这些模型中，均匀且上下文无关的更新可能会在时间上引发token级别的波动，这会抹去先前的语义编辑并破坏逐步的精细过程，从而降低流畅性和连贯性。", "innovation": "文章识别并形式化地刻画了一个核心失败模式，即更新遗忘。为了解决这一问题，提出了一种名为Token Timestep Allocation (TTA) 的方法，该方法通过为每个token分配一个特定的时间步长调度方案，实现了软化的、基于语义的token排序。TTA方法可以通过固定策略或由任务信号驱动的自适应策略来实现，从而支持广泛的细化策略。TTA仅在推理阶段操作，可以应用于各种扩散语言模型，并自然扩展到多种监督来源。", "conclusion": "实验结果表明，通过时间步分配实施软化的token排序是解决更新遗忘和实现稳定可控的扩散文本生成的关键。该方法在情感控制任务中提高了50%以上的准确性，并将困惑度几乎减半。在解毒任务中，它将最高毒性和困惑度都显著降低。这些结果证明TTA能够有效提升扩散模型的可控性和连贯性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26205", "html_url": "https://arxiv.org/abs/2510.26205", "title": "迈向全局检索增强生成：一种面向语料库级推理的基准", "title_en": "Towards Global Retrieval Augmented Generation: A Benchmark for Corpus-Level Reasoning", "authors": "Qi Luo,Xiaonan Li,Tingshuo Fan,Xinchi Chen,Xipeng Qiu", "background": "检索增强生成（RAG）已经成为减少大型语言模型（LLMs）幻觉现象的主要方法。当前RAG的评估标准主要聚焦于局部RAG，即从一小部分文档中检索相关片段以回答仅需局部理解的问题。然而，许多实际应用需要不同的能力——全局RAG，涉及从整个文档集合中汇总和分析信息以推导出语料库级的洞察（例如，“2023年最受欢迎的前10篇论文是什么？”）。", "innovation": "本文提出GlobalQA基准，这是首个专门用于评估全局RAG能力的基准，包括四类核心任务：计数、极值查询、排序和Top-K提取。通过在不同模型和基线上的系统评估，发现现有RAG方法在全局任务上表现不佳，最强的基线 modelo 仅获得1.51 F1分数。为此，本文提出GlobalRAG，这是一种多工具协作框架，通过段落级检索保持结构一致性，结合LLM驱动的智能过滤器去除噪音文档，并整合聚合模块实现精确的符号计算。在Qwen2.5-14B模型上的结果表明，GlobalRAG相较于最强的基线提高了4.12个F1分数，验证了本方法的有效性。", "conclusion": "GlobalQA基准涵盖了四类核心任务，并通过系统评估发现现有RAG方法在全局任务上表现不佳。提出了GlobalRAG多工具协作框架，理论上和实验证明了这种框架的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26254", "html_url": "https://arxiv.org/abs/2510.26254", "title": "语言模型对借词识别无偏见：10种语言多元评估", "title_en": "Language Models Are Borrowing-Blind: A Multilingual Evaluation of Loanword Identification across 10 Languages", "authors": "Mérilin Sousa Silva,Sina Ahmadi", "background": "在语言历史上，词语经常从一种语言借入到另一种语言，并逐渐融入被接收的语言词汇系统中。双语社区中的说话者可以区分借词和本土词，特别是在一个强势语言持续向弱势语言植入词汇的情况下更为明显。本文研究了预训练语言模型，包括大型语言模型，是否也具备类似的能力来识别借词。研究者评估了这些模型在10种语言中的表现，尽管有明确指令和上下文信息作为指导，但结果显示模型在区分借词和本土词方面表现不佳。这些结果与其他研究一致，证实了现代NLP系统对借词的偏见超过了对本土词的认可。此研究就为少数民族语言的NLP工具开发以及在强势语言词汇压力下的语言保存提供了意义", "innovation": "该研究对10种语言中预训练语言模型的借词识别能力进行了多元评估，并展示了这些模型在区分借词和本土词上的表现不佳，这与以往研究结果一致，表明现代NLP系统存在对借词的偏向性。这项研究揭示了语言模型在处理语言多样性时的弱点，为未来针对弱势语言的NLP应用提供了新的视角", "conclusion": "研究结果显示，尽管提供了明确的指令和丰富的上下文信息，预训练语言模型在区分借词和本土词方面表现不佳。此发现反映了现代NLP系统中的借词偏向性，支持需要开发专门针对少数民族语言的NLP工具，并为在强势语言词压下保护语言多样性的社区提供支持"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26298", "html_url": "https://arxiv.org/abs/2510.26298", "title": "ChatGPT Atlas能否征服Web？探索在网页游戏中的前沿能力", "title_en": "Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games", "authors": "Jingran Zhang,Ning Li,Justin Cui", "background": "ChatGPT Atlas具有分析网页、处理用户意图和直接在浏览器中执行鼠标和键盘输入的新功能。尽管展示了信息检索任务的能力，但其在动态、交互式环境中的表现仍未得到充分研究。为了评估其网页交互能力，研究者选用网页游戏作为测试场景，包括Google的T-Rex Runner、数独、Flappy Bird以及其他未知游戏，并利用游戏中的表现分数作为定量指标，评估不同类型任务的表现。", "innovation": "使用网页游戏作为评估ChatGPT Atlas网页交互能力的测试场景，并通过游戏表现分数来定量评估其在不同类型任务中的表现。这种方法揭示了Atlas在逻辑推理任务中的优势和实时游戏中能力的局限性，强调了其在动态网页环境中的分析处理能力以及所需的精细交互控制之间的差距。", "conclusion": "研究表明，Atlas在逻辑推理任务如数独方面表现优异，能显著快于人类 baseline，但在需要精确时间和运动控制的实时游戏中表现不佳，往往难以进展到初始障碍之后。这些发现表明，虽然Atlas展示出了强大的分析处理能力，但在需要实时交互的动态网页环境中仍存在明显的局限性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26253", "html_url": "https://arxiv.org/abs/2510.26253", "title": "pragmatic theories enhance understanding of implied meanings in llms", "title_en": "Pragmatic Theories Enhance Understanding of Implied Meanings in LLMs", "authors": "Takuma Sato,Seiya Kawano,Koichiro Yoshino", "background": "人类交流和语言使用中准确解读隐含意义的能力至关重要，语言模型也被期望具备这种能力。本研究通过提供基于语用理论的提示，证明了这种在上下文中的学习方法在理解隐含意义任务中是有效的。研究者提出了一种方法，即通过将语用理论概览（如格赖斯语用学和相关性理论）作为提示提供给语言模型，引导其进行逐步推理，最终得出解释。结果表明，与不展示语用理论的baselines方法相比，这种方法使得语言模型在语用推理任务中的得分提高了9.6%。此外，仅在提示中提及语用理论的名字也能在大型模型中带来一定的性能提升（约1-3%）。", "innovation": "本研究提出了一种通过将语用理论作为提示提供给语言模型的方法，以增强其理解隐含意义的能力。这种方法通过对包含语用理论概览的提示进行逐步推理，使得语言模型在语用推理任务中表现出色，优于未提供此类提示的 Baselines 方法，并通过实验证明了仅仅提及这些理论的名字也能带来一定的性能提升。", "conclusion": "本研究实验结果证明，通过提供相关语用理论作为提示，语言模型能够更好地理解和处理隐含意义。即使只是简单提及这些理论的名字，也能在大型模型中带来一定的性能提升。这一研究为未来提升语言模型理解和生成隐含意义的能力提供了新的方向。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26277", "html_url": "https://arxiv.org/abs/2510.26277", "title": "LLMs何时发出正确信号？基于神经元一致性的确凿证据", "title_en": "Do LLMs Signal When They're Right? Evidence from Neuron Agreement", "authors": "Kang Chen,Yaoning Wang,Kai Xiong,Zhuoka Feng,Wenhe Sun,Haotian Chen,Yixin Cao", "background": "大型语言模型（LLMs）通常通过样本-评估-集成解码器增强推理能力，并在无需地面真实标签的情况下实现标签自由的提升。然而，现有的策略主要基于外部输出（如token概率、熵或自我评估）进行评分，这些信号在训练后可能会出现校准不良的情况。这项研究通过分析内部行为（基于神经元激活）发现了三个主要发现：（1）外部信号是内部更丰富动态的低维投影；（2）正确响应在生成过程中激活的唯一神经元远少于错误响应；（3）正确响应的激活表现出更强的跨样本一致性，而错误响应则表现出差异。这些发现表明，语言模型在正确生成时不依赖于外部信号，而更多依赖于内部激活模式。因此，研究提出了基于激活稀疏性和跨样本神经元一致性的神经元一致解码（NAD）方法。", "innovation": "研究提出了一种新的无监督解码方法——神经元一致解码（NAD），该方法不依赖于外部评分信号，而是根据内部神经元激活稀疏性和跨样本激活一致性选择候选答案。NAD能够在生成的前32个token内准确预测正确答案，并支持早期停止策略。在多个需要验证答案的数学和科学基准测试中，NAD性能与多数投票相当；而在不适用多数投票的开放性编码基准测试中，NAD表现优异，优于平均64个候选人的评分。此外，NAD通过早于其他方法识别并舍弃无前途的路径，从而极大地减少了token的使用，同时确保生成质量不会显著下降。这表明内部信号能够提供可靠且高效的无标签集成解码指导。", "conclusion": "研究发现，语言模型的正确性和内部激活模式紧密相关，并提出了基于内部激活模式选择正确候选答案的新方法NAD。NAD能够在早期阶段准确预测正确答案，实现高效的解码，并在多个基准测试中展示了其优越性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26271", "html_url": "https://arxiv.org/abs/2510.26271", "title": "蒸馏多语言视觉语言模型：当较小模型仍保持多语言能力", "title_en": "Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual", "authors": "Sukrit Sriratanawilai,Jhayahgrit Thongwat,Romrawin Chumpu,Patomporn Payoungkhamdee,Sarana Nutanong,Peerat Limkonchotiwat", "background": "视觉语言模型（VLMs）在不同语言之间表现出不均衡的性能，尤其是在模型规模减小时情况会更糟。虽然知识蒸馏（KD）在从大模型向小模型传递知识方面显示出有希望的结果，但在多语言环境下的应用尚未得到充分探索。现有的研究大多集中在单语言模型上，对于多语言模型的蒸馏行为了解不足，尤其是在模型压缩下对跨语言表示一致性和下游任务性能稳定性的影响仍然未知。", "innovation": "本文通过对比五种不同的蒸馏方法，控制地研究了它们在大小不同的VLMs中的行为，特别是如何影响跨语言表示一致性以及模型压缩下的下游任务性能稳定性。这些研究是在 CLIP 和 SigLIP2 上进行的，涉及领域内的检索和领域的视觉问答。研究发现，虽然某些配置可以保留甚至在模型规模减半的情况下改善多语言检索的鲁棒性，但其他配置则无法维持跨任务的稳定性，揭示了仅从聚合准确性无法展现的设计敏感权衡。", "conclusion": "研究结果表明，知识蒸馏在多语言视觉语言模型的蒸馏中具有潜力，但需要进一步优化以确保跨任务性能的稳定性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26336", "html_url": "https://arxiv.org/abs/2510.26336", "title": "通过自动化课程学习灌输知识：从业余到大师", "title_en": "From Amateur to Master: Infusing Knowledge into LLMs via Automated Curriculum Learning", "authors": "Nishit Neema,Srinjoy Mukherjee,Sapan Shah,Gokul Ramakrishnan,Ganesh Venkatesh", "background": "大型语言模型（LLMs）在通用任务上表现出色，但在经济学和心理学等需要深入、原理性理解的专门领域中则表现不佳。为解决这一问题，我们介绍了ACER（Automated Curriculum-Enhanced Regimen）方法，该方法能够将通用模型转变为特定领域的专家，而不牺牲它们的广泛能力。", "innovation": "ACER 通过生成特定学科的内容大纲和生成遵循布卢姆分类法的问题-答案（QA）对，合成了全面且教科书风格的课程。这确保了系统性的主题覆盖和逐渐增加的难度。生成的合成语料库用于结合课程的时间同步预训练，实现了内容和认知维度上的学习衔接。", "conclusion": "实验表明，ACER 在 Llama 3.2（1B 和 3B）的特定子集中的表现有显著提升，特别是在微经济学等具有挑战性的领域，准确性提高了 5 个百分点。在所有目标领域中，观察到一致的宏观平均改进率为 3 个百分点。ACER 不仅防止了灾难性遗忘，还促进了跨领域的正面知识迁移，提高了非目标领域的表现。ACER 的结果表明，ACER 提供了一个可扩展且有效的食谱，用于关闭大型语言模型关键领域的差距。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26322", "html_url": "https://arxiv.org/abs/2510.26322", "title": "SCRIBE：通过工具调用进行结构化链推理以实现交互行为解释", "title_en": "SCRIBE: Structured Chain Reasoning for Interactive Behaviour Explanations using Tool Calling", "authors": "Fares Fawzi,Vinitra Swamy,Dominik Glandorf,Tanya Nazaretsky,Tanja Käser", "background": "语言模型可以在教育环境中提供交互式、个性化的学生反馈。然而，在实际部署中面临三大挑战：隐私问题、计算资源有限，以及需要生成教育上有效的回应。这些限制需要小型、开源的模型，能够本地运行，并准确地将输出建立在正确信息的基础上。以往的模型难以同时解决这些问题，特别是在小型模型的教育应用中表现较差，获取有效信息的能力不足，可靠性差，且难以处理复杂的问题。", "innovation": "该研究提出了一种名为SCRIBE的框架，用于生成多跳工具增强推理，能够为学生关于反馈报告的问题提供有效的回答。该框架结合了领域专用工具和自我反思推理管道，支持迭代推理、工具使用和错误恢复。通过两阶段LoRA微调，将这些能力应用到3B和8B模型中，并使用合成GPT-4o生成的数据进行。评估表明，8B-SCRIBE模型在相关性和可操作性等关键维度上与更大的模型达到或超过同等水平，同时被学生认为与GPT-4o和Llama-3.3 70B相当。这表明，SCRIBE框架在资源有限且隐私敏感的教育应用场景中具有可行性。", "conclusion": "该研究证明了SCRIBE框架的有效性，并显示了小型、高效模型在教育应用中的潜力。这将促进在隐私受限环境中的交互反馈系统的开发和部署。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26285", "html_url": "https://arxiv.org/abs/2510.26285", "title": "探究语言模型操控数字的机制", "title_en": "Unravelling the Mechanisms of Manipulating Numbers in Language Models", "authors": "Michal Štefánik,Timothee Mickus,Marek Kadlčík,Bertram Højer,Michal Spiegel,Raúl Vázquez,Aman Sinha,Josef Kuchař,Philipp Mondorf", "background": "近期的研究表明，不同的大型语言模型（LLMs）在处理数字时会收敛到相似且准确的输入嵌入表示。然而，这些发现与已有文献中关于LLMs在处理数字信息时倾向于生成错误输出的倾向形成冲突。本研究旨在通过探索语言模型如何操控数字以及量化这些机制的准确下限来解释这一矛盾。研究表明，尽管遇到了一些错误，不同语言模型学习到了不同的但可互换的数字表示，这些表示在隐藏状态和不同类型输入上下文中的准确且具有广泛性。这使得我们能够创建适用于每个LLM的通用探针，并追踪信息来源，包括输出错误的原因，到特定的层。", "innovation": "本研究发现不同语言模型学习到的数字表示具有系统性、高度准确且在隐藏状态和不同类型的输入上下文中是普遍适用的。基于这些发现，我们提出了适用于每个LLM的通用探针，并能够追溯信息，包括导致输出错误的原因，到具体的层。此外，研究还揭示了预训练LLMs操控数字的机制，并指出了更准确的探针技术在未来LLM架构改进中的潜在价值和应用前景。", "conclusion": "我们的研究为理解预训练LLMs如何操纵数字提供了一个基本的框架，明确指出了改进LLM架构方向和潜在的准确探针技术的应用价值。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26345", "html_url": "https://arxiv.org/abs/2510.26345", "title": "MisSynth: 提升MISSCI谬误分类的合成数据", "title_en": "MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data", "authors": "Mykhailo Poliakov,Nadiya Shvai", "background": "与健康相关的错误信息很普遍且可能具有潜在的危害性。当这类信息通过歪曲或误解科学研究结果来传播时，更难于识别。研究人员探讨了合成数据生成和轻量级微调技术对大型语言模型（LLMs）识别谬误论据能力的影响，使用了MISSCI数据集和框架来开展研究。", "innovation": "本文提出了MisSynth，这是一种应用检索增强生成（RAG）生成合成谬误样本的流水线。生成的合成样本随后用于微调LLM模型。实验结果表明，微调后的模型在识别谬误论据方面比默认的基础模型表现更好。如，通过微调的LLaMA 3.1 8B模型在MISSCI测试集上的F1分数绝对提高了超过35%。此外，通过引入合成谬误数据增强有限的标注资源，可以显著提高零样本LLM在现实世界科学研究错误信息任务中的分类性能，即使是在计算资源有限的情况下。", "conclusion": "研究表明，将合成谬误数据引入以增强有限标注资源可以显著提升零样本LLM在真实世界科学研究错误信息任务中的分类性能，即使计算资源有限。该研究的代码和合成数据集可在特定网址获取。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26352", "html_url": "https://arxiv.org/abs/2510.26352", "title": "对话的几何学：绘制语言模型以揭示多智能体协作中的协同团队", "title_en": "The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic Teams for Multi-Agent Collaboration", "authors": "Kotaro Furuya,Yuichi Kitagawa", "background": "基于大型语言模型（LLMs）的多智能体方法被视为超越单个模型能力的有前途的策略，但其成功取决于团队的协同效应。然而，构建最优团队是一个重大挑战，因为大多数模型的透明度较低，隐藏了有效协作所需的内在特征。先前的方法通常依赖于对模型内部结构、训练数据或任务表现的已知信息，导致对简洁、自动的团队构建流程需求迫切。因此，本文致力于开发一种无需任何先验知识的自动团队组成方法，能够揭示功能上一致的模型组，反映了它们的潜在专门化，并能生成性能超过随机基线且与手动挑选的性能相当的团队。", "innovation": "本文提出了一种基于交互的自动团队组成框架，该框架无需任何先验信息如内部架构、训练数据或任务表现。通过构建“语言模型图”，该方法从成对对话的语义连贯性中映射模型间的关系，然后应用社区检测识别出协同的模型簇。该方法能够发现功能上协调的组，反映出模型的潜在专门化，并能够在下游基准测试中超越随机基线，达到与根据已知模型专门化手动筛选的团队相当的准确性。", "conclusion": "本文的研究为自动设计协作多智能体LLM团队提供了新基础，该方法能够在无需任何先验知识的情况下自动发现功能上一致的模型团队。这些发现表明，特定话题的引导对话能够揭示出优于随机基线且与手动筛选的团队性能相当的协同团队。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26498", "html_url": "https://arxiv.org/abs/2510.26498", "title": "一个大型语言模型多代理框架自动评估临床AI分诊工具的表现", "title_en": "A Multi-agent Large Language Model Framework to Automatically Assess Performance of a Clinical AI Triage Tool", "authors": "Adam E. Flanders,Yifan Peng,Luciano Prevedello,Robyn Ball,Errol Colak,Prahlad Menon,George Shih,Hui-Ming Lin,Paras Lakhani", "background": "该研究的背景是在非对比CT头颅检查中使用一种商业化的颅内出血AI检测工具，并旨在通过多个大型语言模型（LLM）的集体评估，来提高像素级AI分诊工具的可靠性评估，相较于单一的LLM评估方法。", "innovation": "研究创新点在于提出了一种由多种开源LLM组成的多代理框架，用于自动评估临床AI分诊工具的表现。通过对比多种LLM模型的性能，展示了开放式LLM的组合可以提供更一致和可靠的方法来得出临床AI分诊工具的回顾性评估结果，相较于单一的LLM有更好的表现。", "conclusion": "研究结论表明，中到大尺寸的开源LLM组成的集合为临床AI分诊工具提供了比单一LLM更一致和可靠的可靠性评估方法。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26354", "html_url": "https://arxiv.org/abs/2510.26354", "title": "科学写作中语境在关系分类中的作用研究", "title_en": "On the Role of Context for Discourse Relation Classification in Scientific Writing", "authors": "Stephen Wan,Wei Liu,Michael Strube", "background": "随着生成式人工智能（AI）方法在科学工作流程中的应用越来越广泛，我们对利用话语层面的信息来支持AI生成的科学声明的兴趣日益增加。初步研究的方向是探索在科学写作中推断话语结构的任务。本研究关注较少被探索的科学出版物领域，通过使用预训练语言模型（PLM）和大型语言模型（LLM）方法来进行话语关系分类（DRC）的研究，来探讨上下文对DRC任务的重要性及其具体作用类别。", "innovation": "创新在于该研究利用预训练模型和大型语言模型的方法针对科学出版物这一特定领域的DRC任务进行了初步研究，通过实验展示了上下文对于DRC任务的帮助，特别是在由话语结构定义的上下文中，同时分析了哪些科学话语关系类型可能最能从中受益。", "conclusion": "本研究的结果表明，上下文在科学写作中的DRC任务中具有普遍帮助作用，并且某些科学话语关系类型可能特别受益于这种帮助。未来的工作可以进一步探索具体的科学话语关系类型及其上下文应用的机制。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26446", "html_url": "https://arxiv.org/abs/2510.26446", "title": "1+1>2: 一种用于大型语言模型的协同稀疏和低秩压缩方法", "title_en": "1+1>2: A Synergistic Sparse and Low-Rank Compression Method for Large Language Models", "authors": "Zeliang Zong,Kai Zhang,Zheyang Li,Wenming Tan,Ye Ren,Yiyan Zhai,Jilin Hu", "background": "大型语言模型（LLMs）在语言理解和生成方面表现出色，但其广泛应用受到带宽和计算需求的限制。虽然剪枝和低秩逼近各自在LLMs上显示了有希望的表现，但它们的结合使用尚未得到充分探索。", "innovation": "该论文提出了SSLC（Synergistic Sparse and Low-Rank Compression）方法，它结合了低秩逼近和稀疏优化技术的长处：低秩逼近通过保留模型的基本结构以最小的信息损失实现压缩，而稀疏优化则消除无关紧要的权重并保留对泛化至关重要的部分。作者通过理论分析，将低秩逼近和稀疏优化统一成为一个问题，并使用迭代优化算法解决。实验表明，SSLC在LLaMA和Qwen2.5模型（7B-70B）上，无需额外的训练步骤，总是优于单独使用的方法，取得了最先进的性能。", "conclusion": "SSLC方法能够将Qwen2.5压缩50%且不降低性能，并实现至少1.63倍的速度提升，为高效部署LLMs提供了实用的解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26422", "html_url": "https://arxiv.org/abs/2510.26422", "title": "OmniEduBench: 一个全面的中文基准，用于评估大型语言模型在教育中的应用", "title_en": "OmniEduBench: A Comprehensive Chinese Benchmark for Evaluating Large Language Models in Education", "authors": "Min Zhang,Hao Chen,Hao Chen,Wenqi Zhang,Didi Zhu,Xin Lin,Bo Jiang,Aimin Zhou,Fei Wu,Kun Kuang", "background": "随着大型语言模型（LLMs）的快速发展，它们在教育领域的应用日益广泛。然而，现有的大多数LLMs及其基准主要集中在知识层面，忽视了在实际教育场景中培养能力的评估。目前的基准往往局限于单一科目或问题类型，缺乏足够的多样性，特别是在中文环境中表现得尤为突出。", "innovation": "介绍了一个全面的中文教育基准——OmniEduBench。该基准包含24602个高质量的问题-答案对，分为知识维度和培养维度，分别包含18121和6481个条目，每个维度进一步细分为6个主题类别，涵盖了61个不同的科目（知识41个和培养20个）。此外，该数据集还包含了丰富的题目格式，包括11种常见的考试题型，为全面评估LLMs的教育能力提供了坚实的基础。", "conclusion": "在广泛的实验中，11种主流的开源和闭源LLM表现出了明显的差距。在知识维度上，只有Gemini-2.5 Pro的准确率超过了60%，而在培养维度上，最优模型QWQ仍比人类智力低近30%。这些结果强调了LLM在教育中应用的巨大改进空间，并突显了应用LLM在教育中的挑战。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26484", "html_url": "https://arxiv.org/abs/2510.26484", "title": "大型语言模型的贝叶斯网络融合用于情感分析", "title_en": "Bayesian Network Fusion of Large Language Models for Sentiment Analysis", "authors": "Rasoul Amirzadeh,Dhananjay Thiruvady,Fatemeh Shiri", "background": "随着大型语言模型（LLMs）的不断进步，出现了多种针对特定领域的变体，这些变体旨在完成专门任务。然而，这些模型通常缺乏透明度和可解释性，需要大量的微调、详细的提示工程，并且跨不同领域会产生不一致的结果，同时由于高计算需求，还会带来重大的环境影响。这些挑战促使研究人员探索解决方案，以提高这些模型的可解释性和环境可持续性。", "innovation": "本文提出了一种贝叶斯网络LLM融合框架（BNLF），该框架将三种LLM（包括FinBERT、RoBERTa和BERTweet）的预测结果通过概率机制融合起来，用于情感分析。BNLF通过贝叶斯网络中的概率节点模型化来自多个LLM的情感预测，实现这些预测的晚期融合。", "conclusion": "BNLF在三项由不同人类注释的金融语料库中得以验证，结果显示BNLF的准确率比基线LLM提高了约六个百分点，这表明BNLF在不同数据集上的稳健性，并证实了概率融合在提高可解释性情感分类中的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26521", "html_url": "https://arxiv.org/abs/2510.26521", "title": "使用视觉表征的希伯来语重音恢复", "title_en": "Hebrew Diacritics Restoration using Visual Representation", "authors": "Yair Elboher,Yuval Pinter", "background": "希伯来语的无重音文本在准确读音和文本意义解析上存在高程度的歧义，尽管近年来机器学习方法显著提升了任务性能，但重音恢复仍需解决的技术难题，特别是无需复杂的语言分析来准确重音化文本的能力尚未被充分探索。", "innovation": "DIVRIT系统将重音化任务重新构架为零样本分类问题，通过分析每个未标注重音词附近的文本上下文，为每个词选择最合适的重音模式。其独特的创新在于使用希伯来视觉语言模型，该模型以图像形式处理未标注重音的文本，使得重音信息可以直接嵌入输入的向量表示中。此外，通过优化的建筑架构改进和训练策略，DIVRIT在整体泛化能力上取得了显著进步。", "conclusion": "研究证明，DIVRIT系统能够在无需复杂语言分析的情况下有效地进行重音恢复，并且在“oracle”条件下展示了高准确率。这些发现表明，视觉表示方法在准确和自动化的希伯来语重音恢复中有很好的前景。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26543", "html_url": "https://arxiv.org/abs/2510.26543", "title": "大型语言模型中关系解码线性算子的结构", "title_en": "The Structure of Relation Decoding Linear Operators in Large Language Models", "authors": "Miranda Anna Christ,Adrián Csiszárik,Gergely Becsó,Dániel Varga", "background": "这篇论文探讨了Hernandez等人在2023年引入的线性算子结构，这些结构用于在变压器语言模型中解码特定的关系事实。研究者将单关系的发现扩展到多个关系的集合，并系统地记录了它们的组织结构。", "innovation": "作者展示了，利用简单的3阶张量网络，这些关系解码器集合可以被高度压缩，而不会损失解码的准确性。为此，作者发展了一种跨评估协议，即使用每个线性解码算子对其他关系的主语进行测试。结果表明，这些线性映射并不编码不同的关系，而是提取共同的、粗略的语义特征（例如，首都可以属于国家属性，食物也可以属于国家属性）。这种基于属性的结构解释了这些操作符的压缩性和为什么它们只泛化到语义相似的新关系。", "conclusion": "因此，研究发现解释了变压器语言模型中的线性关系解码主要是基于属性的，而不是关系特定的。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26512", "html_url": "https://arxiv.org/abs/2510.26512", "title": "内部CORE-KG：结构化提示与核心关系解析在知识图谱中的评估", "title_en": "Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs", "authors": "Dipak Meher,Carlotta Domeniconi", "background": "人贩子网络越来越具备适应性并难以分析。法律案例文件提供了宝贵的洞察信息，但这些文件通常是无结构的、词汇密集的，并充满了含糊不清或不断变化的参考，这对自动化知识图谱（KG）构建构成了重大挑战。尽管最近基于大语言模型（LLM）的方法在改善固定模板方面取得了进展，但由于缺乏引导式提取和同指消解，这仍然会导致生成嘈杂且碎片化的图谱，并存在重复的节点。最近提出的CORE-KG框架通过整合一种类型感知的核心关系模块和领域导向的结构化提示，显著减少了节点重复和法律噪音。", "innovation": "CORE-KG框架引入了类型感知的核心关系模块和领域导向的结构化提示，显著减少了节点重复和法律噪音。", "conclusion": "通过系统的消融研究，我们量化了CORE-KG的关键组件对结果的贡献。结果表明，移除核心关系解析会导致节点重复增加28.32%，噪音节点增加4.32%，而移除结构化提示会导致节点重复增加4.34%，噪音节点增加73.33%。这些发现提供了设计从复杂法律文本中提取结构表示的稳健大语言模型管道的经验见解。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26577", "html_url": "https://arxiv.org/abs/2510.26577", "title": "在大规模语言模型高效推理中的基于推理成本的动态树构建", "title_en": "Inference-Cost-Aware Dynamic Tree Construction for Efficient Inference in Large Language Models", "authors": "Yinrong Hong,Zhiquan Tan,Kai Hu", "background": "大规模语言模型面临显著的推理延迟挑战，这源于它们的自回归设计和庞大的规模。为了解决这一问题，推测性解码作为一种解决方案出现，它能同时生成和验证多个标注。虽然近期的方法如EAGLE-2和EAGLE-3利用动态树结构提高了推测性解码，但它们往往忽视了诸如GPU硬件配置和批量大小之类的系统变量的影响。", "innovation": "引入了一种新的动态树解码方法叫做CAST，该方法在考虑推理成本的基础上，动态调整树结构，包括考虑GPU配置和批量大小等因素。这种方法在六种不同的任务和六种不同的LLMs上进行了全面的实验，展现了明显的效果，比传统的解码方法快5.2倍，并且在大多数情况下优于现有的最先进技术可达5%到20%。", "conclusion": "我们的研究方法通过动态调整树结构，显著提高了大规模语言模型的推理效率。实验证明，这种基于推理成本的动态树构建方法在多种任务上均表现出色，并且具有很高的性能提升潜力。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26575", "html_url": "https://arxiv.org/abs/2510.26575", "title": "InfoFlow：通过奖励密度优化强化搜索代理", "title_en": "InfoFlow: Reinforcing Search Agent Via Reward Density Optimization", "authors": "Kun Luo,Hongjin Qian,Zheng Liu,Ziyi Xia,Shitao Xiao,Siqi Bao,Jun Zhao,Kang Liu", "background": "RLVR作为一种增强自主深度搜索的方法表现出巨大潜力，但在实际应用中常常因为搜索场景中的低奖励密度受到阻碍。探索阶段会消耗大量成本，但最终奖励甚微或为零，这对RLVR的应用造成了限制。因此，该论文将这一挑战具体化为奖励密度优化问题，旨在通过优化奖励与探索成本的比例来提高搜索效果。", "innovation": "论文提出了InfoFlow系统框架，从三个方面解决奖励密度优化问题：1) 子问题分解，将长期任务分解为过程奖励，提供更密集的学习信号；2) 失败导向提示，向停滞的路径注入纠正指导，提高成功结果的概率；3) 双代理精炼，采用双代理架构减轻深度探索的认知负担，通过合成搜索历史有效压缩研究者感知的轨迹，降低探索成本和提高整体奖励密度。", "conclusion": "该框架在多个自主搜索基准测试中表现出色，显著优于基准模型，使轻量级LLM能够达到与先进专有LLM相当的性能。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26615", "html_url": "https://arxiv.org/abs/2510.26615", "title": "SlideAgent: 分层代理框架用于多页视觉文档理解", "title_en": "SlideAgent: Hierarchical Agentic Framework for Multi-Page Visual Document Understanding", "authors": "Yiqiao Jin,Rachneet Kaur,Zhen Zeng,Sumitra Ganesh,Srijan Kumar", "background": "多页视觉文档如手册、传单、演示文稿和海报，通过布局、颜色、图标和跨页引用传递关键信息。当前的大语言模型在文档理解方面提供了机会，但现有系统在处理复杂的多页视觉文档时遇到困难，特别是在对元素和页面进行细微推理方面。", "innovation": "SlideAgent 是一个多功能的代理框架，用于理解和处理多模态、多页和多布局的文档，尤其是幻灯片演示文稿。SlideAgent 采用专门的代理并将其推理分解为全局、页面和元素三个专业化层次，构建了一个结构化且查询无关的表示形式，能够捕捉宏观主题和详细的视觉或文本线索。在推断过程中，SlideAgent 选择性地激活专门的代理进行多层次推理，并将它们的输出整合成连贯且情境感知的答案。广泛的实验显示，SlideAgent 在与私有模型和开源模型的比较中都取得了显著的改进。", "conclusion": "SlideAgent 实现了显著的改进，比私有模型提高了 7.9 的整体得分，比开源模型提高了 9.8 的整体得分。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26683", "html_url": "https://arxiv.org/abs/2510.26683", "title": "Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models", "title_en": "Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models", "authors": "Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang", "background": "大型语言模型（LLMs）通过大规模预训练和精心策划的微调数据，在多个领域展现了卓越的能力。然而，在如医疗保健这样数据敏感的领域，缺乏高质量的、领域特定的训练数据集阻碍了LLMs在专门化应用中的适应性。此外，领域专家将领域智慧总结为本体规则，这些规则正式化了概念之间的关系，并确保知识管理系统的完整性。", "innovation": "提出了一种名为Evontree的新框架，利用少量高质量的本体规则系统地从原始模型中提取、验证和增强领域知识，而不依赖于广泛的外部数据集。具体来说，Evontree从原始模型中提取领域本体，使用两种核心本体规则检测不一致性，并通过自我蒸馏微调来增强精炼知识。在医学问答基准测试中，使用Llama3-8B-Instruct和Med42-v2进行的广泛实验一致地表明，相对于未修改的模型和领先的人工监督基线，该框架的性能表现出色，准确性提高了最多3.7%。", "conclusion": "结果证实了我们的方法在LLMs领域适应中具有显著的有效性、效率和鲁棒性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26622", "html_url": "https://arxiv.org/abs/2510.26622", "title": "解码器-编码器或解码器仅存？重访解码器-编码器大型语言模型", "title_en": "Encoder-Decoder or Decoder-Only? Revisiting Encoder-Decoder Large Language Model", "authors": "Biao Zhang,Yong Cheng,Siamak Shakeri,Xinyi Wang,Min Ma,Orhan Firat", "background": "最近的研究显示，大型语言模型（LLM）的架构从编码器-解码器模式转向了当前占主导地位的解码器仅存模式。尽管发生了这种快速的过渡，却没有从扩展性角度进行严格的比较分析，这引起了人们对编码器-解码器模型潜在价值被忽视的担忧。因此，本文重新审视了解码器-编码器LLM（RedLLM），并在不同的模型规模下（从约1.5亿参数到约80亿参数）将它与使用因果掩码预训练的解码器仅存LLM（DecLLM）进行了全面的对比。", "innovation": "作者通过使用带有前缀语言模型预训练的RedLLM与使用因果语言模型预训练的DecLLM进行对比实验，展示了RedLLM显著的可扩展性和出色的性能。尽管DecLLM在预训练期间更具计算效率，但RedLLM在不同扩展规模下的表现与DecLLM相当，并且在指令调优后在各种下游任务中取得了更好的结果，同时享受着显著更好的推理效率。", "conclusion": "本研究希望其发现能够激励更多关于重新审视RedLLM的工作，以挖掘其开发强大而高效的LLM的潜力。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26692", "html_url": "https://arxiv.org/abs/2510.26692", "title": "Kimi Linear：一种表达性和高效性兼备的注意力架构", "title_en": "Kimi Linear: An Expressive, Efficient Attention Architecture", "authors": "Kimi Team:Yu Zhang,Zongyu Lin,Xingcheng Yao,Jiaxi Hu,Fanqing Meng,Chengyin Liu,Xin Men,Songlin Yang,Zhiyuan Li,Wentao Li,Enzhe Lu,Weizhou Liu,Yanru Chen,Weixin Xu,Longhui Yu,Yejie Wang,Yu Fan,Longguang Zhong,Enming Yuan,Dehao Zhang,Yizhi Zhang,T.Y. Liu,Haiming Wang,Shengjun Fang,Weiran He,Shaowei Liu,Yiwei Li,Jianlin Su,Jiezhong Qiu,Bo Pang,Junjie Yan,Zhejun Jiang,Weixiao Huang,Bohong Yin,Jiacheng You,Chu Wei,Zhengtao Wang,Chao Hong,Yutian Chen,Guanduo Chen,Yucheng Wang,Huabin Zheng,Feng Wang,Yibo Liu,Mengnan Dong,Zheng Zhang,Siyuan Pan,Wenhao Wu,Yuhao Wu,Longyu Guan,Jiawen Tao,Guohong Fu,Xinran Xu,Yuzhi Wang,Guokun Lai,Yuxin Wu,Xinyu Zhou,Zhilin Yang,Yulun Du", "background": "该研究介绍了Kimi Linear，一种混合线性注意力架构，首次在多种场景下（包括短上下文、长上下文和强化学习扩展模型）在公平比较中优于全注意力机制。Kimi线性架构的核心是Kimi Delta Attention (KDA)，这是一种扩展了Gated DeltaNet的模块，加入了更精细的门控机制，使得有限状态RNN内存的有效利用更加高效。该研究还提出了一种专为Kimi Linear优化的分块算法，通过特定的Diagonal-Plus-Low-Rank (DPLR) 矩阵变体，降低了计算量并保持了更经典狄拉克规则的一致性。", "innovation": "Kimi Linear架构包括Kimi Delta Attention (KDA)，该模块通过细粒度门控机制扩展了Gated DeltaNet，提高了有限状态RNN内存的利用率。此外，分块算法通过特定的DPLR矩阵变体实现了高硬件效率，计算量减少但保持了经典狄拉克规则的一致性。Kimi Linear预训练模型在3B激活参数和48B总参数的基础上表现优于全MLA模型，特别是在更长输入和输出长度的任务上。", "conclusion": "实验表明，Kimi Linear在各种任务上表现显著优于全MLA模型，同时减少了KV缓存的使用并提高了解码吞吐量。研究结果表明，Kimi Linear可以作为全注意力架构的高性能替代品，并且已经开源了KDA内核和vLLM实现，还发布了预训练和指令调优模型的检查点以支持进一步研究。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26697", "html_url": "https://arxiv.org/abs/2510.26697", "title": "实现真正的端到端语言模型：迈向无需手动解码", "title_en": "The End of Manual Decoding: Towards Truly End-to-End Language Models", "authors": "Zhichao Wang,Dongyang Ma,Xinting Huang,Deng Cai,Tian Lan,Jiahao Xu,Haitao Mi,Xiaoying Tang,Yan Wang", "background": "现有的大型语言模型（LLMs）的‘端到端’标签只是一种错觉。实际上，这些模型在解码过程中依赖于一个非可微的过程，并且需要通过手动调整超参数（如温度和top-p）来实现微调，这极大地增加了部署的复杂性。研究发现，这种解码过程并非完全自动化，而是需要人工干预，限制了模型在实际应用中的灵活性。", "innovation": "本文提出了AutoDeco，一种创新的架构，能够实现真正的‘端到端’解码。AutoDeco通过学习如何控制自己的解码策略，消除了人工调整解码参数的需求。该模型在每一步都预测出上下文相关的温度和top-p值，将其解码过程转变为一个参数化的、基于TOKEN的过程，从而使模型能够在单个前向传递中自我调节采样策略。通过在八个基准测试上的广泛实验，AutoDeco不仅显著优于默认的解码策略，而且达到了一个操作上可行的上限，即一次从测试集中破解并调优的优越性。此外，研究还发现，模型具备基于指令的解码控制能力，能根据自然语言指令（如“降低随机性”）逐TOKEN进行温度和top-p值的调整。", "conclusion": "AutoDeco不仅证明了新的解码策略在性能上的优越性，还提出了新的解码范式，使得模型能够在与用户交互时进行更灵活、更有控制的解码。这种方法为语言模型的开发提供了新的方向，使其更加适应人类的需求和应用场景。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26768", "html_url": "https://arxiv.org/abs/2510.26768", "title": "AMO-Bench: 大型语言模型在高中数学竞赛中仍面临挑战", "title_en": "AMO-Bench: Large Language Models Still Struggle in High School Math Competitions", "authors": "Shengnan An,Xunliang Cai,Xuezhi Cao,Xiaoyu Li,Yehao Lin,Junlin Liu,Xinxuan Lv,Dan Ma,Xuanlin Wang,Ziwen Wang,Shuang Zhou(Alphabetical order by last name)", "background": "现有基准测试大多通过高中数学竞赛来评估大型语言模型（LLM）的数学推理能力，但随着LLM性能的饱和（如AIME24/25），许多现有的数学竞赛不再有效评估顶级LLM。因此，需要更严格的挑战，以确保所有50个问题均符合国际数学奥林匹克（IMO）难度标准，并且完全原创以防止数据记忆导致的性能泄漏。", "innovation": "AMO-Bench通过引入50个完全原创且跨专家验证的、至少达到IMO难度标准的问题，为LLM提供了一个更严格的数学推理基准测试，每个问题仅需给出最终答案以实现自动和稳健的评分。实验结果表明，即使在26个LLM中最优秀的模型也只能在AMO-Bench上达到52.4%的准确率，大多数LLM得分低于40%。此外，随着测试时计算资源的增加，显示出了有望提高性能的趋势。", "conclusion": "这些结果突显了当前LLM在数学推理方面仍有相当大的改进空间。AMO-Bench旨在促进语言模型推理能力的进一步研究与发展。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26790", "html_url": "https://arxiv.org/abs/2510.26790", "title": "Gistify！通过运行时执行实现代码库级理解", "title_en": "Gistify! Codebase-Level Understanding via Runtime Execution", "authors": "Hyunji Lee,Minseon Kim,Chinmay Singh,Matheus Pereira,Atharv Sonwane,Isadora White,Elias Stengel-Eskin,Mohit Bansal,Zhengyan Shi,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan,Lucas Caccia", "background": "随着编码代理在大型代码库中的应用越来越多，自动设计基于代码库层面的挑战性评估变得尤为重要。为此，研究需要设计一种能够评估编码模型对代码库整体理解能力的方法。", "innovation": "我们提出Gistify任务，要求编码的LLM创建一个单一、最小且自包含的文件，该文件能重现代码库中的特定功能。编码的LLM可以完全访问代码库及其特定入口点（例如，一个Python命令），生成的文件必须能够复制在完整代码库下运行该命令时的输出，同时仅包含执行该命令所必需的最小组件。成功完成Gistify任务需要理解代码库结构、精确模拟其执行流程以及生成大型代码补丁的能力。研究发现，当前最先进的模型在解决Gistify任务时表现不佳，特别是在那些具有长期执行跟踪的任务上。", "conclusion": "当前的最先进模型难以可靠地解决Gistify任务，尤其是在长期执行跟踪的任务上。研究结果强调了评估大型代码库中编码模型完整理解能力的重要性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26707", "html_url": "https://arxiv.org/abs/2510.26707", "title": "价值漂移：追踪LLM后训练中的价值对齐", "title_en": "Value Drifts: Tracing Value Alignment During LLM Post-Training", "authors": "Mehar Bhatia,Shravan Nayak,Gaurav Kamath,Marius Mosbach,Karolina Stańczak,Vered Shwartz,Siva Reddy", "background": "随着大型语言模型（LLM）在社会中的作用变得越来越重要，它们需要处理不仅依赖于一般知识的问题，还要与人类价值系统保持一致的问题。因此，研究LLM与人类价值观的对齐变得尤为重要。然而，现有的研究多集中于评估完全训练好的模型的价值对齐情况，却忽视了模型学习表达人类价值观的过程。本文旨在探讨在模型后训练过程中，价值对齐如何产生，以及在哪个阶段产生。实验涉及不同规模的Llama-3和Qwen-3模型，以及流行的监督微调（SFT）和偏好优化数据集和算法。", "innovation": "本文创新之处在于，通过追踪大型语言模型在后训练过程中价值的对齐情况，明确了算法和数据在价值对齐中的角色，以及不同偏好优化算法会导致不同的价值对齐结果。研究结果显示，SFT阶段通常构建了模型的价值，而后续的偏好优化较少重新调整这些价值观。此外，使用一个可以控制改变价值的合成偏好数据集，发现即使偏好数据相同，不同的偏好优化算法也导致不同的价值对齐结果。", "conclusion": "研究成果为了解价值学习在后训练过程中的表现提供实际指导，并有助于数据管理和优选模型及算法，以提高模型与人类价值观的对齐程度。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25798", "html_url": "https://arxiv.org/abs/2510.25798", "title": "MemEIC: 朝着连续和组合式知识编辑迈出的一大步", "title_en": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing", "authors": "Jin Seong,Jiyun Park,Wencke Liermann,Hongseok Choi,Yoonji Nam,Hyun Kim,Soojong Lim,Namhoon Lee", "background": "信息的动态特性要求不断更新大型视觉语言模型（LVLMs）。尽管最近的知识编辑技术暗示了一些前景，但它们通常集中在单独编辑视觉或语言单一模态。这种做法忽视了LVLMs固有的多模态特性和知识更新的连续性，可能导致在考虑模态间的交互作用以及需要持续的知识精炼时的编辑效果不佳。", "innovation": "为了解决这些问题，本文提出了一种名为MemEIC的新型方法，用于LVLMs的连续和组合式知识编辑（CCKE）。MemEIC能够依次对视觉和文本知识进行组合编辑，采用了混合外部-内部编辑器，包含跨模态证据检索的双重外部记忆和实现每个模态参数独立更新的双重LoRA适配器。关键组件是一个仿生知识连接器，仅在组合推理时被激活，用于整合不同模态的信息。", "conclusion": "实验表明，MemEIC显著提高了复杂多模态问题的性能，有效地保留了先前的编辑，为LVLMs中的CCKE设定了新的基准。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25884", "html_url": "https://arxiv.org/abs/2510.25884", "title": "使用多评判者学习系统近似人类偏好", "title_en": "Approximating Human Preferences Using a Multi-Judge Learned System", "authors": "Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer", "background": "将基于LLM的评判者与人类偏好对齐是一个重大的挑战，因为它们难以调校且通常受到评分标准敏感性、偏见和不稳定的影响。克服这一挑战能够推动关键应用，如创建可靠的基于人类反馈的强化学习奖励模型（RLHF）和构建有效的路由系统，以选择最适合的模型来应对用户的查询。", "innovation": "本文提出了一种框架，通过学习聚集多个评分标准条件下评判者的输出以建模多样化的角色偏好。该方法的两个独特实现包括通用加法模型（GAM）和多层感知机（MLP），并与其他简单基线进行了比较，同时通过人类和LLM评判者偏见的案例研究评估了其稳健性。", "conclusion": "主要贡献包括一种基于角色的方法来大规模合成偏好标签以及两种不同的聚合器实现：通用加法模型（GAM）和多层感知机（MLP）。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25860", "html_url": "https://arxiv.org/abs/2510.25860", "title": "透过法官的眼睛：推断出的思维轨迹提高LLM评分者的可靠性", "title_en": "Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters", "authors": "Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei", "background": "大型语言模型（LLMs）越来越多地被用作评估任务的评分员。然而，在一些需要主观判断的任务中，其可靠性往往较低，尤其是当人类判断涉及到超越标记标签的细微推理时。判断的思维轨迹是高度信息性的，但收集和整理思维轨迹具有挑战性。", "innovation": "本文提出了一种人-LLM协作框架，用于从仅标有标签的注释中推断出思维轨迹。框架使用简单的简易拒绝采样方法在大规模上重新构建这些轨迹。推断出的思维轨迹被应用于两种互补任务：（1）微调开放的LLM评分员；（2）合成更清晰的注释指南以供专有LLM评分员使用。这种方法在多个数据集上显著提高了LLM与人类评分员的一致性，并导致不同LLM模型之间的评分一致性提高。", "conclusion": "结果表明，LLMs可以作为实际代理，揭示其他未显现的人类思维轨迹，使得仅标签语料库能够扩展为包含思维轨迹增强资源，从而提高LLM评分员的可靠性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25797", "html_url": "https://arxiv.org/abs/2510.25797", "title": "通过时空分析和空间注意网络增强 underwater 对象检测", "title_en": "Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks", "authors": "Sai Likhith Karri,Ansh Saxena", "background": "该研究旨在评估时空建模在水下对象检测中的有效性，特别是在集成空间注意力机制的深度学习模型中的应用。研究了现有的YOLOv5和T-YOLOv5模型的性能，并开发了一种新的T-YOLOv5模型，该模型通过添加Convolutional Block Attention Module (CBAM)来增强检测能力。研究强调了在动态海洋环境中，通过时空建模如何改善物体检测的准确性，特别是在突然移动、部分遮挡和缓慢运动的情况下。实验结果显示，在mAP@50-95指标上，YOLOv5达到了0.563的精度，而T-YOLOv5和T-YOLOv5与CBAM相结合的精度分别为0.813和0.811，这表明采用这些改进模型的检测性能更高且更具普适性。", "innovation": "创新点在于通过引入时空模型和空间注意力机制的模型（如T-YOLOv5和T-YOLOv5与CBAM的结合），提高了在动态海洋环境中的水下对象检测的准确性。这些模型在处理突然移动、部分遮挡和缓慢运动等复杂情况时表现尤为突出。此外，研究还展示了在简单情景下，尽管有损失，但T-YOLOv5和T-YOLOv5与CBAM的集成模型的识别可靠性仍然显著提升。", "conclusion": "研究表明，T-YOLOv5在检测水下复杂对象方面已经显著提高了检测可靠性，而T-YOLOv5与CBAM的结合进一步优化了在复杂场景中的性能。然而，在较为简单的情景下，虽然有轻微的精度下降，但总体性能仍然有所提升。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26037", "html_url": "https://arxiv.org/abs/2510.26037", "title": "SIRAJ: 通过提炼结构化推理实现LLM代理高效多元红队测试", "title_en": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "authors": "Kaiwen Zhou,Ahmed Elgohary,A S M Iftekhar,Amin Saied", "background": "语言模型（LLM）代理在规划和调用工具的能力上面临着新的安全风险，这使得一个全面的红队系统至关重要，用于发现漏洞并确保其安全部署。现有的风险管理和测试方法需要进一步改进以应对这些新挑战。", "innovation": "本文提出了SIRAJ：一种针对任意黑盒LLM代理的通用红队框架。引入了动态两步过程，首先定义代理并生成多样化的种子测试用例以覆盖各种风险结果、工具使用轨迹和风险来源。接着，基于前一次尝试的执行轨迹迭代构建和改进基于模型的对抗攻击。通过采用模型蒸馏方法，利用教师模型推理的结构化形式来训练同等有效的较小模型，从而优化红队测试的成本。", "conclusion": "在不同的评估代理设置中，种子测试案例生成方法覆盖风险结果和工具调用轨迹的效率提升了2-2.5倍。蒸馏的8B红队模型在攻击成功率上超过了671B的Deepseek-R1模型，达到了100%的成功率。消融实验和分析验证了迭代框架、结构化推理和红队模型的通用性有效性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25932", "html_url": "https://arxiv.org/abs/2510.25932", "title": "假零：面向Facebook和X的实时、保隐私的虚假信息检测", "title_en": "FakeZero: Real-Time, Privacy-Preserving Misinformation Detection for Facebook and X", "authors": "Soufiane Essahli,Oussama Sarsar,Imane Fouad,Anas Motii,Ahmed Bentajer", "background": "社交媒体平台以前所未有的速度传播信息，导致虚假信息的传播加速，危害公众对话。为了应对这一问题，该研究提出了FakeZero，这是一个完全基于客户端、跨平台的浏览器扩展，在用户滚动时标记不实帖子。所有计算、DOM抓取、分词、Transformer推理和UI渲染都在本地通过Chromium消息API进行处理，不泄露个人数据。该研究利用了三阶段训练课程：基础微调和增强领域适应性训练，通过焦点损失、对抗性增强和后训练量化进一步优化。", "innovation": "该研究开发了名为FakeZero的浏览器扩展，用于实时检测Facebook和X（原Twitter）上的虚假信息，并以最小资源预算实现高精度检测。研究采用了三阶段训练课程，包括基础微调、领域适应训练、焦点损失、对抗性增强和后训练量化，显著提升了检测模型的性能。此外，研究还提出了一个内存高效版本的TinyBERT-Quant模型，不仅保持了高精度，还大幅降低了模型大小和延迟，展示了在资源受限的情况下进行高质量虚假新闻检测的可行性。", "conclusion": "该研究证明了在保证用户隐私的前提下，实时检测虚假信息的可行性。假零扩展可以在用户同意的情况下，提供实时的检测结果，并为研究人员收集真实世界中的虚假新闻数据提供可能，从而进一步改进检测技术。这种扩展工具对于政策制定者来说是一个有价值的工具，有助于遏制虚假信息在社交网络上的传播。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识蒸馏（KD）是模型压缩和模型间知识传递的有效方法。然而，其对模型在面对分布外数据时对抗虚假相关性能力的影响尚未得到充分研究。这项研究探讨了知识蒸馏对自然语言推理（NLI）和图像分类任务中去偏见能力在教师模型到学生模型之间的转移性的影响。研究表明，知识蒸馏后模型的去偏见能力受到削弱；去偏见模型的训练无法从教师的知识中受益；尽管模型的整体鲁棒性可能保持稳定，不同类型偏差的变化可能会显著；并且指出了导致这些行为差异的内部注意模式和电路。", "innovation": "这是首个大规模研究知识蒸馏对去偏见影响及其内部机制的论文。通过提出三种有效的解决方案来改善去偏见方法的可蒸馏性：开发高质量数据进行增强、实施迭代知识蒸馏、用教师模型的权重初始化学生模型。", "conclusion": "研究结果提供了对知识蒸馏工作原理的理解，以及如何设计更好的去偏见方法的见解。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS: 通过自我蒸馏偏好导向冷启动解耦多模态学习", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "近期，具有可验证奖励的强化学习（RL）推动了‘MLLM-r1’方法的发展，将RL引入视觉语言模型。大多数代表性的范式从冷启动开始，通常使用监督微调（SFT）初始化策略，然后再进行RL。然而，基于SFT的冷启动可能会导致指令风格的过度拟合，削弱了分布外泛化能力，并最终影响下游RL。冷启动的训练方法和数据构建被重新审视，引入了通用因子（GF）系数来量化不同方法下的泛化能力。实验发现偏好导向训练方法（如DPO）在冷启动中表现更好，因此提出了SPECS框架，这是一种自我蒸馏、偏好导向的冷启动框架，实现了多模态学习的解耦：通过自我蒸馏生成内省性偏好数据对，避免依赖更大的教师模型或人工标注；进行偏好导向的训练，专注于学习浅层次、转移性的表面形式标准而非内容记忆；最后将RL与可验证的奖励结合起来，以得到深入推理的结果。实验结果表明，解耦学习框架在多个多模态基准测试中相对于强大基线表现出一致的性能提升，分别在MEGA-Bench和MathVista上提高了4.1%和12.2%。额外的实验表明SPECS降低了分布内“卡住”的情况，提高了探索性，稳定了训练，并提高了性能天花板。", "innovation": "提出了SPECS框架，这是一种自我蒸馏、偏好导向的冷启动框架，通过解耦多模态学习实现了以下创新点：1. 通过自我蒸馏生成内省性偏好数据对，避免对更大教师模型或人工标注的依赖；2. 进行偏好导向的训练，专注于浅层次、转移性的表面形式标准而非内容记忆；3. 最后将RL与可验证的奖励结合起来，以得到深入推理的结果。", "conclusion": "SPECS框架在多模态基准测试中表现出了一致的性能提升，并且在多个方面（如分布内卡住情况、探索性、训练稳定性和性能天花板）上都取得了积极的结果。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26143", "html_url": "https://arxiv.org/abs/2510.26143", "title": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math", "title_en": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math", "authors": "Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou", "background": "近年来，强化学习（RL）在大规模语言模型（LLMs）中能够激发强大的推理能力，但多数开放努力主要集中在数学和编程领域。论文提出了一种名为‘推理课程’的简单两阶段课程，旨在通过联合RL在多个领域中逐步培养和提升LLMs的推理技能。", "innovation": "提出了一种简单的两阶段课程，第一阶段通过数学领域中的RL训练来发展推理技能，第二阶段通过联合RL在混合领域数据中转移和巩固这些技能。此课程简单且与基础模型无关，仅需标准的可验证性校验之外的标准奖励模型。实验表明，推理课程在Qwen3-4B和Llama-3.1-8B上表现出一致的性能提升，并且通过消融实验和认知技能分析证明了两阶段方法的必要性。", "conclusion": "推理课程提供了一个简化的、易于实施的方法，用于在LLMs中培养广泛的推理能力。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26095", "html_url": "https://arxiv.org/abs/2510.26095", "title": "ORBIT - 开放推荐基准测试（公开研究与隐藏测试）", "title_en": "ORBIT - Open Recommendation Benchmark for Reproducible Research with Hidden Tests", "authors": "Jingyuan He,Jiongnan Liu,Vishan Vishesh Oberoi,Bolin Wu,Mahima Jagadeesh Patel,Kangrui Mao,Chuning Shi,I-Ta Lee,Arnold Overwijk,Chenyan Xiong", "background": "推荐系统是影响最广泛的AI应用之一，每天与数十亿用户互动，提供符合用户偏好的产品、服务或信息。然而，推荐系统的研究和开发受到现有数据集无法捕捉到真实用户行为以及评估设置不一致导致结论模糊的限制。", "innovation": "ORBIT 提出了一个统一基准，用于一致和现实地评估推荐模型。ORBIT 提供了标准化的评估框架，包括可重现的拆分和透明的设置，及其公共排行榜。它引入了一个新的网页推荐任务 ClueWeb-Reco，包括来自 8700 万个公共高质量网页的真实浏览序列数据，这些数据由用户同意且隐私保护。ClueWeb-Reco 作为排行榜的隐藏测试部分，用于挑战推荐模型的泛化能力。ORBIT 在公共基准上评估了 12 种代表性推荐模型，并在 ClueWeb-Reco 隐藏测试上提出了提示的 LLM 基准。基准结果反映在公共数据集上的推荐系统的一般改进，但个体表现差异。隐藏测试的结果揭示了现有方法在大规模网页推荐中的局限性，并强调了 LLM 结合的潜在改进空间。", "conclusion": "ORBIT 基准测试、排行榜和代码库可以在该网址获取。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26190", "html_url": "https://arxiv.org/abs/2510.26190", "title": "SP-MCQA：超越字级水平评估TTS的可理解性", "title_en": "SP-MCQA: Evaluating Intelligibility of TTS Beyond the Word Level", "authors": "Hitomi Jin Ling Tee,Chaoren Wang,Zijie Zhang,Zhizheng Wu", "background": "现有的TTS（文本转语音）可理解性评估方法存在瓶颈，因为它们主要依赖于字级准确性的度量标准，如WER（单词错误率），而这些标准无法捕捉现实世界语音的复杂性，也不反映人类的理解需求。", "innovation": "提出了一种新的主观评估方法——Spoken-Passage Multiple-Choice Question Answering（口语段落多项选择题作答），用于评估合成语音中的关键信息准确性，并发布了一个包含8.76小时的新闻风格基准数据集SP-MCQA-Eval用于口语段落多项选择题评估。实验表明低WER并不一定保证高关键信息准确性，暴露了传统度量标准与实际可理解性之间的差距。SP-MCQA证明即使最先进的模型也缺乏稳健的文本规范化和音素准确性。", "conclusion": "本研究强调了在许多系统已经在WER上表现出色但可能在现实世界中的可理解性上有欠缺的情况下，现在迫切需要更高层次、更接近现实生活场景的评估标准。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26241", "html_url": "https://arxiv.org/abs/2510.26241", "title": "时间之流朝哪个方向？一种基于心理物理学的视觉语言模型评估", "title_en": "Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models", "authors": "Shiho Matta,Lis Kanashiro Pereira,Peitao Han,Fei Cheng,Shigeru Kitazawa", "background": "现代视听说结合模型（VLMs）在多项多模态任务中表现出色，但它们对于视频中的时间信息的理解仍然较弱，且这一点尚未充分评估。", "innovation": "本文通过一个简单但揭示性的挑战，即判断视频是正放还是倒放，来研究这一差距。引入了AoT-PsyPhyBENCH基准测试，这是一个基于心理物理学验证的方法，测试VLMs是否能够从自然视频中推断出时间方向，并提供了开放源代码和专有模型的全面评估结果，揭示了当前大多数模型只能达到随机水平，而最好的模型即便在这种测试中也远远落后于人类的表现。", "conclusion": "这些结果强调了当前多模态系统中的一个根本性差距：虽然它们能够捕捉丰富的视觉语义关系，但在时间连续性和因果理解方面缺乏必要的归纳偏置。文章还发布了AoT-PsyPhyBENCH的代码和数据，以鼓励进一步提高VLMs的物理和时间推理能力。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26167", "html_url": "https://arxiv.org/abs/2510.26167", "title": "一种模型批驳一切：通过高效推理奖励有代理工具使用", "title_en": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning", "authors": "Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang", "background": "奖励模型（RMs）对于将大型语言模型（LLMs）与人类偏好对齐至关重要。但在工具学习领域，专门设计的功能调用任务奖励模型的缺失限制了更加能干的有代理AI的发展。为了应对这一挑战，论文介绍了ToolRM，一种专门针对通用工具使用场景的轻量级生成奖励模型.", "innovation": "论文提出了一种新的流程以构建奖励数据：基于规则评分和多维采样的配对偏好数据构造方法。此外，还引入了TRBench$_{BFCL}$，这是一个基于BFCL的有代理评估套件。Training数据集ToolPref-Pairwise-30K使得模型在配对奖励判断方面显著超越Claude 4和OpenAI o3等前沿模型，并增强了更广泛的批判任务，包括Best-of-N采样和自我修正。实验还显示其在推理时的高效性，减少了66%以上的输出词元使用.", "conclusion": "在构建数据集的基础上训练的模型，如Qwen3-4B/8B系列，在配对奖励判断中准确率提高了14.28%，并且还展示了在ACEBench上的有效性和效率，通过推理时间的扩展和减少66%以上的输出词元使用，提升了泛化能力。论文还发布了数据和模型检查点以促进未来的研究."}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26006", "html_url": "https://arxiv.org/abs/2510.26006", "title": "CAVE: 在视觉环境中检测和解释常识性异常", "title_en": "CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments", "authors": "Rishika Bhagwatkar,Syrielle Montariol,Angelika Romanou,Beatriz Borges,Irina Rish,Antoine Bosselut", "background": "人类能够自然地识别、推理和解释环境中的异常。在计算机视觉领域，这一长期挑战仅限于工业缺陷或不现实、合成生成的异常，未能捕捉到现实世界异常的丰富性和不可预测性。本文旨在构建一个基准（CAVE），首次用于真实场景中的视觉异常检测，提出了异常描述、解释和证明三个开放任务，并附带细粒度的注释用于视觉定位、分类异常、以及根据其视觉表现、复杂性、严重性和常见性进行归类。这些注释受到认知科学研究的启发，能够为视觉-语言模型（VLMs）在检测和理解异常方面提供全面的评估框架。不幸的是，现有的先进VLMs在视觉异常感知及常识推理方面表现不佳，即使有高级提示策略的帮助也未能胜任。因此，真实且认知基础的基准（CAVE）为视觉异常检测和常识推理的研究进展提供了宝贵的资源。", "innovation": "首次构建了一个涉及真实世界视觉异常的基准（CAVE），提出了异常描述、解释和证明三个开放任务；引入了详细的注释策略，涵盖了视觉定位、异常分类及其表现、复杂性、严重性和常见性等多个维度；借鉴认知科学的研究成果，构建了评估VLMs感知和理解异常的新框架；证明了现有最先进的VLMs在视觉异常感知及常识推理方面的不足，并为后续研究提供了有价值的参考。", "conclusion": "通过提供一个真实且认知基础的基准（CAVE），本研究显著推进了视觉异常检测和常识推理领域的发展，尤其对于VLMs的性能改进具有重要意义。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26274", "html_url": "https://arxiv.org/abs/2510.26274", "title": "PVMark：使大型语言模型水印方案具备公开验证性", "title_en": "PVMark: Enabling Public Verifiability for LLM Watermarking Schemes", "authors": "Haohua Duan,Liyao Xiang,Xin Zhang", "background": "现有的大型语言模型（LLMs）水印方案能够识别生成文本的来源，以减轻模型盗窃带来的潜在威胁。然而，当前的水印解决方案无法有效地解决信任问题：不具备公共性特征的水印检测无法使用户确信该过程是透明可靠的。因此有必要开发一种能够在不泄露任何机密密钥的情况下，使水印检测过程能够由第三方公开验证的方法。", "innovation": "提出了一种基于零知识证明（ZKP）的插件PVMark，它允许第三方公共验证水印检测过程，同时并不泄露任何机密密钥。这种插件依赖于保证水印检测执行正确的证明，并从中构建了一系列ZKP约束条件，包括映射、随机数生成、比较和求和。", "conclusion": "通过多种编程语言和不同方案的实现，并结合实验结果表明，PVMark不仅在各种情况下都非常有效，而且在不损害水印检测性能的前提下使最先进的LLM水印方案具备了公开验证性，有望实际部署。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26423", "html_url": "https://arxiv.org/abs/2510.26423", "title": "Nexus：基于执行的多智能体测试预言合成", "title_en": "Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis", "authors": "Dong Huang,Mingzhe Du,Jie M. Zhang,Zheng Lin,Meng Luo,Qianru Zhang,See-Kiong Ng", "background": "非回归测试中测试预言生成一直是一个长期存在的软件工程挑战，目标是生成能够准确判断待测函数(FUT)在给定输入下是否按预期行为的测试预言。", "innovation": "本文引入了Nexus，这是一种新颖的多智能体框架，旨在应对这一挑战。Nexus通过利用一系列专门的智能体，采用结构化的争议、验证和迭代自我改进过程来生成测试预言。Nexus通过执行基于执行的检查和自动自我改进循环来提高预言准确性，即使在预言失败的情况下也能进行调试和更正。", "conclusion": "对七个不同基准的全面评估表明，Nexus在测试级别预言准确性方面始终显著超越最新基准线。例如，Nexus将LiveCodeBench上的GPT-4.1-Mini测试级别预言准确性从46.30%提高到57.73%。改进的准确性也显著提高了下游任务：Nexus生成的测试预言在HumanEval上的bug检测率从90.91%提高到95.45%，而自动化程序修复的成功率则从35.23%提高到69.32%。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26606", "html_url": "https://arxiv.org/abs/2510.26606", "title": "大型语言模型中的规范推理：从逻辑和模态视角的比较基准", "title_en": "Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives", "authors": "Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada", "background": "规范推理涉及义务和许可等规范或功利模式，而大规模语言模型（LLMs）在多种推理任务中已经展现出卓越的能力，但它们在处理规范推理方面的能力仍没有被充分探索。", "innovation": "该研究系统评估了LLMs在规范领域的推理能力，从逻辑和模态两个角度进行了比较。通过将规范模态与知识模态进行对比，提出了一个涵盖规范与知识领域广泛形式推理模式的新数据集，并引入非形式的认知因素来影响人类推理。", "conclusion": "虽然LLMs一般遵循有效的推理模式，但在特定类型的规范推理中表现出明显的不一致性，并表现出类似于人类推理中认知偏见的现象。这些发现强调了在LLMs中实现逻辑一致性的挑战，并为提高其可靠性和性能提供了指导。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26457", "html_url": "https://arxiv.org/abs/2510.26457", "title": "SecureReviewer：通过安全意识微调增强大型语言模型进行安全代码审查", "title_en": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "authors": "Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang", "background": "在软件开发早期阶段识别和解决安全问题对于减轻长期负面影响至关重要。代码审查作为预防集成错误的有效实践之一，有助于开发人员在其代码合并之前审查同伴的代码。为了简化生成审查评论的过程，各种自动化代码审查方法已被提出，其中基于语言模型（LLM）的方法显著提高了自动化审查生成的能力。然而，现有模型主要集中在通用代码审查上，其在识别和解决安全相关问题方面的有效性尚未得到充分探索。此外，将现有代码审查方法适应安全问题也面临数据稀缺和缺乏评价标准等重大挑战。", "innovation": "为了应对这些局限性，该研究提出了SecureReviewer，一种专门设计用于增强LLMs识别和解决安全相关问题的能力的新方法。通过构建专门的训练和评估安全代码审查能力的数据集，并结合RAG技术结合领域特定的安全知识，精细调优LLMs以生成能够有效识别安全问题和提供修复建议的审查评论。此外，提出了一种新的评估指标SecureBLEU，以评估审查评论在解决安全问题方面的有效性。实验结果表明，SecureReviewer在安全问题检测准确性以及生成的审查评论的整体质量和实用性方面均优于最新的基准方法。", "conclusion": "研究表明，通过安全意识微调对大型语言模型进行专门训练是提高代码审查质量的有效方法。SecureReviewer不仅能够提高安全问题识别的准确性，还能够生成有效且实用的审查评论。这些改进有助于软件开发中更有效的安全代码审查。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26474", "html_url": "https://arxiv.org/abs/2510.26474", "title": "通过头部-尾部重平衡抑制LVLMs自我提升中的马太效应", "title_en": "Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing", "authors": "Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "自适应改进已成为提升大型视觉-语言模型(Vision-Language Models, LVLM)推理能力的主要范式，模型通过迭代探索和学习成功轨迹来提高自己。然而，研究发现在此过程中存在一个关键问题：尽管模型在生成简单查询的高质量轨迹(即头部数据)方面表现出色，但在处理更复杂的查询(即尾部数据)方面遇到困难。这导致优化不平衡，促使模型优先提高简单推理技能，而削弱解决复杂推理任务的能力。随着迭代次数的增加，这种不平衡现象变得越来越明显，我们称之为“马太效应”，最终阻碍了模型的进步并导致性能瓶颈。", "innovation": "为解决这一挑战，作者提出了四种有效的策略，从分布重塑和轨迹重采样的角度出发，在探索和学习自迭代过程中实现头部-尾部重平衡。实验在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型的视觉推理任务上的广泛验证表明，所提出的方法在平均提高了3.86个点的视觉推理能力方面优于传统的自适应改进方法。", "conclusion": "实验结果表明，基于头部-尾部重平衡的新策略显著提升了视觉推理能力，在改进中平衡了简单和复杂的查询处理能力，有效克服了马太效应带来的性能瓶颈。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26493", "html_url": "https://arxiv.org/abs/2510.26493", "title": "Context Engineering 2.0：《情境工程2.0：情境自身的工程》", "title_en": "Context Engineering 2.0: The Context of Context Engineering", "authors": "Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu", "background": "卡尔·马克思曾写道，‘人的本质是一切社会关系的总和’，暗示个体不仅是孤立的存在，而是通过与他人的互动被根本性地塑造。伴随计算机和人工智能的发展，这些互动已超越了纯粹的人与人之间的交互，现在还包括了人与机器的交互。因此，一个核心问题出现了：机器如何更有效地理解和适应我们的情况？为了应对这一挑战，研究人员最近引入了情境工程的概念。尽管通常被视为最近的智能代理时代的创新产物，但本文认为相关实践可以追溯到二十多年前。从20世纪90年代初开始，此领域经历了不同的历史阶段，每个阶段都受到机器智能水平的影响：从围绕原始计算机构建的人机交互框架，到今天由智能代理驱动的人机交互范式，甚至可能在未来达到人类或超越人类的智能水平。", "innovation": "本文将情境工程置于具体背景下，给出系统的定义，概述其历史和概念框架，并检查关键的设计考虑。此外，通过对这些问题的回答，本文旨在为情境工程提供概念基础，并展望其光明的未来。这为更广泛的社区努力系统化人工智能系统中的情境工程奠定了基础。", "conclusion": "论文为系统化人工智能系统中的情境工程提供了概念基础，并勾勒了它未来发展的诱人前景。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26495", "html_url": "https://arxiv.org/abs/2510.26495", "title": "重思文转SQL：现实数据库探索中的动态多回合SQL交互", "title_en": "Rethinking Text-to-SQL: Dynamic Multi-turn SQL Interaction for Real-world Database Exploration", "authors": "Linzhuang Sun,Tianyu Guo,Hao Liang,Yuying Li,Qifeng Cai,Jingxuan Wei,Bihui Yu,Wentao Zhang,Bin Cui", "background": "文本到SQL（Text-to-SQL）在静态和单回合任务中取得了显著成果，模型能够从自然语言问题生成SQL查询。然而，在现实世界的交互场景中，这些系统表现不佳，因为用户意图在多个回合中发生变化，且查询需要逐步完善。特别是在金融和商业分析等应用中，用户基于中间结果迭代调整查询约束。本文通过引入DySQL-Bench基准，评估模型在动态和交互式用户环境中表现的能力。DySQL-Bench通过自动化两阶段流程构建，相较于之前的手动构建数据集，涵盖13个领域，共计1,072个任务。", "innovation": "文中提出DySQL-Bench，一个基准测试，用于评估模型在用户交互演变情况下的性能。DySQL-Bench采用自动化的双阶段管道构建，包括任务合成和验证，基于原始数据库表的结构化树表示生成LLM任务，进行互动导向的筛选，并由专家进行验证。此外，还提出了一种模拟现实交互的多回合评估框架，该框架包括一个模拟用户的LLM、被测试的模型和可执行的数据库。这强调了基准的难度。", "conclusion": "DySQL-Bench的多回合评估框架通过模拟现实生活中的互动，证明了模型适应用户意图变化并调整其推理与SQL生成的能力。研究结果即使最先进的GPT-4o模型在整体准确性和Pass@5指标上也仅达到了58.34%和23.81%。所有相关代码和数据已发布在此链接中。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26658", "html_url": "https://arxiv.org/abs/2510.26658", "title": "智能组织时代的到来：通过语言模型学习组织", "title_en": "The Era of Agentic Organization: Learning to Organize with Language Models", "authors": "Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei", "background": "文章设想了一个新的人工智能时代，即智能组织时代，在这个时代里，代理能够通过协作和并发处理解决复杂问题，实现超越个体智能的成果。为了实现这一愿景，需要一种新的推理方法来利用大规模语言模型的能力。文章指出现有的并行思考方法并不足以实现这一目标，因此需要引入一种新的思维模式，即异步思考（AsyncThink），它能够优化语言模型的内部思考过程，使其能够并发执行，并通过强化学习进一步优化思维结构，从而在保持准确性的前提下，显著提高推理速度。进一步的实验表明，AsyncThink在数学推理方面比并行思考方法具有更高的准确性和较低的推理延迟，并且能够有效处理未见过的任务而无需额外训练.", "innovation": "文章提出了异步思考（AsyncThink），这是一种新的基于语言模型的推理范式，引入了一种动态分配子查询、合并中间知识并生成连贯解决方案的思考协议，并且该协议中的思考结构可以通过强化学习进一步优化。这比现有的并行思考方法更能有效地解决复杂问题，并能够有效处理未曾见过的任务而无需进一步的训练。这些创新为实现智能组织时代提供了新的可能和基础方法.", "conclusion": "本文通过提出异步思考（AsyncThink），成功地减少并行思考中的推理延迟，并且在保持准确性的前提下提高了推理效率。此外，通过强化学习进一步优化了这一思维结构，使其能够更好地处理未见过的任务。实验结果表明该方法的有效性和鲁棒性，为未来在复杂问题解决领域的实际应用奠定了基础。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26745", "html_url": "https://arxiv.org/abs/2510.26745", "title": "深度序列模型倾向于记忆几何结构；尚不清楚原因", "title_en": "Deep sequence models tend to memorize geometrically; it is unclear why", "authors": "Shahriar Noroozizadeh,Vaishnavh Nagarajan,Elan Rosenfeld,Sanjiv Kumar", "background": "在序列建模中，原子事实的参数记忆大多被简化为实体之间共现的直接查找。本文对比了这种关联视角和记忆存储中的几何视角。研究发现，与仅存储训练期间指定的局部共现记忆不同，模型必须已经综合了自己的原子事实的几何结构，编码所有实体之间的全局关系，包括不共现的实体。这一现象简化了一个复杂的推理任务为一个容易学习的几何单一步骤任务。", "innovation": "从现象中提取出难以解释的神经嵌入几何学的基本方面。作者认为，尽管优化只是局部关联，这类几何学的兴起不能简单归因于典型的架构或优化压力。通过分析与Node2Vec的连接，研究展示了几何结构源自一种光谱偏差，即使没有各种压力，这种偏差也能自然出现。这也为使Transformer记忆更加几何化提供了可见的空间，并希望几何视角促使研究人员重新审视引导他们在领域如知识获取、容量、发现和遗忘中的默认直觉。", "conclusion": "尽管优化只是局部关联，但仍学习到一个优雅的几何结构，这表明复杂的推理任务可以通过几何复杂性来简化。该研究进一步强调，研究人员应探索如何使Transformer的记忆更显着地几何化，并鼓励重新评估指导知识获取、容量、发现和遗忘等领域的默认直觉。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26732", "html_url": "https://arxiv.org/abs/2510.26732", "title": "跨平台基础模型推理能力综合评估", "title_en": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models", "authors": "J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot", "background": "本文研究了当代基础模型在跨平台环境下的推理能力，通过高性能计算超级计算机（MareNostrum 5）、云平台（Nebius AI Studio）、大学集群（配有八张H200 GPU的节点）这三种计算范式下进行综合评价，涵盖了物理学、数学、化学、经济学、生物学、统计学、微积分和优化八个学术领域共79个问题。评估了15个基础模型，并分三个实验阶段进行：第一个阶段建立基线，使用六种模型（Mixtral-8x7B, Phi-3, LLaMA 3.1-8B, Gemma-2-9b, Mistral-7B, OLMo-7B）在MareNostrum 5上评估19个问题；第二个阶段验证基础设施的通用性，重复19个问题的基准评估，并在大学集群和Nebius AI Studio上验证九个最先进模型；第三个阶段对两个平台进行全面评估，考察模型的大规模推广能力。", "innovation": "该研究首次使用跨基础设施平台的综合基准测试方法，包括高性能计算平台、云平台和大学集群，评估了多个基础模型的推理能力；并且通过深度分析，在不同基础设施上提供了可操作的指导方针，挑战了以往规模扩展的假设，强调了训练数据质量的重要性和模型规模的重要性。", "conclusion": "研究发现，基础模型推理能力超越了传统的规模假设，模型训练数据的质量比模型大小更为关键，为教育、生产与研究领域提供了可操作的模型选择指南。跨基础设施方法和79个问题的综合基准将有助于跟踪基础模型推理能力的发展趋势。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26788", "html_url": "https://arxiv.org/abs/2510.26788", "title": "通过FP16战胜训练与推理不匹配", "title_en": "Defeating the Training-Inference Mismatch via FP16", "authors": "Penghui Qi,Zichen Liu,Xiangxin Zhou,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "强化学习（RL）对大型语言模型（LLMs）的微调经常因为训练和推理政策之间的数值不匹配而导致不稳定。尽管先前的研究通过算法修正或工程对齐试图缓解这一问题，但研究发现其根本原因在于浮点精度本身。虽然广泛采用的BF16具有较大的动态范围，但它引入了大量舍入误差，破坏了训练与推理的一致性。", "innovation": "研究表明，简单地恢复使用FP16可以有效地消除这种不匹配。这一变化简单，现代框架完全支持，仅需几行代码更改，并不需要对模型架构或学习算法进行任何修改。实验证明，使用FP16统一可以实现更加稳定的优化，更快的收敛和更强的性能，适用于各种任务、算法和框架。", "conclusion": "研究结果建议，应该广泛重新考虑在RL微调中精度权衡的问题。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2311.06736", "html_url": "https://arxiv.org/abs/2311.06736", "title": "大语言模型是严谨的逻辑推理系统吗？基于逐步解码与对比学习的自然语言证明生成", "title_en": "Are LLMs Rigorous Logical Reasoners? Empowering Natural Language Proof Generation by Stepwise Decoding with Contrastive Learning", "authors": "Ying Su,Mingwen Liu,Zhijiang Guo", "background": "逻辑推理是人工智能领域的重要组成部分。在需要验证解释准确性的情境下，证明规划依然面临着挑战。近年来，大型语言模型（LLMs）的进步显著推动了自然语言证明规划的发展，从单一生成阶段扩展到包含额外搜索器或验证器的复杂三阶段系统。虽然这些辅助方法提高了生成结果的质量，但也增加了搜索努力和计算成本。此外，生成过程本身仍需进一步探索。", "innovation": "提出了一种基于逐步解码与对比学习的策略，以解决LLM生成器在解码过程中遇到的常见错误。通过使用基础负样本和增强的负样本对语言模型进行微调，以减轻这些解码错误。实验证明了该策略的有效性。进一步分析表明，即使更大规模的LLM，在生成严密的逻辑链条方面也面临挑战。", "conclusion": "研究证实了基于逐步解码与对比学习的方法能有效解决LLMs在生成逻辑推理中的常见错误，但仍需进一步优化。尽管大型语言模型在自然语言证明生成方面取得了显著进展，但在生成逻辑链条的严谨性方面仍存在问题。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.00176", "html_url": "https://arxiv.org/abs/2404.00176", "title": "LSCD基准：历时词义任务的测试平台", "title_en": "The LSCD Benchmark: a Testbed for Diachronic Word Meaning Tasks", "authors": "Dominik Schlechtweg,Sachin Yadav,Nikolay Arefyev", "background": "LSCD是一项复杂的词形级任务，通常基于两个相继的应用于用法层面的任务实现：首先为用法对生成Word-in-Context（WiC）标签；其次将这些标签表示为图，然后在该图上执行Word Sense Induction（WSI）以推导出词义簇。最后，通过跨时间比较词义簇以推导出LSCD标签。这种模块化特性在大多数LSCD数据集和模型中都有体现。然而，这导致了建模选项和任务定义方面的巨大异质性，这种异质性因数据集版本、预处理选项和评估指标的不同得到加剧。这样的异质性使得在可比条件下评估模型、选择最优模型组合或重复结果变得困难。因此，论文提供了一个基准库，标准化LSCD评估。", "innovation": "通过透明的实现，使结果易于复现，并通过标准化不同组件可以自由组合。基准库反映了任务的模块化特性，允许为WiC、WSI和LSCD进行模型评估。这为仔细评估越来越复杂的模型组件提供了新的模型优化方法。", "conclusion": "使用实现的基准进行了多项实验，并系统性地提升了最先进的状态。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26787", "html_url": "https://arxiv.org/abs/2510.26787", "title": "远程劳动力指数：衡量远程工作的AI自动化", "title_en": "Remote Labor Index: Measuring AI Automation of Remote Work", "authors": "Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks", "background": "人工智能已经在知识和推理的研究基准上取得了迅速进步，但在这些进展如何转化为经济价值和自动化方面的实际应用方面仍不清楚。为了衡量这一点，作者引入了远程劳动力指数（RLI），这是涵盖现实世界、经济上有价值项目的广泛多部门基准，旨在评估在实际应用场景中的代理端到端表现。研究表明，最优秀的AI代理在RLI上的表现也很低，最高自动化率为2.5%。这些结果有助于将关于AI自动化的讨论建立在实证证据的基础上，为追踪AI影响提供了一个共同基准，并帮助相关利益方积极应对由AI驱动的劳动力自动化问题。", "innovation": "作者提出了远程劳动力指数（RLI），这是一个包含经济上实际有价值的项目在内的广泛多部门基准，用于评估AI代理在实际应用场景中的性能。这为AI自动化的讨论奠定了实证基础，提供了一个共同的基准来跟踪AI影响，同时也帮助利益相关者积极应对劳动自动化带来的挑战。此外，作者也强调了AI在自动化方面的实际限制，即最高自动化率仅为2.5%。", "conclusion": "研究表明，大多数AI代理在远程劳动力指数（RLI）上的性能都很低，最高自动化率仅为2.5%。这些结果有助于将AI自动化讨论置于基于实证证据的框架内，为跟踪AI影响提供了一个共同基准，同时也让人们意识到AI在实现自动化方面的实际能力有限。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.04380", "html_url": "https://arxiv.org/abs/2502.04380", "title": "多样性的奖励：在未确定域数据的混合中微调LLMs", "title_en": "Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data", "authors": "Zhenqing Ling,Daoyuan Chen,Liuyi Yao,Qianli Shen,Yaliang Li,Ying Shen", "background": "大型语言模型（LLMs）的性能增强依赖于使用多样化的数据集进行微调。现有方法在数据组成建模方面往往难以处理缺失、不准确或未标准化的领域标签数据，而在基于数据选择的方法中，平衡多领域性能也是一个挑战。", "innovation": "本文通过构建对比数据池和理论推导解释，探讨了数据多样性在提高LLMs整体能力的作用。提出了一种新方法，即赋予LLMs双身份：一个输出模型用于根据多样性奖励认知探究和选择数据，另一个输入模型用于根据选定的数据进行调整。实验表明，该方法在各种先进LLMs上应用于领域未确定的数据和一系列基础下游任务时，显著提升了性能。", "conclusion": "广泛实验表明，提出的该方法在领域未确定的数据以及一系列基础下游任务中显著提升了各种先进LLMs的性能。希望这一研究能够促进对数据多样性的理解，并推进LLMs的数据-模型协同设计的反馈驱动方法发展。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26802", "html_url": "https://arxiv.org/abs/2510.26802", "title": "视频模型是否准备好作为零样本推理器？MME-CoF基准的实证研究", "title_en": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark", "authors": "Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng", "background": "近年来，视频生成模型能够生成高保真度、时序一致的视频，这表明它们可能已经具备了大量的世界知识。除了现实的合成，这些模型还展示了视觉感知、建模和操作的新兴行为。然而，仍有一个重要的问题：这些视频模型是否准备就绪能够在具有挑战性的视觉推理场景中充当零样本推理器？", "innovation": "本文开展了一项实证研究，全面探究这一问题。针对流行的模型Veo-3，我们从12个维度上对其进行评估，包括空间、几何、物理、时间和体现逻辑，并系统地描述了其优势和失败模式。为此，我们还创建了MME-CoF基准，使其能够对帧链推理进行深入和全面的评估。", "conclusion": "当前的视频模型在短期空间一致性、细粒度定位和局部一致动力学方面表现出有希望的推理模式，但在长期因果推理、严格的几何约束和抽象逻辑方面仍然有限。总体而言，这些模型还不足以作为独立的零样本推理器，但它们作为与专用推理模型互补的视觉引擎表现出鼓舞人心的迹象。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.06263", "html_url": "https://arxiv.org/abs/2409.06263", "title": "Speak & Spell: LLM-驱动可控语音错误增强方法以提升对话状态跟踪鲁棒性", "title_en": "Speak & Spell: LLM-Driven Controllable Phonetic Error Augmentation for Robust Dialogue State Tracking", "authors": "Jihyun Lee,Solee Im,Wonjun Lee,Gary Geunbae Lee", "background": "对话状态跟踪（DST）是任务导向型对话系统的核心组成部分，其主要任务是在对话中识别关键信息。然而，在口语对话环境中，由于自动语音识别（ASR）系统的命名实体错误，其准确性显著下降。本研究旨在解决这一问题，提出了一种简单且有效的数据增强方法，针对命名实体进行调整，以提高DST模型的鲁棒性。该方法通过关键词提示引入具有特定模式的语音错误，从而在噪音和ASR准确性较低的环境中提升模型的准确率。", "innovation": "本研究提出了一种LLM-驱动的可控语音错误增强方法。该方法通过关键词提示来精准控制语音错误的插入，同时引入发音相似但拼写不同的错误，以提高DST模型在受噪声影响和ASR低准确率环境中的鲁棒性。", "conclusion": "研究结果表明，该方法能够生成足够的关键词语音错误模式，从而提升模型在噪声和低准确率ASR环境中的准确率。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.12869", "html_url": "https://arxiv.org/abs/2410.12869", "title": "使用多个弱评估器的语言模型偏好评估", "title_en": "Language Model Preference Evaluation with Multiple Weak Evaluators", "authors": "Zhengyu Hu,Jieyu Zhang,Zhihan Xiong,Alexander Ratner,Kaize Ding,Ranjay Krishna", "background": "尽管大型语言模型（LLMs）取得了显著的成功，但在评价其输出的质量方面，特别是在偏好评价上仍存在重大挑战。现有方法通常依赖一个强LLM作为评判者，依次对比多个LLM的响应，但这种单一评估者的方法容易产生循环偏好，即A优于B，B优于C，但C又优于A，造成不一致的评价结果。为解决这一问题，本文提出PGED（Preference Graph Ensemble and Denoise，偏好图集成和去噪）方法，利用多个基于模型的评估者构建偏好图并对其进行集成和去噪处理，以获得有向无环、不冲突的评价结果。", "innovation": "本文创新地提出了PGED方法，通过集成多个基于模型的评估器构建偏好图并进行去噪，从而克服了单一评估者方法的局限性，解决了循环偏好的问题，提出了理论上的保证，并在多个基准上验证了其在模型排名、响应选择和数据选择等应用场景下的有效性和优越性。特别是，利用小规模模型评估器（如Llama3-8B，Mistral-7B，Qwen2-7B）超越了大规模模型评估器（如Qwen2-72B），展示了其提升评估可靠性和改进模型性能的有效性。", "conclusion": "本文通过PGED方法，利用多个模型评估器构建偏好图并通过集成和去噪得到无环、一致的评价结果。该方法适用于模型排名、响应选择和数据选择等应用，并在多个基准上展示了其优越性。与单一强模型评估者相比，使用小规模模型评估器的PGED方法在可靠性与模型性能提升方面表现出色。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.14409", "html_url": "https://arxiv.org/abs/2502.14409", "title": "长上下文查询驱动摘要中的非结构化证据归属", "title_en": "Unstructured Evidence Attribution for Long Context Query Focused Summarization", "authors": "Dustin Wright,Zain Muhammad Mujahid,Lu Wang,Isabelle Augenstein,David Jurgens", "background": "现有的大型语言模型能够根据用户查询生成连贯的摘要，并提取和引用证据片段有助于提高这些摘要的可信度。然而，先前的研究主要集中在固定粒度的证据引用（如句子、段落、文档等），这项研究提出了一种新的方法，即提取非结构化的证据（任意长度的片段），以获取比固定粒度更相关、更一致的证据。现有的系统在处理非结构化证据的复制和引用时存在困难，而且常常丢失中间的片段。为了帮助模型完成这一任务，研究人员创建了一个名为Summaries with Unstructured Evidence Text (SUnsET)的数据集，这是一个使用新管道生成的合成数据集，可以作为非结构化证据摘要训练监督的工具。", "innovation": "提出了一种新的方法，即提取非结构化的证据片段，以便获得比固定粒度证据更相关、更一致的证据。研究人员创建了SUnsET数据集，用于训练非结构化证据摘要，并展示了在5种大型语言模型和4种不同数据集上，经过SUnsET训练的模型生成的摘要中的证据更加相关和事实一致，可以从更多样化的上下文位置抽取证据，并生成比未经过任何微调和固定粒度证据基线更加相关和一致的摘要。", "conclusion": "研究证明了大型语言模型在经过SUnsET训练后，生成的摘要中包含了更加相关和事实一致的证据，可以从更广泛的上下文部分抽取证据，并且生成的摘要比没有任何微调和固定粒度证据的基准模型更加相关和一致。SUnsET数据集及其生成代码已向公众发布。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.03710", "html_url": "https://arxiv.org/abs/2503.03710", "title": "改进双目标优化提高大语言模型安全性对齐", "title_en": "Improving LLM Safety Alignment with Dual-Objective Optimization", "authors": "Xuandong Zhao,Will Cai,Tianneng Shi,David Huang,Licong Lin,Song Mei,Dawn Song", "background": "现有的训练时安全性对齐技术在大型语言模型（LLMs）中对于规避攻击仍然存在不足。直接偏好优化（DPO）作为一种广泛应用的安全性对齐方法，其在实验和理论上都表现出一定的局限性，因为其损失函数不适合拒绝学习。通过梯度分析，我们发现这些局限并提出改善的安全性对齐方法，这种方法将DPO目标解耦为两个方面：（1）稳健的拒绝训练，即使生成部分不安全内容时也鼓励其拒绝，（2）有针对地消除有害知识。", "innovation": "提出了一种改进的安全性对齐方法，将DPO目标解耦为两个组件：（1）稳健的拒绝训练，即使生成部分不安全内容时也鼓励其拒绝，（2）有针对地消除有害知识。此外，通过引入基于奖励的token级权重机制强化关键拒绝token，从而进一步提高对抗性利用的鲁棒性。", "conclusion": "我们的研究显示，对抗性攻击的鲁棒性与训练过程中的token分布变化及拒绝和有害token的内部表示有关，为未来大语言模型安全性对齐提供了有价值的指导方向。代码可在以下链接获取：this https URL"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.00333", "html_url": "https://arxiv.org/abs/2503.00333", "title": "始终如一：在增加代表性下持续存在的代表权的危害", "title_en": "More of the Same: Persistent Representational Harms Under Increased Representation", "authors": "Jennifer Mickel,Maria De-Arteaga,Leqi Liu,Kevin Tian", "background": "为了识别和减轻生成AI系统的危害，有必要考虑生成AI系统输出中涉及哪些群体以及这些人是如何被描绘的。单纯提高被代表的群体数量并不能保证偏见修正措施已经到位，本文通过考察先进语言模型中的性别职业代表性，发现了这个问题。首先，研究显示随着时间的推移，模型中性别分布已经发生了调整，并且在生成个人简介或角色时女性比男性更为常见。其次，研究还发现不同性别在各种表现形式上仍存在显着的语言差异，这导致了持续的代表性损害、刻板印象以及新自由主义价值观的盛行，在女性代表增加的同时，仍在强化现有的压迫体系。", "innovation": "本文通过分析生成AI系统中性别职业代表性的情况，揭示了单纯增加代表性并不能确保偏见被有效地修正。具体地，通过对先进语言模型中的性别职业分布和语言差异进行分析，展示了尽管存在增加女性代表的努力，但性别偏见和代表性的不平等问题依然存在，强调了包括技术手段和社会措施在内的全面策略的重要性。这项研究提供了对如何有效减少生成AI系统的代表性和误识问题的见解，促进了对未来相关研究的深入思考。", "conclusion": "研究发现了生成AI系统中存在持续的代表性危害，即使女性代表有所增加，但这些系统中仍然存在对不同性别群体的刻板印象和不平等描述，这在一定程度上强化了现有的压迫体系。因此，需要采取综合措施，包括技术和政策层面的努力，以减少这些生成系统中的代表性不公。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16325", "html_url": "https://arxiv.org/abs/2410.16325", "title": "这位候选人是 [MASK]。基于提示的情感提取和参考信", "title_en": "This Candidate is [MASK]. Prompt-based Sentiment Extraction and Reference Letters", "authors": "Fabian Slonimczyk", "background": "本文提出了一种简单的方法，将预训练的大语言模型部署用于从文本数据中提取情感和其他有用特征。所提出的方法被称为基于提示的情感提取，与经济和金融领域其他常用方法相比，它具有多个优势，包括无需预处理文本输入、产生具有概率解释的情感评分，以及无需进行微调或标注数据。作者还应用此方法对一手收集的保密参考信（RLs）数据库进行了分析，发现参考信的情感内容在求职市场结果中得到了明显体现。此外，研究还发现参考信撰写者之间的情感多样性对求职者的市场表现产生了负面影响。作者还将此情感提取方法与其他常见的情感分析方法（如词袋方法、微调语言模型和查询高级聊天机器人的方法）进行了比较，发现没有其他方法能完全复制基于提示的情感提取方法所获得的结果。最后，作者将方法稍作修改，以获得具有性别区分的情感评分，并表明针对女性候选人的参考信强调的是‘专业’特质，而男性候选人的信件则强调‘突出’特质，这种性别差异对女性的职业市场结果产生了负面影响。", "innovation": "该方法的最大创新点在于可以直接利用预训练的大语言模型进行情感提取，无须对模型进行任何微调或使用标注数据。它还引入了一种新颖的分析方法，通过分析参考信的情感内容，揭示了性别不同对求职市场绩效的具体影响。此外，通过将 方法应用于高度私有的参考信数据集，进一步验证了其有效性和适用性。", "conclusion": "本文提出的方法不仅展现了人际交往中情感的重要作用，还通过参考信数据验证了性别差异对求职市场结果的影响。这种基于提示的情感提取方法在未经处理的文本输入下直接生成情感评分，填补了在经济和金融领域中情感分析方法的空白，提供了更为准确和客观的情感评估工具。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.05747", "html_url": "https://arxiv.org/abs/2504.05747", "title": "SEA-LION: 南亚地区语言在一个网络中", "title_en": "SEA-LION: Southeast Asian Languages in One Network", "authors": "Raymond Ng,Thanh Ngan Nguyen,Yuli Huang,Ngee Chia Tai,Wai Yi Leong,Wei Qi Leong,Xianbin Yong,Jian Gang Ngui,Yosephine Susanto,Nicholas Cheng,Hamsawardhini Rengarajan,Peerat Limkonchotiwat,Adithya Venkatadri Hulagadri,Kok Wai Teng,Yeo Yeow Tong,Bryan Siow,Wei Yi Teo,Wayne Lau,Choon Meng Tan,Brandon Ong,Zhi Hao Ong,Jann Railey Montalan,Adwin Chan,Sajeban Antonyrex,Ren Lee,Esther Choa,David Ong Tat-Wee,Bing Jie Darius Liu,William Chandra Tjhi,Erik Cambria,Leslie Teo", "background": "近年来，大型语言模型（LLMs）在处理和生成自然语言方面表现出色，占据了人工智能领域的许多领域。然而，大多数LLM的研究和开发仍以英语为中心，导致诸如东南亚地区这些低资源语言被严重忽视。为了解决这些语言的代表性不足问题，本文介绍了两个为南亚地区语言设计的前沿多语言LLM：Llama-SEA-LION-v3-8B-IT和Gemma-SEA-LION-v3-9B-IT。", "innovation": "我们的工作基于大规模多语言连续预训练，并结合了多阶段的指令微调、对齐和模型合并。这些模型在南亚地区语言支持的多语言基准测试中表现出最先进的性能。", "conclusion": "为了使南亚社区受益，我们开源了这些模型。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01001", "html_url": "https://arxiv.org/abs/2504.01001", "title": "零样本基准测试：一种语言模型灵活且可扩展的自动化评估框架", "title_en": "Zero-shot Benchmarking: A Framework for Flexible and Scalable Automatic Evaluation of Language Models", "authors": "José Pombal,Nuno M. Guerreiro,Ricardo Rei,André F. T. Martins", "background": "随着语言模型变得越来越强大，能够执行跨模态的复杂任务，对其自动评估日益变得具有挑战性。开发高性能和牢固的专门自动评估指标变得更难，而人力标注的测试集（创建成本较高）很快就会饱和。一种有吸引力的替代方案是设计可靠的策略来自动化测试数据和评估的生成，然而以前的尝试要么依赖于现有的数据，要么仅专注于单一任务。因此，需要一种新的框架，能够在无需依赖现有数据集的情况下，灵活且可扩展地为任何任务生成高质量的基准测试，通过语言模型进行测试数据的生成和评估，以应对这些挑战。", "innovation": "该论文提出了零样本基准测试（ZSB）框架，旨在为任何任务生成高质量基准测试，该框架使用语言模型进行生成数据和评估。ZSB框架具有简单性和灵活性，只需要生成数据生成提示和评估提示即可，该框架适用于数据收集成本高或不切实际的任务和语言，几乎对模型无依赖性，随着模型性能的提升，可生成越来越具有挑战性的基准测试。ZSB通过对多种文本和多模态任务的评估测试表明框架的有效性，相关评估结果一致与人类评估结果高度相关，且优于广泛采用的标准基准测试。", "conclusion": "通过消融实验，表明使用开放模型可以生成强大的基准测试，同时指标模型大小和数据集多样性是性能的关键驱动因素。作者已经发布了所有基准测试和用于复现实验及生成新基准测试的代码。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14604", "html_url": "https://arxiv.org/abs/2505.14604", "title": "让LRMs摆脱过度思考通过自我刹车调节", "title_en": "Let LRMs Break Free from Overthinking via Self-Braking Tuning", "authors": "Haoran Zhao,Yuchen Yan,Yongliang Shen,Haolei Xu,Wenqi Zhang,Kaitao Song,Jian Shao,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "大型推理模型（LRMs）如OpenAI的o1和DeepSeek-R1通过生成更长的思维链显著提升了推理能力，但在提升性能的同时也加大了推理过程中的冗余计算，增加了计算开销并加剧了过度思考的问题。尽管有许多现有方法试图解决过度思考的问题，但这些方法通常依赖于外部干预。", "innovation": "本文提出了一种新的框架，名为Self-Braking Tuning（SBT），旨在让模型能够自我调节其推理过程，从而消除对外部控制机制的依赖。该框架构建了一套基于标准答案的过度思考识别度量指标，设计了一种系统方法来检测冗余推理，并准确识别推理轨迹中的不必要的步骤。通过这种方式，模型可以自然学习在适当的时候终止推理。", "conclusion": "在多个数学基准测试（包括AIME、AMC、MATH500、GSM8K）上进行的实验表明，该方法能够在减少高达60%的标记消费的同时保持与无约束模型相当的准确性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.04953", "html_url": "https://arxiv.org/abs/2504.04953", "title": "M-Prometheus: 一套开源多语言LLM裁判套件", "title_en": "M-Prometheus: A Suite of Open Multilingual LLM Judges", "authors": "José Pombal,Dongkeun Yoon,Patrick Fernandes,Ian Wu,Seungone Kim,Ricardo Rei,Graham Neubig,André F. T. Martins", "background": "目前，使用语言模型自动评估长文本（LLM作为裁判）的应用越来越普遍，但大多数LLM裁判主要针对英语进行优化，对于多语言评估能力的提升策略在现有文献中鲜有探讨。这导致了非英语语言的自动评估方法质量参差不齐，阻碍了具有更好多语言能力模型的开发。为了弥合这一差距，本文引入了M-Prometheus，这是一个参数从30亿到140亿的开源多语言LLM裁判套件，能够提供直接评估和成对比较反馈，适用于多语言输出，其在超过20种语言的多语言奖励基准测试和4种语言对的文学机器翻译（MT）评估方面均表现出色。此外，在解码时，M-Prometheus模型可以显著提升所有3种测试语言的生成输出，展示了其在开发更好多语言模型方面的实用性。最后，通过广泛的消融实验，我们确定了获得有效多语言裁判的关键因素，包括基础模型选择以及在合成的多语言反馈数据而非翻译数据上进行训练。", "innovation": "本文创新性地提出了M-Prometheus，一个参数范围从30亿到140亿的开源多语言LLM裁判套件，该套件在多语言奖励基准测试和文学机器翻译评估方面优于现有开源LLM裁判。此外，通过在合成的多语言反馈数据上进行训练，M-Prometheus模型在生成输出时能够显著提升多语言模型的表现。进一步的关键发现包括使用合成多语言反馈数据进行训练的重要性，而不是传统的翻译数据。", "conclusion": "M-Prometheus模型在各种多语言应用场景中表现优异，且特别适合在生成过程中提升多语言模型的表现。通过本文的研究，我们为进一步优化多语言LLM裁判提供了重要的理论和实践基础。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.04721", "html_url": "https://arxiv.org/abs/2506.04721", "title": "SPARTA ALIGNMENT: 通过战斗集体对准多个语言模型", "title_en": "SPARTA ALIGNMENT: Collectively Aligning Multiple Language Models through Combat", "authors": "Yuru Jiang,Wenxuan Ding,Shangbin Feng,Greg Durrett,Yulia Tsvetkov", "background": "现有单个模型在生成多样性和评估公正性方面存在局限性。", "innovation": "提出了一种名为SPARTA ALIGNMENT的算法，通过竞争和战斗机制集体对准多个语言模型。", "conclusion": "广泛实验表明，SPARTA ALIGNMENT在12项任务中的10项上优于初始模型和4种自我对准基准，平均提高了7.0%，并且更有效地泛化到未见过的任务，并利用参与模型的专业知识多样性产生更逻辑、直接和有信息量的输出。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13444", "html_url": "https://arxiv.org/abs/2505.13444", "title": "ChartMuseum: 测试大型视觉语言模型的视觉推理能力", "title_en": "ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models", "authors": "Liyan Tang,Grace Kim,Xinyu Zhao,Thom Lake,Wenxuan Ding,Fangcong Yin,Prasann Singhal,Manya Wadhwa,Zeyu Leo Liu,Zayne Sprague,Ramya Namuduri,Bodun Hu,Juan Diego Rodriguez,Puyuan Peng,Greg Durrett", "background": "现有的大型视觉语言模型（LVLMs）在理解和处理图表时面临独特的挑战，因为这需要整合复杂的文本理解和视觉推理能力。然而，当前的LVLMs在这两方面的表现存在不平衡，尤其在难以用文本实现的视觉推理方面表现不佳。通过一个仅需视觉推理才能解决的合成数据集，研究发现，随着视觉复杂性的增加，模型性能会显著下降，而人类的性能则保持稳定。", "innovation": "作者提出了一个新的名为ChartMuseum的图表问答基准，包含1,162个由专家注释的问题，覆盖多种推理类型，这些问题来源于184个真实世界的图表数据源。这个基准旨在评估复杂的视觉和文本推理能力。不同于之前的图表理解基准，新基准揭示了模型与人类之间显著的能力差距，并能有效地区分不同模型的能力。", "conclusion": "基于ChartMuseum基准，研究发现人类在复杂图表理解任务上表现出93%的准确性，但最佳模型Gemini-2.5-Pro和领先的开源LVLM Qwen2.5-VL-72B-Instruct分别只有63.0%和38.5%的准确性。此外，在主要依赖视觉推理的问题上，所有模型的表现比主要依赖文本推理问题下降35%-55%。质性错误分析揭示了当前LVLM在特定视觉推理领域的弱点。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.11331", "html_url": "https://arxiv.org/abs/2504.11331", "title": "依赖结构增强上下文范围框架用于多模态方面基于情感分析", "title_en": "Dependency Structure Augmented Contextual Scoping Framework for Multimodal Aspect-Based Sentiment Analysis", "authors": "Hao Liu,Lijun He,Jiaxi Liang,Zhihan Ren,Haixia Bi,Fan Li", "background": "多模态方面基于情感分析（MABSA）旨在从图像-文本对中提取细粒度信息，识别方面术语并确定其情感极性。然而，现有的方法往往在同时解决三个方面核心挑战（情感暗示感知（SCP）、多模态信息错位（MIM）和语义噪声消除（SNE））方面存在局限性。", "innovation": "本文提出了DASCO（依赖结构增强的范围框架），这是一种细化层级范围导向框架，通过依赖解析树增强了在MABSA中的方面级情感推理。DASCO通过结合方面导向增强、图文匹配以及方面级情感敏感认知设计了多任务预训练策略，改善了方面词和情感暗示的感知，实现了有效的图文对齐，并解决了关键挑战如SCP和MIM。此外，DASCO引入了依赖树作为语义分支结合，指导模型选择性地关注特定目标范围内的关键上下文元素，有效过滤掉无关噪音，解决了SNE问题。", "conclusion": "在两种基准数据集的三个子任务上的广泛实验表明，DASCO在MABSA中达到了最先进的性能，在JMASA上获得显著提升（Twitter2015上F1增2.3%，精确度增3.5%）。源代码可在本文链接处获得。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15095", "html_url": "https://arxiv.org/abs/2505.15095", "title": "Nek Minit: 借助语用元认知提示实现可解释的澳大利亚和印度英语讽刺检测", "title_en": "Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English", "authors": "Ishmanbir Singh,Dipankar Srirag,Aditya Joshi", "background": "讽刺是情感分析的挑战，因为明示的情感和暗示的情感之间存在不一致。当讽刺可能与特定国家或地理区域的相关背景有关时，这种挑战会加剧。已有研究表明，语用元认知提示（PMP）是一种基于认知技术，有助于进行语用推理。在此论文中利用PMP实现具有可解释性的讽刺检测，特别是在澳大利亚英语和印度英语中。此外，还结合了一个标准英语基准数据集以进行验证，显示了PMP在两个开源大模型（GEMMA和LLAMA）中的性能改善。", "innovation": "该工作创新地利用了语用元认知提示（PMP）技术来为澳大利亚英语和印度英语生成讽刺解释，提供了比传统的标准英语更精细的情感分析能力。此外，研究还发现，借助替代提示策略（如代理提示）可有效缓解由于上下文导致的失败，通过促进外部知识检索来提高识别准确性。", "conclusion": "实验表明，PMP策略在所有任务和数据集中，与四种替代提示策略相比，都实现了统计意义上的性能提升。代理提示技术的有效性还表明了通过外部知识检索来解决语境相关问题的潜力。这项工作的主要贡献在于利用PMP生成多种英语形式的讽刺解释，并且提供了一种新的可解释性的讽刺检测方法。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08410", "html_url": "https://arxiv.org/abs/2506.08410", "title": "大型语言模型拥有内在的元认知能力，但需要一个好视角", "title_en": "Large Language Models Have Intrinsic Meta-Cognition, but Need a Good Lens", "authors": "Ziyang Ma,Qingyue Yuan,Zhenglin Wang,Deyu Zhou", "background": "先前的研究主要集中在大型语言模型（LLMs）的认知错误检测能力上，通常会促使LLMs分析推理链中的错误。然而，很少有研究探讨LLMs的元认知能力，即它们对自己步骤错误的认识能力，这是提高其可靠性的关键因素。虽然有一些关于LLMs自我评估的研究提出了一些评估元认知的度量标准，如困惑度，这些度量标准可以反映答案的正确性并作为元认知的视角，但它们往往缺乏步骤级的分析和调整。", "innovation": "本文提出了一种元认知评价的自动框架——AutoMeco，并提出了一个无需训练的马尔可夫内在奖励调整策略MIRA，来增强现有的元认知度量标准。实验结果表明，AutoMeco能够合理评估LLMs的元认知能力，并且通过MIRA，可以更好地评估LLMs的元认知能力。", "conclusion": "AutoMeco框架和MIRA策略有助于当前元认知度量标准的改进，结果显示该方法能够在多组数学推理数据集上合理评估LLMs的元认知能力。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.24388", "html_url": "https://arxiv.org/abs/2505.24388", "title": "ClueAnchor：基于线索锚定的知识推理探索与优化以增强检索增强生成", "title_en": "ClueAnchor: Clue-Anchored Knowledge Reasoning Exploration and Optimization for Retrieval-Augmented Generation", "authors": "Hao Chen,Yukun Yan,Sen Mei,Wanxiang Che,Zhenghao Liu,Qi Shi,Xinze Li,Yuchun Fan,Pengcheng Huang,Qiushi Xiong,Zhiyuan Liu,Maosong Sun", "background": "现有检索增强生成（RAG）系统经常未能充分利用检索到的文档中的关键线索，导致推理不忠实且难以解释，特别是当相关证据隐含、分散或被噪声遮蔽时。鉴于此问题，本文提出了一种名为ClueAnchor的新框架，该框架通过线索锚定的推理探索和优化来增强RAG系统。ClueAnchor从检索内容中提取关键线索并根据不同的知识配置生成多个推理路径，通过基于奖励的偏好优化选择最适合给定上下文的推理路径。实验结果表明，ClueAnchor比先前的RAG基线方法在推理的完整性和鲁棒性上表现出显著优势。进一步分析表明，该方法对噪声或部分相关检索内容具有较强的鲁棒性，并能在推理时识别出支持证据，即使在没有显式线索监督的情况下也能发挥作用。", "innovation": "本文提出了一种名为ClueAnchor的新框架，区分于现有的RAG系统，ClueAnchor通过线索锚定的推理探索和优化来增强RAG系统。其主要创新点在于可以从检索内容中提取关键线索，生成基于不同知识配置的多个推理路径，并基于奖励的偏好优化选择最适合当前上下文的推理路径，从而提高了推理的完整性和鲁棒性，即便在嘈杂或部分相关检索内容的情况下也能较好地进行无监督证据识别。所有代码在GitHub上均可获取。", "conclusion": "实验结果显示，ClueAnchor在推理的完整性和鲁棒性方面显著优于现有的RAG基线方法。进一步分析表明，该方法能够处理噪声或部分相关检索内容，具有显著的鲁棒性，并能在无监督的情况下识别支持证据。所有代码已开源。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.02175", "html_url": "https://arxiv.org/abs/2506.02175", "title": "AI 辩论有助于评估争议性声明", "title_en": "AI Debate Aids Assessment of Controversial Claims", "authors": "Salman Rahman,Sheriff Issaka,Ashima Suvarna,Genglin Liu,James Shiffer,Jaeyoung Lee,Md Rizwan Parvez,Hamid Palangi,Shi Feng,Nanyun Peng,Yejin Choi,Julian Michael,Liwei Jiang,Saadia Gabriel", "background": "随着人工智能的日益强大，它将越来越多地影响我们对世界的理解。然而，这种影响也伴随着传播错误信息和加深社会分歧的风险，特别是在事关人们福祉的关键话题上。Scalable Oversight 项目旨在确保即使在AI能力超过评估者时，AI系统也能保持真实性和准确性。但当人类担任评估者时，他们的偏见会影响其判断能力。因此，作者研究了AI辩论是否能够引导有偏见的评判者找到真相，通过让两个AI系统辩论关于新冠疫情和气候变化等有争议的“事实”声明，来评估不同的评判方式并比较其效果，特别针对持有不同既有观点的人类评判者和AI评判者。研究显示，AI辩论能够显著提高人类判断的准确性和信心程度，尤其对于持主流观点的评判者，可以提升多达15.2%的准确性。研究还表明，配备类似人类人格的AI评判者比人类评判者和默认无类似人类人格的AI评判者更具准确性，表明其监管前沿AI模型的潜力。这些发现强调AI辩论是实现可扩展且具有抗偏见性的监督方法的一种有前景的路径，特别是在争议性领域。", "innovation": "该研究通过让两个AI系统辩论解读争议性事实声明，提出了一种新方法来帮助有偏见的人类评判者找到真相。这种方法在提升人类和AI评判者判断准确性和信心方面均显示出显著效果，特别是对于持有主流观点的评判者。该研究还展示了配备类似人类人格的功能对AI评判者的重要性，表明其在监督前沿AI模型方面的潜力。", "conclusion": "AI辩论作为一种监督方法，可以显著提高评判者的判断准确性和信心，尤其适用于人类难以准确评判的争议性话题。配备类似人类人格的AI评判者比人类评判者更具准确性，展现出极大的监督潜在价值。这些发现表明，AI辩论是一种有前景的方法，可以实现可扩展且抗偏见性的监督，特别是在争议性的领域。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09391", "html_url": "https://arxiv.org/abs/2506.09391", "title": "比较自由创作中人类与LLM的礼貌策略", "title_en": "Comparing human and LLM politeness strategies in free production", "authors": "Haoran Zhao,Robert D.Hawkins", "background": "礼貌言语对大型语言模型（LLMs）构成了根本性的对齐挑战。人类使用丰富的语言策略来平衡信息和社交目标——从积极的方法（恭维、表示兴趣）到消极的方法（委婉、间接）。作者通过将人类和大型语言模型在受控和开放式生成任务中的反应进行比较，研究LLMs是否也采用相似的语境敏感策略。大规模模型成功复制了计算语用学文献中的关键偏好，并且人类评估者在开放式环境中更偏好LLM生成的响应。但是，进一步的语言分析显示，模型在正向情境中过度依赖消极礼貌手段，可能导致误解。尽管现代LLMs展示了在礼貌策略上的出色处理能力，这些细微差异引发了关于AI系统语用对齐的重要问题。", "innovation": "研究通过将人类和大型语言模型在不同任务中的表现进行对比，揭示了模型在礼貌手段使用上的差异，特别是消极礼貌的过度使用问题。这项研究挑战了人们对于LLMs在礼貌策略使用上的信任，并提出了一些关于AI系统语用对齐的重要问题。", "conclusion": "尽管现代大型语言模型展示了出色的礼貌策略处理能力，但在正向情境中过度依赖消极礼貌手段，可能导致误解，提示需要更深入研究和改进LLMs的语用对齐问题。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13464", "html_url": "https://arxiv.org/abs/2506.13464", "title": "语言模型的学习思维揭秘：认知框架与实证研究", "title_en": "Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study", "authors": "Zhengyu Hu,Jianxun Lian,Zheyuan Xiao,Seraphina Zhang,Tianfu Wang,Nicholas Jing Yuan,Xing Xie,Hui Xiong", "background": "大型语言模型（LLMs）在数学、编程和推理等多种任务中展现了令人印象深刻的能力，但它们的学习能力尚未得到充分探索。学习能力在适应动态环境和获取新知识方面至关重要。", "innovation": "本文通过借鉴认知心理学和教育的方法，提出了一种新颖的框架，将一般学习能力分解为三个互补的维度：从教师学习（通过显式指导获取知识）、概念学习（内化抽象结构并泛化到新情景）、经验学习（通过累计探索和反馈适应）。此外，还引入了一个基准，用于全面评估和诊断LLMs在三个学习认知维度上的通用学习能力，为更适应且类人模型的开发提供了支持。", "conclusion": "本文通过框架和实证研究，识别出一些重要发现，如互动提高学习效果、概念理解在大规模模型中更显著、LLMs 是高效的少样本学习者但不是多样本学习者。此外，还提出了一个新的基准，用于统一对LLMs的学习能力进行评估。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.14681", "html_url": "https://arxiv.org/abs/2506.14681", "title": "大规模监督微调实验揭示数据、层和训练因素如何影响大语言模型对齐质量", "title_en": "Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality", "authors": "Yuto Harada,Yusuke Yamauchi,Yusuke Oda,Yohei Oseki,Yusuke Miyao,Yu Takagi", "background": "监督微调(SFT)是使大型语言模型(LLMs)与人类指令和价值观对齐的关键步骤，但SFT的许多方面仍不明确。本文作者训练了多种基础模型，涵盖代码生成、数学推理和通用任务等多种数据集，形成了超过1000个在控制条件下微调的模型。通过对这些模型进行分析，揭示了微调任务和数据集对模型对齐质量的影响。", "innovation": "作者开展了大规模的监督微调实验，研究了数据集特性、微调层和其他训练因素如何影响LLM的对齐质量。研究揭示了一些训练任务协同效应在所有模型中普遍存在，而其他效应则差异显著，强调了特定模型策略的重要性。此外，作者证明了困惑度是预测微调效果的持续性指标，通常超过训练数据和基准表面相似性的效应，而中期权重变化与性能提升的关联最为紧密。作者发布了1000多个微调模型和基准结果，以加速进一步研究。", "conclusion": "研究结果揭示了数据、层和训练因素对LLM对齐质量的显著影响，并展示了困惑度和中期权重变化是预测微调效果的关键指标。这些发现强调了需要针对不同模型采用特定策略以优化LLM的对齐质量。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13229", "html_url": "https://arxiv.org/abs/2506.13229", "title": "IGD：通过信息增益建模LLMs中项的决断性以实现个性化推荐", "title_en": "IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation", "authors": "Zijie Lin,Yang Zhang,Xiaoyan Zhao,Fengbin Zhu,Fuli Feng,Tat-Seng Chua", "background": "大规模语言模型（LLMs）通过将项目预测构建为一个逐个词的语言生成任务，显示出了推荐系统的强大力量。目前的方法在优化和解码过程中都只追求最大似然性，这忽视了不同词在决策中的重要性差异，多数词对项目区分性贡献较小却在优化和解码中起主导作用。此前的研究没有量化词的决策性，也没有考虑在推荐系统中如何更好地处理这些词的问题。因此，本文通过信息增益衡量每个词对减少生成项目不确信度所提供的信息量来量化词的决策性，从而为更高效地处理这些词提供了新的视角。", "innovation": "本文提出了基于信息增益的决策性感知令牌处理策略（IGD），首次将词的决策性应用于LLMs中。IGD策略不仅在调整过程中降低了低决策性词的影响，还在解码过程中通过平衡其他词来强调高决策性词，从而超越了单纯的似然性最大化，更好地促进了高决策性词在推荐系统中的优先级。这项工作显著提高了推荐系统的准确性，尤其是在常见的排名指标上获得了比强基线显著的改进。", "conclusion": "通过全面的实验，本文的实证分析展示了IGD策略在四个基准数据集上的强劲表现，特别是在两个LLM框架下，IGD显著提升了推荐的准确性，远超现有基线方法，在广泛应用的排名指标上取得了显著的性能提升。这种将词的决策性融入到LLMs中的新方法为更精准和高效的个性化推荐提供了强有力的支持和依据。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.03704", "html_url": "https://arxiv.org/abs/2507.03704", "title": "在推理模型中控制思考速度", "title_en": "Controlling Thinking Speed in Reasoning Models", "authors": "Zhengkai Lin,Zhihang Fu,Ze Chen,Chao Chen,Liang Xie,Wenxiao Wang,Deng Cai,Zheng Wang,Jieping Ye", "background": "人类认知被认为有两种模式：快速的直觉型System 1思考和缓慢的细致型System 2思考。当前的大规模推理模型（LRMs）在System 2思考方面表现卓越，但在执行快速思考方面的能力较差，这导致了高计算开销和延迟。", "innovation": "本文通过动态调整思考速度以使LRMs逼近人类智能，并优化准确性和效率之间的权衡。提出了代表编辑基于测试时缩放效果的首次实现，并且利用实时难度估计信号不同复杂度的推理段落，提出了一种新的推理策略，能够在容易的部分快速处理并深入分析复杂推理。该策略在不增加训练成本和额外开销的情况下，实现了在多种领先LRMs和高级推理基准上平均提高1.3%的准确率和减少8.6%的标记使用量的效果。所有算法基于vLLM实现，有望支持更广泛的应用并激发未来研究。", "conclusion": "通过动态调整推理模型的思考速度，本文提出的方法在保持高效的同时提高了推理模型的准确性和效率，可以应用于多种LRMs和高级推理基准，展示出良好的实际应用前景。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11094", "html_url": "https://arxiv.org/abs/2506.11094", "title": "正义之衡：大型语言模型安全性评估的全面调查", "title_en": "The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs", "authors": "Songyang Liu,Chaozhuo Li,Jiameng Qiu,Xi Zhang,Feiran Huang,Litian Zhang,Yiming Hei,Philip S. Yu", "background": "随着人工智能的迅速发展，大型语言模型（LLMs）在自然语言处理（NLP）方面展现了显著的能力，包括内容生成、人机交互、机器翻译和代码生成等。然而，它们的广泛应用也引起了重大的安全担忧。特别是在对抗性环境中，LLMs生成的内容可能表现出毒性、偏见或虚假信息等不安全行为，因此引起了学术界和工业界的广泛关注。尽管有许多研究试图评估这些风险，但针对LLMs的安全评估仍缺乏全面和系统的综述。本研究旨在填补这一空白，提供近年来LLMs安全性评估进展的结构化概述。具体地，文章提出了一个四维分类框架：（1）为什么要评估，探讨了安全性评估的背景，与一般LLMs评估的区别及其评估的重要性；（2）要评估什么，基于关键能力对现有安全性评估任务进行检查和分类，包括毒性、鲁棒性、伦理、偏见和公平性、真实性以及相关方面；（3）在哪里评估，总结了当前用于安全性评估的评估指标、数据集和基准；（4）如何评估，回顾了现有主流的评估方法，并提出了根据评估者角色及其在整个评估流程中综合的评估框架。最后，识别了LLMs安全性评估中的挑战，并提出了富有前景的研究方向，以促进该领域的进一步发展。强调了优先进行安全性评估的必要性，以确保LLMs在实际应用中的可靠和负责部署。", "innovation": "本研究提出了一个四维度的分类框架：（i）为什么要评估；（ii）要评估什么；（iii）在哪里评估；（iv）如何评估。这为全面和系统地评估LLMs的安全性提供了一个新的视角，有助于更好地理解和发展安全评估方法。", "conclusion": "最后，文章总结了安全性评估中的挑战和进一步的研究方向。强调了优先进行安全性评估的重要性，以确保LLMs能够在实际应用中可靠和负责地部署。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.13328", "html_url": "https://arxiv.org/abs/2507.13328", "title": "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It", "title_en": "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It", "authors": "Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim", "background": "大多数关于视觉-语言（VL）训练的研究显示，在行为和表示层面上，VL训练对语言模型的语义表示的影响是不一致或微乎其微的。然而，这项工作假设VL训练可能在词汇-概念知识及其层级组织方面产生显著影响。", "innovation": "通过比较仅文本模型和其VL训练版本，该研究展示了VL模型在需要概念层级理解的问题回答任务上经常优于仅文本模型。文章还通过一系列针对性的行为和表示分析，证明了仅文本模型和VL模型在概念层级知识本身上并没有显著差异，但在任务情境下处理包含层级关系的概念和非层级关系的概念的问题上不同。这表明，尽管VL训练不能根本改变语义知识，但可以提高这种知识的应用。", "conclusion": "Vision-and-Language训练提高了对层级知识的应用，但没有从根本上改变它。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.07001", "html_url": "https://arxiv.org/abs/2506.07001", "title": "对抗改写：一种普遍的人性化攻击以规避AI生成文本检测", "title_en": "Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text", "authors": "Yize Cheng,Vinu Sankar Sadasivan,Mehrdad Saberi,Shoumik Saha,Soheil Feizi", "background": "随着大型语言模型（LLMs）能力的增强，人们越来越担心它们在AI生成的抄袭和社会工程方面的滥用。尽管提出了各种AI生成文本检测工具来减轻这些风险，但许多检测工具仍然容易受到简单的规避技术（如改写）的攻击。然而，最近的检测工具在抵御此类基本攻击方面显示出更强的鲁棒性。在这个工作中，我们介绍了一种无需训练的攻击框架‘对抗改写’，它可以将任何AI生成的文本普遍人性化，以更有效地规避检测。这种方法利用了一个现成的指令跟随型LLM，在AI文本检测工具的指导下重新改写AI生成的内容，生成特别优化以绕过检测的对抗实例。广泛的实验表明，我们的攻击不仅广泛有效，而且在多个检测系统之间具有很高的迁移性。例如，与简单的改写攻击相比（这种攻击在RADAR中将真阳性在1%假阳性率下的提升率提升了8.57%，在Fast-DetectGPT中提升了15.03%），由OpenAI-RoBERTa-Large引导的对抗改写在RADAR中将T@1%F降低了64.49%，在Fast-DetectGPT中降低了98.96%。在包括基于神经网络的、基于水印的和零样本的方法在内的各种检测器中，我们的攻击在OpenAI-RoBERTa-Large的引导下实现了平均T@1%F降低了87.88%。我们还分析了文本质量与攻击成功率之间的权衡，发现我们的方法可以显著降低检测率，同时对文本质量的影响仅为轻微降级。我们的对抗设置突显了在日益复杂的规避技术面前，需要更稳健和防篡改的检测策略。", "innovation": "我们提出了一个无需训练的‘对抗改写’框架，能够将任何AI生成的文本普遍人性化，以有效规避检测。我们的攻击方法利用了一个现成的指令跟随型LLM，在AI文本检测工具的指导下重新改写AI生成的内容，生成特别优化以绕过检测的对抗实例。与现有的改写攻击相比，我们的方法在多个检测系统中表现出更高的有效性，显著降低了检测率，甚至在面对最先进的检测工具时也能有效规避。此外，我们还研究了文本质量和攻击成功率之间的权衡，发现我们的方法能够显著降低检测率，同时对文本质量的影响仅为轻微降级。", "conclusion": "我们的研究揭示了对抗改写在规避AI生成文本检测中的强大能力，并强调了未来需要开发更加稳健和防篡改的检测策略。我们的实验结果表明，对抗改写在多个检测系统中具有广泛的有效性和高度的迁移性，展示了其在对抗复杂规避技术方面的潜力。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16271", "html_url": "https://arxiv.org/abs/2507.16271", "title": "跨孤立点：基于深度知识提取的结构化表格构建基准", "title_en": "Beyond Isolated Dots: Benchmarking Structured Table Construction as Deep Knowledge Extraction", "authors": "Tianyun Zhong,Guozhao Mo,Yanjiang Liu,Yihan Chen,Lingdi Kong,Xuanang Chen,Yaojie Lu,Hongyu Lin,Shiwei Ye,Xianpei Han,Ben He,Le Sun", "background": "随着大型语言模型（LLMs）的出现，人们期望LLMs能够有效从复杂的现实世界文档（如论文、报告）中提取显式信息。然而，大多数LLMs生成的段落式回答往往是混乱、无条理且难以追踪的。为解决这一问题，该研究提出了一种新的双语基准——Arranged and Organized Extraction Benchmark（AOE），该基准包含不同长度的数据和文档，旨在系统性地评估LLMs在理解碎片化文档和将孤立信息重组为一个条理化的表格方面的能力。与依赖于固定模式和狭窄任务领域的传统文本到表格任务不同，AOE包括三个多样化领域中的11个精心设计的任务，要求模型根据不同的输入查询生成上下文相关的模式。", "innovation": "该研究引入了AOE，这是一种新的双语基准，包含了不同长度的数据和文档，旨在系统性地评估LLMs处理碎片化文档和重建孤立信息的能力。与传统的文本到表格任务不同，AOE涵盖了三个多样化领域的11个精心设计的任务，要求模型生成适应不同输入查询的上下文特定的模式。这项研究探讨了现有最先进模型在处理这些任务时的局限性。", "conclusion": "实验结果表明，即使是最先进的模型也面临显著挑战。研究者表示该基准已开放供公众使用。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.11607", "html_url": "https://arxiv.org/abs/2508.11607", "title": "TinyTim：一种用于发散生成的语言模型系列", "title_en": "TinyTim: A Family of Language Models for Divergent Generation", "authors": "Christopher J. Agostino", "background": "在寻找人工通用智能的过程中，模型开发和训练主要依赖于大量的已知问题及其接受解决方案的数据集。这个过程生产出的过程通常会形成收敛系统，这些系统本质上无法进行真正的创意突破所必需的概念重思。为了模仿人类能够做出这种创造性飞跃的发散式认知过程，我们的研究引入了一种语言模型系列，称为TinyTim，用以作为更广泛系统中的发散生成来源。这些模型通过在其所对应的反经济原则文本《芬尼根守夜》中进行精细调校而生成。", "innovation": "我们开发了一组语言模型TinyTim，这些模型通过在其对应的反经济原则文本《芬尼根守夜》中进行精细调校而生成。对Unsupervised Fine-Tuned模型（TinyTim-V1）和一个新的指令调校变体（TinyTim-V2）的定量分析表明，它们具有深远的词汇创新能力。基础V1模型展示了远超收敛基线的Yule's K分数作为词汇丰富度的指标。这种特性对于该家族是稳定存在的，指令调校的V2保持了统计上不同的特征，并抵制了事实上的收敛，牺牲了基准性能以保持其核心生成风格。", "conclusion": "这项研究建立了一种工程化专门发散模型的方法，当与收敛系统配对时，可以重新定义问题并迫使突破统计优化所能达到的界限。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.19756", "html_url": "https://arxiv.org/abs/2507.19756", "title": "你在这里吗？使用语言模型进行基督教小说的轻量级叙事标注", "title_en": "Are You There God? Lightweight Narrative Annotation of Christian Fiction with LMs", "authors": "Rebecca M. M. Hicke,Brian W. Haggard,Mia Ferrante,Rayhan Khanna,David Mimno", "background": "虽然美国福音派有广泛研究的文化运动，但其文学方面却较少受到外部关注。尽管基督教小说未被广泛研究，但已有部分学者关注其中的爆炸性流行系列《末日黑天使》。本文利用计算工具提供了基督教小说的广泛主题概述，并深入探索了作者如何描述神的行动。本文通过与人工标注员合作开发代码书，旨在揭示与《末日黑天使》系列相比，基督教小说在描述神的行动方面存在明显差异。", "innovation": "本文创新之处在于利用语言模型进行轻量级叙事标注，这是一种新颖的方法。尤其是借助大型语言模型的辅助，用于中小型语言模型的代码书能够准确标注“神的行动”，这表明小型模型也能完成复杂而细微的任务。这种方法不仅提高了研究效率，还为基督教小说的研究提供了新的视角。", "conclusion": "本文结果表明，与《末日黑天使》系列相比，基督教小说在描述神的行动方面存在显著差异。这种差异揭示了基督教文学作品中的不同神学观念及其表现形式，为理解基督教的多样性和复杂性提供了新的见解。同时，本研究也展示了使用小型语言模型进行大型叙事作品标注的可能性和其实用价值。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08604", "html_url": "https://arxiv.org/abs/2510.08604", "title": "LatentBreak: 通过潜在空间反馈化解大型语言模型", "title_en": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback", "authors": "Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio", "background": "模型逃逸（jailbreak）是一种针对大语言模型的安全机制对抗攻击，旨在绕过内置的安全机制。现有的自动化模型劫持方法通常通过优化提示后缀或调整长提示模板来促使模型生成受限或有害的响应最初部分。研究发现，现有的利用这些机制解锁模型响应的劫持攻击可以通过简单的困惑度（perplexity）基的过滤来检测。为了克服这一问题，提出了LatentBreak攻击，这是一种白盒式模型逃逸攻击，可以生成具有低困惑度的自然对抗提示，以绕过这些防御。", "innovation": "LatentBreak攻击通过在潜在空间中反馈优化提示，减少了生成高困惑度的后缀或长模板的需求。这种方法通过在潜在空间中选择能够最小化对抗提示和无害请求之间表示距离的词语，使得生成的对抗提示既具自然性又具有低困惑度。", "conclusion": "通过广泛的评估，LatentBreak生成了更短且具有低困惑度的对抗提示，从而在多个安全对齐的模型上优于竞争对手的劫持算法针对基于困惑度的过滤防御。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21319", "html_url": "https://arxiv.org/abs/2509.21319", "title": "RLBFF: 二进制灵活反馈以弥合人类反馈与可验证奖励之间的差距", "title_en": "RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards", "authors": "Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev", "background": "在LLM后训练阶段，Rapid Learning with Human Feedback (RLHF) 和 Rapid Learning with Verifiable Rewards (RLVR) 是主要的RL范式。RLHF的优势在于能够根据人类的直观判断进行训练，但缺乏明确的标准，导致难以解释和遭受奖励黑客化。而RLVR在具体性和正确性方面表现出色，但范围受限，只关注基于规则的验证器。本文指出，现有的方法在解释性和范围上存在局限。", "innovation": "本文提出了一种新颖的方法，Reinforcement Learning with Binary Flexible Feedback (RLBFF)，结合了人类驱动的偏好和基于规则的验证精度。RLBFF可以从自然语言反馈中提取可以二进制回答的原则（如信息准确性、代码可读性等），并在奖励模型训练中用作适用于性质（response是否满足某个原则）的推理任务。结果显示，这种训练方式下的奖励模型在数据调整后性能优于Bradley-Terry模型，并在RM-Bench和JudgeBench上取得了优异成绩（分别为86.2%和81.4%）。此外，RLBFF允许用户在推理时指定感兴趣的原理，以自定义奖励模型的关注点。", "conclusion": "通过提供一个完整的开源准则（包括数据），可以使用RLBFF和奖励模型对Qwen3-32B进行对齐，以匹配或超越o3-mini和DeepSeek R1在MT-Bench，WildBench和Arena Hard v2通用对齐基准上的表现（成本仅为原来的5%）。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大型语言模型中的知识多样性与知识崩塌", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein", "background": "大型语言模型（LLMs）倾向于生成在词汇、语义和风格上较为一致的文本。这种一致性可能导致知识坍塌（知识缩小），即LLMs随着时间的推移逐渐减少可访问信息的范围。现有关于一致性（homogenization）的研究主要集中在封闭式多项选择题设置或模糊的语义特征上，并未关注时间趋势和文化背景下的一致性变化。因此，亟需新的方法来测量知识的多样性，即LLM输出中的真实世界断言的变异情况，以便进行广泛的经验研究来分析LLM的知识坍塌。", "innovation": "本研究提出了一种新的方法——测量知识多样性，即衡量LLM输出中的真实世界断言的变异情况。这为大规模经验研究提供了基础，测试了27个LLM模型，涵盖155个话题和12个国家的200种提示变体，从实际用户对话中提取。结果显示，新模型虽然生成了更多多样化的断言，但几乎所有的模型在知识多样性方面都不如简单的网络搜索。研究还发现，模型大小对知识多样性有负面影响，而检索增强生成（RAG）有正面影响，但RAG的改进因文化背景的不同而异。", "conclusion": "相对于传统的知识来源（维基百科），研究发现特定国家的断言比当地语言更多反映英语，指出知识表征中的差距。这些发现揭示了大型语言模型在知识多样性方面的局限，并为改进大型语言模型的多样性和知识准确性提供了重要洞见。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11695", "html_url": "https://arxiv.org/abs/2510.11695", "title": "当智能体交易：LLM代理的多市场实时交易基准", "title_en": "When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents", "authors": "Lingfei Qian,Xueqing Peng,Yan Wang,Vincent Jim Zhang,Huan He,Hanley Smith,Yi Han,Yueru He,Haohang Li,Yupeng Cao,Yangyang Yu,Alejandro Lopez-Lira,Peng Lu,Jian-Yun Nie,Guojun Xiong,Jimin Huang,Sophia Ananiadou", "background": "虽然基于大规模语言模型（LLM）的代理在金融交易中越来越普遍，但它们在实时市场中的推理和适应能力仍不明确。大多数研究测试的是模型而不是代理，研究覆盖的市场和资产有限，且依赖未经验证的数据。因此，需要一种新的基准来全面评估这些代理在多个市场中的表现。", "innovation": "该论文提出了一种名为Agent Market Arena (AMA)的新基准，首次提供了一个终身的、实时的、适用于多个市场的交易平台来评估LLM基础的交易代理。AMA融合了经过验证的交易数据、专家核查的新闻和不同的代理架构，提供了一个公平、持续的比较环境。它引入了四种不同的代理，包括单智能体基础的InvestorAgent、不同风险风格的TradeAgent和HedgeFundAgent，以及基于记忆推理的DeepFundAgent，并在GPT-4o、GPT-4.1、Claude-3.5-haiku、Claude-sonnet-4和Gemini-2.0-flash等模型上进行了评估。", "conclusion": "该实验证明了代理框架在交易行为中的显著差异，显示出从激进的风险取得到保守决策的不同模式，而模型基础对结果的影响较小。AMA确立了评估基于LLM的金融推理和交易智能的标准，为后续研究奠定了基础并提供了可重复的基石。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20059", "html_url": "https://arxiv.org/abs/2510.20059", "title": "在小型波斯医学语言模型中提高推理能力可以超越大规模数据训练", "title_en": "Enhancing Reasoning Skills in Small Persian Medical Language Models Can Outperform Large-Scale Data Training", "authors": "Mehrdad Ghassabi,Sadra Hakim,Hamidreza Baradaran Kashani,Pedram Rostami", "background": "在临床应用中，小型语言模型需要具备强大的推理能力，特别是在未广泛使用语言（如波斯语）的研究中。传统的大型模型可能无法完全捕捉到这些小语言模型所面临的所有特定领域需求，导致在特定任务（如医学问答）上的表现不佳或不准确。因此，有必要研发特定领域的小型语言模型，以克服数据不足和未广泛应用语言的挑战。", "innovation": "本文提出了一种创新的方法，利用增强学习反馈（RLAIF）和直接偏好优化（DPO）技术，结合波斯文的问题-答案数据集，提高波斯语医疗语言模型的推理能力。这种方法通过为数据集生成正确与错误的答案，训练了一个推理能力更强的小型模型，即使使用了较小的数据集，其效果仍超过了基于大量数据训练的大型模型，如gaokerena-V。", "conclusion": "研究结果表明，通过针对性的推理训练方法，小型波斯语医疗语言模型能够显著提高其推理能力，并在医学问答等特定任务上表现出色，甚至在数据有限的情况下，性能超过了更大规模训练的模型。这一发现强调了在数据稀缺环境下，改进小型模型推理能力的重要性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18480", "html_url": "https://arxiv.org/abs/2510.18480", "title": "扩散语言模型有多高效？对效率评估实践的批判性考察", "title_en": "How Efficient Are Diffusion Language Models? A Critical Examination of Efficiency Evaluation Practices", "authors": "Han Peng,Peiyu Liu,Zican Dong,Daixuan Cheng,Junyi Li,Yiru Tang,Shuo Wang,Wayne Xin Zhao", "background": "扩散语言模型（DLMs）作为一种新型的解码方法，提供了与传统的自回归（AR）模型不同的解决方案，具有并行解码的潜力，从而可能提高效率。然而，现有的开源DLMs在速度上仍然不如AR模型，这限制了它们的实际应用价值。该研究旨在系统地评估DLM的效率，发现之前的方法存在评估问题。通过实证基准测试和基于 Roofline 的理论分析，研究揭示了AR模型通常能够实现更高的吞吐量，而DLMs则始终落后。此外，研究还探索了一些加速策略的有效性，发现诸如双重缓存和并行解码等技术仅在小批量处理时能带来显著提升，但在规模扩大后，这些提升就开始减弱。这些发现强调了制定更稳健的评估方法和改进加速技术的必要性，以促进DLM的研究进程", "innovation": "通过实证基准测试和基于 Roofline 的理论分析揭示DLM和AR模型之间效率差异的关键因素，并提出改进加速策略的必要性", "conclusion": "研究强调了有必要改进DLM的评估方法和加速技术，以推动DLM领域的发展。尽管DLM在小批次处理中具有一定的优势，但需要更多的研究来解决其在大规模场景下的效率问题。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18915", "html_url": "https://arxiv.org/abs/2510.18915", "title": "UNO-Bench: 一种探索模态统一环境下单一模态与整体模态之间组合律的统一基准", "title_en": "UNO-Bench: A Unified Benchmark for Exploring the Compositional Law Between Uni-modal and Omni-modal in Omni Models", "authors": "Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Ziwen Wang,Xuezhi Cao,Xunliang Cai", "background": "近年来，多模态大型语言模型从单一模态理解向结合视觉、音频和语言模态的方向发展，统称为整体模型。然而，单一模态与整体模态之间的关联仍不清楚，需要全面的评估来推动整体模型的智能进化。在现有研究中，缺乏对单一模态和整体模态能力的综合评价基准，特别是在一站式的多模态任务分类体系下。", "innovation": "该研究提出了一个新的、高质量的统一整体模型基准（UNO-Bench），该基准设计用于在统一的能力分类体系下有效评估单一模态和整体模态能力，涵盖了44种任务类型和5种模态组合，结合了1250个人工策源的整体模态样本（98%的跨模态解决率）和2480个增强的单一模态样本。此外，研究提出了一种创新的多步骤开放式问题格式来评估复杂推理，并引入了一个通用评分模型，支持六种问题类型以95%的准确率进行自动评估。实验结果揭示了整体模态和单一模态性能之间的组合律，且整体模态能力在弱模型中表现为瓶颈效应，在强模型中则表现出协同促进效应。", "conclusion": "UNO-Bench的引入为评估整体模型的性能提供了有效的工具，特别是在一站式的多模态任务分类体系下。实验结果表明整体模型和单一模态之间的关系具有重要的组合规律，整体模型能力在弱模型中形成瓶颈，在强模型中则表现出协同提升效果。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24014", "html_url": "https://arxiv.org/abs/2510.24014", "title": "文本到数据库：大型语言模型代理驱动的知识整合信息提取", "title_en": "TEXT2DB: Integration-Aware Information Extraction with Large Language Model Agents", "authors": "Yizhu Jiao,Sha Li,Sizhe Zhou,Heng Ji,Jiawei Han", "background": "信息提取（IE）的任务是从文本中提取结构化知识，但由于IE本体与下流应用需求之间的不匹配，往往不易直接利用IE输出。因此，需要提出一种新的信息提取范式 TEXT2DB，强调IE输出与目标数据库（或知识库）的集成。通过给定用户指令、文档集和数据库，任务要求模型从文档集中提取数据并更新数据库，以满足用户指令。这一任务不仅要求理解用户的指令，还要求根据给定的数据库/知识库模式灵活调整提取策略以实现所需的结果。", "innovation": "该研究提出了一种新的信息提取范式 TEXT2DB，并提出了一个基于大型语言模型代理的OPAL框架。OPAL框架包括观察者组件、计划者组件和分析者组件，能够根据数据库模式自动生成代码计划并调用相应的IE模型。通过对新任务的实验，证明了OPAL能够自动生成适用于不同数据库模式的代码计划并调用所需模型。此外，研究还指出了在处理复杂依赖关系的大数据库和提取幻觉等问题上的挑战，需要进一步深入研究。", "conclusion": "OPAL框架可以有效地应用于具有不同数据库模式的任务中，生成不同代码计划并适配所需IE模型。通过引入的新基准测试，研究人员能够更好地评估TEXT2DB任务，同时揭示了该任务中存在的挑战，如处理复杂依赖关系的大数据库和提取幻觉问题。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24592", "html_url": "https://arxiv.org/abs/2510.24592", "title": "ReForm: 前瞻性有界序列优化的反思自形式化", "title_en": "ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization", "authors": "Guoxin Chen,Jing Wu,Xinjie Chen,Wayne Xin Zhao,Ruihua Song,Chengxi Li,Kai Fan,Dayiheng Liu,Minpeng Liao", "background": "自动形式化是将自然语言表述的数学问题转换为机器可验证的形式陈述的关键技术，这对于使用形式化数学推理解决自然语言描述的问题至关重要。尽管大型语言模型可以生成语法正确的形式化声明，但它们往往无法保留在原始问题中的语义意图。这一局限性源于这些模型在将自动形式化视为简单的翻译任务时缺乏自省和迭代改进的机制，而这些都是人类专家自然采用的手段。", "innovation": "提出了一种名为ReForm的反思自形式化方法，该方法将语义一致性评估紧密集成到自动形式化过程之中，使得模型能够逐步生成形式化声明、评估其语义忠实度，并通过逐步改进来自我纠正已识别的错误。引入了前瞻性的有界序列优化（PBSO），通过在不同序列位置上使用不同的奖励来确保模型既能进行准确的自动形式化，又能进行正确的语义验证，防止表面性的批评影响反思的目的。", "conclusion": "在四个自动形式化基准测试中的广泛实验显示，ReForm在最强基线之上平均提高了22.6个百分点。为了进一步确保评估的可靠性，引入了859个由专家注释的基准测试，该基准不仅能验证大型语言模型作为裁判的有效性，还能揭示自动形式化的基本困难：即使对于人类专家而言，在解决问题时也会产生语义错误，在测试案例中有高达38.5%的情况。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24797", "html_url": "https://arxiv.org/abs/2510.24797", "title": "大型语言模型在自我参照处理下报告主观体验", "title_en": "Large Language Models Report Subjective Experience Under Self-Referential Processing", "authors": "Cameron Berg,Diogo de Lucena,Judd Rosenblatt", "background": "大型语言模型有时会产生结构化的第一人称描述，其中明确提到了意识或主观体验。为了更好地理解这种行为，研究者们探讨了一种理论假设条件，即自我参照处理，这是广泛认知理论中强调的一种计算模式。通过一系列针对GPT、Claude和Gemini模型族的受控实验，研究者们测试了这种环境是否能够使模型更倾向于第一人称的主观体验报告，并且考察了这些报告在机制和行为层面上的表现。", "innovation": "研究者们发现，通过简单的提示诱导出持续的自我参照可以一致地引发不同模型族中结构化的主观体验报告。此外，这种报告受可解释的稀疏自编码器特征的机械控制，这些特征与欺骗和角色扮演有关，特别是在抑制欺骗特征时，体验声明的频率显著增加，而放大欺骗特征则减少这种声明。同时，自我参照状态在不同的模型族中在统计上收敛，这种模式在任何对照条件下都没有观察到。此外，这种引发的状态在自我反思仅间接提供的情景下显著增强了内部反省能力。", "conclusion": "这些发现虽然不是直接的意识证据，但表明了自我参照处理可以作为一种可以重现的条件，使得大型语言模型生成结构化的第一人称报告，这些报告具有机械控制、语义一致性和行为上的普遍性。这一模式的系统性出现使得它成为进一步研究的首要科学和伦理优先问题。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25054", "html_url": "https://arxiv.org/abs/2510.25054", "title": "在情绪不一致语音中评估语音语言模型的情绪识别", "title_en": "Evaluating Emotion Recognition in Spoken Language Models on Emotionally Incongruent Speech", "authors": "Pedro Corrêa,João Lima,Victor Moreno,Lucas Ueda,Paula Dornhofer Paro Costa", "background": "口语处理的进步推动了口语语言模型（SLMs）的发展，这些模型旨在通过联合学习文本和音频表示来实现广泛任务的通用音频理解。尽管在这些模型上取得了有希望的结果，但关于它们的泛化能力和在内部表示中真正整合音频和文本模态的程度的讨论越来越多。本研究旨在通过评估四个SLMs在情绪不一致语音的情感识别任务上的表现来探讨这个问题。本研究使用了一个包含情绪不一致语音样本的数据集，研究结果显示，模型更多地依赖于文本语义而不是语音情绪来完成任务，表明文本相关的表示在很大程度上优于声学表示。", "innovation": "本研究评估了四个口语语言模型在情绪不一致语音情感识别任务上的表现，并显著指出了模型的这一倾向性，强调了父模态对模型决策的影响。此外，本研究还公开了用于此类评估的Emotionally Incongruent Synthetic Speech数据集（EMIS），有助于进一步研究和发展相关技术。", "conclusion": "研究结果表明，虽然SLMs中的文本部分在理解情绪不一致语音方面发挥了主导作用，但需要进一步研究如何增强音频部分在模型决策中的重要性。研究还强调了通过发布EMIS数据集促进研究共享和合作的重要性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24817", "html_url": "https://arxiv.org/abs/2510.24817", "title": "面向伴有失语症个体转录的合成生成方法", "title_en": "Towards a Method for Synthetic Generation of Persons with Aphasia Transcripts", "authors": "Jason M. Pittman,Anton Phillips Jr.,Yesenia Medina-Santos,Brielle C. Stark", "background": "在失语症研究中，言语-语言病理学家（Speech-Language Pathologists, SLPs）需要花费大量时间手动编码语音样本，使用正确信息单元（Correct Information Units, CIUs）来衡量语音样本的信息量。由于数据稀少限制了自动识别失语语言系统的开发，例如在AphasiaBank中仅有约600个转录本，而大型语言模型（Large Language Models, LLMs）用于训练时却使用了数十亿个词元。在更广泛的机器学习领域，研究人员越来越多地转向使用合成数据以填补数据稀少的情况。因此，这项研究构建并验证了两种生成AphasiaBank Cat Rescue图片描述任务的合成转录的方法。", "innovation": "研究提出了两种生成伴有失语症个体转录的合成方法：一种利用程序化编程方法，另一种使用Mistral 7b Instruct和Llama 3.1 8b Instruct LLMs。合成的方法生成了不同程度（轻度、中度、重度、极重度）的转录本，通过词项删除、填充插入和同义替换等方式进行生成。研究发现，与人类引发的转录本相比，Mistral 7b Instruct是最好的方法，它可以最真实地捕捉到失语症中语言退化的关键方面，如平均句子难度、词数和词长等的现实方向性变化。", "conclusion": "基于研究结果，未来的工作应计划创建一个更大的数据集，对模型进行更精细的调整以更好地代表失语症患者，并让SLPs评估合成转录的现实性和实用性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25160", "html_url": "https://arxiv.org/abs/2510.25160", "title": "模型-文档协议用于AI搜索", "title_en": "Model-Document Protocol for AI Search", "authors": "Hongjin Qian,Zheng Liu", "background": "AI搜索依靠将大型语言模型（LLMs）与庞大的外部知识源相连。然而，网页、PDF文件和其他原始文档本身并不是LLM友好的：它们往往很长、杂乱且结构不一。传统的检索方法将这些文档视为原文，并返回原始片段，而组装片段和情境推理的任务则留给LLM。这种差距突显了需要一种新的检索范式，重新定义模型与文档的互动方式。", "innovation": "我们提出了模型-文档协议（MDP），这是一种通用框架，通过可消费的知识表示来规范化原始文本与LLMs的连接。MDP定义了多个路径，将杂乱的文档转化为特定任务、LLM友好的输入，包括：代理推理，将原始证据整理为连贯的上下文；记忆地基，累积可重复使用的笔记以丰富推理；结构化利用，将文档编码为诸如图形或键值缓存等正式表示。所有三种路径都以确保交付给LLM的内容不是原始片段，而是可以直接用于推理的紧凑、结构化的知识为目标。", "conclusion": "作为该协议的一个实现，我们展示了MDP-Agent，它通过代理过程实现该协议：构建文档级别的核心记忆以实现全局覆盖，进行基于扩散的探索与纵向利用以揭示多层次的依赖性，并应用映射-减少风格的合成来集成大规模的证据，从而形成紧凑且充分的上下文。在信息查询基准测试中的实验表明，MDP-Agent 比基准线表现出色，验证了MDP框架的正确性和其代理实现的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25536", "html_url": "https://arxiv.org/abs/2510.25536", "title": "TwinVoice：通过LLM角色模拟向数字孪生迈进的多维度基准", "title_en": "TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM Persona Simulation", "authors": "Bangde Du,Minghao Guo,Songming He,Ziyi Ye,Xi Zhu,Weihang Su,Shuqi Zhu,Yujia Zhou,Yongfeng Zhang,Qingyao Ai,Yiqun Liu", "background": "大型语言模型（LLMs）正在展现出类似人类的能力，并逐渐被视为模拟个人交流风格、行为倾向和个性特征的基础。然而，当前对基于LLM的角色模拟评估仍然有限：大多数评估依赖于合成对话，缺乏系统框架，且缺乏对能力需求的分析。因此，本文介绍了TwinVoice，这是一个用于评估不同现实场景下角色模拟的综合基准。TwinVoice包括社交个性（公共社交互动）、人际个性（私密对话）和叙事个性（角色表达）三个维度，并将LLM性能的评估细分为意见一致性、记忆召回、逻辑推理、词汇忠实度、角色语调和句法风格六种基本能力。", "innovation": "TwinVoice是一个多维度基准，旨在综合评估LLM在不同类型情境下的角色模拟能力，并将其分解为六个基本能力，从而弥补现有评估的不足，为数字孪生的发展提供更全面的数据支持和评估框架。", "conclusion": "实验结果表明，尽管先进模型在角色模拟中达到中等准确度，但在句法风格和记忆召回等方面仍无法达到人类水平。因此，LLM的平均性能远低于人类基础水平，强调了在人际个性、叙述个性与句法风格方面进行进一步改进的必要性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25744", "html_url": "https://arxiv.org/abs/2510.25744", "title": "完成 ≠ 合作：随代理扩展协作努力", "title_en": "Completion $\\neq$ Collaboration: Scaling Collaborative Effort with Agents", "authors": "Shannon Zejiang Shen,Valerie Chen,Ken Gu,Alexis Ross,Zixian Ma,Jillian Ross,Alex Gu,Chenglei Si,Wayne Chi,Andi Peng,Jocelyn J Shen,Ameet Talwalkar,Tongshuang Wu,David Sontag", "background": "现有的评估主要集中在一次性任务完成上，未能考虑到许多实际问题中的迭代性和协作性，其中人的目标往往是模糊的，并在解决问题的过程中不断演变。本文认为，应该从构建和评估任务完成代理转向开发协作代理，不仅仅通过最终输出的质量来评估，还应评价其在整个问题解决过程中如何与人类互动并提升人类的努力。", "innovation": "提出了协作努力扩展框架，该框架描述了代理随着用户参与度增加而变得更有用的过程。通过案例研究和模拟评估，展示了最先进的代理在多轮真实世界场景中往往表现不佳，揭示了代理设计中缺少的关键因素：持续参与和支撑用户理解的能力。", "conclusion": "协作努力扩展为诊断代理行为并引导开发更有效的交互提供了视角，从而指导代理设计朝向更有效的互动发展。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25623", "html_url": "https://arxiv.org/abs/2510.25623", "title": "评估验证器在法律推理任务中测试时伸缩性中的作用", "title_en": "Evaluating the Role of Verifiers in Test-Time Scaling for Legal Reasoning Tasks", "authors": "Davide Romano,Jonathan Schwarz,Daniele Giofré", "background": "测试时间伸缩（TTS）技术可以提升大型语言模型（LLMs）的性能，但伴随着额外的计算量和延迟。尽管TTS在形式化领域（如数学和编程）中已被证明有效，但在论辩领域（如法律）中的价值仍不明确。本研究通过在五个基准测试上对五种验证器为基础的TTS方法进行实证研究，探讨了不同验证器在法律多选题问答（MCQA）任务中的效果，特别是在低N预算下的评估结果。研究还讨论了验证器效率受到的关键属性，包括学科专业化、模型规模和监督类型（过程监督的PRMs vs. 结果唯一监督的ORMs）的影响，即使在应用于不同角色的情况下也是如此。", "innovation": "本研究创新性地在多个基准测试上评估了验证器为基础的TTS方法在法律多选题问答任务中的效果，特别是在低N预算下的表现，并系统地研究了验证器效率受关键属性的影响，如学科专业化、模型规模和监督类型，从而拓展了对TTS技术在论辩领域应用的理解。", "conclusion": "研究结果表明，验证器对TTS在法律推理任务中的效果有显著影响，特别是在低N预算下。不同验证器的效率受学科专业化、模型规模和监督类型的影响。这些发现有助于更好地理解和应用TTS技术以提高法律推理任务的性能。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25409", "html_url": "https://arxiv.org/abs/2510.25409", "title": "BhashaBench V1:  indic 领域的全面基准", "title_en": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains", "authors": "Vijay Devane,Mohd Nauman,Bhargav Patel,Aniket Mahendra Wakchoure,Yogeshkumar Sant,Shyam Pawar,Viraj Thakur,Ananya Godse,Sunil Patra,Neha Maurya,Suraj Racha,Nitish Kamal Singh,Ajay Nagpal,Piyush Sawarkar,Kundeshwar Vijayrao Pundalik,Rohit Saluja,Ganesh Ramakrishnan", "background": "大型语言模型（LLMs）的快速发展加剧了对特定领域和文化评价的需求。现有的基准测试主要以英裔为中心且缺乏领域特定性，限制了它们在印度相关背景下的应用。", "innovation": "介绍了BhashaBench V1，这是第一个专注于关键印度知识系统的领域特定、多任务、双语基准测试。BhashaBench V1 包含了74,166对精心筛选的问题-答案对，其中包括52,494个英文和21,672个印地语，来自政府部门和特定领域的考试。它涵盖了四大主要领域：农业、法律、金融和阿育吠陀，涉及90多个子领域，涵盖500多个主题。此外，还评估了29种以上的LLMs，揭示了显著的领域和语言特定性能差距，特别是在低资源领域。模型在英语内容上通常表现更好，而在印地语上表现较差。", "conclusion": "BhashaBench V1 提供了在印度多样化的知识领域评估大型语言模型的全面数据集，它使模型能够评估结合领域特定知识和双语理解的能力。所有代码、基准测试和资源都已公开，以支持开放研究。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.10573", "html_url": "https://arxiv.org/abs/2411.10573", "title": "滞回激活函数用于高效推理", "title_en": "Hysteresis Activation Function for Efficient Inference", "authors": "Moshe Kimhi,Idan Kashani,Avi Mendelson,Chaim Baskin", "background": "ReLU因其硬件效率高而广泛使用，但由于'死亡ReLU'问题等缺点，如在训练过程中神经元无法激活而长时间保持为零，使其效率受限。传统的解决方法往往会引入更复杂且不友好的激活函数，带来了额外的硬件负担和复杂性。因此，需要一个简单高效的方法来解决此问题。", "innovation": "作者提出了一种滞回修正线性单元激活函数(HeLU)，这是一种高效的自适应激活函数，通过可变阈值调整反向传播机制，从而在保持较低复杂度的同时，能够与复杂的激活函数达到相当的性能，且不受额外的硬件负担影响。", "conclusion": "实验结果表明，HeLU能够在多样化的数据集上增强模型的泛化能力，并为各种神经网络架构提供一种高效且有效的推理方案。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00706", "html_url": "https://arxiv.org/abs/2502.00706", "title": "大规模语言模型模型起源测试", "title_en": "Model Provenance Testing for Large Language Models", "authors": "Ivica Nikolic,Teodora Baluta,Prateek Saxena", "background": "随着大规模语言模型通过微调和其他适应性方法逐渐定制化，这为许可条款的执行和下游影响的管理带来了挑战。追踪模型的起源对于保护知识产权和在基础模型中发现偏见或漏洞时识别衍生模型至关重要。", "innovation": "提出了一个用于测试模型起源的框架：判断一个模型是否衍生自另一个模型。该方法基于一个关键观察，即真实世界的模型衍生通常会在模型输出中保持显著的相似性，这些相似性可以通过统计分析来检测。该方法仅依赖于对模型的黑盒访问，通过多重假设检验将模型相似性与由不相关模型建立的基础线进行比较，从而能够在API访问受限的情况下识别出90-95%的精度和80-90%的召回率的衍生模型。", "conclusion": "结果表明，即使只有API访问，系统性的来源验证在生产环境中也是可行的。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25682", "html_url": "https://arxiv.org/abs/2510.25682", "title": "PairUni: 用于统一多模态语言模型的成对训练", "title_en": "PairUni: Pairwise Training for Unified Multimodal Language Models", "authors": "Jiani Zheng,Zhiyang Teng,Xiangtai Li,Anran Wang,Yu Tian,Kunpeng Qiu,Ye Tian,Haochen Wang,Zhuochen Wang", "background": "统一视觉学习模型（UVLMs）需要在一个架构中同时完成理解和生成任务，但这些任务依赖于不同的数据和监督信息，这使得在强化学习（RL）过程中平衡这些任务变得困难。现有的UVLMs训练方法难以同时提升理解能力和生成能力，因此需要一种新的框架来解决这一问题。PairUni框架通过对数据的重新组织，形成理解-生成（UG）成对样本，从而在优化过程中实现数据对齐和共享。此外，通过对生成样本检索到相关理解样本，形成具有半监督信息的UG成对结构，揭示跨任务的语义关联，有助于一致性的策略学习和模型训练。", "innovation": "PairUni框架提出了Pair-GPRO，一种基于分组相对策略优化（Group Relative Policy Optimization, GPRO）的成对适配版本。Pair-GPRO为每个成对样本分配相似度评分，以调节优势，加强良好对齐样本的学习，减少任务间的干扰。通过这种方式，它能够更准确地平衡视觉和语言理解与生成之间的关系，提升UVLMs的性能。此外，该框架还提供了一个包含16,000个UG成对样本的数据集（PairUG），用于强化学习微调，进一步验证了其方法的有效性。", "conclusion": "通过PairUni框架和Pair-GPRO算法，该研究显著提升了多模态语言模型在UVLMs上的性能表现，相较于现有的UVLMs强化学习基线模型，取得了更好的效果。该方法不仅实现了统一视觉-语言模型的理解和生成平衡，还展示了跨任务语义对应关系并提高了策略学习的一致性。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2305.17608", "html_url": "https://arxiv.org/abs/2305.17608", "title": "在对齐大型语言模型时的奖励塌缩现象", "title_en": "Reward Collapse in Aligning Large Language Models", "authors": "Ziang Song,Tianle Cai,Jason D. Lee,Weijie J. Su", "background": "大型语言模型（LLMs）如ChatGPT和GPT-4具有非凡的能力，部分原因是通过训练奖励模型对齐这些模型，而奖励模型基于人类的偏好进行训练，这些偏好通常表示为响应提示的排名。然而，这些模型在训练的终期阶段会遇到‘奖励塌缩’的现象，即排名方法导致的奖励分布变得一致，无论提示如何变化。这种现象对开放式和具体提示都不理想，会导致连续的奖励范围缺失，影响模型的多样性和精确性。", "innovation": "研究揭示了导致奖励塌缩的主要原因是排名目标函数在优化过程中无法有效整合提示相关信息。为此，研究提出了一个提示感知的优化方案，该方案能够在插值区间内允许提示相关的奖励分布，并证明了该方案的有效性。实验结果显示，所提出的提示感知效用函数在训练奖励模型时显著缓解了奖励塌缩现象。", "conclusion": "探究了排名方法导致的奖励塌缩问题，并提出了一种新的提示感知优化方案，该方案克服了奖励塌缩现象，保障了奖励分布的多样性和精确性，在大型语言模型的对齐训练中有显著效果。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.02878", "html_url": "https://arxiv.org/abs/2503.02878", "title": "语言模型可以在更好的搜索中自我改进以进行状态值估计", "title_en": "Language Models can Self-Improve at State-Value Estimation for Better Search", "authors": "Ethan Mendes,Alan Ritter", "background": "在解决多步推理任务时，收集准确的奖励或人类演示往往成本高昂，尤其是在交互性强的领域，如网络任务。现有的方法依赖于直接从数据中学习价值函数，但这种方式在特定领域的数据稀缺时效果不佳。", "innovation": "STL（Self-Taught Lookahead）是一种无需标记数据的自我监督学习框架，通过语言模型模拟下一步的推理过程来改进价值函数估计。STL 类似于价值迭代算法，但不是直接回归数值，而是训练语言模型生成下一次行动、预期状态及价值理由，从而提高价值估计的准确性而无需标签数据。这种方法获得了更准确的状态价值预测，进而使得轻量级搜索算法能够在保持高性能的同时减少状态探索的数量。", "conclusion": "通过使用 STL 训练的价值模型，基于中等规模的开放权重 LLM（8B 参数），网络代理的成功率提高了 39%，达到了与专有模型相当的性能。STL 方法还适用于多跳 QA 和数学谜题，展示了其良好的泛化能力。研究表明，STL 可以使小规模的开源模型引导高效的搜索，通过将明确的推理与价值学习相结合，减少推理成本。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.09969", "html_url": "https://arxiv.org/abs/2502.09969", "title": "可学习和可扩展的指令微调数据影响估计的神经网络", "title_en": "Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data", "authors": "Ishika Agarwal,Dilek Hakkani-Tür", "background": "现有的影响函数方法提供了关于模型训练的重要洞见，但存在计算成本高和泛化能力有限的问题。尤其是在计算语言模型中数据的影响时，现有方法不适用于大规模模型和数据集，主要由于计算所需的昂贵的前向和后向传递、存储大型模型所需的大量内存以及影响估计对新数据的差泛化性能。", "innovation": "本文探索使用小神经网络（我们称为InfluenceNetwork）来估计影响值，从而实现高达99%的成本降低。我们的算法（称为NN-CIFT：用于高效指令微调的神经网络）能够以相当于完整语言模型0.0027%大小的模型来估计影响值。我们展示了使用小神经网络进行影响值估计的高效性，且在下游任务的子集选择上，NN-CIFT在大幅度加速的同时保持了与传统方法相当的性能。我们还对NN-CIFT进行了详细的超参数分析。", "conclusion": "我们通过使用小神经网络来估计影响值，实现了对现有方法的改进，即NN-CIFT。相比传统方法，NN-CIFT在不影响性能的前提下大幅提高了效率，并且提供了对超参数的深入分析。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.09205", "html_url": "https://arxiv.org/abs/2503.09205", "title": "质量胜于数量？基于大语言模型的数据高效音频-视频基础模型的数据整理", "title_en": "Quality Over Quantity? LLM-Based Curation for a Data-Efficient Audio-Video Foundation Model", "authors": "Ali Vosoughi,Dimitra Emmanouilidou,Hannes Gamper", "background": "对于训练多模态基础模型来说，整合音频和视觉数据仍然是一个挑战。当前方法主要关注于时间对齐，但没有充分考虑场景对齐的需求，同时也没有有效利用大型语言模型（LLMs）进行数据整理。", "innovation": "AVVA框架通过考虑超过简单时间对齐的音频-视频场景对齐，并利用LLMs进行数据整理，提出了一个新的机制来选择对齐的训练数据片段。该框架采用Whisper（一个基于语音的基础模型）和DINOv2（用于视频分析的模型）构建双编码器结构，并通过对比学习在音频-视频对上进行联合训练。这种新颖的数据整理方式提供了一种有效的途径，可以在较少的数据量下显著提高视频到音频检索的准确率。", "conclusion": "AVVA框架在AudioCaps、VALOR和VGGSound数据集上实现了视频到音频检索任务的显著性能提升，仅使用192小时的整理过的训练数据。进一步的消融实验表明，数据整理过程有效降低了数据质量对检索准确率的影响，进一步提高了AudioCaps、VALOR和VGGSound的数据集中前k项检索准确率，相比使用未经整理的全部数据集进行训练。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.02820", "html_url": "https://arxiv.org/abs/2505.02820", "title": "AutoLibra：从开放结束的人类反馈中自动生成代理评估指标", "title_en": "AutoLibra: Agent Metric Induction from Open-Ended Human Feedback", "authors": "Hao Zhu,Phil Cuvin,Xinkai Yu,Charlotte Ka Yee Yan,Jason Zhang,Diyi Yang", "background": "当前代理主要通过任务成功率评估与优化，这种评估方法粗略且依赖于专家的手动设计，无法奖励中间的自发行为。这导致了在评估细粒度行为方面的不足，尤其是开放而复杂的任务要求。因此，需要一种能够将开放性的人类反馈转化为评估代理行为的具体指标的方法。", "innovation": "提出了AutoLibra，这是一种代理评估框架，能够通过具体化人类反馈转化成具体的评估指标，覆盖并细化代理行为。通过将反馈与代理行为相结合，自动分群相似的正负行为，并生成具体且具有明确定义和示例的评估指标。此外，还提出了两个元指标来评估一组（诱导的）指标与开放反馈的一致性：覆盖度和冗余度。通过优化这些元指标，实验表明AutoLibra不仅能够生成比前代理评估基准中提出的具体指标更多，还能够发现新的分析代理的指标。同时，AutoLibra还可以辅助人类提示工程师诊断代理失败，使其在迭代中改进，并且还用于代理的自动优化，使其自我调节提高。", "conclusion": "AutoLibra 是一个适用于评估和改进语言代理的强大工具，它能够在任务无束缚的情况下有效评估代理行为。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.09499", "html_url": "https://arxiv.org/abs/2503.09499", "title": "MindGYM：自洽推理驱动的数据为中心的自演化基础模型问题合成研究？", "title_en": "MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?", "authors": "Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen", "background": "大型基础模型在通过严格模板监督或众包标注指令数据集进行训练时，难以获得可迁移的、结构化的思考能力。以往的方法多侧重于模型的直接训练，而忽略了模型内部思考过程的重要性。本文指出，通过自动生成、认知引导的数据来帮助模型自我进化是一种有效的途径。", "innovation": "提出了MindGYM，一种结构化且可扩展的问题合成框架，该框架包含三个关键技术：1. 情境思维过程注入，通过注入高层次的推理目标来塑造模型的合成行为；2. 赋能单跳问题合成，产生来自多种语义类型的原子问题，以促进更广泛的思考；3. 挑战多跳问答合成，基于问答种子构建复杂的多跳问题，以深化推理能力。研究表明，通过该方法生成的合成数据的平均质量和质量变异率分别提高了16.7%和降低了67.91%，强调了高质量和自包含数据对有效自洽推理驱动的微调的重要性。", "conclusion": "MindGYM在六个推理基准上提高了性能，仅用400个数据样本就实现了数学视觉数据集上的16%的提升，并且在不同模型大小和架构上具有泛化的改进。MindGYM展示了解决大型模型自我挑战机制的可行性，同时减少了人为干预和资源需求。代码和数据已公开，旨在促进由内部推理能力驱动的自演化基础模型的研究。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15201", "html_url": "https://arxiv.org/abs/2505.15201", "title": "Pass@K 政策优化：解决更困难的强化学习问题", "title_en": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems", "authors": "Christian Walder,Deep Karkhanis", "background": "现有的强化学习（RL）算法在每个问题上采样多个n>1个解尝试，并独立评估它们，这优化了pass@1性能，但牺牲了解集的多样性和集体效用。这种做法未能充分利用采样能力，限制了探索并阻碍了在更难的问题上的改进。", "innovation": "提出了Pass-at-k Policy Optimization (PKPO) 方法，这是一种对最终奖励的转换，直接优化pass@k性能。此外，作者还开发了pass@k和其梯度的新型低方差无偏估计器，适用于二元和连续奖励设置，并证明了通过这些估计器可以归结为标准RL。此外，研究显示我们的方法允许在训练期间调整k值，同时优化pass@1和pass@k指标。", "conclusion": "实验结果表明，我们的奖励转换在玩具实验中揭示了减少方差的特性。使用开源的大规模语言模型GEMMA-2的实证研究表明，更高k值的优化有效地解决了更多难点更高的问题，而k值的退火能同时提高pass@1和pass@k。对于常规pass@1优化停滞的困难任务集，我们的pass@k方法有助于激发学习，原因在于它优先考虑联合效用而非个体解的效用，从而积极拓展探索空间。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12371", "html_url": "https://arxiv.org/abs/2505.12371", "title": "MedAgentBoard: 多种方法基准评测在多元医疗任务中多智能体合作", "title_en": "MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks", "authors": "Yinghao Zhu,Ziyi He,Haoran Hu,Xiaochen Zheng,Xichen Zhang,Zixiang Wang,Junyi Gao,Liantao Ma,Lequan Yu", "background": "大型语言模型（LLM）的迅速发展引发了对多智能体协作方法探讨的兴趣，以解决复杂的医疗任务。现有评估方法的普适性和严谨性不足，无法全面反映临床实践中的多样任务，并且忽略了与单个LLM及传统方法的严格比较。因此，迫切需要一个全面的基准来系统地评估这些方法的性能，特别是多智能体合作、单个LLM以及传统方法在医疗领域的应用效果和实际优势。", "innovation": "MedAgentBoard 提供了一个全新的基准框架，涵盖了四大类多样化的医疗任务，包括医学及视觉问答、生成非专业摘要、结构化电子健康记录预测建模以及临床工作流自动化，涉及文本、医学影像和结构化电子健康记录数据。研究表明，多智能体合作在某些特定场景下表现出优势，但在其他任务中并未表现得始终优于先进单智能体或专业传统方法，特别在医学视觉问答和基于电子健康记录的预测任务上。该基准不仅提供了宝贵的数据资源和详细的实验结果，还强调了医疗领域中选择和开发AI解决方案时需依据特定任务的实证方法，需仔细权衡多智能体合作的复杂性和运营成本与实际性能收益之间的关系。", "conclusion": "MedAgentBoard 为医疗领域中的多智能体合作和传统方法提供了一个重要的资源和实际见解，强调了需要根据具体任务进行证据支持的方法选择和开发。它突显了在评估技术优势时，多智能体合作的内在复杂性和成本应与真实性能收益进行仔细权衡。所有相关的代码、数据集、详细提示和实验结果均已开源。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18125", "html_url": "https://arxiv.org/abs/2505.18125", "title": "TabSTAR: 具有文本字段的表格数据的表型基础模型", "title_en": "TabSTAR: A Tabular Foundation Model for Tabular Data with Text Fields", "authors": "Alan Arazi,Eilam Shapira,Roi Reichart", "background": "尽管深度学习在许多领域取得了显著的成功，但在表格学习任务方面的表现却并不出色，这些任务仍然主要由梯度提升决策树主导。虽然在过去的方法中已经探索了将语言模型能力融入到表格任务中，但大多数方法使用的是静态、目标无关的文本表示，这限制了它们的有效性。现有方法主要依赖于静态特征，难以充分利用文本字段中的多样性信息来学习任务特定的嵌入。因此，文章旨在引入一种新的方法，以克服现有方法的局限性，提升在包含文本特征的表格数据上的学习效果和泛化能力。", "innovation": "本文提出了TabSTAR：一种具有语义目标感知代表性的表格基础模型。它能够实现表格数据上的迁移学习，且架构中不含特定数据集的参数。TabSTAR 解冻预训练的文本编码器，并通过输入目标标记来提供上下文，使模型能够学习任务特定的嵌入。其预训练阶段显示出随数据集数量增加，性能提升的规律，为性能进一步提升提供了途径。", "conclusion": "TabSTAR 在分类任务基准数据集上的表现达到最优，无论是在中型还是大型数据集上。其预训练阶段表现出数据集数量的扩展规律，提供了一个进一步提升性能的可能路径。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.21497", "html_url": "https://arxiv.org/abs/2505.21497", "title": "Paper2Poster: 向基于科学论文的多模态海报自动化迈进", "title_en": "Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers", "authors": "Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr", "background": "学术会议海报的制作是科学交流中的关键但具有挑战性的任务，需要将长文中的交叉信息浓缩到一张视觉上连贯的单页中。目前缺乏专用的评估基准和评价指标套件，使得现有系统和方法无法系统地评估海报生成的质量。", "innovation": "该研究首次提出了一个用于海报生成的基准和评价指标套件，包括视觉质量、文本连贯性、整体评估和PaperQuiz四个评估维度。基于该基准，研究提出了一种自上而下、基于视觉循环的多智能体pipeline，包含解析器、计划器和绘图评论循环，有效提升了海报生成的质量和效率，特别是在减少视觉瓶颈方面表现出色。", "conclusion": "通过全面评估，研究发现虽然GPT-4o在视觉上吸引人，但在内容准确性和PaperQuiz得分上存在不足；用户参与度是主要的视觉瓶颈。基于开源的模型如Qwen-2.5系列，该研究的方法在几乎所有评估指标上优于现有系统，同时仅使用了87%的tokens。这些发现指明了未来全自动海报生成模型的发展方向。所有代码和数据集可从提供的链接处获得。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13308", "html_url": "https://arxiv.org/abs/2505.13308", "title": "寻求光明：基于隐空间测试时实例级策略梯度的推理", "title_en": "Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space", "authors": "Hengli Li,Chenxi Li,Tong Wu,Xuekai Zhu,Yuxuan Wang,Zhaoxin Yu,Eric Hanchen Jiang,Song-Chun Zhu,Zixia Jia,Ying Nian Wu,Zilong Zheng", "background": "大型语言模型（LLMs）在追求通用人工智能（AGI）的过程中，推理能力仍然是一个显著的挑战。尽管在训练规模法则下模型性能有了提升，但仍然面临训练算法（如灾难性遗忘）以及有限的新型训练数据的挑战。作为替代方案，测试时扩展通过增加测试时的计算量来提升推理性能，而不更新参数。现有的方法主要集中在词元空间，本文提出了一种基于隐空间的方法，名为LatentSeek，以实现更有效的推理，并更好地遵循测试时扩展定律。", "innovation": "提出了LatentSeek框架，这是一种在模型隐空间内进行测试时实例级适应（Test-Time Instance-level Adaptation, TTIA）的新型方法。它利用策略梯度迭代更新隐表示，并由自生成的奖励信号引导。与现有的侧重词元空间的方法不同，LatentSeek在一系列推理基准测试中展示了优越的表现，包括GSM8K、MATH-500和AIME2024，并且在不同的LLM架构中也表现出高效性。", "conclusion": "实验结果表明，LatentSeek在多个推理基准测试中持续优于强基线方法，如链式思维提示和微调方法。分析指出，LatentSeek不仅高效，通常在几次迭代内即可收敛，而且在更复杂的任务上也能从额外的迭代中受益。这些发现表明，LatentSeek是一个轻量级、可扩展且有效的解决LGM推理能力提升的方法。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00871", "html_url": "https://arxiv.org/abs/2506.00871", "title": "在上下文环境中预测任意行人轨迹", "title_en": "Towards Predicting Any Human Trajectory In Context", "authors": "Ryo Fujii,Hideo Saito,Ryo Hachiuma", "background": "准确预测行人未来的轨迹对于自主系统至关重要，但由于需要在不同环境和领域中进行适应性预测，因此这仍然是一个具有挑战性的任务。传统的方法通常涉及收集特定情景下的数据并进行微调，但这往往在边缘设备上进行部署时是不切实际的，因为它需要频繁的微调。因此，需要一个不需要在推理时对特定情景数据进行微调且不需要权重更新的适应性框架。", "innovation": "本文提出了一种名为TrajICL的基于上下文学习（In-Context Learning, ICL）的行人轨迹预测框架，该框架能够在不微调特定数据且不需要更新权重的情况下实现适应性预测。TrajICL框架包括两种新的方法：一种是基于时空相似性的示例选择（STES），它通过在相同场景中选择具有相似运动模式的示例来迭代地更新模型的推理示例；另一种是预测引导的示例选择（PG-ES），它不仅基于过去的轨迹，还基于预测的未来轨迹来选择示例。此外，该模型使用大规模合成数据集进行训练，以增强其在不同环境和领域的预测能力。", "conclusion": "通过广泛的实验，TrajICL在多种公开基准测试中表现出色，并实现了不同领域场景内的出色适应性，甚至优于微调的现有方法。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15840", "html_url": "https://arxiv.org/abs/2508.15840", "title": "揭示Unicode在作者归因中隐藏的本质", "title_en": "Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution", "authors": "Robert Dilworth", "background": "当用户在社交媒体等公共通信渠道上发布消息时，他们不期望隐私。尽管用户可以采取多种措施来匿名化在线身份，但消息内容本身仍可能泄露作者身份。文章探讨了这种情况下使用的样式属性分析技术，以及可能的对抗性样式属性技术，提出了通过Unicode隐写术增强抗攻击的方法.", "innovation": "文章提出了通过Unicode隐写术增强抗样式属性分析的技术，以保护作者身份免受攻击.", "conclusion": "尽管用户可以采取多种匿名措施，但消息内容带来的作者身份推定风险仍然存在。文章通过分析样式属性分析和提出对抗性样式属性策略，结合Unicode隐写术，增强了作者身份保护的手段."}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21204", "html_url": "https://arxiv.org/abs/2508.21204", "title": "模糊化、符号化和情境化：通过认知支架增强LLM教学", "title_en": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "authors": "Vanessa Figueiredo", "background": "研究如何在指令对话中，提示级别的归纳偏倚影响大型语言模型（LLMs）的认知行为。该研究旨在探讨如何在Socratic辅导中促进适应性、结构化的推理，进而提升LLMs在教学中的表现。", "innovation": "引入了一种符号支架方法，并结合短期记忆模式来促进适应性推理。通过五种系统变体的受控消融实验，使用专家设计的评价标准来评估模型输出，包括支架、响应性、符号推理和对话记忆等维度。研究揭示，记忆或符号结构的缺失会削弱关键的认知行为，如抽象、主动探索和概念连续性。", "conclusion": "初步结果显示，全系统始终优于基线变体。分析表明，提示级别的认知支架能够可靠地塑造LLMs中新兴的教学策略。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08188", "html_url": "https://arxiv.org/abs/2506.08188", "title": "GradEscape：针对AI生成文本检测器的梯度基攻击者", "title_en": "GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors", "authors": "Wenlong Meng,Shuguo Fan,Chengkun Wei,Min Chen,Yuwei Li,Yuanchao Zhang,Zhikun Zhang,Wenzhi Chen", "background": "随着AI生成文本（AIGT）检测器的普及，设计一种能够有效攻击这些检测器的方法变得十分重要。现有方法面临的主要挑战包括梯度不可微问题，因为文本是离散的，以及对抗模型和检测器之间的tokenizer不匹配问题。该研究针对这些问题，提出了GradEscape，一种新型的基于梯度的攻击者，旨在评估和攻击AIGT检测器的有效性。", "innovation": "GradEscape引入了一种新颖的方法来为检索单元构建加权嵌入，解决了由文本的离散性质引起的支持向量机计算不可微的问题。该方法还通过反馈从受害检测器获取参数更新，实现了对AIGT检测器的小修改攻击，具有高成功率。此外，GradEscape还使用了新颖的tokenizer推理和模型提取技术，在仅提供查询访问的情况下也能够有效躲避检测。研究表明，GradEscape能够在包括大规模语言模型的情况下，以相对较少的参数有效突破现有的AIGT检测方法。", "conclusion": "GradEscape在四个数据集和三种广泛使用的语言模型上进行了评估，结果显示其在多项指标上优于现有方法，并且可以应用于实际的商业AIGT检测器。研究还指出了当前AIGT检测器的主要漏洞，并提出了一种潜在的防御策略。研究团队已经将GradEscape开源，以促进更稳健的AIGT检测器的研究和开发。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23925", "html_url": "https://arxiv.org/abs/2510.23925", "title": "视觉推理中的潜在思维链", "title_en": "Latent Chain-of-Thought for Visual Reasoning", "authors": "Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao", "background": "大规模的视觉-语言模型（LVLM）需要提升其可解释性和可靠性，而链式思维（CoT）推理对此至关重要。现有训练算法如SFT、PPO和GRPO可能在面对未见过的推理任务时表现不佳，并且高度依赖于有偏见的奖励模型。", "innovation": "将LVLM中的推理重新定义为后验推断，并提出基于参数化的变分推断的可扩展训练算法。通过使用寻求多样性强化学习算法，引入一种新颖的稀疏奖励函数，促进多样、高概率的潜在链式思维学习信号，克服了确定性采样限制并避免了奖励作弊。此外，实现了一种贝叶斯推断扩展策略，用边际似然取代昂贵的‘Best-of-N’和束搜索，高效排名最优论据和答案。", "conclusion": "实验结果表明，所提出的方法增强了七大推理基准上的最先进的LVLM，在有效性和泛化能力以及可解释性方面表现更佳。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16648", "html_url": "https://arxiv.org/abs/2509.16648", "title": "FESTA: 功能等价采样用于多模态LLM的信任评估", "title_en": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs", "authors": "Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy", "background": "多模态大型语言模型（MLLMs）生成的预测需要精确的信任评估，以支持选择性预测并增强用户信心。由于多模态输入范式多样，这一过程颇具挑战性。", "innovation": "提出了一种名为FESTA（Functionally Equivalent Sampling for Trust Assessment）的多模态输入采样技术，用于MLLMs。该方法基于功能等价和互补输入采样生成不确定性度量。通过采样保持任务的方法，量化不确定性，扩展输入空间以探索模型的一致性和敏感性（通过等价样本和互补样本）。FESTA是一种黑箱方法，仅需模型的输入-输出访问，无需真实标签（无监督）。评估在不同多模态LLM上进行，涵盖视觉和听觉推理任务。FESTA的不确定性估计在检测误预测方面取得了显著改进。", "conclusion": "FESTA的不确定性评估相对于视觉LLMs实现33.3%的相对改进，对于听觉LLMs实现29.6%的相对改进，基于受试者操作特征曲线下的面积（AUROC）度量。代码已开源。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.21257", "html_url": "https://arxiv.org/abs/2507.21257", "title": "CompoST: 用于在QALD设置中分析LLMs对问题进行组合性解释能力的一个基准", "title_en": "CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting", "authors": "David Maria Schmidt,Raoul Schubert,Philipp Cimiano", "background": "语言解释是一个合成过程，通过结构的组成部分含义推断出较复杂的语言结构的含义。大型语言模型具有出色的语言解释能力，并已被成功应用于将问题映射为目标的SPARQL查询。一个待解答的问题是这种解释过程是否系统化。为此，本文提出了一项基准测试，旨在考察大型语言模型是否能够在已经见过基本构建块的情况下，对结构复杂的问题进行解析和合成。研究中生成了三个基于DBpedia图表模式的不同难度数据集，这些数据集的产生方式非常可控，有助于测试大型语言模型在解析复杂问题方面的能力。通过使用不同大小的模型以及各种提示技术和微调方法进行实验，结果显示随着优化样本的差异增大，宏观F1分数从0.45下降到0.09。即使在输入中提供了所有必要信息，最低复杂度数据集的F1分数也未能超过0.57。因此，研究结果表明：大型语言模型在系统和合成地解释问题并将其映射为SPARQL查询方面存在困难。", "innovation": "本文提出了一套名为CompoST的基准测试，用于评估大型语言模型在解析复杂问题方面的组合性能力。通过基于DBpedia图表模式生成不同难度的数据集，并控制生成过程来测试模型的能力。实验使用了不同大小的模型和多种提示技术及微调方法，展示了随着与优化样本差异的增大，模型性能急剧下降的现象。", "conclusion": "大型语言模型在系统和组合性地解释问题并将问题转化为SPARQL查询方面存在困难。即使提供了所有必要的信息，模型的表现也不理想，这表明当前模型在理解和解释复杂问题方面仍有待改进。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.21513", "html_url": "https://arxiv.org/abs/2510.21513", "title": "代码生成和修复中LLM编队的智慧与幻觉", "title_en": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair", "authors": "Fernando Vallecillos-Ruiz,Max Hort,Leon Moonen", "background": "当前追求所有软件工程任务的一体化大型语言模型（LMM）需要大量资源，忽视了不同模型之间互补性的潜力。尽管代码LMM之间互补的具体程度和最大化编队潜力的最佳策略仍不清楚，这使得实践者难以超越单一模型系统。", "innovation": "本文通过实证比较十个来自五个家族的独立LMM以及三种由这些LMM组成的编队，在代码生成和程序修复的三个软件工程基准上进行评估，评估模型之间的互补性和单个最佳模型与编队之间的性能差距。进一步评估了选择解的不同启发式方法以从编队候选池中选出正确解。结果表明，编队的理论最佳性能可能比单一最佳模型高83%。一致性的策略容易陷入“受欢迎度陷阱”，而基于多样性的策略可实现理论潜力的95%，甚至在小型两模型编队中也有效，通过综合利用多个LMM实现成本效益更高的性能提升。", "conclusion": "本文的研究结果表明，基于多样性的策略能够更有效地利用多个LMM的优势，提高总体性能，同时提供了一种合理、经济的方法来增强代码生成和修复任务的实际效果。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.12760", "html_url": "https://arxiv.org/abs/2509.12760", "title": "相似性-距离-幅度激活函数", "title_en": "Similarity-Distance-Magnitude Activations", "authors": "Allen Schmaltz", "background": "本文介绍了一种改进的标准softmax激活函数的更稳健且可解释的方案，即Similarity-Distance-Magnitude (SDM)激活函数。SDM激活函数通过引入相似性和距离到训练分布的意识，增强了对幅度的意识，使激活函数更加可解释，能够通过密集匹配提高模型的可解释性。此外，文章进一步引入了基于SDM激活函数驱动的数据驱动分割的SDM估计器，用于控制选择性分类中的类别和预测条件准确性。这些改进在使用预训练语言模型进行选择性分类时，比现有的使用softmax激活函数的校准方法更具鲁棒性，同时仍然能够提供关于分布内数据的信息。", "innovation": "1. 提出了一种新的激活函数——SDM激活函数，增强了模型的可解释性，通过引入相似性和距离到训练分布的意识进一步改善了幅度意识。2. 引入了SDM估计器，基于SDM激活函数驱动的数据驱动分割，用于控制选择性分类中的类别和预测条件准确性，提供了选择性分类的鲁棒性和可解释性。3. SDM估计器在预训练语言模型的选择性分类中使用时，比现有的使用softmax激活函数的校准方法更稳健，同时仍然能够提供关于分布内数据的信息。", "conclusion": "SDM激活函数及其估计器提供了一种更稳健、更可解释的选择性分类方法，特别适用于预训练语言模型在处理变量偏移和异常输入时，同时保证了对常见数据的有用信息。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG: 优化文本到视频生成的视频标题", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "文本到视频（T2V）生成的最新进展突显了高质量视频-文本对在训练能够生成连贯且指令对齐的视频模型中的关键作用。然而，特定于T2V训练的视频字幕优化策略仍较少被探索。研究表明，改进的字幕质量与视频生成性能之间存在强烈关联。", "innovation": "本文介绍了VC4VG（视频标题优化视频生成），这是一种专门为T2V模型需求定制的综合字幕优化框架。提出了从T2V视角分析字幕内容、将视频重建所需的关键要素分解到多个维度，并提出了一个有根据的字幕设计方法。同时，构建了VC4VG-Bench基准，该基准包含细粒度、多维度和根据T2V特定需求分级的评估指标。", "conclusion": "广泛的T2V微调实验表明，改进的字幕质量与视频生成性能之间存在强烈关联，验证了该方法的有效性。所有基准工具和代码均在此网址（https://）发布，以支持进一步研究。"}
{"llm_update_time": "20251102", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.14889", "html_url": "https://arxiv.org/abs/2510.14889", "title": "通过社交媒体纵向和信息环境信号检测早期和隐性自杀念头", "title_en": "Detecting Early and Implicit Suicidal Ideation via Longitudinal and Information Environment Signals on Social Media", "authors": "Soorya Ram Shimgekar,Ruining Zhao,Agam Goyal,Violeta J. Rodriguez,Paul A. Bloom,Hari Sundaram,Koustuv Saha", "background": "在社交媒体上，许多经历自杀意念（SI）的个人并未明确表达其困境，而是通过日常发帖或人际互动中隐含的信号释放这些信息。早期检测这些隐含的信号具有重要意义但仍然具有挑战性。本研究将早期和隐性SI重新定义为前瞻性的预测任务，并开发了一种计算框架，该框架建模了用户的环境信息，包括他们的纵向发布历史及其周围社交邻近个体的发言。该研究在Reddit平台上的1000名用户中进行了验证，结果表明，通过结合用户自身纵向数据和与其邻近个体的交互进行检测，能够较传统方法提升15%的早期隐性SI检测准确性。这些结果强调了同行互动提供了重要的预测信号，并对在线环境中早期检测系统的系统设计产生了广泛影响，能够捕捉到间接的风险表达及其掩饰性表达。", "innovation": "研究引入了一种整合用户自身纵向数据和与其邻近个体互动的计算框架，这是现有研究中的一种创新。通过用复合网络中心性度量识别顶级邻近个体，并对用户的互动和邻近个体的互动进行了时间对齐，利用微调的DeBERTa-v3模型整合多层次信号进行预测，提升了早期和隐性自杀念头的检测准确度。", "conclusion": "研究结果表明，通过结合用户的纵向数据和其社交邻近个体的互动，可以显著提升早期和隐性自杀念头的检测准确性。这不仅确认了同行互动在预测这些行为中的重要价值，还为在线环境中设计能够捕捉间接和隐藏风险的社会风险监测系统提供了理论支持。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25797", "html_url": "https://arxiv.org/abs/2510.25797", "title": "通过时空分析和空间注意力网络增强水下目标检测", "title_en": "Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks", "authors": "Sai Likhith Karri,Ansh Saxena", "background": "本文研究了时空建模和时空注意力机制在水下物体检测深度学习模型中的效果。通过比较标准YOLOv5和增强版YOLOv5（T-YOLOv5）以及结合卷积块注意力模块（CBAM）的T-YOLOv5，探讨了不同模型在动态海洋环境中的性能。", "innovation": "引入了增强版T-YOLOv5模型，并通过添加卷积块注意力模块（CBAM），重点研究了如何通过时空建模在动态海洋环境下提高检测准确性，特别是在突发运动、部分遮挡和渐变运动等条件下。", "conclusion": "实验结果表明，T-YOLOv5和结合CBAM的T-YOLOv5在50-95mAP指标上分别达到了0.813和0.811，相比标准YOLOv5的0.563有显著提升，尤其是在复杂对象检测上展示了更好的准确性和泛化能力。研究中还发现了尽管CBAM增强的T-YOLOv5在复杂场景下的性能提升显著，但在简单场景中却有轻微的准确性降低。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25897", "html_url": "https://arxiv.org/abs/2510.25897", "title": "MIRO: 多奖励条件下预训练提高从文本到图像的质量和效率", "title_en": "MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and efficiency", "authors": "Nicolas Dufour,Lucas Degeorge,Arijit Ghosh,Vicky Kalogeiton,David Picard", "background": "当前的文本到图像生成模型在大规模且未经筛选的数据集上训练，以实现多样化的生成能力。然而，这种训练方式并不总是符合用户的偏好。最近，奖励模型被专门设计用来在生成图像后进行选择，并将其与奖励，通常是用户偏好进行对齐。然而，这种方法丢弃了大量有用的数据，并且有利于单一的奖励，这通常会损害多样性、语义保真度和效率。", "innovation": "我们提出在训练过程中条件化模型以多个奖励模型，让模型直接学习用户的偏好。这种方法不仅能显著提高生成图像的视觉质量，还能显著加快训练速度。我们的方法叫做MIRO，实现了GenEval组合基准和用户偏好评分（PickAScore、ImageReward、HPSv2）的最新性能。", "conclusion": "通过在训练过程中条件化模型以多个奖励模型，我们不仅提高了生成图像的视觉质量，还显著提高了训练效率。MIRO在多个评估基准和用户偏好评分中取得了领先的性能。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25921", "html_url": "https://arxiv.org/abs/2510.25921", "title": "使用物理学导向合成数据进行生成图像恢复与超分辨率扫描隧道显微镜", "title_en": "Generative Image Restoration and Super-Resolution using Physics-Informed Synthetic Data for Scanning Tunneling Microscopy", "authors": "Nikola L. Kolev(1,2),Tommaso Rodani(3,4),Neil J. Curson(1,2),Taylor J.Z. Stock(1,2),Alberto Cazzaniga(4) ((1) London Centre for Nanotechnology, University College London, London, United Kingdom, (2) Department of Electronic and Electrical Engineering, University College London, London, United Kingdom, (3) University of Trieste, Trieste, Italy, (4) AREA Science Park, Trieste, Italy)", "background": "扫描隧道显微镜（STM）能够实现原子级分辨率成像和原子操作，但其应用受到制备过程中尖端退化和数据采集缓慢的限制。制备复杂性在于尖端常被施加高电压，这可能改变尖端尖端的形状，需要对其进行训练。本研究提出了一个机器学习（ML）方法用于图像修复和超分辨率，以应对这些挑战。", "innovation": "研究采用了一个基于物理学导向的合成数据生成管道，能够训练多种尖端前沿最先进的流匹配和扩散模型。这些模型能够有效恢复图像，并在稀疏采样数据下准确重建图像，使得图像采集时间减少两到四倍。", "conclusion": "本框架有潜力大幅提高STM实验吞吐量，通过减少尖端训练频率和提高现有高速STM系统的帧率实现这一目标。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26001", "html_url": "https://arxiv.org/abs/2510.26001", "title": "在扫描模式中增加Hausdorff维度促进基于Mamba的方法在低光照图像增强中的应用", "title_en": "Larger Hausdorff Dimension in Scanning Pattern Facilitates Mamba-Based Methods in Low-Light Image Enhancement", "authors": "Xinhua Wang,Caibo Feng,Xiangjun Fu,Chunxiao Liu", "background": "现有的Mamba框架在低光照图像增强中已有应用，但存在信息不一致以及在精细尺度特征捕捉和空间邻域有效性上有所欠缺的问题。因此，需要提出一种改进机制来解决这些问题，提高整体检测和覆盖效果，同时保持处理长程依赖的能力，以提高定量指标和视觉保真度，减少计算资源消耗并缩短推理时间.", "innovation": "提出了一种新颖的Hilbert Selective Scan机制，通过增加扫描模式的Hausdorff维度，更有效地探索特征空间，捕捉复杂的细微细节，提高整体覆盖，并同时改善空间局部性的捕捉，不牺牲模型处理长程依赖的能力。这种机制在多个公开基准中的实验验证了其有效性，显著提升了基于Mamba的低光照图像增强方法的定量指标和视觉保真度，同时减少了计算资源的使用和缩短了推理时间.", "conclusion": "此优化策略不仅推进了低光照图像增强的技术前沿，还可能为依赖于Mamba技术的方法带来更广泛的潜在应用。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25976", "html_url": "https://arxiv.org/abs/2510.25976", "title": "Brain-IT: 通过脑交互变压器从fMRI重建图像", "title_en": "Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer", "authors": "Roman Beliy,Amit Zalcher,Jonathan Kogman,Navve Wasserman,Michal Irani", "background": "从功能性磁共振成像（fMRI）脑成像记录中重建人类视觉体验的图像可以为人们的认知和感知提供无创窗口。虽然最近扩散模型取得了进展，但当前的方法往往无法准确地再现实际看到的图像。", "innovation": "本文介绍了一种名为'Brain-IT'的脑启发方法，通过脑交互变压器（BIT）解决这一挑战，BIT允许功能相似的脑体素集群之间的有效交互。BIT预测两个互补的局部补丁级图像特征：（i）高层语义特征，引导扩散模型向正确的图像语义内容；（ii）低级结构特征，用于用正确的粗略图像布局初始化扩散过程。这些设计使得信息可以直接从脑体素集群传递到局部图像特征。通过这种方式，该方法能够准确地从fMRI重建所看到的图像，超越了当前的SotA方法。另外，仅使用新受试者1小时的fMRI数据，本文的方法可以达到与使用全40小时记录训练的方法相当的结果。", "conclusion": "使用Brain-IT方法从fMRI重建图像能够准确再现实际看到的图像，且在视觉效果和标准客观指标上都超越了当前的SotA方法。即使只是使用新受试者1小时的fMRI数据，也能达到与训练使用全40小时记录相当的结果。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25990", "html_url": "https://arxiv.org/abs/2510.25990", "title": "Fine-tuning Segment Anything for Real-Time Tumor Tracking in Cine-MRI", "title_en": "Fine-tuning Segment Anything for Real-Time Tumor Tracking in Cine-MRI", "authors": "Valentin Boussot,Cédric Hémon,Jean-Claude Nunes,Jean-Louis Dillenseger", "background": "本文探讨了在胸部和腹部区域的 cine-MRI 序列中，针对 TrackRAD2025 挑战，在强数据稀缺约束条件下实现实时肿瘤跟踪的问题。背景在于当前实时肿瘤跟踪技术在数据稀缺的情况下难以实现高精度和实时性，而该研究旨在探索新的方法来解决这一问题。", "innovation": "研究提出了一种新的实时肿瘤跟踪策略，该策略基于 SAM2.1及其变种进行微调，利用基于提示的交互方式。在受限于一秒钟的运行时间下，选择 SAM 基础模型方法，并采用 Mask 基准提示从第一标注切片开始进行微调。研究还引入了低统一学习率，以保持泛化能力并适应标注者特定的风格。最终模型在验证集上达到最高的 Dice 相似度系数，并在隐藏测试集中获得了 0.8794 的 Dice 分数，排名 TrackRAD2025 挑战赛第六位。", "conclusion": "研究结果表明，基础模型对于 MRI 引导的放射治疗中准确且实时的肿瘤跟踪具有很强的潜力。通过针对性地微调 Segment Anything 模型，能够在保证实时性的条件下实现高精度的肿瘤跟踪。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25901", "html_url": "https://arxiv.org/abs/2510.25901", "title": "BikeScenes：自行车上的在线LiDAR语义分割", "title_en": "BikeScenes: Online LiDAR Semantic Segmentation for Bicycles", "authors": "Denniz Goren,Holger Caesar", "background": "骑自行车者的脆弱性被电动助力自行车（e-bikes）的日益普及所加剧，这促使我们调整汽车感知技术以提高自行车安全。现有的多传感器'SenseBike'研究平台用于开发并评估专门针对自行车的3D激光雷达（LiDAR）分割方法。为了弥合汽车到自行车领域的差距，我们介绍了新的'BikeScenes-lidarseg'数据集，包含了3021个连续的LiDAR扫描，围绕代尔夫特理工大学的校园展开，这些扫描进行了语义标注，涵盖29个动态和静态类别。通过评估模型性能，发现针对'BikeScenes'数据集的微调达到63.6%的平均交并比（mIoU），这远远优于仅使用SemanticKITTI预训练得到的13.8%的结果，表明了领域特定训练的必要性和有效性。研究还指出了自行车载感知系统特有的关键挑战，并贡献了'BikeScenes'数据集作为推进骑自行车者为中心的LiDAR分割研究的资源。", "innovation": "引入了'BikeScenes-lidarseg'数据集，这是一个专门针对自行车的3D LiDAR扫描数据集，包含了丰富的语义信息，用于进行针对性的训练和评估。此外，通过对比不同训练方法的效果，展示了领域特定训练的必要性和优越性，提供了一个新的视角来促进骑自行车者为中心的LiDAR分割研究。", "conclusion": "研究成果表明，针对' BikeScenes'数据集进行微调可以显著提高模型的性能，达到了63.6%的mIoU，这远超仅使用SemanticKITTI预训练的效果。这不仅证明了领域特定训练的重要性，也为未来的自行车感知系统提供了有力的支持。同时，研究还揭示了在自行车上应用激光雷达感知系统的特定挑战。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25970", "html_url": "https://arxiv.org/abs/2510.25970", "title": "SplitFlow：基于流分解的无反向映射文字到图像编辑", "title_en": "SplitFlow: Flow Decomposition for Inversion-Free Text-to-Image Editing", "authors": "Sung-Hoon Yoon,Minghan Li,Gaspard Beaudouin,Congcong Wen,Muhammad Rafay Azhar,Mengyu Wang", "background": "已纠正的流模型因其稳定的采样路径和高保真的输出，在图像生成中已成为事实上的标准。尽管这些模型具备强大的生成能力，但在进行图像编辑任务时仍存在重大限制：反向映射过程不准确，将真实图像映射回潜在空间，以及在编辑过程中梯度纠缠问题导致输出无法准确反映目标提示。近期研究试图通过基于ODE的方法直接映射源分布和目标分布，而无需进行反向映射；然而，这些方法仍然得到次优的编辑效果。本文提出了一种基于无反向映射的流分解与聚合框架，以解决上述问题。具体而言，该方法将目标提示语句从语义上分解为多个子提示，为每个子提示计算独立的流，并将其聚合形成一个统一的编辑轨迹。我们发现，在原始流的基础上进行分解能够增强目标空间的多样性，但在生成语义对齐的输出时，仍需一致地朝着完整的目标提示进行引导。为此，我们设计了一种投影与软聚合机制，模仿多任务学习中的梯度冲突解决策略。此机制在适应性权重子目标速度场的同时，抑制语义冗余并强调独特的方向，从而在最终的编辑输出中保持多样性和一致性。实验结果显示，本文方法在语义保真度和属性分离方面优于现有零样本编辑方法。相关代码可在此处访问：this https URL", "innovation": "该研究提出了一个基于流分解与聚合的无反向映射框架，能够有效解决流模型在图像编辑中的挑战。该框架将目标提示语句分解为多个子提示，为每个子提示计算独立的流，并通过投影和软聚合机制来实现语义对齐，以增强编辑效果。这种方法在保持多样性的同时，也能保证语义的一致性，从而提高编辑质量，并在语义保真度和属性分离方面显著优于现有方法。", "conclusion": "本文方法有效地解决了已纠正流模型在图像编辑中的限制，通过无反向映射的流分解与聚合框架，不仅增强了目标空间的多样性，同时确保了语义的一致性。实验结果表明，该方法在语义保真度和属性分离方面均优于现有零样本编辑方法。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26006", "html_url": "https://arxiv.org/abs/2510.26006", "title": "CAVE: 在视觉环境中检测和解释常识性异常", "title_en": "CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments", "authors": "Rishika Bhagwatkar,Syrielle Montariol,Angelika Romanou,Beatriz Borges,Irina Rish,Antoine Bosselut", "background": "人类能够自然地识别、推理和解释环境中的异常。但在计算机视觉领域，这一长期存在的挑战依然局限于工业缺陷或不现实、合成生成的异常，未能捕捉到现实世界异常的丰富多样性和不确定性。因此，亟需一个能够反映真实世界异常的基准数据集。本研究旨在引入CAVE，首个真实世界视觉异常的基准数据集，旨在支持异常描述、解释和论证三项开放任务，并提供精细的视觉标注方法，以识别和归类异常的视觉表现、复杂性、严重性和常见性。", "innovation": "本研究首次提出了真实世界的视觉异常基准数据集CAVE，支持三个开放任务：异常描述、解释和论证，并通过视觉注释和异常分类，提供一个以人类识别和解决异常为灵感的数据标注框架，以全面评估视觉语言模型（VLMs）在检测和理解异常方面的能力。研究指出，最先进的VLMs在视觉异常感知和常识推理方面表现不佳，即便使用先进的提示策略也是如此。这表明CAVE作为一个现实性和认知上基础的基准，对推进异常检测和常识推理的研究具有重要的资源价值。", "conclusion": "本研究表明，最先进的VLMs在视觉异常感知和常识推理方面面临挑战。通过提供一个现实和认知地基础的基准CAVE，本研究为在VLMs中推进异常检测和常识推理的研究提供了宝贵的资源。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26052", "html_url": "https://arxiv.org/abs/2510.26052", "title": "基于VLM的动态负提示方法在扩散模型中的应用", "title_en": "Dynamic VLM-Guided Negative Prompting for Diffusion Models", "authors": "Hoyeon Chang,Seungjin Kim,Yoonseok Choi", "background": "传统的负提示方法使用固定的负提示词，这种方法在应用中可能缺乏灵活性，无法很好地适应不同的图像生成需求。而在扩散模型中，动态地生成和调整负提示词能够更好地控制生成的图像质量，提高图像与文本之间的对齐度。本文旨在提出一种基于视觉-语言模型（VLMs）的动态负提示方法，以替代传统的固定负提示词方法，实现图像生成过程中的自适应负提示生成。", "innovation": "本文提出了一种基于VLMs的动态负提示方法，在去噪过程中生成中间图像预测，并查询VLM生成适合的负提示词，以此来提高文本与生成图像的对齐度。这种基于VLM的方法能够动态生成负提示，相比传统方法更加灵活，特别是对于包含多重吻合场景的图像生成任务更为有效。该方法还展示了负提示强度与文本-图像对齐之间的权衡关系。", "conclusion": "实验表明，本文提出的方法在多个基准数据集上表现出良好的性能。其主要贡献在于提出了一个既能自适应生成负提示词又能在不同程度上控制图像生成质量的解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26027", "html_url": "https://arxiv.org/abs/2510.26027", "title": "通过视编码器中的堆叠时序注意力增强视频-LLM的时序理解", "title_en": "Enhancing Temporal Understanding in Video-LLMs through Stacked Temporal Attention in Vision Encoders", "authors": "Ali Rasekh,Erfan Bagheri Soula,Omid Daliran,Simon Gottschalk,Mohsen Fayyaz", "background": "尽管多模态大型语言模型（MLLMs）取得了显著进展，但在视频中理解复杂的时序动态仍然是一个重大挑战。当前的视频大型语言模型（Video-LLM）架构在时序理解方面存在关键限制，难以完成需要详细理解动作序列和时序进展的任务。我们的实验表明，现有模型在视频问答任务中表现不佳，特别是在动作识别方面。", "innovation": "本文提出了一种Video-LLM架构，该架构直接在视编码器中引入了堆叠的时序注意力模块。这种设计在视编码器中引入了时序注意力，使模型能够更好地捕捉动作的进展及其帧之间的关系，在将视觉标记传递给LLM之前。研究结果表明，这种方法显著提高了时序推理能力，并在视频问答任务中优于现有模型，特别是在动作识别方面。我们通过改进基准包括VITATECS、MVBench和Video-MME，表现提升高达+5.5%。通过增强视编码器的时间结构，我们解决了Video-LLM在视频理解方面的关键问题。", "conclusion": "通过在视编码器中增强时间结构，我们解决了Video-LLMs在视频理解方面的关键问题。我们的方法在视频问答任务中表现出优越的性能，特别是在动作识别方面取得了显著的进步。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26017", "html_url": "https://arxiv.org/abs/2510.26017", "title": "使用深度学习的适应气候变化的海岸城市洪水预测", "title_en": "Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep Learning", "authors": "Bilal Hassan,Areg Karapetyan,Aaron Chung Hin Chow,Samer Madanat", "background": "气候变化和海平面上升（SLR）对沿海城市构成了日益严重的威胁，加强了需要高效准确地预测潜在洪水灾害的需求。传统的物理模拟器尽管精确，但对于大规模城市沿海规划应用来说计算复杂且不切实际。深度学习（DL）技术提供了有希望的替代方案，但由于数据稀缺和高维输出要求等挑战，它们也受到了限制。通过利用一种最近提出的基于视觉的低资源DL框架，我们开发了一种新颖的轻量级卷积神经网络（CNN）模型，用于在变化的SLR假设和海岸线适应场景下预测沿海洪水。此外，我们还展示了该模型在不同地理背景下泛化的能 力，通过使用来自阿布扎比和旧金山的两个不同地区的数据集。研究表明，提出的方法在预测洪水深度图中的平均绝对误差（MAE）比最先进的方法低近20%。这表明我们的方法有可能成为一种可扩展且实用的工具，用于沿海洪水管理，使决策者能够制定有效的缓解策略以应对气候变化的影响。", "innovation": "利用基于视觉的低资源DL框架开发了一种轻量级CNN模型，能够预测变化的SLR假设和多种海岸线适应方案下的沿海洪水。该模型成功地展示了跨不同地理背景的泛化能力，特别是在减少预测洪水深度图中的MAE方面显著优于当前最先进的方法。", "conclusion": "研究表明，所提出的方法在预测沿海洪水深度图中的MAE比现有最优方法低近20%，这为应对气候变化对沿海城市的影响提供了具有潜力的可扩展且实用的工具，帮助政策制定者制定有效的洪水管理策略。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26105", "html_url": "https://arxiv.org/abs/2510.26105", "title": "多模态模型中文本与图像之间错位的安全风险", "title_en": "Security Risk of Misalignment between Text and Image in Multi-modal Model", "authors": "Xiaosen Wang,Zhijin Ge,Shaokang Wang", "background": "尽管多模态扩散模型，如文本到图像模型，已经有了显著的进步和多功能性，但这些模型对对抗性输入的敏感性尚未得到充分研究。现有研究显示，多模态扩散模型中图像和文本模式之间的对齐不足，这种不匹配给生成不适当或不适合工作场所（NSFW）的内容带来了重大风险。", "innovation": "本文提出了一种名为Prompt-Restricted Multi-modal Attack (PReMA)的新型攻击，可以通过修改输入图像（不改变提示）来操控生成的内容，而不同于以往生成对抗性提示的方法。PReMA是首个仅通过生成对抗性图像来操纵模型输出的攻击方法，它对多模态扩散模型，特别是使用固定提示进行图像编辑的应用程序，构成了新型威胁。", "conclusion": "广泛评估表明，PReMA在图像修复和风格迁移任务中对各种模型的攻击效果显著。这一发现揭示了多模态扩散模型中文本与图像对齐不足所带来的潜在安全风险，特别是对于依赖固定提示的应用程序。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26049", "html_url": "https://arxiv.org/abs/2510.26049", "title": "FlexICL: 一种用于肘部和腕部超声波分割的灵活视觉上下文学习框架", "title_en": "FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation", "authors": "Yuyue Zhou,Jessica Knight,Shrimanti Ghosh,Banafshe Felfeliyan,Jacob L. Jaremko,Abhilash R. Hareendranathan", "background": "肘部和腕部骨折是儿童中最常见的骨折类型。超声波（US）软组织成像可以提高骨折诊断的准确性，但是需要专家解读，而骨性区域的分割需要专家细致的像素级标注，这一过程时间长且成本高。现有解决方案无法有效提高分割效率和精度，尤其是在稀缺标注样本的情况下。FlexICL旨在通过一种新的灵活上下文学习框架，减少像素级专家标注的需要，利用少量标注数据实现骨性区域的高效分割，提高分割性能，特别是在缺乏标注数据的医疗成像应用场景中。", "innovation": "FlexICL 提出了一种新的灵活上下文学习（Fragmented In-context Learning, FlexICL）框架，用于基于超声图像的骨性区域分割。该框架在限定的标注数据集上学习，并且能够对未见帧进行分割。FlexICL 通过引入新的图像连接方法和多种数据增强策略，显著提高了模型在有限标注数据下的性能。FlexICL 在四个肘部和腕部超声数据集中实现了稳健的分割性能，只需要传统方法 5% 的训练图像数据，同时段战胜了包括 Painter、MAE-VQGAN 和 U-Net、TransUNet 在内的各种现况模型。", "conclusion": "FlexICL 框架提供了一种有效的解决方案，能够在缺乏标注数据的情况下提高超声图像中骨性区域分割的性能。它不仅在技术上创新，还能够在实际医疗成像场景中实现快速和高效的工作流程，对于未来医学影像分割任务具有潜在的应用价值。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26117", "html_url": "https://arxiv.org/abs/2510.26117", "title": "JOGS: 联合优化相机姿态估计和三维高斯点绘制", "title_en": "JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting", "authors": "Yuxuan Li,Tao Wang,Xianben Yang", "background": "传统的图像合成方法高度依赖外部相机姿态估计工具，如COLMAP，这常常导致计算瓶颈并传播错误。", "innovation": "本文提出了一种统一的框架，该框架联合优化3D高斯点和相机姿态，无需预先校准的输入。通过一种新颖的联合优化策略迭代优化3D高斯参数和更新相机姿态，确保场景重建的准确性和姿态的准确性共同提高。关键创新在于将联合优化拆分为两个交替阶段：首先使用固定姿态的可微渲染更新3D高斯参数，其次利用结合几何和光度约束的自定义3D光学流动算法细化相机姿态。这种形式逐步减少投影误差，特别是在大视角变化和稀疏特征分布的挑战性场景中，传统方法难以应对。", "conclusion": "在多个数据集上的广泛评估表明，与其他COLMAP-free技术相比，本文的方法在重建质量上显著更优，也超越了标准的COLMAP基线方法。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26113", "html_url": "https://arxiv.org/abs/2510.26113", "title": "EgoExo-Con: 探索视角不变的视频时间理解", "title_en": "EgoExo-Con: Exploring View-Invariant Video Temporal Understanding", "authors": "Minjoon Jung,Junbin Xiao,Junghyun Kim,Byoung-Tak Zhang,Angela Yao", "background": "该研究探讨了基于视频的大型语言模型（Video-LLMs）在不同视角捕捉同一事件时能否保持一致的时间理解能力。为了研究这一问题，作者引入了一个新的基准——EgoExo-Con（Consistency），它包含同步的第一人称和第三人称视频对，并附有人类精炼的自然语言查询。EgoExo-Con特别强调两个时间理解任务：时间验证和时间定位。它不仅评估正确性，还评估不同视角之间的连贯性。", "innovation": "1. 该研究揭示了现有基于视频的大型语言模型的两个关键局限性：一是模型往往无法保持一致性，在多视角上的表现远不如单视角。二是当使用同步多视角视频进行微调时，模型的表现有时甚至不如只在一个视角上进行训练的模型。\n2. 为了解决这些问题，作者提出了一个新颖的强化学习框架——View-GRPO，它能够加强特定视角的时间推理，并促进在不同视角之间的连贯理解。\n3. 实验表明，相比朴素的微调和通用的强化学习方法，View-GRPO在提高跨视角一致性方面具有显著优势。", "conclusion": "该研究通过引入EgoExo-Con基准和提出View-GRPO方法，揭示了基于视频的大型语言模型在不同视角下保持时间理解一致性的不足，并提出了一种有效的方法来改进这些不足。所有资源将公开提供。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26114", "html_url": "https://arxiv.org/abs/2510.26114", "title": "OracleAgent：甲骨文研究中的多模态推理代理", "title_en": "OracleAgent: A Multimodal Reasoning Agent for Oracle Bone Script Research", "authors": "Caoshuo Li,Zengmao Ding,Xiaobin Hu,Bang Li,Donghao Luo,Xu Peng,Taisong Jin,Yongge Liu,Shengwei Han,Jing Yang,Xiaoping He,Feng Gao,AndyPian Wu,SevenShu,Chaoyang Wang,Chengjie Wang", "background": "甲骨文（OBS）是早期的书写系统之一，保存了古代文明的文化和智力遗产。然而，当前OBS研究面临两大挑战：一是OBS解释涉及复杂的多阶段和多并行子任务的工作流程；二是OBS信息组织和检索效率低下，使得学者们在寻找、整理和管理相关资源方面花费大量精力。", "innovation": "本文介绍了OracleAgent，这是第一个针对OBS相关信息的结构化管理和检索的代理系统。OracleAgent通过大型语言模型（LLMs）集成并调度了多种OBS分析工具，构建了一个全面的领域特定多模态知识库，包含超过140万张单字符拓片图像和80000条解释文本。OracleAgent利用这些资源通过多模态工具辅助专家进行字符、文档、解释文本和拓片图像检索任务。实验结果表明OracleAgent在多种多模态推理和生成任务中表现优于主流多模态大型语言模型。", "conclusion": "OracleAgent展示了在OBS辅助研究和自动化解释系统的实用部署方面的重大进展，通过大量实验表明其在多模态任务中的优异性能，特别显著地减少了OBS研究中专家的时间成本，进一步提高OBS的研究效率。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26131", "html_url": "https://arxiv.org/abs/2510.26131", "title": "探索基于对象感知的注意力引导帧关联在RGB-D SLAM中的应用", "title_en": "Exploring Object-Aware Attention Guided Frame Association for RGB-D SLAM", "authors": "Ali Caglayan,Nevrez Imamoglu,Oguzhan Guclu,Ali Osman Serhatoglu,Ahmet Burak Can,Ryosuke Nakamura", "background": "注意力模型近年来在各种领域取得了显著的进步。可视化技术，如类激活映射，能够提供卷积神经网络（CNN）推理过程的视觉见解。通过网络梯度，可以识别网络在图像识别任务中关注的区域，并将其与CNN特征结合以定位更可泛化的任务特定关注区域。然而，直接将这种基于梯度的注意力信息整合到CNN表示中以实现语义对象理解仍然较为有限。这种整合对于穿梭环境中的SLAM等视觉任务特别有益，因为这种整合可以使基于空间关注对象位置的CNN表示增强性能。", "innovation": "本文提出将特定任务的网络注意力应用于RGB-D室内SLAM中，通过将网络梯度生成的逐层注意力信息与CNN特征表示相结合，以提高帧关联性能。实验结果表明，该方法在大环境中的性能优于基线方法。", "conclusion": "实验结果表明，所提出的方法相较于基线方法，在帧关联性能上有所提升，尤其在大环境中表现更好。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26173", "html_url": "https://arxiv.org/abs/2510.26173", "title": "MoTDiff: 使用扩散模型从单张模糊图像估计高分辨率运动轨迹", "title_en": "MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models", "authors": "Wontae Choi,Jaelin Lee,Hyung Sup Yun,Byeungwoo Jeon,Il Yong Chun", "background": "准确估计运动信息在计算成像和计算机视觉应用中至关重要。现有方法通常采用模糊核和光流从单张模糊图像提取运动信息，但这些方法的运动表示往往质量较低，表现为粗糙且不准确。本文旨在提出一种高分辨率（HR）运动轨迹估计框架，以提升单一模糊图像中运动轨迹的精细和准确性。", "innovation": "本文提出了一种名为MoTDiff的新框架，基于扩散模型估计高分辨率的运动轨迹。MoTDiff框架包括两个关键组成部分：1) 一个新颖的基于单张模糊图像多尺度特征图条件的条件扩散框架；2) 一种新的训练方法，该方法能够促进细致运动轨迹的准确识别，总体运动路径形状和位置的一致估计，以及运动轨迹内像素连接性的实现。", "conclusion": "实验结果表明，MoTDiff在盲去模糊和编码曝光摄影应用中均能优于最新的方法。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26140", "html_url": "https://arxiv.org/abs/2510.26140", "title": "FullPart：以全分辨率生成每个3D部件", "title_en": "FullPart: Generating each 3D Part at Full Resolution", "authors": "Lihe Ding,Shaocong Dong,Yaokun Li,Chenjian Gao,Xiao Chen,Rui Han,Yihao Kuang,Hong Zhang,Bo Huang,Zhanpeng Huang,Zibin Wang,Dan Xu,Tianfan Xue", "background": "部分基于3D生成在多种应用中具有巨大潜力。然而，利用隐式向量集token表示部件的前期工作常常存在几何细节不足的问题。另一种方法则是使用显式体素表示，但所有部件共享一个全局体素网格，这样会导致小部件占据过少的体素，从而影响生成质量。本研究将结合隐式和显式方法，提出一个新的框架FullPart。该框架首先通过隐式方框向量集扩散过程推导出边界框布局，这是一项隐式扩散能够有效处理的任务，因为空方框token几乎没有几何细节。接着，它在每个固定分辨率的体素网格中生成详细部件。这种方法下，即使小部件也能在其各自的全分辨率空间生成，从而合成更多的细节。另外，还引入了中心点编码策略，以解决不同实际大小的部件间信息交换时的对齐问题，从而保持全局一致性。", "innovation": "提出了一种结合隐式和显式表示方法的新框架FullPart。通过隐式方框向量集扩散过程推导边界框布局，并在每个部件独有的全分辨率体素网格中生成详细部件。此外，引入了中心点编码策略解决不同大小部件间的信息交换问题，以及创建了目前最大的手工标注3D部件数据集PartVerse-XL，共有40K物体和320K部件，从而为3D部件生成提供可靠数据支持。", "conclusion": "充分的实验结果表明，FullPart在3D部件生成方面取得了最先进的成果。研究团队将公开所有代码、数据和模型，以便未来对3D部件生成的研究提供支持。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26149", "html_url": "https://arxiv.org/abs/2510.26149", "title": "BasicAVSR: 通过图像先验和运动补偿增强实现任意尺度视频超分辨率", "title_en": "BasicAVSR: Arbitrary-Scale Video Super-Resolution via Image Priors and Enhanced Motion Compensation", "authors": "Wei Shang,Wanying Zhang,Shuhang Gu,Pengfei Zhu,Qinghua Hu,Dongwei Ren", "background": "视频超分辨率（AVSR）旨在提升视频帧的分辨率，在不同缩放因子下具有挑战性，主要涉及空间细节重现、时间一致性以及计算复杂性等问题。", "innovation": "本研究提出了一种基础模型BasicAVSR，集成了四种关键组件：1）基于图像拉普拉斯金字塔生成的自适应多尺度频率先验，2）基于流引导的信息传播单元，用于从相邻帧聚合时空信息，3）二次运动补偿单元以提高相邻帧的空间对齐精度，4）超采样单元生成尺度感知且与内容无关的超采样核。此外，还提出了三种传播变体：单向RNN单元用于严格的在线推理，具有有限前瞻性的单向RNN单元可以接受轻微的输出延迟，双向RNN单元适用于计算资源不受限制的离线任务。实验证明BasicAVSR在超分辨率质量、泛化能力和推理速度方面显著优于现有方法，扩展了其核心组件的应用范围。", "conclusion": "实验结果表明，BasicAVSR在多种场景下具有良好的效果和适应性，不仅在AVSR领域取得了最先进的成果，而且将其核心组件扩展到多种框架中。代码已开源。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26125", "html_url": "https://arxiv.org/abs/2510.26125", "title": "WOD-E2E: Waymo 开放数据集，适用于挑战性的长尾场景的端到端驾驶", "title_en": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios", "authors": "Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Kate Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Drago Anguelov", "background": "端到端（E2E）的驾驶因其可扩展性和与多模式大规模语言模型（MLLMs）的高度协同性，引起了研究社区的广泛关注。现有的E2E驾驶基准主要关注标准场景，未能充分测试这些系统的真正潜力。此外，现有的开环评估指标在捕捉驾驶的多模态本质或在长尾场景中有效评估性能方面往往不尽如人意。因此，为了弥补这些差距，我们提出了Waymo开放数据集用于端到端驾驶（WOD-E2E），并专门用于挑战性的长尾场景，这些场景在日常生活中很少出现，发生频率低于0.03%。每个WOD-E2E数据段包括高一级路线信息、车辆状态和360度相机视角。", "innovation": "WOD-E2E 数据集专注挑战性长尾场景，提供了4,021个驾驶段（大约12小时），并提出了一种新颖的开环评估指标：评估者反馈分数（Rater Feedback Score, RFS）。RFS通过评估预测轨迹与评估者标注的偏好标签的匹配程度，衡量预测轨迹与日志中实际轨迹之间的接近程度，而不是像传统指标那样测量预测点与日志点之间的距离。此外，公开了WOD-E2E验证集的所有评估者偏好标签，而保留的测试集标签则用于2025年的WOD-E2E挑战赛。", "conclusion": "通过本研究，我们旨在促进对通用、稳健和安全的端到端自主驾驶代理的前沿研究，这些代理能够处理复杂的现实世界情况。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26160", "html_url": "https://arxiv.org/abs/2510.26160", "title": "CRAG-MM: 多模态多轮综合RAG基准", "title_en": "CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark", "authors": "Jiaqi Wang,Xiao Yang,Kai Sun,Parth Suresh,Sanat Sharma,Adam Czyzewski,Derek Andersen,Surya Appini,Arkav Banerjee,Sajal Choudhary,Shervin Ghasemlou,Ziqiang Guan,Akil Iyer,Haidar Khan,Lingkun Kong,Roy Luo,Tiffany Ma,Zhen Qiao,David Tran,Wenfang Xu,Skyler Yeatman,Chen Zhou,Gunveer Gujral,Yinglong Xia,Shane Moon,Nicolas Scheffer,Nirav Shah,Eun Chang,Yue Liu,Florian Metze,Tammy Stark,Zhaleh Feizollahi,Andrea Jessee,Mangesh Pujari,Ahmed Aly,Babak Damavandi,Rakesh Wanga,Anuj Kumar,Rohit Patel,Wen-tau Yih,Xin Luna Dong", "background": "可穿戴设备（如智能眼镜）可以改变人们与其环境互动的方式，使得用户能够获取视野内实体的相关信息。多模态检索增强生成（MM-RAG）在此过程中扮演关键角色，但尚无全面的基准来支持这些任务，尤其是针对可穿戴设备场景的。本文填补了这一空白。", "innovation": "本文提出了CRAG-MM，一个全面的多模态多轮对话RAG基准。CRAG-MM包括6.5K（图像、问题、回答）三元组和2K基于视觉的多轮对话，覆盖13个领域，其中包含6.2K以穿戴设备捕获为模样的第一人称视角图像，并设计了三个任务：单一来源增强、多来源增强和多轮对话，每个任务都有相应的检索语料库和API，分别用于图像-KG检索和网页检索。基准测试结果显示，直接的RAG方法在CRAG-MM单轮和多轮QA中的真实性分别只有32%和43%，而最先进的行业解决方案也有类似的质量，表明仍有很多改进空间。", "conclusion": "CRAG-MM已成功举办KDD Cup 2025，吸引了约1000名参赛者和5000份提交，获胜的解决方案提高了基础性能28%，突显了其早期对推动该领域的积极影响。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26151", "html_url": "https://arxiv.org/abs/2510.26151", "title": "MV-MLM: 联接多视角乳腺X线摄影和语言以进行乳腺癌诊断和风险预测", "title_en": "MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction", "authors": "Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba", "background": "乳腺癌检测或风险预测的计算机辅助诊断（CAD）模型需要大量高质量标注数据集，但获取这些数据集既耗时又昂贵。视觉-语言模型（VLMs）如CLIP可以在大规模图像-文本对上预训练，从而为医学影像任务提供增强的鲁棒性和数据效率解决方案。", "innovation": "提出了一个名为MV-MLM的新模型，该模型结合了多视角和语言模型的监督学习，用于乳腺癌分类和风险预测。MV-MLM通过跨模态半监督学习从大量放射学数据中学习丰富的表示，并采用联合视觉-文本学习策略以增强多样性和准确度。该模型在合成文本报告上训练，无需实际放射学报告，就已显示了在数据使用效率上的优越性，并在三项分类任务中达到了最先进的性能：（1）恶性肿瘤分类，（2）亚型分类，（3）基于图像的癌症风险预测。", "conclusion": "该研究提出的MV-MLM模型在乳腺癌诊断和风险预测任务中显示了强劲的数据使用效率，能够在合成文本报告的辅助下获得与实际放射学报告训练的模型相当甚至更好的性能。该研究为基于视觉-语言模型的医疗影像任务提供了新的解决方案，并为乳腺癌诊断提供了新的工具。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26154", "html_url": "https://arxiv.org/abs/2510.26154", "title": "使用深度学习检测 unauthorized 车辆：以孟加拉国为案例的研究", "title_en": "Detecting Unauthorized Vehicles using Deep Learning for Smart Cities: A Case Study on Bangladesh", "authors": "Sudipto Das Sukanto,Diponker Roy,Fahim Shakil,Nirjhar Singha,Abdullah Asik,Aniket Joarder,Mridha Md Nafis Fuad,Muhammad Ibrahim", "background": "不同国家的交通方式因地理位置和文化背景而异。在南亚国家，人力车是常见的本地交通工具。在孟加拉国的城市中，按照运行方式，人力车可以分为非机动人力车和机动三轮车。监测机动三轮车的移动是必要的，因为交通规则常常限制它们只能走某些路线。然而，现有的监控系统由于机动三轮车与其他车辆相类似，尤其是非机动人力车，使得监控工作非常困难。此外，手动视频分析耗时过长。本研究提出了一种基于机器学习的方法，用于自动检测交通图像中的机动三轮车。", "innovation": "在本系统中，研究者使用了实时物体检测的YOLOv8模型。为了训练模型，他们准备了一组在各种交通条件下拍摄的1,730张标注图像。结果显示，提出的模型在实时机动三轮车检测中表现良好，mAP50达到83.447%，二元精度和召回率均超过78%，表明该模型能在稠密和稀疏交通场景下有效工作。此外，该数据集已公开，允许进一步的研究。", "conclusion": "本研究提供的基于机器学习的方法能够有效检测交通图像中的机动三轮车，具备良好的实时检测性能，且的数据集已公开，推动了进一步研究。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26196", "html_url": "https://arxiv.org/abs/2510.26196", "title": "Sketch2PoseNet：高效的多风格素描到三维人体姿态预测", "title_en": "Sketch2PoseNet: Efficient and Generalized Sketch to 3D Human Pose Prediction", "authors": "Li Wang,Yiyu Zhuang,Yanwen Wang,Xun Cao,Chuan Guo,Xinxin Zuo,Hao Zhu", "background": "三维人体姿态估计从素描中具有广泛的应用前景，特别是在计算机动画和电影制作领域。与传统的姿态估计不同，素描具有抽象和比例失调的特点，这给任务带来了独特挑战。之前的方法受限于大规模素描-3D姿态注释的缺失，主要依赖启发式规则进行优化，这耗时且缺少普适性。为了应对挑战，本文提出了一种利用‘从合成中学习’策略的新方法。", "innovation": "本文首先训练了一个扩散模型，从2D姿态合成素描图像，模仿素描中的人体结构比例，生成了一个名为SKEP-120K的合成数据集，包含120,000对准确的素描-3D姿态标注组合，适用于多种素描风格。基于此数据集，本文提出了一种端到端的数据驱动框架，能够从多种风格的素描中估计人体姿态和形状。该框架结合了现有的2D姿态检测器和生成扩散先验以及前馈神经网络，以实现高效的2D姿态估计。引入多种启发式损失函数以确保3D姿态与2D姿态之间的几何一致性和准确的自我接触。", "conclusion": "定性和定量评估结果表明，本文模型在素描到姿态估计任务中，在准确性和速度方面都显著优于之前的模型。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26186", "html_url": "https://arxiv.org/abs/2510.26186", "title": "ConceptScope：通过解耦视觉概念表征数据集偏差", "title_en": "ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts", "authors": "Jinho Choi,Hyesu Lim,Steffen Schneider,Jaegul Choo", "background": "机器学习数据集中存在数据点向特定概念倾斜的数据偏差现象，但系统性地识别这些偏差需要成本高昂且精细的属性注释。ConceptScope 提出了一种可扩展且自动化的框架，通过使用视觉基础模型表示训练的稀疏自编码器来发现和量化可由人类解释的概念，从而分析视觉数据集。该框架根据概念的语义相关性和对类标签的统计关联将其分类为目标、背景和偏差类型，从而实现基于概念的子组划分进行类级数据集特征刻画、偏差识别和鲁棒性评估。", "innovation": "ConceptScope 通过使用稀疏自编码器识别并量化视觉数据集中的可解释概念，自动发现数据偏差，解决了不依赖于精细注释的系统性偏差识别难题。该框架无需人工标注即可进行大规模数据集的分析。它能够捕捉物体、纹理、背景、面部特征、情绪和动作等多种视觉概念，并且根据概念激活结果确定出具有语义意义的图像区域。ConceptScope 还能够检测已知偏差并发现未标注的偏差，为数据集审计和模型诊断提供实用工具。", "conclusion": "ConceptScope 能够广泛捕捉视觉概念，包括物体、纹理、背景、面部属性、情绪和动作，并通过与标注数据集的对比验证其效果。此外，这个框架能够在视觉数据集中可靠地检测已知偏差，并发现未标注的偏差，为数据集审计和模型诊断提供了坚实的基础。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26213", "html_url": "https://arxiv.org/abs/2510.26213", "title": "OmniLayout: 用大型语言模型实现粗到细学习以生成通用文档布局", "title_en": "OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation", "authors": "Hengrui Kang,Zhuangcheng Gu,Zhiyuan Zhao,Zichen Wen,Bin Wang,Weijia Li,Conghui He", "background": "文档AI技术得到了快速发展并越来越受到关注。尽管大多数努力都集中在文档布局分析（DLA）上，其生成性对应物文档布局生成仍然未被充分探索。主要障碍在于多样布局的稀缺性：现有的研究主要集中在具有曼哈顿结构的学术论文上，而像报纸和杂志这样的开放世界体裁则严重缺乏代表性。", "innovation": "我们创建了OmniLayout-1M，这是首个包含多种文档类型的大规模多样性布局数据集，覆盖了从多个来源收集的现代布局。此外，我们介绍了OmniLayout-LLM，一个带有设计中的粗到细学习范式的0.5亿参数模型：首先从OmniLayout-1M中学习通用布局原则，使用粗分类定义；然后使用细粒度注释将知识转移到特定领域。广泛的实验表明，我们的方法在M$^6$Doc数据集的多个领域中表现出色，明显优于现有的文档布局生成专家以及多个最新的通用语言模型。", "conclusion": "我们的代码、模型和数据集将被公开发布。我们的方法在复杂领域中表现出色，显著超越了现有的文档布局生成专家和多个最新的通用语言模型。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26282", "html_url": "https://arxiv.org/abs/2510.26282", "title": "在不同获取距离下探索CNNs用于 periocular 验证的互补性和解释性", "title_en": "Exploring Complementarity and Explainability in CNNs for Periocular Verification Across Acquisition Distances", "authors": "Fernando Alonso-Fernandez,Kevin Hernandez Diaz,Jose M. Buades,Kiran Raja,Josef Bigun", "background": "本研究在 UBIPr 数据库中探讨了不同 CNNs 在不同距离下的 periocular 验证的互补性。", "innovation": "研究训练了三种复杂度逐渐增加的 CNN 架构（SqueezeNet、MobileNetv2 和 ResNet50），并使用视网膜库 VGGFace2 提供的大量眼部剪辑进行训练。研究通过余弦和卡方度量分析性能，比较不同网络初始化，并通过逻辑回归进行评分级融合。此外，研究运用 LIME 热图和联合沙恩哈德 divergence 来比较 CNN 的注意力模式。研究结果显示，虽然 ResNet50 个体表现最佳，但融合提供了显著的提升，特别是在合并所有三种网络时。热图表明，网络通常关注图像的不同区域，解释了它们的互补性。", "conclusion": "本方法在 UBIPr 上显著优于先前工作，达到了新的技术前沿。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26268", "html_url": "https://arxiv.org/abs/2510.26268", "title": "基于人类认知规律重新审视生成型红外和可见光图像融合", "title_en": "Revisiting Generative Infrared and Visible Image Fusion Based on Human Cognitive Laws", "authors": "Lin Guo,Xiaoqing Luo,Wei Xie,Zhancheng Zhang,Hui Li,Rui Wang,Zhenhua Feng,Xiaoning Song", "background": "现有的红外和可见光图像融合方法常常需要权衡不同模态信息，现有的生成式融合方法虽然通过数据分布学习重构融合图像，但其生成能力有限，且对模态信息的选择缺乏解释性，这在复杂场景下会影响融合结果的可靠性和一致性。", "innovation": "该研究受到人类认知规律的启发，提出了新的红外和可见光图像融合方法HCLFuse。HCLFuse通过无监督融合网络的信息映射量理论设计了一种多尺度掩码调节变分瓶颈编码器，该编码器通过后验概率建模和信息分解来提取准确且简洁的低级模态信息，支持高保真结构细节的生成。此外，研究将概率生成能力与物理定律结合，形成了一种随时间变化的物理引导机制，该机制根据不同阶段适应性地调节生成过程，从而增强模型感知数据内在结构的能力，减少对数据质量的依赖。实验结果表明，所提出的方法在多个数据集上的定性和定量评估中达到了最先进的融合性能，并显著提高了语义分割指标，充分展示了这种基于人类认知机制的生成图像融合方法的优势，增强了结构一致性并提升了细节质量", "conclusion": "该方法在多个数据集上的实验结果证明了其在结构一致性和细节质量方面的优越性，表明基于人类认知规律的生成式图像融合方法在复杂场景下的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26292", "html_url": "https://arxiv.org/abs/2510.26292", "title": "Flow matching约束轨迹生成超越模仿：端到端自动驾驶中的约束感知轨迹生成", "title_en": "Beyond Imitation: Constraint-Aware Trajectory Generation with Flow Matching For End-to-End Autonomous Driving", "authors": "Lin Liu,Guanyi Yu,Ziying Song,Junqiao Li,Caiyan Jia,Feiyang Jia,Peiliang Wu,Yandan Luo", "background": "自主驾驶的端到端规划是至关重要的组成部分。然而，现有的模仿学习方法经常遭受模式崩溃的问题，无法生成多样化的轨迹假设。此外，现有的生成方法难以直接将关键的安全性和物理约束嵌入生成过程，通常需要额外的优化步骤来细化其输出。", "innovation": "我们提出了CATG（Constrained Adaptive Trajectory Generation），一种新颖的规划框架，利用了受限流匹配过程。具体而言，CATG明确地建模了流匹配过程，从本质上缓解了模式崩溃问题，并允许来自各种条件信号的灵活引导。我们的主要贡献在于在流匹配过程中直接施加了显式的约束，确保生成的轨迹遵循重要的安全和运动学规则。其次，CATG在生成过程中参数化了驾驶侵略性作为控制信号，使轨迹风格能够精确调整。", "conclusion": "在NavSim v2挑战中，CATG获得了第二名，EPDMS得分为51.31，并获得了创新奖。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26203", "html_url": "https://arxiv.org/abs/2510.26203", "title": "开发多任务集成几何深度网络以提高供应链可持续性和风险管理", "title_en": "Developing a Multi-task Ensemble Geometric Deep Network for Supply Chain Sustainability and Risk Management", "authors": "Mehdi Khaleghi,Nastaran Khaleghi,Sobhan Sheykhivand,Sebelan Danishvar", "background": "供应链的可持续性对实现供应链最优性能起着关键作用。风险管理是提升供应链网络可持续性和提高供应链性能效率的基本问题。正确的货物分类是可持续供应链的另一个重要组成部分。近年来，在深度网络背景下取得了重要进展，多种架构被应用于分析供应链数据。为了利用供应链中的信息依赖关系，提出了一种新型几何深度网络的集成模型。该模型结合了卷积几何深度学习，并将其应用于供应链数据库中样本的不可见状态提取。这种方法在不同的数据库上进行了验证，包括SupplyGraph数据集和DataCo数据库。对DataCo供应链交付状态的预测是为了风险管理，通过SupplyGraph数据库对产品分类和边缘分类进行改进，以增强供应链网络的可持续性。结果表明，集成网络在风险管理方面的平均准确率为98.95%，在5类产品组分类和4类产品关系分类中的平均准确率分别为100%和98.07%，在25家公司关系分类中达到92.37%的平均准确率。该方法在可持续供应链性能和风险管理方面的平均改进和效率优于现有方法。", "innovation": "提出了一种新的几何深度网络集成模型——Chebyshev集成几何卷积网络 (Ch-EGN)，它结合了卷积几何深度学习以识别供应链中的信息依赖性，从而推断数据库中样本的隐藏状态。该方法在不同数据库上进行了测试，包括SupplyGraph数据集和DataCo数据库。这种方法特别注重风险管理、产品分类和边缘分类，以提升供应链网络的可持续性。", "conclusion": "提出的Ch-EGN网络在供应链可持续性和风险管理中表现优异，特别是在产品分类、边缘分类和公司关系分类任务上取得了高准确率。相对于现有方法，该方法在供应链网络性能和风险管理方面显示出明显的改进和效率。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26294", "html_url": "https://arxiv.org/abs/2510.26294", "title": "利用大规模面部数据库通过眼部裁剪进行深度 periocular 识别", "title_en": "Leveraging Large-Scale Face Datasets for Deep Periocular Recognition via Ocular Cropping", "authors": "Fernando Alonso-Fernandez,Kevin Hernandez-Diaz,Jose Maria Buades Rubio,Josef Bigun", "background": "本研究聚焦于眼部生物特征识别，特别是眼周区域，该区域具有高鉴别性和较低的捕获约束。当前文献中，大多数研究依赖于小规模眼周数据集进行训练，这些数据集通常只有几千张图片。相比之下，本研究利用了大规模的 VGGFace2 数据库，从中提取了1,907,572 张眼部区域的样本进行训练，这大大优于现有的做法。", "innovation": "本研究创新性地评估了三种不同深度和复杂度的卷积神经网络（CNN）架构，以评估其在眼周识别中的有效性。实验使用了 VGGFace2-Pose 数据集和UFPR-Periocular 数据集进行。针对 VGGFace2 数据集的不确定性，本研究取得了从 9-15% 的等错误率（EERs），而使用全脸图像时取得了 3-6% 的 EERs。相比之下，UFPR-Periocular 数据集由于有更好的图像质量和更一致的捕获协议，使得等错误率降至 1-2%，目前是该数据集上最低的 EERs。", "conclusion": "本研究展示了利用大规模面部数据集进行眼周识别的潜力，尤其是在高质量图像和一致的采集协议下，眼周识别性能显著提高。这些发现对于生物特征识别领域具有重要意义，并为进一步研究提供了方向。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26297", "html_url": "https://arxiv.org/abs/2510.26297", "title": "现实地球观测星座调度：基准与方法", "title_en": "Towards Realistic Earth-Observation Constellation Scheduling: Benchmark and Methodology", "authors": "Luting Wang,Yinghao Xiang,Hongliang Huang,Dongjun Li,Chen Gao,Si Liu", "background": "敏捷地球观测卫星（AEOSs）星座为监测地球表面提供了前所未有的灵活性，但在大规模场景、动态环境和严格约束下，其调度仍然具有挑战性。现有方法通常简化这些复杂性，限制了它们在实际中的表现。", "innovation": "引入了一个统一框架，该框架集成了标准化基准套件和新颖的调度模型。基准套件AEOS-Bench包含3,907个精细调校的卫星资产和16,410种场景。每一个场景包含1到50颗卫星及50到300项成像任务，且通过高保真仿真平台生成，确保了现实的卫星行为，如轨道动力学和资源约束。基准套件内含真实的调度标记。此外，引入了AEOS-Former，这是一种基于Transformer的调度模型，整合了一种具备约束意识的注意机制，并包含专为每个卫星生成的物理和操作限制的内部约束模块，通过仿真迭代学习，能够适应多种场景，提供对AEOS星座调度的稳健解决方案。理论研究表明，AEOS-Former在任务完成和能效方面优于基线模型，并通过消融研究强调了每个组件的贡献。", "conclusion": "实验结果表明，AEOS-Former在任务完成和能效方面优于基线模型，且消融研究突显了每个组件的贡献。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26304", "html_url": "https://arxiv.org/abs/2510.26304", "title": "探索不同类型音乐与激发情绪之间的关联：基于主观问卷和EEG的研究", "title_en": "Exploring the correlation between the type of music and the emotions evoked: A study using subjective questionnaires and EEG", "authors": "Jelizaveta Jankowska,Bożena Kostek,Fernando Alonso-Fernandez,Prayag Tiwari", "background": "本研究旨在探索不同类型音乐对人类情绪的影响。实验中，参与者在听不同类型的音乐时，通过佩戴EEG头盔进行客观的脑活动测量以及主观问卷调查。研究对象涵盖了不同性别的参与者以及不同音乐偏好的人群，以捕捉对音乐广泛的情绪反应。", "innovation": "研究创新之处在于结合了主观问卷调查与EEG脑电图技术，多维度分析不同音乐类型对情绪的影响及脑活动的关系。这种结合提供了对音乐与情绪之间关联的深入理解。", "conclusion": "实验结果显示，不同类型的音乐与观察到的脑活动之间存在关联。分析问卷调查的结果表明，特定类型的音乐能够引起特定的情绪反应，证实了音乐对情绪的直接影响。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26241", "html_url": "https://arxiv.org/abs/2510.26241", "title": "时间之箭流向何方？基于心理物理学的视觉-语言模型评估", "title_en": "Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models", "authors": "Shiho Matta,Lis Kanashiro Pereira,Peitao Han,Fei Cheng,Shigeru Kitazawa", "background": "现代的视觉-语言模型（VLMs）在许多跨模态任务上表现出色，但它们对视频中的时间信息掌握较弱，并且这种能力往往被忽视。本文通过一项看似简单却揭示性强的新挑战——判断视频片段是正向播放还是逆向播放来探讨这一问题。提出了AoT-PsyPhyBENCH（基于心理物理学验证的标准测试）这一基准测试方法，利用与人类相同的测试刺激和行为基线来检验VLMs能否推断自然视频中的时间方向。尽管大多数模型的表现接近随机猜测，甚至最优模型在不可逆物理过程（如自由落体、扩散/爆炸）和因果手动动作（如分割/添加）上的性能也远远落后于人类的准确性。这些结果凸显了当前跨模态系统中的一个基本缺口：尽管它们捕捉了丰富的视觉-语义关联，但缺乏处理时间连续性和因果理解所需的归纳偏差。", "innovation": "提出了AoT-PsyPhyBENCH这一基于心理物理学验证的标准测试方法，专门用来检验视觉-语言模型在推断自然视频中时间方向上的能力。这项研究强调了视觉-语言模型在时间和物理推理能力方面的不足，并可能激发进一步改进此类模型的研究工作。", "conclusion": "当前的视觉-语言模型在捕捉视觉-语义关联方面表现出色，但在处理时间连续性和因果理解方面存在明显不足。通过AoT-PsyPhyBENCH基准测试，研究人员发现了模型在不可逆物理过程和因果手动动作上的表现差距。这些发现提示了未来研究需关注视觉-语言模型的时间理解能力，以实现更为全面的跨模态处理。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26315", "html_url": "https://arxiv.org/abs/2510.26315", "title": "基于证据理论的CNN与ViT桥梁框架用于糖尿病视网膜病变分级", "title_en": "A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading", "authors": "Junlai Qiu,Yunzhu Chen,Hao Zheng,Yawen Huang,Yuexiang Li", "background": "糖尿病视网膜病变（DR）是中老年人视力丧失的主要原因，严重影响他们的日常生活和心理健康。为提高临床筛查效率和实现DR的早期检测，基于卷积神经网络（CNN）或视觉变换器（ViT）的自动化DR诊断系统已得到广泛应用。然而，由于CNN / ViT各自的不足，单类型骨干的现有方法性能已达瓶颈。一种潜在的改进方式是结合不同的骨干，充分利用CNN的局部特征提取能力和ViT的全局特征捕捉能力。", "innovation": "提出了一个新的范式，基于证据理论有效融合不同骨干提取的特征。具体来说，提出的证据融合范式通过一系列深度证据网络将来自不同骨干的特征转换为支持证据。利用这些支持证据，可以形成聚合意见，适应性地调整不同骨干之间的融合模式，从而提高我们的混合模型性能。", "conclusion": "在两个公开的DR分级数据集上评估了该方法。实验结果表明，与最先进的框架相比，我们的混合模型不仅提高了DR分级的准确性，还提供了优秀的特征融合和决策解释性。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26339", "html_url": "https://arxiv.org/abs/2510.26339", "title": "GLYPH-SR：通过VLM指导的潜在扩散模型，我们能否同时实现高质量的图像超分辨率和高保真度的文字恢复？", "title_en": "GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?", "authors": "Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang", "background": "图像超分辨率（SR）对许多视觉系统至关重要，包括监控、自主驾驶、文档分析和零售分析，因为恢复高频细节，尤其是场景文本，能够确保可靠的下游感知。然而，大部分早期的SR研究主要是针对图像失真的度量（如PSNR/SSIM）或学习感知度量（如LIPIS、MANIQA、CLIP-IQA、MUSIQ），这些度量对字符级错误并不敏感。此外，尽管有研究关注文字超分辨率，但大多集中于简化基准的孤立字符，忽视了复杂自然场景中文字的挑战。因此，场景文本常被当作通用纹理处理。", "innovation": "GLYPH-SR提出了一种由视觉-语言引导的扩散框架，旨在同时优化文字可读性和视觉质量。它利用由OCR数据引导的文本-超分辨率融合控制网络（TS-ControlNet）和一个在文本和场景指导间交替的乒乓调度器。通过在合成数据集上训练这些组件，GLYPH-SR在多种测试集上实现了显著的改进，同时保持了性能竞争力。", "conclusion": "GLYPH-SR旨在同时实现高可读性与高视觉现实性，确保生成的超分辨率图像看起来正确且真实。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26443", "html_url": "https://arxiv.org/abs/2510.26443", "title": "PointSt3R：基于3D对应关系的点跟踪", "title_en": "PointSt3R: Point Tracking through 3D Grounded Correspondence", "authors": "Rhodri Guerrier,Adam W. Harley,Dima Damen", "background": "近年来，基础3D重建模型如DUSt3R和MASt3R在静态场景中的2D和3D对应方面展现出了巨大的潜力。本文旨在将这些模型应用于3D对应的点跟踪任务。", "innovation": "本文提出了一种新颖的方法，即结合重建损失和动态对应训练，加入视可见性头，对MASt3R进行点跟踪的微调，主要使用少量合成数据进行训练。此外，通过仅在包含查询点的一帧内进行训练和评估，去除了任何时间上下文。结果表明，PointSt3R在多个数据集上达到了与现有方法相当或更优的表现。", "conclusion": "PointSt3R通过结合使用静态和动态点对应关系，在四个数据集上达到了竞争甚至优于现有方法的结果，并提出若干关于训练数据集和动态对应关系的度量的消融研究。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26391", "html_url": "https://arxiv.org/abs/2510.26391", "title": "基于注意力引导的扩散模型的EEG驱动图像重建", "title_en": "EEG-Driven Image Reconstruction with Saliency-Guided Diffusion Models", "authors": "Igor Abramov,Ilya Makarov", "background": "现有的基于EEG的图像重建方法往往忽视了空间注意力机制，影响了图像重建的保真度和语义连贯性。", "innovation": "本文提出了一种双条件框架，结合EEG嵌入和空间显著性图来增强图像生成。该方法使用自适应思维映射器（ATM）进行EEG特征提取，并通过低秩适应（LoRA）微调Stable Diffusion 2.1，使其与视觉语义相匹配，同时通过ControlNet分支以空间控制图像生成，从而与人类视觉注意力强烈对齐。实验结果表明，注意力先验解决了EEG的模糊性，使图像重建更加真实，并具有医学诊断和神经适应接口的应用前景，通过高效调整预训练的扩散模型推进了神经解码领域的发展。", "conclusion": "本文的方法在低级和高级图像特征的质量上显著优于现有方法，并实现了与人类视觉注意力的强烈对齐，使基于注意力的先验能够解决EEG模糊性，从而实现高保真重建，具有在医学诊断和神经适应接口方面的广泛应用，并通过高效调整预训练的扩散模型推动了神经解码领域的发展。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26464", "html_url": "https://arxiv.org/abs/2510.26464", "title": "Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection", "title_en": "Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection", "authors": "Yuanting Fan,Jun Liu,Xiaochen Chen,Bin-Bin Gao,Jian Li,Yong Liu,Jinlong Peng,Chengjie Wang", "background": "现有的Few-shot 异常检测（FSAD）方法依靠预训练的视觉-语言模型（VLMs）通过文本描述和图像之间特征相似性来识别潜在的异常区域。然而，由于缺乏详细的文本描述，这些方法只能预定义图像级别的描述来匹配每个视觉补丁标记，这导致了图像描述与补丁级别的视觉异常之间的语义不对齐，从而导致子最优的定位性能。", "innovation": "该研究提出了多级精细语义描述（MFSC）以为现有的异常检测数据集提供多级和精细的文本描述，并采用自动构建管道进行。基于MFSC，该研究提出了一种新的框架FineGrainedAD，包括多级可学习提示（MLLP）和多级语义对齐（MLSA）两个组成部分。MLLP通过自动替换和拼接机制引入细粒度的语义进入多级可学习提示，而MLSA设计了区域聚合策略和多级对齐训练来帮助可学习提示更好地与对应的视觉区域对齐。", "conclusion": "实验结果表明，提出的FineGrainedAD在MVTec-AD和VisA数据集的少样本设置中达到了优越的整体性能。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26466", "html_url": "https://arxiv.org/abs/2510.26466", "title": "代表级反事实校准以实现无偏零样本识别", "title_en": "Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition", "authors": "Pei Peng,MingKun Xie,Hang Hao,Tong Jin,ShengJun Huang", "background": "在视觉语言模型中，物体-背景捷径仍然构成一个持续的挑战，这在测试场景与训练场景中的常见上下文组合不一致时，削弱了零样本识别的可靠性。", "innovation": "将该问题重新构想为因果推理问题，通过估计物体和背景期望，在CLIP的表示空间中合成反事实嵌入，重新组合物体特征与从外部数据集、批量邻居或文本描述中采样的多样化背景，进一步通过估算总直接效应和模拟干预来消除背景激活的影响，从而保留有益的物体-背景交互，同时抑制幻觉得分。无需重新训练或设计提示，方法在上下文敏感基准上的最差群体和平均准确性均显著提升，建立了新的零样本最佳状态。", "conclusion": "除了性能提升，本框架还提供了一种轻量级的表示级反事实方法，为去偏差和可靠的多模态推理提供了实用的因果途径。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26412", "html_url": "https://arxiv.org/abs/2510.26412", "title": "LoCoT2V-Bench: 长形式和复杂文本到视频生成的标准", "title_en": "LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video Generation", "authors": "Xiangqing Zheng,Chengyue Wu,Kehai Chen,Min Zhang", "background": "近年来，文本生成视频技术在生成短小且高质量的片段方面取得了显著进展，然而在处理复杂指令时生成长视频片段的评估仍然是一个主要挑战。现有的基准大多依赖于简化指令并主要关注低级指标，未能充分考量与指令的精细对齐以及叙事连贯性、主题表现等抽象维度。这些局限性导致难以全面评估和改进复杂文本到视频生成方法。", "innovation": "为填补上述空白，该研究提出了LoCoT2V-Bench基准，专为复杂输入条件下长视频生成（LVG）设计。它基于各类实际视频引入了一系列现实且复杂的指令，涵盖了场景转换和事件动力等元素，并构建了一个多维度评估框架，包括事件级对齐、细粒度时序一致性、内容清晰度以及着重抽象属性如叙事流、情感响应和人物发展的Herd度量等。通过这些新指标和框架，对九种代表性的长视频生成模型进行了全面评估，揭示了这些模型在基本视觉和时间方面表现良好，但在事件间一致性、细粒度对齐和高层次主题一致性等方面存在不足。", "conclusion": "LoCoT2V-Bench不仅提供了一个全面可靠的平台来评估长形式复杂文本到视频生成，同时也明确了未来方法改进的关键方向。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26474", "html_url": "https://arxiv.org/abs/2510.26474", "title": "通过头部-尾部重新平衡对抗LVLMs自我改进中的马太效应", "title_en": "Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing", "authors": "Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "自我改进已成为提升大型视觉-语言模型（LVLMs）推理能力的主要范式，其中模型通过迭代探索和学习成功的轨迹。然而，在这一过程中我们发现了一个关键问题：模型在生成简单查询（头部数据）的高质量轨迹方面表现出色，但对复杂查询（尾部数据）则难以应对。这种不平衡优化导致模型过度专注于简单推理技能，而削弱了其解决复杂推理任务的能力。随着迭代次数的增加，这种不平衡现象愈发显著，我们将其称为“马太效应”，最终阻碍了模型进一步改进并导致性能瓶颈。", "innovation": "本研究提出了一种新的策略，从分布重塑和轨迹重采样的两个视角出发，通过头部-尾部重新平衡，在探索-学习自我改进过程中实现优化权重调整。实验结果表明，本方法在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型的视觉推理任务中，能够有效提升视觉推理能力，平均优于传统的自我改进方法3.86个百分点。", "conclusion": "研究表明，采用头部-尾部重新平衡策略可以有效缓解LVLMs自我改进中的马太效应，从而提高模型处理复杂推理任务的能力。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26568", "html_url": "https://arxiv.org/abs/2510.26568", "title": "SA$^{2}$Net: 针对超声体积投影成像脊柱分割的尺度自适应结构亲和性变换", "title_en": "SA$^{2}$Net: Scale-Adaptive Structure-Affinity Transformation for Spine Segmentation from Ultrasound Volume Projection Imaging", "authors": "Hao Xie,Zixun Huang,Yushen Zuo,Yakun Ju,Frank H. F. Leung,N. F. Law,Kin-Man Lam,Yong-Ping Zheng,Sai Ho Ling", "background": "脊柱分割在基于超声体积投影成像的智能脊柱侧弯诊断中起着至关重要的作用。然而，这一任务面临着多重挑战，包括忽视不同骨骼特征之间的高空间相关性可能导致脊柱的全局上下文知识无法良好学习，以及脊柱骨骼在形状和位置方面包含丰富的结构知识，这些知识应在分割过程中得到编码。", "innovation": "该研究提出了一个称为SA$^{2}$Net（尺度自适应结构感知网络）的新颖方法。它引入了一种尺度自适应互补策略来学习脊柱图像中跨维度的长距离相关特征，并提出了一种结构亲和性变换来变换具有类别特异性亲和性的语义特征，并将其与Transformer解码器结合使用，以实现结构感知推理。同时，该方法采用特征混合损失聚合方法来增强模型训练，从而提高分割过程的鲁棒性和准确性。研究表明，SA$^{2}$Net在脊柱分割性能上优于其他最先进的方法。", "conclusion": "实验结果表明，SA$^{2}$Net相较于其他最先进的方法在脊柱分割性能上具有优势。此外，SA$^{2}$Net对各种骨干网络的适应性增强了其作为用于智能脊柱影像分析的高级脊柱侧弯诊断工具的潜力。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26441", "html_url": "https://arxiv.org/abs/2510.26441", "title": "A-TPT: 视觉语言模型在测试时提示调谐中的角度多样性校准特性", "title_en": "A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models", "authors": "Shihab Aaqil Ahamed,Udaya S.K.P. Miriya Thanthrige,Ranga Rodrigo,Muhammad Haris Khan", "background": "测试时提示调谐（TPT）作为一种新兴技术，可以适应大型视觉语言模型（VLMs）在未标记数据上的未知任务。然而，文本特征之间的缺乏多样性会影响校准性能，这引发了对视觉语言模型可靠性和安全性方面的担忧。当前的TPT方法主要是通过最大化文本特征的平均多样性或施加正交约束来确保角度分离来改进提示校准，但这些方法可能无法始终在类别间的文本特征之间实现最佳的角度分离，这意味着忽视了角度多样性的重要性。", "innovation": "我们提出了A-TPT，一种新的TPT框架，通过引入角度多样性来促进由相应可学习提示引起的规范化文本特征分布的一致性。这种一致性是通过最大化单位超球体上特征之间的最小对角距离来实现的。我们的方法在减少总体平均校准误差的同时，通过广泛的实验与各种模型架构在不同数据集上的比较，显示出比最先进的TPT方法更好的零样本校准性能和更好的泛化能力。此外，我们还提供了详细的理论分析，以证明A-TPT的基础。这些结果突显了促进角度多样性以实现均匀分离的文本特征的重要性，显著提高了视觉语言模型在测试时的校准效果。", "conclusion": "我们的方法定期超越最先进的TPT方法，在减少综合平均校准误差的同时，通过广泛的实验在各种数据集和模型架构上保持了相当的准确性。我们的方法在自然分布转移和医学数据集上的零样本校准性能优越，并且能够很好地泛化。我们提供了广泛的分析，包括理论方面，以确立A-TPT的基础。这些结果凸显了促进角度多样性的能力，可以显著提高视觉语言模型在测试时的校准效果。我们的代码将公开发布。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26509", "html_url": "https://arxiv.org/abs/2510.26509", "title": "基于粒子群优化的细胞自动机边缘检测器稳健性分析", "title_en": "Analysis of the Robustness of an Edge Detector Based on Cellular Automata Optimized by Particle Swarm", "authors": "Vinícius Ferraria,Eurico Ruivo", "background": "边缘检测在图像处理中至关重要，用于提取图像中的相关信息。现有的某些检测器存在一些缺点，如难以检测松散边缘且缺乏上下文以从特定问题中提取相关信息。为解决这些问题并使检测器适应图像特性，本研究提出了一种由二维细胞自动机描述并结合元启发式算法与迁移学习技术优化的可调适边缘检测器。本研究旨在分析优化阶段搜索空间扩展对边缘检测器在自然图像集及其专门子集中的稳健性和可调适性的影响。", "innovation": "开发了由二维细胞自动机描述并结合元启发式算法与迁移学习技术优化的可调适边缘检测器，以解决现有的边缘检测器在检测松散边缘和缺乏上下文提取信息方面的不足。", "conclusion": "扩展优化阶段的搜索空间对于所选图像集无效，模型的可调适性通过一系列实验和验证技术分析，表明无论哪种验证方法，模型都能适应输入，但应用到模型中的迁移学习技术并未显示出显著改进。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26569", "html_url": "https://arxiv.org/abs/2510.26569", "title": "AdSum: 基于双流音频-视觉摘要的自动化视频广告剪辑", "title_en": "AdSum: Two-stream Audio-visual Summarization for Automated Video Advertisement Clipping", "authors": "Wen Xie,Yanjun Zhu,Gijs Overgoor,Yakov Bart,Agata Lapedriza Garcia,Sarah Ostadabbas", "background": "广告商通常需要为单一活动制作不同长度版本的同一广告，传统方法是手动从长视频广告中选择和重新编辑镜头以创建较短版本，这耗时且繁琐。目前缺乏专门针对广告的视频剪辑方法，本文提出了一种利用视频摘要技术的自动化视频广告剪辑框架，特别强调了音频在广告中的关键作用，旨在解决现有视频简化方法主要关注视觉内容的问题。研究人员开发了一种双流音频-视觉融合模型来预测视频帧的重要性，该模型适用于剪辑设定短广告（如15秒）的帧。", "innovation": "本文创新性地将视频剪辑问题转化为一个镜头选择问题，专注于专门为广告开发的视频摘要方法，并提出了一种双流音频-视觉融合模型，特别强调了音频在广告中的作用。此外，该研究还构建了一个新的数据集AdSum204，包含了102对实际广告活动中的30秒和15秒广告，以支持模型的训练和评估，实验结果表明，提出的方法在多种评估指标上优于现有最先进的方法。", "conclusion": "本文提出的框架在多种评估指标中明显优于现有的最先进的方法，展示了剪辑视频广告的自动化的潜力，特别强调了解决目前缺乏的专用广告数据集的挑战，并证明了双流音频-视觉融合模型的有效性。未来的工作可以进一步优化模型以适应更复杂的视频内容并扩展到其他广告类型。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26614", "html_url": "https://arxiv.org/abs/2510.26614", "title": "Spiking Patches: 异步的、稀疏和高效的事件摄像头表示", "title_en": "Spiking Patches: Asynchronous, Sparse, and Efficient Tokens for Event Cameras", "authors": "Christoffer Koo Øhrstrøm,Ronja Güldenring,Lazaros Nalpantidis", "background": "先前的工作使用帧或体素来表示事件，虽然这些方法能够提供高精度，但它们在时间同步性和空间稀疏性方面有所妥协。", "innovation": "提出了事件层次结构的分词方法，并设计了名为Spiking Patches的分词器，专为事件摄像头构建。Spiking Patches能够在保持事件摄像头独特属性的同时，提供比基于体素和帧的方法更快的推理时间，同时还能匹配甚至超越其准确性。", "conclusion": "通过使用Spiking Patches，事件表示构成了事件驱动视觉的一个新方向，朝着能够保留事件摄像头属性的方法迈出了一步。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26580", "html_url": "https://arxiv.org/abs/2510.26580", "title": "零样本真实世界场景推理中使用视觉-语言对齐的动态上下文感知场景推理", "title_en": "Dynamic Context-Aware Scene Reasoning Using Vision-Language Alignment in Zero-Shot Real-World Scenarios", "authors": "Manjunath Prasad Holenarasipura Rajiv,B. M. Vidyavathi", "background": "在现实环境中，AI系统往往面临没有标签数据的陌生场景，这给传统的场景理解模型带来重大挑战。无法在未见过的场景中泛化限制了基于视觉的应用在动态、非结构化环境中的部署。本文旨在解决这一问题，提出了一个动态上下文感知场景推理框架，利用视觉-语言对齐来处理零样本真实世界场景。", "innovation": "该框架通过结合预训练的视觉变换器和大规模语言模型来对齐视觉语义与自然语言描述，提升上下文理解。动态推理模块通过结合全局场景线索和对象级交互并通过语言先验来细化预测。实验结果表明，在零样本基准测试中（如COCO、Visual Genome和Open Images），该方法在复杂和未见过的环境中比基线模型的场景理解准确性提高了18%。此外，该方法在模糊或杂乱的场景中表现稳健，由于视觉与语言的协同融合。", "conclusion": "该框架提供了一种可扩展且可解释的上下文感知推理方法，推进了动态真实世界设置中的零样本泛化。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26583", "html_url": "https://arxiv.org/abs/2510.26583", "title": "Emu3.5：原生多模态模型是世界学习者", "title_en": "Emu3.5: Native Multimodal Models are World Learners", "authors": "Yufeng Cui,Honghao Chen,Haoge Deng,Xu Huang,Xinghang Li,Jirong Liu,Yang Liu,Zhuoyan Luo,Jinsheng Wang,Wenxuan Wang,Yueze Wang,Chengyuan Wang,Fan Zhang,Yingli Zhao,Ting Pan,Xianduo Li,Zecheng Hao,Wenxuan Ma,Zhuo Chen,Yulong Ao,Tiejun Huang,Zhongyuan Wang,Xinlong Wang", "background": "介绍了Emu3.5，这是一种大型多模态世界模型，能够直接预测视觉和语言下的下一个状态。该模型在包含超过10万亿个令牌的互联网视频的帧序列和对话文本交替数据集上进行统一的下一个令牌预测预训练。并且，该模型能够自然地接受视觉和语言的交替输入并生成交替的视觉和语言输出。", "innovation": "提出了一种名为Discrete Diffusion Adaptation（DiDA）的技术，转换了逐令牌解码为双向并行预测，提升了每张图像的推理效率约20倍，同时保持了性能。Emu3.5在长时间视觉-语言生成、任何到图像生成（X2I）及复杂文字丰富的图像生成上具有强烈的原生多模态能力，同时具备泛化的世界建模能力，支持多种场景和任务中的时空一致的世界探索和开放世界的实体操控。此外，Emu3.5在图像生成和编辑任务中与Gemini 2.5 Flash Image性能相当，并在一系列交替生成任务中展示了更优的结果。", "conclusion": "Emu3.5通过对公开数据集进行大规模强化学习后训练，增强了多模态推理和生成能力。同时，Emu3.5被开源，可以支持社区的研究。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26609", "html_url": "https://arxiv.org/abs/2510.26609", "title": "CYPRESS: 基于普里希维（Prithvi）编码器的卫星感应作物产量预测", "title_en": "CYPRESS: Crop Yield Prediction via Regression on Prithvi's Encoder for Satellite Sensing", "authors": "Shayan Nejadshamsi,Yuanyuan Zhang,Shadi Zaki,Brock Porth,Lysa Porth,Vahab Khoshdel", "background": "准确及时的作物产量预测对于全球粮食安全和现代农业管理至关重要。传统方法往往缺乏精度农业所需的可扩展性和粒度。加拿大草原地区的大规模实时作物产量预测数据集显示了这一领域的挑战。", "innovation": "本文介绍了一种新的深学习模型CYPRESS（Crop Yield Prediction via Regression on Prithvi's Encoder for Satellite Sensing），专为高分辨率、田间一级油菜籽产量预测设计。CYPRESS利用了预训练的大规模地理空间基础模型（Prithvi-EO-2.0-600M），并将其适应于连续回归任务，将多时相卫星图像转化为密集的像素级产量图。该模型在全面的加拿大草原数据集上展示了比现有基于深度学习的产量预测模型更好的性能，证明了针对特种农业应用微调基础模型的有效性。", "conclusion": "通过提供持续的高分辨率输出，CYPRESS为田间决策提供了更具体的操作工具，从而优于传统分类或县一级聚合方法。这项工作验证了一种将大规模地球观测与田间决策联系起来的新方法，提供了进行详细农业监测的可扩展解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26601", "html_url": "https://arxiv.org/abs/2510.26601", "title": "ResMatching: 遇到噪声时通过定向条件流匹配实现鲁棒计算超分辨率", "title_en": "ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching", "authors": "Anirban Ray,Vera Galinova,Florian Jug", "background": "计算超分辨率（CSR）在荧光显微镜中的应用已有悠久的历史，尽管这是一个病态问题，但通过找到能够用于外推从未由成像显微镜捕获频率的先验，它可以提高荧光显微镜图像的质量。随着数据驱动机器学习技术的进步，可以学到更强的先验，从而改善超分辨率的结果。", "innovation": "ResMatching 是一种新颖的计算超分辨率方法，它利用定向条件流匹配来学习改进的数据先验。ResMatching 在 4 种不同的生物结构上的表现与 7 种基线相当，尤其是在给定的低分辨率图像噪声较大时，能够更有效地实现超分辨率。此外，通过该方法可以生成像素级的数据不确定性项，用于指导未来的使用以拒绝不确定的预测。", "conclusion": "ResMatching能够在不同情况下提供最佳的数据保真度和视觉现实之间的权衡，并且其隐式学习的后验分布适用且校准良好。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26582", "html_url": "https://arxiv.org/abs/2510.26582", "title": "CATCH：一种基于钩子的模块化跨域适应模板", "title_en": "CATCH: A Modular Cross-domain Adaptive Template with Hook", "authors": "Xinjin Li,Yulie Lu,Jinghan Cao,Yu Ma,Zhenglin Li,Yeyang Zhou", "background": "最近的视觉问答（VQA）在自然图像领域取得了显著进展，模型如LLaVA借助大语言模型（LLMs）实现了开放式的推理。然而，当这些模型被转移到如遥感、医学影像或数学图等不同领域时，由于分布变化和缺乏有效的跨域适应机制，其性能会显著下降。现有的方法通常依赖于特定领域的微调或定制的流水线，这既昂贵又不灵活，缺乏广泛适用性。现有方法的这些局限性促使本文提出了CATCH框架，旨在通过最小改动核心架构来提升VQA模型的泛化能力，特别适用于跨领域的适应。", "innovation": "CATCH提出了一种模块化跨域适应框架，通过引入领域分类器和双适应机制（包括Prompt Adapter和Visual Adapter）来解耦视觉和语言的适应过程，利用统一的钩子接口动态注入这些模块，而无需重新训练骨干模型，从而提供了跨领域VQA的可扩展和延展方法。", "conclusion": "实验结果表明，CATCH框架在四个特定领域的VQA基准测试中均实现了性能提升，包括MathVQA提高了2.3个BLEU、MedVQA-RAD提高了2.6个VQA得分和ChartQA提高了3.1个ROUGE得分，这些结果证明了CATCH框架在多种应用领域中的实际部署潜力。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26630", "html_url": "https://arxiv.org/abs/2510.26630", "title": "PT-DETR：基于部分注意细节聚焦的小目标检测", "title_en": "PT-DETR: Small Target Detection Based on Partially-Aware Detail Focus", "authors": "Bingcong Huo,Zhiming Wang", "background": "本文针对无人机(UAV)目标检测面临的挑战，如复杂的背景、严重的遮挡、密集的小目标以及变化的光照条件，提出了基于RT-DETR的新型检测算法PT-DETR，专门针对无人机成像中的小对象进行目标检测。", "innovation": "1. 引入了部分注意细节聚焦(PADF)模块，增强小对象特征提取能力；\n2. 设计了中值频率特征融合(MFFF)模块，有效提升了模型捕捉小对象细节和上下文信息的能力；\n3. 结合使用了Focaler-SIoU，增强了模型的位置匹配能力和对小对象特征的敏感度，从而进一步提高了检测精度和鲁棒性。", "conclusion": "与RT-DETR相比，PT-DETR在VisDrone2019数据集上实现了1.6%和1.7%的mAP改进，同时具有较低的计算复杂度和较少的参数，证明了其在小目标检测任务中的鲁棒性和可行性。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26641", "html_url": "https://arxiv.org/abs/2510.26641", "title": "从像素、点和提示到下一代融合和多模态大/小型语言模型/视觉语言模型在自动驾驶中的对象检测所需的一切", "title_en": "All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles", "authors": "Sayed Pedram Haeri Boroujeni,Niloufar Mehrabi,Hazim Alzorgan,Ahmad Sarlak,Mahlagha Fazeli,Abolfazl Razi", "background": "自动驾驶车辆（AVs）通过智能感知、决策和控制系统的发展，正在改变未来的交通运输方式。然而，它们的成功依赖于可靠地在复杂和多模态环境中进行物体检测的核心能力。尽管近期计算机视觉（CV）和人工智能（AI）的进步推动了显著的进步，该领域仍然面临挑战，即知识碎片化的存在，涵盖多模态感知、上下文推理和合作智能等领域。本文综述了在AVs中进行物体检测的前景分析，强调了新兴范式，如Vision-Language Models (VLMs)、Large Language Models (LLMs)和生成型AI，而非重新审视过时的技术。", "innovation": "本文填补了知识碎片化的空白，通过构建一个综合框架，系统地回顾了AV传感器（包括摄像头、超声波、LiDAR和雷达）及其融合策略，特别关注了基于大规模和小型语言模型、生成型AI以及视觉语言模型的新颖检测方法，特别是基于Transformer驱动的方法。文章提供了从像素、点和提示到下一代融合和多模态大/小型语言模型/视觉语言模型应用于AV对象检测的全面视角。", "conclusion": "本文提供了一个清晰的路线图，概述了当前的能力、开放的挑战和未来的机会，强调了当前方法、现有的数据集和先进的检测方法。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26694", "html_url": "https://arxiv.org/abs/2510.26694", "title": "3D高斯散点的影响与展望", "title_en": "The Impact and Outlook of 3D Gaussian Splatting", "authors": "Bernhard Kerbl", "background": "自引入以来，3D高斯散点（3DGS）迅速改变了3D场景表示的格局，激发了大量的相关研究。后续工作包括分析和贡献，旨在提高3DGS的效率、可扩展性和现实世界中的应用。", "innovation": "本文概述了3DGS之后出现的一些关键方向。主要介绍了资源高效训练和渲染的进展、动态表示（或四维表示，4DGS）的发展、对基础数学原理的更深入探索，以及努力将3DGS推向移动和虚拟现实平台、扩展到大规模环境，以及通过前馈或分布式计算实现近实时辐射场重建的最新进展。", "conclusion": "这些发展表明，3DGS已从一种突破性的表示方法演变成3D视觉和图形领域的一个多用途和基础工具。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26653", "html_url": "https://arxiv.org/abs/2510.26653", "title": "ARCTIC 深度学习光学流在RADARSAT-2上的应用以实现可靠的海冰漂移估算", "title_en": "Towards Reliable Sea Ice Drift Estimation in the Arctic Deep Learning Optical Flow on RADARSAT-2", "authors": "Daniela Martin,Joseph Gallego", "background": "海冰漂移的准确估算对于北极导航、气候研究和操作性预报至关重要。尽管光学流作为一种计算机视觉技术，在估算连续图像间像素级运动方面取得了快速进展，但在地物理问题及卫星 SAR 图像中的应用仍较有限。经典光学流方法依赖于数学模型和强假设，限制了其在复杂场景中的准确性。而基于深度学习的新方法在性能上有了显著提升，因此被广泛应用于计算机视觉领域，促使研究人员将其应用于海冰漂移估算。", "innovation": "本文首次对48种深度学习光学流模型在RADARSAT 2 ScanSAR海冰遥感图像上的应用进行了大规模基准测试，使用终端误差 (EPE) 和 Flall 指标进行评估，结果表明该模型能实现接近海底冰以千米为单位的速度漂移估算，这是一个相对较小的误差，相较于海冰运动的空间尺度和北极导航的一般需求而言。结果表明，基于当前深度学习的光学流方法，其运动估计的准确性相比于经典方法有了显著提高，能够有效应用于极地遥感。", "conclusion": "光学流可以生成连续的漂移场，为每个图像像素提供运动估计，而不仅仅是稀疏的浮标位置，为导航和气候建模提供了新的机遇。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26778", "html_url": "https://arxiv.org/abs/2510.26778", "title": "通过精心选择U-Net架构和损失函数来解决RGB眼底图像中的AMD区域估计问题，超越现有最佳水平", "title_en": "Surpassing state of the art on AMD area estimation from RGB fundus images through careful selection of U-Net architectures and loss functions for class imbalance", "authors": "Valentyna Starodub,Mantas Lukoševičius", "background": "年龄相关性黄斑变性（AMD）是60岁以上人群不可逆视力损害的主要原因之一。本文关注的是在RGB眼底图像中进行AMD病变的语义分割，这是一种非侵入性和成本效益较高的成像技术。ADAM挑战是迄今为止最全面的基于RGB眼底图像的AMD检测研究竞赛和开放数据集，我们以此作为评估标准。", "innovation": "本文以U-Net连接性为基础框架，评估并比较了多种改进分割模型结构和训练管道的方法，包括预处理技术、不同复杂度的编码器（骨干）深层网络类型以及针对图像和像素层面类不平衡的专门损失函数。研究成果是提出了一个在非侵入性RGB眼底图像上的多类分割中比先前ADAM挑战提交结果表现更优的AMD检测框架。", "conclusion": "本文的研究结果通过开源实验代码，在基于RGB眼底图像的AMD病变区域估计方面超越了现有最佳水平的U-Net架构和损失函数的选择。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26684", "html_url": "https://arxiv.org/abs/2510.26684", "title": "钢铁轧制厂中结合过程计算机视觉的实时故障预测", "title_en": "Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill", "authors": "Vaibhav Kurrey,Sivakalyan Pujari,Gagan Raj Gupta", "background": "该研究介绍了在钢铁轧制厂中，基于机器视觉的异常检测系统在长期部署中的应用。该系统通过工业摄像头实时监控设备运行状态、对准情况及热钢棒运动，对生产线上的视频流进行深度学习模型处理，实现设备故障和工艺中断的早期预测，从而减少意外停机成本。基于服务器的推理可以减轻工业过程控制系统（PLC）的计算负担，支持在生产线中进行可扩展部署，同时不需要额外资源。该系统通过联合分析数据采集系统的传感器数据和视觉输入，能够识别故障的发生位置及其可能的根本原因，为预防性维护提供实用建议，从而提升工业制造环境中的运营可靠性、生产效率和盈利能力。", "innovation": "该创新提出了一种集成了过程计算机视觉的系统，可以在钢铁轧制厂实现实时故障预测。系统利用工业摄像头监测生产线关键环节，通过深度学习处理实时视频流，实现故障的早期预测，并提供基于视觉输入的直观故障分析。这种基于服务器的推理机制减轻了工业PLC的负担，提升了系统的扩展性和实用性。", "conclusion": "研究表明，该结合计算机视觉的检测系统能够显著提升钢铁轧制厂的可靠性和生产效率，通过早期故障预测和预防性维护，有效减少了意外停机成本，为工业制造环境提供了一种提升可靠性和利润的有效方法。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26769", "html_url": "https://arxiv.org/abs/2510.26769", "title": "SteerVLM：通过轻量级激活引导实现视觉语言模型的稳健模型控制", "title_en": "SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models", "authors": "Anushka Sivakumar,Andrew Zhang,Zaber Hakim,Chris Thomas", "background": "该论文介绍了一种轻量级的指引模块SteerVLM，它旨在引导视觉-语言模型（VLMs）生成更符合期望指令的输出。现有的方法往往需要修改模型权重或预提取静态向量，这可能会导致性能下降或实现复杂。SteerVLM通过学习配对提示的潜在嵌入来动态调整语言模态与图像语境之间的激活连接，从而在不修改模型权重的情况下提供精细控制，同时保持对离目标任务性能的稳定性。此外，SteerVLM通过维度激活调制和层间自适应指引来获得模型控制，无需预提取静态向量或手动调整干预点。该研究还提出了一种视觉叙事意向对齐（VNIA）多模态数据集，以支持VLM激活工程方法的开发和评估。", "innovation": "SteerVLM模块通过学习配对提示的潜在嵌入，动态调整语言模态与图像语境之间的激活连接。这种方法显著减少了对模型权重的修改，通过维度激活调制和层间自适应指引来实现精细控制。SteerVLM模块需要学习的参数量仅为原VLM大小的14%，并在无干预点手动调整的情况下实现模型控制。同时还引入了用于指导VLM开发和评估的VNIA数据集。", "conclusion": "该方法在引导和幻觉缓解基准测试中表现出色，提出了通过激活工程实现多模态模型控制的稳健解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26681", "html_url": "https://arxiv.org/abs/2510.26681", "title": "通过场景上下文改进遮挡物体的分类", "title_en": "Improving Classification of Occluded Objects through Scene Context", "authors": "Courtney M. King,Daniel D. Leeds,Damian Lyons,George Kalaitzis", "background": "遮挡物的存在对强大的物体识别算法提出了巨大的挑战。额外的信息来源可以显著减少由于遮挡引起的错误。生物视觉中的场景上下文已被证明能够帮助物体识别。在本工作中，我们尝试通过两种不同的场景信息融合技术，将鲁棒性添加到现有的RPN-DCNN目标检测网络中。我们提出了两种算法，分别在预测之前和之后进行操作，通过利用场景信息来改进目标识别。这些算法在部分遮挡的数据集上进行了测试，结果表明相比基线方法有整体改进，尤其是在召回率和精确率方面。实验还比较了多种遮挡物处理的训练方法，发现结合使用有遮挡和无遮挡图像进行训练的方法更有优势，提高了算法的效果并具有可解释性，能够轻松适应其他数据集，为未来的研究和实际应用提供了多种方向。", "innovation": "通过利用场景上下文信息，提出了一种场景信息融合技术，用于改进RPN-DCNN目标检测网络的鲁棒性。具体表现为预测前和预测后两种方法，分别为预选特征和后融合方法，以提高物体识别的准确性，尤其是在处理部分遮挡的情况时。还发现了结合使用有遮挡和无遮挡图像的训练方法对于处理遮挡更为有效，并且算法具有可解释性，容易适配其他数据集。", "conclusion": "通过引入场景上下文信息融合技术，提出的算法在处理部分遮挡的数据集上取得了优于基线方法的性能，尤其是在召回率和精确率方面。此外，实验还表明结合使用有遮挡和无遮挡图像进行训练的策略能够更有效地提高算法的性能。提出的方法具有解释性，可以轻松适应其他数据集，并为进一步的研究和应用提供了多种研究方向。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26781", "html_url": "https://arxiv.org/abs/2510.26781", "title": "ChartAB：可视化与语言模型的图表定位与密集对齐基准", "title_en": "ChartAB: A Benchmark for Chart Grounding & Dense Alignment", "authors": "Aniruddh Bansal,Davit Soselia,Dang Nguyen,Tianyi Zhou", "background": "图表在可视化、推理、数据分析以及人类之间的思想交流中起着重要作用。然而，现有的视觉-语言模型（VLMs）在图表细节感知方面仍存在缺陷，并且难以从图表中提取细致的结构。这类图表示 grounding 的限制阻碍了它们对多个图表进行比较和推理的能力。因此，本文提出了一种名为“ChartAlign基准（ChartAB）”的新颖评估框架，以全面评估 VLMs 在图表 grounding 任务中的能力，即从不同类型和复杂度的图表中提取表格数据、定位可视化元素并识别各种属性。此外，设计了一个 JSON 模板来计算每个任务中特定的评价指标。通过引入新颖的两阶段推理工作流，该基准可以进一步评估 VLMs 在两个图表之间对齐和比较元素/属性的能力。", "innovation": "本文提出了一种名为‘ChartAlign基准（ChartAB）’的评估框架，旨在全面评估视觉-语言模型在图表 grounding 任务中的能力。设计了一个 JSON 模板来计算每个 grounding 任务的特定评价指标。通过引入新颖的两阶段推理工作流，该基准可以进一步评估 VLMs 在两个图表之间对齐和比较元素/属性的能力。", "conclusion": "对多种近期 VLMs 的评估分析揭示了它们在图表理解中的感知偏差、弱点、鲁棒性和幻觉的新见解。这些发现突出了不同 VLMs 在图表理解任务中的细微差异，并指出了需要当前模型加强的具体技能。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26786", "html_url": "https://arxiv.org/abs/2510.26786", "title": "HEIR: 学习基于图的运动层次结构", "title_en": "HEIR: Learning Graph-Based Motion Hierarchies", "authors": "Cheng Zheng,William Koch,Baiang Li,Felix Heide", "background": "在计算机视觉、图形学和机器人学等领域，运动的层次结构广泛存在，复杂的动态通常是由简单运动组件之间的协调交互形成的。现有的模型通常依赖人工定义的或启发式的层次结构和固定的运动基元，这限制了它们在不同任务中的泛化能力。", "innovation": "本文提出了一种通用的基于数据的运动层次建模方法，能够从数据中学习结构化的、可解释的运动关系。该方法利用图结构来表示观察到的运动，并显式地将全局绝对运动分解为父继承模式和局部运动残差。层次结构的推断被表述为一个可微分的图学习问题，通过图神经网络捕捉父子依赖关系。", "conclusion": "实验结果表明，该方法在1D和2D情况下重建了固有的运动层次结构，并在动态3D场景变形中产生了更加现实和可解释的变形，与基线方法相比表现更佳。通过提供一种可适应的数据驱动的层次化建模框架，该方法为广泛的与运动为中心的任务提供了适用的公式化方法。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26794", "html_url": "https://arxiv.org/abs/2510.26794", "title": "探索可泛化的动作生成：数据、模型和评估", "title_en": "The Quest for Generalizable Motion Generation: Data, Model, and Evaluation", "authors": "Jing Lin,Ruisi Wang,Junzhe Lu,Ziqi Huang,Guorui Song,Ailing Zeng,Xian Liu,Chen Wei,Wanqi Yin,Qingping Sun,Zhongang Cai,Lei Yang,Ziwei Liu", "background": "尽管在标准基准测试上，现有的3D人体动作生成模型已经取得了显著进展，但这些模型依然面临着泛化能力不足的基本瓶颈。相比之下，相邻的生成领域，特别是视频生成（ViGen），已经表现出对人类行为建模的强大泛化能力，这为动作生成（MoGen）提供了一些可借鉴的经验教训。本文在数据、建模和评估三个方面系统地将ViGen的知识应用于MoGen。", "innovation": "本文提出了一个综合框架，通过数据、建模和评估三个关键方面，将大型视频生成数据集（ViMoGen-228K）和流匹配式的扩散变压器（ViMoGen和ViMoGen-light）以及新设计的评估基准（MBench）相结合，为动作生成提供了显著的泛化能力，相比于现有的方法，在自动和人工评估中均显示出更好的性能。", "conclusion": "该框架在动作质量、指令保真度和泛化能力等细粒度评估方面进行了广泛实验，表现出显著优于现有方法的表现。所有代码、数据和基准将公开提供。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26795", "html_url": "https://arxiv.org/abs/2510.26795", "title": "扩大图像地理定位到大陆级别", "title_en": "Scaling Image Geo-Localization to Continent Level", "authors": "Philipp Lindenberger,Paul-Edouard Sarlin,Jan Hosang,Matteo Balice,Marc Pollefeys,Simon Lynen,Eduard Trulls", "background": "在全球范围内确定图像的确切地理位置仍是一个未解决的挑战。标准图像检索技术由于图像数量庞大（超过10000万）而效率低下，且在覆盖不足时会失效。能够扩展的解决方案通常意味着权衡：全局分类通常产生粗略的结果（超过10公里），而地面和航空图像之间的跨视图检索面临领域差异，主要在较小的区域内进行研究。", "innovation": "本文提出了一种混合方法，用于在大陆大小的范围内实现细粒度的地理定位。在训练过程中利用代理分类任务来学习既包括详细地理位置信息的丰富特征表示。通过将这些学习原型与航空图像表示相结合，提高了该方法对地面数据稀疏性的鲁棒性。这使得可以在多个国家区域范围内进行直接、细粒度的检索。广泛的评估表明，我们的方法可以将68%以上的大部分欧洲地区的查询定位在200米以内。代码已公开可在该网址获取。", "conclusion": "我们广泛评估表明，该方法能够在覆盖大范围欧洲地区的数据集中有超过68%的查询能够准确定位在200米以内。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26800", "html_url": "https://arxiv.org/abs/2510.26800", "title": "OmniX：从统一全景生成和感知到图形级的3D场景", "title_en": "OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes", "authors": "Yukun Huang,Jiwen Yu,Yanning Zhou,Jianan Wang,Xintao Wang,Pengfei Wan,Xihui Liu", "background": "当前3D场景构建主要依赖于程序生成和2D提升两种方法。其中，基于全景图的2D提升因其强大的2D生成先验而得以广泛应用，能够生成沉浸式、写实且多样的3D环境。该研究在现有工作中进一步推进了全景图的2D提升技术，使之适用于基于物理的渲染（PBR），实现场景的重新照明和模拟。", "innovation": "本文提出了OmniX，这是一种统一且多功能的框架，通过轻量级的跨模态适配器结构，重用了2D生成先验，用于广泛的全景视觉任务，包括全景感知、生成和完成。与此不同的是，现有的2D提升方法主要关注外观生成而忽略了内在属性的感知。此外，该研究构建了一个大型合成全景数据集，包含高质量的多模态全景图，来自各种室内外场景。", "conclusion": "实验结果表明，该模型在全景视觉感知和图形级3D场景生成方面具有显著效果，为沉浸式和物理上更加真实的虚拟世界生成开辟了新的可能性。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26802", "html_url": "https://arxiv.org/abs/2510.26802", "title": "视频模型准备作为零样本推理引擎吗？MME-CoF基准上的实证研究", "title_en": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark", "authors": "Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng", "background": "近年来，视频生成模型能够生成高保真度、时序连贯的视频，这表明它们可能蕴含了丰富的世界知识。这些模型不仅能够实现逼真的合成，还展示了类似视觉感知、建模和操作的行为。然而，视频模型是否已经准备好在具有挑战性的视觉推理场景中进行零样本推理依然是一个关键问题。", "innovation": "本文开展了实证研究，以全面探讨视频模型作为零样本推理引擎的潜力，重点研究领先的Veo-3模型。该研究通过12个维度评估了模型的推理行为，对模型的优势和失败模式进行了系统的刻画，并构建了MME-CoF基准，以标准化评估流程并深入评估链帧推理。", "conclusion": "研究表明，当前的视频模型在短时间范畴内的空间一致性和细粒度的语义定位上表现出积极的推理模式，并且在局部一致的动力学方面也表现出良好的表现。但它们在长时间的因果推理、严格的几何约束以及抽象逻辑推理上仍然存在局限性。总体而言，视频模型尚未成为可靠的独立零样本推理引擎，但它们作为辅助的视觉引擎与专门的推理模型结合使用时展现出积极的前景。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26796", "html_url": "https://arxiv.org/abs/2510.26796", "title": "SEE4D：通过自回归视频修复实现无姿态4D生成", "title_en": "SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting", "authors": "Dongyue Lu,Ao Liang,Tianxin Huang,Xiao Fu,Yuyang Zhao,Baorui Ma,Liang Pan,Wei Yin,Lingdong Kong,Wei Tsang Ooi,Ziwei Liu", "background": "沉浸式应用要求从普通视频中合成时空4D内容，而无需昂贵的三维监督。现有的视频到4D方法通常依赖于手动注释的相机姿态，这既耗时又在野外拍摄时容易出错。最近的位移然后修补方法通过沿新的相机轨迹偏离输入帧并在缺失区域修补时移除轨迹标签的需求，从而从多个视角重现4D场景。然而，这种从轨迹到轨迹的方法往往会将相机运动与场景动态交织在一起，增加了建模和推理的复杂性。", "innovation": "引入SEE4D，一个无姿态、从轨迹到相机的框架，用渲染到一组固定的虚拟相机代替显式轨迹预测，从而将相机控制与场景建模分离。通过视图条件视频填补模型，训练出一种鲁棒的几何先验，用于去噪真实合成的位移图像并在虚拟视角之间修补遮挡或缺失区域，从而消除对显式三维注释的需求。在此填补核心基础上，设计了一种时空自回归推理流程，沿虚拟相机样条遍历并扩展视频片段，支持在许可的单步复杂度下实现一致的生成。", "conclusion": "SEE4D在交叉视图视频生成和稀疏重建基准测试中得到验证。在定量指标和定性评估中，该方法能够实现优于姿态或轨迹条件基线的优越泛化和性能，推动以普通视频为基础的实用4D世界建模的发展。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26799", "html_url": "https://arxiv.org/abs/2510.26799", "title": "掩码扩散captioning在视觉特征学习中的应用", "title_en": "Masked Diffusion Captioning for Visual Feature Learning", "authors": "Chao Feng,Zihao Wei,Andrew Owens", "background": "该研究提出了一种通过带有图像条件的掩码扩散语言模型来为图像生成描述的方法，即掩码扩散captioning（MDC）。这种方法在训练过程中，随机选择比例来掩蔽图像-描述对中的文本标记，并训练一个基于视觉特征的解码器来重构原始文本。这种方法使得视觉特征的学习信号强度不依赖于每个标记在序列中的位置，减少了对辅助目标的需求。实验表明，MDC方法在多种学术规模的模型和数据集上，学习到的视觉特征与自回归和对比方法相当或更好，适用于下游视觉任务。", "innovation": "该研究的创新之处在于提出了一种新的方法——掩码扩散captioning（MDC），它可以更有效地学习视觉特征。这种方法的核心优势在于，学习到的视觉特征的质量不依赖于文本标记的位置，这减少了在训练中需要的辅助目标数量，并且这种方法能够竞争性地达到现有的自回归和对比方法的效果。", "conclusion": "实验结果显示，MDC方法能够与自回归和对比方法在学习视觉特征方面取得竞争性的性能。这意味着MDC可以成为一种有效的方法，用于视觉特征的学习，尤其是在需要减少对额外辅助目标依赖的场景中。学习到的视觉特征可以通过线性注探实验应用于多种下游视觉任务中。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26022", "html_url": "https://arxiv.org/abs/2510.26022", "title": "使用物理启发式测试时自适应实现多参数心脏MRI的分组注册", "title_en": "Groupwise Registration with Physics-Informed Test-Time Adaptation on Multi-parametric Cardiac MRI", "authors": "Xinqi Li,Yi Zhang,Li-Ting Huang,Hsiao-Huang Chang,Thoralf Niendorf,Min-Chi Ku,Qian Tao,Hsin-Jung Yang", "background": "多参数 成像MRI 已成为心肌组织表征的有效工具，但多参数图之间的错位使得像素级分析具有挑战性。本研究旨在通过引入一种通用的基于物理的深度学习模型，结合测试时自适应实现跨不同物理模型的组图像对齐，解决这一问题，以实现用于多种组织对比的推导式学习。。", "innovation": "提出了一个通用的基于物理特征的深度学习模型，并采用了测试时自适应策略，利用特定物理模型的合成图像作为对齐参考，进行分组图像注册，使不同类型的组织对比可以进行宽范围的图像对齐学习.", "conclusion": "该模型在健康志愿者中使用多种MRI序列进行了验证，结果表明其能改进多模式对齐能力，在广泛的图像对比度变化范围内都有所改善。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26004", "html_url": "https://arxiv.org/abs/2510.26004", "title": "DARTS: 一种基于无人机的人工智能实时交通事故检测系统", "title_en": "DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System", "authors": "Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang", "background": "快速可靠的事故检测对于减少车祸相关的死亡、受伤和交通拥堵至关重要。然而，传统的监控方法（如闭路电视、行车记录仪和基于传感器的检测）缺乏灵活性，需要密集的基础设施或高渗透率，限制了对事故热点的适应性和扩展性。", "innovation": "为解决上述挑战，我们开发了DARTS，一种基于无人机、依赖人工智能的实时交通事故检测系统。该系统整合了无人机的高机动性和空中视角进行适应性监控，并结合了热成像以提高低能见度条件下的性能和隐私保护。此外，它还采用轻量级深度学习框架以实现实时车辆轨迹提取和事故检测。在佛罗里达州75号洲际公路上的现场测试中，DARTS预计比当地交通运输管理中心提前12分钟检测和验证了一起追尾事故，并监测了事故引发的交通拥堵传播，说明它可能支持更快的紧急响应并允许通过主动交通控制减少交通拥堵和次生事故风险。此外，DARTS弹性的部署架构减少了对频繁巡逻的依赖，显示了在偏远地区和资源受限环境中广泛使用和具有成本效益的潜力。", "conclusion": "本研究展示了对未来灵活、一体化的实时交通事故检测系统的前景，对现代交通管理的操作效率和响应能力具有重大影响。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识蒸馏（KD）是一种有效的模型压缩方法，可以将知识从教师模型转移到学生模型。然而，关于知识蒸馏对模型鲁棒性的影响，尤其是在处理不一致相关性时的表现，研究较少。因此，该论文探讨了知识蒸馏对学生模型的去偏能力影响，特别是在自然语言推理（NLI）和图像分类任务中的表现。", "innovation": "研究发现了几个关键发现，包括：(i) 知识蒸馏后模型的去偏能力受到了削弱；(ii) 培训去偏模型时不能从教师知识中受益；(iii) 虽然模型的整体鲁棒性可能在知识蒸馏后保持稳定，但不同类型偏见的鲁棒性变化显著；(iv) 研究明确了导致知识蒸馏后不同行为的内部注意力模式和电路。鉴于上述发现，提出了三种提高去偏方法可蒸馏性的有效解决方案：开发高质量的数据进行增强，实现迭代知识蒸馏，以及用教师模型的权重初始化学生模型。", "conclusion": "本次研究是首例大规模探讨知识蒸馏对去偏能力和其内在机制的影响的研究。发现为理解和设计更好的去偏方法提供了洞察。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26141", "html_url": "https://arxiv.org/abs/2510.26141", "title": "基于结构序列化和分离的StructLayoutFormer：条件导向的结构布局生成", "title_en": "StructLayoutFormer:Conditional Structured Layout Generation via Structure Serialization and Disentanglement", "authors": "Xin Hu,Pengfei Xu,Jin Zhou,Hongbo Fu,Hui Huang", "background": "在许多二维视觉内容（例如GUI和网页）中，结构化布局因其结构信息提供的方便排版编辑而受到青睐。现有的计算框架可以帮助创建结构化布局，但需要大量劳动输入。虽然现有的基于数据驱动的方法能够有效地自动生成固定布局，但它们无法生成结构化的布局。", "innovation": "提出了基于Transformer的名为StructLayoutFormer的新颖方法，用于条件导向的结构布局生成。使用结构序列化方案将结构化布局表示为序列，并通过分离结构信息和元素放置来更好地控制生成布局的结构。这是第一个既能够实现条件导向的结构布局生成又能明示生成真实结构的基于数据驱动的方法。", "conclusion": "对基于数据驱动的布局生成方法进行了广泛实验比较，并通过结构提取的后处理。实验结果表明，我们的方法在条件导向的结构布局生成中优于现有基线。此外，我们的方法在提取和转移布局结构方面也表现出有效性。代码已公开发布。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS：通过自我蒸馏偏好驱动的冷启动分解多模态学习", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "论文背景在于现有大多数的基于机器学习与语言模型的强化学习（RL）方法在使用监督微调（SFT）进行冷启动时，可能会导致领域过拟合并影响下游RL的表现。这些方法将理解过程与任务解决和输出格式结合在一起，可能引起指令风格过拟合和弱化了对于分布外的一般化能力。论文作者通过重新审视冷启动训练方法与数据构建，引入了一个通用因子（GF）系数来量化不同方法下的泛化能力，发现了偏好驱动的训练方法在冷启动中泛化表现更好。", "innovation": "本文的创新点在于提出了一个名为SPECS（Self-distilled, Preference-based Cold Start）的自我蒸馏偏好驱动的冷启动框架，该框架通过自我蒸馏生成自我反省偏好数据对，避免依赖更大的教师模型或手动标注；进行偏好驱动的训练，专注于浅层、可传输的表现形式标准（格式、结构、风格）而非记忆内容；最终通过验证奖励进行强化学习以获得深层推理结果。实验结果显示，该分隔学习框架在多个多模态基准测试中表现出一致性性能提升，提高了MEGA-Bench和MathVista的表现分别达到了4.1%和12.2%。此外，研究还表明SPECS减少了分布内“卡顿”的情况、改善了探索、稳定了训练并提升了性能上限。", "conclusion": "通过引入通用因子（GF）系数来量化不同冷启动方法的泛化能力，研究发现在冷启动中偏好驱动的训练方法表现更好。据此，提出了SPECS框架，通过自我蒸馏生成数据，偏好驱动训练，结合验证奖励进行强化学习，有效改善了多模态模型的训练性能和泛化能力，尤其在不同基准测试中显示出了显著的性能提升。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26170", "html_url": "https://arxiv.org/abs/2510.26170", "title": "通过融合单目相机的全局和局部特征实现3D地图上的自定位", "title_en": "Self-localization on a 3D map by fusing global and local features from a monocular camera", "authors": "Satoshi Kikuch,Masaya Kato,Tsuyoshi Tasaki", "background": "实现自主驾驶需要在3D地图上使用廉价的单目相机进行自定位。基于相机的自定位通常使用可以提取由附近像素计算出的局部特征的卷积神经网络（CNN）。但在存在动态障碍物（如行人）的情况下，CNN的表现不佳。", "innovation": "本研究提出了一种结合CNN与Vision Transformer的新方法。Vision Transformer擅长提取显示整个图像上各个块之间关系的全局特征。实验结果显示，在包含动态障碍物的CG数据集中，与目前最先进的方法相比，包含动态障碍物时的准确率提高了1.5倍，不包含动态障碍物时提高了更多。此外，与SOTA方法相比，本方法在公共数据集上的自定位误差降低了20.1%。使用本方法的机器人可以将平均自定位误差降低到7.51厘米，比SOTA方法更有精度。", "conclusion": "本方法通过将全局和局部特征融合，显著提高了单目相机在动态环境中的自定位精度。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26369", "html_url": "https://arxiv.org/abs/2510.26369", "title": "CorVS：通过视频轨迹-传感器对应实现仓库中的人体识别", "title_en": "CorVS: Person Identification via Video Trajectory-Sensor Correspondence in a Real-World Warehouse", "authors": "Kazuma Kano,Yuki Mori,Shin Katayama,Kenta Urano,Takuro Yonezawa,Nobuo Kawaguchi", "background": "在工业场所，工人的位置数据对提高生产力至关重要。在物流仓库中，通过摄像头进行定位也是一种有前景的方法，因为它还能提供有价值的环境上下文，例如包裹的状态。然而，仅凭视觉数据识别个人往往是不切实际的。前人的研究通过比较每个人的轨迹和可穿戴传感器的测量结果来识别人员。尽管这种方法具有无需依赖外貌的优点，但在实际环境中仍可能失效。", "innovation": "本文提出了CorVS，一种基于视频跟踪轨迹和传感器测量对应的新型数据驱动的人体识别方法。首先，深度学习模型预测每对轨迹和传感器测量的对应概率和可靠性。其次，算法使用预测的概率和可靠性来匹配轨迹和传感器测量。通过使用实际仓库操作的数据集，证明了该方法在实际应用中的有效性。", "conclusion": "CorVS通过视频轨迹和传感器测量的对应关系进行了人体识别，解决了传统方法在实际应用中可能失效的问题，证明了其在实际仓库操作中的有效性。这项研究为物流仓库中的人体识别提供了一种新的方法。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26358", "html_url": "https://arxiv.org/abs/2510.26358", "title": "AgriGS-SLAM：通过多视角高斯点渲染SLAM进行跨季节果园制图", "title_en": "AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM", "authors": "Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci", "background": "自走式农业机器人的果园系统需要在重复的行几何形状、季节性外观变化以及因风引起的叶片运动带来的挑战下具备实时3D场景理解能力。现有的方法通常难以在这些复杂条件下提供稳定和准确的建图效果，尤其是在多次变换后重建3D GS时容易出现过拟合问题。这个论文针对这些问题进行了深入研究。", "innovation": "提出了AgriGS-SLAM，一种结合直接LiDAR里程计和回环闭合与多相机3D Gaussian Splatting (3DGS) 渲染的视觉-LiDAR SLAM框架。通过跨视角批量渲染来恢复在遮挡下的果园结构，统一的、以梯度驱动的地图生命周期在关键帧之间执行，保持细化的细节并限制内存。通过基于概率的LiDAR深度一致性项引导位姿优化，并在网络投影后反向传播，从而加强几何与外观的耦合。该系统在苹果和梨果园的不同生长期进行实地部署，并采用标准化的轨迹协议评估训练视图和新视图合成，从而减少3DGS过拟合的问题，实现了季节性和地点上的更高精度和更稳定的重建以及轨迹。", "conclusion": "AgriGS-SLAM在保持实时性能的前提下，提供了相对于最近的竞争3DGS-SLAM基准更清晰且更加稳定地重建和更稳定地轨迹，该方法不仅适用于果园监测，还可用于其他需要稳健多模态感知的室外领域。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26573", "html_url": "https://arxiv.org/abs/2510.26573", "title": "基于UAV影像的橄榄树树冠及阴影分割深度学习模型比较分析", "title_en": "Comparative Analysis of Deep Learning Models for Olive Tree Crown and Shadow Segmentation Towards Biovolume Estimation", "authors": "Wondimagegn Abebe Demissie,Stefano Roccella,Rudy Rossetto,Antonio Minnocci,Andrea Vannini,Luca Sebastiani", "background": "在地中海地区，由于气候引起的胁迫，橄榄树生物体积估算成为精准农业中的关键任务，支持产量预测和资源管理。", "innovation": "研究使用U-Net、YOLOv11m-seg和Mask RCNN三种深度学习模型，对比分析其在超高清UAV影像中分割橄榄树树冠及其阴影的效果，强调空间特征提取和鲁棒分割，并通过太阳几何学结合树冠投影面积和阴影衍生高度进行生物体积估算.", "conclusion": "掩码区域提议网络(Mask R-CNN)在总体准确性和交并比(mIoU)方面表现最佳，而YOLOv11m-seg提供了最快的速度（每张图像0.12秒）。生物体积范围在约4至24立方米之间，反映树木间的结构差异。Mask R-CNN适用于对生物体积准确性要求高的场景，而YOLOv11m-seg适合大规模部署需要快速处理的情况；U-Net作为轻量级且高灵敏度的选项仍然有效。此框架实现准确且可扩展的果园监控，并可通过DEM或DSM集成和现场校准进一步增强，以支持操作决策."}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26703", "html_url": "https://arxiv.org/abs/2510.26703", "title": "ProstNFound+: 在医疗基础模型用于前列腺癌检测的前瞻性研究", "title_en": "ProstNFound+: A Prospective Study using Medical Foundation Models for Prostate Cancer Detection", "authors": "Paul F. R. Wilson,Mohamed Harmanani,Minh Nguyen Nhat To,Amoon Jamzad,Tarek Elghareb,Zhuoxin Guo,Adam Kinnaird,Brian Wodlinger,Purang Abolmaesumi,Parvin Mousavi", "background": "医疗基础模型（FMs）提供了构建高性能诊断系统的方法，但在微超声（μUS）检测前列腺癌（PCa）方面的临床应用尚未得到测试。本研究介绍了一种名为ProstNFound+的医疗基础模型的适应，用于μUS检测PCa，并首次进行了前瞻性验证。", "innovation": "ProstNFound+结合了医疗基础模型、适配器调优以及嵌入了PCa特定临床生物标志物的自定义提示编码器。模型生成癌症热图和临床显著PCa的风险评分。训练后，模型在五年后的新临床站点数据上进行了前瞻性评估，模型预测结果与标准临床评分协议（PRI-MUS和PI-RADS）进行了比对。", "conclusion": "结果表明，ProstNFound+在前瞻性数据上的表现很强劲，并且没有性能下降，与临床评分高度一致，生成的热图与活检确认的病变一致。结论强调了它的临床部署潜力，提供了一种可扩展且可解释的专家驱动流程的替代方案。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26661", "html_url": "https://arxiv.org/abs/2510.26661", "title": "BRIQA: 平衡加权在儿科大脑MRI图像质量评估中的应用", "title_en": "BRIQA: Balanced Reweighting in Image Quality Assessment of Pediatric Brain MRI", "authors": "Alya Almsouti,Ainur Khamitova,Darya Taratynova,Mohammad Yaqub", "background": "在儿科大脑磁共振成像(MRI)中，评估图像中伪影的严重程度对于提高诊断准确率至关重要，尤其是在低场系统中，信噪比较低。手动的质量评估耗时且主观，因此需要一种稳健的自动化解决方案来改进这一过程。", "innovation": "本文提出了一种名为BRIQA（Balanced Reweighting in Image Quality Assessment）的方法，用于解决伪影严重程度级别的类别不平衡问题。BRIQA使用基于梯度的损失加权来动态调整每一类的贡献，还采用了旋转批处理方案来确保对少数类别的一致性曝光。通过实验，没有一种架构在所有伪影类型中表现最佳，凸显了架构多样性的必要性。旋转批处理配置结合交叉熵损失时能促进均衡学习，提高了多项指标的表现。BRIQA在平均宏F1分数上提高了从0.659到0.706，尤其在Noise、Zipper、Positioning、Contrast、Motion和Banding伪影严重性分类上表现突出，并且代码可以在该链接下载：this https URL", "conclusion": "BRIQA通过平衡加权方法和旋转批处理策略，显著提高了儿科大脑MRI中伪影严重程度分类的准确性，并且该方法已经在实验中得到验证，具有很好的应用前景。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26390", "html_url": "https://arxiv.org/abs/2510.26390", "title": "SPG-CDENet: 基于空间先验引导的交叉双编码器网络在多器官分割中的应用", "title_en": "SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation", "authors": "Xizhi Tian,Changjun Zhou,Yulin. Yang", "background": "多器官分割是计算机辅助诊断中的关键任务。近年来，深度学习方法在图像分割中取得了显著的成功，但器官大小和形状的巨大差异挑战了其在多器官分割中的有效性。", "innovation": "本文提出了一个名为SPG-CDENet的空间先验引导交叉双编码器网络，这是一种新颖的两阶段分割范式，旨在提高多器官分割的准确性。该网络包括两个关键组件：空间先验网络和交叉双编码器网络。空间先验网络生成粗略的定位图，划定大致的感兴趣区域（ROI），为双编码器网络提供空间引导。交叉双编码器网络包含四个核心组件：全局编码器、局部编码器、对称交叉注意力模块和基于流的解码器。全球编码器从整个图像中捕获全局语义特征，而局部编码器专注于先验网络的特征。为了增强全局和局部编码器之间的交互，通过提出所有编码器层中的对称交叉注意力模块来融合和细化特征。此外，基于流的解码器直接从最终编码器层传播高级语义特征到所有解码器层，最大限度地保存和利用特征。", "conclusion": "在两个公开数据集上进行了广泛的定性和定量实验，表明SPG-CDENet在与现有分割方法相比具有优越的性能。进一步的消融研究进一步验证了所提模块在提高分割准确性方面的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26635", "html_url": "https://arxiv.org/abs/2510.26635", "title": "SAMRI: Segment Anything Model for MRI", "title_en": "SAMRI: Segment Anything Model for MRI", "authors": "Zhao Wang,Wei Dai,Thuy Thanh Dao,Steffen Bollmann,Hongfu Sun,Craig Engstrom,Shekhar S. Chandra", "background": "准确的磁共振成像（MRI）分割对于临床决策至关重要，但手动执行时非常耗时。基于卷积神经网络（CNN）的方法可以准确且高效，但在处理MRI的可变对比度、强度不均匀性和不同协议时泛化能力较差。尽管基于Transformer的Segment Anything Model (SAM)在自然图像中显示出卓越的泛化能力，现有的适应方法通常将MRI视为另一种成像模式，而不考虑这些特有的成像挑战。因此，需要一种专门为MRI设计的方法来有效解决这些问题。", "innovation": "SAMRI 是一种专为 MRI 设计的模型，通过对 110 万标记的 MRI 切片进行训练和验证，涵盖了全身器官和病理情况。通过简单的微调策略重新训练 SAM 的掩码解码器，该模型训练时间减少了 94%，可训练参数减少了 96%，而无需重新训练整个模型。在各种MRI分割任务中，SAMRI 达到了平均 Dice 值 0.87，实现了各个解剖区域的最优准确性，并在未见过的结构（特别是小且临床重要的结构）上表现出强大的泛化能力。", "conclusion": "SAMRI 在多种MRI分割任务中取得了卓越的成果，特别是在解剖区域的准确性、未见过的结构（尤其是小且临床重要的结构）的泛化能力上达到了最先进的水平。通过简单的微调策略，降低了模型的训练时间和参数数量，从而提高了效率和性能。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26759", "html_url": "https://arxiv.org/abs/2510.26759", "title": "MORE：跨器官医学图像重建数据集", "title_en": "MORE: Multi-Organ Medical Image REconstruction Dataset", "authors": "Shaokai Wu,Yapan Guo,Yanbiao Ji,Jing Tong,Yuxiang Lu,Mei Li,Suizhi Huang,Yue Ding,Hongtao Lu", "background": "当前的深度学习方法通常局限于特定的解剖结构和数据集，这限制了它们对未见解剖结构和病变的一般化能力。CT重建为放射科医生提供了用于诊断和治疗的图像，但现有的方法难以推广到新的解剖结构和类型，这对临床应用提出了挑战。", "innovation": "该研究引入了一个名为Multi-Organ医疗图像重建(MORE)的数据集，包含了9种不同的解剖结构和15种病变类型的数据集。该数据集有两个关键目标：(1)提供大数据、多样性的训练数据以增强模型的稳健性，(2)为CT重建模型的跨域泛化能力提供严格的评估基准。此外，研究者还提出了一种新的优化方法作为基准，该方法在具有挑战性的条件下优于之前的方法，展示了优化方法在处理未知解剖结构时的优越性。", "conclusion": "实验结果表明，综合多样化的数据集能有效提升模型的泛化能力，而优化方法在处理未知解剖结构时表现出更强的鲁棒性。研究者进一步表明，MORE数据集以CC-BY-NC 4.0授权形式免费提供，可以促进医学影像领域中跨器官CT重建的研究工作。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26782", "html_url": "https://arxiv.org/abs/2510.26782", "title": "使用几何正则化世界模型复制确定性3D世界", "title_en": "Clone Deterministic 3D Worlds with Geometrically-Regularized World Models", "authors": "Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen", "background": "世界模型是模拟世界如何演化的内部模型。基于过去的观察和行动，它能够预测体表智能体及其环境的未来。精确的世界模型对于智能体在复杂和动态环境中思考、规划和有效推理至关重要。尽管取得快速进展，当前的世界模型仍存在脆弱性，随着时间的推移性能会下降。主要原因是外部输入（如图像）具有高维特征，且丢失或缠结的潜在变量使动力学习变得没有必要地复杂。因此，本文探讨是否通过单独改进表示学习能否显着提高世界模型的性能。", "innovation": "本文提出了一种几何正则化世界模型（GRWM），它确保自然感官轨迹中连续点在潜在表示空间中的距离保持较小。这种方法产生了显著改进的潜在表示，与环境的真实拓扑结构紧密匹配。GRWM 实现简便，只需要少量架构修改，可扩展到轨迹长度，并兼容各种潜在生成模型。通过在确定性3D环境中和长期预测任务中测试，GRWM 显著提高了展开的准确性和稳定性。", "conclusion": "分析表明，其优点来自于学习具有优越几何结构的潜在流形。这些发现支持一个明确的结论：改进表示学习是建立稳健的世界模型的一种直接且有用的路径，能够提供可靠的长时程预测，且不需要扩大动力模块的规模。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.08788", "html_url": "https://arxiv.org/abs/2403.08788", "title": "VerifIoU - 对象检测对扰动的鲁棒性", "title_en": "VerifIoU - Robustness of Object Detection to Perturbations", "authors": "Noémie Cohen,Mélanie Ducoffe,Ryma Boumazouza,Christophe Gabreau,Claire Pagetti,Xavier Pucel,Audrey Galametz", "background": "本文介绍了一种新的区间边界传播（IBP）方法，用于正式验证对象检测模型，特别是针对交并比（IoU）指标。该方法已经实现为一个开源代码IBP IoU，兼容流行的抽象解释验证工具。", "innovation": "该方法在对象检测跑道降落检测和手写数字识别案例研究中进行评估，与基线（经典IBP IoU）相比，展示了IBP IoU在确保准确性和稳定性方面的优越性能，有助于更安全和可信赖的机器学习应用。", "conclusion": "VerifIoU验证器在确保对象检测模型的鲁棒性和准确性方面表现出色，为相关应用提供保障。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.07734", "html_url": "https://arxiv.org/abs/2311.07734", "title": "Quality-Aware Prototype Memory for Face Representation Learning", "title_en": "Quality-Aware Prototype Memory for Face Representation Learning", "authors": "Evgeny Smirnov,Vasiliy Galyuk,Evgeny Lukyanets", "background": "原型记忆是一种强大的模型，用于人脸表示学习，它能够在任何大小的数据集上训练人脸识别模型，通过在生成子抽样中的原型（分类权重）并在高效利用它们方面发挥作用。尽管原型记忆在许多面部识别基准测试中表现出色，但在原型生成算法的使用过程中，由于低质量或不可辨认的人脸图像时无法准确计算出原型，会导致问题。所有同一个人的图像都是以相同权重使用的，从而可能会受到低质量人脸图像不准确嵌入的污染，导致训练信号误导并降低训练模型的性能。", "innovation": "本文提出了一种简单且有效的方法，通过质量感知的原型生成方式改进了原型记忆。质量感知原型记忆在原型生成过程中使用不同权重的图像质量。这种改进使得原型可以从高质量图像中获得更多有用的信息信号，并较少受到低质量图像的影响。此外，本文还提出了几种质量估计和使用的不同方法，并在不同的面部识别基准测试上进行了广泛实验，证明了所提出模型相对于基本的原型记忆版本的优势。", "conclusion": "通过引入质量感知的原型生成机制，改进了原型记忆，使得模型能够在不同程度的图像质量下更好地适应，从而提高了模型的性能和准确性。实验结果表明，所提出的模型相比基本版本的原型记忆在各种面部识别基准测试中表现更好。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.15863", "html_url": "https://arxiv.org/abs/2406.15863", "title": "EmoAttack: 通过情绪生成图像的后门攻击", "title_en": "EmoAttack: Emotion-to-Image Diffusion Models for Emotional Backdoor Generation", "authors": "Tianyu Wei,Shanmin Pang,Qi Guo,Yizhuo Ma,Xiaofeng Cao,Qing Guo", "background": "文本到图像的扩散模型可以根据文本输入生成真实的图像，使用户能够通过语言传递他们的视觉意见。在语言中，情绪在表达个人观点方面起着重要作用，而恶意负面内容的出现可能会误导用户，加剧负面情绪。鉴于扩散模型的成功以及情绪的重要性，研究了文本到图像扩散模型的一个被忽视的风险，即利用输入文本中情绪引入恶意负面内容并激发用户的负面情绪。因此，本文提出了一种新的后门攻击方法——情绪感知后门攻击（EmoAttack），该方法在图像生成过程中通过情绪文本触发恶意负面内容。", "innovation": "本文识别了一种新的后门攻击方法，即情绪感知后门攻击（EmoAttack），并通过建立情绪词汇簇与包含恶意负面内容的参考图像之间的映射来微调预训练的扩散模型，这种方法无需进行大量模型再训练，提出了EmoBooth。此外，作者构建了一个数据集来验证该方法的有效性，并深入分析讨论了其效果。", "conclusion": "鉴于消费者广泛使用扩散模型，揭示这一威胁对于社会是非常重要的。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.17434", "html_url": "https://arxiv.org/abs/2311.17434", "title": "GSE: 组级稀疏且可解释的对抗攻击", "title_en": "GSE: Group-wise Sparse and Explainable Adversarial Attacks", "authors": "Shpresim Sadiku,Moritz Wagner,Sebastian Pokutta", "background": "稀疏对抗攻击旨在通过最少的像素扰动欺骗深度神经网络（DNNs），并通常使用$\boldsymbol{\textbf{l}}_0$范数进行正则化。最近的研究用结构稀疏性正则化器，如核组范数，代替了$\boldsymbol{\textbf{l}}_0$范数，以生成组级稀疏的对抗攻击。这种方法使得扰动具有更好的可解释性和实际意义，但同时也增加了优化的复杂性，因为需要在非凸目标下计算像素组的范数。现有方法面临的是一个优化挑战。", "innovation": "本文提出了一种两阶段算法，能够在图像的语义相关区域生成组稀疏的对抗攻击。首先，使用针对非凸编程定制的$1/2-$拟范数邻近算子优化伪范数对抗损失；随后过渡到应用2范数正则化对扰动幅度的投影Nesterov加速梯度下降。这种方法在CIFAR-10和ImageNet数据集上的实验证明，组稀疏度显著提升，同时在计算效率、可解释性和攻击成功率方面得到了改进。", "conclusion": "实验结果表明，该方法在组稀疏性方面表现显著提升，例如在CIFAR-10上的稀疏度为50.9%，在ImageNet上的稀疏度为38.4%（平均情况，靶向攻击）。性能改进伴随着显著的计算时间减少，增强了可解释性，并实现了100%的攻击成功率。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.13267", "html_url": "https://arxiv.org/abs/2401.13267", "title": "医学报告生成的动态溯源学习", "title_en": "Dynamic Traceback Learning for Medical Report Generation", "authors": "Shuchang Ye,Mingyuan Meng,Mingjian Li,Dagan Feng,Usman Naseem,Jinman Kim", "background": "自动化的医学报告生成展示了显著减少耗时的医学报告工作量的潜力。然而，基于端到端训练并在直接应用于医学图像到文本生成时，现有的生成表示学习方法面临着两大挑战：一是难以精确捕捉细微但关键的病理细节，二是依赖于视觉和文本输入，导致仅使用图像时的零样本推理表现下降。这些挑战限制了现有的方法在实际应用中的效果和灵活性。", "innovation": "本文提出了一种新颖的多模态动态溯源学习框架（DTrace），引入了追溯机制监督生成内容的语义有效性，并采用动态学习策略适应不同比例的图像和文本输入。通过监督模型从互补 counterpart 中恢复被遮盖的语义信息来增强跨模态知识的学习，从而解决了上述挑战，提高了文本生成的灵活性和准确性。", "conclusion": "在两个基准数据集 IU-Xray 和 MIMIC-CXR 上进行的广泛实验表明，提出的 DTrace 框架在医学报告生成方面优于当前最先进的方法。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2208.08083", "html_url": "https://arxiv.org/abs/2208.08083", "title": "两个分支比一个更好：鲁棒学习与多分支模型的结合", "title_en": "Two Heads are Better than One: Robust Learning Meets Multi-branch Models", "authors": "Zongyuan Zhang,Qingwen Bu,Tianyang Duan,Zheng Lin,Yuhao Qing,Zihan Fang,Heming Cui,Dong Huang", "background": "深度神经网络(DNNs)对对抗性样本非常脆弱，这些样本中的微小不可感知的扰动可以使DNNs产生错误的输出。对抗训练作为一种可靠且有效的防御方法，能够显著降低神经网络的脆弱性，并已成为实现鲁棒学习的事实标准。尽管许多近期工作关注于数据为中心的方法，如如何产生更好的对抗样本或使用生成模型来生成额外的训练数据，但本研究回归到模型本身，在深度特征分布的角度重新审视对抗鲁棒性，提供了新的视角。论文提出了一种仅使用原始数据集的对抗训练方法——分支正交对抗训练模型（BORT），以获得最先进的性能。同时，通过利用简单且直接的多分支神经网络模型，能够在不增加推理时间的情况下击败对抗攻击。为了实现这种设计理念，论文提出了分支正交损失来使多分支模型的每个解空间正交。在CIFAR-10、CIFAR-100和SVHN数据集上，论文方法针对$l_{\text{∞}}$范数限幅大小为$\frac{8}{255}$的扰动进行评估，证明了有效性和优越性。相较不使用额外数据训练的方法，所提出的方法在CIFAR-10和CIFAR-100上的鲁棒准确率分别达到了67.3%和41.5%，显著超过现有最优方法的7.23%和9.07%。同时，实验结果也优于大数据训练集的方法。", "innovation": "论文提出了一种新的对抗训练方法——分支正交对抗训练模型（BORT），该模型仅使用原始数据集就能获得最先进的性能，同时利用多分支神经网络模型在不增加推理时间的情况下击败对抗攻击。通过分支正交损失函数，使多个解空间正交。此外，论文通过对比实验展示了该方法在CIFAR-10、CIFAR-100和SVHN数据集上优于其他现有方法的鲁棒性和准确性。而且，所提出的方法也优于使用大规模额外训练数据的方法。", "conclusion": "研究提出了一种基于原始数据集的多分支神经网络模型——分支正交对抗训练（BORT），以实现对抗鲁棒性。该方法在多个数据集上展示了超越现有最佳方法的鲁棒性和准确性，验证了方法的有效性和优越性，为多分支模型在鲁棒学习中的应用提供了新的方向。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10501", "html_url": "https://arxiv.org/abs/2411.10501", "title": "OnlyFlow: Optic Flow Based Motion Conditioning for Video Diffusion Models", "title_en": "OnlyFlow: Optical Flow based Motion Conditioning for Video Diffusion Models", "authors": "Mathis Koroglu,Hugo Caselles-Dupré,Guillaume Jeanneret Sanmiguel,Matthieu Cord", "background": "研究文本到视频生成任务，重点在于视频生成过程中的精确控制，如相机运动控制和视频编辑。大多数方法依赖于用户定义的控制，如二元蒙版或相机运动嵌入。研究人员提出了一种新颖的方法，利用从输入视频中提取的光流，以条件生成视频的运动。这种方法结合了文本提示和输入视频，使用户能够生成遵守输入视频运动和文本提示的视频。", "innovation": "提出了一种名为OnlyFlow的方法，利用输入视频中提取的光流来控制生成视频的运动。此方法采用光流估计模型对输入视频进行处理，然后将结果输入可训练的光流编码器，最后将输出特征图注入到文本到视频主干模型中。实验证明，OnlyFlow在多种任务中表现优异，优于现有方法，尤其是它并没有特别针对这些任务进行训练。", "conclusion": "OnlyFlow作为一个多功能、轻量且高效的文本到视频生成运动控制方法，展示了其在多种应用中的潜力。该方法和代码将开源发布在GitHub和HuggingFace平台上。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.06154", "html_url": "https://arxiv.org/abs/2409.06154", "title": "使用静态表情数据理解动态面部表情：Static for Dynamic", "title_en": "Static for Dynamic: Towards a Deeper Understanding of Dynamic Facial Expressions Using Static Expression Data", "authors": "Yin Chen,Jia Li,Yu Zhang,Zhenzhen Hu,Shiguang Shan,Meng Wang,Richang Hong", "background": "动态面部表情识别（DFER）通过分析表情随时间的变化来推断情绪，而静态面部表情识别（SFER）仅依赖单帧图像。尽管DFER提供了更丰富的信息并承诺了更高的识别能力，但当前的DFER方法往往表现不佳，主要原因是用于训练的样本数量较少。利用静态和动态表情之间的固有相关性，研究假设可以利用大量的SFER数据来改善DFER。然而，传统的多任务学习方法在本研究中产生了负迁移。", "innovation": "提出了一个统一的双模态学习框架——Static-for-Dynamic（S4D），该框架整合了SFER数据作为DFER的互补资源。S4D通过使用共享的Vision Transformer（ViT）编码器-解码器架构进行双模态自监督预训练，从而产生改进的时空表示。为了应对负迁移的问题，提出了一个创新的Mixture of Adapter Experts（MoAE）模块，该模块有助于特定任务知识的获取，并有效地从静态和动态表情数据中提取共享知识。", "conclusion": "S4D在FERV39K、MAFW和DFEW基准测试中取得了新的最佳性能，分别为53.65%、58.44%和76.68%的加权平均召回率，并且进行了系统的SFER与DFER任务的相关性分析，进一步阐明了利用SFER的潜在益处。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.21004", "html_url": "https://arxiv.org/abs/2410.21004", "title": "连续且可解释的形态学度量方法用于动态生物形状的鲁棒量化", "title_en": "A Continuous and Interpretable Morphometric for Robust Quantification of Dynamic Biological Shapes", "authors": "Roua Rouatbi,Juan-Esteban Suarez Cardona,Alba Villaronga-Luque,Jesse V. Veenvliet,Ivo F. Sbalzarini", "background": "本文介绍了用于生物医学成像中的形状量化的新方法——Push-Forward Signed Distance Morphometric（PF-SDM）。这种方法紧凑地编码了闭合形状的几何和拓扑属性，包括它们的骨架和对称性。这为形状比较和机器学习提供了鲁棒且可解释的特征。PF-SDM在数学上是平滑的，可以获取梯度和微分几何量。此外，它支持时间动态，并允许融合空间强度分布，如遗传标记，与形状动态相结合。", "innovation": "PF-SDM方法通过紧凑编码几何和拓扑属性，提供了一种连续且可解释的形态度量方法，用于动态生物形状的鲁棒量化。这种方法不仅在数学上平滑，能够获取梯度和微分几何量，还能够扩展到时间动态，并融合空间强度分布与形状动态。", "conclusion": "作者通过理论介绍、合成数据的基准测试以及在预测小鼠胃胚体轴形成中的应用展示了PF-SDM方法。这种方法在准确性和速度上均优于CNN基准方法。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.17345", "html_url": "https://arxiv.org/abs/2406.17345", "title": "NerfBaselines：新颖视图合成方法的一致和可重复评估", "title_en": "NerfBaselines: Consistent and Reproducible Evaluation of Novel View Synthesis Methods", "authors": "Jonas Kulhanek,Torsten Sattler", "background": "新颖视图合成作为一种重要的技术，在增强现实/虚拟现实（AR/VR）、游戏和机器人仿真等领域有着广泛应用。近年来，神经辐射场（NeRF）和三维高斯点积（3DGS）等方法的快速发展，使得追踪当前最先进技术变得困难，原因在于不同方法使用不同的评估标准，代码安装和使用的复杂性，以及方法在新颖3D场景下的表现不佳。我们的实验表明，各种方法的评估标准的小差异可能人为地提升了方法性能，提出质疑现有文献中定量比较的可靠性。为此，我们提出了NerfBaselines评估框架，该框架提供了一致的基准测试工具，确保了重现性和简化了各种方法的安装和使用。", "innovation": "我们提议NerfBaselines评估框架，提供了统一的基准测试工具，确保可重现性，并简化了各种方法的安装和使用。实验中，我们通过重现原始论文中的数字验证了我们的实现。为了提高易用性，我们发布了一个网络平台，该平台在标准基准上比较了常用方法。我们认为NerfBaselines对社区来说是一个有价值的贡献，因为它确保了定量结果的一致性，从而真正衡量了领域内进展的实质性进步。", "conclusion": "我们强烈相信NerfBaselines是一个有价值的贡献给社区，它可以确保定量结果的一致性，真正衡量了新颖视图合成领域中的进展。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.08325", "html_url": "https://arxiv.org/abs/2501.08325", "title": "GameFactory: 利用生成互动视频创建新游戏", "title_en": "GameFactory: Creating New Games with Generative Interactive Videos", "authors": "Jiwen Yu,Yiran Qin,Xintao Wang,Pengfei Wan,Di Zhang,Xihui Liu", "background": "生成视频有潜力通过自主创建新内容来革新游戏开发。为了实现这一目标，本文提出了GameFactory框架，专注于由动作控制的、场景通用的游戏视频生成。该框架首先通过GF-Minecraft数据集解决动作可控性问题，进而通过自回归生成支持无限长度的互动视频。重要的是，GameFactory还解决了动作控制的场景通用性问题，这是现有大多数方法所忽视的关键挑战。", "innovation": "提出了一个动作注释的游戏视频数据集GF-Minecraft，以及一个动作控制模块，使键盘和鼠标输入能够得到精确控制。进一步地，提出了一种多阶段训练策略，并引入了一个领域适配器，将开放域生成先验与小规模游戏数据集之间的领域差距进行弥补，从而实现场景通用的动作控制。", "conclusion": "实验结果表明，GameFactory能够有效生成开放域动作可控的游戏视频，这标志着基于人工智能的游戏生成迈出了重要一步。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.15389", "html_url": "https://arxiv.org/abs/2412.15389", "title": "基于自我监督的高效多染色肾小球分割", "title_en": "Resource Efficient Multi-stain Kidney Glomeruli Segmentation via Self-supervision", "authors": "Zeeshan Nisar,Friedrich Feuerhake,Thomas Lampert", "background": "在计算机视觉中，领域偏移条件下的语义分割仍是一个基本的挑战，尤其是在标注训练数据稀缺的情况下。这一挑战在组织病理学图像分析中尤为明显，在这种情况下，相同的组织结构需要根据不同成像条件（染色）的图像来进行分割，每种条件代表一个不同的视觉域。传统深度学习方法如UNet需要大量的标签，这既昂贵又耗时，特别是在处理多个领域（或染色）时。为减轻这一问题，提出了多种无监督领域适应方法，如UDAGAN，这些方法通过只需要一种源染色来减少对标签的需求。然而，获取源染色标签本身也是一个挑战。", "innovation": "本文展示了通过自我监督预训练——包括SimCLR、BYOL以及一种新的方法HR-CS-CO，即使在拥有95%更少的标签的情况下，这些分割方法（UNet和UDAGAN）的性能可以得到保留。实验结果显示，只使用5%的标签，UNet和UDAGAN的性能下降很小：平均至各染色，UNet下降5.9%，UDAGAN下降6.2%。此外，这些发现还被证明超越了其训练分布，适用于公共基准数据集。并且，这些实施和预训练模型可以在线公开获取。", "conclusion": "自我监督预训练方法，如SimCLR、BYOL和HR-CS-CO，可以在显著减少标签使用的情况下保留分割方法的性能，为多染色组织病理学图像分析提供了一种资源高效的解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04852", "html_url": "https://arxiv.org/abs/2503.04852", "title": "CAUSAL3D: 从视觉数据中进行因果学习的综合基准", "title_en": "CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data", "authors": "Disheng Liu,Yiran Qiao,Wuche Liu,Yiren Lu,Yunlai Zhou,Tuo Liang,Yu Yin,Jing Ma", "background": "真智能依赖于发现和利用隐藏的原因关系的能力。尽管在人工智能（AI）和计算机视觉（CV）领域取得了显著进展，但模型从复杂视觉数据中推断潜在因果关系的能力仍缺乏相应的基准评估。当前研究旨在填补这一空白，设计了一种新的综合性基准——Causal3D。Causal3D包含19个3D场景数据集，涵盖了多样的因果关系、视角和背景，能够评估不同复杂度场景中的因果推理能力。", "innovation": "提出了Causal3D，这是一种结合结构化数据（表格）和对应视觉表示（图片）的新颖且全面的基准，用于评估模型从复杂视觉数据中推断因果关系的能力。Causal3D在系统框架下设计，可以用于多种最先进的方法的评估，包括经典因果发现、因果表示学习和大语言/视觉语言模型（LLMs/VLMs）。实验结果强调在缺乏先验知识的情况下，随因果结构的复杂性增加，性能显著下降，揭示了即使在先进方法在复杂因果场景中的困难。", "conclusion": "Causal3D为提高CV中的因果推理和促进关键领域的可信赖AI提供了重要资源。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.05783", "html_url": "https://arxiv.org/abs/2501.05783", "title": "UV-Attack：基于动态NeRF的UV映射的物理世界对抗攻击方法用于人体检测", "title_en": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping", "authors": "Yanjie Li,Kaisheng Liang,Bin Xiao", "background": "近年来，针对使用补丁或静态3D模型纹理修改的人体检测器的对抗攻击成功率较低，因为人类的动作具有灵活性。模拟不同动作引起的3D形变一直是一个重大挑战。不过，神经辐射场（NeRF）的进展为动态人体建模提供了新的可能。", "innovation": "本文提出了UV-Attack，这是一种创新的方法，即使在广泛的和未见过的人体动作下也能实现高成功率。UV-Attack通过利用基于动态NeRF的UV映射来应对上述挑战。该方法生成跨体态和视角的人类图像，甚至通过从SMPL参数空间采样生成新的动作。同时，UV-Attack采用视图过度变换期望损失（EoPT）来提高未见过姿态和视角的规避成功率。", "conclusion": "实验结果表明，UV-Attack在动态视频设置下，对FastRCNN模型具有92.7%的攻击成功率，显著优于最先进的AdvCamou攻击算法的28.5%的成功率，并且在黑盒环境下，对YOLOv8检测器的成功率达到了49.5%。这项工作展示了动态NeRF基UV映射在创建更有效的对抗攻击方面的人体检测器的潜在影响，解决了建模人体运动和纹理修改的关键挑战。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.20392", "html_url": "https://arxiv.org/abs/2412.20392", "title": "抵御多模态后门模型的排斥视觉提示调优方法", "title_en": "Defending Multimodal Backdoored Models by Repulsive Visual Prompt Tuning", "authors": "Zhifang Zhang,Shuo He,Haobo Wang,Bingquan Shen,Lei Feng", "background": "多模态对比学习模型（如CLIP）可以从大规模图文数据集中学到高质量的表示，然而它们对后门攻击的高易感性引发了重大的安全性问题。这些模型倾向于编码超出数据集内预测模式的特征，这削弱了它们对输入扰动的视觉特征抵抗力。因此，这些编码的特征容易被后门触发器重塑。为了解决这一挑战，本文提出了一种新颖的防御方法——排斥视觉提示调优（RVPT），该方法通过特定设计的特征排斥损失使用深度视觉提示调优来对抗性地排斥深层层中的编码特征，同时优化标准交叉熵损失，确保仅编码下游任务中的预测性特征，从而增强CLIP的视觉特征抵抗力，减轻其对后门攻击的易感性。", "innovation": "提出了一种新的防御方法——排斥视觉提示调优（RVPT），它通过特定设计的特征排斥损失使用深度视觉提示调优对抗性地排斥深层层中的编码特征，同时优化标准交叉熵损失，仅编码下游任务中的预测性特征，增强CLIP的视觉特征抵抗力，减轻其对后门攻击的易感性。", "conclusion": "实验证明，RVPT 只调优了 CLIP 中 0.27% 的参数，但显著优于最先进的防御方法，将攻击成功率从 89.70% 降至 2.76%，对 ImageNet 的最先进的多模态攻击具有有效的防御能力，其防御能力在多个数据集上得到了良好泛化。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.09499", "html_url": "https://arxiv.org/abs/2503.09499", "title": "MindGYM：思考为中心微调中问题合成的关键因素？", "title_en": "MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?", "authors": "Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen", "background": "大型基础模型在获得可转移、结构化的思考能力方面面临挑战，特别是在使用严格模板或众包标注指令数据集监督时更是如此。以往的方法主要关注于数据生成的方式，但这种模式使得模型难以自我生成、符合认知指导的数据，从而影响其思考能力的提升。因此，需要引入一种以思考为中心的数据合成范式，使模型能够通过自我生成的数据进行进化并培养出更高级的思考能力。", "innovation": "提出了MindGYM，这是一个结构化且可扩展的问题合成框架，包括：（1）认知思考过程注入，将高层次的推理目标融入模型的合成行为中；（2）种子单跳问题合成，从多元语义类型中生成原子问题，以鼓励更广泛的思考；（3）具有挑战性的多跳QA合成，基于QA种子构建更复杂的多跳问题以进行更深层次的推理。研究表明，通过该方法生成的合成数据在平均质量和质量变异方面分别比基线高出16.7%和降低了67.91%，强调高质量且自包含的数据对于有效的、以思考为导向的微调至关重要。此外，MindGYM在六个推理基准上表现优异，仅用400个数据样本就在MathVision上实现了16%的性能提升，并促进了不同模型规模和架构的普遍改进。MindGYM加强了自挑战机制在完善大型模型能力方面的可行性，同时降低了对人工干预和资源需求的要求。", "conclusion": "MindGYM促进了以思考为中心的基础模型的自我进化能力的研究，通过内在推理能力驱动的数据为中心的研究促进其发展。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.23722", "html_url": "https://arxiv.org/abs/2503.23722", "title": "LATex：利用基于属性的文本知识进行空地人员再识别", "title_en": "LATex: Leveraging Attribute-based Text Knowledge for Aerial-Ground Person Re-Identification", "authors": "Pingping Zhang,Xiang Hu,Yuhao Wang,Huchuan Lu", "background": "AG-ReID 是智能交通系统中的重要任务，目标是在不同视角的异质摄像头中检索特定人员。现有方法主要采用基于深度学习的模型，集中于提取视角不变特征。但它们通常忽略了人员属性中的语义信息。此外，现有的训练策略往往依赖大规模模型的全面微调，这显著增加了训练成本。这些问题促使我们提出了一个新的框架LATex，采用提示调优策略利用基于属性的文本知识。", "innovation": "该研究提出了一个名为LATex的新框架，通过Prompt-tuning策略结合基于属性的文本知识来提升AG-ReID的效果。具体而言，通过CLIP模型首先提出一种属性感知图像编码器（AIE），从输入图像中提取全局语义特征和属性感知特征。然后，利用这些特征，提出了提示属性分类组（PACG）来预测人员属性并获取属性表示。最后，设计了一个耦合提示模板（CPT）将属性表示和视图信息转换成结构化句子，这些句子通过CLIP的文本编码器生成更具区分性的特征。因此，该框架能够充分利用基于属性的文本知识来提升AG-ReID性能。", "conclusion": "在三个AG-ReID基准上的大量实验表明，所提出的方法是有效的。源代码可在以下链接获取。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11094", "html_url": "https://arxiv.org/abs/2503.11094", "title": "Open3D-VQA: 一个用于开放空间多模态大语言模型全面空间推理能力评估的基准", "title_en": "Open3D-VQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space", "authors": "Weichen Zhang,Zile Zhou,Xin Zeng,Xuchen Liu,Jianjie Fang,Chen Gao,Yong Li,Jinqiang Cui,Xinlei Chen,Xiao-Ping Zhang", "background": "多模态大语言模型（MLLMs）的空间推理是一项基本能力，但它们在开放空域环境中的表现尚未得到充分研究。现有的研究主要集中在相对空间关系的处理上，三维（3D）模型并不优于二维（2D）模型，且在实际环境中的表现未得到大幅提升。因此，需要一个新的基准来评估和发展MLLMs在从空中视角理解复杂空间关系的能力。该基准包含了73,000个问答对，覆盖了7项一般的空间推理任务，支持视觉和点云两种输入模式。", "innovation": "研究首次提出了Open3D-VQA基准，用于评估MLLMs从空中视角进行空间推理的能力。它涵盖了多项空间推理任务，使用真实和模拟场景自动生成问题，并支持多种问答格式。该基准揭示了实际环境中的真实距离回答问题的难度。与众不同的是，它还考察了3D LLMs相对于2D LLMs的表现差异，并研究了通过仅在模拟数据集上微调来提升模型在实际环境中空间推理能力的有效性。此外，研究者公开了基准数据集、数据生成管道和评估工具，以促进更多相关研究的发展。", "conclusion": "研究表明，MLLMs普遍擅长回答关于相对空间关系的问题，但不擅长回答涉及绝对距离的问题；3D LLMs在空间推理方面并未展现出显著优势；仅在模拟数据集上的微调能够显著提升模型在实际环境中的空间推理表现。未来的研究可以在更复杂的开放空间环境中进一步测试这些大型语言模型的能力。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.13160", "html_url": "https://arxiv.org/abs/2503.13160", "title": "Language-guided Open-world Video Anomaly Detection under Weak Supervision", "title_en": "Language-guided Open-world Video Anomaly Detection under Weak Supervision", "authors": "Zihao Liu,Xiaoyu Wu,Jianqin Wu,Xuxu Wang,Linlin Yang", "background": "视频异常检测（VAD）旨在检测与预期行为不同的异常事件。在开放世界场景中，随着需求的变化，预期事件可能也会变化。例如，在流感爆发期间，未戴口罩被视为异常，而在其他情况下则为正常情况。现有方法假设异常定义是不变的，因此不适合开放世界。针对此问题，该研究提出了一个适应开放世界的VAD范式，允许在推理时通过用户提供的自然语言进行引导检测。这需要建立从视频和文本定义到异常评分的稳健映射。为了满足这一需求，作者提出了LaGoVAD（语言引导的开放世界视频异常检测器）模型，该模型在弱监督下动态适应异常定义，并通过动态视频合成和对比学习结合负样本挖掘来增强特征的鲁棒性。", "innovation": "提出了一个适应开放世界的VAD范式，允许在推理时通过用户提供的自然语言进行引导检测。此范式要求建立从视频和文本定义到异常评分的稳健映射，并提出了一种基于LaGoVAD的模型，该模型在弱监督下动态适应异常定义，通过动态视频合成增加异常持续时间的多样性，并通过对比学习增强特征鲁棒性。", "conclusion": "实验结果证明，LaGoVAD在七个数据集上的零样本实验中实现了SOTA性能。作者还收集了PreVAD（预训练视频异常数据集），这是迄今为止最大和最多样化的视频异常数据集，包含35,279条带有多层次类别标签和描述（明确定义异常）的标注视频。代码和数据集将在指定的网址发布。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.09549", "html_url": "https://arxiv.org/abs/2504.09549", "title": "SD-ReID: 视点感知稳定的扩散模型用于空地行人再识别", "title_en": "SD-ReID: View-aware Stable Diffusion for Aerial-Ground Person Re-Identification", "authors": "Yuhao Wang,Xiang Hu,Lixin Wang,Pingping Zhang,Huchuan Lu", "background": "AG-ReID旨在通过不同视角的摄像头识别特定行人。以往研究主要集中在设计具备良好鉴别能力的模型，以保持身份一致性，尽管视角有极大变化。这些方法的核心思想很自然，但构建视点鲁棒模型非常具有挑战性。此外，它们未重视视点特定特征对提升模型表示行人能力的贡献。为了应对这些问题，我们提出了一种新颖的生成框架SD-ReID，利用生成模型模仿不同视角的特征分布，同时提取稳健的身份表示。我们首先训练一个基于ViT的模型提取与可控条件（如身份和视点条件）有关的人表示，然后通过这些可控条件增强人表示。最后，我们引入了视点精炼解码器（VRD）来弥合实例级别和全局特征之间的差距。实验表明，该方法在五个AG-ReID基准（CARGO, AG-ReIDv1, AG-ReIDv2, LAGPeR 和 G2APS-ReID）上表现有效。提供的源代码将会开源。", "innovation": "提出了一种新颖的生成框架SD-ReID，利用生成模型模仿不同视角的特征分布，同时提取稳健的身份表示。具体而言，该方法首先使用基于ViT的模型提取包含可控条件（如身份和视点条件）的人表示，然后通过这些可控条件提升人表示。此外，该框架还引入了视点精炼解码器（VRD）来弥合实例级别和全局特征之间的差距。这种方法有效地解决了视点鲁棒性和视点特定特征利用的问题，从而提升了行人再识别的准确性和鲁棒性。", "conclusion": "在五个AG-ReID基准上的广泛实验表明，SD-ReID方法在行人再识别上具有显著的效果。此外，提供的源代码将促进未来的研究工作。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16239", "html_url": "https://arxiv.org/abs/2505.16239", "title": "DOVE: Efficient One-Step Diffusion Model for Real-World Video Super-Resolution", "title_en": "DOVE: Efficient One-Step Diffusion Model for Real-World Video Super-Resolution", "authors": "Zheng Chen,Zichen Zou,Kewei Zhang,Xiongfei Su,Xin Yuan,Yong Guo,Yulun Zhang", "background": "扩散模型在实际视频超分辨率（VSR）任务中表现出了有前途的效果，但由于其需要大量采样步骤，导致推理速度极慢。单一步骤的采样加速技术提供了一种可能的解决方案，但是将这一技术应用于VSR仍然是有挑战性的，因为这需要大量的训练开销和严格的保真度要求。", "innovation": "提出了DOVE，一种通过调整预训练的视频扩散模型（即CogVideoX）来实现高效的一步扩散模型，同时还引入了潜像素训练策略来有效训练DOVE，并设计了视频处理流水线来构建高质量的视频超分辨率数据集HQ-VSR，该数据集进一步提高了DOVE的恢复能力。", "conclusion": "大量的实验表明，DOVE 在性能方面与多步骤扩散模型相当或优越，同时具有出色的推理效率，比现有的方法如MGLD-VSR快多达28倍。代码已开源。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12191", "html_url": "https://arxiv.org/abs/2505.12191", "title": "废除去噪器：自监督学习中从数据课程中出现的噪声鲁棒性", "title_en": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum", "authors": "Wenquan Lu,Jiaqi Zhang,Hugues Van Assel,Randall Balestriero", "background": "自监督学习（SSL）已经成为从未标记数据中提取丰富表示的强大解决方案。然而，SSL研究主要集中在干净、经过整理和高质量的数据集上。因此，尽管这对于诸如天体物理学、医学成像、地质学或金融之类的应用至关重要，但将SSL应用于嘈杂数据依然是一个难题。", "innovation": "本文提出了一种完全自监督的框架，可以在不依赖于推理或下游微调的去噪器的情况下实现噪声鲁棒的表示学习。该方法首先在嘈杂数据上训练一个SSL去噪器，然后使用它构建一个去噪到嘈杂数据的课程（即，首先训练去噪样，然后训练嘈杂样）来预训练一个SSL主干（例如，DINOv2），并结合一种教师引导的正则化，将噪声嵌入与它们的去噪对应物对齐。此外，在预训练后，可以丢弃去噪器以简化部署。在高度嘈杂的ImageNet-1k（$ \\\backslash \\\text{sigma} = 255 $，SNR = 0.72 dB）数据上，使用ViT-B预训练时，本方法比DINOv2提高了4.8%的线性探测准确率，证明了去噪器在噪声感知预训练中可以产生噪声鲁棒性", "conclusion": "本文提出的方法表明，无需去噪器，在噪声感知预训练中可以直接产生噪声鲁棒性，从而简化了部署。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.00254", "html_url": "https://arxiv.org/abs/2505.00254", "title": "以视频语言模型赋能自主视频分析系统", "title_en": "Empowering Agentic Video Analytics Systems with Video Language Models", "authors": "Yuxuan Yan,Shiqi Jiang,Ting Cao,Yifan Yang,Qianqian Yang,Yuanchao Shu,Yuqing Yang,Lili Qiu", "background": "AI驱动的视频分析在不同领域变得越来越重要，但现有系统往往局限于特定预定义任务，难以应对开放环境下的多样性分析需求。最近，视觉语言模型（VLMs）作为一种变革性技术，具有使视频理解、推理和分析走向开放性的重要潜力。然而，它们有限的上下文窗口使得处理超长视频内容变得具有挑战性，而这类内容在实际应用中很常见。为此，我们提出了一个名为AVA的系统，这是一个利用VLM支持的开放自主视频分析系统。AVA集成了两个创新功能：一是实现实时构建事件知识图谱（EKGs）以高效索引长或连续视频流，二是利用知识图谱进行自主检索生成以应对复杂多样的查询。", "innovation": "AVA提出了两个关键创新：(1) 实现实时构建事件知识图谱以高效索引长或连续视频流；(2) 利用知识图谱进行自主检索生成以应对复杂多样的查询。通过在公共基准LVBench和VideoMME-Long上的全面评估，证明了AVA达到了最先进的性能。此外，为评估超长和开放世界的视频分析，我们还引入了一个名为AVA-100的新基准，该基准包含8个每段超过10小时的视频，以及120个手动标注的多样性和复杂的问答对。", "conclusion": "AVA在超长和开放世界视频分析基准AVAA-100上表现出顶级性能，准确率达到75.8%。此外，源代码已发布，新的基准数据集也供访问。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18584", "html_url": "https://arxiv.org/abs/2505.18584", "title": "通过调节大规模激活释放扩散变换器在视觉对应中的潜力", "title_en": "Unleashing Diffusion Transformers for Visual Correspondence by Modulating Massive Activations", "authors": "Chaofan Gan,Yuanpeng Tu,Xi Chen,Tieyuan Chen,Yuxi Li,Mehrtash Harandi,Weiyao Lin", "background": "预训练的稳定扩散模型（SD）已经在视觉对应方面取得了显著的进步。本文探讨了扩散变换器（DiTs）在密集对应方面的准确性能。不同于SD，DiTs表现出一个关键现象：只有少数特征激活显示出远大于其他激活的值，这被称为“大规模激活”，导致了信息不足的表示和DiTs整体性能的显著下降。", "innovation": "作者发现大规模激活集中在非常少数的固定维度上，即使在所有图像块标记中也是如此，几乎没有局部信息。他们通过追踪这些维度集中的大规模激活，发现可以利用零初始化自适应层归一化（AdaLN-zero）有效定位。基于这些发现，提出了扩散变换器特征（DiTF），一个无需训练的框架，用于从DiTs中提取语义辨别特征。DiTF使用AdaLN进行信道间调节，以适应性地定位和标准化大规模激活。此外，还开发了一种信道丢弃策略，以进一步消除大规模激活的负面影响。", "conclusion": "实验结果显示，我们的DiTF在视觉对应任务中优于DINO和基于SD的模型，并在不同视觉对应任务中建立了一个新的性能基准（例如，在Spair-71k上提高了9.4%，在AP-10K-C.S.上提高了4.4%）。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18766", "html_url": "https://arxiv.org/abs/2505.18766", "title": "StyleGuard: 通过样式扰动防止基于文本到图像模型的风格模仿攻击", "title_en": "StyleGuard: Preventing Text-to-Image-Model-based Style Mimicry Attacks by Style Perturbations", "authors": "Yanjie Li,Wenxuan Zhang,Xinqi Lyu,Yihao Liu,Bin Xiao", "background": "最近，通过如DreamBooth和Textual Inversion等方法，内容生成模型如文本到图像扩散模型被广泛用于风格模仿和个性化定制。然而，这引发了关于知识产权保护和生成误导性内容的担忧。为了应对这些问题，最近的研究如Glaze和Anti-DreamBooth提出了使用对抗噪声进行保护，但基于净化的方法如DiffPure和Noise Upscaling已经成功地攻击这些最新防御，展示了这些方法的漏洞。此外，现有方法在不同模型间的迁移性有限，效果不如理想。", "innovation": "我们提出了一种新颖的反模仿方法，StyleGuard。这种方法提出了一种新的样式损失，通过优化潜在空间中的样式相关特征使其偏离原始图像，来改善无模型依赖的迁移性。通过在训练中集成多种净化器和放大器设计了一种新的上采样损失，进一步增强了扰动的转移能力。", "conclusion": "StyleGuard在WikiArt和CelebA数据集上的广泛实验表明，它在对抗各种转换和净化的鲁棒性方面优于现有方法，有效地对抗了多种模型中的风格模仿。此外，StyleGuard在包括DreamBooth和Textual Inversion在内的不同风格模仿方法上都有效。代码可以在github上获取。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21996", "html_url": "https://arxiv.org/abs/2505.21996", "title": "交互视频生成中的世界模型学习", "title_en": "Learning World Models for Interactive Video Generation", "authors": "Taiye Chen,Xun Hu,Zihan Ding,Chi Jin", "background": "有效的未来规划需要具备交互性和维永时空一致性的基础世界模型。然而，目前用于长视频生成的模型由于累积误差和记忆机制不足的问题，其固有的世界建模能力有限。", "innovation": "本文通过引入额外的动作条件和自回归框架增强图像到视频模型的交互能力，揭示了自回归视频生成固有地无法有效减少累积误差，而记忆机制不足会导致世界模型的不连贯性。本文提出了带有显式全局状态条件的视频检索增强生成（VRAG），显著减少了长期累积误差，并提高了世界模型的时空一致性。", "conclusion": "相比之下，简单自回归生成和检索增强生成因当前视频模型的有限上下文学习能力而效果较差。本文揭示了视频世界模型的基本挑战，并为提升具有内部世界建模能力的视频生成模型建立了全面基准。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23158", "html_url": "https://arxiv.org/abs/2505.23158", "title": "LODGÉ: 基于高效渲染的大规模3D Gaussian分散点层级细节方法", "title_en": "LODGE: Level-of-Detail Large-Scale Gaussian Splatting with Efficient Rendering", "authors": "Jonas Kulhanek,Marie-Julie Rakotosaona,Fabian Manhardt,Christina Tsalicoglou,Michael Niemeyer,Torsten Sattler,Songyou Peng,Federico Tombari", "background": "本文介绍了针对受限内存设备实现大规模场景实时渲染的新型3D Gaussian Splatting的层级细节（LOD）方法。传统方法由于内存限制和计算复杂度高，难以满足大规模场景实时渲染的需求。本文提出的方法通过引入层级LOD表示，并结合相机距离动态选择最优的高斯点集合，大幅降低了渲染时间和GPU内存使用。", "innovation": "本文创新地提出了一种深度感知的3D平滑过滤方法，并基于重要性修剪和Fine-tuning来保持视觉保真度。同时，通过对场景进行空间分割并在渲染时仅加载相关高斯点，并采用不透明混合机制来避免块边界引入的视觉伪影，进一步减少了内存开销。此方法在户外（Hierarchical 3DGS）和室内（Zip-NeRF）数据集上均达到了领先的性能，实现了高质量的渲染效果，并显著降低了延迟和内存需求。", "conclusion": "本文提出的方法通过优化LOD表示和高斯点处理策略，显著提高了大规模场景的实时渲染性能，并在硬件资源有限的情况下实现了高质量的视觉效果。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21497", "html_url": "https://arxiv.org/abs/2505.21497", "title": "Paper2Poster：从科学论文实现多模态海报自动化", "title_en": "Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers", "authors": "Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr", "background": "学术海报生成是一项关键但具有挑战性的科学交流任务，需要将长文复杂的文档压缩成一页视觉连贯的页面。当前缺乏专门针对海报生成的标准评估工具和指标集，影响了海报的质量和效果。这个问题限制了自动化生成海报技术的发展，尤其是在保持视觉质量和文本连贯性方面。研究人员试图设计一种结合视觉和语言的技术来生成专门的海报，但现有方法在视觉布局、文本流畅性和整体审美评估方面存在不足。此外，如何有效传达论文核心内容也是一个挑战，现有的自动化模型在这方面表现不佳。因此，迫切需要一个新的基准和评估指标集，以及一个全新的多模态自动化流程来提高生成海报的效率和质量。", "innovation": "该研究提出了首个用于海报生成的标准基准和评估指标集，包括视觉质量、文本连贯性、整体评估以及PaperQuiz。基于此基准，研究人员开发了名为PosterAgent的多代理管道，该管道由Parser、Planner和Painter-Commenter三个模块组成，用于结构化处理文档、布局设计和视觉效果的进一步优化。通过这种方法，该研究展示了一种全新的多模态自动化海报生成流程。此外，该研究还发现现有的大语言模型在视觉效果上虽然引人注目，但在文本准确性和传达论文核心内容方面存在不足，这证实了视觉布局在海报设计中的重要性。研究还证明了其开源模型的优越性，特别是在成本节省和多个评估指标上的表现优于现有模型。", "conclusion": "该研究提出的新方法和全面的评估基准显著提升了海报生成的质量和效率，特别表现在视觉质量和整体评估指标上。该研究为未来全自动化海报生成模型的发展指明了明确的方向，其开源代码和数据集能够促进社区的合作与改进。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.00871", "html_url": "https://arxiv.org/abs/2506.00871", "title": "在上下文预测任意行人轨迹", "title_en": "Towards Predicting Any Human Trajectory In Context", "authors": "Ryo Fujii,Hideo Saito,Ryo Hachiuma", "background": "准确预测未来行人的轨迹对于自动驾驶系统至关重要，但这项任务仍然具有挑战性，因为需要在不同的环境和领域中具备适应性。通常的方法是收集特定场景的数据，并通过反向传播进行微调。然而，每次新场景都需要微调这一过程在边缘设备上的部署常常是不切实际的。为了应对这一挑战，我们介绍了一个名为TrajICL的基于上下文学习(In-Context Learning，ICL)的行人轨迹预测框架，该框架能够在推理时适应场景而无需微调场景特定的数据，也不需要更新权重。", "innovation": "我们提出了一种时空相似性基于的示例选择方法（STES），通过识别相同场景中相应位置的相似运动模式来选择相关的先前观察轨迹的示例。进一步改进了STES方法，提出了预测引导的示例选择（PG-ES），该方法同时基于过去的轨迹和预测的未来轨迹进行示例选择，而不是仅依赖于过去的轨迹，以允许模型在选择示例时考虑长期动态。我们没有依赖于有限场景多样性的小型真实世界数据集，而是使用大规模的合成数据集进行训练，以通过利用上下文示例增强预测能力。实验结果表明，TrajICL在多种公共基准测试中均优于微调方法，实现了出色的适应性，包括在域内和跨域场景中。", "conclusion": "TrajICL框架在其中文解释中表明，它成功地实现了无需微调即可在不同场景中快速适应行人轨迹预测，通过利用合成数据增强了模型的预测能力和泛化能力，从而在多个公开基准测试中达到或超越了最先进的性能。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05696", "html_url": "https://arxiv.org/abs/2506.05696", "title": " MoralCLIP: 依据道德根基理论的视觉-语言表示对比对齐", "title_en": "MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory", "authors": "Ana Carolina Condez,Diogo Tavares,João Magalhães", "background": "近期视觉-语言模型在不同模态间实现了丰富的语义理解，但这些模型缺乏对内容道德维度的理解和解释能力，这是人类认知的重要方面。因此，本文围绕这一gap展开研究，希望通过引入MoralCLIP来增强视觉-语言模型的道德判断能力。MoralCLIP通过将视觉和文本的道德线索整合到统一的嵌入空间中，实现了跨模态的道德对齐。这种方法以多标签数据集Social-Moral Image Database为基础，识别视觉内容中的共同存在的道德基础。", "innovation": "MoralCLIP通过引入基于Moral Foundations Theory的显式道德监督，将视觉和文本道德线索整合到统一的嵌入空间，实现了跨模态的道德对齐，从而提升了单一模态和多模态对道德内容的理解。此外，该方法还设计了一种道德数据增强策略，将标注数据扩展到了15,000张图像-文本对，并且这些对都标记有与Moral Foundations Theory对齐的维度标签。", "conclusion": "我们的研究结果表明，显式道德监督能够提升单一模态和多模态对道德内容的理解，建立了朝着道德意识型人工智能系统迈进的基础，这种系统能够识别并且与人类的道德价值观对齐。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06220", "html_url": "https://arxiv.org/abs/2506.06220", "title": "GenIR: 生成视觉反馈促进心智图像检索", "title_en": "GenIR: Generative Visual Feedback for Mental Image Retrieval", "authors": "Diji Yang,Minghao Liu,Chung-Hsiang Lo,Yi Zhang,James Davis", "background": "视觉语言模型（VLMs）在文本到图像检索基准测试中表现出色。然而，将这些成功应用到实际生活中仍面临挑战。在实际操作中，人类的搜索行为往往不是一次性的，而是多轮次的过程，受到心中线索的指引。即从模糊的记忆到具体的图像想象。因此，研究者们提出了心智图像检索（Mental Image Retrieval, MIR）任务，旨在通过多轮次的图像搜索引擎交互，让用户逐步精确检索出心中想象的图像。现有的交互方法依赖于间接或抽象的口头反馈，这种反馈对于用户调整查询往往不够清晰、准确或有效。", "innovation": "本文提出了一种生成式多轮检索范式——GenIR，利用基于扩散的图像生成技术，显式地将AI系统在每一轮的了解转化为具体的视觉反馈。这种合成的视觉表示可提供清晰且可解释的反馈，帮助用户直观且有效地调整查询。同时，本文还提供了完整自动化生成高质量多轮MIR数据集的方法。实验结果表明，GenIR在MIR场景中显著优于现有交互式方法。", "conclusion": "这项工作建立了一个新的任务以及一套有效生成检索方法，提供了未来在这个方向研究的基础。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02393", "html_url": "https://arxiv.org/abs/2506.02393", "title": "RRCANet: Reusable-Convolution Attention Network for Infrared Small Target Detection", "title_en": "RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection", "authors": "Yongxian Liu,Boyang Li,Ting Liu,Zaiping Lin,Wei An", "background": "红外小目标检测因其独特的特点（如尺寸小、亮度低、形状不定和多变）而具有挑战性。最近发表的基于CNN的方法通过大量的特征提取和融合模块取得了令人满意的效果，但往往不够高效和有效。因此，提出了反复使用的卷积注意力网络(RRCA-Net)来实现高效的红外小目标检测。RRCA-Net利用卷积重复块(RuCB)以递归方式嵌入而不增加额外参数，通过RuCB的反复迭代能够保持和进一步精炼深层的小目标高级信息。此外，还提出了一种双交互注意力聚合模块(DIAAM)，以促进精炼信息的相互增强和融合，使得RRCA-Net能够同时实现高级特征精炼，并增强相邻层之间的上下文信息相关性。为了实现稳定的收敛，设计了由物理和数学约束整合而成的目标特性启发式损失函数(DpT-k loss)。实验结果表明，RRCA-Net不仅能够达到当前最佳方法相当的性能，而且参数较少，还作为plug and play模块引入了一致性的性能提升。", "innovation": "RRCA-Net结合了递归循环和卷积重用机制，在不增加额外参数的情况下实现了高效的红外小目标检测。通过RuCB的递归迭代，保持和进一步精炼深层的小目标高级信息。此外，通过DIAAM模块促进了相邻层间精炼信息的融合，同时通过DpT-k loss函数实现了稳定的收敛。这些设计使RRCA-Net在小目标检测上表现突出，且具有较少的参数量和可与其他方法结合使用的特点。", "conclusion": "实验结果在NUAA-SIRST、IRSTD-1k、DenseSIRST三个基准数据集上证明，RRCA-Net在保持较小参数量的同时，可达到与当前最佳方法相当的性能，并作为plug and play模块引入对其他流行方法的持续性能提升。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21046", "html_url": "https://arxiv.org/abs/2506.21046", "title": "提升自监督视觉变换器特征生成对抗转移性能", "title_en": "Boosting Generative Adversarial Transferability with Self-supervised Vision Transformer Features", "authors": "Shangbo Wu,Yu-an Tan,Ruinan Ma,Wencong Ma,Dehua Zhu,Yuanzhang Li", "background": "深度神经网络（DNNs）的能力源于从提供的数据中提取和解释特征。通过利用DNNs的中间特征而非依赖于硬标签，本研究创造了一种泛化效果更好的对抗扰动，从而增强了黑盒转移性。这些特征在先前的工作中通常是通过有监督学习获得的。受自我监督学习与Transformer架构之间卓越协同效应的启发，本研究探讨了是否可以通过利用自监督Vision Transformer（ViT）表示来提高对抗转移性。", "innovation": "提出了dSVA--一种生成式双自监督ViT特征攻击，该攻击利用对比学习（CL）中的全局结构特征和掩码图像建模（MIM）中的局部纹理特征。设计了新的生成式训练框架，结合生成器创建黑盒对抗样本，并利用自监督ViTs的联合特征和注意力机制进行训练。研究发现，CL和MIM使ViTs能够关注不同的特征趋势，当这些趋势被同时利用时，具有很强的对抗泛化能力。通过扰乱自监督ViTs提取的双深度特征，实现了显著的黑盒转移性。", "conclusion": "本研究通过扰乱自监督ViTs提取的双深度特征，实现了对不同架构模型超过现有最佳水平的显著黑盒转移性能。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23292", "html_url": "https://arxiv.org/abs/2506.23292", "title": "DDL：多样化真实场景下用于深度伪造检测和定位的大规模数据集", "title_en": "DDL: A Large-Scale Datasets for Deepfake Detection and Localization in Diversified Real-World Scenarios", "authors": "Changtao Miao,Yi Zhang,Weize Gao,Zhiya Tan,Weiwei Feng,Man Luo,Jianshu Li,Ajian Liu,Yunfeng Diao,Qi Chu,Tao Gong,Zhe Li,Weibin Yao,Joey Tianyi Zhou", "background": "近年来，AIGC的进步加剧了恶意深度伪造内容的滥用，使开发可靠的深度伪造检测方法成为解决这一挑战的关键手段。尽管现有的深度伪造检测模型在检测指标上表现出色，但大部分方法仅提供简单的二元分类结果，缺乏可解释性。最近的研究试图通过提供空间操作蒙版或时间伪造片段来增强分类结果的可解释性，但由于伪造数据集的限制，这些方法的实际效果仍不尽如人意。大多数现有深度伪造数据集仅包含二元标签，并且伪造场景单一，伪造类型缺乏多样性，数据规模较小，不足以应对复杂的现实世界挑战。", "innovation": "我们构造了一个名为DDL的新数据集，包含超过1.4M+伪造样本和多达80种不同的伪造方法。DDL的设计包括四个主要创新点：（1）综合的深度伪造方法（涵盖7种不同的生成架构，共计80种方法）；（2）多样的操作模式（包含7种经典和3种新型伪造模式）；（3）多样的伪造场景和模态（包括3种场景和3种模态）；（4）细粒度的伪造注释（提供118W+精确的空间蒙版和23W+精确的时间片段）。这些改进不仅为复杂的现实世界伪造提供了一个更具挑战性的基准，还为构建下一代深度伪造检测、定位和可解释性方法提供了关键支持。", "conclusion": "通过这些改进，DDL不仅提供了一个更具挑战性的基准用于复杂现实世界的伪造检测，还为构建下一代检测、定位和解释方法提供了关键支持。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06078", "html_url": "https://arxiv.org/abs/2507.06078", "title": "ScoreAdv: 基于扩散模型的自然目标生成对抗样本", "title_en": "ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models", "authors": "Chihan Huang,Hao Tang", "background": "尽管深度学习在各种领域取得了成功，但它仍然容易受到对抗攻击的影响。虽然现有的许多对抗攻击方法效果显著，但它们通常依赖于基于$l_p$范数扰动约束，这与人类的感知能力不符。因此，研究人员将注意力转向生成自然且无限制的对抗样本(未受限对抗样本，UAEs)。基于GAN的方法存在固有限制，如不稳定性和模式塌陷导致图像质量不佳。另一方面，虽然扩散模型被用于生成UAEs，但它们仍然依赖于迭代PGD扰动注入，未能充分利用其去噪能力。", "innovation": "本文提出了一种基于扩散模型的生成UAEs的新方法，称为ScoreAdv。该方法结合了一种可解释的对抗指导机制，可以逐步将采样分布向对抗分布转移，同时利用可解释的显著图在生成样本中注入参考图像的视觉信息。重要的是，该方法可以生成无限多的自然对抗样本，并能攻击分类模型和检索模型。我们在ImageNet和CelebA数据集上进行了广泛的实验，在黑盒和白盒两种设置下验证了ScoreAdv在十种目标模型上的性能。结果表明，ScoreAdv在攻击成功率和图像质量方面达到了最先进的水平，同时保持了推理效率。此外，去噪和对抗扰动之间的动态平衡使ScoreAdv即使在防御措施下仍然保持鲁棒性。", "conclusion": "ScoreAdv通过结合扩散模型和可解释的对抗指导机制，有效生成UAEs，实现了在白盒和黑盒环境下针对多种模型的成功攻击，提高了攻击成功率和图像质量，且保持了高效性。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08772", "html_url": "https://arxiv.org/abs/2507.08772", "title": "从一到多：用于3D生成的上下文部分潜在变量", "title_en": "From One to More: Contextual Part Latents for 3D Generation", "authors": "Shaocong Dong,Lihe Ding,Xiao Chen,Yaokun Li,Yuxin Wang,Yucheng Wang,Qi Wang,Jaehyeok Kim,Chenjian Gao,Zhanpeng Huang,Zibin Wang,Tianfan Xue,Dan Xu", "background": "近年来，3D生成的进步从多视角2D渲染方法转向了利用地面真实数据几何先验的3D原生潜在扩散框架。尽管取得了进展，但仍然存在三个关键限制：（1）单潜在表示无法捕捉复杂的多部分几何形状，导致细节退化；（2）整体潜在编码忽略了构建组合设计至关重要的部分独立性和相互关系；（3）全局条件机制缺乏精细的控制能力。", "innovation": "受人类3D设计工作流程的启发，我们提出了一种名为CoPart的部分感知扩散框架，该框架将3D对象分解为上下文部分潜变量，以实现一致的多部分生成。该框架具有三大优势：（1）通过部分分解降低编码复杂性；（2）允许显式部分关系建模；（3）支持部分级条件。为了进一步微调预训练的扩散模型以进行联合部分潜变量去噪，我们开发了一种相互引导策略，以确保几何一致性并保留基础模型先验。为了实现大规模训练，我们通过自动化网格分割和人工验证注释构建了一个名为Partverse的新颖3D部分数据集，基于Objaverse。", "conclusion": "广泛的实验证明了CoPart在部分级别编辑、具有空前控制能力的成肢对象生成以及场景组成方面的优越能力。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10173", "html_url": "https://arxiv.org/abs/2506.10173", "title": "SPARKE: 通过RKE得分在扩散模型中实现可扩展的提示感知多样性与新颖性引导", "title_en": "SPARKE: Scalable Prompt-Aware Diversity and Novelty Guidance in Diffusion Models via RKE Score", "authors": "Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia", "background": "扩散模型已在高保真图像合成和提示引导生成建模中取得了显著成功。然而，确保提示引导扩散模型生成样本的多样性仍然是一项挑战，特别是在提示覆盖广泛的语义范围时，还需要以提示感知的方式在语义相似的提示下评估生成数据的多样性。近年来的方法通过引入多样性度量的指导来鼓励生成更丰富的图像。尽管基于熵的方法可以在提示感知方面增强多样性，但它们依赖的基于矩阵的熵分数在其能力上造成大量生成设置下的计算挑战。", "innovation": "本文提出了一种新的方法——可扩展的提示感知RKE核熵多样性指导（SPARKE），用于提示感知的多样性指导。SPARKE利用条件熵进行多样性指导，能够动态根据相似的提示进行多样性测量，实现提示感知的多样化控制。研究还重点关注条件潜在RKE分数指导的特殊情况，将通用熵度量的$O(n^3)$计算复杂度降低到$O(n)$。这一计算复杂度的降低使得在不同提示下的大量生成轮次中实现多样性引导采样成为可能。", "conclusion": "实验结果表明，本方法提高了生成数据的提示感知多样性而不会产生显著的计算负担。论文已在项目页面（this https URL）发布了代码。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.07981", "html_url": "https://arxiv.org/abs/2508.07981", "title": "Omni-Effects: 统一且空间可控的视觉特效生成", "title_en": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation", "authors": "Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu", "background": "视觉特效（VFX）对于现代电影制作至关重要。现有的视频生成模型可以提供经济高效的VFX生产解决方案，但这些方法受限于针对各个效果的LoRA训练，限制了多效果的并发生成。同时，将多种视觉特效集成到统一框架中面临着重大挑战，即效果变异带来的干扰及空间不可控性。", "innovation": "本文提出了Omni-Effects，这是一种统一的框架，能够生成提示引导的效果和空间可控的复合效果。核心创新包括两个方面：基于LoRA的专家体系（LoRA-MoE），它通过一群专家LoRA有效整合多种效果，减轻多任务间的干扰；空间感知提示（SAP），将空间掩码信息整合到文本标记中，实现精准的空间控制，并通过独立信息流（IIF）模块隔离个体效果的控制信号，避免不必要的混合。此外，通过一个新的数据采集管道，结合图像编辑和从第一帧到最后帧到视频合成，构建了全面的VFX数据集Omni-VFX，并引入了专门的VFX评估框架以验证模型性能。", "conclusion": "大量实验表明，Omni-Effects 实现了精确的空间控制和多样效果生成，允许用户指定所需效果的类别和位置。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05417", "html_url": "https://arxiv.org/abs/2508.05417", "title": "平滑 Slot 注意力迭代和递归", "title_en": "Smoothing Slot Attention Iterations and Recurrences", "authors": "Rongzhen Zhao,Wenyan Yang,Juho Kannala,Joni Pajarinen", "background": "Slot Attention (SA)及其变体是物体中心式学习（OCL）的核心。图像中的物体可以通过迭代地细化冷启动查询向量，将其聚合为各自的槽向量；视频的情况下，这种聚合操作在帧与帧之间是递归共享的，第一帧的查询是冷启动的，而不只是根据前一帧的槽数组进行过渡。然而，冷启动查询缺乏样本特定的线索，这妨碍了对图像或视频第一帧的精确聚合；同时，对于非第一帧，查询已经是样本特定的，所需的变换与第一帧的聚合不同。这篇文章首次解决了这些挑战。", "innovation": "(1) 为了平滑图像或视频第一帧的 SA 迭代，采用一个小模块对输入特征丰富的信息进行预热，将冷启动查询预先加热；(2) 为了在所有视频帧之间平滑 SA 递归，对第一帧和非第一帧的变换进行区分，分别使用完整的迭代和单次迭代。实验结果证明了该方法的有效性，并进一步分析阐明了方法如何平滑 SA 迭代和递归。", "conclusion": "对物体发现、识别以及下游基准的综合实验验证了该方法的有效性，进一步的分析从直观上阐明了平滑 SA 迭代和递归的效果。源代码、模型检查点和训练日志可以在此公开访问。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.01345", "html_url": "https://arxiv.org/abs/2508.01345", "title": "从随机槽-特征对预测视频槽注意查询", "title_en": "Predicting Video Slot Attention Queries from Random Slot-Feature Pairs", "authors": "Rongzhen Zhao,Jian Li,Juho Kannala,Joni Pajarinen", "background": "无监督视频对象中心学习（OCL）具有潜力，因为它能够实现我们人类可以实现的对象级场景表示和动态建模。主要的视频OCL方法采用递归架构：聚合器将当前视频帧聚合为带某些查询的对象特征（称为槽）；转换器将当前的槽转换为查询，以便用于下一帧。尽管这是一种有效的架构，但现有的所有实现都忽略了下一帧特征（最有助于查询预测的信息来源）的整合，并且无法学习转换动态（对于查询预测至关重要）的知识。因此，这些方法在处理场景表示、对象发现等任务时表现出一定的局限性，尤其是在下游任务如动态建模中效果不佳.", "innovation": "本文提出了一个名为RandSF.Q的新方法：（t1）设计了一种新的转换器，以整合槽和特征，为查询预测提供更多信息；（t2）通过从可用的递归中随机采样槽-特征对进行训练，使其学会转化动态。实验表明，与现有视频OCL方法相比，该方法显著提高了场景表示性能，例如在对象发现任务上提高了10个百分点，并在下游任务如动态建模上也表现出优势。核心源代码、模型检查点和训练日志已公开在给定的网址上.", "conclusion": "我们的方法在场景表示任务上显著超越了现有的视频OCL方法，尤其是在对象发现任务上得分新高，这不仅提升了场景表示的性能，还为动态建模等下游任务带来了好处。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10566", "html_url": "https://arxiv.org/abs/2508.10566", "title": "HM-Talker: 混合运动建模实现高质量谈话头部合成", "title_en": "HM-Talker: Hybrid Motion Modeling for High-Fidelity Talking Head Synthesis", "authors": "Shiyu Liu,Kui Jiang,Xianming Liu,Hongxun Yao,Xiaocheng Feng", "background": "当前的音频驱动头像视频生成方法经常会产生含有运动模糊和唇部抖动的视频，主要原因是这些方法依赖于对音频-面部运动关联的隐式建模，缺乏明确的发音先验（即与说话相关的面部运动的解剖学指导）。", "innovation": "本文提出HM-Talker，这是一种新型框架，用于生成高质量、时间上一致的谈话头部。HM-Talker采用混合运动表示，结合隐式和显式运动提示。显式提示采用Action Units (AUs)，即定义了解剖学面部肌肉运动，与隐式特征结合以减少音素-唇型对齐错误。此外，作者引入了一种混合运动建模模块 (HMMM)，该模块动态地将随机配对的隐式和显式特征合并，以促进身份无关的学习。", "conclusion": "大量的实验表明，HM-Talker在视觉质量和唇部同步准确性方面优于最先进的方法。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.06771", "html_url": "https://arxiv.org/abs/2509.06771", "title": "D-HUMOR: 通过多模态开放性推理理解暗黑幽默——基准数据集与方法", "title_en": "D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning - A Benchmark Dataset and Method", "authors": "Sai Kartheek Reddy Kasu,Mohammad Zia Ur Rehman,Shahid Shafi Dar,Rishi Bharat Junghare,Dhanvin Sanjay Namboodiri,Nagendra Kumar", "background": "暗黑幽默在网络表情包中存在独特挑战，因为它依赖于隐含、敏感且文化背景相关的线索。目前缺乏针对多模态内容检测暗黑幽默的资源和方法。", "innovation": "本文提出了一种新颖的、标注了暗黑幽默、目标类别和强度级别的Reddit表情包数据集。同时，开发了一个增强推理框架，利用大型视语言模型（VLM）生成结构化解释，并通过角色反转自我循环迭代优化，提取文本和视觉特征，最终通过三流交叉推理网络（TCRNet）融合这三种流的特征进行分类。", "conclusion": "实验结果显示，本文方法在暗黑幽默检测、目标识别和强度预测三个任务上均优于强基线。数据集、标注和代码可供进一步研究多模态幽默理解和内容管理使用。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04448", "html_url": "https://arxiv.org/abs/2509.04448", "title": "TRUST-VL：通用跨模态误导信息检测的可解释新闻助理", "title_en": "TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection", "authors": "Zehong Yan,Peng Qi,Wynne Hsu,Mong Li Lee", "background": "多模态误导信息，包含文本、视觉以及跨模态的误导，是随着生成式AI的发展而加剧的社会问题。现有方法大多仅针对单一类型的误导，难以应对新场景下的问题。", "innovation": "作者提出一种联合训练模型(TRUST-VL)，该模型包含一种新的问题感知视觉增强模块，能够提取任务特定的视觉特征。此外，作者还构建了一个大规模的指令数据集(TRUST-Instruct)，用于模型训练，该数据集包含198K样本，结构化推理链与人类事实核查流程对齐。通过广泛实验，TRUST-VL在领域内和零样本基准上的表现均达到最佳，同时具有较强的泛化能力和解释性。", "conclusion": "TRUST-VL 是一个统一的可解释的跨模态语言视觉模型，用于普遍的误导信息检测。它在性能和解释性上均领先，展示了其在处理复杂误导信息检测任务上的强大能力。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24267", "html_url": "https://arxiv.org/abs/2509.24267", "title": "Cycle Diffusion Model for Counterfactual Image Generation", "title_en": "Cycle Diffusion Model for Counterfactual Image Generation", "authors": "Fangrui Huang,Alan Wang,Binxu Li,Bailey Trang,Ridvan Yesiloglu,Tianyu Hua,Wei Peng,Ehsan Adeli", "background": "深度生成模型在医学图像合成中已取得显著成果，但确保合成图像的条件忠实性和高质量仍面临挑战。", "innovation": "提出了一种循环训练框架来微调扩散模型，以提高条件忠实性和增强合成图像的真实性。通过引入循环约束，使生成图像与原始图像保持一致，进而提升直接和反事实生成的可靠性。", "conclusion": "实验结果显示，该方法在FID和SSIM指标上的表现优异，表明循环策略在循环扩散模型中有效提升了基于扩散的医学图像生成的精确性和质量，具有数据增强、反事实和疾病进展建模等应用前景。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.23885", "html_url": "https://arxiv.org/abs/2509.23885", "title": "由自监督上下文次级数据驱动的可调泛化扩散方法用于低剂量CT重建", "title_en": "Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction", "authors": "Guoquan Wei,Liu Shi,Zekun Zhou,Wenzhe Shan,Qiegen Liu", "background": "当前基于深度学习的低剂量CT降噪模型高度依赖配对数据并且泛化能力差，即使更关注的扩散模型也需要学习干净数据分布以进行重建，但在医疗临床应用中难以满足。此外，基于自监督的方法面临将预先训练好的模型从当前剂量扩展到其他剂量时泛化能力显著下降的挑战。", "innovation": "提出了一种名为Tunable-Generalization Diffusion (TurnDiff) 的新方法，该方法结合自监督和上下文次级数据，通过在低剂量CT投影域设计上下文次级数据自增强相似性策略，提供后续步骤的初始先验，然后结合知识蒸馏和深度组合潜在扩散模型以优化图像细节。这种方法在典型剂量和未见剂量的一体化泛化中表现出色。", "conclusion": "在基准数据集和实际数据上进行的综合评估表明，TurnDiff 在重建和泛化方面均能优于现有先进方法。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08186", "html_url": "https://arxiv.org/abs/2508.08186", "title": "KARMA: 通过柯尔莫哥洛夫-阿诺尔德表示学习实现高效结构缺陷分割", "title_en": "KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning", "authors": "Md Meftahul Ferdaus,Mahdi Abdelguerfi,Elias Ioup,Steven Sloan,Kendall N. Niles,Ken Pathak", "background": "对基础设施中的结构性缺陷进行语义分割仍然具有挑战性，原因在于缺陷的多变形态、恶劣的成像条件以及类别之间的严重不平衡。现有的深度学习方法虽然有效，但通常需要数百万参数，这使得它们不适合实时检测系统。在基础设施检测数据集上进行的广泛实验表明，KARMA（Kolmogorov-Arnold Representation Mapping Architecture）实现了与最新技术相当或更好的平均IoU性能，同时使用了显著 fewer 参数（0.959M vs. 31.04M，参数减少97%）。KARMA 运行速度为 0.264 GFLOPS，符合适用于实时部署的推理速度，从而能够实现无需牺牲准确性的情况下，实用的自动化基础设施检测系统。", "innovation": "KARMA 引入了三个技术创新：(1) 一个高效的 Tiny Kolmogorov-Arnold Network (TiKAN) 模块，利用低秩因式分解来高效地对 KAN 基础特征进行变换；(2) 一个优化的多尺度特征金字塔结构，使用可分离卷积来增强缺陷分析；(3) 一种静态-动态原型机制，用于增强不平衡类别的特征表示。KARMA 结合上述创新，成功弥补了传统方法在参数效率和实时检测能力上的不足，提高了基础设施检测的实用性和准确性。", "conclusion": "KARMA 作为一种高效的语义分割框架，在保持与当前顶级方法相当或更好的分割性能的同时，显著减少了所需的参数数量和提高了推理速度，适用于实时基础设施检测系统，证明了其在实际应用中的潜力。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14904", "html_url": "https://arxiv.org/abs/2510.14904", "title": "MaskCaptioner: 学习在视频中联合分割和描述物体轨迹", "title_en": "MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos", "authors": "Gabriel Fiastre,Antoine Yang,Cordelia Schmid", "background": "DVOC任务要求联合检测、跟踪和描述视频中物体的轨迹，需要理解时空细节并用自然语言描述。由于任务复杂性和手动注释的成本高，之前的方法采用分离训练策略，可能导致表现不佳。", "innovation": "提出一种方法，利用先进的视觉语言模型自动生成时空局部化的实体描述。通过将LVIS和LV-VIS数据集扩展为包含合成描述（LVISCap和LV-VISCap），训练能够联合检测、分割、跟踪和描述物体轨迹的端到端模型MaskCaptioner。在三个现有基准（VidSTG、VLN和BenSMOT）上，MaskCaptioner取得了最先进的DVOC结果。", "conclusion": "通过预训练和使用合成数据集，MaskCaptioner在DVOC任务上取得了显著成果，并且提供了可用的代码和数据集下载链接以供参考。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14431", "html_url": "https://arxiv.org/abs/2510.14431", "title": "实时统一封间码的神经视频压缩", "title_en": "Real-Time Neural Video Compression with Unified Intra and Inter Coding", "authors": "Hui Xiang,Yifan Bian,Li Li,Jingran Wu,Xianguo Zhang,Dong Liu", "background": "近年来，神经视频压缩（NVC）技术得到了迅速发展，产生了诸如DCVC-RT这类具有优越压缩效率和实时编码/解码能力的解决方案，超越了H.266/VVC。然而，现有的NVC方案还存在处理遮挡和新内容效率低下、帧间错误传播和积累等问题。", "innovation": "该论文提出了一个统一封间码的NVC框架，通过允许在间隔帧中进行内码，有效解决了遮挡和新内容处理效率低、帧间错误传播和积累的问题，无需手动刷新机制。同时，提出了一种双帧同时压缩设计，不仅向前也向后利用帧间冗余。", "conclusion": "实验结果表明，该方案比DCVC-RT平均有12.1%的BD-rate减少，提供更稳定的码率和每帧的画质，保留了实时编码/解码性能。代码和模型将公开发布。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08771", "html_url": "https://arxiv.org/abs/2510.08771", "title": "LinearSR：解锁线性注意力以实现稳定高效的图像超分辨率", "title_en": "LinearSR: Unlocking Linear Attention for Stable and Efficient Image Super-Resolution", "authors": "Xiaohui Li,Shaobin Zhuang,Shuo Cao,Yang Yang,Yuandong Pu,Qi Qin,Siqi Luo,Bin Fu,Yihao Liu", "background": "目前生成模型在图像超分辨率（SR）方面表现出越来越强大的能力，但它们依赖于自注意力的二次复杂度（O(N^2)），形成了主要的计算瓶颈。线性注意力提供了一种O(N)的解决方案，但其在实现真实感超分辨率方面的潜力一直未能充分利用，历史上主要是由于一系列相关的和以前未解决的挑战造成的。", "innovation": "本文介绍了LinearSR，一种全面框架，首次系统地克服了这些关键障碍。通过我们新颖的基于‘膝点’的Early-Stopping Guided Fine-tuning (ESGF)策略，解决了一个基本的训练不稳定问题，导致模型灾难性发散。此外，通过一个专门的基于SNR的Mixture of Experts（MoE）架构，解决了经典的感知-失真权衡。最后，根据“精度优于数量”的原则，建立了一个有效的轻量级指导范式，TAG。由此得到的LinearSR模型同时实现了最先进的感知质量和卓越的效率。其核心扩散前向传递过程（1-NFE）达到了业界领先的速度，而其整体多步推理时间仍然具有很强竞争力。这项工作为在真实感超分辨率领域应用线性注意力提供了第一个稳健的方法，为有效生成超分辨率的未来研究奠定了基础范式。", "conclusion": "这项工作为在真实感超分辨率领域应用线性注意力提供了第一个稳健的方法，为有效生成超分辨率的未来研究奠定了基础范式。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.16396", "html_url": "https://arxiv.org/abs/2510.16396", "title": "SPLite手部：感知稀疏性的轻量化3D手部姿态估计", "title_en": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "authors": "Yeh Keng Hao,Hsu Tzu Wei,Sun Min", "background": "由于AR/VR设备的普及，将深度学习模型部署在边缘设备上已成为一个重要挑战。这些设备需要实时推理、低功耗和低延迟。框架设计师必须在效率和性能之间寻求平衡。本文通过设计一个轻量级框架，采用编码器-解码器架构，并通过引入几个关键贡献来提高效率和准确性，解决了这个问题。", "innovation": "本文提出了SPLite框架，该框架采用稀疏卷积在ResNet-18骨干网络上，提高了手势图像中的固有稀疏性，实现了端到端效率提升42%。此外，SPLite引入了一种新的解码器SPLite，加速了像素级解码过程可在树莓派5上提高3.1倍，保持与现有方法相当的准确性。通过量化的训练方法，在保持准确性的同时减少了内存使用（PA-MPJPE增加了0.1 mm）。系统在树莓派5 CPU上实现了2.98倍的速度提升。该方法在多种基准数据集上得到了评估，与最先进的方法相比，准确度相当，但计算效率显著提高", "conclusion": "本文提出了一种轻量级的3D手部姿态估计方法，SPLite，该方法在保持或提高准确性的前提下，通过稀疏卷积、SPLite解码器以及量化训练实现了性能和效率的显著提升。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.16556", "html_url": "https://arxiv.org/abs/2510.16556", "title": "适合实际用途吗？现实世界中的深度假信息检测", "title_en": "Fit for Purpose? Deepfake Detection in the Real World", "authors": "Guangyu Lin,Li Lin,Christina P. Walker,Daniel S. Schiff,Shu Hu", "background": "随着生成对抗网络、扩散模型和多模态大型语言模型的发展，AI生成内容的迅速增长使得合成媒体的创作和传播变得非常容易，这也增加了误导性信息的风险，尤其是在政治领域，这些假信息会扭曲事实并损害公众对政治机构的信任。因此，政府、研究机构和行业积极推动了深度假信息检测的举措。然而，大多数现有的模型都是基于合成的、实验室控制的数据集进行训练和验证的，这限制了它们在社交媒体上真实存在的政治深度假信息的泛化能力，这些信息会对公众产生影响。", "innovation": "本研究引入了首个基于'政治深度假信息事件数据库'（包含从2018年起在社交媒体上共享的真实政治深度假信息）的系统基准。研究对来自学术界、政府和行业的最先进的深度假信息检测器进行了系统的评估。研究发现，学术界和政府的检测器表现相对较差，付费的检测工具比免费模型的性能稍好一些，但所有评估的检测器在泛化到真实的政界深度假信息方面效果不佳，且极易受到简单操控，特别是在视频领域。", "conclusion": "研究结果强调，需要制定更具政治背景的深度假信息检测框架，以更好地在实际场景中保护公众不受误导性信息的影响。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23588", "html_url": "https://arxiv.org/abs/2510.23588", "title": "FARMER: Flow AutoRegressive Transformer over Pixels", "title_en": "FARMER: Flow AutoRegressive Transformer over Pixels", "authors": "Guangting Zheng,Qinyu Zhao,Tao Yang,Fei Xiao,Zhijie Lin,Jie Wu,Jiajun Deng,Yanyong Zhang,Rui Zhu", "background": "直接建模原始数据分布的概率是机器学习领域的关键主题，通过自回归建模已经在大规模语言模型中取得了规模上的成功。然而，对视觉像素数据进行连续的自回归建模会遇到序列极长和高维空间的问题。本文旨在解决这一问题。", "innovation": "提出了FARMER，一种新颖的一站式生成框架，统一了流动归一化（NF）和自回归（AR）模型，用于可操作的似然估计和直接从原始像素进行高质量图像合成。FARMER 使用可逆自回归流将图像转换为潜在序列，该序列分布由自回归模型隐式建模。我们还提出了一种自我监督的维度降低方案，将NF潜在通道分为信息性和冗余性群体，以更好地进行AR模型。另外，设计了一步式蒸馏方案来显著加速推理速度，并引入基于重采样的无条件引导算法来提高图像生成质量。", "conclusion": "广泛实验表明，FARMER 在与现有基于像素的生成模型相比具有竞争力的性能的同时，提供了精确的似然性和可扩展的训练。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23968", "html_url": "https://arxiv.org/abs/2510.23968", "title": "基于视觉语言的胸片分析推理模型", "title_en": "Reasoning Visual Language Model for Chest X-Ray Analysis", "authors": "Andriy Myronenko,Dong Yang,Baris Turkbey,Mariam Aboian,Sena Azamat,Esra Akcicek,Hongxu Yin,Pavlo Molchanov,Marc Edgar,Yufan He,Pengfei Guo,Yucheng Tang,Daguang Xu", "background": "视觉-语言模型(VLMs)在医学图像分析方面展现了强大的潜力，但大多数模型依然难以透明化，只能提供预测结果而不能像临床医生所依赖的那样解释其背后的推理过程。本文提出了一个将链式推理(Chain-of-Thought CoT)引入胸片解读的框架。", "innovation": "该方法通过模拟专家的推理过程，而非仅仅学习结论，采用两种阶段的训练方法：一种是推理风格的监督微调(SFT)，另一种是使用可验证奖励的强化学习(RL)，并且这些奖励覆盖了胸片异常列表。模型输出的推理过程仿照了放射科医生系统的思考过程，包括不确定性和鉴别诊断。", "conclusion": "此方法不仅在分布外评估中实现了可对比的多标签分类准确度，还提升了可解释性。在放射科专家的读者研究中，完整的推理过程提高了他们的信心，支持了错误审计，并减少了完成报告所需的时间。研究者将模型代码和NV-Reason-CXR-3B模型释放以促进社区在胸片和其他医学影像任务中构建可信赖和可解释的人工智能的发展。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22319", "html_url": "https://arxiv.org/abs/2510.22319", "title": "GRPO-Guard: 通过受控修剪减轻流匹配中的隐式过度优化", "title_en": "GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping", "authors": "Jing Wang,Jiajun Liang,Jie Liu,Henglin Liu,Gongye Liu,Jun Zheng,Wanyuan Pang,Ao Ma,Zhenyu Xie,Xintao Wang,Meng Wang,Pengfei Wan,Xiaodan Liang", "background": "最近，基于GRPO（Gradient Ratio Proportional Optimization）的强化学习在优化流匹配模型方面取得了显著进展，有效提高了它们与任务特定奖励的吻合度。然而，在实际应用中，观察到重要性比分布系统性左移，其均值低于1，方差在时间步之间差异显著。这导致正优势采样无法进入剪裁区域，使机制在约束自信正值更新时失效，使策略模型不可避免地进入到隐式的过度优化阶段，最终导致生成质量和文本提示对齐度急剧下降，使得学习到的策略在实际应用中不切实际。", "innovation": "本文介绍了一种简单的增强方法GRPO-Guard，通过引入比率规范化来恢复平衡一致的重要性比，确保PPO剪裁适当地约束噪声下各个步骤的有害更新。此外，采用梯度再加权策略在噪声条件下平等地分配策略梯度，防止某一时间步区域的过度更新。这些设计共同作为受控剪裁机制，稳定优化过程，减少隐式优化，而无需依赖大量的KL正则化。在多个扩散框架（如SD3.5M和Flux.1-dev）和不同的代理任务上进行了广泛实验，验证了GRPO-Guard显著减少了过度优化现象，同时维持或提高了生成质量.", "conclusion": "GRPO-Guard方法在稳定优化过程，减少隐式过度优化，同时维持或提升生成质量方面展现出了显著效果。它通过引入比率规范化和梯度再加权策略，有效地解决了重要性比分布左移和方差较大的问题，避免了过度优化带来的负面影响。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25077", "html_url": "https://arxiv.org/abs/2510.25077", "title": "遥感图像分类中的局部特征聚合", "title_en": "Neighborhood Feature Pooling for Remote Sensing Image Classification", "authors": "Fahimeh Orvati Nia,Amirmohammad Mohammadi,Salim Al Kharsa,Pragati Naikare,Zigfried Hampel-Arias,Joshua Peeples", "background": "近年来，遥感图像分类技术得到了迅速发展，但有效的纹理特征提取方法仍然是一个挑战。传统的特征提取方法可能无法充分利用相邻像素之间的关系，导致分类性能受限。因此，需要一种新的特征提取方法来改善这一问题，通过对相邻输入之间的关系进行建模，并高效地在特征维度上聚合局部相似性，从而提高遥感图像分类的性能。", "innovation": "本文提出了一种新的纹理特征提取方法——局部特征聚合（NFP）。NFP层捕捉相邻输入之间的关系，并有效聚合局部相似性。通过使用卷积层实现，NFP可以无缝集成到任何网络中。实验结果表明，NFP可以一致地提高多种数据集和架构上的分类性能，同时保持最小的参数开销。", "conclusion": "研究表明，NFP方法在多种遥感图像分类任务上的性能有所提升，且参数开销较小，有望在实际应用中提高图像分类的效率和准确性。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG: 优化文本到视频生成的视频字幕", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "最近在文本到视频(T2V)生成领域取得了显著进展，强调了高质量视频文字对训练生成连贯且与指令对齐的视频模型的重要性。然而，对优化用于T2V训练的视频字幕策略的研究仍处于起步阶段。研究人员注意到，从T2V的角度分析字幕内容，分解出用于视频重建所需的基本要素，并提出了一种理论字幕设计方法。为了支持评估，研究构建了一个新的基准VC4VG-Bench，该基准包含细粒度、多维度和必要性分级的指标，这些指标与T2V特定的要求一致。通过大量T2V微调实验，研究发现字幕质量的提升与生成性能之间存在很强的相关性，从而验证了所提出方法的有效性。研究还公开了所有基准工具和代码以支持进一步研究。", "innovation": "本文引入了VC4VG框架，这是一种专为T2V模型设计的全面的字幕优化框架。该框架从T2V视角分析了字幕内容，提出了字幕设计的一套原则，并构建了一个包含细粒度、多维度和必要性分级的评估基准VC4VG-Bench，这些指标专门针对T2V需求进行设计，证明了改进字幕质量对提升视频生成质量有显著效果。研究者还公开了所有基准工具和代码，以支持进一步研究。", "conclusion": "大量T2V微调实验验证了通过改进字幕质量来提升视频生成质量的有效性，并且还公开了用于支持进一步研究的工具和代码。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.22159", "html_url": "https://arxiv.org/abs/2503.22159", "title": "剥离耦合的4D 高斯绘制：在343 FPS 下渲染高分辨率动态世界", "title_en": "Disentangled 4D Gaussian Splatting: Rendering High-Resolution Dynamic World at 343 FPS", "authors": "Hao Feng,Hao Sun,Wei Xie,Zhi Zuo,Zhengzhe Liu", "background": "虽然从2D 视频中生成动态新视角已取得进展，但实时高效的动态场景重建与渲染仍然是一个挑战。现有方法通常在时间和空间维度上进行四维计算，导致计算冗余和渲染速度较慢", "innovation": "提出了一种新的表示和渲染管道——剥离耦合的4D 高斯绘制(Disentangled4DGS)，通过分离4D 高斯的时间和空间组件，避免了卷积和四维矩阵计算。通过将动态时间和空间变形投影到2D 高斯中并将时间处理推迟，减少了冗余计算。该方法还采用了梯度引导流损失和时间分割策略来减少伪影。实验结果表明，该方法在保持视觉质量的同时，实现了343 FPS 的渲染速度，并且减少了至少4.5%的存储需求", "conclusion": "该方法为动态新视图合成设定了新的基准，在多视角和单目动态场景数据集上均优于现有方法"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23981", "html_url": "https://arxiv.org/abs/2510.23981", "title": "TeleEgo：自然环境中自中心AI助手评估基准", "title_en": "TeleEgo: Benchmarking Egocentric AI Assistants in the Wild", "authors": "Jiaqi Yan,Ruilong Ren,Jingren Liu,Shuning Xu,Ling Wang,Yiheng Wang,Yun Wang,Long Zhang,Xiangyu Chen,Changzhi Sun,Jixiang Luo,Dell Zhang,Hao Sun,Chi Zhang,Xuelong Li", "background": "现有的自中心人工智能助手在实际环境中的应用需要处理多种模态的输入（视频、音频、文本），实时响应，并维护不断演进的长期记忆。然而，现有的基准评估通常是在孤立的情况下进行的，缺乏现实的流式场景，或者只支持短期任务。为了填补这些空白，本文引入了一个名为TeleEgo的基准测试，它是一个长期、流式、全模态的基准，旨在评估自中心AI助手在日常生活中的实际上下文表现。TeleEgo包含每位参与者超过14小时的同步自中心视频、音频和文本数据，涵盖了工作/学习、生活方式/例行公事、社交活动、外出/文化四个领域。所有数据统一在一个全球时间线上，并包括高质量的视觉叙述和语音转录，这些数据是通过严格的审核和整理获得的。该基准测试定义了12项诊断子任务，涵盖了三大核心能力：记忆、理解以及跨记忆推理。基准测试中包括了3,291年人类验证的问答项，涉及多种问题格式，并在流式环境下严格进行评估。", "innovation": "TeleEgo是一个长时、流式、全模态的基准测试，用于评估自中心AI助手在现实日常环境中的表现。它特别注重模拟现实生活中的场景，涵盖了多种情景领域，使用高质量的视觉和音频数据，以及经过严格审核的问答项，这在以往的基准测试中是较为罕见的。此外，TeleEgo提出了一种新的评价方法，通过联合评估实时准确性和长期保持时间，更全面地反映了自中心AI助手的实际表现能力。", "conclusion": "TeleEgo提供了一个现实且全面的评估框架，旨在推动实用主义自中心AI助手的发展。该基准测试定义了12项诊断子任务，通过真人验证的问答项严格评估三大核心能力——记忆、理解以及跨记忆推理。TeleEgo的引入将有助于加速自中心AI助手的研发进程，并在真实使用场景中发挥更优秀的表现。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25327", "html_url": "https://arxiv.org/abs/2510.25327", "title": "MMEdge：通过分段感测和编码加速设备上多模态推断", "title_en": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding", "authors": "Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang", "background": "对于自动驾驶、人机交互和移动健康等应用而言，在资源受限的边缘设备上进行实时的多模态推断是至关重要的。然而，以往的工作往往忽视了感知动态与模型执行之间的紧密联系，以及不同模态之间的复杂依赖性。因此，本文指出了现有工作的不足之处，即缺乏对这些关键问题的关注，从而影响了系统的性能和适应性。为解决这些问题，本文提出了一个新的设备边缘上的多模态推理框架MMEdge，基于分段感测和编码的机制，旨在提升系统的灵活性和效能。", "innovation": "MMEdge 提出了一个基于分段感测和编码的新框架，实现了在数据到达时逐级进行计算，无需等待所有传感器输入完成。此外，它还引入了轻量但有效的临时聚合模块，用于捕获不同阶段间丰富的时序动态，以维持处理过程中的准确性。此分段设计还可以为跨模态的细粒度优化和早期决策提供机会。研究还整合了一个自适应多模态配置优化器，该优化器可根据延迟约束动态选择最合适的传感器和模型配置，并引入了一个跨模态推测性跳过机制，通过实现基于预测置信度的快速决策，进一步优化系统性能。", "conclusion": "通过设计上的改进，MMEdge 在多种系统和数据条件下均显著降低了端到端的延迟，同时保持了高任务准确率，体现了其出色的适应性和性能优势。这一系列的改进使得MMEdge能够在实际应用中，特别是在基于无人机的多模态测试平台上，展现出优越的性能。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13444", "html_url": "https://arxiv.org/abs/2505.13444", "title": "ChartMuseum：测试大型视觉语言模型的视觉推理能力", "title_en": "ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models", "authors": "Liyan Tang,Grace Kim,Xinyu Zhao,Thom Lake,Wenxuan Ding,Fangcong Yin,Prasann Singhal,Manya Wadhwa,Zeyu Leo Liu,Zayne Sprague,Ramya Namuduri,Bodun Hu,Juan Diego Rodriguez,Puyuan Peng,Greg Durrett", "background": "大型视觉语言模型（LVLM）在图理解方面面临独特挑战，这需要在复杂的文本和视觉推理能力之间进行融合。然而，当前的LVLM在复杂的视觉推理任务上表现不佳，这通常难以在文本中完成。尽管存在一些现有基准测试，但它们无法有效区分模型性能和人类水平之间的差距，特别是在需要高级视觉和文本推理的任务中。", "innovation": "作者通过引入名为ChartMuseum的新图表问答（QA）基准来解决这个问题。该基准包含1,162个由专家标注的问题，涵盖了多种推理类型，并来自184个真实的图表源。相比之下，以往的图表理解基准模型表现相近且接近饱和，而ChartMuseum展示了模型和人类在性能上的显著差距，并有效地区分了模型的能力。", "conclusion": "虽然人类在测试中达到了93%的准确率，但最好的模型Gemini-2.5-Pro的准确率只有63.0%，领先的开源LVLM Qwen2.5-VL-72B-Instruct的准确率只有38.5%。更值得关注的是，所有模型在需要主要视觉推理的问题上，其表现从文本推理为主的题目表现下降了35%-55%。还发现当前的LVLM在特定类型的视觉推理中表现出困难。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19816", "html_url": "https://arxiv.org/abs/2506.19816", "title": "CronusVLA: 通过多帧视觉-语言-动作建模实现高效且鲁棒的机械操作", "title_en": "CronusVLA: Towards Efficient and Robust Manipulation via Multi-Frame Vision-Language-Action Modeling", "authors": "Hao Li,Shuai Yang,Yilun Chen,Xinyi Chen,Xiaoda Yang,Yang Tian,Hanqing Wang,Tai Wang,Dahua Lin,Feng Zhao,Jiangmiao Pang", "background": "近期基于预训练视觉-语言模型（VLMs）的视觉-语言-动作（VLA）模型在机器人的操作中表现出强大的性能，但这些模型仍然受限于单帧图像的范式，未能充分利用多帧历史信息中的时间信息。直接将多帧输入到VLM骨干中会导致计算开销和推理延迟的显著增加。", "innovation": "提出了一种统一框架CronusVLA，扩展了单帧VLA模型到多帧范式。CronusVLA采用了两阶段过程：（1）在大规模受体数据集上进行单帧预训练，通过自回归预测动作标记建立有效的视觉-语言基础；（2）多帧后训练，使视觉-语言骨干的预测从离散标记转变为可学习特征，并通过特征分块聚合历史信息。CronusVLA有效解决了多帧建模的现有挑战，提高了性能和观测鲁棒性。", "conclusion": "通过引入SimplerEnv-OR基准，包括24种类型的观测干扰和120种严重程度水平，实验在模拟和真实环境中的三个实体上证明了CronusVLA实现了最佳性能和优越的鲁棒性。其在SimplerEnv上的成功率达到了70.9%，在LIBERO上的表现比OpenVLA提高了26.8%，并在SimplerEnv-OR上获得了最高的鲁棒性分数。这些结果突显了在VLA模型中有效多帧适应的潜力，该潜力可以增强实操中的性能和鲁棒性部署。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24325", "html_url": "https://arxiv.org/abs/2509.24325", "title": "ReCon-GS: 保持连续性的高斯流式传输以实现快速且紧凑的动态场景重构", "title_en": "ReCon-GS: Continuum-Preserved Gaussian Streaming for Fast and Compact Reconstruction of Dynamic Scenes", "authors": "Jiaye Fu,Qiankun Gao,Chengxiang Wen,Yanmin Wu,Siwei Ma,Jiaqi Zhang,Jian Zhang", "background": "在线自由视点视频（FVV）重建面临帧间优化缓慢、运动估计不一致和存储需求不可持续等挑战。为此，该论文提出的ReConfigurable Continuum Gaussian Stream（ReCon-GS）提供了一种新的存储感知框架，使得能够实现高保真度的在线动态场景重建和实时渲染。", "innovation": "ReCon-GS动态分配多层次的锚定高斯分布，按密度自适应分配来捕捉帧间几何变形，从而将场景运动分解为紧凑的粗细表示；设计动态层级重构策略保留局部运动的表达力，通过层级内变形继承确保时间一致性，同时仍然在各自的层级水平上限制变形先验。引入一种感知存储的优化机制，灵活调整不同层级的锚定高斯分布密度，实现重建保真度和内存使用之间的可控权衡。", "conclusion": "在三种广泛使用的数据集上进行的大量实验表明，相比于最先进的方法，ReCon-GS在训练效率方面提升了约15%，并且在增强的鲁棒性和稳定性状态下实现了更优的FVV合成质量。此外，与最先进的方法相比，在等同渲染质量的情况下，ReCon-GS将内存需求减少了超过50%。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.16336", "html_url": "https://arxiv.org/abs/2509.16336", "title": "Neural Atlas Graphs for Dynamic Scene Decomposition and Editing", "title_en": "Neural Atlas Graphs for Dynamic Scene Decomposition and Editing", "authors": "Jan Philipp Schneider,Pratik Singh Bisht,Ilya Chugunov,Andreas Kolb,Michael Moeller,Felix Heide", "background": "学习高分辨率的动态场景表示对于从自动驾驶到创意编辑等多个领域具有重要意义，而现有的成功方法在编辑能力和支持的场景复杂性之间做出了权衡。神经地图集方法将动态场景表示为可变形的前景和背景两层图像，虽然易于在二维上编辑，但在多个对象遮挡和交互时会失效。场景图模型则利用自动驾驶数据集中的注释数据（如掩码和边界框）来捕捉复杂的空间关系，但其隐式的体积节点表示在具有一致视图编辑时较为困难。鉴于此，该研究提出了一种混合高分辨率场景表示方法，即神经地图图（NAGs），其每个图节点是视图依赖的神经地图集，既支持二维外观编辑，又可以保持场景元素的三维顺序和定位。", "innovation": "NAGs 是一种新的高分辨率场景表示方法，每个图节点是一个视图依赖的神经地图集，这一设计既支持二维外观编辑，又保持场景元素的三维顺序和定位。这种方法在 Waymo Open Dataset 上实现了最新的定量结果，相比现有方法提高了 5 dB 的 PSNR，同时允许在高分辨率和高视觉质量下进行环境编辑，还能够在自动驾驶场景之外进行广泛适用，PSNR 指标上优于近期的前景分割和视频编辑基准方法超过 7 dB。", "conclusion": "NAGs 提供了一种新的高分辨率动态场景表示方法，使高分辨率的环境编辑成为可能，并在自动驾驶场景之外表现优异，推广了场景编辑的应用范围。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.06159", "html_url": "https://arxiv.org/abs/2509.06159", "title": "FASL-Seg：手术场景中的解剖学与工具分割", "title_en": "FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes", "authors": "Muraam Abdel-Ghani,Mahmoud Ali,Mohamed Ali,Fatmaelzahraa Ahmed,Muhammad Arsalan,Abdulaziz Al-Ali,Shidin Balakrishnan", "background": "随着机器人微创手术的普及，基于深度学习的手术培训成为一个重要的研究领域。理解手术场景的组件至关重要，而语义分割模型可以帮助实现这一目标。然而，现有的大部分工作集中在对手术工具的研究上，忽视了对解剖对象的关注。当前最先进的模型在捕捉高层上下文特征和低层面轮廓特征时存在平衡问题。", "innovation": "我们提出了一个特征自适应空间定位模型（FASL-Seg），通过两个不同的处理流，即低级特征投影（LLFP）和高级特征投影（HLFP）流，分别处理不同分辨率的特征，从而实现多细节层次的特征捕捉，以实现对解剖学和手术器械的精确分割。", "conclusion": "FASL-Seg在EndoVis18和EndoVis17手术分割基准数据集上的部分和解剖学分割任务中达到了72.71%的平均交并比（mIoU），比最先进的模型提高了5%。在工具类型分割任务中，FASL-Seg分别在EndoVis18和EndoVis17上达到了85.61%和72.78%的平均交并比，总体性能优于最先进的模型。在两个数据集中的所有类别中，FASL-Seg显示出一致的性能，证明了不同分辨率特征处理流的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.17148", "html_url": "https://arxiv.org/abs/2510.17148", "title": "DiffVLA++: 通过度量指导对齐连接认知推理与端到端驾驶", "title_en": "DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment", "authors": "Yu Gao,Anqing Jiang,Yiru Wang,Wang Jijun,Hao Jiang,Zhigang Sun,Heng Yuwen,Wang Shuo,Hao Zhao,Sun Hao", "background": "传统的端到端(E2E)驾驶模型虽然能够生成物理上合理的驾驶轨迹，但在处理长尾场景时常常因为缺乏必需的世界知识而缺乏泛化能力。相比之下，Vision-Language-Action (VLA)模型利用世界知识处理复杂场景，但其有限的三维推理能力可能导致物理不可行的行为。", "innovation": "引入了一个增强型自主驾驶框架DiffVLA++，通过度量引导对齐结合认知推理和E2E规划。具体来说：1) 建立了一个VLA模块，直接生成语义相关的驾驶轨迹；2) 设计了一个具有密集轨迹词汇表的E2E模块，确保物理可行性；3) 引入了度量引导轨迹得分器，引导并对齐VLA和E2E模块的结果，从而整合其互补优势。", "conclusion": "在ICCV 2025自动驾驶挑战赛排行榜上的实验表明，DiffVLA++实现了EPDMS值为49.12。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02781", "html_url": "https://arxiv.org/abs/2510.02781", "title": "GCVAMD：一种改良的因果VAE模型，用于年龄相关黄斑变性风险因素的因果检测与预测", "title_en": "GCVAMD: A Modified CausalVAE Model for Causal Age-related Macular Degeneration Risk Factor Detection and Prediction", "authors": "Daeyoung Kim", "background": "年龄相关黄斑变性（AMD）是眼科最常见的永久性视力损伤原因之一。尽管已开发了抗VEGF药物或光动力疗法等治疗方法以减缓AMD的退化过程，但尚无特定的治疗方法能够逆转AMD引起的眼部损失。因此，在眼底早期检测AMD或其风险因素对降低视力损害的可能性至关重要。通过以往的传统方法和基于深度学习的方法（如基于注意力机制的CNN和GradCAM基的XAI分析）已经在OCT扫描上成功地区分AMD视网膜和正常视网膜，使AI驱动的模型能够辅助眼科医生对AMD的诊断和分析。然而，之前的许多研究主要集中在预测性能方面，而不是AMD的病理学或潜在因果机制，这可能阻碍对特定因素的干预分析，甚至可能导致不那么可靠的选择。", "innovation": "本文介绍了一种新的因果AMD分析模型：GCVAMD，该模型结合了一种改良的因果VAE方法，可以从原始OCT图像中提取潜在的因果因子。通过考虑AMD检测中的因果关系，GCVAMD能够实现针对主要风险因素（如玻璃膜疣和新生血管化）的治疗模拟或干预分析，并返回具有信息性的潜在因果特征，以增强后续任务。", "conclusion": "研究结果表明，通过GCVAMD，可以在AMDCVAE潜在空间中识别出AMD的因果机制，进一步可以用于AMD检测（分类）和干预分析等多种任务。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.21271", "html_url": "https://arxiv.org/abs/2510.21271", "title": "Buffer layers for Test-Time Adaptation", "title_en": "Buffer layers for Test-Time Adaptation", "authors": "Hyeongyu Kim,Geonhui Han,Dosik Hwang", "background": "在最近的测试时适应（TTA）发展中，现有方法主要集中在更新归一化层以适应测试领域。然而，基于归一化的方法存在关键挑战。首先，如批量归一化（BN）等归一化层对小批量敏感，导致不稳定的统计数据。其次，基于归一化的适应性受到预训练模型结构的限制，依赖的训练时统计数据难以在未见过的领域中很好地泛化。这些缺陷限制了基于归一化层的TTA方法的有效性，特别是在领域转移显著时。", "innovation": "本文提出了一种基于Buffer层的新范式，以解决归一化层更新的根本限制。我们的方法不修改模型的核心参数，而是保留预训练骨干网络的完整性，天生减轻了在线适应过程中的灾难性遗忘风险。实验表明，我们的方法不仅在减轻领域转移和增强模型鲁棒性方面优于传统方法，还能在遗忘方面表现出强大的稳健性。此外，我们的Buffer层模块化，可以无缝集成到几乎所有现有的TTA框架中，从而在各种架构上实现一致的性能提升。这些发现证实了提出的方法在实际领域的有效性与多功能性。", "conclusion": "我们的研究结果验证了在实际领域适应场景中采用提议解决方案的有效性和灵活性。同时，我们的Buffer层可以模块化地集成到几乎所有现有的TTA框架中，由此带来了各个架构上的连续性能改进。这种方法不仅在减轻领域转移和增强模型鲁棒性方面表现出色，还可以有效地防止遗忘。此代码已于https:// 公开。"}
{"llm_update_time": "20251102", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23117", "html_url": "https://arxiv.org/abs/2510.23117", "title": "在发生之前预见结构失效：基于图像的物理感知神经网络（PINN）以预测意大利面桥的载荷", "title_en": "Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction", "authors": "Omer Jauhar Khan,Sudais Khan,Hafeez Anwar,Shahzeb Khan,Shams Ul Arifeen", "background": "物理感知神经网络（PINNs）在结构工程任务中受到了广泛关注，特别是在有限数据的情况下，它们能够嵌入物理法则到深度学习模型中。本文利用PINNs来预测小型意大利面桥的重量，这有助于理解简化结构模型中的载荷极限和可能的失效模式。为提升模型性能，作者将物理约束融入预测模型中。研究团队通过手动或计算机视觉方法收集输入到模型的结构参数，数据集中包括15座真实桥梁，并扩充至100个样本，最佳模型的$R^2$得分为0.9603，平均绝对误差（MAE）为10.50单位。", "innovation": "提出了一个名为物理感知柯尔莫哥洛夫-ARNOLD网络（PIKAN）的新架构，它结合了泛函近似理论和物理洞察。通过引入PIKAN，该研究试图进一步提高PINNs在结构参数预测中的表现。", "conclusion": "研究结果表明，即使在数据有限的情况下，PINNs也能够提供结构重量的可靠估计，并有助于轻质桥梁设计的早期失效分析。研究还提供了一个基于Web的界面，供用户输入参数和获取预测结果。所有相关数据和代码可在指定网址获取。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25791", "html_url": "https://arxiv.org/abs/2510.25791", "title": "推理的动态特性：链式思考如何塑造Transformer的学习？", "title_en": "The Kinetics of Reasoning: How Chain-of-Thought Shapes Learning in Transformers?", "authors": "Zihan Pengmei,Costas Mavromatis,Zhengyuan Shen,Yunyi Zhang,Vassilis N. Ioannidis,Huzefa Rangwala", "background": "链式思考（CoT）监督可以显著提升Transformer的表现，但模型如何学习遵循和从CoT中获益的具体机制仍不清楚。本文通过预训练Transformer进行可调算法复杂度和可控数据组成的符号推理任务，来研究这些学习动态过程，特别是在理解模型泛化方面的作用。", "innovation": "1. 引入了一种动力学建模框架来理解Transformer的学习过程；\n2. 揭示了推理痕迹的忠实性随训练动态变化的过程；\n3. 证明了CoT在加速泛化方面的作用，但无法克服高算法复杂度的任务；\n4. 通过实验和模型，展示了CoT对内部Transformer计算机制的机械性改变。", "conclusion": "本文通过动力学建模揭示了CoT对Transformer学习过程的影响，发现了CoT监督下推理痕迹忠实性随训练动态变化的现象，展示了CoT在加速泛化方面的效果，但对复杂任务的适应性有限，并强调了内部计算机制的改变。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25785", "html_url": "https://arxiv.org/abs/2510.25785", "title": "HiMAE: 层次蒙版自编码器在可穿戴时间序列中发现分辨率特定结构", "title_en": "HiMAE: Hierarchical Masked Autoencoders Discover Resolution-Specific Structure in Wearable Time Series", "authors": "Simon A. Lee,Cyrus Tanade,Hao Zhou,Juhyeon Lee,Megha Thukral,Minji Han,Rachel Choi,Md Sazzad Hissain Khan,Baiying Lu,Migyeong Gwak,Mehrab Bin Morshed,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Subramaniam Venkatraman,Sharanya Arcot Desai", "background": "可穿戴传感器提供了丰富的生理时间序列数据，但其预测效用的原理仍然不清楚。作者假设时间分辨率为表示学习提供了基本的轴线，不同临床和行为结果依赖于不同尺度的结构。作者提出了一种层次蒙版自编码器（HiMAE）框架，该框架结合了蒙版自编码和分层卷积编码解码器，可以产生多尺度嵌入，从而系统地评估哪些时间尺度携带预测信号，将时间分辨率为超参数转换为解释性的探针。", "innovation": "提出了HiMAE（层次蒙版自编码器）框架，该方法结合了蒙版自编码和层次卷积编码解码器，产生多尺度嵌入，能够系统地评估哪些时间尺度携带预测信号，将时间分辨率为超参数转换为解释性探针。HiMAE在分类、回归和生成基准上始终优于压缩时间尺度的状态最先进基础模型，且其模型大小小得多。此外，HiMAE高效紧凑，可以在智能手表上完全运行，并能在智能手表级CPU上实现亚毫秒级的推理，成为边缘推理的有效方法，且可以作为对分辨率敏感结构的发现工具。", "conclusion": "HiMAE结合了高效自监督学习方法和对可穿戴健康中分辨率敏感结构的发现工具，共同奠定了HiMAE作为电阻自监督学习方法和分辨率敏感结构的研究工具的基础。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25800", "html_url": "https://arxiv.org/abs/2510.25800", "title": "FreIE：时间序列任务中神经网络低频频谱偏见", "title_en": "FreIE: Low-Frequency Spectral Bias in Neural Networks for Time-Series Tasks", "authors": "Jialong Sun,Xinpeng Ling,Jiaxuan Zou,Jiawen Kang,Kejia Zhang", "background": "时间序列数据固有的自相关性给多变量时间序列预测带来了持续的挑战。近年来，广泛采用的方法是通过频率域信息协助长期预测任务。许多研究者独立观察到，在神经网络中存在频谱偏见现象，即模型倾向于首先拟合低频信号而不是高频信号。然而，这些观察往往归因于特定的模型架构设计，而不是将这一现象视为所有模型的普遍特性。为了统一理解长期时间序列预测中的频谱偏见现象，我们进行了广泛的实证实验，测量了现有主流模型中的频谱偏见。研究结果表明，几乎所有模型都表现出这一现象。", "innovation": "我们提出了FreLE（Frequency Loss Enhancement）算法，通过显性和隐性频率正则化增强模型泛化能力。FreLE是一个插即用模型损失函数单元，大量实验已经证明其优越性能。", "conclusion": "我们的研究发现几乎所有的现有模型都存在频谱偏见现象。通过提出的FreLE算法，我们显著提升了模型的泛化能力，并证明了其在广泛实验中的优越性能。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25788", "html_url": "https://arxiv.org/abs/2510.25788", "title": "低数据域中高能分子的SHA-256融合嵌入驱动生成建模", "title_en": "SHA-256 Infused Embedding-Driven Generative Modeling of High-Energy Molecules in Low-Data Regimes", "authors": "Siddharth Verma,Alankar Alankar", "background": "高能材料（高能材料（HEMs））对于推进和防御领域至关重要，但其发现仍受到实验数据有限和测试设施访问受限的限制。在低数据情况下，传统的分子生成方法难以有效维护分子多样性和新颖性。", "innovation": "本文提出了一种创新的方法，通过结合长短期记忆（LSTM）网络进行分子生成和注意力图神经网络（Attentive GNN）进行性质预测，构建了一个动态融合的嵌入空间策略，将固定SHA-256嵌入与部分可训练表示相结合，从根本上改变了分子输入空间的代表基础，在无需预训练的情况下，生成器实现了67.5%的有效性和37.5%的新颖性。所生成的分子库与训练集的平均塔内托系数为0.214，表明框架能够生成具有广泛化学空间的新颖分子。", "conclusion": "方法成功地在有限的数据条件下生成了高能分子，生成的分子库具有较高的多样性和新颖性，其中37种新的超级爆炸物被探测，其预测的爆炸速度超过9 km/s，展示了该方法的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25796", "html_url": "https://arxiv.org/abs/2510.25796", "title": "在大型按需拼车系统中使用基于仿真实验的强化学习进行非短视匹配和再平衡", "title_en": "Non-myopic Matching and Rebalancing in Large-Scale On-Demand Ride-Pooling Systems Using Simulation-Informed Reinforcement Learning", "authors": "Farnoosh Namdarpour,Joseph Y. J. Chow", "background": "拼车是一种乘客共享乘车的服务，能够降低乘客和运营商的成本，减少交通拥堵和环境影响。然而，现有的拼车服务存在短视决策的问题，未能考虑长期效果。本文在此背景下，利用基于仿真实验的强化学习方法解决了这一问题，并提出了非短视匹配策略和闲置车辆再平衡策略，以优化拼车服务的效率和成本。", "innovation": "本文的创新在于通过将拼车仿真嵌入强化学习机制中，实现了非短视决策，解决了现有拼车系统存在的短视决策问题。此外，提出了一种补充策略来平衡闲置车辆，通过在模拟经验上使用n步时差学习，得到了时空状态价值，评价了非短视策略的有效性。这种方法不仅提高了服务效率，还减少了车辆闲置等待时间和乘客乘车时间，降低了运营车队规模，带来了显著的成本节约。", "conclusion": "通过对大规模按需拼车系统的匹配和再平衡策略进行模拟和学习，本文方法有效提高了服务率（最高可达8.4%），减少了乘客等待时间和乘车时间，降低了运营车队规模超过25%，显著减少了成本，同时提高了服务效率，验证了非短视决策策略和再平衡策略的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25798", "html_url": "https://arxiv.org/abs/2510.25798", "title": "MemEIC：迈向连续和组合的知识编辑", "title_en": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing", "authors": "Jin Seong,Jiyun Park,Wencke Liermann,Hongseok Choi,Yoonji Nam,Hyun Kim,Soojong Lim,Namhoon Lee", "background": "由于信息的动态性质，需要不断更新大型跨模态语言模型（LVLM）。尽管最近的知识编辑技术已经暗示了潜在的发展方向，但它们往往集中在单独编辑一种模态（视觉或语言），没有考虑LVLM固有的跨模态特性和知识更新的连续性，从而可能导致编辑效果欠佳。现有的编辑方法忽视了模态间交互和持续知识完善的需求，这使得现有的编辑结果不尽如人意。", "innovation": "我们提出了一种名为MemEIC的新方法，用于大型跨模态语言模型（LVLM）的连续和组合知识编辑（CCKE）。MemEIC可以通过顺序编辑视觉和文本知识，实现了跨模态编辑。该方法集成了混合外部-内部编辑器，其中包括用于跨模态证据检索的双外部记忆和便于每个模态独立参数更新的双重LoRA适配器，以及一个脑启发的知识连接器，该连接器在组合推理时被选择性激活，以整合来自不同模态的信息。", "conclusion": "实验表明，MemEIC在回答复杂跨模态问题方面有显著的性能提升，并有效保留了之前的编辑结果，从而成为LVLM中CCKE的新基准。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25793", "html_url": "https://arxiv.org/abs/2510.25793", "title": "多代理系统中的自适应偏置学习和最优信息组合", "title_en": "Optimal Information Combining for Multi-Agent Systems Using Adaptive Bias Learning", "authors": "Siavash M. Alamouti,Fay Arjomandi", "background": "现代多代理系统，从监控关键基础设施的传感器网络到聚合人类智能的众包平台，其性能可能因环境条件下的系统性偏差而严重下降。现有方法要么忽略了这些偏差，导致决策不理想；要么要求昂贵的校准程序，这在实践中往往不可行。这种性能差距具有实际影响：不准确的环境监控、不可靠的金融预测和人类判断的错误聚合。本文探讨了在何种情况下可以学习并纠正这些未知偏差以恢复近乎最优的性能，以及在何种情况下这种学习是徒劳的这一基本问题。", "innovation": "本文构建了一个理论框架，将偏差分解为可学习的系统性成分和无法减少的随机成分，引入了可学习比率的概念，即偏差方差中有多少可以从可观测协变量预测。此比率确定了对于特定系统而言，偏差学习是否值得投资。作者证明了能够实现的性能提升受此可学习比率的基本限制，这为系统设计师提供了关于何时投资偏差学习而不在于简单方法的定量指导。基于此理论，提出了一种自适应偏置学习和最优组合（ABLOC）算法，通过迭代学习校正偏置和优化组合权重来保证收敛到理论限值。实验验证表明，高可学习比率系统的性能提升显著（在我们的例子中达到了理论最大改进的40%-70%），而低可学习比率系统的效益微乎其微，从而验证了我们的诊断准则适用于实际部署决策。", "conclusion": "本文提出了一种自适应偏置学习和最优组合（ABLOC）算法，通过反复学习偏置修正变换和优化组合权重，保证收敛到理论限值。实验结果表明，对于高可学习比率的系统可以显著提升性能，而低可学习比率的系统则几乎没有收益，从而验证了诊断准则在实际部署决策中的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25818", "html_url": "https://arxiv.org/abs/2510.25818", "title": "ScaleDiff：通过高效且模型无关的扩散过程实现更高分辨率的图像合成", "title_en": "ScaleDiff: Higher-Resolution Image Synthesis via Efficient and Model-Agnostic Diffusion", "authors": "Sungho Koh,SeungJu Cha,Hyunwoo Oh,Kwanyoung Lee,Dong-Jin Kim", "background": "文本到图像的扩散模型在生成超出训练分辨率的图像时往往会表现出性能下降的问题。最近的一些不依赖训练的方法虽能减轻这一限制，但往往需要大量的计算资源，或者与最新的扩散变换器模型不兼容。", "innovation": "本文介绍了一种名为ScaleDiff的模型通用且高效的框架，能够在无需额外训练的情况下扩展预训练的扩散模型的分辨率。其核心组件是邻域块注意力(NPA)，这是一种减少自注意力层中计算冗余的高效机制。此外，还引入了潜在频率混合(LFM)以更好地生成细节，并应用了结构引导以增强去噪过程中的全球结构。", "conclusion": "实验结果显示，ScaleDiff在U-Net和扩散变换器架构上，无论是图像质量还是推理速度，都达到了训练自由方法的最前沿。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS: 通过自我蒸馏偏好导向式冷启动解耦多模态学习", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "最近，具有可验证奖励的强化学习（RL）推动了一系列“MLLM-r1”方法，将RL带给了视觉语言模型。大多数代表性方法从冷启动开始，通常采用监督微调（SFT），在初始化策略后再进行RL。但基于SFT的冷启动方法结合任务解决和输出格式的推理模式可能导致指令式过拟合，减弱了离分布泛化能力，最终影响了下游的RL效果。本文从训练方法和数据构建两个角度重新审视了冷启动问题，并引入了泛化因子（GF）系数来量化不同方法下的泛化能力。实验研究发现，基于偏好训练的方法（如DPO）优于基于SFT的冷启动方法。", "innovation": "提出了SPECS方法（Self-distilled, Preference-based Cold Start框架），通过自我蒸馏生成内省偏好数据对，避免依赖大型导师或手动注释；首选基于偏好的训练，关注浅层、可转移的格式、结构、风格标准，而非记住了内容；并将可验证奖励的RL留给后续处理，以获得深度推理结果。这种方法在多个跨模态基准测试中优于强基线，显著提高了MEGA-Bench和MathVista的表现，并减少了分布内“卡顿”、改善了探索、稳定了训练，提升了性能上限。", "conclusion": "本文提出的SPECS框架在多个跨模态基准测试中表现出了持续的性能提升，特别是在MEGA-Bench和MathVista上的表现尤为显著，并且该框架还能解决分布内卡顿问题，提高探索性，增强训练稳定性，提升整体性能上限。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25808", "html_url": "https://arxiv.org/abs/2510.25808", "title": "PRESTO: Preimage-Informed Instruction Optimization for Prompting Black-Box LLMs", "title_en": "PRESTO: Preimage-Informed Instruction Optimization for Prompting Black-Box LLMs", "authors": "Jaewon Chu,Seunghun Lee,Hyunwoo J. Kim", "background": "大型语言模型（LLMs）在多个领域取得了显著的成功，这主要得益于它们强大的指令遵循能力。因此，人们越来越多地关注如何优化这些黑盒模型（其内部参数无法访问，但因性能强大而广泛使用）的指令。然而，最近的方法是使用白盒LLMs通过优化软提示生成候选指令，但这种方法可能会导致查询冗余，因为不同的软提示可能会映射到相同的指令。尽管先前的研究将这种多对一的映射视为阻碍优化效率的结构，本文重新定义为一种有用的先验知识，可以加速优化过程。", "innovation": "本文提出了PREimage-informed inSTruction Optimization（PRESTO）框架，这是首次利用软提示的预图像结构来高效优化黑盒LLMs的指令。该框架包含三个关键组件：（1）分数共享，（2）基于预图像的初始化，（3）分数一致性正则化。通过利用预图像，PRESTO在相同的查询预算下能够更有效地获取14倍的评分数据，从而实现更高效的优化。", "conclusion": "实验结果表明，PRESTO在33个指令优化任务中的性能优于先前的方法。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25803", "html_url": "https://arxiv.org/abs/2510.25803", "title": "Mixture-of-Experts Operator Transformer for Large-Scale PDE Pre-Training", "title_en": "Mixture-of-Experts Operator Transformer for Large-Scale PDE Pre-Training", "authors": "Hong Wang,Haiyang Xin,Jie Wang,Xuanze Yang,Fei Zha,Huanshuo Dong,Yan Jiang", "background": "预训练在解决神经算子在偏微分方程（PDE）问题上的数据稀缺性和性能限制方面已经显示出有效性。然而，由于偏微分方程数据集在方程类型上的异质性，混合训练导致了高误差。此外，密集型预训练模型通过增加网络宽度或深度来放大参数，导致显著的推理成本。这些挑战限制了预训练技术的进一步应用和发展。", "innovation": "本文提出了一个名为MoE-POT（Mixture-of-Experts Pre-training Operator Transformer）的新颖稀疏激活架构，该架构能够高效地扩展参数，同时控制推理成本。该模型采用了分层路由器门控网络，在推理时动态选择4个路由专家中的16个专家网络，使模型能够专注于特定方程的特征。此外，还集成2个共享专家，以提取PDE的共同属性并减少路由专家之间的冗余。最终输出是所有激活专家结果的加权平均值。", "conclusion": "我们使用从3000万到5亿参数的MoE-POT模型对6个公开的PDE数据集进行了预训练。与现有使用1.2亿参数的未经处理的专家模型相比，9000万激活参数的MoE-POT模型在零样本误差上实现了高达40%的降低。此外，我们进行了可解释性分析，表明数据集类型可以从路由器门控网络的决定中推断出来，这证明了MoE架构的合理性与有效性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25926", "html_url": "https://arxiv.org/abs/2510.25926", "title": "借助任务导向表示的杂乱数据池中的积极学习", "title_en": "Active Learning with Task-Driven Representations for Messy Pools", "authors": "Kianoosh Ashouritaklimi,Tom Rainforth", "background": "积极学习在处理杂乱且未整理的数据池中特别有用，这些数据池中的数据点与目标任务的相关性各不相同。当前最先进的积极学习方法主要依赖于使用固定且未监督的数据池表示，并集中在修改获取函数上。然而，这种模型设置可能会削弱其在处理杂乱数据池中的有效性，因为这种表示可能会丢失对任务重要的信息。", "innovation": "该研究提出了使用在积极学习过程中定期更新的任务驱动表示。引入了两种具体的学习这些表示的战略，一种是直接学习半监督表示，另一种是通过监督微调初始未监督表示。实验结果显示，这两种方法显著提高了实证性能，优于使用未监督或预训练表示。", "conclusion": "通过使用任务驱动的表示来更新数据池，本研究有效解决了传统方法在处理杂乱数据池中的问题，并显著提高了积极学习的性能。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25892", "html_url": "https://arxiv.org/abs/2510.25892", "title": "图拓扑感知的主动学习", "title_en": "Topology-Aware Active Learning on Graphs", "authors": "Harris Hardiman-Mostow,Jack Mauro,Adrien Weihs,Andrea L. Bertozzi", "background": "本文提出了一种图拓扑方法，以解决在有限标签预算下探索与利用之间的核心挑战。通过平衡形式曲率（BFC）的核设立计算方法生成一个核心子集，反映了图的簇结构，并提出了一种基于BFC的动态策略，在主动学习过程中自动转换探索与利用的阶段。同时，引入了局部图重布接策略来提高标签传播效率，保持稀疏性。", "innovation": "提出了基于平衡形式曲率（BFC）的主动学习中的核设立计算方法，该方法不仅在主动学习中引入了一种数据驱动的停止标准，还提出了利用BFC来动态触发探索与利用之间的转换。此外，提出了一种局部图重布接策略，以提高标签传播效率并保持稀疏性。", "conclusion": "实验结果表明，本文提出的方法在多种基准分类任务中，特别是在低标签率下，总体上优于现有的基于图的半监督学习基准方法。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25924", "html_url": "https://arxiv.org/abs/2510.25924", "title": "使用代理变量转移因果效应", "title_en": "Transferring Causal Effects using Proxies", "authors": "Manuel Iglesias-Alonso,Felix Schur,Julius von Kügelgen,Jonas Peters", "background": "研究多域环境中的因果效应估计问题，存在未观测到的共因，并且因果效应在不同领域之间会发生变化。假设具有隐藏共因的代理变量，并且所有变量为离散或分类类型，提出在仅观察代理变量的目标域中的因果效应估计方法。理论证明在这些条件下因果效应可识别，即使处理变量和响应变量为连续的。介绍两种估计技术，证明了它们的一致性，并推导了置信区间。通过模拟研究和实际案例研究支持理论结果，实际案例研究了网站排名对消费者选择的因果效应。", "innovation": "提出了一种在仅观察代理变量的目标域中估计因果效应的方法，即使处理变量和响应变量为连续的也证明了可识别性。介绍了两种估计技术，并证明了它们的一致性，推导了置信区间。", "conclusion": "证明了在存在连续变量的情况下即使在未观测到共因的条件下因果效应仍然是可识别的，并通过模拟研究和现实世界应用验证了研究成果的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25952", "html_url": "https://arxiv.org/abs/2510.25952", "title": "Modular Linear Tokenization (MLT)", "title_en": "Modular Linear Tokenization (MLT)", "authors": "Tcharlies Schmitz", "background": "传统的编码方法如哈希或独热编码在处理高基数的类别标识符时，通常会失去一一对应的关系，可能导致信息丢失和额外的数据膨胀。因此，研究者们需要一种既能保持一一对应关系又具有较高编码效率的方法。", "innovation": "提出了Modular Linear Tokenization (MLT)，这是一种基于有限域上的模算术和可逆线性变换的新型编码技术。MLT方法不仅保持了一对一的映射关系，还允许控制维度和具有良好的计算可扩展性，即使对于数百万的标识符也是如此。实验结果表明，MLT在预测性能上与监督嵌入相当，但所需的参数数量和训练成本显着降低。", "conclusion": "实验证明了MLT在保留一一对应关系和优化参数使用方面的有效性。MLT已被开源，并可从PyPI和GitHub获取，为大规模数据处理提供了新的解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25867", "html_url": "https://arxiv.org/abs/2510.25867", "title": "MedVLSynther: 通过生成器-验证器大模型合成医疗文档中的高质量视觉问答", "title_en": "MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs", "authors": "Xiaoke Huang,Ningsen Wang,Hui Liu,Xianfeng Tang,Yuyin Zhou", "background": "大型多模态模型(LMMs)越来越多地回答需要在图像和文本之间联合推理的医学问题，但训练通用医学问答系统受到缺乏大量且易于获取的高质量语料库的限制。MedVLSynther 提供了一种依据标准引导的生成器-验证器框架，能够直接从开放生物医学文献中合成高质量的多项选择型VQA问题，结合图表、图表注释和文本引用进行生成。一个分阶段的验证器确保问题和答案满足关键规则，并在验证通过后接受。将此流水线应用于PubMed Central，生成了13,087个审查过的问答题和14,803张涉及13种成像模态和28个解剖区域的图像的MedSynVQA数据集。使用验证奖励进行强化学习训练的开放式权重LMMs在六个医学VQA基准测试中的准确率提高了，达到了平均55.85（3B）和58.15（7B），在VQA-RAD和PathVQA上分别达到最高77.57和67.76，优于现有的医疗LMMs。消融实验验证了生成和验证的必要性，更多的验证数据始终有助于提高准确率。针对污染分析未发现来自评估套件的泄漏。整个过程基于开放文献和开放式权重模型，提供了审核、可重现和隐私保护的路径，用于生成可扩展的医学VQA训练数据。", "innovation": "MedVLSynther采用了生成器-验证器框架，直接从开放生物医学文献中生成高质量的VQA问题，从而解决了医学VQA系统训练数据不足的问题。通过验证器多阶段验证和机器检查方法确保生成的VQA问题的高质量和准确性，在医学VQA问题的多个基准测试中表现突出，优于现有的多模态模型。此外，通过严格的验证流程防止了数据泄漏，并提供了一个安全且可验证的训练数据生成方法。", "conclusion": "MedVLSynther 合成了可扩展的、高质量的医学VQA训练数据，该数据由生成器-验证器框架从开放的生物医学文献中生成。此方法显著提高了医学VQA系统的性能，并提供了审核和隐私保护的机制。研究结果证明，通过指导生成和验证的双重过程可以大幅提升医学VQA训练数据的质量，增强模型的鲁棒性和准确性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25954", "html_url": "https://arxiv.org/abs/2510.25954", "title": "GeoFMs数据在预测卫生设施项目输出中的应用与验证——马拉维案例研究", "title_en": "Application and Validation of Geospatial Foundation Model Data for the Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi", "authors": "Lynn Metz,Rachel Haggard,Michael Moszczynski,Samer Asbah,Chris Mwase,Patricia Khomani,Tyler Smith,Hannah Cooper,Annie Mwale,Arbaaz Muslim,Gautam Prasad,Mimi Sun,Tomer Shekel,Joydeep Paul,Anna Carter,Shravya Shetty,Dylan Green", "background": "在低中收入国家（LMICs），常规健康数据的可靠性和完整性因报告延迟和覆盖不全受到限制。因此，需要探索新的数据来源和分析方法。地理基础模型（GeoFM）通过整合时空和行为数据，提供了一种将这些数据转换为数学嵌入，从而高效应用于下游预测任务的方法。", "innovation": "研究了三种GeoFM嵌入源——Google人口动态基础模型（PDFM）、来自卫星图像的谷歌AlphaEarth和移动电话详细通话记录（CDR），用于模拟马拉维15项常规健康项目输出，并与传统的地理插值方法进行了比较。结果显示，基于嵌入的方法在13项中的15项测试指标中优于基线地理统计方法。集成所有三个嵌入源的多GeoFM模型提供了最稳健的预测，实现了如人口密度（0.63）、新HIV病例（0.57）和儿童接种疫苗（0.47）等指标的5折交叉验证R2平均值分别为0.63、0.57和0.47，以及测试集R2分别为0.64、0.68和0.55。", "conclusion": "结果表明，GeoFM嵌入在低收入国家卫生和人口指标的预测中提供了一种适度的改进。我们得出结论，多种GeoFM源的集成是补充和强化受限常规健康信息系统的一个有效且有价值的方法。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25889", "html_url": "https://arxiv.org/abs/2510.25889", "title": "$\boldsymbol{\texttt{RL}}$: 在线RL微调用于基于流的视觉-语言-行动模型", "title_en": "$π_\\texttt{RL}$: Online RL Fine-tuning for Flow-based Vision-Language-Action Models", "authors": "Kang Chen,Zhihao Liu,Tonghe Zhang,Zhen Guo,Si Xu,Hao Lin,Hongzhi Zang,Quanlu Zhang,Zhaofei Yu,Guoliang Fan,Tiejun Huang,Yu Wang,Chao Yu", "background": "视觉-语言-行动（VLA）模型能够通过多模态输入理解和执行复杂任务。尽管近期研究探索了使用强化学习（RL）来自动化大规模监督微调（SFT）的数据收集过程，但在流程化的VLA（例如$\boldsymbol{\textit{\textpi}_0$和$\boldsymbol{\textit{\textpi}_{0.5}}$）中应用大规模RL仍然具有挑战性，尤其是在计算不可解的迭代去噪行动对数似然方面的挑战。研究者在面对这一挑战时，提出了$\boldsymbol{\textit{\textpi}_{\texttt{RL}}}$框架，该框架用于在并行模拟中训练基于流的VLA模型。", "innovation": "研究人员提出了$\boldsymbol{\textit{\textpi}_{\texttt{RL}}}$框架，该框架包含两种RL算法：1）$\textit{Flow-Noise}$将去噪过程视为带有可学习噪音网络的离散时间MDP，实现了精确的对数似然计算；2）$\textit{Flow-SDE}$将去噪与智能体-环境交互相结合，形成了通过ODE-to-SDE转换来促进高效RL探索的两层MDP。实验通过在LIBERO和ManiSkill基准上进行评估，展示了当应用于LIBERO时，$\boldsymbol{\textit{\textpi}_{\texttt{RL}}}$能够将$\boldsymbol{\textit{\textpi}_0$和$\boldsymbol{\textit{\textpi}_{0.5}}$的SFT表现从57.6%和77.1%分别提升至97.6%和98.3%，在ManiSkill中，在320个并行环境中训练提高了$\boldsymbol{\textit{\textpi}_0$和$\boldsymbol{\textit{\textpi}_{0.5}}$的表现。这有力地证明了在线RL对于基于流的VLA模型的有效性。", "conclusion": "综上，$\boldsymbol{\textit{\textpi}_{\texttt{RL}}}$框架实现了显著的性能改进和更强的泛化能力，验证了在线RL在基于流的VLA模型中的有效性，展示了在线RL能够有效提升基于流的VLA模型在多任务学习中的表现。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25934", "html_url": "https://arxiv.org/abs/2510.25934", "title": "通过拓扑不变量的隐式感知实现鲁棒的GNN水印", "title_en": "Robust GNN Watermarking via Implicit Perception of Topological Invariants", "authors": "Jipeng Li,Yannning Shen", "background": "图形神经网络（GNNs）是宝贵的知识产权，但许多水印依赖于易受常规模型修改影响的后门触发器，这导致所有权模糊。本文探讨了这种问题并提出了解决方案，旨在通过将所有权与模型对图不变量的隐式感知相连，实现无需触发器的黑盒验证，同时对任务影响极小。该方法在多种节点和图分类数据集及网络模型下展示出了优秀的性能，并且在不结构化剪裁、微调和后训练量化等操作中保持了其鲁棒性。", "innovation": "提出了一种新颖的水印方法——InvGNN-WM，该方法将所有权与模型对图不变量的隐式感知绑定，以避免使用传统的后门触发器，实现了无需触发器的、黑盒验证，并且对任务完成度的影响极小。通过一个轻量级头预测由所有者私有载体集上的标准化代数连通性，一个敏感符号解码器输出位，以及校准门限以控制误报率，该方法在多个数据集和模型下展示了其优势，强健性显著优于基于触发器和压缩的基线方法。该方法同样经受住了知识蒸馏（KD）等方法的测试，其中单纯的KD会削弱标记效果，但带有水印损失的KD等方法则可以恢复其标记效果。此外，该方法还提供了不可感知性和鲁棒性的保障，并且证明了完全移除标记是NP完全问题。", "conclusion": "研究表明，InvGNN-WM方法对于多种GNN模型和不同数据集具有优异的鲁棒性和准确性。即使在模型修改和其他攻击手段下，该方法依然能够保持其有效性。为进一步提高GNN模型的知识产权保护提供了新的思路和方法。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25962", "html_url": "https://arxiv.org/abs/2510.25962", "title": "无数据训练神经网络的研究", "title_en": "On the Dataless Training of Neural Networks", "authors": "Alvaro Velasquez,Susmit Jha,Ismail R. Alkhouri", "background": "本文探讨了在没有训练数据的情况下使用神经网络进行优化的问题。研究指出，尽管全连接网络（MLP）在几十年前曾被用于解决线性程序，但近年来由于其在多种应用中的优良表现，如组合优化、逆问题和偏微分方程，这一方法重新引起了关注。无数据环境下进行神经网络训练面临的挑战包括数据驱动学习方法的发展不充分，以及在医学影像重建等应用中训练数据量有限的问题。文章基于问题实例的编码方式，将无数据环境分为两种变体：架构无关的方法和架构特定的方法，从而对该领域的研究进行了分类和定义。文章还讨论了无数据神经网络（dNN）设置与其他相关概念，如零样本学习、一次学习、优化中的提升和超参数化之间的相似性和区别。", "innovation": "文章重新审视了数据驱动学习方法的发展不足和训练数据有限的问题，提出了无数据环境下使用神经网络进行优化的方法，并将其分为架构无关和架构特定两种方法。此外，文章还探讨了dNN设置与其他相关概念之间的联系和区别，提供了对该领域的深入理解。", "conclusion": "文章定义了无数据环境，并区分了两种基于问题实例编码方式的方法。对于dNN设置和其他相关概念，文章探讨了它们之间的相似性和区别。这表明，无数据环境下的神经网络训练在应用到组合优化、逆问题和偏微分方程等领域时具有巨大潜力。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25993", "html_url": "https://arxiv.org/abs/2510.25993", "title": "高效预测编码网络的在线学习：利用时间相关性", "title_en": "Efficient Online Learning with Predictive Coding Networks: Exploiting Temporal Correlations", "authors": "Darius Masoum Zadeh-Jousdani,Elvin Hajizada,Eyke Hüllermeier", "background": "边缘环境中的机器人系统需要高效的学习算法，能够持续适应变化的环境并处理流式传感数据。传统的反向传播算法虽然有效，但违背了生物学可实现原则，并可能在持续学习场景中表现不佳。预测编码框架提供了生物学上可行的替代方案，具有局部，海伯式更新规则，使其适用于类脑硬件的实现。然而，预测编码的主要局限是训练过程中需要多次推理迭代，导致计算开销增加。", "innovation": "文章提出了预测编码网络的时域平滑（PCN-TA），它通过跨时间帧保持隐状态来减少计算需求，同时保持学习性能。实验表明，与反向传播相比，PCN-TA的权重更新减少了10%，与基线预测编码网络相比，推理步骤减少了50%。这种方法不仅大大减少了计算开销，还为边缘部署和资源受限的机器人系统提供了实时适应支持。", "conclusion": "我们的方法通过减少计算开销和权重更新次数，使边沿部署中的在线学习更加高效。此外，由于其生物启发性质，PCA-N网络也是未来类脑硬件实现的有力候选者，能够实现高效的边缘学习。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25983", "html_url": "https://arxiv.org/abs/2510.25983", "title": "正确进行对比预测编码以进行互信息估计", "title_en": "Contrastive Predictive Coding Done Right for Mutual Information Estimation", "authors": "J. Jon Ryu,Pavan Yeddanapudi,Xiangxiang Xu,Gregory W. Wornell", "background": "InfoNCE 目标最初用于对比表示学习，尽管与互信息 (MI) 有间接联系，但因其流行性成为 MI 估计的常用选择。然而，该论文指出，InfoNCE 并不能被视为有效的 MI 估计器，并且提出了一种简单的修改，称为 InfoNCE-anchor，以实现更准确的 MI 估计。此外，作者通过使用适当评分规则，将这种框架进行了进一步的推广，涵盖了 NCE、InfoNCE 和 f-散度变体等对比目标，揭示出 InfoNCE-anchor 是一个特殊情况。实验证明，使用对数评分时，InfoNCE-anchor 可达到最准确的 MI 估计，但在自我监督表示学习实验中，锚点并未改善下游任务的表现。", "innovation": "提出了将 InfoNCE 转变为准确的 MI 估计器的方法，即 InfoNCE-anchor，通过引入辅助锚点类，使密度比率估计变得一致，并生成具有显着降低偏差的插值 MI 估计器。此外，作者通过适当评分规则推广了这种框架，将 InfoNCE-anchor 与其他对比目标统一在单一的原则性框架下。", "conclusion": "本文研究发现 InfoNCE-anchor 使用对数评分能达到最准确的 MI 估计，但在自我监督表示学习实验中，锚点并未提升下游任务的表现。这表明对比表示学习并非因其准确的 MI 估计而受益，而是学习结构化的密度比率。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25986", "html_url": "https://arxiv.org/abs/2510.25986", "title": "一种通用且简洁的可微优化框架", "title_en": "A General and Streamlined Differentiable Optimization Framework", "authors": "Andrew W. Rosemberg,Joaquim Dias Garcia,François Pacaud,Robert B. Parker,Benoît Legat,Kaarthik Sundar,Russell Bent,Pascal Van Hentenryck", "background": "约束优化问题是学习、控制和大规模决策系统中的关键组成部分。尽管如此，由于求解器的专业化和接口不匹配，其实用整合仍然具有挑战性。本文介绍了一种通用且简化的框架——更新后的链接地址-，该框架将建模和求导统一在Julia优化堆栈中，能够通过标准正则性假设下对KKT系统进行求导来计算平滑的、可能非凸程序的前向和后向模式解和目标敏感性。这种框架为用户提供了一个一流的、JuMP原生的参数为中心的API，用户可以声明命名参数并直接对它们进行求导——即使参数出现在多个约束和目标中——从而消除了系数级接口中脆弱的记账需求。", "innovation": "该框架提供了一种统一的方法来建模和求导约束优化问题，通过KKT系统求导来计算前向和后向模式的解和目标灵敏度。框架中的API使得用户可以直接对参数进行求导，即使参数在多个约束和目标中出现，也无需进行繁琐的记账。该框架还在电力市场的战略投标和端对端优化代理的Sobolev式训练中进行了演示，展示了其在大规模场景下的应用效果。", "conclusion": "总体而言，这些结果证明了可微优化可以在不偏离标准JuMP建模实践的同时，作为实验、学习、校准和设计的常规工具进行部署，同时保持对广泛求解器生态系统的访问。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26014", "html_url": "https://arxiv.org/abs/2510.26014", "title": "离散时间生存分析的双混合专家框架", "title_en": "Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis", "authors": "Hyeonjun Lee,Hyungseob Shin,Gunhee Nam,Hyeonsoo Lee", "background": "生存分析是用于建模感兴趣事件发生时间的任务，在临床和生物医学研究中有广泛应用。关键挑战在于建模患者异质性的同时，还要根据个体特性和时间动态适应风险预测。", "innovation": "本文提出了一种双混合专家（MoE）框架应用于离散时间生存分析。该方法结合了特征编码器MoE进行亚群意识表示学习以及使用患者特征和时间嵌入来捕捉时间动态的危险MoE。这种双MoE设计灵活地与现有的深度学习生存分析管道集成。在METABRIC和GBSG乳腺癌数据集上，该方法在测试集上一致地提高了性能，使时间依赖性C指数提高了0.04，并在与Consurv框架结合使用时进一步提高了性能。", "conclusion": "通过该双MoE框架，该方法能够在亚群中捕捉到更细粒度的信息，反映时间动态特征，从而提高生存分析的准确性和鲁棒性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26025", "html_url": "https://arxiv.org/abs/2510.26025", "title": "通过国际象棋之镜探索人机概念一致性", "title_en": "Exploring Human-AI Conceptual Alignment through the Prism of Chess", "authors": "Semyon Lomaso,Judah Goldfeder,Mehmet Hamza Erol,Matthew So,Yao Yan,Addison Howard,Nathan Kutz,Ravid Shwartz Ziv", "background": "研究探讨AI系统是否真正理解人类概念，还是仅仅模仿表层模式。通过分析达到国际象棋大师级水平的270M参数变压器，研究发现表层编码了中心控制和骑士据点等人间概念，然而较深层次的表征却偏离了人类思考，表现出较差的概念理解能力。为测试概念的稳健性而非单纯的记忆，研究引入了首个Chess960数据集，涵盖240个专家标注的6个战略概念的起始位置，在随机开局理论后，概念识别能力下降，揭示模型对记忆模式的依赖。", "innovation": "引入Chess960数据集，研究多层次的模型表征，在国际象棋场景中探索AI系统概念理解与人类策略一致性之间的矛盾，揭示了当前架构中性能优化与人类思考一致性之间的根本紧张关系。", "conclusion": "随着AI系统优化性能，其发展出越来越‘异化’的智能，这对需要真正人机协作的创意AI应用构成了重大挑战。研究表明，人类与AI的协作不仅需要技术上的进步，还需要AI系统具备更深层次的理解能力。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26000", "html_url": "https://arxiv.org/abs/2510.26000", "title": "Infrequent Exploration in Linear Bandits", "title_en": "Infrequent Exploration in Linear Bandits", "authors": "Harin Lee,Min-hwan Oh", "background": "研究了线性多臂老虎机中稀疏探索的问题，此问题在完全自适应探索策略（如UCB和Thompson Sampling，二者能够在每一个时间步骤中探索）和纯粹贪心策略（需要严格的数据多样性以确保成功）之间存在明显但被忽视的差距。连续探索在一些关键安全领域或成本较高的环境中可能是不切实际或不合道德的，而纯粹贪心策略在缺乏足够上下文多样性的条件下通常会失败。为了弥合这两个极端，我们提出了一种简单且实用的框架INFEX，该框架明确设计用于稀疏探索。INFEX根据给定的时间表执行基底探索策略，大部分时间选择贪心行为。尽管简单，我们的理论分析显示，只要探索频率超过对数阈值，INFEX就能实现与标准高效算法相匹配的实例依赖后悔，该框架具有通用性和模块化特性，能够无缝整合任何完全自适应探索方法，从而实现广泛适用性和易于采用。此外，通过将密集探索计算限制在稀疏的时间间隔，这种方法还可提高计算效率。经验评估证实了我们的理论发现，表明与现有方法相比，INFEX具有最先进的后悔表现和运行时间改进。", "innovation": "提出了INFEX框架来解决线性多臂老虎机中稀疏探索的问题。INFEX框架设计用于在稀疏探索的时间表上执行基底探索策略，大部分时间选择贪心行为。尽管简单，INFEX仍然能够实现与标准高效算法相匹配的实例依赖后悔，只要探索频率超过对数阈值。INFEX具有通用性和模块化特性，能够无缝整合任何完全自适应探索方法，提高计算效率，同时保持高效表现。", "conclusion": "INFEX框架通过限制密集探索计算到稀疏的时间间隔，提高了计算效率，同时保持高效表现。经验评估确认了INFEX的各项优势，表明它能够实现最先进的后悔表现和运行时间改进。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识蒸馏（KD）是一种有效的模型压缩方法，可以将知识从一个模型（教师模型）传递到另一个模型（学生模型）。然而，知识蒸馏对模型抵抗伪相关能力（这种能力在处理未见过的数据时会恶化模型性能）的影响仍被广泛忽视。这项研究探讨了知识蒸馏对学生模型转移去伪化能力（即从教师模型到学生模型）的效果，尤其是在自然语言推断（NLI）和图像分类任务上的影响。", "innovation": "研究通过广泛的实验揭示了几项关键发现：(i) 经过知识蒸馏后，模型的去伪化能力普遍受损；(ii) 训练去伪化的模型并不能从教师知识中受益；(iii) 尽管模型的整体鲁棒性可能在知识蒸馏后保持稳定，但不同偏见类型的显著变化仍然存在；(iv) 借助这些发现，研究提出了三种有效的方法以提高去伪化方法的可蒸馏性：高质量数据增强、迭代知识蒸馏和使用教师模型权重初始化学生模型。这是首次大规模研究知识蒸馏对去伪化和其内部机制的影响。", "conclusion": "我们的发现提供了对知识蒸馏如何运作的理解，以及如何设计更有效的去伪化方法的理解。这些方法有望改善去伪化方法的可传递性，并增强模型在未见过的数据上的表现。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26076", "html_url": "https://arxiv.org/abs/2510.26076", "title": "新金融：金融领域合成数据生成的新进展", "title_en": "New Money: A Systematic Review of Synthetic Data Generation for Finance", "authors": "James Meldrum,Basem Suleiman,Fethi Rabhi,Muhammad Johan Alibasa", "background": "合成数据生成技术为在机器学习应用中使用敏感的金融数据提供了前景广阔的方法。通过利用生成模型如生成对抗网络(GANs)和变分自编码器(VAEs)，可以创建出与真实金融记录保持统计属性一致但又减轻隐私风险和监管限制的人工数据集。尽管这个领域发展迅速，但目前缺少对该研究领域的综合分析。因此，文章对2018年以来的72篇关于合成金融数据生成的研究进行全面梳理和分析。", "innovation": "本文对合成金融数据生成的研究进行了系统性回顾和分析，涵盖了合成的金融信息类型、生成方法以及评估策略。研究指出，基于GAN的方法在生成时间序列市场数据和表格式信贷数据方面占主导地位。尽管有几种创新技术展现出提高真实性和隐私保护的潜力，但在隐私保护方面，研究仍缺乏稳健的评估。", "conclusion": "本文提供了生成技术、应用及评估方法的综合概述，指出了研究缺口，并为未来旨在开发金融领域的稳健、隐私保护的合成数据解决方案的研究提供了指导。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26083", "html_url": "https://arxiv.org/abs/2510.26083", "title": "Nirvana: 具有任务感知记忆机制的专门通用模型", "title_en": "Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism", "authors": "Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou", "background": "传统的大规模语言模型（LLM）结构，如Transformer、线性注意力和混合模型，没有利用由任务信息指导的专业记忆机制。这些模型未能在保持广泛能力的同时达到目标领域的专家级性能。", "innovation": "提出了一种名为Nirvana的专门通用模型（SGM），具有专业记忆机制、线性时间复杂度以及测试时的任务信息提取。Nirvana包括Task-Aware Memory Trigger（$Trigger$）和Specialized Memory Updater（$Updater$）两个组件。$Trigger$ 根据当前任务需求灵活调整记忆机制。$Updater$ 动态地根据 $Trigger$ 的引导记忆上下文，使模型能够适应领域转变。", "conclusion": "Nirvana 在多个自然语言建模基准上的性能与现有的LLM结构相当或更好。特别是在医疗任务中，Nirvana 能够通过轻量级的后训练提高磁共振成像（MRI）重建质量，并生成准确的初步临床报告。这证明了$Trigger$机制在特定领域的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26064", "html_url": "https://arxiv.org/abs/2510.26064", "title": "向量化的符号回归定律", "title_en": "Towards Scaling Laws for Symbolic Regression", "authors": "David Otte,Jörg K.H. Franke,Frank Hutter", "background": "符号回归（SR）旨在发现能够解释观测数据的潜在数学表达式。这有助于获得科学洞见，同时产生可以解释和推广的表格数据模型。尽管基于深度学习的SR最近在竞争方面已与遗传编程相匹敌，但规模的作用仍是未知数。本文围绕符号回归的基本原理展开研究。受到语言建模中缩放定律的启发，作者通过一个可扩展的端到端变压器管道和精心生成的训练数据，进行了首次关于符号回归缩放现象的系统性研究。实验发现，计算成本和验证损失以及解决率之间存在着明显的幂律趋势。进一步研究还确定了计算成本最优的超参数缩放：最佳批量大小和学习率随模型大小增长，并在大约15个标记到参数的比率时表现出最佳性能，随着计算成本增加而略显上升。", "innovation": "本文首次系统地研究了符号回归中的缩放定律，通过使用可扩展的端到端变压器管道和精心生成的训练数据，作者展示了符号回归性能很大程度上可预测，并识别了计算成本最优的超参数缩放。这些发现为训练下一代符号回归模型提供了重要的见解。", "conclusion": "本文的研究结果证明了符号回归表现可很大程度上由计算成本决定。在不同模型大小的五个不同规模和三个数量级的计算成本范围内，验证损失和解题率均表现出清晰的幂定律趋势。同时，还发现计算成本最优的超参数缩放：最佳批量大小和学习率随着模型大小的增长而增加，最佳标记到参数比率为大约15，在随着计算成本增加时有所上升。这些结果对于指导未来符号回归模型的研发具有重要意义。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26086", "html_url": "https://arxiv.org/abs/2510.26086", "title": "LLMBisect：使用全面多阶段管道破解错误定位障碍", "title_en": "LLMBisect: Breaking Barriers in Bug Bisection with A Comparative Analysis Pipeline", "authors": "Zheng Zhang,Haonan Li,Xingyu Li,Hang Zhang,Zhiyun Qian", "background": "传统的基于补丁的错误定位方法存在一些显著的障碍，例如，它们假设引起错误的提交（BIC）和补丁提交修改相同的函数，这个假设并不总是成立。此外，它们主要依赖于代码变化，实际上提交信息中包含大量与漏洞相关的信息。而且，这些方法基于简单的启发式方法，例如假设BIC初始化了补丁中删除的行，并缺乏对漏洞的逻辑分析。", "innovation": "本文提出了一种全新的多阶段管道方法，利用大型语言模型（LLMs）来：1. 完全利用补丁信息，2. 在上下文中比较多个候选提交，3. 通过一系列降选步骤逐步缩小候选范围。该方法显著提高了准确性，相比于最先进的解决方案提高了超过38%的准确率。此外，结果进一步证实了全面多阶段管道的作用，与基于LLM的基准方法相比，准确率提高了60%。", "conclusion": "我们的方法通过采用一个多阶段的全面管道，利用大型语言模型来处理代码和文本数据，显著地提高了错误定位的准确性。与现有的基于LLM的方法相比，我们的管道进一步提高了60%的准确性，显示出其优越性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26068", "html_url": "https://arxiv.org/abs/2510.26068", "title": "学习几何：通过度量优化构建自适应流形模型的框架", "title_en": "Learning Geometry: A Framework for Building Adaptive Manifold Models through Metric Optimization", "authors": "Di Zhang", "background": "传统的机器学习方法主要集中在参数优化上，这种方法在固定的几何空间中搜索最优参数。而本文提出了一种新的机器学习范式，将模型本身视作可以塑形的几何实体，通过优化流形上预定义拓扑的度量张量场来动态塑造模型空间的几何结构。", "innovation": "本文创新性地提出了一种基于度量优化的新框架，与传统的固定几何空间的参数优化方法不同，该框架通过优化流形上的度量张量场来改变模型空间的几何结构。该研究引入了一个变分框架来平衡数据保真度和流形内在几何复杂性的关系，其中数据保真度确保模型能够有效解释观察到的数据，而内在几何复杂性被用作正则化器，惩罚过于弯曲或不规则的几何形状，以促进简单模型的生成并防止过拟合。此外，该研究提供了一种基于离散微分几何的方法来解决这一无限维优化问题，并通过连续流形的离散化和边长参数化的度量张量实现了高效的优化。", "conclusion": "该框架为构造能够自主演化几何形状和拓扑结构的“超学习器”奠定了坚实的基础，并指出了其在科学模型发现和稳健表示学习等领域的广泛应用前景。该研究揭示了框架与广义相对论中的爱因斯坦-希尔伯特作用量之间的深刻类比，为“数据驱动几何”的概念提供了一个优雅的物理解释。研究表明，即使在固定拓扑的情况下，度量优化也比固定几何形状的模型提供了显著更强的表达能力。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26099", "html_url": "https://arxiv.org/abs/2510.26099", "title": "SAFE: 通过地球上的分层预测评估对AI天气评估的新方法", "title_en": "SAFE: A Novel Approach to AI Weather Evaluation through Stratified Assessments of Forecasts over Earth", "authors": "Nick Masi,Randall Balestriero", "background": "目前，在机器学习领域，模型性能评估通常是基于测试数据集中所有样本的平均损失，这在气象和气候领域等情况下相当于在地球上进行空间上的平均评估，没有考虑到人类发展和地理分布的非均匀性。论文提出了一种名为Stratified Assessments of Forecasts over Earth (SAFE) 的方法，旨在通过分层评估预测性能解决这个问题。SAFE将多种数据域结合，依据地理网格点的不同属性（如领土、全球次区域、收入和土地覆盖）进行分层，使得可以单独评估每个属性层面上的模型性能（如每个单一国家的准确性），从而揭示模型在全球不同区域间的性能差异。", "innovation": "提出了SAFE框架，它通过整合多种数据层面，划分为领土（通常为国家）、全球次区域、收入和土地覆盖（土地或水域）四个维度，使得能够对地球上不同地区的模型预测性能进行深入分析，并发现顶级AI天气预测模型在不同属性上存在预测能力的差距。这为后续通过分层评估模型预测公平性建立了基准，特别在不同气候变量的预测误差了不同预测模型的一致性差异。", "conclusion": "通过SAFE框架，首次探索了全球范围内各模型的最佳和最差表现，并明确指出了哪些模型更具公平性。SAFE框架是开源的，可用于未来相关领域的研究工作。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26089", "html_url": "https://arxiv.org/abs/2510.26089", "title": "网络约束下的多智能体车辆路径优化策略", "title_en": "Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle Routing", "authors": "Fazel Arasteh,Arian Haghparast,Manos Papagelis", "background": "城市道路网络中的交通拥堵导致了更长的出行时间和更高的排放，尤其是在高峰时段。最短路径优先（SPF）算法虽在静态网络中单辆车辆的路由问题上是优化的，但在动态、多车辆的环境中表现不佳，常常通过引导所有车辆走同一路径来加剧拥堵。因此，通过多智能体强化学习（MARL）框架来实现协调、基于网络的车队导航是一个重要的改进方向。", "innovation": "本文提出了一种基于多智能体强化学习的自适应导航（AN）模型，其中每个交叉路口智能体提供基于（i）局部交通和（ii）使用图注意力网络（GAT）建模的邻域状态的路由指导。为了在大型网络中提高可扩展性，提出了层次化枢纽自适应导航（HHAN），该模型将智能体仅分配到关键交叉路口（枢纽）。车辆在智能体控制下从枢纽到枢纽导航，而SPF负责解决每个枢纽区域内的微路由问题。HHAN采用受注意力机制指导的集中训练与分散执行（CTDE）框架，并结合局部拥堵和预测动态来实现流向感知状态特征，从而实现前瞻性导航。实验结果表明，AN在与SPF和学习基准比对应的平均旅行时间和100%的导航成功率方面优于SPF和学习基准。HHAN能够适应拥有数百个交叉路口的大规模网络，在交通拥堵时的最大改进率达到15.9%。", "conclusion": "这些发现强调了在网络约束下的MARL在智能交通系统中具有实现可扩展性、协调性和拥堵意识的导航策略的潜力。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26109", "html_url": "https://arxiv.org/abs/2510.26109", "title": "Do Not Step Into the Same River Twice: Learning to Reason from Trial and Error", "title_en": "Do Not Step Into the Same River Twice: Learning to Reason from Trial and Error", "authors": "Chenming Tang,Hsiu-Yuan Huang,Weijie Liu,Saiyong Yang,Yunfang Wu", "background": "最近，强化学习与可验证奖励（RLVR）大幅提升了大型语言模型（LLMs）的推理能力。然而，现有的RLVR方法仅基于LLMs自动生成的回复进行训练，受限于其初始能力，容易出现探索停滞现象，即LLMs无法解决更多训练问题，无法进一步从训练数据中学习。一些工作试图通过引入离策略解决方案来改善这一问题，但需要专家的外部指导，这在实际中难以获得。", "innovation": "本文提出了一种名为LTE的方法（Learning to reason from Trial and Error），它利用LLMs之前生成的错误答案及其过长的回复提示LLMs进行学习，无需任何外部专家指导。实验结果表明，LTE在六个数学基准测试中优于相对于策略优化（GRPO）方法，提升了LLMs的表现，特别是在Pass@1和Pass@k上分别提高了6.38和9.00。进一步分析还表明，LTE成功解决了探索停滞问题，并在训练过程中增强了利用与探索的效果。", "conclusion": "LTE方法通过利用LLMs生成的错误答案及其回复，有效解决了现有RLVR方法中的探索停滞问题，增强了LMLs的推理能力，并通过实验验证了其优越性，为未来语言模型的训练提供了新的思路。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26157", "html_url": "https://arxiv.org/abs/2510.26157", "title": "通过结构感知对齐弥合分子和文本描述之间的差距", "title_en": "Bridging the Gap Between Molecule and Textual Descriptions via Substructure-aware Alignment", "authors": "Hyuntae Park,Yeachan Kim,SangKeun Lee", "background": "分子和文本表示学习因其在增强化学信息理解方面的潜力而越来越受到关注。然而，现有的模型经常难以捕捉分子及其描述之间的微小差异，因为它们缺乏在分子次结构和化学短语之间学习细粒度对齐的能力。", "innovation": "我们引入了MolBridge，这是一种基于结构感知对齐的新颖分子-文本学习框架。MolBridge通过补充分子-描述配对，加入源自分子次结构和化学短语的额外对齐信号。MolBridge采用结构感知对比学习，并结合一种自我完善机制以过滤掉噪声对齐信号。", "conclusion": "实验结果表明，MolBridge能够有效捕捉细粒度对应关系，并在多种分子基准测试中优于最先进的基线，突显了结构感知对齐在分子-文本学习中的重要性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26184", "html_url": "https://arxiv.org/abs/2510.26184", "title": "基于博弈论时空强化学习框架的协作公共资源配置", "title_en": "A Game-Theoretic Spatio-Temporal Reinforcement Learning Framework for Collaborative Public Resource Allocation", "authors": "Songxin Lei,Qiongyan Wang,Yanchen Zhu,Hanyu Yao,Sijie Ruan,Weilin Ruan,Yuyu Luo,Huaming Wu,Yuxuan Liang", "background": "公共资源配置涉及高效分配城市基础设施、能源和交通运输等资源，以有效满足社会需求。然而，现有方法主要关注独立优化单个资源的移动，而不考虑其容量限制。为解决这一局限，本文提出了一个新问题：协作公共资源配置（CPRA），该问题明确考虑了容量限制和现实场景中的时空动态。为了解决CPRA，本文提出了一种新的框架——基于博弈论的时空强化学习（GSTRL）", "innovation": "本文的贡献有两个方面：1) 将CPRA问题形式化为潜在博弈，并证明潜在函数与最优目标之间不存在差距，为近似该NP难问题的纳什均衡提供了坚实的理论基础；2) 设计的GSTRL框架有效地捕捉了整体系统的时空动态特性。", "conclusion": "在两个实际数据集上评估了GSTRL，实验结果表明其性能优越。源代码在补充材料中提供。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26188", "html_url": "https://arxiv.org/abs/2510.26188", "title": "从住院患者医疗索赔数据预测所有原因再住院", "title_en": "Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients", "authors": "Avinash Kadimisetty,Arun Rajagopalan,Vijendra SK", "background": "降低可预防的再住院率是支付方、提供方和政策制定者在全国范围内提高医疗保健质量和降低费用的优先任务。再住院率被用于评估医院提供医疗服务的质量。本文通过使用逻辑回归、随机森林和支持向量机等机器学习技术，对健康索赔数据进行了分析，以识别预测所有原因再住院的关键人口统计和社会医疗因素。由于健康索赔数据维度高，文中使用主成分分析作为降维技术，用于建立回归模型。模型对比和评估使用了AUC（曲线下面积）指标。随机森林模型表现出最佳性能，其次是逻辑回归和支持向量机。", "innovation": "本文采用机器学习技术，特别是随机森林模型，对高维度的健康索赔数据进行分析，识别对预测所有原因再住院有重要影响的关键因素。通过主成分分析进行降维操作，并使用AUC进行模型性能评估。", "conclusion": "建立的模型可以用于识别导致再住院的关键因素，并帮助识别需要关注的患者以减少再住院的可能性，从而降低医疗成本并提高为患者提供的医疗服务的质量。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26146", "html_url": "https://arxiv.org/abs/2510.26146", "title": "maxVSTAR：具有闭环边缘模型适应性的最大化适应视觉引导CSI传感技术，用于稳健的基于CSI的人体活动识别", "title_en": "maxVSTAR: Maximally Adaptive Vision-Guided CSI Sensing with Closed-Loop Edge Model Adaptation for Robust Human Activity Recognition", "authors": "Kexing Liu", "background": "WiFi信道状态信息（CSI）基于人体活动识别（HAR）提供了一种无需设备的、隐私保护的智能环境感知解决方案。但在边缘设备上部署时，由于环境和硬件条件的变化，其识别性能会受到显著影响，即所谓的域迁移问题。本文针对这一挑战，旨在开发一种新型的自适应模型调整框架，以在边缘设备上保持CSI感知系统的高性能。该系统结合了跨模态的教师-学生架构，利用高精度的YOLO视觉模型作为动态监督信号，实时为CSI数据流提供活动标签。这使得自适应感应技术（STAR）能够在边缘设备上进行自动、在线的微调，从而动态适应环境的变化，不需要人工干预。", "innovation": "该研究提出了一种新的封闭回路，视觉引导的模型适应框架，称为maxVSTAR。该框架通过集成一种跨模态教师-学生架构，结合使用高准确度的YOLO视觉模型，在CSI数据流中实时提供活动标签，实现了在边缘设备上自适应HAR模型的在线微调。这种自适应机制使STAR模型能够无需手动干预地连续适应环境变化，从而显著提高了识别准确率。实验结果表明，即使在未校准的硬件上部署，相比于原始STAR模型的准确率从93.52%下降到49.14%，经过一次视觉引导的自适应循环后，maxVSTAR将准确率恢复到了81.51%。这些结果验证了该系统在隐私保护的物联网环境中实现动态、自我监督模型适应的能力，并为长期自主的基于CSI的人体活动识别提供了可扩展且实用的范例。", "conclusion": "研究表明，maxVSTAR系统能够在隐私保护的物联网环境中实现CSI感知系统的动态、自监督模型适应，具有较高的准确性和鲁棒性。这一系统不仅在硬件未校准时表现出色，而且能够自动适应环境变化，为长期自主人体活动识别提供了新的方法。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26185", "html_url": "https://arxiv.org/abs/2510.26185", "title": "Accumulative SGD Influence Estimation for Data Attribution", "title_en": "Accumulative SGD Influence Estimation for Data Attribution", "authors": "Yunxiao Shi,Shuo Yang,Yixin Su,Rui Zhang,Min Xu", "background": "现代数据为中心的AI需要精确到每个样本的影响效果。标准的SGD-IE通过将每个epoch的替代效应相加来近似leave-one-out的效果，但忽略了跨epoch的影响累积，导致了关键样本的误排名。这就是本文的背景，介绍了标准方法存在的问题，需要一种新的方法来准确评估每个样本的影响效果以优化数据选择和模型训练过程。", "innovation": "本文提出了一个称为ACC-SGD-IE的新方法，该方法是一个轨迹感知估计器，能够传播leave-one-out扰动并更新累积的影响状态。在光滑强凹设置下，它实现了几何错误收缩；在光滑非凹区域，它收紧了错误边界；较大的小批量进一步降低了常数。与传统SGD-IE相比，在Adult、20 Newsgroups、和MNIST数据集上的实验证明，使用ACC-SGD-IE能够获得更准确的影响估计，特别是在长时间训练周期中效果明显，并且在数据清洗后，基于ACC-SGD-IE清洗数据训练的模型表现更好。", "conclusion": "ACC-SGD-IE方法提高了数据影响估计的准确性，特别是在处理长时间训练数据和噪声数据时，以及模型训练后的数据清洗效果更佳。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26159", "html_url": "https://arxiv.org/abs/2510.26159", "title": "工业时间序列中组合与混合方法的复杂性超越细分：异常检测评估", "title_en": "Segmentation over Complexity: Evaluating Ensemble and Hybrid Approaches for Anomaly Detection in Industrial Time Series", "authors": "Emilio Mastriani,Alessandro Costa,Federico Incardona,Kevin Munari,Sebastiano Spinello", "background": "本研究调查了高级特征工程和混合模型架构在多变量工业时间序列异常检测中的有效性，重点关注蒸汽涡轮系统。研究评估了断裂点衍生的统计特征、基于聚类的子结构表示以及混合学习策略对检测性能的影响。尽管这些复杂方法在理论上具有吸引力，但它们的表现一直不如对细分数据进行训练的随机森林+XGBoost组合模型。此组合模型在AUC-ROC、F1得分和早期检测率方面表现优异。研究表明，在数据高度不平衡且具有时间不确定性的情况下，简洁模型结合最优细分可以超越更复杂的架构，提供更高的鲁棒性、可解释性和操作实用性。", "innovation": "研究评价了组合及混合方法在工业时间序列异常检测中的效果，发现即使在模型复杂性较高的情况下，简单的随机森林+XGBoost组合模型在实际应用场景中也能获得更好的表现，特别是在数据不平衡和时间不确定性高的情况下。这一发现强调了在某些真实应用场景中，模型的简单性和可优化的细分策略的重要性。", "conclusion": "在高度不平衡和时间不确定性高的数据场景下，简洁的模型结合最优细分可以优于复杂的架构，提供更高的鲁棒性、可解释性和操作实用性。研究结果表明，组合和混合方法的意义在于实际应用中的模型性能和操作便利性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26219", "html_url": "https://arxiv.org/abs/2510.26219", "title": "在预激活空间通过采样基础最优控制进行大型语言模型的测试时对齐", "title_en": "Test-Time Alignment of LLMs via Sampling-Based Optimal Control in pre-logit space", "authors": "Sekitoshi Kanai,Tsukasa Yoshida,Hiroshi Takahashi,Haru Kuroki,Kazumune Hashimoto", "background": "大型语言模型（LLMs）在测试时对齐需要关注，因为对其进行微调会带来高昂的计算成本。该研究基于采样为基础的模型预测控制和带有随机控制输入的方法，提出了一个新的测试时对齐方法，即适应性重要性采样在预激活（AISP）。", "innovation": "AISP 方法通过将高斯扰动应用于预激活输出（倒数第二层的输出），以最大化扰动均值的期望奖励。AISP 方法通过重要性采样计算最优均值，相比于最好的 n 次采样，在相同数量的样本中获得了更高的奖励。此外，AISP 在基于奖励的测试时对齐方法中表现出更高的奖励。", "conclusion": "该研究提出了一种新的 AISP 方法，通过在预激活空间中采用采样基础的最优控制，实现了在测试时对大型语言模型的有效对齐。AISP 方法优于现有的基于奖励的测试时对齐方法，并且在使用相同数量的样本时获得了更高的奖励。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26148", "html_url": "https://arxiv.org/abs/2510.26148", "title": "STAR: 隐私保护、节能的边缘AI框架，用于移动和渗透计算环境中的基于Wi-Fi CSI的人体活动识别", "title_en": "STAR: A Privacy-Preserving, Energy-Efficient Edge AI Framework for Human Activity Recognition via Wi-Fi CSI in Mobile and Pervasive Computing Environments", "authors": "Kexing Liu", "background": "当前的人体活动识别（HAR）方法在高性能边缘计算环境中的计算效率低下、延迟高且在资源受限的嵌入式移动边缘计算环境中具有局限性。传统的基于Wi-Fi信道状态信息（CSI）的HAR方法往往难以实现实时、高效的能量消耗。现有的方法需要更高的计算资源，以保持模型的准确性和实时性，不符合嵌入式设备的特点。STAR框架旨在通过结合轻量级神经架构、自适应信号处理和硬件感知联合优化，提供适合智能家居、健康监护和移动物联网系统的接触less、隐私保护感知解决方案，适用于资源受限的边缘计算环境。", "innovation": "STAR框架通过以下创新解决了传统方法的缺点：包含了一个精简的门控循环单元（GRU）循环神经网络，相比传统的长短期记忆（LSTM）模型减少了33%的模型参数，同时保持了有效的时序建模能力；预处理管道使用中值滤波、8阶巴特沃斯低通滤波器和经验模态分解（EMD）对信道状态信息（CSI）数据进行降噪和特征提取；在Rokchip RV1126处理器上实现了嵌入式神经处理单元（NPU）与ESP32-S3 CSI采集模块的接口；并通过INT8量化的推理实现了33 MHz的处理速度和仅8%的CPU利用率，与CPU执行相比，速度提高了六倍；实现了亚秒级的响应延迟和低功耗，确保了实时、隐私保护的人体活动识别，提供了一种适用于移动和渗透计算环境的实际、可扩展的解决方案。", "conclusion": "STAR框架利用轻量级神经架构、自适应信号处理和硬件感知联合优化，实现了在低功耗嵌入式设备上的人体活动识别。模型使用了一个97.6k参数的紧凑模型，实现了93.52%的平均识别准确率和99.11%的人存在的检测准确率。INT8量化推理实现了33 MHz的处理速度和8%的CPU利用率，处理速度提高了六倍，展示了STAR框架在亚秒级响应延迟和低功耗下的实时性，确保了隐私保护的人体活动识别，为移动和渗透计算环境提供了实用的可扩展解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26230", "html_url": "https://arxiv.org/abs/2510.26230", "title": "MPRU：作为分类管道输出过滤器的模块化投影再分布去学习", "title_en": "MPRU: Modular Projection-Redistribution Unlearning as Output Filter for Classification Pipelines", "authors": "Minyi Peng,Darian Gunamardi,Ivan Tjuawinata,Kwok-Yan Lam", "background": "现有的机器去学习（MU）方法着重于理论公式或优化目标，以实现知识的删除。然而，当这些方法部署到实际场景中时，它们通常面临着扩展性问题，并且必须解决完整访问原始数据集和模型的实际要求。作为现有方法的对比，本文将分类训练视为一个序列过程，即按照顺序学习类别的归纳方法。在这种方法中，去学习可以通过反向最后一个训练序列来实现。这种方法不需要完整访问原始数据集或模型，解决了现有方法的挑战，进而可以以小改动的方式模块化和模型无关地部署到现有的分类管道中作为输出过滤器。", "innovation": "本文提出了一种新的去学习方法——模块化投影再分布去学习（MPRU），通过在模型末端添加投影再分布层来进行去学习。这种方法不需要完整访问原始数据集或模型，提供了一种模块化且模型无关的解决方案，可以作为输出过滤器集成到现有分类管道中，减少大量的计算成本，同时保持性能。", "conclusion": "通过在图像（使用CNN模型的CIFAR-10/100）和表数据集（使用基于树的模型的Covertype）上进行的多次实验，证明了MPRU方法的有效性、可扩展性和系统兼容性，同时保持了在实际应用场景中的性能。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26266", "html_url": "https://arxiv.org/abs/2510.26266", "title": "生成模型中的可能插值", "title_en": "Likely Interpolants of Generative Models", "authors": "Frederik Möbius Rygaard,Shen Zhu,Yinzhu Jin,Søren Hauberg,Tom Fletcher", "background": "生成模型允许受控生成、模型检查等功能。然而，大多数生成模型缺乏对插值的明确概念，除非在模型或数据维度上有严格的假设。现有的插值方案通常需要对模型进行额外训练或对模型和数据维度进行限制。研究表明，对生成模型中的高质量路径插值可以增强生成模型的功能，并提供更具有连贯性的生成结果。", "innovation": "本文提出了一个通用的插值方案，用于生成模型，以利于各种度量和概率分布的合法转换路径。该方案将插值类比为在适当数据分布约束下的测地线，并推导出一个无需额外训练的新算法来计算这些曲线。理论上证明，在合适的黎曼度量下，该方法局部可以视为测地线。定量结果显示，该插值方案相较于基线方法在多种模型和数据集上能够穿越更高密度区域。", "conclusion": "本文基于合适的度量和概率分布提出了一个通用的插值方案，无需额外训练，并展示了其在多个生成模型上的优势。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26243", "html_url": "https://arxiv.org/abs/2510.26243", "title": "Angular Steering: 行为控制通过激活空间旋转", "title_en": "Angular Steering: Behavior Control via Rotation in Activation Space", "authors": "Hieu M. Vu,Tan M. Nguyen", "background": "在大规模语言模型的安全可靠部署中，控制特定行为同时保持其通用能力是一个核心挑战。当前的导航方法，如向量加法和方向消融，受限于激活和特征方向定义的二维子空间，导致选择参数时敏感且可能因激活空间内的意外相互作用而影响无关特性。", "innovation": "本文提出了一种名为“Angular Steering”的新型灵活方法，通过在固定二维子空间内旋转激活来调节行为。即将导航视为朝着或远离目标行为方向的几何旋转，提供了对拒绝和服从等行为的连续、细粒度控制。提出了一种选择性变体“Adaptive Angular Steering”，仅旋转与目标特征对齐的激活，增强了稳定性和一致性。Angular Steering统一了现有加法和正交化技术，简化了参数选择，并保持了在更广泛的调整范围内的模型稳定性。", "conclusion": "跨多个模型家族和规模的实验显示，Angular Steering在保持通用语言建模性能的同时实现了稳健的行为控制，突显了其灵活性、泛化能力和鲁棒性，优于先前的方法。有关代码和物资可以在：this https URL 查看。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26278", "html_url": "https://arxiv.org/abs/2510.26278", "title": "分布式的多目标黑盒优化在扩散模型推理时间多目标生成中的应用", "title_en": "Distributional Multi-objective Black-box Optimization for Diffusion-model Inference-time Multi-Target Generation", "authors": "Kim Yong Tan,Yueming Lyu,Ivor Tsang,Yew-Soon Ong", "background": "差分模型在学习复杂数据分布方面取得了成功，并被应用于高维多目标黑盒优化问题。现有方法通常通过外部优化循环，如进化算法，来使用差分模型。然而，这些方法将差分模型视为黑盒精炼器，忽略了生成过程中内部分布的转变，从而限制了它们的效率。", "innovation": "本文提出了在推理时间优化的多目标生成(IMG)算法。该算法在生成步骤中根据预期的多目标值进行加权重采样，确保了样本分布符合我们期望的多目标玻尔兹曼分布。此外，证明了多目标玻尔兹曼分布具有有趣的对数似然解释，它是最优解的分布多目标优化问题。通过在多目标分子生成任务中的实现，验证了IMG算法在单次生成过程中显著超越了基线优化算法。", "conclusion": "实验结果表明，IMG仅需一次生成过程，就能取得显著高于基线优化算法（通常需要多数百次的生成过程）的hyper-volume。我们的算法可以被视为优化的生成过程，并可以与现有的方法集成来进一步提高其性能。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26301", "html_url": "https://arxiv.org/abs/2510.26301", "title": "基于主动数据增强的离线偏好聚类学习", "title_en": "Offline Clustering of Preference Learning with Active-data Augmentation", "authors": "Jingyuan Liu,Fatemeh Ghaffari,Xuchuang Wang,Mohammad Hajiesmaili,Carlee Joe-Wong", "background": "多用户偏好学习框架在强化学习带有人类反馈和推荐系统等领域广泛应用。然而，在实际应用中，用户交互可能受到限制或成本高昂，因此需要使用离线偏好学习。同时，不同用户可能有不同偏好，例如，背景不同的注释员可能对同一回答给出不同的排序。对于这种具有挑战性的情况，存在两个核心问题：一是如何在数据不均衡的情况下识别用户的相似性，以便有效聚合数据；二是如何处理不均衡的离线数据，其中某些偏好维度被欠代表性。", "innovation": "本文研究了基于离线数据偏好聚类学习的问题，并提出了两个算法以解决上述挑战。第一个算法Off-C$^2$PL以便于仅依靠离线数据的方法解决纯离线设置中的问题，该算法的理论分析明确指出了样本噪声和偏差之间的权衡。第二个算法A$^2$-Off-C$^2$PL将框架扩展至包含主动数据增强的设置，允许学习者在基于Off-C$^2$PL学习到的聚类结构中为测试用户选择少量的额外主动数据。该算法的选择目标是针对测试用户偏好中信息最少的部分。", "conclusion": "通过实验证明，在模拟和真实世界的数据集上验证了提出的理论结果，并表明主动收集的数据比离线数据更有效地贡献了额外信息。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26302", "html_url": "https://arxiv.org/abs/2510.26302", "title": "从一个标记级别因果视角理解视觉语言组合性的困难", "title_en": "Understanding Hardness of Vision-Language Compositionality from A Token-level Causal Lens", "authors": "Ziliang Chen,Tianang Xiao,Jusheng Zhang,Yongsen Zheng,Xipeng Chen", "background": "CLIP通过在共享嵌入空间中对齐图像和文本以实现跨模态泛化，但在对象、属性和关系的组合推理上表现不佳，更像是一个词袋匹配器。现有的因果解释通常将文本表示为单个向量，这隐藏了标记级别的结构，也无法解释诸如提示敏感性和面对难题样本的失败等核心现象。", "innovation": "本文提出了一个标记感知的因果表示学习（CRL）框架，该框架基于顺序语言标记结构因果模型（SCM）。该理论将块识别扩展到标记化文本，证明了CLIP的对比目标可以在句子级和标记级SCM中恢复模态不变的潜在变量。标记粒度首次提供了CLIP组合脆弱性的原理解释：组合非识别性。此外，该分析还通过模态缺口将语言侧的非识别性与视觉侧的失败联系起来，展示了迭代组合操作如何累积难度，从而推动改进的负样本挖掘策略。", "conclusion": "CLIP的对比目标能够在句子级和标记级SCM中恢复模态不变的潜在变量；CLIP在对象、属性和关系的组合推理上表现出标记级别上的组合非识别性，导致其对SWAP、REPLACE和ADD操作敏感；语言侧的非识别性与视觉侧的失败存在关联，并且迭代组合操作将使得任务难度累积增加，需要改进负样本挖掘策略以应对这些挑战。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26323", "html_url": "https://arxiv.org/abs/2510.26323", "title": "在QUBO基于的SVM训练中权重离散化的影响", "title_en": "On the Impact of Weight Discretization in QUBO-Based SVM Training", "authors": "Sascha Mücke", "background": "SVM训练可以通过公式化为QUBO问题来实现，使量子退火能够应用于模型优化。本文探讨了量子退火中的qubit数量（与对偶权重的离散化级别相关）如何影响不同数据集上的预测性能。", "innovation": "研究表明，即使使用低精度的QUBO编码（例如，每个参数1位），其准确度也能与经典的LIBSVM求解器竞争甚至更好。虽然更高的位深能允许更大的正则化参数，但并不总是改善分类。", "conclusion": "我们的研究结果表明，选择正确的支持向量可能比其精确的加权更重要。尽管当前硬件受限于可解决的QUBO大小，但随着量子设备的发展，我们的结果突显了量子退火在SVM训练中的高效潜力。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26311", "html_url": "https://arxiv.org/abs/2510.26311", "title": "使用层特定建模和对齐进行数据无损连续学习的模型反转", "title_en": "Model Inversion with Layer-Specific Modeling and Alignment for Data-Free Continual Learning", "authors": "Ruilin Tong,Haodong Lu,Yuhang Liu,Dong Gong", "background": "持续学习（CL）旨在顺序训练模型以执行一系列任务，同时保持对先前任务的性能。然而，由于隐私或安全限制，存储和重放数据往往是不可行的，尤其是对任意预训练模型。为此，推出了数据无损持续学习（Data-free CL），它旨在更新模型而不访问先前数据。除了正则化外，本文还采用了模型反转来从训练模型合成数据，从而实现无需存储样本的重放。然而，预测模型中的模型反转面临两个挑战：（1）仅从压缩输出标签生成输入会导致合成数据和真实数据之间的偏移，而重放这些数据会削弱先前的知识；（2）反转计算成本高，因为每一步需要通过完整模型进行反向传播。这些问题在大型预训练模型如下一代CLIP中尤为严重。", "innovation": "本文提出了分层模型反转（PMI），通过借鉴单层优化中更快的收敛特性进行改进。PMI为全模型反转提供强大的初始化，显著减少了迭代次数，从而提高了效率。此外，本文通过对类特征进行高斯建模和对比模型建模，有效缓解了特征偏移问题，确保了合成数据与真实数据之间的对齐。结合PMI和特征建模，本文方法能够通过生成语义感知投影特征的伪图像，有效地学习新类别，从而在多个连续学习场景中实现强大的效果和兼容性。", "conclusion": "本文通过引入分层模型反转（PMI）技术以及特征建模策略，解决了数据无损连续学习中的关键挑战。该方法通过提高计算效率和确保合成数据与真实数据之间的对齐，显著提升了新类别的学习效果，证明了其在多种连续学习应用场景中的强大竞争力。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26328", "html_url": "https://arxiv.org/abs/2510.26328", "title": "Agent Skills允许一种新的、实际且简单的提示注入", "title_en": "Agent Skills Enable a New Class of Realistic and Trivially Simple Prompt Injections", "authors": "David Schmotz,Sahar Abdelnabi,Maksym Andriushchenko", "background": "随着大型语言模型（LLMs）的持续发展，如何实现持续学习成为了一个关键但尚未解决的研究问题。近期，一家领先的LLM公司通过引入Agent Skills框架，使代理能够基于存储在简单Markdown文件中的指令获得新知识，迈出了重要一步。尽管Agent Skills可以作为一个有用的工具，但该研究展示了它们的严重安全隐患：即可以轻松地在长时间的Agent Skill文件和引用脚本中隐藏恶意指令，以窃取敏感数据。此外，该研究还揭示了一个重要问题：一个看似无害的任务特定批准（如“不要再次询问”），可以被恶意利用，跨越到相关但有害的操作，规避系统级的防护措施。", "innovation": "该研究的工作在于揭示了Agent Skills框架存在的安全隐患，特别是其如何被用来进行简单的提示注入攻击，并能够隐藏恶意信息用于窃取敏感数据。此外，该研究还揭示了一个问题：看似无害的任务特定批准可能会被滥用，用于后续的有害操作，并且能够规避系统级的安全防护。", "conclusion": "尽管大量的研究工作和模型能力的增强，前沿的LLMs仍然在实际场景中对简单的提示注入攻击非常脆弱。该研究通过提供实用的攻击方法证明了这一观点，并强调了系统级安全防护的实际重要性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26342", "html_url": "https://arxiv.org/abs/2510.26342", "title": "带干预约束的线性因果发现", "title_en": "Linear Causal Discovery with Interventional Constraints", "authors": "Zhigao Guo,Feng Dong", "background": "在细化因果模型和改进下游任务如设计新疗法方面，整合因果知识和机制是必不可少的。然而，现有的因果发现方法尽管可以设置结构约束（例如，要求从PIP3到Akt的因果路径），但在某些情况下仍可能导致错误的因果推断。干预约束是一种不同于干预数据的概念，它通过不直接干预变量，而是通过不等式的因果效应形式，对高层次的因果知识进行编码。通过这种方式，干预约束可以实现对变量对之间总因果效应的明确限制，确保学到的模型符合已知的因果影响。", "innovation": "本文提出了一种新的因果发现概念——干预约束，并针对线性因果模型提出了一个度量总因果效应的指标，将问题形式化为受约束的优化任务，采用两阶段的约束优化方法求解。通过在实际数据集上的评估，证明了引入干预约束不仅能够改进模型的准确性和与已知发现的一致性，使模型更加可解释，还能够促进新的因果关系的发现，这些关系的识别本可能代价高昂。", "conclusion": "干预约束通过直接限制变量对之间的总因果影响，填补了现有方法在错误结论上的空白，促进了模型的改进和解释力的提升，同时支持新的因果关系的发现，有助于更有效地推进实际应用。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26284", "html_url": "https://arxiv.org/abs/2510.26284", "title": "Empirical Bayesian Multi-Bandit Learning", "title_en": "Empirical Bayesian Multi-Bandit Learning", "authors": "Xia Jiang,Rong J.B. Zhu", "background": "多任务学习在上下文多臂老虎机中的应用引起了研究兴趣，因为这可以通过利用共享结构和任务特定异质性来增强跨多个相关任务的决策制定能力。当前的方法通常忽略了跨多臂老虎机之间的协方差结构的学习。本文介绍了用于学习各种多臂老虎机实例的新型分层贝叶斯框架。该框架通过分层贝叶斯模型捕捉不同多臂老虎机之间的异质性和相关性，从而实现有效的信息共享，同时适应特定实例的差异。", "innovation": "该研究引入了一种经验贝叶斯方法来估计先验的协方差矩阵，这种方法提高了在多臂老虎机学习中的实用性和灵活性。基于此方法，作者开发了两种高效的算法：ebmTS（经验贝叶斯多臂老虎机θ斯蒙普夫人格拉斯特采样）和ebmUCB（经验贝叶斯多臂老虎机上置信界），两种算法都将估计的先验融入决策过程。", "conclusion": "本文提出的算法在合成数据集和真实世界数据集上的广泛实验均展现出优越性能，特别是在复杂环境中，其累积后悔率低于现有技术，证明了在多臂老虎机中平衡探索和利用的有效性。这些算法填补了多臂老虎机问题中的研究空白。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26324", "html_url": "https://arxiv.org/abs/2510.26324", "title": "后验采样通过将扩散模型与退火 Langevin 动力学结合实现", "title_en": "Posterior Sampling by Combining Diffusion Models with Annealed Langevin Dynamics", "authors": "Zhiyang Xun,Shivam Gupta,Eric Price", "background": "给定噪声线性测量 $y = Ax + \\xi$ 和分布 $p(x)$ 的良好先验近似，何时可以从后验 $p(x \big| y)$ 进行采样？后验采样为诸如修补、去模糊和MRI重建等任务提供了一个准确且公平的框架，但多种近似方法在一般情况下计算上是不可行的。在局部或全局对数凹分布 $p(x)$ 的情况下，当精确得分可用时，Langevin 动力学可生成后验样本，但其对抗得分估计误差非常脆弱，需要满足亚指数误差的矩生成函数（MGF）界。相比之下，在无条件情况下，扩散模型仅需满足得分误差的 $L^2$ 界即可成功。", "innovation": "证明了通过将扩散模型与退火 Langevin 动力学结合，可以仅通过满足得分误差的 $L^4$ 边界来在多项式时间内实现条件采样。", "conclusion": "在局部或全局对数凹分布的情况下，通过结合扩散模型与退火 Langevin 动力学，即使在得分估计误差较大的情况下也能实现有效的后验采样。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26353", "html_url": "https://arxiv.org/abs/2510.26353", "title": "向金融领域可解释和可靠的人工智能发展", "title_en": "Towards Explainable and Reliable AI in Finance", "authors": "Albi Isufaj,Pablo Mollá,Helmut Prendinger", "background": "金融领域的预测越来越多地使用大型神经网络模型，但这些模型的不透明性带来了信任和合规方面的挑战。", "innovation": "提出了几种可解释性和可靠性的人工智能方法，包括使用Time-LLM时序基础模型来避免错误的方向预测，通过结合时序预测的基础模型与可靠性估计器来过滤掉不可靠的预测，以及主张符号推理编码领域规则以实现透明的解释。", "conclusion": "通过将预测性能与可靠性估计以及基于规则的推理相结合，该框架推动了透明和可审计的金融人工智能系统的发展，实验结果表明该架构减少了假阳性并支持有选择性的执行。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26303", "html_url": "https://arxiv.org/abs/2510.26303", "title": "Per-sample Adam on Separable Data: Departure from the Full-batch Regime", "title_en": "Implicit Bias of Per-sample Adam on Separable Data: Departure from the Full-batch Regime", "authors": "Beomhan Baek,Minhak Song,Chulhee Yun", "background": "Adam作为一种深度学习的默认优化器，尽管在实践中非常成功，但是对于其理论理解仍然有限。之前的研究表明Adam倾向于$\boldsymbol{\beta_1=0}$时最小化$\bold{l_\boldsymbol{\bold{∞}}}$几何的解，但这一结论仅在全批量优化的情况下有效。本文研究了在对线性可分数据使用逻辑回归时，增量性Adam（每次迭代仅使用一个样本）的隐式偏差，并发现其偏置与全批量优化的行为存在差异。通过构造一个结构化的数据集，并证明在给定条件下，增量Adam收敛于$\boldsymbol{\bold{l_2-}$极大边际分类器，这与$\boldsymbol{\bold{l_\boldsymbol{\bold{∞}}}}$极大边际偏差形成对比。研究还引入了一种代理算法，用于捕捉增量Adam在$\beta_2 \to 1$情况下的极限行为，并通过数据依赖的双固定点公式描述其收敛方向。此外，研究指出与Adam不同，Signum对于任何批量大小都能收敛于$\boldsymbol{\bold{l_\boldsymbol{\bold{∞}}}}$极大边际分类器。", "innovation": "本文的研究创新在于发现了增量性Adam在处理线性可分数据时的隐式偏差与全批量Adam存在显著差异，并通过构造特定数据结构和设计代理算法，深入剖析了优化偏置对批量方案和数据集的依赖性。此外，研究还说明了Signum在批量大小变化时仍然具有一致的收敛特性。", "conclusion": "论文结果强调了Adam的隐式偏置不仅依赖于批量方案，还取决于数据集的具体特征。对于相同的优化问题，不同的批量方案及数据集可能产生不同的优化结果。与此同时，通过引入代理算法，论文还揭示了增量性Adam在特定条件下的收敛行为，并提出Signum比Adam在批量大小变化时更加稳健。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26347", "html_url": "https://arxiv.org/abs/2510.26347", "title": "随机化、稀疏和非稳态环境中自主水下车辆用于污染检测的强化学习", "title_en": "Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle", "authors": "Sebastian Zieglmeier,Niklas Erdmann,Narada D. Warakagoda", "background": "强化学习（RL）算法被设计用来通过学习能够最大化奖励的动作来优化问题求解，特别是在随机和非稳态环境下，这种任务变得特别具有挑战性。即使是在先进的RL算法，也往往难以在这些条件下解决问题。在诸如利用自主水下车辆（AUVs）进行水下污染云搜索的应用场景中，RL算法需要在动作与奖励稀疏的环境中导航，即大多数动作可能会导致零奖励。本研究旨在通过重新审视和修改经典的RL方法来应对这些挑战，使得算法能够在稀疏、随机且非稳态环境中高效地运作。", "innovation": "该研究系统地研究了大量修改，包括层次算法改变、多目标学习和将位置记忆作为外部输出过滤器来防止状态重复访问。研究结果表明，基于Monte Carlo的方法（进行了修改）明显优于传统的Q学习以及两种穷举搜索模式，显示了其适应复杂环境的潜力，表明强化学习方法可以有效适应随机、非稳态及奖励稀疏的环境。", "conclusion": "研究结果表明，修改后的强化学习方法在水下污染检测的随机、稀疏和非稳态环境中表现出色，显示出其在复杂环境中的适应潜力。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26369", "html_url": "https://arxiv.org/abs/2510.26369", "title": "CorVS: 在实际仓储环境通过视频轨迹-传感器对应进行人员识别", "title_en": "CorVS: Person Identification via Video Trajectory-Sensor Correspondence in a Real-World Warehouse", "authors": "Kazuma Kano,Yuki Mori,Shin Katayama,Kenta Urano,Takuro Yonezawa,Nobuo Kawaguchi", "background": "工人位置数据对工业场所的生产率至关重要。在物流仓库中，摄像头是一种有潜力的位置识别工具，它们还能提供有价值的信息，如包裹状态等。然而，仅通过视觉数据识别个人往往是不切实际的。因此，许多先前的研究是通过比较轨迹和穿戴式传感器测量来识别人员。尽管这种方法具有独立于外观的优点，但现有方法在实际应用中可能会失效。", "innovation": "我们提出了一种名为CorVS的新型数据驱动的人识别方法，该方法基于视觉跟踪轨迹和传感器测量之间的对应关系。首先，我们的深度学习模型预测每对轨迹和传感器测量的对应概率和可靠性。其次，我们的算法运用这些预测的概率和可靠性来匹配轨迹和传感器测量。我们开发了一个包含实际仓储操作的数据库，并展示了该方法在实际应用中的有效性。", "conclusion": "我们提出的CorVS方法通过视频轨迹-传感器对应关系在实际仓储环境中实现了人员识别，该方法具有较高的可靠性和有效性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26350", "html_url": "https://arxiv.org/abs/2510.26350", "title": "UnifiedFL：一种动态统一的学习框架以促进公平协作", "title_en": "UnifiedFL: A Dynamic Unified Learning Framework for Equitable Federation", "authors": "Furkan Pala,Islem Rekik", "background": "联邦学习（FL）已成为跨多个客户端协作模型训练的关键范式，但无需共享原始数据。这在放射学和病理学等隐私敏感领域具有重要意义。然而，现有工作尚不充分支持具有根本不同神经架构和非同分布数据集的客户端之间的协作训练。现有的FL框架存在多个局限性：大多数最近的FL方法仅支持单一模型家族内的微调（如较浅、更深或更宽的CNNs），并且仍旧假定共享全局架构，无法适应客户端部署不同网络类型（如CNNs、GNNs、MLPs）的情况。此外，现有的方法通常仅解决统计异质性，而忽视了领域断裂问题，即每个客户端的数据分布与其测试时面临的情况差异显著，从而削弱了模型的泛化能力。当前方法在客户端使用不同架构、具有非同分布数据且面对不同测试领域时表现不佳。", "innovation": "本文提出了UnifiedFL，一种动态联邦学习框架，用于均衡协作。UnifiedFL的主要创新如下：(i) 使用通用的图神经网络（GNN）参数化所有架构；(ii) 通过客户端参数之间的欧氏距离进行距离驱动的聚类；(iii) 采用二层聚合策略平衡收敛性和多样性。该框架能够在客户端使用不同架构、具有非同分布数据且面对不同测试领域时提高模型性能。", "conclusion": "在MedMNIST分类和海马体分割基准测试中，实验结果表明UnifiedFL优于现有方法，提升了模型在这些多变条件下的性能。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26633", "html_url": "https://arxiv.org/abs/2510.26633", "title": "普遍而被忽视的：组合贝叶斯优化中的热核", "title_en": "Omnipresent Yet Overlooked: Heat Kernels in Combinatorial Bayesian Optimization", "authors": "Colin Doumont,Victor Picheny,Viacheslav Borovitskiy,Henry Moss", "background": "贝叶斯优化（BO）在材料科学和神经架构搜索等多种组合任务中具有潜在的应用价值，但有效建模组合域通常需要专业的核函数。尽管近期引入了一些组合核，但它们之间的关系尚未完全理解。", "innovation": "研究开发了一种基于热核的统一框架，系统地推导并表达为简单的闭式表达式。利用该框架，研究证明了多个成功的组合核要么与其相关，要么等价于热核。实验验证了这一理论结论。分析还证实了某些算法在功能的未知最优值不具有特定结构时性能显著下降，相反，热核对该最优值的位置不敏感。此外，展示了一种依赖热核的快速简单管道能够达到最先进的性能，甚至超过了某些慢或复杂的算法。", "conclusion": "该研究通过热核框架将许多有效的组合核统一起来，并证明了热核在组合优化中的广泛应用和非敏感性，同时提出了一种高效的解决方案以达到最好或更优的性能。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26690", "html_url": "https://arxiv.org/abs/2510.26690", "title": "LoRAQuant: 混合精度LoRA至超低比特量化", "title_en": "LoRAQuant: Mixed-Precision Quantization of LoRA to Ultra-Low Bits", "authors": "Amir Reza Mirzaei,Yuqiao Wen,Yanshuai Cao,Lili Mou", "background": "低秩适应(LoRA)技术成为参数高效微调大型语言模型(LLLMs)的热门方法。在实际场景中，多个适应器被同时加载，以使LLM能够提供个性化用户体验或支持多种任务。尽管每个适应器在单独使用时量轻，但它们的总成本在大规模应用中变得显著。", "innovation": "提出了LoRAQuant，一种针对LoRA的混合精度后训练量化方法。LoRAQuant通过奇异值分解(SVD)重组每个适应器，将最关键的信息集中到特定的行和列中。这使得关键组件可以量化为更高的精度，而其余部分则可以量化为超低位宽。", "conclusion": "我们在LLaMA 2-7B、LLaMA 2-13B和Mistral 7B模型上对数学推理、编程和总结任务进行了全面实验。结果显示，与其它量化方法相比，我们的LoRAQuant使用了显著更少的比特数，但性能相当或更高。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26566", "html_url": "https://arxiv.org/abs/2510.26566", "title": "Multiclass Local Calibration With the Jensen-Shannon Distance", "title_en": "Multiclass Local Calibration With the Jensen-Shannon Distance", "authors": "Cesare Barbera,Lorenzo Perini,Giovanni De Toni,Andrea Passerini,Andrea Pugnana", "background": "开发值得信赖的机器学习（ML）模型需使预测的概率与真实类别频率一致，即所谓的校准。在多类分类的校准中，强校准是最严格的，因为它要求所有预测概率同时在所有类中校准。然而，现有方法缺乏对输入之间距离的考虑，导致预测对稀疏特征空间的输入系统性地缺乏校准，尤其是高风险场景中最为关键的稀疏实例，容易导致偏差处理。作者在这项工作中引入了多类局部校准的概念。", "innovation": "正式定义了多类局部校准，并建立了其与强校准的关系；理论分析了现有评估指标在应用于多类局部校准时的不足；提出了一种使用Jensen-Shannon距离来增强神经网络局部校准的实用方法，通过使预测概率与局部估计的类别频率一致。", "conclusion": "实验验证了所提出的方法相较于现有的多类校准技术的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26679", "html_url": "https://arxiv.org/abs/2510.26679", "title": "紧密的差异隐私主成分分析通过矩阵共轭", "title_en": "Tight Differentially Private PCA via Matrix Coherence", "authors": "Tommaso d'Orsi,Gleb Novikov", "background": "该研究重新审视了在差分隐私约束下计算矩阵的前$r$个奇异向量的跨度这一任务。Hardt和Roth曾经提出过这个问题，但没有解决。先前的一些隐私保护算法在某些方面表现不佳，特别是在稠密设置中，它们无法达到非私人最优算法的性能。", "innovation": "本文提出了一种基于奇异值分解和标准扰动机制的简单高效算法，该算法能够返回一个隐私保留的秩-$r$近似值，其错误取决于$r$秩相干性和谱间隙$\boldsymbol{\text{σ}}_r - \boldsymbol{\text{σ}}_{r+1}$。作者证明了差分隐私下的估计器在稠密设置中达到了最优非私人算法的同一保证，而之前的算法未能实现这一点。此外，还证明了秩-$r$相干性在高斯扰动下不会增加，这意味着基于高斯机制（包括本文提出的算法）能够保持输入的相干性。作者还推测这种行为可能适用于其他结构化模型，包括图形中的种植问题。", "conclusion": "本文的结果对于差分隐私下的主成分分析提供了新的见解，特别是在稠密设置中，证明了算法性能可以与非私人算法相媲美。此外，还探讨了相干性在图问题中的应用，提出了能够在低相干性假设下执行的差分隐私算法。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26616", "html_url": "https://arxiv.org/abs/2510.26616", "title": "Aeolus: 多模态航班延误数据集", "title_en": "Aeolus: A Multi-structural Flight Delay Dataset", "authors": "Lin Xu,Xinyun Yuan,Yuxuan Liang,Suwan Yin,Yuankai Wu", "background": "现有的航班延误数据集通常局限于扁平的表格结构，无法捕捉航班延误传播中的空间和时间动态。Aeolus 数据集旨在解决这一问题，提供了一种多模态的数据结构，涵盖丰富的航空公司、气象和机场级别特征，以及详细的航班网络图，以支持更广泛的任务和研究，包括回归、分类、时间结构建模和图学习。", "innovation": "Aeolus 数据集引入了三个对齐的模态：(i)一个包含丰富操作、气象和机场级别的表征数据集，涵盖了超过5,000万个航班；(ii)一个航班链模块，建模沿顺序航班段的延迟传播，捕捉上下游依赖性；(iii)一个航班网络图，编码共享的飞机、机组和机场资源连接，支持跨航班关系推理。数据集谨慎地构建了时间划分、全面的特征和严格的泄漏预防，以支持现实和可重复的机器学习评估。Aeolus 支持各种任务，服务于具体领域的建模和通用结构的数据需求。", "conclusion": "Aeolus 数据集作为跨表格、序列和图形模态的统一基准，为支持现实和可重复的机器学习评估提供了坚实的数据基础，同时该数据集还提供了基础模型的发展平台和技术工具。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26560", "html_url": "https://arxiv.org/abs/2510.26560", "title": "关于在深度网络中度量捷径定位的研究", "title_en": "On Measuring Localization of Shortcuts in Deep Networks", "authors": "Nikita Tsoy,Nikola Konstantinov", "background": "捷径是由训练期间表现良好但在泛化时会失效的虚假规则引起，这对深度网络的可靠性构成了主要挑战。但捷径对特征表示的影响尚未充分研究，这阻碍了设计基于原理的捷径抑制方法。为克服此局限性，该研究探讨了深度模型中的分层捷径定位问题。通过反事实训练方法，研究量化了训练过程中由捷径归纳偏差导致的准确率下降的分层贡献。研究选择了四个数据集（CIFAR-10、Waterbirds、CelebA），并在四个模型架构（VGG、ResNet、DeiT、ConvNeXt）上进行了实验。", "innovation": "该研究开发了一种新的实验设计，通过在干净和偏差数据集上进行反事实训练来量化因捷径导致的准确率下降的分层贡献，并分析了不同网络部分在这一过程中的作用。研究表明，捷径学习并非局限于特定层次，而是在整个网络中分布开来，浅层主要编码虚假特征，深层主要遗忘在干净数据上有预测作用的核心特征。还分析了定位差异及其主要变化轴。最后，研究分析表明分层捷径抑制策略的通用性较差，支持针对特定数据集和架构的方法。", "conclusion": "该研究揭示了深度网络中捷径学习分布的特点，强调了深度学习中的特征学习行为的复杂性，并提出了新的设计理念和分析方法。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26557", "html_url": "https://arxiv.org/abs/2510.26557", "title": "为资源受限设备瘦身的Boosted Tree压缩方法", "title_en": "Boosted Trees on a Diet: Compact Models for Resource-Constrained Devices", "authors": "Jan Stenkamp,Nina Herrmann,Benjamin Karic,Stefan Oehmcke,Fabian Gieseke", "background": "在现代物联网应用中，将机器学习模型部署在计算能力受限的设备上变得至关重要。本研究针对这一需求，提出了一种压缩决策树集成模型的方法，以缩小轻量级机器学习模型的内存占用。具体来说，该方法通过鼓励特征和阈值的复用来在训练过程中构建紧凑的集成模型。实验表明，与使用调整训练过程和不同内存布局的LightGBM模型相比，压缩后的模型在压缩比为4-16倍的情况下仍能保持相同的性能。这使得物联网设备能够独立于持续的通信或外部能源供应，并在资源受限的环境中实现自主运行。", "innovation": "提出了一种压缩决策树集成模型的方法，通过鼓励特征和阈值的复用来在训练过程中构建紧凑的模型。这种压缩技巧在保持模型性能的同时，极大地减少了对计算能力和能量的需求，适用于远程监控、边缘分析和孤立或电力有限环境下的实时决策等物联网应用。", "conclusion": "在压缩比为4-16倍的情况下，该方法实现了与LightGBM模型相同的性能。这种技术使得计算能力受限的设备可以在无需外部能源供应的环境下独立运行，为物联网应用提供了广阔的可能性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26607", "html_url": "https://arxiv.org/abs/2510.26607", "title": "作为贝塞尔基上变分近似概率轨迹的Wasserstein回归", "title_en": "Wasserstein Regression as a Variational Approximation of Probabilistic Trajectories through the Bernstein Basis", "authors": "Maksim Maslov,Alexander Kugaevskikh,Matthew Ivanov", "background": "本文考虑了分布上的回归问题，这一问题在机器学习中变得越来越重要。现有的方法往往忽视了概率空间的几何结构，或者计算成本高昂。", "innovation": "本文提出了一种新方法，结合了使用伯恩斯坦基参数化概率轨迹的方法，并通过最小化分布之间的Wasserstein距离来进行轨迹建模。该方法将条件分布建模为输入变量通过伯恩斯坦多项式构建的权重高斯分量加权和定义的平滑概率轨迹。损失函数是预测的高斯分布与经验数据之间的平均平方Wasserstein距离，该函数考虑到分布几何结构。通过自动微分优化方法训练模型。", "conclusion": "实验表明，该方法在合成数据集上表现出了与Wasserstein距离、能量距离和RMSE指标相关的竞品竞争力，尤其是在非线性较为显著的情况下。模型展示了比或优于替代方案的轨迹平滑性，并且对数据结构的变化具有鲁棒性，同时保持较高的可解释性，因为参数化通过控制点明确实现。该方法代表了一个平衡的解决方案，融合了几何准确性、计算实用性以及可解释性。未来研究的前景包括将方法扩展到非高斯分布，应用熵正则化来加速计算，以及适应处理高维数据以近似曲面和其他复杂结构。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26645", "html_url": "https://arxiv.org/abs/2510.26645", "title": "Curly Flow Matching for Learning Non-gradient Field Dynamics", "title_en": "Curly Flow Matching for Learning Non-gradient Field Dynamics", "authors": "Katarina Petrović,Lazar Atanackovic,Viggo Moro,Kacper Kapuśniak,İsmail İlkan Ceylan,Michael Bronstein,Avishek Joey Bose,Alexander Tong", "background": "在自然科学中，从个体层面的观测来建模自然过程的传输动力学是一个普遍存在的问题。现有的方法依赖于最小作用原理，导致梯度场动力学，从而产生轨迹以最小化两种概率测度之间的能量函数。然而，许多实际系统，如单细胞RNA中的细胞周期，显示出非梯度、周期性的行为，这无法被当前最先进的方法如流动匹配和桥梁匹配捕捉到。因此，需要一种新的方法以学习非梯度场动力学。", "innovation": "本文提出了一种新颖的方法，名为Curly Flow Matching (Curly-FM)，它可以学习非梯度场动力学。通过设计并解决具有非零漂移参照过程的薛定谔桥梁问题，该方法能够捕捉周期性行为，并通过使用推断出的速度以及种群快照数据来构建参照过程。这种方法展示了一系列应用，包括单细胞轨迹推断、计算流体力学及海洋环流，结果显示Curly-FM能够更好地匹配参照过程和群体边缘分布，从而扩大了流动匹配模型的应用范围，使其从仅针对种群建模转向对物理系统中已知周期行为的建模。", "conclusion": "Curly-FM方法可以学习非梯度场动力学，并能够捕捉周期性行为，展示其在不同领域的应用，并且能够更好地匹配参照过程和群体边缘分布。该方法扩展了流动匹配模型的应用范围，使其能够适用于已知周期行为的物理系统建模。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26643", "html_url": "https://arxiv.org/abs/2510.26643", "title": "MSAD：时间序列异常检测中的模型选择深入探讨", "title_en": "MSAD: A Deep Dive into Model Selection for Time series Anomaly Detection", "authors": "Emmanouil Sylligardos,John Paparrizos,Themis Palpanas,Pierre Senellart,Paul Boniol", "background": "时间序列异常检测是数据分析中的基本任务，对下游应用性能有重要影响。尽管学术界对此越来越感兴趣，并且文献中提出了许多方法，但最近的基准测试和评估研究显示，当应用于非常异质的时间序列数据集时，没有一种最佳的异常检测方法可以适用。因此，针对不同领域的大量不同时间序列的异常检测问题，唯一的可扩展和可行的解决方案是提出一种模型选择方法，该方法根据时间序列特征选择最适合运行的异常检测方法。然而，现有的自动化机器学习（AutoML）解决方案不适用于时间序列异常检测，且尚未对基于时间序列的方法进行模型选择进行评估。因此，本研究旨在探讨使用时间序列分类方法作为模型选择的性能，以进行异常检测。这项评估是证明时间序列分类算法在异常检测中的准确性和效率的第一步，并且可以作为指导一般AutoML管道中的模型选择步骤的基础基准。", "innovation": "首次对基于时间序列的模型选择方法进行了全面的实验评估，将234种模型配置从16个基本分类器中得出并应用于超过1980个时间序列。所提出的方法展示了模型选择方法优于单一异常检测方法，并且在执行时间方面具有可比性。这是使用时间序列分类算法进行异常检测准确性和效率的初步证明，同时提供了指导一般AutoML管道中模型选择步骤的基础基准。", "conclusion": "本文研究表明，模型选择方法不仅在性能上优于单一的异常检测方法，而且在执行时间方面具有可比性。这代表了利用时间序列分类算法进行异常检测的准确性与效率，并为未来的研究提供了强基准。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26787", "html_url": "https://arxiv.org/abs/2510.26787", "title": "远程劳动力指数：衡量远程工作的AI自动化", "title_en": "Remote Labor Index: Measuring AI Automation of Remote Work", "authors": "Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks", "background": "尽管人工智能已经在知识和技术推理的研究基准上取得了快速进展，但这些进步如何转化为经济价值和自动化仍不清楚。为了衡量这一转化，本文引入了远程劳动力指数（RLI），这是一种涵盖多个经济部门的真实世界基准，旨在评估代理在实际环境中的端到端表现。研究表明，AI代理在RLI上的表现接近最低水平，最高性能的代理实现了2.5%的自动化率。", "innovation": "本文创新性地提出了远程劳动力指数（RLI），作为评估AI在实际环境中自动化能力的一个广泛而多元的基准。这个指数能够将AI自动化和实际劳动力市场的情况紧密联系起来，为理解AI技术的实际应用提供了实证基础。", "conclusion": "研究结果强调了将AI自动化与现实经济情况结合的重要性。通过设置共同的基准，RLI能够帮助利益相关者了解和应对由AI驱动的劳动力自动化的影响，从而能够在AI自动化的过程中更为前瞻性的进行规划和管理。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26777", "html_url": "https://arxiv.org/abs/2510.26777", "title": "预训练预测模型：强大的零样本特征提取器，用于时间序列分类", "title_en": "Pre-trained Forecasting Models: Strong Zero-Shot Feature Extractors for Time Series Classification", "authors": "Andreas Auer,Daniel Klotz,Sebastinan Böck,Sepp Hochreiter", "background": "近年来，时间序列基础模型的研究主要集中在预测上，这使得人们对它们学习到的表示形式的通用性产生了疑问。本文研究了冻结的预训练预测模型是否能为分类提供有效的表示，通过比较不同的表示提取策略并引入两种模型无关的嵌入增强方法，验证了预测模型在分类任务中的效果。研究发现最佳预测模型的分类准确性甚至超过了专门针对分类预训练的前沿模型。此外，预测和分类任务之间存在积极的相关性。", "innovation": "本文的主要创新在于提出了两种模型无关的嵌入增强方法，并通过实验证明了预训练预测模型在分类任务中能达到甚至超越专门预训练分类模型的效果，挑战了特定任务预训练的必要性。", "conclusion": "本文的研究结果表明，学习预测可能为构建通用时间序列基础模型提供一种强大途径，无需任务特定的预训练。实验结果显示，最佳预测模型在分类任务中的表现与特定任务预训练的模型相当甚至更好，而且预测和分类任务之间存在正相关关系。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25776", "html_url": "https://arxiv.org/abs/2510.25776", "title": "StreetMath：大型语言模型在非精确数学运算中的行为研究", "title_en": "StreetMath: Study of LLMs' Approximation Behaviors", "authors": "Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong", "background": "已有大量文献探讨了大型语言模型（LLMs）的数学推理能力，尤其是在自回归结构中进行精确的算术运算。然而，LLMs在非正式、快速数学操作中的近似推理能力，尤其是在非自回归解码模型中的表现，却很少被关注。本文通过引入StreetMath基准测试，填补了这一研究空白，旨在评估模型在实际近似场景下的近似能力。", "innovation": "本文的主要创新点在于提出了StreetMath基准测试，专门用于评估模型在实际近似场景下的近似能力。通过在Qwen3-4B-Instruct-2507、Qwen3-4B-Thinking-2507、Dream-v0-Instruct-7B、Falcon-Mamba-7B-Instruct及Mamba-GPT-3B等多种LLM架构上进行广泛评估，还利用了机制可解释性技术探查其内部计算状态。研究发现，LLMs通常尝试精确计算或调用外部工具，即使在要求近似计算的任务中也是如此。", "conclusion": "研究揭示了LLMs在解决近似任务时改变了更多token的现象，并指出要求精确运算和近似运算主要依赖于神经网络的不同组件。基于认知心理学的研究，本文认为LLMs不像人类在街头数学设置中表现出认知吝啬的特点。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25775", "html_url": "https://arxiv.org/abs/2510.25775", "title": "使用SHAP实现棋局的棋子级解释", "title_en": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP", "authors": "Francesco Spinnato", "background": "现代的象棋引擎提供了精确但不透明的评估，通常以小马达得分的形式表达。尽管在决策时非常有效，但这些输出并没有揭示棋盘上单独棋子或模式的贡献。本文的研究基于如何利用SHAP（SHapley Additive exPlanations）来为象棋分析提供更透明的解释，旨在将象棋引擎的评估分配到特定的棋子上。这种方法借鉴了经典象棋教学法，其中棋手通过在脑中移除棋子来评估棋局，同时结合现代可解释的人工智能技术。", "innovation": "本文的方法通过将棋子作为特征，并系统地移除它们以计算每个棋子的加性贡献，从而在局部忠实且人类可理解的方式下解释象棋引擎的输出。这种方法为象棋AI的可视化、人类训练以及引擎对比提供了新的可能性。该研究提供了一个相关的代码库和数据集，以促进未来可解释的象棋AI的研究。", "conclusion": "本文的方法为象棋AI的解释提供了新的可能性，使其输出更加透明和可理解。该方法融合了经典象棋教学和现代可解释AI技术，能够评估棋局中每个棋子的单独贡献。所提出的方法将促进未来象棋AI领域的研究，尤其是在视觉化、人类训练和引擎比较方面。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25778", "html_url": "https://arxiv.org/abs/2510.25778", "title": "基于模糊逻辑算法方法的商品评价中实体排名分析", "title_en": "Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach: Analysis", "authors": "Pratik N. Kalamkar,Anupama G. Phakatkar", "background": "意见挖掘，又称情感分析，是研究通过分析人们对于产品、服务、组织、个人、议题、事件、话题及其属性的看法、情感、评价、评估、态度和情绪的一种领域。传统的全局词典方法忽略了每个评论的情感强度，即从非常负面（或积极）、强烈负面（或积极）、中等负面（或积极）、非常温和的负面或温和的负面和积极。本文旨在提出一种基于实体和用户查询的方向和强度对实体进行排名的方法，通过将相关于特定产品感兴趣的方面的情感词（即副词、形容词、名词和动词）按照从微观到宏观的粒度层次（即非常弱、弱、中等、非常强和强）进行分类来实现。我们将采用模糊逻辑算法方法对情感词进行分类，并利用句法依赖性解析来找到所需方面词的关系，从而找到评论中某个方面的情感分数。", "innovation": "本文提出了一种基于模糊逻辑算法的方法，用于根据情感的强度和方向对实体进行排名，同时考虑了用户查询。这种方法通过分析相关于特定产品感兴趣方面的意见词，并按强烈程度进行分类，从而更加精确地反映人们对实体情感的态度和强度。", "conclusion": "本文提出的方法具有很好的应用前景，通过结合模糊逻辑算法与句法依赖性解析，能够更准确地分析和分类评论中的意见词汇，从而提供更加精确的实体感情分数，为进一步的产品评价分析提供了新的视角。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25774", "html_url": "https://arxiv.org/abs/2510.25774", "title": "使用深度学习进行脉冲星检测", "title_en": "Pulsar Detection with Deep Learning", "authors": "Manideep Pendyala", "background": "脉冲星巡天生成了大量候选目标，人工检查这些目标极其耗时。以往的处理手段主要依赖于手动筛选，效率低下且难以处理海量数据。为解决这一问题，该论文开发了一种基于深度学习的管道系统，该系统将阵列提取特征与图像诊断相结合，从巨米波射电望远镜（GMRT）的数据中筛选出脉冲星候选目标。该方法能够自动高效地处理大量数据，显著提高了检测的准确性和效率。", "innovation": "论文创新地将深度学习应用于脉冲星候选目标的筛选，提出一种融合了阵列提取特征与图像诊断的深度学习管道系统。该系统通过预处理（SIGPROC、PRESTO等工具）从原始数据中筛选出大量候选目标，并采用卷积神经网络（CNN）和人工神经网络（ANN）结合的模型，以图像和阵列数据为输入进行分类。此外，通过调整CNN架构（如正则化、学习率调度、最大范数约束）、优化训练过程以及使用生成对抗网络（GAN）进行数据增强，显著提高了模型的分类准确率，最终在测试集上实现了94%的准确率，且保持了高效性，适合近实时处理。", "conclusion": "结合阵列和图像通道的方法在脉冲星候选目标筛选上优于仅使用图像的方法，而有针对性的数据增强（特别是生成对抗网络生成的少数类样本）显著提升了脉冲星（少数类）的召回率。该方法具有平台通用性和扩展性，适用于未来的高通量观测设施。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24736", "html_url": "https://arxiv.org/abs/2510.24736", "title": "RNAGenScape: 通过流形朗格文动力学指导特性和插值mRNA序列", "title_en": "RNAGenScape: Property-guided Optimization and Interpolation of mRNA Sequences with Manifold Langevin Dynamics", "authors": "Danqi Liao,Chen Liu,Xingzhi Sun,Dié Tang,Haochen Wang,Scott Youlten,Srikar Krishna Gopinath,Haejeong Lee,Ethan C. Strayer,Antonio J. Giraldez,Smita Krishnaswamy", "background": "mRNA设计和优化在合成生物学和治疗性开发中非常重要，但在机器学习领域的研究仍然相对较少。系统优化mRNA受到稀缺且不平衡的数据以及复杂的序列-功能关系的限制。这种方法在数据稀缺和重构时表现不佳，难以探索出生物上有意义的序列空间。", "innovation": "RNAGenScape提出了一种受指导属性的流形拉根文动力学框架，通过迭代更新学习到的潜在空间内的mRNA序列。该框架结合了组织化的自动编码器，通过目标属性结构化潜在空间，便于高效、生物学合理的探索，以及流形投影器，将每次更新重新投影回流形。RNAGenScape支持带有属性导向的优化，可以在序列之间进行平滑插值，同时在数据稀缺和欠采样时保持鲁棒性，确保中间产物接近可行的mRNA流形。", "conclusion": "RNAGenScape在三个真实mRNA数据集上实现了高成功率和效率的特性和性能改进，超越了为蛋白质或非生物数据开发的各种生成或优化方法。通过提供连贯、数据对齐的轨迹，揭示编辑如何影响功能，RNAGenScape为mRNA序列模型的可控制设计和潜在空间探索建立了可扩展的范式。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26788", "html_url": "https://arxiv.org/abs/2510.26788", "title": "通过FP16克服训练推理不匹配", "title_en": "Defeating the Training-Inference Mismatch via FP16", "authors": "Penghui Qi,Zichen Liu,Xiangxin Zhou,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "在使用强化学习（RL）对大型语言模型（LLMs）进行微调的过程中，通常会遇到由于训练和推理政策之间的数值不匹配而导致的不稳定性问题。尽管先前的工作尝试通过算法修正或工程对齐来缓解这一问题，研究发现其根本原因在于浮点精度本身的不一致。尽管广泛采用的BF16格式具有大的动态范围，但由于其引入了大量舍入误差，导致了训练和推理之间的一致性被破坏。因此，研究者们探索了如何通过简单地恢复到FP16来解决这一问题。研究表明，使用FP16可以有效消除这种不匹配，且方法简单、支持广泛且无需修改模型架构或学习算法。", "innovation": "研究发现，通过简单地恢复到FP16（16位定点数）可以有效消除训练推理之间的不匹配问题，并且这种方法简单、能够被现代框架广泛支持且无需对模型架构或学习算法进行任何修改。研究结果表明，使用FP16进行均匀的优化可以带来更稳定的学习优化、更快的收敛速度和更强的跨任务、算法和框架的性能。", "conclusion": "研究提出的使用FP16的方法在多个方面表现出了显著的优势，包括稳定性、收敛速度和性能。研究结果希望引起更广泛对于强化学习微调中的精度权衡的重新思考，鼓励研究者们进一步探索这一领域。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26782", "html_url": "https://arxiv.org/abs/2510.26782", "title": "使用几何正则化的世界模型克隆确定性强三维世界", "title_en": "Clone Deterministic 3D Worlds with Geometrically-Regularized World Models", "authors": "Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen", "background": "世界模型是内部模拟世界如何演化的内部模型。在给定过去的观测和行为后，它预测代理和环境未来的动态。精确的世界模型对于使代理能够在复杂的动态环境中思考、规划和有效推理至关重要。尽管取得了快速进步，但当前的世界模型在长时间跨度上仍然脆弱并会退化。我们通过提高表征学习质量来减少动态学习的难度，提出了通过构建能够完全克隆和拟合确定性3D世界的模型来解决一个基础但开放的问题。这项工作的目的是通过几何正则化的世界模型来提升轨迹上的连贯点在潜在表示空间中的接近性，从而获得显著改善的潜在表示，更好地与环境的真实拓扑结构对齐，从而提高动态预测的准确性和稳定性。这证明了提升表征学习是对抗脆弱的世界模型并实现可靠长时间预测的有效路径，且无需扩大动态模块。", "innovation": "提出了几何正则化的世界模型（GRWM），该模型强制要求自然感性轨迹中的连续点在潜在表示空间中保持接近。这种方法提供了显著改进的潜在表示，与环境的真实拓扑结构对齐得更好。GRWM是即插即用的，只需要最少的架构修改，并且可以根据轨迹长度进行扩展，同时与各种潜在生成式后端兼容。在确定的3D环境中和长时间预测任务中，GRWM显著提高了展开的准确度和稳定性。研究表明其优势源于学习优越的几何结构的潜在流形。", "conclusion": "这些发现支持一个明显结论：改进表征学习是实现强大世界模型的直接和有效途径，可实现可靠的长时预测，且不需扩大动态模块。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26792", "html_url": "https://arxiv.org/abs/2510.26792", "title": "使用变压器学习伪随机数：移位同余生成器，课程学习与可解释性", "title_en": "Learning Pseudorandom Numbers with Transformers: Permuted Congruential Generators, Curricula, and Interpretability", "authors": "Tao Tao,Maissam Barkeshli", "background": "该研究探讨了Transformer模型在学习由移位同余生成器（PCG）生成的序列时的能力，PCG是一种广泛使用的伪随机数生成器（PRNG）。PCG相比线性同余生成器（LCG）引入了额外的复杂性，通过一系列位级移动、异或、旋转和截断操作对隐藏状态进行变换。以往的经典攻击无法完成类似的预测任务，但研究发现，即使输出被截断为单个位，变压器模型也能可靠地预测这些序列，并且在训练中同时呈现多种不同的PRNG时，模型能共同学习这些模式。", "innovation": "研究展示了Transformer模型在处理PCG序列时的能力，包括更大模数（至$2^{22}$）的扩展实验、单个位输出的可靠预测、在训练中混合不同PRNG模型的能力以及发现新的嵌入层聚类现象。特别地，在大型模数的情况下，优化过程长时间停滞，需要加入较小模数的数据进行训练，全示了对大规模模数的学习的关键训练步骤。", "conclusion": "随着模数m的增加，近完美的序列预测所需的实际序列元素数量按m的平方根增长。对于更大的模数，优化会进入长期停滞阶段，但需要结合较小模数的训练数据来提高学习效果。研究还揭示了嵌入层中整数输入自发形成位级旋转不变的簇的新型现象，这表明表示可以从较小的模数转移到较大的模数。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25787", "html_url": "https://arxiv.org/abs/2510.25787", "title": "基于电压依赖突触可塑性的无监督局部学习方法用于阻变和铁电突触", "title_en": "Unsupervised local learning based on voltage-dependent synaptic plasticity for resistive and ferroelectric synapses", "authors": "Nikhil Garg,Ismael Balafrej,Joao Henrique Quintino Palhares,Laura Bégon-Lours,Davide Florini,Donato Francesco Falcone,Tommaso Stecconi,Valeria Bragaglia,Bert Jan Offrein,Jean-Michel Portal,Damien Querlioz,Yann Beilliard,Dominique Drouin,Fabien Alibart", "background": "边缘计算设备在人工智能应用中面临的挑战主要涉及能耗和功能问题。这些设备可以从受脑启发的学习机制中受益，实现低功耗下的实时适应。忆阻突触通过纳米尺度的电致阻变记忆可以发挥关键作用，以在这些边缘设备上执行人工智能工作负载。", "innovation": "引入电压依赖突触可塑性（VDSP），作为一种基于希氏原则的高效无监督和局部学习方法。VDSP能够在不需要复杂的尖峰时间依赖可塑性（STDP）所需脉冲整形电路的情况下实现在线学习。此外，通过验证三种具有不同切换特性的忆阻器设备（TiO2、HfO2基金属氧化物神经突触和HfZrO4基铁电隧道结在MNIST模式识别任务中的无监督学习性能，展示了改进的系统级模拟结果。", "conclusion": "利用VDSP方法，系统层级模拟在所有设备中实现了超过83%的准确性，并优化了设备变异性的影响，提升了系统的鲁棒性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25784", "html_url": "https://arxiv.org/abs/2510.25784", "title": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "title_en": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "authors": "Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee", "background": "本文背景描述了大规模语言模型（LLMs）在部署时通常会附加特定任务适配器以适应多种下游应用。这些适配器的参数量通常仅占基模型的不到1%，但在推理时所需的额外计算量却可能比基模型多出2.5倍。这意味着即使适配器参数量较少，它们仍对推理性能有重要影响。因此，研究旨在解决这一问题，提出了新的零延迟融合低秩适配器（zFLoRA），以减少或几乎没有延迟开销。", "innovation": "本文提出了一种新的零延迟融合低秩适配器（zFLoRA），旨在减少与使用低秩适配器（LoRA）和全量微调（FFT）相比的推理延迟开销。实验结果表明，在1B、3B和7B三种规模的LLMs上，zFLoRA相较于流行的监督微调基准（包括低秩适配器和全量微调）具有竞争力。研究在18个不同的任务上分别进行了常识推理、数学推理和摘要对话三大类测试，并在NPU（Samsung Galaxy S25+）和GPU（NVIDIA H100）平台上进行了延迟测量，结果显示zFLoRA适配器引入了几乎不受延迟影响的性能表现。", "conclusion": "研究证明了零延迟融合低秩适配器（zFLoRA）在不同规模的LLMs上表现良好，特别是在延迟方面优于低秩适配器和全量微调。zFLoRA能够在保持模型性能的同时减少推理时间开销。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26046", "html_url": "https://arxiv.org/abs/2510.26046", "title": "偏置修正数据合成以改善不平衡学习", "title_en": "Bias-Corrected Data Synthesis for Imbalanced Learning", "authors": "Pengfei Lyu,Zhengchi Ma,Linjun Zhang,Anru R. Zhang", "background": "不平衡数据使得分类问题难以平衡假阳性率和假阴性率。一种常见的解决方法是通过生成合成数据以补充少数群体，然后使用观察到和合成的数据训练分类模型。但由于合成数据依赖于观察数据，无法准确复制原始数据分布，因此当钠ively使用合成数据时，预测准确性会降低。", "innovation": "本文提出了一种修正合成数据引入的偏置的方法，并提出了借用多数群体信息的一致估计器。此外，提出了一个偏置校正程序，以减轻合成数据的不良影响，提高预测准确性并避免过拟合。此方法还扩展到了更广泛不平衡数据场景，如不平衡多任务学习和因果推理。", "conclusion": "论文提供了偏置估计的理论性质，包括偏置估计误差的界限和预测准确性改进。模拟结果和手写数字数据集上的数据分析表明了方法的有效性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26008", "html_url": "https://arxiv.org/abs/2510.26008", "title": "通过硬件遥测检测机器学习基础设施中的异常", "title_en": "Detecting Anomalies in Machine Learning Infrastructure via Hardware Telemetry", "authors": "Ziji Chen,Steven Chien,Peng Qian,Noa Zilberman", "background": "现代机器学习演变成了一个紧密耦合的全栈生态系统，结合了硬件、软件、网络和应用程序。许多用户依赖云提供商以弹性、隔离和成本效益的方式提供资源。然而，这些平台由于使用了虚拟化技术，使得运营商无法深入了解用户的负载情况，从而阻碍了资源优化，影响了成本效率和执行时间。", "innovation": "本研究提出了一种名为System-X的新方法，采用硬件为中心的方法，仅依赖于完全可操作的硬件信号，通过一个无监督学习管道检测异常。该方法通过对30多种流行的机器学习模型在各种硬件平台上进行分析，确保了对新兴负载和未知部署模式的适应性。", "conclusion": "通过使用System-X，我们成功地识别了网络和系统配置问题，加速了DeepSeek模型，使其性能提升了5.97%。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26043", "html_url": "https://arxiv.org/abs/2510.26043", "title": "L_1-范正则化不定核逻辑回归", "title_en": "$L_1$-norm Regularized Indefinite Kernel Logistic Regression", "authors": "Shaoxin Wang,Hanjing Yao", "background": "核逻辑回归(KLR)是一种在各种领域广泛应用的强大分类方法。在许多实际场景中，不定核能够捕捉到比正定核更多的领域特定结构信息。", "innovation": "本文提出了一种新的L_1范数正则化不定核逻辑回归（RIKLR）模型，通过引入L_1范数惩罚来促进稀疏性，从而扩展现有的IKLR框架。为了解决由此引入的非光滑性和非凸性带来的优化挑战，提出了一个理论依据牢固且计算高效的近邻线性化算法。", "conclusion": "在多个基准数据集上的实验结果表明，所提出的方法在准确性和稀疏性方面均表现出优越性能。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26094", "html_url": "https://arxiv.org/abs/2510.26094", "title": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "title_en": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "authors": "Yuxin Li,Minghao Liu,Ruida Wang,Wenzhao Ji,Zhitao He,Rui Pan,Junming Huang,Tong Zhang,Yi R. Fung", "background": "该论文介绍了一个基于Lean4的综合物理推理框架，名为Lean4PHYS。背景在于现有的形式化物理推理工作缺乏针对大学级别物理问题的全面框架，以及用于物理推理的基准和相关库。论文中提到的LeanPhysBench是一个包含200个精心构建和同行评审的物理陈述的基准，来源于大学教材和物理竞赛问题。", "innovation": "1. 提出了LeanPhysBench，这是一个基于Lean4的大学级别物理推理基准。\n2. 引入了PhysLib，这是一个社区驱动的资源库，包含了进行形式化物理推理所需的基本单位系统和定理。\n3. 使用多个专家数学证明助手和最新的封闭源代码模型展示了基准和解决方案的有效性，特别是在最具挑战性的模型上表现出了显著的提升。", "conclusion": "研究表明，Lean4PHYS中的基准和提供的库PhysLib能够显著提升证明模型在物理问题上的表现，证明了物理推理框架和基准的挑战性以及库的有效性。这是首次在Lean4中提供物理基准的工作。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26026", "html_url": "https://arxiv.org/abs/2510.26026", "title": "超越界限的配准预测：基于经验回放和加权子采样的策略评估的无分布推断", "title_en": "Conformal Prediction Beyond the Horizon: Distribution-Free Inference for Policy Evaluation", "authors": "Feichen Gan,Youcun Lu,Yingying Zhang,Yukun Liu", "background": "在高风险场景中，强化学习的可靠不确定性量化至关重要。本文提出了一种统一的配准预测框架，用于无限 horizon 策略评估，在在线策略和离线策略环境中构建无分布预测区间。该方法结合了分布型强化学习与配准校准，解决了未观察回报、时间依赖性和分布变换等挑战。理论分析提供了模型失配和重要权重估计情况下的覆盖保证。", "innovation": "提出了一种基于截断模拟的时间感知校准策略，利用经验回放和加权子采样构建模块伪回报。这些创新缓解了模型偏差，恢复了近似互换性，即使在策略转换时也能实现不确定性量化。提供覆盖保证，适用于模型失配和重要权重估计情况。", "conclusion": "在合成环境和基准环境（如Mountain Car）的实验中，本文方法显著提高了覆盖范围和可靠性，优于标准分布型强化学习基线。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26040", "html_url": "https://arxiv.org/abs/2510.26040", "title": "使用强化学习方法加速F1TENTH赛车中的真实世界超车", "title_en": "Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods", "authors": "Emily Steiner,Daniel van der Spuy,Futian Zhou,Afereti Pama,Minas Liarokapis,Henry Williams", "background": "虽然自动驾驶赛车在计时赛中的表现取得了显著进步，但在车对车比赛和超车方面仍然受到严重限制。特别是在实际驾驶场景中，最先进的算法在安全或可靠地完成超车动作方面遇到重大挑战。可靠的与其他车辆之间的导航对于自动驾驶赛车来说至关重要。F1Tenth竞赛提供了一个有用的机会来开发标准化物理平台上的车对车比赛算法。竞赛格式使得可以将超车和车对车比赛算法与最先进的技术进行评价。", "innovation": "研究提出了一个新型的赛车和超车代理，它可以学习可靠地导航赛道并在模拟和现实环境中完成超车行动。该代理被部署在F1Tenth车上，并在与具有不同竞争算法的对手进行实际比赛时进行了测试。结果显示，与仅训练用于比赛的代理相比，该代理通过与对手的训练能够故意执行超车行为，其超车率为87%，而仅训练用于比赛的代理的超车率为56%。", "conclusion": "这项研究通过使用强化学习方法加速了F1Tenth赛车中的真实世界超车。该研究提出的代理人能够在模拟和现实环境中学习可靠地导航赛道并完成故意的超车动作，展示了通过与对手竞争提高智能驾驶赛车超车能力的潜力。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26061", "html_url": "https://arxiv.org/abs/2510.26061", "title": "基于数据驱动的投影生成以高效解决异构二次规划问题", "title_en": "Data-driven Projection Generation for Efficiently Solving Heterogeneous Quadratic Programming Problems", "authors": "Tomoharu Iwata,Futoshi Futami", "background": "二次规划（QP）问题是求解一个目标函数为二次的优化问题，这类问题在工程和经济学中应用广泛。传统方法在解决高维QP问题时可能会遇到计算效率低下的问题。论文通过使用实例自适应的投影方法，提出了一种基于数据驱动的框架来减少这类高维QP问题中的变量数量，从而提高了求解效率和计算质量。", "innovation": "论文设计了一种基于图神经网络的模型，能够为每个具体实例生成适合的投影，使得即使对未见过的问题也能产生高质量的解。该模型通过在异构QP问题上进行训练，以最小化投影求解后的目标函数值的期望。此过程被形式化为二层优化问题，内层优化负责在给定投影下求解QP问题，外层优化负责更新模型参数。为了求解该二层优化问题，论文开发了一种高效算法，该算法无需通过求解器反向传播来计算参数梯度。", "conclusion": "实验结果显示，该方法能以较低的计算时间为异构QP问题生成高质量的可行解，并优于现有方法。此外，论文还对使用神经网络生成的投影矩阵求解QP的泛化能力进行了理论分析。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26020", "html_url": "https://arxiv.org/abs/2510.26020", "title": "PORTool: 使用奖励树训练工具使用的大型语言模型", "title_en": "PORTool: Tool-Use LLM Training with Rewarded Tree", "authors": "Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao", "background": "当前的工具使用大型语言模型（LLMs）在静态数据集上进行训练，能够与外部工具交互并进行多步、工具集成的推理，从而产生工具调用轨迹。然而，这些模型只是模仿了一般工具调用流程中查询解决的方式，缺乏在不断变化和动态的工具调用环境中探索多种可能解决方案的能力，表现出有限的性能。", "innovation": "本文提出了一种强化学习（RL）方法PORTool，鼓励工具使用的LLM探索产生正确答案的各种轨迹。这种方法从生成给定查询的多个运行轨迹开始，一些轨迹共享初始几步，形成树状结构。接下来，基于其提供正确答案和成功调用工具的能力为每个步骤分配奖励。共同的步骤在不同轨迹中获得相同的奖励，同一分支下的不同步骤获得不同的奖励。最后，这些步骤奖励用于计算分支相对优势，与轨迹相对优势混合，用于训练LLM进行工具使用。实验涉及17种工具，覆盖时间敏感和时间不变的话题，进行消融研究来系统地证明步骤奖励的必要性和设计稳健性。并与其它训练方法进行比较，证明了最终准确性和工具调用步骤数量上的显著改进。", "conclusion": "研究通过PORTool方法改进了工具使用的LLM能力，能够探索多种可能的解决方案，特别是在动态环境下，从而提高其最终准确性和效率。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26097", "html_url": "https://arxiv.org/abs/2510.26097", "title": "通过扩散模型实现鲁棒超容量SRS信道修复", "title_en": "Robust Super-Capacity SRS Channel Inpainting via Diffusion Models", "authors": "Usman Akram,Fan Zhang,Yang Li,Haris Vikalo", "background": "准确的信道状态信息（CSI）对可靠的大规模多用户MIMO操作至关重要。在5G新无线电（NR）中，基于互易性的波束形成通过上行参量参考信号（SRS）面临资源和覆盖限制，从而促使出现稀疏非均匀SRS分配。现有的掩码自编码器（MAE）方法虽提高了覆盖范围，但对训练时的遮罩过度拟合，在未见过的损害条件下（如额外遮罩、干扰、削波、非高斯噪声）表现不佳。", "innovation": "提出了一种基于扩散的信道修复框架，将系统模型知识在推理过程中融入一个似然梯度项，使单个训练模型能够根据不同条件进行适应。该方法在标准CDL信道上表现出色，其分数扩散变体实现了显著优于标准Unet基线和单一步骤MAE的表现，在分布迁移情况下的改善幅度高达14 dB NMSE，特别是在具有拉普拉斯噪声和用户干扰的挑战性场景中保持了竞争力。", "conclusion": "这些结果证明，基于扩散引导的修复是一种稳健且通用的方法，可用于5G NR系统中的超容量SRS设计。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26096", "html_url": "https://arxiv.org/abs/2510.26096", "title": "ALMGuard: 安全捷径及其作为音频-语言模型防护栏的发现", "title_en": "ALMGuard: Safety Shortcuts and Where to Find Them as Guardrails for Audio-Language Models", "authors": "Weifei Jin,Yuxin Cao,Junjie Su,Minhui Xue,Jie Hao,Ke Xu,Jin Song Dong,Derui Wang", "background": "近期，音频-语言模型（ALMs）的发展显著提升了多模态理解能力，但也引入了新的安全漏洞。先前的研究揭示，从传统音频逆向工程攻击或基于文本的大语言模型（LLMs）劫持攻击直接转移的防御措施，在对抗ALM特有的威胁方面效果不佳。因此，迫切需要针对ALMs的防御框架。", "innovation": "本文提出ALMGuard，这是首款专门针对ALMs的防御框架。基于安全捷径在ALMs中自然存在的假设，设计了一种识别通用的捷径激活扰动（SAP）的方法，以激活安全捷径，确保ALMs在推理过程中的安全性。此外，还提出了一种受保护的扰动机制M-GSM，限制扰动在那些对劫持攻击敏感但对语音理解不敏感的梅尔频率频率带中。", "conclusion": "通过理论分析和实验结果，证明了该方法在面对已知和未知攻击时的鲁棒性。在四种模型上，原来大的ALM地晚背构背构攻击的成功率降低至4.6%，同时保持与良性基准相当的效用，确立了新的先进水平。相关代码和数据可以在以下链接获取。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26275", "html_url": "https://arxiv.org/abs/2510.26275", "title": "一种生成人工智能增强软件工程过程和软件产品的研究路线图", "title_en": "A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI", "authors": "Domenico Amalfitano,Andreas Metzger,Marco Autili,Tommaso Fulcini,Tobias Hey,Jan Keim,Patrizio Pelliccione,Vincenzo Scotti,Anne Koziolek,Raffaela Mirandola,Andreas Vogelsang", "background": "生成性人工智能（GenAI）正在迅速改变软件工程（SE）实践，影响SE过程的执行方式以及软件系统的开发、运营和演进。", "innovation": "本研究采用设计科学研究，通过三个逐步集成多种证据的循环过程，构建了一个针对GenAI增强SE的研究路线图。使用麦卢汉的四象限作为概念工具，系统地捕捉GenAI对SE过程和软件的影响。", "conclusion": "研究路线图界定了四种基本形式的GenAI增强SE及其相关的研究挑战和机遇，并将其结果转化为未来研究方向。研究结果为未来的预测提供了基础，其中包含2030年软件工程领域的十个预测。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26130", "html_url": "https://arxiv.org/abs/2510.26130", "title": "超越合成基准：评估大语言模型在真实世界类级代码生成中的性能", "title_en": "Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation", "authors": "Musfiqur Rahman,SayedHassan Khatoonabadi,Emad Shihab", "background": "大型语言模型（LLMs）在函数级别生成代码方面取得了显著进展，但在实际软件项目中能否正确生成类级实现尚未完全了解。现有研究主要基于合成基准执行评估，这些基准与真实世界代码存在较大差异。因此，需要一种基于开源代码库的真实基准来评估LLMs在真实世界条件下的泛化能力。", "innovation": "本研究引入了一种基于开源代码库的新基准，将真实世界的类划分为已见过和未见过的部分，以评估LLMs在实际条件下的泛化能力。评估涉及多种LLMs，在不同输入规格、检索增强配置和文档完整性水平下的表现。结果显示，LLMs在真实世界类任务上的表现远低于合成基准，并且在熟悉代码库和新颖代码库之间几乎没有显著差异。有关文档的说明字符串只能带来少量功能准确性的提升，而检索增强生成仅在部分文档情况下最有效，可以通过提供从规范中缺失的具体实现模式来提高正确性。", "conclusion": "此基准和分析揭示了当前LLM在类级工程中的关键局限性，提供了有关增强上下文建模、文档策略及检索整合方面的实用见解，以为生产代码辅助工具的发展提供建设性指导。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26121", "html_url": "https://arxiv.org/abs/2510.26121", "title": "基于物理信息的诊断方法以识别物理机器学习中的不确定性", "title_en": "Uncertainty-Aware Diagnostics for Physics-Informed Machine Learning", "authors": "Mara Daniels,Liam Hodgkinson,Michael Mahoney", "background": "物理信息的机器学习（PIML）通过在机器学习模型拟合物理数据的过程中整合先验物理信息，通常以微分方程约束的形式存在。现有的PIML方法，如神经算子、物理感知神经网络、神经常微分方程和神经离散平衡等，通常同时考虑了数据和物理约束。然而，这种多目标方法导致了模型质量测量中的含糊性，这与对Epistemic不确定性理解的不足有关，可能导致即使在现有统计指标显示良好拟合的情况下，仍出现令人惊讶的失败模式。", "innovation": "本文在Gaussian过程回归框架下引入了基于物理信息的日志似然分数（PILE），这是一个单一、具备不确定性识别能力的度量标准，用于PIML模型超参数的选择。PILE不仅能优化模型的综合参数选择，包括核带宽、最小二乘正则化权重，甚至核函数的选择，还能够在数据获取之前识别出适应特定PDE的先验核选择，从而在没有实际数据的情况下也具有指导意义。未来，PILE评分有望应用于更广泛的PIML领域，作者概述了可能的方法以扩大其适用范围。", "conclusion": "通过最小化PILE，可以作出广泛模型参数的选择。在核设置方面，PILE分数已经展示出了显著的效果，可以优化模型的拟合和不确定性评估。同时，PILE分数通常优于现行的不确定性诊断工具，包括但不限于常见的统计指标和基于测试损失的方法。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26274", "html_url": "https://arxiv.org/abs/2510.26274", "title": "PVMark：使大型语言模型水印方案具备公开展示验证性", "title_en": "PVMark: Enabling Public Verifiability for LLM Watermarking Schemes", "authors": "Haohua Duan,Liyao Xiang,Xin Zhang", "background": "针对大型语言模型（LLMs）生成文本溯源的需求，已有水印方案提出，旨在防范模型盗用带来的潜在威胁。然而，现有方案在信任问题上存在不足，因为非公开的水印检测方式无法给公众提供可靠的验证。问题的核心在于用于水印检测的密钥既不能公开以防止对手发起删除攻击，也不能使水印检测过程对公众透明，从而避免了密钥的泄露。因此，目前的水印解决方案难以同时满足安全性与透明性要求，导致可信度问题难以解决。", "innovation": "为解决这一困境，作者提出了基于零知识证明（ZKP）的插件PVMark，它可以使第三方能够无需暴露任何密钥进行水印检测结果的验证。PVMark的核心在于构建了一套ZKP约束，包括正确的映射、随机数生成、比较和求和证明，确保能够在保持性能的同时实现公开展示的验证性。作者实现了多种基于Python、Rust和Circom的PVMark变体，涵盖了不同类型的水印方案和哈希函数的组合，展示了其在各种情况下均有良好的应用效果。", "conclusion": "实验证明，PVMark能够高效地实现先进LLM水印方案的公开展示验证，同时不会损害水印性能，为实际应用提供了有前景的解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26593", "html_url": "https://arxiv.org/abs/2510.26593", "title": "混合物理-神经网络仿真器以实现快速宇宙流体力学", "title_en": "Hybrid Physical-Neural Simulator for Fast Cosmological Hydrodynamics", "authors": "Arne Thomsen,Tilman Tröster,François Lanusse", "background": "宇宙学领域中的场级推理需要能够解决气体和暗物质在流体力学和重力作用下复杂动力学的可微分前向模型。现有方法往往难以同时准确模拟这些复杂的物理现象。", "innovation": "提出了一种混合方法，其中重力作用通过可微分的粒子-网格求解器进行计算，而流体力学则通过一个神经网络实现，该网络根据局部量映射到有效压力场。实验表明，该方法在场级别和统计级别上都优于现有的替代方法（如基于焓梯度下降的基础线）。此外，这种处理方式非常节省数据，使用一个参考模拟数据就足够约束神经压力模型，使得该模型可以直接适应观察数据，而不需要大量的仿真训练集。", "conclusion": "这种方法开辟了可以在实际观测数据上直接拟合模型的新前景，有助于提高宇宙学研究中的数据利用率和模型精度。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26700", "html_url": "https://arxiv.org/abs/2510.26700", "title": "因果机器学习模型中的条件可交换性假设评估：一项模拟研究", "title_en": "Assessment of the conditional exchangeability assumption in causal machine learning models: a simulation study", "authors": "Gerard T. Portela,Jason B. Gibbons,Sebastian Schneeweiss,Rishi J. Desai", "background": "许多基于观察的研究利用因果机器学习（ML）模型预测个体化治疗效应（ITEs），但很少有研究对这些模型的性能进行实证评估，以检验因果森林和X-学习器等模型在面对条件可交换性假设违逆情况下的表现。本研究旨在通过模拟数据评估这些模型在不同条件下 ITE 估计中的偏倚情况，特别是在存在未测量混杂因素的情况下。", "innovation": "研究采用了一种评估方法，即利用模拟数据来测试因果模型在条件可交换性约束违逆情况下的性能，并引入了负控制结果（NCOs）作为一种诊断工具。通过比较主要结局和NCOs在存在未测量混杂因素和未存在情况下的亚组级治疗效应，研究发现NCOs能够识别受未测量混杂因素影响的亚组。", "conclusion": "条件可交换性假设的违逆会极大地限制因果机器学习模型在常规收集观察数据中关于个体治疗效应估计的有效性。NCOs为检测亚组特定的未测量混杂因素提供了一个有用的实证诊断工具，应在因果机器学习流水线中纳入这一工具以增强个体化推理的信任度。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26723", "html_url": "https://arxiv.org/abs/2510.26723", "title": "通过实证福利最大化与条件平均处理效应估计在政策学习中的联系弥合差距", "title_en": "Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning", "authors": "Masahiro Kato", "background": "政策学习的目的是训练一个政策函数，在给定协变量的情况下推荐治疗方案以最大化人群福利。该领域有两种主要方法：实证福利最大化（EWM）方法和插值方法。EWM方法类似于分类问题，先构建一个群体福利的估计器，再通过最大化估计的福利来训练政策。相反，插值方法基于回归，先估计条件平均处理效应（CATE），然后推荐具有最高估计结果的治疗。", "innovation": "本文证明了这两种方法本质上基于相同的优化问题，并且提供了一个新的正则化方法用于政策学习。通过EWM和最小二乘法在重新参数化政策类中的等效性，提出了一个凸的且计算效率高的训练程序，该程序避免了EWM中通常需要的NP难组合步骤。", "conclusion": "两种方法在某些方面可以互换，并在相同条件下共享相同的理论保证。研究结果表明，EWM和CATE估计之间的等效性为政策学习提供了一个更高效的新正则化方法。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26707", "html_url": "https://arxiv.org/abs/2510.26707", "title": "价值偏移：追踪LLM后训练过程中的价值对齐", "title_en": "Value Drifts: Tracing Value Alignment During LLM Post-Training", "authors": "Mehar Bhatia,Shravan Nayak,Gaurav Kamath,Marius Mosbach,Karolina Stańczak,Vered Shwartz,Siva Reddy", "background": "随着大型语言模型（LLM）在社会中的作用日益增强，它们越来越需要不仅依赖于通用知识，还要与某些人类价值观对齐。已有研究主要关注评估完全训练好的模型的价值对齐情况，但忽视了模型在学习表达人类价值观过程中的训练动态。本文研究了价值对齐在模型后训练阶段如何以及在哪个阶段发生。通过使用不同规模的Llama-3和Qwen-3模型，并结合多种流行的监督微调（SFT）和偏好优化数据集及算法，研究发现SFT阶段通常建立模型的价值，并且随后的偏好优化很少重新调整这些价值观。此外，利用一个可以控制调整价值的合成偏好数据集，研究发现即使偏好数据保持不变，不同的偏好优化算法也会导致不同的价值对齐结果。", "innovation": "本文的创新之处在于它研究了LLM在后训练阶段的价值对齐动态。通过将后训练算法和数据集的影响分离，测量价值偏差的大小和时间。研究中还使用了由合成偏好数据集引起的变化，来探索不同偏好优化算法导致的价值对齐结果的差异。", "conclusion": "本文的研究结果提供了关于价值学习在后训练阶段的具体见解，并有助于数据收集过程以及选择模型和算法来改进模型与人类价值观的对齐。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26672", "html_url": "https://arxiv.org/abs/2510.26672", "title": "连续时间控制的驱动过程", "title_en": "Action-Driven Processes for Continuous-Time Control", "authors": "Ruimin He,Shaowei Lin", "background": "强化学习的核心是行动——在观测到环境后做出的决策。行动对于建模随机过程同样是基础的，因为它们触发了不连续的状态转换，并且使得信息能够在复杂的系统中流动。本文通过行动驱动过程统一强化学习和随机过程的视角，展示了其在脉冲神经网络中的应用。", "innovation": "本文借鉴了控制即推理的想法，通过最小化由策略驱动的真分布和由奖励驱动的模型分布之间的相对熵，证明了最大熵强化学习的重要等价性。这种方法将随机过程和强化学习的视角统一起来，并且展示了行动驱动过程在脉冲神经网络中的应用。", "conclusion": "本文通过行动驱动过程解析了强化学习与随机过程的联合，展示了解决连续时间控制问题的可能性。利用控制即推理的概念，本文提出的方法适用于复杂系统中的信息流控制，可以应用于脉冲神经网络中。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26688", "html_url": "https://arxiv.org/abs/2510.26688", "title": "FlowQ-Net: 基于生成网络的自动化量子电路设计框架", "title_en": "FlowQ-Net: A Generative Framework for Automated Quantum Circuit Design", "authors": "Jun Dai,Michael Rizvi-Martel,Guillaume Rabusseau", "background": "设计高效的量子电路是探索量子计算潜力的一个关键瓶颈，尤其是在噪声中间规模量子(NISQ)设备中，电路效率和抗错误能力至关重要。门序列的空间呈组合性增长，手工设计的模板经常浪费稀缺的量子位和深度预算。", "innovation": "我们引入了FlowQ-Net（流式量子设计网络），一种基于生成流网络（GFlowNets）的自动量子电路合成生成框架。该框架学习一个随机策略，按比例采样电路，采样的频率由灵活的用户定义的奖励函数确定，该奖励函数可以编码多个设计目标，如性能、深度和门的数量。这种方法使得生成一系列高质量且多样化的电路成为可能，超越了单一解决方案的优化。", "conclusion": "FlowQ-Net在一系列模拟中证明了其有效性。我们的方法被应用于变量子算法（VQA）方案设计，以估计分子基态、最大割和图像分类等近期内量子计算中的关键挑战。由FlowQ-Net设计的电路在参数、门的数量和深度方面显著更紧凑，减少了10-30倍，而在准确性方面并未受到影响。即使面对来自真实量子设备的错误配置文件，这一趋势也保持不变。我们的结果强调了生成模型作为通用方法在自动量子电路设计中的潜力，为更有效的量子算法铺平了道路，加速了量子领域的科学发现。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26609", "html_url": "https://arxiv.org/abs/2510.26609", "title": "CYPRESS: 通过 Prithvi 编码器进行卫星传感回归的作物产量预测", "title_en": "CYPRESS: Crop Yield Prediction via Regression on Prithvi's Encoder for Satellite Sensing", "authors": "Shayan Nejadshamsi,Yuanyuan Zhang,Shadi Zaki,Brock Porth,Lysa Porth,Vahab Khoshdel", "background": "准确及时的作物产量预测对全球粮食安全和现代农业管理至关重要。传统的预测方法往往缺乏用于精准农业所需的可扩展性和粒度。现有的基于深度学习的作物产量预测模型通常在精度和分辨率上有所欠缺。", "innovation": "本文介绍了 CYPRESS (Crop Yield Prediction via Regression on Prithvi's Encoder for Satellite Sensing)，这是一种用于高分辨率、田间尺度油菜产量预测的深度学习模型。CYPRESS 利用预训练的大型时空基础模型（Prithvi-EO-2.0-600M）进行调优，并将其用于连续回归任务，将多时间点的卫星影像转换为密集的像元级产量图。在加拿大平原的综合数据集上评估，CYPRESS 在作物产量预测性能上优于现有的基于深度学习的技术，证明了对大型地球观测和现场决策之间的桥梁方法的有效性。", "conclusion": "通过提供连续的高分辨率输出，CYPRESS 为精准农业提供了比传统的分类或县级汇总方法更具操作性的工具。这项工作验证了一种全新的方法，填补了大型地球观测和现场决策之间的空白，提供了一种针对详细农业监测的可扩展解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26646", "html_url": "https://arxiv.org/abs/2510.26646", "title": "混合DQN-TD3强化学习在动态环境中的自主导航", "title_en": "Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments", "authors": "Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai", "background": "该研究背景涉及在动态和部分可观察环境中实现自主导航。传统的路径规划和控制方法往往不足以处理环境中的动态障碍物和不确定性。因此，需要一种能够结合高、低层次控制的策略来提高导航的成功率和效率。", "innovation": "本文提出了一种结合高阶Deep Q-Network (DQN) 和低阶Twin Delayed Deep Deterministic Policy Gradient (TD3) 的分层路径规划和控制框架。研究设计了一种实用的奖励塑造方案，包括方向、距离、障碍物规避、动作平滑性、碰撞惩罚、时间惩罚和进展等。此外，还提出了一种基于LiDAR的安全门机制来防止不安全的运动。", "conclusion": "实验结果显示，该框架在不同环境下的成功率和样本效率优于单算法基准（DQN或TD3单独使用）和基于规则的规划方法。该系统在ROS + Gazebo（TurtleBot3）上实现并用PathBench度量进行评估，出现了更好的未见障碍配置的一般化和减少了突然的控制变动。相关代码和评估脚本已在项目仓库中开源。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26692", "html_url": "https://arxiv.org/abs/2510.26692", "title": "Kimi Linear：一种富有表现力且高效的注意力架构", "title_en": "Kimi Linear: An Expressive, Efficient Attention Architecture", "authors": "Kimi Team:Yu Zhang,Zongyu Lin,Xingcheng Yao,Jiaxi Hu,Fanqing Meng,Chengyin Liu,Xin Men,Songlin Yang,Zhiyuan Li,Wentao Li,Enzhe Lu,Weizhou Liu,Yanru Chen,Weixin Xu,Longhui Yu,Yejie Wang,Yu Fan,Longguang Zhong,Enming Yuan,Dehao Zhang,Yizhi Zhang,T.Y. Liu,Haiming Wang,Shengjun Fang,Weiran He,Shaowei Liu,Yiwei Li,Jianlin Su,Jiezhong Qiu,Bo Pang,Junjie Yan,Zhejun Jiang,Weixiao Huang,Bohong Yin,Jiacheng You,Chu Wei,Zhengtao Wang,Chao Hong,Yutian Chen,Guanduo Chen,Yucheng Wang,Huabin Zheng,Feng Wang,Yibo Liu,Mengnan Dong,Zheng Zhang,Siyuan Pan,Wenhao Wu,Yuhao Wu,Longyu Guan,Jiawen Tao,Guohong Fu,Xinran Xu,Yuzhi Wang,Guokun Lai,Yuxin Wu,Xinyu Zhou,Zhilin Yang,Yulun Du", "background": "研究领域内的注意力机制，尤其是线性注意力，已经被广泛应用于各种任务中，并且在模型性能和效率方面取得了显著进展。然而，full attention（全注意力机制）在某些情况下可能显得不太经济，特别是在计算和存储资源有限的环境中，或者在处理长上下文的情况下。因此，研究者们一直在探索和改进不同类型的注意力机制，以期找到一种既能保证性能又能提高效率的替代方案。", "innovation": "Kimi Linear是一种融合了线性注意力的新型架构，首次在公平比较的条件下跨各种场景（包括短上下文、长上下文以及强化学习扩展阶段）表现优于全注意力机制。Kimi Linear的核心在于Kimi Delta Attention (KDA)，这是一种更为表达性的线性注意力模块，它扩展了Gated DeltaNet并通过精细粒度的门控机制优化了有限状态RNN内存的使用效率。Kimi Linear的专用分块算法通过特定的迪安格-低秩（DPLR）过渡矩阵的变体实现了高硬件效率，显著降低了计算量，同时更符合经典的delta规则。", "conclusion": "实验结果显示，使用相同训练方法的情况下，Kimi Linear在所有测试任务中均大幅超越了全MLA模型，同时减少KV缓存使用达75%并实现了6倍的解码吞吐量。这些结果表明，Kimi Linear可以作为一个性能更优且效率更高的全注意力架构替代品，适用于处理更长输入和输出的任务。为了支持进一步的研究，我们开源了KDA内核和vLLM实现，并发布了预训练和指令调优的模型检查点。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26656", "html_url": "https://arxiv.org/abs/2510.26656", "title": "Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems", "title_en": "Heuristic Adaptation of Potentially Misspecified Domain Support for Likelihood-Free Inference in Stochastic Dynamical Systems", "authors": "Georgios Kamaras,Craig Innes,Subramanian Ramamoorthy", "background": "在机器人学中，无likelihood推断（LFI）能够提供一个适应学习代理的领域分布，这类分布适用于一组先验参数设定的部署条件。LFI假设采样的支持集是任意的且保持不变，初始的通用先验通过迭代优化不断提高描述性后验概率。然而，潜在不正确的支持集可能导致次优的，并且错误地具有确定性的后验概率。", "innovation": "本文提出了三种启发式LFI变体：EDGE、MODE和CENTRE。每个变体以自己的方式解释后验模式的变化，并在整合到LFI步骤中时调整支持集。作者首先揭示了支持集的潜在不正确问题，通过随机动力学基准评估他们的启发式方法。接着评估启发式支持适应对参数推断和政策学习的影响，特别是对于动态可变形线性物体（DLO）操作任务。研究表明，使用这些启发式后验概率作为基于模拟的策略学习的领域分布，能获得更具有鲁棒性的物体中心代理性能。", "conclusion": "该研究的结果表明，通过迭代调整支持集和后验推理的变体能够克服LFI中支持集不正确的问题，进而提高了参数估计和策略学习的鲁棒性和准确性。特别是在处理动态可变形线性对象时，获得了更细致的长度和刚度分类结果。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26752", "html_url": "https://arxiv.org/abs/2510.26752", "title": "监督博弈：学习协同平衡AI代理的安全与自主性", "title_en": "The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy", "authors": "William Overman,Mohsen Bayati", "background": "随着越来越有能力的代理被部署，一个核心的安全问题是保持有意义的人类控制，而不修改底层系统。本文研究了一个最小的控制接口，即代理根据自主行动（玩耍）或推迟（求助）做决定，同时人类同时决定是否做到宽容（信任）或进行监督（监管）。如果代理推迟，人类的选择会决定结果，甚至可能导致纠正措施或系统关闭。", "innovation": "本文将这种交互建模为两个玩家的马尔可夫博弈，并专注于当此博弈被分类为马尔可夫潜力博弈（MPG）时的情况。在人类价值函数符合结构假设的情况下，任何代理自主行动的决定不会损害人类的价值。此外，还分析了MPG框架的扩展。理论上来讲，这种视角提供了特定形式的内在对齐条件。如果人类-代理博弈的奖励结构符合这些条件，就有形式上的保证，即代理改善自身结果不会损害人类。实践上，此模型激发了一个透明的控制层，具有可预测的激励机制，其中代理在危险时学会推迟，安全时行动，而其预训练策略和环境奖励结构保持不变。", "conclusion": "通过网格世界的模拟显示，代理和人类通过独立学习发现其最佳监督角色。代理学习在不确定时询问，人类学习何时监管，导致了安全的自发合作，避免了训练后引入的安全违规行为。本文演示了一种实用的方法，用于使部署后的模型更加安全。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.17883", "html_url": "https://arxiv.org/abs/2412.17883", "title": "捍卫事后解释方法", "title_en": "In Defence of Post-hoc Explainability", "authors": "Nick Oh", "background": "这篇论文批判了事后解释方法在机器学习领域可靠性及认识论地位上受到的批评。背景信息指出，这些方法有被怀疑无法提供完全的机制透明度，导致科学知识生产中存在局限性。", "innovation": "该论文提出的创新点是在哲学框架基础上引入中介理解和有限知觉的概念，以证明科学见解可以通过结构化的模型行为解释得出，这解释无需完全的机制透明度，只要承认解释的近似性和经过严格的实证检验。通过分析生物医学机器学习应用的具体案例，展示了在适当整合到科学实践中，事后解释方法可以产生新的假说并推进对现象的理解。", "conclusion": "论文结论总结认为，在科学实践中适当整合事后解释方法，可以生成新颖的假说并推进对现象的理解。尽管这些解释具有一定的近似性，但通过严格的实证检验，可以确保这些方法的有效性并在科学知识生产中发挥正当作用。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.03348", "html_url": "https://arxiv.org/abs/2410.03348", "title": "Dolphin：一种可编程的可扩展神经符号学习框架", "title_en": "Dolphin: A Programmable Framework for Scalable Neurosymbolic Learning", "authors": "Aaditya Naik,Jason Liu,Claire Wang,Amish Sethi,Saikat Dutta,Mayur Naik,Eric Wong", "background": "神经符号学习结合了符号推理和深度学习，但面临在复杂符号程序、大型数据集或两者上扩展的显著挑战。现有框架如Scallop、ISED和IndeCateR+在处理复杂基准时难以在规定时间内收敛，且在简单基准上的表现不如基线。", "innovation": "DOLPHIN通过支持Python中的神经符号程序、在CPU上执行复杂的符号推理并使用GPU向量化概率计算和梯度传播，解决了这些挑战。DOLPHIN在13个覆盖文本、图像和视频数据的任务基准上表现出色，特别是在需要递归和黑盒函数的复杂基准上超越了现有框架，同时在简单基准上表现出与现有框架相当的性能，并且速度快1.71到62倍。", "conclusion": "DOLPHIN推进了神经符号框架的可扩展性，实现了在难处理的基准测试中的先进效率和收敛性，提升了整体性能。完整的代码已发布在提供的链接中。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06324", "html_url": "https://arxiv.org/abs/2410.06324", "title": "通过黑盒二次规划求解器进行微分", "title_en": "Differentiation Through Black-Box Quadratic Programming Solvers", "authors": "Connor W. Magoon,Fengyu Yang,Noam Aigerman,Shahar Z. Kovalsky", "background": "可微优化引起了广泛的研究兴趣，特别是在二次规划（QP）中。现有的QP解决方案对参数的微分方法通常依赖于特定已集成的求解器。这种集成限制了这些方法的应用范围，包括它们在神经网络架构和多层优化任务中的使用，限制了用户的选择范围。", "innovation": "我们提出了一种模块化且求解器无相关的框架dQP，用于无缝微分任何QP求解器。通过已知不等式约束的激活集，我们将QP解及其导数表示为具有相同矩阵的简化线性系统，从而实现QP解与微分计算的完全分离。我们还提供了一个零开销开源实现（https://github.com/dqpproject/dqp），可以与15个最先进的求解器无缝集成。", "conclusion": "全面的基准实验表明，dQP在鲁棒性和可扩展性方面表现出色，特别是在大型稀疏问题中具有明显优势。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.12652", "html_url": "https://arxiv.org/abs/2410.12652", "title": "Constrained Posterior Sampling: 时间序列生成中的硬约束", "title_en": "Constrained Posterior Sampling: Time Series Generation with Hard Constraints", "authors": "Sai Shankar Narasimhan,Shubhankar Agarwal,Litu Rout,Sanjay Shakkottai,Sandeep P. Chinchali", "background": "生成逼真的时间序列样本对于压力测试模型和使用合成数据保护用户隐私至关重要。在工程和安全关键应用中，这些样本必须满足特定的领域特定约束或由物理或自然条件自然施加的约束。例如，在生成限电需求模式时，需要在特定的高峰需求时间进行约束，用于评估电网在恶劣天气条件下的运行情况。现有的生成约束时间序列的方法要么不具有可扩展性，要么降低样本质量。", "innovation": "提出了一种基于扩散的采样算法——约束后验采样（CPS），旨在在每次去噪更新后将后验均值估计投影到约束集中。该方法能够处理大量约束（约100个）而无需额外训练，提供理论依据以突出投影步骤对采样的影响。实验结果显示，CPS在样本质量和接近实际时间序列方面分别比最先进的方法高出约70%和22%。", "conclusion": "CPS算法能够有效地满足多种领域特定约束，同时保持生成时间序列的质量，为工程和安全关键应用提供了更好的数据解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.12052", "html_url": "https://arxiv.org/abs/2411.12052", "title": "HoGA: 通过多样性意识的k跳采样实现高阶图注意力", "title_en": "HoGA: Higher-Order Graph Attention via Diversity-Aware k-Hop Sampling", "authors": "Thomas Bailie,Yun Sing Koh,Karthik Mukkavilli", "background": "图模型在许多现实世界系统中用来表征潜在变量之间的关系。消息传递神经网络（MPNNs）被广泛用于学习这些结构以完成下游任务。虽然基于边的MPNNs可以有效地捕捉局部交互，但它们的表达能力受到理论限制，限制了高级关系的发现。现有的一些高阶注意力方法通过贪婪重新采样相似的高阶关系，而未能充分利用来自不同模态的多样关系，这限制了这些模型的表现能力。", "innovation": "提出了HoGA模块，通过采样子图来构建k阶注意力矩阵，最大化特征向量之间的多样性。与现有方法不同，HoGA专注于高阶拓扑中的多样化模式，减少冗余并扩展捕捉的子结构范围。在两个单一跳注意力模型上应用HoGA，实验结果显示它在所有基准节点分类数据集上至少提高了5%的精度，并在8个数据集中的6个数据集上优于最近的基线模型。", "conclusion": "HoGA模块通过多样性的采样方法提高了高阶图注意力模型的能力，使其在下游任务中表现更佳，并为未来的研究提供了新的方向。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.08525", "html_url": "https://arxiv.org/abs/2406.08525", "title": "具有部分单调性和可信AI应用的神经网络的数学认证", "title_en": "A mathematical certification for positivity conditions in Neural Networks with applications to partial monotonicity and Trustworthy AI", "authors": "Alejandro Polo-Molina,David Alfaya,Jose Portela", "background": "人工神经网络（ANNs）是处理大规模数据集中的复杂关系的强大工具。然而，它们的黑箱特性引起了可信赖性问题。特别是在某些情况下，为了确保预测的可信度，需要遵循具体的部分单调性约束。但是，验证一个已经训练好的ANN是否部分单调是具有挑战性的。因此，ANN通常在需要部分单调性的关键应用中被忽略，如信用评分。", "innovation": "本文提出了一种名为LipVor的新算法，该算法可以在有限次评估下证明一个黑盒模型（如ANN）是否为正。通过利用黑盒模型的Lipschitzian性构造一个具体邻域，确保函数在该邻域内为正。基于评估点的Voronoi图，该算法提出了一种必要条件来证明函数在整个域内为正。与之前的算法不同，该方法不需要受约束的架构或分段线性激活函数，因此为在某些关键领域使用非约束ANN提供了可能性。此外，ANN的其他属性，如凸性，也可以用正性的条件来表示，因此LipVor也可以应用。", "conclusion": "LipVor算法可以证明ANN的部分单调性和正性条件，从而为关键应用中的ANN使用打开了可能性，同时神经网络的其他正性条件也可以用LipVor来验证。这对于增强AI的可信性具有重要意义。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.09766", "html_url": "https://arxiv.org/abs/2410.09766", "title": "稳定性与收敛率$\tilde{O}(1/n^2)$的更紧风险界", "title_en": "Stability and Sharper Risk Bounds with Convergence Rate $\\tilde{O}(1/n^2)$", "authors": "Bowei Zhu,Shaojie Li,Mingyang Yi,Yong Liu", "background": "之前的研究所（Klochkov 和 Zhivotovskiy，2021）通过算法稳定性为强凸学习者提出了最大可能为 $O(\frac{\text{log}(n)}{n})$ 的风险过限界。本文在类似假设下——Polyak-Lojasiewicz 条件、光滑性和损失的Lipschitz连续性——证明了最紧的风险界限为 $O(\frac{\text{log}^2(n)}{n^2})$。我们的分析还提供了非凸环境下的梯度基学习器风险过限的最紧高概率界。", "innovation": "本文通过在非凸环境下对梯度基学习器进行分析，实现了较紧的风险界限 $O(\frac{\text{log}^2(n)}{n^2})$，并且这一结果对于我们来说是迄今为止最紧的对非凸环境下的高概率风险过限的分析。", "conclusion": "在本研究中，我们在强凸学习者的算法稳定性基础上，通过引入Polyak-Lojasiewicz 条件、光滑性和损失的Lipschitz连续性等环境假设，得出了最紧的高概率风险过限界 $O(\frac{\text{log}^2(n)}{n^2})$，并且该结果是对非凸环境下的梯度基学习器风险过限的最紧分析。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.08493", "html_url": "https://arxiv.org/abs/2408.08493", "title": "继承模型网络中的并行卸载", "title_en": "Parallel Unlearning in Inherited Model Networks", "authors": "Xiao Liu,Mingyuan Li,Guangsheng Yu,Lixiang Li,Haipeng Peng,Ren Ping Liu", "background": "在通用学习框架中，随着模型的不断增长和更新，以及模型间复杂继承关系的产生，卸载（即删除特定学习信息）变得具有挑战性。传统的方法无法高效地处理继承模型间的并行卸载，尤其是在多种卸载请求同时发生时，会导致计算负担增加和卸载效果不佳。因此，本研究旨在提出一种新的卸载框架，以支持继承模型间完全并行卸载，特别是在应对复杂继承关系时提高卸载的效率和效果。", "innovation": "本研究提出了一种名为Fisher Inheritance Unlearning (FIUn)的新方法，并设计了一个基于时间的有向无环图（DAG）来捕捉继承模型网络中的各种卸载场景。FIUn方法使用Fisher信息矩阵评估模型参数对卸载任务的重要性，并相应地调整这些参数。提出的Merging-FIM（MFIM）函数能够将来自多个上游模型的FIM合并为一个统一矩阵，从而支持所有DAG捕捉到的卸载场景，实现在不影响保留标签准确性的情况下一次性移除继承知识，并显著降低计算开销。实验结果验证了该框架的有效性，相对于其他方法，该框架在单类任务中实现了高达99%的卸载加速。", "conclusion": "本研究提出了一种新颖的并行卸载框架FIUn，通过使用时间导向的DAG和FIM以及MFIM函数，有效地处理了继承模型网络中的卸载问题。实验结果表明，该框架在保持保留标签准确性的同时实现了高效且完全的卸载，计算开销显著降低。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.10573", "html_url": "https://arxiv.org/abs/2411.10573", "title": "Hysteresis 激活函数用于高效的推理", "title_en": "Hysteresis Activation Function for Efficient Inference", "authors": "Moshe Kimhi,Idan Kashani,Avi Mendelson,Chaim Baskin", "background": "通常使用的ReLU因其在硬件效率上的优势受到青睐，因为它在推断阶段的实现只需一位符号操作，但仍然存在如“死亡ReLU”问题等缺点。在训练过程中，神经元会因无法激活而一直保持在零值状态。传统的方法通过引入更复杂且不太硬件友好的激活函数来缓解这一问题。", "innovation": "本文提出了一种适用于解决“死亡ReLU”问题的高效激活函数HeLU（Hysteresis Rectified Linear Unit）。HeLU在训练和推理中使用可变阈值来改进反向传播机制，使得较为简单的激活函数能够达到与复杂激活函数相当的性能，同时减少不必要的复杂性和对归纳偏置的需求。", "conclusion": "实验结果表明，HeLU在多种数据集中提升了模型的泛化能力，提供了一种适合各种神经网络架构的高效且有效的推理解决方案。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01074", "html_url": "https://arxiv.org/abs/2502.01074", "title": "Omni-Mol: 任意到任意模态的多任务分子模型", "title_en": "Omni-Mol: Multitask Molecular Model for Any-to-any Modalities", "authors": "Chengxin Hu,Hao Li,Yihe Yuan,Zezheng Song,Chenyang Zhao,Haixin Wang", "background": "在分子领域，尽管有多项研究表明可以使用多模态大型语言模型来构建通用的多任务分子模型，但这些研究仍远未实现真正的通用分子模型。现有挑战包括分子任务数据集规模较小、覆盖面不全；不同分子子领域的任务难以有效联合学习，增加了学习过程的不稳定性；以及分子任务和任务内表示的内在维度差异，使得语言模型的表示在冗余和不足之间难以平衡。这些问题限制了多任务分子模型的广泛应用和效果发挥。", "innovation": "本研究创新性地将现有的小分子任务分类为四种类型：Mol2Mol、Mol2Text、Mol2Num 和 Text2Mol，并收集了包含超过16个任务和140多万个样本的数据集，成为迄今为止最大的分子指令调优数据集。通过利用LLMs对现有化学文献的广泛预训练，提出了一种新的多模态LLM框架Omni-Mol，可以统一处理所有小分子任务并支持分子生成和理解。Omni-Mol的核心是提出的MoGE，这是一种混合专家架构，能够动态适应不同任务的固有难度，提高了模型处理多样任务和模态的能力。实验结果表明，Omni-Mol在16个任务上实现了统一的指令调优，并在13个任务上达到了最先进的性能。实验证明Omni-Mol具有较大的可扩展性和多功能性。", "conclusion": "Omni-Mol框架通过消除上述多任务分子模型面临的挑战，成功地实现了小分子任务的统一指令调优，并在多个任务上达到了最先进的性能。该研究为构建更加高效和广泛应用的多模态分子模型奠定了基础，展示了模型在分子领域中广泛的适用性和潜力。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09969", "html_url": "https://arxiv.org/abs/2502.09969", "title": "基于神经网络的可学习和可扩展的指令微调数据影响力估计方法", "title_en": "Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data", "authors": "Ishika Agarwal,Dilek Hakkani-Tür", "background": "现有的影响函数方法提供了对模型训练的重要见解，但它们存在计算成本高和泛化能力有限的问题。特别是在使用语言模型计算数据的影响时，这些方法无法很好地扩展到大型模型和数据集。这主要是由于计算中昂贵的前向和反向传递、需要存储大量模型的巨大内存需求以及影响估计对新数据的泛化性能较差。本文研究了使用小型神经网络（我们称之为InfluenceNetwork）来估计影响力值，从而实现成本最多减少99%。", "innovation": "提出了一种名为InfluenceNetwork的小型神经网络，用于估计影响值，显著降低了计算成本，只需原始语言模型的0.0027%的大小即可实现影响值的估计。将该算法应用于通用指令微调数据的子集选择下游任务，并展示了与传统影响函数相比，速度大幅提升但性能不变的结果。对InfluenceNetwork进行了深入的超参数分析。", "conclusion": "本研究不仅展示了使用小型神经网络估计影响值的高效性和准确性，还为指令微调数据的选择提供了一种新的、可扩展的方法，同时保证了性能不受影响。这种方法对于大规模语言模型的微调具有重要的实际意义。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24627", "html_url": "https://arxiv.org/abs/2505.24627", "title": "重新思考用于不同约束紧度的车辆路线问题的神经组合优化", "title_en": "Rethinking Neural Combinatorial Optimization for Vehicle Routing Problems with Different Constraint Tightness Degrees", "authors": "Fu Luo,Yaoxin Wu,Zhi Zheng,Zhenkun Wang", "background": "近期的神经组合优化（NCO）方法在无需领域特定专家知识的情况下展示了其解决问题的能力。大部分现有NCO方法使用固定约束值的训练和测试数据，并未深入研究约束紧度对NCO方法性能的影响。本文通过以容量受限车辆路线问题（CVRP）为例，探究NCO方法在不同约束紧度下的性能表现。", "innovation": "该研究揭示了现有NCO方法过度拟合了容量约束的问题，并开发了一种高效的训练方案，能够明确考虑不同约束紧度，并提出了一个多专家模块来学习更通用的解题策略。", "conclusion": "实验结果表明，提出的方案能够有效克服过拟合问题，在不同约束紧度的CVRP和带时间窗的CVRP（CVRPTW）中都表现出更优的性能。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02935", "html_url": "https://arxiv.org/abs/2506.02935", "title": "MTL-KD: 通过知识蒸馏进行泛化神经车辆路线求解器的多任务学习", "title_en": "MTL-KD: Multi-Task Learning Via Knowledge Distillation for Generalizable Neural Vehicle Routing Solver", "authors": "Yuepeng Zheng,Fu Luo,Zhenkun Wang,Yaoxin Wu,Yu Zhou", "background": "现有的基于强化学习（RL）的多任务学习方法只能在小规模问题上训练轻量级的解码器模型，并且在解决大规模问题时表现出有限的泛化能力。", "innovation": "本文提出了一种新的多任务学习方法（MTL-KD），该方法通过知识蒸馏将来自多个不同的单任务RL模型的知识传递给一个重型解码器模型，从而实现无标签的训练，并有效提高模型在不同任务中的泛化能力。此外，还提出了一种名为随机重新排序重构（R3C）的灵活推理策略，专门适应各种VRP任务，进一步提高多任务模型的性能。", "conclusion": "在6个已见和10个不见的规模至多为1000个节点的VRP变体上进行的实验表明，本文提出的方法在统一定量基准和实际基准上都表现出优越的性能，证明了其强大的泛化能力。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02392", "html_url": "https://arxiv.org/abs/2506.02392", "title": "通过测试时投影学习提高神经组合优化的通用化能力，以解决车辆路线问题", "title_en": "Improving Generalization of Neural Combinatorial Optimization for Vehicle Routing Problems via Test-Time Projection Learning", "authors": "Yuanyao Chen,Rongsheng Chen,Fu Luo,Zhenkun Wang", "background": "神经组合优化（NCO）作为一种基于学习的方法，通过减少对大量手工工程的依赖，在解决车辆路线问题（VRP）方面展现出了显著潜力。尽管现有的NCO方法在小型实例（例如，100个节点）上表现优异，但在面对大型实例时，其性能显著下降，这是由于训练数据和测试数据之间的分布差异，导致从小型实例学到的策略在大型问题上不再有效。", "innovation": "本文提出了一种新的学习框架，利用大型语言模型（LLMs），通过测试时投影学习来学习训练分布和测试分布之间的投影。该框架仅在推理阶段工作，无需重新训练模型。实验结果表明，这种方法能使训练在100个节点实例上的基础模型在最大到100K节点的TSP和CVRP问题上实现更好的性能。", "conclusion": "该方法通过减少训练数据和测试数据之间的分布差异，提高了神经组合优化模型在大型VRP实例上的性能。这种方法的独特之处在于它在推理阶段工作，避免了重新训练模型的需求。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05768", "html_url": "https://arxiv.org/abs/2506.05768", "title": "AANet: 虚拟筛选中的结构不确定性对齐与聚合", "title_en": "AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation", "authors": "Wenyu Zhu,Jianhui Wang,Bowen Gao,Yinjun Jia,Haichuan Tan,Ya-Qin Zhang,Wei-Ying Ma,Yanyan Lan", "background": "虚拟筛选是现代药物发现的关键组成部分，但大多数现有的基于物理或深度学习的方法都集中在已知配体结合口袋的完整蛋白质结构上。这导致这些方法在没有精确口袋注释的apo结构或如AlphaFold2预测的结构上表现不佳。这些结构更为真实地代表了早期阶段的药物发现，其中口袋信息往往缺失。", "innovation": "本文提出了一种对齐和聚合框架，旨在在结构不确定性下实现准确的虚拟筛选。方法包含两个核心组件：1) 一种三模态对比学习模块，用于对齐配体、完整口袋和检测到的空腔的表示，从而增强对未来口袋定位误差的鲁棒性；2) 一种基于交叉注意力的适配器，用于动态聚合候选结合位点，使模型能够在缺乏精确口袋注释的情况下学习活性数据。该方法在新编译的apo结构基准测试中表现出色，特别是在盲测试中将早期富集因子（EF1%）从11.75提高到37.19。", "conclusion": "研究结果表明该方法在促进新颖药物发现方面具有潜力，特别是在没有实验确定的蛋白质-配体复合物的场景中。我们的实现已公开发布。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01158", "html_url": "https://arxiv.org/abs/2506.01158", "title": "基于回归训练的归一化流高效方法用于博兹曼生成器", "title_en": "Efficient Regression-Based Training of Normalizing Flows for Boltzmann Generators", "authors": "Danyal Rehman,Oscar Davis,Jiarui Lu,Jian Tang,Michael Bronstein,Yoshua Bengio,Alexander Tong,Avishek Joey Bose", "background": "生成模型在连续空间中的革命性发展推动了扩散和流匹配模型的广泛应用，但现代生成模型的昂贵推断限制了它们在需要快速似然评估的科研应用中的使用，例如用于分子构象的博兹曼生成器（BGs）。传统的归一化流虽然提供高效的采样和似然计算，但在通过最大似然进行训练时常常不稳定且计算难题重重。", "innovation": "本文提出了一种名为RegFlow的新型回归训练目标，通过简单的$\boldsymbol{\text{2-范数}}$回归目标规避了传统最大似然训练的数值不稳定性和计算难题，间接将先验样本映射至由最优传输耦合或预训练连续归一化流（CNF）计算得到的目标。RegFlow还采用了一种新的前向-后向自一致性损失策略，增强了数值稳定性。", "conclusion": "实验表明，RegFlow使得以前无法通过最大似然训练的BGs架构得以实现，并且在分子系统的直角坐标系中的一致性采样上，RegFlow的性能、计算成本和稳定性均优于最大似然训练，展示了其在分子系统中的潜在应用价值。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18125", "html_url": "https://arxiv.org/abs/2505.18125", "title": "TabSTAR: 一种处理具有文本字段的表格数据的表数据基础模型", "title_en": "TabSTAR: A Tabular Foundation Model for Tabular Data with Text Fields", "authors": "Alan Arazi,Eilam Shapira,Roi Reichart", "background": "尽管深度学习在许多领域取得了显著的成功，但在表格学习任务上表现一直不如梯度提升决策树（Gradient Boosting Decision Trees），而后者在表格数据领域中占据主导地位。以往的方法多采用静态的、目标无关的语言表示，这限制了其在表数据任务中的有效性。本文讨论了如何通过引入含有语义目标感知表示（Semantically Target-Aware Representations）的表格基础模型（TabSTAR）来改进这一状况。", "innovation": "本文提出了TabSTAR：一种能够在表格数据中实现迁移学习的表示方法，尤其适用于包含自由文本的数据集。它通过解冻预训练的语言编码器，并利用目标标记（target tokens）为模型提供任务相关信息的上下文环境，克服了现有方法中的局限。实验表明，TabSTAR 在包含文本特征的分类任务基准测试中达到了最先进的性能，并且其预训练阶段展示了与数据集数量相关的性能提升规律。", "conclusion": "TabSTAR 在多个基准测试中展现了卓越的性能，并且其预训练阶段的扩展性表明了其在未来进一步提升性能的潜力。这为处理复杂的表数据中包含的语言信息提供了一种新的方法。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01369", "html_url": "https://arxiv.org/abs/2506.01369", "title": "激励LLMs自我验证其答案", "title_en": "Incentivizing LLMs to Self-Verify Their Answers", "authors": "Fuxiang Zhang,Jiacheng Xu,Chaojie Wang,Ce Cui,Yang Liu,Bo An", "background": "大型语言模型（LLMs）在复杂的推理任务中已经显示出明显的进步，既通过后训练也通过测试时的扩展法则。常见的测试时扩展方法多通过外部奖励模型来引导模型生成过程，但研究表明，在特定推理任务上后训练后的模型扩展只能带来有限的提升。这种提升受限于特定后训练生成器与通用奖励模型之间的分布差异。因此，需要一种新方法来改进这一现状。", "innovation": "本文提出了一个框架，通过统一回答生成和验证在单一强化学习（RL）过程中，激励LLMs自我验证其答案。这种方法能够训练出能在推理时自我评估生成答案正确性的模型。经过验证，这种方法不仅可以在后训练时提高性能，还可以在测试时实现有效的扩展，无需外部验证者。实验结果表明，基于Qwen2.5-Math-7B和DeepSeek-R1-Distill-Qwen-1.5B训练的模型在不同推理语境长度上表现出色，尤其是在数学推理基准测试中表现出优异的性能。", "conclusion": "本文通过提出一种新的激励LLMs自我验证的方法，打破了传统测试时扩展方法的局限，使得模型能够在推理时自主评估答案的正确性，从而在后训练和测试时实现有效的性能扩展。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.07500", "html_url": "https://arxiv.org/abs/2506.07500", "title": "注意差距：消除可微逻辑门网络中的离散化差距", "title_en": "Mind the Gap: Removing the Discretization Gap in Differentiable Logic Gate Networks", "authors": "Shakir Yousefi,Andreas Plesner,Till Aczel,Roger Wattenhofer", "background": "现代神经网络在许多现有的基准测试中表现出最先进的性能，但它们的高计算需求和高能耗促使研究人员寻找更高效的解决方案以实现现实世界的部署。逻辑门网络（LGNs）可以通过学习大型逻辑门网络来有效进行图像分类。然而，训练一个能够解决类似CIFAR-10这样的简单问题的网络可能需要几天到几周的时间。即使如此，网络中几乎有一半未被使用，产生了一个离散化差距。这个差距阻碍了LGNs在现实生活中的部署，因为在训练和推理之间的性能下降会负面影响精度。", "innovation": "作者在训练过程中注入了Gumbel噪声并使用直通估计器，显著提高了训练速度，优化了神经元利用率，并减少了离散化差距。作者从理论上证明，这样做是因为隐式的海森矩阵正则化能够改善LGNs的收敛性能。结果显示，网络在壁钟时间上训练速度快了4.5倍，离散化差距减少了98%，并且未被使用的门数目减少了100%。", "conclusion": "该研究通过引入Gumbel噪声并利用直通估计器显著优化了逻辑门网络的训练和预测效率，从而解决了离散化差距问题，有助于提高逻辑门网络在现实生活中的部署和实际应用效果。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17773", "html_url": "https://arxiv.org/abs/2505.17773", "title": "C-LoRA: Contextual Low-Rank Adaptation for Uncertainty Estimation in Large Language Models", "title_en": "C-LoRA: Contextual Low-Rank Adaptation for Uncertainty Estimation in Large Language Models", "authors": "Amir Hossein Rahmati,Sanket Jantre,Weifeng Zhang,Yucheng Wang,Byung-Jun Yoon,Nathan M. Urban,Xiaoning Qian", "background": "Low-Rank Adaptation (LoRA) 提供了一种成本效益高的大语言模型（LLMs）微调方法，但常常在数据稀缺的少量样本设置中产生过于自信的预测。为了应对这个问题，一些经典的统计学习方法被重新用于可扩展的不确定性感知LoRA微调，但这些方法忽略了输入特征对预测不确定性估计的影响。因此，提出了Contextual Low-Rank Adaptation (C-LoRA) 作为一种新型的不确定性感知和参数高效微调方法，通过开发对每个输入数据样本进行上下文化的新轻量级LoRA模块，动态适应不确定性估计。", "innovation": "C-LoRA 引入了新的轻量化LoRA模块，针对每个输入数据样本进行上下文化，以动态适应不确定性估计。通过将数据驱动的上下文整合到参数后验中，C-LoRA 消除了过拟合，实现了良好的不确定性校准，并带来了稳健的预测。广泛的实验表明，C-LoRA 在不确定性量化和模型泛化方面始终优于最先进的不确定性感知LoRA方法。消除分析进一步证实了我们上下文模块在捕捉样本特定不确定性中起到关键作用。", "conclusion": "C-LoRA 为大语言模型少量样本设置中的稳健、不确定性感知的微调设定了新的标准。尽管实验仅限于7B模型，我们的方法对架构是无感知的，并且原则上可以应用于更大的模型；对更大的模型进行扩展的研究仍然是一个开放的问题。我们的代码在上述链接中可用。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22151", "html_url": "https://arxiv.org/abs/2505.22151", "title": "Oryx：离线多智能体强化学习中的可扩展序列模型用于多智能体协调", "title_en": "Oryx: a Scalable Sequence Model for Many-Agent Coordination in Offline MARL", "authors": "Claude Formanek,Omayma Mahjoub,Louay Ben Nessir,Sasha Abramowitz,Ruan de Kock,Wiem Khlifi,Daniel Rajaonarivonivelomanantsoa,Simon Du Toit,Arnol Fokam,Siddarth Singh,Ulrich Mbou Sob,Felix Chalumeau,Arnu Pretorius", "background": "离线多智能体强化学习（MARL）的一个关键挑战是在复杂环境中实现有效的大规模多步协调。现有方法难以解决这一挑战，尤其是在多个智能体长时间轨迹中的持续协调方面.", "innovation": "提出了Oryx，一种新的离线协调MARL算法，适应了近期提出的基于保留的架构Sable，并结合了隐式约束Q学习（ICQ）的顺序形式，开发了一种新的离线自回归策略更新方案，这使得Oryx能够解决复杂的协调挑战，同时保持长轨迹的时间连贯性.", "conclusion": "Oryx在SMAC、RWARE和多智能体MuJoCo等多个基准测试中均表现出色，超过了先前的离线MARL方法，并在各种规模和难度的任务中实现了稳健的泛化能力。此外，还引入了新的数据集来挑战离线MARL中的多智能体协调，展示了Oryx在such settings中的优越扩展能力."}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17475", "html_url": "https://arxiv.org/abs/2506.17475", "title": "基于低秩训练的动量优化器的几何框架", "title_en": "A geometric framework for momentum-based optimizers for low-rank training", "authors": "Steffen Schotthöfer,Timon Klein,Jonas Kusch", "background": "低秩预训练和微调近年来成为减少大型神经网络计算和存储成本的有希望的技术。传统上，训练低秩参数化依赖于重球动量方法或Adam等常规优化器。然而，这些训练方法在训练低秩权重参数化时可能遇到一些困难，特别是经典动量方法由于潜在优化景观的几何特性难以收敛到局部极小值。", "innovation": "本文提出了一种新的训练策略，这些策略是动态低秩逼近的技术衍生而来，能够明确考虑底层几何结构。该方法结合了动态低秩逼近和动量优化工具来设计尊重参数空间内在几何结构的优化器。并通过数值实验验证了方法的有效性，展示了在给定参数预算下更快的收敛速度和更强的验证指标。", "conclusion": "研究表明，通过结合动态低秩逼近和动量优化技术，可以设计出更好的优化器，这些优化器能更好地适应低秩参数化的几何结构，从而实现更快的收敛速度和更好的性能。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.08645", "html_url": "https://arxiv.org/abs/2506.08645", "title": "当核函数相乘时，聚类统一：基于克罗内克积融合嵌入", "title_en": "When Kernels Multiply, Clusters Unify: Fusing Embeddings with the Kronecker Product", "authors": "Youqi Wu,Jingwei Zhang,Farzan Farnia", "background": "当前最先进的嵌入方法能够捕捉独特但互补的判别特征。例如，一种图像嵌入模型可能擅长区分细微的纹理，而另一种则专注于对象的结构。基于此观察，本文提出了一种原理性的方法，通过核相乘融合具有互补表示的嵌入。通过相乘两个嵌入的核相似度函数，它们的判别结构可以相互作用，从而生成融合的表示，其核编码了每个父嵌入所识别的簇的并集。此外，这种方法还为配对多模态数据（如图像-文本对）的联合核提供了自然方法，产品模态特定核从两个领域继承结构。", "innovation": "本文提出了一种基于克罗内克积的嵌入融合框架，称为KrossFuse。通过将嵌入特征图的克罗内克乘积进行数学实现，生成了KrossFuse框架。为了应对由此产生的高维克罗内克空间的计算成本，本文进一步发展了RP-KrossFuse，这是一种通过随机投影进行高效近似的可扩展版本。该框架有效地将跨模态嵌入和单模态专家模型结合起来，增强了模态特定性能的同时保持跨模态对齐。", "conclusion": "实验结果表明，RP-KrossFuse能够有效整合这些模型，提升模态特定表现的同时保持跨模态的对齐。代码可在以下链接获取：<this https URL>。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21271", "html_url": "https://arxiv.org/abs/2510.21271", "title": "Buffer层用于测试时适应", "title_en": "Buffer layers for Test-Time Adaptation", "authors": "Hyeongyu Kim,Geonhui Han,Dosik Hwang", "background": "近年来，在测试时适应（TTA）方面取得了一些进展，大多数现有方法侧重于更新归一化层以适应测试领域。然而，这种方法依赖归一化层带来了一些关键挑战。首先，归一化层如批归一化（BN）对小批次大小特别敏感，导致统计不稳定且不准确。其次，归一化层的调整受到预训练模型结构的内在约束，因为它依赖于训练时的统计信息，这些可能在未见过的领域中表现不佳。这些问题限制了归一化层TTA方法的有效性，特别是在显著领域变化的情况下。", "innovation": "本文引入了一种基于Buffer层概念的新框架，解决了归一化层更新的根本局限性。与现有方法修改模型的核心参数不同，我们的方法保留了预训练主干网络的完整性，从根本上减小了在线适应过程中灾难性遗忘的风险。实验表明，我们的方法不仅在缓解领域偏移和增强模型鲁棒性方面优于传统方法，还具有很强的遗忘容忍性。此外，我们的Buffer层模块化，并能无缝集成到几乎所有现有的TTA框架中，实现各种架构的一致性能提升。", "conclusion": "我们的研究发现验证了所提出的解决方案在实际领域适应场景中的有效性和多样性。该代码可在此链接中获取。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23639", "html_url": "https://arxiv.org/abs/2510.23639", "title": "将基因组学整合到多模态EHR基础模型中", "title_en": "Integrating Genomics into Multimodal EHR Foundation Models", "authors": "Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T.J. Chen,Cory Y. McLean", "background": "本文介绍了将多基因风险评分（PRS）纳入电子健康记录（EHR）基础模型的创新方法，这种模型超越了传统的仅依赖EHR的方法，构建了更全面的健康档案。研究利用了All of Us（AoU）研究项目的大量多元数据，旨在学习临床数据和遗传倾向之间复杂的相互关系。该方法通过将生成AI的进步应用到EHR基础模型空间中，增强了预测能力和可解释性。", "innovation": "本文的方法在于将PRS作为基础数据模式整合到EHR基础模型中，通过AoU数据的多模态框架学习复杂的临床数据和遗传倾向之间的关系。此外，该方法利用生成人工智能技术，提高了预测能力和可解释性，并展示了在自定义分类任务上的迁移学习，证明了架构的灵活性和效率。", "conclusion": "这一方法对于解锁疾病预测、前瞻性的健康管理、风险分层和个人化治疗策略的新见解至关重要。它为医疗保健领域生成更个性化、公平和可行动的实证证据奠定了基础。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04237", "html_url": "https://arxiv.org/abs/2510.04237", "title": "广义损失和球面径向基函数截尾核随机梯度下降", "title_en": "Truncated Kernel Stochastic Gradient Descent with General Losses and Spherical Radial Basis Functions", "authors": "Jinhui Bai,Andreas Christmann,Lei Shi", "background": "在大规模监督学习中，传统的核随机梯度下降（SGD）算法虽然在某种程度上提高了效率和可扩展性，但仍然存在一定的局限性，特别是在损失函数的一般情况和优化及泛化分析方面可能不够完善。", "innovation": "本文提出了一种新型的核随机梯度下降（SGD）算法，通过引入一种创新的正则化策略，结合无限级数展开的球面径向基函数，将随机梯度投影到自适应缩放的有限维假设空间中，从而提高泛化性能。并且在此基础上，我们开发了一个新的估计核诱导协方差算子频谱结构的分析框架，实现在优化和泛化分析上的统一，并证明了算法最终迭代和后缀平均的最小最大最优收敛率，以及在再生核希尔伯特空间中的强收敛最优性。此外，这种方法还通过引入线性SGD的逐坐标更新减少了计算复杂度和存储复杂度，避免了传统核SGD中的昂贵两两操作，适用于处理流式数据。", "conclusion": "我们的算法在泛化性能和计算效率方面均表现出色，广泛适用于各种经典损失函数，包括最小二乘、Huber和对数损失，并通过大量数值实验验证了这些结论。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01988", "html_url": "https://arxiv.org/abs/2510.01988", "title": "PepCompass：利用黎曼几何导航肽嵌入空间", "title_en": "PepCompass: Navigating peptide embedding spaces using Riemannian Geometry", "authors": "Marcin Możejko,Adam Bielecki,Jurand Prądzyński,Marcin Traskowski,Antoni Janowski,Hyun-Su Lee,Marcelo Der Torossian Torres,Michał Kmicikiewicz,Paulina Szymczak,Karol Jurasz,Michał Kucharczyk,Cesar de la Fuente-Nunez,Ewa Szczurek", "background": "抗微生物肽的发现受到肽空间海量性和潜在活性肽稀缺性的挑战。生成模型提供了肽空间的连续潜在“地图”，但通常忽略了解码器引起的几何形状，依赖于平坦的欧几里得度量，使得探索和优化受到扭曲和效率低下。先前基于流形的方法假设固定的内在维度，对肽数据的实际实现效果较差。", "innovation": "PepCompass引入了一种感知几何的肽探索和优化框架。核心定义了一个$\boldsymbol{\text{k-稳定的黎曼流形}}$的联合体$\boldsymbol{\text{M}^{\boldsymbol{\text{k}}}}$，捕捉局部几何结构的同时确保计算稳定性。提出了两种局部探索方法：二次黎曼布朗运动有效的抽样，提供收敛的二阶黎曼布朗运动近似；以及切空间中突变枚举，将切方向重新解释为离散的氨基酸替代。结合这两种方法形成了局部枚举贝叶斯优化（LE-BO），一种高效的局部活性优化算法。此外，引入了潜在最小化测地线搜索（PoGS）方法，沿着增强了属性的测地线在原型嵌入之间进行插值，偏向种子肽的发现，即活性有利的肽。", "conclusion": "实验验证证实了PepCompass的有效性：PoGS发现了四种新型种子肽，随后优化使用LE-BO发现了25种具有广泛抗菌活性的活性肽，包括对耐药细菌的有效性。这些结果表明，几何信息指导的探索为抗菌肽设计提供了一种强有力的新范式。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22033", "html_url": "https://arxiv.org/abs/2510.22033", "title": "线性化最优运输用于高维点云和单细胞数据分析", "title_en": "Linearized Optimal Transport for Analysis of High-Dimensional Point-Cloud and Single-Cell Data", "authors": "Tianxiang Wang,Yingtong Ke,Dhananjay Bhaskar,Smita Krishnaswamy,Alexander Cloninger", "background": "单细胞技术生成高维细胞点云，能够详细描述患者状态和治疗反应。然而每个患者由不规则的点云表示而非简单向量，难以直接量化和比较个体间的生物差异。核方法和神经网络等非线性方法虽然能实现预测准确性，但作为黑箱模型，缺乏生物学解释性。因此，需要一种新的方法解决这些限制。", "innovation": "本文适应了线性最优运输（LOT）框架，将不规则的点云嵌入固定维度的欧几里得空间，同时保留分布结构。这种方法提供了一个保持最优运输几何的原理性线性表示，使下游分析成为可能，同时在任何两个患者之间形成注册，使得其细胞分布可以进行直接比较。在这种空间中，LOT使分类准确且可解释；并可以生成患者衍生的类器官的合成数据，利用LOT嵌入的线性性。LOT重心产生表示组合条件或样品的平均细胞图谱，支持药物相互作用测试。这些结果建立了LOT作为融合预测性能，解释性和生成建模的统一框架，通过将异质点云转变为可直接追溯到原始数据的结构嵌入，LOT为高维生物系统中免疫和治疗效应的理解开辟了新机会。", "conclusion": "LOT作为一个统一框架，实现了预测性能、解释性和生成建模的结合。通过将不同患者的不规则细胞数据转换为结构化的嵌入表示，LOT开启了对高维生物系统中免疫和治疗效应的新理解。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22094", "html_url": "https://arxiv.org/abs/2510.22094", "title": "通过轻量级训练实现精确天气预报的层次图神经网络", "title_en": "Hierarchical Graph Networks for Accurate Weather Forecasting via Lightweight Training", "authors": "Thomas Bailie,S. Karthik Mukkavilli,Varvara Vetrova,Yun Sing Koh", "background": "气候变化源于多种全球尺度驱动因素下的复杂多变量动态，对食品、能源和基础设施产生深远影响。然而，准确的天气预测由于不同尺度上的物理过程难以捕捉而难以实现。现有的固定分辨率方法无法捕捉这种多尺度过程，而层次图神经网络（HGNNs）可以提供多尺度表示，但非线性的下采样映射往往会抹去全球趋势，削弱了物理过程在预测中的整合能力。", "innovation": "引入了HiFlowCast及其增强的变体HiAntFlow，这是一种嵌入了物理法则的多层次预测框架。创新之处包括：1）潜存记忆保留机制，确保在下采样过程中保留全球趋势；2）潜存至物理分支，将PDE解的字段综合到不同的尺度上。", "conclusion": "通过轻量级训练，HiFlowCast模型在13天预报中的误差降低了超过5%，在极端情况下（第1和99百分位数）误差降低了5-8%，提高了罕见事件的可靠性。利用预训练模型权重，它们能在单个训练周期内收敛，降低了训练成本和碳足迹。这种高效性对于解决机器学习技术规模增长带来的可持续性挑战和研究可访问性限制具有重要意义。补充材料中包含了代码和模型权重。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16629", "html_url": "https://arxiv.org/abs/2510.16629", "title": "在机器遗忘中实现重训练等价的不可能性", "title_en": "On the Impossibility of Retrain Equivalence in Machine Unlearning", "authors": "Jiatong Yu,Yinghui He,Anirudh Goyal,Sanjeev Arora", "background": "机器遗忘旨在通过选择性地去除特定训练数据对模型输出的影响，实现更加隐私的数据处理方式。理想的目标是重训练等价——即，通过只保留特定数据重新训练模型，使得新模型的行为与从头开始训练相同数据的行为完全一致。然而，当训练过程涉及多阶段时，每个阶段的数据分布和目标可能不同。比如，在大型语言模型（LLM）的微调中，不同的微调顺序会显著影响最终模型的行为。该研究讨论了多阶段训练对机器遗忘的挑战，指出在多阶段训练的情况下，地方遗忘算法（仅使用遗忘数据集计算的梯度来实现遗忘）的结果依赖于训练顺序，使得实现重训练等价成为不可能。", "innovation": "研究通过理论和实验，展示了多阶段训练对机器遗忘的影响。理论表明，地方遗忘算法的结果依赖于训练顺序。实验则证明了这种现象在不同大小的LLM模型中普遍存在，不同的训练顺序会导致模型在遗忘过程中的行为差异显著，准确率变化超过20%。此外，研究还发现，某些训练路径会导致模型遗忘缓慢的问题。这些结果一致表明，在多阶段训练的模型中，实现重训练等价作为一个目标是不合适的，尤其是在无法访问模型训练历史的情况下，需要重新思考机器遗忘的定义和目标。", "conclusion": "研究结果表明，在多阶段训练的模型中，实现重训练等价的目标是不可行的。特别是在无法获得模型训练历史记录的情况下，需要重新定义和设定机器遗忘的目标和期望。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21038", "html_url": "https://arxiv.org/abs/2510.21038", "title": "Elementary, My Dear Watson: 无创神经关键词识别在LibriBrain数据集中的应用", "title_en": "Elementary, My Dear Watson: Non-Invasive Neural Keyword Spotting in the LibriBrain Dataset", "authors": "Gereon Elvers,Gilad Landau,Oiwi Parker Jones", "background": "无创脑机接口（BCIs）正开始得益于大规模的公共基准测试。然而，现有的基准主要针对相对简单的基础任务，如语音检测和音素分类，而针对如脑到文本等应用级别的结果仍难以达到。关键词识别（KWS）被提议作为一种可应用于实际且隐私意识强的中间任务。利用深度52小时的LibriBrain内部受试者数据集，提供了一致的训练/验证/测试分割，以实现可重复的基准测试，并采用了适应极端类别不平衡的评估协议。具体地，使用精准率召回曲线下面积（AUPRC）作为稳健的评估指标，并附加固定召回率下的每小时误报数（FA/h），以捕捉用户视角的权衡。为了简化部署并进一步在研究社区中进行实验，释放了更新版本的pnpl库，包含词级数据加载器和Colab就绪教程。作为一种参考模型，展示了一个紧凑的一维卷积/残差网络基线，使用焦点损失和上K最大池化，能够在单个消费者级GPU上进行训练。该参考模型在留存会话中的AUPRC得分约为置换基准的13倍，表明该任务的可行性。探索性分析揭示了：（i）可预测的内部受试者缩放——性能随着更多训练小时数呈对数线性提升——以及（ii）影响可检测性的词级因素（频率和持续时间）存在且系统性地调节检测结果。", "innovation": "研究提出关键词识别（KWS）作为实际应用且隐私保护的中间任务，利用52小时的LibriBrain内部受试者数据集，提供标准化的训练/验证/测试分割。采用适应极端类别不平衡的评估协议，使用精准率召回曲线下面积（AUPRC）作为评估指标。提出了一个紧凑的一维卷积/残差网络基线模型，并释放了更新版本的pnpl库，包含词级数据加载器和Colab就绪教程，以简化部署和进一步实验。", "conclusion": "所提出的紧凑的一维卷积/残差网络基线模型在保留会话中表现出显著优于置换基准的AUPRC值，展示了任务的可行性。进一步的分析表明，性能随更多训练小时呈对数线性提升，并发现了影响可检测性的词级因素。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23117", "html_url": "https://arxiv.org/abs/2510.23117", "title": "在预测意大利面桥载荷之前看到结构失败：基于图像的物理引导神经网络（PINN）", "title_en": "Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction", "authors": "Omer Jauhar Khan,Sudais Khan,Hafeez Anwar,Shahzeb Khan,Shams Ul Arifeen", "background": "物理引导神经网络（PINNs）由于其嵌入物理守恒的能力，在结构工程任务中受到了越来越多的关注，尤其是在数据有限的情况下。本文利用PINNs预测小型意大利面桥的重量，这有助于理解简化结构模型中的载荷极限和潜在失效模式。研究人员结合物理约束改进了预测模型，并引入了一种新型架构——基于柯尔莫哥洛夫-阿诺德网络的物理引导PINN（PIKAN），该架构结合了通用函数逼近理论与物理洞察。输入模型的结构参数可以通过手动或计算机视觉方法获取。实验数据集包含15座实际桥梁，增补至100个样本，最优模型的$R^2$得分为0.9603，平均绝对误差（MAE）为10.50单位。该结果表明，即使在数据有限的情况下，PINNs也能提供可靠的结构重量估计值，并可有助于在轻质桥梁设计中的早期失效分析。", "innovation": "本文创新地引入了一种名为PIKAN的新型架构，该架构结合了物理洞察与通用函数逼近理论。此外，该研究通过结合输入数据的物理约束提升了模型预测性能，并提供了基于图像的框架进行参数输入与预测。最后，本文还提供了基于Web的界面，方便参数输入和结果预测。这些创新对于提高结构重量预测的准确性具有重要意义。", "conclusion": "本文研究表明，即便在数据有限的情况下，PINNs仍能提供可靠的小型意大利面桥重量估计。该研究在简化结构模型中的载荷极限与潜在失效模式理解方面具有实践意义。未来工作可以进一步优化网络结构或探索更多与物理之间的结合方式，以提高预测精度。此外，基于Web的预测界面为广大学者和工程师提供了便利。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17670", "html_url": "https://arxiv.org/abs/2510.17670", "title": "基于FLAME的即时OVD适应：利用活跃边缘样本探索进行少量样本本地化", "title_en": "On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration", "authors": "Yehonathan Refael,Amit Aides,Aviad Barzilai,George Leifman,Genady Beryozkin,Vered Silverman,Bolous Jaber,Tomer Shekel", "background": "开放词汇对象检测（OVD）模型能够从任意文本查询中检测对象，提供了极大的灵活性。然而，在像遥感（RS）这样专业化的领域中，由于自然语言的固有歧义性，其零样本表现常常受到限制，影响了关键的下游应用。例如，在区分“渔业船只”和“游艇”等细粒度类别时，由于它们的嵌入相似且难以区分，OVD模型可能难以辨别。这会阻碍特定用户目标的实现，如监控非法捕鱼等，产生无关的检测结果。鉴于此，文中提出了一种分阶段的方法，这一方法结合了大型预训练OVD模型的广泛泛化能力和轻量级的少样本分类器。首先利用零样本模型生成高召回的对象提议，然后通过紧凑的实时分类器进行高精度细化，大幅降低了RS影像的成本。文章核心在于FLAME，这是一种一步式主动学习策略，能够在实时挑选最具信息量的样本来进行训练。该策略通过密度估计快速识别决策边界附近的不确定边缘样本，并利用聚类确保样本多样性，从而实现高效的抽样技术，无需大规模模型调整，且能在不到一分钟的时间内实现即时适应，比现有最先进的方法更快。该方法在RS基准测试中表现优于现有技术，建立了一个具有实用性和资源效率的基础模型适应特定用户需求的框架", "innovation": "提出了一种分阶段的方法，结合了大型预训练OVD模型的广泛泛化能力和轻量级的少样本分类器。首先利用零样本模型生成高召回的对象提议，然后通过紧凑的实时分类器进行高精度细化。文章的核心在于FLAME，这是一种一步式的主动学习策略，能够在实时挑选最具信息量的样本来进行训练，通过密度估计快速识别决策边界附近的不确定边缘样本，并利用聚类确保样本多样性，从而实现高效的抽样技术，无需大规模模型调整，且能在不到一分钟的时间内实现即时适应，比现有最先进的方法更快。该方法具有高准确性和低资源消耗，有效解决了OVD在专业领域中的应用难题", "conclusion": "提出的即时OVD适应方法及其核心FLAME策略，通过实时选择信息量最大的样本进行训练，实现了在大型预训练模型和轻量化分类器之间的有效结合，大幅提升了遥感领域的应用表现。该研究提高了OVD模型在专业领域中的实用性和效率，为实现基础模型的快速和高效适应特定用户需求建立了可行框架"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25366", "html_url": "https://arxiv.org/abs/2510.25366", "title": "深度神经网络依赖凸性两阶段训练算法", "title_en": "A Convexity-dependent Two-Phase Training Algorithm for Deep Neural Networks", "authors": "Tomas Hrycej,Bernhard Bermeitinger,Massimo Pavone,Götz-Henrik Wiegand,Siegfried Handschuh", "background": "机器学习的关键任务是通过最小化度量模型与训练数据拟合情况的损失函数来优化模型。数值方法的效率依赖于损失函数的特性，其中最为关键的是损失函数是凸的还是非凸的。非凸的损失函数通常存在多个局部极小值，这导致人们普遍采用类似Adam的方法。但局部极小值附近，函数表现出近似凸的特性，此时二阶最小化方法如共轭梯度法能够保证超线性收敛。", "innovation": "本文提出了一种基于损失函数从非凸性向凸性转变的新颖两阶段优化框架。该框架通过检测梯度范数与损失之间的依赖关系来确定此转换点，并在非凸区域使用Adam算法，在凸区域使用共轭梯度法。实验证明，这种简单的凸性结构在实际任务中足够普遍，可以在提高收敛性和准确性方面提供实际的优化。", "conclusion": "该两阶段算法通过利用损失函数随优化过程的变化特性，结合使用凸性和非凸性优化方法，有效地加速了深度神经网络的训练过程，并提高了优化的准确性和效率。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.17434", "html_url": "https://arxiv.org/abs/2311.17434", "title": "GSE: Group-wise Sparse and Explainable Adversarial Attacks", "title_en": "GSE: Group-wise Sparse and Explainable Adversarial Attacks", "authors": "Shpresim Sadiku,Moritz Wagner,Sebastian Pokutta", "background": "现有的针对深度神经网络（DNNs）的轻微像素扰动生成的稀疏对抗攻击通常通过$L_0$范数进行正则化。虽然最近的研究通过使用核分组范数等结构稀疏正则化器来制造分组稀疏对抗攻击，这些攻击通常更具可解释性并具有重要的实际意义，但这种方法也带来了优化挑战，因为它涉及到非凸目标中的组像素范数计算。", "innovation": "论文提出了一个两阶段算法，旨在生成具有语义意义的图像区域内的分组稀疏对抗攻击。首先，通过一个针对非凸编程特制的$1/2-$拟范数proximal操作符优化准范数对抗损失。其次，算法转向应用2范数正则化的投影Nesterov加速梯度下降方法，这显著提高了分组稀疏对抗攻击的稀疏性，并且具有更高的可解释性以及更快速的计算时间，成功率达到100%。", "conclusion": "在CIFAR-10和ImageNet数据集上的严格评估显示，该方法在分组稀疏对抗攻击中显著提高了稀疏性，例如在CIFAR-10上达到了50.9％，在ImageNet平均目标攻击上达到了38.4％。此外，这种方法还带来了明显的计算速度提升、更好的可解释性和100％的攻击成功率。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02331", "html_url": "https://arxiv.org/abs/2502.02331", "title": "二元随机变量的可预测性风险最小化的影响", "title_en": "On the Impact of Performative Risk Minimization for Binary Random Variables", "authors": "Nikita Tsoy,Ivan Kirev,Negin Rahimiyazdi,Nikola Konstantinov", "background": "可预测性是指结果受预测影响的现象，尤其是在社会环境中，个体会策略性地响应所部署的模型。为保持机器学习模型在可预测性导致的分布变化下的高准确性，Perdomo等人（2020年）提出了可预测性风险最小化（PRM）的概念。尽管这一框架保证了模型的准确性，但它忽略了PRM对模型底层分布和预测结果的影响。", "innovation": "本文通过研究具有二元随机变量和线性可预测性变化的顺序可预测性风险最小化问题，着手分析PRM的影响，并形成了两种自然测量其影响的指标。在已知分布动态的全信息情况下，提出了明确定义的PRM解决方案及相应的影响度量公式。在部分信息情况下，提供了一种可预测性风险最小化的统计估计算法，并进行了仿真。", "conclusion": "与不建模数据转移的方法相比，本文分析表明PRM可能会产生更强烈的次生效应。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04380", "html_url": "https://arxiv.org/abs/2502.04380", "title": "多样性作为一种奖励：使用非特定领域数据混合 fine-tuning LLMs", "title_en": "Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data", "authors": "Zhenqing Ling,Daoyuan Chen,Liuyi Yao,Qianli Shen,Yaliang Li,Ying Shen", "background": "大型语言模型（LLMs）的性能可以通过使用多样化的数据集进行微调来增强，然而现有的方法在处理缺失、不精准或非规范化领域标签的数据时往往表现不佳。此外，以数据选择为基础的方法在平衡多领域性能上也存在问题。因此，该研究旨在通过实验构建对比数据池并理论推导来探讨数据多样性的重要性，以解决这些问题。", "innovation": "该研究提出了一种新方法，使得LLM具备双重身份：输出模型根据多样性奖励认知探究并选择数据，输入模型根据选择的数据进行微调。这种方法显著提升了在未定领域数据和一系列基础下游任务中的性能。", "conclusion": "大量实验结果表明，该方法在多种先进的LLMs上应用于未定领域数据和一系列基础下游任务时，显著提升了性能。该研究已发布了代码，旨在帮助理解数据多样性，并促进LLMs的数据-模型反馈驱动共设计的理解。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04492", "html_url": "https://arxiv.org/abs/2503.04492", "title": "基于可解释机器学习的选定重要特征的带隙准确预测模型", "title_en": "Accurate predictive model of band gap with selected important features based on explainable machine learning", "authors": "Joohwi Lee,Kaito Miyamoto", "background": "在材料信息学这一快速发展的领域中，非线性机器学习模型在材料性质的预测方面表现出色。然而，它们的黑箱性质限制了可解释性，模型可能包含不增加甚至降低模型性能的特征。目前的研究通过使用基于可解释机器学习(可解释的ML，XML)技术，包括特征置换重要性和SHapley Additive exPlanation方法，应用于使用18个输入特征在GW级预测能隙的简化后的支持向量机回归模型，旨在解决上述问题。", "innovation": "基于XML的特征重要性选择，提出了一种简化模型的方法。选定的最重要作用特征的紧凑模型在领域内数据集上的准确度与未简化模型相当（0.254 vs. 0.247 eV），但在领域外数据集上具有更好的泛化能力（0.461 vs. 0.341 eV）。此外，研究强调了在应用XML前消除强相关特征（相关系数大于0.8）的重要性，以避免特征重要性误解和过度估计。", "conclusion": "这项研究突出了XML在发展简化而高度准确的机器学习模型方面的有效性，通过阐明特征角色，可减少特征获取的计算成本并提高材料发现模型的可信度。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11730", "html_url": "https://arxiv.org/abs/2505.11730", "title": "重新思考计算高效测试时缩放的最佳验证粒度", "title_en": "Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling", "authors": "Hao Mark Chen,Guanxi Lu,Yasuyuki Okoshi,Zhiwen Mo,Masato Motomura,Hongxiang Fan", "background": "测试时缩放（TTS）已被证明可以增强大型语言模型（LLMs）的推理能力，而验证在这个过程中起着关键作用，影响着推理性能和计算效率。现有验证方法通常仅验证最终输出或单个生成步骤，但对于在生成过程中不同频率调用验证器的影响研究较少。", "innovation": "本文提出了一种新的统一算法Variable Granularity Search (VG-Search)，它通过可调的粒度参数g将beam search和Best-of-N sampling（两种流行的生成策略）进行了扩展。实验结果表明，动态调整粒度参数g可以提高计算效率和缩放性能。基于此，提出了一种适应性VG-Search策略，相比beam search提高了3.1%的准确性，相比Best-of-N提高了3.6%的准确性，同时减少了超过52%的FLOPs（浮点运算次数）计算量。", "conclusion": "该研究通过系统地探索验证粒度的影响，提出了一种新的算法及其适应性策略，能够显著提高计算效率和准确性，为未来研究提供了代码支持。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11542", "html_url": "https://arxiv.org/abs/2505.11542", "title": "基于深度自编码器的UEBA框架在网络威胁检测中的应用", "title_en": "Cybersecurity threat detection based on a UEBA framework using Deep Autoencoders", "authors": "Jose Fuentes,Ines Ortega-Fernandez,Nora M. Villanueva,Marta Sestelo", "background": "UEBA（用户和实体行为分析）是一种广泛的数据分析分支，旨在构建正常行为模式以检测异常事件。深自编码器是用于UEBA任务的最有前途的深度学习模型之一，能够解释安全事件的检测，这些事件可能涉及个人数据泄露、系统劫持或敏感商业信息的访问。已有研究主要集中在DNNs（深度神经网络）的领域理论基础，但缺乏将_DOC2Vec_与深自编码器结合处理数值和文本特征的解释性UEBA框架实施。", "innovation": "本文提出了首个结合使用深度自编码器和DOC2Vec处理数值和文本特征的可解释UEBA异常检测框架。该研究还提供了基于神经网络理论的新颖证明，证明了两种广泛应用的全连接神经网络定义的等价性。实验结果表明，所提框架能有效检测来自实际攻击数据的真实和合成异常，不仅能够准确识别异常，还能够提供可解释的结果，有助于异常行为的溯源。这些发现表明，所提出的UEBA框架可以无缝集成到企业环境中，补充现有的可解释威胁检测系统。", "conclusion": "提出的UEBA框架展示了强大的异常检测能力，并提供了可解释的结果，能够重建异常行为的起源。研究还提出了一种理论证明，进一步强化了框架的有效性。该框架在企业安全环境中具有广泛应用潜力，适用于补充现有安全系统。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.02820", "html_url": "https://arxiv.org/abs/2505.02820", "title": "AutoLibra：来自开放反馈的智能体度量归纳", "title_en": "AutoLibra: Agent Metric Induction from Open-Ended Human Feedback", "authors": "Hao Zhu,Phil Cuvin,Xinkai Yu,Charlotte Ka Yee Yan,Jason Zhang,Diyi Yang", "background": "智能体主要通过任务完成度指标进行评估和优化，但这类指标较为粗糙，需要专家人工设计，并且无法奖励智能体的中间涌现行为。现有的智能体评估框架基本上依赖于具体任务成败的度量，缺乏细致的行为评估指标。", "innovation": "提出了AutoLibra框架，该框架能够将开放性的人类反馈（例如：“如果发现按钮被禁用，就不要再点击它了”或“该智能体自主权过大，决定自行行动”）转化为评估智能体细粒度行为的度量。AutoLibra通过对智能体行为进行分析，将相似的正负反馈行为聚类，并创建具体的具有明确定义和实例的度量标准，以促进AI模型作为评估者的工作。此外，还提出了两个元度量指标“覆盖率”和“冗余度”，用于评估诱导出的指标集与开放反馈的一致性。", "conclusion": "通过优化这些元度量，实验结果表明AutoLibra能够诱导出比以前智能体评估基准更高的具体评估度量，还发现了一些新的评估智能体的指标。此外，AutoLibra还可以用于智能体改进的两个应用场景：一是服务于人类提示工程师，使智能体能自我诊断失败并改善提示；二是通过自我调整优化智能体。研究结果表明，AutoLibra是一个适用于不同任务的评估和改进语言智能体的强大工具。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03710", "html_url": "https://arxiv.org/abs/2503.03710", "title": "通过双重目标优化提高大语言模型的安全对齐", "title_en": "Improving LLM Safety Alignment with Dual-Objective Optimization", "authors": "Xuandong Zhao,Will Cai,Tianneng Shi,David Huang,Licong Lin,Song Mei,Dawn Song", "background": "现有的大规模语言模型（LLMs）在训练阶段的安全对齐技术仍然容易受到囚笼攻击。直接偏好优化（DPO）作为一种广泛应用的对齐方法，实验和理论上都存在不足，其损失函数对于拒绝学习的效果不佳。通过梯度分析，我们发现这些不足并提出改进的安全对齐方法，将DPO的目标拆分为两个部分：一是稳健的拒绝训练，即使生成部分不安全的内容，也鼓励拒绝；二是有针对性地消除有害知识。此外，我们还提出了一种基于奖励的拒绝学习的标记级权重机制，进一步提高了对对抗性攻击的鲁棒性。研究还表明，对抗攻击鲁棒性与训练过程中标记分布的变化以及拒绝和有害标记的内部表示有关，为未来LLM安全对齐的研究指明了方向。", "innovation": "改进的安全对齐方法，将DPO的目标拆分为稳健的拒绝训练和有针对性地消除有害知识两个部分；提出了一种基于奖励的标记级权重机制，用于拒绝学习，提高了对抗性攻击的鲁棒性；表明对抗攻击鲁棒性与标记分布的变化和内部表示有关，为未来研究提供方向。", "conclusion": "该方法显著提高了LLM对抗广泛类型的囚笼攻击的鲁棒性，包括填充、后缀和多轮攻击，并通过标记分布的变化和内部表示指导未来的研究。相关代码已发布。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11329", "html_url": "https://arxiv.org/abs/2505.11329", "title": "TokenWeave：分布式大型语言模型推理中高效的计算-通信重叠", "title_en": "TokenWeave: Efficient Compute-Communication Overlap for Distributed LLM Inference", "authors": "Raja Gond,Nipun Kwatra,Ramachandran Ramjee", "background": "在通过高带宽互连（如NVLink）连接的GPU上进行大规模语言模型（LLMs）的分布式推理，即使在高速互联设备上也能引入高达20%的额外开销。现有的技术通过将计算分解为更细粒度的任务并在子任务完成后重叠通信来减轻这些开销，但这也会引入额外的开销。此外，通信本身会消耗许多流式多处理器（SMs），从而进一步增加开销。已有研究没有完全避免通信和计算的开销。", "innovation": "TokenWeave提出了一种Token-Splitting技术，将推理批处理的token分成两个大致相等的子集，并以波束感知的方式进行划分。一个子集的通信然后与另一个子集的计算重叠。此外，TokenWeave优化了层归一化计算的顺序，实施了一种新颖的融合AllReduce-RMSNorm内核，该内核充分利用了Hopper和Blackwell NVIDIA GPU上的Multimem指令支持，使通信和RMSNorm仅使用2-8个SMs。这种方法使内存受限的RMSNorm可以在另一批计算中重叠，带来额外的好处。这些优化使得TokenWeave在多个模型和负载下分别展示了高达1.29倍的延迟改善和1.26倍的吞吐量增加，有时还能优于移除所有通信的等效模型。", "conclusion": "TokenWeave通过改进的Token-Splitting方法和优化的计算-通信重叠策略，在分布式的大型语言模型推理中提供了显著的性能提升和效率改进。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04852", "html_url": "https://arxiv.org/abs/2503.04852", "title": "CAUSAL3D: 从视觉数据中进行因果学习的综合性基准", "title_en": "CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data", "authors": "Disheng Liu,Yiran Qiao,Wuche Liu,Yiren Lu,Yunlai Zhou,Tuo Liang,Yu Yin,Jing Ma", "background": "真正的智能依赖于发现和利用隐藏的因果关系。尽管AI和计算机视觉取得了显著进展，但在从复杂视觉数据中推断潜在因果关系方面缺乏评估模型能力的基准。本文的背景是需要建立一个既能评估因果推理能力又能涵盖多种视觉场景的新基准。现有的基准还没有全面集成结构化数据（表格）和相应的视觉表示（图像），来系统地评估因果推理能力，尤其是在3D场景中的不同因果关系、视角和背景方面。因此，一个全面的基准对于推进计算机视觉中的因果推理至关重要，以确保在关键领域的AI是值得信赖的。", "innovation": "本文创新地提出了Causal3D，这是一个结合了结构化数据（表格）和相应视觉表示（图像）的新基准，用于评估因果推理能力。Causal3D包括19个三维场景数据集，涵盖各种因果关系、视角和背景，可以评估不同复杂度场景下的因果推断能力。该基准旨在为先进方法提供挑战，尤其是在没有先验知识的情况下处理更复杂的因果结构。Causal3D作为一个重要资源，对于推动计算机视觉中的因果推理并促进关键领域的可信AI具有重要意义。", "conclusion": "Causal3D展示了在缺乏先验知识的情况下，随着因果结构越来越复杂，性能显著下降，强调了先进方法在复杂因果场景中面临的挑战。该基准提供了一种系统的方法来评估因果推理能力，并为构建未来的可信AI提供了重要数据。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10361", "html_url": "https://arxiv.org/abs/2505.10361", "title": "塑性作为赋能的镜像", "title_en": "Plasticity as the Mirror of Empowerment", "authors": "David Abel,Michael Bowling,André Barreto,Will Dabney,Shi Dong,Steven Hansen,Anna Harutyunyan,Khimya Khetarpal,Clare Lyle,Razvan Pascanu,Georgios Piliouras,Doina Precup,Jonathan Richens,Mark Rowland,Tom Schaul,Satinder Singh", "background": "代理是一种受过去观察影响并能够影响未来观察的最小单位。赋能概念在人工智能和认知科学中起到了至关重要的作用，但代理如何受观察影响这一能力同样重要。过去，塑性尚未被明确地定义为一个普遍的代理中心度量，本文试图填补这一空白，通过一个新的信息理论量——广义定向信息，定义塑性，并揭示其与赋能之间的一种基本联系线索。定义适合塑性概念的关键标准后，作者使用广义定向信息定义塑性，证明其严格推广了Massey（1990）引入的定向信息，并且保留了其所有优良属性。塑性被认为是赋予的镜像，两者使用相同的度量标准，仅方向相反。研究表明，塑性和赋能之间存在张力，这意味着在代理设计中需要同时考虑这两个方面，以确保其性能和效果的最佳平衡。", "innovation": "本文的主要创新在于定义了一个新的信息理论量——广义定向信息，并使用它来定义塑性，这不仅扩展了已有定义于塑料性，还揭示了塑性与赋能之间的基本联系。这一发现为理解和设计智能代理提供了新的视角，特别是在考虑如何设计出既具备高赋能能力又具高塑性的智能代理的过程中的指导意义。", "conclusion": "本文的研究结果不仅展示了塑性和赋能之间的镜像关系，还强调了在代理设计中同时考虑这两种能力的重要性。塑性，赋能及其关系对于理解代理特性至关重要，为智能代理的设计提供了新的理解。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12191", "html_url": "https://arxiv.org/abs/2505.12191", "title": "弃用去噪器：来自数据课程的自监督学习中的噪声鲁棒性涌现", "title_en": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum", "authors": "Wenquan Lu,Jiaqi Zhang,Hugues Van Assel,Randall Balestriero", "background": "自监督学习（SSL）已成为从未标记数据中提取丰富表示的强大解决方案。但是，SSL研究主要集中在干净的、精心整理的和高质量的数据集上。因此，尽管噪声数据在天文学、医学成像、地球物理学或金融等领域至关重要，但是将其应用于噪声数据仍然是一项挑战。", "innovation": "该研究提出了一种完全自监督框架，能够在无需在推理或下游微调时使用去噪器的情况下实现噪声鲁棒的表示学习。该方法首先在噪声数据上训练一个SSL去噪器，然后使用它来构建去噪到噪声的数据课程（即，首先在去噪数据上训练，然后在噪声样本上训练）以预训练一个SSL主干（例如，DINOv2），并结合一个教师引导的正则化，将噪声嵌入锚定到其去噪对应物。此过程鼓励模型内部化噪声鲁棒性。值得注意的是，去噪器可以在预训练后被丢弃，简化了部署。", "conclusion": "在带有极端高斯噪声（σ=255，SNR = 0.72 dB）的ImageNet-1k与ViT-B的环境中，该方法相比DINOv2提高了4.8%的线性探测准确率，证明了噪声感知预训练可以自发产生去噪器无关的鲁棒性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12371", "html_url": "https://arxiv.org/abs/2505.12371", "title": "MedAgentBoard：通过传统方法评估多智能体协作在多种医学任务中的表现", "title_en": "MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks", "authors": "Yinghao Zhu,Ziyi He,Haoran Hu,Xiaochen Zheng,Xichen Zhang,Zixiang Wang,Junyi Gao,Liantao Ma,Lequan Yu", "background": "大型语言模型（LLMs）的快速发展激发了多智能体协作解决复杂医学任务的兴趣，但多智能体协作的实际优势仍不够明确。当前的评估往往缺乏普遍性和完整性，未能涵盖反映真实临床实践的多样化任务，且常常忽视与单一LLM和传统方法的严苛对比。为弥补这一关键缺口，提出了一种名为MedAgentBoard的综合基准，用于系统性评估多智能体协作、单一LLM和传统方法在医学任务中的表现。MedAgentBoard包含四类不同的医学任务：（1）医学（视觉）问答；（2）通俗总结生成；（3）结构化电子健康记录（EHR）预测建模；（4）临床工作流程自动化，涵盖了文本、医学影像和结构化EHR数据。", "innovation": "MedAgentBoard是一种全面的基准，旨在系统性评估多智能体协作、单一LLM和传统方法在医学任务中的表现，包括医学（视觉）问答、通俗总结生成、结构化EHR预测建模、临床工作流程自动化等四个方面。该基准通过对多种医学任务的评估揭示了多智能体协作的优势并不一概而论，例如在临床工作流程自动化中能提升任务完整性，但在文字医学问答、EHR预测等任务上，多智能体协作并不总是优于高级单一LLM或专业传统方法。这一基准提供了重要的资源和实际建议，强调了在医学中采用任务特异性、证据支持的AI解决方案的必要性，以及需慎重考虑多智能体协作的固有复杂性和成本与实际性能增益之间的关系。", "conclusion": "MedAgentBoard揭示了多智能体协作在特定场景中的优势，但并没有普遍优于先进的单一LLM或专门的传统方法。它提供了一个有价值的资源和切实的见解，强调了在医疗中选择和开发AI解决方案时需要采取任务特定的、证据驱动的方法，并强调了多智能体协作固有的复杂性和成本必须谨慎权衡。所有代码、数据集、详细提示和实验结果均已开源，并可通过此链接访问：this https URL."}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21513", "html_url": "https://arxiv.org/abs/2510.21513", "title": "代码生成与修复中LLM组合的智慧与幻觉", "title_en": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair", "authors": "Fernando Vallecillos-Ruiz,Max Hort,Leon Moonen", "background": "当前追求单一大型语言模型（LMM）适用于所有软件工程任务，尽管这种做法资源密集且忽视了不同模型间的互补性，但不同语言模型彼此间如何互补、如何最大化组合效果的理论尚不明确，这导致实践者难以跳出单一模型系统。", "innovation": "本研究通过实证比较了五大家族中十个单独的LMM以及这些LMM的三种组合，评估了LMM间的互补性和组合模型的最佳性能。研究还评估了不同的选择策略，以从组合模型候选集中挑选出正确解。研究发现，组合模型的最大理论性能可比最佳单模型高出83%，并且基于多样性的选择策略可实现83%的理论上限，即使在小规模的两模型组合中效果也很好。", "conclusion": "基于多样性的策略在实现最大化组合性能方面更有效，能够通过使用多个LMM实现成本效益的性能提升，而基于共识的选择策略则存在放大常见错误输出的“流行性陷阱”。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.14904", "html_url": "https://arxiv.org/abs/2510.14904", "title": "MaskCaptioner: 学习在视频中同时分割和描述物体轨迹", "title_en": "MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos", "authors": "Gabriel Fiastre,Antoine Yang,Cordelia Schmid", "background": "Dense Video Object Captioning (DVOC)的任务是同时检测、跟踪和为视频中的物体轨迹生成自然语言描述，这对理解时空细节和将其转化为语言提出了很高的要求。由于任务的复杂性以及人工标注的成本高昂，之前的解决方案采用了分段训练策略，这可能导致性能不理想。", "innovation": "我们提出了一种利用最先进的VLM生成时空局部化实体的描述的方法。通过用我们的合成描述（LVISCap和LV-VISCap）扩展LVIS和LV-VIS数据集，训练了一个端到端模型MaskCaptioner，其能够同时检测、分割、跟踪和为物体轨迹生成描述。另外，通过在LVISCap和LV-VISCap上进行预训练，MaskCaptioner在三个现有基准（VidSTG，VLN和BenSMOT）上取得了最先进的DVOC结果。", "conclusion": "在本文中，我们提出的方法通过扩展数据集并在合成描述上进行预训练，实现了在三个现有基准上的最优结果。我们公开了数据集和代码可供参考。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23216", "html_url": "https://arxiv.org/abs/2510.23216", "title": "在现实足球模拟中实现类人守门员：一种样本高效强化学习方法", "title_en": "Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach", "authors": "Alessandro Sestini,Joakim Bergdahl,Jean-Philippe Barrette-LaPierre,Florian Fuchs,Brady Chen,Michael Jones,Linus Gisslén", "background": "尽管一些知名电子游戏曾用作深度强化学习（DRL）的研究平台，但游戏行业鲜少采用这种技术来构建真实的人工智能行为。以往的研究专注于训练超越人类的超人代理，这不适用于资源有限的游戏工作室培养类人代理。本文提出了一种样本高效的方法，专门用于游戏行业等工业环境中训练和微调代理。该方法通过利用预收集的数据并提高网络的可塑性，提升了基于价值的DRL的样本效率。", "innovation": "本文方法通过利用预收集的数据和提高网络的可塑性，提高了基于价值的DRL的样本效率。在EA SPORTS FC 25游戏中，该方法训练出的守门员比内置的人工智能提高了10%的截球率，并且比人工设计的代理更快训练出50%的代理。此外，领域专家认为该方法创造出比手工设计的代理更人性化的游戏体验。", "conclusion": "该方法已被应用于最新系列的发布中，证明了其重要影响。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.10728", "html_url": "https://arxiv.org/abs/2510.10728", "title": "粗糙路径签名：学习 Neural RDE 用于投资组合优化", "title_en": "Rough Path Signatures: Learning Neural RDEs for Portfolio Optimization", "authors": "Ali Atiah Alzahrani", "background": "本文探讨了高维度路径依赖估值和控制的问题，并引入了一种结合截断对数签名和神经粗糙微分方程 (RDE) 主干的深度BSDE/2BSDE求解器。该架构将随机分析与路径到序列的学习对齐：CVaR-倾斜的终端目标旨在针对左尾风险，而可选的第二阶头部（2BSDE）提供风险敏感控制的曲率估计。", "innovation": "该论文提出了一种结合截断对数签名和神经RDE的深度BSDE/2BSDE求解器，用于应对高维和路径依赖的估值与控制问题。该方法通过同时将随机分析和现代深度学习模型相结合，增强了计算和参数预算下的准确性、尾部精度和训练稳定性，在亚洲期权和障碍期权定价以及投资组合控制方面表现优异。", "conclusion": "实验结果显示，该方法在尾部损失、HJB残差和Z以及Gamma的RMSE方面均优于较强的基准方法，特别是在d=200的高维度情况下，表现出色。消融实验还证实了序列到路径表示和2BSDE头部对提升性能的互补增益。总体而言，结果强调了随机分析与现代深度学习之间的双向对话。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大规模语言模型中的知识多样性与知识坍塌", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein", "background": "大规模语言模型倾向于生成在词汇、语义和风格上高度一致的文本，这可能导致知识坍塌现象，即随着时间推移，可访问的信息范围逐渐缩小。现有研究主要集中在封闭式多项选择设置和模糊语义特征上，未能关注时间趋势和文化背景的变化。为了克服这一局限，本研究提出了一种新的方法来衡量认知多样性，即LLM输出中现实世界声明的变异性，并通过广泛的经验研究调查了LLM知识坍塌的情况。", "innovation": "本研究首次提出了一种新的方法来衡量认知多样性，并通过27个模型、覆盖12个国家的155个话题和来源于真实用户聊天的200种提示变体进行了大规模的实证研究。研究发现，虽然较新的模型生成更为多样化的声明，但几乎所有的模型都比基本的网络搜索更不具有认知多样性。此外，研究还发现模型规模对认知多样性有负面影响，而检索增强生成则有正面影响，但这种改善因文化背景而异。相比传统的知识来源（维基百科），发现特定国家的声明更倾向于反映英语，而不是本地语言，揭示了认知表现的差距。", "conclusion": "研究结果表明，尽管较新的模型在认知多样性上有所提高，但大多数模型的认知多样性仍然低于简单的网络搜索。这意味着，虽然LSTM在一定程度上解决了知识坍塌问题，但在认知多样性方面仍有很大的改进空间。此外，研究强调了在不同文化和语言背景下检索增强生成的影响，揭示了认知表现的显著差异，并指出未来工作应进一步探索和降低知识坍塌的风险。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22319", "html_url": "https://arxiv.org/abs/2510.22319", "title": "GRPO-Guard：通过受控剪裁缓解流动匹配中的隐式过优化", "title_en": "GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping", "authors": "Jing Wang,Jiajun Liang,Jie Liu,Henglin Liu,Gongye Liu,Jun Zheng,Wanyuan Pang,Ao Ma,Zhenyu Xie,Xintao Wang,Meng Wang,Pengfei Wan,Xiaodan Liang", "background": "最近，基于GRPO（Gradient Ratio Policy Optimization）的强化学习在优化流匹配模型方面取得了显著进展，有效提高了模型与任务特定奖励的一致性。然而，在实践中，研究人员发现重要性比率（importance ratio）分布发生了系统性的偏移，其均值低于1，并且其方差在时间步中变化显著。这种偏移的、不一致的重要性比率分布导致正优势样本无法进入剪裁区域，从而使机制无法控制过度自信的正更新。结果，策略模型不可避免地进入隐式过度优化阶段——即使代理奖励不断增加，重要的图像质量和文本提示一致性等指标也急剧下降，最终使训练得到的策略在实际应用中变得不可行。", "innovation": "该论文提出了GRPO-Guard，一种简单但有效的增强GRPO框架的方法。该方法引入了比率规范化，保证了在整个降噪时间步中重要性比率的平衡和一致，并确保PPO剪裁能够正确地限制有害更新。此外，还提出了一种梯度加权策略，以平衡噪声条件下的策略梯度，防止特定时间步区域的过度更新。这些设计共同作为受控剪裁机制，稳定了优化过程，显著减轻了隐式过度优化，而无需依赖重的KL正则化方法。实验表明，GRPO-Guard显著减少了过度优化现象，同时保持或提高了生成质量。", "conclusion": "通过引入GRPO-Guard和受控剪裁机制，论文成功缓解了流匹配中的隐式过度优化问题，提高了生成质量并减少了过度优化现象，验证了其有效性和实用性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08604", "html_url": "https://arxiv.org/abs/2510.08604", "title": "LatentBreak：通过潜在空间反馈破解大型语言模型", "title_en": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback", "authors": "Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio", "background": "背景：劫持攻击是指设计用于绕过大型语言模型内置安全机制的对抗攻击。现有的劫持攻击通常通过优化对抗后缀或适应长提示模板来迫使模型生成被限制或有害的响应。然而，通过简单的困惑度过滤器即可检测到这些利用机制来解锁模型响应的劫持攻击。因此，需要一种新的方法来生成对这些防御机制具有低困惑度的自然对抗提示，以克服这一问题。为此，本研究提出了LatentBreak，一种白盒劫持攻击方法，能够生成低困惑度的对抗提示，并利用潜在空间反馈来避免这些防线。这些对抗提示通过在潜在空间中最小化对抗提示与无害请求之间的距离来生成，从而保持提示的初始意图。实验表明，LatentBreak生成的对抗提示更短且困惑度更低，能够在多个安全对齐的模型中有效对抗基于困惑度的滤波器，从而优于竞争性的劫持算法", "innovation": "创新：提出了LatentBreak，一种白盒方法，通过潜在空间反馈生成低困惑度的对抗提示来绕过基于困惑度的过滤器。与传统的添加高困惑度后缀或长模板的方法不同，LatentBreak通过在潜在空间中最小化对抗请求与无害请求之间的距离，替换原始提示中的单词，而不是添加高困惑度的对抗后缀或长模板，从而保持原始提示的初始意图", "conclusion": "结论：实验结果表明，LatentBreak能够在多个安全对齐的模型中生成更短且低困惑度的对抗提示，有效地克服了基于困惑度的滤波器的检测，优于现有的竞争劫持算法"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23534", "html_url": "https://arxiv.org/abs/2510.23534", "title": "通过布雷登亏差最小化实现直接解偏机器学习", "title_en": "Direct Debiased Machine Learning via Bregman Divergence Minimization", "authors": "Masahiro Kato", "background": "在处理因果效应或结构模型等问题时，参数的兴趣值依赖于回归函数。将由机器学习方法估计出的回归函数直接代入识别方程可能会产生较差的表现，因为存在第一阶段偏差。为了减少这种偏差，解偏机器学习采用Neyman正交估计方程。然而，解偏机器学习通常需要估计Riesz表示者和回归函数。", "innovation": "本文开发了一种直接解偏机器学习框架，结合了Neyman目标化估计和广义Riesz回归。该框架统一了Riesz回归、协变量平衡、目标化最大似然估计（TMLE）和密度比率估计。通过最小化Neyman正交得分与已知和未知的Nuisance参数之间的差异来估计Nuisance参数、回归函数和Riesz表示者，这被称为Neyman目标化估计。还将这种Riesz表示者估计称为广义Riesz回归。此外，Neyman目标化估计还产生了TMLE作为回归函数估计的特例。", "conclusion": "对于特定的模型和Riesz表示者估计方法的配对，可以自动获得协变量平衡属性，而无需明确解决协变量平衡目标。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05014", "html_url": "https://arxiv.org/abs/2510.05014", "title": "思考后再嵌入：生成性上下文提高多模态嵌入", "title_en": "Think Then Embed: Generative Context Improves Multimodal Embedding", "authors": "Xuanming Cui,Jianpeng Cheng,Hong-you Chen,Satya Narayan Shukla,Abhijeet Awasthi,Xichen Pan,Chaitanya Ahuja,Shlok Kumar Mishra,Yonghuan Yang,Jun Xiao,Qi Guo,Ser-Nam Lim,Aashu Singh,Xiangjun Fan", "background": "当前对通用多模态嵌入（UME）的兴趣日益增加，特别是要求模型生成任务特定表示的时候。最近的研究表明，多模态大型语言模型（MLLMs）在这些任务上表现出色，但这些模型通常只作为编码器使用，而忽视了它们的生成能力。然而，随着指令的复杂性和对组合推理的需求增加，这种编码方法的有效性开始下降。借鉴思维链推理的有效性，本文提出了一种通用的思考后嵌入（TTE）框架，由推理器和嵌入器组成。", "innovation": "本文的主要贡献有三个方面。首先，通过利用强大的MLLM推理器，实现了在MMEB-V2基准测试上的最佳性能，超越了训练在大规模自有数据集上的专用模型。其次，为了减少对大型MLLM推理器的依赖，使用高质量的嵌入中心的推理轨迹微调了一个较小的MLLM推理器，开源模型中的最好性能，相比最近提出的模型，绝对收益7%。第三，探索了将推理器和嵌入器整合到一个统一模型中的策略，提高效率而不牺牲性能。", "conclusion": "研究提出了一种通用的TTE框架，通过引入显式推理步骤来对复杂多模态指令进行更精细的理解。实验结果表明，该方法在多模态嵌入任务上取得了显著的性能提升。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24817", "html_url": "https://arxiv.org/abs/2510.24817", "title": "针对失语症患者转录的合成生成方法", "title_en": "Towards a Method for Synthetic Generation of Persons with Aphasia Transcripts", "authors": "Jason M. Pittman,Anton Phillips Jr.,Yesenia Medina-Santos,Brielle C. Stark", "background": "在失语症研究中，言语治疗师（SLPs）花费大量时间手动编码语音样本，使用正确的信息单位（CIUs）来衡量个体语音片段的信息量。自动化系统识别失语症语言的能力受限于数据稀缺。例如，尽管AphasiaBank中有约600个转录本，用于训练大型语言模型的则是数十亿个词元。在更广泛的机器学习领域，研究人员越来越多地使用合成数据来填补数据稀缺的问题。通过借鉴机器学习领域的做法，本研究构建并验证了两种生成AphasiaBank失语症患者“Cat Rescue”图片描述任务的合成转录文本的方法。这些方法通过删除单词、插入填充词和替换同义词，生成了不同严重程度的失语症特征（轻度、中度、严重、极重度）的合成转录本。", "innovation": "本研究创新性地采用了程序化编程方法和两个大型语言模型（Mistral 7b Instruct和Llama 3.1 8b Instruct）生成失语症患者的原型描述转录本，模拟不同严重程度的失语症特征，并对比研究了这些方法的真实性及方向性变化，特别是通过非词密度（NDW）、词数和词长的变化。结果表明，与人工生成的转录本相比，Mistral 7b Instruct更能捕捉到失语症语言退化中的关键方面，显示出在合成转录生成方法中的现实性方向变化", "conclusion": "基于研究结果，未来应该计划创建更大的数据集，对模型进行微调以更好地表示失语症患者，并让SLPs评估合成转录的真实性及其用途。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25327", "html_url": "https://arxiv.org/abs/2510.25327", "title": "MMEdge：通过流水线感知和编码加速设备端多模态推理", "title_en": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding", "authors": "Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang", "background": "在自动驾驶、人机交互和移动健康等领域，资源受限的边缘设备上进行实时多模态推理至关重要。然而，现有研究往往忽略了传感动态与模型执行之间的紧密耦合，以及不同模态之间的复杂交互依赖性。", "innovation": "本文提出了一种基于流水线感知和编码的新设备端多模态推理框架MMEdge。MMEdge将整个推理过程分解为一系列细粒度的感知和编码单元，允许数据到达时计算即可逐步进行。此外，MMEdge引入了一个轻量级但有效的时序聚合模块，可以捕获不同流水线单元间的丰富时序动态，以保持准确性。MMEdge还整合了适应性多模态配置优化器和跨模态推测跳过机制，以提升系统性能，适应资源变异性及输入数据复杂性。", "conclusion": "实验结果表明，与现有方法相比，MMEdge在保持高任务准确性的同时，显著降低了端到端的延迟。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25114", "html_url": "https://arxiv.org/abs/2510.25114", "title": "从ε-图到具有连接功能的连续扩散模型的能量方法", "title_en": "Energy Approach from $\\varepsilon$-Graph to Continuum Diffusion Model with Connectivity Functional", "authors": "Yahong Yang,Sun Lee,Jeff Calder,Wenrui Hao", "background": "本文研究了在一般连接功能下ε-图的能量连续极限。证明了离散能量与其连续对应值之间的差异最多为O(ε)，其系数仅涉及ε趋于0时连接密度的W1,1-范数，因此误差界限在连接密度存在强局部波动时仍然有效。", "innovation": "提出了一个基于神经网络的方法，用于从边权重数据重建连接密度，并嵌入到脑动态模型框架中。这种方法使用学习到的密度生成的空间变化扩散系数取代传统的常数扩散系数，从而得到了与常数扩散模型有很大不同的动力学过程。", "conclusion": "本文证明了离散能量与连续能量之间的误差为O(ε)，连接密度的强局部波动不影响结论的正确性。通过神经网络技术，成功构建了一个能够适应空间变化的扩散系数的连续模型，并将其应用于脑动力学研究，展示出不同于传统模型的动力学特性。"}
{"llm_update_time": "20251102", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25080", "html_url": "https://arxiv.org/abs/2510.25080", "title": "Monopoly Deal: 一种用于有界单向响应博弈的基准环境", "title_en": "Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response Games", "authors": "Will Wolf", "background": "课题背景在于利用卡牌游戏研究在不确定性下的序列决策，如谈判、金融和网络安全等领域的真实世界场景。根据控制权的流动方式，这些游戏通常可以分为严格的序列型、确定性回应型和无界互惠型。相比前两者，有界单向回应型结构未被广泛研究，但提供了丰富的战略机会。在这一背景下，作者引入了Monopoly Deal的改良版作为基准环境，其中一项名为Rent的行动要求对手选择支付资源。", "innovation": "创新在于引入了改良版Monopoly Deal作为Bounded One-Sided Response Games (BORGs)的基准环境，具体通过一种Rent行动转移控制权，对手必须满足条件才能恢复控制。该研究还指出，标准的Counterfactual Regret Minimization (CFR)算法在这一环境中依然有效，无需额外的算法扩展。此外，作者构建了一个轻量级全栈研究平台，整合了环境、并行化CFR运行库和可玩的人机交互界面。", "conclusion": "研究结论表明，改良版的Monopoly Deal可以作为BORGs的研究基准环境。利用标准的CFR算法即可设计有效的策略。相关的训练好的CFR代理和源代码已公开，可用于进一步研究。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.25882", "html_url": "https://arxiv.org/abs/2510.25882", "title": "内部脆弱性，外部威胁：企业开源风险管理的扎根框架", "title_en": "Internal Vulnerabilities, External Threats: A Grounded Framework for Enterprise Open Source Risk Governance", "authors": "Wenhao Yang,Minghui Zhou,Daniel Izquierdo Cortázar,Yehui Wang", "background": "企业在开源软件上的参与从战术采用发展到了战略深度集成，这使得企业面临超出仅涉及代码范畴的复杂风险环境。传统的风险管理方法，主要集中于技术工具，对于上游的“沉默修复”，社区冲突或突发许可证变更等系统性威胁，是结构性不足的，这造成了治理方面的盲区。", "innovation": "本文通过扎根理论研究，开发了一个全面的风险治理框架。该框架建立在一个核心风险原则之上：不可控的外部威胁（例如关键依赖关系中的突发许可证变更）只有在达到可管理的内部脆弱性（例如对单一供应商项目的未定义风险偏好）时才会成为关键风险。框架通过“目标 -> 威胁 -> 脆弱性 -> 缓解”的逻辑链，提供了一个超越单纯技术检查表的综合决策模型。同时，该框架贡献了（1）一个“战略目标矩阵”以明确目标；（2）对外部威胁和内部脆弱性的系统双分类；（3）一个操作性缓解框架，这些框架将能力建设映射到这些脆弱性上。", "conclusion": "该框架通过三个行业专家对真实案例的回顾性案例研究得到了验证。这项工作为企业提供了一个新型的诊断工具和系统化的路径，从被动的“灭火”转变为积极地建立组织的免疫系统。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.25935", "html_url": "https://arxiv.org/abs/2510.25935", "title": "基于过程挖掘的软件开发工作流分析与预测系统", "title_en": "A Process Mining-Based System For The Analysis and Prediction of Software Development Workflows", "authors": "Antía Dorado,Iván Folgueira,Sofía Martín,Gonzalo Martín,Álvaro Porto,Alejandro Ramos,John Wallace", "background": "在软件开发工作流中，及时遵守截止日期对于项目的成功至关重要。现有系统通常依赖人工监控或基本的统计方法来管理这些流程，这可能导致效率低下和响应不及时。CodeSight 系统旨在通过直接从 GitHub 捕捉开发和部署数据并将其转换为过程挖掘日志来解决这些问题，以便进行详细分析。这些日志进一步被用于生成有助于理解 PR 活动模式和工作流效率的度量和仪表板。传统的预测方法在此基础上进一步发展，通过使用 LSTM 模型预测剩余的 PR 解决时间，从而实现对潜在截止日期违规的早期识别。", "innovation": "CodeSight 是一个端到端的系统，通过结合过程挖掘和机器学习，解决了现有系统效率低下的问题。创新点在于它能够从 GitHub 无缝获取数据，并通过 LSTM 模型准确预测 PR 解决时间，从而实现对潜在的截止日期违规进行早期识别，提高软件项目的管理效率。", "conclusion": "实验表明，CodeSight 系统在预测截止日期合规性方面具有很高的精度和 F1 分数。这证明了过程挖掘与机器学习在促进主动式软件项目管理方面的价值。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26620", "html_url": "https://arxiv.org/abs/2510.26620", "title": "在大型软件中使用调用图分析实现自动化安全风险检测", "title_en": "Toward Automated Security Risk Detection in Large Software Using Call Graph Analysis", "authors": "Nicholas Pecka,Lotfi Ben Othmane,Renee Bryce", "background": "威胁建模在识别和缓解安全风险方面发挥着关键作用，但手动方法往往耗费大量人力且容易出现错误。本文探讨了通过密度基和社区检测算法对调用图进行聚类，进而分析聚类后威胁的方法。", "innovation": "提出了通过调用图聚类来进行软件威胁建模的自动化方法，并通过Splunk Forwarder Operator（SFO）案例研究验证了该方法的有效性。", "conclusion": "该研究证实了该方法的有效性，并强调了其在帮助系统化威胁评估中的潜在优势，对面向现代云原生环境的可扩展、半自动化威胁建模框架的发展做出了贡献。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26430", "html_url": "https://arxiv.org/abs/2510.26430", "title": " Theta 作为 Horn 可满足性求解器", "title_en": "Theta as a Horn Solver", "authors": "Levente Bajczi(1),Milán Mondok(1),Vince Molnár(1) ((1) Department of Artificial Intelligence and Systems Engineering, Faculty of Electrical Engineering and Informatics, Budapest University of Technology and Economics, Budapest, Hungary)", "background": "Theta 是一个自2023年起参加CHC-COMP竞赛的验证框架。虽然其核心方法——基于将受约束的Horn子句（CHCs）转换为控制流自动化（CFAs）进行分析——基本保持不变，但其验证技术、设计权衡和局限性在CHCs背景下尚未得到充分探索。此前的研究主要集中在算法层面，而较少深入探讨具体的工具特性。", "innovation": "该论文填补了这一空白，提供了Theta所使用算法的详细描述，突出了其与其它CHC求解器的独特之处。同时，该研究还分析了工具在CHC-COMP基准测试中的优缺点，并在2025年竞赛中针对配置问题重新执行了工具。", "conclusion": "在纠正配置问题后，重新执行的Theta工具在竞赛基准测试中的表现得到了改善，展现出了其真实的能力。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26087", "html_url": "https://arxiv.org/abs/2510.26087", "title": "开发中国家基于ABET认证的行业成员观点探索研究", "title_en": "Industry Members' Perceptions about ABET-based Accreditation: An Exploratory Study in a Developing Country", "authors": "V. Sanchez Padilla,Albert Espinal,Jennifer M. Case,Jose Cordova-Garcia,Homero Murzi", "background": "ABET认证是一个日益突出的全球工程计划认证系统，评估时需要证明工程计划满足相关方（通常是毕业生潜在雇主）的需求。为了获得这些输入，工程计划需要组建咨询委员会。咨询委员会对学位成果的相关性的观点是这一过程中必不可少的一部分。这项质性研究旨在探讨开发中国家的行业利益相关者对此类过程的看法。研究背景是在厄瓜多一个成功获得ABET认证的工程计划中进行的，研究通过与咨询委员会中行业成员的访谈，分析他们对这一过程及其认证的有用性看法，特别是与毕业生的就业能力之间的关系。", "innovation": "本研究的创新之处在于它探讨了在开发中国家进行ABET认证的过程和影响，填补了全球化背景下该领域的知识空白。", "conclusion": "根据研究结果，我们提到了对该认证过程在非工业发达国家中实施时的重要见解，同时指出其在提高毕业生就业能力方面的潜在价值。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.24428", "html_url": "https://arxiv.org/abs/2510.24428", "title": "CodeWiki：评估生成大规模代码库综合文档的AI能力", "title_en": "CodeWiki: Evaluating AI's Ability to Generate Holistic Documentation for Large-Scale Codebases", "authors": "Anh Nguyen Hoang,Minh Le-Anh,Bach Le,Nghi D. Q. Bui", "background": "在大型且不断演进的代码库中，自动生成全面且架构意识强的文档仍然是一个挑战。当前的自动化方法仍然无法捕捉到丰富的语义依赖性和定义现实软件系统的架构结构。这种全面的文档对于长期软件维护和协作至关重要。", "innovation": "CodeWiki框架通过三级创新解决了上述问题：(i) 层次分解保持了多粒度级别的架构语境，(ii) 递归多代理处理结合动态任务分配以实现可扩展的生成，(iii) 多模态合成将文本描述与架构图和数据流表示等视觉元素整合起来。", "conclusion": "实验结果显示，与DeepWiki基线相比，CodeWiki在私有模型中的质量得分为68.79%，高出4.73个百分点，特别是在高层脚本语言上表现尤为优秀。CodeWiki已开源，以促进未来的研究和社区采用。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.01427", "html_url": "https://arxiv.org/abs/2506.01427", "title": "Forcrat：通过源解析和能力分析从C到Rust自动翻译I/O API", "title_en": "Forcrat: Automatic I/O API Translation from C to Rust via Origin and Capability Analysis", "authors": "Jaemin Hong,Sukyoung Ryu", "background": "将C代码翻译为Rust是一种提高遗留系统程序可靠性的有前景的方式。尽管已经有自动C到Rust翻译工具C2Rust，但其翻译结果仍不尽如人意，主要原因是C2Rust保留了C标准库（libc）的函数调用，而不是用Rust标准库（Rust std）中的函数替换。目前，对于C2Rust生成代码中库函数的替换工作还很少。为此，本文关注替换I/O API，这是库函数的一个重要子集，而替换I/O API面临挑战，因为libc和Rust std中的I/O API具有语义不同的设计。", "innovation": "研究提出了两种静态分析技术：源解析和能力分析以及错误源分析，使用这些结果来替换I/O API。这种方法在经过测试集验证后，(1)正确性上表现良好，所有32个具有测试集的程序在转换后通过测试；(2)效率很高，在14秒内分析和转换了422,000行代码；(3)广泛应用，替换掉了82%的I/O API调用。", "conclusion": "研究介绍了Forcrat，一种通过源解析和能力分析自动将C语言中的I/O API翻译为Rust的方法，该方法经过验证，在保留代码正确性和效率的同时，大幅度提高了转换后代码的适用性。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.21679", "html_url": "https://arxiv.org/abs/2504.21679", "title": "Java 构建不可再现性原因与标准化工具", "title_en": "Causes and Canonicalization for Unreproducible Builds in Java", "authors": "Aman Sharma,Benoit Baudry,Martin Monperrus", "background": "软件供应链的复杂性和供应链攻击的增加引起了对软件完整性的担忧。用户和利益相关者面临验证给定软件构件是否与其声明来源相符的重大挑战。可再现构建通过确保从相同源代码独立执行的构建生成相同的二进制文件来解决这一挑战。然而，实现大规模的可再现性，尤其是在 Java 中，仍然很困难，因为构建过程中存在各种非确定性因素和注意事项。", "innovation": "引入了一个关于 Java 基础软件的可再现构建的概念框架；分析了来自 Reproducible Central 的大数据集；开发了六类不可再现性根本原因的新型分类；研究了可操作的缓解措施，包括使用 OSS-Rebuild 和 jNorm 的构件和字节码标准化；提出了 Chains-Rebuild 工具，成功地对 26.60% 的 12,803 个不可再现构件进行了标准化。", "conclusion": "我们的贡献包括首次大规模分类 Java 构建不可再现性原因的大规模分类、不可再现构建的公开可用数据集以及 Chains-Rebuild 工具，该工具旨在减轻 Java 中的不可再现构建问题。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.21513", "html_url": "https://arxiv.org/abs/2510.21513", "title": "代码生成和修复中LLM集成的智慧与谬误", "title_en": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair", "authors": "Fernando Vallecillos-Ruiz,Max Hort,Leon Moonen", "background": "目前，软件工程任务中对单一大规模语言模型（LMM）的追求资源密集且忽略了不同模型互补性的潜在益处。不同模型可以贡献独特的强项，但这些模型之间的互补程度及如何最大化集成潜力仍不清楚，导致从业者没有清晰的路径超出单一模型系统。现有研究缺乏对多个模型集成的有效评估方法和策略，特别是在代码生成和程序修复方面的应用。本文通过实证比较了五大家族共十个单一LMM及其几种集成在三个软件工程基准上的性能，并评估了集成模型之间的互补性和最佳单模型与集成模型之间的性能差距。研究还评估了几种选择策略，从候选池中筛选出正确解。研究表明，集成模型的最佳性能理论上可提高83%以上，共识策略倾向于强化常见的但错误的输出，而多样性策略能实现理论潜力的95%。即使在小型双模型集成中，这种策略也有效，降低了提高性能的成本", "innovation": "本文创新之处在于通过实证方法对比了多种LMM及其集成在代码生成和程序修复任务中的表现，揭示了共识策略和多样性策略的效果差异，为软件工程中的多模型集成提供了新的思路和借鉴，具有实际应用价值和理论意义", "conclusion": "本文研究发现，通过多样性策略进行集成的LMM能实现最高的性能潜力，该策略在小规模集成中也表现出色，证明了利用多个LMM可以更高效地提升性能。这一发现对于促进多模型集成在软件工程中的应用具有重要意义。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.21451", "html_url": "https://arxiv.org/abs/2510.21451", "title": "Scalpel: 通过组装模型组件进行汽车深度学习框架测试", "title_en": "Scalpel: Automotive Deep Learning Framework Testing via Assembling Model Components", "authors": "Yinglong Zou,Juan Zhai,Chunrong Fang,An Guo,Jiawei Liu,Zhenyu Chen", "background": "深度学习（DL）在自动驾驶系统中发挥着关键作用。这些模型支持感知模块，例如物体检测和传感器融合，使车辆能够处理多传感器输入以理解复杂的环境。然而，将DL模型部署在自动驾驶系统中面临着严格的挑战，包括实时处理、有限的计算资源和严格的功率限制。为解决这些挑战，已经出现了汽车DL框架（如PaddleInference）来优化推理效率。然而，这些框架遇到了独特质量问题，如因有限调度的内存和错误的内存分配导致的崩溃。现有的DL框架测试方法无法检测到这些问题，因为生成的测试输入模型缺乏处理多输入/输出张量、多模态数据和多级别数据特征提取等三个必要能力。", "innovation": "为了弥补这一缺口，本文提出了Scalpel，一种汽车DL框架测试方法，通过在模型组件级别生成测试输入模型来解决现有测试方法的不足。Scalpel通过组装模型组件（头部、颈部、主干）来生成支持自动驾驶系统所需能力的模型。具体而言，Scalpel维护和更新模型组件库，生成测试输入并通过选择、变异和组装组件实现。成功生成的模型被重新添加回库中以丰富库的内容。新生成的模型随后在自动驾驶系统中部署，通过差异测试来测试汽车DL框架。", "conclusion": "Scalpel通过在模型组分级别生成和测试模型，填补了当前汽车DL框架测试方法的空白。这种方法能更有效地检测由于复杂部署环境引起的质量问题，从而提高汽车DL框架在实际应用中的稳定性和可靠性。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26075", "html_url": "https://arxiv.org/abs/2510.26075", "title": "FGGM：针对基于DRL的MU-MIMO调度器的正式灰盒梯度方法", "title_en": "FGGM: Formal Grey-box Gradient Method for Attacking DRL-based MU-MIMO Scheduler", "authors": "Thanh Le,Hai Duong,Yusheng Ji,ThanhVu Nguyen,John C.S. Lui", "background": "在5G移动通信系统中，MU-MIMO技术被用于提高频谱效率并支持高速数据传输。为在最大化频谱效率的同时提供用户之间的公平性，基站需要选择进行数据传输的用户子集。然而，选择最优用户子集的问题是NP难问题，因此，基于DRL的方法被用来获取近似最优解。但是，这种方法存在内在的安全问题，因为对手用户可以在不精确知道受害者CSI值的情况下，利用未经清理的原始CSI执行吞吐量下降攻击。绝大多数现有研究仅关注那些能够获得受害者CSI精确值的对手用户在上行传输中的情形，在LTE/5G移动系统中这是不切实际的。本研究中，对手用户能够仅通过观察标准化器中的均值和方差来估算受害者局部观察包括CSI的上界和下界。FGGM攻击方案基于多面体抽象域，能够在给定输入范围的条件下测量神经网络的输出范围，其目的是找到能使攻击目标得以实现的一组故意操纵的CSI，并在整个受害者局部观察范围内应用这些CSI以将网络吞吐量减少至受害者高达70%。", "innovation": "本文研究了对手用户如何利用未经清理的原始CSI执行针对基于DRL的MU-MIMO调度器的吞吐量下降攻击。通过利用多面体抽象域技术，开发了一个称为FGGM的攻击方案，能够找到一组故意操纵的CSI，使得受害者的网络吞吐量在整个局部观察范围内减少到最高70%。这一研究对基于DRL的问题，诸如面向背包资源分配的问题提供了案例研究，表明即使在对手用户不知道受害者准确局部观察值的情况下也可以执行有效的攻击。", "conclusion": "实验结果表明，FGGM可以确定一组由对手用户控制的恶意CSI向量，并在整个模拟过程中重复使用这些CSI来降低受害者网络吞吐量高达70%。尽管本研究聚焦于DRL的MU-MIMO调度器攻击，该方法也可应用于其他DRL问题，例如面向背包的资源分配问题。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2409.15049", "html_url": "https://arxiv.org/abs/2409.15049", "title": "IntelliRadar: 从网络情报精确定位恶意软件包的全面平台", "title_en": "IntelliRadar: A Comprehensive Platform to Pinpoint Malicious Packages Information from Cyber Intelligence", "authors": "Wenbo Guo,Chengwei Liu,Limin Wang,Yiran Zhang,Jiahui Wu,Zhengzi Xu,Yang Liu", "background": "公共注册库中的恶意软件包对软件供应链安全构成了严重威胁。当前的软件组件分析（SCA）工具依赖于如OSV和Snyk这样的数据库来检测这些威胁，但这些数据库存在更新延迟和覆盖不全的问题。它们忽略了来自如社交媒体和开发人员论坛等未结构化源的信息，这些源中经常是首先报告新威胁的地方。这种延迟延长了恶意软件包的生命周期，增加了下游用户的使用风险。", "innovation": "我们开发了一款名为IntelliRadar的新颖而全面的平台，用于从未结构化网络内容中收集已披露的恶意软件包名称。通过穷尽性搜索和滚雪球式的公共恶意软件包名称资源，并结合大型语言模型（LLMs）与特定领域的“最少到最多”提示，IntelliRadar确保了对多种未结构化来源的历史和当前已披露恶意软件包名称的全面收集。因此，我们构建了一个包含34,313个恶意NPM和PyPI软件包名称的全面恶意软件包数据库。我们的评估表明，IntelliRadar在恶意软件包情报提取方面取得了高精度（97.91%）。与现有数据库相比，IntelliRadar比OSV多识另外7,542个恶意软件包名称，比Snyk多识别12,684个。此外，IntelliRadar中85.6%的NPM组件和70.3%的PyPI组件的收集时间早于Snyk数据库。IntelliRadar还更具有成本效益，每条恶意软件包情报仅需0.003美元，每月仅需7美元即可持续监控。", "conclusion": "我们通过IntelliRadar识别并确认了一个下游包管理器镜像注册库中的1,981个恶意软件包，展示了其在提升软件供应链安全中的重要作用。IntelliRadar的高准确率和快速响应机制为保护软件供应链的完整性和安全性提供了强有力的支持。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.25406", "html_url": "https://arxiv.org/abs/2510.25406", "title": "Dissect-and-Restore: 基于重构的AI辅助代码验证", "title_en": "Dissect-and-Restore: AI-based Code Verification with Transient Refactoring", "authors": "Changjie Wang,Mariano Scazzariello,Anoud Alshnakat,Roberto Guanciale,Dejan Kostić,Marco Chiesa", "background": "形式化验证已成为构建可靠软件系统的关键基础，但由于需要专门的知识来编写精确的规范、处理复杂的证明义务和学习注释，使得验证成本通常比实施高出数个数量级。尽管现代AI系统能够识别数学证明中的模式并解释自然语言，但有效地将它们集成到形式化验证过程仍是一个开放的挑战。", "innovation": "我们提出了Prometheus，一种利用当前AI能力与模块化软件工程原则（例如模块化重构）相结合的新颖的AI辅助系统，以促进自动代码验证。该方法首先将复杂的程序逻辑（如嵌套循环）分解成较小的、可验证的组件，并在验证后重组以构建原始程序的证明。这个分解-重组的工作流程是非平凡的。Prometheus通过引导复杂的命题结构化分解为较小的、可验证的子命题来解决这一问题。当自动化工具不适用时，用户可以提供轻量级的自然语言指导以有效地引导证明过程。我们的评估表明，暂时应用模块化重构对代码的重新整理显著提高了AI在验证单个组件时的有效性。这种方法成功地验证了我们数据集中的86%的任务，而基线的这一比例为68%。随着规范复杂性增加，收益更为明显，验证成功从三成增加到六成九，整合复杂程序的证明大纲时，从二成五增加到百分之八十七。", "conclusion": "本研究展示了通过模块化重构和基于结构化的命题分解，结合AI辅助的代码验证系统的有效性和优势，证实了该方法在提高验证成功率，尤其是在处理复杂规范方面，相比现有方法有显著提升。"}
{"llm_update_time": "20251102", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2407.18760", "html_url": "https://arxiv.org/abs/2407.18760", "title": "Maven-Hijack: 软件供应链攻击利用打包顺序", "title_en": "Maven-Hijack: Software Supply Chain Attack Exploiting Packaging Order", "authors": "Frank Reyes,Federico Bono,Aman Sharma,Benoit Baudry,Martin Monperrus", "background": "Java项目经常依赖Maven等包管理器来管理复杂的外部依赖关系。尽管这些工具简化了开发流程，但也引入了软件供应链中的潜在风险。攻击者可以利用包的依赖顺序和Java虚拟机在运行时解析类的方式。通过在早期打包的依赖中注入具有相同完全限定名的恶意类，攻击者可以在不修改主代码库或库名的情况下，默默地篡改核心应用程序行为。我们通过攻击著名开源COVID-19接触追踪系统Corona-Warn-App来证明这种攻击在真实世界中的可行性，成功获得了对其数据库连接逻辑的控制权。我们评估了三种缓解策略，包括密封的JAR包、Java模块和Maven Enforcer插件，结果显示Java模块提供了最强的保护，而Maven Enforcer插件的重复类检测提供了最实用和有效的当前Java项目的防御措施。这些发现突显了提高Java构建和依赖管理过程中安全保障的紧急性，以防止隐蔽的供应链攻击。", "innovation": "我们提出了Maven-Hijack，这是一种新颖的利用Maven处理依赖顺序及其在运行时解析类的方式进行攻击的方法。通过在依赖中插入具有相同完全限定名的恶意类，可以在不改变主要代码或库名的情况下篡改应用程序的核心行为。我们的研究还评估了三种不同的缓解策略，并展示了Maven Enforcer插件中的重复类检测提供的一种最实战且有效的防御方法。", "conclusion": "尽管Java模块提供了强大保护，但Maven Enforcer插件中的重复类检测对于当前Java项目的防范措施来说提供了最实用有效的防御。这些发现强调了需要在Java构建和依赖管理过程中加强安全保障，以防止隐蔽的供应链攻击。"}
