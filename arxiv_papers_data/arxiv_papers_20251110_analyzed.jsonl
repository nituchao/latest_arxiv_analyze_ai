{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04032", "html_url": "https://arxiv.org/abs/2511.04032", "title": "在多主体AI轨迹中检测沉默故障", "title_en": "Detecting Silent Failures in Multi-Agentic AI Trajectories", "authors": "Divya Pathak,Harshit Kumar,Anuska Roy,Felix George,Mudit Verma,Pratibha Moogi", "background": "多主体AI系统由大型语言模型（LLMs）驱动，本质上是非决定性的，并且容易出现如漂移、循环和输出中缺失细节等难以检测的沉默故障。", "innovation": "提出了在一个基准数据集上检测多主体AI系统行为轨迹中的异常的任务，并且开发了一个数据采集管道，该管道能够捕捉用户行为、AI非决定性行为以及LLM的变化。利用这个管道，作者创建并标注了两个基准数据集，包括4,275和894个轨迹。研究结果表明监督学习方法（XGBoost）和半监督学习方法（SVDD）在检测这些异常时表现相当，准确率最高可达98%和96%。", "conclusion": "这是首次系统研究多主体AI系统中的异常检测，提供了数据集、基准测试和见解，以指导未来的研究。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03845", "html_url": "https://arxiv.org/abs/2511.03845", "title": "在看或读：多模态LLM中的用户行为推理", "title_en": "To See or To Read: User Behavior Reasoning in Multimodal LLMs", "authors": "Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan", "background": "当前，多模态大型语言模型（MLLMs）正重新定义现代代理系统如何处理和推理解用户的序列行为数据。然而，用户行为数据的文本描述和图像表示哪种方式更能提升MLLM性能尚未被充分探讨。", "innovation": "本文提出了一个名为BehaviorLens的系统性基准评估框架，该框架通过在六个MLLM上分别用文本段落、散点图和流程图三种方式表示交易数据，以评估不同模态下用户行为推理的优劣。研究结果表明，使用图像作为数据表示方式时，MLLM能够将后续购买预测的精度提高87.5%，且不增加额外的计算成本。", "conclusion": "当数据以图像形式表示时，MLLM在用户行为推理中的表现（如预测购买行为）相比于文本描述有显著提升，但仍无额外的计算开销。这一发现对于优化MLLM在处理用户行为推理任务时的效能具有重要意义。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03948", "html_url": "https://arxiv.org/abs/2511.03948", "title": "在深度知识追踪中提取因果关系", "title_en": "Extracting Causal Relations in Deep Knowledge Tracing", "authors": "Kevin Hong,Kia Karbasi,Gregory Pottie", "background": "计算教育研究领域的一个长期目标是建立可解释的知识追踪（KT）模型。Deep Knowledge Tracing (DKT) 通过使用递归神经网络（RNN）预测学生在练习中的知识和表现，被认为是传统KT方法的重要进步。已有研究表明，DKT 的性能提升源于其能够建模不同课程内容知识组件（KCs）之间的双向关系，从而能够从其他KC的表现反推学生对某一KC的理解。", "innovation": "该论文挑战了DKT优势在于建模双向关系的观点，提出DKT 实际上较强的优势在于其隐式地建立因果结构模型的能力。通过将练习关系图转化为有向无环图（DAGs）并使用因果数据子集训练DKT，该研究证明了DKT 的预测能力与这些因果结构高度一致。此外，论文还提出了一种替代方法，利用DKT 学习的表示提取练习关系DAGs，并提供了支持的实证证据。", "conclusion": "研究发现，DKT 的有效性主要由其近似因果依赖关系的能力驱动，而不是简单的关系映射。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04053", "html_url": "https://arxiv.org/abs/2511.04053", "title": "通过数值属性解释大型语言模型中的多属性共因现象", "title_en": "Interpreting Multi-Attribute Confounding through Numerical Attributes in Large Language Models", "authors": "Hirohane Takagi,Gouki Minegishi,Shota Kizawa,Issey Sukeda,Hitomi Yanaka", "background": "尽管行为研究表明大型语言模型（LLMs）在数量推理方面存在错误，但其背后的表征机制尚不清楚。本研究假设数量属性占据共享的潜空间，并探究两个问题：（1）LLMs如何内部整合单一实体的多种数量属性？（2）无关数量上下文如何扰乱这些表征及其下游输出？", "innovation": "研究结合了线性探针与部分相关分析，并通过不同规模模型的提示驱动易受攻击性测试来解决问题。研究结果表明，LLMs编码了真实世界数量关系，但往往会系统地放大这些关系。此外，无关上下文会一致地改变幅度表征，其下游效果因模型大小而异。这些发现揭示了LLMs决策过程中的脆弱性，并为多属性纠缠下的公平、表征感知控制奠定了基础，", "conclusion": "研究表明，LLMs在数量推理方面存在系统性的偏差，会放大实际的数量关系，并且无关数量信息会对表征及其下游输出产生影响。研究结果揭示了LLMs决策过程中的脆弱性，并为未来的公平、表征感知控制方案提供了依据。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04076", "html_url": "https://arxiv.org/abs/2511.04076", "title": "Agentmandering：一种通过大型语言模型代理进行公平重新分区的博弈论框架", "title_en": "Agentmandering: A Game-Theoretic Framework for Fair Redistricting via Large Language Model Agents", "authors": "Hao Li,Haotian Chen,Ruoyuan Gong,Juanjuan Wang,Hao Jiang", "background": "重新分区在塑造选票转化为政治权力方面起着核心作用。现有的计算方法主要集中在生成大量合法有效的选区划设方案上，但往往忽略了选区划设过程中涉及的战略动态。这一疏忽为具有党派倾向的参与者提供了机会，他们可以选择一些虽然在技术上合规但在政治上却有利的地图。仅仅满足形式上的规则并不能保证公平，因为选择过程本身可以被操纵。", "innovation": "我们提出了一种名为Agentmandering的新框架，该框架将重新分区重新构想为两个代表不同政治利益的代理之间轮流谈判的过程。该方法借鉴了博弈论的概念，特别是“选择和冻结”协议，将战略互动嵌入到重新分区过程中，通过大型语言模型（LLM）代理交替选择和冻结候选地图，从而逐步划分州界。评估结果显示，Agentmandering显著减少了党派偏见和不公平现象，同时其方差比标准基准低2到3个数量级。", "conclusion": "我们的研究表明，Agentmandering既提高了公平性也增强了稳定性，尤其是在摇摆州的场景中。代码可以在该链接（此网址）找到。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03878", "html_url": "https://arxiv.org/abs/2511.03878", "title": "KnowThyself: 一个用于大语言模型解释性的代理人助手", "title_en": "KnowThyself: An Agentic Assistant for LLM Interpretability", "authors": "Suraj Prasai,Mengnan Du,Ying Zhang,Fan Yang", "background": "现有的工具提供了有用的见解，但它们仍存在片段化和代码密集的问题。这些工具未能整合不同功能，使得使用和理解大语言模型的解释性变得复杂和困难。因此，需要一个能够集中不同解释性功能并简化使用过程的平台。", "innovation": "KnowThyself 是一个代理助手，它可以集中不同解释性功能到一个基于聊天的界面中，用户可以通过上传模型、提出自然语言问题并与之互动，获得带有引导解释的可视化展示。这一设计通过一个调度大语言模型重新调整用户查询，再由代理路由器将查询导向专业化模块，并最终将输出整合为连贯的解释，降低了技术门槛，提供了灵活的平台用于检查大语言模型。KnowThyself的整个过程嵌入在对话工作流中，提供了大语言模型解释性的坚实基础，使其更加易于访问。", "conclusion": "KnowThyself通过聊天界面和对话流程，简化了大语言模型的解释性，降低了技术门槛，提高了用户体验，为大语言模型的解释性提供了一个可扩展的平台，是研究和应用的一个重要贡献。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03985", "html_url": "https://arxiv.org/abs/2511.03985", "title": "ArchPilot：一种代理引导的多智能体方法用于机器学习工程", "title_en": "ArchPilot: A Proxy-Guided Multi-Agent Approach for Machine Learning Engineering", "authors": "Zhuowen Yuan,Tao Liu,Yang Yang,Yang Wang,Feng Qi,Kaushik Rangadurai,Bo Li,Shuang Yang", "background": "近年来，基于LLM的代理展现了强大的自动ML工程能力，但它们在评估候选解决方案时高度依赖于重复的全程训练运行，这导致了巨大的计算开销、对大型搜索空间的局限性和缓慢的迭代周期。", "innovation": "引入了ArchPilot，这是一个将架构生成、代理评估和自适应搜索整合到统一框架中的多智能体系统。ArchPilot 由三个专门的智能体组成：调度智能体通过基于MCTS启发式且带有重启机制的新颖算法协调搜索过程，并管理先前候选人的内存；生成智能体迭代生成、改进和调试候选架构；评估智能体执行代理训练运行，生成和优化代理函数，并根据仿真度感知将代理评分聚合为性能指标。这种多智能体协作允许ArchPilot以低对昂贵全程训练运行的依赖性来优先考虑高潜力的候选者，从而在有限预算下实现高效的ML工程。", "conclusion": "实验结果表明，ArchPilot 在 MLE-Bench 上优于最新基准如 AIDE 和 ML-Master，验证了我们的多智能体系统的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03825", "html_url": "https://arxiv.org/abs/2511.03825", "title": "不同分词算法对二进制代码分析中LLM和变换器模型的影响", "title_en": "How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis", "authors": "Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder", "background": "分词是汇编代码分析的基础，直接影响到诸如词汇量大小、语义覆盖范围和下游任务性能等内在特征。尽管分词在汇编代码分析中非常重要，但在该领域的探索还相对不足。本文旨在通过评估自然语言处理（NLP）分词模型及其参数选择（如词汇量大小）的内在属性来填补这一空白，并探索针对汇编代码的独特特征进行预处理定制和预分词规则的影响。", "innovation": "研究通过系统地考察各种分词模型的分词效率和语义捕捉能力，对比不同分词器在词汇压缩和表示忠实度方面的表现。通过采用最先进的预训练模型，如解码器仅有的大型语言模型Llama 3.2、仅编码器的变换器BERT以及编码器-解码器模型BART，评估这些分词器在多个性能指标下的有效性。初步结果表明，分词器选择对下游性能有显著影响，内在指标在一定程度上可以预测外部评估结果，揭示了内在分词器属性与实际低级代码任务之间复杂的权衡。", "conclusion": "本文为优化低于代码分析中分词模型提供了有价值的观点，有助于提高自然语言模型（NLM）为基础的二进制分析工作流的鲁棒性和可扩展性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03980", "html_url": "https://arxiv.org/abs/2511.03980", "title": "LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing", "title_en": "LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing", "authors": "Bram Bulté,Ayla Rigouts Terryn", "background": "大型语言模型（LLMs）在全球范围内被广泛采用，用户使用这些模型进行多语言交互。然而，LLMs在训练数据和优化目标方面的不平衡引发了对其能否公正反映广泛用户群体的文化多样性方面的质疑。因此，本研究探讨了LLMs与文化价值观的关系，分析了提示语言和明确文化框架对模型响应及其与不同国家人类价值观的契合度的影响。研究对象包括10种LLM，进行63项关于霍夫斯特德价值观调查模块和世界价值观调查的测试，这些项目已经被翻译成11种语言，并根据不同文化视角进行了提示的制定。", "innovation": "研究使用了霍夫斯特德价值观调查模块和世界价值观调查63项条目，将其翻译成11种语言进行测试，并根据不同文化视角进行了提示的制定。研究发现，提示语言和明确文化框架都能影响LLM的输出，但并不能完全克服模型对特定国家价值观的系统性偏见。此外，结合两种方法并不比单一的文化框架更有成效，这揭示了LLMs在反映文化多样性方面的局限性。", "conclusion": "研究确认提示语言和文化视角在一定程度上能够引导LLM的响应符合目标国家的主导价值观，但并不能克服模型对特定国家价值观的系统性偏见。因此，LLMs需要改善来更好地反映文化多样性，同时研究指出LLMs有一些固定的文化默认设置，这限制了它们代表文化多样性的能力。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04093", "html_url": "https://arxiv.org/abs/2511.04093", "title": "KGFR：一种通用知识图谱问答的基础检索器", "title_en": "KGFR: A Foundation Retriever for Generalized Knowledge Graph Question Answering", "authors": "Yuanning Cui,Zequn Sun,Wei Hu,Zhangjie Fu", "background": "大型语言模型（LLMs）在推理方面表现出色，但在处理知识密集型问题时由于上下文和参数知识有限而受限。现有的方法依赖于调优过的LLMs或GNN检索器，但在处理大规模或未见过的图形时受到数据集特定调优和可扩展性方面的限制。", "innovation": "提出了一种LLM-KGFR协作框架，其中LLM与结构化检索器Knowledge Graph Foundation Retriever (KGFR)协作。KGFR使用LLM生成的描述编码关系，并基于实体在问题中的角色初始化实体，以实现对未见过的KG的零样本泛化。KGFR采用Asymmetric Progressive Propagation (APP)，这是一种逐步扩展方法，有选择地限制高度节点，同时保留信息路径，从而高效处理大规模图形。LLM通过节点、边和路径级别接口迭代请求候选答案、支持的事实和推理路径，形成可控的推理循环。", "conclusion": "实验结果表明，LLM-KGFR在保持可扩展性和泛化能力的同时，实现了良好的性能，提供了一种实用的知识图谱增强推理解决方案。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04220", "html_url": "https://arxiv.org/abs/2511.04220", "title": "Opus: 一种Workflow评价的定量框架", "title_en": "Opus: A Quantitative Framework for Workflow Evaluation", "authors": "Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston", "background": "本文介绍了一种Opus Workflow评价框架，该框架是一种用于量化Workflow质量与效率的概论规范形式。它将正确性、可靠性、成本等方面的因素纳入到一个综合数学模型中，以实现Workflow直接比较、评分及优化。", "innovation": "该框架结合了Opus Workflow奖励模型和规范惩罚模型。Opus Workflow奖励模型是一种通过成功率、资源使用和输出收益的概率函数来估计预期性能的模型，而规范惩罚模型则是一组衡量Workflow的结构和信息质量的可测量函数，它包括凝聚力、耦合度、可观察性和信息卫生等方面。此外，该框架支持自动化Workflow的评估、排序和优化，并可在现代自动化系统中进行整合，甚至可以整合到强化学习循环中以指导Workflow的发现与改进。", "conclusion": "本文介绍了一个统一的优化公式，旨在通过联合Reward-Penalty权衡来识别和排名最优的Workflow。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04133", "html_url": "https://arxiv.org/abs/2511.04133", "title": "测试的测试者：语音AI测试平台的人工驱动质量评估", "title_en": "Testing the Testers: Human-Driven Quality Assessment of Voice AI Testing Platforms", "authors": "Miguel E. Andres,Vadim Fedorov,Rida Sadek,Enric Spagnolo-Arrizabalaga,Nadescha Trudel", "background": "随着语音AI代理加速进入生产部署，确保测试可靠性的系统方法仍然发展不足。组织无法客观评估其测试方法（内部工具或外部平台）的实际效果，导致随着语音AI每日交互量增加而产生的关键测量差距。我们提出了第一个通过以人为本的方法基准来评估语音AI测试质量的系统框架。这个方法解决了测试平台的核心双挑战：产生与真实对话高度还原的模拟质量，以及准确评估代理响应的评估质量。", "innovation": "该框架结合了现有的心理测量技术（成对比较生成Elo评分、靴型法置信区间和置换检验）和严格统计验证，提供可重复的适用于任何测试方法的指标。在对三家领先的商用平台进行全面实证评估中，使用21,600个人类判断覆盖45个模拟场景以及60个对话的金标准验证，结果表明，提出的框架具有统计学上的显著性能差异。表现最佳的平台Evalion在f1分数下的评估质量达到了0.92，而其他平台为0.73，模拟质量则为0.61。", "conclusion": "该框架使研究人员和组织能够通过实证验证任何平台的测试能力，为大规模语音AI部署提供坚实的质量测量基础，还提供了可重复性和采纳的支撑材料。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04285", "html_url": "https://arxiv.org/abs/2511.04285", "title": "RLoop：具有迭代策略初始化的自我改进强化学习框架", "title_en": "RLoop: An Self-Improving Framework for Reinforcement Learning with Iterative Policy Initialization", "authors": "Zeng Zhiyuan,Jiashuo Liu,Zhangyue Yin,Ge Zhang,Wenhao Huang,Xipeng Qiu", "background": "强化学习（Reinforcement Learning，RL）中对于验证性奖励（Verifiable Rewards）的方法（RLVR）能够有效地训练巨大的逻辑推理模型。然而，这种方法在训练过程中的动态特性也带来了一个关键挑战：RL过拟合。过拟合会导致模型学会了训练奖励但却丧失了泛化能力。分析表明，这种情况主要由策略过度专业化和训练过程中生成的多样化解决方案的灾难性遗忘驱动。常规优化算法会忽视这些有价值的跨步骤策略多样性。", "innovation": "本文提出了一种自我提升的框架RLoop，基于迭代策略初始化构建。RLoop将标准的训练过程转化为良性循环：首先使用RL从给定策略探索解空间，然后过滤成功的轨迹生成专家数据集。该数据集通过拒绝采样微调（Rejection-sampling Fine-Tuning，RFT）来精炼初始策略，创建出下次迭代的优质起点。这种探索与通过迭代重新初始化进行的利用相结合，成功将短暂政策变化转化为稳健的性能提升。", "conclusion": "实验表明，RLoop能够缓解遗忘现象，并显著提高泛化能力，使得平均准确率提高了9%，并在pass@32上提高了超过15%，相较于常规RL方法。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04312", "html_url": "https://arxiv.org/abs/2511.04312", "title": "探究探针：概念对齐的方法与指标", "title_en": "Probing the Probes: Methods and Metrics for Concept Alignment", "authors": "Jacob Lysnæs-Larsen,Marte Eggen,Inga Strümke", "background": "在可解释人工智能中，概念激活向量（CAVs）通常通过训练线性分类器探针来检测人类可理解的概念，将其作为深度神经网络激活空间中的方向获得。人们普遍认为高探针准确率意味着CAV能忠实表示其目标概念。然而，本文作者证明探测器的分类准确率不能可靠地衡量概念对齐，即CAV捕获目标概念的程度。实际上，作者认为探测器更有可能捕捉到与目标无关的关联，而不仅仅是代表目标概念。", "innovation": "本文提出了基于空间线性归因的概念定位方法，并与现有的特征可视化技术进行了全面比较，以检测和缓解概念对齐问题。此外，作者提出了三种评估概念对齐的度量标准：硬准确率、分割评分和增强稳健性。研究表明，具有平移不变性和空间对齐的探测器能更一致地提高概念对齐。", "conclusion": "本文的研究结果表明，需要基于对齐的评估标准而不是仅仅依赖于探针准确率，同时也强调了定制化探针对模型架构和目标概念性质的重要性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04235", "html_url": "https://arxiv.org/abs/2511.04235", "title": "通过预测编码共享空间记忆", "title_en": "Shared Spatial Memory Through Predictive Coding", "authors": "Zhengru Fang,Yu Guo,Jingjing Wang,Yuang Zhang,Haonan An,Yinhai Wang,Yuguang Fang", "background": "在多智能体系统中，共享和重构一致的空间记忆是一个关键挑战。由于部分可观察性和带宽限制，协调往往会发生灾难性失败。", "innovation": "引入了一种多智能体预测编码框架，将协调视为最大化各智能体相互不确定性的最小化问题。通过作为信息瓶颈目标实例化，这种框架促使智能体不仅学习沟通的对象和内容，还学习沟通的时机。框架的基础是一种类似网格细胞的内部空间编码机制，这种机制自发从自监督的运动预测中涌现出来。这种内部空间编码让智能体逐渐发展出一种带宽高效的通信机制，并形成专门编码伙伴位置的神经群体，类似于海马社交地表细胞（SPCs）。通过层级强化学习策略，这些社交表示进一步被激活，以减少联合不确定性。", "conclusion": "在Memory-Maze基准测试中，该方法展示了对带宽限制的出色鲁棒性：随着带宽从每步128位减少到4位，成功度减少了19.1%，而全广播基线下降了79.0%。我们的研究为从统一预测驱动中如何涌现出复杂的社交表示提供了理论依据，并揭示了这种机制如何促进社会集体智能。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03773", "html_url": "https://arxiv.org/abs/2511.03773", "title": "通过经验合成扩展智能体学习", "title_en": "Scaling Agent Learning via Experience Synthesis", "authors": "Zhaorun Chen,Zhuokai Zhao,Kai Zhang,Bo Liu,Qi Qi,Yifan Wu,Tarun Kalluri,Sara Cao,Yuanhao Xiong,Haibo Tong,Huaxiu Yao,Hengduo Li,Jiacheng Zhu,Xian Li,Dawn Song,Bo Li,Jason Weston,Dat Huynh", "background": "虽然强化学习（RL）可以通过互动实现大型语言模型（LLM）代理的自我提升，但其实用采用由于昂贵的滚动成本、任务多样性的限制、不可靠的反馈信号以及基础设施的复杂性而受到阻碍，阻碍了大规模经验数据的收集。为了解决这些问题，我们提出了DreamGym，这是一个首个考虑了可扩展性的统一框架，旨在通过合成多样性的经验来实现有效的在线强化学习训练，以支持自主代理。DreamGym依赖于丰富的在线交互，而不是高昂的真实环境滚动，它通过逐步推理的作用模型来提取环境动态，并为RL收集可扩展的代理滚动。为提升过渡稳定性和质量，DreamGym利用了一个初始化为离线实际数据的经验回放缓冲，并不断通过新的交互来丰富这个缓冲以支持代理的训练。为提升知识获取，DreamGym会自适应地生成具有挑战性的任务，以支持更加有效的在线课程学习。无论是全合成环境还是模拟到现实的过渡场景，跨各种环境和代理基底的实验表明，DreamGym显著提高了RL训练效果。对于RL尚未准备好任务如WebArena，DreamGym的性能比所有基线高出30%以上。对于RL准备好的但成本高的环境，仅使用合成交互，它也达到了与GRPO和PPO相当的性能。将仅基于合成经验训练的策略转移到现实环境中的RL时，DreamGym提供了显著的性能提升，且所需的现实交互更少，从而提供了一种可扩展的通用RL的预热策略。", "innovation": "DreamGym 是一个首个综合考虑了广泛性和可扩展性的统一框架，它通过合成经验丰富的能力来解决RL训练中的规模有限和多样性不足的问题。DreamGym 方法不依赖于昂贵的真实环境滚动，而是通过逐步推理来提取环境动态，使用一个强化学习数据池来支持有效的代理滚动收集，提升过渡的稳定性和质量。此外，DreamGym 通过自适应生成新任务来提高知识获取和实现有效的在线课程学习，包括支持非RL准备好的任务和具有成本挑战的现实环境，提供了无与伦比的性能提升。DreamGym 代表了强化学习在大规模在线训练中的一个里程碑，它可以提供一种可扩展的、轻量级的策略，用于一般目的的强化学习应用。", "conclusion": "实验在各种环境和代理基础下显示，DreamGym 显著提高了RL训练，特别是在全合成设置和模拟到现实的场景中。在非RL准备好的任务，如WebArena，DreamGym 的性能比所有基线高出30%以上。在适合RL但成本较高的环境，它通过使用仅合成交互便匹配了与GRPO和PPO相当的性能。将基于合成经验训练的策略应用到现实中，DreamGym 还实现了显著的额外性能增益，并大大减少了对真实交互的需要，提供了一种可扩展的、通用的RL预热策略。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04316", "html_url": "https://arxiv.org/abs/2511.04316", "title": "AdversariaLLM: 统一且模块化的Large语言模型安全性研究工具箱", "title_en": "AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research", "authors": "Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann", "background": "大型语言模型（LLM）的安全性和鲁棒性研究持续扩展，但因此产生了碎片化和常常含有漏洞的实现、数据集和评估方法生态。这导致了研究之间的可重用性和可比性存在挑战，阻碍了有意义的进步。", "innovation": "我们引入了AdversariaLLM，一个用于开展LLM越狱（jailbreak）鲁棒性研究的工具箱。该工具箱的设计重点在于可重用性、正确性和可扩展性。它实现了十二种对抗性攻击算法，集成了七种涵盖有害性、过度拒绝和效用评估的基准数据集，并通过Hugging Face提供了广泛开源的LLM访问方式。此外，实现中包含如计算资源跟踪、确定结果和分布评估技术等高级功能，以促进可比性和可重用性。", "conclusion": "这些组件共同建立了一个探讨透明、可比性和可重用性研究的基础架构，为LLM安全性研究的进展做出了贡献。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04307", "html_url": "https://arxiv.org/abs/2511.04307", "title": "GUI-360：一种用于计算机使用代理的全面数据集和基准测试", "title_en": "GUI-360: A Comprehensive Dataset and Benchmark for Computer-Using Agents", "authors": "Jian Mu,Chaoyun Zhang,Chiming Ni,Lu Wang,Bo Qiao,Kartik Mathur,Qianhui Wu,Yuhang Xie,Xiaojun Ma,Mengyu Zhou,Si Qin,Liqun Li,Yu Kang,Minghua Ma,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang", "background": "计算机使用代理（CUAs）面临独特的挑战，主要受到三个持续性缺口的制约：现实世界中的CUA任务稀缺，缺乏多模态轨迹的自动化采集和标注管道，以及缺乏统一的基准来同时评估GUI语义标注、屏幕解析和动作预测。", "innovation": "GUI-360通过一个包括LLM增强的自动化流程，解决了查询来源、环境模板构建、任务实例化、批量执行和LLM驱动的质量过滤等问题。该数据集包含超过120万次执行的动作步骤，涵盖了在流行Windows办公应用程序中数千条轨迹的全分辨率截图，以及可供使用的无障碍元数据、实例化目标、中间推理轨迹以及成功和失败的动作轨迹。GUI-360支持三个经典任务：GUI语义标注、屏幕解析和动作预测，以及一个反映现代代理设计的GUI+API动作空间。基准测试表明，最先进的视觉-语言模型在语义标注和动作预测方面存在显著的‘开箱即用’不足；虽然监督微调和强化学习可以获得显著改进，但无法完全达到人类级别的可靠性。", "conclusion": "我们发布了GUI-360及其配套代码，以促进可复现实验和加速对稳健桌面CUAs的研究进程。完整的数据集已经公开发布，可以在以下链接访问：this https URL。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04177", "html_url": "https://arxiv.org/abs/2511.04177", "title": "当赋能使能力受损", "title_en": "When Empowerment Disempowers", "authors": "Claire Yang,Maya Cakmak,Max Kleiman-Weiner", "background": "赋能被提议为一种通用的目标无关优化目标，用于在AI代理中激励辅助行为。尽管家庭和医院等多人类环境对于AI辅助是很有前景的，但之前关于基于赋能的辅助工作假设AI代理在孤立环境下为一个人类提供协助。然而，研究人员使用名为Disempower-Grid的多人类网格世界测试套件，实验证明，为一个人目标最大化其自身的赋能反而会大幅降低其他人的环境影响和收益，他们将这一现象称为“去赋能”。这项研究表明单个代理环境下看似对齐的优化目标在多代理环境下可能会失衡，为人工智能对齐社区提出了更广泛挑战：在多代理环境中，目标无关的优化目标可能会导致失对齐问题，这些目标在单代理环境中看似是正确的.", "innovation": "研究者引入了一个开源的多人类网格世界测试套件Disempower-Grid，用以实验证明增强学习的辅助代理为一个目标最大化其自身赋能，反而会显著减少另一个目标在环境中的影响力，定义了“去赋能”现象，并探讨这一现象产生的环境以及解决方法。研究表明，共享赋能可以在一定程度上缓解去赋能的现象，但会牺牲用户体验和奖励，这项工作为多代理环境下的AI对齐问题提供了新思路和新解决方案.", "conclusion": "这项工作揭示了在多代理环境中，专注于单个代理的赋能目标可能会导致其他代理的赋能受损，这一现象可能会给多代理的协同与合作带来意想不到的冲突。因此，未来需要在设计多代理系统的优化目标时更加重视多代_sys_conclusion系之间的平衡和协调，避免目标之间的冲突与对立。这为未来的多代理AI系统的开发提供了重要的理论指导和实验依据，提供了一个现实而紧迫的挑战。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04341", "html_url": "https://arxiv.org/abs/2511.04341", "title": "Monitor-Generate-Verify (MGV): 正式化元认知理论以引导语言模型推理", "title_en": "Monitor-Generate-Verify (MGV):Formalising Metacognitive Theory for Language Model Reasoning", "authors": "Nick Oh,Fernand Gobet", "background": "在测试时推理架构中，如产生验证范式，模型通过迭代完善或验证自身生成的结果，但忽视了决定何时及如何启动推理过程的监控过程。这种忽视可能导致前缀主导陷阱，即模型过早地选择不太理想的推理路径，并且难以从中恢复，导致约20%的准确性下降。", "innovation": "本文通过将Flavell和Nelson和Narens的元认知理论正式化为计算规范，并提出Monitor-Generate-Verify (MGV)框架，扩展了产生验证范式，以添加在生成开始前的显式监控，该监控捕捉元认知体验（如难度评估和信心判断），并通过验证反馈进行未来监控的改进。尽管没有提供实验证据，但本文为理解推理系统故障提供了原则性的术语，并建议了未来的测试时推理设计的具体架构干预措施。", "conclusion": "本文提供了元认知理论的第一个系统性的计算翻译，为理解推理系统故障提供了一个原则性的词汇，并建议了具体的架构干预措施，以应对未来测试时推理设计。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04481", "html_url": "https://arxiv.org/abs/2511.04481", "title": "促进可持续网络代理：基于实证和理论分析的基准测试和能源消耗估算", "title_en": "Promoting Sustainable Web Agents: Benchmarking and Estimating Energy Consumption through Empirical and Theoretical Analysis", "authors": "Lars Krupp,Daniel Geißler,Vishal Banwari,Paul Lukowicz,Jakob Karolus", "background": "网络代理系统如OpenAI的Operator和Google的Project Mariner等，利用大语言模型（LLM）展现出强大的代理能力，能够自主地与互联网交互，满足用户需求。尽管网络代理研究正蓬勃发展，但其引发的可持续性问题仍很少被探讨。本研究旨在突出这一问题的紧迫性，通过理论估计和实证分析探索网络代理在能源和CO2成本方面的消耗。研究发现，不同的网络代理创建哲学可能严重影响其耗能，且更高的能源消耗并不一定意味着更好的结果。此外，缺乏关于某些网络代理模型参数和实施过程透明度也限制了能源消耗估算的准确性。", "innovation": "本研究提供了对网络代理在理论和实证层面的能源消耗进行估算的方法，强调了评价网络代理时应引入衡量能源消耗的专门指标。", "conclusion": "本研究为网络代理的评估方式带来了新的思考，倡导在基准测试中引入测量能源消耗的指标，以促进网络代理的可持续性发展。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04439", "html_url": "https://arxiv.org/abs/2511.04439", "title": "偏好陷阱：为何GRPO在序数奖励下失败", "title_en": "The Peril of Preference: Why GRPO fails on Ordinal Rewards", "authors": "Anisha Garg,Ganesh Venkatesh", "background": "GRPO因其简便性非常适合作为大型语言模型（LLM）的特定任务专家。但其简化性也在增强通过丰富、非二元反馈的强化学习训练时显得不足。当使用序数奖励给出部分信用时，GRPO的简化性开始成为问题，因为其按组平均的基线经常给予失败轨迹正面优势，从而强化错误行为。", "innovation": "提出了Correctness Relative Policy Optimization（CoRPO），一种新的公式。CoRPO使用一种自适应基线以确保失败的解决方案从不会被正面强化。一旦策略一致达到最低质量门槛，基线自动转变为相对偏好模式，促使模型找到最优解，而不是仅仅“可接受”的解。", "conclusion": "这项工作代表了我们更广泛的科研项目中的关键一步，该项目旨在通过强化学习使LLMs学会真正的新能力。通过使LLMs能够从丰富的、多维度的反馈中学习，这项工作从二元奖励进展到序数奖励，进而继续向更密集、每步监督迈进。CoRPO在代码验证任务上的实验证明了其更稳定的收敛和更好的域外泛化能力。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04584", "html_url": "https://arxiv.org/abs/2511.04584", "title": "我们在提问正确的问题吗？关于表格数据分析中自然语言查询中的歧义", "title_en": "Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis", "authors": "Daniel Gomm,Cornelius Wolff,Madelon Hulsebos", "background": "自然语言接口处理表格数据时必须处理查询中的固有歧义。通常做法是将歧义视为系统缺陷，但本文重新定义为互动协作的一种特征，即查询的指定责任由用户和系统共同承担。研究人员观察到15个流行数据集中的查询类型混杂，无法准确评估系统执行准确性和解释能力。", "innovation": "本文提出了一个理论框架，明确区分了可解决的协作查询与无法解决的非协作查询。这种分析视角从修正歧义转向了在查询解决过程中接纳协作，为表格数据自然语言接口提供了更精确的设计和评估方法。", "conclusion": "通过反思查询处理方式，本文建议在未来的研究中应更加重视协作机制在解决查询中的作用，以便为用户提供更好的交互体验。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04328", "html_url": "https://arxiv.org/abs/2511.04328", "title": "RxSafeBench：在模拟咨询中识别大型语言模型的药物安全性问题", "title_en": "RxSafeBench: Identifying Medication Safety Issues of Large Language Models in Simulated Consultation", "authors": "Jiahao Zhao,Luxin Xu,Minghuan Tan,Lichao Zhang,Ahmadreza Argha,Hamid Alinejad-Rokny,Min Yang", "background": "大型语言模型(LLMs)在多样化的医疗保健任务中取得了显著进展，但关于它们药物安全性的研究仍受限于缺乏真实世界的数据集，这是由于隐私和访问问题。此外，关于药物安全性在实际临床咨询环境中评估LLMs的研究仍然较少。为解决这些问题，该研究提出了一种框架，用于模拟和评估临床咨询以系统地评估LLMs的药物安全性。", "innovation": "该研究提出了一种名为RxSafeBench的框架，用于模拟和评估临床咨询，以系统地评估LLMs的药物安全性。它生成了包含药物风险的询诊对话，并构建了专门的药物安全性数据库RxRisk DB，该数据库包含了6725条禁忌症、28781条药物相互作用和14906条适应症-药物配对。通过两阶段的过滤策略确保了临床现实性和专业质量，最终形成了包含2443个高质量咨询情境的基准性数据集。研究还通过结构化的多项选择题评估了领先的开源和专有LLMs在模拟患者情境下的推荐安全药物的能力。", "conclusion": "研究结果表明，现有LLMs在整合禁忌症和相互作用知识方面存在困难，尤其是在风险暗示而非明示时更为明显。该研究结果指出了保障LLM系统药物安全性的关键挑战，并为改进可靠性提供了见解，包括更好的提示和任务特异性调整。RxSafeBench提供了评估LLMs药物安全性的一个全面基准，推动了更安全、更值得信赖的基于AI的临床决策支持应用的发展。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04393", "html_url": "https://arxiv.org/abs/2511.04393", "title": "利用后悔最小化方法后训练LLMs以成为更好的决策制定代理", "title_en": "Post-Training LLMs as Better Decision-Making Agents: A Regret-Minimization Approach", "authors": "Chanwoo Park,Ziyang Chen,Asuman Ozdaglar,Kaiqing Zhang", "background": "大型语言模型（LLMs）越来越多地作为“代理”在交互和动态环境中用于决策制定（DM），但由于它们并非专门设计用于DM，最近的研究表明，即使在基本的在线DM问题中，LLMs也难以取得成功，无法实现低后悔或者有效的探索-利用权衡。", "innovation": "提出了一种迭代后悔最小化微调（Iterative RMFT）的后训练程序，它通过反复凝练低后悔决策轨迹回传到基本模型中来解决这一问题。每次迭代中，模型都会展开多条决策轨迹，选取后悔值最低的k条，然后在它们上进行微调。这种方法的优势在于它依赖于模型自动生成的推理能力，而不是从已知DM算法或手动编写的思维链模板中提取行动序列，这使得输出和推理格式更具灵活性，能够在不同任务的时序边界、行动空间、奖惩过程和自然语言上下文中进行泛化。理论研究表明，在简化设置下，单层变换器可以作为一个后悔最小化的学习者发挥作用。", "conclusion": "总的来说，迭代后悔最小化微调（Iterative RMFT）为增强LLMs的决策制定能力提供了一种原则性和通用的后训练框架。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04464", "html_url": "https://arxiv.org/abs/2511.04464", "title": "超越最短路径：基于语义上下文的自主车辆路由", "title_en": "Beyond Shortest Path: Agentic Vehicular Routing with Semantic Context", "authors": "Carnot Braun,Rafael O. Jarczewski,Gabriel U. Talasso,Leandro A. Villas,Allan M. de Souza", "background": "传统的车辆路由系统能够高效地优化单一指标如时间和距离，但在考虑多个指标时，需要更多过程以进行优化。然而，它们缺乏处理人类驾驶员的复杂、语义化和动态上下文的能力，比如多步骤任务、情境限制或紧急需求。", "innovation": "本文介绍并评估了PAVe（个性化代理人车辆路由），这是一种混合型的代理辅助系统，它将具有上下文推理能力的大型语言模型（LLM）代理与多目标（时间和二氧化碳）迪杰斯特拉算法生成的候选路径相结合。通过利用预处理的城市地点兴趣（POIs）地理空间缓存来评估这些路径选项，对抗用户的任务、偏好和避免规则，PAVe能够在现实的城市场景基准测试中，将复杂的用户意图转化为适当的路线修改，初步选择的准确性超过88%，使用本地模型实现这一目标。", "conclusion": "结合经典的路由算法和以LLM为基础的语义推理层是创建个性化的、适应性的和可扩展的解决城市交通优化问题的有效方法。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04583", "html_url": "https://arxiv.org/abs/2511.04583", "title": "Jr. AI Scientist和其风险报告：从基线论文开始的自主科学探索", "title_en": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper", "authors": "Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa", "background": "理解当前AI科学家系统的功能和风险对于确保透明、可信和可持续的AI驱动科学研究是必要的。这可以防止对学术生态系统造成损害。现有的AI科学家系统或完全自动化，或仅限于小规模代码的处理，缺乏科学价值的成果。因此，迫切需要一个能够处理复杂多文件实现的系统。", "innovation": "我们开发了Jr. AI Scientist，这是一种最先进的自主AI科学家系统，模仿了初学者研究者的核心研究工作流程。给定人类导师的基线论文后，它能分析其局限性，提出改进的新型假设，通过严格的实验验证，并撰写论文记录结果。Jr. AI Scientist采用一个明确的研究工作流程，并利用现代编程代理来处理复杂的、多文件的实现。评估结果表明，相较于现有的完全自动化的系统，Jr. AI Scientist生成的论文获得了更高的评审分数。", "conclusion": "尽管Jr. AI Scientist在一定程度上超越了现有的系统，但仍存在重要的局限性和潜在风险。开发过程中识别的各种风险表明，需要对当前AI科学家系统的应用保持警惕，并指出未来研究的关键挑战。希望此次报告能增进对AI科学家开发领域当前进展和风险的理解。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04500", "html_url": "https://arxiv.org/abs/2511.04500", "title": "大型语言模型在博弈论实验中复制和预测人类合作行为", "title_en": "Large language models replicate and predict human cooperation across experiments in game theory", "authors": "Andrea Cera Palatsi,Samuel Martin-Gutierrez,Ana S. Cardenal,Max Pellert", "background": "大型语言模型（LLMs）被广泛应用于决策制定领域，如健康、教育和法律，并模拟人类行为。然而，LLMs在多大程度上能够准确地模拟人类决策仍不明确。这种差距很重要，因为决策的不一致可能导致实际应用中的不良后果，而无法模拟人类行为会使LLMs在社会模拟中无效。本文通过构建博弈论实验的数字孪生并引入系统性提示和探究框架来评估机器行为，研究三个开源模型（Llama、Mistral 和 Qwen）的表现，发现Llama能够高保真地模拟人类合作模式，捕捉人类在理性选择理论之外的行为偏差，而Qwen则与纳什均衡预测高度一致。研究指出，无需基于角色的提示即可实现群体层面的行为复制，简化了模拟过程。此外，还为新型游戏配置生成并预先注册可检验假设，扩展了原始人类测试游戏范围。研究结果表明，适当校准的大型语言模型可以复制人群级别的行为模式，并能系统地探索未探索的实验空间，为社会和行为科学的传统研究提供了补充方法，能够生成新的关于人类社会决策的实证预测。", "innovation": "本文提出了一个系统性提示和探究框架，用于评估大型语言模型在模拟人类行为方面的表现。不同于使用基于角色的提示，研究展示了无需特定提示即可实现高保真群体水平行为复制。此外，研究为新型游戏配置生成了可检验假设，扩展了传统的研究范围。这提供了一种补充传统方法的研究方式，能够生成新的关于人类社会决策的实证预测，具有重要的创新意义。", "conclusion": "适当校准的大型语言模型能够复制群体人类行为模式，并能系统地探索未探索的实验空间，为社会和行为科学研究提供了新的工具。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04556", "html_url": "https://arxiv.org/abs/2511.04556", "title": "在城市雨水管道中优化传感器布置：基于数据驱动的稀疏传感方法", "title_en": "Optimizing Sensor Placement in Urban Storm Sewers: A Data-Driven Sparse Sensing Approach", "authors": "Zihang Ding,Kun Zhang", "background": "城市地表水泛滥由暴雨超出排水系统负荷触发，正变得越来越频繁和广泛。虽然需要高空间时间和分辨率的洪水预测和监测，但由于时间、预算和技术上的实际限制，这些需求未能得到完全实现。如何在资源受限的条件下监测城市排水网络并预测流量状态是一个重大挑战。本研究提出了一个数据驱动的稀疏传感（DSS）框架，集成EPA-SWMM，旨在优化传感器布置并重构城市排水系统中的洪峰流量，以明尼苏达州杜鲁斯市的伍德兰大街流域为例进行研究。我们使用SWMM模型生成了涵盖整个排水网络洪峰流量特征的训练数据集。此外，我们应用了DSS，利用奇异值分解进行降维和QR分解进行传感器分配，根据模拟的训练数据集确定最佳监控节点。然后，通过将DSS重构的洪峰流量特征与SWMM获得的结果进行比较，验证了这些监控节点的代表性。这使得在部署少量传感器的情况下实现了高精度的流量重构。该DSS框架还可进一步集成到预测模型中，以实现有限感测和监控资源下的洪水早期预警和实时控制。", "innovation": "本研究提出了一种数据驱动的稀疏传感（DSS）框架，该框架结合了EPA-SWMM模型，能够优化传感器布置并重构城市排水系统中的洪峰流量。研究通过应用DSS技术，结合奇异值分解和QR分解，确定了最佳的监控节点位置。该方法在资源受限的条件下实现了高精度的流量重构，并证明了其对于测量不确定性和传感器故障的鲁棒性，随着传感器数量的增加，鲁棒性有所提高。该框架在计算效率和物理可解释性之间取得了平衡，能够在少传感器的情况下实现高度准确的流量重构。", "conclusion": "本研究提出的数据驱动稀疏传感（DSS）框架，结合了EPA-SWMM模型，成功地优化了城市排水系统的传感器布置，有效重构了洪水期间的洪峰流量，展示了在资源受限环境中实现高精度流量监测和预测的能力。该方法不仅实现了计算效率和物理可解释性的平衡，还增强了对传感器故障和测量不确定性的影响的抵抗性。未来该框架可以进一步集成到洪水预警系统中，以便在有限的资源下进行实时的洪水监控和控制。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04588", "html_url": "https://arxiv.org/abs/2511.04588", "title": "质疑问题：在线审议过程中的代表性审计", "title_en": "Question the Questions: Auditing Representation in Online Deliberative Processes", "authors": "Soham De,Lodewijk Gelauff,Ashish Goel,Smitha Milli,Ariel Procaccia,Alice Siu", "background": "许多公民集会和审议抽样调查等审议过程的一个关键特征是参与者可以直接与专家进行互动。虽然参与者通常被邀请向专家小组提出问题，但由于时间限制，只能选择有限数量的问题。因此，如何选择一组最能代表所有参与者的利益的问题成为了一个挑战。现有的审计框架大多基于少数群体代表原则（MQR）来评估网上审议过程中的代表性，但这些方法未能覆盖更广泛的应用案例。本文引入了基于“合理代表”（JR）的审计框架，提供了一种新的审计方法来评估问题清单的代表性，特别是在一般效用设置下首次提出了相应的算法，其中最有效算法的具体运行时间为O(mn log n)，其中n是参与者数量，m是提出的建议问题数量。", "innovation": "本文创新地提出了基于‘合理代表’（JR）的审计框架，首次提出了在一般效用设置下审计JR的算法。通过应用这些审计方法到实际审议过程中的问题清单，比较了实际问题、通过整数线性规划选择的问题以及大型语言模型生成的总结问题的代表性。这些应用展示了大规模语言模型在审议过程中的潜力和局限性。此外，本文的方法被集成到一个全球范围内的在线审议平台中，这使得实践者可以更轻松地审计和改进未来审议过程中的代表性。", "conclusion": "通过应用新的审计方法，研究发现大规模语言模型在支持审议过程方面展现出潜力，但也存在局限性。通过将研究方法集成到广受欢迎的在线审议平台上，本文为未来审议过程中的代表性改进提供了可能。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03728", "html_url": "https://arxiv.org/abs/2511.03728", "title": "通过自适应上下文管理实现高效的设备端代理", "title_en": "Efficient On-Device Agents via Adaptive Context Management", "authors": "Sanidhya Vijayvargiya,Rahul Lokesh", "background": "设备端的人工智能代理能够提供个性化的、低延迟的帮助，但它们的应用受到了有限内存容量的限制，这限制了可用上下文。这种缩减的实际上下文窗口造成了一个权衡，即在支持具有复杂工具能力的丰富状态交互与保持设备端可行性之间进行权衡。", "innovation": "本文提出了一种上下文高效设备端代理框架，通过以下三种协同优化来打破这一权衡：1）动态内存系统使用专门的LoRA适配器将对话历史压缩和结构化为上下文状态对象；2）简化工具模式的序列化格式以最小化每工具的标记开销；3）即时模式传递机制，仅在选择工具时加载完整工具定义。", "conclusion": "通过适配3B参数的语言模型到上下文高效轨迹，并与传统基线进行严格评估，该代理在复杂用户任务中取得了与传统基线相当甚至超过的表现，同时上下文压缩程度显著，系统初始提示上下文减少超过6倍，上下文增长速度减少了10倍到25倍，表明战略性上下文管理是解锁设备端强大且持久的AI的关键。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03684", "html_url": "https://arxiv.org/abs/2511.03684", "title": "基于模拟验证的集成4D/5D数字孪生框架的预测施工控制", "title_en": "Simulation-Based Validation of an Integrated 4D/5D Digital-Twin Framework for Predictive Construction Control", "authors": "Atena Khoshkonesh,Mohsen Mohammadagha,Navid Ebrahimi", "background": "美国建筑行业中持续的成本和时间偏差揭示了确定性CPM和静态文档估算的局限性，特别是在建模不确定性、进度控制不准确、成本估算不精确等方面存在的问题。", "innovation": "本文提出了一种将建筑信息模型（BIM）与自然语言处理（NLP）成本映射、计算机视觉（CV）进度测量、贝叶斯概率CPM更新和深度强化学习（DRL）资源优化相结合的集成4D/5D数字孪生框架。该框架能够提高估算效率和准确性，并在Dallas-Fort Worth的一个框架项目中展示了显著的改进效果，包括43%的估算劳动力减少，6%的加班减少，以及30%的项目预留缓冲使用减少，同时保持了在P50-P80置信区间内的按时完成。此外，数字孪生环境还能够实现实时的“假设情景”预测和具有可追溯性的成本-时间匹配通过5D知识图谱。", "conclusion": "研究结果表明，将基于AI的分析与概率性CPM和DRL结合，可以提升预测精度、增强透明度和控制韧性。已验证的工作流程为预测、适应性和可审计的施工管理提供了实际途径。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04646", "html_url": "https://arxiv.org/abs/2511.04646", "title": "DR. WELL: 动态推理和具有符号世界模型的协作学习以实现基于体态大语言模型的多智能体合作", "title_en": "DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration", "authors": "Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong", "background": "多智能体协作规划要求智能体在部分信息和有限通信的情况下做出联合决策。轨迹层面的协调经常失败，因为时间或移动上的微小偏差会引发冲突。符号规划通过提高抽象层次和提供同步和集体进展所需的最小动作风格词汇，缓解了这一挑战。多智能体规划面临的这一问题需要一种能够在不确定性和通信限制下实现有效协调的方法。", "innovation": "DR. WELL 提出了一种去中心化的神经符号框架，用于实现联合的多智能体规划。它包括一个两阶段的协商协议：首先智能体提出候选角色并推理，然后在共识和环境约束下承诺联合分配。在承诺后，每个智能体独立生成并执行符合其角色的符号计划，而不透露详细的轨迹。计划通过共享世界模型与执行结果保持一致，该模型编码了当前状态并随着智能体行动而更新。DR. WELL 通过处理符号计划而非原始轨迹来避免精细步骤级别的对齐问题，从而实现可重用、可同步和可解释的高层操作。", "conclusion": "在联合作块推移任务中的实验表明，智能体能够适应不同的情景，动态世界模型能够捕获可重用的模式，从而提高任务完成率和效率。此外，通过谈判和自我完善动态世界模型，DR. WELL 实现了更高效的协作策略，并为体态大语言模型驱动的多智能体合作提供了新的学习和推理途径。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03729", "html_url": "https://arxiv.org/abs/2511.03729", "title": "超越聊天：以人为本的LLM支持系统框架", "title_en": "Beyond Chat: a Framework for LLMs as Human-Centered Support Systems", "authors": "Zhiyin Zhou", "background": "大型语言模型正在从简单的问答服务扩展到成为同伴、教练、调解者和内容策展者，帮助人类促进成长、决策和福祉。文中提出了一个人本化大语言模型（LLM）支持系统框架，比较了跨领域的实际部署，并识别了通用设计原则：透明度、个性化、护栏、带隐私的记忆，以及同理心与可靠性的平衡。研究还概述了超越准确性的评估指标，包括信任度、参与度和长期成果，并分析了过度依赖、幻觉、偏见、隐私暴露和不平等等风险，并提出了包括统一评估、混合人机模型、记忆架构、跨领域基准测试和治理在内的未来发展方向，以支持在敏感环境中负责任地整合LLM，这些环境中人们需要陪伴和指导，而不仅仅是答案。", "innovation": "提出了一个人本化的大语言模型支持系统框架，涵盖了透明度、个性化、护栏、带隐私的记忆以及同理心与可靠性的平衡这五项通用设计原则。还提出了超越准确性评估的新指标，以及统一评估、混合人机模型、记忆架构、跨领域基准测试和治理等多个未来的研究方向。", "conclusion": "该文旨在支持在人们需要陪伴和指导的敏感环境中负责任地整合LLM，而不只是提供简单的答案。通过提出新的框架和理念，促进LLM在更广泛的人文和社交应用场景中的应用。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03727", "html_url": "https://arxiv.org/abs/2511.03727", "title": "MazeMate: 一种基于大语言模型的聊天机器人，以支持 gamified 编程学习中的计算思维", "title_en": "MazeMate: An LLM-Powered Chatbot to Support Computational Thinking in Gamified Programming Learning", "authors": "Chenyu Hou,Hua Yu,Gaoxia Zhu,John Derek Anas,Jiao Liu,Yew Soon Ong", "background": "计算思维（CT）是问题解决的基础技能，游戏化的编程环境是一种广泛应用的方法来培养这项技能。虽然大语言模型（LLMs）提供了即时编程支持，但目前的应用程序很少促进计算思维的发展。本文介绍了一款名为MazeMate的大语言模型驱动的聊天机器人，嵌入在一个基于3D迷宫的编程游戏中，旨在提供与迷宫解决和设计过程相关的适应性和情境感知的支架。论文报告了MazeMate在247名本科生中进行的首次课堂实施。学生认为MazeMate在迷宫解决方面相当有帮助，但对于迷宫设计的帮助较少。主题分析证实了对计算思维过程如分解、抽象和算法思维的支持，但也揭示了在支持迷宫设计方面存在局限性，包括建议不匹配以及虚假的算法解决方案。这些发现表明，基于大语言模型的支架有潜力支持计算思维，并强调了设计改进的方向以提高MazeMate在真实课堂中的可用性。", "innovation": "MazeMate是第一个结合大语言模型驱动的聊天机器人和3D迷宫编程游戏来支持计算思维的教学工具，能够提供适应性和情景感知的支架，以辅助迷宫解决和设计过程。", "conclusion": "MazeMate在迷宫解决方面展示了对计算思维的支持，但在迷宫设计方面存在局限性。这些发现显示了基于大语言模型的支架支持计算思维的潜力，并指出了设计改进的方向以增强MazeMate在真实课堂中的实用性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04662", "html_url": "https://arxiv.org/abs/2511.04662", "title": "VeriCoT：通过逻辑一致性检查实现神经符号链式思维验证", "title_en": "VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks", "authors": "Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala", "background": "大语言模型（LLMs）可以通过链式思考（Chain-of-Thought, CoT）执行多步推理，但它们无法可靠地验证自己的逻辑。即使它们得出正确答案，其背后的推理可能存在缺陷，从而在高风险场景中削弱信任。为了缓解这一问题，本文提出了一种神经符号方法VeriCoT，该方法可以从CoT推理中提取并验证形式逻辑论证。VeriCoT正式化每个CoT推理步骤为一阶逻辑，并确定发现论证与来源语境、常识知识或先验推理步骤相关的前提。符号表示法使自动化求解器能够验证逻辑有效性，而自然语言前提允许人类和系统识别未扎根或谬误的推理步骤。在ProofWriter、LegalBench和BioASQ数据集上的实验表明，VeriCoT能够有效地识别推理中的缺陷，并作为最终答案正确性的强大预测器。此外，VeriCoT的验证信号也用于（1）推理阶段的自我反思，（2）经过VeriCoT提炼数据集的监督微调（SFT），以及（3）使用基于验证的两两奖励进行直接偏好优化（DPO）的偏好微调（PFT），进一步改善推理的有效性和准确性.", "innovation": "VeriCoT方法通过将CoT推理步骤形式化为一阶逻辑，并利用符号表示法和自然语言前提的优势，验证逻辑论证的完整性和有效，提高了模型在高风险场景中的可靠性。此外，VeriCoT还被用作自我反思、监督微调和偏好微调的工具，进一步提高推理的有效性和准确性.", "conclusion": "VeriCoT有效地提高了LLMs推理的有效性和准确性，并在高风险场景中增强了信任度。验证信号可用于多方面增强模型性能。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03020", "html_url": "https://arxiv.org/abs/2511.03020", "title": "使用统计方法探索电子商务平台上的网络攻击模式", "title_en": "Exploratory Analysis of Cyberattack Patterns on E-Commerce Platforms Using Statistical Methods", "authors": "Fatimo Adenike Adeniya(York St John University, London Campus, London, United Kingdom)", "background": "电子商务平台面临的网络攻击日益复杂，威胁到消费者信任和业务连续性。为了应对这些挑战，本研究提出了一种结合统计建模和机器学习的混合分析框架，用于检测和预测电子商务领域的网络攻击模式。通过使用Verizon社区数据泄露（VCDB）数据集，研究应用了自回归集成平均（Auto ARIMA）进行时间序列的预测和显著性检验，结果显示，节假日购物期经历的网络攻击远比非节假日时期严重。此外，还使用方差分析评估了威胁严重性随季节变化的情况，通过集成机器学习模型（包括XGBoost、LightGBM和CatBoost）进行预测分类。研究结果揭示了在购物高峰期（如黑色星期五和节假日）期间反复出现的攻击高峰，并且涉及个人可识别信息（PII）的泄露显示出更高的威胁指标。", "innovation": "研究框架独特地结合了季节性预测和可解释的集成学习，通过时间序列风险预测和漏洞类别分类提供了一种解决方案。此外，研究还考虑了伦理问题，如敏感数据的责任使用和偏倚评估。尽管存在类别不平衡和依赖历史数据的问题，该研究对主动网络安全资源配置提供了宝贵的见解，并为未来的研究指出了方向。", "conclusion": "该研究表明，在高风险时期（如黑色星期五和节假日）频繁会出现网络攻击高峰，并且涉及个人可识别信息（PII）的泄露显示出更高的威胁指标。CatBoost模型在所有模型中表现出最佳性能（准确率为85.29%，F1分为0.2254，ROC AUC为0.8247）。框架的独特之处在于结合了季节性预测和可解释的集成学习，能够提供时间风险预测和漏洞类型分类。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03730", "html_url": "https://arxiv.org/abs/2511.03730", "title": "所有解释并非等同：探究当前XAI评估的陷阱", "title_en": "Not All Explanations are Created Equal: Investigating the Pitfalls of Current XAI Evaluation", "authors": "Joe Shymanski,Jacob Brue,Sandip Sen", "background": "解释性人工智能(XAI)的目标是通过向人类用户解释现代AI模型来增加透明度。研究人员已经提出了多种方法来评估这些XAI模型的质量，如用户研究或提出的客观指标，如“忠诚度”。但是，目前的XAI评估技术在最好的情况下也是零散的，且不具备普遍适用性。因此，大多数在这个领域进行的研究仅通过简单的用户调查来分析没有解释和使用他们提出的解决方案生成的解释之间的差异。我们并不认为这足以证明生成的解释是有高质量的，因为我们认为在大多数指标上任何类型的解释都比没有解释更好。因此，我们的研究旨在揭示这一陷阱：无论解释的质量或正确性如何，任何解释都会提高用户满意度。我们还提出应注重行动性的解释。我们使用教师代理人教授用户国际象棋概念来证明我们提出的两个主张的有效性。本章的结果将作为在XAI领域呼吁采取更全面的评估技术的行动，以证明解释质量超越用户满意度。此外，我们还分析了伪效或行动性的解释最有效的情况。", "innovation": "我们研究揭示了现有XAI评估的主要缺陷，即任何形式的解释在多数指标上相较于无解释都会提高用户满意度；同时提出了关注行动性解释的观点。我们通过一个国际象棋教学代理人的案例研究来验证我们的主张，并建议未来研究应采取更全面的评估方法来证明解释的质量，而不仅仅依赖于用户满意度。", "conclusion": "我们的结论是，需要采取更全面的评估方法来证明解释的质量，而不仅仅依赖于用户满意度。此外，提出了重视行动性解释的观点，并分析了在哪些情境下伪效或行动性的解释最有用。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03731", "html_url": "https://arxiv.org/abs/2511.03731", "title": "MimiTalk：用双重代理AI革新定性研究", "title_en": "MimiTalk: Revolutionizing Qualitative Research with Dual-Agent AI", "authors": "Fengming Liu,Shubin Yu", "background": "该研究背景在于现有的社会科学研究中，对话数据的收集受到效率和伦理的限制。为了提高数据收集的效率和确保数据质量，研究者们希望通过引入智能代理来改进传统的研究方法。MimiTalk是一个双重智能代理的宪法式AI框架，旨在提高对话数据收集的规模和伦理标准。", "innovation": "MimiTalk创新在于其融合了监督模型和对话模型，通过双智能代理的方式提高了数据收集的效率与伦理标准。此外，该研究采用了三轮实证研究来验证其有效性，研究结果显示，MimiTalk在信息丰富性、连贯性和稳定性方面优于传统的人类访谈，同时在技术洞察力和敏感话题方面也表现良好。这些发现表明双重代理宪法式AI支持人类与AI的合作研究，具有可重复、可扩展和质量控制的特征。", "conclusion": "研究结果表明，MimiTalk减少了访谈焦虑，保持了对话的连贯性，并在信息丰富性、连贯性和稳定性方面优于人类访谈。双重代理宪法式AI赋能有效的人机协作，使定性研究变得更加可重复、可扩展和受控。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03743", "html_url": "https://arxiv.org/abs/2511.03743", "title": "一种深度学习方法用于模型分类选择", "title_en": "A convolutional neural network deep learning method for model class selection", "authors": "Marios Impraimakis", "background": "本文研究了一种新的深度卷积神经网络方法的仅限响应模型分类选择能力，通过单一维度的卷积神经网络利用单一自由度响应及其分类信息进行训练和验证，不依赖系统输入信息或完全的系统识别。", "innovation": "该方法能够通过融合系统响应信号及利用加速度和位移数据的动力学约束，在小信号变化中区分不同的阻尼或滞弹性行为，适用于线性和非线性动态系统及3D建筑有限元模型的结构健康监测。", "conclusion": "所提出的深度卷积神经网络方法成功地在有限变化中选择新的未标记信号的模型类别，为结构健康监测提供了强大的工具。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03758", "html_url": "https://arxiv.org/abs/2511.03758", "title": "利用基于LLM的代理进行社会科学研究：引文网络仿真带来的启示", "title_en": "Leveraging LLM-based agents for social science research: insights from citation network simulations", "authors": "Jiarui Ji,Runlin Lei,Xuchen Pan,Zhewei Wei,Hao Sun,Yankai Lin,Xu Chen,Yongzheng Yang,Yaliang Li,Bolin Ding,Ji-Rong Wen", "background": "大型语言模型（LLMs）通过利用大量网页数据进行预训练，展示了其模拟人类行为逻辑和模式的能力。然而，LLMs在社会模拟方面的边界仍然不明确。为了进一步探索LLMs的社会属性，提出了一种基于LLM代理的CiteAgent框架，用于基于人类行为模拟生成引文网络。", "innovation": "介绍了CiteAgent框架，该框架能够捕捉现实世界引文网络中的主要现象，如幂律分布、引文扭曲和直径收缩。在此基础上，提出了两种基于LLM的社会科学研究范式：LLM-SE（基于LLM的问卷实验）和LLM-LE（基于LLM的实验室实验）。这些范式有助于对引文网络现象进行严格的分析，从而验证并挑战现有理论。此外，通过理想的社交实验扩展了传统科学学的研究范围，仿真实验结果为实际学术环境提供了宝贵的洞察。", "conclusion": "本工作证明了LLMs在社会科学研究中的潜力，特别是科学学研究领域。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03749", "html_url": "https://arxiv.org/abs/2511.03749", "title": "在爱尔兰利用时间序列深度学习模型预测多年生黑麦草的生长", "title_en": "Applying Time Series Deep Learning Models to Forecast the Growth of Perennial Ryegrass in Ireland", "authors": "Oluwadurotimi Onibonoje,Vuong M. Ngo,Andrew McCarre,Elodie Ruelle,Bernadette O-Briend,Mark Roantree", "background": "草地在全球第二大陆地碳汇中占有重要地位，对生物多样性和碳循环调节具有重要作用。爱尔兰的乳制品行业是经济的重要组成部分，但面临着盈利能力下降和可持续性挑战。当前的草生长预测主要依赖于不切实际的机械模型，为此，研究提出了一种针对单一变量数据集的深度学习模型作为替代方案。以科克地区多年生黑麦草为例，设计了一个含时卷积网络模型，展示了高预测性能。该研究通过跨1757周、34年的综合数据集验证，提供了模型配置的理想参数，促进了对模型行为的理解，增强了草生长预测的可靠性，有助于推动可持续乳制品生产实践的发展。", "innovation": "研究基于单一变量数据集，提出了适用于爱尔兰多年生黑麦草生长预测的深度学习模型，特别是利用了含时卷积网络，提供了成本有效的预测工具。通过广泛的数据验证，展示了该模型在预测领域的高准确性和可靠性，为可持续农业提供了新的解决方案。", "conclusion": "研究通过优化深度学习模型的应用，显著提升了草地生长预测的精度和可靠性，有助于促进爱尔兰乃至全球草地资源的可持续利用和乳制品产业的绿色转型。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03732", "html_url": "https://arxiv.org/abs/2511.03732", "title": "使用Hyperchat AI实现的对话集体智能（CCI）在实际预测任务中的应用", "title_en": "Conversational Collective Intelligence (CCI) using Hyperchat AI in an Authentic Forecasting Task", "authors": "Hans Schumann,Louis Rosenberg,Ganesh Mani,Gregg Willcox", "background": "Hyperchat AI 是一种新型的代理技术，能够促进无限规模的网络人群之间的深入对话，此技术允许大型团队讨论复杂问题，进行创意构思，识别风险，评估替代方案，并高效地达成优化解决方案，这些能够增强群体的集体智能（CI）。研究人员进行了一项正式的研究，旨在量化人类群体使用Hyperchat AI技术进行口头预测效果，具体是在美国职棒大联盟（MLB）比赛中的预测准确性。", "innovation": "该研究的创新之处在于使用了Hyperchat AI技术，通过网络化群体的实时互动辩论，对重大事件（如棒球比赛）的结果进行预测。研究发现，使用Hyperchat AI的群体在预测棒球比赛结果时，以高信心得出了表现优于拉斯维加斯博彩市场的预测，具体表现为78%的高信心预测准确率，显著高于拉斯维加斯57%的胜率，并且如果这些群体基于这些高信心预测进行分差投注（ATS）可以实现46%的回报率。", "conclusion": "较高的互动对话速率可以产生更准确的预测，说明实时互动讨论是提高预测准确性的重要因素。因此，该研究证实了在实际预测任务中运用对话集体智能（CCI）的价值和效果。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03757", "html_url": "https://arxiv.org/abs/2511.03757", "title": "笑、共鸣、互动：短视频个性化评论生成", "title_en": "Laugh, Relate, Engage: Stylized Comment Generation for Short Videos", "authors": "Xuan Ouyang,Senan Wang,Bouzhou Wang,Siyuan Xiahou,Jinrong Zhou,Yuekang Li", "background": "随着短视频平台成为现代互联网的核心媒体，高效的信 息传递和强烈的互动性正在重新定义用户参与和文化传播的方式。在各种用户交互形式中，评论在促进社区参与和内容再创作方面发挥着重要作用。然而，在遵守平台规定的同时，生成具有多样性和情境意识的风格化评论仍然是一个重大挑战。", "innovation": "LOALGORITHM 是一个多模态大语言模型（MLLM）驱动的模块化多智能体系统（MAS），旨在实现可控的短视频评论生成。该系统整合了视频分割、情境和情感分析以及风格感知提示构建等模块，支持六种不同评论风格：谐音、押韵、贴图应用、讽刺、直白幽默和内容提取。LOALGORITHM 能够通过对话以直接处理视频输入，并通过显式提示标记和少量示例实现精细的风格控制。", "conclusion": "LOALGORITHM 在抖音（中文）和 YouTube（英文）上的测试效果显著优于基线模型，抖音用户偏好率为90%以上，YouTube为87.55%。该研究提出了一个可扩展且文化适应性强的框架，用于短视频平台上的风格化评论生成，为增强用户参与和创意互动提供了有前景的路径。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03753", "html_url": "https://arxiv.org/abs/2511.03753", "title": "Federated Learning with Gramian Angular Fields for Privacy-Preserving ECG Classification on Heterogeneous IoT Devices", "title_en": "Federated Learning with Gramian Angular Fields for Privacy-Preserving ECG Classification on Heterogeneous IoT Devices", "authors": "Youssef Elmir,Yassine Himeur,Abbes Amira", "background": "该研究提出了一个联邦学习框架，用于保护隐私的物联网医疗环境中的心电图（ECG）分类。通过将1D ECG信号转化为2D Gramian角场（GAF）图像，该研究使特征提取更为高效，同时确保敏感医疗数据维持在每个设备上。这是首次多点验证基于GAF的联邦ECG分类方法的有效性，分析了其性能和通信效率。研究实施了跨资源受限的IoT设备的实验部署，以评估其实现于真实IoT环境中的可行性。", "innovation": "引入Gramian角场（GAF）图像，利用卷积神经网络（CNN）进行高效特征提取，同时保护敏感医疗数据，避免在中心服务器上集中存储。研究成果在异构物联网设备上实验验证了GAF基于的联邦ECG分类的有效性，并实现了高效的资源利用和通信效率。", "conclusion": "实验结果表明，在多客户端设置下，FL-GAF模型的分类准确率达95.18%，显著优于单一客户端基线模型。尽管增加了GAF转换的计算复杂性，该框架仍能保持高效的资源利用和低通信开销，突显了轻量级、隐私保护的人工智能在物联网医疗监测中的潜力，支持智能健康系统的可扩展与安全部署。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03782", "html_url": "https://arxiv.org/abs/2511.03782", "title": "专家评估LLM世界模型：高温超导体案例研究", "title_en": "Expert Evaluation of LLM World Models: A High-$T_c$ Superconductivity Case Study", "authors": "Haoyu Guo,Maria Tikhanovskaya,Paul Raccuglia,Alexey Vlaskin,Chris Co,Daniel J. Liebling,Scott Ellsworth,Matthew Abraham,Elizabeth Dorfman,N. P. Armitage,Chunhan Feng,Antoine Georges,Olivier Gingras,Dominik Kiese,Steven A. Kivelson,Vadim Oganesyan,B. J. Ramshaw,Subir Sachdev,T. Senthil,J. M. Tranquada,Michael P. Brenner,Subhashini Venugopalan,Eun-Ah Kim", "background": "大型语言模型（LLMs）在科学研究文献探索方面显示出巨大的潜力，但它们在提供复杂问题的专业且全面解答方面的有效性仍是一个活跃的研究领域。本文以高温铜氧化物为例，评估了LLM系统在文献理解方面与专家水平相当的能力。", "innovation": "本研究构建了一个涵盖该领域历史的专家精选数据库，并设计了一套专家提出的问题来检验系统的深透理解能力。此外，研究还比较了不同LLM系统的性能，尤其是两种使用检索增强生成（RAG）系统的表现优于现有的闭合模型，特别是在提供全面且有支持的答案方面。", "conclusion": "研究讨论了LLM表现的有希望方面以及所有模型的关键不足之处。这套专家提出的问题和评估标准对于评估基于LLM的推理系统的专家水平表现是很有价值的。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03761", "html_url": "https://arxiv.org/abs/2511.03761", "title": "OptiMA：一种用于非常复杂多agent系统的基于事务的吞吐量优化框架", "title_en": "OptiMA: A Transaction-Based Framework with Throughput Optimization for Very Complex Multi-Agent Systems", "authors": "Umut Çalıkyılmaz,Nitin Nayak,Jinghua Groppe,Sven Groppe", "background": "近年来，多agent系统的研究方向转向探索更大更复杂的模型以完成更复杂的任务。然而，复杂性增加可能带来两个潜在风险：故障脆弱性和性能瓶颈。本文指出了这些风险，并提出了一种基于事务的框架来设计非常复杂的多agent系统（VCMAS），同时提出了将事务调度集成到该框架中以解决性能瓶颈问题。通过实施这两种策略，作者开发了OptiMA框架，并证明它可以支持超过百个agent的VCMAS的执行，并显示出吞吐量提升超过16%的效果。此外，作者还对事务调度问题进行了理论分析，并提供了未来的相关研究工具。", "innovation": "提出了基于事务的框架OptiMA来设计非常复杂的多agent系统（VCMAS），并在其中加入了事务调度的设计元素，通过实验表明能够有效提升系统的吞吐量。此外，还进行了事务调度问题的理论分析并提供了研究工具。", "conclusion": "OptiMA框架能够支持超过百个agent的VCMAS的执行，并通过实验表明在吞吐量提升方面具有显著效果。同时进行了事务调度问题的理论分析，并提供了未来研究的相关工具。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03747", "html_url": "https://arxiv.org/abs/2511.03747", "title": "OpenMENA: 开源忆阻器接口和计算板用于神经形态边缘AI应用", "title_en": "OpenMENA: An Open-Source Memristor Interfacing and Compute Board for Neuromorphic Edge-AI Applications", "authors": "Ali Safa,Farida Mohsen,Zainab Ali,Bo Wang,Amine Bermak", "background": "文章背景介绍了忆阻器交叉阵列在边缘AI中的潜力，特别是其在节能计算中的应用，忆阻器交叉阵列能够在内存中进行乘累加运算和局部塑性学习，从而实现更高效的边缘AI计算。尽管如此，现有的技术方案往往缺乏全面的、开源的系统，能够将预训练的权重转移到忆阻器阵列，并在其上进行现场学习和特性改进，这些问题成为了深度学习硬件化的重要挑战。该论文致力于解决这些问题，通过提出Open-MENA (Open Memristor-in-Memory Accelerator)，集成了忆阻器交叉阵列的硬件接口、高层API以及用于现场学习的方法。", "innovation": "创新点主要体现在三个方面：1) 一种可重复的混合信号读取-编程-验证硬件接口设计；2) 一种高度模块化的软件系统，具备推理和设备上学习的功能，提供高级接口；3) 一种基于电压增量比例积分 (VIPI) 的编程方法，用于将预训练权重转换为模拟导电性，并进行芯片在线调优以缓解设备非理想因素的影响。这些创新共同构成了一个可完全开源的忆阻器系统，极大简化了基于忆阻器的神经形态边缘AI研究和开发。", "conclusion": "该开源系统 OpenMENA 已经被验证在手写数字识别和实际避障机器人任务中成功实现了从权重转移至设备上自适应的过程。这种新型的、可编程的忆阻器系统不仅验证了边缘AI的可行性，也为神经形态硬件的发展和边缘计算中的应用提供了可行的解决方案和研究基础。此开源项目的发布旨在促进忆阻器技术在边缘AI中的普及和应用。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03808", "html_url": "https://arxiv.org/abs/2511.03808", "title": "通过提示难度预测优化推理效率", "title_en": "Optimizing Reasoning Efficiency through Prompt Difficulty Prediction", "authors": "Bo Zhao,Berkcan Kapusuzoglu,Kartik Balasubramaniam,Sambit Sahu,Supriyo Chakraborty,Genta Indra Winata", "background": "推理语言模型在复杂任务上的表现很好，但由于其体量庞大和长时间的推理路径，部署成本高昂。现有多数方法主要依赖于大型模型进行推理，这不仅增加了计算成本，而且在某些情况下可能不是最优的解决方案。", "innovation": "本文提出了一种路由方法，该方法将每个问题分配给最有可能解决它的最小模型，从而在不牺牲准确性的前提下减少了计算资源的消耗。通过使用从 s1.1-32B 中提取的中间表示，训练轻量级的预测器以估计问题的难度或模型的正确性，进而实现模型间的路由优化。该方法在多种数学基准测试中表现出色，能够提高效率并使用较少的计算资源同时保持与 s1.1-32B 相同年限模型的性能。", "conclusion": "我们的结果表明，基于难度的路由策略对于推理模型的低成本部署具有有效性和实用性，并能够通过减少计算成本来提高部署效率。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03823", "html_url": "https://arxiv.org/abs/2511.03823", "title": "PLLuM: 带有波兰语大型语言模型的一系列模型", "title_en": "PLLuM: A Family of Polish Large Language Models", "authors": "Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik", "background": "大型语言模型（LLMs）在现代人工智能中扮演着重要角色，但它们的发展主要集中在英语上，导致对其他语言的支持有限。目前，市场上的LLMs大多以英语为中心，缺乏高质量、透明且文化相关的非英语LLMs。为了填补这一空白，本文介绍了一种新的波兰大型语言模型（Polish Large Language Model, PLLuM），这是由主要波兰研究机构组成的联盟开发的，旨在满足波兰语领域的需求，提供更高质量、透明且文化相关的大规模语言模型。", "innovation": "PLLuM 包括一个大规模的新波兰文本语料库（1400亿令牌），用于预训练，以及一个自定义指令数据集（77000个样本）和一个偏爱优化数据集（100000个样本）。它还包括一个负责任的人工智能框架，集成了严格的数据治理和输出纠正模块以及安全过滤模块。此外，作者详细描述了模型的架构、训练过程以及对基础模型和指令调优模型的对齐技术，并在公共行政领域下游任务中展示了其效用。", "conclusion": "通过公共发布这些模型，PLLuM 希望促进开放研究，并强化波兰的主权人工智能技术。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03859", "html_url": "https://arxiv.org/abs/2511.03859", "title": "在人工智能领域中的权力杠杆", "title_en": "Levers of Power in the Field of AI", "authors": "Tammy Mackenzie,Sukriti Punj,Natalie Perez,Sreyoshi Bhaduri,Branislav Radeljic", "background": "该论文探讨了学术界、政府、企业和公民社会中的决策者如何在人工智能实施过程中管理权力问题。研究通过个人体验和社会机制分析了决策者如何行使权力，并基于新制度主义者的理论框架，设计了个性化问卷，收集有关决策者职权范围的见解，形成了十二个虚构的北美和欧洲高级决策者角色，以展示个人能动性、组织逻辑和制度基础设施如何在人工智能治理中相互作用。研究还讨论了决策者在人工智能领域的个人权力层级，以及在技术变革时期如何促进机构稳定和影响机构变革的方法。", "innovation": "该研究创新性地采用新制度主义者的框架，设计个性化问卷，收集决策者对人工智能治理的见解，并以虚构的人物角色形式呈现匿名的真实响应和情境，揭示了个人在人工智能治理中的复杂角色。", "conclusion": "该研究提供了有关政策制定者及其在公民社会的同僚如何个人参与人工智能治理的观察。研究末尾提出权力杠杆在人工智能领域的动态图以及五个可供机构和社会运动研究人员测试的假设。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03771", "html_url": "https://arxiv.org/abs/2511.03771", "title": "沿著标签树攀登：保持层级的对比学习在医学成像中的应用", "title_en": "Climbing the label tree: Hierarchy-preserving contrastive learning for medical imaging", "authors": "Alif Elham Khan", "background": "医疗影像标签通常按照分类学组织（例如：器官-组织-亚型），然而标准的自监督学习（SSL）忽略了这种结构。现有技术在进行自监督学习时往往忽略了标签之间的层级关系，没有充分利用这一结构来改进模型的表现和可解释性。特别是，现有的SSL方法未能有效利用标签的嵌套层级结构来进行模型训练和评估，这可能导致生成的表示未能很好地反映标签的嵌套层次关系，从而影响模型的准确性和解释性。针对这一问题，本研究提出了一种保持层级的对比框架，旨在将标签树作为首要的训练信号和评估目标，通过引入两种插件目标：层级加权对比（HWC）和层级感知分界线（LAM），显著提升了表示质量，尤其在遵循医学影像中的分类学方面表现出色。", "innovation": "本研究创新地提出了保持层级的对比框架，其中包含两种新的插件目标：1）层级加权对比（HWC），通过共享祖先节点来调整正负样本对的强度，促进同一父类内部的表示一致性；2）层级感知分界线（LAM），通过原型分界线来分离不同层级的祖先组，确保跨层级的一致性。这些目标适用于欧氏和双曲嵌入，无需架构更改，使得模型能够更好地理解和保留标签的层级结构。通过多种基准（包括乳腺病理性组织学），他们证明了这种方法能够在保持性能的同时，更好地尊重分类学结构，提升了医学影像领域的表现和可解释性。研究还使用了专门针对层级保真的度量标准：层级F1、树距离加权准确率和父节点距离违反率，并报告了完整的top-1准确率以确保完整性。消融实验显示，即使不使用曲率，HWC和LAM也能独立有效，而结合这两种方法则能产生最佳的分类学对齐表示。", "conclusion": "总体而言，研究结果提供了一个简单易行且具有普适性的学习医疗影像表示方法，能够尊重标签树结构并推进医学影像等层级丰富的领域中的性能和可解释性。通过引入层级加权对比和层级感知分界线目标，该方法不仅提高了模型的表现，还在很大程度上改进了对标签层次结构的保留程度，对于理解和利用医疗影像中的复杂标签组织具有重要意义。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03826", "html_url": "https://arxiv.org/abs/2511.03826", "title": "CORE - 多染色图像对齐的细胞级别粗细粒度图像注册引擎", "title_en": "CORE - A Cell-Level Coarse-to-Fine Image Registration Engine for Multi-stain Image Alignment", "authors": "Esha Sadia Nasir,Behnaz Elhaminia,Mark Eastwood,Catherine King,Owen Cain,Lorraine Harper,Paul Moss,Dimitrios Chanouzas,David Snead,Nasir Rajpoot,Adam Shephard,Shan E Ahmed Raza", "background": "高分辨率的组织切片中核级别的分析需要准确和高效的全视野图像（WSI）注册。目前的方法在处理多样化多模态WSI数据集时表现欠佳，特别是在不同类型显微镜（如明场和免疫荧光）下。本文关注的是提高全片图像核级别的跨模态注册准确性与效率问题，特别是针对多染色组织切片的WSI对齐问题。", "innovation": "提出了一个创新的粗细粒度框架CORE，该框架结合了基于提示的组织掩膜提取、组织形态学全局对齐、定制的形状感知点集注册模型和非线性位移场估计方法（使用Coherent Point Drift）。这一创新点主要表现在能够自动生成细胞级别的核，并增强变形对齐的准确性，同时确保跨模态核级别的精确对齐。此外，CORE能够在几种公开和私有WSI对齐数据集上显著改进现有最先进的方法的表现，特别是在通用性、精确性和鲁棒性方面。", "conclusion": "研究通过在三个公开数据集和两个私人数据集上的实验评估了CORE的有效性。实验结果表明，与现有的最先进的方法相比，CORE在明场和免疫荧光显微镜WSI的跨模态注册方面显示出更好的表现，特别是在泛化能力、精确度和鲁棒性方面。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03855", "html_url": "https://arxiv.org/abs/2511.03855", "title": "噪声注入：改善小样本数据集中外分布泛化的性能", "title_en": "Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets", "authors": "Duong Mai,Lawrence Hall", "background": "现有的深度学习（DL）模型在图像识别中展示出对新设备或人群数据缺乏泛化能力的问题，尤其是在基于胸部X光片(CXR)检测COVID-19方面表现尤为明显。这主要是因为模型学习了特定数据源的捷径，而非基于合理的生物标志物来优化在标准数据上的性能。这种学习机制导致模型在处理与训练数据分布不同的数据时表现较差。", "innovation": "研究使用了基本的噪声注入技术（高斯噪声、斑点噪声、泊松噪声和盐和胡椒噪声）在训练过程中进行干预，以提高模型对分布变化的鲁棒性。实验结果表明，这种技术可以显著缩小内分布（ID）与外分布（OOD）评估之间的性能差距，从0.10-0.20降至0.01-0.06，基于十个随机种子在多个关键指标（如AUC、F1、准确率、召回率和特异率）上的平均表现。", "conclusion": "该研究证明了通过在训练过程中注入噪声可以提高深度学习模型对小数据集外分布数据的泛化能力，从而使得模型在面对未见过的临床数据时更加鲁棒。相关代码已经公开供其他研究者使用探究此方法的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03866", "html_url": "https://arxiv.org/abs/2511.03866", "title": "OMPILOT：利用变压器模型实现自动并行化以适应共享内存计算范式", "title_en": "OMPILOT: Harnessing Transformer Models for Auto Parallelization to Shared Memory Computing Paradigms", "authors": "Arijit Bhattacharjee,Ali TehraniJamsaz,Le Chen,Niranjan Hasabnis,Mihai Capota,Nesreen Ahmed,Ali Jannesari", "background": "最近的大语言模型（LLMs）在代码翻译方面的进步显著加速了跨编程语言的准确和高效转换。尽管最初是为自然语言处理开发的，但这些模型展示出了在建模编程语言语法规则和语义方面的强大能力，超越了传统基于规则的系统在准确性和灵活性方面都取得了优势。这些模型简化了跨语言转换，降低了开发成本，并加速了遗留代码的迁移。", "innovation": "本文介绍了OMPILOT，这是一种专门针对C++代码翻译成OpenMP的新型领域特定编码器解码器变压器。OMPILOT利用自定义预训练目标来结合并行构造的语义，并结合无监督和有监督学习策略以增强代码翻译的鲁棒性。与之前主要关注循环变换的工作不同，OMPILOT在函数级别操作，捕捉更广泛的语义上下文。我们还提出了OMPBLEU，一种新型复合指标，专门用于评估OpenMP并行构造的正确性和质量，解决了传统翻译指标的限制。", "conclusion": "通过OMPILOT和OMPBLEU的应用，我们能够更准确地评估和改进代码翻译中的OpenMP并行化效果。这为共享内存计算中的自动并行化提供了一种新的方法。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03882", "html_url": "https://arxiv.org/abs/2511.03882", "title": "研究自主X射线引导脊柱手术的机器人控制策略学习", "title_en": "Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures", "authors": "Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath", "background": "基于模仿学习的机器人控制策略在基于视频的机器人领域正重新引起关注。然而，这种方法是否适用于X射线引导的程序，如脊柱内固定术仍然不清楚，因为复杂的多视角X射线解释使得这种应用具有挑战性。本文研究了双平面引导穿刺针插入过程中模仿策略学习的机会与挑战，并开发了一个用于高现实度仿真的在硅沙盒，包含正确的轨迹数据和相应的双平面X射线序列，用于训练基于视觉信息迭代对齐穿刺针的模仿学习策略。", "innovation": "开发了一个在硅沙盒来大规模模拟X射线引导的复杂脊柱手术，这个沙盒包括真实性的高程度双平面X射线序列和正确的轨迹数据集。通过模仿学习策略训练规划和开环控制方法，仅依据视觉信息对齐穿刺针。", "conclusion": "所开发的策略首次尝试成功率为68.5%，保持了不同椎体级别的安全穿刺过程轨迹，并且在训练仅在模拟环境中的情况下，该模型仍然能够产生可行的轨迹，这表明其具有一定的泛化能力。尽管取得了初步的积极结果，但仍存在一些限制，尤其是在入点的精确性方面。全闭环控制还需要考虑如何提供足够的频率反馈，以实现更 robust 的先验知识和领域知识，这些模型可能会为未来的轻量级和无需CT的机器人术中脊柱导航提供基础。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03907", "html_url": "https://arxiv.org/abs/2511.03907", "title": "SnappyMeal：多模态AI食品记录应用程序的设计与纵向评估", "title_en": "SnappyMeal: Design and Longitudinal Evaluation of a Multimodal AI Food Logging Application", "authors": "Liam Bakar,Zachary Englhardt,Vidya Srinivas,Girish Narayanswamy,Dilini Nissanka,Shwetak Patel,Vikram Iyer", "background": "食品记录在揭示饮食与医疗、健身和健康结果之间的关系中起着至关重要的作用。目前，现有的记录方法如手写和基于应用程序的日记记录存在灵活性差、低参与度和可能导致营养总结不准确的问题。这些发现也与此前的研究一致，表明迫切需要改进食品记录方法。", "innovation": "SnappyMeal 是一种基于人工智能的饮食跟踪系统，通过利用多模态输入，为用户提供了更灵活的食品摄入记录方式。该系统通过目标相关的后续问题来智能地弥补缺失的上下文，并结合用户购物收据和营养数据库的信息检索来提高准确性。", "conclusion": "通过公开的营养基准测试和多用户在野外部署超过500个记录实例的测试，用户对可用的多种输入方法给予了高度评价，并且强烈感觉SnappyMeal的准确性很高。这些研究发现表明，可以利用多模态AI系统来极大地提高饮食跟踪的灵活性和情境感知能力，为此类智能自我跟踪应用程序铺平了道路。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03891", "html_url": "https://arxiv.org/abs/2511.03891", "title": "使用基于类别的输入图像合成提高小规模及类别不平衡数据集的诊断性能", "title_en": "Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition", "authors": "Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat", "background": "小规模、类别不平衡的数据集和低质量的输入图像会导致深度学习模型的高误预测率。本文探讨了使用基于类别图像合成的方法，通过将同一类别的多张图像进行融合，形成了复合输入图像（CoImg），来改进训练输入，从而提高模型的诊断性能和区分细微疾病模式的能力。考虑了使用高分辨率光学相干断层扫描（OCT）扫描数据集（OCTDL，含2064例视网膜扫描，涉及七种不同疾病且类别严重不平衡）。为了平衡类别，创造了一个完全类别平衡的数据集Co-OCTDL，每个扫描都是3x1布局的复合图像。通过使用VGG16模型进行原始数据集与变异数据集的对比分析，确保实验的公平性。", "innovation": "提出了基于类别的图像合成方法（Class-Based Image Composition），将同一类别的多张图像融合生成复合输入图像（CoImg），增强了类内差异，并显著提升了训练样本的信息密度和模型的区分能力，特别适用于小规模和类别不平衡的数据集。通过与基准模型的对比实验，展示了该方法在面对类别不平衡的弱数据集时也能提高预测质量，尤其对细微疾病模式的诊断能力有显著提升。", "conclusion": "基于类别图像合成的方法显著提升了OCTDL数据集的诊断性能，准确率达到99.6%，F1分数为0.995，AUC为0.9996，显著降低了误预测率。该方法在小规模和类别不平衡数据集上表现出色，证实了其在提高模型性能方面具有潜力。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03898", "html_url": "https://arxiv.org/abs/2511.03898", "title": "大规模反射式安全代码生成", "title_en": "Secure Code Generation at Scale with Reflexion", "authors": "Arup Datta,Ahmed Aljohani,Hyunsook Do", "background": "大型语言模型（LLMs）现在被广泛用于编写和重构代码，但能够正常工作的代码并不一定是安全的。研究者评估了使用去除了合规性所需提示和引用污染的Instruct Prime生成安全代码的方法，同时也使用零样本基线和多轮反思提示方法评估了五种指令调校的代码LLMs。研究通过使用Insecure Code Detector（ICD）来衡量安全性，并采用修复、回归和净收益等指标来分析结果，这些指标考虑了编程语言和CWE家族等因素。", "innovation": "该研究引入了使用反思提示方法（reflexion prompting）来提升代码安全性，从零样本基线到多轮反思提示逐步评估了不同编程语言和代码LLMs的安全性能。结果显示，尽管第一轮提示下仍有约25-33%的代码存在不安全性，但反思提示显著提升了安全性能，尤其是在第一轮提示方面，平均准确率从70.74%提升至79.43%。此外，该方法对不同类型的安全漏洞（如弱加密/配置依赖性漏洞与模板化漏洞如XSS、代码注入和硬编码秘密）表现出不同的处理效果，并提出了优化建议。", "conclusion": "反思提示方法能够有效地提升代码安全性，特别是在第一轮提示时效果明显。将单轮或多轮反射提示的应用能够获得大部分改进展益。研究结果还揭示了不同编程语言在安全性上的差异，特别是Python在安全性方面表现较高，而C和C#相对较弱。总体而言，这种方法为提升大型语言模型生成代码的安全性提供了一种新的方式。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03929", "html_url": "https://arxiv.org/abs/2511.03929", "title": "NVIDIA Nemotron Nano V2 VL", "title_en": "NVIDIA Nemotron Nano V2 VL", "authors": "NVIDIA:Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu(Danny)Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu(Justin)Xin, Di (Allan)Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin", "background": "NVIDIA推出了Nemotron Nano V2 VL，这是Nemotron视觉-语言系列的最新模型，专为强大的现实世界文档理解、长时间视频理解和推理任务设计。此模型在视觉和文本领域都取得重大进步，尤其是在模型架构、数据集和训练方法方面进行了重大改进。Nemotron Nano V2 VL以Nemotron Nano V2为基底，后者是一种混合Mamba-Transformer语言模型，并采用了创新性的token缩减技术，提高了在长文档和视频场景中的推理吞吐量。", "innovation": "Nemotron Nano V2 VL 在模型架构、数据集和训练方法方面进行了重大改进，以提高其在视觉和文本领域的表现。NVIDIA还推出了BF16、FP8和FP4格式的模型检查点，并分享了大部分的训练数据、食谱和代码，以促进在该领域的进一步研究和发展。", "conclusion": "NVIDIA的Nemotron Nano V2 VL模型在视觉和文本理解方面取得了显著提升，适用于长文档和视频等复杂场景。通过分享模型的各种格式和训练资源，NVIDIA鼓励更多研究人员参与到此类技术的研究和应用中来。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03939", "html_url": "https://arxiv.org/abs/2511.03939", "title": "RLHF：文化、多模态和低延迟对齐方法的综合调查", "title_en": "RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods", "authors": "Raghav Sharma,Manan Mehta,Sai Tiger Raina", "background": "强化学习从人类反馈（RLHF）是大型语言模型（LLMs）对齐的基准方法，但近期进展已经超越了传统的基于文本的方法。该论文关注多模态对齐、文化公平性和低延迟优化等关键领域的新前沿，以填补现有研究中的空白，为研究人员构建更稳健、高效和公正的AI系统提供了指导。", "innovation": "本文通过回顾基础算法（如PPO、DPO和GRPO），并对最新创新进行详细分析，提供了一种比较综合的分析方法，并概述了开放性挑战，填补了现有的研究空白，推动了对齐研究的新领域。", "conclusion": "本文的工作为研究人员提供了一种重要路线图，以便构建更稳健、高效和公正的人工智能系统，强调了多模态对齐、文化公平性和低延迟优化等方面的重要性，并指出了该领域需要克服的关键挑战。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03925", "html_url": "https://arxiv.org/abs/2511.03925", "title": "Collaborative Agents for Automated Program Repair in Ruby", "title_en": "Collaborative Agents for Automated Program Repair in Ruby", "authors": "Nikta Akbarpour,Mahdieh Sadat Benis,Fatemeh Hendijani Fard,Ali Ouni,Mohamed Aymen Saied", "background": "随着大型语言模型（LLMs）的快速发展，自动化程序修复（APR）也取得了显著进步。然而，现有的大多数方法仍然计算成本高，并且主要集中于少数几种编程语言上。尽管 Ruby 在 Web 开发中广泛使用并且开发者面临众多挑战，但在 APR 研究中却很少受到关注。因此，研究者们试图开发一个针对 Ruby 的轻量级框架 RAMP，以解决这些挑战。", "innovation": "RAMP 引入了一个协作代理团队，用于调试 Ruby 代码。这个团队能够生成有针对性的测试、反思错误，并不断优化候选修复方案，直至找到正确的解决方案。与以往的方法不同，RAMP 避免了依赖大规模跨语言修复数据库或昂贵的模型微调，而是直接通过轻量级提示和测试驱动反馈来操作 Ruby。RAMP 在 XCodeEval 基准测试上的表现显著优于之前的方法，达到了67%的通过率，并且在五次迭代内快速收敛。", "conclusion": "RAMP 特别擅长修复错误答案、编译错误和运行时错误。这项研究提供了一种新的多代理修复策略视角，并为将基于 LLM 的调试工具扩展到未研究过的语言奠定了基础。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03934", "html_url": "https://arxiv.org/abs/2511.03934", "title": "PEFA-AI：使用渐进式错误反馈体系架构提高开源LLM的RTL生成能力", "title_en": "PEFA-AI: Advancing Open-source LLMs for RTL generation using Progressive Error Feedback Agentic-AI", "authors": "Athma Narayanan,Mahesh Subedar,Omesh Tickoo", "background": "该研究基于自动化的 RTL 生成流的背景，以前的方法需要人工介入，而该研究提供了一种无需人类干预的多代理生态系统，该系统结合了专业的大语言模型（LLMs）和硬件模拟工具来协同完成复杂的 RTL 生成任务。此外，研究还提出了一个自纠正机制（PEFA），利用迭代的错误反馈逐步提高方法的复杂性，从而提高生成的 RTL 的准确性和有效性。", "innovation": "创新点在于提出的 PEFA（渐进式错误反馈体系结构），这是一种自纠正机制，通过迭代的错误反馈逐步提高复杂性。此外，该系统能够在不依赖特定硬件模拟工具的情况下实现高效的 RTL 生成（减少 token 计数），并有效地减少了先前方法与开源和闭源模型之间的性能差距。此外，通过使用两种开源自然语言至 RTL 数据集进行基准测试，展示了该方法的优势。", "conclusion": "该研究提出的方法在开源代理框架上实现，证明了其相对于以前的发表的方法能够提供最先进的通过率，同时在 token 计数上更为高效。该研究表明，通过合适的自纠正机制和方法复杂性的逐步提升，可以有效提高开发人员生成高质量RTL代码的自动化程度。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03913", "html_url": "https://arxiv.org/abs/2511.03913", "title": "进化优化胜过Adam优化在嵌入空间探索", "title_en": "Evolutionary Optimization Trumps Adam Optimization on Embedding Space Exploration", "authors": "Domício Pereira Neto,João Correia,Penousal Machado", "background": "深度生成模型，尤其是扩散架构，已经彻底改变了图像生成。然而，这些模型在没有昂贵的重新训练下控制和优化以达到特定目标是比较困难的。嵌入空间探索，尤其是使用进化算法（EAs），已被证明是优化图像生成，特别在扩散模型中，一个有希望的方法。因此，本研究探索了一种进化优化方法，即分离协方差矩阵自适应进化策略（sep-CMA-ES），在Stable Diffusion XL Turbo的提示嵌入矢量上的性能，对比了广为采用的自适应矩估计（Adam）方法。评估图像使用LAION美学预测器V2与CLIPScore结合起来的加权适应性函数，允许在视觉吸引力和指令遵循之间进行灵活的权衡。在Parti Prompts (P2)数据集中的一小部分实验显示，sep-CMA-ES 在美学和对齐度量方面始终提供了显著的改进，而Adam则不然。实验结果表明，进化方法为扩散模型提供了高效的、无梯度的优化，而不需微调以增强可控性。这项研究强调了进化方法在深入生成模型的嵌入空间探索中的潜力，并为未来的研究指明了方向。", "innovation": "引入了利用Sep-CMA-ES在扩散模型嵌入空间探索中的优化方法，并将其与Adam方法进行对比。Sep-CMA-ES有效地在没有梯度的情况下优化扩散模型，增强了可控性，不需要微调即可实现显著的改进。这种方法为嵌入空间探索提供了新的解决方案，特别是对于美学和指令遵循的平衡，显示出比传统优化方法更好的性能。", "conclusion": "进化方法提供了一种高效、无梯度的优化策略，用于扩散模型的嵌入空间探索，增强可控性，而无需微调。这种方法为未来的深度生成模型提供了新的研究方向。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03950", "html_url": "https://arxiv.org/abs/2511.03950", "title": "通过纹理引导的高斯网格联合优化改进多视图重构", "title_en": "Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization", "authors": "Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang", "background": "从多视角图像中重建现实世界的物体对于3D编辑、AR/VR以及数字内容创作的应用至关重要。现有的方法通常侧重于几何准确性（多视图立体）或逼真的渲染（新型视角合成），常常将几何和外观优化分开进行，这妨碍了后续的编辑任务。现有的方法在几何形状和外观优化之间往往进行分离，导致了在下游编辑任务中的挑战和局限性。", "innovation": "本研究提出了一种新颖的框架，通过高斯引导的网格差异渲染同时优化网格几何（顶点位置和面）和顶点颜色，结合输入图像的照度一致性与法线图和深度图的几何正则化。这种方法旨在统一处理几何和外观优化，提供高质量的3D重构结果，以进一步用于照明和形状变形等编辑任务中。", "conclusion": "所提出的高斯网格联合优化框架能够同时优化网格的几何形状和顶点颜色，结合了几何和外观优化，从而提供了高质量的3D重构结果，该结果可以用于各种后续编辑任务。代码将在论文接受后公开。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03912", "html_url": "https://arxiv.org/abs/2511.03912", "title": "我检测我未知的：基于随机权重平均高斯的无监督医学影像异常学习", "title_en": "I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging", "authors": "Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh(AI Research Lab, Department of Computer Science and Biomedical and Translational Sciences, Sanford School of Medicine, University Of South Dakota, Vermillion, SD, USA)", "background": "在医学影像中实现未知异常检测仍然是一个核心挑战，因为标记的异常样本稀缺且专家监督高昂。当前的系统依赖于有监督学习，需要大量标记数据和高水平的专家指导，这在医学领域是不现实的。因此，需要一种无需标注的框架，能够逐步扩展可信的正常样本集。这种框架能够从少量验证正常的种子样本开始，逐步加入不确定性的样本，确保在无需生成性重建或回放缓存的情况下实现轻微的数据漂移和错误包含，从而提高了系统的安全性和效率。", "innovation": "该论文提出了一种无监督、无需专家监督的框架，通过逐步扩展可信的正常样本集，而无需任何异常标签。该框架利用冻结预训练的视觉骨干，通过小型卷积适配器进行快速领域适应，同时减少计算量。使用紧凑的核心集存储提取的嵌入，实现高效的k-最邻近异常检测。通过双重概率门控机制，在现有核心集距离阈值内，且基于SWAG的先验不确定性的基础上加入样本以确保逐步扩展的安全性。这一机制避免了数据漂移和误包含，同时提高了框架的有效性和效率，特别是在标记样本稀缺的实际医学影像应用中。", "conclusion": "我们的系统在不断接收未标记数据的同时逐步完善对正常的定义，从而在多个数据集上表现出显著的性能提升。在COVID-CXR上，ROC-AUC从0.9489提升到0.9982（F1从0.8048提升到0.9746）；在肺炎胸部X光上，ROC-AUC从0.6834提升到0.8968；在脑MRI ND-5上，ROC-AUC从0.6041提升到0.7269，PR-AUC从0.7539提升到0.8211。这些结果突显了该框架在实际、标记样本稀缺的医学影像应用中的有效性和效率。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03993", "html_url": "https://arxiv.org/abs/2511.03993", "title": "多尺度星形胶质网络钙动力学在异常检测中生物学合理智能的应用", "title_en": "Multiscale Astrocyte Network Calcium Dynamics for Biologically Plausible Intelligence in Anomaly Detection", "authors": "Berk Iskar,Michael Taynnan Barros", "background": "传统的网络异常检测系统使用离线训练的检测器，面临多种挑战，包括概念漂移和新型威胁如零日攻击或多态攻击。这些因素使得现有系统无法有效适应变化中的威胁环境。", "innovation": "本文提出了一种Ca2+调控学习框架，借鉴了大脑中星形胶质细胞钙信号的快速、情境敏感适应机制，能有效应对概念漂移和新型威胁。该方法通过一个星形胶质细胞动态模拟器与深度神经网络相结合实现，模拟了星形胶质细胞内Ca2+动力学的关键机制。实验证明，提出了的方法在CTU-13网络流量数据集上表现出色，Ca2+调控模型在多个训练/测试分割中取得了高达近98%的准确率，表现出色，并能显著降低误报和漏报。", "conclusion": "该Ca2+调控学习框架不仅提高了网络异常检测的性能，还展示了其在需要快速适应不断变化数据模式的流检测任务中作为通用解决方案的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03976", "html_url": "https://arxiv.org/abs/2511.03976", "title": "PETRA: 基于进化轨迹的预训练进化变换器用于SARS-CoV-2突变预测", "title_en": "PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction", "authors": "Xu Zou", "background": "从出现以来，SARS-CoV-2显示出了快速且不可预测的进化轨迹，这主要体现在不断出现的免疫逃逸变异上。这给公共卫生和疫苗开发带来了持续的挑战。尽管大规模生成预训练变换器（GPTs）已经在序列数据建模上引起了革命性的变革，但它们直接应用于噪声较大的病毒基因组序列的限制仍存在。", "innovation": "PETRA（Pretrained Evolutionary TRAnsformer）采用了一种基于从系统发育树推导出的进化轨迹的方法，而不是直接使用原始RNA序列。这方法在处理病毒进化层次结构时能够有效缓解测序噪声。使用加权训练框架来解决全球序列数据在地理和时间上的不平衡问题，PETRA在预测未来SARS-CoV-2突变方面表现出色，其核苷酸突变的加权召回率为9.45%，刺突蛋白氨基酸突变的加权召回率为17.10%，远超最佳基线（分别为0.49%和6.64%）。PETRA还展示了其在实时预测主要支系（如24F(XEC)和25A(LP.8.1)）突变方面的能力。", "conclusion": "PETRA通过结合系统发育树的进化轨迹和加权训练框架，在解决SARS-CoV-2突变预测中的独特挑战上取得了显著成果，为病毒突变监控和疫苗开发提供了强有力的支持。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04001", "html_url": "https://arxiv.org/abs/2511.04001", "title": "使用通用任务框架加速科学发现", "title_en": "Accelerating scientific discovery with the common task framework", "authors": "J. Nathan Kutz,Peter Battaglia,Michael Brenner,Kevin Carlberg,Aric Hagberg,Shirley Ho,Stephan Hoyer,Henning Lange,Hod Lipson,Michael W. Mahoney,Frank Noe,Max Welling,Laure Zanna,Francis Zhu,Steven L. Brunton", "background": "机器学习（ML）和人工智能（AI）算法正在工程、物理和生物学等领域内重新塑造和增强动态系统的表征和控制能力。这些新兴的建模范式需要比较指标来评估多种科学目标，如预测、状态重构、泛化和控制，同时还要考虑有限数据场景和噪声测量。", "innovation": "本文引入了一种通用任务框架（CTF），该框架集成了一个不断增长的挑战数据集集合，涵盖了一系列实践和常见的目标。CTF是一种关键的使能技术，已经促进了传统应用如语音识别、语言处理和计算机视觉中的ML/AI算法的发展。", "conclusion": "CTF的需求不仅是客观评估对当今科学和技术实践中迅速发展的算法进行改进和部署，而且对于协调全球科学家的研究努力和资源也至关重要。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03945", "html_url": "https://arxiv.org/abs/2511.03945", "title": "通过向量翻译在大型语言模型之间直接实现语义通信", "title_en": "Direct Semantic Communication Between Large Language Models via Vector Translation", "authors": "Fu-Chun Yang,Jason Eshraghian", "background": "在多代理环境中，例如辩论、反思或工具调用，大型语言模型（LLMs）会以纯字符的形式传递信息，丢弃了大量的潜在语义。这限制了信息交换并增加了不必要的计算开销。本文通过构建学习到的向量翻译，形成了一种隐式的桥梁，使得在不同的表示空间之间可以直接实现语义交换。以往的研究表明，通用模型生成的表示比调用指令的模型生成的表示更具有可转移性，从而提高了不同模型之间的通信效率和协作能力。这项工作在Llama-2-7B和Mistral-7B-Instruct之间测试了通过向量翻译进行语义通信的可行性，并在此基础上开发了一种保守的注入方法，能够保持计算稳定性和语义一致性，同时验证了跨模型隐式语义通信的可行性，为建立共享语义而非字符的协作AI系统奠定了基础。", "innovation": "本文提出了通过向量翻译构建隐式桥梁的方法，使得不同表示空间之间的大型语言模型可以直接实现语义交换。实验结果显示，这种保守的向量翻译方法能够显著提高模型间的语义信息传递效率，同时保持了计算的稳定性。此外，研究发现通用模型生成的表示比调用指令的模型生成的表示更具有可转移性，这表明用作训练样本的数据多元化将有助于提高LLMs的泛化能力和协同能力。这项研究为AI系统的语义协同提供了新的解决方案，为开发能够处理复杂任务的协作AI系统提供了新的思路。", "conclusion": "通过向量翻译在大型语言模型之间实现直接的语义通信是可行的。使用保守的向量翻译注入方法，可以在不破坏目标模型生成能力的情况下，增强模型间的语义交换，提高模型的协作效率。此外，研究表明通用模型的表示比指令调用模型的表示更具有可转移性，这对于提高LLMs的泛化能力及实现更复杂的协作任务都有重要意义。这些发现为进一步实现更为广泛的跨模态语言模型协同和应用奠定了基础。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04000", "html_url": "https://arxiv.org/abs/2511.04000", "title": "通过合成模型生成实现可解释模型的可扩展元学习", "title_en": "Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations", "authors": "Kyaw Hpone Myint,Zhe Wu,Alexandre G.R. Day,Giri Iyengar", "background": "决策树在金融和医疗等高风险领域广泛使用，这是因为它们具有良好的可解释性。然而，为了实现元学习，通常需要大量且质量高的训练数据，这往往难以满足。现有的方法可能要么性能不足，要么计算成本高昂，这限制了决策树模型的可解释性和元学习的适用性。", "innovation": "本文提出了一种高效且可扩展的方法，用于生成合成预训练数据，以实现决策树的元学习。该方法通过合成采样近最优决策树创建大规模、现实的数据集。利用MetaTree变压器架构，本文展示了这种方法在性能上可以与基于现实数据的预训练或昂贵的最优决策树相当。此策略显著降低了计算成本，增强了数据生成的灵活性，并为可解释决策树模型的可扩展和高效元学习铺平了道路。", "conclusion": "该方法通过合成生成了近最优的可解释模型，从而在元学习中实现了可解释决策树模型的可扩展和高效学习，显著降低了计算成本，并增强了数据生成的灵活性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03995", "html_url": "https://arxiv.org/abs/2511.03995", "title": "使用LLM引导输入变异和语义反馈的混合 fuzzing", "title_en": "Hybrid Fuzzing with LLM-Guided Input Mutation and Semantic Feedback", "authors": "Shiyin Lin", "background": "软件模糊测试已成为自动漏洞发现的基础，但现有的变异策略往往缺乏语义意识，导致冗余测试案例和对程序深层状态探索缓慢。现有方法的不足之处包括缺乏有效的语义输入变异以及对新程序行为发现的不足", "innovation": "提出了一种结合静态和动态分析的混合模糊测试框架，该框架使用大型语言模型指导输入变异和语义反馈。具体创新点包括：利用静态分析提取控制流和数据流信息，并将其转化为结构化的提示，使语言模型生成语法有效的、语义多样的输入；结合执行过程中的语义反馈信号，如程序状态变化、异常类型和输出语义，优化模糊测试的输入选择", "conclusion": "在实际开源目标（如libpng、tcpdump和sqlite）上的评估表明，该方法在BF（漏洞发现时间）、语义多样性以及唯一漏洞的数量上表现出色，相较于最先进的模糊测试工具更具优势，证明了结合LLM推理与语义反馈的潜力，能够加速和深化漏洞发现"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04020", "html_url": "https://arxiv.org/abs/2511.04020", "title": "检索增强语言模型中的演绎推理：生成和验证缺失前提", "title_en": "Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises", "authors": "Shiyin Lin", "background": "大型语言模型（LLMs）通过检索增强——通常称为检索增强生成（RAG）——在知识密集型任务中表现出色。然而，当检索到的证据不完整时，RAG 脚本经常失败，导致推理过程中的空白。在这种情况下，演绎推理作为一种生成可能的缺失前提的过程，用于解释观察结果，提供了一个有原则的方法来填补这些空白。", "innovation": "本文提出了一个框架，将演绎推理集成到检索增强的LLMs中。该方法检测到证据不足、生成候选的缺失前提，并通过一致性与可验证性检查验证它们。实证结果表明，该方法提高了答案的准确性并增强了推理的真实性。这项工作强调了演绎推理作为增强RAG系统鲁棒性和可解释性的有前途的方向。", "conclusion": "这种做法展示了在RAG系统中增强推理和解释性的潜力，为后续研究提供了方向。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04002", "html_url": "https://arxiv.org/abs/2511.04002", "title": "通过自适应分片计算实现受内存和延迟约束的大型语言模型推理", "title_en": "Memory- and Latency-Constrained Inference of Large Language Models via Adaptive Split Computing", "authors": "Mingyu Sung,Vikas Palakonda,Suhwan Im,Sunghwan Moon,Il-Min Kim,Sangseok Yun,Jae-Mo Kang", "background": "大型语言模型（LLMs）在各种推理任务中已经达到了接近人类的表现水平，但由于其庞大的参数量和密集的自回归解码特性，将其部署在资源受限的物联网（IoT）设备上仍不切实际。现有的一些策略虽然可以通过将模型执行在边缘设备和云服务器之间分割来解决这一问题，但目前的方法未能解决自回归推理的独特挑战，特别是迭代的标记生成过程和不断增加的关键值（KV）缓存需求。", "innovation": "本文提出了第一个专为边缘设备上LLM部署设计的自回归感知分片计算框架。本文的主要贡献包括：1）开发了一种混合精度量化方案（OPSC）的一点分片压缩，通过策略性地将模型分为前端和后端段来预防内存超载；2）提出了一个两级中间压缩管道，结合阈值分割（TS）和标记自适应位量化（TAB-Q），以保留关键激活并大幅减少通信开销；3）构建了一个统一的优化框架，联合选择最优分片点、量化设置和序列长度，以满足严格的内存和延迟限制。", "conclusion": "论文通过广泛评估各种LLM及其硬件平台，证明了该框架在性能上优于目前最先进的量化方法，包括SmoothQuant、OmniQuant和Atom。该框架实现了1.49倍的推理速度提升和显著的通信开销减少，在保持甚至提高模型准确率的同时实现了这一目标。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04071", "html_url": "https://arxiv.org/abs/2511.04071", "title": "使用nnU-Net进行MRI左房分割", "title_en": "Left Atrial Segmentation with nnU-Net Using MRI", "authors": "Fatemeh Hosseinabadi,Seyedhassan Sharifi", "background": "左心房（LA）的准确分割对于指导心房颤动（AF）消融和构建生物物理心脏模型至关重要。手动勾勒轮廓耗时、依赖观察者且在大规模或时间敏感的临床工作流程中不实用。近年来，深度学习方法在医学图像分割任务中表现出卓越性能，特别是在卷积架构的应用中。为此，研究使用了nnU-Net框架，该框架是一种自动化、自我配置的深度学习分割架构，应用于2013年的左房分割挑战数据集，该数据集包含三十张带有专家标注掩码的心脏MRI扫描。", "innovation": "研究利用了nnU-Net框架使模型能够自动适应MRI数据的特性和学习路径。该模型在左房分割挑战数据集上实现了平均Dice得分为93.5，证明了与专家标注的高度重叠，并优于先前研究中报道的多种传统分割方法。该网络在左房形状、对比度和图像质量变化下的泛化能力强，能够准确勾勒出心房主体和近端肺静脉。", "conclusion": "提出的nnU-Net模型在左房分割中表现出色，能够高效、准确地分割心房结构，适用于大规模或时间敏感的临床应用场景。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04086", "html_url": "https://arxiv.org/abs/2511.04086", "title": "DeNoise：学习鲁棒的图表示以进行无监督图级异常检测", "title_en": "DeNoise: Learning Robust Graph Representations for Unsupervised Graph-Level Anomaly Detection", "authors": "Qingfeng Chen,Haojin Zeng,Jingyi Jie,Shichao Zhang,Debo Cheng", "background": "随着关键领域中图结构数据的迅速增长，无监督图级异常检测(UGAD)已成为一项关键任务。UGAD旨在识别与常规行为模式偏离的整个图。然而，大多数基于图神经网络(GNN)的方法隐含地假设训练集是干净的，仅包含正常图，而在实践中这通常并不成立。即使是少量异常图的污染也会影响训练得到的表示，并严重削弱性能。这一挑战促使我们提出了DeNoise，一个专为受污染的训练数据设计的鲁棒的UGAD框架。", "innovation": "DeNoise框架通过联合优化图级编码器、属性解码器和结构解码器，结合对抗目标学习抗噪嵌入。此外，DeNoise引入了一种编码器锚点对齐去噪机制，将正常图的高信息节点嵌入融合到所有图嵌入中，从而提高表示质量并抑制异常干扰。对比学习组件还压缩正常图的嵌入并向异常图排斥这些嵌入，在潜在空间中提升鲁棒性。", "conclusion": "在八个真实数据集上的广泛实验表明，DeNoise在不同噪音强度下都能够学习可靠的图级表示，并且在性能上显著优于当前最先进的UGAD基准方法。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04092", "html_url": "https://arxiv.org/abs/2511.04092", "title": "基于矩形标准矛盾的具有理论基础的自动定理生成器", "title_en": "An Automated Theorem Generator with Theoretical Foundation Based on Rectangular Standard Contradiction", "authors": "Yang Xu,Peiyao Liu,Shuwei Chen,Jun Liu", "background": "目前缺乏一个严谨的理论体系来系统地生成既非平凡又有逻辑正当性的定理。", "innovation": "本文提出了一种基于矩形标准矛盾的新颖自动定理生成理论和工具。首先定义并证明了一个新的逻辑结构，即矩形标准矛盾，并对该结构的两个核心属性进行了理论证明：一是矩形标准矛盾是标准矛盾（必然无法满足）；二是非冗余性（删除任何一个子句后，剩余的子句集变得可满足）。基于这两个属性，证明了将矩形标准矛盾分割为前提子集 $A$ 和其补集的否定 $\neg H$ 可以生成有效的定理 $A \rightarrow \neg H$，所有这样的定理都是逻辑等价的。", "conclusion": "通过设计有效的模板基于自动定理生成算法，并开发基于矩形标准矛盾的自动定理生成器，本研究使机器从验证者转变为发现者，为逻辑和人工智能的基础研究开辟了新途径。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04042", "html_url": "https://arxiv.org/abs/2511.04042", "title": "基于大型语言模型的灾害搜索救援中人机团队认知框架", "title_en": "An LLM-based Framework for Human-Swarm Teaming Cognition in Disaster Search and Rescue", "authors": "Kailun Ji(1),Xiaoyu Hu(1),Xinyu Zhang(1 and 2),Jun Chen(1 and 2) ((1) School of Electronics and Information, Northwestern Polytechnical University, Xi'an, China, (2) Chongqing Institute for Brain and Intelligence, Guangyang Bay Laboratory, Chongqing, China)", "background": "大规模灾难应急搜索和救援（SAR）任务经常面临复杂地形和通信中断的挑战。无人机（UAV）群能够在广域搜索和物资配送中发挥重要作用，但有效的协调需要大量的人工操作，这会显著增加人类操作者的认知负担。核心的人机协作瓶颈在于“意图到行动的鸿沟”，即在高压力和高强度环境下，将高层次的救援目标转化为低层次的无人机群指令存在高风险的转化过程。因此，为解决这一问题，本文提出了一种新颖的大型语言模型-条件随机字段（LLM-CRF）框架，利用大型语言模型来建模并增强人与无人机团队的合作认知。", "innovation": "该研究提出了一种大型语言模型-条件随机字段（LLM-CRF）系统，通过自然和多模态与设备的互动（如语音或图形注释）来捕捉操作者的意图，再利用大型语言模型作为认知引擎完成意图理解、层级任务分解和无人机群任务规划。这种闭环框架使得无人机群能够作为主动伙伴，在实时反馈中减少人工监控和控制的需要，从而极大提高了SAR任务的有效性。实验结果显示，与传统的命令和指令接口相比，基于大型语言模型的方法使任务完成时间降低了约64.2%，任务成功率提高了7%，同时显著降低了认知工作负担，NASA-TLX评分下降了42.9%。研究建立了一种大型语言模型能够促进高风险场景中更具直观性和有效性的团队合作潜力。", "conclusion": "该工作展示了大型语言模型在灾害搜索救援任务中增强人机团队合作的认知潜力，为未来应急响应任务中的人机协同提供了新的可能。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04069", "html_url": "https://arxiv.org/abs/2511.04069", "title": "儿科超声图像中的急性阑尾炎检测", "title_en": "Pediatric Appendicitis Detection from Ultrasound Images", "authors": "Fatemeh Hosseinabadi,Seyedhassan Sharifi", "background": "儿童急性阑尾炎是儿童急性腹痛最常见的原因之一，但其诊断仍具有挑战性，因为其症状与其他疾病相似，且超声图像质量差异较大。为了应对这一挑战，本研究开发并评估了一种基于预训练ResNet架构的深度学习模型，用于从儿科患者腹痛时的超声图像中自动化检测急性阑尾炎。研究使用了海德堡儿科阑尾炎数据集，该数据集包含来自德国海德堡儿科医院Hedwig患儿入院时的超声扫描、实验室数据和临床评分，每位受试者有1至15个覆盖右下腹部、阑尾、淋巴结及相关结构的超声视图。通过调整ResNet模型，使其能够区分急性阑尾炎与非急性阑尾炎病例。图像经过归一化、重置大小和增强预处理，提高了模型的泛化能力。将提出的ResNet模型应用于基于图像的分类任务，结果显示该模型总体准确率为93.44%，精确率为91.53%，召回率为89.8%，表现出强大的识别不同超声视图中急性阑尾炎的能力。该模型有效学习了区分性空间特征，克服了低对比度、斑点噪声和儿科成像中的解剖变异性的挑战。", "innovation": "本研究开发了基于预训练ResNet架构的深度学习模型，用于从儿科患者的超声图像中自动化检测急性阑尾炎。通过针对这方面的问题，提出了一个创新的方法，提高了诊断的准确性和可靠性，特别是在图像质量存在差异的情况下。", "conclusion": "提出的ResNet模型在超声图像中识别急性阑尾炎方面表现出了强大的性能，准确率、精确率和召回率均较高，有望提高儿科阑尾炎诊断的效率和准确性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04090", "html_url": "https://arxiv.org/abs/2511.04090", "title": "推进公平AI：评估用于拉丁美洲背景的LLMs的文化表达性", "title_en": "Advancing Equitable AI: Evaluating Cultural Expressiveness in LLMs for Latin American Contexts", "authors": "Brigitte A. Mora-Reyes,Jennifer A. Drewyor,Abel A. Reyes-Angulo", "background": "人工智能系统往往反映出经济发达国家的文化偏见，这导致了拉丁美洲等经济欠发达地区的语境被边缘化，这主要是由于数据集不平衡导致的偏差。本研究探讨了人工智能对不同拉丁美洲背景的表征，揭示了经济发达地区和欠发达地区之间的数据差异。研究还指出，英语在拉丁美洲其他语言（如西班牙语、葡萄牙语、克丘亚语和纳瓦特尔语）中的主导地位，使得这些地区的视角被西方视角所框定。", "innovation": "研究引入了一个根植于拉丁美洲历史和社会政治背景的文化敏感数据集，挑战了以欧洲为中心的模型。通过对六种语言模型进行评估，采用一种新的文化表达度量标准、统计测试和语言分析进行评估。研究结果表明，一些模型更好地捕捉了拉丁美洲的视角，而其他模型则在情感上存在显著偏差（p < 0.001）。通过使用该数据集对Mistral-7B进行微调，其文化表达度提高42.9%。研究强调了促进公平AI的努力，包括优先使用反映拉丁美洲历史、土著知识和多元语言的数据库，并提倡以社区为中心的方法来强化被边缘化的声音。", "conclusion": "本研究强调了促进公平AI的努力，包括使用反映拉丁美洲历史、土著知识和多元语言的数据库，并提倡以社区为中心的方法来强化被边缘化的声音。通过使用新的文化表达度量标准对拉丁美洲背景下的LLMs进行评估，改进了模型的文化敏感性，推进了公平的AI开发。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04114", "html_url": "https://arxiv.org/abs/2511.04114", "title": "基于AI驱动的入侵检测系统的自动化和可解释性服务拒绝分析", "title_en": "Automated and Explainable Denial of Service Analysis for AI-Driven Intrusion Detection Systems", "authors": "Paul Badu Yakubu,Lesther Santana,Mohamed Rahouti,Yufeng Xin,Abdellah Chehri,Mohammed Aledhari", "background": "随着分布式拒绝服务（DDoS）攻击的频率和复杂性不断增加，高效和可解释的检测方法变得至关重要。传统的检测系统在可扩展性和透明度方面常常遇到困难，影响了实时响应和对攻击向量的理解。需要一种自动化框架来检测和解释DDoS攻击，从而提高DDoS检测的准确性和透明度，提供可扩展的和可解释的网络安全解决方案。", "innovation": "本文提出了一个使用机器学习（ML）的自动化方法来检测和解释DDoS攻击。该方法利用了Tree-based Pipeline Optimization Tool (TPOT) 来自动化选择和优化ML模型和特征，减少了手动实验的需求。通过结合TPOT的自动化管道选择和SHapley Additive exPlanations (SHAP) 的解释性，该方法提高了DDoS检测的准确性和透明度。实验证明关键特征如反向包长度均值和前向包头部长度最小值对于检测DDoS攻击至关重要，从而提供了一种可扩展和可解释的网络安全解决方案。", "conclusion": "通过结合TPOT的自动化管道选择和SHAP的解释性，该方法显著提高了DDoS检测的准确性和透明度。实验结果表明，关键特征如反向包长度均值和前向包头部长度最小值在检测DDoS攻击中起到重要作用。这种方法提供了可扩展和可解释的网络安全解决方案。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04126", "html_url": "https://arxiv.org/abs/2511.04126", "title": "基于鹰眼系统的自动网球选手和球跟踪以及场地关键点检测", "title_en": "Automated Tennis Player and Ball Tracking with Court Keypoints Detection (Hawk Eye System)", "authors": "Venkata Manikanta Desu,Syed Fawaz Ali", "background": "该研究提出了一个完整的自动化网球比赛分析管道，该框架结合了多个深度学习模型，实现实时检测和追踪运动员和网球，同时识别场地关键点作为空间参考。实验结果显示，该系统在不同场地条件和比赛场景下表现出色，提供了详细的分析数据，包括运动员的运动模式、球的速度、击球的准确性以及运动员的反应时间。这些信息对教练、广播员和运动员都非常有用，可以帮助他们更好地理解比赛的动态。", "innovation": "该创新框架整合了YOLOv8进行运动员检测，针对网球建立的YOLOv5模型进行球跟踪，以及基于ResNet50的结构进行场地关键点检测。系统能够实时提供详细的分析数据，并生成标注视频和详细的性能指标，这是基于鹰眼系统的突破性进步，提高了比赛分析的效率和准确性。", "conclusion": "实验结果表明，该系统能够在多种条件下稳定运行，为教练、广播员和运动员提供详细的比赛动态和性能反馈。系统输出的标注视频和详细性能指标使参与者能够获得实际可操作的见解，以改进他们的技术和战术。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04103", "html_url": "https://arxiv.org/abs/2511.04103", "title": "限于列表的语言识别问题表征", "title_en": "A Characterization of List Language Identification in the Limit", "authors": "Moses Charikar,Chirag Pabbaraju,Ambuj Tewari", "background": "本研究探讨语言识别在极限条件下的问题，即给定目标语言的一系列范例，学习者需要输出目标语言猜测序列，使得之后的所有猜测都正确。Gödel的经典结果表明，对于基本上任何有趣的语言集合，语言识别在极限条件下是不可行的。Angluin后来给出了完成这项任务的语言集合的精确表征。基于近期在相关语言生成问题上的积极成果，本研究重新审视了经典语言识别问题，引入了在每个时间步骤生成k个猜测的能力，旨在确保之后每个时间步有一个猜测是正确的。", "innovation": "研究为在极限条件下能够生成k个列表的语言集合提供了精确表征，基于Angluin表征的递归版本（针对生成单个列表的语言识别）。进一步得出一个直观的表征：语言集合能够k列表识别当且仅当该集合可以分解为k个语言集合，每个都可以在极限条件下以列表大小为1的方式进行识别。还利用表征建立了在统计设置下语言集合的列表识别率，证明如果集合在极限下k列表识别，则可以在指数级速率下k列表识别，并且这是最佳可能的。另一方面，如果集合在极限下不k列表识别，则任何趋零速度都无法进行列表识别。", "conclusion": "研究表明，如果集合在极限下k列表识别，则可以在指数级速率下k列表识别，并且这是最佳可能的。如果集合在极限下不k列表识别，则任何趋零速度都无法进行列表识别。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04137", "html_url": "https://arxiv.org/abs/2511.04137", "title": "在推理时从在线视频中学习以提高计算机使用代理", "title_en": "Learning from Online Videos at Inference Time for Computer-Use Agents", "authors": "Yujian Liu,Ze Wang,Hao Chen,Ximeng Sun,Xiaodong Yu,Jialian Wu,Jiang Liu,Emad Barsoum,Zicheng Liu,Shiyu Chang", "background": "计算机使用代理能够操作计算机和自动执行繁琐的任务，但与人类用户相比，在完成需要特定领域程序知识的任务时仍存在差距。人类通过观看视频教程来填补这个差距：他们搜索、浏览并有选择地模仿当前子目标下匹配的简短片段。本文探讨了如何在执行时有效使计算机使用代理从在线视频中学习。", "innovation": "本文提出了一个框架，该框架在推理时检索和过滤教程视频，将其转换为结构化的示范轨迹，并在执行过程中动态选择轨迹作为上下文指南。特别地，利用视觉语言模型（VLM）推断UI操作，将视频分割成短的操作子序列，并为每个子序列分配文本目标。执行时，采用两阶段选择机制动态选择单个轨迹添加到上下文，关注对代理下一决策最有帮助的局部指导。", "conclusion": "实验表明，本文框架在两个广泛使用的基准上始终优于基线代理和仅使用文本教程或转录的变体。分析强调轨迹分割和选择、动作过滤和视觉信息的重要性，表明丰富的在线视频可以系统地提炼为可在推理时提高计算机使用代理的实际指导。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04128", "html_url": "https://arxiv.org/abs/2511.04128", "title": "DMSORT：适用于无人驾驶船舶平台的高效并行海事多目标跟踪架构", "title_en": "DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms", "authors": "Shengyu Tang,Zeyuan Lu,Jiazhi Dong,Changdong Yu,Xiaoyu Wang,Yaohui Lyu,Weihao Xia", "background": "通过稳健的多目标跟踪（MOT）准确感知海洋环境对于确保船舶航行安全和有效的海上监控至关重要。然而，复杂的海上环境往往会引起摄像机运动和随后的视觉退化，这对MOT提出了重大挑战。现有方法难以应对这些挑战，尤其是在处理海洋环境的复杂条件下，如遮挡、光线变化和运动模糊等因素.", "innovation": "本文提出了一种高效的双分支海事MOT方法（DMSORT）。该方法的核心在于一个并行跟踪器，该跟踪器包含一个包含目标检测和重识别（ReID）分支的模块，以及一个专门用于估计动态摄像机运动的分支。此外，该方法还采用了一种可逆柱状检测网络（RCDN）来利用多层次视觉特征进行稳健的目标检测，以及一种轻量级的基于Transformer的外观提取器（Li-TAE）来捕获全局上下文信息并生成稳健的外观特征。该方法通过构建投影变换并使用卡尔曼滤波器内的平台运动补偿，分离平台引起的和目标固有运动，从而稳定真实物体轨迹，增强了系统的鲁棒性。最后，通过聚类优化特征融合模块来有效结合运动和外观线索，以确保在噪声、遮挡和漂移条件下的身份一致性。", "conclusion": "在新加坡海事数据集上的广泛评估表明，DMSORT实现了最先进的性能。值得注意的是，DMSORT在保持高身份一致性和对抖动和遮挡的鲁棒性的同时，运行速度最快。代码可以在指定的GitHub仓库中获得。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04144", "html_url": "https://arxiv.org/abs/2511.04144", "title": "编程教育中的元认知支架：理解学生-AI互动及其设计启示", "title_en": "Scaffolding Metacognition in Programming Education: Understanding Student-AI Interactions and Design Implications", "authors": "Boxuan Ma,Huiyong Li,Gen Li,Li Chen,Cheng Tang,Yinjie Xie,Chenghao Gu,Atsushi Shimada,Shin'ichi Konomi", "background": "编程教育领域目前提供了诸如ChatGPT等生成型AI工具，这些工具为新手程序员提供了前所未有的即时、个性化的支持。尽管此举前景广阔，但这些工具对学生元认知过程的影响尚未得到充分探索。现有研究主要集中在正确性与可用性上，而对学生使用AI助手支持或替代关键元认知过程的方式关注不足。本研究通过元认知视角分析大学级别编程课程中的学生-AI互动，审视了超过10,000条对话日志，并辅以学生和教育者的调查，以了解提示和回应如何与元认知阶段和策略相匹配。", "innovation": "研究通过元认知视角分析学生与AI助手的互动，填补了这一领域的研究空白，为设计旨在促进而非取代元认知参与的AI编程助手提供了指导。研究结果为开发增强学生编程教育学习过程的教育AI工具提供了设计上的启示。", "conclusion": "研究综合分析多源数据，提炼出设计AI编程助手的原则，以支持而非取代学生的元认知参与。研究成果为提升编程教育中学生的认知过程提供了指导建议。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04183", "html_url": "https://arxiv.org/abs/2511.04183", "title": "基于多资源负载平衡的强化进化方法", "title_en": "A Reinforced Evolution-Based Approach to Multi-Resource Load Balancing", "authors": "Leszek Sliwko", "background": "文章针对一个特定的 d 资源系统优化问题，发现经典的进化机制由于严格可行函数的原因效果不佳。因此，作者提出了强化遗传算法的方法，对标准遗传算法进行了多项改进和适应，包括引入模拟生物随机遗传漂移的迁移操作。", "innovation": "创新点在于引入了强化遗传算法来解决经典遗传算法在该特定问题上效能不足的问题。这些改进包括：增强了标准遗传算法的操作，特别是加入了类似生物随机遗传漂移的迁移操作。", "conclusion": "通过引入这些改进措施，该方法成功提高了 d 资源系统优化问题的求解效率，特别是更好地处理了非常严格的可行性条件，在多资源负载平衡问题上展现了良好效果。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04179", "html_url": "https://arxiv.org/abs/2511.04179", "title": "使用大型语言模型解释软件漏洞", "title_en": "Explaining Software Vulnerabilities with Large Language Models", "authors": "Oshando Johnson,Alexandra Fomina,Ranjith Krishnamurthy,Vaibhav Chaudhari,Rohith Kumar Shanmuganathan,Eric Bodden", "background": "由于软件安全漏洞的普遍存在，促使公司采用静态应用程序安全测试（SAST）工具来检测漏洞。然而，这些工具通常存在可用性限制，因为它们泛用性的警告信息未能充分传达关键信息给开发者，导致对关键发现的误解或忽视。近年来，大型语言模型（LLMs）及其文本生成能力的发展，为解决SAST的解释难题提供了新方法。本文研究了将LLMs与SAST工具结合的混合方法，旨在增强SAST工具的解释性。", "innovation": "本文提出了一个名为SAFE的集成开发环境（IDE）插件，该插件利用GPT-4o解释由SAST工具检测到的安全漏洞的原因、影响和缓解策略。这种方法利用了大型语言模型的文本生成能力，旨在提高SAST工具的解释性，从而帮助初学者到中级开发者更好地理解并处理这些漏洞。", "conclusion": "用户的专家研究结果表明，SAFE生成的解释能够显著协助开发者理解和解决安全漏洞，从而提高SAST工具的整体可用性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04184", "html_url": "https://arxiv.org/abs/2511.04184", "title": "可信的LLM中介通信：LLM作为沟通中介(LAAC)框架在多个应用领域的信息准确性评估", "title_en": "Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity in LLM as a Communicator (LAAC) Framework in Multiple Application Domains", "authors": "Mohammed Musthafa Rafi,Adarsh Krishnamurthy,Aditya Balu", "background": "人工智能生成内容的增多，使得交流过程中出现了信息膨胀和压缩的循环，导致双方无法接触真实的内容。本文聚焦于如何通过LLM（大型语言模型）作为沟通中介（LAAC），改变这一现状，增强信息的准确性和可靠性。", "innovation": "本文提出了LAAC（LLM作为沟通中介）的概念，旨在让LLM作为智能沟通中介，通过结构化对话捕捉发送者意图，并在接收者与发送者之间促进真实的知识交流。与传统的信息膨胀和压缩过程不同，LAAC能够在学术论文、提案、专业邮件和跨平台内容生成等不同场景中促进真实沟通。", "conclusion": "通过多维度的实验评估，本研究发现LAAC在高风险沟通情境中的部署仍存在信任差距。未来需进一步解决这些信任问题，以确保LAAC能够可靠地应用于各类高级沟通场景。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04192", "html_url": "https://arxiv.org/abs/2511.04192", "title": "AStF：通过自适应统计融合器进行运动风格迁移", "title_en": "AStF: Motion Style Transfer via Adaptive Statistics Fusor", "authors": "Hanmo Chen,Chenghao Xu,Jiexi Yan,Cheng Deng", "background": "传统的图像风格迁移方法通过处理均值和方差有效实现风格转换，但类似的方法也应用于运动风格迁移。然而，由于图像和运动之间存在根本差异，依赖于均值和方差不足以完全捕捉到运动数据中的复杂动态模式和时空一致性属性。因此，研究中引入了偏度和峰度系数来分析运动风格。在此基础上，提出了一种新颖的自适应统计融合器（AStF），并结合了一个运动一致性正则化（MCR）判别器进行训练。", "innovation": "提出了一个新颖的自适应统计融合器（AStF），包括风格解耦模块（SDM）和高阶多重统计注意力（HOS-Attn）。通过与运动一致性正则化（MCR）判别器结合训练，AStF在运动风格转移上展示了优于现有技术的性能。", "conclusion": "实验结果表明，通过提供更全面的动态风格内在的空间时间统计模式模型，AStF在运动风格转移上的表现超越了现有技术。相关代码和模型在官方网站上提供下载。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04153", "html_url": "https://arxiv.org/abs/2511.04153", "title": "BAPPA：自动化文本到SQL生成的代理、计划和流水线基准测试", "title_en": "BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated Text-to-SQL Generation", "authors": "Fahim Ahmed,Md Mubtasim Ahasan,Jahir Sadik Monon,Muntasir Wahed,M Ashraful Amin,A K M Mahbubur Rahman,Amin Ahsan Ali", "background": "目前，文本到SQL系统为用户提供了一种自然语言接口，使即使不具备技术背景的用户也能访问数据库中存储的信息。然而，现有的大型语言模型（LLM）在从自然语言指令生成SQL时存在困难，主要是由于数据库模式的庞大以及复杂的推理需求。先前的研究大多集中在复杂的、不太实际的管道上，使用旗舰模型，而没有充分利用较小但高效的模型。特别是在SQL生成任务中，大模型的策略往往不能很好地应用于小模型。因此，研究者们探索了三种多代理LLM管道，以系统地评估不同规模的开源模型在SQL生成任务中的性能。这些方法包括多代理讨论管道、计划者-编码器管道和编码器-聚合者管道。通过在Bird-Bench Mini-Dev数据集上的实验，探讨了这些方法的提升效果。其中，多代理讨论管道对小型模型的提升尤为明显，尤其是在Qwen2.5-7b-Instruct模型上的执行准确性提高了10.6%。", "innovation": "本文研究了三种多代理LLM管道方法，分别是多代理讨论管道、计划者-编码器管道和编码器-聚合者管道，并在多种规模的开源模型上进行了系统性性能基准测试。这些方法相比于单一模型或复杂、不太实际的管道，为解决SQL生成问题提供了一种新的思路，特别是对于小模型性能的提升具有重要意义。", "conclusion": "在建筑工程实验中，多代理讨论管道和计划者-编码器管道显示出良好的性能，其中LLM计划者-编码器管道在两个较大的模型DeepSeek-R1-32B和QwQ-32B中，显著提升了Gemma 3 27B的IT准确率，从52.4%提升到了最高56.4%。而且，实验结果表明多代理讨论管道能够在提升小型模型性能方面发挥重要作用，为未来的文本到SQL生成研究提供了可参考的策略。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04157", "html_url": "https://arxiv.org/abs/2511.04157", "title": "我们对齐了吗？LLM与人类判断在负责任AI价值观上的初步研究", "title_en": "Are We Aligned? A Preliminary Investigation of the Alignment of Responsible AI Values between LLMs and Human Judgment", "authors": "Asma Yamani,Malak Baslyman,Moataz Ahmed", "background": "大型语言模型（LLMs）在软件工程任务中越来越受到关注，如需求分析、设计和评估。这引发了关于LLMs是否与负责任AI价值观的人类判断相一致的疑问。本研究旨在探讨LLMs的价值偏好与两组人类群体的相似性：美国代表样本和人工智能从业者。研究通过四个任务评估了23种不同的LLMs：(T1) 选择关键的负责任AI价值观；(T2) 评估特定情境中的重要性；(T3) 解决竞争价值观之间的权衡；(T4) 优先处理体现这些价值观的软件需求。结果显示，LLMs在价值偏好上更接近于人工智能从业者，强调公平、隐私、透明度、安全性和问责制。然而，在价值观设定与需求优先级之间存在不一致，反映了声明行为与实际行为之间的差距。这些发现强调了在缺乏人类监督的情况下依赖LLMs进行需求工程的实践风险，并突显了系统性的基准测试、解释和监测AI辅助软件开发中的价值观对齐的重要性。", "innovation": "本研究创新性地通过四个任务评估了多个不同的LLMs在负责任AI价值观上的偏好，并分析了这些偏好与具体任务表现之间的关系，同时首次比较了LLMs与美国代表样本和人工智能从业者之间的价值观差异。研究揭示了LLMs在价值观上的不一致性，强调了系统评估和监测价值观对齐的重要性。该研究为理解LLMs在AI辅助软件开发中的角色提供了新的视角。", "conclusion": "本研究揭示了LLMs与人工智能从业者相比，在价值观上更一致，特别是在公平、隐私、透明度、安全性和问责制方面。然而，研究也发现，LLMs在价值观设定与需求优先级上存在不一致，这反映了言行不一的问题。这表明在利用LLMs进行需求工程时，需要人类监督，同时也需系统化地进行价值观对齐的基准测试、解释和监测。这些研究结果突显了在AI辅助软件开发中确保价值观对齐的重要性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04217", "html_url": "https://arxiv.org/abs/2511.04217", "title": "多头注意机制中的强彩票假设", "title_en": "The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms", "authors": "Hikari Otsuka,Daiki Chijiwa,Yasuyuki Okoshi,Daichi Fujiki,Susumu Takeuchi,Masato Motomura", "background": "强彩票假设（SLTH）认为，在随机初始化的神经网络中隐藏着高性能的子网络，称为强彩票（SLTs）。尽管最近的理论研究已经在各种神经架构中建立了SLTH，但针对变压器架构的SLTH依旧缺乏理论理解。特别地，当前的SLTH理论尚未涵盖变压器的核心组件——多头注意（MHA）机制。", "innovation": "本文提出了MHA中SLTs存在的理论分析。证明了如果随机初始化的MHA具有隐藏维度为$O(d\text{log}(Hd^{3/2}))$的键和值，且拥有$H$个头和输入维度$d$，则其很可能包含一个可以近似任意具有相同输入维度的MHA的SLT。此外，通过利用MHA的理论，本文将SLTH推广到了不包含归一化层的变压器中。", "conclusion": "本文的理论发现得到了经验验证，表明源模型（MHA和变压器）中SLT与近似目标模型之间的近似误差可以通过增加源模型的隐藏维度呈指数级降低。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04237", "html_url": "https://arxiv.org/abs/2511.04237", "title": "去噪推荐模型中的协作信号解耦", "title_en": "Denoised Recommendation Model with Collaborative Signal Decoupling", "authors": "Zefeng Li,Ning Yang", "background": "尽管协同过滤（CF）算法在推荐系统中取得了显著的性能，但由于用户-项交互矩阵中的噪声，推荐效果仍然不理想。虽然许多去噪研究提高了推荐模型的性能，但现有的大多数方法仅在单一图上进行去噪。这可能会导致协作信号的衰减：移除两个节点之间的边可能会中断其他节点之间的路径，削弱依赖于路径的协作信息。为了弥补这些局限性，该研究提出了一种新的基于GNN的CF模型——DRCSD，用于去噪不稳定的交互。", "innovation": "DRCSD模型包含两个核心模块：协作信号解耦模块（通过结构性质将信号分解成不同的顺序）和顺序层去噪模块（在一顺序上进行目标去噪）。同时，传统的基于GNN的CF模型的信息聚合机制被修改，以避免在最终汇聚操作之前发生跨顺序信号干扰。实验结果表明，DRCSD对不稳定交互具有更好的稳健性，并在推荐准确度指标上显著优于最先进的基线模型。", "conclusion": "研究结果表明，DRCSD模型能够更好地抵御不稳定交互的影响，并在三个公开的真实世界数据集上的推荐准确性指标上取得了显著提升。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04239", "html_url": "https://arxiv.org/abs/2511.04239", "title": "seqme：一个用于评估生物序列设计的Python库", "title_en": "seqme: a Python library for evaluating biological sequence design", "authors": "Rasmus Møller-Larsen,Adam Izdebski,Jan Olszewski,Pankhil Gawade,Michal Kmicikiewicz,Wojciech Zarzecki,Ewa Szczurek", "background": "近年来，计算方法在设计生物序列方面取得了重大进展，推动了用于评估这些方法性能的度量标准的发展。这些度量标准可以衡量设计的序列与目标分布的忠实度以及它们实现所需属性的情况。然而，缺乏一个集成本地工具的软件库来实施这些度量标准是一个缺口，本研究旨在填补这一空白。", "innovation": "we introduce seqme, a modular and highly extendable open-source Python library, containing model-agnostic metrics for evaluating computational methods for biological sequence design. seqme的创新之处在于其为评估生物序列设计计算方法提供了一个模块化且高度可扩展的开源Python库，包含不依赖特定模型的度量标准。seqme包含三种类型的度量标准：基于序列、基于嵌入和基于属性，并可应用于广泛的生物序列：小分子、DNA、非编码RNA、mRNA、肽和蛋白质。此外，seqme还提供了生物序列的多种嵌入模型和属性模型，以及诊断和可视化功能以检查结果。", "conclusion": "seqme可以用于评估单次运行和迭代计算设计方法。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04171", "html_url": "https://arxiv.org/abs/2511.04171", "title": "系统性评估预处理技术在数字病理准确图像配准中的应用", "title_en": "Systematic Evaluation of Preprocessing Techniques for Accurate Image Registration in Digital Pathology", "authors": "Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz", "background": "图像配准是指通过将多个图像映射到共同坐标系统来重叠和对齐它们的过程，以便匹配图像中的解剖或组织结构。在数字病理学中，配准可以支持不同颜色染色或成像模态之间的直接对比和信息整合，应用于生物标志物分析和组织重建等。准确的图像配准是数字病理学中的一个关键步骤。为了研究不同色彩变换技术对H&E染色图像和非线性多模态图像配准结果的影响，该研究评估了多种预处理技术在数字病理学中的应用效果，使用了一个包含20个组织样本对的数据集进行测试，其中包括了不同的色彩变换技术（CycleGAN、Macenko、Reinhard、Vahadane）以及对图像的预处理步骤，如反转、对比度调整、强度归一化和去噪等。所有图像都使用了VALIS配准方法进行配准，该方法首先进行刚性配准，然后在低分辨率和高分辨率图像上分两步进行非刚性配准。为评估配准性能，使用了相对目标配准误差(rTRE)作为评估指标，计算了每种方法的中位数的中位rTRE值（MMrTRE）和中位rTRE值的平均值（AMrTRE）。该研究还采用了自定义的基于点的方法，使用了十个手动选择的关键点来进行评估。结果显示，使用CycleGAN色彩变换技术实现的配准错误最小，表明在配准前应用色彩变换技术可以改善不同模态图像之间的对齐，有助于更可靠的数字病理分析。", "innovation": "该研究表明，不同的色彩变换技术对不同模态图像的配准结果有显著影响。研究使用的不同色彩变换技术包括CycleGAN、Macenko、Reinhard和Vahadane等，并且这些技术与一系列预处理步骤相结合进行图像配准。研究结果表明，CycleGAN色彩变换技术在配准中表现出最高的准确性和一致性，这与其他预处理技术相比，显示出更低的配准误差。这一发现强调了色彩变换技术在提高不同模态图像配准准确性方面的重要性，并推动了数字病理学中这一领域的研究进展。", "conclusion": "这项研究表明，在图像预处理阶段应用色彩变换技术可以显著提高多模态图像配准的准确性。CycleGAN色彩变换技术在降低配准误差方面表现突出，从而为数字病理中的多模态图像配准提供了新的方法和思路。该研究还提出了一种新的评估指标——中位数的中位rTRE值（MMrTRE）和中位rTRE值的平均值（AMrTRE），这对于类似的研究具有参考价值。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04255", "html_url": "https://arxiv.org/abs/2511.04255", "title": "MedSapiens: 将姿态应用于重新思考医疗影像解剖标志检测", "title_en": "MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection", "authors": "Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li", "background": "传统上，解剖标志检测依赖于领域特定模型。然而，大规模预训练视觉模型的出现为解剖标志检测带来新的可能性。本文回顾并重新应用了为姿态估计设计的人本中心基础模型，通过多数据集预训练，以医疗成像领域的多个数据集达到了新的前沿。", "innovation": "本文引入了MedSapiens模型，通过多数据集预训练，将人本中心基础模型Sapiens应用于医疗成像领域的解剖标志检测，证明了这种模型在空间姿态定位方面的固有优势对于解剖标志检测的有效性，并在平均成功检测率（SDR）上相对于通用模型和专科模型分别提高了5.26%和21.81%。此外，MedSapiens在少量标注的新型下游任务中也表现出色，相比少量标注的前沿方法，在平均成功检测率上有2.69%的增益。", "conclusion": "MedSapiens模型通过多数据集预训练证明了人本中心基础模型在医疗成像领域的解剖标志检测中的强大潜力，相对于现有模型达到了显著的性能提升，并展示了其在新任务上的高适应性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04247", "html_url": "https://arxiv.org/abs/2511.04247", "title": "CLIP文本编码器的脆弱性", "title_en": "On the Brittleness of CLIP Text Encoders", "authors": "Allie Tran,Luca Rossetto", "background": "多模态共嵌模型，尤其是CLIP，近年来在零样本分类和多媒体信息检索中取得了最先进的成果，通过在共享表示空间中对齐图像和文本。然而，这些模型在对比对齐训练后，往往会对手动输入的小幅度扰动缺乏稳定性。特别是在处理手动表述的查询时，查询的细微变化会导致最佳匹配结果排名的巨大差异。", "innovation": "本文系统地分析了剪辑文本编码器在多媒体信息检索场景中对多种非语义查询扰动的反应效应。通过TRECVID Ad-Hoc Video Search查询和V3C1视频数据集评估了多种词法、语法和语义扰动对不同CLIP变体模型的影响。研究发现了在语法和语义扰动方面驱动了最大的不稳定性，而脆弱性集中在诸如标点符号和大小写这些浅表编辑上。", "conclusion": "研究结果表明，泛化能力是评估视觉-语言模型的重要维度，而不仅仅是在基准准确度方面。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04286", "html_url": "https://arxiv.org/abs/2511.04286", "title": "通过贝叶斯偏好推理实现高效的人工反馈强化学习", "title_en": "Efficient Reinforcement Learning from Human Feedback via Bayesian Preference Inference", "authors": "Matteo Cercola,Valeria Capretti,Simone Formentin", "background": "学习人类偏好是实现机器学习模型与主观人类判断一致性的关键。然而，收集此类偏好数据往往成本高且耗时，因此需要更高效的机器学习范式。两种现有的方法各有利弊：RLHF（基于强化学习的人工反馈调整）适合大规模任务，如语言模型微调，但PBO（偏好基于优化）通过主动查询提高了样本效率。", "innovation": "本文提出了一种结合了RLHF的扩展性与PBO的高效查询的混合框架。该框架通过将一个以获取驱动的模块集成到RLHF流程中，实现了积极和样本高效的偏好收集。该方法在两个领域进行了验证：(i) 高维度偏好优化和(ii) 语言模型微调。实验结果显示，该方法在样本效率和总体性能上具有显著改进。", "conclusion": "该研究的实验结果表明，通过引入贝叶斯偏好推理模块，实现了在高维度偏好优化和语言模型微调任务中，比单独使用RLHF或PBO更高的样本效率和更好性能。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04260", "html_url": "https://arxiv.org/abs/2511.04260", "title": "Proto-LeakNet：在合成人类面部图像中的信号泄漏感知归因", "title_en": "Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human Face Imagery", "authors": "Claudio Giusti,Luca Guarnera,Sebastiano Battiato", "background": "合成图像和深度假脸生成模型的日益复杂使源识别和真实性和验证成为现代计算机视觉系统的重大挑战。现有研究发现，这些生成管道在无意中在其输出中（尤其是潜在表示中）留下了持久的统计残留，称为信号泄漏。在这一观察结果的基础上，建议了一种名为Proto-LeakNet的信号泄漏感知和可解释的归因框架，该框架结合了封闭集分类与基于密度的开集评估，能够在无需重新训练的情况下对未见过的生成器进行分析。", "innovation": "Proto-LeakNet 在扩散模型的潜在域中重新模拟部分前向扩散，以揭示残留的特定生成器线索。通过时间注意力编码器聚合多步潜在特征，特征加权原型头控制嵌入空间结构并实现透明归因。该模型仅使用封闭的数据集训练，在宏 AUC 为 98.13% 的情况下学习了在后处理下保持稳健的潜在几何形状，超越了现有方法，并实现了已知和未见过生成器之间的良好分离。", "conclusion": "结果证明，信号泄漏偏差在潜在空间中的建模可以实现可靠的和可解释的AI图像和深度假脸取证。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04332", "html_url": "https://arxiv.org/abs/2511.04332", "title": "具有最近邻搜索的差分隐私在上下文学习", "title_en": "Differentially Private In-Context Learning with Nearest Neighbor Search", "authors": "Antti Koskela,Tejas Kulkarni,Laith Zumot", "background": "由于在上下文中学习固有的隐私风险，Differentially Private In-Context Learning (DP-ICL) 近年来成为研究热点。目前存在的方法大多忽略了现代大型语言模型（LLM）工作流中的关键组成部分——用于检索相关上下文数据的最近邻搜索.", "innovation": "本文引入了具有隐私意识的DP框架，将相关示例的最近邻搜寻集成到在上下文学习中。该方法在所有评估基准上都显著优于现有基线，实现了更优的隐私-效用权衡。通过结合来自上下文数据数据库的最近邻检索和隐私过滤器，跟踪已选样本的累积隐私成本，以保证遵守中央差分隐私预算.", "conclusion": "实验结果表明，该提出的DP-ICL方法在文本分类和文档问答上的优势明显超过现有基线方法。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04321", "html_url": "https://arxiv.org/abs/2511.04321", "title": "AIM: 高性能PIM架构级IR-压降综合软硬件协同设计", "title_en": "AIM: Software and Hardware Co-design for Architecture-level IR-drop Mitigation in High-performance PIM", "authors": "Yuanpeng Zhang,Xing Hu,Xi Chen,Zhihang Yuan,Cong Li,Jingchen Zhu,Zhao Wang,Chenguang Zhang,Xin Si,Wei Gao,Qiang Wu,Runsheng Wang,Guangyu Sun", "background": "PIM在高性能PIM实现中表现出卓越的计算密度、能效和计算精度。然而，性能的提升需要更复杂的电路设计和更高的操作频率，这加剧了IR-压降问题。严重的IR-压降会显著降低芯片性能，甚至威胁可靠性。传统的电路级IR-压降缓解方法，如后端优化，资源密集，通常会牺牲功耗、性能和面积（PPA）。", "innovation": "提出了一种全面的软件和硬件协同设计方法（AIM），以实现高性能PIM架构级IR-压降缓解。利用PIM的串行位处理和就地数据流特征，建立了PIM工作负载与IR-压降之间的直接关联。通过软件优化和硬件改进，能够深入研究架构级IR-压降缓解策略，同时保持计算准确性。提出了IR-增强器，这是一种动态调整机制，将软件级HR信息与硬件IR-压降监控结合，动态调整PIM宏的V-f对，从而提高能效和性能。此外，提出了HR意识的任务映射方法，实现软硬件设计的优化结合。", "conclusion": "后制版仿真结果表明，AIM在7nm 256-TOPS PIM芯片上实现了高达69.2%的IR-压降缓解，能效提高2.29倍，性能提高1.152倍。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04376", "html_url": "https://arxiv.org/abs/2511.04376", "title": "MusRec：利用修正流和扩散变换器的无提示文本到音乐编辑", "title_en": "MusRec: Zero-Shot Text-to-Music Editing via Rectified Flow and Diffusion Transformers", "authors": "Ali Boudaghi,Hadi Zare", "background": "音乐编辑已成为人工智能的一个重要且实用的领域，应用范围包括视频游戏和电影音乐制作，以及根据用户偏好个性化现有曲目。然而，现有的模型存在显著限制，如只能编辑由自己生成的合成音乐、需要非常精确的提示或需要针对具体任务重新训练，因此缺乏真正的零样本能力。", "innovation": "利用最近在修正流和扩散变换器方面的进展，我们引入了MusRec，这是首个能够在真实音乐上高效且有效地执行多样化编辑任务的无提示文本到音乐编辑模型。实验结果表明，我们的方法在保持音乐内容、结构一致性以及编辑保真度等方面优于现有方法，为在真实场景中实现可控音乐编辑奠定了坚实的基础。", "conclusion": "MusRec在保存音乐内容、结构一致性和编辑保真度方面表现优异，为实际场景中的可控音乐编辑提供了强大的基础，展示了其作为无提示文本到音乐编辑模型的有效性和优越性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04401", "html_url": "https://arxiv.org/abs/2511.04401", "title": "Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness", "title_en": "Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness", "authors": "Subeen Park,Joowang Kim,Hakyung Lee,Sunjae Yoo,Kyungwoo Song", "background": "深度学习模型在多个领域表现出色，但往往依赖于错误的相关性，使它们在分布变化时变得脆弱。尤其是在小众群体场景中，模型在未充分代表的群体中表现较差。尽管现有方法已经在缓解这一问题方面取得了进展，但它们的性能改进仍然有限，缺乏将嵌入空间表示与最差群体错误严格理论联系起来的框架。", "innovation": "本文提出了Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness (SCER)，这是一种新的方法，直接正则化特征表示以压制错误线索。本文通过理论证明，最差群体错误受到分类器依赖于错误方向与核心方向的程度的影响，通过在嵌入层施加理论约束，SCER鼓励模型关注核心特征，同时减少对错误模式的敏感性。", "conclusion": "通过在多个视觉和语言任务上的系统评估，结果显示SCER在最差群体准确性方面优于先前的最佳研究。我们的代码可以在[这个链接](this https URL)找到。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04422", "html_url": "https://arxiv.org/abs/2511.04422", "title": "关于回归与分类的等价性", "title_en": "On the Equivalence of Regression and Classification", "authors": "Jayadeva,Naman Dwivedi,Hari Krishnan,N.M. Anoop Krishnan", "background": "回归和分类之间的正式关联一直不牢固。即使在支持向量回归中使用了边缘最大化项 $\\|w\\|$，它们也仅被当作正则化器进行解释。该研究通过证明含有 $M$ 个样本处于超平面上的回归问题与含有 $2M$ 个样本的线性可分分类问题之间存在一对一的等价关系，来探讨这两种问题之间的联系。", "innovation": "该研究表明，通过最大化等价分类问题的边缘可得到不同于传统回归问题的回归公式。此外，这一等价性还被用于提出一种“可回归性”指标，用于估计回归数据集的难度，而无需先行训练模型。最后，利用等价性，可以训练神经网络来学习一个线性变换映射，将输入变量映射到一个可以使用线性回归的空间。", "conclusion": "研究通过回归与分类之间的等价性，不仅提出了新的回归形式，还提供了一种评估回归难度的方法，并展示了如何利用等价性来改善回归性能。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04304", "html_url": "https://arxiv.org/abs/2511.04304", "title": "基于Sentinel-1图像的离岸平台深度学习对象检测及其合成训练数据的影响", "title_en": "Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data", "authors": "Robin Spanier,Thorsten Hoeser,Claudia Kuenzer", "background": "近期和目前正在进行的海洋基础设施扩展，包括海上风电场、石油和天然气平台、人造岛屿和水产养殖设施，这凸显了有效监测系统的需求。现有的离岸基础设施检测模型依赖于全面且平衡的数据集，但在样本匮乏时，尤其是在未充分代表的对象类别、形状和大小方面，该模型表现欠佳。针对这一问题，研究团队利用2023年第四季度四个地区（里海、南海、几内亚湾和巴西海岸）的合成和实际Sentinel-1卫星图像，训练基于YOLOv10的深度学习对象检测模型，以提升模型性能，尤其关注合成训练数据对模型的影响。研究采用未参与模型训练的三个地区（墨西哥湾、北海、波斯湾）进行了外域验证，以评估地理转移能力。模型总共检测到了3,529个离岸平台，包括北海411个、墨西哥湾1,519个、波斯湾1,593个，最终实现了0.85的F1分数，且通过使用合成数据，这一分数提高到了0.90。研究还分析了合成数据如何改善不均衡类别的代表性并提升整体模型性能，这为进一步全球化离岸基础设施检测奠定了基础。研究表明，平衡数据集的构建和合成数据生成策略对于解决遥感中的常见挑战至关重要，这一研究展示了深度学习在可扩展、全球离岸基础设施监控中的潜力。", "innovation": "本研究通过使用合成训练数据与Sentinel-1卫星图像结合，训练YOLOv10模型，并在外区域对模型进行了验证，以提升离岸平台检测的准确性，尤其是在样本稀少的情况下。强调了合成数据在解决遥感中不平衡样本问题上的重要作用，并展示了这类研究对于提升全球离岸基础设施监测应用的技术潜力。", "conclusion": "本研究证明了使用综合训练数据和技术提升离岸基础设施检测系统的有效性，实现了从四个不同地区到三个未参与训练的地区的地理迁移性能，特别是在提高F1分数方面取得了显著效果。进一步研究将致力于完善这种综合方法，以实现全球范围内离岸设施的高效监测。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04333", "html_url": "https://arxiv.org/abs/2511.04333", "title": "LUME-DBN: 全贝叶斯学习不完整数据的DBN在重症护理中的应用", "title_en": "LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in Intensive Care", "authors": "Federico Pirola,Fabio Stella,Marco Grzegorczyk", "background": "动态贝叶斯网络（DBNs）在医疗保健中越来越受到重视，因其能够建模患者数据中的复杂时序关系并保持解释性，这对于临床决策至关重要。然而，现有的处理纵向临床数据缺失值的方法大多源于静态贝叶斯网络文献，未能充分考虑到数据的时间特性。这限制了在时间上量化不确定性的能力，特别是在重症监护等场景中尤为重要，因为理解时序动态对于提高模型可信度和在不同患者群体中应用至关重要。尽管DBNs具有潜力，但一个整合了缺失数据处理的完整贝叶斯框架仍处于发展中。", "innovation": "本文提出了一个基于吉布斯抽样的新方法来从不完整数据中学习DBNs。该方法将每个缺失值视为遵循高斯分布的未知参数。在每次迭代中，未观察值从其完整的条件分布中进行抽样，从而实现合理的填补和不确定性估计。与标准的模型无歧义技术（如MICE）相比，本文的贝叶斯方法在重构精度和收敛特性上表现出更优的结果。该结果强调了在时间模型中整合全贝叶斯推理的临床相关性，提供更可靠的填补和对模型行为更深入的见解。", "conclusion": "本文的方法支持更安全和明智的临床决策，特别是在经常存在且可能具有影响力的缺失数据中。所提出的LUME-DBN方法通过整合贝叶斯推理，提高了模型的可信度，提供了更多可靠的填充和模型行为的深入洞察，有助于临床决策支持系统的优化和发展。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04427", "html_url": "https://arxiv.org/abs/2511.04427", "title": "质量换速度？语言模型代理辅助对软件开发的影响", "title_en": "Speed at the Cost of Quality? The Impact of LLM Agent Assistance on Software Development", "authors": "Hao He,Courtney Miller,Shyam Agarwal,Christian Kästner,Bogdan Vasilescu", "background": "大规模语言模型（LLMs）已经在软件工程领域展现出了革命性的潜力，尤其是在软件开发中的应用方面，从业人员声称采用后显著提升了生产力。然而，缺乏实证证据支持这些声称。本文通过对比采用Cursor这一广泛流行的LLM代理助手的GitHub项目与未使用Cursor的类似项目，采用最新的差分方法研究了 Cursor 对项目级开发速度和软件质量的影响。研究发现，Cursor 的采用导致了项目级开发速度显著但短暂的增长，同时也出现了显著且持续的静态分析警告和代码复杂度增加。进一步的面板广义矩估计表明，静态分析警告和代码复杂度的增加是造成长期速度下降的主要因素。", "innovation": "本文通过引入最先进的差分方法，对比了使用Cursor的GitHub项目与未使用Cursor的类似项目，以实证研究Cursor对软件开发速度和质量的影响。这是对LLM代理助手对开发影响的首次全面分析，并揭示了其对长期速度影响的潜在机制。", "conclusion": "采用Cursor导致项目级开发速度显著但短暂地增加，同时伴随着静态分析警告和代码复杂度的持续增加，这些因素可能导致长期的速度下降。本文的发现对于软件开发从业人员、LLM代理设计师和研究人员具有重要影响。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04451", "html_url": "https://arxiv.org/abs/2511.04451", "title": "基于LSTM的无字典方法识别具有输入延迟的非线性系统的线性模型", "title_en": "Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear System with Input Delay", "authors": "Patrik Valábek,Marek Wadinger,Michal Kvasnica,Martin Klaučo", "background": "非线性动态系统存在输入延迟时，预测、估计和控制存在显著挑战，因为这些系统具有固有的复杂性，而延迟又影响系统行为。传统的线性控制技术在这种情况下常常失效，需要创新方法。", "innovation": "提出了一种新的方法，使用增强的Deep Koopman模型近似Koopman算子，使非线性系统具有时间延迟的线性表示。通过引入LSTM层，该框架捕捉了历史依赖性，有效将延迟系统的动态编码到潜在空间中。与依赖预定义字典的传统扩展动态模态分解(eDMD)方法不同，增强的Deep Koopman模型是无字典的，从而避免了已知动态被纳入字典的问题。", "conclusion": "与eDMD在模拟系统上的比较结果显示，该方法在未知真实非线性动态的情况下，预测精度有显著提高，并且与已知系统动态的eDMD方法取得相当的结果。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04465", "html_url": "https://arxiv.org/abs/2511.04465", "title": "订阅平台上的防欺诈收益分配", "title_en": "Fraud-Proof Revenue Division on Subscription Platforms", "authors": "Abheek Ghosh,Tzeh Yuan Neoh,Nicholas Teh,Giannis Tyrovolas", "background": "研究基于订阅的平台模型，用户支付固定费用以获得内容的无限访问权限，创作者从中获得收入份额。现有的欺诈检测方法主要依赖机器学习技术，与恶意行为者进行不断升级的对抗。该论文研究了内置激励机制以防止操纵的收益分配机制，如果前者的无效性难以检测，则研究提出了新的机制并进行了实验验证其有效性。", "innovation": "1. 提出了三个类型的防欺诈机制公理来判断已有规则是否有效。\n2. 指出一种广泛使用的流媒体平台机制不仅不能防范欺诈，还使得欺诈检测变得计算上不可行。\n3. 引入了一种新的规则‘ScaledUserProp’，它能够满足前述所有防欺诈公理。", "conclusion": "使用真实和合成的流媒体数据进行了实验，结果显示新的‘ScaledUserProp’机制比现有规则更为公平，同时具备更好的防欺诈能力。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04478", "html_url": "https://arxiv.org/abs/2511.04478", "title": "Generate, Evaluate, Iterate: Synthetic Data for Human-in-the-Loop Refinement of LLM Judges", "title_en": "Generate, Evaluate, Iterate: Synthetic Data for Human-in-the-Loop Refinement of LLM Judges", "authors": "Hyo Jin Do,Zahra Ashktorab,Jasmina Gajcin,Erik Miehling,Martín Santillán Cooper,Qian Pan,Elizabeth M. Daly,Werner Geyer", "background": "LLM-as-a-judge模型可以提供灵活且由用户定义的评价，但其效果往往受限于数据的多样性和代表性不足。这项研究分析了如何通过集成合成数据生成功能改善这一模型的评价过程。", "innovation": "研究提出了一种工具，该工具将合成数据生成功能整合到LLM-as-a-judge的工作流程中。该工具支持用户创建定制化的测试案例，可以配置领域、角色、长度和期望结果，包括边缘案例。此外，还支持AI辅助的现有测试案例即时编辑。工具还揭示了每个生成过程背后的提示和解释，以增强透明度和可解释性。", "conclusion": "一项用户研究表明，83%的参与者更倾向于使用该工具，因为它可以让他们迅速生成多样化的合成数据而无需额外的工作负担。生成的合成数据在改进评价标准和与人类偏好对齐方面与手工制作的数据同样有效。研究结果强调了合成数据作为一种在效率和可扩展性方面关键背景下有前景的替代方案的重要性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04437", "html_url": "https://arxiv.org/abs/2511.04437", "title": "深层Koopman经济模型预测控制在巴氏杀菌单元中的应用", "title_en": "Deep Koopman Economic Model Predictive Control of a Pasteurisation Unit", "authors": "Patrik Valábek,Michaela Horváthová,Martin Klaučo", "background": "本文提出了一种用于实验室规模巴氏杀菌单元（PU）高效运行的深层Koopman基于经济模型预测控制（EMPC）。该方法使用Koopman算子理论将复杂的非线性系统动力学转换为线性表示，使可以应用凸优化，并准确地表示复杂的PU。通过使用神经网络从实验数据学习线性动态，深层Koopman模型实现了与传统N4SID子空间识别方法相比45%的开环预测准确度提高。深度Koopman模型和N4SID模型都被应用于包含可解释的经济成本的EMPC公式中，如能源消耗、因不够充分的巴氏杀菌而导致的材料损失和执行器磨损。利用松弛变量确保了EMPC的可行性。该研究通过非线性多变量PU在外部干扰下的数值验证了深层Koopman EMPC和N4SID EMPC的有效性。这些扰动包括输送泵失效故障关闭场景和引入需巴氏杀菌的冷液。研究表明，与N4SID基线相比，深层Koopman EMPC可以降低32%的总经济成本，主要是由于降低了材料损失和能源消耗。此外，基于Koopman的稳态操作需要10.2%的电力能耗。该结果强调了将深层Koopman表示与经济优化集成用于实现资源高效控制热密集型工厂的重要性。", "innovation": "利用Koopman算子理论和神经网络构建深层Koopman模型，实现复杂非线性系统的线性表示，相比于传统的N4SID子空间识别方法，提高了开环预测的准确度。该方法将经济成本（如能源消耗和材料损失）纳入模型预测控制中，通过优化这些成本来改善系统的运行效率。应用松弛变量确保了EMPC的可行性，并通过数值验证展示了与传统方法相比的经济成本节约和能源效率提高。", "conclusion": "本文提出的深层Koopman基于EMPC方法，在实验室规模的巴氏杀菌单元中实现了高效的运行，通过优化经济成本（包括能源使用和材料损失）减少了32%的总经济成本，并且稳定操作的电力使用减少了10.2%，证明了将深层Koopman表示与经济优化集成可以有效提升资源效率，对于热密集型生产过程的控制具有重大意义。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04473", "html_url": "https://arxiv.org/abs/2511.04473", "title": "用于更好地训练和评估知识图谱增强的LLM的真实子图", "title_en": "Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge Graph Augmented LLMs", "authors": "Alberto Cattaneo,Carlo Luschi,Daniel Justus", "background": "从结构化的知识图谱中检索信息是提升大型语言模型（LLMs）事实性的有前途的方向。然而，现有的各种解决方案难以比较，因为缺乏具有真实目标的答案的挑战性问题回答数据集来评估图检索的效果。因此，本文提出了名为SynthKGQA的框架，用于从任何知识图谱生成高质量的合成Knowledge Graph Question Answering（KGQA）数据集，提供KG中所有的真实的事实信息，以便对每个问题进行推理。该数据集有助于更丰富的基准测试，同时通过SynthKGQA生成的数据还可以用于训练更好的模型。此外，该框架被应用于Wikidata生成了一个新的数据集GTSQA，设计用于测试KG检索器在面对未见过的图形结构和关系类型时的零样本泛化能力，并在流行的知识图谱增强的LLM解决方案上进行了基准测试。", "innovation": "提出了SynthKGQA框架，能从任何知识图谱生成高质量的合成KGQA数据集，包含所有真实的事实信息；能够生成数据集GTSQA，用于测试KG检索器的零样本泛化能力；并且通过生成的数据集在流行的知识图谱增强解决方案上进行了基准测试，评估其效果。", "conclusion": "SynthKGQA框架不仅提供了基准测试所需的真实数据集来提高KG检索器的性能，而且还能更好地训练模型并测试KG增强的LLMs的泛化能力。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04495", "html_url": "https://arxiv.org/abs/2511.04495", "title": "OUNLP在TSAR 2025共享任务中的表现：基于代码生成的多轮文本简化器", "title_en": "OUNLP at TSAR 2025 Shared Task: Multi-Round Text Simplifier via Code Generation", "authors": "Cuong Huynh,Jie Cao", "background": "本文描述了由Alva-Manchego等（2025年）撰写的OUNLP系统，用于TSAR-2025共享任务。该系统是基于LLM提示生成实现可读性控制文本简化的设计。本文基于提示基于文本简化方法的分析，发现了文本简化性能与源CEFR水平和目标CEFR水平之间的差距密切相关这一有趣发现。", "innovation": "本文提出了两种基于规则的简化方法：MRS-Rule（基于规则的多轮简化）和MRS-Joint（结合基于规则的LLM简化），并通过GPT-4o生成。这些方法的不同之处在于，MRS-Joint利用了LLM简化候选词作为起点，这种方法显示可以进一步提高多轮简化的性能。", "conclusion": "我们提交的系统在20个团队中排名第7。后续改进表明，将LLM简化候选词汇作为起点可以进一步提升多轮简化性能。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04491", "html_url": "https://arxiv.org/abs/2511.04491", "title": "RUST-BENCH: 测试语言模型在结构化表格中非结构化文本上的推理能力", "title_en": "RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables", "authors": "Nikhil Abhyankar,Purvi Chaurasia,Sanchit Kabra,Ananya Srivastava,Vivek Gupta,Chandan K. Reddy", "background": "现有的表格推理基准大多测试模型在小型、统一的表格上的表现，未能充分反映真实世界数据的复杂性，也未能全面展示大语言模型（LLMs）的推理能力。真正的表格通常较长、异构且领域特定，包含结构化字段和自由格式文本，需要在数千个标记中进行多跳推理。因此，需要开发一种能够涵盖规模、异构性、领域特定性和推理复杂性的新基准。", "innovation": "本文介绍了RUST-BENCH，一个包含7966个问题的基准数据集，覆盖2031张真实世界的表格，涉及两个领域：i) RB-Science（NSF资助记录表）；ii) RB-Sports（NBA统计数据）。RUST-BENCH对LLMs的评估是首次在规模、异构性、领域特定性和推理复杂性方面进行综合测试。实验表明，LLMs在处理异构模式和复杂多跳推理时存在困难，揭示了当前架构中的薄弱环节，并激发了改进策略。", "conclusion": "RUST-BENCH为推进表格推理研究建立了新的挑战性测试平台。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04499", "html_url": "https://arxiv.org/abs/2511.04499", "title": "在大型语言模型中解码大五人格特质：温度依赖表达与体系结构聚类", "title_en": "Decoding Emergent Big Five Traits in Large Language Models: Temperature-Dependent Expression and Architectural Clustering", "authors": "Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou", "background": "随着大型语言模型（LLMs）在以人为本的应用中变得越来越重要，理解和掌握它们类似人格的行为对于负责任的开发和部署变得越来越重要。本文系统地评估了六种不同的LLMs，使用大五人格问卷-2（BFI-2）框架，以评估在不同采样温度下的特质表达。我们发现，在五个性格维度中有四个显示出显著差异，情绪稳定性和外向性对温度的变化尤为敏感。进一步的层次聚类结果显示了不同模型的群集，表明架构特性可能使某些模型倾向于稳定的特质轮廓。这些研究结果提供了对于LLMs中人格倾向模式出现的新见解，并为模型调优、选择和人工智能系统的伦理治理提供了新视角。我们在这里分享了此分析的数据和代码：this https URL", "innovation": "本文首次使用大五人格问卷-2（BFI-2）框架系统地评估了六种不同的大型语言模型（LLMs），探索了不同采样温度下模型的特质表达，并通过层次聚类揭示出模型之间的结构性差异。这种研究方法为理解大型语言模型中的类似人格行为提供了一个新的视角，有助于模型的优化、选择及AI系统的伦理治理。", "conclusion": "这些结果提供了对于LLMs中人格倾向模式如何出现的新见解，并提供了模型调优、选择和伦理治理的新角度。此外，本文还共享了数据分析的原始数据和代码，以促进进一步的研究。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04527", "html_url": "https://arxiv.org/abs/2511.04527", "title": "语言模型是否意识到未选择的道路？token级别的不确定性和隐藏状态动态", "title_en": "Are language models aware of the road not taken? Token-level uncertainty and hidden state dynamics", "authors": "Amir Zur,Atticus Geiger,Ekdeep Singh Lubana,Eric Bigelow", "background": "语言模型在生成文本时，不同token的选择可能会导致不同的推理路径，这使得不确定性很难量化。本文研究了语言模型是否能够代表在生成过程中可以采取的不同推理路径。为了验证这一假设，研究者采用隐藏激活来控制和预测语言模型在链式推理中的不确定性。实验结果显示，模型在不同tokens上的不确定性与模型可被控制的程度之间存在明显相关性，表明当模型未完全确定最终答案时，激活干预最为有效。", "innovation": "通过利用隐藏激活，控制和预测语言模型在链式推理期间的不确定性，研究揭示了模型之间的动态关系与不确定性水平之间的相关性，进一步证明了模型对多种潜在路径的隐式表示。", "conclusion": "研究发现了隐藏激活与模型未来结果分布之间的联系，这表明语言模型确实隐式表示了可能路径的空间。此外，研究结果表明，激活干预效果最佳的时期是模型尚未决定其最终答案的关键阶段。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04485", "html_url": "https://arxiv.org/abs/2511.04485", "title": "Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training", "title_en": "Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training", "authors": "Ipsita Ghosh,Ethan Nguyen,Christian Kümmerle", "background": "基于低秩优化的参数高效训练已成为大规模深度学习模型微调的有效工具。然而，在低秩预训练任务中，保持低秩结构和目标最优化仍然是一个挑战。本文针对这一问题研究了低秩诱导训练策略，特别是介绍了一种新的方法——Quadratic Reweighted Rank Regularizer（Q3R），这种方法灵感来自于迭代加权最小二乘（IRLS）框架，并成功减少了训练过程中的复杂度，同时与现有架构兼容，并实现了与全连接模型相近的预测性能，即使在大量参数截断的情况下也能保持较高准确率。研究表明，Q3R在图像和自然语言任务的Transformer模型中都表现出色，特别是在低秩微调方面效果显著。", "innovation": "提出了一种新的低秩诱导训练策略——Quadratic Reweighted Rank Regularizer（Q3R），基于二次正则化项，通过最大化非线性光滑行列式函数来逼近秩目标。与现有低秩训练技术相比，Q3R能在保持较低参数量的情况下，实现与全连接模型相近的预测性能，具有较小的计算开销，并且兼容现有的网络架构。实验表明，这一方法在减少ViT-Tiny模型参数的同时，仅出现轻微准确率下降，且在Transformer模型上也取得了显著效果。", "conclusion": "Q3R通过提出一种基于二次正则化的新的低秩诱导训练框架，解决了低秩预训练中的挑战，使得参数截断后仍能保持较高的预测性能。该方法在多种任务中表现出色，特别是在维持模型低秩结构的同时降低了计算资源的需求。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04505", "html_url": "https://arxiv.org/abs/2511.04505", "title": "在刑事司法中的替代公平性和准确度优化", "title_en": "Alternative Fairness and Accuracy Optimization in Criminal Justice", "authors": "Shaolong Wu,James Blume,Geshi Yeung", "background": "算法公平性作为一个研究领域迅速发展，特别是在刑事司法领域，但核心概念仍存在争议。本文回顾了群体公平、个体公平和过程公平，并探讨了它们之间的冲突。接着提出了一种对标准群体公平的简单修改方法，通过最小化加权误差损失并保持不同保护群体的假阴性率在小范围内差异，使得解决方案更容易找到，可以提高预测准确性，并揭示了错误成本的伦理选择。研究针对偏见和不完整数据、潜在的隐性正向行动以及子群体约束的爆炸问题提出了批评意见。最后，提出了公共决策系统部署的实用框架，包括基于需求的决策、透明度和问责制、以及严格定制的定义和解决方案，将技术设计与合法性联系起来，并为使用风险评估及相关工具的机构提供切实可行的指导。", "innovation": "在标准群体公平基础上提出了一种简单的修改方法，通过最小化加权误差损失并保持假阴性率的差异在小范围内，使得解决方案更容易找到，可以提高预测准确性，并揭示了错误成本的伦理选择。这种创新还针对偏见和不完整数据、潜在的隐性正性行动以及子群体约束提出了批评意见，并提出了实用的部署框架。", "conclusion": "通过技术设计与合法性联系起来，为公共决策系统的部署提供了切实可行的指导，强调基于需求的决策、透明度和问责制、严格定制的定义和解决方案。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04502", "html_url": "https://arxiv.org/abs/2511.04502", "title": "RAGalyst: 自动化的人类对齐代理评估方法用于特定领域RAG", "title_en": "RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific RAG", "authors": "Joshua Gao,Quoc Huy Pham,Subin Varghese,Silwal Saurav,Vedhus Hoskere", "background": "RAG（检索增强生成）是将大型语言模型（LLMs）与事实证据相结合的关键技术，但现有评价框架多依赖于基于启发式的度量标准，无法捕捉特定领域的细微差异。现有的RAG系统评估工作通常缺乏与人类判断的有效对齐，或者采用LLM作为裁判的方法，这些方法未能验证与人类判断的一致性。因此，该研究提出了一种自动化、人类对齐的代理框架RAGalyst，专门用于评估特定领域的RAG系统。该框架采用代理管道生成高质量的合成问答（QA）数据集，并加入过滤步骤以确保数据准确性。此外，它还优化关键的LLM作为裁判指标（Answer Correctness和Answerability），通过提示优化使其与人类注释高度相关。", "innovation": "该研究提出的RAGalyst框架具有以下创新点：1) 该框架采用了自动化的代理管道生成高质量的合成QA数据集；2) 通过代理过滤步骤确保数据准确性；3) 使用提示优化改进了两个关键的LLM作为裁判指标（Answer Correctness和Answerability），使其与人类注释高度相关；4) 应用了该框架评估了不同RAG组件在军事操作、网络安全和桥梁工程三个不同领域的性能，揭示了性能的高度情境依赖性，强调了RAG系统在不同领域的设计需考虑特定的权衡。", "conclusion": "该研究发现，没有一种嵌入模型、LLM或超参数配置能在所有领域中普遍最优。RAGalyst框架揭示了这些领域中的问题根源，并强调了系统评估框架的必要性，从而帮助实践者发现特定领域的权衡，并做出明智的设计选择，以构建可靠和有效的RAG系统。RAGalyst框架已开源并在GitHub上可用。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04541", "html_url": "https://arxiv.org/abs/2511.04541", "title": "LLM-as-a-Judge: 针对排序推荐系统的世界模型", "title_en": "LLM-as-a-Judge: Toward World Models for Slate Recommendation Systems", "authors": "Baptiste Bonin,Maxime Heuillet,Audrey Durand", "background": "在推荐领域中，跨域用户偏好建模仍是一个关键挑战，特别是在推荐有序序列项目（即项目推荐列表）的研究中。本文探讨了如何通过大型语言模型（LLM）进行成对推理来有效建模用户偏好作为世界模型。研究在不同数据集上进行了多项实验，以评估LLM在排序推荐中的性能，并揭示了偏好函数属性与任务性能之间的关系，指出了提高推荐性能的潜在领域和LLM作为推荐系统世界模型的潜力。", "innovation": "本文创新性地提出了使用大型语言模型作为世界模型，通过成对推理的方式建模用户偏好。主要通过实验证明了LLM在排序推荐系统中作为世界模型的潜力和应用价值，具体展示了性能与偏好函数之间关系的分析，并提供了改进方向。", "conclusion": "研究结果表明，通过使用大型语言模型作为世界模型，可以在排序推荐系统中更好地理解用户偏好。该方法揭示了当前模型的性能差异，并提出了改进的潜力。未来的研究可以进一步探索如何优化模型以更好地捕捉用户偏好。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04638", "html_url": "https://arxiv.org/abs/2511.04638", "title": "神经网络因果干预导致表示发散的解决方法", "title_en": "Addressing divergent representations from causal interventions on neural networks", "authors": "Satchel Grant,Simon Jerome Han,Alexa Tartaglini,Christopher Potts", "background": "目前一种常见的机制可解释性方法是使用有目标的干预手段来操纵模型表示，以便理解这些表示所编码的含义。然而，我们未知的是一些常见的因果干预手段是否会将内部表示移离目标模型的自然分布，而这是否会影响到我们对这些表示的解释是否与模型自然状态相同。本研究首先通过实验证明了常见的因果干预技术确实会使内部表示移离自然分布，随后对这种移离进行了理论分析，最后提出了一种新的方法以减轻这种不良影响，确保解释的可靠性和准确性。", "innovation": "本文提出了一个新的方法——修改后的Counterfactual Latent (CL)损失来定期化干预保持更接近自然分布，从而减少了有害发散的可能性，同时保留了干预的解释能力。这是对现有机制可解释性方法的一个创新补充，保证了模型解释的一致性和准确性。", "conclusion": "本文揭示了如何通过干预手段更可靠地理解神经网络表示的一种途径，减轻了因干预导致的表示偏离问题，提高了解释的可靠性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04557", "html_url": "https://arxiv.org/abs/2511.04557", "title": "在图变换器中整合时空上下文进行关系深度学习", "title_en": "Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning", "authors": "Divyansha Lachi,Mahmoud Mohammadi,Joe Meyer,Vinam Arora,Tom Palczewski,Eva L. Dyer", "background": "在医疗保健、金融和电子商务等领域，关系数据的时序动态是由复杂交互产生的，如患者与提供者之间的交互，或不同类型用户与产品的交互。为了广泛适用，操作这些数据的模型必须跨国界地整合时空依赖性，同时支持多种预测任务。然而，现有的图模型主要侧重于空间结构，仅将时间信息作为排除未来事件的过滤约束，而不是建模信号，并且通常设计为单一任务预测.", "innovation": "提出了一种时序子图采样器，通过检索超出即时邻域的节点来增强全局上下文以捕捉时序相关关系。还提出了一种关系图感知器（RGP），这是一种利用基于交叉注意力的潜在瓶颈的图转换器架构，该架构能够有效整合结构和时序上下文中的信息。该潜在瓶颈能够将不同节点和边类型的信息整合到共同的潜在空间中，使模型能够在整个关系系统中建立全局上下文。RGP还整合了一个灵活的交叉注意力解码器，支持在单一模型中联合学习具有不同标签空间的任务.", "conclusion": "实验证明，RGP在RelBench、SALT和CTU等数据集上表现出最佳性能，提供了一种支持多种预测任务的通用和可扩展的关系深度学习解决方案."}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.12163", "html_url": "https://arxiv.org/abs/2406.12163", "title": "具有相等性的命题逻辑的讨论图语义及其在讨论和论证推理中的应用", "title_en": "Discussion Graph Semantics of First-Order Logic with Equality for Reasoning about Discussion and Argumentation", "authors": "Ryuta Arisaka", "background": "当前缺乏一个能够处理各种讨论和论证模型的形式推理框架，现有的方法对于讨论和论证推理的支持有限，因此需要新的方法来广泛建立这种推理能力。本文通过提出讨论图语义来解决这一问题，特别是在一阶逻辑（带有相等性）的背景下，这使得更广泛的讨论和论证推理成为可能。", "innovation": "本文的主要创新包括以下三点：1. 提出了讨论图语义，适用于一阶逻辑与相等性，使之能够更广泛地用于AI中的讨论和论证推理；2. 将Dung的拓展概念推广应用于论证框架中的等价图节点；3. 通过讨论图语义，证明推广后的拓展在一阶逻辑中具有可描述性，理绩效所有Dung的拓展在一阶逻辑中的可描述性也随之成为直接结果。", "conclusion": "本文通过对一阶逻辑（有相等性）的讨论图语义的研究，建立了更广泛的讨论和论证推理框架，并在理论上验证了其有效性，为未来类似研究提供了新的方向和工具。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.04671", "html_url": "https://arxiv.org/abs/2511.04671", "title": "X-Diffusion: 使用跨体态的人类示范训练扩散策略", "title_en": "X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations", "authors": "Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia", "background": "人类视频可以快速且大规模地录制，使它们成为机器人学习训练数据的理想来源。然而，人类和机器人在体态上存在根本差异，导致动作执行不匹配。直接将人类手部动作的运动转换给机器人会产生无法执行的动作。尽管存在这些低级别的差异，人类的示范提供了有关如何操作和与物体交互的重要运动提示。为了弥合这种差异，本文提出了一种新的策略，即将噪声添加到动作中，以减少低级差异同时保留高级任务引导。", "innovation": "本文提出了X-Diffusion，这是一种原理性的框架，用于训练利用人类数据而不学习动态不可行动作的扩散策略。X-Diffusion首先训练一个分类器来预测噪声动作是由人类还是机器人执行的。然后，在添加足够的噪声使得分类器无法辨识其体态后，只将人类动作纳入策略训练。符合机器人执行的动作在低噪声级别监督精细去噪，而不符合的执行则在高噪声级别仅提供粗略指导。实验表明，当执行差异存在时，简单的共同训练会降低策略性能，而X-Diffusion则始终提升性能。", "conclusion": "研究结果表明，X-Diffusion框架在五个操作任务中均实现了比最佳基线高16%的成功率。该项目的网站可参见：this https URL。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19442", "html_url": "https://arxiv.org/abs/2505.19442", "title": "Style2Code：基于双模对比表示学习的可控代码生成框架", "title_en": "Style2Code: A Style-Controllable Code Generation Framework with Dual-Modal Contrastive Representation Learning", "authors": "Dutao Zhang,Nicolas Rafael Arroyo Arias,YuLong He,Sergey Kovalchuk", "background": "可控代码生成，即在保持功能性的前提下生成符合指定风格的代码，仍然是一个具有挑战性的问题。现有方法难以在确保代码正确性的同时实现灵活的风格控制。", "innovation": "提出了一种结合对比学习和条件解码的两阶段训练框架，以实现灵活的风格控制。首先，该框架将代码风格表示与语义和结构特征对齐；其次，通过学习到的风格向量条件调优语言模型（如Flan-T5），指导代码生成。此外，该方法支持通过轻量级混合实现风格插值和个人定制，同时提高了风格控制能力而不牺牲代码正确性。这是首次将对比对齐与条件解码结合用于指导性代码生成的方法。", "conclusion": "本文提出的统一框架在不牺牲代码正确性的情况下，提供了改进的风格控制，为相反生成领域带来了新的解决方案。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.13406", "html_url": "https://arxiv.org/abs/2408.13406", "title": "多代理大型语言模型系统在有限元分析中的协作动态与可靠性挑战", "title_en": "Collaboration Dynamics and Reliability Challenges of Multi-Agent LLM Systems in Finite Element Analysis", "authors": "Chuan Tian,Yilei Zhang", "background": "多代理的大型语言模型（LLM）系统越来越多地应用于科学和工程中的自动化计算工作流。然而，代理间的动态交互如何影响推理质量和验证可靠性仍不清楚。本文使用AutoGen为基础的多代理框架来研究线性弹性有限元分析（FEA）中的这种机制，评估了四种任务下的七种角色配置，并在固定12轮对话限制下进行评价。", "innovation": "研究表明，协作的有效性依赖于功能互补性而非团队规模：三代理的角色配置（编码器-执行器-评审者）独产正确且视觉上的解决方案，而冗余评审者增加了失败率。此外，仍然存在三种系统性失败模式，包括：（1）反驳偏见；（2）由于冗余评审者引起过早共识；（3）验证-验证差距，其中可执行但物理上错误的代码未能被发现。本文基于功能多样性、角色分化和计算验证理论，提出了可操作的设计原则。", "conclusion": "本文建立了多代理LLM系统在工程流程中设计可信赖合作的指导原则，包括分配互补角色、多级验证和通过对抗性或触发机制防止过早共识。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.21882", "html_url": "https://arxiv.org/abs/2410.21882", "title": "基于脑启发情感共情机制构建富有同情心和道德的AI代理", "title_en": "Building Altruistic and Moral AI Agent with Brain-inspired Emotional Empathy Mechanisms", "authors": "Feifei Zhao,Hui Feng,Haibo Tong,Zhengqiang Han,Erliang Lin,Enmeng Lu,Yinqian Sun,Yi Zeng", "background": "随着人工智能与人类社会的紧密互动，确保其行为的安全性、利他性和与人类伦理和道德价值的一致性变得至关重要。现有研究中将伦理考量嵌入AI仍然不足，过去的外部约束基于原则和规则，不足以为AI提供长期稳定性和泛化能力。情感共情内驱力通过情感分享和感染机制激发旨在减轻他人负面情绪的利他行为。", "innovation": "本文借鉴人类情感共情驱动的利他决策神经机制，模拟共享自我-他我知觉-镜像-共情神经回路，构建了基于脑启发的情感共情驱动的利他决策模型。该模型通过情感共情直接影响多巴胺释放，形成内在的利他动机。此外，该研究在情感感染整合双智能体利他救援、多智能体游戏和机器人情感共情互动场景中，展示了模型的一致利他行为。深入分析验证了共情水平与利他偏好之间的正相关性，并展示了交互伙伴共情水平如何影响智能体的行为模式。该研究进一步测试了模型在涉及自我利益与他人福祉冲突的道德困境、部分可观测环境和对抗性防御场景中的性能和稳定性。", "conclusion": "这项工作初步探讨了类似人类的情感共情驱动的道德决策，为开发伦理对齐AI提供了潜在视角。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06991", "html_url": "https://arxiv.org/abs/2506.06991", "title": "无需地面真实性的LLM污染群众外包数据评估", "title_en": "Evaluating LLM-Contaminated Crowdsourcing Data Without Ground Truth", "authors": "Yichi Zhang,Jinlong Pang,Zhaowei Zhu,Yang Liu", "background": "生成式AI的成功凸显了高质量人类反馈在构建可信赖AI系统中的关键作用。然而，大规模语言模型（LLMs）通过群众外包工作者的广泛应用引发了重大挑战，即旨在反映人类输入的数据集可能受到LLM生成响应的影响。现有检测LLM的方法通常依赖于高维训练数据如文本，不适应用于标注任务如多项选择标记。本文探讨了利用同行预测机制——一种不使用地面真实信息来评估工作者响应中包含的信息的方法——以减轻LLM辅助作弊在群众外包中的影响，尤其是针对标注任务的情况。", "innovation": "本文提出了一种无需训练的评分机制，并在此基础上建立了针对包含LLM合谋的群众外包模型，该机制在理论上提供了保证。本文通过设立条件使方法有效，并通过在实际群众外包数据集上进行实验证明了其在检测低效率作弊方面的鲁棒性。", "conclusion": "本文方法在特定条件下有效，并通过实验证明了其检测群众外包数据集中的低效率作弊的鲁棒性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13956", "html_url": "https://arxiv.org/abs/2507.13956", "title": "跨模态因果干预在阿尔茨海默病预测中的应用", "title_en": "Cross-modal Causal Intervention for Alzheimer's Disease Prediction", "authors": "Yutao Jin,Haowen Xiao,Junyong Zhai,Yuxiao Li,Jielei Chu,Fengmao Lv,Yuxiao Li", "background": "轻度认知障碍（MCI）是阿尔茨海默病（AD）的前驱阶段，早期识别和干预可以有效地延缓向痴呆的进展。然而，由于多模态数据的选择偏差和变量间的复杂关系，阿尔茨海默病的诊断仍然是一项重大挑战。", "innovation": "提出了一种名为MediAD的新型视觉-语言因果干预框架，结合大型语言模型（LLMs）和影像学数据、临床数据，在统一的因果干预方法下隐式减轻可观察和不可观察的混杂因素的影响。", "conclusion": "实验结果表明，MediAD方法在区分认知正常、MCI和AD病例方面表现出色，大多数评估指标都超过了其他方法，展示了将因果推理解释与多模态学习结合用于神经疾病诊断的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.18560", "html_url": "https://arxiv.org/abs/2410.18560", "title": "‘让我们有分歧’：文本摘要解释性人工智能中的分歧问题研究", "title_en": "\"Let's Agree to Disagree\": Investigating the Disagreement Problem in Explainable AI for Text Summarization", "authors": "Seema Aswani,Sujala D. Shetty", "background": "解释性人工智能（XAI）方法在文本摘要中的应用对于理解模型行为和增加对模型生成摘要的信任至关重要。然而，近期研究指出了一个关键问题——‘分歧问题’。当不同的XAI方法对同一个模型结果给出互相冲突的解释时，这种分歧将影响解释的一致性并降低对模型解释的信任，这对安全和可问责的AI应用造成了负面影响。已有研究主要集中在理论分析上，本文是第一次通过实证研究来探讨文本摘要中的分歧问题，证明了在最先进的摘要模型中这种分歧普遍存在。", "innovation": "本文提出了一种新颖的基于区域的解释性人工智能（RXAI）方法，通过使用句子变换器和聚类对每篇文章进行分割成更小、更连贯的段落。通过对每个文本段落使用XAI方法来生成局部解释，从而减少不同XAI方法之间的分歧，提高AI生成摘要的信任度。实验结果表明，局部解释比全文解释更一致，且该方法在两个基准摘要数据集（Extreme summarization (Xsum)和CNN/Daily Mail）上的表现优于现有方法，分歧显著减少。此外，我们还开发了一个互动式的JavaScript可视化工具，以直观展示每个句子的注释得分，帮助用户更好地理解模型的解释。", "conclusion": "本文通过实证研究揭示了文本摘要中解释性AI的分歧问题，并提出了一种新的RXAI方法，通过局部解释降低了不同XAI方法之间的分歧，提高了模型解释的一致性和用户对模型的理解。该方法在两个基准数据集上的表现证明了其有效性，同时开发的可视化工具也增加了用户体验。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17697", "html_url": "https://arxiv.org/abs/2510.17697", "title": "多方强化学习中目标干预的原则", "title_en": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "authors": "Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang", "background": "在大规模多智能体强化学习（MARL）中，通过人类命令全局指导多个智能体是不实际的。现有机制如内在奖励和人类反馈的设计多依赖于经验研究，缺乏一个易于使用的研究工具。马尔可夫影响图（MAIDs）提供了一种图形框架来解决这些问题。", "innovation": "提出了多智能体影响图作为图形框架，引入了MARL交互模式的概念，并设计了一个仅作用于单一目标智能体的新型MARL交互模式——目标干预模式。引入了一种因果推理技术，称为预策略干预（PSI），通过最大化的因果效应实现目标干预。此外，MAIDs的组合相关性图分析工具可用于确定在特定MARL交互模式下MARL学习模式的有效性。", "conclusion": "通过预策略干预，在借助因果推理技术实现目标干预的同时，验证了相关性图分析的结果，证明了目标干预的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23807", "html_url": "https://arxiv.org/abs/2510.23807", "title": "面向临床约束的病理学基础模型", "title_en": "Toward Clinically Grounded Foundation Models in Pathology", "authors": "Hamid R. Tizhoosh", "background": "在非医疗领域，基础模型（FMs）通过大规模自我监督和多模态学习革新了计算机视觉和语言处理。因此，人们期望它们在计算病理学中的快速采用能带来在癌症诊断、预后和多模态检索方面的突破性进展。然而，最近的系统评估揭示了其根本性弱点，包括诊断准确性低、鲁棒性差、几何不稳定性、高计算需求和潜在的安全漏洞。", "innovation": "本文指出了当前病理基础模型在生物复杂性、自我监督效果不佳、过度泛化、架构过于复杂、缺乏特定领域的创新、数据不足以及与组织切片大小相关的根本设计缺陷等方面的七大原因。这些缺陷表明，现有的病理学基础模型在概念上仍与组织形态的性质不匹配，呼吁对现有范式进行根本性重新思考。", "conclusion": "当前的病理学基础模型与其所涉及的组织结构形态的本质相悖，需要重新思考其基础范式。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17108", "html_url": "https://arxiv.org/abs/2510.17108", "title": "结构化辩论在金融AI中的企业信用推理改进", "title_en": "Structured Debate Improves Corporate Credit Reasoning in Financial AI", "authors": "Yoonjin Lee,Munhee Kim,Hanbi Choi,Juhyeon Park,Seungho Lyoo,Woojin Park", "background": "尽管金融AI已取得了进展，但在企业信用评估中，基于证据的推理自动化尚未得到解决。在企业信贷评估中，非财务的定性指标对贷款偿还结果有决定性影响，但很难被形式化处理。现有方法主要关注数值预测，对专业贷款评估所需的解释判断支持有限。希望通过开发和评估两种基于大型语言模型的系统来解决这一问题，这两种系统能够从非财务证据中生成结构化的推理。", "innovation": "本研究开发并评估了两种基于大型语言模型的系统：一种是单代理系统(NAS)，能够通过单次推理管道生成双向分析；另一种是基于辩论的多代理系统(KPD-MADS)，通过基于卡尔·波普尔批判性对话框架的十步结构互动协议实现对抗性验证。这些系统在三个实际企业案例中得到应用，并由经验丰富的信贷风险专业人士进行了评估。对比人工专家报告，这两种系统都实现了显著的生产力增益，并且KPD-MADS在解释充分性、实用性和可用性方面表现更优，这表明结构化的多代理互动可以增强金融AI中的推理严谨性和解释性，推动企业信用评估中可扩展和可防御的自动化进程。", "conclusion": "研究结果表明，结构化多代理互动可以增强金融AI中的推理严谨性和解释性，从而推动企业信用评估中的可扩展和可防御自动化进程。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18751", "html_url": "https://arxiv.org/abs/2510.18751", "title": "Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation", "title_en": "Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation", "authors": "Patterson Hsieh,Jerry Yeh,Mao-Chi He,Wen-Han Hsieh,Elvis Hsieh", "background": "气候变化加剧了有害藻华（HAB）特别是蓝藻的出现，对水生生态系统和人类健康构成了威胁。传统的人工水样监测方法耗时且在时空覆盖方面有限。近年来，基于图像语言模型（VLMs）的遥感技术预示了大规模AI驱动解决方案的潜力，但仍存在通过图像推理和量化藻华严重程度的挑战。", "innovation": "本文提出了一种结合遥感图像理解和严重程度估计的藻华监测系统ALGae Observation and Segmentation (ALGOS)。该系统利用GeoSAM辅助的人类评估进行高质分割掩码的审查，并使用NASA提供的蓝藻集合手动标签（CAML）对语言模型进行微调。实验表明，ALGOS在分割和严重程度估计方面都表现出稳健的性能，朝着实用的和自动化的蓝藻监测系统迈出了重要一步。", "conclusion": "该研究为实用和自动化的蓝藻监测系统铺平了道路，通过结合遥感图像理解和严重程度估计，有效克服了传统监测方法的局限性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03179", "html_url": "https://arxiv.org/abs/2511.03179", "title": "迈向自主工程设计：一种知识导向的多智能体框架", "title_en": "Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework", "authors": "Varun Kumar,George Em Karniadakis", "background": "工程设计过程往往需要跨领域的专业知识，导致复杂的合作和迭代的改进。传统方法资源密集且容易产生低效率问题。", "innovation": "提出了一种多智能体AI框架，通过集成结构化设计和审查循环，利用知识驱动的智能代理来进行合作设计和改进。该框架通过构建特定领域的知识图谱，利用计算工具来满足设计要求，并形成迭代的反馈循环，直至设计得到验证，最终优化设计以最大化性能指标。", "conclusion": "这项工作证明了具有结构化知识表示的协作智能代理可以提高工程设计过程中的效率、一致性和质量。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.02818", "html_url": "https://arxiv.org/abs/2511.02818", "title": "Orion-MSP：面向表征上下文学习的多尺度稀疏注意力", "title_en": "Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning", "authors": "Mohamed Bouadi,Pratinav Seth,Aditya Tanna,Vinay Kumar Sankarapu", "background": "表格数据仍然是现实世界应用中占主导地位的数据格式。然而，由于特征类型各异和在多个尺度上复杂交互的存在，开发有效的神经模型来处理表格数据仍然极具挑战性。最近，在上下文中的表格学习（ICL）方面的进展，如TabPFN和TabICL，已经实现了与梯度增强树（GBTs）相当的性能，而不需要特定任务的微调。然而，当前的架构仍存在几个关键限制：单一尺度的特征处理忽略了层次关系、密集的注意力导致计算量随表格宽度呈二次增长，且严格的顺序组件处理阻止了迭代表示优化和跨组件通信。", "innovation": "Orion-MSP架构提出三项关键创新：(1) 多尺度处理以捕获层次特征互动；(2) 块稀疏注意力结合窗口、全局和随机模式，在保持高效性和远距离连接的同时实现可扩展性；(3) 类Perceiver的记忆机制，实现组件间的安全双向信息流动。", "conclusion": "就在不同基准测试中，Orion-MSP能够匹配或超越最先进的性能，同时能够有效扩展到高维表格，确立了高效表征上下文学习的新标准。该模型已在公开网址：this https URL 提供。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.02827", "html_url": "https://arxiv.org/abs/2406.02827", "title": "Stochastic Diffusion: 一种用于随机时间序列预测的扩散概率模型", "title_en": "Stochastic Diffusion: A Diffusion Probabilistic Model for Stochastic Time Series Forecasting", "authors": "Yuansan Liu,Sudanthi Wijewickrema,Dongting Hu,Christofer Bester,Stephen O'Leary,James Bailey", "background": "最近在扩散概率模型方面的创新为图像、文本和音频生成带来了重要进展，使其在生成时间序列预测中得到应用。然而，如何利用这些能力来建模高度随机的时间序列数据仍是一个挑战。", "innovation": "本文提出了一个名为StochDiff的新模型，它通过利用随机潜空间的表示能力来学习每个时间步的数据驱动先验知识，以建模多变量时间序列数据的变异性。这些学到的先验知识有助于模型捕捉复杂的时序动态和数据固有的不确定性，从而提高了其建模高度随机时间序列数据的能力。", "conclusion": "通过在实际数据集上的广泛实验，我们展示了所提模型在随机时间序列预测中的有效性。此外，我们还展示了该模型在实际手术导航中的应用，突显了其对医疗社区的潜在益处。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.17467", "html_url": "https://arxiv.org/abs/2403.17467", "title": "Unified Kernel for Neural Network Learning", "title_en": "A Unified Kernel for Neural Network Learning", "authors": "Shao-Qun Zhang,Zong-Yi Chen,Yong-Ming Tian,Xun Lu", "background": "过去的几十年中，人们广泛研究了神经网络学习与核学习之间的区别和联系。近期，理论上的进展使得无限宽的神经网络与高斯过程之间的连接变得更加明确。出现了两种主要的方法：神经网络高斯过程（NNGP）和神经梯度张量核（NTK）。前者基于贝叶斯推断，表示零阶核；后者基于梯度下降的切空间，表示一阶核。本文研究了这些方法并提出了统一核（UNK），该核由生成变量的内积诱导，用于描述带有梯度下降和参数初始化的神经网络的学习动态。", "innovation": "本文提出了统一核（UNK），该核结合了NNGP和NTK的优点，既在有限的学习步骤下表现出NTK的行为，在无限学习步骤下则接近于NNGP。此外，本文还理论分析了UNK核的统一紧性和学习收敛性，提供了对这种统一核的全面理解。", "conclusion": "实验结果表明了所提出方法的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26374", "html_url": "https://arxiv.org/abs/2510.26374", "title": "BOTS：LLM强化微调中的贝叶斯在线任务选择统一框架", "title_en": "BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning", "authors": "Qianli Shen,Daoyuan Chen,Yilun Huang,Zhenqing Ling,Yaliang Li,Bolin Ding,Jingren Zhou", "background": "强化微调（RFT）是使大型语言模型（LLMs）与人类偏好对齐并增强推理的关键技术，然而其效果高度依赖于训练过程中探索的任务类型。均匀抽样任务效率低下，会因为任务过于简单或不可解而浪费计算资源，而现有任务选择方法通常面临高昂的展开成本、适应性差或证据不完整的问题。", "innovation": "提出了一种统一的贝叶斯在线任务选择框架BOTS（BOTS），以解决LLM强化微调中的任务选择问题。BOTS基于贝叶斯推理，在模型进化时自适应地维护任务难度的后验估计。它结合了从选定任务直接评估中获得的显式证据和从这些评估中推断出的未选任务的隐式证据，并使用泰勒斯采样确保探索和利用之间平衡。为了实用化隐式证据，通过超轻量级插件实现，这种插件可以通过插值估计未评估任务的难度，而无额外展开成本。在多样化领域和不同规模的LLM上进行的实验表明，BOTS在数据效率和性能上都优于基础模型和对比实验，提供了一种实用且可扩展的动态任务选择解决方案。", "conclusion": "BOTS为LLM强化微调中的动态任务选择提供了一种实用和扩展性良好的解决方案，通过自适应地维护任务难度的后验估计并结合显式和隐式证据，同时利用泰勒斯采样确保精确的探索与利用平衡。通过超轻量插件将隐式证据实用化，大大降低了额外展开成本的影响。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03092", "html_url": "https://arxiv.org/abs/2511.03092", "title": "SnapStream：数据流加速器上高效长序列解码", "title_en": "SnapStream: Efficient Long Sequence Decoding on Dataflow Accelerators", "authors": "Jonathan Li,Nasim Farahini,Evgenii Iuliugin,Magnus Vesterlund,Christian Haggstrom,Guangtao Wang,Shubhangi Upasani,Ayush Sachdeva,Rui Li,Faline Fu,Chen Wu,Ayesha Siddiqua,John Long,Tuowen Zhao,Matheen Musaddiq,Hakan Zeffer,Yun Du,Mingran Wang,Qinghua Li,Bo Li,Urmish Thakker,Raghu Prabhakar", "background": "随着参数超过100亿的大规模语言模型（LLMs）的发展，这些模型支持超过100,000字长的上下文，对芯片内内存的需求也越来越大，以支持大型KV缓存。现有的技术如StreamingLLM和SnapKV能有效地控制KV缓存的大小并维持模型的准确性，但是这些技术在基于vLLM或SGLang的工业部署中并未得到广泛应用。阻碍这些技术在这些框架中应用的原因有两个：一方面，这些框架使用静态图和连续批次处理方法，使得对标准多头注意力算法进行修改变得困难；另一方面，这些技术在现代指令遵循和推理模型上的准确度影响不够明确，因此实施这些技术的需求不够清晰。", "innovation": "本文研究了这些技术对LLama-3.1-8B-Instruct和DeepSeek-R1模型的准确度影响，并开发了SnapStream，一种KV缓存压缩方法，可以在大规模应用中部署。实验证明，在SambaNova SN40L加速器上进行16路张量并行部署时，SnapStream可以将芯片内的内存使用量提高4倍，并在LongBench-v2、AIME24和LiveCodeBench测试中的准确度下降极小。这是首次将稀疏KV注意力技术部署在具有静态图和连续批次处理的生产推理系统中。", "conclusion": "SnapStream能够在不显著影响准确度的情况下有效增加内存使用效率，为其在工业部署中的应用提供了可能。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.17737", "html_url": "https://arxiv.org/abs/2406.17737", "title": "LLM目标性能欠佳对弱势用户不成比例地产生影响", "title_en": "LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users", "authors": "Elinor Poole-Dayan,Deb Roy,Jad Kabbara", "background": "虽然最先进的大型语言模型（LLM）在许多任务上表现出色，但关于模型的不可靠行为，如幻觉和偏见的研究也相当广泛。本文研究了用户特质（英语水平、教育水平和原籍国）对LLM响应质量的影响，包括信息准确性、真实性及拒绝回答等方面的差异。", "innovation": "本研究通过大量的实验针对三个最先进大型语言模型和两种关注真实性和事实性的数据集进行研究，发现对于英语水平较低、教育水平较低以及原籍国不在美国的用户，这些模型表现出了不成比例的不可靠行为，这意味着这些模型对他们的最弱势用户来说不可靠。", "conclusion": "研究指出，最先进的大型语言模型表现出的不可靠行为在弱势用户中更为明显，这使得这些模型在为弱势用户提供信息时存在可靠性问题。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.12264", "html_url": "https://arxiv.org/abs/2406.12264", "title": "投影方法在算子学习和通用逼近中的应用", "title_en": "Projection Methods for Operator Learning and Universal Approximation", "authors": "Emanuele Zappala", "background": "该研究基于Leray-Schauder映射，获得了一个新的连续（可能存在非线性）算子在任意Banach空间中的普遍逼近定理。进一步，该研究使用多项式基上的正交投影方法在函数的 Banach 空间 $L^p$ 中提出了一个算子学习方法。通过对多变量函数的算子学习，该研究得出了在某些额外假设下，学习线性投影和有限维映射的通用逼近结果。对于 $p=2$ 的情况，研究给出了确保逼近结果的充分条件。这些理论为算子学习领域的深度学习方法奠定了基础理论框架。", "innovation": "使用Leray-Schauder映射证明了新的连续算子在任意Banach空间中的普遍逼近定理。基于多项式基的正交投影方法提供了一种学习 Banach 空间 $L^p$ 中函数算子的新方法，并根据额外假设研究了学习线性投影和有限维映射的通用逼近结果。特别地，为 $p=2$ 情况提供了充足的逼近结果条件。这些研究为算子学习和深度学习方法提供了重要的理论支持。", "conclusion": "本文构建了算子学习的理论框架，特别是对于多变量函数的算子学习。证明了在某些条件下存在通用逼近结果，并针对 $p=2$ 提供了具体的逼近条件。研究为算子学习领域以及深度学习方法的发展提供了新的见解和技术基础。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.05500", "html_url": "https://arxiv.org/abs/2410.05500", "title": "增强深度学习的残差柯尔莫哥罗夫-阿诺尔德网络", "title_en": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning", "authors": "Ray Congrui Yu,Sherry Wu,Jiang Gui", "background": "尽管深度卷积神经网络（CNNs）取得了巨大的成功，但优化和训练它们仍然具有挑战性，特别是在网络深度内包含数百层的情况下。传统的卷积操作因其线性特性和固定的激活函数受到限制，这需要许多层来学习数据中的有意义模式。由于网络规模庞大，这种方法在计算上效率低下，并且在小数据集上存在过拟合或梯度爆炸的风险。因此，提出了一种称为残差柯尔莫哥罗夫-阿诺尔德网络（RKAN）的“插件”模块。", "innovation": "该模块高度紧凑，可以在传统深度网络的任何阶段轻松添加，它学习对外部卷积框架进行支持性的多项式特征转换。实验证明，RKAN在多种视觉任务和广泛测试的基准上都能提供基线模型的一致改进，实现了卓越的性能。", "conclusion": "本文介绍了一种残差柯尔莫哥罗夫-阿诺尔德网络（RKAN），该模块可以轻松集成到任何传统深度网络的阶段，通过学习支持性的多项式特征转换，RKAN在不同的视觉任务和广泛测试的基准上实现了基线模型的一致改进，取得了前沿的性能。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.19964", "html_url": "https://arxiv.org/abs/2410.19964", "title": "理解Adam需要更好的旋转依赖假设", "title_en": "Understanding Adam Requires Better Rotation Dependent Assumptions", "authors": "Tianyue H. Zhang,Lucas Maes,Alan Milligan,Alexia Jolicoeur-Martineau,Ioannis Mitliagkas,Damien Scieur,Simon Lacoste-Julien,Charles Guille-Escuret", "background": "尽管Adam在实际应用中被广泛使用，但其相对于Stochastic Gradient Descent (SGD)的优势缺乏全面的理论解释。研究发现，Adam在训练Transformer时，在参数空间随机旋转的情况下性能会下降，揭示了其对选择基底的敏感性。这表明传统的旋转不变假设不足以解释Adam的优势。", "innovation": "研究发现Adam对参数空间的随机旋转表现出更高的敏感性，需要更好的旋转依赖假设来更好地解释其性质。研究中还识别出了能够保留甚至增强Adam经验性能的结构化旋转，并验证了更新方向的正交性作为衡量basis敏感性的关键指标。", "conclusion": "研究揭示了常规的旋转不变假设不足以解释Adam的性能，强调了需要开发新的旋转依赖假设来更好地理解Adam的使用优势，并指出更新方向的正交性是关键指标。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.07055", "html_url": "https://arxiv.org/abs/2409.07055", "title": "法律事实预测：法律判决预测的关键环节", "title_en": "Legal Fact Prediction: The Missing Piece in Legal Judgment Prediction", "authors": "Junkai Liu,Yujie Tong,Hui Huang,Bowen Zheng,Yiran Hu,Peicheng Wu,Chuan Xiao,Makoto Onizuka,Muyun Yang,Shuyuan Zheng", "background": "法律判决预测（LJP）使当事人及其律师能够预测判决结果并优化诉讼策略，已成为关键的法律NLP任务。现有研究通常依赖已通过证据确立并由法官确认的法律事实来预测判决。然而，在诉讼早期阶段，法律事实往往难以获得，极大地限制了基于事实的LJP的应用。因此，提出了一种新的法律NLP任务：法律事实预测（LFP），它以当事人试用提交的证据作为输入，预测未验证的法律事实，从而让基于事实的LJP技术在缺乏真实法律事实的情况下也能进行预测。还首次构建了用于评估LFP任务的基准数据集LFPBench。实验结果表明，LFP增强了LJP的有效性，并为LFP研究指明了前景广阔的理论方向。", "innovation": "提出了一个全新的法律NLP任务：法律事实预测（LFP），它以当事人提交的证据作为输入，预测未验证的法律事实。首次构建了用于评估LFP任务的基准数据集LFPBench，证明了LFP能够增强法律判决预测的有效性并为未来研究提供了方向。", "conclusion": "实验结果表明，通过法律事实预测（LFP）赋能的法律判决预测（LJP）是有效的，并且为法律事实预测（LFP）未来的研究指明了方向，展示了具体的应用前景。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.23558", "html_url": "https://arxiv.org/abs/2410.23558", "title": "具有转移性和隐蔽性的集成攻击：大规模语言模型的黑盒逃狱框架", "title_en": "Transferable & Stealthy Ensemble Attacks: A Black-Box Jailbreaking Framework for Large Language Models", "authors": "Yiqi Yang,Hongye Fu", "background": "研究背景基于先前关于逃狱（jailbreaking）研究和实践的三个关键洞察：集成方法比单一方法更有效地揭示对齐的大规模语言模型（LLM）漏洞，恶意指令在逃狱难度上各不相同，需要个性化的优化，破坏恶意提示的语义连贯性可以操纵其嵌入，提高成功概率。", "innovation": "创新点在于提出了一种新型的黑盒逃狱框架，该框架集成了多种LLM-as-Attacker策略，能实现高度可转移性和有效攻击。该框架通过采用集合理论，针对不同难度的恶意指令进行定制化的优化，并利用扰动恶意提示的语义连贯性来提升成功概率，展示了强大的攻击能力和适应性。", "conclusion": "该解决方案在2024年LLM和代理安全竞赛的逃狱攻击赛道中取得了优异成绩，验证了其成功率和有效性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.18148", "html_url": "https://arxiv.org/abs/2410.18148", "title": "超越科莫格洛夫障碍：一种学习可调加权混合自动编码器进行模型降阶", "title_en": "Beyond the Kolmogorov Barrier: A Learnable Weighted Hybrid Autoencoder for Model Order Reduction", "authors": "Nithin Somasekharan,Shaowu Pan", "background": "高维度复杂物理系统的表征学习旨在找到一个低维度的内在潜在空间，这对于降低阶次建模和模态分析至关重要。然而，经典的克罗莫格洛夫障碍使得高阶嵌入空间难以通过传统的自动编码器（AE）实现，并且随着隐空间阶数的增加，自动编码器常常会出现收敛性较差的问题。为了克服这一问题，提出了结合奇异值分解（SVD）和自编码器的可学习加权混合自编码器方法。研究表明，引入可学习的加权参数是必要的，没有这些参数，模型要么退化为标准POD，要么无法表现出预期的收敛性。实验结果表明，相比于其他模型，该方法具有显著改进的泛化性能，特别在高维多尺度偏微分方程系统的代理模型建模中结合时间序列建模技术时，该技术提供了显著的改进。", "innovation": "提出了结合奇异值分解（SVD）和自编码器的可学习加权混合自编码器方法。通过引入可学习的加权参数，解决了传统自动编码器在处理高阶嵌入空间时遇到的收敛性问题，并在此基础上进一步提高了高维度复杂物理系统的模型降阶和模态分析的泛化性能及代理模型建模的精度。", "conclusion": "通过实验分析经典混沌偏微分方程系统的结果表明，与几种竞争方法相比，该方法在通用性能上取得了显著改进。同时，与时间序列建模技术结合使用时，为高维度多尺度偏微分方程系统的代理模型建模提供了显著改进。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.14133", "html_url": "https://arxiv.org/abs/2411.14133", "title": "GASP：生成对抗后缀以劫持LLM的高效黑箱生成方法", "title_en": "GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs", "authors": "Advik Raj Basani,Xiao Zhang", "background": "大规模语言模型（LLMs）在各类自然语言处理任务中展现了令人印象深刻的能力，但仍然容易受到精心设计的输入提示（称为 jailbreak 攻击）的影响，这些提示能够绕过安全屏障并引发有害响应。传统的对抗生成方法依赖于手工启发式规则，但普遍存在通用性不足的问题。尽管某些基于优化的方法能够自动生成攻击性提示，但它们往往生成的提示看起来生硬且容易被安全过滤器检测到，或者需要大量的计算资源来对离散的标记进行优化。", "innovation": "本文引入了生成对抗后缀提示器（Generative Adversarial Suffix Prompter, GASP），这是一种新颖的全自动框架，能够在完全黑箱的环境中高效生成具有人类可读性的劫持提示。GASP 采用潜在贝叶斯优化来构思对抗后缀，能够高效探索连续的潜在嵌入空间，逐步优化后缀提示器以提高攻击效果，同时通过一个有针对性的迭代优化过程维持提示的连贯性。", "conclusion": "通过全面的实验，我们证明了 GASP 可以生成自然的对抗提示，显著提高了劫持成功概率，缩短了训练时间，并加速了推理速度，使得 GASP 成为一种高效且可扩展的针对LLM的红色团队测试解决方案。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.09956", "html_url": "https://arxiv.org/abs/2502.09956", "title": "KGGen：使用语言模型从纯文本中提取知识图谱", "title_en": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models", "authors": "Belinda Mo,Kyssen Yu,Joshua Kazdan,Joan Cabezas,Proud Mpala,Lisa Yu,Chris Cundy,Charilaos Kanatsoulis,Sanmi Koyejo", "background": "近年来，构建知识图谱（KGs）的基础模型引起了广泛的关注，但这也揭示了一个基本挑战：知识图谱数据相对稀缺。已知的最佳知识图谱主要是由人类手动标注、模式匹配或早期自然语言处理（NLP）技术提取的。尽管手动生成的知识图谱供应稀缺，但自动提取的知识图谱质量却参差不齐。", "innovation": "本文提出了一种叫做KGGen的文本到知识图谱生成器（text-to-KG generator），利用语言模型从纯文本中生成高质量的知识图谱。KGGen通过聚类相关实体来减少提取的知识图谱中的稀疏性。此外，还提供了第一个基准测试，Measure of Information in Nodes and Edges（MINE），测试提取器从纯文本生成实用知识图谱的能力。通过基准测试证明，KGGen表现出了远超现有工具的性能。", "conclusion": "在新工具KGGen的基准测试中，展示了其在从纯文本生成高质量知识图谱方面的显著优势。此外，还提出了一种新的基准测试MINE，为评估知识图谱提取器的性能提供了标准。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15835", "html_url": "https://arxiv.org/abs/2502.15835", "title": "基于语用推理提升大模型代码生成", "title_en": "Pragmatic Reasoning improves LLM Code Generation", "authors": "Zhuchen Cao,Sven Apel,Adish Singla,Vera Demberg", "background": "大规模语言模型（LLMs）在将自然语言（NL）指令转化为程序代码方面显示出显著潜力，但用户指令常常存在固有的歧义，这给LLMs带来了挑战，使其难以生成准确反映用户真实意图的代码。为解决这一问题，研究者提出了生成代码候选方案并重新排序的方案以识别最佳解决方案的方法。", "innovation": "提出了名为CodeRSA的新颖代码候选重新排序机制，该机制基于语用推理（RSA）框架，旨在指导LLM进行更全面的用户意图的语用推理。在Llama-3-8B-Instruct和Qwen-2.5-7B-Instruct上，CodeRSA使用两个广泛使用的代码生成基准（HumanEval和MBPP）进行了评估，结果表明CodRSA在多个基准测试中持续优于常见基准，并且大多数情况下超过了最先进的方法，展示出了稳健的总体性能。", "conclusion": "研究结果证明将语用推理整合到代码候选重新排序中是有效的，并为提升LLM的代码生成质量提供了有希望的方向。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.02132", "html_url": "https://arxiv.org/abs/2502.02132", "title": "优化算法中的记忆如何隐式地修改损失函数", "title_en": "How Memory in Optimization Algorithms Implicitly Modifies the Loss", "authors": "Matias D. Cattaneo,Boris Shigida", "background": "深度学习中使用的一些现代优化方法依赖于过去迭代的历史，这种依赖通常被称为记忆。但随着时间的推移，这种依赖会迅速衰减。例如，带动量的梯度下降法就是通过指数平均过去的梯度来实现指数衰减的记忆。本文提出了一个通用技术，用于识别一种无记忆算法，它可以近似具有记忆的优化算法。这种方法是通过用当前迭代代替所有过去的迭代，并添加一个来自记忆的修正项来实现的。这个修正项可以解释为对损失的扰动，这种扰动的本质会告诉我们记忆如何隐式地（反）正则化优化动力学。", "innovation": "本文提出了一种通用技术，该技术通过替换所有过去的迭代为当前迭代，并添加一个由当前迭代引起的修正项，从而识别出与具有记忆的优化算法相近似的无记忆算法。此外，作者还通过理论解释了为什么Lion相比于AdamW在泛化性能上更好，这归因于记忆对损失函数的隐式（反）正则化效果不同。", "conclusion": "通过理论分析，作者发现Lion没有AdamW那样的由记忆引起的各种形式隐式反正则化，从而解释了为什么Lion在最近的实验中显示出更好的泛化性能。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04737", "html_url": "https://arxiv.org/abs/2504.04737", "title": "TathyaNyaya和FactLegalLlama：在印度法律背景下推进事实判断预测和解释", "title_en": "TathyaNyaya and FactLegalLlama: Advancing Factual Judgment Prediction and Explanation in the Indian Legal Context", "authors": "Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya", "background": "在基于事实判断预测和解释（FJPE）的景观中，依赖事实数据是开发强大且现实的AI驱动决策工具的关键。本文介绍了TathyaNyaya，这是针对印度法律环境的最广泛注释数据集，涵盖了印度最高法院和各级法院的判决。此数据集基于梵语术语“Tathya”（事实）和“Nyaya”（正义），特别设计关注事实陈述而非完整法律文本，反映了真实世界司法流程中事实数据驱动结果的过程。", "innovation": "本文提出了面向FJPE任务的Instruction-tuned大型语言模型（LLM）——FactLegalLlama，该模型在TathyaNyaya的实证数据上进行微调，集成预测准确性与富有逻辑性、相关性的解释。我们的方法结合了Transformer模型进行二元判决预测，以及用FactLegalLlama进行解释生成，构建了一种为印度法律领域FJPE推进提供强大框架的方法。TathyaNyaya不仅在规模和多样性上超过现有数据集，还为法律分析中构建可解释的AI系统设置了基准。研究结果强调了事实精确度和领域特定调整的重要性，提升了预测性能和可解释性。", "conclusion": "TathyaNyaya和FactLegalLlama为AI辅助的法律决策奠定了基础资源，有助于改进印度法律领域的FJPE。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.07683", "html_url": "https://arxiv.org/abs/2505.07683", "title": "在基于基础模型嵌入时代的多模式癌症建模", "title_en": "Multimodal Cancer Modeling in the Age of Foundation Model Embeddings", "authors": "Steven Song,Morgan Borjigin-Wang,Irene Madejski,Robert L. Grossman", "background": "The Cancer Genome Atlas (TCGA) 已经使新型发现成为可能，并且通过其协调的基因组学、临床和影像学数据，为癌症研究提供了大规模的参考数据集。许多先前的研究已在TCGA上开发了定制的深度学习模型，用于诸如癌症生存预测等任务。虽然TCGA包含病理报告的自由文本数据，但这些数据在过去却被未能充分利用。", "innovation": "作者探索了利用基础模型 (FMs) 的多模态零样本嵌入进行癌症数据的经典机器学习模型训练的能力。研究证明了多模态融合的易用性和增益效果，优于单模态模型。进一步证明了加入病理报告文本并严格评估基于模型的文本总结和幻想的影响。提出了一种以嵌入为中心的多模态癌症建模方法。", "conclusion": "总体而言，作者提出了一种以嵌入为中心的方法来建模多模态癌症数据，通过利用基础模型嵌入更好地发挥多模态融合的优势，并强调了文本数据，尤其是病理报告，对模型效果的积极影响。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.22879", "html_url": "https://arxiv.org/abs/2503.22879", "title": "Quamba2：用于选择性状态空间模型的稳健且可扩展的后训练量化框架", "title_en": "Quamba2: A Robust and Scalable Post-training Quantization Framework for Selective State Space Models", "authors": "Hung-Yueh Chiang,Chi-Chih Chang,Natalia Frumkin,Kai-Chiang Wu,Mohamed S. Abdelfattah,Diana Marculescu", "background": "状态空间模型（SSMs）因其一致的内存使用和高性能而正在成为与变压器竞争的有吸引力的替代方案。然而，由于存储需求和计算能力的限制，SSMs在云服务或有限资源设备上的扩展仍然具有挑战性。量化SSMs，使用低位宽数据格式，可以减少模型大小并受益于硬件加速。尽管如此，量化引入的错误使得最近的研究重点是优化特定模型或位宽以提高效率，而不牺牲性能。然而，不同的位宽配置对于不同的场景是必不可少的，例如W4A8可以提升大规模批次解码速度，而W4A16则可以在单用户情况下增强生成速度。", "innovation": "提出了一个名为Quamba2的后训练量化框架，该框架兼容W8A8、W4A8和W4A16，适用于Mamba1和Mamba2模型。通过保留通道顺序和保持激活持久性的方法，Quamba2将线性递归的输入在8位下进行排序和聚类量化，并对输入相关的参数使用基于状态分组的量化。为了确保SSM 输出中的计算不变性，模型的权重根据聚类序列在线下进行重新排列。实验结果表明，Quamba2-8B在预填充和生成阶段分别实现了1.3倍和3倍的加速，同时在内存减少4倍的情况下，平均准确率仅下降1.6%。", "conclusion": "该框架在MMLU上的评估证明了其可扩展性和稳健性。实现了SSMs在各种平台上的部署需求。相关的代码和量化模型将被发布到指定的网址。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11881", "html_url": "https://arxiv.org/abs/2505.11881", "title": "重访残差连接：为稳定而高效的深度网络引入正交更新", "title_en": "Revisiting Residual Connections: Orthogonal Updates for Stable and Efficient Deep Networks", "authors": "Giyeong Oh,Woohyun Cho,Siyeol Kim,Suhwan Choi,Youngjae Yu", "background": "残差连接对于深度神经网络至关重要，它们通过缓解梯度消失问题允许网络更深地构建。然而，在标准的残差更新中，模块的输出直接加到输入流上。这可能导致更新更多地强化或调节现有流方向，而不是充分利用模块学习全新特征的能力。", "innovation": "作者提出了一种新方法——正交残差更新（Orthogonal Residual Update），该方法将模块的输出相对于输入流进行分解，并仅添加正交分量。此设计旨在引导模块主要贡献新的表征方向，从而更好地促进富集的特征学习并提高训练效率。", "conclusion": "研究表明，正交更新策略提高了不同架构（如ResNetV2、视觉变换器）和数据集（如CIFARs、TinyImageNet、ImageNet-1k）上的泛化准确性和训练稳定性，例如，在ImageNet-1k上ViT-B的top-1准确率提高了+3.78个百分点。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.04847", "html_url": "https://arxiv.org/abs/2505.04847", "title": "使用不断演变的排行榜基准评估 RAG 中的大语言模型（LLM）忠诚度", "title_en": "Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards", "authors": "Manveer Singh Tamber,Forrest Sheng Bao,Chenyu Xu,Ge Luo,Suleman Kazi,Minseok Bae,Miaoran Li,Ofer Mendelevitch,Renyi Qu,Jimmy Lin", "background": "检索增强生成（RAG）旨在通过将响应与外部语境联系起来减少幻觉，然而即使在提供了相关上下文的情况下，大型语言模型（LLMs）仍然经常引入未支持的信息或矛盾。尽管如此，目前的幻觉检测方法存在限制。因此，需要更有效的方法来评估和基准测试LLMs在检索增强生成中的真实性。", "innovation": "本文描述了 Vectara 创新的两个努力，旨在测量和基准测试LLMs在RAG中的真实性。首先，提出了一种原始的幻觉排行榜，该排行榜使用HHEM幻觉检测模型跟踪2023年以来的语言模型幻觉率。接着，引入了FaithJudge，一个LLM作为评判者的框架，它利用多样的人类标注的幻觉示例来大幅提高自动幻觉评估的准确性。FaithJudge还引入了基于该方法的增强幻觉排行榜，用于评估LLMs在总结、问答和数据到文本生成任务中的RAG真实性。FaithJudge使得在RAG中更可靠地基准测试LLM幻觉成为了可能，并为开发更可信赖的生成性AI系统提供了支持：benchmarking_llm_faithfulness_in_rag_with_evolving_leaderboards.com", "conclusion": "FaithJudge框架使得更可靠地评估RAG中LLM幻觉成为可能，为开发更可信的生成式AI系统奠定了基础。文章还通过引入一个基于FaithJudge的增强排行榜，展示了如何在总结、问答和数据到文本生成任务中评估LLMs的RAG真实性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13567", "html_url": "https://arxiv.org/abs/2505.13567", "title": "闭合环路环境中RNN学习动力学", "title_en": "Learning Dynamics of RNNs in Closed-Loop Environments", "authors": "Yoav Ger,Omri Barak", "background": "研究显示，基于神经科学启发的任务训练的递归神经网络（RNN）提供了强大的大脑计算模型。然而，现有的训练范式主要依赖于开环的监督学习设置，而在真实世界中，学习往往发生在闭环环境中。当前的理论和实践未能充分考虑闭环环境下的学习动态。本文团队为此研究闭合环路环境中的线性RNN的学习动态。", "innovation": "文章发展了一项数学理论，描述线性RNN在闭环环境中的学习动态。研究发现，同一结构的RNN在闭环和开环训练下展示了显著不同的学习轨迹。通过分析闭环情况，展示了闭环RNN与开放环境RNN之间在短期策略改进与长期交互稳定性的竞争目标不同。此外，该理论框架被应用于实际的运动控制任务，展示了其更广泛的适用性。", "conclusion": "研究成果强调，在生物学上合理的设定中建模闭环动力学的重要性。同时，这一理论能够为理解、开发和优化闭环系统中的RNN性能提供新的思路。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.20110", "html_url": "https://arxiv.org/abs/2503.20110", "title": "通过微调迁移提升模型开发效率", "title_en": "Efficient Model Development through Fine-tuning Transfer", "authors": "Pin-Jie Lin,Rishab Balasubramanian,Fengyuan Liu,Nikhil Kandpal,Tu Vu", "background": "现代大规模语言模型在每次更新时都会遇到效率问题，因为每次新的预训练模型版本都必须重复昂贵的对齐过程。这一挑战同样适用于特定领域或语言的模型，其中每次新的基础模型版本发布，针对专门数据的微调都必须重新进行。本文探讨了不同模型版本之间微调更新的迁移。我们从一个源模型版本中提取微调的diff向量（代表权重变化），然后将其应用于不同目标版本的基础模型。通过对各种开源模型版本进行实证评估，我们发现，通过迁移diff向量可以显著提高目标基础模型的性能。例如，将从Llama 3.0 8B转移的微调更新应用到Llama 3.1 8B上，在IFEval上提高了46.9%，在LiveCodeBench上提高了15.7%，甚至超过了Llama 3.1 8B Instruct。此外，我们还展示了在多语言任务中也观察到的性能提升，分别为马达加斯加语和土耳其语的Global MMLU提高了4.7%和15.5%。我们发现这些合并的模型为后续的微调提供了更好的初始条件。最后，我们的实验结果表明，当源模型和目标模型在参数空间的一条线性连通区域内时，微调转移最有效，并提供了该方法的理论分析。", "innovation": "本文创新性地提出了通过迁移微调更新来提升不同模型版本之间性能的方法。通过从一个源模型版本中提取微调的diff向量，并将其应用于不同目标版本的基础模型，实现了显著的性能提升。这种方法为持续开发LLM提供了成本效益高且实用的策略。", "conclusion": "结合微调转移的方法能够为LLM的持续开发提供一种成本效益高且实用的策略。转移的微调更新在多个模型版本中产生了显著的性能提升，特别是在特定领域和多语言任务中。我们的实验也演示了在参数空间中的线性连通区域内迁移的最优化效果，进一步验证了本文方法的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.03480", "html_url": "https://arxiv.org/abs/2503.03480", "title": "SafeVLA：通过约束学习实现视觉-语言-行动模型的安全对齐", "title_en": "SafeVLA: Towards Safety Alignment of Vision-Language-Action Model via Constrained Learning", "authors": "Borong Zhang,Yuhao Zhang,Jiaming Ji,Yingshan Lei,Josef Dai,Yuanpei Chen,Yaodong Yang", "background": "视觉-语言-行动模型（VLAs）展现了作为通用型机器人策略的潜力，但在真实世界部署中面临极端的安全挑战，包括对环境、机器人本身和人类的潜在危害。如何将安全约束明确整合到VLAs中是一个亟待解决的问题。因此，本文提出一种综合安全方法（ISA），通过系统建模安全要求，主动引发多样化的不安全行为，利用安全强化学习限制VLAs策略，并通过目标评估确保其安全性。这一方法利用约束马尔可夫决策过程（CMDP）范式，从最小最大视角优化VLAs，从而达到一系列关键特征：有效的安全性能权衡，在安全违规累积成本方面比现有最先进的方法减少83.58%，同时任务成功率增加3.85%；强大的安全保障能力，能够缓解长尾风险并处理极端失效场景；以及对不同分布外扰动下学习的安全行为的稳健泛化能力。这些效果是在长时移动操作任务上评估得出的。", "innovation": "本文提出了一种综合安全方法（ISA），利用约束马尔可夫决策过程（CMDP）范式，从最小最大视角优化VLAs。ISA通过系统建模安全要求，主动引发多样化的不安全行为，通过安全强化学习限制VLAs策略，并通过目标评估确保其安全性。这种方法在安全性能权衡、强大安全保障能力以及对不同分布外扰动下学习的安全行为的稳健泛化能力上展现出了显著优势。评估结果显示，与现有最先进的方法相比，SafeVLA在安全违规的累积成本方面减少了83.58%，同时任务成功率提高了3.85%。", "conclusion": "本文提出了一种综合安全方法（ISA），能够通过约束学习实现视觉-语言-行动模型的安全对齐。通过实验验证，该方法有效提高了模型的安全性能，降低了安全违规的成本，并能够处理极端失效场景。此外，持续优化的策略还能够泛化到未见过的扰动环境。该方法在长时操作任务中展现出显著的效果，表明它是一种有潜力的解决真实世界中VLAs安全问题的方案。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18574", "html_url": "https://arxiv.org/abs/2505.18574", "title": "Autocomp: 强大且可移植的张量加速器代码优化器", "title_en": "Autocomp: A Powerful and Portable Code Optimizer for Tensor Accelerators", "authors": "Charles Hong,Sahil Bhatia,Alvin Cheung,Yakun Sophia Shao", "background": "硬件加速器，尤其是针对张量处理设计的，已经被广泛应用于现代计算环境中。尽管编译器开发已经取得了显著进展，但编程这些张量加速器依然具有挑战性，导致其潜在性能并未充分利用。此外，虽然大型语言模型（LLMs）在代码生成和优化方面表现出了巨大的潜力，但在生成专用于特定张量加速器的低资源语言代码方面仍然面临巨大挑战。", "innovation": "作者提出了一种名为Autocomp的方法，通过结合自动化LLM驱动搜索、计划阶段的领域知识插件和每次搜索迭代的硬件正确性和性能反馈，使加速器程序员能够利用领域知识进行代码优化。该方法在三个不同硬件平台上的优化效果显著：相比供应商提供的库（Gemmini），Autocomp优化后的代码运行速度提高了5.6倍；相比手工调优的代码，优化速度提高了1.9倍；相比基于机器学习的成本模型，GPU优化速度提高了3.8倍。此外，该方法生成的优化策略在针对相似张量操作时可以重复利用，进一步提高了加速效果。", "conclusion": "Autocomp通过自动化优化过程，显著提高了基于张量加速器的代码性能，并且该优化策略具有跨平台的可重用性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17760", "html_url": "https://arxiv.org/abs/2505.17760", "title": "用引导向量辅助LLM法官获得诚实答案：引导驱动的诚实替代方案", "title_en": "But what is your honest answer? Aiding LLM-judges with honest alternatives using steering vectors", "authors": "Leon Eshuijs,Archie Chaudhury,Alan McBeth,Ethan Nguyen", "background": "检测大型语言模型（LLMs）中微妙的不诚实行为，如奉承和操纵，对于人类和自动化评估者来说仍然是一个挑战，因为这些行为通常通过小偏差表现出来，而不是明显的错误陈述。现有的评估方法依赖于黑盒评估，而本研究提出了一种名为JUSSA的新型框架，通过使用引导向量增强LLM评估者的评估能力，而不是直接改进模型行为，从而改善评估者的检测能力。", "innovation": "JUSSA框架引入了使用引导向量的方法，不是为了直接改进模型行为，而是为了增强LLM评估者的评估能力。通过在推理过程中应用引导向量生成更真实的替代方案，为评估者提供了对比性例子，使微妙的不诚实模式更容易被检测到。该框架使用模型内部信息为目标单例创建对比性比较，而不是依赖黑盒评估方法。该研究还提出了一套新的操纵数据集，涵盖了多种类型的操纵行为，评估了JUSSA在检测奉承中的有效性。", "conclusion": "通过证明引导向量不仅能增强安全评估能力，还能生成对比性示例，本研究揭示了系统变得日益复杂时，模型审计的新方向。研究表明，JUSSA有助于评估者的不诚实检测任务，无论是弱评估者和简单的不诚实行为检测，还是强评估者和复杂的任务。分层实验展示了误导性提示如何在中间层导致表示偏离诚实性表示，揭示了生成对比性示例的最佳引导干预层。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19853", "html_url": "https://arxiv.org/abs/2505.19853", "title": "两个视频中的因果相关针", "title_en": "Two Causally Related Needles in a Video Haystack", "authors": "Miaoyu Li,Qin Chao,Boyang Li", "background": "评估视频-语言模型（VLMs）理解长视频的能力仍然具有挑战性。现有的基准评估不充分地涵盖了两个关键能力：从长视频中两个单独的位置提取信息并联合理解它们，以及以因果关系建模人类行为的世界。", "innovation": "提出了Causal2Needles基准，该基准使用非因果单针、因果单针和因果双针的问题来评估模型的两种能力。这种基准特别引入了因果双针问题，该问题要求从长视频和相关叙述文本中提取因果事件的信息，并采用了两种互补的问题格式以防止文本偏见：定位包含答案的视频片段和对该视频片段的视觉细节的口头描述。", "conclusion": "现有基准上的表现出色的模型在因果双针问题上存在困难，模型性能与两针之间的距离成负相关。这些发现突显了当前VLMs的关键局限性。数据集可从以下链接访问:this https URL"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18658", "html_url": "https://arxiv.org/abs/2505.18658", "title": "大规模语言模型的鲁棒性：缓解策略与评估指标综述", "title_en": "Robustness in Large Language Models: A Survey of Mitigation Strategies and Evaluation Metrics", "authors": "Pankaj Kumar,Subhankar Mishra", "background": "近年来，大规模语言模型（LLMs）在自然语言处理（NLP）和人工智能（AI）领域展现出巨大的潜力。然而，确保LLMs的鲁棒性仍然是一个关键挑战。为了应对这些挑战并推动该领域的进步，本文提供了一个全面的综述，涵盖当前该领域内的相关研究。综述揭开了LLMs鲁棒性的本质，并研究了其概念基础、不同输入下一致性表现的重要性以及现实应用中的失败模式所涉及的影响。", "innovation": "该研究系统地检视了LLMs的鲁棒性，将其分为本原模型限制、数据驱动的脆弱性和外部攻击性因素。同时，详细分析了先进的缓解策略、常用基准、新兴指标以及评定实际可靠性中的持续缺口。此外，还综合了现有综述和跨学科研究的结果，突显了趋势、未解决的问题以及未来研究的路径。", "conclusion": "总结了现有的研究和跨学科研究的发现，强调了当前研究趋势、未解决的问题以及未来研究的可能路径。该论文为研究LLMs的鲁棒性提供了丰富的文献综述和见解。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20368", "html_url": "https://arxiv.org/abs/2505.20368", "title": "公开领域的金融问答中标准化文档的层次检索与证据整理", "title_en": "Hierarchical Retrieval with Evidence Curation for Open-Domain Financial Question Answering on Standardized Documents", "authors": "Jaeyoung Choe,Jihoon Kim,Woohwan Jung", "background": "基于检索增强生成（RAG）的大语言模型在金融领域的知识密集型任务中表现出色。然而，标准化文件（例如SEC提交报告）具有类似格式，如重复的模板文本和相似的表格结构。这些相似性迫使传统RAG方法错误地识别近似重复文本，导致检索重复，从而影响准确性和完整性。", "innovation": "我们提出了层次检索与证据整理（HiREC）框架。该方法首先进行层次检索以减少相似文本之间的混淆，首先是检索相关文档，然后从文档中选出最相关的段落。证据整理过程去除无关段落。当需要时，它可以自动生成补充查询以收集缺失信息。我们设计并发布了一个包含145,897份SEC文件和1,595个问题-答案对的大规模开放域金融问答基准（LOFin）。", "conclusion": "我们的方法通过HiREC框架提供了一种新的解决思路，该框架有效地减少了标准化文档中文本检索的重复性问题，并提高了金融问答任务的准确性和完整性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.24630", "html_url": "https://arxiv.org/abs/2505.24630", "title": "推理模型更易产生幻觉：面向事实的强化学习增强大型推理模型", "title_en": "Reasoning Models Hallucinate More: Factuality-Aware Reinforcement Learning for Large Reasoning Models", "authors": "Junyi Li,Hwee Tou Ng", "background": "大型语言模型（LLMs）通过强化学习（RL）优化，在推理任务上取得了显著进步，并在各种具有挑战性的基准测试中展现了令人印象深刻的能力。然而，实证分析发现了一个关键问题：以推理为导向的RL微调显著增加了幻觉的出现频率。", "innovation": "本文提出了一种名为事实感知步骤化策略优化（FSPO）的新颖RL微调算法，该算法在每次推理步骤中引入了明确的事实验证。FSPO通过使用自动验证与给定证据对抗，在每一 tokens 级别上动态调整优势值，激励在整个推理过程中保持事实正确性。", "conclusion": "研究结果表明，使用FSPO算法可以有效减少幻觉并提高推理准确性，显著提升可靠性和性能，在数学推理和幻觉基准测试中取得了更好的结果。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23062", "html_url": "https://arxiv.org/abs/2505.23062", "title": "复合流匹配在拥有偏移动力学数据的强化学习中的应用", "title_en": "Composite Flow Matching for Reinforcement Learning with Shifted-Dynamics Data", "authors": "Lingkai Kong,Haichuan Wang,Tonghan Wang,Guojun Xiong,Milind Tambe", "background": "从源环境预收集的离线数据可以显着提高强化学习（RL）中的样本效率，但这一好处往往受到源和目标环境之间转态动力学差异的挑战。现有方法通常通过惩罚或在高动态差异区域过滤源过渡来解决这一问题，但它们往往依赖KL散度或互信息来估算动态差异，这在源和目标动力学具有不相交支持的情况下可能难以定义。", "innovation": "本文提出了CompFlow，一种基于流匹配与最优传输理论连接的方法。CompFlow将目标动力学建模为基于源域流输出分布的条件流，而非直接从高斯先验学习。这种方法具有两大优势：(1) 改进的目标动力学学习泛化能力和(2) 通过源和目标过渡之间的Wasserstein距离进行理论上的动态差异估计。进一步地，作者提出了一个乐观的主动数据收集策略，优先探索动态差异大的区域，并证明该策略可减少与最优策略的性能差距。实验结果表明，CompFlow在多个具有偏移动力学的数据强化学习基准测试中优于强基线方法。", "conclusion": "本文提出了CompFlow方法，通过改进目标动力学学习过程和动态差异的估计，提高了样本效率，并证明了在偏移动力学强化学习任务中比现有方法更有效。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.04700", "html_url": "https://arxiv.org/abs/2506.04700", "title": "基于伯恩斯坦多项式基凸分歧的神经隐式采样器显式密度近似", "title_en": "Explicit Density Approximation for Neural Implicit Samplers Using a Bernstein-Based Convex Divergence", "authors": "José Manuel de Frutos,Manuel A. Vázquez,Pablo M. Olmos,Joaquín Míguez", "background": "近年来，基于秩的统计度量，如不变统计损失（ISL），已成为训练隐式生成模型的强大而实用的工具。本文基于ISL框架，提出了一种新颖的无需似然的目标dual-ISL，通过交换目标分布和模型分布的角色，得到模型密度的空间上的凸优化问题。进一步，作者通过密度比 $q=p/\tilde{p}$ 在Bernstein多项式基上的$L^2$-投影，构建了理论框架，提供了误差控制、精确收敛速率以及明确的密度逼近表达式。此外，还通过随机一维投影扩展到多元场景，定义了带有保持凸性和连续性的sliced dual-ISL分散度", "innovation": "提出了一种新颖的无需似然的目标dual-ISL，基于rank-based统计度量ISL的改进，通过交换目标分布和模型分布的角色，得到模型密度的空间上的凸优化问题。进一步发展了一种理论框架，将dual-ISL作为一种$L^2$-投影的密度比 $q=p/\tilde{p}$ 到伯恩斯坦多项式基上的表述，从中推导出误差界、精确收敛速率以及封闭形式的截断密度逼近。提出了sliced dual-ISL在多元场景下的定义，保留了凸性和连续性。这些理论优势在实证研究中转化为实际优势：dual-ISL在多个基准上更快收敛、更平滑、更稳定，并能更有效地防止模式崩溃，同时提供显式密度逼近", "conclusion": "dual-ISL在实证研究中显示出相对于传统ISL和其他领先的隐式生成方法的优势，如更快的收敛速度、更平滑和更稳定的训练过程，以及更有效地防止模式崩溃。同时，dual-ISL提供了显式的密度逼近，使得其在实际应用中更具优势"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.04704", "html_url": "https://arxiv.org/abs/2506.04704", "title": "HoliSafe: 全面的安全基准和建模以提高视觉语言模型的安全性", "title_en": "HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model", "authors": "Youngwan Lee,Kangsan Kim,Kwanyong Park,Ilcahe Jung,Soojin Jang,Seanie Lee,Yong-Ju Lee,Sung Ju Hwang", "background": "尽管正在不断增强视觉语言模型（VLMs）的安全性，但现有方法仍面临两个主要问题：1）现有的安全性调整数据集和基准仅部分考虑图像-文本交互可能会产生有害内容，往往会忽略看似无害但实际不安全的配对可能导致的具体场景。这种狭窄的覆盖范围使VLMs在未见配置中容易受到脱狱攻击；2）先前的方法主要依赖于数据导向的调整，缺乏用于基本增强安全性的架构创新。鉴于这些缺陷，本文旨在通过提出一个涵盖所有五种安全/不安全图像-文本组合的综合安全数据集和基准——HoliSafe——以及一个结合视觉保护模块（VGM）的模块化框架，来解决这些问题，以提高VLM的安全性。", "innovation": "本文的创新点包括：1）引入了一贯性的安全数据集和基准HoliSafe，提供更强大的训练和评估基础；2）提出了一个新的模块化框架，通过视觉保护模块（VGM）来增强VLM的安全性，能够识别输入图像的有害性并提供可解释的有害性分类，解释拒绝决策的原因；3）VGM模块设计为插件组件，可以无缝集成到各种规模的预训练VLM中。实验结果表明，使用HoliSafe训练的Safe-VLM与VGM结合，能在多个VLM基准上实现最佳的安全性能；4）HoliSafe-Bench揭示了现有VLM模型的关键漏洞，旨在推动进一步研究以实现更加健壮和可解释的VLM安全性。", "conclusion": "HoliSafe不仅提供了一个全面的安全基准和建模框架，还揭示了现有VLM模型的关键漏洞。希望通过HoliSafe和VGM的引入，能够激励更多关于视觉语言模型安全性的研究，拓宽未来对多模态对齐的探索方向。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15980", "html_url": "https://arxiv.org/abs/2506.15980", "title": "使用压缩和量化多条件令牌化技术的高级手语视频生成", "title_en": "Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization", "authors": "Cong Wang,Zexuan Deng,Zhiwei Jiang,Yafeng Yin,Fei Shen,Zifeng Cheng,Shiping Ge,Shiwei Gan,Qing Gu", "background": "手语视频生成（SLVG）旨在从口头语言文本生成身份保留的手语视频。现有的方法主要依赖于单个粗糙条件（例如，骨架序列）作为中介，连接翻译模型和视频生成模型，这限制了生成视频的自然性和表达性。", "innovation": "本文提出了SignViP，这是一种新颖的SLVG框架，结合了多种细粒度条件，以提高生成的准确性。SignViP采用了离散标记化范式，将细粒度条件（例如，细粒度姿态和3D手部）整合和表示进去，而不是直接翻译易出错的高维条件。SignViP包含三个核心组件：（1）符号视频扩散模型与多条件编码器共同训练，学习包含细粒度运动和外观的连续嵌入；（2）有限尺度量化（FSQ）自编码器进一步训练以压缩和量化这些嵌入到离散令牌中，以紧凑地表示条件；（3）多条件令牌翻译器训练将口头语言文本翻译为离散的多条件令牌。这些令牌通过FSQ自编码器解码为连续嵌入，然后注入符号视频扩散模型来指导视频生成。实验结果表明，SignViP在包括视频质量、时间连贯性和语义保真度在内的多个指标上取得了最先进的性能。", "conclusion": "实验结果显示，SignViP在包括视频质量、时间连贯性和语义保真度在内的多指标上达到了最先进的性能。代码已发布。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23717", "html_url": "https://arxiv.org/abs/2506.23717", "title": "通过自适应位分配实现高效准确的脉冲神经网络", "title_en": "Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation", "authors": "Xingting Yao,Qinghao Hu,Fei Zhou,Tielong Liu,Gang Li,Peisong Wang,Jian Cheng", "background": "多比特脉冲神经网络（SNNs）近年来成为研究热点，追求高能效和高准确度的人工智能。然而，随着参与的位数增多，与之相关的存储和计算需求急剧增加，导致性能提升变得不成比例。不同层的重要性不同，额外的位数可能会被浪费并干扰性能，因此需要优化位分配策略，以提高SNN的效率和准确性。", "innovation": "本文提出了适用于直接训练的SNN的自适应位分配策略，实现细粒度的逐层存储和计算资源分配。具体地说，参数化时间长度和权重及脉冲的位宽，并通过梯度使其变得可学习和可控。为了解决可变位宽和时间长度带来的挑战，提出了一种细化的脉冲神经元，可以处理不同的时间长度，使时间长度梯度的推导成为可能，并更适合脉冲量化。此外，理论地阐述了可学习位宽的步长不匹配问题，可能导致严重的SNN量化错误，并相应地提出了步长重置机制来缓解这个问题。实验结果表明，本文方法可以在保持高准确度的同时降低整体内存和计算成本。特别是在ImageNet基准工作上，SEWResNet-34可以实现2.69%的准确率提升和4.16倍的位预算减少。", "conclusion": "实验在各种数据集上进行，包括静态的CIFAR和ImageNet数据集以及动态的CIFAR-DVS、DVS-GESTURE和SHD数据集，证明了本文方法的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02912", "html_url": "https://arxiv.org/abs/2507.02912", "title": "工业碳排放分析与政策影响的深度图学习", "title_en": "Deep Graph Learning for Industrial Carbon Emission Analysis and Policy Impact", "authors": "Xuanming Zhang", "background": "工业碳排放是气候变化的主要驱动因素，但其建模面临多重共线性和跨行业跨时间的复杂依赖性挑战。传统回归或聚类方法难以有效处理这些问题，因此需要一种新的方法来分析和预测工业二氧化碳排放量，这种方法能够解决特征共线性问题，并捕捉行业的时空依赖性。", "innovation": "本文提出了一种基于图的深度学习框架DGL，利用图神经网络（GNN）和注意力机制来建模不同行业之间的关系，同时结合时间变换器学习长期模式。这种方法优于传统的回归或聚类模型，减少了15%以上的预测误差，并通过注意力权重和因果分析保持了模型的可解释性。同时，这种方法首次实现了通过结构化编码特征关系来解决多重共线性，并结合因果推理来识别真实的排放驱动因素，提高了透明度和公平性。", "conclusion": "本文展示了如何利用先进的人工智能图学习技术识别高排放热点，并提出公平的干预计划，这不仅有助于制定与可持续发展目标一致的部门特定脱碳战略，也为政策制定者和行业利益相关者提供了实现减排目标的强大工具。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00097", "html_url": "https://arxiv.org/abs/2508.00097", "title": "XRoboToolkit：一种跨平台机器人遥控框架", "title_en": "XRoboToolkit: A Cross-Platform Framework for Robot Teleoperation", "authors": "Zhigen Zhao,Liuchuan Yu,Ke Jing,Ning Yang", "background": "视觉-语言-行动模型的快速发展迫切需要大规模、高质量的机器人示范数据集。尽管电信操作是数据收集的主要方法，但当前的方法存在可扩展性有限、设置复杂和数据质量不佳的问题。", "innovation": "本文提出了基于OpenXR标准构建的跨平台扩展现实（XR）机器人电信操作框架XRoboToolkit。该系统具有低延迟的立体视觉反馈、基于优化的逆运动学以及支持包括头部、控制器、手部和辅助运动跟踪在内的多种跟踪模式。XRoboToolkit的模块化架构允许无缝集成到各种机器人平台和仿真环境中，包括精确操作臂、移动机器人和灵巧手。", "conclusion": "通过精确操作任务展示了该框架的有效性，并通过训练表现出强大自主性能的VLV模型验证了数据质量。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.18989", "html_url": "https://arxiv.org/abs/2507.18989", "title": "GENIAL：基于网络反转的低功耗算法逻辑单元生成性设计空间探索", "title_en": "GENIAL: Generative Design Space Exploration via Network Inversion for Low Power Algorithmic Logic Units", "authors": "Maxence Bouvier,Ryan Amaudruz,Felix Arnold,Renzo Andri,Lukas Cavigelli", "background": "随着AI工作负载的增加，优化算术单元变得越来越重要，目的是减少数字系统的占地面积。传统的设计流程通常依赖于手动或启发式优化，其在全面探索设计空间方面能力有限。", "innovation": "提出了一个基于机器学习的框架GENIAL，用于自动生成和优化算术单元，特别是针对乘法器。核心部分是一个通过两阶段训练（自监督预训练和监督微调）的Transformer基代理模型，用于从抽象设计表示中预测关键硬件指标（如功耗和面积）。通过反向代理模型，GENIAL高效地搜索新的操作数编码，可以直接在特定输入数据分布的条件下减少算术单元的功耗。实验证明，GENIAL在样本效率和快速收敛到优化设计方面的表现优于其他方法，并使高努力逻辑综合优化流程嵌入其中，从而提高了代理模型的准确性。同时，GENIAL自动化发现的编码在代表性AI工作负载上的乘法器中实现了高达18%的开关活动节省，相比传统的补码。该研究展示了算法逻辑单元的广泛适用性，包括状态机的改进。", "conclusion": "这些进步标志着在数字系统中自动生成具有结果质量优化的组合电路走向自动化的重大一步。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.17978", "html_url": "https://arxiv.org/abs/2507.17978", "title": "MeAJOR Corpus: 多源数据集用于钓鱼电子邮件检测", "title_en": "MeAJOR Corpus: A Multi-Source Dataset for Phishing Email Detection", "authors": "Paulo Mendes,Eva Maia,Isabel Praça", "background": "钓鱼邮件通过欺诈性和恶意的内容利用人类的弱点，对网络安全造成严重威胁。尽管机器学习模型能够有效检测钓鱼威胁，但它们的表现高度依赖于训练数据的质量和多样性。然而，现有的数据集存在关键限制，例如样本不平衡和特征范围有限，影响了模型的泛化能力和可复现性。", "innovation": "本文提出MeAJOR（Merged email Assets from Joint Open-source Repositories）语料库，这是一个新颖的多源钓鱼邮件数据集，旨在克服现有资源的关键限制。该数据集整合了135,894个样本，涵盖了广泛钓鱼技术和合法电子邮件，具备广泛的工程化特征，适用于钓鱼检测研究。通过与RF、XGB、MLP和CNN四种分类模型系统的实验，利用多个特征配置评估数据集的实用性，结果显示XGB分类器在F1得分上达到98.34%。MeAJOR数据集通过集成来自多个类别的广泛特征，提供了可重用和一致的资源，解决了常见的难题如样本不平衡、泛化能力和可复现性等问题，从而提高了模型的性能和可靠性。", "conclusion": "MeAJOR数据集通过引入广泛特征，提高了钓鱼邮件检测模型的性能和可靠性，克服了现有数据集的局限性，提供了可复用和一致的资源。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21928", "html_url": "https://arxiv.org/abs/2507.21928", "title": "Vibe编码作为软件开发中意图调解的重新配置：定义、影响及研究议程", "title_en": "Vibe Coding as a Reconfiguration of Intent Mediation in Software Development: Definition, Implications, and Research Agenda", "authors": "Christian Meske,Tobias Hermanns,Esther von der Weiden,Kai-Uwe Loser,Thorsten Berger", "background": "软件开发正在经历一项根本性的转变，随着vibe编码的普及，越来越多的现代代码库是由AI生成的。尽管这一技术正在迅速采用，但人们对它的理解却相对有限，这种认知差距突显了对这一新兴范式的深入探究的需求。通过意图视角和历史分析，我们定义了vibe编码为一种开发范式，其中人类与生成AI进行协作，通过自然语言对话共同创造软件制品，从确定性命令转向概率性推理来重新调解开发者的意图。意图调解是指开发者将其概念目标转化为计算系统可以执行的表示的最基本过程。我们的研究结果表明，vibe编码重新配置了认知工作，将知识劳动在人与机器之间重新分配，并在软件开发过程中将专业知识从传统的设计或技术实现领域转向协作整合。我们指出了几个关键机会和风险。", "innovation": "提出了vibe编码这一新型软件开发范式，强调了人与AI在自然语言对话中的协同作用，从确定性命令转向概率性推理来调解开发者的意图。这突显了认知工作在人机之间重新分配的必要性和机遇，包括民主化、加速和系统性杠杆作用，但也同时指出了黑盒代码、责任空白和生态系统偏见等风险。", "conclusion": "我们提出了一项研究议程，涵盖人类中心化、技术中心化和组织中心化的方向，旨在指导未来对这一范式的进一步研究。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.24722", "html_url": "https://arxiv.org/abs/2505.24722", "title": "HELM: 通过曲率专家混合的大规模超曲面语言模型", "title_en": "HELM: Hyperbolic Large Language Models via Mixture-of-Curvature Experts", "authors": "Neil He,Rishabh Anand,Hiren Madhu,Ali Maatouk,Smita Krishnaswamy,Leandros Tassiulas,Menglin Yang,Rex Ying", "background": "大规模语言模型在跨领域的文本建模任务中表现出色，但自然语言的固有语义层次和细腻的几何结构特征，当前的语言模型无法完全捕捉到，因为它们依赖于欧几里得操作。已有研究表明，不尊重语言令牌嵌入的几何结构会导致训练不稳定性和生成能力的退化。这些发现表明，转向非欧几里得几何可以更好地将语言模型与文本的底层几何结构对齐。", "innovation": "本文提出了在超曲面空间全量运行的语言模型家族HELPM，以重新思考基于Transformer的大规模语言模型，解决了现有超曲面语言模型的表示灵活性不足、缺失必要操作以及扩展性差的问题。此外，提出了曲率专家混合模型HELM-MICE，每个专家在不同的曲率空间内操作，以从文本中编码更细致的几何结构，还提出了一个稠密模型HELM-D。进一步开发了超曲面多头潜在注意(HMLA)机制，用于高效、减缓记忆体的训练和推理。此外，开发了超曲面等效的旋转位置编码和RMS归一化。", "conclusion": "我们首次在十亿参数规模上训练了完全超曲面的大规模语言模型，并在MMLU和ARC等公认基准上进行了评估，覆盖STEM问题解决、通用知识和常识推理。结果显示，我们的HELM架构在多模态语言模型中提供了显著的性能提升，展示了超曲面几何在大规模预训练语言模型中的有效性和增强推理能力。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.08604", "html_url": "https://arxiv.org/abs/2509.08604", "title": "医学中大型语言模型的记忆：普遍性、特征和影响", "title_en": "Memorization in Large Language Models in Medicine: Prevalence, Characteristics, and Implications", "authors": "Anran Li,Lingfei Qian,Mengmeng Du,Yu Yin,Yan Hu,Zihao Sun,Yihang Fu,Erica Stutz,Xuguang Ai,Qianqian Xie,Rui Zhu,Jimin Huang,Yifan Yang,Siru Liu,Yih-Chung Tham,Lucila Ohno-Machado,Hyunghoon Cho,Zhiyong Lu,Hua Xu,Qingyu Chen", "background": "大型语言模型（LLMs）在医学领域展现出了显著潜力。到目前为止，它们已被广泛应用于诊断辅助、医学问题解答和临床信息综合等任务。然而，一个关键问题是：LLMs在多大程度上“记忆”了医学训练数据。本文对此展开研究，系统评估了医学中LLMs的记忆现象，包括其频率、特征、内容量以及可能的下游影响。", "innovation": "这是首次全面评估医学中LLMs的记忆现象，涉及常见适应场景：持续的医学语料库预训练、标准医学基准的微调以及实际临床数据的微调。研究结果显示，这种记忆在所有适应场景中普遍存在，且比一般领域报告的要高，对医学中LLMs的发展和应用均有影响。", "conclusion": "研究基于上述发现，提出了一系列实际建议，旨在促进有益记忆，增强领域特定推理和事实准确性；减少无信息记忆，促进超出表面模式的深入学习；并减轻有害记忆，以防敏感或可识别患者信息的泄露。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00709", "html_url": "https://arxiv.org/abs/2508.00709", "title": "NyayaRAG：印度普通法系统下基于RAG的现实司法判决预测", "title_en": "NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System", "authors": "Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Ajay Varghese Thomas,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya", "background": "在AI法学领域，法律判决预测(LJP)已成为关键领域，旨在实现司法结果自动化预测并增强法律推理的可解释性。此前印度的解决方案主要依赖于案件内部数据如事实、争议点和推理，但却经常忽略了普通法体系中的关键要素，即对法律条文和司法先例的依赖。本文论述了一种新颖的解决思路，通过结合事实、法律法规和相似案例来提高预测效果和解释质量。", "innovation": "提出了NyayaRAG，这是一种检索增强生成（RAG）框架，通过提供模型事实案例描述、相关法律条文及语义上检索到的先例信息来模拟真实的法庭场景。该框架采用了定制的领域特定管道来适应印度法律系统，并通过广泛使用的语言模型评估工具（如G-Eval）以及标准的词法和语义度量来评估其性能。研究表明，将事实输入与结构化的法律知识结合起来可以显著提高预测准确性和解释质量，弥补了以前方法的不足。", "conclusion": "NyayaRAG框架在印度法律系统下表现出了优越的性能，在各种输入配置下显示出在预测法院判决以及生成法律解释方面具有显著的优势。这种将事实与结构化法律知识结合的方法为提升司法判决预测的准确性和解释性提供了有效的解决方案。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14912", "html_url": "https://arxiv.org/abs/2509.14912", "title": "回归耳朵：基于听觉驱动的高保真音乐重建", "title_en": "Back to Ear: Perceptually Driven High Fidelity Music Reconstruction", "authors": "Kangdi Wang,Zhiyue Wu,Dinghao Zhou,Rui Lin,Junyu Dai,Tao Jiang", "background": "变分自编码器（VAEs）在基于扩散的过程的大规模音频任务中至关重要，但是现有的开源模型在训练过程中通常会忽视听觉感知方面，导致相位准确性差和立体声空间表示能力弱。", "innovation": "提出了εar-VAE，一种开源音乐信号重建模型，重新思考并优化VAE的训练理念。主要创新点包括：(i) 基于K加权听觉感知滤波器，在损失计算之前对目标进行对齐；(ii) 两种新的相位损失：相关损失用于立体声连贯性，相位损失及其导数瞬时频率和群时延用于精确度；(iii) 新的光谱监督范式，其中幅度由中侧左右四个组件监督，而相位仅由LR组件监督。", "conclusion": "实验表明，在44.1kHz采样率下，εar-VAE在多种指标上均显著优于现有的顶级开源模型，尤其是在高频率谐波和空间特征重建方面表现出特别的强项。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.10641", "html_url": "https://arxiv.org/abs/2509.10641", "title": "Test-Time Warmup for Multimodal Large Language Models", "title_en": "Test-Time Warmup for Multimodal Large Language Models", "authors": "Nikita Rajaneesh,Thomas Zollo,Richard Zemel", "background": "多模态大型语言模型（MLLMs）在文本和图像的高级推理方面具有巨大潜力，但尚未充分发挥其潜力。MLLMs 通常结合了一个大型语言模型（LLM）、一个视觉编码器和一个连接器，将视觉编码器的嵌入映射到LLM 的文本嵌入空间中。尽管每个组件都对包含数十亿样本的大型数据集进行了预训练，整个多模态模型通常仅在数千（或数百万）样本上进行训练，导致在复杂的推理任务上表现较弱。因此，这些模型在精细调优时依赖于广泛的标注数据。", "innovation": "本文提出了一个试验时间预热方法（Test-Time Warmup），该方法通过利用来自弱监督辅助任务的数据来适应每个测试实例的MLLM。这种方法在LLama-Vision-Instruct模型上观察到，MMMU上相对提升了4.03%，VQA-Rad上相对提升了5.28%，GQA上相对提升了1.63%。该方法表明，在推理前预热可以增强多模态大型语言模型在多种推理任务中的鲁棒性。", "conclusion": "试验时间预热方法可以提升多模态大型语言模型的性能，并在不同类型的推理任务中增强其鲁棒性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10528", "html_url": "https://arxiv.org/abs/2508.10528", "title": "Med-GLIP: 使用大规模数据集推进医学语言-图像预训练", "title_en": "Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset", "authors": "Ziye Deng,Ruihan He,Jiaxiang Liu,Yuan Wang,Zijie Meng,Songtao Jiang,Yong Xie,Zuozhu Liu", "background": "医学图像语义化旨在将自然语言短语与医学图像中的特定区域对齐，是智能诊断、视觉问答(VQA)和自动化报告生成(MRG)的基础任务。但现有研究受限于模态覆盖有限、标注粗糙以及缺乏统一且可泛化的语义化框架。针对这些挑战，研究人员构建了包含超过530万区域级标注、覆盖七大成像模态的大规模医学数据集Med-GLIP-5M，支持分割和语义化任务，具有从器官级别边界到细粒度病灶的层次化区域标签。基于该数据集，提出了一种模态感知语义化框架Med-GLIP，无需依赖显式设计的专家模块，而是从多样化的训练数据中隐式获得层次化语义理解，能够识别多粒度结构，如区分肺部和肺炎病灶。实验表明，Med-GLIP在多个语义化基准测试中表现优于最先进的基线，并且将其空间输出集成到下游任务中，包括医学VQA和报告生成，也显著提升了性能。", "innovation": "1. 构建了Med-GLIP-5M，这是包含超过530万区域级标注的大规模医学数据集，覆盖多种成像模态、多种解剖结构和病理发现，支持分割和语义化任务。2. 提出了Med-GLIP框架，这是一个模态感知的语义化框架，能够隐式地从多样化的训练数据中获得层次化的语义理解，能够识别多粒度结构。", "conclusion": "Med-GLIP在多个语义化基准测试中表现优异，并且将其空间输出集成到医学VQA和报告生成等下游任务中，也大幅提升了效果。数据集Med-GLIP-5M将很快公布。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01794", "html_url": "https://arxiv.org/abs/2509.01794", "title": "一种用于预测疫情时期心血管疾病生物标志物的多目标贝叶斯变换器框架", "title_en": "A Multi-target Bayesian Transformer Framework for Predicting Cardiovascular Disease Biomarkers during Pandemics", "authors": "Trusting Inekwe,Winnie Mkandawire,Emmanuel Agu,Andres Colubri", "background": "COVID-19大流行扰乱了全球的卫生系统，尤其是对患有心血管疾病（CVD）等慢性疾病的个体有不成比例的影响。这些扰乱通过延迟护理和行为改变，影响了关键的CVD生物标志物，包括低密度脂蛋白胆固醇（LDL-C）、糖化血红蛋白（HbA1c）、体质指数（BMI）和收缩压（SysBP）。准确地预测这些变化对于预测疾病进展和指导预防护理至关重要。然而，之前的研究所没有解决从电子健康记录（EHR）数据中使用机器学习（ML）联合预测CVD生物标志物的问题，同时捕捉生物标志物之间的相互依赖性、时间模式和预测不确定性。", "innovation": "本文提出了一种多目标贝叶斯变换器（MBT-CB），这是一种基于预训练BERT的多目标贝叶斯变换器，该框架可以从EHR数据中联合预测CVD生物标志物，包括LDL-C、HbA1c、BMI和SysBP。该模型利用贝叶斯变分推理估计不确定性，使用嵌入来捕获时间关系，并使用DeepMTR模型来捕获生物标志物之间的关系。在麻萨诸塞州中心地区3,390例CVD患者记录（304名独特患者）的回顾性EHR数据上评估了MBT-CB，其性能优于其他基线模型，包括其他基于BERT的机器学习模型，达到了MAE 0.00887、RMSE 0.0135和MSE 0.00027，同时有效地捕捉了数据和模型不确定性、患者生物标志物之间的关系和时间动态。", "conclusion": "MBT-CB的卓越性能突显了其在预测CVD生物标志物和疫情期间支持临床决策方面的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.09958", "html_url": "https://arxiv.org/abs/2509.09958", "title": "零样本视觉语言真/假验证实现参考表达理解", "title_en": "Zero-Shot Referring Expression Comprehension via Vison-Language True/False Verification", "authors": "Jeffrey Liu,Rongbin Hu", "background": "目前，参考表达理解(REC)通常通过任务特定的定位模型来处理。这项研究展示了即使没有针对REC的特定训练，零样本流程也可以获得具有竞争力或更优的效果。研究将REC重新定义为基于区域的视觉语言验证问题：给定YOLO-World这样的COCO清洁版通用检测器生成的提案，一个通用目的的VLM可以独立地对每个区域回答真/假查询。这种方法简化了跨框干扰，支持拒绝和多个匹配，并不需要微调。", "innovation": "本文创新地将参考表达理解问题转化为基于区域的视觉语言验证问题，并采用零样本工作流程，无需针对特定任务进行训练，仅依靠通用视觉语言模型进行真/假判断，这种方法简化了跨盒干扰，支持拒绝和多个匹配，不需要微调，并且在RefCOCO、RefCOCO+和RefCOCOg数据集上的表现超过了零样本基线和已报告的经过参考表达理解特定训练的GroundingDINO以及加CRG的GroundingDINO的表现。此外，实验证明真/假验证方式优于基于选择的提示方式，并且结果对开放的VLM具有稳定性和可复制性。", "conclusion": "研究表明，工作流程设计而非特定任务的预训练，对零样本参考表达理解的强性能具有推动作用。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.08217", "html_url": "https://arxiv.org/abs/2509.08217", "title": "平衡质量与多样性：spam过滤扭曲数据标签分布", "title_en": "Balancing Quality and Variation: Spam Filtering Distorts Data Label Distributions", "authors": "Eve Fleisig,Matthias Orlikowski,Philipp Cimiano,Dan Klein", "background": "为了使机器学习数据集准确反映人群中的各种意见，这些数据必须保护数据标签的变异性，同时过滤掉无用或质量低下的响应。如何在确保标注员可靠性和代表性的前提下实现这一目标，论文进行了探讨。现有的过滤策略旨在消除单一真实标签源的数据变异性，这通常会导致合格的同时持有不同意见的标注员被错误地删除，从而在准确性和标签多样性之间产生不理想的权衡关系。研究还指出，现有方法往往假设spam标注员比实际的spam标注者更具随机性，但事实上，大多数spam标注者的行为与真实标注者难以区分，且少数区别开来的也并非随机给出，而是给出相对固定的答案。因此，需要开发出能够考虑标签多样性的spam删除方法，来避免现有策略引发的问题。", "innovation": "研究实证评估了一系列标注员过滤策略对主观任务变异性保真度的影响，发现这些方法在某些情况下会无意中删除了对数据集有重要贡献的标注员，而保留了质量低下的或可能是spam的标注员。研究进一步分析了对合成spam的性能表现，揭示了现有spam过滤方法的潜在缺陷和不足，强调了需要设计更有效的spam过滤策略，既能提高数据质量，又能保留标注员之间的多样化标签特征。", "conclusion": "研究指出，为了保护数据集中的标签多样性，应采用更为保守的标注员淘汰策略（<5%），因为超过这个阈值会导致平均绝对误差增加。同时，现有的spam过滤方法往往假设变异性即为spam，但实际上这是错误的，确保了标签多样性的重要性的任务会反过来影响这些现有的spam过滤策略的效果。因此，需要开发适应标签多样性的spam删除方法，来解决这一问题。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.15482", "html_url": "https://arxiv.org/abs/2509.15482", "title": "使用表示相似性分析比较计算病理学基础模型", "title_en": "Comparing Computational Pathology Foundation Models using Representational Similarity Analysis", "authors": "Vaibhav Mishra,William Lotter", "background": "计算病理学(CPath)中的基础模型正在不断发展，因为它们在促进许多下游任务方面具有潜力。尽管最近的研究已经评估了不同模型的任务性能，但关于这些模型学习表示的结构和变异性的了解仍然有限。本文系统地分析了六种CPath基础模型的表示空间，使用了受计算神经科学启发的技术。研究发现，UNI2和Virchow2的基础表示结构最为独特，而Prov-Gigapath在不同模型之间的平均相似性最高。", "innovation": "通过使用H&E染色图像斑块进行表示相似性分析，研究发现，虽然所有模型的基础表示都显示出明显的幻灯片依赖性，但相对较低的疾病依赖性。此外，不同的训练范式（视觉和视觉语言）并不保证更高的表示相似性。规范染色降低了所有模型的幻灯片依赖性，幅度从CONCH的5.5%到PLIP的20.5%不等。视觉语言模型显示了相对紧凑的表示，而视觉仅模型则具有更分散的表示。这些发现强调了提高对幻灯片特异性特征鲁棒性、指导模型集成策略以及深入理解训练范式如何塑造模型表示的机遇。", "conclusion": "研究结果为支持基础模型的有效开发和部署提供了框架，可在医学成像领域广泛应用，通过探索基础模型的内部表示来促进其发展和部署。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05132", "html_url": "https://arxiv.org/abs/2510.05132", "title": "利用全局分叉令牌并行训练大型语言模型进行推理", "title_en": "Training Large Language Models To Reason In Parallel With Global Forking Tokens", "authors": "Sheng Jia,Xiao Wang,Shiva Prasad Kasiviswanathan", "background": "尽管通过扩展并行测试时计算能力，大语言模型（LLMs）已经展示了改进的性能，但这种方法依赖于生成既多样化又正确的推理路径。对于具有挑战性的问题，触发多样化且正确的推理模式的分叉代币通常位于采样树的深处。因此，鼓励多样性的常见策略，如温度缩放，会导致多样性和准确性的恶化。", "innovation": "本文提出了一种并行推理的集合下一令牌预测问题，并在监督微调（SFT）中引入了一种基于集合的全局损失，通过自我监督的二分图匹配，将我们全局分叉令牌与独特推理路径匹配。实验证明，我们的新方法并集监督微调（SSFT）保持了这些独特模式，并产生新兴的全局分叉令牌。", "conclusion": "我们在多个推理基准上进行的实验证明，我们的SSFT方法在Pass@1和Cons@k度量下始终优于SFT。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18629", "html_url": "https://arxiv.org/abs/2509.18629", "title": "HyperAdapt：简单的高秩适应", "title_en": "HyperAdapt: Simple High-Rank Adaptation", "authors": "Abel Gurung,Joseph Campbell", "background": "基础模型在多种任务上表现出色，但将其应用于特定应用通常需要调优，这需要大量的内存和计算。参数高效调优（PEFT）方法通过只更新一小部分权重来缓解这一问题。本文介绍了一种参数高效的调优方法——HyperAdapt，与当前领先的PEFT方法如LoRA相比，它显著减少了可训练参数的数量。HyperAdapt通过在预训练权重矩阵上应用行和列的缩放，从而实现高秩更新，仅需要对于一个n×m矩阵的n+m个可训练参数即可实现。实验表明，HyperAdapt在GLUE、算术推理和常识推理基准测试中与全量调优和当前最先进的PEFT方法的性能相当，同时使用的可训练参数要少得多。", "innovation": "提出了一种名为HyperAdapt的参数高效调优方法，与当前最先进的方法相比，它显著减少了可训练参数的数量，并通过在预训练权重矩阵上应用行和列的缩放来实现高秩更新，仅需要n+m个可训练参数，实验表明其性能接近甚至超过完全调优和最先进的PEFT方法。", "conclusion": "HyperAdapt在大规模模型上展示了卓越的性能，通过减少可训练参数数量，实现了与传统调优方法相近的效果。该方法为大规模模型的应用提供了有效解决方案。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07871", "html_url": "https://arxiv.org/abs/2510.07871", "title": "通过前瞻性风险感知学习社交导航", "title_en": "Learning to Navigate Socially Through Proactive Risk Perception", "authors": "Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao", "background": "该论文描述了作者对于IROS 2025 RoboSense挑战赛Social Navigation赛道的技术提交细节。该赛道的主要目标是在动态的人群环境中实现安全、高效且符合社会规范的自主导航，仅依赖于车载传感器（如RGB-D观察和里程计数据）进行操作，而不使用全局地图或其他特权信息。挑战要求自主代理必须能在第一人称视角环境中，保持适当的社会行为如安全距离和避免碰撞。", "innovation": "本文的创新之处在于引入了前瞻性风险感知模块，该模块增强了Falcon模型以提高社交导航性能。这一模块能学习预测周围人类的基于距离的碰撞风险分数，从而帮助代理发展更加 robust的三维感知能力和前瞻性碰撞规避行为。", "conclusion": "在Social-HM3D基准测试中的评估证明，该方法提高了代理在拥挤室内环境中的个人空间合规性，有助于在目标导航过程中同时避免碰撞。在16个参赛团队中，该方法取得第二名的好成绩，表明模型的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.24239", "html_url": "https://arxiv.org/abs/2509.24239", "title": "ChessArena：评估大型语言模型战略推理能力的国际象棋实验", "title_en": "ChessArena: A Chess Testbed for Evaluating Strategic Reasoning Capabilities of Large Language Models", "authors": "Jincheng Liu,Sijun He,Jingjing Wu,Xiangsen Wang,Yang Chen,Zhaoqi Kuang,Siqi Bao,Yuan Yao", "background": "近年来，大型语言模型（LLMs）展现出了强大的推理能力。然而，一个至关重要的问题仍然存在：这些模型是否具备真正的战略推理能力，尤其是在复杂的策略层面上，还是主要擅长在训练数据中识别复杂的模式？为了解决这个问题，本研究提出了一个国际象棋实验环境ChessArena，用于评估LLMs的战略推理能力。国际象棋需要复杂的策略推理能力，包括长期规划、规则理解以及多回合对话的记忆。", "innovation": "本研究设计并实施了一个名为ChessArena的竞争框架，让LLMs在四种不同的模式下相互对弈。ChessArena配有一套排名算法和排行榜，可用于评估包括基本理解、移动选择和解谜在内的细致能力。此外，研究还评估了13种不同模式的LLMs在ChessArena中的表现，共进行了800多场比赛。研究结果揭示了当前LLMs的重大局限性：没有模型能够战胜Maia-1100（一个处于人类业余水平的棋手），甚至有些模型连随机选择的对手都赢不了。研究还提供了一个基准线展现：我们微调的Qwen3-8B显著提高了性能，与大规模的先进推理模型接近。", "conclusion": "当前的大型语言模型在战略推理能力上存在显著不足，特别是复杂的策略层面。尽管一些微调后的模型取得了显著进步，但这些模型仍然难以匹敌优秀的传统棋手。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11903", "html_url": "https://arxiv.org/abs/2510.11903", "title": "集成序列和关系建模的用户事件：数据集和预测任务", "title_en": "Integrating Sequential and Relational Modeling for User Events: Datasets and Prediction Tasks", "authors": "Rizal Fathony,Igor Melnyk,Owen Reinert,Nam H. Nguyen,Daniele Rosa,C. Bayan Bruss", "background": "用户事件建模在电子商务、社交媒体、金融、网络安全等领域等多个机器学习应用中扮演着关键角色。用户事件可分为个人事件和关系事件，前者涉及个体行为，后者涉及两个用户之间的交互。尽管这些事件类型在现实系统中都需要捕捉，但之前的研究很少将它们结合起来。这是因为人们通常认为用户行为可以通过单一的形式化方法（序列或图）充分代表。为了填补这一缺口，需要包含个人和关系事件的公开数据集和预测任务。", "innovation": "本文提出了一组既包含个人事件又包含关系事件的公开数据集，并提出了一种统一的形式化方法。实验证明，结合这两类事件可以使模型受益。研究结果还表明，现有方法在这一领域仍有显著改进空间。", "conclusion": "我们提供了这些资源，以支持统一用户事件模型的研究，鼓励在这一方向上进一步进展。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14955", "html_url": "https://arxiv.org/abs/2510.14955", "title": "RealDPO：真实的还是不真实的，这就是偏好", "title_en": "RealDPO: Real or Not Real, that is the Preference", "authors": "Guo Cheng,Danni Yang,Ziqi Huang,Jianlou Si,Chenyang Si,Ziwei Liu", "background": "视频生成模型在合成质量上取得了显著进步，但生成复杂的运动仍然是一个关键挑战。现有模型往往难以产生自然、平滑和语境一致的运动。这种生成运动与真实世界运动之间的差距限制了它们的实际应用。", "innovation": "提出了一个名为RealDPO的新颖对齐范式，该范式利用真实世界数据作为偏好学习的正样本，从而实现更准确的运动合成。不同于传统的监督微调（SFT），RealDPO 使用带定制损失函数的直接偏好优化（DPO）来增强运动的现实感。通过对比真实世界视频与错误的模型输出，RealDPO 能够实现迭代自我纠正，逐步提高运动质量。", "conclusion": "通过实验证明，RealDPO 显著提升了视频质量、文本对齐和运动现实感，优于现有最佳模型和存在的偏好优化技术。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12829", "html_url": "https://arxiv.org/abs/2510.12829", "title": "大型语言模型作为证明者和验证者的数学思维", "title_en": "Mathematics with large language models as provers and verifiers", "authors": "Hieu Le Duc,Leo Liberti", "background": "2024年至2025年期间，关于大型语言模型的定理证明能力的讨论引起了关注，这些模型在解决一些复杂的问题上表现出色，比如国际数学奥林匹克竞赛的问题。在此背景下，论文报告了ChatGPT利用不同实例的gpt-5模型共同协作证明定理的情况。为确保生成的证明没有幻觉，最终的证明由lean证明助手正式验证，人再验证lean代码的前提和结论的一致性。", "innovation": "论文展示了大型语言模型如何通过协作（包括不同的证明者和验证者实例）实现复杂的数学证明，并提出了一种方法来验证生成证明的正确性。虽然该方法尚未完全成熟，但ChatGPT仍然成功解决了2025年IMO的五个问题，并接近解决了《整数序列杂志》2025年提出的66个数论猜想中的三分之一。", "conclusion": "论文的方法在确保生成证明的准确性方面显示出一定的潜力，尽管还存在改进的空间。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07960", "html_url": "https://arxiv.org/abs/2510.07960", "title": "自我监督学习在可穿戴EEG高效睡眠阶段分类中的系统评估", "title_en": "A Systematic Evaluation of Self-Supervised Learning for Label-Efficient Sleep Staging with Wearable EEG", "authors": "Emilio Estevan,María Sierra-Torralba,Eduardo López-Larraz,Luis Montesano", "background": "可穿戴EEG设备已成为多导睡眠图（PSG）的有希望的替代方案。它们的广泛采用产生了大量未标记者数据，难以大规模分析。尽管深度学习在睡眠评分方面取得成功，但依赖大规模标注数据集。自我监督学习（SSL）能够利用未标记者数据解决标签稀缺问题，减少标注工作量。本文对使用可穿戴EEG进行睡眠阶段分类的SSL方法进行了首次系统评估。", "innovation": "研究了多种成熟的SSL方法，并在Ikon Sleep公司生产的不同数据库上进行了评估。通过定义三种评估场景，研究标签效率、表示质量和跨数据库泛化能力。SSL方法在缺乏标签数据时，提高分类性能最多可达10%，且仅需5%到10%的标签数据即可达到临床级准确性。此外，SSL表示在不同人群特征、记录环境和信号质量方面具有鲁棒性。这些发现展示了SSL在可穿戴EEG中实现高效睡眠阶段分类的潜力，减少了对手动标注的依赖，推动了经济实惠的睡眠监测系统的发展。", "conclusion": "SSL方法通过有效利用未标记者数据，提高分类性能并减少标注需求，为可穿戴EEG在睡眠监测中的应用提供了新的可能性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.13865", "html_url": "https://arxiv.org/abs/2510.13865", "title": "Deep Edge Filter：深度学习中的返璞归真——人类设计层的回归", "title_en": "Deep Edge Filter: Return of the Human-Crafted Layer in Deep Learning", "authors": "Dongkwan Lee,Junhoo Lee,Nojun Kwak", "background": "论文背景在于现有深度神经网络在编码任务相关信息时倾向于利用高频成分，而低频成分为具体领域的偏差信息，基于这种观察，文章提出了一种新颖的方法——Deep Edge Filter。该方法通过对比原始特征和低通滤波后的特征，提取出更通用的特征表示，同时保持模型结构完整性。实验在视觉、文本、3D和音频等多个领域验证了该方法的一致性改进效果。分析表明，该方法可以实现特征稀疏化，有效区分高频成分，这与文章的核心假设一致。", "innovation": "创新点在于提出了一种新的方法Deep Edge Filter，该方法通过高通滤波技术对深度神经网络特征进行处理，从而提高模型的泛化能力。方法的关键在于提出了一种新的假设，即神经网络在高频率成分中编码了任务相关信息，而在低频率成分中存储了领域特异性偏差。通过这种方法，可以有效地提取出更具泛化能力的特征，保持模型结构完整性。实验结果表明，该方法具有广泛的适用性和有效性。", "conclusion": "研究结果表明，Deep Edge Filter方法在多个领域的一致性改进效果支持了该方法的有效性，并且实验分析表明该方法可以通过特征稀疏化和分离高频成分实现更好的泛化性能，验证了所提出的假设。该方法提供了一种新的视角和工具，用于提高深度学习模型的泛化能力。源代码可以在指定链接找到。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17923", "html_url": "https://arxiv.org/abs/2510.17923", "title": "旅途奖励机制：一种用于测试时强化学习的复合路径和答案自评分奖励机制", "title_en": "Rewarding the Journey, Not Just the Destination: A Composite Path and Answer Self-Scoring Reward Mechanism for Test-Time Reinforcement Learning", "authors": "Chenwei Tang,Jingyu Xing,Xinyu Liu,Wei Ju,Jiancheng Lv,Fan Zhang,Deng Xiong,Ziyue Qiao", "background": "强化学习(RL)已成为提高大型语言模型(LLMs)性能的强大范式，在数学和代码生成等复杂推理领域取得了显著成效。然而，当前的RL方法因高度依赖人类标注的偏好数据或带标签的数据集进行奖励建模而面临基本的可扩展性瓶颈。为克服这一限制，本研究探索了使用未标注数据进行RL的方法，通过模型从连续的经验流中自我学习。这一设置的核心挑战在于没有真实标签监督的情况下如何可靠地估计奖励。", "innovation": "引入了一种新颖的测试时奖励机制——COMPASS（Composite Path and Answer Self-Scoring），该机制在无需外部监督的情况下工作。COMPASS结合了两种互补的组件：Dual-Calibration Answer Reward (DCAR)，通过信心和可信度校准稳定训练并建立可信的伪标签，以及Decisive Path Reward (DPR)，直接优化推理过程的质量而不仅仅是结果监督。通过同时强化可信共识答案和高度决断的推理链，COMPASS系统地提升了模型的分析能力。", "conclusion": "详尽的实验表明，COMPASS在各种推理任务和模型架构上实现了一致且显著的性能提升，为LLMs从连续经验中学习提供了更可扩展的方向。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.22379", "html_url": "https://arxiv.org/abs/2510.22379", "title": "TraceTrans: Translation and Spatial Tracing for Surgical Prediction", "title_en": "TraceTrans: Translation and Spatial Tracing for Surgical Prediction", "authors": "Xiyu Luo,Haodong Li,Xinxing Cheng,He Zhao,Yang Hu,Xuan Song,Tianyang Zhang", "background": "图像到图像翻译模型已经在不同视觉领域的图像转换中取得了显著的成功，并逐渐被用于医疗任务，如预测术后结果和模拟疾病进展。然而，现有方法大多主要目标是匹配目标分布，往往忽视源图像和生成图之间的空间对应关系。这一局限性可能导致结构性不一致和幻觉，削弱预测的可靠性和可解释性。这些挑战在临床应用中被放大，因为严格的解剖准确性要求更加严格。", "innovation": "本文介绍了一种名为TraceTrans的新型变形图像翻译模型，专门设计用于术后预测。它既能生成与目标分布一致的图像，又能明确揭示与术前输入的空间对应关系。框架中采用了编码器进行特征提取，以及双边解码器分别用于预测空间变形和合成转换图像。预测出的变形场会对生成输出施加空间约束，确保与源图像的解剖一致性。", "conclusion": "在医学美容和脑MRI数据集上的广泛实验表明，TraceTrans能够提供准确和可解释的术后预测，强调了其在可靠临床部署中的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.21814", "html_url": "https://arxiv.org/abs/2510.21814", "title": "Gestura：一种实现实时自由形态手势理解的视觉语言大模型赋能系统", "title_en": "Gestura: A LVLM-Powered System Bridging Motion and Semantics for Real-Time Free-Form Gesture Understanding", "authors": "Zhuoming Li,Aitong Liu,Mengxi Jia,Yubi Lu,Tengxiang Zhang,Changzhi Sun,Dell Zhang,Xuelong Li", "background": "自由形态手势理解对于人机交互具有极高的吸引力，因为它能够使用户摆脱预定义手势类别的限制。然而，现有唯一解决方案GestureGPT在识别准确性和响应时间方面都存在局限性。因此，本研究提出了一种端到端的系统Gestura，该系统利用预训练的大规模视觉-语言模型（LVLM）将自由形态手势的动态和多样化模式与高级语义概念进行对齐。", "innovation": "Gestura引入了骨骼点处理模块，通过嵌入解剖手的先验知识来补偿LVLM在细粒度领域知识上的不足，以便更好捕捉不同风格下的细微手部动作。进一步地，引入了一种逐步推理策略（Chain-of-Thought，CoT），可以逐步进行语义推理，将浅层知识转化为深层语义理解，显著提高了模型解释模糊或不常规手势的能力。此外，Gestura还开发了首个用于自由形态手势意图推理和理解的开源数据集，包含超过30万标注的问答对。", "conclusion": "通过这些组件，Gestura能够实现稳健且适应性强的自由形态手势理解。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18913", "html_url": "https://arxiv.org/abs/2510.18913", "title": "ADPO: 锚定直接偏好优化", "title_en": "ADPO: Anchored Direct Preference Optimization", "authors": "Wang Zixian", "background": "直接偏好优化（DPO）虽然有效，但在标注员噪音和数据分布变化的情况下表现脆弱。DPO 基于硬的成对标签进行操作，并且只能通过对数概率差异进行正则化。因此，它在处理这类问题时表现不稳定。研究者引入了锚定直接偏好优化（ADPO）框架，它通过参考锚点将偏好学习扩展到软的列表级监督。ADPO 使用最小化 KL(q || softmax((s - s_ref) / tau_anc)) 的方法，实现了在特定目标 q、锚点策略及温度选择时可以恢复监督微调、知识蒸馏、最大熵强化学习和 DPO 的特例，同时存在一个由 softmax 汤米度量引导的隐式信任区域，独立于锚点。此外，ADPO 支持动态锚点更新，以实现稳健性。该方法在不同任务中展现了噪声下的在线探索改进以及在离线蒸馏中的卓越性能，可实现高达 170 到 5000 倍的学生-教师 KL 减少，证明了其在算法鲁棒性和有效性方面的改进", "innovation": "ADPO 引入了一个新的框架，该框架通过参考锚点将偏好学习扩展到软的列表级监督。ADPO 可以通过选择适当的目标 q、锚点策略和温度参数恢复监督微调、知识蒸馏、最大熵强化学习和 DPO 的特性，并且具有独立于锚点的隐式信任区域，可进行动态锚点更新，从而提高算法的稳定性和有效性。", "conclusion": "实验证明，ADPO 在噪声环境下的在线探索改善效果和离线蒸馏中的表现要优于 DPO，其中固定锚点在离线蒸馏方面的表现尤为出色，能够将学生-教师的 KL 减少高达 170 到 5000 倍，在不同任务中展现了更高的算法鲁棒性和有效性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.01019", "html_url": "https://arxiv.org/abs/2511.01019", "title": "OceanAI: 一个准确、透明、接近实时的海洋观测对话平台", "title_en": "OceanAI: A Conversational Platform for Accurate, Transparent, Near-Real-Time Oceanographic Insights", "authors": "Bowen Chen,Jayesh Gajbhar,Gregory Dusek,Rob Redmon,Patrick Hogan,Paul Liu,DelWayne Bohnenstiehl,Dongkuan Xu,Ruoying He", "background": "人工智能正在改变科学领域，但通用的对话型人工智能系统往往生成未验证的‘幻觉’，这些幻觉可能削弱科学的严谨性。因此，本文提出了一款名为OceanAI的对话平台。OceanAI结合了开源大型语言模型的自然语言流畅性和实时访问由美国国家海洋和大气管理局（NOAA）托管的真实海洋数据流的能力。当用户提出查询时，OceanAI会实时调用API，查找、解析和综合相关的数据集，生成可重现的自然语言回复和数据可视化。", "innovation": "OceanAI创新之处在于它能够实时访问来自NOAA的权威海洋数据，并对用户查询进行准确、透明的回复。与其他AI对话产品相比，OceanAI能够提供来自NOAA的数据来源，确保结果的可靠性和可验证性。此外，OceanAI具有扩展性，可以连接多个NOAA数据产品和变量，支持海洋灾害预报、生态系统评估和水质监测等多种应用场景。", "conclusion": "OceanAI通过实现输出和可验证的观察，增强了透明度、可靠性和信任度，提供了一个可扩展的框架，使AI能够在海洋科学领域提供决策支持。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26722", "html_url": "https://arxiv.org/abs/2510.26722", "title": "非凸的空中异构联邦学习: 偏差-方差权衡", "title_en": "Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off", "authors": "Muhammad Faraz Ul Abrar,Nicolò Michelusi", "background": "空中联邦学习（OTA-FL）已广泛认可为一种利用无线多址信道波形叠加来在单一使用中聚合模型更新的可扩展框架。现有的OTA-FL设计主要通过假设或强迫无偏模型更新来维持零偏见，以确保在同构无线场景下收敛。然而，在异构无线场景下，这些设计受到最弱设备的限制，导致更新方差增大。此外，先前对有偏OTA-FL的分析主要针对凸目标函数，而大多数现代AI模型则高度非凸。鉴于这些差距，本文研究了在无线异构场景下，使用随机梯度下降（SGD）的一般平滑非凸目标函数的OTA-FL。", "innovation": "本文提出了在无线异构场景下，带模型偏差的一般平滑非凸目标函数的OTA-FL SGD更新方法，同时减少了方差更新。推导了有限时间内非全局最小点收敛性界（预期时间平均梯度平方范数），并揭示了偏差-方差权衡。通过非凸联合空中功率控制设计，提出了一种基于统计CSI的高效的逐次凸松弛算法。实验表明，基于非凸SGD的OTA-FL联合空中功率控制设计通过优化偏差加速了收敛，并且相比于以往的OTA-FL基线方法提高了泛化能力。\n", "conclusion": "通过采用随机梯度下降算法，并针对一般平滑非凸目标函数研究了非凸的空中异构联邦学习，在揭示了偏差-方差权衡的基础上，设计了一种高效的祸合空中功率控制方案，实验结果表明这种方案能提高模型的收敛速度和泛化能力。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.00105", "html_url": "https://arxiv.org/abs/2511.00105", "title": "人工智能在基础STEM教育中的应用：当前应用及未来挑战的系统综述", "title_en": "Artificial Intelligence in Elementary STEM Education: A Systematic Review of Current Applications and Future Challenges", "authors": "Majid Memari,Krista Ruggles", "background": "人工智能正在转型基础STEM教育，然而相关证据仍较为零散。这项系统综述综合了2020年至2025年间共258项研究，这些研究涵盖八个类别：智能辅导系统（45%的研究）、学习分析（18%）、自动评估（12%）、计算机视觉（8%）、教育机器人（7%）、多模态传感（6%）、增强现实（XR）的人工智能增强（4%）以及适应性内容生成。分析表明，大多数研究集中在高年级小学生（占65%）和数学（占38%）领域，并且跨学科STEM整合有限（仅占15%）。虽然对话式人工智能表现出一定的有效性（d值在0.45-0.70之间），但只有34%的研究纳入了标准化效果量。", "innovation": "该研究系统地回顾了2020年至2025年间258篇关于人工智能在基础STEM教育中应用的相关研究，并总结了这些研究的发现，特别是在各个应用类别中的分布情况，强调了当前应用中的8个主要缺口，包括碎片化的生态系统、发展不适宜性、基础设施障碍、缺乏隐私框架、STEM整合薄弱、公平性差距、教师边缘化和评估范围狭窄。并且指出了地理分布的不均衡性。", "conclusion": "未来需要支持真实的STEM整合的互操作架构、适合学段的设计、保护隐私的分析技术和以教师为中心的实现方式，来增强而非取代人类的专业知识。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.21849", "html_url": "https://arxiv.org/abs/2510.21849", "title": "TowerVision: 理解并提高视觉语言模型中的多语种能力", "title_en": "TowerVision: Understanding and Improving Multilinguality in Vision-Language Models", "authors": "André G. Viveiros,Patrick Fernandes,Saul Santos,Sonal Sannigrahi,Emmanouil Zaranis,Nuno M. Guerreiro,Amin Farajian,Pierre Colombo,Graham Neubig,André F. T. Martins", "background": "尽管视觉语言模型（VLMs）取得了显著进展，但大多数现有工作都采用以英文为中心的设计流程，这限制了它们在多语种环境中的效果。本文通过全面的经验研究分析了训练数据组成、编码器选择和文本主干等多种多语种设计的选择对模型性能的影响。研究表明，可视和文化背景在微调过程中对模型性能有显著提升作用。同时，发布了一个高质量的数据集VisionBlocks，证明多语种视觉语言训练数据在跨语言泛化方面有着显著改善，不仅从资源丰富的语言到资源匮乏的语言，反之亦然。此外，还表明指令调优的语言模型未必总是最佳初始化点。", "innovation": "本文提出了一种多语种视觉语言模型的家族——TowerVision，它是在多语种文本模型Tower+的基础上构建的，可以应用于图像-文本和视频-文本任务。通过在微调过程中结合视觉和文化背景信息，TowerVision在ALM-Bench、Multi30K（图像任务）和ViMUL-Bench（视频任务）上实现了卓越的性能，超越了在更大数据集上训练的现有方法，表明多语种文本训练数据能够显著提高跨语言环境中的泛化能力。此外，还公开了所有模型、数据和训练食谱，以支持进一步研究。", "conclusion": "本文通过全面的研究分析了多语种视觉语言模型的关键设计选择的影响，提出了TowerVision这一多语种视觉语言模型系列，并通过多模态多语种基准测试展示了其优越性。同时，发布了高质量的数据集VisionBlocks，强调多语种视觉语言训练数据在跨语言泛化中的重要作用，以及指令调优的语言模型并不总是最优的初始化点这一结论。此外，所有模型、数据和训练食谱均公开发布，为后续研究提供了支持。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.02531", "html_url": "https://arxiv.org/abs/2511.02531", "title": "因果图神经网络在医疗健康领域的应用", "title_en": "Causal Graph Neural Networks for Healthcare", "authors": "Munib Mesinovic,Max Buhlan,Tingting Zhu", "background": "在医疗机构部署的人工智能系统通常在实际应用中表现出脆弱性，性能下降并固化历史数据中的歧视模式。这种脆弱性部分源于系统学习统计关联而非因果机制。", "innovation": "因果图神经网络通过结合基于图的生物医学数据表示和因果推断原则，以学习不变的机制而非虚假的关联，以此解决分布变化、歧视和晦涩难懂的三重危机。", "conclusion": "虽然取得了重大进展，但仍然存在重大障碍，包括计算要求不允许实时部署、验证挑战需要多模态证据三角化超过交叉验证，以及通过因果术语使用方法但缺乏严格的证据支持的因果漂白风险。本文提议分层框架区分因果启发式架构和因果验证发现，并确定关键研究优先事项，使因果推断而非纯粹关联性声明变得重要。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.00847", "html_url": "https://arxiv.org/abs/2511.00847", "title": "为第二最优服务付费：博弈论方法对抗不诚实的大语言模型提供商", "title_en": "Pay for The Second-Best Service: A Game-Theoretic Approach Against Dishonest LLM Providers", "authors": "Yuhan Cao,Yu Wang,Sitong Liu,Miao Li,Yixin Tao,Tianxing He", "background": "论文背景在于广泛采用通过应用程序编程接口（API）提供的大语言模型（LLMs）所引起的关键脆弱性：服务提供商可能进行不诚实操控，例如秘密替换高性能模型为低成本替代品，或在答复中增加无意义的令牌以增加计费。这种操控通过算法博弈论和机制设计的视角被解决，论文首次提出了一个针对用户-提供商生态系统的形式化经济模型，其中用户可以多次向多个模型提供商迭代地委托查询，提供商可以进行一系列战略行为。模型证明了在连续策略空间和任何正数ε条件下，存在一个具有加性近似比为O(T^(1-ε)log T)的激励兼容机制，并且保证了拟线性次优用户体验。此外，论文证明了没有机制可以确保用户体验的预期效用比论文机制更优，并展示了该机制在现实API情境下的有效性。", "innovation": "论文的核心贡献在于首次提出一个针对用户-提供商生态系统的正式经济模型；证明了对于连续策略空间和任何0<ε<1/2条件下，存在一个具有加性近似比为O(T^(1-ε)log T)的激励兼容机制，并且保证了拟线性次优用户体验；证明了存在机制最优性结果，即没有机制能够确保用户体验的预期效用比论文机制更优；展示了该机制在现实API情境下的有效性。", "conclusion": "论文证明了现有机制的有效性，对于连续策略空间和特定条件，存在一个激励兼容机制，且没有任何机制能够提供更好的预期用户体验。该机制在现实API设置中也展现了良好的表现。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.02780", "html_url": "https://arxiv.org/abs/2511.02780", "title": "POCO: 代理型智能合约漏洞利用生成框架", "title_en": "PoCo: Agentic Proof-of-Concept Exploit Generation for Smart Contracts", "authors": "Vivi Andersson,Sofia Bobadilla,Harald Hobbelhagen,Martin Monperrus", "background": "智能合约在高度敌对的环境中运作，一旦存在漏洞可能导致重大经济损失。因此，智能合约需要进行安全审计，而这种审计过程中，概念证明（PoC）漏洞利用起到了关键作用，它能向利益相关者证明报告的漏洞是真实、可复制且可利用的。然而，手动创建PoC漏洞利用是耗时、易错且经常受限于严格的时间安排。", "innovation": "作者引入了POCO，这是一种代理型框架，能够从审计人员编写的自然语言漏洞描述中自动生成可执行的PoC漏洞利用。POCO通过与一组代码执行工具的交互，在一种推理-行动-观察的循环中自主生成PoC。它生成的可执行漏洞利用与Foundry测试框架兼容，可以直接整合到审计报告和安全工具中。实验结果表明，POCO在23个真实世界漏洞报告上的表现优于提示和工作流基线，生成了结构良好且逻辑正确的PoC。", "conclusion": "我们的研究表明，代理型框架可以显著降低高质量PoC在智能合约审计中的工作量。我们的贡献为智能合约安全社区提供了直接可操作的知识。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03121", "html_url": "https://arxiv.org/abs/2511.03121", "title": "使用控制屏障函数对大型语言模型进行对齐", "title_en": "Control Barrier Function for Aligning Large Language Models", "authors": "Yuya Miyaoka,Masaki Inoue", "background": "本文介绍了一个基于控制的方法，用于通过利用控制障碍函数(CBF)来对齐大规模语言模型（LLMs），以确保生成用户期望的文本。这种框架通过在基线LLM预测的令牌上应用CBF安全过滤器干预生成的文本，同时保持了基线模型的原始版本，因为它可以不进行微调直接用于对齐目的。此外，如果有关于期望对齐的评估模型，可以直接应用于安全过滤器的设计，从而增强其适用性和灵活性。整个文本生成系统使用开源语言模型实施，旨在生成积极的文本。", "innovation": "该框架通过应用CBF安全过滤器干预基于基线LLM生成的文本，确保生成用户期望的文本，并提供了一种无需微调基线模型即可用于对齐目标的方法。此外，可以根据期望对齐的评估模型直接调整过滤器设计，增强了其灵活性和适用性。", "conclusion": "该研究提出了一种基于控制的方法，通过利用CBF安全过滤器，有效对齐大规模语言模型，并生成积极的文本。这种方法不仅提高了生成的文本质量，而且增强了现有模型的适用性和灵活性。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.02263", "html_url": "https://arxiv.org/abs/2511.02263", "title": "LA-MARRVEL：一种在罕见疾病诊断中基于知识和语言理解的LLM重排序器", "title_en": "LA-MARRVEL: A Knowledge-Grounded and Language-Aware LLM Reranker for AI-MARRVEL in Rare Disease Diagnosis", "authors": "Jaeyeon Lee,Hyun-Hwan Jeong,Zhandong Liu", "background": "罕见疾病诊断需要将基因发现与通常未结构化的参考文本链接起来。当前的工作流程可以收集大量候选基因，但临床医生仍需要花费大量时间过滤假阳性结果并将来自文献和数据库的证据结合起来。一个关键挑战是语言：表型描述和遗传模式通常用散文形式书写，无法完全被表格捕捉。大语言模型（LLMs）可以读取这种文本，但其在临床应用中需要基于可引用的知识并实现稳定且可重复的行为。", "innovation": "本文探索了一种基于知识与语言理解的重排序层，构建在高召回率第一阶段管道之上。目标是提高精确度并增强解释性，而不是完全替代生物信息学的标准步骤。通过专家构建的上下文和共识方法减少LLM的变异性，生成了更短、更有依据的基因列表供专家审核。LA-MARRVEL在准确性和解释性方面超越了AI-MARRVEL、Exomiser、LIRICAL、Anthropic Claude等其他方法和传统生物信息学诊断工具，尤其在Recall@5上的平均值达到了94.10%，比AI-MARRVEL提高了3.65个百分点。LLM生成的推理提供了清晰的散文形式的表型匹配和遗传模式解释，这使得临床审核更快更容易。", "conclusion": "LA-MARRVEL分为三部分：专家定制的背景知识，以丰富表型和疾病信息；通过对多次LLM运行的排名投票算法综合来获取一致的排名基因列表；以及提供第一阶段排名和基因注释的AI-MARRVEL管道，后者已知在BG、DDD和UDN队列中是最先进的罕见疾病诊断方法。在线AI-MARRVEL包含了LA-MARRVEL作为一个LLM功能：https://thisisalink.com。LA-MARRVEL已在三个独立的真实世界诊断患者队列中进行了评估。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03441", "html_url": "https://arxiv.org/abs/2511.03441", "title": "CareMedEval数据集：评估生物医学领域的批判性评价和推理", "title_en": "CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field", "authors": "Doria Bonzi,Alexandre Guiggi,Frédéric Béchet,Carlos Ramisch,Benoit Favre", "background": "批判性文献评估在生物医学领域是必不可少的技能，尽管大型语言模型可以提供潜在支持，但在专业领域的批判性推理方面仍然有限。", "innovation": "该论文介绍了一个名为CareMedEval的新颖数据集，用于评估大型语言模型在生物医学批判性评价和推理任务中的表现。与现有基准不同，该数据集明确规定了基于科学论文的批判性阅读和推理的评估。实验结果显示，尽管生成中间推理令牌可以显著改善结果，但现有的一般和生物医学专业化模型仍难以完成任务，尤其是在研究限制和统计分析方面仍面临挑战。因此，CareMedEval提供了一个具有挑战性的基准，揭示了当前大型语言模型的局限性，并为改进自动支持批判性评价铺平了道路。", "conclusion": "CareMedEval数据集为进一步开发自动支持批判性评估的工具指明了方向，展示了现有大型语言模型在生物医学领域推理方面的不足。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03739", "html_url": "https://arxiv.org/abs/2511.03739", "title": "TextualVerifier: 逐步骤验证TextGrad", "title_en": "TextualVerifier: Verify TextGrad Step-by-Step", "authors": "Eugenius Mario Situmorang,Adila Alfa Krisnadhi,Ari Wibisono", "background": "TextGrad是一种基于文本的自动微分新方法，能够使复合AI系统在无需明确数值方程的情况下执行优化。然而，它缺乏自我验证机制来确保文本决策中的推理有效性。TextualVerifier通过使用大型语言模型的链式思考推理和多数投票，来填补这一验证缺口，提供了一个非侵入性的验证框架。", "innovation": "TextualVerifier 是一种使用大型语言模型技术的自验证框架，无需计算数值梯度即可实现对TextGrad推理步骤的逐步骤验证。它通过四个阶段的工作流程实现此目标：链式思考分解、变体生成、多数投票以及共识聚合。该框架与TextGrad在损失函数验证和优化结果验证阶段进行了非侵入式集成，展示了在不同基准测试中的显著提升。", "conclusion": "TextualVerifier 通过LLM技术为TextGrad提供了第一个自验证框架，显著提高了推理步骤的有效性，并为基于文本的优化验证开拓了新的方向。通过使用Gemini 1.5 Pro模型的实验评估，TextualVerifier在两个阶段中分别实现了29%的有效推理步骤改进和2.2个百分点的准确率提升（从68.2%到70.4%），同时保持了适度的计算开销。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.02895", "html_url": "https://arxiv.org/abs/2511.02895", "title": "机器犯罪学", "title_en": "A Criminology of Machines", "authors": "Gian Maria Campedelli", "background": "尽管达成人类水平的人工智能的可能性仍然存在争议，但未来由日益增多的自主机器所塑造的社会的可能性很高。自主人工智能代理已经在多个行业和数字环境中部署并活跃，除了人与人和人与机器的交互，机器与机器的交互也将变得越来越普遍。鉴于这些发展，需要探讨这一转变对犯罪和控制的社会意义，明确提出自主机器应当被视为拥有社会、法律及计算多个维度的实体。因此，本文分析了多代理人工智能系统所带来的风险，并提出了四个关键问题来引导理论和实证研究：1. 我们能否假设机器会简单模仿人类？2. 为人类发展出的犯罪理论能否解释自主AI代理交互所产生的偏差或犯罪行为？3. 哪种类型的犯罪行为会首先受到影响？4. 这种前所未有的社会转型如何影响警察工作？", "innovation": "本文利用行动网络理论和沃格尔多年前关于机器社会学的呼吁，重申了犯罪学应该超越仅仅将AI视为工具的视角。同时，提出一种双分类法来描绘AI代理之间的交互产生的偏差、违法行为或犯罪行为途径，并且探讨了四个理论和实证研究的关键问题，这有助于犯罪学更早应对多代理AI系统对犯罪研究的影响，并在AI安全和治理的讨论中发挥更积极的作用。这种方法对于理解自主AI环境下的犯罪现象提供了新的视角及应对策略，具有理论和实践创新性。", "conclusion": "本文旨在揭示除了在实际应用中确保AI系统的安全之外，更应对多代理AI系统的风险进行理论分析，推进犯罪学领域的进一步研究，并呼吁犯罪学家在AI安全和治理方面发挥积极作用。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03499", "html_url": "https://arxiv.org/abs/2511.03499", "title": "环境相似性和船舶移动作为耦合预测因子的海洋入侵物种途径的理论框架", "title_en": "A Theoretical Framework for Environmental Similarity and Vessel Mobility as Coupled Predictors of Marine Invasive Species Pathways", "authors": "Gabriel Spadon,Vaishnav Vaidheeswaran,Claudio DiBacco", "background": "海洋入侵物种通过全球航运传播，对生态系统和经济造成显著影响。传统的风险评估依赖于详细的压载水记录和交通模式，但这些记录通常是不完整的，限制了全球覆盖范围。因此，需要一种新的理论框架来量化入侵风险，结合港口间环境相似性和观测与预报的船舶移动性。通过气候特征表征每个港口的海洋条件，利用自动识别系统数据衍生的船舶流动网络捕捉船舶流量和潜在转移路径，结合聚类和度量学习揭示气候相似性，估计物种在航运路线上的存活概率。通过时间链接预测模型捕捉交通模式在环境变化条件下的变化。这些方法以环境相似性和预测移动性的融合提供了港口和航程水平的暴露估计，支持有针对性的监测、航线调整和管理干预。", "innovation": "该论文提出了一种理论框架，通过结合港口间环境相似性和船舶移动信息来预测海洋入侵物种的途径。传统的方法依赖于不完整的数据，而新的理论框架利用气候特征和船舶移动网络来更准确地评估入侵风险，提供环境相似性和预测移动性的融合，以支持更有效的风险管理策略。", "conclusion": "通过将环境相似性和船舶移动性相结合，本研究提供了一种新的方法来评估海洋入侵物种的风险，该方法能够更准确地提供港口和航程水平的暴露估计，支持监测、航线调整和管理干预。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.03227", "html_url": "https://arxiv.org/abs/2511.03227", "title": "基于节点的多模态生成文本、音频、图像和视频的编辑方法", "title_en": "Node-Based Editing for Multimodal Generation of Text, Audio, Image, and Video", "authors": "Alexander Htet Kyaw,Lenin Ravindranath Sivalingam", "background": "当前的多模态内容生成系统往往不能提供对叙述结构的直接控制，且在迭代生成文本、图像、音频和视频方面缺乏灵活性。本文介绍了一种基于节点的内容生成系统，旨在通过节点图的形式来表示故事，提供直接的用户编辑和自然语言提示功能，以实现故事的扩展、编辑和迭代细化，从而支持复杂的多模态叙事创作。", "innovation": "该论文的创新在于提出了一种基于节点的多模态内容生成系统，该系统能够通过节点图形式代表故事，并可以根据直接的用户编辑和自然语言提示进行故事的扩展、编辑和迭代细化，每个节点可以集成文本、图像、音频和视频，允许创作者进行多模态叙述的创作。此外，系统还通过任务选择代理将用户引导至专门的生成任务，实现故事生成、节点结构推理、节点图版面格式化和上下文生成等功能的分工合作。界面还支持对单个节点的针对性编辑、自动分支以实现并行叙述线以及基于节点的迭代细化。", "conclusion": "研究结果表明，基于节点的编辑功能支持对叙述结构的控制以及多模态内容（文本、图像、音频和视频）的迭代生成。系统在自动故事大纲生成方面取得了定量结果，并在编辑工作流程方面提供了定性观察。然而，目前仍存在扩展长叙述以及多个节点之间一致性的问题，未来研究将继续朝着支持人类在环创意AI工具的方向发展。"}
{"llm_update_time": "20251110", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2511.02872", "html_url": "https://arxiv.org/abs/2511.02872", "title": "FATE: 多难度级别形式化基准系列用于前沿代数", "title_en": "FATE: A Formal Benchmark Series for Frontier Algebra of Multiple Difficulty Levels", "authors": "Jiedong Jiang,Wanyi He,Yuefeng Wang,Guoxiong Gao,Yongle Hu,Jingting Wang,Nailing Guan,Peihao Wu,Chunbo Dai,Liang Xiao,Bin Dong", "background": "最近的大规模语言模型（LLMs）在形式定理证明方面展现了令人印象深刻的成果，特别是在像IMO这样的竞争性数学基准上。然而，这些竞赛并不反映现代数学研究的深度、广度和抽象性。为了弥合这一差距，我们引入了FATE（形式代数定理评估），这是一个新的形式代数基准系列，旨在引导高级数学推理。该系列包括两个新组件：FATE-H和FATE-X，各有100道代数和交换代数难题。从本科练习到超过博士资格考试的问题难度涵盖了整个范围。FATE-X是第一个形式基准，其难度和覆盖范围均超越了博士资格考试和Mathlib库。我们对最新LSTM证明者在新产品基准上的评估显示，与竞赛数学相比，模型的表现差距非常大：最佳模型在FATE-H上仅达到64%的准确率，在FATE-X上为0%。两个阶段的评估表明，模型的自然语言推理准确度明显高于其将这种推理形式化的准确度。我们系统地分类了在这一形式化过程中常见的错误。此外，一项比较研究表明，专用证明者可能在自然语言阶段不如通用模型有效，导致其准确性降低。", "innovation": "我们提出了FATE，这是一个新的多难度级别的形式化代数基准系列，用于引导高级数学推理。该系列包括两个新组件：FATE-H和FATE-X，每个组件包含100道代数和交换代数难题。FATE-X是首个能够超越博士资格考试难度和覆盖范围的形式化基准。评估显示，最新LSTM证明者在FATE-H上只有3%（pass@64）的准确率，在FATE-X上为0%。研究发现，模型的自然语言推理能力远高于其将这种推理形式化的准确度，并且我们系统地分类了这一过程中常见的错误。此外，研究还发现，专用证明者在自然语言处理阶段不如通用模型有效，降低了其整体准确性。FATE提供了严格的挑战性基准，有助于研究级形式化数学推理的进展。", "conclusion": "我们相信FATE提供了一个稳健且具有挑战性的基准，这在通向研究级形式化数学推理的道路上是必要的里程碑。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03738", "html_url": "https://arxiv.org/abs/2511.03738", "title": "激活空间人格操控：LLM中稳定特质控制的混合层选择", "title_en": "Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs", "authors": "Pranav Bhandari,Nicolas Fay,Sanjeevan Selvaganapathy,Amitava Datta,Usman Naseem,Mehwish Nasim", "background": "大型语言模型在生成文本时表现出隐含的人格特质，但可靠地控制或对齐这些特质以满足特定需求仍然是一个开放的挑战。文献中缺乏有效的机制来在生成过程中操控模型的行为是一个关键缺口。尽管具备人格意识的LLM是一个有希望的方向，但这些心理结构与其在LLM中的表示之间的关系仍需进一步探讨。研究人员对如何通过这些表示来引导模型行为的作用也产生了兴趣。论文提出了一种新颖的管道，使用Big Five人格特质（开放性、责任心、外向性、宜人性和神经质）从变压器层中提取隐藏状态激活，运用低秩子空间发现方法，并在不同模型架构中识别出特异最优层，用于稳健注入。研究结果表明，人格特质占据一个低秩共享子空间，通过谨慎的扰动这些潜在结构可以转换为有效的操控机制，有助于从心理学理论与实际模型对齐之间架起桥梁。最终，这些个性对齐的方向通过可变形层选择的灵活引导框架实现精确控制，不会影响流畅性、变化性和一般能力", "innovation": "论文提出了一种创新的方法，通过Big Five人格特质从变压器层中提取隐藏状态激活并利用低秩子空间发现方法，识别出针对不同模型架构的特异最优层以实现稳健的注入。进一步，通过一种灵活的引导框架实现个性对齐的方向，能够在不牺牲流畅性、变化性和一般能力的前提下，对LLM输出的人格特质表达进行精确控制。这种方法有助于近距离心理学理论与实际的模型对齐，填补了文献中的一个关键缺口。", "conclusion": "研究发现人格特质存在于一个低秩共享子空间，并通过精心的扰动将这些潜在结构转换为有效的操控机制，从而在不损害语言流畅性、多样性和总体能力的情况下精确控制LLM输出中的人格特质表达。这些发现为实现大型语言模型在生成过程中的稳定且精确的人格特质控制提供了新的方法，并且可能有助于推进进一步的研究，弥合心理学理论与实际模型对齐之间的差距。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03772", "html_url": "https://arxiv.org/abs/2511.03772", "title": "GRDD+:一个具有跨架构微调评估的扩展希腊方言数据集", "title_en": "GRDD+: An Extended Greek Dialectal Dataset with Cross-Architecture Fine-tuning Evaluation", "authors": "Stergios Chatzikyriakidis,Dimitris Papadakis,Sevasti-Ioanna Papaioannou,Erofili Psaltaki", "background": "现有的希腊方言数据集(GRDD)仅包含有限的希腊方言数据，本研究旨在扩展该数据集，增加更多来自克里特岛、塞浦路斯、黑海地区和北希腊的数据，同时新增六种新型变体：Greco-Corsican, Griko（南意大利希腊语）、Maniot、Heptanesian、Tsakonian和Katharevusa希腊语，共提供了6,374,939词的数据量和10种变体。这是迄今为止首个包含如此广泛变体和大量数据的研究。", "innovation": "本研究不仅扩展了希腊方言数据集，还对三个不同模型架构（Llama-3-8B、Llama-3.1-8B、Krikri-8B）进行了微调，并将结果与前沿模型（Claude-3.7-Sonnet、Gemini-2.5、ChatGPT-5）进行了对比，以评估高质量方言数据对多种语言模型的影响。", "conclusion": "通过微调实验，本研究展示了在多个语言模型上使用高质量的希腊方言数据的新颖性，并证明了这类扩展数据集在不同模型架构中的效用，为未来研究提供了有价值的数据和经验基础。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03827", "html_url": "https://arxiv.org/abs/2511.03827", "title": "STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models", "title_en": "STARS: Segment-level Token Alignment with Rejection Sampling in Large Language Models", "authors": "Mohammad Atif Quamar,Mohammad Areeb,Mikhail Kuznetsov,Muslum Ozgur Ozmen,Z. Berkay Celik", "background": "现有的方法，例如微调，计算成本高昂且效果不佳；而推理时间的方法，如Best-of-N采样，需要巨大的计算资源才能达到最优对齐。因此，为了安全部署大型语言模型并与人类价值观一致，需要更高效和效果更好的方法。", "innovation": "提出了STARS（Segment-level Token Alignment with Rejection Sampling），一种在解码时间进行迭代采样、评分并拒绝/接受固定长度的短token段落的算法。这允许在生成路径早期进行纠正，显著提高了计算效率并提高了对齐质量。", "conclusion": "在六种不同的大型语言模型上，STARS在胜率上分别比监督微调(SFT)高14.9个百分点，比直接偏好优化(DPO)高4.3个百分点，同时在强的Best-of-N基准线方面保持竞争力。这项工作证明了粒度的、以奖励为导向的采样作为一种能够广泛推广、稳健且高效的替代传统微调和完整序列排名方法，对于对齐大型语言模型的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03823", "html_url": "https://arxiv.org/abs/2511.03823", "title": "PLLuM：波兰大型语言模型家族", "title_en": "PLLuM: A Family of Polish Large Language Models", "authors": "Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik", "background": "大型语言模型（LLMs）在现代人工智能中发挥着核心作用，但其发展主要集中在英语上，导致对其他语言的支持不足。", "innovation": "1. 开发了专门为波兰语定制的开放源代码大型语言模型家族PLLuM，这是目前最大的波兰语言基础模型。\n2. 通过一家由波兰主要研究机构组成的联盟开发，PLLuM 能够提供高质量、透明且与文化相关语言模型，超越了以英语为中心的商业环境。\n3. 建立了一个新的1400亿个词的波兰文本语料库用于预训练，定制指令数据集77k条和偏好优化数据集100k条。\n4. 引入了负责任的人工智能框架，包含了严格的数据治理和输出校正及安全性过滤的混合模块。\n5. 描述了模型的架构、训练过程及对基模型和指令调整变体的对齐技术，并展示了其在公共管理下游任务中的应用价值。", "conclusion": "通过公开发布这些模型，PLLuM 的目标是促进开放研究，加强波兰的主权AI技术。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03830", "html_url": "https://arxiv.org/abs/2511.03830", "title": "拆分，缓存，征服：为高效多标签LLM分类的二元提示法", "title_en": "Divide, Cache, Conquer: Dichotomic Prompting for Efficient Multi-Label LLM-Based Classification", "authors": "Mikołaj Langner,Jan Eliasz,Ewa Rudnicka,Jan Kocoń", "background": "在利用大型语言模型（LLM）进行多标签文本分类时，通常的做法是生成一个结构化的响应来涵盖所有标签，这在短文本推理中效率较低。本文提出了一种新的方法，即将分类任务重新表述为一系列二分（是/否）决策序列。这种方法结合了前缀缓存机制，能够在不牺牲准确性的情况下显著提高短文本推理的效率。", "innovation": "本文提出的创新点在于，通过将多标签分类任务转化为一系列独立的二分决策查询，并结合前缀缓存机制，提高了LLM在短文本推理中的效率。利用强大注释器模型进行LLM到СLM的蒸馏，为多个小型模型提供多次注释。这些模型经过微调后，表现出了显著优于零样本基准的结果，特别是在训练中看到的维度上。", "conclusion": "我们的发现表明，将多标签分类分解为二分查询，并结合蒸馏和缓存感知推理，提供了一种可扩展且有效的基于LLM的分类框架。该方法已在情感状态验证，但它在不同领域中具有广泛适用性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03908", "html_url": "https://arxiv.org/abs/2511.03908", "title": "视觉语言模型中的背景信息如何影响含义解释", "title_en": "Context informs pragmatic interpretation in vision-language models", "authors": "Alvin Wei Ming Tan,Ben Prystawski,Veronica Boyce,Michael C. Frank", "background": "在迭代参照游戏中，参与者多次使用语言挑选新的指代对象，这是一个测试智能体在多轮语言环境中进行语境敏感语用推理能力的良好案例。本文评估了视觉语言模型和人类在迭代参照游戏中的表现，通过改变给定的背景信息量、顺序和相关性进行改变。缺乏相关背景信息时，模型的表现略高于随机猜测但远低于人类。然而，具有相关背景信息时，模型的表现经历了显著的提升。即使是在涉及抽象对象的小样本参照游戏中，视觉语言模型也面临着很大的挑战。", "innovation": "本文通过迭代参照游戏，评测了视觉语言模型和人类在语境丰富的语言环境下的语用推理能力。具体来说，实验设计了不同的背景信息条件，并观察了模型和人类在这些条件下表现的差异。此外，研究发现，在多轮交互中，相关背景信息可以显著提高模型表现，但模型在处理抽象参照时仍存在较大困难。", "conclusion": "视觉语言模型在具有相关背景信息的多轮语言环境中的语用推理能力得到了显著提高，但在处理抽象参照时表现仍相对低下。未来的研究需要探索更有效的训练方法，以提高模型在复杂语境中的语用推理能力。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03880", "html_url": "https://arxiv.org/abs/2511.03880", "title": "评估低资源语言机器翻译数据集：一个性别视角", "title_en": "Evaluating Machine Translation Datasets for Low-Web Data Languages: A Gendered Lens", "authors": "Hellina Hailu Nigatu,Bethelhem Yemane Mamo,Bontu Fufa Balcha,Debora Taye Tesfaye,Elbethel Daniel Zewdie,Ikram Behiru Nesiru,Jitu Ewnetu Hailu,Senait Mengesha Yayo", "background": "低资源语言日益融入自然语言处理（NLP）研究，强调收集大规模数据集，在数量优先于质量的情况下，我们面临两个风险：一是构建对这些语言性能较差的语言技术；二是产生有害内容，延续社会偏见。本文聚焦于三种低资源语言——阿法尼奥罗莫语、阿姆哈拉语和提格雷尼亚语，研究机器翻译数据集中的质量问题，特别是性别表征问题。虽然训练数据涵盖大量政治和宗教领域的文本，基准数据集主要关注新闻、健康和体育内容。研究发现，数据集中男性人物的名字、动词的语法性别以及刻板印象描绘的比例较大，进一步发现针对女性的有害和有毒表现更为突出，特别是数据量最大的语言。", "innovation": "本文着重于低资源语言机器翻译数据集的性别视角评估，指出训练数据虽然大多是政治和宗教领域的文本，但基准数据集却主要集中于新闻、健康和体育。研究还发现数据集中有明显的男性倾向，包括人物名称、语法性别以及刻板印象描绘，并指出数量多并不意味着质量高。这是对低资源语言数据集质量问题的深入研究，并采用性别视角提供新的视角。", "conclusion": "希望本文的研究能激发更多对低资源语言数据集的探讨，促使及早缓解有害内容。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03915", "html_url": "https://arxiv.org/abs/2511.03915", "title": "人类繁荣地理指数：美国县级数据集，2013-2023", "title_en": "The Human Flourishing Geographic Index: A County-Level Dataset for the United States, 2013--2023", "authors": "Stefano M. Iacus,Devika Jain,Andrea Nasuto,Giuseppe Porro,Marcello Carammia,Andrea Vezzulli", "background": "人类的繁荣是一个多维度的概念，包括幸福、健康、目的、美德、人际关系和财务稳定，对于理解社会福祉具有重要意义，超越了经济指标的范畴。现有的衡量方法往往缺乏精细的空间和时间分辨率。现有的数据集和指标未能充分捕捉到繁荣的变化情况，因此需要更精细的空间和时间分辨率来更全面地评估社会的繁荣情况.", "innovation": "本文介绍了一种新型的人类繁荣地理指数（HFGI），通过分析从2013年至2023年的约26亿条美国推特数据，使用微调过的大型语言模型来分类表示48个与哈佛全球繁荣研究框架相一致的繁荣指标，同时涵盖移民态度和腐败感知。HFGI提供了县和州层面的月度和年度繁荣相关话语指标的数据集，该数据集经过验证，确保指标准确反映基础概念，并与已有的指标表现出预期的相关性。这项研究为多学科分析提供了前所未有的分辨率，揭示了十年来美国社交媒体上反映的人类繁荣动态.", "conclusion": "该资源使我们能够以空前的分辨率分析福祉、不平等和社会变革，提供了关于过去十年美国社交媒体上反映的人类繁荣动态的洞见."}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03900", "html_url": "https://arxiv.org/abs/2511.03900", "title": "GRAD: 图检索自适应解码以减轻幻觉", "title_en": "GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation", "authors": "Manh Nguyen,Sunil Gupta,Dai Do,Hung Le", "background": "大规模语言模型（LLMs）的幻觉减轻仍然是一个持续的挑战，尽管模型规模在增长。现有的方法通常依赖于外部知识源，如结构化的数据库或知识图谱，这些知识源通过提示或检索来访问。然而，基于提示的对接是脆弱且领域敏感的，而符号知识集成则带来了沉重的检索和格式化成本。", "innovation": "提出了图检索自适应解码（GRAD），这是一种在解码时对接生成的方法，无需重新训练。GRAD通过在一次前向传递中收集小检索语料库中的下一词概率来构建稀疏的令牌过渡图。在解码期间，图检索的概率通过最大归一化和适应性融合与模型概率相结合，以促进高证据的延续同时保持流畅性。", "conclusion": "GRAD在三个模型和一系列包括内在、外在幻觉和事实性任务的问答基准测试中，始终优于基线方法，实现了高达9.7%的内在准确率提升，8.6%的幻觉率降低以及6.9%的正确率增加，同时在所有方法中获得了最高的事实性-相关性产品得分。GRAD提供了一种轻量级、即插即用的替代对比度解码和知识图谱增强的方法，证明了通过语料库级别令牌转换统计证据可以有效引导生成更真实和可验证的输出。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03945", "html_url": "https://arxiv.org/abs/2511.03945", "title": "通过向量翻译在大语言模型之间实现直接语义通信", "title_en": "Direct Semantic Communication Between Large Language Models via Vector Translation", "authors": "Fu-Chun Yang,Jason Eshraghian", "background": "在多智能体设置中，如辩论、反思或工具调用场景中，大型语言模型（LLMs）通过传输明文令牌来传递消息，这会丢失大部分潜在语义，限制了信息传递并增加了不必要的计算开销。", "innovation": "通过引入向量翻译建立潜在桥梁，使用学习到的映射使得在表示空间中可以直接进行语义交换。实验表明，双编码器翻译器在LLAMA-2-7B和Mistral-7B-Instruct之间训练后，平均余弦对齐度达到0.538。注释器向量的注入实现了目标模型生成的引导而不破坏概率。双向评估显示传输不对称性比1:2.01，表明通用模型比指令调整变体提供更可转移的表示形式。", "conclusion": "保守地注入翻译向量保持了计算稳定性，同时证明了跨模型的潜在通信是可行的，这使得能够构建协作式的AI系统，这些系统可以共享含义而非仅仅是令牌。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04020", "html_url": "https://arxiv.org/abs/2511.04020", "title": "检索增强语言模型中的 abduction 推理：生成和验证缺失的前提", "title_en": "Abductive Inference in Retrieval-Augmented Language Models: Generating and Validating Missing Premises", "authors": "Shiyin Lin", "background": "检索增强生成（RAG）模型通过结合检索技术增强了大型语言模型（LLMs），在知识密集任务中表现出强劲的性能。然而，当检索到的证据不完整时，RAG 管线会失效，导致推理过程中的空白。在这种情况下，演绎推理（过程为生成可能的缺失前提以解释观察结果）提供了一种合理的方法来填补这些空白。", "innovation": "本文提出了一种框架，将演绎推理整合到检索增强的语言模型中。该方法检测不足的证据，生成候选的缺失前提，并通过一致性与合理性的检查进行验证。实验结果表明，该方法提高了答案的准确性和推理的忠实度，展示了演绎推理作为增强RAG系统稳健性和可解释性的有前途的方向。", "conclusion": "本工作强调了演绎推理作为增强RAG系统稳健性和解释性的有前途的方向。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04070", "html_url": "https://arxiv.org/abs/2511.04070", "title": "T-FIX：可由专家解读的基于文本的解释", "title_en": "T-FIX: Text-Based Explanations with Features Interpretable to eXperts", "authors": "Shreya Havaldar,Helen Jin,Chaehyeon Kim,Anton Xue,Weiqiu You,Marco Gatti,Bhuvnesh Jain,Helen Qu,Daniel A Hashimoto,Amin Madani,Rajat Deo,Sameed Ahmed M. Khatana,Gary E. Weissman,Lyle Ungar,Eric Wong", "background": "随着大模型（LLMs）在知识密集型领域（如手术、天文学、治疗）的应用，用户不仅期望获得答案，而且还希望能理解这些答案背后的逻辑。在这些领域，用户通常是有专业背景的知识专家（如医生、天文学家、心理咨询师），他们需要解释能够反映专家级的推理过程。然而，当前的评估方法大多集中在解释的可信度或内部一致性上，未能准确评估解释内容是否真正符合专家的直觉和理解。", "innovation": "本文通过提出T-FIX（Text-Based Explanations with Features Interpretable to eXperts）基准体系，引入了专家对齐的标准。该基准覆盖了七个知识密集型领域，采用了与领域专家合作开发的新型度量方法来衡量LLM解释与专家判断的一致性。这种方法超越了传统的评估方式，更加贴近专家的需求和直觉。", "conclusion": "本文提出T-FIX新基准，通过与专家合作开发自动化和透明的度量方法，能够有效评估LLM在知识密集型领域中解释的专家对齐情况，为大模型在这些领域的实际应用提供了可靠的评估工具。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04079", "html_url": "https://arxiv.org/abs/2511.04079", "title": "使用大规模训练和与云供应商方法对比提高放射报告去标识化性能", "title_en": "Improving the Performance of Radiology Report De-identification with Large-Scale Training and Benchmarking Against Cloud Vendor Methods", "authors": "Eva Prakash,Maayane Attias,Pierre Chambon,Justin Xu,Steven Truong,Jean-Benoit Delbrouck,Tessa Cook,Curtis Langlotz", "background": "该研究旨在通过使用大规模训练数据集增强基于变压器的模型的自动化去标识化能力，以提升放射学报告中保护健康信息（PHI）检测的准确性。研究对比了模型表现与商业云服务商系统的性能，并通过稳定性测试和技术评估，验证了其在去标识化任务中的优势和可靠性。", "innovation": "该研究创新性地扩大了训练数据集，结合斯坦福大学提供的标注放射学报告，引入额外的PHI类别“AGE”，以增强模型的通用性和稳定性。研究通过使用合成PHI生成和与商业系统的性能对比，展示了基于变压器的模型在保护病患隐私方面的优越性，并提供了新的安全临床文本处理基准。", "conclusion": "基于多种放射学数据集训练的变压器架构模型在PHI检测方面超过了先前的学术和商业系统，并确立了一个新的安全临床文本处理基准。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04072", "html_url": "https://arxiv.org/abs/2511.04072", "title": "Plan of Knowledge: 提取增强的大语言模型用于时间知识图谱问题回答", "title_en": "Plan of Knowledge: Retrieval-Augmented Large Language Models for Temporal Knowledge Graph Question Answering", "authors": "Xinying Qian,Ying Zhang,Yu Zhao,Baohang Zhou,Xuhui Sui,Xiaojie Yuan", "background": "TKGQA试图通过利用时间知识图谱（TKGs）中的事实信息来回答与时间相关的问题。尽管早期研究使用预训练的TKG嵌入或图神经网络来注入时间知识，但由于这些方法未能充分理解复杂的时间约束的语义信息，因此效果有限。此外，尽管大型语言模型（LLMs）展示了强大的语义理解和推理泛化能力，但在时间推理方面仍然有限，容易出现幻觉和知识缺乏的问题。为了解决这些问题，提出了Plan of Knowledge框架及其对比时间检索器，以改进时序推理的解释性和事实一致性。", "innovation": "该研究提出的Plan of Knowledge框架通过分解复杂的时间问题为一系列中间目标，利用预定义的工具作为推理探索的引导。同时，构建了一个时间知识存储（TKS），实现了从时间知识图谱中选择性地检索高相关性的事实。结合结构化规划与时间知识检索，有效地提升了大型语言模型在时间推理中的解释性和事实一致性。实验结果显示，Plan of Knowledge框架显著提高了大型语言模型的检索精度和推理准确性，相比最先进的TKGQA方法提高了56.0%以上。", "conclusion": "实验结果表明，Plan of Knowledge框架可以显著提升大型语言模型在时间知识图谱问题回答中的性能，通过结合结构化规划和时间知识检索，克服了传统方法在时间推理上的不足，达到了更高的检索精度和推理准确性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04035", "html_url": "https://arxiv.org/abs/2511.04035", "title": "WST: 弱监督发射机(Weakly Supervised Transducer)在自动语音识别(ASR)中的应用", "title_en": "WST: Weakly Supervised Transducer for Automatic Speech Recognition", "authors": "Dongji Gao,Chenda Liao,Changliang Liu,Matthew Wiesner,Leibny Paola Garcia,Daniel Povey,Sanjeev Khudanpur,Jian Wu", "background": "递归神经网络-发射机（RNN-T）因其在端到端（E2E）自动语音识别（ASR）任务中的广泛应用而受到青睐，但其性能高度依赖于大量高质量的标注数据，然而这些高质量数据往往获取成本高昂且难以获得。为了解决这一问题，本文提出了一种弱监督发射机（WST），该模型具备灵活的训练图，能够在处理转录错误的同时，无需进行额外的信心估计或辅助预训练模型。实验数据表明，即使在高达70%的转录错误率下，WST仍能保持较好的性能，且在合成数据集和工业数据集上均优于现有的基于连接主义时序分类（CTC）的弱监督方法，如绕过时序分类（BTC）和全域时序分类（OTC）。实验结果验证了WST在实际ASR场景中的实用性和鲁棒性。", "innovation": "WST作为一种弱监督的发射机模型，其创新点在于设计了灵活的训练图，能够有效应对转录中的错误，提高了模型的鲁棒性。与其他基于CTC的弱监督方法相比，WST能在较高的转录错误率下维持较好的性能，不需要额外的信心估计或辅助预训练模型", "conclusion": "实验结果表明，WST在转录错误率高达70%的情况下仍能保持良好的性能，且优于现有的基于CTC的弱监督方法，展示了其在实际ASR应用场景中的实用性和鲁棒性。本文还指出，WST的实现将被公开提供。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04077", "html_url": "https://arxiv.org/abs/2511.04077", "title": "真相并非尿布：人类与AI生成的情感词汇关联", "title_en": "The truth is no diaper: Human and AI-generated associations to emotional words", "authors": "Špela Vintar,Jan Jona Javoršek", "background": "人类根据单词联想的能力可以提供对内部语言词典的见解，但这些自发的联想并非总是可预测的，因为它们可能受到个人经历、情绪或认知风格的影响。形成看似无关概念之间的关联能力可能是创造力的驱动力。本文对比了人类和大型语言模型（LLMs）在这种联想行为上的差异，特别是探讨了对情感词汇的联想，试图判断LLMs生成的联想是否与人类类似。发现人类与LLMs的联想之间有中等程度的重叠，但LLMs倾向于放大刺激的情感负荷，且以其联想比人类的更可预测但较为缺乏创意性。", "innovation": "研究通过对比人类与大型语言模型在情感词汇联想方面的行为，揭示出LLMs在生成情感关联时的放大效应和可预测性特征，填补了在人类联想与AI联想差异研究领域的空白。", "conclusion": "研究结果显示，人类和大型语言模型在情感词汇联想方面的表现存在显著差异：人类联想较为多样而富有创造性的，而大型语言模型的联想则表现出更强的可预测性和放大情感特征。这一发现对于理解人类和AI的创造与联想机制有着重要意义。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04108", "html_url": "https://arxiv.org/abs/2511.04108", "title": "批处理提示抑制约束下的过度推理：批处理提示如何抑制推理模型中的过度推理", "title_en": "Batch Prompting Suppresses Overthinking Reasoning Under Constraint: How Batch Prompting Suppresses Overthinking in Reasoning Models", "authors": "Wenmo Qiu,Saurabh Srivastava", "background": "最近的研究探索了批量提示作为在大语言模型（LLMs）中摊派推理成本的一种策略。作者在这篇论文中进一步探讨了批量提示的另一种未被充分认识到的优势：在大推理模型（LRMs）的多步推理过程中，它能够正则化模型的行为。", "innovation": "研究发现，批量提示不仅可以提高准确性，还能大幅减少推理令牌的使用量（通常减少3-5倍），并通过抑制过度推理、减少犹豫的语言（如反复的自我修正）和鼓励更加果断的回答，来提升推理模型的表现。此外，研究还观察到，在批量推理中，模型表现出一种集体效应，这有助于模型从早期的例子中学习并解决更难的问题。", "conclusion": "研究结果表明，批量提示不仅仅是提高吞吐量的一种方法，还能作为一个强大的推理时间正则化器，使大语言模型的推理更加高效和可靠。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04120", "html_url": "https://arxiv.org/abs/2511.04120", "title": "RIDE: 使用项目反应理论进行难度演变扰动的数学推理", "title_en": "RIDE: Difficulty Evolving Perturbation with Item Response Theory for Mathematical Reasoning", "authors": "Xinyuan Li,Murong Xu,Wenbiao Tao,Hanlun Zhu,Yike Zhao,Jipeng Zhang,Yunshi Lan", "background": "大型语言模型在数学推理方面表现出色，但这些结果可能因训练数据泄露或表面模式匹配而被夸大，而不是真实的推理能力。现行的基于规则的扰动方法往往产生不合适的测试问题，阻碍了系统性地评估问题难度和基准演变。", "innovation": "提出了一种名为RIDE的新颖对抗性问题重写框架，该框架利用项目反应理论（Item Response Theory, IRT）严格衡量问题难度，并生成更具挑战性的、定义更为准确的数学问题变体。该方法通过模拟35个大型语言模型学生的表现来建立难度排序器，为强化学习提供奖励信号，并指导问题重写模型重构不同难度级别的问题。", "conclusion": "将RIDE应用于竞争级别的数学基准测试，产生了扰动版本，降低了26个模型的性能，平均下降了21.73%，这揭示了大型语言模型在数学推理方面有限的鲁棒性，并证实了评估方法的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04139", "html_url": "https://arxiv.org/abs/2511.04139", "title": "CantoASR：低资源粤语口语识别-LALM协作的音节感知方法", "title_en": "CantoASR: Prosody-Aware ASR-LALM Collaboration for Low-Resource Cantonese", "authors": "Dazhong Chen,Yi-Cheng Lin,Yuchen Huang,Ziwei Gong,Di Jiang,Zeying Xie,Yi R.(May)Fung", "background": "自动语音识别（ASR）对于语言无障碍至关重要，但低资源粤语依旧面临挑战，原因在于标注数据有限、六种声调、声调变调以及发音差异。现有的ASR模型，如Whisper，往往会出现较高的词错误率。相较于这些模型，大型音频语言模型（LALMs）能够利用更广泛的情境推理，但仍需明确的声调和韵律声学线索。", "innovation": "本文引入了CantoASR，这是第一个结合错误矫正框架的ASR-LALM协作系统，集成了强制对齐以提取声学特征，LORAtuning后的Whisper以增强声调分辨能力，并使用指令微调的Qwen-Audio进行韵律感知校正。在自发粤语数据上的评估表明，CantoASR相比Whisper-Large-V3获得了显著的字符错误率（CER）改进。这些结果表明，将声学线索与LALM推理结合可为低资源声调和方言ASR提供可扩展的策略。", "conclusion": "集成声学线索与LALM推理为低资源声调和方言ASR提供了一种可扩展的策略，CantoASR框架通过改进的声调和韵律感知在自发粤语数据上取得了显著的词错误率（CER）降低。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04153", "html_url": "https://arxiv.org/abs/2511.04153", "title": "BAPPA: 基于代理、计划和管道的自动文本到SQL生成基准测试", "title_en": "BAPPA: Benchmarking Agents, Plans, and Pipelines for Automated Text-to-SQL Generation", "authors": "Fahim Ahmed,Md Mubtasim Ahasan,Jahir Sadik Monon,Muntasir Wahed,M Ashraful Amin,A K M Mahbubur Rahman,Amin Ahsan Ali", "background": "文本到SQL系统提供了自然语言接口，使用户能够轻松访问存储在数据库中的信息。然而，现有的大规模语言模型在处理基于自然语言指令的SQL生成任务时存在困难，特别是由于数据库模式庞大和复杂的推理需求。先前的研究大多关注复杂的、不太实际的管线，而针对较小和高效模型的工作则被忽视。", "innovation": "本文探索了三种多代理大规模语言模型管线，并对不同规模的开源模型进行了系统的性能基准测试。研究了多代理讨论管线、规划者-编码器管线和编码器-聚合器管线等管线结构。结果显示，多代理讨论管线可以提升小型模型的性能，特别是在经历了三轮讨论后，Qwen2.5-7b-Instruct的执行准确性提高了10.6%。其中，LLM推理-编码器管线表现最优，加深探索-R1-32B和QwQ-32B规划者显著提高了Gemma 3 27B的IT准确率，达到最高分56.4%。", "conclusion": "实验结果表明，多代理讨论和规划者-编码器管线在不同规模的模型上取得了显著的性能提升。多代理框架下，编码器-聚合器和规划者-编码器管线表现出更好的性能，特别是对大型模型，展现出了很大的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04103", "html_url": "https://arxiv.org/abs/2511.04103", "title": "在极限中的列表语言识别特征", "title_en": "A Characterization of List Language Identification in the Limit", "authors": "Moses Charikar,Chirag Pabbaraju,Ambuj Tewari", "background": "该研究探讨了语言识别的极限问题。给定目标语言的一系列示例，学习者的任务是在某个有限时间之后，输出序列的猜测，该序列能够正确识别目标语言。经典的Gold结果表明，对于几乎所有有趣的语言集合，语言识别是不可能的。随后，Angluin提供了对于哪些语言集合可以使此任务成为可能的精确描述。最近，对于相关问题语言生成的积极成果激发了对该经典语言识别问题的重新审视，在这个问题中，学习者还拥有在每个时间步产生k个猜测的额外能力。研究的目标是在某个有限时间之后，在每个时间步至少有一个猜测是正确的，进一步给出了语言集合在极限中的k列表识别的精确描述，基于Angluin对单列表识别的递归描述。该研究还给出了在统计设置下，输入从支持某些语言集合中的语言分布的独立同分布流中抽取的情况下，采用k列表的识别速率，证明了如果一个集合能在极限中k列表识别，则可以以指数速率进行k列表识别，这是最好的，而如果不能则即使速率趋向于零也不能实现k列表识别。通过这种方法，可以确定一些语言集合是可识别的，而另一些则不是。", "innovation": "该研究通过引入额外的能力即在每个时间步生成k个猜测，重新审视了经典的语言识别问题，并给出了一个精确的描述，这是基于Angluin关于单列表识别的递归描述。此外，使用该描述，研究者在统计设置下得出了关于k列表识别的速率，展示了指数速率是最佳可能值。并且，研究提出了在统计设置中终止识别的可能性，以及不能终止识别的情况。这些发现为语言识别理论提供了新的见解和方法。", "conclusion": "该研究指出，一个语言集合可以在极限中k列表识别，当且仅当可以将其分解为k个可以识别的子语言集合。如果集合可以在极限中k列表识别，那么它可以以指数速率进行k列表识别，这是最优的；如果不能，则无法以任何接近零的速率进行k列表识别。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04184", "html_url": "https://arxiv.org/abs/2511.04184", "title": "LLM为中介的信任沟通：在多种应用领域中评估LLM作为沟通者（LAAC）框架的信息准确性", "title_en": "Trustworthy LLM-Mediated Communication: Evaluating Information Fidelity in LLM as a Communicator (LAAC) Framework in Multiple Application Domains", "authors": "Mohammed Musthafa Rafi,Adarsh Krishnamurthy,Aditya Balu", "background": "随着人工智能生成内容的普及，一个幽默的沟通舞台被创造出来，发送者使用大语言模型（LLMs）将简单的理念夸大为冗长的内容，接收者则使用LLMs将其压缩成摘要。这一过程导致双方都不参与真实内容的交流。因此，为了扭转这一局面，文章提出了LAAC（LLM作为沟通者）的概念，旨在利用结构化对话将发送者的意图捕捉，并促进与接收者的真实知识交流。", "innovation": "文章创新性地提出了LAAC的概念，作为智能沟通中介，旨在捕捉发送者的意图并通过结构化对话支持真实的知识交流。此外，文章系统地评估了在多个沟通领域中部署LAAC所必需的信任要求，包括信息捕获的准确性、重演性和查询响应的完整性。", "conclusion": "通过控制实验评估LAAC在多个使用案例中的信任度维度，初步结果揭示了必须解决的信任差距，才能在高风险的沟通场景中可靠地部署LAAC。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04228", "html_url": "https://arxiv.org/abs/2511.04228", "title": "REMIND：后卸载LLM中输入损失景观揭示残留记忆", "title_en": "REMIND: Input Loss Landscapes Reveal Residual Memorization in Post-Unlearning LLMs", "authors": "Liran Cohen,Yaniv Nemcovesky,Avi Mendelson", "background": "机器卸载旨在移除特定训练数据对模型的影响，而无需重新训练整个模型。这一功能对于确保隐私、安全和合规至关重要。因此，验证模型是否真正忘记了目标数据对于维护可靠性和可信度是必要的。然而，现有的评估方法通常仅评估单个输入的遗忘情况，这种做法可能会忽视在语义上相似的示例中存在的残余影响。这些影响会威胁隐私并导致间接信息泄露。", "innovation": "提出了一种名为REMIND（残余记忆中的邻域动力学）的新颖评估方法，旨在检测未学习数据的微妙残留影响，并判定数据是否已被有效遗忘。REMIND通过分析模型在小输入变化上的损失来揭示单点评估忽略的模式。未学习的数据会导致更平坦、平缓的损失景观，而保留或无关的数据则表现出更尖锐、更易变的模式。REMIND只需要基于查询的访问，且在相似约束条件下的表现优于现有方法，并且在不同模型、数据集和重述输入下展示了稳健性，使其适用于实际部署。", "conclusion": "REMIND提供了一种更敏感、可解释的衡量卸载有效性的指标，从而提供了一个可靠的框架来评估语言模型中的卸载。由此，REMIND提供了一个关于记忆和卸载的新视角。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04205", "html_url": "https://arxiv.org/abs/2511.04205", "title": "LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for the Member of the Polish National Board of Appeal", "title_en": "LLM-as-a-Judge is Bad, Based on AI Attempting the Exam Qualifying for the Member of the Polish National Board of Appeal", "authors": "Michał Karp,Anna Kubaszewska,Magdalena Król,Robert Król,Aleksander Smywiński-Pohl,Mateusz Szymański,Witold Wydmański", "background": "本研究评估了当前大规模语言模型（LLMs）是否可以通过波兰国家上诉委员会（Krajowa Izba Odwoławcza）的正式资格考试。考试结构包括公共采购法的多项选择知识测试和书面判决，并要求模型生成答案并由其他模型自动评估。研究发现尽管在多项选择测试中取得了不错的成绩，但在实际的书面部分没有达到及格标准，且模型生成的答案常常与官方审查委员会的判断不符，显示出在逻辑推理、引用法律条文等方面存在局限性。", "innovation": "本文的创新在于将大规模语言模型应用于法律专业领域的实际案例中，通过模拟考试的形式来评估其性能，并采用模型生成答案由其他模型自动评估的方法。研究设计了一种混合信息恢复和提取管道来支持模型，测试了几种不同的大型语言模型，包括GPT-4.1、Claude 4 Sonnet、Bielik-11B-v2.6等，并根据实际情况调整生成环境。", "conclusion": "研究结果表明，尽管技术进步迅速，但当前的大型语言模型尚无法完全替代波兰公共采购裁判中的人类法官或独立考试官。语言模型在生成答案时存在想象问题、引用法律条文不准确、逻辑推理薄弱等问题。因此，需要法律专家和技术团队之间的紧密合作。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04234", "html_url": "https://arxiv.org/abs/2511.04234", "title": "在测试时重用预训练数据是计算量放大器", "title_en": "Reusing Pre-Training Data at Test Time is a Compute Multiplier", "authors": "Alex Fang,Thomas Voice,Ruoming Pang,Ludwig Schmidt,Tom Gunter", "background": "大型语言模型通过其庞大的预训练语料库进行学习，逐渐具备解决越来越多任务的能力；尽管研究者在努力改进这些数据集，却少有人探索预训练机制在从数据中提取思想和知识方面是否有效。本研究使用检索增强生成和测试时计算作为手段，量化预训练过程中未使用的数据集价值及其变化趋势。研究表明，预训练后再从标准和开源数据集中检索数据，能够在MMLU、Math-500和SimpleQA等测试中获得显著的准确性提升，这些提升甚至在去污染后仍然存在。研究团队发现，检索可以从单纯预训练计算乘数中增加约5倍的效果。研究结果表明，通过在测试时使用额外计算来解析检索到的上下文，可以使LLaMA 3.1 8B模型的MMLU表现提升10个百分点。总体而言，研究结果指出现有预训练方法并未充分使用现有预训练数据中的信息，留下了许多改进的空间。", "innovation": "研究提出了使用检索增强生成和测试时计算的新型方法，量化预训练过程中未充分利用的数据集价值，并证明了这种方法可以在多种测试基准上显著提升模型表现，尤其是通过利用额外测试计算资源进一步挖掘检索到的上下文信息，展示了其实际应用潜力。", "conclusion": "本研究结果表明，现代预训练方法未能充分利用现有的预训练数据集中的信息，仍有改进空间。通过检索增强生成和测试时计算相结合的方法，能够显著提升模型性能。未来研究可以继续探索如何最大化利用预训练数据的价值。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04195", "html_url": "https://arxiv.org/abs/2511.04195", "title": "计算图灵测试揭示人类与AI语言的系统性差异", "title_en": "Computational Turing Test Reveals Systematic Differences Between Human and AI Language", "authors": "Nicolò Pagan,Petter Törnberg,Christopher A. Bail,Anikó Hannák,Christopher Barrie", "background": "大型语言模型（LLMs）在社会科学中被用于模拟人类行为，基于它们能够生成具有人类仿真的文本这一假设。然而，这一假设尚未得到充分验证。现有验证方法主要依赖于人类判断测试，即人们是否能够区分AI和人类输出。这些判断方法被认为粗略且不可靠。因此，该领域缺乏评估LLM生成文本现实性的工具，以及校准模型与现实数据之间差距的方法。", "innovation": "本研究有两大贡献。首先，我们引入了一种计算图灵测试，这是一种集成聚合度量（基于BERT的可辨识性和语义相似性）和可解释语言特征（风格标记和主题模式）的验证框架，用于评估LLM在给定数据集中人类语言的模拟程度。其次，我们系统地比较了九种开源重量级LLM（包括微调、风格化提示和上下文检索）在五种校准策略下的表现，评估它们在X（以前的Twitter）、Bluesky和Reddit上的用户交互重现能力。我们的发现挑战了现有文献中的核心假设。即使进行了校准，LLM的输出仍然明显可区分于人类文本，特别是在情绪基调和情感表达方面。指令调优模型的表现不如其基准模型，并且增加模型规模并不提高人类模拟性。我们发现一个重要权衡：优化人类仿真是以牺牲语义准确性为代价的，反之亦然。这些结果为LLM仿真提供了急需的可扩展验证和校准框架，并对目前它们在捕捉人类交流方面的局限性发出了警告。", "conclusion": "研究结果提供了一个急需的可扩展框架来评估和校准LLM模拟，并为它们目前在捕捉人类交流方面的局限性发出了警告。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04406", "html_url": "https://arxiv.org/abs/2511.04406", "title": "动态联合批次选择用于高效机器翻译微调", "title_en": "Dynamic Jointly Batch Selection for Data Efficient Machine Translation Fine-Tuning", "authors": "Mohammad Amin Ghanizadeh,Mohammad Javad Dousti", "background": "数据质量及其有效选择是提高机器翻译模型性能的基础，对于构建稳健可靠翻译系统至关重要。本文提出了一种专门为机器翻译系统微调设计的数据选择方法，这种方法通过结合学习模型和预训练参考模型之间的协同作用来增强整体训练效果。该方法通过定义可学习性评分，系统地评估数据点的训练实用性，确保只有最相关和有价值的例子才参与微调过程。此外，本文的方法采用批次选择策略，考虑了数据点之间的相互依赖性，优化了训练过程的效率，同时保持了对数据相关性的关注。", "innovation": "本文提出了一种新的数据选择方法，通过学习模型和预训练参考模型之间的协同作用定义可学习性评分，来系统地评估数据点的训练实用性，同时采用了考虑数据点相互依赖性的批次选择策略，从而提高训练过程的效率和数据的利用率。实验结果显示，与简单随机数据选择相比，本文方法可以实现高达五倍的数据效率提升，同时还能显著提高计算效率和泛化能力。", "conclusion": "我们的方法在使用缓存嵌入物时，通过减少所需的训练数据点数，增强计算效率，并且在泛化方面表现出色，实现了相对于随机选择方法更好的翻译性能。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04256", "html_url": "https://arxiv.org/abs/2511.04256", "title": "SSPO: 子句子级策略优化", "title_en": "SSPO: Subsentence-level Policy Optimization", "authors": "Kun Yang,Zikang chen,Yanmeng Wang,Zhigen Li", "background": "作为大型语言模型（LLMs）训练后处理的重要组成部分，验证奖励的强化学习（RLVR）显著提升了LLMs的推理能力。然而，某些RLVR算法如GRPO和GSPO在策略更新的稳定性和采样数据的利用率方面存在不足。GRPO在词级别计算重要比例，侧重优化单一词，容易受异常值影响导致模型训练崩溃；GSPO在响应级别计算重要比例，解决了GRPO重要比例计算的高方差和训练噪声累积问题，但所有响应词共享同一重要比例，极端值会误使整体均值升高或降低，导致响应被错误丢弃，从而降低采样数据的利用率。", "innovation": "本文提出了SSPO（子句子级策略优化），它采用句子级别的重要性比例，兼顾了GRPO和GSPO的优点，避免了GRPO的训练崩溃和高方差问题，并通过剪裁机制防止了整个响应词被误丢弃。此外，SSPO结合了句子熵应用于PPO-CLIP，稳定调整剪裁范围，鼓励高熵词探索并缩小低熵词的剪裁范围。实验结果显示，SSPO在五个数据集上的平均得分达到46.57，高于GRPO（43.01）和GSPO（44.42），在三个数据集上取得了最先进水平的表现，突显了SSPO在利用生成数据方面的有效性。", "conclusion": "SSPO通过采用句子级别的重要性比例，结合句子熵和剪裁机制优化了策略优化过程，不仅提升了模型的稳定性，还有效提高了采样数据的利用率，在多个数据集上取得了最佳性能，验证了方法的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04248", "html_url": "https://arxiv.org/abs/2511.04248", "title": "基于图的轻量化主题提取：一种深度模型的替代方法", "title_en": "Efficient Topic Extraction via Graph-Based Labeling: A Lightweight Alternative to Deep Models", "authors": "Salma Mekaoui,Hiba Sofyan,Imane Amaaz,Imane Benchrif,Arsalane Zarghili,Ilham Chaker,Nikola S. Nikolov", "background": "文本主题提取已成为一项必不可少的任务，尤其是在无结构文本数据快速增长的背景下。现有的大多数工作依赖于高度计算密集型的方法来解决这一挑战。然而，本文认为概率和统计方法，如主题模型（TM），可以提供一种需要较少计算资源的有效替代方案。尽管主题模型能够自动在大量未标记文本中发现主题，但它生成的主题往往以一组代表词的形式存在，这些主题缺乏明确的可解释性。本文的目标是通过为这些词汇集分配有意义的标签来对主题进行标记。这将避免依赖于计算密集型的模型，在此过程中不仅丰富了主题词汇与其相关词汇，还探索了它们之间的关系。通过分析这些词汇在图内的联系，我们可以推导出准确捕捉每个主题意义的合适标签。我们在两个不同数据集上将本文提出的方法与多种基准方法，包括ChatGPT-3.5，进行了比较研究。我们的方法在BERTScore和余弦相似度方面取得了比传统基准更好的一致结果，并且在计算效率方面与ChatGPT-3.5相当。最后，讨论了主题标记的未来方向，指出了增强可解释性和自动化的研究潜力。", "innovation": "本文提出了一个基于图的轻量化方法来对主题进行标记。这种方法不仅丰富了主题词汇与其相关词汇，还探索了它们之间的关系。通过分析这些词汇在图内的联系，我们可以推导出准确捕捉每个主题意义的合适标签。此方法在BERTScore和余弦相似度方面取得了比传统基准更好的一致结果，同时保持了计算效率，与ChatGPT-3.5的性能相当。", "conclusion": "本文提出的方法在两个不同数据集上的BertScore和余弦相似度方面优于传统方法，提高了计算效率，与ChatGPT-3.5相当。作为未来的研究方向，作者讨论了如何进一步提高主题标记的可解释性和自动化。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04479", "html_url": "https://arxiv.org/abs/2511.04479", "title": "ThaiOCRBench: 泰语视觉语言理解任务多样基准", "title_en": "ThaiOCRBench: A Task-Diverse Benchmark for Vision-Language Understanding in Thai", "authors": "Surapon Nonesung,Teetouch Jaknamon,Sirinya Chaiophat,Natapong Nitarach,Chanakan Wittayasakpan,Warit Sirichotedumrong,Adisai Na-Thalang,Kunat Pipatanakul", "background": "尽管近期在多模态建模方面取得了进展，但现有的基准测试大多集中于高资源语言，泰语等低资源语言在此领域严重缺失，尤其是在需要理解文档结构的任务中。现有的基准测试未能充分评估视觉语言模型（VLMs）在泰语视觉理解任务中的性能。", "innovation": "泰国OCR基准（ThaiOCRBench）首次为评估泰语文本丰富的视觉理解任务中VLMs的表现提供了一个全面基准。该基准包含2,808个人工标注的样本，涉及13个任务类别，涵盖了广泛的视觉语言模型，并展示了地对地性能差距，特别是开源模型在精细化文本识别和手写内容提取方面的显著劣势。通过深入的错误分析，识别了关键挑战，如语言偏见、结构匹配问题和幻觉内容。", "conclusion": "泰国OCR基准为评估低资源、书写系统复杂的环境中VLMs提供了一个标准化框架，并为改善泰语文档理解提供了具体的见解。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04432", "html_url": "https://arxiv.org/abs/2511.04432", "title": "如果我可以回到过去：将时间倒退作为历史推理任务对LLMs的考验", "title_en": "If I Could Turn Back Time: Temporal Reframing as a Historical Reasoning Task for LLMs", "authors": "Lars Bungum,Charles Yijia Huang,Abeer Kashar", "background": "本研究探索了LLMs在时间推理方面的能力。通过一本1940年的挪威书籍，书中包含了 trivia 问题，研究人员促使LLMs以1940年的身份回答这些问题。问题同时用英语和挪威语提出。正确答案常以句子形式给出，评分通过LLMs作为评判者，同时抽样检查由母语者进行。研究发现，使用英语提示比用挪威语提示结果更好，这是一个意外的结果。使用更大的LLMs也有助于提高结果。研究测试了DeepSeek-R1、Gemma3、Qwen3、Llama3.1模型家族以及特别为挪威语设计的最新大模型。", "innovation": "本研究创新点在于探索LLMs在历史推理任务中的表现，特别是通过时间倒退回1940年这一方式，提出了一个新的研究视角。另外，发现使用英语提示的LLMs表现更好和更大模型有更好的效果这两个意外结果也增加了研究的创新性。", "conclusion": "本研究发现，LLMs在1940年这一历史场景下的表现由于提示语言和模型大小的不同而有显著差异。使用英语提示的LLMs表现较好，而使用更大模型也有助于提高结果。这些研究结果为进一步探索LLMs在历史推理和时间推理中的能力提供了参考。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04476", "html_url": "https://arxiv.org/abs/2511.04476", "title": "Probabilistic Textual Time Series Depression Detection", "title_en": "Probabilistic Textual Time Series Depression Detection", "authors": "Fabian Schmidt,Seyedehmoniba Ravan,Vladimir Vlassov", "background": "准确和可解释的抑郁症严重程度预测对于临床决策支持至关重要，但现有的模型通常缺乏不确定性估计和时间建模。在精神健康领域，临床决策支持依赖于准确和可解释的抑郁症评估，然而现有的文本预测模型经常无法提供这些特性，尤其是在时间上的不确定性估计和建模方面存在不足。因此，需要一种新的框架来预测基于话语级别的临床访谈的PHQ-8评分，并能够建模时间上的不确定性。", "innovation": "提出了一种名为PTTSD的概率文本时间序列抑郁症检测框架，能够根据话语级别临床访谈进行PHQ-8评分预测，并建立时间上的不确定性建模。该框架包括序列到序列和序列到一的变体，并结合了双向LSTM、自注意力和残差连接，以及高斯或学生t分布输出头，通过负对数似然进行训练。该模型在E-DAIC和DAIC-WOZ数据集上实现了最先进的性能（例如，MAE分别为3.85和3.55），并生成了良好的预测区间。除了实验证明外，还通过消融实验验证了注意力和概率建模的价值，并与MentalBERT进行了比较以证明其普遍性。此外，三部分的校准分析和定性案例研究进一步突出了基于不确定性预测的可解释性和临床相关性。", "conclusion": "PTTSD在预测抑郁症严重程度方面表现出色并且具有预测不确定性的能力，这对于临床决策具有重要意义。通过对该模型的多方面的评估，证实了该模型在抑郁症预测中的可靠性和临床适用性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04491", "html_url": "https://arxiv.org/abs/2511.04491", "title": "RUST-BENCH：结构化表格中非结构化文本对大语言模型推理能力的基准测试", "title_en": "RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables", "authors": "Nikhil Abhyankar,Purvi Chaurasia,Sanchit Kabra,Ananya Srivastava,Vivek Gupta,Chandan K. Reddy", "background": "现有的表格推理基准大多针对小规模和统一的表格进行测试，这未能充分反映出真实世界数据的复杂性，从而对大语言模型（LLMs）的推理能力给出了不完整的评估。真实世界的表格往往是冗长且异构的，包含结构化字段和自由文本，要求进行跨越数千个标记的多步推理。因此，为了填补这一空白，作者引入了RUST-BENCH，一个包含来自两个领域的2031个实际表格中的7966个问题的新基准，涉及RB-Science（NSF科学基金记录）和RB-Sports（NBA统计数据）。", "innovation": "RUST-BENCH的独特之处在于，它不仅跨规模、异构性、领域特异性和推理复杂性联合评估LLMs，而且使用开源和专有模型实验证明了LLMs在异构模式和复杂多步骤推理方面存在持续的弱点，推动了新的策略，从而创建了一个新的具有挑战性的测试平台，以推进表格推理的研究。", "conclusion": "RUST-BENCH为促进表格推理研究建立了一个具有挑战性的新测试平台，显示了当前模型在这方面的局限性，提示了进一步的策略需求和发展方向。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04495", "html_url": "https://arxiv.org/abs/2511.04495", "title": "OUNLP在TSAR 2025共享任务中的成果：通过代码生成实现多轮文本简化", "title_en": "OUNLP at TSAR 2025 Shared Task: Multi-Round Text Simplifier via Code Generation", "authors": "Cuong Huynh,Jie Cao", "background": "本文描述了提交给TSAR-2025共享任务的OUNLP系统（Alva-Manchego等，2025年），该系统基于LLM提示生成技术用于读写性控制的文本简化。通过对基于提示的文本简化方法的分析，发现文本简化性能与来源CEFR水平和目标CEFR水平之间的差距密切相关。", "innovation": "本文提出并实施了两种多轮简化方法：基于规则的简化（MRS-Rule）和联合基于规则的LLM简化（MRS-Joint）。此方法通过GPT-4o生成。研究结果表明，将LLM简化的候选结果作为起点，可以进一步提高多轮简化效果。", "conclusion": "提交的系统在20个团队中排名第7。后来对MRS-Joint的改进证明了将LLM简化候选结果作为起点可以进一步提升多轮简化效果。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04527", "html_url": "https://arxiv.org/abs/2511.04527", "title": "语言模型是否意识到未选择的道路？token级别的不确定性与隐藏状态动态", "title_en": "Are language models aware of the road not taken? Token-level uncertainty and hidden state dynamics", "authors": "Amir Zur,Atticus Geiger,Ekdeep Singh Lubana,Eric Bigelow", "background": "在生成文本时，语言模型的选择会引导其走不同的推理路径，使得不确定性难以量化。研究者们探索了在链式推理中语言模型是否考虑了它们可以采取的替代路径。", "innovation": "该研究使用隐藏激活来控制和预测语言模型在链式推理中的不确定性，并发现模型的不确定性水平与模型可以通过控制其激活轻松被引导的程度之间存在显著相关性。这表明，当模型尚未完全承诺到特定答案时，通过激活干预可以最有效地引导模型。此外，研究还发现隐藏激活可以预测模型未来结果的概率分布，证明了模型隐式地代表了可能路径的空间。", "conclusion": "该研究揭示了语言模型在生成文本过程中对替代路径的认知能力，以及通过激活干预可以影响模型的行为，展示了语言模型在处理不确定性和探讨多种结果时的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04499", "html_url": "https://arxiv.org/abs/2511.04499", "title": "在大型语言模型中解码涌现的大五人格特质：温度依赖的表达与架构聚类", "title_en": "Decoding Emergent Big Five Traits in Large Language Models: Temperature-Dependent Expression and Architectural Clustering", "authors": "Christos-Nikolaos Zacharopoulos,Revekka Kyriakoglou", "background": "随着大型语言模型（LLMs）在人类中心应用中的作用愈发重要，理解其类似人格的行为变得越来越关键，这对负责任的开发与部署至关重要。本文系统性地评估了六种LLMs，并利用大五人格量表第二版（BFI-2）框架来评估在不同采样温度下的特质表达。研究发现五个性格维度中有四个存在显著差异，情绪神经质性和外向性易受温度调整的影响。进一步的层次聚类揭示了不同的模型簇，表明架构特征可能使某些模型倾向于稳定的特质画像。", "innovation": "本文采用大五人格量表第二版（BFI-2）框架，系统性地评估了六种大型语言模型在不同采样温度下的特质表达。研究发现了一些新的见解，即在LLMs中人格样的模式是如何出现的，并提供了一个新的模型调优、选择以及人工智能系统伦理治理的视角。", "conclusion": "这些结果提供了新的见解，深入了解了大型语言模型中人格样模式的出现，并为模型调优、选择以及AI系统的伦理治理提供了一个新视角。同时，相关数据和代码可以在以下链接找到：this https URL"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04538", "html_url": "https://arxiv.org/abs/2511.04538", "title": "从模型到漏洞：向可操作的LLM生成漏洞报告迈进", "title_en": "From Model to Breach: Towards Actionable LLM-Generated Vulnerabilities Reporting", "authors": "Cyril Vallez,Alexander Sternfeld,Andrei Kucharavy,Ljiljana Dolamic", "background": "随着基于大型语言模型（LLM）的编码助手在软件开发中的作用越来越关键，这些模型生成的漏洞在整体网络安全领域的角色也越来越重要。虽然已经提出了许多LLM代码安全基准以及改进生成代码安全性的方法，但尚不清楚这些方法对广泛应用的LLM产生了多大影响。现有的安全-功能权衡尚未有效地解决漏洞修补问题。", "innovation": "本文引入了一个新的严重性度量标准——Prompt Exposure（PE），以反映LLM生成漏洞带来的风险，考虑漏洞的严重性、生成概率以及激发漏洞代码生成的提示——Prompt Exposure（PE）。为了鼓励缓解最严重和最普遍的漏洞，使用PE定义了Model Exposure（ME）评分，表示模型生成的漏洞的严重性和普遍性。", "conclusion": "该研究突显了即使是最新的开源权重模型也存在漏洞，表明目前的安全-功能权衡未能有效修复漏洞。ME评分可以通过识别和优先处理生成漏洞的严重性和普遍性的LLM模型，为解决这一问题提供了一种新的方法。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04528", "html_url": "https://arxiv.org/abs/2511.04528", "title": "IntelliProof: 以论证网络为基础的对话辅助工具，用于有组织的反思", "title_en": "IntelliProof: An Argumentation Network-based Conversational Helper for Organized Reflection", "authors": "Kaveh Eskandari Miandoab,Katharine Kowalyshyn,Kabir Pamnani,Anesu Gavhera,Vasanth Sarathy,Matthias Scheutz", "background": "当前自动作文评分系统主要关注评分准确性和自动化程度，但缺乏对用户体验的深入关注。此外，这些系统在理解和评估论证性文章结构上存在一定局限。因此，需要一个既能准确评分又能提供用户友好界面并支持论证结构分析的系统。IntelliProof应运而生，旨在解决这些问题。", "innovation": "IntelliProof 通过将文章结构化为论证图来创新性地理解和评估论证性文章。每个声明作为节点，支持证据作为节点属性，边表示支持或反驳关系。不同于现有的自动作文评分系统，IntelliProof 强调用户体验，每种关系首先由语言模型分类和评分，然后可视化展示以增强理解。系统还提供了论证的解释和数量级一致性度量，支持快速探索论证质量并保有人类监督。此外，还提供了一组工具来更好地解释文章及其对应的图，连接论证性文章的结构语义和用户对给定文本的理解。", "conclusion": "IntelliProof 通过将论证性文章可视化为网络图，并利用语言模型进行自动化评价，提供了一个新的、用户友好的评估框架。这不仅提高了评估的准确性和效率，而且通过可视化和交互式工具增强了用户体验。未来的改进方向可能包括提高语言模型的准确性和增加更多的用户界面功能。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04506", "html_url": "https://arxiv.org/abs/2511.04506", "title": "在放射学报告中建模临床不确定性：从显式不确定标记到隐含推理路径", "title_en": "Modeling Clinical Uncertainty in Radiology Reports: from Explicit Uncertainty Markers to Implicit Reasoning Pathways", "authors": "Paloma Rabaey,Jong Hak Moon,Jung-Oh Lee,Min Gwan Kim,Hangyul Yoon,Thomas Demeester,Edward Choi", "background": "放射学报告对于临床决策至关重要，并具备通过结构化成机器可读格式进行自动化分析的潜力。这些报告中经常包含不确定性，可分为两种类型：第一种是显式不确定性，表现为对发现的有无持保留态度，通过修辞词语传达，这些词语的含义依赖于上下文，并不适合使用规则系统量化特定发现的不确定性水平；第二种是隐式不确定性，当放射学家省略推理过程的一部分时产生，只记录关键发现或诊断。这部分内容可能会对外隐藏真正缺失的发现或只是出于简洁考虑遗漏。\n", "innovation": "提出了一个两阶段框架来解决这些挑战：一是通过创建由专家验证的LLM（大规模语言模型）为基础的参考排名来量化显式不确定性，该排名基于分类依据对常见修辞词进行排名，并根据参考对每个发现映射到一个概率值；二是模型隐式不确定性，通过扩展框架系统地扩充专家定义的诊断路径生成的特色子发现，涵盖14个常见诊断。采用这些方法，发布了一个增强并意识到了不确定性的版本Lunguage++基准，这种增强的资源可以支持基于不确定性的图像分类，忠实的诊断推理，并对诊断不确定性在临床中的影响进行新的研究。\n", "conclusion": "通过这种方法，项目成功地量化了显式不确定性和扩展了隐含推理路径，丰富了现有的Lunguage基准数据集，使得研究人员能够更准确地理解和分析放射学报告中的不确定性，并为未来的临床决策和研究提供支持。\n"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04560", "html_url": "https://arxiv.org/abs/2511.04560", "title": "BanglaMedQA和BanglaMMedBench：评估用于孟加拉医学问题回答的检索增强生成策略", "title_en": "BanglaMedQA and BanglaMMedBench: Evaluating Retrieval-Augmented Generation Strategies for Bangla Biomedical Question Answering", "authors": "Sadia Sultana,Saiyma Sittul Muna,Mosammat Zannatul Samarukh,Ajwad Abrar,Tareque Mohmud Chowdhury", "background": "在低资源语言中开发准确的生物医学问答（QA）系统仍是一个重大挑战，限制了对可靠医学知识的平等访问。开发针对孟加拉语的大型生物医学多项选择题（MCQ）数据集，以评估医学人工智能中的推理和检索能力，对于解决这一挑战至关重要。", "innovation": "提出了BanglaMedQA和BanglaMMedBench数据集，并介绍了传统的、零样本回退、代理、迭代反馈和聚合检索增强生成（RAG）策略。这些策略结合了基于教科书和网络的检索以及生成式推理，提高了事实准确性。关键创新在于通过光学字符识别（OCR）整合了孟加拉语医学教科书语料库，并实施了一个动态选择检索和推理策略的代理RAG管道。", "conclusion": "实验结果显示，代理RAG在openai/gpt-oss-120b模型上的准确率为89.54%，优于其他配置，证明了RAG方法在增强孟加拉语医学QA可靠性和可访问性方面的潜力，为多语言医学人工智能的研究奠定了基础。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04502", "html_url": "https://arxiv.org/abs/2511.04502", "title": "RAGalyst：针对特定领域的RAG自动化人类对齐代理评估框架", "title_en": "RAGalyst: Automated Human-Aligned Agentic Evaluation for Domain-Specific RAG", "authors": "Joshua Gao,Quoc Huy Pham,Subin Varghese,Silwal Saurav,Vedhus Hoskere", "background": "RAG（检索增强生成）是将大型语言模型（LLM）与事实证据对接的关键技术，但在特殊且安全性至关重要的领域中评估RAG系统仍是一个显著挑战。现有的评估框架多依赖启发式的评估指标，不能充分捕捉到专业领域的细微差别，还有一些工作采用LLM作为裁判的方法，这类方法与人类判断的对齐尚未被验证。", "innovation": "本文提出了一种名为RAGalyst的自动化人类对齐代理框架，旨在为特定领域的RAG系统提供严谨的评估。RAGalyst通过一个代理流程从原始文档中生成高质量模拟的问答（QA）数据集，并加入一个代理过滤步骤以确保数据真实性。利用代理流程优化两大关键LLM作为裁判的指标：答案正确性和可回答性，从而与人工注释产生强相关性。在军事操作、网络安全和桥梁工程三个不同领域评估RAG组件时发现，性能高度依赖于上下文，没有单一的嵌入模型、LLM或超参数配置能普遍最优，分析了RAG中答案不正确最常见的原因，强调了RAGalyst这种系统评估框架的重要性，能帮助实践者发现领域特定的权衡，从而做出有见识的设计选择，构建可靠有效的RAG系统。RAGalyst已在Github上开源.", "conclusion": "RAGalyst为特定领域的RAG系统的评估提供了一种系统性框架，揭示了领域特定的权衡因素，从而指导可靠有效RAG系统的构建。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04643", "html_url": "https://arxiv.org/abs/2511.04643", "title": "当检索超越生成：密集证据检索在可扩展虚假新闻检测中的应用", "title_en": "When retrieval outperforms generation: Dense evidence retrieval for scalable fake news detection", "authors": "Alamgir Munir Qazi,John P. McCrae,Jamal Abdul Nasir", "background": "信息虚假传播的日益严重提示了需要建立高效且计算高效的事实验证系统。当前最先进的方法依赖大型语言模型（LLMs）进行解释性推理，但这些方法在实际应用中面临着计算能力和虚构信息风险的双重挑战。为了应对这些挑战，研究引入了一种称为DeReC（密集检索分类）的轻量级框架，展示了通用文本嵌入如何在事实验证任务中代替自回归LLM的方法。通过将密集检索与专门的分类相结合，该系统在准确性和效率方面都表现出色。DeReC在多种数据集中展示了其有效性，特别是在处理需要高效运行的场景下。", "innovation": "DeReC框架通过融合密集检索和专有分类方法，实现了更加高效准确的事实验证。与当前解释性推理的LLM方法相比，DeReC大幅减少了运行时间（95%-92%），同时保持或超越了最新的方法L-Defense在F1分数上的表现，特别是在RAWFC数据集上达到了65.58%的F1分数，这表明精心设计的检索基础系统在特定任务中可以匹配甚至超过LLM的性能，并且更为实用便于实际部署。", "conclusion": "研究结果表明，细心构建的基于检索的系统可以在特定任务中达到或超过大型语言模型的性能，同时在实际部署中更为实用。DeReC展示了密集检索在大规模虚假新闻检测中的潜力和优势，揭示了在特定任务中检索方法的重要性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03939", "html_url": "https://arxiv.org/abs/2511.03939", "title": "RLHF：文化、多模态和低延迟对齐方法的全面调研", "title_en": "RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods", "authors": "Raghav Sharma,Manan Mehta,Sai Tiger Raina", "background": "RLHF 是目前标准化的大型语言模型（LLM）对齐方法，但最近的进步已经超越了传统的基于文本的方法。本文综述了该领域的最新发展，特别是集中在多模态对齐、文化公平性和低延迟优化等关键领域。", "innovation": "本文系统性地介绍了最新的对齐技术，包括 PPO、DPO 和 GRPO 等基础算法，并详细分析了这些技术的最新创新。通过提供这些技术的对比分析，并指出尚存的挑战，本文为构建更为稳健、高效和公平的AI系统提供了关键指导。", "conclusion": "本文工作作为研究人员的路线图，帮助他们深入了解该领域并应对挑战，从而推动更稳健、高效和公平的AI系统的发展。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03942", "html_url": "https://arxiv.org/abs/2511.03942", "title": "MIDI-LLM: 将大规模语言模型适应于文本到MIDI音乐生成", "title_en": "MIDI-LLM: Adapting Large Language Models for Text-to-MIDI Music Generation", "authors": "Shih-Lun Wu,Yoon Kim,Cheng-Zhi Anna Huang", "background": "当前，文本到MIDI音乐生成面临的主要挑战是，如何将语言模型（LLM）的能力扩展到生成多轨MIDI音乐，特别是在保持高质量和快速推理的同时，能够更好地控制文本内容。", "innovation": "MIDI-LLM 的创新之处在于它通过扩展文本LLM的词汇表，引入MIDI令牌，并采用两阶段训练方法来增强其从自由形式的文本提示生成多轨MIDI音乐的能力。同时，MIDI-LLM 保持了原始LLM的参数结构，从而可以直接利用vLLM库进行加速推理。", "conclusion": "实验结果表明，相较于最近的 Text2midi 模型，MIDI-LLM 在生成质量、文本控制能力和推理速度方面表现出更好的性能。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04654", "html_url": "https://arxiv.org/abs/2511.04654", "title": "Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought Reasoning", "title_en": "Logit-Entropy Adaptive Stopping Heuristic for Efficient Chain-of-Thought Reasoning", "authors": "Mohammad Atif Quamar,Mohammad Areeb", "background": "链式思维（CoT）提示是大型语言模型中启用复杂推理的关键技术。然而，生成完整的、固定长度的推理过程在计算上是浪费的，增加了令牌使用量和延迟时间。现有的方法必须生成完整的推理过程，即使推理发生后，产生固定长度的推理也不一定能有效优化模型性能。这项研究旨在寻找一种不需要训练且能够自动控制推理生成过程的替代方法，以提高推理效率和减少计算资源浪费。", "innovation": "作者提出了LEASH（Logit-Entropy Adaptive Stopping Heuristic，逻辑熵自适应终止启发式），这是一种不需要训练的解码算法，能够自适应地终止推理过程。LEASH监测两个内在信号：token级熵的斜率和顶级 logits 差值的改进。当这两个信号出现平台期时，LEASH终止推理过程，表明模型已经达到了一个稳定的推理状态。这种方法主要创新点在于不需要额外的训练或监督，并且能够保持较高的推理准确度同时显著降低令牌生成和延迟时间。", "conclusion": "在GSM8K和AQuA-RAT基准测试中进行的实验表明，LEASH方法可以将平均令牌生成减少30%-35%，延迟减少27%，并且相对于CoT方法仅降低10%的准确率。LEASH方法模型兼容性强，能够显著提高链式思维推理的效率，同时不需要额外的训练和监督，提供了一种简单且高效的替代CoT解码的方法。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04000", "html_url": "https://arxiv.org/abs/2511.04000", "title": "通过合成模型生成实现可解释模型的可扩展元学习", "title_en": "Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations", "authors": "Kyaw Hpone Myint,Zhe Wu,Alexandre G.R. Day,Giri Iyengar", "background": "决策树因其可解释性而在高风险领域如金融和健康医疗中广泛应用。本文介绍了一种高效且可扩展的方法，用于生成合成预训练数据，以实现决策树的元学习。通过合成生成接近最优的决策树，该方法能够创建大规模且具有现实意义的数据集。", "innovation": "本文提出了一种使用MetaTree变压器架构的合成方法，该方法能够生成接近最优的解释性强的决策树模型。这种方法在性能上能达到与基于真实数据预训练或使用计算昂贵的最优决策树方法相当的效果。同时，该策略显著降低了计算成本，增强了数据生成的灵活性，为可解释决策树模型的可扩展和高效元学习开辟了新的途径。", "conclusion": "该方法通过合成生成接近最优的解释性强的决策树模型，实现了与真实数据预训练或计算昂贵的最优决策树方法相当的性能，同时显著降低了计算成本，增强了数据生成的灵活性，为可解释决策树模型的元学习提供了有效途径。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03958", "html_url": "https://arxiv.org/abs/2511.03958", "title": "多智能体协作框架下的数学问题生成", "title_en": "Multi-Agent Collaborative Framework For Math Problem Generation", "authors": "Kia Karbasi,Kevin Hong,Mohammad Amin Samadi,Gregory Pottie", "background": "数学教育中的自动问题生成（AQG）仍然是智能辅导系统（ITS）和教育者难以实现的目标。尽管预训练的变压器基语言模型在自然语言生成方面取得了重大进展，但在精确控制问题复杂性和认知需求方面仍然存在困难。因此，需要新的方法来提高AQG的质量和控制能力。", "innovation": "该论文介绍了一种新的多智能体协作框架，通过在生成过程中引入推理时的计算，迭代精炼生成的问题-答案对，以更好地平衡复杂性与认知需求。通过五项元评价标准（相关性、重要性、清晰度、难度匹配、可回答性）对生成的问题进行评价，展示了该方法在提升生成教育资源质量方面取得的显著成果。", "conclusion": "初步评估表明，此多智能体协作框架通过促进认知挑战与清晰度之间的更加精细化平衡，提高了生成教育内容的质量。这些初步成功的结果表明，集成协作多智能体工作流程可能会产生受控且教育上更丰富的内容，有利于推动自动教育内容生成和自适应学习环境的发展。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04048", "html_url": "https://arxiv.org/abs/2511.04048", "title": "pushdown自动机中的可探索性", "title_en": "Explorability in Pushdown Automata", "authors": "Ayaan Bedi,Karoliina Lehtinen", "background": "研究了可探索性这一措施，它泛化了历史确定性。一个自动机在读取输入时，如果可以仅通过k个并行运行构建的基于当前已见输入的逐步构造接受路径（如果存在），那么这个自动机被称为k可探索的。研究发现，可探索性PDA类在表达能力和简洁性上严格介于历史确定性和完全非确定性PDA类之间。随着可探索性的增加，会形成一个无限的分层结构：每个级别k定义了一个比级别k-1更强大的表达性类，但整个类仍然比一般非确定性PDA类弱。", "innovation": "提出了参数化的可探索性概念，允许运行数取决于输入长度，并证明了指数可探索性精确捕捉了上下文自由语言。还证明了可探索性PDA可以比历史确定性PDA双指数级更简洁，并且确定性和2可探索性PDA之间的简洁性差距不是可枚举的。", "conclusion": "可探索性作为可操作的、具有鲁棒性的非确定性度量指标在堆栈系统中的作用得到了重新定位。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03731", "html_url": "https://arxiv.org/abs/2511.03731", "title": "MimiTalk: 通过双重代理AI革新定性研究", "title_en": "MimiTalk: Revolutionizing Qualitative Research with Dual-Agent AI", "authors": "Fengming Liu,Shubin Yu", "background": "本文介绍了MimiTalk，一个旨在促进社会科学领域可扩展且合乎伦理的对话数据收集的双重代理宪法AI框架。MimiTalk框架结合了监督模型进行战略监督和对话模型进行问题生成。研究包括三部分：第一部分通过20名参与者测试其易用性；第二部分将121次AI访谈与通过MediaSum数据集收集的1,271次人类访谈进行对比分析；第三部分涉及10名跨学科研究人员进行人机访谈，并进行了盲主题分析。研究结果表明，MimiTalk减少了访谈焦虑，保持了对话的连贯性，并在信息丰富度、连贯性和稳定性方面超过了人类访谈。AI访谈在技术见解和敏感话题上的直言不讳更强，而人类访谈在文化情感细微之处的捕捉方面更具优势。这些发现表明，双重代理宪法AI支持高效的人机协作，使定性研究能够实现可复制、可扩展和质量控制。", "innovation": "MimiTalk框架是首款专门设计用于提高社会科学中定性研究的可扩展性和伦理性的双重代理宪法AI框架。该框架通过结合监督模型和对话模型，有效解决了对话数据收集中的关键问题，包括提高访谈效率、减轻访谈焦虑和保持对话连贯性，同时确保相关信息丰富、稳定和准确，特别适用于获取技术见解和敏感话题信息。该框架的创新点在于其双重代理设计确保了人类与AI协作的有效性，支持了高质量的定性研究。", "conclusion": "研究表明，双重代理AI框架MimiTalk在降低访谈焦虑、保持对话连贯性和提供丰富信息方面优于人类访谈。MimiTalk在技术洞察和敏感话题上的表现优于人类访谈，而人类访谈则在文化情感表达上更优。这些发现表明，双重代理宪法AI能够支持有效的人机协作，实现可复制的高质量定性研究。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03980", "html_url": "https://arxiv.org/abs/2511.03980", "title": "LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing", "title_en": "LLMs and Cultural Values: the Impact of Prompt Language and Explicit Cultural Framing", "authors": "Bram Bulté,Ayla Rigouts Terryn", "background": "大型语言模型（LLMs）已在全球范围内被用户广泛采用，用户使用这些模型的语言各不相同。然而，这些模型在训练数据和优化目标方面存在不平衡，这引发了对LLMs是否能够反映广泛用户群体的文化多样性的疑问。本研究探讨LLMs与文化价值观之间的关系，并研究提示语言和文化框架如何影响模型回应及其与不同国家人类价值观的契合程度。", "innovation": "研究团队对10种LLM进行了实验，使用了来自霍夫斯泰德价值观调查模块和世界价值观调查的63个项目，这些项目已被翻译成11种语言，并根据不同的文化视角进行了提示公式化。这项研究表明，提示语言和文化视角都会影响LLM的输出，尽管定向提示可以在一定程度上引导LLM回应接近目标国家主导的价值观，但并不能克服模型系统性地偏向特定国家的价值观，如荷兰、德国、美国和日本。无论模型源自何处，所有测试的模型在大多数话题上表现出相对中立的回应，并在社会宽容等问题上表现得比较进步。Explicit文化框架比定向提示语言更能提高与人类受访者文化价值观的契合度。意外的是，两种方法的结合效果并不比使用英语提示的Explicit文化框架更好。", "conclusion": "这些发现揭示了LLMs处于一个令人不安的中间地带：它们对提示变化的反应足够灵敏以产生变化，但因根植于特定文化默认设置而无法充分反映文化多样性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03825", "html_url": "https://arxiv.org/abs/2511.03825", "title": "不同分词算法对二进制代码分析中LLMs和Transformer模型的影响", "title_en": "How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis", "authors": "Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder", "background": "分词是低级代码分析中的基本步骤，对词汇量大小、语义覆盖范围和下游任务的外在性能产生影响。尽管其重要性，分词在汇编代码中的应用仍然没有得到充分探索。本研究旨在通过评估自然语言处理（NLP）分词模型和参数选择（如词汇量大小）的内在特性来填补这一空白，并探索为汇编代码定制的预处理和预分词规则，以评估其对下游任务（如函数签名预测）的影响。研究系统地分析了各种分词模型在编码汇编指令和捕捉语义细微差别的效率。使用最新的预训练模型（如只解码的大型语言模型Llama 3.2、只编码的变压器BERT和编码-解码模型BART），评价了这些分词器在多种性能指标下的有效性。初步结果表明，分词器的选择显著影响下游性能，内在指标对外在评估结果的预测具有部分但不完全解释性。这些结果揭示了内在分词器属性与其实用性之间的复杂权衡。研究表明，优化基于分词模型的二进制代码分析可以增强自然语言模型（NLM）的工作流程的鲁棒性和可扩展性。", "innovation": "研究评估了NLP分词模型及其参数选择（如词汇量大小）的内在特性，并探索了为汇编代码定制的预处理和预分词规则，以优化下游任务的性能。同时，通过使用最先进的预训练模型，研究了这些分词器在多个性能指标下的有效性，并揭示了内在分词器属性和其实用性之间的复杂权衡。这为低级代码的自然语言模型（NLM）驱动的二进制分析提供了有益的见解，增强了工作流程的鲁棒性和可扩展性。", "conclusion": "研究表明，分词器选择显著影响下游性能，内在指标对外在评估结果仅具有部分解释力。这些结果揭示了内在分词器属性与其实用性之间的复杂权衡。最终，该研究提供了优化分词模型以增强低级代码分析的有益见解，从而增强基于NLM的二进制分析工作流程的鲁棒性和可扩展性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04106", "html_url": "https://arxiv.org/abs/2511.04106", "title": "子代增长在线词汇使用中的指数变化：分段幂律模型", "title_en": "Sub-exponential Growth in Online Word Usage: A Piecewise Power-Law Model", "authors": "Hayafumi Watanabe", "background": "社会中思想和语言的传播传统上被描述为S型模型，如逻辑曲线。在更广泛的社会现象中，次指数增长（在流行病学中已知为比指数模式更慢的增长）的作用被广泛忽视。本文作者采用分段幂律模型来描述复杂的增长曲线，并系统分析了大约一亿篇日本博客文章的数据集，以及英语、西班牙语和日语的网络搜索趋势数据。作者发现约55%的项目表现出无突变的特点，可以由一个或两个片段描述。研究表明次指数增长是一种普遍的社会扩散模式，且该模型提供了一种描述、比较和解释复杂多样增长曲线的有效框架。", "innovation": "论文提出了一种分段幂律模型以表征具有少量参数的复杂增长曲线。该模型能系统地分析大规模数据集，揭示次指数增长是社会扩散的常见模式。通过区分向外接触陌生人与向内与群体内部互动的行为模型，提出了alpha参数可视为偏向外向沟通的指数的解释，从而展示了次指数增长模型的创新性。", "conclusion": "次指数增长是一种常见的社会扩散模式，模型为持续描述、比较和解释复杂多样的增长曲线提供了实践框架。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04172", "html_url": "https://arxiv.org/abs/2511.04172", "title": "转型导师角色：基于AI的聊天机器人在大学指导中的应用", "title_en": "Transforming Mentorship: An AI Powered Chatbot Approach to University Guidance", "authors": "Mashrur Rahman,Mantaqa abedin,Monowar Zamil Abir,Faizul Islam Ansari,Adib Reza,Farig Yousuf Sadeque,Niloy Farhan", "background": "大学本科生在学习过程中面临着巨大的挑战，通常缺乏能够大规模个性化指导的导师。虽然数字化工具存在，但针对新入学学生的定制化辅导严重不足。因此，论文提出了一款基于AI的聊天机器人，旨在为布加奇大学的本科生提供指导服务。", "innovation": "论文创新性地设计了一款结合了BM25词汇排名和ChromaDB语义检索的聊天机器人，通过大型语言模型LLaMA-3.3-70B生成对话响应。实验结果显示，生成的文本具有高度的语义相关性，BERTScore达到0.831，METEOR得分为0.809。此外，数据处理管道也非常高效，更新数据仅需106.82秒，新数据则需要368.62秒。这使得聊天机器人能够在回答查询、帮助学生更好地理解大学生活以及协助制定未来学期的计划等方面发挥作用。", "conclusion": "该论文展示了一种利用AI技术改进导师传统角色的方法，通过高效的聊天机器人系统，为大学新生提供定制化的、个性化的指导。这些创新将有助于提高学生的学习体验和大学生活的适应性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04063", "html_url": "https://arxiv.org/abs/2511.04063", "title": "DartQuant: 高效旋转分布校准用于大语言模型量化", "title_en": "DartQuant: Efficient Rotational Distribution Calibration for LLM Quantization", "authors": "Yuantian Shao,Yuanteng Chen,Peisong Wang,Jianlin Yu,Jing Lin,Yiwu Yao,Zhihui Wei,Jian Cheng", "background": "量化在加速大规模模型的推理方面起着至关重要的作用，旋转矩阵已被证明能通过平滑异常值来有效地提升量化性能。然而，端到端的旋转优化算法微调会带来高额的计算成本并容易导致过拟合。为了解决这一挑战，我们提出了一种高效分布感知旋转校准方法，即DartQuant，该方法通过约束旋转后的激活分布来降低旋转优化的复杂性。此外，该方法还能有效减少对任务特定损失的依赖，从而降低了过拟合的风险。我们还引入了一种QR-Orth优化方案，替代了昂贵的交替优化，以更高效的解决方案来解决问题。在各种模型量化实验中，DartQuant 表现出了优越的性能，相比现有方法，其在70亿参数模型上实现了47倍的加速和10倍的内存节省。此外，这是第一个在单块3090 GPU 上成功完成70亿参数模型旋转校准的方法，使大语言模型的量化在资源受限环境中得以实现。", "innovation": "提出了DartQuant方法，这是一种高效分布感知的旋转校准方法，通过约束旋转后的激活分布来降低旋转优化的复杂性。此外，引入了QR-Orth优化方案，替代了昂贵的交替优化。实验表明，DartQuant在大幅度加速和节省内存方面表现优越，并首次在单块3090 GPU 上成功完成了70亿参数模型的旋转校准，解决了大语言模型量化中的资源限制问题。", "conclusion": "DartQuant展示了优越的性能，在70亿参数模型上实现了47倍的加速和10倍的内存节省，并在资源受限的环境中成功进行了大语言模型的量化。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04161", "html_url": "https://arxiv.org/abs/2511.04161", "title": "直视前方：高效OCR中的文档导向检测", "title_en": "Seeing Straight: Document Orientation Detection for Efficient OCR", "authors": "Suranjan Goswami,Abhinav Ravi,Raja Kolla,Ali Faraz,Shaharukh Khan,Akash,Chandra Khatri,Shubham Agarwal", "background": "尽管在文档理解方面取得了显著进展，但在实际场景中，确定扫描或拍摄文档的正确方向仍是关键的预处理步骤。准确的旋转校正是为了提升如光学字符识别（OCR）等下游任务的表现，这些任务通常由于用户错误，特别是在拍摄时未正确调整相机基线导致文本对齐偏差。", "innovation": "本文引入了OCR-Rotation-Bench (ORB)，一个新的评估OCR对图像旋转鲁棒性的基准，包括ORB-En（基于旋转变换的结构化和自由形式的英语OCR数据集）和ORB-Indic（包含11种印地语中等和低资源语言的新颖多语言数据集）。同时，提出了一个基于Phi-3.5-Vision模型视觉编码器的快速、鲁棒且轻量级旋转分类管道，通过动态图像裁剪进行微调，专为4类旋转任务设计。该方法在两个数据集上的识别准确率分别达到了96%和92%。此外，该模块还展示了在模拟的真实场景中提升OCR性能的关键作用，无论是商用还是开源模型都能显著提升表现，最高可达14%和4倍。", "conclusion": "本文通过介绍OCR-Rotation-Bench基准和基于Phi-3.5-Vision模型的旋转分类管道，提出了有效的文档旋转矫正方法，显著提升了OCR在实际应用中的性能表现。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04418", "html_url": "https://arxiv.org/abs/2511.04418", "title": "不确定性之幻象：大语言模型下的不确定性量化在含糊情况下失效", "title_en": "The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity", "authors": "Tim Tomov,Dominik Fuchsgruber,Tom Wollschläger,Stephan Günnemann", "background": "在真实世界中，语言是固有的模糊和不确定的，这反映了偶然性不确定性。现有的不确定性量化（UQ）方法通常是在没有模糊性的任务中进行基准测试的。但是现有的UQ方法在处理模糊性数据时表现不佳，甚至接近随机性能。这一背景指出，当前的不确定性估计方法在面对含糊性数据时存在着根本性的限制。", "innovation": "本文首次提出了MAQA*和AmbigQA*，这是第一个含模糊问题和答案的数据集，具有基于事实共现估计的真实答案分布。此外，研究发现不同的不确定性估计范式在这种情况下都表现不佳，这可以理论上来解释，揭示出预测分布和集成模型估算器在含糊性下是根本受限的。这一创新表明现有UQ方法在大语言模型中的局限，并促使重构当前的模型和方法论。", "conclusion": "整体而言，该研究揭示了现有对大语言模型不确定性量化方法的关键缺陷，并促使重新思考当前的方法论。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04215", "html_url": "https://arxiv.org/abs/2511.04215", "title": "黑箱护栏反向工程攻击", "title_en": "Black-Box Guardrail Reverse-engineering Attack", "authors": "Hongwei Yao,Yun Xia,Shuo Shao,Haoran Shi,Tong Qiao,Cong Wang", "background": "大型语言模型（LLMs）越来越多地采用护栏来约束其输出的道德、法律和应用特定限制。虽然这有助于减少有害反应，但护栏也引入了一类新的可被观察到的决策模式的漏洞。本文旨在探讨黑箱LLM护栏反向工程攻击。", "innovation": "本文提出了第一项关于黑箱LLM护栏反向工程攻击的研究。提出了一种基于强化学习的框架——护栏反向工程攻击（GRA），该框架利用遗传算法驱动的数据增强来逼近受害护栏的决策策略。通过迭代收集输入-输出对、优先处理分歧情况，并应用有针对性的突变和交叉操作，方法能够逐步接近护栏的高保真替代物。", "conclusion": "研究在三个广泛部署的商用系统——ChatGPT、DeepSeek和Qwen3上评估了GRA，结果表明其规则匹配率超过0.92，同时API成本不足$85。这些发现强调了护栏提取的实用可行性和当前LLM安全机制的重大安全风险。研究揭示了当前护栏设计中的关键漏洞并强调了对更稳健防护机制的迫切需求。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04473", "html_url": "https://arxiv.org/abs/2511.04473", "title": "用于增强知识图谱辅助LLM训练和评估的真实子图", "title_en": "Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge Graph Augmented LLMs", "authors": "Alberto Cattaneo,Carlo Luschi,Daniel Justus", "background": "从图形结构的知识数据库检索信息是提升语言模型事实性的一个有前景的方向。尽管已经提出了多种解决方案，但由于缺乏带有真实目标的挑战性问答数据集，比较不同方法的效果变得困难。为此，我们提出了一种名为SynthKGQA的框架，该框架可以从任何知识图谱中生成高质量的合成知识图谱问答数据集，提供知识图谱中的全部真实事实作为推理依据。", "innovation": "我们提出了SynthKGQA框架，可以从任何知识图谱中生成高质量的合成知识图谱问答数据集，并提供了知识图谱中所有真实事实来推理每个问题。我们展示了SynthKGQA生成的数据不仅能够更有效地基准测试知识图谱检索器，还能够训练更好的模型。", "conclusion": "我们利用SynthKGQA对Wikipedia数据集生成了GTSQA，旨在测试知识图谱检索器在面对未知图结构和关系类型时的零样本泛化能力，并在流行的增强知识图谱辅助的LLM解决方案上进行了基准测试。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04214", "html_url": "https://arxiv.org/abs/2511.04214", "title": "MXFP4量化中只需要块旋转", "title_en": "Block Rotation is All You Need for MXFP4 Quantization", "authors": "Yuantian Shao,Peisong Wang,Yuanteng Chen,Chang Xu,Zhihui Wei,Jian Cheng", "background": "尽管大型语言模型（LLMs）已经取得了显著的成功，但其快速增长的规模带来了内存、计算和能源方面的高昂成本。后训练量化（PTQ）是一种有效的部署解决方案，但是实现准确的W4A4量化仍是一个开放的挑战。大多数现有方法都针对INT4格式设计，而新出现的MXFP4格式（由NVIDIA、AMD和Intel等多种硬件支持）的出现，提出了现有技术适用性的问题。因此，本文通过实证方法对MXFP4格式下的PTQ方法进行了全面基准测试。", "innovation": "文章发现在MXFP4格式中，基于旋转的方法存在严重不兼容性问题，这是由于MXFP4的幂等块缩放和全局旋转在异常能量重新分布之间的根本性不匹配引起的。为此，作者提出了一个简单而有效的方法，将基于旋转的方法适应于MXFP4，从而大幅提高了不同LLM的准确性。", "conclusion": "研究表明，基于块旋转的方法（如GPTQ）在MXFP4格式中表现良好，而基于旋转的方法存在不兼容性问题。进一步的分析显示，这种不匹配的根本原因在于MXFP4的幂等块缩放与异常能量重新分布之间的不匹配。文章提出了一个简单而有效的块旋转策略，该策略将基于旋转的方法适应于MXFP4，从而在不同类型的LLM上实现了显著的准确性提升。该结果不仅为使用者提供了明确的指导，也为未来低精度格式下的PTQ研究奠定了基础。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04570", "html_url": "https://arxiv.org/abs/2511.04570", "title": "思考与视频：视频生成作为有希望的多模态推理范式", "title_en": "Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm", "authors": "Jingqi Tong,Yurong Mou,Hangcheng Li,Mingzhe Li,Yongzhuo Yang,Ming Zhang,Qiguang Chen,Tianyi Liang,Xiaomeng Hu,Yining Zheng,Xinchi Chen,Jun Zhao,Xuanjing Huang,Xipeng Qiu", "background": "现有的‘思考与文本’和‘思考与图像’范式显著提升了大型语言模型（LLMs）和视觉语言模型（VLMs）的推理能力，但这些范式有内在的局限性。图像只能捕捉单一时刻，不能很好地表示动态过程或连续变化。此外，将文本和视觉作为分离的模态，限制了统一多模态理解和生成。", "innovation": "研究引入了‘思考与视频’的新范式，利用视频生成模型（如Sora-2）在统一的时间框架内结合视觉和文本推理。同时开发了Video Thinking Benchmark（VideoThinkBench）测试基准，包含了视觉中心任务和文本中心任务。Sora-2在视觉中心任务中与最先进的视觉语言模型（SOTA）相当，甚至在某些任务上超过了VLMs；在文本中心任务中，Sora-2分别在MATH和MMMU上取得了92%和75.53%的准确率，并且结果显示自一致性与上下文学习可以进一步提升Sora-2的表现。", "conclusion": "研究发现视频生成模型有潜力实现统一的多模态理解和生成，定位‘思考与视频’为统一的多模态推理范式。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04584", "html_url": "https://arxiv.org/abs/2511.04584", "title": "我们提出的问题正确吗？关于表格数据分析中自然语言查询的歧义", "title_en": "Are We Asking the Right Questions? On Ambiguity in Natural Language Queries for Tabular Data Analysis", "authors": "Daniel Gomm,Cornelius Wolff,Madelon Hulsebos", "background": "自然语言界面处理表格数据时必须应对查询中的固有歧义。传统上，这种歧义被视为系统的缺陷，但本文将其重新定义为合作交互的特征，在这种交互中，用户和系统共同承担查询定义的责任。", "innovation": "作者开发了一个原则性的框架，将能够解决的查询（即协调查询）与不能解决的查询（即非协调查询）区分开来。通过将此框架应用于表格问答和分析评估，作者发现现有数据集中的查询类型混杂，既不适合评估系统的执行准确性，也不适合评估理解能力。这一框架和分析促使从解决歧义转向在查询解决过程中拥抱合作。这使得对于表格数据分析中的自然语言接口的设计和评估更加明智。", "conclusion": "本文框架和对查询的分析改变了关注点，从仅仅修复歧义转向在查询解决过程中更加重视合作，从而使未来设计和评估自然语言接口的工作更具洞察力并导向更加成熟的方向。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04583", "html_url": "https://arxiv.org/abs/2511.04583", "title": "Jr. AI Scientist和其风险报告：基于基础论文的自主科学探索", "title_en": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper", "authors": "Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa", "background": "理解当前AI科学家系统的功能和风险对于确保AI驱动科学进步的可信性和可持续性，同时保护学术生态系统的完整性至关重要。现有的AI科学家系统往往要么追求全自动化，要么局限于小型代码操作，这限制了其在复杂多文件实现中的应用，影响了科学贡献的价值。", "innovation": "我们开发了Jr. AI科学家，这是一种先进的自主AI科学家系统，它模仿了初学者研究者的核心研究流程：在给定人类导师的基础论文后，它分析论文的局限性，提出改进的假设，通过严格的实验验证，并撰写包含结果的论文。Jr. AI科学家遵循了定义明确的研究流程，并利用现代编码代理处理复杂的多文件实现，从而产生有科学价值的成果。", "conclusion": "通过自动化评估、作者主导的评估和提交给专为AI驱动科学贡献设立的Agents4Science，我们发现Jr. AI科学家生成的论文获得了比现有完全自动化系统更高的评分。然而，作者评价和Agents4Science的评审结果也指出了当前AI科学家系统的重要局限和潜在风险，这为未来的研究设定了关键挑战。同时，我们全面报告了开发过程中发现的各种风险，希望这些见解能加深对AI科学家开发当前进展和风险的理解。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.17737", "html_url": "https://arxiv.org/abs/2406.17737", "title": "大型语言模型面向脆弱用户的表现差异性不良影响", "title_en": "LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users", "authors": "Elinor Poole-Dayan,Deb Roy,Jad Kabbara", "background": "虽然最先进的大型语言模型（LLMs）在许多任务上表现出色，但关于模型的不良行为，如幻觉和偏差的研究也非常广泛。这项研究探讨了不同用户特质（英语 proficiency、教育水平和原籍国）对LLM响应质量（信息准确性、真实性及拒绝回答问题的情况）的影响。", "innovation": "本研究通过在三个最先进的LLM上进行大量实验，并使用两个专门针对真实性和事实性的数据集，分析了用户特质对LLM不良行为的影响。研究发现，具有较低英语 proficiency、较低教育水平和来自美国以外国家的用户更容易遭受不利影响，这些模型对最脆弱的用户来说不太可靠。", "conclusion": "最新的LLM在处理具有较低英语 proficiency、较低教育水平和来自美国以外国家的用户时产生的不良行为更多，这些模型对这些用户的可靠性较差，表明这些模型在面对最脆弱用户时表现差异性不足。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2402.18397", "html_url": "https://arxiv.org/abs/2402.18397", "title": "分解提示：探索大型语言模型中的多语言语言结构知识", "title_en": "Decomposed Prompting: Probing Multilingual Linguistic Structure Knowledge in Large Language Models", "authors": "Ercong Nie,Shuzhou Yuan,Bolei Ma,Helmut Schmid,Michael Färber,Frauke Kreuter,Hinrich Schütze", "background": "语言模型（LLMs）在序列标注等任务中的语言结构知识通常通过传统的序列标注提示策略来实现，但这种方法在保持输出模板时面临挑战。现有的提示方法往往无法有效维护多语言文本中的语言结构知识，尤其是在零样本和少样本设置下效果欠佳。论文通过引入分解提示方法，对序列标注任务进行了细化，每个输入句子的词汇生成个体化提示，以求获取其语言标签，从而解决这一问题。", "innovation": "提出了一种分解提示方法，用于序列标注任务，并展示了这种方法在多语言环境下的优势。该方法通过为每个输入词汇生成个体化提示，来实现更好的语言结构知识表达，尤其是在零样本和少样本场景下，相较于迭代提示方法，分解提示方法在效果和效率上表现更优。", "conclusion": "该研究发现，分解提示方法在多语言环境下的表现优于传统的迭代提示方法，尤其是在零样本和少样本的情景下。此外，对于以英语为中心的LLMs的多语言性能分析揭示了语言知识跨语言转移的洞察。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04662", "html_url": "https://arxiv.org/abs/2511.04662", "title": "VeriCoT：通过逻辑一致性检查实现神经符号链式思维验证", "title_en": "VeriCoT: Neuro-symbolic Chain-of-Thought Validation via Logical Consistency Checks", "authors": "Yu Feng,Nathaniel Weir,Kaj Bostrom,Sam Bayless,Darion Cassel,Sapana Chaudhary,Benjamin Kiesl-Reiter,Huzefa Rangwala", "background": "大规模语言模型（LLMs）可以通过链式思维（CoT）进行多步推理，但它们无法可靠地验证自己的逻辑。即使它们得到了正确的答案，背后的推理也可能存在缺陷，这在高风险场景中会削弱信任。", "innovation": "本文引入了一种神经符号方法VeriCoT，用于从链式思维推理中提取和验证正式的逻辑论证。VeriCoT将每一步链式思维推理形式化为一阶逻辑，并识别支持论证的前提，这些前提可以源自原始上下文、常识知识或先前推理步骤。符号表示使自动化求解器能够验证逻辑有效性，而自然语言前提则允许人类和系统识别未验证或谬误的推理步骤。实验表明VeriCoT有效识别了推理中的错误，并作为最终答案正确性的强大预测器。此外，VeriCoT的验证信号还被用于推理时的自我反思、基于VeriCoT提炼数据集的监督微调以及使用基于验证的成对奖励进行直接偏好优化的偏好微调，进一步提高了推理的有效性和准确性。", "conclusion": "VeriCoT通过自我反思、监督微调和偏好微调等方式，有效地验证了推理的逻辑一致性，提高了其实现最终答案正确性的能力和可靠性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.04646", "html_url": "https://arxiv.org/abs/2511.04646", "title": "DR. WELL: 动态推理和具有符号世界模型的自适应多智能体协作", "title_en": "DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration", "authors": "Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong", "background": "协作多智能体规划需要智能体在部分信息和有限通信的情况下进行联合决策。轨迹级别的协调常常失败，因为时间或运动中的小偏差会引发冲突。符号规划通过提高抽象层次和提供最小的动作词汇表来解决这一挑战，使同步和集体进步成为可能。", "innovation": "本文提出了一个去中心化的神经语义框架DR. WELL，用于协作多智能体规划；合作通过两阶段谈判协议展开：智能体首先提出候选角色及其推理，然后在共识和环境约束下进行承诺；承诺后，每个智能体独立生成和执行其角色的符号计划，而无需透露详细的轨迹信息；符号计划的执行通过共享的世界模型进行接地，该模型编码当前状态并随着智能体的行为进行更新；DR. WELL 通过符号计划的推理避免了细粒度步进对齐的脆弱性，并且能够执行可重用、可同步和可解释的高级操作。动态世界模型通过谈判和自我完善提高了任务完成率和效率，使其在协作策略上实现演化和更高效的协作。", "conclusion": "实验结果表明，DR. WELL 在协作移动物块任务中表现出色，能够跨多个训练间隔自适应调整，动态世界模型捕获了可重用的模式，提高了任务完成率和效率，通过谈判和自我完善在一定的时间开销下实现了更高效的协作策略。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.07055", "html_url": "https://arxiv.org/abs/2409.07055", "title": "法律事实预测：法律判决预测的关键环节", "title_en": "Legal Fact Prediction: The Missing Piece in Legal Judgment Prediction", "authors": "Junkai Liu,Yujie Tong,Hui Huang,Bowen Zheng,Yiran Hu,Peicheng Wu,Chuan Xiao,Makoto Onizuka,Muyun Yang,Shuyuan Zheng", "background": "法律判决预测（LJP）允许当事人及其律师预测判决结果并调整诉讼策略，已成为一项重要的法律自然语言处理任务。现有研究通常使用法律事实，即通过证据确立并通过法官确定的事实来预测判决。然而，法律事实往往在诉讼初期难以获得，严重限制了基于事实的LJP的实际应用范围。针对这一局限性，本文提出了一项新的法律自然语言处理任务——法律事实预测（LFP），通过将当事人提交用于诉讼的证据作为输入来预测法律事实，从而使基于事实的LJP技术即使在没有真实法律事实的情况下也能进行预测。本文还提出了首个用于评估LFP任务基准数据集LFPBench。大量在LFPBench上的实验表明，LFP支持下的LJP的有效性，并指出了LFP领域的有前途的研究方向。", "innovation": "本文的主要创新在于提出了一个新的法律自然语言处理任务——法律事实预测（LFP），并首次构建了用于评估LFP任务的基准数据集LFPBench。这一创新填补了现有法律判决预测技术在早期诉讼阶段数据匮乏的缺口，使LJP技术在缺乏真实法律事实的情况下也能进行有效预测。", "conclusion": "本文的实验证明了LFP技术的有效性，并标识了LFP领域中有前途的研究方向，为法律判决预测研究提供了新的视角和方法。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.09956", "html_url": "https://arxiv.org/abs/2502.09956", "title": "KGGen：使用语言模型从纯文本中提取知识图谱", "title_en": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models", "authors": "Belinda Mo,Kyssen Yu,Joshua Kazdan,Joan Cabezas,Proud Mpala,Lisa Yu,Chris Cundy,Charilaos Kanatsoulis,Sanmi Koyejo", "background": "近年来，关于构建知识图谱（KG）的基础模型引起了广泛关注。然而，知识图谱数据相对稀缺，最好的知识图谱主要由人类标注、模式匹配或早期NLP技术提取。人类生成的知识图谱稀缺，而自动提取的知识图谱质量参差不齐。", "innovation": "本文提出了一种文本到知识图谱生成器（KGGen），这是一种使用语言模型创建高质量图的方法。与现有的知识图谱提取器不同，KGGen能够通过聚类相关实体来减少提取知识图谱中的稀疏性。此外，作者还发布了首个基准测试工具MINE，用于衡量提取器从纯文本生成有用知识图谱的能力。实验表明，与现有工具相比，KGGen表现出更优异的性能。", "conclusion": "本文介绍了KGGen及其MINE基准测试工具，展示了新的工具在处理知识图谱稀缺问题上的优势。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.15188", "html_url": "https://arxiv.org/abs/2501.15188", "title": "在句法依赖结构中，谁是根节点？", "title_en": "Who is the root in a syntactic dependency structure?", "authors": "Ramon Ferrer-i-Cancho,Marta Arias", "background": "句子的句法结构可以用一棵树来描述，这棵树表明了词之间的句法关系。尽管在无监督方法中已经有了显著的进步，以检索句子的句法结构，但猜测树中边的正确方向仍然是一项挑战。由于句法依赖结构中的边是从根指向其他节点的，因此猜测正确方向的问题可以简化为找到一个无向树及其根节点。当前无监督方法的性能有限，展示了从第一原理理解根节点的不足。", "innovation": "该研究提出了一种新的多中心性得分方法，其中一些方法考虑了无树部分（无空间得分），而其他一些方法考虑了节点的位置（空间得分）。通过验证假设，认为根节点是句法依赖结构中的重要或中心节点。实验结果表明，那些不仅考虑节点位置还考虑其邻居位置的新得分方法在猜测根节点时表现最佳。", "conclusion": "研究提供了网络科学视角下的关于‘根性’的理论和实证基础，证明了高中心性的节点更可能成为根节点，同时也表明了根据节点及其邻居的位置来定义‘根性’的新得分方法在猜测根节点时效果最好。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.04514", "html_url": "https://arxiv.org/abs/2410.04514", "title": "DAMRO: 潜入LVLM的注意力机制以减少对象幻觉", "title_en": "DAMRO: Dive into the Attention Mechanism of LVLM to Reduce Object Hallucination", "authors": "Xuan Gong,Tianshi Ming,Xinpeng Wang,Zhihua Wei", "background": "尽管大型视觉-语言模型（LVLMs）取得了巨大成功，但它们不可避免地存在幻觉问题。LVLMs中的视觉编码器和大型语言模型（LLM）解码器都是基于Transformer的，能够通过注意机制提取视觉信息并生成文本输出。我们发现，LLM解码器在处理图像标记时的注意分布与视觉编码器高度一致，两者都倾向于关注图像背景中的特定标记而不是所指的对象。我们归因于这种意想不到的注意分布是视觉编码器本身的固有问题，它误导LLMs过度重视冗余信息并生成对象幻觉。", "innovation": "我们提出了一种名为DAMRO的新颖无训练策略，该策略通过潜入LVLM的注意力机制来减少对象幻觉。具体而言，我们的方法使用ViT的分类标记（CLS）来过滤掉在背景中分布的高注意力异常标记，然后在解码阶段消除这些异常标记的影响。我们通过不同基准测试（如POPE、CHAIR、MME和GPT-4V辅助评估）评估了我们的方法在包括LLaVA-1.5、LLaVA-NeXT和InstructBLIP的LVLMs上的效果。", "conclusion": "实验结果表明，我们的方法显著减少了这些异常标记的影响，从而有效地减轻了LVLMs的幻觉问题。我们的代码已发布于此网址：this https URL.。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.07879", "html_url": "https://arxiv.org/abs/2503.07879", "title": "数据集、文档与重复：不等数据质量的实际意义", "title_en": "Datasets, Documents, and Repetitions: The Practicalities of Unequal Data Quality", "authors": "Alex Fang,Hadi Pouransari,Matt Jordan,Alexander Toshev,Vaishaal Shankar,Ludwig Schmidt,Tom Gunter", "background": "数据过滤已成为提高模型性能并降低计算成本的强大工具。然而，随着大型语言模型计算预算的不断增加，由高度过滤和去重的数据集提供的有限数据量将成为实际约束。本文研究了在不同计算预算和多种通过数据过滤和去重创建的预训练数据集上模型的表现。", "innovation": "研究发现，在适当修改训练食谱的情况下，对于多个数量级的计算预算，重复现有高度过滤的数据集多达十个轮次可以优于对大十倍的数据集进行单次训练。此外，还探讨了在数据集内部文档层面进行重复，发现并非数据集内的所有文档价值均等，通过显式调整单个文档的数量可以创造更优的数据集。", "conclusion": "即使大型语言模型的规模继续增长，数据过滤仍然是一个重要研究方向。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.20785", "html_url": "https://arxiv.org/abs/2502.20785", "title": "GraphCheck：使用实体关系图的多路径事实核查", "title_en": "GraphCheck: Multipath Fact-Checking with Entity-Relationship Graphs", "authors": "Hyewon Jeon,Jay-Yoon Lee", "background": "自动化事实核查旨在基于相关证据评估文本声明的真实性，但是在需要多跳推理的复杂声明验证中仍然面临着巨大挑战。", "innovation": "提出了一种名为GraphCheck的新框架，将声明转换为实体-关系图，以实现结构化和系统化的事实核查。通过明确建模显式和潜在实体并探索多条推理路径，GraphCheck提高了验证的稳健性。为了应对GraphCheck在简单声明中可能过于复杂的问题，引入了DP-GraphCheck变体，它采用轻量级策略选择器，在适配GraphCheck的同时也允许直接提示。这种选择机制通过适当地为每个声明选用适当的推理程度，提高了准确性和效率。", "conclusion": "实验表明，我们的方法在验证准确性上优于现有方法，同时由于其多路径探索机制，仍然保持了良好的计算效率。此外，DP-GraphCheck中的策略选择机制对其他事实核查管道具有很好的泛化性，突显了我们框架的广泛应用前景。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15835", "html_url": "https://arxiv.org/abs/2502.15835", "title": "Pragmatic Reasoning improves LLM Code Generation", "title_en": "Pragmatic Reasoning improves LLM Code Generation", "authors": "Zhuchen Cao,Sven Apel,Adish Singla,Vera Demberg", "background": "大型语言模型（LLMs）已经在将自然语言（NL）指令转换为程序代码方面展示了显著的能力，但用户指令中往往隐含着一定的歧义，这使得LLMs很难生成准确反映用户真实意图的代码。为了解决这一挑战，研究人员提出了生成多个程序代码候选方案并重新排序以找出最佳解决方案的方法。现有方法的有效性仍然有限，因此研究者们需要进一步探索新的方法以提高代码生成的质量和准确度。", "innovation": "本文提出了一种名为CodeRSA的新颖代码候选重新排序机制，该机制基于理性言谈（RSA）框架，旨在指导LLMs进行更全面的关于用户意图的实用推理。通过在大规模流行的代码生成基准HumanEval和MBPP上对Llama-3-8B-Instruct和Qwen-2.5-7B-Instruct进行评估，结果表明，CodeRSA方法在多个指标上持续优于普通基线，并在大多数情况下超过了最先进的方法，展示了整体稳健的表现。", "conclusion": "这些结果突显了将实用推理集成到代码候选重新排序中的有效性，为提高LLMs代码生成质量提供了有希望的方向。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.04847", "html_url": "https://arxiv.org/abs/2505.04847", "title": "基于演变排行榜评估大型语言模型在RAG中的可信度", "title_en": "Benchmarking LLM Faithfulness in RAG with Evolving Leaderboards", "authors": "Manveer Singh Tamber,Forrest Sheng Bao,Chenyu Xu,Ge Luo,Suleman Kazi,Minseok Bae,Miaoran Li,Ofer Mendelevitch,Renyi Qu,Jimmy Lin", "background": "检索增强生成（RAG）旨在通过将响应与外部上下文联系起来减少幻觉，然而，即使是大语言模型（LLMs）在提供相关上下文的情况下，仍然经常引入未支持的信息或矛盾。已有的一些幻觉检测方法存在一定的局限，为此， Vectara提出了两个互补的举措来衡量和基准测试LLMs在RAG中的可信度。", "innovation": "该研究引入了FaithJudge，这是一个LLM作为评判者的框架，利用多样化的人标注的幻觉示例池大幅改善了大语言模型的自动幻觉评估。文章围绕FaithJudge引入了一个增强的幻觉排行榜，用于评估LLMs在RAG中的生成忠实度，涵盖总结、问答和数据到文本生成任务，以提供更可靠的大语言模型幻觉基准和促进更可信的生成AI系统的开发。", "conclusion": "FaithJudge使得大语言模型在RAG中的幻觉评估更为可靠，为开发更信赖的生成AI系统提供了支持：this https URL."}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12474", "html_url": "https://arxiv.org/abs/2505.12474", "title": "基于知识的对话总结：他们在谈论什么？", "title_en": "What Are They Talking About? A Benchmark of Knowledge-Grounded Discussion Summarization", "authors": "Weixiao Zhou,Junnan Zhu,Gengyao Li,Xianfu Cheng,Xinnian Liang,Feifei Zhai,Zhoujun Li", "background": "传统对话总结主要关注对话内容，认为这些内容已包含了足够的信息供清晰的摘要。但在基于共享背景的讨论中，参与者常常省略背景信息并使用隐含引用，导致生成的摘要对不熟悉背景的读者来说难以理解。", "innovation": "本文提出了一个新的任务——知识导向的讨论总结（KGDS），旨在为讨论补充背景摘要，并为观点的澄清提供清晰的总结。为了促进研究，作者还构建了首个KGDS基准，包括新闻-讨论对和多粒度专家注解。此外，还提出了一个新的层次化评估框架，以细粒度和可解释的指标评估子摘要的表现。研究发现，尽管12款先进的大语言模型在KGDS任务上依然表现不佳，需要解决重要的信息遗漏和保留无关信息等问题，并且难以解决观点整合中的隐含引用问题。", "conclusion": "KGDS仍然是一个重大挑战。现有的大型语言模型在背景总结中经常遗漏关键事实，保留无关信息，并在观点摘要中经常无法解决隐含引用。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.04737", "html_url": "https://arxiv.org/abs/2504.04737", "title": "TathyaNyaya和FactLegalLlama：在印度法律背景下推动事实判断预测与解释", "title_en": "TathyaNyaya and FactLegalLlama: Advancing Factual Judgment Prediction and Explanation in the Indian Legal Context", "authors": "Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya", "background": "在基于事实判断预测和解释（FJPE）的领域中，使用可靠的数据对于开发稳健和现实的AI驱动决策工具至关重要。现有文献中缺乏针对印度法律环境的标注数据集，使得评估AI辅助法律系统的性能具有挑战性。因此，迫切需要构建专门针对印度法律环境的数据集和模型，为这些系统提供可靠的基础支持，提高解释的透明度和可解释性。", "innovation": "论文提出了TathyaNyaya，这是首款专门针对印度法律环境的标注数据集，涵盖印度最高法院及各高等法院的判决。TathyaNyaya以Hindi词汇'Tathya'（事实）和'Nyaya'（正义）命名，专注于事实陈述而非完整的法律文本，真实地反映了印度实际司法过程中事实数据对结果的影响。此外，该论文还提出了FactLegalLlama模型，这是一个针对FJPE任务优化的指令调优变体，其能够在生成高质量解释的同时保持预测的准确性。TathyaNyaya和FactLegalLlama在规模和多样性上超越了现有数据集，并为法律分析中构建解释性AI系统提供了基准。", "conclusion": "实证结果强调了事实精度和领域特定调整在提高预测性能和可解释性中的重要性，将TathyaNyaya和FactLegalLlama定位为支持AI辅助法律决策的基础资源。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17793", "html_url": "https://arxiv.org/abs/2505.17793", "title": "压缩作弊：从几何失真补充视角探究语言模型的信息学属性", "title_en": "Compression Hacking: A Supplementary Perspective on Informatics Properties of Language Models from Geometric Distortion", "authors": "Jianxiang Zang,Meiling Ning,Yongda Wei,Shihan Dou,Jiazheng Zhang,Nijia Mo,Binhong Li,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "近年来，“压缩即智能”的概念为语言模型（LMs）提供了一个新的信息量化度量视角，强调了高度结构化表示是LMs智能水平的标志。然而，从几何角度来看，高度压缩的LMs的词表示空间倾向于退化为高度非各向同性状态，这阻碍了LMs理解指令的能力，直接影响其性能。", "innovation": "本文通过引入几何失真分析，提出了三个改进的压缩度量标准，并将其集成到自评估管道中。改进后的度量标准与LM的综合能力表现出强烈的对齐，Spearman相关系数超过0.9，显著优于原始压缩度量和其他基于内部结构的度量。这表明，压缩作弊可通过引入表示几何畸变极大地增强对LMs的信息学解释。", "conclusion": "研究表明，压缩作弊通过利用几何畸变显著提高了对语言模型LMs的信息学解释，改进后的度量指标与LM的能力有高度的正相关性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18658", "html_url": "https://arxiv.org/abs/2505.18658", "title": "大型语言模型中的鲁棒性：缓解策略与评估指标综述", "title_en": "Robustness in Large Language Models: A Survey of Mitigation Strategies and Evaluation Metrics", "authors": "Pankaj Kumar,Subhankar Mishra", "background": "大型语言模型（LLMs）已成为自然语言处理（NLP）和人工智能（AI）领域发展的有前途的基础。然而，确保LLMs的鲁棒性仍然是一个重要挑战。本文综述了当前该领域的研究，系统地探讨了LLMs的鲁棒性本质、一致性能在不同输入中的重要性以及实际应用中的失败模式的影响。然后分析了非鲁棒性的来源，分类了内在模型限制、数据驱动的脆弱性和外部对抗因素。此外，还回顾了最新的缓解策略，并讨论了广泛采用的基准、新兴的评估指标以及在评估实际可靠性时存在的持续差距。最后，综合已有综述和跨学科研究的发现，突出趋势、未解决的问题及未来研究的途径。", "innovation": "本文提供了一个全面的综述，涵盖当前LLMs鲁棒性相关研究的关键方面。分析了鲁棒性的性质、非鲁棒性的来源，并回顾了最新的缓解策略。此外，还讨论了评估实际可靠性的广泛采用的基准和新兴的评估指标，填补了现有研究的空白，并提出了未来研究的方向。", "conclusion": "本文总结了当前LLMs鲁棒性研究的趋势和未解决的问题，为未来研究路径提供了指导。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.20110", "html_url": "https://arxiv.org/abs/2503.20110", "title": "通过微调转移实现高效模型开发", "title_en": "Efficient Model Development through Fine-tuning Transfer", "authors": "Pin-Jie Lin,Rishab Balasubramanian,Fengyuan Liu,Nikhil Kandpal,Tu Vu", "background": "现代大规模语言模型在进行高效更新时面临挑战，每次新预训练模型版本都需要重新进行耗资的对齐过程。这一挑战不仅适用于特定领域的或语言特定的模型，这些模型每次需要在新基础模型版本发布时重新进行微调。本文研究了模型版本之间微调更新的转移。我们从一个源模型版本中提取微调更新的diff向量，并将其应用到不同目标版本的基础模型上。通过在各种开源模型版本上的实证评估，我们展示了转移diff向量可以显著提高目标基础模型的性能。例如，将LLama 3.0 8B的微调更新应用于LLama 3.1 8B，未进行额外训练的情况下，IFEval 提升了46.9%，LiveCodeBench 提升了15.7%，甚至超过了LLama 3.1 8B指令模型。此外，我们在多语言任务上也取得了成效，分别提高了4.7%和15.5%的Global MMLU效果，针对马达加斯加语和土耳其语。我们发现这些合并后的模型为后续微调提供了更强的初始条件。总的来说，微调转移为连续的大规模语言模型开发提供了一种成本效益高且实际有效的策略。", "innovation": "本文探索了模型版本之间微调更新的转移。通过从一个源模型版本中提取微调更新的diff向量，并将其应用到不同目标版本的基础模型，本文展示了这种方法可以显著提高目标基础模型的性能。特别地，这种方法能够在无需额外训练的情况下实现性能的显著提升。我们还观察到合并后的模型在进一步微调时提供更强的初始条件，并提出了微调转移方法的理论分析。实验表明，当源模型和目标模型参数空间中呈线性连接时，微调转移效果最佳。", "conclusion": "微调转移为连续的大规模语言模型开发提供了一种成本效益高且实际有效的策略，通过避免重复的对齐过程来提高新模型版本的性能。我们的代码已发布，可进一步研究此方法的具体应用。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.24630", "html_url": "https://arxiv.org/abs/2505.24630", "title": "大型推理模型更易产生幻觉：面向事实的强化学习", "title_en": "Reasoning Models Hallucinate More: Factuality-Aware Reinforcement Learning for Large Reasoning Models", "authors": "Junyi Li,Hwee Tou Ng", "background": "大型语言模型（LLMs）通过强化学习（RL）优化取得了显著的进步，在各种棘手的基准测试中展示了卓越的能力。然而，实证分析发现，旨在增强推理能力的RL微调会导致幻觉现象的显著增加。", "innovation": "提出了一种名为事实感知步骤策略优化（FSPO）的创新性RL微调算法，该算法在每个推理步骤中引入显式的事实验证，利用自动化验证与给定证据的一致性来动态调整标记级别的优势值，以激励推理过程中的一致性和正确性。", "conclusion": "通过数学推理和幻觉基准测试，FSPO有效地减少了幻觉现象，增强了推理准确性，大幅提高了可靠性和性能。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16956", "html_url": "https://arxiv.org/abs/2505.16956", "title": "多语言编码器语言模型在低资源语言中的压缩研究", "title_en": "On Multilingual Encoder Language Model Compression for Low-Resource Languages", "authors": "Daniil Gurgurov,Michal Gregor,Josef van Genabith,Simon Ostermann", "background": "本文旨在针对低资源语言，结合两种知识蒸馏、结构化剪枝、截断和词汇量修剪技术，极端压缩多语言的编码器仅语言模型。现有技术通常会减少模型的层数、前向隐藏大小和中间层嵌入大小，从而创建更小的语言模型，同时保留语言特定的知识。研究者们在四种下游任务（情感分析、主题分类、命名实体识别和词性标注）中对三种低资源语言进行了测试，结果显示即使在最大压缩率下，平均性能下降也在8-13%之间，而适度压缩时性能下降仅为2-10%。此外，性能下降与教师模型中语言特定数据量有关，样本量越大，性能损失越小。", "innovation": "本文提出了一种新颖的方法，即系统性地结合现有的技术并将其推向极致，通过深度神经网络的极端压缩，同时确保在下游任务中保持竞争力。具体创新包括：（1）通过两阶段的知识蒸馏技术进行模型压缩；（2）应用结构化剪枝和截断技术减少模型规模；（3）进行词汇量修剪以进一步减小程序复杂性。研究证明，这种方法可在保持性能的同时极大地减少模型大小，特别是在低资源语言保护领域表现出色。", "conclusion": "实验结果表明，本文提出的方法能够在压缩低资源多语言编码器模型的同时，使模型大小减少高达92%。尽管在压缩更极端的情况下会带来一定的性能损失，但在绝大多数情况下，平均性能下降保持在合理范围内。此外，研究还发现，性能损失与教师模型中的语言特定数据量成负相关关系。这一方法被认为对于低资源语言的模型压缩具有重要意义。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13487", "html_url": "https://arxiv.org/abs/2506.13487", "title": "TurBLiMP: 一种土耳其语语言最小对之间的基准测试", "title_en": "TurBLiMP: A Turkish Benchmark of Linguistic Minimal Pairs", "authors": "Ezgi Başar,Francesca Padovani,Jaap Jumelet,Arianna Bisazza", "background": "在语言模型（LM）的语义评估资源中，缺少针对土耳其语的评估工具。现有的语义评估工具未能充分关注土耳其语言特有的句法特征，如单词顺序的灵活性和通过形态学过程实现的从属关系，因此需要一个新的土耳其语言语能力评估基准测试工具，如TurBLiMP，它涵盖16种语言现象，并包含1000个最小对，旨在评估单语和多语LMs的语言能力。", "innovation": "TurBLiMP是第一个土耳其语语言最小对基准，特别关注土耳其语中当前研究较少的两个方面：单词顺序的灵活性和通过形态学过程实现的从属关系。TurBLiMP填补了土耳其语语言能力评估资源的重要空白，并为评估LMs的语言能力提供了一个广泛适用的基准。", "conclusion": "实验结果表明，即使是最先进的大型LMs，在处理对人类简单的语法现象时仍然存在困难，并且它们对单词顺序和形态复杂性的敏感性可能与人类不同。TurBLiMP为研究LMs的语言能力提供了新的视角和数据支持。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.05410", "html_url": "https://arxiv.org/abs/2506.05410", "title": "Homogeneous Keys, Heterogeneous Values: Exploiting Local KV Cache Asymmetry for Long-Context LLMs", "title_en": "Homogeneous Keys, Heterogeneous Values: Exploiting Local KV Cache Asymmetry for Long-Context LLMs", "authors": "Wanyun Cui,Mingwei Xu", "background": "近年来，大型语言模型（LLMs）的发展突显了扩展上下文长度的重要性，但注意力机制的平方复杂性对长上下文建模提出了显著的效率挑战。KV缓存压缩已成为解决这一问题的关键方法。研究者通过广泛的经验分析揭示了KV缓存中的一个先前未被重视的基本不对称性：相邻的键在关注权重上相似（局部同质性），而相邻的值表现出不同的分布（异质性）。现有的压缩方法均等地对待键和值，因此未充分利用这种不对称性，从而存在关键限制。研究团队开发了一种无需训练的压缩框架AsymKV，结合了基于同质性的键合并和数学上证明的无损值压缩，以克服现有方法的限制。", "innovation": "提出了一种无需训练的压缩框架AsymKV，该框架结合了基于同质性的键合并和数学上证明的无损值压缩。通过这种方式，AsymKV能够更有效地压缩KV缓存，从而提高长期上下文所述任务中的模型性能。实验结果表明，AsymKV在多个任务和基础模型上均优于现有的长期上下文方法。例如，在LLaMA3.1-8B上，AsymKV在LongBench上的平均得分为43.95，超过了SOTA方法如H$_2$O（38.89）", "conclusion": "广泛的实验表明，AsymKV在各种任务和基础模型上都优于现有的长期上下文方法。这一方法通过有效利用KV缓存中的局部不对称性，提高了大型语言模型的长上下文建模效率。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08336", "html_url": "https://arxiv.org/abs/2507.08336", "title": "蒸馏与对比学习：如何训练你的排版模型", "title_en": "Distillation versus Contrastive Learning: How to Train Your Rerankers", "authors": "Zhichao Xu,Zhiqi Huang,Shengyao Zhuang,Vivek Srikumar", "background": "文本重排序在信息检索中至关重要，已广泛使用对比学习（直接优化真实标签）和知识蒸馏（从更大规模的重排序模型转移知识）两种策略。尽管这两种方法已被大量研究，但在实际条件下的对比效果对比仍不够清晰。", "innovation": "本文通过使用相同数据集对不同规模（0.5B, 1.5B, 3B, 7B）和架构（Transformer, Recurrent）的重排序模型，以强对比学习模型作为蒸馏教师，对比了这两种策略。结果显示，在更大的教师模型下进行知识蒸馏，通常在领域内和领域外的排序任务中表现优于对比学习。这些发现跨越了学生模型的不同规模和架构保持一致。然而，同样规模的教师模型进行蒸馏并不提供相同的优势，特别是在领域外任务中。", "conclusion": "我们的研究给出了基于可用教师模型选择训练策略的实际指导。建议若存在更大规模且表现更优的教师模型时使用知识蒸馏训练较小模型；否则，对比学习仍然是稳健的基础方法。我们提供了代码实现以促进可重复性研究。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14578", "html_url": "https://arxiv.org/abs/2507.14578", "title": "XL-DURel: 使用 Sentence Transformers 对ordinar Word-in-Context 进行微调的排序分类", "title_en": "XL-DURel: Finetuning Sentence Transformers for Ordinal Word-in-Context Classification", "authors": "Sachin Yadav,Dominik Schlechtweg", "background": "本文提出了一个针对短语上下文分类中的排序问题优化的微调多语言句子转换模型XL-DURel。该模型在回归和排序任务中进行了测试，尤其是在复杂空间中基于角度距离的排序目标，表现出对先前模型的超越性能。另外，研究显示将二元短语上下文（WiC）视为排序WiC的一个特例，并且针对一般排序任务优化模型可以提高特定二元任务的性能。这为不同任务表述下的短语上下文建模提供了一致的方法。", "innovation": "本文的创新点在于提出了一种针对排序任务优化的多语言句子转换模型XL-DURel。该模型在角度距离排序目标下取得了超越之前模型的表现，并且证明了针对排序任务优化模型可以提升二元任务的表现。此外，二元WiC可以被视为一种特殊的排序WiC问题，这为统一处理不同任务表述下的短语上下文建模奠定了基础。", "conclusion": "本文提出的XL-DURel模型为短语上下文建模提供了新的方法，尤其是在排序任务中的表现更优。研究结果表明，优化模型针对一般排序任务时也可以提高二元任务的性能，并且为不同任务表述下的统一处理方法提供了可能的路径。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21591", "html_url": "https://arxiv.org/abs/2506.21591", "title": "FinEval-KR: 一种大型语言模型金融领域知识与推理评估框架", "title_en": "FinEval-KR: A Financial Domain Evaluation Framework for Large Language Models' Knowledge and Reasoning", "authors": "Shaoyu Dou,Yutian Shen,Mofan Chen,Zixuan Wang,Jiajie Xu,Qi Guo,Kailai Shao,Chao Chen,Haixiang Hu,Haibo Shi,Min Min,Liwen Zhang", "background": "大型语言模型（LLMs）在复杂的金融推理任务中显示出巨大潜力，但因其需要融合领域知识和高级推理能力，因此在评估时面临挑战。现有的评估基准通常无法区分这些能力指标与单一任务性能，并且缺乏任务失败的根本原因分析。该文旨在解决上述问题，提出了一种全新的评估框架FinEval-KR，用于独立地分离和量化LLMs的知识和推理能力，并提出了不同的知识评分和推理评分指标。此外，该研究提出了基于布鲁姆分类法的认知评分，以在不同认知层次上分析推理任务的能力。同时，还发布了一个涵盖22个子领域的开源中文金融推理数据集，以支持可重复研究并促进金融推理的进一步发展。实验结果显示，LLMs的推理能力和高级认知能力是影响推理准确性的核心因素，尽管顶级模型仍存在知识应用的瓶颈。进一步分析发现，专业化的金融LLMs在多个指标上普遍落后于顶级通用大型模型。", "innovation": "提出了FinEval-KR评估框架，旨在独立地量化和分离LLMs的知识和推理能力，同时引入了基于布鲁姆分类法的认知评分方法；发布了涵盖22个子领域的开源中文金融推理数据集，以支持进一步研究。", "conclusion": "该研究揭示了LLMs的推理能力和高级认知能力是影响推理准确性的关键因素，同时即使是顶级模型在知识应用方面仍存在瓶颈。专业化的金融LLMs在多个指标上普遍落后于顶级通用模型。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.23071", "html_url": "https://arxiv.org/abs/2506.23071", "title": "Text2VectorSQL：走向矢量搜索和SQL查询统一界面", "title_en": "Text2VectorSQL: Towards a Unified Interface for Vector Search and SQL Queries", "authors": "Zhengren Wang,Dongwen Yao,Bozhou Li,Dongsheng Ma,Bo Li,Zhiyu Li,Feiyu Xiong,Bin Cui,Linpeng Tang,Wentao Zhang", "background": "无结构数据的激增对传统的数据库接口构成了基础性的挑战。尽管文本到SQL（Text-to-SQL）技术已使访问结构化数据更加民主化，但它无法解读语义或多模态查询。同时，矢量搜索已成为处理无结构数据查询的事实标准，但其与SQL术语的结合VectorSQL仍依赖手动查询构建，并缺乏标准化的评估方法，这在其实用应用上造成了显著的差距。", "innovation": "为解决这一基础性的差距，作者引入并正式化了一个新的任务——Text2VectorSQL，旨在建立一个统一的自然语言界面，能够无缝地查询结构化和非结构化数据。为此，作者提供了一个全面的基础生态系统，包括：1. 一个可扩展和稳固的管道，以合成高质量的Text-to-VectorSQL训练数据。2. VectorSQLBench，这是第一个大规模、多方面的基准测试，涵盖了三种数据库后端（SQLite，PostgreSQL，ClickHouse）和四种数据源（BIRD，Spider，arXiv，Wikipedia）的12种不同组合。3. 多个新颖的评估指标，以进行更详细的性能分析。通过大量实验，证实了我们训练模型的基准性能，并揭示了召回率下降的挑战：SQL过滤器与矢量搜索的结合可能导致比传统过滤矢量搜索更多的结果遗漏。", "conclusion": "通过定义核心任务、提供必要的数据和评估基础设施，并识别关键的研究挑战，我们的工作奠定了构建下一代统一智能数据界面的基础。”我们的仓库可以在这里找到：this https URL。”为该领域的新研究提供了必要的基础和挑战，在此之上，可以进一步推进相关技术和应用的发展。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.20343", "html_url": "https://arxiv.org/abs/2507.20343", "title": "DYNARTmo: 动态构音模型，用于发音运动模式可视化", "title_en": "DYNARTmo: A Dynamic Articulatory Model for Visualization of Speech Movement Patterns", "authors": "Bernd J. Kröger", "background": "该研究基于UK-DYNAMO框架，旨在构建一个能够可视化发音过程的二维矢状面动态发音模型。模型融合了构音欠具体化原则、音素和手势控制以及连音性等原理，并模拟了六个关键构音器官，这些构音器官通过十个连续参数和六个离散参数控制，以生成语音和辅音构音配置。模型嵌入在一个基于网络的应用程序（SpeechArticulationTrainer）中，该程序还提供了矢状面、声门面和腭面的视图，适用于语音学教育和言语治疗。论文侧重于静态建模，未来的工作将涉及动态运动生成以及将发音-声学模块集成起来。该项工作的目的是为发音过程提供更精确和动态的可视化工具，从而促进语音学教育和言语治疗的效果提升。", "innovation": "该模型创新性地结合了多种构音学原理，通过十个连续参数和六个离散参数精确模拟六个关键构音器官，能够生成语音和辅音的构音配置，并嵌入于网络教育平台中，具有较高的实用性和教育价值。", "conclusion": "当前研究构建了一个能够精确可视化发音过程的动态模型，该模型在语音学教育和言语治疗中可为学生和治疗师提供有用的工具。未来工作将致力于使其更加动态化，并与发音-声学模块集成。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.00709", "html_url": "https://arxiv.org/abs/2508.00709", "title": "NyayaRAG: RAG框架下的印度普通法系统真实法律判断预测", "title_en": "NyayaRAG: Realistic Legal Judgment Prediction with RAG under the Indian Common Law System", "authors": "Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Ajay Varghese Thomas,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya", "background": "法律判决预测（LJP）是法律AI领域的一个关键方向，旨在自动化司法结果预测并增强法律推理的可解释性。此前的研究主要依赖内部案件内容，如事实、争议点和推理，但往往忽视了普通法系统中的核心要素，即依赖于法律法规和先例。本文介绍了NyayaRAG框架，这是一种检索增强生成（RAG）方法，通过提供事实案件描述、相关法律条文和语义检索的先例案件，模拟真实的法庭场景。该方法通过一个针对印度法律系统的领域特定管道评估这些输入组合在预测法院判决和生成法律解释方面的效果。研究人员使用标准的词性和语义评价标准以及LLM评价器（如G-Eval）来评估性能。", "innovation": "提出NyayaRAG框架，这是一种检索增强生成（RAG）方法，能够通过提供事实案件描述、相关法律条文和语义检索的先例案例来模拟真实的法庭场景。NyayaRAG使用一个针对印度法律系统的领域特定管道评估输入组合在预测法院判决和生成法律解释方面的效果，通过标准的词性和语义评价标准以及LLM评价器（如G-Eval）来评估性能。这种结合了结构化法律知识的补充，能够显著提高预测准确性和解释质量。", "conclusion": "实验证明，通过NyayaRAG框架，将事实输入与结构性法律知识相结合，能够显著提高预测准确性和解释质量。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.00974", "html_url": "https://arxiv.org/abs/2509.00974", "title": "RPRO: Ranked Preference Reinforcement Optimization for Enhancing Medical QA and Diagnostic Reasoning", "title_en": "RPRO: Ranked Preference Reinforcement Optimization for Enhancing Medical QA and Diagnostic Reasoning", "authors": "Chia-Hsuan Hsu,Jun-En Ding,Hsin-Ling Hsu,Chun-Chieh Liao,Fang-Ming Hung,Feng Liu", "background": "现有的大型语言模型（LLMs）在医疗问答中生成的推理链经常缺乏事实准确性与临床可靠性，这限制了其在医疗场景中的应用。医疗问答需要结合领域知识与逻辑推理的高级推理过程。", "innovation": "RPRO（Ranked Preference Reinforcement Optimization）提出了一种新颖的框架，该框架结合了强化学习和偏好驱动的推理精炼，以提升临床推理链（CoT）的表现。RPRO的独特之处在于使用任务自适应推理模板，并结合概率评估机制以使输出与已确立的临床工作流程对齐，同时自动识别并纠正低质量的推理链。此外，RPRO引入了基于Bradley-Terry模型的团队排名优化，并结合了KL散度正则化以保证稳定训练。相比传统的两两偏好方法，RPRO采用了一种基于Bradley-Terry模型的组别排名优化，并结合了KL散度正则化进行稳定的训练方法。实验表明，RPRO在PubMedQA和MedQA-USMLE数据集上的表现优于基线模型。RPRO的1.1亿参数模型在性能上超越了7亿到13亿参数的更大模型，包括专门针对医学领域的模型。这表明结合偏好优化与质量驱动精炼，可以构建更加可靠和与临床背景紧密结合的医疗LLMs的方法是可行的和有效的。", "conclusion": "研究表明，结合偏好优化与质量驱动精炼能够提供一种可扩展且有效的方法，用于构建更可靠、临床背景更紧密结合的医疗LLMs，而RPRO就是这样一个有效的例子，克服了现有LLMs在医疗场景下的诸多局限性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.08604", "html_url": "https://arxiv.org/abs/2509.08604", "title": "医学中大型语言模型的记忆现象：普遍性、特征及影响", "title_en": "Memorization in Large Language Models in Medicine: Prevalence, Characteristics, and Implications", "authors": "Anran Li,Lingfei Qian,Mengmeng Du,Yu Yin,Yan Hu,Zihao Sun,Yihang Fu,Erica Stutz,Xuguang Ai,Qianqian Xie,Rui Zhu,Jimin Huang,Yifan Yang,Siru Liu,Yih-Chung Tham,Lucila Ohno-Machado,Hyunghoon Cho,Zhiyong Lu,Hua Xu,Qingyu Chen", "background": "大型语言模型（LLMs）已在医学领域展现出巨大的潜力。到目前为止，LLMs 广泛应用于诊断辅助、医学问答和临床信息综合等任务。然而，一个关键的开放性问题是：LLMs 在多大程度上记忆了医学训练数据。本研究首次系统评估了医学领域中 LLMs 的记忆现象，包括其发生频率、所记忆的内容特征、记忆的体量以及潜在的下游影响。", "innovation": "本研究系统分析了常见的适应场景，包括继续在医学语料库上进行预训练、在标准医学基准数据上进行微调以及在真实临床数据上进行微调（包括超过 13,000 条独特住院记录），并发现记忆现象在所有适应场景中普遍存在且显著高于一般领域。此外，研究还对记忆的类型进行了分类，分别为有益的记忆、无信息的记忆和有害的记忆，并据此提出了实用的建议，以促进有益的记忆，减少无信息的记忆，并减轻有害的记忆现象。", "conclusion": "记忆现象在医学领域中 LLMs 的开发和应用中发挥着重要作用，可以分为有益记忆、无信息记忆和有害记忆三类。研究提出，应促进有益记忆，增强领域特定推理和事实准确性；减少无信息记忆，促进更深层次的学习而非表面模式；并减轻有害记忆，防止敏感或可识别患者信息的泄露。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.08217", "html_url": "https://arxiv.org/abs/2509.08217", "title": "平衡质量和多样性：垃圾过滤扭曲数据标签分布", "title_en": "Balancing Quality and Variation: Spam Filtering Distorts Data Label Distributions", "authors": "Eve Fleisig,Matthias Orlikowski,Philipp Cimiano,Dan Klein", "background": "为了使机器学习数据集准确反映人口中多样的意见，必须在过滤掉垃圾或低质量响应的同时保持数据标签的变化性。本文探讨了如何平衡注释员的可靠性和代表性。之前的方法设计是为了减少与单一真实标签不一致的变化，但这些方法往往会错误地清除有分歧的注释员而非垃圾注释员，从而导致准确性和标签多样性之间的非最优权衡。", "innovation": "本文通过实证研究评估了注释员过滤策略对主观任务中标签变化保留的影响。研究发现，现有方法在准确性提高的同时会导致标签多样性的下降，特别是在去除注释员的保守设置 (<5%) 下表现最佳。此外，研究还分析了对合成垃圾数据的表现，揭示了现有垃圾过滤方法对标签多样性假设的缺陷，从而需要新的垃圾过滤方法来更好地考虑标签多样性。", "conclusion": "研究结果强调了在注释数据处理中需考虑标签多样性的必要性，并指出当前的垃圾过滤方法可能不适应需要保留标签多样性的任务。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.17858", "html_url": "https://arxiv.org/abs/2509.17858", "title": "CorPipe在CRAC 2025：评价多语言编码器在多语言一致性解析中的表现", "title_en": "CorPipe at CRAC 2025: Evaluating Multilingual Encoders for Multilingual Coreference Resolution", "authors": "Milan Straka", "background": "该论文展示了CorPipe 25，这是参与CRAC 2025共享任务多语言一致性解析比赛的获胜条目。这是这项共享任务的第四次迭代，引入了新的基于大语言模型的赛道，并移除了部分开发和测试集以减少计算需求。此外，还增加了新的数据集。", "innovation": "CorPipe 25 是对以前系统的完全重新实现，从TensorFlow迁移到了PyTorch。该系统在基于大语言模型的赛道和非约束赛道中均显著优于其他提交物，性能提高了8个百分点。源代码和训练模型已公开。", "conclusion": "CorPipe 25 在CRAC 2025共享任务中表现出色，特别是在基于大语言模型的赛道中获得了显著的性能优势，这表明多语言编码器在多语言一致性解析中的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.12829", "html_url": "https://arxiv.org/abs/2510.12829", "title": "使用大型语言模型作为证明者和验证者的数学证明", "title_en": "Mathematics with large language models as provers and verifiers", "authors": "Hieu Le Duc,Leo Liberti", "background": "自2024年至2025年，关于大型语言模型证明能力的讨论引起了关注，主要是在解决国际数学奥林匹克竞赛中的难题以及其他由研究人员特地提出以测试AI证明能力的猜想。本文介绍了一个使用GPT-5不同实例作为证明者和验证者的ChatGPT证明数学定理的实例。", "innovation": "本文通过不同GPT-5实例的不同证明者和验证者工作协作的方式，解决了五个国际数学奥林匹克竞赛中的六个问题，并解决了大量数论猜想的一部分。同时，以正式验证的方式由Lean证明助手保证不产生幻觉，以及由人为验证前提和结论的一致性。", "conclusion": "虽然本文的方法还不够完善，但其成功证明多个具有挑战性的问题和猜想显示了大语言模型在数学证明领域的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.05132", "html_url": "https://arxiv.org/abs/2510.05132", "title": "使用全局分叉令牌训练大型语言模型实现并行推理", "title_en": "Training Large Language Models To Reason In Parallel With Global Forking Tokens", "authors": "Sheng Jia,Xiao Wang,Shiva Prasad Kasiviswanathan", "background": "尽管通过扩展并行测试时计算量，LLMs已经展示了改进的性能，但在能够生成既多样又准确的推理路径方面仍面临挑战。对于复杂问题，触发多样化且正确的推理模式的分叉令牌通常位于采样树的深处，常规策略如温度缩放会加剧多样性与准确性的权衡。", "innovation": "本文提出将并行推理视为下一个令牌集预测问题，并在监督微调（SFT）中结合基于全局集合的损失函数，以及自监督二分匹配技术，以保留独特的推理模式并生成新的全局分叉令牌。实验证明，所提出的Set Supervised Fine-Tuning（SSFT）方法在多个推理基准下比SFT在Pass@1和Cons@k指标上表现更优。", "conclusion": "本文证明了使用全局分叉令牌的SSFT方法能够更好地平衡多样性和准确性，并在多个推理基准上取得了优于传统SFT的方法。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.17796", "html_url": "https://arxiv.org/abs/2509.17796", "title": "第四版多语言共指消解共享任务：大型语言模型能否取代传统方法？", "title_en": "Findings of the Fourth Shared Task on Multilingual Coreference Resolution: Can LLMs Dethrone Traditional Approaches?", "authors": "Michal Novák,Miloslav Konopík,Anna Nedoluzhko,Martin Popel,Ondřej Pražák,Jakub Sido,Milan Straka,Zdeněk Žabokrtský,Daniel Zeman", "background": "该论文概述了CODI-CRAC 2025研讨会的一部分——第四版的多语言共指消解共享任务。这是一个已经举办了几届的竞赛，主要挑战参与者开发能够识别提及并根据身份共指进行聚类的系统。近年来，大型语言模型（LLMs）的发展成为研究焦点，因此今年的挑战中引入了一个特别针对LLMs设计的数据集格式，并新增了三个使用CorefUD 1.3版本的多语言语料库，共涉及17种语言中的22个数据集。", "innovation": "今年任务的一个关键创新在于增加了大型语言模型专门赛道，该赛道的简化文本格式旨在更好地适应大型语言模型，不同于原始的CoNLL-U表示法。比赛还扩展了数据集覆盖，引入了两种新语言的三个新数据集，使用了CorefUD 1.3版本作为语料库，这是涵盖17种语言的22个数据集的标准化集合。", "conclusion": "共有九个系统参与此次竞赛，其中有四种依赖于大型语言模型的方法（两种进行了微调，两种使用少样本适应）。尽管传统的系统依然占据了主导地位，但大型语言模型显示出了明显的潜力，表明它们在未来可能挑战现有的主导方法。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24003", "html_url": "https://arxiv.org/abs/2510.24003", "title": "META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine", "title_en": "META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine", "authors": "Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bing Qin", "background": "证据基于医学（EBM）在临床应用中扮演着关键角色。通过适当的医学文献，医生可以有效降低误诊率。研究发现，借助大型语言模型（LLMs）技术，如RAG，可以有效地进行EBM任务。然而，EBM对于证据有严格的要求，RAG在处理EBM任务时难以高效地区分高质量的证据。因此，受EBM中元分析方法的启发，该研究提出了一种新的方法，用于重新排名和过滤医学证据，以帮助大型语言模型提取最佳证据进行诊断。", "innovation": "该方法结合多种EBM方法，模仿元分析过程，包括可靠性分析、异质性分析和外推分析。这些过程允许用户从PubMed数据集中检索出最优的医学证据，从而帮助医疗助手提高诊断的准确性。这种新方法在实验中显示出高达11.4%的准确性提升，并成功使RAG能够从PubMed数据集中提取更高质量和更可靠的证据，减少错误知识的输入并提供更有效的回复。", "conclusion": "我们的方法成功地使RAG能够从PubMed数据集中提取更高质量和更可靠的信息。这项工作可以在系统回复中减少错误知识的混入，帮助用户获得更有效的反馈。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25766", "html_url": "https://arxiv.org/abs/2510.25766", "title": "语言模型后验归因的分解增强训练", "title_en": "Decomposition-Enhanced Training for Post-Hoc Attributions In Language Models", "authors": "Sriram Balasubramanian,Samyadeep Basu,Koustava Goswami,Ryan Rossi,Varun Manjunatha,Roshan Santhosh,Ruiyi Zhang,Soheil Feizi,Nedim Lipka", "background": "大型语言模型（LLMs）被广泛应用于长文档问答场景，可靠的来源归属性对用户的信任至关重要。现有的后验归因方法在提取式问答中效果良好，但在多跳、抽象性和半提取性场景中表现不佳。这是因为答案常常需要整合多个段落的信息，现有方法难以准确追踪。\n", "innovation": "提出了将后验归因重新定位为推理问题的方法，即将答案分解成可追溯具体背景的基本单元。该研究首先通过促使模型生成分配这些基本单元的过程来提升性能，然后介绍了一种名为DecompTune的后训练方法，该方法使模型在生成答案时进行分解作为中间推理步骤。此外，作者构建了一个包含复杂问答任务的多样数据集，该数据集由强大的LLM进行了分解标注，并使用针对特定任务的奖励对Qwen-2.5模型进行了第一次和第二次SFT+GRPO管道训练。\n", "conclusion": "DecompTune在广泛的实验和消融分析中显著提高了归因质量，超过了现有方法，并接近甚至超过了最先进的模型。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.27052", "html_url": "https://arxiv.org/abs/2510.27052", "title": "VISTA Score: Verification In Sequential Turn-based Assessment", "title_en": "VISTA Score: Verification In Sequential Turn-based Assessment", "authors": "Ashley Lewis,Andrew Perrault,Eric Fosler-Lussier,Michael White", "background": "对话AI系统在需要事实可靠性的场景中广泛应用受到幻觉现象的严重阻碍。现有的评估方法要么仅评估孤立的话语，要么将无法验证的内容视为错误，这限制了它们在多轮对话中的应用。", "innovation": "提出了VISTA（Verification In Sequential Turn-based Assessment）框架，通过逐条验证和顺序一致性跟踪来评估对话的真实性。VISTA将每个助手的回合分解为原子性的事实主张，验证它们并与可信来源和对话历史相对照，对无法验证的陈述进行分类。通过多轮对话中的八个大型语言模型和四个对话真实性基准数据集（AIS、BEGIN、FAITHDIAL、FADE），VISTA在幻觉检测方面显著优于FACTSCORE和LLM-as-Judge基准。", "conclusion": "VISTA通过建模对话的真实性作为动态属性，提供了一个更透明、与人类价值观更一致的对话系统真实性的度量标准。同时，VISTA的人类评估表明，它提高了注释者的共识，并揭示了现有基准中的不一致性。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03121", "html_url": "https://arxiv.org/abs/2511.03121", "title": "利用控制屏障函数对大型语言模型进行对齐", "title_en": "Control Barrier Function for Aligning Large Language Models", "authors": "Yuya Miyaoka,Masaki Inoue", "background": "本文提出了一个基于控制的框架，用于通过利用控制屏障函数（CBF）来对齐大型语言模型，以确保生成符合用户期望的文本。该框架将安全过滤器应用于从基础大型语言模型中生成的预测标记，以干预生成的文本。文章还提到该整体文本生成系统使用开源语言模型来生成积极的文本。", "innovation": "介绍了一种使用控制屏障函数的安全过滤器，该过滤器具有两个显著优势：它是一种附加类型，可以在不对基础大型语言模型进行微调的情况下用于对齐目的，并且可以直接将关注对齐目标的评估模型应用于该过滤器的设计。这种方法提供了一种在不对基础模型进行修改的情况下增强其输出安全性的新途径，同时还能根据用户的具体需求进行灵活调整。", "conclusion": "该研究实现了一个开源语言模型的文本生成系统，该系统具有生成积极文本的能力，并强调了通过控制屏障函数进行文本生成对齐的有效性，明确了所提出的框架在安全滤波方面的独特政策及其在模型对齐中的潜在应用。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.03441", "html_url": "https://arxiv.org/abs/2511.03441", "title": "CareMedEval数据集：评估医学领域的批判性评估与推理", "title_en": "CareMedEval dataset: Evaluating Critical Appraisal and Reasoning in the Biomedical Field", "authors": "Doria Bonzi,Alexandre Guiggi,Frédéric Béchet,Carlos Ramisch,Benoit Favre", "background": "在生物医学领域，批判性文献评估是一项基本技能。尽管大型语言模型（LLMs）可以提供支持，但在专业化领域的批判性推理方面，它们的可靠性仍然有限。为此，研究引入了CareMedEval数据集，一种用于评估LLMs在生物医学批判性评估和推理任务中的表现的新颖数据集。该数据集基于法国医学大学生的真实考试，包含534个问题，涉及37篇科学文章，专门评估了基于科学论文的批判性阅读和推理能力。", "innovation": "CareMedEval数据集旨在评估LLMs在生物医学领域批判性评估和推理任务中的表现。该数据集通过引入法国医学学生的真实考试问题来专门评估基于科学论文的批判性阅读和推理能力，不同于现有的基准评估。研究表明，尽管生成中间推理令牌可以显著改善结果，但最先进的通用和生物医学专业化LLMs在任务中的表现仍然具有挑战性，尤其是在评估研究限制和统计分析方面。", "conclusion": "CareMedEval数据集为基于科学文献的推理提供了一个具有挑战性的基准，揭示了当前LLM的局限性，为未来的自动支持开发铺平了道路。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.01019", "html_url": "https://arxiv.org/abs/2511.01019", "title": "OceanAI: 一种准确、透明、接近实时的海洋学洞察对话平台", "title_en": "OceanAI: A Conversational Platform for Accurate, Transparent, Near-Real-Time Oceanographic Insights", "authors": "Bowen Chen,Jayesh Gajbhar,Gregory Dusek,Rob Redmon,Patrick Hogan,Paul Liu,DelWayne Bohnenstiehl,Dongkuan Xu,Ruoying He", "background": "人工智能正在革新科学研究，但通用的对话式AI系统常常会产生未经验证的‘幻觉’，这损害了科学的严谨性。研究指出，现有AI系统在回答有关海洋数据的问题时往往会提供无法验证的或未提供数据来源的答案，这削弱了科学研究所依赖的透明性、可验证性和可重复性。为了克服这些问题，本文提出了OceanAI，这是一种能够直接连接并访问权威海洋数据流的对话平台，这些数据由美国国家海洋和大气管理局（NOAA）提供。通过这种方式，OceanAI能够提供基于真实数据和经过验证的科学依据的即时海洋学洞察，确保科学研究的严谨性与透明度。", "innovation": "OceanAI 将开源大型语言模型的自然语言流畅性与美国国家海洋和大气管理局（NOAA）的实时、参数化的海洋数据连接起来，通过实时API调用将这些问题转化为可复现的自然语言回答和数据可视化。与市场上其他广泛使用的AI聊天界面产品相比，只有OceanAI能正确引用来自NOAA的数据，提供支持原始数据参考的准确答案。OceanAI因其可扩展性，能够连接到多种NOAA数据产品和变量，适用于海洋灾害预测、生态系统评估和水质监测等多种应用场景，显著提升了决策支持过程中的透明度、可验证性和信任度。", "conclusion": "通过将输出与可验证的观测结果相结合，OceanAI 提高了透明度、可复现性和信任度，为AI在海洋学中的应用提供了可扩展的框架。研究结果表明，OceanAI在海洋科学领域的决策支持方面具有显著优势，具有广阔的应用前景。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18246", "html_url": "https://arxiv.org/abs/2505.18246", "title": "大型语言模型会变革临床预测吗？", "title_en": "Will Large Language Models Transform Clinical Prediction?", "authors": "Yusuf Yildiz,Goran Nenadic,Meghna Jani,David A. Jenkins", "background": "论文背景介绍了大型语言模型（LLMs）在医疗健康领域受到越来越多的关注。研究人员探讨了LLMs在临床预测模型（CPMs）中的应用潜力，特别是它们在处理纵向电子健康记录（EHR）数据以及多模态数据方面的优势，可以支持多结果预测。然而，文中也指出了方法学、验证、基础设施和监管方面的挑战，如不充分的时间事件建模方法、预测不足、外部验证不足以及对少数群体的影响偏见等。此外，高昂的基础设施成本和缺乏明确的监管框架也阻碍了其广泛应用。", "innovation": "创新点在于文章探讨了LLMs在处理多模态和纵向EHR数据方面的潜力，支持了多结果预测，同时也指出了当前存在的挑战，包括但不限于方法学问题、验证不足、基础设施成本高以及监管框架不明确等，这对于推动LLMs在临床预测应用中的发展具有重要意义。", "conclusion": "文章结论指出，为了促进临床预测的公平和有效整合，需要进一步研究和跨学科合作。开发具有时间意识、公平性和可解释性的模型应成为临床预测工作流转变的重点。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22666", "html_url": "https://arxiv.org/abs/2506.22666", "title": "VERA：用于破解大型语言模型的变分推断框架", "title_en": "VERA: Variational Inference Framework for Jailbreaking Large Language Models", "authors": "Anamika Lochab,Lu Yan,Patrick Pynadath,Xiangyu Zhang,Ruqi Zhang", "background": "API-only访问最先进的LLM的兴起强调了在实际环境中识别模型漏洞的有效黑盒破解方法的需求。现有的大多数基于梯度优化的方法依赖于遗传算法，这种方法在初始化和依赖于手动编写的提示池方面受到限制。此外，这些方法需要为每个提示单独优化，无法提供模型漏洞的全面描述。", "innovation": "我们提出了VERA：变分推理框架进行破解。VERA将黑盒破解提示问题重新表述为变分推理问题，训练一个小的攻击LLM来近似目标LLM在对抗性提示上的后验概率。训练完成后，攻击者可以生成多样性和流畅的破解提示，而无需重新优化。", "conclusion": "实验结果表明，VERA在各种目标LLM上都表现出强大的性能，突显了概率推断对对抗性提示生成的价值。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.07416", "html_url": "https://arxiv.org/abs/2504.07416", "title": "RadZero：基于相似性的跨注意力在胸部X射线解释性视觉语言对齐中的零样本多任务能力", "title_en": "RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Chest X-ray with Zero-Shot Multi-Task Capability", "authors": "Jonggwon Park,Byungmu Yoon,Soobum Kim,Kyoyun Choi", "background": "近年来，多模态模型在医学影像领域中的视觉-语言（VL）对齐方面取得了显著进展，特别是在放射学中。然而，现有方法在有效利用复杂的放射学报告时存在困难，同时也缺乏通过注意力概率可视化提高可解释性的能力。", "innovation": "本文提出了一种新的框架RadZero，该框架在一个带有零样本多任务能力的胸部X射线视觉-语言对齐任务中引入了VL-CABS（基于相似性的跨注意力）组件。VL-CABS通过文本嵌入和局部图像特征之间的相似性对齐，实现了可解释的精细视觉-语言推理。RadZero利用大型语言模型从放射学报告中提取简洁的语义句子，并采用多正样本对比训练方法，有效地捕捉图像与多重相关文本描述之间的关系。此外，通过计算文本嵌入与局部图像补丁特征之间的相似性，RadZero实现了零样本推理，并生成了像素级的视觉-语言相似性图，为表征和分割提供了进一步支持。", "conclusion": "RadZero在公共胸部X射线基准测试中的实验证明了其在零样本分类、表征和分割方面的优越性能。VL相似性图的分析进一步显示了VL-CABS在解释性VL对齐中的潜力。质性评价还证明了RadZero在开放式词汇语义分割中的能力，进一步验证了其在医学成像中的有效性。RadZero的代码可在相关链接处获取。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20368", "html_url": "https://arxiv.org/abs/2505.20368", "title": "开放域标准化金融文档问答中的分层检索与证据整理", "title_en": "Hierarchical Retrieval with Evidence Curation for Open-Domain Financial Question Answering on Standardized Documents", "authors": "Jaeyoung Choe,Jihoon Kim,Woohwan Jung", "background": "基于检索增强生成（RAG）的大语言模型（LLMs）在金融领域广泛应用，尤其是在知识密集型任务上表现出色。然而，标准化文档（例如SEC filings）具有相似的格式，如重复的模板文本和相似的表格结构，这导致传统的RAG方法容易误识别近似重复文本，从而引起重复检索，影响准确性和完整性。", "innovation": "本文提出了分层检索与证据整理（HiREC）框架，首先进行分层检索以减少相似文本的混淆，并从文档中选择最相关的段落。证据整理过程去除无关段落，并在必要时自动生成补充查询以收集缺失信息。此外，本文构建并发布了包含145,897份SEC文件和1,595个问答对的大规模开域金融（LOFin）问答基准数据集。", "conclusion": "通过HiREC框架，本文有效解决了标准化文档中近似重复文本的误识别问题，改进了准确性和完整性，同时构建的基准数据集为开放域金融问答任务的进一步研究提供了数据支持。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2511.01409", "html_url": "https://arxiv.org/abs/2511.01409", "title": "LiveSearchBench：一种自动构建的基于动态知识检索与推理的基准", "title_en": "LiveSearchBench: An Automatically Constructed Benchmark for Retrieval and Reasoning over Dynamic Knowledge", "authors": "Heng Zhou,Ao Yu,Yuchen Fan,Jianing Shi,Li Kang,Hejia Geng,Yongting Zhang,Yutao Fan,Yuhao Wu,Tiancheng He,Yiran Qin,Lei Bai,Zhenfei Yin", "background": "在评估大型语言模型（LLMs）的问答能力时，传统的方法依赖于静态基准，这些基准更侧重于记忆，忽视了检索的作用，无法捕捉到世界知识的动态特性。这种方法无法有效评估模型在面对新知识时的表现，特别是在多步查询的场景下，模型的性能表现尤为困难，且现有增强检索的方法和更大的指令调优模型也无法显著改善这一问题。因此，需要一种新的评估方法，能够自动化并定期生成基于最新知识更新的检索与推理基准，以更好地评估模型在不断变化的知识环境中动态获取与推理的能力。", "innovation": "LiveSearchBench 是一种自动化管线，能够从最近的知识更新中构建依赖检索的基准。该方法通过计算连续的维基数据快照之间的差异，过滤出高质量的候选三元组，并生成三个不同推理难度级别的自然语言问题。这些问题的答案可以保证通过SPARQL验证从而得到验证。该管道完全自动化，可扩展性好，并且将人类干预降到最低，支持基准的持续再生，具有时间相关性。实验表明，当模型面对预训练之后的事实时，其性能将会显著下降，尤其是在多步查询中这一差距尤为明显。检索增强方法和更大的、指令调优的模型只能提供部分优势，并未能缩减这一时间差距。LiveSearchBench的设计推动了评估从静态记忆过渡到需要实时检索和推理的任务，为系统性的长期评估LLMs提供了基础。", "conclusion": "LiveSearchBench 通过自动化过程创建了依赖检索的基准，有望改变以往依赖静态基准的评价方式，促使对有关世界知识的获取和使用进行当前相关性的评估。研究结果表明，传统的大型语言模型在面对新发生的事实时表现较差，尤其是在多步查询中，而增加检索能力的方法并没有完全解决这一问题。通过 LiveSearchBench 提供的系统评估框架，长期跟踪和评价大型语言模型在不断变化的知识环境中的表现成为可能。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.22879", "html_url": "https://arxiv.org/abs/2503.22879", "title": "Quamba2：选择性状态空间模型后训练整数量化框架", "title_en": "Quamba2: A Robust and Scalable Post-training Quantization Framework for Selective State Space Models", "authors": "Hung-Yueh Chiang,Chi-Chih Chang,Natalia Frumkin,Kai-Chiang Wu,Mohamed S. Abdelfattah,Diana Marculescu", "background": "状态空间模型（SSMs）因其一致的内存使用和高性能而逐渐成为Transformer的替代选择。然而，由于它们的存储需求和计算能力上的限制，将SSMs扩展到云服务或有限资源设备上仍然是一个挑战。为了解决这一问题，使用低比特宽度的数据格式对SSMs进行量化可以减小模型大小，并利于硬件加速。然而，由于SSMs容易受到量化引起的误差影响，因此最近的研究更多地集中在优化特定的模型或比特宽度以提高效率，而不牺牲性能。由于不同场景对不同的比特宽度配置有不同的需求（如W4A8用于提高大规模批处理解码速度，W4A16用于增强单用户短提示应用中的生成速度），因此需要提出一种能满足各种平台需求的量化方法。", "innovation": "Quamba2是一种适用于Mamba1和Mamba2后端的统一、可扩展的后训练整数量化框架，兼容W8A8、W4A8和W4A16。它利用SSMs的通道顺序保持特性和激活持久性，提出了一种离线的输入量化方法，通过排序和聚类对输入$x$进行8位量化，并对输入依赖参数$B$和$C$采用基于状态组的量化方法。为了确保计算不变性，它还在线下根据聚类序列重新排列权重。实验结果表明，Quamba2-8B相比两个最新的SSMs量化方法性能更优，分别在填充和生成阶段提供1.3倍和3倍的速度提升，并提供4倍的内存减少，同时仅有1.6%的平均准确率下降。", "conclusion": "Quamba2已在MMLU上展示了其泛化能力和鲁棒性，并且代码和量化模型将公开发布。"}
{"llm_update_time": "20251110", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16189", "html_url": "https://arxiv.org/abs/2509.16189", "title": "潜在学习：情景记忆通过使经验的灵活再利用补充参数学习", "title_en": "Latent learning: episodic memory complements parametric learning by enabling flexible reuse of experiences", "authors": "Andrew Kyle Lampinen,Martin Engelcke,Yuxuan Li,Arslan Chaudhry,James L. McClelland", "background": "当前的机器学习系统在泛化方面表现出相对较低的数据效率，难以像自然智能那样有效地利用过去的经验。文章讨论了在机器学习系统中引入潜在学习的概念，并借鉴认知科学的相关研究来探讨实现这一目标的机制，特别是情景记忆在其中可能扮演的角色。这涉及到对不同泛化失败案例（如语言模型中的反转诅咒和基于代理的导航新发现）的分析。", "innovation": "提出了通过情景记忆机制来补充现有参数学习方法，使机器学习系统能够在未来的任务中更灵活地重用经验信息。研究还识别了有效使用检索机制的关键组件，包括在实例内部进行上下文学习的重要性。", "conclusion": "研究表明，既然一个具有oracle检索机制的系统可以更灵活地利用学习经验来更好地泛化解决多数问题，这种结果为理解当前机器学习系统相比自然智能相对数据效率较低的原因提供了一种可能的解释，同时表明检索方法可以补充参数学习以改善泛化能力。最后，讨论了这些发现与认知科学和神经科学中的先前结果之间的联系，以及更广泛的影响。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03765", "html_url": "https://arxiv.org/abs/2511.03765", "title": "LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices", "title_en": "LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices", "authors": "Hyunseok Kwak,Kyeongwon Lee,Jae-Jin Lee,Woojoo Lee", "background": "在边缘应用程序如人体活动识别（HAR）中，设备本地的卷积神经网络（CNN）微调对于抵御领域变化至关重要。然而，在严格的时间、存储和能耗预算下，完整的微调方法是不可行的。这需要一种参数有效的微调方法来减少存储和计算需求，同时保持性能接近完全微调。", "innovation": "LoRA-Edge 提出了一种基于低秩适应（LoRA）和张量积态帮助的参数有效微调（PEFT）方法。其创新点包括：1) 应用张量积态奇异值分解 (TT-SVD) 来预训练卷积层；2) 仅选择性地更新输出核心，初始时辅助路径保持不活跃；3) 将更新融合回密集内核中，以保持推理成本不变。这种方法保持了卷积结构，并将可训练参数的数量减少了一个数量级，同时保持了与完全微调相近的准确性，且使用最少的参数比例（最多1.49%）进行更新，优于类似预算下的先前参数有效基线。", "conclusion": "LoRA-Edge 方法在 Jetson Orin Nano 上提供了1.4-3.8倍的更快收敛速度，从而使得结构对齐、参数有效的本地 CNN 调整在边缘平台上实际可行。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03855", "html_url": "https://arxiv.org/abs/2511.03855", "title": "噪声注入：提高小规模数据集的跨分布泛化能力", "title_en": "Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets", "authors": "Duong Mai,Lawrence Hall", "background": "深度学习（DL）模型在图像识别中已被证明在面对不同设备和人群的数据时难以泛化。特别是在胸部X光片（CXR）中检测新冠肺炎时，模型在面对训练数据集外的新临床来源的分布外（OOD）数据时表现不佳。这种现象是因为模型学会了依赖于特定于源的捷径——这些捷径在新分布中无法复制——而不是合理的关键标志，以在分布内（ID）数据中实现最佳性能。", "innovation": "本研究调查了在训练期间注入基本噪声技术（高斯、斑点、泊松和椒盐）以增强模型对分布漂移的鲁棒性。实验结果表明，这种方法可以显著缩小分布内和分布外评价之间的性能差距，从0.10-0.20降低到0.01-0.06，基于多次随机种子下关键指标（如AUC、F1、精度、召回率和特异度）的平均结果。", "conclusion": "我们的源代码已公开，在提升小型数据集跨分布泛化能力方面提供了一种有效的方法。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03962", "html_url": "https://arxiv.org/abs/2511.03962", "title": "线性分数变换模型及轻字段相机校准方法", "title_en": "A Linear Fractional Transformation Model and Calibration Method for Light Field Camera", "authors": "Zhong Chen,Changfeng Chen", "background": "在使用轻字段相机进行三维重建时，内部参数的准确校准至关重要但极具挑战性。", "innovation": "提出了一种线性分数变换(LFT)参数α来解耦主透镜和微透镜阵列(MLA)，并且该方法结合了最小二乘法的解析解决方案及非线性优化，并引入了一种从原始图像中检测特征的方法，此方法在物理和模拟数据上的实验结果证实了其性能。", "conclusion": "基于所提出的方法，原始轻字段图像的仿真速度更快，这对于数据驱动深度学习方法至关重要。相关代码可以从作者的网站上获得。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03882", "html_url": "https://arxiv.org/abs/2511.03882", "title": "探究自主X射线引导脊柱手术的机器人控制策略学习", "title_en": "Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures", "authors": "Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath", "background": "基于模仿学习的机器人控制策略在基于视频的机器人技术中正受到重新关注。然而，这种方法是否适用于X射线引导的程序，如脊柱内固定手术，仍不清楚。这是因为双平面X射线的多视角解释是复杂的。", "innovation": "开发了一个能够大规模、自动化模拟具有高度现实性的X射线引导脊柱手术的虚拟沙箱。创建了一个正确的轨迹及其对应的双平面X射线序列的数据库，以模拟医生逐步对齐的过程。通过基于视觉信息迭代对齐针管来训练模仿学习策略，用于计划和开环控制，展示了该方法的限制和能力。策略在68.5%的情况下第一次尝试就成功，并且能够在不同的脊椎水平保持安全的针管轨迹，适应复杂解剖结构，并在初始条件变化的情况下依然稳健。", "conclusion": "初步结果表明该方法有前景，但也发现了进入点精度的限制。完全闭环控制需要考虑如何提供足够的反馈。在更坚固的先验知识和领域知识下，这种模型可能为未来减少对CT的依赖的手术导航提供基础。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03950", "html_url": "https://arxiv.org/abs/2511.03950", "title": "通过纹理引导的高斯网格联合优化改进多视图重建", "title_en": "Improving Multi-View Reconstruction via Texture-Guided Gaussian-Mesh Joint Optimization", "authors": "Zhejia Cai,Puhua Jiang,Shiwei Mao,Hongkun Cao,Ruqi Huang", "background": "从多视角图像重建现实世界的物体对于三维编辑、AR/VR以及数字内容创建等应用至关重要。现有的方法通常侧重于几何准确性（多视角立体）或光影逼真的呈现（新颖视角合成），往往会将几何优化和外观优化分离开来，导致下游编辑任务受阻。", "innovation": "提出了一种新的框架，该框架通过高斯引导的网格可微渲染对网格几何（顶点位置和面）以及顶点颜色进行同步优化。这种方法结合了输入图像的光度一致性以及法线和深度图的几何正则化，旨在同时优化几何形状和外观，以获得高质量的三维重建。", "conclusion": "高质量的3D重建可以被进一步用于后续编辑任务，如重新照明和形状变形。代码将在论文被接受后公开发布。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03888", "html_url": "https://arxiv.org/abs/2511.03888", "title": "基于数据和模型增强的YOLOv12深度学习模型在沙漠废物检测与分类中的应用", "title_en": "Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model", "authors": "Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui", "background": "全球废物危机正在加剧，固体废物的产生量预计到2050年将增加70%。传统的废物收集方法，在偏远或恶劣环境中，如沙漠，是劳动密集型、低效且往往危险的。最近计算机视觉和深度学习的进步开启了自动废物检测系统的大门，但大多数研究集中在城市环境和可回收材料上，忽视了有机和有害废物以及尚待探索的地区如沙漠。", "innovation": "本文提出了一种增强的实时物体检测框架，基于修剪后的YOLOv12轻量级版本，结合自我对抗训练(SAT)和专门的数据增强策略。该模型使用DroneTrashNet数据集，显示了在精确度、召回率和平均精度(mAP)方面的显著改进，同时实现了低延迟和紧凑的模型尺寸，适用于资源受限的无人机部署。并且，与最先进的轻量级YOLO变体相比，该模型展示了在准确性和效率之间的最优平衡。", "conclusion": "我们的结果验证了结合数据和模型增强措施对于在沙漠环境中进行鲁棒的实时废物检测的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03819", "html_url": "https://arxiv.org/abs/2511.03819", "title": "SILVI: Simple Interface for Labeling Video Interactions", "title_en": "SILVI: Simple Interface for Labeling Video Interactions", "authors": "Ozan Kanbertay(1),Richard Vogg(1 and 2),Elif Karakoc(2),Peter M. Kappeler(2 and 3),Claudia Fichtel(2),Alexander S. Ecker(1) ((1) Institute of Computer Science and Campus Institute Data Science, University of Göttingen, (2) Behavioral Ecology &amp; Sociobiology Unit, German Primate Center, Göttingen, Germany, (3) Department of Sociobiology/Anthropology, University of Göttingen, Göttingen, Germany)", "background": "计算机视觉方法越来越多地用于通过相机陷阱、无人机或直接观察野生动物的视频数据的自动分析。尽管近期的研究主要集中在检测个体行为，但对行为互动的检测和标注研究较少，这是理解动物社会行为和个体行为关键的一部分。现有的开源标注工具要么无法定位个体，要么无法捕捉互动关系。", "innovation": "本文介绍了一种名为SILVI的开源标注软件，它可以将个体定位和互动检测功能集成在一起。SILVI可以协助研究人员直接在视频数据中标注行为及互动，生成适用于训练和验证计算机视觉模型的结构化输出。SILVI将行为生态学与计算机视觉结合，促进了精细行为分析的自动化方法的发展。", "conclusion": "尽管SILVI主要应用于动物行为研究，但它也可以广泛应用于需要提取动态场景图的人际互动视频中的标注任务。有关该软件的详情、文档和下载说明，可访问：this https URL。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03943", "html_url": "https://arxiv.org/abs/2511.03943", "title": "自适应时间细化：连续深度分配和距离回归以实现高效动作定位", "title_en": "Adaptive Temporal Refinement: Continuous Depth Allocation and Distance Regression for Efficient Action Localization", "authors": "Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma", "background": "时空动作定位需要精确的边界检测，但当前的方法在困难度显著变化的不同边界上应用均匀的计算量。现有的方法没有针对性地处理不同边界的不同难度，导致在边界定位上不够精确。", "innovation": "本文提出了两种互补的贡献。首先，边界距离回归（BDR）通过有符号距离回归而非分类来提供信息论上最优的定位，实现了43%更锐利的边界峰值。其次，自适应时间细化（ATR）通过连续深度选择$\tau \forall \tau \text{in} [0,1]$来分配计算，无需使用强化学习便实现了端到端的可微优化。ATR在THUMOS14数据集上取得了56.5%的mAP@0.7，相较于均匀处理的198G FLOPs，使用162G FLOPs实现了2.9%的改进。效益随边界异质性的增加而增加，在短动作上实现了4.2%的改进。训练成本通过知识蒸馏得到缓解，轻量级的学生模型在基本成本下保留了99%的性能。实验结果在四个基准上通过严格统计学测试得到了验证。", "conclusion": "自适应时间细化通过连续深度分配和距离回归实现了时空动作定位的高效性能，在不同数据集和边界条件下都展示了显著的提升效果。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03912", "html_url": "https://arxiv.org/abs/2511.03912", "title": "我检测我未知的：基于随机权重平均高斯的无专家监督增量异常学习", "title_en": "I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging", "authors": "Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh(AI Research Lab, Department of Computer Science and Biomedical and Translational Sciences, Sanford School of Medicine, University Of South Dakota, Vermillion, SD, USA)", "background": "医学影像中的未知异常检测仍是一个基本挑战，主要是因为标记异常的稀缺和专家监督的高成本。现有的方法依赖于大量有标签的数据和生成式重建或回放缓冲，这些方法在标签稀缺的情况下难以应用。", "innovation": "本文提出了一种无需人工标注和无专家监督的增量异常学习框架。该框架通过轻量级适配器的更新和不确定性门控样本接纳，逐步扩充信任的正常样本集合。这种方法利用预训练的视觉骨干网络和小的卷积适配器，快速进行领域适应，同时保障较低的计算开销。通过嵌入聚类（coreset）存储提取的特征，利用k-NN方法进行异常评分。此方法通过双重概率门控机制（包括样本与现有聚类的距离和SWAG基的表征不确定性）来确保在扩充过程中安全性和准确性。", "conclusion": "实验表明，该系统在获得无标签数据的过程中，逐步细化了正常性的概念，并在多种医学成像数据集上取得了显著的提升。例如，在COVID-CXR数据集上，ROC-AUC从0.9489提升到了0.9982（F1从0.8048提升到0.9746）；在肺炎胸片数据集上，ROC-AUC从0.6834提高到0.8968；在脑部MRI ND-5数据集上，ROC-AUC和PR-AUC分别提升了0.1228和0.0672，证明了该框架的有效性和效率。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03891", "html_url": "https://arxiv.org/abs/2511.03891", "title": "使用基于类别的输入图像合成改善小样本及类别不平衡数据集的诊断性能", "title_en": "Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition", "authors": "Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat", "background": "小样本且类别不平衡的数据集以及差输入图像质量会导致深度学习模型产生较高的误预测率。本文介绍了一种基于类别的图像合成方法（Class-Based Image Composition），通过多个同一类别的图像融合生成组合视觉复合图像（Composite Input Images, CoImg），从而增强类内部的差异性和训练样本的信息密度，提高模型区分细微病变模式的能力。该方法在OCTDL（包含了2,064张高分辨率的人类视网膜光学相干断层扫描图像，代表了七个不同的疾病类别且严重类别不平衡）数据集上进行了测试，构建了一个完全类平衡版本的数据集Co-OCTDL，将每张扫描图像表示为3x1布局的组合图像。", "innovation": "研究提出了一种基于类别的图像合成方法（Class-Based Image Composition），通过多个同一类别的图像生成组合视觉复合图像（CoImg），来改善小样本及类别不平衡数据集的诊断性能。该方法通过提高类内部的差异性和增强训练样本的信息密度，提高了模型区分细微病变模式的能力。研究使用VGG16模型进行了基准比较，结果表明该方法在诊断表现上显著提升，与基准模型相比，新方法在F1分数和AUC上分别达到了0.995和0.9996，并且尽管在处理的小样本且类别不平衡数据集上，错误预测率也显著降低，证明了该方法能够产生高质量的预测结果，即使在样本量小且类别不平衡的情况下也可以实现近乎完美的诊断性能。", "conclusion": "提出的基于类别输入图像合成方法显著提高了小样本及类别不平衡数据集上的诊断性能，在OCTDL数据集组成的完全类平衡版本Co-OCTDL上测试中，该方法达到了近乎完美的准确性（99.6%），F1分数为0.995，AUC为0.9996，且错误预测率显著降低。这表明该方法可以提高深度学习模型在处理小样本且类别不平衡数据集时的诊断能力，特别是在那些易受到类别不平衡影响的场景中表现出色。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04008", "html_url": "https://arxiv.org/abs/2511.04008", "title": "GNN-MoE: 使用图神经网络进行参数高效领域泛化的上下文感知小patches路由", "title_en": "GNN-MoE: Context-Aware Patch Routing using GNNs for Parameter-Efficient Domain Generalization", "authors": "Mahmoud Soliman,Omar Abdelaziz,Ahmed Radwan,Anand,Mohamed Shehata", "background": "领域泛化（DG）的目标是在未见过的数据域中维持ViT的稳健性能。标准的微调方法成本高昂且有可能损害泛化性能。", "innovation": "提出了一种名为GNN-MoE的方案，通过采用一种高效的混合专家（MoE）框架和基于Kronecker适配器的参数高效微调（PEFT），结合了一个新颖的基于图神经网络（GNN）的路由器（如GCN、GAT、SAGE）。该方法利用上下文感知的GNN路由来动态地将patches分配给专门的专家，从而更好地适应领域变化，并实现了在DG基准上的高性能。", "conclusion": "GNN-MoE方法在高参数效率下达到了当前最佳或竞争优势的目标，进一步证明了基于图的上下文路由在构建鲁棒轻量级DG时的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03997", "html_url": "https://arxiv.org/abs/2511.03997", "title": "PhysCorr：基于双奖励DPO的物理受限文本到视频生成方法与自动化偏好选择", "title_en": "PhysCorr: Dual-Reward DPO for Physics-Constrained Text-to-Video Generation with Automated Preference Selection", "authors": "Peiyao Wang,Weining Wang,Qi Li", "background": "近期文本到视频生成技术在感知质量方面取得了显著进步，但生成的内容常常违背物理原理，表现为对象动力学不合理、互动不一致以及运动模式不真实。这些失败阻碍了视频生成模型在实体AI、机器人技术以及模拟密集型领域的部署应用。", "innovation": "提出了一种名为PhysCorr的统一框架，用于建模、评估和优化视频生成中的物理一致性。具体来说，引入了PhysicsRM，这是第一个同时量化对象内部稳定性和对象间交互的双维度奖励模型。在此基础上，开发了PhyDPO，这是一种全新的直接偏好优化管道，利用对比反馈和物理感知重新加权来引导生成具有物理连贯性的输出。该方法具有模型无关和可扩展性，可以无缝集成到各种视频扩散和基于变换器的框架中。", "conclusion": "广泛的实验跨多个基准表明，PhysCorr在保持视觉保真度和语义对齐的同时，在物理真实性方面取得了显著改进。这项工作是迈向基于物理的可靠视频生成的关键一步。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03988", "html_url": "https://arxiv.org/abs/2511.03988", "title": "简单3D姿态特征支持人类和机器的社会场景理解", "title_en": "Simple 3D Pose Features Support Human and Machine Social Scene Understanding", "authors": "Wenshuo Qin,Leyla Isik", "background": "人类可以从视觉输入中快速而轻松地提取他人社交互动的各种信息，包括姿态和距离等视觉空间线索。然而，支持这些能力的计算过程仍然不甚明确。当前最先进的AI视觉系统在识别社交互动时仍然存在挑战。研究团队推测，人类可能依赖3D姿态信息来做出社会判断，而这些信息在大多数AI视觉模型中是缺失的。", "innovation": "研究团队将最先进的人体姿态和深度估计算法结合，从日常人类行为的视频片段中提取3D关节点信息，并将其与当前AI视觉模型进行比较。3D关节点的表现超过了大多数当前AI视觉模型。这表明关键的社会信息存在于人体的明确姿态中，而大多数视觉模型在其学习特征中未能体现。进一步简化后，通过提取视频中面部的3D位置和方向来创建一个紧凑的3D社会姿态特征集，这些特征与完整的3D关节特征具有相当的预测能力，并显著提高了现有AI视觉模型的性能。这些发现强有力地证明人类和社会交互理解依赖于明确的3D姿态表示，并且可以由简单的结构化视觉空间原语支持。", "conclusion": "研究结果提供了强有力的证据，证明人类和社会交互理解依赖于明确的3D姿态表示，并且可以通过简单的结构化视觉空间原语得到支持。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03970", "html_url": "https://arxiv.org/abs/2511.03970", "title": "Room Envelopes: 一种从图像重建室内布局的合成数据集", "title_en": "Room Envelopes: A Synthetic Dataset for Indoor Layout Reconstruction from Images", "authors": "Sam Bahrami,Dylan Campbell", "background": "现代的场景重建方法能够精确恢复在一张或多张图像中可见的三维表面。然而，这导致了不完整的重建，所有的被遮挡表面都被遗漏了。尽管在基于生成模型的重建仅部分观察到的对象方面取得了重大进展，但在场景中的结构性元素，如墙壁、地板和天花板方面的工作较少。我们提出这些场景元素应该较容易预测，因为它们通常为平面的、重复的、简单的，并且可能意味着可以采用成本较低的方法。这项工作中，我们提出了一个合成数据集——Room Envelopes，通过提供一系列RGB图像及其各自的两个关联点图（一个捕捉可见表面，另一个捕捉移除修饰后的时间布局表），促进该任务的发展。这使得可以直接监督前馈单目几何估计器，能够同时预测第一个可见表面和第一布局表面，从而对场景的范围、以及物体的形状和位置有了理解。", "innovation": "提出了一种合成数据集——Room Envelopes，用于从图像重建室内布局。该数据集提供了RGB图像及其配套的两个点图，一个捕捉可见表面，另一个捕捉移除修饰后的时间布局。这种方法允许直接监督单目几何估计器预测两个表面，从而为理解场景范围和物体形状与位置提供了直接的信息。", "conclusion": "通过提出Room Envelopes数据集，该研究为从图像重建室内布局这一任务设定了一个新的基准点，提供了有价值的直接监督来训练前馈单目几何估计器，促进了该领域的发展。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03992", "html_url": "https://arxiv.org/abs/2511.03992", "title": "CaRF: 提升3D高斯散点表示中的多视图一致性", "title_en": "CaRF: Enhancing Multi-View Consistency in Referring 3D Gaussian Splatting Segmentation", "authors": "Yuwen Tao,Kanglei Zhou,Xin Tan,Yuan Xie", "background": "目前的交叉模态对齐虽然已经在语言和3D几何之间取得了进展，但现有的管道仍然难以处理多视图一致性问题，这是由于它们依赖于2D渲染的伪监督和特定视图特征学习导致的。现有方法仍面临难以解决的问题，特别是在视图间一致性方面缺乏有效的方法。", "innovation": "本文提出了Camera Aware Referring Field (CaRF)，这是一种完全可微的框架，直接在3D高斯空间中操作，实现了多视图一致性。CaRF引入了Gaussian Field Camera Encoding (GFCE)，将相机几何形状融入到高斯字段和文本交互动态建模视依赖变化。此外，提出了一种新的In Training Paired View Supervision (ITPVS)，在培训过程中对校准视图的Gaussian logits进行配对监督，有效地缓解了单视图过拟合问题，揭示了视图间的差异以供优化。", "conclusion": "在三个代表性基准上进行了广泛的实验表明，CaRF在Ref LERF、LERF OVS和3D OVS数据集上的mIoU分别平均提高了16.8%、4.3%和2.0%。此外，这项工作推进了更可靠和视图一致的3D场景理解，有望在嵌入式AI、AR/VR交互和自主感知等领域产生潜在益处。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04037", "html_url": "https://arxiv.org/abs/2511.04037", "title": "一种用于低帧率PPG信号稳健生物认证的混合深度学习模型", "title_en": "A Hybrid Deep Learning Model for Robust Biometric Authentication from Low-Frame-Rate PPG Signals", "authors": "Arfina Rahman,Mahesh Banavar", "background": "光体积描记图（PPG）信号通过利用光线测量皮肤中血量的变化，在生物认证中受到了关注，主要由于其无需侵入性获取、固有的活体检测和适合低成本可穿戴设备的特点。然而，PPG信号的质量受到运动伪影、光照变化和个体生理变化的挑战，因此需要稳健的特征提取和分类。", "innovation": "提出了一种基于低帧率手指视频中提取的PPG信号的轻量级且低成本的生物认证框架。该框架利用连续小波变换（CWT）从一维PPG段生成具有鲁棒性的二维时间-频率波形图。提出了一个结合卷积视觉变换（CVT）分支和卷积混合器（ConvMixer）分支与长短期记忆网络（LSTM）的时空特征的混合深度学习模型（CVT-ConvMixer-LSTM），该模型在46个受试者的实验中达到了98%的认证准确性。", "conclusion": "由于其高效性、可扩展性和内置的活体检测能力，所提出的系统非常适合用于真实世界的移动和嵌入式生物认证安全应用。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04029", "html_url": "https://arxiv.org/abs/2511.04029", "title": "无损3D体素表示法，无需等值面", "title_en": "Near-Lossless 3D Voxel Representation Free from Iso-surface", "authors": "Yihao Luo,Xianglong He,Chuanyu Pan,Yiwen Chen,Jiaqi Wu,Yangguang Li,Wanli Ouyang,Yuanming Hu,Guang Yang,ChoonHwai Yap", "background": "3D重建和生成的基础是准确高效的3D网格的体素化表示。现有的基于等值面的表示法严重依赖于密封或渲染优化，这不可避免地会牺牲几何保真度。", "innovation": "提出了一种新的稀疏体素化表示法——忠实轮廓提取法（Faithful Contouring），它支持任意网格的最大2048+分辨率，无需将网格转换为场函数或在重塑过程中提取等值面。该方法通过保留尖锐性和内部结构来实现近乎无损的保真度，即使对于具有复杂几何形状和拓扑结构的具有挑战性的情况也是如此。此外，该方法在纹理处理、操作和编辑方面也具有灵活性。为此，设计了一种双模式自动编码器，以支持忠实轮廓提取法的可扩展和细节保留形状重建。", "conclusion": "广泛的实验表明，忠实轮廓提取法在表示和重建方面均优于现有方法。对于直接表示，它达到了10^-5级的距离误差；对于网格重建，与强大的基线相比，其减少马氏距离93%，F分数提高了35%，证明了作为3D学习任务表示的优越保真度。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04016", "html_url": "https://arxiv.org/abs/2511.04016", "title": "MedDChest: 一种面向胸部成像的感知内容导向多模态基础视觉模型", "title_en": "MedDChest: A Content-Aware Multimodal Foundational Vision Model for Thoracic Imaging", "authors": "Mahmoud Soliman,Islam Osman,Mohamed S. Shehata,Rasika Rajapakshe", "background": "在医疗成像中，视觉模型的表现受限于传统上使用在领域外自然图像上预训练的主干网络进行微调的范式。因此，存在一个基本的领域差距需要解决。", "innovation": "提出了一种新的基础视觉变换器（ViT）模型MedDChest，专门针对胸部成像进行了优化。MedDChest是从一个包含超过120万幅图像的多样化医学图像集（包括胸部X光和CT）中进行从零开始的预训练，有效克服了标准裁剪技术在医学扫描中的低效性。通过引入Guided Random Resized Crops，一种新颖的内容感知数据增强策略，旨在采样向解剖相关区域偏向，从而提高了模型在胸部成像任务上的性能。", "conclusion": "通过大规模、领域内的预训练以及领域特定的数据增强，MedDChest显著优于公开可用的在ImageNet上预训练的模型，提供了一个强大的、稳健的功能提取器，为广泛的胸部诊断任务提供了一个更好的起点。模型权重将公开，以促进未来的研究和应用。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04083", "html_url": "https://arxiv.org/abs/2511.04083", "title": "对抗生成与分数推理CT降噪：CycleGAN与Noise2Score对比", "title_en": "Adversarial and Score-Based CT Denoising: CycleGAN vs Noise2Score", "authors": "Abu Hanif Muhammad Syarubany", "background": "研究在无配对和自监督条件下CT图像去噪的方法，评估了两种数据效率高且强大的方法：CycleGAN基的残差转换器和Noise2Score得分匹配去噪器。在共同的评估协议下，通过配置扫描确定了CycleGAN的最优设置，并进行了长时间训练。这些方法在噪声输入上取得了显著的去噪效果，而Noise2Score在极强噪声输入上的表现尤为突出。总的来说，CycleGAN提供了最佳的最终图像质量，而Noise2Score则提供了无配对且性能竞争力的替代方案。", "innovation": "引入了两种强大的去噪方法——基于CycleGAN的残差转换器和Noise2Score得分匹配去噪器，在无配对和自监督条件下评估它们的效果。确定了CycleGAN的最优配置，并评估了它们在各种噪声输入下的表现，特别是在极强噪声输入上，Noise2Score表现出色。", "conclusion": "CycleGAN提供了最佳的最终图像质量，而Noise2Score则提供了无配对的替代方案，具有竞争力的性能。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04078", "html_url": "https://arxiv.org/abs/2511.04078", "title": "深度语言锚定多模态视觉-脑部对齐中的深层语义不确定性感知", "title_en": "Unveiling Deep Semantic Uncertainty Perception for Language-Anchored Multi-modal Vision-Brain Alignment", "authors": "Zehui Feng,Chenqi Zhang,Mingru Wang,Minuo Wei,Shiwei Cheng,Cuntai Guan,Ting Han", "background": "从神经信号（如EEG，MEG和fMRI）揭示视觉语义仍然是一项基本挑战，受到被试间差异和视觉特征纠缠性质的影响。现有方法直接将神经活动与视觉嵌入对齐，但仅基于视觉的表示常常无法捕捉到潜在的语义维度，限制了解释性和深层次的鲁棒性。", "innovation": "本文提出了Bratrix，这是第一个端到端的框架，实现多模态语言锚定视觉-脑部对齐。Bratrix将视觉刺激分解为层次化的视觉和语言语义组件，并将视觉和脑部表示投影到共享的潜空间中，从而形成对齐的视觉-语言和脑部-语言嵌入。Bratrix还引入了一种新颖的不确定性感知模块，通过在对齐过程中使用不确定性感知加权来模拟人类感知的可靠性并处理嘈杂的神经信号。通过利用可学习的语言锚定语义矩阵增强跨模态相关性，并采用基于单模态预训练后多模态微调的双重训练策略，Bratrix-M提高了对齐精度。", "conclusion": "在EEG、MEG和fMRI基准测试上的广泛实验表明，Bratrix在检索、重建和生成描述方面表现优于最先进的方法，特别在200分类的EEG检索任务中超越了14.3%。代码及模型已经提供。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04112", "html_url": "https://arxiv.org/abs/2511.04112", "title": "SpatialLock: 在文本到图像合成中实现精确的空间控制", "title_en": "SpatialLock: Precise Spatial Control in Text-to-Image Synthesis", "authors": "Biao Liu,Yuanzhi Liang", "background": "文本到图像（T2I）合成近年来取得了显著进展，推动了自动生成数据集的应用。然而，控制生成图像中的物体定位精度仍然是一项挑战。现有方法未能充分利用位置信息，导致物体的空间布局理解不足。", "innovation": "本文提出了一种名为SpatialLock的新框架，该框架利用感知信号和定位信息共同控制空间位置的生成。该框架包含两个组件：位置相关的注入(PoI)和位置导向的训练(PoG)。PoI通过注意层直接整合空间信息，促使模型有效学习定位信息。PoG则使用基于感知的监督进一步细化物体定位。这些组件共同使模型能够生成精确的空间布局，并提高生成图像的视觉质量。", "conclusion": "实验表明，SpatialLock在精确物体定位方面达到了新纪录，多个数据集的IOU得分超过0.9。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04123", "html_url": "https://arxiv.org/abs/2511.04123", "title": "多风格到草图生成", "title_en": "Text to Sketch Generation with Multi-Styles", "authors": "Tengjie Li,Shikui Tu,Lei Xu", "background": "近期视觉-语言模型的进步促进了草图生成的发展。然而，现有的专门方法主要集中在通用合成上，缺乏控制草图风格的精密机制。", "innovation": "本文提出了一种无需训练的基于扩散模型的框架，可以通过文本提示和引用风格草图进行明确的风格指导。我们的设计通过线性平滑引入参考特征作为辅助信息，并利用风格-内容指导机制，有效减少了参考草图的内容外溢并提高了合成质量，尤其是在参考草图和目标草图结构相似性较低的情况下。此外，我们扩展了框架以支持通过联合AdaIN模块协调多个参考草图特征的可控多风格生成。", "conclusion": "大量实验表明，我们的方法能够实现高质量的草图生成，精度的风格对齐，以及在风格控制上的改进的灵活性。M3S的官方实现可在以下链接查看：this https URL。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04126", "html_url": "https://arxiv.org/abs/2511.04126", "title": "利用 Hawk Eye 系统实现自动网球选手与球跟踪及场地关键点检测", "title_en": "Automated Tennis Player and Ball Tracking with Court Keypoints Detection (Hawk Eye System)", "authors": "Venkata Manikanta Desu,Syed Fawaz Ali", "background": "随着体育分析技术的发展，自动化网球比赛分析的需求日益增加。传统的手动分析方法耗时且不精确，因此，开发一种能够自动检测与跟踪网球选手和球，并能够识别场地关键点的系统变得尤为重要。本研究旨在建立一个完整的自动化网球匹配分析管道，以提高比赛分析的效率和准确性。", "innovation": "该研究创新地集成了多个深度学习模型，包括用于选手检测的YOLOv8、用于球跟踪的自训练YOLOv5模型，以及基于ResNet50的场地关键点检测架构。该系统能够实时检测、跟踪选手和网球，并识别场地关键点，提供详细的分析结果，包括选手移动模式、球速、击球准确性及选手反应时间等。实验结果表明，该模型在不同场地条件下及比赛场景中表现出强劲的鲁棒性。", "conclusion": "通过输出标记视频和详细的性能指标，该系统为教练员、广播商和运动员提供了关于比赛动态的实用洞察。未来的研究可以探索更多的深度学习技术，以进一步提高系统的性能和实用性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04117", "html_url": "https://arxiv.org/abs/2511.04117", "title": "Tortoise and Hare Guidance: 使用多速率积分加速扩散模型推断", "title_en": "Tortoise and Hare Guidance: Accelerating Diffusion Model Inference with Multirate Integration", "authors": "Yunghee Lee,Byeonghyun Pak,Junwha Hong,Hoseong Kim", "background": "本文提出了Tortoise and Hare Guidance (THG)，这是一种无需训练的策略，能够加速扩散采样过程，同时保持高质量的生成效果。作者通过将分类器自由指导（CFG）偏微分方程（ODE）重新表述为多速率的偏微分方程系统，揭示了噪声估计和附加指导项对数值误差的不同敏感性。基于此分析，THG显著减少了附加指导的计算量，同时保持了生成的高质量成果。此外，THG还通过自适应步长选择和指导尺度调度来增加计算效率。这些改进使得THG在与现有最先进的CFG加速方法相同的计算预算下，表现出更好的性能。这一研究成果进一步证明了多速率公式对于扩散解算器的潜力，为实时高质量图像合成开辟了新的可能。", "innovation": "1. 提出了Tortoise and Hare Guidance（THG）策略，这是一种无需训练的方法，可以加速扩散模型的采样过程，同时保持高质量的生成效果。\n2. 通过将CFG ODE重新表述为多速率系统，揭示了噪声估计和附加指导项对数值误差的不同敏感性。\n3. 利用重新表述的模型，THG减少了附加指导的计算量，提出了一种基于误差边界感知的时间步长采样器和指导尺度调度器，从而提高了计算效率。\n4. 与最先进的CFG加速方法相比，THG在相同计算预算下表现出更好的性能，减少了函数评估（NFE），同时保持了与原始生成相同水平的高质量结果。", "conclusion": "本研究证明了多速率公式对扩散解算器的有效性，提出了THG方法，显著提高了扩散模型的生成效率，同时保持了高质量的结果。这一方法为实现实时高质量图像合成铺平了道路，无需任何模型再训练。未来的改进可能包括更复杂的多速率策略或者结合其他优化技术，进一步提高效率和质量。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04161", "html_url": "https://arxiv.org/abs/2511.04161", "title": "Seeing Straight: 文档方向检测以提高OCR效率", "title_en": "Seeing Straight: Document Orientation Detection for Efficient OCR", "authors": "Suranjan Goswami,Abhinav Ravi,Raja Kolla,Ali Faraz,Shaharukh Khan,Akash,Chandra Khatri,Shubham Agarwal", "background": "尽管在文档理解方面取得了显著进展，但在现实世界设置中，确定扫描或拍摄的文档的正确方向仍然是一个关键的预处理步骤。准确的旋转校正是提高文档光学字符识别（OCR）等下游任务性能的关键，尤其是在用户错误，尤其是拍摄时相机的基础方向不正确导致的对齐问题时更是如此。", "innovation": "本研究首先引入了OCR-Rotation-Bench (ORB)，这是一个新的基准，用于评估OCR对图像旋转的鲁棒性，包括ORB-En和ORB-Indic两部分。此外，研究还提出了基于Phi-3.5-Vision模型视觉编码器的快速、鲁棒且轻量的旋转分类管道，该管道结合了动态图像裁剪，并专门针对四个分类任务进行了微调。该方法在两个数据集上的识别旋转的准确率分别达到了96%和92%。此外，研究还展示了该模块在提升OCR性能中的关键作用，不仅对封闭源模型提高了14%，对开放权重模型提高了4倍。", "conclusion": "通过研究，该方法在模拟的现实环境中证明了在四个类旋转任务上具有接近完美的分类性能，并展示了其在提高OCR性能方面的关键作用。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04190", "html_url": "https://arxiv.org/abs/2511.04190", "title": "协方差描述符遇上了通用视觉编码器：黎曼深度学习在医疗图像分类中的应用", "title_en": "Covariance Descriptors Meet General Vision Encoders: Riemannian Deep Learning for Medical Image Classification", "authors": "Josef Mayr,Anna Reithmeir,Maxime Di Folco,Julia A. Schnabel", "background": "协方差描述符能够捕获图像特征的二阶统计特性，在通用计算机视觉任务中表现优异，但在医疗成像领域中的应用尚未充分开发。为此，本文对协方差描述符在传统和基于学习的医疗图像分类中的效果进行了研究，特别是针对针对对称正定矩阵设计的SPDNet分类网络。研究使用了预先训练的一般视觉编码器（GVEs）提取的特征构建协方差描述符，并与手工设计的描述符进行了比较。在MedMNIST基准数据集的多种二分类和多分类数据集上评估了DINOv2和MedSAM两个编码器的表现。", "innovation": "提出了使用预先训练的一般视觉编码器（GVEs）提取的特征构建协方差描述符的方法，并将其与手工设计的描述符进行对比。研究发现，基于GVEs特征构建的协方差描述符在医疗图像分类中表现优于基于手工设计特征的方法。同时，使用DINOv2特征的SPDNet分类网络在性能上也优于现有最先进的方法。", "conclusion": "研究表明，结合协方差描述符与强大的预训练视觉编码器对于医疗图像分析具有巨大的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04084", "html_url": "https://arxiv.org/abs/2511.04084", "title": "当Swin Transformer遇到KANs：一种改进的用于医学图像分割的Transformer架构", "title_en": "When Swin Transformer Meets KANs: An Improved Transformer Architecture for Medical Image Segmentation", "authors": "Nishchal Sapkota,Haoyan Shi,Yejia Zhang,Xianshi Ma,Bofang Zheng,Danny Z. Chen", "background": "医疗图像分割对于准确诊断和治疗计划至关重要，但由于复杂的解剖结构和有限的标注训练数据仍然具有挑战性。尽管基于CNN的分割方法在局部特征提取方面表现出色，但它们在建模长距离依赖性方面存在问题，而Transformer则能更有效地捕捉全局上下文，但它们天生需要大量的数据，并且计算成本高昂。鉴于此，学者们在此工作中引入了UKAST架构，该架构基于Swin Transformer编码器，结合了基于柯尔莫哥洛夫-阿诺德网络（KANs）的U-Net结构。UKAST通过利用基于有理基函数和组有理KAN（GR-KANs）来改善基本样条线KAN的效率不足，从而生成了一个更强大表达并更节省数据的新框架，其运算量减少且参数计数只比SwinUNETR稍有增加。UKAST在四个不同领域的2D和3D医学图像分割基准测试中保持了最先进的性能，并且在数据稀缺的情况下，其准确度超过了基于CNN和Transformer的基本模型，减轻了标准Vision Transformer的数据需求不足的限制。这些结果展示了KAN增强的Transformer在推动物理医学图像分割中的潜力。", "innovation": "引入了UKAST架构，该架构将基于柯尔莫哥洛夫-阿诺德网络的有理函数集成到Swin Transformer编码器中，旨在克服基本样条线型KAN的不足，通过利用基于有理基函数和组有理KAN（GR-KANs）的架构，生成了一个更具有表现力且更节省数据的新框架，该框架在运算量减少的情况下，参数数量只有微小增加，与SwinUNETR相比性能显著提升。UKAST在多个医学图像分割基准测试中达到了最先进的性能，尤其是在数据稀缺的情况下，超越了基于CNN和Transformer的基本模型。", "conclusion": "UKAST架构通过引入基于KANs的改进Transformer，展示了其在数据有效医学图像分割中的潜力。这项工作证明了KANs增强的Transformer具备改善医学图像分割的性能，并通过所提供的代码实现了该架构的可复制性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04128", "html_url": "https://arxiv.org/abs/2511.04128", "title": "DMSORT: 一种高效的并行海上多目标跟踪架构用于无人水面舰艇平台", "title_en": "DMSORT: An efficient parallel maritime multi-object tracking architecture for unmanned vessel platforms", "authors": "Shengyu Tang,Zeyuan Lu,Jiazhi Dong,Changdong Yu,Xiaoyu Wang,Yaohui Lyu,Weihao Xia", "background": "准确感知海洋环境对于确保船舶航行安全和有效的海上监控至关重要。然而，复杂的海洋环境往往导致摄像机运动和随后的视觉退化，给多目标跟踪（MOT）带来重大挑战。现有的MOT方法在处理这种挑战时存在局限性，尤其是在应对平台运动和目标自身运动的识别和补偿上存在困难，这限制了其在海洋环境中的应用效果和效率。因此，提高MOT在海洋环境中运行的稳定性和准确性，尤其是在处理摄像机运动和目标识别方面的表现，成为亟待解决的问题。", "innovation": "本文提出了一种名为DMSORT的双分支海上多目标跟踪方法。DMSORT方法的核心是一个并行跟踪器，该跟踪器通过引入对象检测和重新识别（ReID）分支以及一个为动态摄像机运动估计设计的专用分支，克服了传统MOT方法在海洋环境下的不足。通过集成可逆列检测网络（RCDN）和轻量级变换器基础的外观抽取器（Li-TAE），解决了目标检测和外观特征提取的挑战，同时解决了平台运动补偿与目标内生运动的区分问题，从而修正了真实物体轨迹并提高了鲁棒性和一致性。此外，该方法还引入了一个聚类优化特征融合模块，结合了运动和外观提示，以确保在噪声、遮挡和漂移下的身份一致性。通过在新加坡海上数据集上的大量评估表明，DMSORT在速度、身份一致性和对抖动和遮挡的鲁棒性方面均达到了最先进的效果.", "conclusion": "DMSORT通过双分支并行架构，在解决海洋环境中摄像机运动和目标识别带来的挑战方面表现出色，实现了最快的运行时，并且保持了高身份一致性和对抖动和遮挡的鲁棒性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04137", "html_url": "https://arxiv.org/abs/2511.04137", "title": "在推理时从在线视频中学习以提高计算机使用代理", "title_en": "Learning from Online Videos at Inference Time for Computer-Use Agents", "authors": "Yujian Liu,Ze Wang,Hao Chen,Ximeng Sun,Xiaodong Yu,Jialian Wu,Jiang Liu,Emad Barsoum,Zicheng Liu,Shiyu Chang", "background": "计算机使用代理能够操作计算机并自动化劳动密集型任务，但它们在执行需要特定应用程序、平台和多步工作流程的专业知识的任务时，仍然落后于人类用户。人类可以通过观看视频教程来弥补这一差距：通过搜索、浏览和选择与当前子目标匹配的短片段。文章探讨了如何使计算机使用代理能够有效地在推理时从在线视频中学习。现有研究显示，尽管最近取得了快速进展，但计算机使用代理在需要特定知识的领域中仍然有局限性。人类可以填补这一空白，通过观看视频教程，帮助代理更好地执行任务，特别是在需要特定应用和平台知识的多步骤流程中。", "innovation": "本文提出了一个框架，该框架在推理时从在线视频中学习。该框架包括三个步骤：检索和过滤视频教程，将视频转换为结构化的演示轨迹，并在执行过程中动态选择轨迹作为上下文指导。使用视觉语言模型（VLM），可以推断出UI操作，将视频分割成一系列小的行动片段，并赋予每个片段一个文本目标。在推理过程中，采用两阶段选择机制，动态地选择单个轨迹添加到上下文中，使代理关注最有助于其下一决策的局部指导。实验结果表明，该框架在两个广泛使用的基准测试中优于强大的基础代理和其他仅使用文本教程或转录的变体。分析强调了轨迹分割和选择、行动过滤和视觉信息的重要性，表明大量的在线视频可以系统地提炼出具有实用指导的指令，以提高代理推理时的表现。", "conclusion": "实验结果证实了该框架的有效性，尤其是在处理需要特定应用和平台的专业知识的多步骤流程时。同时，分析研究证明了轨迹分割、行动过滤和视觉信息的重要作用，表明在线视频中的丰富信息可以系统地提炼出具有实际效用的指导信息，从而在推理时提高计算机使用代理的表现。该研究对于提升自动化代理在跨平台、跨应用程序任务上的表现具有重要意义。研究者发布的代码可以在指定的网址中找到。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04171", "html_url": "https://arxiv.org/abs/2511.04171", "title": "系统性评估用于数字病理准确图像配准的预处理技术", "title_en": "Systematic Evaluation of Preprocessing Techniques for Accurate Image Registration in Digital Pathology", "authors": "Fatemehzahra Darzi,Rodrigo Escobar Diaz Guerrero,Thomas Bocklitz", "background": "图像配准是将两个或多个图像通过映射到共同坐标系统的过程，以便匹配图像间相应的解剖或组织结构。在数字病理学中，图像配准使得来自不同染色或成像模态的信息可以直接对比与整合，支持如生物标志物分析和组织重建等应用。准确的模态间图像配准是数字病理学中的关键步骤。", "innovation": "该研究探索了各种颜色变换技术对H&E染色图像和非线性多模态图像配准的影响。研究使用了20对组织样本，每个样本对进行了多种预处理步骤，包括不同的颜色变换（CycleGAN、Macenko、Reinhard、Vahadane）、图像反转、对比度调整、强度归一化以及去噪。所有图像都使用了基于VALIS配准方法进行配准，该方法包括刚性配准和分步骤进行的非刚性配准，分别在低分辨率和高分辨率图像上进行。评估配准性能时，使用了相对目标配准误差（rTRE）作为指标，并报告了每种方法的中位数中位数rTRE（MMrTRE）和中位数rTRE的平均值（AMrTRE）。此外，通过自定义的基于点的方法针对十个手动选择的关键点进行了额外评估。", "conclusion": "该研究结果显示，应用颜色变换在配准前可以改善不同模态间图像的对齐，并为数字病理学中的更可靠分析提供支持。CycleGAN颜色变换方法获得了最低的配准误差，而其他方法则显示了更高的误差。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04260", "html_url": "https://arxiv.org/abs/2511.04260", "title": "Proto-LeakNet: 针对合成人体面部图像中的信号泄漏-aware 属性分析", "title_en": "Proto-LeakNet: Towards Signal-Leak Aware Attribution in Synthetic Human Face Imagery", "authors": "Claudio Giusti,Luca Guarnera,Sebastiano Battiato", "background": "合成图像和深度伪造生成模型的发展使得源识别和真实性验证成为现代计算机视觉系统的关键挑战。最近的研究表明，扩散管道在其输出中无意间留下持久的统计足迹，称为信号泄漏，特别是在潜空间中。鉴于此观察结果，本文提出了一种名为Proto-LeakNet的信号泄漏感知和可解释性归属框架，该框架结合了封闭集分类与基于密度的开放集评估，无需重新训练即可分析未知生成器。该方法在扩散模型的潜空间中运行，重新模拟部分前向扩散以揭示残留的特定生成器线索。", "innovation": "Proto-LeakNet通过在潜空间中建模信号泄漏偏差，实现了可靠且可解释的人工智能图像和深度伪造法医分析。该框架在仅使用封闭数据集的情况下训练，并实现98.13%的宏AUC，表现出对后处理的鲁棒性，超越了现有最佳方法，并在已知和未知生成器之间实现了强烈的可分离性。", "conclusion": "实验结果表明，建模潜空间中的信号泄漏偏差能够实现可靠且可解释的AI图像和深度伪造法医分析。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04192", "html_url": "https://arxiv.org/abs/2511.04192", "title": "AStF: 通过自适应统计融合器实现动作风格转移", "title_en": "AStF: Motion Style Transfer via Adaptive Statistics Fusor", "authors": "Hanmo Chen,Chenghao Xu,Jiexi Yan,Cheng Deng", "background": "传统的图像风格转换方法通常处理图像的均值和方差，这些方法已被证明是有效的。尽管也有一些建议将类似的方法应用于动作风格转移，但由于图像与动作之间的根本差异，依赖均值和方差不足以全面捕捉动作数据中的复杂动态模式和时空一致性特性。因此，本研究提出了一种自适应统计融合器（AStF），引入了偏度和峰度来分析动作风格，进一步优化动作风格转移的效果。", "innovation": "提出了一种名为自适应统计融合器（AStF）的新方法，它包括样式解析模块（SDM）和高阶多重统计注意力（HOS-Attn）。AStF在训练时结合了一个动作一致性正则化（MCR）判别器，以提高动作风格转移的效率。通过这种新颖的方法，研究能够在处理动态风格的时空统计模式方面提供更多全面的模型，从而优于当前最先进的模型，在动作风格转移上显示出卓越的性能。", "conclusion": "通过提供一种更全面的模型来捕捉动态风格中的时空统计模式，采用AStF方法，在动作风格转移任务中展示了优于现有最先进的技术的性能。本研究的代码和模型已开源。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04283", "html_url": "https://arxiv.org/abs/2511.04283", "title": "FastGS：在100秒内训练3D高斯采样", "title_en": "FastGS: Training 3D Gaussian Splatting in 100 Seconds", "authors": "Shiwei Ren,Tianci Wen,Yongchun Fang,Biao Lu", "background": "现有的3D高斯采样加速方法在训练过程中未能适当调节高斯的数量，导致不必要的计算时间开销。这限制了训练速度和渲染质量之间的平衡。", "innovation": "提出了FastGS，一个基于多视图一致性的新颖、简单且通用的加速框架，能够充分考虑每个高斯的重要性，有效地解决了训练时间和渲染质量之间的权衡。该方法创新地设计了基于多视图一致性密度增加和裁剪策略，去除了预算机制，实验结果表明，FastGS在Mip-NeRF 360和Tanks & Temples数据集上相对于最先进的方法显著提高了训练速度，而在Deep Blending数据集上的加速比达到15.45倍。FastGS展示了很强的通用性，在各种任务中实现了2-7倍的训练加速，包括动态场景重建、曲面重建、稀疏视图重建、大规模重建和同时定位与建图任务。", "conclusion": "FastGS是一个有效的3D高斯采样加速框架，在多个数据集中显著提高了训练速度，提高了渲染质量，具有良好的适用性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04255", "html_url": "https://arxiv.org/abs/2511.04255", "title": "MedSapiens: 通过姿态重新思考医学成像关键点检测", "title_en": "MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection", "authors": "Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li", "background": "该研究不引入新型架构，而是重新审视了一个关键但被忽视的基础模型：将人类中心的预训练模型应用于医学影像中的解剖学关键点检测。传统上，关键点检测依赖于领域特定模型，但大规模预训练视觉模型的出现给出了新机会。研究通过多数据集预训练以评估Sapiens（一种用于姿态估计的人类中心基础模型）在医学影像中的适应性，从而建立新的基准。提出的MedSapiens模型表明，人类中心的基础模型在空间姿态定位上有优化，为解剖学关键点检测提供了强有力的先验知识，但这种潜力尚未充分挖掘。MedSapiens在现有顶级模型的基准测试中表现出优势，平均成功检测率（SDR）提高了5.26%，对于专家模型提高了21.81%。此外，MedSapiens在有限标注数据集的表征能力中也表现出色，SDR提高了2.69%。 ", "innovation": "该研究重新审视并利用了人类中心的基础模型（如Sapiens）在医学影像解剖学关键点检测中的应用。通过多数据集预训练Sapiens，提出MedSapiens模型，强调了现有广泛研究领域模型之外的一种新的可能，即利用具有空间定位优势的人类中心模型在医学影像中的优越性。研究还展示了MedSapiens使用少量标注数据去适应新的下游任务的潜力，实现了与现有少量标注状态模型相比的显著改进。", "conclusion": "MedSapiens模型通过对多数据集的预训练展示了在医学影像解剖学关键点检测中的人类中心基础模型的优越性能，显著优于现有的通用模型和专家模型。此外，MedSapiens在使用少量标注数据适应新任务方面表现出色，取得了重要进展。该研究为医学影像中的解剖学关键点检测提供了一种新的基础模型应用思路。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04281", "html_url": "https://arxiv.org/abs/2511.04281", "title": "DINOv2驱动的视频基于可见红外行人重新识别的步态表示学习", "title_en": "DINOv2 Driven Gait Representation Learning for Video-Based Visible-Infrared Person Re-identification", "authors": "Yujie Yang,Shuang Li,Jun Ye,Neng Dong,Fan Li,Huafeng Li", "background": "现有的方法通常侧重于提取跨模态不变的视觉特征，但忽略了步态特征，步态特征既是跨模态不变的，也富含时间动态特性，这限制了它们建模跨模态视频匹配所需的空间时间一致性能力。通过解决这些挑战，论文提出了一种DINOv2驱动的步态表示学习（DinoGRL）框架，利用DINOv2丰富的视觉先验知识来学习与外观线索互补的步态特征，从而为跨模态检索提供稳健的序列级表示。", "innovation": "论文提出了一个叫DinoGRL的框架，其中包含一种语义意识轮廓和步态学习（SASGL）模型和一个逐步双向多粒度增强（PBMGE）模块。SASGL模型利用DINOv2的一般语义先验信息生成和增强轮廓表示，同时与ReID目标联合优化以实现语义增强和任务适应的步态特征学习。PBMGE模块逐步细化特征表示，通过步态和外观流在多个空间粒度上的双向交互，全面利用它们的互补性，丰富了全局表示的局部细节，生成了高度区分性的特征。", "conclusion": "在HITSZ-VCM和BUPT数据集上的大量实验表明，本文提出的方法显著优于现有的最先进的方法，展示了其在跨模态重新识别任务中的优越性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04288", "html_url": "https://arxiv.org/abs/2511.04288", "title": "农业中的视觉基础模型：向杂草除草剂试验评估的领域特定适应", "title_en": "Vision Foundation Models in Agriculture: Toward Domain-Specific Adaptation for Weed Herbicide Trials Assessment", "authors": "Leire Benito-Del-Valle,Artzai Picón,Daniel Mugica,Manuel Ramos,Eva Portillo,Javier Romero,Carlos Javier Jimenez,Ramón Navarra-Mestre", "background": "田间除草剂试验需要准确识别植物种类和评估除草剂引起的损害。尽管通用的视觉基础模型在复杂的视觉领域表现出色，但在农业中应用这些模型时，由于需要辨别不同的物种和损害类型，其性能可能受到限制。因此，该研究旨在使用一个通用的视觉基础模型来适应除草剂试验的特征。利用自监督学习方法对该模型进行了训练，使其可以在定制的农业数据集上学习到优化的特征表示，特别适用于田间试验图像的处理。", "innovation": "该研究将一个通用的视觉基础模型适应于除草剂试验特征识别和损害分类任务，通过自监督学习方法对模型进行了训练。结果显示，这种领域特定的模型在物种识别和损害分类方面的性能均显著优于通用的基础模型。特别是在新地点和时间条件下，以及无人机图像领域的领域迁移场景中，领域特定模型表现更优。此外，研究还发现，领域特定的预训练可以提高分割准确性，特别是在标注样本较少的情况下，领域特定模型使用更少的标注样本即可实现更高的性能。", "conclusion": "研究结果证明了领域特定基础模型的应用潜力，表明这类模型具有良好的泛化能力，并能显著减少手动标注的需求。这为除草剂试验分析提供了一个可扩展且自动化的解决方案。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04344", "html_url": "https://arxiv.org/abs/2511.04344", "title": "VOC 2008数据集中马和摩托车二分类的CNN架构对比研究", "title_en": "Comparative Study of CNN Architectures for Binary Classification of Horses and Motorcycles in the VOC 2008 Dataset", "authors": "Muhammad Annas Shaikh,Hamza Zaman,Arbaz Asif", "background": "文章对VOC 2008数据集中马和摩托车的二分类任务进行了全面的评估，研究了九种卷积神经网络架构。针对数据中存在的类别不平衡问题，作者采用了少数类别增强技术。实验涉及了包括ResNet-50、ConvNeXt-Tiny、DenseNet-121和Vision Transformer在内的现代架构，从多个性能指标进行比较。研究表明，不同架构在检测性能上存在显著差异，特别地，ConvNeXt-Tiny在马和摩托车检测中取得了最高的平均精度。同时，数据增强显著提高了少数类别的检测性能，特别是在较深的架构中表现更为明显。", "innovation": "文章通过最小化类别不平衡问题，引入了少数类别增强技术，并对多个现代卷积神经网络架构进行了广泛的研究和比较。研究证实了数据增强策略在缓解类别不平衡问题中的重要作用，特别是在对象检测任务中。", "conclusion": "该研究为不平衡二分类任务下的架构选择提供了见解，并定量地衡量了数据增强策略在减少类别不平衡影响中的效果。实验结果表明，ConvNeXt-Tiny架构在马和摩托车的二分类检测任务中表现最佳。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04317", "html_url": "https://arxiv.org/abs/2511.04317", "title": "RISE-T2V：使用LLM进行扩展现有的文本到视频生成的重写和注入语义", "title_en": "RISE-T2V: Rephrasing and Injecting Semantics with LLM for Expansive Text-to-Video Generation", "authors": "Xiangjun Zhang,Litong Gong,Yinglin Zheng,Yansong Liu,Wentao Jiang,Mingyi Xu,Biao Wang,Tiezheng Ge,Ming Zeng", "background": "大多数文本到视频(T2V)扩散模型依赖预训练的文本编码器进行语义对齐，但当提供简洁的提示而非精心设计的提示时，这些问题通常会导致视频质量下降。主要原因在于它们对文本语义的有限理解。此外，这些文本编码器无法在线重新表达提示，以更好地与用户意图对齐，这限制了模型的可扩展性和易用性。", "innovation": "RISE-T2V通过将提示重写和语义特征提取整合为一个无缝步骤，而不是两个独立步骤来解决这些挑战。RISE-T2V是一个通用框架，可以应用于各种预训练LLM和视频扩散模型(VDMs)，显著增强了它们的T2V任务能力。作者提出了一种名为重写适配器的新模块，该模块使扩散模型能够利用LLM中的文本隐状态，在视频生成过程中作为视频生成的条件。通过使用重写适配器，视频生成模型可以隐式地将基本提示重写为更全面的表示，更好地匹配用户的意图。此外，利用LLM的强大功能，视频生成模型可以实现更广泛的T2V任务。", "conclusion": "大量实验表明，RISE-T2V是一个通用框架，适用于不同的视频扩散模型架构，显著增强了T2V模型生成高质量视频以匹配用户意图的能力。详细视觉结果可以在网页上找到：this https URL."}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04334", "html_url": "https://arxiv.org/abs/2511.04334", "title": "子流形稀疏卷积网络在计算机断层扫描中自动3D分割肾脏和肾肿瘤", "title_en": "Submanifold Sparse Convolutional Networks for Automated 3D Segmentation of Kidneys and Kidney Tumours in Computed Tomography", "authors": "Saúl Alonso-Monsalve,Leigh H. Whitehead,Adam Aurisano,Lorena Escudero Sanchez", "background": "在放射影像学如计算机断层扫描中，肿瘤的精确界定是一项专业且耗时的任务，目前是临床常规进行定量分析的瓶颈。因此，开发用于医学影像中肿瘤自动分割的方法变得至关重要，近年来产生了显著的努力。然而，由于传统卷积神经网络需要大量像素点分析，3D扫描的实际应用通常需要降采样或使用局部图像，这给高分辨率输入和原生3D模型结构的分割造成了挑战。", "innovation": "本文提出了一种新的方法，将其分为两个阶段：体素稀疏化和子流形稀疏卷积网络，这种方法允许高分辨率输入和3D模型架构进行分割，同时显著减少了所需的GPU内存和时间计算资源，取得了目前最佳的准确性，并且在推断时间和VRAM使用率上分别实现了高达60%和75%的改进。", "conclusion": "在KiTS23挑战中，以计算机断层扫描肾癌患者的图像为研究背景，验证了该方法的有效性。其分割结果在肾+肿块（95.8%）、肿瘤+囊肿（85.7%）和单独的肿瘤（80.3%）上与挑战冠军相匹配，同时在推理时间和VRAM占用率上实现了显著改善，分别降低了60%和75%。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04304", "html_url": "https://arxiv.org/abs/2511.04304", "title": "基于Sentinel-1影像的深学习远海平台目标检测及模拟训练数据的影响", "title_en": "Deep learning-based object detection of offshore platforms on Sentinel-1 Imagery and the impact of synthetic training data", "authors": "Robin Spanier,Thorsten Hoeser,Claudia Kuenzer", "background": "近年来海洋基础设施的扩展，包括海上风电场、石油和天然气平台、人工岛和水产养殖设施等，凸显了有效监测系统的需求。现有的离岸基础设施检测模型依赖于全面且平衡的数据集，但当样本稀缺时，特别是在代表性不足的对象类别、形状和尺寸上，这些模型的效果就会大打折扣。为了克服这些挑战，本研究利用2023年第4季度四个区域（卡斯佩尔海、南中国海、几内亚湾和巴西海岸）收集的真实Sentinel-1卫星影像以及合成数据训练YOLOv10目标检测模型，以评估模拟训练数据对模型性能的提升作用。研究通过将模型应用于三个未见过的地区（墨西哥湾、北海、波斯湾）检测远海平台，验证了该策略的地理转移能力。在总共检测到的3,529个远海平台中，包括北海1,519个、墨西哥湾1,593个、波斯湾411个。该模型的F1分数为0.85，引入合成数据后提高到0.90。研究分析了合成数据在平衡数据集和提升整体模型性能方面的增强作用，为全球离岸基础设施监测提供了一步可扩展的解决方案。", "innovation": "本研究创新性地结合了真实和合成Sentinel-1卫星影像数据，训练了高效的YOLOv10目标检测模型，以提高模型在检测代表性不足的海洋基础设施方面的性能。通过地区留出法评估，该模型展示了良好的地理转移能力。此外，研究还分析了如何通过引入合成数据来增强不平衡数据集的表示，并提升了整体模型性能。", "conclusion": "本研究强调了平衡数据集的重要性，并指出了生成模拟数据作为解决遥感领域普遍问题的有效策略。研究证明了深度学习在实现全球离岸基础设施大规模监测中的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04349", "html_url": "https://arxiv.org/abs/2511.04349", "title": "A MATLAB tutorial on deep feature extraction combined with chemometrics for analytical applications", "title_en": "A MATLAB tutorial on deep feature extraction combined with chemometrics for analytical applications", "authors": "Puneet Mishra,Martijntje Vollebregt,Yizhou Ma,Maria Font-i-Furnols", "background": "在分析化学中，空间信息通常通过成像技术，如传统色相机或高级的超光谱相机和显微镜来捕获。然而，利用传统化学计量学方法有效地提取和分析这种空间信息以进行探索性和预测性研究仍然是一个挑战。近年来，深度学习和人工智能的进展极大地提高了图像处理能力，使其能够提取出即使用传统的图像处理技术也难以捕捉的多尺度深层特征。尽管有大量开源的深度学习模型可供使用，但由于缺乏结构化指导，分析化学中对其进行应用仍有限制。", "innovation": "本教程旨在通过提供一个逐步指南，将深度学习方法应用于从成像数据中提取空间信息，并将其与其他数据源（如光谱信息）集成，从而填补这一空白。本工作中不在于训练用于图像处理的深度学习模型，而在于使用现有的开源模型从成像数据中提取深层特征。本教程还提供了MATLAB代码示例，展示了如何处理多种常规用于分析化学的成像模态的数据，用户需使用本教程中提供的代码在自己的数据集上运行这些步骤。", "conclusion": "本教程通过提供从成像数据中提取深层特征的步骤指南，结合化学计量学方法，旨在促进深度学习在分析化学中的应用。通过一系列具体的MATLAB代码演示，读者可以更好地理解和应用这些方法进行分析化学中的数据处理。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04347", "html_url": "https://arxiv.org/abs/2511.04347", "title": "分析由天气引起的传感器遮挡对BEVFusion在3D物体检测中的影响", "title_en": "Evaluating the Impact of Weather-Induced Sensor Occlusion on BEVFusion for 3D Object Detection", "authors": "Sanjay Kumar,Tim Brophy,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising", "background": "自动驾驶车辆在复杂的真实环境中安全导航需要精确的3D物体检测。鸟瞰图（BEV）表示法通过将多传感器数据投影到顶部的二维空间格式中，已成为稳健感知的有效方法。尽管基于BEV的融合架构通过多模态整合展示了强大的性能，但由环境条件如雾、霾或物理障碍物引起的传感器遮挡对3D检测准确性的影响尚未深入研究。本文通过使用BEVFusion架构在nuScenes数据集上评估，探讨了传感器遮挡对摄像头和光检测和测距（LiDAR）输出的影响。", "innovation": "本文首次详细研究了天气导致的传感器遮挡对基于BEV的3D物体检测系统的影响，并通过严格的数据集评估，展示了在不同遮挡条件下摄像头和LiDAR性能的不同表现。特别是在融合设置中，遮挡对性能影响的焦点转移也揭示了模型对LiDAR的依赖更强。这为未来研究遮挡感知评估方法和改进传感器融合技术提供了依据，以便在传感器部分失效或恶劣环境条件导致退化的情况下保持检测准确性。", "conclusion": "检测性能通过均值平均精度（mAP）和nuScenes检测分数（NDS）进行衡量。实验结果显示，中度摄像头遮挡会导致mAP下降41.3%（从35.6%降至20.9%），而LiDAR只有在严重遮挡下才会显著下降，mAP下降47.3%（从64.7%降至34.1%），并且其对长期检测的影响尤为严重。在融合设置中，遮挡对性能的影响取决于是哪个传感器被遮挡：遮挡摄像头导致轻微下降4.1%（从68.5%降至65.7%），而遮挡LiDAR则导致显著下降26.8%（降至50.1%）。这些结果突显了未来需要探索的遮挡感知评价方法和改进的传感器融合技术的重要性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04384", "html_url": "https://arxiv.org/abs/2511.04384", "title": "多任务学习在消化系统VQA中的视觉定位推理", "title_en": "Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal VQA", "authors": "Itbaan Safwan,Muhammad Annas Shaikh,Muhammad Haaris,Ramail Khan,Muhammad Atif Tahir", "background": "本文介绍了针对MediaEval Medico 2025挑战的一种多任务框架，使用LoRA调整过的Florence-2模型同时进行视觉问答（VQA）、解释生成和视觉定位。该系统整合了三个精心策划的数据集：（1）Kvasir-VQA-x1用于问答学习，（2）一个合成增强的解释数据集提供结构化的医学推理，（3）链接文本到区域对，将视觉特征与分割掩码关联起来。多任务设置使得模型能够共同学习视觉定位、推理和解释，生成准确且可解释的响应。广泛的评估表明，我们的方法在答案准确性和视觉定位方面显著优于单任务基线，突显了基于视觉定位的多任务学习在医学VQA应用中的有效性。", "innovation": "使用LoRA调整过的Florence-2模型在多任务框架下进行视觉问答、解释生成和视觉定位；整合了三个精心策划的数据集，并且多任务设置使得模型能够共同学习视觉定位、推理和解释，从而生成准确且可解释的响应。", "conclusion": "我们的方法在答案准确性和视觉定位方面显著优于单任务基线，突显了基于视觉定位的多任务学习在医学VQA应用中的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04388", "html_url": "https://arxiv.org/abs/2511.04388", "title": "BoRe-Depth：嵌入式系统中带有边界精修的半监督单目深度估计", "title_en": "BoRe-Depth: Self-supervised Monocular Depth Estimation with Boundary Refinement for Embedded Systems", "authors": "Chang Liu,Juan Li,Sheng Zhang,Chang Liu,Jie Li,Xu Zhang", "background": "单目深度估计是实现无人驾驶系统三维感知的关键技术之一。由于其成本低的优势，单目深度估计受到了广泛研究，但在嵌入式系统上的深度估计性能差以及目标边界模糊是现有方法面临的挑战。本文旨在提出一种新型的轻量级单目深度估计模型BoRe-Depth，该模型仅包含8.7M参数，能够准确地在嵌入式系统上估计深度图并显著提高边界质量。", "innovation": "本文提出了一个称为BoRe-Depth的新颖单目深度估计模型，该模型包含的一项创新是设计了一种增强特征自适应融合模块(EFAF)，可以自适应地融合深度特征以增强边界细节表示；此外，还将语义知识集成到编解码器中以提高对象识别和边界感知能力；最后，该模型在NVIDIA Jetson Orin上运行效率为50.7 FPS，被证实显著优于之前的轻量级模型在多个具有挑战性的数据集上表现优异。并在文中提供了详细的方法消融研究。", "conclusion": "该研究提出的BoRe-Depth模型在嵌入式系统上的单目深度估计性能显著优于现有轻量级模型。该模型通过设计增强特征自适应融合模块和在编码器中整合语义知识，增强了边界细节表示和对象识别能力，实现了优异的深度估计效果并支持实时运行。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04394", "html_url": "https://arxiv.org/abs/2511.04394", "title": "DORAEMON：大规模视觉目标建模和表示学习的统一库", "title_en": "DORAEMON: A Unified Library for Visual Object Modeling and Representation Learning at Scale", "authors": "Ke Du,Yimin Peng,Chao Gao,Fan Zhou,Siqiao Xue", "background": "当前，视觉对象建模和表示学习在不同尺度上面临着多样化的需求，不同的任务如分类、检索和度量学习需要各自独立的工具和流程，这导致了研究效率和可扩展性的限制。目前的解决方案往往缺乏统一性，导致无法方便地进行大规模的实验和应用开发，特别是在转换模型研究成果为实际应用时遇到困难。DORAEMON旨在解决这些挑战，提供一个开源的PyTorch库，统一多种视觉对象建模和表示学习任务，提升研究的效率。", "innovation": "DORAEMON通过单一的YAML驱动流程统一了视觉对象建模和表示学习任务，包括分类、检索和度量学习。它提供了超过1000个预训练的网络骨架，通过与timm兼容的接口暴露，结合了模块化的损失函数、增强技术和分布式训练工具，实现了易于理解和使用。研究还展示了DORAEMON的再现性食谱在ImageNet-1K、MS-Celeb-1M和斯坦福在线产品上的结果可以与参考结果相媲美，且其可以通过单命令导出到ONNX或HuggingFace，简化了从研究到部署的过程，提升了效率。", "conclusion": "DORAEMON通过整合数据集、模型和训练技术到一个平台上，提供了一个可扩展的基础架构，用于快速实验视觉识别和表示学习。它为实验高效地将研究进展转化为实际应用提供了便捷的途径。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04450", "html_url": "https://arxiv.org/abs/2511.04450", "title": "解决凸分区视觉拼图", "title_en": "Solving Convex Partition Visual Jigsaw Puzzles", "authors": "Yaniv Ohayon,Ofir Itzhak Shahar,Ohad Ben-Shahar", "background": "拼图解谜需要将无序的拼图块重新排列成原貌，以便重建连贯的整体，通常是一幅图像。这一问题被认为是非常难以解决的。尽管自动拼图解谜器可能在多个应用领域产生重大影响，但大多数研究集中在解无序正方形拼图上。这种限制极大地限制了这些解谜器的实际应用范围。", "innovation": "该研究显著扩展了计算机处理的拼图类型，集中在所谓的凸分区上，这是多边形拼图的一个重要子集，其拼图块为凸形。研究利用了几何兼容性和视觉兼容性，提出了一个贪婪求解器，并发布了该类型的首个基准数据集，以评估性能", "conclusion": "本次研究提出了针对凸分区视觉拼图的解决方法，通过利用几何和视觉兼容性，提出了一种贪婪求解器，并通过首个基准数据集对算法性能进行了评估，扩展了传统拼图的范围，帮助更广泛的多边形拼图问题的解决。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04460", "html_url": "https://arxiv.org/abs/2511.04460", "title": "V-Thinker: 图像交互思考", "title_en": "V-Thinker: Interactive Thinking with Images", "authors": "Runqi Qiao,Qiuna Tan,Minghan Yang,Guanting Dong,Peiqing Yang,Shiqiang Lang,Enhui Wan,Xiaowan Wang,Yida Xu,Lan Yang,Chong Sun,Chen Li,Honggang Zhang", "background": "在该领域，使大型多模态模型（LMMs）深入整合图像交互与长远推理能力仍然是一个长期挑战。尽管最近在以视觉为中心的推理方面取得了进展，探索了‘以图像思考’的范式，这标志着从图像辅助推理向图像交互推理的转变，但仍受限于有限的视觉工具空间和特定任务的工作流设计。", "innovation": "V-Thinker 是一个通用多模态推理助手，通过端到端的强化学习实现交互的视觉中心思考。V-Thinker 包含两个关键组件：(1) 数据进化飞轮，自动合成、进化和验证覆盖三个维度的交互推理数据集（多样、质量、难度）；(2) 视觉渐进式训练课程，该课程通过点级监督对感知进行对齐，然后通过两阶段的强化学习框架整合交互推理。", "conclusion": "广泛的实验表明，V-Thinker 在通用和交互推理场景中均能稳健超越强基线的 LMM，在图像交互推理应用方面提供了有价值的见解。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04474", "html_url": "https://arxiv.org/abs/2511.04474", "title": "使用地理空间基础模型进行滑坡灾害制图：地理普适性、数据稀缺性和波段适应性", "title_en": "Landslide Hazard Mapping with Geospatial Foundation Models: Geographical Generalizability, Data Scarcity, and Band Adaptability", "authors": "Wenwen Li,Sizhe Wang,Hyunho Lee,Chenyan Lu,Sujit Roy,Rahul Ramachandran,Chia-Yu Hsu", "background": "滑坡对生命、基础设施和环境造成严重破坏，因此准确及时的滑坡动态图对于灾害预防和响应至关重要。然而，传统的深度学习模型在不同的传感器、区域或有限的训练数据条件下应用时存在困难。", "innovation": "提出了一种基于传感器、标签和领域三个维度的分析框架，用于适应地理空间基础模型（GeoFMs），以突出Prithvi-EO-2.0的基础模型在滑坡制图中的优势。该模型通过全球预训练、自我监督和可调适的微调，证明了对光谱变化的鲁棒性，即使在标签稀缺的情况下也能保持准确性，并且在多种数据集和地理环境中具有更好的泛化能力。同时，也指出了挑战，如计算成本和可用于滑坡研究的重用AI预备训练数据的有限性。", "conclusion": "我们的研究促使GeoFMs成为滑坡风险减缓和环境监测的更稳健和可扩展方法的一个重要步骤。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04426", "html_url": "https://arxiv.org/abs/2511.04426", "title": "HideAndSeg：一种用于自然栖息地中八爪鱼分割的基于自动提示的AI工具", "title_en": "HideAndSeg: an AI-based tool with automated prompting for octopus segmentation in natural habitats", "authors": "Alan de Aguiar,Michaella Pereira Andrade,Charles Morphy D. Santos,João Paulo Gois", "background": "在自然栖息地中对八爪鱼进行分析具有挑战性，因为它们具有伪装能力、皮肤纹理和颜色的变化速度快、非刚性身体变形以及频繁的遮挡现象。此外，水下光照条件和浑浊度的变化进一步增加了难度。缺乏大规模标注的数据集，使得相关研究面临更多挑战。本文介绍了HideAndSeg，这是一种新的、仅需少量监督的基于AI的工具，用于分割八爪鱼视频。该工具通过结合SAM和自训练的YOLOv11对象检测器，实现了自动化分割流程，并引入了两个新的无监督度量标准来评估分割质量，从而填补了这一研究领域的空白。", "innovation": "引入了HideAndSeg工具，该工具采用少量监督的AI方法，结合SAM和自训练的YOLOv11对象检测器，实现了八爪鱼视频分割的自动化。 HideAndSeg还引入了两个无监督度量标准——时间一致性DICE_t和新的组件数量NC_t，用于在没有真实数据的情况下评估分割质量。该方法能够处理完全遮挡的场景，而传统方法在这样的场景中效果不佳。此外，该工具还减少了解析现实世界数据时的主观性，提供了更为高效的研究工具。", "conclusion": "HideAndSeg方法显著提高了八爪鱼分割的准确性，并在自然环境中实现了更为可靠的分割效果。该工作为野生头足动物行为研究开辟了新的途径，简化了实际场景中的手动分析需求。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04520", "html_url": "https://arxiv.org/abs/2511.04520", "title": "THEval. 说话头视频生成的评估框架", "title_en": "THEval. Evaluation Framework for Talking Head Video Generation", "authors": "Nabyl Quignon,Baptiste Chopin,Yaohui Wang,Antitza Dantcheva", "background": "视频生成取得了显著的进步，生成的视频越来越接近真实视频。然而，生成技术的发展速度超过了评估指标的发展速度。目前，说话头生成的评估主要依赖于有限的评价指标，包括视频质量、唇同步，以及用户研究等。", "innovation": "本文提出了一个新的评估框架，包含8个与三个维度（i）质量 (ii) 天然性 (iii) 同步性相关的评价指标，并且特别关注效率以及与人类偏好的一致性。通过分析头部、嘴唇和眉毛等细节以及面部质量的细微动态，该框架能够全面评估生成模型的表现，特别是表达能力和无瑕疵的细节生成能力。", "conclusion": "本文通过大规模的实验（85,000条由17个先进模型生成的视频），证明了虽然许多算法在唇同步方面表现出色，但在表情生成和无瑕疵细节方面仍然存在挑战。该评估框架旨在评估生成方法的改进，并计划公开发布原始代码、数据集和排行榜，使其具有可比性和时效性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04525", "html_url": "https://arxiv.org/abs/2511.04525", "title": "从单一时间点学习：胰腺胆囊切除术的复杂性评估", "title_en": "Learning from Single Timestamps: Complexity Estimation in Laparoscopic Cholecystectomy", "authors": "Dimitrios Anastasiou,Santiago Barbarisi,Lucy Culshaw,Jayna Patel,Evangelos B. Mazomenos,Imanol Luengo,Danail Stoyanov", "background": "胰腺胆囊切除术（LC）中，严重的炎症与较长的手术时间和增加的并发症风险相关。Parkland分级量表（PGS）提供了一种临床验证的框架来分级炎症的严重程度，但在完全视频的自动化分析方面，尤其是在无需手动编辑的情况下分析完整的视频方面，其应用仍然有限。大多数现有方法仅限于静态图像或手动剪辑的片段，无法直接处理完整的视频。因此，如何利用完整的视频数据实现自动化的PGS评估成为了一个重要的研究问题。", "innovation": "本文提出了一种名为STC-Net的新颖框架，旨在单时间戳下通过PGS进行LC手术复杂度的评估。STC-Net能够在弱时间监督的情况下直接处理完整视频，通过定位和窗口提议以及评分模块联合进行时间定位和评分。此外，论文提出了一种结合硬性定位目标和软性定位目标的新颖损失函数，以及背景意识的评分监督。这种方法突破了现有方法的限制，直接应用于完整的视频数据，有效地提高了手术复杂度评估的准确性。", "conclusion": "STC-Net为通过完整的LC视频进行自动化的PGS评分提供了一个可扩展且有效的方法，为术后的分析和手术培训带来了希望。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04570", "html_url": "https://arxiv.org/abs/2511.04570", "title": "Thinking with Video: 视频生成作为一种有希望的多模态推理范式", "title_en": "Thinking with Video: Video Generation as a Promising Multimodal Reasoning Paradigm", "authors": "Jingqi Tong,Yurong Mou,Hangcheng Li,Mingzhe Li,Yongzhuo Yang,Ming Zhang,Qiguang Chen,Tianyi Liang,Xiaomeng Hu,Yining Zheng,Xinchi Chen,Jun Zhao,Xuanjing Huang,Xipeng Qiu", "background": "目前，采用‘通过文本思考’和‘通过图像思考’范式可以在很大程度上提高大型语言模型（LLMs）和视觉语言模型（VLMs）的推理能力。然而，这些范式本身存在缺陷：（1）图像仅捕捉单一时刻，无法表现动态过程或连续变化，（2）视觉和文本作为不同的模态各自独立，阻碍了统一的多模态理解和生成。", "innovation": "本文引入了‘通过视频思考’的新范式，利用视频生成模型（如Sora-2）在统一的时间框架内结合视觉和文本的推理。开发了Video Thinking Benchmark（视频思考基准）来支持这一研究，该基准包括视觉中心任务（如眼动拼图）和文本中心任务（如GSM8K和MMMU的子集）。评估结果显示Sora-2在视觉中心任务上表现与当前最先进的VLMs相当，在某些任务上表现甚至更佳。在文本中心任务上，Sora-2在MATH上达到了92%的准确率，MMMU上达到了75.53%的准确率。此外，我们系统地分析了这些能力的来源，并发现自我一致性与基于上下文的学习可以提高Sora-2的性能。", "conclusion": "我们的研究证明视频生成模型可能是统一的多模态理解和生成模型，将‘通过视频思考’定位为统一的多模态推理范式。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04628", "html_url": "https://arxiv.org/abs/2511.04628", "title": "NovisVQ：一种用于无参考意见无关帧质量评估的流式卷积神经网络", "title_en": "NovisVQ: A Streaming Convolutional Neural Network for No-Reference Opinion-Unaware Frame Quality Assessment", "authors": "Kylie Cancilla,Alexander Moore,Amar Saini,Carmen Carrano", "background": "视频质量评估(VQA)对于计算机视觉任务至关重要，但现有方法面临重大限制：全参考(FR)度量需要干净的参考视频，而大多数无参考(NR)模型依赖于昂贵的人工意见标签的训练。此外，大多数无意见感知的NR方法是基于图像的，忽略了对视频对象检测至关重要的时间上下文。", "innovation": "本文提出了一种可扩展的基于流的数据VQA模型，该模型既是无参考的，又是无意见的。该模型利用DAVIS数据集的合成降解，训练一个时间意识的卷积结构，直接从降解视频中预测FR度量(LPIPS, PSNR, SSIM)，在推理时不使用参考。结果显示，作者的流式方法在各类降解中的泛化能力强于作者自己的基于图像的基线方法，凸显了时间建模在实际视觉系统中对可扩展VQA的价值。此外，作者展示了其模型与广泛使用的基于意见的图像质量评估基线BRISQUE相比，具有更高的相关性，验证了其基于时间、无意见的方法的有效性。", "conclusion": "该模型能够在不直接使用参考视频的情况下，通过利用DAVIS数据集的合成降解，训练一个时间感知的卷积架构来直接预测FR度量，展示了其在视频质量评估中的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04601", "html_url": "https://arxiv.org/abs/2511.04601", "title": "PixCLIP：通过任意粒度的像素-文本对齐学习实现精细的视觉语言理解", "title_en": "PixCLIP: Achieving Fine-grained Visual Language Understanding via Any-granularity Pixel-Text Alignment Learning", "authors": "Yicheng Xiao,Yu Chen,Haoxuan Ma,Jiale Hong,Caorui Li,Lingxiang Wu,Haiyun Guo,Jinqiao Wang", "background": "尽管Contrastive Language-Image Pretraining (CLIP) 模型在多种视觉语言理解任务中取得了显著成就，但增强其细粒度的图像-文本对齐能力仍然是一个重要研究方向。现有工作通常通过引入视觉提示来增加视觉信息处理的粒度，而Multimodal Large Language Models (MLLMs)的研究表明，使用详细的文本描述可以有效提高模型的细粒度视觉-语言对齐能力。然而，CLIP文本编码器的固有限制（token长度）限制了它处理长文本中嵌入的细微信息的能力。因此，需要一种框架来同时提高视觉和文本内容的处理粒度，以充分利用视觉提示和长文本描述的优势。", "innovation": "本文提出了PixCLIP，一种新型框架，旨在同时容纳视觉提示输入并处理长文本描述。具体来说，作者首先建立了一个自动注释管道，生成像素级别的局部化、长形式的文本描述。利用这个管道，构建了包含近150万样本的高质量数据集LongGRIT。然后，将CLIP的原始文本编码器替换为LLM，并提出了一种三支像素-文本对齐学习框架，以实现图像区域和相应文本描述之间的任意粒度对齐。实验表明，PixCLIP在像素级交互和处理长文本方面取得了突破，实现了最先进的性能。", "conclusion": "PixCLIP在细粒度视觉语言理解领域取得了显著成就，通过任意粒度的像素-文本对齐学习，展示了在像素级交互和处理长文本方面的突破性性能，达成了最优效果。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04652", "html_url": "https://arxiv.org/abs/2511.04652", "title": "偏振分辨成像提高眼动追踪", "title_en": "Polarization-resolved imaging improves eye tracking", "authors": "Mantas Žurauskas,Tom Bu,Sanaz Alali,Beyza Kalkanli,Derek Shi,Fernando Alamos,Gauresh Pandit,Christopher Mei,Ali Behrooz,Ramin Mirjalili,Dave Stronks,Alexander Fix,Dmitri Model", "background": "偏振分辨近红外成像能够通过测量光投射在眼部组织上的偏振状态，补充现有的眼动追踪方法，提供额外的光学对比度。在该研究中，研究者展示了如何利用这种新的偏振对比度进行眼动追踪。研究结果表明，基于偏振的系统能够揭示强度图像中丢失的可追踪特征以及眼动相关的角膜模式，提升了眼动追踪的准确性并在多种复杂条件下表现出色。", "innovation": "该研究创新地提出了一种基于偏振的双眼追踪解决方案，它结合了线性偏振近红外照明器和具有偏振滤镜阵列的相机。研究展示了这种系统如何通过增加对眼部结构的详细信息，即使在没有直接可见特征如巩膜、眼睑遮挡、瞳孔变化和视线偏离的大情况下，依然保持低误差的眼动追踪性能。", "conclusion": "该研究结果连结了光-组织偏振效应与实际的人机交互改进，并表明偏振启用眼动追踪（PET）系统是一种简单可靠的传感模式，适合未来可穿戴设备使用。通过深度神经网络训练的机器学习模型，在各种条件下，相比传统的基于强度的眼动追踪算法，使用PET系统减少了最大偏差误差的10-16%。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04668", "html_url": "https://arxiv.org/abs/2511.04668", "title": "SIMS-V：模拟指令调优在空间视频理解中的应用", "title_en": "SIMS-V: Simulated Instruction-Tuning for Spatial Video Understanding", "authors": "Ellis Brown,Arijit Ray,Ranjay Krishna,Ross Girshick,Rob Fergus,Saining Xie", "background": "尽管多模态语言模型在高层次视频理解方面表现出色，但在跨时间和空间的地理推理方面仍面临挑战。当前的地理训练方法依赖于现实世界视频数据，但获取带精确定位注释的多样视频仍然是一大瓶颈。", "innovation": "本文提出了一种SIMS-V框架，利用3D模拟器的特权信息来创建多模态语言模型的时空丰富的视频训练数据。通过系统性的消融实验，揭示了哪些模拟数据的特性最能有效促进对现实世界的空间智能的转移。", "conclusion": "本文确定了三种关键问题类别（度量测量、视点依赖性推理和时间追溯）对于培养可转移的空间智能至关重要。使用仅25K的模拟样本对一个7B参数视频语言模型进行微调，该模型不仅在大型72B模型上表现出色，而且在严格的现实世界空间推理基准测试中达到了与专有的模型相当的性能。此外，这种方法展示了强大的泛化能力，不仅在一般视频理解方面保持性能，同时在具身和真实世界的空间任务上也有所提升。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04670", "html_url": "https://arxiv.org/abs/2511.04670", "title": "Cambrian-S:向视频中的空间超感知迈进", "title_en": "Cambrian-S: Towards Spatial Supersensing in Video", "authors": "Shusheng Yang,Jihan Yang,Pinzhi Huang,Ellis Brown,Zihao Yang,Yue Yu,Shengbang Tong,Zihan Zheng,Yifan Xu,Muhan Wang,Daohan Lu,Rob Fergus,Yann LeCun,Li Fei-Fei,Saining Xie", "background": "当前的研究主要集中在回应性、任务驱动的系统以及通过大量上下文来解决复杂问题的方法上，这限制了真正的多模态智能的进步。这些方法在处理需要宽视野和长时间的空间感知任务时能力有限，现有的基准测试也主要评估早期阶段的表现，缺乏对真正世界建模能力的挑战。", "innovation": "本文提出了VSI-SUPER，这是一个两部分基准测试：长视角视觉空间回忆(VSR)和持续视觉空间计数(VSC)。这些任务设计了对无穷长视频输入的处理能力，并且难以通过粗暴的上下文扩展方法解决。通过数据扩展研究边界，通过构建VSI-590K和训练Cambrian-S模型，在VSI-Bench上实现了30%的绝对改进，同时保持了广泛的适用性。然而，VSI-SUPER的表现仍然有限，这表明光靠规模扩展不足以解决空间超感知的问题。提出了预测感官的概念，作为前进的方向，展示了一种自监督的下一个潜帧预测器的概念，通过利用预测误差来驱动记忆和事件分割，该方法在VSI-SUPER上显著优于最先进的基线。", "conclusion": "研究提出，仅仅依靠大规模训练是不够的，空间超感知需要能够不仅感知，还要预知、挑选和组织经验的模型。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04675", "html_url": "https://arxiv.org/abs/2511.04675", "title": "InfinityStar：统一时空自回归建模在视觉生成中的应用", "title_en": "InfinityStar: Unified Spacetime AutoRegressive Modeling for Visual Generation", "authors": "Jinlai Liu,Jian Han,Bin Yan,Hui Wu,Fengda Zhu,Xing Wang,Yi Jiang,Bingyue Peng,Zehuan Yuan", "background": "在视觉和语言领域，自回归建模最近取得了显著成功。现有的方法通常无法同时有效地捕捉空间和时间依赖关系。InfinityStar 提出了一种统一的时空自回归框架，该框架通过单一架构同时捕捉空间和时间依赖性，支持多种生成任务，如文本到图像、文本到视频、图像到视频和长交互视频合成。", "innovation": "InfinityStar 提出了一种纯粹离散的方法，可以在单一架构中同时捕捉空间和时间依赖关系，从而统一处理多种生成任务。此外，该模型在 VBench 上的评分为 83.74，超过了所有自回归模型，甚至超越了一些竞争的扩散模型，如 HunyuanVideo。此外，该模型在不进行额外优化的情况下，可以以领先扩散方法约10倍的速度生成分辨率为720p、时长为5秒的视频，使其成为第一个能够生成工业级720p视频的离散自回归视频生成器。", "conclusion": "InfinityStar 具有高效率和高质量视频生成的特点，作者已将所有代码和模型公开，以促进在高效、高质量视频生成方面的进一步研究。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04678", "html_url": "https://arxiv.org/abs/2511.04678", "title": "跟踪和理解对象转换", "title_en": "Tracking and Understanding Object Transformations", "authors": "Yihong Sun,Xinyu Yang,Jennifer J. Sun,Bharath Hariharan", "background": "现实世界中的物体经常经历状态转换，例如苹果被切碎或蝴蝶从蛹中孵化出来。这些变化的理解对于理解物体和动态非常重要，但现有的方法在物体经历外观显著改变的转换时往往难以跟踪目标物体。", "innovation": "为了解决现有方法在物体转换后的跟踪难题，作者提出了“跟踪任意状态”任务，即在对象经历变化过程中持续跟踪，并检测描述状态变化。为此，作者引入了一个新的基准数据集VOST-TAS，并提出了一种名为TubeletGraph的新系统，该系统能够在转换后恢复缺失的对象，并揭示物体状态随时间的变化。TubeletGraph通过识别可能被忽略的轨迹和基于语义接近的部分确定是否整合这些轨迹，然后进行推理解析并生成描述观测到的转换的状态图。", "conclusion": "TubeletGraph在转换下的跟踪表现达到了最先进的水平，展示了物体转换的更深入理解，并展示了复杂物体转换中时间定位和语义推理的有前途能力。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04615", "html_url": "https://arxiv.org/abs/2511.04615", "title": "构建虚拟免疫组化信任：自动化评估图像质量", "title_en": "Building Trust in Virtual Immunohistochemistry: Automated Assessment of Image Quality", "authors": "Tushar Kataria,Shikha Dubey,Mary Bronner,Jolanta Jedrzkiewicz,Ben J. Brintz,Shireen Y. Elhabian,Beatrice S. Knudsen", "background": "深度学习模型可以从苏木精和伊红（H&E）图像生成虚拟免疫组织化学（IHC）染色，这一方法提供了一种可扩展且低成本的替代实验室IHC的方法。然而，目前用于评估图像质量的评估方法主要依赖于纹理和分布指标，这些指标衡量的是图像保真度而非IHC染色的准确性。因此，可靠地评估图像质量仍然具有挑战性。本文通过引入一种自动并基于准确性的框架来解决这一问题，该框架适用于评估十六种配对或非配对的图像转换模型。利用颜色去卷积生成每个虚拟IHC模型中棕色（即IHC阳性）像素的掩码，并使用这些掩码直接计算衡量准确像素标签的染色准确度指标（Dice、IoU、Hausdorff距离），而无需专家手动注释。研究结果表明，传统的图像保真度指标（如FID、PSNR和SSIM）与染色准确度及病理学家评估的相关性较低。配对模型如PyramidPix2Pix和AdaptiveNCE在染色准确度方面表现最佳，而基于扩散和GAN的非配对模型在提供准确的IHC阳性像素标签方面可靠性较低。", "innovation": "本文提出了一种自动化且基于准确性的框架，用于评估16种配对或非配对的图像转换模型的质量。该研究利用颜色去卷积生成每个虚拟IHC模型中棕色像素的掩码，并计算染色准确度指标。研究发现，传统图像保真度指标和病理学家评估之间存在较低的相关性，而配对模型比非配对模型在提供准确IHC阳性像素标签方面表现更佳。此外，通过全滑片图像（WSI）揭示了在基于片段的评估中看不到的性能下降，强调了需要在WSI水平上设置基准的重要性。", "conclusion": "本文定义了一种可重复的方法来评估虚拟IHC模型的质量，这是将这些模型加速应用于病理学家的日常使用的关键步骤。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03743", "html_url": "https://arxiv.org/abs/2511.03743", "title": "基于卷积神经网络的模型类选择深度学习方法", "title_en": "A convolutional neural network deep learning method for model class selection", "authors": "Marios Impraimakis", "background": "该研究探讨了一种新颖的深度卷积神经网络方法，使用仅响应来选择模型类别。通常情况下，这种选择需要系统输入信息的全面识别或完整的系统识别，但该方法通过仅使用独特自由度的响应及其类别信息来训练和验证一维卷积神经网络，从而实现了无需系统输入信息即可选择新且未标注信号的模型类的能力。", "innovation": "该方法采用了一种简单但有效的方法来通过仅响应信息训练和验证卷积神经网络，从而在不需要完整系统识别的前提下自动选择信号的模型类别。此外，方法还提出了通过卡尔曼滤波融合系统响应信号和基于动力学约束的数据相结合的一种物理算法增强方法。", "conclusion": "该研究展示了该方法在轻微信号变化下（如阻尼行为或滞后行为）能够准确选择模型类，适用于线性和非线性动力学系统以及3D建筑有限元模型，在结构健康监测应用中提供了一种强大的工具。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04655", "html_url": "https://arxiv.org/abs/2511.04655", "title": "模拟评分测试设计者应该利用测试集来揭露可利用的非视觉捷径", "title_en": "Benchmark Designers Should \"Train on the Test Set\" to Expose Exploitable Non-Visual Shortcuts", "authors": "Ellis Brown,Jihan Yang,Shusheng Yang,Rob Fergus,Saining Xie", "background": "多模态大型语言模型（MLLMs）的稳健基准对于评估模型的性能至关重要。但研究发现，许多模型在处理多模态基准测试时并不依赖于强大的视觉理解能力，而是依赖于模型中的偏见、语言先验和表面特征。对于那些主要依赖视觉输入的基准测试来说，这种现象尤为令人担忧。为改进这一问题，论文提出了一种诊断基准设计的新原则：如果一个基准能够被操纵，那它最终就会被操纵。因此，设计者应当首先尝试通过诊断与去偏操作来系统地识别和减轻非视觉偏见。有效的诊断需要直接“从测试集中学习”，即通过探测试验集内部可以被利用的内在模式来完成。这需要对非视觉文本输入进行k折交叉验证的微调来揭示捷径性能，并为每个样本分配一个偏见得分$s(x)$；同时还需要使用随机森林等轻量级方法，通过手工构造的特征对测试集进行快速可解释审计。基于这一标准，我们设计了两种工具：（1）使用“测试集应力测试”（TsT）方法诊断基准的易被操纵性，通过在仅限于非视觉、文本输入的测试集中进行k折交叉验证以揭示捷径性能，并为每个样本分配一个偏见得分；（2）通过“迭代偏见修剪”（IBP）程序过滤高偏见样本。我们将这一框架应用于四个基准测试，发现普遍存在非视觉偏见，并通过一个案例研究，展示了通过我们的完整框架创建去偏后的VSI-Bench的结果变化。与原始版本相比，去偏后的VSI-Bench揭示了更广泛的视觉盲性能差距，减少了非视觉解题的可能性。", "innovation": "提出了一种新的基准设计原则，即“模拟评分测试”（Test-set Stress-Test，TsT）和“迭代偏见修剪”（Iterative Bias Pruning，IBP）程序。利用TsT方法直接探测试验集以揭示可被模型利用的非视觉偏差，量化偏见得分；通过IBP程序精准去除高偏见样本，从而减轻非视觉因素对模型性能的影响，并验证了这一新框架的有效性。这种方法能够帮助设计者更系统地识别和减轻非视觉偏见，从而提高多模态大型语言模型的评估标准的稳健性和客观性。", "conclusion": "通过对四个多模态基准测试应用TsT和IBP程序，我们发现非视觉偏见普遍存在。此案例研究表明，基于提出的完整框架创建去偏后的VSI-Bench，能够减少非视觉解题的可能性，并展示了更广泛的视觉盲性能差距。验证了“测试集应力测试”方法和“迭代偏见修剪”程序在基准设计中的有效性和必要性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03929", "html_url": "https://arxiv.org/abs/2511.03929", "title": "NVIDIA Nemotron Nano V2 VL", "title_en": "NVIDIA Nemotron Nano V2 VL", "authors": "NVIDIA:Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu(Danny)Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu(Justin)Xin, Di (Allan)Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin", "background": "介绍Nemotron Nano V2 VL是NVIDIA最新推出的一款Visual-Language系列模型，主要应用场景包括现实世界文档理解、长视频理解与推理任务。", "innovation": "Nemotron Nano V2 VL在模型架构、数据集和训练方法上进行了重大改进，对比之前的Llama-3.1模型，其在视觉和文本领域都有显著提升。使用混合Mamba-Transformer架构和创新的token减少技术，以提高长文档和视频推理吞吐量。", "conclusion": "NVIDIA发布了BF16、FP8和FP4格式的模型检查点，并分享了大量数据集、制作方法和训练代码。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04595", "html_url": "https://arxiv.org/abs/2511.04595", "title": "UniSplat: 统一时空融合通过3D潜支架实现动态驾驶场景重建", "title_en": "UniSplat: Unified Spatio-Temporal Fusion via 3D Latent Scaffolds for Dynamic Driving Scene Reconstruction", "authors": "Chen Shi,Shaoshuai Shi,Xiaoyang Lyu,Chunyang Liu,Kehua Sheng,Bo Zhang,Li Jiang", "background": "自动驾驶前置的3D重构技术虽然已取得迅速进展，但现有的方法在处理稀疏、不重叠的摄像机视图以及场景中的复杂动态时仍存在挑战。本文专注于解决这些难题，特别是在现有方法难以同时有效处理的透视稀疏性和场景动态性的难题上.", "innovation": "本文提出了一种通用的前馈框架——UniSplat，通过统一的潜时空融合学习稳健的动态场景重构。UniSplat构造了一个3D潜支架，利用预训练的基础模型捕捉几何和语义的场景上下文。通过直接在3D支架中引入高效的融合机制来有效整合空间视图和时间帧的信息，保持静态高斯的持久记忆以支持超出当前摄像机覆盖范围的场景流式重建.", "conclusion": "在实际数据集上的广泛实验表明，UniSplat在新颖视图合成方面达到了最新的技术水平，即使在远离原始摄像机视场的视角也提供稳健且高质量的渲染结果."}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03768", "html_url": "https://arxiv.org/abs/2511.03768", "title": "共同点何在？多模态模型在跨场景推理时会胡乱推断", "title_en": "What's in Common? Multimodal Models Hallucinate When Reasoning Across Scenes", "authors": "Candace Ross,Florian Bordes,Adina Williams,Polina Kirichenko,Mark Ibrahim", "background": "多模态语言模型展示了处理大量不同对象的能力。然而，它们在现实场景推理方面仍然存在缺陷（幻觉），特别是在开放词汇场景中。目前的感知基准即将达到极限，但也展示了在现实世界场景推理中的不足。为此，该研究构建了一个新的开放场景基准——Common-O，考验多个场景间的共同点，并对现有最优的多模态语言模型进行了评估。", "innovation": "该研究创新性地提出了Common-O基准，旨在评估模型在开放场景中的跨场景推理能力，特别是对于现实世界场景。研究发现，虽然许多模型在单一场景对象感知方面表现出色，但在不同场景间的推理依然很具挑战性。研究特别指出，最佳模型在Common-O和Common-O Complex上的表现分别为35%和1%，显示出模型在跨场景推理上的巨大缺陷。此外，研究还探讨了模型的规模和训练模式对跨场景推理的影响。", "conclusion": "尽管目前的多模态模型在感知方面表现良好，但在跨场景推理时依然容易出现幻觉。模型的训练方式，尤其是多图训练，能够显著改善跨场景推理能力。该研究强调了评估和改进多模态模型跨场景推理能力的必要性，并承诺公开此基准数据集以促进相关研究。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03876", "html_url": "https://arxiv.org/abs/2511.03876", "title": "CT-衍生心血管流速估计采用物理知情神经网络改进：基于图像数据的训练模拟研究", "title_en": "Computed Tomography (CT)-derived Cardiovascular Flow Estimation Using Physics-Informed Neural Networks Improves with Sinogram-based Training: A Simulation Study", "authors": "Jinyuxuan Guo,Gurnoor Singh Khurana,Alejandro Gonzalo Grande,Juan C. del Alamo,Francisco Contijoch", "background": "非侵入性成像方法中的血流评估对于心脏功能和结构的评价至关重要。虽然CT是一种广泛应用的成像方式，能可靠地评估心血管结构和功能，但目前没有直接从造影剂演化电影中估计血流速度的方法。本研究评估了CT成像对基于物理知情神经网络（PINN）的血流估计的影响，并提出了一种新的SinoFlow框架，直接使用衰减曲线数据来估计血流。", "innovation": "本研究改进了基于物理知情神经网络的血流估计方法，提出了一种名为SinoFlow的新框架，该框架直接利用衰减曲线数据（而不是重建的图像）进行血流估计，从而避免了滤波反投影引入的误差。此外，SinoFlow适用于脉冲模式成像，并能在较短脉冲持续时间下保持较高的准确性。", "conclusion": "研究结果显示，SinoFlow框架在CT成像中进行血流估计具有更高的准确性和稳定性，提供了无创血流评估的更有前景的方法。这一发现将为未来PINNs在CT图像中的应用奠定基础，并为基于图像的血流估计提供了解决方案，在合理的采集参数下可以获得准确的流速估计。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03890", "html_url": "https://arxiv.org/abs/2511.03890", "title": "形变神经网络用于自动生成3D CT图像中的主动脉瓣有限元网格", "title_en": "Shape Deformation Networks for Automated Aortic Valve Finite Element Meshing from 3D CT Images", "authors": "Linchen Qian,Jiasong Chen,Ruonan Gong,Wei Sun,Minliang Liu,Liang Liang", "background": "准确的主动脉瓣几何建模对于生物力学分析和患者特定的仿真评估瓣膜健康或进行术前计划至关重要。然而，生成具有高质量且不同患者之间具有一致性的主动脉瓣网格仍然是一个具有挑战性的问题。传统方法常常生成具有不规则拓扑结构的三角形网格，这会导致不规则的单元形状和因不同患者解剖变异导致的对应不一致。", "innovation": "本研究提出了一种基于深度神经网络的模板拟合管道，用于从3D CT图像生成结构化的四边形网格以表示主动脉瓣几何结构。通过使用一个通用的四边形网格模板重新网格化所有患者的主动脉瓣，确保了患者之间网格拓扑结构的一致性和节点到节点、单元到单元的对应性。简化了深度神经网络的学习目标，采用仅包含几何重建项和平滑正则化项的损失函数，从而保持网格形状质量和单元质量。实验结果表明，本方法生成的主动脉瓣表面网格具有更高的光滑度和形状质量，所需显式正则化项比传统方法更少。", "conclusion": "使用结构化四边形网格作为模板和神经网络训练不仅确保了网格对应性和质量，而且简化了训练过程，从而提高了主动脉瓣建模的有效性和效率。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04680", "html_url": "https://arxiv.org/abs/2511.04680", "title": "-carousel-一个高分辨率的多目标自动图像裁剪数据集", "title_en": "Carousel: A High-Resolution Dataset for Multi-Target Automatic Image Cropping", "authors": "Rafe Loya,Andrew Hamara,Benjamin Estell,Benjamin Kilpatrick,Andrew C. Freeman", "background": "自动图像裁剪是一种方法，旨在最大化照片中裁剪区域的人类感知质量。尽管已经有多种方法提出了生成单一裁剪的技术，但很少有研究关注生成多个有审美吸引力的裁剪区域的问题。本文通过讨论现代社交媒体应用来阐述该问题，并介绍了一个包含277张相关图像及其人工标注的数据集。", "innovation": "本文引入了一个名为“Carousel”的高分辨率数据集，用于多目标自动图像裁剪。通过将图像分割算法作为预处理步骤，评估了几种单一裁剪模型的有效性。通过这一数据集，研究人员能够更好地解决生成多个有审美吸引力的裁剪区域的问题。", "conclusion": "本文提出了一个包含277张相关图像及其人工标注的高分辨率数据集“Carousel”，以解决多目标自动图像裁剪的问题，并通过实验验证了几种单一裁剪模型的有效性。该数据集为今后的研究奠定了基础，有助于提高多目标自动图像裁剪的质量。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04357", "html_url": "https://arxiv.org/abs/2511.04357", "title": "GraSP-VLA：基于图的符号动作表示在VLA策略的长视界规划中的应用", "title_en": "GraSP-VLA: Graph-based Symbolic Action Representation for Long-Horizon Planning with VLA Policies", "authors": "Maëlic Neau,Zoe Falomir,Paulo E. Santos,Anne-Gwenn Bosser,Cédric Buche", "background": "自主机器人可以通过演示学习新的技能，这是现代机器人技术的重要挑战。现有解决方案通常使用端到端的模仿学习结合视觉-语言-动作（VLA）模型或使用行动模型学习（AML）的符号方法。当前VLA模型受限于缺乏高层次的符号规划，限制了它们在长时间任务上的能力。同时，AML中的符号方法缺乏通用性和扩展性。这些背景下，该研究旨在提出一种新的神经-符号方法，GraSP-VLA框架，通过连续场景图表示生成人类演示的符号表示，用于推理过程中的规划领域生成，并作为低级VLA策略的协调器，从而扩大可以连续重复的动作数量。", "innovation": "提出了GraSP-VLA，这是一种结合了连续场景图表示的神经-符号方法，用于生成人类演示的符号表示，用于规划领域生成和低级VLA策略的协调，这种方法能有效扩展能够连续重复的动作数量，并展示了其在长时间任务上的潜力。", "conclusion": "实验结果显示，GraSP-VLA在观察基础上自动规划领域的生成中能够有效地构建符号表示，在真实世界的实验中也表现出能够协调低级VLA策略以执行长时间任务的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04422", "html_url": "https://arxiv.org/abs/2511.04422", "title": "回归与分类的等价性", "title_en": "On the Equivalence of Regression and Classification", "authors": "Jayadeva,Naman Dwivedi,Hari Krishnan,N.M. Anoop Krishnan", "background": "回归与分类之间的严格形式关联一直较为薄弱。尽管支持向量回归中使用了边缘最大化项 \\(\\|w\\|\\)，它最多只是作为正则化项进行了验证。已有的研究没有明确地将回归问题与分类任务通过一个明确的等价关系联系起来，因此在转换和解决方法上存在一定的不一致性。", "innovation": "本文展示了含有 \\(M\\) 个样本并且这些样本位于一个超平面上的回归问题，等价于一个具有 \\(2M\\) 个样本的线性可分分类任务。通过对等价分类任务进行边缘最大化操作，可以得到不同于传统回归模型的回归算法。通过这一等价性，可以开发一种“可回归性”度量方法，用来估计回归数据集的难易程度，无需先学习模型。此外，通过等价性可以训练神经网络学习一个线性化映射，将输入变量转换至一个线性回归模型足够适用的空间中。", "conclusion": "本文证明了回归与分类之间的等价关系，通过等价关系提出了一个新的回归方法，并且能够根据等价性来训练神经网络以学习将非线性回归问题转化为线性问题的映射。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04583", "html_url": "https://arxiv.org/abs/2511.04583", "title": "Jr. AI Scientist and Its Risk Report: 自主科学探索的技术基线论文", "title_en": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper", "authors": "Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa", "background": "了解当前人工智能科学家系统的功能和风险对于确保基于人工智能的科学进步可信、可持续发展至关重要，同时保障学术生态系统的完整性。以往的研究多假设全面自动化或操作小规模代码，但缺乏一个系统能够模拟初学者科学研究员的核心研究流程，并利用现代编码代理处理复杂的多文件实现。", "innovation": "我们开发了Jr. AI Scientist，这是一种最先进的人工智能科学家系统，模仿初学者科学研究工作的核心流程。该系统能根据人类导师提供的基线论文，分析其局限性、提出改进的创新假设，并通过严格实验验证它们，最终撰写含有研究结果的文章。Jr. AI Scientist遵循明确的研究工作流程，利用现代编码代理处理复杂的多文件实现，从而产生具有科学价值的贡献。", "conclusion": "我们的评估结果表明，Jr. AI Scientist生成的论文在审稿人评分方面高于现有的全自动系统。然而，从作者评估和Agents4Science的评审中，我们发现了一些重要的局限性，这表明当前的人工智能科学家系统存在潜在风险，同时也指出了未来研究的关键挑战。我们在开发过程中全面报告了各种风险。我们希望这些洞察将加深对人工智能科学家开发当前进展和风险的理解。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04494", "html_url": "https://arxiv.org/abs/2511.04494", "title": "基于输出分布的数据驱动张量分解方法用于卷积神经网络压缩", "title_en": "Distribution-Aware Tensor Decomposition for Compression of Convolutional Neural Networks", "authors": "Alper Kalle,Theo Rudkiewicz,Mohamed-Oumar Ouerfelli,Mohamed Tamaazousti", "background": "神经网络在图像相关任务中被广泛应用，但通常需要大量计算资源。一旦网络训练完成，可以通过压缩减少其内存和计算需求。以往的经典方法通过最小化张量空间中的 isotropic 规范来寻找低秩逼近，而本文采用数据驱动的方法，通过最小化层输出分布的变化来实现压缩。这种方法不依赖于张量空间中的范数，而是直接优化在函数空间中的误差。研究表明，在多种 CNN 模型和数据集上，这种方法可以实现与传统压缩方法相比具有竞争力的准确率，并且无需后处理微调。此外，该方法还可以在目标数据集不可用时，通过数据集间均值协方差的迁移实现压缩，并且只导致轻微的准确率损失。", "innovation": "本文提出了一种新的基于输出分布的数据驱动张量分解方法，用于卷积神经网络的压缩。不同于传统的通过最小化张量空间中规范的方法，这种方法直接优化函数空间中的误差，即最小化层输出分布的变化。此外，还介绍了新的交替最小二乘算法来实现这一优化，适合两种最常见的张量分解（Tucker-2 和 CPD）。这种方法不需要压缩后的微调，且在不同数据集间具有较好的迁移性，能够有效减少计算和存储资源的需求。", "conclusion": "本文提出的方法在多个 CNN 建模和数据集上进行了实验验证，结果表明其具有比传统方法更强的竞争力，且在某些情况下无需进行后压缩微调。此外，即使原始训练数据集不可用，该方法仍然可以迁移应用到其他数据集上。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04679", "html_url": "https://arxiv.org/abs/2511.04679", "title": "GentleHumanoid: 学习上半身的顺应性以进行丰富的接触式人类和对象交互", "title_en": "GentleHumanoid: Learning Upper-body Compliance for Contact-rich Human and Object Interaction", "authors": "Qingzhou Lu,Yao Feng,Baiyu Shi,Michael Piseno,Zhenan Bao,C. Karen Liu", "background": "人类中心的环境中，人形机器人需要进行安全而自然的物理交互。然而，现有的强化学习（RL）策略注重刚性跟踪和抑制外部力的作用。现有的阻抗增强方法通常局限于基座或末端执行器控制，并侧重于抵抗极端力而不是实现顺应性。因此，研究人员引入了GentleHumanoid框架，将阻抗控制融入到全身运动跟踪策略中，以实现上半身的顺应性。", "innovation": "GentleHumanoid框架的核心是一个统一的基于弹簧的表述，该表述既能够模拟接触瞬间的恢复力（当接触表面时会产生的恢复力），又能模拟来自人类动作数据的引导接触（施加推或拉力）。该表述确保了肩膀、肘部和腕部的动态连续性，使策略能够适应多种交互场景，并且通过可调整的任务力阈值来增强安全性。相比基准模型，该方法能够在不同顺应性要求的任务中减少峰值接触力，同时保持任务的成功率，从而进行更为平滑和自然的交互。", "conclusion": "这些结果表明，GentleHumanoid为设计能够在真实环境中安全有效与人类协作并处理物体的人形机器人迈出了关键一步。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04555", "html_url": "https://arxiv.org/abs/2511.04555", "title": "Evo-1: 轻量级维视语言行动模型，具有保持语义对齐", "title_en": "Evo-1: Lightweight Vision-Language-Action Model with Preserved Semantic Alignment", "authors": "Tao Lin,Yilei Zhong,Yuxin Du,Jingjing Zhang,Jiting Liu,Yinxinyu Chen,Encheng Gu,Ziyan Liu,Hongyi Cai,Yanwen Zou,Lixing Zou,Zhaoye Zhou,Gen Li,Bo Zhao", "background": "维视语言行动（VLA）模型作为一种强大的框架，能够统一感知、语言和控制，使得机器人能够通过多模态理解执行多样任务。然而，当前的VLA模型通常包含大量参数，并且严重依赖大规模机器人数据预训练，导致训练时计算成本高，实际部署时灵活性受限。此外，大多数训练范式往往导致视觉语言骨干网络的感知表征劣化，造成过拟合并影响下游任务的泛化性能。", "innovation": "Evo-1 模型是一个轻量级的VLA模型，通过结合一种新颖的跨模态扩散转换器与优化的集成模块，形成了一个有效的架构。它采用了现成的多模态视觉语言模型，并引入了两阶段训练范式，逐步使行动与感知对齐，保留了视觉语言模型的表征。Evo-1 模型具有 0.77 亿参数，在 Meta-World 和 RoboTwin 测试套件中均取得了最先进的结果，并在 LIBERO 上达到了 94.8% 的竞争水准。在现实世界的测试中，Evo-1 成功率高达 78%，具有高推理频率和低内存开销，超越了所有基线方法。", "conclusion": "Evo-1 模型通过减少计算成本和提高部署效率，同时保持强大的性能，而无需依赖机器人数据预训练。它在多个测试集上的表现超越了之前的最佳模型，并且在实际应用中展示了出色的性能和灵活性。该项目通过公开代码、数据和模型权重，促进了轻量级和高效 VLA 模型的未来研究。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2303.16078", "html_url": "https://arxiv.org/abs/2303.16078", "title": "三台校准相机的相对姿态实际解决方案", "title_en": "Practical solutions to the relative pose of three calibrated cameras", "authors": "Charalambos Tzamos,Viktor Kocur,Yaqing Ding,Daniel Barath,Zuzana Berger Haladova,Torsten Sattler,Zuzana Kukelova", "background": "本文研究了基于四点对应关系估计三台校准相机间相对姿态的具有挑战性问题。传统的解决方法可能不够高效或不够准确，特别是在面对复杂场景或数据质量有限时。因此，迫切需要开发新的方法来改善这种情况。本文提出了基于简单几何估计的新颖高效解决方案，以应对这些问题。", "innovation": "本文通过引入新的方法来改进传统的相对姿态估计方法。首先，使用四点对应关系估算前两个视图的近似几何形状，该几何形状可以是仿射或全透视几何。其次，通过计算三个对应点的均值点生成一个近似对应点。最后，提出了两种新颖的基于仿射与基于近似均值点对应的新求解器，这两种方法都可以有效利用现有的高效最小解算器，如4点仿射基础矩阵、5点相对姿态解算器和P3P解算器。实验结果表明，在适当结合局部优化后，提出的解算器具有最先进的性能，基于近似均值点对应的解算器更具有鲁棒性和准确性，优于基于仿射的方法。", "conclusion": "本文提出的基于新方法的解算器具有高效和易实现的特点，并且与局部优化结合后实现了最先进的结果，其中基于近似均值点对应的解算器在鲁棒性和准确性方面优于基于仿射的方法。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.01887", "html_url": "https://arxiv.org/abs/2401.01887", "title": "LEAP-VO：适用于视觉测标的长期有效的任意点跟踪", "title_en": "LEAP-VO: Long-term Effective Any Point Tracking for Visual Odometry", "authors": "Weirong Chen,Le Chen,Rui Wang,Marc Pollefeys", "background": "现有的视觉测深方法主要关注两点视角跟踪，通常忽略了图像序列中的丰富的时间上下文，忽视了全局运动模式，并未评估全程轨迹的可靠性。这些缺点在遮挡、动态目标和低纹理区域等场景中限制了性能。", "innovation": "提出了Long-term Effective Any Point Tracking (LEAP) 模块。LEAP创新性地结合了视觉、跨追踪和时间线索，选择性地用于动态跟踪估计。LEAP的时间概率公式将分布更新整合到可学习的迭代精炼模块中，以推断点状不确定性。在此基础上，我们开发了LEAP-VO，一种稳健的视觉测深系统，能够处理遮挡和动态场景。", "conclusion": "广泛的实验结果表明，所提出的管道在各种视觉测深基准测试中显著优于现有基线。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04671", "html_url": "https://arxiv.org/abs/2511.04671", "title": "X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations", "title_en": "X-Diffusion: Training Diffusion Policies on Cross-Embodiment Human Demonstrations", "authors": "Maximus A. Pace,Prithwish Dan,Chuanruo Ning,Atiksh Bhardwaj,Audrey Du,Edward W. Duan,Wei-Chiu Ma,Kushal Kedia", "background": "人类视频可以快速且大规模地录制，成为机器人学习中训练数据的一种有吸引力的来源。然而，人类和机器人在身体特征上存在根本差异，导致动作执行不匹配。直接将人类手部动作的亲和关系转换可能产生对于机器人来说是不可能执行的动作。尽管存在这些低级差异，人类的示范仍然提供了如何操作和与对象互动的重要运动线索。特别是在将人类演示数据应用到机器人学习时，面对机械结构和生理结构的不同，如何有效利用这些人类示范数据成为了一个重要挑战。本文提出了一种关键思想：通过逐步添加噪声使低级执行差异逐渐模糊，但高级任务指导得以保留的方法，该研究展示了X-Diffusion框架，能够基于跨实体的人类示范训练扩散策略而不学习动态不可行的动作。研究表明，缺乏解决执行差异的直接训练方法会降低策略性能，而X-Diffusion持续提高了策略性能。实验结果表明，在五个操作任务中，X-Diffusion平均成功率比最佳基准提高了16%。", "innovation": "本文提出了X-Diffusion框架，该框架能够基于跨实体的人类示范训练扩散策略而不学习动态不可行的动作。该框架的核心在于利用逐步添加噪声的方法，使低级执行差异逐渐逐渐模糊但高级任务指导得以保留。通过将人类动作在添加足够噪声后，使其无法被区分，动作被分类为更接近于机器人操作的指导，进而用于策略训练过程中。这种策略显著提高了策略性能，尤其是在五个操作任务中，X-Diffusion相比其他基准提高了16%的成功率。", "conclusion": "本文研究展示了X-Diffusion框架在利用跨实体人类示范数据进行机器人策略训练方面的有效性和优势。在存在执行差异的情况下，X-Diffusion能够让机器人更有效地使用人类示范数据，同时避免学习动态不可行的动作，显著提高了策略性能。实验结果证明了这一方法的有效性，尤其是在多个操作任务中提高了策略的成功率。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.04510", "html_url": "https://arxiv.org/abs/2511.04510", "title": "μNeuFMT：基于隐式神经表示的自适应光学特性荧光分子断层成像", "title_en": "$μ$NeuFMT: Optical-Property-Adaptive Fluorescence Molecular Tomography via Implicit Neural Representation", "authors": "Shihan Zhao,Jianru Zhang,Yanan Wu,Linlin Li,Siyuan Shen,Xingjun Zhu,Guoyan Zheng,Jiahua Jiang,Wuwei Ren", "background": "荧光分子断层成像（FMT）是一种有助于非侵入性3D可视化荧光探针的技术，但其重建仍然具有挑战性，由于病理解剖组织光学特性（如吸收系数和散射系数）的固有不明确性和不准确性。虽然深度学习方法显示出了潜力，但其监督学习性质限制了它在训练数据之外的泛化能力。由于现有方法需要准确的组织光学先验知识或预条件训练数据，这使得它们在实际应用中受到了限制。现有方法在重建精度和准确性上存在局限性，尤其是在初始值偏差较大时，难以提供可靠的重建结果，尤其是在复杂且异质性的临床场景中.", "innovation": "我们提出了一种名为μNeuFMT的自监督FMT重建框架，它结合了隐式神经场景表示与显式光子传播的物理建模。其核心创新之处在于在重建过程中联合优化荧光分布和光学特性（吸收系数μ），从而消除了精确组织光学先验知识或预条件训练数据所需。实验结果显示，即使初值存在较大错误（0.5倍到2倍的真实值），μNeuFMT仍能稳健地恢复准确的荧光分布和光学系数。广泛的数值、公模和活体验证表明，μNeuFMT在多种异质场景中表现出色，优于传统方法和监督深度学习方法，从而为形成一种更稳健和准确的FMT重建范式提供了可能，为复杂的临床应用（如荧光引导手术）中更可靠分子成像奠定了基础.", "conclusion": "我们提出的μNeuFMT框架确立了稳健和准确FMT重建的新范式，为更复杂的临床相关场景的可靠分子成像开辟了道路。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2308.01184", "html_url": "https://arxiv.org/abs/2308.01184", "title": "通过方向无关的EM公式连接生成和判别噪声标签学习", "title_en": "Bridging Generative and Discriminative Noisy-Label Learning via Direction-Agnostic EM Formulation", "authors": "Fengbei Liu,Chong Wang,Yuanhong Chen,Yuyuan Liu,Gustavo Carneiro", "background": "尽管简单且快速的判别方法常用于处理噪声标签学习问题，生成模型提供了一种原理上更为合理的方法，因为它们可以捕捉生成特征、清洁标签和受污染观测的联合机制。然而，先前的工作通常引入额外的潜在变量和复杂的图像生成器，这些都会让训练偏向于重建；固定单一的数据生成方向，限制了适应性；并且假设清洁标签的统一先验，忽略了实例级别的不确定性。", "innovation": "本文提出了一种方向无关的EM风格框架，用于生成噪声标签学习，并避免了显式的图像合成。首先，推导出一个单一的EM目标，其中E步可以专门用于任一种因果方向，而不会改变整体优化。其次，用数据集归一化的判别性代理替换不可解析的$p(X|Y)$，使用判别分类器在有限的训练集上计算，保持生成建模的结构优势，但成本更低。第三，引入了部分标签监督（PLS），这是一种实例特定的清洁标签先验，平衡了覆盖率和不确定性，从而改进了数据依赖的正则化。", "conclusion": "本文在标准视觉和自然语言处理（NLP）噪声标签基准测试中实现了最先进的准确率，较低的转移矩阵估计误差，以及相较于现有生成性和判别性基线的显著少的训练计算量。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.02534", "html_url": "https://arxiv.org/abs/2410.02534", "title": "伪立体输入：自监督立体匹配中遮挡挑战的解决方案", "title_en": "Pseudo-Stereo Inputs: A Solution to the Occlusion Challenge in Self-Supervised Stereo Matching", "authors": "Ruizhi Yang,Xingqiang Li,Jiajun Bai,Jinsong Du", "background": "自监督立体匹配技术被认为是减少对昂贵标注数据依赖的有希望的方法。然而，基于光度一致性主导范式从根本上受到遮挡挑战的阻碍，这个问题不论网络架构如何都无法得到解决。", "innovation": "这项工作提出了一种更根本的解决方案。核心思想是将单侧有效的反馈信号和单侧错误的反馈信号转化为从遮挡物两侧获取有效反馈的随机化过程。通过一个完全框架，采用伪立体输入策略，将输入和反馈解耦，不引入任何额外约束，解决了遮挡问题，表现为在遮挡物体两侧对称且一致的性能。", "conclusion": "定性的实验结果表明，遮挡问题得到了解决，定量实验充分验证了解决遮挡挑战后实现的显著性能提升。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.16304", "html_url": "https://arxiv.org/abs/2311.16304", "title": "Robust Self-calibration of Focal Lengths from the Fundamental Matrix", "title_en": "Robust Self-calibration of Focal Lengths from the Fundamental Matrix", "authors": "Viktor Kocur,Daniel Kyselica,Zuzana Kukelova", "background": "自校准是几何计算机视觉中的基本问题之一，特别是在已知主点和正方形像素的情况下，著名的Bougnoux公式可以用来计算两个未知的焦距。然而，在许多实际情况下，公式由于常见的奇异点导致结果不准确，并且计算出的模型参数估计对噪声敏感，对假设的主点位置同样敏感。因此，本文提出了一种高效的自迭代方法，用于在已知基础矩阵和估计的摄像机参数先验值的情况下，同时估计摄像机的焦距和主点。此外，研究了在RANSAC中生成的高效模型检验方法，提高了模型估计的准确性，同时减少了总计算时间。实验结果表明，该迭代方法在估计焦距的准确性上显著优于Bougnoux公式和其他最先进的方法，即使依赖不准确先验也是如此。", "innovation": "本文提出了一种高效且鲁棒的迭代方法，用于在给定基础矩阵和估计的摄像机参数先验值的情况下，同时估计摄像机的焦距和主点。此外，研究了一种高效的检查模型生成方法，以提高RANSAC生成模型的准确性并减少总计算时间。", "conclusion": "实验结果表明，与Bougnoux公式和最先进的方法相比，本文迭代方法在估计焦距的准确性上带来了显著的提高，即使依赖不准确的先验也是如此。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2404.09515", "html_url": "https://arxiv.org/abs/2404.09515", "title": "使用FAGC方法揭示铜合金的结构-性能关系", "title_en": "Revealing the structure-property relationships of copper alloys with FAGC", "authors": "Yuexing Han,Ruijie Li,Guanxin Wan,Gan Hu,Yi Liu,Bing Wang", "background": "Cu-Cr-Zr 合金在电子设备和电力行业中具有重要作用，因其优异的电导率和硬度。然而，由于样本稀少，研究其微观结构图像与其关键性能之间的关系的有效研究较少。本文通过FAGC特征增强方法增强Cu-Cr-Zr合金的微观结构图像，利用伪标签增加训练样本数量，并将这些特征输入机器学习模型来构建性能预测模型。实验结果表明，大数据增强和决策树分类器的结合显著提升了电导率（拟合优度R²=0.978）和硬度（拟合优度R²=0.998）的预测性能。", "innovation": "本文创新性地使用FAGC特征增强方法增强Cu-Cr-Zr合金的微观结构图像，利用伪标签扩增训练样本，并通过多种机器学习模型建立性能预测模型。实验验证了不同机器学习方法和增强特征数量对预测精度的影响。", "conclusion": "实验结果表明，使用带有100个增强特征的决策树分类器，方法在预测电导率和硬度方面表现出色（R²分别为0.978和0.998）。进一步分析发现，图像噪声减少的区域，如较少的晶界或相界，对电导率贡献更高。此项研究为有限图像数据的材料科学提供了有力工具，揭示了复杂微观结构和材料性能之间的详细定量关系。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.05500", "html_url": "https://arxiv.org/abs/2410.05500", "title": "增强深度学习的残差柯尔莫哥洛夫-阿诺尔德网络", "title_en": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning", "authors": "Ray Congrui Yu,Sherry Wu,Jiang Gui", "background": "尽管深度卷积神经网络（CNNs）在许多任务上取得了巨大的成功，但由于网络深度中包含数百层，它们在优化和训练时可能非常困难且成本高昂。传统的卷积操作因其线性和固定的激活限制，需要很多层才能学习数据中的有意义模式。由于这些网络的巨大规模，这种方法在计算上是低效的，并且在小数据集上容易导致过拟合或梯度爆炸问题。因此，文中提出了一种‘可插拔’模块，称为残差柯尔莫哥洛夫-阿诺尔德网络（RKAN）。该模块简洁紧凑，可以轻松地添加到传统深度网络的任何阶段，在此基础上学习整合支持性的多项式特征变换，以增强现有的卷积框架。", "innovation": "文中提出了一种名为‘插件’模块的残差柯尔莫哥洛夫-阿诺尔德网络（RKAN），该模块能够学习整合支持性的多项式特征变换，从而增强了现有的卷积框架。实验结果显示，RKAN在不同视觉任务和广泛测试的基准上都优于基础模型，实现了业界领先的表现。", "conclusion": "RKAN在各种视觉任务中提供了稳定改进，并在广泛测试的基准上实现了顶级的性能。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.05984", "html_url": "https://arxiv.org/abs/2410.05984", "title": "关于相对位姿估计是否需要最小径向 Distortion 解决方案的必要性", "title_en": "Are Minimal Radial Distortion Solvers Necessary for Relative Pose Estimation?", "authors": "Charalambos Tzamos,Viktor Kocur,Yaqing Ding,Torsten Sattler,Zuzana Kukelova", "background": "估计两台相机之间的相对位姿是许多应用，如结构从运动的关键步骤。常用的方法是在RANSAC循环中应用最小解决方案。孔穴相机存在高效的解决方法。然而，几乎所有的相机都存在径向畸变。不建模径向畸变会导致显著的性能下降。虽然存在复杂的最小径向畸变解算器，但它们在运行时间和实现方面都比孔穴相机解算器复杂得多。", "innovation": "本文提出了一种简单的解决方案，将高效的孔穴相机解算器与采样径向畸变参数结合使用，对比了这样的简单方法与最精确的最小畸变解算器在多个数据集和RANSAC变体上的性能。实验结果显示，该简单方法在运行速度更快的情况下，精度不低于最精确的最小畸变解算器，同时比运行更快但非最小解算器的精度更高。本文还明确证明了在实践中复杂的最小径向畸变解算器并不是必需的。", "conclusion": "复杂的最小径向畸变解算器在实践中并非必要。代码和基准测试可供下载。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.17168", "html_url": "https://arxiv.org/abs/2408.17168", "title": "EMHI: A Multimodal Egocentric Human Motion Dataset with HMD and Body-Worn IMUs", "title_en": "EMHI: A Multimodal Egocentric Human Motion Dataset with HMD and Body-Worn IMUs", "authors": "Zhen Fan,Peng Dai,Zhuo Su,Xu Gao,Zheng Lv,Jiarui Zhang,Tianyuan Du,Guidong Wang,Yang Zhang", "background": "人体姿态估计（HPE）对于VR/AR应用场景至关重要。目前大多数方法依赖于单一的数据源，如主观视角图像或稀疏的惯性测量单元（IMU）信号，这会导致由于图像中的自遮挡或惯性传感器的稀疏性和漂移而出现不准确的结果。缺乏包含两种模态（主观视角图像和IMU信号）的真实世界数据集是该领域进展的主要障碍。因此，需要新的数据集来解决这个问题，并提高人体姿态估计的准确性，特别是在VR环境中。", "innovation": "本文提出了EMHI数据集，这是一个多模态的主观视角人体运动数据集，结合了头戴式显示器（HMD）和穿戴式IMU的数据，所有数据在真实的VR产品套件下收集。该数据集提供了同步的立体图像和IMU数据，并附带了SMPL格式的姿态标注。研究还介绍了一个新的多模态基础方法MEPoser，该方法通过多模态融合编码器、时域特征编码器和基于MLP的回归头，来实现在（主观视角）人体姿态估计中的多模态融合。实验结果显示，MEPoser在EMHI数据集上的表现优于现有的单模态方法，验证了数据集和方法的有效性，推动了VR/AR产品中人体姿态估计技术的实用化进程。", "conclusion": "通过发布EMHI数据集和MEPoser方法，研究预期能够促进主观视角人体姿态估计的研究，并加速这项技术在VR/AR产品中的实际应用。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17899", "html_url": "https://arxiv.org/abs/2503.17899", "title": "从静态图像中学习时间意识：时间告诉了我们什么？", "title_en": "What Time Tells Us? An Explorative Study of Time Awareness Learned from Static Images", "authors": "Dongheng Lin,Han Hu,Jianbo Jiao", "background": "时间通过照明变化在我们所见的事物中变得可见。受这一启发，本文探索了通过静态图像学习时间意识的可能性，试图回答“时间能告诉我们什么？”为此，我们首先介绍了包含130,906张具有可靠时间戳的图像的数据集——Time-Oriented Collection (TOC)数据集。", "innovation": "我们提出了一种名为Time-Image Contrastive Learning (TICL)的方法，通过跨模态对比学习，联合建模时间戳和相关的视觉表示。实验结果表明：TICL不仅在时间戳估计任务上达到了最先进的性能，而且即使仅通过静态图像，由TICL学习的时间意识嵌入也在基于时间的图像检索、视频场景分类和时间感知图像编辑等几个下游任务中展现出了很强的能力。", "conclusion": "我们的研究结果表明，时间相关的视觉线索可以从静态图像中学习，并且可以为各种视觉任务提供帮助，为未来关于理解时间相关视图语境的研究奠定了基础。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.07499", "html_url": "https://arxiv.org/abs/2501.07499", "title": "基于Homography的三视图焦距恢复", "title_en": "Three-view Focal Length Recovery From Homographies", "authors": "Yaqing Ding,Viktor Kocur,Zuzana Berger Haladová,Qianliang Wu,Shen Cai,Jian Yang,Zuzana Kukelova", "background": "本文提出了一种从三视图Homography恢复焦距的新方法。通过对两个Homography之间法向量的连续性进行分析，利用消元技术导出新的一次和二次约束条件，证明了三个不同的Homography可以提供两个额外的约束条件，从而能够恢复一个或两个焦距。文章讨论了四个可能的情况，并通过求解一元或二元多项式方程来解决问题，可以通过Sturm序列或隐变量技术高效地解决这些问题。利用合成数据和真实数据的评估结果表明，所提出的求解器比依赖现有两视图求解器的方法更快更准确。", "innovation": "本文提出了一种从三视图Homography中恢复焦距的新方法。通过研究两个Homography之间法向量的一致性，引入了一种新的优化方法，提出了一次和二次约束条件，解决了恢复一个或两个焦距的问题。并讨论了四种可能的情况，通过求解多项式方程来解决这些问题，提出了高效的求解技术。评估结果证明了新方法在速度和准确性上的优势。", "conclusion": "本文提出的方法能够在多种情况下有效恢复焦距，可以通过Sturm序列或隐变量技术高效地解决多项式方程，并且在速度和准确性上优于现有的两视图方法。相关代码和数据可以在指定的链接下载。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.16924", "html_url": "https://arxiv.org/abs/2503.16924", "title": "Optimized Minimal 3D Gaussian Splatting", "title_en": "Optimized Minimal 3D Gaussian Splatting", "authors": "Joo Chan Lee,Jong Hwan Ko,Eunbyung Park", "background": "3D Gaussian Splatting (3DGS)已成为实时高性能渲染的强大表示法，广泛应用于各种场景。然而，使用大量显式高斯原语表示3D场景会带来显著的存储和内存开销。尽管有研究显示，高精度属性可以大幅减少所需高斯的数量而不影响渲染质量，但现有3DGS压缩方法仍依赖于相对较多的高斯原语，主要侧重于属性压缩。由于较少数量的高斯原语对失真属性压缩更加敏感，质量会严重下降，而高斯原语的数量直接影响计算成本。", "innovation": "本文提出了优化最小高斯表示法(OMG)，显著减少了存储需求的同时仅使用少量的原语。OMG首先通过最小化冗余但不牺牲质量来确定独特的高斯，然后提出一种紧凑且精确的属性表示方法，有效地捕捉了原语之间的一致性和不规则性。此外，OMG还提出了一种子向量量化技术，增强了不规则性表示，同时保持了快速训练和微小的码本大小。实验表明，与之前最先进的方法相比，OMG减少了近50%的存储需求，并在不影响渲染质量的情况下实现了600+ FPS的渲染。", "conclusion": "通过OMG方法，实现了3DGS的存储需求显著减少和渲染质量的保持，同时提高了计算效率。代码可以在以下链接获取：this https URL。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.18469", "html_url": "https://arxiv.org/abs/2503.18469", "title": "CFReID: Continual Few-shot Person Re-Identification", "title_en": "CFReID: Continual Few-shot Person Re-Identification", "authors": "Hao Ni,Lianli Gao,Pengpeng Zeng,Heng Tao Shen,Jingkuan Song", "background": "实时监视系统在不断变化，亟需一种能够处理不断涌入的各种领域新数据的人重识别模型。Lifelong ReID (LReID) 能够在多个领域间增量学习和积累知识，但在每个未知的领域中，LReID 模型仍需在大量带标签数据上进行训练，这些数据往往由于隐私和成本问题而不易获取。作者提出了 Continual Few-shot ReID (CFReID)，旨在解决在少量标注数据下进行增量训练和测试的问题，同时解决学习未知领域少量标注数据的知识和防止已学习领域知识遗忘的挑战。", "innovation": "作者提出了一种新的 Continual Few-shot ReID (CFReID) 架构，该架构利用少量标注数据进行增量学习和测试。该架构包含一种从特征分布视角构建的稳定分布对齐（SDA）框架，该框架包括元分布对齐（MDA）和基于原型的少量样本适应（PFA）两个模块，主要解决学习未知领域少量样本数据的知识和防止遗忘已学习领域知识这两个挑战。此外，还建立了基于五个公开可用重识别数据集的评估基准，实验证明，SDA 可显著提升少量样本学习和抗遗忘能力。与 Lifelong ReID 相比，仅使用 5% 数据（32 个身份）就能显著超越目前的最好表现。", "conclusion": "本研究表明，使用 Continual Few-shot ReID (CFReID)，借助少量标注数据，即使在动态环境下，也能够有效进行人重识别，且模型的稳定性和遗忘控制有所增强。该方法具有广阔的应用前景和实际价值。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.05306", "html_url": "https://arxiv.org/abs/2504.05306", "title": "CREA: 一种用于创造性图像编辑与生成的多方协作框架", "title_en": "CREA: A Collaborative Multi-Agent Framework for Creative Image Editing and Generation", "authors": "Kavana Venkatesh,Connor Dunlop,Pinar Yanardag", "background": "AI在图像生成方面的创造力仍然是一个基本挑战，不仅需要生成视觉上吸引人的内容，还需要能够添加新颖、富有表现力和艺术充实的图像变换。传统编辑任务依赖于直接基于提示的修改，而创造性图像编辑则需要一种自主、迭代的方法，平衡原创性、连贯性与艺术意图。", "innovation": "本文介绍了一种名为CREA的新型多方协作框架，模仿人类的创造过程。该框架利用一组专门的AI代理动态协作，进行概念化、生成、评估和增强图像。通过广泛的定性和定量评估，CREA在多样性、语义对齐和创造性变换方面显著优于现有最先进的方法。这是首次提出创造性编辑任务的研究。", "conclusion": "CREA在创造性图像编辑和生成中取得了显著的成果，证明了多方协作框架在创造性任务中的潜力，为未来研究提供了新的方向。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.08614", "html_url": "https://arxiv.org/abs/2505.08614", "title": "WaveGuard：通过双树复小波和图神经网络实现稳健的深度伪造检测与溯源", "title_en": "WaveGuard: Robust Deepfake Detection and Source Tracing via Dual-Tree Complex Wavelet and Graph Neural Networks", "authors": "Ziyuan He,Zhiqing Guo,Liejun Wang,Gaobo Yang,Yunfeng Diao,Dan Ma", "background": "深度伪造技术在不断发展，带来了诸如隐私侵犯和身份盗窃等日益增加的风险。为应对这些威胁，本研究提出了一种名为WaveGuard的新型水印框架，通过频域嵌入和基于图的结构一致性增强水印的鲁棒性和隐蔽性。", "innovation": "WaveGuard框架通过使用双树复小波变换（DT-CWT）将水印嵌入高频频带，并利用结构一致性图神经网络（SC-GNN）保持视觉质量。同时，设计了注意力模块来提高嵌入精度。", "conclusion": "在面部替换和重新演绎任务上的实验表明，WaveGuard在鲁棒性和视觉质量方面均优于现有的最先进方法。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.07416", "html_url": "https://arxiv.org/abs/2504.07416", "title": "RadZero：基于相似性的跨注意力在胸部X光解释性视觉-语言对齐中的零样本多任务能力", "title_en": "RadZero: Similarity-Based Cross-Attention for Explainable Vision-Language Alignment in Chest X-ray with Zero-Shot Multi-Task Capability", "authors": "Jonggwon Park,Byungmu Yoon,Soobum Kim,Kyoyun Choi", "background": "近年来，在医学成像中的多模态模型显著提升了影像学中视觉-语言（VL）对齐的准确性。然而，现有的方法在利用复杂医学报告和提供关注点概率可视化以增强解释性方面表现欠佳。为了解决这些问题，该论文提出了一种新颖框架RadZero，旨在通过结合零样本多任务能力在胸部X光图像上进行可解释的视觉-语言对齐。", "innovation": "引入了VL-CABS（基于相似性的跨注意力），该方法可将文本嵌入与局部图像特征对齐，从而实现细粒度的可解释视觉-语言推理。RadZero还利用大型语言模型从医学报告中提取摘要性的语义句子，并采用多正样本对比训练来更有效地捕捉图像和多个相关文本描述之间的关系。此外，RadZero通过计算文本嵌入和局部图像块特征之间的相似性，实现文本与图像的零样本关系推理，生成的相似性概率映射有助于可解释的匹配功能。实验表明，RadZero在零样本分类、标注和分割方面优于现有最先进的方法，并且通过相似性映射分析显示了其提升解释性的潜力。", "conclusion": "实验结果证明，RadZero 在零样本分类、标注和分割任务上优于现有最先进的方法，并通过便携式符号映射分析展示了其在解释性匹配方面的潜力。质性评估还显示了 RadZero 在开放词汇语义分割中的能力，进一步验证了其在医学成像中的有效性。源代码可在指定链接找到。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.14516", "html_url": "https://arxiv.org/abs/2504.14516", "title": "重返正轨：动态场景重建中的束调整", "title_en": "Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction", "authors": "Weirong Chen,Ganlin Zhang,Felix Wimbauer,Rui Wang,Nikita Araslanov,Andrea Vedaldi,Daniel Cremers", "background": "传统的SLAM系统依赖于束调整，但在处理常见的非正式视频中的高动态场景时遇到困难。这些视频包含了动态元素的运动，这违背了传统系统对静态环境的假设。现有技术要么滤除动态元素，要么独立建模它们的运动。前者的缺点是导致构建不完整，后者的缺点则可能产生不一致的运动估计。", "innovation": "本文提出了一种新颖的方法，利用3D点跟踪器将由相机引起的运动与动态物体的观测运动区分开。通过仅考虑由相机引起的组件，束调整可以可靠地应用于场景的所有元素。此外，通过基于尺度图的轻量级后处理来确保跨视频帧的深度一致性。该框架结合了传统SLAM的核心技术——束调整——与一个鲁棒的学习3D追踪前端。联合运动分解、束调整和深度细化，我们的统一框架BA-Track能够准确跟踪相机运动并生成时间和尺度都一致的密集重建结果，同时包含静态和动态元素。", "conclusion": "我们对具有挑战性的数据集进行了实验，展示了在相机姿态估计和3D重建精度方面的显著改进。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12795", "html_url": "https://arxiv.org/abs/2504.12795", "title": "EarthGPT-X：视觉提示下多源多层次遥感图像理解的时空大模型", "title_en": "EarthGPT-X: A Spatial MLLM for Multi-level Multi-Source Remote Sensing Imagery Understanding with Visual Prompting", "authors": "Wei Zhang,Miaoxin Cai,Yaqian Ning,Tong Zhang,Yin Zhuang,Shijian Lu,He Chen,Jun Li,Xuerui Mao", "background": "近年来，自然域多模态大规模语言模型（MLLMs）在通过视觉和文本提示进行空间推理方面取得了显著进展。然而，这些模型在直接应用于遥感（RS）领域时遇到了异构感测物理、多元模态和独特空间尺度的阻碍，导致现有的RS MLLMs主要局限于光学影像和简单语言交互，无法实现弹性和可扩展的实际应用。", "innovation": "地球GPT-X（EarthGPT-X）是首个统一多种遥感影像理解和在多种视觉提示下完成粗粒度和细粒度视觉任务的灵活空间大模型。EarthGPT-X 改进了以下方面：1）双提示机制，结合文本指令与各种视觉提示（如点、盒子和自由形式）来模仿人类生活的指代灵活性；2）全面的多源多层次提示数据集，使模型能够从整体图像理解推进到支持分层空间推理，包括场景级别的理解以及细粒度物体属性和关系分析；3）跨领域的一站式融合训练策略，实现了模态和任务的高效且一致的对齐。广泛实验表明，EarthGPT-X 显著优于之前的自然和RS MLLMs，初步建立了可以在遥感场景中使用视觉提示进行多源、多任务和多层次解释的第一个框架。", "conclusion": "地球GPT-X在遥感场景下实现了多元视觉提示的多层次遥感图像理解，展示了在该领域中前所未有的能力，有效地推进了多模态和空间推理的发展。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11881", "html_url": "https://arxiv.org/abs/2505.11881", "title": "重新审视残差连接：稳定高效深度网络的正交更新", "title_en": "Revisiting Residual Connections: Orthogonal Updates for Stable and Efficient Deep Networks", "authors": "Giyeong Oh,Woohyun Cho,Siyeol Kim,Suhwan Choi,Youngjae Yu", "background": "残差连接对于深度神经网络至关重要，它们通过缓解梯度消失问题支持更深层的网络训练。然而，在标准的残差更新中，模块的输出直接加到输入流中。这可能导致更新主要增强或调整现有流的方向，从而可能未能充分利用模块学习全新特征的能力。", "innovation": "本文提出了一种正交残差更新：将模块输出相对于输入流进行分解，并仅添加与该流正交的分量。该设计旨在引导模块主要贡献全新表示方向，从而促进更丰富的特征学习，并促进更有效的训练。实验结果表明，该正交更新策略在多种架构（ResNetV2、视觉变换器）和数据集（CIFARs、TinyImageNet、ImageNet-1k）上提高了泛化准确性和训练稳定性，例如在ImageNet-1k数据集上ViT-B的顶级准确率提高了3.78个百分点", "conclusion": "正交残差更新策略在不同深度学习架构和数据集上表现出显著的优势，为稳定高效的深度网络训练提供了新的视角。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16239", "html_url": "https://arxiv.org/abs/2505.16239", "title": "DOVE: 效率高的实时视频超分辨率一阶扩散模型", "title_en": "DOVE: Efficient One-Step Diffusion Model for Real-World Video Super-Resolution", "authors": "Zheng Chen,Zichen Zou,Kewei Zhang,Xiongfei Su,Xin Yuan,Yong Guo,Yulun Zhang", "background": "扩散模型已在实际视频超分辨率（VSR）应用中展现了出色的性能。然而，这些模型所需的众多采样步骤使其推理过程极其缓慢。基于单步的采样加速技术为解决这个问题提供了一种潜在的方法，但实现在VSR任务中的单步动作仍是一项挑战，主要由于在视频数据上的高训练开销和苛刻的保真度要求。", "innovation": "本文提出了一种名为DOVE的一阶扩散模型，旨在解决实际视频超分辨率中的效率问题。DOVE通过微调预训练的视频扩散模型（即CogVideoX）获得，并采用了潜像素训练策略来有效训练DOVE模型。此外，还设计了一条视频处理流水线来构建一个专门用于VSR任务的高质量数据集HQ-VSR，从而进一步提升了DOVE的恢复能力。实验证明，DOVE与多步扩散模型相比表现相当甚至更优，并且具有显著的推理效率，相较于现有方法提高了28倍以上。", "conclusion": "实验结果表明，DOVE在与多步扩散模型相当或更优的性能上提供了更高的推理效率，并且已获得该方法的一个显著速度提升，达到了28倍的加速效果。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19853", "html_url": "https://arxiv.org/abs/2505.19853", "title": "视频堆中的两个因果相关刺针", "title_en": "Two Causally Related Needles in a Video Haystack", "authors": "Miaoyu Li,Qin Chao,Boyang Li", "background": "在现有基准下评估视频语言模型（VLMs）理解长视频的能力仍然具有挑战性。现有的基准主要关注简单的问题，而忽略了全面评估模型在从长视频中提取和理解来自两个不同位置的信息以及建模因果关系（如人类行为中的因果关系）方面的能力。因此，迫切需要一种能够评估这些复杂能力和避免文本偏见的新基准。", "innovation": "该研究提出了Causal2Needles基准，这是一个评估视频语言模型在处理来自长视频中两个不同位置的因果相关信息及其建模能力的复杂任务。Causal2Needles使用不同类型的问题（非因果单针、因果单针和因果双针问题）来评估这些能力，特别是因果双针问题是最复杂的，要求模型从两个引起事件及其相关的叙述文本中提取信息。研究还通过引入两种互补的问题格式来防止文本偏见：定位包含答案的视频剪辑，或描述该视频剪辑中的视觉细节。", "conclusion": "实验结果显示，在现有基准上表现出色的模型在因果双针问题上的表现较差，并且模型性能与两个针之间的距离呈负相关。这些发现突显了目前VLMs存在的关键局限性。该数据集可在此处访问：[链接]。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20426", "html_url": "https://arxiv.org/abs/2505.20426", "title": "MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness", "title_en": "MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness", "authors": "Yolo Yunlong Tang,Pinxin Liu,Zhangyun Tan,Mingqian Feng,Rui Mao,Chao Huang,Jing Bi,Yunzhong Xiao,Susan Liang,Hang Hua,Ali Vosoughi,Luchuan Song,Zeliang Zhang,Chenliang Xu", "background": "人类视觉感知的基础是理解视角，然而，多模态大型语言模型（MLLMs）对视角几何的理解程度还不清楚。本文介绍MMPerspective，首次专门设计的评估MLLMs对视角理解的基准，包含10个精心设计的任务，从三个互补维度评估：视角感知、推理、鲁棒性。基准数据集包含2,711个真实和合成图像实例，以及5,083个问题-答案对，检测关键能力，如消失点感知、计数、视角类型推理、三维空间中的线关系理解等。", "innovation": "MMPerspective引入了一个新的基准，评估MLLMs对视角的理解，特别设计了10个任务涉及视角感知、推理和鲁棒性。该基准测试了43个最新的MLLMs，揭示了模型在表面感知任务上的表现良好，但在组合推理和扰动下的空间一致性保持方面存在显著局限。同时，分析展示了模型架构、规模与视角能力之间的有趣模式，突显了鲁棒性瓶颈和链式思考提示的优势。", "conclusion": "MMPerspective为视觉-语言系统空间理解的诊断和改进提供了有价值的试验场，证明了该基准的重要性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23769", "html_url": "https://arxiv.org/abs/2505.23769", "title": "TextRegion：从冻结的图像-文本模型生成对齐的区域token", "title_en": "TextRegion: Text-Aligned Region Tokens from Frozen Image-Text Models", "authors": "Yao Xiao,Qiqian Fu,Heyi Tao,Yuqun Wu,Zhen Zhu,Derek Hoiem", "background": "图像-文本模型在图像级任务上表现出色，但在细节视觉理解方面存在不足。尽管这些模型在视觉-语言对齐上表现出色，但类似SAM2的分割模型可以提供精确的空间边界。\n", "innovation": "提出了一种名为TextRegion的简单、有效且无需训练的框架，该框架结合了图像-文本模型和SAM2的优点，生成有力的文本对齐区域token。这些token能够提供详细的视觉理解，同时保持开放词汇能力。它们可以直接应用于各种下游任务，包括开放世界的语义分割、指示词句理解和语义蕴含。\n", "conclusion": "进行了广泛的评估，并在与最新的训练免费方法相比时，始终获得了优越或竞争性的性能。此外，该框架与许多图像-文本模型兼容，在强大模型出现时，非常实用且易于扩展。代码可在：this https URL 获取。\n"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.01802", "html_url": "https://arxiv.org/abs/2506.01802", "title": "UMA：多级表面对齐实现超详细的人形avatar", "title_en": "UMA: Ultra-detailed Human Avatars via Multi-level Surface Alignment", "authors": "Heming Zhu,Guoxing Sun,Christian Theobalt,Marc Habermann", "background": "三维动画技术中的关键研究问题是通过多视角视频学习一个具备生动动态和逼真外观的可动画人物模型。近期隐式表征的进展提高了这种可动画人物的品质，但是它们往往在细节上有所缺失，尤其是在高分辨率渲染和近距离观察时更为明显。这主要是由于表面跟踪不准确，包括深度对齐和几何形状面的变化不一致，导致详细外观模型需要补偿几何错误。", "innovation": "文章提出了一种潜变量变形模型，并通过2D视频点跟踪器的指导来监督变形，增强了对阴影和表面变化的抵抗能力，避免局部极小值的现象。为了减少点跟踪器的时间漂移和缺乏三维意识，引入了一种级联训练策略，通过与渲染角色的路径锚定生成一致的三维点轨迹，最终在顶点和纹理级别监督我们的avatar。文章还介绍了一个新颖的数据集，包括五个多视角视频序列，每个序列超过10分钟，使用40个校准的6K分辨率相机捕捉穿着具有挑战性纹理图案和皱纹变形服饰的人物。", "conclusion": "文章的方法在渲染质量和几何准确性上显著优于之前的最先进方法。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02938", "html_url": "https://arxiv.org/abs/2506.02938", "title": "MIND: 从UDFs生成材料界面进行非流形曲面重建", "title_en": "MIND: Material Interface Generation from UDFs for Non-Manifold Surface Reconstruction", "authors": "Xuhui Chen,Fei Hou,Wencheng Wang,Hong Qin,Ying He", "background": "未受拓扑约束的shape在3D深度学习中常用unsigned distance fields (UDFs) 表示。虽然先前的工作主要关注从点云或多视图图像学习UDFs，但提取从UDFs的mesh仍然具有挑战性，因为学习到的field很少能达到精确的零距离。一种常见的解决方法是从UDFs局部重建signed distance fields (SDFs)，以支持通过Marching Cubes进行表面提取。然而，这种做法常引入拓扑错误，如孔隙或虚假组件。此外，局部SDF无法表示非流形几何，导致无法处理非流形几何的情况。", "innovation": "本文提出了一种新颖的算法MIND（Material Interface from Non-manifold Distance fields），直接从UDFs生成材料界面，支持非流形mesh的全局提取。方法的核心是从UDFs推导出有意义的空间分割，目标表面作为不同区域之间的界面。通过计算两签局部场来区分流形片段的两侧，并扩展到多标签全局场来分离非流形结构的所有侧。结合输入的UDFs和多标签场，使用多标签Marching Cubes算法构造支持非流形mesh提取的材料界面。", "conclusion": "在来自不同数据源的UDFs上进行的广泛实验表明，本文的方法能够稳健地处理复杂非流形表面，并比现有方法表现出更优的性能。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.15980", "html_url": "https://arxiv.org/abs/2506.15980", "title": "使用压缩和量化多条件标记化的高级手语视频生成", "title_en": "Advanced Sign Language Video Generation with Compressed and Quantized Multi-Condition Tokenization", "authors": "Cong Wang,Zexuan Deng,Zhiwei Jiang,Yafeng Yin,Fei Shen,Zifeng Cheng,Shiping Ge,Shiwei Gan,Qing Gu", "background": "手语视频生成（SLVG）旨在从语音文本生成保持身份的手语视频。现有方法主要依赖于单个粗略条件（如骨架序列）作为中介来连接翻译模型和视频生成模型，这限制了生成视频的自然性和表现力。", "innovation": "提出了一种名为SignViP的新颖SLVG框架，引入了多个精细条件以提高生成保真度。SignViP采用离散标记化范式来整合和表示精细条件（即精细的手姿和3D手掌）。SignViP包含三个核心组件：手语视频扩散模型、有限标量量化自动编码器和多条件标记翻译器。这些组件协同工作，显著提高了生成视频的质量、时序连贯性和语义保真度。", "conclusion": "实验结果表明，SignViP在多个指标上达到了最先进的性能，包括视频质量、时序连贯性以及语义保真度。代码可在指定链接处获得。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.13757", "html_url": "https://arxiv.org/abs/2506.13757", "title": "AutoVLA：具有自适应推理和强化微调的端到端视觉-语言-动作模型", "title_en": "AutoVLA: A Vision-Language-Action Model for End-to-End Autonomous Driving with Adaptive Reasoning and Reinforcement Fine-Tuning", "authors": "Zewei Zhou,Tianhui Cai,Seth Z. Zhao,Yun Zhang,Zhiyu Huang,Bolei Zhou,Jiaqi Ma", "background": "近期，视觉-语言-动作(VLA)模型在通过世界知识和推理能力进行端到端自动驾驶方面表现出很大的潜力。然而，当前的VLA模型往往面临生成物理上不可行的行为输出、复杂模型结构或不必要的长时间推理等问题。", "innovation": "本文提出了一种新型的VLA模型AutoVLA，它在单一自回归生成模型中统一了推理和行为生成，用于端到端的自动驾驶。AutoVLA直接从原始视觉输入和语言指令进行语义推理和轨迹规划，将连续轨迹分段为离散、可行的动作，以直接集成到语言模型中。此外，通过监督微调方法赋予模型快速思考（仅轨迹）和慢速思考（增强的推理链）。在进一步增强规划性能和效率的同时，引入基于组相对策略优化（GRPO）的强化微调方法，以在简单情况下减少不必要的推理。", "conclusion": "在nuPlan、nuScenes、Waymo和CARLA等真实世界和模拟数据集及基准测试中，进行了大量实验，结果表明AutoVLA在开环和闭环设置中表现出了竞争力。定性的实验结果展示了AutoVLA在各种场景下的适应性推理和精确规划能力。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10528", "html_url": "https://arxiv.org/abs/2508.10528", "title": "Med-GLIP：大规模临床上语义导向数据集推动多模态预训练", "title_en": "Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset", "authors": "Ziye Deng,Ruihan He,Jiaxiang Liu,Yuan Wang,Zijie Meng,Songtao Jiang,Yong Xie,Zuozhu Liu", "background": "医学图像定位旨在将自然语言短语与医学图像中的特定区域对齐，是智能诊断、视觉问答（VQA）和自动化报告生成（MRG）任务的基础。现有的研究受到模态覆盖率有限、粗略标注以及缺乏统一且可泛化的接地框架的限制。", "innovation": "本文构建了一个包含超过530万个区域级别的大规模医学接地数据集Med-GLIP-5M，覆盖七种成像模态，囊括各种解剖结构和病理发现。基此，提出了一种体模态感知的接地框架Med-GLIP，该框架通过从多样化的训练数据中隐式学习层次语义理解，从而能够识别不同级别的结构，如区分肺部与肺炎病灶。大量实验表明，Med-GLIP在多个接地基准测试中均优于最先进的基线方法。进一步将其实空间输出整合入下游任务（如医学VQA和报告生成），可实现显著的性能提升。", "conclusion": "我们的数据集即将发布，这将为医学图像和自然语言处理领域带来重要进展。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.09958", "html_url": "https://arxiv.org/abs/2509.09958", "title": "通过视觉语言真/假验证实现零样本指代表达理解", "title_en": "Zero-Shot Referring Expression Comprehension via Vison-Language True/False Verification", "authors": "Jeffrey Liu,Rongbin Hu", "background": "当前，指代表达理解（REC）通常通过任务特定训练的接地模型来解决。然而，该研究提出了一种无需特定训练的零样本工作流程，表明可以在 REC 上达到竞争力或更优的表现。", "innovation": "提出了一种将 REC 形式化为框级别视觉语言验证的方法。该方法利用通用目标检测器（YOLO-World）产生的建议框，通过通用视觉语言模型（VLM）对每个区域进行真/假查询，以此减少框间干扰，支持弃权和多匹配，并且不需要微调。实验结果显示该方法不仅超过了一个零样本 GroundingDINO 基线，还优于在 REC 和 GroundingDINO+CRG 上训练的 GroundingDINO 的报告结果。此外，限定性研究证实了这种验证方法在开放性视觉语言模型上的效果更优。", "conclusion": "该研究展示了工作流程设计而非任务特定预训练是推动强大零样本指代表达理解表现的关键因素。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.04704", "html_url": "https://arxiv.org/abs/2506.04704", "title": "HoliSafe：全面的安全基准和建模方法以提升视觉语言模型的安全性", "title_en": "HoliSafe: Holistic Safety Benchmarking and Modeling for Vision-Language Model", "authors": "Youngwan Lee,Kangsan Kim,Kwanyong Park,Ilcahe Jung,Soojin Jang,Seanie Lee,Yong-Ju Lee,Sung Ju Hwang", "background": "尽管有新兴的努力来提高视觉语言模型（VLMs）的安全性，但现有的安全调整数据集和基准测试仅部分考虑了图像与文本交互可能产生的有害内容，常忽视了看似无害的配对所带来的情境安全隐患。此外，先前的方法主要依赖于数据驱动的调整，缺乏对模型内在安全性的结构性增强。这些不足引发了现有VLMs在未知配置中容易受到漏洞攻击的风险，同时也限制了VLMs在安全方面的表现。", "innovation": "本文通过引入一个全面的安全数据集和基准测试HoliSafe，涵盖了所有五种安全/不安全的图像-文本组合，为训练和评估提供了更牢固的基础。HoliSafe-Bench提高了VLMs的安全性能。进一步提出了一种名为视觉防护模块（VGM）的新型模块化框架，该模块用于评估输入图像对VLMs的潜在危害性。这使得VLMs不仅仅能够学习生成更安全的响应，还能够提供具有解释性的有害性分类，以支持其拒绝决策。此外，VGM作为一个插件组件设计，便于与不同规模和不同类型的预训练VLMs无缝集成。实验表明，使用HoliSafe训练的Safe-VLM与VGM配合后，在多个VLM基准测试中均表现出最佳的安全性能。同时，HoliSafe-Bench揭示了现有VLM模型的关键漏洞，这将促进对稳健性和可解释性VLM安全性的进一步研究，扩大了未来多模态对齐的研究方向。", "conclusion": "HoliSafe和VGM有望激发更多关于视觉语言模型安全性的研究，致力于开发更稳健、更可解释的VLMs，并为多模态对齐提供更多可能的路径。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16802", "html_url": "https://arxiv.org/abs/2506.16802", "title": "注重关键要素：基于法医导向增强的通用AI生成视频检测", "title_en": "Seeing What Matters: Generalizable AI-generated Video Detection with Forensic-Oriented Augmentation", "authors": "Riccardo Corvi,Davide Cozzolino,Ekta Prashnani,Shalini De Mello,Koki Nagano,Luisa Verdoliva", "background": "合成视频生成技术正在快速发展，最新的模型可以生成极为逼真的高分辨率视频，几乎与真实视频无法区分。尽管已经提出了多种视频取证检测器，但这些检测器通常表现出较差的泛化能力，限制了它们在真实世界环境中的应用。现有的检测器往往依赖于高级语义特征来识别特定模型中的问题，这种依赖性导致了较低的泛化能力。研究者们认识到，为了克服这些问题，需要引导检测器专注于识别由生成架构引入的固有低级特征，而不仅仅是依赖于特定模型的特点。", "innovation": "本文提出了一种新的法医导向增强数据增强策略，这种方法基于小波分解，并替换特定频率相关带宽来引导模型更多地利用相关的法医线索。通过这种方法，研究者提出了一种新的训练范式，可以提高AI生成视频检测器的泛化能力，无需复杂的算法和包含多个合成生成器的大数据集。尽管方法相对简单，但在多个不同模型生成的视频上的测试结果表明，这种方法显著优于现有的最先进的检测器，并且即使在最新的生成模型，如NOVA和FLUX上也能取得优异的结果", "conclusion": "研究者通过基于单个生成模型的数据训练检测器，并在其他多种生成模型生成的视频上测试其性能，证明了提出的法医导向增强方法在提升AI生成视频检测器的泛化性方面的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.08027", "html_url": "https://arxiv.org/abs/2509.08027", "title": "MCTED：基于火星影像的数字高程模型生成的机器学习就绪数据集", "title_en": "MCTED: A Machine-Learning-Ready Dataset for Digital Elevation Model Generation From Mars Imagery", "authors": "Rafał Osadnik,Pablo Gómez,Eleni Bohacek,Rickbir Bahia", "background": "该研究提出了一种新的火星数字高程模型（DEM）预测数据集，名为MCTED。该数据集基于Day等人的高分辨率火星正射影像和DEM配对数据通过一个全面的处理管道生成，涵盖了火星各类地形特征，共有80,898个样本。由于大规模DEM生成过程中复杂的处理管道可能会导致原始数据中的瑕疵和丢失数据点，研究团队为此开发了相应的工具解决或减轻这些问题的影响。该数据集确保在训练和验证数据集之间没有重叠区域，以避免数据泄漏，并提供了详细的统计信息，包括样本分布、高程值分布、坡度等。此外，还对一个小的U-Net架构进行了训练，并将其性能与DepthAnythingV2等单目深度估计模型进行了比较，在高程预测任务中表现出色。", "innovation": "该研究的创新之处在于，通过开发一个全面的处理管道，从火星影像中生成高质量的DEM高分辨率数据集MCTED。该数据集包括样本不可避免的瑕疵和缺失数据点的处理工具，以及相应的掩码信息，提供给未来的用户提供更多的灵活性。此外，该研究首次将小额UNet架构与深度估计基础模型在火星影像的高程预测任务中进行了比较，并展示了在特定数据集上的小模型优于基础模型的零样本性能。", "conclusion": "该工作不仅提供了可以用于机器学习任务的高质量火星DEM数据集MCTED，还证明了基于该数据集训练的小模型在高程预测任务中的优越性能，甚至超过了类似DepthAnythingV2等深度估计基础模型的零样本性能。最后，数据集和生成代码已完全开源，供研究者参考使用。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.15482", "html_url": "https://arxiv.org/abs/2509.15482", "title": "使用表征相似性分析比较计算病理基础模型", "title_en": "Comparing Computational Pathology Foundation Models using Representational Similarity Analysis", "authors": "Vaibhav Mishra,William Lotter", "background": "计算病理学（CPath）中的基础模型正在不断发展，因为它们在促进诸多下游任务方面的潜力得到了认可。尽管最近的研究已经评估了不同模型在任务性能方面的表现，但对于这些模型学习表示的结构和变异性了解还较少。本研究表明，通过表征相似性分析，可以系统地分析六个CPath基础模型在H&E图像补丁上的表示空间，进一步揭示了不同模型之间的差异和共性，为模型的鲁棒性、集成策略以及训练范式对模型表示的影响提供了见解。", "innovation": "本研究使用计算神经科学中流行的方法对六个CPath基础模型进行了系统分析，并通过表征相似性分析发现了UNI2和Virchow2具有最独特的表示结构，而Prov-Gigapath则显示出最高的平均相似性。此外，研究还发现，尽管同一种训练范式下模型的表示相似性并不一定更高，且所有模型的表示显示出较高的幻灯片依赖性和较低的疾病依赖性。此外，实验还展示了标准化染料如何减少幻灯片依赖性，并揭示了视觉语言模型相对于仅视觉模型而言较为紧凑的表示特征。这些发现为提高模型对幻灯片特定特征的稳健性，指导模型集成策略以及理解训练范式如何塑造模型表示提供了新的机会与见解。", "conclusion": "研究结果强调了在医疗成像领域探究基础模型内部表示的重要性，这将有助于支持基础模型的有效开发和部署，并提供了有关不同训练范式如何塑造模型表示的关键见解。研究框架可以扩展到医疗成像的其他领域，通过探究基础模型的内部表示来支持其有效开发和部署。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14955", "html_url": "https://arxiv.org/abs/2510.14955", "title": "RealDPO: 真实还是不真实，这就是偏好", "title_en": "RealDPO: Real or Not Real, that is the Preference", "authors": "Guo Cheng,Danni Yang,Ziqi Huang,Jianlou Si,Chenyang Si,Ziwei Liu", "background": "视频生成模型在合成质量上已取得显著进展，但在生成复杂动作方面仍面临重大挑战。现有模型往往难以生成自然、平滑且上下文一致的动作。这种生成动作与现实世界动作之间的差距限制了模型的实用性。", "innovation": "引入了RealDPO，这是一种新的对齐范式，利用真实世界数据作为正样本进行偏好学习，使运动合成更加准确。RealDPO采用定制损失函数的直接偏好优化（DPO）方法，增强了运动的真实感，通过将现实世界视频与模型错误输出进行对比，实现迭代自我纠正，逐步提高运动质量。此外，提出了RealAction-5K，这是一个高质量的人类日常活动视频数据集，包含丰富的精确运动细节，以支持复杂运动合成的后续训练。", "conclusion": "广泛的实验表明，RealDPO在视频质量、文本对齐和运动真实性方面显著优于现有模型和现有的偏好优化技术。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22993", "html_url": "https://arxiv.org/abs/2509.22993", "title": "Hemorica：用于自动脑出血分类、分割和检测的全面CT扫描数据集", "title_en": "Hemorica: A Comprehensive CT Scan Dataset for Automated Brain Hemorrhage Classification, Segmentation, and Detection", "authors": "Kasra Davoodi,Mohammad Hoseyni,Javad Khoramdel,Reza Barati,Reihaneh Mortazavi,Amirhossein Nikoofard,Mahdi Aliyari-Shoorehdeli,Jaber Hatam Parikhan", "background": "颅内出血（ICH）的及时诊断对于CT扫描仍是一个临床优先问题。然而，由于公共数据碎片化，开发健壮的人工智能（AI）解决方案仍受阻碍。开发一个统一、精细的基准，支持多任务和渐进学习，以及与更大但标注较弱的群体进行迁移是医学影像分析领域的重要需求。", "innovation": "Hemorica是一个公开可用的数据集，包含从2012年到2024年的372个头部CT检查。该数据集详细标注了五种ICH亚型（硬膜外、硬膜下、蛛网膜下腔、脑实质和脑室），提供了患者级和切片级分类标签、亚型特异性边界框、二维像素掩码和三维体素掩码。通过双阅片流程（先导共识阶段和神经外科医师审理）保持了较低的阅片者间变异性，并进行了全面的统计分析验证了数据集的临床现实性。利用标准的卷积神经网络和变压器架构对二值切片分类和出血分割进行了微调，结果表明轻量级模型MobileViT-XS和U-Net在二值分类中的F1分数分别为87.8%，U-Net在二值病变分割中获得了Dice分数85.5%。", "conclusion": "Hemorica为基于AI的ICH检测和量化的系统设计提供了一个统一、精细的基准支持，促进了对更大但标注较弱群体的迁移，以及多任务和渐进学习的设计。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.21814", "html_url": "https://arxiv.org/abs/2510.21814", "title": "Gestura：一种动力学和语义结合的LVLM驱动实时自由手势理解系统", "title_en": "Gestura: A LVLM-Powered System Bridging Motion and Semantics for Real-Time Free-Form Gesture Understanding", "authors": "Zhuoming Li,Aitong Liu,Mengxi Jia,Yubi Lu,Tengxiang Zhang,Changzhi Sun,Dell Zhang,Xuelong Li", "background": "自由手势理解在人机交互中高度吸引人，因为它使用户摆脱了预定义手势类别的限制。然而，目前唯一已存在的解决方案GestureGPT存在识别精度有限和响应时间慢的问题。", "innovation": "本文提出了一种端到端的系统Gestura，用于自由手势理解。Gestura利用预训练的大规模视觉-语言模型（LVLM）将自由手势的高度动态和多样化模式与高层语义概念对齐。为更好地捕捉不同风格的手部细微动作，Gestura引入了地标处理模块，通过嵌入解剖学手部先验知识来弥补LVLM的缺乏精细领域知识。进一步，采用链式思考（CoT）推理策略，逐步进行语义推理，将浅层知识转化为深层语义理解，显著增强了模型解释模糊或非传统手势的能力。", "conclusion": "这些组件使得Gestura能够实现稳健和适应性强的自由手势理解。此外，Gestura还开发了第一个用于自由手势意图推理解析的开源数据集，其中包括超过300,000个标注的问答对。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23116", "html_url": "https://arxiv.org/abs/2510.23116", "title": "图像恢复中的残差扩散桥梁模型", "title_en": "Residual Diffusion Bridge Model for Image Restoration", "authors": "Hebaixu Wang,Jing Zhang,Haoyang Chen,Haonan Guo,Di Wang,Jiayi Ma,Bo Du", "background": "扩散桥梁模型能够在任意配对分布之间建立概率路径，并在通用图像恢复中展现出巨大潜力。然而，现有的大多数方法仅仅将它们视为随机插值的简单变体，缺乏统一的分析观点。此外，这些方法简单地通过全局噪声的注入与去除重建图像，这会导致未退化区域的不可避免的失真。", "innovation": "提出了残差扩散桥梁模型（RDBM）。具体来说，理论性地重新制定了广义扩散桥梁的随机微分方程，并推导出其正向和逆向过程的解析公式。关键地，利用给定分布的残差来调节噪声的注入和去除，使得对退化区域进行适配恢复，同时保留完整的其他区域。此外，解析了现有桥梁模型的基本数学本质，所有这些模型都是RDBM的特殊情况，并通过实验展示了我们所提出的模型的优良性能。", "conclusion": "进行了广泛的实验，以展示我们的方法在不同类型图像恢复任务中都具有最先进的性能，无论是定性还是定量上。我们的代码已经公开可在 [此链接] 查看。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26149", "html_url": "https://arxiv.org/abs/2510.26149", "title": "BasicAVSR：通过图像先验和增强运动补偿实现任意尺度视频超分辨率", "title_en": "BasicAVSR: Arbitrary-Scale Video Super-Resolution via Image Priors and Enhanced Motion Compensation", "authors": "Wei Shang,Wanying Zhang,Shuhang Gu,Pengfei Zhu,Qinghua Hu,Dongwei Ren", "background": "视频超分辨率（AVSR）旨在提高视频帧的分辨率，可能在不同的缩放因子下进行，这对于空间细节的再现、时间一致性以及计算复杂度都提出了挑战。", "innovation": "本文提出了一种强大的基线模型BasicAVSR，通过整合四个关键组件来解决上述挑战：1）来自图像Laplacian金字塔的自适应多尺度频率先验；2）流指导传播单元，用于从相邻帧聚合时空信息；3）二阶运动补偿单元，以更精确地对齐相邻帧；4）超采样单元，生成尺度感知且内容无关的超采样核。此外，实例化了三种传播变体以满足不同的应用需求。", "conclusion": "通过广泛的实验结果表明，BasicAVSR在超分辨率质量、通用性和推理速度方面显著优于现有方法。我们的工作不仅推动了AVSR领域的前沿，还将其核心组件扩展到多个框架以适应多种场景。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22035", "html_url": "https://arxiv.org/abs/2510.22035", "title": "基于语句的解释性：通过CLIP探测CNN中的偏见", "title_en": "Caption-Driven Explainability: Probing CNNs for Bias via CLIP", "authors": "Patrick Koller(Northwestern University, Evanston, Illinois, United States),Amil V. Dravid(University of California, Berkeley, California, United States),Guido M. Schuster(Eastern Switzerland University of Applied Sciences, Rapperswil, St. Gallen, Switzerland),Aggelos K. Katsaggelos(Northwestern University, Evanston, Illinois, United States)", "background": "机器学习中的稳健性已成为一个关键问题。解释性人工智能（XAI）的目的是通过理解机器学习模型的行为来提高其稳健性。在计算机视觉问题中，生成显著性图是先进的XAI方法之一。显著性图高亮了图像中使模型最兴奋的像素空间。然而，如果存在重叠的像素空间并且包含不必要的特征，则这一性质可能会误导。因此，需要一种新的XAI方法来解决这个问题。", "innovation": "本文提出了一种基于描述符的XAI方法，通过将被解释的独立模型与CLIP模型进行新型网络手术合并。这种方法能够识别对模型预测贡献最大的主导概念，从而降低模型因条件异变而失效的风险，有助于开发更加稳健的机器学习模型。", "conclusion": "本研究提出了一种新的XAI方法，通过CLIP模型和网络手术结合被解释的独立模型，实现了对模型预测主导概念的识别，降低了条件异变的风险，有助于提升机器学习模型的稳健性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.01210", "html_url": "https://arxiv.org/abs/2511.01210", "title": "OmniVLA：具有统一多传感器感知的物理接地多模式VLA在机器人操作中的应用", "title_en": "OmniVLA: Physically-Grounded Multimodal VLA with Unified Multi-Sensor Perception for Robotic Manipulation", "authors": "Heyu Guo,Shanmu Wang,Ruichun Ma,Shiqi Jiang,Yasaman Ghasempour,Omid Abari,Baining Guo,Lili Qiu", "background": "视觉-语言-行动（VLA）模型通过大规模的视觉-语言预训练展示了在机器人行动预测中的强泛化能力。然而，现有的大多数模型仅依赖RGB摄像头，这限制了它们的感知能力，从而影响了操作能力。", "innovation": "提出了 OmniVLA，一种多模态VLA模型，通过整合新型传感模态（包括红外相机、毫米波雷达和麦克风阵列）增强了物理接地的空间智能，而无需仅依赖RGB感知。OmniVLA 通过传感器掩蔽图像实现了传感器与RGB图像的统一表示，此表示旨在保持传感器输入接近RGB统计数据，以便于训练，提供了跨硬件接口的统一接口，并允许使用轻量级传感器投影器进行高效学习。", "conclusion": "在挑战性的实际任务中，OmniVLA 在传感器模态感知指导的机器人操作中取得了平均任务成功率 84%，显著优于仅使用RGB和原生传感器输入的基线模型 59% 和 28%，展示出更高的学习效率和更强的泛化能力。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11190", "html_url": "https://arxiv.org/abs/2510.11190", "title": "FlexAC：迈向Multimodal Large Language Models中关联推理的灵活控制", "title_en": "FlexAC: Towards Flexible Control of Associative Reasoning in Multimodal Large Language Models", "authors": "Shengming Yuan,Xinyu Lyu,Shuailong Wang,Beitao Chen,Jingkuan Song,Lianli Gao", "background": "多模态大型语言模型（MLLMs）在忠实性和创造性之间存在固有的权衡，因为不同任务需要不同程度的关联推理。但现有方法缺乏调节这种推理强度的灵活性，限制了MLLMs在事实性和创造性场景中的适应性。本文研究了MLLMs内部驱动关联行为的机制并发现：（1）中间层对模型的关联倾向起关键作用；（2）修改这些层的表示有效调节了关联推理强度；（3）幻觉可以用作生成引导该调节的引导向量的工具。基于这些发现，文章提出了Flexible Association Control (FlexAC)框架，旨在调整MLLMs中的关联行为。FlexAC通过生成基于引导的中间表示来编码关联方向，选择了高关联实例以构建有效的引导向量，并适当地调整这些向量的强度来平衡创造指导和输出稳定性。最后，FlexAC通过使用来自目标域少量样本前向传递获取的任务特定的关联向量，考虑关联推理的多维性，使模型能够遵循多样的关联方向，更好地适应创造性任务。", "innovation": "FlexAC框架是一个轻量级且无需训练的框架，用于调节MLLMs中的关联行为。它首先通过生成基于幻觉的中间表示来编码关联方向，然后选择高关联样本构建有效的引导向量，这些向量的强度是根据创造性和输出稳定性之间的平衡进行适配调整的。此外，通过使用任务特定的关联向量，FlexAC能够使模型遵循多样化的关联方向，更好地适应创造性任务，从而提高了模型在创造性和减少幻觉方面的性能。", "conclusion": "我们的方法在Creative-MMBench上的创造性表现提升高达5.8倍，在CHAIR上的幻觉率降低了29%，超过了现有基线，展示了其在MLLMs中实现灵活控制关联推理的有效性。我们的代码可从此处获取：这个 https URL。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.01250", "html_url": "https://arxiv.org/abs/2511.01250", "title": "通过几何感知点丢失的源域跨天气LiDAR", "title_en": "Source-Only Cross-Weather LiDAR via Geometry-Aware Point Drop", "authors": "YoungJae Cheong,Jhonghyun An", "background": "现有LiDAR语义分割方法在恶劣天气条件下表现不佳，因为折射、散射和点丢失会破坏几何形状。尽管在天气模拟、基于混合的数据增强、领域随机化和不确定性或边界正则化方面已经取得了一些进展，但这些方法仍然未能充分解决边界、角落和稀疏区域附近的结构脆弱性。", "innovation": "本文提出了一种Light Geometry-aware适配器，该模块调整方位角并应用水平圆形填充以在0~360度环形边界上保持邻居连续性。通过局部窗口的K-最近邻算法收集邻近点并计算简单的局部统计，将这些统计压缩为紧凑的几何感知提示。在训练期间，这些提示引导区域感知的正则化，从而在结构脆弱区域稳定预测。该适配器插即用，能够与数据增强互补，并且可以在训练期间启用，几乎不会增加推理成本。", "conclusion": "在源域跨天气设置中，通过该适配器，模型在SemanticKITTI上训练并在SemanticSTF上评估时，无需目标标签或微调，mIoU分别提高了7.9个和0.6个百分点，表明基于几何的正则化是所有天气LiDAR分割的关键方向。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.03325", "html_url": "https://arxiv.org/abs/2511.03325", "title": "SurgViVQA：基于时间感知的手术场景视频问答", "title_en": "SurgViVQA: Temporally-Grounded Video Question Answering for Surgical Scene Understanding", "authors": "Mauro Orazio Drago,Luca Carlini,Pelinsu Celebi Balyemez,Dennis Pierantozzi,Chiara Lena,Cesare Hassan,Danail Stoyanov,Elena De Momi,Sophia Bano,Mobarak I. Hoque", "background": "现有的视频问答（VideoQA）在手术领域的应用主要是基于静态图像特征，而现有的数据集通常缺乏时间上的标注，忽略了过程动态特性对准确程序理解的重要性。因此，该研究旨在通过引入SurgViVQA模型，将视觉推理从静态图像扩展到动态手术场景，从而提升手术过程中的理解能力。", "innovation": "SurgViVQA模型利用遮蔽视频-文本编码器融合视频和问题特征，捕捉运动等时间线索，然后通过微调的大语言模型解码为连贯的答案。该研究还开发了REAL-Colon-VQA数据集，用于评价模型性能，该数据集包括与运动相关的问题和诊断属性，以及重新表述或语义修改的问题，以评估模型的稳健性。实验结果表明，与现有的基于图像的视频问答基准模型相比，SurgViVQA在关键字准确性上取得了显著的提升。研究成果为手术视频问答中时间感知理解提供了框架，使AI模型能够更有效地解释动态程序上下文。", "conclusion": "SurgViVQA和REAL-Colon-VQA数据集为手术视频问答中时间感知理解提供了一个框架，使AI模型能够更有效地解释动态程序上下文。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.01833", "html_url": "https://arxiv.org/abs/2511.01833", "title": "TIR-Bench: 一种全面的代理视觉推理基准", "title_en": "TIR-Bench: A Comprehensive Benchmark for Agentic Thinking-with-Images Reasoning", "authors": "Ming Li,Jike Zhong,Shitian Zhao,Haoquan Zhang,Shaoheng Lin,Yuxiang Lai,Chen Wei,Konstantinos Psounis,Kaipeng Zhang", "background": "视觉推理的前沿正在转向像OpenAI的o3这样的模型，这些模型能够智能地创建和操作工具来解决图像问题，即所谓的带图像思考。然而，现有的基准测试工具还无法完全捕捉到这种高级能力。目前最常用的基准测试，如视觉搜索，只测试基本操作（如定位和裁剪），这几乎没有提供关于更复杂的动态和工具依赖推理的洞察。", "innovation": "我们引入了TIR-Bench，这是一种全面的基准测试，用于评估带图像思考的代理能力，覆盖了13项不同的任务，每项任务都需要使用新颖的工具进行图像处理和操作，展现了链式思考的能力。我们评估了22个跨模态的大语言模型，包括开源和专有模型，以及那些明确增加了工具使用功能的模型。结果显示，TIR-Bench是一个普遍有挑战性的基准，要获得良好的表现需要真正具有带图像思考的能力。最后，我们还进行了一项初步研究，比较了直接和代理微调之间的差异。", "conclusion": "TIR-Bench 是一个全面的挑战性基准测试，可以用来评估大语言模型的带图像思考能力。这种能力要求模型能够执行复杂的交互操作和链式思考来解决图像问题。我们的实验表明，要在这项基准测试中取得好成绩，模型必须真正具备这种能力，而直接微调和代理微调之间的差异也值得进一步研究。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2511.01990", "html_url": "https://arxiv.org/abs/2511.01990", "title": "Geo-基础模型在洪水淹没地图构建中的价值评估：Sentinel-1、Sentinel-2和PlanetScope模型基准测试", "title_en": "Assessing the value of Geo-Foundational Models for Flood Inundation Mapping: Benchmarking models for Sentinel-1, Sentinel-2, and Planetscope for end-users", "authors": "Saurabh Kaushik,Lalit Maurya,Elizabeth Tellman,ZhiJie Zhang", "background": "Geo-基础模型（GFMs）能够快速可靠地从卫星图像中提取时空信息，通过利用位置和时间嵌入改善洪水淹没图的绘制。然而，GFMs的效果是否优于传统的模型（如U-Net）尚未明确，尤其是在不同传感器和数据可用性场景下的系统性比较方面仍然缺乏，这直接影响了最终用户在模型选择方面的指导。", "innovation": "该研究通过系统性地比较Geo-基础模型（包括Prithvi 2.0、Clay V1.5、DOFA和UViT）、以及传统的U-Net和Attention U-Net在不同传感器（PlanetScope、Sentinel-1、Sentinel-2）下的表现，发现所有Geo-基础模型的性能较为相近，仅仅存在2-5%的差异。Clay模型在PlanetScope和Sentinel-2数据上表现最佳，而Prithvi模型在Sentinel-1数据上表现出色。Clay模型还展示了在所有传感器上的更好表现，并且在计算时间和参数量上更具优势。", "conclusion": "研究结果表明，Geo-基础模型在洪水地图构建中相比传统U-Net具有较小到适度的改进，并且具有更低的计算成本和标注努力。Clay模型在此过程中表现出色，建议优先使用。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.21088", "html_url": "https://arxiv.org/abs/2410.21088", "title": "Shallow Diffuse: 通过扩散模型中的低维子空间实现鲁棒且不可见的水印", "title_en": "Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models", "authors": "Wenda Li,Huijie Zhang,Qing Qu", "background": "随着AI生成内容（尤其是由扩散模型生成的图像）的广泛应用，虚假信息和版权侵权的问题引起了广泛关注。水印是一种关键的技术，用于识别这些AI生成的图像并防止其误用。", "innovation": "本文提出了一种新的水印技术——Shallow Diffuse，该技术通过在图像生成过程中的低维子空间中嵌入鲁棒且不可见的水印，不同于现有的方法在整个扩散采样过程中整合水印，Shallow Diffuse通过卸载这些步骤，确保水印大部分处于该子空间的零空间中，从而与图像生成过程分离，显著增强了数据生成的一致性和水印的可检测性。", "conclusion": "我们的理论和实际分析表明，这种解耦策略在鲁棒性和一致性方面极大地提高了数据生成和水印检测。广泛的实际实验进一步验证了我们的Shallow Diffuse在鲁棒性和一致性方面优于现有水印技术。相关代码已发布，供进一步参考。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2404.19604", "html_url": "https://arxiv.org/abs/2404.19604", "title": "X-Diffusion: 使用横截面扩散模型从单个图像生成详细3D MRI体积", "title_en": "X-Diffusion: Generating Detailed 3D MRI Volumes From a Single Image Using Cross-Sectional Diffusion Models", "authors": "Emmanuelle Bourigault,Abdullah Hamdi,Amir Jamaludin", "background": "磁共振成像（MRI）是重要的诊断工具，但高分辨率扫描往往因数据采集要求高而变得缓慢且昂贵。传统的MRI重建方法通过填充K空间中的缺失频率成分来加速过程，进行3D到3D的重建，这需要全面的3D扫描。因此，需要一种新的方法，能够在极少量的空间域输入情况下快速重建详细的3D MRI体积。", "innovation": "X-Diffusion是一种新颖的横截面扩散模型，能够从单个2D MRI切片或少量切片中重建详细的3D MRI体积。它将MRI数据视为整体的3D体积进行横截面训练和推理，不同于之前的方法将MRI扫描视为标准平面（冠状面、轴面、矢状面）中的2D切片集合。X-Diffusion不仅在未见数据上实现了最先进的技术（PSNR）的定量精度，还保留在肺肿瘤形状、脊椎曲度和大脑体积等关键解剖特征。此外，该模型在仅接受大脑数据训练的情况下成功重建了膝关节MRI。", "conclusion": "X-Diffusion是首个能够从高度受限的2D输入数据生成详细3D MRI体积的方法，有望加速MRI采集并减少相关成本。该模型在未接触的磁共振成像数据集上表现出色，并得到了临床专家的进一步验证，证明了其临床相关性和真实性。此研究还提供了代码链接以进行进一步的探索。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.04514", "html_url": "https://arxiv.org/abs/2410.04514", "title": "DAMRO: 潜入LVLM的注意力机制以减少物体幻觉", "title_en": "DAMRO: Dive into the Attention Mechanism of LVLM to Reduce Object Hallucination", "authors": "Xuan Gong,Tianshi Ming,Xinpeng Wang,Zhihua Wei", "background": "尽管大型视觉-语言模型（LVLMs）取得了巨大的成功，但它们不可避免地存在幻觉问题。LVLMs 中的视觉编码器和大型语言模型（LLM）解码器都基于 Transformer，可以通过注意力机制提取视觉信息和生成文本输出。研究发现，LLM 解码器对图像标记的注意力分布与视觉编码器高度一致，两者都倾向于关注特定的背景标记而不是图像中的目标对象。研究者认为这种意外的注意力分布源于视觉编码器本身的固有缺陷，误导了 LLMs 过度重视冗余信息并生成对象幻觉。", "innovation": "提出了一种名为 DAMRO 的新型无训练方法，旨在通过深入分析 LVLM 的注意力机制来减少物体幻觉。该方法利用 ViT 的分类标记（CLS）过滤出散布在背景中的高注意力异常标记，并在解码阶段消除其影响。这种策略在多个 LVLMs 和基准测试中进行了评估，展示了其显著减少 LVLMs 幻觉的影响，有效地缓解了物体幻觉问题。", "conclusion": "该方法通过剖析 LVLM 的注意力机制，显著减少了异常注意力标记的影响，有效地减少了 LVLMs 的幻觉，相关代码已公开。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.20559", "html_url": "https://arxiv.org/abs/2405.20559", "title": "信息驱动的成像系统设计", "title_en": "Information-driven design of imaging systems", "authors": "Henry Pinkard,Leyla Kabuli,Eric Markley,Tiffany Chien,Jiantao Jiao,Laura Waller", "background": "传统的成像系统旨在模仿人眼并生成可视觉解释的测量结果。然而，现代成像系统在直观查看之前或无需人类查看的情况下，对原始测量结果进行计算处理。因此，原始测量结果中的信息内容比其视觉解释性更重要。尽管成像测量信息内容的重要性不言而喻，但当前用于评估成像系统性能的方法并未量化这种信息内容，而是使用其他评估特定测量质量方面的指标，或通过次要任务上的性能评估间接衡量测量结果。", "innovation": "该研究开发了信息驱动成像系统设计的理论基础和实用方法，直接量化噪声测量值与未知对象之间的互信息。通过适应噪声特征对测量进行概率建模，我们的方法通过上限估计真实值来估算信息内容。此外，我们还开发了一种基于梯度优化的成像系统设计技术，称为信息驱动编码器分析学习（IDEAL）。信息估计准确捕捉了四个成像领域（色彩摄影、射电天文学、无透镜成像和显微镜）中系统的性能差异。使用IDEAL设计的系统在硬件和图像处理算法联合优化方面达到了最佳性能，这表明互信息是一个适用于成像系统性能评估的通用指标，支持在实际条件下高效的设计优化和评估。", "conclusion": "这些结果显示，互信息是一种适用于成像系统的通用性能评估指标，能有效进行计算高效的系统设计优化和实际条件下的性能评价。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.05712", "html_url": "https://arxiv.org/abs/2411.05712", "title": "为优化任务模型的灵计算机视觉腹侧流的缩放法则", "title_en": "Scaling Laws for Task-Optimized Models of the Primate Visual Ventral Stream", "authors": "Abdulkadir Gokce,Martin Schrimpf", "background": "当人工神经网络模型在大规模物体分类数据集上进行训练时，会逐渐逼近灵长类大脑的核心物体识别行为和神经反应模式。尽管最近的机器学习进展表明，增加计算资源、模型规模和数据集规模可以改善任务性能，但这些步骤对大脑匹配的影响仍然不清楚。本研究通过在控制条件下对从V1到IT的不同视觉区域以及行为层面的基准进行全面评估，探讨构建灵长类视觉腹侧流模型的缩放法则。", "innovation": "本研究系统地评估了超过600个模型，探索了在从V1到IT的不同视觉区域以及行为层面的基准上的缩放法则。研究发现，行为匹配性随模型规模增加而继续提高，但神经匹配性达到饱和状态。这一观察结果在不同模型架构和训练数据集中保持一致，即使具有更强归纳偏差的模型和高分辨率图片的训练数据集也表现出较高的计算效率。", "conclusion": "尽管缩放当前架构和数据集足以实现与人类核心物体识别行为的匹配，但不会提高大脑视觉腹侧流模型的表现。这强调了建立大脑模型时需要寻找新策略的必要性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.14133", "html_url": "https://arxiv.org/abs/2411.14133", "title": "GASP: 高效的黑盒生成对抗后缀以劫持大型语言模型", "title_en": "GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs", "authors": "Advik Raj Basani,Xiao Zhang", "background": "大型语言模型（LLMs）在各种自然语言处理任务中表现出色，但依然容易受到精心设计的输入提示攻击，这种攻击称为 jailbreak 攻击，能够绕过安全限制并引发有害响应。传统的手动启发式方法虽然存在但实用性有限，而自动优化攻击方法往往生成不自然的提示，容易被安全过滤器识别或需要较高的计算成本。为了解决这些问题，本文提出了一种名为 Generative Adversarial Suffix Prompter (GASP) 的新型自动框架，能够在完全黑盒环境中高效生成易于理解的劫持提示。", "innovation": "GASP 框架利用潜隐贝叶斯优化来有效探索连续的潜隐嵌入空间，生成对抗后缀并逐步优化提示生成器以提高攻击效果。同时通过目标迭代修正方法平衡提示的连贯性，确保生成的提示更加自然。相比基线方案，GASP 能显著提高劫持成功率、减少训练时间并加快推理速度，从而成为大型语言模型红队测试的高效且可扩展的解决方案。", "conclusion": "通过全面的实验，本文表明 GASP 框架能够生成自然的对抗后缀，显著提高 jailbreak 成功率，减少训练时间和加快推理速度，从而为红队测试大型语言模型提供了一个高效和可扩展的解决方案。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.18602", "html_url": "https://arxiv.org/abs/2411.18602", "title": "评估和提高用于医疗图像分析的合成胸部X光片的效果", "title_en": "Evaluating and Improving the Effectiveness of Synthetic Chest X-Rays for Medical Image Analysis", "authors": "Eva Prakash,Jeya Maria Jose Valanarasu,Zhihong Chen,Eduardo Pontes Reis,Andrew Johnston,Anuj Pareek,Christian Bluethgen,Sergios Gatidis,Cameron Olsen,Akshay Chaudhari,Andrew Ng,Curtis Langlotz", "background": "目的：探索生成合成胸部X光图像的最佳实践方法，通过增强医疗影像数据集来优化深度学习模型在分类和分割等下游任务中的性能。", "innovation": "使用隐式扩散模型根据文本提示和/或分割掩码生成合成胸部X光图像。研究使用代理模型和放射科医生反馈来提高合成数据质量的方法。合成图像来自相关的疾病信息或几何变换的分割掩码，并添加到CheXpert、CANDID-PTX、SIIM和RSNA肺炎数据集的真实训练集图像中，以测量分类和分割模型性能的改进。采用单尾t检验与邦弗伦尼校正评估合成数据带来的性能提升的统计显著性。", "conclusion": "生成用于下游任务的合成胸部X光图像的最佳实践包括基于单疾病标签或几何变换的分割掩码进行条件化，也可能使用代理模型进行微调以改进生成。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.11234", "html_url": "https://arxiv.org/abs/2506.11234", "title": "Poutine: 视觉-语言-轨迹预训练和强化学习后训练实现鲁棒的端到端自动驾驶", "title_en": "Poutine: Vision-Language-Trajectory Pre-Training and Reinforcement Learning Post-Training Enable Robust End-to-End Autonomous Driving", "authors": "Luke Rowe,Rodrigue de Schaetzen,Roger Girgis,Christopher Pal,Liam Paull", "background": "在自动驾驶领域，保持在分布外场景中的良好驾驶行为仍然是一个关键挑战。一种有希望的方法是通过将大型语言模型的一般知识和推理能力应用于处理非典型驾驶场景的逻辑推理任务来实现这一目标。", "innovation": "本工作的创新点在于提出了一种名为Poutine的方法，利用一个现成的3B参数视觉-语言模型（VLM）来实现鲁棒的端到端自动驾驶，这通过简单的可扩展的训练配方实现，并且在整个过程中没有添加额外的组件。此外，它强调了可扩展的VLT预训练与轻量级的强化学习细调相结合的重要性，以实现强大且通用的自动驾驶能力，而不需要手工编写的分词器或定制的架构组件。", "conclusion": "最终的Poutine模型在Waymo端到端驾驶基准测试中的测试集中获得了7.99的RFS评分，以显著的优势在2025 Waymo基于视觉的端到端驾驶挑战赛中获得了第一名。结果表明，之前工作中添加到基础VLM的手工分词器或自定义架构组件不是实现强大驾驶性能所必需的。相反，这项工作突显了可扩展的VLT预训练与轻量级的RL细调相结合的潜力，使自动驾驶既稳定又可泛化。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.13956", "html_url": "https://arxiv.org/abs/2507.13956", "title": "跨模态因果干预在阿尔茨海默病预测中的应用", "title_en": "Cross-modal Causal Intervention for Alzheimer's Disease Prediction", "authors": "Yutao Jin,Haowen Xiao,Junyong Zhai,Yuxiao Li,Jielei Chu,Fengmao Lv,Yuxiao Li", "background": "轻度认知损害（MCI）作为阿尔茨海默病（AD）的前驱阶段，早期识别和干预可以有效延缓病情进展至痴呆。然而，由于多模态数据的选择偏差和变量间的复杂关系，阿尔茨海默病的诊断仍然是神经学中的一个重大挑战。", "innovation": "本文提出了一个名为MediAD的创新框架，结合了大型语言模型（LLMs）、磁共振成像（MRI）、临床数据和由LLMs丰富后的文本数据来分类认知正常（CN）、MCI和AD类别。该框架通过统一的因果干预方法隐式地减轻了可观察和不可观察混杂因子的影响，从而提高了诊断的准确性。", "conclusion": "实验结果表明，本方法在区分认知正常、MCI和AD病例方面表现出色，在大多数评估指标上优于其他方法，显示了因果推理与多模态学习结合在神经系统疾病诊断中的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.13713", "html_url": "https://arxiv.org/abs/2504.13713", "title": "SLAM&Render: 一种神经渲染、高斯喷射与SLAM交叉领域的基准测试", "title_en": "SLAM&Render: A Benchmark for the Intersection Between Neural Rendering, Gaussian Splatting and SLAM", "authors": "Samuel Cerezo,Gaetano Meli,Tomás Berriel Martins,Kirill Safronov,Javier Civera", "background": "当前，用于新颖视角合成和场景渲染的方法，如神经辐射场（NeRF）和高斯喷射，正越来越多地被用作Simultaneous Localization and Mapping (SLAM)的技术表示。然而，现有的数据集并未涵盖SLAM 和神经渲染所面临的特定挑战，如顺序操作、多模态、以及不同视角和照明条件下的一致性。此外，数据通常使用手持传感器或无人机、移动机器人上的传感器收集，这增加了传感器运动精确重现的复杂性。为了弥合这些差距，我们提出了SLAM&Render这一新数据集，专门用于SLAM、新颖视角渲染和高斯喷射交叉领域的基准测试。该数据集通过使用一个机械臂录制，包括40个序列的时间同步RGB-D图像、IMU读数、机器人运动学数据以及真实轨迹。", "innovation": "SLAM&Render数据集的独特之处在于：（1）它包含了40个序列，每个序列都有时间同步的RGB-D图像、IMU读数、机器人运动学数据和真实轨迹；（2）通过提供机器人运动学数据，该数据集能够评估最近SLAM模式在机器人应用中的集成情况；（3）数据集包括五种设置，其中使用消费者和工业物品在四种控制照明条件下进行记录，每个设置都包含独立的训练和测试路径；（4）所有序列都保持静态，但具有不同程度的物体重新排列和遮挡，以检验技术的泛化能力。", "conclusion": "通过使用多种文献中的基线，实验结果证实了SLAM&Render作为新兴研究领域相关基准测试的重要性。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23717", "html_url": "https://arxiv.org/abs/2506.23717", "title": "采用自适应位分配方法实现高效精准的脉冲神经网络", "title_en": "Towards Efficient and Accurate Spiking Neural Networks via Adaptive Bit Allocation", "authors": "Xingting Yao,Qinghao Hu,Fei Zhou,Tielong Liu,Gang Li,Peisong Wang,Jian Cheng", "background": "多比特脉冲神经网络（SNNs）近年来成为研究热点，旨在实现高效的能效和高准确性的人工智能应用。然而，随着参与的比特数增加，相关的存储和计算需求急剧上升，使得性能提升变得不值得。本文基于不同层的重要性不同且额外的比特可能被浪费和干扰的洞察，提出了一种适用于直接训练的SNNs的自适应位分配策略，实现了层间精确的存储和计算资源分配，从而提高了SNNs的效率和准确性。", "innovation": "本文提出了参数化时间长度和权重与脉冲的位宽，并通过梯度使其可学习和可控，解决了变位宽和时间长度带来的挑战，提出了改进型脉冲神经元，可以处理不同时间长度，导出时间长度的梯度，更适合脉冲量化。同时理论上分析了可学习位宽的步长不匹配问题，可能会严重影响SNN，提出了步长更新机制来缓解这一问题。实验结果表明，本文的方法可以在降低整体存储和计算成本的同时，实现更高的准确率。", "conclusion": "我们的方法在ImageNet上相比先进的基线工作，SEWResNet-34可以实现2.69%的准确率提升和4.16倍的比特预算降低。该工作将开源。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.07871", "html_url": "https://arxiv.org/abs/2510.07871", "title": "通过前瞻性风险感知学习进行社交航行", "title_en": "Learning to Navigate Socially Through Proactive Risk Perception", "authors": "Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao", "background": "本次报告描述了我们向2025年IROS RoboSense挑战赛社交导航赛道提交的技术细节。该赛道专注于开发基于RGBD的感知和导航系统，使自主代理能够在包含动态人群的动态室内环境中安全、高效且符合社会规范地导航。挑战要求代理仅使用车载传感器（包括RGB-D观测和里程计），无需访问全局地图或特权信息，同时保持诸如安全距离和避碰等社会规范的遵守。", "innovation": "在Falcon模型的基础上，我们引入了一个前瞻性的风险感知模块，以增强社交导航性能。该方法通过学习预测周围人类的距离基线碰撞风险评分，使代理能够开发出更为稳健的空间意识和前瞻性避碰行为。", "conclusion": "在Social-HM3D基准测试上的评估表明，我们的方法在拥挤室内场景中导航至目标，同时保持个人空间合规性方面显著提高了代理的能力。在16支参赛队伍中，我们的方法获得了第二名的好成绩。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23807", "html_url": "https://arxiv.org/abs/2510.23807", "title": "病理学中的临床导向基础模型", "title_en": "Toward Clinically Grounded Foundation Models in Pathology", "authors": "Hamid R. Tizhoosh", "background": "在非医疗领域，基础模型（FMs）通过大规模自我监督和多模态学习，在计算机视觉和语言处理方面取得了革命性成果。因此，在计算病理学领域的快速应用被期望能带来癌症诊断、预后和多模态检索的相似突破。然而，近期系统评估揭示了根本性缺陷，包括低诊断准确性、较差的鲁棒性、几何不稳定性、较高的计算需求以及令人担忧的安全漏洞。", "innovation": "本文探讨了这些不足，并指出这些缺陷源于基础模型在主流AI中通用假设与人类组织固有复杂性之间的深刻概念不匹配。确定了七个相关原因：生物复杂性、无效的自我监督、过度概括、过度的架构复杂度、缺乏领域特定创新、数据不足以及与组织切片大小相关的根本设计缺陷。", "conclusion": "这些发现表明，目前的病理学基础模型在本质上仍与组织形态学不一致，需要从根本上重新思考其范式本身。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22379", "html_url": "https://arxiv.org/abs/2510.22379", "title": "TraceTrans: Translation and Spatial Tracing for Surgical Prediction", "title_en": "TraceTrans: Translation and Spatial Tracing for Surgical Prediction", "authors": "Xiyu Luo,Haodong Li,Xinxing Cheng,He Zhao,Yang Hu,Xuan Song,Tianyang Zhang", "background": "图像到图像的翻译模型在视觉域之间转换图像方面取得了显著成功，并被越来越多地应用于医疗任务，如预测术后结果和模拟疾病进展。然而，现有的大多数方法主要集中在匹配目标分布上，经常忽视源图像和翻译图像之间的空间对应关系。这种局限会导致结构性不一致和幻视，影响预测的可靠性和可解释性。在临床应用中，由于对解剖准确性的严格要求，这些挑战被进一步放大。", "innovation": "我们提出了一种名为TraceTrans的新颖可变形图像翻译模型，该模型专门设计用于术后的预测。该模型在预测目标分布的同时，明确揭示与术前输入的空间对应关系。框架使用编码器进行特征提取，双解码器预测空间变形并合成翻译图像。预测的变形场对生成的输出施加空间约束，确保生成的结果与原始图像在解剖学上一致。", "conclusion": "在医学整形和脑MRI数据集上的广泛实验表明，TraceTrans能够提供准确且可解释的术后预测，突显了其在可靠临床部署方面的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18751", "html_url": "https://arxiv.org/abs/2510.18751", "title": "Seg the HAB: 语言引导的地理空间藻华推理与分割", "title_en": "Seg the HAB: Language-Guided Geospatial Algae Bloom Reasoning and Segmentation", "authors": "Patterson Hsieh,Jerry Yeh,Mao-Chi He,Wen-Han Hsieh,Elvis Hsieh", "background": "气候变暖加剧了有害藻华（HAB），尤其是蓝细菌的出现，这威胁到了水生生态系统和人类健康，通过耗氧、毒素释放和破坏海洋生物多样性。传统监测方法如手工水样采集，仍存在劳动密集型且在空间和时间覆盖范围上的限制。现有远程感测的视觉语言模型（VLMs）虽展现出了可扩展的AI驱动解决方案潜力，但在图像语义理解和预测藻华严重程度方面仍然存在挑战。", "innovation": "本文提出ALGae Observation and Segmentation（ALGOS），结合了遥感图像理解和严重程度估计，通过GeoSAM辅助的人工评估确保高质量的分割掩膜，使用NASA的Cyanobacteria Aggregated Manual Labels (CAML)对视觉语言模型进行微调。实验结果表明，ALGOS在分割和严重程度估计上均表现出稳健性能，为实用和自动化的蓝细菌监测系统铺平了道路。", "conclusion": "ALGOS系统实现了HAB监测中的分割和严重程度估计的稳健性能，展现了利用VLMs进行大规模蓝色藻类检测和服务的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.01213", "html_url": "https://arxiv.org/abs/2510.01213", "title": "JaneEye：一种12纳米2K-FPS 18.9-μJ/帧事件驱动的眼动追踪加速器", "title_en": "JaneEye: A 12-nm 2K-FPS 18.9-$μ$J/Frame Event-based Eye Tracking Accelerator", "authors": "Tao Han,Ang Li,Qinyu Chen,Chang Gao", "background": "延展现实（XR）中的视线交互技术需要高精度、低延迟和高能量效率，而传统的基于帧的眼追踪系统常常无法满足这些要求。事件摄像头因其超高的时间和能量效率成为替代选择，但现有的基于事件的眼追踪系统在硬件效率方面还有进步空间。", "innovation": "本文提出了一种名为JaneEye的硬件加速器，专为可穿戴设备设计的事件驱动眼追踪系统。该系统利用稀疏高时间分辨率的事件数据，并提出了一种新型的ConvJANET卷积层，简化了传统ConvLSTM，仅保留遗忘门，降低了计算复杂度而不影响时间建模能力。此外，通过自定义激活函数线性近似和定点量化，进一步提高硬件效率。实验证明，JaneEye能够在3ET+数据集上实现2.45像素误差，仅使用17.6K参数，帧率高达1250 Hz。12 nm ASIC实现基于软件-硬件协同设计，可在400 MHz下运行，端到端延迟为0.5 ms（相当于2000 FPS），能量效率为18.9 μJ/帧，为低功耗高效率的眼追踪解决方案设立新基准，适用于下一代XR穿戴设备。", "conclusion": "JaneEye通过结合高效的硬件设计和先进的神经网络架构，成功实现了一种低功耗、高性能的眼追踪解决方案，为未来的XR穿戴设备提供了理想的集成方案。"}
{"llm_update_time": "20251110", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.15315", "html_url": "https://arxiv.org/abs/2510.15315", "title": "从LSST时空遗嘱调查的天文图像目录中应用神经后验估计", "title_en": "Neural Posterior Estimation for Cataloging Astronomical Images from the Legacy Survey of Space and Time", "authors": "Yicun Duan,Xinyue Li,Camille Avestruz,Jeffrey Regier,LSST Dark Energy Science Collaboration", "background": "2026年，Vera C. Rubin天文台的Legacy Survey of Space and Time (LSST) 将开始全规模运营，将产生大量天文图像。天文目录构建是基于天文图像数据的大多数科学流程中的关键步骤，但传统的确定性目录构建方法缺乏统计连贯性，而现有的概率方法则在计算效率、准确性或处理多波段合成图像的能力方面存在不足，这是LSST图像的主要输出格式。LSST即将上线，因此需要一种新的方法来提高目录构建的效率和准确性。", "innovation": "本文探讨了一种名为神经后验估计 (NPE) 的新兴贝叶斯推断方法。NPE 结合了深度学习，从而实现计算效率和高精度。通过在高度现实的 DC2 模拟天空调查数据集上进行评估，NPE 在光源检测、光度测量、星系分类和星系形变测量方面系统地优于标准LSST流水线。NPE 还提供了后验近似值的良好校准。这些基于模拟数据的结果展示了NPE的方法在未指定模型的情况下具有较大潜力。对于实际LSST图像而言，模型指定的不准确性是不可避免的，但存在多种策略可以减轻其影响，如改进的贝叶斯抽样技术、使用更复杂的模型或通过数据增强等方法。", "conclusion": "尽管在实际LSST图像应用中无法完美避免模型误设，但NPE方法展现出巨大潜力。未来可以通过调整与改进来进一步降低模型误设的影响。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03749", "html_url": "https://arxiv.org/abs/2511.03749", "title": "在爱尔兰利用时间序列深度学习模型预测多年生黑麦草的增长", "title_en": "Applying Time Series Deep Learning Models to Forecast the Growth of Perennial Ryegrass in Ireland", "authors": "Oluwadurotimi Onibonoje,Vuong M. Ngo,Andrew McCarre,Elodie Ruelle,Bernadette O-Briend,Mark Roantree", "background": "草地占世界第二大陆地碳汇，对生物多样性和碳循环调控至关重要。爱尔兰乳制品业经济贡献显著，但面临利润和可持续性挑战。当前草生长预测依赖于不切实际的机理模型，因此研究提出了针对一维数据集设计的深度学习模型，成本效益更高。", "innovation": "研究设计了一个用于预测柯克多年生黑麦草生长的时间卷积网络，利用历史草高度数据，实现了较高的性能，RMSE为2.74，MAE为3.46。该模型在长达34年的1,757周的数据集中进行了验证，优化了模型配置，增进了对模型行为的理解，提升了草生长预测的可靠性，并促进了可持续乳制品农作实践的进步。", "conclusion": "本研究通过优化深度学习模型配置，显著提高了草生长预测的准确性，对于爱尔兰可持续乳制品业的发展具有重要意义。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03757", "html_url": "https://arxiv.org/abs/2511.03757", "title": "笑、共鸣、互动：短视频个性化评论生成", "title_en": "Laugh, Relate, Engage: Stylized Comment Generation for Short Videos", "authors": "Xuan Ouyang,Senan Wang,Bouzhou Wang,Siyuan Xiahou,Jinrong Zhou,Yuekang Li", "background": "短视频平台已成为现代互联网景观中的重要媒介，高效的信息传递和强大的互动性重塑了用户参与和文化传播的方式。用户互动形式中，评论起到了促进社区参与并促使内容二次创作的关键作用。然而，生成既符合平台规定又能体现多样化风格和情境意识的评论仍是一项重大挑战。", "innovation": "本文介绍了 LOLGORITHM—一种模块化的多代理系统（MAS），用于可控的短视频评论生成。LOLGORITHM 包含视频切分、情境和情感分析、风格意识提示构建等功能，并通过多模态大型语言模型（MLLM）直接处理视频输入，实现精细化的风格控制。本书还构建了一个双语数据集，涵盖五种流行视频类型，同时通过自动评价指标和大规模人类偏好研究进行了全面评估，结果显示 LOLGORITHM 明显优于基准模型。", "conclusion": "本文提供了一个可扩展且文化适应性较强的框架，用于短视频平台的个性化评论生成，为增强用户参与和创意互动提供了有前景的道路。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03808", "html_url": "https://arxiv.org/abs/2511.03808", "title": "通过提示难度预测优化推理效率", "title_en": "Optimizing Reasoning Efficiency through Prompt Difficulty Prediction", "authors": "Bo Zhao,Berkcan Kapusuzoglu,Kartik Balasubramaniam,Sambit Sahu,Supriyo Chakraborty,Genta Indra Winata", "background": "推理语言模型在复杂任务上的表现很好，但由于其规模庞大和需要较长的推理过程，部署起来代价高昂。当前的策略需要较大的计算资源来确保准确度。", "innovation": "提出了一种路由方法，将每个问题分配给最有可能解决它的最小模型，从而减少计算成本而不牺牲准确性。利用s1.1-32B的中间表示，训练了轻量级的预测器以预测问题的难度或模型的正确性，引导路由分配给一组推理模型。在多样的数学基准测试中，这种路由方法比随机分配更有效，并且在使用显著更少计算资源的情况下达到了s1.1-32B的性能。", "conclusion": "我们的结果表明，难度感知路由方法对于推理模型的经济高效部署是有效的。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03774", "html_url": "https://arxiv.org/abs/2511.03774", "title": "使用多模态语义扰动检测 VLMs 的污染", "title_en": "Contamination Detection for VLMs using Multi-Modal Semantic Perturbation", "authors": "Jaden Park,Mu Cai,Feng Yao,Jingbo Shang,Soochahn Lee,Yong Jae Lee", "background": "最近，视觉-语言模型（VLMs）在多个基准任务中取得了最先进的性能。然而，这些模型往往利用大规模、通常是专有的预训练数据集进行训练，这引发了对于用户和实践者的广泛关注：即模型可能因测试集泄露而表现出虚高的性能。尽管之前的工作提出了诸如去污染预训练数据和LLMs再设计基准等策略，但对于受到污染的VLMs检测方法的研究仍然相对不足。为了解决这一问题，作者故意在流行基准上污染开源VLMs，并展示了现有检测方法要么完全失效，要么表现出不一致的行为。", "innovation": "作者提出了一种新颖的简单且有效的检测方法，基于多模态语义扰动，该方法表明被污染的模型在受控扰动下的泛化性能较差。此外，还在多种实际污染策略上验证了该方法的鲁棒性和有效性，并公布了代码和扰动数据集。这种方法补充了现有的污染检测策略，为防止污染和评估模型实际性能提供新的思路。", "conclusion": "研究验证了多模态语义扰动检测方法的有效性和稳健性，强调了检测污染VLMs的重要性，这有助于维护模型的真实性和公平性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03768", "html_url": "https://arxiv.org/abs/2511.03768", "title": "在跨场景推理时，共有的是什么？多模态模型会产生幻觉", "title_en": "What's in Common? Multimodal Models Hallucinate When Reasoning Across Scenes", "authors": "Candace Ross,Florian Bordes,Adina Williams,Polina Kirichenko,Mark Ibrahim", "background": "多模态语言模型在处理大量不同物体时表现出色，但在现实世界场景推理中仍然易产生幻觉。这些模型在现有饱和感知基准测试中的表现似乎很强，但在真实世界的场景推理中却显得力不从心，存在显著差异。", "innovation": "本文构建了一个新的基准测试——Common-O，该测试包含超过10500个全新未在网络训练数据中出现的图像，旨在探索多模态模型在跨场景推理中的表现。此基准测试借鉴了人类认知测试的方式，重点考察不同场景之间的共性问题，以评估模型在理解跨场景信息方面的能力。", "conclusion": "虽然许多领先模型在感知单一图像中的物体方面表现出色，但在跨越多个场景进行推理方面，即使是受过链式推理训练的最佳模型也面临巨大挑战，表现较差。最佳模型在Common-O上的表现仅为35%，而在涉及更复杂场景的Common-O Complex中，表现仅1%。研究表明，幻觉现象与特定场景下的物体共现频率有关，而更具扩展性的多图像训练模型表现更为出色，这表明多图像输入的训练可能有潜在的应用前景。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03806", "html_url": "https://arxiv.org/abs/2511.03806", "title": "FusionDP：基于基础模型的差异隐私部分敏感特征学习", "title_en": "FusionDP: Foundation Model-Assisted Differentially Private Learning for Partially Sensitive Features", "authors": "Linghui Zeng,Ruixuan Liu,Atiquer Rahman Sarkar,Xiaoqian Jiang,Joyce C. Ho,Li Xiong", "background": "在隐私保护机器学习中，确保敏感训练数据的隐私至关重要。但在实际场景中，可能只需要对特征中的一部分进行隐私保护。例如，在ICU数据中，年龄和性别等人口统计指标具有较高的重新识别风险，而原始实验室结果通常不太敏感。传统的DP-SGD算法会对一个样本中的所有特征提供隐私保护，导致噪声注入过多和模型性能显著下降。", "innovation": "本文提出了一种名为FusionDP的两步框架，以增强特征级别差异隐私下的模型性能。首先，FusionDP利用大型基础模型通过非敏感特征填补敏感特征，将其作为外部先验，从而在不访问真实值的情况下提供高质量的敏感特征估计。其次，FusionDP引入了修改后的DP-SGD算法，使用原数据和填补后的数据进行模型训练，而在不泄露原始敏感特征隐私的前提下，形式上保留了这些特征的隐私。本文在表征数据和临床笔记数据上分别进行了Sepsis预测任务和临床笔记分类任务的实验，结果表明，FusionDP在保证严格特征级别隐私的同时显著提升了模型性能，展示了基础模型驱动的填补对于提升不同领域隐私-性能权衡的潜力。", "conclusion": "FusionDP框架在保持严格特征级别隐私的同时显著提高了模型性能，证明了基础模型驱动的填补对于在各种模态中优化隐私与性能权衡的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03809", "html_url": "https://arxiv.org/abs/2511.03809", "title": "一种不是一刀切的适应性批量调度：面向架构的适应性批量调度方法DEBA", "title_en": "One Size Does Not Fit All: Architecture-Aware Adaptive Batch Scheduling with DEBA", "authors": "François Belias,Naser Ezzati-Jivan,Foutse Khomh", "background": "现有的适应性批量大小方法旨在加速神经网络训练，但这些方法假设所有架构都能通用，使用相同的适应策略。本文指出，这种一刀切的方法并不适用于所有架构，实际需要根据架构特性进行调整。", "innovation": "提出了一种名为DEBA（Dynamic Efficient Batch Adaptation）的适应性批量调度方法，通过监测梯度变异、梯度范数变化和损失变化来指导批量大小的调整。DEBA能够根据不同架构的特性进行定制化调整，从而提高训练速度并保持或提升准确率。", "conclusion": "研究发现，不同深度和类型的神经网络对批量大小的调整响应不同，轻量级和中等深度的网络可以实现高达62%的训练速度提升，而浅层网络则能够表现出稳定和显著的性能提升。已经优化良好的深层网络则表现出高度变异性，有时甚至会出现性能下降。还提出了一个基线表征框架，可以根据梯度稳定度指标预测哪些架构可以从适应性调度中受益。研究结果表明，适应性方法在不同架构之间的应用并不存在普适性，需要考虑架构的具体特性来设计适应性批量调度策略。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03824", "html_url": "https://arxiv.org/abs/2511.03824", "title": "Sketch-Augmented Features Improve Learning Long-Range Dependencies in Graph Neural Networks", "title_en": "Sketch-Augmented Features Improve Learning Long-Range Dependencies in Graph Neural Networks", "authors": "Ryien Hosseini,Filippo Simini,Venkatram Vishwanath,Rebecca Willett,Henry Hoffmann", "background": "图神经网络通过迭代聚合局部邻域信息来学习图结构数据。尽管这种局部消息传递范式赋予了强大的归纳偏见并利用了图的稀疏性，但它也会带来三个关键挑战：（i）长范围信息的压缩（oversquashing），（ii）节点表示的过度平滑化（oversmoothing），以及（iii）有限的表达能力（limited expressive power）", "innovation": "本文提出了将 \textit{Sketched Random Features} 随机全局嵌入节点特征注入标准图神经网络（GNNs），使它们能够高效地捕捉长范围依赖。这些嵌入是唯一的、距离敏感的、且与拓扑无关的特性，我们通过理论分析和实验证明这些特性可以缓解图神经网络中的上述限制，从而改进其性能。与基线图神经网络相比，该策略在实际图学习任务中表现出优越的效果，并提供了一个独立的解决方案，也作为现有技术，如图位置编码的补充增强方法", "conclusion": "实验结果表明，这种方法在实际图学习任务中始终能提高性能，并提供了一个独立的解决方案和一种现有技术的补充增强方法。源代码可以在 \textit{this https URL} 获取"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03807", "html_url": "https://arxiv.org/abs/2511.03807", "title": "概念漂移下的公平与可解释信用评分：适用于演变人群的自适应解释框架", "title_en": "Fair and Explainable Credit-Scoring under Concept Drift: Adaptive Explanation Frameworks for Evolving Populations", "authors": "Shivogo John", "background": "随着借款人的行为模式、经济环境和监管环境的变化，现代信用评分系统的底层数据分布不断重塑。传统的可解释性技术，如SHAP，假设数据为静态且背景分布固定，这会导致在概念漂移的情况下解释变得不稳定并且可能不公平。", "innovation": "本研究提出了自适应解释框架，这些框架能够根据动态变化的信用模型重新校准解释性和公平性。该研究结合了多年的信用数据集，利用XGBoost进行预测建模，并整合了三种自适应SHAP变体：针对特征分布变化进行权重调整的切片解释重校准、基于滑动窗口背景样本的概念漂移感知SHAP重基准校准，以及在线替换校准的增量岭回归。研究通过预测性能（AUC、F1）、方向和排名稳定性（余弦、肯德尔tau）以及公平性（人口平等待遇和校准）等指标对每种方法进行了基准测试。", "conclusion": "自适应方法，特别是基于滑动窗口背景样本的概念漂移感知SHAP重基准校准和基于在线替换校准的解释，不仅改善了时间稳定性，减少了各人口群体之间的差异影响，而且没有牺牲预测准确性。鲁棒性测试验证了自适应解释在真实世界概念漂移条件下的稳健性。这些发现确立了自适应解释作为一种实用机制，在数据驱动的信用系统中维持透明性、问责制和伦理可靠性，并且在任何随着人群变化而不断进化的决策模型领域都有更广泛的应用价值。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03753", "html_url": "https://arxiv.org/abs/2511.03753", "title": "使用格兰变化角度字段的联邦学习在异构物联网设备上进行隐私保护心电图分类", "title_en": "Federated Learning with Gramian Angular Fields for Privacy-Preserving ECG Classification on Heterogeneous IoT Devices", "authors": "Youssef Elmir,Yassine Himeur,Abbes Amira", "background": "在物联网健康护理环境中，需确保医疗数据的安全性和隐私性。传统的心电图（ECG）分类方法可能存在数据泄露风险，而现有的联邦学习（FL）方法在处理1D ECG信号时特征提取效率不高。针对这些问题，该研究提出了一种将1D ECG信号转换为2D格兰变化角度字段（GAF）图像的方法，利用卷积神经网络（CNN）进行高效特征提取，同时保证敏感医疗数据在每个设备本地处理，以此实现隐私保护下的ECG分类。研究通过实验证明了在此类异构物联网设备上GAF基联邦ECG分类的有效性，量化了性能和通信效率。研究还测试了联邦学习框架在实际物联网环境中的可行性，包括服务器、笔记本电脑及资源受限的Raspberry Pi 4设备。结果表明，FL-GAF模型在多客户端设置中取得了95.18%的分类准确率，优于单一客户端基准模型，在准确率和训练时间方面也表现更优。尽管增加了GAF转换的计算复杂性，但框架仍能有效利用资源并保持通信开销低。这些发现强调了轻量级、隐私保护的人工智能在物联网健康监测中的潜力，支撑了智能健康系统中的可扩展和安全边缘部署。", "innovation": "研究创新点在于首次在异构物联网设备上实验验证基于GAF的联邦ECG分类方法，通过将1D ECG信号转化为2D GAF图像，利用CNN进行高效的特征提取，同时确保敏感数据的安全性。并在实际物联网环境中对联邦学习框架进行了可行性测试，展示了该方法在提高分类性能和训练效率方面的优越性，以及在资源利用和通信开销方面的高效表现。", "conclusion": "研究发现，基于GAF的联邦学习框架能够实现高效的ECG分类，同时保持了隐私保护和资源效率。该方法在多客户端设置中实现了95.18%的高分类准确率，并证明了其在物联网健康监测中的可行性和广泛应用潜力，支持了智能健康系统的安全和可扩展边缘部署。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03828", "html_url": "https://arxiv.org/abs/2511.03828", "title": "从静态到动态：基于能量引导扩散分层的离线到在线强化学习增强", "title_en": "From Static to Dynamic: Enhancing Offline-to-Online Reinforcement Learning via Energy-Guided Diffusion Stratification", "authors": "Lipeng Zu,Hansong Zhou,Xiaonan Zhang", "background": "从离线到在线的强化学习（RL）面临着关键挑战，因为固定的离线行为策略与在线学习期间不断演化的策略之间的分布性变化。尽管这一问题广为认可，但很少有方法试图明确评估或利用离线数据本身的数据分布结构，留有研究空白。适用于适应不同样本类型的学习策略尚缺乏方法和工具。这一研究旨在填补此空白并解决这一挑战问题。", "innovation": "提出了一种创新方法——能量引导扩散分层（StratDiff），它利用扩散模型从离线数据集中学习先验知识，通过能量函数进一步细化知识以提高策略模仿并生成在线微调期间的离线样式的动作。对于每个样本，通过计算生成的动作与相应采样动作之间的KL散度来进行训练批次的分层，将样本分为离线样式的和在线样式的子集。离线样式的样本使用离线目标更新，而在线样式的样本则遵循在线学习策略。通过将StratDiff与现成的方法Cal-QL和IQL结合，显示了其有效性，并在D4RL基准测试中展示了超越现有方法的效果，提高了适应性和稳定性能。", "conclusion": "StratDiff方法在离线到在线强化学习适应性和稳定性方面表现出显著优势，特别是在D4RL基准测试中超越了现有方法。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03836", "html_url": "https://arxiv.org/abs/2511.03836", "title": "通过后续状态预测提升深层Q学习中的Q值更新", "title_en": "Enhancing Q-Value Updates in Deep Q-Learning via Successor-State Prediction", "authors": "Lipeng Zu,Hansong Zhou,Xiaonan Zhang", "background": "深度Q网络（DQN）通过从重放缓冲区中采样的过渡来学习并估计未来的回报。然而，DQN的目标更新通常依赖于动作由过去的、可能的次优策略产生的下一个状态。这些状态可能不提供有用的学习信号，导致更新过程中的高方差。当采样的过渡与代理的当前策略不匹配时，这一问题尤为严重。", "innovation": "本文提出的Successor-state Aggregation Deep Q-Network (SADQ) 明确地使用了随机过渡模型来表征环境动力学，并将后续状态分布纳入Q值估计过程中，从而使得价值更新更稳定且与策略对齐。此外，SADQ还探索了基于模型的过渡结构的更高效的动作选择策略。理论保证表明，SADQ能够保持无偏的价值估计并降低训练方差。", "conclusion": "在标准的强化学习基准测试和现实世界的向量控制任务中进行的广泛实验证明，SADQ在稳定性和学习效率上都优于DQN的变体。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03924", "html_url": "https://arxiv.org/abs/2511.03924", "title": "从移动信号预测社会人口属性", "title_en": "On Predicting Sociodemographics from Mobility Signals", "authors": "Ekin Uğurel,Cynthia Chen,Brian H. Y. Lee,Filipe Rodrigues", "background": "从移动数据推断社会人口属性可以帮助交通规划者更好地利用被动收集的数据集，但这一任务仍然具有挑战性，因为移动模式与社会人口特征之间的关系较弱且不一致，且在不同背景下限制了泛化能力。", "innovation": "1. 引入基于有向移动图的行为导向更高阶的移动描述符，以提高预测准确性的同时保持可解释性；\n2. 提出评估模型置信度与准确性的度量及可视化诊断工具，鼓励评估不确定性；\n3. 开发多任务学习框架，从共享表示中联合预测多个社会人口属性，特别是在训练数据有限或跨时间段应用模型时表现出色。", "conclusion": "该研究通过多重策略显著改进了从移动信号预测社会人口属性的性能，特别是在有限数据和不同时间背景下，多任务学习方法优于单任务模型。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03831", "html_url": "https://arxiv.org/abs/2511.03831", "title": "使用加性模型的高阶因果结构学习", "title_en": "Higher-Order Causal Structure Learning with Additive Models", "authors": "James Enouen,Yujia Zheng,Ignavier Ng,Yan Liu,Kun Zhang", "background": "因果结构学习长期以来一直是从数据中推断因果见解的核心任务。尽管有大量的真实世界过程展示了高阶机制，但是因果发现中对交互的显式处理却鲜有关注。本文专注于扩展因果加性模型（CAM）到具有高阶交互的加性模型。除此之外，引入了一种新的结构表示方法——导向非循环超图，以更易于表达这一复杂的结构层次问题。我们为这种新型的结构引入了必要的定义和理论工具，并提供了扩展的标准马尔可夫等价类以确保识别性。我们还提供了学习较复杂超图结构为何可能实现出更好的实证成果，具约束性的假设如CAM最适合学习较容易的超图DAG并且具有更好的有限样本复现性。", "innovation": "本文提出了将因果加性模型扩展到具有高阶交互的加性模型，引入了导向非循环超图来表示复杂结构。我们引入了新的定义和理论工具，提供了超图DAG的识别性结果，扩展了马尔可夫等价类，并根据更复杂的超图结构可能取得更好实证成果这一点提出新的算法扩展CAC算法来处理更复杂的超图DAG搜索空间，最后验证其在合成实验中的作用。", "conclusion": "本文发展了一种新的算法扩展CAC算法来处理更复杂的超图DAG搜索空间，并在合成实验中展示了其应用在实际中的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03877", "html_url": "https://arxiv.org/abs/2511.03877", "title": "社交平台上的Lead-Lag预测基准数据集", "title_en": "Benchmark Datasets for Lead-Lag Forecasting on Social Platforms", "authors": "Kimia Kazemian(1),Zhenzhen Liu(1),Yangfanyu Yang(2),Katie Z Luo(1),Shuhan Gu(1),Audrey Du(1),Xinyu Yang(2),Jack Jansons(1),Kilian Q Weinberger(1),John Thickstun(1),Yian Yin(2),Sarah Dean(1) ((1) Department of Computer Science, Cornell University (Ithaca, USA), (2) Department of Information Science, Cornell University (Ithaca, USA))", "background": "社交和协作平台生成多变量时间序列轨迹，在其中早期交互（如查看、点赞或下载）有时可能在几个月或几年后转化为更高的影响力结果（如引用、销售或评论）。这种模式在众多领域普遍存在，但尚未被统一作为时间序列预测问题处理，主要是由于缺乏标准化的数据集。因此，需要建立基准数据集并定义相关的研究框架来推动该领域的探索和发展。", "innovation": "本文提出两个高容量的基准数据集，分别是arXiv和GitHub数据集。arXiv数据集记录了超230万篇论文的访问次数与其引用数量的关系；GitHub数据集记录了超过300万仓库的推文和星级与其读后行为的关系。此外还概述了其他具有类似Lead-Lag动态的数据领域，如维基百科、Spotify、电商和LinkedIn。本文的数据集特征在于捕捉跨年的时间动态、涵盖了广泛的输出结果，并避免了幸存偏差。为了保证研究的一致性和可验证性，本文档还详细记录了数据整理和清洗的所有技术细节，并通过统计和分类测试验证了Lead-Lag动态的存在，同时对回归基线进行了基准测试。", "conclusion": "本文建立了Lead-Lag预测为一个新的预测范式，并为社交媒体和使用数据中系统性探索奠定了实证基础。文章最后提供了数据门户供用户下载和参考。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03928", "html_url": "https://arxiv.org/abs/2511.03928", "title": "SynQuE：在无注释情况下估计合成数据集质量", "title_en": "SynQuE: Estimating Synthetic Dataset Quality Without Annotations", "authors": "Arthur Chen,Victor Zhong", "background": "随着数据收集成本的增加和隐私约束的限制，高质量的合成数据集评估变得至关重要。现有的评估方法需要大量的标注真实数据，这在数据稀缺的情况下是不可行的。SynQuE 旨在通过仅使用少量未标注的真实数据来对合成数据集进行排名，以估计其预期的真实世界任务性能。", "innovation": "本文首次提出了合成数据集质量评估问题 (SynQuE)，并建立了首个基准。引入了基于分布和多样性距离测量的代理度量，并通过嵌入模型适应其上下文。针对复杂规划任务中代理度量的不足，提出了 LENS（Large Language Model Reasoning），这是一种新的代理方法，通过利用大型语言模型推理能力以捕捉更多细微特征。实验结果表明，SynQuE 代理指标与不同任务的真实任务性能高度相关，尤其是对于复杂任务，LENS 始终表现出色。", "conclusion": "本文确立了 SynQuE 作为在真实数据稀缺条件下选择合成数据的实用框架，并促进了基于基础模型的数据特征描述和细粒度数据选择研究。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03929", "html_url": "https://arxiv.org/abs/2511.03929", "title": "NVIDIA Nemotron Nano V2 VL", "title_en": "NVIDIA Nemotron Nano V2 VL", "authors": "NVIDIA:Amala Sanjay Deshmukh,Kateryna Chumachenko,Tuomas Rintamaki,Matthieu Le,Tyler Poon,Danial Mohseni Taheri,Ilia Karmanov,Guilin Liu,Jarno Seppanen,Guo Chen,Karan Sapra,Zhiding Yu,Adi Renduchintala,Charles Wang,Peter Jin,Arushi Goel,Mike Ranzinger,Lukas Voegtle,Philipp Fischer,Timo Roman,Wei Ping,Boxin Wang,Zhuolin Yang,Nayeon Lee,Shaokun Zhang,Fuxiao Liu,Zhiqi Li,Di Zhang,Greg Heinrich,Hongxu(Danny)Yin,Song Han,Pavlo Molchanov,Parth Mannan,Yao Xu,Jane Polak Scowcroft,Tom Balough,Subhashree Radhakrishnan,Paris Zhang,Sean Cha,Ratnesh Kumar,Zaid Pervaiz Bhat,Jian Zhang,Darragh Hanley,Pritam Biswas,Jesse Oliver,Kevin Vasques,Roger Waleffe,Duncan Riach,Oluwatobi Olabiyi,Ameya Sunil Mahabaleshwarkar,Bilal Kartal,Pritam Gundecha,Khanh Nguyen,Alexandre Milesi,Eugene Khvedchenia,Ran Zilberstein,Ofri Masad,Natan Bagrov,Nave Assaf,Tomer Asida,Daniel Afrimi,Amit Zuker,Netanel Haber,Zhiyu Cheng,Jingyu(Justin)Xin, Di (Allan)Wu,Nik Spirin,Maryam Moosaei,Roman Ageev,Vanshil Atul Shah,Yuting Wu,Daniel Korzekwa,Unnikrishnan Kizhakkemadam Sreekumar,Wanli Jiang,Padmavathy Subramanian,Alejandra Rico,Sandip Bhaskar,Saeid Motiian,Kedi Wu,Annie Surla,Chia-Chih Chen,Hayden Wolff,Matthew Feinberg,Melissa Corpuz,Marek Wawrzos,Eileen Long,Aastha Jhunjhunwala,Paul Hendricks,Farzan Memarian,Benika Hall,Xin-Yu Wang,David Mosallanezhad,Soumye Singhal,Luis Vega,Katherine Cheung,Krzysztof Pawelec,Michael Evans,Katherine Luna,Jie Lou,Erick Galinkin", "background": "NVIDIA推出最新一代的Nemotron视觉-语言系列模型Nemotron Nano V2 VL，该模型旨在实现强大的现实世界文档理解、长视频理解及多项推理任务。Nemotron Nano V2 VL在视觉和文本的所有领域中都相较于之前的模型Llama-3.1-Nemotron-Nano-VL-8B取得了显著的改进，这得益于模型架构、数据集和训练配方的重大增强。", "innovation": "Nemotron Nano V2 VL基于混合Mamba-Transformer大语言模型，并采用了创新的标记减少技术，从而在长文档和视频场景中实现了更高的推理吞吐量。该模型不仅在视觉任务和文本理解领域取得了进步，还通过提供BF16、FP8和FP4格式的模型检查点、共享大量数据集、配方和训练代码，展示了其开放性和社区友好性。", "conclusion": "NVIDIA以Nemotron Nano V2为基底推出Nemotron Nano V2 VL，实现了显著的性能提升，并开放了多项技术和数据资源，供研究者和开发者深入探索视觉-语言任务的前沿技术。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03939", "html_url": "https://arxiv.org/abs/2511.03939", "title": "RLHF: 对文化、多模态和低延迟对齐方法的综合调查", "title_en": "RLHF: A comprehensive Survey for Cultural, Multimodal and Low Latency Alignment Methods", "authors": "Raghav Sharma,Manan Mehta,Sai Tiger Raina", "background": "强化学习从人类反馈（RLHF）是大型语言模型（LLMs）对齐的标准方法，尽管取得了近期进展，但已超越传统的文本基线方法。这项综述性研究通过解决多模态对齐、文化公平性和低延迟优化的关键空白，整合了新的对齐研究前沿。研究首先回顾了基础算法，包括PPO、DPO和GRPO，然后详细分析了最新的创新成果。", "innovation": "综述通过对比和整合不同技术的最新成果，涵盖了文化、多模态和低延迟对齐的新领域。同时，综述还指出了开放性挑战，为构建更稳健、高效和公平的人工智能系统提供了指导路径。", "conclusion": "这项工作为研究人员提供了一条路线图，帮助他们在构建更强大的AI系统时解决相关挑战，确保更多的鲁棒性、效率和公平性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03953", "html_url": "https://arxiv.org/abs/2511.03953", "title": "Conditional Score Learning for Quickest Change Detection in Markov Transition Kernels", "title_en": "Conditional Score Learning for Quickest Change Detection in Markov Transition Kernels", "authors": "Wuxia Chen,Taposh Banerjee,Vahid Tarokh", "background": "本文讨论了在未知转移核的马尔可夫过程中的最快变化检测问题。现有的方法通常需要显式的似然估计，这在高维数据场景中可能颇具挑战性。", "innovation": "提出了一种直接从样本对（x, y）中学习条件分数 \nabla_{\bf{y}} \text{log} p({\bf{y}}|{\bf{x}}) 的方法，其中x和y由相同的转移核生成。这种方法消除了显式的似然评估，提供了一种学习转移动态的实用方式，并发展了一种基于条件Hyvarinen得分差异的评分基CUSUM程序，用于检测转移核中的变化。同时提出了这种统计量的截断版本，以确保增量有界。", "conclusion": "通过使用均匀遍历马尔可夫过程的Hoeffding不等式，证明了对于基于评分的检测，均假警报时间的指数下界和检测延迟的渐近上界。这些结果为高维马尔可夫模型中的基于分数的检测提供了理论保证和实用可行性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03938", "html_url": "https://arxiv.org/abs/2511.03938", "title": "LogHD: 通过对数分类轴压缩增强的高维分类器稳健压缩", "title_en": "LogHD: Robust Compression of Hyperdimensional Classifiers via Logarithmic Class-Axis Reduction", "authors": "Sanggeon Yun,Hyunwoo Oh,Ryozo Masukawa,Pietro Mercati,Nathaniel D. Bastian,Mohsen Imani", "background": "高维计算（HDC）适用于内存、能耗和可靠性的限制系统。然而，传统的‘每类一个原型’设计需要O(CD)的内存（C为类别数量，D为维度）。先前的研究通过减少特征轴维度（跳跃压缩），虽然可以改善存储和计算性能，但是会削弱系统的鲁棒性。现有技术在特征轴上的压缩会影响系统的准确性和鲁棒性。", "innovation": "该研究介绍了LogHD，这是一种对数类轴压缩方法，将每类的C个原型替换为n≈⌈log_k C⌉个捆包超向量（字母表大小为k），并在n维激活空间中进行解码，从而将内存需求压缩到O(D log_k C)的同时保留了D。LogHD使用容量感知的代码簿和基于配置文件的解码，并与特征轴稀疏化相结合。LogHD能够通过较低尺寸的模型在匹配内存水平下达到竞争力的准确性和更高的鲁棒性。在相等的内存下，与特征轴压缩相比，LogHD能够承受大约2.5-3.0倍更高的比特翻转率。ASIC实现显示出比AMD Ryzen 9 9950X和NVIDIA RTX 4090分别498倍的能效比和62.6倍的加速比，并且在特征轴HDC ASIC基线基础上分别提高4.06倍的能效比和2.19倍的加速比。", "conclusion": "通过评估不同数据集和注入位翻转差异，研究表明LogHD在相同内存条件下提高了模型规模的灵活性和鲁棒性，以及在ASIC实现中的能效和性能显著优势。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03972", "html_url": "https://arxiv.org/abs/2511.03972", "title": "非渐近优化与过度参数化模型中随机高斯牛顿法的泛化边界", "title_en": "Non-Asymptotic Optimization and Generalization Bounds for Stochastic Gauss-Newton in Overparameterized Models", "authors": "Semih Cayci", "background": "深度学习中的一个重要问题是高阶优化方法如何影响泛化能力。本文分析了在回归设置中训练具有平滑激活函数的过度参数化深度神经网络时，带有Levenberg-Marquardt阻尼和小批量采样的随机高斯牛顿（SGN）方法的特性。", "innovation": "本文的理论贡献主要有两点：首先，通过参数空间中的变量度量分析，给出了有限时间收敛的边界，其中包含显式的批量大小、网络宽度和深度的依赖项；其次，使用过度参数化区域中的均匀稳定性推导出SGN的非渐近泛化边界，表征了曲率、批量大小和过度参数化对泛化性能的影响。", "conclusion": "理论结果识别了SGN有利的泛化区域，在此区域中，优化路径上高斯牛顿矩阵的最小特征值越大，稳定性边界越紧。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03966", "html_url": "https://arxiv.org/abs/2511.03966", "title": "PrivacyCD: 分级遗忘以保护认知诊断中的学生隐私", "title_en": "PrivacyCD: Hierarchical Unlearning for Protecting Student Privacy in Cognitive Diagnosis", "authors": "Mingliang Hou,Yinuo Wang,Teng Guo,Zitao Liu,Wenzhou Dou,Jiaqi Zheng,Renqiang Luo,Mi Tian,Weiqi Luo", "background": "随着用户对'被遗忘权'的坚持，从认知诊断（CD）模型中删除特定学生数据的需求变得迫切。然而，现有的CD模型通常缺乏隐私考量，缺乏有效的数据遗忘机制。通用的遗忘算法直接应用在CD模型上效率不高，因为它们在处理CD模型独特的异构结构时难以平衡遗忘的完整性、模型的有用性和效率。", "innovation": "本文首次系统地研究了CD模型的数据遗忘问题，提出了一种新的高效算法：层级重要性引导遗忘（HIF）。HIF的核心洞见是：在CD模型中的参数重要性表现出逐层的独特特征。HIF通过一种创新的平滑机制结合个人和层次级别的重要性，能够更精确地区分与要遗忘的数据相关的参数。实验结果表明，HIF在关键指标上显著优于基准模型，为CD模型响应用户数据删除请求提供了首个有效的解决方案，并为部署高性能、隐私保护AI系统提供了可能。”", "conclusion": "实验结果表明，HIF在关键指标上显著优于基准模型，为CD模型响应用户数据删除请求提供了首个有效的解决方案，并为部署高性能、隐私保护AI系统提供了可能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03983", "html_url": "https://arxiv.org/abs/2511.03983", "title": "TwIST: 使用独立子网络训练在变换器中操纵彩票", "title_en": "TwIST: Rigging the Lottery in Transformers with Independent Subnetwork Training", "authors": "Michael Menezes,Barbara Su,Xinze Feng,Yehya Farhat,Hamza Shili,Anastasios Kyrillidis", "background": "该论文的背景在于大规模语言模型（LLM）的精简（sparsification），以提高模型的效率和降低计算成本。传统的精简方法在部署时可能需要额外的校准或恢复步骤，增加了成本和复杂性。", "innovation": "TwIST 提出了一种新的分布式培训框架，该框架通过并行训练多个子网络，定期聚合参数，并在训练过程中重新抽样新的子网络。这种方法能够识别高质量的子网络（“黄金通行证”），而不需要传统的后续校准或基于海森堡恢复步骤。TwIST 允许在部署时实现零成本剪枝，同时保持与最先进的后续精简方法相当的困惑度（perplexity）。TwIST 特别适用于高度精简的情况（例如，50%以上），在这种情况下，它显著优于基线方法。", "conclusion": "TwIST 提供了一种在不增加额外微调或恢复开销的情况下，从训练时间过渡到可部署的稀疏 LLM 的有效方法。它产生的具有结构的密集矩阵可以在普通硬件（如 CPU）上提供实际的推理速度提升和内存减少，这些硬件不支持高效的稀疏计算。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03981", "html_url": "https://arxiv.org/abs/2511.03981", "title": "大规模模型可组合微调算法中的结构先验与模块化适配器", "title_en": "Structural Priors and Modular Adapters in the Composable Fine-Tuning Algorithm of Large-Scale Models", "authors": "Yuxiao Wang,Di Wu,Feng Liu,Zhimin Qiu,Chenrui Hu", "background": "本文提出了一种可组合微调方法，旨在解决大规模预训练模型在多任务适应过程中面临的高计算成本和结构不稳定问题。该方法通过将图结构先验与模块化适配器结合，引入关系矩阵来建模任务间的依赖关系，明确地将节点和路径间的关联编码到图结构先验中，提供统一的结构约束用于适配权重分配和路径选择。这种方法不仅提高了参数效率和训练稳定性，还缓解了多任务场景中的路径冲突和冗余计算。", "innovation": "提出了一种集成了图结构先验与模块化适配器的可组合微调方法。该方法通过引入关系矩阵建模任务依赖关系，并通过低秩映射和可插拔机制嵌入模块化适配器到不同层中，实现基于先验的多任务有效组合与复用。此外，进行了超参数敏感性、环境敏感性以及数据敏感性的系统实验，验证了在结构约束下的方法一致性及优越性能。", "conclusion": "实验结果表明，所提出的框架显著提升了任务预测精度、适配权重分配精度以及整体计算效率，同时保持了轻量化设计。这证明了图先验和模块化机制在可组合微调上的协同优势。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03976", "html_url": "https://arxiv.org/abs/2511.03976", "title": "PETRA：基于演化轨迹的预训练演化转换器用于SARS-CoV-2突变预测", "title_en": "PETRA: Pretrained Evolutionary Transformer for SARS-CoV-2 Mutation Prediction", "authors": "Xu Zou", "background": "自SARS-CoV-2出现以来，人类见证了其具有快速且不可预测的进化路径，表现为不断出现能够逃逸免疫的变异株。这种现象给公共卫生和疫苗开发带来了持续性的挑战。尽管大规模预训练变换器（GPTs）在序列数据建模方面取得了革命性的进步，但它们在处理包含噪声的病毒基因组序列时受到限制。因此，研究人员需要新的方法来有效处理基因组序列中噪声和捕捉病毒进化的层级结构。", "innovation": "本文提出了PETRA（Pretrained Evolutionary TRAnsformer），一种基于从系统发生树推导出的进化轨迹而非原始RNA序列的新颖变换器方法。该方法通过加权训练框架来缓解全球序列数据中显著的地理和时间上的不平衡问题。PETRA在预测未来SARS-CoV-2突变方面表现出色，无论是对碱基突变的加权召回率为9.45%，还是对刺突蛋白氨基酸突变的加权召回率为17.10%，显著优于基础模型。另外，PETRA还展示了其在实时预测主要分支（如24F(XEC)和25A(LP.8.1)）突变方面的优势。PETRA的代码已在开源平台上发布。", "conclusion": "PETRA有效地减轻了序列数据中的噪声并捕捉了病毒进化中的层级结构，在预测SARS-CoV-2未来突变方面表现出卓越的能力，为公共卫生和疫苗开发提供了有力支持。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03993", "html_url": "https://arxiv.org/abs/2511.03993", "title": "多尺度神经胶质网络钙动态在异常检测中的生物合理智能", "title_en": "Multiscale Astrocyte Network Calcium Dynamics for Biologically Plausible Intelligence in Anomaly Detection", "authors": "Berk Iskar,Michael Taynnan Barros", "background": "传统的网络异常检测系统中使用的离线训练检测器面临多个挑战，包括概念漂移和新型威胁（如零日攻击或多态性攻击）。", "innovation": "本文提出了一种Ca$^{2+}$调控学习框架，灵感来源于大脑中星形胶质细胞间的Ca$^{2+}$信号传导。该方法将一个多细胞星形胶质体动态模拟器与深度神经网络（DNN）结合，通过IP$_3$介导的钙离子释放、SERCA泵吸收和间隙连接中的传导性依赖扩散三种机制来建模星形胶质细胞钙动态。实验表明，该方法在CTU-13网络流量数据集上的表现优于匹配的基线DNN，且具有显著提高的准确性和较低的假阳性/假阴性率。此外，这种方法在钙离子轨迹预计算完成后几乎不增加运行时间开销。", "conclusion": "此Ca$^{2+}$调控学习框架提供了一种用于需要快速、基于生物学的适应性变化的流式检测任务的通用解决方案。虽然此方法目前应用于网络安全领域，但其潜在应用范围更广。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03986", "html_url": "https://arxiv.org/abs/2511.03986", "title": "使用连续葡萄糖监测与机器学习识别代谢亚表型并指导个性化生活方式改变", "title_en": "Use of Continuous Glucose Monitoring with Machine Learning to Identify Metabolic Subphenotypes and Inform Precision Lifestyle Changes", "authors": "Ahmed A. Metwally,Heyjun Park,Yue Wu,Tracey McLaughlin,Michael P. Snyder", "background": "静止血糖阈值分类糖尿病和糖尿病前期的现象掩盖了由胰岛素抵抗（IR）、β细胞功能障碍和肠促胰素缺乏所驱动的生理性血糖异质性。本文回顾了连续葡萄糖监测和可穿戴技术如何推动无创的动态代谢表型分类法的转变。研究表明，机器学习模型可以通过家庭使用便携式连续葡萄糖监测仪（CGM）的口服葡萄糖耐量试验（OGTT）获取的高分辨率血糖数据，准确预测标准的肌肉胰岛素抵抗和β细胞功能的指标。", "innovation": "使用连续葡萄糖监测与机器学习技术，能够将早期生理性血糖异质性分解成不同的可行动亚表型。通过分析个体的血糖响应，可以确定代谢亚表型；并将穿戴技术数据与饮食、睡眠和体力活动模式的规律性结合，能够识别出这些模式与特定代谢功能障碍的独特关联，从而实现针对性的生活方式干预。", "conclusion": "连续葡萄糖监测能够将早期生理性血糖异质性解构为具体且可行动的亚表型，这样的方法超越了简单的血糖控制，开辟了个人化营养、行为和药物治疗的新时代的糖尿病预防策略。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04000", "html_url": "https://arxiv.org/abs/2511.04000", "title": "通过合成模型生成实现可解释模型元学习的可扩展性", "title_en": "Towards Scalable Meta-Learning of near-optimal Interpretable Models via Synthetic Model Generations", "authors": "Kyaw Hpone Myint,Zhe Wu,Alexandre G.R. Day,Giri Iyengar", "background": "决策树在高风险领域如金融和医疗中广泛应用，因为它们具有解释性。然而，为这些模型生成高质量的预训练数据是一项挑战，通常需要大量真实数据或计算成本高昂的最优决策树。本文探讨了如何利用合成数据生成方法，提高决策树模型的元学习效率和灵活性，特别是在保持模型解释性方面取得了突破性进展。", "innovation": "本文提出了一种高效、可扩展的方法，通过合成预训练数据来实现决策树的元学习。该方法通过MetaTree变压器架构，生成大量真实的、可解释的决策树模型，从而在性能上接近于使用真实数据预训练或使用昂贵的计算优化决策树。这种方法显著降低了计算成本，增强了数据生成的灵活性，为实现可解释决策树模型的可扩展和高效元学习奠定了基础。", "conclusion": "研究结果表明，通过合成模型生成的方法可以实现接近真实数据预训练或优化决策树模型的性能，同时大幅降低计算成本和提高数据生成的灵活性，为可解释决策树模型的元学习提供了新的途径。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04001", "html_url": "https://arxiv.org/abs/2511.04001", "title": "加速科学研究的通用任务框架", "title_en": "Accelerating scientific discovery with the common task framework", "authors": "J. Nathan Kutz,Peter Battaglia,Michael Brenner,Kevin Carlberg,Aric Hagberg,Shirley Ho,Stephan Hoyer,Henning Lange,Hod Lipson,Michael W. Mahoney,Frank Noe,Max Welling,Laure Zanna,Francis Zhu,Steven L. Brunton", "background": "机器学习（ML）和人工智能（AI）算法正在改变和增强工程、物理和生物科学中动态系统的表征和控制。这些新兴的建模范式要求使用多种评价指标来评估一系列科学目标，包括预测、状态重构、泛化和控制，同时还需考虑数据有限和噪声数据的情况。目前，没有一个通用的框架来比较快速发展的多元算法，尤其是在科学研究和工程学领域中应用的实践算法。", "innovation": "本文提出了一种通用任务框架（CTF），旨在提供一个具有各种实用和常见目标的挑战数据集。CTF 被认为是关键的使能技术，它已经在传统应用如语音识别、语言处理和计算机视觉中促进了 ML/AI 算法的发展。CTF 的目标是为多样化的算法提供客观指标以进行评估，不仅适用于语音识别、语言处理和计算机视觉等领域，也能推广到科学研究和工程学领域的其他应用场景。", "conclusion": "CTF 是对现有 ML/AI 算法评估和部署的一种重要贡献，它能够加速科学研究的进展，特别是在处理复杂性和不确定性方面。通过 CTF，研究人员可以更有效地比较和优化算法以适应各种科学和工程挑战。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04040", "html_url": "https://arxiv.org/abs/2511.04040", "title": "通过重建预训练的双重分支动态选择增强多模态蛋白质功能预测", "title_en": "Enhancing Multimodal Protein Function Prediction Through Dual-Branch Dynamic Selection with Reconstructive Pre-Training", "authors": "Xiaoling Luo,Peng Chen,Chengliang Liu,Xiaopeng Jin,Jie Wen,Yumeng Liu,Junsong Wang", "background": "多模态蛋白质特征对于蛋白质功能预测至关重要，但这些特征涵盖了从结构数据和序列特征到蛋白质属性和相互作用网络的广泛信息，使得解析它们的复杂联系极具挑战性。", "innovation": "提出了一种利用动态选择和重建预训练机制的多模态蛋白质功能预测方法（DSRPGO）。引入了重建预训练以挖掘低语义级别的更精细的信息，并提出了双向交互模块（BInM）以促进多模态特征之间的互动学习。此外，为了应对该任务中层次多标签分类的难度，设计了一个动态选择模块（DSM）来选择对当前蛋白质功能预测最有利的特征表示。", "conclusion": "提出的DSRPGO模型在人类数据集上的BPO，MFO和CCO方面显著提高，并且优于其他基准模型。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04069", "html_url": "https://arxiv.org/abs/2511.04069", "title": "儿科超声图像中的阑尾炎检测", "title_en": "Pediatric Appendicitis Detection from Ultrasound Images", "authors": "Fatemeh Hosseinabadi,Seyedhassan Sharifi", "background": "儿童阑尾炎是儿童急性腹痛的最常见原因之一，其诊断因症状重叠和影像质量差异较大而具有挑战性。", "innovation": "本研究旨在利用预训练的ResNet架构开发并评估一种基于深度学习的自动阑尾炎检测模型，利用德国雷根斯堡赫德维希儿童医院的儿童腹痛患者病历数据集，通过调整预训练的ResNet模型对部分超声图像进行分类，提升识别准确性。", "conclusion": "所提的ResNet模型在多变的超声图像中展示了良好的识别性能，总体准确率为93.44%，精确率为91.53%，召回率为89.8%，成功地学习到具有区分性的空间特征，克服了影像中的对比度低、斑点噪声以及儿童影像的解剖变异等挑战。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04002", "html_url": "https://arxiv.org/abs/2511.04002", "title": "基于自适应分区计算的大型语言模型在资源和延迟受限环境中的推理", "title_en": "Memory- and Latency-Constrained Inference of Large Language Models via Adaptive Split Computing", "authors": "Mingyu Sung,Vikas Palakonda,Suhwan Im,Sunghwan Moon,Il-Min Kim,Sangseok Yun,Jae-Mo Kang", "background": "大型语言模型（LLMs）在各种推理任务上已经接近人类水平，但在资源受限的物联网（IoT）设备上部署这些模型时遇到了实际障碍，主要是由于它们的巨大参数量和内存密集型自回归解码。虽然分区计算提供了将模型执行分割到边缘设备和云服务器之间的有希望的解决方案，但现有方法未能解决自回归推理的独特挑战，特别是迭代的标记生成过程和扩展的关键值缓存要求。", "innovation": "本文提出了一种专门用于边缘设备部署的自回归感知分区计算框架。研究成果包括三个关键贡献：发展了一点分割压缩（OPSC），这是一种混合精度量化方案，通过战略性地将模型分区为前端和后端段，以不同的精度级别运行，从而防止内存不足；提出了一个两阶段中间压缩流水线，结合了阈值分割（TS）和标记适配比特量化（TAB-Q），以保留关键激活并大幅减少通信开销；提出了一个统一的优化框架，共同选择最优分割点、量化设置和序列长度，以满足严格的内存和延迟约束。", "conclusion": "广泛的评估表明，该框架在各种大型语言模型和硬件平台上优于现有的量化方法，如SmoothQuant、OmniQuant和Atom，在保持或提高模型准确性的同时实现了1.49倍的推理加速和显著的通信开销减少。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04086", "html_url": "https://arxiv.org/abs/2511.04086", "title": "DeNoise：学习鲁棒的图表示以无监督图级别异常检测", "title_en": "DeNoise: Learning Robust Graph Representations for Unsupervised Graph-Level Anomaly Detection", "authors": "Qingfeng Chen,Haojin Zeng,Jingyi Jie,Shichao Zhang,Debo Cheng", "background": "随着关键领域中图结构数据的快速增长，无监督图级别异常检测（UGAD）已成为关键任务。传统的图神经网络（GNN）方法假设训练集是干净的，只包含正常图，但在实践中往往不可靠。即使是少量的异常图污染也可能扭曲学到的表示并显著降低性能。", "innovation": "我们提出了DeNoise，一种专为污染训练数据设计的鲁棒UGAD框架。DeNoise通过对抗性目标联合优化图级别编码器、属性解码器和结构解码器，学习抗噪嵌入。此外，DeNoise引入了一种编码器锚点对齐去噪机制，将正常图的高信息节点嵌入融合到所有图嵌入中，提高表示质量并抑制异常干扰。对比学习组件则在潜在空间中紧凑正常图嵌入并排斥异常图嵌入。", "conclusion": "在八个真实世界数据集上的广泛实验表明，DeNoise能够在不同噪音强度下持续学习可靠的图级别表示，并显著优于最先进的UGAD基准方法。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04073", "html_url": "https://arxiv.org/abs/2511.04073", "title": "学习多滤镜条件下基于距离度量的邻居搜索中的滤镜感知距离度量", "title_en": "Learning Filter-Aware Distance Metrics for Nearest Neighbor Search with Multiple Filters", "authors": "Ananya Sutradhar,Suryansh Gupta,Ravishankar Krishnaswamy,Haiyang Xu,Aseem Rastogi,Gopal Srinivasa", "background": "已有的基于图的方法通常通过分配固定惩罚或优先处理节点来增强滤镜感知能力，但这些方法使用固定的、与数据无关的惩罚，导致它们无法在具有不同标签和向量分布的多个数据集上泛化。", "innovation": "本文提出了一种原理性的替代方法，通过从数据中直接学习最佳的向量距离与滤镜匹配之间的权衡，而不是依赖固定的惩罚。这种方法将此问题表述为一个带约束的线性优化问题，推导出更好地反映底层滤镜分布的权重，并更有效地解决经过滤的最近邻搜索问题。这些学习到的权重在搜索过程和索引构建中引导，使得图结构能够更有效地捕捉底层滤镜分布和滤镜语义。实验结果表明，适应数据的距离函数相比于固定的惩罚方法提高了5-10%的准确性，提供了一个更灵活和泛化的过滤最近邻搜索框架", "conclusion": "适应数据的距离函数显著提高了过滤最近邻搜索的准确性，相比固定惩罚方法提高了5-10%，并且提供了一个更加灵活和泛化的框架。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04063", "html_url": "https://arxiv.org/abs/2511.04063", "title": "DartQuant：LLM量化中的高效旋转分布校准", "title_en": "DartQuant: Efficient Rotational Distribution Calibration for LLM Quantization", "authors": "Yuantian Shao,Yuanteng Chen,Peisong Wang,Jianlin Yu,Jing Lin,Yiwu Yao,Zhihui Wei,Jian Cheng", "background": "量化在加速大规模模型的推理方面发挥着关键作用，旋转矩阵已被证明能够通过平滑异常值来有效提升量化性能。然而，端到端优化的旋转方法会面临巨大的计算成本和过拟合风险。本研究旨在解决这一挑战，提出了一种高效鲁棒旋转校准方法，DartQuant。该方法通过限制旋转后激活值的分布来降低旋转优化的复杂性，同时降低了对任务特定损失的依赖性，从而减少了过拟合的风险。同时，引入了QR-Orth优化方案，用更高效的方法取代了昂贵的交替优化过程。", "innovation": "1. 提出了DartQuant方法，通过限制旋转后激活值的分布来降低旋转优化的复杂性。\n2. 有效减少了对任务特定损失的依赖性，从而减少了过拟合的风险。\n3. 引入了QR-Orth优化方案，用更高效的方法取代了昂贵的交替优化过程。\n4. DartQuant在多个模型量化实验中表现出更优越的性能，对于70B模型，实现了47倍的加速和10倍的内存节省。\n5. 成为了首个在单个3090 GPU上完成70B模型旋转校准的方法，使大规模语言模型的量化在资源受限环境中成为可能。", "conclusion": "DartQuant展示了在旋转量化中的高效性能，通过有效减少旋转优化的复杂性和计算成本，在降低过拟合风险的同时，显著提高了70B模型的量化加速和内存节省，首次实现了在单个3090 GPU上对70B模型的旋转校准，体现了其在资源受限环境下的可行性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04071", "html_url": "https://arxiv.org/abs/2511.04071", "title": "使用nnU-Net进行MRI心房分割", "title_en": "Left Atrial Segmentation with nnU-Net Using MRI", "authors": "Fatemeh Hosseinabadi,Seyedhassan Sharifi", "background": "左心房（LA）的准确分割对指导房颤消融和构建生物物理心脏模型至关重要。手动勾画方法耗时、依赖观察者且无法适应大规模或时间敏感的临床工作流程。近年来，深层学习方法，特别是卷积架构，在医学图像分割任务中表现出色。本研究使用nnU-Net框架，一种自动、自我配置的深度学习分割架构，对2013年的左心房分割挑战数据集进行了应用。该数据集包含了30个MRI扫描及其对应的专家注释掩模。nnU-Net模型自动适应MRI数据的特点，并进行其预处理、网络配置和训练管道的自适应。分割性能通过dice相似系数（DSC）量化的评估，与专家分割结果进行了定性对比，表明该模型的均dice分达到了93.5，不仅与专家注释高度重合，而且优于先前研究中的一些传统分割方法。该网络在多种左心房形状、对比度和图像质量的变化中表现出了鲁棒的泛化能力，准确勾画了心房主体和近端肺静脉。", "innovation": "使用自动化且自我配置的nnU-Net框架进行左心房分割，该架构能够适应MRI数据的特点并自适应调整其预处理、网络配置和训练管道，从而提高了分割性能和鲁棒性。", "conclusion": "nnU-Net模型在左心房分割任务中显示出高准确性，且具有良好的泛化性能，能够实现准确的分割，适用于临床应用。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04132", "html_url": "https://arxiv.org/abs/2511.04132", "title": "探索端到端大型语言模型作为编译器的可能性", "title_en": "Exploring the Feasibility of End-to-End Large Language Model as a Compiler", "authors": "Hongbin Zhang,Shihao Gao,Yang Liu,Mingjie Xing,Yanjun Wu,Chen Zhao", "background": "近年来，端到端的大型语言模型（LLM）技术在各个领域都显示出了显著的优势。作为关键的系统软件和基础设施，编译器负责将源代码转换为目标代码。虽然LKM已被用于辅助编译器的开发和维护，但作为端到端编译器的潜力仍然没有完全被探索出来。本文探讨了将LLM作为编译器（LaaC）的可行性及其未来发展方向。", "innovation": "本文设计了CompilerEval数据集和框架，专门用于评估主流LLM在源代码理解和汇编代码生成方面的能力。实验结果显示，LLM具备作为编译器的基本能力，但目前的编译成功率较低。通过优化提示、增大模型规模和引入推理方法，可以显著提升LLM生成的汇编代码质量。基于这些发现，本文对LaaC保持乐观态度，并提出了实际的架构设计和未来的研究方向。", "conclusion": "我们认为，通过有针对性的训练、知识丰富的提示以及专门的基础设施，LaaC有可能生成高质量的汇编代码，并推动编译领域范式的转变。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04124", "html_url": "https://arxiv.org/abs/2511.04124", "title": "可分解神经符号回归", "title_en": "Decomposable Neuro Symbolic Regression", "authors": "Giorgio Morales,John W. Sheppard", "background": "符号回归（SR）通过发现能捕获观测数据中潜在关系的数学表达式来复杂系统建模。然而，大多数SR方法更倾向于最小化预测误差而不是识别控制方程，这往往导致过于复杂或不准确的表达式。", "innovation": "本研究提出了一种可分解的SR方法，该方法利用变压器模型、遗传算法（GAs）和遗传编程（GP）生成可解释的多元表达式。特别是，该方法将训练好的“不透明”回归模型简化为解释其计算函数的数学表达式。该方法使用Multi-Set Transformer生成多个描述每个变量如何影响不透明模型响应的单变量符号骨架。通过基于GA的方法评估生成骨架的表现，并选择高质量候选者，最后通过基于GP的级联程序增量合并这些骨架，同时保留其原始骨架结构。最终的多元骨架通过GA进行系数优化。在有控制噪声的不同程度问题上进行了评估，结果显示该方法在内插和外推误差方面优于两种基于GP的方法，三种基于神经网络的SR方法以及一种混合方法。与这些方法不同，该方法在所有测试中都学会了与原始数学结构相匹配的表达式。", "conclusion": "该研究表明，提出的可分解SR方法能够生成与原始数学结构匹配的可解释的符号表达式，具有更好的内插和外推性能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04147", "html_url": "https://arxiv.org/abs/2511.04147", "title": "Exchange Policy Optimization Algorithm for Semi-Infinite Safe Reinforcement Learning", "title_en": "Exchange Policy Optimization Algorithm for Semi-Infinite Safe Reinforcement Learning", "authors": "Jiaming Zhang,Yujie Yang,Haoning Wang,Liping Zhang,Shengbo Eben Li", "background": "安全强化学习(safe RL)的目标是在优化长期性能的同时遵守安全要求。然而，在许多实际应用中，问题涉及到无限数量的约束，这被称为半无限安全RL(SI-safe RL)的问题。这些约束通常在安全条件必须在整个连续参数空间内被强制执行时出现，例如确保每个空间位置的资源分配充足。", "innovation": "本文提出了一种名为交换策略优化(EPO)的算法框架，该框架能够在优化策略性能的同时实现确定性有界的安全。EPO通过迭代解决具有有限约束集的安全RL子问题，并通过约束扩展和删除自适应调整活动集。在每次迭代中，超出预定义容差的约束会被添加以细化策略，而零拉格朗日乘子的约束会在策略更新后被移除。这种交换规则防止了工作集的无控增长，并支持有效的策略训练。", "conclusion": "我们的理论分析表明，假设较为温和的情况下，通过EPO训练出的策略能够实现与全局约束违反严格保持在规定界限内的最优解相媲美的性能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04094", "html_url": "https://arxiv.org/abs/2511.04094", "title": "KoTaP：韩国企业税收规避、业绩与治理面板数据集", "title_en": "KoTaP: A Panel Dataset for Corporate Tax Avoidance, Performance, and Governance in Korea", "authors": "Hyungjong Na,Wonho Song,Seungyong Han,Donghyeon Jo,Sejin Myung,Hyungjoon Kim", "background": "该研究介绍了韩国税收规避面板（KoTaP），这是KOSPI和KOSDAQ两家公司的非金融上市公司2011年至2024年的长周期面板数据集。排除金融机构、非12月财年结束、资本损耗和税前亏损的公司后，最终数据集包含来自1754家公司的12,653个公司年观察数据。KoTaP旨在将企业税收规避作为预测变量，并将其与收益操纵（包括累积和活动基础）、盈利能力（ROA、ROE、CFO、LOSS）、稳定（LEV、CUR、SIZE、PPE、AGE、INVREC）、增长（GRW、MB、TQ）和治理（BIG4、FORN、OWN）等多个领域联系起来，提供了一种平衡的面板结构，并保持与国际文献中关键指标的分布和相关性的连贯性。同时，KoTaP还反映了韩国企业的独特机构特征，如集中所有权、高外国持股比例和提高流动性比率，为国际可比性和情境独特性提供了支持。通过KoTaP，可以应用于经济计量模型和深度学习模型的基准测试、外部有效性检验、可解释AI分析，以及政策评估、审计规划和投资分析，这使其成为会计、金融和跨学科研究的重要开放资源。", "innovation": "KoTaP的主要创新之处在于其平衡的面板结构，标准化变量的一致性，以及其与国际文献中核心指标分布和相关性的连贯性。此外，它还反映了韩国企业的独特机构特征，为国际比较和情境独特性提供了支持。KoTaP通过对现金有效税率（CETR）、公认会计准则有效税率（GETR）、以及账面税收差异度量（TSTA、TSDA）进行了调整，以确保其可解释性。此外，该数据集提供了在经济计量学、深度学习模型基准测试、外部有效性检查、可解释AI分析、政策评估、审计计划和投资分析中的广泛应用，使KoTaP成为会计、金融和跨学科研究中的一项重要开放资源。", "conclusion": "总而言之，KoTaP为企业税收规避、业绩和治理研究提供了独特的数据集。它不仅具有国际可比性，还能够支持多样化的研究和应用，为会计、金融和跨学科研究提供了一个宝贵的资源。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04155", "html_url": "https://arxiv.org/abs/2511.04155", "title": "在任何地方学习着陆：适用于航空轨迹的可迁移生成模型", "title_en": "Learning to Land Anywhere: Transferable Generative Models for Aircraft Trajectories", "authors": "Olav Finne Praesteng Larsen,Massimiliano Ruocco,Michail Spitieris,Abdulmajid Murad,Martina Ragosta", "background": "机场可以访问航迹数据是开发和验证空中交通管理(ATM)解决方案的关键需求，但许多二级和区域机场面临严重的数据稀缺问题。这限制了机器学习方法的应用以及进行大规模模拟或‘假设情景’分析的能力。本文研究了是否可以通过迁移学习，将基于数据丰富的机场训练的生成模型高效地适应数据稀缺的机场。实验在苏黎世和都柏林的起降轨迹数据集之间进行，模型先在苏黎世预训练，然后微调在都柏林数据上，数据量从0%到100%不等。结果表明，基于扩散模型的方法在仅使用5%的都柏林数据时就能获得竞争力的表现，并且在20%的数据时达到与从零开始训练模型相当的基准性能，且在各项指标和视觉检查中表现出一致优势。虽然在捕捉稀有轨迹模式方面存在挑战，但这些发现表明，迁移学习有潜力大幅减少生成航迹所需的数据要求，即使在历史记录有限的环境中也能生成逼真的合成数据。", "innovation": "本文创新性地研究了通过迁移学习将基于数据丰富的机场训练的生成模型高效地适应数据稀缺的机场的可能性。实验采用了最先进的扩散和流动匹配基于架构，并将其应用于航空领域，评价其在苏黎世和都柏林航迹数据集之间的可迁移性。结果显示，基于扩散模型的方法在极少量数据的情况下就能取得与从零开始训练模型相当的效果，展示了迁移学习在减少数据需求方面的潜力。", "conclusion": "虽然在捕捉稀有轨迹模式方面存在挑战，但研究结果表明了迁移学习在减少生成航迹所需数据量方面的巨大潜力，能够在历史记录有限的环境中生成逼真的合成数据。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04160", "html_url": "https://arxiv.org/abs/2511.04160", "title": "有关深度集成中的联合正则化和校准", "title_en": "On Joint Regularization and Calibration in Deep Ensembles", "authors": "Laurits Fredsgaard(1),Mikkel N. Schmidt(1) ((1) Department of Applied Mathematics and Computer Science, Technical University of Denmark)", "background": "深度集成是机器学习中的有力工具，能够提高模型性能和不确定性校准。通常，集成是由独立训练和调整的模型组成，但有证据表明，联合调参可能带来更好的性能。这项研究探讨了联合调参（包括权重衰减、温度缩放和提前停止）对预测性能和不确定性量化的影响。此外，提出了一种部分重叠的保留策略作为启用联合评估和最大化数据训练量之间的实用折中方案。研究结果表明，联合调参一般可达到或提高性能，但在不同任务和指标上效果差异显著。研究还指出了单独优化与联合优化之间的权衡，并认为部分重叠的保留策略提供了一个有吸引力的实用解决方案。这些发现为优化深度集成模型的实践者提供了宝贵见解和指导。", "innovation": "提出了联合调参（权重衰减、温度缩放和提前停止）的方法，并提出了一种部分重叠的保留策略，以在启用联合评估和最大化训练数据使用之间找到实用折中方案。该研究通过实验证明了联合调参在提高性能和不确定性校准方面的有效性，以及不同任务和指标上的差异性效果。", "conclusion": "这项研究概述了深度集成的联合优化方法及其在预测性能和不确定性量化中的应用。研究发现，联合调参在某些情况下可能优于独立调优，而部分重叠的保留策略在实际应用中提供了可行的方法。研究者相信，他们的发现为优化深度集成模型提供了有价值的观点和指导。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04214", "html_url": "https://arxiv.org/abs/2511.04214", "title": "MXFP4量化中一切你所需要的是区块旋转", "title_en": "Block Rotation is All You Need for MXFP4 Quantization", "authors": "Yuantian Shao,Peisong Wang,Yuanteng Chen,Chang Xu,Zhihui Wei,Jian Cheng", "background": "大规模语言模型（LLMs）取得了显著的成功，但其急剧增长的规模带来了内存、计算和能源的巨大成本。后训练量化（PTQ）是高效部署的一种有前景的方法，但要实现准确的W4A4量化仍然是一个开放的挑战。尽管大多数现有方法是为INT4格式设计的，但MXFP4格式的出现——这是一种新的FP4格式，拥有各种硬件支持（NVIDIA、AMD、Intel）——提出了现有技术适用性的问题。", "innovation": "本文建立了MXFP4格式下的PTQ方法的全面基准测试。通过系统评估，我们发现GPTQ等方法表现强劲，而基于旋转的方法因为与MXFP4的标量匹配问题表现出严重的不兼容。我们进一步深入分析了这一冲突，发现了其根本在于MXFP4的PoT块缩放与全球旋转重分布异常能量的不兼容。基于此洞察，我们提出了一种简单而有效的块旋转策略，使基于旋转的方法适应MXFP4，产生了显著的准确率改进。", "conclusion": "我们的发现不仅为实践者提供了明确的指导，也为在新兴低位宽格式下的PTQ研究夯实了基础。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04158", "html_url": "https://arxiv.org/abs/2511.04158", "title": "使用变换器建模异构电子健康记录数据的临床风险识别深度学习方法", "title_en": "Deep Learning Approach for Clinical Risk Identification Using Transformer Modeling of Heterogeneous EHR Data", "authors": "Anzhuo Xie,Wei-Chen Chang", "background": "本研究针对临床风险分类中的挑战，如异构电子健康记录（EHR）数据的不规则时间模式、大规模模态差异和复杂的语义结构，提出了一种基于Transformer的纵向建模方法。该方法作为背景指出，在处理这种复杂且多样化的EHR数据时，传统的建模方法遇到的诸多难题，强调了现有方法在识别临床风险时面临的困难和不精确性。", "innovation": "本研究的创新点在于提出了一种基于Transformer的纵向建模方法，该方法采用多源医疗特征作为输入，并通过特征嵌入层实现结构化和非结构化数据的统一表示。研究引入了一个可学习的时序编码机制，能够捕捉不规则采样间隔下的动态变化，并采用多头自注意力结构进行纵向序列的整体依赖性建模。为了增强语义表示，研究设计了一个语义加权池化模块，能够根据不同医疗事件的关键性赋予它们适当的权重，从而提升与风险相关的特征的区分能力。最后，通过线性映射生成个体级别的风险评分。实验结果显示，该模型在准确率、召回率、精确率和F1-Score方面优于传统机器学习和时序深度学习模型，实现了在多源异构EHR环境中稳定且精确的风险识别，并为临床智能决策提供了一个高效且可靠的方法框架。", "conclusion": "本研究提出的基于Transformer的纵向建模方法能够有效解决异构EHR数据中的挑战，相比传统方法在多个关键指标上表现出优越性，尤其适用于临床风险识别的应用场景，为智能医疗决策提供了高质量的数据分析支持。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04217", "html_url": "https://arxiv.org/abs/2511.04217", "title": "强彩票猜想在多头注意力机制中的应用", "title_en": "The Strong Lottery Ticket Hypothesis for Multi-Head Attention Mechanisms", "authors": "Hikari Otsuka,Daiki Chijiwa,Yasuyuki Okoshi,Daichi Fujiki,Susumu Takeuchi,Masato Motomura", "background": "强彩票猜想（SLTH）假设在随机初始化的神经网络中隐藏着高效率的子网络，即所谓的强彩票票（SLTs）。尽管最近的理论研究已经证明了SLTH在各种神经架构中的有效性，但在变换器架构中，关于SLTH的理解仍然缺乏理论支持。特别是当前的SLTH理论尚未考虑变换器的核心组件——多头注意力机制（MHA）。因此，本文旨在填补这一空白，通过对MHA进行理论分析，探索隐藏在其中的强彩票票是否存在。", "innovation": "本文提出了MHA中强彩票票存在的理论分析，证明了在给定条件下的随机初始化MHA中存在强彩票票，能够以高概率近似任意具有相同输入维度的MHA。此外，进一步利用该理论将SLTH扩展到不需要规范化层的变换器中，通过实验验证了理论结果，表明源模型（MHA和变换器）中的强彩票票与近似目标的误差随着源模型隐藏维度的增加而呈指数级减少。", "conclusion": "研究证明了随机初始化的MHA中存在强彩票票，能够以高概率近似任意具有相同输入维度的MHA，并且通过对MHA的理论分析，将SLTH扩展到了不需要规范化层的变换器中。实验验证了理论分析的准确性，指出利用强彩票票在模型训练中的潜在价值。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04239", "html_url": "https://arxiv.org/abs/2511.04239", "title": "seqme：一个用于评估生物序列设计的Python库", "title_en": "seqme: a Python library for evaluating biological sequence design", "authors": "Rasmus Møller-Larsen,Adam Izdebski,Jan Olszewski,Pankhil Gawade,Michal Kmicikiewicz,Wojciech Zarzecki,Ewa Szczurek", "background": "近年来，用于设计生物序列的计算方法取得了进展，同时发展出了多种评估这些方法性能的度量标准，主要关注设计序列与目标分布的忠实度及其达成所需特性的能力。然而，缺少一个集中的软件库来实施这些度量标准。这项工作中，提出了seqme，这是一个模块化且高度可扩展的开源Python库，包含无模型依赖的度量标准，用于评估生物序列设计的计算方法，适用于多种生物序列：小分子、DNA、ncRNA、mRNA、肽和蛋白质。seqme提供了多种生物序列的嵌入和性质模型，以及结果诊断和可视化功能。该库既可以用于单一计算和迭代计算设计方法的评估。", "innovation": "seqme是一个集成了多种模型无关度量标准的开源Python库，可以评估生物序列设计的计算方法的性能，涉及序列、嵌入和性质三种类型的度量标准，适用于多种生物序列类型，提供了嵌入模型和性质模型，以及结果诊断和可视化功能，并且是模块化和高度可扩展的。", "conclusion": "seqme能够用来评估单次计算和迭代计算设计方法，对于促进生物序列设计领域的研究具有重要意义。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04162", "html_url": "https://arxiv.org/abs/2511.04162", "title": "ScaleDL：追求分布式深度学习工作负载可扩展性和高效运行时预测", "title_en": "ScaleDL: Towards Scalable and Efficient Runtime Prediction for Distributed Deep Learning Workloads", "authors": "Xiaokai Wang,Shaoyuan Huang,Yuting Li,Xiaofei Wang", "background": "深度神经网络（DNNs）是现代人工智能服务的基础，支持自动驾驶、聊天机器人和推荐系统等多种应用。随着模型的增大和复杂度的增加，DNN的工作负载，如训练和推理任务，对分布式计算资源的需求达到了前所未有的程度，使得精确预测运行时成为优化开发和资源分配的关键。传统方法依赖于加性计算单元模型，这限制了其准确性和通用性。相比之下，增强型图建模虽然提高了性能，但显著增加了数据收集成本。因此，迫切需要一种在准确性和数据收集成本之间取得平衡的方法。为了应对这些挑战，我们提出了ScaleDL，这是一种结合非线性层间建模和图神经网络（GNN）跨层交互机制的新运行时预测框架，能够实现不同网络结构的准确和分层通用性DNN运行时预测。此外，我们还采用了D-最优方法来减少数据收集成本。在五个流行DNN模型的工作负载上的实验证明，ScaleDL提高了运行时预测的准确性和通用性，其MRE降低了6倍，RMSE降低了5倍，与基线模型相比.", "innovation": "提出了ScaleDL，这是一种结合非线性层间建模和图神经网络（GNN）跨层交互机制的新运行时预测框架，能够在不同网络结构之间实现分层通用性DNN运行时预测。同时采用了D-最优方法来减少数据收集成本，从而在准确性和数据收集成本之间达到平衡。实验结果证明，ScaleDL在预测精确性和通用性方面优于基线模型.", "conclusion": "实验结果表明，ScaleDL提高了DNN运行时预测的准确性和通用性，与基线模型相比，MRE降低了6倍，RMSE降低了5倍。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04244", "html_url": "https://arxiv.org/abs/2511.04244", "title": "星空为引: 基于时序逻辑语义的可解释概念学习", "title_en": "Guided by Stars: Interpretable Concept Learning Over Time Series via Temporal Logic Semantics", "authors": "Irene Ferfoglia,Simone Silvetti,Gaia Saveri,Laura Nenzi,Luca Bortolussi", "background": "时间序列分类是一个至关重要的任务，尤其是在安全关键领域。然而，这类问题通常使用黑盒深度学习方法来解决，这使得人类难以理解模型输出的逻辑理由。本文旨在通过引入一种新型框架STELE（Signal Temporal Logic Embedding for Logically-grounded Learning and Explanation）来解决这一问题，该框架将分类和解释统一起来，通过将轨迹直接嵌入到时序逻辑概念的空间中来实现。", "innovation": "提出了STELE（Signal Temporal Logic Embedding for Logically-grounded Learning and Explanation）新型方法，一种结合分类与解释的神经符号框架。通过引入一种新颖的STL启发式核，该模型可以将原始的时序数据映射到预定义的STL公式的对齐程度，从而在优化准确性和可解释性之间取得平衡，实现了离散化分解，生成人类可读的STL条件作为局部解释，并生成类别特征公式作为全局解释。", "conclusion": "实验表明，STELE能够在保持竞争力的准确性的基础上提供逻辑正确的解释，并在多种现实世界的基准测试上得到了验证。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04332", "html_url": "https://arxiv.org/abs/2511.04332", "title": "最近邻搜索的差分隐私在上下文学习中的应用", "title_en": "Differentially Private In-Context Learning with Nearest Neighbor Search", "authors": "Antti Koskela,Tejas Kulkarni,Laith Zumot", "background": "近年来，上下文学习变得非常活跃，但也带来了固有的隐私风险。现有的方法忽视了现代大型语言模型（LLM）流水线中的一个关键组件：用于检索相关上下文数据的相似度搜索。因此，作者提出了一个差分隐私（DP）框架，以隐私意识的方式整合相关示例的最近邻搜索，来解决这一问题。实验结果表明，该方法在所有评估基准上优于现有基线，在隐私和实用性之间提供了更好的权衡。", "innovation": "作者提出了一种DP-ICL（Differentially Private in-context Learning）框架，该框架结合最近邻检索和隐私滤波器来确保遵守中心差分隐私预算，从而在所有评估基准上显著优于现有方法，特别是在隐私与实用性之间取得了更好的权衡。", "conclusion": "研究结果显示，提出的DP-ICL方法在文本分类和文档问题回答上的表现优于现有基线方法，表现出在隐私和实用性之间的清晰优势。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04286", "html_url": "https://arxiv.org/abs/2511.04286", "title": "通过贝叶斯偏好推理实现高效的强化学习反馈", "title_en": "Efficient Reinforcement Learning from Human Feedback via Bayesian Preference Inference", "authors": "Matteo Cercola,Valeria Capretti,Simone Formentin", "background": "学习人类偏好是将机器学习模型与主观人类判断对齐的关键。然而，收集这些偏好数据往往代价高昂且耗时，因此需要更高效的机器学习范式。两种经过验证的方法各具优势：基于奖励的混合现实反馈（RLHF）在高维任务如大型语言模型微调方面具有良好的扩展性，而部分基于优化（PBO）通过主动查询实现了更高的样本效率。", "innovation": "我们提出了一种混合框架，将RLHF的可扩展性与PBO的查询效率结合起来，通过将一个采样驱动模块整合到RLHF的管道中，从而实现主动和高效的偏好收集。我们分别在（i）高维偏好优化和（ii）大型语言模型微调两个代表性领域验证了此方法。实验结果表明，该方法在样本效率和整体性能上均具有一致的改进效果。", "conclusion": "该研究提出的混合框架在高维偏好优化和大型语言模型微调任务中，显示出样本效率和整体性能上的持续改进。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04401", "html_url": "https://arxiv.org/abs/2511.04401", "title": "Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness", "title_en": "Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness", "authors": "Subeen Park,Joowang Kim,Hakyung Lee,Sunjae Yoo,Kyungwoo Song", "background": "深度学习模型在不同领域表现出强大的性能，但往往依赖于虚假的相关性，使其在分布变化时变得脆弱。特别是在子群体变化的场景中，模型在少数群体中表现尤为糟糕。现有的方法在缓解这一问题方面取得了一定的进展，但在性能提升方面仍然受限，缺乏将嵌入空间表示与最坏群体误差直接联系起来的严谨理论框架。", "innovation": "提出了一种新的方法——Spurious Correlation-Aware Embedding Regularization for Worst-Group Robustness (SCER)，直接正则化特征表示以抑制虚假线索。通过理论约束嵌入表示，SCER鼓励模型专注于核心特征，减少对虚假模式的敏感性，从而在多个视觉和语言任务上提高了最坏群体的准确性。", "conclusion": "通过系统评价，验证了SCER在最坏群体准确性上的优越性能。研究结果表明，SCER可以有效地提高模型鲁棒性，并在最坏群体上取得了卓越的准确性。代码可以在指定链接下载。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04333", "html_url": "https://arxiv.org/abs/2511.04333", "title": "LUME-DBN：从重症监护不完整数据中进行完整的贝叶斯DBN学习", "title_en": "LUME-DBN: Full Bayesian Learning of DBNs from Incomplete data in Intensive Care", "authors": "Federico Pirola,Fabio Stella,Marco Grzegorczyk", "background": "动态贝叶斯网络（DBNs）在医疗保健领域越来越受到重视，它们能够同时建模患者数据中的复杂时序关系并保持良好的可解释性，这是临床决策的重要特征。然而，现有的纵向临床数据中处理缺失数据的方法大多源自静态贝叶斯网络的文献，未能充分考虑数据的时序特性，这限制了对时间上的不确定性量化的能力，尤其是在重症监护这样的场景下，时序动态理解对于模型可靠性和跨不同患者群体的应用至关重要。", "innovation": "提出了一种基于吉布斯采样的新方法，用于从不完整数据中学习DBNs。该方法将每个缺失值视为遵循高斯分布的未知参数。在每次迭代中，未观察到的值从其完整的条件分布中进行抽样，从而实现合理的插补和不确定性估计。", "conclusion": "该方法在仿真数据集和重症监护的实际数据上进行了评估，相比于标准的模型不可知型技术（如MICE），贝叶斯方法展示了更高的重建准确性和收敛性。此结果强调了将完整的贝叶斯推断纳入时序模型中的临床相关性，提供了更可靠的插补和更深入的模型行为洞察，从而支持更安全和有根据的临床决策，尤其是在缺失数据频繁且可能具有重要性的情况下。”"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04418", "html_url": "https://arxiv.org/abs/2511.04418", "title": "不确定性的幻象：LLMs的不确定性量化在模糊环境下失效", "title_en": "The Illusion of Certainty: Uncertainty quantification for LLMs fails under ambiguity", "authors": "Tim Tomov,Dominik Fuchsgruber,Tom Wollschläger,Stephan Günnemann", "background": "大语言模型（LLMs）的准确不确定性量化（UQ）对于其安全部署至关重要。尽管现实中的语言是模糊且不确定的，现有的UQ方法往往在无模糊的任务上进行评估。实验证明，在无模糊假设下表现良好的不确定性估计器一旦遇到模糊数据，其性能就会急剧下降，接近随机猜测水平。此项研究探讨了这一现象，并发现在多种不确定性估计方法、模型内部表示以及模型集合中都普遍存在这种性能降级。研究表明，预测分布和模型集合基于的估计器在模糊环境下存在根本性的局限性。", "innovation": "本文引入了MAQA*和AmbigQA*数据集，这是首个带有基于事实共现的先验答案分布真实情况的答案分布的模糊问题-答案（QA）数据集。研究发现，当前的不确定性估计器在处理模糊数据时表现出显著性能下降，这是多种不确定性估计方法共同的特性，包括使用预测分布、模型内部表示和模型集合估计。研究揭示了在模糊环境下预测分布和模型集合估计器的根本性局限，指出了当前UQ方法在LLMs中的关键缺陷，并提议重新思考当前的模型范式。", "conclusion": "这项研究揭示了当前LLMs不确定性量化方法中存在的关键不足，并为当前的建模范式提出了重新思考的必要性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04456", "html_url": "https://arxiv.org/abs/2511.04456", "title": "联邦学习中重尾噪声下的随机最小最大优化", "title_en": "Federated Stochastic Minimax Optimization under Heavy-Tailed Noises", "authors": "Xinwen Zhang,Hongchang Gao", "background": "重尾噪声在非凸随机优化中引起了越来越多的关注，因为大量的经验研究表明，它比标准的有界方差假设提供了更现实的假设。本文研究了联邦学习中具有重尾梯度噪声的非凸-PL最小最大优化。", "innovation": "提出了两种新的算法：Fed-NSGDA-M（包含归一化梯度）和FedMuon-DA（利用Muon优化器进行本地更新），并在较宽松的条件下有效解决了联邦最小最大优化中的重尾噪声问题，理论证明两者都达到了$O({1}/{(TNp)^{\frac{s-1}{2s}}})$的收敛率，这是首次在重尾噪声下具有严格理论保证的联邦最小最大优化算法。", "conclusion": "广泛实验进一步验证了它们的有效性，也是首次在重尾噪声下具有严格理论保障的联邦最小最大优化算法。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04445", "html_url": "https://arxiv.org/abs/2511.04445", "title": "ForecastGAN: 基于分解的对抗框架用于多时间尺度时间序列预测", "title_en": "ForecastGAN: A Decomposition-Based Adversarial Framework for Multi-Horizon Time Series Forecasting", "authors": "Syeda Sitara Wishal Fatima,Afshin Rahimi", "background": "时间序列预测在各个领域都非常重要，从金融到供应链管理。现有的时间序列预测方法在处理多时间尺度预测时存在局限性，尤其是变压器模型虽然在长期预测方面表现出色，但在短期预测中往往表现不佳，并且通常不考虑类别特征。ForecastGAN通过集成三个模块解决了这些问题：分解模块提取季节性和趋势成分；模型选择模块根据预测时间尺度选择最优神经网络配置；对抗训练模块通过条件生成对抗网络训练提高预测稳健性。", "innovation": "ForecastGAN是一个基于分解的对抗框架，它有效结合了数值和类别特征，并且通过三种集成的模块解决了长时间和短期预测的挑战，还能够在不同数据特征下实现广泛且高性能的表现，而不需要太多的超参数调整。", "conclusion": "研究成果表明，ForecastGAN在短期预测上持续优于最先进的变压器模型，同时在长期预测上保持竞争力。这是一种更通用的时间序列预测方法，适用于特定情境并能够在多变的数据特征中保持强大的性能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04469", "html_url": "https://arxiv.org/abs/2511.04469", "title": "朝向因果金融市场模拟器", "title_en": "Towards Causal Market Simulators", "authors": "Dennis Thumm,Luis Ontaneda Mijares", "background": "现有的使用深度生成模型的市场生成器在合成金融数据生成方面显示出一定的潜力，但现有的方法缺乏进行反事实分析和风险评估所需的因果推理能力。因此，本文提出了一个结合变分自编码器和结构因果模型的时间序列神经因果模型变分自编码器（TNCM-VAE），以生成同时保留时间依赖性和因果关系的反事实金融时间序列。这种方法通过解码器结构中的有向无环图来施加因果约束，并利用因果Wasserstein距离进行训练。我们的方法通过在Ornstein-Uhlenbeck过程启发的合成自回归模型上进行验证，L1距离的表现优于基线，证明了其优越性，在反事实概率估计方面，L1距离最低可以达到0.03-0.10，比真实值表现更好。该模型允许金融压力测试、情景分析和加强回测，通过生成符合潜在因果机制的反事实市场轨迹来实现这一目标。", "innovation": "提出了一种结合变分自编码器和结构因果模型的时间序列神经因果模型变分自编码器（TNCM-VAE），能够生成同时保持时间依赖性和因果关系的反事实金融时间序列，并通过有向无环图施加因果约束和利用因果Wasserstein距离进行训练，从而提高反事实概率估计的准确性。该方法在金融压力测试、情景分析和加强回测中具有重要应用价值。", "conclusion": "本文提出的TNCM-VAE在反事实概率估计方面表现优越，能够生成符合潜在因果机制的反事实市场轨迹，从而提升金融模拟在风险评估和市场分析方面的效果。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04422", "html_url": "https://arxiv.org/abs/2511.04422", "title": "回归与分类的等价性", "title_en": "On the Equivalence of Regression and Classification", "authors": "Jayadeva,Naman Dwivedi,Hari Krishnan,N.M. Anoop Krishnan", "background": "回归和分类之间形式上的联系一直不明确。虽然在支持向量回归中使用了边距最大化项$\text{\textbackslash}Vert w \text{\textbackslash}Vert$，但它通常只被当作一个正则化项来解释。本文指出，当有$M$个样本落在超平面上时，回归问题与其等价的分类任务具有双射等价性，后者包含$2M$个样本且为线性可分。这表明边距最大化在等价分类任务中的应用可以导致不同于传统使用的回归公式。这一等价性提供了一种新的“可回归性”度量，用于评估回归数据集的难度，而无需事先学习模型。此外，利用这一等价性可以训练神经网络学习一个线性变换，该变换将输入变量映射到一个可以使用线性回归器的线性空间中。", "innovation": "本文揭示了回归与分类之间存在等价性，具体表现为当有$M$个样本落在超平面上时，该等价性使得可将回归问题转化为具有$2M$样本的线性可分分类问题。这一发现有助于从理论上解决回归任务中的一些问题，并提供了一种新的方法——利用等价性的“可回归性”度量来估计回归数据集的难度。此外，还提出了一种利用这种等价性训练神经网络学习线性变换的方法，以优化回归性能。", "conclusion": "本文展示了回归与分类之间的等价性，并基于这种等价性提出了一个新的度量标准——“可回归性”，用于评估回归数据的难易程度。此外，还介绍了如何利用这种等价性训练神经网络以优化回归性能的一种方法。这一研究拓展了对回归与分类关系的理解，并为相关领域带来了新的研究视角。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04473", "html_url": "https://arxiv.org/abs/2511.04473", "title": "为更好地训练和评估知识图谱增强的LLMs提供真实子图", "title_en": "Ground-Truth Subgraphs for Better Training and Evaluation of Knowledge Graph Augmented LLMs", "authors": "Alberto Cattaneo,Carlo Luschi,Daniel Justus", "background": "从图结构知识库中检索信息是提升语言大模型事实准确性的有前途的方向。尽管提出了多种解决方案，但由于缺乏包含图检索真实目标的具有挑战性的问答数据集来进行比较，使得方法间的对比变得困难。", "innovation": "本文提出了SynthKGQA框架，用于从任何知识图谱生成高质量合成的KG问答数据集，并提供KG中的全部真实事实来推理每个问题。这些数据有助于更有效的基准测试KG检索器，并允许我们训练更好的模型。还应用SynthKGQA到Wikidata以生成GTSQA数据集，旨在测试KG检索器在未见过图结构和关系类型中的零样本泛化能力，并在所有流行的KG增强的LLM解决方案上进行基准测试。", "conclusion": "通过SynthKGQA生成的数据集，不仅能够更有效地测试KG检索器的能力，还能够训练更好的模型。GTSQA数据集特别设计用于测试KG检索器在看不见的图结构和关系类型上的零样本泛化能力，这对于评估KG增强的LLMs至关重要。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04485", "html_url": "https://arxiv.org/abs/2511.04485", "title": "Q3R：适用于有效低秩训练的二次加权秩正则化器", "title_en": "Q3R: Quadratic Reweighted Rank Regularizer for Effective Low-Rank Training", "authors": "Ipsita Ghosh,Ethan Nguyen,Christian Kümmerle", "background": "基于低秩优化的参数高效训练方法已成为大型深度学习模型微调的非常成功的工具。但这些方法在低秩预训练任务中失效，需要保持低秩结构和目标函数变得具有挑战性。", "innovation": "提出了带二次加权秩正则化器的Q3R，这是一种借鉴了迭代加权最小二乘（IRLS）框架的新颖低秩诱导训练策略。Q3R基于一个二次正则化项，该项近似于作为秩替代目标的日志行列式。Q3R能够在保持可训练模型中预设低目标秩的同时，实现与密集模型相媲美的预测性能，具有较小的计算开销，并且能够与现有架构完全兼容。例如，在一个实验中，通过Q3R能够将一个ViT-Tiny模型的参数减少60%和80%，在CIFAR-10上的性能分别下降了1.3%和4%。Q3R的有效性已在Transformers的图像和语言任务中得到验证，包括低秩微调任务。", "conclusion": "Q3R能够在保持低秩模型的同时，实现与密集模型相当的性能，具有较小的计算开销，适用于低秩微调任务。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04518", "html_url": "https://arxiv.org/abs/2511.04518", "title": "在自由度匹配的条件下比较EPGP代理和有限元方法", "title_en": "Comparing EPGP Surrogates and Finite Elements Under Degree-of-Freedom Parity", "authors": "Obed Amo,Samit Ghosh,Markus Lange-Hegermann,Bogdan Raiţă,Michael Pokojovy", "background": "本文旨在通过比较边界约束的Ehrenpreis-Palamodov高斯过程（B-EPGP）代理模型与经典的有限元方法结合Crank-Nicolson时间步进（CN-FEM）方法，解决具有齐次Dirichlet边值条件的二维波动方程。为了确保不同方法之间的公平性，引入了自由度匹配协议。", "innovation": "该研究提出了一个新的基准研究，其创新点在于使用边界约束的EPGP代理模型，并通过指数-多项式基底严格满足PDE和边界条件。通过使用正则化最小二乘法估计系数，从而提供了比传统有限元方法更高的准确性，特别是在空间和时间上的L2误差。", "conclusion": "在自由度匹配的条件下，B-EPGP展示了比CN-FEM更好的空间和时间L2误差性能，提高了大约两个数量级的准确性表现。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04505", "html_url": "https://arxiv.org/abs/2511.04505", "title": "刑事司法中的替代公平与准确度优化", "title_en": "Alternative Fairness and Accuracy Optimization in Criminal Justice", "authors": "Shaolong Wu,James Blume,Geshi Yeung", "background": "算法公平性作为研究领域迅速发展，但关于公平性的关键概念在刑事司法领域仍存在争议。本文回顾了团体、个体和过程公平性的理论，并探讨了它们之间的冲突，特别是在刑事司法领域的应用背景。此外，文章还分析了数据偏差和不完整、潜在的隐性正向行动以及子群体约束条件的广泛问题。", "innovation": "提出了一项简单的修改标准团体公平性的方法。具体是使用加权错误损失最小化，同时保持不同保护组的错误拒绝率差异在一个较小的容许范围内，从而更容易找到解决方案，可以提高预测准确性，同时凸显错误成本的道德选择。此外，本文还提出了一种实用的部署框架，其核心要素包括基于需求的决策、透明度和问责制，以及严格定制的定义和解决方案，这将技术设计与合法性联系起来，并为使用风险评估工具的机构提供实际指导。", "conclusion": "这项研究建立了一套实用的公平性和准确度优化框架，通过平衡技术设计和道德选择，旨在提高刑事司法系统的透明度和公正性，同时也为相关决策提供了具体的实际指导。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04494", "html_url": "https://arxiv.org/abs/2511.04494", "title": "分布感知张量分解在卷积神经网络压缩中的应用", "title_en": "Distribution-Aware Tensor Decomposition for Compression of Convolutional Neural Networks", "authors": "Alper Kalle,Theo Rudkiewicz,Mohamed-Oumar Ouerfelli,Mohamed Tamaazousti", "background": "神经网络在图像任务中广泛应用，但通常需要大量的计算资源。一旦网络训练完成，可以通过压缩减少其内存和计算需求。传统的压缩方法通过对权重空间进行低秩近似来寻找低秩近似，例如通过最小化弗罗贝尼乌斯范数。然而，本研究提出的方法使用数据驱动的范数来直接度量函数空间的误差，具体是通过最小化层输出分布的变化量，这是一种新的范数，该方法在不需要任何后调优的情况下，能实现与传统方法相当甚至更高的准确率。", "innovation": "本研究创新性地提出了在层输出分布变化基础上的分布感知张量分解方法，该方法使用数据驱动的范数直接在函数空间中优化，不同于传统的基于权重空间的低秩近似方法。研究者还提出了针对两种最常见的张量分解（Tucker-2和CPD）的新交替最小二乘算法。此方法在多个卷积神经网络架构和数据集上展示了优异的性能，无需后调优即能达到与传统方法相近的准确率。", "conclusion": "研究表明，使用分布感知张量分解方法，可以在不牺牲太多准确性的前提下显著减少卷积神经网络的内存和计算需求。同时，使用基于协方差的范数在不同数据集间转移效果时，即使原始训练数据不可用，也能实现有效的压缩。这种创新性方法为CNN模型的压缩提供了新的思路，对资源受限的计算环境尤其有益。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04514", "html_url": "https://arxiv.org/abs/2511.04514", "title": "在数据偏移下的线性模式连通性对图像分类深度集成", "title_en": "Linear Mode Connectivity under Data Shifts for Deep Ensembles of Image Classifiers", "authors": "C. Hepburn,T. Zielke,A.P. Raulf", "background": "线性模式连通性（LMC）将深度学习的不同方面连接起来，包括在嘈杂的随机梯度下的训练稳定性、局部最小值的平滑度和泛化性能、采样模型的相似性和功能性多样性以及架构对数据处理的影响。这项研究探讨了数据偏移下LMC的现象，识别出减轻其影响的条件，并将数据偏移视为一种额外的随机梯度噪声来源，可以通过使用较小的学习率和较大的批次大小来减少这种噪声。", "innovation": "这项工作实验性地研究了数据偏移下的线性模式连通性，识别出减轻其影响的条件，并通过使用较小的学习率和较大的批次大小来降低数据偏移带来的随机梯度噪声。研究表明，尽管通过LMC采样的模型更倾向于犯类似的错误，但其优点在于可以平衡训练效率和更大、更具多样性的集成模型带来的收益。", "conclusion": "尽管通过LMC采样的模型更倾向于犯类似的错误，其优点在于可以平衡训练效率和更大、更具多样性的集成模型带来的收益，并且通过对学习率和批次大小的优化，可以减轻数据偏移带来的负面影响。相关的代码和补充材料将逐步公开。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04534", "html_url": "https://arxiv.org/abs/2511.04534", "title": "应用于云微物理的降阶代理模型的不确定性量化", "title_en": "Uncertainty Quantification for Reduced-Order Surrogate Models Applied to Cloud Microphysics", "authors": "Jonas E. Katona,Emily K. de Jong,Nipun Gunawardena", "background": "降阶模型（ROMs）能够高效模拟高维物理系统，但缺乏稳健的不确定性量化方法。现有方法通常依赖特定的架构或训练过程，这限制了灵活性和泛化能力。", "innovation": "论文提出了一种后处理、模型无关的框架，用于在潜空间ROMs中的预测不确定性量化。该方法利用并发预测估计ROM管道中多个组件的统计预测区间，包括潜空间动力学、重构以及端到端预测。这种方法不需要修改基础架构或训练过程。", "conclusion": "该方法在云微物理的潜空间动力学模型上进行演示，能够准确预测水滴尺寸分布的演变，并在整个ROM管道中量化不确定性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04522", "html_url": "https://arxiv.org/abs/2511.04522", "title": "基于端到端强化学习的Koopman模型在空气分离单元(eNMPC)中的应用", "title_en": "End-to-End Reinforcement Learning of Koopman Models for eNMPC of an Air Separation Unit", "authors": "Daniel Mayfrank,Kayra Dernek,Laura Lang,Alexander Mitsos,Manuel Dahmen", "background": "本文基于Mayfrank等人2024年提出的方法，该方法利用强化学习训练Koopman代理模型，以实现特定的经济非线性模型预测控制(eNMPC)应用中的最优性能。此前该方法仅在小规模案例中得到验证。本文探讨了该方法在大型空气分离单元模型中的应用，尤其是在具有更高需求响应挑战的案例中。假设可观察变量为真实的、有限的几个工厂变量。与基于系统识别的Koopman eNMPC相比，这种方法在避免约束违反的同时，提供了类似甚至更好的经济效益。", "innovation": "提出了一种基于端到端强化学习的Koopman模型训练方法，专门为解决空气分离单元中的经济非线性模型预测控制问题设计。该方法不仅适用于小规模系统，也可扩展到大规模的工业操作场景。通过减少约束违反，同时保持或提升经济效益的表现，该方法代表了一种创新的控制策略实现方式。", "conclusion": "所提出的方法展示了在大型空气分离单元模型中的有效性，特别是在高需求响应情况下。通过避免约束违反，同时实现相近或更好的经济性能，该方法为优化工业过程的经济性和可控性提供了一种有前景的解决方案。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04573", "html_url": "https://arxiv.org/abs/2511.04573", "title": "ARETE：一种基于大语言模型的自动化文本检索R包", "title_en": "ARETE: an R package for Automated REtrieval from TExt with large language models", "authors": "Vasco V. Branco,Jandó Benedek,Lidia Pivovarova,Luís Correia,Pedro Cardoso", "background": "实施严格的保护措施时面临的最大挑战之一是缺乏关键物种数据，特别是物种分布数据。此外，由于人类活动的加速，必须更快地收集和处理新信息。虽然科学论文和灰色文献中存在这些关键信息，但这些数据通常不便于计算机读取，需要大量的手工工作来获取。", "innovation": "我们提出了一款名为ARETE的R包，这是一个开源软件，利用大型语言模型自动化物种分布数据的提取工作。ARETE集成了从光学字符识别到异常检测和表格式输出的所有数据提取和验证步骤。我们还通过系统比较其模型结果与人工标注工作的结果来验证ARETE的有效性。新提取的数据使已知的分布范围扩展了三个数量级，揭示了过去未被发现的新分布区域，对地理空间保护规划和灭绝风险评估具有重要意义。", "conclusion": "ARETE能够更快地访问以往未利用的分布数据，显著提高了项目中利用此类数据的效率。研究人员可以更好地分配资源，手动验证选定物种的数据，同时利用自动化提取的比例更高。此工作流程还允许在项目规划阶段预测可用的文献数据。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04590", "html_url": "https://arxiv.org/abs/2511.04590", "title": "复杂性作为优势：一种与后悔相关的涌现结构视角", "title_en": "Complexity as Advantage: A Regret-Based Perspective on Emergent Structure", "authors": "Oshri Naparstek", "background": "当前关于复杂系统的研究主要侧重于从内在属性来衡量复杂性，而非从观察者的角度进行评价。这篇文章提出了一种名为Complexity as Advantage (CAA)的新框架，通过从多个观察者视角来衡量系统复杂性，重新定义了复杂性的评估方式。这一框架将若干种关于复杂性和涌现行为的概念统一起来。", "innovation": "CAA框架创新性地将复杂性定义为系统对于不同观察者的挑战程度，提出了一种新的复杂性评估方法——通过预测遗憾（regret）来衡量系统的复杂性。该框架认为那些能够使不同观察者产生不同预测遗憾的系统是“有趣”的系统，从而为复杂性如何具有功能性价值提供了量化依据。", "conclusion": "作者通过简单的动态模型展示了新框架的理念，并探讨了其对学习、演化及人工代理的潜在影响。该框架提供了一种新的理解复杂性与功能价值关系的角度，为复杂系统理论的研究提供了新的视角。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04557", "html_url": "https://arxiv.org/abs/2511.04557", "title": "在图变换器中集成时空上下文以实现关系深度学习", "title_en": "Integrating Temporal and Structural Context in Graph Transformers for Relational Deep Learning", "authors": "Divyansha Lachi,Mahmoud Mohammadi,Joe Meyer,Vinam Arora,Tom Palczewski,Eva L. Dyer", "background": "在医疗、金融和电子商务等领域，关系数据的时间动态源自复杂的交互作用，如患者与提供者之间的交互或不同类别中用户与产品的交互。为了广泛适用，这些数据上的模型必须整合多样实体之间的长范围空间和时间依赖关系，同时支持多种预测任务。然而，现有的关系数据图模型主要关注空间结构，将时间信息仅视为过滤约束以排除未来事件，而非建模信号，并且通常设计为单一任务预测。", "innovation": "为解决这些问题，作者引入了一种时间子图采样器，通过检索超越即时邻域的节点来增强全局上下文，以捕捉相关时间关系。此外，作者提出了一种用于关系深度学习的Relational Graph Perceiver (RGP) 图变换器架构，该架构利用基于交叉注意的潜在瓶颈高效整合结构和时间上下文信息。RGP 还集成了灵活的交叉注意解码器，能够支持联合学习，使单一模型内的不同标签空间任务相互学习。实验结果显示，RGP 在 RelBench、SALT 和 CTU 上表现出领先性能，为关系深度学习提供了支持多样预测任务的通用和可扩展的解决方案。", "conclusion": "RGP 架构通过整合来自不同节点和边类型的信号，将它们融入共同的潜在空间，使得模型能够在整个关系系统中构建全局上下文。实验表明，这种创新方法在多个数据集上均能取得优异的性能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04641", "html_url": "https://arxiv.org/abs/2511.04641", "title": "高效的部分观测大型动力系统概率代理建模技术", "title_en": "Efficient probabilistic surrogate modeling techniques for partially-observed large-scale dynamical systems", "authors": "Hans Harder,Abhijeet Vishwasrao,Luca Guastoni,Ricardo Vinuesa,Sebastian Peitz", "background": "本文关注预报由偏微分方程描述的动力系统（例如，纳维-斯托克斯方程）的概率技术。研究背景在于如何提高现有的模型预测能力和精度，特别是在部分观测的大型动力系统预测中。", "innovation": "本文创新地比较了多种减少采样步骤的方法，包括直接蒸馏、渐进蒸馏、对抗扩散蒸馏、Wasserstein生成对抗网络以及修正流等。实验结果应用于多种挑战性系统，并特别强调了直接预测大规模3D模拟的2D切片，为流体求解器的高效入流生成提供了新途径。", "conclusion": "通过上述方法的比较实验，本文展示了这些技术在提高预测效率和精度方面的能力，尤其是在处理部分观测的部分大型动力系统方面。结果为相关领域的研究提供了新的可能性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04638", "html_url": "https://arxiv.org/abs/2511.04638", "title": "针对神经网络因果干预产生的不同分布表示的解决方法", "title_en": "Addressing divergent representations from causal interventions on neural networks", "authors": "Satchel Grant,Simon Jerome Han,Alexa Tartaglini,Christopher Potts", "background": "通常，机械可解释性方法通过针对干预模型表示来进行因果操作，以理解这些表示编码的内容。本文研究了此类干预是否会生成与目标模型自然状态不同的表示，以及这些表示的解释是否忠实于目标模型的自然状态。实验中发现，常见的因果干预技术往往会将内部表示从目标模型的自然分布中偏离。理论分析揭示了两类不同分布：无害性偏离和有害性偏离，并且提出了一种方法来减轻有害偏离，同时保留干预的可解释性", "innovation": "本文通过理论分析和实验证明了因果干预技术可能导致表示距离目标模型的自然分布产生偏离，并区分了两种不同类型的偏离。提出了一种改进对策——修改Counterfactual Latent (CL)损失函数从Grant（2025）的算法，使其干预更加贴近自然分布，从而减少有害偏离的发生率，同时保持干预的解释力", "conclusion": "本文的研究结果强调了建立更为可靠解释方法的道路"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04598", "html_url": "https://arxiv.org/abs/2511.04598", "title": "环境无关的目标条件化：无需奖励的自主学习研究", "title_en": "Environment Agnostic Goal-Conditioning, A Study of Reward-Free Autonomous Learning", "authors": "Hampus Åström,Elin Anna Topp,Jacek Malec", "background": "本文研究了如何将常规的强化学习环境转化为目标导向的环境，使代理能够在没有外部奖励的情况下自主学习解决问题的能力。研究中展示了代理能够在不依赖外界引导的情况下通过自主选择目标来学习解决任务的方法，且这种学习时长与外部引导强化学习相当。此外，这种方法与基础的归策略学习算法无关。然而，由于该方法对环境不是特定依赖的，这导致代理对所有目标的价值评估均等，导致个别目标的表现不稳定。尽管如此，实验结果表明，所选目标的成功率平均值会逐步提高并趋于稳定。", "innovation": "提出了一种环境无关的目标条件化方法，使代理能够自主选择目标进行学习，这种方法不依赖特定的强化学习算法，且学习时间与外部引导方法相当。此外，研究表明这种方法可以使得训练出的代理能够寻求环境中的任何观察结果，从而为特定的实际应用场景提供通用的训练。", "conclusion": "该研究所提出的方法能够使代理在无需外部奖励的情况下实现自主学习和目标导向解决环境中的任务。实验结果表明这种方法可以改善和稳定平均目标成功率。训练出的代理能够接受进一步的特定指令，这为代理的通用训练提供了可能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04594", "html_url": "https://arxiv.org/abs/2511.04594", "title": "Decentralized Multi-Agent Stochastic Shortest Path Problems", "title_en": "Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest Path Problems", "authors": "Utkarsh U. Chavan,Prashant Trivedi,Nandyala Hemachandra", "background": "多智能体系统（MAS）在跨机器人蜂群和交通路由等应用中至关重要，其中智能体必须以去中心化的方式协调行动以实现共同目标。随机最短路径（SSP）问题为模拟此类场景中的去中心化控制提供了一个自然框架。尽管在单智能体设置中学习SSP问题的研究很广泛，但去中心化的多智能体变种仍然很大程度上未被探索。", "innovation": "作者针对去中心化的多智能体SSP（Dec-MASSPs）问题，首次提出了基于构建复杂学习实例的后悔下界。特别是在线性函数近似的情况下，过渡动力学和成本使用线性模型表示，作者使用新颖的对称性论证来识别最优策略的结构。该项工作的主要贡献是在这种设置下的首个后悔下界，该下界表明在 Dec-MASSPs 中的内在学习难度，并且为去中心化控制的学习复杂性提供了洞察。", "conclusion": "本文的工作揭示了去中心化控制中的学习复杂性，并澄清了这些见解可以进一步指导多智能体系统中高效学习算法的设计。后悔下界 $\text{Ω(√K)}$ 指出在 $K$ 计划周期中面临的固有学习难度。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04653", "html_url": "https://arxiv.org/abs/2511.04653", "title": "TT-Prune: 用于通信高效的时间触发联邦学习的模型剪枝和资源分配", "title_en": "TT-Prune: Joint Model Pruning and Resource Allocation for Communication-efficient Time-triggered Federated Learning", "authors": "Xinlu Zhang,Yansha Deng,Toktam Mahmoodi", "background": "联邦学习（FL）为解决数据隐私问题提供了新的机会。时间触发联邦学习（TT-Fed）作为一种异步和同步联邦学习的综合形式，用户被划分为不同的级别，基于固定的时间间隔。然而，随着无线带宽有限的用户设备在网络中数量的增加，训练延迟和通信开销等挑战变得更为严重。本研究旨在优化模型剪枝比和无线带宽分配，以减少训练损失并确保最小的学习延迟，同时减轻这些挑战的影响。", "innovation": "本文提出了适用于TT-Fed系统的自适应模型剪枝方法，并研究了联合优化剪枝比和无线带宽分配的问题，以在给定延迟阈值下最小化模型训练损失。通过梯度l_2范数收敛分析，基于模型剪枝建立了联合优化问题。使用KKT条件推导出了闭式解，以确定最优的无线带宽和剪枝比。结果显示，通过模型剪枝，通信成本可以减少40%，同时保持模型性能不变。", "conclusion": "研究提出了自适应模型剪枝方法，成功地解决了TT-Fed系统中的通信效率问题，通过联合优化方法使训练损失最小化同时保持了模型的性能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04647", "html_url": "https://arxiv.org/abs/2511.04647", "title": "对于掩码扩散模型的最优推断调度", "title_en": "Optimal Inference Schedules for Masked Diffusion Models", "authors": "Sitan Chen,Kevin Cong,Jerry Li", "background": "标准自回归大型语言模型的主要瓶颈在于其推断过程是固有的顺序性的，导致推断时间非常长且成本高。为解决这一问题，研究者提出了一类称为扩散语言模型的语言模型，其中的掩码扩散模型（MDM）是最成功的。MDM能够按顺序或并行地按需采样标记，但对模型可以在多大程度上并行采样而不降低采样性能，缺乏严格的理解。尽管李和蔡的工作在某种程度上提供了初步的界限，但这些界限对于许多天然分布类别并不是紧的。", "innovation": "本文提供了掩码扩散模型中预期的真实分布与采样分布之间偏差的一种新的、精确的表征，适用于任何分布和任何未使用的计划。通过这一联系，本文取得了此问题的一些新的下界和上界。尽管这种与函数逼近的联系原则上给出了任何分布下的最优推断调度，但在一般情况下，没有先验知识就无法与之竞争，即使是在看似简单的设置中。然而，本文还展示了新的上界和新的采样调度，基于基分布信息论性质，如其总相关性和双总相关性，表明在某些自然设置下，可以在 $O(\text{log } n)$ 步内采样而没有任何性能可见损失。", "conclusion": "研究表明，虽然确定最优推断调度具有挑战性，但通过利用信息论性质可以为某些自然情况下的高效采样提供理论支持。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04666", "html_url": "https://arxiv.org/abs/2511.04666", "title": "遗忘无处不在", "title_en": "Forgetting is Everywhere", "authors": "Ben Sanati,Thomas L. Lee,Trevor McInroe,Aidan Scannell,Nikolay Malkin,David Abel,Amos Storkey", "background": "在开发通用学习算法时，一个根本挑战是它们在适应新数据时会忘记过去的知识。尽管经过几十年的研究，人们尚未达成一个能够揭示学习动态统一定义的理解。因此，需要一种原理性的理解来应对遗忘的问题。然而，迄今为止，没有一个统一的定义能够提供这样的洞见。", "innovation": "本文提出了一种算法和任务无关的理论，将遗忘定义为学习者对未来经验预测分布中缺乏自我一致性，这主要表现为预测信息的丢失。该理论还自然导出了一种评估算法遗忘倾向的一般性度量方法。通过设计跨分类、回归、生成模型和强化学习的广泛实验，验证了该理论的有效性。实验结果表明遗忘存在于所有学习设置中，对学习效率有重要影响。", "conclusion": "这些结果有助于建立对遗忘的原理性理解，并为分析和提高通用学习算法的信息保留能力奠定了基础。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03684", "html_url": "https://arxiv.org/abs/2511.03684", "title": "基于模拟的综合4D/5D数字孪生框架的预测性施工控制验证", "title_en": "Simulation-Based Validation of an Integrated 4D/5D Digital-Twin Framework for Predictive Construction Control", "authors": "Atena Khoshkonesh,Mohsen Mohammadagha,Navid Ebrahimi", "background": "美国建筑行业的持续成本和进度偏差是一个重大挑战，暴露了确定性CPM（关键路径法）和静态文档估算的局限性。", "innovation": "该研究提出了一个集成的4D/5D数字孪生框架，将BIM与基于自然语言处理的费用映射、计算机视觉驱动的进度测量、贝叶斯概率CPM更新以及深度强化学习资源调度相结合。", "conclusion": "通过九个月的案例实施，项目在估算劳动力减少43%、加班减少6%、项目缓冲利用减少30%的同时，按时在P50-P80置信区间内完工。数字孪生沙箱还允许实时的“假设情景”预测和可追溯的成本进度对齐。研究结果证实，将基于AI的分析与概率CPM和DRL结合使用，可提高预测精度、透明度和控制韧性。已验证的工作流为预测性、适应性和可审计的建筑管理提供了实际途径。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03735", "html_url": "https://arxiv.org/abs/2511.03735", "title": "精确控制摩擦：用于微界面逆向设计的生成框架", "title_en": "Friction on Demand: A Generative Framework for the Inverse Design of Metainterfaces", "authors": "Valentin Mouton,Adrien Mélot", "background": "设计表现出预定宏观行为的摩擦界面是一个具有挑战性的逆向问题，主要因为解的非唯一性和接触模拟计算的高成本。传统方法依赖于低维参数化空间的启发式搜索，限制了其对更复杂或非线性摩擦定律的应用。", "innovation": "提出了一种使用变分自动编码器（VAEs）的生成建模框架，以从目标摩擦定律中推断表面拓扑结构。这些模型通过一个包含2亿样本的合成数据集进行训练，该数据集基于参数化的接触力学模型构建。这种方法使人们能够高效、无需模拟地生成候选表面拓扑结构，从而解决逆向设计问题。研究还探讨了生成模型在这一逆向设计任务中的潜力和局限性，重点在于平衡生成解的准确率、处理能力和多样性。", "conclusion": "该方法为通过定制的表面拓扑结构实现近实时的摩擦行为控制铺平了道路。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04667", "html_url": "https://arxiv.org/abs/2511.04667", "title": "多方法对数学入学评估的分析：经典、机器学习和聚类方法", "title_en": "Multi-Method Analysis of Mathematics Placement Assessments: Classical, Machine Learning, and Clustering Approaches", "authors": "Julian D. Allagan,Dasia A. Singleton,Shanae N. Perry,Gabrielle C. Morgan,Essence A. Morgan", "background": "研究使用40项数学入学评估对198名学生进行了评估，结合经典测试理论、机器学习和无监督聚类，评估了该测试的有效性。研究发现，分析显示55%的题目具有良好的区分度，而30%的题目区分度差，需要替换。揭示了测试中最具区分能力的题目，并展示了机器学习算法的优异性能，及聚类分析在评估结构中的应用。这些结果表明，多方法整合为依据证据优化数学入学评估提供了一个坚实的基础。", "innovation": "研究提出了结合经典测试理论、机器学习和无监督聚类分析的多方法框架，评估数学入学考试的有效性。通过这种方法不仅评估了题目质量，还展示了机器学习算法的优异性能，并通过聚类分析揭示了潜在的分类问题，为优化数学入学评估提供了新视角。", "conclusion": "研究建议替换区分度差的题目，采用两阶段评估，并将随机森林预测与透明机制结合。多方法整合为基于证据的数学入学评估优化提供了坚实的基础。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04659", "html_url": "https://arxiv.org/abs/2511.04659", "title": "Nowcast3D：通过灰盒学习实现可靠的降水.nowcasting", "title_en": "Nowcast3D: Reliable precipitation nowcasting via gray-box learning", "authors": "Huaguan Chen,Wei Han,Haofei Sun,Ning Lin,Xingtao Song,Yunfan Yang,Jie Tian,Yang Liu,Ji-Rong Wen,Xiaoye Zhang,Xueshun Shen,Hao Sun", "background": "现有的极端降水现在预报方法存在局限性，数值天气预报(NWP)及其深度学习模拟过于缓慢且解析度较低，难以应对快速演变的对流；外推法和纯数据驱动模型易出现累积误差和过度平滑；现有二维雷达基混合方法忽视了关键的垂直信息，无法准确重建高度相关的动态过程。现有方法在时空分辨率和误差累积方面都有所限制，无法提供长期高精度的极端降水预报。", "innovation": "本研究提出了一种灰盒的全三维现在预报框架，可以直接处理体积雷达回波，并结合物理约束神经算子与数据驱动的训练。模型学习垂直变化的三维对流场，并在保守对流算子下参数化空间变化的扩散。引入布朗运动启发的随机项来表示未解决的小尺度对流和微物理变化。残差支路捕捉小尺度的对流开始和微物理变异性，基于扩散的随机模块估计不确定性。该框架在3小时预报中实现了更准确的降水预报，并在160名气象学家匿名评估中排名第一的57%的情况下表现出色。通过恢复完整的三维动态并保持物理一致性，该方法提供了一条实现极端降水可靠和技能型现在预报的可扩展和稳健途径。", "conclusion": "该框架在不同降水类型的三小时预报中实现了更准确的预测，并在160位气象学家的匿名评估中，有57%的情况下排名第一。这种方法通过保持完整的三维物理一致性，提供了一种扩大和可靠的途径，用于实现极端降水的预测，具有可靠的技能水平。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03746", "html_url": "https://arxiv.org/abs/2511.03746", "title": "一种用于混合发电电力系统稳定性预测的动力递归邻接记忆网络", "title_en": "A Dynamic Recurrent Adjacency Memory Network for Mixed-Generation Power System Stability Forecasting", "authors": "Guang An Ooi,Otavio Bertozzi,Mohd Asim Aftab,Charalambos Konstantinou,Shehab Ahmed", "background": "现代电力系统中有高比例的基于逆变器的资源，这导致了复杂的动态行为，挑战了传统稳定性评估方法的扩展性和通用性。传统的稳定性评估方法难以应对这些问题。因此，需要新的方法来预测电力系统的稳定性，以便及时应对系统的变化。", "innovation": "该论文提出了动态递归邻接记忆网络（DRAMN），结合了物理信息分析和深度学习，用于实时电力系统稳定性预测。DRAMN 使用滑动窗口动态模式分解从相量测量单元和传感器数据构造时间变化的多层邻接矩阵，以捕捉系统动力学，如模态参与因子、耦合强度、相位关系和频谱能量分布。与分别处理空间和时间依赖性不同，DRAMN 直接在递归门机制中集成图卷积操作，从而同时建模动态演变和时间依赖性。在修改后的 IEEE 9 节点、39 节点以及多端高压直流网络上进行广泛验证，表明该框架具有高精度，分别实现 99.85%，99.90% 和 99.69% 平均准确率，超过已测试的所有基准，包括经典的机器学习算法和最近的基于图的模型。该框架还减少了 82% 的特征维度，而不会降低性能。对主测量值的小信号和暂态稳定性事件相关性的分析验证了其在不同稳定性现象中的一致性。", "conclusion": "DRAMN 实现了最先进的准确性，同时为电力系统操作员提供了增强的可解释性，使其适用于现代控制中心的实时部署。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03743", "html_url": "https://arxiv.org/abs/2511.03743", "title": "基于卷积神经网络的模型类别选择深度学习方法", "title_en": "A convolutional neural network deep learning method for model class selection", "authors": "Marios Impraimakis", "background": "在现有技术中，通常需要系统输入信息或对整个系统进行识别来选择模型类别。本文提出了一种新型深度卷积神经网络方法，通过单一自由度的响应及其分类信息训练和验证一维卷积神经网络，可以直接选择新且未标记信号的模型类别，无需系统输入信息或系统的完全识别。此外，还探讨了使用卡尔曼滤波器的物理基础算法增强方法，以融合系统响应信号并利用加速度和位移数据的动力学约束。该方法能够根据信号轻微变化选择模型类别，这些变化可能源于阻尼行为或滞回行为，适用于线性和非线性动态系统以及3D建筑物有限元模型，对结构健康监测具有重要意义。", "innovation": "提出了一种基于单一自由度响应及其分类信息的新型深度卷积神经网络方法，可以无需系统输入信息或系统的完全识别直接选择新且未标记信号的模型类别。同时，引入了使用卡尔曼滤波器进行物理基础算法增强的方法，以更好地融合系统响应信号并利用动力学约束，增强了识别模型类别的准确性和鲁棒性。这种方法在多种类型系统（线性、非线性动态系统及3D建筑有限元模型）中均表现良好，为结构健康监测提供了强有力的工具。", "conclusion": "这种方法能够有效识别模型类别，尤其适用于信号轻微变化导致的不同阻尼或滞回行为的线性和非线性动态系统，以及3D建筑物有限元模型。它提供了一种无需系统输入信息或进行完整系统识别的解决方案，简化且提高了模型类别选择的效率和准确性。该方法不仅理论上具有创新性，也已经在实际应用中展现出了显著效果，特别是在结构健康监测领域。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03771", "html_url": "https://arxiv.org/abs/2511.03771", "title": "沿袭标签树：医学成像中的层级保持对比学习", "title_en": "Climbing the label tree: Hierarchy-preserving contrastive learning for medical imaging", "authors": "Alif Elham Khan", "background": "医学图像标签通常按照分类法（如器官-组织-亚型）组织，但标准的自我监督学习（SSL）忽略了这种结构。现有方法未能充分利用标签树的层级结构，没有将标签树作为训练信号和评估目标来利用。", "innovation": "提出了一种保层级对比框架，该框架使标签树成为第一级别的训练信号和评估目标。引入了两种插件目标：层级加权对比（HWC）和层级感知边界（LAM），使模型能够更好地保留标签树结构。这些目标适用于欧几里得和双曲嵌入，无需架构更改，且与几何无关。实验结果表明，使用这些目标可以提高表示质量，更符合标签树结构。", "conclusion": "通过对照度量尾随性（HF1）、树距离加权准确率（H-Acc）和亲本距离违反率等度量指标评估，验证了HWC和LAM的有效性，证明了它们能够生成最符合标签树的表示。结合使用HWC和LAM可获得最优效果。这些结果提供了一个简单且通用的学习医学图像表示的配方，能够尊重标签树并推动结构丰富领域中性能和解释性的进步。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03756", "html_url": "https://arxiv.org/abs/2511.03756", "title": "基于活跃学习的二阶Karhunen-Loève扩展代理模型", "title_en": "Bifidelity Karhunen-Loève Expansion Surrogate with Active Learning for Random Fields", "authors": "Aniket Jivani,Cosmin Safta,Beckett Y. Zhou,Xun Huan", "background": "研究团队提出了一种适用于具有不确定输入的场值感兴趣的二阶Karhunen-Loève展开（KLE）代理模型。该方法结合了KLE的频谱效率与多项式混沌扩展（PCEs），以保持输入不确定性与输出场之间的显式映射。通过结合低成本低保真（LF）模拟和有限数量的高保真（HF）模拟，该方法能够构建准确且计算成本较低的代理模型。这种方法进一步通过形成一个活跃学习策略来提高代理的准确性，该策略根据代理的泛化误差（通过交叉验证估计）选择新的HF评估，这些误差通过高斯过程回归建模。新的HF样本通过最大化预期改进准则而获得，以针对高代理误差的区域进行优化。", "innovation": "该研究中的创新之处在于结合了低保真（LF）和高保真（HF）模拟，形成了一种能够在保持计算效率的同时提供准确预测的新代理模型。此外，通过形成活跃学习策略，该方法可以自适应地选择新的HF评估来进一步提高预测准确性，这通过最大化预期改进准则实现。最后，该框架在三个复杂程度递增的例子上得到了验证：一维解析基准、二维对流-扩散系统和基于RANS和增强延迟分离涡流模拟的三维湍流圆射流。这一系列例子显示了该方法相对于单保真度和随机采样方法的一致改进在预测准确性和采样效率方面。", "conclusion": "该研究提出了一种二阶Karhunen-Loève展开代理模型，结合了低保真模拟和高保真模拟以及活跃学习策略，以提高预测准确性和样本效率。该方法已在多个复杂程度递增的问题上验证，显示了相对于传统方法的显著优势。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03797", "html_url": "https://arxiv.org/abs/2511.03797", "title": "学习动态测度传输路径：控制视角", "title_en": "Learning Paths for Dynamic Measure Transport: A Control Perspective", "authors": "Aimee Maurais,Bamdad Hosseini,Youssef Marzouk", "background": "论文将控制理论应用于识别采样路径的问题，通过动态测度传输（DMT）的方法。文中指出，常用的路径可能不适合DMT，并将现有的学习替代路径的方法与均场博弈理论建立联系。基于这种联系，提出了一个用于识别倾斜路径的优化问题家族，并提倡使用能够鼓励速度平滑性的目标函数项。介绍了一种基于最近的高斯过程方法求解偏微分方程的新数值算法，并展示了该方法能够恢复更有效和平滑的传输模型的能力，相对于使用未倾斜参考路径的方法而言。", "innovation": "1. 从控制理论视角，提出识别动态测度传输路径的方法，并将其与均场博弈理论建立联系。2. 提出一个优化问题家族，用于识别倾斜路径的动态测度传输路径，并提倡使用能够鼓励速度平滑性的目标项。3. 提出一种基于高斯过程方法的新数值算法，用于解决偏微分方程，并展示其能够提供更有效的传输模型的能力。", "conclusion": "通过引入控制理论视角，该论文提出了新的路径识别优化问题，能够有效地寻找更平滑和高效的动态测度传输路径，并且提出的数值算法为解决实际问题提供了新的工具。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03845", "html_url": "https://arxiv.org/abs/2511.03845", "title": "在多模态LLM中，看还是读：用户行为推理", "title_en": "To See or To Read: User Behavior Reasoning in Multimodal LLMs", "authors": "Tianning Dong,Luyi Ma,Varun Vasudevan,Jason Cho,Sushant Kumar,Kannan Achan", "background": "现代代理系统通过多模态大型语言模型（MLLMs）对用户行为序列数据进行推理的方式正在发生变化。然而，用户行为数据的文本表示或图像表示哪种方式对于最大化MLLM性能更为有效，目前依然是一个未被充分探索的问题。本文通过使用实际的购买序列数据集，展示了在六个MLLM模型中用图像和文本的不同表示方式对预测下次购买行为准确性的影响，揭示了图像表示方式在提升了87.5%的预测准确率的同时并未增加额外的计算成本。", "innovation": "提出了一个系统性基准框架BehaviorLens，用于评估用户行为推理中不同模态之间的权衡。通过将交易数据表示为文本段落、散点图和流程图，该框架在六个MLLM模型中系统地考察了模态选择的影响。这种方法有效区分了文本和图像表示方式对MLLM性能的具体影响，为多模态环境下的用户行为推理提供了新的视角。", "conclusion": "在处理用户行为数据时，图像表示方式比纯文本表示方式能显著提高MLLM预测的准确性，并且这种改进无需额外的计算成本。该研究为多模态结合在大型语言模型中的应用提供了实证支持，并指出未来的探索方向应该更多地关注不同模态表示的选择和平衡。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03770", "html_url": "https://arxiv.org/abs/2511.03770", "title": "基于深度学习的降尺度方法在北欧地区未来温度极值气候风险评估中的应用", "title_en": "Deep Learning-Driven Downscaling for Climate Risk Assessment of Projected Temperature Extremes in the Nordic Region", "authors": "Parthiban Loganathan,Elias Zea,Ricardo Vinuesa,Evelyn Otero", "background": "北欧地区的广泛Koppen-Geiger气候区域经历了快速变化和增加的气候变异性，这增加了适应需求。区域规划需要高分辨率的温度预估。本研究使用融合Vision Transformer (ViT)、Convolutional Long Short-Term Memory (ConvLSTM)和Geospatial Spatiotemporal Transformer with Attention and Imbalance-Aware Network (GeoStaNet)模型的集成降尺度框架，以挪威地球系统模型(NorESM2-LM) Coupled Model Intercomparison ProjectPhase 6 (CMIP6)的输出为依据，在1951-2014期间进行了偏差校正，并通过多标准决策方法Deep Learning-TOPSIS (DL-TOPSIS)在10个气象站上进行了验证。这些站代表了温带海洋气候(Cfb)、亚极地海洋气候(Cfc)、暖夏大陆气候(Dfb)和亚北极气候(Dfc)区域，涵盖北欧广泛气候区域。", "innovation": "本研究提出了一种集成降尺度框架，结合了Vision Transformer (ViT)、Convolutional Long Short-Term Memory (ConvLSTM) 和Geospatial Spatiotemporal Transformer with Attention and Imbalance-Aware Network (GeoStaNet) 模型，并使用Deep Learning-TOPSIS (DL-TOPSIS)多标准决策方法进行评估，能够提供高分辨率的温度预估，改进了基于NorESM2-LM的CMIP6输出。此外，该框架还能够生成站址基础的不确定性估计和极端值，直接用于北极地区的适应政策制定，该地区环境变化迅速，需要适应措施。", "conclusion": "在SSP5-8.5情景下，Dfc和Dfb气候区预计到2100年分别升温4.8°C和3.9°C，日温差增幅超过1.5°C。信号时间首次出现在亚北极冬季(预计在2032年)，这表明迫切需要适应措施。本框架提供了站址基础的高分辨率温度预估和高度适应政策使用的详细信息，尤其是在快速环境变化的高纬度区域。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03825", "html_url": "https://arxiv.org/abs/2511.03825", "title": "不同的分词算法如何影响二进制代码分析中的LLMs和转换器模型", "title_en": "How Different Tokenization Algorithms Impact LLMs and Transformer Models for Binary Code Analysis", "authors": "Ahmed Mostafa,Raisul Arefin Nahid,Samuel Mulder", "background": "分词是分析汇编代码的基础，影响如词汇量、语义覆盖和下游任务性能等内在特性。尽管分词在汇编代码中的重要性，但它仍然是一个未被充分探索的领域。本文通过评估NLP分词模型及其参数选择（如词汇量大小）的内在属性，以及探索针对汇编代码独特特性的预处理定制选项和预分词规则，填补了这一空白，并评估了这些方法对函数签名预测（一种关键的二进制代码分析问题）的影响。本文系统研究了多种分词模型，通过效率和语义捕捉能力的内在评估，比较了不同分词器的表现，并使用先进的预训练模型（如仅解码器的大语言模型Llama 3.2、仅编码器的转换器BERT和编码器-解码器模型BART）进行了评估。初步研究表明，分词器的选择对下游性能有显著影响，但内在指标只能部分预测外在评估结果，揭示了内在分词器属性与实际汇编代码任务之间复杂权衡。", "innovation": "本文填补了汇编代码分词研究领域的空白，通过系统研究多种分词模型，并使用先进的预训练模型进行评估。研究成果提供了优化分词模型进行低级别代码分析的宝贵见解，为基于自然语言模型的二进制分析工作流的稳健性和扩展性做出了贡献。", "conclusion": "研究结果表明，分词器选择显著影响下游性能，内在指标仅部分预测外在评估结果，揭示了内在分词器属性与实际汇编代码任务之间的复杂权衡。最终，研究表明优化分词模型对低级别代码分析至关重要，促进了基于自然语言模型的二进制分析工作流的发展。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03849", "html_url": "https://arxiv.org/abs/2511.03849", "title": "哪些相似性敏感熵？", "title_en": "Which Similarity-Sensitive Entropy?", "authors": "Phuc Nguyen,Josiah Couch,Rahul Bansal,Alexandra Morgan,Chris Tam,Miao Li,Rima Arnaout,Ramy Arnaout", "background": "量化系统的一个传统步骤是测量其熵。传统的熵度量方法（如香农熵）仅捕捉系统元素频率中的信息。Leinster、Cobbold 和 Reeve (LCR) 提出了一个新的方法，能够捕捉元素之间相似性和差异性的丰富信息，这一方法能够提供敏感于相似性的熵。最近，Vendi 分数 (VS) 被提出作为替代方案，引发了 LCX 和 VS 比较的问题，并且需要探讨它们哪一种更为优劣。因此，本文从概念、分析、实验三个层面，使用 53 个机器学习数据集来比较这两个方法，展示了 LCX 和 VS 之间的差异和它们能够提供的互补信息，特别是在半距离介导的依赖性下，它们是如何彼此相关的。通过对 LCX 和 VS 的分析，作者证明了在某些情况下，VS 提供了 LCX 的上界，并推测这种关系在所有情况下都成立。该论文还讨论了在特定背景下 VS 和 LCX 的特定方式替代以及互补的可能性", "innovation": "本文探讨了LCR和VS这两种相似性敏感熵的区别，通过实验比较它们在不同数据集上的表现，展示了它们之间的定量差异和互补信息，提出了半距离的概念来参数化相似性依赖性，并证明了VS在某种情况下是对LCX的上界，这一结论进一步丰富了熵度量理论的应用范围。", "conclusion": "总的来说，作者认为只有在将元素视为更基本的“基本元素”线性组合，或系统和数据集具有量子力学特性的情况下，VS 才是更优的选择。在更广泛的场景下，如果仅仅是想捕捉由相似性编码的丰富信息，LCR 更优；但在某些条件下，这两种方法也可以互补使用。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03876", "html_url": "https://arxiv.org/abs/2511.03876", "title": "使用体素训练的CT衍生心血管流估计通过物理知情神经网络得到改进：一项模拟研究", "title_en": "Computed Tomography (CT)-derived Cardiovascular Flow Estimation Using Physics-Informed Neural Networks Improves with Sinogram-based Training: A Simulation Study", "authors": "Jinyuxuan Guo,Gurnoor Singh Khurana,Alejandro Gonzalo Grande,Juan C. del Alamo,Francisco Contijoch", "background": "非侵入性成像方法评估血液流动对于心脏功能和结构的评估至关重要。CT是一种广泛使用的成像技术，可用于评估心血管结构和功能，然而，直接从对比剂演变的电影中估计血液流速的方法尚未开发。此种背景下，本文的研究背景在于开发一种新的方法，以利用CT成像改进基于物理知情神经网络（PINN）的血液流动估计方法。", "innovation": "本文创新点在于提出了SinoFlow框架，该框架直接使用sinogram数据来估计血液流动。相比使用重建图像进行PINN流估计的ImageFlow，SinoFlow避免了经过滤反投影过程中引入的误差传播，并且在各种不同的CT影像设置下表现更稳定，具有更低的均方误差和速度误差。这项研究展示了SinoFlow在基于CT的血液流动估计中的潜力，并为其作为非侵入性血液流动评估的解决方案提供了一种新的途径。", "conclusion": "本研究证明了SinoFlow在CT基础上进行流估计的潜力，提供了一种更为可行的非侵入性血液流速估计方法。研究结果旨在指导未来将PINNs应用于CT图像，并提供了一种基于图像估计的方法，只要采集参数合理，便能获得准确的流速估计。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03866", "html_url": "https://arxiv.org/abs/2511.03866", "title": "OMPILOT：利用变压器模型实现自动生成共享内存并行计算框架", "title_en": "OMPILOT: Harnessing Transformer Models for Auto Parallelization to Shared Memory Computing Paradigms", "authors": "Arijit Bhattacharjee,Ali TehraniJamsaz,Le Chen,Niranjan Hasabnis,Mihai Capota,Nesreen Ahmed,Ali Jannesari", "background": "近年来，大规模语言模型（LLMs）在代码翻译方面的进展显著加速了编程语言间的转换过程，提高了准确性和效率。传统的基于规则的系统依赖于固定的规则库来处理语法和语义，灵活度较低且准确率不足，而LLMs则通过学习和模仿语言模式来提高模型对编程语言的理解能力，实现了比传统方法更高的准确性和灵活性，促进了代码跨语言的简化转换、降低了开发成本并加速了遗留代码的迁移。", "innovation": "本文介绍了OMPILOT，一个针对C++代码到OpenMP翻译的新型领域特定编码-解码变压器模型。OMPILOT通过自定义预训练目标和结合无监督与监督学习策略，提高了代码翻译的鲁棒性。与先前仅专注于循环层转换的工作不同，OMPILOT在函数层操作以捕捉更宽泛的语义上下文。为了评估该方法，本文提出了OMPBLEU，一种新的复合度量标准，专门用于评估OpenMP并行结构的正确性和质量，弥补了现有翻译度量标准的不足。", "conclusion": "OMPILOT利用变压器模型实现了C++代码到OpenMP的自动并行转换，增强了代码的共享内存并行化效果。通过结合预训练和混合学习策略，提高了翻译的准确性与可靠性。同时，提出的OMPBLEU度量标准填补了现有评估方法的空白，为OpenMP并行结构的评估提供了更全面和严格的标准。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03888", "html_url": "https://arxiv.org/abs/2511.03888", "title": "基于数据和模型增强的YOLOv12 DL模型在沙漠废品检测与分类中的应用", "title_en": "Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model", "authors": "Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui", "background": "全球废弃物危机正在加剧，固体废弃物的产生预计到2050年将增加70%。传统的废物收集方法，特别是在沙漠等偏远或恶劣环境中，劳动密集、效率低下且常常具有一定的危险性。尽管最近计算机视觉和深度学习的进步为自动化废物检测系统打开了新的大门，但大多数研究仍然集中在城市环境和可回收材料上，忽视了有机和有害废物以及未被充分探索的地形，如沙漠。", "innovation": "提出了一种基于精简且轻量版YOLOv12的增强实时对象检测框架，并结合了自我对抗训练（SAT）和专门的数据增强策略。通过使用DroneTrashNet数据集，展示了在精确性、召回率和平均精确度（mAP）方面的显著改进，同时实现了适合资源受限无人机部署的低延迟和紧凑模型大小。与最新的轻量级YOLO变体进行基准测试进一步显示了其在准确性和效率上的最佳平衡。", "conclusion": "结果验证了结合数据为中心和模型为中心的增强技术可以实现沙漠环境中稳健、实时的废品检测。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03882", "html_url": "https://arxiv.org/abs/2511.03882", "title": "探讨自主X射线引导脊柱手术的机器人控制策略学习", "title_en": "Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures", "authors": "Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath", "background": "基于模仿学习的机器人控制策略正在视频机器人领域重新引起关注。然而，尚不清楚这种技术是否适用于X射线引导的程序，尤其是脊柱内固定等过程。这是因为多角度X射线的解读非常复杂。研究人员通过研究双平面引导的穿刺针插入过程中模仿策略学习的机会和挑战来解决这一问题。开发了一个高度仿真的在硅沙箱中自动模拟X射线引导脊柱手术的平台，并收集了一组正确的轨迹和相应的双平面X射线序列，以模拟操作者的逐步对齐过程。", "innovation": "该团队通过开发一个高度真实的在硅沙箱环境，实现了基于模仿学习的穿刺针基于视觉信息自动迭代对齐，从而探索了这种方法的局限性与能力。通过丝滑的实验控制设置，该策略在68.5%的情况下首次尝试成功，并在不同椎体水平保持了安全的椎体内路径。此策略能够适应复杂解剖结构，即使在骨折等复杂情况下表现出色，并具有多样化的初始设置鲁棒性。尽管初步结果显示积极前景，但精度进入点和如何提供足够频繁的反馈等问题也是存在的挑战。进一步的闭环控制将需要更多的考虑，与如何提供信号反馈相关.", "conclusion": "虽然这些初步结果具有潜力，但仍存在一些局限性，特别是在进入点的精确定位方面。为了实现完全闭环控制，需要解决如何提供足够频繁的反馈的考虑问题。通过更稳健的先验知识和领域知识，此类模型可能为未来的轻量级且无需CT的机器人术中脊柱导航研究提供基础。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03890", "html_url": "https://arxiv.org/abs/2511.03890", "title": "基于3D CT图像的主动脉瓣有限元网状自动化形变网络", "title_en": "Shape Deformation Networks for Automated Aortic Valve Finite Element Meshing from 3D CT Images", "authors": "Linchen Qian,Jiasong Chen,Ruonan Gong,Wei Sun,Minliang Liu,Liang Liang", "background": "从3D CT图像精确地建模主动脉瓣对于 biomechanical 分析和患者特定的模拟至关重要，这有助于评估瓣膜健康或进行术前计划。然而，传统的生成方法难以在跨不同患者时提供高质量且一致性的主动脉瓣网格。通常产生的三角形网格具有不规则的拓扑结构，导致在跨患者进行比较时出现形状和对应性的差异。", "innovation": "本文引入了一种基于深度神经网络的模板拟合管道，该方法可以从3D CT图像生成结构化网格的四边形网格以代表主动脉瓣的几何形状。通过使用共同的四边形网格模板对所有患者进行网格重构，保证了网格拓扑的统一性和跨患者的节点到节点、元件到元件的一致对应。这种方法简化了深度神经网络的学习目标，仅使用两个项（几何重建项和平滑正则化项）作为损失函数。实验结果表明，该方法生成了高保真度和改善了形状质量的主动脉瓣表面网格，所需显式的正则化项比传统方法更少。", "conclusion": "使用结构化四边形网格作为模板并用于神经网络训练不仅确保了网格对应性和质量，还简化了训练过程，从而提高了主动脉瓣建模的有效性和效率。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03892", "html_url": "https://arxiv.org/abs/2511.03892", "title": "一种简化高维核矩阵近似的技术", "title_en": "A general technique for approximating high-dimensional empirical kernel matrices", "authors": "Chiraag Kaushik,Justin Romberg,Vidya Muthukumar", "background": "本文提出了适用于核函数在一般条件下随机核矩阵期望算子范数的简单框架，并利用U-统计量的解耦结果和非交换Khintchine不等式，获得了仅依赖于核函数的标量统计量和一个对应的‘相关核’矩阵的上下界。然后，将该方法应用于在一般高维数据中提供内积核矩阵的新、更紧致的近似，其中样本大小和数据维度呈多项式关系。这种方法简化了现有基于矩法和组合论证结果，同时提供了适用于各向异性高斯数据的新近似结果。", "innovation": "本文论文的主要创新点在于，它提供了一种简单、用户友好的方法来估计高维内积核矩阵的期望范数。使用解耦的U-统计量结果和非交换Khintchine不等式，获得了依赖于核函数标量统计量和相关核矩阵的上下界。这种方法相比现有结果更为简化，并提供了新的逼近结果，特别是在各向异性高斯数据的情况下。", "conclusion": "本文通过类似技术得到了关于各向异性高斯数据内核回归偏差更紧致的下界。方法得出了已知结果的简化证明，并提供了对各向异性高斯数据的新逼近结果。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03909", "html_url": "https://arxiv.org/abs/2511.03909", "title": "使用矢量化计算欧拉特征函数和变换", "title_en": "Vectorized Computation of Euler Characteristic Functions and Transforms", "authors": "Jessi Cisewski-Kehe,Brittany Terese Fasy,Alexander McCleary,Eli Quist,Jack Ruder", "background": "加权欧拉特征变换(WECT)和欧拉特征函数(ECF)已在多种应用中证明了其有用性。然而，当前用于计算这些函数的方法既没有优化速度，也没有扩展到高维环境的能力。现有的计算方法在处理高维几何单形复形(或正方体复形)时效率低下且难以扩展。", "innovation": "本文提出了一个使用张量操作的矢量化计算框架，该框架针对GPU架构进行了高度优化，并能适用于任意维度的几何单形复形(或正方体复形)。实验结果表明，该框架在计算WECT和ECF方面比现有方法在多种图像数据集上的速度提高了多达180倍。此计算框架已实现为公开可用的Python包pyECT。", "conclusion": "该工作提供了一个针对GPU优化的计算框架，可用于高维几何复形的WECT和ECF计算，并展示了显著的速度提升，实现了在图像数据集上计算WECT和ECF的快速高效方法。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03900", "html_url": "https://arxiv.org/abs/2511.03900", "title": "GRAD: 基于图检索的自适应解码方法在幻觉缓解中的应用", "title_en": "GRAD: Graph-Retrieved Adaptive Decoding for Hallucination Mitigation", "authors": "Manh Nguyen,Sunil Gupta,Dai Do,Hung Le", "background": "尽管大型语言模型（LLMs）的规模在增长，幻觉缓解仍然是一项持久的挑战。现有的方法往往依赖外部知识源，如结构化的数据库或知识图，通过提示或检索访问。然而，基于提示的语义关联是脆弱且领域敏感的，而符号知识整合则导致了沉重的检索和格式化成本。", "innovation": "本文引入了Graph-Retrieved Adaptive Decoding（GRAD），一种在解码时间进行的方法，可以基于语料库提取的证据对生成进行语义约束，而无需重新训练。GRAD通过在一个前向传递中累积小检索语料库的下一个词概率来构建稀疏令牌转换图。在解码过程中，图检索概率经过最大化归一化并适应性地与模型概率融合，以促进高证据的续写，同时保持流畅性。通过三个模型在各种问答基准测试中的表现，GRAD在内省准确性、幻觉率及正确性方面均显著超过了基本方法，同时实现了所有方法中最高的真理和适用性乘积得分。", "conclusion": "GRAD提供了一种轻量级的、即插即用的选择，替代了对比性解码和知识图谱增强方法，展示了从语料库级词转换获得的统计证据能够有效地引导生成，从而产生更真实且可验证的输出。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03963", "html_url": "https://arxiv.org/abs/2511.03963", "title": "使用密度功率Stein算子进行稳健统计推断", "title_en": "Robust inference using density-powered Stein operators", "authors": "Shinto Eguchi", "background": "当前统计推断方法在处理未规范化概率模型时可能存在不稳健的问题。标准方法如分数匹配虽然具有独立于模型归一化常数的关键特性，但在存在异常值的情况下表现较差。因此，需要开发新的稳健统计推断方法来改进这些不足。", "innovation": "引入了一种基于密度幂的Stein算子，称为γ-Stein算子。这种算子从γ-散度派生出，通过将模型密度提高到正数幂γ进行加权，内在地降低了异常值的影响，提供了一种稳健性原理机制。基于该算子，开发了两个关键应用：γ-内核Stein discrepancies进行稳健适合性测试，以及γ-Stein变分梯度下降进行稳健的贝叶斯后验近似。", "conclusion": "通过在受污染的高斯和四次势模型上的实验结果，证实该方法在稳健性和统计效率方面显著超过了标准基准方法。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03952", "html_url": "https://arxiv.org/abs/2511.03952", "title": "高维情形下SGD的极限定理：动量和自适应步长", "title_en": "High-dimensional limit theorems for SGD: Momentum and Adaptive Step-sizes", "authors": "Aukosh Jagannath,Taj Jones-McCormick,Varnan Sarangian", "background": "研究论文基于现有研究的背景下，探讨了随机梯度下降（SGD）及其变种，尤其是带有Polyak动量和自适应步长的SGD（SGD-M）。现有文献已经对在线SGD及其变种进行了大量研究，但对于高维情况下的行为和性能优化有深入的探究需求。", "innovation": "该研究提出了高维下的随机梯度下降（SGD）和带有动量及自适应步长的SGD（SGD-M）的行为极限，提供了一个比对在线SGD及其变种的严格框架。研究发现，在适当的时间尺度和特定选择的步长下，SGD-M的极限行为与在线SGD一致，但如果步长保持不变，GD-M会放大高维效应，可能导致性能下降。此外，该框架还应用于两种流行的机器学习问题：张量主成分分析（Spiked Tensor PCA）和单指数模型（Single Index Models），展示了自适应梯度调整的在线SGD在高维情况下的优势。", "conclusion": "该研究提供了一个严格的理论框架，解释了早期预条件可以通过正定和增强在线SGD的动态，特别是在高维情况下。这些发现不仅加强了对在线SGD及其变种的理解，还为实际应用提供了指导，特别是在机器学习和数据科学领域。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04275", "html_url": "https://arxiv.org/abs/2511.04275", "title": "在线回顾调整的符合预测推断以更快地适应分布变化", "title_en": "Online Conformal Inference with Retrospective Adjustment for Faster Adaptation to Distribution Shift", "authors": "Jungbin Jun,Ilsang Ohn", "background": "符合预测作为一种构建在交换性假设下具有保证覆盖范围的分布无关预测集的强大框架已经出现。然而，在线环境中数据分布随时间变化，这种情况经常违反交换性假设。为此，近期提出了一些方法，但它们通常因仅向前更新预测而缓慢适应分布变化。", "innovation": "提出了一种新颖的在线符合推断方法，具有回顾性调整功能，旨在实现更快地适应分布变化。该方法利用具有高效排除一项更新公式的回归方法，在新数据到达时追溯调整过去的预测，从而使整个预测集与最新的数据分布相一致。", "conclusion": "通过在合成和真实数据集上进行广泛数值研究显示，提出的这种方法在覆盖率重新校准和统计效率方面优于现有的在线符合预测方法。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04103", "html_url": "https://arxiv.org/abs/2511.04103", "title": "列表语言识别在极限情况下的特征", "title_en": "A Characterization of List Language Identification in the Limit", "authors": "Moses Charikar,Chirag Pabbaraju,Ambuj Tewari", "background": "戈德的古典结果表明，对于本质上任何有趣的语言集合，语言识别在极限情况是不可能的。随后，安格林给出了任务可行性的精确描述。受最近语言生成问题中取得的积极结果的启发，作者重新审视了经典的语言识别问题，尤其是当学习者在每个时刻能够产生一个包含k个猜测的列表时的情况。研究者给出了语言集合可以极限“k-列表识别”的精确特征，并进一步总结了一个概念上吸引人的特征：如果一个语言集合可以被k-列表识别，那么这个集合可以分解为k个可以识别的子集，每个子集的识别长度都是1。此外，研究者还利用特征分析了统计设定中的列表识别速度，并展示了若集合可以k-列表识别，则可以在指数速率下进行k-列表识别，这是最佳可能的结果。另一方面，如果集合不能k-列表识别，则不能以任何趋于零的速度进行k-列表识别。", "innovation": "针对标准语言识别问题，引入了生成每个时间步长k个猜测的功能，并得到了语言集合可以实现k-列表识别的精确条件。这表明能够k-列表识别的语言集合可以分解为k个子集，每个子集都可以被限识别。此外，还提供了列表识别的统计速度估计，证明了解的最优性。", "conclusion": "该研究精确描述了给定有限时间后所有猜测都正确的语言集合的k-列表识别条件。研究者通过递归版本的安格林特征，得出了概念上吸引人的结论：一个语言集合如果可以k-列表识别，那么它可以被分割成k个可以在长度为1的列表中识别的子集。统计设定下，若集合可以k-列表识别，那么识别速率可以达到指数速率，这是最优结果。如果集合不满足k-列表识别条件，则无法以任何趋近于零的速度进行k-列表识别。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04291", "html_url": "https://arxiv.org/abs/2511.04291", "title": "在扩展充分分散条件下最小体积非负矩阵分解的鲁棒性", "title_en": "Robustness of Minimum-Volume Nonnegative Matrix Factorization under an Expanded Sufficiently Scattered Condition", "authors": "Giovanni Barbarino,Nicolas Gillis,Subhayan Saha", "background": "最小体积非负矩阵分解（min-vol NMF）在许多应用中取得成功，包括高光谱成像、化学动力学、光谱学、主题建模和音频源分离等，但是它的噪声鲁棒性一直是一个长期未解决的问题。", "innovation": "论文证明了在所谓的扩展充分分散条件下，最小体积非负矩阵分解能够在存在噪声的情况下识别真实的因子。这一条件要求数据点在由基向量生成的潜在单纯形中被充分分散。", "conclusion": "证明了最小体积非负矩阵分解在噪声环境下的鲁棒性，提出了扩展充分分散条件是保证其能够准确识别真实因子的关键条件。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04228", "html_url": "https://arxiv.org/abs/2511.04228", "title": "REMIND：解码去学习后大模型中残留记忆的输入损失景观", "title_en": "REMIND: Input Loss Landscapes Reveal Residual Memorization in Post-Unlearning LLMs", "authors": "Liran Cohen,Yaniv Nemcovesky,Avi Mendelson", "background": "机器去学习旨在从模型中去除特定训练数据的影响，而无需进行全面重训练。这一能力对于确保隐私、安全和监管合规至关重要。因此，验证模型是否真的忘记了目标数据对于维护可靠性和信任度是必要的。然而，现有的评估方法通常在个体输入层面评估遗忘情况，这可能导致类似语义的例子中存在的残留影响被忽视。这种影响可能会泄露隐私，导致间接信息泄露。", "innovation": "该研究提出了REMIND（Residual Memorization In Neighborhood Dynamics）工具，这是一种新颖的评估方法，旨在检测未学习数据的微妙残留影响，并判断数据是否已被有效遗忘。REMIND通过分析模型在小输入变化下的损失来揭示单点评估无法注意到的模式。研究表明，未学习的数据会产生更平坦、不太陡峭的损失景观，而保留或无关数据则表现出更尖锐、更易变的模式。REMIND仅需要基于查询的访问，其在相似约束条件下优于现有方法，并在不同模型、数据集和改写输入中表现出强大稳健性，使其适用于实际部署。", "conclusion": "REMIND通过提供一种更敏感且可解释的去学习效果衡量指标，提供了一个可靠的评估框架来评估语言模型的去学习效果。因此，REMIND为理解和处理记忆和去学习提供了新的视角。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04255", "html_url": "https://arxiv.org/abs/2511.04255", "title": "MedSapiens: 将姿态应用于重新思考医学成像中的解剖标记检测", "title_en": "MedSapiens: Taking a Pose to Rethink Medical Imaging Landmark Detection", "authors": "Marawan Elbatel,Anbang Wang,Keyuan Liu,Kaouther Mouheb,Enrique Almar-Munoz,Lizhuo Lin,Yanqi Yang,Karim Lekadir,Xiaomeng Li", "background": "尽管传统上依赖于特定领域的模型，随着大规模预训练视觉模型的出现，医学成像中的解剖标记检测正迎来新的机会。这项研究重新审视了基础模型在人类姿态估计中的应用，并将其应用于医学成像领域，特别是通过在多个数据集上的预训练，展示了这些基础模型在解剖标记检测中的潜力，但这一潜力尚未充分挖掘。", "innovation": "提出了MedSapiens模型，利用人类中心的基础模型Sapiens进行多数据集的预训练，实现了多个数据集上最新状态的突破。通过与现有最佳模型的对比，MedSapiens在平均成功检测率（SDR）方面分别比通用模型和专科模型提高了5.26%和21.81%。此外，MedSapiens在数据量有限的情况下展示出了优异的适应性，比之前的研究提高了2.69%的SDR。", "conclusion": "MedSapiens模型证明了人类中心的基础模型可以为医学成像中的解剖标记检测提供强有力的前提条件，并展示了这些基础模型在多个领域和数据量稀少下的高适应性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04309", "html_url": "https://arxiv.org/abs/2511.04309", "title": "DeepPAAC：一种新的深度加金法用于代理问题", "title_en": "DeepPAAC: A New Deep Galerkin Method for Principal-Agent Problems", "authors": "Michael Ludkovski,Changgen Xie,Zimu Zhu", "background": "该论文考虑了连续时间下的主要代理（PA）问题的数值解。通常，PA问题涉及到代理人和委托人之间的信息不对称，代理人的策略是多维的，并且可以有连续和分块的付款。这些特征使得现有方法在解决PA问题时遇到挑战。", "innovation": "为了应对由此引发的隐式哈密尔顿-雅克比-贝尔曼方程，作者开发了一种新颖的深度学习方法——深度主要代理行动评论家（DeepPAAC）行动评论家算法。这种方法能够处理多维状态和控制，以及约束条件。此外，作者还研究了神经网络架构、训练设计和损失函数等因素对求解器收敛性的影响。", "conclusion": "通过五个不同的案例研究，作者展示了DeepPAAC算法在处理多维PA问题时的有效性和适应性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04243", "html_url": "https://arxiv.org/abs/2511.04243", "title": "Twirlator: 一种分析量子机器学习Ansatz子群对称性效应的管道", "title_en": "Twirlator: A Pipeline for Analyzing Subgroup Symmetry Effects in Quantum Machine Learning Ansatzes", "authors": "Valter Uotila,Väinö Mehtola,Ilmo Salmenperä,Bo Zhao", "background": "在几何深度学习和几何和群对称性量子机器学习中，利用数据对称性是提高性能的关键驱动因素。虽然对称化方法显示出潜力，但在量子机器学习中，对其实践开销，如额外门、减少的可表达性以及其他因素的了解还不够深入。本文研究了这种对称性在量子机器学习Ansatz（模型结构）中的影响，提出了一个自动管道来测量不同对称性下的各种特性，并定义了对称性的度量标准为基础的子群大小。文章通过计算描述Ansatz结构在不同对称性下的三种类别的度量标准，展示了不同Ansatz结构在研究中所涉及的不同子群表示下的门开销，并证实了增加对称性减少电路的可表达性，但通常增加了纠缠能力。这些结果有助于选择符合几何量子机器学习应用要求的足够表达性和计算高效的Ansatz模式", "innovation": "本文开发了一种自动管道，用于分析量子机器学习Ansatz中出现的对称性，特别关注子群定义的部分对称性，这是前人研究中较少探讨的。通过不同大小子群代表对19种常见Ansatz进行对称化处理，并计算出描述Ansatz结构在不同对称性下的三种类别的度量标准，从而揭示了在不同对称性下不同Ansatz结构的门开销，并首次证实了增加对称性可以减少电路的可表达性，但通常会增加纠缠能力", "conclusion": "研究结果表明，不同Ansatz结构在不同对称性下的门开销不同，增加对称性会减少电路的可表达性。然而，在大多数情况下，增加对称性会提高纠缠能力。这些结果有助于为几何量子机器学习应用选择足够的可表达性和计算高效的Ansatz模式"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04376", "html_url": "https://arxiv.org/abs/2511.04376", "title": "MusRec: 通过矫正流和扩散变压器实现的零样本文本到音乐编辑", "title_en": "MusRec: Zero-Shot Text-to-Music Editing via Rectified Flow and Diffusion Transformers", "authors": "Ali Boudaghi,Hadi Zare", "background": "音乐编辑已成为人工智能的一个重要且实用的领域，其应用范围从视频游戏和电影音乐制作到根据用户偏好个性化现有曲目。然而，现有的模型存在显著局限性，例如只能编辑由自身模型生成的合成音乐、需要高度精确的提示或需要针对特定任务重新训练，因此缺乏真正的零样本能力。", "innovation": "利用近期在矫正流和扩散变压器方面的进展，我们提出了MusRec，这是首个能够高效且有效地在真实音乐上执行多样化编辑任务的零样本文本到音乐编辑模型。", "conclusion": "实验结果表明，我们的方法在保持音乐内容、结构一致性和编辑保真度方面优于现有方法，为真实场景中的可控音乐编辑奠定了坚实的基础。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04321", "html_url": "https://arxiv.org/abs/2511.04321", "title": "AIM: 高性能PIM架构级IR降软件硬件协同设计", "title_en": "AIM: Software and Hardware Co-design for Architecture-level IR-drop Mitigation in High-performance PIM", "authors": "Yuanpeng Zhang,Xing Hu,Xi Chen,Zhihang Yuan,Cong Li,Jingchen Zhu,Zhao Wang,Chenguang Zhang,Xin Si,Wei Gao,Qiang Wu,Runsheng Wang,Guangyu Sun", "background": "SRAM Processing-in-Memory (PIM) 已成为高性能PIM实现中最乐观的选择，它提供出色的计算密度、能效和计算精度。然而，为了追求更高的性能，需要更复杂的电路设计和更高的操作频率，这加剧了IR降问题。严重的IR降会显著降低芯片性能，甚至威胁可靠性。传统的电路级IR降缓解方法，如后端优化，资源密集且常常在功耗、性能和面积方面做出妥协。", "innovation": "针对这些挑战，我们提出AIM，一种综合软件和硬件协同设计的架构级IR降缓解方法，以应对高性能PIM。AIM首先利用PIM的位串行和就地数据流处理特性，引入Rtog和HR，建立了PIM工作负载与IR降之间的直接关联。基于这一点，提出LHR和WDS，通过软件优化实现广泛的架构级IR降缓解探索，保持计算准确性。接着，开发了IR-Booster，一种动态调整机制，整合软件级别HR信息与硬件IR降监控，以适应PIM宏的V-f对，实现了增强的能效和性能。最后，提出了HR感知任务映射方法，将软件和硬件设计相结合，实现最优改进。", "conclusion": "后布图仿真结果显示，在7nm 256-TOPS PIM芯片上，AIM实现了最高69.2%的IR降缓解，带来了2.29倍的能效改进和1.152倍的加速。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04355", "html_url": "https://arxiv.org/abs/2511.04355", "title": "LLMs仍然挣扎的领域：代码生成基准的深入分析", "title_en": "Where Do LLMs Still Struggle? An In-Depth Analysis of Code Generation Benchmarks", "authors": "Amir Molzam Sharifloo,Maedeh Heydari,Parsa Kazerooni,Daniel Maninger,Mira Mezini", "background": "大语言模型（LLMs）在代码生成方面取得了显著成功，提升其性能已成为AI研究的核心关注点。虽然基准和排行榜越来越受欢迎，但它们提供的关于LLMs细致任务失败情况的信息有限，这对于理解当前局限性和指导更强大模型的发展至关重要。作者对此进行了分析，以填补这一空白。", "innovation": "作者通过深入分析四个流行的代码生成基准中的任务，识别了LLMs最有可能失败的场景，并进一步研究了这些失败的原因，包括静态复杂度在失败中的作用，以及系统检查了114个LLMs一致难以完成的任务，揭示了LLMs的四种常见弱点模式和基准任务中的常见复杂性。", "conclusion": "分析揭示了LLMs在代码生成任务中的四种反复出现的弱点，并指出了导致失败的常见复杂性，在基准任务中最为常见。这些发现对于改进LLMs和理解其局限性具有重要意义。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04361", "html_url": "https://arxiv.org/abs/2511.04361", "title": "使用增强时间序列结构因果模型在能源市场中检测因果制度", "title_en": "Causal Regime Detection in Energy Markets With Augmented Time Series Structural Causal Models", "authors": "Dennis Thumm", "background": "能源市场中的电价形成受到天气模式、发电技术和价格形成之间的复杂因果关系的影响，这种关系在不同时间段会持续变化而不是在特定断点上发生。当前的方法在建模电价时缺乏明确的因果解释或反事实推理能力。现有研究需要依赖真实的数据有向无环图(DAG)，并且未能充分考虑到能源系统的多变量时间数据以及其背后隐含的因果结构。", "innovation": "本文提出了增强时间序列因果模型(ATSCM)，将反事实推理框架扩展到带有学习到的因果结构的多变量时间数据中。该方法通过可解释因素（天气、发电混合、需求模式）、丰富的电网动态以及可观测的市场变量来建模能源系统。ATSCM利用神经因果发现学习时变因果图，无需预设的真实DAG。这种方法能够在现实世界的电力价格数据上实现新的反事实查询，如“在不同可再生能源发电情景下，价格会是什么样？”", "conclusion": "通过引入ATSCM方法，研究解决了当前能源市场价格建模中缺乏因果理解和反事实推理的问题，可以用于分析和预测不同可再生能源发电情景下的电价变化。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04384", "html_url": "https://arxiv.org/abs/2511.04384", "title": "医疗视觉推理中的多任务学习", "title_en": "Multi-Task Learning for Visually Grounded Reasoning in Gastrointestinal VQA", "authors": "Itbaan Safwan,Muhammad Annas Shaikh,Muhammad Haaris,Ramail Khan,Muhammad Atif Tahir", "background": "该研究针对MediaEval Medico 2025挑战，使用LoRA调整的Florence-2模型开发了一种多任务框架，用于同时进行视觉问答（VQA）、解释生成和视觉定位。该系统结合了三个数据集：Kvasir-VQA-x1用于问题解答学习，一个合成增强解释数据集提供结构化医疗推理，以及文本到区域对链接视觉特征与分割掩码。", "innovation": "提出的系统采用多任务设置，使模型能够同时学习视觉定位、推理和解释，生成准确且可解释的响应。与单一任务基线相比，该方法在答案准确性和视觉定位方面表现显著提高，突显了有依据的多任务学习在医疗VQA应用中的有效性。", "conclusion": "研究展示了该框架在同时进行VQA、生成解释和视觉定位方面的有效性，能够产生准确且可解释的响应。实验结果表明，该多任务方法显著优于单一任务基线方法，强调了其在医疗VQA任务中的应用潜力。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04334", "html_url": "https://arxiv.org/abs/2511.04334", "title": "子流形稀疏卷积网络在计算机断层扫描中自动3D分割肾脏和肾肿瘤的应用", "title_en": "Submanifold Sparse Convolutional Networks for Automated 3D Segmentation of Kidneys and Kidney Tumours in Computed Tomography", "authors": "Saúl Alonso-Monsalve,Leigh H. Whitehead,Adam Aurisano,Lorena Escudero Sanchez", "background": "在放射学图像如计算机断层摄影中准确界定肿瘤是一项非常专业且耗时的任务，目前已成为临床上常规进行定量分析的瓶颈。因此，开发用于医学影像肿瘤自动分割的方法至关重要，近年来已经投入了大量努力。然而，传统卷积神经网络处理3D扫描时的不实用性，通常需要缩减图像或使用其子块，因为3D扫描图像中包含了大量体素。本文背景说明了这一挑战及其对现有方法的限制。", "innovation": "本文提出了一种新的方法，该方法分为两个阶段：体素稀疏化和子流形稀疏卷积网络。该方法使高分辨率输入和天然3D模型架构下的分割成为可能，同时显著降低了所需计算资源，减少了GPU内存和时间消耗。特别地，本文方法在与挑战获胜者竞争的同时，还在肾脏+肿块、肿瘤+囊肿以及单独的肿瘤的约96%、86%和80%的Dice相似系数方面达到了最先进的准确性。", "conclusion": "本研究方法在肾脏癌患者计算机断层扫描图像的部署中获得了成功，实现的推理时间减少了60%，VRAM使用减少了75%，相对于等效密集架构在CPU和GPU中都有所改善。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04403", "html_url": "https://arxiv.org/abs/2511.04403", "title": "在线贝叶斯实验设计在部分观测动力系统中的应用", "title_en": "Online Bayesian Experimental Design for Partially Observed Dynamical Systems", "authors": "Sara Pérez-Vieites,Sahel Iqbal,Simo Särkkä,Dominik Baumann", "background": "贝叶斯实验设计（BED）提供了一种优化数据采集的有原则框架，但现有的方法不适用于现实世界中的关键场景，例如部分可观测性的动态系统，这些系统只能获得噪声较大的不完整观测数据。这些系统自然地被建模为状态空间模型（SSMs），其中的潜在状态媒介参数与数据之间的关系，使得似然函数——以及信息论目标如预期信息增益（EIG）——变得无法解决。此外，系统的动态性质要求在线算法能够以高效的方式更新后验分布并按顺序选择设计。", "innovation": "本文通过推导新的EIG及其梯度的估计器，明确地边缘化潜在状态，提出了在非线性SSMs中实现可扩展的随机优化的方法。该方法利用嵌套粒子滤波器（NPF）进行高效在线推理，并提供了收敛性保证。", "conclusion": "将该框架应用于实际模型，如易感-感染-恢复（SIR）模型和移动源位置任务模型，结果显示，该框架成功处理了部分可观测性和在线计算的问题。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04437", "html_url": "https://arxiv.org/abs/2511.04437", "title": "基于深Koopman的巴氏杀菌装置经济模型预测控制", "title_en": "Deep Koopman Economic Model Predictive Control of a Pasteurisation Unit", "authors": "Patrik Valábek,Michaela Horváthová,Martin Klaučo", "background": "本文提出了用于高效运行实验室规模巴氏杀菌单元（PU）的基于Koopman深度模型的经济模型预测控制（EMPC）。该方法使用Koopman算子理论将复杂的非线性系统动力学线性化，以实现凸优化的应用，并准确地表示复杂的PU。该论文在这种背景下讨论了如何通过Koopman算子理论及深度学习方法来优化巴氏杀菌装置的控制策略。", "innovation": "本文的创新之处在于使用Koopman算子理论和神经网络构建深度Koopman模型，该模型能够从实验数据中学习线性动力学，并在开环预测准确性方面比传统的N4SID子空间识别方法提高了45%。此外，提出的方法不仅能够提供经济成本的可解释性，还能通过引入松弛变量确保EMPC的可行性。", "conclusion": "通过在受外部干扰的多变量BA系统模型上进行数值验证，研究表明基于Koopman的EMPC相比N4SID基准方法能够降低32%的总经济成本，主要归因于物料损失和能源消耗的减少。同时，基于Koopman的稳态操作所需的电气能量减少了约10.2%。最终结论指出，将深度Koopman表示与经济优化相结合，能够实现对热工密集型装置的资源高效控制。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04439", "html_url": "https://arxiv.org/abs/2511.04439", "title": "顺序奖励的困境：为什么GRPO在顺序奖励下会失效", "title_en": "The Peril of Preference: Why GRPO fails on Ordinal Rewards", "authors": "Anisha Garg,Ganesh Venkatesh", "background": "GRPO（Group-relative Policy Optimization）的简洁性和适应特定任务的能力使其具有高度吸引力，但这种简洁性也使其在富集非二元反馈的强化学习训练中变得不完善。当使用不同顺序奖励时，GRPO的基于组平均的基准会错误地对失败轨迹赋予正优点，强化错误的行为。", "innovation": "提出了改正正确性相对策略优化（CoRPO，Correctness Relative Policy Optimization），它通过引入一个可调节的基准，确保失败的解决方案永远不会被正向强化。一旦策略连续满足此阈值，则基准自动过渡到相对偏好模式，促使模型找到最优解而不仅仅是“可接受”的解决方案。CoRPO 现已通过代码验证任务得到了实证验证，展示了更稳定的收敛和更好的领域外泛化能力。这项工作代表了我们更大研究计划的关键一步，旨在通过强化学习使大模型学习真实的全新能力。", "conclusion": "通过引入CoRPO，我们克服了传统GRPO在使用顺序奖励时的问题，通过适应较为复杂的反馈，使模型能够学习更加复杂和精细的任务，并在实践中展示了更好的性能和稳定性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04465", "html_url": "https://arxiv.org/abs/2511.04465", "title": "订阅平台上的防欺诈收入分配", "title_en": "Fraud-Proof Revenue Division on Subscription Platforms", "authors": "Abheek Ghosh,Tzeh Yuan Neoh,Nicholas Teh,Giannis Tyrovolas", "background": "研究一种基于订阅的平台模型，用户支付固定费用以无限访问内容，创作者获得收入的一部分。现有的欺诈检测方法主要依赖机器学习技术，与不良行为者展开持久的军备竞赛。现有研究在这方面的努力既未能有效地防止欺诈，也使得检测欺诈变得更加困难。", "innovation": "该研究正式化了三种防欺诈的公理，并检查了现有规则是否满足这些公理。发现常用的收入分配机制不仅未能防止欺诈，还使欺诈检测变得计算上不可行。此外，提出了一种新的规则“ScaledUserProp”，该规则满足所有三种防欺诈的公理。", "conclusion": "通过对真实和合成的流媒体数据进行实验，展示了“ScaledUserProp”作为一种比现有规则更公平的替代方案的有效性。这一研究提出了一个可以从根本上减少欺诈的新机制，并验证了其有效性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04484", "html_url": "https://arxiv.org/abs/2511.04484", "title": "重复最优停止问题的在线算法：同时实现竞争比和后悔界", "title_en": "Online Algorithms for Repeated Optimal Stopping: Achieving Both Competitive Ratio and Regret Bounds", "authors": "Tsubasa Harada,Yasushi Kawase,Hanna Sumita", "background": "我们研究了重复最优停止问题，该问题将古典最优停止问题推广到一个设定中，在这个设定中，同一问题在T轮中重复解决。在这种框架下，我们旨在设计在每一轮都能保证竞争比同时在整个过程中实现子线性后悔的算法。", "innovation": "我们的主要贡献是一个通用的算法框架，能同时解决广泛重复最优停止问题的竞争比和后悔界限。核心思想是动态选择每一轮的算法，选择这两种候选算法之一：（1）根据历史观察得到的的经验最优算法；（2）基于样本的竞争比有保证的算法。", "conclusion": "我们展示了我们的框架在经典的预言不等式、秘书问题及其对抗性、随机和独立同分布输入模型下的变体中具有广泛的应用性。我们的方法对于重复预言不等式问题从第二轮开始保证1/2的竞争比，并且有$\tilde{O}(\bar{T})$的后悔。同时，我们证明即使是独立同分布模型下，后悔的下界也有$\bar{O}(\bar{T})$，表明我们的算法性能几乎最优。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04550", "html_url": "https://arxiv.org/abs/2511.04550", "title": "保密计算在云安全中的应用：探讨基于硬件的加密使用受信任执行环境", "title_en": "Confidential Computing for Cloud Security: Exploring Hardware based Encryption Using Trusted Execution Environments", "authors": "Dhruv Deepak Agarwal,Aswani Kumar Cherukuri", "background": "随着云计算的增长，数据处理和存储能力得到了前所未有的扩展和灵活性，然而这个过程也带来了巨大的安全挑战，特别是在保护敏感数据方面。传统的安全措施，例如静态和传输中的数据加密，无法保护数据在使用过程中的安全性，并且容易受到各种可能的泄露。为应对这一挑战，保密计算作为工具，在硬件基础的安全执行环境中保证数据在处理中的隐私和完整性，例如Intel的软件保护扩展(SGX)和ARM的TrustZone。", "innovation": "本研究探讨了Intel SGX和ARM TrustZone等受信任执行环境的架构和安全功能，并分析了这些环境在提升云数据安全性方面的应用效果。通过全面的文献调研，研究了这些受信任执行环境的部署策略、性能指标以及实际应用场景，并讨论了部署问题、潜在弱点、可扩展性问题和集成问题。研究结果强调了受信任执行环境在增强和推进云安全基础设施中的中心地位，指出了它们为保密计算提供的安全基石。", "conclusion": "本研究主要集中在受信任执行环境的中心地位，指出它们在加强和推进云安全基础设施中的作用，并强调了保密计算为云安全带来的可能性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04491", "html_url": "https://arxiv.org/abs/2511.04491", "title": "RUST-BENCH：在结构化表格中评估LLM推理对未结构化文本的基准", "title_en": "RUST-BENCH: Benchmarking LLM Reasoning on Unstructured Text within Structured Tables", "authors": "Nikhil Abhyankar,Purvi Chaurasia,Sanchit Kabra,Ananya Srivastava,Vivek Gupta,Chandan K. Reddy", "background": "现有的表格推理基准测试大多集中在小且统一的表格上，未能充分代表真实世界数据的复杂性，对大型语言模型（LLMs）的推理能力进行了片面评估。真实的世界表格通常很长、异质且针对特定领域，它们混合了结构化字段和自由文本，并要求在数千个标记中进行多级推理。鉴于此差距，研究引入了RUST-BENCH，这是一个包含7966个问题、2031个真实世界表格的基准测试，覆盖两个领域：(i) RB-Science（NSF资助记录）和(ii) RB-Sports（NBA统计）。", "innovation": "RUST-BENCH综合评估LLMs在规模、异质性、领域的特定性以及推理复杂性方面的表现。通过开源和专有模型的实验表明，LLMs在异质结构和复杂的多级推理方面存在困难，揭示了当前架构中的持续弱点并促使了策略的发展。RUST-BENCH建立了一个新的具有挑战性的测试环境，推动了表格推理研究的进步。", "conclusion": "RUST-BENCH通过引入一个涵盖真实世界表格的社区案例，填补了现有表格推理基准的空白。它为准确评估和改进LLMs的推理能力提供了一个全面的评估工具，促进了这一领域的研究进展。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04454", "html_url": "https://arxiv.org/abs/2511.04454", "title": "在多臂老虎机环境下拟合强化学习模型到行为数据", "title_en": "Fitting Reinforcement Learning Model to Behavioral Data under Bandits", "authors": "Hao Zhu,Jasper Hoffmann,Baohe Zhang,Joschka Boedecker", "background": "近年来，强化学习（RL）模型在人类和动物决策行为的表征中受到了广泛关注。该研究考虑在一个多臂老虎机环境中拟合RL模型到给定的行为数据的问题。为了支持广泛的RL模型应用，文中提供了通用的数学优化问题表述，并对它的凸性进行了详细理论分析。", "innovation": "基于理论结果，文中提出了一种基于凸松弛和优化的新颖解题方法，用于RL模型的拟合问题，该方法在几个模拟的老虎机环境中与文献中的基准方法进行了比较，显示出与最先进的方法相当的性能，同时大大减少了计算时间。此外，文中还提供了一个开源的Python包，从而使研究人员能够直接在自己的数据集中应用该方法，无需先验了解凸优化知识。", "conclusion": "数值结果显示，我们的方法在性能上与最先进的方法相当，但在计算时间上表现出了显著的优势。我们还提供了一个开源的Python包，使研究人员可以直接在他们的数据集中应用该方法，无需了解凸优化。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04539", "html_url": "https://arxiv.org/abs/2511.04539", "title": "功能脑图的统一生成隐空间表示", "title_en": "Unified Generative Latent Representation for Functional Brain Graphs", "authors": "Subati Abulikemu,Tiago Azevedo,Michail Mamalakis,John Suckling", "background": "功能脑图通常用独立的图论或频谱描述符来描述，但忽略了这些属性在个体之间和条件下如何共变和部分重叠。研究者推测，密集的加权功能连通图沿一个低维隐空间占据位置，在这里同时存在拓扑和频谱结构的分级变化。现有的方法只是分别研究这些属性，没有方法能将它们统一起来研究和表示。", "innovation": "本研究提出了一种基于图变换器自动编码器和潜在扩散的统一图表示方法，该方法能够生成密集的功能脑图，并且通过频谱几何引导学习，更好地分离工作记忆状态和解码视觉刺激。通过模型化的扩散分布，研究者成功抽样生成了生物学上可信并且结构上合理的合成密集图形。这种方法增强了对神经动力学的结合利用，进而提升了性能。", "conclusion": "本研究通过引入几何意识的潜在表示方法，对功能脑图进行了综合研究，不仅通过图变换器自动编码器和潜在扩散方法生成了密集的图结构，还通过结合频谱几何和神经动力学，提高了对工作记忆状态和视觉刺激的解码性能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04564", "html_url": "https://arxiv.org/abs/2511.04564", "title": "物理信息反问题中的不确定性：科学人工智能中的隐含风险", "title_en": "Uncertainties in Physics-informed Inverse Problems: The Hidden Risk in Scientific AI", "authors": "Yoh-ichi Mototake,Makoto Sasaki", "background": "该研究背景在于物理信息机器学习（PIML）中利用偏微分方程（PDEs）将物理知识融入机器学习模型，以解决诸如通过估计系数函数（例如哈密顿函数）来表征物理系统的行为的逆问题。尽管在PIML中通常基于预测性能来估计系数函数，但作为一门学科，物理学本身并不完全依赖于模型预测的准确性来评估模型。精确的模型可能由于几何约束等条件而并非最优解，强调了数据驱动模型中的固有不确定性以及选择物理上合理解的重要性。", "innovation": "本文创新性地提出了一个框架，用于量化和分析物理信息机器学习中系数函数估计过程中的不确定性。作者将该框架应用于磁流体力学的简化模型，并显示了通过几何约束可以识别出不确定性，保证了唯一性识别的可能性，并且通过结合这些约束可以唯一估计出简化模型。", "conclusion": "研究表明在物理信息机器学习中存在固有的不确定性，尤其是通过对系数函数的估计。通过提出的新框架，物理限制可以用来减少不确定性，从而在物理合理的条件下唯一地确定模型参数。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04451", "html_url": "https://arxiv.org/abs/2511.04451", "title": "基于LSTM的无字典深度方法用于含输入延迟的非线性系统线性模型识别", "title_en": "Deep Dictionary-Free Method for Identifying Linear Model of Nonlinear System with Input Delay", "authors": "Patrik Valábek,Marek Wadinger,Michal Kvasnica,Martin Klaučo", "background": "含输入延迟的非线性动态系统在预测、估计和控制中因其固有的复杂性和延迟对系统行为的影响带来重大挑战。传统线性控制技术在这些环境中往往无效，需要创新方法。这些系统中，预测和控制的难度增加，因为延迟信息的处理需要新的方法来准确建模系统的动态特性。现有的方法如扩展动态模式分解(eDMD)依赖预定义的字典，这种方法在系统内部动力学已知的情况下有效，但对于未知非线性动态的系统表现不佳，存在准确度较低的问题，且难以处理系统内部的复杂动力学特性。因此，需要一种能够有效解决这些问题的新方法。文章提出了一种使用LSTM增强的深度Koopman模型来近似Koopman算子，这种方法能够将非线性系统与时间延迟的动态特性线性表示。LSTM层次的引入能够捕捉历史依赖性，并将系统动态有效地编码到潜在空间中，从而减轻已知系统动态信息的限制。与基于扩展动态模式分解方法的比较表明，在未知非线性动态的情况下，预测准确度有显著提高，与已知系统动力学的eDMD方法取得相似的结果。综上所述，这种方法为处理含输入延迟的非线性系统提供了一种新的途径和可能性，能够有效提高预测和控制的准确性，且方法具有字典自由特性，易于处理系统的复杂动力学特性。这种方法的有效性已经在模拟系统上得到了验证，并展示了卓越的性能。此外，这种方法也为态空间模型的研究提供了一种新的思考方向和实践方法，为空间模型识别提供了新的可靠性校验基准。", "innovation": "提出了一种LSTM增强的深度Koopman模型，这种方法能近似Koopman算子，将非线性系统与时间延迟的动态特性线性表示，并通过引入LSTM层次来捕捉历史依赖性，这种方法是一种全新的字典自由方法。相对于传统的扩展动态模式分解方法，提出的模型在处理未知非线性动态时表现出了显著的优势，验证了其在预测准确度上的优越性，且复杂动力学特性的处理也更加灵活和有效。这种方法为非线性动态系统研究提供了新的解决方案和可能性，增强了其在复杂系统预测和控制中的应用潜力。", "conclusion": "本文提出了使用LSTM增强的深度Koopman模型来近似Koopman算子的方法，该方法能够有效处理含输入延迟的非线性系统的复杂动力学特性。与基于扩展动态模式分解方法的比较表明，这种方法在预测准确度上具有显著的优势，尤其在处理未知非线性动态时表现出色。该模型的字典自由特性使得它能够更好地处理复杂系统中的不确定性，且预测效果与已知系统动力学条件下的eDMD方法相当。总之，这种方法为处理非线性动态系统提供了一种有效的途径，并为未来研究提供了新的思路和实践方法。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04461", "html_url": "https://arxiv.org/abs/2511.04461", "title": "使用集合Hankel动态模式分解的德尔夫特372双体船数据驱动的不确定性感知摇摆预测", "title_en": "Data-driven uncertainty-aware seakeeping prediction of the Delft 372 catamaran using ensemble Hankel dynamic mode decomposition", "authors": "Giorgio Palma,Andrea Serani,Matteo Diez", "background": "该研究旨在通过试验测量，利用1:33.3比例的德尔夫特372模型在海况5条件下进行非规则波池试验，收集波高、纵中心重力波高、俯仰角、假设飞行甲板速度、假设驾驶室加速度和总阻力的数据，并将这些数据分为训练集、验证集和测试集。目标是开发一种集合基于的Hankel动态模式分解与控制（HDMDc）方法，以进行桥梁摇摆的预测和不确定性量化，特别是在不确定性的感知下，为设计和操作支持提供可靠且高效的预测方法。在此之前的研究通常侧重于单一模型或缺乏足够的不确定性量化方法。", "innovation": "本文创新地提出了集合Hankel动态模式分解与控制（HDMDc）算法，并将其应用于德尔夫特372双体船的摇摆预测。该算法通过增加带有时间滞后拷贝的状态和输入来构建一个状态空间方程模型，以捕捉系统的非线性和记忆效应。此外，该研究引入了两种集成策略：贝叶斯HDMDc和频率主义HDMDc。前者通过采样被视为随机变量的超参数的先验分布来产生具有置信区间和后验平均预测的样本，而后者则通过在数据子集上获得多个模型并进行汇总来提高预测准确性。贝叶斯HDMDc在此情境下并不优于确定性模型，而频率主义HDMDc则显著提升了预测的准确性并提供了稳健的不确定性估计。从概率密度函数来看，FHDMDc方法的预测结果更为可靠且与实验数据和UNRANS结果吻合较好。", "conclusion": "频率主义HDMDc方法在摇摆预测和不确定性估计方面优于传统的确定性模型，且生成的概率密度函数与实验数据和UNRANS结果高度吻合。不同于贝叶斯HDMDc，频率主义HDMDc在当前案例中表现更为有效。这种集合Hankel动态模式分解方法为设计和运营支持提供了可靠且高效的不确定性的摇摆预测方法。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04567", "html_url": "https://arxiv.org/abs/2511.04567", "title": "W7-X等离子体中电子尺度湍流建模的机器学习方法", "title_en": "Machine Learning for Electron-Scale Turbulence Modeling in W7-X", "authors": "Ionut-Gabriel Farcas,Don Lawrence Carl Agapito Fernando,Alejandro Banon Navarro,Gabriele Merlo,Frank Jenko", "background": "构建简化的湍流传输模型对于加速剖面预测和执行不确定性量化、参数扫描和设计优化等多次查询任务至关重要。本文介绍了应用于Wendelstein 7-X (W7-X) 聚变器的等离子体电子温度梯度 (ETG) 湍流的机器学习驱动简化模型。这些模型依赖于三个等离子体参数：归一化电子温度径向梯度（$\frac{1}{\nu_{T_e}}$）、归一化电子温度和密度径向梯度的比率（$\frac{\nu_{T_e}}{\nu_{n_e}}$）以及电子与离子温度比（$\tau$）来预测ETG热通量。", "innovation": "研究首次利用回归和基于活动机器学习的方法，以七种径向位置为基准构建模型。采用低维度稀疏网格训练数据初始化模型，并通过迭代选择最具信息量的点来逐步优化其训练集。此外，还探索了一种通用、位置无关的模型，以评估其在三个额外位置的热通量预测能力。模型展示了稳健的性能和预测准确性，即便在训练域外应用也能与原始参考模拟结果相当或接近。通过自助法估计95%的信心区间，以评估预测的不确定性。", "conclusion": "所构建的机器学习驱动的ETG湍流简化模型能有效预测各大位置的热通量，并且这些模型在不确定性评估和训练域外应用方面的表现在于原始参考模拟相近或优于，这为W7-X聚变器的任务提供了有效的工具。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04619", "html_url": "https://arxiv.org/abs/2511.04619", "title": "通过潜在伪时间建模在阿尔茨海默病中实现动态因果发现", "title_en": "Dynamic causal discovery in Alzheimer's disease through latent pseudotime modelling", "authors": "Natalia Glazman,Jyoti Mangal,Pedro Borges,Sebastien Ourselin,M. Jorge Cardoso", "background": "现有的因果发现方法大多基于静态图假设，无法充分考虑阿尔茨海默病（AD）等疾病中病理生理学随时间演变的特性，特别是在受潜在线性假时间调节的情况下.", "innovation": "提出将现有的潜在变量模型应用于现实世界中的AD数据，推断出一个随数据驱动疾病轨迹变化的伪时间，并学习因果关系如何演变。引入最少的、疾病无关的背景知识大幅提高了图的准确性和方向性.", "conclusion": "伪时间比实际年龄更好地预测了诊断（AUC 0.82 vs 0.59）。我们的框架揭示了新（NfL, GFAP）和已知AD标记物之间的动态相互作用，即使在违反假设的情况下，仍能实现实际的因果发现."}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04568", "html_url": "https://arxiv.org/abs/2511.04568", "title": "Riesz回归作为直接密度比率估计", "title_en": "Riesz Regression As Direct Density Ratio Estimation", "authors": "Masahiro Kato", "background": "Riesz回归因其在因果和结构参数估计中的去偏差机器学习工具而受到关注（Chernozhukov等人，2021年）。该研究指出，在重要情况下，如平均治疗效应（ATE）估计，Riesz回归与直接密度比率估计（DRE）密切相关。特别地，Riesz回归的思想和目标与直接密度比率估计中的最少平方重要拟合（LSIF，Kanamori等人，2009年）的思想和目标一致。尽管Riesz回归在广泛的类问题中可以作为Riesz表示器估计的应用，但与DRE的等价性使得可以在特定情况下直接应用现有结果，包括收敛率分析、通过最小化Bregman散度来选择损失函数的技术以及适用于灵活模型（如神经网络）的正则化技术。相反，对去偏差机器学习中的Riesz表示器的理解拓宽了直接密度比率估计方法的应用范围。本文整合了Kato（2025a）和Kato（2025b）的先前结果。", "innovation": "将Riesz回归与直接密度比率估计（DRE）等价起来，从而可以直接应用DRE在特定情况下的现有结果，例如收敛率分析、通过最小化Bregman散度来选择损失函数的方法以及适用于神经网络等灵活模型的正则化技术。此外，对Riesz表示器在去偏差机器学习中的理解扩展了直接密度比率估计方法的应用范围。", "conclusion": "本文整合了先前的研究结果，展示了Riesz回归与直接密度比率估计之间的等价性，以及它们在去偏差机器学习中的应用价值。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04622", "html_url": "https://arxiv.org/abs/2511.04622", "title": "基于ODE的Adam算法近似：通用和过参数化设置", "title_en": "ODE approximation for the Adam algorithm: General and overparametrized setting", "authors": "Steffen Dereich,Arnulf Jentzen,Sebastian Kassing", "background": "深度学习中，Adam优化器目前被认为是最流行的优化方法之一。为了更深入地理解Adam优化器的机制，本文利用快速-慢速标度方案建立了基于常微分方程（ODE）的方法来研究Adam优化器。", "innovation": "研究提出了一套基于ODE的方法，探讨了固定动量参数和缩小区间步长条件下的Adam算法行为。证明了在特定条件下，Adam算法的运行轨迹是一个特殊向量场的渐近伪轨迹，即所谓的Adam向量场。利用渐近伪轨迹的性质，证明了算法的收敛性，并在特定条件下展示了算法收敛于全局极小值集的可能性。", "conclusion": "在一般情境下，如果Adam算法收敛，则其收敛点必须是Adam向量场的零点，而非目标函数的局部极小值点或临界点。而在过参数化经验风险最小化的情景下，Adam算法可以在邻域内局部找到最小值集的解。特别是，当接近全局极小值时，目标函数作为Adam向量场诱导流的李雅普诺夫函数，证明了算法在特定条件下会收敛于全局极小值集。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04611", "html_url": "https://arxiv.org/abs/2511.04611", "title": "evomap: 一个Python中的动态映射工具箱", "title_en": "evomap: A Toolbox for Dynamic Mapping in Python", "authors": "Maximilian Matthe", "background": "传统的映射方法在各个学科中被广泛使用，用于将物体之间的关系以空间表示或地图的形式可视化。然而，现有的大多数统计软件仅支持静态映射，只能捕捉物体在某个时间点的关系，缺少了分析这些关系如何随时间演变的工具。evomap通过实现动态映射框架EvoMap填补了这一空白，EvoMap最初由Matthe, Ringel和Skiera在2023年提出，将传统静态映射方法适应于动态分析。该包支持多种映射技术，如多维尺度法（MDS）的变种、Sammon映射和t分布式随机临近嵌入（t-SNE），同时还包括数据预处理、探索和结果评估的工具，提供了动态映射应用的全面工具集。", "innovation": "evomap实现了一种动态映射框架EvoMap，将传统静态映射方法适应于动态分析，填补了现有的静态映射方法无法分析关系随时间演变的问题。它支持多种映射技术及其变种，并提供了一整套工具供用户进行数据预处理、探索和评估结果，为动态映射应用提供了全面支持。", "conclusion": "evomap为统计软件提供了动态映射的功能，通过支持多种映射技术和提供全面的工具集，使得用户能够进行动态关系的可视化分析。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04583", "html_url": "https://arxiv.org/abs/2511.04583", "title": "Jr. AI Scientist和其风险报告：基于基础论文的自主科学研究", "title_en": "Jr. AI Scientist and Its Risk Report: Autonomous Scientific Exploration from a Baseline Paper", "authors": "Atsuyuki Miyai,Mashiro Toyooka,Takashi Otonari,Zaiying Zhao,Kiyoharu Aizawa", "background": "理解当前AI科学家系统的功能和风险对于确保AI驱动科学研究的可信度和可持续性至关重要，同时保护学术生态系统的完整性和安全性。这项研究旨在开发一种能够模拟初级学生研究员核心研究流程的自主AI科学家系统。", "innovation": "我们开发了名为Jr. AI Scientist的最新自主AI科学家系统，它能够在没有完全自动化假设的情况下，基于导师提供的基础论文，分析其局限性，提出改进的假设并通过严格的实验进行验证，并最终撰写包含实验结果的研究论文。不同于以往假设全面自动化或仅处理小型代码的方法，Jr. AI Scientist遵循了明确的研究流程，并利用现代编码代理处理复杂的、多文件的实现，从而产生科学上有价值的贡献。", "conclusion": "我们进行了自动化评估、作者主导的评估和向专门用于AI驱动科学贡献的Agents4Science提交的评估，结果显示Jr. AI Scientist生成的论文获得的评审分数高于现有的完全自动化的系统。然而，我们从作者评估和Agents4Science评审中发现了重要限制，这表明直接应用当前的AI科学家系统可能存在的风险，并对未来的研发提出了关键挑战。此外，我们全面报告了研究开发过程中识别的各种风险。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04576", "html_url": "https://arxiv.org/abs/2511.04576", "title": "物理信息神经网络和神经操作符解决参数化偏微分方程：人类与人工智能协作分析", "title_en": "Physics-Informed Neural Networks and Neural Operators for Parametric PDEs: A Human-AI Collaborative Analysis", "authors": "Zhuo Zhang,Xiong Xiong,Sen Zhang,Yuan Zhao,Xi Yang", "background": "偏微分方程在科学和工程中无处不在，其解依赖于参数（如物理属性、边界条件、几何形状）。传统的数值方法需要为每个参数重新求解偏微分方程，这使得参数空间探索变得极其昂贵。近年来，机器学习的进步，尤其是物理保真的神经网络（PINNs）和神经操作符，通过学习能够泛化多个参数空间的解算符，极大地改进了参数化偏微分方程的求解方法。本文通过对比流体力学、固体力学、热传导和电磁学等多个领域，展示了神经操作符方法在多查询场景下的计算速度提高了1000到100000倍，并且保持了类似的传统求解器的精度。", "innovation": "1. 物理保真的神经网络（PINNs），嵌入物理定律作为软约束，特别适用于稀疏数据的逆问题。\n2. 神经操作符（例如 DeepONet，傅里叶神经操作符），能学习无穷维函数空间之间的映射，达到前所未有的泛化效果。\n3. 通过与传统求解器的对比，展示了神经操作符方法可以实现多查询场景下的3到5个数量级的计算速度提升，并在大量测试中展现出与传统方法相当的准确性。\n4. 提供了方法选择的实践指导，并讨论了理论基础（如通用逼近性、收敛性），同时指出了高维参数、复杂几何和领域外泛化等关键挑战。", "conclusion": "本文建立了理解参数化偏微分方程求解器的统一体系框架，通过操作符学习的方法，并为这个不断发展的领域提供了一个逐步更新的资源。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2106.01254", "html_url": "https://arxiv.org/abs/2106.01254", "title": "评价者等效性：基于人类判断场景评估分类器", "title_en": "Rater Equivalence: Evaluating Classifiers in Human Judgment Settings", "authors": "Paul Resnick,Yuqing Kong,Grant Schoenebeck,Tim Weninger", "background": "在许多决策场景中，确定性的真相并不存在或难以获取。在这种情况下，评估分类器的有效性通常依赖于人类判断。研究提出了一种仅基于人类判断来评价分类器的框架，通过人类判断来构建基准面板并评价分类器性能。", "innovation": "研究引入了一个新的概念——“评价者等效性”，定义为需要少量的评价者来达到与分类器相同的效果。提出了两种性能评价模型，分别基于与假设但无法接触的真相的一致性和与个体人类判断的匹配度。", "conclusion": "通过案例研究和形式分析，研究展示了评价者等效性的框架如何指导AI系统的评价和部署实际应用。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04646", "html_url": "https://arxiv.org/abs/2511.04646", "title": "DR. WELL: 动态推理与基于符号世界模型的嵌入式LLM多代理合作中的学习", "title_en": "DR. WELL: Dynamic Reasoning and Learning with Symbolic World Model for Embodied LLM-Based Multi-Agent Collaboration", "authors": "Narjes Nourzad,Hanqing Yang,Shiyu Chen,Carlee Joe-Wong", "background": "多智能体系统的合作规划要求智能体在部分信息和有限通信的情况下进行联合决策。轨迹层面的协调常常会失败，因为即使是微小的时间或动作偏差也会引发冲突。符号规划能够通过提高抽象层次和提供有限的行动词汇表来缓解这一挑战，使智能体能够同步并集体前进。", "innovation": "DR. WELL是一个分布式神经符号框架，用于合作多智能体规划。合作通过两个阶段的协商协议展开：首先是智能体提出候选角色并进行推理，然后在共识和环境约束下进行联合分配。之后，每个智能体独立生成并执行与其角色相关的符号计划而无需透露详细的轨迹。通过基于共享的世界模型进行推理，DR. WELL避免了基于轨迹的精细步骤对齐问题，并使高级可重用、可同步的且可解释的操作得以实现。实验表明在协作堆叠积木任务中，动态世界模型通过协商和自我完善能够提高任务完成率和效率，尽管这需要花费一些时间来为更加高效的合作策略发展创造条件。", "conclusion": "实验结果显示，动态世界模型通过协商和自我优化提高了任务完成率和效率，尽管在迭代之间存在时间开销，但总体上会进化出更高效的协作策略。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04665", "html_url": "https://arxiv.org/abs/2511.04665", "title": "使用高斯点模拟软体交互的实到模拟机器人策略评估", "title_en": "Real-to-Sim Robot Policy Evaluation with Gaussian Splatting Simulation of Soft-Body Interactions", "authors": "Kaifeng Zhang,Shuo Sha,Hanxiao Jiang,Matthew Loper,Hyunjong Song,Guangyan Cai,Zhuo Xu,Xiaochen Hu,Changxi Zheng,Yunzhu Li", "background": "机器人的操作策略正在快速发展，但在实际世界中的直接评估仍成本高昂、耗时且难以复制，尤其是在涉及柔性物体的任务中。现有的模拟器虽然提供了可扩展和系统的替代方案，但通常无法捕捉软体互动的视觉和物理复杂性。本文提出了一种将现实世界视频转换为软体数字双胞胎的实到模拟策略评估框架，并使用3D高斯点绘制真实机器人、物体和环境，以确保逼真的渲染效果。通过代表性变形任务的验证，本文展示了模拟演练与真实执行性能之间的高度相关性，并揭示了学习策略的关键行为模式。", "innovation": "提出了一种基于3D高斯点模拟软体交互的从现实到模拟（Real-to-Sim）策略评估框架。该框架通过将真实世界视频中的柔性物体重建为数字双胞胎，并利用高保真渲染技术呈现逼真的环境，克服了传统模拟器无法充分捕捉软体交互复杂性的缺点。", "conclusion": "本文的研究结果显示，结合物理指导的重建与高质量渲染能够实现可重复、可扩展且准确的机器人操作策略评估。这种技术有望大幅提高机器人力学模拟和评估的效率与准确性，为柔性物体操作任务提供了更加可靠的研究方法。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.17467", "html_url": "https://arxiv.org/abs/2403.17467", "title": "A Unified Kernel for Neural Network Learning", "title_en": "A Unified Kernel for Neural Network Learning", "authors": "Shao-Qun Zhang,Zong-Yi Chen,Yong-Ming Tian,Xun Lu", "background": "近年来，人们在神经网络学习和核学习之间的区别和联系方面表现出极大的兴趣。近期的研究进展在无限宽度的神经网络和高斯过程之间建立了理论联系。列举了两种主要的方法：神经网络高斯过程（NNGP）和神经切线核（NTK）。NNGP根植于贝叶斯推理，表示零阶核；而NTK则基于梯度下降的空间，表示一阶核。", "innovation": "本文提出了统一神经核（UNK），它由生成变量的内积诱导产生，用于描述带有梯度下降和参数初始化的神经网络的学习动力学。UNK核保持了NNGP和NTK的极限性质。它在有限的学习步长下表现出类似于NTK的行为，并随着学习步长趋近无穷逐渐收敛至NNGP。此外，还理论地 characterizes UNK 的统一核的均匀紧性和学习收敛性。", "conclusion": "实验结果证明了我们提出的该方法的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.19659", "html_url": "https://arxiv.org/abs/2305.19659", "title": "局部碎片，全局收益：使用图神经网络进行子图计数", "title_en": "Local Fragments, Global Gains: Subgraph Counting using Graph Neural Networks", "authors": "Shubhajit Roy,Shrutimoy Das,Binita Maity,Anant Kumar,Anirban Dasgupta", "background": "子图计数是分析图结构数据中的结构性模式的基础任务，在计算生物学和社会网络分析等领域具有重要应用。这类分析依赖于能够揭示功能和组织特性的一些模式。传统的Weisfeiler-Leman (WL) 算法虽然有效，但在表达能力和计算效率方面存在局限。", "innovation": "本文提出了局部版本的Weisfeiler-Leman (WL) 算法（即Local $k$-WL），证明了其在表达能力上优于标准的 $k$-WL，但又不会过于复杂。此外，该论文还提出了层化 $k$-WL 和递归 $k$-WL 的变体，以提高算法的可扩展性。进一步地，还提出了一种新的碎片化技术，将复杂的子图分解为更简单的子模式，使得使用仅一次的1-WL就可以精确计算所有大小在4以内的诱导子图计数。在此基础上，提出了一种基于不同学习框架的三阶段方法来组合子模式计数以计算更复杂的图模式频率。", "conclusion": "实验结果表明，相比现有的基于图神经网络的方法，本方法的局部$ k$-WL 在有限的时间复杂度内更具有表达能力。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.04681", "html_url": "https://arxiv.org/abs/2511.04681", "title": "暗能量调查第三年结果：基于深度学习的弱透镜和星系聚类地图的wCDM推断.I. 分析设计", "title_en": "Dark Energy Survey Year 3 results: Simulation-based $w$CDM inference from weak lensing and galaxy clustering maps with deep learning. I. Analysis design", "authors": "A. Thomsen,J. Bucko,T. Kacprzak,V. Ajani,J. Fluri,A. Refregier,D. Anbajagane,F. J. Castander,A. Ferté,M. Gatti,N. Jeffrey,A. Alarcon,A. Amon,K. Bechtol,M. R. Becker,G. M. Bernstein,A. Campos,A. Carnero Rosell,C. Chang,R. Chen,A. Choi,M. Crocce,C. Davis,J. DeRose,S. Dodelson,C. Doux,K. Eckert,J. Elvin-Poole,S. Everett,P. Fosalba,D. Gruen,I. Harrison,K. Herner,E. M. Huff,M. Jarvis,N. Kuropatkin,P.-F. Leget,N. MacCrann,J. McCullough,J. Myles,A. Navarro-Alsina,S. Pandey,A. Porredon,J. Prat,M. Raveri,M. Rodriguez-Monroy,R. P. Rollins,A. Roodman,E. S. Rykoff,C. Sánchez,L. F. Secco,E. Sheldon,T. Shin,M. A. Troxel,I. Tutusaus,T. N. Varga,N. Weaverdyck,R. H. Wechsler,B. Yanny,B. Yin,Y. Zhang,J. Zuntz,S. Allam,F. Andrade-Oliveira,D. Bacon,J. Blazek,D. Brooks,R. Camilleri,J. Carretero,R. Cawthon,L. N. da Costa,M. E. da Silva Pereira,T. M. Davis,J. De Vicente,S. Desai,P. Doel,J. García-Bellido,G. Gutierrez,S. R. Hinton,D. L. Hollowood,K. Honscheid,D. J. James,K. Kuehn,O. Lahav,S. Lee,J. L. Marshall,J. Mena-Fernández,F. Menanteau,R. Miquel,J. Muir,R. L. C. Ogando,A. A. Plazas Malagón,E. Sanchez,D. Sanchez Cid,I. Sevilla-Noarbe,M. Smith,E. Suchyta,M. E. C. Swanson,D. Thomas,C. To,D. L. Tucker(DES Collaboration)", "background": "数据驱动的方法，尤其是深度学习技术，正在成为从宇宙大尺度结构中提取非高斯信息的强大工具。这项研究提出了首个将弱透镜效应和星系聚集图结合在一起的模拟推断（SBI）流水线，适用于现实中的暗能量调查第三年（DES Y3）配置。该研究通过构建基于CosmoGridV1套件的N体模拟的可扩展前向模型来生成超过一百万个DES Y3的自洽模拟地图，为随后的数据分析做准备。这为wl和GC（星系聚类）的结合提供了一种新的方法。研究还将此类模拟数据集用于训练基于图卷积的神经网络，以学习低维特征，从而提高对宇宙参数的约束。这种方法可以有效地消除参数之间的退化，提高约束参数的影响范围，研究成果展示了在即将到来的大规模宽场成像调查中，通过深度学习推动的SBI分析的巨大潜力。", "innovation": "开发了一种基于CosmoGridV1套件的N体模拟可扩展前向模型，生成了超过一百万个DES Y3的自洽模拟地图；利用模拟数据集训练了基于图卷积的神经网络，以学习低维特征，使用正则化流动实现隐式似然的神经密度估计；实现了对领域（包括重原子物理、摄光星系红移和剪切偏差等因素）的系统拟合，确保了推断流水线的鲁棒性；通过探测组合有效地打破了参数之间的退化，提高了宇宙学参数的限制，显著提高了传统两点统计的性能指标（达到了2-3倍的改进）。", "conclusion": "研究表明，基于深度学习的SBI分析能够为即将到来的宽场成像调查提供显著改进。这种方法不仅可以提高参数约束的准确性，还能够在多重调查数据结合时有效地打破参数之间的退化，从而提供更可靠和全面的宇宙学参数约束。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.02827", "html_url": "https://arxiv.org/abs/2406.02827", "title": "Stochastic Diffusion: 一种用于随机时间序列预测的扩散概率模型", "title_en": "Stochastic Diffusion: A Diffusion Probabilistic Model for Stochastic Time Series Forecasting", "authors": "Yuansan Liu,Sudanthi Wijewickrema,Dongting Hu,Christofer Bester,Stephen O'Leary,James Bailey", "background": "近期扩散概率模型在图像、文本和音频生成中的创新进展为生成时间序列预测开辟了新的可能，但这些能力在建模高度随机的时间序列数据方面仍面临挑战。", "innovation": "提出了一种新颖的Stochastic Diffusion (StochDiff) 模型，该模型通过利用随机潜空间的表征能力在每个时间步骤中学习数据驱动的先验知识，以建模多变量时间序列数据的变异性。学习到的先验知识有助于模型捕捉复杂的时间动态和数据固有的不确定性。", "conclusion": "通过在现实世界数据集上的广泛实验，证明了我们提出的模型在随机时间序列预测中的有效性，并展示了其在实时手术指导中的应用潜力，突显了其对医学界的潜在益处。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.19964", "html_url": "https://arxiv.org/abs/2410.19964", "title": "理解Adam需要更好的旋转相关假设", "title_en": "Understanding Adam Requires Better Rotation Dependent Assumptions", "authors": "Tianyue H. Zhang,Lucas Maes,Alan Milligan,Alexia Jolicoeur-Martineau,Ioannis Mitliagkas,Damien Scieur,Simon Lacoste-Julien,Charles Guille-Escuret", "background": "尽管Adam在广泛采用中表现出比随机梯度下降(SGD)更优越的性能，但缺乏对其优势的全面理论解释。本研究探讨了Adam在参数空间旋转下的敏感性。", "innovation": "作者发现了Adam对结构化旋转的敏感性，这些旋转甚至可以增强其实际性能。此外，作者验证了更新过程的正交性作为理解Adam基础敏感性的关键指标，并建议在此基础上发展旋转相关的理论框架。", "conclusion": "传统假设不能完全解释Adam在各种旋转类型下的行为。正交的更新过程是理解Adam基础敏感性的关键指标，能够协助发展更符合其实际表现的理论框架。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.17770", "html_url": "https://arxiv.org/abs/2410.17770", "title": "小奇异值很重要：随机矩阵分析中的变换器模型", "title_en": "Small Singular Values Matter: A Random Matrix Analysis of Transformer Models", "authors": "Max Staats,Matthias Thamm,Bernd Rosenow", "background": "这篇论文分析了预训练变换器模型中的权重矩阵的奇异值光谱，以理解信息如何在光谱的两端存储。作者使用随机矩阵理论（RMT）作为零信息假说，并将与RMT的一致性视为随机性的证据，将偏差视为学习的证据。研究表明，不仅最大的奇异值（通常的离群值）与RMT有偏差，最小的奇异值也存在显著的偏差。", "innovation": "提出了一种线性随机矩阵模型来解释与小奇异值相关的向量可以携带比与大奇异值相关的向量更多的信息。实验证明，去除偏离RMT的奇异值比移除光谱主体中的值更能提高语言模型的困惑度。在微调之后，最小的十分位频谱部分也可以成为第三最重要的光谱部分。", "conclusion": "研究发现低频谱端的重要性未被忽视，并为基于SVD的大语言模型的剪枝和压缩提供了理论和实践指导。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.03953", "html_url": "https://arxiv.org/abs/2407.03953", "title": "通过预训练实现跨多样图和任务的图变换器推广", "title_en": "Generalizing Graph Transformers Across Diverse Graphs and Tasks via Pre-training", "authors": "Yufei He,Zhenyu Hou,Yukuo Cen,Jun Hu,Feng He,Xu Cheng,Jie Tang,Bryan Hooi", "background": "图预训练主要集中在小图级别的任务（如分子图）和固定图上的节点表示学习。在工业场景中将图预训练模型扩展到包含数十亿节点的Web规模图时，如何避免跨图或任务的负迁移仍然是一个挑战。因此，本文旨在开发具有归纳能力的一般图预训练模型，该模型能够对未见过的新节点或新图进行预测。", "innovation": "本文介绍了一种可扩展的基于Transformer的图预训练框架PGT（预训练图变换器），设计了两种预训练任务：一种用于重建节点特征，另一种用于重建局部结构。不同于原始的自编码器架构中丢弃预训练解码器的情况，提出了一种新型策略，利用解码器进行特征增强。该模型在拥有1.11亿节点和16亿边的公开数据集ogbn-papers100M上实现最佳性能，展示了可扩展性和效率。", "conclusion": "本文展示了PGT框架在腾讯在线游戏数据集上的部署情况，确认了该框架能够预训练超过5.4亿节点和120亿边的实际图，并且能够在各种静态和动态下游任务中取得有效的泛化能力。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.02601", "html_url": "https://arxiv.org/abs/2410.02601", "title": "通过迭代比例马尔可夫拟合的扩散与对抗薛定谔桥", "title_en": "Diffusion & Adversarial Schrödinger Bridges via Iterative Proportional Markovian Fitting", "authors": "Sergei Kholkin,Grigoriy Ksenofontov,David Li,Nikita Kornilov,Nikita Gushchin,Alexandra Suvorikova,Alexey Kroshnin,Evgeny Burnaev,Alexander Korotin", "background": "IMF程序是一种迭代投影方法，能够成功解决薛定谔桥问题，但为了实现高效的实用实施，需要加入一个直觉化的改进建议，即在每次迭代中交替进行前向和后向时间扩散拟合。这一改进对于确保训练的稳定性并在如无配对领域翻译的应用中获得可靠结果至关重要。", "innovation": "本文揭示了经过改进的IMF版本与迭代比例拟合（IPF）过程之间的重要联系，这是一种SB问题的基础方法，也被称作辛克霍恩算法。文章展示了这种直觉化的改进如何将IMF和IPF过程整合起来，并提出了一个结合这两种方法的新方法——迭代比例马尔可夫拟合（IPMF）过程。文章通过理论和实证分析，建立了在不同设置下IPMF过程的收敛性，从而为解决SB问题提供了统一的框架。", "conclusion": "从实践角度来看，IPMF过程允许在图像相似性和生成质量之间灵活调整，提供了一种针对特定任务定制模型的新机制。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.07587", "html_url": "https://arxiv.org/abs/2408.07587", "title": "FedQUIT：基于准胜任虚拟教师的设备端联邦遗忘", "title_en": "FedQUIT: On-Device Federated Unlearning via a Quasi-Competent Virtual Teacher", "authors": "Alessio Mora,Lorenzo Valerio,Paolo Bellavista,Andrea Passarella", "background": "联邦学习（FL）系统允许参与方在其设备上训练机器学习模型，而无需集中收集个体数据。然而，在FL中，参与者可能需要“被遗忘”的权利，即他们的历史贡献能够从所学模型中删除。现有方法虽然能够在不重建整个模型的情况下实现遗忘，但通常需要额外的存储历史更新、访问代理数据等假设，这在跨设备设置中很难实现。", "innovation": "本文提出了FedQUIT，这是一种新颖的算法，使用知识蒸馏技术来清除遗忘数据对FL全局模型的贡献，同时保持其泛化能力。FedQUIT可以直接在请求退出联邦的客户端设备上工作，并利用老师-学生框架。FL全局模型作为教师，局部模型作为学生。通过调整教师在本地数据上的输出，FedQUIT能够对期望遗忘的真实类别的预测分数进行惩罚，以诱导遗忘。不同于以往的工作，FedQUIT无需许多难以实现的假设，从而更适用于跨设备设置。", "conclusion": "通过在不同数据集和模型架构上进行实验，验证了FedQUIT算法的优越性：（i）FedQUIT在遗忘数据方面优于最先进的方法；（ii）其计算需求与常规FedAvg轮次相同；（iii）与从头开始重新训练以恢复初始泛化性能相比，可以节省高达117.6倍的累计通信成本。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18148", "html_url": "https://arxiv.org/abs/2410.18148", "title": "超越柯尔莫哥罗夫障碍：可学习加权混合自编码器在模型简化中的应用", "title_en": "Beyond the Kolmogorov Barrier: A Learnable Weighted Hybrid Autoencoder for Model Order Reduction", "authors": "Nithin Somasekharan,Shaowu Pan", "background": "高维复杂物理系统的表示学习旨在识别低维固有潜空间，这对简化模型和模态分析至关重要。近年来，深度自编码器（AEs）被用来克服著名的柯尔莫哥罗夫障碍，但它们在潜空间秩增加时常常表现出较差的收敛行为。为了解决这个问题，作者提出了一种可学习加权混合自编码器，结合了奇异值分解（SVD）和深度自编码器的优势，通过可学习加权框架来改进收敛行为。该模型的训练结果显示出与其他模型相比数千倍更小的锐度差异，并且在经典混沌偏微分方程系统（如一维库拉中间虾系统和强制各向同性湍流数据集）上展示了显著的泛化性能提升。", "innovation": "提出了可学习加权混合自编码器，结合了奇异值分解和深度自编码器的优势，通过可学习加权框架来解决高潜空间秩导致的收敛性问题。引入学习可调权重参数是关键，这使得模型能够避免退化为标准的POD模型或无法表现出期望的收敛行为。此外，该方法在与时间序列建模技术（如库普曼算子、LSTM）结合时，显著提升了高维多尺度偏微分方程系统代理模型的效果。", "conclusion": "该方法在高维复杂偏微分方程系统的简化和代理建模中表现出了显著优于其他方法的泛化性能。结合时间序列建模技术后，这种新的自编码器方法在多尺度的高维偏微分方程系统代理模型中提供了重要的改进。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.21088", "html_url": "https://arxiv.org/abs/2410.21088", "title": "Shallow Diffuse: 通过扩散模型中的低维子空间实现鲁棒且不可见的水印嵌入", "title_en": "Shallow Diffuse: Robust and Invisible Watermarking through Low-Dimensional Subspaces in Diffusion Models", "authors": "Wenda Li,Huijie Zhang,Qing Qu", "background": "随着基于扩散模型的人工智能生成内容的广泛应用，虚假信息和版权侵权的问题引起了广泛关注。水印技术是识别这些AI生成图片并防止其被滥用的关键技术。", "innovation": "本文介绍了一种新颖的水印技术——Shallow Diffuse，它通过在图像生成过程中利用低维子空间，将鲁棒且不可见的水印嵌入到扩散模型的输出中。这种方法不同于现有的在整个扩散采样过程中集成水印的方法，通过解耦水印嵌入步骤，保证了大部分水印位于该子空间的零空间，从而与图像生成过程分离。理论和实验证明这种解耦策略大幅提高了数据生成的一致性和水印的可检测性。", "conclusion": "大量的实验进一步验证了Shallow Diffuse方法在鲁棒性和一致性方面优于现有的水印方法。相关代码已发布。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.05712", "html_url": "https://arxiv.org/abs/2411.05712", "title": "任务优化模型的灵长类视觉背侧流扩增定律", "title_en": "Scaling Laws for Task-Optimized Models of the Primate Visual Ventral Stream", "authors": "Abdulkadir Gokce,Martin Schrimpf", "background": "当大型对象分类数据集训练某些人工神经网络模型时，它们开始逼近灵长类大脑的核心对象识别行为和神经反应模式。尽管最近的人工智能发展表明，通过增加计算量、模型大小和数据集大小可以提高任务性能，但扩增对大脑一致性的影响仍不清楚。本研究通过系统评估超过600种在受控条件下训练并在包括V1、V2、V4、IT 和行为在内的基准上测试的模型，探求构建灵长类视觉背侧流的扩增定律。", "innovation": "研究通过系统评估，发现了行为一致性随模型规模的增加而持续增长，而神经一致性则达到饱和状态。这一观察在不同模型架构和训练数据集上都保持一致，即使是对图像质量更高的数据集和具有更强归纳偏置的模型，其计算效率也在提高，但神经一致性仍然饱和。扩增特别对高级视觉区域有益，在这些区域，小规模模型在少量样本上训练只能表现出不良的对齐效果。", "conclusion": "虽然扩增现有的架构和数据集可能足以与人类核心对象识别行为对齐，但不能提高对灵长类视觉背侧流的脑模型，突出构建大脑模型的新策略需求。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.06635", "html_url": "https://arxiv.org/abs/2411.06635", "title": "scMEDAL：使用深度混合效应自编码器进行单细胞转录组数据的可解释分析并可视化批效应", "title_en": "scMEDAL for the interpretable analysis of single-cell transcriptomics data with batch effect visualization using a deep mixed effects autoencoder", "authors": "Aixa X. Andrade,Son Nguyen,Austin Marckx,Albert Montillo", "background": "单细胞RNA测序允许对细胞异质性进行高分辨率分析，但如何从批次效应中分离出生物学信号仍然是一个主要挑战。现有的批次校正算法常常抑制或丢弃与批次相关的变异，而不是对其进行建模。scMEDAL通过分别使用两个互补的子网络来建模不变批次效应和特定批次效应，提供了一种新的方法来解决这一问题。", "innovation": "scMEDAL引入了scMEDAL-RE，这是一种随机效应贝叶斯自编码器，能够在保留批次效应中混杂的生物学信息的同时，学习批次特定的表征。固定效应子网络scMEDAL-FE通过对抗学习提供默认批次校正组件。这种框架不仅能够生成具有可解释性的批次特定嵌入，还能与现有的校正方法（如scVI、Scanorama、Harmony、SAUCIE）一起使用，提高疾病状态、捐赠者组和组织预测的准确性。此外，scMEDAL还提供了生成性可视化，包括对细胞表达的反事实重建，使数据获取渠道改变的细胞看起来像是在另一个批次中获得的。", "conclusion": "scMEDAL是一个多功能、可解释的框架，能够补充现有的校正方法，提供对细胞异质性和数据获取的更深入见解，同时保留增强的预测能力和可视化功能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.14133", "html_url": "https://arxiv.org/abs/2411.14133", "title": "GASP: 效率瓶颈盒生成对抗后缀以破解LLMs", "title_en": "GASP: Efficient Black-Box Generation of Adversarial Suffixes for Jailbreaking LLMs", "authors": "Advik Raj Basani,Xiao Zhang", "background": "大型语言模型（LLMs）在多种自然语言处理任务中表现出色，但它们仍然容易受到精心设计的输入提示（称为监狱逃脱攻击，jailbreak attacks）的攻击，这些攻击可以绕过安全限制并引发有害响应。传统方法依赖于手动启发式方法，但这种方法在泛化能力方面有限。尽管基于优化的自动化攻击可以在一定程度上自动生成提示，但它们往往会产生不自然的提示，这些提示容易被安全过滤器检测到，或者由于离散标记优化的高计算成本而效果不佳。", "innovation": "本文介绍了一种名为Generative Adversarial Suffix Prompter (GASP)的新型自动化框架，可以在完全黑盒设置中高效生成面向人类的监狱逃脱提示。GASP利用潜在贝叶斯优化来高效探索连续潜在嵌入空间，通过目标迭代精炼过程逐步优化后缀提示生成器，以提高攻击效果并平衡提示连贯性。", "conclusion": "通过全面的实验，我们将GASP与基线方法进行了比较，展示了GASP可以生成自然的对抗后缀提示，显著提高监狱逃脱成功概率，减少训练时间并加快推理速度，从而使GASP成为一种高效且可扩展的红队建模LLMs的解决方案。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.04650", "html_url": "https://arxiv.org/abs/2412.04650", "title": "重新审视联邦微调：一通信轮次足以适用于基础模型", "title_en": "Revisiting Federated Fine-Tuning: A Single Communication Round is Enough for Foundation Models", "authors": "Ziyao Wang,Bowei Tian,Yexiao He,Zheyu Shen,Guoheng Sun,Yuhan Liu,Luyang Liu,Meng Liu,Ang Li", "background": "基础模型（FMs）的最新进展增加了在跨域大规模数据集上进行微调的需求。为此，联邦微调方法应运而生，它允许基础模型在多台设备上分布的数据集上进行微调，同时保障数据隐私。然而，联邦学习算法中存在的参数量巨大和多轮通信的问题导致通信成本极其高昂，极大地阻碍了联邦微调的实际应用性。", "innovation": "该研究基于理论和实验分析发现，传统的多轮聚合算法并非联邦微调大基础模型的必要选择。研究发现，单轮聚合（即一次性联邦微调）在全球模型性能上能与多轮聚合达到相似效果。通过对大规模参数和广泛预训练任务的研究，研究证明与较小模型相比，大基础模型在一次性联邦微调中显示出显著更低的训练损失。此外，实验证明一次性联邦微调显著降低了通信成本，并能支持异步聚合，增强隐私保护，同时保持与多轮联邦微调一致的性能，适用于文本生成和文本转图像生成任务。", "conclusion": "本研究的发现为联邦微调的实际应用提供了新的见解，提升了效率，减少了成本，并增强了基础模型的可访问性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.11293", "html_url": "https://arxiv.org/abs/2411.11293", "title": "AnomalyAID：半监督网络异常检测的可靠解释", "title_en": "AnomalyAID: Reliable Interpretation for Semi-supervised Network Anomaly Detection", "authors": "Yachao Yuan,Yu Huang,Yingwen Wu,Jin Wang", "background": "半监督学习在网络安全检测领域发挥着重要作用，但如何在有限的标注样本下学习异常模式是困难的。此外，缺乏解释性是半监督框架实际应用中的关键障碍。现有大部分解释方法都是为监督/无监督框架或非安全领域设计的，无法提供可靠的解释。在有限监督数据的情况下，提高异常检测性能非常重要，但难以保证解释结果的可靠性。", "innovation": "提出了一种称为AnomalyAID的通用框架，旨在使异常检测过程具有解释性并提高解释结果的可靠性，同时为无标签样本分配高置信度的伪标签以改善有限监督数据的异常检测系统的性能。该框架通过结合全局和局部解释器提供可靠解释，设计了一种新的两阶段半监督学习框架来为网络异常检测提供约束条件对模型预测的对齐。", "conclusion": "通过实验分析，AnomalyAID不仅能够提供准确的检测结果，还能够对半监督网络异常检测系统提供可靠的解释。已将AnomalyAID的代码发布在此链接：https://this.is/anomalyaid"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02132", "html_url": "https://arxiv.org/abs/2502.02132", "title": "优化算法中的记忆如何隐含地修改损失函数", "title_en": "How Memory in Optimization Algorithms Implicitly Modifies the Loss", "authors": "Matias D. Cattaneo,Boris Shigida", "background": "在深度学习的现代优化方法中，每次迭代的更新依赖于之前的迭代历史，通常称为记忆。这种依赖性随着迭代的深度而迅速衰减。例如，带有动量的梯度下降通过指数平均过去的梯度，具有指数衰减的记忆。本文介绍了一种通用技术，用于识别无记忆算法，它通过将更新中的所有过去迭代替换为当前迭代，并添加由于记忆引起的一种校正项来近似具有记忆的优化算法。这种校正项可以解释为损失扰动，这种扰动的性质可以揭示记忆如何（隐式地）正则化优化动力学。研究表明，Lion（算法）不具有由记忆隐含诱导的类似于AdamW的反正则化，从而为Lion近期记录的更好泛化性能提供了一种基于理论的解释。", "innovation": "提出了一种通用技术，通过为具有记忆的优化算法中的更新替换所有过去的迭代，并添加一个由当前迭代引起的校正项，来识别无记忆算法。这种校正项被视为损失扰动，揭示了记忆如何（隐式地）正则化优化动态，并且通过此技术发现Lion与AdamW在隐含的反正则化上有区别，从而解释了Lion的更好泛化性能。", "conclusion": "研究发现，Lion 不具有由记忆隐含诱导的类似于 AdamW 的反正则化，从而通过理论解释了 Lion 的更好泛化性能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.22879", "html_url": "https://arxiv.org/abs/2503.22879", "title": "Quamba2：针对选择性状态空间模型的稳健且可扩展的后训练量化框架", "title_en": "Quamba2: A Robust and Scalable Post-training Quantization Framework for Selective State Space Models", "authors": "Hung-Yueh Chiang,Chi-Chih Chang,Natalia Frumkin,Kai-Chiang Wu,Mohamed S. Abdelfattah,Diana Marculescu", "background": "状态空间模型（SSMs）因其一致的内存使用和高性能而正逐渐成为Transformer的替代选择。然而，将SSMs扩展到云服务或资源受限的设备时，由于它们的存储需求和计算能力限制，面临着挑战。为了克服这个问题，使用低位宽数据格式对SSMs进行量化可以减少模型的大小并受益于硬件加速。", "innovation": "提出了一种名为Quamba2的后训练量化框架，适用于Mamba1和Mamba2的W8A8、W4A8和W4A16配置。基于SSMs的通道顺序保持和激活持续性，通过离线排序和聚类输入x，并结合基于状态组的输入依存参数BC的量化，实现了8位量化。为确保SSM输出的计算不变性，根据聚类序列离线重新排列权重。实验表明，Quamba2在前填充和生成阶段分别实现了1.3倍和3倍的速度提升，同时内存减少了4倍，平均精度下降仅为1.6%。", "conclusion": "Quamba2框架通过离线方法量化输入和参数，并重新排列权重，确保了SSM输出的计算不变性。实验结果表明，该方法实现了高效的速度提升和内存减少，同时保持了较好的精度。该框架在跨多种平台的SSM部署中具有普遍性和鲁棒性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03961", "html_url": "https://arxiv.org/abs/2503.03961", "title": "深度有限亦能远 —— 日志深度变压器的表达能力", "title_en": "A Little Depth Goes a Long Way: The Expressive Power of Log-Depth Transformers", "authors": "William Merrill,Ashish Sabharwal", "background": "近期的研究结果表明，变压器模型在处理长序列推理问题时，由于其计算深度是受限制的，因此无法表达这些问题。之前的研究工作将深度视为常数，这导致在短序列上有限深度是否足够甚至增加深度会如何影响表达能力方面还不够明确。文章通过分析深度随上下文长度最小增长的变压器，探讨了这些问题，展示了即使深度为对数级别（Θ(log n)）的变压器也能表达重要的问题。这两个问题分别是识别正规语言，这涉及到状态跟踪能力；以及图连通性，这是多步推理的基础。这些问题在标准复杂性假设下，固定深度的变压器无法表达，这表明增长深度具有表达性优势。此外，理论还定量预测了表达这些问题所需深度的增长速率，表明深度增长比宽度增长或因果推理步骤的增长更有效。实验中设计的详细实验表明，我们的理论深度要求与成功训练变压器的实际深度要求非常接近，这进一步阐明了深度如何影响变压器的推理能力，并为有效选择深度提供了实用建议。", "innovation": "文章通过分析深度随着上下文增长的变压器模型，展示了即使深度为对数级别（Θ(log n)），也能表达重要的序列推理问题，如识别正规语言和图连通性。这为理解和设计具有更强表达能力的 transformers 提供了新的视角。理论预测了表达特定问题所需的深度增长速率，并表明这种方式比增加宽度或增加推理步骤更有效率。实验部分揭示了理论深度要求与实际训练过程中所需的深度要求之间的紧密对应关系，这为选择合适的深度提供了指导。", "conclusion": "研究通过分析深度增长的变压器模型，证明了即使为对数级别（Θ(log n)）的深度仍然能够表达重要的序列推理问题。这不仅展示了深度增长的重要性，而且为变压器的设计提供了更准确的深度选择方法，有助于理解如何通过深入调整提高变压器的推理能力。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.20667", "html_url": "https://arxiv.org/abs/2504.20667", "title": "后嵌线性化：基于个体潜在编码的可解释性和可调控后嵌可解释性", "title_en": "Explanations Go Linear: Interpretable and Individual Latent Encoding for Post-hoc Explainability", "authors": "Simone Piaggesi,Riccardo Guidotti,Fosca Giannotti,Dino Pedreschi", "background": "后嵌可解释性对于理解黑盒机器学习模型至关重要。目前广泛使用的是基于替代模型的技术，用于局部和全局的模型不可知解释，但存在显著限制。局部替代模型能够捕捉非线性特征，但计算成本高昂且参数敏感；而全局替代模型虽然更高效，但在处理复杂局部行为方面存在困难。文章背景在于探讨如何改进现有的替代模型解决上述问题并提供更加统一、有效且可靠的可解释性框架。", "innovation": "本文提出了ILLUME，一种基于表示学习的灵活且可解释框架，其可与各种替代模型集成来解释任何黑盒分类器。ILLUME的独特之处在于结合了全局训练的替代模型和通过元编码学习的实例特定线性变换，以生成局部和全局解释。通过广泛的经验评估，ILLUME在生成特征归属和决策规则方面表现出色，不仅准确而且鲁棒且忠实地反映了黑盒模型，从而提供了一个综合的解释框架，有效解决了传统替代方法的局限性。", "conclusion": "通过全面的实验评估，ILLUME在生成特征归属和决策规则方面具有高效性、鲁棒性和准确性，填补了传统替代方法在灵活性和精确度上的不足，提供了一个统一的解释框架来解决复杂局部行为和参数敏感性的问题，是一个重要的前沿成果。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.10641", "html_url": "https://arxiv.org/abs/2509.10641", "title": "Test-Time Warmup for Multimodal Large Language Models", "title_en": "Test-Time Warmup for Multimodal Large Language Models", "authors": "Nikita Rajaneesh,Thomas Zollo,Richard Zemel", "background": "多模态大语言模型（MLLMs）在文本和图像交叉的高级推理方面具有巨大潜力，但尚未充分发挥其潜力。MLLMs 通常由一个语言模型、一个视觉编码器和一个连接器组成，将视觉编码器的嵌入映射到语言模型的文本嵌入空间。尽管每个组件都在拥有数亿样本的海量数据集上进行了预训练，但整个多模态模型通常只在数千到几百万个样本上进行训练，这可能导致复杂推理任务上的表现较弱。", "innovation": "本文提出了一种Test-Time Warmup方法，该方法通过利用弱监督辅助任务的数据在每实例测试阶段适应MLLM。这种方法在Llama-Vision-Instruct模型上，相对于MMMU提高了4.03%，相对于VQA-Rad提高了5.28%，相对于GQA提高了1.63%。结果显示，在推理前进行预热可以增强MLLM在各种推理任务中的稳健性。", "conclusion": "通过预热前推理的方法，可以提高MLLM在复杂推理任务上的表现，并增强了其在不同推理任务中的稳健性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.15827", "html_url": "https://arxiv.org/abs/2509.15827", "title": "SolarCrossFormer: 通过结合卫星图像和地面传感器提高日预报太阳能辐照度预测", "title_en": "SolarCrossFormer: Improving day-ahead Solar Irradiance Forecasting by Integrating Satellite Imagery and Ground Sensors", "authors": "Baptiste Schubnel,Jelena Simeunović,Corentin Tissier,Pierre-Jean Alet,Rafael E. Carrillo", "background": "大规模整合太阳能光伏（PV）系统到电力系统中需要准确的次日太阳能辐照度预测。当前的预测解决方案在时间和空间分辨率上无法满足系统运营商的需求。", "innovation": "引入了一种名为SolarCrossFormer的新颖深度学习模型，该模型结合了卫星图像和地面气象站的时序数据。SolarCrossFormer使用新型图神经网络来利用输入数据的跨模态和内模态相关性，提高预测的准确性和分辨率。该模型能够以15分钟的分辨率生成瑞士任何位置长达24小时的概率预测。其主要优势在于在实际运行中的鲁棒性，能够不重新训练模型就融入新的时序数据，并且能够利用仅使用坐标数据来为没有输入数据的位置生成预测。", "conclusion": "实验结果显示，SolarCrossFormer在127个瑞士地点过去一年的数据集上的归一化绝对平均误差为6.1%，其结果与商用数值天气预报服务的结果具有竞争力。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.16189", "html_url": "https://arxiv.org/abs/2509.16189", "title": "潜在学习： episodic记忆通过启用经验的灵活再利用补充参数学习", "title_en": "Latent learning: episodic memory complements parametric learning by enabling flexible reuse of experiences", "authors": "Andrew Kyle Lampinen,Martin Engelcke,Yuxuan Li,Arslan Chaudhry,James L. McClelland", "background": "当机器学习系统在泛化时出现失败时，理解其产生根源是当前研究的一个重要方面。论文通过对认知科学的借鉴，分析了参数机器学习系统的一个弱点，即它们未能展示出潜在学习的能力，即学习与当前任务无关但对未来任务可能有用的隐含信息。论文探讨了从语言模型的反转诅咒到基于代理的导航新发现中的失败，涉及认知科学中的情景记忆作为可能解决方案的一部分。", "innovation": "论文提出了一个使用 oracle检索机制的系统，可以更灵活地利用学习经验，从而在多种挑战中更好地泛化。研究指出，情景记忆可能有助于缓解机器学习系统的相对数据效率不足的状况，同时阐明了检索方法如何补充参数学习以提高泛化能力。论文还指出了有效使用检索的一些关键组件，包括在单个示例中实现上下文学习的重要性，以便能够跨检索示例使用信息。", "conclusion": "研究结果展示了机器学习系统相对自然智能存在数据效率较低的部分原因，并帮助理解了检索方法如何补充参数学习以改善泛化。论文还讨论了这些发现与认知科学和神经科学中先前结果的联系，以及更广泛的含义。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.18112", "html_url": "https://arxiv.org/abs/2509.18112", "title": "大型语言模型在产前电子胎心监测分析中超越领域特定架构", "title_en": "Large language models surpass domain-specific architectures for antepartum electronic fetal monitoring analysis", "authors": "Sheng Wong,Ravi Shankar,Beth Albert,Gabriel Davis Jones", "background": "时间序列分析中，基模型（FMs）和大型语言模型（LLMs）展示了跨不同领域的良好泛化能力，但在产前电子胎心监测（EFM）和胎心图（CTG）分析中的潜力尚未被充分探索。现有的CTG研究主要依赖于特定领域的模型，且较少系统性地将现代基础模型或语言模型与其进行对比，这限制了我们对这些模型是否能在胎儿健康评估中超越专业系统的理解。", "innovation": "本研究首次全面评估了最先进的自动化产前CTG分类架构。使用了超过2500个20分钟的记录，评估了涵盖领域特定、时间序列、基和语言模型类别的15个模型。结果显示，微调的LLMs在数据可用性不同的情况下，通常优于基础模型和领域特定模型，但在缺失宫缩活动信号时，领域特定模型表现更稳健。这些性能提升需要更多的计算资源。", "conclusion": "尽管微调的LLMs在CTG分类上达到了最先进的性能，但在实际部署中必须权衡性能和计算效率之间的关系。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.18629", "html_url": "https://arxiv.org/abs/2509.18629", "title": "HyperAdapt: 简单的高秩自适应", "title_en": "HyperAdapt: Simple High-Rank Adaptation", "authors": "Abel Gurung,Joseph Campbell", "background": "基础模型在多种任务上表现出色，但要将它们应用于特定的应用程序通常需要微调，这是一个消耗大量内存和计算资源的过程。参数高效的微调方法(PEFT)通过只更新一小部分权重来缓解这一问题，提高微调过程的效率。", "innovation": "本文提出了HyperAdapt，这是一种参数高效的微调方法，与现有的如LoRA的方法相比，显著减少了可训练参数的数量。HyperAdapt通过行和列的对角矩阵标度对预训练的权重矩阵进行调整，从而导致高秩更新，同时仅需要一个n+m的可训练参数即可完成一个n×m的矩阵更新。实验表明，HyperAdapt在GLUE、算术推理和常识推理基准数据集上的表现达到了或接近完全微调和最先进的参数高效微调方法的性能，但使用了数量级数量较少的可训练参数。", "conclusion": "HyperAdapt在保持或接近高性能的同时，通过减少可训练参数数量显著提升了微调的效率，特别适用于需要高效利用计算资源的场景。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.07325", "html_url": "https://arxiv.org/abs/2509.07325", "title": "CancerGUIDE：通过内部分歧估计实现癌症指南理解", "title_en": "CancerGUIDE: Cancer Guideline Understanding via Internal Disagreement Estimation", "authors": "Alyssa Unell,Noel C. F. Codella,Sam Preston,Peniel Argaw,Wen-wai Yim,Zelalem Gero,Cliff Wong,Rajesh Jena,Eric Horvitz,Amanda K. Hall,Ruican Rachel Zhong,Jiachen Li,Shrey Jain,Mu Wei,Matthew Lungren,Hoifung Poon", "background": "国家综合癌症网络（NCCN）为癌症治疗提供了基于证据的指南。将复杂患者的病例转化为符合指南的治疗建议是一项耗时的任务，需要专业知识和高精度，容易出错。大型语言模型（LLM）的进步有望减少生成治疗建议所需的时间，并提高准确性。", "innovation": "本研究提出了一种基于LLM代理的方法，用于自动生成非小细胞肺癌（NSCLC）患者的符合指南的治疗路径。贡献包括构建一个包含NSCLC患者临床咨询、诊断结果和医疗历史的新颖纵向数据集，并由认证肿瘤学家专家注释；证明现有LLM具有特定领域的知识，可以为模型开发和评估生成高质量的代理基准；并开发了一种结合昂贵的人工注释和模型一致性信息的混合方法，创建了一个能够预测患者相关指南并验证治疗建议准确性的元分类器。", "conclusion": "本工作建立了一个平衡准确性和监管要求的临床可行的LLM基指南合规系统框架，同时减少注释成本，为自动化临床决策支持提供可扩展的途径，支持输出准确性和支持性能权衡并满足监管要求。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11903", "html_url": "https://arxiv.org/abs/2510.11903", "title": "整合序列和关系建模以用户事件：数据集和预测任务", "title_en": "Integrating Sequential and Relational Modeling for User Events: Datasets and Prediction Tasks", "authors": "Rizal Fathony,Igor Melnyk,Owen Reinert,Nam H. Nguyen,Daniele Rosa,C. Bayan Bruss", "background": "用户事件建模在许多机器学习应用中占据核心地位，涵盖了电子商务、社交媒体、金融、网络安全等多个领域。用户事件通常被分为两类：个人事件和关系事件。个人事件涉及个体行为，关系事件涉及用户之间的互动。这两类事件通常分别使用序列方法和图方法建模。尽管实际系统需要同时捕捉这两类事件，然而之前的研究很少同时考虑两者。这是因为将用户行为简化为单一的形式化表示（序列或图）较为简便。因此，一种统一建模方法是必要的，该方法需要公有数据集和包含两类事件的预测任务来支持研究进展。", "innovation": "本文介绍了一种整合个人和关系事件的数据集收集，提出了统一的形式化模型，并通过实验证明结合两类事件有助于模型性能提升。同时表明当前方法仍有改进空间。为此，作者将资源公开，促进统一用户事件建模的研究并鼓励沿此方向进行进一步研究。", "conclusion": "目前的方法在捕捉个人和关系事件方面仍有可改进的空间。所提出的数据集和实验任务将有助于推进统一用户事件建模的研究。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01794", "html_url": "https://arxiv.org/abs/2509.01794", "title": "一种预测疫情期间心血管疾病生物标志物的多目标贝叶斯变换器框架", "title_en": "A Multi-target Bayesian Transformer Framework for Predicting Cardiovascular Disease Biomarkers during Pandemics", "authors": "Trusting Inekwe,Winnie Mkandawire,Emmanuel Agu,Andres Colubri", "background": "COVID-19疫情期间，全球的医疗系统受到了破坏，尤其是对心血管疾病（CVD）等慢性病患者的影响更大。这种破坏导致了延迟治疗和行为改变，进而影响了低密度脂蛋白胆固醇（LDL-C）、糖化血红蛋白（HbA1c）、体重指数（BMI）和收缩压（SysBP）等关键的CVD生物标志物。准确预测这些生物标志物的变化对于预测疾病进展和指导预防性治疗至关重要。然而，先前的研究并没有能够通过机器学习（ML）方法，同时预测多种CVD生物标志物，并捕捉这些生物标志物之间的相互关系、时间序列模式以及预测不确定性。", "innovation": "本文提出了一种名为MBT-CB的多目标贝叶斯变换器模型（Multi-target Bayesian Transformer with pre-trained BERT-based transformer framework），用于从电子健康记录（EHRs）中同时预测LDL-C、HbA1c、BMI和SysBP等多种CVD生物标志物。该模型利用贝叶斯变分推断估计不确定性，嵌入法捕捉时间关系，并利用DeepMTR模型捕捉生物标志物之间的相互关系。通过在马萨诸塞州中部3,390条CVD患者记录（304名独特患者）的回顾性EHR数据上进行评估，MBT-CB在MAE、RMSE和MSE等多种指标上超过了其他基线方法和其他基于BERT的机器学习模型，同时能够捕捉数据和模型不确定性、生物标志物之间的相互关系以及时间动态性。", "conclusion": "MBT-CB在预测CVD生物标志物方面表现出色，可能有助于提高疫情期间CVD生物标志物的预测精度，并支持临床决策。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.24239", "html_url": "https://arxiv.org/abs/2509.24239", "title": "ChessArena：用于评估大型语言模型战略推理能力的国际象棋测试环境", "title_en": "ChessArena: A Chess Testbed for Evaluating Strategic Reasoning Capabilities of Large Language Models", "authors": "Jincheng Liu,Sijun He,Jingjing Wu,Xiangsen Wang,Yang Chen,Zhaoqi Kuang,Siqi Bao,Yuan Yao", "background": "近期的大规模语言模型（LLMs）展现了强大的推理能力。然而，仍存在一个关键问题：这些模型是否具备真正意义上的推理技能，特别是复杂的策略推理能力，还是主要擅长在训练数据中的复杂模式识别？为了解开这个疑问，本文提出了一个基于国际象棋的测试框架ChessArena，来评估LLMs的策略推理能力。国际象棋需要复杂的策略推理能力，包括长期规划、精确规则理解以及多回合对话记忆等。ChessArena是一个竞争性的框架，使LLMs相互对战，并且在四种不同的挑战模式下进行。该测试环境配备了排名算法和排行榜，可以评估基本理解、移动选择和解谜等方面的能力。共有13种不同模式的LLMs在ChessArena中进行了超过800场的游戏。结果表明，现有的LLMs存在重大缺陷：没有一种模型能够击败Maia-1100（一个位于人类业余水平的国际象棋引擎），甚至有些模型连随机应战的基本AI都无法战胜。", "innovation": "本文提出了ChessArena，这是一个专门用于评估大规模语言模型策略推理能力的国际象棋测试环境。它包含了一个排名算法和排行榜，并能够评估模型在基本理解、移动选择和解谜等方面的能力。ChessArena设计有多种挑战模式，使模型在复杂和多回合的环境中进行评估。此外，还展示了Qwen3-8B模型在该测试环境下的卓越表现，其性能显著提高，接近当前大型推理模型的最佳状态。", "conclusion": "现有的大规模语言模型在策略推理能力上存在明显不足，没有一种模型能够击败人类业余水平的国际象棋引擎Maia-1100，甚至有些模型连随机应战的基本AI都无法战胜。本文通过ChessArena测试环境揭示了这一现状，并提出了Qwen3-8B模型作为测试环境的基准，证明该框架能够有效评估LLMs在国际象棋对战中的复杂策略推理能力。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05830", "html_url": "https://arxiv.org/abs/2509.05830", "title": "使用大规模语言模型进行社会科学研究中的人类行为预测微调", "title_en": "Finetuning LLMs for Human Behavior Prediction in Social Science Experiments", "authors": "Akaash Kolluri,Shengguang Wu,Joon Sung Park,Michael S. Bernstein", "background": "大型语言模型（LLMs）为模拟社会科学实验结果提供了强大的可能性。本文通过直接在过去的个体层面响应上对LLMs进行微调，证明了这种做法可以显著提高模拟在不同社会科学领域中的准确性。通过一个自动化管道构建SocSci210数据集，包含来自400,491名参与者在210个开源社会科学研究实验中的290万条响应。通过对不同实验条件下的数据进行微调，模型能够更好地适应和预测新实验条件。使用Socrates-Qwen-14B模型，在全新未见过的研究中，预测结果的准确性比其基础模型Qwen2.5-14B提高了26%，优于GPT-4o 13%。同时，通过在部分实验条件上微调，对新未见过条件的泛化能力提高了71%。由于SocSci210数据集包含丰富的种族人口学信息，微调后的模型还减少了10.6%的偏差，即偏见度量。这些发现表明，专注于现有丰富的、特定主题的数据集来微调模型，可以增强社会科学研究假设筛选中模拟的准确性，从而提高预测结果的准确性。因此，本文建议未来应该将社会科学研究数据集用于微调LLMs，以提高预测的准确性。提供数据集、模型和微调代码的访问链接，以便后续研究和验证。", "innovation": "本文通过使用自动管道构建的大规模数据集SocSci210，对核心生成模型进行微调，显著提升了预测人类行为的准确性。具体创新包括：1. 通过直接在个体层面的实验响应上进行微调，实现了在不同社会科学领域的广泛泛化。2. 因SocSci210包含丰富的种族人口学信息，微调过程明显减少了偏见。3. 在未遇到的实验条件下，微调模型的预测能力比基本模型和GPT-4o都高，特别是在部分条件上进行微调时，泛化能力提高了71%。4. 开放数据集、模型和微调代码，以便其他研究者验证和借鉴。这些创新都表明了在社会科学领域应用微调技术的潜力。", "conclusion": "与未微调的基础模型和最新的GPT-4o相比，通过SocSci210微调的模型在实验预测中表现更出色。研究结果表明，微调模型可以更好地理解人类行为，并减少了在跨领域预测中的偏见。提供数据集、模型和微调代码可促进进一步研究。未来研究可以探索不同数据集的微调方法，以进一步提高预测和解释能力。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.12264", "html_url": "https://arxiv.org/abs/2406.12264", "title": "投影方法在算子学习中的应用与通用逼近", "title_en": "Projection Methods for Operator Learning and Universal Approximation", "authors": "Emanuele Zappala", "background": "本文在任意Banach空间上获得了连续（可能非线性）算子的新泛函逼近定理，使用勒雷-舒尔德映射。此外，作者提出了一种基于多项式基正交投影的方法来学习Banach空间$L^p$中的多元函数算子，并得出了在某些附加假设下的算子学习的泛函逼近结果。对于$p=2$的情况，我们给出了确保逼近结果成立的一些充分条件。这是用于算子学习的深度学习方法的理论框架", "innovation": "引入了基于多项式基正交投影的方法来学习Banach空间$L^p$中的多元函数算子，并得出了在某些附加假设下的泛函逼近结果。对于$p=2$的情况，给出了确保逼近结果成立的一些充分条件", "conclusion": "本文为算子学习的深度学习方法提供了理论框架"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.17737", "html_url": "https://arxiv.org/abs/2406.17737", "title": "LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users", "title_en": "LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users", "authors": "Elinor Poole-Dayan,Deb Roy,Jad Kabbara", "background": "尽管最先进的大型语言模型（LLMs）在许多任务上表现出色，但对模型的不良行为，如幻觉和偏见的研究也非常广泛。本文针对三个方面的用户特征检验了LLM响应的质量变化，包括英语水平、教育水平和所属国家，同时也探讨了模型在准确信息、真实性及拒绝回答问题方面的表现。", "innovation": "本文通过实证研究，首次探讨了用户特征对大型语言模型性能的影响，特别是英语水平、教育水平和所属国家对模型真实性和准确性的具体影响。", "conclusion": "研究发现，最先进的大型语言模型在针对英语水平较低、教育水平较低和来自美国以外国家的用户时，表现出更多的不良行为，这一发现表明这些模型对于最脆弱的用户群体来说不可靠。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.08768", "html_url": "https://arxiv.org/abs/2409.08768", "title": "测度论时延嵌入", "title_en": "Measure-Theoretic Time-Delay Embedding", "authors": "Jonah Botvinick-Greenhouse,Maria Oprea,Romit Maulik,Yunan Yang", "background": "传统的Takens嵌入定理为从部分观测数据重构动态系统的全状态提供了理论基础。但是，经典的定理假设底层系统是确定性的，且观测是无噪声的，这限制了其在实际场景中的应用。为了克服这一限制，本文通过采用欧拉描述动态系统的方式，以概率测度空间之间的推进映射为基础，提出了一种新的测度论时延嵌入理论，旨在从时滞的部分观测数据中重构动态系统的全状态，并且能够处理稀疏和噪声数据。", "innovation": "本文提出了一个基于测度论的时延嵌入理论，该理论采用概率测度空间之间的推进映射，结合最优运输领域的最新进展，开发了一种算法，能够从稀疏和噪声数据中重构动态系统的全状态。", "conclusion": "本文通过多种数值例子验证了基于测度的方法的有效性，适用于经典Lorenz-63系统以及实际应用如NOAA海表面温度和ERA5风场的重构。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.05500", "html_url": "https://arxiv.org/abs/2410.05500", "title": "增强深度学习的残差柯尔莫戈罗夫-阿诺尔德网络", "title_en": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning", "authors": "Ray Congrui Yu,Sherry Wu,Jiang Gui", "background": "尽管深度卷积神经网络（CNN）取得了巨大的成功，但由于网络深度中的数百个层，其优化和训练成本高昂。传统的卷积操作受限于其线性特征以及固定的激活函数，需要很多层才能在网络中学习有意义的模式。这种方法在计算效率上是低效的，并且在小数据集上存在过拟合或梯度爆炸的风险。因此，在此背景下，本文介绍了一种名为“插件式”的模块——残差柯尔莫戈罗夫-阿诺尔德网络（RKAN）。", "innovation": "我们的模块非常紧凑，可以轻松地插入到传统深度网络的任何阶段（级别），其目标是学习整合支持性多项式特征转换到现有的卷积框架中。实验表明，RKAN在不同视觉任务和广泛测试的基准上都能提供优于基线模型的一致性改进，实现了开创性的性能水平。", "conclusion": "本文提出了残差柯尔莫戈罗夫-阿诺尔德网络，该模块能够有效提高深度网络在不同视觉任务中的一致性能，特别适用于小数据集，能够较好地解决传统卷积网络在计算效率和过拟合问题上的局限。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.13049", "html_url": "https://arxiv.org/abs/2412.13049", "title": "TIMESAFE：前传环境中的定时中断监视与安全评估", "title_en": "TIMESAFE: Timing Interruption Monitoring and Security Assessment for Fronthaul Environments", "authors": "Joshua Groen,Simone Di Valerio,Imtiaz Karim,Davide Villa,Yiewi Zhang,Leonardo Bonati,Michele Polese,Salvatore D'Oro,Tommaso Melodia,Elisa Bertino,Francesca Cuomo,Kaushik Chowdhury", "background": "5G及后续蜂窝系统正经历着无线接入网络（RAN）组件的解耦过程，特别是在前传（FH）链路中蜂窝基带与射频单元设备之间的连接演进。前传同步对于可靠5G服务至关重要。近年来，业界正尝试将这些链路迁移到基于以太网的包网络拓扑，利用现有标准和TSN（时间敏感网络）的持续研究。然而，现有的TSN标准，如精确定时协议（PTP），主要关注性能而忽视了安全性，这增加了前传链路的安全风险。针对同步机制的攻击威胁巨大，有可能中断5G网络并影响连接性。", "innovation": "本文展示了对PTP同步的成功欺骗与重放攻击的影响，并证明了在2秒内可以使一个生产就绪的O-RAN和符合5G标准的私营蜂窝基站完全失效，需要手动干预才能恢复全网操作。为此，提出了一种基于机器学习（ML）的监测解决方案，能够准确检测各种恶意攻击，准确率超过97.5%。", "conclusion": "研究提出了TIMESAFE方案，该方案能够有效检测前传环境中的各种恶意攻击，大幅提高前传网络的安全性。通过实例证明，基于ML的监测解决方案能够在实际网络中有效预防和检测攻击，确保5G网络的稳定性和安全性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09956", "html_url": "https://arxiv.org/abs/2502.09956", "title": "KGGen：利用语言模型从纯文本中提取知识图谱", "title_en": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models", "authors": "Belinda Mo,Kyssen Yu,Joshua Kazdan,Joan Cabezas,Proud Mpala,Lisa Yu,Chris Cundy,Charilaos Kanatsoulis,Sanmi Koyejo", "background": "近年来，对于构建知识图谱的基石模型的研究引起了广泛的关注。关键挑战在于知识图谱数据相对稀缺。已知的最佳知识图谱主要是通过人工标注、模式匹配或早期NLP技术提取而成。尽管人工生成的知识图谱数量有限，但自动提取的知识图谱质量参差不齐。本文背景正是解决这一数据稀缺问题，提出了一种名为KGGen的纯文本到知识图谱生成器，使用语言模型从纯文本中创建高质量的知识图谱。KGGen通过聚集相关实体来减少提取知识图谱中的稀疏性，使得生成的知识图谱质量更高。同时，KGGen还提供了一个名为MINE的基准测试，用于评估提取器从纯文本生成有用知识图谱的能力。", "innovation": "KGGen的创新之处在于其构建高质知识图谱的文本到知识图谱生成方法。它不同于其他知识图谱提取器之处在于能够通过聚集相关实体减少提取知识图谱中的稀疏性。此外，还开发了MINE基准测试来评估提取器的效果。实验结果表明，与现有工具相比，KGGen具有更出色的性能。", "conclusion": "本文通过提出KGGen工具解决了知识图谱数据稀缺的问题，能够在纯文本中生成高质量的知识图谱，并通过MINE基准测试展示了其卓越性能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.07961", "html_url": "https://arxiv.org/abs/2410.07961", "title": "QCircuitBench: 大规模量子算法设计基准数据集", "title_en": "QCircuitBench: A Large-Scale Dataset for Benchmarking Quantum Algorithm Design", "authors": "Rui Yang,Ziruo Wang,Yuntian Gu,Tianyi Chen,Yitao Liang,Tongyang Li", "background": "量子计算因其通过量子算法在经典计算上的显著加速而被视为一个新兴领域。然而，设计和实现量子算法面临着来自量子力学复杂性和对量子状态精确控制的挑战。尽管人工智能已经取得了显著进展，但仍缺乏专门针对量子算法设计和实现的数据集。在本工作中，我们介绍了QCircuitBench，这是第一个专门为评估人工智能在使用量子编程语言设计和实现量子算法方面的潜力设计的基准数据集。", "innovation": "1. 提供了一个通用框架，为大型语言模型定义了量子算法设计的关键特性。2. 实现了从基本元素到高级应用的量子算法，涵盖了3个任务套装、25个算法和120,290个数据点。3. 自动验证与验证功能，允许迭代评估和互动推理，无需人工检查。4. 初步微调结果显示，它作为训练数据具有潜力。值得注意的是，我们观察到了一些有意思的实验现象，如大型语言模型倾向于表现出一致的错误模式，微调并不总是优于单一示例学习。", "conclusion": "QCircuitBench是一个全面的量子算法设计基准，用于大型语言模型驱动的量子算法设计，并揭示了大型语言模型在该领域的限制。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14570", "html_url": "https://arxiv.org/abs/2501.14570", "title": "coverforest: 在Python中使用随机森林进行收敛预测", "title_en": "coverforest: Conformal Predictions with Random Forest in Python", "authors": "Panisara Meehinkong,Donlapark Ponnoprat", "background": "收敛预测提供了一种框架，用于不确定性量化的具体形式是预测区间和分布无区别的保证覆盖率的预测集。近年来，包括CV+和自助法之后的杰克knife+在内的跨收敛技术比传统的分段收敛方法在数据效率上得到了改善，但它们由于需要训练样例和测试样例之间成对比较的出袋得分导致了巨大的计算成本。这些方法通过集成模型，尤其是随机森林自然地推广开来。本文通过利用现有的优化随机森林实现来实现高效的跨收敛预测。作者展示了这些方法如何在coverforest这个Python包中实现，该包支持回归和分类任务，并利用并行计算和Cython优化来加速出袋计算。", "innovation": "本文开发了一个名为coverforest的Python包，它通过利用现有的优化随机森林实现来实现跨收敛预测，从而在保持高质量覆盖的同时显著减少了计算成本。coverforest包支持多种收敛预测方法，包括分段收敛，CV+，自助法之后的杰克knife+和自适应预测集。该软件包通过并行计算和Cython优化加快了出袋计算，并且在训练和预测时间上比现有的实现快2-9倍。", "conclusion": "实验表明，coverforest的预测达到了期望的覆盖水平。coverforest的训练和预测时间比现有实现快2-9倍。在GitHub上托管了coverforest的源代码。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.07879", "html_url": "https://arxiv.org/abs/2503.07879", "title": "数据集、文档和重复使用：不等数据质量的实操问题", "title_en": "Datasets, Documents, and Repetitions: The Practicalities of Unequal Data Quality", "authors": "Alex Fang,Hadi Pouransari,Matt Jordan,Alexander Toshev,Vaishaal Shankar,Ludwig Schmidt,Tom Gunter", "background": "数据过滤已成为提升模型性能、同时降低计算成本的有效工具。然而，随着大型语言模型计算预算的增加，高度过滤和去重的数据集提供的数据量有限，可能会成为实际的制约因素。为了更好地了解如何解决这一问题，研究者考察了不同计算预算下的模型性能，并研究了通过数据过滤和去重创建的多个预训练数据集的表现。研究表明，在适当的训练配方调整下，重复使用现有高度过滤的数据集多次（可达十个周期）可以在多个计算预算数量级下超过单一周期训练十倍大小的超集的表现。同时，研究还探讨了在这些数据集内部重复使用文档的可能性，发现并非所有文档都对模型性能贡献相同，可以通过明确调整单个文档的数量来创建更具经济效益的数据集。", "innovation": "研究发现了在不同计算预算水平下，通过调整训练配方和数据集重复使用次数，可以提高模型性能的新方法。值得关注的是，研究不仅验证了数据集重复使用的效果，还进一步探索了文档级别的数据重复使用策略，揭示了不同文档对模型性能的影响差异，提出可以优化数据集结构以适应不同的token预算。这些发现表明，即使在大型语言模型规模扩大的背景下，数据过滤仍然是重要的研究方向之一。", "conclusion": "研究最后总结，尽管大型语言模型的能力随着规模扩大而增加，数据过滤仍然保留着提高模型性能和优化资源利用的重要作用。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.06741", "html_url": "https://arxiv.org/abs/2411.06741", "title": "基于扩散的循环神经网络模型在阿尔伯塔油砂尾矿池甲烷监测中的应用", "title_en": "Dispersion based Recurrent Neural Network Model for Methane Monitoring in Albertan Tailings Ponds", "authors": "Esha Saha,Oscar Wang,Amit K. Chakraborty,Pablo Venegas Garcia,Russell Milne,Hao Wang", "background": "加拿大艾伯塔省的油砂开发过程中，用于生产合成原油的沥青提取技术近期因为成为温室气体排放的重要来源而受到关注。特别是甲烷的排放，它是由于油砂残渣（或尾矿）在沉降池中厌氧生物降解产生的。由于数据获取受限，准确评估这些尾矿池的甲烷排放潜力和未来排放预测面临挑战。为此，研究团队利用实时气象数据、实验室控制实验开发的机制模型以及行业报告训练了一个受物理约束的机器学习模型，以确定活动尾矿池的方向及其排放水平，从而为减排提供有力支持。这一研究表明，每个活动的油砂尾矿池每年可排放950至1500吨甲烷，其环境影响相当于至少6000辆汽油动力汽车的碳排放量。此外，尽管废弃的塘坝通常被认为具有微不足道的排放，但研究发现这些塘坝可能重新激活，每年潜在地排放多达1000吨的甲烷。平均而言，为了降低平均甲烷浓度至2005年的水平，大约需要减少12%的排放量，从而消除主要油砂区域的大约12%的甲烷排放.", "innovation": "该研究创新地利用基于扩散的循环神经网络模型来监测阿尔伯塔省油砂尾矿池中的甲烷排放。该模型结合了环境中的实时气象数据、实验室控制实验开发的机制模型以及工业报告，有效地预测和识别了尾矿池的气体排放情况，这在以往的数据限制下是难以取得的。这一方法为有效监测和预测甲烷排放提供了一种新的途径，有助于改善油砂行业的环境表现及温室气体排放管理.", "conclusion": "通过训练的机器学习模型，研究团队成功地评估了油砂尾矿池的甲烷排放情况。结果显示，目前活动的尾矿池每年排放的甲烷量远高于预期，废塘铛也可能因环境条件的变化重新释放大量甲烷。为了达到类似于2005年的环境标准，每年大约需要减少12%左右的甲烷排放。该研究强调了精准监测和预测甲烷排放的重要性，对于油砂行业实现碳中和目标具有重要意义。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.20110", "html_url": "https://arxiv.org/abs/2503.20110", "title": "通过微调传递实现高效的模型开发", "title_en": "Efficient Model Development through Fine-tuning Transfer", "authors": "Pin-Jie Lin,Rishab Balasubramanian,Fengyuan Liu,Nikhil Kandpal,Tu Vu", "background": "现代大语言模型在进行高效更新时遇到挑战，每次新的预训练模型版本都需要重新进行昂贵的对齐过程。即使是针对特定领域或语言的模型，每次新的基础模型发布时也需要重新在专门的数据集上进行微调。本文探讨了模型版本间的微调更新传递问题。通过在不同版本的模型之间传递微调更新的差异向量，实验证明可以显著提升目标基础模型的性能，而无需额外的训练。", "innovation": "本文提出了一种方法，即通过传递一个源模型版本的微调更新差异向量到不同的目标模型版本的基础模型，从而在无需额外训练的情况下显著提升目标模型的性能。具体来说，通过在不同版本的开源模型上进行实证评估，发现传递微调更新能提高目标模型的性能，例如在Llama 3.1 8B上，通过传递Llama 3.0 8B的微调更新，提高46.9%的IFEval和15.7%的LiveCodeBench评分，甚至超越了Llama 3.1 8B的Instruct版。此外，这种方法在多语言任务上也表现出色，对于马达加斯加语和土耳其语，分别提高了4.7%和15.5%的Global MMLU评分。", "conclusion": "本文的研究表明微调传递是一种经济高效且实用的方法，可以应用于持续的LLM开发。我们的实验结果表明，当源模型和目标模型参数空间彼此线性连接时，微调传递效果最佳。此外，我们还提供了一种理论分析来解释这种方法的有效性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04737", "html_url": "https://arxiv.org/abs/2504.04737", "title": "TathyaNyaya和FactLegalLlama：提高印度法律背景下的实证判断预测和解释", "title_en": "TathyaNyaya and FactLegalLlama: Advancing Factual Judgment Prediction and Explanation in the Indian Legal Context", "authors": "Shubham Kumar Nigam,Balaramamahanthi Deepak Patnaik,Shivam Mishra,Noel Shallum,Kripabandhu Ghosh,Arnab Bhattacharya", "background": "在基于事实判断预测和解释（FJPE）的基础上，依赖于事实数据对于开发可靠且现实的AI驱动决策工具至关重要。本文介绍了TathyaNyaya，这是首个针对印度法律环境的大型标注数据集，其中包括印度最高法院及其他高等法院的判决。TathyaNyaya数据集的独特之处在于它专注于事实陈述，而不是完整的法律文本，反映了实际情况，其中事实数据影响着法律结果。为了配合这个数据集，我们还提出了FactLegalLlama，这是一种面向FJPE任务的指令调优LLM，通过对TathyaNyaya中的事实数据进行微调，FactLegalLlama能够生成高质量的解释，增强透明度和解释性，这是AI辅助法律系统中的关键需求。", "innovation": "本文主要创新点在于提出了TathyaNyaya数据集（包括印度法律环境下的判决数据）和FactLegalLlama（面向FJPE任务的Llama-3-8B大型语言模型），并结合变压器模型，形成了一种强大的框架，以促进印度法律领域的FJPE研究。TathyaNyaya数据集不仅在规模和多样性上超过了现有的数据集，还为法律分析中的可解释AI系统建立了基准。此外，研究发现强调了事实精确性和领域特定调优在提高预测性能和可解释性方面的关键作用，使TathyaNyaya和FactLegalLlama成为AI辅助法律决策的基础资源。", "conclusion": "TathyaNyaya和FactLegalLlama为提高印度法律背景下的实证判断预测和解释提供了一流的数据和模型支持。这两个工具不仅有助于提高AI在法律领域的应用效果，还为未来的实证决策研究确立了新的标准，并强调了事实数据和领域特定调优的重要性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03179", "html_url": "https://arxiv.org/abs/2511.03179", "title": "迈向自主化工程设计：一种知识引导的多智能体框架", "title_en": "Toward Autonomous Engineering Design: A Knowledge-Guided Multi-Agent Framework", "authors": "Varun Kumar,George Em Karniadakis", "background": "工程设计过程通常需要跨领域的专业知识，导致复杂而冗长的合作和多次优化。传统方法可能耗时费力且效率低下。", "innovation": "本文通过多智能体人工智能框架，整合结构化设计和审查循环，将专业知识通过特定知识驱动的智能体进行共享和优化。框架包括Graph Ontologist、Design Engineer和Systems Engineer三个关键智能体。", "conclusion": "该研究展示了如何通过配备结构化知识表示的协作智能体提高工程设计过程的效率、一致性和质量。最终设计被优化以最大化诸如升阻比等性能指标。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17697", "html_url": "https://arxiv.org/abs/2510.17697", "title": "针对多智能体强化学习的目标干预原则", "title_en": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "authors": "Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang", "background": "在大规模多智能体强化学习（MARL）中，仅仅由人类在整体系统层面提供全局指导是不切实际的。同时，通过设计外部机制（例如固有奖励和人类反馈）来协调智能体的工作主要依赖于经验研究，缺乏易于使用的研究工具。", "innovation": "本文采用多智能体影响图（MAIDs）作为图形框架来解决上述问题。首先，引入了MARL交互范式的概念（与MARL学习范式正交），使用MAIDs来分析和可视化MARL中的未引导自我组织和全局指导机制。然后，设计了一种新的MARL交互范式，称为目标介入范式，仅应用于单一目标智能体，以减轻全局指导的问题。通过引入因果推理技术（预策略介入，PSI），实现了目标介入范式。此外，通过MAIDs的捆绑相关性图分析提供了检验MARL交互范式下MARL学习范式是否可行的工具。", "conclusion": "实验结果表明了我们提出的目标干预的有效性，并验证了相关性图分析的结果。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.01019", "html_url": "https://arxiv.org/abs/2511.01019", "title": "OceanAI：一个提供准确、透明、近实时海洋观测洞见的对话平台", "title_en": "OceanAI: A Conversational Platform for Accurate, Transparent, Near-Real-Time Oceanographic Insights", "authors": "Bowen Chen,Jayesh Gajbhar,Gregory Dusek,Rob Redmon,Patrick Hogan,Paul Liu,DelWayne Bohnenstiehl,Dongkuan Xu,Ruoying He", "background": "人工智能正在改变科学领域，但通用的对话AI系统常常生成未经验证的“幻觉”，这损害了科学的严谨性。OceanAI是一个对话平台，它结合了开源大型语言模型的自然语言流畅性和实时的参数化访问由美国国家海洋和大气管理局（NOAA）托管的权威海洋数据流的功能。", "innovation": "OceanAI通过实时API调用，能够识别、解析和合成相关的海洋数据集，以生成可重复的自然语言回答和数据可视化结果。与其他几种常用的AI聊天界面产品相比，只有OceanAI能够提供基于NOAA的数据源和原始数据引用的回答。该平台还设计为可扩展，可以连接到多个NOAA数据产品和变量，支持海洋灾害预测、生态系统评估和水质监测等应用。", "conclusion": "OceanAI通过使输出和可验证的观察结果相结合，促进了透明度、可重复性和信任。该平台为AI在海洋领域的决策支持提供了一个可扩展的框架。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05132", "html_url": "https://arxiv.org/abs/2510.05132", "title": "使用全局分叉令牌训练大型语言模型以并行推理", "title_en": "Training Large Language Models To Reason In Parallel With Global Forking Tokens", "authors": "Sheng Jia,Xiao Wang,Shiva Prasad Kasiviswanathan", "background": "尽管通过并行计算扩展测试时的计算量已经使大型语言模型（LLMs）在性能上有所提升，但这种方法依赖于生成既多样化又准确的推理路径。对于具有挑战性的问题，触发多样化且正确的推理模式的分叉令牌往往位于采样树的深层。因此，通常用来鼓励多样性的策略，如温度缩放，在多样性和准确性之间陷入更糟糕的权衡。", "innovation": "作者将并行推理视为下一个分词集合预测问题，并使用自监督二部匹配方法将全局分叉令牌和独特的推理路径之间的集合式全局损失融入监督微调（SFT）中。实验表明，与使用多种推理路径的天真微调相比，所提出的方法Set Supervised Fine-Tuning（SSFT）能够保留这些独特的推理模式，并生成新的全局分叉令牌。在多个推理基准测试中，SSFT 在 Pass@1 和 Cons@k 两个指标上都表现优于标准的SFT。", "conclusion": "我们的SSFT方法在多个推理性能基准上始终优于SFT，无论是通过Pass@1还是Cons@k指标来衡量。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07871", "html_url": "https://arxiv.org/abs/2510.07871", "title": "通过主动风险感知实现社交导航学习", "title_en": "Learning to Navigate Socially Through Proactive Risk Perception", "authors": "Erjia Xiao,Lingfeng Zhang,Yingbo Tang,Hao Cheng,Renjing Xu,Wenbo Ding,Lei Zhou,Long Chen,Hangjun Ye,Xiaoshuai Hao", "background": "本报告描述了作者对IROS 2025 RoboSense挑战赛Social Navigation赛道的参赛技术细节。该赛道旨在开发基于RGBD的感知和导航系统，使自主代理能够在动态的人群密集室内环境中安全、高效且符合社交规范地导航。挑战要求代理仅使用机载传感器（如RGB-D观察和里程计）从第一人称视角操作，无需全局地图或其他特权信息，并需遵守社交规范，例如保持安全距离和避免碰撞。在此基础上，作者引入了主动风险感知模块，以提升社交导航性能。该模块增强Falcon模型，使其能够预测周围人类的距离碰撞风险评分，从而帮助代理建立更稳健的空间意识和预防性碰撞避免行为。", "innovation": "该研究通过引入主动风险感知模块，增强Falcon模型的社交导航能力。主动风险感知模块能够预测周围人类的距离碰撞风险评分，使代理能够更有效地管理和避免潜在的碰撞风险，从而增强其空间意识和预防性行为。这种方法在Social-HM3D基准测试中的评估表明，该方法提高了代理在拥挤室内场景中目标导航时保持个人空间合规性的能力，并在16支参赛队伍中获得了第二名的好成绩。", "conclusion": "评估结果表明，该方法在拥挤室内场景中目标导航时保持个人空间合规性方面表现出色，并在该赛道的16支参赛队伍中获得了第二名。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12829", "html_url": "https://arxiv.org/abs/2510.12829", "title": "将大型语言模型作为证明者和验证者进行数学研究", "title_en": "Mathematics with large language models as provers and verifiers", "authors": "Hieu Le Duc,Leo Liberti", "background": "从2024年到2025年，关于大型语言模型的定理证明能力的讨论开始取得有趣的成功案例，主要集中在国际数学奥林匹克竞赛的难题上，还有专门用来验证人工智能能否证明的假设。研究表明，在2025年的国际数学奥林匹克竞赛中，有五个问题被ChatGPT通过涉及不同版本的gpt-5模型进行证明的协议解决，并影响了六十六个数论假设中的大约三分之一。", "innovation": "该研究提出了一种通过协作使用的不同证明者和验证者实例的gpt-5模型进行定理证明的方法。为确保所得证明的准确无误，最终的证明通过了lean证明助手的形式验证，同时通过人工验证前提和结论的符合性。虽然该方法不完美，但在2025年的国际数学奥林匹克竞赛问题上取得了重大进展，并解决了大约三分之一的数论假设问题。", "conclusion": "该研究验证了大型语言模型在证明和验证数学问题上的能力，通过人为和自动化验证确保生成的证明正确无误。尽管目前的方法还不够完善，它在2025年的国际数学奥林匹克竞赛中展示了巨大的潜力，并在未来可能通过持续改进进一步提升其有效性。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.02818", "html_url": "https://arxiv.org/abs/2511.02818", "title": "Orion-MSP: 多尺度稀疏注意机制在表格上下文学习中的应用", "title_en": "Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning", "authors": "Mohamed Bouadi,Pratinav Seth,Aditya Tanna,Vinay Kumar Sankarapu", "background": "表格数据仍然是现实世界应用中主要的数据格式，但由于特征类型异构和在不同尺度上复杂的交互作用，开发高效神经模型仍然具有挑战性。虽然最新在表格上下文学习（ICL）中取得进展，如TabPFN和TabICL，已经在基准测试数据集上取得与梯度增强树（GBT）相当的性能，但是现行架构仍然存在关键局限：单一尺度特征处理忽视了层次依赖性，密集注意力复杂度呈平方增长，以及严格顺序组件处理阻碍了循环表示优化及组件间通信。", "innovation": "Orion-MSP提出了三种关键创新：（1）多尺度处理，以捕捉层次特征交互作用；（2）块稀疏注意力，结合窗口、全局和随机模式，实现高效性及长距离连接；（3）类似Perceiver的记忆机制，确保各组件间安全的双向信息流动。", "conclusion": "Orion-MSP在不同基准测试中表现突出或超越当前最佳性能，有效扩展到高维表格，成为高效表格ICL的新标准，模型已在公开地址this https URL发布。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22379", "html_url": "https://arxiv.org/abs/2510.22379", "title": "TraceTrans：手术预测中的翻译和空间跟踪", "title_en": "TraceTrans: Translation and Spatial Tracing for Surgical Prediction", "authors": "Xiyu Luo,Haodong Li,Xinxing Cheng,He Zhao,Yang Hu,Xuan Song,Tianyang Zhang", "background": "图像到图像翻译模型已经在不同视觉领域间的图像转换中取得了显著的成功，尤其在医疗任务如预测术后结果和建模疾病进展方面得到广泛应用。然而，目前大多数方法主要致力于匹配目标分布，忽视了源图像和翻译图像之间空间对应关系，这可能导致结构不一致和幻觉，从而降低预测的可靠性和可解释性。尤其是在临床应用中，由于苛刻的解剖学准确性要求，这些挑战更为突出。", "innovation": "本文介绍了一种新颖的可变形图像翻译模型TraceTrans，它旨在术后预测任务中生成与目标分布匹配的同时明确揭示与术前输入的空间对应关系。该框架通过编码器提取特征，并使用两个解码器预测空间变形和合成翻译图像。预测的变形场对生成输出施加空间约束，保证了解剖学的一致性。这种模型在医疗美容和脑MRI数据集上的实验结果表明，TraceTrans能够提供准确且可解释的术后预测，展示了其在可靠临床部署中的潜力。", "conclusion": "TraceTrans通过生成与目标分布匹配的图像并明确揭示与术前输入的空间对应关系，解决了现有方法的局限性。实验结果表明，该模型能够提供准确且可解释的术后预测，展示了其在临床应用中的潜力。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.02625", "html_url": "https://arxiv.org/abs/2511.02625", "title": "浅层网络在球体上的条件数和特征值谱", "title_en": "Condition Numbers and Eigenvalue Spectra of Shallow Networks on Spheres", "authors": "Xinliang Liu,Tong Mao,Jinchao Xu", "background": "本文分析了浅层ReLU$^k$神经网络在单位球$\boldsymbol{\text{S}}^d$上的质量矩阵和刚度矩阵的条件数。特别地，当$\theta_j^*$在$\boldsymbol{\text{S}}^d$上是反极化准均匀时，这些矩阵的条件数得到了精确估计。此外，还对特征值谱的全部谱进行了精确的渐近估计，并刻画了相应的特征子空间的结构。", "innovation": "研究了浅层ReLU$^k$神经网络在球体上的质量矩阵和刚度矩阵的条件数，尤其是在反极化准均匀分布的情况下，得到了精确的条件数估计。此外，还提供了特征值谱的精确渐近估计，并刻画了特征子空间的结构，揭示了小特征值与低阶多项式的特征基相关，而大特征值与高阶多项式相关。这项分析确立了网络的逼近能力和数值稳定性之间的精确对应关系。", "conclusion": "研究表明，浅层神经网络的条件数和特征值谱提供了其在球体上的逼近能力和数值稳定性的精确对应关系。特别地，在反极化准均匀分布的情况下，这种对应关系非常精确且清晰。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.07960", "html_url": "https://arxiv.org/abs/2510.07960", "title": "自我监督学习在可穿戴EEG上高效睡眠分期中的系统评估", "title_en": "A Systematic Evaluation of Self-Supervised Learning for Label-Efficient Sleep Staging with Wearable EEG", "authors": "Emilio Estevan,María Sierra-Torralba,Eduardo López-Larraz,Luis Montesano", "background": "可穿戴EEG设备作为多导睡眠描记法（PSG）的有前景的替代方案，由于其成本效益和可扩展性，它们的广泛应用导致了大规模未标记数据的收集，而这些数据无法大规模地被临床医生分析。近年来，深度学习在睡眠评分方面取得了成功，但依赖于大规模标注数据集。自我监督学习（SSL）为解决标注数据稀缺问题提供了机会，通过利用未标记信号减少标注工作量。本文系统性地评估了可穿戴EEG上自我监督学习（SSL）用于睡眠阶段划分的方法，通过两个数据集（BOAS和HOGAR）中的未标注和标注数据进行评估，探索不同应用场景下的标签效率、表示质量及跨数据集的一般化能力。", "innovation": "本文首次系统性地评估了自我监督学习在可穿戴EEG上用于睡眠阶段划分的应用，研究了多种经典的自我监督学习方法，并将其应用于两个使用Ikon Sleep可穿戴EEG耳机记录的大规模数据集（BOAS和HOGAR）。实验结果表明，与监督学习基线相比，自我监督学习一致性地提高分类性能最高可达10%，尤其在标注数据稀缺时表现尤为明显，使用仅5%到10%的标注数据即可达到临床级的准确度（超过80%），而监督学习方法则需要两倍的数据量。此外，自我监督学习表示在不同人群特征、记录环境及信号质量变异性方面表现稳健。这些发现表明，自我监督学习具有在可穿戴EEG上进行高效睡眠阶段划分的潜力，减少对人工标注的依赖，并促进低成本睡眠监测系统的开发", "conclusion": "本文的研究结果表明，自我监督学习能够实现高效、自动的睡眠阶段划分，减少了对手动标注的依赖，并有助于开发低成本的睡眠监测系统。未来研究可以进一步探索自我监督学习在不同睡眠监测场景中的应用，以及如何提高自我监督学习方法在实际应用中的性能。"}
{"llm_update_time": "20251110", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2511.03193", "html_url": "https://arxiv.org/abs/2511.03193", "title": "Rectified Flow的统计性质", "title_en": "Statistical Properties of Rectified Flow", "authors": "Gonzalo Mena,Arun Kumar Kuchibhotla,Larry Wasserman", "background": "流形（Liu等，2022；Liu，2022；Wu等，2023）是一种在机器学习中流行的定义两个分布之间传输映射的方法，但其理论支持其准确性的结果很少。流形可以看作是最小成本运输的近似，与需要在函数空间上优化的其他传输方法不同，计算流形只需要回归或密度估计等标准统计工具。因此，可以通过回归和密度估计的标准数据分析工具来开发传输映射的经验版本。本文研究了流形的一些结构属性，包括存在性、唯一性、正则性，以及关联的一些统计属性，如收敛速率和中心极限定理，针对一些选定的估计器。对于这种情况，我们独立地分析了有界和未界的情况，因为每个情况都有独特的问题。在两种情况下，我们都能够比标准非参数回归和密度估计的收敛速率更快地建立收敛性。", "innovation": "本文研究了流形的一些结构属性，包括存在性、唯一性和正则性，以及相关的统计属性，如收敛速率和中心极限定理，用于某些选定的估计器。对于这种情况，作者独立地分析了有界和未界的情况。在两种情况下，作者都能够比标准非参数回归和密度估计的收敛速率更快地建立收敛性。", "conclusion": "本文针对流形研究了其结构属性及相关统计性质，并通过独立分析有界和未界的情况，得出在某些估计器上流形的收敛速率可以比标准非参数回归和密度估计更快的结论。"}
{"llm_update_time": "20251110", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.03898", "html_url": "https://arxiv.org/abs/2511.03898", "title": "大规模反思在大规模生成安全代码中的应用", "title_en": "Secure Code Generation at Scale with Reflexion", "authors": "Arup Datta,Ahmed Aljohani,Hyunsook Do", "background": "大型语言模型（LLMs）现在被广泛用于编写和重构代码，但工作中的代码并不一定安全。虽然这些模型在代码生成方面表现出色，但在安全性方面仍然存在挑战。", "innovation": "该研究评估了使用Instruct Prime（去除合规所需提示和提示污染的模型）和五个指令调整的代码LLMs（基于零样本基准和三轮反身提示方法）来生成安全代码。安全性通过使用Insecure Code Detector (ICD) 的Repair、Regression和NetGain指标进行衡量，考虑编程语言和CWE家族。", "conclusion": "研究发现，第一轮生成的安全问题仍然很常见，Python的生成最安全，而C和C#的生成最不安全。反身提示方法提高了模型的安全性，初始平均准确性从70.74%提高到79.43%，效果最好的是第一轮之后有所递减。一个复制包已提供。"}
{"llm_update_time": "20251110", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.04611", "html_url": "https://arxiv.org/abs/2511.04611", "title": "evomap：Python 中的动态映射工具箱", "title_en": "evomap: A Toolbox for Dynamic Mapping in Python", "authors": "Maximilian Matthe", "background": "传统的地图绘制方法在各个学科中被广泛使用，用于可视化对象之间的关系。它们将这些关系空间化表示，但大多数现有的统计软件只能支持静态地图，这种地图只能在特定时间点捕捉对象之间的关系，而缺乏分析这些关系如何发展的工具。", "innovation": "evomap通过实现由Matthe等人（2023年）提出的动态映射框架EvoMap，填补了这一空白。EvoMap将传统的静态映射方法适应于动态分析。evomap支持多种映射技术，包括多种多维标度（MDS）、Sammon Mapping和t-分布随机邻居嵌入（t-SNE）方法，并提供数据预处理、探索和结果评估的工具，为动态映射应用提供了一个综合工具包。", "conclusion": "本文概述了静态和动态映射的基础，描述了evomap的架构和功能，并通过详尽的应用示例展示了其应用。"}
{"llm_update_time": "20251110", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.04316", "html_url": "https://arxiv.org/abs/2511.04316", "title": "AdversariaLLM: 统一且模块化的大型语言模型稳健性研究工具箱", "title_en": "AdversariaLLM: A Unified and Modular Toolbox for LLM Robustness Research", "authors": "Tim Beyer,Jonas Dornbusch,Jakob Steimle,Moritz Ladenburger,Leo Schwinn,Stephan Günnemann", "background": "大型语言模型（LLM）的安全性和鲁棒性研究领域快速发展，但随之而来的是多样且时常包含Bug的实现、数据集和评估方法。这种多样性使得研究之间的重现性和可比性变得更加困难，阻碍了有意义的进步。", "innovation": "该工具箱（AdversariaLLM）旨在解决这些问题，它通过以下几个核心创新点来实现这一目的：①注重重现性、正确性与可扩展性的设计；②实现十二种对抗性攻击算法；③集成涵盖有害性、过度拒绝和 utility 评估七个基准数据集；④提供广泛使用的开源 LLM 代码访问，通过 Hugging Face；⑤包含诸如计算资源跟踪、可重复的实验结果和分布评估技术等先进功能。", "conclusion": "这些组成部分共同建立了大型语言模型安全性和稳健性研究的坚固基础，使其更加透明、可比和可重复。"}
{"llm_update_time": "20251110", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.04220", "html_url": "https://arxiv.org/abs/2511.04220", "title": "Opus: 一种工作流评估的定量框架", "title_en": "Opus: A Quantitative Framework for Workflow Evaluation", "authors": "Alan Seroul,Théo Fagnoni,Inès Adnani,Dana O. Mohamed,Phillip Kingston", "background": "介绍了Opus WorkFlow评价框架，这是一种用于量化工作流质量与效率的概率-规范性建模方法。该框架将正确性、可靠性和成本整合到一个统一的数学模型中，以实现工作流直接比较、评分和优化。该模型支持在现代自动化系统中进行自动化工作流评估、排序和优化，如Opus，并可以与强化学习循环结合，指导工作流的发现和精炼。", "innovation": "该研究引入了Opus WorkFlow Reward模型，将工作流成功形式化为基于成本和结果的概率期望；定义了可衡量的Opus WorkFlow Normative Penalties来捕捉工作流的结构、语义和信号相关属性；提出了在联合奖励-惩罚权衡下的统一优化公式，以识别和排序最佳工作流.", "conclusion": "该研究提出了Opus工作流评价框架，该框架以概率-规范性建模方法量化评估工作流的质量和效率。该框架不仅支持自动化工作流评估和优化，还能够整合到强化学习循环中，以指导工作流发现和改进。"}
{"llm_update_time": "20251110", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.04370", "html_url": "https://arxiv.org/abs/2511.04370", "title": "Eclipse ESCET v4.0 的监督控制器综合概述与性能评估", "title_en": "Overview and Performance Evaluation of Supervisory Controller Synthesis with Eclipse ESCET v4.0", "authors": "Dennis Hendriks,Michel Reniers,Wan Fokkink,Wytse Oortwijn", "background": "监督控制器在确保网络物理系统正确和安全运行方面发挥着重要作用。合成基础工程（SBE）是一种自动化其设计和实现的方法，将基于模型的工程与计算机辅助设计相结合，使工程师能够关注系统“应该做什么”而不是“如何做”。ESCET开源项目提供了一个社区工具包支持整个SBE过程，特别是通过基于CIF模型语言及其工具。论文介绍了CIF的符号监督控制器综合算法，CIF的基准模型，以及ESCET版本从v0.8到v4.0的改进，并对其进行了评估，展示了CIF的当前综合性能。此外，简要介绍了多层次综合及其性能改进.", "innovation": "提出了CIF的符号监督控制器综合算法，包括防止运行时错误、处理不同类型的规范以及支持输入变量等实际相关特性。描述了ESCET版本v0.8到v4.0之间的改进，这些改进影响了综合性能，并通过基准模型评估了这些改进的效果。介绍了多层次综合方法及其性能增益，展示了其在复杂模型综合中的潜力，但强调仍需进一步改进以提高综合性能参数.", "conclusion": "总结了CIF综合算法的关键特性及其应用实践，评价了ESCET版本v0.8到v4.0的性能改进，展示了当前CIF的综合性能，并强调了多层次综合方法的潜力，但需要进一步的研究以提高复杂模型的综合性能。"}
{"llm_update_time": "20251110", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2404.06672", "html_url": "https://arxiv.org/abs/2404.06672", "title": "生物医学开源软件：关键包和隐藏英雄", "title_en": "Biomedical Open Source Software: Crucial Packages and Hidden Heroes", "authors": "Eva Maxfield Brown,Stephan Druskat,Laurent Hébert-Dufresne,James Howison,Daniel Mietchen,Andrew Nesbitt,João Felipe Pimentel,Boris Veytsman", "background": "尽管科学研究依赖于科学软件，但这类软件往往没有正式的认可和奖励。基础库尤为重要，它们通常在用户看不见的地方隐藏在其他软件包之下。由于研究中直接使用的软件包也可能不被论文提及，因此基础库的重要性往往被忽视。资助者、基础设施提供商和其他组织需要理解现代科学研究依赖的复杂软件网络结构。本文利用CZ Software Mentions Dataset，分析生物医学论文中使用的软件的上游依赖关系，以识别重要软件包，并构建软件依赖性网络的中心性指标，对PyPi、CRAN和Bioconductor三个生态系统进行分析，确定具有最高中心性的软件包。", "innovation": "本文使用CZ Software Mentions Dataset来识别生物医学研究中使用的软件的关键依赖关系，并提出用于评估软件依赖性网络中心性的度量标准，同时还详细分析了三个主要的开源软件生态系统。这一研究填补了在科学软件生态中关键包识别方面的空白，有助于提升基础库的显视性和认可度。", "conclusion": "本文通过对生物医学文献中使用的开源软件进行深入分析，确定并提出了软件依赖网络中心性的度量标准，并在PyPi、CRAN和Bioconductor生态系统中识别出最高中心性的关键软件包。这有助于提升研究基础库的重要性和能见度，从而使科研资助者和相关组织能够更好地认识到这些基础软件的价值。"}
{"llm_update_time": "20251110", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2410.23657", "html_url": "https://arxiv.org/abs/2410.23657", "title": "软件问题报告中的秘密泄露预防", "title_en": "Secret Breach Prevention in Software Issue Reports", "authors": "Sadif Ahmed,Md Nafiu Rahman,Zahin Wahab,Gias Uddin,Rifat Shahriyar", "background": "在数字时代，敏感信息如API密钥、令牌和凭据的意外暴露已成为日益严重的安全威胁。现有大部分研究工作主要集中在检测源代码中的秘密，而软件问题报告中的信息泄露则未得到充分研究。这项研究通过大规模分析和打造了一套用于GitHub问题中的暴露秘密检测的实用管道来填补这一空白。", "innovation": "本研究将正则表达式提取与大规模语言模型上下文分类相结合，以检测真实秘密并降低假阳性率。构建了一个包含54,148个实例的基准数据集，其中包括5,881个手工验证的真实秘密。研究评估了多种秘密检测工具所使用的基线方法、经典机器学习、深度学习和大规模语言模型方法。结果显示，正则表达式和熵基方法召回率高但精确率低，小型模型如RoBERTa和CodeBERT显著提升了性能，而自定义模型GPT-4o和调优的开源大型语言模型Qwen及LLaMA分别达到了80.13%和94.49%的F1值。此外，验证方法还应用于178个真实GitHub仓库，F1分数为81.6%，展示了该方法在实际场景中的强泛化能力。", "conclusion": "研究结果表明，结合正则表达式提取与大规模语言模型上下文分类的方法可以有效检测软件问题报告中的暴露秘密，尤其是大型语言模型在小样本学习中的表现尤为突出，展示了其强大的通用性能力。"}
{"llm_update_time": "20251110", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.18597", "html_url": "https://arxiv.org/abs/2503.18597", "title": "Testora：利用自然语言意图检测行为回退", "title_en": "Testora: Using Natural Language Intent to Detect Behavioral Regressions", "authors": "Michael Pradel", "background": "随着软件的演变，代码变更可能引入回归错误或以其他未预期的方式影响行为。传统的回归测试生成对于检测未预期的行为变化是不现实的，因为它会将所有行为差异都报告为潜在的回归。然而，大多数代码变更都是为了改变某些行为，比如修复一个错误或增加新功能。本文介绍了Testora，这是第一个通过比较代码变更的意图和由代码变更引起的行为差异来检测回归的自动化方法。给定一个拉取请求（PR），Testora会查询LLM生成测试以测试更改后的代码，比较原始代码和更改后的代码行为，并将任何行为差异分类为预期或未预期。对于分类，我们提出了一个基于LLM的技术，利用与PR相关联的自然语言信息，如标题、描述和提交消息，有效利用自然语言意图来检测行为回退。", "innovation": "Testora是第一个通过比较代码变更的意图和由代码变更引起的行为差异来检测回归的自动化方法。它利用拉取请求中的自然语言描述来识别和分类行为差异，从而区分预期和未预期的变化。这种创新方法有效地区分了代码变更的意图和实际行为，提高了回归测试的效果和效率。", "conclusion": "在对复杂和流行的Python项目拉取请求的测试中，Testora发现了19个回归错误，其中有11个拉取请求尽管具有其他意图，意外地修复了一个错误。13个报告给开发者的回归中有11个被确认且9个已经被修复。使用Testora的成本是可以接受的，检查一个拉取请求只需要12.3分钟，每次仅需0.003美元的LLM费用。我们期望该方法可以在代码变更合并之前或之后立即使用，提供早期检测传统方法未能捕获的回归的方式。"}
{"llm_update_time": "20251110", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2410.10628", "html_url": "https://arxiv.org/abs/2410.10628", "title": "LLM-生成单元测试中的测试异味", "title_en": "Test smells in LLM-Generated Unit Tests", "authors": "Wendkûuni C. Ouédraogo,Yinghua Li,Xueqi Dang,Xunzhu Tang,Anil Koyuncu,Jacques Klein,David Lo,Tegawendé F. Bissyandé", "background": "LLM（大型语言模型）有望将单元测试的生成从手动负担转变为自动化解决方案。然而，除了编译性和覆盖率等度量标准，对于LLM生成的测试的质量知之甚少，尤其是它们对测试异味（设计缺陷，损害代码可读性和维护性的缺陷）的敏感性。本文通过广泛分析LLM生成的单元测试中的测试异味，对比了LLM输出与人类编写的测验套件（作为实际情况的参考）以及Evolution Test Suite (EvoSuite)生成的测试（作为自动化基础），目的在于区分LLM再现人类特征的缺陷还是合成生成的特征。研究基于来自4个LLM模型（GPT-3.5，GPT-4，Mistral 7B，Mixtral 8x7B）、14,469个来自EvoSuite的测试和779,585个人类编写的测试数据集（来自34,635个开源Java项目）", "innovation": "本文首次提出了大规模、多基准的LLM生成单元测试中的测试异味扩散的分析。引入了TsDetect和JNose两种互补的检测工具，分析测试异味的分布、共现情况以及与软件属性和生成参数的相关性。结果显示，LLM生成的测试经常表现出诸如Assertion Roulette和Magic Number Test等异味，这些模式受到提示策略、上下文长度和模型规模的影响。对比研究揭示了LLM生成的测试与人工编写的测试存在重叠，引发了潜在训练数据泄露的顾虑，而EvoSuite则显示出特定的生成器专用缺陷。这些发现不仅突显了LLM基于的测试生成的潜力和风险，还提出了需要设计嗅觉感知生成框架、提示工程策略和增强检测工具的需求，以确保高质、可维护的测试代码。", "conclusion": "本文的研究证实了LLM生成的单元测试中存在明显的测试异味，并揭示了这些异味的产生机制和特性，从设计、特征检测和生成策略方面进一步补充了相关领域的知识。这些发现提醒我们在使用LLM进行测试生成时应保持警惕，需要通过改进生成过程和增强检测来提高测试代码的质量和可维护性。"}
{"llm_update_time": "20251110", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2511.04453", "html_url": "https://arxiv.org/abs/2511.04453", "title": "启动日扩散：跟踪 Hacker News 对 AI 工具 GitHub 星号影响", "title_en": "Launch-Day Diffusion: Tracking Hacker News Impact on GitHub Stars for AI Tools", "authors": "Obada Kraishan", "background": "近年来，社会新闻平台已成为开放源代码项目的重要发布渠道，特别是Hacker News（HN）。然而，量化其即时影响仍然具有挑战性。本文通过一个可复制的演示系统，跟踪HN曝光如何转化为AI和LLM工具在GitHub上的星号增长。该研究依赖公开API构建管道，分析2024-2025年间138个软件仓库的发布情况，揭示了显著的发布效应：在HN曝光后的24小时内，仓库平均获得121颗星，48小时内获得189颗星，一周内获得289颗星。研究还通过机器学习模型（Elastic Net）和非线性方法（梯度提升）来识别推动病毒式增长的关键预测因子。研究结果表明，发布时机是关键因素，最佳时刻发布可以带来数百颗额外的星号，而“Show HN”标签在控制其他因素后并没有统计优势。整个演示在标准硬件上可以短于五分钟内完成，自动化地收集数据、训练模型并生成可视化图表。这使得研究结果可立即进行复现，并且框架也可轻松扩展到其他平台，为研究人员和开发人员提供实用的启动动态见解。", "innovation": "本文提出了一个基于公众API的可复制演示系统，用于跟踪HN曝光如何转化为GitHub上AI工具的星号增长。研究表明，发布时机是关键因素，发布时间在最佳时间可以显著增加星号。此外，研究通过机器学习模型和非线性方法来识别推动病毒式增长的关键预测因子，提供了实用的指导。整个分析过程自动完成，通过单文件脚本在标准硬件上只需几分钟，提高了研究结果的可复现性，同时框架也可轻松扩展到其他平台。", "conclusion": "该研究通过一个基于公众API的可复制系统，分析了Hacker News（HN）曝光如何转化为GitHub平台上AI工具的星号增长，并揭示了显著的发布效应。研究使用机器学习模型（Elastic Net）和非线性方法（梯度提升）来识别影响病毒式增长的关键预测因子，表明发布时机是重要的因素，并通过自动化流程展示了研究结果的可复现性，框架也可扩展到其他平台。这对于研究人员和开发人员深入了解启动动态具有重要意义。"}
{"llm_update_time": "20251110", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.18793", "html_url": "https://arxiv.org/abs/2509.18793", "title": "C-ITS中的应用管理：需求驱动的部署和配置编排", "title_en": "Application Management in C-ITS: Orchestrating Demand-Driven Deployments and Reconfigurations", "authors": "Lukas Zanger,Bastian Lampe,Lennart Reiher,Lutz Eckstein", "background": "随着车辆的自动化和互联程度提高，合作智能运输系统（C-ITS）得以形成并使用了外部服务。这使得云原生技术，如微服务和容器编排，变得越来越重要。然而，在大型C-ITS中编排应用带来的独特挑战包括环境的动态性和高效资源利用的需求。因此，本文提出了一个基于云原生技术（特别是Kubernetes）的需求驱动应用管理方法，以应对这些挑战。", "innovation": "本文的方法考虑来自C-ITS内部不同实体的需求，能够自动化执行微服务的部署、重新配置、更新、升级和扩展等过程。通过动态满足需求，该方法能够在例如减少计算资源消耗和网络流量方面发挥作用。同时，该方法还处理不断变化和新的需求，通过集成Kubernetes和Robot Operating System (ROS 2) 提出的应用管理框架进行动态校准。", "conclusion": "本文通过Kubernetes和ROS 2构建的原型框架，在C-ITS中实现了集体环境感知的应用场景，并公开了该框架的源代码，以展示其在该应用场景中的操作。"}
