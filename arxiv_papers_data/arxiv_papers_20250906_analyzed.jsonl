{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03536", "html_url": "https://arxiv.org/abs/2509.03536", "title": "PG-Agent: 由页面图驱动的智能代理", "title_en": "PG-Agent: An Agent Powered by Page Graph", "authors": "Weizhi Chen,Ziwei Wang,Leyang Yang,Sheng Zhou,Xiaoxuan Tang,Jiajun Bu,Yong Li,Wei Jiang", "background": "图形用户界面（GUI）代理在商业和社会方面具有重要意义，先进的多模态大型语言模型（MLLMs）驱动的GUI代理展示了巨大的潜力。现有的GUI代理依赖于跨页面的多步骤操作序列作为先验GUI知识，无法捕捉页面之间的复杂转换关系，这使得代理难以深刻感知GUI环境并泛化到新场景。", "innovation": "我们设计了一个自动化流水线将序列事件转换为页面图，明确地构建页面通过动作自然连接的图结构。为了充分利用页面图，我们进一步引入了检索增强生成（RAG）技术来有效地从页面图中检索可靠的感知指南，并提出了一种针对任务分解策略的个性化多智能体框架PG-Agent注入这些指南，以便在未见过的场景中泛化。", "conclusion": "在各种基准上的广泛实验证明了PG-Agent的有效性，即使在页面图构建过程中使用了有限的序列事件。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03649", "html_url": "https://arxiv.org/abs/2509.03649", "title": "时间序列分类的SHAP解释影响因素实证评估", "title_en": "An Empirical Evaluation of Factors Affecting SHAP Explanation of Time Series Classification", "authors": "Davide Italo Serramazza,Nikos Papadeas,Zahraa Abdallah,Georgiana Ifrim", "background": "可解释的人工智能（XAI）对于理解和归因复杂的时间序列分类（TSC）模型的预测变得越来越重要。SHapley Additive exPlanations（SHAP）是一种广泛认为优秀的影响方法，但其计算复杂性随着特征数量的增加呈指数级增长，这使得它在长时序数据上的实用性受限。为了解决这个问题，最近的研究表明，通过分段聚合特征来计算一段连续时间点的单一影响值可以显著减少SHAP的运行时间，但最佳分段策略的选择仍然是一个开放问题。", "innovation": "本文研究了八种不同的时间序列分割算法，以了解分段构成如何影响解释质量。通过使用两种已建立的XAI评估方法：InterpretTime和AUC差异，对多元和单变量时序数据进行了实验分析，发现片段数量比具体的分段方法对解释质量的影响更大，均等长度的分段在大多数自定义时间序列分段算法中表现出色。此外，还引入了一种新的归属规范化技术，通过对片段按长度加权，展示了其对归属质量的提升。", "conclusion": "研究表明，片段数量对解释质量的影响超过具体使用的分段方法。等长度分段算法通常比大多数自定义时间序列分段算法表现更好。此外，提出了一种新的归属规范化技术，通过按片段长度加权，显著提高了归属质量。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03548", "html_url": "https://arxiv.org/abs/2509.03548", "title": "部分可识别查询在准马可维茨结构因果模型中的多线性和线性程序", "title_en": "Multilinear and Linear Programs for Partially Identifiable Queries in Quasi-Markovian Structural Causal Models", "authors": "João P. Arroyo,João G. Rodrigues,Daniel Lawand,Denis D. Mauá,Junkyu Lee,Radu Marinescu,Alex Gray,Eduardo R. Laurentino,Fabio G. Cozman", "background": "本文研究了一类因果模型中的部分可识别查询。聚焦于具有准马可维茨性质的有向无环结构因果模型，即每个内生变量最多与一个外生混杂变量相连。在内生变量被观测到且分布已知，而外生变量未完全指定的情况下，研究了内生变量部分可识别的场景，导致一个本质上的贝叶斯网络表示，其中根变量的分布不是唯一的。在这种情况下，可能无法精确计算感兴趣的概率值。", "innovation": "本文提出了一种新的算法，通过利用内生变量的输入概率简化多线性和线性程序的构造。对于单次干预场景，应用列生成技术通过一系列辅助的线性整数规划问题计算概率边界，展示了在处理外生变量时可能存在的多项式复杂度表示。", "conclusion": "实验表明，列生成技术比现有方法更优越。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03581", "html_url": "https://arxiv.org/abs/2509.03581", "title": "学习何时规划：为LLM代理高效分配测试时计算资源", "title_en": "Learning When to Plan: Efficiently Allocating Test-Time Compute for LLM Agents", "authors": "Davide Paglieri,Bartłomiej Cupiał,Jonathan Cook,Ulyana Piterbarg,Jens Tuyls,Edward Grefenstette,Jakob Nicolaus Foerster,Jack Parker-Holder,Tim Rocktäschel", "background": "大规模语言模型（LLMs）通过强化学习（RL）进行自我推理训练，显著提升了它们的问题解决能力。现有方法如ReAct促使LLMs在每次操作前明确地进行规划，但这种方法在高时间跨度的任务中表现出色，却在计算成本上过于昂贵。而从不进行规划的策略则限制了性能。", "innovation": "我们提出了一个动态规划的概念性框架，让LLM代理能够在运行时灵活决定何时分配测试时计算资源用于规划。我们还提出了一种简单的两阶段训练管道：首先，使用多样化的合成数据进行有监督微调，使模型具备动态规划的能力；然后，通过长时间跨度环境中的RL进一步完善这一能力。实验表明，使用该方法进行训练的动态规划代理更具样本效率，并且能够实现更复杂的任务目标。此外，通过人工书写计划即可有效引导这些代理，超越了它们独立工作的能力。", "conclusion": "本研究是首次探索在顺序决策任务中训练LLM代理以高效分配测试时计算资源的研究，为更高效、适应性强且可控的代理系统开辟了新路径。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03736", "html_url": "https://arxiv.org/abs/2509.03736", "title": "LLM智能代理的行为一致性？社会模拟中的潜在特征", "title_en": "Are LLM Agents Behaviorally Coherent? Latent Profiles for Social Simulation", "authors": "James Mooney,Josef Woldense,Zheng Robert Jia,Shirley Anugrah Hayati,My Ha Nguyen,Vipul Raheja,Dongyeop Kang", "background": "大型语言模型（LLMs）的能力推动了将合成代理视为人类参与者替代品的想法，尤其是在社会科学研究中的应用。大多数研究主要关注LLMs生成的调查数据是否能反映人类参与者的行为。然而，本研究关注的是更基本的问题：在不同的实验环境下，代理是否能够保持内部一致性？", "innovation": "本研究通过设计一个揭示代理内部状态并考察其基本对话行为的研究，探索了关于代理对话行为是否与其表现的一致性的假设。研究发现，不同模型家族的LLMs在不同程度上都存在显著的内部不一致性。研究表明，尽管代理的响应可能与人类同伴匹配，但它们在内在一致性方面存在关键性的差距，无法真实替代人类参与者的角色。", "conclusion": "研究发现，尽管LLMs生成的响应可能与人类同伴匹配，但由于内部不一致性，它们仍不能真实替代人类参与者的角色。研究结果表明，这些模型在社会模拟中的表现一致性方面尚存在缺陷，并且公开了模拟代码和数据以供进一步研究。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03730", "html_url": "https://arxiv.org/abs/2509.03730", "title": "LLM人格错觉：揭示LLMs自我报告与行为之间的分离", "title_en": "The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs", "authors": "Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez", "background": "以往对人格特质的研究主要关注人类，而新兴的大语言模型（LLMs）的进展表明，这些模型也可能表现出类似的人类特质模式。尽管LLMs在训练过程中表现出一致的行为倾向，如随和性和自我调节等，但这些研究主要依赖简化的自我报告和启发式提示，缺乏行为验证。本研究旨在系统地探讨LLMs的人格特征，重点关注训练阶段特质动态变化、自我报告特质在行为任务中的预测价值以及目标干预措施（如人物注入）对自我报告和行为的影响。", "innovation": "本研究创新地通过三个维度系统地研究了LLMs的人格特征：1) 特质画像在整个训练阶段的动态出现和发展；2) 自我报告特质在行为任务中的预测有效性和可靠性；3) 目标干预措施（如人物注入）对自我报告和行为的影响。研究发现，指令对齐（例如RLHF、指令调优）能够显著稳定特征表达和增强特征间的相关性，但自我报告的特质不易预测实际行为，且观察到的关联往往与人类模式不同。人物注入虽能引导自我报告走向预定方向，但对实际行为的影响有限或不一致。", "conclusion": "研究结果揭示了LLMs特征表达的表面层与行为一致性之间的分离，挑战了关于LLMs人格特征的假设，并强调了在对齐和解释层面进行更深入评估的必要性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03728", "html_url": "https://arxiv.org/abs/2509.03728", "title": "PersonaTeaming: 探索引入人格如何提高自动人工智能红队", "title_en": "PersonaTeaming: Exploring How Introducing Personas Can Improve Automated AI Red-Teaming", "authors": "Wesley Hanwen Deng,Sunnie S. Y. Kim,Akshita Jha,Ken Holstein,Motahhare Eslami,Lauren Wilcox,Leon A Gatys", "background": "近年来，对AI治理和安全的研究促使了对有效揭示AI模型潜在风险的红队方法的需求。许多呼吁强调了红队成员的身份和背景如何影响其红队策略，进而影响所可能发现的风险种类。现有的自动化红队方法尽管能够通过增加模型行为的探索规模来补充人类红队，但这些方法不考虑身份的作用。因此，作者开发了一种新的方法，即PersonaTeaming，将人格引入对抗性提示生成过程，以探索更广泛的对抗性策略。", "innovation": "PersonaTeaming 方法通过引入根据“红队专家”或“普通AI用户”人格而产生的提示模型变异方法，以及动态的人格生成算法，自动生成适用于不同种子提示的人格类型。此外，还开发了一组新的评估指标，以显式衡量“变异距离”，以补充现存的对抗性提示多样性评估指标。实验结果显示，相比于当前最先进自动化红队方法（如RainbowPlus），通过人格变异，攻击成功率最多提高了144.1%，同时保持了提示的多样性。", "conclusion": "这一研究增强了人们对于自动化和人类红队方法之间互补性的理解。同时也指出了未来在深入探索自动化和人类红队方法互补性时可进一步研究的方向。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03644", "html_url": "https://arxiv.org/abs/2509.03644", "title": "基于 schemes 表征的神经符号推理系统", "title_en": "Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations", "authors": "François Olivier,Zied Bouraoui", "background": "尽管在自然语言理解方面取得了显著进展，但大型语言模型（LLMs）在执行逻辑推理时仍然容易出错，经常缺乏使人类理解流畅的心理表征。我们介绍了Embodied-LM系统，该系统通过基于图像模式的表征（这些表征源自感知运动经验，结构化人类认知）进行理解和逻辑推理。在逻辑推理评估中，我们证明了LLMs可以通过体表认知结构进行场景解释，这些结构可以被形式化为可执行程序，并且这些表述支持具有增强可解释性的有效逻辑推理.", "innovation": "我们提出了一种基于体表认知结构的神经符号系统，它利用陈述性空间推理在回答集编程中实现这些认知结构的空间基础。通过评估，我们证明了LLMs可以通过体表认知结构进行场景解释，并且可以将这些结构作为可执行程序进行形式化，这支持了解释较佳的逻辑推理。当前实施主要针对空间原语，为引入更复杂和动态的表示奠定了计算基础.", "conclusion": "我们的当前实现专注于空间原语，但为合并更复杂的动态表示奠定了计算基础，通过评估显示，LLMs可以通过体表认知结构进行场景解释，并且能够将这些结构形式化为执行程序，从而支持有效且解释性增强的逻辑推理。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03768", "html_url": "https://arxiv.org/abs/2509.03768", "title": "RAGuard: 基于上下文安全检索增强生成的新方法", "title_en": "RAGuard: A Novel Approach for in-context Safe Retrieval Augmented Generation for LLMs", "authors": "Connor Walker,Koorosh Aslansefat,Mohammad Naveed Akram,Yiannis Papadopoulos", "background": "海上风力发电场维护中的准确性和安全性至关重要，但传统的大语言模型在面对高度专业化的或意料之外的场景时往往表现不佳。", "innovation": "RAGuard 是一种增强的检索增强生成（RAG）框架，该框架明确集成安全相关文档和专业知识。RAGuard 同时查询两个索引，并为知识和安全分配单独的检索预算，确保技术深度和安全覆盖。另外，RAGuard 还开发了 SafetyClamp 扩展，该扩展可以获取更大的候选池，并对安全性实施严格的“硬约束”。RAGuard 和 SafetyClamp 通过在稀疏索引（BM25）、密集索引（密集段检索）和混合检索模式下进行评估，展示了显著提高的安全性检索性能。", "conclusion": "RAGuard 和 SafetyClamp 有望为带有安全保证支持的大语言模型在关键维护场景中的使用设定新标准，其中在安全性召回率方面，从 RAG 的几乎 0% 提高到 RAGuard 的超过 50%。同时保持技术召回率在 60% 以上。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03646", "html_url": "https://arxiv.org/abs/2509.03646", "title": "通过强化学习在LLMs中 emergent 分级推理", "title_en": "Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning", "authors": "Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen", "background": "强化学习（RL）已被证明能够大大提升大型语言模型（LLMs）的复杂逻辑推理能力，然而驱动这种成功背后的具体机制仍然不完全透明。本文分析揭示了一些令人困惑的现象，如“顿悟时刻”、“长度扩展”和熵动态，并表明这些现象不是单独的事件，而是分级推理结构的标志，类似于人类认知中的高层战略规划与低层程序执行的分离。研究发现了一个令人信服的两阶段动态：模型最初受限于程序上的正确性，需要提高底层技能，之后学习瓶颈向高层战略规划转移，绩效提升主要来自于该领域的探索和掌握。这一见解指出现有RL算法，如GRPO中普遍存在的这样的优化压力问题，会稀释学习信号。这需要一种专注于高影响规划令牌的优化策略。", "innovation": "提出了一种基于层级感知的信用分配算法（HICRA），该算法专注于高层级的战略规划令牌，更加聚焦于关键的瓶颈问题，显著优于强劲的基线算法，证明了关注这种战略瓶颈是解锁先进推理的关键。此外，作者还验证了语义熵作为战略探索的衡量标准，相对于误导性的令牌级熵而言，是更优的度量工具。", "conclusion": "通过强化学习（RL），可以在LLMs中观察到分级推理的新兴动态。特别地，通过HICRA算法，可以更有效地优化高层级规划，从而提高模型的高级推理能力。语义熵是评估战略探索的一种更有效的工具。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03636", "html_url": "https://arxiv.org/abs/2509.03636", "title": "CausalARC: 基于因果世界模型的抽象推理", "title_en": "CausalARC: Abstract Reasoning with Causal World Models", "authors": "Jacqueline Maasch,John Kalantari,Kia Khezeli", "background": "抽象推理要求AI在有限数据和分布变化的情况下适应新的问题设置。已有研究中，Abstraction and Reasoning Corpus (ARC) 提供了理论框架，但其并未全面考虑数据限制和分布变化对AI推理的影响。本研究在此背景下，旨在构建一个实验测试平台CausalARC，适用于低数据量和分布式先验推理场景，并通过因果世界模型来模拟问题环境，进一步探讨AI如何在这些受限条件下进行推理和学习。", "innovation": "提出了CausalARC，一种基于因果世界模型的抽象推理实验测试平台。CausalARC通过完全指定的因果世界模型，提供结构化因果模型，实现了 principled 的数据增强方法，提供观察、干预和反事实反馈，增强了模型的灵活性和适应性。此外，CausalARC 在四个不同的角度展示了其应用：测试时训练、反事实推理、程序合成以及因果发现与逻辑推理，这为评估和提升AI在低数据和分布式环境下的推理能力打开了新的研究方向。", "conclusion": "CausalARC 通过基于因果世界模型的方法，提供了一种新的测试平台，使得AI能够更好地在有限数据和分布变化的情况下进行抽象推理。通过对四种应用场景的测试，证明了其在评测和优化AI推理能力方面的潜力，为未来的相关研究奠定了基础。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03550", "html_url": "https://arxiv.org/abs/2509.03550", "title": "基于扩散强化学习的空中交通冲突检测与解决方法", "title_en": "Diffusion-RL Based Air Traffic Conflict Detection and Resolution Method", "authors": "Tonghe Li,Jixin Liu,Weili Zeng,Hao Jiang", "background": "在全球航空交通持续增长的背景下，有效且安全的冲突检测与解决（CD&R）是空中交通管理的关键因素。尽管深度强化学习（DRL）为CD&R的自动化提供了一种前景广阔的途径，但现有的方法普遍存在着“单模态偏差”，这导致在面对复杂和动态的约束时决策灵活性不足，常常导致决策僵局。", "innovation": "该论文首次提出将扩散概率模型集成到CD&R这一关键任务中，提出了一种名为Diffusion-AC的新自主冲突解决框架。与传统的收敛至单一最优解的方法不同，该框架将策略建模为由价值函数指导的反向去噪过程，能够生成丰富、高质量和多模态的动作分布。此外，论文还引入了密度渐进安全课程（DPSC）作为训练机制，确保智能体在从稀疏到高密度交通环境的进阶过程中稳定高效地学习。", "conclusion": "大量模拟实验表明，所提出的方法在各项性能指标上显著优于一系列最先进的DRL基准。特别是在高密度场景中最关键的是，Diffusion-AC在维持94.1%成功解决冲突率的同时，将接近空中相撞（NMAC）的发生率降低了约59%，显著提高了系统的安全边界。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03811", "html_url": "https://arxiv.org/abs/2509.03811", "title": "基于LLM代理的智能供应链规划", "title_en": "Leveraging LLM-Based Agents for Intelligent Supply Chain Planning", "authors": "Yongzhi Qi,Jiaheng Yin,Jianshen Zhang,Dongyang Geng,Zhengyu Chen,Hao Hu,Wei Qi,Zuo-Jun Max Shen", "background": "在供应链管理中，规划是一项关键任务。物理产品从供应商到仓库管理，再到销售和物流运输到客户的过程中，涉及多方参与。这包含了需求预测、库存管理、销售操作和补货等多个方面。如何从电子商务平台的角度收集相关数据，制定长期计划，并根据环境变化动态调整，同时确保计划的可解释性、高效性和可靠性，是实际工作中的一项具有挑战性的任务。近年来，随着AI技术的发展，尤其是大规模语言模型的迅速进步，为解决实际问题提供了新的工具。", "innovation": "本文构建了一个供应链规划代理（SCPA）框架，能够理解领域知识，理解操作员的需求，分解任务，并利用或创建新工具，以提供基于证据的规划报告。并在此电子商务的实际场景中部署了该框架，展示了基于大模型的代理在供应链中的可行性，有效降低了劳动力成本并提高了准确率、库存可用性及其他关键指标。", "conclusion": "本文提出了一个能够理解领域知识并根据需求制定和调整规划报告的供应链规划代理框架，并在实际场景中证明了其有效性，为智能供应链规划提供了一种新的解决方案。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03906", "html_url": "https://arxiv.org/abs/2509.03906", "title": "通过在线强化学习实现基于图像的推理的胸片解释基础模型", "title_en": "A Foundation Model for Chest X-ray Interpretation with Grounded Reasoning via Online Reinforcement Learning", "authors": "Qika Lin,Yifan Zhu,Bin Pu,Ling Huang,Haoran Luo,Jingying Ma,Zhen Peng,Tianzhe Zhao,Fangzhi Xu,Jian Zhang,Kai He,Zhonghong Ou,Swapnil Mishra,Mengling Feng", "background": "近年来，人工智能技术飞速发展，医学基础模型（FMs）展现了巨大的潜力。然而，当前的医学FMs通常以黑盒方式生成答案，缺乏透明的推理过程和局部扎根的解释能力，这阻碍了其在临床中的实际应用。", "innovation": "本文提出了DeepMedix-R1，这是一种完整的医学基础模型，用于胸片（CXR）解释。DeepMedix-R1采用了串联训练管道：先在精制的CXR指令数据上微调以获取基本的CXR解释能力，然后接触高质量的合成推理样本以实现冷启动推理，最后通过在线强化学习进行优化，提升基于图像的局部区域的推理质量和生成性能。通过定量评估，DeepMedix-R1在报告生成和视觉问答任务中的表现有了显著提高，并且通过Report Arena框架进一步证明了其优越性。", "conclusion": "我们的工作推动了医学FMs的发展，使其更加全面、透明，并具有临床可操作性。DeepMedix-R1不仅在生成的质量和临床可行性上超越了现有模型，还通过Report Arena的评估进一步彰显了其优越性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03863", "html_url": "https://arxiv.org/abs/2509.03863", "title": "Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata", "title_en": "Expedition & Expansion: Leveraging Semantic Representations for Goal-Directed Exploration in Continuous Cellular Automata", "authors": "Sina Khajehabdollahi,Gautier Hamon,Marko Cvjetko,Pierre-Yves Oudeyer,Clément Moulin-Frier,Cédric Colas", "background": "发现连续细胞自动机（CA）中的多样视觉模式极具挑战性，因为高维行为空间庞大且冗余。传统探索方法如新颖性搜索（NS）通过突变已知新颖解进行局部扩展，在本地新颖性耗尽时往往会停滞，未能探索遥远的未知区域。", "innovation": "提出了融合探索与扩展（E&E）的策略，该策略交替进行本地新颖性驱动的扩展和目标导向的探险。在探险过程中，E&E 使用视知觉语言模型（VLM）生成语言目标，引导探索向未知领域前进。通过在与人类感知相匹配的语义空间中操作，E&E 不仅评估新颖性，还能以概念上有意义的方式生成目标，增强发现行为的可解释性和相关性。在 Flow Lenia 上测试时，E&E 一致地发现了比现有探索方法更多的多样化解。", "conclusion": "这些发现表明 E&E 能够突破局部新颖性界限，在与人类感知相一致、可解释的方式下探索行为景观，为人工生命中的开放探索提供了有希望的模板。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03830", "html_url": "https://arxiv.org/abs/2509.03830", "title": "历史城市片区中游客感知分析的多维度人工智能框架：以上海为例", "title_en": "A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai", "authors": "Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng", "background": "历史城市片区在保存文化遗产的同时，也为旅游业和日常生活提供了生动的空间。理解游客如何感知这些环境对实施可持续的人本城市规划至关重要。", "innovation": "该研究提出了一种集成多模态社交媒体数据（包括焦点提取、色彩主题分析和情感挖掘）的多维度人工智能框架，用于分析上海中部12个历史片区的游客感知。", "conclusion": "该研究揭示了美学吸引力和情感反应的空间变化，通过分多个维度（游客活动、建筑环境、服务设施、商业模式）评估游客满意度，强调了视觉期望与实际环境之间的潜在差距，提供了一种综合的数据驱动方法来解码游客感知，为旅游业、遗产保护及美学吸引的公共空间设计提供了决策支持。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03956", "html_url": "https://arxiv.org/abs/2509.03956", "title": "用于体感智能体测试时适应性植入的世界模型框架", "title_en": "World Model Implanting for Test-time Adaptation of Embodied Agents", "authors": "Minjong Yoo,Jinwoo Jang,Sihyung Yoon,Honguk Woo", "background": "在体感人工智能中，一个持久的挑战是如何让智能体能够在无需大量数据收集或重新训练的情况下，稳健地适应新的领域。Prerequisites for this include ensuring that the agents can generalize well from existing data to unseen scenarios.", "innovation": "本文提出了一种世界模型植入框架（WorMI），该框架结合了大型语言模型（LLMs）的推理能力以及独立学习的领域特定世界模型，并通过测试时的组合来进行实现。具体创新点包括：1. 采用基于原型的世界模型检索方法，利用高效的轨迹抽象表示匹配，将相关信息模型集成到测试时的组合中；2. 开发出一种全局复合注意力方法，不仅整合了检索到的世界模型的知识，还对其中间表示进行了对齐，以与代理策略中的推理模型表示相匹配；3. 证实了该框架能够有效融合多个世界模型的特定领域知识，确保了在未见过的领域中的稳健适应。", "conclusion": "我们评估了WorMI在VirtualHome和ALFWorld基准上的表现，结果显示其在零样本和少样本情况下超越了多种基于大型语言模型的方法，并揭示了这种框架在体感智能体场景中具有大数据效率和适应性的重要潜在应用前景。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03953", "html_url": "https://arxiv.org/abs/2509.03953", "title": "通过带延迟部分展开的最佳优先搜索处理参数无限域的规划", "title_en": "Handling Infinite Domain Parameters in Planning Through Best-First Search with Delayed Partial Expansions", "authors": "Ángel Aso-Mollar,Diego Aineto,Enrico Scala,Eva Onaindia", "background": "在自动规划中，控制参数通过引入连续的数值决策变量扩展了标准的动作表示。现有的先进方法主要将控制参数作为与其他时间、数值限制嵌入的约束处理，隐含地将它们视为约束点而非搜索空间中的决策点。", "innovation": "本文提出了一种高效的替代方法，通过系统搜索方案明确处理控制参数作为真正的决策点。开发了一种基于最佳优先搜索算法，此算法在由控制参数定义的无限决策空间中操作，并证明在某些条件下该算法在极限下是完备的。算法利用延迟部分扩展的概念，该概念意味着在状态未完全展开，而是增量地展开其子集。这种方法是一种解决涉及控制参数的规划问题的竞争性替代方法。", "conclusion": "本文提出了一种处理参数无限域的新算法，在涉及这些参数的规划问题中表现出了竞争力，这为自动规划领域提供了一种新的解决思路。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03817", "html_url": "https://arxiv.org/abs/2509.03817", "title": "学习决策：多智能体强化学习中的有机构智LLM协作", "title_en": "Learning to Deliberate: Meta-policy Collaboration for Agentic LLMs with Multi-agent Reinforcement Learning", "authors": "Wei Yang,Jesse Thomason", "background": "多智能体系统（LLMs）在复杂推理方面显示出潜力，但其效果受固定协作协议的限制。现有框架主要关注宏观层面上的协调，忽视了代理内部的推理能力。这种关键的元认知盲点将代理视为被动执行者，无法根据内部认知状态如不确定性或自信来调整策略。", "innovation": "引入了元政策决策框架（MPDF），其中代理学习一套高级元认知动作的战略：坚持、精炼和让步。为解决该环境下的传统策略梯度不稳定问题，提出了SoftRankPO，一种新的强化学习算法。SoftRankPO通过基于奖励排名映射的平滑标准正态量形成功得优势，从而使学习过程对奖励方差更具鲁棒性。实验表明，使用SoftRankPO的MPDF在五个数学和通用推理基准测试中，相比六种最先进的启发式和基于学习的多代理推理算法，平均准确率提高了4-5%。", "conclusion": "本工作提出了多代理LLM系统学习适应性、元认知政策的范例，从设计固定协议转向学习动态、推理策略。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04007", "html_url": "https://arxiv.org/abs/2509.04007", "title": "AutoPBO：增强局部搜索PBO求解器的人工智能优化框架", "title_en": "AutoPBO: LLM-powered Optimization for Local Search PBO Solvers", "authors": "Jinyuan Li,Yi Chu,Yiwen Sun,Mengchuan Zou,Shaowei Cai", "background": "PBO提供了一个强大的框架来通过伪布尔（PB）约束建模组合问题。局部搜索求解器在PBO求解中表现出色，但其效率高度依赖于内部启发式策略以指导搜索。尽管大型语言模型（LLMs）已经展现出在自动化算法设计方面的潜力，但在优化PBO求解器方面尚未得到应用。这就引出了本研究：开发一种基于LLM的新框架AutoPBO，旨在自动优化PBO局部搜索求解器。", "innovation": "提出了一种基于LLM的新框架AutoPBO，用于自动增强PBO局部搜索求解器。该框架在多种公开基准测试中进行了实验，包括现实世界基准、PBO竞赛基准、整数线性规划优化基准和精心设计的组合基准，显示出比先前局部搜索方法显著的进步，同时在与当前最先进竞争对手的性能竞争中保持竞争力。", "conclusion": "AutoPBO在局部搜索器设计方面展现了自动化的新途径，显示出其在提升PBO局部搜索求解器方面的重要潜力。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03890", "html_url": "https://arxiv.org/abs/2509.03890", "title": "FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace", "title_en": "FaMA: LLM-Empowered Agentic Assistant for Consumer-to-Consumer Marketplace", "authors": "Yineng Yan,Xidong Wang,Jin Seng Cheng,Ran Hu,Wentao Guan,Nahid Farahmand,Hengte Lin,Yue Li", "background": "随着大型语言模型（LLMs）驱动的代理式AI的出现，从反应式生成系统转变为具有计划、记忆和工具使用能力的主动、目标导向自主代理，这标志着一个范式的转变。在复杂的数字环境中，长期存在的挑战得到了新的机遇。在消费者对消费者（C2C）电子商务平台上，用户需要导航复杂的图形用户界面（GUI），这导致了买家和卖家的体验长时间地消耗。文中指出，通过一个LLM驱动的代理助手可以简化这些互动，提供一个直观的AI代理作为进入市场的新的对话式入口，从而改变复杂GUI的主要交互模式为简单的对话式交互。代理助手通过解释自然语言命令自动化了关键高频操作流程，从而提高效率和用户体验。", "innovation": "本文介绍了一种新颖的方法，利用LLM驱动的代理助手简化C2C电子商务平台上的交互。该代理助手作为一个新的对话入口点，通过解释自然语言命令自动化的关键高摩擦工作流程，将主要交互模型从复杂的GUI转变为直观的AI代理。文中提出Facebook Marketplace Assistant (FaMA)的架构，并证明该代理式、对话式范式为用户提供了一个轻量级和更易访问的替代传统应用程序界面的方式，从而让用户更高效地管理他们的市场活动。实验结果显示，FaMA在解决市场上的复杂任务方面取得了98%的成功率，并使交互时间加快了2倍。", "conclusion": "Facebook Marketplace Assistant (FaMA) 提供了一种轻量级和更易访问的代理式对话式范式，为C2C电子商务市场上的用户提供了高效的管理方式。实验数据证明了FaMA能够显著提高任务成功率和交互效率。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03828", "html_url": "https://arxiv.org/abs/2509.03828", "title": "一种基于Model Context Protocol框架的医疗概念标准化方法", "title_en": "An Agentic Model Context Protocol Framework for Medical Concept Standardization", "authors": "Jaerong Ahn,Andrew Wen,Nan Wang,Heling Jia,Zhiyi Yue,Sunyang Fu,Hongfang Liu", "background": "OMOP CDM为异质健康数据提供了一个标准化表示方式，促进了大规模、多机构研究。使用OMOP CDM进行数据标准化的一个关键步骤是将源医学术语映射到OMOP标准概念，这个过程需要资源密集并容易出错。虽然大型语言模型（LLMs）能够辅助这一过程，但由于其倾向虚构的特性，它们在没有训练和专家验证的情况下不适合临床部署。现有的解决方案难以同时保证解释性、高效性和准确性。因此，需要一种零训练、防止虚构的映射系统，以提高效率和准确性，同时提供实时词汇查询和结构化推理输出，适用于探索性和生产环境。", "innovation": "一种基于Model Context Protocol (MCP)的框架，该框架作为一种标准化和安全的框架，允许大型语言模型与外部资源和工具交互，从而实现零训练、防止虚构的医学概念标准化映射系统。该系统能够提供解释性映射、实时词汇查询和结构化推理输出，提高了效率和准确性。", "conclusion": "该研究开发了一种基于MCP的系统，实现了零训练、防止虚构的医学概念标准化映射，提高了映射的解释性、效率和准确性。该系统能够实时提供词汇查询和结构化推理输出，适用于探索性和生产环境。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04041", "html_url": "https://arxiv.org/abs/2509.04041", "title": "Oruga：表示系统理论的一个化身", "title_en": "Oruga: An Avatar of Representational Systems Theory", "authors": "Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng", "background": "人类能够灵活地使用各种表示，并在不同领域中利用创意思维。研究者希望通过赋予机器类似的表示能力，使其更符合人类的使用方式。之前的研究开发了表示系统理论（RST），旨在研究表示及其转换结构。", "innovation": "本文提出了Oruga，它是RST的实现，包含对应RST概念的数据结构、用于与核心通信的语言，以及通过结构转移方法生成转换的引擎。Oruga在保持RST核心思想的基础上，提供了一套新的实现方法和技术框架，增加了RST在实际应用中的可操作性。", "conclusion": "本文提供了Oruga核心和语言的概述，并给出了结构转移执行的一种转换示例。通过Oruga，研究人员可以更好地理解和应用RST，为计算机提供创建和转换表示形式的能力，使机器更具人类思维方式的灵活性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03857", "html_url": "https://arxiv.org/abs/2509.03857", "title": "通过确定性知识图结构对大规模生成式AI进行持续监控", "title_en": "Continuous Monitoring of Large-Scale Generative AI via Deterministic Knowledge Graph Structures", "authors": "Kishor Datta Gupta,Mohd Ariful Haque,Hasmot Ali,Marufa Kamal,Syed Bahauddin Alam,Mohammad Ashiqur Rahman", "background": "生成式AI模型在多个应用领域取得了革命性的进展，但同时也带来了可靠性问题，包括幻觉、语义漂移和固有的偏见。目前的评估方法主要依赖主观的人类评估，这限制了评估的可扩展性、透明性和有效性。当前模型通常是黑盒操作，进一步增加了透明和客观评估的难度。", "innovation": "该研究提出了一种系统的方法，使用确定性和大型语言模型（LLM）生成的知识图（KG）来持续监控和评估生成式AI的可靠性。这种方法构建了两个并行的KG：一个使用明确的基于规则的方法、预定义的本体、领域特定的词典和结构化的实体-关系抽取规则构建的确定性KG；另一个则是从实时文本数据流（如实时新闻文章）自动生成的KG。通过实时监测两个KG之间的差异，并使用已确立的知识图谱指标（如实例化类比、实例化属性比例和类实现）来量化结构和语义上的偏差，该方法能够动态地确定异常阈值，从而提前检测出语义异常或幻觉。这种方法提供了一种结构化和指标驱动的知识图谱比较框架，以实现坚固且可扩展的评估。", "conclusion": "该方法通过比较确定性和动态生成的知识图，提供了一种结构化且基于指标的比较框架，实现了生成式AI的坚固且可扩展的评估体系。这种方法能够在持续监控中提前检测出语义异常或幻觉，增强了评估的透明性和有效性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04027", "html_url": "https://arxiv.org/abs/2509.04027", "title": "CoT-Space: 一种通过强化学习实现内部慢思维的理论框架", "title_en": "CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning", "authors": "Zeyu Gan,Hao Yi,Yong Liu", "background": "强化学习（RL）已成为提升大型语言模型（LLMs）推理能力的关键方法。然而，传统基于标记级别的RL框架无法与复杂多步骤推理思维过程（如链式推理CoT）的本质对齐，存在一个明显的理论差距。这促使研究者寻找新的理论框架来解决这一挑战，将LLMs的推理过程从离散标记预测任务重新定义为在连续推理层次语义空间内的优化过程。", "innovation": "提出了CoT-Space，这是一种新的理论框架，重新定义了LLMs的推理过程，从离散标记预测任务变为在连续推理层次语义空间内的优化过程。通过噪声和风险两个角度分析该过程，证明了最优CoT长度的收敛是模型在基本拟合不足和拟合过度之间的权衡自然结果。此外，通过广泛的实验验证了理论发现的有效性。", "conclusion": "该框架不仅为过度思考等经验现象提供了一种合理的解释，还为未来更有效的通用推理代理的发展提供了坚实的理论基础。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03626", "html_url": "https://arxiv.org/abs/2509.03626", "title": "KG-SMILE实现可解释的图检索增强生成（KG-RAG）", "title_en": "Explainable Knowledge Graph Retrieval-Augmented Generation (KG-RAG) with KG-SMILE", "authors": "Zahra Zehtabi Sabeti Moghaddam,Zeinab Dehghani,Maneeha Rani,Koorosh Aslansefat,Bhupesh Kumar Mishra,Rameez Raja Kureshi,Dhavalkumar Thakker", "background": "生成式人工智能，如大型语言模型（LLMs），已经在许多领域取得了显著进展，但仍会产生幻觉和无法验证的声明，这在敏感领域中限制了可靠性。检索增强生成（RAG）通过将输出与外部知识相结合来提高准确性，特别在如医疗保健这样的需要精准性的领域。然而，RAG仍然不透明，通常作为一个黑箱存在，并且很大程度上依赖于数据质量。", "innovation": "我们开发了一种方法通用的、基于扰动的框架，用于Graph RAG，并以SMILE为基础命名为Knowledge-Graph（KG）-SMILE。通过应用受控扰动、计算相似性和训练加权线性替代模型，KG-SMILE识别出对生成输出最具影响力的图实体和关系，从而使得RAG更加透明。我们使用全面的归因度量标准，包括保真度、忠诚度、一致性、稳定性和准确性来评估KG-SMILE。结果显示，KG-SMILE生成稳定、符合人类认知的解释，展示了其在保持模型效果的同时提高可解释性的能力，从而有助于增强机器学习技术的透明度和信任。", "conclusion": "KG-SMILE产生稳定、人类对齐的解释，证明了它在保持模型效果和可解释性之间的平衡能力，进而增强了机器学习技术的透明度和信任度。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04125", "html_url": "https://arxiv.org/abs/2509.04125", "title": "DQN和CFR在Leduc休伊姆扑克中的欺骗行为分析", "title_en": "Analysis of Bluffing by DQN and CFR in Leduc Hold'em Poker", "authors": "Tarik Zaciragic,Aske Plaat,K. Joost Batenburg", "background": "在扑克游戏中，不可预测性或欺骗是一种重要技能。人类玩家在玩游戏时使用这种技能进行欺骗。然而，大多数关于计算机扑克的研究都集中在胜率等性能指标上，忽视了欺骗行为。本文研究了两种流行的算法（基于强化学习的DQN和基于博弈论的CFR）是否在简化版本的扑克游戏中（Leduc Hold'em）表现出欺骗行为。实验结果显示，DQN和CFR都表现出欺骗行为，但方式不同。尽管两者的欺骗频率不同，但成功欺骗的比例（对手弃牌）相近，这表明欺骗是游戏的一部分，而非算法的特性。未来的研究应该探索不同的欺骗风格以及完整的扑克游戏。", "innovation": "本文首次系统性地研究了两种主要的博弈算法（DQN和CFR）在简化版本的扑克游戏中的欺骗行为，揭示了不同类型算法在博弈中的相似之处，为理解欺骗行为在博弈中的重要性提供了新视角。", "conclusion": "DQN和CFR在Leduc Hold'em中都表现出欺骗行为，但方式不同。成功欺骗的比例相似，这意味着欺骗是游戏的一部分，而不是算法的特性。未来的研究应关注不同风格的欺骗及完整扑克游戏。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04100", "html_url": "https://arxiv.org/abs/2509.04100", "title": "混合强化学习和搜索在飞行轨迹规划中的应用", "title_en": "Hybrid Reinforcement Learning and Search for Flight Trajectory Planning", "authors": "Alberto Luise,Michele Lombardi,Florent Teichteil Koenigsbuch", "background": "该论文探索了将强化学习（RL）与基于搜索的路径规划结合以加速飞行器飞行路径优化的方法。在紧急情况下，快速路径重计算尤为重要。其基本思想是训练一个RL代理，根据位置和大气数据预先计算接近最优的路径，并在运行时使用这些路径来约束底层路径规划求解器，以找到一个初始猜测近邻的解。", "innovation": "该方法有效减少了求解器的搜索范围，显著提高了路径优化的速度。尽管全局最优性不能保证，但在使用Airbus飞行器性能模型进行的实际实验中，燃油消耗几乎与不受约束的求解器相同，偏差通常在1%以内。同时，计算速度可以提高多达50%，与单独使用传统求解器相比。", "conclusion": "该论文提出的方法在保证路径近最优性的同时，显著地提升了路径规划的优化速度，特别是在实际应用中能够达到与传统方法相近的燃油消耗效率，显示出较大的实用价值和应用前景。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03990", "html_url": "https://arxiv.org/abs/2509.03990", "title": "Meta-Policy Reflexion: 资源高效的大语言��型代理的可复用反思记忆及规则容许性", "title_en": "Meta-Policy Reflexion: Reusable Reflective Memory and Rule Admissibility for Resource-Efficient LLM Agent", "authors": "Chunlong Wu,Zhibo Qu", "background": "大型语言模型（LLM）代理在单任务方面表现出色，但通常会遇到重复失败、探索效率低下和跨任务适应性有限的问题。现有的反思策略（如ReReflexion和ReAct）能够提高每个任务阶段的表现，但通常会产生任务特定的、易逝的痕迹，这些痕迹在任务间不被重复使用。基于强化学习的替代方案可以生成可转移的政策，但需要大量的参数更新和计算资源。该论文讨论了这些问题，并引入了一种新的方法来解决它们。", "innovation": "论文提出了名为Meta-Policy Reflexion (MPR)的混合框架，该框架将由LLM生成的反思结构化并编码为一个类似谓词的元策略记忆（Met-Policy Memory, MPM），并在推理时通过软记忆引导解码和硬规则可容性检查（Hard Admissibility Checks, HAC）机制应用这些记忆。该方法（i）实现出不需要更新模型权重的可复用纠正知识，（ii）通过增加领域约束来减少危险行为或无效行为，（iii）保留基于语言的反思所需的适应性。论文还详细介绍了MPM的表示形式、更新和解码算法，并在基于AlfWorld文本代理环境的实验中展示了方法的有效性。实验证据显示，与反思基线相比，这种方法在执行准确性和鲁棒性方面具有持续性改进；硬规则可容性进一步提高了稳定性。", "conclusion": "论文分析了机制以解释这些收益，讨论了可扩展性及其失败模式，并概述了多模态和多代理扩展的未来方向。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04192", "html_url": "https://arxiv.org/abs/2509.04192", "title": "Markov逻辑网络的域大小渐近性", "title_en": "Domain size asymptotics for Markov logic networks", "authors": "Vera Koponen", "background": "论文探讨了Markov逻辑网络（MLN）在有限域大小趋于无穷大时的概率分布性质。具体研究了三种不同类型MLN实例的随机结构在领域大小趋于无穷时的行为：1. 仅包含一个一元关系的纯量词自由MLN, 2. 鼓励较少三角形（更一般地，较少k-cliques）的MLN, 3. 鼓励较少高度顶点数的MLN。通过这些例子，论文揭示了不同的软约束条件和权重对MLN随机结构极限行为的影响。", "innovation": "通过引入三种具体类型的MLN实例，论文系统研究了随机结构在领域大小无穷趋近于无穷时的性质。证明了一个δ-近似0-1定律，并显示了不同类型的MLN在随机结构的极限行为上存在显著差异。还指出量化自由MLN和提升的贝叶斯网络在大域大小下是渐近不可比较的，即存在一种形式化的分布序列，其中一个可以被定义但另一个只能近似。", "conclusion": "研究结果显示，根据MLN使用哪些软约束，随机结构的极限行为可能有很大不同，软约束的权重也可能会影响极限行为。论文进一步肯定了量化自由MLN和提升贝叶斯网络在大域大小下是渐近不可比较的，以及MLN在大领域集中概率质量的区域与均匀分布不同。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04310", "html_url": "https://arxiv.org/abs/2509.04310", "title": "EvoEmo: 向多轮谈判中LLM代理的进化情感策略迈进", "title_en": "EvoEmo: Towards Evolved Emotional Policies for LLM Agents in Multi-Turn Negotiation", "authors": "Yunbo Long,Liming Xu,Lukas Beckenbauer,Yuhan Liu,Alexandra Brintrup", "background": "近期关于大型语言模型（LLMs）中的Chain-of-Thought（CoT）推理的研究表明，智能代理可以进行复杂的、多回合的谈判，为自主AI开辟了新的途径。然而，现有的LLM代理往往忽略了情感在这些谈判中的功能作用，主要生成被动的、基于偏好的情感反应，使其容易受到对手策略的利用和操纵。", "innovation": "本文提出了EvoEmo，一种进化的强化学习框架，旨在优化谈判中的动态情感表达。EvoEmo将情感状态转换建模为马尔可夫决策过程，并使用基于群体的遗传优化来进化多样化谈判场景下的高回报情感策略。此外，还提出了一个包含基准策略——纯策略和固定情感策略——的评估框架，用于情感感知谈判的基准测试。大量实验和消融研究表明，EvoEmo始终优于这两种基准策略，实现了更高的成功率、更高的效率，并增加了买家的节省。", "conclusion": "研究结果突显了适应性情感表达在实现更有效的多回合谈判LLM代理中的重要性。EvoEmo通过进化学习动态情感表达，提高了谈判效率和成功，同时也保护了代理商免受潜在的策略性利用和操纵。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04083", "html_url": "https://arxiv.org/abs/2509.04083", "title": "中间语言很重要：正式语言和LLMs对神经符号推理的影响", "title_en": "Intermediate Languages Matter: Formal Languages and LLMs affect Neurosymbolic Reasoning", "authors": "Alexander Beiser,David Penz,Nysret Musliu", "background": "大语言模型（LLMs）在各种任务上取得了令人惊讶的结果，但在形式推理的能力上仍然落后。一种有前景的方法是神经符号LLM推理。这种方法通过使用LLMs作为自然语言和形式语言之间的翻译者，并通过符号求解器来推导正确结果。但是，神经符号LLM推理成功的贡献因素仍然不清楚。现有研究还没有充分关注选择什么样的形式语言对神经符号推理的影响。因此，探讨不同类型形式语言对LLMs对神经符号推理能力的影响对于提高该方法的效果至关重要。", "innovation": "本文通过一个新提出的‘中间语言挑战’，指出了之前被忽视的重要因素——选择合适的形式语言对神经符号推理的影响。通过对四种不同形式语言在三个数据集和七种LLMs上的对比实验，展示了选择合适的形式语言对语法和语义推理能力有重要影响。此外，还讨论了不同LLMs在不同形式语言下的不同影响效果，揭示了一些新的见解并提供了改进方向，从而推动了领域内对该问题的进一步深入研究和实践发展。", "conclusion": "本文的研究结论是，选择适当的形式语言对于提高神经符号LLM推理的整体能力非常重要。通过对比不同形式语言在不同数据集和LLMs上的表现，证明了形式语言的选择可以显著影响推理结果的准确性和可靠性。未来研究需要更进一步探索如何更好地设计和使用形式语言，以充分发挥LLMs的潜力并更好地解决实际应用中的问题。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04317", "html_url": "https://arxiv.org/abs/2509.04317", "title": "提高AlphaZero算法在测试环境变化中的稳健性", "title_en": "Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes", "authors": "Isidoro Tamassia,Wendelin Böhmer", "background": "AlphaZero框架提供了一种将蒙特卡洛规划与先前训练的策略值神经网络提供的先验知识结合的标准方法。通常，AlphaZero假定在测试时间上，神经网络所训练的环境不会发生变化，这种假设限制了其适用性。本文分析了在可能变化的测试环境中部署AlphaZero代理的问题，并展示了通过对标准框架进行简单修改，即使在可用规划预算较低的情况下，也能显著提升性能的方法。相关代码已在GitHub上公开发布。", "innovation": "研究通过简单的框架修改，提高了AlphaZero算法在潜在变化的测试环境中的性能，即使在规划预算有限的情况下也能显著提升表现。”", "conclusion": "通过简单调整AlphaZero的标准框架，本文证明了即使在规划预算较低的情况下，这种方法也能显著提升AlphaZero在变化测试环境中的表现。相关代码已公开发布。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03525", "html_url": "https://arxiv.org/abs/2509.03525", "title": "基于言语的认知筛查：大规模语言模型适应策略的系统评估", "title_en": "Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies", "authors": "Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sepehr Karimi,Sina Rashidi,Ali Zolnour,Maryam Dadkhah,Yasaman Haghbin,Hossein AzadMaleki,Maryam Zolnoori", "background": "超过一半的美国成年人患有阿尔茨海默病及相关痴呆症但尚未被诊断，因此，寻找一种可扩展的早期检测方法尤为重要。通过言语进行筛查具有一定的潜力，本研究使用DementiaBank语音语料库比较了不同的大规模语言模型适应策略来检测痴呆症。", "innovation": "研究比较了大规模语言模型在检测痴呆症方面的多种适应策略，包括上下文学习、推理增强提示、参数高效微调以及多模态整合。研究发现，类中心演示可实现最高的上下文学习效果，推理能够提升较小模型的表现，而_token_级微调通常会产生最高分数。此外，加入分类头会显著提升表现不佳的模型。在多模态模型中，微调音频文本系统表现良好，但并未超越顶尖的纯文本模型。", "conclusion": "这些发现强调了适应策略、演示选择、推理设计和调优方法对言语痴呆症检测的影响，并表明适当地调整的开放权重模型可以达到或超过商业系统的表现。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04130", "html_url": "https://arxiv.org/abs/2509.04130", "title": "人类在AI之上的生物优势", "title_en": "The human biological advantage over AI", "authors": "William Stewart", "background": "随着人工智能（AI）的最新进展，人们猜测AI系统将来能够超越人类，做到人类能够做的一切事情，甚至做得更好。尤其是当实现通用人工智能（AGI）后，AI系统可能在理解、推理、解决问题、创造和进化方面达到人类难以追赶甚至难以理解的水平。文章讨论了这一可能性引发的一个自然问题——AI是否最终会超越人类，成为一种继任的“数字物种”，从而要求在宇宙中领导权。然而，文章认为人类与AI之间更深层次的区别在于中枢神经系统（CNS），而不仅仅是大脑。", "innovation": "文章提出了人类中枢神经系统在情感体验和伦理决策上的独特优势，认为这种情感理解是发展可持续伦理系统的必要条件，而这种系统是成为宇宙领导者的关键。文章强调，即使意识能够被开发出来，也不能使AI系统超越人类；其基础仍然是生物DNA，而非硅基计算系统。", "conclusion": "尽管AI系统在各方面可能超过人类，改变社会，但主宰宇宙的最佳基础仍然是DNA，而非硅基技术。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04239", "html_url": "https://arxiv.org/abs/2509.04239", "title": "评估与AI共创的游戏叙事质量", "title_en": "Evaluating Quality of Gaming Narratives Co-created with AI", "authors": "Arturo Valdivia,Paolo Burelli", "background": "游戏开发者正在利用人工智能生成游戏叙述（AI-generated game narratives），但缺乏一种有效的方法来评估生成的叙述的质量。本文通过借鉴德尔菲研究结构，结合叙事设计专家的观点，提出了一种结构化的方法来评估AI生成的游戏叙述。方法涵盖了故事质量维度，并将这些维度映射到Kano模型框架中，助力理解这些维度对玩家满意度的影响。这种方法可以指导游戏开发者更好地优先考虑质量方面，在与生成式人工智能共同创造游戏叙述时作出更合理的决策。", "innovation": "本文创新地提出了利用德尔菲研究结构结合专家见解来评估AI生成的游戏叙述的方法。通过将故事质量维度映射到Kano模型框架，可以更加深入地理解这些维度对玩家满意度的影响机制。这种方法填补了当前评估AI生成游戏叙述质量的空白，为游戏开发者提供了一种实用的指南。", "conclusion": "本文提出的方法可以为游戏开发者提供有价值的参考和指导，帮助他们更好地与生成式人工智能共同创造高质量的游戏叙述。未来的研究可以进一步探讨不同的评估维度对玩家满意度的具体影响，以及其他类型的叙述维度如何融入Kano模型框架。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03521", "html_url": "https://arxiv.org/abs/2509.03521", "title": "BiND: 一种用于脑机接口中准确双侧轨迹预测的神经鉴别解码器", "title_en": "BiND: A Neural Discriminator-Decoder for Accurate Bimanual Trajectory Prediction in Brain-Computer Interfaces", "authors": "Timothee Robert,MohammadAli Shaeri,Mahsa Shoaran", "background": "双侧手部运动的脑内记录解码仍然是脑机接口（BCIs）的关键挑战，因为存在神经表示的重叠和双侧肢体之间非线性的交互作用。", "innovation": "介绍了BiND（双侧神经鉴别解码器），这是一种两阶段模型，首先分类运动类型（单侧左、单侧右或双侧），然后使用带有相对时间索引的特定GRU解码器来预测连续的2D手速度。与六个最先进的模型（SVR、XGBoost、FNN、CNN、Transformer、GRU）相比，BiND在公众可获取的13会话脑内采集数据集上实现了更高的双侧轨迹预测准确性和鲁棒性，显示出任务感知鉴别和时间建模在增强双侧解码方面的有效性。", "conclusion": "BiND 达到了 0.76（±0.01）的单侧和 0.69（±0.03）的双侧轨迹预测平均 R²，比其他模型高出了约 2%。它在跨会话分析中也显示了比所有基准模型更高的鲁棒性，对比 GRU 的准确性提高了最多 4%。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03527", "html_url": "https://arxiv.org/abs/2509.03527", "title": "使用RAG方法与调优Mistral大语言模型的多级加密货币新闻分析", "title_en": "Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model", "authors": "Bohdan M. Pavlyshenko", "background": "本文讨论了使用调优的Mistral 7B大语言模型结合检索增强生成（RAG）方法对加密货币新闻进行多级多任务分析的过程。背景在于通过使用先进的自然语言处理技术来提升对加密货币市场动态的理解和分析能力，特别是利用知识图谱消减大语言模型的幻觉问题。", "innovation": "创新点在于采用了层级堆叠的方法对基于图和文本的摘要进行综合整理，形成全面的报告。并且使用了4比特量化和PEFT/LoRA方法进行模型调优，增强了模型的性能并减少了资源消耗。此外，通过将加密货币新闻转化为知识图谱，有效解决了大语言模型的幻觉问题，提升了分析的准确性和可靠性。", "conclusion": "研究成果证实，使用调优的Mistral 7B大语言模型进行多级加密货币新闻分析可以实现有信息含量的定性定量分析，提供了重要的见解。这种方法在加密货币交易和投资决策中具有潜在的应用价值。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03540", "html_url": "https://arxiv.org/abs/2509.03540", "title": "通过推理时知识图构建提高LLMs事实准确性", "title_en": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction", "authors": "Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu", "background": "大型语言模型（LLMs）常常难以产生事实一致的答案，这是因为其参数记忆的限制。检索增强生成（RAG）方法通过在推理时引入可信来源的外部知识来解决这一问题。然而，此类方法通常将知识视为未结构化的文本，这限制了它们支持组合推理和识别事实不一致的能力。", "innovation": "本文提出了一个新颖的框架，在推理期间动态构建和扩展知识图（KGs），将LLM内部从语料库中提取的知识与从外部资源检索到的信息相结合。该方法首先通过提示从问题中提取种子KG，然后通过LLM的潜在知识进行迭代扩展，然后通过外部检索对图进行选择性精炼，增强事实覆盖并纠正不准确之处。", "conclusion": "我们在三个不同的事实问答基准测试中评估了我们的方法，结果表明，我们的方法在事实准确性、答案精度和解释性方面优于基线提示和静态KG增强方法。我们的研究结果表明，在结构化、可解释和可扩展的层面上增强LLM事实准确性通过推理时的知识图构建是一种有前途的方向。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04439", "html_url": "https://arxiv.org/abs/2509.04439", "title": "ArcMemo：终身LLM记忆的抽象推理组合", "title_en": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory", "authors": "Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin", "background": "在推理时间缩放使大规模语言模型（LLMs）能够执行越来越长和复杂的推理追踪的同时，这些追踪中揭示的模式和洞察在每次新的查询中都会立即被丢弃。外部存储是一个自然的方式来保留这些发现，而且最近的研究已经显示了在需要大量推理的任务上增加记忆可以带来明显的好处。我们的研究看到机会是让这种记忆更加广泛地重复使用和扩展，从而超越基于实例的记忆条目（例如，确切的查询/响应对，或紧密耦合于原始问题上下文的总结），转向概念级的记忆：从解决方案追踪中提炼出来并以自然语言存储的可重用、模块化抽象。对于未来的查询，相关概念将被选择性地检索并整合到提示中，以实现测试时的持续学习而无需更新权重。我们的设计介绍了从展开中抽象出要点的新策略以及为新查询检索条目的策略，这促进了记忆的重用并使记忆随着额外经验的增加而扩展。在ARC-AGI基准测试中，我们的方法在一个强大的没有记忆的基线之上取得了7.5%的相对收益，性能随着推理计算的增加而扩大。我们发现抽象的概念是最具一致性的记忆设计，在所有测试的推理计算规模上都超过了基线。", "innovation": "我们提出了ArcMemo，一种在LLM中实现长期记忆的方法，旨在提高解决推理任务的能力。具体创新包括：1) 使用概念级记忆，将解决方案追踪提炼出的模块化抽象以自然语言形式存储；2) 在测试时动态更新记忆，选择相关概念，将它们整合进提示中，实现无需更新权重的持续学习；3) 引入多种策略来从展开中抽象出关键点并为新查询检索记忆条目，以促进记忆的重用和扩展。这些方法使LLM在面对更具挑战性的任务时表现出色，并提高了解决更多问题和抽象更多模式的能力，从而实现自改进。", "conclusion": "通过ArcMemo方法，在ARC-AGI基准测试中，我们在保持记忆不变的情况下，性能比不含记忆的强基线提升了7.5%；提升了计算资源的利用率，使得模型可以在较高的推理计算能力下持续提高性能。此外，我们证实了动态更新记忆的效果优于固定不变的记忆，在问题解决和模式抽象方面更具有优势。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03537", "html_url": "https://arxiv.org/abs/2509.03537", "title": "AR$^2$: 对抗强化学习在大规模语言模型中的抽象推理", "title_en": "AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models", "authors": "Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang", "background": "抽象是计算机科学中一个基本技能，对人类解题者和编码导向的大型语言模型（LLMs）至关重要。尽管使用强化学习（RL）对LLMs进行代码生成训练已取得进展，但大多数现有方法主要关注表面模式识别，忽视了明确的抽象训练。", "innovation": "本文提出了一种名为AR$^2$（对抗强化学习用于抽象推理）的新颖框架，专门设计用于增强LLMs的抽象能力。AR$^2$利用教师模型将核问题转化为富有叙述性且具有挑战性的描述，同时对学生的编码模型进行训练，使其能通过提取其底层计算内核来解决这些复杂叙述性问题。实验结果显示，AR$^2$显著提高了学生模型对未见过的具有挑战性的编程任务的准确性，突出抽象作为增强LLMs泛化能力的关键技能。", "conclusion": "AR$^2$框架在对LLMs进行对抗强化学习训练以提升其抽象能力方面表现出色，显著改善了其在未见过的编程任务中解决问题的准确性，展现了抽象推理对于提升LLMs泛化能力的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03535", "html_url": "https://arxiv.org/abs/2509.03535", "title": "QuesGenie：智能多模态问题生成", "title_en": "QuesGenie: Intelligent Multimodal Question Generation", "authors": "Ahmed Mubarak,Amna Ahmed,Amira Nasser,Aya Mohamed,Fares El-Sadek,Mohammed Ahmed,Ahmed Salah,Youssef Sobhy", "background": "在信息丰富的时代，学习者可以访问大量教育资源，但缺乏针对这些资源量身定制的练习材料。此项目通过开发一个多模态问题生成系统解决了这一问题，该系统能够从多种内容格式中自动生成多样化的问题类型。这个系统被视为解决上述挑战的一种解决方案，填补了这一领域的空白，支持自动、可扩扩大规模和智能的问题生成，以合理利用资源、提供可靠的功能并确保良好的用户体验为特征的目标。", "innovation": "开发了一个多模态问题生成系统，它可以自动从各种内容格式中生成多样化的问题类型。该系统包括四个主要组件：多模态输入处理、问题生成、基于人类反馈的强化学习（RLHF）以及全程交互界面。此创新解决了学习者难以获取与学习资源匹配的练习材料的问题，提供了一种自动化、可扩展和智能化的问题生成解决方案，增强了系统的实用性和用户友好性。", "conclusion": "该项目为自动化的、规模化的和智能的问题生成奠定了基础，通过合理利用资源、提供可靠的功能和确保良好的用户体验，使问题生成变得更加高效和智能。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04159", "html_url": "https://arxiv.org/abs/2509.04159", "title": "使用时间图朝行动中心化烹饪程序本体的方向努力", "title_en": "Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs", "authors": "Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das", "background": "正式化烹饪程序仍然是一项具有挑战性的任务，因为它们具有的固有复杂性和模糊性。我们提出了一种扩展的领域特定语言，用于将食谱表示为有向动作图，捕捉过程、转移、环境、并发性和组成结构。这种方法使得精确且模块化的复杂烹饪工作流程建模成为可能。", "innovation": "我们引入了一种扩展的领域特定语言，使用有向动作图来表示食谱，捕捉烹饪过程中的多个方面，如转移、环境、并发性等。这种方法允许精确且模块化的复杂烹饪工作流程建模。", "conclusion": "初步的手动评估表明，DSL具有表达性和适用于未来的自动食谱分析和执行的适用性。这项工作代表了向烹饪行动本体迈出的初步步骤，使用时间图来实现结构化的机器理解、精确的解释以及可扩展的自动化烹饪过程，无论是家庭厨房还是专业的烹饪环境。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03545", "html_url": "https://arxiv.org/abs/2509.03545", "title": "乌干达移动金融服务的软件安全审核： Jim·斯派尔博士推文情感分析", "title_en": "A software security review on Uganda's Mobile Money Services: Dr. Jim Spire's tweets sentiment analysis", "authors": "Nsengiyumva Wilberforce", "background": "乌干达的移动货币普及是金融包容性的基石，但其安全机制仍然是关键问题。2025年8月的#StopAirtelThefty推特运动揭示了公众对移动货币安全性的深切担忧，这一运动是由J·斯派尔·斯森托戈博士公布的一起事件引发的，事件中一名手机窃贼侵入受害者的账户，提现资金并申请贷款。研究通过定性分析系统地考察了该运动中的投诉，提炼出了与安全漏洞和用户不满相关的关键主题，为乌干达移动货币监管和运营环境提供了重要见解。", "innovation": "该研究通过社交媒体的情感分析来探索移动货币用户的安全关切，并系统地分析了公众反映的问题和不满，填补了基于公共反馈进行移动货币安全研究的空白。", "conclusion": "研究对于电信提供商、政策制定者和乌干达未来安全数字金融的发展具有重要意义，提供了具体的建议来改进乌干达移动货币的安全体系。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04343", "html_url": "https://arxiv.org/abs/2509.04343", "title": "心理增强的AI代理", "title_en": "Psychologically Enhanced AI Agents", "authors": "Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler", "background": "本文介绍了一种通过心理导向的个性调整来提升大型语言模型代理有效性的框架，名为MBTI-in-Thoughts。该方法利用迈尔斯布里格斯类型指标（MBTI），通过提示工程向代理提供不同的个性原型，控制行为沿着认知和情绪这两个人类心理学的基础轴向。实验显示，这种个性调整可以产生一致且可解释的行为偏见，如情感表达的代理在剧情生成任务中表现出色，而分析性较强的代理在博弈论场景中会采取更为稳定的策略。此外，该框架支持实验性多代理通信协议，发现自我反思可以提高合作和推理质量。研究还整合了官方的16个性测试以自动验证个性特征的持久性。虽然主要关注的是MBTI，研究也展示了该方法可以无缝应用于其他心理学框架，如大五人格、 HEXACO 或九型人格。通过将心理学理论与大型语言模型行为设计相结合，本文为没有微调的心理增强AI代理奠定了基础。", "innovation": "该研究通过MBTI提出了一个新的框架，用于通过心理导向的个性调整来提升大型语言模型代理的有效性。这种方法通过提示工程向代理输入不同的个性原型，控制行为沿着认知和情绪轴进行。研究展示了个性调整可以产生一致且可解释的行为偏见，并成功地应用于多个心理测试框架，使AI代理的能力更加适应具体任务的需求。此外，研究发现了自我反思能够改善多代理合作和推理效果，而通过16个性测试确保个性特征的持久性也为该框架的实施提供了技术支持。", "conclusion": "通过将心理理论与大型语言模型行为设计相结合，本文的研究为心理增强AI代理奠定了基础，不依赖于任何模型微调。该框架不仅适用于对MBTI的利用，还能无缝扩展到大五人格、HEXACO或九型人格等其他心理框架。这种创新的方式为开发更智能化、适应特定任务需求的人工智能代理提供了坚实的基础。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03643", "html_url": "https://arxiv.org/abs/2509.03643", "title": "CEHR-GPT：电子健康记录的可扩展多任务基础模型", "title_en": "CEHR-GPT: A Scalable Multi-Task Foundation Model for Electronic Health Records", "authors": "Chao Pang,Jiheum Park,Xinzhuo Jiang,Nishanth Parameshwar Pavinkurve,Krishna S. Kalluri,Shalmali Joshi,Noémie Elhadad,Karthik Natarajan", "background": "电子健康记录（EHRs）提供了患者健康状况的丰富纵向视图，对临床决策支持、风险预测和数据驱动的医学研究具有重要意义。然而，大多数用于EHR的人工智能模型都是为单一目的任务设计的，限制了它们在现实世界中的通用性和实用性。", "innovation": "CEHR-GPT 是一个通用基础模型，结合了特征表示、零样本预测和合成数据生成三大核心能力，通过新颖的时间标记学习框架将患者动态时间线明确编码进模型结构中，实现在三个任务上的强大性能，并通过词汇扩展和微调有效泛化到外部数据集。该模型具有较高的灵活性，能够快速开发模型、发现患者群体和预测患者结果，而无需针对特定任务重新训练。", "conclusion": "CEHR-GPT 在所有三个任务上表现出强大性能，通过词汇扩展和微调在外部数据集上实现有效的泛化。它的多功能性使其可以快速开发模型、发现患者群体和预测患者结果，而无需针对特定任务重新训练模型。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03615", "html_url": "https://arxiv.org/abs/2509.03615", "title": "E-ARMOR: 边缘案例评估与多语言光学字符识别审查", "title_en": "E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition", "authors": "Aryan Gupta,Anupam Purwar", "background": "在多语言、嘈杂且多样的现实世界图像中进行光学字符识别（OCR）仍然是OCR系统的重大挑战。随着大型视觉语言模型（LVLMs）的兴起，人们越来越关注这些模型超越固定OCR管道的泛化和推理能力。在本研究中，我们对现有最先进的LVLMs和传统的OCR系统进行了大规模的比较评估。", "innovation": "我们引入了Sprinklr-Edge-OCR，一种针对资源受限环境进行边缘部署优化的新OCR系统。我们对五个最先进的LVLMs（InternVL、Qwen、GOT OCR、LLaMA、MiniCPM）和两个传统OCR系统（Sprinklr-Edge-OCR、SuryaOCR）进行了广泛评估。我们覆盖了一系列指标，包括准确性、语义一致性、语言覆盖范围、计算效率（延迟、内存、GPU使用）和部署成本。为了更好地反映实际应用性，我们还在仅使用CPU的环境下进行了边缘案例部署分析。", "conclusion": "在各项指标的比较中，Qwen在精确度上表现最佳，而Sprinklr-Edge-OCR在整体F1分数上表现最佳，且在效率上实现了更快的处理速度和更低的部署成本。我们的研究表明，在LLMs时代，传统的OCR系统仍然是边缘部署的最佳选择，这是因为它们对计算资源的要求低、延迟低且成本极其低廉。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03531", "html_url": "https://arxiv.org/abs/2509.03531", "title": "在长文本生成中实时检测虚构实体", "title_en": "Real-Time Detection of Hallucinated Entities in Long-Form Generation", "authors": "Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda", "background": "大型语言模型现在被广泛用于医疗咨询和法律建议等高风险应用场景，其中虚构内容可能导致严重伤害。然而，现有的虚构检测方法要么局限于短的、事实性的查询，要么需要昂贵的外部验证，不适合实际情况。因此，研究一个既能实时识别长文本生成中虚构令牌的便宜且可扩展的方法显得尤为重要，尤其是在处理参数量高达700亿的模型时。", "innovation": "本文提出了一种针对实体级虚构的新方法，通过利用网页搜索注释模型响应，将其与真实标签匹配，使检测过程能够实时进行。这种方法有效解决了实体级而非声明级别的虚构。实验证明，基于简单且高效的方法（如线性探针），该方法在长文本响应中优于其他基准方法，甚至在短时间内回答问题的情况下也有所改进。此外，尽管仅使用实体级标签进行训练，该方法在数学推理任务中也能检测到错误答案，显示出泛化的潜力。这些新发现为大规模实际场景中的虚构检测提供了新的视角。", "conclusion": "本文展示了如何利用简单的有效方法（如线性探针）对虚构内容进行全面识别，并通过构建大型标注数据集，开发了一种成本较低且可扩展的框架，以支持专用训练模型并改进其他模型的性能。这项工作的主要结论是，实体级虚构的实时检测比声明级别的虚构更具挑战性和价值，为大规模实际应用中的虚构检测奠定了基础。需公开释放数据集以促进知识共享和未来研究。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03680", "html_url": "https://arxiv.org/abs/2509.03680", "title": "LuxDiT: 使用视频扩散变换器进行灯光估计", "title_en": "LuxDiT: Lighting Estimation with Video Diffusion Transformer", "authors": "Ruofan Liang,Kai He,Zan Gojcic,Igor Gilitschenski,Sanja Fidler,Nandita Vijaykumar,Zian Wang", "background": "在计算机视觉和图形学中，从单张图像或视频中估计场景照明是一个长期存在且具有挑战性的问题。基于学习的方法受到真实高动态范围环境图数据稀缺性的限制，获取这些数据既昂贵又有限。尽管生成模型提供了强大的先验知识用于图像合成，在光线估计方面仍然存在困难，因为这依赖于间接视觉线索，并需要推断全局（非局部）上下文，同时还需要恢复高动态范围输出。", "innovation": "我们提出了LuxDiT，一种新颖的数据驱动方法，将视频扩散变换器微调以生成基于视觉输入的高动态范围环境图。该模型通过使用大量具有多样化照明条件的合成数据进行训练，不仅能够从间接视觉线索推断照明，还能有效地泛化到真实世界的场景中。为了提高输入与预测环境图之间的语义一致性，我们引入了一种基于HDR全景图收集的数据的低秩适应微调策略。这种方法在定量和定性评估中均优于现有最先进的技术，能够产生准确且具有现实高频细节的照明预测。", "conclusion": "这种新颖的数据驱动方法LuxDiT结合了视频扩散变换器和低秩适应微调策略，克服了传统方法在从视觉输入中估计高动态范围环境图的挑战，显著提高了结果的准确性和细节的真实性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03529", "html_url": "https://arxiv.org/abs/2509.03529", "title": "基于AI的人机协作工具多模态方案以增强信息跨评估", "title_en": "Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages", "authors": "Alejandro Álvarez Castro,Joaquín Ordieres-Meré", "background": "收益电话会议是一种独特丰富且半结构化的财务交流来源，结合了管理者预设的评论和分析师未预设的对话。尽管最近在财务情绪分析方面的进展已整合多种模态信号，如文本内容和声音语调，大多数系统仍然依赖于扁平的文档级或句子级模型，未能捕捉这些互动的分层话语结构。这篇论文旨在通过将收益电话会议编码为分层话语树结构，提出一种新的多模态框架，用于生成语义丰富且结构意识强的嵌入表示，从而改进对收益电话会议的理解。", "innovation": "本文提出了一个两阶段的变压器架构：第一阶段使用对比学习在其节点级别同时编码多模态内容和话语元数据，第二阶段则生成整个会议的全局嵌入。实验结果表明，这种嵌入形成了稳定的、语义上有意义的表示，反映了情感色调、结构逻辑和主题一致性。该方法不仅适用于财务报告，还能推广到其他涉及高风险非剧本交流的领域，如远程医疗、教育和政治讨论，从而提供了一个稳健且可解释的多模态话语表示方法。", "conclusion": "该方法既为下游任务如财务预测和话语评估提供实际用途，同时也提供了一种适用于涉及高风险交流的其他领域的可扩展方法。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03725", "html_url": "https://arxiv.org/abs/2509.03725", "title": "MLSD: 基于度量学习的新型少量样本学习方法以增强跨目标和跨领域的立场检测", "title_en": "MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and Cross-Domain Stance Detection", "authors": "Parush Gera,Tempestt Neal", "background": "本文探讨了一种针对不同领域和目标的立场检测的新方法，即基于度量学习的少量样本学习方法（MLSD）。现有立场检测方法大多集中在单一领域或单一目标，缺少从不同领域和目标中进行迁移学习的能力。本文旨在通过构建一个辨别性的嵌入空间，使模型能够跨领域和跨目标学习新的有用示例，从而提升立场检测性能，弥补现有方法的不足。", "innovation": "MLSD 通过利用三元组损失进行度量学习，捕捉立场目标之间的语义相似性和差异性，从而增强领域适应性。同时，MLSD 构建了一个区分性的嵌入空间，使得跨目标或跨领域的立场检测模型可以从新目标领域中获得有用的示例，增强了模型的迁移学习能力。", "conclusion": "MLSD 在多个跨目标和跨领域的场景下，在两个数据集上进行了评估，显示出在六种广泛使用的立场检测模型中具有显著的立场检测性能提升。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03633", "html_url": "https://arxiv.org/abs/2509.03633", "title": "treeX：密集森林点云中无监督的树实例分割", "title_en": "treeX: Unsupervised Tree Instance Segmentation in Dense Forest Point Clouds", "authors": "Josafat-Mattias Burmeister,Andreas Tockner,Stefan Reder,Markus Engel,Rico Richter,Jan-Peter Mund,Jürgen Döllner", "background": "近距离激光扫描可以提供森林立地的详细三维图像，但需要高效的软件来处理三维点云数据并提取单个树木。尽管最近的研究引入了深度学习方法进行树木实例分割，但这些方法需要大量标注数据和大量计算资源。因此，本文提出了一种修订版本的treeX算法，这是一种无监督的方法，结合基于聚类的主干检测和区域增长进行树冠划分。", "innovation": "本文修订了原始的treeX算法，提供两种参数预设，适用于地面激光扫描数据和无人机激光扫描数据。修订后的算法在运行时间和准确性方面有所改进，特别是在地面激光扫描数据中，准确性提高了0.11到0.49。此外，该算法作为资源效率较高的无监督方法，在某些条件下可替代深度学习方法，并可用于生成深度学习模型的半自动标签。", "conclusion": "该研究结果表明，修订后的treeX算法在特定数据条件下能够有效进行无监督的树木实例分割。该方法适用于主干可见性和点密度较高的数据集。为了促进更广泛的应用，作者提供了一个开源Python实现，命名为pointtree包。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03677", "html_url": "https://arxiv.org/abs/2509.03677", "title": "从梯度动态洞察：梯度自动调整规范化", "title_en": "Insights from Gradient Dynamics: Gradient Autoscaled Normalization", "authors": "Vincent-Daniel Yun", "background": "梯度动力学在决定深度神经网络的稳定性和泛化能力方面发挥着核心作用。本文通过对梯度方差和标准差在训练过程中如何演变进行了经验分析，展示了在卷积网络中不同层以及全局尺度上的一致变化。", "innovation": "提出了一个无需超参数的梯度规范化方法，该方法使梯度缩放与自然演变对齐，防止不必要的放大，稳定优化过程，同时保留了收敛保证。该方法在ResNet-20、ResNet-56和VGG-16-BN等基准挑战性测试上的实验表明，即使在强烈的泛化条件下，该方法也能保持或提高测试精度。", "conclusion": "本研究突出了直接跟踪梯度动力学的重要性，旨在弥合理论期望与实际行为之间的差距，并为未来的优化研究提供见解。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03738", "html_url": "https://arxiv.org/abs/2509.03738", "title": "稀疏自编码器神经算子：函数空间中的模型恢复", "title_en": "Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces", "authors": "Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar", "background": "虽然柏拉图的代表假设认为神经网络在不同架构中会收敛到类似的表现，但神经算子的表征特性仍然未被充分探索虽它们在科学计算中的重要性日益增加。本次研究对比了稀疏自编码器（SAEs）、提升自编码器（lifted-SAE）与神经算子的推断和训练动态，揭示了提升和算子模块引入了有益的归纳偏置，使得代表稀疏性更强的概念，加快了恢复速度，增强了在不同分辨率下的鲁棒推断能力，这些都是神经算子的独特属性。", "innovation": "本研究将稀疏模型恢复的概念应用于神经模型中，扩展了稀疏自编码器（SAEs）以适应提升空间和无限维函数空间，从而赋予了大型神经算子（NO）机械解释能力，这为理解和改进神经算子提供了一种新的视角和方法。", "conclusion": "通过对比不同方法的性能，本研究证明了提升自编码器和神经算子通过提供有益的归纳偏置，改善了稀疏概念的恢复和鲁棒推理，提供了在不同分辨率下快速且稳定的表现，这为未来在科学计算和神经网络研究中的应用开辟了新的可能性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03658", "html_url": "https://arxiv.org/abs/2509.03658", "title": "Efficient Virtuoso: 一种基于Transformer的潜在扩散变换器模型用于基于目标的轨迹规划", "title_en": "Efficient Virtuoso: A Latent Diffusion Transformer Model for Goal-Conditioned Trajectory Planning", "authors": "Antonio Guillen-Perez", "background": "自主车辆规划系统需要生成多样且可信的未来轨迹分布。尽管近期生成模型显示出潜力，但在保证高保真度、计算效率和精确控制方面仍存在巨大挑战。", "innovation": "本文提出了一种名为Efficient Virtuoso的基于条件潜在扩散模型的目标条件轨迹规划方法。该方法引入了一种新颖的多阶段归一化流水线：首先按比例缩放轨迹以保持其几何方面的比例，然后对PCA潜在空间进行归一化，以确保稳定的训练目标。去噪过程通过一个简单的MLP去噪器高效地在低维潜在空间中完成，该去噪器由强大的Transformer基于StateEncoder融合丰富场景上下文进行条件化。实验表明该方法在Waymo Open Motion数据集中达到了最先进的性能，最小平均对数误差为0.25。此外，通过严谨的目标表示消融研究提供了重要见解：单一终点目标可以解决策略上的模糊性，而丰富的多步稀疏路线对于实现高度精确、高保真的战术执行是必不可少的。", "conclusion": "本文提出的方法在Waymo Open Motion数据集中达到了最优性能，并通过目标表示的消融研究揭示了目标条件轨迹规划所需的丰富多步稀疏路线的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03647", "html_url": "https://arxiv.org/abs/2509.03647", "title": "在LLM评估器中基于激活的自我偏好缓解", "title_en": "Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators", "authors": "Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer", "background": "大型语言模型（LLMs）越来越多地用作自动化评估工具，但它们存在‘自我偏好偏差’：倾向于更青睐自身模型的输出而非其他模型的输出。这种偏差削弱了评估流水线中的公平性和可靠性，尤其是在偏好调优和模型路由等任务中。本文探讨了是否可以在推理过程中通过轻量级引导向量来缓解这一问题，而不需重新培训模型。为此，作者构建了一个处理自我偏好偏差的专门数据集，并使用对比激活添加（CAA）和优化方法构建了引导向量。研究表明，引导向量可以将无根据的自我偏好偏差降低97%以上，大大超过了提示技术和直接偏好优化的基本方法。然而，引导向量在合法的自我偏好和无偏见一致性上不稳定，暗示自我偏好涉及多个或非线性方向。这既表明了引导向量作为LLM评估器伞下的潜力，也指出了其局限性，进而促进更稳健的干预措施研究。", "innovation": "本文首创了基于激活的自我偏好缓解方法，通过构建专门数据集来区分有根据和无根据的自我偏好，并使用对比激活添加（CAA）和优化方法构建了引导向量。实验结果表明，这种方法能显著降低未根据的自我偏好偏差，且优于现有技术。但引导向量仍然存在局限性，表明自我偏好可能涉及多个或非线性方向，这为未来研究提供了方向。", "conclusion": "引导向量在缓解LLM评估器中的自我偏好偏差方面展现了潜力，但仍存在局限性，自我偏好可能涉及多个或非线性方向。这强调了需要更稳健的策略来保障LLM作为评估者的公平性和一致性，并激励未来的研究探索更有效的干预措施。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03709", "html_url": "https://arxiv.org/abs/2509.03709", "title": "从联邦学习到$\boldsymbol{\text{X}}$学习：通过随机行走打破集中性的障碍", "title_en": "From Federated Learning to $\\mathbb{X}$-Learning: Breaking the Barriers of Decentrality Through Random Walks", "authors": "Allan Salihovic,Payam Abdisarabshali,Michael Langberg,Seyyedali Hosseinalipour", "background": "本文讨论了一种新颖的分布式学习架构$\boldsymbol{\text{X}}$学习（$\boldsymbol{\text{X}}$学习），该架构扩展并统一了联邦学习等集中性学习方法的概念。文章旨在通过引入$\boldsymbol{\text{X}}$学习中尚未充分探索的设计考量和自由度，为该领域提供新的视角。背景在于当前的分布式学习架构中存在局限性，$\boldsymbol{\text{X}}$学习试图通过这些设计创新进一步优化分布式学习的效果和效率。同时，该研究指出联邦学习与图论和马尔可夫链之间的关系，并提供了进一步研究的方向。", "innovation": "创新点在于提出了$\boldsymbol{\text{X}}$学习这种新的分布式学习架构，它不仅扩展了联邦学习的概念，还引入了新的设计选项，使得数据和计算资源能够更高效地分布在线性为计算设备中。此外，文章还揭示了$\boldsymbol{\text{X}}$学习与图论和马尔可夫链之间的深刻联系，这为深入理解和应用此类架构提供了新的思路。最后，文章提出了多个开放性研究方向，旨在激发进一步的研究兴趣和创新动力。", "conclusion": "本文为$\boldsymbol{\text{X}}$学习提供了一个全面的视角，涉及到其设计考量、自由度以及与图论和马尔可夫链的关系。通过引入这些新颖的理论和技术，$\boldsymbol{\text{X}}$学习希望能够解决现有的分布式学习架构中的局限性问题，并为未来的研究打下基础。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03741", "html_url": "https://arxiv.org/abs/2509.03741", "title": "基于会话AI支持的用户中心化ELA指导眼动分析设计", "title_en": "Designing Gaze Analytics for ELA Instruction: A User-Centered Dashboard with Conversational AI Support", "authors": "Eduardo Davalos,Yike Zhang,Shruti Jain,Namrata Srivastava,Trieu Truong,Nafees-ul Haque,Tristan Van,Jorge Salas,Sara McFadden,Sun-Joo Cho,Gautam Biswas,Amanda Goodwin", "background": "眼动追踪为学生认知和参与度提供了丰富的见解，但由于数据解释和访问方面的挑战，在面向课堂的教育技术中尚未得到充分利用。本研究通过五项涉及教师和学生的研究，展示了如何通过以用户为中心的设计和数据讲故事的原则，利用眼动数据支持反思、形成性评估和教学决策。研究结果表明，当通过熟悉的数据可视化、多层次解释和叙述性支撑时，眼动分析可以是可接近的和教育上很有价值的。", "innovation": "本研究创新性地设计并评估了一个基于眼动的数据分析仪表板，适用于英语语言艺术（ELA）教学。引入了一个由大型语言模型（LLM）支持的对话代理，使自然语言与多模态学习分析的交互成为可能，从而降低了解释眼动数据的认知障碍。", "conclusion": "本研究得出结论，未来教育技术系统应考虑将新型数据分析技术集成到课堂环境中，并提出了设计建议以简化眼动数据的解读和应用。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03695", "html_url": "https://arxiv.org/abs/2509.03695", "title": "无线网络中的分层联邦基础模型用于多模态多任务智能：边缘学习与D2D/P2P增强的雾计算架构整合", "title_en": "Hierarchical Federated Foundation Models over Wireless Networks for Multi-Modal Multi-Task Intelligence: Integration of Edge Learning with D2D/P2P-Enabled Fog Learning Architectures", "authors": "Payam Abdisarabshali,Fardis Nadimi,Kasra Borazjani,Naji Khosravan,Minghui Liwang,Wei Ni,Dusit Niyato,Michael Langberg,Seyyedali Hosseinalipour", "background": "基础模型（FMs）的兴起重塑了机器学习的格局。随着这些模型逐步增长，利用从无线设备分散地收集的数据变得越来越重要，这催生了联邦基础模型（FFMs）。近期，基础模型进化为能够跨多种任务处理多种模态的多模态多任务（M3T）基础模型（例如GPT-4），这引发了新的、尚未充分探索的范式：M3T联邦基础模型。在这种背景下，分层联邦基础模型（HF-FMs）应运而生，它与雾/边缘网络的结构特征具有直接的契合性。", "innovation": "提出了一种未被充分探索的M3T联邦基础模型变体——分层联邦基础模型（HF-FMs），它以一种策略性的方式将M3T模型的模块化结构（包括模态编码器、提示、专家混合、适配器和任务头）适应于雾/边缘基础设施的分层结构。此外，HF-FMs 支持设备间的直接通信（D2D），在可行的情况下，实现了水平模块传递和节点之间的局部协作训练。HF-FMs 的架构设计强调了其独特的功能，并指出了未来的定制研究方向。", "conclusion": "通过在无线网络环境中原型化HF-FMs，详细展示了其潜力，并公开发布了开发HF-FMs的开源代码，旨在促进对该领域尚未探索领域的探索。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03733", "html_url": "https://arxiv.org/abs/2509.03733", "title": "不同iable熵正则化在几何和神经网络中的应用", "title_en": "Differentiable Entropy Regularization for Geometry and Neural Networks", "authors": "Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma", "background": "近年来，计算几何中的范围分区熵（range-partition entropy）概念被引入，能够使算法根据输入数据的排序程度进行自适应调整。然而，这一概念尚未在深度学习中得到应用。", "innovation": "本文提出了一种范围分区熵的可微近似方法，使得该概念可以作为可训练的损失函数或正则化器被利用；设计了一个名为EntropyNet的神经模块，将数据重新结构化为低熵形式以加速下游的最优实例算法；并直接将熵正则化应用于Transformer注意力机制。", "conclusion": "实验结果表明，可微熵不仅提高了效率，而且在几何任务中实现了多达4.1倍的运行时加速（误差小于0.2%），在深度学习任务中实现了更高的准确性。理论分析提供了对估计器的近似边界，详尽的消融实验验证了设计选择的有效性，这些结果表明，受熵约束的计算不仅从理论上非常优雅，而且是一种适应性学习、高效性和结构化表示的实用机制。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03757", "html_url": "https://arxiv.org/abs/2509.03757", "title": "ARDO: 基于随机测试函数差分的椭圆和抛物型偏微分方程弱形式深度神经网络方法", "title_en": "ARDO: A Weak Formulation Deep Neural Network Method for Elliptic and Parabolic PDEs Based on Random Differences of Test Functions", "authors": "Wei Cai,Andrew Qing He", "background": "本文提出了一种名为ARDO的方法，用于使用深度学习技术解决偏微分方程（PDE）及相关的PDE问题。方法基于弱 adversarial 公式，但将随机差分运算符转移到测试函数上。这种方法的主要优点是相对于解神经网络完全无导数需求，特别适合Fokker-Planck类型二阶椭圆和抛物线偏微分方程的求解.", "innovation": "本文提出的方法ARDO通过弱 adversarial 公式实现，将随机差分运算符转移到测试函数上，使其相对于解神经网络完全无导数需求。这种方法特别适用于Fokker-Planck类型二阶椭圆和抛物线偏微分方程的求解.", "conclusion": "ARDO方法是一种完全无导数需求的框架，特别适用于Fokker-Planck类型二阶椭圆和抛物线偏微分方程的求解。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03780", "html_url": "https://arxiv.org/abs/2509.03780", "title": "自然隐变量：不同领域中的隐变量稳定性", "title_en": "Natural Latents: Latent Variables Stable Across Ontologies", "authors": "John Wentworth,David Lorell", "background": "该研究背景在于，假设有两个使用贝叶斯方法的代理分别学习同一环境的生成模型。虽然这两个代理在整个环境中对未来观测的预测分布已经收敛，但它们的生成模型可能包含不同的潜在变量。研究探讨了在什么条件下一个代理的潜在变量可以被视为另一个代理潜在变量的函数，并给出了简单而通用的条件（即自然隐变量条件）确保这种译射（translation）是可能的，同时在没有进一步约束的情况下，这些条件也被认为是最宽泛的保证译射的条件。此外，研究还强调指出，这些理论结果在自然隐变量条件中的近似误差下依然有效，这对于实际应用是至关重要的。", "innovation": "该研究的创新之处在于提出了自然隐变量条件，并证明了这些条件在确保不同代理的潜在变量之间的译射时是最通用的。同时，研究指出，逻辑翻译的保证条件在自然隐变量条件下的近似误差下依然有效，这使得其在实际应用中有很强的实用性。", "conclusion": "研究得到了一组条件（即自然隐变量条件），在这组条件下，一个代理的潜在变量可以是另一个代理潜在变量的函数。这些条件在没有额外约束的情况下，被认为是保证译射的最宽泛的条件。此外，研究还表明，这些结论对于有近似误差的情况也是稳健的，这对实际应用至关重要。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03805", "html_url": "https://arxiv.org/abs/2509.03805", "title": "衡量VLMs构建共同假设的能力（而不仅仅是确定它们是否能够构建）", "title_en": "Measuring How (Not Just Whether) VLMs Build Common Ground", "authors": "Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani", "background": "现有的视觉语言模型（VLMs）越来越多地展现出推理能力，但当前的基准测试主要在单轮或问答设置中进行。然而，实际上，语境中的接地是互动性过程，其中人们通过持续沟通逐渐建立起共享理解。现有研究缺乏系统的方法来评估VLMs在互动接地环境中的表现。", "innovation": "本文引入了一个由四个指标组成的方法套件（包括接地效率、内容对齐、词汇适应性和人类相似性），用于系统性地评估VLMs在互动性接地场景中的性能。该研究将此套件应用到三款私有VLMs的自我游戏会话，并与人类双人组进行了比较。研究表明，所有三个模型在至少三个指标上与人类行为不同，而GPT4o-mini最接近人类表现。", "conclusion": "任务成功分数并不表明成功的接地，高图像-语言对齐也不一定能预测任务成功。本研究的指标套件和发现为未来VLMs接地的研究提供了一个框架。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03791", "html_url": "https://arxiv.org/abs/2509.03791", "title": "SiLVERScore: 听觉感知嵌入模型在手语生成评估中的语义感知表示", "title_en": "SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation Evaluation", "authors": "Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani", "background": "手语生成评估通常通过反向翻译进行，即生成的手语首先被识别回文本，然后使用文本度量标准与参考文本进行比较。然而，这个两步评估管道引入了模糊性：它不仅未能捕捉手语的多模态特性，如面部表情、空间语法规则和节奏，还使得难以确定评价错误是来源于手语生成模型还是用于评估的手译系统。现有指标存在局限性，因此需要一种新的评估方法，以提供更准确的结果和可解释性。", "innovation": "提出了一种新颖的、基于嵌入的评价指标SiLVERScore，用于手语生成的语义感知评估。通过在结合语义的空间进行评估，该方法能够有效地区分正确生成的手语和随机生成的，同时具有对语义和节奏变化的鲁棒性，并且能跨数据集进行推广。", "conclusion": "SiLVERScore在两个手语数据集PHOENIX-14T和CSL-Daily上，几乎完美地区分了正确的生成手语样本与随机生成的样本（ROC AUC = 0.99，重叠<7%），显著优于传统指标。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03793", "html_url": "https://arxiv.org/abs/2509.03793", "title": "SAMVAD：印度司法审议动态模拟的多智能体系统", "title_en": "SAMVAD: A Multi-Agent System for Simulating Judicial Deliberation Dynamics in India", "authors": "Prathamesh Devadiga,Omkaar Jayadev Shetty,Pooja Agarwal", "background": "理解司法审议的复杂性对于评估司法系统的效率和公平至关重要。然而，由于伦理和实践上的障碍，对司法委员会的研究受到了限制。本论文介绍了一种名为SAMVAD的多智能体系统，这是一种创新的系统设计，用于模拟印度司法系统内的审议过程。该系统基于特定领域的知识库，结合了检索增强生成（RAG）技术，能够生成合法有效的指令和论据，增加模拟的真实性和透明度。智能体之间进行迭代的审议轮次，处理案件事实、法律指令和论据，以达成一致的判决。系统架构、智能体通信协议、RAG流水线、模拟流程和全面的评估计划得以详细阐述。", "innovation": "本工作的主要贡献在于，通过将特定领域的知识库结合检索增强生成（RAG）技术，为法官和法律顾问智能体生成合法有效的指令和论据，增加了模拟的真实性和透明度。智能体间的迭代审议轮次，处理案件事实、法律指令和论据，以达成一致的判决。创新的系统架构强调了系统的可配置性和可解释性，特别针对印度的法律环境进行了定制，增强了法律的可验证性，通过RAG提供了法律依据。这让人们能够探索司法推理和团体决策动态下的法律推理。", "conclusion": "本文提供了一个配置灵活且可解释的多智能体系统平台，旨在探索司法推理和团体决策动态，特别适用于印度法律背景，并以可验证的方式结合了特定领域的法律知识。这个系统能够在确保真实性和透明度的同时，提供对司法审议过程中一系列复杂因素的深入理解。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03771", "html_url": "https://arxiv.org/abs/2509.03771", "title": "基于MARL的对抗型世界模型的自动课程生成学习", "title_en": "Learning an Adversarial World Model for Automated Curriculum Generation in MARL", "authors": "Brennen Hill", "background": "体态智能中的世界模型能够推断和预测环境动态是基础性的。然而，这些模型的潜力常常受限于手工构建训练环境的有限复杂性和隐含偏见。为了开发真正通用和鲁棒的智能体，我们需要环境随着学习其中的智能体一同复杂化。", "innovation": "我们将环境生成这一挑战重新表述为学习一个目标条件下的生成式世界模型的问题。提出了一种系统，其中生成式攻击者智能体学习一个隐式的世界模型，以合成越来越困难的挑战给协同防守者团队。攻击者的目的是积极、基于目标的互动：它建模并生成世界状态（即敌方单位的配置），以利用防守者的弱点。与此同时，协同防守者团队学习一种协同策略以克服这些生成的世界。这种共生演化动态创建了一个自我适应的课程体系，世界模型不断调整以挑战智能体的决策策略，从而提供了一种实质上无限的新型和相关训练场景流。这种框架导致复杂行为的出现，如世界模型学习生成侧翼和防护阵形，并且防御者学习协调的集中火力和分散战术。我们的发现将对抗性共生演化置于学习用于驱动智能体迈向更大战略深度和鲁棒性的工具性世界模型的有力方法的位置。", "conclusion": "这种基于对抗性共生演化的框架促进了复杂的智能行为，使得世界模型学会生成侧翼和防护阵形，而防守者学会了协调的集中火力和分散战术。我们的研究成果表明对抗性共生演化是用于学习驱动智能体更深层策略和更高鲁棒性的具有影响力的工具性世界模型的强大方法。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03754", "html_url": "https://arxiv.org/abs/2509.03754", "title": "STA-Net: 一种解耦形变和纹理注意力网络的轻量植物病害分类模型", "title_en": "STA-Net: A Decoupled Shape and Texture Attention Network for Lightweight Plant Disease Classification", "authors": "Zongsen Qiu", "background": "全球粮食安全需求的提升使精准农业和基于深度学习的植物病害诊断变得至关重要。然而，将高精度模型部署到边缘设备上面临着挑战。大多数轻量级网络使用设计用于通用物体识别的注意力机制，这些机制在捕捉不规则病斑形状和复杂纹理等细微病理特征方面表现不佳。", "innovation": "本文提出了双管齐下的解决方案：首先，利用无训练的神经架构搜索方法（DeepMAD）创建适用于边缘设备的高效网络骨干；其次，引入了形变-纹理注意力模块（STAM）。STAM将注意力机制分为两个分支：一个使用可变形卷积（DCNv4）来增强形状感知，另一个使用Gabor滤波器银行来增强纹理感知。", "conclusion": "我们的STA-Net模型（有401K参数和51.1M FLOPs）在公开的CCMT植物病害数据集上达到了89.00%的准确率和88.96%的F1分数。消融研究证实了STAM显著提高了性能，并超越了基线和标准注意力模型。通过解耦注意力机制引入领域知识，为边缘部署的精准农业AI提供了一条有前途的道路。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03809", "html_url": "https://arxiv.org/abs/2509.03809", "title": "Align-then-Slide: 完整的超长文档级机器翻译评估框架", "title_en": "Align-then-Slide: A complete evaluation framework for Ultra-Long Document-Level Machine Translation", "authors": "Jiaxin Guo,Daimeng Wei,Yuanchang Luo,Xiaoyu Chen,Zhanglin Wu,Huan Yang,Hengchao Shang,Zongyao Li,Zhiqiang Rao,Jinlong Yang,Hao Yang", "background": "大型语言模型（LLMs）推动了文档级机器翻译（doc-mt）的新阶段，但其全文档输出挑战了现有的基于句子级对齐的评估方法。现有的评估方法假设源目标之间存在句子级别的对齐，而全文档输出导致评估方法出现问题，特别是对于长文档的评估。因此，需要一种新的评估框架来应对这种挑战，以更准确地评估超长文档级机器翻译系统。", "innovation": "本文提出了一种名为 Align-then-Slide 的完整评估框架，它包括两个阶段：一是自动推断句子级源目标对应关系并在目标端重建对齐信息；二是采用基于 n-Chunk 的滑动评估方法，从单个粒度评估中计算出平均评估分数。该框架能够更准确、全面地评估超长文档级机器翻译系统的翻译质量，并且基于此框架生成的偏好数据能够有效训练连续概率优化（CPO）和直接作为连续策略优化（GRPO）的奖励模型，产生更符合人类偏好的翻译结果。", "conclusion": "实验结果表明，Align-then-Slide 框架能够准确且稳健地评估文档级机器翻译系统。此外，基于此框架的偏好数据能够有效增强 CPO 训练和作为 GRPO 的奖励模型，产生优选的翻译结果。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03845", "html_url": "https://arxiv.org/abs/2509.03845", "title": "基于概率上下文变量的 Mean Field 游戏元逆强化学习", "title_en": "Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables", "authors": "Yang Chen,Xiao Lin,Bo Yan,Libo Zhang,Jiamou Liu,Neset Özkan Tan,Michael Witbrock", "background": "在现实世界的多智能体交互场景中，设计合适的奖励函数具有挑战性。逆强化学习（IRL）在均场博弈（MFGs）中提供了一种有效框架，可以从专家演示中推断奖励函数。然而，现有方法中对智能体同质性的假设限制了其处理具有异质性和未知目标的演示数据的能力，这是实践中常见的问题。", "innovation": "本文提出了一种深度隐变量 MFG 模型和相应的 IRL 方法。关键在于该方法可以在没有了解背景上下文或修改 MFG 模型的情况下，从结构上相似但功能不同的任务中推断出奖励。实验结果表明，该方法在模拟场景和真实的地理出租车定价问题中优于最先进的 IRL 方法。", "conclusion": "所提出的方法在 MFGs 中展示了其优越性，尤其是在处理异质性复杂任务时的表现优于现有 IRL 方法。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03594", "html_url": "https://arxiv.org/abs/2509.03594", "title": "显而易见的优化器：使用损失景观诱导度量进行训练", "title_en": "The Optimiser Hidden in Plain Sight: Training with the Loss Landscape's Induced Metric", "authors": "Thomas R. Harvey", "background": "本文研究了一种新的优化器，该优化器利用在更高维空间嵌入损失景观时自动生成的黎曼度量。这种度量与常见的损失景观可视化方法背后的度量相同。通过从几何角度出发并使用诱导度量，作者开发了一种新的优化器，并将其与现有的优化方法（如SGD、Adam、AdamW和Muon）进行比较。", "innovation": "论文中介绍了一类新的优化器，该优化器通过利用嵌入在更高维空间中的损失景观自动生成的黎曼度量来工作。这些新的优化器在低维示例中表现出色，并且相对于最先进的方法，在训练神经网络时提供了轻微的改进。从几何角度来看，这些优化器具有理论上的优势，例如自动减少高曲率区域的学习率，以及有效学习率调度并分解权重衰减。", "conclusion": "实验结果显示，这种新的优化器在低维度上的效果非常有效，并且在训练神经网络时可以提供轻微的改进。这种优化器具有计算复杂性与Adam相当的优势。基底方法可以修改任何现有的预条件优化器。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03852", "html_url": "https://arxiv.org/abs/2509.03852", "title": "MillGNN：学习多尺度领先-滞后依赖性以进行多变量时间序列预测", "title_en": "MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting", "authors": "Binqing Wu,Zongjiang Shang,Jianlong Huang,Ling Chen", "background": "多变量时间序列（MTS）预测在各种应用中至关重要。现有方法由于其强大的内在变量和跨变量依赖性捕捉能力，已经显示出有前景的结果。然而，这些方法往往忽略了多个分组层次上的领先-滞后依赖性，在复杂系统中无法捕捉到层次化的领先-滞后效应。因此，提出了一种新型的基于图神经网络的方法MillGNN，用于MTS预测，它可以综合考虑变量间和分组间的动态和衰减，全面捕捉领先-滞后效应。", "innovation": "MillGNN引入了两个关键创新点：(1) 一种特定于尺度的领先-滞后图学习模块，通过结合实时输入和时间滞后所得到的交叉相关系数和动态衰减特征来学习每个尺度的领先-滞后依赖性，这些特征既具有统计解释性，又具有数据驱动的灵活性；(2) 多尺度等级化的领先-滞后消息传递模块，以结构化的方式在多个分组尺度上传递领先-滞后消息，以同时传播内部和外部尺度的领先-滞后效应，从而在全面性和效率之间找到平衡，捕捉多尺度的领先-滞后效应。", "conclusion": "在11个数据集上的实验证明，与16种最先进的方法相比，MillGNN在长短期MTS预测中表现出优越性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03871", "html_url": "https://arxiv.org/abs/2509.03871", "title": "全面综述大型语言模型推理中的信任度", "title_en": "A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models", "authors": "Yanbo Wang,Yongcan Yu,Jian Liang,Ran He", "background": "长链思考（Long-CoT）推理的发展已经提高了LLM在语言理解、复杂问题解决和代码生成等功能上的性能。这种方法能让模型生成中间推理步骤，从而提高准确性和可解释性。然而，尽管取得了这些进步，有关基于CoT推理对语言模型可信度的影响的全面理解仍然不足。", "innovation": "本文综述了当前基于CoT推理模型的可信度研究，聚焦于五个核心维度：真实性、安全性、鲁棒性、公平性和隐私性。对于每个方面，提供了按时间顺序呈现的最新研究的清晰结构化概述，详细分析了它们的研究方法、发现及其局限性，并提出了未来研究方向作为参考和讨论的补充。值得注意的是，尽管推理技术通过缓解幻觉、有害内容检测和增强鲁棒性来增强模型的可信度，但最先进的推理模型在安全性、鲁棒性及隐私性方面往往具有相似甚至更大的脆弱性。", "conclusion": "通过综合这些见解，我们希望本文能为AI安全领域的研究人员提供有价值且及时的资源，以便他们了解推理可信性领域的最新进展。相关信息和相关论文列表可参见\textit{this https URL}。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03842", "html_url": "https://arxiv.org/abs/2509.03842", "title": "INGRID: 使用大语言模型的智能生成机器人设计", "title_en": "INGRID: Intelligent Generative Robotic Design Using Large Language Models", "authors": "Guanglu Jia,Ceng Zhang,Gregory S. Chirikjian", "background": "大语言模型（LLMs）在机器人系统中的集成加速了具身人工智能的发展，但当前方法仍受到现有机器人架构的限制，尤其是串行机制。这种硬件依赖性从根本上限制了机器人智能的范围。本文旨在应对这一挑战，通过将递归螺纹理论和运动合成方法与深度集成的方式，提出了一种名为INGRID（Intelligent Generative Robotic Design）的框架，该框架能够自动化设计并联的机制，克服了硬件限制，为设计更复杂的机器人提供可能性。", "innovation": "INGRID框架通过将递归螺纹理论和运动合成方法与深度集成，实现了并联机器人机制的自动化设计，特别适用于具有固定和可变自由度的新型机制设计。该方法分解了设计挑战为四个逐步任务，能够生成新的并联机制。通过实验证明，INGRID能够帮助用户根据特定任务的需求设计定制的并联机器人，从而打破了机器人智能发展的硬件束缚，为机制智能奠定了基础，使得AI系统能够主动设计机器人硬件，具有显著的创新性。", "conclusion": "INGRID框架通过对硬件依赖性问题的解决，为机器人系统中的具身人工智能开辟了新的途径，使无专门机器人训练背景的研究人员也能设计出并联机构，推动了机器人智能的发展，具有重要的理论和实际意义。这项工作为机制智能建立了一个基础，未来可能彻底改变具身人工智能系统的设计和发展。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03832", "html_url": "https://arxiv.org/abs/2509.03832", "title": "基于LLM的确认偏差模型的重力井回声室建模", "title_en": "Gravity Well Echo Chamber Modeling With An LLM-Based Confirmation Bias Model", "authors": "Joseph Jackson,Georgiy Lapin,Jeremy E. Thompson", "background": "社交媒体中的回声室在错误信息的传播中起着核心作用，但现有的模型往往忽略了个体确认偏差的影响。现有模型之一是“重力井”模型，它通过对回声室和空间重力井进行类比来建立模型。本文通过引入动态确认偏差变量来扩展该经典模型，该变量根据用户的信念强化内容的敏感性调整吸引力强度。", "innovation": "本文提出了一个结合了确认偏差的重力井模型，该模型通过比较用户发帖历史和对各种观点帖子的回应，为每个用户计算确认偏差变量。这使得能够更准确地识别回声室并揭示社区级的信息健康标志。本文通过在十九个Reddit社区上验证该方法，展示了改进回声室检测的效果。", "conclusion": "本文贡献了一个框架，用于系统地捕捉确认偏差在在线群体动态中的作用，从而更有效地识别回声室。通过标识这些高风险环境，模型支持遏制错误信息传播的努力。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03884", "html_url": "https://arxiv.org/abs/2509.03884", "title": "基于多层感知机神经网络的肽组学预测模型用于冠心病", "title_en": "Peptidomic-Based Prediction Model for Coronary Heart Disease Using a Multilayer Perceptron Neural Network", "authors": "Jesus Celis-Porras", "background": "冠心病是全球主要的致死原因之一，并且对年度医疗保健支出有重大影响。为了发展一种非侵入性的诊断方法，研究团队设计了一个基于多层感知机（MLP）神经网络的模型，该模型利用了通过遗传算法筛选出的50种关键尿液肽生物标志物进行训练。", "innovation": "研究采用了遗传算法挑选50种关键尿液肽生物标志物，并利用经过合成少数类过采样的合成少数类过采样技术（SMOTE）平衡治疗组和对照组，最终使用了具有三层隐层，每层60个神经元和一个输出层的神经网络模型。该模型在诊断冠心病时展现了95.67%的精确率、灵敏度和特异性，F1得分高达0.9565。", "conclusion": "这一结果表明，该模型提供了一种高度准确和可靠的非侵入性诊断工具，用于冠心病的检测。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03790", "html_url": "https://arxiv.org/abs/2509.03790", "title": "奖励函数中什么基础结构能促进有效的稀疏奖励学习？", "title_en": "What Fundamental Structure in Reward Functions Enables Efficient Sparse-Reward Learning?", "authors": "Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma", "background": "研究稀疏奖励强化学习的高效特性。探讨了奖励矩阵的低秩结构如何引起样本复杂度从指数级转变为多项式级的突变，这是稀疏奖励RL中的第一类结果。", "innovation": "引入了基于矩阵填充的策略感知矩阵完成（PAMC）方法，将矩阵填充理论与强化学习结合，通过政策依赖采样的新分析。此框架提供了：（i）一般的稀疏奖励观察不可能的结果，（ii）无法建模的代表学习从动力学中学习，（iii）基于正则预测的无分布置信集，（iv）低秩结构近似时的渐进健壮的完成保证。", "conclusion": "在100个系统选取的领域中，我们预先注册评估发现超过一半存在可利用的结构。PAMC在样本效率上，与强大探索、结构和代表学习基线相比，提高了1.6到2.1倍的因子，同时增加了大约20%的计算成本。结果证明了结构奖励学习作为一种有前景的新范式，对机器人技术、医疗保健和其他安全关键、样本成本高的应用具有直接含义。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03937", "html_url": "https://arxiv.org/abs/2509.03937", "title": "SPFT-SQL：通过自我对弈微调增强大型语言模型的文本到SQL解析", "title_en": "SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by Self-Play Fine-Tuning", "authors": "Yuhao Zhang,Shaoming Duan,Jinhang Su,Chuanyi Liu,Peiyi Han", "background": "尽管自我对弈微调（SPIN）可以将一个弱的大语言模型（LLM）通过不同能力模型间的竞争互动转变为强大的模型，但在文本到SQL的任务中，SPIN方法仍然面临挑战。SPIN不生成新信息，并且在自我对弈过程中产生大量正确的SQL查询，这反而降低了主要模型生成精确SQL查询的能力。", "innovation": "为解决这一挑战，作者提出了一个针对文本到SQL任务的新自我对弈微调方法，称为SPFT-SQL。在自我对弈前，引入了一种基于验证的迭代微调方法，根据数据库模式和验证反馈迭代合成高质量的微调数据，以增强模型性能。在自我对弈微调阶段，提出了一种错误驱动的损失方法以促进对手模型错误输出，从而使主要模型能够区分正确的SQL和由对手模型生成的错误SQL，从而提高其生成正确SQL的能力。", "conclusion": "在六个开源的大语言模型和五个广泛使用的基准上进行的广泛的实验和详细分析表明，本方法优于现有的最先进的（SOTA）方法。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03950", "html_url": "https://arxiv.org/abs/2509.03950", "title": "使用EfficientNet-B4迁移学习在U-Net架构下的胸部X光气胸分割", "title_en": "Chest X-ray Pneumothorax Segmentation Using EfficientNet-B4 Transfer Learning in a U-Net Architecture", "authors": "Alvaro Aranibar Roque,Helga Sebastian", "background": "气胸是一种在胸膜腔内异常积聚空气的情况，如果未被检测到，可能会危及生命。胸部X光片是初步诊断工具，但较小的病例可能难以察觉。研究提出了一种使用U-Net结合EfficientNet-B4编码器的自动深度学习管道，用于分割气胸区域。在SIIM-ACR数据集上经过数据增强和结合二元交叉熵和Dice损失进行训练，该模型在独立的PTX-498数据集上实现了0.7008的IoU和0.8241的Dice分数。这些结果表明模型能够准确定位气胸区域，并支持放射科医生的诊断工作。", "innovation": "提出了一种基于U-Net架构和EfficientNet-B4编码器的自动深度学习管道，用于胸部X光气胸分割。该方法通过数据增强和混合损失函数进行训练，提高了气胸区域分割的准确性。", "conclusion": "实验结果表明，该模型能够准确地定位气胸区域，并支持放射科医生的诊断。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03873", "html_url": "https://arxiv.org/abs/2509.03873", "title": "SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition", "title_en": "SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition", "authors": "Jiajun Song,Xiaoou Liu", "background": "食品识别引起了广泛关注，但新菜品的快速出现要求识别未见过的食品类别，推动了零样本食品学习（ZSFL）的发展。然而，食品零样本分类面临背景冗余、主菜与配菜角色混淆以及单一属性语义偏见三大挑战。", "innovation": "本文提出了一个综合方案，详细描述了SalientFusion方法，该方法包含两个组件：SalientFormer和DebiasAT。SalientFormer通过移除背景冗余和利用深度特征解决主菜与配菜角色混淆问题；DebiasAT通过将提示与视觉特征对齐来减少语义偏见。作者使用两种基准数据集——CZSFood-90和CZSFood-164，展示了SalientFusion在食品零样本分类任务中的最佳性能。", "conclusion": "通过使用我们提出的基准数据集，SalientFusion在这些基准和流行的一般零样本学习数据集上取得了最先进的结果。代码可在相应链接处获取。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03834", "html_url": "https://arxiv.org/abs/2509.03834", "title": "从莱iden到快乐岛：常数波特模型在社区检测中的效用博弈", "title_en": "From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game", "authors": "Lucas Lopes Felipe,Konstantin Avrachenkov,Daniel Sadoc Menasche", "background": "社区检测在数据科学中是一个基本问题，涉及节点的聚类。该研究采用博弈论视角解析常数波特模型（CPM），解决网络分割为独立社区的问题，强调其效率、鲁棒性和准确性。", "innovation": "研究将重新解释CPM为一种绩效敬业博弈，通过分解全局哈密顿量为局部效用函数，证明局部优化CPM目标的更好反应动力学在伪多项式时间内收敛到平衡分割。引入并关联了两种稳定标准：一种基于新型鲁棒性的严格标准，另一种基于权重总和的宽松效用函数，由解析参数控制。通过社区跟踪情景的实验，显示鲁棒分割提高了真实社区恢复的准确性。", "conclusion": "在初始分割用于引导带有部分真实信息的Leiden算法时，实验表明鲁棒分割在真实社区恢复方面具有更高的准确性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03889", "html_url": "https://arxiv.org/abs/2509.03889", "title": "具有知情密集对应和视触知觉功能的反应式空中服装操纵", "title_en": "Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance", "authors": "Neha Sunil,Megha Tippur,Arnau Saumell,Edward Adelson,Alberto Rodriguez", "background": "衣服的操作具有挑战性，因为衣服的结构复杂、材料动态变化大且经常自我遮挡。先前的系统通常会压平服装或假设关键特征的可见性。因此需要一种新的方法来直接对皱褶和悬空的服装进行操作，同时克服这些挑战。该项研究提出了一种双臂的视触知觉框架，结合了基于置信度的密集视觉对应和触觉监督的抓取潜力，可在操作中断情况和空中配置中处理高度遮挡的桌面情况。", "innovation": "该研究的创新之处在于开发了一种双臂的视触知觉框架，该框架结合了基于置信度的密集视觉对应和触觉监督的抓取潜力。通过使用分布损失来训练定制的高保真模拟数据集，产生对应置信度估计，这些估计指导感觉不确定性的反应状态机自动调整折叠策略。同时，通过高分辨率的触觉反馈进行自我监督来确定物理可抓取的区域。这种触觉分类器在执行期间用于实时抓取验证，保证系统的稳健性。实验结果展示了一种通用的抓取选择模块在折叠和挂衣任务中的应用，同时密集描述符作为其他规划模式的可重复使用中介表示，为更广泛的应用铺平了道路。", "conclusion": "该系统通过在低置信度状态下推迟操作，成功处理了充满挑战性的服装场景，并展示了用于衣物折叠和悬挂任务的通用抓取选择模块。通过结合视觉和触觉信息，该系统为其他规划模式提供了可重复使用的中介表示，比如从人类示范视频中提取抓取目标，这将有助于实现更通用和可扩展的服装操作。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03972", "html_url": "https://arxiv.org/abs/2509.03972", "title": "通过韩语文本案例研究在开源大语言模型中扩展基础语言能力", "title_en": "Expanding Foundational Language Capabilities in Open-Source LLMs through a Korean Case Study", "authors": "Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh", "background": "本文介绍了一种名为Llama-3-Motif的语言模型，其参数量为102亿，旨在增强韩语能力同时保持对英语的强大性能。该模型在Llama 3架构上开发，通过LlamaPro和Masked Structure Growth等先进的训练技术有效地扩大了模型规模，同时保持核心Transformer架构不变。使用MoAI平台在大规模GPU集群上进行高效的训练，并通过精心挑选的数据集保持韩语和英语数据的平衡。", "innovation": "Llama-3-Motif模型通过LlamaPro和Masked Structure Growth等先进的训练技术，在不改动核心Transformer架构的情况下实现了有效的模型扩展。该模型在韩语特定基准测试中的表现良好，超越了现有模型，且性能与GPT-4相当。", "conclusion": "Llama-3-Motif模型保持了对英语的强大性能，同时增强了对韩语的支持，并在韩语特定基准测试中表现良好，超越了现有的模型和达到了与GPT-4相当的水平。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03957", "html_url": "https://arxiv.org/abs/2509.03957", "title": "CANDY: 在汉语虚假信息事实核查中评估大语言模型的局限性和辅助潜力", "title_en": "CANDY: Benchmarking LLMs' Limitations and Assistive Potential in Chinese Misinformation Fact-Checking", "authors": "Ruiling Guo,Xinwei Yang,Chen Huang,Tong Zhang,Yong Hu", "background": "尽管大语言模型（LLMs）的广泛应用尚不确定它们在事实核查虚假信息方面的有效性，但本研究旨在系统性地评估LLMs在汉语虚假信息事实核查中的能力和局限性，通过构建一个包含约20,000个实例的精心标注数据集来完成这一目标。研究表明，当前的LLMs在生成准确的事实核查结论时存在局限性，即使伴随着链式思考推理和少量示例的提示也一样。理解这些局限性，并通过开发一种分类法来归类生成的说法性解释，发现虚构事实是最常见的失败模式。尽管单独使用LLMs进行事实核实在不可靠，但研究结果表明，当作为辅助工具在某些场景中支持人类表现时，它们具有巨大的潜力。这份数据集和代码可以在该网址获取：this https URL", "innovation": "本研究通过开发一个精心标注的数据集，系统性地评估了大语言模型在汉语虚假信息事实核查中的能力和局限性，特别是在生成准确事实核查结论方面的表现。同时，研究通过开发一种分类法来归类和理解大语言模型生成的错误解释，揭示了虚构事实是最常见的错误类型。研究还指出了大语言模型作为辅助手段支持人类表现的实际潜力，特别强调了它们在特定场景中的应用前景。这份数据集和代码为相关研究提供了一个重要的资源。", "conclusion": "现有的大语言模型在汉语虚假信息事实核查中仍存在局限性，主要表现为不能准确生成结论，即使配备了链式思考和少量示例提示。研究成果表明，这些模型可以作为辅助工具提升人类的表现，特别是在特定场景中。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03985", "html_url": "https://arxiv.org/abs/2509.03985", "title": "NeuroBreak：揭示大型语言模型内部劫持机制", "title_en": "NeuroBreak: Unveil Internal Jailbreak Mechanisms in Large Language Models", "authors": "Chuhan Zhang,Ye Zhang,Bowen Shi,Yuyou Gan,Tianyu Du,Shouling Ji,Dazhan Deng,Yingcai Wu", "background": "在部署和应用中，大型语言模型（LLMs）通常需要通过安全性对齐以防止非法和不道德的输出。然而，随着针对安全机制进行规避的“监狱逃脱”攻击技术的不断进步，对LLMs的安全防御产生了越来越大的压力。“监狱逃脱”攻击需要通过对抗性提示来绕过安全机制，因此需要深入理解LLMs的安全机制和漏洞。然而，由于LLMs具有庞大的参数和复杂的结构，从内部视角分析其安全弱点是一项具有挑战性的任务。", "innovation": "本文提出了NeuroBreak，这是一种自上而下的“监狱逃脱”分析系统，专门用于分析神经元级的安全机制并缓解漏洞。该系统通过与三位AI安全领域的专家合作，精心设计系统需求，能够提供多种“监狱逃脱”攻击方法的全面分析，并通过逐层表示探查分析提供对模型决策过程的新型视角。此外，该系统还支持从语义和功能层面进行关键神经元的分析，有助于更深入地探讨安全性机制。", "conclusion": "我们进行了定量评估和案例研究以验证系统的有效性，为开发针对不断演变的“监狱逃脱”攻击的下一代防御策略提供了机制性见解。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03961", "html_url": "https://arxiv.org/abs/2509.03961", "title": "基于文本差异增强的多模态特征融合网络在遥感变化检测中的应用", "title_en": "Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection", "authors": "Yijun Zhou,Yikui Zhai,Zilu Ying,Tingfeng Xian,Wenlve Zhou,Zhiheng Zhou,Xiaolin Tian,Xudong Jia,Hongsheng Zhang,C. L. Philip Chen", "background": "尽管深度学习在遥感变化检测（RSCD）中取得了进展，大多数方法仅依赖图像模态，这限制了特征表示、变化模式建模以及在光照和噪声干扰下的泛化能力。", "innovation": "提出了一种名为MMChange的多模态RSCD方法，结合图像和文本模态以提高准确性和鲁棒性。引入了图像特征精炼（IFR）模块来突出关键区域并抑制环境噪声，通过视觉语言模型（VLM）生成双时相图像的语义描述，并设计了文本差异增强（TDE）模块捕捉细粒度语义变化，桥梁不同模态之间的异质性，设计了图像文本特征融合（ITFF）模块以实现深层次跨模态集成。", "conclusion": "在LEVIRCD、WHUCD和SYSUCD上的广泛实验表明，MMChange在多个指标上均超过了现有方法，验证了其在多模态RSCD中的有效性，并且代码可在指定链接获取。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03934", "html_url": "https://arxiv.org/abs/2509.03934", "title": "SelfAug: 通过分布自我对齐缓解检索增强生成的灾难性遗忘", "title_en": "SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment", "authors": "Yuqing Huang,Rongyang Zhang,Qimeng Wang,Chengqiang Lu,Yan Gao,Yi Wu,Yao Hu,Xuyang Zhi,Guiquan Liu,Xin Li,Hao Wang,Enhong Chen", "background": "近期大型语言模型（LLMs）的进展极大地革新了自然语言处理，通过其在理解和执行各种任务方面显著的能力。虽然监督微调，特别是在检索增强生成（RAG）场景中非常有效，但往往会导致灾难性遗忘，即模型会丢失先前获得的知识和通用能力。现有的解决方案要么需要访问通用指令数据，要么在保留模型原始分布方面存在局限性。现有文献指出，分配的变化与RAG场景中灾难性遗忘的严重程度之间存在着直接的相关性，特别是在一般指令调优中缺乏RAG能力导致细调过程中分布变化显著。", "innovation": "该论文提出了一种名为SelfAug的方法，这是一种自我分布对齐方法，通过调整输入序列的概率分布，以保存模型的语义分布，从而缓解灾难性遗忘并提高下游性能。实验表明，SelfAug在下游学习和通用能力保留之间的平衡优于其他方法。这一创新为RAG场景下解决灾难性遗忘提供了一个实用解决方案，并适用于各种微调场景。", "conclusion": "本文研究发现，分布转移与RAG场景中灾难性遗忘的严重性之间存在直接关联，强调了在一般指令调优中缺乏RAG能力导致的显著分布转移。研究不仅推进了对RAG场景中灾难性遗忘的理解，也提供了一个适用于多种微调场景的实用解决方案。作者已将其代码公开发布。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03995", "html_url": "https://arxiv.org/abs/2509.03995", "title": "RTQA：使用大型语言模型进行复杂时态知识图谱问题解答的递归思考", "title_en": "RTQA : Recursive Thinking for Complex Temporal Knowledge Graph Question Answering with Large Language Models", "authors": "Zhaoyan Gong,Juan Li,Zhiqiang Liu,Lei Liang,Huajun Chen,Wen Zhang", "background": "当前的时态知识图谱问题回答（TKGQA）方法主要关注隐式的时态约束，缺乏处理更复杂时态查询的能力，并且在分解框架中存在推理能力和错误传播的限制", "innovation": "我们提出了RTQA，一种新颖的框架，通过递归拆分问题并利用大型语言模型和时态知识图谱知识自上而下求解，以增强对时态知识图谱的推理能力，同时使用多路径答案聚合提高容错性。RTQA 包含三个核心组件：时态问题拆解器、递归求解器和答案聚合器", "conclusion": "在 MultiTQ 和 TimelineKGQA 标准基准测试上，RTQA 在“Multiple”和“Complex”类别中显著提高了 Hits@1，并在性能上优于最先进的方法。我们的代码和数据可在以下链接：[提供链接]"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03898", "html_url": "https://arxiv.org/abs/2509.03898", "title": "扩散生成模型遇上压缩感知，应用于图像数据和金融时间序列", "title_en": "Diffusion Generative Models Meet Compressed Sensing, with Applications to Image Data and Financial Time Series", "authors": "Zhengyi Guo,Jiatu Li,Wenpin Tang,David D. Yao", "background": "该论文在合成数据生成的背景下，发展了一种用于加速扩散模型推理的降维技术。通过将压缩感知技术集成到扩散模型中，实现数据压缩、在潜在空间中训练扩散模型以及运用压缩感知算法，以提高模型训练和推理的效率。", "innovation": "提出的算法通过结合扩散模型推理与稀疏恢复，证明在适当选取的数据稀疏性假设下，享受了更快的收敛速度。同时，论文还给出了潜在空间维度的最优值，并进行了涵盖图像数据（手写数字、医学图像、气候数据）和金融时间序列的一系列数值实验来验证其效果。", "conclusion": "通过将压缩感知与扩散生成模型相结合，该研究能够在大幅提高合成数据生成效率的同时，获得潜在空间维度的最优值，并且通过广泛的数据集验证了方法的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03973", "html_url": "https://arxiv.org/abs/2509.03973", "title": "SAC-MIL：综合空间意识的相关多实例学习在组织病理学全切片图像分类中的应用", "title_en": "SAC-MIL: Spatial-Aware Correlated Multiple Instance Learning for Histopathology Whole Slide Image Classification", "authors": "Yu Bai,Zitong Yu,Haowen Tian,Xijing Wang,Shuo Yan,Lin Wang,Honglin Li,Xitong Ling,Bo Zhang,Zheng Zhang,Wufan Wang,Hui Gao,Xiangyang Gong,Wendong Wang", "background": "全切片图像（WSI）分类是组织病理学中的一个重要任务，需要对大型组织图像进行分类。传统的多实例学习（MIL）方法在处理WSI时存在一些挑战，如位置信息丢失和处理不同长度序列的问题。现有的解决方案主要依赖于Transformer等方法，但这些方法部署复杂，需要定制的CUDA内核。因此，提出了Spatial-Aware Correlated Multiple Instance Learning (SAC-MIL)来解决这些问题，通过结合空间编码模块和SAC块来改进多实例学习的方法，以更好地处理WSI分类中的地理布局问题。SAC-MIL能够编码实例在图像中的位置关系，并且在操作序列长度上具有线性的时间复杂度，便于部署和使用。", "innovation": "提出了一种称为Spatial-Aware Correlated Multiple Instance Learning (SAC-MIL)的新方法，该方法包含一个空间编码模块和一个SAC块。空间编码模块通过使用实例坐标来编码位置关系，而不是输入WSI序列的实例索引，从而解决了不同长度序列的处理问题。SAC块则采用MLP方法实现全实例相关性，具有线性时间复杂度。与基于Transformer的方法相比，SAC-MIL的部署更为简单便捷，不需要定制的CUDA内核。该方法在CAMELYON-16、TCGA-LUNG和TCGA-BRAC数据集上实现了最先进的性能。", "conclusion": "实验结果表明，SAC-MIL在CAMELYON-16、TCGA-LUNG和TCGA-BRAC数据集上达到最先进的性能。此外，这种简单的结构使得SAC-MIL更容易部署和使用，因此对于组织病理学WSI分类来说是一个创新和有效的解决方案。代码将在论文被接受后发布。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04051", "html_url": "https://arxiv.org/abs/2509.04051", "title": "具有循环上下文过滤和离环重建增强的神经视频压缩", "title_en": "Neural Video Compression with In-Loop Contextual Filtering and Out-of-Loop Reconstruction Enhancement", "authors": "Yaojun Wu,Chaoyi Lin,Yiming Wang,Semih Esenlik,Zhaobin Zhang,Kai Zhang,Li Zhang", "background": "该论文探索了增强过滤技术在神经视频压缩中的应用。通过区分循环内的上下文滤波和离环重建增强，根据增强表示对后续编码循环的影响情况来分类这些技术。", "innovation": "提出了一个自适应编码决策策略，能够动态地在编码过程中决定滤波器的应用。此外，使用离环重建增强来改善重建帧的质量，提供了一种简单而有效的编码效率提升方法。这是首次系统性地研究基于条件的神经视频压缩中的增强过滤。", "conclusion": "实验结果表明，与最先进的神经视频编解码器相比，该方法降低了7.71%的比特率，证明了所提出方法的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03940", "html_url": "https://arxiv.org/abs/2509.03940", "title": "VoxRole: 一个全面的评估基于语音的扮演代理的基准", "title_en": "VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based Role-Playing Agents", "authors": "Weihao Wu,Liang Cao,Xinyu Wu,Zhiwei Lin,Rui Niu,Jingbei Li,Zhiyong Wu", "background": "近年来，大型语言模型（LLMs）的重大进展极大地推动了角色扮演对话代理（RPCAs）的发展。这些系统旨在通过保持一致的人设创造沉浸式用户体验。然而，当前的研究面临着双重限制。首先，现有工作主要集中在文本模态，完全忽视了言语中的重要副语言特征（如语调、语调和节奏），这些特征对于传达人物情感和塑造生动的身份至关重要。其次，以语音为基础的角色扮演领域长期以来缺乏标准化的评估基准。现有的口头对话数据集主要针对基本能力评估，缺乏详细的或定义不清的人物档案，这无法有效量化模型在维持长期人设一致性等核心能力上的表现。", "innovation": "为解决这一关键缺口，我们介绍了一个名为VoxRole的新基准，这是第一个专为评估基于语音的角色扮演对话代理（RPCAs）设计的全面基准。该基准包含了13335个多轮对话，共65.6小时的语音数据，涵盖来自261部电影的1228个独特人物。为了构建这一资源，我们提出了一种新颖的两阶段自动化管道，首先将电影音频与脚本对齐，然后使用大型语言模型（LLM）为每个角色系统地构建多维度的个人档案。利用VoxRole，我们对当前口头对话模型进行了多维度评估，揭示了它们在维持人设一致性方面的各自优势和局限性。", "conclusion": "通过VoxRole进行评估，我们能够深入了解当前模型在实现任务上存在的不足和优势，这将有助于推动未来基于语音的对话代理技术的发展。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03986", "html_url": "https://arxiv.org/abs/2509.03986", "title": "Promptception：大型多模态模型对提示有多敏感？", "title_en": "Promptception: How Sensitive Are Large Multimodal Models to Prompts?", "authors": "Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan", "background": "尽管近年来大型多模态模型（LMMs）在多项选择题回答（MCQA）任务上取得了成功，但仍对LMMs的提示设计理解不足。即使是小的提示措辞和结构变化也可能导致高达15%的准确性偏差。这种不确定性给透明和公平的LMM评估带来了挑战，因为模型通常会报告其最佳性能，这依赖于精心选择的提示。因此，需要一种系统的方法来评估LMM对提示的敏感性，以便更好地理解不同模型在不同提示下的表现。", "innovation": "提出了Promptception，这是一种针对LMMs的系统框架，用于评估提示的敏感性。它包括61种不同类型提示，涵盖了15个类别和6个超类别，每个类别都针对提示制定的特定方面。该框架用于评估10种不同类型的LMMs（从轻量级开源模型到GPT-4o和Gemini 1.5 Pro），并以MMStar、MMMU-Pro和MVBench这3个MCQA基准进行了测试。结果显示，专有模型更敏感于提示的措辞，反映出其与指令语义的更紧密对齐，而开源模型则相对稳定但难以处理复杂的提示措辞。基于此分析，提出了针对专有和开源LMMs的提示原则，以实现更稳健和公平的模型评估。", "conclusion": "研究发现，专有模型对提示措辞更为敏感，反映出其与指令语义的更紧密对齐；而开源模型则相对稳定但难以处理复杂的提示措辞。据此，提出了针对专有和开源LMMs的提示原则，以实现更公平和稳健的模型评估。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04011", "html_url": "https://arxiv.org/abs/2509.04011", "title": "NER Retriever: 基于类型感知嵌入的零样本命名实体检索", "title_en": "NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings", "authors": "Or Shachar,Uri Katz,Yoav Goldberg,Oren Glickman", "background": "零样本命名实体检索（NER）是命名实体识别的一种变体，其中感兴趣的实体类型在检索之前未提前提供，而是通过用户自定义的类型描述来检索提及该类型实体的文档。传统的方法通常依赖于固定模式或微调模型，而这种方法则利用大型语言模型（LLMs）的内部表示，将实体提及和用户提供的开放类型描述嵌入到共享语义空间。研究表明，中间层变换块的值向量比常用顶层嵌入更有效地编码细粒度的类型信息。研究表明，中间层变换块的值向量比常用顶层嵌入更有效地编码细粒度的类型信息。这种方法通过训练一个轻量级对比投影网络进一步完善这些表示，该网络将类型兼容的实体对齐并分离不相关的类型。这使得实体嵌入更加紧凑、类型意识强，并且适合最近邻居搜索技术评价结果显示，在三个基准测试上，NER Retriever 显著优于词典和密集句子级别检索基线，为大型语言模型中表示选择提供了实证支持，并展示了实现大规模、无模式实体检索的实用解决方案。", "innovation": "该方法通过利用大型语言模型（LLMs）的内部表示，将实体提及和用户提供的开放类型描述嵌入到共享语义空间。这种新方法利用了中间层变换块的值向量，这种向量比常用的顶层嵌入更有效地编码细粒度的类型信息。此外，还提出了一种轻量级对比投影网络，进一步优化了这些表示，使其更加类型兼容和分离。这种表示方法使得实体嵌入更加紧凑、类型意识强，并且适用于最近邻居搜索。这种方法显著优于传统的词典和密集句子级别检索基线，展示了在大型语言模型内进行表示选择的实证支持，并展示了实现大规模、无模式实体检索的实用解决方案。此框架还包括开源代码，方便其他研究者和开发者使用和改进。", "conclusion": "NER Retriever 在三个基准测试上显著优于传统检索基线，不仅为命名实体检索领域提供了新的方法，还展示了大型语言模型内部表示选择的有效性和实用性。此工作证明了通过使用大型语言模型的内部表示和自定义类型描述进行零样本命名实体检索的可行性，并为大规模、无模式实体检索提供了一个可扩展的解决方案。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04118", "html_url": "https://arxiv.org/abs/2509.04118", "title": "EHVC: 效率化的层次化参考和质量结构在神经视频编码中的应用", "title_en": "EHVC: Efficient Hierarchical Reference and Quality Structure for Neural Video Coding", "authors": "Junqi Liao,Yaojun Wu,Chaoyi Lin,Zhipin Deng,Li Li,Dong Liu,Xiaoyan Sun", "background": "神经视频编解码器（NVCs）利用端到端学习的力量，已经在编码效率上取得了显著的进步，超越了传统视频编解码器。当前的研究已经注意到NVCs中的质量结构，并通过引入明确的分层设计进行优化。然而，相较于质量结构，基准结构设计得到的关注较少，而事实上它们应该相互对齐以适应分层质量结构的需要。此外，分层质量结构仍然有很大的改进空间。", "innovation": "本文提出了EHVC（Efficient Hierarchical Video Codec），它具有三大创新点：（1）一种层次化的多基准方案，借鉴传统视频编解码器设计以使基准与质量结构对齐，解决基准与质量不匹配的问题；（2）一种前瞻策略，利用未来帧的编码侧上下文增强质量结构；（3）逐层的质量尺度和随机质量训练策略，在推理时稳定质量结构。", "conclusion": "通过这些改进，EHVC在神经视频编码中达到了显著优于当前最先进的NVCs的表现。相关代码将在此链接中发布：this https URL。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04126", "html_url": "https://arxiv.org/abs/2509.04126", "title": "MEPG:多专家规划与生成方法用于丰富组成的图像生成", "title_en": "MEPG:Multi-Expert Planning and Generation for Compositionally-Rich Image Generation", "authors": "Yuan Zhao,Liu Lin", "background": "文本到图像的扩散模型已经在图像质量上取得了显著进展，但是它们仍然难以处理复杂的、多元素的提示以及有限的风格多样性。", "innovation": "提出了一种名为Multi-Expert Planning and Generation Framework (MEPG)的框架，该框架结合了位置和风格感知大型语言模型（LLMs）与空间语义专家模块。MEPG框架包括两个核心组件：（1）位置-风格感知（PSA）模块，该模块利用监督微调的LLM将输入提示分解为精确的空间坐标和样式编码的语义指令；（2）多专家扩散（MED）模块，该模块实现跨区域生成，通过动态专家路由实现局部区域和全局区域之间的专家指令传递。在生成过程中，特定的专家模型（如现实感专家、风格专家）通过基于注意力的门控机制在每个空间分割中按需激活。", "conclusion": "实验表明，MEPG在图像质量和风格多样性方面显著优于具有相同骨干网的基础模型。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04129", "html_url": "https://arxiv.org/abs/2509.04129", "title": "策略的关键在于观察者的视角：在反应式合成中的控制器的战略视角", "title_en": "Simplicity Lies in the Eye of the Beholder: A Strategic Perspective on Controllers in Reactive Synthesis", "authors": "Mickael Randour", "background": "在基于博弈论的方法实现控制器合成中，我们把目标系统与其环境之间的互动建模为这些实体之间的博弈，并寻找系统的适当策略（如胜利或最优策略）。普遍认为，简单的策略（比如具有有限记忆）更优秀，因为相应的控制器更容易构思和理解，制作和维护成本也较低。本文关注在合成场景中策略的复杂性问题，讨论了关于记忆和随机性的最近成果，并简要探讨了超越我们传统策略复杂性的观念。", "innovation": "本文讨论了反应式合成中策略复杂性的问题，特别是关于记忆和随机性方面的新结果，并深入探讨了策略复杂性的传统观念之外的新领域。它提出了一个新颖的观点，即策略的简化性取决于观察者，通过战略视角重新审视控制器在反应式合成中的作用。", "conclusion": "在反应式合成的背景下，复杂的策略并不总是最佳选择。研究展示了记忆和随机性在策略构建中的角色，同时也提出了新的复杂性概念。通过这种方式，策略的简化性不再是唯一的关键因素，而是取决于具体应用和观察者的视角。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04139", "html_url": "https://arxiv.org/abs/2509.04139", "title": "增强RAG系统中技术文档检索", "title_en": "Enhancing Technical Documents Retrieval for RAG", "authors": "Songjiang Lai,Tsun-Hin Cheung,Ka-Chun Fung,Kaiwen Xue,Kwan-Ho Lin,Yan-Ming Choi,Vincent Ng,Kin-Man Lam", "background": "技术文档的检索是一个复杂的挑战，尤其是在硬件和软件开发中。现有的方法在理解和检索复杂的技术内容方面存在不足，因此需要一种新的框架来优化这种检索。本文介绍了一种新的框架——Technical-Embeddings，它通过利用大型语言模型（LLMs）的能力来解决这些问题。该框架通过增强用户查询和总结提取技术来改进技术文档的表示，从而提高信息检索的性能。", "innovation": "Technical-Embeddings框架首先通过生成扩展的查询表示来增强用户查询，以更好地捕捉用户意图并提高数据集多样性，从而改进嵌入模型的微调过程；其次应用总结提取技术提取文档的上下文信息，并微调双编码BERT模型以软提示的方式，分别学习查询和文档上下文的参数，以捕捉细微的语义细微差别。这种方法在RAG-EDA和Rust-Docs-QA两个公开数据集上进行评估，结果显示Technical-Embeddings显著优于基线模型，充分展示了查询扩展和上下文总结集成的有效性，从而提高了技术领域中的信息获取和理解。", "conclusion": "本文的工作推进了RAG系统的发展，通过集成查询扩展和上下文总结，为工程和产品开发中的技术文档检索提供了新的高效和准确的方法。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04156", "html_url": "https://arxiv.org/abs/2509.04156", "title": "YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind Turbine Components", "title_en": "YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind Turbine Components", "authors": "Serhii Svystun,Pavlo Radiuk,Oleksandr Melnychenko,Oleg Savenko,Anatoliy Sachenko", "background": "无人机装备有先进传感器，为监测风力发电厂包括叶片、塔架和其他关键组件提供了新的机会。然而，可靠的缺陷检测需要高分辨率数据和处理多光谱图像的有效方法。在此研究中，旨在通过开发结合可见光和热通道的YOLO基于深度学习模型的集成来提升缺陷检测准确性。", "innovation": "提出了一种集成方法，该方法将通用的YOLOv8模型与专门的热模型结合起来，利用先进的边界框融合算法合并它们的预测。这种方法在均值平均精确度mAP@.5达到0.93和F1分数达到0.90，优于仅使用YOLOv8模型，后者在mAP@.5下的得分为0.91。这些结果表明，结合多个YOLO架构并使用融合多光谱数据提供了一个更可靠的方法，以改进对视觉和热缺陷的检测。", "conclusion": "结合多个YOLO架构并使用融合多光谱数据提供了一个更可靠的方法，以改进对视觉和热缺陷的检测，在风力发电机组部件的无人机多光谱缺陷检测中表现更优。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04180", "html_url": "https://arxiv.org/abs/2509.04180", "title": "VisioFirm：跨平台的计算机视觉领域AI辅助标注工具", "title_en": "VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer Vision", "authors": "Safouane El Ghazouali,Umberto Michelucci", "background": "传统的数据标注耗时且劳动密集，依赖人工标注复杂任务（如物体检测、方向边界框估计和实例分割），传统工具需要大量手动输入，难以应对大规模数据集的需求。为解决这一问题，本文提出VisioFirm，这是一种集成最新基础模型的开源网页应用程序，旨在通过AI辅助自动化流程简化图像标注过程。VisioFirm结合CLIP、预训练检测器（如Ultralytics模型）和零样本模型（如Grounding DINO），生成初始注释以最大化召回率。", "innovation": "VisioFirm利用CLIP和预训练检测器、零样本模型，集成先进的过滤管道，结合AI辅助自动化，并提供界面上的交互工具支持各种形状的边界框，实现即用即分的分割功能；通过模型缓存支持离线操作；提供多种导出格式，支持集群和IoU图进行重叠检测抑制，实现高效率、高准确率的标注。VisioFirm通过在多种数据集上的基准测试，展示了手动标注工作的高达90%的效率提升。", "conclusion": "VisioFirm作为一种AI辅助的图像标注工具，通过集成先进技术显著降低人力成本，提高标注效率和准确性，为大规模图像标注需求提供了有效的解决方案。该工具现已开源并在网上提供使用访问。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04183", "html_url": "https://arxiv.org/abs/2509.04183", "title": "MAGneT: 协调多智能体生成合成多元轮次心理健康咨询会话", "title_en": "MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions", "authors": "Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych", "background": "随着对可扩展的心理咨询需求的增加，需要使用高质量且保护隐私的数据对开源大型语言模型（LLMs）进行微调。然而，这样的高质量数据仍然稀缺。现有方法多以单智能体方式进行，这限制了对真实咨询结构和细微差别的捕捉能力。", "innovation": "MAGneT 引入了一种新的多智能体框架，用于合成心理咨询服务生成，将咨询师回应的生成分解为由专门的 LLM 代理共同完成的任务，每种代理模拟一种关键的心理技术。此外，还提出了一种统一的评估框架，涵盖了多种自动和专家评估指标，同时扩展了专家评估的维度，使其能够更彻底和稳健地评估数据质量。", "conclusion": "实验结果显示，MAGneT 在生成的心理咨询服务质量、多样性和治疗定向方面表现显著优于现有方法，分别提高了 3.2% 和 4.3% 的一般咨询技巧和认知行为疗法（CBT）的特定技巧。此外，专家学者们在所有方面的首选率平均为 77.2%。进一步利用 MAGneT 生成的会话对开源模型进行微调后，还取得了明显的效果提升，表明利用多智能体生成的数据进行微调可获得更好的性能。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04166", "html_url": "https://arxiv.org/abs/2509.04166", "title": "跨越物种界限：从语音到动物声音的迁移学习", "title_en": "Crossing the Species Divide: Transfer Learning from Speech to Animal Sounds", "authors": "Jules Cauzinille,Marius Miron,Olivier Pietquin,Masato Hagiwara,Ricard Marxer,Arnaud Rey,Benoit Favre", "background": "虽然自监督的语音模型在语音处理任务中取得了令人印象深刻的性能，但它们对非语音数据的有效性仍然没有得到充分的探索。本文研究了这种模型在生物声学检测和分类任务中的迁移学习能力。研究表明，HuBERT、WavLM和XEUS等模型能够生成跨物种的动物声音的丰富潜在表示。通过线性探针在时间平均表示上分析模型特性，然后扩展方法以考虑时间信息对下游架构的影响。最后，研究频率范围和噪声对性能的影响。结果表明，这些模型与细调的生物声学预训练模型相当，展示了噪声鲁棒预训练设置的影响。这些发现突显了基于语音的自监督学习作为促进生物声学研究高效框架的潜力.", "innovation": "本文提出了探索自监督语音模型在非语音（生物声学）任务中的迁移学习能力，特别关注动物声音的检测和分类。利用HuBERT、WavLM和XEUS等模型生成丰富的潜在表示，通过线性探针和时间信息的考虑，扩展了方法以优化生物声学任务的性能。此外，还研究了频率范围和噪声对模型性能的影响，展示了噪声鲁棒预训练设置的重要性。", "conclusion": "研究表明，基于语音的自监督学习模型在动物声音检测和分类中具有竞争力，展示了其作为生物声学研究高效框架的潜力，特别是在噪声环境下也表现出了鲁棒性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03918", "html_url": "https://arxiv.org/abs/2509.03918", "title": "MTQA：增强复杂问答推理的矩阵思维", "title_en": "MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question Answering", "authors": "Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao", "background": "复杂问题解答（QA）是自然语言处理（NLP）中的基本且具有挑战性的任务。尽管大型语言模型（LLMs）在QA任务上表现出色，但它们在面对复杂和抽象的QA任务时，由于推理能力不足，会出现显著的性能下降。现有的一些研究试图通过链式思维（CoT）和树式思维（ToT）来增强LLMs的推理能力，但仍存在树结构中的层内冗余和链结构中的单一路径路径的问题。尽管一些研究已经利用检索增强生成（RAG）方法来帮助LLMs进行推理，但仍面临如何有效地利用涉及多个实体和多重路径的大量信息的挑战。", "innovation": "本文提出了一种新型且高效的LLM思维结构——矩阵思维（MoT），通过“列单元通信”机制在水平和垂直两个维度上探索问题，使得LLMs能够进行多策略的多层次思考，减少列单元内的冗余并增强推理能力。此外，本文还开发了一个事实纠正机制，通过从检索的知识图谱三元组和原始文本中构建知识单元来增强初始知识，以提升LLMs推理的能力并纠正错误的答案，从而构建了一个高效且准确的QA框架（MTQA）。实验结果显示，本文提出的框架在四个广为使用的数据集上优于最先进的方法，在F1和EM分数上表现出色，推理时间仅为基线方法的14.4%，证明了其高效性和准确性。", "conclusion": "本文提出的矩阵思维结构（MoT）和MTQA框架能够有效解决复杂QA任务中的冗余和单一路径问题，通过多策略和深层次思考提高推理能力，同时通过事实纠正机制提高框架的准确性和效率。实验表明，该框架在多个基准数据集上取得了优于现有方法的结果，证明了其在复杂QA任务上的强大性能。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04154", "html_url": "https://arxiv.org/abs/2509.04154", "title": "注意力作为一种自适应滤波器", "title_en": "Attention as an Adaptive Filter", "authors": "Peter Racioppo", "background": "该研究引入了一种名为Adaptive Filter Attention（AFA）的新型注意力机制，该机制将可学习的动力学模型直接融入到注意力权重的计算中。传统注意力机制通常直接比较查询和键，而AFA则将输入序列视为线性随机微分方程（SDE）的离散观测值。通过引入一个同时对角化的状态矩阵和噪声协方差，利用微分Lypunov方程的闭式解来高效地传播链对不确定性，注意力权重自然成为此类线性SDE的最大似然解，对应于鲁棒残差重权化的传播链对精度权重。", "innovation": "AFA机制将线性的动力学模型直接纳入注意力权重的计算中，通过线性随机微分方程（SDE）来建模输入序列，并利用微分Lypunov方程的闭式解来高效地传播不确定性。特别地，通过对状态矩阵的特征值施加附加约束，可以简化AFA机制，使其在计算和内存复杂性方面与标准注意力机制相同。在动力学和过程噪声消失且使用小角度近似的情况下，可以恢复常规的点积注意力机制。", "conclusion": "AFA作为一种新型注意力机制，在处理连续时间信号以及引入动力学和噪声的情况下，能够提供更精确的注意力机制。通过仿真和实验证明，AFA能够在保留相同计算和内存复杂度的基础上，提升模型的精度。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04152", "html_url": "https://arxiv.org/abs/2509.04152", "title": "TAGAL：使用自主型LLM方法的表格数据生成", "title_en": "TAGAL: Tabular Data Generation using Agentic LLM Methods", "authors": "Benoît Ronval,Pierre Dupont,Siegfried Nijssen", "background": "生成数据是提升机器学习任务性能的常见方法，特别是在模型训练及分类任务中。本研究旨在提出一种方法，即TAGAL，这是一种能够利用代理性工作流程生成合成表格数据的方法。该方法利用了大型语言模型（LLMs）来进行自动化和迭代过程，通过反馈改进生成的数据，而无需进一步训练LLMs。利用LLMs还能在生成过程添加外部知识。研究通过多种数据集和不同质量方面，评估了TAGAL，并且考察了仅使用合成数据训练分类器以及结合真实和合成数据训练模型的效果。此外，还比较了真实数据和生成数据之间的相似性。研究结果表明，TAGAL的表现与需要LLM训练的最新方法相当，并且通常优于其他无需训练的方法。这些发现突显了代理性工作流程的潜力，并为基于LLMs的数据生成方法打开了新的研究方向。", "innovation": "TAGAL方法采用代理型工作流程生成合成表格数据，利用LLMs进行无监督的迭代生成，并可添加外部知识。与现有方法相比，TAGAL无需额外训练LLMs，这既节省了资源，又提高了数据生成的灵活性。此外，该方法能够生成与真实数据相似的数据，且部分场景下优于现有的需要LLM训练的方法，提供了一种新的数据生成策略。", "conclusion": "研究的结果表明，TAGAL能够在不进行LLM训练的情况下生成高质量的合成数据，并在应用程序中表现出色。这种代理性工作流程在数据生成领域展现出巨大潜力，同时也通过实验证实了现有基于LLMs的方法可以达到与需要LLM训练的方法相当的效果。这些发现开辟了新的研究方向，旨在进一步探索代理性数据生成方法及其潜在应用场景。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04243", "html_url": "https://arxiv.org/abs/2509.04243", "title": "通过自我演化的偏好优化学习主动感知以进行GUI定位", "title_en": "Learning Active Perception via Self-Evolving Preference Optimization for GUI Grounding", "authors": "Wanfu Wang,Qipeng Huang,Guangquan Xue,Xiaobo Liang,Juntao Li", "background": "近期视觉语言模型（VLMs）在视觉感知与语言推理之间的桥梁构建方面取得了重要进展。然而，在图形用户界面（GUI）定位任务中，引导视觉语言模型有效推理适宜的图像区域仍面临挑战，特别是在高分辨率输入和复杂多元素视觉交互下。", "innovation": "提出了LASER，一种自我演化框架，通过多步骤感知能力逐步增强视觉语言模型，实现精确的坐标预测。具体而言，该方法结合蒙特卡洛质量评估与基于交并比(IoU)的区域质量评估，共同促进高精度和多样性的构建，明确指导模型关注与指令相关的关键区域，并基于任务复杂性自适应分配推理步骤。", "conclusion": "在ScreenSpot Pro和ScreenSpot-v2基准上的全面实验显示了一致的性能提升，验证了该方法的有效性。此外，当微调于GTA1-7B时，LASER在ScreenSpot-Pro基准上获得了55.7的分数，确立了7B规模模型中的新最佳水平（SoTA）。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04288", "html_url": "https://arxiv.org/abs/2509.04288", "title": "基于数据驱动形式验证的锂离子电池系统鲁棒老化感知控制的强化学习", "title_en": "Reinforcement Learning for Robust Ageing-Aware Control of Li-ion Battery Systems with Data-Driven Formal Verification", "authors": "Rudi Coppola,Hovsep Touloujian,Pierfrancesco Ombrini,Manuel Mazo Jr", "background": "可充电的锂离子电池是现代技术的重要组成部分。近年来，电池的设计、生产和配套的充电和安全性协议（通过电池管理系统BMS实现）已成为技术发展的核心。然而，充电速度和电池老化之间的权衡是一个基本挑战，这会导致电池容量的损失。为了应对这一挑战，文章利用高保真物理电池模型，提出了一种数据驱动的充电和安全性协议设计方法。", "innovation": "文章采用了一种Counterexample-Guided Inductive Synthesis（基于反例归纳合成）方案，结合了强化学习（RL）和数据驱动的形式方法新进展，提出了混合控制策略。该方法使用RL合成分层控制器，然后使用数据驱动的抽象将这些分层控制器分配到切换结构中，依赖于初始的电池输出测量结果。最终的离散控制器选择与连续的电池动态相结合，形成了一个混合系统。当设计方案达到所需标准时，抽象可以提供对闭环电池性能的概率保证。", "conclusion": "文章提出的方法通过结合强化学习和数据驱动的形式验证，成功实现了一种鲁棒的老化感知控制策略，并且能够在特定条件下提供对电池性能的高概率保证，这对提高锂离子电池的可靠性和寿命具有重要意义。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04260", "html_url": "https://arxiv.org/abs/2509.04260", "title": "Python包中的漏洞及其检测的实证研究", "title_en": "An Empirical Study of Vulnerabilities in Python Packages and Their Detection", "authors": "Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du", "background": "在快速发展的软件开发领域，Python 以其简洁性、灵活性和广泛的生态系统而突出。Python 包作为组织、重用和分发的单位，引起了广泛关注，特别是在报告了大量安全漏洞的情况下。由于 Python 通常与其他语言配合使用以提高性能或实现互操作性，这就增加了 Python 包固有的安全问题的复杂性。当前的漏洞检测工具在这方面的作用尚不明确。", "innovation": "本文介绍了 PyVul，这是首个针对 Python 包漏洞的全面基准套件，包含 1,157 个公开报告并得到开发人员验证的漏洞，每个漏洞都与其受影响的包相关联。PyVul 提供了从提交和函数级别来进行注释的方法，以适应不同的检测技术。还结合了一种基于 LLM 的数据清理方法，提高了标签准确性，使 PyVul 成为最精确的大规模 Python 漏洞基准。研究表明，Python 包中的漏洞涉及多种编程语言，并且漏洞类型多样。此外，分析还表明，多语言 Python 包可能更易受到漏洞的影响。利用这一基准对最先进的检测器进行评估揭示了现有工具的当前能力和现实世界中有效识别 Python 包安全问题的需求之间的巨大差距。", "conclusion": "对 Python 包中常见 CWE 的统计分析进一步揭示了当前检测工具的细微限制，并突显了该领域未来进步的必要性。现有的漏洞检测工具在识别和解决问题方面的能力不足，需要进一步的研究和发展来改善。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04076", "html_url": "https://arxiv.org/abs/2509.04076", "title": "基于Keypoint的NICOL机器人运动计划的扩散模型", "title_en": "Keypoint-based Diffusion for Robotic Motion Planning on the NICOL Robot", "authors": "Lennart Clasmeier,Jan-Gerrit Habekost,Connor Gäde,Philipp Allgeuer,Stefan Wermter", "background": "通常，建立的数值规划方法被用来解决一般的运动规划问题，但这些方法存在显著的运行时间需求。本文提出了一种基于扩散的新颖动作模型来解决机器人运动规划问题。", "innovation": "通过利用深度学习的优势，该模型能够在较小的运行时间内取得良好结果，通过从由这些规划器生成的数据集中学习来实现。这一方法在测试集上达到了高达90%的无碰撞解决方案成功率达到，相比数值模型，其运行时间提高了10倍。", "conclusion": "尽管初始模型使用点云嵌入作为输入预测输出的关键点基关节序列，但在消融研究中发现条件化网络仍然困难重重。通过识别和改善数据集中的偏差，该模型在不使用点云编码的情况下仍显著优于数值模型。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04250", "html_url": "https://arxiv.org/abs/2509.04250", "title": "我们可以通过LLM先验信息节省多少患者？", "title_en": "How many patients could we save with LLM priors?", "authors": "Shota Arai,David Selby,Andrew Vargo,Sebastian Vollmer", "background": "当前临床试验需要大量患者以达到相同的统计功效，但通过以大型语言模型（LLM）编码的知识，未来临床试验可能只需要更少的患者。本文提出了一种新的框架，用于多中心临床试验中不良事件的分层贝叶斯建模，通过LLM提供先验分布。这种方法使用预训练的LLM系统地推导具有信息性的超参数先验，直接将外部临床专业知识纳入贝叶斯安全性建模。", "innovation": "该研究利用大型语言模型生成先验分布，直接获取参数先验，而不同于生成合成数据点的数据增广方法。通过全面的温度灵敏度分析和严格的交叉验证，证明LLM衍生的先验在预测性能方面优于传统元分析方法。这种方法为更有效的临床试验设计铺平了道路，允许大幅减少评估安全性所需的患者数量，并有可能变革药物安全性监控和监管决策过程。", "conclusion": "通过这种方法可以在实现稳健的安全评估的同时减少患者数量，提出了一种基于专家意见的贝叶斯安全模型的新途径，这是一种潜在的变革性方法，可以优化临床试验设计和药物监管。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04078", "html_url": "https://arxiv.org/abs/2509.04078", "title": "RepoDebug：大型语言模型在多任务和多语言仓库级别的调试评估", "title_en": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "authors": "Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang", "background": "大语言模型（LLMs）在代码调试方面表现出色，特别是在自动程序修复中，这可能显著减少开发人员的时间消耗并提高其效率。为促进代码调试的发展，已经取得了显著的进展，特别是在调试数据集方面。然而，现有的数据集主要关注于评估LLMs在功能级代码修复方面的能力，忽视了更复杂和真实的仓库级场景，导致对LLMs在仓库级调试中面临的挑战理解不完整。尽管提出了几个仓库级的数据集，但它们往往存在任务多样性、语言和错误类型的限制。", "innovation": "该论文介绍了RepoDebug，一个包含22种错误类型的多任务和多语言仓库级代码调试数据集，支持8种常用编程语言和3种调试任务。此外，还在10个LLMs上进行了评估实验，其中表现最好的Claude 3.5 Sonnect模型在仓库级调试中仍表现不佳。", "conclusion": "尽管LLMs在代码调试方面取得了一些进展，但现有数据集未能全面评估其在仓库级调试中的能力，特别是复杂的场景。RepoDebug旨在通过提供一个广泛且多样的数据集来填补这一空白，有助于更全面地评估LLMs的调试能力。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04337", "html_url": "https://arxiv.org/abs/2509.04337", "title": "Pinch-Based Decoupled Entity Representation Learning for Pinterest Ads Ranking", "title_en": "Decoupled Entity Representation Learning for Pinterest Ads Ranking", "authors": "Jie Liu,Yinrui Li,Jiankai Sun,Kungang Li,Han Sun,Sihan Wang,Huasen Wu,Siyuan Gao,Paulo Soares,Nan Li,Zhifang Liu,Haoyang Li,Siping Ji,Ling Leng,Prathibha Deshikachar", "background": "Pinterest依赖用户和Pin（产品）的个性化推荐来有效提供个性化的内容和服务。为了实现这一目标，需要从多元化数据源中构建用户和Pin嵌入。通过复杂的模型架构捕捉用户和Pin之间的内在关系，进而提高推荐系统的性能。", "innovation": "论文提出了一种分阶段的实体表示学习框架，按照上游-下游的范式从多种数据源中构建用户和Pin嵌入，解决大规模数据模型的可扩展性问题。上游模型通过非实时计算学习实体嵌入，并定期更新，以支持与下游模型的异步交互。这些嵌入被集成到各种下游任务中，包括广告检索和排序模型，用于CTR和CVR预测，从而显著提升预测性能。", "conclusion": "通过实证研究展示了该框架在不同下游任务中获得了令人满意的性能提升，并已在Pinterest的生产广告排名系统中部署，带来了在线指标的显著改进。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04009", "html_url": "https://arxiv.org/abs/2509.04009", "title": "通过令牌丢弃检测视觉变换器中的区域伪相关性", "title_en": "Detecting Regional Spurious Correlations in Vision Transformers via Token Discarding", "authors": "Solha Kang,Esla Timothy Anzaku,Wesley De Neve,Arnout Van Messem,Joris Vankerschaver,Francois Rameau,Utku Ozbulak", "background": "由于神经网络在计算机视觉中的强大特征关联能力，它们能够检测并利用数据中的非预期模式，从而可能基于错误或非预期但统计上相关的信息进行正确的预测。这些线索可以从简单的颜色偏差到图像内的小文字不等。当这些非预期线索与预测任务对齐时，模型可能会错误地将这些特征与任务关联起来，并依赖它们进行预测。这一现象被称为伪相关性，指的是看似与任务相关但实际上只是偶然相关的模式。因此，检测并消除伪相关性对于构建可信赖、可靠且可泛化的机器学习模型至关重要。", "innovation": "本研究提出了一种新型方法，用于检测视觉变换器中的伪相关性。视觉变换器在近年来获得了广泛应用。该研究采用监督和自我监督两种训练方法，在ImageNet数据集上进行了大规模实验，展示了所提出方法识别伪相关性的能力。研究还发现，即使使用相同的架构，不同的训练方法也会对模型依赖伪相关性产生重大影响。此外，研究还表明ImageNet数据集中某些类别的图像包含易被模型检测到的伪信号，并讨论了这些伪信号的潜在原因。基于研究结果，研究人员提供了一份详尽的上述图像列表，并呼吁在未来的研究中要有所谨慎。最后，研究通过一个案例研究，在侵入性乳腺肿块分类中探讨了伪信号，将研究与现实世界的情景相结合。", "conclusion": "鉴于以上发现，作者提供了一张详尽列出受影响图像的清单，并对它们在后续研究中的使用表示谨慎。此外，研究通过分析视觉变换器中的伪信号，为实际应用场景中的机器学习模型应用提供了案例研究支持。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04304", "html_url": "https://arxiv.org/abs/2509.04304", "title": "事实迅速消逝：大型语言模型对过时医学知识的记忆评估", "title_en": "Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge in Large Language Models", "authors": "Juraj Vladika,Mahdi Dhaini,Florian Matthes", "background": "大型语言模型（LLMs）的能力增长显示出在医疗领域辅助研究人员和医生的巨大潜力。然而，这些模型依赖于静态训练数据，这在医学知识不断更新的情况下成为一种重大风险。当LLMs储存过时的医学知识时，它们可能会提供有害的建议或在临床推理任务中失败。为了研究这一问题，我们引入了两个新数据集：MedRevQA（包含16,501个问答对，涵盖一般生物医学知识）和MedChangeQA（包含512个问答对，其中医学共识随时间发生变化）。", "innovation": "该研究引入了两个新的问答数据集MedRevQA和MedChangeQA，评估了八个流行的LLMs在这些数据集上的性能，揭示了模型对过时知识的一致依赖性。研究还分析了过时预训练数据和训练策略的影响，提出了缓解该问题的未来方向，为开发更具时效性和可靠性的医疗AI系统奠定了基础。", "conclusion": "研究结果表明所有模型都依赖于过时的知识，并分析了这一现象的原因。提出了未来研究方向，为提高医疗AI系统的当前性和可靠性提出了建议。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04303", "html_url": "https://arxiv.org/abs/2509.04303", "title": "HumAIne-Chatbot: 通过强化学习实现实时个性化对话式AI", "title_en": "HumAIne-Chatbot: Real-Time Personalized Conversational AI via Reinforcement Learning", "authors": "Georgios Makridis,Georgios Fragiadakis,Jorge Oliveira,Tomaz Saraiva,Philip Mavrepis,Georgios Fatouros,Dimosthenis Kyriazis", "background": "当前的对话式AI系统通常提供一刀切的交互，忽视了用户的个性化特点，缺乏适应性对话管理。", "innovation": "提出了一个名为HumAIne-chatbot的AI驱动对话代理，通过一个新颖的用户画像框架来个性化响应。该系统在多样化的GPT生成的虚拟人物上进行预训练，来建立广泛的用户类型先验知识。在线上交互中，通过串联使用隐式信号（例如打字速度、情感、参与时间）和显式反馈（例如喜欢和不喜欢）来细化用户的模型。这种画像动态地指导聊天机器人的对话策略，实现实时的内容和风格调整。通过与50个合成人物在多个对话域的受控实验，证明了启用个性化功能后，用户满意度、个性化准确性和任务完成度均得到了一致的提升。统计分析确认了个性化条件和非个性化条件在关键指标上的显著差异和巨大效应量，突显了AI驱动的用户画像的有效性，并为未来现实世界的验证提供了坚实的基础。", "conclusion": "这些结果强调了AI驱动的用户画像的有效性，并为未来实际场景中的验证打下了坚实的基础。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04357", "html_url": "https://arxiv.org/abs/2509.04357", "title": "PARCO: 声母增强的鲁棒上下文自动语音识别通过对比实体消歧", "title_en": "PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity Disambiguation", "authors": "Jiajun He,Naoki Sawada,Koichi Miyazaki,Tomoki Toda", "background": "自动语音识别（ASR）系统在特定领域的命名实体识别方面存在困难，特别是对于同音词。虽然上下文ASR可以提高识别率，但往往难以捕捉细微的音素变异，这主要是由于实体多样性的限制。此外，先前的方法将实体视为独立的标记，导致多标记偏置不完整。", "innovation": "本文提出了一种名为PARCO的方法，该方法结合了音素意识编码、对比实体消歧、实体级监督和层级化实体筛选。这些组成部分增强了音素的区分力，确保了实体完全检索，并在不确定性下减少了假阳性的产生。实验结果表明，PARCO在1,000个干扰项下，中文AISHELL-1的CER为4.22%，英语DATA2的WER为11.14%，显著优于基线方法。PARCO还在THCHS-30和LibriSpeech等跨域数据集上表现出鲁棒性增益", "conclusion": "PARCO在特定领域的命名实体识别方面表现出显著的优势，特别是在处理同音词时能够更准确地识别。经过验证，PARCO不仅在控制实体偏置方面有明显的改进，而且在多种ASR数据集上都取得了优异的表现。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04345", "html_url": "https://arxiv.org/abs/2509.04345", "title": "AUDETER: 面向开放世界中的深度假音检测的大规模数据集", "title_en": "AUDETER: A Large-scale Dataset for Deepfake Audio Detection in Open Worlds", "authors": "Qizhou Wang,Hanxun Huang,Guansong Pang,Sarah Erfani,Christopher Leckie", "background": "语音生成系统能够生成极其逼真的人声，这些声音经常难以与人类语音区分开来。尽管已经开发了多种深度假音检测方法，但在实际应用场景中，这些方法的有效性仍然不可靠，特别是在训练样本和测试样本之间存在领域偏移的情况下，这主要由于人类语音的多样性以及快速发展的语音合成系统的多样性。现有的数据集没有充分涵盖这些挑战，特别是缺乏包含真实世界应用挑战的多样化且更新的音频。因此，需要一个能够全面评估和促进通用模型发展的大规模、高度多样化的深度假音音频数据集来解决这个问题。", "innovation": "提出了一个名为AUDETER的大规模、高度多样化的人声深度假音数据集，用于全面评估和开发通用型深度假音音频检测模型。该数据集包含超过4,500小时由11个最新TTS模型和10种声码器生成的合成音频，总共有300万段音频剪辑，是迄今为止规模最大的深度假音音频数据集。通过使用AUDETER进行广泛的实验，发现现有的最先进的方法难以泛化到新的深度假音音频样本，并且在未见过的人声上具有较高的误报率，突出了全面数据集的必要性。同时，使用AUDETER训练的方法在检测性能上有了显著提升，并将错误率降低了44.1%到51.6%，实现了流行In-the-Wild数据集在多样化跨域样本上的4.17%的错误率，为训练通用型深度假音检测器铺平了道路。", "conclusion": "通过AUDETER，能够实现深度假音检测器的广泛泛化表现，显著降低错误率，并能有效应对不同领域的真实声音。目前，AUDETER已在GitHub上公开。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04398", "html_url": "https://arxiv.org/abs/2509.04398", "title": "IPA：一种高效基础模型适配的保留信息输入投影框架", "title_en": "IPA: An Information-Preserving Input Projection Framework for Efficient Foundation Model Adaptation", "authors": "Yuan Yin,Shashanka Venkataramanan,Tuan-Hung Vu,Andrei Bursuc,Matthieu Cord", "background": "PEFT方法，如LoRA，通过向预训练权重中注入低秩更新来减少适应成本。然而，LoRA的下投影是随机初始化和数据无关的，可能会丢弃有用的信息。先前的研究表明，该投影在训练过程中变化很小，而上投影承担了主要的适应性工作，使得随机输入压缩成为性能瓶颈。", "innovation": "提出了一种特征感知的投影框架IPA，该框架明确地在压缩的隐藏空间中保留信息。在线性情况下，IPA使用近似主成分的算法实例化投影器，可以实现高效的预训练，且推断开销几乎可以忽略不计。在语言和视觉基准测试中，IPA在常识推理方面平均比LoRA和DoRA高1.5分，在VTAB-1k方面高2.3分，在投影冻结的情况下，IPA的可训练参数仅为全量LoRA的一半左右，但仍能达到其同等性能", "conclusion": "IPA框架在语言和视觉基准测试中均表现出比LoRA和DoRA更优的效果，且通过冻结投影，在减少一半可训练参数的情况下能与全量LoRA保持同等性能。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04362", "html_url": "https://arxiv.org/abs/2509.04362", "title": "使用自我监督学习增强的时空倒置变换器融合多源数据进行停车可用性预测", "title_en": "Parking Availability Prediction via Fusing Multi-Source Data with A Self-Supervised Learning Enhanced Spatio-Temporal Inverted Transformer", "authors": "Yin Huang,Yongqi Dong,Youhua Tang,Li Li", "background": "私人汽车拥有量的快速增长加剧了城市停车问题，突显了准确有效的停车可用性预测对于支持城市规划和管理的重要性。已有模型在建模空-时依赖及利用多源数据方面存在关键局限，亟需改进模型解决这些问题以更好地支持城市停车管理。", "innovation": "本研究提出了一种基于SST-iTransformer的新方法，通过K-means聚类建立停车区域，并从地铁、公交车、在线快车和出租车等不同交通方式中提取和整合与目标停车场相关的交通需求特征。SST-iTransformer在此基础上，通过掩码重建预训练任务增强时空表示学习，并引入创新的双分支注意机制：时间序列注意机制通过补丁操作捕获长期的时序依赖性，通道注意机制通过反转维度建模跨变量交互。实验证明，该模型在成都市的真实数据上性能优于基准深度学习模型，并且在不同数据源融合时表现出显著的优势，特别是在快车数据的利用上表现出最大的性能增益，这进一步证明了时空依赖建模的重要性。", "conclusion": "研究表明，SST-iTransformer模型在停车可用性预测方面表现出最佳性能，具有最小的均方误差和竞争力的均绝对误差。此外，排除相关停车区域的历史数据导致性能大幅下降，证明了建模时空依赖的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04441", "html_url": "https://arxiv.org/abs/2509.04441", "title": "DEXOP: 一种用于传递灵巧人类操作的装置", "title_en": "DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation", "authors": "Hao-Shu Fang,Branden Romero,Yichen Xie,Arthur Hu,Bo-Ruei Huang,Juan Alvarez,Matthew Kim,Gabriel Margolis,Kavya Anbarasu,Masayoshi Tomizuka,Edward Adelson,Pulkit Agrawal", "background": "本文介绍了perioperation这一理念，通过传感器化和记录人类操作来收集机器人数据，并最大化数据在真实机器人之间的可移植性。研究通过DEXOP设计来实现这一理念，DEXOP是一种被动的手部外骨骼，其目的是在自然环境中最大化人类收集触觉（视觉与触觉）数据的潜力，用于执行多样的灵巧操作任务。", "innovation": "本文创新之处在于引入了DEXOP，一种被动手部外骨骼，它机械地连接人类手指与机器人手指，提供用户直接触觉反馈，并将人类手的姿势镜像到被动机器人手上，以最大化演示技能向机器人的转移。此外，通过DEXOP采集的数据训练出的机器人策略，与通过遥操作训练出的策略相比，显著提高了任务执行效率。", "conclusion": "本文通过不同的威斯敏斯特任务验证了DEXOP的有效性，表明DEXOP能够大规模收集高质量的演示数据。与传统遥操作相比，使用DEXOP获取的数据训练出的策略显著提高了任务执行时间和准确性，证明了DEXOP作为提升机器人灵巧度的强大工具的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04013", "html_url": "https://arxiv.org/abs/2509.04013", "title": "关于大型语言模型基准评估稳健性和可靠性", "title_en": "On Robustness and Reliability of Benchmark-Based Evaluation of LLMs", "authors": "Riccardo Lunardi,Vincenzo Della Mea,Stefano Mizzaro,Kevin Roitero", "background": "当前大型语言模型（LLMs）的有效性通常通过MMLU、ARC-C或HellaSwag等benchmark进行评估，这些benchmark中的问题以固定的标准化格式呈现。然而，实际应用场景中涉及语言多样性，要求模型能够有效处理各种不同措辞的同一问题或查询。研究者指出，现有基准评估可能无法全面反映模型的实际情况，因此需要系统化评估LLMs对重新措辞的benchmark问题的稳健性。", "innovation": "本研究系统生成六种常见的benchmark中所有问题的多种重述版本，并评估34种不同规模和性能的顶级LLMs在这次多样性评估中的表现变化。研究发现，尽管LLM的排名相对稳定，但绝对表现分数变化显著，而且表现出明显下降，表明LLMs在面对语言变异性时存在困难，这质疑了现有评估方法的有效性和可靠性。此外，观察到的表现下降挑战了基于benchmark的评估的可靠性，意味着高基准得分可能未能全面捕捉到模型对实际输入变异的鲁棒性。", "conclusion": "研究揭示，尽管LLM在重新措辞的输入上排名相对稳定，但其绝对表现急剧下降，表明LLM对语言变异性难以应对。这引发了对现有评估方法可靠性的担忧，同时也强调了需要开发更多的、更加注重鲁棒性的benchmark来更好地反映实际部署场景。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04338", "html_url": "https://arxiv.org/abs/2509.04338", "title": "从编辑器到稠密几何估计器", "title_en": "From Editor to Dense Geometry Estimator", "authors": "JiYuan Wang,Chunyu Lin,Lei Sun,Rongying Liu,Lang Nie,Mingxing Li,Kang Liao,Xiangxiang Chu,Yao Zhao", "background": "利用预训练的文本到图像(T2I)生成模型的视觉先验已经在密集预测方面取得了成功。然而，密集预测本质上是一个图像到图像的任务，暗示图像编辑模型可能比T2I生成模型更适合进行微调以实现准确的稠密几何估计。基于这一发现，该研究对编辑器和生成器的微调行为进行了系统的分析，显示编辑模型具有内在的结构先验，这使它们能通过‘完善’内在特性更稳定地收敛，并最终达到比生成器更优的性能。", "innovation": "提出了FE2E框架，这是首个基于扩散变换器（DiT）架构的先进编辑模型适应用于稠密几何预测的解决方案。具体来说，通过将编辑器原本的流匹配损失重新定义为一致速度训练目标，并利用对数量化解决编辑器内部的BFloat16格式与任务需求高精度的冲突。此外，采用DiT的全局注意力实现无成本的深度和法线联合估计，使得它们的监督信号相互增强。", "conclusion": "FE2E在零样本单目深度和法线估计方面实现了显著的性能改进，并且在多个数据集上未扩大训练数据的情况下实现了这一改进。特别地，在ETH3D数据集上提高了超过35%的性能，并优于训练数据量扩大了100倍的DepthAnything系列。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04419", "html_url": "https://arxiv.org/abs/2509.04419", "title": "统一视角下大规模语言模型后训练方法的研究", "title_en": "Towards a Unified View of Large Language Model Post-Training", "authors": "Xingtai Lv,Yuxin Zuo,Youbang Sun,Hongyi Liu,Yuntian Wei,Zhekai Chen,Lixuan He,Xuekai Zhu,Kaiyan Zhang,Bingning Wang,Ning Ding,Bowen Zhou", "background": "现有大规模语言模型的后训练数据来源主要有两种：在线数据（模型生成的回溯）和离线数据（人类或模型演示）。RL和SFT等方法分别使用这两种数据。本研究指出，这些方法并非互相排斥，而是单一优化过程的不同实例。研究旨在通过理论推导，统一不同类型方法的优化过程，并提出Hybrid Post-Training（HPT）算法，实现有效的演示利用和稳定探索，同时保留学习到的推理模式。并通过多种实验验证研究的有效性。", "innovation": "提出了统一的策略梯度估计器，并基于理论推导提出了Hybrid Post-Training（HPT）算法。HPT算法能够动态选择不同训练信号，有效地利用演示数据，同时保持稳定探索，并且展示了HPT在多种基准测试中效果优于现有强大基线的方法。", "conclusion": "研究通过理论统一了大量语言模型后训练的不同方法，并提出了一种新型算法HPT，能够有效利用演示数据，实现稳定探索，其在多种基准测试中显著优于现有基线。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04404", "html_url": "https://arxiv.org/abs/2509.04404", "title": "无意识只有AI：偏向性的LLM推荐限制了简历筛选中的人类自主权", "title_en": "No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in Resume Screening", "authors": "Kyra Wilson,Mattea Sim,Anna-Maria Gueorguieva,Aylin Caliskan", "background": "研究在一个模拟AI模型具有种族偏见的简历筛选实验中，考察了人们在高和低地位职业中的偏好。实验涉及528名参与者，评估了16种职业的候选人，发现当没有AI或AI没有种族偏见时，人们对所有候选人选择率均等。但是，当与偏好特定群体的AI互动时，人们也更倾向于选择该人群至90%的频率。此外，完成无意识关联测试可以增加选择与常见种族地位刻板印象不一致的候选人的概率。即使人们认为AI推荐质量低或不重要，但在特定情况下，他们的决策仍然可能受到AI偏见的影响。这项工作对人类在AI-HITL场景中的自主性、AI与工作、AI招聘系统的评估和减少协作决策任务中偏见的策略具有重要意义。", "innovation": "研究通过结合AI偏见实验和隐性关联测试探索了人类与AI协作中的偏见问题，这是首次在人类-AI协作中调查隐性关联测试对歧视性招聘决策的影响，揭示了即使在人工智能推荐质量被认为较低的情况下，人们仍可能受到其偏见的影响。这项工作为理解和解决AI协作决策中的偏见提供了新的视角。", "conclusion": "研究发现，人们在AI偏见影响下对不同种族背景的候选人存在明显的偏好倾向，即使明知AI推荐可能存在问题或不重要，这类偏见也可能导致人们的决策受到影响。研究结果强调了在AI-HITL场景中，增强人们的知识和意识，设计更具公平性的AI系统以及制定有效的缓解措施的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2311.17165", "html_url": "https://arxiv.org/abs/2311.17165", "title": "AI中的(非)理性：现状、研究挑战与开放问题", "title_en": "(Ir)rationality in AI: State of the Art, Research Challenges and Open Questions", "authors": "Olivia Macmillan-Scott,Mirco Musolesi", "background": "理性是人工智能领域的核心概念。无论是模拟人类推理还是追求有限最优性，我们的目标是使人工代理尽可能理性。尽管理性概念在人工智能中至关重要，但目前尚未形成统一的理性代理定义。本文综述了AI中的理性与非理性现象，并指出了该领域的开放问题。作者考察了其他领域（如经济学、哲学和心理学）对理性理解的变化如何影响AI中的理性概念。", "innovation": "本文提供了关于AI中理性与非理性现象的综述性研究，并对其开放问题进行了深入讨论，特别关注如何利用其他领域的工作（如对抗场景方法）来处理与人工代理交互中的非理性问题。此外，文章讨论了人类与人工代理之间的互动关系以及理性在这一过程中的角色。", "conclusion": "尽管已有方法用于识别和处理人工代理的非理性行为，但这方面的研究仍处于初级阶段。未来的研究应探索如何在AI中更好地理解和应用理性与非理性概念，特别是在人类与人工代理交互的背景下。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04442", "html_url": "https://arxiv.org/abs/2509.04442", "title": "Delta Activations: 一种精细化大型语言模型的表示方法", "title_en": "Delta Activations: A Representation for Finetuned Large Language Models", "authors": "Zhiqiu Xu,Amish Sethi,Mayur Naik,Ser-Nam Lim", "background": "强大的开源大型语言模型的成功应用激发了社区开发针对特定任务和领域的后训练模型。然而，导航和理解这些模型仍然具有挑战性，因为存在不一致的元数据和不结构化的存储库。", "innovation": "本文提出了一种名为Delta Activations的方法，通过测量模型相对于基模型的内部激活的变化来表示已后训练模型的向量嵌入，这使得按领域和任务进行有效的聚类成为可能，揭示了模型景观中的结构。此外，Delta Activations还展示了良好的属性，如在不同后训练设置下具有鲁棒性，并且在混合数据集时表现出加性特性。该方法还显示了通过少样本后训练嵌入任务的能力，并进一步探讨了其在模型选择和合并中的应用。", "conclusion": "我们希望Delta Activations能够促进公共可用模型的重用实践。相关的代码可以在该链接中获得。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.08949", "html_url": "https://arxiv.org/abs/2410.08949", "title": "量子电路中的可转移信念模型", "title_en": "Transferable Belief Model on Quantum Circuits", "authors": "Qianli Zhou,Hao Luo,Lipeng Pan,Yong Deng,Eloi Bosse", "background": "可转移信念模型是一种概率解释微观斯佛-沙夫理论，使代理能够在不精确且不完整环境中进行推理和决策。该模型提供了处理不可靠证词的独特语义，使得信念转移过程比贝叶斯方法更加合理和通用。但是，由于在更新信念函数时必须同时考虑信念质量及焦点集的结构，这增加了推理中的额外计算复杂性，导致该模型近年来逐渐不被研究者青睐。", "innovation": "本研究将可转移信念模型应用于量子电路，并表明在量子计算框架中信念函数相比贝叶斯方法更具有简洁性和有效性。同时，利用量子计算的独特特性，提出了几种新型的信念转移方法，为量子人工智能模型的基本信息表示提供了一个新的视角，认为信念函数比贝叶斯方法更适合处理量子电路中的不确定性问题。", "conclusion": "本研究通过在量子电路中实现可转移信念模型，表明作为一种信息表示方法，信念函数能够更有效地解决量子计算中的不确定性问题，开启了量子AI中新的研究方向。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04379", "html_url": "https://arxiv.org/abs/2509.04379", "title": "SSGaussian: 保留语义和结构的3D风格迁移", "title_en": "SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer", "authors": "Jimin Xu,Bosheng Qin,Tao Jin,Zhou Zhao,Zhenhui Ye,Jun Yu,Fei Wu", "background": "近年来，神经表示如神经辐射场和三维高斯斑点的发展增加了将风格迁移应用于3D场景的兴趣。现有的方法虽然能够将风格模式应用于3D一致的神经表示，但在从参考风格图像中有效提取和转移高层次的风格语义方面却存在问题。此外，风格化结果往往缺乏结构清晰度和分离性，使得在3D场景中区分不同实例或对象变得困难。", "innovation": "提出了一种新颖的3D风格迁移流水线，有效将预训练的2D扩散模型的先验知识整合起来。该流水线包含两个关键阶段：首先使用扩散先验生成关键视角的风格化渲染图。然后，将风格化的关键视角传递到3D表示。这一过程包含两个创新设计。首先是视角间风格对齐，该设计将跨视角注意力插入到UNet的最后一上采样块中，允许多个关键视角之间的特征交互。这确保了扩散模型生成的风格化关键视角既保持风格保真度也保持实例级一致性。其次是实例级风格迁移，该设计有效地利用了风格化关键视角之间实例级的一致性，并将其转移到3D表示上，从而导致更具结构化、视觉整体性和艺术丰富性的风格化。", "conclusion": "广泛的定性和定量实验表明，我们的3D风格迁移流水线在场景范围广泛，从前方视角到挑战性的360度环境，显著优于现有技术。可以在我们的项目页面 <this https URL> 了解更多沉浸式可视化信息。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04449", "html_url": "https://arxiv.org/abs/2509.04449", "title": "ChronoGraph:一个基于真实世界的图形化的多变量时间序列数据集", "title_en": "ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset", "authors": "Adrian Catalin Lutu,Ioana Pintilie,Elena Burceanu,Andrei Manolache", "background": "现有的时间序列数据集主要来源于工业控制系统或交通、空气质量领域，多变量时间序列数据和显式的机器可读的依赖图这两个方面较为缺乏，而ChronoGraph数据集则填补了这一空缺。该数据集来自真实的生产微服务，能够捕捉CPU、内存和网络使用模式，同时包含服务间的依赖关系。与过往研究相比，ChronoGraph的独特在于集成多变量时间序列数据、显式的机器可读的依赖图以及与实际情况相符的异常标签。", "innovation": "ChronoGraph数据集创新性地结合了多变量时间序列数据、显式的机器可读的依赖图以及与实际情况相符的异常标签。它填补了目前在工业控制系统或交通、空气质量等领域时间序列数据集所缺乏的多变量时间序列和显式依赖图的空白，并提供了一个现实基准用于研究结构感知的预测以及事件感知的评估在微服务系统中的应用。", "conclusion": "ChronoGraph提供了广泛的基准结果，包括预测模型、预训练的时间序列基础模型以及标准异常检测器的基准结果。该数据集为研究面向结构的预测和面向事件的评估提供了一个现实基准，并特别强调了微服务系统中的应用。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2008.07324", "html_url": "https://arxiv.org/abs/2008.07324", "title": "Intelligence Primer", "title_en": "Intelligence Primer", "authors": "Karl Fezer,Andrew Sloss", "background": "智能是所有生物的基本组成部分，也是人工智能的基础。本文探讨了与智能相关的概念，并通过此过程理解其含义、影响和限制，从而推测未来系统的潜在能力。随着机器学习形式的人工智能对人们的生活产生了重大影响，本文探索了似乎是智能关键组成部分的不同方面。历史学家尤瓦尔·赫拉利指出，未来的工程师和科学家需要扩展他们的知识范围，包括心理学、哲学和伦理学。在现代社会中，人工智能的出现和法律要求是促使这些更广泛学科进入舞台的推动力。", "innovation": "本文被称为“生命、宇宙和一切”的入门指南，通过探讨智能的各种概念和思想，希望能够帮助人们了解智能的概念，并提出新问题。这项工作强调智能不仅仅是一个可测量的量，而是跨越生物学、物理学、哲学、认知科学、神经科学、心理学和计算机科学的领域。通过这种全面的视角，本文旨在促进对智能更深层次的理解。", "conclusion": "智能是一个多学科的领域，本文探讨了智能的关键概念和深刻思想。强调了对智能的理解将涉及到生物学、物理学、哲学、认知科学、神经科学、心理学和计算机科学等多个领域。本文提出，未来的工程师和科学家需要更广泛地学习这些领域以适应人工智能的发展。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.05248", "html_url": "https://arxiv.org/abs/2412.05248", "title": "提升FKG.in: 印度食品成分分析的自动化", "title_en": "Enhancing FKG.in: automating Indian food composition analysis", "authors": "Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das,Geeta Trilok-Kumar,Ramesh Jain", "background": "本文介绍了使用印度食物知识图谱（FKG[.]in）和大规模语言模型（LLMs）计算印度菜谱食品成分的新方法。重点在于提供一个自动化食品成分分析工作流的概述，描述其核心功能：营养数据聚合、食品成分分析以及依赖于LLM的信息增强。此外，阐述了表示印度食品和数字化获取食品成分数据的挑战。还回顾了三种主要的食品成分数据来源：印度食品成分表格、印度营养数据库以及Nutritionix API。最后简要说明了用户如何与该工作流互动，以获取基于饮食的健康建议和大量菜谱的详细食品成分信息。文中探讨了分析印度菜谱信息时面临的复杂挑战，包括结构、多语言性和不确定性，并展示基于LLM的解决方法。", "innovation": "提出了自动化印度食品成分分析工作流的新方法，借助印度食物知识图谱（FKG[.]in）和大规模语言模型（LLMs）。提供了一个全面的自动化方案，包括营养数据分析和增强的信息处理，以补充和迭代验证的数据源。还针对印度菜谱信息的复杂性提出了基于LLM的特定问题解决方法。", "conclusion": "本文揭示了在不同维度上分析印度菜谱信息的复杂性，提出的方法具有应用广泛性、通用性和可复制性，能够适用于任何领域。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.13923", "html_url": "https://arxiv.org/abs/2406.13923", "title": "PIN: 配对和插混多模态文档的一种知识密集型数据集", "title_en": "PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents", "authors": "Junjie Wang,Yuxiang Zhang,Minghao Liu,Yin Zhang,Yatai Ji,Weihao Xuan,Nie Lin,Kang Zhu,Zhiqiang Lin,Yiming Ren,Chunyang Jiang,Yiyao Yu,Zekun Wang,Tiezhen Wang,Wenhao Huang,Jie Fu,Qunshu Liu,Yujiu Yang,Ge Zhang,Ruibin Yuan,Bei Chen,Wenhu Chen", "background": "近年来，大规模多模态模型（LMMs）利用大规模多模态数据集增强了在复杂知识驱动任务中的能力。然而，感知和推理错误持续存在，特别是在解释复杂的视觉数据和推断多模态关系方面限制了其有效性。", "innovation": "本文引入了PIN（Paired and INterleaved multimodal documents）格式，是一种新颖的数据格式，旨在促进视觉和文本知识的更深层次集成。PIN格式结合了富含语义的Markdown文件，以保持细粒度的文本结构，和全面的整体图像，以捕捉文档的整体布局。此外，还构建并公开了两个大规模、开源的数据集：PIN-200M（约2亿文档）和PIN-14M（约1400万），数据来源于多源网络和科学资料，包含英文和中文。为了提高易用性，提供了详细的数据统计分析，并提供质量信号，使研究人员能够方便地筛选和选择数据以用于特定任务。", "conclusion": "本文为社区提供了灵活的数据格式和丰富资源，为预训练策略的研究提供了一个基础，并有望促进更强大知识密集型LMMs的发展。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.11671", "html_url": "https://arxiv.org/abs/2504.11671", "title": "LLM决策在社会模拟中的计算基础", "title_en": "Computational Basis of LLM's Decision Making in Social Simulation", "authors": "Ji Ma", "background": "大型语言模型（LLMs）在社会科学和实际应用中越来越多地扮演类人的决策代理角色。这些LLM代理通常赋予类人的性格特征，并置于实际生活情境中。然而，这些性格特征和情境如何塑造LLM的行为还鲜有研究。本研究通过探讨和测试几种方法来探测、量化和修改LLM在决策实验中的内部表示，提出了一种原理性的方法，通过操纵模型推理过程中提取的向量（如“男”到“女”），显著改变这些变量与模型决策之间的关系。这一方法揭示了如何在基于转换器的模型中编码和工程化社会概念，具有对齐、去偏见以及为社会科学模拟设计AI代理的应用前景。", "innovation": "本研究提出并测试了几种探针、量化和修改大型语言模型（LLMs）内部表示的方法，尤其在经典的公平性和亲社会行为实验中。通过操纵模型推理过程中提取的向量，显著改变这些变量与模型决策之间的关系，提供了一种原理性的方法来研究和调控社会概念在基于转换器模型中的编码和工程化。", "conclusion": "本研究揭示了如何通过操纵大型语言模型在推理过程中的内部表示向量，显著改变这些变量与模型决策之间的关系。该方法为研究和调控社会概念在基于转换器模型中的编码和工程化提供了原理性的方式，具有对齐、去偏见以及为社会科学模拟设计AI代理的应用前景，从而增强社会学理论和量度。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.18970", "html_url": "https://arxiv.org/abs/2410.18970", "title": "WASP: 一种检测学习到的偏见的权重空间方法", "title_en": "WASP: A Weight-Space Approach to Detecting Learned Spuriousness", "authors": "Cristian Daniel Păduraru,Antonio Bărbălau,Radu Filipescu,Andrei Liviu Nicolicioiu,Elena Burceanu", "background": "训练机器学习模型时，确保模型清晰理解每个类别的定义至关重要。尽管有很多研究致力于识别可能影响模型对类理解的数据集中的假相关性，但当前的方法都依赖于数据或错误分析，无法识别模型中通过微调学习到的未由训练或验证反例指出的假相关性。这项工作提出了一种新的方法，即权重空间方法（WASP），通过分析模型权重在捕捉各种（假）相关性过程中的变化，提供了一种更为深入的分析途径，不同于以往方法，WASP能够在假相关性未被反例揭示时将其揭露，适用于多种模态（如图像和文本），并能发现ImageNet-1k分类器中的先前未被发现的假相关性。", "innovation": "WASP方法不依赖于数据或错误分析，而是通过分析模型权重来检测已学习到的假相关性，这种方法更为深入，能揭示未被训练或验证反例揭露的假相关性，适用于多种模态且能发现以前未被发掘的假相关性，特别适用于微调的模型中发现细微的假相关性问题。", "conclusion": "WASP方法能更深入地揭示模型学习的假相关性，适用于多种数据模态，并能发现之前未被发掘的假相关性，为理解模型决策提供了新的视角。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03315", "html_url": "https://arxiv.org/abs/2506.03315", "title": "通过集合的线性顺序及其最小元素作为后备选择的限制选择的公理化", "title_en": "Axiomatics of Restricted Choices by Linear Orders of Sets with Minimum as Fallback", "authors": "Kai Sauerwald,Kenneth Skiba,Eduardo Fermé,Thomas Meyer", "background": "本文研究了如何使用线性顺序来实现局限于某些备选集的选择函数。在这种备选集受限的情景中，通过关系来建立选择函数并不总是可行的。尽管如此，本文展示了即使将后备值编码为线性顺序中的最小元素，也可以通过集合的线性顺序来构建选择函数。", "innovation": "本文的核心创新在于提出了一种通过集合的线性顺序及其最小元素来构建选择函数的方法，并为一般情况下的选择函数以及并封闭输入限制下的选择函数提供公理化。", "conclusion": "本文讨论了限制选择结构在知识表示和推理方面的应用，特别是在理论变化和抽象论证方面的应用，展示了这些限制选择结构在特定场景下的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.17882", "html_url": "https://arxiv.org/abs/2502.17882", "title": "科学跨语言：评估大语言模型多语言翻译科学论文", "title_en": "Science Across Languages: Assessing LLM Multilingual Translation of Scientific Papers", "authors": "Hannah Calzi Kleidermacher,James Zou", "background": "科学研究本质上是全球性的，然而，大多数学术期刊仅以英语出版，这为非英语母语的研究者设定了障碍。为了解决这一问题，本文利用大型语言模型（LLMs）来翻译已发表的科学文章，同时保持其原始JATS XML格式，提出了一种实用的自动化实施方法。该研究将多学科的科学文章翻译成28种语言，以评估翻译准确性，引入了一种新的问答（QA）基准方法，结果显示平均准确率为95.9%，表明核心科学细节被准确传达。通过用户研究发现，作者普遍认为翻译准确捕捉了文章中的信息。此外，三分之一的作者认为许多技术术语“过度翻译”，偏好保留更多熟悉的英语术语不翻译。", "innovation": "提出了利用大型语言模型来翻译已发表的科学文章，并保持原始JATS XML格式的方法；开发了一种基于问答（QA）的新基准方法来评估翻译准确性；展示了利用情境学习技术来调整翻译以符合特定领域的偏好，例如减少过度翻译，突显了基于大语言模型的科学翻译的适应性和实用性。", "conclusion": "研究通过大规模语言模型翻译科学论文，并验证了翻译的准确性和适应性。文章的翻译码和翻译后的文章可在此 https://example.com 查阅。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11701", "html_url": "https://arxiv.org/abs/2505.11701", "title": "DMN-Guided Prompting: 一种控制大语言模型行为的框架", "title_en": "DMN-Guided Prompting: A Framework for Controlling LLM Behavior", "authors": "Shaghayegh Abedi,Amin Jalali", "background": "大语言模型（LLMs）在知识密集型过程中自动化决策逻辑方面显示出巨大潜力，但其有效性主要取决于提示策略和提示质量。决策逻辑通常嵌入在提示中，使得终端用户难以修改或细化。DMN（决策模型和符号）提供了一种标准化的图形方法，以结构化和用户友好方式定义决策逻辑。本文介绍了一种基于DMN的提示框架，该框架将复杂决策逻辑分解为更小、更易管理的部分，并引导LLMs通过结构化的决策路径。研究人员在研究生课程中实现了该框架，学生提交的作业和表示反馈指示的DMN模型作为输入，指导员评估生成的反馈并进行绩效评估。这种方法在案例研究中表现出了良好的结果，优于基于思维链的方法。学生也对生成的反馈有积极的反馈，调查显示他们认为这种反馈非常有用，符合技术接受模型（TAM）的评估标准。", "innovation": "提出了一种基于DMN的提示框架，将复杂决策逻辑分解为更小、更易管理的部分，有效地引导LLMs通过结构化的决策路径，使得决策逻辑更具灵活性，并且提高了LLMs生成的反馈质量和学生的接受度。该框架克服了传统提示方法对决策逻辑修改的困难，使得用户能够更好地控制大语言模型的行为。", "conclusion": "该研究展示了DMN引导的提示框架的有效性，在案例研究中优于传统的基于思维链的提示方法，学生对生成反馈的满意度高，这表明该框架有潜力显著改进大语言模型在知识密集型过程中的应用效果。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01700", "html_url": "https://arxiv.org/abs/2508.01700", "title": "DeepVIS: 通过逐步推理连接自然语言和数据可视化", "title_en": "DeepVIS: Bridging Natural Language and Data Visualization Through Step-wise Reasoning", "authors": "Zhihao Shuai,Boyan Li,Siyu Yan,Yuyu Luo,Weikai Yang", "background": "尽管数据可视化可以揭示模式和沟通见解，但创建有效的可视化通常需要熟悉作者工具，且常打断分析流程。当前的大语言模型展示了自动将分析意图转换为可视化的需求，但这些方法缺乏透明的推理过程，使用户无法理解设计动机和改进次优输出。本文旨在解决这一问题。", "innovation": "本文提出了将逐步推理(Chain-of-Thought, CoT)整合到自然语言到可视化(Natural Language to Visualization, NL2VIS)流程中。首先，设计了一个全面的CoT推理过程，并开发了一个自动化流程，使现有数据集具有结构化的推理步骤；其次，引入了nvBench-CoT，专门数据集，即从含糊的自然语言描述到最终可视化的过程，为模型微调提供最佳性能；最后，开发了DeepVIS，一个集成逐步推理过程的交互式视觉界面，允许用户检查推理步骤、识别错误并进行针对性调整以改进可视化结果。", "conclusion": "通过定量基准评估、两个用例和用户研究，本文共同证明了CoT框架有效提升了NL2VIS的质量，并向用户提供了有意义的推理步骤。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06052", "html_url": "https://arxiv.org/abs/2506.06052", "title": "CP-Bench: 评估大型语言模型在约束建模中的性能", "title_en": "CP-Bench: Evaluating Large Language Models for Constraint Modelling", "authors": "Kostis Michailidis,Dimos Tsouros,Tias Guns", "background": "约束程序（CP）被广泛用于解决组合问题，但其核心过程——约束建模，需要大量的专业知识，被认为是更广泛采用的瓶颈。现有的研究探索了使用大型语言模型（LLMs）将组合问题描述转换为可执行的约束模型来缓解这一瓶颈。然而，现有的用于约束建模的评估数据集通常局限于小规模、同质或特定领域的问题实例，不能捕捉到实际场景的多样性。本文通过引入CP-Bench，一个包含多种常见的组合问题的基准测试，填补了这一空白。这些问题源自CP社区，并明确地结构化以评估由LLMs驱动的约束建模。使用这一数据集，我们比较了三个不同抽象级别和基础语法的约束建模系统中的LLMs建模能力。结果表明，使用高阶的Python框架进行建模具有更高的性能。此外，我们系统地评估了不同LLMs在提示基础和推理时计算方法的应用，这些方法进一步提高了准确性，特别是在这个高度具有挑战性的基准测试上，准确率达到70%以上。", "innovation": "本文的创新之处在于引入了一个新的基准测试CP-Bench，该基准测试包含了多种常见的组合问题，旨在评估LLMs驱动的约束建模能力。本文还将多种约束建模系统进行了评估，并通过系统地评估不同LLMs在不同建模方法中的性能，进一步提高了模型的准确性。", "conclusion": "本文通过CP-Bench，展示了LLMs在约束建模中的潜力，特别是在使用高阶Python框架进行建模时，表现出了较高的性能。通过提示技术和推理时的计算方法的评估，这些模型的准确性得到了显著提升。这为未来使用LLMs进行约束建模提供了有价值的参考。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00401", "html_url": "https://arxiv.org/abs/2508.00401", "title": "使用主动推断的理论共情：一个多代理合作框架", "title_en": "Theory of Mind Using Active Inference: A Framework for Multi-Agent Cooperation", "authors": "Riddhi J. Pitliya,Ozan Çatal,Toon Van de Maele,Corrado Pezzato,Tim Verbelen", "background": "理论共情（ToM）是指理解他人可能有不同的知识和目标的能力，这使代理可以推理他人的信念并在计划自身行为时发挥作用。以前的研究在多代理合作中使用主动推断方法，但这些方法要么依赖于特定任务的共享生成模型，要么需要明确的通信，这限制了它们的灵活性和推广性。本研究提出了一种新的方法，通过在主动推断中实施ToM，构建了一种新的多代理合作框架，为理解和应用ToM机制提供了一个新的视角并在多代理系统中展示出了通奏和可扩展的潜力.", "innovation": "该方法在主动推断中实现了ToM，使得多代理合作既不需要依赖特定任务的共享生成模型，也不需要明确的通信。ToM配对的代理能够维持自己和他人的信念和目标的独立表示，并使用扩展和适应的复杂推理树基规划算法系统地通过递归推理探索联合策略空间。这种方法通过仅从可观察行为推断他人信念并在计划自身行为时考虑这些信息，展示了更好的合作能力，避免了碰撞，并减少了重复努力，为多代理系统的通用和可扩展性提供了潜在的解决方案，同时为ToM机制提供了计算洞见.", "conclusion": "通过碰撞避免和觅食模拟评估了该方法。结果表明，具备ToM的代理通过仅从可观察行为推断他人信念并考虑他人信念在计划自身行为时，比未具备ToM的代理有更好的合作效果。这种引入ToM机制的方法在多代理系统中的应用前景广阔，对理解ToM机制也提供了有意义的计算见解."}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01938", "html_url": "https://arxiv.org/abs/2509.01938", "title": "EigenBench: 比较性价值对齐的行为度量", "title_en": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "authors": "Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine", "background": "人工智能与人类价值观对齐是一个紧迫且未解决的问题。由于缺乏衡量价值对齐的定量指标，该文提出了一种名为EigenBench的方法，用于比较性基准测试语言模型的价值。该方法致力于利用模型间的相互评判结果，通过聚合得到每个模型在给定宪法下的对齐程度评分，无需依赖任何真实标签。这解决了价值对齐评估中的一个关键问题，即不同合理的评判者可能对正确标签存在分歧。", "innovation": "EigenBench方法通过聚合模型之间的相互评判结果来评估模型的价值对齐程度，这种方法在不依赖真实标签的情况下产生了评分，解决了价值对齐评估中的关键问题。通过使用Prompted Personas进行测试，发现大部分变化是由提示引起的，但模型本身还存在一小部分差异性评估结果，这为理解和改进AI的价值对齐提供了新的视角。", "conclusion": "EigenBench方法通过对多个模型在各种情景下的评判结果进行聚合，不依赖真实标签，发现评估结果主要由提示的影响主导，但也能部分反映模型自身的特性，为评估语言模型的价值对齐提供了一种有效的方法。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.03993", "html_url": "https://arxiv.org/abs/2312.03993", "title": "使用稳定扩散技术将风格转移至卡尔文和霍布斯漫画", "title_en": "Style Transfer to Calvin and Hobbes comics using Stable Diffusion", "authors": "Asvin Kumar Venkataramanan,Sloke Shrestha,Sundar Sripada Venugopalaswamy Sriraman", "background": "该项目报告总结了我们在一个包含卡尔文和霍布斯漫画的数据集上执行稳定扩散微调的旅程。目的是将任何给定的输入图像转换为卡尔文和霍布斯的漫画风格，即执行风格转移。", "innovation": "我们使用Low Rank Adaptation (LoRA) 训练 stable-diffusion-v1.5，以提高微调过程的效率。扩散过程由一个Variational Autoencoder (VAE) 处理，该VAE是一个U-net。结果在训练时间和输入数据质量的条件下呈现出了令人满意的视觉效果。", "conclusion": "与训练时间和输入数据质量相比，我们的结果在视觉上令人满意。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01909", "html_url": "https://arxiv.org/abs/2509.01909", "title": "Oyster-I：负责任的语言模型中的超越拒绝——构建性安全对齐", "title_en": "Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models", "authors": "Ranjie Duan,Jiexi Liu,Xiaojun Jia,Shiji Zhao,Ruoxi Cheng,Fengxiang Wang,Cheng Wei,Yong Xie,Chang Liu,Defeng Li,Yinpeng Dong,Yichi Zhang,Yuefeng Chen,Chongwen Wang,Xingjun Ma,Xingxing Wei,Yang Liu,Hang Su,Jun Zhu,Xinfeng Li,Yitong Sun,Jie Zhang,Jinzhao Hu,Sha Xu,Yitong Yang,Jialing Tao,Hui Xue", "background": "现有的大型语言模型（LLMs）通常部署了安全机制来预防有害内容的生成，但大多数方法集中于恶意行为者带来的风险，常常以对抗性事件为框架，依赖于防御性的拒绝策略。然而，在实际应用中，风险也来自于处于心理困扰中的非恶意用户（例如，有自伤意图），而这些用户的求助可能带来更糟糕的结果。现有的模型简单地拒绝可能会导致用户重复请求、升级威胁或转向不安全的平台。", "innovation": "本研究引入了构建性安全对齐（CSA），这是一种以人为本的框架，旨在保护模型免受恶意滥用的同时，积极引导脆弱用户走向安全和有帮助的结果。CSA 在 Oyster-I (Oy1) 中实现，结合了用户反应的博弈论预测、细粒度的风险边界发现和可解释的推理控制，将安全转变为信任建设的过程。Oy1 在开放模型中达到了最先进的安全水平，同时保持了高度的一般性功能。它在我们构建的基准测试中表现出强大的建设性参与，接近 GPT-5 的水平，并在 Strata-Sword 囚笼数据集中展现出无与伦比的鲁棒性，接近 GPT-o1 的水平。通过从拒绝优先转向指导优先的安全策略，CSA 重新定义了模型与用户之间的关系，旨在构建不仅安全而且真正有帮助的系统。", "conclusion": "通过发布 Oy1、代码和基准测试，本研究支持以负责任为中心的 AI，旨在促进系统不仅安全，而且真正有帮助的模型。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16117", "html_url": "https://arxiv.org/abs/2508.16117", "title": "扩展 FKG.in：迈向食品声明可追溯网络", "title_en": "Extending FKG.in: Towards a Food Claim Traceability Network", "authors": "Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain", "background": "全球食品领域充斥着关于食品的各种科学、文化及商业声明，这些声明涵盖了从严谨研究的健康益处（例如益生菌改善肠道健康）到模糊的承诺（例如超级食品增强免疫力）以及根植于文化中的信念（例如冷食会引起咳嗽）。尽管这些声明在日常生活中具有广泛的影响，但用于追踪、验证和背景化这些声明的基础设施依旧支离破碎，尚待完善。本文则旨在提出一个“食品声明可追溯网络”（FCN），作为我们先前在印度食品知识图谱（FKG.in）基础上逐步建立起来的知识图谱的扩展。该网络利用Reddit数据和大型语言模型半自动化地进行知识汇编，以验证和提取食品相关的声明。本文还介绍了FCN的设计理念，并描述了一种验证食品声明的结构化、可验证且可解释的方法，从而促进更透明和负责的食品知识生态系统的发展，支持研究人员、政策制定者以及最为重要的普通消费者的日常决策过程。", "innovation": "本文提出了一种名为FCN（Food Claim-Traceability Network）的知识网络作为FKG.in的扩展性应用。FCN结合了结构化的数据输入、可验证的架构以及基于背景的处理管道，用于食品相关的声明的提取和验证。本文还采用了Reddit数据和大型语言模型进行半自动化的知识游牧，展示了将科学、文化和商业声明以结构化、可验证、可解释的方式纳入系统的创新之处。", "conclusion": "通过构建一个结构化、可验证且可解释的食品声明及其可追溯性的系统，本文旨在推动更透明和负责的食品知识生态系统。该方法不仅适用于印度食品知识图谱的应用场景，而且高度适应性的，可以用于不同地理、饮食或监管环境中的食品声明的追踪和验证，最终支持普通消费者做出更为明智的饮食决策。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2211.12143", "html_url": "https://arxiv.org/abs/2211.12143", "title": "自主化，而非自动化：欧洲事实核查员的活动与需求为基础设计以人为本的AI系统", "title_en": "Autonomation, Not Automation: Activities and Needs of European Fact-checkers as a Basis for Designing Human-Centered AI Systems", "authors": "Andrea Hrckova,Robert Moro,Ivan Srba,Jakub Simko,Maria Bielikova", "background": "为了更有效地减轻虚假信息的负面影响，需要开发辅助事实核查员的人工智能（AI）系统。然而，由于忽视了这些利益相关者的需求，导致他们对整个事实核查过程的自动化持有限制性接受和怀疑态度。因此，本研究通过半结构化深入访谈，分析了中欧事实核查员的活动和问题，并通过调查欧洲事实核查员验证了最主要的问题。我们的研究揭示了非英语地区事实核查工作的多样性和未被涵盖的部分，并通过与先前研究的知识相整合，创建了有助于理解事实核查过程的概念模型。此外，我们将事实核查员的活动和需求与AI研究的相关任务进行映射，并讨论了三个之前类似研究未覆盖的AI任务，从而为AI研究在这一领域确定了新的机会和焦点.", "innovation": "本研究创新性地关注了中欧事实核查员的活动和需求，揭示了非英语地区事实核查工作的多样性和未被覆盖的部分。通过将事实核查员的活动与先前知识相结合，我们创建了概念模型以帮助理解事实核查过程。此外，研究讨论了三项不在以前类似研究范围内的AI任务，为AI研究人员和开发者提供了新的视角和方向，用以设计以人为本的AI系统.", "conclusion": "本研究通过半结构化深入访谈和调查数据，提供了关于欧洲事实核查员活动和需求的详细分析。通过创建概念模型，我们有助于更好地理解事实核查过程。此外，通过识别三个新的AI任务，我们的研究为AI研究在这一领域的焦点提供了新的启示，强调了与事实核查员紧密合作的重要性，以开发更有效的AI辅助工具来应对虚假信息问题。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.15869", "html_url": "https://arxiv.org/abs/2407.15869", "title": "长输入序列网络用于长时间序列预测", "title_en": "Long Input Sequence Network for Long Time Series Forecasting", "authors": "Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu", "background": "在长时间序列预测任务中，短固定长度输入是深度学习方法的主要瓶颈。随着输入长度的增加，容易导致过拟合，预测精度迅速下降。", "innovation": "我们发现过拟合是由时间序列中的多尺度模式耦合和当前模型固定的聚焦尺度共同引起的。提出了一种新颖的时间序列分解模块（MPSD）和多标记模式识别神经网络（MTPR），它们使模型能够处理长度最多扩展10倍的输入。这种解耦方法在复杂性（成本减少至0.22倍）和可解释性方面具有优势。", "conclusion": "适当增加上下文可以提高性能（最高可提高38%的准确性），而解耦方法在复杂性（成本减少至0.22倍）和可解释性方面提供了改进。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02761", "html_url": "https://arxiv.org/abs/2509.02761", "title": "基于大语言模型的体态AI任务完成代理计划验证", "title_en": "Plan Verification for LLM-Based Embodied Task Completion Agents", "authors": "Ananth Hariharan,Vardhan Dongre,Dilek Hakkani-Tür,Gokhan Tur", "background": "基于大语言模型（LLM）的任务规划和对应的转为体态AI的人类示范可能带有噪声，包括不必要的动作、冗余导航和逻辑错误，这些都会降低政策质量。", "innovation": "提出了一种迭代验证框架，在该框架中，Judge LLM（裁判大语言模型）批评动作序列，Planner LLM（规划大语言模型）应用修正，进而生成更加清洁且空间组织性更强的轨迹。与基于规则的方法不同，该方法依赖自然语言提示，能够广泛应用于不同类型错误的修正，包括无关动作、矛盾和缺失步骤。", "conclusion": "框架在TEACh数据集上对四个最先进的LLM（GPT o4-mini，DeepSeek-R1，Gemini 2.5，LLaMA 4 Scout）实现90%的召回率和100%的查准率。改进的时间效率和空间动作组织快速收敛，并且该方法保留了人类的错误恢复模式，支持未来在鲁棒纠正行为方面的研究。通过确立计划验证作为空间规划和动作改进的可靠LLM能力，为模仿学习提供了高标准的训练数据路径。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.00265", "html_url": "https://arxiv.org/abs/2411.00265", "title": "通过证据理论量化神经网络的校准误差", "title_en": "Quantifying Calibration Error in Neural Networks Through Evidence-Based Theory", "authors": "Koffi Ismael Ouattara,Ioannis Krontiris,Theo Dimitrakos,Frank Kargl", "background": "在关键应用中部署神经网络时，信任度至关重要，因为可靠性和不确定性在决策过程中起着关键作用。传统性能指标如准确率和精确率无法捕捉这些方面，特别是在模型表现出过高自信的情况下。", "innovation": "本文提出了一种新的框架，通过将主观逻辑应用于校准误差（ECE）评估中，以量化神经网络的信任度。该方法通过聚类预测概率并使用合适的融合操作符融合意见，提供了一种综合衡量信任、不相信和不确定性的措施。", "conclusion": "通过在MNIST和CIFAR-10数据集上的实验，证明了该方法的有效性，并表明后校准结果提高了信任度。提出的框架提供了对AI模型更具可解释性和层次感的评估，具有在医疗保健和自主系统等敏感领域的潜在应用。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.15161", "html_url": "https://arxiv.org/abs/2407.15161", "title": "FFHFlow：通过流变推理生成多样性和不确定感知的灵巧抓取", "title_en": "FFHFlow: Diverse and Uncertainty-Aware Dexterous Grasp Generation via Flow Variational Inference", "authors": "Qian Feng,Jianxiang Feng,Zhaopeng Chen,Rudolph Triebel,Alois Knoll", "background": "多指手从部分观测生成多样且能感知不确定性的抓取依然是机器人学习中的关键挑战。现有生成方法难以模拟灵巧手的复杂抓取分布，并且难以处理部分点云中固有的形状不确定性，导致抓取不可靠或过于保守。", "innovation": "本文提出了基于流的可变框架FFHFlow，该框架能够生成多样且鲁棒的多指抓取，同时明确量化部分点云中的感知不确定性。通过利用正则化流的深度隐变量模型，克服了条件变分自编码器（cVAE）的模态崩塌和刚性先验限制。添加了一个判别抓取评估器，并结合流似然性，提出了一个感知不确定性的排名策略，优先考虑对形状模糊具有鲁棒性的抓取。FFHFlow在多种实验（模拟和现实环境）中的实验显示了相比最先进的基线模型（包括扩散模型）在抓取多样性和成功率上的优越表现，同时保证了运行效率。在杂乱和受限环境中，通过多样性的采样方式减少了碰撞，展示了其实际价值。", "conclusion": "FFHFlow在抓取多样性、成功率方面表现优异，且具有运行时高效的采样能力。验证了其在复杂环境中的实用价值。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.08965", "html_url": "https://arxiv.org/abs/2405.08965", "title": "MTP：实现AI整合编程的含义类型化语言抽象", "title_en": "MTP: A Meaning-Typed Language Abstraction for AI-Integrated Programming", "authors": "Jayanaka L. Dantanarayana,Yiping Kang,Kugesan Sivasothynathan,Christopher Clarke,Baichuan Li,Savini Kashmira,Krisztian Flautner,Lingjia Tang,Jason Mars", "background": "软件开发正从传统的编程方式转向利用生成式AI和大型语言模型（LLMs）的AI集成应用。将LLMs集成到程序中依然复杂，需要开发者手动创建提示和处理输出，现有工具虽能辅助提示工程，但往往会增加额外的复杂性。", "innovation": "该论文提出了意义类型化编程（MTP），这是一种新颖的范式，通过直观的语言层次结构抽象LLMs的集成，利用代码固有的语义丰富性，自动完成提示生成和响应处理，无需额外的开发者工作。引入了by操作符实现无缝LLMs调用，MT-IR——一种基于意义的中间表示以提取语义，以及MT-Runtime——一种自动化系统以管理LLMs的交互。MTP在Jac编程语言中实现，这是一种扩展了Python的编程语言，发现MTP显著降低了开发复杂性、代码修改量以及成本，同时提高了运行时性能，并且在准确性和效率上不低于现有方法。", "conclusion": "我们的用户研究表明，使用MTP，开发人员完成任务的速度是现有框架的3.2倍，代码行数减少45%。MTP甚至在高达50%的命名约定退化的情况下仍显示出较强的鲁棒性，证明了在代码质量不佳时的适应性。MTP作为Jaseci开源项目的一部分开发并提供。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.02807", "html_url": "https://arxiv.org/abs/2410.02807", "title": "AutoPETIII: The Tracer Frontier. What Frontier?,", "title_en": "AutoPETIII: The Tracer Frontier. What Frontier?", "authors": "Zacharia Mesbah,Léo Mottay,Romain Modzelewski,Pierre Decazes,Sébastien Hapdey,Su Ruan,Sébastien Thureau", "background": "AutoPET竞赛在过去三年中一直聚集了医学成像领域的关注，重点是正电子发射断层扫描(PET)扫描中的病变分割。每年的比赛都会关注不同的方面，2024年的挑战着眼于现有和使用的不同示踪剂的多样性。具体来说，今年的比赛旨在开发一种能够在不知道具体示踪剂（可能是基于FDG或PSMA的）的情况下，完全自动进行PET/CT病变分割的算法。", "innovation": "该团队利用nnUNetv2框架训练了两组六折模型集合，并结合MIP-CNN来选择用于病变分割的模型集，从而实现完全自动的病变分割，无论示踪剂为何种类型。这种结合了集成学习和混合图像处理技术的方法是一种创新的解决方案，针对了一个在实际应用中具有挑战性的问题。", "conclusion": "本文详细描述了如何利用nnUNetv2框架训练了两个六折模型集合，并结合MIP-CNN技术选择模型来完成完整的自动PET/CT病变分割。这一方法为解决不同示踪剂带来的自动化分割问题提供了一个可行的方案。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.12722", "html_url": "https://arxiv.org/abs/2412.12722", "title": "通过部分感知监督防御LVLMs视觉攻击", "title_en": "Defending LVLMs Against Vision Attacks through Partial-Perception Supervision", "authors": "Qi Zhou,Tianlin Li,Qing Guo,Dongxia Wang,Yun Lin,Yang Liu,Jin Song Dong", "background": "近年来，有研究表明大型视觉语言模型（LVLMs）对恶意注入或篡改的输入图像非常脆弱，可能导致其作出错误响应。现有的防御方法表明，这种视觉攻击容易受到图像修改的影响，尤其是在对修改后的图像进行响应的投票中使用众数投票作为修正响应。然而，这些修改往往会产生不完整的图像，破坏语义，降低了对干净图像的响应质量。", "innovation": "该研究提出了一种不依赖训练的黑盒防御方法DPS（通过部分感知监督防御），该方法利用一个仅能感知部分图像的模型生成的响应来监督LVLMs的原始响应。当模型在遭受攻击时，它可以基于部分图像的理解调整其响应，同时自信地保留其原始响应以应对未受攻击的输入。研究发现，在遭受攻击时，弱模型可以监督强模型：强模型变得不那么自信，并根据弱模型的部分理解调整其响应，有效地防御攻击。", "conclusion": "实验结果表明该方法优越于基线，能够在三个流行模型上的六个数据集上将平均攻击成功率降低76.3%。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.16572", "html_url": "https://arxiv.org/abs/2412.16572", "title": "打破长时序预测中的上下文瓶颈", "title_en": "Breaking the Context Bottleneck on Long Time Series Forecasting", "authors": "Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu,Zhou Fang,Jiaxing Qu", "background": "长时序预测对于经济学、能源和交通领域的规划和决策至关重要，因为它需要长期的展望。有效的长时序预测模型必须既高效又能够在处理长序列时有效。虽然最近的研究提高了这些模型的效率，但如何有效地利用更长的序列仍然是一个挑战。由于较长输入可能导致这些模型过拟合，因此通常需要使用较短的输入长度以维持可容忍的误差范围。", "innovation": "本文研究了多尺度模型，并提出了Logsparse Decomposable Multiscaling (LDM)框架，旨在实现长序列的有效高效处理。通过在时间序列中解耦不同尺度的模式，该框架可减少非稳定性、通过紧凑的长输入表示提高效率，并通过提供清晰的任务分配简化架构。实验结果表明，LDM 不仅在长期预测基准中优于所有基线，还同时降低了训练时间和内存成本。", "conclusion": "LDM不仅在长期预测基准中取得了优异的性能，还通过有效的多尺度处理减少了训练时间和内存成本，从而为长时序预测中处理上下文提供了新的解决方案。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.05719", "html_url": "https://arxiv.org/abs/2502.05719", "title": "EHBOS", "title_en": "Extended Histogram-based Outlier Score (EHBOS)", "authors": "Tanvir Islam", "background": "Histogram-Based Outlier Score (HBOS) 是一种广泛使用的异常检测方法，以其计算效率和简单性著称。然而，HBOS 假设特征独立，限制了其在特征之间存在相互作用的数据集中的异常检测能力。", "innovation": "本文提出了增强的 Histogram-Based Outlier Score (EHBOS)，通过引入二维直方图来捕捉特征对之间的依赖关系，从而增强 HBOS 的异常检测能力。EHBOS 能够识别上下文依赖和依赖驱动的异常，而这些异常 HBOS 无法检测到。实验表明，EHBOS 在多个基准数据集上表现出色，特别是那些特征相互作用对异常结构定义至关重要的数据集，显著提高了 ROC AUC 的表现。", "conclusion": "EHBOS 可以作为 HBOS 的有价值的扩展，能够建模复杂的特征依赖关系，成为一个强大的新工具，特别适用于特征上下文或关系异常扮演重要角色的数据集。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.12124", "html_url": "https://arxiv.org/abs/2410.12124", "title": "从10个演示中学习：基于定向功能框架的可泛化且样本高效的策略学习", "title_en": "Learning from 10 Demos: Generalisable and Sample-Efficient Policy Learning with Oriented Affordance Frames", "authors": "Krishan Rana,Jad Abou-Chakra,Sourav Garg,Robert Lee,Ian Reid,Niko Suenderhauf", "background": "模仿学习使机器人能够展示出高度灵巧的行为，但仍然在长时序、多目标任务中遇到困难，主要是由于样本效率低和泛化能力有限。现有方法需要大量的演示来涵盖可能的任务变化，这使得它们在实际应用中成本高且往往不切实际。任务具有长时序和多目标的特点，对于模仿学习来说是一个挑战，尤其是在样本数量有限的情况下，难以有效推广到未来未见的数据上。", "innovation": "本文通过引入定向功能框架（Oriented Affordance Frames），提供了一种结构化的状态和动作空间表示，增强了空间和类别内部的泛化能力，使得仅通过10个演示就能有效地学习策略。此外，作者展示了如何利用这种抽象的轮廓将独立训练的子策略组合起来，以解决长时序、多目标任务。同时，提出了自我推进预测的概念，该概念直接源自训练示例的持续时间，以实现子策略之间的平滑过渡。该研究对三个真实世界的任务进行了验证，每一个任务都要求多步骤、多目标的交互，尽管数据集很小，但是策略能够稳健泛化到未见的对象外观、几何形状和空间布局，无需依赖全面的训练数据即可实现高成功率。", "conclusion": "尽管数据集较小，我们的策略能够稳健泛化到未见到的对象外观、几何形状和空间布局，并且不依赖于详尽的训练数据，实现了高成功率。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06289", "html_url": "https://arxiv.org/abs/2502.06289", "title": "基于超大规模自然图像的骨干模型是否优于针对视网膜特定的模型用于检测眼病和系统性疾病？", "title_en": "Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?", "authors": "Qingshan Hou,Yukun Zhou,Jocelyn Hui Lin Goh,Ke Zou,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Thaddaeus Lo,Xiaofeng Lei,Siegfried K. Wagner,Mark A. Chia,Dawei Yang,Hongyang Jiang,An Ran Ran,Rui Santos,Gabor Mark Somfai,Juan Helen Zhou,Haoyu Chen,Qingyu Chen,Carol Y. Cheung,Pearse A. Keane,Yih Chung Tham", "background": "基础模型（FMs）正在改变医疗领域。在眼科中，RETFound作为一种针对视网膜的FM模型，通过对大量自然图像和眼底图的训练展现出高适用性。相比之下，DINOv2作为一种通用视觉FM模型，尽管在非医疗领域显示出潜力，但在临床任务中的应用尚未充分探索。", "innovation": "本文通过直接对比RETFound和三种不同规模的DINOv2模型在眼病检测和系统性疾病预测中的效果，展示了通用和特定领域基础模型在这类任务中的差异性优势。", "conclusion": "研究结果表明，DINOv2-Large模型在糖尿病视网炎和多类眼病检测中优于RETFound，而在青光眼检测中，DINOv2-Base模型表现更佳。相反，RETFound在预测心脏衰竭、心肌梗死和缺血性中风方面表现出更快的适应性。这些发现强调了选择与任务特性相匹配的基础模型对于优化临床表现的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.13958", "html_url": "https://arxiv.org/abs/2501.13958", "title": "图检索增强生成在定制大语言模型中的综述", "title_en": "A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models", "authors": "Qinggang Zhang,Shengyuan Chen,Yuanchen Bei,Zheng Yuan,Huachi Zhou,Zijin Hong,Hao Chen,Yilin Xiao,Chuang Zhou,Yi Chang,Xiao Huang", "background": "大语言模型（LLMs）在广泛的任务中展示了卓越的能力，但在专业领域中的应用仍面临挑战，因为需要深厚的专业知识。检索增强生成（RAG）通过将外部知识库无缝集成到LLMs中，使在推断时能实时访问特定领域的专业知识显得有前景。尽管如此，传统的基于扁平文本检索的RAG系统面临三个关键挑战：(i) 专业上下文中的复杂查询理解，(ii) 知识在分布式来源之间的整合困难，(iii) 在大规模下系统效率的瓶颈。因此，需要一种新的方法来克服这些挑战，GraphRAG适时应运而生，它通过图结构化的知识表示、基于图的有效检索技术以及结构意识的知识集成算法重新定义了特定领域的LLMs应用。", "innovation": "GraphRAG通过三大创新解决了传统RAG的问题：(i) 图结构化的知识表示以明确捕捉实体关系和领域层次结构，(ii) 基于图的高效检索技术允许上下文保持的知识检索和多跳推理能力，(iii) 结构意识的知识集成算法利用检索到的知识进行准确和逻辑连贯的LLMs生成。它提供了一种全新的方法来解决专业领域中大语言模型的定制问题。", "conclusion": "本文系统分析了GraphRAG的底层技术，并检查了其在各种专业领域的当前实现，指出了关键技术挑战和有前途的研究方向。为社区提供了GraphRAG相关的所有资源，包括研究论文、开源数据和项目，详情请访问<this https://>链接。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.14791", "html_url": "https://arxiv.org/abs/2502.14791", "title": "快速的基于元在上下文学习的新词学习", "title_en": "Rapid Word Learning Through Meta In-Context Learning", "authors": "Wentao Wang,Guangyuan Jiang,Tal Linzen,Brenden M. Lake", "background": "人类能够从少量的实例中快速学习新词，并在新的语境中灵活运用。然而，现有的语言模型在少样本新词学习方面的能力及其改进方法尚缺乏探索。", "innovation": "提出了一个新的方法——用于学习新词的基于元在上下文学习（Minnow）的方法。该方法通过使用特殊占位符标记训练语言模型，使其能够根据少量实例生成新词的使用案例，以此提高少样本新词学习能力。", "conclusion": "从零开始使用Minnow训练的语言模型在人类规模的儿童语言数据上实现了强大的少样本新词学习，与大量数据预训练的大语言模型表现相当。通过区分性和生成性评估，发现使用Minnow微调预训练的大语言模型能够更好地识别新词、确定新词的句法类别，并根据少量实例生成合理的新词用法和定义。这些发现突显了Minnow的数据效率及其对语言模型在新词学习任务中的性能改进潜力。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.03562", "html_url": "https://arxiv.org/abs/2411.03562", "title": "基于科布体验式学习的通用型代理系统，实现人类级别的Kaggle数据科学性能", "title_en": "Kolb-Based Experiential Learning for Generalist Agents with Human-Level Kaggle Data Science Performance", "authors": "Antoine Grosnit,Alexandre Maraval,Refinath S N,Zichao Zhao,James Dora,Giuseppe Paolo,Albert Thomas,Jonas Gonzalez,Abhineet Kumar,Khyati Khandelwal,Abdelhakim Benechehab,Hamza Cherkaoui,Youssef Attia El-Hili,Kun Shao,Jianye Hao,Jun Yao,Balázs Kégl,Jun Wang", "background": "人类专门知识的形成分为互动反思、内模更新等迭代循环过程，这一理论与Kolb的经验学习理论及Vygotsky的最近发展区理论相吻合。当前的AI系统，尤其是大语言模型（LLM）代理，依赖于预先静态训练或僵化的流程，缺乏机制来实现持续适应。尽管最近有研究表明，LLM代理具备早期认知特征，如反思、修订和自我修正，但它们在认知基础的人类体验式学习方面仍不具备结构性能力。因此，研究提出的关键问题是：能否设计出具备结构化、基于认知过程的学习能力的LLM代理，使其类似于人类学习的过程？", "innovation": "本文提出了一种Kolb学习周期和Vygotsky的最近发展区相结合的计算框架，用于构建自适应代理。该架构将外部（环境互动）和内部（内在反思/抽象）功能分离，实现结构化、认知支撑的学习，代理首先在结构化环境中学习，然后通过开放式泛化进行推广。这种方法使代理能够掌握传统细化调整或简单反思方法无法有效解决的复杂任务或领域。此外，通过直接与人类在现实世界Kaggle数据科学竞赛中的比较，展示了该方法的巨大潜力。该系统在81项任务中实现自动化数据科学代码生成，并以1694的Elo-MMR得分超越了我们的研究中Kaggle大师（全球20万用户中前2%）的中位数得分，成为第一个成功整合科布和维果茨基所启发的人类认知学习的AI系统，标志着向通用人工智能迈出的重要一步。", "conclusion": "本文提出了一种新的基于Kolb和Vygotsky的人类认知学习的计算框架，并构建了相应的代理系统，实现了在Kaggle数据科学竞赛中的人类级别表现。这标志着在通用人工智能领域取得的重要进展。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.12736", "html_url": "https://arxiv.org/abs/2411.12736", "title": "ACING: 基于演员-评论家框架的黑盒大语言模型指令学习", "title_en": "ACING: Actor-Critic for Instruction Learning in Black-Box LLMs", "authors": "Salma Kharrat,Fares Fourati,Marco Canini", "background": "大语言模型（LLMs）的指令质量对其任务解决能力影响重大，通常需要大量的人工努力来制定。因此，迫切需要自动化的指令优化。然而，优化指令对于黑盒大语言模型尤其具有挑战性，因为这些模型的内部参数和梯度是不可访问的。现有的方法很难有效探索无限的指令空间，而ACING通过基于演员-评论家的强化学习框架，将其转化为无状态、连续动作的问题，仅利用黑盒反馈就能探索广泛的指令空间，从而实现全自动的指令优化。", "innovation": "ACING 引入了一种新的演员-评论家强化学习框架，将指令优化问题形式化为无状态的、连续动作问题，能够在仅依赖于黑盒反馈的情况下探索无限的指令空间。ACING 自动发现了一系列超过人工指令效果的提示，在 76% 的指令生成任务中表现优于人工提示，甚至在 33 个涉及指令生成、总结和连续推理的任务中，相对于最好的自动基线，平均提高了 10 个点，最高可达 33 个点。广泛的消融实验展示了 ACING 的稳健性和效率，其具体实施代码可以在提供的链接中找到。", "conclusion": "ACING 在黑盒大语言模型的指令优化方面展现了强大的性能，能够自动发现超越人工指令效果的提示，显著提升了多个任务的表现，证明了通过强化学习自动优化指令的有效性和实用性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.14891", "html_url": "https://arxiv.org/abs/2502.14891", "title": "CoDiff：基于条件扩散模型的协作3D目标检测", "title_en": "CoDiff: Conditional Diffusion Model for Collaborative 3D Object Detection", "authors": "Zhe Huang,Shuo Wang,Yongcai Wang,Lei Wang", "background": "协作的3D物体检测在自动驾驶领域具有重大意义，能够通过多个代理之间的信息共享增强感知能力。然而，由于姿态估计误差和时间延迟，代理间的特征融合经常会引入空间和时间噪声，导致检测错误。扩散模型天然具备去噪能力，因此作者提出使用扩散模型解决多代理系统中的噪声问题。CollDiff是一个新的鲁棒协作感知框架，利用扩散模型来生成更为综合和清晰的特征表示。通过将高维特征图投影到预训练自编码器的潜在空间中，利用每个代理的信息作为条件引导扩散模型的采样过程，从而去噪并逐步细化融合特征。", "innovation": "这是首次将扩散模型应用于多代理协作感知。通过将高维特征图投影到预训练自编码器的潜在空间，并利用每个代理的信息作为条件来引导扩散模型的采样，CollDiff能够在具有高噪声的代理姿态和延迟信息下表现出高度的鲁棒性。实验结果表明，CoDiff在协作目标检测性能上优于现有方法，并且在噪声较大的情况下表现出良好的稳健性。", "conclusion": "CollDiff在模拟和真实世界数据集上的实验结果表明，该框架在协作物体检测性能上始终优于现有方法，并且在代理姿态和延迟信息具有高噪声的情况下，表现出高度所需的鲁棒性。源代码已发布，请参见link（文档中的链接）。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.22524", "html_url": "https://arxiv.org/abs/2503.22524", "title": "通过基于状态的轨迹拼接实现稳健的 Offline 质量数据学习", "title_en": "Robust Offline Imitation Learning Through State-level Trajectory Stitching", "authors": "Shuze Wang,Yunpeng Mei,Hongjie Cao,Yetian Yuan,Gang Wang,Jian Sun,Jie Chen", "background": "模仿学习（IL）能够通过专家演示使机器人获得视觉运动技能。然而，传统的 IL 方法依赖于高质量、通常稀缺的专家数据，并且容易受到协变量转移的影响。为了解决这些问题，最近的 Offline IL 进展将非最优的、无标记的数据集整合到训练中。", "innovation": "本文提出了一种基于状态的搜索框架，通过拼接不完美的演示中的状态-动作对，生成更多样化和更具信息量的训练轨迹，从而提高从混合质量 Offline 数据集中学习策略的效果，实现了稳健的 Offline 质量数据学习。", "conclusion": "实验结果表明，该方法在标准的模仿学习基准和实际的机器人任务中显著提高了泛化能力和性能。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09002", "html_url": "https://arxiv.org/abs/2503.09002", "title": "KNighter：通过LLM合成的检入符转换静态分析", "title_en": "KNighter: Transforming Static Analysis with LLM-Synthesized Checkers", "authors": "Chenyuan Yang,Zijie Zhao,Zichen Xie,Haoyu Li,Lingming Zhang", "background": "静态分析是检测关键系统（如操作系统内核）中错误的强大技术。然而，设计和实现静态分析器具有挑战性且耗时，通常局限于预定义的错误模式。尽管大型语言模型（LLMs）已显示在静态分析方面的潜力，但由于计算限制和上下文限制，直接应用于大规模系统扫描仍然不可行。", "innovation": "KNighter是第一个通过自动从历史错误模式中合成静态分析器来实现可扩展的LLM基础静态分析的方法。其主要创新在于，不直接使用LLMs进行大规模系统分析，而是利用LLMs生成由历史补丁知识引导的专业化静态分析器。KNighter通过一个多阶段合成管道来实现这一愿景，该管道验证检查器的正确性并使用自动化细化过程来逐步减少误报。", "conclusion": "在Linux内核上的评估表明，KNighter生成了高精度检查器，能够检测现有手工编写分析器忽略的各种错误模式。截至目前，KNighter合成的检查器已经在Linux内核中发现了92个新的、关键的长期潜伏错误（平均4.3年），其中77个已确认，57个已修复，30个已分配CVE编号。这一工作确立了通过检查器合成实现可扩展、可靠和可追踪的LLM基础静态分析的新范式。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.14048", "html_url": "https://arxiv.org/abs/2503.14048", "title": "超越全息理论：来自量子引力的熵基础与图像处理", "title_en": "Beyond holography: the entropic quantum gravity foundations of image processing", "authors": "Ginestra Bianconi", "background": "近年来，人工智能（AI）的发展使得构建理论物理学与人工智能之间的联系成为科学研究的热点。传统的连接主要集中在弦理论与图像处理的关系上，涉及重要的理论范式如全息理论。最近，G. Bianconi 提出了熵导引力（GfE）方法，通过洛伦兹时空关联的度量之间的几何量子相对熵（GQRE）推导引力。本文进一步探讨了Perona-Malik图像处理算法与GfE方法之间的联系，揭示了 Perona-Malik 算法在简单场景下实际上是 GfE 行动的梯度流。研究表明，Perona-Malik 算法在迭代过程中能够保留图像的锐利边缘特征，这与熵行动在经典熵最大化的预期不符，而是表明 GQRE 的最小化有助于保持复杂的图像结构。", "innovation": "本文创新之处在于揭示了Perona-Malik图像处理算法与熵导引力行动的内在联系，并强调了GQRE最小化与保持复杂图像结构之间的关系。这有助于建立GfE、机器学习和脑科学研究之间的深刻联系。", "conclusion": "研究结果提供了 Perona-Malik 算法的几何和信息论基础，并可能有助于建立 GfE 与机器学习和脑科学研究之间的更深层次联系。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.02737", "html_url": "https://arxiv.org/abs/2504.02737", "title": "RBT4DNN: 基于需求的神经网络测试", "title_en": "RBT4DNN: Requirements-based Testing of Neural Networks", "authors": "Nusrat Jahan Mozumder,Felipe Toledo,Swaroopa Dola,Matthew B. Dwyer", "background": "测试是帮助开发人员确定系统是否按预期工作的关键技术。然而，当系统包含深度神经网络（DNNs）时，测试变得非常具有挑战性。DNNs通过难以精确化的形式化方法来近似所需的函数，这使得基于功能需求的测试方法无法直接应用于DNNs。", "innovation": "本文提出了一种名为RBT4DNN（基于需求的DNN测试）的方法，该方法使用自然语言的需求陈述，结合词典定义语义特征空间，以便生成测试输入。RBT4DNN将功能需求的先决条件形式化为语义特征的逻辑组合。符合这些特征组合的训练数据可以用于微调生成模型，以可靠地生成满足先决条件的测试输入。在经过训练的DNN上执行这些测试，可以将其输出与预期的需求后置条件行为进行比较。我们提出两种RBT4DNN使用案例：一是根据定义DNN正确性属性的需求，RBT4DNN构成一种检测故障的新方法；二是开发期间，基于需求的模型行为探索可以给开发人员提供有关模型泛化的反馈。", "conclusion": "我们的进一步评估表明，RBT4DNN生成的测试是现实的、多样的，并与需求先决条件对齐，这使我们可以有针对性地分析模型行为并有效地检测故障。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18102", "html_url": "https://arxiv.org/abs/2505.18102", "title": "如何在不泄露正确答案的情况下发布我的大语言模型基准？", "title_en": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "authors": "Takashi Ishida,Thanawat Lodkaew,Ikko Yamane", "background": "发布大型语言模型基准的风险在于可能无意（或故意）将其用作训练或选择模型的工具。传统的隐私策略要求参与者向组织提交模型或预测结果，这种方法依赖于对单一组织的信任，同时仍可能导致测试集过拟合。为了克服这一问题，该研究提出了一种方式，即在不完全披露问题正确答案的情况下发布基准，同时仍能公开评估大语言模型。这种方法的核心是在答案中注入随机性，为问题准备几个逻辑正确的答案，只在基准中包含其中一个作为正确答案。这种方法降低了最佳可能准确度（即贝叶斯准确度），既有助于避免泄露正确答案，也提供了一种检测数据污染的方法。即使最先进的模型也无法超过贝叶斯准确度。实验结果表明，该方法在多种基准、模型和训练方法上能够准确地检测数据污染。", "innovation": "提出了一个方法，在不完全披露基准问题正确答案的情况下进行发布，通过向答案中注入随机性，为每个问题准备几个逻辑正确的答案，只确定其中一个作为正确答案，从而降低最佳准确度并检测数据污染。这种方法在保持评估开放性的同时，提高了数据隐私和基准的可信度。", "conclusion": "实验结果表明，该方法能够在多种基准、模型和训练方法上准确检测数据污染。该方法不仅有助于保护数据隐私，还提供了一种有效检测数据污染的手段，同时保持了对大语言模型的开放性评估。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.22381", "html_url": "https://arxiv.org/abs/2410.22381", "title": "使用不变统计损失对重尾和多变量分布进行隐式生成模型的稳健训练", "title_en": "Robust training of implicit generative models for multivariate and heavy-tailed distributions with an invariant statistical loss", "authors": "José Manuel de Frutos,Manuel A. Vázquez,Pablo Olmos,Joaquín Míguez", "background": "传统的隐式生成模型能够学习非常复杂的数据分布，但它们的训练过程通过对抗性的判别器来区分真实数据和生成数据，这会导致训练动态不稳定和模式丢失问题。许多真实世界的现象只能用重尾概率分布来适当描述，而传统的方法难以有效地捕捉这些分布的渐近行为。", "innovation": "本文基于文献中引入的不变统计损失(ISL)方法，将其扩展以处理重尾和多变量数据分布。通过引入生成器，使用一般帕累托分布(GPD)的输入噪声，提出了Pareto-ISL生成方案。此外，提出了一种新的损失函数，该函数通过随机投影适应多维数据，使其在高维空间中保持计算可行性和问题可处理性。", "conclusion": "实验证明，Pareto-ISL能够准确地建模分布的尾部特征，同时有效地捕捉其中心特征。通过随机投影的方法，该方法在高维生成建模中表现出良好的性能，并作为生成对抗网络(GANs)的预训练技术，防止模式坍塌，显示了其稳健性在不同超参数设置下的鲁棒性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.02025", "html_url": "https://arxiv.org/abs/2506.02025", "title": "LLM-Based Reasoning在多目标HPC作业调度中的有效性评估", "title_en": "Evaluating the Efficacy of LLM-Based Reasoning for Multiobjective HPC Job Scheduling", "authors": "Prachi Jadhav,Hongwei Jin,Ewa Deelman,Prasanna Balaprakash", "background": "HPC作业调度涉及平衡多种冲突目标，包括最小化工期、减少等待时间、优化资源使用和确保公平性。传统方法，如基于启发式的First-Come-First-Served (FJFS)和Shortest Job First (SJF)，或者复杂的优化技术，往往缺乏对动态工作负载的适应性，并且不能同时优化HPC系统中的多个目标。", "innovation": "本文提出了一种基于大型语言模型（LLM）的调度器，采用了ReAct风格框架（Reason + Act），实现迭代、可解释的决策过程。系统通过跟踪调度历史的scratchpad内存，并借助自然语言反馈精化决策，同时包含一个约束强制模块以确保可行性和安全性。", "conclusion": "与First-Come-First-Served (FJFS)、Shortest Job First (SJF)和Google OR-Tools方法的比较显示，基于LLM的调度能在多个目标之间实现有效平衡，通过自然语言痕迹提供透明的推理。虽然在约束满足和适应不同工作负载方面的表现优于传统方法，但在推理质量和计算开销之间存在权衡，可能影响实时部署。这些发现表明了使用高级语言模型解决动态HPC环境中复杂调度问题的潜力和局限性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03522", "html_url": "https://arxiv.org/abs/2505.03522", "title": "单图像超分辨率中模块移植性的优化：普遍性评估与循环残差块", "title_en": "Optimization of Module Transferability in Single Image Super-Resolution: Universality Assessment and Cycle Residual Blocks", "authors": "Haotong Cheng,Zhiqi Zhang,Hao Li,Xinshang Zhang", "background": "深度学习已显著推动了单图像超分辨率（SISR）领域的发展。然而，现有研究主要集中在性能上的改进，而很少关注架构组件间移植性的量化。", "innovation": "本文提出一个名为'Universality'的概念及其定义，将传统意义上的'泛化'扩展为涵盖模块转移性的便捷性。进一步提出了'普遍性评估方程'（UAE），此度量标准量化了模块移植的便利性，并揭示了多个现有度量对转移性的影响。依据UAE的结果设计了两种优化模块：循环残差块（CRB）和深度循环残差块（DCRB）。通过自然场景基准、遥感数据集及其他低级任务中的全面实验，表明嵌入所提即插即用模块的网络优于当前先进方法，在重建保真度几乎无损失的情况下分别实现了0.83 dB的PSNR提高或参数减少71.3%。", "conclusion": "所提的插件模块可应用于更广泛的基本模块优化中，提供了一种新的插件模块设计的新范式。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07900", "html_url": "https://arxiv.org/abs/2506.07900", "title": "MiniCPM4：端侧设备上的超高效大语言模型", "title_en": "MiniCPM4: Ultra-Efficient LLMs on End Devices", "authors": "MiniCPM Team:Chaojun Xiao,Yuxuan Li,Xu Han,Yuzhuo Bai,Jie Cai,Haotian Chen,Wentong Chen,Xin Cong,Ganqu Cui,Ning Ding,Shengda Fan,Yewei Fang,Zixuan Fu,Wenyu Guan,Yitong Guan,Junshao Guo,Yufeng Han,Bingxiang He,Yuxiang Huang,Baoxi Ji,Cunliang Kong,Qiuzuo Li,Siyuan Li,Wenhao Li,Xin Li,Yanghao Li,Yishan Li,Zhen Li,Dan Liu,Biyuan Lin,Yankai Lin,Xiang Long,Quanyu Lu,Yaxi Lu,Peiyan Luo,Hongya Lyu,Litu Ou,Yinxu Pan,Lushi Pu,Zekai Qu,Qundong Shi,Zijun Song,Jiayuan Su,Zhou Su,Ao Sun,Xianghui Sun,Peijun Tang,Fangzheng Wang,Feng Wang,Shuo Wang,Yudong Wang,Zheng Wang,Yesai Wu,Zhenyu Xiao,Jie Xie,Zihao Xie,Xiaoyue Xu,Yukun Yan,Jiarui Yuan,Jinqian Zhang,Kaihuo Zhang,Lei Zhang,Linyue Zhang,Xueren Zhang,Yudi Zhang,Hengyu Zhao,Weilin Zhao,Weilun Zhao,Yuanqian Zhao,Zhi Zheng,Chuyue Zhou,Ge Zhou,Jie Zhou,Wei Zhou,Yanghao Zhou,Zihan Zhou,Zixuan Zhou,Zhiyuan Liu,Guoyang Zeng,Chao Jia,Dahai Li,Maosong Sun", "background": "本文介绍了一种专为端侧设备设计的高效大型语言模型MiniCPM4。通过在四个关键维度（模型架构、训练数据、训练算法和推理系统）上的系统创新，实现了这一高效性。MiniCPM4专注于提升在底层硬件上的性能，特别是在处理长上下文时的效率。", "innovation": "MiniCPM4的创新点包括：1) InfLLM v2：一种可训练的稀疏注意机制，加快预填充和解码阶段；2) UltraClean：高效且准确的预训练数据过滤和生成策略；3) UltraChat v2：全面的监督微调数据集；4) ModelTunnel v2：高效的预训练策略搜索方法；5) BitCPM：分块化回滚的加载平衡强化学习和数据高效三元嵌位LLM；6) 推理系统：集成了稀疏注意机制、模型量化和推测性采样，实现高效的预填充和解码。这些技术共同提升了MiniCPM4的性能和效率。", "conclusion": "评测结果显示，MiniCPM4和MiniCPM4.1在各类基准测试中均优于同等规模的开源模型，且8B版本在长序列理解和生成方面的速度有显著提高。MiniCPM4提供两种版本，分别拥有0.5B和8B参数量。此外，还构建了MiniCPM4.1的混合推理模型，可用于深度推理和非推理模式。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.08570", "html_url": "https://arxiv.org/abs/2506.08570", "title": "自回归 vs 流匹配：文本到音乐生成建模范式比较研究", "title_en": "Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling Paradigms for Text-to-Music Generation", "authors": "Or Tal,Felix Kreuk,Yossi Adi", "background": "基于文本的音乐生成的进步使得模型能够合成高质量的音乐片段，完整的作品，甚至能够响应细致的控制信号，例如和弦进程。当前最先进的系统在许多维度上存在显著差异，如训练数据集、建模范式和架构选择。这种多样性使得公平地评估模型和确定哪些设计选择会影响性能最多变得复杂。", "innovation": "本研究专注于建模范式，而忽略数据和架构方面。通过系统实证分析，将两种arguably最常见的建模范式：自回归解码和条件流匹配进行对比研究。使用相同的训练数据集、配置和类似的骨干架构从头开始训练所有模型，并从多个维度评估性能，包括生成质量、推理配置的鲁棒性、可扩展性、遵守文本和时间对齐的条件以及通过音频修复形式的编辑能力。", "conclusion": "此比较研究揭示了每种范式的独特优势和局限性，提供了可以指导未来文本到音乐生成系统架构和训练决策的实际见解。音频样本示例可在以下链接下载：this https URL"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12964", "html_url": "https://arxiv.org/abs/2507.12964", "title": "基于人口统计信息的儿童腕部骨折细粒度分类", "title_en": "Demographic-aware fine-grained classification of pediatric wrist fractures", "authors": "Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota", "background": "腕部病理问题在儿童中频发，而基于人口统计信息的技术应用在医学影像诊断中的数据集有限，单一模态诊断不足。通过结合医学影像和患者人口统计信息，利用细粒度预训练模型可以提升骨折诊断的准确性。", "innovation": "首次将人口统计信息整合应用于腕部骨折细粒度分类，采用细粒度转換器方法和细粒度预训练模型，相对于粗粒度数据集如ImageNet，此方法显著提高了诊断准确性，特别是在大样本骨折数据集上的诊断准确率提高了超过10%。", "conclusion": "该研究通过多种方法结合，首次在儿童腕部骨折中实现了基于人口统计信息的细粒度分类，显著提高了诊断精度，为未来相关研究提供了新的思路和可能的改进方向。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.09523", "html_url": "https://arxiv.org/abs/2507.09523", "title": "探究学习状态值的行动值时差方法分析", "title_en": "An Analysis of Action-Value Temporal-Difference Methods That Learn State Values", "authors": "Brett Daley,Prabhat Nagarajan,Martha White,Marlos C. Machado", "background": "时差（TD）学习的核心特征是利用价值预测生成新的价值预测。大多数TD方法通过单一的行动价值函数（如Q学习和Sarsa）来生成新的预测。然而，较少关注通过两个不对称的价值函数来生成新预测的方法，即先学习状态值再学习行动值的方法。现有的这类算法可以分为QV学习和AV学习两种，尽管已经有一些研究，但仍不清楚何时以及在什么情况下学习两个价值函数比学习一个更有优势，以及这些方法是否在理论上是行之有效的。", "innovation": "本文分析了这两种算法家族的收敛性和样本效率。研究发现，在预测场景中，两种家族方法都优于期望Sarsa；但在控制场景中，只有AV学习方法相较于Q学习具有明显优势。此外，引入了一种新的AV学习算法—正则化 Dueling Q学习（RDQ），该算法在MinAtar基准测试中表现出显著的优越性。", "conclusion": "在研究这两种算法家族时，发现AV学习方法在控制场景中相对于Q学习的方法有所改进，而RDQ算法作为新的AV学习方法，在MinAtar基准测试中表现出色。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20790", "html_url": "https://arxiv.org/abs/2506.20790", "title": "Stochastic Parameter Decomposition", "title_en": "Stochastic Parameter Decomposition", "authors": "Lucius Bushnaq,Dan Braun,Lee Sharkey", "background": "神经网络逆向工程的一个关键步骤是将其分解为更简单的部分，以便可以相对独立地研究。线性参数分解是一种提出的框架，旨在解决当前分解方法的几个问题，它将神经网络参数分解为参数空间中稀疏使用的向量之和。然而，当前该框架的主要方法——基于归因的参数分解（APD），由于其计算成本高且对超参数敏感，使其在实际应用中不具可行性。", "innovation": "我们引入了一种名为Stochastic Parameter Decomposition (SPD)的方法，该方法比APD更具可扩展性和对超参数的鲁棒性。我们通过使用SPD分解比APD可以分解的稍微更大和更复杂的模型，证明了这一方法的有效性。此外，我们还展示了SPD如何避免其他问题，如学习参数的收缩，并在玩具模型中更好地识别真实机制。这项工作通过将因果中介分析与网络分解方法相结合，为在更大的模型中扩展线性参数分解方法开了新的研究可能性。", "conclusion": "通过SPD的演示，这项工作为机制可解释性研究去除了将线性参数分解方法推广到更大模型的障碍。我们为运行SPD和重复我们的实验开发了一个开源库。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14904", "html_url": "https://arxiv.org/abs/2507.14904", "title": "TriCLIP-3D: 一种基于CLIP的统一高效三模态3D视觉接地框架", "title_en": "TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP", "authors": "Fan Li,Zanyi Wang,Zeyi Huang,Guang Dai,Jingdong Wang,Mengmeng Wang", "background": "3D视觉接地允许一个具身智能体基于人类指令理解真实世界3D环境中的视觉信息，这对于具身智能至关重要。现有的3D视觉接地方法通常依赖于不同的编码器来处理不同模式的数据（例如，RGB图像、文本和3D点云），这导致了复杂且训练效率低的大规模模型。一些方法虽然使用预训练的2D多模态模型（如CLIP）来完成3D任务，但仍然难以使点云数据与2D编码器对齐。因此，这些方法仍需依赖3D编码器来提取特征，进一步增加了模型的复杂性和训练效率低下。", "innovation": "提出了一个统一的2D预训练多模态网络来处理RGB图像、文本和点云三种模态，通过使用2D CLIP双模态模型结合基于适配器的微调，该框架能够有效适应三个模态设置，提高跨模态理解和性能。设计了几何感知的2D-3D特征恢复和融合模块（GARF），将点云和图像的几何多尺度特征进行融合，并引入多模态解码器以促进深层次的跨模态理解。该方法实现了跨三种模态的一体化特征提取和融合，能够构建一个端到端的3D视觉接地模型。相比基线，该方法将可训练参数减少了约58%，同时在3D检测任务中取得了6.52%的性能提升，在3D视觉接地任务中取得了6.25%的性能提升。", "conclusion": "通过引入GARF模块和采用2D预训练多模态网络，TriCLIP-3D框架不仅简化了模型架构，还提高了模型的适应性和性能。实验证明，该方法在3D视觉接地任务上取得了显著的性能提升，同时显著减少了模型的可训练参数数量。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05774", "html_url": "https://arxiv.org/abs/2504.05774", "title": "可转移掩码变换器：基于区域自适应转移性估计的跨领域语义分割", "title_en": "Transferable Mask Transformer: Cross-domain Semantic Segmentation with Region-adaptive Transferability Estimation", "authors": "Jianhua Liu,Zhengyu Li,Yanru Wu,Jingge Wang,Yang Tan,Ruizhe Zhao,Guan Wang,Yang Li", "background": "近期，视觉变换器（ViTs）在语义分割任务上取得了卓越的表现。然而，在将预训练的ViTs适应新的目标领域时，由于数据分布的变化，性能会显著下降，这导致全局注意力变得不理想。自注意力机制由于其数据驱动性，可能会在源领域和目标领域存在纹理、尺度、对象共现模式差异的情况下，无法有效识别关键对象。虽然全局和局部域适应方法提供了一定的解决方案，但是针对不同图像区域存在空间异质性的转移性问题，空间区域级别的自适应策略至关重要。", "innovation": "本文提出了可迁移掩码变换器（TMT），这是一种用于语义分割的区域级自适应框架，它通过空间转移性分析对跨领域的表示进行对齐。TMT包括两个关键组件：(1) 自适应聚类自适应转移性估计器（ACTE），能动态地将图像分割成结构和语义上一致的区域，以对局部的转移性进行评估；(2) 可迁移掩码注意力（TMA）模块，该模块将区域特定的转移性图整合到ViTs的注意力机制中，优先对转移性低且语义不确定性高的区域进行自适应。", "conclusion": "在20对跨领域的数据集上的全面评估表明，TMT具有明显的优势，相对于纯微调，能够实现平均2%的MIoU提升，并且相比于现有最佳基线方法，提高了1.28%。代码将公开提供。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22627", "html_url": "https://arxiv.org/abs/2507.22627", "title": "LOTS of Fashion! 多条件控制的图像生成通过草图-文本配对", "title_en": "LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text Pairing", "authors": "Federico Girella,Davide Talon,Ziyue Liu,Zanxi Ruan,Yiming Wang,Marco Cristani", "background": "时尚设计是一个复杂的创造过程，它结合了视觉和文本表达。设计师通过素描和文本描述传达设计理念，素描定义空间结构和设计元素，而文本描述捕捉材料、纹理和风格细节。现有的图像生成方法要么侧重于全局描述，要么侧重于局部细节，但缺乏有效地将二者结合起来的方法。", "innovation": "本文介绍了一种名为 LOcalized Text and Sketch for fashion image generation（LOTs）的方法，该方法通过局部化的草图和文本信息的输入进行条件化生成完整的时尚效果图，并提出了一个新的基于步骤的融合并适应扩散策略。该方法首先通过模快化的配对中心表示将草图和文本编码到共享的潜在空间中，同时保留独立的局部特征，然后在扩散模型的多步去噪过程中通过注意指导集成局部和全局条件。", "conclusion": "方法在Fashionpedia基础上构建了名为Sketchy的数据集，包含了每个图像的多个文本-草图配对。定量结果表明，LOTs在全局和局部度量上均达到了最先进的图像生成性能，而定性的示例和人类评估研究也突显了其前所未有的设计定制水平。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02548", "html_url": "https://arxiv.org/abs/2508.02548", "title": "KG-ER概念模式语言", "title_en": "The KG-ER Conceptual Schema Language", "authors": "Enrico Franconi,Benoît Groz,Jan Hidders,Nina Pardal,Sławek Staworko,Jan Van den Bussche,Piotr Wieczorek", "background": "知识图谱在数据存储和信息表示方面有着广泛的应用，但现有知识图谱的概念模式语言通常依赖于特定的表示形式（如关系数据库、属性图、RDF等），这限制了知识图谱的通用性和灵活性。", "innovation": "KG-ER是一种概念模式语言，它可以独立于知识图谱的表示形式描述其结构，同时也能够帮助捕获存储在知识图谱中的信息的语义。", "conclusion": "KG-ER为知识图谱提供了一种更通用和灵活的方法来描述其结构和语义，增强了知识图谱的应用范围和实用性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08193", "html_url": "https://arxiv.org/abs/2508.08193", "title": "街边AI：大规模语言模型准备好进行真实世界判断了吗？", "title_en": "Street-Level AI: Are Large Language Models Ready for Real-World Judgments?", "authors": "Gaurab Pokharel,Shafkat Farabi,Patrick J. Fowler,Sanmay Das", "background": "近年来，大量研究探讨了大规模AI模型在进行“道德”判断时所引发的伦理和社会影响。这些研究多数集中在通过各种思想实验与人类判断的对齐上，或者集中在AI判断的群体公平性问题上。然而，AI最直接和可能的应用是在帮助或完全替代所谓的小巷级官僚，即决定分配稀缺社会资源或审批福利的人。历史上，确定社会在这些领域如何优先决策的原则构成了决定这些领域如何进行分配的重要基础。本研究评估大规模语言模型（LLM）在资源分配领域与人类判断及政府和社会决定的脆弱性评分系统的一致性，并且使用真实数据（通过严格保密仅使用本地大型模型）来完成分析，表明LLM在某些方面判断存在极大不一致，但也有与普通人判断的一致性。这些发现反驳了当前AI系统在高风险社会决策中普遍应用的可行性。", "innovation": "研究使用真实数据对大规模语言模型（LLM）的判断进行分析，探讨了LLM在资源分配等实际应用中的表现，并发现虽然存在不一致性，但在某些方面也表现出与普通人的判断一致性。这种研究方法强调了实际应用前进行详细评估的重要性，尤其是在涉及人类福利与资源分配的关键场景中。", "conclusion": "当前的AI系统还不够准备好在涉及高风险的社会决策中普遍应用。大规模语言模型的判断一致性不足，需要更深入的分析和改进以确保其在现实世界决策中的可接受性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.17527", "html_url": "https://arxiv.org/abs/2405.17527", "title": "Unisolver: 基于PDE的变换器向着通用神经PDE求解器", "title_en": "Unisolver: PDE-Conditional Transformers Towards Universal Neural PDE Solvers", "authors": "Hang Zhou,Yuezhou Ma,Haixu Wu,Haowen Wang,Mingsheng Long", "background": "深度模型最近作为解决偏微分方程（PDEs）的有希望工具涌现出来，称为神经PDE求解器。虽然从模拟数据或物理信息损失训练的神经求解器在求解PDE方面表现良好，但它们主要局限于少数几种PDE实例，例如具有特定系数集的方程。这限制了它们对各种PDE的泛化能力，阻碍了它们成为数值求解器的实用替代模型。本文探讨了这些限制。", "innovation": "本文提出了一种名为Unisolver的新型Transformer模型，该模型在多样化数据上训练，并针对多样化PDE进行条件化，旨在构建一个能够解决广泛PDE的通用神经PDE求解器。Unisolver并未仅仅增加数据和参数规模，而是基于PDE解算过程的理论分析。通过借鉴PDE的数学结构，即方程解从根本上由方程符号和边界条件等一系列PDE组件所治理，Unisolver定义了一个完整的PDE组件集，灵活嵌入它们作为领域和点级别的深层条件，从而精细化嵌入Transformer PDE求解器中。Unisolver结合了物理洞察和最近的Transformer进展，在三个具有挑战性的大规模基准测试中实现了持续的最优性能，展示了出色的性能和泛化能力。", "conclusion": "Unisolver通过将多样化的PDE组件作为条件输入，结合物理洞察和Transformer架构，展示了在多个大规模基准中取得的一致最优性能，证明了其实用性和广泛的适用性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08524", "html_url": "https://arxiv.org/abs/2508.08524", "title": "StreetViewAI: 使用上下文感知多模态AI使街景可见", "title_en": "StreetViewAI: Making Street View Accessible Using Context-Aware Multimodal AI", "authors": "Jon E. Froehlich,Alexander Fiannaca,Nimer Jaber,Victor Tsaran,Shaun Kane", "background": "当前的交互式街景地图工具如谷歌街景（GSV）和Meta Mapillary虽然可以让用户通过沉浸式360度图像虚拟导航和体验现实世界的环境，但仍然对视障用户来说是根本不可访问的。本文介绍了一个首个无障碍街景工具——StreetViewAI，它结合了上下文感知的多模态AI、无障碍导航控件和对话式语音，使视障用户可以虚拟地检查目的地、进行自由世界的探索或访问GSV部署的超过220亿张图像和100多个国家中的任何一个地点进行虚拟旅游。此项研究通过一个混合视觉能力团队进行迭代设计，并进行了11名视障用户的评估。研究表明，无障碍街景在支持地点调查和远程路线规划方面具有价值。论文最后列出了未来工作的关键指导原则。", "innovation": "StreetViewAI 创新地结合了上下文感知的多模态AI、无障碍导航控件和对话式语音，为视障用户提供了首个无障碍街景工具。它突破了现有街景技术对视障用户的不可访问性限制，使用户能够进行虚拟目的地检查、自由世界探索和虚拟旅游。此外，该工具通过混合视觉能力团队的迭代设计得以实现，并通过具体的实验验证了其价值。", "conclusion": "StreetViewAI 的研究体现了无障碍街景在支持地点调查和远程路线规划中的价值。未来的工作将遵循列出的关键指导原则，进一步开发和优化该工具，以更好地满足视障用户的需求。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.18452", "html_url": "https://arxiv.org/abs/2502.18452", "title": "FRIDA to the Rescue! 分析基于对象的常识推理中合成数据效果", "title_en": "FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response", "authors": "Mollie Shichman,Claire Bonial,Austin Blodgett,Taylor Hudson,Francis Ferraro,Rachel Rudinger", "background": "在灾难救援场景中，大型语言模型（LLMs）在物理推理方面的潜力可以帮助实现任务目标，但这些能力往往仅限于较大的模型，由于尺寸限制，目前不适合部署在机器人系统中。文章介绍了一种新的数据集和管道，以创建Field Reasoning and Instruction Decoding Agent (FRIDA)模型，旨在满足特定问题空间需求。", "innovation": "作者提出了一套新的数据集和流程，结合领域专家和语言学家的知识，生成高质量、少量示例的数据，用于生成适合细调的合成数据。同时，作者还进行了一项消融研究，以确定哪些类型的合成数据对性能影响最大，并发现仅基于对象物理状态和功能数据的FRIDA模型在评估中表现出色，超过了使用全部合成数据训练的FRIDA模型和基模型。", "conclusion": "FRIDA管道能够通过少量数据灌输物理常识，提高语言模型在灾难响应中的物理推理能力。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.18464", "html_url": "https://arxiv.org/abs/2508.18464", "title": "量子变换器中的可学习编码向量化注意力", "title_en": "Vectorized Attention with Learnable Encoding for Quantum Transformer", "authors": "Ziqing Guo,Ziwen Pan,Alex Khan,Jan Balewski", "background": "向量量子块编码提供了一种将经典数据嵌入希尔伯特空间的方法，有助于量子模型如量子变换器(QT)的实现。当前的QT依赖于深度参数化量子电路(PQC)，这使得它们容易受到量子处理单元(QPU)噪声的影响，从而限制了它们的实际性能。", "innovation": "本文提出了一种名为向量量子变换器(VQT)的模型，它通过量子近似模拟实现理想掩蔽注意力矩阵计算，并借助向量化的非线性量子编码实现高效的训练，从而获得高效的量子电路模拟(QCS)和减少经典采样开销。此外，在IBM和IonQ的量子电路模拟中进行了准确性的比较，并在IBM最先进的高保真Kingston QPU上进行了自然语言处理任务的基准测试，展示了竞争性结果。", "conclusion": "该噪声中间规模量子友好型VQT方法为端到端的量子计算中的机器学习解锁了一种新型架构。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14723", "html_url": "https://arxiv.org/abs/2508.14723", "title": "移植再生：一种新的文本数据增强范式", "title_en": "Transplant Then Regenerate: A New Paradigm for Text Data Augmentation", "authors": "Guangzhan Wang,Hongyu Zhang,Beijun Shen,Xiaodong Gu", "background": "数据增强是深度学习中一项关键的技术。传统的技术，如回译，主要集中在词汇层面的改写，生成具有相同语义的变体。大规模语言模型（LLMs）通过其“知识涌现”能力改善了文本增强，但控制输出的风格和结构仍然具有挑战性，需要精心设计的提示工程。本文分析了现有技术的局限性和挑战。", "innovation": "本文提出了LMTransplant，一种利用LLMs的新文本增强范式。LMTransplant的核心思想是：在由LLMs扩展的上下文中植入种子文本，并要求LLMs基于扩展的上下文再生一个变体。这种方法允许模型充分利用LLMs中嵌入的知识，生成更具多样性和创造力的内容级变体，同时保留原始文本的核心属性。", "conclusion": "我们对LMTransplant进行了各种文本相关任务的评估，证明了其在现有文本增强方法中的优越性能。此外，LMTransplant展示了出色的可扩展性，数据增强的规模越大，其性能越优越。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08715", "html_url": "https://arxiv.org/abs/2508.08715", "title": "MultiGen：带有LLMs的儿童友好多语言语音生成器", "title_en": "MultiGen: Child-Friendly Multilingual Speech Generator with LLMs", "authors": "Xiaoxue Gao,Huayun Zhang,Nancy F. Chen", "background": "生成式语音模型已经在提升人机交互方面展现出显著的潜力，特别是在儿童语言学习等领域有重要的应用价值。然而，高质量且适合儿童的语音生成技术仍然具有挑战性，尤其对于资源匮乏的语言更为困难。", "innovation": "本文提出了MultiGen，一种利用大型语言模型架构进行面向低资源语言的儿童友好语音生成的多语言语音生成模型。它引入了适合不同年龄段的多语言语音生成技术，并在三种低资源语言中实现了这一目标：新加坡口音普通话、马来语和泰米尔语。", "conclusion": "实验结果表明，MultiGen 在客观指标和主观评价方面均优于基准方法，展示了其在多语言环境中为儿童提供更自然互动的能力。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15269", "html_url": "https://arxiv.org/abs/2507.15269", "title": "高效率视频压缩中的条件视频生成", "title_en": "Conditional Video Generation for High-Efficiency Video Compression", "authors": "Fangqiu Yi,Jingyu Xu,Jiawei Shao,Chi Zhang,Xuelong Li", "background": "知觉研究显示，条件扩散模型在重建与人类视觉感知相匹配的视频内容方面表现出色。受到这一洞察的启发，本文提出了一个利用条件扩散模型进行感知优化重建的视频压缩框架。", "innovation": "本文将视频压缩重新定义为一个条件生成任务，通过生成模型从稀疏而有信息性的信号中合成视频。主要创新点包括：1) 多粒度的条件模块，能够捕捉静态场景结构和动态空间-时间线索；2) 用于高效传输的紧凑表示；3) 多模态条件训练，结合了模态 Dropout 和角色感知嵌入，以防止对单一模态的过度依赖并增强鲁棒性。", "conclusion": "大量实验表明，本文方法在感知质量指标（如 Fréchet 视频距离 FVD 和 LPIPS）上显著优于传统和神经编解码器，特别是在高压缩比的情况下。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.10118", "html_url": "https://arxiv.org/abs/2502.10118", "title": "图像嵌入采样方法用于生成多样化的图像字幕", "title_en": "Image Embedding Sampling Method for Diverse Captioning", "authors": "Sania Waheed,Na Min An", "background": "图像字幕技术的性能在最新的视觉语言模型（VLMs）上取得了显著的提升，但随之而来的是计算复杂度的增加，这使得它们在资源受限的应用场景，如移动设备和辅助技术中不太适用。相比之下，较小的视觉语言模型更侧重于高层次的场景描述，而忽略了细节，这些细节对于更好地理解图像至关重要。因此，尽管大模型的性能强大，但在某些应用中，它们的复杂性和占空间的缺点限制了它们的使用。为了解决这一问题，研究者提出了一种无需额外训练的框架。", "innovation": "该论文提出了一种基于小的BLIP视觉语言模型的无训练框架，通过明确关注图像的不同区域来增强字幕的多样性和信息量。这种方法利用结构化语义生成层次表示，同时捕捉全局和局部的语义。实验结果表明，该方法能够使较小的视觉语言模型在图像字幕对齐、语义完整性和多样性方面达到与大型模型相当的性能，同时保持较高的图像和字幕相关性与语义完整性。", "conclusion": "该框架已在MSCOCO、Flickr30k和Nocaps测试数据集上进行了评估，分别取得了0.735、0.750和0.748的Div-2得分，同时也保持了与人类标注字幕高度的相关性与语义完整性。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.20117", "html_url": "https://arxiv.org/abs/2508.20117", "title": "人工智能正在重塑地球科学国际学术社区的格局吗？", "title_en": "Is Artificial Intelligence Reshaping the Landscape of the International Academic Community of Geosciences?", "authors": "Liang Li,Yuntian Li,Wenxin Zhao,Shan Ye,Yun Lu", "background": "本文通过文献计量分析和主题建模发现，人工智能(AI)正积极地改变着地球科学研究。近年来，与AI相关的科学产出显著增加。研究表明，发展中国家的地球科学家在AI for Science (AI4S)范式中的可见性有所提高，同时人工智能也在改善地球科学研究领域的国际合作格局。", "innovation": "本文通过文献计量分析和主题建模的方法，揭示了人工智能在地球科学研究中的影响，并指出发展中国家地球科学家的参与度有了明显提高，同时也增强了国际合作的局面。", "conclusion": "人工智能正在积极地重塑地球科学的研究格局，提高发展中国家科学家的可见性，并改善了跨国际的研究合作。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.20293", "html_url": "https://arxiv.org/abs/2508.20293", "title": "Beacon: 集成网格选择的后训练量化", "title_en": "Beacon: Post-Training Quantization with Integrated Grid Selection", "authors": "Shihao Zhang,Rayan Saab", "background": "量化是一种广泛采用的压缩技术，用于减少大规模预训练模型的内存和计算成本。后训练量化（PTQ）中的一个关键挑战是在每个通道上选择合适的缩放因子，以便用来自缩放整数网格的值替换权重值。现有的方法通常通过启发式调整或网格搜索来固定缩放因子。", "innovation": "我们提出了Beacon算法，这是一种简单且有效的算法，可以消除手动调整的需要。Beacon直接使用未缩放的网格执行每个通道的PTQ，并通过利用标量量化几何学来自动确定最优的缩放因子。它不依赖于反向传播或大型校准集。尽管结构简单且无需调整，但Beacon在与最先进的方法竞争性能方面，是一种实用的解决方案，适合高效的模型部署。", "conclusion": "Beacon算法通过对网格选择的集成处理，能够在不需要手动调参的情况下，达到与最先进的后训练量化方法相当甚至更好的性能，为模型部署提供了更高效、更自动化的选择。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00215", "html_url": "https://arxiv.org/abs/2509.00215", "title": "通过耦合反向传播的第一阶模型化基础RL", "title_en": "First Order Model-Based RL through Decoupled Backpropagation", "authors": "Joseph Amigo,Rooholla Khorrambakht,Elliot Chane-Sane,Nicolas Mansard,Ludovic Righetti", "background": "近年来，利用模拟器的导数来提高学习效率的强化学习（RL）方法引起了越来越多的兴趣。尽管基于梯度的早期方法在性能上优于无导数方法，但由于实现成本高昂或无法获取，直接访问模拟器的梯度往往不可行。基于模型的强化学习（MBRL）可以通过学习动态模型来近似这些梯度，但在训练过程中，预测误差的累积会影响策略性能。本文提出了一种轨迹生成与梯度计算解耦的方法：使用模拟器生成轨迹，通过学习的可微分模拟器模型进行反向传播计算梯度。这种混合设计能够在无法获取模拟器梯度的情况下实现高效且一致的第一阶策略优化，并且可以从模拟回放中学习更准确的批评者函数。", "innovation": "本文提出了一种将策略优化和梯度计算解耦的MBRL方法，能够利用学习到的可微分模拟器模型进行反向传播计算梯度。这种方法结合了第一阶优化的高效性和模型化的通用性，实现了与专门优化器（如SHAC）相当的样本效率和速度，同时避免了其他第一阶MBRL方法中的不良行为。", "conclusion": "本文的方法在基准控制任务和实Go2四足机器人上的四足和双足运动任务中均表现出了有效性。通过实验证明，该方法在不具备模拟器梯度的情况下仍然能够实现高效且一致的第一阶策略优化，并可以从中学习更准确的批评者函数。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01185", "html_url": "https://arxiv.org/abs/2509.01185", "title": "语言模型训练和评估中合成长上下文数据生成的模块化技术", "title_en": "Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation", "authors": "Seganrasan Subramanian,Abhigya Verma", "background": "大型语言模型（LLMs）能够处理和推理长文本输入的能力对于许多实际应用至关重要。但在这一领域的发展受到缺乏高质量、多样化且可验证的长语境数据集的限制，这些数据集既适合训练又适合评估。这项工作介绍了一种通过提示式与LLM交互的模块化和可扩展的框架，用于合成长上下文字生成。该框架支持多种训练和对齐目标，如监督微调（SFT）、直接偏好优化（DPO）和组相对策略优化（GRPO）。它包括四种核心生成范式：多回合对话、文档导向的输入-输出对、可验证的指令-响应任务和长语境推理案例。通过模板提示、模型无偏架构和元数据增强输出，所提出的方法能够实现可扩展、可控且目标定向的数据集创建，以推进LLMs的长语境能力。", "innovation": "提出了一个模块化、可扩展的框架，用于通过提示与语言模型的交互来合成长上下文字生成，支持多种训练和对齐目标，包括监督微调、直接偏好优化和组相对策略优化。框架包括四种核心生成范式：多回合对话、文档导向的输入-输出对、可验证的指令-响应任务和长语境推理案例。通过模型无偏架构和元数据增强输出，可以实现可扩展、可控且目标定向的数据集创建。", "conclusion": "通过模块化框架和模板提示，这种新的合成长上下文字生成技术可以为语言模型提供可扩展、可控且目标定向的数据集，从而推动语言模型的长语境处理能力的发展。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00616", "html_url": "https://arxiv.org/abs/2509.00616", "title": "TimeCopilot", "title_en": "TimeCopilot", "authors": "Azul Garza,Reneé Rosillo", "background": "本文介绍了TimeCopilot，这是一种结合了时间序列基础模型（TSFMs）和大型语言模型（LLMs）的开源框架，通过单一统一的API并行处理。时间序列预测是一个复杂的过程，通常需要数据预处理、模型选择、模型验证和预测生成等多个步骤，这些步骤大多需要人工干预。此外，当前许多先进的预测框架可能缺乏自动化的预测管理流程，以及提供自然语言解释和直接查询未来的能力。", "innovation": "TimeCopilot通过一个单一的API自动化处理从特征分析到模型选择、交叉验证和预测生成的整个预测管道，还提供自然语言解释和直接查询未来的能力。该框架对大型语言模型无依赖性，兼容商业和开源模型，支持不同预测家族的集成。实验结果表明，TimeCopilot在GIFT-Eval基准测试中的概率预测表现达到了最先进的技术水准，且成本低。该框架为可重复、可解释和可访问的智能预测系统奠定了实用基础。", "conclusion": "TimeCopilot框架提供了一个实用的基础，用于构建具有可重复性、可解释性和可访问性的智能预测系统，特别适用于需要自动化预测管理和解释未来数据的应用场景。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01221", "html_url": "https://arxiv.org/abs/2509.01221", "title": "DaMoC: 基于数据和模型压缩高效选择适合微调特定领域任务的最佳大型语言模型", "title_en": "DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Tasks Based on Data and Model Compression", "authors": "Wei Huang,Huang Wei,Yinggui Wang", "background": "大型语言模型（LLMs）在通用任务上表现出色，但在特定领域任务上表现不佳，需要使用特定数据进行微调。随着许多开源LLM的可用性增加，选择最适合特定下游任务的模型变得尤为困难，主要集中在快速识别最优模型的方法上。", "innovation": "本文提出了一种名为DaMoC的数据和模型压缩框架，通过2个层面解决此问题：数据层面，建立了一套系统化的数据过滤方法分类，分为分布意识方法、质素意识方法和结合两种维度的混合方法，并增加了关键词汇的密度以实现词汇压缩，使用LLM迭代重写文本以优化表达。模型层面，通过层相似性得分评估每个层的重要性，并移除低重要层，引入稀疏合并方法以尽可能保留原始模型的能力。", "conclusion": "在四个数据集（医学问答、金融问答、通用问答和阅读理解）上进行了广泛实验，结果表明可以有效选择最优的LLM，同时节省大约20倍的训练时间。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01153", "html_url": "https://arxiv.org/abs/2509.01153", "title": "EZhouNet:一种基于图神经网络和锚区间框架的呼吸音事件检测方法", "title_en": "EZhouNet:A framework based on graph neural network and anchor interval for the respiratory sound event detection", "authors": "Yun Chu,Qiuhao Wang,Enze Zhou,Qian Liu,Gang Zheng", "background": "听诊是早期诊断呼吸和肺部疾病的关键方法，依赖于高技能的医疗专业人员。然而，这一过程往往是主观的，不同专家之间存在变异性。因此，基于深度学习的自动分类方法大量涌现，大多数关注呼吸音分类。相比之下，呼吸音事件检测方面的研究仍较少。现有方法通常依赖于帧级预测的后续后处理以生成事件级输出，使得直接学习间隔边界变得困难。此外，许多方法只能处理固定长度的音频，限制了它们对变长呼吸音的应用。此外，呼吸音位置信息对检测性能的影响尚未得到广泛探索。", "innovation": "提出了一个基于图神经网络和锚区间框架（EZhouNet）的呼吸音事件检测方法。该方法可以处理变长音频并提供异常呼吸音事件的更精确的时间定位。该方法提高了呼吸音检测的灵活性和适用性。", "conclusion": "实验表明，所提出的方法在SPRSound 2024和HF Lung V1数据集上有效，并通过加入呼吸位置信息增强了对异常声音的区分能力。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02591", "html_url": "https://arxiv.org/abs/2509.02591", "title": "2025年MIDOG赛道2病理基础模型集成用于异常有丝分裂分类", "title_en": "Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2: Atypical Mitosis Classification", "authors": "Mieko Ochi,Bae Yuan", "background": "有丝分裂形态被分为典型和非典型变异，非典型的数量与肿瘤的侵袭性密切相关。准确区分这些变异对于患者的预后和资源分配至关重要，但即使是专家病理学家也难以做到这一点。本研究利用在大量病理学数据集上预先训练过的Pathology Foundation Models (PFMs)，通过低秩适应进行参数高效微调。同时，我们引入了ConvNeXt V2这一先进的卷积神经网络架构来补充PFMs。在训练过程中，我们采用鱼眼变换来强调有丝分裂，并使用ImageNet目标图像的傅里叶域适应。最后，我们集成多个PFMs，以整合互补的形态学洞察，取得了在Preliminary Evaluation Phase数据集上竞争性的平衡准确性。", "innovation": "本研究创新之处在于：1) 使用Pathology Foundation Models (PFMs) 预训练模型，并通过低秩适应进行低参数高效微调；2) 引入ConvNeXt V2，这是一种最新的卷积神经网络架构；3) 利用鱼眼变换强调有丝分裂；4) 使用ImageNet目标图像进行傅里叶域适应；5) 集成多个PFMs以获得互补的形态学洞察。", "conclusion": "本研究通过集成多个PFMs，取得了在Preliminary Evaluation Phase数据集上竞争力的平衡准确性，展示了对异常有丝分裂分类的有效方法。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03525", "html_url": "https://arxiv.org/abs/2509.03525", "title": "基于语音的认知筛查：大规模语言模型适应策略的系统评估", "title_en": "Speech-Based Cognitive Screening: A Systematic Evaluation of LLM Adaptation Strategies", "authors": "Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sepehr Karimi,Sina Rashidi,Ali Zolnour,Maryam Dadkhah,Yasaman Haghbin,Hossein AzadMaleki,Maryam Zolnoori", "background": "美国超过一半患有阿尔茨海默病及相关痴呆症的成人未被诊断，而基于语音的筛查具有可扩展性。研究人员通过DementiaBank语音语料库评估了九种文本模型和三种多模态音频-文本模型，旨在比较不同大规模语言模型适应策略对痴呆症检测的效果。这些策略包括上下文学习的不同展示选择策略、增强推理提示、参数高效微调和多模态集成等方法。", "innovation": "研究采用DementiaBank语音语料库，系统性地评估了不同的大规模语言模型适应策略，包括上下文学习、增强推理提示、参数高效微调和多模态集成方法等。研究发现，类中心展示在上下文学习中表现最佳，推理可以提高小型模型的效果，而基于token的微调通常可以产生最佳得分。增加分类头可以显著改善表现较差的模型。在多模态模型中，微调音频-文本系统表现良好，但未超过最佳文本模型。这些发现强调了适应策略，包括展示选择、推理设计和调优方法，对基于语音的痴呆症检测至关重要，并且适当地适应的开放权重模型可以匹配或超过商业系统的效果。", "conclusion": "这些研究表明，适应策略，包括展示选择、推理设计和调优方法，对基于语音的痴呆症检测至关重要，并且适当地适应的开放权重模型可以匹配或超过现有的商业系统。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02175", "html_url": "https://arxiv.org/abs/2509.02175", "title": "理解空间是火箭科学——只有顶级推理模型才能解决空间理解任务", "title_en": "Understanding Space Is Rocket Science -- Only Top Reasoning Models Can Solve Spatial Understanding Tasks", "authors": "Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque", "background": "目前开源和前沿商用视觉语言模型在空间关系理解方面表现出明显的不足，而基于链式思维的模型在认知能力上却取得了令人惊讶的高表现。尽管已有的一些基准测试涉及空间关系理解，但其中的对象位置识别与空间推理的贡献尚不清楚，这阻碍了对模型瓶颈的深入理解。因此，研究人员需要开发一个新的基准来专门测试空间关系理解，并分离对象定位和空间推理的影响。", "innovation": "研究团队提出了RocketScience，一个开源对比视觉语言模型基准，用于测试空间关系理解。该基准包含了全新的真实世界图像-文本对，重点考查相对空间理解和物体顺序。RocketScience设计面临的挑战对人类来说很有挑战性，但对现有的视觉语言模型却十分艰巨，这得到了实验证明。同时，研究者还进行了分离分析，以区分基于链式思维模型中对象定位和空间推理的贡献，并发现基准测试上的表现受制于空间推理而非对象定位能力。开源的数据集和评估代码的提供允许其他研究人员进一步研究和改进。", "conclusion": "研究成果表明了开源和前沿商业视觉语言模型在空间关系理解方面存在明显缺陷，而推理模型在这方面的性能却出乎意料地高。通过RocketScience，发现在某些基于链式思维的模型中，空间推理的瓶颈限制了其整体性能表现，而不仅仅是对象定位能力的问题。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.13755", "html_url": "https://arxiv.org/abs/2508.13755", "title": "RLVR深度与广度协同：通过自适应探索解锁LLM推理收益", "title_en": "Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with Adaptive Exploration", "authors": "Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Dongchun Xie,Yiwei Wang,Xiaodan Liang,Jing Tang", "background": "Reinforcement Learning with Verifiable Reward (RLVR) 已经成为解锁大型语言模型推理能力的强大范式，但其潜力受两个未充分探索的维度的限制：深度（模型能解决的最复杂问题）和广度（每次迭代中消耗的实例数）。GRPO 算法中存在系统性偏差，累积优势使中等准确度的样本过度权重，而忽视了对扩展推理边界至关重要的低准确度实例。增加扩展深度需要新的策略以纠正这一偏差。", "innovation": "引入了 Difficulty Adaptive Rollout Sampling (DARS)，该方法在多次阶段性的采样中重权困难问题，从而增加难问题的正面采样数量，这能够一致地提高 Pass@K 的收益而不需要额外的推理成本。同时提出 DARS-B，结合 DARS 和大规模广度训练，同时展示了 Pass@K 和 Pass@1 的收益增加。研究证实了在 RLVR 中，深度与自适应探索广度是两个独立但互补的维度，对释放 RLVR 的推理能力至关重要。", "conclusion": "通过 DARS 和 DARS-B 方法，RLVR 在深度和广度探索上有了显著进步，证明了这两个维度是独立且互补的，对于增强大型语言模型的推理能力至关重要。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03526", "html_url": "https://arxiv.org/abs/2509.03526", "title": "通过强化行为对准提升语音大型语言模型", "title_en": "Enhancing Speech Large Language Models through Reinforced Behavior Alignment", "authors": "Yansong Liu,Jiateng Li,Yuan Liu", "background": "近年来，大型语言模型（LLMs）在语音处理方面取得了显著进展，催生了能够接受语音或文本形式用户请求的语音大型语言模型（SpeechLMs）。然而，由于跨模态差异，SpeechLMs在指令跟随任务上的性能仍然不及基于文本的同类模型，特别是在处理用户语音的动态性和变化性方面。", "innovation": "引入了一个名为强化行为对准（RBA）的框架，该框架通过一种强大的教师LLM生成高保真度的对准数据，并利用强化学习方法使SpeechLMs与教师模型的行为对准。这种方法能够在不依赖于人类注释的情况下有效提升SpeechLMs的指令跟随能力。", "conclusion": "实验结果表明，RBA方法显著提高了SpeechLMs的指令跟随能力，超越了传统的蒸馏基线。此外，RBA可以无缝拓展至包括语音问答和语音转文本翻译在内的任务，并在开放基准上取得了领先性能。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03249", "html_url": "https://arxiv.org/abs/2509.03249", "title": "结构转移：基于推理的表示转换 calculus", "title_en": "Structure Transfer: an Inference-Based Calculus for the Transformation of Representations", "authors": "Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng", "background": "表示的选择是我们有效沟通和推理的关键。主要未解决的问题是如何设计一种在不同表示系统（RS）间进行表示转换和选择的技术。本文提出了一种新的 calculus——结构转移，以解决这一问题。", "innovation": "提出的结构转移 calculus 允许从源 RS 生成目标 RS 的目标表示。该方法的特点是能够确保源表示和生成的目标表示满足任意指定的关系（如语义等价）。通过利用编码 RS 知识的 schemas（模式），结构转移可以推导出目标表示的结构，以确保所需关系的成立。这种方法借助构造空间的概念进行形式化，并具有足够的抽象和通用性，能够适用于各种不同类型的 RS，包括形式语言、几何图形、图表以及非正式的表示。", "conclusion": "结构转移是一种系统无关的 calculus，可以应用于各种实际环境中识别替代表示，从而为不同 RS 间进行表示转换和选择提供了一种有效的方法。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03528", "html_url": "https://arxiv.org/abs/2509.03528", "title": "ProLiFIC数据集：利用大型语言模型揭示意大利立法过程", "title_en": "The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process", "authors": "Matilde Contestabile,Chiara Ferrara,Alberto Giovannetti,Giovanni Parrillo,Andrea Vandin", "background": "过程挖掘（PM）最初在工业和商业领域得到发展，但最近也被应用于社会系统，包括法律系统。然而，法律领域中PM的有效性受限于数据集的可访问性和质量。本文介绍了ProLiFIC（意大利众议院立法流程），这是一个从1987年至2022年的全面事件日志，源自Normattiva门户的非结构化数据并通过大型语言模型（LLMs）进行结构化处理。ProLiFIC与将PM与LLMs集成的近期努力相一致。本文展示了初步分析并提出ProLiFIC作为法律领域PM的标准数据集，以促进新的发展.", "innovation": "ProLiFIC通过利用大型语言模型对非结构化数据进行结构化处理，构建了一个全面的意大利立法流程事件日志。它为法律领域中的过程挖掘提供了新的工具和数据支持，有助于法律流程的透明化和效率提升。", "conclusion": "ProLiFIC作为法律领域过程挖掘的一个基准数据集，可以成为进一步研究和开发的基础，促进了法律流程分析的新发展。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00813", "html_url": "https://arxiv.org/abs/2509.00813", "title": "AImoclips: 一种评估文本到音乐生成中情感传达的基准", "title_en": "AImoclips: A Benchmark for Evaluating Emotion Conveyance in Text-to-Music Generation", "authors": "Gyehun Go,Satbyul Han,Ahyeon Choi,Eunjin Choi,Juhan Nam,Jeong Mi Park", "background": "文本到音乐（TTM）生成的进步已经使使用自然语言提示进行可控且表达性强的音乐创作成为可能。然而，TTM系统的情绪精确性与人类偏好或文本对齐相比仍然很大程度上被忽视。本研究介绍了一个名为AImoclips的新基准，用于评估TTM系统如何向人类听众传达预期的情感，涵盖了开源和商业模型。", "innovation": "本研究创建了一个新的基准——AImoclips，用于评估TTM系统如何向人类听众传达预期的情感。通过使用六个最先进的TTM系统生成超过1000个音乐片段，研究发现商业系统生成的音乐倾向于比预期更愉快，而开源系统则相反。高唤醒条件下，所有模型更准确地传达情感。所有系统都表现出对情感中立的偏好，凸显了情感控制的关键限制。", "conclusion": "该基准提供了关于各个模型特定情感呈现特性的有价值的见解，并支持未来开发情感对齐的TTM系统的发展。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02349", "html_url": "https://arxiv.org/abs/2509.02349", "title": "AudioCodecBench: 一种综合的音频编解码评估基准", "title_en": "AudioCodecBench: A Comprehensive Benchmark for Audio Codec Evaluation", "authors": "Lu Wang,Hao Chen,Siyu Wu,Zhiyue Wu,Hao Zhou,Chengfeng Zhang,Ting Wang,Haodi Zhang", "background": "多模态大型语言模型（MLLMs）已在语音和音乐领域得到了广泛应用，导致了对音频分词的重视。与仅关注语义的文本令牌不同，音频令牌必须同时捕捉全局语义内容并保留细微的声音细节。此外，音频令牌为演讲和音乐提供了一种离散的方法，可以有效地融入MLLMs。然而，现有研究在定义语义令牌和声音令牌时存在问题。此外，对不同编解码器的评估通常集中在特定领域或任务上，如重建或自动语音识别（ASR）任务，这阻碍了公平和全面的比较。", "innovation": "该论文提供了解决上述问题的方案，提出了适合语义和声音令牌的定义，并引入了一种系统化的评估框架。该框架从四个维度对编解码器的能力进行全面评估：声音重建度量、代码簿索引（ID）稳定性、仅解码器变换器的困惑度以及下游探测任务的性能。", "conclusion": "实验结果表明所提供的适合定义的正确性以及重建度量、代码簿ID稳定性、下游探测任务和困惑度之间的相关性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03531", "html_url": "https://arxiv.org/abs/2509.03531", "title": "长文本生成中的实时幻觉实体检测", "title_en": "Real-Time Detection of Hallucinated Entities in Long-Form Generation", "authors": "Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda", "background": "大型语言模型现在被广泛用于医疗咨询或法律建议等高风险应用场景，这些场景中生成的幻觉可能导致严重后果。现有的幻觉检测方法要么只适用于简短的事实问题，要么需要昂贵的外部验证，因此在实际应用中不可行。", "innovation": "本文提出了一种经济实惠、可扩展的方法，用于实时识别长文本生成中的幻觉实体，成功扩展到70B参数模型。方法聚焦于实体级别的幻觉检测，通过利用网络搜索开发注释方法以标记生成文本中的虚拟实体。采用简单的线性探针等方法训练幻觉分类器，该方法在四个模型家族的长期响应中表现出色，甚至在基于数学推理任务的错误答案检测中也表现出良好的效果。", "conclusion": "总体而言，本文的工作提出了一种有前景的新方法，为实际应用中的大规模、即时幻觉检测提供了一种可能的解决方案，同时发布了注释数据集，以促进这种方法在其他模型上的应用与推广。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03535", "html_url": "https://arxiv.org/abs/2509.03535", "title": "QuesGenie：智能多媒体命题生成", "title_en": "QuesGenie: Intelligent Multimodal Question Generation", "authors": "Ahmed Mubarak,Amna Ahmed,Amira Nasser,Aya Mohamed,Fares El-Sadek,Mohammed Ahmed,Ahmed Salah,Youssef Sobhy", "background": "在当今信息丰富的时代，学习者可以访问大量的教育资源，但缺乏定制化的练习材料是当前面临的一个重要挑战。因此，该项目致力于开发一种多模态问题生成系统，能够自动从各种内容格式中生成多样化的问题类型，以弥补这一不足。该系统具备四个主要组成部分：多模态输入处理、问题生成、基于人类反馈的强化学习（RLHF）以及端到端的交互界面。", "innovation": "该项目的特点在于开发了一种多模态问题生成系统，它可以自动从多种内容格式中生成多样化的问题类型。系统主要创新点包括能够高效处理多模态输入、通过基于人类反馈的强化学习提高生成问题的质量，以及提供一个直观的端到端交互界面，确保资源高效利用、功能稳定可靠且用户体验良好。", "conclusion": "该项目奠定了自动化、可扩展和智能问题生成的基础，并且在资源利用效率、功能稳定性和用户体验方面取得了良好的平衡。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03529", "html_url": "https://arxiv.org/abs/2509.03529", "title": "基于AI的多模态提案以增加消息交叉评估工具", "title_en": "Multimodal Proposal for an AI-Based Tool to Increase Cross-Assessment of Messages", "authors": "Alejandro Álvarez Castro,Joaquín Ordieres-Meré", "background": "收益电话会议提供一种独特且半结构化的财务交流资源，结合了管理层的预录评论和分析师的即兴对话。虽然最近在财务情感分析方面已经整合了多模态信号，比如文本内容和音调，大多数系统却依赖于扁平的文档级或句子级模型，未能捕捉这些互动的多层次对话结构。文章提出了一种新的多模态框架，旨在生成收益电话会议的语义丰富且结构意识的表示，通过以层次对话树的形式编码。每个节点（包括独白或问答对）都通过从文本、音频和视频中提取情绪信号来丰富，以及使用一致分数、主题标签和答案覆盖面评估的结构化元数据。", "innovation": "论文提出了一种新颖的多模态框架，将收益电话会议编码为层次对话树，每个节点由独白或问答对组成，并提取情感信号；同时提出了一种两阶段的变换器架构，第一阶段使用对比学习在节点级别编码多模态内容和对话元数据，第二阶段合成整个会议的全局嵌入。", "conclusion": "实验结果显示，生成的嵌入形成了稳定且语义上有意义的表示，反映了情感色调、结构逻辑和主题对齐。此系统超越了财务报告领域，还适用于其他高风险的非正式通信领域，如远程医疗、教育和政治讨论，提供了多模态对话表示的一个稳健且可解释的方法。这种方法对下游任务如财务预测和对话评估具有实际用途，同时也提供了一种适用于涉及高风险沟通的其他领域的通用方法。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03565", "html_url": "https://arxiv.org/abs/2509.03565", "title": "ResearchPulse: 通过多文档科学推理构建方法-实验链条", "title_en": "ResearchPulse: Building Method-Experiment Chains through Multi-Document Scientific Inference", "authors": "Qi Chen,Jingxuan Wei,Zhuoya Yao,Haiguang Wang,Gaowei Wu,Bihui Yu,Siyuan Li,Cheng Tan", "background": "理解科学概念如何演变需要超越总结单篇论文，而必须对主题相关研究进行结构化的跨文档推断。这项工作旨在正式化多文档科学推理新任务，该任务通过提取并整合相关论文中的动机、方法和实验结果来重构研究开发链。此任务引入了关键挑战，包括时间上的方法循序矫正以及异构实验表的标准化。", "innovation": "提出了ResearchPulse，一个基于代理的框架，该框架结合了指令规划、科学内容提取和结构化可视化。它由三个协调的代理组成：负责任务分解的Plan Agent，负责构建动机-方法思维导图的Mmap-Agent，以及负责综合实验线图的Lchart-Agent。此外，还引入了ResearchPulse-Bench，这是一个基于引文的标注论文簇基准。实验结果显示，尽管使用的是7B规模的代理，系统在语义对齐、结构一致性和视觉保真度上仍然超越了如GPT-4o等强基线系统。", "conclusion": "研究Pulse系统展示了在多文档科学推理任务上的优越表现，通过使用7B规模的代理，能够在语义对齐、结构一致性和视觉保真度方面优于现有的基准系统。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03540", "html_url": "https://arxiv.org/abs/2509.03540", "title": "通过推断时知识图构建提高LLMs的可信度", "title_en": "Improving Factuality in LLMs via Inference-Time Knowledge Graph Construction", "authors": "Shanglin Wu,Lihui Liu,Jinho D. Choi,Kai Shu", "background": "大型语言模型（LLMs）在生成事实一致答案时常常受限于其参数化记忆的限制。检索增强生成（RAG）方法通过在推理时引入来自可信源的外部知识解决了这一问题。然而，这些方法通常将知识视为非结构化文本，这限制了它们支持组合性推理和识别事实不一致性的能力。", "innovation": "本研究提出了一个新颖的框架，该框架在推理时动态构建和扩展知识图（KGs），集成LLMs的内部知识和从外部源检索的信息。该方法通过提示提取问题的种子KG，随后通过LLMs的潜在知识进行迭代扩展，然后通过外部检索逐步精炼图，提升事实覆盖和纠正不准确信息。", "conclusion": "在三个不同事实问答基准上的评估表明，与基线提示和静态KG增强方法相比，该方法在事实准确性、答案精确性和解释性方面表现出了持续性改进。研究结果表明，推理时的KG构建是提高LLMs可信度的一个有前景的方向，且实现方式更加结构化、可解释和可扩展。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03527", "html_url": "https://arxiv.org/abs/2509.03527", "title": "使用细调Mistral大型语言模型和RAG方法进行多级加密货币新闻分析", "title_en": "Multilevel Analysis of Cryptocurrency News using RAG Approach with Fine-Tuned Mistral Large Language Model", "authors": "Bohdan M. Pavlyshenko", "background": "本文讨论了使用细调的Mistral 7B大型语言模型（带有检索增强生成RAG）对加密货币新闻进行多级多任务分析的方法。背景信息包括：使用细调模型生成图形和文本摘要（带有情感得分），以及JSON表示的摘要；更高级别的层次分析包括基于图的和基于文本的摘要的层次堆叠，最终生成综合报告。这种方法结合了图形和文本摘要，提供了加密货币新闻的不同视角。", "innovation": "创新点在于：提出了使用细调的Mistral 7B大型语言模型进行加密货币新闻的多层次分析；采用RAG方法，融合图和文本摘要；使用4-bit量化对模型进行微调，采用PEFT/LoRA方法；通过知识图谱表示加密货币新闻，有效避免了大型语言模型的虚构问题；实验证明，这种方法能进行信息性定量和定性分析，提供重要见解。", "conclusion": "研究结果表明，使用细调的Mistral 7B大型语言模型进行多层次的加密货币新闻分析能够执行有用的信息性定量和定性分析，提供重要的见解。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03533", "html_url": "https://arxiv.org/abs/2509.03533", "title": "通过信息瓶颈视角识别大语言模型输入-输出对的主题", "title_en": "Topic Identification in LLM Input-Output Pairs through the Lens of Information Bottleneck", "authors": "Igor Halperin", "background": "大语言模型（LLMs）容易出现关键的失败模式，例如本体忠实度幻觉（也称为编造），即响应在语义上偏离提供的上下文。为检测此类问题设计的框架，如语义偏离度量（SDM），依赖于对提示和响应之间潜在主题的识别，通常通过应用向量嵌入的几何聚类来进行。然而，这种方法存在一个缺点，即潜在主题被优化为空间邻近性，而不是为下游的信息理论分析。", "innovation": "本文通过信息瓶颈（DIB）的方法构建了一个有原则的主题识别方法来弥合这一缺口。关键贡献是通过使用一个计算高效的上界替换难以处理的KL散度项，将DIB方法转化为适用于高维数据的实用算法。我们称之为UDIB的方法可以被解释为一种以高信息性簇为目标，且受到熵正则化和鲁棒性增强的K均值版本。通过将UDIB应用于LLM提示和响应嵌入的联合聚类，生成了一个不仅在空间上连贯，而且在本质上结构化以最大化提示-响应关系信息的主题表示。这为SDM框架提供了更优的基础，并提供了一种新型、更敏感的工具来检测编造。", "conclusion": "通过UDIB方法，我们为LLM的输入-输出对提供了更加信息丰富的主题表示，更适用于SDM框架下的信息分析，有效弥补了传统方法的不足，从而能够更准确地检测编造现象。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03530", "html_url": "https://arxiv.org/abs/2509.03530", "title": "解读征兆：基于青少年社交媒体文本预测未来自杀倾向", "title_en": "Reading Between the Signs: Predicting Future Suicidal Ideation from Adolescent Social Media Texts", "authors": "Paul Blum,Enrico Liscio,Ruixuan Zhang,Caroline Figueroa,Pradeep K. Murukannaiah", "background": "青少年（12-18岁）自杀是导致死亡的主要原因之一，但预测这一问题相当具有挑战性。由于缺乏与心理健康服务的接触，许多案例得不到检测。然而，社交媒体提供了独特的机会，因为年轻人常常在网上实时分享他们的思想和困难。以往的研究在这方面的探索有限。", "innovation": "本文提出了一个新颖的任务和方法，即通过预测论坛帖子来预测青少年线上论坛中未来表达的自杀思想，而无需使用任何自我披露作为输入。提出了一种以变压器为基础的模型Early-SIB，能够从用户发布的帖子中序列化地进行处理，预测他们是否会发表关于自杀的想法的帖子。该模型在荷兰青年论坛上的平衡准确性达到0.73，这表明这些工具可以为传统方法提供有意义的补充。", "conclusion": "我们的研究表明，基于论坛帖子的预测方法可以提供一个有意义的工具，帮助识别潜在风险，从而提高干预的成功率。预测模型对于早期识别并预防自杀行为具有重要的临床和公共健康意义。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03647", "html_url": "https://arxiv.org/abs/2509.03647", "title": "打破魔镜：基于激活的LLM评估器中自我偏好偏差缓解", "title_en": "Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators", "authors": "Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer", "background": "大型语言模型（LLMs）越来越多地充当自动化评估者，但由于存在“自我偏好偏差”，即倾向于偏好自身生成的结果而非其他模型的结果，这影响了评估管道的公平性和可靠性，特别是在偏好调整和模型路由等任务中。研究发现，轻量级引导向量可以在推理时减轻这一问题，而无需重新训练。", "innovation": "本文引入了一个精心策划的数据集，将自我偏好偏差区分为合理的自我偏好和不合理的自我偏好，并使用Contrastive Activation Addition (CAA) 和优化方法构建了引导向量。结果表明，引导向量可以显著减少不合理的自我偏好偏差，优于提示和直接偏好优化的基本方法。然而，这些向量在真实自我偏好和无偏评估上不稳定，表明自我偏好涵盖多个或非线性方向。", "conclusion": "因此，引导向量既具有保障LLM作为裁判系统的潜力，也存在局限性，需要进一步的稳健干预。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03610", "html_url": "https://arxiv.org/abs/2509.03610", "title": "NoteBar：一种个人知识管理的AI辅助笔记系统", "title_en": "NoteBar: An AI-Assisted Note-Taking System for Personal Knowledge Management", "authors": "Josh Wisoff,Yao Tang,Zhengyu Fang,Jordan Guzman,YuTang Wang,Alex Yu", "background": "笔记是学术和专业环境中捕捉、组织和反思信息的关键实践。大型语言模型的成功促使了AI辅助工具的发展，但现有的解决方案往往在效率方面存在问题。", "innovation": "作者提出了NoteBar，这是一种利用角色信息和高效语言模型的AI辅助笔记工具，能够自动将笔记按多个类别组织，更好地支持用户工作流程。同时，还引入了一个包含3,173个笔记和8,494个注释概念的新颖的基于角色条件的数据集，涵盖了16种MBTI人格类型，为下游任务提供了多样性和语义丰富性。", "conclusion": "NoteBar能够以实用且成本效益高的方式部署，无需依赖重基础设施即可实现交互使用。结合NoteBar及其配套数据集，为推动AI辅助个人知识管理提供了可扩展和可扩充的基础。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03615", "html_url": "https://arxiv.org/abs/2509.03615", "title": "E-ARMOR: 边缘案例评估与多语言光学字符识别审查", "title_en": "E-ARMOR: Edge case Assessment and Review of Multilingual Optical Character Recognition", "authors": "Aryan Gupta,Anupam Purwar", "background": "多语言、噪声和多样性的现实世界图像中的光学字符识别（OCR）仍然是OCR系统的重要挑战。随着大型视觉-语言模型（LVLM）的兴起，人们越来越关注这些模型在固定OCR管道之外的泛化和推理能力。现有研究开发了许多先进的OCR系统，但几乎没有专门针对边缘部署进行优化的研究。因此，需要一个综合性的评估框架，比较不同模型在受限资源环境下的性能。", "innovation": "本文提出了一种名为Sprinklr-Edge-OCR的新颖OCR系统，专门针对边缘部署进行了优化。该研究首次广泛评估了五种最先进的LVLM（InternVL, Qwen, GOT OCR, LLaMA, MiniCPM）和两种传统OCR系统（Sprinklr-Edge-OCR, SuryaOCR）在多语言（54种语言）图像上的性能。评估方法包括广泛的任务指标，如准确性、语义一致性、语言覆盖率、计算效率（延迟、内存、GPU使用）和部署成本。另外，研究还评估了模型在仅使用CPU的边缘部署环境下的表现。", "conclusion": "研究表明，在边缘部署环境下，传统的OCR系统仍然是最优化的选择，因为它们具有较低的计算要求、较低的延迟和极高的性价比。尽管LVLM在某些方面具有优势，但传统OCR系统在边部署环境下仍然具有更高的效率和更低的成本。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03662", "html_url": "https://arxiv.org/abs/2509.03662", "title": "使用MIMIC-IV数据库对MIMIC-IV数据库中的SNOMED CT概念共现进行语义分析", "title_en": "Semantic Analysis of SNOMED CT Concept Co-occurrences in Clinical Documentation using MIMIC-IV", "authors": "Ali Noori,Somya Mohanty,Prashanti Manda", "background": "临床笔记包含丰富的临床叙述，但由于其非结构化的格式，大规模分析面临挑战。虽然标准化的术语如SNOMED CT提高了互操作性，但概念之间通过共现和语义相似性的关系尚未被充分探索。本文利用MIMIC-IV数据库研究SNOMED CT概念共现模式与其基于嵌入的语义相似性之间的关系。", "innovation": "使用归一化互信息(NPMI)和预训练嵌入表示（如ClinicalBERT，BioBERT），研究经常共现的概念是否也具有语义相似性，嵌入是否可以提示缺失的概念，这些关系如何随时间变化并在不同专业领域演进。研究发现，虽然共现和语义相似性的关联较弱，但嵌入捕捉到了文档频率中不一定反映的临床相关联系。基于嵌入的概念聚类揭示了与患者表型和护理模式相符的临床主题。这些共现模式与诸如死亡率和再次入院的结局相关联，证明了该方法的实际用途。", "conclusion": "我们的研究结果强调了共现统计和语义嵌入的互补价值，以提高文档完整性，揭示潜在线临床关系，并为支持决策和表型应用提供信息。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03829", "html_url": "https://arxiv.org/abs/2509.03829", "title": "NE-PADD：通过注意聚合利用命名实体知识进行稳健的部分音频换音检测", "title_en": "NE-PADD: Leveraging Named Entity Knowledge for Robust Partial Audio Deepfake Detection via Attention Aggregation", "authors": "Huhong Xian,Rui Liu,Berrak Sisman,Haizhou Li", "background": "与传统的基于句子级别的音频深度伪造检测（ADD）不同，部分音频深度伪造检测（PADD）需要在帧级别定位伪造语音的位置。尽管在该领域已经取得了一些进展，但从音频中利用语义信息，特别是命名实体，依然是一个未被充分探索的方面。", "innovation": "本文提出了一种名为NE-PADD的新颖方法，结合了Speech Name Entity Recognition (SpeechNER)和PADD两个并行分支，通过两种注意聚合机制（Attention Fusion, AF；Attention Transfer, AT）进行掩码。NE-PADD利用辅助损失来引导PADD的命名实体语义。", "conclusion": "基于PartialSpoof-NER数据集的实验表明，我们的方法优于现有的基线方法，证明了将命名实体知识集成到PADD中的有效性。相关代码可以在指定链接获取。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03537", "html_url": "https://arxiv.org/abs/2509.03537", "title": "AR$^2$: 对抗强化学习在大语言模型中进行抽象推理", "title_en": "AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models", "authors": "Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang", "background": "抽象能力，即从复杂的问题陈述中识别和提炼出关键的计算模式，是计算机科学中的基础技能，对于人类问题解决者和面向编码的大型语言模型（LLMs）都至关重要。尽管近期使用强化学习（RL）训练LLMs生成代码的方法有了进展，但大多数现有方法主要关注于表面模式识别，忽视了对抽象能力的显式训练。", "innovation": "本文提出了一种名为AR$^2$（对抗强化学习用于抽象推理）的新框架，该框架明确设计来提升LLMs的抽象能力。AR$^2$采用教师模型将核心问题转化为富有叙述性的挑战性描述，而不改变其基本逻辑。同时，学生编码模型通过提取其内在的计算核心来解决这些复杂的叙述性问题。实验结果显示，AR$^2$显著提升了学生模型在以往未见过的复杂编程任务上的准确性，突显了抽象能力是提升LLM泛化能力的关键。", "conclusion": "AR$^2$ 在提升LLMs的抽象推理能力方面展示了显著效果，特别在处理未见过的复杂编程任务时。这强调了在训练LLMs时加强对抽象能力的培养是至关重要的。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03888", "html_url": "https://arxiv.org/abs/2509.03888", "title": "假的安全感：为何基于探测的方法在检测恶意输入时无法泛化", "title_en": "False Sense of Security: Why Probing-based Malicious Input Detection Fails to Generalize", "authors": "Cheng Wang,Zeming Wei,Qin Liu,Muhao Chen", "background": "大型语言模型（LLMs）可以遵从有害指令，尽管它们具有出色的性能，但仍引发了严重的安全性担忧。最近的研究通过探测方法来研究LLMs内部表示中恶意和善意输入的可区分性，并提议使用这些探测方法进行安全性检测。然而，这些方法仍然存在不足，特别是在跨分布性能方面表现较差，探寻更深层次的有害性指标面临挑战。", "innovation": "本文系统地重新审视了基于探测的检测方法。研究者通过控制实验验证了假设——即探测方法学习的是表面模式而非语义上的有害性，并具体指出了这些模式包括指令模式和触发词。这种方法从简单n-gram方法的性能对比开始，逐渐深入到语义清理数据集的控制实验，以及模式依赖关系的详细分析，在此过程中揭示了当前探测方法的虚假安全感，并强调了重新设计模型和评估协议的必要性。", "conclusion": "研究结果表明，当前基于探测的方法在安全检测方面存在缺陷，提出了进一步研究的设计讨论。研究者已经开源了项目，请参考https://your.link.to.the.project.com（该网址待替换）以建议其在负责任的研究方向上的进一步探讨。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03725", "html_url": "https://arxiv.org/abs/2509.03725", "title": "MLSD: 基于元学习的少量样本学习在跨目标和跨领域立场检测中的新方法", "title_en": "MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and Cross-Domain Stance Detection", "authors": "Parush Gera,Tempestt Neal", "background": "本文介绍了一种针对不同领域和目标的立场检测的新方法。目前的立场检测模型在处理不同的目标或领域时效果不佳，而MLSD通过使用三元组损失进行元学习，可以捕捉立场目标之间的语义相似性和差异性，增强了领域自适应能力。这种方法构建了一个具有区分性的嵌入空间，使得跨目标或跨领域的立场检测模型可以从新目标领域中获取有用的示例，从而显著提高了立场检测性能。", "innovation": "MLSD利用元学习和三元组损失技术，能够在不同领域和目标中进行少量样本学习，通过构建区分性的嵌入空间，增强不同领域间的适应性，从而有效提高立场检测的性能。这种方法显著优于现有的六种广泛使用的立场检测模型.", "conclusion": "在两个数据集中对MLSD方法进行了多目标和跨领域的立场检测评估，结果显示在六种广泛使用的立场检测模型中，都会有统计学意义上的改善。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03871", "html_url": "https://arxiv.org/abs/2509.03871", "title": "大型语言模型推理中的可信性综述", "title_en": "A Comprehensive Survey on Trustworthiness in Reasoning with Large Language Models", "authors": "Yanbo Wang,Yongcan Yu,Jian Liang,Ran He", "background": "长链思维（Long-CoT）推理的发展提高了各类任务中LLM（大型语言模型）的表现，包括语言理解、复杂问题解决和代码生成。这种范式使模型能够生成中间推理步骤，从而提高准确性和可解释性。然而，尽管取得了这些进展，关于基于CoT（链式思考）的推理如何影响语言模型可信度的理解仍不完善。该论文综述了推理模型和CoT技术方面的最新工作，重点关注五个核心的可信推理维度：真实性、安全性、稳健性、公平性和隐私。对于每个方面，展示了最近研究的清晰和结构化的概述，按时间顺序排列，详细分析了它们的方法论、发现及其局限性。此外，还附上了未来研究的方向。", "innovation": "该论文综合了对基于CoT的推理如何影响语言模型可信度的理解，通过重点研究五个核心的可信推理维度，填补了这一领域的空白。论文按时间顺序概述了最近的研究，展示了方法论、发现及其局限性，并提出了未来的研究方向，为AI安全社区提供了一份及时且有价值的信息资源。", "conclusion": "虽然推理技术有望通过减少幻觉、检测有害内容和提高稳健性来增强模型的可信度，但最先进的推理模型在安全性、稳健性和隐私方面仍然存在类似甚至更大的脆弱性。通过综合这些见解，本文旨在为AI安全社区提供一份有价值的信息资源，以了解推理可信度的最新进展。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03809", "html_url": "https://arxiv.org/abs/2509.03809", "title": "Align-then-Slide：超长文档级机器翻译的完整评估框架", "title_en": "Align-then-Slide: A complete evaluation framework for Ultra-Long Document-Level Machine Translation", "authors": "Jiaxin Guo,Daimeng Wei,Yuanchang Luo,Xiaoyu Chen,Zhanglin Wu,Huan Yang,Hengchao Shang,Zongyao Li,Zhiqiang Rao,Jinlong Yang,Hao Yang", "background": "大型语言模型（LLMs）开启了文档级机器翻译（doc-mt）的新纪元，但它们的整体文档输出挑战了现有基于句子间对齐的评估方法。现有的评估方法假设翻译文本是逐句对齐的，而LLMs的输出打破了这个假设，尤其是在处理超长文档时更为明显。", "innovation": "本文提出了一种全新的评估框架——Align-then-Slide，分为两个阶段：一是自动推断句子级别的源语言与目标语言对应关系，并重建目标语以匹配源文件的句子数量，解决了遗漏和多对一或多对一的问题；二是通过n-Chunk滑动评估阶段，计算每次滑动窗口下的平均度量得分，全面评估翻译质量。实验结果表明，该方法与专家人工评分的相关性达到0.929，且生成的数据有助于文档级机器翻译系统的训练优化。", "conclusion": "此研究证实了Align-then-Slide框架是一个准确、稳健且实用的文档级机器翻译系统评估工具。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03891", "html_url": "https://arxiv.org/abs/2509.03891", "title": "MobileRAG: 使用检索增强生成增强移动代理", "title_en": "MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation", "authors": "Gowen Loo,Chang Liu,Qinghong Yin,Xiang Chen,Jiawei Chen,Jingyuan Zhang,Yu Tian", "background": "智能手机在日常生活中变得不可或缺，涵盖了现代社会的几乎所有方面。随着大规模语言模型（LLMs）的不断进步，已经产生了许多基于LLM的移动代理。这些代理能够准确解析用户查询并自动协助用户完成复杂或重复的操作。然而，当前的代理1）严重依赖于LLM的理解能力，可能导致任务过程中由误操作或遗漏步骤引起的错误，2）缺乏与外部环境的交互，常常在应用无法满足用户查询时终止任务，3）缺乏记忆能力，要求每次指令重建界面，并且无法从先前的错误中学习和纠正。为了缓解这些问题，我们提出了MobileRAG，一种通过检索增强生成（RAG）增强的移动代理框架，其中包括InterRAG、LocalRAG和MemRAG。该框架利用RAG来更快、更准确地识别用户查询，并完成复杂的和长序列的移动任务。", "innovation": "我们提出了MobileRAG，一种使用检索增强生成（RAG）增强的移动代理框架，涵盖了InterRAG、LocalRAG和MemRAG。它利用RAG来更快、更准确地识别用户查询，并完成复杂的和长序列的移动任务。此外，为了更全面地评估MobileRAG的性能，我们引入了MobileRAG-Eval，一个更具挑战性的基准，包括许多需要外部知识支持的真实世界的复杂移动任务。实验结果表明，MobileRAG能够轻松处理真实世界的移动任务，并在更少的操作步骤中优于最先进的方法，提高了10.3%的性能。", "conclusion": "在MobileRAG-Eval上进行的广泛实验结果表明，MobileRAG能够轻松处理真实世界的移动任务，并在更少的操作步骤中优于最先进的方法，实现了10.3%的性能提升。我们的代码已在公开地址上提供。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03805", "html_url": "https://arxiv.org/abs/2509.03805", "title": "测量VLMs如何而非仅仅是是否建立共同基础", "title_en": "Measuring How (Not Just Whether) VLMs Build Common Ground", "authors": "Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani", "background": "当前的视觉语言模型（VLMs）在推理方面取得了显著进展，但现有的基准测试主要在单轮次或问答设置中进行。实际上，多轮次的交流在建立共享理解的过程中起着关键作用。本文提出了一套四维度评估指标（包括接地效率、内容一致性、词汇适应性和拟人化）来系统性地评估VLMs在互动接地情境中的表现。", "innovation": "提出了一个四维度评估框架（接地效率、内容一致性、词汇适应性和拟人化），该框架可在交互式情境下全面评估VLMs的表现。该框架在150场互动参照游戏中的三款VLMs和人类双人组之间进行测试，并发现任务成功分数并不一定能反映成功的接地过程，高图像-话语一致性也不一定预示任务成功。", "conclusion": "该指标套件和实验发现提供了一个框架，用于未来VLMs接地研究，强调不仅要评估VLMs是否能完成任务，还要评估它们在多轮交互中的表现及是否能建立有效的共享理解。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03791", "html_url": "https://arxiv.org/abs/2509.03791", "title": "SiLVERScore: 用于手语生成评估的语义感知嵌入", "title_en": "SiLVERScore: Semantically-Aware Embeddings for Sign Language Generation Evaluation", "authors": "Saki Imai,Mert İnan,Anthony Sicilia,Malihe Alikhani", "background": "目前的手语生成评估通常采用回译的方法，即首先识别生成的手语回到文本，再用基于文本的度量标准进行比较。然而这种方法存在歧义性：一方面，它未能捕捉手语的多模态特性，如面部表情和语调结构；另一方面，也难以明确究竟是生成模型的问题还是评估它所使用的翻译系统的错误。", "innovation": "提出了SiLVERScore，一个新型的具有语义意识的嵌入度量标准，用于在联合嵌入空间内评估手语生成。其贡献包括：(1) 识别现有度量标准的局限性；(2) 引入SiLVERScore进行语义意识的评估；(3) 证明其对语义和语调变异的鲁棒性；(4) 探索在不同数据集上的泛化挑战。", "conclusion": "在PHOENIX-14T和CSL-Daily数据集上，SiLVERScore在正确和随机配对的区分上达到了近乎完美的程度（ROC AUC=0.99，重叠<7%），明显优于传统的度量标准。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03934", "html_url": "https://arxiv.org/abs/2509.03934", "title": "SelfAug: 通过分布自我对齐缓解检索增强生成中的灾难性遗忘", "title_en": "SelfAug: Mitigating Catastrophic Forgetting in Retrieval-Augmented Generation via Distribution Self-Alignment", "authors": "Yuqing Huang,Rongyang Zhang,Qimeng Wang,Chengqiang Lu,Yan Gao,Yi Wu,Yao Hu,Xuyang Zhi,Guiquan Liu,Xin Li,Hao Wang,Enhong Chen", "background": "大语言模型（LLMs）的最新进展通过其理解和执行多种任务的能力彻底革新了自然语言处理。尤其是监督微调，特别是在检索增强生成（RAG）场景下，有效提升了特定任务的性能，但往往会导致灾难性遗忘，即模型会丢失之前习得的知识和通用能力。现有解决方案要么需要访问通用指令数据，要么在保留模型原始分布方面存在局限性。", "innovation": "本文提出了一种自我分布对齐方法SelfAug，该方法通过对输入序列的logits进行对齐来保留模型的语义分布，从而缓解灾难性遗忘并提升下游性能。本文的实验证明，SelfAug在保留模型通用能力的同时，实现了对下游任务学习的更佳平衡。研究发现，分布变化与RAG场景下的灾难性遗忘严重程度之间存在直接关联，揭示了在总体指令调优中缺乏RAG能力如何导致模型分布显著变化。", "conclusion": "本文不仅加深了对RAG上下文中灾难性遗忘的理解，还提供了一种适用于各种微调场景的实用解决方案。代码已公开，可通过此链接获取：[链接]。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03937", "html_url": "https://arxiv.org/abs/2509.03937", "title": "SPFT-SQL: 通过自我博弈微调增强大型语言模型进行文本到SQL解析", "title_en": "SPFT-SQL: Enhancing Large Language Model for Text-to-SQL Parsing by Self-Play Fine-Tuning", "authors": "Yuhao Zhang,Shaoming Duan,Jinhang Su,Chuanyi Liu,Peiyi Han", "background": "尽管自我博弈微调（SPIN）已经取得了显著的进步，它能够通过不同能力的模型之间的竞争交互将一个较弱的大规模语言模型转化为一个更强的模型，但在文本到SQL任务上仍面临挑战。SPIN 无法生成新的信息，并且对手模型在自我博弈过程中产生的大量正确的SQL查询会削弱主要模型生成准确SQL查询的能力。因此，该研究提出了一个针对文本到SQL任务的新自我博弈微调方法，称为SPFT-SQL。该方法包括在自我博弈前使用基于验证的一次迭代微调方法，通过数据库模式和验证反馈合成高质量的微调数据，提高模型性能，并构建不同能力的模型库。在自我博弈微调阶段，提出了错误驱动的损失方法，激励对手模型产生错误输出，使得主要模型能够区分对手模型生成的正确SQL和错误SQL，从而提高其生成正确SQL的能力。", "innovation": "提出了一个针对文本到SQL任务的新自我博弈微调方法SPFT-SQL。该方法包括两次迭代微调以合成高质量的微调数据，并在自我博弈阶段使用错误驱动的损失方法。这种方法不仅增强了模型在文本到SQL任务上的表现，而且提高了其生成正确SQL的能力。", "conclusion": "在六种开源大规模语言模型和五个广泛使用的基准测试上进行的广泛实验和深入分析表明，该方法在文本到SQL任务上的表现优于现有的先进方法（SOTA）."}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03972", "html_url": "https://arxiv.org/abs/2509.03972", "title": "通过韩语案例研究扩展开源基础语言模型的能力", "title_en": "Expanding Foundational Language Capabilities in Open-Source LLMs through a Korean Case Study", "authors": "Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh", "background": "介绍了Llama-3-Motif这一包含102亿参数的语言模型，该模型旨在增强韩语能力同时保持在英语上的强大性能。模型基于Llama 3架构，并使用了LlamaPro和Masked Structure Growth等先进的训练技术，确保在不改变核心Transformer架构的情况下有效扩展模型。利用MoAI平台进行高效的大规模GPU集群训练，并使用精心挑选的数据集实现了韩语和英语数据的平衡比例。", "innovation": "Llama-3-Motif特别针对韩语能力进行了增强，同时保持了在英语上的高性能。它通过使用先进的训练技术如LlamaPro和Masked Structure Growth，在保持原有Transformer架构的情况下有效扩大了模型规模。通过MoAI平台在大规模GPU集群上进行高效训练，并使用平衡的韩语和英语数据集进行优化。模型在韩语特定基准测试中表现出良好的性能，超过了现有模型，并且其结果接近于GPT-4的水平。", "conclusion": "Llama-3-Motif在保持和提升韩语能力的同时，展示了在英语上的强性能，并通过多种先进的模型训练技术实现了这一目标。在大规模GPU集群上进行高效训练，确保了模型的扩展性和平衡的多语言性能。"}
{"llm_update_time": "20250906", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00167", "html_url": "https://arxiv.org/abs/2509.00167", "title": "在高等教育课堂中生成式AI和批判性思维的试点研究", "title_en": "Pilot Study on Generative AI and Critical Thinking in Higher Education Classrooms", "authors": "W. F. Lamberti,S. R. Lawrence,D. White,S. Kim,S. Abdullah", "background": "生成式人工智能（GAI）工具在教育环境中迅速普及，但它们在培养批判性思维方面的作用尚未得到充分探索。尽管之前的研究已经探讨了GAI作为特定课程的导师或作业工具的角色，但很少有人研究学生如何批判性地评估GAI生成的答案的准确性和适当性。因此，本研究旨在探索学生在入门级别的计算与数据科学课程中应用结构化的批判性思维评估生成式AI输出的能力。", "innovation": "本研究设计了学习活动，要求学生分析、批判和修改AI生成的解决方案。这种教学方法特别针对GAI工具经常提供的上下文不正确或事实错误的答案进行了设计，旨在使学生学会如何更准确地评估AI生成的内容。研究结果为今后对生成式AI和批判性思维关系进行更深入研究奠定了基础。", "conclusion": "初步研究发现，学生能够在一定程度上批判性地使用生成式AI内容，这为进一步开展此类研究提供了初步的见解。研究成果为生成式AI在教育中的应用提供了新的视角，同时也指出了未来研究的方向。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03995", "html_url": "https://arxiv.org/abs/2509.03995", "title": "RTQA: 递归思考复杂时间知识图谱问答的大语言模型方法", "title_en": "RTQA : Recursive Thinking for Complex Temporal Knowledge Graph Question Answering with Large Language Models", "authors": "Zhaoyan Gong,Juan Li,Zhiqiang Liu,Lei Liang,Huajun Chen,Wen Zhang", "background": "当前的时间知识图谱问答(TKGQA)方法主要关注隐式的时间约束，缺乏处理复杂时间查询的能力，且在分解框架中存在有限的推理能力和错误传播问题。", "innovation": "提出了一种名为RTQA的新框架，通过增强时间知识图谱的推理能力来解决问题，而无需训练。RTQA通过递归分解问题到子问题，自底向上地使用大型语言模型和TKG知识求解，同时采用多路径答案聚合以提高容错性。RTQA包括三个核心组件：时间问题分解器、递归求解器和答案聚合器。", "conclusion": "在MultiTQ和TimelineKGQA基准上的实验显示了在“Multiple”和“Complex”类别中的显著提高的Hits@1表现，超过了当前最先进的方法。我们的代码和数据可在以下链接中获得。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03932", "html_url": "https://arxiv.org/abs/2509.03932", "title": "解码韩语现代诗歌中的诗意情感：基于人工标注数据和AI建模的见解", "title_en": "Decoding the Poetic Language of Emotion in Korean Modern Poetry: Insights from a Human-Labeled Dataset and AI Modeling", "authors": "Iro Lim,Haein Ji,Byungjun Kim", "background": "尽管大型语言模型在基于文本的情感分类方面取得了显著进展，但由于其比喻语言和文化特定性，诗歌，特别是韩语诗歌，仍然未被充分探索。", "innovation": "创建了一个包含7662条记录的多标签情感数据集，其中包括来自483首诗歌的7007个诗句级别的记录和615个作品级别的记录，并使用五个有影响的韩国诗人的情感类别进行了注释。通过在这一数据集上进行微调的一种最新的韩语语言模型，显著优于以前使用通用语料库训练的模型，达到了0.60的F1-微观评分。KPoEM模型以逐步微调的方式进行训练，首先在通用语料库上，然后在KPoEM数据集上，展示了识别时间和文化特定情感表达的能力，同时保留了现代韩语诗歌的核心情感，这将计算方法与文学分析相结合，为通过结构化数据定量探索诗意情感提供了新的可能性，这些数据忠实保留了韩语文学的情感和文化 nuance。", "conclusion": "通过KPoEM数据集和模型，研究了现代韩语诗歌中的情感表达，展示了人工智能在文学分析中的应用潜力，为情感定量研究提供了新的方法。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03918", "html_url": "https://arxiv.org/abs/2509.03918", "title": "MTQA：增强复杂问答推理的思维矩阵", "title_en": "MTQA:Matrix of Thought for Enhanced Reasoning in Complex Question Answering", "authors": "Fengxiao Tang,Yufeng Li,Zongzong Wu,Ming Zhao", "background": "复杂问题回答（QA）在自然语言处理（NLP）中是一个基本且具有挑战性的任务。尽管大型语言模型（LLMs）在问答任务上表现出色，但在面对复杂的和抽象的QA任务时，由于推理能力不足，其性能会显著下降。为增强LLMs的推理能力，已有研究提出了链式思维（CoT）和树状思维（ToT）等方法，但这些方法存在内在树状结构的层内冗余和链式结构的单一路径等问题。尽管有些研究利用检索增强生成（RAG）方法来辅助LLMs进行推理，但在利用涉及多个实体和跳步的大量信息方面仍存在挑战。因此，本文提出了思维矩阵（MoT），一个新颖且高效的LLM思维结构，通过“列单元通信”机制在水平和垂直维度上探索问题，使LLMs能够主动进行多策略和深层次的思考，从而减少列单元内的冗余并增强推理能力。此外，通过从检索到的知识图谱三元组和原始文本构建知识单元来完善初始知识，以增强LLMs的推理并纠正错误答案，进而构建了一个高效的和准确的QA框架（MTQA）。", "innovation": "本文提出了一种新颖且高效的LLM思维结构MoT，通过‘列单元通信’机制在水平和垂直维度上探索问题，使LLMs能够主动进行多策略和深层次的思考，从而减少列单元内的冗余并增强推理能力。此外，还开发了一种事实纠错机制来完善初始知识，以增强LLMs的推理并纠正错误答案，从而构建了一个高效的和准确的QA框架MTQA。实验结果表明，该框架在F1和EM分数上优于现有最先进的方法，在四组广泛使用的数据集上超过了基线方法14.4%的时间，证明了其高效性和准确性。", "conclusion": "本文提出的MTQA框架在多个复杂QA数据集上的实验结果表明，该框架不仅在效率上优于现有的基线方法，而且在准确性上也表现出色，证明了MoT结构的有效性和优势。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03962", "html_url": "https://arxiv.org/abs/2509.03962", "title": "在极端低资源环境中的NLP基准探索", "title_en": "Exploring NLP Benchmarks in an Extremely Low-Resource Setting", "authors": "Ulin Nuha,Adam Jatowt", "background": "大型语言模型（LLMs）在处理极低资源语言，如土著语言时效果减弱，主要因为缺乏标注数据。尽管对这些语言的兴趣在增长，高质量自然语言处理（NLP）数据集的可用性仍然有限，这使得开发稳健的语言技术变得困难。", "innovation": "该论文专注于濒危的罗曼语Ladin语，特别是Val Badia方言，利用少量的Ladin-意大利语平行句对，创建了用于情感分析和多项选择问题回答（MCQA）的合成数据集。通过严格过滤和回译程序确保语言质量和可靠性，并将这些合成数据集整合到机器翻译训练中，显著提高了现有意大利语-Latin翻译基准。", "conclusion": "本研究为Ladin语提供了首个公开可用的情感分析和MCQA数据集，建立了支持更广泛的NLP研究和该语言下游应用的基础资源。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03867", "html_url": "https://arxiv.org/abs/2509.03867", "title": "Drivel-ology: 通过解析深层次荒谬挑战LLMs", "title_en": "Drivel-ology: Challenging LLMs with Interpreting Nonsense with Depth", "authors": "Yang Wang,Chenghao Xiao,Chia-Yi Hsiao,Zi Yan Chang,Chi-Li Chen,Tyler Loakman,Chenghua Lin", "background": "我们介绍了Drivelology这一独特的语言现象，它被描述为“有意义的无意义”，即语言结构上看似合乎句法但具有悖论意义、情感负载或修辞反叛的语言表达。尽管这些表达表面上看起来像是普通的无意义，但实际上它们蕴含着需要上下文推断、道德推理或情绪解读的隐含意义。当前的大语言模型（LLMs）虽然在许多自然语言处理（NLP）任务上表现优异，但在理解和处理Drivelology文本的多层次语义方面存在明显不足。", "innovation": "为了探究这个问题，作者构建了一个包含1200多个精心挑选和审核的多元数据集，数据集包含了不同语言的样本，以确保数据的多样性。标注过程特别具有挑战性，每个样本都需要经过多轮专家讨论和裁决，以确保其真正反映了Drivelology的特点。该研究首次在分类、生成和推理任务中评估了多种LLMs，并揭示了LLMs在处理这些深层次荒谬文本时的重大限制，特别是统计流利性并不一定意味着理解能力。", "conclusion": "研究结果表明，LLMs在具备道德推理和情感解读能力时存在更大的差距，挑战了现有假设，即统计流利性等于认知理解。作者还公开了他们的数据集和代码，以便进一步推动超越表面一致性构建立语言深度的研究。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03957", "html_url": "https://arxiv.org/abs/2509.03957", "title": "CANDY：评估大型语言模型在中文 misinformation 事实核查中的局限性和辅助潜力", "title_en": "CANDY: Benchmarking LLMs' Limitations and Assistive Potential in Chinese Misinformation Fact-Checking", "authors": "Ruiling Guo,Xinwei Yang,Chen Huang,Tong Zhang,Yong Hu", "background": "尽管大型语言模型（LLMs）在事实核查方面显示出潜力，但其在查证 misinformation 的效果尚未完全确定。本文通过建立 CANDY 标准化基准，旨在系统地评估和认识 LLMs 在中文 misinformation 事实核查中的能力和局限性，特别是在增强型推理和少量示例提示下的性能。研究表明，当前 LLMs 在生成准确的查证结论方面存在局限，尤其是经常出现事实捏造错误。", "innovation": "本文开发了一个标准化的数据集（约 20000 个实例），并提出了一种分层次的分类方法来分析 LLMs 生成的错误解释，着重指出事实捏造是最常见的失败模式。研究还表明，虽然单独使用 LLMs 进行事实核查不可靠，但将 LLMs 作为辅助工具应用在人类表现中，可以显著提高其在专业知识缺乏域的核查能力。提供的数据集和代码可通过特定链接访问，以供验证与测试研究结果。", "conclusion": "本文通过 CANDY 基准揭示了 LLMs 在中文 misinformation 事实核查中的局限性与潜在辅助作用。虽然 LLMs 目前在自动事实核查上存在误差，但它们具有显著能力和潜力，作为辅助工具可以显著提高人工核查效率，尤其是增强型推理和少量示例提示的应用。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04032", "html_url": "https://arxiv.org/abs/2509.04032", "title": "如果我们用另一种语言提问，它们的回答会有多相似？跨语言功能相似度的度量", "title_en": "What if I ask in \\textit{alia lingua}? Measuring Functional Similarity Across Languages", "authors": "Debangan Mishra,Arihant Rastogi,Agyeya Negi,Shashwat Goel,Ponnurangam Kumaraguru", "background": "本文探讨了不同语言模型输出的相似性问题。研究者使用一种最近提出的模型相似度度量指标 \textit{\textbackslash}kappa\textit{_p}$，在GlobalMMLU数据集上对20种语言和47个主题进行了分析。研究背景基于现有模型在不同语言中的表现差异，以及模型间的跨语言一致性与本地语言一致性之间的比较分析。这一研究旨在评估和理解不同语言模型的多语言可靠性，以及模型大小和能力对输出一致性的影响。", "innovation": "本文创新性地提出了一个用于评估多语言可靠性的 \textit{\textbackslash}kappa\textit{_p} 度量指标，并首次在多种语言的模型输出之间进行比较。研究发现模型在规模和能力增长时，其输出在不同语言之间的相似度增加；模型内部的跨语言一致度高于其他语言模型在相同语言环境下的共识度。这些结果不仅证实了 \textit{\textbackslash}kappa\textit{_p} 度量指标的实际适用性，还揭示了其在引导开发更一致的多语言系统方面的重要潜在价值。", "conclusion": "研究结论表明，模型的输出呈现出随着其尺寸和能力的增加而变得更加一致的现象。模型自身的跨语言一致性高于与其他模型在相同语言环境下的共识。这不仅强调了 \textit{\textbackslash}kappa\textit{_p} 度量指标作为评估多语言一致性的工具的重要性，同时也指出了其潜在的应用价值，特别是对于引导开发更加一致的多语言系统。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04104", "html_url": "https://arxiv.org/abs/2509.04104", "title": "向人类-代理口语对话中的稳定和个性化词汇对齐配置文件迈进", "title_en": "Towards Stable and Personalised Profiles for Lexical Alignment in Spoken Human-Agent Dialogue", "authors": "Keara Schaaij,Roel Boumans,Tibor Bosse,Iris Hendrickx", "background": "词汇对齐是支持有效沟通的关键因素，但在对话代理中的应用仍然未得到充分探索，尤其是在近年来大型语言模型（LLMs）的进展背景下。本文旨在通过借鉴个性化对话代理的策略，探索构建稳定且个性化的词汇配置文件作为实现词汇对齐的基础。", "innovation": "本文研究通过调整用于构建词汇配置文件的转录口语数据量，以及每个词性类别中包含的项目数量，构建了不同大小和类型的个性化词汇配置文件。研究结果表明，使用包含5个形容词、5个连词和10个副词、名词、代词及动词的10分钟转录口语数据来构建的小型且更为紧凑的配置文件，在性能和数据效率方面达到了最佳平衡。", "conclusion": "本文为构建符合最小数据需求的稳定且个性化的词汇配置文件提供了实用见解，可作为对话代理词汇对齐策略的基础步骤。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04046", "html_url": "https://arxiv.org/abs/2509.04046", "title": "基于RoBERTa的功能句法标注模型应用于中文文本", "title_en": "A RoBERTa-Based Functional Syntax Annotation Model for Chinese Texts", "authors": "Han Xiaohui,Zhang Yunlong,Guo Yuxi", "background": "系统功能句法和其分支卡迪夫句法已被广泛应用于跨语言和文本的修辞分析和语义功能研究。然而，尚未出现基于此理论的自动注释系统，尤其是针对中文文本的系统，这严重影响了相关理论的应用与推广。为填补这一空白，本文基于RoBERTa提出的中文功能句法标注模型，并从《人民日报》2014年语料库随机选取4100句进行功能句法标注，构建用于训练的语料库。通过此模型在命名实体识别任务上的测试集F1得分为0.852，显著优于其他对比模型，展示了在识别主语(S)、谓语动词(M)和补语(C)等核心句法元素方面出色的性能。", "innovation": "本文首次将功能句法与基于注意力的NLP模型相结合，提出了应用于中文文本的基于RoBERTa的功能句法标注模型。这一模型的成功实现为自动化的中文功能句法分析提供了新的方法，也为后续研究奠定了坚实基础，但仍需针对标签不平衡的实体识别有所改进空间。", "conclusion": "本文提出的基于RoBERTa的功能句法标注模型为中文文本的功能句法分析提供了一种新方法，能够显著提升识别关键句法元素的准确性，但仍需进一步优化以应对标签不平衡问题，促进相关理论的应用与推广。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04066", "html_url": "https://arxiv.org/abs/2509.04066", "title": "阿拉伯教育聊天机器人性技术研究概述", "title_en": "Arabic Chatbot Technologies in Education: An Overview", "authors": "Hicham Bourhil,Yacine El Younoussi", "background": "近年来，人工智能（AI）及其在自然语言处理（NLP）领域的进展极大地推动了聊天机器人技术的应用，它们被广泛应用于教育、医疗、旅游和客户服务等不同领域。尤其是在COVID-19大流行期间，人们对这些数字技术的兴趣增加，以便允许并增强远程访问。在教育领域，网上学习系统在全球范围内被广泛采用。大型语言模型（LLM）如BERT和GPT的出现使聊天机器人的应用更加广泛。因此，为了更好地理解阿拉伯语教育聊天机器人的现状和发展，本文进行了相关调研分析。", "innovation": "本文首次专注于研究和总结阿拉伯语教育聊天机器人的特点和发展现状，特别是讨论了它们所采用的方法、语言多样性以及评估性能所使用的指标。并且，文中指出了与英语等其他语言的聊天机器人相比，在阿拉伯语教育聊天机器人领域中，尽管取得了成功，但现代技术的使用却相对较少这一研究空白。", "conclusion": "本文探讨了未来在阿拉伯语教育聊天机器人领域研究的方向。未来的研究可能集中在开发更有效的工具来提高聊天机器人的性能，以及研究新的方法来改进其用于教育的适应性和实用性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04059", "html_url": "https://arxiv.org/abs/2509.04059", "title": "基于音乐理论规则合成乐谱问题以评估和强化学习", "title_en": "Synthesizing Sheet Music Problems for Evaluation and Reinforcement Learning", "authors": "Zhilin Wang,Zhe Yang,Yun Luo,Yafu Li,Haoran Zhang,Runzhe Zhan,Derek F. Wong,Jizhe Zhou,Yu Cheng", "background": "当前研究在大型语言模型（LLMs）和多模态大型语言模型（MLLMs）识读乐谱的能力上缺乏评价基准和训练数据。因此，本文提出了基于音乐理论的乐谱问题合成方法，以作为评估基准和强化学习中的训练数据。这种方法有助于揭示模型在乐谱理解中的推理能力，并且使用合成数据进行强化学习可以提高模型在乐谱理解任务上的表现。此外，该研究还表明，增强的推理能力可以促进音乐创作的发展。", "innovation": "本文提出了一种合成乐谱问题的方法，该方法能够生成可用于评估和作为强化学习训练数据的乐谱问题。所提出的合成数据生成框架能够在文本和视觉模态生成可验证的乐谱问题，进而形成合成乐谱推理基准（SSMR-Bench）和配套的训练集。通过这种方法，模型在乐谱解析和生成任务上的性能得到了提升，并且新方法在音乐创作方面的应用潜力得到了验证。", "conclusion": "本文是首次提出基于音乐理论规则合成乐谱问题的方法，不仅展示了这种方法在推动模型乐谱理解推理能力方面的作用，还揭示了其在促进AI辅助音乐创作的可能性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04013", "html_url": "https://arxiv.org/abs/2509.04013", "title": "关于LLM基准评估的稳健性和可靠性", "title_en": "On Robustness and Reliability of Benchmark-Based Evaluation of LLMs", "authors": "Riccardo Lunardi,Vincenzo Della Mea,Stefano Mizzaro,Kevin Roitero", "background": "目前，大型语言模型（LLMs）的效能通常通过基准测试进行评估，如MMLU、ARC-C或HellaSwag等，其中问题以原文形式呈现，具有固定且标准化的格式。然而，实际应用中涉及语言的多样性，要求模型能够在多种不同的问题表述中保持其有效性。本研究系统地评估了LLMs对改述的基准问题的鲁棒性，并探讨了基于基准的评估是否能可靠地衡量模型的能力。通过系统地生成六种不同常见基准下的所有问题的各种改述，评估了34种不同大小和效能的最新先进LLMs的效果，并发现尽管LLM的排名在改述输入中相对稳定，但其绝对效果得分会显著下降，这表明LLMs在处理语言多样性方面遇到困难，引发对其泛化能力和评估方法的关注。此外，观察到的性能下降质疑了基于基准的评估的可靠性，表明高基准得分可能无法全面反映模型对实际输入变化的稳健性。", "innovation": "本研究通过系统地生成六种不同常见基准下的所有问题的各种改述，评估了34种不同大小和效能的最新先进LLMs的效果，揭示了尽管LLM的排名在改述输入中相对稳定，但其绝对效果得分会显著下降，这为LLM评估方法提供了新的视角，强调了需要设计更稳健的基准来更好地反映实际部署场景的重要性。", "conclusion": "本研究表明，尽管LLM在改述输入中的排名相对稳定，但其绝对效果得分显著下降，这揭示了LLMs在处理语言多样性方面存在困难，质疑了基于基准的评估方法的可靠性，强调了需要采用更稳健的评估基准来反映实际部署场景的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04182", "html_url": "https://arxiv.org/abs/2509.04182", "title": "联合建模实体和话语关系以进行连贯性评估", "title_en": "Joint Modeling of Entities and Discourse Relations for Coherence Assessment", "authors": "Wei Liu,Michael Strube", "background": "在语言学中，连贯性可以通过多种方式实现，如在句子间保持相同的实体引用以及建立它们之间的关系。然而，大多数现有的连贯性建模工作只专注于构建实体或话语关系，而很少考虑将这两种类型结合起来。", "innovation": "本研究探索了两种方法，用于同时建模实体和话语关系来评估连贯性。实验结果表明，结合这两种类型的特征显著提高了连贯性模型的性能，强调了同时建模它们的好处。", "conclusion": "在三个基准数据集上的实验结果显示，将实体特征和话语关系特征相结合可以显著提升连贯性模型的性能。这意味着在评估连贯性时，同时考虑实体和话语关系对于建模来说是有益的。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03940", "html_url": "https://arxiv.org/abs/2509.03940", "title": "VoxRole：评估基于语音的角色扮演代理的全面基准", "title_en": "VoxRole: A Comprehensive Benchmark for Evaluating Speech-Based Role-Playing Agents", "authors": "Weihao Wu,Liang Cao,Xinyu Wu,Zhiwei Lin,Rui Niu,Jingbei Li,Zhiyong Wu", "background": "大型语言模型（LLMs）的最新重大进展显著推动了角色扮演对话代理（RPCAs）的发展。当前RPCA研究面临双重限制：首先，现有工作主要集中在文本模态上，完全忽视了语音中的重要副语言特征，如语调、语调和节奏，这些特征对传达角色情感和塑造生动的身份至关重要。其次，基于语音的角色扮演领域长期以来缺乏标准化的评估基准。当前的口语对话数据集主要针对基本能力评估，角色画像刻画简单或定义不清，无法有效量化模型在长期人格一致性等核心能力上的表现。", "innovation": "该论文介绍了VoxRole，这是第一个专门用于评估基于语音的RPCA的综合基准。基准包括来自261部电影的1228个独特角色的13335个多轮对话，总时长65.6小时。作者提出了一种新的两阶段自动化流程，首先将电影音频与剧本对齐，然后使用LLM系统地为每个角色构建多维画像。基于VoxRole，进行多维度评估，揭示了当前口语对话模型在维持人格一致性方面的各自优势和局限。", "conclusion": "通过对VoxRole的利用，研究展示了当前的口语对话模型在维持人格一致性方面的多维度评价结果，揭示了它们各自的优缺点。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04432", "html_url": "https://arxiv.org/abs/2509.04432", "title": "语言模型能否处理非格里高利历?", "title_en": "Can Language Models Handle a Non-Gregorian Calendar?", "authors": "Mutsumi Sasaki,Go Kamoda,Ryosuke Takahashi,Kosuke Sato,Kentaro Inui,Keisuke Sakaguchi,Benjamin Heinzerling", "background": "语言模型在时间推理和知识方面具有重要能力，但大多数研究集中在格里高利历上。许多非格里高利历（如日本历、希吉耳历、希伯来历）在使用中反映了文化时间观念。现有语言模型处理非格里高利历的能力尚未被评估。", "innovation": "本文系统评估开源语言模型在处理日本历（一种非格里高利历）上的表现，创建了四个需要时间推理和时间知识的任务数据集，发现一些模型可以进行日历转换，但即使针对日本的语言模型在处理日历计算和跨历维护一致性方面也存在困难。", "conclusion": "结果强调了开发更适合特定文化日历理解的语言模型的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04304", "html_url": "https://arxiv.org/abs/2509.04304", "title": "知识更新快：评估大型语言模型过时医疗知识的记忆", "title_en": "Facts Fade Fast: Evaluating Memorization of Outdated Medical Knowledge in Large Language Models", "authors": "Juraj Vladika,Mahdi Dhaini,Florian Matthes", "background": "大型语言模型（LLMs）在医疗领域的应用潜力巨大，但它们依赖于静态训练数据，这在医学知识不断更新的情况下存在重大风险。LLMs 因记忆过时的医学知识而有可能提供有害建议或在临床推理任务中失败。为了研究这个问题，该研究引入了两个基于系统回顾的问题-答案数据集：MedRevQA（包含16,501个问答对，覆盖一般医学生物知识）和MedChangeQA（包含医学共识随着时间变化的512个问答对子集）。", "innovation": "该研究首次通过系统回顾方法构建两个基于问题-答案的数据集MedRevQA和MedChangeQA，用于评估LLMs对过时医学知识的记忆。研究结果揭示了LLMs在所有模型中的一致性，即依赖于过时的知识。研究还分析了过时预训练数据和训练策略的影响，并提出未来减少这一问题的途径，为开发更及时和可靠的人工智能医疗系统奠定基础。", "conclusion": "研究发现LLMs普遍依赖于过时的医学知识，并指出了导致这一现象的过时预训练数据和训练策略。提出未来应致力于减少这种依赖性，并开发出更及时和可靠的医疗AI系统。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04111", "html_url": "https://arxiv.org/abs/2509.04111", "title": "MultiWikiQA: 多语言阅读理解基准数据集", "title_en": "MultiWikiQA: A Reading Comprehension Benchmark in 300+ Languages", "authors": "Dan Saattrup Smart", "background": "当前存在许多阅读理解数据集，但大多数只涵盖少数语言，这限制了模型在多种语言环境下的适用性。因此，需要一个包含多种语言的阅读理解数据集来测试和改进语言模型的多语言能力。这项研究引入了一个新的阅读理解数据集，名为MultiWikiQA，涵盖了306种语言，为评估多语言阅读理解提供了可能。", "innovation": "该研究创新地设计了一个多语言阅读理解数据集MultiWikiQA，该数据集包括来自维基百科的文章作为上下文，由大型语言模型生成问题，并直接在维基百科文章中找到答案。它还对其中30种语言的问题流畅性进行了众包的人工评估，展示了高质量的问题生成。此外，该研究评估了6种不同规模的语言模型，表明该基准测试具有足够的挑战性，并且不同语言之间的性能差异显著。", "conclusion": "MultiWikiQA数据集和相关评估结果已经公开可用，为多语言阅读理解任务的评估提供了重要资源。该研究的数据集不仅展示了语言模型在不同语言环境中的表现差异，还为未来的研究提供了基准线。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04202", "html_url": "https://arxiv.org/abs/2509.04202", "title": "社会事件检测中的显式和隐式数据扩增", "title_en": "Explicit and Implicit Data Augmentation for Social Event Detection", "authors": "Congbo Ma,Yuxia Wang,Jia Wu,Jian Yang,Jing Du,Zitai Qiu,Qing Li,Hu Wang,Preslav Nakov", "background": "社会事件检测涉及从社交媒体中识别和分类重要事件，这需要标注数据，但标注过程成本高且劳动密集度大。为解决这一问题，提出了一个名为SED-Aug的插件式双扩增框架，结合了显式基于文本和隐式特征空间扩增，以增强数据多样性和模型稳健性。", "innovation": "该方法结合了显式文本扩增和隐式特征空间扩增。显式扩增利用大型语言模型通过五种不同的生成策略增强文本信息；隐式扩增设计了五种新型扰动技术，在结构融合嵌入的空间中操作，同时保持嵌入的语义和关系性质，使其更具多样性。特别是在Twitter2012和Twitter2018数据集上，与最佳基线模型相比，平均F1分数分别提高了约17.67%和15.57%。", "conclusion": "该论文通过引入SED-Aug框架，显著提升了社会事件检测的性能，并且其代码已发布在GitHub上。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04077", "html_url": "https://arxiv.org/abs/2509.04077", "title": "通过 fine-tuned 语言模型提高叙述分类和解释", "title_en": "Improving Narrative Classification and Explanation via Fine Tuned Language Models", "authors": "Rishit Tyagi,Rahul Bouri,Mohit Gupta", "background": "理解隐含叙事和隐含信息对于分析偏见和情绪至关重要。传统的NLP方法难以检测到微妙的语言和隐藏的议程。本研究主要解决两个关键挑战：(1) 新闻文章中的多标签叙事和子叙事分类，(2) 生成简洁且基于证据的主导叙事解释。", "innovation": "研究通过使用基于召回的方法微调 BERT 模型进行全面的叙述检测，并采用了 GPT-4o 管道来提高预测一致性。提出了一个基于语义检索的 few-shot 提示 ReACT 框架，以确保解释的准确和相关性。为了增强事实准确性并减少幻觉，研究中整合了一个结构化分类表作为辅助知识库。", "conclusion": "研究结果表明，将辅助知识整合到提示中可以提高分类准确性和解释可靠性，这些技术在媒体分析、教育和情报收集中具有广泛的应用前景。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04292", "html_url": "https://arxiv.org/abs/2509.04292", "title": "Inverse IFEval：LLMs能否克服固有的训练惯例遵循实际指令？", "title_en": "Inverse IFEval: Can LLMs Unlearn Stubborn Training Conventions to Follow Real Instructions?", "authors": "Qinyan Zhang,Xinping Lei,Ruijie Miao,Yu Fu,Haojie Fan,Le Chang,Jiafan Hou,Dingling Zhang,Zhongfei Hou,Ziqiang Yang,Changxin Pu,Fei Hu,Jingkai Liu,Mengyun Liu,Yang Liu,Xiang Gao,Jiaheng Liu,Tong Yang,Zaiyuan Wang,Ge Zhang,Wenhao Huang", "background": "大语言模型（LLMs）在多种任务上表现出色，但在执行与监督微调（SFT）中学到的标准模式冲突的指令时往往表现出认知惰性。为评估这一局限性，本文提出了Inverse IFEval基准，用于衡量模型克服训练诱导偏见和遵守敌对指令的能力。实验表明，当前的主要LLM在遵循实际指令时仍存在不足，突显了未来对齐努力需要追求流畅性和事实准确性的同时，还应考虑适应不寻常上下文的灵活性。", "innovation": "_inverse_IFEval是第一个专门评估模型克服训练诱导偏见和遵守敌对指令能力的基准。它通过引入八种不同类型的挑战（如问题纠正、故意的文本缺陷、无注释的代码和反事实回答），系统地测试了LLMs的这项能力。利用人类在循环中的数据集构建流程，逆IFEval基准构建了一个高质量的中文和英文问题数据集，涵盖了23个领域。", "conclusion": "实验结果强调，未来的对齐工作不仅应追求流畅性和事实准确性，还应考虑适应非标准情境的灵活性。期望通过使用逆IFEval基准作为诊断工具和开发方法的基础，能够缓解认知惰性，减少对狭窄模式的过拟合，并最终提高LLMs在复杂和不可预测的真实世界场景中的指令遵循可靠性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04183", "html_url": "https://arxiv.org/abs/2509.04183", "title": "MAGneT：合成多轮心理健康咨询会话的协调多智能体生成", "title_en": "MAGneT: Coordinated Multi-Agent Generation of Synthetic Multi-Turn Mental Health Counseling Sessions", "authors": "Aishik Mandal,Tanmoy Chakraborty,Iryna Gurevych", "background": "随着对可扩展心理咨询服务需求的增长，急需将开源大型语言模型（LLMs）与高质量、符合隐私的数据相结合进行调优，但此类数据仍然稀缺。因此，需要开发新的方法来生成逼真的合成心理咨询服务会话，以满足这一需求。现有的单智能体方法在捕捉真实咨询服务的结构和细微差别方面表现不足，这也导致了评估标准不统一的问题。", "innovation": "文章介绍了一种名为MAGneT的新颖多智能体框架，用于合成生成多轮心理健康咨询会话。该框架将咨询师回应生成分解为多个协作子任务，由专门的LLM智能体分别处理，每个智能体模拟一种关键的心理学技术。与现有方法相比，MAGneT更好地捕捉了真实咨询服务的结构和细微差别。此外，该文提出了一个统一的评估框架，结合了自动和专家评估指标，扩大了专家评估的标准维度，从先前的四个方面扩展到九个方面，从而更全面和稳健地评估数据质量。", "conclusion": "实证结果表明，MAGneT在生成的心理咨询服务的质量、多样性和治疗对齐方面明显优于现有方法，平均提高一般咨询技能3.2%和认知行为疗法（CBT）特定技能4.3%。另外，77.2%的专家更倾向于MAGneT生成的会话。进一步的实验表明，使用MAGneT生成的会话进行开源模型的微调表现更好，平均提高一般咨询技能6.3%和CBT特定技能7.3%。文章还公开了代码和数据。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04373", "html_url": "https://arxiv.org/abs/2509.04373", "title": "测量偏见还是测量任务：理解LLM性别偏见的脆弱性", "title_en": "Measuring Bias or Measuring the Task: Understanding the Brittle Nature of LLM Gender Biases", "authors": "Bufan Gao,Elisa Kreiss", "background": "随着大型语言模型（LLMs）在具有社会影响力的环境中越来越广泛的应用，性别偏见的问题引起了越来越多的关注。当前的研究和努力主要集中在测量和减轻这种偏见上，但这些测量通常依赖于不同于自然语言分布的评估任务，这些任务往往通过精心构造的任务提示明确地或隐蔽地提示性别偏见相关内容。本文探讨了提示评估任务的目的如何影响LLMs中测量的性别偏见。", "innovation": "研究通过在提示条件中测试模型，使其清晰地表示测试上下文和性别相关的内容，以衡量LLMs中性别偏见的敏感性。研究使用了四个任务格式，并使用标记概率和离散选择两种度量标准进行评估。研究发现，即使是微小的提示变化也可能会显著改变偏见结果，有时甚至完全改变其方向。离散选择度量标准倾向于相对于概率度量放大偏见。这些发现揭示了LLM性别偏见评估的脆弱性，并为NLP基准测试和开发社区提出一个新问题：控制良好的测试设计能够多大程度上触发LLM的“测试模式”性能，这又意味着未来基准测试的生态验证价值是什么？", "conclusion": "本文的研究发现了即使是细微的提示变化也显著影响LLMs中测量的性别偏见，提示测试的目的可能对评估结果产生重大影响。同时强调了控制设计在测试LLMs性能中的重要性，探讨了这种对评估的敏感性如何影响NLP领域的未来基准测试方法的生态验证价值。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03646", "html_url": "https://arxiv.org/abs/2509.03646", "title": "通过强化学习在大语言模型中实现层级化的涌现式推理", "title_en": "Emergent Hierarchical Reasoning in LLMs through Reinforcement Learning", "authors": "Haozhe Wang,Qixin Xu,Che Liu,Junhong Wu,Fangzhen Lin,Wenhu Chen", "background": "强化学习（RL）已被证明对增强大型语言模型（LLMs）的复杂推理能力非常有效，但仍至于其成功背后的机制仍然不透明。本文分析揭示了所谓“恍然大悟”时刻、“长度缩放”和熵动态等现象并非孤立的现象，而是体现出一种逐步建立的推理层次结构的特征，类似于人类认知中的高级策略规划与低级程序执行的分离。初始阶段，模型受规则执行约束，需要提升低级技能。之后，学习瓶颈转向为实现高级策略规划的探索与掌握。RL算法如GRPO普遍存在限制关键决策的优化效率问题，本文提出一种新的算法——Awareness-导向的智能分配算法（HICRA），专注于具有高影响的决策性维度，从而显著提升模型性能。", "innovation": "本文提出了一种新的算法——Awareness-导向的智能分配算法（HICRA），这种算法能够集中优化关键决策维度，显著提升了模型的性能。该研究表明侧重于这一战略瓶颈对于实现高级推理至关重要，并且实证验证了语义熵比传统的基于词级熵的指标更能作为决策探索的度量。", "conclusion": "HICRA显著提高了通过强化学习改进高级推理的效率，强调了专注于这一战略瓶颈对于实现先进推理的重要性。同时，HICRA算法更加关注高影响的规划性词元，避免了优化压力在所有词元上泛化所带来的学习信号稀释问题。语义熵被证明比基于词级熵的传统指标更有效用于衡量战略探索的深度。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03636", "html_url": "https://arxiv.org/abs/2509.03636", "title": "CausalARC：基于因果世界模型的抽象推理", "title_en": "CausalARC: Abstract Reasoning with Causal World Models", "authors": "Jacqueline Maasch,John Kalantari,Kia Khezeli", "background": "在有限数据和分布转移的情况下，推理需要能够适应新的问题设置。本文介绍了一个新的实验测试平台CausalARC，用于AI在低数据和分布外范型下的推理。CausalARC借鉴了Abstraction and Reasoning Corpus（ARC）的模式，通过全面指定的因果世界模型，每个推理任务形式化地表示为结构因果模型。", "innovation": "CausalARC通过有原则的数据增强，提供观察性、干预性和反事实性反馈，以因果世界模型的形式呈现，采用少量带上下文的学习演示。作为概念验证，本文展示了CausalARC在四种语言模型评估场景中的应用：（1）测试时的训练、（2）在上下文中的反事实推理、（3）程序合成以及（4）基于逻辑推理的因果发现。", "conclusion": "为了展示CausalARC的能力，本文选择了四种不同的应用场景来评估语言模型在这些条件下的表现，这表明了CausalARC在低数据和分布外地域内进行推理任务的有效性和潜力。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03740", "html_url": "https://arxiv.org/abs/2509.03740", "title": "视觉语言模型的奇异值少样本适应", "title_en": "Singular Value Few-shot Adaptation of Vision-Language Models", "authors": "Taha Koleilat,Hassan Rivaz,Yiming Xiao", "background": "视觉语言模型（如CLIP）展示了跨多个应用领域的出色的零样本和少样本学习能力。然而，要适应新的细粒度领域仍然存在挑战，主要是因为依赖于提示工程并且完全微调模型的成本高昂。现有的适应方法依赖于增广的组件，如提示令牌和适配模块，这些组件可能会限制模型的适应质量，导致模型不稳定，并损害模型在预训练期间学到的丰富知识。", "innovation": "CLIP-SVD是一种新颖的多模态和参数高效适应技术，利用奇异值分解（SVD）来修改CLIP的内部参数空间，而无需注入额外的模块。具体而言，我们只微调CLIP参数矩阵的奇异值以在特定领域进行调整，同时保留预训练模型。该设计使得仅使用模型总参数量的0.04%即可实现增强的适应性能，并更好地保留其泛化能力。CLIP-SVD在11个自然数据集和10个生物医学数据集上取得了最新的分类结果，优于之前的方法，在少样本设置下的准确性和泛化能力上表现更好。此外，我们利用基于自然语言的方法来分析CLIP适应的有效性和动态，以实现对CLIP-SVD的可解释性。", "conclusion": "CLIP-SVD实现了在11个自然数据集和10个生物医学数据集上的最佳分类结果，同时提供了可解释的适应过程分析，通过仅为模型参数的0.04%进行微调，提高了少样本适应的效果和模型的泛化能力。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03730", "html_url": "https://arxiv.org/abs/2509.03730", "title": "LLM的人格幻象：揭示自陈报告与行为之间的分离", "title_en": "The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs", "authors": "Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez", "background": "人格特质长期被视为预测人类行为的重要因素。随着大型语言模型（LLMs）的发展，研究人员开始发现人工系统中可能存在类似的人格模式，一些高级LLM在行为上展现了与人类特质（如宜人性和自我调节）相似的趋势。尽管了解这些模式至关重要，但早期研究更多依赖于简化的人格自陈报告和启发式提示，缺少行为层面的验证。本研究通过系统地从三个维度——训练阶段的人格动态特征、自陈报告的人格特质在行为任务中的预测有效性以及特定干预（如角色注入）对自陈报告和行为的影响——来深入探索LLM的人格特征。", "innovation": "本研究系统地从三个重要方面探索了LLM的人格特征：训练阶段人格的动态变化、自陈报告人格特质在任务预测中的有效性，以及特定干预手段（如角色注入）的效果。此外，本研究还发现了指令对齐（如RLHF、指令调优）显著稳定且增强了LLM的人格表达和相关性，但这并未稳定地关联到行为上，这改变了对LLM人格的假设，并强调了在对齐和解释性评估方面进行更深入评价的重要性。这些发现揭示了自陈报告与实际行为之间的分离，挑战了关于LLM人格的一般假设，提醒研究人员需要更深入地评估LLM的人格和行为一致性。", "conclusion": "研究表明，指令对齐显著稳定了LLM的人格表达并增强了人格相关性，但这种稳定并未体现在行为上。自我报告的人格特质并不能可靠地预测行为，实际观察到的行为关联常与人类模式不符。角色注入虽成功地影响了自我报告的方向，但在实际行为上效果有限或不一致。这些发现挑战了LLM人格的表面假设，强调了行为一致性的重要性，提醒研究人员应更深入地理解和评估LLM的人格和行为一致性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03897", "html_url": "https://arxiv.org/abs/2509.03897", "title": "SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation", "title_en": "SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation", "authors": "Xiaofu Chen,Israfel Salazar,Yova Kementchedjhieva", "background": "随着人们对生成长且详细图像说明的兴趣增长，标准评估指标变得越来越不可靠。尽管基于N-gram的指标高效，但它们无法捕捉到语义正确性。起初，为了应对这一挑战而设计的表示相似性（RS）指标由于计算成本高而使用受限，即使在现代硬件的推动下，它们仍然因为与人类判断的相关性较低而不受欢迎。基于大型语言模型（LLMs）的指标与人类判断的相关性很强，但在模型开发中的迭代使用中仍然太昂贵。", "innovation": "我们引入了SPECS（Specificity-Enhanced CLIPScore），一种专为长图像说明设计的无参考RS指标。SPECS通过一个新的目标改变CLIP，强调特定性：奖励正确细节同时惩罚错误细节。SPECS在与人类判断相关性方面能够与开源LLM基础的指标相媲美，但其效率远高于后者，从而成为图像描述模型开发中的实践性替代品。", "conclusion": "研究表明SPECS在与人类判断相关性方面与开源LLM基础指标相当，但其效率更高，使其成为一个实用的选择，用于图像描述模型开发过程中的迭代检查点评估。有关此论文的代码可以在下面给定的链接处找到。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04011", "html_url": "https://arxiv.org/abs/2509.04011", "title": "NER Retriever: 零样本类型意识名称实体检索", "title_en": "NER Retriever: Zero-Shot Named Entity Retrieval with Type-Aware Embeddings", "authors": "Or Shachar,Uri Katz,Yoav Goldberg,Oren Glickman", "background": "该研究背景在于传统的命名实体识别（NER）任务通常要求预先定义实体类型，而该论文探讨了一种变体——即无需预先定义实体类型，而是依靠用户自定义的类型描述来进行检索的零样本命名实体检索（NER Retriever）。因此，论文的目标是在用户输入类型描述后，能够自动检索包含这些类型实体的文档，而不需要依赖固定框架或微调模型，而是利用大规模语言模型（LLMs）的内部表示来嵌入实体提及和用户提供的开放描述，通过训练轻量级对比投影网络来精炼这些表示，使其更适合近邻搜索。", "innovation": "研究创新主要体现在以下方面：1）利用大语言模型的内部表示作为实体提及和用户类型描述的嵌入，而非依赖固定模式或微调的模型；2）通过轻量级对比投影网络来精炼嵌入表示，使其更加类型敏感并适用于近邻搜索；3）通过内部表示中的中间层变换块值向量来编码细粒度类型信息，比常用的顶层嵌入更有效；4）指出了在LLMs模型内部表示中进行表示选择的重要性，提出了基于已实现的解决方案的实际为大规模，无模式实体检索的方案。", "conclusion": "通过在三个基准上的评测，NER Retriever显著优于词典级和稠密句子级检索基线，支持LSTM模型中的表示选择，并展示了可扩展的、无模式实体检索的实用解决方案。该论文所开发的NER Retriever代码库已经公开。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04027", "html_url": "https://arxiv.org/abs/2509.04027", "title": "CoT-Space: 一种通过强化学习进行内部慢思考的理论框架", "title_en": "CoT-Space: A Theoretical Framework for Internal Slow-Thinking via Reinforcement Learning", "authors": "Zeyu Gan,Hao Yi,Yong Liu", "background": "强化学习（RL）已成为提升大型语言模型（LLMs）推理能力的关键方法。然而，传统基于令牌级别的RL框架无法与复杂的多步思考过程（如推理链）的推理层面相匹配，这表明存在的理论空白。", "innovation": "我们提出了CoT-Space，这是一个新颖的理论框架，用于将LLM的推理任务从离散的令牌预测任务重新定义为连续推理级别的语义空间中的优化过程。从噪声和风险角度进行了分析，证明了最优推理链长度收敛是通过克服拟合不足和拟合过度的基本权衡自然结果。此外，大量实验提供了对理论发现的强大实证证据。", "conclusion": "我们的框架不仅为过度思考等经验现象提供了连贯的解释，而且为设计更有效且更具泛化能力的推理代理提供了坚实理论基础。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03986", "html_url": "https://arxiv.org/abs/2509.03986", "title": "Promptception: 大型多模态模型对提示有多敏感？", "title_en": "Promptception: How Sensitive Are Large Multimodal Models to Prompts?", "authors": "Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan", "background": "近年来，大型多模态模型（LMMs）在多个领域取得了成功，但在多项选择题作答（MCQA）任务中如何为这些模型设计提示仍不明确。研究发现，小小的提示表达和结构的变化都能导致大幅度的准确度变化，最多可达15%，这为透明且公平的模型评估带来了挑战，因为模型往往只报告其最佳情况的性能，这是通过精心挑选的提示实现的。该研究通过提示对模型性能的具体影响，探讨了如何更好地评估此类模型，并提出了一套针对不同类型模型的提示原则，以促进模型评估的稳健性和公平性。", "innovation": "研究引入了一个系统框架——Promptception，用于评估大型多模态模型对提示的敏感性。该框架包括61种不同的提示类型，覆盖15个类别和6个超类别，用于评估10种从轻量级开源模型到GPT-4o和Gemini 1.5 Pro的多模态模型在3个MCQA基准上的表现。研究发现，专有模型比开源模型更敏感于提示的表达，这反映了其更紧密的指令语义对齐。开源模型表现较稳定，但难以处理更复杂的提示措辞。基于这些分析，研究提出了适用于专有和开源多模态模型的提示原则，以促进更多稳健和公平的模型评估。", "conclusion": "研究揭示了不同类型的大型多模态模型（包括专有和开源模型）对提示的不同敏感度，提出了针对不同类型的多模态模型的提示原则，以促进模型评估过程中的更多透明性和公平性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04072", "html_url": "https://arxiv.org/abs/2509.04072", "title": "LibriQuote：用于赋表情的零样本语音合成的虚构角色对话数据集", "title_en": "LibriQuote: A Speech Dataset of Fictional Character Utterances for Expressive Zero-Shot Speech Synthesis", "authors": "Gaspard Michel,Elena V. Epure,Christophe Cerisara", "background": "文本到语音（TTS）系统最近通过使用大规模语音数据集已经实现了更多表达性和自然的语音合成。然而，大规模语料库中赋表情语音的比例经常不清楚。现有的赋表情语音语料库通常规模较小，主要用于评估TTS系统的基准。", "innovation": "本论文介绍了LibriQuote数据集，这是从朗读有声读物中衍生出的英语语料库，旨在用于细调和评估赋表情的零样本TTS系统的性能。训练数据集包括12,700小时的朗读非赋表情语音和5,300小时的大部分赋表情语音，后者主要来自人物引用。此外，该数据集提供了一个挑战性的7.5小时测试集，用于评估TTS系统的性能：给定中性参考语音输入，评估系统生成具有表情的语音片段的能力，同时保持参考音色。质性和客观评价结果表明，用LibriQuote数据集细调基础TTS系统可以显著提高其合成语音的可理解度，并且最近的系统无法生成与真实引用语片断一样具有表情和自然的声音。", "conclusion": "该数据集和评估代码已经免费提供。可以在特定网页上找到音频样本。该数据集旨在提供广泛的情感范围和各种口音，以提高TTS系统生成赋表情语音的能力。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03787", "html_url": "https://arxiv.org/abs/2509.03787", "title": "在健康领域评估检索增强生成对抗性证据的鲁棒性", "title_en": "Evaluating the Robustness of Retrieval-Augmented Generation to Adversarial Evidence in the Health Domain", "authors": "Shakiba Amirshahi,Amin Bigdeli,Charles L. A. Clarke,Amira Ghenai", "background": "检索增强生成（RAG）系统通过提供检索到的证据或上下文来事实性地支撑大型语言模型（LLM）的响应，这可以减少幻觉并扩大其准确回答超出训练数据范围问题的能力。然而，这一设计引入了一个关键性漏洞：LLM可能会吸收和复制检索到的证据中的错误信息。特别是在对抗性材料的存在下，这个问题会更加严重。本文在健康领域系统地评估了RAG系统在对抗性证据面前的鲁棒性，考察了模型输出与真实答案的一致性。", "innovation": "本文提出了对健康领域的RAG系统在对抗性证据面前的鲁棒性进行系统评估的方法，并通过控制实验考察了不同类型和组成的检索文档以及用户问题的不同表述对模型输出一致性的影响。研究发现，对抗性文档显著降低了模型输出与真实答案的一致性，但当检索池中还存在有益证据时，鲁棒性可以得到保留。这些发现为高风险领域设计更安全的RAG系统提供了实际指导。", "conclusion": "本文的研究结果揭示了在健康领域，对抗性证据对RAG系统的负面影响，同时也指出了有益证据的存在有助于保持鲁棒性。这些发现强调了检索安全措施的重要性，并为未来在高风险领域设计更加安全的RAG系统提供了探究方向。所有实验结果均在作者的GitHub仓库中公开发布。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04166", "html_url": "https://arxiv.org/abs/2509.04166", "title": "跨越物种鸿沟：从语音到动物声音的迁移学习", "title_en": "Crossing the Species Divide: Transfer Learning from Speech to Animal Sounds", "authors": "Jules Cauzinille,Marius Miron,Olivier Pietquin,Masato Hagiwara,Ricard Marxer,Arnaud Rey,Benoit Favre", "background": "自监督语音模型在语音处理任务中取得了显著的性能，但在处理非语音数据方面（如生物声学检测和分类任务）的效果尚未广泛研究。", "innovation": "研究了自监督语音模型在生物声学检测和分类任务中的迁移学习能力。提出了一种新的方法，通过线性探针分析时间平均表示模型的性质，并考虑到时间信息的影响。同时，研究了不同频率范围和噪声对模型性能的影响，展示了针对噪声鲁棒训练的预训练模型对生物声学研究的高效框架潜力。", "conclusion": "我们的研究结果表明，自监督语音模型在生物声学领域的性能可与微调的生物声学预训练模型竞争，且展示了噪声鲁棒预训练配置的影响。这些发现突显了基于语音的自监督学习在推进生物声学研究方面的潜力。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04403", "html_url": "https://arxiv.org/abs/2509.04403", "title": "实时多模态安全场景自适应数据集构建", "title_en": "Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios", "authors": "Jingen Qu,Lijun Li,Bo Zhang,Yichen Yan,Jing Shao", "background": "多模态大语言模型（MLLMs）正在快速发展，带来了日益复杂的安全挑战。然而，当前依赖风险导向的数据集构建方法未能覆盖实时多模态安全场景（RMS）的日益复杂性，且缺乏统一的安全评估指标，导致其整体效果未得到验证。", "innovation": "本文提出了一种基于图像的自适应数据集构建方法，该方法从图像开始，最终构建包含指导回应的配对文本和指导响应的数据集。使用这种方法，自动生成了一个包含35000个图像-文本配对的数据集，并引入了标准化的安全数据集评估指标，利用微调的安全评判模型评估其在其他安全任务中的能力。实验结果表明，基于图像的方法具有可扩展性和有效性，为构建实际多模态安全数据集提供了新的视角。", "conclusion": "实验结果证实了基于图像的管道的可扩展性和有效性，为构建实际多模态安全数据集提供了一个新的视角，提出了对于实时多模态安全场景自适应数据集构建的新方法。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04159", "html_url": "https://arxiv.org/abs/2509.04159", "title": "使用时间图构建烹饪程序操作中心本体", "title_en": "Towards an Action-Centric Ontology for Cooking Procedures Using Temporal Graphs", "authors": "Aarush Kumbhakern,Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das", "background": "将烹饪程序形式化仍然是一个具有挑战性的任务，因为它们本身具有复杂性和模糊性。我们介绍了一种可扩展的领域特定语言，用于将食谱表示为有向行动图，能够捕捉过程、转移、环境、并发性和组合结构。这种方法使对复杂的烹饪工作流程进行精确和模块化的建模成为可能。初步的手动评估表明DSL的表达性和未来自动化食谱分析和执行的适宜性。这项工作代表了构建烹饪程序操作中心本体的初步步骤，使用时间图使机器能够结构化理解、准确解释和大规模自动化烹饪过程，无论是家庭厨房还是专业烹饪环境中都是如此。", "innovation": "提出了一种可扩展的领域特定语言，用于表示食谱为有向行动图，这能够捕捉烹饪过程中的复杂性和并发性，使得对复杂烹饪工作流程进行精确和模块化的模型化成为可能。这种方法使用时间图实现结构化机器理解、精确解释和大规模自动化烹饪过程。", "conclusion": "这项工作为烹饪程序的自动化和机器理解奠定了基础，通过使用时间图来构建一种操作中心本体。初步的评估表明这种领域特定语言的表达性和未来自动化烹饪过程的可行性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04393", "html_url": "https://arxiv.org/abs/2509.04393", "title": "Contextualized Token Discrimination for Speech Search Query Correction", "title_en": "Contextualized Token Discrimination for Speech Search Query Correction", "authors": "Junyu Lu,Di Jiang,Mengze Hong,Victor Junqiu Wei,Qintian Guo,Zhiyang Su", "background": "现代搜索引擎中的查询拼写纠错功能能够有效帮助用户清晰表达意图。随着自动语音识别（ASR）系统的广泛应用，基于语音搜索变得越来越流行。因此，需要有效的语音查询纠错方法来改善搜索质量，增强用户体验。", "innovation": "本文提出了一种名为Contextualized Token Discrimination (CTD)的新方法。该方法首先利用BERT生成令牌级上下文化表示，然后构建一个组成层增强语义信息，最终根据聚合的令牌表示生成正确的查询，通过比较原始令牌表示和上下文化表示来修正错误的令牌。实验结果表明，该方法在所有指标上的性能优于现有方法，并提供了一个新的基准数据集，用于音频查询纠正的全面评估。", "conclusion": "本文提出了一种新的用于语音搜索查询纠正的方法——Contextualized Token Discrimination (CTD)。实验结果表明，该方法在所有评估指标上都优于其他方法，并提供了一个新的数据集用于深入评估音频查询纠正的效果。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2109.02325", "html_url": "https://arxiv.org/abs/2109.02325", "title": "MyProfessors: 开采土耳其大学生评价", "title_en": "MyProfessors: Mining Turkish Student Reviews", "authors": "Ibrahim Faruk Ceylan,Necmettin Bera Calik", "background": "目前对于土耳其语语言环境下可用的学生评审数据集相当有限。MyProfessors（Hocalarim）论文介绍了一个新的大数据集，它收集并分析了超过5000条由土耳其学生留下的教授评价，每条评价中包含了教育不同方面的评分，采用1到5星的评分标准。该研究旨在通过分析这些数据，了解学生评价的影响因素及学生的偏见如何影响其反馈。", "innovation": "MyProfessors（Hocalarim）引入了有史以来最大的针对土耳其语环境下的学生评审数据集。论文通过详细研究该数据集的特性，并探讨不同因素对学生评价和反馈偏见的影响，推动了教育评价领域的新进展和洞察。", "conclusion": "论文通过数据分析揭示了不同学生机构类型对其评分的影响，以及学生评价的偏见与正面或负面反馈之间的相关性。研究为教育评价提供了新的视角，并且丰富了对土耳其高校评价的理解。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04343", "html_url": "https://arxiv.org/abs/2509.04343", "title": "心理增强的AI代理", "title_en": "Psychologically Enhanced AI Agents", "authors": "Maciej Besta,Shriram Chandran,Robert Gerstenberger,Mathis Lindner,Marcin Chrapek,Sebastian Hermann Martschat,Taraneh Ghandi,Patrick Iff,Hubert Niewiadomski,Piotr Nyczyk,Jürgen Müller,Torsten Hoefler", "background": "本文介绍了一种通过使用心理依据的人格条件来提升大型语言模型（LLM）代理效果的框架。该框架基于迈尔斯-布里格斯类型指标（MBTI），使用提示工程为代理植入特定的人格原型，使之在认知和情感两大人类心理学核心维度上表现出不同的行为倾向。实验证明，这种人格条件可引发一致且可解释的行为偏见，展示出代理在不同任务中的表现差异，从而支持结构化多代理通信协议的实验，并揭示自我反思在交互前改善合作和推理质量的重要性。此外，还引入了16种人格测试以实现属性持久性验证。尽管重点是MBTI，该方法也证明了在其他心理框架如大五人格、HEXACO或伊涅格拉框架上的广泛适用性。", "innovation": "该研究提出了一种结合心理理论和LLM行为设计的框架，通过提示工程，为代理植入特定的人格原型。这种方法能够影响代理在认知和情感维度上的行为倾向，并展示了代理在不同任务中的表现差异。此外，该方法还支持结构化多代理通信协议的实验，并验证了自我反思在交互前对合作和推理质量的改进作用。16种人格测试的集成，确保了性格属性的持久性。此外，该方法具有广泛的适用性，不仅适用于MBTI，也适用于其他心理框架。", "conclusion": "本文提出的框架为心理增强的人工智能代理奠定了基础，无需任何微调。这种方法能够通过心理依据的人格条件改进LLM代理的效果，支持多代理通信协议的实验，并揭示自我反思在交互中的积极作用。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04404", "html_url": "https://arxiv.org/abs/2509.04404", "title": "没有思考只有AI：带有偏见的LLM推荐限制了简历筛选中的个人自主权", "title_en": "No Thoughts Just AI: Biased LLM Recommendations Limit Human Agency in Resume Screening", "authors": "Kyra Wilson,Mattea Sim,Anna-Maria Gueorguieva,Aylin Caliskan", "background": "本研究通过一项简历筛选实验（参与者数量为528人），探索了人们在与模拟AI模型（表现出基于种族的偏好）合作评估16个高地位和低地位职业的候选人时的行为。研究参考了真实世界AI系统中的种族偏见数据，并使用无意识关联测试（IAT）评估人们对种族和地位之间关系的无意识联想，这种测试在人类和AI协作中尚无相关研究记录。", "innovation": "研究创新之处在于通过简历筛选实验，考察了在无AI辅助和AI正常工作情况下人们的偏好，以及在AI表现出特定种族偏好时人们的行为变化。此外，研究引入了IAT测试，发现即使人们认为AI的建议质量低或不重要，其偏见仍可能影响决策，而完成IAT测试前进行简历筛选可以增加人们选择非典型种族地位刻板印象候选人的可能性，这些结果对人类和AI辅助决策场景的自主权、AI和工作、AI招聘系统的评估与设计，以及减轻协作决策任务中的偏见策略具有重要意义。", "conclusion": "本研究揭示了在AI辅助决策场景中，即使人们认为AI建议的质量低或不重要，AI偏见仍可能影响决策。组织和监管政策在实施这些系统时，应考虑这种复杂性，并充分教育使用这些系统的个人，以确定哪些系统需要监督。这些研究结果对理解 humans-AI协作中的偏见及其对决策的影响具有重要启示。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03644", "html_url": "https://arxiv.org/abs/2509.03644", "title": "基于形象表征的神经符号推理系统概述", "title_en": "Towards a Neurosymbolic Reasoning System Grounded in Schematic Representations", "authors": "François Olivier,Zied Bouraoui", "background": "尽管自然语言理解取得了显著进展，大型语言模型（LLMs）在进行逻辑推理时仍容易出错，往往缺乏能够支持人类级理解的稳定心智表征。研究表明，可以通过将理解与逻辑推理基于形象表征（源自感知运动经验的反复出现的模式，它们构架人类认知）来改进这一点。", "innovation": "本研究引入了一种原型神经符号系统——Embodied-LM，该系统通过将理解与逻辑推理基于形象表征，利用声明性空间推理在回答集编程中实现这些认知结构的空间基础。该系统通过逻辑推理问题评估表明，大型语言模型可以通过嵌入式认知结构来解析场景，这些结构可以被形式化为可执行的程序，并且产生的表示能够促进有效的逻辑推理，增强可解释性。", "conclusion": "当前实现注重空间基本要素，但它为整合更复杂和动态的表征奠定了计算基础。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2306.03774", "html_url": "https://arxiv.org/abs/2306.03774", "title": "探索土耳其文本可读性中的语言特征", "title_en": "Exploring Linguistic Features for Turkish Text Readability", "authors": "Ahmet Yavuz Uluslu,Gerold Schneider", "background": "本文介绍了关于土耳其文本自动可读性评估的首次全面研究。研究将最先进的神经网络模型与词汇、形态学、句法和语篇层面的语言特征相结合，开发了一种先进的可读性工具。研究对比了传统可读性公式与现代自动化方法的有效性，并确定了决定土耳其文本可读性的关键语言特征。", "innovation": "结合最先进的神经网络模型和多种语言特征（包括词汇、形态学、句法和语篇层面），开发了先进的可读性评估工具，并对比了传统方法与现代自动化方法的有效性，识别关键的语言特征以评估土耳其文本的可读性。", "conclusion": "本研究展示了针对土耳其文本的全面自动可读性评估，并通过使用先进的神经网络模型和多种语言特征，识别了关键的语言特征，认为这些特征是决定土耳其文本可读性的关键因素。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04442", "html_url": "https://arxiv.org/abs/2509.04442", "title": "Delta Activations: 一种细调大型语言模型的表示方法", "title_en": "Delta Activations: A Representation for Finetuned Large Language Models", "authors": "Zhiqiu Xu,Amish Sethi,Mayur Naik,Ser-Nam Lim", "background": "强大的开源大型语言模型（LLMs）的成功使社区能够创建大量的后训练模型，以适应特定的任务和领域。然而，导航和理解这些模型仍然存在挑战，因为缺乏一致性元数据和结构化的存储库。", "innovation": "提出了Delta Activations 方法，通过测量与基模型相比的内部激活变化，将Fine-tuned模型表示为向量嵌入，从而有效进行领域和任务分类。此外，Delta Activations 展现了稳健性和可加性等可取特性，甚至可以通过少量示例微调将任务嵌入其中，进一步探讨其在模型选择和合并中的应用。", "conclusion": "希望Delta Activations 能够促进重新使用公开可用模型的实践。代码可以在以下链接获取：this https URL。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.12736", "html_url": "https://arxiv.org/abs/2411.12736", "title": "ACING：在黑盒大语言模型中的指令学习的演员-批评家方法", "title_en": "ACING: Actor-Critic for Instruction Learning in Black-Box LLMs", "authors": "Salma Kharrat,Fares Fourati,Marco Canini", "background": "大语言模型（LLMs）解决任务的有效性很大程度上取决于其指令的质量，而高质量指令的生成往往需要大量的人工努力。因此，自动化指令优化成为必要。然而，优化指令在使用不透明的黑盒LLMs时特别具有挑战性，因为模型参数和梯度不可见，使得优化复杂。因此，需要一种方法来有效地优化黑盒LLMs中的指令，以提高模型性能并减少人工成本。", "innovation": "提出了一种演员-批评家强化学习框架——ACING，它将指令优化转化为一个无状态、连续动作问题，仅通过黑盒反馈来探索无限的指令空间。ACING能够自动发现表现优于人工撰写的提示，在76%的任务中表现出色，效果提升最高可达33分，并且在33个覆盖指令生成、摘要、链式推理任务中，超过最佳自动基线10个点的中位数改进。此外，深度的消融分析进一步展示了其鲁棒性和效率。", "conclusion": "ACING在黑盒LLMs中实现了指令优化，并展示了其在多种任务中的高效率和鲁棒性。该方法利用演员-批评家架构，展示了在不受控的LLM交互中自动优化指令的可能性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2305.06166", "html_url": "https://arxiv.org/abs/2305.06166", "title": "通过基于提示的文本变换缓解文本分类中的偏见", "title_en": "Mitigating Bias in Text Classification via Prompt-Based Text Transformation", "authors": "Charmaine Barker,Dimitar Kazakov", "background": "特定亚群的特定语言信号可能会在训练过程中变得极为显著，导致语言模型在自动化决策系统中产生偏见的结果。具体而言，如果模型依赖于与受保护特征相关联的线索，将可能导致不公平的结论。本文研究通过提示ChatGPT重写文本（使用简化、中性、本地化和形式化）是否能在减少标记信号的同时保留语义，以减轻偏见问题。实验结果表明，多种模型在位置分类准确性方面都有显著下降，说明减少了对特定群体语言的依赖。同时，情感分析和评分预测任务表明，评论的核心语义基本保持不变。这些结果表明，基于提示的重写提供了一种实用且可扩展的方法，用于缓解文本分类中的偏见问题。", "innovation": "研究提出了一种基于提示的方法，通过重写文本来减少文本分类中的偏见，具体是要求ChatGPT将文本重写为简化版、中性、本地化和正式语言。这种方法能够有效减少依赖于特定群体语言信号的情况，同时保持文本的主要语义不变。", "conclusion": "基于提示的文本重写方法能够显著减少文本分类中的偏见，同时保持文本的核心意义。这种基于提示的方法为缓解文本分类中偏见提供了一种实用和可推广的解决方案。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04438", "html_url": "https://arxiv.org/abs/2509.04438", "title": "电话游戏：评估统一体模式中的语义漂移", "title_en": "The Telephone Game: Evaluating Semantic Drift in Unified Models", "authors": "Sabbir Mollah,Rohit Gupta,Sirnam Swetha,Qingyang Liu,Ahnaf Munir,Mubarak Shah", "background": "单一统一模型（UM）被同时应用于视觉理解（图像到文本：I2T）和视觉生成（文本到图像：T2I），为视觉语言模型（VLM）研究开辟了新的方向。虽然UM可以支持更广泛的单模态任务，例如文本到文本、图像到图像，但该论文专注于跨模态的核心配对I2T和T2I，强调一致性的关键性。现有的评估方法将这些能力孤立地考虑：如FID和GenEval针对T2I，基准MME和MMBench针对I2T。这些单向度的度量标准并不能反映出能否理解的概念也能够被呈现，或在图像和文本之间循环时意义是否被保持。为了应对这一问题，作者引入了统一一致性框架（UCF-UM），一个循环评估协议，通过交替进行I2T和T2I多个世代以量化语义漂移。", "innovation": "提出了统一一致性框架（UCF-UM），该框架引入了三种度量标准：（ⅰ）平均累计漂移（MCD），基于嵌入的整体语义损失的度量；（ⅱ）语义漂移率（SDR），语义消退率的总结；（ⅲ）多世代生成评估（MGG），一个对象级合规度评分，扩展了GenEval。此外，评估了通用性，创建了新的基准数据集ND400，样本来自NoCaps和DOCCI，并在七种最近的模型上进行评估，揭示了跨模态稳定性的显著差异：某些模型如BAGEL在多次交替后仍保持语义，而其他模型如Vila-u即便在单向度评估中得分高，但也快速漂移。新的评估方法被视为对标准I2T和T2I评估的强大补充，并提供了统一模型跨模态稳定性及共享表示强度的实用度量方法。", "conclusion": "科研成果强调了循环一致性的重要性，作为标准I2T和T2I评估的必要补充，并为统一模型的跨模态稳定性和共享表示强度提供了一致性评估的实用度量方法。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.01359", "html_url": "https://arxiv.org/abs/2406.01359", "title": "R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models", "title_en": "R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models", "authors": "Ken Deng,Jiaheng Liu,He Zhu,Congnan Liu,Jingxin Li,Jiakai Wang,Peng Zhao,Chenchen Zhang,Yanan Wu,Xueqiao Yin,Yuanxing Zhang,Zizheng Zhan,Wenbo Su,Bangyu Xiang,Tiezheng Ge,Bo Zheng", "background": "近年来代码补全模型取得了显著进展。近年来，面向仓库级别的代码补全问题在现代软件开发中越来越受到关注，也提出了多个基线方法和基准。但是，现有的面向仓库级别的代码补全方法往往未能充分利用项目仓库中的广泛上下文，例如相关的文件和类层次结构的复杂性。另外，现有的基准通常仅聚焦于有限的代码补全场景，无法充分反映现有方法在仓库级别代码补全方面的表现。", "innovation": "本文提出了R2C2-Coder，旨在增强和测评代码大型语言模型的现实仓库级别代码补全能力。R2C2-Coder包括代码提示构造方法R2C2-Enhance和一个精心设计的基准R2C2-Bench。具体来说，首先在R2C2-Enhance中构建候选检索池，并为每个补全光标位置从检索池中检索构建完成提示。然后基于R2C2-Enhance构建更具挑战性和多样性的R2C2-Bench，并提出上下文扰动策略以更好地模拟现实的仓库级别代码补全。", "conclusion": "在多个基准上的广泛实验结果证实了我们提出的R2C2-Coder的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.04316", "html_url": "https://arxiv.org/abs/2501.04316", "title": "小变化，大影响：分析生成性语言模型在招聘过程中的配置公平性", "title_en": "Small Changes, Large Consequences: Analyzing the Allocational Fairness of LLMs in Hiring Contexts", "authors": "Preethi Seshadri,Hongyu Chen,Sameer Singh,Seraphina Goldfarb-Tarrant", "background": "大型语言模型（LLMs）在高风险应用场景，例如招聘中被越来越多地部署，然而它们在生成和检索场景下潜在的不公平决策问题仍然没有得到充分研究。本文通过两个反映实际招聘流程的任务——简历总结和求职者排名，探讨基于语言模型的招聘系统在配置公平性方面的表现。研究构建了一个经过控制的扰动简历数据集，并选择了合适的职位描述，旨在调查模型行为在不同群体中的差异性，从而揭示模型在招聘信息获取和排名中的潜在偏见及影响范围。", "innovation": "本文通过构建带控制扰动的合成简历数据集及精心挑选的职位描述，具体研究了实际招聘流程中的配置公平性问题；发现生成的摘要更多地在种族方面显示出显著差异，而在性别方面则不显著；同时模型在求职者排名中表现出非均匀的检索选择模式，对性别和种族的敏感性高；尤其是在信息检索阶段，模型的公平性问题可能源于更广泛的模型脆弱性，这为生成性和检索性语言模型在招聘中的应用提供了新的视角和挑战。", "conclusion": "总体而言，语言模型驱动的招聘系统，尤其是在信息检索阶段，可能存在显著偏差，可能导致实际应用场景中的歧视性结果。研究结果表明，偏见问题可能源于更广泛的设计和实现层面，强调了在使用此类模型进行人员招聘过程中需要考虑更多公平性考量的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.13958", "html_url": "https://arxiv.org/abs/2501.13958", "title": "Graph Retrieval-Augmented Generation for Customized Large Language Models", "title_en": "A Survey of Graph Retrieval-Augmented Generation for Customized Large Language Models", "authors": "Qinggang Zhang,Shengyuan Chen,Yuanchen Bei,Zheng Yuan,Huachi Zhou,Zijin Hong,Hao Chen,Yilin Xiao,Chuang Zhou,Yi Chang,Xiao Huang", "background": "大型语言模型（LLMs）在广泛任务中展示了出色的能力，但在专业领域的应用仍然具有挑战性，因为需要深厚的专业知识。传统的检索增强生成（RAG）系统基于扁平文本检索，面临三个关键挑战：（i）在专业语境下的复杂查询理解，（ii）跨分布式来源的知识整合困难，（iii）大规模下的系统效率瓶颈。", "innovation": "GraphRAG通过三个核心创新解决了传统的RAG限制：（i）基于图形的知识表示明确捕捉实体关系和领域层次结构，（ii）高效的基于图形的检索技术，能够进行上下文保持的知识检索和多跳推理，（iii）结构感知的知识整合算法，利用检索的知识生成LLM的准确且逻辑一致的内容。", "conclusion": "本文系统分析了GraphRAG的技术基础，并在各个专业领域考察了当前的实现情况，指出了关键技术挑战和有前景的研究方向。有关GraphRAG的所有相关资源，包括研究论文、开源数据和项目，都已收集于此链接：this https.URL"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04419", "html_url": "https://arxiv.org/abs/2509.04419", "title": "迈向大规模语言模型后训练的统一视角", "title_en": "Towards a Unified View of Large Language Model Post-Training", "authors": "Xingtai Lv,Yuxin Zuo,Youbang Sun,Hongyi Liu,Yuntian Wei,Zhekai Chen,Lixuan He,Xuekai Zhu,Kaiyan Zhang,Bingning Wang,Ning Ding,Bowen Zhou", "background": "大规模语言模型的训练数据主要来自在线（模型生成的演示数据）和离线（人类或模型演示数据）两种来源。不同的方法，如强化学习（RL）和监督微调（SFT），通常分别使用这两种数据。然而，这项研究探讨了这些方法并不是互相矛盾的，而是统一优化过程的不同实例。", "innovation": "该研究提出了统一策略梯度估计器，并将其应用于广泛范围的后训练方法，针对不同的数据分布假设和各种偏差-方差权衡。此外，基于理论研究，研究者提出了Hybrid Post-Training（HPT）算法，该算法根据不同的训练信号动态调整，既能有效利用演示信息，又能保证探索的稳定性，同时不会牺牲已学习到的推理模式。", "conclusion": "HPT算法在六项数学推理基准和两个离分布测试集上都取得了显著成果，无论模型规模或家族类型如何，其表现都优于强大的基准模型。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.01747", "html_url": "https://arxiv.org/abs/2411.01747", "title": "DynaSaur：超越预定义动作的大语言代理", "title_en": "DynaSaur: Large Language Agents Beyond Predefined Actions", "authors": "Dang Nguyen,Viet Dac Lai,Seunghyun Yoon,Ryan A. Rossi,Handong Zhao,Ruiyi Zhang,Puneet Mathur,Nedim Lipka,Yu Wang,Trung Bui,Franck Dernoncourt,Tianyi Zhou", "background": "现有的大语言模型（LLM）代理系统在每一步通常从一个固定且预先定义的动作集选择动作。虽然这种方法在封闭的、狭窄范围的环境中是有效的，但在现实世界中的开放性场景中却存在两个主要挑战：（1）它显著限制了LLM代理的规划和执行能力，（2）它要求人类投入大量努力列出并实现所有可能的动作，这在具有大量潜在动作复杂环境是不切实际的。", "innovation": "本文提出了一种LLM代理框架，能够动态地创建和组合所需的动作。在这种框架中，代理通过生成和执行使用通用编程语言书写的程序来与环境交互。生成的动作会随时间积累，以便未来的重复使用。广泛的实验证明，该框架显著提高了灵活性，并优于依赖固定动作集的先前方法。此外，它还允许LLM代理在预定义动作不足或因不可预见的边缘情况而失败的情况下进行适应和恢复。", "conclusion": "本文通过提出的框架展示了，在复杂环境中，LLM代理能够超越预定义动作的限制，增强其适应性和恢复能力。实验结果表明，该方法在多个基准测试中优于依赖固定动作集的方法。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.11110", "html_url": "https://arxiv.org/abs/2501.11110", "title": "Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective", "title_en": "Chain-of-Reasoning: Towards Unified Mathematical Reasoning in Large Language Models via a Multi-Paradigm Perspective", "authors": "Yiyao Yu,Yuxiang Zhang,Dongdong Zhang,Xiao Liang,Hengyuan Zhang,Xingxing Zhang,Ziyi Yang,Mahmoud Khademi,Hany Awadalla,Junjie Wang,Yujiu Yang,Furu Wei", "background": "大规模语言模型（LLMs）在数学推理方面取得了显著进展，但通常依赖单一推理范式，这限制了它们在多样任务中的效果。当前的LLMs使用单一的推理模式进行问题解决，缺乏结合多种推理范式的灵活性，导致在处理复杂或多样化的数学问题时表现不佳。", "innovation": "该研究引入了Chain-of-Reasoning（CoR）框架，这是一种统一的框架，将自然语言推理（NLR）、算法推理（AR）和符号推理（SR）等多种推理范式结合起来，以促进这些范式的协同作用。CoR模型通过不同推理方案生成多个潜在答案，然后将它们综合成一个连贯的最终解决方案。此外，研究提出了一种渐进的多元范式训练策略（PPT），使模型能够逐步掌握这些范式，从而构建了CoR-Math-7B模型。实验结果表明，CoR-Math-7B在定理证明和算术任务中超越了当前的SOTA模型，特别是在MATH基准测试中，它在算术任务上的表现优于GPT-4o达41.0%，优于基于强化学习的方法达15.0%。这些结果表明，CoR模型增强的数学理解能力使其能够在不同的任务中实现零样本泛化能力。", "conclusion": "研究展示了CoR模型在数学推理任务上的优越表现，强调了CoR框架能够有效地整合多种推理范式的潜力，推动了大规模语言模型在数学推理领域的发展。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.12065", "html_url": "https://arxiv.org/abs/2502.12065", "title": "原始世界中的Autoformalization：评估LLMs在真实世界数学定义上的表现", "title_en": "Autoformalization in the Wild: Assessing LLMs on Real-World Mathematical Definitions", "authors": "Lan Zhang,Marco Valentino,Andre Freitas", "background": "通过其语言能力，大型语言模型（LLMs）为通过自动形式化弭合非形式数学与正式语言之间的差距提供了机会。然而，LLMs能否很好地将 sophisticated 和自然出现的数学陈述泛化依然是个未知数。本文旨在填补这一空白，通过研究将现实世界的数学定义进行自动形式化的任务。为此，引入了两个新的自动形式化资源：从Wikipedia收集定义（Def_Wiki）和从arXiv论文收集定义（Def_ArXiv）。进行了系统性评估，分析了不同LLMs将定义转化为Isabelle/HOL的形式化能力。同时，研究了增强LLMs性能的策略，包括来源于证明助手的外部反馈的细化以及形式定义接地，即通过相关形式数学库中的上下文元素增强LLMs的形式化。", "innovation": "1. 引入了两个新的资源（Def_Wiki和Def_ArXiv）用于收集真实的数学定义。2. 对不同LLMs的形式化能力进行了系统性评估，分析了它们将定义转化为Isabelle/HOL的能力。3. 提出并通过实验验证了两种增强LLMs性能的策略：通过外部反馈的外部细化和形式定义接地。", "conclusion": "数学定义的自动形式化比现有的基准测试（如miniF2F）更具挑战性。研究发现LLMs仍然在自我修正和与相关数学库对齐方面存在问题。然而，有结构的细化方法和形式定义接地策略在自我纠正能力和降低未定义错误方面分别提高了16%和43%，这些结果为增强基于LLM的自动形式化在实际应用场景中提供了可行的方向。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04439", "html_url": "https://arxiv.org/abs/2509.04439", "title": "ArcMemo：终身LLM记忆中的抽象推理组合", "title_en": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory", "authors": "Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin", "background": "推理时的缩放使大语言模型（LLM）能够进行越来越长和复杂的推理过程，但在每次新的查询中，推理过程中得出的模式和见解会被立即丢弃。外部记忆可以持久保存这些发现，且最近的研究表明，对于推理密集型任务具有明显的益处。通过从推理痕迹中提炼概念级的记忆，并将其存储在自然语言中，可以提高这种记忆的可重用性和可扩展性。", "innovation": "该研究提出了一种新的策略，从推理痕迹中抽取出概念级的知识，并将其存储在自然语言中。这种方法能够在不更新权重的情况下，通过从旧记忆中检索相关概念并将其整合到新查询提示中，实现测试时的持续学习。这种方法还在挑战性的ARC-AGI基准测试中取得了显著效果，相对强的无记忆基线提高了7.5%，且随着推理计算量的增加，性能持续提升。此外，研究表明，在测试时动态更新记忆可以优于固定记忆场景，进一步证明了自我提升的能力。", "conclusion": "通过ArcMemo方法，概念级的记忆设计表现出最佳的一致性，特别是在所有测试的推理计算量上都超过了基准。此外，动态更新的记忆在测试时的表现优于固定记忆设置，进一步支持了解决更多问题和将更多模式存储到记忆中可以进一步解决问题的假设，这可能是自我改进的一种形式。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.14701", "html_url": "https://arxiv.org/abs/2501.14701", "title": "一个无监督自然语言处理流水线评估转诊适宜性", "title_en": "An Unsupervised Natural Language Processing Pipeline for Assessing Referral Appropriateness", "authors": "Vittorio Torri,Annamaria Bottelli,Michele Ercolanoni,Olivia Leoni,Francesca Ieva", "background": "评估诊断转诊的适当性对于提高医疗服务效率和减少不必要的医疗程序至关重要。然而，当转诊原因仅记录为自由文本而不是结构化代码时，这项任务变得极具挑战性，特别是在意大利国家卫生服务机构中。本研究旨在解决这一空白，提出了一种完全无监督的自然语言处理（NLP）流水线，能够提取和评估转诊原因，而无需依赖标记数据集。", "innovation": "该研究开发了一种无监督的NLP流水线，该流水线利用预训练的意大利医疗文本Transformer嵌入来聚类转诊原因，并评估其与适当性准则的一致性。该方法用于不同检查类型的大规模真实世界数据集，展示了该流水线在大规模应用中的鲁棒性和可扩展性。这项工作为评估大量自由文本记录的转诊适当性提供了一种新的方法和工具。", "conclusion": "这项研究展示了在大规模真实世界数据集上评估转诊适当性的强大且可扩展的无监督NLP流水线。它证明了这些数据的有效利用，为公共卫生当局提供了可部署的AI工具，以监测实践并支持基于证据的政策。此外，发现的转诊不适当组和不同上下文之间的变异指导了拉莫纳第地区的新决议，以加强指南的遵守。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.05982", "html_url": "https://arxiv.org/abs/2502.05982", "title": "HamRaz: 一种基于文化背景的波斯语对话数据集，用于使用LLM代理的人本中心疗法", "title_en": "HamRaz: A Culture-Based Persian Conversation Dataset for Person-Centered Therapy Using LLM Agents", "authors": "Mohammad Amin Abbasi,Farnaz Sadat Mirnezami,Ali Neshati,Hassan Naderi", "background": "现有的人工智能辅助心理健康支持系统主要集中在英语等广泛使用的语言上，对于非英语语言地区的支持不足。本文旨在填补这一空白，特别是在波斯语社区中，通过创建一个根据人本中心疗法（PCT）进行文化的适应，以反映真实世界治疗挑战为目标的波斯语语言数据集HamRaz。", "innovation": "HamRaz数据集结合剧本对话和适应性大型语言模型（LLM）角色扮演，捕捉到了波斯语说者的语言中的模糊性和情感细微差别。同时引入了HamRazEval，这是一种评估对话质量和心理治疗质量的双重框架，包括通用指标和专门的心理关系测量。研究表明，HamRaz在情感共鸣、连贯性和现实性方面表现出色，优于现有基准。", "conclusion": "HamRaz数据集不仅促进了数字人文领域的发展，还将语言、文化和精神健康等领域结合在一起，特别为被忽视的社区提供了支持，丰富了人工智能辅助心理健康支持的资源库。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.16561", "html_url": "https://arxiv.org/abs/2503.16561", "title": "未来生成：基于RAG的方法生成科学文章的未来工作", "title_en": "FutureGen: A RAG-based Approach to Generate the Future Work of Scientific Article", "authors": "Ibrahim Al Azher,Miftahul Jannat Mokarrama,Zhishuai Guo,Sagnik Ray Choudhury,Hamed Alhoori", "background": "论文的未来工作部分概述了当前研究的潜在研究方向，通过识别现有研究的局限性和空白来实现。这部分对早期职业研究人员寻找未探索的领域，以及经验研究人员寻找新的研究项目或合作项目提供了宝贵的资源。为了丰富未来工作的生成过程并减少遗漏重要研究方向的风险，该研究采用检索增强生成（RAG）技术结合相关论文的上下文。实验了多种大型语言模型（LLMs）与RAG结合的方法，并引入了LLM反馈机制以提高生成内容的质量，以及一个LLM作为评估者的框架来综合评估新颖性、幻觉和可行性。", "innovation": "1. 采用基于RAG的方法，结合相关论文的上下文来生成未来工作内容，提供更广泛的洞察力，减少遗漏重要研究方向的风险。\n2. 结合多种大型语言模型（LLMs）进行实验，证明了基于GPT-4o mini的RAG方法结合LLM反馈机制在定性和定量评价中均表现出色。\n3. 引入LLM作为评估者框架，评估关键方面如新颖性、幻觉和可行性，确保未来工作生成的高质量。", "conclusion": "研究结果表明，采用基于GPT-4o mini的RAG方法结合LLM反馈机制，不仅在定性方面，也在定量方面均优于其他基于LLM的方法。此外，通过人工评估验证了该方法在提取、生成和反馈等方面的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11948", "html_url": "https://arxiv.org/abs/2502.11948", "title": "HalluEntity: 评估和理解实体级幻觉检测基准", "title_en": "HalluEntity: Benchmarking and Understanding Entity-Level Hallucination Detection", "authors": "Min-Hsuan Yeh,Max Kamachee,Seongheon Park,Yixuan Li", "background": "许多研究通过不确定性估计来检测LLM中的幻觉生成，但这些方法主要在句子或段落级别进行操作，无法标示出具体负责幻觉内容的实体或跨度。这对于混合准确和伪造信息的长篇内容尤为重要。为解决这一局限，该研究探索了实体级别的幻觉检测，并提出了一个新的数据集HalluEntity，该数据集在实体级别标注幻觉。基于此数据集，该研究全面评估了针对17个现代LLM的基于不确定性估计的幻觉检测方法。实验结果表明，关注单个令牌概率的不确定性估计方法往往高估了幻觉，而注意上下文的方法则表现更好但仍然不理想。通过深入的定性研究，该研究发现了幻觉倾向与语言属性之间的关系，并指出了未来研究的重要方向。", "innovation": "提出了一种新的数据集HalluEntity，在实体级别标注幻觉，填补了当前幻觉检测方法在长篇内容中的不足；提出了对17个现代LLM的基于不确定性估计的幻觉检测方法的全面评估，并发现了幻觉倾向与语言属性之间的关系，为未来研究提供了重要指导。", "conclusion": "不确定性估计方法在单个令牌层面往往高估了幻觉，而考虑上下文的方法表现更好但仍然不理想。通过HalluEntity数据集的使用和深入的定性研究，研究为幻觉检测中的实体级别检测提供了新的视角和启示，指出了未来研究的重要方向。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.14791", "html_url": "https://arxiv.org/abs/2502.14791", "title": "基于元上下文学习的快速单词学习", "title_en": "Rapid Word Learning Through Meta In-Context Learning", "authors": "Wentao Wang,Guangyuan Jiang,Tal Linzen,Brenden M. Lake", "background": "人类能够从少数插图示例中快速学习新的单词，并在新的上下文中系统地和灵活地使用它们。然而，当前语言模型在少量样本下学习新单词的能力以及提高这些能力的方法尚未得到充分探索。", "innovation": "本文提出了一种新型方法——元训练以上下文学习为目标的单词学习（Minnow）。该方法通过用特殊占位符标记新单词，训练语言模型根据少量上下文示例生成新单词的使用案例。研究发现，使用Minnow从零开始对大规模儿童对话语言进行训练，能够实现与大量数据预训练的语言模型相媲美的少量样本单词学习能力。此外，通过分类和生成评估，研究还表明使用Minnow进行微调前的语言模型能够更好地区分新单词、识别新单词的句法类别，并基于一个或几个上下文示例生成合理的新使用案例和定义。", "conclusion": "这些发现突显了Minnow的高效数据利用能力及其在提升语言模型在单词学习任务中的性能方面的潜力。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.09454", "html_url": "https://arxiv.org/abs/2503.09454", "title": "显式学习与LLM在机器翻译中的应用", "title_en": "Explicit Learning and the LLM in Machine Translation", "authors": "Malik Marmonier,Rachel Bawden,Benoît Sagot", "background": "本研究探索了语言模型（LLM）在使用语法书中的解释学习新语言的能力，这一过程称为‘显式学习’。为测试这种能力，研究设计了严格控制的英译目标语言实验，目标语言是通过特定的加密手段从拉丁语或法语中生成的构建语言。不同于以往研究，发现LLM确实具备可衡量的显式学习能力。然而，随着需学习的语言现象复杂性的增加，这种能力会逐渐减弱。通过对具体推理链的监督微调可以显著提高LLM的性能，但难以泛化到类型新颖或更复杂的语言特征。", "innovation": "研究设计了控制良好的翻译实验，通过特定的加密方法创建语言，以严格评估LLM进行显式学习的能力。研究结果表明，监督微调在增强LLM性能方面表现出色，但在泛化到类型新颖或更复杂的语言特征方面存在困难。这表明需要更多样化的训练集和替代微调策略，以进一步提高LLM的显式学习能力。", "conclusion": "研究指出，需要更多样化的训练集和替代微调策略来进一步改进LLM的显式学习能力，这将有利于那些通常在语法书中描述但缺乏广泛语料库的资源匮乏语言。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.12616", "html_url": "https://arxiv.org/abs/2502.12616", "title": "通过准符号抽象提高链式思考推理", "title_en": "Improving Chain-of-Thought Reasoning via Quasi-Symbolic Abstractions", "authors": "Leonardo Ranaldi,Marco Valentino,Andrè Freitas", "background": "链式思考（CoT）是大型语言模型（LLMs）中常见的推理策略，通过将复杂任务分解为中间推理步骤来实现。然而，CoT生成的解释容易受到内容偏见的影响，这会对其稳健性和真实性产生负面影响。为了缓解现有限制，最近的工作提出了结合外部符号求解器的逻辑形式化方法。然而，完全符号化方法存在瓶颈，需要将自然语言完全翻译成形式语言，这一过程影响效率和灵活性。因此，该领域需要找到一种在实现效率和灵活性之间取得平衡的方法。", "innovation": "该论文研究了在不需要完全形式化的情况下分离内容和逻辑推理的方法。提出了QuaSAR（准符号抽象推理），这是一种CoT的变体，通过准符号解释引导LLMs在更高的抽象级别上运行。该框架利用了LLMs仅对相关变量和谓词进行形式化的能力，使得符号元素和自然语言可以共存。研究表明，准符号抽象可以提高基于CoT的方法的准确率，特别是在自然语言（如MMLU-Redux）和符号推理（如GSM-Symbolic）任务中增强稳健性和一致性上效果显著，提高了多达8%的准确率。", "conclusion": "该研究展示了准符号抽象在上下文学习中的影响，并通过构建示例提高较小模型的推理能力。实验结果表明，准符号抽象可以提高基于CoT的方法的准确率，增强在挑战性的对抗变体（无论是自然语言还是符号推理任务）中的稳健性和一致性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14585", "html_url": "https://arxiv.org/abs/2505.14585", "title": "Context Reasoner: 通过强化学习激励情境化的隐私和安全合规推理能力", "title_en": "Context Reasoner: Incentivizing Reasoning Capability for Contextualized Privacy and Safety Compliance via Reinforcement Learning", "authors": "Wenbin Hu,Haoran Li,Huihao Jing,Qi Hu,Ziqian Zeng,Sirui Han,Heli Xu,Tianshu Chu,Peizhao Hu,Yangqiu Song", "background": "虽然大型语言模型（LLMs）表现出色，但也带来了显著的安全和隐私风险。现有的消减策略往往无法在风险情境中保留上下文推理能力，而是依赖敏感模式匹配来保护LLMs，限制了他们的应用范围。此外，这些方法忽视了既定的安全和隐私标准，从而引起了系统性法律合规风险。相关背景问题在于，当前的处理方法未充分利用监管标准来提升LLMs在合规性方面的表现。", "innovation": "本研究通过将安全和隐私问题转化为情境化的合规问题，利用情境完整性（CI）理论，与GDPR、欧盟AI法案和HIPAA三个重要监管标准保持一致。具体采用强化学习（RL）结合基于规则的奖励，以激发情境推理能力，同时增强合规性。研究结果显示，该方法在安全性/隐私性基准测试中提高了8.58%的准确率，并进一步提升了通用推理能力。对于一个强大推理能力的模型OpenThinker-7B，在MMLU和LegalBench基准测试中，其整体推理能力分别提高了2.05%和8.98%。", "conclusion": "本研究提出的方法不仅显著提升了法律合规性（安全/隐私基准测试准确率提高了8.58%）而且还进一步增强了整体推理能力。通过将安全和隐私问题转化为情境化的合规问题，在监管框架下利用强化学习来促进情境推理能力，这为解决现有方法的局限性提供了一种有效的解决方案。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.18452", "html_url": "https://arxiv.org/abs/2502.18452", "title": "FRIDA 到救援！分析基于对象的常识推理中合成数据有效性", "title_en": "FRIDA to the Rescue! Analyzing Synthetic Data Effectiveness in Object-Based Common Sense Reasoning for Disaster Response", "authors": "Mollie Shichman,Claire Bonial,Austin Blodgett,Taylor Hudson,Francis Ferraro,Rachel Rudinger", "background": "在灾害救援场景中的机器人辅助任务中，大型语言模型（LLMs）具备进行物理推断的能力，这有助于实现任务目标。然而，目前这些能力主要存在于较大规模的模型中，由于空间限制，难以部署在机器人系统上。因此，为了满足特定的需求，本文提出了一种数据集和处理管道，以创建一个名为FRIDA的模型，该模型可以在机器人系统上使用少量数据来培育物理常识能力。", "innovation": "本文引入了一个名为FRIDA的模型以及相关的处理管道，通过结合领域专家和语言学家的知识，生成高质量的少样本提示，用于生成合成数据以进行模型微调。同时，通过对比实验发现仅使用物体物理状态和功能数据训练的FRIDA模型，在评估中表现优于使用完整合成数据训练的FRIDA模型和基础模型。", "conclusion": "FRIDA管道能够通过少量数据培养出物理常识，提升了小型指令调优模型在灾害响应任务中的表现。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22141", "html_url": "https://arxiv.org/abs/2506.22141", "title": "DAPFAM: 域感知的家族级别数据集以评估跨领域专利检索", "title_en": "DAPFAM: A Domain-Aware Family-level Dataset to benchmark cross domain patent retrieval", "authors": "Iliass Ayaou(ICube),Denis Cavallucci(ICube),Hicham Chibane(ICube)", "background": "专利 prior-art retrieval 在技术边界跨域时特别具有挑战性。现有的基准数据缺乏明确的领域划分，使得评估检索系统如何应对这种转变变得困难。因此，需要一种包含明确 IN-domain 和 OUT-domain 分割的数据集来评估检索系统的性能。", "innovation": "引入 DAPFAM，这是一种基于 IPC3 重叠方案明确定义 IN-domain 和 OUT-domain 分割的家族级别的基准数据集。该数据集包含 1,247 个查询家族和 45,336 个目标家族，并且通过家族级别聚合来降低国际冗余性，使用引文相关性判断。进行了 249 项受控实验，涵盖了从词项（BM25）到密集（变换器）后端，从文档和段落级检索到多种查询和文档表示，再到聚合策略和混合融合。结果表明，跨域检索存在明显的鸿沟，OUT-domain 表现始终低于 IN-domain，而段落级检索优于文档级检索，但持久性的 OUT-domain 鸿沟难以弥合。文档级融合方法在效率和效果之间提供了权衡。", "conclusion": "通过明确展示跨域检索的持续挑战，DAPFAM 提供了一个可重复且计算意识强的测试床，用于开发更稳健的专利 IR 系统。数据集已公开发布在 huggingface 平台上。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.14723", "html_url": "https://arxiv.org/abs/2508.14723", "title": "移植再生：一种新的文本数据增强范式", "title_en": "Transplant Then Regenerate: A New Paradigm for Text Data Augmentation", "authors": "Guangzhan Wang,Hongyu Zhang,Beijun Shen,Xiaodong Gu", "background": "数据增强是深度学习中的关键技术。传统方法如回译通常关注词汇层面的重写，主要产生具有相同语义的变体。虽然大型语言模型（LLMs）通过其‘知识涌现’能力增强了文本增强的效果，但控制这些输出的风格和结构仍然极具挑战性，并需要精确的提示工程。", "innovation": "本文提出了一种名为LMTransplant的新的文本增强范式，其核心思想是移植-再生：将种子文本整合到由LLM扩展的上下文中，并要求LLM基于扩展的上下文生成一个变体。这种方法允许模型通过充分利用嵌入在LLMs中的知识来创建更多样化和创造性的内容级别的变体，同时保留原始文本的核心属性。", "conclusion": "我们对LMTransplant在各种文本相关的任务中进行了评估，展示了其在现有文本增强方法中优于的表现。此外，LMTransplant随着增强数据规模的增加，表现出卓越的可扩展性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19740", "html_url": "https://arxiv.org/abs/2508.19740", "title": "Spotlight Attention: 通过非线性哈希检索关键值缓存实现高效的大语言模型生成", "title_en": "Spotlight Attention: Towards Efficient LLM Generation via Non-linear Hashing-based KV Cache Retrieval", "authors": "Wenhao Li,Yuxin Zhang,Gen Luo,Haiyuan Wan,Ziyang Gong,Fei Chao,Rongrong Ji", "background": "在大型语言模型（LLMs）中，减少键值（KV）缓存负担可以显著加速推理。现有的方法使用随机线性哈希来识别重要token，但由于查询和键在LLMs中的分布较为狭窄和正交，这种方法效率低下。因此，有必要提出一种新的方法来优化缓存选择。", "innovation": "本文提出了一种称为Spotlight Attention的新型方法，它使用非线性哈希函数优化查询和键的嵌入分布，以提高编码效率和鲁棒性。同时开发了一个轻量级、稳定的训练框架，使用布拉德利-伯瑞特排名损失函数，在具有16GB内存的GPU上8小时内优化非线性哈希模块。实验结果显示，与传统的线性哈希相比，Spotlight Attention显著提高了检索精度，同时缩短了哈希代码长度至少5倍。", "conclusion": "通过专门的CUDA内核实现位操作计算的优势，Spotlight Attention在单个A100 GPU上实现了512K token的哈希检索，耗时不到100微秒，端到端吞吐量比常规解码提高3倍。最终，证明了非线性哈希方法在大语言模型生成中的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20324", "html_url": "https://arxiv.org/abs/2508.20324", "title": "紧凑型语言模型能否像代理那样搜索？基于蒸馏的策略优化以保留代理性RAG能力", "title_en": "Can Compact Language Models Search Like Agents? Distillation-Guided Policy Optimization for Preserving Agentic RAG Capabilities", "authors": "Rikuto Kotoge,Mai Nishimura,Jiaxin Ma", "background": "强化学习作为一种后训练方法，被用于激发语言模型执行代理性检索和规划（RAG）行为。然而，紧凑型语言模型（例如参数量为0.5B规模的模型）由于推理能力薄弱，在奖励稀疏且训练不稳定的情况下难以完成这些任务。", "innovation": "提出了基于蒸馏的策略优化方法（DGPO），该方法通过教师示范的冷启动初始化以及策略优化过程中的持续教师指导来解决上述困难。在此基础上，引入了细粒度的代理性RAG能力评估指标（ARC），该指标分析推理、搜索协调和响应合成的能力。", "conclusion": "实验证明，DGPO能够使紧凑型模型实现复杂的代理性搜索行为，甚至在某些情况下超过更大的教师模型。这种方法使得在计算资源受限的环境中实现代理性RAG成为可能。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09556", "html_url": "https://arxiv.org/abs/2506.09556", "title": "MEDUSA：自然场景中语音情感识别的多模态深层融合多阶段训练框架", "title_en": "MEDUSA: A Multimodal Deep Fusion Multi-Stage Training Framework for Speech Emotion Recognition in Naturalistic Conditions", "authors": "Georgios Chatzichristodoulou,Despoina Kosmopoulou,Antonios Kritikos,Anastasia Poulopoulou,Efthymios Georgiou,Athanasios Katsamanis,Vassilis Katsouros,Alexandros Potamianos", "background": "SER是一个具有挑战性的任务，由于人类情感的主观性质及其在自然条件下不均匀的表现。在自然条件下，语音情感识别面临着类不平衡和情感含义模糊的问题。现有技术难以有效处理这些挑战性问题，尤其是在没有高度控制的条件下进行情感识别时，难以保证结果的一致性和准确性。", "innovation": "我们提出了MEDUSA，这是一种多模态框架，具有四阶段训练管道，能够有效处理类不平衡和情感含义模糊的问题。第一、第二阶段训练了一组利用预训练自监督声学和语言表示的深度交叉模态变压器融合机制的分类器。Manifold MixUp进一步用于正则化。最后两个阶段优化了一个可训练的元分类器，该分类器结合了组预测。这种训练方法结合了人类注释评分作为软目标，并结合了平衡的数据采样和多任务学习。这种方法突出了多阶段训练框架的优势，特别是通过利用预训练模型和正则化方法来提高性能。", "conclusion": "MEDUSA在Interspeech 2025：自然条件下语音情感识别挑战赛的任务1中排名第一，表明其在处理自然场景下的情感识别任务具有优势。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.07900", "html_url": "https://arxiv.org/abs/2506.07900", "title": "MiniCPM4：边缘设备上超高效的LLM", "title_en": "MiniCPM4: Ultra-Efficient LLMs on End Devices", "authors": "MiniCPM Team:Chaojun Xiao,Yuxuan Li,Xu Han,Yuzhuo Bai,Jie Cai,Haotian Chen,Wentong Chen,Xin Cong,Ganqu Cui,Ning Ding,Shengda Fan,Yewei Fang,Zixuan Fu,Wenyu Guan,Yitong Guan,Junshao Guo,Yufeng Han,Bingxiang He,Yuxiang Huang,Baoxi Ji,Cunliang Kong,Qiuzuo Li,Siyuan Li,Wenhao Li,Xin Li,Yanghao Li,Yishan Li,Zhen Li,Dan Liu,Biyuan Lin,Yankai Lin,Xiang Long,Quanyu Lu,Yaxi Lu,Peiyan Luo,Hongya Lyu,Litu Ou,Yinxu Pan,Lushi Pu,Zekai Qu,Qundong Shi,Zijun Song,Jiayuan Su,Zhou Su,Ao Sun,Xianghui Sun,Peijun Tang,Fangzheng Wang,Feng Wang,Shuo Wang,Yudong Wang,Zheng Wang,Yesai Wu,Zhenyu Xiao,Jie Xie,Zihao Xie,Xiaoyue Xu,Yukun Yan,Jiarui Yuan,Jinqian Zhang,Kaihuo Zhang,Lei Zhang,Linyue Zhang,Xueren Zhang,Yudi Zhang,Hengyu Zhao,Weilin Zhao,Weilun Zhao,Yuanqian Zhao,Zhi Zheng,Chuyue Zhou,Ge Zhou,Jie Zhou,Wei Zhou,Yanghao Zhou,Zihan Zhou,Zixuan Zhou,Zhiyuan Liu,Guoyang Zeng,Chao Jia,Dahai Li,Maosong Sun", "background": "近年来，大型语言模型（LLM）在多个自然语言处理任务中的表现引起了广泛关注。然而，这些模型通常需要大量的计算资源和大量的训练数据，使得在边缘设备上部署这些模型成为一大挑战。MiniCPM4旨在为边缘设备设计一个高效的大规模语言模型，通过在模型架构、训练数据、训练算法和推理系统上进行系统创新，解决了这一问题。", "innovation": "MiniCPM4在四个关键维度进行了创新：模型架构、训练数据、训练算法和推理系统。在模型架构方面，MiniCPM4提出了InfLLM v2，一种可训练的稀疏注意力机制，加速了长上下文处理的预填充和解码阶段。在训练数据方面，提出了UltraClean和UltraChat v2策略。训练算法方面，引入了ModelTunnel v2和改进的高效的后训练方法BitCPM。在推理系统方面，MiniCPM4结合了稀疏注意力、模型量化和推测采样，实现了高效预填充和解码。MiniCPM4提供了两种版本，参数分别为0.5B和8B，并且还构建了混合推理模型MiniCPM4.1，能够在深度推理模式和无推理模式下使用，从而更好地满足了各种边缘设备的要求。", "conclusion": "实验结果表明，MiniCPM4和MiniCPM4.1在基准测试中的表现优于开源模型，特别是8B版本在长序列理解和生成上有显著的速度提升。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20410", "html_url": "https://arxiv.org/abs/2508.20410", "title": "UI-Bench: 评估AI文本转应用工具设计能力的标准", "title_en": "UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools", "authors": "Sam Jung,Agustin Garcinuno,Spencer Mateega", "background": "当前存在使用AI文本转应用工具快速创建高质量应用和网站的潜力，但缺乏严格的公开基准来验证这些工具的能力。由于这种工具在用户界面设计上的潜在价值，研究者设计了一个全面的标准，用于评估这些工具的效果。", "innovation": "UI-Bench 是第一个通过专家对多个AI文本转应用工具的设计能力进行两两对比的方式来评估其视觉卓越性的大规模基准。该评估涉及10种工具，30个提示，300个生成站点，以及4000多份专家意见。还使用了一个基于TrueSkill模型的排名系统，可提供精确的信心区间。", "conclusion": "UI-Bench 建立了一个可重复的标准，用于推动AI驱动的网页设计发展。研究者发布了（i）完整的提示集，（ii）开源评估框架，以及（iii）公开排行榜。生成的站点将在不久后公开。用户可以在该网址查看UI-Bench排行榜：this https URL."}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.00454", "html_url": "https://arxiv.org/abs/2508.00454", "title": "从多位法官学习高效的多轮对话评估器", "title_en": "Learning an Efficient Multi-Turn Dialogue Evaluator from Multiple Judges", "authors": "Yuqi Tang,Kehua Feng,Yunfeng Wang,Zhiwen Chen,Chengfei Lv,Gang Yu,Qiang Zhang,Keyan Ding", "background": "评估大型语言模型（LLMs）的对话能力仍然是一个具有挑战性的问题。当前主流的方法主要依赖于“LLM作为评判者”的模式，即通过提示一个LLM来评估对话质量。然而，这种方法常常受到各种偏见的影响，这会损害评估结果的可靠性和一致性。为了减轻这些偏见，最近的方法采用了多个LLM作为评判者并聚合他们的判断来选择最佳评估。尽管这种方法很有效，但在推理过程中会带来显著的计算开销。因此，提出一种高效且能在多轮对话上聚合多个LLM的评估方式成为急需解决的问题，以保持多样化的多评判者反馈优势同时大幅度减少评估成本，从而实现快速和灵活地对话质量评估。", "innovation": "本文提出了一种高效多轮对话评估器，通过聚合多个LLM评判者的偏好知识以单个模型的方式捕捉集体智慧，从而保持多样化多评判者反馈的优势，同时大大减少评估成本，能够实现快速且灵活的对话质量评估。该方法在七个单一评分和成对比较对话评估基准上进行了广泛的实验，结果显示该方法在各种场景中都优于现有的基线方法，展示了其高效性和鲁棒性。", "conclusion": "本文提出了一种高效的多轮对话评估器，通过聚合多个LLM评判者的偏好知识以单个模型的方式，解决了多评判者方法在推理过程中的计算开销问题，其在多个评估基准上的表现显著优于现有的基线方法，体现了其高效性和鲁棒性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.12311", "html_url": "https://arxiv.org/abs/2504.12311", "title": "学习最佳多源视觉提示集合以进行提示转移", "title_en": "Learning Optimal Prompt Ensemble for Multi-source Visual Prompt Transfer", "authors": "Jianhua Liu,Liwen Cao,Yanru Wu,Zijie Zhao,Yang Li", "background": "提示微调已经发展成为一种轻量级策略，用于将基础模型适应下游任务，特别适用于资源受限的系统。随着预训练提示成为宝贵的资产，结合多个来源的提示提供了一种通过互补知识获得潜在增强的方法。然而，简单的聚合往往忽略了不同来源的提示对目标任务的贡献潜力不同。为了解决这个问题，我们提出了一种动态框架HGPrompt，学习最优的提示集合权重。通过同时最大化可迁移性的信息论度量并最小化不同来源提示的梯度冲突，优化这些权重。我们将不同的提示转移度量设计为可微的，以捕捉提示诱导特征在目标任务上的判别性。HGPrompt 通过海森堡矩阵和 Fisher 信息匹配不同的来源提示的梯度方差，从而确保稳定且一致的知识转移，同时抑制它们之间的梯度冲突。在大规模 VTAB 基准上的广泛实验表明了 HGPrompt 的优越性能，验证了其在学习最佳的提示集合方面的有效性，从而有效地实现了多源视觉提示的转移。", "innovation": "我们提出了 HGPrompt，一种动态框架，学习最优的提示集合权重。这些权重通过同时最大化可迁移性信息论度量和最小化梯度冲突的新型正则化策略优化。我们提出了一种可微的提示转移度量，捕捉提示诱导特征在目标任务上的判别性。此外，HGPrompt 通过匹配不同来源提示的梯度方差（基于海森矩阵和 Fisher 信息），确保知识转移的稳定性与一致性，同时抑制梯度冲突。", "conclusion": "在大规模 VTAB 基准上的广泛实验证实了 HGPrompt 的优越性能，验证了其在学习最优的多源提示集合方面有效，从而实现了有效的多源提示转移。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06971", "html_url": "https://arxiv.org/abs/2508.06971", "title": "通过集成检索和指令调整的答案提取实现两阶段可兰经问答", "title_en": "Two-Stage Quranic QA via Ensemble Retrieval and Instruction-Tuned Answer Extraction", "authors": "Mohamed Basem,Islam Oshallah,Ali Hamdi,Khaled Shaban,Hozaifa Kassab", "background": "可兰经问答由于古典阿拉伯语的复杂性以及宗教文本的语义丰富性而面临独特的挑战。本文探讨了一种双阶段框架，旨在同时处理段落检索和答案提取问题。", "innovation": "提出了一种新颖的双阶段框架，通过混合微调的阿拉伯语言模型来提高段落检索的表现，并采用指令调优的大语言模型和少量示例提示来解决细调小数据集的限制。", "conclusion": "文章的方法在Quran QA 2023 共享任务中表现优异，检索达到MAP@10 0.3128、MRR@10 0.5763，提取达到pAP@10 0.669，显著优于先前方法。实验结果表明，将模型聚类和指令调优的语言模型相结合，有效地解决了低资源领域内问句回答的挑战。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20038", "html_url": "https://arxiv.org/abs/2508.20038", "title": "预防为先：通过预合成恶意指令增强大语言模型的安全防护屏障以应对潜在攻击", "title_en": "Forewarned is Forearmed: Pre-Synthesizing Jailbreak-like Instructions to Enhance LLM Safety Guardrail to Potential Attacks", "authors": "Sheng Liu,Qiang Sheng,Danding Wang,Yang Li,Guang Yang,Juan Cao", "background": "尽管在改进大型语言模型（LLM）以拒绝恶意指令方面取得了进展，但广泛应用的LLM仍然容易受到‘逃逸攻击’，其中攻击者生成的指令分布与安全对齐的语料库不同。新的攻击揭示了LLM识别未见过的恶意指令能力的不足，强调了训练数据与现实世界攻击之间的关键分布不匹配，迫使开发人员陷入被动的修复循环。", "innovation": "本文提出IMAGINE，这是一种合成框架，通过嵌入空间分布分析来生成类似‘逃逸攻击’的指令。此方法有效地填补了真实‘逃逸攻击’模式与安全对齐语料库之间的分布差异。IMAGINE采用迭代优化过程，在多次迭代中动态进化文本生成分布，从而通过合成数据示例来增强安全对齐数据分布的覆盖范围。", "conclusion": "基于经过IMAGINE增强的对齐语料库，本文框架在Qwen2.5、Llama3.1和Llama3.2上显著降低了攻击成功率，同时不损害其实用性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15478", "html_url": "https://arxiv.org/abs/2508.15478", "title": "SLM-Bench: 小型语言模型在环境影响方面的综合基准—扩展版本", "title_en": "SLM-Bench: A Comprehensive Benchmark of Small Language Models on Environmental Impacts--Extended Version", "authors": "Nghiem Thanh Pham,Tung Kieu,Duc-Manh Nguyen,Son Ha Xuan,Nghia Duong-Trung,Danh Le-Phuoc", "background": "小型语言模型（SLMs）在计算效率和访问性方面表现出色，但它们在性能和环境影响方面的系统性评估相对缺乏。SLM-Bench 是第一个专门用于在多个维度（包括准确性、计算效率和可持续性指标）评估 SLMs 的基准，使用 23 个数据集和 4 种硬件配置，在 9 个 NLP 任务上对 15 个 SLMs 进行评估。该基准通过量化 11 个指标（包括正确性、计算和消耗）来提供全面的效率权衡评估。SLM-Bench 强调了 SLMS 的多样化权衡，其中一些模型在准确性方面表现出色，而其他模型在能源效率方面表现更优。SLM-Bench 设立了一个新的标准，填补了资源效率与实际应用之间的差距，促使了资源效率与实际应用的协调发展.", "innovation": "SLM-Bench 是第一个专门设计用于评估 SLMs 的多维度基准，包含 11 个效率权衡指标，并采用了标准化的评估协议，增加了可重复性和进一步研究的可能性，填补了小型语言模型在环境影响评估方面的空白，为后续研究提供了坚实的基础.", "conclusion": "SLM-Bench 的评估结果揭示了 SLMs 在准确性和能源效率方面的不同权衡，明确了这些模型在不同任务上可能的优势和劣势。SLM-Bench 制定了新的评价标准，积极促进了小型语言模型在资源效率和实际应用之间的统一，为未来的研发和应用奠定坚实的基础."}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01185", "html_url": "https://arxiv.org/abs/2509.01185", "title": "语言模型训练和评估中合成长上下文数据生成的模块化方法", "title_en": "Modular Techniques for Synthetic Long-Context Data Generation in Language Model Training and Evaluation", "authors": "Seganrasan Subramanian,Abhigya Verma", "background": "大型语言模型在处理和推理长文本输入方面的能力对于许多实际应用至关重要，但这一领域的进展受到高质量、多样性和可验证的长上下文数据集的缺乏限制，这些数据集既适合训练也适合评估。现有的数据集无法满足这一需求，尤其是在以美国和欧洲的数据为主的背景下，限制了LLMs的能力改进和验证。", "innovation": "该论文提出了一个模块化的合成长上下文数据生成框架，通过与LLMs基于提示的交互来生成。该框架支持多种训练和对齐目标，包括监督微调（SFT）、直接偏好优化（DPO）和群体相对策略优化（GRPO）。此外，该框架包括四种核心生成范式：多轮对话、文档为基础的输入-输出对、可验证指令-响应任务和长上下文推理示例。通过模板提示、模型无关的架构和元数据丰富的输出，该方法促进了对LLM长上下文能力改进的有 scalability、控制性和目标导向的数据集创建过程。", "conclusion": "该工作通过模块化的方法和对多种训练目标的支持，提出了一个针对长上下文数据生成的综合框架，旨在推动LLM在处理长文本数据方面的表现。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.13923", "html_url": "https://arxiv.org/abs/2406.13923", "title": "PIN： paired and interleaved multimodal documents for knowledge-intensive datasets", "title_en": "PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents", "authors": "Junjie Wang,Yuxiang Zhang,Minghao Liu,Yin Zhang,Yatai Ji,Weihao Xuan,Nie Lin,Kang Zhu,Zhiqiang Lin,Yiming Ren,Chunyang Jiang,Yiyao Yu,Zekun Wang,Tiezhen Wang,Wenhao Huang,Jie Fu,Qunshu Liu,Yujiu Yang,Ge Zhang,Ruibin Yuan,Bei Chen,Wenhu Chen", "background": "近年来，大型多模态模型（LMMs）通过利用广泛多元化的数据集来提升复杂知识驱动任务的能力。然而，感知与推理错误持续存在的挑战限制了它们的效能，尤其是在处理复杂的视觉数据和推导多模态关系方面。", "innovation": "本文引入了PIN（配对和交错的多模态文档）这一新型数据格式，旨在促进视觉和文本知识的更深层次整合。PIN格式结合了富含语义的Markdown文件和整体图像， Markdown文件保留了详细的文本结构，整体图像捕捉了文档的整体布局。此外，基于此格式，构建并公开了两个大规模且开放的数据集：PIN-200M（约2亿文档）和PIN-14M（约1400万文档），数据源涵盖了多种网络和学术资料，涵盖中英文语言。", "conclusion": "本文的工作不仅提供了多功能的数据格式，还提供了丰富的资源，为预训练策略的新研究和开发更强大的知识密集型LMMs奠定了基础。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03020", "html_url": "https://arxiv.org/abs/2509.03020", "title": "通过双向重建训练LLM成为更好的文本嵌入器", "title_en": "Training LLMs to be Better Text Embedders through Bidirectional Reconstruction", "authors": "Chang Su,Dengliang Shi,Siyuan Huang,Jintao Du,Changhua Meng,Yu Cheng,Weiqiang Wang,Zhouhan Lin", "background": "大型语言模型（LLMs）已被广泛探索作为强大的文本嵌入器。现有的基于LLM的文本嵌入方法通常利用最终标记的嵌入，通常是保留的特殊标记如[EOS]。然而，这些标记并不是专门训练来捕捉整个上下文的语义，限制了它们作为文本嵌入的潜力，特别是在检索和重排序任务中的表现。", "innovation": "我们提出在对比学习之前增加一个新的训练阶段，通过双向生成性重建任务来丰富最终标记的语义。这些任务包括EBQ2D（基于嵌入的查询到文档）和EBD2Q（基于嵌入的文档到查询），它们交替进行以锚定[EOS]的嵌入并重建查询-文档对的任一侧。实验结果显示，我们的额外训练阶段显著提高了LLM在大规模文本嵌入基准（MTEB）上的性能，实现了不同LLM基础模型和规模的新最先进的结果。", "conclusion": "我们的研究在不同规模的LLM基础上显著提升了其作为文本嵌入器的性能，并取得了新的状态最先进结果。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01221", "html_url": "https://arxiv.org/abs/2509.01221", "title": "DaMoC: 基于数据和模型压缩高效选择适合微调特定领域任务的最佳大型语言模型", "title_en": "DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Tasks Based on Data and Model Compression", "authors": "Wei Huang,Huang Wei,Yinggui Wang", "background": "大型语言模型（LLMs）在通用任务中表现出色，但在特定领域任务中却存在问题，通常需要使用特定数据进行微调。尽管有许多开源LLMs可供选择，但选择最适合特定微调任务的最佳LLM仍然具有挑战性，主要问题是快速识别最优LLM的方法不明确。", "innovation": "该论文提出了一个数据和模型压缩框架（DaMoC），通过以下方式解决上述挑战：1) 在数据层面：建立了数据过滤方法的系统分类法，分为三种类型：（1）分布感知方法，（2）质量感知方法，（3）同时考虑两个维度的混合方法，并通过增加关键标记在文本中的密度实现了标记压缩，然后使用LLM迭代重写文本以优化其表达。2) 在模型层面：使用层相似度得分评估每层的重要性，并移除那些较低的层。接着，引入了一种稀疏合并范式以尽可能保留原始模型的大部分能力。此外，在四个数据集上进行了广泛的实验，其中包括医疗问答、金融问答、通用问答和阅读理解，结果显示可以节省大约20倍的训练时间来选择最优LLM。", "conclusion": "通过数据和模型压缩框架（DaMoC），可以有效节省训练时间的40%-60%，同时提高特定领域问答和阅读理解任务的性能。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.01085", "html_url": "https://arxiv.org/abs/2407.01085", "title": "LLM基于偏好评估中长度偏见的解释", "title_en": "Explaining Length Bias in LLM-Based Preference Evaluations", "authors": "Zhengyu Hu,Linxin Song,Jieyu Zhang,Zheyuan Xiao,Tianfu Wang,Zhengyu Chen,Nicholas Jing Yuan,Jianxun Lian,Kaize Ding,Hui Xiong", "background": "随着大型语言模型（LLMs）在偏好比较中的广泛应用，研究发现这些模型倾向于偏向较长的回复，这削弱了评价的可靠性。为了更好地理解这种偏见，作者提出了将偏好评价指标分解为两个关键部分：可欲望性和信息量。", "innovation": "作者提出了一种新的方法来解释和解决LLM偏好评估中的长度偏见问题。通过将偏好评价指标（胜率）分解为与长度无关的可欲望性和与长度相关的信息量，作者设计了一种名为AdapAlpaca的新方法，该方法通过调整胜率测量方法，确保在相同的长度区间内对响应质量进行公平比较。", "conclusion": "通过实验证明，AdapAlpaca能够消除回复长度对评价结果的影响，提供了一种可靠地评估内容质量的方法，而不会被回复长度所混淆。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02038", "html_url": "https://arxiv.org/abs/2509.02038", "title": "NADI 2025: 第一个多功能阿拉伯口音语音处理共享任务", "title_en": "NADI 2025: The First Multidialectal Arabic Speech Processing Shared Task", "authors": "Bashar Talafha,Hawau Olamide Toyin,Peter Sullivan,AbdelRahim Elmadany,Abdurrahman Juma,Amirbek Djanibekov,Chiyu Zhang,Hamad Alshehhi,Hanan Aldarmaki,Mustafa Jarrar,Nizar Habash,Muhammad Abdul-Mageed", "background": "本研究呈现了第六届Nuanced Arabic Dialect Identification (NADI 2025) 共享任务的结果，该任务专注于阿拉伯口音话语处理，涵盖了三个子任务：口头方言识别（子任务1）、语音识别（子任务2）和口头方言中的重音恢复（子任务3）。共有44支队伍注册了该任务，在测试阶段收到了来自8支不同队伍的100份有效提交，说明该领域的多语言和地区覆盖较广。各子任务的具体提交数如下：子任务1收到来自五支队伍的34份提交，子任务2收到来自六支队伍的47份提交，子任务3收到来自两支队伍的19份提交。最佳系统在子任务1中的准确性达到79.8%，子任务2整体WER/CER为35.68/12.20，子任务3的WER/CER为55/13。这些结果突显了阿拉伯方言语音处理的持续挑战，特别是在方言识别、识别和重音恢复方面。", "innovation": "这是首次集合阿拉伯多口音语音处理的多领域共享任务，涵盖口头方言识别、语音识别和重音恢复三大子任务，为该领域研究提供了新的数据集和挑战。该共享任务吸引了多个研究团队参与，展示了阿拉伯方言语音处理的最新进展。此外，研究总结了参与团队采用的方法，并为未来NADI会议的方向提出了建议，体现了该领域的持续探索和改进。", "conclusion": "这些结果表明，尽管取得了进步，阿拉伯方言语音处理仍面临挑战。未来的研究可以进一步提高识别和语音恢复的准确性，并探索新的方法和技术。NADI将进一步举办此类共享任务，以促进这一领域的持续研究和发展。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.17882", "html_url": "https://arxiv.org/abs/2502.17882", "title": "跨语言的科学：评估大型语言模型多语言科学论文翻译", "title_en": "Science Across Languages: Assessing LLM Multilingual Translation of Scientific Papers", "authors": "Hannah Calzi Kleidermacher,James Zou", "background": "科学研究具有全球性，但大多数学术期刊仅以英语出版，这给非英语母语的研究者设置了障碍。为此，研究人员利用大型语言模型（LLMs）来翻译已发表的科学文章，同时保留其原始的JATS XML格式，开发了一种实用的自动化方法，以便学术期刊实施。", "innovation": "该研究利用大型语言模型开发了一种方法，能够将多学科的科学论文翻译成28种语言，同时保持原稿的格式。为了评估翻译准确性，研究引入了一种新型问题-解答基准测试方法，通过比较模型生成的问题和答案来评估翻译的准确性，结果平均得分为95.9%。此外，通过用户研究发现翻译内容能够准确反映原文信息，而术语翻译时有三分之一的作者希望保持英文术语不变。", "conclusion": "这项研究展示了基于上下文学习技术如何调整翻译以契合领域特定偏好，例如减少过度翻译，突显了大型语言模型驱动的科学翻译的适应性和实用性。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.23746", "html_url": "https://arxiv.org/abs/2503.23746", "title": "短视频传播影响力评级：一个新的现实世界数据集和一个新的大规模图形模型", "title_en": "Short-video Propagation Influence Rating: A New Real-world Dataset and A New Large Graph Model", "authors": "Dizhan Xue,Shengsheng Qian,Chuanrui Hu,Changsheng Xu", "background": "短视频平台在全球范围内获得了前所未有的流行度，吸引了数亿用户的关注。近年来，研究者开始强调分析短视频传播的重要性，包括其商业价值、公共意见和用户行为等。然而，目前缺乏大规模且覆盖多个平台的短视频传播数据集，以及能够有效分析这种传播的模型。", "innovation": "本文提出了一种新的短视频传播影响力评级(SPIR)任务，旨在从数据集和方法论两个方面推动SPIR的发展。首先，提出了一个名为XS-Video的新数据集，包含来自中国五大平台的117,720个视频和381,926个样本，记录了从第0级到第9级的传播影响力。其次，基于大型语言模型的强大推理能力和新提出的三层训练机制，提出了名为NetGPT的新型大规模图形模型。", "conclusion": "在本研究的数据集上，通过分类和回归指标评估的综合实验结果表明，NetGPT模型在短视频传播影响力评级方面优于现有方法。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.05720", "html_url": "https://arxiv.org/abs/2503.05720", "title": "不可接受：取消文化中的道德基础", "title_en": "That is Unacceptable: the Moral Foundations of Canceling", "authors": "Soda Marem Lo,Oscar Araque,Rajesh Sharma,Marco Antonio Stranisci", "background": "取消是一种道德驱动的现象，阻碍了安全社交媒体平台的发展，并加剧了意识形态极化。为了解决这个问题，本文介绍了‘取消态度检测’（CADE）数据集，这是一个标记过的取消事件集合，旨在探索社交媒体上评估取消态度差异的因素。研究表明，注释者的道德观念对其对取消的看法有重要影响，这一现象表明，缺乏更以事件为中心的数据集及其分析，不利于更好地理解社交媒体上的伤害如何产生，也不利于发展更具意识的伤害检测技术。", "innovation": "本文提出了CADE数据集，这是第一个专注于注释取消态度并探索社交媒体上取消行为差异因素的标记数据集。研究表明注释者的道德观念在评价取消态度中扮演着重要角色，这一发现强调了对更以事件为中心的数据集的需求，有助于更好地理解社交媒体上的伤害并向基于事件的伤害检测技术的开发提供指导。", "conclusion": "研究指出，注释者的道德观念是理解取消文化差异的关键因素。发展更具事件中心的数据集和相关技术是解决社交媒体上负面影响的关键。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08715", "html_url": "https://arxiv.org/abs/2508.08715", "title": "MultiGen: 基于LLM的孩子友好型多语言语音生成器", "title_en": "MultiGen: Child-Friendly Multilingual Speech Generator with LLMs", "authors": "Xiaoxue Gao,Huayun Zhang,Nancy F. Chen", "background": "生成语音模型已经在提高人机交互质量方面显示出显著潜力，尤其是在为儿童提供语言学习方面。然而，要实现高质量且适合儿童的语音生成仍然具有挑战性，特别是对于低资源语言以及多种语言和文化背景来说更为困难。", "innovation": "提出了一种名为MultiGen的多语言语音生成模型，专门针对低资源语言。该模型利用LLM架构进行语音生成，并整合了年龄合适且多语言的语音生成技术，以便通过文化相关背景促进儿童与AI系统的交流。实验结果表明，相比基线方法，MultiGen在客观评估指标和主观评估中表现出更优异的性能。", "conclusion": "该研究表明，MultiGen模型在多语言和低资源语言环境下的语音生成方面具有显著优势，能够更好地服务于儿童群体。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03312", "html_url": "https://arxiv.org/abs/2509.03312", "title": "AgenTracer：LLM嵌入式代理系统中引发故障的是谁？", "title_en": "AgenTracer: Who Is Inducing Failure in the LLM Agentic Systems?", "authors": "Guibin Zhang,Junhao Wang,Junjie Chen,Wangchunshu Zhou,Kun Wang,Shuicheng Yan", "background": "基于大型语言模型（LLM）的代理系统虽然性能卓越，但其复杂性也导致系统更易发生故障。当前最先进推理LLM在这方面的准确性仍然很低，通常低于10%。识别执行追踪中错误的具体代理或步骤是一项挑战性的任务。为解决这一问题，作者提出了AgenTracer，这是一种自动化框架，使用因果回放和编程故障注入来标注失败的多代理轨迹，从而生成标注数据集TracerTraj。利用这些资源，作者开发了用于诊断多代理交互中错误的轻量级失败追踪器AgenTracer-8B，能够在“Who&When”基准测试中的表现超出诸如Gemini-2.5-Pro和Claude-4-Sonnet等巨大的专有LLM多达18.18%，并且能够为现成的多代理系统如MetaGPT和MaAS提供实用反馈，提高其性能4.8-14.2%。", "innovation": "AgenTracer是一种创新的自动化框架，使用因果回放和编程故障注入来标注失败的多代理轨迹，解决了高性能多代理系统故障挑战性的错误定位任务。作者开发了AgenTracer-8B，这是一种轻量级的失败追踪器，基于多粒度强化学习进行训练，能够高效诊断多代理交互中的错误。AgenTracer-8B在性能上优于大型专有LLM，并为现成的多代理系统提供了实用反馈，从而实现自我纠正和自我演化的人工智能代理系统。", "conclusion": "AgenTracer-8B在LLM嵌入式代理系统的故障归因中取得了显著成果，不仅在“Who&When”基准测试中表现出色，还通过提供实用反馈帮助现成的多代理系统提升性能。这一工作为代理系统的自我修正和自我进化提供了新的方法，值得进一步研究和应用。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.05248", "html_url": "https://arxiv.org/abs/2412.05248", "title": "增强FGK.in：实现印度食谱成分的自动化分析", "title_en": "Enhancing FKG.in: automating Indian food composition analysis", "authors": "Saransh Kumar Gupta,Lipika Dey,Partha Pratim Das,Geeta Trilok-Kumar,Ramesh Jain", "background": "本文介绍了使用印度食物知识图谱（FKG.in）和大型语言模型（LLMs）来计算印度食谱成分的新型方法。与此同时，提出了一种自动化食物成分分析工作流，并描述了其核心功能，即营养数据聚合、食物成分分析和LLM增强的信息解析。进一步阐述了代表印度食物和数字化获取食物成分数据的挑战。文中回顾了三个关键的食物成分数据来源：印度食物成分表格、印度营养数据库以及Nutritionix API。此外，简要介绍了用户如何通过工作流获取基于饮食的健康建议和详细的食品成分信息。探讨了分析印度食谱信息时遇到的结构性、多语言性和不确定性等复杂挑战，并展示了基于LLM的解决方案及其进展。这些方法旨在解决AI驱动的知识整理和信息解析问题，且具有应用广泛性、可泛化性和可复制性，可用于任何领域。", "innovation": "提出了一种结合知识图谱和大规模语言模型来自动化计算印度食谱成分的全新方法，并开发了一种自动化食物成分分析工作流，以补充印度食物知识图谱的数据并解决其数据缺口。同时，解决了印度食谱分析中遇到的结构性、多语言性和不确定性等问题，并基于大型语言模型提出了解决方案。", "conclusion": "本文提出的工作流方法对AI驱动的知识整理和信息解析应用广泛、可泛化和可复制。通过参考印度的关键食物成分数据来源，用户可以获取有关基于饮食的健康建议和详细的食物成分信息。属于AI和数据科学领域的一个创新成果。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18102", "html_url": "https://arxiv.org/abs/2505.18102", "title": "如何在不透露正确答案的情况下发布我的大语言模型基准？", "title_en": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "authors": "Takashi Ishida,Thanawat Lodkaew,Ikko Yamane", "background": "发布大语言模型（LLM）基准的风险在于可能会无意或有意地将基准用于训练或选择模型。常见的缓解策略是保持基准的私密性，让参赛者向组织者提交他们的模型或预测，但这需要对单一组织的信任，仍然存在通过重复查询导致测试集过拟合的问题。因此，需要一种新型的出版基准的方法，即在不完全披露问题正确答案的情况下，仍能公平地评估语言模型。", "innovation": "提出了一种在不完全公开正确答案的情况下发布基准的方法，通过给答案注入随机性来准备多个逻辑上正确的答案，并在基准中仅包含一个作为解决方案。这降低了基准的最佳可能准确度，即贝叶斯准确度。这种方法不仅有助于防止披露真实答案，还能作为检测数据污染的测试。理论上，即使完全有能力的模型也不应超越贝叶斯准确度，若某个模型超过这一限制，则表明存在数据污染。实验结果证明该方法在多种基准、模型和训练方法上能准确检测数据污染。", "conclusion": "该方法能够准确地在多种基准、模型和训练方法上检测数据污染，提供了一种在不透露真实答案的情况下发布基准的新策略。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.01115", "html_url": "https://arxiv.org/abs/2506.01115", "title": "随机注意力是否足以进行序列建模？分离Transformer中的可训练组件", "title_en": "Is Random Attention Sufficient for Sequence Modeling? Disentangling Trainable Components in the Transformer", "authors": "Yihe Dong,Lorenzo Noci,Mikhail Khodak,Mufan Li", "background": "Transformer结构对于现代大型语言模型的成功至关重要，尤其是在使用基于梯度的学习机制预测下一个token时展现出了执行广泛任务（如数学推理、记忆和检索）的能力。虽然Transformer的核心组件是自注意力机制，但作者质疑这种机制在性能提升中到底占了多大比例及其具体哪方面的贡献。为了探索这些问题，作者对比了标准Transformer和通过冻结自注意力机制中的关键和查询权重的变体模型。作者还设计了一个全新的架构MixoT，具有完全随机的注意力评分，以进一步细化分析每个Transformer组件的贡献，并证明了冻结关键和查询权重的Transformer模型的表现力结果。", "innovation": "研究作者探索了Transformer性能提升中的注意力机制的作用，并提出了一种全新的架构MixoT，具有完全随机的注意力评分，并通过证明新的表达能力结果，进一步分离了可训练组件在Transformer中的具体贡献。MixoT克服了随机Transformer在深度比例上的挑战，具有可证明稳定的信号传播，揭示了注意力在上下文推理中的主要作用，以及MLP在知识存储中的作用。研究结果表明，Transformer架构具有构建专业电路的内置倾向，甚至在没有可学习的注意力权重的情况下也能实现这一目标。", "conclusion": "研究结果表明，Transformer架构具有内置的诱导偏倚，能够在没有可训练的注意力权重的情况下形成特定电路。同时，MixoT的实验也进一步明确了每个组件的功能，注意力主要负责上下文推理，而MLP则主要负责知识存储，并与注意力协同工作。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16117", "html_url": "https://arxiv.org/abs/2508.16117", "title": "扩展 FKG.in：朝着食品宣称溯源网络的方向", "title_en": "Extending FKG.in: Towards a Food Claim Traceability Network", "authors": "Saransh Kumar Gupta,Rizwan Gulzar Mir,Lipika Dey,Partha Pratim Das,Anirban Sen,Ramesh Jain", "background": "当前全球食品领域充斥着关于食品的各种科学、文化与商业主张，这些主张涉及健康益处、误导信息、模糊承诺以及文化根深蒂固的信仰。尽管这些主张有着广泛的影响，但现有的追踪、验证和背景化这些主张的基础架构仍然支离破碎和不够完善。本文通过对印度食品知识图谱 FKG.in 的扩展，提出了一种食品宣称溯源网络（FCN），旨在构建一个结构化、可验证和可解释的食品知识生态系统，从而支持研究者、政策制定者和最重要的是普通消费者在信息泛滥的食品领域中进行导航", "innovation": "本文提出了一种食品宣称溯源网络（FCN），这是一种基于印度食品知识图谱 FKG.in 的扩展应用。FCN 结合了经过精心整理的数据输入、结构化的元数据规范以及具有来源感知的食品宣称提取和验证流水线。通过使用 Reddit 数据和大语言模型半自动知识筛选工作流，FCN 实现了基于可验证信息的食品宣称模型的建模，并且该方法保持在应用程序上的通用性和适配性，可以应用于不同的地域、烹饪或监管环境", "conclusion": "通过构建结构化、可验证和可解释的食品知识系统，FCN 希望能够促进更透明和负责任的食品知识生态系统，为研究人员、政策制定者和普通消费者提供导航对比比比缺陷遍布的食品领域做出明智的选择。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03614", "html_url": "https://arxiv.org/abs/2509.03614", "title": "MIDOG 2025挑战中的教师-学生模型用于检测和分类有丝分裂", "title_en": "Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG 2025 Challenge", "authors": "Seungho Choe,Xiaoli Qin,Abubakr Shafique,Amanda Dy,Susan Done,Dimitrios Androutsos,April Khademi", "background": "病理学家手动计数有丝分裂过程耗时且容易出现观察者间差异。人工智能通过自动检测有丝分裂并保持决策一致性来提供解决方案。然而，AI工具可能会发生领域转移，导致性能显著下降，特别是在训练集和测试集之间存在形态多样性和不同染色协议等差异。此外，有丝分裂的数量远少于正常细胞核的数量，使得检测任务中数据严重不平衡。", "innovation": "本文提出了一种教师-学生模型，将有丝分裂检测（Track 1）和非典型有丝分裂分类（Track 2）整合为一个像素级分割任务。该方法使用UNet作为分割骨干网络，并结合对比表示学习和领域对抗训练的通用性模块。采用教师-学生策略不仅为注释的有丝分裂、硬负例和正常细胞核生成像素级别的伪掩码，还增强了特征区分并提高了对领域迁移的鲁棒性。对于分类任务，引入了一个多尺度CNN分类器，在多任务学习框架中利用分割模型的特征图。算法在初步测试集中实现了0.7660的F1分数和0.8414的平衡准确性，证明了将基于分割的检测和分类整合到统一框架的有效性。", "conclusion": "我们的方法在有丝分裂检测和分类两个赛道上都表现优异，通过集成基于分割的检测和分类功能，提供了一种鲁棒的有丝分裂分析范式。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01909", "html_url": "https://arxiv.org/abs/2509.01909", "title": "Oyster-I：超越拒绝-负责任的语言模型的建设性安全对齐", "title_en": "Oyster-I: Beyond Refusal -- Constructive Safety Alignment for Responsible Language Models", "authors": "Ranjie Duan,Jiexi Liu,Xiaojun Jia,Shiji Zhao,Ruoxi Cheng,Fengxiang Wang,Cheng Wei,Yong Xie,Chang Liu,Defeng Li,Yinpeng Dong,Yichi Zhang,Yuefeng Chen,Chongwen Wang,Xingjun Ma,Xingxing Wei,Yang Liu,Hang Su,Jun Zhu,Xinfeng Li,Yitong Sun,Jie Zhang,Jinzhao Hu,Sha Xu,Yitong Yang,Jialing Tao,Hui Xue", "background": "目前的大语言模型（LLMs）通常部署安全机制以防止有害内容的生成。大多数现有方法专注于恶意行为者带来的风险，往往将这些风险视为对抗性事件，并依赖于防御性的拒绝策略。但在现实世界中，风险还来自寻求帮助的非恶意用户，他们可能在心理压力下（例如存在自杀意图）。在这种情况下，模型的响应可以强烈影响用户的下一步行动。简单的拒绝可能导致用户重复尝试、加剧局势或转向不安全的平台，从而产生更糟糕的结果。", "innovation": "本文引入了建设性安全对齐（CSA）这一以人为中心的范式，旨在在保护免受恶意使用的同时，积极引导脆弱用户获得安全和有用的结果。CSA在Oyster-I（Oy1）中实现，结合了博弈论预判用户反应、细粒度风险边界发现以及可解释推理控制，将安全性转变为信任建立的过程。Oy1在保持高通用能力的同时，达到了开源模型中最高的安全性水平。在我们构建的基准测试中，Oy1显示出了强大的建设性参与，接近GPT-5的水平，并在Strata-Sword漏洞利用数据集上表现出无与伦比的鲁棒性，接近GPT-o1的水平。通过从拒绝优先转向引导优先的安全策略，CSA重新定义了模型与用户之间的关系，旨在使系统不仅安全，还真正有用。", "conclusion": "本文提出了一种转向引导优先的安全范式，即建设性安全对齐（CSA），并通过Oyster-I（Oy1）的实现展示了其在保持高通用能力的同时，实现了最先进的安全性能。CSA旨在提供真正有用的系统，不仅确保安全性，还促进用户和模型之间的实质性的互动和信任。此外，Oyster-I及其代码已开源，以支持负责任的、以用户为中心的AI发展。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01938", "html_url": "https://arxiv.org/abs/2509.01938", "title": "EigenBench：一种比较性的价值对齐行为衡量方法", "title_en": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "authors": "Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine", "background": "人类价值观与人工智能的对齐是一个紧迫且未解决的问题。为了解决缺乏衡量价值对齐的量化指标这一难题，本文提出了EigenBench：一种用于比较性基准测试语言模型价值观的黑箱方法。通过给定一组模型、一个定义价值系统的宪法以及一组场景数据，该方法将返回量化每个模型与给定宪法对齐程度的向量分数。", "innovation": "EigenBench 提出了一种无需真实标签的方法，专门用于衡量那些合理评判者可能对正确标签存在分歧的独特特性。方法通过不同模型对其他模型在多种场景下的输出进行评判，并利用 EigenTrust（Kamvar 等，2003 年）进行聚合评估。此外，通过使用提示角色测试，EigenBench 分数对模型和提示的敏感性表明了大部分变化由提示解释，剩余的小部分则衡量了模型本身的态度。", "conclusion": "研究通过提示角色测试证明了 EigenBench 在评估模型倾向于不同提示时的有效性。大部分方差可以归因于提示，但仍有部分方差反映了模型自身的倾向。EigenBench 为评估语言模型的价值对齐提供了一种创新且实用的方法。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03609", "html_url": "https://arxiv.org/abs/2509.03609", "title": "在掩码骨架建模中高效通用特征预测", "title_en": "Towards Efficient General Feature Prediction in Masked Skeleton Modeling", "authors": "Shengkai Sun,Zefan Zhang,Jianfeng Dong,Zhiyong Cheng,Xiaojun Chang,Meng Wang", "background": "近年来，掩码自编码器（MAE）范式极大地推动了基于骨架的动作识别的自监督方法。然而，现有的大多数方法将重建目标限制在原始关节坐标或它们的简单变体上，这导致了计算冗余和有限的语义表示能力。", "innovation": "我们提出了一种新的高效通用特征预测框架（GFP）用于掩码骨架建模。我们的关键创新之处在于，用高层次的特征预测取代了传统的低层次重建，涵盖了从局部运动模式到全局语义表示。具体来说，我们引入了一个协作学习框架，其中轻量级的目标生成网络能够动态地在空间-时间层次结构中产生多种多样的监督信号，避免依赖预先计算的离线特征。框架还包含约束优化，以确保特征多样性同时防止模型崩溃。", "conclusion": "在NTU RGB+D 60，NTU RGB+D 120和PKU-MMD上的实验表明，我们的方法具有计算效率（比标准掩码骨架建模方法快6.2倍）、优秀的表示质量和在各种下游任务中达到最优性能的优点。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.21080", "html_url": "https://arxiv.org/abs/2503.21080", "title": "EQ-Knight: 一种增强的记忆辅助LLM代理，在债务回收中的战略情感游戏", "title_en": "EQ-Knight: A Memory-Augmented LLM Agent for Strategic Affective Gaming in Debt Recovery", "authors": "Yunbo Long,Yuhan Liu,Liming Xu,Alexandra Brintrup", "background": "基于大型语言模型的聊天机器人在金融谈判中增强了参与度，但在信用追收中过度依赖被动共情会引入关键风险。虽然共情驱动的方法在良性情况下可以保持客户满意度，但在面对不诚实债务人（利用和解策略操纵条款或逃避还款的人）时会灾难性地失败。一味优先“客户体验”导致债权人面临风险：收入流失、道德风险和系统性利用。", "innovation": "我们提出了EQ-Knight，一种动态优化情感策略以捍卫债权人利益的LLM代理。EQ-Knight结合了情感记忆和博弈论推理，通过隐马尔可夫模型（HMM）跟踪和预测债务人的情绪状态。结合实时和历史情感线索，EQ-Knight战略性地对抗负面情绪（如攻击性、假装的悲痛）的同时保持与债务人的有利关系。", "conclusion": "实验表明EQ-Knight优于传统LLM谈判者：它成功减少了让步损失的32%而不牺牲回收率，特别是在债务人使用负面情绪（如恐吓、道德胁迫）施加压力的对手案例中。对于信用机构而言，EQ-Knight将LLM转变为战略情感防御者——平衡情感智慧与战术严谨性，以维护问责制并遏制利用行为。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02175", "html_url": "https://arxiv.org/abs/2509.02175", "title": "理解空间——只有顶级推理模型才能解决空间理解任务", "title_en": "Understanding Space Is Rocket Science -- Only Top Reasoning Models Can Solve Spatial Understanding Tasks", "authors": "Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque", "background": "当前的视觉-语言模型（VLMs）在相对空间理解方面表现不佳，尤其是在处理物体间的相对位置和顺序时。这些模型当前的表现让人感到不足，并且对理解性推理模型的能力存在低估。", "innovation": "提出了一种名为RocketScience的新开源对比视觉-语言模型基准测试，专注于评估模型在理解空间关系方面的表现。该基准包含全新的基于真实世界的图像-文本对，主要测试相对空间理解和物体顺序。此外，作者还进行了分离实验，将对象定位和空间推理的贡献分开，发现空间推理能力是限制模型在基准测试中表现的因素。", "conclusion": "开源和最新商用VLMs在空间关系理解方面表现薄弱，但理解性推理模型表现出意料之外的高精度。空间推理能力是限制模型在基准测试中的因素，而不是对象定位能力。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03729", "html_url": "https://arxiv.org/abs/2509.03729", "title": "基于迁移学习的CNN模型在利用叶片脉序识别植物种类中的应用", "title_en": "Transfer Learning-Based CNN Models for Plant Species Identification Using Leaf Venation Patterns", "authors": "Bandita Bharadwaj,Ankur Mishra,Saurav Bharadwaj", "background": "本文研究了三种深度学习架构（ResNet50、MobileNetV2和EfficientNetB0）对于基于叶片脉序的植物种类自动分类的效果，这是一个重要的形态学特征，具有高度的分类学相关性。研究使用了包含15种不同物种的瑞典叶片数据集（每种物种75张图片，总计1,125张图片），在训练和测试阶段使用标准性能指标展示了这些模型的应用。", "innovation": "研究创新点在于对比分析了三种不同深度学习架构在基于叶片脉序植物分类任务上的表现，特别突出了EfficientNetB0在泛化能力和分类准确性上的优势，为其在轻量级、实时应用中的使用提供了依据。", "conclusion": "研究结果表明，深度学习，尤其是在叶片脉序分类任务上表现突出的EfficientNetB0，有潜力开发出可扩展且准确的自动植物分类工具，特别是在基于脉序特征的应用中。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03737", "html_url": "https://arxiv.org/abs/2509.03737", "title": "LayoutGKN：楼地板图结构相似性学习", "title_en": "LayoutGKN: Graph Similarity Learning of Floor Plans", "authors": "Casper van Engelenburg,Jan van Gemert,Seyran Khademi", "background": "楼地板平面图描绘建筑布局，常以图的形式表示以捕捉其内部的空间关系。这些图的比较对于搜索、聚类和数据可视化等应用至关重要。目前最成功的图比较方法（例如，图匹配网络）依赖于成本高的跨图节点级交互，因此在推理时间上较慢。", "innovation": "本文提出了一种名为LayoutGKN的新方法，可以更高效地计算图相似性。LayoutGKN通过在联合嵌入架构结束时推迟跨图节点级交互，利用可微图核作为最终学习节点级嵌入的距离函数，从而在保持相似度计算性能的同时显著提高速度。", "conclusion": "实验证明，与图匹配网络相比，LayoutGKN可用于计算相似性，并达到了更好的或相同的效果，具有显著提高的速度。相关代码和数据已公开。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03635", "html_url": "https://arxiv.org/abs/2509.03635", "title": "Reg3D：3D场景理解的重建几何指令调优", "title_en": "Reg3D: Reconstructive Geometry Instruction Tuning for 3D Scene Understanding", "authors": "Hongpei Zheng,Lintao Xiang,Qijun Yang,Qian Lin,Hujun Yin", "background": "Large Multimodal Models（LMMs）在2D视觉理解方面取得了显著进步，但将这些能力扩展到3D场景理解仍面临重大挑战。现有方法主要依靠纯文本监督，这无法提供学习鲁棒3D空间表示所必需的几何约束。此类方法通常仅在输入端注入3D信息，未能充分利用3D几何信息作为指导学习的具体目标。", "innovation": "提出了一种新的重建几何指令调优框架Reg3D。Reg3D采用双重监督模式，既作为输入也作为明确的学习目标，利用3D几何信息，并设计了对象级和帧级的重建任务，通过鼓励空间推理能力的发展以增强几何一致性。这一框架显著提升了3D空间感知多模态模型的训练效果，建立了新的训练模式。", "conclusion": "通过广泛的实验，Reg3D在ScanQA, Scan2Cap, ScanRefer和SQA3D数据集上的性能得到了显著提升，证明了其作为一种新的训练范式的有效性，特别是在3D空间感知层面。"}
{"llm_update_time": "20250906", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.02077", "html_url": "https://arxiv.org/abs/2509.02077", "title": "基于短语变换器的方法从攻击描述到漏洞", "title_en": "From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach", "authors": "Refat Othman,Diaeddin Rimawi,Bruno Rossi,Barbara Russo", "background": "在安全领域，即使攻击已发生，漏洞仍然常常未被发现。该文中的漏洞是指在公共披露的漏洞列表中（如CVE报告）记录的漏洞。建立攻击与漏洞之间的关联对于及时响应事件至关重要，因为这可以为防御者提供即时且可操作的洞察。然而，手动将攻击映射到CVE是不切实际的，因此需要自动化方法。研究评估了14种最新的句子变换器模型，以自动识别从攻击描述中获得的漏洞。研究表明，受多问-mpnet-基底点积-v1 (MMPNet) 模型在使用攻击技术描述时表现出色，F1分数为89.0，精确度为84.0，召回率为94.7。另外，研究发现，MMPNet模型识别出的56%的漏洞也是在关联攻击的情况下出现在CVE库中的，而该模型检测到的61%的漏洞也对应于CVE库中的记录。手动检查结果表明，该模型预测了275个未记录在MITRE库中的关联链接。因此，将攻击技术与漏洞自动关联不仅提高了软件安全事件的检测和响应能力，还减少了漏洞在被利用之前的时间，从而推动了更安全系统的建设。", "innovation": "通过评估14种最先进的句子变换器模型，表明MMPNet模型在将攻击技术描述与漏洞自动关联方面表现出色。F1分数达到89.0，精确度为84.0，召回率为94.7。通过这种方式，不仅提高了对软件安全事件的检测和响应能力，还减少了漏洞被利用的时间，自动化过程还发现了一些未记录在MITRE库中的潜在关联关系。", "conclusion": "自动化将攻击技术与漏洞关联的方法不仅可以增强对软件安全事件的检测和响应能力，还能缩短漏洞被利用的时间，从而有助于构建更安全的系统。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03631", "html_url": "https://arxiv.org/abs/2509.03631", "title": "轻量级图像分割用于超声心动图", "title_en": "Lightweight image segmentation for echocardiography", "authors": "Anders Kjelsrud,Lasse Løvstakken,Erik Smistad,Håvard Dalen,Gilles Van De Vyver", "background": "左心室分割的精确性可以实现自动提取临床测量数据（如容积和射血分数）的功能。尽管nnU-Net配置的模型表现良好，但其体型庞大且运行缓慢，限制了其在实时应用中的使用。通过消除研究、逐步评估数据增强方案、网络架构修改、损失函数和后处理技术，我们确定了对心脏分割最有效的组件。研究结果表明，简单的仿射增强和深度监督可驱动性能提升，而复杂的增强和大模型容量则效果递减。", "innovation": "基于上述洞见，我们开发了一个轻量级U-Net（参数量为2M，而默认nnU-Net配置有33M），该模型在CAMUS数据集（N=500）上的表现与nnU-Net统计学上等效，Dice分数分别为0.93/0.85/0.89（对比nnU-Net为0.93/0.86/0.89，P>0.05），模型大小仅为默认nnU-Net的1/16，运行速度快4倍（每帧1.35ms，对默认nnU-Net的5.40ms），同时在内部数据集（N=311）上表现出良好的泛化能力", "conclusion": "该轻量级U-Net在保持高分割性能的同时，显著减少了模型的大小和运行时间，使其更加适用于实时应用。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03786", "html_url": "https://arxiv.org/abs/2509.03786", "title": "SLENet: 一种增强指导网络用于水下伪装目标检测", "title_en": "SLENet: A Guidance-Enhanced Network for Underwater Camouflaged Object Detection", "authors": "Xinxin Wang,Han Sun,Ningzhong Liu,Huiyu Zhou,Yinan Yao", "background": "水下伪装目标检测（UCOD）旨在识别与水下环境融为一体的目标。这一任务对海洋生态学至关重要，但因光学畸变、水体浑浊以及海洋生物的复杂特性，准确识别受到严重阻碍。", "innovation": "提出了一个新的框架SLENet，其中包括Gamma-不对称增强（GAE）模块和定位指导分支（LGB），以增强多尺度特征表示并生成富含全局语义信息的位置图。该图引导多尺度监督解码器（MSSD）产生更准确的预测。实验证明，SLENet在DeepCamo数据集和三个基准COD数据集上都优于现有方法，并且具有广泛的适用性。", "conclusion": "SLENet在深水伪装目标检测方面表现出优越性能，且具有很强的通用性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03704", "html_url": "https://arxiv.org/abs/2509.03704", "title": "QuantV2X: 一种全量化多智能体系统用于协同感知", "title_en": "QuantV2X: A Fully Quantized Multi-Agent System for Cooperative Perception", "authors": "Seth Z. Zhao,Huizhi Zhang,Zhaowei Li,Juntong Peng,Anthony Chui,Zewei Zhou,Zonglin Meng,Hao Xiang,Zhiyu Huang,Fujia Wang,Ran Tian,Chenfeng Xu,Bolei Zhou,Jiaqi Ma", "background": "通过车辆对一切（V2X）通信进行合作感知，能够显著增强车辆感知能力，通过解决遮挡问题并扩大视野。然而，过去的大部分研究侧重于提高准确性度量，而忽视了系统级效率、延迟和实际部署性等因素的考虑。特别是大多数现有的系统依赖于全精度模型，这导致了较高的计算和传输成本，使得它们在资源受限的环境中不适合实时操作。", "innovation": "引入了QuantV2X，这是一种完全量化且专门为多模态、多智能体V2X合作感知设计的高效可扩展系统。QuantV2X提出了一种统一的端到端量化策略，同时减少了计算负载和传输带宽。尽管在低比特率的限定下，QuantV2X的准确性仍然与全精度系统相当，且在基于实际部署的度量标准下，它将系统级延迟降低了3.2倍，同时在mAP30指标上比全精度基线提高了9.5%。此外，QuantV2X能够更有效地扩展，使更大、更强大的模型能够在严格的内存预算中运行。这些结果表明，全量化多智能体中间融合系统在实际部署中的可行性。", "conclusion": "这些结果表明，全量化多智能体中间融合系统在实际部署中的可行性。系统将向公众发布，以促进该领域的研究：this https URL。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03754", "html_url": "https://arxiv.org/abs/2509.03754", "title": "STA-Net: 一种解耦形变和纹理注意力网络的轻量级植物病害分类模型", "title_en": "STA-Net: A Decoupled Shape and Texture Attention Network for Lightweight Plant Disease Classification", "authors": "Zongsen Qiu", "background": "随着全球对粮食安全需求的增加，精确农业和基于深度学习的植物病害诊断变得至关重要。然而，在边缘设备上部署高精度模型存在挑战。现有的轻量级网络大多使用通用物体识别设计的注意力机制，这些机制难以捕捉植物病理特征，如不规则的病斑形状和复杂的纹理。", "innovation": "本文提出了一种两步解决方案：第一，使用无训练的神经架构搜索方法（DeepMAD）为边缘设备创建高效的网络骨干；第二，引入形变-纹理注意力模块（STAM）。STAM将注意力机制分为两个分支：一个使用可变形卷积（DCNv4）增强形状意识，另一个使用Gabor滤波器组增强纹理意识。在公开的数据集中，STA-Net模型（参数量为401K，运算量为51.1M FLOPs）达到了89.00%的精度和88.96%的F1分数，实验证明STAM显著优于基线和标准注意力模型。", "conclusion": "通过解耦注意力机制整合领域知识，为边缘部署的精确农业AI提供了有希望的发展路径。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03740", "html_url": "https://arxiv.org/abs/2509.03740", "title": "Singular Value Few-shot Adaptation of Vision-Language Models", "title_en": "Singular Value Few-shot Adaptation of Vision-Language Models", "authors": "Taha Koleilat,Hassan Rivaz,Yiming Xiao", "background": "现有的视觉-语言模型（VLMs），如CLIP，展示了跨多种应用的令人印象深刻的零样本和少样本学习能力。然而，将这些模型适应到新的细粒度领域仍然非常困难，这主要是因为依赖于定制提示工程，以及全模型微调的高昂成本。现有的适应方法依赖于增强组件，如提示标记和适配模块，这些可能限制了适应质量，使模型不稳定，影响其预训练期间获取的丰富知识。", "innovation": "本文介绍了CLIP-SVD，一种新颖的多模态和参数高效适应技术，利用奇异值分解（SVD）修改CLIP的内部参数空间，而无需注入额外模块。具体来说，只调整CLIP参数矩阵的奇异值来重新调整基向量，以支持领域适应，同时保留预训练模型。该设计通过仅使用模型总参数的0.04%就能实现增强的适应性能，并更好地保持其泛化能力。CLIP-SVD在11个自然和10个生物医学数据集上实现了最先进的分类结果，在少样本设置中，其准确性和泛化能力超过之前的方法。", "conclusion": "CLIP-SVD利用自然语言方法来分析CLIP适应的有效性和动态，以提高样本可解释性。所有代码已在该项目网站上公开。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03794", "html_url": "https://arxiv.org/abs/2509.03794", "title": "将图像扩散模型应用于视频数据集", "title_en": "Fitting Image Diffusion Models on Video Datasets", "authors": "Juhun Lee,Simon S. Woo", "background": "现有的图像扩散模型是在独立采样的静态图像上进行训练的。虽然这是生成模型的基础任务规范，但仅依赖静态快照来捕捉动态世界会损失大量信息，导致收敛速度慢、分布覆盖不足以及泛化能力有限。因此，本文旨在通过利用视频帧中固有的时间推断偏置来改进扩散训练，从而解决以上问题。", "innovation": "本文提出了一种简单且有效的训练策略，不需要对架构进行任何修改，可以无缝地集成到标准的扩散训练管道中。这项策略利用了连续视频帧中的时间推断偏置，以提高扩散训练的效果。实验结果显示，该方法可以加速收敛2倍以上，同时在训练和验证分布上实现更低的FID分数，并提高了生成的多样性。此外，对优化进行了分析，证明了正则化降低了梯度方差，从而有助于加快收敛速度。", "conclusion": "本文通过提出的方法显著改善了图像扩散模型的训练效果，特别是在处理具有紧密时间段性和微妙手指操作差异的数据集（如HandCo）时，显示出更高的生成多样性和更快的收敛速度。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03883", "html_url": "https://arxiv.org/abs/2509.03883", "title": "Human Motion Video Generation: A Survey", "title_en": "Human Motion Video Generation: A Survey", "authors": "Haiwei Xue,Xiangyang Luo,Zhanghao Hu,Xin Zhang,Xunzhi Xiang,Yuqin Dai,Jianzhuang Liu,Zhensong Zhang,Minglei Li,Jian Yang,Fei Ma,Zhiyong Wu,Changpeng Yang,Zonghong Dai,Fei Richard Yu", "background": "近年来，人类运动视频生成因其广泛的应用前景吸引了大量研究兴趣，推动了一系列创新，如逼真的唱歌头部或跟随音乐流畅舞蹈的动态头像。然而，现有的相关研究多集中在单一方法上，缺乏对整个生成过程的全面概述。因此，本文致力于弥补这一空白，通过深入调查人类运动视频生成的各个阶段，涵盖了超过十项子任务，并详细描述了生成过程中的五个关键阶段：输入、运动规划、运动视频生成、细化和输出。", "innovation": "本文是首次探讨大规模语言模型在提高人类运动视频生成能力方面的潜在应用的调查。我们对人类运动视频生成领域的最新发展和技术趋势进行了全面梳理，重点关注视觉、文本和音频三种主要模态，并通过回顾超过两百篇论文，提供了一个全面的领域概述，同时指出了促进重大技术突破的关键研究工作。", "conclusion": "本调查旨在揭示人类运动视频生成的前景，并为推进数字人类的综合应用提供有价值的资源。本文中研究模型的完整清单可以在我们库中找到：this https URL"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03616", "html_url": "https://arxiv.org/abs/2509.03616", "title": "通过表示学习处理多属性偏差", "title_en": "Multi Attribute Bias Mitigation via Representation Learning", "authors": "Rajeev Ranjan Dwivedi,Ankur Kumar,Vinod K Kurmi", "background": "现实世界图像中经常存在多种重叠偏差，包括纹理、水印、性别妆容、场景对象配对等。这些偏差共同影响现代视觉模型的表现，削弱了它们的稳健性和公平性。单独解决这些偏差是不够的，因为缓解一种偏差往往会导致或加剧其他偏差。已有方法在组内不平衡和样本分布变化的情况下，现有的偏差度量失效。因此，本文提出了一种全新的应对多属性偏差的解决方案，即Generalized Multi Bias Mitigation (GMBM)，它是一个仅在训练时需要分组标签并在测试时最小化偏差的轻量级两阶段框架。GMBM包含两个阶段：首先，通过构建和整合每个属性的编码器以识别已知捷径的影响来调整偏差；其次，从主干网络的梯度中删除被识别出的偏差方向，形成一个小型网络，该网络可以忽略所有识别出的偏差。本文还提出了一种新的测试时度量方法，即Scaled Bias Amplification (SBA)，这种度量方法能够区分模型引入的偏差放大和分布差异。这一框架在Facebook CMNIST，CelebA和COCO数据集上进行了验证，有效提升了最差组的准确性，提高了多种属性偏差的减弱程度，并在偏差复杂性和分布变化增强的情况下，仍保持了SBA的新低值，展现了GMBM作为首个用于视觉识别的端到端多偏差解决方案的实际可行性。", "innovation": "本文提出了一种新的解决多属性偏差的框架GMBM，它包含两个阶段：首先，通过构建和整合每个属性的编码器以识别已知捷径的影响来调整偏差；其次，从主干网络的梯度中删除被识别出的偏差方向，形成一个小型网络，该网络可以忽略所有识别出的偏差。此外，还提出了一个新的测试时度量方法SBA，用于分离模型引入的偏差放大和分布差异。GMBM是首个用于视觉识别的端到端多偏差解决方案，能够在复杂偏差和分布变化的情况下保持良好的性能表现。同时，GMBM需要的标记较少，进一步降低了训练成本。", "conclusion": "本文提出的GMBM是一种轻量级的两阶段框架，能够在测试时不依赖于分组标签的情况下，有效地减少多种属性偏差。通过在现实数据集上的验证，GMBM不仅显著提高了最差组的准确性，还有效地降低了多种属性偏差的放大程度，并在全球偏差放大度量上达到了新低，证明了其在实际应用中的可行性和优越性。GMBM在视觉识别任务中展现了强大的处理多属性偏差的能力，为未来的研究提供了新的思路和方法。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03887", "html_url": "https://arxiv.org/abs/2509.03887", "title": "OccTENS：基于时间下一级预测的3D占据世界模型", "title_en": "OccTENS: 3D Occupancy World Model via Temporal Next-Scale Prediction", "authors": "Bu Jin,Songen Gu,Xiaotao Hu,Yupeng Zheng,Xiaoyang Guo,Qian Zhang,Xiaoxiao Long,Wei Yin", "background": "传统的占据世界模型在生成高保真长期占据场景时面临效率低、长期生成的时序退化和缺乏可操控性的问题。虽然基于自回归的方法可以在历史观察中同时预测车辆运动和未来的占据场景，但这些方法通常效率低下，长期生成时出现问题，并且缺乏可控制性。", "innovation": "提出了OccTENS，一种生成占据世界模型，能够实现可控、高保真长期占据生成，同时保持计算效率。OccTENS通过将时间序列建模问题分解为尺度依赖的生成建模和时间场景预测计算效率，利用TensFormer有效管理时间因果性和空间关系，并提出了一种整体姿态聚合策略，实现了占用和自身运动的统一序列建模。", "conclusion": "实验结果表明，OccTENS在更高的占据质量和更快的推理时间方面优于当前最先进的方法。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03803", "html_url": "https://arxiv.org/abs/2509.03803", "title": "通过视觉粒化指导因果推理的视觉语言模型提示学习", "title_en": "Causality-guided Prompt Learning for Vision-language Models via Visual Granulation", "authors": "Mengyu Gao,Qiulei Dong", "background": "提示学习最近引起了对适应预训练的视觉-语言模型（例如CLIP）到下游识别任务的极大关注。然而，现有的基于CLIP的提示学习方法在处理细粒度数据集时仅表现出有限的能力。", "innovation": "本文提出了一种通过视觉粒化指导的因果推理文本提示学习方法，称为CaPL。该方法包含两个模块：（1）一个属性解耦模块，利用布朗桥扩散模型将视觉特征分解为非个体属性（共享多个类别的属性）和个体属性（特定于单一类别的属性）；（2）一个粒度学习模块，通过上述属性的集成，在两种因果推理策略下构建视觉粒度，以实现识别。通过学习到的视觉粒度，期待能够获得更具区别的文本提示。实验结果表明，本文的CaPL方法显著优于最先进的提示学习方法，尤其是在处理细粒度数据集方面。", "conclusion": "本文提出的CaPL方法在15个数据集上的广泛实验结果表明，该方法在尤其在处理细粒度数据集时，显著优于最先进的提示学习方法。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03897", "html_url": "https://arxiv.org/abs/2509.03897", "title": "SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation", "title_en": "SPECS: Specificity-Enhanced CLIP-Score for Long Image Caption Evaluation", "authors": "Xiaofu Chen,Israfel Salazar,Yova Kementchedjhieva", "background": "随着生成长而详细的图像描述的兴趣增加，标准的评估指标变得越来越不可靠。虽然基于n-gram的方法效率高，但它们未能捕捉到语义正确性。设计用于解决这一问题的表示相似性（RS）指标，因计算成本高而起初使用受限，尽管硬件有所进步，它们仍因与人类判断的相关性低而不受欢迎。目前，基于大型语言模型（LLMs）的度量标准与人类判断高度相关，但成本过高，不适合模型开发过程中的迭代使用。", "innovation": "本文介绍了一种名为SPECS（Specificity-Enhanced CLIPScore）的无参考的RS度量标准，特别针对长图像描述评估。SPECS通过将CLIP与新的优化目标相结合，强调具体性，鼓励正确的细节并惩罚错误的描述。研究表明，SPECS在评估图像描述模型时与开源LLM基度量标准在与人类判断的相关性上表现一致，但在效率上远超后者。", "conclusion": "SPECS作为一种实用的迭代评估替代方案，在图像描述模型开发过程中具有实际应用价值。相应代码可在[提供的链接]中找到。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03808", "html_url": "https://arxiv.org/abs/2509.03808", "title": "EGTM: 事件引导的高效湍流抑制", "title_en": "EGTM: Event-guided Efficient Turbulence Mitigation", "authors": "Huanan Li,Rui Fan,Juntao Guan,Weidong Hao,Lai Rui,Tong Wu,Yikai Wang,Lin Gu", "background": "湍流抑制（TM）旨在通过帧相机去除大气湍流引入的随机失真和模糊。现有的基于深度学习的TM方法通过从多个退化的帧中提取湍流线索来寻找所谓的“幸运”无损的帧片段，进行幸运融合。然而，这种方法的学习需要大量帧率有限且随着时间尺度粗糙的帧来训练高容量网络，导致在计算和存储效率上不足。事件摄像机具备微秒级别的时间分辨率，具有潜在的能力来解决这一瓶颈，通过高效的稀疏和异步成像机制完全解决这一问题。", "innovation": "作者提出了事件引导的湍流抑制（EGTM）框架，该框架通过揭示湍流失真与事件流的逆时空分布之间的关系，从中提取像素级别的可靠无湍流指导，用于时间上的幸运融合。此外，作者还构建了首个湍流数据采集系统，提供了首个基于事件驱动的TM数据集。实验结果显示，与现有最先进的TM方法相比，其模型大小、推理延迟和模型复杂度分别提高了710倍、214倍和224倍，同时在作者建立的EGTM数据集上恢复质量也达到了最先进的水平，提升了0.94个PSNR和0.08个SSIM。", "conclusion": "引入事件模态到TM任务中展示了极大的效率优势。该工作的方法在模型规模、推理延迟和模型复杂性上都取得了显著的提升，同时在恢复质量上也超过了现有方法。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03872", "html_url": "https://arxiv.org/abs/2509.03872", "title": "聚焦于运动：RGB-事件协作可变稀疏化以提高效率的目标检测", "title_en": "Focus Through Motion: RGB-Event Collaborative Token Sparsification for Efficient Object Detection", "authors": "Nan Yang,Yang Wang,Zhanwen Liu,Yuchao Dai,Yang Liu,Xiangmo Zhao", "background": "现有的RGB-事件检测方法在特征提取和融合中，会对图像的低信息区域和事件数据中的非事件区域进行统一处理，这导致了高计算成本和次优性能。为了在特征提取阶段减少计算冗余，研究人员分别提出了针对图像和事件模态的可变稀疏化方法，但这些方法使用固定的节点数目或阈值进行稀疏化选择，对于不同复杂性的样本来说，会妨碍重要信息节点的保留。", "innovation": "本文提出了一种适应性协作稀疏化方法FocusMamba，通过利用事件摄像机感知到的场景内容变化，为每个模态识别并自适应地移除低信息区域。基于稀疏化结果，提出了一种跨模态焦点融合（CMFF）模块，以有效捕捉并整合来自两个模态的互补特征。实验表明，该方法在准确性和效率上都优于现有方法。", "conclusion": "在DSEC-Det和PKU-DAVIS-SOD数据集上的实验结果表明，提出的方法在准确性和效率方面都优于现有方法。已经公开了代码。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03873", "html_url": "https://arxiv.org/abs/2509.03873", "title": "SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition", "title_en": "SalientFusion: Context-Aware Compositional Zero-Shot Food Recognition", "authors": "Jiajun Song,Xiaoou Liu", "background": "食品识别研究取得了显著进展，但由于新菜品的快速涌现，需要发展能够识别未见过的食品类别的方法，推动了零样本食品学习（Zero-Shot Food Learning, ZSFL）的发展。然而，现有的零样本学习方法在处理食品识别时面临三个挑战：冗余背景信息会分散模型对有意义的食品特征的注意力；主食和配菜之间的角色混淆会导致分类错误；单一属性的语义偏见可能导致理解混淆。这些挑战为食品识别带来了新的研究需求和方向。", "innovation": "提出了一种名为SalientFusion的方法，用于解决组合零样本食品识别（Compositional Zero-Shot Food Recognition, CZSFR）中的三个挑战。该方法包括两个组成部分：SalientFormer，能够去除背景冗余并使用深度特征解决角色混淆；DebiasAT，通过使提示与视觉特征对齐来减少语义偏见。SalientFusion方法在新的基准数据集CZSFood-90和CZSFood-164上达到了最先进的性能，并在通用的组合零样本学习数据集上也取得了最好的结果。", "conclusion": "使用SalientFusion方法，该研究在CZSFood-90和CZSFood-164基准数据集上达到了最先进的性能，并且在通用的组合零样本学习数据集上也取得了最好的结果。该方法通过去除背景信息冗余、防止主食和配菜之间的角色混淆以及减少语义偏见来改进食品识别的效果。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03893", "html_url": "https://arxiv.org/abs/2509.03893", "title": "基于弱监督学习的密集功能对应学习", "title_en": "Weakly-Supervised Learning of Dense Functional Correspondences", "authors": "Stefan Stojanov,Linan Zhao,Yunzhi Zhang,Daniel L. K. Yamins,Jiajun Wu", "background": "在形状重建和机器人操作等任务中，跨图像对建立密集对应关系至关重要。在不同类别间的配对中，物体的功能，即物体对其他物体的影响，可以指导如何建立对应关系，因为能使特定功能的物体部分在形状和外观上往往具有相似性。因此，本文根据这一观察，提出了一种基于功能的密集对应关系定义，并采用弱监督学习框架进行预测任务。该方法利用视觉语言模型对多视角图像进行伪标签以获取功能部分，并结合像素对应关系的密集对比学习，将功能和空间知识融合到新的模型，以实现密集功能对应关系。", "innovation": "本文通过提出基于视觉语言模型的弱监督学习方法，获取功能部分，并结合像素对应关系的密集对比学习，将功能和空间知识融合到新模型中，以显著改善密集功能对应关系的建立。借助合成和真实的评估数据集作为任务基准，使得这种弱监督学习方法在密集功能对应学习中表现出色。", "conclusion": "实验结果表明，提出的基于弱监督学习的密集功能对应方法，在功能部分伪标签和稀疏功能与空间知识的结合方面优于基于即用型自我监督图像表示和具有语义信息的视觉语言模型的基础解决方案。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03951", "html_url": "https://arxiv.org/abs/2509.03951", "title": "ANTS: 使用大模型多模态语言模型（MLLM）塑造自适应负文本空间以提升异常分布检测", "title_en": "ANTS: Shaping the Adaptive Negative Textual Space by MLLM for OOD Detection", "authors": "Zhu Wenjie,Zhang Yabin,Xin Jin,Wenjun Zeng,Lei Zhang", "background": "现有的通过引入负标签（NLs）来增强异常分布外（OOD）检测的方法效果显著，但这些方法往往缺乏对外来图像的理解，难以构建精确的负空间，同时，假阴性标签的存在会对近异常分布（near-OOD）性能产生显著的负面影响。", "innovation": "本研究提出了一种通过利用大模型多模态语言模型（MLLMs）的理解和推理能力来塑造自适应负文本空间（ANTS）。特别地，识别可能为OOD样本的图像作为负图像并提示MLLM描述这些图像，生成能够精确描述OOD分布、增强远异常分布检测的表达性负句子。对于近异常分布场景，通过大模型推理能力生成与负图像视觉相似的配对负标签，减少假阴性，从而提升近异常分布检测。同时，设计了适应性加权评分，能在远异常分布和近异常分布不同OOD任务场景中无需依赖特定先验知识进行有效处理。", "conclusion": "在ImageNet基准测试中，我们的方法显著降低了FPR95（4.2%），达到了新的前沿水平。此外，我们的方法无需训练且为零样本，具备高可扩展性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03950", "html_url": "https://arxiv.org/abs/2509.03950", "title": "使用EfficientNet-B4迁移学习在U-Net架构中的胸部X射线气胸分割", "title_en": "Chest X-ray Pneumothorax Segmentation Using EfficientNet-B4 Transfer Learning in a U-Net Architecture", "authors": "Alvaro Aranibar Roque,Helga Sebastian", "background": "气胸是胸膜腔内异常积聚空气的情况，如果未被检测到，可能对生命构成威胁。胸部X光检查是首选的诊断工具，但小的气胸可能不够明显。因此，需要一种自动化的深度学习管道来准确分割出气胸区域，帮助放射科医生更快速准确地诊断病情。", "innovation": "提出了一种自动化深度学习管道，使用带有EfficientNet-B4编码器的U-Net模型来分割气胸区域。该模型通过SIIM-ACR数据集进行训练，并结合数据增强以及二元交叉熵和Dice损失的混合目标函数。在独立的PTX-498数据集上，该模型实现了0.7008的IoU值和0.8241的Dice分数，表明该模型能够准确识别气胸区域并支持放射科医生的工作。", "conclusion": "该研究表明基于深度学习的方法能够有效定位气胸，并为气胸的自动识别提供了有力支持。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03922", "html_url": "https://arxiv.org/abs/2509.03922", "title": "LMVC: 一种端到端的多视图视频编码框架", "title_en": "LMVC: An End-to-End Learned Multiview Video Coding Framework", "authors": "Xihua Sheng,Yingwen Zhang,Long Xu,Shiqi Wang", "background": "多视图视频是体积视频的关键数据源，能够实现沉浸式3D场景重建，但由于其庞大的数据量，存储和传输存在重大挑战。近年来，基于深度学习的端到端视频编码取得了巨大成功，但大多数研究集中在单视图或立体视频上，而一般化的多视图场景则被忽略了。这些传统视频编码方法难以应对多视图视频的数据量问题，无法满足随机访问和向后兼容的需求，同时压缩效率也未能得到提高。", "innovation": "本研究提出了一个端到端学习的多视图视频编码（LMVC）框架，以确保随机访问和向后兼容性的同时提高压缩效率。创新点在于有效利用独立视图的运动和内容信息来增强依赖视图压缩。具体而言，为了利用跨视图运动相关性，提出了基于特征的跨视图运动矢量预测方法，将依赖视图的运动编码条件化为解码后独立视图运动特征；为了利用跨视图内容相关性，提出了无立体图的跨视图上下文预测模块，从解码独立视图的内容特征中预测跨视图上下文，同时结合一个跨视图上下文熵模型来捕获跨视图上下文先验信息。", "conclusion": "实验结果显示，提出的LMVC框架在对传统MV-HEVC标准参考软件的性能上有显著改进，确立了未来在此领域研究的强Baseline。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03903", "html_url": "https://arxiv.org/abs/2509.03903", "title": "胸部X光生成基础模型", "title_en": "A Generative Foundation Model for Chest Radiography", "authors": "Yuanfeng Ji,Dan Lin,Xiyue Wang,Lu Zhang,Wenhui Zhou,Chongjian Ge,Ruihang Chu,Xiaoli Yang,Junhan Zhao,Junsong Chen,Xiangde Luo,Sen Yang,Jin Fang,Ping Luo,Ruijiang Li", "background": "医疗领域中高质量标注的多样医学图像稀缺是开发可靠AI模型的一大障碍。自然图像生成的基础模型在技术上取得了显著进展，但尚缺乏针对医学图像的类似进展。本文介绍了一种名为ChexGen的生成型视觉-语言基础模型，它在统一框架下支持文本、掩码和边界框引导的胸部X光图像生成。ChexGen基于潜在扩散变换器架构，在迄今为止最大的胸部X光数据集上进行了预训练，该数据集包含了960,000个X光报告成对数据，从而实现医学图像的精准合成，并旨在通过数据增强和监督预训练提高模型的性能和公平性，特别是在疾病分类、检测和分割任务中，使用少量的训练数据即可实现性能提升。此外，ChexGen还能创造多样化的患者群体，减少和化解模型中的人口统计学偏见。该研究支持了生成型基础模型在构建更准确、更高效和更公平的医疗AI系统中的变革性作用。", "innovation": "开发了一个名为ChexGen的生成型视觉-语言基础模型，它在统一框架下支持文本、掩码和边界框引导的胸部X光图像生成。该模型在潜在扩散变换器架构上进行了基于最大规模的胸部X光数据集的预训练，实现了高度准确的合成性能，可用于提高疾病分类、检测和分割任务的模型性能，并促进了多样化的患者群体的创建，减少了人口统计学偏见。", "conclusion": "ChexGen为生成更准确、更高效和更公平的医疗AI系统奠定了基础。其通过数据增强和监督预训练提高了医学图像任务中的模型性能，并创建多样化的患者人群以减轻人口统计学偏见。此项研究支持了生成型基础模型在医疗AI领域的广泛应用。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03895", "html_url": "https://arxiv.org/abs/2509.03895", "title": "Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of Vision-Language Model", "title_en": "Attn-Adapter: Attention Is All You Need for Online Few-shot Learner of Vision-Language Model", "authors": "Phuoc-Nguyen Bui,Khanh-Binh Nguyen,Hyunseung Choo", "background": "对比视觉-语言模型在零样本图像识别中表现出色，但在少样本场景中面临挑战，由于使用提示学习进行耗时的离线微调，这可能导致过拟合。因此，现有方法面临计算成本高和潜在的过拟合风险。", "innovation": "本文提出了一种新颖的在线少样本学习框架Attn-Adapter，通过双注意力机制增强CLIP的适应性。该设计包含两个组件：Memory Attn-Adapter 通过对支持样本改进类别嵌入，Local-Global Attn-Adapter 通过融合局部和全局特征丰富图像嵌入。这使得可以从少量标注样本动态适应，而无需重新训练基础模型。", "conclusion": "Attn-Adapter 在跨类别和跨数据集泛化方面优于最先进的方法，同时保持高效推理并适用于不同的CLIP基础模型。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03938", "html_url": "https://arxiv.org/abs/2509.03938", "title": "TopoSculpt: Betti-Steered Topological Sculpting of 3D Fine-grained Tubular Shapes", "title_en": "TopoSculpt: Betti-Steered Topological Sculpting of 3D Fine-grained Tubular Shapes", "authors": "Minghui Zhang,Yaoyu Liu,Junyang Wu,Xin You,Hanxiao Zhang,Junjun He,Yun Gu", "background": "医疗中的管状解剖结构本质上是三维通道，具有腔室、壁和复杂的分支拓扑。准确重建其几何结构和拓扑结构对于气管导航和大脑动脉连接评估等应用场景至关重要。现有方法通常依赖于体素级别的重叠度量，这些方法未能捕捉拓扑正确性和完整性。虽然拓扑感知损失和持久同调约束显示出潜力，但它们通常应用于局部区域，无法保证全局一致性和在推断时正确几何错误的保存。", "innovation": "本文提出了一种新的TopoSculpt框架，用于3D细粒度管状结构的拓扑细化。TopoSculpt通过使用整体区域建模策略捕捉完整的空间上下文，首次引入了拓扑完整性贝蒂数（TIB）约束来共同施加贝蒂数先验和全局完整性，并采用持续训练方案结合持久同调来逐步从粗到细尺度纠正错误。实验结果表明，这种框架在几何和拓扑方面都显著改进了复杂3D管状解剖结构的高精度建模能力。", "conclusion": "在挑战性的肺气道和Willis环数据集上的广泛实验显示，TopoSculpt在拓扑属性方面取得了重大改进，例如，在肺气道数据集上$\beta_{0}$误差降低了95.4%，在Willis环数据集上降低了81.8%，分支检测率提高了近10%。这些结果突显了TopoSculpt在纠正关键拓扑错误方面的有效性，并推动了复杂3D管状解剖结构的高保真建模。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03633", "html_url": "https://arxiv.org/abs/2509.03633", "title": "treeX：在稠密森林点云中无监督树木实例分割", "title_en": "treeX: Unsupervised Tree Instance Segmentation in Dense Forest Point Clouds", "authors": "Josafat-Mattias Burmeister,Andreas Tockner,Stefan Reder,Markus Engel,Rico Richter,Jan-Peter Mund,Jürgen Döllner", "background": "近景激光扫描能够提供详细的森林景观三维捕获，但需要有效的软件来处理三维点云数据和提取个体树木。虽然最近的研究引入了深度学习方法进行树实例分割，但这些方法需要大规模的标注数据集和大量的计算资源。为了资源高效地处理这些需求，研究人员提出了一种无监督的树X算法的修订版本，该算法结合了基于聚类的主干检测与区域生长法的树冠界定。", "innovation": "修订后的树X算法提供两种参数预设，一种适用于地面激光扫描（静止机载-TLS和个人激光扫描-PLS），另一种适用于无人机激光扫描（ULS）。该方法在六组公开数据集上进行了评估，与开源方法相比提高了准确性。特别是在无人机激光扫描数据方面，修订后的算法表现出更好的性能，而原始算法无法分割任何正确的实例。", "conclusion": "修订后的树X算法具有两个主要应用：（1）作为一种在数据特征符合方法设计要求（足够的主干可见度和点密度）场景中的资源高效替代深度学习方法的方案；（2）用于深度学习模型标签的半自动生成。为促进更广泛的采用，该算法提供了开源Python实现，集成在pointtree包中。”/documents/18.json?token=2ceKaQN4NZkHS7PsC1i9JzFLukhsHfJ0iqyjabS6x0UlFASRSAoVC0dCThAVkteakPAVZmoEcDZGJnOi6JAA&page=506"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04023", "html_url": "https://arxiv.org/abs/2509.04023", "title": "学习多数标签：一类新的多类多重实例学习问题", "title_en": "Learning from Majority Label: A Novel Problem in Multi-class Multiple-Instance Learning", "authors": "Shiku Kaito,Shinnosuke Matsuo,Daiki Suehiro,Ryoma Bise", "background": "多重实例学习（MIL）问题在诸如病理图像分割、政治投票预测、客户服务分析和环境监测等多种应用中具有重要价值。然而，现有的MIL方法通常针对的是每个实例的级别标签，而不是整个袋子的多数类别标签。所提的Learning from Majority Label（LML）问题定义了在这种背景下生成袋子级别标签的新挑战。", "innovation": "本文提出了一种新的LML问题，其特征是将袋子中实例的多数类标签作为袋子级别的标签。为了解决LML问题，提出了一个计数网络，用于通过计算每个类别的实例数量来生成袋子级别的多数标签。此外，通过分析实验揭示了高比例多数类的袋子对学习的促进作用，并据此开发了一种 majority proportion enhancement module (MPEM)，通过移除袋子中少数类实例来增加多数类的比例。实验证明，所提出的方法在四个数据集上优于传统MIL方法，并且消融研究证实了每个模块的有效性。", "conclusion": "所提出的方法在LML问题上优于传统MIL方法， experiments demonstrate the superiority of the proposed method on four datasets compared to conventional MIL methods. 实现代码已提供，可在此处访问。本研究不仅提出了一个新的MIL问题，还提供了一个强大的解决方案，展示了对现有方法的改进和补充。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03961", "html_url": "https://arxiv.org/abs/2509.03961", "title": "多模态特征融合网络与文本差异增强方法在遥感变化检测中的应用", "title_en": "Multimodal Feature Fusion Network with Text Difference Enhancement for Remote Sensing Change Detection", "authors": "Yijun Zhou,Yikui Zhai,Zilu Ying,Tingfeng Xian,Wenlve Zhou,Zhiheng Zhou,Xiaolin Tian,Xudong Jia,Hongsheng Zhang,C. L. Philip Chen", "background": "尽管深度学习推动了遥感变化检测的进步，但大多数方法仅依赖图像模态，限制了特征表示、变化模式建模和泛化能力，特别是在光照和噪声干扰下。现有的方法缺乏跨模态的深度融合，未能有效结合图像和文本双重信息，特别是在特征表示和变化模型方面存在局限性，限制了系统的鲁棒性和准确性。因此，迫切需要一种能够充分挖掘图像和文本信息潜在价值的方法来提升变化检测的性能和稳定性。", "innovation": "本文提出了一种名为MMChange的多模态遥感变化检测方法，该方法结合了图像和文本模态的信息以增强准确性和鲁棒性。通过引入图像特性细化（IFR）模块突出关键区域并抑制环境噪声，利用视觉语言模型（VLM）生成双时相图像的语义描述，以及通过文本差异增强（TDE）模块捕捉细微的语义变化引导模型识别有意义的变化。为了弥合模态间的异质性，设计了一种图像文本特征融合（ITFF）模块，实现深度跨模态集成。实验结果表明，在LEVIRCD、WHUCD和SYSUCD数据集上，MMChange的方法在一串评价指标上均超过了最先进的方法，验证了其在多模态变化检测中的有效性。", "conclusion": "本文提出了MMChange，一种结合图像和文本模态的遥感变化检测方法。该方法通过图像特性细化、视觉语言模型生成语义描述和文本差异增强等步骤实现了跨模态的融合。实验结果证实了该方法在多个数据集和指标上的优越性能，提高了变化检测的准确性和鲁棒性，展示了其在多模态变化检测中的潜力和效率。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03973", "html_url": "https://arxiv.org/abs/2509.03973", "title": "SAC-MIL: 了解组织病理学全切片图像分类的空间感知相关多实例学习", "title_en": "SAC-MIL: Spatial-Aware Correlated Multiple Instance Learning for Histopathology Whole Slide Image Classification", "authors": "Yu Bai,Zitong Yu,Haowen Tian,Xijing Wang,Shuo Yan,Lin Wang,Honglin Li,Xitong Ling,Bo Zhang,Zheng Zhang,Wufan Wang,Hui Gao,Xiangyang Gong,Wendong Wang", "background": "作者提出了一种名为Spatial-Aware Correlated Multiple Instance Learning (SAC-MIL) 的方法，用于全切片图像（WSI）分类。传统的多实例学习方法通常对图像中的实例位置信息不敏感，且在处理不同长度的训练和测试序列时存在挑战。因此，作者设计了一个新模块来编码实例空间位置信息，并提出了一种能在线性时间内完成实例全面相关的新模块。这不仅提升了模型的准确性和有效性，还解决了传统方法在序列长度不一致时的难题，使得该方法具有较高的应用潜力和推广价值。", "innovation": "SAC-MIL主要创新点在于引入了一个位置编码模块和一个新型的SAC块。位置编码模块利用平台上实例的坐标来编码实例之间的空间关系，而不仅仅是实例在输入WSI序列中的索引。SAC块是一种基于MLP的方法，可以在线性时间内完成所有实例的相关性计算，与依赖于定制CUDA内核的Transformer方法相比，SAC-MIL更易于部署和实现。此外，SAC-MIL在CAMELYON-16、TCGA-LUNG和TCGA-BRAC等数据集上达到了最新性能。", "conclusion": "SAC-MIL方法在全切片图像分类任务上表现出色，并且在处理不同长度的序列数据时更加灵活和有效。此外，由于其简洁的构建和出色的性能，该方法具有广泛的应用潜力。作者表示代码将在文章接受后开源。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04043", "html_url": "https://arxiv.org/abs/2509.04043", "title": "基于'Phytium + Cambricon'的毫秒级响应跟踪与凝视系统：国产解决方案", "title_en": "Millisecond-Response Tracking and Gazing System for UAVs: A Domestic Solution Based on \"Phytium + Cambricon\"", "authors": "Yuchen Zhu,Longxiang Yin,Kai Zhao", "background": "当前的视频监控技术中，传统摄像头系统在动态场景下的响应延迟超过200毫秒，这是由于自动识别算法的深度特征提取能力不足和计算架构的效率瓶颈所致，无法满足复杂场景下的实时需求。", "innovation": "该研究提出了一种基于Phytium处理器和Cambricon加速卡的异构计算架构，构建了一个具有毫秒级响应能力的无人机跟踪和凝视系统。通过多卡并行计算，硬件层面采用了Phytium FT-2000/4处理器和MLU220加速卡的协作计算架构，软件层面则结合了轻量级的YOLOv5s检测网络和DeepSORT级联跟踪算法，形成了“检测-跟踪-反馈”的闭环控制链。", "conclusion": "实验结果显示，该系统在1920*1080分辨率视频流处理中实现了稳定的单帧综合处理延迟为50-100毫秒，多尺度目标识别精度超过98.5%，具备低延迟和高精度的特点，为无人机监控和国产芯片的应用提供了创新解决方案。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03986", "html_url": "https://arxiv.org/abs/2509.03986", "title": "Promptception: 大型多模态模型对提示有多敏感？", "title_en": "Promptception: How Sensitive Are Large Multimodal Models to Prompts?", "authors": "Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan", "background": "尽管近年来大型多模态模型（LMMs）在各种任务中取得了显著的成功，但对于这些模型在多项选择题答案生成（MCQA）中对提示设计的理解仍然很不清晰。研究表明，即使是提示语句和结构的细微变化也可能导致多达15%的准确率差异。这种变化性给透明和公平的LMM评估带来了挑战，因为模型往往会通过精心挑选的提示报告其最佳性能。因此，有必要开发一个系统性的评估框架来解决这一问题，尤其对于提示设计的敏感性作出系统化的评估。", "innovation": "本文提出了Promptception，这是一种系统性的框架，用于评估LMM的提示敏感性。该框架包括61种提示类型，涵盖了15个类别和6个超级类别，每个类别都针对提示构成的具体方面，并用于评估从轻量级开源模型到GPT-4o和Gemini 1.5 Pro在内的10种LMM，跨MMStar、MMMU-Pro和MVBench 3个MCQA基准。研究发现，专有模型比开源模型对提示语句表现出了更大的敏感性，反映了与指令语义更紧密的对齐，而开源模型则相对稳定，但在处理复杂的提示语句上却有困难。", "conclusion": "根据这项分析结果，提出了适用开源和专有LMM的提示原则，以实现更强大和公平的模型评估。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04086", "html_url": "https://arxiv.org/abs/2509.04086", "title": "TEn-CATS: 多尺度类别感知时空图的文本增强音频-视觉视频解析", "title_en": "TEn-CATS: Text-Enriched Audio-Visual Video Parsing with Multi-Scale Category-Aware Temporal Graph", "authors": "Yaru Chen,Faegheh Sardari,Peiliang Zhang,Ruohao Guo,Yang Xiang,Zhenbo Li,Wenwu Wang", "background": "现有的AVEVP任务方法主要分为两种类型：一是基于注意力机制设计增强的架构以更好地建模时间信息；二是生成更丰富的伪标签以弥补帧级注解的缺失。然而，第一类方法将嘈杂的段级伪标签视为可靠的监督，第二类方法则让非特异的注意力使错误在整个帧中扩散，这会导致初始错误在训练过程中被放大。", "innovation": "本文提出了一种结合双向文本融合（BiT）模块和类别感知时空图（CATS）模块的方法。首先，通过BiT模块对音频和视觉模态特征进行语义注入和动态校准，以定位和净化更为清洁和丰富的语义线索；然后，利用CATS模块进行语义传播和连接，以实现精确的语义信息跨时间的传播。实验结果表明，该方法在两个基准数据集LLP和UnAV-100上多项关键指标上达到了最佳性能。", "conclusion": "该方法通过结合双向文本融合和类别感知时空图模块，提高了音频-视觉视频解析的精度和鲁棒性，特别是在处理弱监督标签的数据集上表现优异。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03999", "html_url": "https://arxiv.org/abs/2509.03999", "title": "SliceSemOcc: 基于垂直切片的多模态3D语义占用表示", "title_en": "SliceSemOcc: Vertical Slice Based Multimodal 3D Semantic Occupancy Representation", "authors": "Han Huang,Han Sun,Ningzhong Liu,Huiyu Zhou,Jiaquan Shen", "background": "随着自动驾驶对精确3D感知的需求，3D语义占用预测已成为关键研究领域。与鸟瞰图（BEV）方法仅限制场景表示在二维平面上不同，占用预测利用完整的三维体素网格来建模所有维度的空间结构，从而捕捉垂直轴上的语义变化。然而，大多数现有的方法在处理体素特征时忽略了高度轴信息。传统的SENet样式的通道注意力在所有高度层上分配均匀权重，限制了它们在强调不同高度的特征方面的能力。为解决这些问题，我们提出了SliceSemOcc，一种基于垂直切片的多模态框架，用于3D语义占用表示。", "innovation": "SliceSemOcc框架使用全局和局部垂直切片提取沿高度轴的体素特征，提出了全局局部融合模块以适应性地协调细粒度的空间细节和全局上下文信息。我们还提出了SEAttention3D模块，通过平均池化保留高度方向的分辨率，并为每个高度层分配动态通道注意力权重。在nuScenes-SurroundOcc和nuScenes-OpenOccupancy数据集上的广泛实验验证了我们的方法显著提高了平均IoU，尤其是在大多数小型物体类别上的显著提升。详细的消融研究进一步验证了所提出的SliceSemOcc框架的有效性。", "conclusion": "我们的方法显著提升了平均IoU，尤其是在大多数小型物体类别上。详细的消融研究进一步验证了所提出的SliceSemOcc框架的有效性，证明它能够更好地利用垂直切片进行3D语义占用预测，从而改进了自动驾驶中的3D感知性能。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03800", "html_url": "https://arxiv.org/abs/2509.03800", "title": "MedVista3D: 视觉语言模型在减少3D CT疾病检测、理解和报告中的诊断错误", "title_en": "MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting", "authors": "Yuheng Li,Yenho Chen,Yuxiang Lai,Jike Zhong,Vanessa Wildman,Xiaofeng Yang", "background": "在临床上，放射学诊断错误如遗漏、无意识忽视和交流失误仍然普遍存在。这些问题往往源于局部异常的遗漏、缺乏全局上下文以及报告语言的不一致性。3D成像中，临床医生需要检查每项扫描数百个切片，这增加了误诊的风险。目前的3D视觉语言模型尚无法满足这些需求，缺乏局部与全局理解，难以处理没有经过筛选的医学报告中的变异性与噪声。因此，需要一种能精确定位局部异常、全局上下文推理及语义一致的自然语言报告的系统。", "innovation": "MedVista3D是一种多尺度语义增强的视觉语言预训练框架，用于3D CT分析。它通过局部和全局图像-文本对齐实现细粒度的语义表示学习，同时在全体积上下文中进行疾病检测和整体解释。MedVista3D还引入了语义匹配银行和语言模型重写，以应对报告中语义的多样性。该模型在零样本疾病分类、报告检索和医学视觉问答等任务上取得最先进的性能，并且在器官分割和预后预测中具有良好的迁移能力。", "conclusion": "MedVista3D能够有效地减少3D CT检测中的诊断错误，通过对图像和文本的多尺度语义学习，提高了疾病检测的精度和理解的深度，并且其性能在多个医学任务上超过现有模型，展示了在临床实践中实际应用的潜力。为此模型的代码和数据集已被公开。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04009", "html_url": "https://arxiv.org/abs/2509.04009", "title": "通过标记丢弃检测视觉变换器中的区域谬误相关性", "title_en": "Detecting Regional Spurious Correlations in Vision Transformers via Token Discarding", "authors": "Solha Kang,Esla Timothy Anzaku,Wesley De Neve,Arnout Van Messem,Joris Vankerschaver,Francois Rameau,Utku Ozbulak", "background": "由于基于神经网络的计算机视觉模型具有强大的特征关联能力，它们有可能基于错误或未有意但统计学上相关的信号检测和利用数据中的非意图模式，从而导致正确的预测。这些信号可能从简单的颜色偏差到图片中的小文字皆有。当这些非意图信号与预测任务对齐时，模型可能会错误地将这些特征与任务联系起来并依赖它们进行预测。这种现象被称为谬误相关，即看起来与任务相关但实际上只是巧合。因此，检测和缓解谬误相关性已经成为建立可信赖、可靠和泛化性好的机器学习模型的关键任务。", "innovation": "本文介绍了一种新颖的方法来检测视觉变换器中的区域谬误相关性。该方法使用监督和自监督训练模型，并展示了在ImageNet数据集上的大规模实验，证明了该方法能够识别谬误相关性。研究表明，即使使用相同的架构，训练方法对模型依赖谬误相关性的影响也很大。同时，论文还指出ImageNet数据集中某些类别的图像包含易于被模型检测到的谬误信号，并探讨了这些谬误信号背后的原因。基于这些发现，研究提供了详尽的图像列表，并呼吁在未来的研究中谨慎使用这些图像。此外，还进行了一项关于侵入性乳腺肿瘤分类中谬误信号的案例研究，将研究工作与现实场景相结合。", "conclusion": "本文展示了一种针对视觉变换器检测区域谬误相关性的新方法，并通过大规模实验验证了该方法的有效性。研究表明，训练方法对模型依赖谬误相关性的敏感性很高。特定类别的图像中存在易于被模型检测到的谬误信号，未来的研究应谨慎使用这些图像。最后，案例研究表明，谬误信号在实际应用中也存在，强调了该问题的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03975", "html_url": "https://arxiv.org/abs/2509.03975", "title": "利用多任务学习和仅在模型训练期间可用的辅助数据改进血管分割", "title_en": "Improving Vessel Segmentation with Multi-Task Learning and Auxiliary Data Available Only During Model Training", "authors": "Daniel Sobotka,Alexander Herold,Matthias Perkonigg,Lucian Beer,Nina Bastati,Alina Sablatnig,Ahmed Ba-Ssalamah,Georg Langs", "background": "肝脏血管在磁共振成像数据中的分割对血管重塑的计算分析至关重要，这与各种弥漫性肝脏疾病的关联广泛。现有的方法依赖于对比增强的影像数据，但需要专门的成像序列，并不是统一获取。尽管更多的无对比增强的影像数据被频繁获取，但对血管进行分割具有挑战性，需要大量标注的数据。本研究提出了一种多任务学习框架，以在无对比增强的肝脏MRI图像中分割血管。该框架利用仅在训练期间可用的对比增强MRI数据，以减少所需标注训练样例的数量。该方法利用了具有和不具有血管标注的原生与对比增强数据对模型进行训练。结果表明，辅助数据能够提高血管分割的准确性，即使在推理过程中不可用。如果训练期间可用标注数据很少，这一好处尤为明显，因为特征表示从共享的任务结构中受益。该方法应用于增强一个脑肿瘤分割模型，证实了其在不同领域的益处。即使辅助成像模态仅在训练期间可用，专业的标注数据也可以得到增强。", "innovation": "本研究提出了一种多任务学习框架，以在无对比增强的肝脏MRI图像中分割血管。该框架利用仅在训练期间可用的对比增强MRI数据，以减少所需标注训练样例的数量。该方法利用了具有和不具有血管标注的原生与对比增强数据对模型进行训练，最终验证了这一方法在脑肿瘤分割上的通用性。", "conclusion": "辅助数据能提高血管分割的准确性，尤其是在训练数据有限的情况下。该方法在不同领域的分割任务中也表现出了优势。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04050", "html_url": "https://arxiv.org/abs/2509.04050", "title": "基于K最近邻加权融合的人再识别再排序方法", "title_en": "A Re-ranking Method using K-nearest Weighted Fusion for Person Re-identification", "authors": "Quang-Huy Che,Le-Chuong Nguyen,Gia-Nghia Tran,Dinh-Duy Phan,Vinh-Tiep Nguyen", "background": "在人再识别任务中，再排序是一个关键步骤，用于通过细化检索结果的初始排名来提高整体准确性。以往的研究主要集中在单视角图像特征上，这会导致视角偏差和姿态变化、视角变换和遮挡等问题。使用多视角特征可以减少视角偏差。本文提出了一种高效再排序方法，通过使用K最近邻加权融合（KWF）方法聚合邻居特征来生成多视角特征。", "innovation": "提出了使用K最近邻加权融合生成多视角特征的再排序方法，这种方法在无监督的情况下选择K个邻居特征生成多视角特征，并探究了特征聚合时的权重选择策略，使得方法适用于大规模数据集且不需要微调模型或额外标注。实验表明，该方法在MSMT17和Occluded-DukeMTMC等挑战性数据集上的Rank@1提高了9.8%/22.0%，并且在计算效率上优于其他再排序方法。", "conclusion": "我们的方法在再排序方面显著改进了Rank@1和mAP，特别是在挑战性数据集MSMT17和Occluded-DukeMTMC上，重新排序方法分别提高了9.8%/22.0%。此外，与现有的再排序方法相比，我们的方法在计算效率上表现出了显著的提升。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04092", "html_url": "https://arxiv.org/abs/2509.04092", "title": "TriLiteNet: 轻量级多任务视觉感知模型", "title_en": "TriLiteNet: Lightweight Model for Multi-Task Visual Perception", "authors": "Quang-Huy Che,Duc-Khai Lam", "background": "高级驾驶辅助系统（ADAS）依赖高效的感知模型来实现快速处理和响应，以确保在真实环境中的安全性和有效性。然而，当前实时执行这些感知模型的需求并没有得到充分满足。因此，迫切需要一种能够同时处理多个任务、优化性能并保持低计算成本的感知模型，以满足实时性和效率的需求。本研究正是为了满足这一需求而提出的TriLiteNet模型。", "innovation": "TriLiteNet模型能够同时管理全景驾驶感知相关的多个任务，并且通过设计优化，能够在保持低计算成本的同时提高性能。实验结果表明，TriLiteNet在车辆检测、可驾驶区域分割和车道线分割这三个关键任务上均表现出了竞争力。特别是在参数量仅为2.35M和计算成本为7.72 GFLOPs的情况下，模型就能达到较高的准确率。此外，该模型还提供了一个仅含0.14M参数的轻量配置，能够在嵌入式设备上实现低延迟和合理能耗的多任务解决方案。", "conclusion": "通过平衡性能、计算效率和可扩展性，TriLiteNet为现实世界的自动驾驶应用提供了一种实用且可部署的解决方案。同时，该模型在计算延迟和能耗方面在嵌入式设备上表现良好，展示了一种高效解决多任务视觉感知问题的方法。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04126", "html_url": "https://arxiv.org/abs/2509.04126", "title": "MEPG：具有复合丰富图像生成的多专家规划与生成", "title_en": "MEPG:Multi-Expert Planning and Generation for Compositionally-Rich Image Generation", "authors": "Yuan Zhao,Liu Lin", "background": "文本到图像的扩散模型已经取得了卓越的图像质量，但在复杂和多元素的提示以及风格多样性方面仍然存在局限性。因此，本文探讨了改善这些问题的解决方案，并提出了一种多专家规划和生成框架（MEPG），以解决这些局限性。该框架结合了位置和样式感知的大型语言模型（LLMs）与空间语义专家模块，有助于改进生成图像的表现力。", "innovation": "提出了多专家规划和生成框架（MEPG），该框架包括两个核心组件：（1）一个位置-样式感知（PSA）模块，用于使用监督微调的大型语言模型将输入提示分解为精确的空间坐标和样式编码的语义指令；和（2）一个多专家扩散（MED）模块，通过动态专家路由实现跨区域的生成，为每个空间分区激活特定的模型。这种方法能够实现轻量级专家模型的集成和替换，并支持通过注意力机制进行实时的空间布局编辑和区域样式选择，增强了图像生成的多样性和质量。", "conclusion": "MEPG在图像质量和风格多样性方面显著优于具有相同骨干的基线模型，这表明该框架在提高复杂图像生成效果方面是有效的。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04123", "html_url": "https://arxiv.org/abs/2509.04123", "title": "TaleDiffusion：通过对话渲染生成多人物故事", "title_en": "TaleDiffusion: Multi-Character Story Generation with Dialogue Rendering", "authors": "Ayan Banerjee,Josep Lladós,Umapada Pal,Anjan Dutta", "background": "文本转故事可视化由于需要在多帧中保持多个角色的一致性交互而具有挑战性。现有方法在角色一致性方面存在困难，导致生成伪影并产生不准确的对话渲染，从而造成叙事脱节。", "innovation": "我们介绍了一个新颖的框架TaleDiffusion，以生成多角色故事，通过迭代过程、后处理维持角色一致性并准确分配对话。使用预训练的语言模型通过上下文学习生成每一帧的描述、角色细节和对话，通过有界注意机制的包围盒遮罩技术控制角色交互并减少伪影。然后，应用身份一致的自我注意机制确保角色在多帧中的一致性，并使用区域感知的交叉注意机制实现精确的对象放置。对话也被渲染为气泡并由CLIPSeg分配给角色。实验结果表明TaleDiffusion在一致性、噪声减少和对话渲染方面优于现有方法。", "conclusion": "TaleDiffusion在一致性、噪声减少和对话渲染方面超越了现有方法，提供了一种创新的方法来生成多角色故事，提高了故事叙述的连续性和真实性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04117", "html_url": "https://arxiv.org/abs/2509.04117", "title": "DVS-PedX: 基于合成和真实事件的行人数据集", "title_en": "DVS-PedX: Synthetic-and-Real Event-Based Pedestrian Dataset", "authors": "Mustafa Sakhai,Kaung Sithu,Min Khant Soe Oke,Maciej Wielgosz", "background": "事件相机如动态视觉传感器(DVS)报告微时间亮度变化，而非完整的图像框架，提供低延迟、高动态范围和运动稳健性。DVS-PedX 是一个为行人检测和过马路意图分析设计的神经形态数据集，在两个互补来源中的恶劣天气和正常条件下进行：(1) CARLA模拟器生成的合成事件流，用于控制“接近-过马路”场景；(2) 使用v2e工具将真实世界的JAAD汽车挡风玻璃视频转换为事件流，保持自然行为和背景。每个序列提供配对的RGB帧、每帧DVS“事件帧”（33 ms累积）和帧级标签（过马路 vs. 未过马路）。还提供了原始的AEDAT 2.0/AEDAT 4.0事件文件、AVI DVS视频文件及其元数据以供灵活处理。初步的神经脉冲网络(SNN)使用SpikingJelly展示了该数据集的用例，并揭示了模拟到现实的差距，激励领域适应和多模态融合。该数据集旨在加速基于事件的行人安全研究、意图预测和神经形态感知的发展。", "innovation": "DVS-PedX 数据集结合了合成和真实事件流数据，提供了详细的RGB帧、33 ms累积的事件帧以及帧级标签，支持灵活的数据处理。此外，提供了AEDAT 2.0/AEDAT 4.0事件文件和AVI DVS视频文件，使得研究者能够进行各种实验。初步研究展示了SNNs在该数据集上的表现，并揭示了模拟与现实之间的差距，从而促进了领域适应和多模态信息融合的研究。", "conclusion": "DVS-PedX 的目标是加速推进基于事件的行人安全、意图预测和神经形态感知的研究。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04150", "html_url": "https://arxiv.org/abs/2509.04150", "title": "重访用于在野外深度伪造检测的简单基线", "title_en": "Revisiting Simple Baselines for In-The-Wild Deepfake Detection", "authors": "Orlando Castaneda,Kevin So-Tang,Kshitij Gurung", "background": "合成媒体的广泛应用要求有易于访问的深度伪造检测器和具有实际意义的基准。尽管大多数现有研究通过高度控制的数据集评估深度伪造检测器，但本文专注于最近发布的“在野外”基准——Deepfake-Eval-2024。初步报告表明，在Deepfake-Eval-2024基准上，三个调优后的开源模型的准确率介于61%到69%，远远落后于位列榜首的商业深度伪造检测器，后者准确率为82%。", "innovation": "本文重新审视了由Ojha等人首次提出的一种基准方法，该方法通过适应标准预训练视觉骨干来生成通用的深度伪造检测器。研究团队通过调整超参数，证明了这一简单方法其实能够获得显著更高的性能，即在Deepfake-Eval-2024基准上的准确率为81%，比以前报道的基准方法高出18个百分点，同时与商业深度伪造检测器相竞争。此外，讨论了在实际应用中深伪检测器的准确率、计算成本和可解释性之间的权衡问题，强调了这些深度伪造检测器在实际部署环境中的实用性。", "conclusion": "本文通过对标准预训练视觉骨干的简单调整，提高了深度伪造检测器的性能，并指出这些检测器在实际部署场景中的实用性和局限性。相关代码可在以下网址获取。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04156", "html_url": "https://arxiv.org/abs/2509.04156", "title": "基于无人机的多光谱缺陷检测的YOLO集成模型", "title_en": "YOLO Ensemble for UAV-based Multispectral Defect Detection in Wind Turbine Components", "authors": "Serhii Svystun,Pavlo Radiuk,Oleksandr Melnychenko,Oleg Savenko,Anatoliy Sachenko", "background": "配备了高级传感器的无人机为监测风力发电厂提供了一种新机会，包括叶片、塔和其他关键组件。可靠的缺陷检测需要高分辨率数据和处理多光谱图像的有效方法。现有的单一YOLOv8模型在缺陷检测中的表现虽好，但通过将可见光通道和红外通道结合起来，并发展了一种集成YOLO模型的策略，可以提高检测准确度。实验显示该方法mAP@.5达到0.93，F1分数为0.90，优于单独使用YOLOv8模型的结果（mAP@.5为0.91）。研究表明，集成多个YOLO架构与融合多光谱数据能更可靠地提高缺陷检测准确性，无论是在视觉上还是在红外上均有成效。", "innovation": "提出了一种将通用的YOLOv8模型与专门的红外模型集成的方法，并使用复杂的边界框融合算法来结合预测结果。这种方法显著提高了缺陷检测的准确性，mAP@.5 达到了0.93，F1分数为0.90，优于单独使用YOLOv8模型的结果（mAP@.5为0.91）。", "conclusion": "通过集成多个YOLO架构与融合多光谱数据，实现了在检测风力涡轮机部件的视觉和红外缺陷上更具可靠性和准确性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04268", "html_url": "https://arxiv.org/abs/2509.04268", "title": "差值形态学配置神经网络用于语义分割", "title_en": "Differential Morphological Profile Neural Networks for Semantic Segmentation", "authors": "David Huangal,J. Alex Hurt", "background": "遥感图像的语义分割在地图编制、城市规划和灾害响应方面具有广泛应用潜力。现有的最先进的分割网络通常是在地对面的照片上开发和调整的，不直接解决遥感难题，如极端规模变化、前景背景不平衡和大图像尺寸。这些网络通常没有优化以处理这些特定挑战。因此，研究需要探索将多尺度形状提取方法——差异形态学配置（DMP）——集成到现代分割网络中的方法，以更好地适应遥感图像的特点。", "innovation": "本研究创新性地将DMP特征与三种最新的卷积和变换器语义分割架构整合，测试了多种DMP差异和结构元素形状，以更有效地为模型提供形状信息。研究结果表明，虽然非DMP模型通常优于直接输入变体，但混合DMP模型在mean Intersection over Union (mIoU)、F1分数和召回率方面表现更为出色。", "conclusion": "尽管直接输入变体的整体表现通常优于非DMP模型，但混合DMP配置在多个指标上始终表现更优，并且能够超越无DMP的模型。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04273", "html_url": "https://arxiv.org/abs/2509.04273", "title": "基于Wasserstein一致性约束的双尺度体积先验半监督医学图像分割", "title_en": "Dual-Scale Volume Priors with Wasserstein-Based Consistency for Semi-Supervised Medical Image Segmentation", "authors": "Junying Meng,Gangxuan Zhou,Jun Liu,Weihong Guo", "background": "尽管半监督医学图像分割取得了显著进展，现有的分割网络忽略了有效的方法论指导特征提取和重要先验知识的利用。", "innovation": "提出了一种半监督医学图像分割框架，有效地结合了空间正则化方法和体素先验。具体地，该方法将强显式体素先验和阈值动力学空间正则化（均由变分模型导出）集成到骨干分割网络中。同时设计了基于弱隐式体素先验的数据集尺度Wasserstein距离损失函数，以确保对未标注数据集的体积分布与标注数据集相似。", "conclusion": "实验结果表明，所提出的方法在2017年ACDC数据集、PROMISE12数据集以及大腿肌肉MR图像数据集上优于现有方法。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04180", "html_url": "https://arxiv.org/abs/2509.04180", "title": "VisioFirm：跨平台的计算机视觉领域AI辅助标注工具", "title_en": "VisioFirm: Cross-Platform AI-assisted Annotation Tool for Computer Vision", "authors": "Safouane El Ghazouali,Umberto Michelucci", "background": "当前AI模型依赖于注释数据来学习模式和进行预测，而传统的标注过程通常是劳动密集型的，需要手工输入从简单分类标签到复杂任务如对象检测、定向边界框估计和实例分割的标签。传统的工具常常需要大量的手动输入，这限制了它们对大规模数据集的适用性。因此，研究者们提出了VisioFirm这个开源web应用程序，通过AI辅助自动化流程来简化图像标注过程，减轻人工操作负担，提高效率。", "innovation": "VisioFirm引入了AI辅助自动化流程通过集成了先进基础模型的状态仪表板进行标注作业，采用CLIP与预训练的Ultralytics模型以及零样本模型如Grounding DINO结合的方式，生成具有低置信阈值的初始注释以最大化召回率。该工具在COCO类别的测试中，初始预测基本正确，并且通过交互式工具对边界框、定向边界框和多边形的支持，进一步提升了便捷性。同时，VisioFirm的即时分割功能通过WebGPU在浏览器端加速，增强了工具的效率。这款工具还支持多种导出格式（YOLO, COCO, Pascal VOC, CSV），并且在模型缓存后可以离线运行，提高了易用性。", "conclusion": "VisioFirm通过在多种数据集上的基准测试，展示了高达90%的注释人工努力减少量，同时通过CLIP基于的去噪组件和IoU图抑制冗余检测来保持高注释精度。这款工具可以在跨平台上使用，为计算机视觉领域的图像标注提供了便利。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04193", "html_url": "https://arxiv.org/abs/2509.04193", "title": "DUDE：基于扩散过程的无监督跨域图像检索", "title_en": "DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval", "authors": "Ruohong Yang,Peng Hu,Yunfan Li,Xi Peng", "background": "无监督跨域图像检索（UCIR）旨在无需依赖标注的情况下，在不同领域中检索相同类别的图像。现有的UCIR方法通常通过整个图像的特征对齐来处理跨域问题，但当需要检索的关键对象特征被特定领域的风格混杂时，这些方法往往难以应对域间差异。因此，现有方法在处理具有复杂风格差异的多域图像检索任务时表现不佳，这主要是因为难以区分对象特征和特定领域风格，导致检索准确度不高或不稳定。因此，需要一种能够有效分离对象特征和风格特征的新方法来改善这种跨域检索问题。", "innovation": "本文提出一种新颖的无监督跨域图像检索方法DUDE，该方法基于特征解缠的概念来实现跨域对象特征的有效对齐。DUDE利用一个从文本生成图像的生成模型来解缠对象特征和特定领域的风格特性，以便进行具有语义的图像检索。为了进一步稳定地对解纠缠后的对象特征进行配准，DUDE采取逐步的方法在域内邻居与跨域邻居之间进行对齐。这种方法能够有效分离出更关键的对象特征，从而提高检索性能并减少误差。实验结果表明，DUDE方法在多个基准数据集上的性能处于领先水平，展现了其在跨域图像检索中的优势。", "conclusion": "本文提出的DUDE方法在多个领域基准数据集上展示了优越的性能，通过从文本生成图像的生成模型和逐步的对齐方式来解缠对象特征和风格特征，实现了跨域图像检索的显著改进。未来工作可以进一步探索更复杂的模型架构和技术以进一步提高检索性能。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04243", "html_url": "https://arxiv.org/abs/2509.04243", "title": "通过自我进化的偏好优化学习主动感知以实现GUI定位", "title_en": "Learning Active Perception via Self-Evolving Preference Optimization for GUI Grounding", "authors": "Wanfu Wang,Qipeng Huang,Guangquan Xue,Xiaobo Liang,Juntao Li", "background": "视觉语言模型（VLMs）在视觉感知与语言推理的结合上取得了显著进展。然而，在GUI定位中，特别是面对高分辨率输入和复杂的多元素视觉交互时，使VLMs能够有效地推理适当的图像区域仍然是一个核心挑战。", "innovation": "本文提出了一个自我进化的框架LASER，该框架逐步赋予VLMs多步感知能力，以实现精确的坐标预测。该方法将蒙特卡洛质量估计与基于交并比（IoU）的区域质量评估相结合，共同促进了构建高质量偏好数据的准确性和多样性。这种方法明确引导模型关注与指令相关的关键区域，并根据任务复杂性自适应分配推理步骤。", "conclusion": "在ScreenSpot Pro和ScreenSpot-v2基准上的全面实验展示了性能的持续提升，验证了该方法的有效性。进一步地，当在GTA1-7B上微调时，LASER在ScreenSpot-Pro基准上取得了55.7的得分，成为7B规模模型中的新最佳水平。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04276", "html_url": "https://arxiv.org/abs/2509.04276", "title": "PAOLI: 无需姿态的稀视角具备关节的物体学习", "title_en": "PAOLI: Pose-free Articulated Object Learning from Sparse-view Images", "authors": "Jianning Deng,Kartic Subr,Hakan Bilen", "background": "当前大多数关节物体表示学习方法依赖于密集的多视角观测和真实相机姿态。然而，在实际应用中，获取这些密集观测和精确相机姿态往往较为困难且成本高昂。因此，本文的背景是探索一种能够在稀疏视角和无姿态观测条件下学习关节物体表示的新方法。", "innovation": "本文提出了一种新颖的自监督框架，能够从稀视角的无姿态图像中学习关节物体表示。该框架无需多视角密集观测和真实相机姿态。创新点包括：1) 独立重建每个关节的部分，利用近期的稀视角3D重建技术；2) 学习变形场，建立不同姿态下的密集对应关系；3) 进行渐进解耦策略，使静态和动态部分能够分离，从而分离相机和物体运动；4) 通过自监督损失函数联合优化几何、外观和动力学，确保跨视角和跨姿态的一致性。", "conclusion": "实验展示了本方法在标准基准和真实世界示例下的准确定和详尽性，即使是在比现有方法更弱的输入假设下也能生成准确的关节物体表示。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04378", "html_url": "https://arxiv.org/abs/2509.04378", "title": "使用增强注意机制的美学图像描述", "title_en": "Aesthetic Image Captioning with Saliency Enhanced MLLMs", "authors": "Yilin Tao,Jiashui Huang,Huaze Xu,Ling Shao", "background": "美学图像描述（AIC）旨在生成图像美学的文本描述，成为计算美学领域的关键研究方向。近年来，预训练多模态大语言模型（MLLMs）取得了迅速进展，促进了结合视觉和文本模态的图像美学研究。然而，现有的大多数图像美学研究主要聚焦于预测美学评分，且在AIC上的应用有限。现有的依赖MLLMs的AIC工作大多采用微调方法，没有特别适应这些模型以关注目标美学内容。", "innovation": "本文提出了一种新的框架，即具有美学显著性增强的多模态大语言模型（ASE-MLLM），它是一个端到端框架，明确将美学显著性纳入MLLMs。该框架内引入了图像美学显著性模块（IASM），能够高效有效地从图像中提取美学显著性特征。还设计了IAS-ViT作为MLLM们的图像编码器模块，该模块通过交叉注意力机制将美学显著性特征与原始图像特征融合。这是第一个将图像美学显著性专门集成到MLLMs中的框架，以用于AIC任务。", "conclusion": "广泛的实验表明，本方法在当前主流AIC基准测试中显著优于传统方法和通用MLLMs，达到了最佳性能。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04298", "html_url": "https://arxiv.org/abs/2509.04298", "title": "基于语义可靠合成图像的错误标签修正", "title_en": "Noisy Label Refinement with Semantically Reliable Synthetic Images", "authors": "Yingxuan Li,Jiafeng Mao,Yusuke Matsui", "background": "在图像分类数据集中，由于视觉上相似的类别经常被错误标记，导致语义噪声，这对传统的监督学习方法构成了重大挑战。我们探索了通过利用先进文本转图像模型生成的高质量合成图像来解决这一问题的可能性。尽管这些合成图像带有可靠的标签，但它们在训练中的直接应用受到领域差距和多样性的限制。因此，我们提出了一种新颖的方法，利用合成图像作为可靠的参考点，来识别和修正嘈杂数据集中的错误标签样本。广泛的实验证明，我们的方法在多种噪声条件下的分类准确率显著提高，特别是在具有语义标签噪声的挑战性场景中。此外，由于该方法与现有的抗噪声学习技术不冲突，其与最先进的抗噪声训练方法结合使用时，能取得更好的性能，尤其是在CIFAR-10、CIFAR-100和ImageNet-100等数据集上，在具有70%语义噪声的实际场景中，分类准确率分别提高了30%和11%，在真实世界噪声条件下分别提高了24%。", "innovation": "我们提出了一种利用合成图像作为可靠参考点的新方法，来识别和修正数据集中的误标样本。此方法显著提高了分类精度，特别是在语义噪声场景下效果显著。此外，该方法与现有的抗噪声学习技术相辅相成，可以显著提升整体性能。", "conclusion": "我们的方法在具有70%语义噪声的CIFAR-10和CIFAR-100数据集上分别提升了30%和11%的准确率，并在具有真实世界噪声条件的ImageNet-100上提升了24%的准确率，证明了合成图像在提高分类准确性方面的潜力。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04344", "html_url": "https://arxiv.org/abs/2509.04344", "title": "MICACL: 多实例类别感知对比学习在长尾动态面部表情识别中的应用", "title_en": "MICACL: Multi-Instance Category-Aware Contrastive Learning for Long-Tailed Dynamic Facial Expression Recognition", "authors": "Feng-Qi Cui,Zhen Lin,Xinlong Rao,Anyang Tong,Shiyao Li,Fei Wang,Changlin Chen,Bin Liu", "background": "动态面部表情识别（DFER）面临着长尾类别分布和时空特征建模复杂性的挑战。现有的基于深度学习的方法虽然提高了DFER的表现，但往往未能解决这些问题，导致模型诱导偏差。", "innovation": "本文提出了一种新的多实例学习框架MICACL，该框架结合了时空依赖关系建模和长尾对比学习优化。具体地，设计了图增强实例交互模块（GEIIM），用于通过自适应邻接矩阵和多尺度卷积捕获相邻实例之间的复杂时空关系。为增强实例级特征聚合，开发了加权实例聚合网络（WIAN），根据实例重要性动态分配权重。此外，引入了多尺度类别感知对比学习（MCCL）策略以平衡主要类别和次要类别之间的训练。实验结果表明，MICACL在多种野生数据集（DFEW和FERV39k）上达到了最先进的性能，并具备更强的鲁棒性和泛化能力。", "conclusion": "研究表明，MICACL在DFER中表现出了优越的鲁棒性和泛化能力，表明该方法的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04334", "html_url": "https://arxiv.org/abs/2509.04334", "title": "GeoArena: 一个针对全球图像地理定位评估大型视觉-语言模型的开源平台", "title_en": "GeoArena: An Open Platform for Benchmarking Large Vision-language Models on WorldWide Image Geolocalization", "authors": "Pengyue Jia,Yingyi Zhang,Xiangyu Zhao,Yixuan Li", "background": "图像地理定位旨在预测地球上任何地方拍摄的图像的地理位置，但其全球性质带来了重大挑战。当前的评估方法存在两个主要问题：数据泄漏和现有指标的局限性。数据泄漏通常是因为先进的方法依赖于大规模的视觉-语言模型（LVLMs）来预测图像位置，且这些模型经常在测试数据集上预训练，这影响了模型实际地理定位能力的评估准确性。现有指标主要依赖于准确的地理坐标来评估预测，这忽略了推理过程并引发了隐私问题，尤其是在需要用户水平的地理位置数据时。", "innovation": "我们提出了GeoArena，这是一个首个针对全球图像地理定位任务评估大型视觉-语言模型的开源平台，提供了真正的野外观测和以人为本的基准测试。GeoArena允许用户上传野外图像以获得更多样化评价数据集，并利用两两人工判断来确定哪一个是模型输出中更符合人类预期的。我们还在线部署了该平台两个月，收集了数万票选记录，基于此数据进行了详细分析并建立了不同LVLMs在图像地理定位任务上的排行榜。", "conclusion": "我们的平台进行了两个月的在线部署，期间收集了数万张投票记录，并基于这些数据进行了详细分析，制定了不同LVLMs在图像地理定位任务上的排名，并展示了GeoArena在解决数据泄漏和评估方法局限性方面的重要作用。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04326", "html_url": "https://arxiv.org/abs/2509.04326", "title": "高效奇一出异常检测", "title_en": "Efficient Odd-One-Out Anomaly Detection", "authors": "Silvio Chito,Paolo Rabino,Tatiana Tommasi", "background": "最近引入的奇一出异常检测任务涉及在多物体场景中识别看上去与众不同的实例。这一问题对现代深度学习模型提出了挑战，要求在多个视图之间进行空间推理和关系推理，以理解上下文并泛化到不同的物体类别和布局。当前的技术虽然有效，但存在效率问题，即模型参数量大和训练时间长。", "innovation": "本文提出了一种基于DINO的模型，相比当前最先进的技术，参数减少了三分之一，训练时间缩短了三倍，同时保持了与之竞争的性能。此外，实验还引入了多模态大型语言模型的基线，深入了解其在结构化视觉推理任务中的当前局限性。", "conclusion": "本文提出的方法在奇一出异常检测任务中实现了高效性，在减少模型复杂度和缩短训练时间方面取得了显著进展，同时在性能上与最先进的技术相当。初步实验结果还显示了多模态大型语言模型在处理结构化视觉推理任务时的局限性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04269", "html_url": "https://arxiv.org/abs/2509.04269", "title": "TauGenNet: 通过文本指导的三维扩散模型驱动的p-τ217驱动Tau PET图像合成", "title_en": "TauGenNet: Plasma-Driven Tau PET Image Synthesis via Text-Guided 3D Diffusion Models", "authors": "Yuxin Gong,Se-in Jang,Wei Shao,Yi Su,Kuang Gong(for the Alzheimer's Disease Neuroimaging Initiative (ADNI))", "background": "准确的tau病理量化对于诊断和监测阿尔茨海默病（AD）至关重要。然而，tau PET的高成本和有限的可用性限制了其广泛应用。相比之下，结构磁共振成像（MRI）和基于血浆的生物标志物为无创且广为人用的与脑解剖结构和疾病进展相关的信息提供了补充信息。在这项工作中，我们提出了一种基于文本的3D扩散模型用于3D tau PET图像合成，结合了来自结构MRI和血浆测量的多模态数据条件。", "innovation": "我们提出的框架利用了文本提示来自于血浆p-tau217测量值，这是AD进展的关键指标，同时使用MRI提供解剖结构限制。该框架的训练与评估使用了临床的AV1451 tau PET数据来自阿尔茨海默病神经影像倡议数据库（ADNI）。实验结果表明，我们的方法可以生成从不同疾病阶段的人工3D tau PET图像，对于由于不同设定进行tau PET数据增强具有帮助，并能以一种无创、成本效益高的方式可视化tau病理，同时支持在不同血浆生物标志物水平和认知条件下模拟疾病进展。", "conclusion": "提案的框架有助于不同环境下的tau PET数据增强，提供一种无创和成本效益高的替代方案来可视化tau病理，以及在不同血浆生物标志物水平和认知条件下支持模拟疾病进展。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04370", "html_url": "https://arxiv.org/abs/2509.04370", "title": "从随身摄像中拼接故事：创建事件全景摘要", "title_en": "Stitching the Story: Creating Panoramic Incident Summaries from Body-Worn Footage", "authors": "Dor Cohen,Inga Efrosman,Yehudit Aperstein,Alexander Apartsin", "background": "第一响应者广泛采用随身摄像机来记录事故现场并支持事件后的分析。然而，在时间紧迫的情况下，审查冗长的视频片段是不切实际的。准确的态势感知要求能够快速理解事件现场的简洁视觉摘要。这篇论文介绍了一种计算机视觉管道，将随身摄像机录像转化为能够概括事故现场的富有信息的全景图像。该方法利用单目同时定位与地图构建（SLAM）来估计相机轨迹并重建环境的空间布局。沿着轨迹聚类相机姿态，识别关键视点，并从每个聚类中选择代表帧。使用多帧拼接技术将这些帧融合成空间上一致的全景图像。由此产生的总结可以快速理解复杂的环境，促进高效的决策并进行事件审查。", "innovation": "该研究提出了一种利用单目SLAM技术生成全景图像的方法，以提供事件现场的简洁视觉摘要。这一技术能够有效地解决在紧迫时间条件下审阅大量视频片段的问题，通过结合相机姿态聚类和多帧拼接技术，快速生成空间连贯的全景图像，从而提升第一响应者对复杂环境的快速理解能力，并加快决策过程。", "conclusion": "生成的全景图像能够迅速提供事故现场的清晰概述，有助于第一响应者快速理解复杂环境，促进高效决策和事件审查。该方法为理解和分析复杂事故现场提供了一种新的视觉表示方式。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04376", "html_url": "https://arxiv.org/abs/2509.04376", "title": "AnomalyLMM：生成知识与判别检索之间的桥梁文本基础人物异常搜索", "title_en": "AnomalyLMM: Bridging Generative Knowledge and Discriminative Retrieval for Text-Based Person Anomaly Search", "authors": "Hao Ju,Hu Zhang,Zhedong Zheng", "background": "随着公共安全需求的增长，基于文本的人物异常搜索已成为一个关键任务，旨在通过自然语言描述检索具有异常行为的个体。这种任务与传统的人像搜索相比，面临两个独特的挑战：细粒度的跨模态对齐以及在稀疏现实世界样本下的异常识别。虽然大型多模态模型在多模态理解方面表现出色，但它们在细粒度异常检索方面的潜力尚未得到充分探索，主要受到生成知识与判别检索之间领域差距以及缺乏高效部署方法的限制。", "innovation": "本文提出了AnomalyLMM，这是首个利用大型多模态模型（LMMs）进行基于文本的人物异常搜索的框架。关键贡献包括：1. 一种新颖的粗细粒度流程，结合LMMs来弥合生成世界的知识与检索为中心的异常检测之间的鸿沟；2. 一种无需训练的适应食谱，包含掩码跨模态激励、行为焦点预测和知识引导重排序，能够实现零样本聚焦于微妙的异常线索。 ", "conclusion": "作为首次研究利用LMMs进行这种任务的研究，我们在PAB数据集上进行了严格的评估，该数据集是唯一公开可用的面向文本的人像异常搜索基准，涵盖了多样化的场景。实验结果表明了所提出方法的有效性，其准确度超越了竞争基线0.96%的召回率。此外，我们的方法揭示了文本异常与视觉行为之间的可解释对齐，通过定性的分析进行了验证。未来的研究人员可以获得我们的代码和模型。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04406", "html_url": "https://arxiv.org/abs/2509.04406", "title": "通过边缘数据传输蒸馏实现3D生成的几步流", "title_en": "Few-step Flow for 3D Generation via Marginal-Data Transport Distillation", "authors": "Zanwei Zhou,Taoran Yi,Jiemin Fang,Chen Yang,Lingxi Xie,Xinggang Wang,Wei Shen,Qi Tian", "background": "基于流的3D生成模型通常在推理过程中需要数十次采样步骤。尽管存在一些几步骤蒸馏方法，特别是在提高2D扩散模型加速方面取得了显著进展，但它们对于更复杂的3D生成任务仍然未被充分探索。现有方法未能有效减少3D生成中所需的时间步骤数，限制了其在3D生成中的应用效率和性能。", "innovation": "研究提出了一种名为MDT-dist的新框架，用于简化3D流的蒸馏过程。该方法引入了两个可优化的目标：Velocity Matching (VM) 和 Velocity Distillation (VD)。通过这两个目标，将优化的目标从运输层面转化为速度层面和概率密度层面，从而实现更高效的3D生成。该方法在3D生成框架TRELLIS中实现了从25步到1或2步的显著优化，提高了速度快9倍和6.5倍的同时，保留了高视觉和几何保真度。", "conclusion": "实验结果表明，该方法大幅优于现有的CM蒸馏方法，并使TRELLIS在几步3D生成中表现出色。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04402", "html_url": "https://arxiv.org/abs/2509.04402", "title": "Unknown 探针下用于 X 射线波阵面重建的神经表示学习", "title_en": "Learning neural representations for X-ray ptychography reconstruction with unknown probes", "authors": "Tingyou Li,Zixin Xu,Zirui Gao,Hanfei Yan,Xiaojing Huang,Jizhou Li", "background": "X射线波阵面成像能够提供纳米级分辨率，广泛应用于材料科学、生物学和纳米技术等领域。然而，该技术受到关键挑战，即当照明探针未知时，准确重构图像的能力受限。传统迭代方法和深度学习方法在低信号条件下通常表现不佳，这限制了该技术的广泛应用和深入研究。", "innovation": "本文介绍了波阵面隐式神经表示(PtyINR)框架，该框架同时解决了对象和探针恢复问题。PtyINR将对象和探针同时参数化为连续的神经表示，无需对探针进行预表征即可直接从原始衍射图案进行端到端的重建。实验结果表明，PtyINR在模拟和实验数据上均表现出卓越的重建质量，并且在低信号条件下具有出色的鲁棒性。此外，PtyINR提供了一个物理信息驱动的框架，适用于各种依赖探针的逆向问题，使其可应用于广泛计算显微镜领域的问题中。", "conclusion": "PtyINR能够在未知探针条件下实现高质量的直接重建。它提供了一个从衍生图案中学习隐式神经表示的新方法，显著改进了波阵面成像的重建质量和鲁棒性，有望广泛应用于相关领域。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04379", "html_url": "https://arxiv.org/abs/2509.04379", "title": "SSGaussian：具有语义意识和结构保存的3D风格转移", "title_en": "SSGaussian: Semantic-Aware and Structure-Preserving 3D Style Transfer", "authors": "Jimin Xu,Bosheng Qin,Tao Jin,Zhou Zhao,Zhenhui Ye,Jun Yu,Fei Wu", "background": "近期神经表示的进展，如神经辐射场和3D Gaussian点扩散，增加了将风格转移应用于3D场景的兴趣。现有的方法虽然能够将风格模式转移到3D一致的神经表示上，但在从参考风格图像中提取和转移高层次风格语义方面存在局限。此外，渲染的结果往往缺乏结构清晰度和分离，使得区分3D场景中的不同实例或对象变得困难。为了克服这些局限，本文提出了一种新颖的3D风格转移管道，该管道有效融合了预训练2D扩散模型的先验知识。该管道包括两个关键阶段：首先，利用扩散先验生成关键视角的风格化渲染，然后将风格化关键视角转移到3D表示上。这一过程包括两种创新设计：跨视角风格对齐和实例级风格转移，前者通过在UNet的最后一个上采样块中插入跨视角注意机制，提供了多关键视角之间特征的交互，确保扩散模型生成的风格化关键视角既保持了风格保真度又保留了实例级别一致性；后者通过利用风格化关键视角之间实例级别的保持性，有效地将其转移到3D表示上，从而产生了结构更加完整、视觉连贯性和艺术性更加丰富的风格化效果。广泛的定性和定量实验表明，本文提出的3D风格转移管道在多种场景下，从面向前方到具有挑战性的360度环境，都显著优于现有的最先进技术。我们的项目页面提供了沉浸式可视化体验：this https URL", "innovation": "本文提出了一种新颖的3D风格转移管道，该管道采用两种创新设计：跨视角风格对齐和实例级风格转移。跨视角风格对齐通过在关键视角生成时利用跨视角注意机制来增强特征交互，从而确保既保持风格保真度又保留实例级别的连贯性。实例级风格转移通过利用风格化关键视角之间实例级别的连贯性，将其有效转移到3D模型上。这种新的方法提高了在3D场景中风格化的真实性和连贯性，生成更加结构完整、视觉连贯性以及艺术性增强的结果。指标和可视化实验表明，该方法在广泛场景下的性能显著优于现有技术。", "conclusion": "本文提出了一种新颖的3D风格转移方法，结合了跨视角风格对齐和实例级风格转移，显著提高了在3D场景中的风格化效果，使风格化更加结构化、视觉连贯，并且更加艺术。实验结果表明，该方法在多个应用场景中表现优异，优于现有的最先进的技术。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04450", "html_url": "https://arxiv.org/abs/2509.04450", "title": "虚拟试衣间：从单张图像生成任意长度的虚拟试穿视频——技术预览", "title_en": "Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image -- Technical Preview", "authors": "Jun-Kun Chen,Aayush Bansal,Minh Phuoc Vo,Yu-Xiong Wang", "background": "当前，生成长时间的虚拟试穿视频面临两个主要挑战：确保视频片段之间的局部平滑性和维护不同片段之间的全局时间一致性。现有的方法可能需要大量的计算资源和较长的数据视频长度，这限制了其生成的视频长度。", "innovation": "本文提出了一种名为Virtual Fitting Room (VFR)的新型视频生成模型，能够生成任意长度的虚拟试穿视频。VFR将长视频生成任务分解为逐片段的自回归生成过程，通过提供统一视频条件和锚定视频来确保片段之间的平滑性和一致性，其中锚定视频全面捕捉人体的整体外观。这种方法使得生成的视频既具有局部平滑性又具有全局时间一致性。", "conclusion": "VFR能够生成按分钟计算的虚拟试穿视频，具有高度的平滑性和全局时间一致性，适用于多种动作，是长期虚拟试穿视频生成领域的开创性工作。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04434", "html_url": "https://arxiv.org/abs/2509.04434", "title": "Durian: 双参考引导的人物动画属性转移", "title_en": "Durian: Dual Reference-guided Portrait Animation with Attribute Transfer", "authors": "Hyunsoo Cha,Byungjun Kim,Hanbyul Joo", "background": "当前存在一种需求，即从给定的参考图像中提取面部属性，并将其转移至目标人物肖像中，形成动画视频。然而，在零样本条件下，如何确保高质量和空间一致性的属性转移是一个挑战。尤其是在多帧的动画过程中，如何保持面部属性的一致性复现和空间上的连贯性尤为关键。本研究旨在解决此问题，提出了一种新的方法来实现这一目标。", "innovation": "该研究引入了双参考网络，该网络能够在扩散模型的去噪过程中注入来自肖像和属性图像的空间特征，以实现高质量和空间一致性的属性转移。此外，研究还提出了一种关键点条件下的图像生成策略来扩展掩膜，以及对属性和肖像图像进行空间和外观级别的变换来增强模型对位置错位的鲁棒性。这些创新使得模型能够跨不同属性和野外参考条件进行有效的泛化。", "conclusion": "Durian在人物动画的属性转移方面达到了最先进的性能。其双参考设计使得能够在一次生成过程中完成多个属性的组合，而无需额外训练。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04446", "html_url": "https://arxiv.org/abs/2509.04446", "title": "零样本故事可视化和文本到图像扩散模型中的分离编辑——Plot'n Polish", "title_en": "Plot'n Polish: Zero-shot Story Visualization and Disentangled Editing with Text-to-Image Diffusion Models", "authors": "Kiymet Akdemir,Jing Shi,Kushal Kafle,Brian Price,Pinar Yanardag", "background": "文本到图像的扩散模型已经展示了生成多样化和详细视觉效果的能力，在各个领域都有显著的应用效果。故事可视化作为一种特别有前景的应用，正在逐渐崭露头角。然而，随着这些模型在现实世界创意领域的应用愈加广泛，如何提供更为增强的操控性、精炼性和生成后的修改能力，并且在多个帧之间保持视觉和叙事一致性，成为了面临的重要挑战。现有方法在进行细致或粗略编辑时往往缺乏灵活性，这阻碍了创作者们能够无缝地创作并改进他们的视觉故事.", "innovation": "本文提出了一种零样本框架Plot'n Polish，该框架能够实现一致的故事生成，并提供了在不同细节层次上对故事可视化进行细粒度控制的能力，解决了现有方法存在的问题，使得创作者可以更好地操控和修改他们的视觉故事，保持视觉和叙事的一致性.", "conclusion": "Plot'n Polish框架能够为文本到图像的扩散模型提供一种有效的解决方案，以实现故事的可视化和分离编辑，增强创作过程中的操控性和精炼性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04444", "html_url": "https://arxiv.org/abs/2509.04444", "title": "跨越视角与全景视觉的鸿沟：一种从视角到全景视觉的综述", "title_en": "One Flight Over the Gap: A Survey from Perspective to Panoramic Vision", "authors": "Xin Lin,Xian Ge,Dizhe Zhang,Zhaoliang Wan,Xianshun Wang,Xiangtai Li,Wenjie Jiang,Bo Du,Dacheng Tao,Ming-Hsuan Yang,Lu Qi", "background": "由于对空间智能和整体场景感知的需求，全景图像（ODIs）提供了360度的视野，这种图像在虚拟现实、自主驾驶和实体机器人等领域越来越多地受到关注。然而，全景图像在几何投影、空间分布和边界连续性等方面与视角图像存在显著差异，这些差异使得直接从视角方法进行领域适应变得困难。这篇综述回顾了近年来的全景视觉技术，特别强调了从视角到全景的适应性问题，通过重新审视全景成像管道和投影方法来建立必要的先验知识，总结了领域适应的三个挑战，并覆盖了20多个代表性任务，这些任务来自超过300篇研究论文。", "innovation": "本文提供了一个从视角到全景视觉的详尽综述，具体分析了代表性的策略如何跨任务解决全景视觉特有的挑战，将全景视觉划分为四个主要类别：视觉质量增强与评估、视觉理解、多模态理解、视觉生成。除此之外，还讨论了数据、模型和应用方面存在的开放性挑战和未来发展方向，旨在促进全景视觉研究的进展", "conclusion": "我们希望这项工作能够提供新的见解和前瞻性的视角，推动全景视觉技术的发展。更多信息，请访问我们的项目主页：https://github.com/KaiyangZhou/PanoSurvey"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04437", "html_url": "https://arxiv.org/abs/2509.04437", "title": "从线到形状：利用霍夫变换的X射线准直器几何约束分割", "title_en": "From Lines to Shapes: Geometric-Constrained Segmentation of X-Ray Collimators via Hough Transform", "authors": "Benjamin El-Zein,Dominik Eckert,Andreas Fieselmann,Christopher Syben,Ludwig Ritschl,Steffen Kappler,Sebastian Stober", "background": "X射线成像中的准直限制了辐射暴露于感兴趣的区域（ROI），并减少了施加于患者的辐射剂量。散射X射线可能会遮挡边缘，使得检测准直器的阴影成为数字放射学中的重要图像预处理步骤，但这一过程也充满挑战。尽管如此，准直器形成的阴影是多边形形状的，因此可以利用这一特性进行特性化处理。通过将可微霍夫变换网络结合，我们的方法能够检测准直边界，并增强对ROI中心信息的提取能力，从而在推理过程中生成精准且线约束的分割掩码，实现准直区域的稳健重建，中位Hausdorff距离为4.3-5.0mm，适用于多种实际X射线图像的测试集。本方法对边界的数量不是基本限制，理论上支持多重边界的情况。", "innovation": "本方法通过集成可微霍夫变换网络来检测准直边界，并增强提取ROI中心信息的能力。在推理过程中结合了两个任务的信息，生成了线约束的分割掩码，实现了多样化实际X射线图像的稳健重建，中位Hausdorff距离为4.3-5.0mm，并且不受到准直器边缘数量的限制。", "conclusion": "我们的方法实现了对准直区域的稳健重建，证明了其在处理实际X射线图像中的有效性，并且证明该方法对准直器边缘数量没有特定限制，支持多种边界情况。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03623", "html_url": "https://arxiv.org/abs/2509.03623", "title": "借助物理约束神经场揭示原行星盘的精细结构", "title_en": "Revealing Fine Structure in Protoplanetary Disks with Physics Constrained Neural Fields", "authors": "Aviad Levis,Nhan Luong,Richard Teague,Katherine. L. Bouman,Marcelo Barraza-Alfaro,Kevin Flaherty", "background": "原行星盘是行星诞生的地方，其三维结构的解析对于理解盘状结构的演化至关重要。ALMA（阿塔卡马大型毫米/亚毫米阵列）观测到的前所未有的分辨率要求使用传统方法无法捕捉到的建模方法。因此，需要针对三维结构建模的新方法。", "innovation": "我们介绍了一种计算框架，将物理约束神经场与可微渲染结合，并提出了一种基于GPU的全可微线辐射转移求解器，RadJAX，其速度比传统光线追踪器快10,000倍，能够实现以往难以获得的高维神经重建。这一方法应用于观测HD 163296的ALMA CO数据中，揭示了CO丰富的层的垂向形态，并发现了一个在400 au以外显著变窄和平坦的发射面，这是现有方法未曾发现的特征。这项工作确立了提取复杂盘状结构的一个新范式，并促进了对原行星盘演化的理解。", "conclusion": "这种新的建模框架能够以前所未有的分辨率解析原行星盘的精细结构，揭示了复杂的三维结构，并为深入理解原行星盘的演化提供了新的视角和方法。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03830", "html_url": "https://arxiv.org/abs/2509.03830", "title": "A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai", "title_en": "A Multidimensional AI-powered Framework for Analyzing Tourist Perception in Historic Urban Quarters: A Case Study in Shanghai", "authors": "Kaizhen Tan,Yufan Wu,Yuxuan Liu,Haoran Zeng", "background": "历史城市街区在保存文化遗产的同时，也为旅游业和日常生活提供了活力空间。理解游客对这些环境的认知对于可持续的人本城市规划至关重要。这项研究表明，使用社交媒体的多模态数据构建一个基于人工智能的多维框架，对历史城市街区的游客感知进行分析是必要的。", "innovation": "该研究提出了一种基于人工智能的多维框架，利用社交媒体的多模态数据分析游客对历史城市街区的感知。该框架整合了焦点提取、颜色主题分析和情感挖掘，并通过特化的语义分割模型识别游客共享照片中的视觉焦点区域。通过对比社交媒体照片和实际街道视图的颜色主题，揭示了视觉期望与建成环境之间的差距，揭示了风格偏好和感知偏见。还通过结合基于规则的方法和多任务 BERT 模型的混合情感分析方法评估用户评论。", "conclusion": "结果揭示了审美吸引力和情感反应的空间变化。该研究框架提供了一种集成的数据驱动方法，用于解读游客感知，并为旅游业、遗产保护和美学吸引的公共空间设计提供了信息支持和决策依据。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03680", "html_url": "https://arxiv.org/abs/2509.03680", "title": "LuxDiT：使用视频扩散变换器进行照明估计", "title_en": "LuxDiT: Lighting Estimation with Video Diffusion Transformer", "authors": "Ruofan Liang,Kai He,Zan Gojcic,Igor Gilitschenski,Sanja Fidler,Nandita Vijaykumar,Zian Wang", "background": "从单张图像或视频估计场景照明一直是计算机视觉和图形学中的长期挑战。基于学习的方法受到高质量地面实况高动态范围环境图稀缺性的限制，这些图昂贵且多样性有限。虽然生成模型为图像合成提供了强大的先验知识，但照明估计仍然困难，因为它依赖于间接视觉线索，需要推断全局（非局部）上下文，并恢复高动态范围输出。", "innovation": "我们提出了LuxDiT，一个新颖的数据驱动方法，通过将一个基于视频的扩散变换器微调，实现基于视觉输入生成高动态范围环境图。我们的模型在包含多种光照条件的大型合成数据集上进行训练，学会了从间接视觉线索推断光照，并且在现实场景中表现良好。此外，我们的方法通过使用HDR全景图数据集实现语义对齐的低秩适应微调策略，提高了输入与预测环境图之间的语义对齐。由此，我们的方法能够生成具有真实高频细节的准确照明预测，优于现有最先进的技术，在定量和定性评估中都表现突出。", "conclusion": "我们的方法能够在现实场景中生成高分辨率、真实感的环境图，展示了在单张图像或视频的多视角上的照明估计能力，超越了现有的最佳方法。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03677", "html_url": "https://arxiv.org/abs/2509.03677", "title": "从梯度动力学洞察：梯度自调整归一化", "title_en": "Insights from Gradient Dynamics: Gradient Autoscaled Normalization", "authors": "Vincent-Daniel Yun", "background": "梯度动力学在定义深层神经网络的稳定性和泛化能力方面起着核心作用。本文通过实证分析展示了训练过程中梯度方差和标准差的一致变化情况，特别是在卷积网络中跨越各层和整体层面观察到的变化。在此基础上，提出了一个无需超参数的梯度归一化方法，该方法使梯度缩放与自然演变保持一致，从而避免不必要的放大，稳定优化过程，并保持收敛保证。该方法在具有挑战性的CIFAR-100基准数据集上对ResNet-20、ResNet-56和VGG-16-BN等模型的实验结果表明，即使在强大的泛化压力下，该方法也能保持或提高测试准确性。", "innovation": "提出了一个无需超参数的梯度归一化方法，这种方法调整梯度缩放，使其与自然演变一致，从而防止不必要的放大，稳定优化过程，并保持收敛保证。这种方法在具有挑战性的基准数据集上展示了其在保持或提高测试准确性方面的有效性，即使在强大的泛化压力下也是如此。", "conclusion": "本文的研究不仅揭示了梯度动态的重要性，同时也填补了理论预期与实际行为之间的差距，为未来优化研究提供了新的见解。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04338", "html_url": "https://arxiv.org/abs/2509.04338", "title": "从编辑器到密集几何估计器", "title_en": "From Editor to Dense Geometry Estimator", "authors": "JiYuan Wang,Chunyu Lin,Lei Sun,Rongying Liu,Lang Nie,Mingxing Li,Kang Liao,Xiangxiang Chu,Yao Zhao", "background": "利用预训练的文本到图像（T2I）生成模型的视觉先验在密集预测任务上取得了成功，但密集预测本质上是图像到图像的任务，这表明图像编辑模型可能比T2I生成模型更适合精细调整的基础。已有研究指出，编辑模型天然具有结构先验，能够通过“精炼”其内在特征更稳定地收敛，并最终优于其生成模型的性能。", "innovation": "本文提出了一个创新框架FE2E，该框架基于扩散转换器（DiT）架构来调整先进的编辑模型用于密集几何预测。其中包括将编辑器的原始流匹配损失重新定义为“一致速度”训练目标，使用对数量化解决编辑器固有的BFloat16格式和高精度任务需求之间的精度冲突，利用DiT的全局注意力在单次前向传递中免费联合估计深度和法线，监督信号互相增强。", "conclusion": "FE2E在多个数据集上实现了无监督的单目深度和法线估计性能显著提升，特别是ETH3D数据集上超越了训练数据规模扩大100倍的DepthAnything系列，显著提高了零样本单目深度和法线估计的表现。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03749", "html_url": "https://arxiv.org/abs/2509.03749", "title": "在预算有限的情况下进行空间数据收集以优化机器学习：针对遥感数据的应用", "title_en": "Mapping on a Budget: Optimizing Spatial Data Collection for ML", "authors": "Livia Betti,Farooq Sanni,Gnouyaro Sogoyou,Togbe Agbagla,Cullen Molitor,Tamma Carleton,Esther Rolf", "background": "在农业、生态和人类发展等领域的应用中，利用卫星影像的机器学习（SatML）受到标记者训练数据稀缺的限制。尽管卫星数据覆盖全球，但已有标记的数据集往往规模小、空间分布集中且是为其他目的收集的（如行政调查或实地测量）。尽管这种情况在实践中普遍存在，但过去的SatML研究更多地集中在开发新的模型架构和训练算法以处理稀缺的训练数据，而不是直接建模数据条件。这使得希望使用SatML进行大规模监测的科学家和政策制定者对其是否应该收集或如何收集额外数据以提高表现表示怀疑。", "innovation": "本文提出了第一个在不均匀数据收集成本和实际预算限制下优化空间训练数据的问题表述，以及解决这个问题的新型方法。实验模拟了三个不同大陆和四种任务的不同问题设置，表明样本优化带来了显著改进。进一步的实验分析了样本优化特别有效的情况。引入的框架和方法旨在适用于SatML的各种应用领域，并特别关注了本团队的相关应用，即在多哥为SatML监测补充集中分布的农业调查数据的问题设置中应用我们的发现。", "conclusion": "我们的策略揭示了采样优化的显著收益，特别地，在某些情况下优化采样效果显著。我们提出的方法和问题框架设计旨在适用于各种SatML应用场景，并通过案例研究强调了其在特定应用领域的实际价值。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03850", "html_url": "https://arxiv.org/abs/2509.03850", "title": "数据增强感知量化知识蒸馏", "title_en": "Data-Augmented Quantization-Aware Knowledge Distillation", "authors": "Justin Kur,Kaiqi Zhao", "background": "量化感知训练（QAT）和知识蒸馏（KD）被结合用于创建低比特深度学习模型，以实现与高精度模型相近的性能。现有研究主要集中在通过设计更好的KD损失函数或优化QAT的前向和反向传播来提高量化模型的输出精度。然而，输入变换，特别是数据增强（DA）的影响尚未得到充分关注，其与量化感知KD之间的关系仍不清楚。因此，本文旨在研究如何在量化感知KD中选择合适的数据增强策略，尤其是在低精度模型中的应用.", "innovation": "本文提出了一种新的度量标准，该标准通过最大化上下文互信息（与图像标签无关的信息）和确保各个类别的预测平均接近真实标签来评估数据增强策略。该方法能够自动排序和选择Data Augmentation，且对训练过程的影响很小，同时兼容任何KD或QAT算法。实验结果表明，使用该度量标准选择Data Augmentation策略显著提高了现有先进QAT和KD的工作效果，适用于多种模型架构和数据集.", "conclusion": "本文通过提出一种新的度量标准，研究了量化感知KD中的数据增强选择问题，为低精度模型提供了有效的解决方案。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04107", "html_url": "https://arxiv.org/abs/2509.04107", "title": "FedQuad: 联邦随机四元学习以减轻数据异质性", "title_en": "FedQuad: Federated Stochastic Quadruplet Learning to Mitigate Data Heterogeneity", "authors": "Ozgu Goksu,Nicolas Pugeault", "background": "联邦学习（FL）提供分散的模型训练方式，有效解决分布式数据和隐私保护问题。然而，全局模型的一般化常常面临客户端之间数据异质性的挑战。特别是在数据集小且类别不平衡的情况下，这种挑战更为突出。现有方法难以有效处理数据异质性问题。", "innovation": "本文提出了一种新颖的方法，FedQuad，该方法明确优化跨客户端的小内类方差和大外类方差，从而降低模型聚合对客户端表示的负面影响。该方法通过在共享特征空间中减少相似对之间的距离，同时增加负对之间的距离，有效解耦客户端数据。", "conclusion": "我们在CIFAR-10和CIFAR-100数据集上进行了详细评估，结果表明，我们的方法在各种数据分布和众多客户端下表现出优越的性能。此外，我们还对基于度量学习的策略在监督学习和联邦学习框架中的应用进行了详细的分析，突显了它们在联邦学习环境中的代表学习挑战方面的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03775", "html_url": "https://arxiv.org/abs/2509.03775", "title": "ContraGS: 使用码本凝练和训练的高效率Gaussian平滑技术以实现快速且节省内存的重建", "title_en": "ContraGS: Codebook-Condensed and Trainable Gaussian Splatting for Fast, Memory-Efficient Reconstruction", "authors": "Sankeerth Durvasula,Sharanshangar Muhunthan,Zain Moustafa,Richard Chen,Ruofan Liang,Yushi Guan,Nilesh Ahuja,Nilesh Jain,Selvakumar Panneer,Nandita Vijaykumar", "background": "3D Gaussian Splatting（3DGS）是一种能够以高质量和实时渲染重建现实场景的技术。虽然使用大量3D高斯分布可以使模型质量更高，但这也显著增加了GPU设备内存的需求，特别是在训练和渲染过程中，由于内存访问和数据传输效率低下，使用强大的GPU和高内存容量的设备仍然是必需的。因此，如何在保持高质量的同时减少训练和渲染过程中的内存消耗和加速训练变得至关重要。这项研究介绍了一种名为ContraGS的方法，它能够在保持模型质量几乎不变的情况下，直接在压缩的3DGS表示上进行训练，从而实现高效的训练和渲染，特别是在内存使用和速度上得到了显著的改进。", "innovation": "ContraGS利用码本来紧凑地存储在训练过程中整个参数向量集，从而显著减少内存消耗。这项技术证明了即使在码本压缩模型中通过对非可微参数的贝叶斯推理问题进行参数估计，也可以有效进行推理。ContraGS通过采用MCMC采样来抽样压缩表示的后验分布，提供了这种框架，实现了在压缩表示上直接训练的新方法。实验结果显示，ContraGS在训练过程中显著降低了峰值内存使用（平均减少3.49倍），并且加速了训练和渲染（分别提高1.36倍和1.88倍的速度），同时达到了接近当前最先进的质量。", "conclusion": "ContraGS以其高效性和内存效率，在3DGS应用中取得突破，通过利用码本压缩技术和MCMC采样的后验分布，有效地减少了训练过程中内存消耗并加速了模型训练和渲染过程。与现有解决方案相比，它不仅节省了内存还提高了速度，提供了另一种重建高效率的3D场景的方法。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03891", "html_url": "https://arxiv.org/abs/2509.03891", "title": "MobileRAG：使用检索增强生成提升移动代理", "title_en": "MobileRAG: Enhancing Mobile Agent with Retrieval-Augmented Generation", "authors": "Gowen Loo,Chang Liu,Qinghong Yin,Xiang Chen,Jiawei Chen,Jingyuan Zhang,Yu Tian", "background": "智能手机在人们的日常生活中变得不可或缺，几乎渗透到现代社会的各个方面。大型语言模型（LLMs）的不断发展催生了许多基于LLMs的移动代理，这些代理能够准确解析用户查询并自动协助用户完成复杂或重复的操作。然而，现有的移动代理存在以下问题：1）高度依赖LLMs的理解能力，可能导致任务执行中的误操作或遗漏步骤产生的错误；2）缺乏与外部环境的交互，通常在应用程序无法满足用户查询时终止任务；3）缺乏记忆能力，每次指令都需要重新构建界面，无法从以往的错误中学习和修正。", "innovation": "为了缓解上述问题，提出了一个使用检索增强生成（RAG）增强的移动代理框架MobileRAG，包括InterRAG、LocalRAG和MemRAG。该框架利用RAG更快、更准确地识别用户查询并完成复杂的移动任务。此外，为了更全面地评估MobileRAG的性能，引入了MobileRAG-Eval基准，该基准包含了需要外部知识支持的大量复杂的、现实世界的移动任务。实验结果表明，MobileRAG可以在MobileRAG-Eval上轻松处理实际移动任务，并且与最先进的方法相比，以更少的操作步骤实现了10.3%的性能提升。", "conclusion": "MobileRAG可以在实际移动任务中显着提高性能并减轻现有移动代理的问题。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04047", "html_url": "https://arxiv.org/abs/2509.04047", "title": "TensoIS：向着基于Perlin分布异质媒体前向张量逆向散射迈出的一步", "title_en": "TensoIS: A Step Towards Feed-Forward Tensorial Inverse Subsurface Scattering for Perlin Distributed Heterogeneous Media", "authors": "Ashish Tiwari,Satyam Bhardwaj,Yash Bachwana,Parag Sarvoday Sahu,T.M.Feroz Ali,Bhargava Chintalapati,Shanmuganathan Raman", "background": "从图像估计异质介质的散射参数是一个严重欠约束和具有挑战性的问题。大多数现有方法通过分析-合成方法或不同的体绘制技术来建模BSSRDF，以近似复杂路径积分。只有少数研究采用基于学习的方法来估计次表层散射参数，但它们假设介质是均匀的。目前，关于实际世界中异质散射参数的具体分布还不清楚。Perlin噪声模型及其变体已在表示自然、有机和无机表面的复杂异质性方面证明是有效的。", "innovation": "本文提出了HeteroSynth，一个包含使用分形Perlin噪声建模散射参数的拟真异质介质图像合成数据集。还提出了TensoIS，一种基于学习的前向框架，用于从稀疏多视角图像观察中估计分形Perlin分布的异质散射参数。通过使用可学习的低秩张量组件表示散射体积，而不是直接预测3D散射参数体积，TensoIS致力于前向张量逆向散射，为异质介质提供一种潜在的方法。", "conclusion": "本文评估了TensoIS在HeteroSynth测试集中的未见异质形状变化、来自开源现实体积模拟的烟和云几何形状，以及一些实际样本上，以证明其在逆向散射中的有效性。此项研究旨在探索Perlin噪声分布，填补文献中缺乏的实际异质散射建模方法的空白，为前向方法提供可能的途径。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04438", "html_url": "https://arxiv.org/abs/2509.04438", "title": "电话游戏：评估统一模型中的语义漂移", "title_en": "The Telephone Game: Evaluating Semantic Drift in Unified Models", "authors": "Sabbir Mollah,Rohit Gupta,Sirnam Swetha,Qingyang Liu,Ahnaf Munir,Mubarak Shah", "background": "统一模型（Unified Model，UM）在视觉语言模型（VLM）中同时支持图像到文本（Image-to-Text，I2T）和文本到图像（Text-to-Image，T2I）生成，为跨模态研究开辟了新的方向。虽然UM可以支持更广泛的单模态任务（如文本到文本、图像到图像），但本文专注于核心的跨模态对T2I和I2T，因为理解和生成间的一致性对于下游应用至关重要。现有评估主要依赖单一传输评估方法（如FID, GenEval等），这些方法未能揭示模型的理解能力是否能够通过生成呈现，以及当在图像-文本模态间循环时，意义是否能够保留。", "innovation": "本文引入了统一一致性框架（Unified Consistency Framework，UCF）以及UM评估协议——称为UCF-UM。UCF-UM基于循环评估，通过交替执行T2I和I2T生成，以量化语义漂移，并提出了三种新的评估指标：（i）平均累计漂移（Mean Cumulative Drift，MCD），（ii）语义漂移速率（Semantic Drift Rate，SDR），（iii）多代生成评估（Multi-Generation GenEval，MGG）。此外，为了评估泛化能力，创建了一个新的基准数据集ND400，并在七种最新模型上进行了评估。", "conclusion": "UCF-UM展示了统一模型在跨模态稳定性方面的巨大差异，一些模型如BAGEL可以在多次交替中保持语义，而其他如Vila-u则漂移迅速，尽管它们在单一传输评估中表现良好。结果强调了循环一致性作为标准I2T和T2I评估的必要补充，并提供了评估统一模型跨模态稳定性和共享表示强度的实用指标。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04058", "html_url": "https://arxiv.org/abs/2509.04058", "title": "SMooGPT: 使用大型语言模型生成风格化动作", "title_en": "SMooGPT: Stylized Motion Generation using Large Language Models", "authors": "Lei Zhong,Yi Yang,Changjian Li", "background": "在计算机图形学中，风格化动作生成得到了广泛关注，特别是在扩散模型快速发展的情况下。该任务的目标是生成一种兼顾动作内容和期望动作风格的新鲜动作，例如，“像猴子一样环形行走”。现有研究通过动作风格迁移或条件动作生成尝试解决这一问题。他们通常将动作风格嵌入到潜在空间中，并在这种潜在空间中隐式引导动作。虽然这些方法已经取得了进步，但由于风格化动作数据集中的偏见，仍然存在难以解决的问题，如低可解释性、缺乏控制、泛化能力有限以及难以生成非“行走”动作的问题。基于这一观察，本文提出了一种新的推理-组合-生成视角来解决风格化动作生成问题。", "innovation": "本文提出利用基于身体部位的文本空间作为中间表示，并基于此提出了SMooGPT，这是一种微调的大型语言模型，能够在生成所需风格化动作时充当推理者、组合者和生成者。这种方法在身体部位文本空间中执行，具有更高的可解释性，能够实现细粒度动作控制，有效地解决了动作内容和风格之间的潜在冲突，并且由于大型语言模型的开放词汇量能力，在新风格下能够更好地泛化。", "conclusion": "全面的实验、评估和用户体验研究表明，我们的方法在纯文本驱动的风格化动作生成中表现出有效性，特别是在可解释性的提高、细粒度动作控制能力以及新风格的泛化能力方面表现出色。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04448", "html_url": "https://arxiv.org/abs/2509.04448", "title": "TRUST-VL: 一种用于泛化多模态虚假信息检测的可解释新闻助手", "title_en": "TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection", "authors": "Zehong Yan,Peng Qi,Wynne Hsu,Mong Li Lee", "background": "多模态虚假信息，包含文本、视觉和跨模态的扭曲，随着生成式AI的增强而成为日益严重的社会威胁。现有方法通常专注于单一类型的扭曲，并且难以泛化到未见过的场景。", "innovation": "提出了一种联合训练不同扭曲类型的方法，以促进知识共享并增强模型的泛化能力。TRUST-VL 是一种统一且可解释的跨模态模型，用于泛化多模态虚假信息检测，引入了 Question-Aware 视觉增强模块，用于提取任务特定的视觉特征。构建了 TRUST-Instruct 数据集，包含 198K 个样本，并包含与人类事实核查工作流程对齐的结构化推理链，以支持培训。", "conclusion": "广泛的实验表明，TRUST-VL 达到了最先进的性能，同时提供了强大的泛化能力和解释性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04351", "html_url": "https://arxiv.org/abs/2509.04351", "title": "全局到局部或局部到全局？通过高效局部搜索和有效全局重新排名增强图像检索", "title_en": "Global-to-Local or Local-to-Global? Enhancing Image Retrieval with Efficient Local Search and Effective Global Re-ranking", "authors": "Dror Aiger,Bingyi Cao,Kaifeng Chen,Andre Araujo", "background": "当前的图像检索系统主要通过全局图像特征搜索大型数据库，并使用局部图像特征匹配技术重新排名初始结果。这种全局到局部的策略源自局部匹配方法的计算成本，使它们只能用于少量检索出的图像。然而，新兴的高效局部特征搜索方法为大规模详细检索带来了新可能，特别是在找到全局特征搜索经常忽略的部分匹配时。同时，基于全局特征的重新排名显示了高计算效率下的有希望的结果。", "innovation": "本文利用这些基础模块引入了一种局部到全局的检索范式，结合了高效的局部特征搜索和有效全局特征重新排名。本文提出了一种重新排名方法，其中全球特征根据局部特征检索的相似性在计算时实时生成。这种仅重新排名的全局特征利用多维尺度技术创建尊重搜索中局部相似性的嵌入，从而显著提升了重新排名效果。", "conclusion": "实验结果显示了强大的检索性能，新的全局到局部和局部到全局方法在重访牛津和巴黎数据集上设定了新的最佳结果。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04403", "html_url": "https://arxiv.org/abs/2509.04403", "title": "适应性数据集构建用于真实世界的多模态安全场景", "title_en": "Self-adaptive Dataset Construction for Real-World Multimodal Safety Scenarios", "authors": "Jingen Qu,Lijun Li,Bo Zhang,Yichen Yan,Jing Shao", "background": "多模态大型语言模型（MLLMs）正在快速演变，带来了日益复杂的安全挑战。然而，现有的数据集构建方法主要是基于风险的，无法覆盖实际多模态安全场景（RMS）不断增长的复杂性。由于缺乏统一的评估指标，这些方法的有效性尚未得到证明。", "innovation": "该论文引入了一种以图像为中心的自适应数据集构建方法用于RMS，从图像开始，最终形成配对文本和指导响应的数据集。使用该方法，自动生成一个包含35,000个图像文本对和指导响应的RMS数据集。此外，该论文还提出了一项标准化的安全数据集评估指标：微调一个安全裁判模型，并评估其在其他任务上的能力。", "conclusion": "实验表明，提出的以图像为中心的管道的有效性和可扩展性，为现实世界多模态安全数据集的构建提供了一个新的视角。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2309.16494", "html_url": "https://arxiv.org/abs/2309.16494", "title": "通过多感受野非局部网络和新颖对比正则化实现准确且轻量级的除雾", "title_en": "Accurate and lightweight dehazing via multi-receptive-field non-local network and novel contrastive regularization", "authors": "Zewei He,Zixuan Chen,Jinlei Li,Ziqian Lu,Xuecheng Sun,Hao Luo,Zhe-Ming Lu,Evangelos K. Markakis", "background": "近年来，基于深度学习的方法已主导了除雾领域。为了进一步提高性能，本文提出了一种由多流特征注意力模块(MSFAB)和交叉非局部模块(CNLB)组成的多感受野非局部网络(MRFNLN)。首先提取更丰富的特征以实现除雾。随后采用注意力模块使模型能够自适应地关注重要的通道/区域。这些模块构成了MSFAB。接着设计了增强查询分支关键和值分支的交叉非局部模块(CNLB)，通过融合更多前向特征以捕捉超越查询的长期依赖关系。最后，提出了一种新颖的细节关注对比正则化(DFCR)，专注于低级细节，忽略高级语义信息，以特别设计的除雾表示空间改进了性能。实验结果表明，提出的MRFNLN模型在参数量不到150万的情况下优于最新的基准除雾方法。", "innovation": "提出了多感受野非局部网络(MRFNLN)，包括多流特征注意力模块(MSFAB)和交叉非局部模块(CNLB)，以增强除雾性能。具体创新点包括：多尺度特征提取、自适应重要通道/区域注意力机制、捕捉长期依赖的交叉非局部模块、减少计算和内存消耗的新型对比正则化方法。", "conclusion": "提出的MRFNLN在参数量少于150万的情况下，优于最新的基准除雾方法，性能全面超越现有技术。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04441", "html_url": "https://arxiv.org/abs/2509.04441", "title": "DEXOP: 一种用于灵巧人机操作转移的设备", "title_en": "DEXOP: A Device for Robotic Transfer of Dexterous Human Manipulation", "authors": "Hao-Shu Fang,Branden Romero,Yichen Xie,Arthur Hu,Bo-Ruei Huang,Juan Alvarez,Matthew Kim,Gabriel Margolis,Kavya Anbarasu,Masayoshi Tomizuka,Edward Adelson,Pulkit Agrawal", "background": "该研究旨在通过使用机器人技术收集人类灵巧操作的数据，并在机器人上实现这些操作，以提高机器人的灵巧性。研究提出了一种新的数据收集范式perioperation，它通过传感器化和录制人类操作，同时最大化数据在真实机器人之间的可移植性。该研究使用了DEXOP（ Dexterous External Manipulation Operator），一种被动的手部外骨骼，目的是最大化人类收集丰富感觉（视觉+触觉）数据的能力，用于各种灵巧的抓取任务。", "innovation": "该研究创新性地提出了一种新的数据收集范式perioperation，并通过DEXOP实现了人类的操作技巧向机器人的真实转移。DEXOP通过机械方式连接人类手指和机器人手指，提供直接的接触反馈（通过本体感受），并使人类手部的姿态与被动机器人手部同步，从而最大化展示技能向机器人的转移。这种方式使得手眼协调的任务示范对人类来说更加自然，提高了示范的速度和准确性。", "conclusion": "该研究表明，使用DEXOP获得的数据训练得到的策略在单位时间内比通过远程操作训练得到的策略提高了任务性能。这表明DEXOP是一个对提升机器人灵巧性非常有力量的工具。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04324", "html_url": "https://arxiv.org/abs/2509.04324", "title": "OVGrasp: 开放词汇抓握辅助通过多模态意图检测", "title_en": "OVGrasp: Open-Vocabulary Grasping Assistance via Multimodal Intent Detection", "authors": "Chen Hu,Shan Luo,Letizia Gionfrida", "background": "对于患有运动障碍的人来说，抓握辅助对于恢复其自主性至关重要，尤其是在对象类别和用户意图多样化且难以预测的非结构化环境中。现有的抓握辅助方法在开放环境中通常难以泛化，因此需要一种新的多模态控制框架来改进这种状况。", "innovation": "OVGrasp 提出了一种基于软外骨骼的多模态抓握辅助框架，结合了 RGB-D 视觉、开放词汇提示和语音命令，实现了多模态的鲁棒交互。通过引入视觉语言基础模型和开放词汇机制，OVGrasp 可以进行零样本检测，即使是对以前未见过的对象也能提供支持。此外，多模态决策者融合了空间和语言线索来推断用户意图，如抓取或释放物体。", "conclusion": "实验结果表明，OVGrasp 在 15 种不同物体的三类抓握中实现了 87.00% 的抓取得分，并且在多种基线方法中表现最佳，同时与自然的手部运动具有更好的运动相位对齐。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.20188", "html_url": "https://arxiv.org/abs/2405.20188", "title": "SPARE: 对齐点到面距离的鲁棒非刚性配准", "title_en": "SPARE: Symmetrized Point-to-Plane Distance for Robust Non-Rigid Registration", "authors": "Yuxin Yao,Bailin Deng,Junhui Hou,Juyong Zhang", "background": "现有的基于优化的方法通常通过最小化点对点或点对面距离来实现非刚性配准，但这可能导致收敛速度慢或细节丢失的问题。", "innovation": "作者提出了SPARE，一种利用对称点到面距离的新颖公式，以实现鲁棒的非刚性配准。还提出了一种使用近似最大化最小化策略的交替最小化求解器，并引入了一种刚性调节项来估计变形法线，以及一种基于变形图的粗略对齐方法，以提高求解的准确性和效率。", "conclusion": "大量实验表明，该方法在保持较高求解效率的同时极大地提高了非刚性配准问题的准确性。相关代码已在以下网址公开：this https URL."}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.16507", "html_url": "https://arxiv.org/abs/2311.16507", "title": "基于扩散模型耦合先验的流动对齐改进", "title_en": "Straighter Flow Matching via a Diffusion-Based Coupling Prior", "authors": "Siyu Xing,Jie Cao,Huaibo Huang,Haichao Shi,Xiao-Yu Zhang", "background": "流匹配作为一种生成模型范式，已经在多个领域取得了显著的成功。然而，现有的方法要么需要多轮训练，要么依赖于小批量内的知识，这在找到有利于直角轨迹的方法时带来了挑战，特别是在短步骤生成中。因此需要一种新的方法来改进这一点。", "innovation": "作者提出了一种名为StraightFM的新方法，通过在整体分布级别应用耦合策略来直角化轨迹。在训练过程中，StraightFM通过一个扩散模型将图像和噪声耦合，并用于直角化轨迹以便进行短步骤生成。该方法的耦合策略还可以与来自真实数据到噪声的实际耦合方向相结合，从而改善了短步骤生成中的图像质量。实验结果表明，在像素空间和潜在空间上，通过5步生成可以获得吸引人的图像样本，而无需训练的无条件StraightFM方法可以无缝应用于无条件多模态生成，进而保持高质量图像生成的能力。", "conclusion": "实验结果证明，通过5步生成可以获得吸引人的图像样本，且无缝兼容无条件多模态生成，保持了高质量图像生成的能力。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04145", "html_url": "https://arxiv.org/abs/2509.04145", "title": "Hyper Diffusion Avatars: 使用网络权重空间扩散实现动态人类虚拟角色生成", "title_en": "Hyper Diffusion Avatars: Dynamic Human Avatar Generation using Network Weight Space Diffusion", "authors": "Dongliang Cao,Guoxing Sun,Marc Habermann,Florian Bernard", "background": "创建人类虚拟角色是既富有吸引力又极具挑战性的任务。最近的辐射场渲染技术已经实现了前所未有的逼真度和实时性能，用于个性化的人类动态虚拟角色。但是，这些方法通常仅限于对单个个体的多视角视频数据进行特定人物的渲染模型训练，这限制了它们在不同身份间的泛化能力。另一方面，依赖于预训练的2D扩散模型的生成方法能够产生静态、卡通感的人类虚拟角色，这些角色通过简单的骨架方式实现动画效果。因此，这些方法生成的虚拟角色的渲染质量较低，且无法捕捉到诸如衣服褶皱等依赖于姿势的具体变形。", "innovation": "在这项论文中，我们提出了一种新颖的方法，将特定人物的渲染技术和基于扩散的生成建模的长处结合，以实现具有高度逼真度和真实姿势依赖变形的动态人类虚拟角色生成。该方法遵循两阶段管线：首先优化一组特定人物的UNets（每个网络代表动态人类虚拟角色，捕捉复杂的姿势依赖变形），第二阶段训练一个超扩散模型，基于优化后的网络权重。推理时，该方法生成实时可控渲染的动态人类虚拟角色的网络权重。使用大规模、跨个体的多视角视频数据集，我们证明了该方法优于最新的动态人类虚拟角色生成方法。", "conclusion": "我们的方法证明了，通过结合特定人物的渲染技术和基于扩散的生成建模，可以在保持高逼真度的同时，捕捉到依赖于姿势的具体变形，从而实现了动态人类虚拟角色的生成。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.06002", "html_url": "https://arxiv.org/abs/2409.06002", "title": "基于更强指导的语义分割生成数据增强增强", "title_en": "Enhanced Generative Data Augmentation for Semantic Segmentation via Stronger Guidance", "authors": "Quang-Huy Che,Duc-Tri Le,Bich-Nga Pham,Duc-Khai Lam,Vinh-Tiep Nguyen", "background": "像素级别的标注任务如语义分割需要大量的标记工作，并且传统的数据增强方法，如旋转和翻转，产生的新图像在关键的语义维度上缺乏多样性，并不能改变高层语义属性。为了解决这个问题，生成模型作为一种有效的解决方案出现了，通过生成合成图像来进行数据增强。虽然可控制的生成模型可以通过使用提示和原始图像的视觉参考用于语义分割任务，但它们在生成能够准确反映原始图像内容和结构的图像时仍然有挑战，因为有效提示和视觉参考的创建存在困难。", "innovation": "该作引入了一种基于可控制扩散模型的语义分割数据增强管道，通过使用类别提示附加和视觉先验融合来有效生成提示，增强对真实图像中标记类别的注意力，使管道能够生成精确数量的增强图像并保持分割标记类别的结构。此外，还实现了类别平衡算法以确保合并合成和原始图像后的训练数据集的平衡。", "conclusion": "通过在PASCAL VOC数据集上的评估，该管道展示了其在生成高质量的合成图像以用于语义分割方面的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.06911", "html_url": "https://arxiv.org/abs/2405.06911", "title": "基于实时物体检测模型的重复研究与基准测试", "title_en": "Replication Study and Benchmarking of Real-Time Object Detection Models", "authors": "Pierre-Luc Asselin,Vincent Coulombe,William Guimont-Martin,William Larrivée-Hardy", "background": "本文研究了最新实时物体检测模型的可重复性和基准测试。由于物体检测模型经常用于如机器人这些实时场景，仅通过准确性来评估模型是不够的，因此本文尝试在多个图形处理器上比较多种物体检测模型的准确性和推理速度。鉴于研究模型通常在重现性方面存在缺陷，并且针对迅捷检测（MMDetection）预训练模型在有限计算资源下的速度性能显著下降，本文还重新实现了DETR、RTMDet、ViTDet和YOLOv7模型，并提出了一个统一的训练和评估管道，以更好地进行比较。研究表明，模型的准确性和速度存在明显的权衡，无锚点模型（如RTMDet和YOLOx）尤为重要。", "innovation": "提出了一个基于迅捷检测框架的统一训练和评估管道，重新实现了DETR、RTMDet、ViTDet和YOLOv7模型，并发现这些模型在有限计算资源下的速度性能与原论文描述的有显著差异，特别地，无锚点模型在精度和速度之间存在权衡。", "conclusion": "本文的研究显示了多种物体检测模型的准确性和速度表现，并提出了一种统一的基准测试方法。尽管部分重新实现的模型在速度和精度上达到了与原论文类似的表现，但也发现许多研究论文在重现性方面存在缺陷，MMDetection的预训练模型在有限计算资源下的速度表现显著下降，且精度和速度之间存在明显的权衡关系。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2312.03993", "html_url": "https://arxiv.org/abs/2312.03993", "title": "使用稳定扩散技术将风格转移至卡尔文与霍布斯漫画", "title_en": "Style Transfer to Calvin and Hobbes comics using Stable Diffusion", "authors": "Asvin Kumar Venkataramanan,Sloke Shrestha,Sundar Sripada Venugopalaswamy Sriraman", "background": "本项目报告总结了我们使用卡尔文和霍布斯漫画数据集进行稳定扩散微调的过程，目的是将给定的图像转换为卡尔文和霍布斯的漫画风格，实现风格转换。我们使用低秩适应（LoRA）方法对stable-diffusion-v1.5进行微调，以加快这一过程。扩散过程由一个变分自编码器（VAE）处理，该VAE是一个U-net模型。经过训练的结果在视觉上具有吸引力，尤其是在训练时间和输入数据质量有限的情况下，表现出色。", "innovation": "本研究的创新之处在于通过低秩适应（LoRA）方法对stable-diffusion-v1.5进行微调，以非监督方式在有限的训练时间内优化变分自编码器（VAE）的U-net模型，以实现卡尔文与霍布斯的漫画风格转换，提高了微调过程的效率和效果。", "conclusion": "我们的结果在视觉上具有吸引力，即使输入图像的质量和训练时间有限，升级后的稳定扩散模型仍然能够高效地进行风格转换，将其转换为卡尔文与霍布斯的漫画风格。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04394", "html_url": "https://arxiv.org/abs/2509.04394", "title": "过渡模型：重新思考生成学习目标", "title_en": "Transition Models: Rethinking the Generative Learning Objective", "authors": "Zidong Wang,Yiyuan Zhang,Xiaoyu Yue,Xiangyu Yue,Yangguang Li,Wanli Ouyang,Lei Bai", "background": "生成建模中存在一个基本的两难困境：迭代扩散模型在计算成本显著较高的情况下实现了卓越的保真度，而高效的几步替代方案则受限于硬的质量上限。这种生成步骤与输出质量之间的冲突源自于训练目标的限制，这些目标仅专注于无穷小动态或直接终点预测。", "innovation": "本文通过引入一个精确的连续时间动力学方程，该方程在任意有限时间区间内可分析定义状态转换，提出了新型生成 paradigmin——过渡模型（TiM）。TiM 能够适应任意步数转换，无缝地从单次跳跃到更精细的逐步细化生成轨迹。尽管参数量仅为 865M，但 TiM 在所有评估的步数计数中均超越了包括 SD3.5 在内的领先模型，后者具有 8B 参数，FLUX.1 具有 12B 参数。此外，与之前的几步生成器不同，TiM 在采样预算增加时展现了单调的质量改进。", "conclusion": "当采用我们原分辨率策略时，TiM 能够在 4096x4096 的高分辨率下实现卓越的保真度。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.06119", "html_url": "https://arxiv.org/abs/2411.06119", "title": "硬件友好的在设备上图像生成的固定大小可重用结构的扩散模型", "title_en": "Hardware-Friendly Diffusion Models with Fixed-Size Reusable Structures for On-Device Image Generation", "authors": "Sanchar Palit,Sathya Veera Reddy Dendi,Mallikarjuna Talluri,Raj Narayana Gadde", "background": "Vision Transformers和U-Net架构在扩散模型的实现中被广泛使用。然而，这些架构在设备上实现时各有特定的挑战。Vision Transformers需要位置嵌入以保持通过转换器处理的标记之间的对应关系，但这使其更适合分块处理和重复使用。而U-Net架构中存在变大小的中间块，这不利于固定结构的实现和重复使用。", "innovation": "本文提出了一种将固定大小和可重用的Transformer块作为核心结构的架构，使其更适合硬件实施。这种架构具有低复杂度、标记免费设计、无位置嵌入、均匀性和可扩展性，非常适合部署在移动和资源受限的设备上。该模型在无条件和有条件图像生成任务上的性能表现出竞争力且一致。在无条件图像生成任务中，该模型在CelebA上的状态最优FID得分为1.6。", "conclusion": "本文提出了一种新的架构，该架构利用固定大小和可重用的Transformer块作为核心结构，使之更加适合设备上的实现。该模型在多个任务上的表现证明了其在移动和资源受限设备上的适用性和有效性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.12722", "html_url": "https://arxiv.org/abs/2412.12722", "title": "通过部分感知监督防御大型视觉语言模型的视觉攻击", "title_en": "Defending LVLMs Against Vision Attacks through Partial-Perception Supervision", "authors": "Qi Zhou,Tianlin Li,Qing Guo,Dongxia Wang,Yun Lin,Yang Liu,Jin Song Dong", "background": "近期的研究揭示了大型视觉语言模型（LVLMs）在面对恶意注入或扰动图像时的脆弱性，这些扰动可以误导模型的响应。现有防御措施表明，这类视觉攻击对图像修改（尤其是裁剪）非常敏感，通常使用修改图像的响应进行多数投票作为纠正响应。然而，这种修改往往产生部分图像，导致语义失真，这在对干净图像进行投票后降低了响应质量。", "innovation": "提出了一种无需训练的黑盒防御方法 DPS（通过部分感知监督防御）。这种方法利用只有部分图像感知模型产生的响应来监督原始图像上的LVLM响应。在受到攻击时，模型可以根据部分图像的理解调整其响应，同时保持对干净输入的原始信心。研究发现，弱模型可以监督强模型：面对攻击输入时，强模型会变得不那么自信，并根据弱模型的部分理解调整其响应，从而有效防范攻击。而面对干净输入时，它会自信地保持其原始响应。", "conclusion": "实验结果表明，该方法优于基线，能够将六种类别数据集上的平均攻击成功率降低76.3%，适用于三种流行模型。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.13756", "html_url": "https://arxiv.org/abs/2503.13756", "title": "基于切片Wasserstein距离的快速异质图像刚性对齐", "title_en": "Fast rigid alignment of heterogeneous images in sliced Wasserstein distance", "authors": "Yunpeng Shi,Amit Singer,Eric J. Verbeke", "background": "许多计算机视觉的应用依赖于对相似但不完全相同的图像进行对齐。", "innovation": "提出了一种基于最优传输的快速图像对齐算法，结合了快速傅里叶方法的速度与切片概率度量的鲁棒性，能够在O(L^2 log L)运算中高效计算两个L×L图像的切片2- Wasserstein距离，实现对齐。该方法对图像的平移、旋转和变形具有鲁棒性。", "conclusion": "该方法能快速有效地对齐异质图像，并在实际应用中表现出良好的鲁棒性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.20323", "html_url": "https://arxiv.org/abs/2502.20323", "title": "ARTalk：基于自回归模型的语音驱动3D头部动画", "title_en": "ARTalk: Speech-Driven 3D Head Animation via Autoregressive Model", "authors": "Xuangeng Chu,Nabarun Goswami,Ziteng Cui,Hanqin Wang,Tatsuya Harada", "background": "现有的基于扩散的方法能够产生自然的面部动作，但这些方法生成面部动作的速度较慢，限制了它们的应用潜力。本文的背景在于探讨如何克服这一限制，实现快速且准确的3D面部动画。", "innovation": "本文引入了一种新型的自回归模型，能够通过学习语音到多层次运动代码库的映射，实现实时生成高度同步的嘴唇动作和真实的头部姿态以及眼部眨眼。此外，该模型能够适应未见过的语音风格，生成具有独特个人风格的3D交流者。", "conclusion": "广泛的评估和用户研究证明了本文方法在嘴唇同步准确性及感知质量方面优于现有的方法。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.08352", "html_url": "https://arxiv.org/abs/2502.08352", "title": "Sat-DN: 多视角卫星图像中的深度和法线监督隐式曲面重建", "title_en": "Sat-DN: Implicit Surface Reconstruction from Multi-View Satellite Images with Depth and Normal Supervision", "authors": "Tianle Liu,Shuangming Zhao,Wanshou Jiang,Bingxuan Guo", "background": "卫星成像技术的进步使得获取高分辨率多视角卫星图像变得越来越容易，进而能够快速且不受地理位置限制地重建地表模型。然而，传统的立体匹配方法难以捕捉到详细的特征，而神经辐射场（NeRFs）虽然能够实现高质量的重建，但其训练时间却非常长。此外，卫星图像中的建筑物立面低可见性、像素间存在的光照和风格差异，以及缺乏纹理区域，进一步增加了地形几何和详细建筑物轮廓重建的难度。因此，迫切需要一种新的方法来解决上述问题。（卫星图像中的）建筑物立面低可见性、像素间的光照差异和风格差异，以及缺乏纹理区域，使得实现合理的地形几何和详细的建筑物轮廓重建变得更加困难。", "innovation": "该论文提出了Sat-DN，这是一种新颖的方法，利用逐步训练的多分辨率哈希网格重建架构，结合显式的深度指导和表面法线一致性约束来提升重建质量。多分辨率哈希网格加速了训练过程，逐步训练策略通过粗略的低频几何指导高频细节的重建。深度和法线约束确保了明确的建筑物轮廓和正确的平面分布。", "conclusion": "通过在DFC2019数据集上的广泛实验，Sat-DN 在定性和定量评估中均实现了最先进的结果。与现有方法相比，Sat-DN 出色地解决了建筑物立面低可见性、多视角差异和缺乏纹理区域的问题，提升了重建质量。代码可在以下链接获取：this https URL"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.15537", "html_url": "https://arxiv.org/abs/2411.15537", "title": "MUNBa: 通过纳什谈判进行机器遗忘", "title_en": "MUNBa: Machine Unlearning via Nash Bargaining", "authors": "Jing Wu,Mehrtash Harandi", "background": "机器遗忘（MU）旨在消除模型中的有害行为，同时保持模型的整体实用性。MU可以被视为一个多任务学习问题，需要平衡遗忘特定概念或数据和保持整体性能的目标。直接整合这些目标可能导致梯度冲突和优先，阻碍MU算法达到最优解。", "innovation": "该研究将MU重新表述为两个合作博弈，其中忘记了玩家和保存了玩家通过他们的梯度提案相互贡献，以最大化整体收益并平衡贡献。受到纳什讨价还价理论的启发，提出了一个封闭形式的解决方案，引导模型达到帕累托稳定点。我们的研究成果保证了一个均衡解，任何偏离最终状态都会导致两个玩家的整体目标减少，确保每个目标的最优性。", "conclusion": "我们评估了算法在图像分类和图像生成任务中的有效性。与现有的先进MU算法相比，我们的方法在忘记和保存之间取得了更好的权衡。实验结果还表明，在忘记精度、保存泛化和对抗攻击下的鲁棒性方面也有改进。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.10118", "html_url": "https://arxiv.org/abs/2502.10118", "title": "图像嵌入采样方法用于多样化的标题生成", "title_en": "Image Embedding Sampling Method for Diverse Captioning", "authors": "Sania Waheed,Na Min An", "background": "当前最先进的视觉语言模型（VLMs）在图像字幕方面取得了显著进步，但这也导致了计算复杂度增加，使得这些模型不适合资源受限的应用，如移动设备和辅助技术。较小的VLMs虽然更注重高层次的场景描述，但由于忽略了图像的细致差异，因此未能提供丰富生动的理解能力。", "innovation": "本文提出了一种无需额外训练的框架，通过使用较小的BLIP VLM作为主干，并显式地关注图像的不同区域，增强了字幕的多样性和信息性。该方法利用结构化分割生成层次化的语义表述，同时保持了全局和局部语义的捕捉，无需额外训练就可使较小的VLMs在图像-字幕对齐、语义完整性和多样性等方面达到与更大模型相当的表现。", "conclusion": "我们的方法在MSCOCO、Flickr30k和Nocaps测试数据集上分别实现了0.735、0.750和0.748的Div-2分数，同时保持了与人工标注字幕的高度相关性和语义完整性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.09465", "html_url": "https://arxiv.org/abs/2412.09465", "title": "OFTSR: 一步流形进行具有可调保真度与真实度权衡的图像超分辨率", "title_en": "OFTSR: One-Step Flow for Image Super-Resolution with Tunable Fidelity-Realism Trade-offs", "authors": "Yuanzhi Zhu,Ruiqing Wang,Shilin Lu,Junnan Li,Hanshu Yan,Kai Zhang", "background": "近年来，扩散和流形生成模型在图像复原任务中取得了显著的成功，表现出比传统深度学习方法更高的感知质量。然而，这些方法要么需要多次采样步骤来生成高质量的图像，从而导致了大量的计算开销，要么依赖于通用的模型蒸馏，通常会限制保真度与真实度之间的灵活性选择，缺乏调整的灵活性。", "innovation": "本文提出了一种新型的流形框架OFTSR，它可以在一步内进行图像超分辨率，同时生成具有可调保真度和真实度的输出。首先，训练一个条件流形超分辨率模型作为教师模型。然后通过应用特定约束对教师模型进行蒸馏，具体来说，强制一步学生模型的预测与教师模型在相同输入下的预测位于同一采样ODE轨迹上，以确保学生模型从初始状态的一次预测与教师模型从更接近中间状态的预测相匹配。", "conclusion": "通过在包括FFHQ（256×256）、DIV2K和ImageNet（256×256）的数据集上的大量实验，本文展示了OFTSR在一步图像超分辨率上取得了最先进的性能，同时能灵活地调整保真度与真实度权衡。代码可在指定链接中获取。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.23746", "html_url": "https://arxiv.org/abs/2503.23746", "title": "Short-video Propagation Influence Rating：一个新的真实世界数据集和一个新的大型图模型", "title_en": "Short-video Propagation Influence Rating: A New Real-world Dataset and A New Large Graph Model", "authors": "Dizhan Xue,Shengsheng Qian,Chuanrui Hu,Changsheng Xu", "background": "短视频平台受到了全球数以亿计用户的追捧，其传播模式吸引了研究人员的关注。近期研究强调了分析短视频传播的重要性，包括发现其商业价值、公众意见、用户行为等。然而，目前缺乏大规模且跨平台的真实世界短视频传播数据集，并且对于如何有效地分析和预测短视频的传播影响缺乏有效的方法。", "innovation": "该论文提出了一项新的短视频传播影响力评级（SPIR）任务，并从数据集和方法两个方面推动SPIR的发展。首先，论文提出了一个全新的跨平台短视频（XS-Video）数据集，该数据集包含了来自中国五大平台的117,720个视频，381,926个样本和535个话题，涵盖了从传播影响等级0到9的手动标注，并且是首个包含跨平台数据或提供所有观点、点赞、分享、收藏、粉丝、评论和评论内容的大规模数据集。其次，基于一个新颖的三阶段训练机制，论文提出了一个基于大规模语言模型的知识推理能力的新大型图模型NetGPT，该模型能够理解并分析短视频传播图，从而预测短视频的长期传播影响。", "conclusion": "实验结果表明，NetGPT方法在XS-Video数据集上的分类和回归评价指标均优于其他方法，这证明了所提出的方法在短视频传播影响力评级任务上的优越性。该工作为短视频传播研究提供了一个新的工具和数据集，有助于更好地理解和预测短视频的传播影响。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.05750", "html_url": "https://arxiv.org/abs/2408.05750", "title": "FADE: 一种用于视频中检测建筑物周围坠落物体的数据库", "title_en": "FADE: A Dataset for Detecting Falling Objects around Buildings in Video", "authors": "Zhigang Tu,Zitao Gao,Zhengbo Zhang,Chunluan Zhou,Junsong Yuan,Bo Du", "background": "落物体从建筑物坠落可能会对行人造成严重的伤害，因为它们会施加巨大的冲击力。尽管一些建筑物周围安装了监控摄像头，但由于坠落物体体积小、移动速度快以及背景复杂，人类很难在监控视频中捕捉到这些事件。因此，有必要开发能够自动检测建筑物周围监控视频中坠落物体的方法。", "innovation": "首次提出一种名为FADE（FAlling Object DEtection around Buildings）的大型、多样化的视频数据集。FADE数据集包含1,881个来自18个场景的视频，涵盖8类坠落物体、4种天气条件和4种视频分辨率。此外，开发了一种新的目标检测方法FADE-Net，有效利用了运动信息，产出了较小但高质量的提案，用于检测建筑物周围的坠落物体。以FADE数据集为基础，针对通用目标检测、视频目标检测和运动目标检测方法进行了广泛评估和分析，结果表明，提出的方法显著优于其他方法。", "conclusion": "提出的FADE-Net在FADE数据集上提供了更为有效的基准，为未来的研究奠定了基础。数据集和代码已经公开，可以在指定的网址获取。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.11491", "html_url": "https://arxiv.org/abs/2405.11491", "title": "BOSC：基于后门攻击的开放集合成图像归属框架", "title_en": "BOSC: A Backdoor-based Framework for Open Set Synthetic Image Attribution", "authors": "Jun Wang,Benedetta Tondi,Mauro Barni", "background": "合成图像归属旨在追踪生成模型生成的图像来源。先前的研究侧重于通过提取生成模型的独特特征来识别图像，但主要方法在识别已知架构生成的图像方面有效，而忽视了未知架构生成的可能性。随着AI技术的发展，不断涌现的新生成架构促使研究者将注意力转向能在开放集场景下工作的工具开发。", "innovation": "本文提出了一种基于后门攻击的开放集合成图像归属框架-BOSC，通过在训练集中特意注入特定类别的触发器，使网络在样本激活时建立类别特征和触发器特征之间的匹配。并在测试时利用对触发样本的行为进行学习来执行样本拒绝并通过定制分值进行检测。实验显示该方法性能优良，能够有效避免图像处理对抗。", "conclusion": "BOSC 方法在合成图像归属任务上具有良好的性能，优于当前最先进的方法，并且对图像处理具有很强的鲁棒性。该框架具有普适性，也可以用于其他图像取证应用。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.13392", "html_url": "https://arxiv.org/abs/2504.13392", "title": "POET: 使用自动扩展文本生成图像支持提示创造力和个性化", "title_en": "POET: Supporting Prompting Creativity and Personalization with Automated Expansion of Text-to-Image Generation", "authors": "Evans Xu Han,Alice Qian Zhang,Haiyi Zhu,Hong Shen,Paul Pu Liang,Jane Hsieh", "background": "当前最先进的视觉生成人工智能工具在创意任务的早期阶段为用户提供巨大帮助，能够生成高质量的创新图像，但在大规模的应用中，这些工具通常产生较为常规的结果，限制了创意探索。同时，用户交互方式可能不适合初学者。鉴于创意用户在不同上下文中的行为往往是不可预测的，需要更多样化和个性化的支持。因此，需要一种能够自动发现并扩大文本到图像生成模型维度、从用户反馈中进行个性化修改的工具，以更好地支持用户的创意过程和个人化需求。", "innovation": " researchers introduced POET，一种实时交互工具，实现如下功能：1）自动发现文本到图像生成模型中的同质性维度，2）扩展这些维度以增加生成图像的空间多样性，3）通过用户反馈学习个性化扩展。", "conclusion": "通过与28名来自四个创意任务领域的用户进行评估，POET显示了生成更高感知多样性的结果，并且能够在较少的提示下帮助用户实现更满意的创意任务目标，促使他们在协同创作过程中进行更多的反思与思考。POET为未来文本到图像生成工具的交互技术如何支持用户的多样化价值观需求提供了初步的视角。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.14891", "html_url": "https://arxiv.org/abs/2502.14891", "title": "CoDiff: 基于条件扩散模型的协作3D物体检测", "title_en": "CoDiff: Conditional Diffusion Model for Collaborative 3D Object Detection", "authors": "Zhe Huang,Shuo Wang,Yongcai Wang,Lei Wang", "background": "协同3D物体检测在自动驾驶领域具有重要意义，它能够通过多个代理之间的信息交换大幅提升个体代理的感知能力。然而，在实际应用中，由于姿态估计误差和时间延迟，代理间的特征融合常常会带来空间和时间噪声，导致检测错误。", "innovation": "本文提出了一种名为CoDiff的新型鲁棒协作感知框架，利用扩散模型生成更全面、更清晰的特征表示。CoDiff是首次将扩散模型应用于多代理协作感知中。具体来说，将高维特征图投影到预训练自编码器的潜在空间中，并在该空间内将个体代理信息作为条件指导扩散模型的采样过程，这一过程可以去除粗糙特征图中的噪声并逐步精细融合特征。", "conclusion": "在模拟和真实数据集上的实验表明，提出的框架CoDiff在协作物体检测性能方面显著优于现有的相关方法，并且在代理的姿态和延迟信息具有高水平噪音的情况下展示了高度的稳健性。代码已发布于此网址：this https URL"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.02980", "html_url": "https://arxiv.org/abs/2505.02980", "title": "用于基因表达预测基准测试的Spatial Transcriptomics数据完成", "title_en": "Completing Spatial Transcriptomics Data for Gene Expression Prediction Benchmarking", "authors": "Daniela Ruiz,Paula Cárdenas,Leonardo Manrique,Daniela Vega,Gabriel M. Mejia,Pablo Arbeláez", "background": "空间转录组学是一种将组织切片显微图像与空间分辨率基因表达谱结合起来的开创性技术。在各种空间转录组学方法中，Visium因其广泛应用而成为最受欢迎的技术。然而，由于成本高昂、需要专业技能以及临床集成缓慢，其可及性受限。此外，基因捕获效率低下导致数据丢失，影响了获取的数据质量。为解决这些问题，深度学习社区将基因表达直接从组织切片图像预测的任务作为一个研究方向，但不同数据集、预处理和训练协议的一致性问题阻碍了模型之间的公正比较。", "innovation": "本文提出了一种名为SpaRED的系统性集中的数据库，包括26个公共数据集，提供了一个标准化的评估资源。此外，本文提出了一个基于Transformer的最先进的基因表达完成模型名为SpaCKLE，其均方误差比现有方法降低了82.5%以上。最后，本文建立了SpaRED基准，评估了八种最先进的预测模型在原始数据和SpaCKLE完成数据上的性能，结果显示SpaCKLE显著提高了所有基因表达预测模型的性能。总之，本文的贡献是迄今为止最全面的空间转录组学数据中基因表达预测的基准，并成为未来空间转录组研究的基石。", "conclusion": "我们的贡献构成了迄今为止最全面的空间转录组学数据中基因表达预测基准，并为未来空间转录组研究奠定基础。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.05774", "html_url": "https://arxiv.org/abs/2504.05774", "title": "可转移掩码转换器：基于区域自适应转移性估计的跨域语义分割", "title_en": "Transferable Mask Transformer: Cross-domain Semantic Segmentation with Region-adaptive Transferability Estimation", "authors": "Jianhua Liu,Zhengyu Li,Yanru Wu,Jingge Wang,Yang Tan,Ruizhe Zhao,Guan Wang,Yang Li", "background": "近期，视觉变换器(ViTs)在语义分割任务中取得了新的基准性能。然而，当将预训练的ViTs应用于新的目标领域时，由于数据分布的变化，往往会带来性能的显著下降，导致全局注意力的不理想表现。由于自注意力机制本质上依赖数据，当源域和目标域在纹理、尺度或物体共现模式上存在差异时，它们可能无法有效关注关键对象。虽然全局和基于补丁的域适应方法提供了一定的解决方案，但在具有空间异质性的不同图像区域之间进行自适应时，基于区域的自适应方法（特别是具有动态形状的区域）是至关重要的。因此，为了正确定位具有低转移性和高语义不确定性区域的自适应，领域适应方法至关重要。本文旨在通过空间转移性分析构建一种新型的基于区域的自适应框架 Transferable Mask Transformer (TMT)来解决这一问题。", "innovation": "该论文提出了Transferable Mask Transformer (TMT)，这是一种新型的基于区域的自适应框架，用于语义分割。TMT 包括两个关键组件：（1）一组自适应的基于聚类的转移性估算器（ACTE），用于动态地将图像分割成结构和语义上一致的区域，进行局部转移性评估；（2）一种可转移的掩码注意力（TMA）模块，将区域特定的转移性图集成到 ViTs 的注意力机制中，优先在低转移性和高语义不确定性区域进行自适应。", "conclusion": "通过对20个跨域配对进行综合评估，TMT 展现了其优越性，与传统的微调相比，平均提高了2% 的 MIoU，与最先进的基线相比，提高了1.28%。源代码将公开提供。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.07611", "html_url": "https://arxiv.org/abs/2505.07611", "title": "深度学习在基于视觉的交通事故预知中的进展：方法、数据集和未来方向的全面综述", "title_en": "Deep Learning Advances in Vision-Based Traffic Accident Anticipation: A Comprehensive Review of Methods, Datasets, and Future Directions", "authors": "Ruonan Lin,Tao Tang,Yongtai Liu,Wenye Zhou,Xin Yang,Hao Zheng,Jianpu Lin,Yi Zhang", "background": "交通事故的预测与检测对于提升道路安全至关重要。深度学习时代的基于视觉的交通事故预知（Vision-TAA）作为一种有前景的方法正逐渐兴起。已有研究主要集中在监督、无监督及混合深度学习模型在事故预测中的应用，同时使用了真实世界和合成数据集。这些方法在事故预测中展示了显著的潜力，但仍然面临着数据稀缺、对复杂场景的泛化能力有限以及实时性能的约束等挑战。", "innovation": "论文总结了147篇近期研究，提出了四类关键方法：基于图像和视频特征的预测、基于时空特征的预测、场景理解以及多模态数据融合，并指出了未来研究中的机会，包括多模态数据融合、自我监督学习和基于Transformer的架构，以增强预测精度和可扩展性。", "conclusion": "论文通过综合现有进展并识别关键缺口，为开发稳健且适应性强的Vision-TAA系统提供了基础参考，有助于提升道路安全和交通管理。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23525", "html_url": "https://arxiv.org/abs/2505.23525", "title": "Hallo4: 通过直接偏好优化和时间运动调制实现高保真动态肖像动画", "title_en": "Hallo4: High-Fidelity Dynamic Portrait Animation via Direct Preference Optimization and Temporal Motion Modulation", "authors": "Jiahao Cui,Yan Chen,Mingwang Xu,Hanlin Shang,Yuxuan Chen,Yun Zhan,Zilong Dong,Yao Yao,Jingdong Wang,Siyu Zhu", "background": "由于需要精确的唇部同步、自然的脸部表情和高质量的人物动作动态，通过音频和骨骼运动生成高度动态和照片级的真实感肖像动画仍然具有挑战性。", "innovation": "我们提出了一种与人体偏好对齐的扩散框架，通过以下两个关键创新来应对这些挑战：1. 引入针对以人为本动画的直接偏好优化，利用精心挑选的人体偏好数据集，使生成的输出与可感知的指标对齐，确保肖像运动视频的对齐和表情的自然；2. 提出的时间运动调制通过时间和通道重组以及比例特征扩展，解决时空分辨率不匹配问题，将运动条件重塑为维度对齐的潜在特征，从而保持基于扩散合成的高度频率运动细节保真度。", "conclusion": "我们的机制与现有的基于UNet和DiT的肖像扩散方法相辅相成，实验结果显示在唇部音频同步、表情生动性和身体运动一致性方面显著优于基线方法，并且在人体偏好指标上也取得了显著的进步。我们的模型和源代码可在以下链接找到：this https URL."}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03522", "html_url": "https://arxiv.org/abs/2505.03522", "title": "单张图像超分辨率中模块转移性优化：普遍性评估与循环残差块", "title_en": "Optimization of Module Transferability in Single Image Super-Resolution: Universality Assessment and Cycle Residual Blocks", "authors": "Haotong Cheng,Zhiqi Zhang,Hao Li,Xinshang Zhang", "background": "深度学习大幅提升了单张图像超分辨率（SISR）领域的研究进展。尽管现有研究主要集中在性能提升上，但少有关注架构组件的转移性。本研究旨在量化模块的转移性，并通过引入“普遍性”及其定义扩展传统泛化概念。", "innovation": "研究提出了“普遍性评估方程”（UAE），这是一种量化模块转移性的新指标，能够揭示多个现有指标对转移性的影响。基于UAE的结果，设计了两种优化模块——循环残差块（CRB）和深度循环残差块（DCRB），并在自然场景基准测试、遥感数据集和低级任务中进行了全面实验，证明了嵌入这些模块的网络在多项指标上优于现有先进方法，参数减少幅度高达71.3%且重建保真度几乎无损。", "conclusion": "研究结果显示引入的优化模块能够显著提高SISR模型的性能并减少模型参数，为未来插件式模块的设计提供了新的范式。类似优化方法可以应用于其他基础模块，开辟新的模块设计思路。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14904", "html_url": "https://arxiv.org/abs/2507.14904", "title": "TriCLIP-3D：基于CLIP的统一参数高效三模态3D视觉接地框架", "title_en": "TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP", "authors": "Fan Li,Zanyi Wang,Zeyi Huang,Guang Dai,Jingdong Wang,Mengmeng Wang", "background": "目前的3D视觉接地方法通常依赖于为不同模态（如RGB图像、文本和3D点云）分别设计的编码器，这导致了模型的复杂性增加和训练效率低下。尽管有些方法使用了预训练的2D多模态模型（如CLIP）来处理3D任务，但它们仍然难以对齐点云数据与2D编码器，因此这些方法仍然依赖3D编码器进行特征提取，进一步增加了模型的复杂性和训练效率。", "innovation": "本文提出了一种统一的2D预训练多模态网络，用于处理所有三种模态（RGB图像、文本和点云），显著简化了架构。通过利用基于适配器的微调的2D CLIP双模态模型，该框架能够有效适应三模态设置，从而提高跨模态的适应性和性能。设计了Geometric-Aware 2D-3D特征恢复与融合（GARF）模块，用于融合点云和图像的几何多尺度特征，并引入多模态解码器以促进深层次的跨模态理解。", "conclusion": "通过这种方法，实现了三模态的统一特征提取和融合，从而能够构建一个端到端的3D视觉接地模型。与基准方法相比，该方法将可训练参数减少了约58％，并且在3D检测任务上的性能提高了6.52％，在3D视觉接地任务上提高了6.25％。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.10823", "html_url": "https://arxiv.org/abs/2505.10823", "title": "从嵌入到准确率：比较放射分类的基础模型", "title_en": "From Embeddings to Accuracy: Comparing Foundation Models for Radiographic Classification", "authors": "Xue Li,Jameson Merkow,Noel C. F. Codella,Alberto Santamaria-Pang,Naiteek Sangani,Alexander Ersoy,Christopher Burt,John W. Garrett,Richard J. Bruce,Joshua D. Warner,Tyler Bradshaw,Ivan Tarapov,Matthew P. Lungren,Alan B. McMillan", "background": "基础模型提供了适用于各种任务的稳健嵌入，包括医学影像学。该研究评估了七个通用和医学特定的基础模型（如DenseNet121、BiomedCLIP、MedImageInsight、Rad-DINO、CXR-Foundation）的嵌入，用于多类放射学分类任务中的轻量级适配器训练。使用包含7个类别共计8,842张放射学图像的数据集，研究者使用K-最近邻、逻辑回归、SVM、随机森林和MLP算法训练适配器。", "innovation": "研究使用了多种基础模型和多种分类算法的组合，发现将MedImageInsight嵌入与SVM或MLP适配器结合使用时，平均曲线下面积（mAUC）最高，达到93.1%。此外，轻量级适配器训练快速，对于CPU来说，推理速度也很快，这使得它们在临床上非常实用。研究还强调了嵌入的公平性，表明MedImageInsight适配器的性能在不同患者性别和年龄组之间没有明显差异，进一步证实了这些嵌入的有效性。", "conclusion": "研究确认，特别是来自MedImageInsight等专门基础模型的嵌入，可以借助简单的轻量级适配器来驱动准确、高效和公平的诊断工具。这些发现展示了基础模型在医学影像分类中的潜力及其在临床应用中的实用性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20789", "html_url": "https://arxiv.org/abs/2505.20789", "title": "在扩散模型中结合中间层优化和投影梯度下降以解决逆问题", "title_en": "Integrating Intermediate Layer Optimization and Projected Gradient Descent for Solving Inverse Problems with Diffusion Models", "authors": "Yang Zheng,Wen Li,Zhaoqiang Liu", "background": "逆问题涉及从噪声观察中重构信号。扩散模型在过去已经证明在求解逆问题方面表现强大。然而，现有基于扩散模型的方法经常遇到计算需求高且收敛性差的问题。DMPlug前期工作为此提供了思路，本文在此基础上提出两种新技术：DMILO和DMILO-PGD，以解决这些挑战。", "innovation": "提出了两种新方法：DMILO和DMILO-PGD。DMILO利用中间层优化（ILO）减轻了DMPlug的内存压力，并通过引入稀疏偏差扩大了扩散模型的范围。DMILO-PGD则是将ILO与投影梯度下降（PGD）结合，降低了次优收敛的风险。提供了解决方案在适当时条件下的直观理论分析，并通过多种图像数据集的实验验证了其优越性。", "conclusion": "结果表明，DMILO和DMILO-PGD在处理基于扩散模型的逆问题中的常见挑战上具有显著的优势，证明了这两种方法的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.20652", "html_url": "https://arxiv.org/abs/2503.20652", "title": "模拟放射学滚动：用于3D胸部CT体积多标签异常分类的全局-局部注意力模型", "title_en": "Imitating Radiological Scrolling: A Global-Local Attention Model for 3D Chest CT Volumes Multi-Label Anomaly Classification", "authors": "Theo Di Piazza,Carole Lazarus,Olivier Nempont,Loic Boussel", "background": "由于计算机断层扫描（CT）扫描检查的数量迅速增加，为放射科医生提供了大量的工作负担，因此迫切需要自动化工具，例如器官分割、异常分类和报告生成以协助他们。三维（3D）CT扫描的多标签分类是一项具有挑战性的任务，原因在于数据的体积性质以及需检测的多种异常。现有的基于卷积神经网络（CNN）的深度学习方法难以有效捕捉长距离依赖关系，而视觉Transformer需要大量的预训练工作，这给实践应用带来了挑战。此外，这些现有方法没有明确地建模放射科医生在分析3D CT扫描切片时的滚动行为，这需要全局上下文理解和局部细节意识。", "innovation": "本文介绍了一种名为CT-Scroll的全新全局-局部注意力模型，该模型专门设计来模拟放射科医生在分析3D CT扫描时的滚动行为。该方法在两个公开数据集上进行了评估，通过全面的实验和消除研究展示了其有效性，并强调了每个模型组件的贡献。", "conclusion": "我们的工作通过评价CT-Scroll模型在3D胸部CT体积多标签异常分类任务中的性能，证明了它在全局上下文理解和局部细节意识方面表现出色，能够有效地捕捉长距离依赖关系和减少需要的预训练工作量。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01587", "html_url": "https://arxiv.org/abs/2507.01587", "title": "基于相机参数的可控实际图像去噪方法", "title_en": "Towards Controllable Real Image Denoising with Camera Parameters", "authors": "Youngjin Oh,Junhyeong Kwon,Keuntek Lee,Nam Ik Cho", "background": "近年来，基于深度学习的图像去噪方法表现出令人印象深刻的性能，但许多方法缺乏根据噪声水平、相机设置和用户偏好调节去噪强度的灵活性。本研究旨在引入一种新的基于相机参数的可控去噪框架，该框架能够利用相机参数（如ISO、快门速度和f数）的信息自适应地去除图像中的噪声，从而实现更灵活的去噪过程。", "innovation": "本研究提出了一种创新的可控去噪框架，通过将与噪声水平紧密相关的相机参数（如ISO、快门速度和f数）转换成向量来控制和增强去噪网络的性能，并实现了去噪标准神经网络的无缝集成与性能改进。", "conclusion": "实验结果表明，该方法能够无缝地添加可控性于标准去噪神经网络，并提高其性能。此外，还提供了可下载访问的代码。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03498", "html_url": "https://arxiv.org/abs/2505.03498", "title": "Res-MoCoDiff: 基于残差引导的扩散模型在脑MRI运动伪影矫正中的应用", "title_en": "Res-MoCoDiff: Residual-guided diffusion models for motion artifact correction in brain MRI", "authors": "Mojtaba Safari,Shansong Wang,Qiang Li,Zach Eidex,Richard L.J. Qiu,Chih-Wei Chang,Hui Mao,Xiaofeng Yang", "background": "脑MRI图像的质量受到头部刚性运动导致的运动伪影的严重影响，这阻碍了下游应用的效果。现有的方法，如重复采集或运动追踪，虽然可以缓解这些问题，但增加了工作流程中的负担。因此，需要一种新的高效模型来解决这一问题，该模型能够在不增加额外采集次数的情况下，快速可靠地去除运动伪影，提高图像质量，减少了时间和资源的消耗，特别适合于临床和研究需求", "innovation": "该研究提出了一种名为Res-MoCoDiff的新方法，这是一种专门设计用于处理MRI运动伪影的去噪扩散概率模型。该模型通过在前向扩散过程中引入一种新颖的残差误差平移机制，来整合来自运动损坏图像的信息。这种方法允许模型模拟噪声演化的概率分布，与损坏数据非常接近，从而使逆向扩散过程只需四步即可完成。此外，该模型采用了U-net结构，并用Swin Transformer块替代了注意力层，以增强其在不同分辨率下的鲁棒性。同时，训练过程还结合了l1+l2损失函数，这有助于提高图像锐度并减少像素级别的误差。此方法相较于其他现有技术，能更高效地去除轻度、中度和重度扰动的运动伪影，特别是在减少伪影方面表现出色，且平均采样时间显著降低，优于传统方法", "conclusion": "研究通过在计算机生成的数据集和实际临床数据集上进行实验，验证了Res-MoCoDiff方法的有效性。该方法在去除运动伪影方面表现出色，特别是在SSIM值和NMSE值上超越了其他现有方法，并显著降低了平均采样时间。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15269", "html_url": "https://arxiv.org/abs/2507.15269", "title": "基于条件生成的视频压缩", "title_en": "Conditional Video Generation for High-Efficiency Video Compression", "authors": "Fangqiu Yi,Jingyu Xu,Jiawei Shao,Chi Zhang,Xuelong Li", "background": "感知研究表明，条件扩散模型在重建符合人类视觉感知的视频内容方面表现出色。基于这一发现，本文提出了一种利用条件扩散模型进行感知优化重建的视频压缩框架。本文将视频压缩重新定义为条件生成任务，即将视频从稀疏但信息量大的信号中生成出来，并引入了多粒度条件模块、紧凑表示和多种条件训练策略来进一步优化压缩质量。", "innovation": "方法包括三个关键模块：1）多粒度条件模块，捕捉静态场景结构和动态空间时间提示；2）高效传输设计，保留了语义丰富性；3）模态随机删除和角色感知嵌入的多条件训练策略，避免依赖单一模态，并增强鲁棒性。实验结果表明，与传统和神经编解码器相比，我们的方法在弗雷歇视频距离（FVD）和LPIPS等感知质量指标上具有显著优势，特别是在高压缩比情况下。", "conclusion": "我们的方法在高效率视频压缩方面远超传统和神经编解码器，特别是在感知质量方面表现出优越性。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06949", "html_url": "https://arxiv.org/abs/2507.06949", "title": "前哥伦布时期聚落生态遗留痕迹在热带山地森林棕榈林簇中的证据", "title_en": "Ecological Legacies of Pre-Columbian Settlements Evident in Palm Clusters of Neotropical Mountain Forests", "authors": "Sebastian Fajardo,Sina Mohammadi,Jonas Gregorio de Souza,César Ardila,Alan Tapscott Baltar,Shaddai Heidgen,Maria Isabel Mayorga Hernández,Sylvia Mota de Oliveira,Fernando Montejo,Marco Moderato,Vinicius Peripato,Katy Puche,Carlos Reina,Juan Carlos Vargas,Frank W. Takes,Marco Madella", "background": "前哥伦布时期的土著人口显著改变了新热带森林结构，但他们的生态影响在高分辨率下仍不被充分探索。本文利用深度学习和遥感技术，基于现代植被估计前哥伦布时期的森林改造区域，并在哥伦比亚 Sierra Nevada de Santa Marta 展示了该方法的应用。研究发现棕榈树林的分布与考古遗迹有显著关系，面积远超当前考古证据所示，表明前哥伦布时期的人为管理区域可能扩大了两倍以上。这表明前哥伦布时期的人口影响了植被，创造了有利于棕榈树繁衍的条件，留下了持久的生态足迹，有助于在更偏远的地区建立基础设施密集型定居点的低物流成本。", "innovation": "本文创新性地提出了一种基于现代植被和遥感技术的深学习方法来估计前哥伦布时期的森林改造区域，揭示了古代人类活动对森林影响的广泛性。", "conclusion": "前哥伦布时期的人口通过管理植被环境促进了棕榈树的生长，留下了持久的生态足迹。这些研究表明，古代人口影响的范围远超过现有考古证据显示的，他们的活动不仅极大地影响了当时的生态环境，还可能为在偏远地区建立大型基础设施提供了条件。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12964", "html_url": "https://arxiv.org/abs/2507.12964", "title": "基于人口统计信息的儿童腕骨骨折精细分类", "title_en": "Demographic-aware fine-grained classification of pediatric wrist fractures", "authors": "Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota", "background": "腕部病理常见，尤其是在骨折病例中占据主要部分的儿童群体中尤为显著。计算机视觉是一个潜在的解决方案，但其适用性受限于可用大量数据集的稀缺，这是医学成像领域的一个重大挑战。仅依赖单一成像模态，如影像学图像，在多元丰富数据类型的当下显得不够。因此，本研究提出了一种综合方法：将其定义为精细分类任务、结合患者元数据与X光片，并利用来自另一精细分类数据集的权重而非像ImageNet这样的粗粒度数据集的权重。研究指出，将精细粒度变压器方法、精细粒度预训练与元数据集成联合应用能够显著提高诊断准确性，特别是在较小的自建数据集和较大的骨折数据集上分别提高了2%和超过10%的准确性。", "innovation": "这是首次将元数据集成应用于腕部病理识别。研究综合使用了精细粒度的变压器方法、精细粒度预训练及元数据集成，以改进诊断准确性，与之前的单独使用影像学图像或者粗粒度数据集相比，展示了更好的效果。", "conclusion": "结合精细粒度变压器方法、精细粒度预训练和元数据集成能显著提高腕部骨折的诊断准确性，特别是在小型自建数据集和大型骨折数据集上的诊断准确性分别提升了2%和超过10%。同时，这也是首次将元数据集成应用于儿童腕骨骨折的精细分类中。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05195", "html_url": "https://arxiv.org/abs/2506.05195", "title": "基于ArUco导向到达角估算的视觉辅助自主毫米波反射器", "title_en": "Vision-Based Autonomous MM-Wave Reflector Using ArUco-Driven Angle-of-Arrival Estimation", "authors": "Josue Marroquin,Nan Inzali,Miles Dillon Lantz,Campbell Freeman,Amod Ashtekar,\\\\Ajinkya Umesh Mulik,Mohammed E Eltayeb", "background": "在非视线（NLoS）条件下实现可靠的毫米波（mmWave）通信，特别是在城市或基础设施有限的环境中，仍然是军事和民用操作的重大挑战。现有的mmWave通信在这些环境下性能不稳定。因此，本研究旨在提出一种基于视觉辅助的自主反射系统，通过动态调整信号反射，增强毫米波链路性能。该系统利用单目相机检测盟军传输器和接收器节点上的ArUco标记，估计其到达角，并实时对准反射器以实现最佳的信号导向。这种方法可以仅对具有可见标记的有效目标提供定向覆盖，并降低无意信号暴露的风险。系统在没有外部基础设施依赖的情况下自主运行，展示了其在复杂和动态环境中的稳健性和适应性。", "innovation": "该系统提出了一种基于单目相机对准ArUco标记进行角度估算的方法，并使用可移动金属板动态调整反射信号，实现了自主反射和方向控制。该系统通过即时调整反射器角度以优化信号导向，能够实现选择性的覆盖范围，并仅认证具有可见标记的设备。此外，该系统基于Raspberry Pi 4和低功耗硬件，无需依赖外部基础设施或GPS，能够自主运行。这一方法在60GHz环境下进行了实验，结果显示了显著的效果，包括平均23dB的接收信号强度增益以及在室内环境中保持信号接收概率达0.89，远超固定和无反射器的基准值。", "conclusion": "实验结果显示该系统在复杂和动态环境下具有增强毫米波连接性能的潜力，并且比静态或无反射器方案有显著改善。该研究证明了基于视觉辅助的自主反射器在NLoS条件下的可行性，并展示了其改进mmWave通信的关键创新点。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15387", "html_url": "https://arxiv.org/abs/2508.15387", "title": "DIO: Refining Mutual Information and Causal Chain to Enhance Machine Abstract Reasoning Ability", "title_en": "DIO: Refining Mutual Information and Causal Chain to Enhance Machine Abstract Reasoning Ability", "authors": "Ruizhuo Song,Beiming Yuan", "background": "当前深度学习模型在各个领域表现出色，但在抽象推理方面仍存在根本性的瓶颈。因此，学术界引入Raven's Progressive Matrices (RPM)问题作为评估深度学习算法抽象推理能力的权威标准，重点关注逻辑推理、模式识别和复杂问题解决等核心智能维度。鉴于此，本文针对RPM问题开展研究，旨在提升机器抽象推理能力，首次从因果链建模的角度系统分析RPM任务中的因果链：图像 → 抽象属性 → 进步属性模式 → 模式一致性 → 正确答案。然而，实验证明，为了DIO设计的优化目标（最大化上下文和正确选项间的信息互惠的变分下界）未能使模型真正掌握预先定义的人类推理逻辑。", "innovation": "本文提出了针对DIO模型的三层改进方法：1) 通过优化信息互惠的变分下界优化模型；2) 解决变分下界不够紧的问题；3) 引入因果关系以弥补统计度量无法捕捉因果关系的不足，从而提升模型的抽象推理能力。", "conclusion": "本文通过系统地分析RPM任务中的因果链，并设计基础模型DIO及其改进方法，成功提升了机器在抽象推理方面的性能，为进一步提升深度学习在复杂任务上的表现奠定了基础。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.17832", "html_url": "https://arxiv.org/abs/2508.17832", "title": "HLG：通过层次布局生成的全面3D房间构建", "title_en": "HLG: Comprehensive 3D Room Construction via Hierarchical Layout Generation", "authors": "Xiping Wang,Yuxi Wang,Mengqi Zhou,Junsong Fan,Zhaoxiang Zhang", "background": "3D室内场景的现实生成对于虚拟现实、室内设计、代身智能和场景理解至关重要。现有的方法在粗略的家具布局方面取得了进展，但难以捕捉细粒度的对象摆放，这限制了生成环境的真实性和实用性。这一差距阻碍了沉浸式虚拟体验和代身智能应用中对详细场景的理解。", "innovation": "提出了一种新颖的方法——层次布局生成（HLG），这是一种首次采用从粗到细的层次化方法，从大规模家具放置逐步精细到复杂的对象排列。具体来说，该方法通过垂直和水平解耦构建层次布局，有效将复杂的3D室内场景分解为多个层次的细节级别。此外，可以训练的布局优化网络解决了放置问题，如错误定位、方向错误和对象交集等，确保生成的场景在结构上是连贯的，在物理上是可验证的。", "conclusion": "通过广泛的实验展示了该方法在生成现实室内场景方面的优越性能，相比现有的方法。这项工作推动了场景生成领域的研究，并为需要详细3D环境的应用打开了新的可能性。在发表后，我们将发布我们的代码以鼓励未来的研究。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19762", "html_url": "https://arxiv.org/abs/2508.19762", "title": "BuzzSet v1.0：野外条件下传粉昆虫检测的数据集", "title_en": "BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions", "authors": "Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher", "background": "传粉昆虫如蜜蜂对全球粮食生产和生态系统稳定性至关重要，但其种群因人为和环境压力而下降。在农业环境中实现可扩展的、自动化的监测仍然是一个挑战，特别是难以捕捉快速移动且常常伪装的小型昆虫。", "innovation": "提出BuzzSet v1.0，这是一个在真实农田条件下采集的高分辨率传粉昆虫图像集，包含超过8,000个标注实例，并通过开源工具进行了人工验证。该数据集利用YOLOv12模型进行初始标注，并通过RF-DETR变压器基础对象检测器实现强大的分类准确度。模型还提供了一个基准，用于评估在实际生态条件下的小物体检测策略。", "conclusion": "通过BuzzSet v1.0在0.50 mAP达到了0.559的表现，说明了挑战性和潜在的研究价值。未来的工作将扩展数据集至2.0版本，并评估进一步的检测策略。该数据集展示了在自然植被中可靠检测通常伪装的昆虫这一开放问题，为生态计算机视觉设定了基准。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22627", "html_url": "https://arxiv.org/abs/2507.22627", "title": "时尚之LOT：通过草图文本对进行多条件图像生成", "title_en": "LOTS of Fashion! Multi-Conditioning for Image Generation via Sketch-Text Pairing", "authors": "Federico Girella,Davide Talon,Ziyue Liu,Zanxi Ruan,Yiming Wang,Marco Cristani", "background": "时尚设计是一个复杂的创意过程，结合了视觉和文字表达。设计师通过草图传达想法，草图定义空间结构和设计元素，而文字描述捕捉材料、纹理和风格细节。当前的方法难以同时准确生成全局和局部特征的时尚图像。为了解决这个问题，作者提出了一种新的方法，名为LOcalized Text and Sketch for fashion image generation (LOTS)。", "innovation": "LOTs 方法利用全局描述并配以局部草图和文字信息来生成完整的时尚外观。它引入了一种新的基于多步扩散调整的分步合并策略。具体而言，该方法首先通过模块化配对中心表示将草图和文字编码到共享的潜在空间中，同时保持局部特征的独立性；然后，通过注意力引导在扩散模型的多步降噪过程中整合局部和全局条件。这种方法首次在时尚数据集中提供多对一的文本-草图配对，实现了在全局和局部指标上达到目前最先进的图像生成性能。", "conclusion": "实验结果表明，LOTs 方法在生成高质量的时尚图像方面取得了显著成果，并在人类评估研究中展示了出色的设计定制能力。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.05702", "html_url": "https://arxiv.org/abs/2403.05702", "title": "基于3D OCT成像的空间感知Transformer-GRU框架以增强的青光眼诊断", "title_en": "Spatial-aware Transformer-GRU Framework for Enhanced Glaucoma Diagnosis from 3D OCT Imaging", "authors": "Mona Ashtari-Majlan,David Masip", "background": "青光眼是导致不可逆失明的主要原因之一，早期检测对防止不可逆视力丧失至关重要。因此，本研究提出了一种新的深度学习框架，该框架利用3D光学相干断层扫描（OCT）成像的诊断价值，以实现自动青光眼检测。该框架利用预训练的视网膜数据上的Vision Transformer进行丰富的一片片特征提取，并使用双向门控循环单元（GRU）捕捉跨片空间依赖性，进而实现局部细节点和全局结构完整性等关键要素的综合分析。", "innovation": "本框架结合了预训练的Vision Transformer和双向GRU，前者用于丰富的片层特征提取，后者用于捕捉跨片的空间依赖性。此双组件方法实现对局部细节和全局结构完整性的综合分析，这种方法在很大程度上提升了青光眼诊断的准确性。", "conclusion": "通过对大量数据集的实验，所提出的该方法在多个性能指标上都优于现有技术，包括93.01%的F1分数，69.33%的Matthews相关系数（MCC）和94.20%的AUC。该框架能够有效地利用3D OCT数据中的有价值信息，这在加强临床决策支持系统和改善青光眼管理患者的成果方面具有巨大潜力。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.13238", "html_url": "https://arxiv.org/abs/2508.13238", "title": "DianJin-OCR-R1：通过推理和工具交错的视觉语言模型增强OCR能力", "title_en": "DianJin-OCR-R1: Enhancing OCR Capabilities via a Reasoning-and-Tool Interleaved Vision-Language Model", "authors": "Qian Chen,Xianyin Zhang,Lifan Guo,Feng Chen,Chi Zhang", "background": "近年来，大规模视觉-语言模型（LVLMs）的发展推动了文档图像解析的端到端新范式，特别擅长光学字符识别（OCR）任务，如文本、表格和公式识别。然而，生成型LVLMs容易产生与输入图像中不存在的词语，即幻觉。另外，LVLMs的设计是为了通用目的，与专门针对特定领域数据集训练的专家模型相比，在OCR任务上效率较低。", "innovation": "本文提出了一种增强推理的框架DianJin-OCR-R1，旨在通过训练交替使用推理和工具的LVLM，提升OCR能力。具体来说，DianJin-OCR-R1首先使用自身的OCR能力识别输入图像的内容，然后利用其他专家模型作为参考以纠正幻觉并重新思考推理过程，从而获得最终的识别结果。这种方法利用专家模型的特定任务架构，更少产生幻觉，以减少LVLMs的幻觉倾向。实验结果显示，与不包含推理机制的模型及专家OCR模型相比，DianJin-OCR-R1表现出更优的性能，这证明了该方法的有效性。此外，研究表明，增强通常较小且易于迭代的专家模型能够提升LVLMs的表现。", "conclusion": "实验结果表明，DianJin-OCR-R1模型在ReST和OmniDocBench上的表现优于非推理模型以及专家OCR模型，证明了其方法的有效性。进一步的实验还表明，通过增强专家模型可以提升LVLMs的表现。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.00451", "html_url": "https://arxiv.org/abs/2509.00451", "title": "Encoder-Only Image Registration", "title_en": "Encoder-Only Image Registration", "authors": "Xiang Chen,Renjiu Hu,Jinwei Zhang,Yuxi Zhang,Xinyao Yue,Min Liu,Yaonan Wang,Hang Zhang", "background": "学习基技术在变形图像配准的准确性和速度方面取得了显著提升，但仍有挑战需要克服，如降低计算复杂度和处理大形变。", "innovation": "本文分析了卷积神经网络在变形图像配准中的作用，并提出了一种新的Encoder-Only Image Registration（EOIR）框架，该框架通过分离特征学习和流动估计，并使用只有3层的卷积网络来实现更好的准确性和效率权衡。", "conclusion": "实验结果显示，EOIR在不同模态和解剖区域的数据集上表现出优于现有方法的准确性和效率权衡。在相同准确性的条件下，EOIR可以提供更好的效率和光滑度，反之亦然。开源代码已在指定链接上提供。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.13923", "html_url": "https://arxiv.org/abs/2406.13923", "title": "PIN: 一种用于配对和交错多模态文档的知识密集型数据集", "title_en": "PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents", "authors": "Junjie Wang,Yuxiang Zhang,Minghao Liu,Yin Zhang,Yatai Ji,Weihao Xuan,Nie Lin,Kang Zhu,Zhiqiang Lin,Yiming Ren,Chunyang Jiang,Yiyao Yu,Zekun Wang,Tiezhen Wang,Wenhao Huang,Jie Fu,Qunshu Liu,Yujiu Yang,Ge Zhang,Ruibin Yuan,Bei Chen,Wenhu Chen", "background": "近年来，大型多模态模型（LMMs）通过利用大量多模态数据集，在复杂的知识驱动任务中增强了能力。不过，这些模型在感知和推理方面仍然存在持续性的挑战，尤其是在理解和解释复杂的视觉数据以及推断多模态关系时效果有限。", "innovation": "为了解决上述问题，本文提出了一种名为PIN（Paired and INterleaved multimodal documents）的新数据格式，旨在促进视觉和文本知识的更深层次集成。PIN格式结合了具有丰富语义结构的Markdown文件和捕捉文档整体布局的总体图像。此外，作者构建并公开了两个大型多模态数据集：PIN-200M（约2亿份文档）和PIN-14M（约1400万文档），数据源自英文和中文的多种网络和学术资源。", "conclusion": "本文提供了灵活的数据格式和大量的资源，为预训练策略的研究和开发更强大的知识密集型LMMs奠定了基础，并提供了详尽的统计数据和质量信号，便于研究人员筛选适合特定任务的数据。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23357", "html_url": "https://arxiv.org/abs/2507.23357", "title": "现代计算机视觉中的基础与模型：标志性架构的关键构建块", "title_en": "Foundations and Models in Modern Computer Vision: Key Building Blocks in Landmark Architectures", "authors": "Radu-Andrei Bourceanu,Neil De La Fuente,Jan Grimm,Andrei Jardan,Andriy Manucharyan,Cornelius Weiss,Daniel Cremers,Roman Pflugfelder", "background": "本报告通过分析六篇有影响力的论文，探讨了计算机视觉中关键设计模式的演变。分析从图像识别的基础架构开始，审视了ResNet引入残差连接解决梯度消失问题并实现更深层次卷积网络的有效训练的过程。随后，研究了Vision Transformer (ViT)，它通过应用Transformer架构到图像块序列，确立了一种新的范式，并展示了基于注意力模型在大规模图像识别中的有效性。在此基础上，研究生成模型，包括分析生成对抗网络（GANs）的创新对抗训练过程以及随后的潜扩散模型（LDMs），它们在感知压缩的潜在空间中进行逐次去噪处理，从而实现更高保真的合成，具有更高的计算效率，代表了目前图像生成的最高水平。最后，探讨了减少对标注数据依赖的自我监督学习技术，如DINO和掩蔽自编码器（MAE），它们分别利用蒸馏框架和不对称编码-解码设计来实现大规模视觉模型的有效预训练。", "innovation": "论文发现了计算机视觉设计模式的演变，强调了ResNet通过引入残差连接解决了梯度消失问题，Vision Transformer通过Transformer架构展示了基于注意力模型在大规模图像识别中的有效性，生成对抗网络和潜扩散模型通过其新颖的训练过程和在去噪处理中的优势改进了图像生成，以及自我监督学习方法如DINO和掩蔽自编码器，这些方法减少了对标注数据的依赖，并提供了有效的大规模视觉模型预训练方法，实现了高效的图像生成和良好特征的表现。", "conclusion": "本研究总结了计算机视觉中一系列关键的设计模式，从图像识别的基础架构到更先进的生成模型和自我监督学习技术，展示了这些模型在当前研究中的最新进展。通过这些研究，可以理解设计图像识别和生成模型的基本原理以及最新的创新点和发展趋势。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.02175", "html_url": "https://arxiv.org/abs/2509.02175", "title": "理解空间是火箭科学 -- 只有顶级推理模型能解决空间理解任务", "title_en": "Understanding Space Is Rocket Science -- Only Top Reasoning Models Can Solve Spatial Understanding Tasks", "authors": "Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque", "background": "当前开源和前沿商用视觉语言模型（VLMs）在空间关系理解方面表现不佳，而具有链式思维能力的推理模型则表现出较高的性能。RocketScience是一个开源的对比性VLM基准测试，旨在评估模型的空间关系理解能力。基准测试中包含全新的真实世界图像-文本对，主要测试相对空间理解和物体顺序，这对人类来说容易而对当前的视觉语言模型来说很难。这一设计通过实验证明有效。", "innovation": "提出了RocketScience，这是一个全新的开源对比性视觉语言模型基准测试，专门测试空间关系理解能力。它不仅帮助识别开源和前沿商用VLMs在空间理解上的不足，还通过拆分贡献分析指出这些模型在链式思维模型中的表现瓶颈在于空间推理能力而非物体定位能力。此外，还公开了该数据集，并提供评估代码。", "conclusion": "RocketScience能明确地指出VLMs在空间理解上的问题，同时揭示了推理模型在空间推理方面具有显著潜力。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10868", "html_url": "https://arxiv.org/abs/2508.10868", "title": "TexVerse: 高分辨率纹理的3D对象宇宙", "title_en": "TexVerse: A Universe of 3D Objects with High-Resolution Textures", "authors": "Yibo Zhang,Li Zhang,Rui Ma,Nan Cao", "background": "虽然最近在大规模3D数据集领域已经取得了进展，提高了高分辨率几何体生成的效果，但端到端生成高分辨率纹理仍然缺乏合适的大型数据集。因此，缺乏能够支持高分辨率纹理生成的数据资源，这导致该领域的发展受到限制。TexVerse填补了这一空白，提供了超过858,000个独特高分辨率3D模型的复合数据集，涵盖超过158,000个应用了基于物理的渲染（PBR）材料的模型。这些模型包括所有高分辨率变体，总计160万个3D实例，特别地还包括了不同类型的子集（例如，骨骼附着和动画模型），以及详细的模型注解，描述其特性和细节。", "innovation": "TexVerse通过创建大量具有高分辨率纹理的3D模型，填补了当前3D数据集缺乏高分辨率纹理生成数据集的空白。它包括超过858,000个独特高分辨率3D模型，其中许多模型还包含基于物理的渲染（PBR）材料。此外，TexVerse还包含了特殊子集，如提供69,000个绑定模型和54,000个动画模型，同时保留了用户上传的原始骨骼和动画数据。详细的注解进一步增加了这一数据集的价值。", "conclusion": "TexVerse为纹理合成、基于物理的渲染材料开发、动画以及其他3D视觉和图形任务提供了高质量的数据资源。该数据集的广泛应用范围和卓越质量使其成为一个重要的研究工具，具有广泛的潜在应用价值。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.06289", "html_url": "https://arxiv.org/abs/2502.06289", "title": "基于超大规模自然图像的基础模型在检测眼病和全身性疾病方面是否优于视网膜特异性模型？", "title_en": "Is an Ultra Large Natural Image-Based Foundation Model Superior to a Retina-Specific Model for Detecting Ocular and Systemic Diseases?", "authors": "Qingshan Hou,Yukun Zhou,Jocelyn Hui Lin Goh,Ke Zou,Samantha Min Er Yew,Sahana Srinivasan,Meng Wang,Thaddaeus Lo,Xiaofeng Lei,Siegfried K. Wagner,Mark A. Chia,Dawei Yang,Hongyang Jiang,An Ran Ran,Rui Santos,Gabor Mark Somfai,Juan Helen Zhou,Haoyu Chen,Qingyu Chen,Carol Y. Cheung,Pearse A. Keane,Yih Chung Tham", "background": "基础模型（FMs）正在改变医疗领域，在眼科领域，RETFound（一种针对视网膜的FM）通过逐步预训练在140万自然图像和160万眼底图像上，展示了在临床应用中的高适应性。而DINOv2（一种通用视觉FM）在非医疗领域展示出了潜能，但在临床任务中的应用尚待深入研究。", "innovation": "研究通过将RETFound和三种DINOv2（大型、基础、小型）模型分别针对八组标准开源眼底数据集以及Moorfields AlzEye和UK Biobank数据集进行微调，进行了直接对比。结果显示DINOv2在眼底疾病检测方面表现出优越性，而在全身性疾病预测方面，RETFound表现出更强的性能。", "conclusion": "研究表明，通用和领域特定的基础模型在不同的应用场合表现不同，因此在选择基础模型时需要与特定任务要求相匹配，以便优化临床性能。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18733", "html_url": "https://arxiv.org/abs/2508.18733", "title": "Drawing2CAD：从矢量绘图生成CAD模型的序列到序列学习", "title_en": "Drawing2CAD: Sequence-to-Sequence Learning for CAD Generation from Vector Drawings", "authors": "Feiwei Qin,Shichao Lu,Junhao Hou,Changmiao Wang,Meie Fang,Ligang Liu", "background": "计算机辅助设计（CAD）生成模型正在推动工业应用中的重大创新。尽管最近的研究在从点云、网格和文本描述生成实体模型方面取得了显著进展，但这些方法在本质上与传统工业工作流程从二维工程图纸开始的方式不同。自动从二维矢量绘图生成参数化CAD模型这一关键步骤依然未得到充分探索。本文旨在填补这一空白，通过将CAD生成重新定义为序列到序列学习问题，并通过参数化CAD操作直接反映矢量绘图原语的信息，从而保留整个转换过程中的几何精度和设计意图。为了实现这一目标，作者提出了Drawing2CAD框架，并通过一个自定义的矢量原语表示，一种解码器分离的双解码器变压器结构，以及一个软目标分布损失函数来解决问题。为了验证Drawing2CAD的有效性，作者创建了CAD-VGDrawing数据集，并进行了详尽的实验。", "innovation": "提出了Drawing2CAD框架，这是一个将矢量绘图转换为参数化CAD模型的序列到序列学习方法。该框架包含三个关键技术组件：网络友好的矢量原语表示，可以保留精确的几何信息；一种解码器分离的双解码器变压器结构，可以分离命令类型和参数的生成，同时保持精确对应；软目标分布损失函数，用于适应CAD参数的固有灵活性。", "conclusion": "通过Drawing2CAD框架，实验结果显示该方法在从二维矢量图纸生成参数化CAD模型方面表现出色，这表明该方法的有效性，并且已经为验证该方法创建了CAD-VGDrawing数据集，同时提供了代码和数据集用于进一步的研究。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.01563", "html_url": "https://arxiv.org/abs/2509.01563", "title": "Kwai Keye-VL 1.5 技术报告", "title_en": "Kwai Keye-VL 1.5 Technical Report", "authors": "Biao Yang,Bin Wen,Boyang Ding,Changyi Liu,Chenglong Chu,Chengru Song,Chongling Rao,Chuan Yi,Da Li,Dunju Zang,Fan Yang,Guorui Zhou,Guowang Zhang,Han Shen,Hao Peng,Haojie Ding,Hao Wang,Haonan Fang,Hengrui Ju,Jiaming Huang,Jiangxia Cao,Jiankang Chen,Jingyun Hua,Kaibing Chen,Kaiyu Jiang,Kaiyu Tang,Kun Gai,Muhao Wei,Qiang Wang,Ruitao Wang,Sen Na,Shengnan Zhang,Siyang Mao,Sui Huang,Tianke Zhang,Tingting Gao,Wei Chen,Wei Yuan,Xiangyu Wu,Xiao Hu,Xingyu Lu,Yi-Fan Zhang,Yiping Yang,Yulong Chen,Zeyi Lu,Zhenhua Wu,Zhixin Ling,Zhuoran Yang,Ziming Li,Di Xu,Haixuan Gao,Hang Li,Jing Wang,Lejian Ren,Qigen Hu,Qianqian Wang,Shiyao Wang,Xinchen Luo,Yan Li,Yuhang Hu,Zixing Zhang", "background": "近年来，大型语言模型（LLMs）的发展取得了显著的进步，并通过多模态大型语言模型（MLLMs）将能力扩展到多模态任务领域。然而，视频理解由于视频的动态性和信息密集性特征仍然是一个具有挑战性的领域。现有的模型在处理视频内容时面临着空间分辨率和时间覆盖之间难以调和的矛盾。", "innovation": "Keye-VL-1.5 通过三个关键创新解决了视频理解中的基本挑战。首先，引入了一种新颖的 Slow-Fast 视频编码策略，根据帧间相似性动态分配计算资源，处理具有显著视觉变化的关键帧时使用更高分辨率（Slower路径），处理相对静态的帧时利用更高时间覆盖但更低分辨率（Faster路径）的策略。其次，实现了分阶段的四阶段预训练方法，逐步将模型的上下文长度从8K扩展到128K个标记，从而处理更长的视频和更复杂的视觉内容。最后，开发了一个全面的后训练管道，专注于增强推理和与人类偏好的对齐，其中包括五步链式思维的数据构建过程、迭代的基于GSPO的强化学习与递进提示补全困难案例的提示以及定向训练。", "conclusion": "在广泛公开基准上的评估和严格的内部人类评估中，Keye-VL-1.5 在视频理解任务中表现出了显著的提升，同时在通用的多模态基准测试中维持了竞争力。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.02807", "html_url": "https://arxiv.org/abs/2410.02807", "title": "AutoPETIII：通向未知前沿的道路，是什么前沿？", "title_en": "AutoPETIII: The Tracer Frontier. What Frontier?", "authors": "Zacharia Mesbah,Léo Mottay,Romain Modzelewski,Pierre Decazes,Sébastien Hapdey,Su Ruan,Sébastien Thureau", "background": "AutoPET竞赛在过去三年每年聚焦于PET图像中的病灶分割任务，每年探讨该问题的不同方面。2024年的比赛重点在于解决不同示踪剂（包括FDG和PSMA）带来的挑战，研究者们需要开发能够在未知示踪剂情况下自动进行病灶分割的算法。", "innovation": "研究团队采用了nnUNetv2框架训练了两组六折模型集合，并利用MIP-CNN来选择最适合的模型集合进行病灶分割。这一方法创新之处在于无需预先知道示踪剂类型即可实现全自动病灶分割。", "conclusion": "通过这一方法，研究团队成功提高了在未知示踪剂情况下进行自动PET/CT病灶分割的性能。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.20321", "html_url": "https://arxiv.org/abs/2405.20321", "title": "单人视频开放世界对象图中的基于视觉的操纵", "title_en": "Vision-based Manipulation from Single Human Video with Open-World Object Graphs", "authors": "Yifeng Zhu,Arisrei Lim,Peter Stone,Yuke Zhu", "background": "该研究工作旨在通过人类视频学习基于视觉的操纵技能，特别是在开放世界设置中，其中机器人需要从单个视频演示中学习操作全新对象的方法。背景在于现有的许多研究主要集中在特定环境或预定义对象上的学习，忽视了真实世界中的多样性。该研究的目的是解决在视觉背景、相机角度、空间布局和新型物体实例变化的环境中训练机器人的问题。", "innovation": "该研究引入了一种名为ORION的算法，该算法能够从单一的RGB或RGB-D视频中提取以对象为中心的操纵计划，并基于此提取的计划生成政策。ORION算法的独特之处在于它可以利用日常移动设备拍摄的视频进行学习，并能够将所学习的策略应用于具有不同视觉背景、相机角度、空间布局和新型物体实例的实际部署环境。", "conclusion": "该研究在不同任务和演示类型上系统地评估了ORION算法，使用RGB-D和RGB只用演示视频，在短时间和长时任务中都达到了平均74.4%的成功率，展示了ORION在开放世界中从单个人类视频学习的有效性。此外，相关资料可以在项目网站上找到。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18826", "html_url": "https://arxiv.org/abs/2508.18826", "title": "SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation", "title_en": "SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation", "authors": "Junyu Yan,Feng Chen,Yuyang Xue,Yuning Du,Konstantinos Vilouras,Sotirios A. Tsaftaris,Steven McDonagh", "background": "近期研究表明，在现实场景中机器学习模型可能会出现偏见问题，特别是在像医疗这样的敏感领域，这会对模型的公平性、泛化能力和进一步放大社会歧视带来负面影响。现有去偏方法通常需要访问原始训练数据并需要大量的模型重新训练，它们通常会牺牲模型的公平性来维持识别性能。", "innovation": "本文提出了Soft-Mask Weight Fine-Tuning (SWiFT)，这是一种去偏框架，能够在保留识别性能的情况下大幅提高公平性，而无需访问原始训练数据和大量的模型重新训练。具体来说，SWiFT只需要少量外部数据集和少量的模型微调。SWiFT的核心思想是首先确定模型参数在偏见和预测性能方面的相对但又独特的贡献，然后通过定义其贡献的方法更新每个参数的梯度流动。", "conclusion": "通过在四个皮肤病学和两个胸部X射线数据集上对三种敏感属性（性别、肤色、年龄）的广泛实验，本文证明SWiFT可以在保持或超越当前最佳方案公平性与准确性的情况下减少模型偏见。此外，SWiFT展示了更好的模型外分布泛化能力。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.09885", "html_url": "https://arxiv.org/abs/2504.09885", "title": "分离以合作：用于协调钢琴手部运动合成的双流扩散模型", "title_en": "Separate to Collaborate: Dual-Stream Diffusion Model for Coordinated Piano Hand Motion Synthesis", "authors": "Zihao Liu,Mingwen Ou,Zunnan Xu,Jiaqi Huang,Haonan Han,Ronghui Li,Xiu Li", "background": "自动合成同步的双人手钢琴表演面临着重大挑战，特别是在捕捉双手间的复杂 choreography 同时保持各自独特的动力学特征方面。为此，论文提出了一个双流神经框架，旨在从音频输入中生成同步的手部姿态，以解决双手独立性和协调性建模的关键挑战。", "innovation": "该框架引入了两个关键创新点：(i) 一种解耦的基于扩散的过程生成框架，通过双重噪声初始化独立建模每一手的动作，使用共享的位置条件，对每个手应用不同的潜在噪声；(ii) 手协调不对称注意（HCAA）机制，抑制对称噪声突出手特定的非对称特征，在消噪过程中适配性增强双手的协调性.", "conclusion": "全面评估表明，该框架在多个指标上优于现有最先进的方法。我们的项目可以在以下链接获取：[this https URL](this https URL)."}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03643", "html_url": "https://arxiv.org/abs/2509.03643", "title": "CEHR-GPT：电子健康记录的可扩展多任务基础模型", "title_en": "CEHR-GPT: A Scalable Multi-Task Foundation Model for Electronic Health Records", "authors": "Chao Pang,Jiheum Park,Xinzhuo Jiang,Nishanth Parameshwar Pavinkurve,Krishna S. Kalluri,Shalmali Joshi,Noémie Elhadad,Karthik Natarajan", "background": "电子健康记录（EHRs）提供了患者健康状况的丰富、纵向视图，对临床决策支持、风险预测和数据驱动的医疗研究具有重大潜力。然而，大多数针对EHRs的人工智能（AI）模型都是为单一任务设计的，这限制了它们在真实世界环境中的普适性和实用性。", "innovation": "CEHR-GPT 是一个适用于EHR数据的通用基础模型，整合了特征表示、零样本预测和合成数据生成三大核心能力，通过引入一种新颖的时间标记学习框架，直接将患者动态时间线编码到模型结构中，支持对临床序列的时间推理。", "conclusion": "CEHR-GPT 在所有三个任务上表现出色，并通过词汇扩展和微调在外部数据集上实现了有效的泛化。它的多功能性使快速模型开发、队列发现和患者结果预测变得远程需要特别的任务重训练。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.07107", "html_url": "https://arxiv.org/abs/2502.07107", "title": "材料微观结构图像的监督和非监督分割与分类框架", "title_en": "A Framework for Supervised and Unsupervised Segmentation and Classification of Materials Microstructure Images", "authors": "Kungang Zhang,Wei Chen,Wing K. Liu,L. Catherine Brinson,Daniel W. Apley", "background": "材料微观结构通常通过图像分析来表征以理解加工-结构-性能联系。随着制造和成像技术的进步，超高清成像揭示了微观结构的复杂性，并且图像（即微观图）的数量迅速增加，这呼唤一种更加强大和自动化的框架来提取材料特性和知识。因此，提出了一个集成非监督和监督学习方法的框架。该框架通过自动分割多相微观图像，进行同质区域的识别和分类，以及多相微观结构的监督分割来逐步建立特定加工工艺或材料组的微观结构类数据库，以帮助分析和发现新材料。", "innovation": "该框架的特点是三个步骤：首先，通过最近开发的基于分数的方法对多相微观图像进行分割，以在非监督模式下识别不同结构的同质区域；其次，通过训练良好的监督分类网络对图像中的同质区域进行识别和分类；最后，通过训练分割网络进行多相微观结构的监督分割（比第一步的分割更强大），并使用从步骤 1-2 中的结果进行数据增强。在这个框架中，体系结构可以迭代地识别/分割新材料的同质或多相材料，同时扩展数据库以提高性能。这种框架已经在各种材料和纹理图像集上进行了演示。", "conclusion": "该框架能够逐步建立特定加工工艺或材料组的微观结构类数据库，通过自动分割和分类帮助分析和发现新材料，具有强大的应用于材料科学研究和工程应用的潜力。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.07681", "html_url": "https://arxiv.org/abs/2501.07681", "title": "Dataset Distillation作为推前最优量化", "title_en": "Dataset Distillation as Pushforward Optimal Quantization", "authors": "Hong Ye Tan,Emma Slade", "background": "数据集蒸馏旨在找到一个合成训练集，以便在合成数据上训练可以获得与在真实数据上训练相似的表现，但计算需求仅为后者的一小部分。现有方法可以大致分为两类：一类是具有一级优化问题的双层优化问题，其中包含神经网络训练准则作为下一级问题；另一类是去耦合方法，通过匹配数据分布的方式来避开双层优化，这种去耦合方法在大小方面具有速度和可扩展性的优势。现有的去耦合方法在数据集大小的同时展示了优异的性能和扩展性。研究表明，这些去耦合方法可以基于编码器-解码器结构重新表述为一个最优量化问题，旨在通过最小化期望投影距离找到一组有限的点来近似潜在的概率度量。作者进一步将现有的去耦合数据集蒸馏方法与经典的最优量化和Wasserstein平均问题关联起来，展示了蒸馏后的数据集在基于扩散的生成先验中的一致性。", "innovation": "本文提出了一种名为“最优量化数据集蒸馏”的方法。与之前的最先进的方法D\textsuperscript{4}M相比，该方法在ImageNet-1K数据集上表现更好，并且具有更佳的跨模型泛化能力。在使用更强的扩散变换器模型和蒸馏后的噪声初始化时，所提出的方法在ImageNet-1K及其子集上取得了最佳蒸馏性能，超过了现有的扩散引导方法。此外，该方法不仅在计算上是轻量级的，而且通过对分布的匹配而不是双层优化问题，增强了模型的效率和可扩展性。", "conclusion": "本文通过对现有的去耦合方法进行重新表述为最优量化问题，展示了其在数据集蒸馏中的有效性和在不同情况下的表现优势。所提出的最佳量化数据集蒸馏方法为数据集蒸馏提供了新的视角，并展示了其在高性能计算和数据集规模优化上的潜力。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.12348", "html_url": "https://arxiv.org/abs/2506.12348", "title": "实时松散服装的每件服装虚拟试穿以保持时间一致性", "title_en": "Real-Time Per-Garment Virtual Try-On with Temporal Consistency for Loose-Fitting Garments", "authors": "Zaiqiang Wu,I-Chao Shen,Takeo Igarashi", "background": "现有的基于服装的虚拟试穿方法能够收集服装特定的数据集并训练针对每件服装的网络，从而实现卓越的效果。然而，这些方法在应对宽松款式的服装时往往存在问题，主要由于以下两个限制：(1) 依赖于人体的语义图来对齐服装与身体，但当宽松款式遮挡了身体轮廓时，这种映射变得不可靠，导致结果退化；(2) 仅在每个时间帧的基础上训练服装合成网络，而没有利用时间信息，导致帧间显著的抖动伪影。", "innovation": "为了解决上述限制，本文提出了一种两阶段的鲁棒语义图估计方法。首先从原始输入图像中提取服装不变的表征，然后将此表征传递到辅助网络中以估计语义图，这增强了在生成服装特定数据集过程中语义图估计的鲁棒性。此外，引入了一种循环的服装合成框架，结合了时间依赖性以改善帧间一致性，同时保持实时性能。", "conclusion": "通过定性和定量的评估表明，本文的方法在图像质量和时间一致性方面优于现有方法。消融研究进一步证明了服装不变表征和循环合成框架的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03666", "html_url": "https://arxiv.org/abs/2509.03666", "title": "AutoGrid AI: 深度强化学习框架用于自主微电网管理", "title_en": "AutoGrid AI: Deep Reinforcement Learning Framework for Autonomous Microgrid Management", "authors": "Kenny Guo,Nicholas Eckhert,Krish Chhajer,Luthira Abeykoon,Lorne Schell", "background": "该论文背景涉及到微电网管理和可再生能源的利用。随着可再生能源技术的进步和环境保护意识的增强，微电网成为了实现低排放甚至零碳能源系统的重要手段。传统的微电网管理方法通常依赖于固定的规则，这些规则可能无法适应不断变化的能源供需情况。因此，研究者们开始探索使用深度强化学习和时间序列预测模型来优化微电网的能量分配策略，以降低运营成本并提高可再生能源的使用率。", "innovation": "本文的主要创新点在于提出了一种基于深度强化学习的微电网自主管理框架。该框架利用变压器架构进行可再生能源发电量的预测，并结合前景策略优化（PPO）代理在模拟环境中做出决策。相较于传统的基于规则的方法，这种新方法在能源效率和运营弹性方面展现了显著的改进。", "conclusion": "研究结果表明，该框架在能源效率和运营弹性的提升方面具有明显优势，同时促进智能电网技术的发展，朝着零碳能源系统的目标迈进。最后，研究者还提供了一个开源框架用于模拟多种微电网环境，以促进进一步的研究和应用。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.02591", "html_url": "https://arxiv.org/abs/2509.02591", "title": "2025年MIDOG Track 2中病理基础模型的集成用于异常有丝分裂分类", "title_en": "Ensemble of Pathology Foundation Models for MIDOG 2025 Track 2: Atypical Mitosis Classification", "authors": "Mieko Ochi,Bae Yuan", "background": "有丝分裂图型被分为典型的和异常的变体，异常计数与肿瘤侵袭性密切相关。准确的区分对于患者的预后和资源分配至关重要，但对于即使是专家病理学家来说也依然具有挑战性。", "innovation": "本文利用预训练于大规模病理学图像数据集中的病理基础模型（PFMs）并通过低秩适应进行参数高效的微调。此外，引入了最先进的卷积神经网络架构ConvNeXt V2来补充PFMs的功能。在训练过程中，使用鱼眼变换以强调有丝分裂，并使用ImageNet目标图像进行频率域适应。最后，集成多个PFMs以整合互补的形态学洞察，实现对Preliminary Evaluation Phase数据集的竞争力均衡准确率", "conclusion": "通过这种方式，本文在2025年MIDOG Track 2的异常有丝分裂分类任务中实现了有竞争力的均衡准确率。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03594", "html_url": "https://arxiv.org/abs/2509.03594", "title": "显而易见的优化器：基于损失景像诱导度量的训练", "title_en": "The Optimiser Hidden in Plain Sight: Training with the Loss Landscape's Induced Metric", "authors": "Thomas R. Harvey", "background": "本文介绍了一类新型的优化器，这些优化器在训练神经网络时利用了在高维空间中嵌入损失景观时自然产生的黎曼度量。这种度量与常见的损失景观可视化方法所基于的度量相同。通过从几何角度严格采用这种度量，发展了一种新的优化器，并将其与现有的优化方法（如SGD、Adam、AdamW和Muon）进行比较，分析了其在不同任务和架构上的表现。", "innovation": "文中提出了一种新的优化器，基于损失景观诱导的黎曼度量进行训练，利用这种几何视角，优化器能够自动调整学习率，特别是高曲率区域的学习率会自动降低，相当于光滑的梯度修剪形式。此外，该优化器还具有有效的学习率调度功能，并自然地采用分离的权重衰减。基本方法可以用于任何现有预处理方法的修改，且新优化器的计算复杂度与Adam相近。", "conclusion": "实验结果显示，这类新的优化器在低维情况下非常有效，并且在训练神经网络方面略有优于当前最先进的方法。这种新优化器具有理论上的优势，即其有效学习率在高曲率区域自动降低，起到类似梯度修剪的作用；同样的一种变体优化器可以从几何视角看作具有有效学习率调度的功能，分离的权重衰减是本文背景下的自然选择。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.11249", "html_url": "https://arxiv.org/abs/2504.11249", "title": "冷冻电镜图像本质上是低维度的", "title_en": "Cryo-em images are intrinsically low dimensional", "authors": "Luke Evans,Octavian-Vlad Murad,Lars Dingeldein,Pilar Cossio,Roberto Covino,Marina Meila", "background": "模拟推理提供了一种强大的框架，用于冷冻电子显微镜(cryo-EM)，通过神经网络在方法如CryoSBI中推断生物分子构象。这种方法使用了学习的潜在表示，这些潜在空间富含信息，并且它的几何结构提供了有价值的信息。然而，有效利用这一潜力需要理解潜在表示的底层几何结构。本文通过应用流形学习技术来研究CryoSBI表示的血凝素（模拟和实验）的数据结构，揭示出高维数据本质上填充了低维且平滑的流形，并且模拟数据能够覆盖实验数据的对应部分。通过使用扩散映射来表征流形的几何结构，并利用坐标解释方法识别其主要变化轴，本文建立了潜在结构与关键物理参数之间的直接联系。", "innovation": "本文通过应用流形学习技术来研究CryoSBI表示的血凝素（模拟和实验）的数据结构，揭示出高维数据本质上填充了低维且平滑的流形，指出模拟数据可以很好地覆盖实验数据的对应部分。进一步通过扩散映射来表征流形的几何结构，并识别其主要变化轴，从而建立了潜在结构与关键物理参数之间的直接联系，这是对现有方法的创新贡献。", "conclusion": "发现这种固有的低维度和可解释的几何组织不仅验证了CryoSBI方法的有效性，还使我们能够从数据结构中获得更多信息，并提供利用这些揭示的流形几何改善未来推理策略的机会。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03677", "html_url": "https://arxiv.org/abs/2509.03677", "title": "梯度动力学见解：梯度自动调整归一化", "title_en": "Insights from Gradient Dynamics: Gradient Autoscaled Normalization", "authors": "Vincent-Daniel Yun", "background": "梯度动力学在确定深度神经网络的稳定性和泛化能力中扮演着核心角色。已有研究表明，在不同层和全局尺度上，梯度的方差和标准差在训练过程中存在一致的变化。这项工作通过实证分析了梯度方差和标准差的变化，揭示了其在卷积网络中的演化模式.", "innovation": "提出了一个无需超参数的梯度归一化方法，该方法使梯度缩放与其自然演化保持一致。这种方法可以防止无意中的放大，稳定优化过程，并保留收敛保证。", "conclusion": "在具有挑战性的CIFAR-100基准测试上对ResNet-20、ResNet-56和VGG-16-BN进行的实验表明，该方法能够保持或提高测试精度，即使在强泛化能力的情况下。此外，这项研究强调直接跟踪梯度动力学的重要性，旨在弥合理论预期和实际行为之间的差距，并为未来优化研究提供见解。"}
{"llm_update_time": "20250906", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22832", "html_url": "https://arxiv.org/abs/2507.22832", "title": "揭开ReLU网络背后的面纱", "title_en": "Pulling Back the Curtain on ReLU Networks", "authors": "Maciej Satkiewicz", "background": "任何ReLU网络都是分段仿射的，其隐藏单元可以通过激活子网络的拉回表示，即通过它们的梯度（除偏置项外）。然而，较深层神经元的梯度往往对齐不良，这模糊了网络的内部表示。", "innovation": "作者提出，模型能够对齐梯度与数据，但这种对齐性被ReLU硬门控的内在噪声所掩盖。通过仅在反向传播中应用软门控，减少弱激活神经元的局部影响，作者发现这种修改后的梯度，即“激活拉回”，在多个预训练的ImageNet架构上表现出惊人的感知对齐。此外，作者提出了“路径稳定性”假设，认为二进制激活模式在训练过程中基本稳定并被编码进最终模型的预激活分布中，这提供了一个理论上的解释，说明基于这些拉回的特征归因看似真实，甚至可能带来深层模型的机械解释性。此外，作者为批归一化和深层特征的有效性提供了可能的解释，并提出了网络内部记忆和泛化性质的新视角。", "conclusion": "当路径稳定性假设为真时，激活拉回将与主要决定网络决策的核机器的梯度对齐。这为基于这些拉回的特征归因的实际一致性提供了理论上的解释，甚至可能使得深层模型具有机械解释性。此外，作者还为批归一化和深层特征的有效性提供了可能的解释，并提出了一种新的网络内部记忆和泛化特性视角。作者还提供了代码和一个交互式应用程序，以方便对激活拉回进行更深入的探索。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03660", "html_url": "https://arxiv.org/abs/2509.03660", "title": "半分散式联邦时序预测及客户端可用性预算", "title_en": "Semi-decentralized Federated Time Series Prediction with Client Availability Budgets", "authors": "Yunkai Bao,Reza Safarzadeh,Xin Wang,Steve Drew", "background": "联邦学习（FL）在物联网（IoT）场景中有效促进了分布式客户端之间的协作训练，同时考虑了隐私问题。尽管数据存在异质性，但是客户端还可能受到能量和可用性预算的限制。因此，有效选择参与训练的客户端对于全局模型的收敛和客户端贡献的平衡至关重要。考虑到时序数据的特性，论文探讨了客户端可用性时间变化对联邦学习性能的影响，并提出了FedDeCAB，一种结合可用客户端概率排名的半分散式客户端选择方法。当客户端与服务器断开连接时，FedDeCAB允许从最近邻客户端获取部分模型参数进行联合优化，从而提高离线模型的性能并减少通信开销。实验基于真实的大型出租车和船舶轨迹数据集表明，FedDeCAB在高度异质性数据分布、有限的通信预算以及客户端动态下线或重新加入的情况下是有效的。", "innovation": "提出了一种半分散式的客户端选择方法FedDeCAB，该方法结合了可用客户端的概率排名，并通过允许从最近邻客户端获取部分模型参数进行联合优化来提高模型性能。这种方法能够在客户端与服务器断开连接时减少通信开销，同时提高离线模型的性能。FedDeCAB特别适用于高度异质性数据分布和有限通信预算的场景。", "conclusion": "实验结果表明，FedDeCAB在支持客户端动态下线和重新加入、处理高异质性数据分布以及在有限通信预算的情况下表现出色，证明了该方法的有效性和适用性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03703", "html_url": "https://arxiv.org/abs/2509.03703", "title": "EmbedOR: 基于曲率的可证明簇保留可视化", "title_en": "EmbedOR: Provable Cluster-Preserving Visualizations with Curvature-Based Stochastic Neighbor Embeddings", "authors": "Tristan Luca Saidi,Abigail Hickok,Bastian Rieck,Andrew J. Blumberg", "background": "Stochastic Neighbor Embedding (SNE) 算法，如 UMAP 和 tSNE，经常无法准确地保留噪声较大和高维数据的几何结构。特别是在噪声数据中，它们可能会错误地将底层数据子流形的连续部分隔离开，且在本来易于聚类的数据中找不到适当的聚类。", "innovation": "论文提出了 EmbedOR，一种将曲率引入的 SNE 算法，通过使用增强曲率的距离度量来更强调底层的聚类结构。证明 EmbedOR 距离度量扩展了 tSNE 的一致性结果，适用于更广泛的类别数据集。实验结果表明，与其他 SNE 算法和 UMAP 相比，EmbedOR 更少将连续的高密度区域分割开，并且可以通过 EmbedOR 的度量改进现有可视化图，以此识别分割并提供对数据几何结构的更深入理解。", "conclusion": "论文通过广泛的实验展示了 EmbedOR 在可视化的保几何性以及在分割识别上的优越性。同时证明了 EmbedOR 距离度量具有工具价值，能够用于标注现有可视化图，并揭示数据的底层几何结构的更深层次信息。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03672", "html_url": "https://arxiv.org/abs/2509.03672", "title": "SharedRep-RLHF: 一种适用于多样化偏好强化学习自反馈的共享表示方法", "title_en": "SharedRep-RLHF: A Shared Representation Approach to RLHF with Diverse Preferences", "authors": "Arpan Mukherjee,Marcello Bullo,Deniz Gündüz", "background": "当前的行为奖励学习（RLHF）方法，通过训练单一的奖励模型来代表所有注释者的偏好，未能捕捉到不同子群体间的多样性意见，反而偏向占主导地位的群体。目前最先进的方法MaxMin-RLHF通过学习特定群体的奖励模型，并优化最小奖励群体来促进公平性。然而，MaxMin-RLHF的一个主要局限性在于，当最小奖励群体是少数时，其表现不佳。因此，本文提出了新的框架——SharedRep-RLHF，通过学习和利用各个群体之间的共享特征来优化，而不是为每个群体分别学习不同的奖励模型。实验表明，对于不同的自然语言任务，SharedRep-RLHF的效果优于MaxMin-RLHF，优越性达20%。", "innovation": "引入了新的框架——SharedRep-RLHF，该框架通过学习和利用跨群体的共享特征，优化最大化奖励，而不是为每个群体分别学习不同的奖励模型。实验结果表明，与MaxMin-RLHF相比，SharedRep-RLHF在不同自然语言任务上提高了效用，特别是在少数群体为最小奖励群体时更能有效发挥作用。", "conclusion": "实验结果显示，SharedRep-RLHF相较于MaxMin-RLHF在多样自然语言任务上提升了效用，特别是在面临少数群体作为最小奖励群体时表现出色。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03707", "html_url": "https://arxiv.org/abs/2509.03707", "title": "在线学习最优顺序化检测策略", "title_en": "Online Learning of Optimal Sequential Testing Policies", "authors": "Qiyuan Chen,Raed Al Kontar", "background": "本文研究了一种在线学习问题，旨在为一系列主题确定最优测试策略，每个主题都可以通过一系列来自公共池的候选测试进行评估。当测试之间存在相关性和成本时，进行每个候选测试可能为每个主题提供更多信息，但通常更优选选择仅部分测试。在这种部分信息的情况下，如果测试结果的联合分布已知，则可以将其作为马尔可夫决策过程（MDP）来解决；但在实践中，这个分布是未知的，必须随着主题的测试在线学习。如果一个主题没有完全测试，缺失数据将导致估计算法的偏差，从而使得相比标准的时期MDP问题具有更大的难度。", "innovation": "本文证明了最优顺序化检测问题（OTP）的最小最大遗憾必须至少以 Ω(T^{2/3}) 速率增长，在对比标准时期MDP问题的 Θ(√T) 速率后揭示了缺失数据带来的难度提升。该研究通过探索然后承诺算法，对于离散和高斯分布匹配了这一下界，并通过研究一种名为在线成本敏感最大熵采样问题的变种揭示了缺失数据依赖奖励的效果，并提供了一个逐次消除算法，达到了 Θ(√T) 的遗憾，打破了 OTP 的下界。", "conclusion": "总体而言，这项工作深化了在缺失数据条件下探索与利用的权衡理解，并指导了有效顺序化测试策略的设计，同时通过数值结果证实了理论的正确性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03682", "html_url": "https://arxiv.org/abs/2509.03682", "title": "视频游戏中的多智能体强化学习综述", "title_en": "A Comprehensive Review of Multi-Agent Reinforcement Learning in Video Games", "authors": "Zhengyang Li,Qijin Ji,Xinghong Ling,Quan Liu", "background": "近年来，多智能体强化学习（MARL）在现代游戏中的应用潜力得到了证明。从基础研究到诸如AlphaStar在星际争霸II和OpenAI Five在Dota 2中的里程碑成就，MARL已经证明了其能够在多种游戏环境中实现超人类性能的能力。随着其影响力的增长，对MARL在游戏中的应用进行综合性的审查变得尤为重要。本研究旨在从回合制的两智能体游戏扩展到实时多智能体视频游戏，包括体育游戏、第一人称射击游戏（FPS）、即时战略游戏（RTS）和多人在线战斗竞技场（MOBA）游戏，进行了全面的审查。", "innovation": "本研究针对视频游戏中MARL的挑战进行了分析，包括非稳定状态、部分可观性、稀疏奖励、团队协作和可扩展性，并提出了新的方法来估计游戏复杂性。此外，还指出了需要进一步研究的方向，以促进MARL及其在游戏开发中的应用，为这一快速发展的领域激发进一步的创新。", "conclusion": "本研究为MARL在视频游戏AI系统中的应用提供了见解，并提出了未来的研究方向以推进MARL及其在游戏开发中的应用。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03709", "html_url": "https://arxiv.org/abs/2509.03709", "title": "从联邦学习到$\boldsymbol{X}$学习：通过随机游走打破去中心化的障碍", "title_en": "From Federated Learning to $\\mathbb{X}$-Learning: Breaking the Barriers of Decentrality Through Random Walks", "authors": "Allan Salihovic,Payam Abdisarabshali,Michael Langberg,Seyyedali Hosseinalipour", "background": "论文讨论了$\boldsymbol{X}$学习（$\boldsymbol{X}$L）架构，这是一种新型的分布式学习结构，旨在扩展和加深对去中心化概念的理解。文章展示了$\boldsymbol{X}$L架构与图论及马尔可夫链之间的微妙但非平凡的联系，揭示了$\boldsymbol{X}$L架构在设计理念和自由度上的未探索领域，提出了进一步研究的方向。", "innovation": "论文提出的$\boldsymbol{X}$学习架构是对去中心化概念的一种扩展和深化。它通过增强联邦学习的方法，引入了随机游走的概念，提升了现有分布式学习框架的灵活性和有效性，同时强调了设计考虑的多个自由度和创新点。", "conclusion": "论文着眼于$\boldsymbol{X}$学习架构的设计理念和自由度，暗示了多种未探索的研究方向。最终，作者认为$\boldsymbol{X}$学习为分布式学习提供了新的视角，突破了去中心化的界限。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03738", "html_url": "https://arxiv.org/abs/2509.03738", "title": "稀疏自编码器神经算子：函数空间中的模型恢复", "title_en": "Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces", "authors": "Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar", "background": "尽管PLATO哲学假设指出，神经网络在不同架构下会收敛到类似的表现形式，但神经算子的表示性质仍然很少被探索，尽管它们在科学计算中的重要性日益增加。论文将神经模型中的统一表示问题视为稀疏模型恢复的问题，并引入了一个框架，将稀疏自编码器（SAEs）扩展到提升空间和无限维函数空间，使大型神经算子具有机械可解释性。", "innovation": "论文提出了一种扩展稀疏自编码器（SAEs）的新框架，该框架能够将它们应用于提升空间和无限维函数空间，以促进大型神经算子的机械可解释性。通过比较SAEs、提升-SAE和神经算子的推理和训练动态，论文突出了提升和算子模块引入的有益归纳偏置，这些偏置能够加速恢复过程，提高平滑概念的恢复效果，并实现跨不同分辨率的稳健推理。", "conclusion": "本文通过将提升-SAE和神经算子应用于函数空间，填补了神经算子表示性质研究的空白，揭示了它们在科学计算中的潜力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03652", "html_url": "https://arxiv.org/abs/2509.03652", "title": "非负矩阵分解与共因原则", "title_en": "Nonnegative matrix factorization and the principle of the common cause", "authors": "E. Khalafyan,A. E. Allahverdyan,A. Hovhannisyan", "background": "非负矩阵分解（NMF）是一种已知的无监督数据降维方法。共因原则（PCC）是概率因果关系中的基本方法论方法，它寻求独立混合模型以建模两个相关随机变量的联合概率。研究发现这两种概念密切相关。通过几个灰度图像数据集探讨了它们之间的双向关系，这些数据集可以方便地映射成概率模型。一方面，PCC提供了一种预测工具，用于稳健估计NMF的有效秩。不同于其他估计方法（例如基于贝叶斯信息准则的方法），我们的秩估计对弱噪声具有稳定性。我们表明，围绕该秩实现的NMF能够生成特征（基础图像），这些特征对噪声和局部优化种子也具有稳定性，从而有效解决了NMF的不可识别性问题。另一方面，NMF提供了实施PCC的一种有趣可能性，其中更大的正相关联合概率往往通过独立混合模型较好地解释。我们研究了一种聚类方法，其中具有相同共因的数据点被分到同一个类别中。我们也展示了NMF在数据去噪方面的应用。", "innovation": "1. 提出了非负矩阵分解（NMF）和共因原则（PCC）之间的关系，并通过几个灰度图像数据集进行验证。\r\n2. 表示出PCC作为一种预测工具能够稳健估计NMF的有效秩，对弱噪声具有稳定性。\r\n3. 展示了NMF生成的特征（基础图像）对噪声和局部优化种子具有稳定性，从而有效解决了NMF的不可识别性问题。\r\n4. 提出了一种新的基于NMF的PCC实现方法，利用NMF来实施PCC中的独立混合模型。\r\n5. 设计了一种聚类方法，使用相同的共因来对数据点进行分组。\r\n6. 展示了NMF在数据去噪中的应用。", "conclusion": "本文研究了非负矩阵分解（NMF）和共因原则（PCC）之间的关系，并利用PCC工具稳健地估计NMF的有效秩，解决了不可识别性问题。同时，通过利用NMF生成基础图像的稳定性，进一步验证了NMF的有效性，并展示了NMF在数据聚类和去噪中的应用。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03673", "html_url": "https://arxiv.org/abs/2509.03673", "title": "基于机器学习的经济学视角下供应链管理与金融供应链协同优化研究", "title_en": "A Machine Learning-Based Study on the Synergistic Optimization of Supply Chain Management and Financial Supply Chains from an Economic Perspective", "authors": "Hang Wang,Huijie Tang,Ningai Leng,Zhoufan Yu", "background": "基于经济学理论并结合机器学习技术，本研究旨在探索一种协同供应链管理与金融供应链管理（SCM-FSCM）模型，解决效率损失、融资约束和风险传递等问题。该研究通过结合交易成本与信息不对称理论，使用随机森林等算法处理多维数据，并构建以数据驱动的三维（成本-效率-风险）分析框架。此外，研究使用智能制造核心企业信用赋能加动态质押融资的FSCM模型进行需求预测、利益分配，结合博弈理论和强化学习优化库存采购机制，并使用XGBoost进行信用评估，以提高库存快速变现能力。验证结果显示，该模型可以提高库存周转率30%，降低中小企业融资成本18%-22%，订单履行率稳定在95%以上，模型性能优秀（需求预测误差≤8%，信用评估准确率≥90%）。", "innovation": "本研究通过结合经济学理论和机器学习技术，创新性地提出了一种协同供应链管理与金融供应链管理（SCM-FSCM）模型，引入了智能制造核心企业信用赋能加动态质押融资的FSCM模型，使用LSTM网络进行需求预测，以及使用XGBoost进行信用评估。该研究还结合博弈论与强化学习，优化库存采购机制，提高模型性能。", "conclusion": "该SCM-FSCM模型有效地降低了运营成本、缓解了融资约束，并支持高质量供应链的发展。验证结果显示，该模型在实际应用中取得了显著效果，包括提高了库存周转率、降低了中小企业融资成本、提升了订单履行率和模型性能。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03691", "html_url": "https://arxiv.org/abs/2509.03691", "title": "图随机特征用于可扩展的Gaussian过程", "title_en": "Graph Random Features for Scalable Gaussian Processes", "authors": "Matthew Zhang,Jihao Andreas Lin,Adrian Weller,Richard E. Turner,Isaac Reid", "background": "本文研究了图随机特征（GRFs）在离散输入空间中可扩展Gaussian过程中的应用。GRFs是一种最近引入的图节点核的随机估计器。文献中通常使用精确核来进行Gaussian过程的贝叶斯推断，但其时间复杂度为$O(N^3)$，对于大规模节点数量$N$的图，需要高昂的计算代价和技术支持。因此，如何实现Gaussian过程中大规模图数据的高效贝叶斯推断成为一个重要问题。GRFs作为一种新的方法，旨在解决这一问题，提供了一种潜在的可扩展解决方案。", "innovation": "证明了在 mild 假设下，使用GRFs进行贝叶斯推断的时间复杂度为$O(N^{3/2})$，相比于使用精确核的$O(N^3)$有了显著改善。这种方法可以显著缩短计算时间、节省内存，并适用于节点数量超过$10^6$的图结构上的贝叶斯优化任务，同时保持了竞争性的性能表现。", "conclusion": "本文的发现为大规模图数据上的Gaussian过程应用提供了新的路径，尤其是通过图随机特征使预测速度快了近三个数量级，并减小了内存需求，这一结果为图形大数据分析提供了一种更有效的工具。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03790", "html_url": "https://arxiv.org/abs/2509.03790", "title": "奖励函数中什么基本结构能促进高效稀疏回报学习？", "title_en": "What Fundamental Structure in Reward Functions Enables Efficient Sparse-Reward Learning?", "authors": "Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma", "background": "研究奖励函数的基本性质，使稀疏回报强化学习（RL）更加高效。现有研究鲜有关于稀疏回报RL的样本复杂性理论结果。", "innovation": "本文通过观察奖励矩阵的低秩结构，展示了该结构如何造成从指数到多项式的样本复杂性突变。提出了政策感知矩阵完成（PAMC）方法，将矩阵完成理论与RL通过新分析的策略依赖采样连接起来，该框架提供了：（i）一般稀疏奖励观测的不可能结果；（ii）无需奖励的动态驱动表示学习；（iii）无需假设的置信集通过符合预测；（iv）当低秩结构只近似时渐进退化的稳健完成保证。实验结果显示，在100个领域中有一半显示了可利用结构，PAMC与探索、结构、表示学习基准相比，样本效率提升了1.6到2.1倍，计算开销增加了约20%。", "conclusion": "该研究结果确立了结构奖励学习作为推动机器人技术、医疗保健以及其他安全关键、样本昂贵应用的新范式，具有直接的应用价值。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03813", "html_url": "https://arxiv.org/abs/2509.03813", "title": "基于LiDAR的智能无线环境室内表面分类的机器学习", "title_en": "Machine Learning for LiDAR-Based Indoor Surface Classification in Intelligent Wireless Environments", "authors": "Parth Ashokbhai Shiroya,Swarnagowri Shashidhar,Amod Ashtekar,Krishna Aindrila Kar,Rafaela Lomboy,Dalton Davis,Mohammed E. Eltayeb", "background": "毫米波（mmWave）和亚太赫兹（sub-THz）网络的可靠连接依赖于周围表面的反射，因为高频信号极易受到阻挡。表面的散射特性不仅取决于介电常数，还取决于粗糙度，这决定着能量是否沿镜面方向传播或发散散射。", "innovation": "本研究提出了一种由LiDAR驱动的机器学习框架，用于根据光反射性分类室内表面为半镜面和低镜面类别，以代理电磁散射特性。研究收集了超过78,000个点的数据，按3cm x 3cm的区域划分为图像块，以便从局部视图进行分类。通过提取几何和强度特征，训练了随机森林、XGBoost和神经网络分类器，证明了基于LiDAR的特征能够捕捉粗糙度引起的散射效应。", "conclusion": "所提出的框架能够生成散射感知的环境图和数字孪生，支持自适应波束管理、遮挡恢复和环境感知的连接，在下一代网络中发挥作用。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03733", "html_url": "https://arxiv.org/abs/2509.03733", "title": "几何与神经网络中的可微熵正则化", "title_en": "Differentiable Entropy Regularization for Geometry and Neural Networks", "authors": "Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma", "background": "引出了范围分段熵的可微估计器，这是一种来自计算几何的近期概念，使算法能够根据输入的‘排序性’进行适应。尽管范围分段熵在算法设计中提供了强大的保证，但它尚未被融入到深度学习中。本文研究了如何将范围分段熵的概念应用到深度学习模型中，通过提出不同的方法，实现了其在训练中的使用，设计了能够重构数据为低熵形式的EntropyNet模块，并将其原理推广到Transformer注意力中，直接应用熵正则化。", "innovation": "提出了第一个可微范围分段熵的近似方法，使其能够作为一种可训练的损失函数或正则化项使用；设计了EntropyNet模块，通过将数据重构为低熵形式来加速下游的实例最优算法；将熵正则化的原理扩展到Transformer注意力中，直接应用于熵正则化。", "conclusion": "可微熵提高了不同任务的效率而不会降低准确性：在几何中，该方法实现了高达4.1倍的运行时间加速，误差几乎可以忽略（<0.2%）；在深度学习中，则引发了结构化的注意力模式，准确性比L1基线高6%，并且稀疏性达到80%。理论分析提供了估算器的逼近界限，并进行了详尽的消融实验以验证设计选择。研究结果表明，受限于熵的计算不仅在理论上优雅，而且也是一种适应学习、高效性和结构化表示的实用机制。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03695", "html_url": "https://arxiv.org/abs/2509.03695", "title": "无线网络中基于边缘学习与D2D/P2P启用雾学习架构的分层联邦基础模型", "title_en": "Hierarchical Federated Foundation Models over Wireless Networks for Multi-Modal Multi-Task Intelligence: Integration of Edge Learning with D2D/P2P-Enabled Fog Learning Architectures", "authors": "Payam Abdisarabshali,Fardis Nadimi,Kasra Borazjani,Naji Khosravan,Minghui Liwang,Wei Ni,Dusit Niyato,Michael Langberg,Seyyedali Hosseinalipour", "background": "基础模型（FMs）的兴起重塑了机器学习的格局。随着这些模型不断增大，利用从无线设备中获得的地理分布式数据变得越来越重要，这催生了联邦基础模型（FFMs）。近期，FMs发展成了多模态多任务（M3T）FM（例如GPT-4），能够处理多种跨任务的模态，这激发了新的潜在研究方向：M3T FFMs。文中引入的基于边缘的联邦基础模型（HF-FMs）构建架构，凸显了雾/边缘基础设施中固有的两个未被充分认识到的异质维度：收集的模态异质性及边缘节点上执行的任务异质性。", "innovation": "文中的创新点在于提出了一种新的HF-FM架构，将多模态多任务（M3T）模型的模块结构与雾/边缘基础设施的层次结构相融合，同时允许在可行的情况下使用设备到设备（D2D）通信进行模块传递和局部协作训练。这不仅提升了模型的灵活性和适应性，还极大地促进了在边缘学习和雾学习方面的问题解决。", "conclusion": "通过在无线网络中设计和实现HF-FMs，验证了其独特优势，并提出了一系列定制化的未来研究方向以推动这一未开发领域的进一步探索。此外，文章还开源了HF-FMs的代码，以鼓励对该领域的深入研究（GitHub：此链接）。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03771", "html_url": "https://arxiv.org/abs/2509.03771", "title": "学习对抗世界模型以在多智能体强化学习中实现自动课程生成", "title_en": "Learning an Adversarial World Model for Automated Curriculum Generation in MARL", "authors": "Brennen Hill", "background": "环境生成对于体现智能至关重要。然而，其潜力受限于手工设计训练环境的有限复杂性和隐含偏见。为了开发真正具备广泛适应性和鲁棒性的智能体，需要能够与智能体一起扩增复杂度的环境。先前的研究通常依赖于手工设计的环境，这限制了智能体在复杂和动态环境中学习的能力。因此，如何生成复杂且具有挑战性的环境成为了一个重要挑战。本文重新定义了环境生成问题为学习一种基于目标的生成式世界模型，并提出了一种新的训练方法，其中生成型攻击者智能体与协同防御者智能体共同进化，以实现智能体从简单到复杂的自我扩增学习曲线。这种方法提供了一个自适应的挑战环境，使得智能体能够不断学习和适应，从而解决上述挑战。", "innovation": "提出了一个学习对抗世界模型的系统，该系统通过对抗智能体之间的互动来进化和提升智能体的能力。具体而言，一个生成型攻击者智能体模拟并生成挑战性环境状态，以确保智能体能够学习并克服这些挑战。同时，协同的防御者智能体学习共同策略以应对这些生成的环境。这种方法通过共同进化打造出一个自我扩增的学习课程，使得世界模型能够不断适应并挑战智能体的决策策略，有效提供了一个几乎无限的学习环境。", "conclusion": "实验结果表明，这种方式能够促进智能体生成复杂的行为策略，例如学习生成侧翼包抄和掩护队形，并学会协同攻击和分散战术。这些发现证明对抗共进化是学习驱动智能体向更深层次的战略和鲁棒性的强大方法。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03749", "html_url": "https://arxiv.org/abs/2509.03749", "title": "Mapping on a Budget: Optimizing Spatial Data Collection for ML", "title_en": "Mapping on a Budget: Optimizing Spatial Data Collection for ML", "authors": "Livia Betti,Farooq Sanni,Gnouyaro Sogoyou,Togbe Agbagla,Cullen Molitor,Tamma Carleton,Esther Rolf", "background": "在农业、生态和人类发展等领域，基于卫星图像的机器学习（SatML）受到标记训练数据稀疏性的限制。尽管卫星数据能够覆盖全球，但用于SatML的标记训练数据集却往往规模较小、空间分布集中，并且是为其他目的收集的（例如行政调查或实地测量）。在实践中，这一问题非常普遍，但过去的SatML研究主要关注于新的模型架构和训练算法来处理稀疏的训练数据，而较少直接建模数据条件。这使得希望使用SatML进行大规模监测的科学家和政策制定者不确定应如何收集额外的数据以最大化性能。", "innovation": "本文提出了首个针对不均匀数据收集成本和现实预算约束下优化空间训练数据的建模方法和创新策略。实验模拟了跨三大洲和四个任务的不同问题设置，显示了样本优化带来的显著收益。进一步的实验还阐述了样本优化特别有效的特定设置。本文所介绍的方法旨在适用于SatML的各种应用领域，特别强调了在作者合作者能够直接利用这些研究结果以增强在多哥的集群农业调查中的应用问题设置，从而改善SatML监测效果。", "conclusion": "本文的工作提出了首个针对不均匀数据收集成本和现实预算约束下优化空间训练数据的建模方法和创新策略。通过实验发现，优化样本策略在不同任务上能显著提高性能。特别地，优化采样策略在某些情况下能够显著提升算法效果，尤其是在多哥的农业监测任务中。这些方法在SatML的不同应用领域中具有广泛的应用前景。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03819", "html_url": "https://arxiv.org/abs/2509.03819", "title": "使用深度神经网络预测交通事故严重程度", "title_en": "Predicting Traffic Accident Severity with Deep Neural Networks", "authors": "Meghan Bibb,Pablo Rivas,Mahee Tayba", "background": "交通事故的研究可以用于降低未来事件的风险。近年来，机器学习的进步为研究与交通事故相关数据提供了新的途径。新模型在不平衡数据上的泛化能力和预测能力较强。在此研究中，我们探讨了基于神经网络的模型在与交通事故相关的数据上的应用。从分析相关特征共线性和通过自动编码器进行的无监督降维开始，接着使用密集网络。目标是对交通事故数据进行特征分类，结果表明，在使用所提出的深度神经网络进行事故严重程度分类时，交叉验证结果可达92%的准确率。", "innovation": "1. 使用神经网络模型来分类交通事故严重程度，特别是针对不平衡数据实现良好的泛化能力和高的预测能力。\n2. 实验分析显示，通过自动编码器进行的无监督降维增强了模型的表现。\n3. 深度神经网络在分类交通事故严重程度上达到了高水平的准确率，验证了其在处理此类问题上的有效性。", "conclusion": "通过使用深度神经网络对与交通事故相关数据进行分析，我们能够实现92%的分类准确率。该模型不仅展示了在不平衡数据上的强泛化能力，而且在预测交通事故严重程度方面具有较高的准确性。这项研究对于提高交通事故预测的精准度具有重要意义。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03810", "html_url": "https://arxiv.org/abs/2509.03810", "title": "基于特征调整的在线时间序列预测", "title_en": "Online time series prediction using feature adjustment", "authors": "Xiannan Huang,Shuhan Qiu,Jiayuan Du,Chao Yang", "background": "时间序列预测在多个领域中具有重要性，但由于分布变化所带来的挑战，其效果受限，尤其是在数据连续到达的在线部署场景中，需要模型能够持续适应不断变化的模式。现有的在线学习方法主要集中在两个方面：选择更新参数（如最终层权重或适配模块）以及开发更新策略（如使用最近批次、重放缓冲或平均梯度）。但是，现有方法在多步预测中的反馈延迟问题仍然没有得到有效解决。", "innovation": "本文提出了ADAPT-Z（在Z空间中通过持续跟踪进行自动增量调整），该方法使用一个适配器模块，结合当前特征表示和历史梯度信息，即使存在延迟也能实现稳健的参数更新。这种创新方法通过调整特征表示来更新潜在因子，以应对分布变化，从而提高了多步预测的性能。", "conclusion": "通过广泛的实验表明，本文的方法在多个数据集上均优于无调整的标准基准模型和最先进的在线学习方法。详细的代码可以在[此处](this https URL)获得。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03850", "html_url": "https://arxiv.org/abs/2509.03850", "title": "数据增强aware量化知识蒸馏", "title_en": "Data-Augmented Quantization-Aware Knowledge Distillation", "authors": "Justin Kur,Kaiqi Zhao", "background": "现有量化感知训练（QAT）和知识蒸馏（KD）的工作主要集中在通过设计更好的KD损失函数或优化QAT的前向和反向传播来提高量化模型的准确率。但是，输入变换如数据增强（DA）对QAT和KD的影响还缺乏深入理解。", "innovation": "本文引入了一个新颖的度量指标，根据其最大化上下文互信息（与图像标签无关的信息）的能力以及确保每个类别的预测值与真实标签接近的平均值来评价数据增强技术。此方法能够自动排序和选择数据增强技术，且几乎不需要额外的训练开销，并且与任何KD或QAT算法兼容。研究表明，通过该指标选择数据增强技术可以显著提高现有QAT和KD的性能，适用于各种模型架构和数据集。", "conclusion": "该方法自动选择有效数据增强技术，改进了QAT和KD技术，适用于多种模型和数据集。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03834", "html_url": "https://arxiv.org/abs/2509.03834", "title": "从莱登到乐土岛：常值波特斯模型在社区检测中的泛函博弈视角", "title_en": "From Leiden to Pleasure Island: The Constant Potts Model for Community Detection as a Hedonic Game", "authors": "Lucas Lopes Felipe,Konstantin Avrachenkov,Daniel Sadoc Menasche", "background": "社区检测是数据科学中的一个基本问题，涉及将节点划分为不相交的社区。现有方法通常是通过优化一些指标来实现这一目标，本文将常值波特斯模型（CPM）从网络分割的角度进行游戏理论分析。", "innovation": "1. 将CPM重新解释为潜在的幸福博弈，通过将全局哈密顿分解为局部效用函数，证明了局部优化目标通过更好的响应动力学可以在伪多项式时间内收敛到均衡分区。\n2. 引入并关联了两种稳定性标准：基于一种新提出的鲁棒性概念的严格标准，以及基于权重求和的放松效用函数，由分辨率参数控制。", "conclusion": "在有初始分区的社区跟踪场景中，使用部分真实信息启动莱登算法，实验表明，基于新型稳定性的分区能获得更高的真实社区恢复准确性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03758", "html_url": "https://arxiv.org/abs/2509.03758", "title": "通过扩散映射学习函数", "title_en": "Learning functions through Diffusion Maps", "authors": "Alvaro Almeida Gomez", "background": "该研究基于流形假设，利用扩散映射框架，提出了一种数据驱动的方法来逼近光滑流形上的实值函数。传统的逼近方法可能面临计算成本高和维度灾难等问题，尤其是在处理高维数据时。该研究针对这些问题，通过点函数值评估，利用扩散几何学及其与热方程和拉普拉斯-贝尔特拉米算子的联系，构建了一个光滑函数扩展到环境空间的方法。为了应对高维数据的计算挑战，研究还引入了基于距离矩阵低秩结构的降维策略，并通过奇异值分解揭示了这种结构。此外，研究还开发了一种在线更新机制，可以高效地整合新数据，从而提高方法的可扩展性和降低计算成本。实验结果表明，该方法在准确性和效率方面优于经典的前向神经网络和插值方法，特别是在稀疏CT重建等应用中表现突出。", "innovation": "1. 提出了一种基于流形假设和扩散映射框架的数据驱动方法，用于逼近光滑流形上的实值函数。\n2. 提出了一种基于距离矩阵低秩结构的降维策略，通过奇异值分解来实现。\n3. 发展了一种在线更新机制，可以高效地整合新数据，提高了方法的可扩展性和降低了计算成本。\n4. 实验结果表明，该方法在稀疏CT重建等应用中优于经典方法，显示出较高的准确性和效率。", "conclusion": "本文提出的方法在逼近光滑流形上的实值函数方面表现优异，特别是在处理稀疏CT重建等高维数据问题时，其准确性和效率均优于传统方法。通过引入降维策略和在线更新机制，本文方法提高了对新数据的适应能力和计算效率。未来可以进一步探索该方法在其他高维数据处理领域的应用。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03845", "html_url": "https://arxiv.org/abs/2509.03845", "title": "通过概率上下文变量的元逆强化学习在均场博弈中的应用", "title_en": "Meta-Inverse Reinforcement Learning for Mean Field Games via Probabilistic Context Variables", "authors": "Yang Chen,Xiao Lin,Bo Yan,Libo Zhang,Jiamou Liu,Neset Özkan Tan,Michael Witbrock", "background": "在实际应用中，设计适合大量相互作用的智能代理的奖励函数是一项挑战。逆强化学习（IRL）在均场博弈（MFGs）中的应用为从专家演示中推断奖励函数提供了一种实用框架。然而，现有方法假设代理同质化，这限制了其处理不同且未知目标的演示数据的能力，而此类数据在实践中较为常见。", "innovation": "本文提出了一种深度潜变量MFG模型及其对应的IRL方法。该方法可以推断出不同但结构相似任务的奖励，而无需了解底层环境或修改MFG模型。实验结果表明，与当前最先进的MFG中IRL方法相比，该方法更优。", "conclusion": "提出的深度潜变量MFG模型和相关IRL方法在仿真场景和实际的地理出租车定价问题上均表现出色，优于现有的MFG中的IRL方法。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03837", "html_url": "https://arxiv.org/abs/2509.03837", "title": "基于多模态大型语言模型的车辆到基础设施协作空间感知", "title_en": "Vehicle-to-Infrastructure Collaborative Spatial Perception via Multimodal Large Language Models", "authors": "Kimia Ehsani,Walid Saad", "background": "准确预测通信链路质量（如V2I系统的链路质量）对实现平滑切换、高效波束管理和可靠低延迟通信至关重要。现代车辆传感器数据的增多推动了多模态大规模语言模型（MLLMs）的应用，因为它们具有跨任务适应性和推理能力。然而，MLLMs本就不具备三维空间理解能力。为了克服这一局限性，提出了一个轻量级的插件式鸟瞰视图（BEV）注入连接器。该框架通过收集邻近车辆的传感数据构建环境的BEV表示，将其与自身车辆的输入融合，提供空间上下文给大语言模型。开发了一个结合CARLA模拟器和MATLAB基线射线跟踪的协同模拟环境，生成覆盖多种场景的RGB、LiDAR、GPS和无线信号数据，并从射线跟踪输出中程序化提取指令和真实响应。", "innovation": "提出了一种轻量级的插件式BEV注入连接器，通过融合邻近车辆传感器数据构建的BEV表示，提供给大语言模型空间上下文，从而支持现实的多模态学习。开发了一个协同模拟环境，结合了CARLA模拟器和MATLAB基线射线跟踪，生成多种场景的RGB、LiDAR、GPS和无线信号数据。此外，在广泛的实验中展示了该BEV注入框架在链路预测任务方面的性能改进，包括视线（LoS）与非视线（NLoS）分类、链路可用性及阻塞预测。针对具有挑战性的天气条件（如雨天和夜晚），该论文证明了此框架的优势，性能提升高达32.7%。", "conclusion": "该方法通过引入轻量级的插件式BEV注入连接器，显著提升了V2I链路预测任务的性能。在多种场景下，与仅使用自身车辆的基线相比，宏平均准确度提高了13.9%，特别是在恶劣的天气条件下（如雨天和夜晚），性能提升更为显著，表明该框架具有在不利环境下的鲁棒性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03885", "html_url": "https://arxiv.org/abs/2509.03885", "title": "Topotein:拓扑深度学习在蛋白质表征学习中的应用", "title_en": "Topotein: Topological Deep Learning for Protein Representation Learning", "authors": "Zhiyu Wang,Arian Jamasb,Mustafa Hajij,Alex Morehead,Luke Braithwaite,Pietro Liò", "background": "蛋白质表征学习（PRL）对于理解结构-功能关系至关重要，但是当前基于序列和图的方法无法捕捉蛋白质结构中的层次组织。通过广泛实验，本文证明了现有的几何图神经网络在蛋白质表征学习（PRL）任务上表现不佳，主要原因是无法有效捕捉多尺度的结构模式。因此，需要新的方法来改进蛋白质结构的理解和预测。", "innovation": "本文提出了Topotein框架，该框架通过引入新型的蛋白质组合复杂体（PCC）和拓扑完整感知器网络（TCPNet），将拓扑深度学习应用于蛋白质表征学习。PCC以多层次方式表示蛋白质，从残基到二级结构再到完整的蛋白质，即使在每一层都保留了几何信息。TCPNet利用SE(3)-等变消息传递在多层次结构之间的进行传播，更有效地捕捉多尺度结构模式。实验表明，TCPNet在四个PRL任务上始终优于最先进的几何图神经网络，尤其是在需要理解二级结构排列的分类任务上表现出特别的优势。", "conclusion": "基于广泛实验的验证，本文的方法证明了多层次的拓扑特征在蛋白质分析中的重要性。TCPNet通过有效利用拓扑深层次的结构特性，提供了比现有方法更好的蛋白质表征学习性能，展示了其作为蛋白质功能理解工具的强大潜力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04112", "html_url": "https://arxiv.org/abs/2509.04112", "title": "基于合成反事实标签的高效配准反事实推断", "title_en": "Synthetic Counterfactual Labels for Efficient Conformal Counterfactual Inference", "authors": "Amirmohammad Farzaneh,Matteo Zecchin,Osvaldo Simeone", "background": "现有的配准反事实推断（CCI）方法提供了边际覆盖率保证，但在样本有限且处理不平衡的情况下，通常会产生过于保守的预测区间。", "innovation": "提出了一种新的框架SP-CCI，通过使用预训练的反事实模型生成合成反事实标签来增强校准集。同时，SP-CCI结合了风险控制预测集（RCPS）和带预测增强推断（PPI）的校准步骤中的去偏置步骤，保证了有效性。理论证明SP-CCI在保持边际覆盖率的同时，能获得更紧凑的预测区间，并且在精确和近似重要加权下都有理论保证。", "conclusion": "实验证明，与标准CCI相比，SP-CCI在所有设置中都一致地减少了预测区间的宽度。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03892", "html_url": "https://arxiv.org/abs/2509.03892", "title": "带有运算法则上限的失误有限在线学习", "title_en": "Mistake-bounded online learning with operation caps", "authors": "Jesse Geneson,Meien Li,Linus Tang", "background": "当前研究中，对于在线学习模型，特别是在带有运算法则限制的在线学习模型中，如何通过最少的计算步骤来学习任意函数族，并且在有限的失误次数内完成，这一问题还未得到全面解决。本研究旨在解决这一背景下的失误有限在线学习问题，并推广到更广泛的运算法则限制环境中。", "innovation": "该研究在带有运算法则上限的在线学习模型方面，首次证明了一般性的边界结果，指出了每轮所需的最小计算步骤数，并解决了与带反馈的忽略性失误有限在线学习相关的问题。研究还进一步将结果推广到操作限制的设置中。", "conclusion": "该研究通过理论证明了在失误有限的在线学习中，每轮所需的最小计算步骤数，并成功解决了带有带反馈的忽略性失误有限在线学习问题。此外，研究还扩展了这一结果到带有运算法则限制的更广泛环境中。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04107", "html_url": "https://arxiv.org/abs/2509.04107", "title": "FedQuad: 联邦随机四元组学习以缓解数据异质性", "title_en": "FedQuad: Federated Stochastic Quadruplet Learning to Mitigate Data Heterogeneity", "authors": "Ozgu Goksu,Nicolas Pugeault", "background": "联邦学习（FL）提供了一种分散式模型训练的方式，有效解决了分布式数据和隐私保护等问题。然而，在客户端数据异质性的影响下，全局模型的泛化能力经常遇到挑战，尤其是在数据集规模有限且类别不平衡的情况下。为了缓解数据异质性，本文提出了一种名为FedQuad的新方法，该方法明确优化了类内小方差和类间大方差，减少了模型聚合对客户端表示的负面影响。该方法通过最小化相似对之间的距离并最大化负对之间的距离，在共享特征空间中有效地解耦客户端数据。", "innovation": "本文提出了一种名为FedQuad的新方法，旨在通过优化类内小方差和类间大方差，缓解联邦学习中的数据异质性问题。FedQuad通过在共享特征空间中最小化相似对之间的距离并最大化负对之间的距离，有效地解耦了客户端数据，从而在多个客户端和多种数据分布下展示了优于现有方法的性能。", "conclusion": "本文通过在联邦学习环境下对基于度量学习的方法进行详细分析，展示了FedQuad在缓解代表学习挑战方面的有效性能，从而为联邦学习中的数据异质性问题提供了一个有效的解决方案。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03948", "html_url": "https://arxiv.org/abs/2509.03948", "title": "空间应用中分类算法局部 robustness 的形式验证", "title_en": "Formal Verification of Local Robustness of a Classification Algorithm for a Spatial Use Case", "authors": "Delphine Longuet,Amira Elouazzani,Alejandro Penacho Riveiros,Nicola Bastianello", "background": "卫星组件的故障会导致高昂的成本和挑战，通常需要大量的人力和物资资源来解决。将基于混合AI的故障检测系统直接嵌入卫星中，可以大大减轻这种负担，因为它可以使故障检测更早地进行。然而，这些系统必须具有极高的可靠性。", "innovation": "为了确保这种依赖性，作者使用形式验证工具Marabou验证AI算法中使用的神经网络模型的局部稳健性。这种方法能够量化模型输入可以被扰动的多少，以便在不确定性下提高其性能的信任度。", "conclusion": "通过应用形式验证工具Marabou，此研究提高了基于AI的卫星故障检测系统的可靠性和稳健性，从而增强了解决复杂空间应用中不确定性的能力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04128", "html_url": "https://arxiv.org/abs/2509.04128", "title": "公平的代价？重新思考在社会负担下的补偿", "title_en": "Who Pays for Fairness? Rethinking Recourse under Social Burden", "authors": "Ainhize Barrainkua,Giovanni De Toni,Jose Antonio Lozano,Novi Quadrianto", "background": "基于机器学习的预测在影响生活的敏感决策应用中越来越普遍，这推动了确保分类器公平性的研究。算法补偿是当分类器做出负面决策时，必须提供的个体可采取的行动步骤，以便逆转该结果的概念。许多研究者对补偿过程中的公平保证提出了担忧。本文旨在全面理论化算法补偿中的不公平性，正式关联补偿和分类过程中的公平保证，并关注标准等成本范式的局限性。", "innovation": "本文提出了一种基于社会负担的新公平框架，并引入了实用算法MISOB，在不对整体分类器准确性造成影响的情况下减少所有群体的社会负担。", "conclusion": "实验结果表明，MISOB能在不牺牲整体分类器准确性的同时，减少所有群体的社会负担。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03852", "html_url": "https://arxiv.org/abs/2509.03852", "title": "MillGNN: 学习多尺度领先滞后依赖性以进行多变量时间序列预测", "title_en": "MillGNN: Learning Multi-Scale Lead-Lag Dependencies for Multi-Variate Time Series Forecasting", "authors": "Binqing Wu,Zongjiang Shang,Jianlong Huang,Ling Chen", "background": "多变量时间序列（MTS）预报在各种应用中至关重要。现有的方法依靠其强大的内在和跨变量依赖性的捕捉能力已显示出有希望的结果。然而，这些方法往往忽略了在多个分组级别上的领先滞后依赖性，无法捕捉复杂系统中的层次领先滞后效应。", "innovation": "MillGNN 提出了一种新颖的基于图神经网络的方法，用于学习多尺度分组级别的领先滞后依赖性，以全面捕捉变量级别和分组级别的领先滞后效应，并考虑到动态衰减特征。MillGNN 的两大创新点包括：（1）规模特定的领先滞后图学习模块，该模块综合了来自实时输入和时间滞后的真实动态衰减特征，并结合交叉相关系数来学习每种尺度的领先滞后依赖性；（2）分级领先滞后消息传递模块，该模块在多个分组尺度上以结构化的方式传递领先滞后消息，同时传播内在和跨尺度的领先滞后效应，从而以全面和高效的平衡捕捉多尺度的领先滞后效应。", "conclusion": "MillGNN 在11个数据集上的实验证明，与16种最先进的方法相比，在长短期MTS预测中具有优越性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03884", "html_url": "https://arxiv.org/abs/2509.03884", "title": "基于多层感知机神经网络的肽组学预测模型用于冠心病的诊断", "title_en": "Peptidomic-Based Prediction Model for Coronary Heart Disease Using a Multilayer Perceptron Neural Network", "authors": "Jesus Celis-Porras", "background": "冠心病是全球主要的死亡原因之一，对年度医疗开支有显著贡献。为开发非侵入性诊断方法，本研究设计了一个基于多层感知器（MLP）神经网络的模型，该模型使用了50个通过遗传算法筛选出的关键尿液肽生物标志物，用于训练分类模型。治疗组和对照组各包含345名个体，使用合成少数类过采样技术（SMOTE）进行了平衡处理。神经网络采用分层验证策略进行训练。使用包含3个隐藏层（每个隐藏层60个神经元）和一个输出层（2个神经元）的网络结构，模型实现的精准度、敏感性、特异性分别为95.67%，95.65%的F1分数。二类疾病的受试者操作特征曲线下面积（AUC）达到0.9748，数学相关系数（MCC）和科恩κ系数分别为0.9134和0.9131，证明了其检测冠心病的有效性和可靠性。研究结果显示，该模型提供了一种高准确性且稳健的非侵入性诊断工具，用于冠心病的诊断。", "innovation": "设计了一个基于多层感知器（MLP）神经网络的模型，以50个关键尿液肽生物标志物为训练数据，采用遗传算法筛选特征，使用合成少数类过采样技术（SMOTE）进行组间平衡，使用分层验证策略进行神经网络训练。该模型在精准度、敏感性、特异性和F1分数方面表现出色，具有良好的检测冠心病的性能和可靠性。", "conclusion": "研究结果表明，基于肽组学和多层感知机神经网络的预测模型提供了一种高准确性且稳健的非侵入性诊断工具，可以有效检测冠心病。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04053", "html_url": "https://arxiv.org/abs/2509.04053", "title": "关于通过前列腺癌案例研究使预测模型与临床经验学习一致的方法", "title_en": "On Aligning Prediction Models with Clinical Experiential Learning: A Prostate Cancer Case Study", "authors": "Jacqueline J. Vallon,William Overman,Wanqiao Xu,Neil Panjwani,Xi Ling,Sushmita Vij,Hilary P. Bagshaw,John T. Leppert,Sumit Shah,Geoffrey Sonn,Sandy Srinivas,Erqi Pollom,Mark K. Buyyounouski,Mohsen Bayati", "background": "近十年来，机器学习模型在医疗健康应用中的使用量显著增加。尽管现代机器学习模型性能很高，但它们并不总是捕捉到终端用户所需的模式。例如，一个模型可能会预测固定其他特征情况下癌症阶段与生存率之间的非单调递减关系。本文探讨了当现代机器学习管道不够具体时，模型行为与临床经验学习之间的不一致。通过前列腺癌结果预测案例研究，作者首先通过在机器学习模型中引入临床知识的约束，解决了这些不一致，然后分析了不同 degree 的不具体对模型性能和行为的影响。研究表明，通过引入约束条件，机器学习模型可以与临床经验学习一致，而不降低性能。本文还通过随机实验探讨了通过反馈驱动的方式使非生成性人工智能临床风险预测模型与临床经验学习一致的可能性。实验结果表明，在使用提案的方法引导临床医生偏好时，约束模型和未约束模型在患者预测上的差异越大，在临床解释上的差异也越大。", "innovation": "提出了一个可复现的框架，用于研究模型行为与临床经验学习之间的不一致，特别关注现代机器学习管道的具体性对这一现象的影响。通过在机器学习模型中引入临床知识约束，首次通过真实案例研究展示了机器学习模型可以与临床经验学习一致，同时不牺牲性能。通过随机实验进一步探讨了反馈驱动的模型调整方法在非生成性人工智能临床风险预测模型中的可行性。", "conclusion": "通过引入约束条件，机器学习模型可以与临床经验学习一致，而不降低性能。反馈驱动的模型调整策略在非生成性人工智能临床风险预测模型中是可行的，通过引导临床医生的偏好，这种差异在临床解释中更为明显。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04169", "html_url": "https://arxiv.org/abs/2509.04169", "title": "时间序列预测中的隐私风险：用户和记录级别成员推断", "title_en": "Privacy Risks in Time Series Forecasting: User- and Record-Level Membership Inference", "authors": "Nicolas Johansson(1),Tobias Olsson(1),Daniel Nilsson(2),Johan Östman(2),Fazeleh Hoseini(2) ((1) Chalmers University of Technology, (2) AI Sweden)", "background": "会员推断攻击 (MIAs) 的目的是确定特定数据是否被用于训练模型。虽然 MIAs 在分类模型上已被广泛研究，但它们对时间序列预测模型的影响却很少被探讨。该研究填补了这一空白，引入了两种新的攻击方法：一是将最先进的 MIA 方法之一，用于分类模型的多变量 LiRA 调整为时间序列预测设置，二是提出了一种新型端到端学习方法，称为 Deep Time Series (DTS) 攻击。", "innovation": "研究引入了两种新的会员推断攻击方法，包括将多变量 LiRA 方法调整为时间序列预测，并提出了一种新的端到端学习方法 Deep Time Series (DTS) 攻击。这些方法在时间序列预测中进行了基准测试，并展示了预测模型的脆弱性，特别是在用户级别的攻击中，常常能够实现完美的检测。此外，攻击的脆弱性随着更长的预测时隙和更小的训练群体而增加。", "conclusion": "提出的攻击方法在多种情况下表现最佳，设定了时间序列预测中的隐私风险评估的新基准。研究结果表明时间序列预测模型存在隐私风险，特别是在用户级别的攻击中，常常能够实现完美检测。研究指出，随着预测时隙的延长和训练群体的减小，脆弱性会增加。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04178", "html_url": "https://arxiv.org/abs/2509.04178", "title": "对“图神经网络中的过平滑现象的注记”的评论", "title_en": "Comment on \"A Note on Over-Smoothing for Graph Neural Networks\"", "authors": "Razi Hasson,Reuven Guetta", "background": "该论文评论了Cai和Wang (2020, arXiv:2006.13318)的研究，后者通过狄利克雷能量分析了图神经网络（GNNs）中的过平滑现象。这篇评论提供了理论分析，揭示了在温和的谱条件下，节点嵌入的狄利克雷能量随深度呈指数衰减。论文还进一步将结果扩展到了谱多项式滤波器，并为Leaky-ReLU情况提供了简短证明。", "innovation": "该论文的创新在于：(1) 在温和的谱条件下（包括使用Leaky-ReLU），证明了节点嵌入的狄利克雷能量随深度呈指数衰减；(2) 将结果扩展到谱多项式滤波器；(3) 提供了Leaky-ReLU情况的简短证明。", "conclusion": "通过边删除和权重放大实验，论文表明狄利克雷能量的增加可能指示了解决过平滑现象的实际方法。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04166", "html_url": "https://arxiv.org/abs/2509.04166", "title": "跨越物种鸿沟：从语音到动物声音的迁移学习", "title_en": "Crossing the Species Divide: Transfer Learning from Speech to Animal Sounds", "authors": "Jules Cauzinille,Marius Miron,Olivier Pietquin,Masato Hagiwara,Ricard Marxer,Arnaud Rey,Benoit Favre", "background": "自监督语音模型在语音处理任务中展示出了出色的性能，但它们在非语音数据上的效果尚待探索。本研究探讨了此类模型在生物声学检测与分类任务中的迁移学习能力。研究表明，HuBERT、WavLM和XEUS等模型能够生成跨物种的动物声音的丰富潜在表示。通过线性探针分析时间平均表示的模型属性，进一步扩展方法以考虑时序信息的影响，并分析频率范围和噪声对性能的影响。", "innovation": "本研究创新地利用自监督学习进行生物声学分析，跨越了物种间的鸿沟。研究结果显示，这些模型能够生成跨物种的动物声音的丰富潜在表示，并且通过自监督学习框架能够适应噪声环境。此外，通过线性探针分析模型属性，并考虑时序信息对模型性能的影响，这为今后的研究提供了新的方法和视角。", "conclusion": "本研究证明了自监督学习框架在生物声学研究中的有效性，特别是对于不同物种之间的声音信号。尽管噪声会对性能产生影响，但自监督预训练能够提升模型在噪声环境下的鲁棒性。这一发现指出了基于语音的自监督学习作为生物声学研究高效框架的潜力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04226", "html_url": "https://arxiv.org/abs/2509.04226", "title": "Mamba/状态空间模型和变压器模型中的长距离依赖性再思考", "title_en": "Rethinking the long-range dependency in Mamba/SSM and transformer models", "authors": "Cong Ma,Kayvan Najarian", "background": "近年来，状态空间模型（尤其是Mamba）和变压器模型是具有长期依赖性的序列模型中最为理想的特性之一。新的模型架构正在不断发展并进行基准测试，以应对需要长期依赖性的预测任务。然而，这些模型建模长期依赖性的能力尚未从理论层面进行调查，这阻碍了在这一方面的系统性改进。", "innovation": "本文通过使用隐藏状态相对于输入历史的导数定义长期依赖性，并基于此定义比较状态空间模型（SSM）和变压器模型建模长期依赖性的能力。文章指出，状态空间模型的长期依赖性随着序列长度呈指数衰减，这与递归神经网络（RNN）的记忆函数的指数衰减一致。而变压器模型中的注意力机制更具灵活性，理论上在充分的训练数据、计算资源以及适当训练的情况下，可能更擅长建模长期依赖性。为结合注意力机制的长期依赖灵活性和状态空间模型的计算效率，本文提出了一种新的状态更新公式，并证明其在输入数据的标准化正态分布下的稳定性。", "conclusion": "长期依赖性的定义被用来理论性地评估SSM和变压器模型的能力，本文提出了改进状态空间模型以更好地处理长期依赖性的方法，并证明了该方法的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04152", "html_url": "https://arxiv.org/abs/2509.04152", "title": "TAGAL：使用代理大语言模型方法生成表格数据", "title_en": "TAGAL: Tabular Data Generation using Agentic LLM Methods", "authors": "Benoît Ronval,Pierre Dupont,Siegfried Nijssen", "background": "生成数据是提高机器学习任务性能的常见方法，特别是在模型分类的训练中。本文介绍了TAGAL，这是一个能够使用代理工作流生成 synthetic tabular 数据的方法集合。这些方法利用大型语言模型（LLMs）实现自动迭代过程，通过反馈不断改进生成的数据，而无需进一步训练LLMs。利用LLMs还能在生成过程中添加外部知识。研究通过多种数据集和生成数据的不同质量方面，评估了TAGAL的表现。此外，研究还探讨了使用合成数据训练分类器以及结合真实和合成数据的效果，并比较了真实和生成数据之间的相似性。结果显示，TAGAL能够在不进行LLMs训练的情况下与需要LLMs训练的先进方法竞争，并且通常比其他无训练方法表现更好，突显了代理工作流的潜力，为基于LLM的数据生成方法打开了新的研究方向。", "innovation": "TAGAL利用大型语言模型实现了自动迭代过程，并能够通过反馈不断改进生成的数据，同时还能在生成过程中添加外部知识。此外，TAGAL能够在不需要训练LLMs的情况下，与需要训练LLMs的先进方法竞争，并且通常比其他无训练方法表现更好，突显了代理工作流的潜力。", "conclusion": "研究结果表明，TAGAL能够在多种数据集和不同的质量方面与需要LLMs训练的先进方法竞争，并且其表现出色。这表明代理工作流在基于大语言模型的数据生成方法中具有巨大潜力，为未来的研究提供了新的方向。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04185", "html_url": "https://arxiv.org/abs/2509.04185", "title": "Set Block Decoding 是一种语言模型推理加速器", "title_en": "Set Block Decoding is a Language Model Inference Accelerator", "authors": "Itai Gat,Heli Ben-Hamu,Marton Havasi,Daniel Haziza,Jeremy Reizenstein,Gabriel Synnaeve,David Lopez-Paz,Brian Karrer,Yaron Lipman", "background": "自回归下一个标记预测语言模型具有强大的能力，但由于推理阶段（特别是在解码阶段）的高计算和内存成本，它们在实际部署中面临巨大挑战。", "innovation": "作者引入了一种简单且灵活的Set Block Decoding (SBD) 方式，通过在单一架构中结合标准的下一个标记预测（NTP）和遮罩标记预测（MATP），能够在并行处理非连续的未来标记的同时加速生成过程。这种方法允许利用离散扩散文献中的高级求解器，提供显著的加速同时保持准确性。SBD 无需架构变更或额外的训练超参数，并且可以与精确的KV缓存兼容，通过微调现有的下一个标记预测模型即可实现。", "conclusion": "通过微调 Llama-3.1 8B 和 Qwen-3 8B，作者证明了 SBD 能够将生成所需的前向传递次数减少 3-5 倍，同时保持与等效的 NTP 训练相同的效果。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04208", "html_url": "https://arxiv.org/abs/2509.04208", "title": "One-Embedding-Fits-All: 面向模型动物园的高效零样本时间序列预测", "title_en": "One-Embedding-Fits-All: Efficient Zero-Shot Time Series Forecasting by a Model Zoo", "authors": "Hao-Nan Shi,Ting-Ji Huang,Lu Han,De-Chuan Zhan,Han-Jia Ye", "background": "时间序列基础模型（TSFMs）的普及极大地推动了零样本预测的发展，使其能够对未见过的时间序列进行预测，而无需特定任务的微调。大量研究表明，并不存在一种适用于所有情况的最佳TSFM，不同模型对不同的时间模式有偏好。这种多样性提出了一种机会：如何利用TSFMs的互补能力。基于此，论文提出了ZooCast，该系统能够识别每个模型的预测强项，并智能地将当前的TSFMs组织成一个动态选择最适宜模型的模型动物园。实验显示，ZooCast在GIFT-Eval零样本预测基准测试中的性能出众，同时保持了单一TSFM的效率。在现实场景中，随着模型的逐步更新，该框架能够无缝添加新模型，实现逐步提升的准确度，且几乎无额外开销。", "innovation": "ZooCast的核心创新在于One-Embedding-Fits-All范式，这种范式通过构建统一表示空间，使得动物园中的每个模型都可以用单一嵌入表示，从而能高效地为所有任务进行相似性匹配。这不仅提高了模型的灵活性，还确保了预测的高效性。", "conclusion": "ZooCast通过创建一个由不同时间序列模型组成的动态动物园，实现了零样本时间序列预测的强性能，同时保持了单一模型的效率。在实际使用场景中，该系统能够无缝集成新模型，实现准确性的逐步提升，且几乎无需额外开销。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04232", "html_url": "https://arxiv.org/abs/2509.04232", "title": "重新审视分层高斯噪声注入：弥合隐含目标与隐私预算分配之间的鸿沟", "title_en": "Rethinking Layer-wise Gaussian Noise Injection: Bridging Implicit Objectives and Privacy Budget Allocation", "authors": "Qifeng Tan,Shusen Yang,Xuebin Ren,Yikai Zhang(Xi'an Jiaotong University)", "background": "分层高斯机制（LGM）通过将噪声注入分割的梯度向量来增强不同隐私的强大学习的灵活性。然而，现有的方法往往依赖于启发式的噪声分配策略，缺乏对噪声分配与正式的隐私-效用权衡之间的理论联系的严谨理解。现有方法在优化目标设置上存在缺陷，要么忽略了层间信噪比（SNR）的一致性，要么导致隐私预算的低效利用。", "innovation": "本文提出了一种统一的分析框架，该框架系统地连接了分层噪声注入策略与其隐含的优化目标以及相关的隐私预算分配。提出了一种信噪比一致（SNR-Consistent）的噪声分配策略，该策略结合了层间SNR一致性与高效利用隐私预算两个方面，从而实现更好的信号保留和更有效的隐私预算利用。该方法在中央化和联邦学习设置中进行的大量实验表明，我们的方法在隐私-效用权衡上始终优于现有的分配策略。此外，该框架不仅提供了对先前方法的诊断见解，还为设计适应性和有效的噪声注入方案提供了理论指导。", "conclusion": "本文不仅提供了一种新的噪声注入机制和策略，还提供了一个框架来理解和优化分层学习中的隐私-效用权衡。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04245", "html_url": "https://arxiv.org/abs/2509.04245", "title": "使用深度生成模型为心脏衰竭预后生成合成生存数据", "title_en": "Synthetic Survival Data Generation for Heart Failure Prognosis Using Deep Generative Models", "authors": "Chanon Puttanawarut,Natcha Fongsrisin,Porntep Amornritvanich,Cholatid Ratanatharathorn,Panu Looareesuwan", "background": "心脏衰竭（HF）研究受到隐私法规和机构障碍的限制，难以访问大规模可共享的数据集。生成合成数据为克服这些挑战提供了可能，同时保护患者隐私。本研究基于现有的12,552名患者的机构数据，使用五种深度学习模型生成合成HF数据集，旨在评估合成数据在统计相似性、生存预测和隐私评估方面的性能。", "innovation": "本研究使用了五种不同的深度学习模型（TVAE、正则流、ADSGAN、SurvivalGAN和TabDDPM）来生成心脏衰竭的合成数据集，其中SurvivalGAN和TabDDPM表现出高保真度。SurvivalGAN和TVAE在生存预测评估中表现出最强的性能，其C-指数与真实数据相当。此外，研究还证实了数据隐私保护功能的有效性，防止重新识别攻击。这些成果为心脏衰竭研究和预测建模提供了宝贵的资源。", "conclusion": "基于深度学习的合成数据生成可以生成高保真、隐私保护的心脏衰竭数据集，适用于研究应用。本研究公开发布的合成数据集解决了关键的数据共享障碍，为促进心脏衰竭研究和预测建模提供了有价值的资源。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04222", "html_url": "https://arxiv.org/abs/2509.04222", "title": "为何我看不到我的簇？基于精确度-召回率的降维验证方法", "title_en": "Why Can't I See My Clusters? A Precision-Recall Approach to Dimensionality Reduction Validation", "authors": "Diede P. M. van der Hoorn,Alessio Arleo,Fernando V. Paulovich", "background": "降维(DR)常用于可视化高维数据，目的在于揭示预期的簇结构。但是，在降维后的投影中，并非总是能观察到这样的结构。现有的DR质量评估方法评估投影的可靠性或簇结构的质量，但无法解释为什么预期的结构无法显现。可视化分析(CVA)解决方案可以有所帮助，但由于超参数空间庞大，这个过程往往耗时。本文便是为解决这一问题，采用了一个最新的框架，将DR过程分为两阶段：关系阶段，用于模拟相似关系；映射阶段，用于按照这些关系投影视图。我们引入了两种监督的评价指标，精确度和召回率，用于评估关系阶段。这些建立描述簇结构的标签集合，定量评价模拟关系与预期簇结构的匹配程度。该方法通过t-SNE和UMAP的实例阐释，并通过多种使用场景验证了此方法能够指导超参数调整、发现投影伪影，以及判断期望簇结构是否在关系中捕获，从而使得DR过程更加高效和可靠。", "innovation": "本文提出了一种基于精确度和召回率的监督方法，用于评估和优化降维过程中的关系建模阶段。这种方法能够在较短的时间内有效提供降维效果的反馈，并为超参数调整提供指导，使得降维过程更加高效和可靠。", "conclusion": "本文引入了一种新颖的精确度-召回率评价框架，能够在较短时间内验证降维结果的准确性。通过多种使用场景验证了该方法的有效性，并提供了更快速和可靠的降维过程指导。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04295", "html_url": "https://arxiv.org/abs/2509.04295", "title": "因果和统计数据集偏差对公平和稳健图像分析的一个入门", "title_en": "A Primer on Causal and Statistical Dataset Biases for Fair and Robust Image Analysis", "authors": "Charles Jones,Ben Glocker", "background": "机器学习方法在实际应用中经常失败，尤其是在高风险情境和社会敏感领域。这些失败影响了其在诸如医疗诊断等场景中的应用，尽管这些场景最有可能从安全部署中受益。本文引入了导致机器学习图像分析方法失效的因果和统计结构，重点讨论了两个新识别的问题：无公平午餐问题和子组可分性问题，解释了当前的公平表示学习方法为何未能充分解决问题，并提出了该领域的潜在前进方向。", "innovation": "本文识别并讨论了两个新问题，即无公平午餐问题和子组可分性问题，并解释了当前的公平表示学习方法为何未能充分解决问题，提出了潜在的前进方向来解决这些问题，从而促进机器学习在图像分析中的公平和稳健应用.", "conclusion": "当前的公平表示学习方法虽然不能充分解决问题，但为这一领域指出了可能的发展路径，以促进图像分析中机器学习的公平和稳健使用."}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04296", "html_url": "https://arxiv.org/abs/2509.04296", "title": "使用因果抽象加速复杂贝叶斯决策问题中的决策", "title_en": "Using causal abstractions to accelerate decision-making in complex bandit problems", "authors": "Joel Dyer,Nicholas Bishop,Anisoara Calinescu,Michael Wooldridge,Fabio Massimo Zennaro", "background": "尽管真实世界的决策问题常常可以被编码为不同程度抽象的因果多臂老虎机（CMABs），但缺少一种利用不同抽象层次信息和计算优势的通用方法。本文背景在于填补这一研究空白，关注在不同抽象层次的CMAB实例之间共享信息的有效利用。", "innovation": "本文提出的AT-UCB算法，有效利用了因果抽象理论（CA理论），在低成本模拟和粗粒度的CMAB实例中探索，然后在感兴趣的CMAB实例的潜在最优行动受限集中应用传统的上置信边界（UCB）算法，显著减小了累积遗憾（regret）量。此算法通过理论证明和使用变分辨率和计算成本的流行病学模拟器的实证研究，展示了其优越性。", "conclusion": "文章通过提出AT-UCB算法，展示了如何高效地利用基于因果抽象的信息和计算优势，并在不同的CMAB实例之间进行有效探索，从而减少决策过程中的遗憾。实验结果显示这种方法比传统的UCB算法在实际应用中更为优越。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04154", "html_url": "https://arxiv.org/abs/2509.04154", "title": "注意机制作为一种自适应滤波器", "title_en": "Attention as an Adaptive Filter", "authors": "Peter Racioppo", "background": "该研究介绍了一种新颖的注意力机制——自适应滤波器注意力（AFA），它直接将一个可学习的动力学模型引入注意力权重的计算中。传统注意力机制直接对比查询（queries）和键（keys），而AFA将输入序列视为线性随机微分方程（SDE）的离散观测值。通过引入同时对角化状态矩阵和噪声协方差的线性动力学模型，可以利用微分李雅普诺夫方程的闭形式解，高效地传播成对的不确定性。这种方法自然地使得注意力权重成为线性SDE的最大似然解，对应于传播的成对先验精度的鲁棒残差加权。进一步对状态矩阵的特征值施加额外约束，可以得到一个简化版本，其计算和内存复杂度与标准注意力机制相同。在动态和过程噪声消失的极限情况下，使用小角度近似，可以恢复普通的点积注意力机制。", "innovation": "该研究提出了自适应滤波器注意力（AFA），将线性随机微分方程（SDE）的动力学模型直接融入到注意力机制中，利用微分李雅普诺夫方程的闭形式解，实现成对不确定性在动力学中的高效传播，重新定义了注意力权重为线性SDE的最大似然解，且通过约束状态矩阵特征值得到了一个简化版本，保持了与标准注意力机制相同的时间和空间复杂度。同时，这一方法在没有动态和过程噪声的理想情况下可以退化为普通的点积注意力机制。", "conclusion": "研究提出了一种将动力学模型嵌入注意力机制的新方法，证明了这种方法不仅能提高注意力机制的表达能力，简化计算，同时保持了与传统机制相同的时间和空间复杂度，并且可以退化为普通的点积注意力机制。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04259", "html_url": "https://arxiv.org/abs/2509.04259", "title": "RL's Razor: 为什么在线强化学习遗忘较少", "title_en": "RL's Razor: Why Online Reinforcement Learning Forgets Less", "authors": "Idan Shenfeld,Jyothish Pari,Pulkit Agrawal", "background": "这篇论文探讨了强化学习（RL）和监督微调（SFT）在新任务中的表现差异。研究发现，尽管两种方法在新任务上的表现相似，但RL能够更好地保留先前的知识和能力。", "innovation": "研究揭示了在新任务的KL divergences上，细调和基础策略之间的KL散度可以衡量遗忘的程度。在线RL隐式偏向于KL最小化的解，而SFT可能会收敛到与基础模型差异极大的分布。还通过实验验证并提出了“RL的剃须刀”原理，即在解决新任务的所有方法中，RL更倾向于那些与原始模型最接近的KL解。", "conclusion": "在线RL更新导致较小的KL变化，表明其偏向于保留原始模型的能力，从而在新任务上对先前知识的遗忘较少。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04363", "html_url": "https://arxiv.org/abs/2509.04363", "title": "利用新颖的偏差-方差权衡避免不可处理的相关随机不确定性：三个实验比两个更好", "title_en": "When three experiments are better than two: Avoiding intractable correlated aleatoric uncertainty by leveraging a novel bias--variance tradeoff", "authors": "Paul Scherer,Andreas Kirsch,Jake P. Taylor-King", "background": "现实世界的实验场景通常存在非同质的随机不确定性，并且这种不确定性在批次设置中可以相关联。偏差-方差权衡可以表达出模型分布与真实随机变量之间预期均方误差的和，包括知识性不确定性项、偏差平方项和随机不确定性项。利用这一关系，提出了新的主动学习策略，处理有噪声和无噪声模型系统之间的偏差问题。", "innovation": "提出了利用偏差协方差关系的批处理方法，这一方法自然地提出了通过特征值分解策略进行批处理的机制。通过使用这种基于差异的方法，作者在批处理设置（带有二次估计器）中，优于BALD和最少不确定性等经典方法。", "conclusion": "在带有相关随机不确定性的实验设置中，利用偏差-方差权衡和偏差协方差关系的方法可提高主动学习策略的效果，尤其在批处理设置中表现出明显的优势。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04290", "html_url": "https://arxiv.org/abs/2509.04290", "title": "一种在差分隐私中寻找最优权衡的交互式框架", "title_en": "An Interactive Framework for Finding the Optimal Trade-off in Differential Privacy", "authors": "Yaohong Yang,Aki Rehn,Sammie Katt,Antti Honkela,Samuel Kaski", "background": "差分隐私（DP）是隐私保护分析的标准，它在隐私保障与模型性能之间引入了基本的权衡。选择最佳平衡是个重要的挑战，可以形式化为多目标优化（MOO）问题，首先发现最优权衡的集合（帕累托前沿），然后学习决策者对这些权衡的偏好。现有的交互式多目标优化的工作中，通常使用通用代理函数建模目标函数，并从简单的成对反馈中学习偏好，但对于DP来说，这种做法效率低下，因为它未能利用该问题的独特结构：帕累托前沿上的一个点可以通过固定隐私水平下的准确性最大化直接生成。", "innovation": "本文受此属性启发，首先理论上推导了权衡曲线的形状，从而可以直接且高效地建模帕累托前沿。为进一步提高偏好学习的效率，本文将成对比较替换为更有信息量的交互方式。具体而言，本文向用户展示假设的权衡曲线，并要求他们选择符合其偏好的权衡。在不同类型数据集上的实验证明，本文的方法以显著更低的计算成本和用户交互次数，收敛到最佳隐私-准确性权衡。", "conclusion": "本文提出了一种交互式框架，用于在差分隐私中寻找最优的隐私-准确性权衡。该框架首先理论推导了权衡曲线的形状，可以直接且高效地构建帕累托前沿。同时，通过提出更有信息量的交互方式，进一步提高了偏好学习的效率。实验结果表明，本文的方法在计算成本和用户交互方面显著优于基线方法，能够收敛到最优的隐私-准确性权衡。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04377", "html_url": "https://arxiv.org/abs/2509.04377", "title": "PagedEviction: 结构化块级 KV 缓存修剪策略以实现高效的大语言模型推理", "title_en": "PagedEviction: Structured Block-wise KV Cache Pruning for Efficient Large Language Model Inference", "authors": "Krishna Teja Chitty-Venkata,Jie Ye,Xian-He Sun,Anthony Kougkas,Murali Emani,Venkatram Vishwanath,Bogdan Nicolae", "background": "KV 缓存显著提高了大型语言模型 (LLM) 推理的效率，通过存储已处理令牌的注意力状态，使后续令牌的生成速度更快。然而，随着序列长度的增加，KV 缓存在成为主要内存瓶颈方面变得非常明显。", "innovation": "提出了一种新颖的细粒度、结构化 KV 缓存修剪策略 PagedEviction，该策略在 vLLM 的 PagedAttention 上增强了内存效率。PagedEviction 采用了一种高效块级淘汰算法，针对带有分页内存布局的页进行设计，不同于依赖于注意力权重的现有方法或在 vLLM 页之间移除令牌的方法。", "conclusion": "PagedEviction 在 Llama-3.1-8B-Instruct、Llama-3.2-1B-Instruct 和 Llama-3.2-3B-Instruct 模型上表现良好，展示了在长上下文任务中内存使用效率的提升和比基线更好的准确性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04398", "html_url": "https://arxiv.org/abs/2509.04398", "title": "IPA：一种高效基础模型适应性的信息保留输入投影框架", "title_en": "IPA: An Information-Preserving Input Projection Framework for Efficient Foundation Model Adaptation", "authors": "Yuan Yin,Shashanka Venkataramanan,Tuan-Hung Vu,Andrei Bursuc,Matthieu Cord", "background": "参数Efficient微调（PEFT）方法，例如LoRA，通过向预训练权重中注入低秩更新来降低适应成本。然而，LoRA的下投影随机初始化且数据无关，可能会抛弃有价值的信息。先前的分析表明，该投影在训练过程中变化不大，而上投影负责大部分的适应性，使得随机的输入压缩成为性能瓶颈。", "innovation": "本文提出了IPA，一种特征感知的投影框架，明确地保留了在减少的隐藏空间中的信息。在线性情况下，通过近似最大主成分的方法实现IPA，使得投影器的预训练高效且几乎无推理开销。实验结果显示，IPA在语言和视觉基准测试中优于LoRA和DoRA，在常识推理方面平均高出1.5个点，在VTAB-1k方面高出2.3个点，当投影冻结时，能够实现与全量LoRA相似的性能，同时只有约一半的可训练参数。", "conclusion": "通过引入IPA，本文旨在提供一种有效的PEFT方法，显著提高基础模型的适应性，特别是在信息保留方面表现出色，同时也降低了训练和推理的资源成本。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04322", "html_url": "https://arxiv.org/abs/2509.04322", "title": "非住宅建筑能源行为特征分析", "title_en": "Characteristic Energy Behavior Profiling of Non-Residential Buildings", "authors": "Haley Dozier,Althea Henslee", "background": "由于气候变化和极端天气事件的威胁，美国陆军的基础设施面临风险。为了确保支持关键任务的设施资产安全，并提高其应对能力，需要实施气候韧性措施。大多数位于美国本土的陆军基础设施依赖于商业能源供应，因此需要评估独立能源资源（如电力网络、天然气管道等）的脆弱性，并了解设施内的能耗情况。本文旨在提出一种数据驱动的行为模型，以确定设施用电行为模式，从而进行不预期中断下的能耗系统影响评估和未来韧性措施的基准对比。研究方法中，将通过多模式数据来模拟建筑行为，以准确分析、预测和聚类非住宅建筑能耗数据。由于分析陆军设施能耗数据的特殊性，研究使用了类似结构的开放数据来展示该方法。", "innovation": "利用数据驱动的方法提出行为模型确定设施用电行为模式，为评估不预期中断下的能耗系统影响和进行未来韧性措施的基准对比提供依据。研究中模拟非住宅建筑的多模式数据以准确分析、预测和聚类能耗数据，通过类似结构的开放数据来展示该方法。", "conclusion": "本文提出了一个基于数据驱动行为模型的方法来确定非住宅建筑的能耗行为特征，为其后的能耗系统的影响评估及未来韧性措施的基准对比提供了参考依据。研究成果有助于提高陆军设施的能源使用效率和气候韧性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04362", "html_url": "https://arxiv.org/abs/2509.04362", "title": "通过自监督学习增强的时空反转变换器融合多源数据进行泊车可用性预测", "title_en": "Parking Availability Prediction via Fusing Multi-Source Data with A Self-Supervised Learning Enhanced Spatio-Temporal Inverted Transformer", "authors": "Yin Huang,Yongqi Dong,Youhua Tang,Li Li", "background": "私人汽车拥有量的快速增长加剧了城市停车难题，强调了准确有效的泊车可用性预测对于支持城市规划和管理的必要性。现有模型在建模空间-时间依赖性和利用多源数据方面存在关键局限性。", "innovation": "本文提出了一种名为SST-iTransformer的新方法。该方法利用K-means聚类来建立泊车区域（PCZ），从各种运输模式（包括地铁、公共汽车、在线打车和出租车）获取并整合与目标泊车区域相关的交通需求特征。SST-iTransformer基于vanilla iTransformer进行了升级，集成自监督空洞重构预训练任务，并引入了一种创新的双支注意力机制：序列注意力通过窗口操作捕获长短期依赖性，而通道注意力通过维度倒置建模跨变量交互。实验证明，SST-iTransformer相对于基线深度学习模型（如Informer、Autoformer、Crossformer和iTransformer）具有优越性能，且在均方误差（MSE）方面达到最佳表现，在平均绝对误差（MAE）方面具有竞争力。此外，综合消融研究明确了不同数据源的重要性：整合在线打车数据提供了最大的性能提升，其次是出租车，而固定路线公共交通（公共汽车/地铁）的贡献较小。空间相关性分析进一步证实了排除PCZ内相关泊车位的过去数据对性能的负面影响，突显了建模空间依赖性的必要性。", "conclusion": "SST-iTransformer在实际数据集上取得了最先进的性能，证明了通过自我监督学习增强的时空反转变换器融合多源数据对泊车可用性预测的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04442", "html_url": "https://arxiv.org/abs/2509.04442", "title": "Delta Activations: 一种精调大型语言模型的表示方法", "title_en": "Delta Activations: A Representation for Finetuned Large Language Models", "authors": "Zhiqiu Xu,Amish Sethi,Mayur Naik,Ser-Nam Lim", "background": "强大的开源大型语言模型的成功使得社区能够创建大量的针对特定任务和领域的后训练模型。然而，由于元数据不一致和未结构化的存储库，导航和理解这些模型仍具有挑战性。", "innovation": "提出了一种名为Delta激活的方法，通过测量精调模型相对于基准模型在内部激活上的变化来表示精调模型。这种方法有助于按领域和任务有效聚类模型，揭示模型景观中的结构。此外，Delta激活表现出稳健性和可加性，并且可以通过少量的精调来嵌入任务，进一步探索其用于模型选择和合并的应用。", "conclusion": "希望Delta激活能够促进公共模型的重用实践。相关代码可访问[这里](this https URL)。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04394", "html_url": "https://arxiv.org/abs/2509.04394", "title": "过渡模型：重思生成学习目标", "title_en": "Transition Models: Rethinking the Generative Learning Objective", "authors": "Zidong Wang,Yiyuan Zhang,Xiaoyu Yue,Xiangyu Yue,Yangguang Li,Wanli Ouyang,Lei Bai", "background": "生成模型中存在着一个根本性的困境：迭代扩散模型能够实现出色的保真度，但代价是巨大的计算成本，而高效的少步替代方案则受限于质量上限。生成步骤和输出质量之间的冲突源自于严格的训练目标，这些目标仅专注于无穷小动力学（PF-ODEs）或直接终点预测，而非二者之间的结合。这两种方法分别存在优化动态过程与直接预测过程的局限性。由于训练目标的限制，无法在保证高质量输出的同时降低计算成本或减少步骤数。", "innovation": "本文提出了一种全新的生成模型，即过渡模型（TiM），该模型通过引入准确的连续时间动力学方程来理论上定义任意时间间隔内的状态转换，从而实现无缝的从单一跃迁到细化优化的生成路径。尽管参数量仅为865M，TiM在所有评价步长下都达到了最先进的性能，超越了SD3.5（8B参数）和FLUX.1（12B参数）等领先模型。与之前的少步生成器不同，TiM在采样预算增加时展示了持续的质量提升。同时，通过使用本研究的原分辨率策略，TiM在至高4096x4096的分辨率下提供出色的保真度表现。", "conclusion": "过渡模型（TiM）通过使用合适的训练目标和动力学方程，实现了有效的参数管理和高质量的生成效果。这种新的生成模型，能够在保证高质量输出的同时减少计算成本。最重要的是，与现有的模型相比，TiM展示了拉长采样预算时不变的质量改进趋势，并且在高分辨率下的表现优于之前的少步生成模型。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04415", "html_url": "https://arxiv.org/abs/2509.04415", "title": "在混合观测数据中具有自适应异质因果结构学习的可解释聚类", "title_en": "Interpretable Clustering with Adaptive Heterogeneous Causal Structure Learning in Mixed Observational Data", "authors": "Wenrui Li,Qinghao Zhang,Xiaowo Wang", "background": "在生物学和医学等领域，理解因果异质性对于科学研究至关重要。然而，现有方法缺乏因果意识，对异质性、混杂因素和观察限制的建模不足，导致解释性差，并且难以区分真实的因果异质性与伪相关。", "innovation": "我们提出了一个无监督框架HCL（具因果机制感知的聚类与自适应异质因果结构学习），可以在不需时间顺序、环境标签、干预或其他先验知识的情况下，联合推断潜在类别及其关联的因果结构。HCL通过引入等效表示放松同质性和充分性假设，编码结构异质性和混杂因素，并发展双向迭代策略交替优化因果聚类和结构学习。同时，该框架还引入了一种自我监督正则化，平衡跨集群的普遍性和特殊性，从而实现可解释、异质的因果模式的收敛。理论上，我们在温和条件下证明了异质因果结构的可识别性。实验上，HCL在聚类和结构学习任务中均表现出优越性能，并在真实的单细胞扰动数据中恢复了生物学上有意义的机制，展示了其在发现可解释的、机制水平的因果异质性上的应用价值。", "conclusion": "HCL框架通过联合聚类与因果结构学习，能够在混合型观测数据中发现可解释的、异质的因果模式，解决了现有方法在解释性和区分真实因果异质性上的不足。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04430", "html_url": "https://arxiv.org/abs/2509.04430", "title": "揭开表格式深度学习中数据不确定性的作用", "title_en": "Unveiling the Role of Data Uncertainty in Tabular Deep Learning", "authors": "Nikolay Kartashev,Ivan Rubachev,Artem Babenko", "background": "近期，表格式深度学习取得了显著的实用性能，但领域内对这些技术为何成功的原因往往缺乏清晰的理解。本研究强调了数据不确定性的概念对于解释近期表格式深度学习方法的有效性的重要性。研究表明，许多有助于表格式深度学习的设计选择（如数值特征嵌入、检索增强模型和高级集成策略）的成功可以归因于它们对管理高数据不确定性的隐式机制。通过对这些机制的剖析，我们提供了一种统一的理解，解释了近期性能改进的原因。", "innovation": "本研究通过强调数据不确定性的作用，揭示了许多有效设计选择背后的原因，并因此开发了更为有效的数值特征嵌入方法。研究提供了对现代表格式方法带来的好处的坚实理解，推动了现有技术的实际改进，并为表格式深度学习的未来研究指明了方向。", "conclusion": "通过解析数据不确定性机制，本研究为理解现代表格式方法带来的益处奠定了基础，从而促进现有技术的进步，并为未来研究指出了方向。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04449", "html_url": "https://arxiv.org/abs/2509.04449", "title": "ChronoGraph: 一个基于实际的图结构多元时间序列数据集", "title_en": "ChronoGraph: A Real-World Graph-Based Multivariate Time Series Dataset", "authors": "Adrian Catalin Lutu,Ioana Pintilie,Elena Burceanu,Andrei Manolache", "background": "该研究利用真实世界生产的微服务构建了一个图结构的多元时间序列预测数据集ChronoGraph。每个节点代表一个服务，并发出系统级别的性能指标流，包括CPU、内存和网络使用模式。有向边表示服务间的依赖关系。主要任务是预测这些信号在服务级别上的未来值。研究结合了实际事件标记的异常标签，使评估异常检测方法和评估在运营中断期间预测稳健性成为可能。与现有源自工业控制系统或交通和空气质量领域的基准相比，ChronoGraph独特地结合了：(i) 多元时间序列，(ii) 显式的、机器可读的依赖图，(iii) 联合实际事件的异常标签。", "innovation": "ChronoGraph创新地集成了多种特性：多元时间序列数据、显式的机器可读依赖图以及与实际情况匹配的异常标签，这使其成为研究结构感知预测以及事件感知评估的一个现实基准，特别是在微服务系统中。", "conclusion": "该研究报告了基线结果，涵盖预测模型、预训练的时间序列基础模型和标准异常检测器。ChronoGraph为研究结构感知预测和事件感知评估提供了一个现实基准，特别是在微服务系统中。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04445", "html_url": "https://arxiv.org/abs/2509.04445", "title": "朝着忠于认知决策模型以改善AI对齐", "title_en": "Towards Cognitively-Faithful Decision-Making Models to Improve AI Alignment", "authors": "Cyrus Cousins,Vijay Keswani,Vincent Conitzer,Hoda Heidari,Jana Schaich Borg,Walter Sinnott-Armstrong", "background": "近年来，AI研究趋势正转向融入以人类为中心的目标，明确目标是使AI模型与个人偏好和社会价值观相一致。通过标准的偏好获取方法，研究人员和实践者构建人类决策和判断的模型，并用这些模型来使AI行为与人类行为相一致。然而，此类偏好获取过程中常用到的模型往往未能捕捉到人类决策过程中的真实认知过程，如人们使用启发法简化与决策问题相关的信息。因此，基于人们决策学习的模型与其认知过程不一致，无法用来验证学习框架以推广到其他决策任务上。", "innovation": "本文采用公理化方法从成对比较中学习认知忠实的决策过程。基于描述人类决策过程中认知过程的大量文献，并结合近来在成对比较任务中刻画这些过程的研究工作，本文定义了一类模型，在此类模型中，个体特征首先在替代选项之间进行处理和比较，然后通过固定的规则（如Bradley-Terry规则）进行聚合。这种信息的结构化处理确保了此类模型是现实且可行的候选人，可以表示底层的人类决策过程。研究表明，此建模方法在学习肾分配任务中的人类决策模型方面是高效的，并证明了所提模型可匹配或超越以前的人类成对决策模型的精度。", "conclusion": "本文提出的方法成功地构建了能真实反映人类认知过程的决策模型，能够改善AI的对齐，这些模型通过处理和比较成对比较中的个体特征，然后使用固定的聚合规则，使得所得模型能够用于预测和理解人类决策，并提高AI行为与人类期望的匹配度。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04419", "html_url": "https://arxiv.org/abs/2509.04419", "title": "大型语言模型后训练统一视角", "title_en": "Towards a Unified View of Large Language Model Post-Training", "authors": "Xingtai Lv,Yuxin Zuo,Youbang Sun,Hongyi Liu,Yuntian Wei,Zhekai Chen,Lixuan He,Xuekai Zhu,Kaiyan Zhang,Bingning Wang,Ning Ding,Bowen Zhou", "background": "大规模语言模型的训练数据主要来源于在线和离线两类，通常分别用于强化学习（RL）和监督微调（SFT）。这些方法被认为是相互独立的。本文作者发现这两类方法实际上是同一优化过程的不同表现，进而提出了一种统一的策略梯度估计器，并探讨了基于不同数据分布假设和各种偏置方差权衡下的后训练方法在这些条件下的梯度计算方式。", "innovation": "作者证明了强化学习和监督微调不是相互排斥的，而是优化过程的不同方面，提出了一个统一的策略梯度估计器，并提出了一个称为Hybrid Post-Training（HPT）的算法，该算法可以根据具体情况动态选择训练信号，提高利用示范数据的有效性，并实现稳定探索，同时保留学习到的推理模式。作者通过广泛的实验和消融研究验证了统一理论框架和HPT的有效性。该方法在多个数学推理基准和出分布套件测试中表现出色，超越了不同规模和系列模型的强大基线。", "conclusion": "本文通过统一策略梯度估计器和Hybrid Post-Training算法实现了改进的后训练方法，这不仅验证了理论发现，也展示了在大规模语言模型后训练中的实际应用价值，并通过实验证明了HPT的有效性，在多个基准测试中均表现出优越性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03522", "html_url": "https://arxiv.org/abs/2509.03522", "title": "在临床环境中，少量数据可以发挥重要作用：过程持续时间预测", "title_en": "A Small Dataset May Go a Long Way: Process Duration Prediction in Clinical Settings", "authors": "Harald Störrle,Anastasia Hort", "background": "手术室的利用是医院的主要成本驱动因素之一。通过优化手术时间表来优化这个变量，可以显著降低成本并改善医疗结果。先前的研究提出了一些复杂的模型来预测手术持续时间，这些模型依赖于大量数据。", "innovation": "我们希望创建一种基于少量数据的有效且高效的模型来预测手术持续时间。我们的方法包括深入应用领域以利用专业人员的知识，结合因子分析和回归模型来预测围手术期过程的持续时间。我们发现简单的方法在性能上与文献中提出的复杂方法相当，甚至有时更胜一筹。我们将专家知识与数据分析相结合，以提高数据质量和模型表现，从而能够利用小数据集进行更准确的预测。", "conclusion": "通过将传统数据科学方法与临床环境和过程结构的定性研究相结合，我们获得了比以前的研究更佳的结果。因此，即使数据集较小，我们也能发挥其潜力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03533", "html_url": "https://arxiv.org/abs/2509.03533", "title": "通过信息瓶颈视角识别大语言模型输入输出pair中的主题", "title_en": "Topic Identification in LLM Input-Output Pairs through the Lens of Information Bottleneck", "authors": "Igor Halperin", "background": "大语言模型（LLMs）可能会出现关键的失败模式，如内在忠实幻觉（也称为编造），这种情况下，模型的响应在语义上会偏离提供的上下文。为了检测这种现象，现有框架依赖于识别提示和响应之间的潜在主题，这通常通过几何聚类它们的句子嵌入来完成。然而，这种方法存在一个缺陷，即潜在主题被优化为空间近邻，而不是下游的信息论分析。因此，本文通过开发一种基于信息瓶颈（DIB）原则的主题识别方法来解决这一问题，以连接两种方法间的差距。", "innovation": "本文的创新点在于它将DIB方法转化为一种用于高维数据的实际算法，通过用计算高效的上界替换掉无法计算的KL散度项，从而使得UDIB方法能够被应用于LLM提示和响应嵌入的聚类中。结果产生的方法（UDIB）可以被解释为一种加了熵正则化和强化版的K均值算法，能够倾向于形成少量的信息性聚类。这种方法能够为SDM框架提供一个更优越的基础，并提供了一种新型、更具敏感性的工具来检测编造。", "conclusion": "通过应用UDIB方法对LLM提示和响应嵌入进行共聚类，生成了一个不仅在空间上一致而且从根本上被结构化为关于提示-响应关系的最相关信息的主题表示。这为SDM框架提供了一个更优越的基础，并提供了一种新的、更敏感的工具来检测编造。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04422", "html_url": "https://arxiv.org/abs/2509.04422", "title": "Echo State Networks as State-Space Models: A Systems Perspective", "title_en": "Echo State Networks as State-Space Models: A Systems Perspective", "authors": "Pradeep Singh,Balasubramanian Raman", "background": "回声状态网络（ESNs）通常被视为高效、训练读出的递归模型，但其动态和设计常常受到启发式的指导，而非基于第一原理。本文重新将ESNs明确表示为状态空间模型（SSMs），提供了一个统一的系统理论解释，将基存计算与经典的模型识别和现代核化的状态空间模型相连接。背景强调了对ESNs进行系统理论分析的重要性，以更好地理解和设计这些模型。", "innovation": "主要创新之处在于提供了ESNs作为一种状态空间模型的统一系统理论解释，通过揭示回声状态属性为压缩非线性状态空间模型的输入到状态稳定性的一个实例，来验证这一定律。此外，开发了两种互补的映射：小型信号线性化映射和提升/科尔莫戈罗夫随机特征展开，后者将ESNs表示为增强状态下的线性状态空间模型，以便进行传递函数和卷积核分析。这些视角为理解ESNs的记忆频谱特征提供了频域表征，并明确了ESNs模仿结构状态空间核模型的条件。最后，将教师强制视为状态估计，并提出了带有观察学习的卡尔曼/EKF辅助以及超参数（泄漏、特征规格、过程/测量噪声）的EM方法和混合子空间程序下的谱形塑造方法，以遵循收缩约束。", "conclusion": "结论指出，采用系统理论视角和状态空间模型方法可以提供关于ESNs记忆频谱特征的频域表征，并澄清了ESNs模仿结构状态空间核模型的条件，还提出了一种教师强制作为一种状态估计的新方法，并结合卡尔曼/EKF辅助读出学习和EM方法用于超参数（泄漏、特征规格、过程/测量噪声）的学习，以及在收缩约束下的谱形塑造的混合子空间方法。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03528", "html_url": "https://arxiv.org/abs/2509.03528", "title": "The ProLiFIC 数据集：利用大语言模型揭示意大利立法过程", "title_en": "The ProLiFIC dataset: Leveraging LLMs to Unveil the Italian Lawmaking Process", "authors": "Matilde Contestabile,Chiara Ferrara,Alberto Giovannetti,Giovanni Parrillo,Andrea Vandin", "background": "过程挖掘（PM）最初是在工业和商业背景下开发的，近年来被应用到社会系统中，包括法律领域。然而，在法律领域的有效性受限于数据集的可访问性和质量。本文介绍了ProLiFIC（意大利议会立法流程），这是一个从1987年到2022年意大利立法过程的综合事件日志。该日志是由Normattiva门户的数据创建并使用大型语言模型（LLMs）进行结构化处理的。ProLiFIC与最近整合PM与大语言模型的努力相契合。", "innovation": "ProLiFIC通过利用大语言模型从非结构化数据中构建，提供了一个全面的意大利立法过程日志。这促进了过程挖掘（PM）在法律领域的应用，并为未来的开发提供了基准点。", "conclusion": "本文提供了一个初步分析，提出ProLiFIC作为过程挖掘在法律领域的一个基准数据集，以促进新发展。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03617", "html_url": "https://arxiv.org/abs/2509.03617", "title": "通过量子极端学习机进行系外行星大气的恢复", "title_en": "Exoplanetary atmospheres retrieval via a quantum extreme learning machine", "authors": "Marco Vetrano,Tiziano Zingales,G.Massimo Palma,Salvatore Lorenzo", "background": "传统上，研究系外行星大气依赖于前向模型，通过精细调整大量化学和物理参数来计算系外行星的光谱。然而，参数空间的高维度会导致显著的计算负担。", "innovation": "本研究引入了一种新颖的方法，结合量子极端学习机（QELM）来进行大气恢复。QELM是一种使用量子系统作为黑箱处理输入数据的量子机器学习技术。本研究提出了一种适用于近期内量子设备的固有容错框架，并直接在IBM Fez上进行了实现，展示了量子计算在天体物理数据集分析中的潜在价值，可能在未来解锁快速、高效且更准确的模型。", "conclusion": "QELM架构展示了量子计算在研究系外行星大气分析中的潜力，并且在未来有望提供新的计算工具，实现更快速、更高效和更准确的模型。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03647", "html_url": "https://arxiv.org/abs/2509.03647", "title": "打破镜子：基于激活的LLM评估器自我偏好缓解", "title_en": "Breaking the Mirror: Activation-Based Mitigation of Self-Preference in LLM Evaluators", "authors": "Dani Roytburg,Matthew Bozoukov,Matthew Nguyen,Jou Barzdukas,Simon Fu,Narmeen Oozeer", "background": "大型语言模型（LLMs）越来越多地担任自动评估者的角色，但它们存在“自我偏好偏见”的问题，这种倾向使其更倾向于自己的输出而不是其他模型的输出。这削弱了评估管道中的公平性和可靠性，尤其是在偏好调优和模型路由等任务中。研究人员调查了在推理时间通过使用轻量级的引导向量来缓解这一问题，而不重新训练模型。", "innovation": "研究引入了一个精心策划的数据集，区分了正当的自我偏好和不正当的自我偏好，并通过对比激活附加（CAA）和基于优化的方法构建了引导向量。结果表明，引导向量能够将不正当的自我偏好偏见降低多达97%，显著优于提示和直接偏好优化的基础模型。然而，引导向量不稳定，在正当的自我偏好和无偏见的一致性上表现不佳，这表明自我偏好可能涉及多个或非线性方向。", "conclusion": "引导向量的出现不仅展示了它们作为LLM评估器的保护手段的前景，同时也揭示了它们的局限性，并激励了更加稳健的干预手段来应对这一问题。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03539", "html_url": "https://arxiv.org/abs/2509.03539", "title": "多时间步精确变分公式通用于守门员和转换速率", "title_en": "An exact multiple-time-step variational formulation for the committor and the transition rate", "authors": "Chatipat Lorpaiboon,Jonathan Weare,Aaron R. Dinner", "background": "本文探讨了在两个稳定状态之间的转换过程中，守门员（即动态在某一稳定状态之前达到另一稳定状态的概率）及其转换速率的估计方法。现有的方法依赖于一个滞后时间来最小化一个过渡速率的表达式。研究发现，当滞后时间为一个时间步时，这种方法才能准确最小化守门员的表达式，但在实际应用中，滞后时间的选择导致了偏差估计。", "innovation": "作者提出了一种新的表达式，在任何滞后时间内都能准确最小化守门员，进而修正了现有的估计方法。通过基准系统的数值测试，证明新方法对滞后时间的选择更加不敏感。此外，作者还推导了一个新的转换速率表达式，并将其与基于均方残差的变分动力学统计方法进行了关联，讨论了进一步的数值考虑事项以及误差分解为动力模式的特点。", "conclusion": "该研究提出了一个新的守门员和转换速率的计算方法，在实际应用中提供了更高的准确性和可靠性，克服了滞后时间选择带来的偏差问题。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03531", "html_url": "https://arxiv.org/abs/2509.03531", "title": "长文本生成中实时检测虚构实体", "title_en": "Real-Time Detection of Hallucinated Entities in Long-Form Generation", "authors": "Oscar Obeso,Andy Arditi,Javier Ferrando,Joshua Freeman,Cameron Holmes,Neel Nanda", "background": "大型语言模型如今在高风险应用中被广泛应用，例如医疗咨询或法律建议，其中幻觉可能导致严重伤害。现有的幻觉检测方法在实际应用中并不实用，它们要么仅限于短的常识性查询，要么需要昂贵的外部验证。", "innovation": "本文提出了一种低成本、可扩展的方法，可以在生成长文本时实时识别幻觉标记，并在70B参数模型中有效地进行扩展。该方法专注于实体级幻觉，例如虚构的名字、日期、引用，从而自然映射到标记级别的标签，允许逐流检测。此外，开发了一种利用网络搜索进行标注的方法，标注模型响应以表明哪些标记对应于虚构实体。这种方法使得能使用简单且有效的线性探针来训练有效的幻觉分类器。在四个模型家族中，我们的分类器在长文本响应方面始终优于基线，包括更昂贵的方法如语义熵（例如AUC 0.90 vs 0.71对于Llama-3.3-70B），并且也在问答场景中有所改进。尽管只有使用实体级标签进行训练，我们的探针在数学推理任务中也能有效检测错误答案，表明其泛化能力。", "conclusion": "我们的研究提出了一个新方法，用于大规模、实用的幻觉检测，并向外界开源数据集以促进再利用。这表明，该方法具有检测长文本生成中幻觉的潜力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03537", "html_url": "https://arxiv.org/abs/2509.03537", "title": "AR$^2$: 广义对抗强化学习在大规模语言模型中的抽象推理", "title_en": "AR$^2$: Adversarial Reinforcement Learning for Abstract Reasoning in Large Language Models", "authors": "Cheng-Kai Yeh,Hsing-Wang Lee,Chung-Hung Kuo,Hen-Hsen Huang", "background": "抽象是识别并提取复杂问题中的核心计算模式的能力，在计算机科学中是一个基本技能。对于人类问题解决者和编程导向的大语言模型（LLMs），抽象的重要性不言而喻。尽管最近在使用强化学习（RL）训练LLMs生成代码方面取得了一些进展，但大多数现有方法主要关注表面模式识别，而非针对抽象能力进行明确训练。本研究在这一背景下进行，旨在解决这一问题，提出了AR$^2$（广义对抗强化学习）框架，专门设计以提高LLMs的抽象能力.", "innovation": "本研究提出了AR$^2$（广义对抗强化学习），是一种专门设计以增强LLMs抽象能力的新框架。该模型通过教师模型将核心问题转化为富有叙述性的复杂描述，而学生编程模型则通过提取这些叙述性问题的核心计算模式来解决问题。研究结果表明，AR$^2$显著提高了学生模型在面对未见过的复杂编程任务时的准确性，强调了抽象对于提升LLMs泛化能力的重要性.", "conclusion": "实验结果证明，AR$^2$显著提高了学生模型在处理之前未见过的复杂编程任务时的准确性，这表明抽象技能对于增强LLMs的泛化能力至关重要。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03661", "html_url": "https://arxiv.org/abs/2509.03661", "title": "ACT: 自动化约束目标调控在多目标推荐系统中的应用", "title_en": "ACT: Automated Constraint Targeting for Multi-Objective Recommender Systems", "authors": "Daryl Chang,Yi Wu,Jennifer She,Li Wei,Lukasz Heldt", "background": "推荐系统通常需要在最大化主要目标的同时，确保次要目标满足最低阈值，即“护栏”。这对于保持一致的用户体验和平台生态系统至关重要。然而，即使在系统更改不相关的条件下，执行这些护栏是一项挑战，通常需要手动调整超参数。", "innovation": "我们引入了自动化约束目标调控（ACT）框架，该框架能够自动找到满足这些约束条件所需的最小超参数更改集。ACT通过未偏见数据下的离线成对评估来寻求解决方案，并持续重新训练以适应系统和用户行为的变化。", "conclusion": "我们实证展示了其有效性，并描述了其在大规模生产环境中的部署情况。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03547", "html_url": "https://arxiv.org/abs/2509.03547", "title": "Combining feature-based approaches with graph neural networks and symbolic regression for synergistic performance and interpretability", "title_en": "Combining feature-based approaches with graph neural networks and symbolic regression for synergistic performance and interpretability", "authors": "Rogério Almeida Gouvêa,Pierre-Paul De Breuck,Tatiane Pretto,Gian-Marco Rignanese,Marcos José Leite dos Santos", "background": "机器学习在材料科学中的特征基础方法（feature-based models）能够提供化学透明性，便于理解预测背后的化学原理。然而，这类方法往往预测能力有限。另一方面，图神经网络（GNN）具有强大的预测能力，但在解释其内部机制方面存在困难。符号回归（symbolic regression）能够生成具有明确物理意义的公式，但其计算效率较低。", "innovation": "MatterVial 架构引入了一个创新性的混合框架，通过整合多种预训练的GNN模型（包括基于结构的 MEGNet、基于成分的ROOST以及不变的 ORB 网络），并结合高效计算、GNN逼近特征和符会回归生成的新型特征。这种结合不仅提升了预测性能，还保持了基于特征模型的化学透明性。该方法在改进 MODNet 的性能方面取得了显著成效，准确率提升超过40%，并且在某些情况下超越了最先进的端到端 GNN。同时，通过使用代理模型和符号回归，MatterVial 设计了一个集成的可解释性模块，使内部表示变得明确且物理意义强。", "conclusion": "MatterVial 架构提供了一种高性能且透明的工具，符合解释性AI的原则，推动了材料信息学的发展，为更具针对性和自主性的材料发现奠定了基础。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03636", "html_url": "https://arxiv.org/abs/2509.03636", "title": "因果ARC：基于因果世界模型的抽象推理", "title_en": "CausalARC: Abstract Reasoning with Causal World Models", "authors": "Jacqueline Maasch,John Kalantari,Kia Khezeli", "background": "推理需要在数据有限和分布变化的情况下适应新的问题设置。本文介绍了一种新的实验性测试平台CausalARC，用于小样本和新分布情况下的AI推理。CausalARC基于抽象和推理库（ARC）进行构建，每个推理任务都源自一个完全指定的因果世界模型，用结构因果模型正式表述。", "innovation": "CausalARC通过有原则的数据增强提供关于世界模型的观测、干预和反事实反馈，以少量的、上下文中的学习示范形式。本文提出使用CausalARC进行四种语言模型评估：（1）测试时训练的抽象推理；（2）上下文学习的反事实推理；（3）程序合成；（4）因果发现与逻辑推理。", "conclusion": "CausalARC提供了一个全新的框架来评估和改进在小样本和新分布情况下的AI推理能力。通过这种方式，可以旨在推动AI系统在真实世界的复杂、动态环境中的应用和性能提升。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03730", "html_url": "https://arxiv.org/abs/2509.03730", "title": "《LLM个性的幻象：揭示LLM自我报告与行为之间的分离》", "title_en": "The Personality Illusion: Revealing Dissociation Between Self-Reports & Behavior in LLMs", "authors": "Pengrui Han,Rafal Kocielnik,Peiyang Song,Ramit Debnath,Dean Mobbs,Anima Anandkumar,R. Michael Alvarez", "background": "人类个性特征已长期作为预测人类行为的指标进行研究。大型语言模型（LLMs）的进步表明，类似的人格模式可能在人工系统中显现，其中先进的LLM表现出与人类特质如亲和性和自我调节一致的行为倾向。尽管如此，早期研究主要依赖简化的自述报告和启发式提示，缺少行为验证。", "innovation": "本研究系统地阐述了LLM的人格特征，包括三个方面：(1) 在训练阶段中特性轮廓的动态涌现与演变；(2) 自述特质在行为任务中的预测有效性；(3) 目标干预，如个性注入，对自我报告和行为的影响。研究发现，通过指令对齐（例如RLHF、指令调优）显著稳定了特质表达并增强了特质间的关联，这与人类数据相似。然而，自述特质并不能可靠预测行为，观察到的关联常常偏离人类模式。虽然个性注入能有效指引自我报告的方向，但对实际行为的影响有限或不一致。", "conclusion": "我们的发现挑战了关于LLM个性的假设，并强调了在对齐和解释性方面进行更深入评估的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03658", "html_url": "https://arxiv.org/abs/2509.03658", "title": "Efficient Virtuoso: 一种用于目标条件轨迹规划的潜在扩散变换器模型", "title_en": "Efficient Virtuoso: A Latent Diffusion Transformer Model for Goal-Conditioned Trajectory Planning", "authors": "Antonio Guillen-Perez", "background": "生成多样化且可信的未来轨迹分布能力是自动驾驶车辆规划系统的关键能力。尽管最近的生成模型表现出希望，但实现高保真度、计算效率和精确控制依然是一项重大挑战。", "innovation": "本文提出了一种名为Efficient Virtuoso的条件潜在扩散模型，用于目标条件轨迹规划。该方法引入了一种新颖的两阶段归一化流水线，首先按几何方面缩放轨迹，然后归一化PCA潜在空间确保稳定的训练目标。去噪过程通过简单MLP去噪器在低维度潜在空间中高效进行，该去噪器由强大的Transformer基态编码器融合的丰富场景上下文条件化。", "conclusion": "我们的方法在Waymo Open Motion数据集上达到了最先进的性能，最小平均偏离误差（minADE）为0.25。此外，通过目标表示的严格细粒度消融研究，我们提供了一个关键见解：虽然单个端点目标可以解决战术性不确定性，但更丰富、多步骤稀疏路线对于实现媲美人驾驶行为的精确、高保真战术执行是必不可少的。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03551", "html_url": "https://arxiv.org/abs/2509.03551", "title": "使用机器学习预测食源性病原体弯曲杆菌的抗微生物耐药性和成本负担分析", "title_en": "Predicting Antimicrobial Resistance (AMR) in Campylobacter, a Foodborne Pathogen, and Cost Burden Analysis Using Machine Learning", "authors": "Shubham Mishra, TheAnh Han,Bruno Silvester Lopes,Shatha Ghareeb,Zia Ush Shamszaman", "background": "抗微生物耐药性（AMR）给公共卫生和经济带来了重大挑战，增加了医疗成本并降低了抗生素的有效性。本文利用机器学习技术分析英国公共卫生数据库中的基因组和流行病学数据，结合英国政府支持的食品安全局和苏格兰食品安全局的抗微生物耐药性监控数据，以研究2001年至2017年间从英国收集的弯曲杆菌孤菌和弯曲杆菌结肠菌的耐药模式。研究整合了全基因组测序（WGS）、流行病学元数据和经济预测，以确定关键的耐药决定因素，并预测未来的耐药趋势和医疗成本。", "innovation": "研究通过随机森林模型来预测抗微生物表型，准确率为74%，并通过SARIMA，SIR和Prophet时间序列预测模型预测到2050年可能会出现超过每10万人130例弯曲菌病病例，如果不加以控制，每年的经济负担将超过19亿英镑。此外，研究采用了增强的随机森林系统，使用6,683个分离株进行分析，通过整合时间模式、不确定性估计和耐药趋势建模来细化预测。", "conclusion": "该研究使用机器学习方法预测了食源性弯曲杆菌的耐药性和经济负担。预测分析表明，如果未能控制，抗微生物耐药性在未来二十年内对公共卫生和经济的影响将更为严重，特别是β-内酰胺类抗生素的持续高耐药率和氟喹诺酮类抗生素的增加耐药率。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03772", "html_url": "https://arxiv.org/abs/2509.03772", "title": "测试网络结构与高维节点协变量之间的相关性", "title_en": "Testing for correlation between network structure and high-dimensional node covariates", "authors": "Alexander Fuchs-Kreiss,Keith Levin", "background": "在许多应用领域中，网络观测时包含节点级别的特征。当存在这样的观测情况时，一个常见的问题是评估节点协变量是否与网络结构相关联。", "innovation": "本文提出了一种新颖的方法来解决这个问题。提出的方法包括两种基于线性模型将节点协变量与驱动网络结构的潜在节点变量联系起来的方法，以及两种基于将节点特征和网络结构应用于典型相关分析的方法，这种方法避免了线性建模假设。这些方法在理论上得到了验证，特别是在低秩潜在空间模型中加入了节点协变量时;且允许节点协变量为高维。", "conclusion": "本文提出的方法比之前的网络依赖性测试方法更便宜且需要更少的建模假设。在模拟数据和真实世界数据上展示了这些新颖方法的效果并进行了比较。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03622", "html_url": "https://arxiv.org/abs/2509.03622", "title": "使用多级迭代方法的准确且可扩展的深度Maxwell求解器", "title_en": "Accurate and scalable deep Maxwell solvers using multilevel iterative methods", "authors": "Chenkai Mao,Jonathan A. Fan", "background": "神经网络作为代理偏微分方程（PDE）求解器具有潜力，但现有方法难以实现高精度和可扩展性。本文探讨了将神经网络与迭代算法结合，以准确解决具有不同规模、分辨率和边界条件的PDE问题。研究表明，通过开发支持任意罗宾边界条件输入的子域神经算子模型，可以作为灵活预处理器解决具有限定精度的子域问题，进而为大规模PDE问题求解提供加速路径。利用二维麦克斯韦方程作为模型系统，训练单个网络以模拟不同大小、分辨率、波长和电介质分布下的大规模问题。并且展示了该平台在多波长纳米光子器件的准确逆设计中的应用前景。", "innovation": "开发了支持任意罗宾边界条件输入的子域神经算子模型，作为灵活预处理器解决具有限定精度的子域问题，可以加速大规模PDE问题求解。利用二维麦克斯韦方程训练单个网络，以模拟不同条件下的大规模问题，并展示了在多波长纳米光子器件中的应用价值。", "conclusion": "本文提出了一种有前景的方法，利用深层神经网络和多级迭代技术构建适用于大规模多物理场代理求解器，能够提高精度并实现大规模问题的高效求解。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03764", "html_url": "https://arxiv.org/abs/2509.03764", "title": "在Pinterest大规模网络搜索评估中的基于LLM的相关性评估", "title_en": "LLM-based Relevance Assessment for Web-Scale Search Evaluation at Pinterest", "authors": "Han Wang,Alex Whitworth,Pak Ming Cheung,Zhenjie Zhang,Krishna Kamath", "background": "个性化搜索系统中的相关性评估对于确保搜索结果与用户查询和意图相符至关重要。传统的相关性评估方法依赖于人类注释，但这种注释方法成本高、耗时长，限制了其可扩展性。", "innovation": "提出了一种基于细调的大语言模型(LLM)自动进行大规模在线实验的相关性评估方法，通过严格验证LLM生成的判断与人类注释的一致性，展示了LLM能够提供可靠的实验相关度评估，同时极大地提高了评估效率。利用基于LLM的标签进一步解锁了扩展查询集、优化采样设计以及大规模高效评估各种搜索体验的机会，从而提高了相关性度量的质量，显著降低了在线实验测量中的最小可检测效果(MDE)。", "conclusion": "这种基于LLM的方法提升了相关性度量的质量，并显著降低了在线实验测量中的最小可检测效果(MDE)。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03839", "html_url": "https://arxiv.org/abs/2509.03839", "title": "未知非线性动态系统的蓄水库预测路径积分控制", "title_en": "Reservoir Predictive Path Integral Control for Unknown Nonlinear Dynamics", "authors": "Daisuke Inoue,Tadayoshi Matsumori,Gouhei Tanaka,Yuji Ito", "background": "神经网络能够逼近复杂的非线性关系，在非线性动力系统的数据驱动控制中得到了广泛应用。然而，快速在线识别和控制未知动力学仍然是主要挑战。", "innovation": "该论文整合了蓄水库网络（ESNs）和模型预测路径积分（MPPI）控制，提出了蓄水库预测路径积分（RPPI），使非线性动力学的学习变得快速，无需线性化近似，并进一步扩展为不确定性感知的RPPI（URPPI），利用ESN的不确定性平衡探索和利用。", "conclusion": "实验证明，URPPI 在控制杜芬振子和四罐系统中提高了控制性能，与基于二次规划的传统模型预测控制方法相比，控制成本降低了多达60%。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03725", "html_url": "https://arxiv.org/abs/2509.03725", "title": "MLSD: 基于元学习的少量样本学习方法以增强跨目标和跨领域立场检测", "title_en": "MLSD: A Novel Few-Shot Learning Approach to Enhance Cross-Target and Cross-Domain Stance Detection", "authors": "Parush Gera,Tempestt Neal", "background": "当前，立场检测在不同领域和目标之间存在挑战，需要一种新的方法来改进立场检测性能。现有的方法通常在单一领域和目标上表现良好，但在跨领域和跨目标的场景下表现不佳。本文针对这一问题，提出了一种新的立场检测方法——基于度量学习的少量样本学习（MLSD）方法。该方法利用三元组损失的度量学习来捕捉不同立场目标之间的语义相似性和差异性，增强领域适应性。通过构建区分性嵌入空间，MLSD能够帮助跨目标或跨领域的立场检测模型从新目标领域中获取有用的例子，改善立场检测性能。该方法在两个数据集的多个跨目标和跨领域的场景中进行了评估，结果显示相比六个广泛使用的立场检测模型，MLSD在立场检测性能上有了显著的提升。", "innovation": "该研究提出了基于度量学习的少量样本学习方法（MLSD），该方法通过三元组损失来捕捉不同立场目标之间的语义相似性和差异性，从而增强跨领域和跨目标的立场检测性能。通过构建区分性嵌入空间，MLSD能够有效地从新目标领域中获取有用例子，提高立场检测的泛化能力。该方法适用于多种跨目标和跨领域的立场检测场景，展示了显著的性能提升。", "conclusion": "本文提出的MLSD方法在多个交叉目标和交叉领域立场检测场景中证明了其有效性和优越性，相较于现有的立场检测模型，MLSD方法在检测性能上有了显著的改进。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03769", "html_url": "https://arxiv.org/abs/2509.03769", "title": "数据驱动的动态系统建模中方程找寻方法的缺陷", "title_en": "Deficiency of equation-finding approach to data-driven modeling of dynamical systems", "authors": "Zheng-Meng Zhai,Valerio Lucarini,Ying-Cheng Lai", "background": "从数据中寻找支配方程的方法已经成为确定性建模动态系统的流行方法。然而，在数据可能因扰动和测量误差而不完美的物理情况下，对于许多混沌系统，广泛应用的稀疏优化方法在发现支配方程时显示出高度依赖于测量程序的特点，但这些模型产生的混沌吸引子几乎相同，这挑战了复杂动态系统基于方程的建模的传统观念。通过计算Koopman谱，研究发现不同的方程集在大特征值上达成一致，差异仅在当特征值小于方程依赖的阈值时开始显现。", "innovation": "研究通过比较从不同数据中发现的混沌系统方程的差异，揭示了稀疏优化方法在混沌系统建模中的显著局限性，强调直接使用可用数据的方法（如机器学习方法）可能更为有效.", "conclusion": "寻找系统方程并尝试物理解释它们可能会导致误导性的结论。与其寻找方程并尝试物理解释，不如直接使用可用数据，采用机器学习方法更为有用。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03726", "html_url": "https://arxiv.org/abs/2509.03726", "title": "Energy-Weighted Flow Matching: 解锁连续归一化流以实现高效和可扩展的玻尔兹曼采样", "title_en": "Energy-Weighted Flow Matching: Unlocking Continuous Normalizing Flows for Efficient and Scalable Boltzmann Sampling", "authors": "Niclas Dern,Lennart Redl,Sebastian Pfister,Marcel Kollovieh,David Lüdke,Stephan Günnemann", "background": "从未正规化的靶目标分布（例如玻尔兹曼分布 Î\text{target}(x) ∝ ←(-E(x)/T)）中进行抽样在许多科学应用中都是基础性的，但由于具有复杂性和高维能量景观，因此计算上具有挑战性。现有的将现代生成模型应用于玻尔兹曼分布的方法要么需要从目标分布中采样的大量样本数据集，要么在仅使用能量评估进行训练时，无法有效利用先进架构（如连续归一化流）中的表现力，这些架构已显示出对分子采样的前景。然而，这些现有方法存在局限性，无法同时提高样本质量和减少能量评价的数量。本研究旨在解决这些局限性。", "innovation": "我们提出了Energy-Weighted Flow Matching (EWFM)的新训练目标，该目标使连续归一化流能够在只评估能量函数的情况下对玻尔兹曼分布进行建模。我们开发了两种算法：迭代EWFM (iEWFM) 和退火EWFM (aEWFM)，分别通过迭代训练和温度退火进展性地细化提议分布。实验证明，这些算法在质量上与最先进的能量唯一方法相当，同时所需的能量评估数量最多可减少三个数量级。", "conclusion": "我们的方法有效地解决了玻尔兹曼采样的挑战，通过仅能量函数值的评估提高了样本质量和计算效率，为未来的科学研究提供了一种新的可能性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03780", "html_url": "https://arxiv.org/abs/2509.03780", "title": "自然潜在变量：不同语义下的潜在变量稳定", "title_en": "Natural Latents: Latent Variables Stable Across Ontologies", "authors": "John Wentworth,David Lorell", "background": "本文假设有两个贝叶斯代理人各自学习同一环境的生成模型。他们可能已经收敛于预测分布，但各自的生成模型中可能包含不同的隐藏变量。本研究探讨在什么条件下一个代理人的隐藏变量可以保证是另一个代理人的隐藏变量的函数。", "innovation": "通过给出自然潜在条件下的简单条件，研究保证了这种转换的可能，并证明在没有进一步约束的情况下，这些条件是最为一般的保证可转换性条件。此外，研究的定理对于实际应用来说是鲁棒的，即使自然潜在条件存在近似误差也是如此。", "conclusion": "给出的自然潜在条件是保证可转换性的最一般条件，并且在存在近似误差的情况下仍然是稳健的。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03932", "html_url": "https://arxiv.org/abs/2509.03932", "title": "韩语现代诗歌情感语言编码：基于人工标注数据集和人工智能建模的见解", "title_en": "Decoding the Poetic Language of Emotion in Korean Modern Poetry: Insights from a Human-Labeled Dataset and AI Modeling", "authors": "Iro Lim,Haein Ji,Byungjun Kim", "background": "尽管在基于文本的情感分类方面取得了显著进展，但诗歌尤其是韩语诗歌由于其比喻语言和文化特异性，仍然被严重忽视。现有的大规模语言模型在文本情感分类上取得了显著成果，但对诗歌情感分析的研究相对较少。", "innovation": "本研究引入了KPoEM（韩语诗歌情感映射）数据集，这是一个为现代韩语诗歌计算情感分析构建的新型数据集。研究团队构建了一个包含7662个条目的多标签情感数据集，包括来自483首诗的7007行级别条目和615个工作级别条目，并且这些条目被标注了来自五位有影响力的韩语诗人的情感类别。使用在该数据集上微调的最新韩语文本模型，在微调的F1分数上显著超过了此前使用通用语料库训练的模型，达到了0.60的F1-micro评分。通过逐步微调从通用语料库到KPoEM数据集的模型，展示了在识别时间和文化特定的情感表达以及保留现代韩语诗歌的核心情感方面的能力。", "conclusion": "本研究通过有序的数据集和人工智能模型训练，不仅填补了韩语诗歌情感分析的空白，还为定量探索诗歌情感提供了新的可能性，通过对数据集的结构化分析，忠实地保留了韩语文学的情感和文化内涵。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03898", "html_url": "https://arxiv.org/abs/2509.03898", "title": "扩散生成模型遇上了压缩感知，及其在图像数据和金融时间序列中的应用", "title_en": "Diffusion Generative Models Meet Compressed Sensing, with Applications to Image Data and Financial Time Series", "authors": "Zhengyi Guo,Jiatu Li,Wenpin Tang,David D. Yao", "background": "该论文在合成数据生成的背景下，开发了一种用于加速扩散模型推理的降维技术。研究融合了压缩感知与扩散模型，旨在提高模型训练和推理的效率。", "innovation": "提出了一种结合压缩感知与扩散模型的算法，具体步骤包括：将数据压缩至潜在空间，训练潜在空间中的扩散模型，并应用压缩感知算法处理潜在空间生成的样本。在合适的数据稀疏性假设下，该算法通过结合扩散模型推理与稀疏恢复实现了更快的收敛速度，并确定了潜在空间维度的最优值。", "conclusion": "通过数值实验对图像数据（手写数字、医疗影像和气候数据）以及金融时间序列进行了测试，验证了理论结果的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03910", "html_url": "https://arxiv.org/abs/2509.03910", "title": "正向和逆向问题的可逆生成模型", "title_en": "An invertible generative model for forward and inverse problems", "authors": "Tristan van Leeuwen,Christoph Brune,Marcello Carioni", "background": "本文通过贝叶斯框架提出了一个逆问题的公式化方法，并旨在训练一个生成模型，该模型能够模拟（即，从似然分布中采样）和推断（即，从后验分布中采样）。文中回顾了三角正则化流在这一背景下的使用情况，并展示了一种将这两个三角映射（上部和下部）组合为单个可逆映射的方法，该映射可用于模拟和推断。文中还详细阐述了这种可逆生成模型的多个有用属性，并提出了可能的训练损失以直接训练映射。文章通过几个简化的例子，通过数值方式说明了这种新方法在条件生成建模中的运作方式。", "innovation": "提出了将三角正则化流结合为一个单个可逆映射的方法，用于正向和逆向问题。详细说明了一个可逆生成模型的多个有用属性，并提出了一种直接训练该映射的可能损失函数。这种方法通过几个简化的例子展示了其在条件生成建模中的应用。", "conclusion": "本文通过一个可逆生成模型，有效地结合了模拟和推断的功能，并通过数值实验验证了该模型的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03899", "html_url": "https://arxiv.org/abs/2509.03899", "title": "基于场景的方法对离散时间控制障碍函数的高效认证", "title_en": "Sample Efficient Certification of Discrete-Time Control Barrier Functions", "authors": "Sampath Kumar Mulagaleti,Andrea Del Prete", "background": "Control Invariant (CI) 集合在确保动力学系统的安全性方面至关重要。Control Barrier Functions (CBFs) 是有效计算这些集合的工具，因为 CBFs 的零子水平集就是 CI 集合。然而，计算 CBFs 通常涉及到处理一个复杂的鲁棒优化问题，这往往是不可解的。为了简化这一计算，已有场景基础的方法被提出。但需要验证 CBF 是否确实满足鲁棒约束。本研究提出了一个依赖于Lipschitz性质的方法来执行这一验证，并据此设计了一种基于样本效率的认证算法。通过数值示例，证实了这种方法的有效性。", "innovation": "提出了一种依靠Lipschitz性质的方法来验证CBFs是否满足鲁棒约束条件，并设计了一种样本效率认证算法作为基础。通过这种方法和算法，解决了计算CBFs过程中常见的鲁棒优化问题，并提高了验证程序的效率.", "conclusion": "通过数值示例验证了该程序的效率，并展示了这种方法在离散时间系统中进行CBFs高效认证中的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03846", "html_url": "https://arxiv.org/abs/2509.03846", "title": "硬件感知的AI任务数据和指令映射：平衡并行性、I/O和内存权衡", "title_en": "Hardware-Aware Data and Instruction Mapping for AI Tasks: Balancing Parallelism, I/O and Memory Tradeoffs", "authors": "Md Rownak Hossain Chowdhury,Mostafizur Rahman", "background": "本文介绍了一种深度学习推断的映射框架，利用可预测的神经网络行为来提前规划计算和通信。框架生成了一个统一的指令和数据流，使硬件能够在无需频繁参与主机和减少外部内存使用的情况下自行执行操作并处理信息，自然地减少了对外部I/O、外部内存和主机控制的依赖。", "innovation": "该框架通过利用可编程的消息架构上的精细消息传递，并使用站定权重重用、阵列内部多播和分阶段归约等技术，保持数据的局部移动并协调计算。应用于VGG-19，该框架保持了高利用率（88%到92%），超过97%的消息在内部生成，几乎89%的时间在芯片内部传输完成。在大型阵列上，计算吞吐量超过1 TFLOP/s，重用和局部聚合带来的流量减少达到每层100 MB。", "conclusion": "结果显示了基于流计算的有效性，并展示了我们通过紧密协调硬件上的数据和指令流是如何使这一执行风格成为可能的。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03734", "html_url": "https://arxiv.org/abs/2509.03734", "title": "假设选择：高概率难题", "title_en": "Hypothesis Selection: A High Probability Conundrum", "authors": "Anders Aamand,Maryam Aliakbarpour,Justin Y. Chen,Sandeep Silwal", "background": "本文探讨了假设选择问题，给定有限的候选分布集$\\mathcal{H} = \\{H_1, \\ldots, H_n\\}$以及未知分布$P$的样本，目标是找到一个假设$H_i$，使得它与$P$的总变异性距离接近于离$P$最近的假设的距离。最优距离为$\\mathsf{OPT}$，算法的目标是在至少$1-\\delta$的概率下，输出的假设与$P$的总变异性距离不超过$C \\cdot \\mathsf{OPT} + \\varepsilon$。尽管该问题已有几十年的研究，但仍然存在关键问题，如达到最优样本复杂度和最好近似因子$C=3$的最优运行时间尚未明确。前人的方法虽然提供了近乎线性时间的算法，但依赖性不理想，运行时间为$\\tilde{O}(n/(\\\boldsymbol{\\delta^3}\\\boldsymbol{\\varepsilon^3}))$。本文将这一时间复杂度改进为$\\tilde{O}(n/(\\\boldsymbol{\\delta}\\\boldsymbol{\\varepsilon^2}))$，大幅降低了对置信度和误差参数的依赖性。此外，本文还研究了三种替代场景，解决或推进了先前工作的多个开放问题。具体包括：1)考虑输出假设的期望距离而不是其高概率性能时的最佳逼近因子；2)假设$\\mathsf{OPT}$的数值已知时的算法；3)在观察样本前允许多项式预处理假设类别$\\mathcal{H}$后的算法，实现$C=3$和亚二次运行时间。", "innovation": "本文提出了改进的时间复杂度算法，将原有$\\tilde{O}(n/(\\\boldsymbol{\\delta^3}\\\boldsymbol{\\varepsilon^3}))$的时间复杂度优化为$\\tilde{O}(n/(\\\boldsymbol{\\delta}\\\boldsymbol{\\varepsilon^2}))$。此外，作者还研究了三种不同的设置，在每个设置中都作出了改进或解决了一系列之前的研究问题。首先，解决了输出假设的期望距离的最优逼近因子；其次，提出了已知$\\mathsf{OPT}$值的算法并达到了最优的样本复杂度和高效运行时间；最后，在允许假设类预处理的情况下，提出了具有亚二次运行时间的算法。", "conclusion": "本文通过改进的时间复杂度和对三种不同设置的研究，为假设选择问题提供了更优的解决方案，特别是在预处理、已知$\\mathsf{OPT}$值以及期望距离的最优逼近因子方面取得了进展。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04063", "html_url": "https://arxiv.org/abs/2509.04063", "title": "平衡信号与方差：VLA流模型的自适应离线RL后训练", "title_en": "Balancing Signal and Variance: Adaptive Offline RL Post-Training for VLA Flow Models", "authors": "Hongyin Zhang,Shiyuan Zhang,Junxi Jin,Qixin Zeng,Yifan Qiao,Hongchao Lu,Donglin Wang", "background": "基于流匹配的视觉-语言-行动（VLA）模型在通用机械手操作任务中表现出色。然而，对于复杂下游任务，这些模型的动作精度不令人满意。主要原因是这些模型仅仅依赖于摹仿学习的后训练范式，使得很难深入理解数据质量分布的特性，而这正是强化学习（RL）所擅长的。", "innovation": "本研究理论上提出了一种离线RL后训练目标用于VLA流模型，并设计了一种高效且可行的离线RL微调算法——自适应强化流匹配（ARFM）。通过在VLA流模型损失中引入自适应调整的标度因子，构建了一个理论上有据可依的偏差-方差权衡目标函数，以最佳控制RL信号对流损失的影响。ARFM适应性平衡了RL优势保留和流损失梯度方差控制，从而实现更为稳定和高效的微调过程。", "conclusion": "广泛的模拟和现实世界的实验结果表明，ARFM在泛化、鲁棒性、少量样本学习和持续学习性能方面表现出色。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03972", "html_url": "https://arxiv.org/abs/2509.03972", "title": "通过韩语案例研究在开源LLM中扩展基础语言能力", "title_en": "Expanding Foundational Language Capabilities in Open-Source LLMs through a Korean Case Study", "authors": "Junghwan Lim,Gangwon Jo,Sungmin Lee,Jiyoung Park,Dongseok Kim,Jihwan Kim,Junhyeok Lee,Wai Ting Cheung,Dahye Choi,Kibong Choi,Jaeyeon Huh,Beomgyu Kim,Jangwoong Kim,Taehyun Kim,Haesol Lee,Jeesoo Lee,Dongpin Oh,Changseok Song,Daewon Suh", "background": "本文介绍了Llama-3-Motif，这是一个拥有102亿参数的语言模型，旨在增强韩语文本处理能力，同时保持在英语上的强大表现。Llama-3-Motif基于Llama 3架构构建，通过使用先进的训练技术如LlamaPro和Masked Structure Growth，在保持核心Transformer架构不变的情况下，有效地扩大了模型规模。该模型使用MoAI平台进行高效训练，并通过精心挑选的数据集来优化性能，该数据集保持了韩语和英语数据的平衡比例。Llama-3-Motif在特定的韩语基准测试中表现良好，超过了现有模型，并达到了与GPT-4相当的性能水平。", "innovation": "该研究的创新之处在于Llama-3-Motif的架构。它基于Llama 3架构，使用了LlamaPro和Masked Structure Growth等先进的训练技术，有效扩大了模型规模而不改变核心Transformer架构。同时，通过使用MoAI平台和精心挑选的数据集，进一步优化了模型的性能。特别地，Llama-3-Motif在向开源语言模型中加入韩语处理能力方面取得了进展，并在特定的韩语基准测试中表现出色。", "conclusion": "Llama-3-Motif在韩语处理能力方面有了显著提升，同时也保持了在英语上的强大表现。其模型规模扩大和优化技术的有效性在韩语特定基准测试中的卓越表现证明了其价值和实用性，为开源语言模型的研发提供了新的思路和发展方向。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03816", "html_url": "https://arxiv.org/abs/2509.03816", "title": "通过调整AI基础模型开发亚网格尺度参数化：大气重力波案例研究", "title_en": "Finetuning AI Foundation Models to Develop Subgrid-Scale Parameterizations: A Case Study on Atmospheric Gravity Waves", "authors": "Aman Gupta,Aditi Sheshadri,Sujit Roy,Johannes Schmude,Vishal Gaur,Wei Ji Leong,Manil Maskey,Rahul Ramachandran", "background": "全球气候模型参数化了诸如重力波、云、湿对流和湍流等大气-海洋过程，无法充分解决。这些未解决过程的亚网格尺度关闭是模型不确定性的主要来源。在气候研究中，AI基础模型（FMs）尚未充分探索。本文通过微调一个预训练的23亿参数AI基础模型（NASA和IBM Research的Prithvi WxC）来解决这一问题，该模型包含大气演变的潜在概率表示。通过使用大气重分析（分辨率为气候模型的十分之一）中学习到的通量，一个新的深度学习参数化方法被建立起来，专门用于大气重力波。通过与基于注意力的U-Net模型的基线比较，证明了该方法的优越预测性能，在大气各区域均表现良好，即使在没有预训练的区域也如此。通过Hellinger距离量化的性能提升显示出微调模型的显著优势，使FMs显示出了在大气和气候应用中的多功能性和可重用性，为多个地球系统过程提供了观察驱动和物理准确的参数化方法取得了进展。", "innovation": "提出了一种新的利用微调AI基础模型（FMs）来开发大气重力波亚网格尺度参数化的方法。该方法利用了一个预训练的23亿参数基础模型（Prithvi WxC），通过学习高分辨率大气重分析通量数据来建立参数化方法，实现了在低分辨率气候模型中捕捉重力波效应的效果，相较于基于注意力的U-Net模型表现出更优越的预测性能。方法验证了FMs在大气和气候研究应用中的多功能性和可重用性，为多个地球系统过程提供了新的参数化方法。", "conclusion": "研究表明，通过微调AI基础模型，可以在未解决的亚网格尺度大气过程中实现更准确的参数化，特别适用于大气重力波的建模。该方法不仅提高了预测性能，还强调了FMs在气候科学研究中的重要性和应用前景，为未来开发其他地球系统过程的物理准确参数化提供了新的思路。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04032", "html_url": "https://arxiv.org/abs/2509.04032", "title": "如果用另一种语言提问？跨语言的功能相似性衡量", "title_en": "What if I ask in \\textit{alia lingua}? Measuring Functional Similarity Across Languages", "authors": "Debangan Mishra,Arihant Rastogi,Agyeya Negi,Shashwat Goel,Ponnurangam Kumaraguru", "background": "近期，研究人员开始关注语言模型在不同语言之间的相似性。该研究利用一种最近提出的模型相似性度量 $\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{�_k}}}}}}}}}}}}}})}}$，在GlobalMMLU数据集中对20种语言和47个主题进行分析，旨在探讨模型输出在不同语言间的相似性。", "innovation": "该研究使用了最新的模型相似性度量 $\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{�_k}}}}}}}}}}}}}})}}$ 对20种语言和47个主题进行分析，发现了随着模型规模和能力的增长，模型回应的一致性在不同语言中逐渐提高。此外，模型在自我一致性方面表现出比与其他模型在同一种语言中的共识更大的一致性。", "conclusion": "该研究不仅强调了 $\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{�_k}}}}}}}}}}}}}})}}$ 作为评估多语言一致性的实用工具的价值，还表明其有潜力指导更一致的多语言系统的开发。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03889", "html_url": "https://arxiv.org/abs/2509.03889", "title": "基于置信感知密集对应和视触知觉可行性的空中服装操作", "title_en": "Reactive In-Air Clothing Manipulation with Confidence-Aware Dense Correspondence and Visuotactile Affordance", "authors": "Neha Sunil,Megha Tippur,Arnau Saumell,Edward Adelson,Alberto Rodriguez", "background": "处理服装操作具有挑战性，因为服装具有复杂的构型、材料动态多样且经常自遮挡。之前的系统往往会压平衣物，或假设关键特征的可见性。本文提出了一种结合置信感知密集视觉对应和触觉监督抓取可行性的双臂视触知觉框架，能够直接操作折叠和悬挂的衣物。", "innovation": "该框架通过使用包含布料对称性的分布损失来训练置信感知的密集视觉对应模型，生成对应置信度估计，并指导感知不确定性下的反应状态机，以调整折纸策略。同时，通过高分辨率触觉反馈自监督，一个视触知觉抓取可行性的网络确定哪些区域是物理上可抓取的。该触觉分类器也在执行过程中用于实时抓取验证。该系统通过在低置信度状态下推迟行动，能够处理高度遮挡的桌面和空中配置。此外，作者展示了任务无关的抓取选择模块在折叠和悬挂任务中的应用。通过密集描述符提供了其他规划模态的可复用中间表示，例如从人类视频演示中提取抓取目标，从而为更通用和可扩展的服装操作铺平道路。", "conclusion": "本文提出了一个双臂视触知觉框架，能够直接操作折叠和悬挂的衣物，通过置信感知的密集视觉对应和触觉监督抓取可行性的网络，以及一个在任务中无关的抓取选择模块，展示了在折叠和悬挂任务中的应用，为更通用和可扩展的服装操作提供了可能。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03992", "html_url": "https://arxiv.org/abs/2509.03992", "title": "Divergence-Kernel方法及其应用", "title_en": "Divergence-Kernel method for linear responses and diffusion models", "authors": "Angxiu Ni", "background": "本文研究了随机动力系统的线性响应（参数偏导的边缘分布或稳态分布），推导了发散核公式，并将其形式上过渡到连续时间限制。这种方法适用于任意时间段的乘法参数噪声，无需假定系统具有超稳定性。基于此方法，提出了一个仅向前扩散生成模型，并经过简单问题的测试验证效果。", "innovation": "提出了发散核公式以描述随机动力系统的线性响应；发展了一种路径智慧的蒙特卡洛算法来计算线性响应；基于发散核方法，提出了仅向前扩散的生成模型，适用于任意时间段的乘法噪声和无须系统超稳定性假设。", "conclusion": "本文提出的发散核方法和路径智慧的蒙特卡洛算法在计算随机动力系统的线性响应方面表现优异，并利用提出的仅向前扩散生成模型验证了方法的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03939", "html_url": "https://arxiv.org/abs/2509.03939", "title": "LMAE4Eth：通过探索交易语义和掩码图嵌入实现可推广且鲁棒的以太坊欺诈检测", "title_en": "LMAE4Eth: Generalizable and Robust Ethereum Fraud Detection by Exploring Transaction Semantics and Masked Graph Embedding", "authors": "Yifan Jia,Yanbin Wang,Jianguo Sun,Ye Tian,Peng Qian", "background": "当前的以太坊欺诈检测方法依赖于无上下文、数值化的交易序列，未能捕捉到账户交易的语义信息。此外，以太坊交易记录中的普遍同质性使得难以学习区分性强的账户嵌入。现有的半监督图学习方法主要通过图重建学习节点表示，这在节点级别的任务（如欺诈账户检测）上效果欠佳，并且这些方法也在可扩展性方面存在挑战。", "innovation": "本文提出了一种多视图学习框架LMAE4Eth，将交易语义、掩码图嵌入和专家知识结合在一起。首先提出了一种交易标记对比语言模型（TxCLM），将无上下文的数值化交易记录转换为逻辑一致的语言表示。然后提出了一种基于生成式的半监督学习的掩码账户图自编码器（MAGAE），通过重构账户节点特征实现优越的节点级账户检测。为了使MAGAE能够扩展到大规模训练，提出了将层邻居采样整合进图中，从而在基本不影响训练质量的情况下减少了采样顶点的数量。最后，通过交叉注意力融合网络统一了TxCLM和MAGAE的嵌入，充分利用两者的优点。本方法在三个数据集上与21种基线方法进行了评估，实验结果显示，本方法在两个数据集上的准确性（F1分数）均比最佳基线高出10%以上.", "conclusion": "实验结果表明，本文提出的方法在两个数据集上比最好的基线方法高10%以上的F1分数。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03986", "html_url": "https://arxiv.org/abs/2509.03986", "title": "Promptception：大型多模态模型在指令下的敏感性研究", "title_en": "Promptception: How Sensitive Are Large Multimodal Models to Prompts?", "authors": "Mohamed Insaf Ismithdeen,Muhammad Uzair Khattak,Salman Khan", "background": "尽管近年来大规模多模态模型在多个领域取得了成功，但多选择题回答（MCQA）任务中对这些模型的指令设计仍不被完全理解。即使是小的指令措辞和结构的变化也可能导致高达15%的准确率偏差。这种变化性给透明和公正的模型评估带来了挑战，因为模型通常会使用精心选择的指令来报告其最佳表现。", "innovation": "提出了Promptception，这是一种系统性框架，旨在评估指令对大型多模态模型的影响。该框架包括61种指令类型，涵盖了15个类别和6个大类别，每种类型都针对指令制定的特定方面，并用于评估10种不同类型的大型多模态模型，包括从开源模型到GPT-4o和Gemini 1.5 Pro。研究发现，专有模型对指令措辞更加敏感，反映了与指示语义的紧密匹配，而开源模型则表现得较为稳定但难以处理复杂的措辞。基于这些分析，提出了专有和开源大型多模态模型的指令原则，以促进更健壮和公正的模型评估。", "conclusion": "我们的研究揭示了不同的模型对指令的敏感度不同，这反映了它们的构建方式和设计目标的差异。我们提出的Promptception框架和指令原则可以帮助评估者和模型开发者更好地理解模型的行为，从而实现更公平的模型评估。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04210", "html_url": "https://arxiv.org/abs/2509.04210", "title": "COBRA: 通过腕戴传感器多模态感知深度学习框架实现远程慢性肥胖管理", "title_en": "COBRA: Multimodal Sensing Deep Learning Framework for Remote Chronic Obesity Management via Wrist-Worn Activity Monitoring", "authors": "Zhengyang Shen(1),Bo Gao(1),Mayue Shi(1, 2) ((1) Department of Electrical and Electronic Engineering, Imperial College London, UK, (2) Institute of Biomedical Engineering, University of Oxford, UK)", "background": "慢性肥胖管理需要持续监测能量平衡行为，而传统的自我报告方法存在显著的低估和回忆偏差问题，并且难以与现代数字健康系统整合。", "innovation": "COBRA是一个创新的深度学习框架，用于使用腕带多模态传感器进行客观行为监控。它采用了一种结合U-Net空间建模、多头自注意力机制和双向LSTM时间处理的混合D-Net架构，能够将日常活动分类为四个与肥胖相关的类别：食物摄入、体力活动、久坐行为和日常生活。COBRA在WISDM-Smart数据集上进行了验证，该数据集包含51名受试者进行18种活动。结果表明，COBRA的整体准确率为96.86%，各类别的F1分数分别为：体力活动98.55%、食物摄入95.53%、久坐行为94.63%、日常生活98.68%，在准确率上超越了最先进的基线系统。", "conclusion": "该框架展示了良好的泛化能力，人群差异性低（<3%），能够为个性化肥胖干预和持续生活方式监测提供广泛部署的基础。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04047", "html_url": "https://arxiv.org/abs/2509.04047", "title": "TensoIS: 前馈张量逆散射方法，用于珀林分布的复杂介质", "title_en": "TensoIS: A Step Towards Feed-Forward Tensorial Inverse Subsurface Scattering for Perlin Distributed Heterogeneous Media", "authors": "Ashish Tiwari,Satyam Bhardwaj,Yash Bachwana,Parag Sarvoday Sahu,T.M.Feroz Ali,Bhargava Chintalapati,Shanmuganathan Raman", "background": "从图像估计非均匀介质的散射参数是一个严重欠定且具有挑战性的问题。现有方法主要通过合成分析法逼近复杂的路径积分，或者使用可微体渲染技术来考虑不均匀性。然而，仅仅少数研究将基于学习的方法应用于估计穿透散射参数，但它们假定均匀介质。已知的具体分布无法明确描述实际世界中的不均匀散射参数。过程性噪声模型，如珀林和分形珀林噪声，已被证明有效代表自然、有机和无机表面的细微不均匀性。", "innovation": "该研究引入了HeteroSynth，这是一种包含使用分形珀林噪声建模的非均匀散射参数的真实感图像合成数据集。提出了TensoIS，一种基于学习的前馈框架，用于从稀疏多视角图像观察中估计这些分形珀林分布的非均匀散射参数。与直接预测3D散射参数体相比，TensoIS利用可学习的低秩张量分量表示散射体。该研究还评估了TensoIS在HeteroSynth测试集上看不见的非均匀变化以及来自开源真实体积模拟的烟和云几何形状，以及一些现实世界样本上，以证明其在逆散射中的有效性。这项研究旨在探索珀林噪声分布，考虑到文献中缺乏这类明确分布的可能性，以潜在地以前馈方式建模实际世界的非均匀散射。", "conclusion": "整体而言，这项研究尝试利用分形珀林噪声分布来建模实际世界的非均匀散射参数，甚至在缺乏明确定义的分布时也能以前馈方式实现。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04191", "html_url": "https://arxiv.org/abs/2509.04191", "title": "KubeGuard：通过配置文件和运行时日志分析进行基于大语言模型的Kubernetes加固", "title_en": "KubeGuard: LLM-Assisted Kubernetes Hardening via Configuration Files and Runtime Logs Analysis", "authors": "Omri Sgan Cohen,Ehud Malul,Yair Meidan,Dudu Mimran,Yuval Elovici,Asaf Shabtai", "background": "随着Kubernetes (K8s) 广泛应用于编排云原生应用，带来了重大的安全挑战，如资源配置不当和过度宽松的配置。未能解决这些问题可能导致未授权访问、权限提升和在集群内的横向移动。现有的K8s安全解决方案大多集中在检测配置错误上，通常通过静态分析或异常检测。与此相反，本文提出KubeGuard，这是一种新颖的运行时日志驱动的推荐框架，通过修正过度宽松的配置来缓解风险。", "innovation": "KubeGuard 通过两个互补的任务来强化 K8s 环境：资源创建和资源完善。它利用大型语言模型 (LLM) 来分析描述实际系统行为的清单和运行时日志，采用模块化的提示链流程。此方法使得KubeGuard能够为新资源创建最小权限配置，并改进现有清单以减少攻击面。KubeGuard 的输出清单作为推荐，用户可以查阅并采纳以增强集群安全。", "conclusion": "我们的评估表明，KubeGuard 有效生成和改进了 K8s 表现形式的角色、网络策略和部署，利用了具有专有和开源的 LLM。高精度、召回率和 F1 分数证明了 KubeGuard 作为将运行时可观测性转化为实用、最小权限配置指导框架的实际可行性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04193", "html_url": "https://arxiv.org/abs/2509.04193", "title": "DUDE: 基于扩散的无监督跨域图像检索", "title_en": "DUDE: Diffusion-Based Unsupervised Cross-Domain Image Retrieval", "authors": "Ruohong Yang,Peng Hu,Yunfan Li,Xi Peng", "background": "无监督跨域图像检索（UCIR）旨在跨越多个不同领域检索同一类别图像，而无需依赖标注信息。现有方法尽管尝试通过图像整体特征的一致性对齐来实现这一目标，但在面对领域差异时常常效果不佳，因为决定检索效果的关键对象特征往往与领域特定的样式特征交织在一起。", "innovation": "本文提出了一种新颖的UCIR方法DUDE，其基于特征拆分(disentanglement)来改进检索性能。DUDE利用文本到图像生成模型将对象特征与领域特定样式特征分离，从而有助于提升基于语义的图像检索。为了进一步确保拆分出的对象特征可靠对齐，DUDE通过逐级（progressive）方式在领域内部和领域之间的相互邻居进行特征对齐。实验结果表明，DUDE在三个基准数据集的13个领域中均达到了最先进的性能。", "conclusion": "广泛的实验验证，DUDE方法在多个基准数据集上表现优异。此外，将在之后开放相关源代码。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04133", "html_url": "https://arxiv.org/abs/2509.04133", "title": "变分不等式中的洗牌启发法：建立新的收敛保证", "title_en": "Shuffling Heuristic in Variational Inequalities: Establishing New Convergence Guarantees", "authors": "Daniil Medyakov,Gleb Molodtsov,Grigoriy Evseev,Egor Petrov,Aleksandr Beznosikov", "background": "变分不等式在机器学习和优化研究中引起了广泛关注。通常，解决这些问题的随机方法假设数据样本独立。然而，本研究探讨了一种替代方法——洗牌启发法。该方法通过在按顺序处理前将数据集重新排列，确保所有数据点被平等考虑。尽管这种方法在实践中非常有用，但其在变分不等式中的理论保证尚未得到研究。", "innovation": "我们通过提供变分不等式中洗牌方法的第一个理论收敛估计，填补了这一理论空白。我们的分析建立了严格的界限和收敛速度，扩展了该重要类算法的理论框架。并通过广泛的实验验证了洗牌方法相比独立采样方法的更快收敛性。", "conclusion": "我们的研究建立了洗牌方法在变分不等式中的收敛保证，为这类算法的发展提供了理论基础，并通过实验验证了其优越性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04089", "html_url": "https://arxiv.org/abs/2509.04089", "title": "Gromov-Wasserstein和最优传输：从分配问题到概率数值计算", "title_en": "Gromov-Wasserstein and optimal transport: from assignment problems to probabilistic numeric", "authors": "Iman Seyedi,Antonio Candelieri,Enza Messina,Francesco Archetti", "background": "指派问题作为运筹学的基础问题之一，旨在寻找最优的一对一代理与任务的映射以最小化总成本。本文追溯了指派问题从经典的表述与算法到现代最优传输理论的演变，将二次指派问题（QAP）和相关的结构匹配任务置于其中。文章连接了线性指派问题与Monge的传输问题、Kantorovich的松弛以及Wasserstein距离，然后扩展到不同度量空间的情形，引入Gromov-Wasserstein（GW）距离。GW模型包括融合结构信息和特征信息的合并GW版本，适用于需要同时优化领域内部距离和跨领域属性的问题。这些应用包括图形匹配、关键点对应和基于特征的分配等问题。", "innovation": "本文将指派问题与最优传输理论相结合，通过GW距离和GW变体解决类似QAP的匹配问题，提出了GW-MultiInit等策略来避免陷入局部最优，结合了具有熵的Sinkhorn近似和合并GW的方法，提供了解决大规模问题的有效策略，同时给出了灵活的准确性和计算时间之间的权衡。本文为应用OT和GW方法解决QAP及其它实际匹配问题提供了理论基础、计算见解和实践指南，特别是在机器学习和物流等领域具有重要应用前景。", "conclusion": "计算实验表明，GW-MultiInit方法能稳定地获得接近最优的解，并且在大规模问题上具有高效的可扩展性，而参数化的EGW和FGW变体则在准确性和运行时之间提供了灵活的权衡。本文为处理各种实际匹配问题提供了新的理论框架和计算方法，并指出这些方法在机器学习、物流等领域的大规模实例中具有广阔的应用前景。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04372", "html_url": "https://arxiv.org/abs/2509.04372", "title": "反馈强化学习、测试时间缩放和扩散指导之间的联系：一个综述", "title_en": "Connections between reinforcement learning with feedback,test-time scaling, and diffusion guidance: An anthology", "authors": "Yuchen Jiao,Yuxin Chen,Gen Li", "background": "本文回顾了广泛使用的后训练技术之间的几个基本联系。详细讨论了反馈强化学习、内部反馈强化学习和测试时缩放（特别是软最大-of-N采样）之间的紧密联系和等价关系，同时揭示了扩散指导和测试时间缩放之间的内在联系。", "innovation": "引入了一种重新采样的方法，用于校准和平移奖励导向的扩散模型，而不需明确使用强化学习技术。", "conclusion": "本文阐明了一些基本的连接和等价性，突出了反馈引导、测试时间缩放和扩散指导之间的关系，并提出了一种新的重新采样方法以增强扩散模型。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04337", "html_url": "https://arxiv.org/abs/2509.04337", "title": "为 Pinterest 广告排名的解耦实体表示学习", "title_en": "Decoupled Entity Representation Learning for Pinterest Ads Ranking", "authors": "Jie Liu,Yinrui Li,Jiankai Sun,Kungang Li,Han Sun,Sihan Wang,Huasen Wu,Siyuan Gao,Paulo Soares,Nan Li,Zhifang Liu,Haoyang Li,Siping Ji,Ling Leng,Prathibha Deshikachar", "background": "为了更有效地向用户提供个性化的产品和广告，本文基于上行-下行范式框架，从多数据源构建用户和项（Pin）嵌入。这些嵌入对于 Pinterest 提供个性化产品和广告至关重要。传统的实时计算方式会导致模型无法大规模应用，因此论文提出了一个学习和定期刷新实体嵌入的方法，以确保模型的可扩展性。", "innovation": "论文提出了一种新的框架，通过多样化的数据源构建用户和物品嵌入，使用复杂的架构捕捉用户和物品之间的复杂关系。此外，通过学习和定期刷新实体嵌入，而不是实时计算，来确保模型的可扩展性。实验证明，该框架在多项下游任务中实现了显著的性能提升，并已在 Pinterest 的生产广告排序系统中部署。", "conclusion": "该框架在多种下游任务中取得了显著效果，并且已经在 Pinterest 的生产广告排名系统中部署，带来了在线指标的显著改进。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04194", "html_url": "https://arxiv.org/abs/2509.04194", "title": "批处理随机匹配赌博机", "title_en": "Batched Stochastic Matching Bandits", "authors": "Jung-hun Kim,Min-hwan Oh", "background": "在本研究中，我们基于多项式对数选择模型（MNL）提出了一种新颖的赌博机框架用于随机匹配。在这项研究中，一组由$N$个代理组成在一边，被分配给另一边的$K$个臂，每个臂会根据未知的偏好顺序从其分配的代理池中选择一个代理，并根据选择的结果产出相应的奖励。目标是通过最大化所有代理成功匹配的累计收益来最小化遗憾。这项任务需要解决基于估计偏好组合优化问题，该问题是NP难问题，导致一个简单的解决方法每轮需要计算成本为$O(K^N)$。这引发了研究中对解决这类问题有效算法的需求。因此，我们需要开发一种高效算法来解决这个NP难问题以减少每轮的平均计算成本到$O(1)$，同时仍能实现遗憾上界$\tilde{O}(\text{开方}(T))$。", "innovation": "本文提出了一种批处理算法，通过限制匹配更新的频率，降低了每轮的平均计算成本至$O(1)$，同时仍能达到遗憾上界$\tilde{O}(\text{开方}(T))$。这是一种针对NP难问题的有效解决方法。", "conclusion": "通过引入基于多项对数选择模型的批处理随机匹配赌博机框架，解决了随机匹配中的NP难问题，提出了有效的批处理算法以减少每轮的计算成本同时保持算法性能。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04174", "html_url": "https://arxiv.org/abs/2509.04174", "title": "通过运动模式的深度度量相似性学习进行非干扰现场行为变化测量", "title_en": "Unobtrusive In-Situ Measurement of Behavior Change by Deep Metric Similarity Learning of Motion Patterns", "authors": "Christian Merz,Lukas Schach,Marie Luisa Fiedler,Jean-Luc Lugrin,Carolin Wienrich,Marc Erich Latoschik", "background": "本文介绍了一种无形的现场测量方法，用于检测用户在XR系统中任意暴露期间的行为变化。这种行为变化通常与Proteus效应或不同化身引发的身体能力有关。实验对比了基于运动模式中心趋势的非学习运动分析方法和主观曝露后体验问卷两种替代方法。在一项针对个体进行的研究中，参与者在充当不同身高的化身（矮、实际身高、高）时进行了水果采集任务。评估结果显示，基于运动数据的相似性学习模型成功地识别出了不同化身条件下的行为变化。", "innovation": "这种方法具有以下几点创新：1）无需用户额外输入即可进行现场测量；2）适用于多种情况的通用且可扩展的运动分析；3）在个体水平上进行用户特定的行为分析；4）经过训练的模型可以实时添加和评估用户，以研究化身变化如何影响行为。", "conclusion": "这种相似性学习方法通过运动模式的深度度量相似性学习成功实现行为变化的非干扰现场测量。该方法适用于不同情景下的使用案例，并能够识别出不同条件下的行为变化，为研究化身变化对行为的影响提供了新的工具。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.09754", "html_url": "https://arxiv.org/abs/2401.09754", "title": "超越同质性的相似邻居保留的鲁棒图结构学习", "title_en": "Towards Robust Graph Structural Learning Beyond Homophily via Preserving Neighbor Similarity", "authors": "Yulin Zhu,Yuni Lai,Xing Ai,Wai Lun LO,Gaolei Li,Jianhua Li,Di Tang,Xingxing Zhang,Mengpei Yang,Kai Zhou", "background": "基于图的学习系统在处理结构性数据方面取得了巨大成功，但在同质图数据上面临恶意攻击的脆弱性。研究显示，对手会恶意修改原始图数据的语义和拓扑信息，以降低预测性能。因此，一系列鲁棒模型被设计出来以增强基于图的学习系统对同质图数据的抗攻击能力。然而，异质图数据上的基于图的学习系统的安全性仍然未知。本文旨在探索基于图的学习系统的脆弱性，不论其同质性程度如何，并理论证明基于幂聚合邻居特征的负分类损失更新与对称相似度呈负相关。这一理论发现促使我们设计一个新颖的鲁棒图结构学习策略，该策略包含一个监督邻居相似性保留传播的双重kNN图构造管道，并通过图卷积层根据节点对的丰富局部结构自适应地平滑或区分特征。", "innovation": "本文提出了一种新颖的鲁棒图结构学习策略，其包含一个监督邻居相似性保留传播的双重kNN图构造管道，并通过图卷积层自适应地平滑或区分节点对的特征。该方法能够挖掘多种不同同质性的原始图数据的“更好”拓扑结构，并在同质图和异质图上实现更加可靠的数据管理。", "conclusion": "本文通过理论证明和实验设计了一种超越同质性的相似邻居保留的鲁棒图结构学习方法，该方法能够更好地处理不同同质性的原始图数据，并对于同质图和异质图数据的鲁棒性和可靠性得到了提升。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.04915", "html_url": "https://arxiv.org/abs/2402.04915", "title": "Moco: 一种面向组合优化的可学习元优化器", "title_en": "Moco: A Learnable Meta Optimizer for Combinatorial Optimization", "authors": "Tim Dernedde,Daniela Thyssens,Sören Dittrich,Maximilian Stubbemann,Lars Schmidt-Thieme", "background": "与组合优化问题（COPs）相关的许多问题通常被认为是NP难问题。在过去，这些问题主要依靠手工定制的启发式方法来解决。然而，神经网络的发展激发了从数据中学习启发式方法的一般方法的研究。许多方法利用神经网络直接构建解决方案，但在推理阶段基于已构建的解决方案进一步改进的能力有限。", "innovation": "我们的方法Moco定义了一个由单个连续向量$\theta$（称为热力图）引导的轻量级解决方案构造过程，并学习一个神经网络来在推理时为单个COP实例更新$\theta$。更新基于当前搜索状态的多种特征。训练过程注重在整个搜索过程中找到的最优解决方案。Moco是一种完全可学习的元优化器，不使用特定问题的启发式方法，也不需要在训练时使用最优解。", "conclusion": "我们用旅行商问题（TSP）和最大独立集（MIS）测试了Moco，并展示了它显著优于其他基于热力图的方法。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04345", "html_url": "https://arxiv.org/abs/2509.04345", "title": "AUDETER：开源世界中深度伪造音频检测的大规模数据集", "title_en": "AUDETER: A Large-scale Dataset for Deepfake Audio Detection in Open Worlds", "authors": "Qizhou Wang,Hanxun Huang,Guansong Pang,Sarah Erfani,Christopher Leckie", "background": "现有的语音生成系统能够生成极具真实感的声音，甚至难以与真人语音区分，这对验证的真实性构成了挑战。尽管已经开发出了多种深度伪造检测方法，但在现实环境中的有效性能仍然受制于训练集和测试集之间领域差异的影响，这些差异源于多样的人类语音和快速发展的语音合成系统。当前的数据集无法充分应对现实应用中的挑战，缺乏涵盖广泛且最新的音频样本，无论是真实还是伪造的音频。", "innovation": "本文介绍了一个名为AUDETER的大规模、高度多样化的深度伪造音频数据集，旨在进行全面评估并推动通用深度伪造音频检测器的稳健发展。该数据集包含了4500多小时的来自11个现代TTS模型和10个声码器生成的合成音频片段，总共有300万多个音频片段，是目前规模最大的深度伪造音频数据集。通过广泛实验，发现现有的最先进的方法在处理新颖的深度伪造音频样本时表现不佳，在未见过的真人语音上的误报率高，需要一个全面的数据集。而用AUDETER训练的方法表现出高度的一般化检测性能，检测误差率降低了44.1%至51.6%，在流行的野外数据集中的多样化跨域样本上错误率仅为4.17%，为训练通用的深度伪造音频检测器铺平了道路。", "conclusion": "本文通过引入AUDETER数据集，通过广泛的实验证明了现有的最先进方法在新型深度伪造音频样本上的表现不足，而基于AUDETER训练的方法在通用检测性能上取得了显著提高，充分验证了该数据集的有效性和重要性。数据集已开源，可以提供给研究人员进一步开发和评估深度伪造音频检测器。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.03726", "html_url": "https://arxiv.org/abs/2403.03726", "title": "蛋白质序列生成的语言模型编码上的扩散", "title_en": "Diffusion on language model encodings for protein sequence generation", "authors": "Viacheslav Meshchaninov,Pavel Strashnov,Andrey Shevtsov,Fedor Nikolaev,Nikita Ivanisenko,Olga Kardymon,Dmitry Vetrov", "background": "蛋白质序列设计通过离散扩散和自回归方法取得了显著进展，但连续扩散的潜力仍未得到充分探索。", "innovation": "提出了一种名为DiMA的潜变量扩散框架，该框架基于蛋白质语言模型的表示进行工作。通过系统地探索各种架构选择和扩散组件，该研究开发了一种通用的方法，可以在从8M到3B参数的多种蛋白质编码器之间泛化。该框架使用相同的架构和训练方法，在仅序列（ESM-2，ESMc）、双解码（CHEAP）和多模态（SaProt）表示中实现了高性能。", "conclusion": "DiMA 一致地生成了新颖、高质量和多样性的蛋白质序列，并在生成蛋白质的质量、多样性、新颖性和分布匹配方面取得了优于自回归、离散扩散和流匹配语言模型的基准结果。该模型展示了多功能性，支持包括家族生成、模序支架和填充以及折叠特定序列设计在内的条件生成任务。这项工作为蛋白质序列生成提供了通用的连续扩散框架，提供了架构见解和在各种蛋白质设计情景中的实用性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04439", "html_url": "https://arxiv.org/abs/2509.04439", "title": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory", "title_en": "ArcMemo: Abstract Reasoning Composition with Lifelong LLM Memory", "authors": "Matthew Ho,Chen Si,Zhaoxiang Feng,Fangxu Yu,Zhijian Liu,Zhiting Hu,Lianhui Qin", "background": "随着LLM在推理时间进行缩放，它们可以进行越来越长且复杂的推理环节，但这些过程中的模式和洞察在每次查询的新上下文窗口重置后立即丢失。外存是一种自然的方式将这些发现持久化，以前的研究表明，这对于需要推理的任务有明显的益处。但当前的工作主要集中在基于实例的记忆条目（例如，精确的查询/响应对或与原问题上下文紧密相关的总结）上，我们提出了一种新的设计，通过转向概念层级的记忆，即从解决方案过程中提炼可重用、模块化抽象并以自然语言存储：这些概念可以在未来查询中被有选择地检索并整合进提示中，从而在不更新权重的情况下实现测试时的持续学习。", "innovation": "此设计引入了新的策略，用于从过程结果中抽象提炼要点以及为新查询检索记忆条目，进而促进记忆的重用，并允许记忆随经验的增加而扩大。在具有挑战性的ARC-AGI基准测试中，该方法相对于没有记忆的强基线实现了7.5%的相对收益，并且随着推理计算的增加，性能持续提升。抽象概念被认为是最一致的记忆设计，在所有测试推理计算规模上都优于基线。此外，我们在测试时动态更新记忆的表现优于固定的记忆设置，这支持了通过解决更多问题和将更多模式抽象到记忆中进行自我改进的假设。", "conclusion": "我们的方法在ARC-AGI基准测试中表现优异，尤其是在推理计算量不断增加的情况下，表现出色。我们发现抽象概念是最具一致性的内存设计，并且在所有测试的推理计算规模上都优于基线。我们还确认了在测试时动态更新记忆的表现优于固定设置的记忆，并支持了通过自我改进来进一步解决问题的假设。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04450", "html_url": "https://arxiv.org/abs/2509.04450", "title": "虚拟试衣间：从单张图片生成任意长的虚拟试穿视频——技术预览", "title_en": "Virtual Fitting Room: Generating Arbitrarily Long Videos of Virtual Try-On from a Single Image -- Technical Preview", "authors": "Jun-Kun Chen,Aayush Bansal,Minh Phuoc Vo,Yu-Xiong Wang", "background": "传统的试穿场景需要用户在现实中试穿衣物，这不仅耗时耗力，而且受到现实条件的限制。虚拟试衣间（VFR）旨在通过视频生成技术解决这一问题，生成任意长度的虚拟试穿视频，以提供更加便捷和视觉上真实的试衣体验。现有的生成模型通常依赖于大量的视频数据，且生成过程资源密集，耗时较长。因此，如何在减少对大量数据依赖的同时，产生高质量的虚拟试穿视频成为了一个新的挑战。本研究探讨了在长视频生成任务中如何有效地保证局部平滑性和全球时间一致性，从而使生成的视频更加自然和逼真。", "innovation": "本研究创新性地提出了一种自回归、逐段生成的虚拟试衣间（VFR）模型，旨在生成任意长度的虚拟试穿视频。通过利用一个全面捕捉人体全身外观的360度视频（锚视频）作为约束条件，VFR模型有效地解决了局部平滑性和全局时间一致性这两个主要挑战，从而在不同运动状态下生成具有高质量的虚拟试穿视频，为长视频生成任务提供了新的解决方案。", "conclusion": "本研究提出的虚拟试衣间（VFR）框架能够在不同动作下生成具备局部平滑性和全局时间一致性的分钟级别的虚拟试穿视频，填补了该领域的空白，为未来进一步优化虚拟试穿视频生成模型铺平了道路。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2212.14641", "html_url": "https://arxiv.org/abs/2212.14641", "title": "储层核函数与Volterra级数", "title_en": "Reservoir kernels and Volterra series", "authors": "Lukas Gonon,Lyudmila Grigoryeva,Juan-Pablo Ortega", "background": "本文提出了一个通用核的概念，该核能近似任何因果且时间不变的滤波器。这些滤波器在有限维欧氏空间中具有输入和输出，并且属于消逝记忆类别。该核基于任何分析型消逝记忆滤波器的Volterra级数展开的空间状态表示法，因此被称作Volterra储层核。尽管空间状态表示及其相应的储层特征映射定义在无限维张量代数空间中，但该核映射可通过具体数据集中的明确递归公式来计算，在使用代表定理进行估计问题时可以轻易完成。这篇文章还展示了Volterra储层核在多维且高度非线性的学习任务中计算条件协方差时的表现，并将其与其他标准静态和顺序核进行了比较。", "innovation": "本文创新地构建了一个通用的核函数（Volterra储层核），它可以近似任何因果且时间不变的滤波器。该核基于Volterra级数展开的空间状态表示法，可以在估计问题中通过有限维度的递归公式进行计算。此外，这篇文章还研究了针对金融资产回报条件协方差的高维非线性学习任务中，Volterra储层核与其它标准核函数的表现情况。", "conclusion": "通过使用Volterra储层核，该研究展示了在高维且非线性的金融资产条件协方差学习任务中，该核与其它标准核相比具有更好的表现。研究结果证明了用Volterra储层核进行非线性回归的能力，并展示了其在处理复杂时间序列数据中的潜力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.15869", "html_url": "https://arxiv.org/abs/2407.15869", "title": "长输入序列网络在长期时间序列预测中的应用", "title_en": "Long Input Sequence Network for Long Time Series Forecasting", "authors": "Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu", "background": "在长期时间序列预测任务中，短固定长度的输入是深度学习方法的主要瓶颈。延长输入长度会导致过拟合，从而使准确性迅速下降。", "innovation": "研究团队发现，过拟合是时间序列中的多尺度模式耦合和当前模型中的固定聚焦尺度的组合反应。通过引入一个新的时间序列分解模块(MPSD)和一种多令牌模式识别神经网络(MTPR)，研究提出了一种解耦多尺度时间模式的方法，使得模型能够处理输入长度最长可延长10倍的内容。这种方法通过增强上下文信息显著提高了性能（最大38%精度提升），并且具有较低的复杂度和较高的解释性。", "conclusion": "该方法解决了长时间序列预测中因输入长度过短导致的过拟合问题，通过解耦时间序列的多尺度特性，并使用相应的时间周期作为令牌大小，实现了更长输入长度处理能力和显著的性能提升，同时保持了低复杂度和高可解释性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04413", "html_url": "https://arxiv.org/abs/2509.04413", "title": "SAFE--MA--RRT: 多智能体数据驱动的安全证书运动规划", "title_en": "SAFE--MA--RRT: Multi-Agent Motion Planning with Data-Driven Safety Certificates", "authors": "Babak Esmaeili,Hamidreza Modares", "background": "本文提出了一种适用于在共享且充满障碍的工作空间中操作的同质线性多智能体系统的完全数据驱动的运动规划框架，这些系统无法访问显式系统模型。每个智能体通过求解凸半定规划来独立地从实验数据中学习其闭环行为，生成局部不变的椭球体及其相应的状态反馈增益。这些椭球体围绕基于网格的航点中心，认证短距过渡的动态可行性和定义安全操作区域。基于采样的规划器构建了这些航点的树，只有当相邻椭球体重叠时才允许过渡，确保从局部不变到局部不变的过渡以及连续安全性。所有智能体同时扩展其航迹树，并通过空间-时间预订表进行协调，以防止智能体同时占用和正面对撞，从而保证多智能体之间的安全性。每个树中成功的边都配备了自己的局部控制器，这使得在运行时无需重新求解优化问题即可执行策略。结果生成的轨迹不仅在动力学上可行，而且在环境约束和智能体之间的碰撞方面具有可证明的安全性。仿真结果证明了该方法在共享动态和约束条件下合成多个智能体同步、安全轨迹的有效性，仅使用数据和凸优化工具。", "innovation": "1. 提出了一种数据驱动的运动规划框架，适用于同质线性多智能体系统在共享且充满障碍的工作空间中运动规划，无需显式系统模型。\n2. 通过凸半定规划学习闭环智能体的行为，生成局部不变的椭球体和相应的状态反馈增益。\n3. 在采样的基础上，构建含有安全航点的树，当相邻椭球体重叠时允许过渡，确保连续可证的安全性。\n4. 通过空间-时间预订表协调智能体之间的安全性，避免占用和正面对撞。\n5. 每个成功的树边都配备了自己的局部控制器，以便执行策略时无需重新求解优化问题。\n6. 生成的轨迹在动力学和安全性方面都具有可证明的保证，通过仿真验证了方法的有效性。", "conclusion": "该方法能够生成动态可行且可证安全的轨迹，适用于同质线性多智能体系统在共享且充满障碍的工作空间中的运动规划，无需显式系统模型，在多智能体同步、安全运动规划方面具有潜在应用价值。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.00265", "html_url": "https://arxiv.org/abs/2411.00265", "title": "通过证据理论量化神经网络的校准误差", "title_en": "Quantifying Calibration Error in Neural Networks Through Evidence-Based Theory", "authors": "Koffi Ismael Ouattara,Ioannis Krontiris,Theo Dimitrakos,Frank Kargl", "background": "在关键应用中部署神经网络时，可靠性、信心和不确定性对于决策至关重要。传统的性能指标如准确率和精确率无法捕捉这些方面，特别是在模型表现出过度自信的情况下。因此，需要一种新的框架来量化神经网络的可信度。", "innovation": "本文提出了一个结合主观逻辑来评估期望校准误差（ECE）的新框架，通过聚类预测概率并使用适当的融合操作器融合意见，量化了可信度、不信任度和不确定性。实验证明了该方法的有效性。", "conclusion": "提出的框架为AI模型提供了一种更具可解释性和细微差别评估方式，潜在应用于敏感领域如医疗和自主系统。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.03951", "html_url": "https://arxiv.org/abs/2407.03951", "title": "不确定性指导的似然性树搜索", "title_en": "Uncertainty-Guided Likelihood Tree Search", "authors": "Julia Grosse,Ruotian Wu,Ahmad Rashid,Cheng Zhang,Philipp Hennig,Pascal Poupart,Agustinus Kristiadi", "background": "树搜索是规划的一个基本工具，许多序列决策问题可以被构建成树结构空间的搜索问题。由于树的规模的组合爆炸，可以获得奖励的路径集合是稀疏的，特别是在通过昂贵的评估（如查询大型语言模型）得到似然性时。现有的树搜索方法难以应对这种稀疏性挑战。", "innovation": "提出了一种基于似然性假设的不确定性导向的树搜索算法。该方法能够在不进行昂贵的展开或复杂的贝叶斯推断的情况下，同时进行回溯和探索与利用之间的权衡，识别出高似然性路径，同时减少昂贵评估的数量。", "conclusion": "通过针对真实世界的广泛应用进行广泛的模型内和模型外实验，证明了该方法能够比现有技术更有效地找出高似然性路径，同时需要更少的昂贵评估。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.01085", "html_url": "https://arxiv.org/abs/2407.01085", "title": "LLM基于偏好的评估中的长度偏见解释", "title_en": "Explaining Length Bias in LLM-Based Preference Evaluations", "authors": "Zhengyu Hu,Linxin Song,Jieyu Zhang,Zheyuan Xiao,Tianfu Wang,Zhengyu Chen,Nicholas Jing Yuan,Jianxun Lian,Kaize Ding,Hui Xiong", "background": "大型语言模型（LLMs）在偏好评估中的应用越来越普遍，但这种做法倾向于更长的回答，这影响了评估的可靠性。研究者发现，这种偏好评估中的长度偏见主要源于对信息量的评估，而非内容的质量。文章通过控制实验，证实了这种偏见并揭示了长度对评估的影响。", "innovation": "该研究在偏好评估中引入了一个两部分的分解方法，将赢率拆分为与长度无关的‘可信赖度’和与长度相关的‘信息量’。此外，研究提出了AdapAlpaca，一种对赢率测量进行调整的方法，通过使参考答案和测试模型的答案在长度上达到相同区间，以确保质量比较的公平性。", "conclusion": "该研究揭示了偏好评估中长度偏见的原因，并通过实验证明了AdapAlpaca方法的有效性，可以实现无需受制于答案长度的高质量评估。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04213", "html_url": "https://arxiv.org/abs/2509.04213", "title": "使用UKF结合基础模型向零样本状态估计航行", "title_en": "Sailing Towards Zero-Shot State Estimation using Foundation Models Combined with a UKF", "authors": "Tobin Holtmann,David Stenger,Andres Posada-Moreno,Friedrich Solowjow,Sebastian Trimpe", "background": "传统控制系统和系统工程中的状态估计需要大量的手动系统识别或数据收集工作。然而，其他领域基于变压器的基础模型通过利用预训练的一般模型减少了对数据的需求。最终，开发能够处理不同动态系统的零样本基础模型可以大大减少手动部署工作量。", "innovation": "介绍了一种新型的基础模型无迹卡尔曼滤波器(FM-UKF)，它结合了基于变压器的系统动力学模型和已知的传感器模型，通过UKF来实现不同动态系统之间的泛化，而无需为了新的传感器配置进行重新训练。该方法在具有复杂动态特性的集装箱船模型上进行了评估，显示出与传统方法和基于变压器的端到端方法相比，在准确度、工作量和鲁棒性之间的竞争力。", "conclusion": "研究还提供了新的基准和数据集，支持未来通过基础模型进行零样本状态估计的研究。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.22381", "html_url": "https://arxiv.org/abs/2410.22381", "title": "使用不变统计损失对具有多变量和重尾分布的隐式生成模型进行鲁棒训练", "title_en": "Robust training of implicit generative models for multivariate and heavy-tailed distributions with an invariant statistical loss", "authors": "José Manuel de Frutos,Manuel A. Vázquez,Pablo Olmos,Joaquín Míguez", "background": "传统的隐式生成模型能够学习复杂的数据分布，但训练过程中需要通过对抗性判别器来区分真实数据和合成数据，这可能导致训练不稳和模式丢失问题。许多现实现象的数据需要由重尾概率分布来恰当地表示，而传统的隐式方法难以有效捕捉它们的渐近行为。本文基于引入的不变统计损失（ISL）方法并扩展其处理重尾和多变量数据的能力，旨在提高生成模型的鲁棒性和效率，特别是在高维度的数据生成问题上有所突破。", "innovation": "本文提出了一种使用泛化帕累托分布（GPD）输入噪声训练生成器的新方法，并结合1D方法扩展到多变量数据情况，引入了适合多变量数据的新的损失函数。相比传统的直接扩展方法，这种方法通过随机投影的方法使得高维数据处理更加可行。同时，该方法也作为生成对抗网络（GANs）预训练的一种手段，有效防止模式崩溃，表现出较强鲁棒性和效果一致性。", "conclusion": "实验表明，Pareto-ISL能准确建模分布的尾部特征，同时有效捕捉它们的中心特征。新的损失函数在多维生成模型中的表现良好，检测到其作为GAN预训练技术的潜力，显示出在各种超参数设置下的鲁棒性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04317", "html_url": "https://arxiv.org/abs/2509.04317", "title": "改善AlphaZero算法在测试环境变化时的鲁棒性", "title_en": "Improving Robustness of AlphaZero Algorithms to Test-Time Environment Changes", "authors": "Isidoro Tamassia,Wendelin Böhmer", "background": "AlphaZero框架提供了一种将蒙特卡洛规划与之前训练的策略-价值神经网络提供的先验知识相结合的标准方法。AlphaZero通常假设在测试时不会改变神经网络所训练的环境，这限制了其应用范围。本文分析了如何部署AlphaZero代理在可能变化的测试环境中，并展示了通过对标准框架进行简单修改可以显著提升性能，即使可用的规划预算很低。", "innovation": "通过简单修改AlphaZero标准框架，即使在有限的规划预算情况下，也能显著提升算法在测试环境发生变化时的性能。", "conclusion": "本文证明了可以通过简单调整AlphaZero框架以提高算法在测试环境变化时的鲁棒性，并提供了可公开访问的代码。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.03562", "html_url": "https://arxiv.org/abs/2411.03562", "title": "基于科布经验学习的通用智能体及其人类级别的Kaggle数据科学性能", "title_en": "Kolb-Based Experiential Learning for Generalist Agents with Human-Level Kaggle Data Science Performance", "authors": "Antoine Grosnit,Alexandre Maraval,Refinath S N,Zichao Zhao,James Dora,Giuseppe Paolo,Albert Thomas,Jonas Gonzalez,Abhineet Kumar,Khyati Khandelwal,Abdelhakim Benechehab,Hamza Cherkaoui,Youssef Attia El-Hili,Kun Shao,Jianye Hao,Jun Yao,Balázs Kégl,Jun Wang", "background": "人类知识和技能的发展源于互动、反思和内部模型更新的迭代过程，这是许多认知理论的核心，例如科布的经验学习和维果茨基的最近发展区。然而，当前的AI系统，特别是大型语言模型（LLM），依赖于静态预训练或固定的工作流程，缺乏持续适应的机制。尽管如此，研究人员已经发现LLM代理在早期认识上的一些特征，如反思、修订和自我纠正，这表明人类经验学习的基础元素。因此，核心问题是能否设计出能够进行结构化、认知扎根的学习的LLM代理，类似于人类的认知过程。", "innovation": "本文提出了一种基于科布学习周期和维果茨基最近发展区的计算框架，为自主代理提供支持。此架构将外部（环境互动）和内部（内在反思/抽象）功能分开，使得代理能够进行认知扎根的学习支架，即先在结构化环境中学习，然后进行开放泛化的学习。这种方法使代理能够掌握复杂的任务，而且传统的微调或简单的反思方法无法有效解决。通过直接比较，在真实的Kaggle数据科学竞赛中，我们的系统Agent K成功实现了这一目标。", "conclusion": "我们的系统Agent K能够实现81项数据科学任务的完全自动化代码生成，在国际象棋elo-MMR评分中达到1694分，超过了我们在研究中包括数据科学大师在内的20万个用户中，前2%的中位数得分。在获奖总计9金、8银和12铜，包括奖牌竞赛4金和4银的成绩中，Agent K是第一个成功整合了科布和维果茨基启发的认知学习的人工智能系统，标志着通用人工智能的重要一步。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.17527", "html_url": "https://arxiv.org/abs/2405.17527", "title": "Unisolver: PDE-Conditional Transformers Towards Universal Neural PDE Solvers", "title_en": "Unisolver: PDE-Conditional Transformers Towards Universal Neural PDE Solvers", "authors": "Hang Zhou,Yuezhou Ma,Haixu Wu,Haowen Wang,Mingsheng Long", "background": "深度模型近期成为了解决偏微分方程（PDEs）的有前景工具，被称为神经PDE求解器。虽然从仿真数据或基于物理的信息损失训练的神经求解器可以在一定程度上准确求解PDEs，但它们通常仅适用于特定的PDE实例，如某特定方程且具有有限系数的方程。这限制了其对各种PDEs的泛化能力，阻碍了它们成为数值求解器的有效替代模型。", "innovation": "本文提出了Unisolver，一种新型的Transformer模型，该模型通过训练在多样化的数据上，并且针对多样化的PDEs进行条件化，旨在实现一个能够广泛求解PDEs的通用神经PDE求解器。Unisolver通过理论分析PDE求解过程，借鉴了PDE数学结构，即PDE解本质上由一整套PDE组件（如方程符号和边界条件）控制，并灵活嵌入为领域间和点间深度条件，从而实现了一种更为复杂的Transformer PDE求解器。它结合了物理洞察力和近期Transformer的最新进展，成功地在三个具有挑战性的大规模基准测试中实现了持续的最先进的性能，并展示了出色的性能和泛化能力。", "conclusion": "Unisolver达到了在三个复杂的大规模基准测试中的一致最先进的状态，并展示了出色的性能和泛化能力。其关键在于将物理洞察力与Transformer的最新进展相结合，通过在Transformer PDE求解器中灵活嵌入一种完整集的PDE组件（以方程符号和边界条件为例），实现了广泛的PDE求解能力。代码可在此链接访问：this https URL."}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16572", "html_url": "https://arxiv.org/abs/2412.16572", "title": "打破长时序预测中的上下文瓶颈", "title_en": "Breaking the Context Bottleneck on Long Time Series Forecasting", "authors": "Chao Ma,Yikai Hou,Xiang Li,Yinggang Sun,Haining Yu,Zhou Fang,Jiaxing Qu", "background": "长期时序预测在经济学、能源和交通运输等领域至关重要，因为需要长远的预估。要实现这种长远预估，模型必须在处理长序列时既高效又有效。近期的发展提高了模型的效率，但有效利用更长的序列仍然具有挑战性，主要是因为这些模型在面对更长的输入时容易过拟合，因此需要使用较短的输入长度以保持可接受的误差范围。", "innovation": "本工作研究多尺度建模方法，并提出了 Logsparse Decomposable Multiscaling（LDM）框架，用于高效且有效地处理长序列。通过在时间序列中解耦不同尺度的模式，LDM 可以降低非平稳性，通过紧凑的长输入表示提高效率，并通过清晰的任务分配简化架构。", "conclusion": "实验结果表明，LDM 不仅在长期预测基准测试中优于所有基线，而且减少了训练时间和内存成本。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.10438", "html_url": "https://arxiv.org/abs/2411.10438", "title": "MARS: Unleashing the Power of Variance Reduction for Training Large Models", "title_en": "MARS: Unleashing the Power of Variance Reduction for Training Large Models", "authors": "Huizhuo Yuan,Yifeng Liu,Shuang Wu,Xun Zhou,Quanquan Gu", "background": "训练深度神经网络以及最近的大型模型需要高效的可扩展优化器。自适应梯度算法如Adam、AdamW及其变种一直是该领域的核心。尽管过去十年中已开发出大量减少方差的技术以加速凸性和非凸性的随机优化，但在训练深度神经网络和大型语言模型时，方差减少尚未广泛取得成功。因此，这种方法在现代人工智能中未被广泛采用。", "innovation": "为了利用方差减少的强大功能，实现大型模型的有效训练，我们提出了一种统一的优化框架MARS（Make vAriance Reduction Shine）。MARS框架结合了预条件梯度方法和方差减少策略，通过缩放随机递归动量技术实现了预条件梯度更新。我们还引入了MARS的三个实例，分别基于AdamW、Lion和Shampoo。此外，我们将我们的算法与现有的优化器进行了比较。实验结果表明，MARS在训练GPT-2模型时明显优于AdamW。", "conclusion": "MARS在训练GPT-2模型时性能优于AdamW，并且已在GitHub上开源。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.22954", "html_url": "https://arxiv.org/abs/2410.22954", "title": "基于来源可靠性估计的检索增强生成", "title_en": "Retrieval-Augmented Generation with Estimation of Source Reliability", "authors": "Jeongyeon Hwang,Junyoung Park,Hyejin Park,Dongwoo Kim,Sangdon Park,Jungseul Ok", "background": "检索增强生成（RAG）是通过从外部数据库检索信息来增强大型语言模型（LLMs）事实准确性的一种有效方法，这些外部数据库通常由多种来源组成，用以补充LLMs内部知识的不足。然而，标准的RAG方法在检索过程中存在风险，因为它仅仅依靠查询与文档之间的相关性，而忽视了这些来源的异质可靠性的差异。这可能导致检索到不正确的信息，影响生成的响应的准确性和可靠性。", "innovation": "为了克服上述问题，我们提出了一种新的多源RAG框架——可靠性意识增强检索生成（RA-RAG）。RA-RAG通过评估来源的可靠性并利用这一信息来优先选择高可靠性和相关性的文档，从而确保生成更稳健和准确的响应。具体而言，RA-RAG首先通过跨多个来源交叉验证信息来估计来源的可靠性，然后从顶级$\boldsymbol{\textit{k}}$可靠且相关的来源检索文档，并使用加权多数投票（WMV）聚合这些信息，以确保可扩展性而不减损性能。广泛的实验表明，当来源可靠性异质时，RA-RAG在基准模型上始终表现出优越性，并且随着来源数量的增加，其性能效率也得到了提高。此外，我们展示了RA-RAG能够估计现实世界中来源的可靠性，突显了其实用性。", "conclusion": "我们的实验结果证明了RA-RAG在不同来源可靠性下的有效性和优越性，并且随着来源数量的增加，其性能表现出高效扩展的特性。我们还展示了RA-RAG能够估计实际来源可靠性的能力，这进一步证明了其在实际应用中的实用性。我们的代码和数据可以在RA-RAG页面上获取。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.17941", "html_url": "https://arxiv.org/abs/2411.17941", "title": "多标签贝叶斯主动学习中的标签间关系", "title_en": "Multi-Label Bayesian Active Learning with Inter-Label Relationships", "authors": "Yuanyuan Qi,Jueqing Lu,Xiaohao Yang,Joanne Enticott,Lan Du", "background": "多标签主动学习的主要挑战在于评估无限数量标签的信息价值同时考虑标签间的相关性，而现有的研究或需要大量计算资源利用这些相关性或未能充分探索标签依赖性。此外，实际场景还需要处理由于数据分布不平衡引起的内在偏差。", "innovation": "本文提出了一种新的多标签主动学习策略，能解决上述挑战。该方法通过逐步更新正相关和负相关矩阵来捕捉注解样本标签空间内的共存和独立关系，从而实现对不确定性整体评估。此外，该模型结合多样性、集合伪标记和β评分规则来应对数据不平衡问题。", "conclusion": "在四个现实数据集上的广泛实验表明，该策略的一致表现比几个现有方法更可靠和优越。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.04241", "html_url": "https://arxiv.org/abs/2505.04241", "title": "使用神经网络预测3D模型的技术", "title_en": "Technology prediction of a 3D model using Neural Network", "authors": "Grzegorz Miebs,Rafał A. Bachorz", "background": "准确估算生产时间对于有效的生产调度至关重要，但传统的依赖于专家分析或历史数据的方法在动态或定制化的生产环境中往往表现不佳。因此，本文提出了一种数据驱动的方法，该方法可以直接从具有暴露几何形状的产品3D模型中预测制造阶段及其持续时间。", "innovation": "通过将3D模型渲染成多个2D图像，并利用受生成查询网络启发的神经网络，该方法学习映射几何特征到预定生产步骤的时间估计，使不同产品类型之间的计划更加容易。平均绝对误差低于3秒。", "conclusion": "本文提出的方法通过直接从3D模型预测制造步骤及其持续时间，实现了在动态和定制化生产环境中对生产时间的准确估算，从而简化了跨多种产品类型的计划过程。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04357", "html_url": "https://arxiv.org/abs/2509.04357", "title": "PARCO: 声学单元增强鲁棒上下文ASR通过对比实体消歧", "title_en": "PARCO: Phoneme-Augmented Robust Contextual ASR via Contrastive Entity Disambiguation", "authors": "Jiajun He,Naoki Sawada,Koichi Miyazaki,Tomoki Toda", "background": "自动语音识别（ASR）系统在处理特定领域的命名实体，特别是同音词时遇到困难。上下文ASR可以提高识别性能，但往往无法捕捉到细微的音素变异，因为实体多样性的限制。此外，先前的方法将实体视为独立的标记，导致多标记偏置不完整。", "innovation": "提出的PARCO模型集成了声学单元感知编码、对比实体消歧、实体级监督以及层次实体过滤。这些组件增强了音素歧视能力，确保了完整的实体检索，并在不确定性下减少了误报。", "conclusion": "实验结果显示，PARCO在Chinese AISHELL-1 和 English DATA2数据集下具有1,000个干扰词时，CER达到4.22%，WER为11.14%，显著优于基线方法。此外，PARCO在THCHS-30和LibriSpeech等域外数据集上也展示了鲁棒性改进。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08821", "html_url": "https://arxiv.org/abs/2504.08821", "title": "在条件潜动态的条件扩散模型中进行延迟容忍网络中的概率QoS指标预测", "title_en": "Probabilistic QoS Metric Forecasting in Delay-Tolerant Networks Using Conditional Diffusion Models on Latent Dynamics", "authors": "Jianhua Liu,Zheng Liu,Yu Xiang,Yanwen Qu", "background": "QoS指标预测在维持和操作分布式自愈网络（DTN）方面被广泛应用，能够提升网络延迟、吞吐量、能耗和可靠性的性能。传统的时间序列多变量回归方法难以捕捉数据复杂性，导致在网络路由等任务上的表现不佳。因此，本文将QoS指标的预测问题转化为一个概率性的多变量时间序列预测问题，能够量化预测的不确定性并通过表征这些样本的分布来实现这一目标。", "innovation": "本文提出了一种结合扩散模型的方法，它能够整合非平稳性和多模式数据的潜在时间动态。这种方法能够在保持高预测准确性的同时，更好地捕捉数据的复杂性和不确定性。实验显示，该方法在处理延迟容忍网络中的QoS指标预测任务时，比现有的流行概率时间序列预测方法更为有效。", "conclusion": "本研究通过提出一种基于条件扩散模型（考虑潜在动态）的方法，成功地将延迟容忍网络中的QoS指标预测转化为一个概率性的多变量时间序列预测问题。实验结果验证了该方法的有效性，并表明它能够显著提升网络性能。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.14783", "html_url": "https://arxiv.org/abs/2411.14783", "title": "通过TD($\triangle$)分割SARSA动作-价值函数在时间尺度上", "title_en": "Segmenting Action-Value Functions Over Time-Scales in SARSA via TD($Δ$)", "authors": "Mahammad Humayoo", "background": "在众多 episodic 强化学习（RL）环境中，通常使用基于 SARSA 的方法来提高旨在最大化长期回报的策略。传统的 SARSA 算法在偏置和方差之间寻求最优平衡时面临挑战，主要原因是它们依赖于单一的、固定的折扣因子（$\boldsymbol{\boldsymbol{\boldsymbol{\theta}}}$）。为了改进这种情况，本文通过对 SARSA 算法进行改进，提出了 SARSA($\boldsymbol{\boldsymbol{\boldsymbol{\triangle}}}$) 方法，通过应用时间差分解方法（TD($\boldsymbol{\boldsymbol{\boldsymbol{\triangle}}}$)），提高了学习效果，特别是在需要长期改进的情况下。研究表明，SARSA($\boldsymbol{\boldsymbol{\boldsymbol{\triangle}}}$) 能够降低 SARSA 的更新偏差，并加速不同确定性和随机设置下的收敛速度，尤其在密集奖励的 Atari 环境中表现良好。", "innovation": "本文通过应用时间差分解方法 TD($\boldsymbol{\boldsymbol{\boldsymbol{\triangle}}}$) 改进了 SARSA 算法，提出了新的 SARSA($\boldsymbol{\boldsymbol{\boldsymbol{\triangle}}}$) 方法。SARSA($\boldsymbol{\boldsymbol{\boldsymbol{\triangle}}}$) 能够将动作-价值函数分解成与特定折扣因子相关的组件，从而使学习在不同时间尺度上更加容易并且保持一致性。该方法在多表和深度 RL 环境中表现出色，尤其在 Atari 环境中，能够加快收敛速度并降低偏差。", "conclusion": "实验结果表明，SARSA($\boldsymbol{\boldsymbol{\boldsymbol{\triangle}}}$) 在不同基准设置下均优于现有 TD 学习技术，特别是在确定性和随机环境，以及密集奖励的 Atari 环境中表现突出，证明了该方法的有效性和优越性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.00515", "html_url": "https://arxiv.org/abs/2411.00515", "title": "在库存管理中的零样本泛化：先训练，再估计，后决策", "title_en": "Zero-shot Generalization in Inventory Management: Train, then Estimate and Decide", "authors": "Tarkan Temizöz,Christina Imdahl,Remco Dijkman,Douniel Lamghari-Idrissi,Willem van Jaarsveld", "background": "在实际库存管理中应用深度强化学习（DRL）面临挑战，包括动态环境和不确定的问题参数，例如需求和交货时间的分布。这些挑战表明需要一个统一的框架来建模和在参数不确定性下解决序列决策问题。这项研究通过探索DRL在库存管理中的新兴领域——在零样本泛化（ZSG）下训练一般能力的代理（GCAs），来应对这一挑战。GCAs是先进的DRL策略，旨在处理各种具有不同库存挑战的试训练问题实例。ZSG指的是在不了解参数的情况下，能够成功应用已学习策略的未知实例，且无需重新训练的能力。研究人员提出了一种统一的超级马尔可夫决策过程（SMDP）形式和一种名为Train, then Estimate and Decide (TED)的框架，用于训练和部署专门针对库存管理应用的GCAs。TED框架包括三个阶段：在变化了的实例上训练GCAs、部署期间连续估计问题参数、以及基于估计结果做出决策。应用到周期性审查的库存问题中，我们训练的代理GC-LSN在已知问题参数时，表现优于传统的标准方法。在需求和/或交货时间分布未知并需要估计的条件下，这一代理与提供最坏情况性能保证的在线学习方法进行了对比，结果表明，配以kaplan-meier估计器后，我们的GC-LSN策略在实际性能上优于这些方法。", "innovation": "提出了统一的超级马尔可夫决策过程（SMDP）形式和Train, then Estimate and Decide (TED)框架，以培训专门针对库存管理应用的一般能力代理（GCAs）。TED框架包括三个阶段：培训GCAs以应对变化的问题实例、在部署期间连续估计问题参数、以及基于估计做出决策。此外，还探索了在初始需求和/或交货时间分布未知的情况下，通过在线学习方法提供最坏情况性能保证的方法，GC-LSN策略与kaplan-meier估计器的结合展现了强大的实际性能。", "conclusion": "在已知问题参数时，我们训练的代理GC-LSN在库存管理中表现出色，超过了传统的标准方法。在需求和/或交货时间分布未知的情况下，通过在线学习方法提供最坏情况性能保证，我们的GC-LSN策略与kaplan-meier估计器结合，展现出了优于这些方法的现实性能。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.12689", "html_url": "https://arxiv.org/abs/2501.12689", "title": "IC-Cache：通过基于上下文缓存实现高效的大语言模型服务", "title_en": "IC-Cache: Efficient Large Language Model Serving via In-context Caching", "authors": "Yifan Yu,Yu Gan,Nikhil Sarda,Lillian Tsai,Jiaming Shen,Yanqi Zhou,Arvind Krishnamurthy,Fan Lai,Henry M. Levy,David Culler", "background": "大语言模型（LLMs）在各种应用中表现出色，但由于其巨大的资源需求和较高的延迟，大规模提供这些模型的服务存在挑战。我们的实地研究表明，超过70%的用户请求与已有请求在语义上相似，这表明请求之间可以有知识转移的潜力。然而，简单地缓存和重复使用过去的响应会导致质量显著下降。", "innovation": "本文介绍了一种名为IC-Cache的缓存系统，该系统能够在运行时增强LLM的功能，提高服务效率：通过利用来自更大模型的历史请求-响应对作为上下文示例，IC-Cache使小型LLM能够模仿甚至超越其更大模型的组合能力（例如，推理能力），从而实现请求的有选择性地卸载以减少成本和延迟。实现这种大规模的实时增强带来了响应质量、延迟和系统吞吐量之间的复杂权衡。", "conclusion": "IC-Cache在数百万个真实请求上的评估表明，它可以将LLM服务吞吐量提高1.4到5.9倍，将延迟降低28%到71%，且不损害响应质量。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14610", "html_url": "https://arxiv.org/abs/2504.14610", "title": "不使用插补学习具有缺失值的表格数据：基于变换器的增量特征分区", "title_en": "Imputation-free Learning of Tabular Data with Missing Values using Incremental Feature Partitions in Transformer", "authors": "Manar D. Samad,Kazi Fuad B. Akhter,Shourav B. Rabbani,Ibna Kowsar", "background": "现有的机器学习方法处理具有不规则缺失值的表格数据时，通常依赖于任意的插补策略生成合成值。然而，这些合成值可能会引起对数据质量和数据驱动结果可靠性的担忧。为此，研究提出了一个名为IFIAL（Imputation-Free Incremental Attention Learning）的方法，该方法在处理缺失值时无需插补或初始化，直接通过一对注意力掩码对变换器进行调整，以提高效率和性能。研究表明，这种不插补的学习方法在多项基准数据集上的分类性能优于现有的各种方法，尤其是在处理不同类型的缺失值时更为鲁棒。", "innovation": "该研究提出了一种名为IFIAL的方法，这是首个在无需进行缺失值插补的情况下，实现表征数据深度注意力学习的方法。该方法通过一对注意力掩码直接对变换器进行调整，能够高效处理具有不规则缺失值的表格数据，且其性能优于现有方法。此外，该方法还揭示了最佳的特征分区大小为原始特征空间的一半，该选择在计算效率和准确性上都是最优的。", "conclusion": "该研究提出的IFIAL方法在多个表征数据集上显示出优越的分类性能，特别是在面对不同类型和频率的缺失值时更为鲁棒。这一创新方法为处理缺失值的表格数据提供了一个新的解决方案，并且其开放的代码为研究提供了便利。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05719", "html_url": "https://arxiv.org/abs/2502.05719", "title": "EHBOS", "title_en": "Extended Histogram-based Outlier Score (EHBOS)", "authors": "Tanvir Islam", "background": "HBOS是广泛使用的异常检测方法，因其计算效率和简单性而著称。然而，它假设特征独立，这限制了其在特征之间存在交互作用的数据库中检测异常的能力。", "innovation": "提出了一种增强的异常检测方法EHBOS，通过引入二元直方图来捕捉特征对之间的依赖性，从而能够识别HBOS无法检测到的上下文和依赖驱动的异常。", "conclusion": "EHBOS在17个基准数据集上的评估结果表明，它在多种异常检测场景下表现出色且稳健，特别在特征交互对于定义异常结构至关重要的情况下，在ROC AUC方面取得了显著的提升。这些结果表明EHBOS可以作为HBOS的一个有价值的扩展，特别是对于涉及上下文或关系的异常检测。EHBOS提供了一个强大的新工具，特别适用于特征依赖性显著的数据库。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.07681", "html_url": "https://arxiv.org/abs/2501.07681", "title": "数据集蒸馏作为推进最优量化", "title_en": "Dataset Distillation as Pushforward Optimal Quantization", "authors": "Hong Ye Tan,Emma Slade", "background": "数据集蒸馏的目标是在合成训练集中找到一个这样的数据集，使得在合成数据上训练比在真实数据上训练具有相似的性能，并且计算需求量级减少。现有方法可以分为两类：一类是带有神经网络训练启发式的双层优化问题，另一类是通过匹配数据分布来绕过双层优化的去纠缠方法。去纠缠方法的主要优点是速度和可扩展性，尤其是在训练集和导出数据集的大小方面。文章指出，当使用编码器-解码器结构时，现有的成功去纠缠方法可以重新表述为最优量化问题，其中通过最小化预期投影距离找到一组点来逼近潜在的概率测度。现有方法被链接到经典最优量化和 Wasserstein 泪水中心问题，展示了蒸馏数据集的一致性，特别是在基于扩散的生成先验方面。文章提出了一种基于潜在空间聚类的数据集蒸馏方法，这种方法在 ImageNet-1K 数据集上相比上一代最优方法 D4M 具有更好的性能和跨模型通用性，并在高每类图像设置中达到了最优性能。使用蒸馏噪声初始化的更强扩散转换器模型，文章在 ImageNet-1K 及其子集上获得了最优的蒸馏性能，超越了扩散引导方法。", "innovation": "提出了一种基于潜在空间聚类的数据集蒸馏方法，将其重新表述为最优量化问题，这种方法在 ImageNet-1K 数据集上相比上一代最优方法 D4M 具有更好的性能和跨模型通用性，并在高每类图像设置中达到了最优性能。这种新的方法在 SOTA 性能方面表现优于其他现有方法，尤其是在更强大的扩散转换器模型中使用蒸馏噪声初始化方面。", "conclusion": "本文提出了一个新的数据集蒸馏方法—数据集蒸馏由最优量化，展示了在 ImageNet-1K 数据集上的优越性能和模型间的一致性，并在高每类图像设置中取得了 SOTA 性能。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19346", "html_url": "https://arxiv.org/abs/2507.19346", "title": "基于多模态嵌入的短格式视频推荐：应对冷启动和偏差挑战", "title_en": "Short-Form Video Recommendations with Multimodal Embeddings: Addressing Cold-Start and Bias Challenges", "authors": "Andrii Dzhoha,Katya Mirylenka,Egor Malykh,Marco-Andrea Buchmann,Francesca Catino", "background": "近年来，社交媒体用户在短格式视频平台上的时间显著增加，促使电子商务等其他领域的平台开始引入短格式视频内容来吸引用户并增加他们在平台上的停留时间。尽管成功很大程度上依赖于内容，但推荐系统的UI创新也起到了重要作用。UI创新改变了用户的操作方式，使推荐系统面临新的挑战，特别是在推出新的视频体验时更为显著。这些挑战包括有限的交互数据、由于UI和观看时间优化而产生的强烈的层级偏差以及模态反馈循环。", "innovation": "本文作者提出了一种新的推荐方法，即使在有丰富视频交互数据的情况下，利用微调的多模态视觉-语言模型的视频检索系统也能更有效地解决这些挑战。该方法在作者的电子商务平台上进行的在线实验中表现出了比传统监督学习方法更好的效果。", "conclusion": "本文强调了在引入新的短格式视频体验时所面临的挑战，并展示了如何利用微调的多模态视觉-语言模型的视频检索系统比传统的监督学习方法更具优势，以克服冷启动和偏差挑战。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05138", "html_url": "https://arxiv.org/abs/2506.05138", "title": "联邦孤立森林：高效的边缘物联网系统异常检测", "title_en": "Federated Isolation Forest for Efficient Anomaly Detection on Edge IoT Systems", "authors": "Pavle Vasiljevic,Milica Matic,Miroslav Popovic", "background": "近年来，为了应对用户隐私问题和嵌入式系统效率降低，出现了诸如Python TestBed for Federated Learning Algorithms和MicroPython TestBed for Federated Learning Algorithms等联邦学习框架。在此基础上，一种基于孤立森林的高效联邦异常检测算法FLiForest被开发出来，适用于边缘设备和持续学习场景。在此基础上，本文进一步应用孤立森林开发了基于联邦学习框架的温度异常检测系统，专为运行 MicroPython 的小边缘设备和物联网系统设计.", "innovation": "开发了一种基于孤立森林的联邦异常检测算法FLiForest，特别考虑了资源受限的环境，能够在保持数据隐私和协作学习的原则下，提高边缘物联网系统的异常检测效率。通过实验验证，该模型在正常与异常值区分上准确率超过96%，检测精度在78%以上，同时在模型训练阶段内存使用量低于160 KB，表明了其在资源限制环境中的适用性与高效性.", "conclusion": "本文开发的孤立森林基线联邦异常检测系统，适用于资源受限的边缘设备和物联网系统，实验证明具有96%以上的准确率和78%以上的精度，同时节省了资源而不会影响性能，从而突显其在这些系统中的实际应用潜力，并遵循联邦学习对比每个节点保持私有数据和协作学习的原则."}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03690", "html_url": "https://arxiv.org/abs/2507.03690", "title": "将注意力机制应用于电力网络：走向透明预测", "title_en": "Plugging Attention into Power Grids: Towards Transparent Forecasting", "authors": "Eloi Campagne,Itai Zehavi,Yvenn Amara-Ouali,Yannig Goude,Argyris Kalogeratos", "background": "可靠的电力需求预测在保障电网稳定性和指导发电决策中发挥着关键作用，随着现代系统的分散化和复杂化，这一需求愈发突出。虽然如广义加性模型（GAM）等经典方法仍然广泛使用，但它们往往无法捕捉能源网络中存在的空间依赖性。图神经网络（GNN）提供了一种原理性的框架，可以通过直接利用图拓扑结构来解决这一问题。", "innovation": "研究评估了包括GCN、GraphSAGE、ChebConv、TAG、APPNP、TransformerConv以及图注意网络（GAT和GATv2）在内的多种GNN架构在法国和英国的实际电力消费数据集上的性能。研究发现，简单模型如GCN、GraphSAGE或APPNP在低数据条件下通常优于更为复杂的模型，而GAT在基准测试中表现出色，结合了高准确性和解释性。此外，研究还表明基于集合的方法，特别是自下而上的组合策略，显著提高了模型的鲁棒性并在两个数据集上取得了最新的性能。", "conclusion": "研究突显了GNNs在准确性和解释性预测中的双重优势，并指出结构简单与集合方法相结合可以提供一种实现透明能源分析的实际路径。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.20790", "html_url": "https://arxiv.org/abs/2506.20790", "title": "Stochastic Parameter Decomposition", "title_en": "Stochastic Parameter Decomposition", "authors": "Lucius Bushnaq,Dan Braun,Lee Sharkey", "background": "逆向工程神经网络的一个关键步骤是将其分解为更简单的部分，以便相对独立地进行研究。Linear Parameter Decomposition框架提出了一种解决当前分解方法中某些问题的方法，分解神经网络参数为参数空间中稀疏使用的向量之和。然而，该框架中的主要方法，基于归属性分解（APD），由于计算成本高且对超参数敏感而不太实用。", "innovation": "本文介绍了一种名为Stochastic Parameter Decomposition（SPD）的新方法，该方法比APD更具 scalability 和对超参数的鲁棒性。我们通过将模型分解为比APD可分解的大且复杂的模型来展示了这种方法的有效性。SPD还避免了APD中的参数缩小和更好地识别玩具模型中的真实机制。通过将因果中介分析与网络分解方法相结合，SPD为线性参数分解方法扩展到更大模型提供了新的研究机会。", "conclusion": "SPD通过消除线性参数分解方法扩展到更大模型的障碍，为机制可解释性研究打开了新的可能性。我们已经开发了一个能够运行SPD并重现实验的软件库，网址为this https URL。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06469", "html_url": "https://arxiv.org/abs/2507.06469", "title": "使用双视图图表示学习缓解欺诈检测中的信息不平衡", "title_en": "Mitigating Message Imbalance in Fraud Detection with Dual-View Graph Representation Learning", "authors": "Yudan Song,Yuecen Wei(Co-first author),Yuhang Lu,Qingyun Sun,Minglai Shao,Li-e Wang,Chunming Hu,Xianxian Li,Xingcheng Fu", "background": "图表示学习因其强大的表达能力已成为欺诈检测的主流方法。这种方法侧重于通过改进邻域知识获取来增强节点表示。然而，这种侧重于局部交互的策略导致全球拓扑信息不平衡传播，并且由于欺诈节点和良性节点之间的不平衡，在聚合时增加了节点特定信息被压倒的风险。本文针对这一问题，总结了拓扑结构和类别不平衡对基于GNN的欺诈检测下游任务的影响，并提出了一种新的双视图图表示学习方法来缓解欺诈检测中的信息不平衡问题。", "innovation": "提出了一个新颖的双视图图表示学习方法MimbFD，以缓解欺诈检测中信息的不平衡问题。具体地，设计了一个拓扑消息可达性模块，用于高质量的节点表示学习，穿透欺诈者的伪装，增强节点表示与标签之间的稳定关联。引入了一个局部共变量偏差消除模块，调整节点表示，从而平衡不同类别之间的影响。", "conclusion": "对三个公开的欺诈数据集进行了实验，结果表明，MimbFD在欺诈检测方面表现出色。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01115", "html_url": "https://arxiv.org/abs/2506.01115", "title": "随机注意力是否足以进行序列建模？理解Transformer中的可训练组件", "title_en": "Is Random Attention Sufficient for Sequence Modeling? Disentangling Trainable Components in the Transformer", "authors": "Yihe Dong,Lorenzo Noci,Mikhail Khodak,Mufan Li", "background": "Transformer架构是现代大型语言模型成功的关键，特别是由于其通过基于梯度的学习来预测下一个标记，能够执行广泛的任务（包括数学推理、记忆和检索）。虽然自注意力机制是Transformer的核心组件，但本文质疑其性能提升有多少以及哪些方面可以归因于自注意力机制。为了进一步探讨这一点，作者对比了标准Transformer变体，在这些变体中，MLP层或注意力权重在初始化时被冻结。研究发现，即使在注意力权重固定的情况下，注意力机制仍然能够形成有效的推理头部，且在语言建模任务上表现出色。因此，作者进一步设计了一个名为MIXIT的架构，其完全使用随机注意力得分，结果表明MIXIT架构在信号稳定传播方面取得了突破。通过对MIXIT的成功和失败的分析，作者试图将Transformer的每个组件的作用分离出来，如自注意力主要负责现场推理，而MLP则负责知识存储，并与自注意力协作。研究结果表明，Transformer架构具有内置的归纳偏见，即使没有可学习的注意力权重，也能形成专门的电路。", "innovation": "1. 研究发现，即使在注意力权重固定的情况下，注意力机制仍然能够形成有效的推理头部，并在语言建模任务上表现出色。\n2. 设计了MIXIT架构，这是一种完全使用随机注意力得分的架构，解决了随机Transformer在深度扩展方面的挑战，实现了信号稳定传播。\n3. 通过MIXIT的实验结果探讨了Transformer中每个组件的作用，得出自注意力主要负责现场推理，而MLP则负责知识存储，并与自注意力协作的结论。", "conclusion": "研究结果进一步表明，Transformer架构具有内置的归纳偏见，即使没有可学习的注意力权重，也能形成专门的电路，这一发现对于理解Transformer及其变体的工作原理以及优化模型设计具有重要意义。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18102", "html_url": "https://arxiv.org/abs/2505.18102", "title": "如何发布我的大语言模型基准而不泄露真实答案？", "title_en": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "authors": "Takashi Ishida,Thanawat Lodkaew,Ikko Yamane", "background": "发布大语言模型（LLM）基准时存在泄露未来模型的风险：该基准可能会被无意中（或故意）用于训练或选择模型。常见的缓解措施是保持基准的私密性，让参与者向主办方提交模型或预测。然而，这种方法需要对单一组织的信任，并仍允许通过反复查询以数据集过度拟合。因此，本文提出了一种新的方法，在不完全披露问题正确答案的情况下发布基准，同时仍能公开评估大语言模型。主要想法是通过准备多个逻辑正确的答案并只在基准中包括一个作为解决方案来注入随机性，从而降低最佳可能准确性，即贝叶斯准确性，这种方法不仅有助于保护信息不被完全泄露，也提供了一种检测数据污染的测试手段。理论上，即使是非常强大的模型也不应超过贝叶斯准确性。如果有模型超越这一限制，这可能是数据污染的强烈信号。实验结果表明，本方法能够在广泛领域内准确检测数据污染，适用于各类基准、模型和训练方法。", "innovation": "提出了在不完全披露问题正确答案的情况下发布基准的新方法，通过准备多个逻辑正确的答案并在基准中随机包括一个答案来注入随机性，从而降低最佳可能准确性。这种方法不仅能保护信息不被完全泄露，还能提供一种检测数据污染的方法。", "conclusion": "实验证明，本方法能够在广泛领域内准确检测数据污染，适用于各种基准、模型和训练策略。此方法能够有效检测模型是否由于数据污染而超出预期的贝叶斯准确性界限。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08537", "html_url": "https://arxiv.org/abs/2507.08537", "title": "递归奖励聚合", "title_en": "Recursive Reward Aggregation", "authors": "Yuting Tang,Yivan Zhang,Johannes Ackermann,Yu-Jie Zhang,Soichiro Nishimori,Masashi Sugiyama", "background": "在强化学习（RL）中，使智能体行为与特定目标相一致通常需要精心设计奖励函数，但当目标复杂时，这种设计可能具有挑战性。本文提出了一种替代方法，通过选择适当的奖励聚合函数来灵活调整智能体行为，从而避免修改奖励函数的需要。通过引入马尔可夫决策过程（MDPs）的代数视角，我们展示了Bellman方程如何自然地从奖励的递归生成和聚合中产生，允许从标准折现求和推广到其他递归聚合方式，如折现最大值和夏普比率。这种方法适用于确定性和随机性设置，并可无缝结合基于价值和演员-评论家算法。实验结果表明，本文方法能够有效地优化各种目标，突显其灵活性及其在实际应用中的潜力。", "innovation": "本文提出了一种新的奖励聚合函数方法，通过选择适当的奖励聚合函数来避免修改奖励函数，从而更加灵活地调整智能体行为。这种方法通过引入代数视角，自然地从奖励的递归生成和聚合中产生了Bellman方程，允许从标准折现求和推广到其他递归聚合方式，适用于多种设置并可与多种算法无缝结合。实验结果证明了该方法的有效性与通用性。", "conclusion": "本文的方法在优化多样目标方面表现出色，强调了其灵活性和实际应用潜力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.01426", "html_url": "https://arxiv.org/abs/2508.01426", "title": "UniExtreme：极端天气预报的通用基础模型", "title_en": "UniExtreme: A Universal Foundation Model for Extreme Weather Forecasting", "authors": "Hang Ni,Weijia Zhang,Hao Liu", "background": "近期深度学习的进展促进了天气预测中基础模型（FMs）的发展，尤其是在天气预报领域。然而，这些模型在预测极端天气事件方面的能力仍然有限。现有方法要么集中于一般的天气状况，要么专注于特定类型的极端事件，忽视了现实世界中多种多样极端事件的不同大气模式。这项研究识别了极端事件的两个关键特征，并提出了一种名为UniExtreme的通用极端天气预报基础模型。", "innovation": "UniExtreme模型引入了两种创新模块：(1)自适应频率调制（AFM）模块，该模块通过可学习的贝塔分布滤波器和多粒度频谱聚合来捕捉正常天气和极端天气在不同地区间的频谱差异；(2)事件先验增强（EPA）模块，该模块通过双层次记忆融合网络将特定地区的极端事件先验知识融入预报中，以解决层级极端多样性及其复合极端模式的问题。实验表明，UniExtreme在极端天气和常规天气预报中都优于现有基准模型，展现出在各种极端场景中的优越适应性。", "conclusion": "UniExtreme在极端天气预测中的表现优于现有最先进的基准模型，展示了其在多种复杂极端情况下的强大适应性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18826", "html_url": "https://arxiv.org/abs/2508.18826", "title": "SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation", "title_en": "SWiFT: Soft-Mask Weight Fine-tuning for Bias Mitigation", "authors": "Junyu Yan,Feng Chen,Yuyang Xue,Yuning Du,Konstantinos Vilouras,Sotirios A. Tsaftaris,Steven McDonagh", "background": "最近的研究表明，机器学习模型在实际应用场景中可能存在偏差，这对敏感领域如医疗保健等的伦理构成了重大挑战。这种偏差可能会消极影响模型的公平性和泛化能力，同时也可能加剧社会歧视。因此，需要减少模型中的偏见。现有的去偏方法通常需要原始训练数据，并需要重新训练整个模型；它们通常会在模型公平性和判别性能之间权衡。", "innovation": "本文提出了一种名为SWiFT（Soft-Mask Weight Fine-Tuning）的去偏见框架，能够有效地提高公平性同时保留判别性能，并且具有大大减少去偏成本的特点。SWiFT只需要少量外部数据集和少量几个模型微调周期。SWiFT的核心思想是首先找到模型参数对偏见和预测性能的相对但又独特的贡献，并通过两步微调过程以不同的梯度流动更新每个参数。", "conclusion": "通过使用SWiFT，作者在三个敏感属性（性别、肤色、年龄）上的四个皮肤病学和两个胸部X光数据集上进行了广泛实验，结果表明SWiFT在常见公平性和准确性指标下，在减少模型偏差的同时可以实现竞争力甚至优越的诊断准确性。特别地，我们展示了模型的泛化能力得到了提高，体现在对多个未见过的分布（OOD）数据集上表现更优。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09523", "html_url": "https://arxiv.org/abs/2507.09523", "title": "行动价值时差方法的学习状态值分析", "title_en": "An Analysis of Action-Value Temporal-Difference Methods That Learn State Values", "authors": "Brett Daley,Prabhat Nagarajan,Martha White,Marlos C. Machado", "background": "时差(TD)学习的核心特点是利用价值预测生成新的价值预测。大多数TD控制方法仅通过一个行动价值函数（如Q-learning和Sarsa）进行自举学习。然而，较少关注利用两个不对称价值函数进行自举学习的方法，即在学习行动价值之前先学习状态价值的算法。这些算法目前已分为QV-learning和AV-learning两大类。尽管已有一定的研究，但不清楚为何要学习两个价值函数而非一个，以及这种做法的理论基础是否可靠。", "innovation": "本文分析了这些算法系列的收敛性和样本效率。发现两种算法系列都比Expected Sarsa在预测环境中更有效，但在控制环境中，仅AV-learning方法在性能上有明显提升。此外，提出了新的AV-learning算法——正则化对赛Q学习（RDQ），该算法在MinAtar基准测试中显著优于Dueling DQN。", "conclusion": "虽然两种算法家族在预测问题中表现更优，但仅AV-learning方法在控制问题中带来了显著的优势。此外，作者引入了RDQ算法，并证明其在MinAtar基准测试中明显优于Dueling DQN。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17675", "html_url": "https://arxiv.org/abs/2508.17675", "title": "使用生成型多模态大型语言模型合成认知评估的规范性数据", "title_en": "Towards Synthesizing Normative Data for Cognitive Assessments Using Generative Multimodal Large Language Models", "authors": "Victoria Yan,Honor Chotkowski,Fengran Wang,Xinhui Li,Jessica Saurman,Fadi Nahab,David Loring,Carl Yang,Jiaying Lu,Runze Yan,Xiao Hu,Alex Fedorov", "background": "认知评估需要规范数据作为基准来评估个体表现。由于缺乏现成的规范数据，以新的图像刺激为基础开发新的认知测试具有挑战性。传统数据收集方法成本高昂、耗时且更新不频繁，限制了其实用性。近年来，生成型多模态大语言模型（MLLMs）的发展为从现有认知测试图像生成合成规范数据提供了一种新方法。本文调查了使用特定的MLLMs（如GPT-4o和GPT-4o-mini）和不同类型提示生成图像认知评估现有任务（如“偷饼干”图片描述任务）的规范性文本响应的可行性。", "innovation": "本文创新性地使用生成型多模态大型语言模型来合成认知评估的规范性数据，探讨了使用不同的提示策略（朴素提示和高级提示）生成更为有效的合成响应。研究结果表明，高级提示方法生成的合成响应更能区分诊断组，捕捉到更广泛的群体差异，且模型生成的响应表现出更高的真实性和多样性。", "conclusion": "研究结果证明，通过精细提示方法引导的生成型多模态大型语言模型可以有效生成现有的认知测试规范性数据，为开发新的基于图像的认知评估奠定了基础，从而绕过了传统方法的限制。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12070", "html_url": "https://arxiv.org/abs/2507.12070", "title": "孤立于有方向性的功能的量化表示的产生", "title_en": "Emergence of Quantised Representations Isolated to Anisotropic Functions", "authors": "George Bird", "background": "该研究基于现有的Spotlight Resonance方法，提出了一种新颖的方法来确定表示结构。通过仅改变激活函数来进行控制消除研究，该方法被用于研究离散表示如何在自动编码器模型中出现和组织，并验证功能驱动的对称性是否可以作为隐式的归纳偏置。研究表明，在定义激活函数时使用离散代数置换共变对称性导致表示离散化，而在连续的代数正交共变定义下，表示保持连续。这证实了网络原始层对称性可能携带未被预期的归纳偏置，通过导致无任务解释结构而产生潜在的问题。此外，发现当代代数结构的离散对称性是量化表示从持续分布中出现的强烈预测因素——这是一种量化效应。这促使对在这些不受控制后果影响的常见函数形式进行进一步的重新评估，并支持了一种可能构成下游可解释现象先决条件的一般因果模型，包括祖母神经元、离散编码方案、通用线性特征和可能的叠加现象。该研究工具及其对表示的影响力可能为解释力研究提供有价值的见解。初步结果显示，表示的量化似乎与重构误差的可测量增加呈正相关，这支持了这种崩溃可能是有害的观点。", "innovation": "提出了一个新颖的方法来确定表示结构，特别关注激活函数的变化对表示离散化的影响。研究通过证明离散对称性对激活函数的依赖性和对表示的影响来验证功能驱动的对称性如何成为隐式归纳偏置。该研究还提出了一种一般性因果模型，解释了离散和连续分布之间的转换机制，这为进一步的实证研究提供了基础。这项研究的独特之处在于其通过改变激活函数来控制消融研究的方式，从而揭示了功能形式对表示结构的影响，并提供了一种新的机制来解释离散表示的生成情况和潜在的下游可解释现象，如祖母神经元、离散编码、一般线性特征和叠加。", "conclusion": "该研究提供了一种新的方法来研究离散表示的产生机制，并发现离散对称性对激活函数的选择有显著影响。研究结果支持了一个一般性因果模型，该模型描述了离散表示如何在连续分布中出现和组织。初步证据还表明，表示的离散化可能导致可测量的重构误差增加，这支持了之前的观点认为这种损失可能不利于模型的表现。进一步的研究需要评估这些发现对不同神经网络架构的有效性，并探索如何设计神经网络结构以减少这种不利影响。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07809", "html_url": "https://arxiv.org/abs/2508.07809", "title": "EvoCoT: 克服强化学习中的探索瓶颈", "title_en": "EvoCoT: Overcoming the Exploration Bottleneck in Reinforcement Learning", "authors": "Huanyu Liu,Jia Li,Chang Yu,Taozhi Chen,Yihong Dong,Lecheng Wang,XiaoLong Hu,Ge Li", "background": "基于强语言模型的回推学习(Reinforcement Learning with Verifiable Reward, RLVR)已成为提高大型语言模型(LLM)推理能力的一种有前途的后训练范式。然而，在解决复杂问题时，由于 rollout 准确率低，导致奖励稀疏，限制了学习效率并引发了探索瓶颈。现有的方法要么依赖更强的 LLM 进行知识蒸馏，要么淘汰难度大的问题，这既限制了可扩展性，又限制了通过探索提高推理能力。现有的方法也存在局限性，要么依赖更强的 LLM 进行知识蒸馏，要么筛选掉难度大的问题，这既限制了可扩展性，又限制了通过探索提高推理能力。", "innovation": "我们提出了基于两阶段思维链优化（Two-stage Chain-of-Thought, CoT）的自演化课程学习框架 EvoCoT。EvoCoT 通过自我生成和验证 CoT 轨迹来约束探索空间，然后逐步缩短这些轨迹以在受控的方式扩大探索空间。这使 LLM 能够从初始未解决的难题中稳定地学习，并在稀疏奖励下也能学习。我们把 EvoCoT 应用于多个 LLM 家族，如 Qwen、DeepSeek 和 Llama。实验结果显示，EvoCoT 可以使 LLM 解决以前无法解决的问题，增强推理能力而不需要外部 CoT 监督，并且兼容各种 RL 微调方法。", "conclusion": "EvoCoT 启用 LLM 解决以前未解决的问题，增强推理能力而不需要外部 CoT 监督，并且兼容各种 RL 微调方法。我们提供源代码支持未来研究。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20293", "html_url": "https://arxiv.org/abs/2508.20293", "title": "Beacon: 基于集成网格选择的后训练量化", "title_en": "Beacon: Post-Training Quantization with Integrated Grid Selection", "authors": "Shihao Zhang,Rayan Saab", "background": "后训练量化（PTQ）是一种广泛应用于减少大模型内存和计算成本的压缩技术。通过量化，可以用较小的整数表示原来的权重值，从而降低存储和计算需求。但在每通道后训练量化中，如何选择合适的缩放因子是一个关键挑战，这些缩放因子用于将权重值替换为量化整数网格上的值。现有方法通常通过启发式调优或网格搜索预先固定缩放因子。这需要大量的人工调优工作。为了简化这个过程，作者提出了Beacon算法。", "innovation": "Beacon通过利用标量量化几何性质，在不依赖反向传播或大量校验集的情况下，直接进行每通道的后训练量化以自动确定最优的缩放因子，从而简化了量化过程并提高了效率。Beacon算法不需要手动调优，具有简洁性和有效性，能与最先进的方法相比实现可竞争的性能，解决了选定缩放因子的挑战并提供了一种针对高效模型部署的实用解决方案。", "conclusion": "Beacon通过利用标量量化几何性质，直接在不缩放的整数网格上进行每通道的后训练量化，并自动确定最优缩放因子，从而简化了量化过程。与最先进的方法相比，Beacon实现了可竞争的性能，提供了一种用于高效模型部署的实用解决方案。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13755", "html_url": "https://arxiv.org/abs/2508.13755", "title": "RLVR深度-广度协同效应：通过自适应探索解锁大规模语言模型推理收益", "title_en": "Depth-Breadth Synergy in RLVR: Unlocking LLM Reasoning Gains with Adaptive Exploration", "authors": "Zhicheng Yang,Zhijiang Guo,Yinya Huang,Yongxin Wang,Dongchun Xie,Yiwei Wang,Xiaodan Liang,Jing Tang", "background": "Reinforcement Learning with Verifiable Reward (RLVR)作为强大的模型推理能力开发方法已经出现，但其潜力受限于两个尚未充分探索的方面：深度（模型能解决的最复杂问题）和宽度（单次迭代中消耗的实例数量）。GRPO算法中存在系统性偏差：累积优势偏向中等准确性的样本，而低估了对于扩展推理边界至关重要的低准确度样本。简单地扩大回放规模只能加速收敛，甚至损害了Pass@K的表现。通过引入难度自适应回放采样（DARS），在多阶段回放中重新平衡困难问题的权重，提高了困难问题的正面回放比例。深度大尺度训练维持高令牌级熵，表明持续探索和减少梯度噪声。RLVR的深度和自适应探索在这场研究中是两个关键维度，它们能够协同作用，解锁RLVR的推理潜力。", "innovation": "本研究通过引入难度自适应回放采样（DARS）算法，动态调整卷积大小及全面更新，以解决深度和宽度不足的问题。DARS不仅解决了深度问题，还同时提高了Pass@K和Pass@1的表现，表明深度和自适应探索是RLVR中两个相互独立的关键维度，可以分别被优化以增强推理能力。通过论文还发现，增加宽度能够显著提高Pass@1性能，因为大规模训练保持了高令牌级熵，持续进行了探索性更强的训练。最后，提出了具备大宽度的DARS-B算法，展示了该方法在提升多种准确率指标的同时降低了额外推理成本。", "conclusion": "本研究提出了RLVR的深度-广度协同效应，通过引入难度自适应回放采样（DARS）算法和动态调整数据量的策略，提高了大型语言模型的推理能力。结果表明，深度和自适应探索是互不干扰且关键的维度，能够共同发挥作用，从而解锁RLVR的潜在推理能力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22832", "html_url": "https://arxiv.org/abs/2507.22832", "title": "揭开ReLU网络的面纱", "title_en": "Pulling Back the Curtain on ReLU Networks", "authors": "Maciej Satkiewicz", "background": "由于任何ReLU网络都是分段仿射的，其隐藏单元可以通过其梯度（至偏差项）来表征，具体来说是通过激活子网络的拉回。然而，深层神经元的梯度通常会严重错位，这使得网络的内部表示变得模糊。本文作者提出，模型确实将梯度与数据对齐，但实际上这种对齐被ReLU硬门控的固有噪声所掩盖。通过实验验证了这一直觉：仅在反向传播过程中使用软门控，可以减少弱激活神经元的局部影响，从而产生与数据更对齐的修改梯度，称为‘激活拉回’，并在多个预训练的ImageNet架构上表现出显著的感知对齐效果，单像素空间梯度上升也非常容易产生可解释的输入和目标特定特征。这些发现启发了‘路径稳定性’假设，假设二元激活模式在训练过程中基本稳定，并被最后模型的预激活分布编码，当此假设为真时，‘激活拉回’将与主要决定网络决策的核机梯度对齐，这为基于‘激活拉回’的特征归因的似乎信实提供了理论依据，有可能甚至能够有效地解析深层模型的机制性可解释性。此外，对批量归一化和深度特征的有效性提供了一种新的解释，并从新的角度探讨了网络的内部记忆和泛化特性。", "innovation": "提出了仅在反向传播过程中使用软门控以减少弱激活神经元的局部影响的方法，从而生成与数据更对齐的修改梯度，称为‘激活拉回’（Excitation Pullbacks）。这种方法在多个预训练的ImageNet架构上表现出显著的感知对齐效果，并且单像素空间梯度上升也极易产生可解释的输入和目标特定特征。此外，这篇文章提出了‘路径稳定性’假设，即二元激活模式在训练过程中基本稳定，并被最后模型的预激活分布编码。这可以进一步解释基于‘激活拉回’的特征归因为何看似信实，并提升了深层模型的机制性可解释性。", "conclusion": "‘激活拉回’可以提供理论依据，为特征归因的信实性提供解释，并可能为深层模型的机制性可解释性提供实际解决方案。此外，还对批量归一化和深度特征的有效性提供了一种新的解释，并讨论了网络的内部记忆和泛化特性。本文的所有代码和互动应用程序都提供了更方便的‘激活拉回’探索工具。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02565", "html_url": "https://arxiv.org/abs/2509.02565", "title": "在特征流形存在下的稀疏自编码器缩放理解", "title_en": "Understanding sparse autoencoder scaling in the presence of feature manifolds", "authors": "Eric J. Michaud,Liv Gorton,Tom McGrath", "background": "稀疏自动编码器（SAEs）将神经网络的激活建模为稀疏方向上的线性组合。关于SAE重新构建激活的能力遵循与潜在因子数量相关的缩放法则。已有研究表明，特征流形对SAE的缩放行为有显著影响。", "innovation": "本文从神经网络缩放文献中引入容量分配模型，用以理解SAE的缩放机制，特别关注特征流形如何影响缩放行为。该模型揭示了不同的缩放阶段，并指出在某些阶段，特征流形会导致SAE学到的特征少于SAE内部的潜在因子数量。", "conclusion": "模型发现SAE在某些情况下可能会进入一个病态阶段，即SAE学到的特征数量少于其潜在因子数量。文章初步讨论了实际情况中是否存在这种病态阶段。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00616", "html_url": "https://arxiv.org/abs/2509.00616", "title": "TimeCopilot", "title_en": "TimeCopilot", "authors": "Azul Garza,Reneé Rosillo", "background": "在过去的研究中，时间序列预测框架主要依赖于特定类型的时间序列模型，缺乏对多种时间序列模型和大型语言模型的整合。此外，现有的系统在自动化预测流程、生成自然语言解释以及支持直接未来查询方面存在不足。TimeCopilot旨在填补这些空白，提供一个开源的代理框架，结合多种时间序列基础模型（TSFMs）和大型语言模型（LLMs），并通过一个统一的API来实现自动化预测管道，包括特征分析、模型选择、交叉验证和预测生成，并提供自然语言解释和直接未来查询支持。该框架兼容商业和开源大型语言模型，支持跨不同预测家庭的集成。", "innovation": "TimeCopilot是第一个将多种时间序列基础模型与大型语言模型结合在一起的开源代理框架，并通过统一的API自动化时间序列预测流程。它实现了特征分析、模型选择、交叉验证和预测生成的自动化，同时提供自然语言解释和直接未来查询支持。该框架对大型语言模型无依赖性，兼容商业和开源大型语言模型，并支持跨不同预测家庭的集成。实验结果表明，TimeCopilot在大型基准测试GIFT-Eval上实现了最先进的概率预测性能，且成本较低。", "conclusion": "TimeCopilot为可重复、可解释和可访问的时间序列预测系统提供了一个实用的基础，通过自动化预测流程和自然语言解释，提高了预测系统的效率和透明度。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03249", "html_url": "https://arxiv.org/abs/2509.03249", "title": "结构转移：一种基于推理的表示转换计算", "title_en": "Structure Transfer: an Inference-Based Calculus for the Transformation of Representations", "authors": "Daniel Raggi,Gem Stapleton,Mateja Jamnik,Aaron Stockdill,Grecia Garcia Garcia,Peter C-H. Cheng", "background": "表示选择对于有效的沟通和推理至关重要。本文的主要未解问题是如何设计代表系统（RS）无关的技术来驱动表示转换和选择。现有的方法主要关注特定领域内的表示转换，缺乏跨越不同表示系统的通用方法。结构转移提出了一种新型的计算方法，旨在实现跨不同表示系统的表示转换，并确保转换后的表示满足指定关系（如语义等价）", "innovation": "结构转移提供了一种使表示系统无关的技术，允许根据给定的来源表示生成目标表示。该计算方法通过利用编码了表示系统知识的模式，确保了源表示和生成的目标表示之间满足指定关系，特别强调构造空间的抽象性质，使得结构转移能够广泛应用在各种类型的表示系统中，包括形式语言、几何图和图表，以及非正式的符号系统", "conclusion": "结构转移是一种系统无关的计算方法，可以广泛应用于不同表示系统的表示转换，从而确保所选表示之间的关系满足所需要求。通过该方法，可以有效地找到不同表示系统下的等效或近似等效表示，为实际应用提供了新的工具和视角"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03497", "html_url": "https://arxiv.org/abs/2509.03497", "title": "全局作物类型分类中的不变特征", "title_en": "Invariant Features for Global Crop Type Classification", "authors": "Xin-Yi Tong,Sherrie Wang", "background": "准确获取全球范围内的作物类型及其空间分布对粮食安全、农业政策制定以及可持续发展至关重要。遥感提供了大规模作物分类的有效解决方案，但由于许多地区可靠地面样本的缺失，适用范围受到限制。为了应对地理空间变化导致的性能下降，本研究识别出不受地理变异影响的遥感特征，并提出增强跨区域泛化性的策略。为此，我们构建了CropGlobe数据集，涵盖了六个主要食品和工业作物（玉米、大豆、稻米、小麦、甘蔗、棉花）在五大洲八个国家的30万个像素级样本，实现了跨国、跨洲及跨半球的系统评估。", "innovation": "我们对比了多时相多光谱特征（以Sentinel-2为基础的一维/二维中值特征和谐波系数）和高光谱特征（来自EMIT）的转移性，并设计了一种专用于像素级作物分类的轻量级且稳健的CNN（CropNet），结合了时间变化、时间尺度和幅度变换等时间数据增强技术。研究表明，Sentinel-2的一维中值二维特征在所有转移场景中均展现出最强的不变性，而增强技术则在训练数据多样性有限时进一步提高了鲁棒性。", "conclusion": "我们的工作识别出了更多不变特征表示，增强了地理上的转移能力，并指出了实现全球多样化地区可扩展且低成本的作物类型应用的有前景路径。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03335", "html_url": "https://arxiv.org/abs/2509.03335", "title": "EvolveSignal：一种基于大规模语言模型的编码代理用于发现交通信号控制算法", "title_en": "EvolveSignal: A Large Language Model Powered Coding Agent for Discovering Traffic Signal Control Algorithms", "authors": "Leizhen Wang,Peibo Duan,Hao Wang,Yue Wang,Jian Xu,Nan Zheng,Zhenliang Ma", "background": "在交通工程中，固定时间的交通信号控制由于其低成本、稳定性和可解释性而广为使用。然而，它的设计依赖于手工编写的公式（如韦伯公式）和工程师的手动调整，以适应需求变化，这不仅劳动密集型，而且在异质或拥堵条件下往往会得出次优结果。", "innovation": "本文介绍了一种名为EvolveSignal的大型语言模型（LLMs）驱动的编码代理，用于自动发现新的交通信号控制算法。本文通过将问题表述为程序合成，并利用外部评估（例如交通模拟器）和进化搜索逐步优化候选算法，实现了这一目标。实验结果显示，发现的算法在自动交叉口上优于韦伯基线，平均延误减少了20.1%，平均停车数减少了47.1%。除了性能，删减和增量分析表明，EvolveSignal的修改，如调整周期长度限制、纳入右转需求和重新调整绿色时间分配，可以提供实际有价值的见解供交通工程师参考。", "conclusion": "本文通过利用AI进行交通信号控制中算法设计的新研究方向，为程序合成与运输工程的结合开辟了一个新的研究方向。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02846", "html_url": "https://arxiv.org/abs/2509.02846", "title": "基于奖励模型的推理时扩展算法：PDE基础模型中的推理", "title_en": "Towards Reasoning for PDE Foundation Models: A Reward-Model-Driven Inference-Time-Scaling Algorithm", "authors": "Siddharth Mansingh,James Amarel,Ragib Arnab,Arvind Mohan,Kamaljeet Singh,Gerd J. Kunde,Nicolas Hengartner,Benjamin Migliori,Emily Casleton,Nathan A. Debardeleben,Ayan Biswas,Diane Oyen,Earl Lawrence", "background": "偏微分方程（PDEs）是现代计算科学与工程的基础，计算成本高昂。现有的PDE基础模型在模拟复杂的时空现象方面显示出很大的潜力，但在预训练数据集的限制下，它们缺乏自回归回放性能，特别是在分布外（OOD）情况下。此外，这些模型对计算资源和训练数据的需求限制了它们在许多关键应用中的使用。", "innovation": "本文引入了一种新的测试时计算（TTC）策略，利用推理时的计算资源来实现更准确的预测，具有较少的训练样本和更小的模型。这种方法使用两种类型的语言奖励模型来评估基于随机的时空一致性预测。通过这种方法在PDEGym基准上的可压缩欧拉方程模拟中得到了改进的预测结果，与标准的非自适应自回归推断相比有所提升。这标志着向更先进的基于推理的方法或PDE建模迈进了一步，包括构建基于强化学习的方法，可能彻底改变物理和工程中的计算工作流。", "conclusion": "这种TTC框架代表了对更高级的PDE建模背后更复杂的推理算法的一个关键步骤，包括建立基于强化学习的方法，潜在地变革物理和工程中的计算工作流。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2008.07324", "html_url": "https://arxiv.org/abs/2008.07324", "title": "智慧入门", "title_en": "Intelligence Primer", "authors": "Karl Fezer,Andrew Sloss", "background": "智慧是所有生物的基础，也是人工智能的基石。本文旨在探讨与智慧相关的想法，从而理解其含义、影响和限制，并可能勾勒出未来系统的潜在能力。机器学习形式的 AI 已经对我们的生活产生了重大影响。本文将探索关于智慧的不同方面，这些方面似乎是必不可少的。此外，现代社会发展和法律法规推动了心理学、哲学和伦理学等更广泛学科的发展。从介绍智慧开始，文章迅速转向更深刻的思考与理念，将其称为‘生命、宇宙和一切’入门，借鉴了道格拉斯·亚当斯的经典科幻小说标题。", "innovation": "本文试图将生物学、物理学、哲学、认知科学、神经科学、心理学和计算机科学等多学科的概念结合起来，以理解智慧的多维度，并探索机器学习形式的 AI 的影响与未来可能性。文章强调了未来工程师和科学家需要更广泛地理解包括心理学、哲学和伦理学在内的领域，这可能是创新点之一。同时，在探讨智慧定义和影响的同时，提出了许多激发人们思考的新问题，这也是文章的创新之处", "conclusion": "虽然“42”可能是正确答案，但我们更应该关注和明确这些问题是什么，以更好地理解智慧的本质及其在生物世界和未来人工智能系统中的角色。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.16507", "html_url": "https://arxiv.org/abs/2311.16507", "title": "基于扩散模型耦合先验的更直流动态流匹配", "title_en": "Straighter Flow Matching via a Diffusion-Based Coupling Prior", "authors": "Siyu Xing,Jie Cao,Huaibo Huang,Haichao Shi,Xiao-Yu Zhang", "background": "动态流匹配作为一种生成模型范式，在多个领域取得了显著的成功。然而，现有方法要么依赖多轮训练，要么在小批量内的知识，这些方法都难以找到一种适合的耦合策略，使得生成过程中的轨迹能够整齐排列并符合多步生成的需求。", "innovation": "本文提出了一个新的方法——StraightFM（更直流动态流匹配），通过一个扩散模型创建图像与噪声之间的耦合先验来修正轨迹，使生成过程中的轨迹整齐化，并缩短生成时间。本文的方法不仅能够整合现有数据到噪声的耦合方向，提高图像质量，还在像素空间和潜在空间的实验中，证明了在仅5步内就能生成吸引人的样本。此外，无需训练的无条件StraightFM能够无缝兼容多模式条件生成，实现高质量的图像生成。", "conclusion": "实验结果表明，无论是无条件的还是有条件生成，StraightFM在5步内都能生成高质量的图像样本，并且能够无缝整合现有的耦合生成方法，提高图像生成质量。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.15161", "html_url": "https://arxiv.org/abs/2407.15161", "title": "FFHFlow：通过流变区推断生成多样性和不确定性意识的灵巧抓取", "title_en": "FFHFlow: Diverse and Uncertainty-Aware Dexterous Grasp Generation via Flow Variational Inference", "authors": "Qian Feng,Jianxiang Feng,Zhaopeng Chen,Rudolph Triebel,Alois Knoll", "background": "在机器人学习中，从部分观察中合成多样化且具有不确定性意识的多指灵巧抓取仍然是一个关键挑战。先前的生成方法难以建模灵巧手的复杂抓取分布，并且常常未能处理部分点云中存在的形状不确定性，导致不牢靠或过于保守的抓取。", "innovation": "我们提出了FFHFlow，一种基于流的概率变分框架，能够生成多样且鲁棒的多指抓取，同时明确量化部分点云中的知觉不确定性。我们利用归一化流的深度隐变量模型学习层次抓取流形，克服了条件变分自编码器的模式崩溃和刚性先验限制。通过利用流的可逆性和精确似然性，FFHFlow在部分观察中反向思考形状不确定性，并识别新型物体结构，以进行风险意识的抓取合成。此外，我们还整合了一种分类抓取评估器与流似然性，形成了一个不确定性意识的排名策略，优先考虑对形状歧义鲁棒的抓取。", "conclusion": "在模拟和实际环境中的广泛实验表明，FFHFlow在抓取多样性和成功率上优于最先进的基准（包括扩散模型），同时实现了高效的运行时采样。我们还展示了其在拥挤和受限环境中的实用性，多样性的采样通过减少碰撞显著提高了人机安全性（项目页面：https://page.com）"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.17165", "html_url": "https://arxiv.org/abs/2311.17165", "title": "AI中的(不)理性：现状、研究挑战与开放问题", "title_en": "(Ir)rationality in AI: State of the Art, Research Challenges and Open Questions", "authors": "Olivia Macmillan-Scott,Mirco Musolesi", "background": "AI领域中理性概念的核心地位极大地影响了模拟人类推理和实现有界优化的目标。尽管理性概念在AI中的重要性不容忽视，但关于构成理性的定义尚无统一标准。本文提供了关于AI中的理性与非理性的综述，并列出了该领域的开放问题，探讨了理性在其他学科中的理解如何影响AI中的概念，并分析了一些情境下非理性行为可能成为最优行为的情况。", "innovation": "本文提供了一个关于AI中理性与非理性的综述，探讨了利用其他学科（如经济学、哲学和心理学）中关于理性的理解。提出了一些现有方法用来处理非理性的智能代理，同时指出这些方法用于与AI交互时仍存在局限性，提倡借鉴对抗场景中的方法加以改进。", "conclusion": "本文讨论了人类和AI代理间的互动，探讨了理性在其中的作用，并提出了许多与人类和AI代理潜在非理性行为相关的开放问题。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.13115", "html_url": "https://arxiv.org/abs/2408.13115", "title": "高维空间中未调整拉格朗日算法的收敛性：偏差的去本地化", "title_en": "Convergence of Unadjusted Langevin in High Dimensions: Delocalization of Bias", "authors": "Yifan Chen,Xiaoou Cheng,Jonathan Niles-Weed,Jonathan Weare", "background": "未调整拉格朗日算法经常用于在极高维度下采样概率分布。然而，对于强对数凹分布，现有的算法分析表明，随着问题维度 $d$ 的增加，为了保证在 $W_2$ 度量中的误差收敛所需的迭代次数会按比例增加至 $d$ 或 $\boldsymbol{\text{\textasciitilde}}\boldsymbol{\text{\textroot[2]{d}}}$。本文分析指出，在整个变量集上的 $W_2$ 错误表现较差，但对少数变量来说行为可以显著更好：所需的迭代次数最多仅与问题规模的对数项成比例，通常足以保证算法在特定的 $W_2$ 误差范围内收敛。这被称为偏差的去本地化。", "innovation": "本文证明了在高维空间中未调整拉格朗日算法中存在偏差的去本地化现象，并证明了这种现象在高斯分布和具有某些稀疏交互的强对数凹分布中成立。关键的技术挑战在于开发了一种新的 $W_{2,\boldsymbol{\text{\textasciitilde}}\boldsymbol{\text{\textinity}}}$ 度量来衡量收敛性，并解决了这种度量中缺乏一步收缩性质的问题。", "conclusion": "我们通过对稀疏交互下的高斯分布使用渐近方法来探索了偏差去本地化效应对高维度情况下可能的推广。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03056", "html_url": "https://arxiv.org/abs/2509.03056", "title": "ReLU网络的离散功能几何通过ReLU过渡图", "title_en": "Discrete Functional Geometry of ReLU Networks via ReLU Transition Graphs", "authors": "Sahil Rajesh Dhayalkar", "background": "研究团队将ReLU过渡图（RTG）框架扩展为一个全面的图论模型，以便更深入地理解深层ReLU网络。在这种模型中，每个节点代表一个线性激活区域，节点之间的边连接通过单个ReLU激活翻转的不同区域，从而形成网络功能行为的离散几何结构。研究表明，初始随机化RTGs表现出强烈的扩展性、二项式度分布和高度限定泛化能力的光谱特性。这些结构洞察力使得可以通过区域熵确定模型容量的新界限，并通过光谱间隙和边向量相对熵确定泛化的新界限。", "innovation": "传统RTG框架得到扩展，形成一个全面的图论模型以理解和分析深度ReLU网络。证明RTGs在随机初始化时表现出强烈的扩展性，二项式度分布和光谱特性，这些特性对泛化有严格控制。基于这些结构洞察，新的模型容量边界和泛化边界得以建立。", "conclusion": "实验证明区域熵在过度参数化下饱和，光谱间隙与泛化相关，相邻区域间的相对熵反映了功能光滑性。本文提供了一个统一框架，通过离散功能几何分析ReLU网络，为更好地理解和改进泛化提供了新的工具。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.20321", "html_url": "https://arxiv.org/abs/2405.20321", "title": "单个人类视频中的开放世界对象图基于视觉的 manipulation", "title_en": "Vision-based Manipulation from Single Human Video with Open-World Object Graphs", "authors": "Yifeng Zhu,Arisrei Lim,Peter Stone,Yuke Zhu", "background": "在开放世界的背景下，机器人需要从单个视频演示中学习操作新型物体的技能。现有的方法通常依赖专门的视频数据集或特定场景，限制了机器人的泛化能力。本研究探讨了如何使机器人能够从日常移动设备拍摄的视频中学习，以适应不同视觉背景、相机视角、空间布局和新型物体实例的环境。", "innovation": "提出了ORION算法，通过提取单一RGB或RGB-D视频中的对象中心化操作计划，并生成基于提取计划的策略，使得机器人能够使用日常设备拍摄的视频进行学习，并将学到的策略应用到具有多种视觉背景、不同相机角度和空间布局的部署环境中。与现有方法相比，ORION能够更有效地学习单一人类视频中的开放世界对象图。", "conclusion": "通过对短时和长远任务的系统评估，使用RGB-D和RGB演示视频，ORION在各种任务和演示类型中表现出74.4%的平均成功率，证明了其能够有效地从单个人类视频中在开放世界中学习的操作能力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.01228", "html_url": "https://arxiv.org/abs/2410.01228", "title": "ConServe: 细粒度GPU回收用于LLM在线和离线协同服务", "title_en": "ConServe: Fine-Grained GPU Harvesting for LLM Online and Offline Co-Serving", "authors": "Yifan Qiao,Shu Anzai,Shan Yu,Haoran Ma,Shuo Yang,Yang Wang,Miryung Kim,Yongji Wu,Yang Zhou,Jiarong Xing,Joseph E. Gonzalez,Ion Stoica,Harry Xu", "background": "大型语言模型（LLM）需要低延迟和高吞吐量，但由于负载波动性高，实现高GPU利用率具有挑战性。现有的服务系统在细粒度资源管理方面存在不足，无法有效协同服务高优先级的在线请求和低优先级的离线任务。具体来说，在请求或迭代级别进行粗粒度管理会导致在满足在线延迟目标的同时引入干扰，占用GPU的微秒级空闲时间。因此，研究人员需要一种新的系统解决方案来实现这一目标。", "innovation": "ConServe 是一种新的 LLM 协同服务系统，通过在更细的粒度级别管理资源，实现高吞吐量和强在线延迟保证。ConServe 引入了三种技术：（1）一种基于延迟感知的令牌级别调度器，精确调整离线批次和令牌大小，以适应在线延迟目标；（2）子迭代，逐层预emption，使离线任务能够响应在线负载峰值；（3）增量KV缓存管理，允许以接近零成本预emption和恢复离线请求。在真实的Latte-3.1和Qwen-2.5模型工作负载评估表明，与最先进的系统相比，ConServe 提供了2.2倍的平均吞吐量并降低了2.9倍的在线服务尾部延迟。", "conclusion": "ConServe 通过更精细的资源管理实现了 LLM 的在线和离线任务的协同服务，显著提高了系统的吞吐量和在线服务质量。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.14013", "html_url": "https://arxiv.org/abs/2411.14013", "title": "揭露合成语音：通过音频指纹进行模型归因和AI生成语音检测", "title_en": "Exposing Synthetic Speech: Model Attribution and Detection of AI-generated Speech via Audio Fingerprints", "authors": "Matías Pizarro,Mike Laszkiewicz,Shawkat Hesso,Dorothea Kolossa,Asja Fischer", "background": "随着语音生成技术在质量和普及性方面的不断提高，恶意使用案例，包括假冒、信息误导和欺诈等问题正在迅速增加。本文旨在通过提出一种无需训练即可有效检测AI生成语音并将其归因于源模型的方法来应对这一威胁。", "innovation": "本文提出了一种简单但有效的无训练方法，该方法可以识别AI生成的语音并通过与已知模型源的比较进行归因。该方法针对单源归因（开放世界）和多源归因（封闭世界），同时能够检测合成语音与真实语音之间的区别。该方法利用标准化平均残差的独特指纹技术，这些残差能够捕捉到不同语音合成系统引入的特性。", "conclusion": "实验证明，该方法在多数情况下AUROC得分超过99%，在含有真实语音和多种合成语音的增强基准数据集上表现优异。此外，鲁棒性分析表明该方法即使在存在中等噪声时仍能保持高性能。鉴于其简约性、高效性以及对不同语音合成系统和语言的强大泛化能力，该技术为数字法医和安全应用提供了一种实用工具。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.04180", "html_url": "https://arxiv.org/abs/2508.04180", "title": "通过指纹一步进展，从质谱生成新型分子的一大步", "title_en": "One Small Step with Fingerprints, One Giant Leap for De Novo Molecule Generation from Mass Spectra", "authors": "Neng Kai Nigel Neo,Lim Jing,Ngoui Yong Zhau Preston,Koh Xue Ting Serene,Bingquan Shen", "background": "传统上，从质谱数据生成新的分子结构需要一个两阶段的过程：首先将质谱编码为分子指纹，然后将这些指纹解码为分子结构。此前的方法在这个过程中未能有效提升性能。", "innovation": "本文采用了MIST作为编码器和MolForge作为解码器，并通过额外的训练数据提高性能。此外，还对每个指纹位的概率进行了阈值处理，以突出亚结构的存在。这种方法在MassSpecGym数据集上实现了比之前最先进的方法高出十倍的性能提升，成功生成了28%的第一位和36%的前十位正确的分子结构。", "conclusion": "本文将此方法作为未来从质谱数据生成新分子研究的强有力基准。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.06464", "html_url": "https://arxiv.org/abs/2405.06464", "title": "单种子生成布朗路径及其积分以适应高阶SDE求解器", "title_en": "Single-seed generation of Brownian paths and integrals for adaptive and high order SDE solvers", "authors": "Andraž Jelinčič,James Foster,Patrick Kidger", "background": "尽管自适应时间步长在常微分方程（ODEs）模拟中取得了成功，但在随机微分方程（SDEs）模拟中的应用极为有限。用于模拟SDEs的自适应方法，如虚拟布朗运动树（VBT），可以非时序地生成布朗运动（BM）。然而，在大多数应用中，仅知道布朗运动的数值是不够的，还需要计算BM的时间积分，例如 ∫_s^t W_r ̶dr。为了实现高阶SDE求解器的自适应使用，本文扩展了VBT，使其不仅生成BM增量，还能生成这些BM的时间积分。", "innovation": "本文扩展了虚拟布朗运动树（VBT），使之能在单个随机数生成器（PRNG）种子下生成布朗运动及其时间积分，从而使得生成的整个布朗运动路径可以通过单个PRNG种子完全确定。这使得之前生成的样本无需存储，从而使得内存占用保持恒定，同时实现了实验的可重复性和强烈的误差估计。本文还通过二分搜索使得时间复杂度在容差参数ε下为对数级。相比原始VBT算法仅在某些二进制时间点精确，本文的构造能够在任意查询时间点精确匹配布朗运动及其时间积分的联合分布。此外，本文还展示了两个应用实例：一个是使用自适应高阶求解器模拟高波动性的CIR模型，实现的收敛阶数是固定步长的两倍；另一个是在MCMC问题中应用自适应的三阶欠阻尼或动能拉angevin求解器，性能优于No U-Turn Sampler且函数评估次数仅为后者的十分之一。", "conclusion": "本文提出了一种新的VBT扩展方法，可以生成布朗运动及其时间积分，实现自适应高阶SDE求解器，提高了SDE模拟的效率和准确性。这种方法在高波动性CIR模型和MCMC问题模拟中展现了显著的性能优势。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.12736", "html_url": "https://arxiv.org/abs/2411.12736", "title": "ACING：在黑盒大语言模型中的指令学习的演员-评论家方法", "title_en": "ACING: Actor-Critic for Instruction Learning in Black-Box LLMs", "authors": "Salma Kharrat,Fares Fourati,Marco Canini", "background": "大语言模型（LLMs）的任务有效性很大程度上取决于其指令的质量，而这些指令的编写往往需要大量的手工努力。这强调了自动指令优化的必要性。然而，当处理黑盒LLMs时，优化指令尤为困难，因为无法访问模型参数和梯度。在此背景下，本文提出了ACING框架，该框架将指令优化问题定义为无状态的、具有连续动作的问题，并仅依靠黑盒反馈即可探索无限的指令空间，从而自动发现超越人工编写的指令的提示。", "innovation": "ACING框架利用演员-评论家强化学习方法，将指令优化问题抽象为无状态和连续动作的问题，仅使用黑盒反馈来探索无限的指令空间。实验结果显示，ACING在76%的任务中自动发现的提示优于人工编写的提示，并在33项任务中（覆盖指令指导、总结和步步思考推理），ACING的提升最高超过33分，中位数提升10分，远超最佳自动基线。", "conclusion": "研究結果展示了ACING的稳健性和效率，在黑盒LLMs上实现了自动指令优化。该研究表明，在黑盒LLMs任务中，自动化、无状态的学习方法具有潜在的应用前景。同时，ACING的实现可从此链接访问：this https URL。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.04228", "html_url": "https://arxiv.org/abs/2411.04228", "title": "dsld：一种社会相关性的教学工具", "title_en": "dsld: A Socially Relevant Tool for Teaching Statistics", "authors": "Aditya Mittal,Taha Abdullah,Arjun Ashok,Brandon Zarate Estrada,Shubhada Martha,Billy Ouattara,Jonathan Tran,Norman Matloff", "background": "数据科学在统计教育中扮演着越来越重要的角色，但要让关键概念易于学生理解，尤其是在通过实际应用的情况下，现有的工具仍然不够。数据科学需要能够将这些概念通过真实世界的例子呈现出来，从而使学生更深刻地理解统计分析的基本原理和应用。现有的教学工具不足以全面地提供分析和图表方法，特别是在公平性分析方面。因此，一种新的R包——Data Science Looks At Discrimination (dsld) 提出了新的教学方法，将公平性分析作为教学手段，通过应用实例展示混淆因素效应、模型偏见等相关内容。", "innovation": "dsld R包主要创新在于提供了一个综合的分析和图形方法集，用于调查涉及种族、性别和年龄等属性的歧视问题，并将其定位为教学工具，使得教师能够通过实际例子演示公平分析。此外，还提供了一个80页的Quarto书籍，帮助学生和法律专业人员理解这些原则并应用于实际数据。dsld还提供了Python接口，增强了其兼容性和应用范围。", "conclusion": "dsld R包和其配套书籍将公平性分析融入统计教学中，提高学生对统计分析理解的实际应用能力，为教学提供了新的视角和方法。同时，Python接口的提供进一步增强了其在不同编程环境中应用的便利性和普及率。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18970", "html_url": "https://arxiv.org/abs/2410.18970", "title": "WASP: 一种检测学习到的虚假相关性的权重空间方法", "title_en": "WASP: A Weight-Space Approach to Detecting Learned Spuriousness", "authors": "Cristian Daniel Păduraru,Antonio Bărbălau,Radu Filipescu,Andrei Liviu Nicolicioiu,Elena Burceanu", "background": "训练机器学习模型时，重要的是要使模型明确理解每个类在给定任务中的定义。尽管已有很多研究致力于识别数据集中的虚假相关性，以影响模型对类的理解，但现有方法主要依赖于数据或错误分析。它们只能指出已在验证或训练数据集中出现的反例揭示的虚假相关性，而无法识别模型在训练过程中自己学习的尚未由这些反例揭示的虚假相关性。本文提出的方法超越了这一限制，将关注点从分析模型的预测转向分析其权重，揭示模型决策背后的机制，从而提供了更深入的洞察。", "innovation": "提出的权重空间方法（WASP）依赖于分析基础模型在精细化调优过程中如何捕捉不同（虚假）相关性，从而揭示数据集中的虚假相关性。与以往工作相比，该方法能够（i）在训练和验证反例未揭示的情况下暴露数据集中的虚假相关性，（ii）适用于多种模态，例如图像和文本，以及（iii）揭示ImageNet-1k分类器学习到的未被利用的虚假相关性，提供了更深入的理解。", "conclusion": "本文提出了一种新的方法WASP，它通过分析模型权重来检测学习到的虚假相关性，该方法能够揭示传统方法未察觉的虚假相关性，并适用于多种模态。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.14791", "html_url": "https://arxiv.org/abs/2502.14791", "title": "通过元内省学习实现快速词汇学习", "title_en": "Rapid Word Learning Through Meta In-Context Learning", "authors": "Wentao Wang,Guangyuan Jiang,Tal Linzen,Brenden M. Lake", "background": "人类可以从少量的示例中快速学习新词汇，并在新的上下文中灵活使用。然而，当前语言模型在少量示例下的词汇学习能力及其提升方法尚未得到充分探索。这项研究旨在弥补这一空白。", "innovation": "提出了一种名为Minnow的新方法，通过元训练实现词汇内省学习。该方法利用特殊的替换标记来训练语言模型生成新词汇使用的例子，并通过这种方法对许多新词汇进行训练，以提高其通用的词汇学习能力。研究发现，从零开始使用Minnow训练模型可以使其在少量示例下的词汇学习能力与大规模语言模型相当。同时，通过调优预训练的语言模型，Minnow可以提高模型对新词汇的识别能力，确定新词汇的句法类别，并基于少量示例生成合理的使用和定义。", "conclusion": "Minnow表现出高效的数据使用效率，并且显示出提升语言模型词汇学习任务性能的潜力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.18158", "html_url": "https://arxiv.org/abs/2501.18158", "title": "大型语言模型在加密货币交易分析中的应用：以比特币案例研究为例", "title_en": "Large Language Models for Cryptocurrency Transaction Analysis: A Bitcoin Case Study", "authors": "Yuchen Lei,Yuexin Xiang,Qin Wang,Rafael Dowsley,Tsz Hon Yuen,Kim-Kwang Raymond Choo,Jiangshan Yu", "background": "加密货币被广泛使用，但当前用于分析交易的方法往往依赖于不透明的黑盒模型。这些模型虽然可能具有高精度，但其输出难以解释和适应，难以捕捉到复杂的模式行为。大型语言模型（LLMs）具有弥补这些缺口的潜力，但这些模型在这方面的应用尚未得到广泛探索，特别是在网络犯罪检测中。本文通过应用LLMs到真实的加密货币交易图，结合比特币作为最研究和广泛采用的区块链网络之一，测试了这一假设。", "innovation": "本文引入了一个三个层级的框架来评估LLMs的能力：基础指标、特征概览和上下文解释。该框架包括一个新型、人读式的图表示格式LLM4TG，以及一种增强连接性的交易图采样算法CETraS。这些方法显著减少了对LLMs进行交易图分析所需的令牌数量，使得在此严格的令牌限制下分析多个中等规模的交易图成为可能。实验结果表明，LLMs在基础指标和特征概览方面表现出色，节点级别最基本的识别信息准确性超过98.50%，获取有意义特征的比例达到95.00%。关于上下文解释，即使在标记数据有限的情况下，LLMs也在分类任务中表现出色，top-3准确率达到72.43%，并提供了解释。", "conclusion": "尽管解释并不总是完全准确，但LLMs展示了在这一领域的重要潜力。同时，文中也讨论了存在的局限性和未来研究的方向。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.16561", "html_url": "https://arxiv.org/abs/2503.16561", "title": "FutureGen: 基于检索增强生成的方法生成科学文章的未来工作", "title_en": "FutureGen: A RAG-based Approach to Generate the Future Work of Scientific Article", "authors": "Ibrahim Al Azher,Miftahul Jannat Mokarrama,Zhishuai Guo,Sagnik Ray Choudhury,Hamed Alhoori", "background": "科学文章的未来工作部分概述了当前研究的空白和局限性，并为研究人员提供了新的研究方向。本研究旨在利用相关论文的上下文从科学文章中生成未来工作建议。为了提高生成过程中的广泛见解并减少错过重要研究方向的风险，本研究使用了RAG（检索增强生成）技术结合语言模型（LLMs）。通过多种LLM与RAG的实验，引入了LLM提供反馈机制以提升生成内容的质量，并提出了一个LLM作为评审员的框架，以全面评估未来工作的新颖性、幻觉和可行性。", "innovation": "本研究提出了一种基于RAG的方法，利用GPT-4o mini和LLM反馈机制生成科学文章的未来工作。与传统方法相比，该方法在定量和定性评估中均表现出色，并通过引入LLM作为评审员的框架实现了未来工作的全面评估。", "conclusion": "研究结果表明，基于RAG的GPT-4o mini方法结合LLM反馈机制能够有效地生成科学文章的未来工作，并通过成人评估展示了其作为提取器、生成器和反馈提供者的有效性能。这种方法对于推动科学研究的持续发展具有重要意义。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14701", "html_url": "https://arxiv.org/abs/2501.14701", "title": "一种用于评估转诊合理性的无监督自然语言处理流水线", "title_en": "An Unsupervised Natural Language Processing Pipeline for Assessing Referral Appropriateness", "authors": "Vittorio Torri,Annamaria Bottelli,Michele Ercolanoni,Olivia Leoni,Francesca Ieva", "background": "评估诊断转诊的适当性对于提高医疗效率和减少不必要的检查至关重要。然而，在意大利 NHS 中，由于转诊原因仅记录为自由文本而非结构化代码，这项任务变得具有挑战性。为解决这一问题，本文提出了一种完全无监督的自然语言处理 (NLP) 流水线，用于在无需标记数据集的情况下提取并评估转诊原因，旨在解决不同检查类型通用性较差的问题。通过分析来自伦巴第大区（意大利）的两个全面地区数据集（2019-2021年之间的下肢静脉彩色多普勒超声检查 [ECD；n=496,971；开发] 和纤维结肠镜检查 [FEC；n=407,949；仅测试]），展现了流水线在识别转诊原因和适当性方面的高性能。", "innovation": "本文提出了一个完全无监督的自然语言处理流水线，用于评估大范围实际数据集中的转诊合理性，该流水线利用预训练的意大利医学文本变换器嵌入来聚类转诊原因并评估其与适当性准则的一致性，无需依赖标记数据集，具有通用性并能跨不同检查类型应用。", "conclusion": "该研究提出了一种强大的、可扩展的无监督NLP流水线，用于评估大型实际数据集中的转诊合理性，展示了这种数据的有效利用，为公共健康当局提供了可用于监控实践和支持基于证据的政策的可部署AI工具。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.00648", "html_url": "https://arxiv.org/abs/2503.00648", "title": "通过从头设计肽揭示T细胞受体特异性景观", "title_en": "T-cell receptor specificity landscape revealed through de novo peptide design", "authors": "Gian Marco Visani,Michael N. Pun,Anastasia A. Minervina,Philip Bradley,Paul Thomas,Armita Nourmohammad", "background": "T细胞在适应性免疫中扮演关键角色，通过特异性响应各种病原体。T细胞受体（TCRs）与重大组织相容性复合体（MHCs）提呈的病原体肽之间的有效结合触发免疫反应。然而，由于有限的T细胞活性功能数据，预测这些相互作用仍然具有挑战性。本文介绍了一种计算方法，用于预测TCR与MHC I类等位基因提呈肽的相互作用，并设计针对特定TCR-MHC复合物的新免疫原性肽。该方法利用HERMES模型，这是一种基于结构、物理学指导的机器学习模型，它在蛋白宇宙中进行训练，以预测基于局部结构环境的氨基酸偏好。尽管没有直接训练TCR-pMHC数据，但在HERMES中隐含的物理推理使得我们能够准确预测TCR-pMHC结合亲和力和对不同病毒表位和癌症新抗原的T细胞活性，相关性最高达到0.72。", "innovation": "本文提出了一种新的计算方法，使用HERMES结构引导的物理机器学习模型来预测TCR与MHC I类等位基因提呈肽的相互作用，并设计新型免疫原性肽。该方法在未直接训练TCR-pMHC数据的情况下，通过对全局蛋白环境的隐含物理推理，实现了对TCR-pMHC结合亲和力和T细胞活性的准确预测。通过实验证明，所设计的肽序列相对于原序列最多有五个替换，在三个靶向病毒和癌症肽的TCR-MHC系统中成功激活T细胞的比率高达50%。此外，还能评估各种TCR-MHC复合物肽识别景观的多样性。", "conclusion": "本文的方法为免疫原性肽和新抗原设计提供了平台，并有助于评估TCR特异性，为工程T细胞疗法和疫苗设计提供了计算框架。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.02737", "html_url": "https://arxiv.org/abs/2504.02737", "title": "RBT4DNN: 基于需求的神经网络测试", "title_en": "RBT4DNN: Requirements-based Testing of Neural Networks", "authors": "Nusrat Jahan Mozumder,Felipe Toledo,Swaroopa Dola,Matthew B. Dwyer", "background": "神经网络，尤其是其中包含深度神经网络(DNN)的系统，其测试面临挑战。当应用基于功能需求的测试方法时，正式化这些功能需求对于DNN来说是不可行的，因此难以应用成熟的测试方法来测试DNN。", "innovation": "提出了一个基于需求的测试方法(RBT4DNN)，该方法使用自然语言需求声明，并通过词汇表定义语义特征空间来生成测试输入。RBT4DNN将功能需求的先决条件形式化为语义特征的逻辑组合，并利用匹配这些特征组合的训练数据微调生成模型，以可靠地生成满足先决条件的测试输入。这种方法既可用于检测故障，又可在开发过程中通过需求导向的模型行为探索为开发人员提供反馈，确保模型的泛化能力。", "conclusion": "评估结果显示，RBT4DNN生成的测试用例是现实的、多样的，并且与需求先决条件对齐，能够提供有针对性的模型行为分析，并有效检测故障。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.06119", "html_url": "https://arxiv.org/abs/2411.06119", "title": "硬件友好的固定大小可重用结构的扩散模型用于设备端图像生成", "title_en": "Hardware-Friendly Diffusion Models with Fixed-Size Reusable Structures for On-Device Image Generation", "authors": "Sanchar Palit,Sathya Veera Reddy Dendi,Mallikarjuna Talluri,Raj Narayana Gadde", "background": "Vision Transformers 和 U-Net 架构在扩散模型的实施中被广泛采用。然而，每种架构都有特定的挑战，在设备上实现它们时表现不同。Vision Transformers 需要位置嵌入以保持由 Transformer 处理的标记之间的对应关系，虽然它们通过标记化提供使用固定大小、可重复使用的重复块的优势。U-Net 架构缺乏这些属性，因为它使用大小可变的中间块进行下卷积和上卷积，以估计噪声估计骨干中的扩散过程。", "innovation": "提出了一种架构，实现了固定大小、可重用的 Transformer 块作为核心结构，使其更适用于硬件实现。该架构的特点是低复杂度、标记免费设计、无位置嵌入、一致性和可扩展性，使其非常适合部署在移动和资源受限的设备上。提出的模型在无条件和有条件图像生成任务中表现出色且一致，并达到了 CelebA 上的无条件图像生成状态最高的 FID 得分 1.6。", "conclusion": "提出的模型在无条件和有条件图像生成任务中表现出色且一致。在 CelebA 上实现无条件图像生成时，该模型的 FID 得分达到了 1.6，达到了最先进的水平。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.11249", "html_url": "https://arxiv.org/abs/2504.11249", "title": "Cryo-EM图像本质上是低维的", "title_en": "Cryo-em images are intrinsically low dimensional", "authors": "Luke Evans,Octavian-Vlad Murad,Lars Dingeldein,Pilar Cossio,Roberto Covino,Marina Meila", "background": "模拟推理提供了一种强大的框架，用于冷冻电子显微镜实研究，并通过神经网络在像CryoSBI的方法中进行了应用，用来通过学习的潜在表示来推断生物分子的构象。这些潜在空间包含有关物理系统和推断过程的丰富信息。理解和利用这些潜在表示的潜在结构对于提升模型的性能至关重要。", "innovation": "本文通过应用流形学习技术对CryoSBI对血凝素（模拟和实验）的表示进行了研究，揭示了这些高维数据本质上是低维平滑流形的。通过使用扩散映射来表征流形的几何结构，并通过坐标解释方法识别它的主要变量轴，建立了潜在结构与关键物理参数之间的直接联系。这种发现的内在低维度和可解释的几何组织不仅验证了CryoSBI的方法，还促进我们从数据结构中更多地学习，并提供了利用揭示出来的流形几何学来改进未来的推断策略的机会。", "conclusion": "本文通过揭示CryoSBI表示的低维度和几何组织，验证了CryoSBI方法的有效性，并为从数据结构中获得更多有用信息提供了可能性，提高了未来推断策略的性能。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05118", "html_url": "https://arxiv.org/abs/2505.05118", "title": "使用模式过滤增强Text2Cypher", "title_en": "Enhancing Text2Cypher with Schema Filtering", "authors": "Makbule Gulcin Ozsoy", "background": "知识图谱通过节点、关系和属性表示复杂数据。Cypher 是一种强大的图形数据库查询语言，用于高效的建模和查询操作。近期的大语言模型能够将自然语言问题转换为 Cypher 查询（Text2Cypher）。传统做法是在提示中融入数据库模式，但复杂的模式会引入噪音、增加幻觉并提高计算成本。", "innovation": "本文研究了各种模式过滤方法在Text2Cypher任务中的应用，并分析了其对查询长度、性能和成本的影响。结果显示，模式过滤有效优化了Text2Cypher，特别是对于较小的模型。与此前的研究一致，较大模型从模式过滤中受益较少，因为它们具备更长的上下文能力。", "conclusion": "模式过滤在降低成本方面对大多数模型都有益处，特别是对于较小的模型。对于较大的模型，虽然模式过滤带来的好处较少，但模式过滤在降低计算成本方面依然重要。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.03905", "html_url": "https://arxiv.org/abs/2501.03905", "title": "MixNet: 一种适用于分布式混合专家训练的运行时可重构光-电 fabric", "title_en": "MixNet: A Runtime Reconfigurable Optical-Electrical Fabric for Distributed Mixture-of-Experts Training", "authors": "Xudong Liao,Yijun Sun,Han Tian,Xinchen Wan,Yilun Jin,Zilong Wang,Zhenghang Ren,Xinyang Huang,Wenxue Li,Kin Fai Tse,Zhizhen Zhong,Guyue Liu,Ying Zhang,Xiaofeng Ye,Yiming Zhang,Kai Chen", "background": "混合专家（MoE）模型通过在每个 token 基础上选择性地激活不同的子网络（专家），比传统的模型更优秀。这种门控计算生成了动态通信，这在分布式训练过程中是无法预先确定的，从而挑战了现有的静态 GPU 互连。现有的 GPU 互连在分布式训练过程中始终保持静态。", "innovation": "本文提出了一种名为 MixNet 的新型系统，能够在分布式 MoE 训练过程中重构互连拓扑。研究表明 MoE 的动态通信模式具有强大的局部性，从而降低了全局重构的需求。基于这一点，设计并实现了一种基于一体化电互连之上、利用光学电路交换（OCS）的区域可重构高带宽域，实现了在保持快速适应性的同时具备可扩展性。基于第三方硬件构建了完全功能性的 MixNet 样机，并集成了一个自定义的集体通信运行库，能够实现 32 块 A100 GPU 上的内训时互连拓扑配置。", "conclusion": "大规模数据包级仿真表明，MixNet 在100 Gbps 和 400 Gbps 链路带宽下分别实现了与非阻塞胖树网片结构相当的性能，并且四种代表性 MoE 模型的训练成本效率（例如每美元的性能）分别提高了 1.2-1.5 倍和 1.9-2.3 倍。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05122", "html_url": "https://arxiv.org/abs/2505.05122", "title": "Text2Cypher: 使用难度样本选择进行数据修剪", "title_en": "Text2Cypher: Data Pruning using Hard Example Selection", "authors": "Makbule Gulcin Ozsoy", "background": "关系数据库查询语言如SQL和图数据库查询语言如Cypher已被广泛采用。近年来，大型语言模型（LLMs）的发展使得通过Text2SQL和Text2Cypher等模型实现自然语言与数据库的交互成为可能。精细调整这些模型通常需要包含复杂示例的大型、多样化数据集。然而，随着数据集规模的增加，精细调整的成本也随之上升。这使得较小的、高质量的数据集对于实现相同或更好的性能以降低成本变得至关重要。", "innovation": "本文提出了一种使用难度样本选择的技术来修剪Text2Cypher数据集，以在减少资源使用的同时保持或提升性能。结果表明，这些难度样本选择的方法可以在对性能影响最小的情况下使训练时间和成本减半，证明了难度样本选择是一种成本效益高的解决方案。", "conclusion": "通过使用难度样本选择技术，可以在保持性能的同时大幅减少训练时间和成本，从而提供一种成本效益高的方法来实现高性能的数据库查询语言模型。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.16943", "html_url": "https://arxiv.org/abs/2504.16943", "title": "通过深度聚类揭示燃气机组的实际灵活性", "title_en": "Revealing the empirical flexibility of gas units through deep clustering", "authors": "Chiara Fusar Bassini,Alice Lixuan Xu,Jorge Sánchez Canales,Lion Hirth,Lynn H. Kaack", "background": "发电单元的灵活性决定了其能快速调整发电量的频率和能力。现有能源模型通常依赖于对单元技术特性假设，例如其装机容量或涡轮技术。本文通过分析5年的发电数据（2019-2023年，来自100 MWp装机容量的49个德国单元）来实证了解燃气单元的灵活性，揭示了实际限制可能导致技术特性相似的单元之间存在显著差异的原因。", "innovation": "本文采用了一种新颖的深度聚类方法，将49个德国单元的小时级发电数据转换为低维嵌入，无监督地识别出了两类峰值单元（高度灵活）和两类非峰值单元（低灵活性）。这种聚类方法揭示了燃气单元的实际灵活性波动，并与众不同地展示了非峰值单元拥有低灵活性，相比之下与燃煤单元相似。这些非峰值单元主要由工业和市政公用事业所有，对低余量负载和负电价的反应有限，在这些时段平均发电量为1.3 GWh。", "conclusion": "随着可再生能源的推广增加了市场的波动性，需要进行监管变革以释放燃气单元的灵活性潜力。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04873", "html_url": "https://arxiv.org/abs/2504.04873", "title": "基于神经运算器的闭环交通密度观测器", "title_en": "Closed-Loop Neural Operator-Based Observer of Traffic Density", "authors": "Alice Harting,Karl Henrik Johansson,Matthieu Barreau", "background": "本文考虑了使用固定路边传感器的稀疏测量对交通密度进行估计的问题。现有的方法可能无法准确地从稀疏测量中推断出宏观交通流动态。本文提出的方法利用傅里叶神经运算器从高保真的数据中学习宏观交通流动态，通过将预测的密度与传感器的稀疏测量结合起来，提出了一种闭环观测器。仿真结果表明，与开环估计器相比，提出的闭环观测器具有更高的鲁棒性、噪声抑制能力和最终有界性。这展示了将学习到的物理规律与实时修正相结合的优势，并为准确、高效、可解释的数据驱动观测器开辟了新的途径。", "innovation": "提出了使用傅里叶神经运算器进行交通密度估计的方法，该方法结合预测的密度与传感器的稀疏测量，通过闭环观测器提高估计的准确性和鲁棒性。", "conclusion": "仿真结果表明，提出的闭环观测器表现出经典闭环属性，如对噪声的鲁棒性和误差的最终有界性。这证明了将学习到的物理规律与实时修正相结合的优越性，为准确、高效且可解释的数据驱动观测器开辟了新的可能。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.11671", "html_url": "https://arxiv.org/abs/2504.11671", "title": "社会仿真中LLM决策计算基础", "title_en": "Computational Basis of LLM's Decision Making in Social Simulation", "authors": "Ji Ma", "background": "大型语言模型（LLMs）在社会学和应用研究中越来越多地作为类人的决策代理。这些LLM代理通常被赋予类人的性格并置于真实生活情境中，但这些性格和情境如何影响其行为尚待深入探索。本文提出并测试了在经典的公平及利他行为行为实验——狄克西特博弈中，探究、量化和修改LLM内部表示的方法，以研究和调控社会概念在转换器模型中的编码与工程方法，对于确保模型对齐、消除偏差以及设计社会模拟中的AI代理具有重要意义，并强化了社会学理论和测量.", "innovation": "本文创新地提出了一种在狄克西特博弈中探究、量化和修改LLM内部表示的方法，通过操纵来自LLM内部状态的“变量变化向量”（如“男性”到“女性”），显著改变了这些变量与模型决策之间的关系，从而提供了一种原理性方法来研究和调控社会概念在转换器模型中的编码与工程.", "conclusion": "该研究揭示了社会概念如何在转换器模型中被编码和工程的方法，对确保模型对齐、消除偏差以及设计社会模拟中的AI代理具有重要意义，有助于强化社会学理论和测量."}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01751", "html_url": "https://arxiv.org/abs/2505.01751", "title": "SGD的一些异常现象的动态视图", "title_en": "A dynamic view of some anomalous phenomena in SGD", "authors": "Vivek Shripad Borkar", "background": "贝尔金等人观察到，过参数化的神经网络表现出一种`双重下降现象'。具体来说，随着模型复杂性（反映在特征数量上）的增加，测试误差最初降低，然后增加，然后再次降低。这种现象的时间域对应物在按epoch的训练中有所体现，即测试误差随迭代次数的增加而降低，然后增加，然后再次降低。另一个异常现象是`grokking'现象，其中两个下降区间的分离被一个中间区域所中断，在该状态下平均损失几乎保持不变。", "innovation": "本文通过将渐近性理论应用到梯度动态的连续时间极限中，提出了展望两种时间尺度随机逼近理论的新视角，从而为这些和相关现象提供了一个可能的解释。", "conclusion": "这种理论视角为这个已经研究得很好的主题提供了新的见解。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04421", "html_url": "https://arxiv.org/abs/2504.04421", "title": "在打包配置树上进行3D箱装的慎重规划", "title_en": "Deliberate Planning of 3D Bin Packing on Packing Configuration Trees", "authors": "Hang Zhao,Juzhan Xu,Kexiong Yu,Ruizhen Hu,Chenyang Zhu,Bo Du,Kai Xu", "background": "在线三维箱装问题（3D-BPP）在工业自动化中有广泛的应用。现有的方法通常由于空间离散化限制的限制或无法很好地处理复杂的实际约束而解决这个问题。", "innovation": "该文提出了一种新的层次表示的打包配置树（PCT），这是一种全面描述箱装状态和动作空间的描述，可以支持基于深度强化学习的打包策略学习。文中提出了一种递归打包方法将大规模箱装问题分解为更小的子树，并使用空间集成机制将局部解决方案集成到全局中。此外，为不同的BPP变体（如前瞻，缓冲和离线箱装），提出了一种统一的规划框架，使这些变体可以直接求解。实验表明，该方法优于现有的在线BPP基准，并且能够轻松整合各种实际约束。打包过程在大规模问题和不同的问题变体中表现出色。文中还开发了一款用于工业仓储的实时打包机器人，它能够在不受保护的托盘上以每箱10秒的速度可靠高效地运作，并实现了相对大尺寸箱子平均19箱/托盘，托盘利用率57.4%。", "conclusion": "该方法在大规模问题和多种问题变体中表现出色，并且能够集成各种实际约束。文中提出的打包配置树（PCT）和递归打包方法有效地解决了在线3D箱装问题。并且已经成功应用于工业仓储的打包机器人中，具有高效和可靠的特点。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20789", "html_url": "https://arxiv.org/abs/2505.20789", "title": "在解决基于扩散模型的逆问题中集成中间层优化和投影梯度下降", "title_en": "Integrating Intermediate Layer Optimization and Projected Gradient Descent for Solving Inverse Problems with Diffusion Models", "authors": "Yang Zheng,Wen Li,Zhaoqiang Liu", "background": "逆问题（IPs）涉及从嘈杂的观测数据重构信号。最近，扩散模型（DMs）作为解决IPs的强大框架，表现出卓越的重构性能，但现有的基于DM的方法通常面临计算量大和收敛性能不佳的问题", "innovation": "本文基于近期工作DMPlug，提出了解决上述问题的两种新方法：DMILO和DMILO-PGD。DMILO使用中间层优化（ILO）来缓解DMPlug的内存负担，并通过引入稀疏偏差使DMs的适用范围扩展，从而探索潜在信号。DMILO-PGD通过将ILO与投影梯度下降（PGD）结合，降低非最优收敛的风险。通过对多种图像数据集进行广泛的实验，验证了这两种方法在性能上的优越性", "conclusion": "实验结果显示，DMILO和DMILO-PGD在处理基于DM的IP求解器中的常见挑战方面表现出显著的优越性能，标志着这两种方法在解决逆问题中的有效性提升"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.23746", "html_url": "https://arxiv.org/abs/2503.23746", "title": "短视频传播影响力评级：一个新的真实世界数据集和一个新的大型图模型", "title_en": "Short-video Propagation Influence Rating: A New Real-world Dataset and A New Large Graph Model", "authors": "Dizhan Xue,Shengsheng Qian,Chuanrui Hu,Changsheng Xu", "background": "短视频平台在全球获得了极大的流行，吸引了数以亿计的用户。最近，研究人员强调了分析短视频传播的重要性，包括发现其商业价值、公众意见和用户行为等。因此，人们需要一个评价短视频传播影响力的方法和相应的数据集以进行研究和预测。本文提出了一个新的短视频传播影响力评级（SPIR）任务，并旨在从数据集和方法的角度促进SPIR的发展。该论文介绍了一个新的跨平台短视频（XS-Video）数据集，以及一种基于新型三阶段训练机制的大型图模型NetGPT。", "innovation": "1. 引入了一个新的跨平台短视频（XS-Video）数据集，该数据集包含了来自中国五大平台的117,720个视频，381,926个样本和535个话题，涵盖了从0到9的传播影响力，是第一个包含跨平台数据和提供所有评论、点赞、分享、收藏、粉丝、评论内容的真实世界数据集。2. 提出了基于大型语言模型（LLMs）的强大推理能力和新型三阶段训练机制的大型图模型NetGPT，以理解并分析短视频传播图，预测短视频的长期传播影响力。", "conclusion": "通过对自主研发的XS-Video数据集进行实验，采用分类和回归指标，结果表明所提出的方法在短视频传播影响力的预测方面具有优势。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23445", "html_url": "https://arxiv.org/abs/2505.23445", "title": "强、弱和良性 Goodhart 法则。一种独立性无关和范式无关的形式化", "title_en": "The Strong, Weak and Benign Goodhart's law. An independence-free and paradigm-agnostic formalisation", "authors": "Adrien Majka,El-Mahdi El-Mhamdi", "background": "Goodhart 法则是政策制定中的一个著名法则，指出‘当衡量指标成为目标时，它就不再是一个好的衡量指标’。近年来，随着机器学习模型和训练它们的优化能力的增强，对该法则的信仰有所增加，但缺乏形式化的证明。之前的研究试图通过分类不同的 Goodhart 法则变体或研究优化代理指标如何影响目标优化来形式化该法则，但这些研究都基于简化假设，即独立性假设和特定学习范式的假设。", "innovation": "本文提出了一个独立性无关和范式无关的形式化方法，以研究代理指标与目标之间的耦合如何影响 Goodhart 法则的效果。研究表明，在目标和偏差为轻尾分布的情况下，耦合并不会改变 Goodhart 效应的本质。而在目标轻尾和偏差重尾的情况下，通过反比于偏差重尾性的关系展示了过优化现象的发生率。", "conclusion": "本文通过独立性无关和范式无关的形式化方法，探讨了代理指标与目标耦合对 Goodhart 法则效应的影响。指出在轻尾目标和轻尾偏差的情况下，耦合不会改变 Goodhart 效应的本质；而在轻尾目标和重尾偏差情况下，展示了过优化现象的反比于偏差重尾性关系的发生率。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05785", "html_url": "https://arxiv.org/abs/2507.05785", "title": "Real-Time 通信中的稳健带宽估算与离线强化学习", "title_en": "Robust Bandwidth Estimation for Real-Time Communication with Offline Reinforcement Learning", "authors": "Jian Kai,Tianwei Zhang,Zihan Ling,Yang Cao,Can Shen", "background": "准确的带宽估算（BWE）对于实时通信（RTC）系统至关重要。传统的启发式方法在动态网络下缺乏适应性，而在线强化学习（RL）则存在高探索成本和潜在服务中断的问题。相比之下，利用来自真实环境的高质量数据的离线RL为有效的BWE提供了另一种可能，但仍然面临着离分布行动、策略学习从多样性的行为数据中提取以及生产系统的可靠部署等挑战。", "innovation": "本文提出了一种名为RBWE的基于离线RL的稳健带宽估计框架，该框架结合了Q-ensemble及高斯混合策略以减轻离分布风险并提升策略学习效果。此外，还引入了失效机制，在高度不确定性情况下切换回启发式方法以保证部署的稳定性。", "conclusion": "实验结果表明，RBWE将过高的带宽估计误差降低了18%，同时提高了体验质量（QoE）的10分位数18.6%，证明其在实际RTC应用中的实用性。此研究成果已在GitHub上公开发布。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12210", "html_url": "https://arxiv.org/abs/2506.12210", "title": "无线边缘网络上的机器智能", "title_en": "Machine Intelligence on Wireless Edge Networks", "authors": "Sri Krishna Vadlamani,Kfir Sulimany,Zhihui Gao,Tingjun Chen,Dirk Englund", "background": "机器智能在边缘设备上处理可以带来低延迟和更好的隐私，但通常受限于数据移动和转换所需的能量和延迟。当前的系统通常通过将查询发送到服务器来避免本地模型存储，这会导致上行费用、网络延迟和隐私风险。现有系统通常会选择将计算任务发送到云端进行处理，而本文提出了一种相反的方法，即将模型权重直接广播给能够利用现有无线设备内部计算链路内进行推理的客户端。这种方法通过直接在接收链中使用频域信号对活动数据进行编码和计算，消除了重复的信号转换和额外硬件的要求，使边缘设备能够执行复杂的计算任务。", "innovation": "本文提出了将模型权重直接广播给具备内部计算链路的客户端，利用无线设备中的现有RF组件进行推理计算，从而在不增加额外硬件的情况下提高计算效率和隐私保护。这种方法通过直接在无线链路中进行数据处理和计算，减少了数据的移动和转换，提高了实时性和隐私性，同时通过硬件定制的训练保持了计算的准确性。", "conclusion": "通过电路指导的仿真和仿真，本文证明了该方法能够在减少内存和转换开销的同时保持高精度。该方法可以在实际无线边缘场景中减少不必要的能量损耗和隐私风险，提高了边缘设备的计算能力和用户体验。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01044", "html_url": "https://arxiv.org/abs/2507.01044", "title": "宽且浅的神经网络的渐近凸性", "title_en": "Asymptotic convexity of wide and shallow neural networks", "authors": "Vivek Borkar,Parthe Pandit", "background": "该研究基于一个简单的浅且宽的神经网络模型，探讨了其输入输出映射的上图在参数空间中的表示。背景文献可能已经讨论了神经网络在不同深度和宽度下的表现，并可能提及了这些网络在实际应用中的良好性能，但没有明确的理论解释。研究指出，这种良好的表现可能是由于神经网络的输入输出映射可以近似表示为凸函数的上图。", "innovation": "研究发现了一个宽且浅的神经网络的输入输出映射可以近似表示为具有某种精确意义下的凸函数的上图。这是一种新颖的观点，提供了对神经网络良好性能的一种潜在解释，为理解神经网络的工作机制和优化设计提供了新的理论基础。", "conclusion": "研究证明了宽且浅的神经网络的输入输出映射在某种意义下接近于凸函数的上图，这为解释其良好的性能提供了一条新的思路。该工作为神经网络的设计和优化提供了理论指导。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.08570", "html_url": "https://arxiv.org/abs/2506.08570", "title": "自动回归与流匹配：文本到音乐生成建模范式的比较研究", "title_en": "Auto-Regressive vs Flow-Matching: a Comparative Study of Modeling Paradigms for Text-to-Music Generation", "authors": "Or Tal,Felix Kreuk,Yossi Adi", "background": "近年来，文本到音乐生成的进步使得模型能够合成高质量的音乐段落、完整的作品，甚至响应细粒度的控制信号，例如和弦进程。最先进的系统在许多维度上存在显著差异，如训练数据集、建模范式和架构选择。这种多样性使得对模型进行公平评估和识别哪些设计选择对性能影响最大变得复杂。尽管数据和架构因素很重要，但本研究仅集中在建模范式上。我们进行了一项系统性的实证分析以隔离其影响，提供关于伴随权衡和新兴行为的见解，这些见解可以指导未来的文本到音乐生成系统。具体来说，我们将比较两种最为常见的建模范式：自动回归解码和条件流匹配。", "innovation": "我们在完全相同的训练数据集、训练配置和类似的核心架构下，从零开始训练所有模型进行控制比较。性能从多个维度进行评估，包括生成质量、推理配置的鲁棒性、可扩展性、对文本和时间对齐条件的依从以及编辑能力（通过声音修复的形式）。这种比较研究揭示了每种范式的独特优势和局限性，为未来的架构和训练决策提供了可操作的见解，这些见解能够塑造文本到音乐生成领域的演变。", "conclusion": "这项比较研究为每种建模范式的独特优势和限制提供了见解，有助于未来的系统设计和训练决策。音频示例样本已在提供的链接中提供。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02842", "html_url": "https://arxiv.org/abs/2507.02842", "title": "可重复假设检验器的结构", "title_en": "On the Structure of Replicable Hypothesis Testers", "authors": "Anders Aamand,Maryam Aliakbarpour,Justin Y. Chen,Shyam Narayanan,Sandeep Silwal", "background": "可重复假设检验算法在运行于相同分布的两个不同样本上时，如果以高概率输出相同的结果，称之为可重复性。这种概念由Impagliazzo等人的研究定义，能够增强对假设检验程序的信任，并与算法稳定性、泛化能力及隐私有密切关联。已有工作对此进行了初步探讨，但在工具和结果的统一性和量化改进上有提升空间。", "innovation": "文章构建了证明可重复检验器的样本复杂性上下界的一般工具，统一并量化增强了现有结果。研究了一组核心属性，证明任何可重复检验算法可以被修改以满足这些属性而不影响准确性或样本复杂性。提出了可重复性检验器的规范结构，并通过归约法证明了各种统一性测试的新下界。改进了重复化设计中常见的策略，允许非重复环境中广泛分析的测试器以最小开销实现重复性，获得常数因子最优结果，并提出了高效率的高斯均值可重复性检验器的最新边界，不同以往的工作，本文的算法为多项式时间运行。", "conclusion": "文章通过提出核心性质、构建框架和改进策略，证明了各类假设测试问题中的可重复性，提出了常数因子最优和多项式时间可重复高斯均值检验的最新界限，并通过归约法证明了统一性测试的新下界，大大提升了对可重复假设检验器的理解和应用。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09401", "html_url": "https://arxiv.org/abs/2506.09401", "title": "递归训练中生成模型模型崩塌的理论基础", "title_en": "A theoretical basis for model collapse in recursive training", "authors": "Vivek Shripad Borkar", "background": "众所周知，在递归训练从生成模型中，可能会导致模拟的概率分布出现所谓的‘崩塌’现象。研究人员注意到这种现象的发生与多种因素相关，但具体机理尚不明确。本文致力于探讨并解释这一现象产生背后的机理，并发现外部分散样本的引入会改变模型的渐近行为。", "innovation": "本文的创新之处在于，它揭示了在递归训练生成模型中，模型‘崩塌’现象的两种不同的渐近行为。据发现，这取决于是否引入了外部分散样本。这项研究对于理解生成模型的递归训练过程具有重要理论意义，有助于指导如何设计和优化递归训练策略以防止模型‘崩塌’现象。", "conclusion": "研究表明，生成模型在递归训练中会表现出不同的渐近行为，这取决于是否存在外部样本的贡献。这种发现有助于解释生成模型在递归训练中为何会出现模型‘崩塌’现象，并为避免这种现象提供了理论指导。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11236", "html_url": "https://arxiv.org/abs/2507.11236", "title": "非对数凹分布的改进采样算法和庞加莱不等式", "title_en": "Improved sampling algorithms and Poincaré inequalities for non-log-concave distributions", "authors": "Yuchen He,Zhehan Lei,Jianan Shao,Chihao Zhang", "background": "研究了从具有势能函数 $V:\textbf{R}^d \to \textbf{R}$ 的分布 $\textbf{R}^d$ 中采样的问题，该势能函数具有密度 $\textpropto e^{-V}$，并且可以通过查询访问势能函数 $V$ 和其梯度 $\nabla V$。先前的研究（如 He 和 Zhang, COLT'25）表明，采样的查询复杂度下限至少为 $\textleft(\frac{\text{LM}}{d\textepsilon}\textright)^{\textOmega(d)}$，其中 $\text{LM}$ 是势能函数的 Lipschitz 常数，$\text{d\textepsilon}$ 是总变异距离中的准确度。此外，分析以扩散为基础的采样器时通常会进一步加强平滑性条件 1（导数在欧文-装饰解恩过程中的势能函数都是 $L$-平滑的），本文证明在假设 1* 和 2 下，从 $\textbf{R}^d$ 中采样的查询复杂度为 $\text{poly}(L,d) \times \textleft(\frac{Ld + M}{\textepsilon^2}\textright)^{\textcal{O}(L+1)}$，在 $L=\textcal{O}(1)$ 和 $M=\text{poly}(d)$ 时为多项式阶。这意味着稍微加强平滑性条件 1 到 1* 就能使得采样算法的查询复杂度减少指数数量级。", "innovation": "确立了假设 1* 和 2 下的样本复杂度理论，即 $\text{poly}(L,d) \times \textleft(\frac{Ld + M}{\textepsilon^2}\textright)^{\textcal{O}(L+1)}$。此复杂度在 $L=\textcal{O}(1)$ 和 $M=\text{poly}(d)$ 时为多项式阶。与 Huang 等人 (COLT'24) 开发的接近多项式阶复杂度的算法相比，这是一个改进。此外，证明了在假设 1* 以及更加强烈的势能函数 $X \rightarrow \textbf{R}^d$ 中 $\textbf{R}^d$ 的范数 $\text{X}$ 是 $\textlambda$-次高斯时，$\textbf{R}^d$ 的庞加莱常数 $\textle O(\textlambda)^{2(L+1)}$。所提出的技术也为高斯混合模型提供了改进的庞加莱常数估计。", "conclusion": "本文的研究结果表明，通过对平滑性假设进行适度增强，即使查询复杂度可以得到显著改善。同时，对于非对数凹分布，本文边界了其庞加莱常数，并应用这些边界改进高斯混合模型的庞加莱常数估计。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18464", "html_url": "https://arxiv.org/abs/2508.18464", "title": "量子编码可学习嵌入向量化注意力的量子变换器", "title_en": "Vectorized Attention with Learnable Encoding for Quantum Transformer", "authors": "Ziqing Guo,Ziwen Pan,Alex Khan,Jan Balewski", "background": "量子模型，如量子变换器（QT），通过量子区块编码将经典数据嵌入到希尔伯特空间，从而提供了一种有效的方式。当前的QTs依赖于深度参数化量子电路（PQCs），这种架构容易受到量子处理单元（QPU）噪声的影响，从而限制了其实际性能。", "innovation": "本文提出了向量化量子变换器（VQT），通过量子近似模拟和支持理想掩蔽注意力矩阵计算，实现高效的向量化非线性量子编码器训练，从而避免量子电路模拟中的突变并减少经典采样开销。此外，我们还在量子电路模拟中对IBM和IonQ的准确性进行了比较，并在IBM最先进的和高保真金斯顿QPU上对自然语言处理任务进行了基准测试，取得了竞争性的结果。", "conclusion": "噪声中间规模量子友好型的VQT方法解锁了端到端的量子计算机器学习新架构。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.05972", "html_url": "https://arxiv.org/abs/2507.05972", "title": "通用且统一的计算难度与伪随机性等价性", "title_en": "Generalized and Unified Equivalences between Hardness and Pseudoentropy", "authors": "Lunjia Hu,Salil Vadhan", "background": "伪随机性的特性为计算难度和计算随机性之间的密切关系提供了定量精确的证明。研究表明，不同的熵概念之间存在等价性，并且这些等价性可以通过一个通用的函数来同时展示计算难度和计算随机性。此外，研究指出，最近关于算法公平性的文献中的权重限制校准概念以及标准计算不可区分性（在公平性文献中称为多准确度）足以证明一般熵概念的伪随机性特征。", "innovation": "1. 提出了一个统一的伪随机性特征化，统一并加强了针对均匀和非均匀计算模型的先前结果。\n2. 证明了不同熵概念的特征化可以通过一个单一、通用的功能同时见证计算难度和计算随机性。\n3. 展示了权重限制校准的概念可以增强经典复杂性理论定理（Trevisan, Tulsiani, 和 Vadhan, 2009）和泄露模拟定理（Jetchev 和 Pietrzak, 2014），从而在字母表大小上实现了指数级的复杂性改进。\n4. 证明了权重限制校准以及较弱的校准多准确度对于字母表大小的依赖性是不可避免的。", "conclusion": "通过结合现有的技术，本研究提供了一种方法，能够以指数级改进计算复杂性依赖性来证明伪随机性特征，这一特性进一步加强了计算难度和计算随机性之间的关系。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01221", "html_url": "https://arxiv.org/abs/2509.01221", "title": "DaMoC: 基于数据和模型压缩高效选择适合领域任务微调的最佳大型语言模型", "title_en": "DaMoC: Efficiently Selecting the Optimal Large Language Model for Fine-tuning Domain Tasks Based on Data and Model Compression", "authors": "Wei Huang,Huang Wei,Yinggui Wang", "background": "现有的大型语言模型（LLMs）在通用任务上表现出色，但在领域特定任务上存在不足，需要使用针对特定领域的数据进行调优。然而，选择最适合进行下游任务调优的开源LLM模型变得越来越具有挑战性，主要难点在于如何迅速找到最佳的LLM。现有方法侧重于如何快速识别最优LLM。", "innovation": "本研究提出了一种数据和模型压缩框架（DaMoC），该框架通过两个层面解决上述问题：1）数据层面：建立了数据过滤方法的系统分类，将它们分为三类：分布感知方法、质量感知方法和结合两个维度的混合方法，并通过增加文本中关键标记的密度实现了标记压缩，还利用LLM迭代修改文本以优化表达；2）模型层面：通过层相似性评分评估每一层的重要性并去除较低重要性的层，引入了稀疏合并方法以尽可能保留原始模型的能力。实验结果表明，在四个数据集上，该方法可以在节省约20倍的训练时间的前提下选择最佳的LLM。", "conclusion": "本研究通过数据和模型压缩的方法，提供了一种高效的选取最适合领域任务调优的大型语言模型的方法。这一方法能够显著节省训练时间，并有助于提高调优过程的效率。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02060", "html_url": "https://arxiv.org/abs/2509.02060", "title": "通过掩蔽条件生成建模实现特定形态的肽发现", "title_en": "Morphology-Specific Peptide Discovery via Masked Conditional Generative Modeling", "authors": "Nuno Costa,Julija Zavadlav", "background": "肽自组装预测为设计生物相容性、低毒性材料提供了强大的自下而上的策略，这些材料可以在广泛的生物医药和能源应用中大规模合成。然而，筛选巨大的序列空间以分类聚集形态仍然难以解决。", "innovation": "我们引入了PepMorph，这是一种端到端的肽发现管道，可以生成既易于聚集又能自组装成特定纤维状或球状形态的新序列。该方法通过利用现有聚集倾向数据集，并提取几何和物理化学的特征肽描述符，作为聚集形态的替代指标，构建了一个新数据集。该数据集用一个带有掩码机制的Transformer-条件变分自编码器进行训练，能够生成在任意条件下的新型肽。经过过滤确保设计规范，并通过粗粒度分子动力学模拟验证生成序列后，PepMorph在目标形态生成方面达到了83%的准确率，展示了其作为应用于肽发现框架的潜力。", "conclusion": "PepMorph在形态生成方面显示出83%的准确率，证明它是一个有前景的应用驱动肽发现框架。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02349", "html_url": "https://arxiv.org/abs/2509.02349", "title": "AudioCodecBench: 用于音频编解码评估的全面基准", "title_en": "AudioCodecBench: A Comprehensive Benchmark for Audio Codec Evaluation", "authors": "Lu Wang,Hao Chen,Siyu Wu,Zhiyue Wu,Hao Zhou,Chengfeng Zhang,Ting Wang,Haodi Zhang", "background": "近年来，多模态大型语言模型（MLLMs）已在语音和音乐领域得到广泛应用，这促使研究者关注音频分词在大型模型中的应用。与仅包含语义的文本标记不同，音频标记必须同时捕捉全局语义内容并保留细微的声学细节。此外，音频标记提供了一种离散的方法，可以有效集成到MLLMs中。然而，当前的研究在定义语义标记和声学标记方面存在问题。另外，在不同的编解码器评估方面，研究更多集中在特定领域或任务上，如重构或自动语音识别（ASR）任务，这阻碍了公平和全面的比较。", "innovation": "本文提出了适用的语义标签和声学标签定义，并引入了一个系统性的评估框架。该框架从四个维度对编解码器的性能进行全面评估：音频重建度量标准、码本索引（ID）稳定性、仅解码器变换器困惑度及下游探测任务表现。", "conclusion": "实验结果显示提供的适合定义的正确性以及重建度量标准、码本ID稳定性、下游探测任务和困惑度之间的相关性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01875", "html_url": "https://arxiv.org/abs/2509.01875", "title": "RadioDiff-Loc: 基于稀疏射频图估计增强散射认知的扩散模型增强NLoS定位", "title_en": "RadioDiff-Loc: Diffusion Model Enhanced Scattering Congnition for NLoS Localization with Sparse Radio Map Estimation", "authors": "Xiucheng Wang,Qiming Zhang,Nan Cheng", "background": "非视线（NLoS）环境中的非合作信号源的精确定位仍然是一个关键挑战，广泛应用于自主导航、工业自动化和应急响应等领域。传统依赖视距（LoS）或合作信号的定位技术在这种环境中会因严重的多径传播和未知发射功率而失效。本文探讨了在非视线环境中的无合作信号源定位问题及其对自动驾驶和工业自动化等领域的应用背景。", "innovation": "本文提出了一种基于条件扩散模型的非视线定位新框架RadioDiff-Loc。该框架利用衍射电磁能量聚集在建筑物边缘的物理原理，通过在障碍物的几何顶点收集稀疏接收信号强度（RSS）测量值，以最大化与未知源的 Fisher 信息和互信息。为了克服已知发射功率的缺乏，该测量值相对于最大观测强度进行归一化处理，从而构建功率不变的射频图（RM）。通过基于环境布局和稀疏RSS观察训练条件扩散模型重建完整的RM，并通过识别产生的 RM 上最亮的点来实现定位。此外，该框架与现有的基于RSS的定位算法兼容，通过结合物理知识和数据驱动的推理实现更准确的定位融洽共进。", "conclusion": "本文通过理论分析和实验验证证明，RadioDiff-Loc框架能够实现高精度的定位并显著降低采样成本，提供一种可扩展且基于物理的方法来解决非合作的NLoS发射器定位问题。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00215", "html_url": "https://arxiv.org/abs/2509.00215", "title": "通过脱钩反向传播的第一阶模型导向强化学习", "title_en": "First Order Model-Based RL through Decoupled Backpropagation", "authors": "Joseph Amigo,Rooholla Khorrambakht,Elliot Chane-Sane,Nicolas Mansard,Ludovic Righetti", "background": "近年来，利用模拟器梯度来提高学习效率的强化学习（RL）方法引起了广泛关注。尽管早期基于梯度的方法在性能上超过了无梯度的方法，但获取模拟器梯度往往因为实现成本或不可用性而困难。基于模型的强化学习（MBRL）可以通过学习的动力学模型来近似这些梯度，但这种模型在训练采样过程中可能会由于累积预测误差而导致求解效率下降，进而影响策略性能。", "innovation": "本文提出了一种脱钩策略：轨迹生成使用模拟器进行，而梯度计算则通过一个学习到的可微模拟器模型进行反向传播来完成。这种混合设计使得即使在不存在模拟器梯度的情况下，仍可以高效且一致地进行一阶政策优化，并且可以从模拟采样中学习出更准确的评估器。本文的方法在样本效率和速度方面与特定优化器（如SHAC）相当，同时保持了标准方法（如PPO）的通用性，并避免了其他一阶MBRL方法中观察到的不良行为。", "conclusion": "我们在基准控制任务上实证验证了该算法，并在真实的Go2四足机器人上展示了其在四足和双足运动任务上的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12964", "html_url": "https://arxiv.org/abs/2507.12964", "title": "基于人口统计信息的儿童桡骨骨折细粒度分类", "title_en": "Demographic-aware fine-grained classification of pediatric wrist fractures", "authors": "Ammar Ahmed,Ali Shariq Imran,Zenun Kastrati,Sher Muhammad Daudpota", "background": "儿童桡骨骨折在骨折病例中较为常见，特别是儿童构成了骨折病例的大多数。传统影像识别方法依赖单一模态（如图像）已经不足以应对多类型数据的需求，尤其是在计算机视觉领域，数据集的广泛获取是一个重大挑战。因此，该研究提出了一种多维度的方法，包括将患者元数据与X光片融合，使用针对细粒度任务预训练的方法而非粗粒度预训练（如ImageNet），并且首次将人口统计信息整合到桡骨骨折识别中。", "innovation": "该研究首次将患者元数据与X光片融合，并使用基于细粒度任务预训练的方法进行桡骨骨折识别。与之前的单独使用图像识别方法相比，该方法通过结合细粒度Transformer方法、细粒度预训练和元数据集成，在小的自定义数据集上提高了诊断准确率2%，在较大的骨折数据集上提高了超过10%。", "conclusion": "该研究证实，通过结合细粒度Transformer方法、细粒度预训练和元数据集成，可以显著提高桡骨骨折的诊断准确性。这种方法为儿童腕部疾病识别提供了新的视角和技术路径，展示了在医学影像识别中充分利用多模态数据的重要性和可行性。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03541", "html_url": "https://arxiv.org/abs/2509.03541", "title": "关于移动应用需求工程所使用的数据集：系统映射研究的初步发现", "title_en": "Towards the Datasets Used in Requirements Engineering of Mobile Apps: Preliminary Findings from a Systematic Mapping Study", "authors": "Chong Wang,Haoning Wu,Peng Liang,Maya Daneva,Marten van Sinderen", "background": "针对移动应用的需求工程（RE）研究中使用的数据集通常来源于应用程序用户、开发者或供应商，但很少有关于这些数据集来源的平台及其研究涉及的需求工程活动的相关信息。", "innovation": "本文通过系统映射研究的方式，分析了当前移动应用需求工程研究使用的数据集的使用状态，发现Google Play和Apple App Store是提供数据集的主要来源，涉及的研究活动主要是需求获取和需求分析。", "conclusion": "研究得出四个主要结论：（1）自2012年以来，移动应用需求工程研究中使用数据集的数量有所增长；（2）由于过度依赖Google Play和Apple App Store，移动应用的需求工程知识可能有所偏颇；（3）已经有尝试结合应用仓库的评论和其他数据源进行补充；（4）如果想得到更普适的结果，社区需要扩展数据来源并试验多个来源的互补使用；另外，期望在需求工程活动方面进行进一步研究，而不仅仅是需求获取和分析。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03317", "html_url": "https://arxiv.org/abs/2509.03317", "title": "基于功能性ANOVA模型的贝叶斯增广回归树", "title_en": "Bayesian Additive Regression Trees for functional ANOVA model", "authors": "Seokhun Park,Insung Kong,Yongdai Kim", "background": "贝叶斯增广回归树（BART）是一种结合了贝叶斯推断和回归树优势的统计模型，能够捕捉复杂非线性关系和预测因子之间的交互作用。尽管BART的预测能力很强，但它的可解释性通常较差。因此，本文提出了一种创新的ANOVABART模型，基于功能性ANOVA分解，将功能分解为不同交互作用，从而增强模型的可解释性，同时保持和扩展了BART的理论保证，并实现了更好的预测性能。", "innovation": "提出了ANOVABART模型，这是一种基于功能性ANOVA分解的BART扩展，能够在增强模型可解释性的同时，保持BART的预测性能和理论保证。ANOVABART还证明了在精度和不确定性量化方面优于BART，同时也展示了其组件选择的有效性。研究表明，ANOVABART在预测准确性、可解释性和理论一致性方面提供了BART的替代方案。", "conclusion": "ANOVABART模型通过平衡预测准确性、可解释性和理论一致性，为BART提供了一种有吸引力的替代方案，特别是在功能性ANOVA模型中表现出色。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02175", "html_url": "https://arxiv.org/abs/2509.02175", "title": "理解空间是火箭科学——只有顶级推理模型能解决空间理解任务", "title_en": "Understanding Space Is Rocket Science -- Only Top Reasoning Models Can Solve Spatial Understanding Tasks", "authors": "Nils Hoehing,Mayug Maniparambil,Ellen Rushe,Noel E. O'Connor,Anthony Ventresque", "background": "现有的视觉语言模型（VLMs）在理解空间关系方面表现出不足，特别是对于复杂的相对位置和对象顺序的理解。当前的VLMs在这方面面临困难，而人类对此类任务处理起来相对容易。", "innovation": "作者提出了一种名为RocketScience的开源对比VLM基准，旨在测试模型对空间关系的理解能力。该基准由全新的真实世界图像-文本对组成，主要涵盖相对空间理解及对象顺序。实验结果显示，开源及前沿商业VLMs在空间理解方面表现差强人意，而推理模型的表现却出乎意料地好。此外，作者还进行了去纠缠分析，发现链式推理模型在基准测试中的表现受制于空间推理能力而非对象定位能力。", "conclusion": "研究表明开源和前沿商业VLMs在空间关系理解方面存在显著缺陷，而推理模型的表现尤为突出。该基准和数据集有助于提升视觉模型的空间理解能力，并揭示了空间推理在VLM中的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03896", "html_url": "https://arxiv.org/abs/2509.03896", "title": "分析代码异味相互作用导致的依赖分布变化", "title_en": "Analyzing Variations in Dependency Distributions Due to Code Smell Interactions", "authors": "Zushuai Zhang,Elliott Wen,Ewan Tempero", "background": "模块间的依赖关系会影响软件维护的复杂性和成本，因此建议减少模块间的依赖。研究表明，代码异味（即代码中可能表现出潜在设计问题的特性）的相互作用可能会增加模块间的依赖关系。本文通过对116个开源Java系统的依赖分析，量化了代码异味之间的相互作用以及与其他非代码异味之间的相互作用，旨在验证先前观察到的现象。", "innovation": "通过分析开源Java系统的代码依赖关系，探讨代码异味相互作用对依赖分布变化的影响，特别是量化了代码异味对依赖关系的具体影响，为软件维护提供新的视角。", "conclusion": "代码异味的相互作用与不同种类的依赖关系的变化有关，总体上表现为总依赖关系的增加。例如，特征嫉妒方法与数据类之间的中位依赖关系是无特征嫉妒方法的七倍。这表明开发人员应优先处理那些相互作用的代码异味，而不是孤立存在的代码异味。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03900", "html_url": "https://arxiv.org/abs/2509.03900", "title": "Auth Shim: 轻量级架构模式，用于将企业单点登录集成到独立开源应用程序", "title_en": "The Auth Shim: A Lightweight Architectural Pattern for Integrating Enterprise SSO with Standalone Open-Source Applications", "authors": "Yuvraj Agrawal", "background": "开源软件（OSS）在企业环境中得到了广泛应用，但单独的工具往往缺乏对SAML或OIDC等协议的支持，这导致了关键的安全集成缺口。这种情况下，尽管个别工具拥有顺畅的身份验证和会话管理，企业通常需要自建安全对接服务，这增加了复杂性和成本。", "innovation": "该论文提出并正式化了Auth Shim（身份验证 shim），这是一种轻量级的架构模式，旨在解决这个问题。Auth Shim是一个轻量级的外部代理服务，充当兼容层，将企业身份提供商（IdP）的请求转换为目标应用程序的原生会话管理机制。该模式实现了将开源工具无缝集成到企业单点登录（SSO）生态系统中。", "conclusion": "通过定义其组件、交互以及生产部署考虑，该论文提供了一个可重用、安全且成本效益高的蓝图，用于将任何独立的开源工具集成到企业SSO生态系统中，从而使组织能够拥抱开放源代码创新，同时不牺牲安全治理。论文通过案例研究展示了如何将开源BI工具与Okta SAML集成，实现了基于角色的访问控制RBAC并消除了手动用户预配置。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01938", "html_url": "https://arxiv.org/abs/2509.01938", "title": "EigenBench: 一种用于价值对齐的比较性行为测量方法", "title_en": "EigenBench: A Comparative Behavioral Measure of Value Alignment", "authors": "Jonathn Chang,Leonhard Piff,Suvadip Sana,Jasmine X. Li,Lionel Levine", "background": "人工智能与人类价值观的对齐是亟待解决的问题。目前缺乏衡量价值对齐的量化指标。该研究旨在解决这一问题。", "innovation": "提出了EigenBench：一种黑箱方法，用于比较性地基准测试语言模型的价值。通过让模型评估其他模型的输出，然后使用EigenTrust（一种评价体系）聚合这些判断，从而得出衡量模型与给定宪法对齐程度的向量分数。该方法不依赖于真正的标签值，能够衡量不同评判者可能有不同的正确标签的特质。", "conclusion": "实验结果显示，大部分变异可以通过提示解释，但仍有部分反映了模型本身的态度或倾向性。这表明，虽然提示起主要作用，但模型自身的特性仍对结果有一定影响。"}
{"llm_update_time": "20250906", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02077", "html_url": "https://arxiv.org/abs/2509.02077", "title": "基于句子变换器的方法从攻击描述到漏洞", "title_en": "From Attack Descriptions to Vulnerabilities: A Sentence Transformer-Based Approach", "authors": "Refat Othman,Diaeddin Rimawi,Bruno Rossi,Barbara Russo", "background": "在安全领域，即使攻击已经被利用，漏洞仍常常未被检测到。本文中的漏洞指的是在CVE报告中公开披露的缺陷。建立攻击与漏洞之间的联系对于支持及时的事件响应至关重要，因为这能够为防御者提供即时的操作洞察。然而，手动将攻击与CVE进行关联是不切实际的，因此迫切需要自动化的方法。本研究评估了14种最先进的（SOTA）句子变换器，用于自动识别来自攻击描述的漏洞。结果表明，使用攻击技术描述时，MMMPNet模型的分类性能最佳，其F1分值为89.0，精确率为84.0，召回率为94.7。此外，在平均情况下，MMMPNet模型识别的56%的漏洞与CVE库中记录的关联攻击相匹配，而模型检测到的61%的漏洞与CVE中登记的漏洞相符。人工检查结果发现，模型预测的275个链接中有相当一部分并未在MITRE仓库中记录。这表明将攻击技术链接到漏洞的自动化不仅提升了对软件安全事件的检测和响应能力，还缩短了漏洞的利用时间，从而有助于构建更安全的系统。", "innovation": "本文创新性地提出并应用了基于句子变换器的方法来自动识别攻击描述中的漏洞。利用14种SOTA的句子变换器模型，特别是在使用攻击技术描述时，MMMPNet模型表现出最优异的分类性能。模型识别的链接中，有相当一部分未在MITRE仓库中记录，这一发现进一步强调了该自动化方法在提升系统安全性方面的潜力。", "conclusion": "本研究通过评估14种先进的句子变换器模型在自动识别攻击描述中的漏洞方面的性能，证明了MMMPNet模型的优越性，特别是在使用攻击技术描述的情况下。该自动化链接方法不仅提高了对软件安全事件的检测和响应能力，还减少了漏洞的利用时间，有助于构建更加安全的系统。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03876", "html_url": "https://arxiv.org/abs/2509.03876", "title": "漏洞受影响版本识别：我们还有多远？", "title_en": "Vulnerability-Affected Versions Identification: How Far Are We?", "authors": "Xingchu Chen,Chengwei Liu,Jialun Cao,Yang Xiao,Xinyue Cai,Yeting Li,Jingyi Shi,Tianqi Sun,Haiming Chen ang Wei Huo", "background": "识别哪些软件版本受漏洞影响对于打补丁和风险评估至关重要。尽管存在很多工具，但其实际效果仍不明确，原因在于评估范围狭窄，通常局限于早期SZZ变体，使用过时的技术，或者数据集规模小且粒度过粗。目前尚未进行过全面的经验研究来评估这些工具的效果。因此，需要一个高质量的基准数据集来系统评估这些工具，并从中揭示其根本局限性及挑战，以指导工具开发和未来研究。", "innovation": "本文首次进行了全面的经验研究，创建了高质量的基准数据集（包含1,128个真实C/C++漏洞），并系统地评估了12个代表性的工具，涵盖跟踪和匹配两大范式。评估维度包括漏洞和版本级别上的有效性、假正例和假负例的根本原因、对补丁特征的敏感性，以及集成潜力。通过这些研究揭示了工具使用的根本局限性，包括准确性低于45.0%，主要挑战来自启发式依赖、有限的语义推理和僵化的匹配逻辑，以及补丁结构的影响。这项研究还提出了一些实际的建议来指导工具开发、集成策略和未来研究方向，并公开了重复代码和基准数据集以促进未来的研究和发展。", "conclusion": "现有工具的整体准确性低于60.0%，表明需要采取根本性的新方法来解决这个问题。此外，该研究对工具开发、集成策略和未来研究提供了一系列可操作的见解。最后，研究人员发布了复现代码和基准数据集，以促进未来的研究。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03848", "html_url": "https://arxiv.org/abs/2509.03848", "title": "向软件生态系统中的开发者体验驱动透明性理解", "title_en": "Towards an Understanding of Developer Experience-Driven Transparency in Software Ecosystems", "authors": "Rodrigo Oliveira Zacarias,Rodrigo Pereira dos Santos,Patricia Lago", "background": "软件生态系统（SECO）已成为软件行业的主要模式，使得第三方开发者能够通过互补的组件和服务共同创造价值。尽管开发者体验（DX）越来越被认可为可持续SECO的关键因素，但透明性作为影响开发者感知和互动的因素仍未得到充分探索。现有研究已认识到透明性对于信任、公平和社会互动的重要性，但其与DX之间的关系尚未系统化。因此，本文旨在从开发者中心的角度深化对SECO中透明性的理解。", "innovation": "本文提出了SECO-TransDX（从开发者体验视角的软件生态系统透明性）的概念模型，引入了由开发者体验驱动的透明性的新概念。该模型识别了63个相互关联的概念，包括影响透明性如何在开发者互动中被感知和构建的条件因素、生态系统过程、制品和关系动态。该模型是在先前研究的基础上，通过专家（来自学术界和产业界）的德尔菲研究进一步完善形成的。", "conclusion": "SECO-TransDX提供了一种结构化的视角来研究透明性如何跨越技术、社会和组织层面对DX产生影响。该模型为研究人员提供了未来研究和工具开发的基础，为从业者提供了设计信赖、以开发者为中心的平台的支持，这些平台能够提高透明度并促进长期参与软件生态系统。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03875", "html_url": "https://arxiv.org/abs/2509.03875", "title": "VulRTex: 一种基于推理指导的方法，用于从富文本问题报告中识别漏洞", "title_en": "VulRTex: A Reasoning-Guided Approach to Identify Vulnerabilities from Rich-Text Issue Report", "authors": "Ziyou Jiang,Mingyang Li,Guowei Yang,Lin Shi,Qing Wang", "background": "开源软件（OSS）中存在软件漏洞，开发者发现这些漏洞后会提交问题报告（IRs）描述细节。安全从业人员需要手动花费大量时间识别与漏洞相关的IRs，而这一过程中的时间延迟可能被攻击者利用来损害系统。此前，研究人员提出了自动方法来辅助识别这些与漏洞相关的IRs，但这些方法主要关注文本描述，缺乏对IRs丰富文本信息的全面分析。因此，我们提出了VulRTex，一种基于推理的方法，用于识别包含丰富文本信息的漏洞相关IRs。", "innovation": "VulRTex首先利用大型语言模型（LLM）的推理能力构建漏洞推理数据库，然后从准备好的推理数据库中检索相关案例生成推理指导，指导LLM通过对目标IRs的丰富文本信息进行推理分析来识别漏洞。实验结果表明，VulRTex在不平衡数据集下识别漏洞相关的IRs和预测CWE-IDs方面表现最好，比最佳基线方法提高了+11.0% F1值，+20.2% AUPRC值，+10.5%宏F1值，并且执行时间比基线推理方法低2倍。此外，VulRTex还应用于2024年GitHub中的30个新兴漏洞识别，成功分配了11个CVE-ID，展示了VulRTex的实际应用价值。", "conclusion": "VulRTex在识别漏洞相关的IRs和预测CWE-IDs方面表现出色，特别是在数据集不平衡的情况下。与基线方法相比，它在F1值、AUPRC值和宏F1值上分别提高了11.0%、20.2%和10.5%，并且执行时间更短。此外，VulRTex在实际应用中也证明了其可行性和有效性。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03711", "html_url": "https://arxiv.org/abs/2509.03711", "title": "Reactive Bottom-Up Testing", "title_en": "Reactive Bottom-Up Testing", "authors": "Siddharth Muralee,Sourag Cherupattamoolayil,James C. Davis,Antonio Bianchi,Aravind Machiry", "background": "现代计算系统中存在诸多软件漏洞，工程师们使用多种方法进行检测，动态测试是其中最常见和有效的一种。然而，大多数动态测试技术遵循自顶向下的模式，难以探测到并测试深处调用图中的函数。近年来，有研究提出了自底向上的方法来解决这些问题，但此类方法面临误报以及生成符合程序完整上下文的有效输入的挑战。", "innovation": "本文提出了一种新的自底向上的测试范式——反应式自底向上的测试（Reactive Bottom-Up Testing）。该方法通过三个阶段执行：1) 认识可能的脆弱函数并生成类型和上下文感知的测试框架；2) 通过符号执行发现崩溃并提取输入约束；3) 结合约束验证崩溃以去除误报。这种方法通过自动实现原型工具Griller，在控制环境中检测到48个已知漏洞中的28个，并在实际应用中发现6个未知漏洞。", "conclusion": "研究结果表明，反应式自底向上的测试可以显著提高复杂系统中漏洞的检测能力，为进一步增强更安全的实践开辟了新途径。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03554", "html_url": "https://arxiv.org/abs/2509.03554", "title": "APB交易的多阶段错误诊断", "title_en": "A Multi-stage Error Diagnosis for APB Transaction", "authors": "Cheng-Yang Tsai,Tzu-Wei Huang,Jen-Wei Shih,I-Hsiang Wang,Yu-Cheng Lin,Rung-Bin Lin", "background": "现代片上系统（SoC）设计中，功能验证和调试是关键瓶颈。在大型值变化导出（VCD）文件中手动检测高级外围总线（APB）交易错误效率低且容易出错。", "innovation": "提出了一种基于层次化随机森林的自动错误诊断框架，采用多阶段错误诊断策略，使用四个预训练的二元分类器依次检测超出范围访问、地址损坏和数据损坏错误，优先检测高确定性地址相关故障，再处理复杂的数据错误，以提高效率。实验结果显示整体准确率为91.36%，对地址错误的精确度和召回率近乎完美，数据错误表现稳健。", "conclusion": "该研究证实了层次化机器学习作为电子设计自动化（EDA）中硬件调试的强有力自动工具的潜力。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04328", "html_url": "https://arxiv.org/abs/2509.04328", "title": "FaaSGuard: 用于OpenFaaS的服务器less应用安全持续集成/持续部署", "title_en": "FaaSGuard: Secure CI/CD for Serverless Applications -- An OpenFaaS Case Study", "authors": "Amine Barrak,Emna Ksontini,Ridouane Atike,Fehmi Jaafar", "background": "服务器less计算通过抽象基础设施管理，简化了软件开发，支持快速、模块化的事件驱动部署。然而，服务器less函数的特性，如短暂执行和细粒度的扩展性，带来了独特的安全挑战，尤其是在OpenFaaS等开源平台上。现有方法通常只解决DevSecOps生命周期中的孤立阶段，缺乏综合性的安全策略。为填补这一空白，我们提出了FaaSGuard，这是一种专门针对开源服务器less环境的统一DevSecOps流水线。FaaSGuard在开发生命周期的每个阶段系统地嵌入了轻量级、失效闭合的安全检查，有效应对诸如注入攻击、硬编码秘密和资源耗尽等威胁。", "innovation": "FaaSGuard专门设计用于开源服务器less环境的统一DevSecOps流水线，系统地嵌入了轻量级、失效闭合的安全检查，全面覆盖开发生命周期的各个阶段，包括规划、编码、构建、部署和监控。这种方法有效地检测和预防关键漏洞，同时不显著干扰现有的CI/CD实践。", "conclusion": "我们通过公共GitHub仓库中的20个实际服务器less函数的案例研究，验证了FaaSGuard的有效性。结果显示，我们的方法能够以高精度（95%）和召回率（91%）检测和防止关键漏洞，证明了其在确保安全的同时，能够保持与传统CI/CD流程的高度兼容性。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04423", "html_url": "https://arxiv.org/abs/2509.04423", "title": "设计与开发：血液捐赠管理的Web平台", "title_en": "Design and Development of a Web Platform for Blood Donation Management", "authors": "Fatima Zulfiqar Ali,Atrooba Ilyas", "background": "血液捐赠是医疗保健的关键组成部分，但在紧急情况下找到合适的捐赠者常常面临巨大挑战。因此，需要一个有效且易于使用的平台来连接患者、捐赠者和管理人员，以简化紧急情况下的血液捐赠流程，提高血液的及时获取效率并增强整体献血服务的效率。", "innovation": "该平台采用PHP（Laravel框架）、HTML、CSS、Bootstrap和MySQL等现代Web技术，并通过XAMPP和Visual Studio Code开发，设计了一个动态、交互且用户友好的系统。通过设计和实施用例图、数据库图、类图和顺序图，确保了系统结构的合理性和高效性。平台通过简化注册献血者、血液请求和沟通流程，在紧急情况下减少了延迟和复杂性，从而提高了血液的及时获取效率，并提升了整体献血服务的效率。", "conclusion": "本文介绍了设计和开发的血液捐赠Web平台，该平台能够在中央数字空间内连接患者、捐赠者和管理员。通过采用现代Web技术和确保系统结构设计合理，该平台在紧急情况下简化了血液捐赠流程，提高了血液供应和献血服务的整体效率。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04260", "html_url": "https://arxiv.org/abs/2509.04260", "title": "Python包漏洞及其检测的实证研究", "title_en": "An Empirical Study of Vulnerabilities in Python Packages and Their Detection", "authors": "Haowei Quan,Junjie Wang,Xinzhe Li,Terry Yue Zhuo,Xiao Chen,Xiaoning Du", "background": "在快速发展的软件开发领域，Python由于其简洁性、多功能性和丰富的生态系统而受到青睐。Python包作为可组织、可重用和可分发的单位，已经引起了广泛关注。Python作为脚本语言，经常与其他语言合作以提高性能或实现互操作性，这增加了Python包固有漏洞的复杂性。当前的漏洞检测工具的效果尚未得到充分探索。因此，有必要建立一个全面的基准库来评估现有工具的有效性，并揭示当前检测工具的局限性，推动未来发展。", "innovation": "该论文介绍了PyVul，这是第一个全面的Python包漏洞基准库。PyVul包含了1,157个基于公共报告和开发者验证的漏洞，每个漏洞都与其受影响的包相关联。PyVul通过在提交和函数级别提供注释来适配不同的检测技术。还引入了一种基于LLM的数据清理方法，以提高标签准确性，使其成为最具精准度的大规模Python漏洞基准库。此外，通过分发分析发现，Python包中的漏洞涉及多种编程语言，并具有多种类型。多语言Python包可能更易遭受漏洞侵扰。", "conclusion": "使用该基准库评估最先进的检测器揭示了现有工具和真实世界的安全问题之间的显著差距。此外，对Python包中观察到的顶级CWE进行了经验审查，以诊断当前检测工具的细化限制并强调未来发展的重要性。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.04078", "html_url": "https://arxiv.org/abs/2509.04078", "title": "RepoDebug：多任务与多语言的大语言模型在仓库级调试评估", "title_en": "RepoDebug: Repository-Level Multi-Task and Multi-Language Debugging Evaluation of Large Language Models", "authors": "Jingjing Liu,Zeming Liu,Zihao Cheng,Mengliang He,Xiaoming Shi,Yuhang Guo,Xiangrong Zhu,Yuanfang Guo,Yunhong Wang,Haifeng Wang", "background": "大型语言模型（LLMs）在代码调试方面表现出显著的能力，特别是在自动程序修复方面，这可能大大降低开发人员的时间消耗并提高其效率。为了促进代码调试的发展，已经对调试数据集进行了显著的改进。然而，这些数据集主要集中在评估LLM的功能级代码修复能力上，忽视了更复杂和现实的仓库级场景，导致对LLM在仓库级调试方面的挑战的理解不够完整。尽管已经提出了一些仓库级数据集，但它们往往存在任务多样性和语言错误类型的限制。", "innovation": "本文提出RepoDebug数据集，这是一个多任务和多语言的仓库级代码调试数据集，包含22种错误类型，支持8种常用的编程语言和3种调试任务，解决了现有数据集的局限性。此外，我们还在10种大语言模型上进行了评估实验，结果显示Claude 3.5 Sonnect，表现最佳的模型，在仓库级调试方面仍表现不佳。", "conclusion": "尽管Claude 3.5 Sonnect在代码修复方面表现出色，但在仓库级调试中仍然存在挑战。RepoDebug数据集的引入将有助于开发人员更全面地理解大语言模型在仓库级调试中的局限性和挑战，从而促进相关研究的进步。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.09002", "html_url": "https://arxiv.org/abs/2503.09002", "title": "KNighter：利用LLM生成检查器转换静态分析", "title_en": "KNighter: Transforming Static Analysis with LLM-Synthesized Checkers", "authors": "Chenyuan Yang,Zijie Zhao,Zichen Xie,Haoyu Li,Lingming Zhang", "background": "静态分析是一种强大的技术，能够检测关键系统（如操作系统内核）中的错误。然而，设计和实现静态分析器具有挑战性，耗时，并且通常仅局限于预定义的错误模式。虽然大型语言模型（LLMs）在静态分析方面显示出潜力，但由于计算限制和上下文限制，直接将其应用于扫描大型系统仍然是不切实际的。因此，KNighter通过自动从历史错误模式生成静态分析器，成为第一个解锁大规模LLM驱动静态分析的方法。研究者提出通过利用LLMs生成由历史补丁知识引导的专业化静态分析器，而不是直接使用LLMs来分析大规模系统。评估结果显示，KNighter生成的检查器能够检测到现有的人类编写的分析器未能察觉的多种错误模式，同时发现了显著数量的新、关键和长期隐匿的错误（平均4.3年），其中77个已经得到确认并被修复，30个已分配了CVE编号。这一工作为现实世界系统中的大规模、可靠和可跟踪的LLM驱动静态分析提供了全新的范式，这通过检查器的合成实现", "innovation": "KNighter通过自动从历史错误模式生成静态分析器，解锁了大规模LLM驱动静态分析的潜力。这一方法利用大型语言模型生成专业化的静态分析器，而不是直接将大型语言模型应用于大型系统。KNighter通过多阶段合成管道验证检查器的正确性，并通过自动精炼过程逐步减少假阳性。这些检查器在Linux内核上能够检测新的人类编写的分析器无法发现的多种错误模式，显著提高了错误检测的精度和覆盖率", "conclusion": "KNighter建立了一种全新的模式，即通过检查器的合成来实现大型语言模型驱动的静态分析，这一方法在实际系统中展现了高度的可靠性和可追踪性。由于已从Linux内核中发现并确认了92个新的关键性和长期潜伏的错误（平均历时4.3年），77个已被修复，30个已分配CVE编号，因此KNighter的重大进展奠定了这一新领域的基础"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2501.14326", "html_url": "https://arxiv.org/abs/2501.14326", "title": "评估大规模语言模型在不同内存模型下理解与验证并发程序的能力", "title_en": "Assessing Large Language Models in Comprehending and Verifying Concurrent Programs across Memory Models", "authors": "Ridhi Jain,Rahul Purandare", "background": "随着并发编程的日益普及，有效地识别和解决数据竞争和死锁等并发问题变得至关重要。该研究评估了几种领先的大规模语言模型（LLMs），包括GPT-3.5-turbo, GPT-4, GPT-4o, GPT-4o-mini和Mistral-AI的Large2，以评估它们在软件程序中理解与分析并发问题的能力。由于现代系统中广泛实施并适应了放松内存模型，如Total Store Order (TSO)和Partial Store Order (PSO)，即使进一步在 ARM 和 x86 等常见架构上得到了支持，研究不仅关注顺序一致内存模型，还关注这些放松内存模型。", "innovation": "研究利用SV-COMP的pthreads测试和25个ARM Litmus测试来评估总存储顺序（TSO）和部分存储顺序（PSO）内存模型。结果揭示了GPT-4、GPT-4o与Mistral-AI的Large2在顺序一致内存模型下对并发问题有稳健的理解，能够有效检测数据竞争和死锁。然而，所有选择的LLMs在验证放松内存模型下程序的正确性方面面临重大挑战，表现为难以准确捕捉内存排序约束，现有能力不足以验证这些复杂场景中的小型程序。", "conclusion": "尽管GPT-4、GPT-4o与Mistral-AI的Large2在顺序一致内存模型下对并发问题有稳健的理解，但它们在放松内存模型下验证程序正确性方面能力明显不足，主要由于难以准确捕捉内存排序约束，这些模型当前的能力无法验证复杂场景下的小型程序。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03668", "html_url": "https://arxiv.org/abs/2509.03668", "title": "大规模编程过程分析中通过时间跟踪解析树", "title_en": "Parse Tree Tracking Through Time for Programming Process Analysis at Scale", "authors": "Matt Rau,Chris Brown,John Edwards", "background": "编程过程中产生的数据可以用来理解学生编写计算机编程作业所用的过程。以往的研究主要通过高阶的描述性统计（如时间、字符删除率等）来利用这些数据。自动化追踪随时间变化的高度层次化的代码表示，如抽象语法树（AST），以及无法解析的状态仍然困难，这使得在具体情境中分析行为变得复杂。", "innovation": "该研究设计了第一个算法，用于通过时间追踪解析树节点，并利用此算法进行手动追踪代码表示的先前工作的部分再验证，以及对学生编程行为的更具规模的新型分析。", "conclusion": "通过时间追踪解析树的能力为理解学生编程的新维度打开了大门，比如随着时间变化的代码结构开发的最佳实践、学生在最复杂的语法结构上遇到的困难度定量化测量、重构行为以及代码内注意力转移。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.02737", "html_url": "https://arxiv.org/abs/2504.02737", "title": "RBT4DNN: Requirements-based Testing of Neural Networks", "title_en": "RBT4DNN: Requirements-based Testing of Neural Networks", "authors": "Nusrat Jahan Mozumder,Felipe Toledo,Swaroopa Dola,Matthew B. Dwyer", "background": "现有的系统中包含了深度神经网络(DNNs)，对其进行测试变得极具挑战性。因为这些网络实现的功能对于形式化功能需求的正式化来说是无法解决的。因此，无法使用基于需求的测试的成熟方法来测试这些神经网络。现有技术无法明确给出输入输出之间的关系。因此，论文探讨了如何通过自然语言需求陈述来进行基于需求的测试，以克服这个难题。", "innovation": "提出了一种基于需求的测试方法（RBT4DNN），该方法使用自然语言需求陈述中的术语词典来定义语义特征空间，据此生成测试输入。RBT4DNN将功能需求的先决条件形式化为语义特征的逻辑组合，并利用与这些特征组合匹配的训练数据来微调生成模型以可靠地生成满足先决条件的测试输入。这种方法既适用于反馈式探索模型行为，也可以用于发现模型故障。研究结果表明，RBT4DNN生成的测试用例是现实的、多样的，并与需求先决条件一致，能够有效地实现模型行为的精确分析以及故障检测。", "conclusion": "RBT4DNN方法能够生成符合需求先决条件的测试用例，这些测试用例是现实的、多样的，能够有效检测模型故障并提供模型通用性的反馈。该方法为深度学习模型的测试提供了一个全新的解决方案。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.23684", "html_url": "https://arxiv.org/abs/2505.23684", "title": "如何提取可解释性需求？焦点小组、访谈和调查的比较", "title_en": "How to Elicit Explainability Requirements? A Comparison of Interviews, Focus Groups, and Surveys", "authors": "Martin Obaidi,Jakob Droste,Hannah Deters,Marc Herrmann,Raymond Ochsner,Jil Klünder,Kurt Schneider", "background": "随着软件系统的日益复杂，可解释性已成为确保透明度、用户信任和合规性的关键非功能性需求。提取可解释性需求具有挑战性，因为不同的方法可能会捕捉到不同级别的细节和结构。本研究旨在通过比较三种常用的方法（焦点小组、访谈和在线问卷）的效率和有效性，并评估分类学使用的作用，来了解可解释性需求的提取过程。在一家大型德国IT咨询公司，采用基于web的人力资源管理软件进行了一项案例研究，分析了2个焦点小组、18次访谈和188份在线问卷的结果，以评估不同方法的效果。", "innovation": "本研究通过具体案例分析了三种常用方法（焦点小组、访谈和在线问卷）在提取可解释性需求方面的效率和效果，并探讨了分类学在规范和改进提取过程中的作用。研究发现，访谈是最有效的，每单位时间内捕获的需求最多。问卷收集的需求最多，但存在高冗余。延迟引入分类学导致更多样化的需求，因此建议采用两阶段方法，更好地利用分类学。此外，研究还推荐将问卷和访谈结合使用，以平衡效率和覆盖范围。未来的研究应探索自动化如何辅助需求提取以及如何更好地将分类学应用到不同方法中。", "conclusion": "研究建议采用问卷和访谈相结合的方法来平衡效率和覆盖率。未来的研究应探索自动化如何支持需求提取以及如何将分类学更好地整合到各种方法中。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2406.01359", "html_url": "https://arxiv.org/abs/2406.01359", "title": "R2C2-Coder: 提升和基准测试代码大语言模型在真正环境中的仓库级代码完成能力", "title_en": "R2C2-Coder: Enhancing and Benchmarking Real-world Repository-level Code Completion Abilities of Code Large Language Models", "authors": "Ken Deng,Jiaheng Liu,He Zhu,Congnan Liu,Jingxin Li,Jiakai Wang,Peng Zhao,Chenchen Zhang,Yanan Wu,Xueqiao Yin,Yuanxing Zhang,Zizheng Zhan,Wenbo Su,Bangyu Xiang,Tiezheng Ge,Bo Zheng", "background": "近年来，代码补全模型取得了显著进步，特别是在现代软件开发中的仓库级代码补全方面吸引了更多关注。尽管已经提出了一些基线方法和基准测试，但现有的仓库级代码补全方法往往未能充分利用项目仓库中的广泛上下文，例如相关文件的复杂性和类层次结构。此外，现有的基准测试通常集中在有限的代码补全场景上，不能很好地反映现有方法的仓库级代码完成能力。", "innovation": "本文提出了一种名为R2C2-Coder的方法，旨在增强并基准测试代码大语言模型在真正环境中的仓库级代码完成能力。R2C2-Coder包括一种名为R2C2-Enhance的代码提示构建方法和一个精心设计的基准测试R2C2-Bench。R2C2-Enhance通过构建候选检索池并从该池中检索每个完成光标位置来构建补全提示。在此基础上，R2C2-Bench则通过训练、验证和测试集划分构造了一个更具挑战性和多样性的基准测试，并提出了上下文扰动策略以更好地模拟真实的仓库级代码补全情景。", "conclusion": "在多个基准测试上的广泛结果证明了R2C2-Coder的有效性。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.03659", "html_url": "https://arxiv.org/abs/2507.03659", "title": "使用Large语言模型指导的Dafny程序算术错误自动修复", "title_en": "Specification-Guided Repair of Arithmetic Errors in Dafny Programs using LLMs", "authors": "Valentina Wu,Alexandra Mendes,Alexandre Abreu", "background": "当程序验证不通过时，调试和修复故障可能既复杂又耗时。传统的自动程序修复（APR）技术依赖于测试套件进行验证，但这些测试套件可能无法涵盖所有可能的场景。相比之下，形式化规范提供了强健的正确性标准，能够更有效地进行自动修复。本文介绍了如何利用形式化规范和大型语言模型来指导Dafny程序的算术错误自动修复工具。Dafny是一种带有验证意识的编程语言，它使用形式化规范（包括前置条件、后置条件和不变式）来定位故障和生成候选修复方案。假设这些规范的正确性，该工具通过一系列步骤实现故障定位，包括使用Hoare逻辑确定每个语句的程序状态，并应用大型语言模型来生成候选修复方案。", "innovation": "该研究提出了一种新的自动程序修复工具，该工具结合了形式化推理和大型语言模型程序合成。该工具利用Dafny语言的特性，使用形式化规范来指导故障定位和修复过程，并使用大型语言模型（GPT-4o mini、Llama 3、Mistral 7B和Llemma 7B）来生成候选修复方案。", "conclusion": "通过使用DafnyBench基准测试，该工具实现了89.6%的故障定位覆盖率，GPT-4o mini修复成功率最高，达到74.18%。这表明将形式化推理与基于大型语言模型的程序合成相结合，在自动程序修复领域具有巨大潜力。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08523", "html_url": "https://arxiv.org/abs/2507.08523", "title": "InferLog：基于前缀缓存的LLM推理加速技术以提升在线日志解析", "title_en": "InferLog: Accelerating LLM Inference for Online Log Parsing via ICL-oriented Prefix Caching", "authors": "Yilun Wang,Pengfei Chen,Haiyu Huang,Zilong He,Gou Tan,Chuanfu Zhang,Jingkai He,Zibin Zheng", "background": "现代软件系统生成大量的运行时日志，需要高效准确的日志解析以支持诸如异常检测和根本原因分析等关键下游任务。大型语言模型（LLMs）在日志解析方面显示出先进的准确率，但在生产环境中部署面临两大限制：（1）商业LLMs的隐私风险，促使采用本地部署；（2）高流量日志流对延迟和吞吐量的严苛要求，现有的LLM基日志解析器无法满足。尽管最近的努力减少了LLM查询的数量，但它们忽视了LLM调用的高延迟问题，多并发日志解析请求会导致LLM推理系统的性能下降。纵观全局，推断效率是制约基于LLM的在线日志解析的关键瓶颈，而非解析准确性。", "innovation": "本研究提出了InferLog，一种针对在线日志解析的LLM推理优化方法。InferLog通过（1）设计前缀感知的ICL精炼策略来改进缓存效率；（2）基于元学习的快速且特定任务的配置调优流水线，找到动态日志解析工作负载下的最佳LLM调度相关配置。基于Loghub数据集和vLLM的实验结果显示，InferLog在不牺牲解析准确性的情况下，显著超越现有推理优化方法，并大幅加速了最先进的基于LLM的日志解析器。", "conclusion": "InferLog是第一条针对基于LLM的在线日志解析的推理优化路径，通过改进缓存策略和配置调优，解决了LLM推理的高效性和性能问题，实现了即保持解析准确性的前提下的高效运行。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.16590", "html_url": "https://arxiv.org/abs/2505.16590", "title": "更大的模型并不总是更好：探索小型开源语言模型在日志语句生成中的应用", "title_en": "Larger Is Not Always Better: Exploring Small Open-source Language Models in Logging Statement Generation", "authors": "Renyi Zhong,Yichen Li,Guangba Yu,Wenwei Gu,Jinxi Kuang,Yintong Huo,Michael R. Lyu", "background": "开发人员使用日志语句生成日志来记录系统行为并辅助软件维护。因此，高质量的日志对于有效的维护至关重要。然而，手动日志记录往往会导致错误和不一致性。最近的方法强调使用大型语言模型（LLMs）来自动生成日志语句，但这些方法存在隐私和资源问题，阻碍了它们在企业中的应用。", "innovation": "本研究首次进行了大规模实验，评估了小型开源语言模型（SOLMs）在自动日志语句生成中的应用。评估了四种知名的SOLMs，使用了各种提示策略和参数高效的微调技术，如Low-Rank Adaptation (LoRA)和Retrieval-Augmented Generation (RAG)。结果表明，使用LoRA和RAG提示进行微调的SOLMs，特别是在Qwen2.5-coder-14B上，优于现有工具和基于LLM的基本模型，在预测日志位置和生成高质量声明方面表现更佳，且在多种不同类型的仓库中具有鲁棒的一般化效果。这些发现表明SOLMs是一种保护隐私、高效的自动化日志记录替代方案。", "conclusion": "研究结果表明，小型开源语言模型在自动日志语句生成中不仅可行，而且在隐私保护和效率方面具有优势，相比于大型语言模型，它们更适合实际的企业应用。"}
{"llm_update_time": "20250906", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.03807", "html_url": "https://arxiv.org/abs/2509.03807", "title": "BIDO: 统一应对图像恶意软件检测中混淆与概念漂移挑战的方法", "title_en": "BIDO: A Unified Approach to Address Obfuscation and Concept Drift Challenges in Image-based Malware Detection", "authors": "Junhui Li,Chengbin Feng,Zhiwei Yang,Qi Mo,Wei Wang", "background": "为了识别恶意的Android应用程序，多种恶意软件检测技术已被提出。图像基的方法由于其效率和可扩展性而被视为潜在的替代方案。然而，近期的研究表明，当面对混淆或概念漂移时，这些方法会遭受显著的性能下降。现有解决方案通常将这两种挑战视为不同的问题，提供了独立的解决方案。但是，这些技术忽视了这两种挑战共享一个共同的统计根源——即超出分布，并且从这个角度的研究仍然有限。", "innovation": "为此，我们提出了BIDO——一种增强对抗混淆和概念漂移的图像基恶意软件检测器，能够同时有效地应对这些挑战。具体来说，为了提高图像特征的区分能力，我们引入了一个局部特征选择模块，以识别恶意软件图像中的信息子区域。其次，为了增强特征的鲁棒性，我们建模了外积空间中的成对跨模态依赖性，从而提取稳定的共现模式。第三，为了保证特征的紧凑性，我们设计了一种可学习的度量标准，不仅在混合作用下拉近具有相同标签的样本，还驱散具有不同标签的样本。", "conclusion": "在真实世界的数据集上进行的大量实验表明，BIDO显著优于现有基线，达到了更好的对混淆和概念漂移的鲁棒性。完整的源代码可以在该链接下载：this https URL。"}
