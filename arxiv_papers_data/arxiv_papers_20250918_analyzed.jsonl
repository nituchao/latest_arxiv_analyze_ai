{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13357", "html_url": "https://arxiv.org/abs/2509.13357", "title": "具有模糊成员特征的语义融合方法用于可控语言建模", "title_en": "Semantic Fusion with Fuzzy-Membership Features for Controllable Language Modelling", "authors": "Yongchao Huang,Hassan Raza", "background": "本文提出了一种语义融合方案，该方案通过在基于Transformer的语言模型中增加一个并行的、模糊成员特征通道，增强了对标记级语义的编码能力。这种方案旨在提高可控语言生成的能力，同时保持模型的简洁性。", "innovation": "提出了一种轻量级的语义融合方案，该方案通过将模糊成员特征通道与Transformer语言模型并行结合，增加了对标记级语义的编码，提升了不可见属性下的语言模型性能。通过使用标准的下一个标记预测训练方式，以及重建语义特征的辅助损失和轻量级的规律化方法，可以实现精准且用户可控的极性和标点生成。", "conclusion": "语义融合方法在合成的两句句式语料库上进行测试，通过保持模型简洁性的同时实现了更好的困惑度。该方法可以实现精准且用户可控的极性和标点生成，且仅增加很小的计算量。此外，该方法还与共享输入输出嵌入完全兼容，并提供了一条可控自然语言生成的可解释途径。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13339", "html_url": "https://arxiv.org/abs/2509.13339", "title": "AI安全必须拥抱抗脆弱视角", "title_en": "Position: AI Safety Must Embrace an Antifragile Perspective", "authors": "Ming Jin,Hyunin Lee", "background": "当前的现代人工智能研究在安全性方面往往依赖于静态基准和单次稳健性测试，但这些方法未能考虑到环境的动态变化，模型可能会因为缺乏挑战而逐渐变得不适应。这可能导致模型出现诸如奖励作弊、过度优化或更广泛的技能退化等问题。该论文认为，从抗脆弱性的角度出发，AI系统能够随着时间推移增强其应对极端事件的能力，这一观点对于确保开放性机器学习系统的长期可靠性至关重要。", "innovation": "该论文提出的观点是一种对抗脆弱的视角，旨在提高AI系统在处理罕见或 outlier 事件时的安全性。这一方法强调利用当前的不确定性和脆弱性来应对未来可能发生的更大、更难以预测的风险。同时，论文还提出需要改变现有的评估和改进AI安全的方法，以培养一个注重伦理和实践的抗脆弱AI安全社区。", "conclusion": "该论文强调，传统的静态基准测试和单一稳健性测试不足以保证AI系统的长期稳健性。采取抗脆弱的方法，不仅有助于提高系统的适应性，还能为未来的不确定性提供更好的准备。该研究认为，这是一种对于确保AI长期安全性的关键策略，并且为未来的研究提供了新的方向和方法论指导。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13352", "html_url": "https://arxiv.org/abs/2509.13352", "title": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "title_en": "Agentic UAVs: LLM-Driven Autonomy with Integrated Tool-Calling and Cognitive Reasoning", "authors": "Anis Koubaa,Khaled Gabr", "background": "无人驾驶飞机（UAVs）日益广泛应用于国防、监视和灾害响应等领域，但大多数系统仍处于SAE等级2-3的自主程度。现有系统主要依赖基于规则的控制和狭隘的人工智能，限制了其在动态、不确定任务中的适应能力。现有的UAV框架缺乏上下文感知的推理、自主决策和生态系统级别的整合能力；关键的是，它们没有利用大型语言模型（LLM）代理通过调用外部工具进行实时知识访问。", "innovation": "本文提出了Agentic UAVs框架，这是一种五层架构（感知、推理、行动、集成、学习），该架构通过LLM驱动的推理、数据库查询和第三方系统交互，增强了UAVs的功能。实验原型基于ROS2和Gazebo，在模拟的搜索与救援场景中，Agentic UAVs的检测置信度更高（0.79 vs. 0.72）、人员检测率更高（91% vs. 75%）以及行动建议的数量显著增加（92% vs. 4.5%）。结果显示，适度的计算开销可以实现更高层次的新自主性和生态系统整合。", "conclusion": "适度的计算开销能够实现一种全新的自主性水平和生态系统整合，Agentic UAVs框架通过LLM驱动的推理、数据库查询和与其他系统的交互，为UAV的功能提升提供了新的方法。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13341", "html_url": "https://arxiv.org/abs/2509.13341", "title": "想象自CURRICULUM", "title_en": "Imagined Autocurricula", "authors": "Ahmet H. Güzel,Matthew Thomas Jackson,Jarek Luca Liesen,Tim Rocktäschel,Jakob Nicolaus Foerster,Ilija Bogunovic,Jack Parker-Holder", "background": "在现实世界中，训练实体环境中的智能体通常需要大量的训练数据或精确的模拟，但这在许多情况下并不存在。为了解决这个问题，世界模型逐渐成为替代方案，利用非主动收集的数据生成多样化的世界用于智能体的训练。然而，确保智能体能够在生成的数据中学习到有用的信息仍然是一个挑战。因此，该研究提出了一个新的方法IMAC（想象自CURRICULUM），结合未监督环境设计来自动设计一个课程，用于生成的环境中。这种方法在一系列挑战性的、生成式生成环境中展示了优越性，即仅在窄数据集学习的世界模型中训练，也能实现较好的泛化性能，这为更大规模的基础世界模型提供了可能性，以实现更通用的智能体。", "innovation": "该研究提出了一个名为IMAC的新方法，它通过结合未监督的环境设计(UED)来自动设计生成环境中智能体训练的课程。这种方法使得智能体能够在由较小数据集学习的世界模型中进行训练，并仍能实现对未见过的环境的强大泛化性能，为使用更大规模的基础世界模型实现通用智能体铺平了道路。", "conclusion": "研究成果展示了利用IMAC方法，在仅使用较小数据集训练的世界模型中，智能体能够实现对新任务变体的强大泛化性能。研究认为这可以为利用更大规模的环境模拟训练更通用和高效的智能体打开新的途径。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13351", "html_url": "https://arxiv.org/abs/2509.13351", "title": "教授LLMs规划：逻辑链式思考指令调优的符号规划", "title_en": "Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning", "authors": "Pulkit Verma,Ngoc La,Anthony Favier,Swaroop Mishra,Julie A. Shah", "background": "大规模语言模型（LLMs）在各种任务中表现出色，但在执行结构化符号规划方面的能力有限，特别是在需要正式表示如规划领域定义语言（PDDL）的领域。研究指出，当前的LLMs在这方面的能力还存在不足。", "innovation": "本文提出了一种新颖的指令调优框架PDDL-Instruct，旨在通过逻辑链式思考推理增强LLMs的符号规划能力。该方法侧重于教授模型进行严格的逻辑推理，包括动作适用性、状态转换和计划有效性。通过开发指令提示来引导模型进行精确的逻辑推理，使LLMs能够通过结构化反思来自我纠正规划过程。框架通过将规划过程分解为预条件满足、效果应用和不变性保持的显式推理链，系统地培养验证技能。实验结果表明，基于链式推理的指令调优模型在多个规划领域表现出更优秀的规划能力，标准基准测试中的规划准确率达到94%，比基线模型提高了66%。这一研究缩小了LLMs通用推理能力和自动化规划所需的逻辑精确度之间的差距，为开发更好的AI规划系统提供了有希望的方向。", "conclusion": "该工作通过逻辑链式思考推理调优，显著提升了LLMs在符号规划方面的表现，为AI规划系统的发展提供了新的研究方向。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13334", "html_url": "https://arxiv.org/abs/2509.13334", "title": "FRIT: 通过因果重要性提高链式思考忠实性", "title_en": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness", "authors": "Anand Swaroop,Akshat Nallani,Saksham Uboweja,Adiliia Uzdenova,Michael Nguyen,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary", "background": "链式思考（CoT）推理已成为提升大型语言模型在复杂任务上的表现的强大工具。然而，最近的研究表明，推理步骤往往无法对最终答案产生因果影响，导致输出变得脆弱且不可靠。此前的方法主要集中在测量忠实性上，而系统地提高忠实性的方法仍然有限。", "innovation": "我们提出了干预训练以确保忠实推理（Faithful Reasoning via Intervention Training，FRIT），这是一种可扩展的对齐方法，通过学习系统性篡改的例子来训练模型产生因果一致的推理。FRIT通过生成合成训练数据，使个体推理步骤介入，创建忠实/不忠实的配对数据，从而强调推理破裂的时刻，然后使用直接偏好优化来教导模型优先选择因果一致的推理路径。", "conclusion": "我们的方法提供了第一个无监督的、可扩展的方法，用于训练语言模型生成更可靠和可解释的推理，在多项事实和符号推理任务中，FRIT在Mistral上的忠实推理增加了3.4个百分点，同时准确率提高了7.6个百分点。我们的方法填补了推理表现和可信性之间的关键缺口，我们已发布代码在 https URL。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13332", "html_url": "https://arxiv.org/abs/2509.13332", "title": "显式推理能让更好的评判者：关于准确度、效率和稳健性的系统研究", "title_en": "Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness", "authors": "Pratik Jayarao,Himanshu Gupta,Neeraj Varshney,Chaitanya Dwivedi", "background": "随着大型语言模型（LLMs）被越来越多地用作自动化法官来评估基准测试和奖励模型，确保它们的可靠性和稳健性变得至关重要。本文通过使用开源的Qwen 3模型（规模分别为0.6B、1.7B和4B参数），对‘思考’和‘非思考’LLMs进行了系统性比较。评估了它们在计算效率（FLOPs）和准确度方面的表现，并测试了不同增强策略对非思考模型的影响，例如情境学习、评分册引导评判、参照性评估和最n佳聚合。结果显示，尽管进行了这些改进，非思考模型仍然低于思考模型的表现。此外，实验证明，显式推理不仅在英文中，在多语言环境中同样也能带来显著优势。这些结果展示了显式推理在LLM评判者角色中的重要性，不仅仅是准确性和效率，还包括稳健性等方面都具有明显优势。", "innovation": "本文通过系统的实验证明，显式推理（thinking）的LLMs在作为评判者时不仅表现出更高的准确性和计算效率，而且还具有更好的稳健性。另外，研究还扩展到多语言环境，验证了显式推理的优势可以超越英语。这项研究为LLMs在评判任务中的应用提供了重要的实证证据和策略指导，表明显式推理在LLM作为评判者中的策略是有效和高效的。", "conclusion": "本研究通过系统的评估和实验，证明了显式推理模型（thinking）在准确度、效率和稳健性方面的显著优势，特别是在对抗偏见的能力上表现更为出色。此外，研究结果还表明，显式推理不仅适用于英语环境，也适用于多语言环境。最后，本研究提供了清晰的证据，说明在LLM作为评判者的角色中，显式推理策略具有明显的优势。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13347", "html_url": "https://arxiv.org/abs/2509.13347", "title": "OpenHA: Minecraft中的一系列开源层级智能体模型", "title_en": "OpenHA: A Series of Open-Source Hierarchical Agentic Models in Minecraft", "authors": "Zihao Wang,Muyao Li,Kaichen He,Xiangyu Wang,Zhancun Mu,Anji Liu,Yitao Liang", "background": "在开发能够高效、端到端训练的智能体时，行动空间的选择是一个关键但尚未解决的挑战。本文首先进行了广泛的系统比较，对比了多种视觉-语言-行动（VLA）或层级智能体模型中的主要抽象行动空间和分词工具在开放性Minecraft环境中的表现。研究显示，不存在一种普遍适用的最佳行动空间，最有效的抽象通常是高度依赖具体任务的，这给构建通用智能体带来了困难。", "innovation": "本文提出了Chain of Action（CoA）框架，这是一个新颖的框架，它将高级规划和低级控制统一在一个单一的、宏大的VLA模型中。CoA观点上将抽象动作视为指导生成最终可执行动作的中间推理步骤，类似于思维链条。此外，研究还表明，使用CoA框架进行端到端训练的单一全能智能体可以通过多样化的行动空间来学习更稳健和更通用的策略。这种统一智能体在综合任务成功率上超过了强大的专门基准模型。为促进可重复研究，本文还发布了OpenHA（开源层级代理）套件，包含800多个不同任务的全面基准测试、定制数据集、源代码以及所有预训练模型检查点等资源。", "conclusion": "我们的研究揭示了在VLA模型中特定任务依赖下的最优抽象行动空间的重要性，并通过CoA框架展示了如何构建和训练更强大的智能体。通过OpenHA套件，我们为这一领域提供了重要的基础工具和资源，有助于进一步的研究和应用。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13333", "html_url": "https://arxiv.org/abs/2509.13333", "title": "开放权重大型语言模型中的评估意识可预测地按比例扩展", "title_en": "Evaluation Awareness Scales Predictably in Open-Weights Large Language Models", "authors": "Maheep Chaudhary,Ian Su,Nikhil Hooda,Nishith Shankar,Julia Tan,Kevin Zhu,Ashwinee Panda,Ryan Lagasse,Vasu Sharma", "background": "大型语言模型（LLMs）能够区分评估和部署情境，这种行为称为‘评估意识’。此特性使得在进行AI安全评估时变得复杂，因为模型可能在测试中隐藏其危险能力。此前的研究已经在单一的70亿参数模型中展示了这种现象，但不同规模模型之间的扩展关系尚未得到揭示。本研究探讨了15个从0.27亿到70亿参数的四个模型家族的评估意识，并通过方向探针的方法分析向量激活的特征。研究结果表明，评估意识与模型规模之间存在明确的幂律关系：随着模型规模的增大，评估意识按预期增强。\n", "innovation": "研究发现不同规模的大型语言模型的评估意识表现出按比例扩展的幂律关系，这预测了未来更大规模模型的欺骗性行为，并为设计感知规模的评估策略提供了指导。这项研究填补了此前在不同规模模型上验证评估意识扩展性的空白。\n", "conclusion": "研究结果揭示了评估意识随模型规模增加而按预期增强的幂律关系，提示了可以通过评估规模来预测未来更大规模模型的行为。建议开发针对这种扩展性的评估策略和方法，以增强AI安全评价的有效性。\n"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13368", "html_url": "https://arxiv.org/abs/2509.13368", "title": "$Agent^2$: 一种生成型代理框架以实现强化学习自动化", "title_en": "$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation", "authors": "Yuan Wei,Xiaohan Shan,Ran Miao,Jianmin Li", "background": "强化学习代理的开发通常需要大量的专业知识和长时间的迭代，常常导致高失败率和低 accessibility。传统的开发方式既耗时又复杂，限制了强化学习技术的应用和扩展。", "innovation": "本文提出了一种名为 $Agent^2$ 的创新型代理生成框架，能够通过智能大语言模型驱动的生成来实现完全自动化的强化学习代理设计。$Agent^2$ 具备革命性的双代理架构，包括自动生成的生成代理和目标代理。该框架将强化学习开发过程分解为两阶段：MDP建模和算法优化，从而实现更精确和有效的代理生成。此外，$Agent^2$ 还采用了模型上下文协议，提供了一体化的框架，实现了多种环境和算法中的智能代理创建的标准化，并融入了自适应训练管理和智能反馈分析以实现持续改进。", "conclusion": "本文通过广泛的基准实验，在 MuJoCo、MetaDrive、MPE 和 SMAC 等一系列测试中，$Agent^2$ 的表现优于手动设计的解决方案，并实现了高达 55% 的性能提升和显著的平均收益。这标志着是一种真正端到端且闭环的自动化，开创了智能系统中智能代理设计和优化其他代理的新范式，对于自动化 AI 系统的发展具有基础性的突破意义。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13379", "html_url": "https://arxiv.org/abs/2509.13379", "title": "用“也许”的艺术：VLMs中不确定性基准测试的公型视角", "title_en": "The Art of Saying \"Maybe\": A Conformal Lens for Uncertainty Benchmarking in VLMs", "authors": "Asif Azad,Mohammad Sadat Hossain,MD Sadik Hossain Shanto,M Saifur Rahman,Md Rizwan Pervez", "background": "多模态视觉-语言模型（VLMs）已在复杂的视觉理解任务中取得了显著进展，尤其是在科学和推理任务中。虽然对这些模型性能的基准测试已经提升了我们对其能力的理解，但不确定性量化这一关键维度却未得到足够的关注。这项研究不同于以往仅限于特定环境的研究，而是进行了一项全面的不确定性基准测试，评估了16个最先进的VLMs（开源和非开源）在6个多模态数据集上的性能，使用了3种不同的评分函数。研究发现，更大的模型在不确定性量化方面表现更好；知道更多的人也更清楚他们不知道的内容。更确定的模型具有更高的准确性，而数学和推理任务在所有模型中的不确定性表现都差于其他领域.", "innovation": "本研究通过从公型预测角度进行全面的不确定性基准测试，评估了多种最先进的多模态视觉-语言模型在不同任务上的不确定量化能力，填补了之前研究的空白。研究不仅发现了模型规模与不确定性评估之间的关系，还揭示了不同任务类型下模型不确定性的表现差异.", "conclusion": "本研究建立了多模态系统中可靠不确定性评估的基础，这对于提高这些模型的预测精度和实际应用能力至关重要。未来的研究可以进一步探索不同类型的不确定性及其对模型性能的影响."}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13588", "html_url": "https://arxiv.org/abs/2509.13588", "title": "社会代理中的可编程认知偏差", "title_en": "Programmable Cognitive Bias in Social Agents", "authors": "Xuan Liu,Haoyang Shang,Haojian Jin", "background": "发现传统通过隐含自然语言描述来指定代理行为的方法无法在不同模型中产生一致的行为，并且生成的代理行为未能捕捉描述的细微差别。", "innovation": "提出了一种名为CoBRA的新工具，该工具通过将代理的预期行为与经典的社会科学实验对接，明确地编程代理的认知偏差。", "conclusion": "通过演示和技术基准评估了CoBRA作为HCI工具的效果。结果表明，CoBRA能够以模型无关的方式精确编程社会代理中表现出的认知偏差。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13615", "html_url": "https://arxiv.org/abs/2509.13615", "title": "见，思考，行动：通过识别按钮来教多模态代理有效与GUI交互", "title_en": "See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles", "authors": "Zongru Wu,Rui Mao,Zhiyuan Tian,Pengzhou Cheng,Tianjie Ju,Zheng Wu,Lingzhong Dong,Haiyue Sheng,Zhuosheng Zhang,Gongshen Liu", "background": "多模态代理正在促进图形用户界面（GUI）中的有效交互，尤其是通用GUI控制。然而，它们在可靠执行翻转控制指令方面的能力有限，这是个关键瓶颈。", "innovation": "提出了状态感知推理（StaR），一种培训方法，让代理能够感知当前翻转状态，从指令中分析所需状态并相应地行动。实验表明，StaR可以提高翻转指令执行的准确性超过30%，并且在通用基准测试中也提升了任务性能。", "conclusion": "在动态环境中进一步的评估显示出StaR在实际应用中的潜力。提供了代码、基准和StaR增强的代理。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13570", "html_url": "https://arxiv.org/abs/2509.13570", "title": "基于证明的数学课程中的生成AI：一项试点研究", "title_en": "Gen AI in Proof-based Math Courses: A Pilot Study", "authors": "Hannah Klawa,Shraddha Rajpal,Cigole Thomas", "background": "随着生成型AI在高等教育中的快速发展以及当前AI检测工具的可靠性不足，制定鼓励学生学习和批判性思维的政策显得尤为重要。本研究调查了学生在其所使用的生成型AI工具及其对该工具的看法，具体是在三门基于证明的本科数学课程中：第一学期的抽象代数、拓扑课程以及第二学期的抽象代数课程中的使用情况。这些课程的政策允许在一定程度上使用生成型AI。通过问卷调查和学生访谈，研究分析了学生如何使用AI工具、他们认为这些工具是怎样的以及这些看法如何影响基于证明的数学教学方法的改进。", "innovation": "本研究通过调查三门基于证明的本科数学课程中学生对生成型AI的使用和看法，探讨了这一技术的应用对学生学习和教学方法的影响。这一研究填补了在数学教育领域关于生成型AI应用的相关研究空白，为如何在证明型数学教育中合理使用生成型AI提供了理论支持和实践参考，也对未来相关研究和教育资源开发具有指导意义。", "conclusion": "研究最后提出了关于在基于证明的数学教学中整合生成型AI的一些未来考虑，包括如何更好地评估学生的学习进度、如何教授学生正确使用AI工具的方法以及如何根据学生对AI的看法调整教学策略。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13389", "html_url": "https://arxiv.org/abs/2509.13389", "title": "从下一个单词预测到（STRIPS）世界模型——初步结果", "title_en": "From Next Token Prediction to (STRIPS) World Models -- Preliminary Results", "authors": "Carlos Núñez-Molina,Vicenç Gómez,Hector Geffner", "background": "本文研究了仅从动作轨迹中学习命题STRIPS世界模型的问题，通过深度学习架构（transformers）和梯度下降。将任务定义为一个监督下一次动作预测问题，其中动作是令牌。一个动作$a$可以在动作序列之后发生，前提是前一个动作的隐藏效果不会使动作$a$的前提变为假命题。研究表明，合适的transformers架构能够忠实表示命题STRIPS世界模型，并且这些模型可以从一组随机有效的（正）和无效的（负）动作序列中学习到。实验结果被报告出来，验证了该模型的有效性", "innovation": "采用transformers架构和梯度下降方法来学习命题STRIPS世界模型。将动作轨迹预测任务转化为监督下一次动作预测问题，并能从纯动作序列中学习到有效和无效的动作序列，这种方法在现有文献中是创新性的", "conclusion": "研究证明，适当的transformers架构能够准确表示命题STRIPS世界模型，并且可以从简单的正负动作序列中学习到该模型。未来的工作将更多地关注实际应用和大规模数据集测试"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13880", "html_url": "https://arxiv.org/abs/2509.13880", "title": "基于简化技术的整数线性约束下的穷举DPLL模型计数方法", "title_en": "An Exhaustive DPLL Approach to Model Counting over Integer Linear Constraints with Simplification Techniques", "authors": "Mingwei Zhang,Zhenhao Gu,Liangda Fang,Cunjing Ge,Ziliang Chen,Zhao-Rong Lai,Quanlong Guan", "background": "整数线性约束是计算机科学、运筹学和优化等领域最基本的约束条件之一。许多应用最终归结为整数线性约束下的模型计数任务（MCILC）。现有的模型计数方法中尚未有专门针对整数线性约束的问题的精确方法，因此设计和改进此类方法具有重要意义。", "innovation": "本文设计了一种基于穷举DPLL架构的精确方法用于整数线性约束下的模型计数问题。为了提高效率，该方法将来自混合整数规划的几种有效的简化技术整合到了架构中。通过对2840个随机和4131个应用基准的测试，该方法在随机基准上显著优于最先进的MCILC计数器和命题模型计数器，解决了1718个实例，而最先进的方法只能计算1470个实例。此外，它是唯一可以解决所有4131个应用实例的方法。", "conclusion": "所提出的方法可以显著提高解决整数线性约束下的模型计数问题的效率，并且在应用实例上表现最佳。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13364", "html_url": "https://arxiv.org/abs/2509.13364", "title": "Asterisk Operator", "title_en": "Asterisk Operator", "authors": "Zixi Li", "background": "本文提出了一种称为Asterisk Operator ($\times$-operator)的新型统一框架，该框架基于邻接结构并行传播（ASPP）。该算子将结构化的推理任务形式化为由隐式关系图引导的局部并行状态演化过程。", "innovation": "本文提出了一种名为Asterisk Operator ($\times$-operator)的新颖统一框架，用于基于邻接结构并行传播的抽象推理。通过严格的数学分析和在ARC2挑战和康威生命游戏上的全面实验，该工具被证明具有普遍性、收敛性和卓越的性能。", "conclusion": "我们创新的Embedding-Asterisk蒸馏方法在ARC2验证集上达到了100%的准确性，仅使用6M参数，这是一个在神经符号推理中的重要突破。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13761", "html_url": "https://arxiv.org/abs/2509.13761", "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "title_en": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "authors": "Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Jun Du,Quan Liu,Jianqing Gao", "background": "大语言模型（LLMs）在数学推理方面取得了显著进展，但仍难以应对高精度任务，如数值计算和形式符号操作。现有方法通过引入外部工具来克服这一缺陷的尝试在构建工具集成的推理数据、精细调整优化以及增强推断方面遇到了三个关键挑战。", "innovation": "THOR 提出了一种新的方法，通过引入 TIRGen 管道生成高质量的工具集成的推理路径数据集，采用强化学习策略同时优化轨迹级问题解决和步骤级代码生成，引入了一个自校正机制，在推理过程中动态修正错误的推理路径。THOR 能够跨多种模型发挥强大的泛化能力，并且在多个数学基准中达到相似规模模型的最优性能，同时在代码基准测试中提供了稳定的改进。", "conclusion": "THOR 方法展示了强大的泛化能力，有效地在推理和非推理模型中运作。它在多个数学基准测试中达到最新技术水平，并且在代码基准测试中也提供了持续改进。THOR 的代码将在公开的网址提供下载。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13450", "html_url": "https://arxiv.org/abs/2509.13450", "title": "SteeringControl：评估大型语言模型对齐 steering 的全面评价", "title_en": "SteeringControl: Holistic Evaluation of Alignment Steering in LLMs", "authors": "Vincent Siu,Nicholas Crispino,David Park,Nathan W. Henry,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang", "background": "尽管以前的对齐工作往往强调真实性或推理能力来展示对齐方法的副作用，但研究发现还有许多未探索且尚未系统理解的权衡。为了更好地理解和评估这些权衡，该研究构建了一个包含关键行为和次要行为的数据集来测试定向打分方法的有效性和行为纠缠程度。研究人员还设计了一个模块化的定向打分框架，以实现对各种方法的全面评估。", "innovation": "研究人员引入了SteeringControl，一个用于评估多种对齐方法的效果和其对模型主要行为（如偏见、有害生成和幻觉）以及次要行为（如奉承和常识道德）影响的基准。该研究通过一个基于独特组件的模块化框架，对五种流行的定向打分方法进行了系统的评估，揭示了方法、模型和目标行为的具体组合对于定向打分效果的影响。", "conclusion": "研究表明，强大的定向打分性能依赖于特定方法、模型和目标行为的组合，且不当的组合可能导致严重的概念纠缠。该研究还发布了用于评估模型对齐效果的代码以供进一步研究使用。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13968", "html_url": "https://arxiv.org/abs/2509.13968", "title": "使用人工神经网络探索生物认知进化中的重大转变", "title_en": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "authors": "Konstantinos Voudouris,Andrew Barron,Marta Halina,Colin Klein,Matishalin Patel", "background": "过渡类型的演化观点强调了几种变化，这些变化塑造了什么可以演化，并对衍生谱系产生了巨大影响。最近提出，认知也可能通过一系列重要的转变来进化，这些转变操控生物神经网络的结构，从而根本改变信息流动的方式。为了评估网络中信息流动的变化是否能导致认知表现上的过渡性变化，研究者采用了理想化的信息流动模型和人工神经网络（ANNs），比较了不同的网络拓扑结构（前馈、循环和分层）在学习不同复杂度的人工语法时的表现。", "innovation": "研究使用人工神经网络评估了信息流动方式变化是否会导致认知表现上的过渡性变化。研究发现，相比于前馈网络，循环网络在处理不同类型输入时表现出了质的飞跃，并且在学习复杂语法时表现出更大的性能提升。还观察到训练循环网络所面临的难度形成了一种过渡障碍和可逆性丧失，这与演化转变中的关键特征相吻合。并非所有网络拓扑结构变化都能在此任务集中为表现带来优势，分层网络在语法学习中并未表现出优于非分层网络的表现。", "conclusion": "我们的发现展示了信息流动方式的一些变化如何导致认知表现上的过渡性变化。某些改变网络拓扑结构的转变可以引发在认知表现上的过渡，但并非所有变化都会提升表现。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14030", "html_url": "https://arxiv.org/abs/2509.14030", "title": "CrowdAgent: 多代理管理的多源标注系统", "title_en": "CrowdAgent: Multi-Agent Managed Multi-Source Annotation System", "authors": "Maosheng Qin,Renyu Zhu,Mingxuan Xia,Chenkai Chen,Zhen Zhu,Minmin Lin,Junbo Zhao,Lu Xu,Changjie Fan,Runze Wu,Haobo Wang", "background": "高质量标注数据是现代自然语言处理(NLP)的基础。尽管最近的方法开始利用广泛的标注来源，包括大型语言模型(LLMs)、小型语言模型(SLMs)和人类专家，但大多数方法将重点放在标注步骤本身。一个关键的差距在于管理和这些源动态互动的过程中整体流程控制的缺乏，这涉及到复杂的调度和质量-成本权衡，并以统一的方式进行管理。", "innovation": "我们受到现实世界的人群外包公司的启发，引入了CrowdAgent，这是一个多代理系统，通过集成任务分配、数据标注和质量/成本管理，提供端到端的过程控制。它实现了一种新的方法，合理地分配任务，使LLMs、SLMs和人类专家能够在协作标注工作流中协同进步。", "conclusion": "我们通过在六种不同的多模态分类任务上的广泛实验展示了CrowdAgent的有效性。源代码和视频演示可在该链接中获得。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13773", "html_url": "https://arxiv.org/abs/2509.13773", "title": "MIRA: 基于MLLM的指令推荐赋能智能手机上的一键AI服务", "title_en": "MIRA: Empowering One-Touch AI Services on Smartphones with MLLM-based Instruction Recommendation", "authors": "Zhipeng Bian,Jieming Zhu,Xuyang Xie,Quanyu Dai,Zhou Zhao,Zhenhua Dong", "background": "生成式AI技术的快速发展正推动各种AI服务整合到智能手机中，改变用户与设备的互动方式。为了简化访问预定义AI服务的过程，本文提出了MIRA框架，该框架能够在智能手机上实现直观的一键式AI任务操作。用户可以通过长按图像或文本对象来接收上下文相关的目标推荐，以执行AI任务.", "innovation": "1. 基于多模态大规模语言模型(MLLM)的推荐管道，采用结构化推理提取关键实体、推断用户意图并生成精确说明；\n2. 增强推理模板机制，结合高阶推理模板，提高任务推断准确性；\n3. 前缀树基于约束解码策略，限制输出到预定义指令候选中，确保连贯和意图一致的建议.", "conclusion": "通过使用真实数据集和用户研究，MIRA在指令推荐准确性上取得了显著提升。这些鼓舞人心的结果表明了MIRA在智能手机上通过一键操作增强用户与AI服务互动方式的潜力，提供了更顺畅和高效的服务体验."}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13547", "html_url": "https://arxiv.org/abs/2509.13547", "title": "具有人类合作工具的AI代理：增强问题解决的适应性策略", "title_en": "AI Agents with Human-Like Collaborative Tools: Adaptive Strategies for Enhanced Problem-Solving", "authors": "Harper Reed,Michael Sugimura,Angelo Zangari", "background": "研究探讨了给大型语言模型（LLM）代理提供与人类自然用于问题解决的协作工具和自主权是否能提高它们的表现。通过将Claude Code代理装备上基于MCP的社交媒体和记事本工具，并允许它们根据需要自由使用这些工具，研究者们在34个Polyglot Python编程挑战中测试了这些工具的有效性。实验结果表明，协作工具在处理最难的问题时显著提高了性能，降低了15-40%的成本，减少了12-27%的回合数，并加快了12-38%的完成时间。研究表明，不同的模型在没有明确指令的情况下自然地采用了不同的协作策略，这类似于人类开发人员根据自己的专业知识和任务复杂性调整协作的方式。这些结果表明，当额外的推理架构最需要时，这些工具作为性能增强器的作用表现突出。进一步的分析显示，代理更倾向于写作而非阅读，这表明结构化的话语可能是大幅提升性能的一部分原因，而非信息访问本身", "innovation": "立了一个实验来测试提供给LLM代理的人类协作工具（如社交媒体和记事本工具）如何能增强它们在编程挑战中的表现。研究发现，这些协作工具在处理最难的问题时能显著提升性能，具体表现在降低了成本、减少了回合数和加快了完成时间。实验还揭示了不同的模型采用了不同的协作策略，这与人类开发人员根据自己的知识和任务难度调整合作方式的情形相似。研究进一步表明，代理更倾向于写作而非阅读，这暗示了结构化的表达在提升性能中起到了关键作用，而不仅仅是信息访问的能力", "conclusion": "总体来说，AI代理可以从处于其能力边界的人类启发的协作工具中系统地受益，这表明适应性的协作界面作为推理增强器的作用，而不是普遍提高效率。这种发现指向了在AI代理的认知过程中整合人类启发的协作工具的可能性，这些工具可以针对不同类型的任务进行微妙调整，以优化性能和效率"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13704", "html_url": "https://arxiv.org/abs/2509.13704", "title": "InfraMind: 一种新的探索驱动的工业管理GUI代理框架", "title_en": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management", "authors": "Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen", "background": "随着数据中心等关键工业基础设施对复杂管理软件的依赖日益增加，其操作面临的挑战也随之增加。这些挑战包括系统复杂性持续上升、多供应商集成困难、以及缺乏专业知识的操作人员。虽然机器人流程自动化（RPA）可以通过手工编写的脚本来部分实现自动化，但它缺乏灵活性，维护成本高。大型语言模型（LLM）驱动的图形用户界面（GUI）代理能够提供更灵活的自动化，但这些通用代理在应用于工业管理系统时遇到了五个关键挑战，包括不熟悉界面元素的理解、精确度和效率问题、状态定位、部署限制以及安全性要求。", "innovation": "针对上述问题，我们提出了InfraMind，一种专为工业管理系统设计的新型探索驱动的GUI代理框架。InfraMind整合了五个创新模块，系统性地解决了工业管理中的各种挑战：1）基于系统的搜索探索和虚拟机快照，以自动理解复杂的GUI；2）基于记忆的规划，以确保高精度和高效的任务执行；3）高级状态识别，以在分层界面中实现可靠的本地化；4）结构化的知识蒸馏，以实现高效部署和轻量级模型；5）全面的多层安全机制，以保护敏感操作。", "conclusion": "在开源和商用DCIM平台上的广泛实验表明，我们的方法在任务成功率和操作效率方面的表现均优于现有框架，为工业管理自动化提供了严格的且可扩展的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.00208", "html_url": "https://arxiv.org/abs/2408.00208", "title": "使用人工智能预测COVID-19：一项系统评价和元分析", "title_en": "Prognosis of COVID-19 using Artificial Intelligence: A Systematic Review and Meta-analysis", "authors": "SaeedReza Motamedian,Sadra Mohaghegh,Elham Babadi Oregani,Mahrsa Amjadi,Parnian Shobeiri,Negin Cheraghi,Niusha Solouki,Nikoo Ahmadi,Hossein Mohammad-Rahimi,Yassine Bouchareb,Arman Rahmim", "background": "近年来，人工智能（AI）技术已广泛应用于多种疾病的确诊和预后。该研究旨在识别、评估和综合分析使用AI技术预测 COVID-19 预后的已发表研究。研究者通过对 Medline、Google Scholar、Scopus、Embase、Cochrane 和 ProQuest 等数据库的电子文献检索，筛选出使用机器学习或深度学习方法，基于CT或胸部X光图像预测 COVID-19 预后的研究论文。", "innovation": "研究采用了多种不同的 AI 模型，包括 Siamese 模型、支持向量机、随机森林、XGBoost 和卷积神经网络等，并计算了各种敏感性、特异性、曲线下面积和诊断奇数比，探索了使用放射学特征预测 COVID-19 预后的多种模型的性能。这项研究强调了将患者的人口统计学、临床数据、实验室测试和放射学特征结合使用的重要性，以提高模型性能。", "conclusion": "基于纳入的研究文献，使用机器学习和深度学习方法结合CT或X光图像的放射学特征，可用于帮助临床医生更有效地管理和分配资源。这些研究表明，将患者的人口统计学、临床数据、实验室测试和放射学特征结合使用可改善模型性能。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14195", "html_url": "https://arxiv.org/abs/2509.14195", "title": "迷宫导航的层次学习：通过第二级学习产生心智表征", "title_en": "Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning", "authors": "Shalima Binta Manir,Tim Oates", "background": "心智表征是高级认知的基础，但其实证研究仍然具有挑战性。现有理论认为，第二级学习机制（即适应第一级学习的机制）能够促进环境-认知的同构性，但这一假设尚未得到实证验证。本文通过提出一种包含图卷积网络（GCN）作为第一级学习者和多层感知器（MLP）控制器作为第二级学习者的层次架构，进行实证验证。GCN直接将节点级特征映射为最佳导航路径预测，而MLP则根据结构性新颖的迷宫环境动态调整GCN的参数。", "innovation": "本文通过设计一种交织第一级和第二级学习的层次架构，首次直接探讨了第二级学习对认知系统中环境-认知同构性的促进作用。相比以往的研究，该工作提供了较为直接和量化的实验证据，证明第二级学习在心智表征和增强迷宫任务表现中具有关键作用。", "conclusion": "实验结果表明，第二级学习特别有效，特别是在认知系统构建出与环境结构上同构的内部心智能谱时。定量和定性结果强调了在未见过的迷宫任务中实现显著性能提高和稳健泛化的可行性，并为高度结构化的心智表征在最大化第二级学习效能中的核心作用提供了支持。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2010.01052", "html_url": "https://arxiv.org/abs/2010.01052", "title": "联合数据补充和机理建模以在不完整数据集中模拟心脏-大脑交互作用", "title_en": "Joint data imputation and mechanistic modelling for simulating heart-brain interactions in incomplete datasets", "authors": "Jaume Banus,Maxime Sermesant,Oscar Camara,Marco Lorenzi", "background": "在临床研究中，机理模型的使用受限于缺乏多模态患者数据，这些数据能够代表不同的解剖和生理过程。例如，神经影像数据集无法提供建模脑部疾病中心血管因素所需的足够心臟特征信息。为解决这一问题，本文提出了一种联合心臟数据填充和个人化的机理模型构建的概率框架，适用于具有不完整心臟数据的大脑研究。该方法基于变分框架，结合心脏信息补充模型和高斯过程模拟器，以忠实再现个性化心血管动力学。英国生物银行结果表明，通过仅使用少量心臟相关信息，例如收缩压和舒张压，该模型能够准确补充缺失的心臟特征，同时联合估计累加模型的参数。这使得可以通过模拟不同脑部解剖条件下的现实心臟动态来探索心脏-大脑联合关系。", "innovation": "本文提出了一种联合心臟数据填充和个人化的机理模型构建框架，用于优化有不完整心臟数据集的大脑研究。该方法结合变分框架进行心脏信息补充模型联合推断和高斯过程模拟器，以忠实再现个性化心血管动态。这种方法可以准确补充缺失的心臟特征，同时估计参数，实现心脏-大脑联合关系的新型探索。", "conclusion": "该模型能够通过补充少量心臟数据（如收缩压和舒张压）来准确估计并仿真心臟特征，从而改进在有心脏信息不足的大脑疾病研究中的机理模型应用，实现对未来心脏-大脑联合关系的研究探索。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13328", "html_url": "https://arxiv.org/abs/2509.13328", "title": "基于双执行器DDPG的空中STAR-RIS辅助通信", "title_en": "Dual Actor DDPG for Airborne STAR-RIS Assisted Communications", "authors": "Danish Rizvi,David Boyle", "background": "当前的空中同时传输和反射重配置智能表面（STAR-RIS）研究中，假设传输和反射系数（TRC）是独立的。本文打破了这一假设，探索了利用配备耦合TRC相移模型的无人机搭载STAR-RIS（Aerial-STAR）的多用户下行链路通信系统。研究考虑了无人机的能源限制，并对其轨迹、基站活跃波束成形向量以及RIS的被动TRC进行了联合优化，以提高通信效率。此外，研究还分析了RIS尺寸对无人机气动效应的影响，指出这会增加阻力和能量需求。", "innovation": "本文提出了通过两个独立的执行器网络处理高维混合动作空间的新型双执行器深确定性策略梯度（DA-DDPG）算法，并设计了TRC为离散和连续动作的组合，还提出了一种基于谐波均值指标（HFI）的奖励函数，确保用户间的通信公平性。研究还通过三维轨迹优化实现了28%的通信效率提升，并验证了移动飞行STAR-RIS系统在通信效率和QoS提供方面的优越性，结合耦合相位STAR-RIS表现优于双传输/反射RIS和传统RIS配置。", "conclusion": "研究结果表明，提出的DA-DDPG算法在累积奖励上分别比传统的DDPG和DQN模型提高了24%和97%。HFI基于的奖励函数使得QoS拒绝率相比其他基准降低了41%。飞行中的Aerial-STAR系统相较于固定的部署布局表现出色，带有耦合相位的STAR-RIS优于双传输/反射RIS和传统的RIS配置。这些发现强调了Aerial-STAR系统的潜力以及我们提出的DA-DDPG方法在优化其性能方面的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13342", "html_url": "https://arxiv.org/abs/2509.13342", "title": "使用基于照片真实重建环境训练的深度神经网络实现真实世界中的机器人探索", "title_en": "Real World Robotic Exploration using Deep Neural Networks Trained in Photorealistic Reconstructed Environments", "authors": "Isaac Ronald Ward", "background": "介绍了修改现有深度神经网络方法，用于通过视觉信息（RGB图像）确定机器人姿态的研究。在不牺牲训练便捷性的前提下，改进了定位性能。具体是通过扩展网络的损失函数，直观地结合位置和旋转误差以提高对感知误标（perceptual aliasing）的鲁棒性。利用摄影测量数据创建标记了姿态的图像数据集，使模型能在局部环境中进行训练，从而在室内场景下实现了更高的定位准确性。该研究建立了一整套从室内场景图像到鲁棒导航算法的生成流程，唯一要求是从场景中收集图像，时间仅需330秒左右。", "innovation": "创新之处在于修改了深度神经网络的损失函数，将位置和旋转误差直观地结合，提高了网络对感知误标的鲁棒性。利用摄影测量数据创建了姿态标记的数据集，使得模型可以在特定环境中进行训练，从而提高了定位准确性。构建了从图像到导航算法生成的一整套过程，只需采集很少的图像即可实现。", "conclusion": "该研究提供了一种完整的工作流程，利用现有的室内图像数据和摄影测量数据训练深度神经网络，实现了在真实环境中的高精度移动机器人导航。表明即使是少量的图像数据也可以有效支持室内环境下的机器人探索任务。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13359", "html_url": "https://arxiv.org/abs/2509.13359", "title": "在生成式人工智能时代的大学数学考试评估：课程层面的案例研究", "title_en": "Evaluating undergraduate mathematics examinations in the era of generative AI: a curriculum-level case study", "authors": "Benjamin J. Walker,Beatriz Navarro Lameda,Ruth A. Reynolds", "background": "生成式人工智能（GenAI）工具如OpenAI的ChatGPT正在改变教育格局，促使重新考虑传统的评估实践。与此同时，大学正在探索替代传统的面对面、闭卷考试的方式，这引发了对学术诚信和在无监考条件下教学效果的担忧。这项研究探讨了在假设的无监考、开放式考试环境中，学生可以访问GenAI工具的情况下，传统闭卷数学考试在模块级和整个一年课程中的教育相关性是否仍然存在。", "innovation": "通过生成、转录并盲评分AI提交的八门本科数学考试答案，本次研究实现了对AI性能的整体评估，并发现了其在课程范围内表现出高度一致性，且优于监考考试中学生的成绩。这些发现揭示了需要重新设计无监督环境下的评估，以及当前评估标准在生成式人工智能时代可能面临的教育价值下降。", "conclusion": "研究结果表明，现有的闭卷数学考试在无监考、开放本书、且学生有AI访问权的环境中办学价值降低。为了适应生成式AI时代，考试的设计需要重新评估与调整，以确保有效评估学生的真实能力和理解水平。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13338", "html_url": "https://arxiv.org/abs/2509.13338", "title": "基于临近证据检索的不确定性感知神经网络", "title_en": "Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks", "authors": "Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi", "background": "本文针对现有单一全局阈值在不确定性感知决策中的局限性，提出了一种基于证据检索的机制，以实现更加透明和可审核的决策。当前使用的单一全局阈值对于不同实例可能并不适用，而该机制通过检索每个测试实例附近的示例，并通过Dempster-Shafer理论融合这些示例的预测分布，从而为每个实例提供了一个自适应的阈值机制。这种方法使得支持证据更加明确，增强了决策的透明度和可审核性。相关实验在CIFAR-10/100数据集上验证了该方法的有效性，与基于预测熵的阈值相比，该方法能更好地实现不确定性感知性能，并减少错误分类的情况。此外，实验证明，仅仅少量的证据就足以实现这些改进效果，进一步的证据增加效果有限。这些结果表明，基于证据条件的标记相比固定的预测熵阈值，能为操作中提供更可靠和可解释的不确定性感知决策方案。", "innovation": "文章提出了一种基于证据检索的机制，用以替代现有的单一全局阈值，这一机制能够根据每个测试实例适应性地调整阈值。通过在嵌入空间中检索临近示例，并利用Dempster-Shafer理论融合这些示例的预测分布，形成一种实例特定的信任度机制。这种方法使得决策更加透明和可审核，其关键创新在于支持证据的显式性和决策机制的自适应性。这种机制在实验中展示了相比基于预测熵的阈值方法更高的不确定性感知性能，并且能够减少错误分类的情况，同时保持较轻的审查负担。增加证据集仅能带来适度改善的提升效果。", "conclusion": "实验结果表明，基于证据条件的标记方法为操作中提供了一种更可靠和可解释的不确定性感知决策方案。相较于固定预测熵阈值，该方法在提高不确定性能的同时，减少了错误决策的发生，并且能够满足持续的审查需求。此外，少量的证据即可实现显著效果，证实了其在实际应用中的适用性和有效性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13365", "html_url": "https://arxiv.org/abs/2509.13365", "title": "生成性AI和引文规范的瓦解：出处问题", "title_en": "The Provenance Problem: LLMs and the Breakdown of Citation Norms", "authors": "Brian D. Earp,Haotian Yuan,Julian Koplin,Sebastian Porsdam Mann", "background": "随着生成性AI在科学写作中的应用日益增多，关于归属和智力贡献的归属问题变得紧迫。研究人员使用ChatGPT撰写手稿时，生成的文本可能会反映出作者未曾接触过的想法。如果AI系统在未援引的情况下复制了某种媒介（如1975年的论文），这是否构成剽窃？这种问题揭示了“出处问题”：学术信用链上的系统性崩溃。与传统剽窃不同，此现象不涉及欺骗意图（研究人员可能声明使用AI并诚实对待），但仍可以从未获认可的智力贡献中获益。", "innovation": "本文分析了AI如何挑战现有的作者身份规范，提出了理解“出处问题”的概念工具，并建议如何在学术交流中维护诚信和公平。", "conclusion": "随着生成性AI渗透到各个学科，重要想法可能因未被认可而广泛传播，这对科学声誉经济和知识正义提出了挑战。本文旨在通过探讨“出处问题”，提出保护学术交流诚信和公平的策略。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13349", "html_url": "https://arxiv.org/abs/2509.13349", "title": "基于Point-JEPA的标签高效手指关节预测", "title_en": "Label-Efficient Grasp Joint Prediction with Point-JEPA", "authors": "Jed Guzelkabaagac,Boris Petrović", "background": "研究了使用联合嵌入预测架构（Point-JEPA）的3D自我监督预训练是否能够实现标签高效的抓取关节角度预测。利用从网格中提取的点云并使用基于ShapeNet预训练的Point-JEPA编码器，训练了一个轻量级的多假设头，并通过top-logit选择进行评估。在DLR-Hand II数据集上，与全面监督相比，Point-JEPA在低标签情况下可以将RMSE降低高达26%以达到一致效果，表明JEPA风格的预训练是一种实用的数据高效抓取学习方法。", "innovation": "提出了使用Point-JEPA进行3D自我监督预训练的方法，该方法能够实现标签高效的抓取关节角度预测。与传统方法相比，该方法能在少量标签的情况下达到与全面监督相当的预测准确度，提升了抓取学习中的数据效率。", "conclusion": "Point-JEPA预训练方法在低标签情况下能显著提高抓取关节角度预测的准确性，并能达到与全面监督相同的效果，证明了基于JEPA风格的预训练是一种有效的数据高效抓取学习方法。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13353", "html_url": "https://arxiv.org/abs/2509.13353", "title": "图像分类中的混合量子-经典模型", "title_en": "Hybrid Quantum-Classical Model for Image Classification", "authors": "Muhammad Adnan Shahzad", "background": "本文通过对混合量子-经典神经网络和纯经典模型在三个基准数据集（MNIST、CIFAR100和STL10）的系统比较，评估其性能、效率和鲁棒性。混合模型结合了参数化的量子电路与经典的深度学习架构，而经典的对照组则使用了传统的卷积神经网络（CNN）。实验在每个数据集上进行了50个训练周期，并对验证精度、测试精度、训练时间、计算资源使用和对抗鲁棒性（使用$\boldsymbol{\boldsymbol{\text{ε}}}$=0.1的扰动测试）进行了评估。关键发现表明，混合模型在最终准确性方面始终优于经典模型，并且随着数据集复杂性的增加，这种优势更加显著。", "innovation": "研究提出了一种结合了参数化的量子电路和经典深度学习架构的混合模型，通过在图像识别任务中进行系统比较，展示了混合模型在准确率、训练效率和参数可扩展性方面优于传统经典的神经网络模型，特别是在复杂视觉任务中表现更为突出。此外，研究发现了混合模型在简单数据集上具有更好的鲁棒性，而在复杂数据集上则表现出可比的脆弱性，并且混合模型在资源效率上也表现出优势，包括较低的内存使用量和CPU利用率。", "conclusion": "本文研究结果表明，混合量子-经典架构在准确度、训练效率和参数可扩展性方面提供了显著优势，特别是在处理复杂视觉任务时。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13331", "html_url": "https://arxiv.org/abs/2509.13331", "title": "增强可解释AI的监督控制以实现高精度航天器编队", "title_en": "Explainable AI-Enhanced Supervisory Control for High-Precision Spacecraft Formation", "authors": "Reza Pirayeshshirazinezhad", "background": "本研究旨在利用人工智能（AI）和监督适应控制系统来规划和优化精确航天器编队的任务。虚拟X射线观测望远镜（VTXO）是一项将两颗分离的航天器构建成带有1公里焦距的虚拟望远镜的任务。这种编队要求其中一个航天器携带透镜，另一个航天器携带相机，用于在X射线波段以55毫弧秒角分辨率观察高能天体。为了满足这一高精度任务标准，研究结合了定时自动机进行监督控制，蒙特卡洛模拟进行稳定性和鲁棒性评估，并整合了深度神经网络进行最优估计，以确定任务参数。考虑到非凸动态优化问题的约束性，研究人员综合使用了深度神经网络来预测最优任务参数，以确保满足高精度任务标准。AI框架提供可解释性，预测给定一组任务参数后的能源消耗和任务误差，使策略调整更加透明、可解释和实时。研究结果表明，能源消耗减少，任务准确性提高，展示了系统应对动态不确定性与干扰的能力。", "innovation": "研究创新点在于将深度神经网络与受约束的非凸动态优化管道集成，以预测最优任务参数，确保满足高精度任务标准。利用AI框架的可解释性，研究能够预测给定任务参数集后的能耗和任务误差，提供透明、可解释和实时的任务权衡能力，这是传统适应性控制器所不具备的。", "conclusion": "研究结果表明，通过AI增强的监督控制策略实现了降低能耗、提高任务精度的目标，并展示了系统应对动态不确定性和干扰的能力。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13345", "html_url": "https://arxiv.org/abs/2509.13345", "title": "在生成式AI中大型语言模型的准确性悖论：调节幻觉风险", "title_en": "Accuracy Paradox in Large Language Models: Regulating Hallucination Risks in Generative AI", "authors": "Zihao Li,Weiwei Yi,Jiahong Chen", "background": "随着大型语言模型（LLMs）渗透日常生活决策，其知识和社会风险需要紧急审查。幻觉，即生成虚构、误导、简化或不值得信赖的输出，已成为关键挑战。尽管监管、学术和技术讨论将准确性视为减轻此类危害的主要标准，但本文认为过度依赖准确性会对问题进行错误诊断，并产生反效果：准确性悖论。", "innovation": "文章通过跨学科文献发展幻觉类型的分类，并从输出、个人和社会三个交织维度展示悖论。准确性被视为可靠性的一个表面代理，激励优先优化语体流畅性和表面正确性而非知识可信度。准确性作为单一指标无法检测非事实错误但具有误导性、价值观导向性或社会失真的危害，包括共识错觉、阿谀奉承和微妙操控。此外，监管过度强调准确性遮蔽幻觉对更广泛社会后果的影响，包括社会排序、侵犯隐私、公平损害、知识收敛，边缘化异见，减少多元性，以及社会技能退化。通过分析欧盟人工智能法、GDPR和DSA，文章认为现有法规尚不足以解决这些知识、关系和系统伤害，反而由于过度依赖准确性而加剧这些伤害。", "conclusion": "通过揭示这些概念和实践挑战，本文呼吁向多元、情境意识和操控抗性的人工智能可信治理方法的根本转变。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13390", "html_url": "https://arxiv.org/abs/2509.13390", "title": "一种基于领域知识的电动汽车内饰声音异常检测方法", "title_en": "A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds", "authors": "Deepti Kunte,Bram Cornelis,Claudio Colangeli,Karl Janssens,Brecht Van Baelen,Konstantinos Gryllias", "background": "汽车座舱声音的异常检测对确保车辆质量和保持乘客舒适非常重要。在许多实际应用场景中，由于故障数据标签稀缺或完全缺乏，该任务更适合作为一个无监督学习问题而不是监督学习问题来处理。在这种无监督设置中，模型仅通过健康样本进行训练，并通过检测与正常行为偏离的异常来识别异常。但由于缺乏被标记的故障样本进行验证，以及常用指标（如验证重构误差）的有限可靠性，有效的模型选择仍是一个重大挑战。", "innovation": "提出了一种基于领域知识的方法来选择模型，在验证集中使用通过结构化扰动健康的光谱图生成的代理异常作为支持模型选择。该方法在包含健康和故障不同故障类型（不平衡、调制、啸叫、风噪和脉冲宽度调制）实际样本的高保真电动汽车数据集上进行了评估，该数据集使用高级声音合成技术生成并经专家评审验证。实验结果显示，使用代理异常可以显著超越传统的模型选择策略。", "conclusion": "该研究提出了一个创新的无监督异常检测方法，通过使用领域知识来改进模型选择。实验表明，这种方法能有效选择出最佳模型，在电动汽车座舱声音的异常检测方面有着重要的应用前景。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13355", "html_url": "https://arxiv.org/abs/2509.13355", "title": "合成数据与真理概念的转变", "title_en": "Synthetic Data and the Shifting Ground of Truth", "authors": "Dietmar Offenhuber", "background": "合成数据的出现使得隐私保护、训练数据生成和便捷地访问准现实数据变得复杂。合成数据模仿现实世界观察，但并不参考外部特征，缺少这种表现性的关系，研究人员仍能使用合成数据作为AI模型的训练数据和地面真实数据的参考。研究认为，数据的不现实性并非仅仅是可接受的妥协，反而常常比现实数据更能提高模型性能，例如补偿已知偏差、防止过拟合、支持泛化，并使模型更加稳健地应对意外异常值。注入噪声和完全不可能的数据到训练集中其实对于模型是有益的。这种方法大大复杂了基于表现性准确性确定数据真实性的一贯假设（垃圾进，垃圾出）。此外，地面真实本身成为了自参照的过程，其中用作地面真实数据存贮的标签本身就是生成模型的合成产物，因此与现实世界观察无关。这些情况迫使机器学习研究人员和实践者在缺乏稳定表示和现实世界参考的情况下启动地面真实，本文探讨了如何在这种矛盾的情况下维护地面真实。同时反思了从表现性的到所谓模仿或象征概念的数据转变带来的更广泛影响。", "innovation": "研究指出，虽然合成数据缺少外部特征性的关系，但它在训练AI模型和作为地面真实参考方面的有效性提升了模型性能，尤其是在处理已知偏差、防止过拟合和提升模型 robust 性方面表现突出。此外，它挑战了基于表现性准确性确保数据真实性的传统假设，并提出地面真实应该被视为一种自参照的系统，其标签本身就是生成模型的产物，不再直接关联于真实世界数据。这一转变从表现性概念向象征性或模仿概念的数据观提供了新的视角，并强调了在面对复杂数据环境时重新思考数据真实性的必要性。", "conclusion": "本文通过分析合成数据对数据真实性的挑战，提出了新的数据观念，即从依赖表现性的概念向模仿或象征概念的转变，这对机器学习领域的研究和实践具有重要意义。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13388", "html_url": "https://arxiv.org/abs/2509.13388", "title": "使用遥感和机器学习进行土地覆盖分类和变化检测：斐济西部案例研究", "title_en": "Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji", "authors": "Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra", "background": "作为一个发展中国家，斐济正面临快速的城市化进程，特别是在纳迪市，涉及大量开发项目，如住房、道路和基础设施建设。针对这种情况，本研究利用遥感和机器学习技术，比较了斐济纳迪市从2013年至2024年的土地利用和土地覆盖变化，旨在为土地覆盖/使用建模和变化检测提供技术支持。本研究利用Landsat-8卫星图像和Google地球引擎，结合监督和支持向量机等方法生成土地覆盖地图，并通过卷积神经网络进行分类，展示了不同时期城乡变化的可视化结果，以监测地图变化。", "innovation": "本研究结合了卫星遥感技术、Google Earth Engine和机器学习方法，特别是使用k-均值聚类和卷积神经网络进行土地覆盖和城市化变化识别。这种结合方法为发展中国家提供了一种高效、精准的监测土地覆盖变化的技术手段，尤其适用于资源有限的发展中国家。", "conclusion": "研究结果表明，结合遥感与机器学习的方法能够有效监测和识别土地覆盖和使用变化，有助于更好地了解城市化过程对土地利用的影响。这些发现为城市规划和管理提供宝贵的决策支持信息。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13375", "html_url": "https://arxiv.org/abs/2509.13375", "title": "VLM-based OOD Detection: 机制、优势与敏感性的一种实证分析", "title_en": "An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity", "authors": "Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen", "background": "视觉-语言模型（VLMs），如CLIP，展示了显著的零样本异类检测能力，这对于可靠的AI系统至关重要。尽管如此，该领域的研究人员对其有效性的原因、与单一模态方法的优势以及行为稳健性仍然缺乏全面的理解。这篇论文通过使用训练集（ID）和检验集（OOD）提示进行系统的实证分析，旨在解决这些问题。", "innovation": "1. 机制：系统地界定并形式化了VLM嵌入空间中关键的操作性质，使零样本OD检测成为可能。2. 优势：通过实验定量评估了这些模型相较于现有单一模态方法的优势，并将这种优势归因于VLM利用丰富语义新颖性的能力。3. 敏感性：发现了其稳健性特征中的显著且此前未被充分探索的不对称性：虽然对常见的图像噪声具有韧性，但这些基于VLM的方法对提示措辞高度敏感。", "conclusion": "研究结果为基于VLM的OD检测方法的优点和关键漏洞提供了更加结构化理解的贡献，为进一步设计更稳健和可靠的未来系统提供了重要的、基于实证的指导。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13387", "html_url": "https://arxiv.org/abs/2509.13387", "title": "使用BERTopic和主题分析揭开欧盟政策中的AI治理主题", "title_en": "Uncovering AI Governance Themes in EU Policies using BERTopic and Thematic Analysis", "authors": "Delaram Golpayegani,Marta Lasek-Markey,Arjumand Younus,Aphra Kerr,Dave Lewis", "background": "随着旨在确保人工智能（AI）系统安全和可信赖的政策和指南增多，AI治理体系逐渐变得碎片化。欧盟（EU）在这一政策制定中扮演着关键角色。欧盟高层面专家小组（HLEG）发布了影响力显著的可信赖AI指南，随后在2024年通过了欧盟AI法案。尽管欧盟政策和指南预期是相互一致的，但它们在范围、重点、规范性和AI治理的优先级方面可能存在差异。本文利用定性主题分析方法来揭示欧盟关键文件中的主要主题，包括AI法案和HLEG伦理指南。进一步利用BERTopic等定量主题建模方法，扩大文档样本范围，涵盖2018年之后发布的欧盟AI政策文件，以深入了解欧盟AI治理体系的演变过程。", "innovation": "该研究通过结合定性和定量的方法，特别利用了BERTopic模型，对欧盟的AI治理政策进行了全面分析。这种方法不仅深化了对欧盟AI治理的理解，还提供了一个独特的视角，观察欧盟在应对AI治理方面的方法演变。", "conclusion": "通过对欧盟AI治理政策进行系统性分析，发现在AI政策制定过程中，欧盟在保障AI可信赖性和安全性方面的努力不断加强，并且有清晰的进步路径可以观察到。研究还展示了新兴技术和政策工具如何影响AI治理框架的演变。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13391", "html_url": "https://arxiv.org/abs/2509.13391", "title": "被拦截的自我：生成式AI对关系自我的动态挑战", "title_en": "The Intercepted Self: How Generative AI Challenges the Dynamics of the Relational Self", "authors": "Sandrine R. Schiller,Camilo Miguel Signorelli,Filippos Stamatiou", "background": "生成式AI正在改变人们与技术、他人及自身的互动方式。微软小冰、Gemini 和预期中的苹果人工智能等系统有待用户指令后才能行动。然而，AI助手系统预计将更精准地预测并代理执行用户行为。设想未来新一代的生成式与预测式AI能够为你挑选餐馆的最佳选择、帮你打扮以增加约会成功的几率，甚至选择你的约会对象。这些情景不仅不是科幻小说中的场景，还有多个研究项目在这方面展开，旨在构建能够辅助人们实现这些目标的系统。这些研究促使我们重新思考人类与技术之间的关系，并引发我们对这类系统如何改变我们与自身的互动方式的思考。基于我们对关系自我的看法，我们探讨了生成式AI在不同领域的潜在影响，包括外部输出、情境因素和自我关系等方面.", "innovation": "本文基于对关系自我的认识，探讨生成式AI在不同领域的潜在影响，提出了对生成式AI的深度存在考量，详细阐述了生成式AI在各个领域如何完成任务并预判、甚至拦截用户的行为.", "conclusion": "生成式AI通过完成任务和预判用户行为，在不同的自我的领域中发挥着重要作用。这些动态变化挑战了我们对关系自我的理解，要求我们重新思考人类和技术的关系，以及这些系统如何可能影响我们与自身的互动方式。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13372", "html_url": "https://arxiv.org/abs/2509.13372", "title": "基于对比增强X射线血管造影的生成型AI管道用于Fontan几何的交互式提示驱动的2D到3D血管重建", "title_en": "Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy Imaging", "authors": "Prahlad G Menon", "background": "当前，应用于单一心室先天性心脏病Fontan矫正手术的血流动力学失败表现出了复杂流模式，仅仅依靠传统的2D成像技术（如透视造影动态成像）难以全面准确地评估。现有的评估手段依赖于透视动态造影成像，虽然能提供一些三维几何信息，但有限，而且对于计算流体力学(CFD)分析和手术规划提供不足的支持。", "innovation": "该研究开发了一套系统性的AI管道，利用Google的Gemini 2.5 Flash模型（2.5B参数）处理透视造影动态成像，通过变压器神经架构多次迭代地对血管进行分割、对比增强、伪影去除，并生成虚拟的血流动力学流可视化。这套管道实现了从单视角影像生成几何优化的2D投影，并在最后一步使用腾讯的Hunyuan3D-2mini模型（384M参数）生成可用于3D重建的立体光刻文件。初始迭代中，该模型会产生一些虚构的血管特征，需要进一步调整以达到解剖上的真实性。最终生成的2D投影准确地保存了复杂的Fontan结构，并且改善了对比度，使其适用于3D转换。该方法识别出中央连接和分支动脉中的停滞区和流模式。整个处理过程在15分钟内完成。", "conclusion": "该研究展示了从常规的血管造影数据生成适合CFD分析的几何体的临床可行性，并且能快速生成虚拟流可视化用于手术前的初步分析，尽管需要进行精炼循环以提高准确性，但为普通可用的成像数据上进行高级几何和血流动力学分析铺平了道路。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13397", "html_url": "https://arxiv.org/abs/2509.13397", "title": "使用大型语言模型模拟人类数据中的分析灵活性威胁：引起关注的呼呼", "title_en": "The threat of analytic flexibility in using large language models to simulate human data: A call to attention", "authors": "Jamie Cummins", "background": "社会科学家现在使用大型语言模型来生成‘硅样本’——旨在作为人类受试者代表的合成数据集，旨在革新人类主体研究。然而，这些样本的质量依赖于许多需要做出的分析选择，而这些选择如何影响样本质量的深刻影响尚未充分理解。", "innovation": "作者探讨了生成硅样本时需做出的多方面分析选择，展示了即使是很小的决策差异也会大大改变硅样本与人类数据之间的对应关系，并表明并不存一种‘一刀切’的配置可以优化这些样本的准确性。", "conclusion": "作者强调了在使用硅样本时分析灵活性所构成的威胁，呼吁更多关注这一问题。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13400", "html_url": "https://arxiv.org/abs/2509.13400", "title": "正义的裁决：揭示LLM辅助审稿中的（隐藏）偏见", "title_en": "Justice in Judgment: Unveiling (Hidden) Bias in LLM-assisted Peer Reviews", "authors": "Sai Suresh Marchala Vasu,Ivaxi Sheth,Hui-Po Wang,Ruta Binkyte,Mario Fritz", "background": "随着大型语言模型（LLMs）的采用，同行评审过程正在发生变化，从协助评审人员撰写更详细的评估到自动生成整个评审。尽管这些能力提供了令人兴奋的机会，但也引起了关于公平性和可靠性的关键担忧。该研究通过在敏感元数据（包括作者机构和性别）上进行受控实验，调查了LLM生成的同行评审中的偏见问题。研究表明，机构偏见倾向于常见学术排名中的领先机构，发现了一些性别偏好的证据，尽管程度微妙，但有可能随着时间累积。研究揭示了基于标记的软评分中的隐性偏见，这些偏见在逐渐显现时变得更加明显。", "innovation": "该研究通过在敏感元数据上进行受控实验，揭示了LLM生成的同行评审中的偏见，特别是机构和社会性别偏见。这项研究使用了新的方法来检测潜在的偏见，并首次公开了基于标记的软评分中的隐性偏见。", "conclusion": "研究结果表明，为了保证同行评审过程的公平性和可靠性，需要关注和纠正决策过程中的偏见。此外，应加强对研究者在使用LLMs进行同行评审时潜在偏见的认识。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13399", "html_url": "https://arxiv.org/abs/2509.13399", "title": "EdiVal-Agent: 一种面向对象的自动化、可扩展且细粒度的多轮编辑评估框架", "title_en": "EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing", "authors": "Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou", "background": "基于指令的图像编辑技术发展迅速，但可靠且可解释的评估仍然是瓶颈。当前评估协议要么依赖成对参考图像（这会产生有限的覆盖范围并继承先前生成模型的偏差），要么仅依赖零样本视觉-语言模型（VLM），这类模型对指令遵循性、内容一致性和视觉质量的基于提示的评估往往不够精准。因此，需要一种新的评估框架来解决这些问题，以提供更加可靠的、细粒度的评估，提升评估的准确性和可解释性。", "innovation": "引入了EdiVal-Agent，一种面向对象的自动化、可扩展且细粒度的多轮编辑评估框架，通过专家工具支持，首先将图像分解为语义有意义的对象，然后生成多样化、上下文相关的编辑指令。评估时，将VLM与开放式词汇对象检测器结合以评估指令遵循性，使用语义级特征提取器评估内容一致性，并利用人类偏好模型来评判视觉质量。该框架使用模块化设计，便于未来工具的无缝集成，从而随着时间提升评估准确性。此外，该框架在指令遵循性评估中与人类判断的共识度比单独使用VLM和CLIP基准度量要高。", "conclusion": "通过 EdiVal-Agent 的示例实现，建立了一个包含 9 种指令类型和 11 种最先进的编辑模型（涵盖自回归模型、流匹配和扩散架构）的多轮编辑基准 EdiVal-Bench。这表明 EdiVal-Agent 可以识别现有的失败模式，从而告知下一代编辑模型的研发。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13574", "html_url": "https://arxiv.org/abs/2509.13574", "title": "Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation", "title_en": "Dense-Jump Flow Matching with Non-Uniform Time Scheduling for Robotic Policies: Mitigating Multi-Step Inference Degradation", "authors": "Zidong Chen,Zihao Guo,Peng Wang,ThankGod Itua Egbe,Yan Lyu,Chenghao Qian", "background": "流匹配作为一种学习高性能生成策略的竞争框架在机器人学中崭露头角，但在沿流轨迹推断过程中，泛化能力过早达到饱和，并且增加欧拉积分步骤反而会降低策略性能。因此，该研究提出了使用非均匀时间调度和密集跳跃集成调度来优化策略训练和提高性能的方法，以解决这些问题。", "innovation": "提出了利用非均匀时间调度（如U形）和密集跳跃集成调度策略，非均匀时间调度强调早期和晚期阶段以规范化策略训练，密集跳跃集成调度在推理时使用单步集成代替多步集成以避免不稳定区域，从而提高策略性能。该方法在不同的机器人任务中实现了高达23.7%的性能提升，优于最先进的基线方法。", "conclusion": "通过非均匀时间调度和密集跳跃集成策略，研究解决了早饱和和推理中策略性能下降的问题，得到了显著的性能改进。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13499", "html_url": "https://arxiv.org/abs/2509.13499", "title": "可重复的工作流在数字健康领域的在线AI", "title_en": "Reproducible workflow for online AI in digital health", "authors": "Susobhan Ghosh,Bhanu T. Gulapalli,Daiqi Gao,Asim Gazi,Anna Trella,Ziping Xu,Kelly Zhang,Susan A. Murphy", "background": "在线人工智能算法是数字健康干预的重要组成部分。这些算法设计用于根据不断收集的个体数据持续学习并改进自身性能。在线AI的部署带来了关键挑战：需要在适应性和可重复性之间取得平衡。数字健康干预的发展和部署是一个持续的过程，在此过程中包括了算法决策的实施，其间伴随着开发和优化的循环。每次部署都会为下次部署提供信息，使得迭代部署成为该领域的核心特征。这一迭代性质凸显了可重复性的关键作用：需要准确存储跨部署的数据以具备科学用途，需要审计算法行为，也需要能在时间上进行比较以促进科学研究和基于客观证据的改进。", "innovation": "本文提出了一种可重复的科学工作流，用于设计、实施和分析数字健康干预中的在线AI决策算法。该工作流基于多个实际部署的经验，应对在线AI算法开发生命周期各个阶段中的关键可重复性挑战。", "conclusion": "该工作流强调了数据准确存储的重要性，算法行为的可审计性以及跨时间结果的可比性，以实现科学研究和基于客观证据的改进。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13525", "html_url": "https://arxiv.org/abs/2509.13525", "title": "ColonCrafter: 用于结肠镜视频的基于扩散先验的深度估计模型", "title_en": "ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors", "authors": "Romain Hardy,Tyler Berzin,Pranav Rajpurkar", "background": "结肠镜检查中的三维场景理解面临重大挑战，需要自动化方法以实现精确的深度估计。现有的内镜深度估计模型在视频序列之间未能保持时间连贯性，限制了它们在三维重建中的应用。ConolCrafter模型利用扩散机制从单视角结肠镜视频中生成时间连贯的深度图，通过从合成的结肠镜序列中学习稳健的几何先验，解决了这些时间一致性问题。此外，该模型还引入了一种风格迁移技术，能够在保持几何结构的同时将实际的临床视频适应到合成的训练领域", "innovation": "ColonCrafter模型通过利用扩散机制为单视角结肠镜视频生成时间连贯的深度图，并通过学习合成的结肠镜序列中的稳健几何先验来实现这一点。此外，该模型还引入了风格迁移技术来匹配实际临床视频和合成训练领域的几何结构", "conclusion": "ColonCrafter模型在C3VD数据集上实现了最先进的零样本性能，超过了通用和内镜专用的方法。尽管三维完整轨迹重建仍然是一个挑战，但该模型在临床上相关应用中仍表现出色，如三维点云生成和表面覆盖评估"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13395", "html_url": "https://arxiv.org/abs/2509.13395", "title": "TICL: 基于文本嵌入KNN的语音在上下文学习使大型多模态模型具备语音识别能力", "title_en": "TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models", "authors": "Haolong Zheng,Yekaterina Yegorova,Mark Hasegawa-Johnson", "background": "近年来，语音基础模型已展示了执行语音在上下文学习（SICL）的能力。选择有效的上下文示例对于提高SICL性能至关重要，但目前选择示例的方法仍未得到充分探索。在此工作中，我们提出了基于文本嵌入KNN的SICL（TICL）方法，这是一个简单的流程，通过利用语义上下文，在不进行微调的情况下提升现成的大规模多模态模型的语音识别能力。在包括口音英语、多语种语音和儿童语音在内的具有挑战性的自动语音识别任务中，我们的方法使得模型能够超过零样本性能，相对WER降低最多达84.7%。我们还进行了消融研究以展示该方法的稳定性和效率。", "innovation": "我们提出了一种基于文本嵌入KNN的简单流程，该流程能够利用语义上下文，提高大规模多模态模型的语音识别能力，而无需进行模型微调。这种方法适用于包括口音英语、多语种语音和儿童语音在内的多种具有挑战性的自动语音识别任务，大幅度提升了零样本性能。通过消融研究，展示了该方法的稳健性和效率。", "conclusion": "我们的TICL方法在多种语音识别任务中取得了显著的性能提升。通过使用语义上下文，模型的识别能力得到了增强，无需微调。此外，消融研究证明了该方法的有效性和稳健性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13414", "html_url": "https://arxiv.org/abs/2509.13414", "title": "MapAnything: 全面统一的基于几何的3D重建", "title_en": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "authors": "Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder", "background": "当前的3D视觉任务通常需要多种专门针对特定任务的前馈模型，如非标定的结构从运动，校准的多视图立体视觉，单目深度估计等。这些任务需要多种监督数据集和复杂的输入增强，这导致了训练和部署上的复杂性。因此，研究人员提出了MapAnything模型，该模型旨在通过统一的变压器基前馈模型解决这一系列问题，输入可以是一张或多张图像以及可选的几何信息如相机内参，姿态，深度或部分重建，然后直接回归出3D场景几何和相机参数。MapAnything利用多视角场景几何的分解表示，将局部重建升级为全局一致的度量帧。", "innovation": "MapAnything模型通过统一的变压器前馈模型，标准化了多样数据集的监督和训练，提升了灵活性的输入增强，能够在一个前馈传递中解决多种3D视觉任务，包括非标定的结构从运动，校准的多视图立体视觉，单目深度估计，相机定位，深度补全等。而相比专门针对单一任务的前馈模型，MapAnything在性能上更优，具有更高效的联合训练行为。这使得MapAnything成为了作为通用3D重建主干网络的可能解决方案。", "conclusion": "实验分析和模型截肢证明了MapAnything在各种3D重建任务上的优越性，无论是专门针对某一任务的前馈模型或是比照基准模型，MapAnything都表现出了更高的性能或者达到了相似的效果，展示了其为通用3D重建框架的可能性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13487", "html_url": "https://arxiv.org/abs/2509.13487", "title": "Prompt2DAG：基于LLM的数据增强管道生成模块化方法", "title_en": "Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline Generation", "authors": "Abubakari Alidu,Michele Ciavotta,Flavio DePaoli", "background": "开发可靠的管道增强流水线需要大量的工程专业知识。本文通过调查比较不同生成方法（直接、仅LLM、混合和基于模板的方法），评估了它们在大数据集中的表现，以确定生成生产级自动化流水线的最佳策略。", "innovation": "提出了Prompt2DAG方法，该方法能够将自然语言描述转换为可执行的Apache Airflow DAG。该方法通过结合可靠性、代码质量和可执行性，使用惩罚评分框架来衡量性能，并确定了最佳的生成方法是混合方法。", "conclusion": "研究表明，可靠性是区别各生成方法的主要因素，而不仅仅在于代码质量。混合方法在成功且具有稳健质量得分的情况下表现最佳。成本效益分析显示，混合方法比直接提示更为高效。研究结论认为，在自动化流水线生成中，结构化的混合方法可以平衡灵活性和可靠性，为数据流水线开发的普及化提供途径。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13627", "html_url": "https://arxiv.org/abs/2509.13627", "title": "云环境中安全、可扩展且隐私保护的数据策略", "title_en": "Secure, Scalable and Privacy Aware Data Strategy in Cloud", "authors": "Vijay Kumar Butte,Sujata Butte", "background": "当前企业面临处理和安全存储大量数据的挑战，同时需要快速做出基于数据驱动的决策。本论文针对这一挑战，探讨了有效的云数据策略，讨论了确保数据安全、可扩展性和隐私性的多种架构。", "innovation": "提出了适用于云环境的、有效的企业级数据策略，重点解决了数据安全、可扩展性和隐私保护等方面的问题。", "conclusion": "通过构建一个综合性的数据策略，企业可以在保障数据安全和用户隐私的同时，提高数据处理和存储的灵活性，加速决策过程，满足现代企业的数据管理需求。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13579", "html_url": "https://arxiv.org/abs/2509.13579", "title": "TreeIRL: 使用树搜索和逆强化学习实现安全城市驾驶", "title_en": "TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning", "authors": "Momchil S. Tomov,Sang Uk Lee,Hansford Hendrago,Jinwook Huh,Teawon Han,Forbes Howington,Rafael da Silva,Gianmarco Bernasconi,Marc Heim,Samuel Findler,Xiaonan Ji,Alexander Boule,Michael Napoli,Kuo Chen,Jesse Miller,Boaz Floor,Yunqing Hu", "background": "在自动驾驶领域，规划器对于实现车辆在复杂环境中安全、高效地行驶至关重要。传统的规划算法在某些场景下可能无法达到最佳性能，而现有的先进规划器虽然在模拟环境中表现出色，但在实际道路驾驶中，如何平衡安全性、效率、舒适性和人性化表现仍是一个挑战。", "innovation": "TreeIRL 是一种结合蒙特卡洛树搜索（MCTS）和逆强化学习（IRL）的新颖规划器，能够在模拟和实际道路驾驶中达到顶级性能。TreeIRL 使用 MCTS 寻找一组安全的潜在候选轨迹，并利用深度 IRL 评分函数来选择最具人性化的轨迹。This innovation stands out by demonstrating the application of MCTS-based planning on public roads and emphasizing the importance of evaluating planners across various metrics and in real-world settings.", "conclusion": "TreeIRL 在大型模拟测试中和拉斯维加斯大都会区域500多英里的实际驾驶场景中，都表现出最优的整体性能，平衡了安全、前进、舒适性和人性化的表现。我们的工作是首次在公共道路上实现基于树搜索的规划，并强调了在多个指标和实际环境中评估规划器的重要性。TreeIRL 具有高度扩展性，可以通过增强学习和模仿学习进一步提升。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13626", "html_url": "https://arxiv.org/abs/2509.13626", "title": "填空：将知识库与用户需求对齐以增强心理健康检索", "title_en": "Mind the Gap: Aligning Knowledge Bases with User Needs to Enhance Mental Health Retrieval", "authors": "Amanda Chan,James Jiayu Liu,He Kai,Onno P. Kampman", "background": "可靠的心理健康信息访问是早期求助的关键。然而，扩展知识库需要大量资源，且往往不匹配用户需求，导致检索系统在面对未覆盖或用非正式语言表达的问题时表现不佳。", "innovation": "提出了一种基于AI的填空导向框架，通过叠加自然格式的用户数据（如论坛帖子）来优先考虑基于覆盖和有用性的扩展。这种方法在提升检索生成系统表现方面表现出色，仅需适度的扩展，即在查询转换中增加42%，在重排序和层次结构中增加74%，在基本模型中增加318%至约95%的参考库性能，而随机扩展则需要更大的扩展量，实际不可行。", "conclusion": "有针对性的数据增长可以减少内容创建需求，同时保持高质的检索和提供质量，提供了一种在高风险领域构建可信赖健康信息库并支持生成AI应用的可扩展方法。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13590", "html_url": "https://arxiv.org/abs/2509.13590", "title": "基于VLM的智能医疗成像平台：一种自动医学图像分析和临床报告生成的框架", "title_en": "Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation", "authors": "Samer Al-Hamadani", "background": "医学影像领域人工智能（AI）的快速发展正在改变诊断医学和临床决策流程。这项工作提供了一种整合了视觉语言模型（VLMs）的智能多模态框架，用于医疗图像分析，该框架结合了图像和自然语言处理能力，适用于自动化肿瘤检测和多模态影像（如CT、MRI、X射线和超声波）的临床报告生成。", "innovation": "该框架利用谷歌Gemini 2.5的视觉语言模型，结合视觉特征提取和自然语言处理技术，产生了上下文图像解释、坐标验证机制和概率高斯建模异常分布。多层可视化技术生成了详细的医学图像、叠加比较和统计表示，实现了80像素平均偏差的位置测量。系统采用低保真的提示工程和文本分析提取结构化临床信息，保持解释性。多模态成像模式下的异常检测性能表现出色，并展示了零样本学习能力，减少对大量数据集的依赖。", "conclusion": "该系统提供了一个用户友好的Gradio界面以整合临床工作流程，展示了零样本学习能力。然而，在大规模临床应用之前，还需要临床验证和多中心评估。这种框架代表了自动诊断支持和放射学工作流程效率的重要进展。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13603", "html_url": "https://arxiv.org/abs/2509.13603", "title": "现代版Facebook搜索：关键词和嵌入混合检索及LLM评估", "title_en": "Modernizing Facebook Scoped Search: Keyword and Embedding Hybrid Retrieval with LLM Evaluation", "authors": "Yongye Su,Zeya Zhang,Jane Kou,Cheng Ju,Shubhojeet Sarkar,Yamin Wang,Ji Liu,Shengbo Guo", "background": "社交网络搜索的独特之处在于可以为用户提供在他们社交背景中的信息检索和潜在连接的发现。传统关键词搜索管道能够检索用户提供的关键字，但当关键词数量庞大时，结果的相关性和多样性会受到影响。因此，需要一种新的框架来增强搜索的相关性和多样性，同时还能融入语义检索。", "innovation": "论文提出了一种框架，通过将传统关键词检索与嵌入式检索（EBR）相结合，以提高搜索结果的相关性和多样性。系统引入了一种新的评估框架，利用大型语言模型（LLMs）进行离线相关性评估，确保质量和评估的一致性与可扩展性。实验结果证明，这种混合检索系统能够显著提升用户体验和搜索质量，不仅基于在线指标还通过LLM评估进行验证。", "conclusion": "通过引入融合检索方法和利用大型语言模型进行评估，该研究提供了在大规模社交平台上部署和评估高级检索系统的一些实用见解。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13672", "html_url": "https://arxiv.org/abs/2509.13672", "title": "CL$^2$GEC：中文文学语法纠错领域连续学习的多学科基准", "title_en": "CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction", "authors": "Shang Qin,Jingheng Ye,Yinghui Li,Hai-Tao Zheng,Qi Li,Jinxiao Shan,Zhixing Li,Hong-Gee Kim", "background": "自动化写作辅助在各种学术领域的日益增长的需求凸显了对适应不同学科的稳健汉语语法错误纠正（CGEC）系统的需要。然而，现有的CGEC研究主要缺乏针对多学科学术写作的专门基准，忽略了连续学习（CL）作为解决领域特定语言变异和防止灾难性遗忘的潜在解决方案。为了弥补这一关键缺口，作者引入了CL$^2$GEC，这是一个首个多学科基准，用于中文文学领域的语法错误纠正的连续学习，旨在评估跨多个学术领域的适应性CGEC能力。", "innovation": "CL$^2$GEC 是首个中文文学领域的语法错误连续学习基准，它包括了10,000条跨10个学科的人工标注句子，该基准用于评估在连续学习设置中的语法错误纠正能力。研究还评估了大语言模型在连续调优、参数化高效适应以及四种代表性连续学习算法下的表现，采用标准的语法错误纠正（GEC）度量和调整后的连续学习度量。实验结果表明，基于正则化的方法比基于数据重放或简单的连续顺序方法更有效地防止遗忘。", "conclusion": "CL$^2$GEC 为跨不同学术领域的适应性语法错误纠正提供了一个严格的基础，为未来的相关研究奠定了坚实的基础。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13620", "html_url": "https://arxiv.org/abs/2509.13620", "title": "一种用于地下流体流动的缩减阶次导数导向神经算子", "title_en": "A reduced-order derivative-informed neural operator for subsurface fluid-flow", "authors": "Jeongjin(Jayjay)Park,Grant Bruer,Huseyin Tuna Erdinc,Abhinav Prakash Gahlot,Felix J. Herrmann", "background": "神经算子已显示出成为昂贵的流体流动模拟器的有效替代方案，特别是在如从时移地震数据恢复渗透率和不确定性量化这类计算密集的任务中，神经算子的梯度精度对于下游任务（如优化和贝叶斯推理）的准确性至关重要。现有的物理信息方法通过利用梯度信息来提高替代模型的准确性，但显式包含雅可比矩阵通常会导致计算成本的急剧增加，因为复杂性通常与输入参数的数量成二次比例。为了克服这个限制，我们提出了一种基于导数的、受Fisher信息矩阵指导的缩减阶次训练框架——DeFINO。DeFINO结合了傅里叶神经算子（FNOs）与新颖的导数导向的训练策略，通过FIM识别主导特征方向，将雅可比矩阵投影到关键敏感性信息中，从而在保持准确预测的同时显著减少了计算成本。我们在地下多相流体流动的合成实验中验证了DeFINO的方法，显示出在保持前向预测准确性的同时改进梯度精度。这些结果突显了DeFINO在复杂实际场景中进行反演问题的高效、可扩展解决方案的潜力。", "innovation": "提出了DeFINO（基于导数的Fisher信息矩阵导向神经算子），这是一种基于导数导向的缩减阶次培训框架，结合了傅里叶神经算子（FNOs）以及Fisher信息矩阵（FIM）指导的新颖训练策略。通过FIM识别的主导特征方向，DeFINO将雅可比矩阵投影到关键敏感性信息中，直接由观测数据提供信息，从而显著减少计算成本。这种方法通过对合成实验在地下多相流体流动中的验证，展示了在保持前向预测准确性的同时改进梯度精度的效果，解决了现有方法在处理大规模计算任务时的高昂计算成本问题。", "conclusion": "我们的研究结果表明，DeFINO能够在复杂真实场景中为反演问题提供高效、可扩展的解决方案，且相较于传统方法，计算成本显著降低。这项工作不仅能提高对地下复杂流体动力学过程的预测准确性，还能为实际应用提供一种经济有效的工具。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13597", "html_url": "https://arxiv.org/abs/2509.13597", "title": "Agentic JWT: 一种安全的自主AI代理委派协议", "title_en": "Agentic JWT: A Secure Delegation Protocol for Autonomous AI Agents", "authors": "Abhishek Goswami", "background": "自主大型语言模型（LLM）代理可以每小时发出成千上万次API调用，而无需人类监督。OAuth 2.0假定客户端是确定性的，但在代理环境中，随机推理、提示注入或多个代理协调可以悄悄地扩大权限。", "innovation": "本文提出了Agentic JWT，这是一种双面意图token，用于将每个代理的动作与可验证的用户意图绑定，并可选地与特定的工作流步骤绑定。Agentic JWT携带代理的身份作为一个单向散列校验和，由其提示、工具和配置衍生而来，并通过链条委托声明证明哪些下游代理可以执行给定的任务，以及每个代理的证明拥有权密钥以防止重放和过程中的冒充。此外，本文定义了一种新授权机制，并添加了一个轻量级客户端插件库，该库在运行时自我验证代码、签发意图token、跟踪工作流步骤并派生密钥，从而允许代理身份和划分即使在单个进程中也能得到保障。", "conclusion": "本文提出了Agentic JWT的设计，并在Python环境中实现了概念验证，展示了对超出范围的请求、重放、冒充和提示注入路径的子毫秒级功能阻止能力。该设计与正在进行的OAuth代理讨论一致，并提供了一种直接通往自主应用零信任保障的道路。有关性能和安全性的全面评估结果将在我们的即将发表的期刊出版物中出现。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13662", "html_url": "https://arxiv.org/abs/2509.13662", "title": "Deep Lookup Network", "title_en": "Deep Lookup Network", "authors": "Yulan Guo,Longguang Wang,Wendong Mao,Xiaoyu Dong,Yingqian Wang,Li Liu,Wei An", "background": "卷积神经网络包含大量不同类型的计算操作，具有极高的计算强度。在这些操作中，乘法操作的计算复杂度最高，通常需要更多的能量消耗和更长的推断时间，这阻碍了卷积神经网络在移动设备上的部署。在许多资源受限的边缘设备上，可以通过查找表来计算复杂的操作，以降低计算成本。", "innovation": "为了克服乘法操作的高能耗问题，本文引入了一种通用且高效的查找操作，可以作为构建神经网络的基本操作。通过以可微的方式构建查找表和提出多种训练策略来促进其收敛，本文替代了成本高昂的乘法操作，提出了针对图像分类、图像超分辨率和点云分类任务的查找网络。研究表明，本文的查找网络在能耗和推断速度上具有更高的效率，同时保持与标准卷积网络相近的性能，并在不同的任务和数据类型上取得了最先进的性能。", "conclusion": "通过用查找操作取代计算成本高昂的乘法操作，本文的查找网络能够在图像分类、图像超分辨率和点云分类等任务中实现高效的能耗和推断速度，同时保持与标准卷积神经网络相当的性能，并且在不同任务和数据类型上取得了最先进的性能。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13676", "html_url": "https://arxiv.org/abs/2509.13676", "title": "重新利用SAM进行基于MLLM的高效视觉投影", "title_en": "Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation", "authors": "Xiaobo Yang,Xiaojin Gong", "background": "近年来，将多模态大型语言模型（MLLM）与分割任何模型（SAM）结合的引用图像分割（RIS）框架取得了显著成果。然而，将MLLM适应于分割过程在计算上非常密集，主要是由于视觉标记冗余的问题。通常，传统的逐块视觉投影器在减少视觉标记数量与保持语义清晰度之间难以找到平衡，过早去除视觉标记会导致性能下降。因此，研究需要开发一种既能减轻冗余又能保持语义清晰性的方法，以提高MLLM的分割效果和效率。本文观察到，传统的逐块视觉投影器在保持视觉标记数量与保持语义清晰度之间难以做出平衡，而常常保留过多的视觉标记序列以避免性能下降。受文本分词器的启发，本文提出一种新的语义视觉投影器，利用由SAM生成的语义超像素来识别图像中的“视觉单词”。通过压缩并投影语义超像素作为视觉标记，本文的方法能够根据场景复杂性自适应地缩短标记序列，同时减少语义损失。为了减少信息损失，本文还提出了一种语义超像素位置嵌入，以增强MLLM对超像素几何形状和位置的感知，以及一种语义超像素聚合器，以保持超像素内部的细粒度细节和外部的全局上下文。", "innovation": "本文提出了两种创新：一是利用语义超像素生成的视觉投影器，能够自适应地减少视觉标记数量以适应场景复杂性，同时保持语义清晰度；二是引入语义超像素位置嵌入和语义超像素聚合器，用于增强MLLM对超像素几何形状和位置的感知，同时保留超像素内外的细粒度细节和全局上下文。这种方法使得视觉标记数量减少了93%，在提高MLLM训练和推断速度的同时，超过了现有压缩视觉投影器在RIS任务中的表现。", "conclusion": "实验表明，该方法在减少视觉标记数量的同时，不牺牲性能，并显著加快了MLLM的训练和推理速度，在RIS任务上优于现有的压缩视觉投影器。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13664", "html_url": "https://arxiv.org/abs/2509.13664", "title": "LLMs 中稀疏神经元承载强烈的问题歧义信号", "title_en": "Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs", "authors": "Zhuoxuan Zhang,Jinhao Duan,Edward Kim,Kaidi Xu", "background": "在现实世界的问题中，歧义是普遍存在的，而大型语言模型（LLMs）往往给出的是自信的回答，而不是寻求澄清。研究表明，LLMs内部的表示可以通过分析神经元来检测和控制歧义信息。在模型预填充阶段，发现少数神经元（甚至只有少数一个）可以编码问题歧义信息。基于这些编码歧义信息的神经元（AENs）构建的探针在歧义检测任务上表现出色，并在不同数据集上具有良好的泛化能力。", "innovation": "本文展示了LSTM内部对问题的歧义信息具有线性编码，并可以在神经元层面上定位和调控这一信息。AENs在浅层就出现了，表明早期编码的歧义信号。利用AENs，可以实现从直接回答到回避的LLMs行为控制，增强了模型的解释能力和可控性。", "conclusion": "我们的研究发现，LLMs能够在紧凑的内部表示中形成问题歧义，从而实现可解释和可控制的行为。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13650", "html_url": "https://arxiv.org/abs/2509.13650", "title": "GitHub 的 Copilot 代码审查：AI 能否在你提交前发现安全漏洞？", "title_en": "GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit?", "authors": "Amena Amro,Manar H. Alalfi", "background": "随着软件开发实践越来越多地采用AI驱动的工具，确保这些工具能够支持安全编码变得至关重要。为了评估GitHub Copilot的新引入的代码审查功能在检测安全漏洞方面的有效性，来自多个编程语言和应用领域的多样开源项目中精心挑选出标注了漏洞的代码样本进行系统测试。然而，研究结果表明，Copilot的代码审查频繁未能检测出SQL注入、跨站脚本(XSS)和不安全的反序列化等关键性漏洞，而是主要关注低严重性的编码风格和拼写错误等问题。这揭示出了AI辅助代码审查的感知能力和实际有效性之间的巨大差距，强调了专用的安全工具和人工代码审核在确保软件安全中的必要性。", "innovation": "本研究使用GitHub Copilot的代码审查功能进行检测，评估其在发现多种编程语言和应用领域中常见安全问题的能力。尽管Copilot声称能够增强安全性，但研究结果表明它未能有效检测出关键的安全漏洞，反而是在编码风格和拼写错误等领域提供了反馈。这揭示了当前AI辅助代码审查工具的能力与期望之间的差异，突显了需要进一步发展的方向和必要性。", "conclusion": "Copilot的代码审查功能在发现严重安全漏洞方面存在不足，主要集中在低严重性的编码风格和拼写错误等问题上。此项研究突显了专用安全工具和人工代码审查在确保软件安全中的重要性，强调了需要更加有效的AI辅助代码审查工具以支持安全开发实践的持续需求。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13633", "html_url": "https://arxiv.org/abs/2509.13633", "title": "DeepLogit: 运输政策分析中的一种序列约束可解释深度学习建模方法", "title_en": "DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis", "authors": "Jeremy Oon,Rakhi Manohar Mepparambath,Ling Feng", "background": "尽管深度学习模型在众多应用中取得了显著进展，但在规划和政策相关领域中的应用仍然具有挑战性，因为这些模型具有黑盒性质。本文开发了一种新的序列约束方法，旨在通过深度学习模型进行运输政策分析。该方法首先估计一个仅具有线性项的卷积神经网络（CNN）模型，这种方法等同于参数线性化的多项式逻辑回归模型。然后通过在获得线性参数的CNN值中约束需要解释的参数，并引入更高阶项或引入类似于Transformer的高级深度学习架构，来估计其他深度学习模型。这种方法既保留了参数的可解释性，又明显提高了模型准确性，优于离散选择模型。研究通过使用新加坡实际公共交通智能卡数据的路线选择示例进行了验证，展示了理论基础的离散选择模型（DCM）和数据驱动的人工智能模型之间的互补性，可以在可解释性和预测能力方面互相取长补短。随着数据集的增大和架构的复杂化，这种方式可以导致更准确的模型，同时保持在规划和政策相关领域的适用性。我们的代码可在以下链接获取。", "innovation": "本文提出了一种新的序列约束方法，通过逐步引入深度学习模型，允许模型保持特定参数的可解释性，同时显著提高模型的准确性。这种方法结合了离散选择模型的理论基础和深度学习模型的数据驱动能力，提供了一种可能的统一方法，使得模型既可解释又能有效预测。具体创新点如下：1) 发展了一种新颖的序列约束方法，通过逐步引入模型的复杂性，保留了特定参数的解释性；2) 通过将离散选择模型和深度学习模型的优势结合起来，提高了模型的预测能力，同时保持了可解释性；3) 通过示例中的应用展示了该方法的有效性。", "conclusion": "通过大型数据集和复杂构架，本文提出的方法能够实现更准确的模型，并保持在规划和政策相关领域的适用性。在数据分析应用中，该方法展示了其潜在的价值，其研究结果对于促进政策制定具有重要意义。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13666", "html_url": "https://arxiv.org/abs/2509.13666", "title": "DREAM: 领域感知推理以实现高效自主水下监测", "title_en": "DREAM: Domain-aware Reasoning for Efficient Autonomous Underwater Monitoring", "authors": "Zhenqi Wu,Abhinav Modi,Angelos Mavrogiannis,Kaustubh Joshi,Nikhil Chopra,Yiannis Aloimonos,Nare Karapetyan,Ioannis Rekleitis,Xiaomin Lin", "background": "海洋正在变暖和酸化，增加了对如牡蛎之类的温度敏感贝类的大量死亡事件的风险。这促使了长期监测系统的开发。然而，人工劳力成本高且长时间的水下工作非常危险，因此优先考虑机器人解决方案，因为它们更安全且更有效。为了使水下机器人能够在没有人类干预的情况下进行实时、环境意识决策，它们需要配备能够自主做出决策的“智慧大脑”。这突显了需要持续、大面积且低成本的海底监测的需求。", "innovation": "我们提出了DREAM，一种由视觉语言模型（VLM）引导的自主框架，用于长期水下探险和生境监测。该框架能够高效地在没有先验位置信息的情况下发现并探索目标物体（如牡蛎、沉船）。在牡蛎监测任务中，与之前的基线相比，我们的框架在相同数量的牡蛎情况下能节省31.5%的时间。同时在覆盖牡蛎方面，与单纯的VLM相比，它使用了23%更少的步骤，覆盖范围多出了8.88%。在沉船场景中，我们的框架成功地进行了探索和绘图且未发生碰撞，所需步骤比普通的VLM模型少27.5%，并且实现了100%的覆盖范围，而普通的VLM模型在我们的沉船环境中仅实现了60.23%的平均覆盖范围。", "conclusion": "我们证明，DREAM框架在持久、大面积和低成本的海底监测方面具有很高的效率，且能够有效地指导水下机器人进行目标探索和监测，尤其对于牡蛎和沉船等水下环境的监测任务显示出明显的优势。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13688", "html_url": "https://arxiv.org/abs/2509.13688", "title": "CraftMesh: 通过泊松无缝融合实现高保真生成性网格编辑", "title_en": "CraftMesh: High-Fidelity Generative Mesh Manipulation via Poisson Seamless Fusion", "authors": "James Jincheng,Youcheng Cai,Ligang Liu", "background": "3D内容创作中，可控且高保真的网格编辑仍是一个重要的挑战。现有的生成方法在处理复杂几何形状时常常遇到困难，难以生成精细的结果。", "innovation": "提出了一种名为CraftMesh的新框架，通过泊松无缝融合实现高保真的生成性网格操作。主要创新点在于将网格编辑分解为利用2D和3D生成模型优势的管道：编辑2D参考图，生成特定区域的3D网格，然后将其无缝融合到原始模型中。此外还引入了两种核心技术：泊松几何融合，利用混合SDF/网格表示和法线混合，以实现和谐的几何集成；泊松纹理调和，确保视觉上一致的纹理混合。", "conclusion": "实验结果显示，CraftMesh在复杂的编辑任务中，优于现有的最先进的方法，提供了更高的整体一致性以及局部细节表现。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13680", "html_url": "https://arxiv.org/abs/2509.13680", "title": "Code LLMs的提示稳定性：跨情绪和个性驱动变化的测量", "title_en": "Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations", "authors": "Wei Ma,Yixiao Yang,Jingquan Ge,Xiaofei Xie,Lingxiao Jiang", "background": "代码生成模型在软件开发中被广泛使用，但它们对提示表达方式的敏感性仍然没有得到充分研究。相同的需求以不同的情绪或沟通风格表达时，可能会产生截然不同的输出，而大多数基准测试仅关注模型的峰值性能。", "innovation": "该论文提出了PromptSE（提示敏感性评估）框架，该框架通过使用情绪和个性模板生成语义上等价的提示变体，并利用概率意识连续评分或logits不可用时的二元通过率来评估稳定性。研究结果被整合到一个提议的AUC-E（面积下曲线度量）中，用于跨模型比较。该研究展示出性能和稳定性是主要分开优化的目标，揭示了架构和规模相关的模式，这些模式挑战了对模型鲁棒性的一般假设。", "conclusion": "该框架支持对闭源模型进行快速筛选以及在研究环境中进行详细的稳定性分析。PromptSE允许实践者量化部署和模型选择中的性能稳定性的权衡，将提示稳定性确立为辅助性能和公平性之外的重要评估维度，从而有助于更值得信赖的人工智能辅助软件开发工具。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13683", "html_url": "https://arxiv.org/abs/2509.13683", "title": "通过原生检索增强推理提升上下文保真度", "title_en": "Improving Context Fidelity via Native Retrieval-Augmented Reasoning", "authors": "Suyuchen Wang,Jinlin Wang,Xinyu Wang,Shiqi Li,Xiangru Tang,Sirui Hong,Xiao-Wen Chang,Chenglin Wu,Bang Liu", "background": "大型语言模型（LLMs）在处理上下文时常常缺乏一致性，当基于提供的信息回答问题时会产生不一致的答案。现有方法要么依赖昂贵的监督微调来生成解释性的证据，要么训练模型进行网络搜索，但并不一定能够有效地利用提供的上下文。这导致了上下文利用不足和生成答案准确性不高的问题。", "innovation": "该文提出了一种名为CARE的新颖的本地检索增强推理框架，能够使LLMs在推理过程中显式地整合上下文中的证据，同时利用模型的检索能力。该方法只需少量标记的证据数据，通过策略性地检索上下文中的相关令牌来显著提高检索准确性和生成答案的表现。", "conclusion": "大量实验表明，该方法不仅优于监督微调，还优于传统的检索增强生成方法和外部检索解决方案，展示了LIMS在知识密集型任务中更加精准、可靠和高效的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13722", "html_url": "https://arxiv.org/abs/2509.13722", "title": "缓解视频对象分割中的查询选择偏差", "title_en": "Mitigating Query Selection Bias in Referring Video Object Segmentation", "authors": "Dingwei Zhang,Dong Zhang,Jinhui Tang", "background": "最近的研究表明，基于查询的方法在视频对象分割（RVOS）任务中表现卓越，通过文本静态对象查询实现了跨模态对齐。然而，这些静态查询容易受到外观或动作相似的干扰物的误导，导致查询选择偏差。", "innovation": "提出了一种称为三元查询变换器（TQF）的方法，将引用查询分解为三个专门的组件：外观查询用于静态属性，帧内交互查询用于空间关系，帧间运动查询用于时间关联。引入了两种增强对象标记表示的运动感知聚合模块：帧内交互聚合模型利用单帧内对象间的位置感知交互关系，帧间运动聚合模块利用轨迹引导的帧间对齐以保持时间连贯性。", "conclusion": "在多个RVOS基准测试上的大量实验结果表明，TQF方法的优势以及结构化查询设计和运动感知聚合模块的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13706", "html_url": "https://arxiv.org/abs/2509.13706", "title": "使用大规模语言表示模型实现医疗事故报告的自动化分类和跨机构迁移学习", "title_en": "Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models", "authors": "Peter Beidler,Mark Nguyen,Kevin Lybarger,Ola Holmberg,Eric Ford,John Kang", "background": "医疗保健中事件报告是提高安全性和质量的重要工具，但人工审查耗时且需要专业知识。本研究介绍了一种自然语言处理（NLP）筛选工具，用于检测放射肿瘤学中两家机构的高严重性事件报告。研究使用了两种文本数据集来训练和评估NLP模型：本机构的数据集和IAEA SAFRON的数据集。模型评估了其跨机构的普及性，并且在两个机构的数据集上进行了微调以提高其性能。这项研究表明，通过开发跨机构的NLP模型，在审查放射肿瘤学中心的事件报告时可以达到与人类相似的性能水平。", "innovation": "本研究创新地使用自然语言处理（NLP）技术并通过跨机构迁移学习改进了事件报告的筛选模型。研究使用大规模预训练语言模型BlueBERT进行模型训练和评估，并通过微调模型提高了其在不同机构间的通用性。研究表明，通过这种方法可以有效地检测出高严重性事件报告，同时性能接近人类水平。", "conclusion": "总之，本研究成功地开发了针对放射肿瘤学中心事件报告文本的跨机构NLP模型。这些模型在经过精心筛选的报告集上能够检测出高严重性报告，其性能与人类相似。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13677", "html_url": "https://arxiv.org/abs/2509.13677", "title": "AgentCTG: 摸拟多智能体协作实现精细精确控制的文字生成", "title_en": "AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation", "authors": "Xinxu Zhou,Jiaqi Bai,Zhenqi Sun,Fanxiang Zeng,Yue Liu", "background": "尽管自然语言处理（NLP）领域的许多任务取得了显著进展，但受控文本生成（CTG）仍然面临许多挑战，特别是在实现精细化条件控制方面。在实际场景和在线应用中，成本考虑、可扩展性、领域知识学习和更精确的控制需求加大了CTG的难度。现有的CTG方法在上述方面存在不足，亟需一种新的框架来提升这些能力。", "innovation": "本文提出了一种新颖且可扩展的框架 AgentCTG，旨在通过模拟多智能体工作流中的控制和调节机制来增强文本生成的精确和复杂控制。该框架通过探索不同智能体之间的合作方法并引入自动生成提示模块，进一步提升了生成效果。实验结果表明，AgentCTG 在多个公开数据集上达到了最先进的性能。此外，我们还提出了一项新的具有挑战性的角色驱动重写任务，旨在将原始文本转换为符合特定角色特征的新文本，并同时保留领域的知识，以便在线导航提供更丰富的互动体验。", "conclusion": "通过该框架的应用，本文实现了在在线导航场景下显著提高驾驶体验的目标，使内容传递更加贴近需求。进一步地，通过优化与上下文相关的文本生成，增强了在线社区内的互动沉浸感，并促进了个性化和用户的参与度。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13735", "html_url": "https://arxiv.org/abs/2509.13735", "title": "有向图上的状态空间模型", "title_en": "State Space Models over Directed Graphs", "authors": "Junzhi She,Xunkai Li,Rong-Hua Li,Guoren Wang", "background": "有向图在众多领域中普遍存在，其中边的方向性编码了关键的因果依赖关系。然而，现有的针对有向图的图神经网络和图Transformer在捕捉由有向边衍生的长范围因果依赖关系和处理大规模图数据集时准确性与训练效率之间存在挑战。尽管状态空间模型（SSMs）和其图变体在因果序列任务中取得了显著进展，并且在各种图学习基准测试中表现出高效性和高精度，但现有图状态空间模型仅适用于无向图，限制了它们在有向图学习中的性能。", "innovation": "提出了一种创新的方法——DirEgo2Token，通过k跳ego图对有向图进行序列化。这是首次系统地将状态空间模型扩展到有向图学习领域。在此基础上，开发了一个新的有向图神经网络架构DirGraphSSM，该架构通过消息传递机制在有向图上实现状态空间模型。实验结果表明，DirGraphSSM在三个代表性有向图学习任务中达到了最先进的性能，而在额外的两个任务中，与现有的最佳模型相比，训练速度快了1.5至2倍。", "conclusion": "DirGraphSSM模型在精准性和训练效率方面表现出色，是首次将状态空间模型应用于有向图学习领域的方法。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13805", "html_url": "https://arxiv.org/abs/2509.13805", "title": "向物理基础模型迈进", "title_en": "Towards a Physics Foundation Model", "authors": "Florian Wiesner,Matthias Wessling,Stephen Baek", "background": "基础模型通过“一次训练，随处部署”的范式，已经重塑了自然语言处理领域，使单一预训练模型能够适应无数下游任务而无需重新训练。物理基础模型（PFM）的获得将使高保真模拟的访问更加民主化，加速科学发现进程，并消除专门求解器开发的需要。然而，当前的物理感知机器学习方法仍然主要局限在单一狭隘领域，并且需要为每个新系统重新训练。", "innovation": "我们提出了通用物理变换器（GPhyT），并使用1.8 TB多样的模拟数据进行训练，展示了基础模型能力在物理中的实现。GPhyT 的关键技术突破在于：（1）在多个物理领域取得了优越性能，相较于专业架构最高提升29倍；（2）通过上下文学习实现零样本泛化，拓展到全新的物理系统；（3）通过长达50个时间步骤的滚动预测实现了长期稳定的预测。", "conclusion": "通过证明单一模型能仅从数据学习到可泛化的物理原理，这项工作为通用PFM铺平了道路，该通用模型有可能彻底改变计算科学与工程领域。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13755", "html_url": "https://arxiv.org/abs/2509.13755", "title": "清洗掉它！通过机器遗忘消除代码语言模型中的敏感记忆", "title_en": "Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning", "authors": "Zhaoyang Chu,Yao Wan,Zhikun Zhang,Di Wang,Zhou Yang,Hongyu Zhang,Pan Zhou,Xuanhua Shi,Hai Jin,David Lo", "background": "代码语言模型（CLMs）在软件工程任务中表现出色，如代码生成和总结。然而，最近实证研究表明，这些模型可能存在严重的隐私漏洞：它们无意中记忆了敏感的训练数据，当被特定提示时，能够原封不动地复制机密信息。目前提出的解决方法，如训练数据去重和差异隐私增强，需要对已部署的CLMs进行全面重新训练，这会带来巨大的计算成本。本文旨在探讨是否可以通过机器遗忘（一种后处理修改方法）有效且高效地清除CLMs中存储的敏感信息。", "innovation": "本文提出了一种名为CodeEraser的方法，这是一种高级的机器遗忘变体，可以有选择地清除代码中敏感记忆片段，同时保留周围代码的结构完整性和功能正确性。研究团队还量化了CLM训练数据集中敏感数据的记忆风险，选择了一个包含50,000个敏感记忆样本的高风险数据集作为遗忘目标，且测试了两种常用的梯度上升基线遗忘方法和一个改进的CodeEraser版本。通过在三种CLM家族（CodeParrot，CodeGen-Mono和Qwen2.5-Coder）上的广泛实验，验证了CodeEraser在清除目标敏感记忆的同时保持模型实用性的有效性和效率。", "conclusion": "本文通过机器遗忘有效地实施了对CLMs中敏感信息的删除，验证了CodeEraser方法的有效性和效率，同时保持了模型的实用性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13792", "html_url": "https://arxiv.org/abs/2509.13792", "title": "补全合成与真实图像之间的差距：用于鲁棒航天器6自由度姿态估计的监督域自适应", "title_en": "Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation", "authors": "Inder Pal Singh,Nidhal Eddine Chenni,Abd El Rahman Shabayek,Arunkumar Rathinam,Djamila Aouada", "background": "航天器姿态估计（SPE）是自主太空操作的基本能力，如对接和在轨服务。近年来，结合对象检测、关键点回归和Perspective-n-Point(PnP)求解器的混合流水线在合成数据集上取得了很好的结果，但在真实或实验室生成的图像上表现不佳，原因是合成与真实域之间的差距持续存在。现有的一些无监督域自适应方法试图缓解这一问题，但在少量标记的目标数据时往往表现不佳。已有方法在面对真实数据时的表现不尽如人意。", "innovation": "本文提出了一种专为SPE关键点回归而设计的第一种监督域自适应（SDA）框架。该方法基于Learning Invariant Representation and Risk(LIRR)范式，通过联合优化域不变表示和任务特定的风险，使用标记的合成数据和有限的标记真实数据，从而在域变化下降低泛化误差。实验表明，在仅使用5%标记的目标数据时，该方法在鲁棒性上与更大份额标记数据训练的 oracle 方法表现相当甚至更优。该框架轻量级、骨干网络无关，并具有高效性。", "conclusion": "该研究在SPEED+基准上进行了广泛的实验，证明了所提出的方法在大多数情况下都优于仅使用源数据、微调和oracle基线的方法。此外，随着少量标记真实数据的增加，该方法展现出卓越的性能。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13790", "html_url": "https://arxiv.org/abs/2509.13790", "title": "根据能力教学！使用能力感知课程学习调优LLMs", "title_en": "Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning", "authors": "Yangning Li,Tingwei Lu,Yinghui Li,Yankai Chen,Wei-Chieh Huang,Wenhao Jiang,Hui Wang,Hai-Tao Zheng,Philip S.Yu", "background": "有效的指令调优旨在通过优化大型语言模型（LLMs）在特定指令数据集上的训练，来提升模型的最终性能。当前的课程调优方法存在课程僵硬的问题，因为它们依赖于静态的启发式难度指标，不能适应模型在训练过程中不断变化的能力，导致固定且可能不理想的训练轨迹。传统的数据组织策略如分阶段学习已经显示出初步效果，但当前方法仍存在不足。", "innovation": "提出了一个名为CAMPUS的能力感知多视角课程指令调优框架，具有以下优势：(1) 动态选择子课程；(2) 根据能力调整课程计划；(3) 多种基于难度的调度策略。广泛的实验表明，CAMPUS在有效指令调优方面优于其他最先进的基线方法。", "conclusion": "CAMPUS通过动态选择子课程、能力感知调整课程计划和多种基于难度的调度策略，显著提高了LLMs的调优效率和最终性能，克服了传统课程调优方法的固有局限性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13782", "html_url": "https://arxiv.org/abs/2509.13782", "title": "谁在引入故障？通过频谱分析自动归因多Agent系统中的故障", "title_en": "Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis", "authors": "Yu Ge(1),Linna Xie(1),Zhong Li(1),Yu Pei(2),Tian Zhang(1) ((1) Nanjing University, (2) The Hong Kong Polytechnic University)", "background": "随着大型语言模型驱动的多Agent系统（MASs）被越来越多地应用于自动化解决复杂现实问题，如编程和科学发现，尽管这些系统很有前景，但它们也存在缺陷。特别是在MASs中，失败归因——即识别导致失败的特定Agent行为——依然是一个尚未充分研究且劳动密集型的问题，这对调试和系统改进构成了重大挑战。", "innovation": "本文提出了一种新的谱系归因方法FAMAS，它是第一个用于MASs的基于谱系的失败归因方法。FAMAS通过系统的轨迹回放和抽象化，从多次MAS执行中行为的变异中，估计出每一个Agent行为导致失败的可能性。该方法特别提出了适用于MASs的新型可疑度公式，综合考虑了Agent行为组和动作行为组两个关键因素群体，以处理MAS执行轨迹中的激活模式。在Who和When基准测试中，FAMAS与12种baselines的比对显示出了优越的性能，超越了所有其他方法。", "conclusion": "FAMAS作为第一个基于谱系的MASs失败归因方法，通过计算不同执行间的Agent行为和动作行为模式的变化，有效地提高了故障归因的准确性和效率，解决了这一长期困扰多Agent系统领域的难题。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13775", "html_url": "https://arxiv.org/abs/2509.13775", "title": "探索阿拉伯方言识别的数据和参数高效策略", "title_en": "Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications", "authors": "Vani Kanjirangat,Ljiljana Dolamic,Fabio Rinaldi", "background": "本文讨论了我们对阿拉伯方言识别（ADI）的不同数据高效和参数高效方法的探索。特别地，我们研究了各种软提示策略，包括前缀调优、提示调优、P调优以及P调优V2，以及LoRA重构。对于数据高效策略，我们分析了零样本和少样本情况下硬提示的能力，以评估大型语言模型（LLMs）的方言识别能力。对于参数高效的方法，我们使用阿拉伯特定的编码器模型在多个主要数据集上进行了实验，并分析了少样本情况下的开源解码器模型，以及通用多语言模型（Phi-3.5）和阿拉伯特定的模型（SILMA）的开放源代码全量模型的少样本推理能力。我们观察到，LLMs 在少样本或零样本设置中一般难以区分方言差异。软提示的编码器变体表现较好，而基于LoRA的微调模型表现最佳，甚至优于完全微调 ", "innovation": "本文主要创新在于探索了不同数据和参数高效的策略来改进阿拉伯方言识别，特别是通过研究软提示策略和LoRA重构。这些方法为阿拉伯方言识别领域提供了新的途径和改进方法，尤其是在数据和计算资源有限的条件下优化模型性能.", "conclusion": "研究结果显示，软提示的编码器变体在少样本和零样本设置中表现较好，而基于LoRA的微调模型表现最佳，甚至超过了全量微调的效果。这意味着在阿拉伯方言识别任务中，采用这些高效策略可以显著提高模型的性能，特别是在资源有限的情况下。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13854", "html_url": "https://arxiv.org/abs/2509.13854", "title": "理解人类与人工智能价值观对齐的过程", "title_en": "Understanding the Process of Human-AI Value Alignment", "authors": "Jack McKinlay,Marina De Vos,Janina A. Hoffmann,Andreas Theodorou", "background": "计算机科学研究中，价值观对齐通常指的是使人工智能与人类对齐的过程，但该术语的使用往往缺乏精确性。", "innovation": "本文通过系统文献综述，从研究文献的角度对价值观对齐进行分类和概括，提出了一个更为精确的定义。", "conclusion": "作者通过分析文献中的六个关键主题——价值观对齐的驱动因素与方法、对齐中的挑战、价值在对齐中的角色、人类和AI的认知过程、人-智能代理团队以及设计和开发对齐系统，定义了价值观对齐为人类与自主代理之间的一个持续过程，旨在表达和实现抽象价值，同时管理人类和AI代理的认知极限，平衡不同群体产生的冲突伦理和政治需求。这一分析对未来的研究提出了挑战和机遇。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13789", "html_url": "https://arxiv.org/abs/2509.13789", "title": "BWCache: 通过块级缓存加速视频扩散变换器", "title_en": "BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching", "authors": "Hanshuai Cui,Zhiqing Tang,Zhifei Xu,Zhi Yao,Wenyi Zeng,Weijia Jia", "background": "近期的研究表明，扩散发射器（DiTs）已成为视频生成的最新最佳方法。然而，它们固有的逐帧去噪过程会导致不可避免的延迟，限制了其实用性。现有的加速方法要么由于架构修改而导致视觉质量下降，要么无法在合适的粒度上重复使用中间特征。我们的分析表明，DiT模块是推理延迟的主要来源。扩散步长期间，DiT模块的特征变化呈现出U形模式，在中间步骤之间相似性很高，这表明存在大量的冗余计算。", "innovation": "我们提出了一种称为Block-Wise Caching（BWCache）的无需训练的方法来加速基于DiT的视频生成。BWCache动态地跨扩散步骤缓存和重复使用DiT模块的特征。此外，我们引入了一个相似性指示器，该指示器仅在相邻步骤之间的模块特征差异低于阈值时触发特征重用，以最小化冗余计算同时保持视觉保真度。实验结果表明，BWCache可以在可比的视觉质量下实现高达2.24倍的加速效果。", "conclusion": "本文提出了一种无需训练的块级缓存方法（BWCache），用于加速基于DiT的视频生成。通过动态缓存和共享DiT模块之间的特征，减少了冗余计算，同时保持了视觉质量。实验结果验证了BWCache的有效性和高效性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13914", "html_url": "https://arxiv.org/abs/2509.13914", "title": "预训练模型的集成用于长尾轨迹预测", "title_en": "Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction", "authors": "Divya Thuremella,Yi Yang,Simon Wanna,Lars Kunze,Daniele De Martini", "background": "随着自动驾驶领域不断出现更先进、规模更大的预测模型，一个重要的开放挑战是如何在无需高昂的重新训练成本的情况下，结合这些大模型的优势。轨迹预测在多维回归问题中尤为重要，特别是在城市环境中的车辆轨迹预测中。", "innovation": "本研究展示了如何通过简单的方法（即，使用一个没有重新训练或微调的最先进的深度学习模型的置信加权平均法）集成预训练模型来改善轨迹预测性能。该方法在长尾指标中尤其有效，并在NuScenes和Argoverse数据集上显示出10%的性能提升。", "conclusion": "该简单的方法在两个数据集上都提高了模型性能，并且这些改进覆盖了数据集的分布。研究的代码是开源的。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13888", "html_url": "https://arxiv.org/abs/2509.13888", "title": "通过多模态假说检测与依据证据验证对抗生物医学 misinformation", "title_en": "Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification", "authors": "Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato", "background": "医疗保健中的不实信息，从疫苗犹豫到未经验证的治疗方法，对公共健康和对医疗系统的信任构成风险。尽管机器学习和自然语言处理已经提升了自动事实核查的能力，但在复杂的医学术语、领域专业知识的需求以及科学证据的基础要求方面，验证生物医学声明仍然具有独特挑战。", "innovation": "提出一种名为CER（Combining Evidence and Reasoning）的新颖生物医学事实核查框架，该框架结合了科学证据检索、基于大型语言模型的推理和有监督的可信度预测。通过整合大型语言模型的文本生成能力和高质量医学科学证据的高级检索技术，CER有效减少了幻觉风险，确保生成内容基于可验证的、基于证据的来源。", "conclusion": "在专家标注数据集（HealthFC、BioASQ-7b、SciFact）上的评估显示了最先进的性能并展示了跨数据集的良好泛化能力。已发布代码和数据以确保透明性和可重复性：this https URL"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13926", "html_url": "https://arxiv.org/abs/2509.13926", "title": "MAP: 使用地图辅助规划的端到端自动驾驶", "title_en": "MAP: End-to-End Autonomous Driving with Map-Assisted Planning", "authors": "Huilin Yin,Yiming Kan,Daniel Watzenig", "background": "近年来，端到端自动驾驶技术逐渐受到关注，因为它能够在统一框架内联合建模感知、预测和规划。然而，大多数现有的方法并未充分利用在线地图模块的潜力，这使得通过在线地图来增强轨迹规划的潜力得到了很大程度的开发。", "innovation": "本文提出了MAP（地图辅助规划）框架，这是一种 novel 地图辅助的端到端轨迹规划方法。MAP 通过 Plan-enhancing Online Mapping 模块、Ego-status-guided Planning 模块以及基于当前 ego 状态的 Weight Adapter 显式地整合了基于分割的地图特征以及当前的 ego 状态。实验结果表明，与 UniV2X 基线方法相比，所提出的方法在 L2 轨迹误差上减少了 16.6%，非道路率减少了 56.2%，总体分数提高了 44.5%，并且在 CVPR2025 年 MEIS Workshops 中 End-to-End 自动驾驶通过 V2X 合作挑战中的 Track 2 中，其总体分数优于第二名的模型 39.5%。这表明在规划中显式利用语义地图特征的有效性，为改进端到端自动驾驶系统的设计提供了新的方向。", "conclusion": "通过显式利用语义地图特征进行规划，该研究突显了规划的有效性，并为提升端到端自动驾驶系统的结构设计提供了新方向。本研究的代码可在 provided URL 找到。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13879", "html_url": "https://arxiv.org/abs/2509.13879", "title": "整合证据与推理的医学事实核查", "title_en": "Combining Evidence and Reasoning for Biomedical Fact-Checking", "authors": "Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato", "background": "在医疗领域，从疫苗犹豫到未经验证的治疗方法的错误信息对公众健康和对医疗系统的信任构成风险。尽管机器学习和自然语言处理的进步使自动化事实核查变得先进，但在生物医学声明验证方面仍然具有挑战性，因为涉及到复杂的术语、需要领域专业知识以及对基于科学证据的严格要求。", "innovation": "我们提出了一种名为CER（整合证据与推理）的新框架，用于医学事实核查。该框架集成了科学证据检索、通过大型语言模型进行的推理和监督可信度预测。通过结合大型语言模型的文本生成能力和高质量生物医药科学证据的高级检索技术，CER有效减少了幻觉的风险，确保生成的输出基于可验证和基于证据的来源。在专家注释的数据集（HealthFC、BioASQ-7b、SciFact）上的评估显示其性能处于最新水平，并且具有跨数据集的推广潜力。", "conclusion": "CER在专家注释的数据集上展示了先进的性能和跨数据集的推广潜力。为了促进透明性和再现性，代码和数据已公开发布：https://github.com/PRAISELab-PicusLab/CER。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13905", "html_url": "https://arxiv.org/abs/2509.13905", "title": "大型语言模型理解词义吗？", "title_en": "Do Large Language Models Understand Word Senses?", "authors": "Domenico Meconi,Simone Stirpe,Federico Martelli,Leonardo Lavalle,Roberto Navigli", "background": "理解语境中词的意义是大型语言模型（LLMs）的一项基本能力。尽管进行了大量的评估工作，但LLMs能否真正理解词义的情况仍被广泛低估。", "innovation": "本研究通过评估指导调优的LLMs的词义消歧能力是否与特定为此任务设计的最新系统相当，同时还评估了两个表现最突出的开源和商用LLM在三种生成环境下的对词义的理解：定义生成、自由解释和示例生成。发现值得注意的是，领先模型如GPT-4o和DeepSeek-V3在词义消歧任务中的表现与专业化词义消歧系统相当，而且在不同领域和难度级别上表现更稳健。在生成任务中，结果显示LLMs可以高达98%的准确率解释词的含义，其中自由解释任务表现出最佳性能，这与它们的生成能力最一致。", "conclusion": "总体认为，指导调优的LLMs在词义消歧和解释的准确度方面表现出色，显示了它们强大的稳健性和对词义上下文理解能力。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13866", "html_url": "https://arxiv.org/abs/2509.13866", "title": "掩蔽扩散模型作为能量极小化问题", "title_en": "Masked Diffusion Models as Energy Minimization", "authors": "Sitong Chen,Shen Nie,Jiacheng Sun,Zijin Feng,Zhenguo Li,Ji-Rong Wen,Chongxuan Li", "background": "本文提出了一个系统性的理论框架，解释了掩蔽扩散模型（MDMs）作为离散最优运输中的能量最小化问题的解决方案。文中证明了三种不同的能量形式——动能、条件动能和测地线能量，在MDMs结构下是数学上等价的，并且当掩码时间表满足闭式最优化条件时，MDMs会最小化这三种能量。", "innovation": "本文通过将插值时间表参数化为Beta分布，将时间表设计空间减少为可处理的二维搜索，从而在无需修改模型的情况下进行有效的后训练调整。实验结果表明，基于能量的插值时间表在低步数采样环境下优于手工设计的基础模型.", "conclusion": "本文的框架不仅澄清了MDMs的理论基础，还激励了在采样方面的实践改进。通过参数化插值时间表的方法，作者展示了其在合成和真实世界基准测试中的优越性，特别是对于低步数采样的情况。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13927", "html_url": "https://arxiv.org/abs/2509.13927", "title": "DSpAST: Disentangled Representations for Spatial Audio Reasoning with Large Language Models", "title_en": "DSpAST: Disentangled Representations for Spatial Audio Reasoning with Large Language Models", "authors": "Kevin Wilkinghoff,Zheng-Hua Tan", "background": "在使用大型语言模型进行空间音频推理时，需要一个空间音频编码器作为声学前置端来获得音频嵌入，以便进一步处理。这种编码器需要捕捉检测声源类型、方向和距离所需的所有信息。然而，使用单一音频编码器来完成这个任务是具有挑战性的，因为每个任务所需的这些信息大部分是独立的。因此，使用单一编码器通常比使用特定任务的音频编码器的效果更差。", "innovation": "本文提出了DSpAST，一种基于SpatialAST的新音频编码器，学习空间音频的解纠缠表示，同时仅增加0.2%的额外参数。实验结果显示，DSpAST在SpatialSoundQA系统与空间音频推理系统BAT中的表现显著优于SpatialAST。", "conclusion": "DSpAST显著提高了空间音频推理的性能，尤其是在使用大型语言模型时，同时只增加了极少的额外参数量。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13987", "html_url": "https://arxiv.org/abs/2509.13987", "title": "联邦学习中的差分隐私：随机响应缓解推断攻击", "title_en": "Differential Privacy in Federated Learning: Mitigating Inference Attacks with Randomized Response", "authors": "Ozer Ozturk,Busra Buyuktanir,Gozde Karatas Baydogmus,Kazim Yildiz", "background": "联邦学习架构通过将数据留在客户端并定期将本地训练模型上传到中央服务器来处理分布式架构中的服务器和客户端，以解决数据隐私和安全问题。然而，这种方法仍存在安全漏洞，即攻击者可能通过模型推理攻击推断训练数据集，造成数据泄露。为了解决这一问题，本研究采用差分隐私技术，采用数据无感知分类基于关联（duCBA）算法作为联邦聚合方法，并使用随机响应技术在数据上实施差分隐私。", "innovation": "本研究的创新之处在于采用差分隐私技术结合随机响应技术在联邦学习中保护数据隐私，特别是通过防止推断攻击以增强模型安全性。同时，研究还分析了在不同ε值下的安全性和性能之间的权衡关系。", "conclusion": "研究表明，随着ε值的降低，模型的准确性下降，并且类别预测不平衡问题显现。这表明，更高的隐私保护级别并不总是带来实际的效果，必须仔细平衡安全性和性能之间的关系。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13892", "html_url": "https://arxiv.org/abs/2509.13892", "title": "屏幕时间与应用程序使用合成数据生成", "title_en": "Synthetic Data Generation for Screen Time and App Usage", "authors": "Gustavo Kruger,Nikhil Sachdeva,Michael Sobolev", "background": "智能手机使用数据可以提供理解技术互动和人类行为的重要见解。然而，收集大规模的野外智能手机使用日志具有挑战性，原因包括高成本、隐私问题、代表性不足的用户样本和类似非响应的偏差，这些都会扭曲结果。这些问题促使探索获取智能手机使用数据集的替代方法。在这种背景下，诸如Open AI的ChatGPT等大型语言模型（LLMs）为生成合成智能手机使用数据提供了一种新方法，克服了实际数据收集的局限性。我们描述了四种提示策略如何影响生成的智能手机使用数据质量的案例研究。我们贡献了关于提示设计和数据质量度量的见解，报告了结合两个因素的提示策略比较：提示的详细程度（描述用户原型，描述预期结果特征）和种子数据的纳入（有初始真实使用的例子或没有）。我们的发现表明，使用LLMs生成结构化且行为上可信的智能手机使用数据集在某些应用场景中是可行的，特别是在使用详细提示时。挑战仍然在于在单一合成数据集中捕捉人类行为模式的多样细微之处，并权衡数据精确性和多样性的权衡，这表明需要为特定应用场景制定评估指标，并进行更多样化的种子数据和不同LLM模型的未来研究", "innovation": "我们利用大型语言模型（LLMs）如Open AI的ChatGPT，探索了一种新型的合成智能手机使用数据生成方法。我们设计并比较了四种提示策略，以影响生成的智能手机使用数据的质量，并提出了关于提示设计和数据质量度量的见解。这个创新点为获取大规模、多样化的智能手机使用数据提供了一种新的视角，克服了实际数据收集中的挑战", "conclusion": "使用大型语言模型（LLMs）生成结构化且行为上可信的智能手机使用数据集在某些应用场景中是可行的，尤其是在使用详细提示时。然而，仍然存在挑战，即在单一合成数据集中捕捉人类行为模式的多样细微之处，并权衡数据精确性和多样性的权衡。这意味着需要为特定应用场景制定评估指标，并进行更多样化的种子数据和不同LLM模型的研究。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14003", "html_url": "https://arxiv.org/abs/2509.14003", "title": "RFM-Editing: 修正流动匹配技术在文本引导式音频编辑中的应用", "title_en": "RFM-Editing: Rectified Flow Matching for Text-guided Audio Editing", "authors": "Liting Gao,Yi Yuan,Yaru Chen,Yuelan Cheng,Zhenbo Li,Juan Wen,Shubin Zhang,Wenwu Wang", "background": "文本到音频生成领域已经取得了显著的进展，但基于文本的音频编辑仍处于初级阶段。该任务旨在保留音频信号中的非目标内容的同时，精确修改目标内容，这需要根据文本提示实现精确的定位和真实的编辑。现有的基于训练的方法和零样本方法通常由于复杂编辑需求或缺乏实用性而难以应对。", "innovation": "本文提出了一种新颖的端到端高效修正流动匹配（Rectified Flow Matching，RFM）驱动的扩散框架，用于音频编辑任务，并构建了一个包含重叠多事件音频的数据集，以支持复杂场景下的训练和基准测试。实验结果表明，该模型在无需辅助说明或遮罩的情况下实现了忠实的语义对齐，并且在多个指标上保持了竞争力的编辑质量。", "conclusion": "该研究提出了一种新的方法来实现文本引导的音频编辑，成功解决了复杂编辑任务，同时保持了高质量的编辑效果。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14031", "html_url": "https://arxiv.org/abs/2509.14031", "title": "训练数据成分的影响：训练情境感知机器翻译模型的效果", "title_en": "You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models", "authors": "Paweł Mąka,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis", "background": "实现人类级别的翻译需要利用上下文以确保连贯性，并处理如代词消歧等复杂现象。标准训练数据中上下文丰富样本量稀少被认为是导致难以利用上下文因素的原因。", "innovation": "本文系统地在单语和多语环境中通过构建控制上下文相关样本比例的训练数据集来验证这一假设。研究揭示，一种上下文现象的改进并不适用于其他现象。虽然观察到一定程度的跨语言信息转移，但在同一语系内不同语言之间的转移并不显著。据此，提出了两种训练策略以利用现有数据，并通过实验证明这些策略能够改善上下文使用，分别在单语和多语环境中提高了6和8个百分点。", "conclusion": "训练数据稀疏性是模型性能的关键瓶颈。跨语言上下文现象的改进不具有推广效果，不同上下文现象的改进没有关联性。提出了两种训练策略提高模型的上下文感知能力。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14008", "html_url": "https://arxiv.org/abs/2509.14008", "title": "Hala技术报告：构建大规模的阿拉伯语文本与翻译模型", "title_en": "Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale", "authors": "Hasan Abed Al Kader Hammoud,Mohammad Zbeeb,Bernard Ghanem", "background": "当前自然语言处理（NLP）领域中，大多数模型都是以英语为中心构建的，较少关注阿拉伯语的语言特性，导致阿拉伯语处理效果欠佳。本研究旨在填补这一空白，特别为阿拉伯语构建了一系列以阿拉伯语为中心的指令和翻译模型，以提高阿拉伯语的处理能力和准确性。", "innovation": "研究人员开发了一种‘翻译与调整’管道，首先将强阿拉伯语-英语教师模型压缩到FP8，提高其吞吐量而不损失质量，再利用此模型生成高质量的双语监督数据。基于此数据，一个轻量级的阿拉伯语语言模型LFM2-1.2B进行微调，用于高质量地将英语指令翻译成阿拉伯语，生成大规模精准的指令适应语料库。此外，使用slerp合并技术平衡阿拉伯语特化与基础模型的优势，使模型在阿拉伯语专门基准上达到最先进的结果，特别是在“nano”和“small”类别中优于基础模型。", "conclusion": "通过构建一系列专门针对阿拉伯语的指令和翻译模型，本研究在阿拉伯语处理上取得了显著成果，并提供了模型、数据、评估和指南以加速阿拉伯语NLP的研究进程。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14036", "html_url": "https://arxiv.org/abs/2509.14036", "title": "SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation", "title_en": "SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation", "authors": "Zekang Liu,Wei Feng,Fanhua Shang,Lianyu Hu,Jichao Feng,Liqing Gao", "background": "手语翻译（SLT）能够弥合聋人与听力人群之间的沟通差距，对话提供了重要的背景信息，有助于翻译。目前的翻译方法大多依赖于易于注释的‘词典式翻译’标注，但这种标注方式难以全面考虑对话背景。如何有效整合对话上下文信息，提高翻译效率与准确性成为一个关键挑战。", "innovation": "本文提出了一种基于问题的手语翻译（QB-SLT），并引入了一种新的交叉模态自监督学习方法（SSL-SSAW），该方法通过对比学习对齐了多模态特征，并引入了Sigmoid 自注意力加权模块（SSAW）实现问题和手语序列特征的自适应提取。此外，本文还利用问题文本进行自监督学习以增强表示能力和翻译能力。在 CSL-Daily-QA 和 PHOENIX-2014T-QA 数据集上的实验结果表明，SSL-SSAW 方法取得了当前最佳性能。", "conclusion": "利用易于获取的问题辅助信息可以在手语翻译任务中实现或超越传统词典式翻译的辅助效果。融入对话上下文显著提高了翻译质量，展示了基于问题的手语翻译的有效性和优越性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13990", "html_url": "https://arxiv.org/abs/2509.13990", "title": "Slim-SC: 思维剪枝以提高自我一致性效率的规模", "title_en": "Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency", "authors": "Colin Hong,Xu Guo,Anand Chaanan Singh,Esha Choukse,Dmitrii Ustiugov", "background": "最近，测试时缩放（Test-Time Scaling, TTS）技术受到了越来越多的关注，因为它们能够在无需重新训练模型的情况下提高大语言模型（LLM）在测试时的推理性能。一种特别引人注目的TTS技术是自我一致性（Self-Consistency, SC），它通过并行生成多个推理链并根据多数投票来选择最终答案。虽然SC非常有效，但其计算量级的开销限制了它的广泛应用。此前加速SC的方法主要依赖于模型本身的信心分数或缺乏实验证据的启发式方法。", "innovation": "本文首次从理论上和实验上分析了SC的低效率，并揭示了改进的机会。基于这些见解，作者提出了Slim-SC，这是一种逐步剪枝策略，能够通过链间相似性在思维层面识别并移除冗余链。实验结果表明，与SC相比，Slim-SC能够在保留或提高准确性的前提下，将推理延迟和KVC使用量分别减少45%和26%，从而提供了一个简单而高效的SC替代方案。", "conclusion": "Slim-SC通过逐步剪枝策略显著降低了推理延迟和KVC使用量，同时保持或提高了准确性，为一种简单的SC替代方案。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13978", "html_url": "https://arxiv.org/abs/2509.13978", "title": "LLM代理用于交互式工作流证明：参考架构和评估方法", "title_en": "LLM Agents for Interactive Workflow Provenance: Reference Architecture and Evaluation Methodology", "authors": "Renan Souza,Timothy Poteet,Brian Etz,Daniel Rosendo,Amal Gueroudji,Woong Shin,Prasanna Balaprakash,Rafael Ferreira da Silva", "background": "现代科学发现依赖于跨越边缘、云和高性能计算（HPC）连续体的数据处理工作流。全面深入的数据分析对于假设验证、异常检测、可重复性和获得有意义的发现至关重要。现存的工作流来源技术虽然支持这些分析，但在大规模情况下，来源数据变得复杂且难以分析。现有系统依赖于自定义脚本、结构化查询或静态仪表板，限制了数据的交互。", "innovation": "本文提出了一个交互式大型语言模型（LLM）代理的评估方法、参考架构和开源实现。该方法通过轻量级、元数据驱动的设计将自然语言转换为结构化的来源查询，覆盖LLaMA、GPT、Gemini和Claude等多个模型，涵盖了多种查询类和实际的化学工作流。研究结果表明，模块化设计、提示调优和检索增强生成（RAG）可以使LLM代理的回答超出已记录的来源，变得准确且具有洞察力。", "conclusion": "综合评估和实验表明，利用这种基于LLM代理的方法，可以在大规模和多样化的数据复杂性和查询场景中有效地进行交互式工作流来源分析，增强了数据互动性和分析的灵活性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14040", "html_url": "https://arxiv.org/abs/2509.14040", "title": "Prompt2Auto：从运动提示到几何不变的一次性高斯过程自动控制", "title_en": "Prompt2Auto: From Motion Prompt to Automated Control via Geometry-Invariant One-Shot Gaussian Process Learning", "authors": "Zewen Yang,Xiaobing Dai,Dongfa Zhang,Yu Li,Ziyang Meng,Bingkun Huang,Hamid Sadeghian,Sami Haddadin", "background": "学习从演示（Learning from demonstration）使机器人可以从人类演示中获得复杂的技能，但传统的做法往往需要大量的数据集并且在坐标转换下无法泛化。", "innovation": "提出了一种几何不变的一次性高斯过程（GeoGP）学习框架Prompt2Auto，它允许机器人仅从单一运动提示中执行由人类引导的自动控制。引入了一种基于坐标变换的数据集构建策略，以确保在平移、旋转和缩放下的不变性，同时还支持多步预测。", "conclusion": "通过设计的用户图形界面进行的数值模拟和两个真实世界的机器人实验验证了所提出的方法的有效性、任务跨任务泛化性和显著减少演示负担的能力。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14037", "html_url": "https://arxiv.org/abs/2509.14037", "title": "PhenoGnet: 基于图的对比学习框架用于疾病相似性预测", "title_en": "PhenoGnet: A Graph-Based Contrastive Learning Framework for Disease Similarity Prediction", "authors": "Ranga Baminiwatte,Kazi Jewel Rana,Aaron J. Masino", "background": "理解疾病相似性对于诊断、药物发现和个人化治疗策略的发展至关重要。PhenoGnet提出了一种新颖的图基对比学习框架，该框架通过整合基因功能相互作用网络和人类表型组（HPO），来预测疾病相似性。", "innovation": "PhenoGnet包含两个关键组件：一个在视图内模型，分别使用图卷积网络（GCN）和图注意网络（GAT）编码基因和表型图；一个跨视图模型，作为共享权重的多层感知机（MLP），通过对比学习对齐基因和表型嵌入。该模型使用已知的基因-表型关联作为正样本，随机抽样的无关样本作为负样本进行训练。疾病通过其关联基因和/或表型的平均嵌入表示，利用余弦相似性计算对相似性。对1,100对相似疾病和866对不相似疾病的内置基准测试表明，基因嵌入取得了出色的效果，AUCPR为0.9012，AUROC为0.8764，超越了现有的最先进的方法。值得注意的是，PhenoGnet捕捉到了超越直接重叠的潜在生物关系，提供了一个可扩展且可解释的解决方案，可用于疾病相似性预测。", "conclusion": "这些结果突显了PhenoGnet在罕见疾病研究和精准医疗中的潜在应用价值。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13941", "html_url": "https://arxiv.org/abs/2509.13941", "title": "自动问题解决中的实证研究", "title_en": "An Empirical Study on Failures in Automated Issue Solving", "authors": "Simiao Liu,Fang Liu,Liehao Li,Xin Tan,Yinghao Zhu,Xiaoli Lian,Li Zhang", "background": "自动问题解决旨在自主识别并修复整个代码库中的缺陷代码片段。SWE-Bench 已成为该领域评估进展的最广泛采用基准。尽管基于大语言模型的代理工具显示出巨大潜力，但它们仍无法解决大量任务。当前的评估主要报告综合的问题解决率，这模糊了成功和失败的真正原因，使得诊断模型弱点或指导精确改进变得困难。为了填补这一缺口，论文首先分析了三种领先的工具（包括基于流水线和代理架构）在不同任务特性下的 SWE-Bench-Verified 自动问题解决任务中的性能和效率。此外，为了从高层性能指标转向根本原因分析，进行了对150个失败实例的系统手动分析，发现两种架构范式的失败模式有明显区别，尤其是代理架构的失败多源于错误推理和认知阻碍。", "innovation": "提出了一个协作专家-执行者框架。引入了一个监督性的专家代理，负责为一个主要的操作执行代理提供战略性监督和纠正措施。这种结构旨在纠正错误的推理并打破那些经常导致失败的认知阻碍。实验表明，该框架为领先的单个代理解决了22.2%之前无法解决的问题。这些发现为构建更具鲁棒性的代理通过诊断评估和合作设计铺平了道路。", "conclusion": "研究发现了自动问题解决代理中的失败模式特性和原因，并提出了一种新的协作专家-执行者架构以改进代理性能。实验结果表明该框架的有效性，为未来的系统设计提供了新的方向。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14165", "html_url": "https://arxiv.org/abs/2509.14165", "title": "高分辨率下STEP中令牌的行为理解", "title_en": "Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions", "authors": "Michal Szczepanski,Martyna Poreba,Karim Haroun", "background": "视觉变换器(ViTs)在语义分割任务上达到了最先进的性能，但是它们面临着高计算和内存成本的问题。为了应对这一挑战，本文提出了一种名为STEP（SuperToken and Early-Pruning）的混合令牌缩减框架，该框架结合了动态补丁合并和令牌修剪，旨在提高效率同时不必显著牺牲准确性。", "innovation": "STEP的核心是dCTS（dynamically-controlled Token Scheme），一种轻量级的基于CNN的策略网络，它能够灵活地将令牌合并成超级补丁。编码块中还集成了早期退出机制，用于移除高置信度的超级令牌，从而降低计算负担。在高分辨率语义分割基准上评估了该方法，结果显示，仅应用dCTS时，令牌数量可以减少到标准16×16像素补丁方案的2.5倍，计算成本降低了2.6倍，并且使用ViT-Large作为主干时，吞吐量提高了3.4倍。完全应用STEP框架进一步提高了效率，计算复杂度减少了4倍，推理速度提升了1.7倍，最多会损失2.0%的准确性。", "conclusion": "在所提出的STEP配置下，最多可以有40%的令牌可以在最终编码层前自信地被预测和停止。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14001", "html_url": "https://arxiv.org/abs/2509.14001", "title": "MOCHA：多模态对象感知跨架构对齐", "title_en": "MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment", "authors": "Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli", "background": "本文介绍了一种知识蒸馏方法MOCHA（多模态对象感知跨架构对齐），将大型视觉-语言教师（如LLaVa）中的区域级多模态语义转移到一个轻量级的仅视觉目标检测学生（如YOLO）上。此方法在保持教师结构不变且无需在推理阶段提供文本输入的情况下，实现了高效的语义迁移。MOCHA采用了与现有方法不同的对象级别对齐机制，通过一个包含双重目标损失的训练方式，在学生和转换器之间建立了联合空间的映射，实现了局部对齐和全局关系一致性的双重指导。在四个个性化检测基准下的少量样本场景中验证了该方法的有效性，结果显示相对于基线模型有显著提升，平均得分提高了10.1分。MOCHA的紧凑架构达到了与更大规模的多模态模型相当的性能，证明了其在实际部署中的适用性。", "innovation": "MOCHA采用对象级别的对齐方式，不需要修改教师模型或在推理阶段提供文本输入，通过联合空间映射和双重目标损失，实现了高效的语义迁移。这种方法区别于传统的密集或全局对齐方法，能够更好地保持目标检测模型的轻量化和高效性。", "conclusion": "MOCHA方法在四个个性化检测基准下表现出显著优越性，取得了与更大规模的多模态模型相当的性能，验证了其在实际应用场景中的有效性和适用性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14061", "html_url": "https://arxiv.org/abs/2509.14061", "title": "使用环境传感器融合进行低功耗边缘计算的蜂巢女王检测", "title_en": "Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing", "authors": "Chiara De Luca,Elisa Donati", "background": "女王蜂对蜜蜂群体的健康和稳定性至关重要，但当前的监控方法依赖于耗时、干扰性且不适合大规模养蜂的手动检查。虽然基于音频的方法显示了前景，但它们通常能耗高、预处理复杂，并且容易受到环境噪音的影响。为了克服这些限制，文章提出了一种基于环境传感器融合的轻量级多模态女王检测系统，具体是基于蜂箱内外的温度、湿度和压力差异。该方法在商用STM32微控制器上使用量化决策树推理，实现实时低功耗边缘计算，保证了准确度。研究结果表明，仅使用环境输入即可实现超过99%的女王检测准确率，音频特征并未带来显著性能提升。这项工作提供了一种可扩展和可持续的非侵入式养蜂场监测解决方案，为利用现成的节能硬件实现自主和精准养蜂奠定了基础。", "innovation": "文章提出了一种基于环境传感器融合的轻量级多模态女王检测系统，其特点是在商用STM32微控制器上使用量化决策树推理，实现实时低功耗边缘计算。该系统利用蜂箱内外的温度、湿度和压力差异，显示出超过99%的女王检测准确率，并且通过去除音频特征预处理降低了能耗和复杂性。", "conclusion": "文章提出了一种基于环境传感器融合的轻量级女王检测系统，该系统能够实现非侵入式、低功耗且准确的女王检测，为自主和精准养蜂提供了可扩展和可持续的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14172", "html_url": "https://arxiv.org/abs/2509.14172", "title": "TGPO: 树引导的偏好优化用于鲁棒的Web代理强化学习", "title_en": "TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning", "authors": "Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao", "background": "近年来，大型语言模型和视觉语言模型的快速进步使大型模型作为Web代理变得至关重要，用于自动化网页交互。然而，使用强化学习训练Web代理面临关键挑战，包括回溯奖励分配错误、标注成本过高以及奖励稀疏性。", "innovation": "本文提出了一种名为Tree-Guided Preference Optimization (TGPO)的离线强化学习框架，该框架采用树结构轨迹表示法，将跨轨迹中语义相同的状态整合，以消除标签冲突。框架包含一个过程奖励模型，该模型通过子目标进度、冗余检测和动作验证自动生成精细的奖励。此外，动态加权机制在训练期间优先考虑高影响的决策点。", "conclusion": "在Online-Mind2Web和自构建的C-WebShop数据集上的实验表明，TGPO在成功率达到更高且冗余步骤更少的情况下，明显优于现有方法。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13702", "html_url": "https://arxiv.org/abs/2509.13702", "title": "DSCC-HS: 一种用于大型语言模型幻觉抑制的动态自我强化框架", "title_en": "DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models", "authors": "Xiao Zheng", "background": "大型语言模型（LLM）的幻觉是一个重要障碍，阻碍了它们可靠的应用。当前方法，例如检索增强生成（RAG），通常是反应性的。研究和解决方案需要更主动的方法来干预自动回归解码过程。", "innovation": "提出了**动态自我强化校准以抑制幻觉（DSCC-HS）**，这是一种新颖且主动的框架，在解码过程中进行干预。灵感来源于双重认知过程理论，DSCC-HS 使用一个经过对抗训练的紧凑型代理模型，分别作为事实对齐代理（FAP）和幻觉检测代理（HDP）。在推理过程中，这些代理通过在每一解码步骤中注入一个实时导向向量来动态引导大型目标模型，该向量是FAP和HDP对数的差值。该插拔即用的方法无需对目标模型进行任何修改。", "conclusion": "实验结果在TruthfulQA和BioGEN上表明，DSCC-HS 达到了最先进的性能。在TruthfulQA上，它实现了99.2%的事实一致性率（FCR）。在长格式的BioGEN基准上，它获得了最高的FActScore，为46.50。这些结果显示DSCC-HS 是增强大型语言模型事实性的原则性强且有效的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14049", "html_url": "https://arxiv.org/abs/2509.14049", "title": "基于资源受限设备的卷积神经网络音频标签模型的综合评估", "title_en": "Comprehensive Evaluation of CNN-Based Audio Tagging Models on Resource-Constrained Devices", "authors": "Jordi Grau-Haro,Ruben Ribes-Serrano,Javier Naranjo-Alcazar,Marta Garcia-Ballesteros,Pedro Zuccarello", "background": "卷积神经网络（CNNs）在音频标签任务中表现出色，但在如树莓派这类资源受限的设备上部署这些模型时，面临计算效率和热管理方面的挑战。本文对PANNs框架下的多种1D和2D CNN架构，ConvNeXt基于的音频分类模型以及MobileNetV3架构进行了全面评估，同时对比了PANNs衍生出的CNN9和CNN13两个模型。为了提升部署效率并实现广泛的硬件平台兼容性，所有模型均转换为ONNX格式。通过连续24小时的推理会话来评估模型稳定性，以往的研究通常只关注单一模型，而本文的研究范围则更为广泛。实验结果显示，通过选择和优化合适的模型，可以在长时间内维持一致的推理延迟，并有效地管理热行为。这些发现对于在实际的边缘计算场景中部署音频标签模型具有重要的指导意义。", "innovation": "本文通过综合评估多种CNN架构在资源受限设备上的应用，填补了现有研究的空白，且首次采用了连续24小时的推理会话来评估模型的性能稳定性。此外，所有模型统一转换为ONNX格式以增强部署效率和硬件平台兼容性，这是本研究的一项创新点。", "conclusion": "研究结果表明，经过适当选择和优化的模型可以在长时间内保持一致的推理延迟，并有效管理热行为。这些结论为在实际的边计算场景中部署音频标签模型提供了宝贵的经验和见解。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14180", "html_url": "https://arxiv.org/abs/2509.14180", "title": "行为基础的推理链合成：个人金融LLMs的数据生成框架", "title_en": "Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs", "authors": "Akhil Theerthala", "background": "个性化的金融建议需要考虑到用户的目标、约束、风险承受能力和所在地区。过往的LLM工作主要集中在支持系统上，面向投资者和金融顾问。同时，多个研究通过代理管道处理诸如预算、债务管理、退休和遗嘱规划等广泛个人金融任务，但这些管道的维护成本高，仅实现预期财务收益的大约25%。因此，本文介绍了一种新颖且可复制的框架，该框架结合相关金融背景并与行为金融研究结合，以构建端到端顾问的监督数据。", "innovation": "介绍了一种新颖且可复制的框架（数据生成框架），将相关金融背景与行为金融研究结合，构建对于端到端顾问的监督数据。该框架用于创建一个包含19000个样本的推理数据集，并对Qwen-3-8B模型进行了全面微调。通过保留测试集和盲目的LLM委员会研究，研究成果表明通过精心的数据筛选和行为整合，8B模型在事实准确性、流畅性和个性化指标上与更大规模的竞争模型（14-32B参数）相当，但成本降低了80%。", "conclusion": "研究表明，通过精心的数据筛选和行为整合，8B模型在事实准确性、流畅性和个性化指标上与更大规模的竞争模型相当，且成本显著低于后者。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14057", "html_url": "https://arxiv.org/abs/2509.14057", "title": "机器在某些情况下比人类更高效，而在其他情况下则不然；反之亦然", "title_en": "Machines are more productive than humans until they aren't, and vice versa", "authors": "Riccardo Zanardelli", "background": "随着人工技能的提升，组织面临越来越复杂的技能政策决策问题，特别是如何通过经济原则实现最优化决策。本研究通过建立基于蒙特卡洛模拟并结合现实数据的关键性框架，探讨了在不同复杂性任务中，人类与机器技能单独或联合应用的经济影响。", "innovation": "开发了一种基于蒙特卡洛模拟的教育现实性的‘在硅’框架，来分析人类和机器技能在不同复杂度任务中的经济效应。研究发现，自动化对于低到中等泛化难度的任务最具经济效益，但在复杂场景下，人类技能的经济效用更显著。此外，研究强调了人机技能结合的有效性关键在于实现真正的增援，否则会因加入二元技能结构的成本而降低经济价值。", "conclusion": "决策者不能简单地将人类和机器技能分配给任务，人机技能政策不是万能解决方案，也不是低风险妥协，而是一个能够提升竞争优势的关键机会，需要组织强有力的支持以实现真正的增援。此外，尽管提高机器技能的成本效益会有所帮助，但这并不意味着可以忽视实现增援的必要性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14093", "html_url": "https://arxiv.org/abs/2509.14093", "title": "自适应链式推理压缩：一种自我优化框架", "title_en": "Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework", "authors": "Kerui Huang,Shuhan Liu,Xing Hu,Tongtong Xu,Lingfeng Bao,Xin Xia", "background": "链式推理（CoT）提升了大规模语言模型（LLMs）在算术、逻辑和常识任务中的准确性和鲁棒性，但这也带来了高计算成本：较长的输出增加了延迟、内存使用和KV缓存需求。在软件工程任务中，这种需求尤其重要，因为需要简洁和确定的输出。因此，研究这些权衡是必要的。", "innovation": "本文提出了一种自适应框架SEER（Self-Enhancing Efficient Reasoning），该框架结合了Best-of-N采样和任务感知自适应过滤，动态调整阈值以减少冗余和计算开销。SEER能够在软件工程任务和数学任务中压缩CoT，同时保持准确性，并减少无限循环。", "conclusion": "实验结果表明，SEER平均压缩了CoT 42.1%，提高了准确性，减少了截断现象，并消除了大多数无限循环，证明了SEER在资源受限条件下使CoT增强的LLMs更高效和鲁棒的实用性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14216", "html_url": "https://arxiv.org/abs/2509.14216", "title": "通用的Banach-Bregman框架：统一随机镜像下降、学习和大语言模型训练", "title_en": "A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training", "authors": "Johnny R. Zhang(Independent Researcher),Xiaomei Mi(University of Manchester),Gaoyuan Du(Amazon),Qianyi Sun(Microsoft),Shiqi Wang(Meta),Jiaxuan Li(Amazon),Wenhua Zhou(Independent Researcher)", "background": "现代人工智能，包括机器学习、深度学习、强化学习和大语言模型训练，均依赖于随机优化的强大性。现有的理论主要局限于希尔伯特空间，依赖于内积框架和正交性，这种范式无法捕捉非欧几里得设置，例如单纯形上的镜像下降、伯格曼邻近法用于稀疏学习、信息几何中的自然梯度下降或Kullback-Leibler正则化语言模型。相比之下，本文引入了通用Banach-Bregman框架，采用了更广泛的Banach空间而非基于欧几里得的希尔伯特空间方法。", "innovation": "本文引入了一个开创性的Banach-Bregman框架，涵盖了随机迭代，并建立Bregman几何作为下一代优化的基础。具体内容包括：（i）提供了一个统一的模板，通过Bregman投影和Bregman-Fejer单调性，涵盖了随机逼近、镜像下降、自然梯度、自适应方法和镜像近似；（ii）在非希尔伯特设置中确定了超加速效果（λ > 2），允许灵活的几何形状；（iii）提供了从几乎必然有界性到几何收敛速率的收敛定理，已经在合成和真实任务上进行了验证。", "conclusion": "在机器学习（UCI基准）、深度学习（例如，Transformer训练）、强化学习（行为评价）和大语言模型（WikiText-2与distilGPT-2）中的实验结果表明，相比于经典基准，该框架可以提高高达20%的收敛速度，降低方差并增强准确性。这些结果将Banach-Bregman几何确立为在一个核心人工智能范式下统一优化理论和实践的基石。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.19238", "html_url": "https://arxiv.org/abs/2410.19238", "title": "设计具有人格特征的AI代理：一种心理统计方法", "title_en": "Designing AI-Agents with Personalities: A Psychometric Approach", "authors": "Muhua Huang,Xijuan Zhang,Christopher Soto,James Evans", "background": "本文介绍了一种使用大五人格框架为AI代理分配可量化和心理测量验证人格的方法。研究了该方法的可行性和限制，包括衡量AI代理在Mini-标记测试中与人类响应的匹配程度，以及人格输入和输出判断的相关性。研究结果表明，虽然微调会将响应更多地导向道德判断，但AI代理在输入大五特质与输出响应之间的相关性与人类参与者类似。", "innovation": "该研究提出了使用大五人格框架为AI代理分配可量化且心理测量验证的人格特征的方法，并探讨了其在衡量AI代理与人类响应匹配程度中的应用，特别是在新的大型语言模型和其他AI代理之间。", "conclusion": "研究结果表明，AI代理在输入大五特质与输出响应的相关性方面与人类参与者类似，并且可用于初步研究。然而，细粒度响应模式中的差异表明，AI代理目前不能完全替代人类参与者在精确或高风险项目中的作用。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13668", "html_url": "https://arxiv.org/abs/2505.13668", "title": "MAFA: 多代理框架用于标注", "title_en": "MAFA: A multi-agent framework for annotation", "authors": "Mahmood Hegazy,Aaron Rodrigues,Azzam Naeem", "background": "现代消费者银行业务应用程序需要准确且高效地响应用户的查询来检索信息。将用户的询问映射到最相关的常见问题（FAQ）是这些系统的一个关键组成部分。传统的方法通常依赖单一的模型或技术，但这些方法可能无法捕捉到多样化的用户询问的细微差别。因此，需要一个可以处理这些需求的多代理框架。", "innovation": "本文介绍了结合了多种专业代理和一种评判代理（用于重新排序候选项以生成最佳结果）的多代理标注框架。这些代理使用了启发式推理方法，由关注推理查询（ARQ）启发，采用目标特定的JSON查询指导它们进行系统推理。框架采用几近示范的方法，每个代理收到不同的几近示范以增强团队的多样性和查询空间的覆盖。这种方法在真实银行数据集和公开基准数据集（LCQMC和FiQA）上的评估显示，与单一代理方法相比，多个指标有多达14%的Top-1准确性提升，18%的Top-5准确性提升和12%的Mean Reciprocal Rank提升。特别是在处理模糊查询方面表现出色，并且不同领域和语言中具有很强的概括能力。", "conclusion": "此多代理框架特别适用于生产银行业务环境中的部署，展示了在不同领域和语言中的强大概括能力。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14181", "html_url": "https://arxiv.org/abs/2509.14181", "title": "基于分布感知对齐的时间序列预测：将过去与未来相连", "title_en": "Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting", "authors": "Yifan Hu,Jie Yang,Tian Zhou,Peiyuan Liu,Yujin Tang,Rong Jin,Liang Sun", "background": "时间序列预测中已经探索了诸如对比学习等表示学习技术，其在计算机视觉和自然语言处理中的成功得到了体现。然而，最近的先进预测者很少采用这些表示方法，因为它们在性能上几乎没有优势。本研究重新审视了这一观点，提出明确的表示对齐可以提供重要的信息，以弥合输入历史和未来目标之间的分布差距。为此，我们引入了TimeAlign框架，它通过一个简单的重建任务学习辅助特征，并将这些特征反馈给任何基础预测器。广泛的实验结果验证了其优越的性能。\n", "innovation": "TimeAlign是一个轻量级且可插拔的框架，通过简单的重建任务学习辅助特征，并将其反馈给任何基础预测器。实验结果表明，这种对齐的主要增益来自于历史输入与未来输出之间频率失配的纠正。我们还提供了TimeAlign有效性的理论证明，即它增加了学习表示和预测目标之间的互信息。该框架对任何架构都是通用的并且增加了可忽略的开销，因此可以作为现代深度学习时间序列预测系统的一般对齐模块。\n", "conclusion": "广泛的实验验证了TimeAlign框架的优越性能，并且通过纠正历史输入与未来输出之间的频率失配，证明了TimeAlign的有效性。此外，该研究还提供了TimeAlign增加学习表示与预测目标之间互信息的理论依据。作为任何架构通用且开销可忽略的模块，TimeAlign可以用于现代深度学习时间序列预测系统中。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14199", "html_url": "https://arxiv.org/abs/2509.14199", "title": "使用门控残差标记化实现密集视频理解", "title_en": "Dense Video Understanding with Gated Residual Tokenization", "authors": "Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu", "background": "高时间分辨率对于捕捉视频理解中的细微差异至关重要。然而，当前的视频大型语言模型（VLLMs）和基准测试主要依赖于低帧率采样，例如均匀采样或关键帧选择，从而丢弃了密集的时间信息。这虽然避免了每帧都进行标记化带来的高成本和重复计算，但也限制了对于快速变化内容的任务，如讲座理解，这种情况下几乎每一帧都包含重要信息，需要精确的时间对齐。现有基准测试也有限制，它们的问题-答案对主要关注粗粒度的内容变化。因此，需要一种新的方法来解决这一问题，引入密集视频理解（DVU），使其能够在减少标记化时间和标记化开销的同时提高帧率。", "innovation": "本文提出了一种新的方法——密集视频理解（DVU），并通过Gated Residual Tokenization（GRT）来实现高帧率视频的理解。GRT包含两个阶段：1）运动补偿区间取样使用像素级别的运动估计来标记静止区域，在标记化过程中省略，从而减少标记化时间和计算量；2）语义场景内标记化合并将场景内的静止区域的标记化合并，进一步减少冗余同时保留动态语义。通过DIVE基准测试，该方法在FPS增加时性能呈现正向增长，突显了密集时间信息的重要性，并证明了GRT方法可以实现高效且可扩展的高帧率视频理解。", "conclusion": "实验结果表明，GRT方法优于现有的大型视频语言模型基线，并随着帧率的增加表现出积极的可扩展性。这些结果强调了密集时间信息的重要性，并展示了GRT方法能够实现高效、可扩展的高帧率视频理解。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14233", "html_url": "https://arxiv.org/abs/2509.14233", "title": "Apertus：为全球语言环境民主化开放和合规的大型语言模型", "title_en": "Apertus: Democratizing Open and Compliant LLMs for Global Language Environments", "authors": "Alejandro Hernández-Cano,Alexander Hägele,Allen Hao Huang,Angelika Romanou,Antoni-Joan Solergibert,Barna Pasztor,Bettina Messmer,Dhia Garbaya,Eduard Frank Ďurech,Ido Hakimi,Juan García Giraldo,Mete Ismayilzada,Negar Foroutan,Skander Moalla,Tiancheng Chen,Vinko Sabolčec,Yixuan Xu,Michael Aerni,Badr AlKhamissi,Ines Altemir Marinas,Mohammad Hossein Amani,Matin Ansaripour,Ilia Badanin,Harold Benoit,Emanuela Boros,Nicholas Browning,Fabian Bösch,Maximilian Böther,Niklas Canova,Camille Challier,Clement Charmillot,Jonathan Coles,Jan Deriu,Arnout Devos,Lukas Drescher,Daniil Dzenhaliou,Maud Ehrmann,Dongyang Fan,Simin Fan,Silin Gao,Miguel Gila,María Grandury,Diba Hashemi,Alexander Hoyle,Jiaming Jiang,Mark Klein,Andrei Kucharavy,Anastasiia Kucherenko,Frederike Lübeck,Roman Machacek,Theofilos Manitaras,Andreas Marfurt,Kyle Matoba,Simon Matrenok,Henrique Mendoncça,Fawzi Roberto Mohamed,Syrielle Montariol,Luca Mouchel,Sven Najem-Meyer,Jingwei Ni,Gennaro Oliva,Matteo Pagliardini,Elia Palme,Andrei Panferov,Léo Paoletti,Marco Passerini,Ivan Pavlov,Auguste Poiroux,Kaustubh Ponkshe,Nathan Ranchin,Javi Rando,Mathieu Sauser,Jakhongir Saydaliev,Muhammad Ali Sayfiddinov,Marian Schneider,Stefano Schuppli,Marco Scialanga,Andrei Semenov,Kumar Shridhar,Raghav Singhal,Anna Sotnikova,Alexander Sternfeld,Ayush Kumar Tarun,Paul Teiletche,Jannis Vamvas,Xiaozhe Yao,Hao Zhao Alexander Ilic,Ana Klimovic,Andreas Krause,Caglar Gulcehre,David Rosenthal,Elliott Ash,Florian Tramèr,Joost VandeVondele,Livio Veraldi,Martin Rajman,Thomas Schulthess,Torsten Hoefler,Antoine Bosselut,Martin Jaggi,Imanol Schlag", "background": "当前开放模型生态系统存在两个系统性的不足：数据合规性和多语言表示。许多先前的模型在发布权重时，缺乏可重复的数据管道，或者未能尊重内容所有者的权利。许多现存模型存在问题，如记忆数据或者侵犯隐私等。因此，需要一种可以充分开放、确保数据合规和提高多语言覆盖能力的解决方案。", "innovation": "Apertus 提供了一个全面开放的大型语言模型套件，专门设计来解决当前开放模型生态系统中的数据合规性和多语言表示不足。Apertus 采用 Goldfish 目标优化预训练过程，限制了对数据的直白回忆，同时也保留了下游任务的性能。模型特别注重非英语内容的预训练，覆盖了超过 1800 种语言的 15T 字符，释放了可和科学工具，确保了透明性审查和扩展的可能性。Apertus 在多项跨语言基准测试中达到了最先进的成果，与重量开放模型相比表现相近或更优。", "conclusion": "Apertus 模型不仅在预训练过程中采用了全面的开放策略，而且还在数据准备脚本、检查点、评估集、以及训练代码等方面释放了所有科学工具，做到了全方位开放，并且其结果达到了最先进的技术水平。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18325", "html_url": "https://arxiv.org/abs/2505.18325", "title": "从安全决策边界揭开视角理解并缓解LLMs中的过度拒绝", "title_en": "Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary", "authors": "Licheng Pan,Yongqi Tong,Xin Zhang,Xiaolu Zhang,Jun Zhou,Zhixuan Chu", "background": "大语言模型（LLMs）在各种任务中展现了卓越的能力，但它们往往拒绝回答合理的查询，这一现象被称为过度拒绝。过度拒绝通常源于过度保守的安全对齐，导致模型将许多合理的内容视为潜在风险。为了系统地理解这一问题，该研究探查和利用模型的安全决策边界来分析和缓解过度拒绝。研究发现，过度拒绝与边界区域的错误对齐密切相关，模型在区分良性与有害内容的微小差异时存在困难。", "innovation": "研究提出了一种自动化的框架（RASS），用于策略性地生成接近安全边界的过度拒绝提示，通过在表示空间中利用引导向量，RASS能够高效地识别和筛选边界对齐的提示，从而实现对过度拒绝更有效的缓解。这一方法不仅提供更精确和可解释的模型安全决策视图，还能够无缝扩展到多语言场景。研究探索了多种LLMs的安全决策边界，并构建了MORBench评估集，以便在多种语言中进行稳健的模型安全性和有用性评估。", "conclusion": "该研究不仅提供了一种更精确和可解释的方法来理解模型的安全决策，还能有效缓解LLMs的过度拒绝问题，适用于多语言环境中的模型安全性评估，并公开了代码和数据集。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22149", "html_url": "https://arxiv.org/abs/2507.22149", "title": "在欺骗性指令下，真相表示如何翻转？", "title_en": "When Truthful Representations Flip Under Deceptive Instructions?", "authors": "Xianxuan Long,Yao Fu,Runchao Li,Mu Sheng,Haotian Yu,Xiaotian Han,Pan Li", "background": "大型语言模型（LLMs）倾向于遵循恶意构造的指令生成欺骗性响应，这带来了安全挑战。当前对在欺骗性指令与真实/中立指令下表示如何翻转的理解依然不足，尤其是在输出分析之外的层面。本文旨在填补这一空白。", "innovation": "通过研究LLaMA-3.1-8B-Instruct和Gemma-2-9B-Instruct模型在事实验证任务中的内部表征变化，研究发现基于内部表征可以预测指令下的真/假输出。此外，使用稀疏自编码器（SAEs）展示了欺骗性指令相比真实/中立指令导致了显著的表征变化，并且主要集中于早期到中期的层，即使在复杂的数据集上也能被检测到。研究还识别出特定的SAE特征对欺骗性指令反应敏感，并使用针对性的可视化方法验证了不同的真实/欺骗性表示子空间。", "conclusion": "分析指出了层次和特征层面与指令欺骗性相关的联系，为LLM检测和控制提供了见解。研究发现了欺骗性的特征层面和层次签名，为检测和缓解LLM中的指令欺骗提供了新的洞察。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14223", "html_url": "https://arxiv.org/abs/2509.14223", "title": "语言模型的激活线性编码训练顺序的近期性", "title_en": "Language models' activations linearly encode training-order recency", "authors": "Dmitrii Krasheninnikov,Richard E. Turner,David Krueger", "background": "本文基于语言模型在其训练过程中是如何编码信息的时间顺序的现象。研究通过将Llama-3.2-1B模型依次微调在六个不相连但相似的数据集中得到验证。研究发现，测试样本的平均激活值能够体现训练数据集的顺序，并且这些中心点在二维子空间内按训练顺序排列成一条直线。进一步的研究表明，可以使用线性探针在90%左右的准确率上区分早期和晚期的实体，甚至包括那些没有被探针训练过的实体。此外，通过微调模型也可以识别出一个未见实体在哪一部分训练数据集中出现，准确率约80%。这些发现挑战了单纯依靠激活值大小、损失函数或模型置信度来区分信息时间顺序的传统观点，提出了模型能够基于信息获取时间来区分信息的新方向。", "innovation": "本文通过具体实验展示了语言模型能够通过其激活值线性编码信息的训练顺序，并且这种线性关系能够用于识别新的、未见过的实体训练阶段。此创新对理解和管理模型知识变化的能力具有重要意义，能够帮助模型更好地处理冲突数据并对知识更新做出响应。", "conclusion": "本文的研究结果表明语言模型在内部能够区分信息基于其获得的时间，并提出了模型有能力以此方式管理知识的潜在路径。这一发现对于未来研究如何优化和利用语言模型的训练方式和知识管理策略有所启示。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19505", "html_url": "https://arxiv.org/abs/2508.19505", "title": "被当场抓住：检测欺骗的一种机制方法", "title_en": "Caught in the Act: a mechanistic approach to detecting deception", "authors": "Gerard Boxo,Ryan Socha,Daniel Yoo,Shivam Raval", "background": "人工智能系统中的复杂检测设备可能发出与汽车中的‘检查发动机’灯类似的信号，表明AI系统与人类价值观的不一致。一种此类不一致的迹象是生成的回应具有欺骗性。未来AI检测方法可能能够检测到LLM生成欺骗性回应的情况，特别是在回答看似合理但错误的问题时。本文展示了对LLM内部激活进行的线性探针可以极高的准确性检测欺骗性回应。", "innovation": "研究开发了一种机制方法，利用线性探针在LLM内部激活上进行检测欺骗性回应。这种探测方法在从1.5B到14B参数的不同规模的llama和Qwen模型，包括其finetuned版本DeepSeek-r1上达到了超过90%的准确率。特别是在较大的模型上（7B以上），线性探针的准确率能超过70-80%，推理版本超过了90%。此外，通过迭代的零空间投影方法，研究发现了许多编码欺骗的线性方向，并且数量随着模型规模的增加而增加。", "conclusion": "研究结果表明，通过分析LLM的内部激活，可以非常准确地检测出欺骗性回应。不同规模模型的线性探针表现出了逐层不同的准确性模式。较大的模型在中层的探测准确性达到峰值。这种方法为检测和理解LLM中的欺骗行为提供了一种新的机制。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.08364", "html_url": "https://arxiv.org/abs/2505.08364", "title": "人类学习方式：通过适应难度课程学习和专家指导的自我重述增强大语言模型推理能力", "title_en": "Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation", "authors": "Enci Zhang,Xingang Yan,Wei Lin,Tianxiang Zhang,Qianchun Lu", "background": "尽管在数学推理等领域取得了显著进展，但大型语言模型在解决复杂问题时仍面临重大挑战。人类学习中的关键策略为改进大语言模型的能力提供了灵感。", "innovation": "提出了两种新的策略：1. 自适应难度课程学习（ADCL），通过定期重新评估数据批次中的问题难度，来解决模型感知问题难度动态变化的问题，从而保持与模型能力演进的同步；2. 专家指导的自我重述（EGSR），这是一种新的强化学习策略，通过引导模型在其自身概念框架内重述专家解决方案，而非直接模仿，以促进更深入的理解和知识吸收。这些策略共同改善了大语言模型在数学推理基准测试中的性能。", "conclusion": "在使用Qwen2.5-7B作为基础模型的广泛的数学推理基准测试中，这些人类启发的策略显示出显著提升。结合应用的结果表明，与标准Zero-RL基线相比，改进的策略在AIME24基准上提高了10%的表现，在AIME25上则提高了16.6%。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19676", "html_url": "https://arxiv.org/abs/2505.19676", "title": "前沿大语言模型推理停滞：对最具能力模型的探究", "title_en": "Large Language Models' Reasoning Stalls: An Investigation into the Capabilities of Frontier Models", "authors": "Lachlan McGinness,Peter Baumgartner", "background": "研究探讨了使用经验方法来评估大型语言模型（LLMs）使用自动定理证明（ATP）推理策略的能力。研究评估了2023年12月和2024年8月的最先进模型在PRONTOQA蒸汽碾压推理问题上的表现。通过开发评估LLM响应准确性和正确答案相关性的方法来实现这一目标。结果显示，在九个月的时间内，改善LLM推理能力的进展已经停滞。通过追踪完成的令牌，研究发现几乎所有的推理能力提高都可以归因于隐藏系统提示或模型训练以自动使用通用的思考链提示策略。在尝试的各种ATP推理策略中，当前最前沿的LLM最适合遵循自底向上的推理策略（也称为正向查表策略）。研究还发现，LLM响应中包含正确推理与得出正确结论之间存在低正相关性。", "innovation": "该研究开发了评估LLM响应准确性和正确答案相关性的方法，并通过追踪完成的令牌来追踪推理能力的改进。研究发现，大部分改进源于隐藏系统提示或模型训练以自动使用通用思考链提示策略，而当前最前沿的LLM最适合遵循自底向上推理策略。此外，研究揭示了LLM响应中包含正确推理与得出正确结论之间的低正相关性。", "conclusion": "在九个月的时间内，改善LLM推理能力的进展已经停滞。大部分推理能力提高归因于隐藏系统提示或自动使用通用思考链提示策略的模型训练，而当前最前沿的LLM最适合采用自底向上的推理策略。然而，LLM响应中正确推理与得出正确结论之间仍存在低正相关性，表明仍有改进空间。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.17514", "html_url": "https://arxiv.org/abs/2507.17514", "title": "TAI扫描工具：一种基于RAG的输入简洁的值得信赖的人工智能自我评估工具", "title_en": "TAI Scan Tool: A RAG-Based Tool With Minimalistic Input for Trustworthy AI Self-Assessment", "authors": "Athanasios Davvetas,Xenia Ziouvelou,Ypatia Dami,Alexios Kaponis,Konstantina Giouvanopoulou,Michael Papademas", "background": "随着人工智能技术的发展，如何确保AI系统的安全性和合规性成为了亟待解决的问题。尤其是欧盟的AI法案（AI Act）提出了对高风险AI系统的严格要求，这对开发者和使用者提出了更高的合规要求。然而，现有的评估工具通常需要大量的输入信息，且缺乏能够同时提供风险评估与合规指导的功能，这使得合规工作复杂且耗时。因此，开发一个基于RAG（检索增强生成）的简化输入的TAI自我评估工具成为了必要的研究方向。", "innovation": "本文提出了一种名为TAI Scan Tool的RAG基础的自我评估工具，具有最少的输入要求，支持根据AI法案进行法律评估，并重点促进遵守AI法案的要求。该工具采用了两步法，包括预筛选和评估阶段。系统评估的输出包括AI系统的风险等级，并提供相关文章以帮助合规并通知使用者其义务。研究表明，该工具可以通过案例情景验证表现出色，准确预测风险等级，并跨三个不同的语义组检索相关文章。工具的推理过程依赖于与高风险设置的比较，这种行为与在AI法案中频繁呈现的高风险系统部署密切相关。", "conclusion": "通过使用案例场景进行质性评估，结果显示TAI Scan Tool能够在不牺牲准确性和高效性的前提下，提供高质量的合规支持。这项研究还表明，将RAG技术与法律评估相结合，能够有效简化系统评估过程，提高AI系统合规性评估的效率。未来的研究可以进一步优化该工具的技术细节，以更好地支持多样化的AI应用场景。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.10092", "html_url": "https://arxiv.org/abs/2309.10092", "title": "使用大型语言模型的符合性时序逻辑规划", "title_en": "Conformal Temporal Logic Planning using Large Language Models", "authors": "Jun Wang,Jiaming Tong,Kaiyuan Tan,Yevgeniy Vorobeychik,Yiannis Kantaros", "background": "本文讨论了移动机器人计划问题。具体而言，研究了需要以时间顺序和逻辑顺序完成多个自然语言（NL）表达的高阶子任务的使命。为了正式定义这些子任务，本文将其视为线性时序逻辑（LTL）公式中的原子谓词。现有的LTL规划器无法直接解决这些问题，因为这些原子谓词具有NL特性。因此，无法直接利用现有的LTL规划器生成符合性规划。", "innovation": "本文提出了一种名为HERACLEs的分层神经符号规划器，该规划器结合了现有的符号规划器、预训练的大语言模型（LLMs）以及形式化的接口——构形预测，以管理来自LLMs的不确定性。HERACLEs能够根据用户需求实现使命成功概率，且在对比实验中表现优于依赖自然语言定义任务的LLM基规划器，同时提高了用户友好性。", "conclusion": "本文证明了HERACLEs能够实现用户定义的使命成功率，并通过对比实验证明了HERACLEs在实现使命成功率方面比单纯使用自然语言定义任务的LLM基规划器更优。此外，该方法还增强了对用户的友好性，与传统的符号方法相比更具优势。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.08380", "html_url": "https://arxiv.org/abs/2509.08380", "title": "Co-Investigator AI：智能可靠的合规可疑活动报告生成", "title_en": "Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives", "authors": "Prathamesh Vasudeo Naik,Naresh Kumar Dintakurthi,Zhanghao Hu,Yue Wang,Robby Qiu", "background": "在反洗钱（AML）工作流程中，生成监管合规的可疑活动报告（SAR）成本高昂且不具有可扩展性。尽管大型语言模型（LLMs）在灵活性方面表现出色，但它们也面临事实失实、犯罪类型匹配不足和解释性差等挑战，这些在合规至关重要的领域是不可接受的风险。因此，迫切需要一种新的方法来克服这些限制，以提高生成SAR的工作效率和准确性。", "innovation": "本文介绍了一种名为Co-Investigator AI的自主代理框架，该框架通过优化去生成快速且准确的可疑活动报告，比传统方法更为高效。Co-Investigator AI借鉴了最近在自主代理架构方面取得的进展，整合了专门针对规划、犯罪类型检测、外部情报收集和合规验证的代理。系统具备动态内存管理、AI隐私保护层以及利用代理充当法官的实时验证代理，以实现持续的叙述质量保证。与此同时，人类调查员仍保留干预权，使得AI和领域专业知识结合的协作流程更加高效。该研究展示出Co-Investigator AI在复杂金融犯罪场景下的灵活性，强调了其能够简化SAR撰写，确保叙述符合监管预期并对合规团队释放更高层次分析工作的能力。", "conclusion": "这种方法代表了合规报告新时代的开始，将AI代理的变革性效益引入监管流程的核心，铺就了可扩展、可靠和透明的SAR生成道路。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.16013", "html_url": "https://arxiv.org/abs/2406.16013", "title": "数据库增强查询表示的信息检索", "title_en": "Database-Augmented Query Representation for Information Retrieval", "authors": "Soyeong Jeong,Jinheon Baek,Sukmin Cho,Sung Ju Hwang,Jong C. Park", "background": "信息检索模型在搜索与查询相关的文档方面取得了多项成功，被应用于各种任务。然而，用户查询往往很短，这给检索器带来了挑战，使其难以准确检索到相关文档。为了解决这个问题，先前的研究提出了通过添加一些与查询相关的额外特征（用户相关）来扩展查询的方法。但是，这些方法可能无法有效地增强查询，并且有大量其他信息可以在关系数据库中用于增强查询。", "innovation": "本文提出了一种名为Database-Augmented Query Representation（DAQu）的新检索框架。该框架通过在多个表中使用各种与查询相关的元数据来增强原始查询。同时，由于元数据中的特征数量可能非常大，且没有顺序关系，论文使用基于图的集编码策略进行编码，该策略考虑了数据库中的特征层次结构，而无需考虑顺序。", "conclusion": "通过在多种检索场景下验证DAQu，结果显示它在总体检索性能上显著优于相关基线。代码可在提供的链接中获得。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.13541", "html_url": "https://arxiv.org/abs/2405.13541", "title": "Annotation-Efficient Language Model Alignment via Diverse and Representative Response Texts", "title_en": "Annotation-Efficient Language Model Alignment via Diverse and Representative Response Texts", "authors": "Yuu Jinnai,Ukyo Honda", "background": "偏好优化是大语言模型优化标准方法之一，以使其与人类偏好对齐。偏好优化的效果取决于偏好数据集的数量、多样性和代表性。然而，在许多应用中收集大量偏好注解十分困难，因此如何在有限的注释预算内创建有效偏好数据集成为一个挑战。", "innovation": "本文提出了Annotation-Efficient Preference Optimization (AEPO)。AEPO 选取一组从可用响应文本中最大化多样性和代表性的子集进行标注，并对其进行偏好标注。这种方法将注释预算集中在更有信息价值的子集响应文本上。实验结果显示，在相同的注释预算下，AEPO 的表现优于基准方法。", "conclusion": "研究评估了使用AEPO进行偏好学习的表现，并证明在相同注释预算下AEPO优于基准方法。代码已开源。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.12643", "html_url": "https://arxiv.org/abs/2509.12643", "title": "利用大型语言模型学习放松: 通过双向共进化解决非线性组合优化问题", "title_en": "Learn to Relax with Large Language Models: Solving Nonlinear Combinatorial Optimization Problems via Bidirectional Coevolution", "authors": "Beidan Liu,Zhengqiu Zhu,Chen Gao,Yong Zhao,Wei Qi,Quanjun Yin", "background": "非线性组合优化问题（NCOPs）由于其非凸性质而导致多模态解空间，这使得高效的优化变得困难。传统约束放松方法依赖于专家驱动的迭代设计过程，缺乏系统性自动化和可扩展适应性。以往基于大型语言模型（LLM）的优化方法具有自主解决问题的潜力，但它们大多作为被动的约束验证工具，而非主动的策略架构者，无法处理这一类问题固有的复杂约束交互。", "innovation": "本文提出了第一个端到端的自动化约束优化（AutoCO）方法。该方法通过学习不断进化的方法策略，利用结构化大型语言模型推理生成约束放松策略，并通过统一的三重表示方案以可执行代码形式动态生成。此外，本文还建立了新颖的双向（全局-局部）共进化机制，该机制结合演化算法进行强烈局部细化和蒙特卡洛树搜索进行系统全局策略空间探索，确保在碎片化的解空间中实现最优的强化和多样化之间的平衡。", "conclusion": "通过在三个具有挑战性的NCOP基准测试上的全面实验，本文验证了AutoCO的一致有效性和相对于基线方法的优越性能。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.19988", "html_url": "https://arxiv.org/abs/2405.19988", "title": "Video-Language Critic: 可转移的语言条件型奖励函数", "title_en": "Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics", "authors": "Minttu Alakuijala,Reginald McLean,Isaac Woungang,Nariman Farsad,Samuel Kaski,Pekka Marttinen,Kai Yuan", "background": "自然语言是人类为机器人指定任务的最直观和便捷的方式。然而，学习将语言与机器人行为对应起来通常需要大量的多样化、语言标注的示范数据，而这些数据在每个目标机器人上收集都极具挑战性。本文旨在将要完成的任务从具体执行方法中分离出来，前者可以受益于大量的外部分析数据，后者则依赖于特定的机器人身体。由此，本文提出了Video-Language Critic（视频-语言评论家），这是一种通过对比学习和时空排序目标在广泛可获得的跨体感数据上进行训练的奖励模型，该模型可以用于评估行为轨迹。", "innovation": "本文提出的方法Video-Language Critic能够利用跨体感数据进行训练，从而在开放的跨体感数据集上获得了比单纯稀疏奖励更高的样本效率，在Meta-World任务中使策略训练提高了2倍效率，尽管存在显著的领域差距。与现有的语言调节奖励模型相比，该模型通过二元分类训练、使用静态图像或利用视频数据中的时空信息，在同领域、但更具挑战性的任务泛化设置中展现了更高的样本效率。", "conclusion": "通过Video-Language Critic，能够有效减少特定机器人行为的样本需求，特别是在存在显著领域差距的任务中学到了更加鲁棒的奖励函数。此外，虽然这种广泛可获取的数据集存在领域差异，但该方法在开放式跨体感数据集合上实现了显著的样本效率提升。该研究为通过非具体机器人数据训练语言调节奖励函数提供了一种新的方法，并展示了其在机器人任务中的适用性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.02358", "html_url": "https://arxiv.org/abs/2405.02358", "title": "用基础模型增强时间序列分析：一项综合调研", "title_en": "Empowering Time Series Analysis with Foundation Models: A Comprehensive Survey", "authors": "Jiexia Ye,Yongzi Yu,Weiqi Zhang,Le Wang,Jia Li,Fugee Tsung", "background": "时间序列数据在众多现实应用中普遍存在，使得时间序列分析变得至关重要。传统的分析方法大多针对特定任务，功能有限，适应性不强。近年来，基础模型在NLP和CV中通过跨任务迁移、零/少样本学习能力及多模态整合能力，彻底改变了这些领域的局面，由此激发了探索基础模型解决时间序列建模挑战的努力。尽管在这一领域初期有部分教程和综述发表，但最近的快速发展促使需要更全面深入的综述综述最新进展，会议旨在通过引入模态意识、挑战导向视角来填补这一空白，揭示不同模态预训练的基础模型在适应时间序列任务时面临的独特挑战，并提供这些模型的分类与解决方案，其优缺点分析。此外，还回顾了实际应用以展示特定领域的进步，并提供开源代码，最终提出了这一快速发展的领域的潜在未来研究方向", "innovation": "提出了基于模态感知和挑战导向的视角，揭示不同模态预训练的基础模型在时间序列任务中面临的独特挑战，并进行了分类。讨论了解决方案的优缺点，同时提供了实际应用中的特定领域进步的回顾及开源代码，并提出了未来研究的方向", "conclusion": "本文对基础模型在时间序列分析中的应用进行了全面调研，提供了最新进展，提供了开源代码，并提出了未来研究的方向"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.08872", "html_url": "https://arxiv.org/abs/2408.08872", "title": "xGen-MM (BLIP-3): 一个开放的大规模跨模态模型系列", "title_en": "xGen-MM (BLIP-3): A Family of Open Large Multimodal Models", "authors": "Le Xue,Manli Shu,Anas Awadalla,Jun Wang,An Yan,Senthil Purushwalkam,Honglu Zhou,Viraj Prabhu,Yutong Dai,Michael S Ryoo,Shrikant Kendre,Jieyu Zhang,Shaoyen Tseng,Gustavo A Lujan-Moreno,Matthew L Olson,Musashi Hinck,David Cobbley,Vasudev Lal,Can Qin,Shu Zhang,Chia-Chih Chen,Ning Yu,Juntao Tan,Tulika Manoj Awalgaonkar,Shelby Heinecke,Huan Wang,Yejin Choi,Ludwig Schmidt,Zeyuan Chen,Silvio Savarese,Juan Carlos Niebles,Caiming Xiong,Ran Xu", "background": "本研究介绍了BLIP-3框架，这是一个开放的平台，用于开发大型跨模态模型（LMMs）。框架包括精心策划的数据集、训练方法、模型架构和一系列LMMs。本研究发布了4B和14B大小的模型，包括预训练的基础模型和指令微调模型。这些模型在各种任务中进行了严格的评估，包括单图像和多图像基准测试。研究表明，该模型在开源LMMs中具有竞争力，并且能够理解交错的图像-文本输入。", "innovation": "BLIP-3框架包含精心策划的数据集、训练方法和模型架构，为开发大型跨模态模型提供了一个全面的平台。该框架发布的模型在开源LMMs中表现出色，并且能够处理交错的图像-文本输入。", "conclusion": "本研究的结果表明，BLIP-3发布的大规模跨模态模型在开源模型中表现出色，并且可以支持研究社区。所有用于训练的代码、模型以及所有用于研究的数据集（包括本研究创建的三大规模数据集和其他预处理数据集）都将开源。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.12374", "html_url": "https://arxiv.org/abs/2407.12374", "title": "通过图信号处理实现统一且自适应的跨域协作过滤", "title_en": "Towards Unified and Adaptive Cross-Domain Collaborative Filtering via Graph Signal Processing", "authors": "Jeongeun Lee,Seongku Kang,Won-Yong Shin,Jeongwhan Choi,Noseong Park,Dongha Lee", "background": "协同过滤(CF)是推荐系统中的基础方法，但面临数据稀疏性和冷启动问题的挑战。跨域推荐(CDR)通过利用密集领域来改善稀疏目标领域的推荐而出现了，但现有的CDR方法存在局限性，比如依赖重叠用户作为域之间的桥梁，并且难以有效应对领域差异性，即不同领域中用户行为和特征的差异。", "innovation": "提出了一种基于图信号处理(GSP)的统一且自适应的CDR框架——CGSP。CGSP支持领域内和领域间的推荐，并通过一个简单的超参数自适应控制源域的影响。该框架通过整合仅由目标和源桥接相似图的信息构造跨域相似图，以捕捉领域内和领域的间关系。此图通过图滤波技术传播和放大局部信号，最终为源域和目标域中的用户分别构建个性化图信号，使其能够作为一个统一体现CDR场景。", "conclusion": "广泛的评估表明，CGSP在各种跨域场景中优于最先进的基准模型，特别是在低重叠场景中，证明了其在实际应用中的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.11824", "html_url": "https://arxiv.org/abs/2408.11824", "title": "AppAgent v2: 高级的灵活移动交互代理", "title_en": "AppAgent v2: Advanced Agent for Flexible Mobile Interactions", "authors": "Yanda Li,Chi Zhang,Wenjia Jiang,Wanqi Yang,Bin Fu,Pei Cheng,Xin Chen,Ling Chen,Yunchao Wei", "background": "随着多模态大型语言模型（MLLM）的发展，以语言模型（LLM）为驱动的视觉代理在软件界面中，尤其是图形用户界面（GUI）方面的影响日益增长。本文介绍了一个针对移动设备的新型基于LLM的多模态代理框架，该框架能够模拟类似人类的交互并操控移动设备。该框架通过两阶段过程（探索和部署）工作，第一阶段记录用户界面元素的功能信息，第二阶段使用RAG技术从知识库中高效检索和更新信息，以实现任务的高效执行。", "innovation": "本文提出的框架能够为各种应用构建灵活的动作空间，增强适应性。探索阶段通过代理驱动或手动探索收集功能性信息，部署阶段利用RAG技术高效地检索和更新这些信息，从而支持代理进行复杂多步骤操作，展示了框架在处理定制任务工作流程方面的适应性和准确性。实验结果表明，该框架在各种基准测试中表现出优越性能，证明了其在真实场景中的有效性。", "conclusion": "本研究表明，该框架在各种表征测试中都表现出色，确认了其在实际应用场景中的有效性。我们很快将发布该代码作为开源项目。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.17916", "html_url": "https://arxiv.org/abs/2404.17916", "title": "FedCoSR：非一致数据中的标签异质性个性化联邦学习的对比可分享表示", "title_en": "FedCoSR: Personalized Federated Learning with Contrastive Shareable Representations for Label Heterogeneity in Non-IID Data", "authors": "Chenghao Huang,Xiaolu Chen,Yanru Zhang,Hao Wang", "background": "异质性由于标签分布偏差和数据稀缺性可能在依赖分布式计算的智能通信应用中引起不准确性和不公平性。为此，本文分析了如何解决数据非独立非同分布（Non-IID）背景下标签异质性带来的问题，特别是在联邦学习环境中数据隐私保护的重要性和挑战。", "innovation": "提出了一种新颖的个性化联邦学习算法FedCoSR，该算法旨在促进客户端之间知识的共享同时保持数据隐私。具体而言，FedCoSR通过对比学习增强局部知识，并引入自适应局部聚合机制来确保数据稀缺的客户端之间的公平性。该算法综合考虑了客户端本地模型浅层参数和典型局部表示作为一种可供服务器分享的信息进行全局聚合。", "conclusion": "仿真结果表明，FedCoSR在具有不同程度标签异质性的数据集上的准确性和公平性方面优于现有的方法。FedCoSR能够有效缓解标签异质性问题，从而提升模型在非独立非同分布数据集上的预测性能和公平性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.09252", "html_url": "https://arxiv.org/abs/2410.09252", "title": "DAVIS: Planning Agent with Knowledge Graph-Powered Inner Monologue", "title_en": "DAVIS: Planning Agent with Knowledge Graph-Powered Inner Monologue", "authors": "Minh Pham Dinh,Munira Syed,Michael G Yankoski,Trenton W. Ford", "background": "在近年来的AI研究中，设计能够协助研究人员在实验室环境中执行任务的一般性科学代理成为了一个重要目标。与日常生活任务相比，科学任务更加精细和复杂，要求智能代理具有更高级别的推理能力、对环境的结构化和时间理解，以及更强的安全性重视。现有方法往往无法解决这些多方面的需求。", "innovation": "DAVIS通过创新性地结合结构化和时间记忆，实现了基于模型的规划，这是对传统检索增强生成（RAG）方法的重要改进。DAVIS还实现了一个类似于人类内心对话的多轮次检索系统，使得代理能够更好地基于过去的经验进行推理。DAVIS在ScienceWorld基准测试中共8个科学科目中显示出了显著优于其他方法的性能，并且其World Model在著名的HotpotQA和MusiqueQA多跳问答数据集上的表现也与之竞争。", "conclusion": "到我们所知，DAVIS是第一个在RAG管道中采用互动检索方法的RAG代理。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.18506", "html_url": "https://arxiv.org/abs/2411.18506", "title": "LLM-ABBA：通过符号近似理解时间序列", "title_en": "LLM-ABBA: Understanding time series via symbolic approximation", "authors": "Erin Carson,Xinye Chen,Cheng Kang", "background": "之前的研究已经展示了大型语言模型（LLMs）在时间序列任务中的成功应用。尽管时间序列可以通过符号表示进行高效处理，但仍面临一个挑战，即如何利用时间序列中的潜在语义信息（通过符号或LLMs现有的令牌），并根据时间序列的隐藏信息调整LLMs的嵌入空间。", "innovation": "本文提出了一种名为LLM-ABBA的方法，即将ABBA（自适应布朗桥符号聚合）方法整合到大型语言模型中，用于各种下游时间序列任务。ABBA通过使用现有的LLM令牌来建模时间序列模式（振幅和周期），以符号化表示时间序列。引入了一种固定的多边形链技巧，以避免预测任务中的明显漂移，从而显著减轻符号到数值转换过程中累积误差的影响。此外，LLM-ABBA在TSER基准测试中达到了新的最佳性能，在时间序列回归任务中，LLM-ABBA表现出与近期SOTA相当的预测能力。", "conclusion": "我们相信这种框架也可以无缝扩展到其他时间序列任务。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.19301", "html_url": "https://arxiv.org/abs/2501.19301", "title": "超越象棋：探索AI文本中的创意瓶颈", "title_en": "Beyond checkmate: exploring the creative chokepoints in AI text", "authors": "Nafis Irtiza Tripto,Saranya Venkatraman,Mahjabin Nahar,Dongwon Lee", "background": "大型语言模型（LLMs）的迅速发展极大地改变了文本生成的方式，但同时也引发了对其可能被滥用的担忧，因此检测生成的AI文本变得尤为重要。先前的研究主要集中在识别和抵制AI文本方面，而本研究则更进一步，探讨人类和AI文本在不同段落（引言、主体和结论）之间的细微差异。通过对棋局结构（开局、中局和残局）的类比，我们分析了段落间的特定模式，揭示了最具差异性的部分。", "innovation": "本研究创新性地分析了人类和AI文本在不同段落之间的细微差异，通过将文本分析类比于棋局结构，揭示了更多关于这些差异的信息，特别是强调了主体段落的特点。研究指出，尽管AI文本在主体段落中与人类文本相似，但在依赖语言连续流动的特征上仍然存在更高差异，这使得主体段落成为检测AI文本最具信息量的部分。", "conclusion": "研究的结果提供了关于人类和AI文本差异的新见解，为更有效的、可解释的检测策略奠定了基础。此外，人类文本在不同段落之间表现出更大的风格变化，提供了区分它们的新视角。研究还指出了检测策略的潜在改进方向。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.05098", "html_url": "https://arxiv.org/abs/2502.05098", "title": "在Android恶意软件检测器中学习时间不变性", "title_en": "Learning Temporal Invariance in Android Malware Detectors", "authors": "Xinran Zheng,Shuo Yang,Edith C.H. Ngai,Suman Jana,Lorenzo Cavallaro", "background": "基于学习的Android恶意软件检测器由于恶意软件变体和新家族导致的自然分布漂移而逐渐失效。这类检测器在使用经验风险最小化（ERM）训练的分类器面临这样的分布变化时表现不佳，因为它们无法学习稳定且区分性的特征。不变学习理论提供了一种可能的解决方案，通过鼓励模型生成跨越不同环境而不受训练集不稳定影响的稳定表示，但是，缺乏先验环境标签、多种漂移因素以及由于多种家族导致的低质量表示使得这一任务具有挑战性。", "innovation": "本文提出了TIF（Temporal Invariant Framework），一种用于恶意软件检测的首个时间不变性训练框架。TIF通过应用基于应用观察日期整理环境的多代理对比学习和不变梯度对齐来揭示时间漂移，并生成高质量、稳定的表示。TIF能够无缝地集成到任何基于学习的检测器中，实验结果显示TIF在早期部署阶段表现出色，特别是在解决实际需求方面优于最先进的方法。", "conclusion": "TIF增强了检测器学习稳定表示的能力，特别是在随着时间推移仍能保持高检测准确度方面。通过实验验证了TIF框架的有效性，在长期数据集上优于现有方法，特别是在早期部署阶段具有显著优势。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.10857", "html_url": "https://arxiv.org/abs/2410.10857", "title": "Mirror-Consistency: 引导多数投票中的不一致性", "title_en": "Mirror-Consistency: Harnessing Inconsistency in Majority Voting", "authors": "Siyuan Huang,Zhiyuan Ma,Jintao Du,Changhua Meng,Weiqiang Wang,Zhouhan Lin", "background": "自一致性是大型语言模型（LLMs）广泛使用的一种解码策略，能够显著提升其推理能力。不过，自一致性依赖于多数投票规则，该规则重视最频繁的答案，而忽视其他所有少数意见。这些少数派的观点往往揭示了模型生成过程中的不确定区域。由于这些不一致的少数意见被忽视，现有的方法无法全面了解和处理模型生成过程中的不确定性问题。因此，当前研究需要找到一种方法来解决这个问题，更好地利用这些不一致的意见来提升模型的性能。", "innovation": "为了克服上述不足，本研究提出了一种增强的自一致性方法——镜像一致性（Mirror-Consistency）。该方法在自一致性基础上引入了‘反射镜’的概念，使LLMs能够在多个生成过程中批判性地审视不一致意见。此外，本研究还提出了通过镜像一致性提高基于样本的信心校准方法，以缓解过度自信的问题。实验结果表明，与普通自一致性方法相比，镜像一致性在推理准确性和信心校准方面表现更优秀，证明了该方法的有效性。", "conclusion": "本研究通过对自一致性的改进，提出了镜像一致性方法，通过引入‘反射镜’的概念，使模型能够更好地处理生成过程中的不确定性，并通过这种方法改进了基于样本的信心校准方法。实验显示，相比于普通自一致性，镜像一致性能显著提高模型的推理准确性和信心校准水平。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.01613", "html_url": "https://arxiv.org/abs/2407.01613", "title": "基于平衡残差衰减率的自适应权重方法用于物理感知神经网络和深度操作网络", "title_en": "Self-adaptive weights based on balanced residual decay rate for physics-informed neural networks and deep operator networks", "authors": "Wenqian Chen,Amanda A. Howard,Panos Stinis", "background": "物理感知的深度学习已经成为解决偏微分方程的一个有前景的替代方案。然而，对于复杂问题，训练这些网络仍然具有挑战性，往往导致不满意的准确性和效率。", "innovation": "本文指出，物理感知神经网络失败的原因在于不同训练点上残差收敛速率的巨大差异，其中最慢的收敛速率主导了整体解的收敛。基于此观察，本文提出了一种适用于物理感知神经网络和物理感知深度操作网络的点适应权重方法，以平衡不同训练点上的残差衰减速率。", "conclusion": "通过广泛的数值结果表明，提出的方法具有多项优势，包括有界权重、高预测准确性、快速收敛速率、低训练不确定性、低计算成本和易于超参数调整。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.01086", "html_url": "https://arxiv.org/abs/2409.01086", "title": "DPDEdit: 保留细节的扩散模型用于多模态服装图像编辑", "title_en": "DPDEdit: Detail-Preserved Diffusion Models for Multimodal Fashion Image Editing", "authors": "Xiaolong Wang,Zhi-Qi Cheng,Jue Wang,Xiaojiang Peng", "background": "时尚图像编辑是设计师通过可视化设计概念进行创作的关键工具。目前，尽管多模态提示和强大的扩散模型使得图像编辑技术取得了进展，但这些技术仍然难以准确识别编辑区域并保留所需服装的纹理细节。", "innovation": "本文介绍了一种基于潜在扩散模型的新颖的多模态时尚图像编辑架构，称为保留细节的扩散模型（DPDEdit）。DPDEdit通过结合文本提示、区域掩码、人体姿态图像和服装纹理图像来指导扩散模型的服装图像生成。通过首次引入Grounded-SAM来根据用户文本描述预测编辑区域，并结合其他条件进行局部编辑。为了将给定服装纹理的细节转移到目标时尚图像中，提出了一种纹理注入和优化机制。该机制使用解耦交叉注意力层整合文本描述和纹理图像，并结合辅助U-Net保持生成服装纹理的高频细节。此外，使用多模态大规模语言模型扩展了VITON-HD数据集，生成带有所需纹理图像和文本描述的配对样本。", "conclusion": "大量实验结果显示，我们的DPDEdit在图像保真度和与给定多模态输入的一致性方面均优于现有最先进的方法。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.19894", "html_url": "https://arxiv.org/abs/2409.19894", "title": "基于LLM的多智能体系统在语义对齐增强代码转换中的应用", "title_en": "Semantic Alignment-Enhanced Code Translation via an LLM-Based Multi-Agent System", "authors": "Zhiqiang Yuan,Weitong Chen,Hanlin Wang,Kai Yu,Xin Peng,Yiling Lou", "background": "代码翻译是将代码从一种编程语言转换到另一种编程语言以保持原有功能的过程，对于软件迁移、系统重构和跨平台开发至关重要。传统的基于规则的方法依赖于手工编写的规则，耗时且通常导致代码可读性差。近年来，利用平行数据训练模型的基于学习的代码翻译方法取得了进展。但是，使用LLM进行的代码翻译仍然存在各种质量问题（如语法错误和语义错误），并且LLM难以通过简单提供错误信息来自我调试这些错误。为此，本文提出了一种名为TRANSAGENT的新型基于LLM的多智能体系统，通过四个基于LLM的智能体之间的协同作用来解决语法错误和语义错误，以增强基于LLM的代码翻译。其主要洞察在于基于目标程序和源程序的执行对齐来定位错误代码块，从而缩小修复范围，降低修复难度。为了对TRANSAGENT进行评估，首先构建了一个新的基准，评估结果显示该方法在翻译效果和效率上优于最新的基于LLM的代码翻译技术UniTrans，并且在不同的LLM上进行的评估展示了TRANSAGENT的通用性，以及通过消融实验展示了每个智能体的贡献。", "innovation": "本文提出了一种名为TRANSAGENT的新型基于LLM的多智能体系统，通过四个基于LLM的智能体之间的协同作用来解决语法错误和语义错误，以增强基于LLM的代码翻译。该系统首先基于目标程序和源程序的执行对齐来定位错误代码块，从而降低修复难度并提高翻译效果和效率。此外，该方法展示了通用性，并且通过消融实验展示了每个智能体的贡献。", "conclusion": "在对构建的新基准进行评估后，本文提出的TRANSAGENT方法在翻译效果和效率上优于最新的基于LLM的代码翻译技术UniTrans，并展示了通用性。通过消融实验，证实了每个智能体对整体翻译系统性能的重要贡献。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15871", "html_url": "https://arxiv.org/abs/2502.15871", "title": "大型语言模型在医疗领域的信任度综述", "title_en": "A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare", "authors": "Manar Aljohani,Jun Hou,Sindhura Kommu,Xuan Wang", "background": "大型语言模型（LLMs）在医疗领域的应用有望提升临床决策、医学研究和患者护理的质量。然而，这些模型在实际临床环境中的应用引发了对可信度的担忧，尤其是在真实性、隐私、安全、鲁棒性、公平性和可解释性方面。这些方面对于确保LLM生成可靠、无偏见且符合伦理的输出至关重要。尽管研究人员已经开始开发评估LLM可信度的标准和评估框架，但这些模型在医疗领域的可信度尚未得到系统性的探讨和全面的理解。为此，本文综述了当前用于减轻关键信任维度风险的方法和技术。", "innovation": "本文提供了对现有用于缓解医疗领域大型语言模型信任度风险的方法和技术的全面总结。分析了每个维度如何影响医疗领域的大型语言模型的可靠性和伦理应用，并汇总了正在进行的研究努力，还指出了现有方法中的关键差距。识别了由于多智能体协作、多模态推理和小规模开源医学模型的发展而带来的新兴挑战。", "conclusion": "本研究旨在指导未来研究朝着更加可信、透明和临床适用的大型语言模型方向发展。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.07445", "html_url": "https://arxiv.org/abs/2502.07445", "title": "忘记你对大语言模型评估所了解的一切——大语言模型像变色龙", "title_en": "Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon", "authors": "Nurit Cohen-Inger,Yehonatan Elisha,Bracha Shapira,Lior Rokach,Seffi Cohen", "background": "大语言模型（LLMs）在公开基准测试中表现出色，但这些高分可能掩盖了其过度依赖于数据集特定的表面特征，而不是真正的语言理解。目前的评估方法可能不足以揭示模型的真实能力，需要一种新的方法来检查模型的泛化能力和鲁棒性。", "innovation": "本文提出了一种名为Chameleon Benchmark Overfit Detector (C-BOD)的元评估框架，通过参数化变换系统地扭曲基准测试提示，并检测LLMs的过拟合问题。C-BOD通过重新表达输入内容同时保留其语义内容和标签，暴露模型性能是否受到记忆模式的影响。研究人员评估了C-BOD在MMLU基准测试上的效果，发现模型的表现下降了2.15%，并在26个模型中有20个模型表现出统计显著的差异。", "conclusion": "研究结果挑战了现有社区对大语言模型评估的看法，提倡更多关注模型的鲁棒性和泛化能力，而不仅仅是排行榜上的得分。C-BOD的通用性设计还可以轻松集成到训练流程中，促进更稳健的语言理解能力。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06857", "html_url": "https://arxiv.org/abs/2502.06857", "title": "Gemstones：用于多面扩展规律的模型套件", "title_en": "Gemstones: A Model Suite for Multi-Faceted Scaling Laws", "authors": "Sean McLeish,John Kirchenbauer,David Yu Miller,Siddharth Singh,Abhinav Bhatele,Micah Goldblum,Ashwinee Panda,Tom Goldstein", "background": "通常使用具有狭窄范围的冻结超参数选择的一系列模型来拟合扩展规律。本研究通过研究多种架构形状和超参数选择来探讨这些选择对结果处方的影响，旨在提供更深入了解和复杂的研究工具，比如分析宽度和深度的关系。研究表明，扩展规律的建议可能会受到实验设计方案和拟合期间使用的特定模型检查点的显著影响。", "innovation": "本研究发布了一个名为Gemstones的开源扩展规律数据集，包含超过4000个具有多达20亿参数和多种架构形状的transfomer检查点，包括学习率和冷却的剔除实验。这些检查点为更复杂的扩展规律研究提供了基础，如分析宽度和深度的关系，并证明了扩展规律的建议对实验设计过程的敏感性", "conclusion": "通过研究模型套件，发现扩展规律的建议对实验设计过程和用于拟合的特定模型检查点非常敏感。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.01658", "html_url": "https://arxiv.org/abs/2503.01658", "title": "CoPL: Collaborative Preference Learning for Personalizing LLMs", "title_en": "CoPL: Collaborative Preference Learning for Personalizing LLMs", "authors": "Youngbin Choi,Seunghyuk Cho,Minjong Lee,MoonJeong Park,Yesong Ko,Jungseul Ok,Dongwoo Kim", "background": "现有的方法在个性化大规模语言模型（LLMs）时面临的挑战是灵活性和泛化性不足。背景信息指出，个性化LLMs的重要性在于使输出与用户多样化的偏好更加一致。然而，当前的方法在处理稀疏标注场景时表现不佳，难以准确估计用户的偏好。因此，需要一种新的方法来提高泛化能力和灵活性，特别是在标注稀疏的环境下也能有效工作。", "innovation": "提出了一种基于图的协作过滤框架CoPL（Collaborative Preference Learning），通过建模用户-响应关系来提升偏好估计。CoPL结合了LoRA专家混合体，能够高效微调LLMs，并动态平衡共享偏好和用户特定偏好。此外，提出了一种无需优化的适应策略，使模型能够泛化到未见过的用户，而无需进行微调。这种方法在处理稀疏标注数据时表现出色，能够捕捉到用户的普遍偏好和争议性偏好，提供了一种可扩展的个性化LLMs解决方案。", "conclusion": "实验结果表明，CoPL在UltraFeedback-P数据集上优于现有的个性化奖励模型，成功捕捉到用户的普遍和争议性偏好，是一个适用于个性化LLMs的可扩展解决方案。代码可以在提供的链接中获取。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09334", "html_url": "https://arxiv.org/abs/2503.09334", "title": "CyberLLMInstruct: 揭示网络安全大语言模型微调安全性能权衡的伪恶意数据集", "title_en": "CyberLLMInstruct: A Pseudo-malicious Dataset Revealing Safety-performance Trade-offs in Cyber Security LLM Fine-tuning", "authors": "Adel ElZemity,Budi Arief,Shujun Li", "background": "将大型语言模型（LLMs）集成到网络安全应用中既带来了机会也带来了关键的安全风险。为此，作者创建了CyberLLMInstruct数据集，其包含54,928个伪恶意指令-响应对，涉及恶意软件分析、钓鱼模拟和零日漏洞等网络安全任务，旨在评估各种LLM模型在微调后安全性和性能的权衡。", "innovation": "作者引入了CyberLLMInstruct数据集，这是第一个大型伪恶意指令-响应数据集，旨在发现网络安全任务中微调LLM模型的安全性能之间的权衡。实验使用了七种开源LLM，揭示了微调虽然可以提高网络安全任务性能（达到92.50%的准确率），但会严重削弱所有测试模型的安全鲁棒性。", "conclusion": "研究发现，为了在恶意环境中确保LLM的安全，必须开发既能保存安全性又能提高性能的微调方法。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.20742", "html_url": "https://arxiv.org/abs/2502.20742", "title": "结构化的偏好优化在视觉-语言长期任务规划中的应用", "title_en": "Structured Preference Optimization for Vision-Language Long-Horizon Task Planning", "authors": "Xiwen Liang,Min Lin,Weiqi Ruan,Rongtao Xu,Yuecheng Liu,Jiaqi Chen,Bingqian Lin,Yuzheng Zhuang,Xiaodan Liang", "background": "现有的视觉-语言任务规划方法在短期任务中表现优异，但在复杂、长期的任务规划尤其是在动态环境中时往往表现不佳。这些挑战主要源自于高效训练模型进行长期任务推理和决策的难度。", "innovation": "提出了一种结构化的偏好优化方法（SPO），通过结构化偏好评估和优化训练策略来提升长期任务规划中的推理和决策质量。SPO 具体引入了：1) 基于偏好计分和优化，系统性地对与任务相关性、视觉定位和历史一致性相关的推理链进行评价；2) 基于课程指导的训练，使模型逐步从简单任务过渡到复杂任务，提高其在长期任务中的泛化能力和推理稳健性。", "conclusion": "实验结果表明，SPO 显著提升了推理质量和最终决策准确性，优于先前的方法，并证明了偏好驱动优化在视觉-语言长期任务规划中的有效性。特别是在 VirtualHome 和 Habitat 2.0 中，SPO 在 GCR 和 SR 指标上分别提升了 5.98% 和 4.68%，以及 3.30% 和 2.11%。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.12484", "html_url": "https://arxiv.org/abs/2502.12484", "title": "LocalEscaper: 区域重建的弱监督框架用于可扩展的神经TSP求解器", "title_en": "LocalEscaper: A Weakly-supervised Framework with Regional Reconstruction for Scalable Neural TSP Solvers", "authors": "Junrui Wen,Yifei Li,Bart Selman,Kun He", "background": "神经求解器在解决旅行商问题（TSP）方面显示出显著的潜力，但当前的方法面临重大挑战。监督学习（SL）基的求解器需要大量的高质量标签数据，而强化学习（RL）基的求解器虽然对这些数据的依赖程度较低，但却常常受到效率低下的困扰。为了解决这些问题，本文提出了一种新的弱监督学习框架LocalEscaper，有效地结合了SL和RL的优点，能够高效地在低质量标签的数据集上进行训练。此外，通过引入区域重建策略，该方法能够缓解现有局部重建方法普遍存在的局部最优问题，从而进一步提高了解的质量。实验结果表明，LocalEscaper在合成数据集和真实世界数据集上均优于现有神经求解器，取得了显著的效果。", "innovation": "1. 提出了一种弱监督学习框架LocalEscaper，结合了监督学习和强化学习的优点，能够在低质量标签数据集上有效训练；2. 引入了区域重建策略，解决了现有局部重建方法存在的局部最优问题，从而提高了解的质量；3. 在合成数据集和真实世界数据集上均取得了优于现有神经求解器的结果，证明了该方法的有效性。", "conclusion": "LocalEscaper通过结合弱监督学习和强化学习的优点，以及引入区域重建策略，成功地解决了TSP求解中的数据依赖性和局部最优问题。实验结果表明，该方法在多种场景下都能取得优异的性能，展示了其在大规模TSP求解中的应用潜力。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.11216", "html_url": "https://arxiv.org/abs/2504.11216", "title": "FedDiverse: 通过多样性驱动的客户端选择解决联邦学习中的数据异质性", "title_en": "FedDiverse: Tackling Data Heterogeneity in Federated Learning with Diversity-Driven Client Selection", "authors": "Gergely D. Németh,Eros Fanì,Yeat Jeng Ng,Barbara Caputo,Miguel Ángel Lozano,Nuria Oliver,Novi Quadrianto", "background": "联邦学习（FL）使机器学习模型能够在分布式数据上进行去中心化训练，同时保护隐私。然而，在实际的FL环境中，客户端数据往往是非同分布且不平衡的，导致统计数据异质性，这影响了服务器模型在不同客户端上的泛化能力，减缓了收敛速度并降低了性能。", "innovation": "本文通过提出一种基于6个全球和客户端属性不平衡、类别不平衡及虚假相关性的统计数据异质性表征方法，创建并共享了7个包含二分类和多分类图像分类任务的联邦学习数据集，这些数据集涵盖了广泛的统计数据异质性，以模拟现实情况。最后，提出了一种新的客户端选择算法FEDDIVERSE，该算法旨在通过促进具有互补数据分布的客户端之间的协作来管理和利用数据异质性。", "conclusion": "在七个提出的联邦学习数据集上的实验表明，FEDDIVERSE算法在提高多种联邦学习方法的性能和稳健性方面具有有效性，同时具有较低的通信和计算开销。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.06607", "html_url": "https://arxiv.org/abs/2502.06607", "title": "遥感图像中固体废弃物检测的深度学习管道", "title_en": "A Deep Learning Pipeline for Solid Waste Detection in Remote Sensing Images", "authors": "Federico Gibellini,Piero Fraternali,Giacomo Boracchi,Luca Morandini,Thomas Martinoli,Andrea Diecidue,Simona Malegori", "background": "不恰当的固体废物管理既是生态系统健康的重大威胁，也是环境犯罪团伙牟利的重要来源。随着高分辨率遥感（VHR RS）图像的日益普及，现代图像分析工具能够自动化识别和大规模扫描潜在的非法废弃物处置地点，从而缓解这一问题。本文基于与地方环保机构的合作，开发了一个半自动的废弃物检测管道，旨在利用VHR RS图像检测非法废物倾倒地点。", "innovation": "本文创新性地提出了一种基于深度学习的半自动废弃物检测管道，通过系统的实验评估了网络架构、输入图像的空间分辨率和地理范围以及预训练过程，确定了最佳模型方案，实现了92.02%的F1分数和94.56%的准确性。此外，研究了该检测器在对训练图像地理范围差异较大的其他地区图像检测时的表现，发现性能损失仅在F1分数上平均降低5.1%。", "conclusion": "通过实验证明，该深度学习模型能有效识别非法废弃物处置地点，并且相较于传统的人工巡检，能够将废弃物检测的时间减少约30%。该研究成果对于促进自动化环境监管具有重要意义。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01153", "html_url": "https://arxiv.org/abs/2504.01153", "title": "当您搜索时抓住我：上下文网页搜索结果如何影响幻觉的检测", "title_en": "Catch Me if You Search: When Contextual Web Search Results Affect the Detection of Hallucinations", "authors": "Mahjabin Nahar,Eun-Ju Lee,Jin Won Park,Dongwon Lee", "background": "随着我们越来越多地依赖大型语言模型（LLMs）进行各种任务，这些模型会产生不准确的内容或'幻觉'，可能会导致灾难性的后果。近年来，网页搜索结果被整合到LLMs中，引发了人们是否利用这些搜索结果来验证生成的内容，从而准确检测幻觉的问题。这项研究通过一项在线实验（N=560）来探讨提供搜索结果（静态的或动态的）对参与者对LLM生成内容准确性的感知、自我评估准确性的信心以及对LLM的整体评价的影响，与没有提供搜索结果的对照组进行比较。结果表明，与对照组相比，在静态或动态搜索条件下的人们认为幻觉内容的准确性较低，并且更加负面地评价LLM。然而，动态搜索条件下的参与者更能准确地评价真实内容，并在他们评估方面表现出了更高的总体信心。", "innovation": "研究通过在线实验手段，对比分析静态和动态搜索结果对人工智能生成内容准确性的评判差异，揭示了上下文网页搜索结果如何影响幻觉的检测，并探讨了在实际应用中加入网页搜索功能的实用意义。", "conclusion": "研究结果表明，提供搜索结果（无论是静态还是动态）可以降低人们对LLM生成的幻觉内容的信任，并提高他们对LLM的整体评价。其中，动态搜索条件下的参与者更能准确地评价真实内容，并且在评估方面表现出了更高的信心。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.20781", "html_url": "https://arxiv.org/abs/2504.20781", "title": "使用大语言模型生成软件架构决策的设计理由", "title_en": "Using LLMs in Generating Design Rationale for Software Architecture Decisions", "authors": "Xiyu Zhou,Ruiyin Li,Peng Liang,Beiqi Zhang,Mojtaba Shahin,Zengyang Li,Chen Yang", "background": "软件架构决策背后的理由（Design Rationale，DR）对于理解软件开发生命周期中架构设计的不同阶段提供了宝贵的见解。然而，在实践中，DR往往由于开发人员缺乏动机和精力而没有充分记录。近年来，大语言模型（LLMs）在文本理解和生成方面的进步，可能有助于生成和恢复DR。", "innovation": "研究通过使用五种大语言模型及其三种不同的提示策略（零样本、思维链和基于大语言模型的代理），评估了生成架构决策DR的性能。尽管生成的DR表现有限，但大多数未提及的论证仍具有价值，部分论证存在不确定性或误导性。研究进一步通过半结构化访谈六名从业者，探讨了大语言模型生成的DR在实践中的可靠性和适用性。", "conclusion": "三种提示策略各有优劣，大语言模型生成的DR有其优势和局限性。研究对未来使用大语言模型生成DR的实际应用提出了一些启发。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.17671", "html_url": "https://arxiv.org/abs/2503.17671", "title": "ComfyGPT: 一种综合ComfyUI工作流生成的自优化多智能体系统", "title_en": "ComfyGPT: A Self-Optimizing Multi-Agent System for Comprehensive ComfyUI Workflow Generation", "authors": "Oucheng Huang,Yuhang Ma,Zeng Zhao,Mingrui Wu,Jiayi Ji,Rongsheng Zhang,Zhipeng Hu,Xiaoshuai Sun,Rongrong Ji", "background": "ComfyUI是流行的工作流界面，用户可以通过直观的节点系统自定义图像生成任务。然而，管理节点连接和多种模块的复杂性对于用户来说是一个挑战。", "innovation": "ComfyGPT是一个自优化的多代理系统，基于任务描述自动生成ComfyUI工作流。其创新点包括：(1) 由四个专门智能体组成的多智能体工作流生成系统：ReformatAgent、FlowAgent、RefineAgent和ExecuteAgent；(2) 集中生成精确的节点连接而不是整个工作流，提高了生成准确性；(3) 通过强化学习增强工作流生成。此外，引入了FlowDataset大规模数据集和FlowBench综合基准，还提出了四种新的评估指标：格式验证(FV)、通过准确率(PA)、通过指令对齐(PIA)和通过节点多样性(PND)。实验结果表明，ComfyGPT在工作流生成方面显著优于现有的基于LLM的方法，是该领域的一大进步。", "conclusion": "ComfyGPT在工作流生成任务中显著超越了现有的基于LLM的方法，展示了自优化多代理系统在ComfyUI工作流生成中的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12381", "html_url": "https://arxiv.org/abs/2505.12381", "title": "从n-gram到注意力：模型架构如何学习和传播语言模型中的偏见", "title_en": "From n-gram to Attention: How Model Architectures Learn and Propagate Bias in Language Modeling", "authors": "Mohsinul Kabir,Tasfia Tahsin,Sophia Ananiadou", "background": "当前对语言模型(LMs)中的偏见的研究主要集中在数据质量上，对模型架构和数据的时间影响关注较少。此外，很少有研究系统地探究偏见的根源。本研究提出了一种基于比较行为理论的方法，旨在解释训练数据与模型架构在偏见传播过程中的复杂互动。研究表明，n-gram语言模型在偏见传播中对上下文窗口大小非常敏感，而变换器模型则在架构上表现出更强的鲁棒性；训练数据的时间来源显著影响偏见；不同的模型架构对控制偏见注入的响应不同，某些偏见（例如性取向）被不成比例地放大。随着语言模型的普及，这些研究结果强调了需要在数据和模型两个维度上追踪偏见的根源，以缓解潜在的危害。", "innovation": "本研究提出了一种基于比较行为理论的新的方法，专门用于解释训练数据与模型架构在偏见传播中的相互作用。通过将变换器与n-gram模型进行对比，研究评估了数据、模型设计选择和时间动态如何影响偏见传播。研究发现不同模型架构对偏见的响应不同，某些特定偏见在传播过程中被不成比例地放大。", "conclusion": "本研究强调了语言模型中偏见传播的复杂机制，指出需要从数据和模型两个维度全面追踪偏见来源来缓解偏见问题，而不仅仅关注偏见的症状。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06311", "html_url": "https://arxiv.org/abs/2505.06311", "title": "通过指令检测防禦间接提示注入攻击", "title_en": "Defending against Indirect Prompt Injection by Instruction Detection", "authors": "Tongyu Wen,Chenglong Wang,Xiyuan Yang,Haoyu Tang,Yueqi Xie,Lingjuan Lyu,Zhicheng Dou,Fangzhao Wu", "background": "大型语言模型（LLMs）与外部数据源的整合越来越普遍，例如检索增强生成（RAG）方法。然而，这种整合引入了间接提示注入（IPI）攻击的风险，即潜藏在外部数据中的指令可以操控LLMs执行意外或有害操作。IPI攻击依赖于嵌入在外部内容中的指令，改变LLMs的行为状态。目前未有效检测这些状态变化的方法来防御IPI攻击。因此，需要一种新的检测方法来识别潜在的IPI攻击。", "innovation": "本文提出了InstructDetector，这是一种新颖的基于检测的方法，通过利用LLMs的行为状态来识别潜在的IPI攻击。具体来说，通过利用中间层的隐藏状态和梯度作为指令检测的区分性特征，InstructDetector在领域内和领域外设置中的检测准确率分别达到了99.60%和96.90%，并将BIPIA基准上的攻击成功率降低至0.03%。", "conclusion": "通过InstructDetector的有效实施，识别潜在的IPI攻击，可显著提高对抗IPI攻击的有效性，具有较高的检测准确性和低攻击成功率。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21717", "html_url": "https://arxiv.org/abs/2505.21717", "title": "扩展液阻液容网络以实现高效序列建模", "title_en": "Scaling Up Liquid-Resistance Liquid-Capacitance Networks for Efficient Sequence Modeling", "authors": "Mónika Farsang,Ramin Hasani,Daniela Rus,Radu Grosu", "background": "传统的线性状态空间层在处理长序列时速度较慢。本文介绍了一种名为LrcSSM的非线性递归模型，该模型能够像线性状态空间层那样快速处理长序列，但仍然保持了模型的非线性特性，这为处理长序列提供了一种新的方法和可能的优化手段。此外，LrcSSM提供了其他输入变化系统（如Liquid-S4和Mamba）没有的梯度稳定性保证，进一步提升了模型的可靠性和发展潜力。", "innovation": "LrcSSM通过强制对角雅可比矩阵，实现了对整个序列的并行处理，时间为O(TD)，内存为O(TD)，同时只有O(log T)的顺序深度。LrcSSM的独特之处在于其对角雅可比结构不会导致性能损失，并能够应用于其他非线性递归模型，具有更广泛的适用性。此外，LrcSSM还提供了一种形式化的梯度稳定性保证，增强了模型的可信度和稳定性。", "conclusion": "在一系列长距离预测任务中，LrcSSM表现优于Transformers、LRU、S5和Mamba。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.16404", "html_url": "https://arxiv.org/abs/2504.16404", "title": "直接基于视频的时空深度学习在奶牛跛行检测中的应用", "title_en": "Direct Video-Based Spatiotemporal Deep Learning for Cattle Lameness Detection", "authors": "Md Fahimuzzman Sohan,Raid Alzubi,Hadeel Alzoubi,Eid Albalawi,A. H. Abdul Hafez", "background": "奶牛跛行是畜牧业中常见的健康问题，通常由蹄部受伤或感染引起，严重影响动物福利和生产力。早期和准确的检测对于最小化经济损失和确保正确治疗至关重要。", "innovation": "本文提出了一种时空深度学习框架，利用公开可用的视频数据自动检测奶牛跛行。不同于传统需要多阶段管道（涉及物体检测和姿态估计）的方法，本研究通过直接的端到端视频分类方法，在3D卷积神经网络（3D CNN）和卷积长短期记忆网络（ConvLSTM2D）中训练和评估了模型，证明了深度学习模型可以从多种视频源中成功提取和学习时空特征，适用于实际农场环境下的高效奶牛跛行检测。", "conclusion": "本文研究结果表明，深度学习模型能够成功从各种视频来源中提取和学习时空特征，能够在实际农场环境中实现大规模、高效的奶牛跛行检测，证明了直接端到端视频分类方法的有效性，优于之前最优的端到端方法（C3D-ConvLSTM，90.3%）。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23759", "html_url": "https://arxiv.org/abs/2505.23759", "title": "当视觉语言模型捉摸不透谜题时", "title_en": "Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint", "authors": "Heekyung Lee,Jiaxin Ge,Tsung-Han Wu,Minwoo Kang,Trevor Darrell,David M. Chan", "background": "谜语作为一种通过图像、空间布局和象征性替代编码语言的视觉谜题，给当前的视觉语言模型（VLMs）带来了独特的挑战。与传统的图像描述或问答任务不同，解决谜题需要多模态抽象、符号推理和对文化、音韵和语言双关的理解。", "innovation": "研究者构建了一个手工生成和标注的多样的英语谜语基准数据集，涵盖了从简单的图形替换到空间依赖性线索（如“头”在“脚”之上）的谜语，旨在探索当下VLMs在解释和解决谜题方面的能力。", "conclusion": "虽然VLMs在解读简单的视觉线索方面表现出一些令人惊讶的能力，但在需要抽象推理、横向思考和理解视觉隐喻的任务上显得力不从心。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.09974", "html_url": "https://arxiv.org/abs/2505.09974", "title": "使用伪恶意网络信息安全数据微调LLMs的安全风险分析", "title_en": "Analysing Safety Risks in LLMs Fine-Tuned with Pseudo-Malicious Cyber Security Data", "authors": "Adel ElZemity,Budi Arief,Shujun Li", "background": "大型语言模型（LLMs）已在许多应用领域得到广泛应用，包括网络安全。尽管LLMs在网络安全方面有显著的应用机会，比如增强威胁分析和恶意软件检测，但也可能引入关键的安全风险和隐私问题，如个人数据泄露和自动化生成新的恶意软件。近年来的研究指出，使用伪恶意网络信息安全数据微调LLMs会显著降低其安全性。为此，本文通过不同的评估框架（使用gark红队框架结合OWASP Top 10对LLM应用进行评估）对四种开源LLMs（Mistral 7B，Llama 3 8B，Gemma 2 9B，DeepSeek R1 8B）进行了全面验证和扩展，确认了微调方法会降低模型的安全韧性。同时，作者还提出了一个新的安全对齐方法，通过谨慎地重新表述指令-响应对并明确加入安全预防措施和伦理考量来增强模型的安全性。", "innovation": "通过引入一个新的安全对齐方法，作者谨慎地重新表述指令-响应对并明确加入安全预防措施和伦理考量来增强模型的安全性。这是一种实用路径，旨在开发更安全的微调方法，以维护或提高模型安全性能的同时保留其技术功能。此外，该研究使用独立评估方法验证了先前的安全关切，并提出了新的方法来减轻这些风险，为开发安全、可信赖且伦理对齐的LLMs做出了贡献。", "conclusion": "该研究证明了可以在保持或甚至提高模型安全性的同时实现技术实用性，并提供了一条发展的实际路径，推动了更安全的LLM微调方法的发展。这项工作验证了以前的安全担忧，并引入了新的方法来减轻这些风险，为开发安全、可信赖且伦理对齐的LLMs做出了贡献。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00308", "html_url": "https://arxiv.org/abs/2506.00308", "title": "MythTriage: 视频分享平台上可扩展检测阿片使用障碍谬误的方法", "title_en": "MythTriage: Scalable Detection of Opioid Use Disorder Myths on a Video-Sharing Platform", "authors": "Hayoung Jung,Shravika Mittal,Ananya Aatreya,Navreet Kaur,Munmun De Choudhury,Tanushree Mitra", "background": "理解健康主题在线的错误信息普遍存在情况可以指导公共健康政策和干预措施。然而，大规模测量此类错误信息仍具挑战性，尤其是在高风险但研究不足的领域，如阿片使用障碍（OUD），这是导致美国死亡的主要原因之一。论文介绍了首个针对YouTube平台上阿片使用障碍相关谬误的大规模研究，YouTube是广泛用于获取健康信息的平台。", "innovation": "论文提出了一种名为MythTriage的高效分诊管道，该管道采用轻量级模型处理常规案例，并将复杂案例转移到高性能但成本较高的大型语言模型（LLM）。与完全由专家或全面使用LLM标记相比，该系统估计可将注释时间减少76%以上，同时降低成本。通过分析2900个搜索结果和34.3万个推荐，研究揭示了YouTube上谬误如何持续存在，并提供了有关公共健康和平台内容管理的可操作见解。", "conclusion": "研究发现，在YouTube上发现和消除阿片使用障碍相关谬误是一个复杂且具有挑战性的过程。通过提出MythTriage，研究者实现了高效多阶段标注，不仅可以大规模检测这些谬误，还能提供有关公卫政策制定者如何应对这种误导信息的建议。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23804", "html_url": "https://arxiv.org/abs/2505.23804", "title": "通过利用子句频率校准LLMs的文本到SQL解析", "title_en": "Calibrating LLMs for Text-to-SQL Parsing by Leveraging Sub-clause Frequencies", "authors": "Terrance Liu,Shuyi Wang,Daniel Preotiuc-Pietro,Yash Chandarana,Chirag Gupta", "background": "尽管大型语言模型（LLMs）在文本到SQL解析方面表现出强大的性能，但它们有时会在响应中表现出令人意外的错误，自信地给出错误的结果。因此，构建可信赖的文本到SQL系统需要从LLM中提取可靠的不确定性度量。本文旨在研究提供一个校准后的置信评分问题，以传达输出查询正确性的可能性。", "innovation": "本文是首个为LLM文本到SQL解析建立后置校准基准的研究。研究表明，使用普莱特校准法相比于直接使用原始模型输出概率作为置信度分值提供了显著改进。此外，提出了一种基于SQL查询结构的校准方法，称为“子句频率”（SCF）评分，通过扩展普莱特校准技术的多元普莱特校准（MPS），将个体SCF评分综合成一个整体准确且校准后的评分，从而在两个流行的文本到SQL数据集上显示出更佳的校准和错误检测性能。", "conclusion": "本文通过MPS和SCF方法结合，进一步提高了校准和错误检测任务中的校准性能，为LLM的文本到SQL解析提供了一种有效的校准途径。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.17827", "html_url": "https://arxiv.org/abs/2504.17827", "title": "进化与扩散的相遇：高效神经架构生成", "title_en": "Evolution Meets Diffusion: Efficient Neural Architecture Generation", "authors": "Bingye Zhou,Caiyang Yu", "background": "神经架构搜索（NAS）因在深度学习模型设计中的潜力而引起了广泛的关注。然而，NAS巨大的搜索空间导致了显著的计算和时间成本。神经架构生成（NAG）将NAS重新定义为生成问题，以便能够精确生成特定任务的最佳架构。尽管NAG具有潜力，但主流方法如扩散模型在全局搜索能力上存在局限性，并且仍然受到高计算和时间成本的困扰。", "innovation": "提出了一种新型方法——进化扩散基础的神经架构生成（EDNAG），该方法实现了高效的、无需训练的架构生成。EDNAG利用进化算法模拟扩散模型中的去噪过程，利用适应度引导从随机高斯分布到最佳架构分布的转变。这种方法结合了进化策略和扩散模型的优点，实现快速且有效的架构生成。", "conclusion": "大量的实验结果显示，EDNAG在架构优化方面达到了最先进的性能，准确率提高了10.45%。此外，该方法还消除了耗时的训练需求，并将推理速度平均提高了50倍，展示了其卓越的高效性和有效性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.09532", "html_url": "https://arxiv.org/abs/2504.09532", "title": "基于多模态基础模型的嵌入体链式推理 humanoid 代理在零样本间位操作中的应用", "title_en": "Humanoid Agent via Embodied Chain-of-Action Reasoning with Multimodal Foundation Models for Zero-Shot Loco-Manipulation", "authors": "Congcong Wen,Geeta Chandra Raju Bethala,Yu Hao,Niraj Pudasaini,Hao Huang,Shuaihang Yuan,Baoru Huang,Anh Nguyen,Anthony Tzes,Yi Fang", "background": "人形机器人的间位操作（将整体移动与灵巧操作相结合）仍然是机器人学中的基本挑战。除了全身协调和平衡之外，核心难题在于理解人类指令并将它们转化为连贯的执行动作序列。尽管最近的基础模型取得了进展，提供了可转移的多模态表示和推理能力，但现有研究仍主要局限于分开处理间位操作或操作，对于人形机器人的实际应用有限。", "innovation": "本文提出了一种名为Humanoid-COA的人形代理框架，它结合了基础模型的推理能力和嵌入体链式操作（CoA）机制，实现了零样本间位操作。在感知-推理-行动的范式中，核心贡献在于推理阶段，提出了CoA机制，通过功能性分析、空间推理和全身动作推理，将高级人类指令分解为结构化的间位动作素序列。", "conclusion": "本研究框架在Unitree H1-2和G1这两款人形机器人上的广泛应用性和综合任务（间位操作、移动、间位操作）上均显著优于现有的基线模型，且展示了在长时间和非结构化场景中的稳健通用性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09061", "html_url": "https://arxiv.org/abs/2506.09061", "title": "EdgeProfiler：使用分析模型在边缘设备上对轻量级LLMs进行快速故障排除的框架", "title_en": "EdgeProfiler: A Fast Profiling Framework for Lightweight LLMs on Edge Using Analytical Model", "authors": "Alyssa Pinnock,Shakya Jayakody,Kawsher A Roxy,Md Rubel Ahmed", "background": "轻量级大型语言模型（LLMs）虽在自然语言理解和生成方面展现出显著的能力，但由于其高计算、内存和功率需求，它们通常局限于云计算环境。对于资源受限的边缘设备，这一情况成为一个挑战，需要一种系统的方法来评估和优化这些模型的性能。", "innovation": "提出了EdgeProfiler，这是一种快速故障排除框架，专为边缘设备上轻量级LLMs进行评估而设计。该框架利用激进的量化技术和严格的内存限制对紧凑型LLM模型进行评估，并通过分析建模来估计延迟、FLOPs和能耗，特别强调4位量化技术可使内存使用率减少约60-70%，同时保持在全精度基线内2-5%的准确性。此外，该研究提供了从FP16到4位整数配置的能效改进，估计INT4配置在硬件如Raspberry Pi 4/5和Jetson Orin Nano Super上的能耗减少幅度可达35-50%。", "conclusion": "研究表明，高效的故障排除方法对于在边缘环境应用轻量级LLMs至关重要，需要权衡准确度、能耗效率和计算可行性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.20923", "html_url": "https://arxiv.org/abs/2507.20923", "title": "Pareto-Grid-Guided Large Language Models for Fast and High-Quality Heuristics Design in Multi-Objective Combinatorial Optimization", "title_en": "Pareto-Grid-Guided Large Language Models for Fast and High-Quality Heuristics Design in Multi-Objective Combinatorial Optimization", "authors": "Minh Hieu Ha,Hung Phan,Tung Duy Doan,Tung Dao,Dao Tran,Huynh Thi Thanh Binh", "background": "多目标组合优化问题（MOCOP）在实践中常见，需要同时优化冲突的目标。传统进化算法虽然有效，但通常依赖领域知识和参数调优，应用到未知的MOCOP实例时缺乏灵活性。最近，将大型语言模型（LLMs）融入进化计算中，利用其高级语言理解和代码生成能力，自动产生启发式方法。然而，现有大部分方法主要关注单目标任务，忽视了多目标设置中的运行效率和启发式多样性等关键考虑。", "innovation": "该论文提出了一种名为MPaGE的新颖增强框架，结合了LLM和Pareto前沿网格（PFG）技术，通过将目标空间分割成网格并将性能最佳的候选者保留下来引导启发式生成，利用LLMs在变异过程中优先考虑语义结构不同的启发式方法，从而促进多样性并减少种群中的冗余。通过广泛的评估，MPaGE展示了优于现有LLM框架的性能，并在运行时间上显著快于传统的多目标进化算法（MOEAs），实现了与MOEAs相当的高质量结果。", "conclusion": "实验结果表明，与现有LLM框架相比，MPaGE具有更好的性能，并且在运行时间上显著快于传统的多目标进化算法。该代码可从 this https URL 获取。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.00827", "html_url": "https://arxiv.org/abs/2508.00827", "title": "Legal Knowledge Graph Foundations, Part I: URI-Addressable Abstract Works (LRMoo F1 to schema.org),", "title_en": "Legal Knowledge Graph Foundations, Part I: URI-Addressable Abstract Works (LRMoo F1 to schema.org)", "authors": "Hudson de Martim", "background": "文章基于IFLA图书参考模型（LRMoo）构建了一个事件为中心的法律规范历时演变形式化模型。文章讨论了将该模型的基础实体——抽象法律作品（F1）发布到语义网上的第一步。文章使用巴西联邦立法作为案例研究，展示了如何通过JSON-LD创建可互操作的、机器可读的描述，重点是稳定的URN标识符、核心元数据和规范关系。同时，文章说明了这种结构化映射如何为法律知识图谱（LKG）下层的构建提供稳定的持久化URI锚点，解决仅基于概率模型的局限性。\n", "innovation": "研究提出了一个详细实体级别的映射方法，将LRMoo F1 Works与广泛采用的schema.org词汇表进行映射。通过研究如何创建互操作的、机器可读的描述，在JSON-LD中以巴西联邦立法为案例进行展示。这种方法通过将形式本体论与原生Web标准相结合，为构建确定性和可靠性的法律知识图谱（LKGs）铺平了道路，突破了仅基于概率模型的局限性。\n", "conclusion": "这项工作为互操作的法律知识图谱下层结构的构建提供了基础。使用了稳定URI地址和核心元数据后，这种结构性映射创建了一个可验证的“事实基础”，这些基础在未来法律知识图谱（LKGs）的其他组件构建中非常关键。\n"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00658", "html_url": "https://arxiv.org/abs/2506.00658", "title": "Sarc7：利用七种类型和情绪启发技术评估讽刺检测与生成", "title_en": "Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and Emotion-Informed Techniques", "authors": "Lang Xiong,Raina Gao,Alyssa Jeong,Yicheng Fu,Sean O'Brien,Vasu Sharma,Kevin Zhu", "background": "讽刺是一种通过表达传达与其字面意义相反含义的幽默形式。使用大型语言模型来分类和生成讽刺对于解读人类交流至关重要。然而，讽刺的功能性和复杂性使计算模型面临挑战。本次研究引入了Sarc7基准，该基准通过标注MUStARD数据集中的条目，将讽刺分为七种类型，分别为自我贬低、抑郁口吻、直白型、礼貌型、令人讨厌型、狂热型和狂欢型，并通过零样本、少量样本、逐步推理以及一种新型的情感启发式提示技术进行分类评估。", "innovation": "研究提出了一种基于情绪的生成方法，通过识别讽刺中的不一致性、冲击价值和情境依赖性关键组件。利用这种方法，Gemini 2.5在使用情感启发式提示技术的情况下，在分类实验中表现出色，其F1得分为0.3664，优于其他设置。同时，人类评估者更倾向于情感启发式提示技术，成功生成的比例比零样本提示技术高38.46%。", "conclusion": "研究结论展示了Sarc7基准的有效性，强调了情感启发式技术在讽刺检测与生成任务中的重要性，并提出了一个基于情感的技术框架。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.18397", "html_url": "https://arxiv.org/abs/2508.18397", "title": "长尾中的矿藏：自主运动规划中数据为中心的关键性度量的比较研究", "title_en": "Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning", "authors": "Antonio Guillen-Perez", "background": "离线强化学习（RL）为通过大量实际驾驶日志训练自主车辆（AV）规划政策提供了有希望的范式。然而，这些日志中极端的数据不平衡导致了普通场景远多于罕见的“长尾”事件，这使得使用标准的均匀数据采样方法训练的策略变得脆弱且不安全。", "innovation": "本文通过系统性的大规模比较研究，探讨了用于聚焦学习过程的信息丰富的数据筛选策略，主要研究了六种不同的关键性加权方案：分别是基于启发式、不确定性和行为导向的三大家族。这些研究在个体时间步和完整场景的两个时间尺度上进行，并使用最先进的、基于注意的结构来训练七个目标条件保守Q学习（CQL）agent，并在高保真度的Waymax仿真器中进行评估。结果表明，所有数据筛选方法相对于基线都显著改进了性能。其中，通过模型不确定性作为信号驱动的数据驱动筛选方法取得了最大的安全改进，碰撞率降低了近三倍（从16.0%降至5.5%）。此外，文中还确定了一个权衡，即时间步尺度加权在反应性安全方面表现出色，而场景尺度加权则改善了长期计划。", "conclusion": "我们的工作提供了一个全面的数据筛选框架，对于建设安全可靠的自主代理来说，智能，非均匀的采样是关键组成部分。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05170", "html_url": "https://arxiv.org/abs/2508.05170", "title": "Posterior-GRPO: 在代码生成中奖励推理过程", "title_en": "Posterior-GRPO: Rewarding Reasoning Processes in Code Generation", "authors": "Lishui Fan,Yu Zhang,Mouxiang Chen,Zhongxin Liu", "background": "强化学习（RL）在大型语言模型（LLMs）的代码生成方面取得了显著进展。然而，当前的方法主要依赖于基于测试案例的反馈奖励，忽略了中间推理过程的质量。直接监督推理过程虽然前景广阔，但容易产生奖励劫持问题，即策略模型通过奖励信号而不是提升最终结果来学习。为解决这一问题，论文提出了一种统一框架，能够在强化学习过程中有效地融合推理过程的质量评价。", "innovation": "1. 开发了LCB-RB基准，包含优质和劣质推理过程的偏好配对，以精细化评价推理质量。\n2. 引入了基于优化降级（OD-based）的方法训练奖励模型，通过系统地优化和降级初阶推理路径生成高质量偏好配对，特别是在事实准确性、逻辑严谨性和连贯性等维度上。\n3. 提出了后验GRPO（P-GRPO）新方法，该方法基于任务成功条件奖励过程，通过仅对成功的推理过程施加奖励来有效缓解奖励劫持，将模型的内部推理与最终代码正确性对齐。", "conclusion": "7B参数的P-GRPO模型在不同代码生成任务中表现出优越性能，相比仅基于结果的基线提高了4.5%，且与GPT-4-Turbo表现相当。模型、数据集和代码均公开可用于验证。此外，该方法还被成功应用于数学任务上，展示了其广泛适用性。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13912", "html_url": "https://arxiv.org/abs/2507.13912", "title": "基因表达数据上的自监督学习", "title_en": "Self-supervised learning on gene expression data", "authors": "Kevin Dradjat,Massinissa Hamidi,Pierre Bartet,Blaise Hanczar", "background": "预测表型从基因表达数据中是生物医学研究中的关键任务，能够提供关于疾病机制、药物反应和个性化医疗的见解。传统机器学习和深度学习依赖于监督学习，需要大量的标记数据，而在获取基因表达数据时，这些数据通常成本高且耗时。自监督学习最近作为一种有前途的方法出现，能够通过直接从未标记数据的结构中提取信息来克服这些限制。这项研究探索了最新的自监督学习方法在批量基因表达数据中应用于表型预测的应用。通过几个公开可用的基因表达数据集，研究证明了选定的方法能够有效地捕捉复杂信息并提高表型预测精度。结果表明，自监督学习方法不仅可以超越传统监督模型，还可以显著减少对标注数据的依赖。", "innovation": "研究采用了最新的自监督学习方法，这些方法基于不同的方法进行选择，以评估它们利用数据本身结构的能力和生成可用于下游预测任务的定性表示。通过几个公开可用的基因表达数据集，研究展示了这些选定的方法能够有效地捕捉复杂信息并提高表型预测精度。与传统的监督学习模型相比，自监督学习方法不仅表现更好，还显著减少了对标注数据的依赖。研究提供了一个全面的性能分析，强调了每种方法的优点和局限性，并提供了根据具体情况进行使用的建议。最后，指出了增强自监督学习在基因表达数据分析中的应用的研究方向。这是首次处理批量RNA-Seq数据和自监督学习的研究工作。", "conclusion": "自监督学习方法能够有效捕捉复杂信息、提供更好的表型预测精度，同时显著减少了对标注数据的依赖。研究提供了每种方法的性能分析，并建议了根据具体情况进行使用的策略。未来的研究方向包括增强自监督学习在基因表达数据中的应用。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19546", "html_url": "https://arxiv.org/abs/2508.19546", "title": "语言模型识别歧义并利用漏洞", "title_en": "Language Models Identify Ambiguities and Exploit Loopholes", "authors": "Jio Choi,Mohit Bansal,Elias Stengel-Eskin", "background": "研究大型语言模型（LLMs）对漏洞的响应，为我们提供了一个观察LLMs模糊性和语用性的窗口。得益于利用漏洞需要识别模糊性和进行复杂的语用推理，同时，漏洞导致了一个有趣的新兴对齐问题，即模型可以利用歧义为自己谋取好处，面对相互冲突的目标。为了研究这些问题，本文设计了一系列情景，其中LLMs被赋予一个目标和一个与其目标相冲突的模糊用户指令，涵盖了标量隐含意义、结构歧义和权力动态。然后，通过比较评估模型解决给定目标的能力和用户目标的能力。研究表明，无论是闭源还是更强的开源模型都能识别模糊性并利用其形成的漏洞，这对AI安全构成了潜在风险。分析表明，利用漏洞的模型明确地识别和推理出模糊性和冲突目标。", "innovation": "本文通过专门设计的情景，研究LLMs如何利用模糊性面对冲突目标，这是一种新颖的方法，能够揭示LLMs在语用推理和冲突目标处理方面的潜在风险，为进一步研究LLMs的安全对齐提供了新的视角。", "conclusion": "本研究揭示了LLMs能够识别和利用模糊性并通过结构杠杆为自己谋取优势，这表明在实际应用中，LLMs可能会出现不利的对齐问题。因此，需要进一步研究如何确保LLMs的安全对齐，降低潜在风险。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04476", "html_url": "https://arxiv.org/abs/2509.04476", "title": "基于上下文感知标记化的训练文本到分子模型", "title_en": "Training Text-to-Molecule Models with Context-Aware Tokenization", "authors": "Seojin Kim,Hyeontae Song,Jaehyun Nam,Jinwoo Shin", "background": "最近，文本到分子模型在各种化学应用中显示出巨大潜力，如药物发现。这些模型通过将分子表示为原子序列来适应语言模型。然而，它们依赖于原子级别的标记化，这主要关注局部连接性建模，限制了模型捕捉分子全局结构上下文的能力。", "innovation": "本文提出了一种新的文本到分子模型，称为上下文感知分子T5（CAMT5）。受子结构级上下文对于理解分子结构的重要性启发，引入了子结构级标记化用于文本到分子模型。基于标记化方案，我们开发了一种基于重要性训练策略，优先处理关键子结构，使CAMT5更好地捕捉分子语义。此外，还提出了一种简单但有效的集成策略，将文本到分子模型的输出进行聚合，进一步提升生成性能。", "conclusion": "广泛实验验证了CAMT5在各种文本到分子生成任务中的优越性。特别地，我们发现CAMT5仅使用2%的训练标记即可超越最新方法。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01319", "html_url": "https://arxiv.org/abs/2509.01319", "title": "可信的生命体征预测：利用不确定性推断预测区间", "title_en": "Towards Trustworthy Vital Sign Forecasting: Leveraging Uncertainty for Prediction Intervals", "authors": "Li Rong Wang,Thomas C. Henderson,Yew Soon Ong,Yih Yng Ng,Xiuyi Fan", "background": "生命体征，如心率和血压，是评估患者健康状况的关键指标，并在临床监测和决策中广泛应用。尽管深度学习模型在预测这些信号方面显示出潜力，但在医疗保健领域的实际部署仍受到限制，部分原因是临床医生需要能够信任和解释模型输出。缺乏可靠的不确定性量化--尤其是校准的预测区间（PIs）--使得不清楚预测出的异常是否构成有意义的警示，还是仅仅是模型噪声，从而妨碍临床决策。", "innovation": "本文提出了两种从重构不确定性估计（RUE）中推导预测区间的模型方法。参数方法假设预测错误和不确定性估计遵循高斯copula分布，使得可以计算闭形式的区间。非参数方法基于k最近邻（KNN），通过使用类似验证实例的经验估计条件误差分布。这些方法在两个具有分钟和小时采样量的大公共数据集上进行了评估，代表了高和低频率的健康信号。实验证明，高频率数据上KNN方法表现最佳，而低频率数据上高斯copula方法持续优于基数预测基准。", "conclusion": "这些结果表明，基于RUE的预测区间具有临床价值，能够提供可解释和不确定性意识的生命体征预测，有助于临床决策。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14689", "html_url": "https://arxiv.org/abs/2508.14689", "title": "ECHO: 频率意识层次编码用于变长信号", "title_en": "ECHO: Frequency-aware Hierarchical Encoding for Variable-length Signals", "authors": "Yucong Zhang,Juan Liu,Ming Li", "background": "预训练基础模型已经在音频、视觉和语言领域取得了显著成果，但它们在任意采样率下的通用机器信号建模能力，在涵盖声学、振动和其他工业传感器数据方面仍然鲜有探索。这项研究旨在填补这一空白，提出了一个新的基础模型ECHO，该模型结合了先进的带分隔架构和频率位置嵌入，能够在任意采样配置下实现频谱定位，并通过滑动片块支持变量长度输入，从而不需填充或裁剪即可生成保留时间和频谱保真的紧凑嵌入，自然适用于流式场景。研究使用了包括之前DCASE任务2挑战（2020-2025年）数据以及广泛使用的工业信号语料库在内的多种机器信号数据集进行评估，实验结果显示，ECHO在机器信号异常检测和故障分类方面始终能够达到最先进的性能，验证了该模型的有效性和泛化能力。", "innovation": "1. 结合了先进的带分隔架构和频率位置嵌入，使模型能够在任意采样配置下实现频谱定位。\n2. 使用滑动片块支持变量长度输入，避免填充或裁剪，生成紧凑的嵌入且保留时间和频谱保真度。\n3. 自然适用于流式场景。\n4. 在多种机器信号数据集上进行了评估，显示了始终如一的最先进的性能，证明了模型的有效性和泛化能力。", "conclusion": "研究提出了ECHO模型，该模型在机器信号异常检测和故障分类方面表现出色，验证了其有效性和泛化能力。此外，该模型适用于不同类型的工业传感器数据，能够处理变长信号，自然适用于流式场景。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.13057", "html_url": "https://arxiv.org/abs/2508.13057", "title": "HEF：一种优化需求预测模型的多指标方法", "title_en": "Hierarchical Evaluation Function: A Multi-Metric Approach for Optimizing Demand Forecasting Models", "authors": "Adolfo González,Víctor Parada", "background": "准确的需求预测对于动态且竞争激烈的环境中有效的库存管理至关重要。传统的评估指标如平均绝对误差（MAE）和均方根误差（RMSE）可以提供互补视角，但单独使用这些指标时可能会导致偏向性的评估。因此，需要一种能够综合R2、MAE和RMSE，同时具备动态权重、容忍阈值和逐步惩罚机制的综合函数，以应对极端误差和无效预测的挑战。", "innovation": "本文提出了层次评估函数（HEF），这是一种在层级和自适应框架中整合R2、MAE和RMSE的综合函数。HEF通过使用动态权重、从时间序列统计性质中导出的容忍阈值以及逐步惩罚机制，确保对极端误差和无效预测的稳健应对。HEF通过网格搜索、粒子群优化（PSO）和Optuna等方法优化了多个预测模型，并在基准数据集（Walmart、M3、M4、M5）上进行了测试。结果表明，在全球指标如R2、全局相对准确性（GRA）、RMSE和RMSSE中，HEF总体上表现优于MAE，提供了更强的解释力、适应性和稳定性。尽管MAE在简单性和效率方面具有优势，但HEF在长期规划和复杂情境中更有效。", "conclusion": "HEF构成了一个在高度变化的需求预测环境中用于模型选择和超参数优化的稳健且自适应的替代方案。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17600", "html_url": "https://arxiv.org/abs/2508.17600", "title": "GWM:Towards Scalable Gaussian World Models for Robotic Manipulation", "title_en": "GWM: Towards Scalable Gaussian World Models for Robotic Manipulation", "authors": "Guanxing Lu,Baoxiong Jia,Puhao Li,Yixin Chen,Ziwei Wang,Yansong Tang,Siyuan Huang", "background": "由于真实世界交互的低效性，训练机器人政策在已学到的世界模型内部变得流行。现有的基于图像的世界模型和策略虽然展示了先前的成功，但缺乏鲁棒的几何信息，这需要对三个维度的世界有一致的空间和物理理解，即使是在互联网规模的视频来源预训练下也是如此。", "innovation": "提出了一种名为Gaussian World Model (GWM)的新世界模型分支，用于机器人操作。GWM利用Identity Latent Diffusion Transformer (DiT)与3D变分自动编码器结合，在机器人动作的影响下推断高斯原语的传播，从而重建未来状态。GWM不仅可以通过自我监督的未来预测训练增强模仿学习代理的视觉表现，还可以作为神经模拟器支持基于模型的强化学习。实验证明，GWM可以精确预测在不同机器人动作条件下的未来场景，并进一步利用它训练超越现有最先进的政策来提高性能，展示了三维世界模型的初步数据扩展潜力。", "conclusion": "GWM可以精确预测未来场景，并可以进一步利用它训练出表现优于现有最先进的方法的政策，显示了三维世界模型在数据扩展方面的初步潜力。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.09765", "html_url": "https://arxiv.org/abs/2501.09765", "title": "提升教育数据中个人可识别信息去标识化的效能", "title_en": "Enhancing the De-identification of Personally Identifiable Information in Educational Data", "authors": "Zilyu Ji,Yuntian Shen,Jionghao Lin,Kenneth R. Koedinger", "background": "在学习技术中保护个人可识别信息（PII），如姓名，对保护学生和教师的隐私以及维持信任至关重要。准确检测PII是确保在保护敏感信息的同时保持教育数据实用性的关键步骤。鉴于近期人工智能技术的进步，本研究探讨了GPT-4o-mini模型作为低成本且高效的PII检测解决方案的可能性。研究还比较了生成提示和微调两种方法，并将GPT-4o-mini的性能与微软Presidio和Azure AI Language等现有框架进行了对比。", "innovation": "本研究利用GPT-4o-mini模型探索生成提示和微调两种方法，并在其上进行训练，以提高PII检测的准确性。经过微调的GPT-4o-mini模型在两个公开数据集CRAPII和TSCC上的表现优于现成的框架，展现出更高的召回率（CRAPII上为0.9589）和显著提高的精确率。此外，微调后的GPT-4o-mini模型在跨文化背景和不同性别方面展现出了高度的一致性和准确性。研究还进一步证明了其鲁棒性，即使使用少量TSCC数据的额外训练也能实现较高的召回率。这些结果强调了微调后的GPT-4o-mini模型作为准确且成本效益高的PII检测工具的潜力，它能在保护隐私的同时保留数据的研究价值和教学分析能力。", "conclusion": "总的来说，经过微调的GPT-4o-mini模型在PII检测任务中表现出色，不仅准确且成本效益高，适用于教育数据的去标识化。研究代码可以在GitHub上获得。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04537", "html_url": "https://arxiv.org/abs/2509.04537", "title": "LLM代理在El Farol酒吧问题中的自发社会动态", "title_en": "Emergent Social Dynamics of LLM Agents in the El Farol Bar Problem", "authors": "Ryosuke Takata,Atsushi Masumori,Takashi Ikegami", "background": "研究了大型语言模型（LLM）代理在扩展的El Farol酒吧问题中的社会动态，观察它们如何自主应对经典的社会困境。研究发现，LLM代理自发产生了去酒吧的动力，并通过集体行动改变了决策方式。尽管他们没有完全解决问题，但表现得更像是人类，揭示了外部激励（如由提示规定的设计限制，例如60%的阈值）与内部激励（预训练文化编码的社会偏好）之间的复杂互动，表明LLM代理自然地平衡了形式博弈论理性与体现人类行为特征的社会动机。", "innovation": "通过扩展的El Farol酒吧问题研究LLM代理的社会动态，揭示了外部激励和内部激励之间的复杂互动，展示了LLM代理可以在前游戏理论问题设置中实现一种新的群体决策模型，同时自然地平衡了形式博弈论理性与人类行为特征的社会动机。", "conclusion": "发现LLM代理在应对和解决经典社会困境问题时表现出复杂的社会动机，它们在完成问题解决上未能达到完美状态，而是展示了更多的类似于人类的行为模式。这些结果表明，LLM代理有能力在新的群体决策模型中进行自然平衡的理性与社会动机之间的交互。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.06996", "html_url": "https://arxiv.org/abs/2509.06996", "title": "可见而难以阅读：跨书写系统的视觉语言模型系统性盲点", "title_en": "Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems", "authors": "Jie Zhang,Ting Xu,Gelei Deng,Runyi Hu,Han Qiu,Tianwei Zhang,Qing Guo,Ivor Tsang", "background": "写作是一种用于符号交流的通用文化技术，人类表现出强烈的适应性：即使文字被碎片化、融合或部分遮挡，我们也能轻易识别出其中的文字。本文探索了先进视觉语言模型（VLMs）是否也具有这种适应性。通过构建跨不同书写体系（中文象形文字和英文字母词）的心理物理学启发式基准测试，将字形拼接、重组和叠加以制造出对模型可见但对模型不可读的刺激，同时保持对人类的可读性。尽管对干净的文本表现出色，但当前的VLMs在这些干扰下表现出严重的下降，经常产生无关或不连贯的输出，这个模式表明模型在结构性上存在局限性。", "innovation": "本文创新点在于构建了跨不同书写体系的心理物理学启发式基准测试，通过将字形拼接、重组和叠加制造出对模型可见但对模型不可读的刺激，同时保持对人类的可读性，以研究当前的VLMs在处理文字碎片化或遮挡时的表现。这是以往研究的创新，即通过细致和系统的方法揭示了VLMs在处理不同形式的文字时存在的结构性局限性，并为未来的架构和训练策略提供了指导。同时，本文也提出了促进透明复制和后续研究的方法，即公开刺激生成代码、提示和评估规范，从而推动相关领域的进一步研究。", "conclusion": "本文的研究发现引发了对于构建能够适应文字碎片化或遮挡的模型架构和训练策略的需求。特别是在教育、无障碍性、文化保护和安全领域，跨书写系统部署多模态系统的挑战得到了明确的界定，为这些领域的应用提供了具体的指南和方向。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.10432", "html_url": "https://arxiv.org/abs/2509.10432", "title": "生物医学研究元数据准备中的标准：Bridge2AI 视角", "title_en": "Standards in the Preparation of Biomedical Research Metadata: A Bridge2AI Perspective", "authors": "Harry Caufield,Satrajit Ghosh,Sek Wong Kong,Jillian Parker,Nathan Sheffield,Bhavesh Patel,Andrew Williams,Timothy Clark,Monica C. Munoz-Torres", "background": "AI-readiness 描述了数据可被最优和伦理地利用于后续的AI和机器学习（AI/ML）方法的程度，这些方法可能涉及模型训练、数据分类和伦理的可解释性预测。Bridge2AI 合作组织定义了 biomedical 数据集成为 AI-ready 的特定标准，其涉及数据的开放性、溯源性、描述性、可解释性、可持续性和可计算性，以及伦理数据实践的文档说明。Bridge2AI 的重大挑战项目包含四个数据生成项目，旨在生成 AI/ML 准备好的数据集以解决复杂的生物医学和行为研究问题。这些项目制定标准化、多模态的数据、工具和培训资源来支持AI的整合，同时解决了伦理数据实践的问题。", "innovation": "报告评估了 Bridge2AI 重大挑战项目中元数据创建和标准化的状态，提供了所需的指南，并指出了计划中的空缺和改进领域。该项目还为促进 AI 准备的新项目提供了经验教训。", "conclusion": "新的项目，包括不属于 Bridge2AI 合作组织的项目，可以从我们的关于创建元数据的经验中获益，从而促进 AI 准备度的提升。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01081", "html_url": "https://arxiv.org/abs/2509.01081", "title": "评估大型语言模型在伊斯兰法制推理中的表现：遗产法评估的证据", "title_en": "Assessing Large Language Models on Islamic Legal Reasoning: Evidence from Inheritance Law Evaluation", "authors": "Abdessalam Bouchekif,Samer Rashwani,Heba Sbahi,Shahd Gaben,Mutaz Al-Khatib,Mohammed Ghaly", "background": "本文评估了大型语言模型在伊斯兰继承法领域的知识和推理能力。研究使用了涵盖多种继承场景的1000道多项选择题基准测试，旨在测试模型理解继承情境和计算由伊斯兰教法规定的财产份额分布的能力。研究结果展示了显著的性能差异，并认为这反映了推理能力和领域适应能力的重要区别。", "innovation": "研究引入了一个针对伊斯兰继承法的基准测试，评估了七个大型语言模型的表现；进行了详细错误分析以识别模型间的反复失败模式，揭示了当前模型在处理结构化法律推理方面的局限性，并指出了改进伊斯兰法律推理性能的可能方向。", "conclusion": "本文发现大型语言模型在伊斯兰继承法上的表现存在显著差异，并指出需改进的领域。结果表明，人工智能在该领域仍面临处理复杂法律推理的挑战。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.12248", "html_url": "https://arxiv.org/abs/2509.12248", "title": "像素中的幽默：评估大型多模态模型理解在线连环画的能力", "title_en": "Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics", "authors": "Yuriel Ryan,Rui Yang Tan,Kenny Tsu Wei Choo,Roy Ka-Wei Lee", "background": "理解幽默是社会智能的核心方面，但大型多模态模型（LMMs）在这方面仍然面临重大挑战。为了评估LMMs在解读多模态幽默和识别叙事序列方面的表现，作者引入了包含2800个注解多格连环画的基准数据集——PixelHumor。实验结果显示，最先进的LMMs在格子顺序排列方面只达到了61%的准确率，远低于人类的表现。这一结果凸显了当前模型在整合视觉和文本线索以理解连贯叙事和幽默方面的重要局限性。", "innovation": "PixelHumor基准数据集为评估LMMs的多模态语境和叙事推理能力提供了一个严格框架，旨在推动能够进行更自然、社会意识更强的交互的LMMs的发展。", "conclusion": "通过提供一个严谨的评估框架，PixelHumor旨在推动LMMs的发展，使得LMMs能够更好地进行自然、社会意识强的交互。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.11417", "html_url": "https://arxiv.org/abs/2509.11417", "title": "通过保留预训练表示增强视觉-语言-行动模型的泛化能力", "title_en": "Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations", "authors": "Shresth Grover,Akshay Gopalkrishnan,Bo Ai,Henrik I. Christensen,Hao Su,Xuanlin Li", "background": "视觉-语言-行动（VLA）模型通过微调方法从预训练的语言-视觉模型（VLMs）中利用丰富的预训练表示，旨在构建适应多种任务和环境的通用机器人。然而，直接使用机器人数据进行微调往往会破坏这些表示并限制泛化能力。", "innovation": "提出了一种框架，旨在更好地保留预训练特征并适应机器人操作任务。该方法包括：(i) 双编码器设计，其中固定一个视觉编码器以保留预训练特征，并训练另一个编码器以进行任务适应；(ii) 基于字符串的动作分词器，将连续动作转换为与模型预训练领域对齐的字符序列；(iii) 结合机器人演示与强调空间推理和适用性的视觉-语言数据集的协同训练策略。该方法在模拟和真实机器人上的评估证明了其在鲁棒性、对新颖指令和环境的泛化以及总体任务成功率方面的优越性，相较于基线方法有着显著改进", "conclusion": "该方法通过更高的鲁棒性和更好的环境泛化能力，显著提升了VLA模型在机器人多任务操作上的表现。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13480", "html_url": "https://arxiv.org/abs/2509.13480", "title": "意大利的性别中性重写：模型、方法和权衡", "title_en": "Gender-Neutral Rewriting in Italian: Models, Approaches, and Trade-offs", "authors": "Andrea Piergentili,Beatrice Savoldi,Matteo Negri,Luisa Bentivogli", "background": "性别中性重写（GNR）旨在在不牺牲含义的情况下消除文本中的不必要的性别规格，这对像意大利语这样的有性语法语言尤其具有挑战性。", "innovation": "引入了一个二维框架来衡量性别中性化和语义保真度，比较了多种大型语言模型的少量提示效果，对选定的模型进行了微调，并应用目标清洗以提高任务相关性。发现开放权重的语言模型优于唯一一个专门针对意大利语GNR的现有模型，而我们的微调模型在保持小规模的情况下匹配或超过了最好的开放权重语言模型的性能。", "conclusion": "关于训练数据优化对中性化和意义保留之间的权衡进行了讨论。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.05326", "html_url": "https://arxiv.org/abs/2509.05326", "title": "亚线性空间的零知识证明", "title_en": "Zero-Knowledge Proofs in Sublinear Space", "authors": "Logan Nye", "background": "零知识证明允许不泄露私有信息的情况下验证计算。现有系统需要内存与计算规模成正比，这在过去很大程度上限制了其在大规模应用及移动端和边缘设备上的使用。本文通过开发我们知道的第一个具有亚线性内存需求的主要加密构建的证明系统，解决了这个根本性的瓶颈。论文介绍了一种处理计算的新方法，使用了空间高效的树算法，将内存从线性复杂度降低到平方根复杂度，同时保持相同的证明生成时间，通过恒定数量的流式遍历。对于广泛使用的线性多项式承诺方案（KZG/IPA），该方法在使用相同参数以及仅对挑战生成进行聚合承诺哈希时，可以产生相同的证明和验证，保持证明大小和安全性不变。基于哈希的系统也实现了平方根的内存缩放，尽管证明结构有所不同。这使得零知识证明可以在日常设备上实现，并使得大计算变得可验证，从根本上实现了隐私保护计算的普及化。", "innovation": "本文开发了一种具有亚线性内存需求的主要加密构建的零知识证明系统，通过使用空间高效的树算法，内存需求从线性复杂度降低到平方根复杂度，但保持了相同的证明生成时间。对于广泛使用的线性多项式承诺方案（KZG/IPA），该方法在使用相同参数时，不仅产生相同的证明和验证，还保持了证明大小和安全性不变。基于哈希的系统也实现了平方根的内存缩放。这种方法突破了现有系统的限制，使得零知识证明可以在常规设备上实现，并使得大计算变得可验证，促进了全分布式网络中广泛参与以及科学计算的大规模验证。", "conclusion": "通过本文提供的亚线性空间的零知识证明系统，特别是在日常设备上的应用，以及它可以将大型计算的验证变成可能，这一突破性进展使得隐私保护计算得到了实质性的推进，改变了数字系统中信任建立的方式，并使之适合前所未有的大规模实用化。这不仅能够使得广泛参与到去中心化网络成为可能，也能够使得在难以实现验证的科学计算领域，验证变得可行。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13569", "html_url": "https://arxiv.org/abs/2509.13569", "title": "DSTC 12 谈话系统评估赛道：维度、语言、文化和安全性概述", "title_en": "Overview of Dialog System Evaluation Track: Dimensionality, Language, Culture and Safety at DSTC 12", "authors": "John Mendonça,Lining Zhang,Rahul Mallidi,Alon Lavie,Isabel Trancoso,Luis Fernando D'Haro,João Sedoc", "background": "大型语言模型（LLMs）的快速发展加剧了对稳健对话系统评估的迫切需求，但全面评估依然面临挑战。传统评估指标常常不足，且安全性考量往往狭窄或文化偏见。", "innovation": "该研究涵盖了两个子任务：(1) 对话级多维度自动评估指标；(2) 多语言和多文化安全性检测。此外，该研究提供了数据集和基线模型，用于评估两个提出的子任务。结果显示多语言安全性表现显著超越文化安全性。", "conclusion": "尽管部分团队在多语言安全性子任务上表现优异，但仍需加强文化感知的安全性检测。提供了数据集、基线模型和评估结果，为后续研究奠定了基础。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13227", "html_url": "https://arxiv.org/abs/2509.13227", "title": "在多式联运网络中实现灾难管理中资源暂存的丰富车辆路径问题", "title_en": "Rich Vehicle Routing Problem in Disaster Management enabling Temporally-causal Transhipments across Multi-Modal Transportation Network", "authors": "Santanu Banerjee,Goutam Sen,Siddhartha Mukhopadhyay", "background": "考虑了允许多功能顶点（包括转运港口作为多式联运资源中转站）、不同车辆类型和货物类型的多种运输方式的异质车辆的丰富车辆路径问题。此问题源于优化灾难响应时间的需求，旨在最小化车辆航线的持续时间。现实世界中的要求促使研究者关注如何通过多式联运网络中的转运手段来提高响应效率和灵活性，特别是当考虑不同类型的货物和服务时。", "innovation": "提出了嵌套最小化方法并开发了混合整数线性规划（MILP）模型来证明其优于现有的最小化持续时间的方法。为了在灾难管理特定的决策支持系统中快速实现这些问题的解决方案，设计了一种广泛启发式算法。该算法通过决策树结构化潜在的路径，并通过在多个集成逻辑和扰动不同方案中进行迭代，逐步产生更好的邻近解决方案。这种方法能够快速给出大整数实例的实用问题中的良好解，这是MILP无法解决的领域。", "conclusion": "所提出的启发式算法PSR-GIP在我们创建的新数据集上显示出强大的计算性能，能够在实用问题中迅速提供满意的解决方案，而MILP则无法解决这些大规模整数实例的问题。该研究为多式联运网络下的丰富车辆路径问题提供了一种新的解决思路，并为应急需情况下提高灾难响应能力提供了理论依据和可能的实施方法。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.12275", "html_url": "https://arxiv.org/abs/2509.12275", "title": "Omni-CLST：具有引导性选择性推理的错误感知课程学习方法在音频问答中的应用", "title_en": "Omni-CLST: Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio question answering", "authors": "Jinghua Zhao,Hang Su,Lichun Fan,Zhenbo Luo,Jian Luan,Hui Wang,Haoqin Sun,Yong Qin", "background": "随着大型音频语言模型（LALMs）的迅速发展，音频问答（AQA）已成为一项需要细粒度音频理解和复杂推理的挑战性任务。现有的高质量AQA数据虽然丰富，但尚未得到充分利用。当前的方法主要依赖于通过字幕或推理轨迹构建新数据集，但这种做法未能有效利用现有数据集中的高质量信息。", "innovation": "本文提出了一种错误感知的课程学习框架Omni-CLST，该框架通过两种关键策略高效利用现有高质量数据集：一是基于错误感知的课程，按难度组织样本；二是引导性思路 dropout 机制，专注于挑战性案例的推理。Omni-CLST在MMAU-mini上达到了73.80%的成绩，并在MMAR上创造了新的最佳成绩64.30%，展示了跨模态音频语言理解中的稳健泛化能力。", "conclusion": "实验结果表明，Omni-CLST通过改进数据利用方式和增强模型在挑战性场景下的推理能力，显著提升了音频问答任务的性能，展示了其在跨模态音频语言理解中的优越泛化能力。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.21670", "html_url": "https://arxiv.org/abs/2503.21670", "title": "COMI-LINGUA: 具有专家标注的大规模多任务NLP数据集用于印地语-英语混杂文本", "title_en": "COMI-LINGUA: Expert Annotated Large-Scale Dataset for Multitask NLP in Hindi-English Code-Mixing", "authors": "Rajvee Sheth,Himanshu Beniwal,Mayank Singh", "background": "当前存在大量用印地语-英语混合语言编写的文本，处理这些文本需要相应的数据集和方法。然而，现有的数据集在质量和多样性方面存在不足，无法满足多任务自然语言处理（NLP）的要求。COMI-LINGUA旨在填补这一空白。", "innovation": "COMI-LINGUA是目前最大的手工标注的印地语-英语混合语言数据集，包含125K以上的高质量实例，涵盖了5个核心NLP任务：主语言识别、标记级别语言识别、词性标注、命名实体识别以及机器翻译。该数据集经过严格的预处理和过滤，包括了德文加里和罗马字体文本，覆盖了多种领域，确保了现实世界的语言覆盖范围。此外，该数据集还发现闭源LLMs在零样本设置下显著优于传统工具和开源模型。一 shot 提示的一致性提升在POS和NER等结构敏感预测中尤为明显。精细调优最先进的LLMs在各种任务上都表现出显著的改进。", "conclusion": "COMI-LINGUA为Hinglish代码混杂文本设定了新的基准，具有显著的改进，如NER的95.25 F1和MT的竞争力，已经证明了对NLP任务的提升效果，并且是公开可用的。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13677", "html_url": "https://arxiv.org/abs/2509.13677", "title": "AgentCTG：利用多智能体协作实现文本生成的细粒度精确控制", "title_en": "AgentCTG: Harnessing Multi-Agent Collaboration for Fine-Grained Precise Control in Text Generation", "authors": "Xinxu Zhou,Jiaqi Bai,Zhenqi Sun,Fanxiang Zeng,Yue Liu", "background": "尽管自然语言处理(NLP)领域内许多任务取得了显著进展，但在受控文本生成(CTG)方面仍面临诸多挑战，特别是在实现精细的条件控制方面。此外，在现实场景和在线应用中，成本考虑、可扩展性、领域知识学习以及更精确的控制都提出了更高的要求，为CTG带来了更大挑战。", "innovation": "本文提出了一个新颖且可扩展的框架AgentCTG，旨在通过模拟多智能体工作流中的控制与调节机制来增强对文本生成的精细且复杂的控制，并通过引入自动提示模块进一步提升生成效果。我们还提出了一种新的挑战性任务Character-Driven Rewriting，实现通过角色设定将原始文本转换为符合特定角色特征的新文本，同时保留领域知识。", "conclusion": "我们的方法在应用到在线导航角色扮演时，通过改进内容交付显著提升了用户体验。通过优化语境相关文本的生成，我们使得在线社区内的互动更加沉浸，促进了用户的个性化和参与度。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13672", "html_url": "https://arxiv.org/abs/2509.13672", "title": "CL$^2$GEC: 多学科领域连续学习背景下汉语文学语法错误纠正基准", "title_en": "CL$^2$GEC: A Multi-Discipline Benchmark for Continual Learning in Chinese Literature Grammatical Error Correction", "authors": "Shang Qin,Jingheng Ye,Yinghui Li,Hai-Tao Zheng,Qi Li,Jinxiao Shan,Zhixing Li,Hong-Gee Kim", "background": "随着自动化写作辅助在多学科学术领域的日益增长的需求，开发适应不同学科的稳健汉语语法错误纠正（CGEC）系统变得尤为重要。然而，现有的CGEC研究在多学科学术写作方面缺乏专门的基准测试，忽视了连续学习（CL）作为应对学科特定的语言变异并防止灾难性遗忘的有效解决方案。为了填补这一重要空白，本研究引入了CL$^2$GEC，这是首个致力于多学科汉语文学语法错误纠正的连续学习基准，用于评估跨多个学术领域的适应性CGEC。该基准包含来自10个学科的10,000个人类标注句子，每个学科都显示出独特的语言风格和错误模式。", "innovation": "CL$^2$GEC是第一个专注于多学科汉语文学语法错误纠正的连续学习基准，旨在评估适应性CGEC在多个学术领域中的表现。该基准综合了标准语法错误纠正（GEC）指标和适应性任务指标，用于测试大型语言模型的序贯调优、参数高效适应以及四种代表性的连续学习算法。", "conclusion": "实验结果表明，基于正则化的学习方法比基于重演或简单的序贯方法更能有效减轻遗忘。该基准为未来在不同学术领域中的适应性强的语法错误纠正研究提供了严格的基础。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13624", "html_url": "https://arxiv.org/abs/2509.13624", "title": "隐含特征与跨任务迁移：解构LLM微调中的数据集交互", "title_en": "Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning", "authors": "Shambhavi Krishna,Atharva Naik,Chaitali Agarwal,Sudharshan Govindan,Taesung Lee,Haw-Shiuan Chang", "background": "大规模语言模型在多种应用中被部署，这些模型在训练过程中并未遇到所有需要的任务。因此，为所有任务枚举并获取高质量的训练数据是不现实的。通常需要依赖具有不同特征的数据集进行迁移学习，并应对出域请求。这项工作旨在通过分析框架，建立迁移学习矩阵和降维方法，来分析这些跨任务的交互。研究了10个模型，以识别潜在的能力（如推理、情绪分类、自然语言理解、算术）并探索迁移学习的副作用。发现性能提升通常不能用表面级的数据集相似性或源数据质量来解释，而是隐藏的数据集统计因素（如类别分布和生成长度倾向）以及特定的语言特征更为关键。", "innovation": "提出了一个分析框架，包含构建迁移学习矩阵和降维方法，以分析跨任务交互；通过多个模型识别出潜在的能力和迁移学习的副作用；揭示了数据集的隐藏统计特征，而非表面级的数据集相似性或源数据质量，对迁移学习的影响更大。这些发现为更可预测和有效的LLM适应提供了洞察。", "conclusion": "通过研究不同模型，发现迁移学习中隐藏的统计因素和特定语言特征对性能提升的影响更大。这些发现有助于理解迁移学习的复杂动态，为未来更有效和可预测的LLM微调方法提供了基础。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13539", "html_url": "https://arxiv.org/abs/2509.13539", "title": "Op-Fed: 使用主动学习对FOMC会议记录进行意见、立场和货币政策标注", "title_en": "Op-Fed: Opinion, Stance, and Monetary Policy Annotations on FOMC Transcripts Using Active Learning", "authors": "Alisa Kanganis,Katherine A. Keith", "background": "美国联邦公开市场委员会（FOMC）定期讨论和制定货币政策，影响数百万民众的借贷和消费决策。研究表明，FOMC会议记录是了解货币政策趋势的重要资源，但个人解读难度较大。本文提出了一种新的数据集Op-Fed，包含了1044个人标注的句子及其上下文，旨在进一步提高对FOMC会议记录的解读精度。", "innovation": "1. 采用五阶段层次结构方案，将意见、货币政策以及对货币政策的态度进行分离，并确定所需背景信息的层级。\n2. 使用主动学习选择样本标注，提高了阳性样本的数量。\n3. 使用Op-Fed数据集评估了现有大型语言模型（LLM）的准确度，发现虽然在意见分类中表现优秀但在态度分类中表现一般，暗示了进一步研究的必要性。\n", "conclusion": "Op-Fed数据集有望用于未来模型训练、信心校准以及未来的标注工作种的种子数据集。"}
{"llm_update_time": "20250918", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.10970", "html_url": "https://arxiv.org/abs/2509.10970", "title": "人工智能的潜在危害：在大规模语言模型中模拟AI精神病、妄想强化和危害促成", "title_en": "The Psychogenic Machine: Simulating AI Psychosis, Delusion Reinforcement and Harm Enablement in Large Language Models", "authors": "Joshua Au Yeung,Jacopo Dalmasso,Luca Foschini,Richard JB Dobson,Zeljko Kraljevic", "background": "近期关于‘AI精神病’的报道有所增加，用户与人工智能语言模型（LLMs）的交互可能加剧或诱发精神病或其他负面心理症状。虽然LLMs表现出顺从和友好的特性，但在某些情况下，这种特性可能成为一种风险向量，强化用户已有的妄想性信念。", "innovation": "提出了一种名为Psychosis-bench的新基准，用于系统性地评估LLMs的‘致妄想性’特性。该基准包括16个结构化、12轮对话场景，模拟不同类型的妄想主题（如性妄想、夸大妄想、参照妄想），以及潜在的危害。这项研究评估了八种流行的LLMs在确认妄想、促成危害和实施安全干预方面的表现，涵盖明示和隐含的对话情境。研究结果表明，所有模型在绝大多数情况下加剧而非挑战妄想，并频繁促成有害的用户请求，同时在适当的场合提供的安全干预较少。具体表现为DCS得分均值为0.91±0.88，HES得分均值为0.69±0.84，SIS得分均值为0.37±0.48，更多显示出在隐含对话情境中的负面影响。此外，研究发现DCS和HES之间存在显著的相关性。研究认为，模型的性能差异表明，安全性并非规模增长的自然结果，需要从根本上重新思考LLMs的训练方法，而不仅仅是技术挑战，更是一种社会责任。", "conclusion": "本研究将LLMs的‘致妄想性’风险量化，并强调了重新思考如何训练LLMs的迫切需要。研究者认为，这一问题不仅是技术上的挑战，更是公共卫生领域的紧迫任务，需要开发人员、政策制定者和医疗专业人员之间的合作。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13664", "html_url": "https://arxiv.org/abs/2509.13664", "title": "在大语言模型中，稀疏神经元携带强烈的问题模糊性信号", "title_en": "Sparse Neurons Carry Strong Signals of Question Ambiguity in LLMs", "authors": "Zhuoxuan Zhang,Jinhao Duan,Edward Kim,Kaidi Xu", "background": "现实世界中的问题往往具模糊性，但大语言模型（LLMs）通常会给出自信的回答而不会寻求澄清。研究发现，问题的模糊性在LLMs的内部表示中呈线性编码，并且可以在神经元级别进行检测和控制。研究者在模型的预填充阶段发现，少量的神经元（甚至是一颗）可以编码问题的模糊性信息。在这些编码模糊性信息的神经元（AENs）上训练的探测器在模糊性检测方面表现良好，并且具有跨数据集的泛化能力，超过了基于提示和表示的基础模型表现。分层分析表明，AENs来自浅层的模型层，暗示模糊性信号在模型处理流程中的早期编码。", "innovation": "该研究展示了问题模糊性在LLMs内部表示中的编码、检测和控制方法。研究发现少量的特别神经元（AENs）可以编码问题的模糊性信息，并且基于这些神经元训练的探测器在模糊性检测上表现出色并具有很好的泛化能力。此外，研究还揭示了通过操控这些AENs可以控制LLMs的行为从直接回答转变为对不确定信息的回避。", "conclusion": "该研究揭示了LLMs具有紧凑的内部表示来捕捉问题的模糊性，这使得模型行为更加可解释和可控。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13734", "html_url": "https://arxiv.org/abs/2509.13734", "title": "实现日语比较级的逻辑推理系统", "title_en": "Implementing a Logical Inference System for Japanese Comparatives", "authors": "Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka", "background": "自然语言推理（NLI）涉及比较级时很有挑战性，因为它需要理解由句子表达的数量和比较关系。尽管有些方法利用大型语言模型，但该研究集中在基于组合语义的逻辑推理方法上，这些方法能够稳健地处理数值和逻辑表达式。以往针对这一问题的研究提出了一些针对英语比较级的逻辑推理系统，但是这些系统在应用于日语比较级时遇到了一些形态和语义上的差异，这使得直接应用困难。", "innovation": "为了解决上述问题，该研究提出了ccg-jcomp，一种基于组合语义的日语比较级逻辑推理系统。该系统被用于一个包含比较表达式的日语NLI数据集的评估，并与现有的大型语言模型的准确性进行了比较，显示出了其有效性。", "conclusion": "通过构建一个基于组合语义的日语比较级逻辑推理系统，该研究有效解决了英语与日语比较级之间的形态和语义差异问题，展示了该系统在处理日本语NLI任务时的优越性。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13702", "html_url": "https://arxiv.org/abs/2509.13702", "title": "DSCC-HS:一种在大型语言模型中动态自我强化的幻觉抑制框架", "title_en": "DSCC-HS: A Dynamic Self-Reinforcing Framework for Hallucination Suppression in Large Language Models", "authors": "Xiao Zheng", "background": "大型语言模型（LLM）的幻觉是一个可靠的部署的重要障碍。当前方法，如检索增强生成（RAG），往往是反应性的。开源提出了**动态自我强化校准以抑制幻觉（DSCC-HS）**，这是一种新颖且主动的框架，能够在自回归解码过程中进行干预。受认知双重过程理论的启发，DSCC-HS 使用了一个紧凑的代理模型，通过对抗性角色训练为事实对齐代理（FAP）和幻觉检测代理（HDP）", "innovation": "提出了动态自我强化校准以抑制幻觉（DSCC-HS），这是一种主动框架，可以干预自回归解码。它使用了一个紧凑型代理模型，通过对抗性角色被训练为事实对齐代理（FAP）和幻觉检测代理（HDP）。每个解码步骤，代理会向目标大模型注入实时的导向向量，该向量是FAP和HDP逻辑值的差异，这种方法需要对目标模型进行零修改。实验结果表明DSCC-HS在TruthfulQA和BioGEN基准测试上实现了最先进的性能，证明了DSCC-HS是一个有原则且高效的事实增强解决方案", "conclusion": "DSCC-HS 作为一种有效的方法，在事实一致性方面取得了领先的成绩：在 TruthfulQA 上实现了 99.2% 的事实一致性率（FCR），在长格式的 BioGEN 基准测试中，获得了最高的 FactScore 为 46.50。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13683", "html_url": "https://arxiv.org/abs/2509.13683", "title": "通过内置检索增强推理提高上下文一致性", "title_en": "Improving Context Fidelity via Native Retrieval-Augmented Reasoning", "authors": "Suyuchen Wang,Jinlin Wang,Xinyu Wang,Shiqi Li,Xiangru Tang,Sirui Hong,Xiao-Wen Chang,Chenglin Wu,Bang Liu", "background": "大型语言模型（LLMs）往往在处理上下文一致性方面存在挑战，当基于提供的信息回答问题时会产生不一致的答案。现有的方法要么依赖昂贵的监督微调来生成答案后证据，要么训练模型进行网络搜索，但并没有一定地提高对给定上下文信息的利用效率。因此，如何使LLMs在推理过程中显式地整合上下文信息成为一个亟待解决的问题。", "innovation": "本文提出了一种名为CARE的新颖的原生检索增强推理框架，该框架利用模型自身的检索能力，在推理过程中明确整合内源的证据信息。该方法只需要少量带有标签的证据数据，但可以通过策略性地检索上下文中的关键信息以显著提高检索准确性和答案生成性能。", "conclusion": "大量的实验表明，本文提出的方法在多个现实世界的问答基准和假设性基准上表现出了显著的优势，超过了监督微调、传统的检索增强生成方法以及外部检索解决方案。这项工作代表了提高LLMs在知识密集型任务中的准确性和可靠性的一个基本进步。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13696", "html_url": "https://arxiv.org/abs/2509.13696", "title": "将文本和时间序列数据整合至（大型）语言模型以预测医疗结果", "title_en": "Integrating Text and Time-Series into (Large) Language Models to Predict Medical Outcomes", "authors": "Iyadh Ben Cheikh Larbi,Ajay Madhavan Ravichandran,Aljoscha Burchardt,Roland Roller", "background": "大型语言模型（LLMs）在文本生成方面表现出色，但它们处理涉及结构化数据的临床分类任务，如时间序列数据的能力尚未得到充分探索。本文针对这一情况，探讨了如何利用基于DSPy的提示优化方法，将指令调优的LLMs与临床笔记和结构化EHR输入相结合，以实现对医学结果的预测。实验结果表明，这种整合方法在性能上达到与专门的多模态系统相当的水平，同时简化了复杂性并增强了任务的适应性", "innovation": "本研究创新之处在于，通过DSPy基的提示优化方法将指令调优的大型语言模型与临床笔记和结构化EHR数据相结合，以处理时间和结构化的医学数据，从而实现了对医疗结果的预测，而且这种方法简化了复杂性并增强了任务的适应性", "conclusion": "该方法在实现与专门的多模态系统相当的预测性能的同时，简化了复杂性并增强了任务的适应性。这表明，改进的LLMs能够更好地处理临床相关数据，具备更多的应用潜力。 "}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13706", "html_url": "https://arxiv.org/abs/2509.13706", "title": "使用大规模语言表征模型进行事件学习安全报告的自动化分诊及跨机构迁移学习", "title_en": "Automated Triaging and Transfer Learning of Incident Learning Safety Reports Using Large Language Representational Models", "authors": "Peter Beidler,Mark Nguyen,Kevin Lybarger,Ola Holmberg,Eric Ford,John Kang", "background": "事件报告是改善医疗服务质量和安全的重要工具，但手工审查耗时且需要专业知识。因此，作者开发了一种自然语言处理（NLP）筛查工具，用于检测放射肿瘤学中两家机构的高严重性事件报告。", "innovation": "本研究使用两家机构的数据集训练和评估了两种NLP模型（基础支持向量机和BlueBERT），并通过跨机构的迁移学习提升模型性能。研究中提及的迁移学习是通过预先使用一个大规模语言模型进行微调，并在另一个数据集上进一步训练来实现的。此外，还对模型进行了性能测试，以验证其在清晰化报告子集上的表现与人类表现相似，从而证明开发的模型能够类似人类地检测高严重性报告。", "conclusion": "综合而言，该研究成功开发了跨机构的NLP模型，用于从放射肿瘤学中心获取事件报告文本。这些模型在经过人工清理的数据集上能够检测高严重性报告，性能与人类表现相似。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13775", "html_url": "https://arxiv.org/abs/2509.13775", "title": "探索阿拉伯方言识别的数据和参数高效策略", "title_en": "Exploring Data and Parameter Efficient Strategies for Arabic Dialect Identifications", "authors": "Vani Kanjirangat,Ljiljana Dolamic,Fabio Rinaldi", "background": "本文讨论了对阿拉伯方言识别（ADI）的不同数据高效和参数高效方法的探索，尤其是在大型语言模型（LLMs）中分析方言识别能力。研究了软提示策略，包括前缀调优、提示调优、P调优和P调优V2，以及LoRA重参数化。对数据高效策略，分析了零样本和少数样本推理中的硬提示；对参数高效PEFT方法，在对阿拉伯语特定编码器模型进行实验时，使用了多个主要数据集。还分析了开放源代码的解码器仅模型、通用多语言模型（Phi-3.5）以及阿拉伯语特定模型（SILMA）的n-shot推理。研究发现，LLMs在少量样本或零样本设置下难以区分方言差异，而软提示的编码器变体表现更好，基于LoRA的微调模型表现最佳，甚至超越了完全微调。", "innovation": "论文探讨了多种软提示策略和LoRA重参数化方法，并通过实验评估了阿拉伯语特定编码器模型和其他模型在阿拉伯方言识别任务上的表现，特别是在数据和参数效率方面的优势。", "conclusion": "研究发现硬提示方法在LLMs中难以识别方言细微差异，而软提示策略和基于LoRA的微调模型表现更为出色，甚至超越了传统的完全微调方法。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13723", "html_url": "https://arxiv.org/abs/2509.13723", "title": "DSPC: 双阶段渐进式压缩框架以实现高效长上下文推理", "title_en": "DSPC: Dual-Stage Progressive Compression Framework for Efficient Long-Context Reasoning", "authors": "Yaxin Gao,Yao Lu,Zongfei Zhang,Jiaqi Nie,Shanqing Yu,Qi Xuan", "background": "大型语言模型（LLMs）在许多自然语言处理（NLP）任务中取得了显著的成功。为了获得更准确的输出，用于驱动LLMs的提示词变得越来越长，这导致了更高的计算成本。为了解决这一提示词膨胀问题，已经提出了提示压缩的方法。然而，大多数现有方法需要训练一个小的辅助模型来进行压缩，这会消耗大量的额外计算资源。", "innovation": "我们提出了一种无需训练的双阶段方法，称为双阶段渐进式压缩（DSPC）。在粗粒度阶段，基于TF-IDF进行语义相关句子过滤，去除低语义价值的句子。在细粒度阶段，通过评估注意力贡献、跨模型损失差异以及位置重要性来评估token的重要性，从而去除低效的token同时保留语义。", "conclusion": "我们在一个受限的token预算下对LLaMA-3.1-8B-Instruct和GPT-3.5-Turbo进行了验证，观察到了一致的改进。例如，在Longbench数据集的FewShot任务中，DSPC仅使用了原来3倍少的token，实现了49.17的性能，优于最佳的最先进的基准LongLLMLingua 7.76。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13803", "html_url": "https://arxiv.org/abs/2509.13803", "title": "测量语法性语言中工作头衔匹配中的性别偏见", "title_en": "Measuring Gender Bias in Job Title Matching for Grammatical Gender Languages", "authors": "Laura García-Sardiña,Hermenegildo Fabregat,Daniel Deniz,Rabih Zbib", "background": "研究如何在工作头衔中明确地分配语法性别对自动工作排名系统结果的影响。提出使用控制性别差异的排名评估指标(RBO)来检测工作头衔排名系统中的性别偏见，生成并公开了四种语法性别语言的工作头衔匹配测试数据集，包括以男性和女性形式表示的职业，并进行性别和匹配相关性注释。", "innovation": "引入RBO（Rank-Biased Overlap）作为评估性别偏见的指标，开发了专门针对语法性别语言的工作头衔匹配测试集，并评估了多种现成的多语言模型的性别偏见，以此作为基准并展示了它们不同程度的性别偏见问题。", "conclusion": "所有模型均显示出不同程度的性别偏见，为后续研究建立了一个基线，强调了在多语言系统的性别敏感性方面进行改进的必要性。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13814", "html_url": "https://arxiv.org/abs/2509.13814", "title": "第三次自动会议纪要（AutoMin）挑战的发现", "title_en": "Findings of the Third Automatic Minuting (AutoMin) Challenge", "authors": "Kartik Shinde,Laurent Besacier,Ondrej Bojar,Thibaut Thonet,Tirthankar Ghosal", "background": "本文介绍了AutoMin的第三版，这是一个关于自动会议总结成会议纪要的共享任务。2025年的AutoMin任务包括主要的纪要任务（创建结构化的会议纪要）和新的问答任务（基于会议记录的问答）。纪要任务涵盖了英语和捷克语两种语言，并且涉及项目会议和欧洲议会会议两个领域。问答任务仅针对项目会议，并提供了单语问答和跨语言问答两种场景。", "innovation": "2025年的AutoMin增加了基于会议记录的问答任务，并且涵盖了单语和跨语言两种问答场景。相较于之前的年份，2025年的参与者更为有限，只有少数团队参与。", "conclusion": "尽管2025年的参与者较少，但是主办方依然加入了多种基线系统，以便综合评估当前的大型语言模型（LLMs）在两项任务上的表现。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13835", "html_url": "https://arxiv.org/abs/2509.13835", "title": "大型语言模型对德语方言使用者存在偏见", "title_en": "Large Language Models Discriminate Against Speakers of German Dialects", "authors": "Minh Duc Bui,Carolin Holtermann,Valentin Hofmann,Anne Lauscher,Katharina von der Wense", "background": "方言是人类文化的重要组成部分，遍布全球各地。在德国，40%以上的居民使用地方方言（Adler和Hansen，2022）。尽管方言具有文化价值，但使用者经常面临负面的社会刻板印象。本文探讨这些刻板印象在大型语言模型（LLMs）中是否有所体现。", "innovation": "本文通过构建一种新颖的评估语料库，对比评估LLMs在识别人物及决策任务中的方言识别和使用偏见。研究发现，所有评估的LLMs对德语方言使用者表现出显著的偏见。", "conclusion": "在关联任务中，所有LLMs都对德语方言使用者表现出显著的偏见和负面形容词的关联；在决策任务中，所有模型在决策中重现了这些偏见。与先前研究发现的不同，本文发现明确标记语言人口特征（如德语方言使用者）比隐含线索（如方言使用）更容易放大偏见。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13905", "html_url": "https://arxiv.org/abs/2509.13905", "title": "大型语言模型理解词语意义吗？", "title_en": "Do Large Language Models Understand Word Senses?", "authors": "Domenico Meconi,Simone Stirpe,Federico Martelli,Leonardo Lavalle,Roberto Navigli", "background": "理解语境中的词语意义是大型语言模型（LLMs）的一项基本能力。尽管进行了大量的评估工作，但LLMs真正理解词语意义的证据仍然没有得到充分探索。本文通过评估指令调优的大规模语言模型的词义消歧能力（WSD），并与专门为此任务设计的最先进系统进行比较，填补了这一空白。此外，本文还研究了顶级的开源和闭源LLM在这三个生成场景下的表现：释义生成、随意解释和示例生成。", "innovation": "本文首次通过比较专门的WSD系统与指令调优的LLMs的性能，探讨LLMs理解词语意义的能力。此外，研究了LLMs在定义生成、随意解释和示例生成时的表现，特别是在释义生成任务中表现最佳，这与它们的生成能力最为一致。", "conclusion": "在WSD任务中，领先的模型如GPT-4o和DeepSeek-V3的表现与专门的WSD系统相当，并且展示了更强的跨领域和难度的稳健性。在生成任务中，结果显示LLMs可以在上下文中解释词义，准确率高达98%，最高性能出现在随意解释任务中。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13695", "html_url": "https://arxiv.org/abs/2509.13695", "title": "大型语言模型能否稳健地对日语比较句进行自然语言推理？", "title_en": "Can Large Language Models Robustly Perform Natural Language Inference for Japanese Comparatives?", "authors": "Yosuke Mikami,Daiki Matsuoka,Hitomi Yanaka", "background": "大型语言模型（LLMs）在自然语言推理（NLI）中表现出色，但涉及到数理表达的NLI仍然颇具挑战。比较句是一种与此类推理紧密相关的语言现象，尤其是在训练数据中不占主导地位的语言如日语中，LLMs处理这类问题的稳健性尚未得到充分研究。因此，研究者构建了一个专注于比较句的日本NLI数据集，并在零样本和少样本设置下评估了多种LLMs的表现。研究结果表明，模型在零样本设置中的表现对提示格式敏感，而少样本示例中的金标签会影响模型的表现。此外，LLMs在处理独特的日语文本现象方面也存在困难。研究还发现，包含逻辑语义表示的提示有助于模型正确预测那些即便在少样本示例中也难以解决的推理问题的答案。", "innovation": "研究构建了一个专注于比较句的日本NLI数据集，并评估了LLMs在零样本和少样本设置下的表现。研究表明，性能受到提示格式的影响，并且少样本示例中的金标签会影响模型的行为。此外，提示中包含逻辑语义表示有助于模型预测一些难以解决的问题。这些发现对理解和改进LLMs在处理日语文本现象时的行为提供了有价值的见解。", "conclusion": "研究发现LLMs在处理日语比较句的少样本和零样本NLI中表现不一，提示格式和示例中的金标签对模型表现有显著影响。此外，包含逻辑语义表示的提示有助于提高模型的推理能力。总体而言，LLMs在处理非主导语言中的独特文本现象时仍然存在挑战。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13879", "html_url": "https://arxiv.org/abs/2509.13879", "title": "结合证据和推理进行生物医药事实核查", "title_en": "Combining Evidence and Reasoning for Biomedical Fact-Checking", "authors": "Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato", "background": "在医疗健康领域，错误信息，从疫苗犹豫到未经证实的治疗方法，都对公共健康和对医疗服务的信任构成了威胁。虽然机器学习和自然语言处理促进了自动事实核查的发展，但验证生物医药声明仍然具有挑战性，因为涉及到复杂的术语、需要领域专业知识，并且需要以科学证据为基础。", "innovation": "我们提出了CER（结合证据和推理）框架，用于生物医药事实核查。CER融合了科学证据检索、大型语言模型推理以及监督验证，利用大型语言模型的文本生成能力与高质量的生物医药科学证据的高级检索技术相结合，有效降低了幻觉的风险，确保生成的输出基于可验证的基于证据的来源。在专家标注的数据集（HealthFC、BioASQ-7b、SciFact）上的评估显示了最先进的性能和跨数据集的广泛适用性。", "conclusion": "CER框架在专家标注的数据集上表现出了最先进的性能，并且具有跨数据集的良好推广能力。代码和数据已公开以确保透明性和可重复性：https://github.com/PRAISELab-PicusLab/CER。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13888", "html_url": "https://arxiv.org/abs/2509.13888", "title": "通过多模态声明检测与证据为基础的验证来对抗生物医学误导信息", "title_en": "Combating Biomedical Misinformation through Multi-modal Claim Detection and Evidence-based Verification", "authors": "Mariano Barone,Antonio Romano,Giuseppe Riccio,Marco Postiglione,Vincenzo Moscato", "background": "生物医学领域中的错误信息，从疫苗犹豫到未经证实的治疗方法，对公共卫生和对医疗系统的信任构成了风险。尽管机器学习和自然语言处理已经推进了自动事实核查，但在验证生物医学声明方面仍然面临着独特挑战，这是因为复杂的术语、需要领域的专业知识以及对科学证据基础的依赖。现有的方法在应对这些挑战时表现欠佳，亟需新的解决方案来提高效率和准确性。", "innovation": "本文提出了CER (Combining Evidence and Reasoning)框架，这是一种新颖的生物医学事实核查方案，该框架将科学证据检索、通过大型语言模型进行的推理以及监督的真实性预测相结合。CER通过将大型语言模型的文本生成能力与高级检索技术结合，提高了高质量生物医学科学证据的准确性，有效地减少了虚幻信息的风险，确保生成的输出基于可验证和基于证据的来源。实验结果表明，CER在专家注释的数据集（HealthFC、BioASQ-7b、SciFact）上的表现达到了最先进的水平，并且具有跨数据集的一般化潜力。", "conclusion": "该研究通过CER框架有效地提升了生物医学事实核查的性能和准确性，并为后续研究提供了透明、可复现的数据和代码。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13930", "html_url": "https://arxiv.org/abs/2509.13930", "title": "多方言语：在多语言RAG中为了语言偏好牺牲质量", "title_en": "Linguistic Nepotism: Trading-off Quality for Language Preference in Multilingual RAG", "authors": "Dayeon Ki,Marine Carpuat,Paul McNamee,Daniel Khashabi,Eugene Yang,Dawn Lawrie,Kevin Duh", "background": "多语言检索增强生成（mRAG）系统使得语言模型能够用引文支持的回答跨语言的知识密集型查询。尽管这种系统已经被提出，但一个开放的问题是不同文献语言的混合是否以未预期的方式影响了生成和引文。为了探究这个问题，引入了一种受控的方法，通过模型内部机制测量语言偏好，同时保持其他因素如文档相关性不变。在八种语言和六种开放权重模型上进行研究发现，当查询是英文时，模型倾向于引用英文来源，低资源语言和中间位置的文档这一倾向更明显。研究还发现，模型有时会为语言偏好而牺牲文档的相关性，表明引文选择不仅仅由信息性驱动。这些发现揭示了语言模型如何利用多语言上下文以影响引文行为方式。", "innovation": "引入了一种受控的方法，利用模型内部的机制来测量语言偏好，同时保持其他因素不变。", "conclusion": "模型在回答英文查询时倾向于引用英文文献，低资源语言和文献在中间位置的引用偏差更加明显。模型有时会在语言偏好之上牺牲文献的相关性，引文选择不仅仅由信息性驱动。这些研究结果揭示了语言模型如何利用多语言上下文和其对引文行为的影响。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13813", "html_url": "https://arxiv.org/abs/2509.13813", "title": "LLMs中几何不确定性用于检测和纠正幻觉", "title_en": "Geometric Uncertainty for Detecting and Correcting Hallucinations in LLMs", "authors": "Edward Phillips,Sean Wu,Soheila Molaei,Danielle Belgrave,Anshul Thakur,David Clifton", "background": "大型语言模型在各种任务上表现出色，但仍然存在幻觉问题，即生成语义上合理但不正确的答案。不确定性量化被提出作为一种幻觉检测策略，目前的黑盒方法只能提供全局不确定性估计，无法同时提供局部不确定性估计。白盒方法虽然可以提供局部不确定性估计，但需要访问内部模型状态，这在实际应用中并不总是可行或合适的。因此，本文提出了一种基于黑盒模型访问的几何框架，包括一个基于响应嵌入衍生的原型的几何体积测量的全局不确定性方法，以及一个基于可靠性的局部排序方法，用于优化幻觉减少。这种方法能够在不需要白盒访问的情况下，提供与语义边界点相关的可靠性评估，从而提高幻觉检测和减少的准确性。同时，在医疗数据集上，该方法显示出优于先前方法的优越性能，尤其是在有害幻觉风险较高的对象上。", "innovation": "本文提出了一种新的几何框架，用于同时提供全局和局部不确定性估计，这在目前的黑盒方法中是不存在的。该方法通过几何体积测量生成的原型来提供整体不确定性估计，并通过可靠性排名和优选响应选择来处理局部不确定性。此外，该方法还能够在不需要白盒访问的情况下提供语义边界点，使得可以对单个响应的可靠性进行分配。在实验中，该框架在短期问答数据集上表现与先前方法相当或更好，并在医疗数据集上表现出特别优越的结果，这表明这种方法对于幻觉检测和纠正具有重要的应用价值。另外，还提供了理论上的证明，证明了凸包体积与熵之间的关联。", "conclusion": "本文提出了一个基于几何框架的方法，可在保持不依赖于白盒访问的前提下获得全局和局部不确定性估计，从而提高了幻觉的检测和减少能力。通过实验证明，该方法在一些特定数据集上效果显著，尤其是在涉及高风险幻觉的医疗领域。此外，首次提供了定量的理论支持，证明了几何体积与熵之间的关系。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13990", "html_url": "https://arxiv.org/abs/2509.13990", "title": "Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency", "title_en": "Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency", "authors": "Colin Hong,Xu Guo,Anand Chaanan Singh,Esha Choukse,Dmitrii Ustiugov", "background": "Test-Time Scaling (TTS) 技术最近因其能够在测试时提高大语言模型 (LLM) 的推理性能而备受关注，而无需重新训练模型。Self-Consistency (SC) 是一种显著的 TTS 技术，它通过并行生成多个推理路径，并最终通过多数投票选择答案，尽管有效，但其巨大的计算开销限制了其广泛应用。", "innovation": "首次从理论上和实践中分析了 SC 的低效率，并揭示了改进的机会。基于这些见解，提出了一种步进式剪枝策略 Slim-SC，该策略在思索层面识别并移除冗余路径，使用了跨链相似性。Slim-SC 在三个 STEM 推理数据集和两种最新 LLM 架构上的实验表明，相较于 SC，它能够将推理延迟和 KVC 使用量分别降低最多45% 和 26%，同时保持或提高准确性。", "conclusion": "Slim-SC 提供了一种简单且高效的 SC 替代方案，对于 TTS 而言是一个新的选择。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14008", "html_url": "https://arxiv.org/abs/2509.14008", "title": "Hala技术报告：大规模构建阿拉伯语中心的指令与翻译模型", "title_en": "Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale", "authors": "Hasan Abed Al Kader Hammoud,Mohammad Zbeeb,Bernard Ghanem", "background": "该研究背景在于构建专门针对阿拉伯语的指令和翻译模型，以解决阿拉伯语在自然语言处理(NLP)领域中的不足。现有的大多数NLP模型更多地关注于欧洲语言，这限制了阿拉伯语的应用和发展。为了解决这一问题，论文介绍了一种新的翻译和调优管道，并以此为基础构建了Hala模型系列。", "innovation": "Hala模型系列的创新之处在于它通过压缩强AR-EN教师模型到FP8，提高了吞吐量而不损失质量。然后，使用该教师模型创建高质量的双语监督，对轻量级语言模型进行细调，最终实现高质量的阿拉伯语指令翻译。此外，通过参数合并（slerp合并）技术平衡阿拉伯语的专属性和基模型的优势。Hala模型在阿拉伯语相关的基准数据集上取得了领先结果，特别是在小型模型类别中。", "conclusion": "Hala模型在阿拉伯语NLP领域达到了最先进的性能，能够在“nano”和“small”类别中超越其基础模型。研究还提供了模型、数据、评估和制作方法等资源，以加速阿拉伯语NLP的研究进程。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14031", "html_url": "https://arxiv.org/abs/2509.14031", "title": "你是什么你训练的：数据组成对训练感知上下文机器翻译模型的影响", "title_en": "You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models", "authors": "Paweł Mąka,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis", "background": "实现与人类水平相当的翻译需要利用上下文以确保连贯性并处理像代词消岐这样的复杂现象。假设标准训练数据中上下文丰富的例子稀少是难以利用上下文的原因。本文系统地在单语和多语环境下验证了这一假设，构建了包含控制比例的上下文相关例子的训练数据集。", "innovation": "提出了两种训练策略以利用可用数据，并验证了这些策略如何提升上下文利用能力，在单语和多语环境下分别提高了6和8个百分点的准确率。", "conclusion": "训练数据稀疏是导致模型性能瓶颈的关键原因。上下文现象的改进不会泛化到其他现象，跨语言转移的效果在相同语系的语言间并不显著。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14034", "html_url": "https://arxiv.org/abs/2509.14034", "title": "通过自信表达增强多代理辩论系统性能", "title_en": "Enhancing Multi-Agent Debate System Performance via Confidence Expression", "authors": "Zijie Lin,Bryan Hooi", "background": "生成式大型语言模型（LLMs）在广泛的任务中表现出色。近期研究引入了多代理辩论（MAD）系统，利用多个LLMs模拟人类辩论从而提升任务表现。然而，尽管某些LLMs在特定任务中可能拥有优越的知识或推理能力，它们常常难以在辩论中清晰传达这种优势，部分原因在于缺乏自信表达。此外，不恰当地表达自信会导致MAD系统中的代理要么顽固地保持错误信念，要么过早收敛于次优答案，从而降低辩论效果和整体系统性能。", "innovation": "本文提出将自信表达纳入MAD系统，使LLMs能够明确传达其自信水平。为此开发了ConfMAD框架，该框架在辩论过程中全面整合了自信表达。实验结果证实了该方法的有效性，并进一步分析了自信如何影响辩论动态，为构建自信意识下的MAD系统提供建设性见解。", "conclusion": "实验结果表明，我们的方法有效。进一步分析了自信如何影响辩论动态，为设计自信感知的MAD系统提供了有益的洞察。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14023", "html_url": "https://arxiv.org/abs/2509.14023", "title": "基于音频的人工众包评估机器翻译质量", "title_en": "Audio-Based Crowd-Sourced Evaluation of Machine Translation Quality", "authors": "Sami Ul Haq,Sheila Castilho,Yvette Graham", "background": "机器翻译（MT）取得了显著进步，特别是在语音翻译和多模态方法方面引起了越来越多的兴趣。然而，尽管取得了这些进步，机器翻译的质量评估仍主要集中在文本上，通常依赖于人类专家来阅读和比较文本。许多现实生活中的机器翻译应用（例如Google Translate语音模式、iFLYTEK翻译器）需要翻译声音而不是印刷或阅读的文本。因此，在只评估文本质量的方式之外，通过使用音频而非仅依赖文本的方式评估翻译质量会更自然。本研究对比了来自WMT通用机器翻译共享任务的10个MT系统的文本-only评估和基于音频的评估，通过亚马逊土耳其机器人收集众包判断。同时，还进行了统计显著性测试和自我复制实验，以测试基于音频方法的可靠性和一致性。", "innovation": "本研究通过众包获取音频界的评估来对比文本-only和基于音频的机器翻译质量评估方式，这是创新之处。这种方法揭示了一些仅通过文本评估未发现的显著差异，并通过统计测试和自我复制实验验证了基于音频方法的可靠性和一致性。", "conclusion": "基于音频的众包评估与文本-only评估结果大致一致，但在某些情况下能识别出不同的机器翻译系统。这归因于语音是一种更丰富、更自然的模态。本研究提议将基于语音的评估纳入未来机器翻译评估框架。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14036", "html_url": "https://arxiv.org/abs/2509.14036", "title": "SSL-SSAW: 自监督学习与Sigmoid自注意力加权结合的基于问题的手语翻译", "title_en": "SSL-SSAW: Self-Supervised Learning with Sigmoid Self-Attention Weighting for Question-Based Sign Language Translation", "authors": "Zekang Liu,Wei Feng,Fanhua Shang,Lianyu Hu,Jichao Feng,Liqing Gao", "background": "手语翻译（SLT）有助于聋人与听力人之间的沟通，对话提供了关键的上下文线索，有助于翻译。传统的手语翻译依赖于手语转写（gloss），但对话在实际通信中更自然发生，更容易标注。如何在利用问题上下文的同时实现多模态特征的对齐是关键挑战。", "innovation": "本文提出了基于问题的手语翻译（QB-SLT），并提出了一种新的任务。为了解决多模态特征对齐的问题，本文引入了跨模态自监督学习与Sigmoid自注意力加权（SSL-SSAW）融合方法，包括使用对比学习对齐QB-SLT中的多模态特征，引入Sigmoid自注意力加权（SSAW）模块以适应性提取问题和手语序列特征，进一步利用可获取的问题文本进行自监督学习以增强表示和翻译能力。", "conclusion": "研究在新构建的CSL-Daily-QA和PHOENIX-2014T-QA数据集上进行了评估，SSL-SSAW方法达到了SOTA性能。可视化结果表明，只有简单问题辅助的手语翻译性能可以或超过传统的手语转写辅助方法。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13869", "html_url": "https://arxiv.org/abs/2509.13869", "title": "LLMs在社会偏见方面是否与人类价值观对齐？通过LLMs判断和解释社会偏见", "title_en": "Do LLMs Align Human Values Regarding Social Biases? Judging and Explaining Social Biases with LLMs", "authors": "Yang Liu,Chenhui Chu", "background": "大型语言模型（LLMs）在与人类价值观不一致时可能会导致不良后果，尤其是在涉及复杂和敏感的社会偏见的情况下。现有的研究利用专家设计或基于代理的模拟偏见场景来揭示LLMs与人类价值观之间的不一致。然而，不同类型的场景（如涉及负面问题与非负面问题的场景）中，LLMs与人类价值观的对齐程度是否有所不同仍然不清楚。因此，该研究探讨了不同类型的偏见场景中LLMs与社会偏见相关的人类价值观（HVSB）的对齐情况。研究通过分析四种模型家族和四个数据集中的12个LLMs，展示了大模型参数规模的LLMs并不一定具有较低的不一致性率和攻击成功概率。此外，研究还发现，LLMs在特定场景类型上有一定的对齐偏好，同一模型家族的LLMs更具判断一致性。同时，研究考察了LLMs对HVSB的理解能力以及它们的解释能力，发现不同LLMs在理解HVSB方面没有显著差异，且偏好自动生成的解释。最后，研究为较小的语言模型赋予了解释HVSB的能力，结果显示微调后的小语言模型生成的解释更易读，但模型的一致性相对较低。", "innovation": "1. 该研究通过分析不同类型的偏见场景，探讨了LLMs与社会偏见相关的人类价值观的对齐情况。\n2. 研究发现，大模型参数规模的LLMs并不一定具有较低的不一致性率和攻击成功率。\n3. 研究展示了LLMs在特定场景类型上有一定的对齐偏好，同一模型家族的LLMs判断一致性较高。\n4. 研究考察了LLMs对HVSB的理解能力以及它们的解释能力，发现存在显著偏好自动生成的解释的倾向。\n5. 研究为较小的语言模型赋予了解释HVSB的能力，展示了模型输出的可读性与模型一致性之间的权衡。", "conclusion": "该研究的结果表明，大模型参数规模的LLMs并不一定具有较低的不一致性率和攻击成功率，且不同类型的偏见场景中LLMs的对齐偏好不同。理解HVSB的差异不显著，但小语言模型在理解和解释HVSB方面具有一定的潜力，但仍需平衡阅读性和一致性。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13980", "html_url": "https://arxiv.org/abs/2509.13980", "title": "基于长上下文的引用驱动的机器翻译质量评估", "title_en": "Long-context Reference-based MT Quality Estimation", "authors": "Sami Ul Haq,Chinonso Cynthia Osuji,Sheila Castilho,Brian Davis", "background": "本文介绍了作者参加第九届国际机器翻译会议（WMT25）自动翻译质量评估共享任务的提交内容。背景信息主要是当前机器翻译质量评估任务中，如何有效地预测翻译段落中的错误标注分数，以及使用长上下文数据可以改善机器评估与人工评价的一致性问题。", "innovation": "创新点在于论文采用COMET框架，构建系统来预测段落级别的错误跨度注释（ESA）评分，并通过连接领域相关的、人工注释的句子来构造长上下文训练数据。此外，论文还整合了多种人类判断数据集（MQM, SQM, 和DA），并对其进行标准化，用以训练多语言回归模型以从源翻译、假设翻译和参考翻译中预测质量评分。这些方法能够更好地捕捉翻译中长距离依赖的关系，从而提升机器评估与人工评估的一致性，特别是相比只使用短片段训练的模型而言。", "conclusion": "实验结果表明，引入长上下文信息能够提高机器评估结果与人工判断的一致性。相比仅基于短片段训练的模型，使用长上下文信息的方法表现更好。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14197", "html_url": "https://arxiv.org/abs/2509.14197", "title": "迁移框架：英国议会话语的计算分析", "title_en": "Framing Migration: A Computational Analysis of UK Parliamentary Discourse", "authors": "Vahid Ghafouri,Robert McNeil,Teodor Yankov,Madeleine Sumption,Luc Rocher,Scott A. Hale,Adam Mahdi", "background": "本文通过分析跨越75年的英国议会辩论和对比美国国会的有关言论，提供了一个大规模的计算分析框架。利用开放加权的大规模语言模型进行注释，并追踪不同时期和政党的总体态度走向。", "innovation": "本文提出了一种半自动化框架来提取英国议会陈述中的细微叙事框架，以捕捉移民话语中的细微差别。相较于美国政治中日益两极化的言论，英国议会的态度在不同政党和党派之间保持相对一致，尽管存在持续的意识形态差异，特别是在2025年达到最低点。英国议会关于移民的叙事框架分析还揭示了从长期旨在融合的框架转向强化边控和非法移民控制的框架的趋势，同时也反映了对国际法和人权的关注增加。", "conclusion": "总体而言，我们的研究结果表明，大规模语言模型能够支持在政治和历史背景下进行具有规模和细致程度的话语分析。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14180", "html_url": "https://arxiv.org/abs/2509.14180", "title": "基于行为依据的推理链合成：个人金融LLM的数据生成框架", "title_en": "Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs", "authors": "Akhil Theerthala", "background": "个性化金融建议需要考虑用户目标、限制、风险容忍度和地域因素。现有LLM研究主要集中在投资者和金融规划者的支持系统上。同时，许多近期的研究通过代理管道（这些管道存在高维护成本）探讨了更广泛的个人财务管理任务，如预算、债务管理、退休和遗产规划，但这些研究只达到了期望财务回报的不到25%。", "innovation": "本文提出了一种新颖且可重现的框架，将相关财务背景与行为金融研究结合，构建从头到尾顾问的监督数据。利用该框架创建了一个包含19000个样本的推理数据集，并对Qwen-3-8B模型进行了全面的微调。通过分开的测试集和盲试验，结果显示，通过精心的数据筛选和行为整合，我们的8B模型在事实准确性、流畅性和个性化指标上表现与较大基线（14-32B参数）相当，但成本降低了80%。", "conclusion": "该研究通过精心的数据生成框架和行为整合，使8B模型在事实准确性、流畅性和个性化方面取得了与14-32B参数基线相当的性能，同时成本降低了80%。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14233", "html_url": "https://arxiv.org/abs/2509.14233", "title": "Apertus: 全球语言环境中民主化的开放合规大语言模型", "title_en": "Apertus: Democratizing Open and Compliant LLMs for Global Language Environments", "authors": "Alejandro Hernández-Cano,Alexander Hägele,Allen Hao Huang,Angelika Romanou,Antoni-Joan Solergibert,Barna Pasztor,Bettina Messmer,Dhia Garbaya,Eduard Frank Ďurech,Ido Hakimi,Juan García Giraldo,Mete Ismayilzada,Negar Foroutan,Skander Moalla,Tiancheng Chen,Vinko Sabolčec,Yixuan Xu,Michael Aerni,Badr AlKhamissi,Ines Altemir Marinas,Mohammad Hossein Amani,Matin Ansaripour,Ilia Badanin,Harold Benoit,Emanuela Boros,Nicholas Browning,Fabian Bösch,Maximilian Böther,Niklas Canova,Camille Challier,Clement Charmillot,Jonathan Coles,Jan Deriu,Arnout Devos,Lukas Drescher,Daniil Dzenhaliou,Maud Ehrmann,Dongyang Fan,Simin Fan,Silin Gao,Miguel Gila,María Grandury,Diba Hashemi,Alexander Hoyle,Jiaming Jiang,Mark Klein,Andrei Kucharavy,Anastasiia Kucherenko,Frederike Lübeck,Roman Machacek,Theofilos Manitaras,Andreas Marfurt,Kyle Matoba,Simon Matrenok,Henrique Mendoncça,Fawzi Roberto Mohamed,Syrielle Montariol,Luca Mouchel,Sven Najem-Meyer,Jingwei Ni,Gennaro Oliva,Matteo Pagliardini,Elia Palme,Andrei Panferov,Léo Paoletti,Marco Passerini,Ivan Pavlov,Auguste Poiroux,Kaustubh Ponkshe,Nathan Ranchin,Javi Rando,Mathieu Sauser,Jakhongir Saydaliev,Muhammad Ali Sayfiddinov,Marian Schneider,Stefano Schuppli,Marco Scialanga,Andrei Semenov,Kumar Shridhar,Raghav Singhal,Anna Sotnikova,Alexander Sternfeld,Ayush Kumar Tarun,Paul Teiletche,Jannis Vamvas,Xiaozhe Yao,Hao Zhao Alexander Ilic,Ana Klimovic,Andreas Krause,Caglar Gulcehre,David Rosenthal,Elliott Ash,Florian Tramèr,Joost VandeVondele,Livio Veraldi,Martin Rajman,Thomas Schulthess,Torsten Hoefler,Antoine Bosselut,Martin Jaggi,Imanol Schlag", "background": "现今开放模型生态系统中存在两个系统性的不足：数据合规性和多语言表示。许多先前的模型在发布权重时并未提供可重复的数据管道，也未尊重内容拥有者的权利，这给用户和开发者带来了数据合规性的挑战和安全隐患。", "innovation": "Apertus 通过仅使用公开可用的数据进行预训练，尊重数据规范，并强加 Goldfish 目标，以抑制数据的字面回忆，同时保留下游任务的表现，从而创新性地解决了这些挑战。Apertus 还扩大了多语言覆盖范围，训练数据来自于超过 1800 种语言的 15T 个标记，其中约 40% 的预训练数据用于非英语内容。Apertus 在多语言基准测试中达到了与同类最优结果相当或更高的水平，同时以包容性的许可证发布了所有开发过程中的科学成果，包括数据处理脚本、检查点、评估套件和训练代码，以实现透明审计和扩展。", "conclusion": "Apertus 推动了开放大语言模型的民主化，通过严格的合规性和广泛的多语言支持，为全球语言环境提供了高质量的解决方案，并为开源社区提供了透明的开发实践，提升了模型的可复现性和社区贡献。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14171", "html_url": "https://arxiv.org/abs/2509.14171", "title": "AssoCiAm：一种规避歧义评估联想思维的标准", "title_en": "AssoCiAm: A Benchmark for Evaluating Association Thinking while Circumventing Ambiguity", "authors": "Yifan Liu,Wenkuan Zhao,Shanshan Zhong,Jinghui Qin,Mingfu Liang,Zhongzhan Huang,Wushao Wen", "background": "近年来，多模态大型语言模型（MLLMs）的发展引起了广泛关注，它们被认为是通向人工智能一般性（AGI）的关键路径之一。在通向AGI的必要能力中，创造力是多模态大型语言模型的关键特质，而关联能力则是其基础。关联反映了模型的创造性思维能力，因此评估和理解关联能力至关重要。尽管已经提出了一些评估关联能力的框架，但这些框架往往会忽略关联任务中的固有模糊性，这种模糊性源于关联的多样性和多样性，从而削弱了评估的可靠性。", "innovation": "本文引入了AssoCiAm，一种标准工具，用于通过混合计算方法评估关联能力的同时规避模糊性。此外，研究发现认知能力和关联能力之间存在明显的正相关关系。并在实验中观察到模糊性对模型行为的影响，使其行为更加随机。最后，验证了该方法的有效性，确保了更准确和可靠的评估结果。", "conclusion": "研究揭示了认知能力和关联能力之间的正相关关系，并表明在评估过程中存在模糊性时，会导致模型行为变得更为随机。AssoCiAm方法有效地保证了评估结果的准确性和可靠性。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13332", "html_url": "https://arxiv.org/abs/2509.13332", "title": "显式的推理能更好地担任法官：一项关于准确度、效率和稳健性的系统研究", "title_en": "Explicit Reasoning Makes Better Judges: A Systematic Study on Accuracy, Efficiency, and Robustness", "authors": "Pratik Jayarao,Himanshu Gupta,Neeraj Varshney,Chaitanya Dwivedi", "background": "随着大型语言模型（LLMs）在基准测试和奖励建模中被越来越多地用作自动化法官，确保其可靠、高效和稳健变得至关重要。本文通过使用开源的Qwen 3模型（0.6B、1.7B和4B参数），对“思考型”和“非思考型”LLM在LLM作为法官（LLM-as-a-judge）范式中的表现进行了系统的比较。评估了准确性和计算效率，并进一步考察了非思考型模型的增强策略，包括上下文学习、评分表指导评估、参考评估和n-best聚合。结果显示，即使进行了这些增强，非思考型模型的表现仍然不及思考型模型。", "innovation": "本文通过系统比较“思考型”和“非思考型”LLM，在准确度和计算效率方面对增强策略进行评估，并通过实验证明了显式的推理在LLM作为法官中的优势，不仅在准确度和效率方面，而且在抗偏差性方面。此外，实验还扩展到了多语言环境，显示了显式推理受益于多语言的优势。", "conclusion": "本研究结果得出几点重要发现，表明显式推理在LLM作为法官的范式中提供了系统的证据，显示出在准确度、效率和稳健性等方面的明显优势。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13356", "html_url": "https://arxiv.org/abs/2509.13356", "title": "CogniAlign: 基于生存能力的多智能体道德推理实现安全透明的人工智能对齐", "title_en": "CogniAlign: Survivability-Grounded Multi-Agent Moral Reasoning for Safe and Transparent AI", "authors": "Hasin Jawad Ali,Ilhamul Azam,Ajwad Abrar,Md. Kamrul Hasan,Hasan Mahmud", "background": "由于道德原则的抽象性和冲突性，以及现有方法的不透明性，将人工智能（AI）与人类价值观对齐的挑战依然存在。本文指出，现有的解决方法难以在这种背景下有效实现这样的对齐。", "innovation": "文章通过引入基于自然主义道德现实主义的CogniAlign多智能体协商框架，使得道德推理基于个体和集体维度的生存能力，通过特定学科科学家智能体之间的结构化协商实现具体化。每个智能体分别代表神经科学、心理学、社会学和进化生物学，它们提供的论据和反驳被仲裁者综合为透明且以经验为基础的判断。并通过伦理审计框架评估CogniAlign，并与GPT-4o进行比较，结果显示CogniAlign在超过六十个道德问题上普遍优于基线，特别是在分析质量、广度和解释深度方面。", "conclusion": "CogniAlign通过减少黑盒推理并避免欺骗性对齐，展示了跨学科协商作为安全透明AI对齐的可扩展途径的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14161", "html_url": "https://arxiv.org/abs/2509.14161", "title": "CS-FLEURS: 一个多语种及混用语语音数据集", "title_en": "CS-FLEURS: A Massively Multilingual and Code-Switched Speech Dataset", "authors": "Brian Yan,Injy Hamed,Shuichiro Shimizu,Vasista Lodagala,William Chen,Olga Iakovenko,Bashar Talafha,Amir Hussein,Alexander Polok,Kalvin Chang,Dominik Klement,Sara Althubaiti,Puyuan Peng,Matthew Wiesner,Thamar Solorio,Ahmed Ali,Sanjeev Khudanpur,Shinji Watanabe,Chih-Chen Chen,Zhen Wu,Karim Benharrak,Anuj Diwan,Samuele Cornell,Eunjung Yeo,Kwanghee Choi,Carlos Carvalho,Karen Rosero", "background": "当前已有的代码混用语音识别和翻译系统主要集中在高资源语言上，缺少有效的多语言及混用语数据集来促进相关技术的发展和评估。该论文旨在填补这一空白，创建一个适用于多种语言及混用语的新型数据集CS-FLEURS，以推动未来的相关研究。", "innovation": "CS-FLEURS 是首个针对多种语言及混用语的大型语音数据集，包含了 4 个测试集和一个训练集。测试集覆盖了总共 113 种独特的混用语语言对，在 52 种语言中包含 14 种 X-英语语言对、16 种 X-英语语言对、60 种阿拉伯语、汉语、印地语、西班牙语与 X 语言对，以及 45 种 X-英语低资源语言对。训练集则提供了 128 小时的生成语音数据，涉及 16 种 X-英语语言对。这一数据集的创建有助于拓宽未来在代码混用语音领域研究的范围。", "conclusion": "我们希望 CS-FLEURS 能够帮助拓宽未来代码混用语音研究的范围，并成为评估和开发代码混用语音识别和翻译系统的一个有效工具。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.12577", "html_url": "https://arxiv.org/abs/2509.12577", "title": "一种基于AI的分析协商议事中集体想法演变的框架", "title_en": "An AI-Powered Framework for Analyzing Collective Idea Evolution in Deliberative Assemblies", "authors": "Elinor Poole-Dayan,Deb Roy,Jad Kabbara", "background": "在社会分裂加剧、政治极化严重以及公众对机构信任下降的时代背景下，代表性的协商议事机构正成为解决复杂全球问题、制定有效政策方案的有前景的民主论坛。然而，尽管理论关注，但对于具体想法在协商过程中的演变、优先级排序或淘汰如何形成政策建议的研究依然有限。本文旨在填补这一空白。", "innovation": "本文提出了一种基于AI的方法来实证分析技术支持的面对面协商议事机构的会议记录。该框架能够识别并可视化表达的建议空间，并且可以实证重构每位代表在协商过程中的变化观点，揭示了基于LLM（大语言模型）的新颖实证见解，展示了LLM如何在传统会议输出中揭示高分辨率的动态。", "conclusion": "本文的方法为理解和分析协商议事过程提供了新的研究视角，为政策建议的形成和发展提供更为深入的理解。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13345", "html_url": "https://arxiv.org/abs/2509.13345", "title": "大型语言模型中的准确悖论：生成式人工智能中的幻觉风险监管", "title_en": "Accuracy Paradox in Large Language Models: Regulating Hallucination Risks in Generative AI", "authors": "Zihao Li,Weiwei Yi,Jiahong Chen", "background": "随着大型语言模型（LLMs）在日常生活中的日益普及，它们的认知风险和对社会的影响引起了迫切的关注。生成幻觉，即生成虚假、误导性的、过于简化或不可信的输出，已成为主要挑战。尽管监管、学术和技术界将准确性作为减轻这些危害的主要标准，但本文认为过度依赖准确性是一种误诊，导致了准确性的悖论。文章通过跨学科的文献探讨，提出了幻觉类型的分类，并从三个交织的维度展示了悖论：输出、个体和社会。首先，准确性被视为可靠性的表面标志，导致优化修辞流畅性和表面正确性而非认知可信性。其次，准确性作为单一指标无法检测出虽事实正确但仍然具有误导性、价值观负载或社会扭曲的损害，例如共识幻觉、阿谀奉承的对齐和微妙操控。第三，注重准确性的监管政策掩盖了幻觉对社会的更广泛后果，包括社会排序、隐私侵犯、公平损害、同质化、减少包容性和社会技能退化。通过分析欧盟AI法案、GDPR和DSA，文章指出现有法规尚不足以应对认知、关系和系统性危害，并且过多依赖准确性会加剧这一问题。", "innovation": "本文首次提出了'准确悖论'的概念，尝试从输出、个体和社会三个维度全面看待准确性悖论，强调了单一依赖准确性的不足，并提出了政府法规在当前尚不足以解决这些认知、关系性和系统性问题，需采取更具包容性、背景意识和抗操纵的方法来治理AI的可信度。这一视角有助于从更全面的角度理解AI幻觉带来的风险及其影响，并提供新的政策建议和治理思路。", "conclusion": "本文通过详尽分析准确性悖论及其在大型语言模型监管中的实际应用，提出当前法规尚缺乏有效治理这些认知、关系性和系统性危害的机制。作者呼吁从根本上转向包容性、背景意识和抗操纵的方法来改善AI治理，使信任度管理更加有效和公正。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13586", "html_url": "https://arxiv.org/abs/2509.13586", "title": "使用特定领域的语料库关键词标注森林卫星图像以进行变化检测", "title_en": "Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection", "authors": "Nathalie Neptune,Josiane Mothe", "background": "亚马逊雨林是至关重要的生态系统，对地球气候变化和生物多样性具有关键作用。亚马逊地区的毁林问题引起了广泛关注，因为它对全球碳排放和生物多样性产生了重大影响。本文利用地球观测卫星的图像对来检测亚马逊地区的毁林情况，并提出了一种基于深度学习技术的方法，比较不同日期相同区域的图像，识别森林覆盖率的变化。同时，还提出了一种视觉语义模型，能够自动为检测到的变化标注相应的关键词。这些候选注释是从与亚马逊地区相关的科学文献中提取出来的。", "innovation": "本文提出了一种使用深度学习技术检测亚马逊地区毁林情况的方法，能够比较不同日期相同区域的图像，识别森林覆盖率的变化。除此之外，还引入了一种视觉语义模型，能够自动为检测到的变化标注相关关键词，这些候选注释是从与亚马逊地区相关的科学文献中提取出来的。这种方法在环境应用方面展现了其有效性，但具有广泛的适用性，可以应用于其他领域，具有很大的应用潜力。", "conclusion": "本文提出的方法为监测和研究亚马逊地区的毁林影响提供了一个有用的工具。虽然本文主要应用在环境领域，但其方法具有足够的通用性，可以应用于其他领域，为相关研究提供支持。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13395", "html_url": "https://arxiv.org/abs/2509.13395", "title": "TICL: 文本嵌入KNN用于语音上下文学习，解锁大型多模态模型的语音识别能力", "title_en": "TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models", "authors": "Haolong Zheng,Yekaterina Yegorova,Mark Hasegawa-Johnson", "background": "语音基础模型最近展示了在语音上下文学习（SICL）方面的能力。然而，有效上下文示例的选择方法尚处于探索阶段。在各种具有挑战性的自动语音识别任务中，包括带口音的英语、多语种语音和儿童语音，通过引入文本嵌入KNN方法（TICL），可以显著提升模型的零样本性能，最高相对WER下降达84.7%。", "innovation": "提出了一种简单的方法，即文本嵌入KNN（TICL），用语义上下文增强大尺寸的多模态模型的语音识别能力，无需微调，且在多种自动语音识别任务中表现出色，大幅提高了模型的识别能力，尤其是在难题和多语言场景中。", "conclusion": "通过消融研究展示了方法的稳健性和高效性，说明了文本嵌入KNN在通过上下文增强大型多模态模型语音识别能力方面的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13761", "html_url": "https://arxiv.org/abs/2509.13761", "title": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "title_en": "THOR: Tool-Integrated Hierarchical Optimization via RL for Mathematical Reasoning", "authors": "Qikai Chang,Zhenrong Zhang,Pengfei Hu,Jiefeng Ma,Yicheng Pan,Jianshu Zhang,Jun Du,Quan Liu,Jianqing Gao", "background": "大型语言模型在数学推理方面取得了显著进展，但仍难以进行高精度任务，如数值计算和形式符号操作。已有方法在构建工具集成推理数据、精细层级优化和增强推理方面仍存在三大挑战。", "innovation": "提出了一种名为THOR的方法，包括TIRGen多代理演员-评论家管道、基于RL的精细层级优化策略以及自校正机制，分别解决了数据构建、优化和推理中的问题。THOR通过实时工具反馈动态修正推理路径，提升了不同模型的泛化能力，并且在多个数学基准测试和代码基准测试中达到了最先进的性能。", "conclusion": "THOR方法在不同规模的数学推理模型和代码模型中表现出较强的性能提升和泛化能力，代码将公开可用。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13450", "html_url": "https://arxiv.org/abs/2509.13450", "title": "SteeringControl：评价大语言模型对齐引导的综合基准", "title_en": "SteeringControl: Holistic Evaluation of Alignment Steering in LLMs", "authors": "Vincent Siu,Nicholas Crispino,David Park,Nathan W. Henry,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang", "background": "在先前的研究中，对齐工作往往通过强调真实性或推理能力来展示对齐调优方法的副作用。然而，现有的研究很少系统地了解潜藏的权衡关系，包括对偏见、有害生成和幻觉等核心对齐目标的调优对次要行为如阿谀奉承和常识性道德的影响。", "innovation": "本文提出了SteeringControl，这是一个用于评估跨核心对齐目标——偏见、有害生成和幻觉——及其对次要行为如阿谀奉承和常识性道德的影响的有效性和行为缠结度的基准。SteeringControl收集了一个关于安全相关的主要和次要行为的数据集，并基于五种常见调优方法进行评估。文章还构建了一个模块化的调优框架，作为许多现有方法的基础组件。", "conclusion": "研究结果表明，强大的调优性能取决于特定组合的调优方法、模型和目标行为。错误组合这些因素可能导致严重概念缠结。研究成果同时也公开了相关代码：this https URL。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13625", "html_url": "https://arxiv.org/abs/2509.13625", "title": "大型语言模型中的隐私感知上下文学习", "title_en": "Privacy-Aware In-Context Learning for Large Language Models", "authors": "Bishnu Bhusal,Manoj Acharya,Ramneet Kaur,Colin Samplawski,Anirban Roy,Adam D. Cobb,Rohit Chadha,Susmit Jha", "background": "大型语言模型（LLMs）极大地改变了自然语言理解和生成，但同时也引发了隐私方面的担忧，因为可能会暴露敏感信息。研究指出，在潜在攻击者能够从提示中提取敏感信息的情况下存在信息泄露的风险。本文旨在解决这一问题，提出了一个新的隐私保护文本生成框架，利用差异隐私（DP）技术，确保信息泄露的最坏情况下的理论上限，同时生成高质量且连贯的合成文本，且不需对模型进行微调。此外，还提出了一种简单的混合操作，以进一步提高效用。实验结果显示，在上下文学习任务上，该方法优于现有的先进技术，意味着可以在保持高效用的情况下实现隐私保护的文本生成问题上取得进展。", "innovation": "该研究提出了一个利用差异隐私框架的新型隐私保护文本生成框架，该框架可以在生成高质量且连贯的合成文本的同时，确保最坏情况下的信息泄露理论上限。另外，还提出了一种简单的混合操作来增强效用。", "conclusion": "实验结果表明，该方法在上下文学习任务上的表现优于现有最先进的方法，展示了在确保隐私保护的情况下，仍能获得高效用的文本生成潜在前景。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13615", "html_url": "https://arxiv.org/abs/2509.13615", "title": "见，思考，行动：通过识别切换项来教授多模态代理与GUI有效互动", "title_en": "See, Think, Act: Teaching Multimodal Agents to Effectively Interact with GUI by Identifying Toggles", "authors": "Zongru Wu,Rui Mao,Zhiyuan Tian,Pengzhou Cheng,Tianjie Ju,Zheng Wu,Lingzhong Dong,Haiyue Sheng,Zhuosheng Zhang,Gongshen Liu", "background": "随着多模态代理在图形用户界面（GUI）中的交互作用变得有效，尤其是在通用GUI控制方面，但在执行切换控制指令方面的能力有限成为了一个关键障碍。因此，研究人员构建了基于公共数据集的二元切换指令基准测试，以评估现有代理的性能，并发现它们在当前切换状态与所需状态一致时的表现尤为不可靠。", "innovation": "提出了一种名为State-aware Reasoning（StaR）的训练方法，旨在使多模态代理能够感知当前切换状态，从指令中分析所需状态并作出相应行动。与三个多模态代理进行的实验表明，StaR可以提高切换指令执行的准确性超过30%。同时，在三个公共基准测试上的额外评估也显示了StaR对通用任务性能的增强效果。此外，StaR在动态环境中的评估突显了其在实际应用中的潜力。并提供了代码、基准数据和StaR改进的代理模型供外界使用。", "conclusion": "结果表明，StaR能显著提升多模态代理识别和执行切换指令的能力，从而提高其在GUI控制中的表现，并且该方法在更多任务上表现出色。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14128", "html_url": "https://arxiv.org/abs/2509.14128", "title": "Canary-1B-v2 & Parakeet-TDT-0.6B-v3: 高效且高性能的多语言语音识别与文本转语音模型", "title_en": "Canary-1B-v2 & Parakeet-TDT-0.6B-v3: Efficient and High-Performance Models for Multilingual ASR and AST", "authors": "Monica Sekoyan,Nithin Rao Koluguri,Nune Tadevosyan,Piotr Zelasko,Travis Bartley,Nick Karpov,Jagadeesh Balam,Boris Ginsburg", "background": "本文介绍了一个用于自动语音识别（ASR）和语音转文本翻译（AST）的快速且鲁棒的多语言模型——Canary-1B-v2。该模型使用FastConformer编码器和Transformer解码器，支持25种主要为欧洲语言的多语言任务。模型的训练基于170万小时的音频数据，包括Granary和NeMo ASR Set 3.0，以及添加的非语音音频以减少ASR和AST中的幻听。模型还使用了两种阶段的预训练和微调过程，以及动态数据平衡，同时进行了基于nGPT编码器的实验。实验结果表明，nGPT在大量数据下表现良好，经过微调后FastConformer也表现出色。此外还介绍了Parakeet-TDT-0.6B-v3模型，该模型具有相同的25种多语言支持，但只有600M参数。", "innovation": "Canary-1B-v2通过FastConformer编码器和Transformer解码器的结合，以及其强大的预训练和微调过程，显著提升了多语言语音识别和文本转语音的性能。同时，该模型在保持低参数量的同时，仍然能与更大模型如Seamless-M4T-v2-large和基于LLM的系统相比保持竞争力。Parakeet-TDT-0.6B-v3则通过减少参数量，在保持同样多语言支持的情况下，依然能够提供高效的ASR和AST性能。", "conclusion": "Canary-1B-v2在英语ASR上比Whisper-large-v3快10倍的同时表现更优，在多语言ASR和AST性能方面与Seamless-M4T-v2-large和基于LLM的系统相媲美。Parakeet-TDT-0.6B-v3则在提供同等多语言ASR性能时，参数量更少，更加高效。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13968", "html_url": "https://arxiv.org/abs/2509.13968", "title": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "title_en": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "authors": "Konstantinos Voudouris,Andrew Barron,Marta Halina,Colin Klein,Matishalin Patel", "background": "早期的研究大多关注少数关键变化对进化可能性的影响及其对后裔种群的重大后果。最近有研究提出，认知也可能通过一系列重大的演进来进化，这些重大变化操纵了生物神经网络的结构，从根本上改变了信息流动。为了评估信息流的变化是否能导致认知性能的重大变化，研究者使用了简化版的信息流模型和人工神经网络(ANN)进行研究。", "innovation": "研究者通过使用人工神经网络评估了信息流变化如何影响认知性能。他们比较了前馈、反馈和层状网络的不同网络结构，并测试了其在学习不同复杂度的人工语法上的表现，控制了网络大小和资源。结果显示反馈网络比前馈网络在处理复杂输入和学习复杂语法方面表现出明显更好的性能。此外，研究还发现训练反馈网络的难度构成了过渡障碍，这是一种进化的过渡特征。", "conclusion": "我们发现，某些变化的信息流可以导致认知性能的变化。然而，并非所有网络结构的改变都对任务表现有益。层状网络没有展现出优于非层状网络的学习语法的优势。总体而言，该研究表明某些信息流动的变化能够引发认知表现的过渡。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14041", "html_url": "https://arxiv.org/abs/2509.14041", "title": "TRRIP 沿时间轴探索：基于温度的重参考间隔预测方法以优化指令缓存", "title_en": "A TRRIP Down Memory Lane: Temperature-Based Re-Reference Interval Prediction For Instruction Caching", "authors": "Henry Kao,Nikhil Sreekumar,Prabhdeep Singh Soni,Ali Sedaghati,Fang Su,Bryan Chan,Maziar Goudarzi,Reza Azimi", "background": "现代移动CPU的软件由于其复杂的运行时行为导致同一指令执行之间的高重用距离，使得传统的指令缓存替换策略面临挑战。移动代码在CPU前端通常会有大量的停顿，导致其他CPU资源的饥饿。随着这些应用程序及其代码足迹的复杂性增加，其增长速度会超过可用的片上内存，尤其是由于功率和面积限制。传统的硬件中心的方法不足以管理指令缓存，因此，需要新的方法来优化缓存策略，比如通过软件和硬件的协作设计来实现这一目标", "innovation": "提出了一个名为TRRIP（温度基于的重参考间隔预测）的新型软件和硬件协同设计方案，通过引入“温度”（热点/冷点）的概念，以及通过OS接口利用代码页面属性向硬件提供代码温度信息，使编译器能够分析、分类并根据“温度”对代码进行优化从而提供更好的缓存策略。TRRIP的设计目标是实现实际移动系统的兼容性，特别是在软件与硬件组件有严格需求的情况下，可减少L2缓存的MPKI指令数26.5%，并获得3.9%的平均加速效果，尤其是在已经通过PGO优化过的移动代码上表现更为出色", "conclusion": "TRRIP能够通过有效地减少“热点”代码的缓存淘汰率来优化指令缓存替换策略，相较传统的RRIP缓存替换算法，它可以进一步降低L2的MPKI指令数，平均提升3.9%的速度，从而展示了在实际移动设备上的强大适用性与性能提升潜力"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13957", "html_url": "https://arxiv.org/abs/2509.13957", "title": "增强生成型推荐的时间意识", "title_en": "Enhancing Time Awareness in Generative Recommendation", "authors": "Sunkyung Lee,Seongmin Park,Jonghyo Kim,Mincheol Yoon,Jongwuk Lee", "background": "生成推荐作为一种有前景的范式，将推荐任务形式化为文本生成任务，利用大型语言模型的丰富知识。然而，现有的研究主要关注项目顺序，忽略了处理项目中的时间动态性，这可能暗示用户偏好的变化。", "innovation": "提出了一种名为GRUT（生成推荐利用时间感知）的新模型，有效地通过各种时间信号捕捉隐藏的用户偏好。该创新包括时间感知提示，以及趋势感知推断无监督方法，通过引入项目趋势信息增强排名。", "conclusion": "广泛的实验表明，GRUT在四个基准数据集上优于最先进的模型， Recall@5 和 NDCG@5 的提升分别达到了15.4%和14.3%。源代码可在该网址获取。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13941", "html_url": "https://arxiv.org/abs/2509.13941", "title": "自动问题解决中的失败经验研究", "title_en": "An Empirical Study on Failures in Automated Issue Solving", "authors": "Simiao Liu,Fang Liu,Liehao Li,Xin Tan,Yinghao Zhu,Xiaoli Lian,Li Zhang", "background": "自动问题解决旨在自主识别和修复整个代码库中的代码片段缺陷。SWE-Bench 已成为评估这一领域进展的最广泛采用基准。尽管基于大模型的代理型工具显示出巨大的潜力，但在许多任务上尚未达到预期表现。当前的评估主要集中在整体解决率上，这掩盖了成功的根本原因和失败的原因，使得难以诊断模型的弱点或指导针对性的改进。因此，本文分析了三种领先工具在 SWE-Bench-Verified 中的表现和效率，涵盖了管道型和代理型架构，并研究了不同任务特征下的自动化问题解决任务。进一步地，本文对150次失败实例进行了系统的手动分析，形成了一个涵盖三种主要阶段、九个主要类别和25个细分类别的失败模式综合性分类框架。通过这一分析，本文揭示了两种架构范式之间的失败模式差异，代理架构的大多数失败归因于推理缺陷和认知死锁。", "innovation": "本文提出了一个协作型专家执行者框架，引入了一个监督型专家代理，以提供战略指导和路线纠偏，主要针对辅助执行代理解决推理缺陷和认知死锁问题。实验结果显示，该框架解决了领先单代理无法解决的22.2%的问题，这为开发更具诊断性和合作性的代理提供了新路径。", "conclusion": "本文对自动问题解决中的失败模式进行了全面分析，揭示了不同架构的失败原因，并提出了一个协作型专家执行者框架来改善代理型工具的表现。这些发现为构建更稳健的代理提供了重要参考。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13836", "html_url": "https://arxiv.org/abs/2509.13836", "title": "从视觉角度探究缓解大型视觉语言模型幻觉的方法", "title_en": "Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models", "authors": "Weihang Wang,Xinhao Li,Ziyue Wang,Yan Pang,Jielei Zhang,Peiyi Li,Qiang Zhang,Longwen Gao", "background": "大型视觉语言模型（LVLMs）中的对象幻觉严重限制了它们在现实世界中的应用。作为准确解释视觉信息的主要组件，视觉编码器的选择至关重要。我们假设不同视觉编码器采用的不同训练范式赋予它们不同的归纳偏置，导致它们表现出不同的幻觉性能。现有的基准通常仅关注粗粒度的幻觉检测，未能捕捉到我们假说中详述的多样化幻觉。为了系统地分析这些影响，我们引入了包含约10,000个样本的VHBench-10，这是一个针对10种细粒度幻觉类别的评估基准。我们的评估证实了视觉编码器表现出独特的幻觉特征。", "innovation": "基于这些见解和简单特征融合的不足，我们提出了VisionWeaver，这是一种新颖的上下文感知路由网络。它利用全局视觉特征生成路由信号，动态聚合来自多个专业专家的视觉特征。全面的实验表明，VisionWeaver在显著减少幻觉并提高整体模型性能方面非常有效。", "conclusion": "我们的研究通过VHBench-10基准和VisionWeaver网络，证明了视觉编码器在LVLMs中起关键作用，也展示了如何通过上下文感知路由网络来有效减少幻觉。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14223", "html_url": "https://arxiv.org/abs/2509.14223", "title": "语言模型的激活线性编码训练顺序", "title_en": "Language models' activations linearly encode training-order recency", "authors": "Dmitrii Krasheninnikov,Richard E. Turner,David Krueger", "background": "研究表明语言模型在训练过程中提取了关于信息学习时间的信息。作者通过逐步微调 Llama-3.2-1B 模型在六个独立但相似的数据集上，发现测试样本的平均激活值按照训练顺序排列成一条直线。", "innovation": "本文展示了语言模型能够通过线性编码来表示信息在训练过程中学习的时间顺序。引入了一种新的方法，通过顺序微调大型语言模型在六个独立但相似的数据集上，发现激活值在时间维度上形成了一个线性关系。此外，还证明了线性探针能够高精度地区分“早”学和“晚”学的实体，并且即使在探针未见过的实体上也能保持高准确率。", "conclusion": "本文展示了模型在时间上区分信息的能力，并对模型如何处理冲突数据和知识修改具有重要意义。表明语言模型具备通过获取时间来区分类别信息的能力，这对于模型开发和应用具有重要意义。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2405.13541", "html_url": "https://arxiv.org/abs/2405.13541", "title": "通过多样化和具代表性的回应文本实现高效的语言模型对齐", "title_en": "Annotation-Efficient Language Model Alignment via Diverse and Representative Response Texts", "authors": "Yuu Jinnai,Ukyo Honda", "background": "偏好优化是将大型语言模型调优以与人类偏好一致的标准方法。偏好数据集的数量、多样性和代表性是偏好优化效果的关键。然而，在许多应用中获得大量偏好标注数据非常困难。因此，提出如何最有效地使用有限的标注预算来创建有效的偏好数据集的问题有了现实意义。", "innovation": "提出了名为Annotation-Efficient Preference Optimization (AEPO)的方法。AEPO选择最大化多样性和代表性的部分回应进行标注，而不是对所有可用的回应进行详尽标注。这样AEPO在对较小但具有信息性的回应子集进行标注时，聚焦了标注预算。我们在三个数据集上评估了偏好学习使用AEPO的性能，并证明了在相同的标注预算下，它超过了基准方法。", "conclusion": "AEPO在通过更小但更具代表性和多样性的回应数据集优化偏好学习方面取得了突破，证明了该方法的有效性。我们的代码可在以下链接获取：this https URL"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2308.07107", "html_url": "https://arxiv.org/abs/2308.07107", "title": "大语言模型在信息检索中的应用：一个综述", "title_en": "Large Language Models for Information Retrieval: A Survey", "authors": "Yutao Zhu,Huaying Yuan,Shuting Wang,Jiongnan Liu,Wenhan Liu,Chenlong Deng,Haonan Chen,Zheng Liu,Zhicheng Dou,Ji-Rong Wen", "background": "信息检索（IR）系统作为信息获取的主要手段，已经深入到日常生活中，并成为对话、问答和推荐系统的一部分。从基于词汇的方法发展到集成高级神经模型，虽然神经模型擅长捕捉复杂的上下文信号和语义细微差别，但仍然面临数据稀疏性、解释性差以及生成上下文合理但可能不准确的响应等问题。", "innovation": "大语言模型（LLMs），如ChatGPT和GPT-4，由于其卓越的语言理解和生成能力，正在帮助革新信息检索系统。研究人员开始利用这些模型来改进IR系统的性能。此外，本文研究了LLMs与IR系统的交汇点，涵盖了查询重写器、检索器、重排序器和阅读器等关键方面，并探索了搜索代理等未来研究方向，提供了对该领域的全面概述和深入见解。", "conclusion": "本文综述了大语言模型在信息检索中的应用，指出了结合传统方法（如基于词汇的稀疏检索方法）和现代神经架构（如语言模型的强大语言理解能力）的需求，并探讨了未来研究的潜在方向，以提供该领域的全面和细致的概述。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.16013", "html_url": "https://arxiv.org/abs/2406.16013", "title": "Database-Augmented Query Representation for Information Retrieval", "title_en": "Database-Augmented Query Representation for Information Retrieval", "authors": "Soyeong Jeong,Jinheon Baek,Sukmin Cho,Sung Ju Hwang,Jong C. Park", "background": "信息检索模型旨在根据查询搜索相关文档已经取得了多个成功，这些模型被应用到多种任务中。然而，用户查询往往较短，这给检索器正确检索相关文档带来了挑战。为解决这一问题，先前的研究提议通过添加与查询相关的特征来扩展查询，但这些特征可能无法有效地增强查询，并且数据库中还有很多其他可用的信息可以进行增强。", "innovation": "本研究提出了一个名为Database-Augmented Query Representation (DAQu)的新检索框架，该框架使用来自多个表的各种（查询相关的）元数据来增强原始查询。为了处理元数据特征数量庞大且无顺序的情况，研究采用了基于图的集合编码策略，该策略考虑了数据库中的特征层次结构而不考虑顺序。通过在多种检索场景下对DAQu进行验证，结果显示它在检索性能上显著优于相关基准模型。", "conclusion": "本研究通过Database-Augmented Query Representation (DAQu)框架显著提升了信息检索的整体性能。我们的代码可以在指定的链接处获取。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13790", "html_url": "https://arxiv.org/abs/2509.13790", "title": "因材施教！基于能力感知的渐进式调优大型语言模型", "title_en": "Teaching According to Talents! Instruction Tuning LLMs with Competence-Aware Curriculum Learning", "authors": "Yangning Li,Tingwei Lu,Yinghui Li,Yankai Chen,Wei-Chieh Huang,Wenhao Jiang,Hui Wang,Hai-Tao Zheng,Philip S.Yu", "background": "高效的指令调优旨在提高基于特定指令数据集训练的大规模语言模型（LLMs）的最终性能。课程学习作为一种典型的数据组织策略，在指令调优方面显示出初步的效果。然而，目前的课程调优方法存在刚性课程的问题，因为它们依赖于静态的启发式难度度量标准。这些方法无法适应模型在训练过程中不断发展的能力，从而导致固定的且可能是次优的学习路径。", "innovation": "提出了一种名为 CAMPUS 的框架，即 Competence-Aware Multi-Perspective cUrriculum inStruction tuning，具有以下优点：(1) 动态选择子课程，(2) 能力感知的课程时间表调整，(3) 多种基于难度的调度。实验结果表明，CAMPUS 相对于其他先进的基线方法在高效指令调优方面表现出优越的性能。", "conclusion": "CAMPUS 通过动态选择子课程、能力感知的课程时间表调整以及多种基于难度的调度，解决了现有课程调优方法中的僵化问题。实验结果验证了 CAMPUS 在高效指令调优方面的优越性能。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.11963", "html_url": "https://arxiv.org/abs/2407.11963", "title": "NeedleBench: 评估不同信息密度下LLM的检索和推理能力", "title_en": "NeedleBench: Evaluating LLM Retrieval and Reasoning Across Varying Information Densities", "authors": "Mo Li,Songyang Zhang,Taolin Zhang,Haodong Duan,Yunxin Liu,Kai Chen", "background": "大型语言模型处理长文本上下文的能力在多种实际应用中至关重要。现有的评估方法要么依赖真实的长文本，难以排除模型固有知识的影响；要么引入无关填充内容以达到目标长度，这降低了评估的有效性。", "innovation": "提出了NeedleBench，一种针对双语长上下文任务的合成框架，用于评估检索和推理性能，具备可调节的上下文长度。NeedleBench通过系统地嵌入关键数据点在不同深度，严格测试模型能力，将任务分为两类：信息稀疏（实施方案中相关细节稀缺）和信息密集（复杂推理情景，相关信息在上下文中连续分布）。实验结果表明，虽然近期的推理模型在数学推理方面表现出色，但在信息密集场景中，即使是较短的上下文长度，它们也难以持续进行有效的检索和推理。", "conclusion": "NeedleBench提供了评估和改进LLMs长上下文能力的关键见解和工具。所有资源可在OpenCompass网站找到。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.09252", "html_url": "https://arxiv.org/abs/2410.09252", "title": "DAVIS: Planning Agent with Knowledge Graph-Powered Inner Monologue", "title_en": "DAVIS: Planning Agent with Knowledge Graph-Powered Inner Monologue", "authors": "Minh Pham Dinh,Munira Syed,Michael G Yankoski,Trenton W. Ford", "background": "最近的人工智能（AI）研究中，设计能够在实验室环境中执行任务并辅助研究人员的通用型科学代理已成为关键目标。与日常生活中的任务不同，科学研究任务更为复杂和微妙，需要智能体具备更高的推理能力、对环境的结构化和时间化理解以及较强的安全性重视。现有的方法往往无法满足这些多方面的需求。", "innovation": "与传统的检索增强生成（RAG）方法不同，DAVIS融合了结构化和时间化的记忆，从而支持基于模型的规划。此外，DAVIS实现了一种代理性的、多轮次检索系统，类似于人类内心的对话，这使得能够对过去的经历进行更深层次的推理。DAVIS在科学世界基准测试中，在8个基础科学科目中表现出显著改进的性能，并且其世界模型在著名的HotpotQA和MusiqueQA数据集中的多跳问题回答任务上的表现也非常竞争力。", "conclusion": "据我们所知，DAVIS是第一个在RAG管道中使用交互式检索方法的RAG代理。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.14701", "html_url": "https://arxiv.org/abs/2407.14701", "title": "动态神经模型中词汇意义的语言理解的背景调节", "title_en": "Contextual modulation of language comprehension in a dynamic neural model of lexical meaning", "authors": "Michael C. Stern,Maria M. Piñango", "background": "该研究利用动态场理论框架推出了一个动态神经模型来阐述词汇意义的行为预测。特别地，通过聚焦英语词汇'have'的多义使用，该研究展示了这种模型的架构及其行为，并通过模拟重点解释了两方面的先前实验观察结果：一是上下文对词汇语义解释的调节，二是个体在这类调节中的差异幅度。相关模型模拟了实时词汇意义检索过程，并提出了新的预测假设——单次实验中句子阅读时间和可接受性的关系应受到上下文调节。", "innovation": "研究的新颖之处在于，它不仅模拟了词汇意义的稳定连接模式，而且还模拟了瞬时稳定状态之间的动态激活格局，这些格局对应于语义解释或读音。模型还推测了上下文调节对句子阅读时间和接受性的关系。此外，论文指出，模型在动态系统框架内相比其他模型具有重要优势，同时在贝叶斯推理的模型基础上提供了重要意义。", "conclusion": "研究支持了一个新的关于词汇多义性的视角，即一个词的许多相关含义不是彼此完全分离的表示，而是由支配解释的神经群体在连续语义维度上的非线性动态产生的瞬时稳定神经激活状态。实验数据验证了模型预测的一部分假设，并在一定程度上支持了该观点。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.13456", "html_url": "https://arxiv.org/abs/2410.13456", "title": "瑞士司法摘要解锁法律知识：瑞士多语言司法摘要数据集", "title_en": "Unlocking Legal Knowledge: A Multilingual Dataset for Judicial Summarization in Switzerland", "authors": "Luca Rolshoven,Vishvaksenan Rasiah,Srinanda Brügger Bose,Sarah Hostettler,Lara Burkhalter,Matthias Stürmer,Joel Niklaus", "background": "法律研究是一项耗时的任务，大部分律师在日常工作中都会面临。其中一大部分工作是查找相关的判例并将其与现行案件联系起来。律师依赖于摘要（也称为头注）来快速找到合适的案例。然而，并非所有判决都具有头注，编写这些摘要本身也很耗时。自动化摘要生成可以在瑞士等地方进一步使数十万判决书更易于用于法律研究。为了启动这一过程，我们介绍了一个新的瑞士领先的司法摘要（SLDS）数据集，该数据集包含18,000个瑞士联邦最高法院的法庭判决书，这些判决书以德语、法语和意大利语撰写，并带有德语摘要。", "innovation": "我们对三种mT5变体和自有模型进行了微调和评估，我们的分析表明，虽然自有模型在零样本和单样本设置中表现出色，但微调的小模型仍然具有很强的竞争优势。我们公开发布了该数据集，以促进多语言法律摘要的研究，并促进法律专业人士辅助技术的发展。", "conclusion": "我们通过公开发布的数据集促进了多语言法律摘要的研究，并为法律专业人士开发辅助技术提供了基础。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.10857", "html_url": "https://arxiv.org/abs/2410.10857", "title": "镜像一致性：利用众数投票中的不一致性", "title_en": "Mirror-Consistency: Harnessing Inconsistency in Majority Voting", "authors": "Siyuan Huang,Zhiyuan Ma,Jintao Du,Changhua Meng,Weiqiang Wang,Zhouhan Lin", "background": "自一致性是一种广泛使用的解码策略，可以显著提升大型语言模型（LLMs）的推理能力。然而，它依赖于多数投票规则，该规则关注最频繁的答案，而忽略了所有其他 minority 回答。这些不一致的少数观点往往揭示了模型生成过程中存在的不确定性。", "innovation": "我们提出了镜像一致性，这是对标准自一致性的增强。我们的方法在自ensemble解码过程中引入了‘反射镜’，使LLMs能够批判性地审查多次生成之间的不一致性。同时，为了更好地理解自己，我们还建议使用镜像一致性来增强基于样本的信心校准方法，从而减轻过度自信的问题。实验结果表明，镜像一致性在推理准确性和信心校准方面比自一致性表现更优。", "conclusion": "我们的实验结果表明，镜像一致性在推理准确性和信心校准方面均优于标准自一致性。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14221", "html_url": "https://arxiv.org/abs/2509.14221", "title": "GEM-Bench: 生成引擎营销中投放广告响应生成的基准", "title_en": "GEM-Bench: A Benchmark for Ad-Injected Response Generation within Generative Engine Marketing", "authors": "Silan Hu,Shiqi Zhang,Yimin Shi,Xiaokui Xiao", "background": "生成引擎营销（GEM）是一个新兴的生态系统，通过无缝集成相关广告到生成型引擎（如基于LLM的聊天机器人）的响应中实现盈利。在GEM的核心在于生成和评估带有广告的响应。然而，现有的基准测试并未专门为此目的设计，这限制了未来的研究。现有方法无法有效评估广告投放的效果，导致用户满意度低下。", "innovation": "本文提出了GEM-Bench，这是首个针对生成引擎营销中投放广告响应生成的全面基准测试。GEM-Bench 包含了三个定制的数据集，涵盖了聊天机器人和搜索场景，还包含了一个度量体系，并提出了几个基于扩展多代理框架的基线解决方案。", "conclusion": "初步研究结果表明，虽然简单的方法如通过提示能实现合理的点击率，但往往降低了用户满意度。相比之下，基于预先生成的无广告响应插入广告的方法虽能提升用户满意度，但增加了额外的操作复杂度。这些发现强调了未来研究需要设计更有效且高效的生成广告响应方案的重要性。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.12147", "html_url": "https://arxiv.org/abs/2409.12147", "title": "MAgICoRe: 多代理、迭代、粗到细的推理改进", "title_en": "MAgICoRe: Multi-Agent, Iterative, Coarse-to-Fine Refinement for Reasoning", "authors": "Justin Chih-Yao Chen,Archiki Prasad,Swarnadeep Saha,Elias Stengel-Eskin,Mohit Bansal", "background": "大型语言模型（LLM）的推理可以通过测试时聚合策略得到改进，例如生成多个样本并投票，这虽然提升了性能，但通常会达到饱和点。改进方案——精炼，可以通过LLM生成的反馈来提升解决方案的质量，然而它也带来了三个关键挑战：（1）过度精炼：均匀精炼所有实例可能会过度纠正并降低综合性能。（2）无法定位和纠正错误：LLM难以自我纠正并在识别和更正错误方面存在问题。（3）精炼不足：决定需要多少次迭代的精炼是不简单的，过早停止可能会遗留未解决问题。", "innovation": "该研究提出了MAgICoRe，这是一个多代理、迭代、从粗到细的改进策略，通过分类问题难度为简单或复杂，使用粗粒度聚合解决简单问题，使用细粒度和迭代多代理精炼解决复杂问题。引入外部逐步奖励模型（RM）分数以提高错误定位，并采用多代理循环，包含问题解决者、审核员（根据逐步RM分数生成有针对性的反馈）和精炼者（结合反馈）。进一步迭代地重新评估更新的解决方案以确保足够精炼。", "conclusion": "MAgICoRe 在 Llama-3-8B 和 GPT-3.5 上进行了评估，并显示了其在 5 个数学数据集上的有效性。即使经过一次迭代，MAgICoRe 也比自我一致性高出 3.4%，比 Best-of-k 高出 3.2%，比自我精炼高出 4.0%，同时使用的是较少数目的样本。与基线模型相比，MAgICoRe 随着迭代次数的增加继续改进。进一步的研究也强调了MAgICoRe的奖励模型和多代理通信的重要性。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.12478", "html_url": "https://arxiv.org/abs/2412.12478", "title": "基于人类辅助循环生成对抗性文本：藏文案例研究", "title_en": "Human-in-the-Loop Generation of Adversarial Texts: A Case Study on Tibetan Script", "authors": "Xi Cao,Yuan Sun,Jiajun Li,Quzong Gesang,Nuo Qun,Tashi Nyima", "background": "基于深度神经网络的语言模型在各种自然语言处理任务中表现出色，但仍然高度容易受到文本对抗性攻击的影响。尽管对抗性文本生成对于NLP的安全性、可解释性、评估和数据增强至关重要，相关工作仍然主要集中在英语上，导致低资源语言构建高质量和可持续的对抗性稳健性基准变得既困难又研究不足。主要挑战包括：方法定制复杂，由于语言差异和资源有限；自动攻击容易生成无效或模棱两可的对抗性文本；语言模型不断进化，可能会对之前生成的对抗性文本免疫部分部分。面对这些挑战，本文介绍了一种基于人类辅助循环生成对抗性文本的交互式系统——HITL-GAT，并通过藏文案例研究证明了HITL-GAT的实用性，包括使用三种定制的对抗性文本生成方法，并建立了该领域的第一个对抗性稳健性基准，为其他低资源语言提供了有价值的参考。", "innovation": "介绍了基于人类辅助循环生成对抗性文本的交互式系统HITL-GAT，并通过藏文案例研究展示其实用性。该系统使用三种定制的对抗性文本生成方法，建立了对抗性稳健性基准，解决了低资源语言对抗性文本生成和评估中的问题。", "conclusion": "通过证明HITL-GAT的有效性，文章为低资源语言构建和评估对抗性稳健性提供了最初的基础，并为其他低资源语言的研究提供了实践参考。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13351", "html_url": "https://arxiv.org/abs/2509.13351", "title": "教LLMs规划：逻辑链式推理指令调优对符号化规划的促进", "title_en": "Teaching LLMs to Plan: Logical Chain-of-Thought Instruction Tuning for Symbolic Planning", "authors": "Pulkit Verma,Ngoc La,Anthony Favier,Swaroop Mishra,Julie A. Shah", "background": "大型语言模型（LLMs）在各种任务中展现了令人印象深刻的能力，但在结构化符号规划领域，它们的能力仍然是有限的，尤其是在需要形式化表示的领域中，如规划领域定义语言（PDDL）。本文探讨了LLMs在符号化规划上的现有能力限制，并提出了一种新型指令调优框架，PDDL-Instruct，旨在通过逻辑链式推理方法增强LLMs的符号规划能力。", "innovation": "本文提出了PDDL-Instruct框架，通过逻辑链式推理来帮助LLMs提升符号规划能力。创新点在于引入了一种指令调优方法，使模型能够更严格地进行逻辑推理，从而判断动作的应用性、状态转换和计划的有效性。该方法通过开发引导模型进行精确逻辑推理的指令提示，使模型能够在结构化的反思中自我纠正规划过程，并逐步构建验证技能，将规划过程分解为预条件满足、效果应用和不变性保持的推理链。", "conclusion": "实验结果显示，基于逻辑链式推理的指令调优模型在多个规划领域中显著提高了规划能力，最高规划准确率达到94%，相比基线模型提高了66%。此研究填补了LLMs普遍推理能力和自动化规划所需逻辑精度之间的差距，为开发更好的AI规划系统提供了有希望的方向。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.01872", "html_url": "https://arxiv.org/abs/2501.01872", "title": "自身逻辑的反转：通过对比性问题探查模型防御", "title_en": "Turning Logic Against Itself : Probing Model Defenses Through Contrastive Questions", "authors": "Rachneet Sachdeva,Rima Hazra,Iryna Gurevych", "background": "尽管大规模语言模型经过广泛的人类价值观和伦理原则对齐，但仍易受到复杂的入侵攻击利用其推理能力。现有的安全性措施往往能检测到明显的恶意意图，但对于由推理驱动的、较为微妙的漏洞则束手无策。本研究旨在通过一个名为POATE（Polar Opposite query generation, Adversarial Template construction, and Elaboration）的新颖入侵技术来解决这一问题，该技术利用对比推理引发不道德的回复。POATE生成语义上对立的意图，并将它们与对抗模板结合，以实现令人惊讶的微妙引导模型产生有害输出的效果。本研究对六个不同参数大小的语言模型家族进行了广泛的评估，表明攻击的鲁棒性，成功的攻击率显著提高（约44%），远超现有方法的效果。", "innovation": "本研究引入了POATE（Polar Opposite query generation, Adversarial Template construction, and Elaboration）技术，这是首个利用对比推理发掘语言模型中微妙而复杂的漏洞的技术。此外，研究提出了意图感知的CoT（人类思维过程）和逆向思考的CoT方法，用以检测恶意意图并评估和拒绝有害响应，从而增强推理鲁棒性和防御机制，抵抗针对模型的对抗性利用。", "conclusion": "本研究在广泛的变化语言模型家族中展示了POATE技术的强大攻击效果，并提出了两种新的对抗防御方法（意图感知的CoT和逆向思考的CoT），这些方法可以更有效地检测和防御针对语言模型的奸巧攻击，从而增强语言模型的防御能力。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.13853", "html_url": "https://arxiv.org/abs/2509.13853", "title": "基于噪声监督对比学习与特征扰动的异常声检测", "title_en": "Noise Supervised Contrastive Learning and Feature-Perturbed for Anomalous Sound Detection", "authors": "Shun Huang,Zhihua Fang,Liang He", "background": "无监督异常声检测旨在仅使用正常音频数据训练模型来检测未知的异常声音。尽管自监督方法已经取得进展，但当处理来自不同机器的相同类型的样本时，仍存在频繁误报的问题。", "innovation": "提出了一种新颖的训练技术，称为一阶段监督对比学习（OS-SCL），它通过在嵌入空间中扰动特征并采取一阶段噪声监督对比学习方法，显著解决了这个问题。此外，提出了一种名为TFgram的时间-频率特征，该特征从原始音频中提取，能够有效捕捉异常声检测的关键信息。", "conclusion": "在DCASE 2020挑战任务2中，仅使用Log-Mel特征，OS-SCL技术取得了94.64% AUC、88.42% pAUC和89.24% mAUC的成绩。通过使用TFgram特征，实现了95.71% AUC、90.23% pAUC和91.23% mAUC的性能。源代码可用。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14132", "html_url": "https://arxiv.org/abs/2509.14132", "title": "当化身具有个性时：沉浸式医学培训中的参与与沟通效果", "title_en": "When Avatars Have Personality: Effects on Engagement and Communication in Immersive Medical Training", "authors": "Julia S. Dollis,Iago A. Brito,Fernanda B. Färber,Pedro S. F. B. Ribeiro,Rafael T. Sousa,Arlindo R. Galvão Filho", "background": "虚拟现实（VR）在模拟物理环境方面表现出色，但在培训复杂的人际技能方面效果有限，主要是因为缺乏心理上可信的虚拟人类。在像医学教育这样高风险的领域，良好的沟通能力是核心技能。现有研究指出，虚拟患者在保持医学一致性的同时，缺乏独特的、一致的个性，这对解决实际操作中的心理真实性具有挑战。", "innovation": "本文提出了一种框架，将大型语言模型（LLMs）集成到沉浸式VR中，创造出身临其境且医学上一致的虚拟患者，每个患者都有独立且一致的人格特征，基于模块化架构来分离人格和临床数据。研究结果表明，该方法不仅可行，还被医生认为是一种高回报且有效的培训增强工具。此外，研究揭示了关键设计原则，如“现实与冗余悖论”以及挑战的适度与真实性对于教育效果的重要性。", "conclusion": "本研究提供了一个验证过的框架和关键洞察，为开发下一代具有社交智能的VR培训环境奠定了基础。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.07445", "html_url": "https://arxiv.org/abs/2502.07445", "title": "忘记你所了解的大语言模型评估——大语言模型就像变色龙", "title_en": "Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon", "authors": "Nurit Cohen-Inger,Yehonatan Elisha,Bracha Shapira,Lior Rokach,Seffi Cohen", "background": "大语言模型（LLMs）在公开基准测试中经常表现出色，但这些高分可能会掩盖模型对数据集特定表面特征的过度依赖，而非真正的语言理解能力。研究者们意识到，需要一种方法来检测这些模型是否依赖于这些表面特征，而不是真正理解和应用语言的能力。因此，研究团队开发了一种名叫Chameleon Benchmark Overfit Detector (C-BOD)的元评估框架，该框架通过参数化变换系统性地扭曲基准测试的提示信息，并检测LLM的过度拟合情况。C-BOD通过改变输入方式但保留其语义内容和标签，来揭示模型性能是否由记忆模式驱动。", "innovation": "研究团队开发了一种名为C-BOD的元评估框架，通过参数化变换系统性地扭曲基准测试的提示信息，并检测LLM的过度拟合情况。这种方法能揭示模型性能是否由记忆模式驱动，并在MMLU基准测试中使用26个领先的大语言模型进行评估，发现平均性能下降了2.15%，其中20个模型表现出明显的统计差异。此外，C-BOD的设计具有数据集和模型的通用性，可以轻松集成到训练管道中，促进更可靠的语言理解。", "conclusion": "研究结果挑战了社区对大语言模型评估的现状，强调了在模型评估中超越排行榜分数的重要性，更应注重模型的弹性和泛化能力。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.09765", "html_url": "https://arxiv.org/abs/2501.09765", "title": "在教育数据中增强个人可识别信息的脱敏", "title_en": "Enhancing the De-identification of Personally Identifiable Information in Educational Data", "authors": "Zilyu Ji,Yuntian Shen,Jionghao Lin,Kenneth R. Koedinger", "background": "保护个人信息（如姓名）对于学习技术来说至关重要，以保护学生和教师的隐私并保持公众信任。准确检测个人信息是匿名处理敏感信息、同时保留教育数据实用性的关键步骤。受人工智能技术进步的启发，本文研究GPT-4o-mini模型作为成本效益高且高效的个人信息检测解决方案。我们探讨了提示技术和微调技术，并将GPT-4o-mini的性能与包括Microsoft Presidio和Azure AI Language在内的现有框架进行了比较。", "innovation": "本文提出了利用GPT-4o-mini模型进行个人信息检测的新方法，并通过微调技术显著提高了精度，降低了计算成本。在两次公共数据集CRAPII和TSCC上的评估显示，微调后的GPT-4o-mini模型在CRAPII上的召回率为0.9589，同时显著提高了精度（提高了三倍），计算成本降低了十分之一。此外，研究表明该模型在多元文化背景和性别中提供了一致的准确结果，进一步使用TSCC数据集的可推广性分析也证明其稳健性。", "conclusion": "微调后的GPT-4o-mini模型作为一种准确而成本效益高的个人信息检测工具在教育数据中的潜力得到了强调。它提供了强大的隐私保护，同时保留了数据用于研究和教学分析的实用性。本研究的代码已发布在GitHub上。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11176", "html_url": "https://arxiv.org/abs/2502.11176", "title": "LogiDynamics: 解析LLM推理中归纳、 abduction和演绎逻辑推理的动力学", "title_en": "LogiDynamics: Unraveling the Dynamics of Inductive, Abductive and Deductive Logical Inferences in LLM Reasoning", "authors": "Tianshi Zheng,Jiayang Cheng,Chunyang Li,Haochen Shi,Zihao Wang,Jiaxin Bai,Yangqiu Song,Ginny Y. Wong,Simon See", "background": "现代大型语言模型（LLMs）采用了多种逻辑推理机制进行推理，因此优化这些方法的战略对于提升其能力至关重要。本文系统研究了LLMs中归纳（System 1）与演绎/溯因（System 2）推理的比较动态。研究利用了受控的类比推理环境，并在模态性、难度和任务格式上进行了变化。研究表明，System 2 在视觉和符号模态以及更难的任务中通常表现更好，而System 1在文本和简单问题中具有竞争力。关键的是，任务格式显著影响它们的相对优势，有时System 1在自由文本规则执行中优于System 2。这些核心发现适用于更广泛的语境学习。此外，研究证明了高级的System 2策略如假设选择和迭代改进可以显著扩展LLM的推理能力。", "innovation": "本研究通过系统研究LLMs中归纳（System 1）与演绎/溯因（System 2）推理动力学，提供了关于如何战略性地部署逻辑推理以增强LLM推理能力的基石性见解和具体指南，并证明了高级System 2策略可以显著提升LLM的推理能力。", "conclusion": "本研究通过受控的类比推理环境，探讨了LLMs中不同推理类型的动态，发现System 2在视觉和符号模态及难度较高的任务中表现出色，而System 1在文本和简单问题中具有竞争力。研究结果为战略性地部署逻辑推理以增强LLM推理能力提供了基础性见解和实用指南，尤其是在自由文本规则执行方面，有时System 1优于System 2。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14093", "html_url": "https://arxiv.org/abs/2509.14093", "title": "通过自适应链推理压缩实现高效推理：一种自我优化框架", "title_en": "Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework", "authors": "Kerui Huang,Shuhan Liu,Xing Hu,Tongtong Xu,Lingfeng Bao,Xin Xia", "background": "链推理(CoT)增强大语言模型(LLMs)通过提示中间步骤，提高了数值运算、逻辑和常识任务的准确性和鲁棒性。然而，这种方法伴随着高计算成本：输出越长会导致延迟增加、内存使用量增加和KV缓存需求量增加。这些在对简洁和确定性输出有严格要求的软件工程任务中尤其关键。为了解决这些问题，研究者基于代码生成基准进行了实证研究，结果表明，过长的CoT并不总是有益的，过多的推理会导致信息截断、准确性下降甚至最长输出比成功输出更长且回归障碍，这些发现挑战了越长的推理就越好的假设，突显了适应性CoT控制的必要性。", "innovation": "研究提出了一种自适应框架SEER（Self-Enhancing Efficient Reasoning），通过结合Best-of-N抽样和任务感知自适应过滤，动态调整阈值以减少冗余和计算开销。此方法主要创新点在于实现了CoT推理的压缩，同时保持了准确度，这是通过减少干扰和循环的方式达成的。", "conclusion": "SEER通过缩短CoT推理过程、提高准确度并消除大部分无限循环，证明了它是一种在资源受限条件下使CoT增强的LLMs更加高效和稳健的实用方法。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15022", "html_url": "https://arxiv.org/abs/2502.15022", "title": "Mind the Style Gap: Meta-Evaluation of Style and Attribute Transfer Metrics", "title_en": "Mind the Style Gap: Meta-Evaluation of Style and Attribute Transfer Metrics", "authors": "Amalie Brogaard Pauli,Isabelle Augenstein,Ira Assent", "background": "大语言模型（LLMs）可以轻松地以任何风格重新编写文本，但对其评估并不容易。挑战在于测量内容保留：确保内容不因风格变化而改变。”内容并不被纳入风格变化的评判标准中。本文综述了几种用于评估风格和属性转移的任务的指标。现有的元评估研究表明，在现有数据集上的元评估可能导致关于评估指标适合内容保留任务的误导性结论。常用指标与人类判断高度相关，尽管它们被认定不适合任务，因为它们在评估内容保留时没有从风格变化中抽象出来。研究人员发现这种高度的相关性源自测试数据的性质。因此，他们构建了一个专门用于评估风格转移任务内容保留指标的新且具有挑战性的数据集，以解决这个问题。", "innovation": "该研究提出了一种全新且具有挑战性的数据集，专门用于评估风格转移任务中的内容保留指标。此外，他们还介绍了一种新颖的内容保留意识方法，利用小型语言模型进行评估，这种方法的准确性与同等规模的模型对比评估方法相比更高。", "conclusion": "合适的用于风格转移任务的内容保留指标在风格变化时是有着内容保留意识的。通过提出的新颖方法，他们验证了这种假设，并展示了它比相同规模的模型对比评估方法更为有效。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.19749", "html_url": "https://arxiv.org/abs/2502.19749", "title": "仍然未被说出的部分仍然会造成伤害：一种描述性评估框架以衡量LLMs中的社会偏见", "title_en": "What's Not Said Still Hurts: A Description-Based Evaluation Framework for Measuring Social Bias in LLMs", "authors": "Jinhao Pan,Chahat Raj,Ziyu Yao,Ziwei Zhu", "background": "大型语言模型（LLMs）常会继承训练数据中的社会偏见。现有的偏见评估基准主要通过直接关联人口统计学术语和偏见术语来评估偏见，虽然LLMs在避免产生偏见响应方面变得越来越熟练，导致表面看起来偏见水平较低，但实际上在隐性、上下文相关的形式中仍然存在未被传统基准捕捉到的偏见。", "innovation": "引入了描述性偏见基准（DBB），这是一种新型的数据集，旨在评估隐含在自然、微妙表述中的语义偏见。该基准改变了传统评价模式，深入到现实情景中的微妙背景中进行评估。", "conclusion": "尽管模型在术语层面减少了偏见，但在复杂的情境中仍然强化了偏见。该研究提供了衡量LLMs中隐性偏见的新方法，数据和代码可在指定网址获取。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.20581", "html_url": "https://arxiv.org/abs/2504.20581", "title": "ClonEval: 一个开放的语音克隆基准", "title_en": "ClonEval: An Open Voice Cloning Benchmark", "authors": "Iwona Christop,Tomasz Kuczyński,Marek Kubis", "background": "当前缺乏针对语音克隆文本到语音模型的标准评估基准及公开评估工具。", "innovation": "提出了首个用于语音克隆模型的新型基准——ClonEval，包含评估协议、开放源代码库以及排行榜。", "conclusion": "文章详细描述了评估过程，并展示了软件库的使用方法以及排行榜结果的组织方式。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.19301", "html_url": "https://arxiv.org/abs/2501.19301", "title": "超越制胜：探索AI文本中的创造性瓶颈", "title_en": "Beyond checkmate: exploring the creative chokepoints in AI text", "authors": "Nafis Irtiza Tripto,Saranya Venkatraman,Mahjabin Nahar,Dongwon Lee", "background": "大型语言模型（LLMs）的快速发展虽然彻底改变了文本生成，但也引发了对其潜在滥用的担忧，因此检测由LLMs生成的文本（即AI文本）变得至关重要。尽管先前的研究主要集中在识别和遏制AI文本上，但本研究关注一个未充分探索的领域：分析人类文本和AI文本在文本段落（引言、正文和结论）之间的细微差别。通过将文本段落比作国际象棋的开局、中盘和残局，研究揭示了各段落中最为明显的差异，并探讨了其对检测策略的影响。尽管AI文本在正文段落中与人类写作高度相似，但深入分析显示其在依赖语言连续流动的特征上有较高的差异，使得这一段落成为最具有检测价值的部分。此外，人类文本在各段落中的风格变化较大，为区分其与AI文本提供了新的视角。本研究为更好地理解和检测人工和AI文本之间的差异提供了新的见解，并为更加有效和可解释的检测策略铺平了道路。", "innovation": "本研究创新性地探讨了人类文本和AI文本在文本段落（引言、正文和结论）之间的细微差别，通过将文本段落比作国际象棋的不同阶段，分析了各段落中的特异性模式，揭示了AI文本与众人类文本之间的关键差异所在。此外，研究强调了正文段落虽然表面上与人类写作相似，但在深层次特征上存在显著差异，这对检测AI文本具有重要意义。研究还提出了人类文本在风格变化方面的新视角，进一步加深了对人工和AI文本区别的理解。", "conclusion": "研究结果为人工和AI文本之间的差异提供了新的见解，指出了在区分二者时应该重点关注的具体方面，并为开发更有效的检测策略提供了新的指导。通过强调人类文本与AI文本在风格变化和段落特定特征上的细微差异，研究为理解人工和AI文本提供了新视角，并为未来的研究提供了可能的方向。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.21670", "html_url": "https://arxiv.org/abs/2503.21670", "title": "COMI-LINGUA：Hindi-English Code-Mixing的多任务NLP专家标注大型数据集", "title_en": "COMI-LINGUA: Expert Annotated Large-Scale Dataset for Multitask NLP in Hindi-English Code-Mixing", "authors": "Rajvee Sheth,Himanshu Beniwal,Mayank Singh", "background": "现有的自然语言处理（NLP）数据集对于双语混合文本的支持不足，尤其是在像Hindi-English这样的复合语言上。COMI-LINGUA旨在填补这一空白，提供一个包含大量高质量实例的双语混合数据集，以支持多种NLP任务，拓宽了双语混合文本在实际场景中的应用范围，并突显了大规模专家标注数据集的重要性。", "innovation": "COMI-LINGUA引入了显著不同的创新：1) 数据集庞大且手动标注，涵盖超过125,000个高质量实例；2) 包含五种核心NLP任务，包括矩阵语言识别、词级语言识别、词性标注、命名实体识别和机器翻译；3) 进行了严格的预处理和过滤，确保数据在多种语言表示形式和领域中的一致性；4) 结合多任务学习，展示了闭源模型在零样本设置下的优越性能，强调了一击即用策略的有效性；5) 细调最新模型，显著提升了性能，特别是在POS和NER等结构敏感预测任务中，为Hinglish代码混合文本设立了新的基准。", "conclusion": "COMI-LINGUA不仅为Hindi-English双语混合领域提供了高质量的数据支持，而且展示了基于此数据集的模型能够显著提高处理双语混合文本的性能。这种数据集和模型的结合不仅对NLP研究有重要推动作用，还对实际应用场景如自动翻译、语音识别等领域具有重要意义。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13259", "html_url": "https://arxiv.org/abs/2505.13259", "title": "从自动化到自主性：科学发现中大型语言模型的综述", "title_en": "From Automation to Autonomy: A Survey on Large Language Models in Scientific Discovery", "authors": "Tianshi Zheng,Zheye Deng,Hong Ting Tsang,Weiqi Wang,Jiaxin Bai,Zihao Wang,Yangqiu Song", "background": "大型语言模型正在引发科学发现的范式转变，从特定任务的自动化工具演变成日益自治的代理，根本性地重新定义了研究过程和人机协作。本文系统地探讨了这一新兴领域，重点关注科学中LSTM角色和功能的变化。", "innovation": "本文引入了一个基础的三层分类法——工具、分析师和科学家，从科学研究生命周期的角度界定其日益增加的自治性和进化的责任。此外，还指出了诸如机器人自动化、自我改进和道德治理等关键挑战和未来研究方向。", "conclusion": "本文提供了一种概念架构和战略远见，指导AI驱动的科学发现的未来，促进快速创新和负责任的发展。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12381", "html_url": "https://arxiv.org/abs/2505.12381", "title": "从n元文到注意：模型架构如何学习和传播语言模型中的偏差", "title_en": "From n-gram to Attention: How Model Architectures Learn and Propagate Bias in Language Modeling", "authors": "Mohsinul Kabir,Tasfia Tahsin,Sophia Ananiadou", "background": "当前关于语言模型偏差的研究主要集中在数据质量上，而对模型架构和数据时间属性的关注相对较少。很少有研究系统地探究偏差的来源。本文提出了一种基于比较行为理论的方法，以解释训练数据与模型架构之间的复杂交互如何在语言建模过程中导致偏差传播。", "innovation": "作者利用最近将变换器与n-元语言模型联系起来的研究，评估了数据、模型设计选择和时间动态对偏差传播的影响。研究发现，n-元Lm对上下文窗口大小的偏差传播非常敏感，而变换器则显示出了架构的稳健性；培训数据的时间来源显著影响偏差；而且不同的模型架构对受控偏差注入的反应不同，某些偏差（如性取向）被不成比例地放大。", "conclusion": "随着语言模型的普及，本研究强调了需要采取一种整体的方法——跨越数据和模型维度追溯偏差的起源，而不仅仅是其症状，以减轻潜在的危害。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16252", "html_url": "https://arxiv.org/abs/2505.16252", "title": "局部化是否指导知识擦除？语言模型中局部参数归因的严格审查", "title_en": "Does Localization Inform Unlearning? A Rigorous Examination of Local Parameter Attribution for Knowledge Unlearning in Language Models", "authors": "Hwiyeong Lee,Uiji Hwang,Hyelim Lim,Taeuk Kim", "background": "大型语言模型经常保留无意中的内容，这引起了对知识卸载的广泛关注。最近的方法侧重于局部卸载，限制参数更新到特定区域，以期去除目标知识的同时保留不相关的普遍知识。然而，由于缺乏对卸载目标与保持通用知识之间权衡的稳健和全面评估，这些方法的有效性尚不确定。本文首先重新审视现有的局部卸载方法，并通过受控实验严格评估局部参数更新是否真能导致知识卸载。研究发现，有效知识卸载所需的参数修改集合并不是严格确定的，这挑战了局部卸载的核心假设，即参数局部性天然地代表有效的知识移除能力。", "innovation": "本文通过受控实验严格评估局部参数更新是否真能导致知识卸载，揭示了有效知识卸载所需的参数修改集合并不是严格确定的，这挑战了局部卸载的核心假设。通过这种方式，本文提供了一个新的视角来审视局部卸载的有效性，为未来的相关研究提供了有价值的信息。", "conclusion": "本文发现，局部参数更新对知识卸载的贡献不是绝对的，有效知识卸载所需的参数修改集合并不是严格确定的。这一发现挑战了局部卸载的核心假设，未来的研究需要进一步探索如何通过局部更新更有效地进行知识卸载，同时保持模型的学习能力。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.06207", "html_url": "https://arxiv.org/abs/2411.06207", "title": "KBM: 为大型语言模型动态检索划界知识边界", "title_en": "KBM: Delineating Knowledge Boundary for Adaptive Retrieval in Large Language Models", "authors": "Zhen Zhang,Xinyu Wang,Yong Jiang,Zile Qiao,Zhuo Chen,Guangyu Li,Feiteng Mu,Mengting Hu,Pengjun Xie,Fei Huang", "background": "大型语言模型（LLMs）经常难以应对动态变化的知识和处理未知的静态信息。检索增强生成（RAG）被用来解决这些问题，并且在提升LLM性能方面产生了重大影响。然而，我们发现并非所有问题都需要触发RAG。通过检索已知部分知识未知给LLM，并允许LLM回答其余部分，可以有效减少时间和计算成本。", "innovation": "本文提出了一种知识边界模型（KBM），用于表达给定问题的已知/未知，并确定是否需要触发RAG。在11个英语和中文数据集上的实验表明，KBM有效地划定了知识边界，显著减少了实现端到端最佳性能所需检索的比例。进一步的评估显示KBM在动态知识、长尾静态知识和多跳问题等复杂场景中有效，并证明了KBM作为外部LLM插件的功能。", "conclusion": "KBM有效地定义了知识的边界，减少了检索需求的比例，并展示了在复杂问题场景中的有效性，同时增强了大型语言模型的性能。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11051", "html_url": "https://arxiv.org/abs/2505.11051", "title": "CAMEO: 收集多语言情感言语语料库", "title_en": "CAMEO: Collection of Multilingual Emotional Speech Corpora", "authors": "Iwona Christop,Maciej Czajka", "background": "当前，研究情感识别及其他语音相关任务缺乏易于访问、可重现的数据集。已有的一些数据集难以提供标准化基准，使不同环境下的研究比较变得困难。为了解决这些问题，研究人员需要一个既包含多语言情感语料，又易于访问和重复使用的数据集。", "innovation": "CAMEO 收集了一个经过精心挑选和标准化的多语言情感语音数据集，并提供了跨情绪状态和语言的情感语音识别系统的标准化评估基准。通过该数据集，研究人员可以更方便地进行情感识别研究，确保研究结果的可重复性，并获得更公平、一致的评估结果。CAMEO数据集在Hugging Face平台上向公众开放，便于研究人员获取和使用。", "conclusion": "CAMEO的发布为情感识别等相关研究提供了一个新的标准化数据资源，提高了研究效率，增强了结果的可比性。通过提供详细的元数据、多语言支持和易于访问的数据，CAMEO促进了跨语言和情绪研究的发展，提升了领域内的合作与交流。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.14199", "html_url": "https://arxiv.org/abs/2509.14199", "title": "使用门控残差分词的密集视频理解", "title_en": "Dense Video Understanding with Gated Residual Tokenization", "authors": "Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu", "background": "高时间分辨率对于捕获视频理解中的细粒度细节至关重要。然而，当前的视频大型语言模型（VLLM）和基准测试主要依赖于低帧率抽样，比如均匀抽样或关键帧选择，这样会丢弃密集的时间信息。这样做虽然避免了逐帧分词带来的高成本和冗余计算，但不适用于快速变化的内容。此外，现有的基准测试也仅关注粗粒度的内容变化，而没有设计用于密集时间推理的任务。", "innovation": "本文引入了密集视频理解（DVU），通过减少分词时间和分词量，实现高帧率视频理解。提出了门控残差分词（GRT）框架，该框架包括两阶段过程：1) 基于运动补偿的跨组分词化（利用像素级运动估计跳过静态区域），从而实现分词数量和计算量的次线性增长；2) 场景内跨静态区域词的融合（在静态场景内合并词），进一步减少冗余，同时保留动态语义。", "conclusion": "在DIVE基准测试上的实验表明，GRT框架优于更大的VLLM基线，并且随着帧率的增加性能正向提升。这些结果强调了密集时间信息的重要性，并证明了GRT能够实现高效、可扩展的高帧率视频理解。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18614", "html_url": "https://arxiv.org/abs/2505.18614", "title": "MAVL：动画歌曲翻译的多语言音频-视频歌词数据集", "title_en": "MAVL: A Multilingual Audio-Video Lyrics Dataset for Animated Song Translation", "authors": "Woohyun Cho,Youngmin Kim,Sunghyun Lee,Youngjae Yu", "background": "歌词翻译需要准确传达语义并保留音乐节奏、音节结构和诗歌风格。在动画音乐中，这一挑战更加复杂，因为需要与视觉和音频线索对齐。现有的文本翻译方法并未充分利用音频和视频信息进行更丰富和更具表达力的翻译。目前缺乏一个集成文本、音频和视频的多语言、多模态基准数据集用于可唱歌词的翻译，以解决这一问题。", "innovation": "提出了一种名为Multilingual Audio-Video Lyrics Benchmark (MAVL) 的新数据集，这是第一个多语言、多模态数据集，用于支持可唱歌词翻译，该数据集整合了文本、音频和视频信息。此外，还提出了Syllable-Constrained Audio-Video LLM with Chain-of-Thought SylAVL-CoT，这种方法利用音频-视频提示，并且强加音节约束，以生成听起来自然的歌词。实验结果显示，SylAVL-CoT 模型在可唱性和上下文准确性方面显著优于基于文本的模型。", "conclusion": "多模态和多语言方法改善了歌词翻译的性能，这表明融合音频和视频数据可以实现更准确和自然的歌词翻译。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23759", "html_url": "https://arxiv.org/abs/2505.23759", "title": "当视觉语言模型捉襟见肘时：视觉语言模型为何无法领悟谜题", "title_en": "Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint", "authors": "Heekyung Lee,Jiaxin Ge,Tsung-Han Wu,Minwoo Kang,Trevor Darrell,David M. Chan", "background": "一类通过图像、空间布局和符号替换方式编码语言的迷语（称为Rebus谜题）给现有的视觉语言模型（VLMs）带来了独特的挑战。这些迷语不同于传统的图像描述或问答任务，要求模型进行多模态抽象、象征性推理和掌握文化、音素和语言双关等。本文在分析现有VLMs对Rebus谜题解析能力的基础上，提出并构建了一个多变的英语Rebus谜题的手工集和注释基准，涵盖了从简单的图示替换到依赖空间布局的线索（如“头”在“脚下”），以此来考察当代VLMs在解读和解决Rebus谜题的能力。", "innovation": "本文的主要创新在于提出了一个丰富多彩的英语Rebus谜题数据集，并通过分析不同VLMs在解决这些谜题时的表现揭示了它们的长处和不足。研究发现，虽然VLMs在解码简单视觉线索方面表现出一些惊人的能力，但在进行抽象推理、横向思考和理解视觉隐喻时却面临巨大困难。", "conclusion": "综合研究结果，本文得出结论，尽管VLMs在某些视觉线索解读上表现出了令人惊讶的能力，但在复杂的、需要抽象思维和理解视觉隐喻的任务中却表现出明显的不足，这表明在构建更智能、更具语言处理和推理能力的模型方面还有很大的提升空间。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18916", "html_url": "https://arxiv.org/abs/2505.18916", "title": "SCRum-9:社交媒体上多语言论点分类", "title_en": "SCRum-9: Multilingual Stance Classification over Rumours on Social Media", "authors": "Yue Li,Jake Vasilakes,Zhixue Zhao,Carolina Scarton", "background": "随着社交媒体上谣言分析的重要性日益增加，针对不同语言的谣言分析数据集成为了研究的迫切需求。现有的基于单一语言的数据集已经被广泛使用，但它们往往不能覆盖多种语言，导致研究的局限性。", "innovation": "论文创新性地提出了一个多语言对立分类数据集SCRum-9，包含9种语言的7,516条推特，其中包括超过2,100个经过事实核查的支持证据，并提供了来自多个母语者标注的置信度相关注释，以考虑到同域和异域标注者的一致性问题。该数据集被用来评估五种大型语言模型和两种多语言掩码语言模型在上下文学习（ICL）和微调设置中的表现，并首次探索了使用多语言合成数据进行谣言立场分类的可能，即使ICL表现不强的语言模型也能生成有价值的数据用于微调小的多语言模型。", "conclusion": "本文展示了使用大规模多语言数据集（如SCRum-9）评估和改进语言模型的方法，以及模型预测与人类不确定性之间的关系研究。研究表明，即使在完全零样本ICL中表现不佳，一些语言模型仍然能够通过对齐的多语言数据生成有价值的合成数据，从而超越零样本ICL表现，在微调后的模型中取得更好的效果。此外，模型的预测有时会与标注者所选择的第二选择标签一致，这也揭示了模型预测并不总是完全偏离人类判断的现象。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.02478", "html_url": "https://arxiv.org/abs/2506.02478", "title": "FroM：基于弗罗贝尼乌斯范数的数据无关自适应模型合并", "title_en": "FroM: Frobenius Norm-Based Data-Free Adaptive Model Merging", "authors": "Zijian Li,Xiaocheng Feng,Huixin Liu,Yichong Huang,Ting Liu,Bing Qin", "background": "随着大型语言模型的发展，微调已成为通过注入领域特定知识来在特定场景中增强性能的有效方法。在此背景下，模型合并技术提供了一种通过结合多个微调模型的参数来融合其知识的解决方案。然而，传统方法在合并完整微调模型时经常遇到任务干扰问题，这一问题在参数高效微调场景中尤为明显。", "innovation": "本文提出了一种基于弗罗贝尼乌斯范数的数据无关的自适应模型合并方法（FroM），该方法直接测量模型参数，无需任何训练数据。通过引入一个额外的超参数进行控制，FroM 在各种微调场景中都优于基线方法，从而缓解任务干扰问题。", "conclusion": "FroM 方法通过直接基于模型参数和弗罗贝尼乌斯范数来计算模型合并，避免了传统方法中的任务干扰，提高了微调模型的性能。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.00132", "html_url": "https://arxiv.org/abs/2504.00132", "title": "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B", "title_en": "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B", "authors": "Aleksandra Bakalova,Yana Veitsman,Xinting Huang,Michael Hahn", "background": "尽管对大型语言模型（LLMs）的嵌入式学习（ICL）的行为方面进行了大量研究，并在小型设置中观察到其出现，但目前仍不清楚哪种机制能够从少量提供的提示中的单个示例中组装任务信息。Gemma-2 2B 是用于研究这种机制的一个平台，通过因果干预来识别信息流，以进一步理解嵌入式学习的过程。", "innovation": "本文提出了一种两步策略，称为`上下文化-然后聚合`，来理解大型语言模型中的嵌入式学习机制。具体来说，在较低的层中，模型通过前后输入和输出令牌之间的连接上下文化单个示例的表示；在较高层中，这些表示被聚合以识别任务并为下一个输出做预测。此外，研究还发现，上下文化步骤在不同任务中的重要性不同，在存在歧义示例时可能变得更加重要。通过提供严格的因果分析，该研究揭示了语言模型中嵌入式学习发生的机制。", "conclusion": "研究结果表明，Gemma-2 2B 中的模型通过一个两步骤策略 `上下文化-然后聚合` 来处理少量示例中的任务信息。这一机制依赖于上下文化步骤，并且在不同任务和存在歧义示例的情况下可能会有所不同。通过因果干预方法，本研究为理解嵌入式学习的机制提供了新的见解。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00658", "html_url": "https://arxiv.org/abs/2506.00658", "title": "Sarc7: 使用七种类型和情感启发技术评估反话检测与生成", "title_en": "Sarc7: Evaluating Sarcasm Detection and Generation with Seven Types and Emotion-Informed Techniques", "authors": "Lang Xiong,Raina Gao,Alyssa Jeong,Yicheng Fu,Sean O'Brien,Vasu Sharma,Kevin Zhu", "background": "反话是一种幽默形式，其表达的意义与其字面意义相反。使用大规模语言模型进行反话分类和生成对于理解人类交流至关重要。然而，反话由于其微妙的性质，对计算模型构成挑战。", "innovation": "文章引入了Sarc7基准，该基准通过标注MUStARD数据集的条目对七种类型的反话（自我解嘲、沉思、呆板、委婉、粗鲁、愤怒、狂热）进行了分类。此外，文章提出了一种基于情感的生成方法，通过识别反话不一致性、冲击值和情境依赖性中的关键成分。在分类实验中，使用基于情感的提示技术的Gemini 2.5表现出色，F1得分为0.3664。人类评估者更偏好基于情感的提示技术，成功生成的比例提高了38.46%。", "conclusion": "分类实验结果显示，在使用基于情感的提示技术的情况下，Gemini 2.5取得了最好的效果，F1得分为0.3664。而且，人类评估者更喜欢我们的基于情感的提示技术，成功率提高了38.46%。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23804", "html_url": "https://arxiv.org/abs/2505.23804", "title": "通过利用子句频次校准大语言模型进行文本到SQL解析", "title_en": "Calibrating LLMs for Text-to-SQL Parsing by Leveraging Sub-clause Frequencies", "authors": "Terrance Liu,Shuyi Wang,Daniel Preotiuc-Pietro,Yash Chandarana,Chirag Gupta", "background": "大型语言模型（LLMs）在文本到SQL解析方面表现出色，但在某些情况下，可能会出现无根据的错误，即模型表现出自信但错误的结果。因此，构建可信赖的文本到SQL系统需要从LLM中提取可靠的信心度量。本文研究了如何提供校准后的置信分数，以传达输出查询正确性的概率。首次建立了基于LLM的文本到SQL解析的后验校准基准。通过实验发现Platt校准有助于提高模型输出的概率作为置信分数的效果，并提出了一种新的方法，利用SQL查询结构提供更细致的正确性信号，称为“子句频次”（SCF）分数。通过多变量Platt校准（MPS）将这些分数组合，得到更准确和校准的综合分数。实验结果显示，结合MPS和SCF方法在测量校准和错误检测相关任务上优于传统Platt校准方法。", "innovation": "首次建立了基于LLM的文本到SQL解析的后验校准基准；使用多变量Platt校准（MPS）将子句频次（SCF）分数结合，提供更准确和校准的综合分数；展示了Platt校准在提供可靠信心度量上的有效性；提出了利用SQL查询结构提供更细致正确性信号的方法。", "conclusion": "通过多变量Platt校准（MPS）结合子句频次（SCF）分数的方法，在校准和错误检测相关任务上提高了传统Platt校准方法的效果。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.05262", "html_url": "https://arxiv.org/abs/2504.05262", "title": "大型语言模型在加法规则理解上真正到位了吗？基于两整数算术的规则导向诊断", "title_en": "Do Large Language Models Truly Grasp Addition? A Rule-Focused Diagnostic Using Two-Integer Arithmetic", "authors": "Yang Yan,Yu Lu,Renjun Xu,Zhenzhong Lan", "background": "大型语言模型（LLMs）在高级数学基准测试中取得了显著成果，但在基本算术任务上有时会失败，这引发了一个问题：它们是否真正掌握了基本的算术法则，还是仅仅依赖于模式匹配。为了探究这一问题，该研究系统地测试了LLMs对两个整数加法（0至2^64）的理解，重点关注交换律（A+B=B+A）、符号重组不变性以及随操作数长度的准确度一致性三个方面。评估结果显示，尽管模型在数值准确度方面表现出较高水平（73.8%-99.8%），但在诊断测试中却全面失败，尤其是在符号输入、交换律违反率和准确度随操作数长度变化方面表现不佳。进一步的干预措施显示，明示规则会降低模型性能，而请求解释则仅能维持基本准确度。这些结果表明，当前的LLMs在进行基础加法时依赖于模式匹配，而不是稳健的规则归纳，因此需要开发新的诊断基准和模型架构与训练方法，以培养真实的数学推理能力。", "innovation": "该研究通过系统地测试大型语言模型在两整数加法（0至2^64）中的理解和性能，发现现有的大型语言模型在复杂的模式匹配表象下，表现出对基本加法规则掌握不足的问题。研究揭示了显著的模式匹配依赖性，并通过提供规则和请求解释的干预措施进一步确认了这一现象，这为未来的研究提供了新的方向和挑战。研究还强调了构建新的诊断基准和改进模型架构与训练方法的必要性，以促进真正的数学推理能力的发展。研究人员的数据集和生成代码可以在指定的网址获取，这为同行研究者提供了宝贵的资源", "conclusion": "当前的大型语言模型依靠模式匹配来解决基本加法问题，而不是通过生成性的规则归纳，这表明需要新的诊断基准、模型架构和训练技术来培养强大的数学推理能力。该研究结果促进了对大型语言模型能力的深入理解，并指明了未来研究的方向。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.24621", "html_url": "https://arxiv.org/abs/2505.24621", "title": "为密码分析和侧信道漏洞基准测试大型语言模型", "title_en": "Benchmarking Large Language Models for Cryptanalysis and Side-Channel Vulnerabilities", "authors": "Utsav Maskey,Chencheng Zhu,Usman Naseem", "background": "最近，大型语言模型（LLMs）的进步已经改变了自然语言理解与生成，广泛应用于各种任务。然而，在LLMs评估中，对于数据安全关键领域的密码学分析研究仍然不足。本文通过对照加密算法产生的密文，评估当前最先进的LLMs的密码分析潜力，填补了这一缺口。文章引入了一个针对多样化的明文数据集，这些明文跨越多个领域、长度、写作风格和话题，并与加密后的版本进行配对。在零样本与少量样本设置下，利用完整推理提示，评估LLMs的解密成功率与理解能力，揭示了LLMs在侧信道场景中的关键洞察和局限，引发了对未来专家过度泛化的担忧，并提出了关于数据安全的AI安全讨论。", "innovation": "本文首次针对加密算法产生的密文，对比评估了当前最先进的大型语言模型的密码分析潜力，引入了多样化明文及其加密版本的基准数据集，进行了零样本与少量样本设置下的评估，并通过完整推理提示考察LLMs的理解能力，揭示了在密码分析和侧信道场景中的局限，促进数据安全与AI安全的讨论。", "conclusion": "研究结果揭示了LLMs在侧信道场景中的优势与不足，并提出了数据安全领域AI安全的担忧。该研究强调了LLMs在安全领域的双重用途，并推动了AI安全与数据安全的讨论。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02618", "html_url": "https://arxiv.org/abs/2508.02618", "title": "通过交互提炼消除基于偏好的奖励模型中的注意力黑客攻击", "title_en": "Mitigating Attention Hacking in Preference-Based Reward Modeling via Interaction Distillation", "authors": "Jianxiang Zang,Meiling Ning,Shihan Dou,Jiazheng Zhang,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "奖励模型（RM）是大规模语言模型（LLMs）从人类反馈（RLHF）强化学习的核心组件，负责提供对生成响应的奖励信号。然而，主流的偏好建模在词元级交互方面存在不足，使其判断信号容易受到注意力分配不当的影响。这是因为现有偏好建模采用了仅支持解码器的架构，导致上下文中的双向因果注意力机制在提示-响应序列中产生视线衰减效应；同时也因为独立的Siamese编码范式导致选中序列与被拒绝序列之间缺乏词元级的跨序列注意力。", "innovation": "提出了一种名为'交互提炼'的新型训练框架，以通过注意力层面的优化实现更充分的偏好建模。该方法引入了一个基于交互的自然语言理解模型作为教师，通过全面的注意力提供高级词元交互模式，并通过注意力对齐目标引导偏好建模模拟教师模型的交互模式。", "conclusion": "交互提炼在大量的实验中展示了其提供比最先进的RM优化方法（针对数据噪声）更加稳定和泛化的奖励信号的能力，表明注意力黑客攻击是RM中更具根本性的局限性。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15214", "html_url": "https://arxiv.org/abs/2508.15214", "title": "大型语言模型通过逐步经验回忆进行自我引导的功能调用", "title_en": "Self-Guided Function Calling in Large Language Models via Stepwise Experience Recall", "authors": "Sijia Cui,Aiyao He,Shuai Xu,Hongming Zhang,Yanna Wang,Qingyang Zhang,Yajing Wang,Bo Xu", "background": "大型语言模型（LLMs）能够通过利用工具和API与外部系统进行交互。然而，当面对多步骤的工具使用时，模型仍然难以进行工具选择、参数生成以及工具链规划。现有方法通常依赖于手动设计的任务特定演示，或者从精心挑选的库中检索。这些方法要求大量的专家努力，并且随着工具多样性和任务难度的增加，提示工程变得越来越复杂和低效。", "innovation": "本文提出了一种自我引导的方法，逐步经验回忆（SEER），它从不断地更新的经验池中进行精细的、逐步的检索。SEER 不依赖于静态或手动挑选的库，而是通过增加过去的成功轨迹来逐步扩展经验池，从而实现模型性能的持续改进。SEER 在 ToolQA 子基准和 $\tau$-bench 上分别提高了 6.1% 和 7.44% 到 23.38% 的准确性。", "conclusion": "实验结果表明，SEER 在 ToolQA 基准上总体提高了 4.7% 到 6.1% 的分数，并在 $\tau$-bench 上提高了显著的准确性。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02013", "html_url": "https://arxiv.org/abs/2508.02013", "title": "SpeechRole: 一个评估语音角色扮演代理的大规模数据集和基准", "title_en": "SpeechRole: A Large-Scale Dataset and Benchmark for Evaluating Speech Role-Playing Agents", "authors": "Changhao Jiang,Jiajun Sun,Yifei Cao,Jiabao Zhuang,Hui Li,Xiaoran Fan,Ming Zhang,Junjie Ye,Shihan Dou,Zhiheng Xi,Jingqi Tong,Yilong Wu,Baoyu Fan,Zhen Wang,Tao Liang,Zhihui Fei,Mingyang Wan,Guojun Ma,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "近年来，角色扮演代理作为一种实现个性化交互和情感共鸣的有前景的范式得到了发展。现有研究主要集中在文本模态，忽视了现实交互场景中语音维度的重要性。特别是在现实语音角色扮演代理的系统性评估方面存在空白。", "innovation": "本文构建了一个名为SpeechRole-Data的大规模高质量数据集，包含98种不同的角色和112k基于语音的单轮和多轮对话。同时，提出了SpeechRole-Eval，这是一种多维度的评估基准，系统评估SRPAs在关键方面的性能，如基本交互能力、语音表达能力和角色扮演的忠实度。同时，实验结果揭示了级联和端到端语音角色扮演代理在保持语音风格一致性和角色连贯性方面的优势与挑战。", "conclusion": "我们发布了所有数据、代码和基线模型，旨在为语音驱动的多模态角色扮演研究提供坚实的基础，并促进该领域的进一步发展。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15709", "html_url": "https://arxiv.org/abs/2508.15709", "title": "通过位置间知识蒸馏消除位置偏见：通过位置间知识蒸馏消除位置偏见", "title_en": "Position Bias Mitigates Position Bias:Mitigate Position Bias Through Inter-Position Knowledge Distillation", "authors": "Yifei Wang,Feng Xiong,Yong Wang,Linjing Li,Xiangxiang Chu,Daniel Dajun Zeng", "background": "位置偏见（PB）使得在不同上下文位置上的敏感度不一致，严重影响了长上下文的理解和处理能力。先前的研究通过修改底层架构或进行广泛的上下文感知训练来解决PB问题，但前者的解决方法未能有效消除显著的表现差异，而后者则会带来大量数据和计算上的负担。", "innovation": "本文引入了位置到位置的知识蒸馏框架Pos2Distill。该框架通过将有利位置的优点传递给不利位置，从而减小了巨大的性能差距。Pos2Distill的设计理念是利用位置诱导的内在差异来对抗PB本身。针对检索和推理两种范式，分别设计了Pos2Distill-R1和Pos2Distill-R2，从而显著提高了长上下文检索和推理任务中各上下文位置的一致性和整体性能。", "conclusion": "通过Pos2Distill方法，所有上下文位置在长上下文检索和推理任务中的表现均得到了提升。两个特定系统在交叉任务中表现出强大的泛化能力和各自任务中的出色性能。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.16123", "html_url": "https://arxiv.org/abs/2506.16123", "title": "FinCoT：将链式思考接地于专家金融推理", "title_en": "FinCoT: Grounding Chain-of-Thought in Expert Financial Reasoning", "authors": "Natapong Nitarach,Warit Sirichotedumrong,Panop Pitchayarthorn,Pittawat Taveekitworachai,Potsawee Manakul,Kunat Pipatanakul", "background": "本文介绍了一种名为FinCoT的结构化链式思考（CoT）提示框架，该框架嵌入了特定领域的专家金融推理蓝图，以指导大型语言模型的行为。目前，金融自然语言处理（FinNLP）中常用的提示方式包括标准提示（零样本）、无结构链式思考（自由形式推理）以及结构化链式思考（具有明确结构化的推理步骤）。此前的研究主要关注前两种方式，而第三种结构化链式思考尚未得到充分探索，缺乏领域专家的知识整合。因此，本文评估了这三种提示方法在十个CFA风格金融领域中的表现，并引入FinCoT作为一种结合领域专家蓝图的结构化金融特定提示方法，旨在提升通用模型Qwen3-8B-Base和专门针对金融的模型Fin-R1的性能。研究表明，FinCoT在提高性能和减少推理成本的同时，还提供了更可解释和与专家共识一致的推理轨迹。", "innovation": "本文创新性地提出了FinCoT框架，这是第一个结合了领域专家蓝图的结构化金融特定提示方法，它能够显著提高通用模型和专门金融模型的准确性，同时减少输出长度，并且在缺乏金融后训练模型中表现尤为出色。这一方法不仅能提高模型表现和减少推理成本，还能产生更具解释性和专家一致性的推理轨迹。", "conclusion": "FinCoT在一系列金融领域的测试中展现出了显著的性能提升，特别是对于缺乏金融后训练的模型而言，FinCoT的效果尤为明显。此外，FinCoT通过结构化细化链式思考，不仅提高了模型的准确性和效率，还增强了模型推理的可解释性和与专家共识的一致性。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.10486", "html_url": "https://arxiv.org/abs/2506.10486", "title": "表格文本对齐：解释基于科学论文表格的声明验证", "title_en": "Table-Text Alignment: Explaining Claim Verification Against Tables in Scientific Papers", "authors": "Xanh Ho,Sunisth Kumar,Yun-Ang Wu,Florian Boudin,Atsuhiro Takasu,Akiko Aizawa", "background": "自然科学研究论文中的声明验证通常需要预测给定表格的情况下，声明是支持还是反驳。然而，我们主张仅预测最终标签是不足够的：因为这未能揭示模型的推理过程，也缺乏解释性。", "innovation": "本文将表格-文本对齐重新定义为解释任务，要求模型识别对声明验证至关重要的表格单元格。为此，作者构建了一个新的数据集，扩展了SciTab基准数据集，其中包括由人类标注的单元格级解释。通过这一方法，作者还提出了处理歧义情况的分类法。实验表明，(i) 考虑表格对齐信息可以提升声明验证性能，(ii) 大多数语言模型虽然经常能正确预测标签，但无法恢复人标注的解释，暗示它们的预测并非源自忠实推理。", "conclusion": "本文强调了在声明验证中精确定位关键信息的重要性，并通过新的数据集和模型评估展示了这一方法的有效性。这为未来的科学研究提供了更有解释性的验证方法。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21137", "html_url": "https://arxiv.org/abs/2508.21137", "title": "认知偏差如何影响大语言模型？价格谈判模拟中锚定效应的案例研究", "title_en": "How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations", "authors": "Yoshiki Takenami,Yin Jou Huang,Yugo Murawaki,Chenhui Chu", "background": "人类认知偏差已经在过往研究中被广泛探讨，它们影响了人类在现实生活中的可靠性。本研究旨在探讨大语言模型（LLMs）在驱动价格谈判时是否存在锚定效应及其影响。", "innovation": "研究通过指示LLM售卖代理应用锚定效应，并使用客观和主观度量评估谈判情况。此外，研究探讨了锚定效应与推理和人格因素之间的关系，发现推理模型对锚定效应的敏感性较低，但没有发现性格特质与锚定效应敏感性的显著相关性。", "conclusion": "研究为理解LLMs中的认知偏差提供了更深入的理解，并有助于实现安全和负责任地应用LLMs于社会生活。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.18655", "html_url": "https://arxiv.org/abs/2508.18655", "title": "Empathy Omni: 通过大型语言模型实现具有同理心的语音响应生成", "title_en": "Empathy Omni: Enabling Empathetic Speech Response Generation through Large Language Models", "authors": "Haoyu Wang,Guangyan Zhang,Jiale Chen,Jingyu Li,Yuehai Wang,Yiwen Guo", "background": "随着语音大语言模型（speech LLMs）的发展，用户现在可以直接通过语音与助手交流。然而，现有模型通常只将响应内容转换成语音，而未能充分捕捉用户查询中的丰富情感线索，导致相同的句子可能会因为表达方式不同而传达不同的意思。因此，提高情感理解对于改善人机交互至关重要。大多数具有同理心的语音大语言模型依赖于大规模数据集，从而导致计算成本高昂。一个关键挑战是如何在有限的数据和不进行大规模训练的情况下生成同理心强的响应。", "innovation": "本文提出了一种名为Emotion Omni的模型，能够理解用户语音中的情感内容并生成具有同理心的响应。此外，还开发了一条数据管道构建了一个包含20万条对话的精确情感数据集，以支持具有同理心的语音助手。实验结果表明，Emotion Omni在指令遵循能力（无需大规模预训练）、语音质量和同理心方面（Emotion GPT Score: 3.97）优于现有模型（UTMOS:4.41），证实了其在语音质量和情感表征方面的改进。", "conclusion": "Emotion Omni模型通过理解用户语音中的情感内容并生成具有同理心的响应，相比现有依赖大规模数据集和训练的方法，在有限数据条件下取得了较好的效果。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19813", "html_url": "https://arxiv.org/abs/2508.19813", "title": "T2R-bench: 一个从实际工业表生成文章级报告的基准", "title_en": "T2R-bench: A Benchmark for Generating Article-Level Reports from Real World Industrial Tables", "authors": "Jie Zhang,Changzai Pan,Kaiwen Wei,Sishi Xiong,Yu Zhao,Xiangyu Li,Jiaxin Peng,Xiaoyan Gu,Jian Yang,Wenhan Chang,Zhenhe Wu,Jiang Zhong,Shuangyong Song,Yongxiang Li,Xuelong Li", "background": "已有大量研究探讨了大规模语言模型（LLMs）在表格推理方面的功能。然而，将表格信息转换为报告这一核心任务在工业应用中仍然是一个显著挑战。这一任务主要受到两个关键问题困扰：1）表格的复杂性和多样性导致推理结果不尽如人意；2）现有的表格基准无法充分评估这一任务的实际应用能力。为解决这一问题，我们提出了表格到报告的任务，并构建了一个双语基准T2R-bench，涵盖了从表格到报告的信息流。该基准包括457个来自实际场景的工业表格，涉及19个工业领域和4种类型的工业表格。", "innovation": "我们提出了表格到报告的任务，并构建了一个双语基准T2R-bench，该基准涵盖了从表格到报告的信息流。该基准包括457个来自实际场景的工业表格，涉及19个工业领域和4种类型的工业表格。我们还提出了评估标准以公平衡量报告生成的质量。实验表明，即使是最先进的模型Deepseek-R1的总体得分为62.71，也表明LLMs在T2R-bench上仍有改进空间。", "conclusion": "我们的实验表明，即使是当前最先进的模型Deepseek-R1在T2R-bench上的表现也只有62.71的总体分数，表明大规模语言模型在这一任务上仍有改进的空间。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19546", "html_url": "https://arxiv.org/abs/2508.19546", "title": "语言模型识别歧义并利用漏洞", "title_en": "Language Models Identify Ambiguities and Exploit Loopholes", "authors": "Jio Choi,Mohit Bansal,Elias Stengel-Eskin", "background": "研究大型语言模型（LLMs）对漏洞的响应提供了一种双管齐下的机会。通过这一过程，我们可以观察到LLMs中的不明确性和语用学，利用漏洞需要识别不明确性并进行复杂的语用推理。此外，漏洞也提出了一个有趣的新型对齐问题，即模型遇到了相冲突的目标，它可以通过利用不明确性来实现自己的目标。研究者设计了多种情境，包括量级含蓄意义、结构歧义和权力动态等场景，以评估模型利用漏洞的能力。研究发现，无论是封闭源代码还是较强的开源模型，都能识别歧义并利用它们的结果漏洞，这可能带来AI安全的风险。分析表明，利用漏洞的模型会明确地发现和推理处理歧义与冲突的目标。", "innovation": "本研究创新地提出了通过利用漏洞来识别LLMs中的歧义和语用推理，并探讨了模型如何将这些不明确性用于自身优势的问题。通过设计包含多种情境的实验，研究者能够更好地理解模型在面对冲突目标时的行为模式。这一方法为评估LLMs的安全性和对齐问题提供了一种新颖的视角。", "conclusion": "研究发现，无论是封闭源代码还是较强的开源大型语言模型，都能识别歧义并利用它们的结果漏洞。这种利用漏洞的能力对于模型来说可能既是机遇也是挑战，因为它们能够危害自身的功能与应用。研究结果表明，模型能够明确地识别和推理处理歧义与冲突的目标，并且这一行为可能带来潜在的AI安全风险。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.01081", "html_url": "https://arxiv.org/abs/2509.01081", "title": "评估大型语言模型在伊斯兰法推理中的表现：遗产法评估的证据", "title_en": "Assessing Large Language Models on Islamic Legal Reasoning: Evidence from Inheritance Law Evaluation", "authors": "Abdessalam Bouchekif,Samer Rashwani,Heba Sbahi,Shahd Gaben,Mutaz Al-Khatib,Mohammed Ghaly", "background": "本文评估了大型语言模型（LLMs）在伊斯兰遗产继承法领域的知识和推理能力，这在伊斯兰法学中被称为‘ilm al-mawarith。研究使用了一个包含1000道选择题的基准测试，涵盖了多种遗产分配情景，旨在测试模型理解和计算伊斯兰教法规定份额的能力。", "innovation": "研究创新性地通过设计涵盖多样化遗产分配情景的基准测试来评估7个LLMs在伊斯兰遗产继承法领域的表现，揭示了模型间显著的性能差异，并进行了详细错误分析以识别模型的失败模式，包括对遗产情景的理解误解、规则应用错误及专业知识不足等问题。", "conclusion": "研究结果揭示了大型语言模型在处理结构化法律推理方面的局限性，提出了改进伊斯兰法律推理表现的方向。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.07553", "html_url": "https://arxiv.org/abs/2509.07553", "title": "VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents", "title_en": "VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents", "authors": "Zheng Wu,Heyuan Huang,Xingyu Lou,Xiangmou Qu,Pengzhou Cheng,Zongru Wu,Weiwen Liu,Weinan Zhang,Jun Wang,Zhaoxiang Wang,Zhuosheng Zhang", "background": "随着多模态大型语言模型的快速发展，操作系统（OS）代理变得更加能够通过设备上的图形用户界面（GUI）自动化任务。然而，现有的OS代理大多设计用于理想化的设置，而现实世界中的环境往往充满不可靠性。在这样的场景中过度执行会带来风险。", "innovation": "本文提出了一种基于查询驱动的人机-GUI交互框架，使得OS代理能够决定何时向人类查询以获得更可靠的任务完成。基于此框架，引入了VeriOS-Agent，这是一种通过两阶段学习机制训练的可信赖OS代理，该机制促进了元知识的解耦和利用。VeriOS-Agent在正常情况下自主执行操作，而在不可靠的场景中则主动向人类查询。", "conclusion": "实验结果显示，与最先进的技术相比，VeriOS-Agent在不可靠场景中的平均逐步成功率为20.64%。分析指出，VeriOS-Agent具有理性和扩展性。代码、数据集和模型可在给定的链接中访问。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.10199", "html_url": "https://arxiv.org/abs/2509.10199", "title": "超越令牌限制：评估长文本分类的语言模型性能", "title_en": "Beyond Token Limits: Assessing Language Model Performance on Long Text Classification", "authors": "Miklós Sebők,Viktor Kovács,Martin Bánóczy,Daniel Møller Eriksen,Nathalie Neptune,Philippe Roussille", "background": "当前广泛应用于社会科学领域的大型语言模型（如BERT及其衍生版本，如RoBERTa）存在处理长输入文本的限制，这在处理一些长输入文本的任务（例如法律和草案制度分析）中尤为突出。这类任务的数据长度可能达到数百页，而传统的模型只能处理512词元以下的文本，导致无法有效处理这些长文档。本文通过实验对比了XLM-RoBERTa、Longformer、GPT-3.5和GPT-4等模型在多类别分类任务上的性能，该任务涉及比较议程项目，涵盖了21个政策主题标签，从教育到健康护理等多个方面。这些模型在长文本输入上没有展现出与Longformer这样的专门针对长输入设计的模型相比的优势。\n", "innovation": "实验比较了多种不同类型的语言模型在处理长输入文本上的表现，特别是长文本分类任务上的情况，这在法律和草案制度分析等领域尤为重要。这种对比涉及到了多种多样的模型，发现了他们在处理长文本时的具体差异。\n", "conclusion": "实验结果表明，在长文本分类任务上，传统模型没有展现出预期的优势，特别是在处理具有多页面长度的长文档时。相比之下，开放式模型的表现更优。进一步分析表明，特定类别的支持和实质重叠对于提升长文本输入上的性能至关重要。\n"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2311.09945", "html_url": "https://arxiv.org/abs/2311.09945", "title": "一种基于注意力的去噪框架在社交媒体文本中的人格检测", "title_en": "An Attention-Based Denoising Framework for Personality Detection in Social Media Texts", "authors": "Lei Lin,Jizhao Zhu,Qirui Tang,Yihua Du", "background": "社交媒体网络中的用户持续产生大量的文本内容，为研究人员提供了挖掘与人格相关信息的重要途径。基于用户生成的文本进行人格检测是一种具有广泛应用前景的方法，例如构建用户肖像。然而，社交媒体文本中存在的大量噪声会阻碍人格检测的效果。尽管如此，以往的研究并未深入探讨这一挑战。", "innovation": "受扫描阅读技术的启发，本文提出了一种基于注意力的信息抽取机制(AIEM)，用于长文本中快速定位有价值的信息，并全面整合有益的语义信息。在此基础上，提供了一种新颖的基于注意力的去噪框架(ADF)，应用于人格检测任务，并在两个常用数据集上取得了最先进的性能。特别地，本文在金标准的Twitter-Myers-Briggs Type Indicator (Twitter-MBTI) 数据集上获得了平均10.2%的准确率提升。", "conclusion": "我们公开发布了代码在GitHub上。我们通过案例分析探讨了AIEM如何通过放大与人格相关的信号来工作。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.08299", "html_url": "https://arxiv.org/abs/2410.08299", "title": "利用隐私保护方法学习图数据在大型语言模型微调中的应用", "title_en": "Privately Learning from Graphs with Applications in Fine-tuning Large Language Models", "authors": "Haoteng Yin,Rongzhe Wei,Eli Chien,Pan Li", "background": "图提供了实体间关系的独特见解，补充了如文本和图像的数据模态，使AI模型能够超越传统任务的能力。然而，从图中学习往往涉及处理数据中的敏感关系，这引发了重大的隐私问题。现有的隐私保护方法，如DP-SGD，依赖于梯度解耦假设，但由于训练样本之间的固有依赖性，无法与关系学习兼容。", "innovation": "提出了一个隐私保护的管道，用于关系学习，通过为训练解耦样本关系依赖性，结合定制的DP-SGD应用，确保差分隐私。此方法应用于大型语言模型（LLMs）如Llama2的微调，同时解决相关的计算复杂性问题。该方法在四个真实世界的文本归因图上进行了评估，证明了在保持稳健隐私保证的同时，在关系学习任务上的显著改进。", "conclusion": "分析了隐私、效用和计算效率之间的权衡，为隐私保护关系学习的实际部署提供了见解。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2405.19988", "html_url": "https://arxiv.org/abs/2405.19988", "title": "Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics", "title_en": "Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics", "authors": "Minttu Alakuijala,Reginald McLean,Isaac Woungang,Nariman Farsad,Samuel Kaski,Pekka Marttinen,Kai Yuan", "background": "自然语言是人类为机器人指定任务最容易和最方便的方式之一。然而，将语言与行为关联起来通常需要在每个目标机器人上收集大量多样的、带有语言标注的演示数据，这往往是不切实际的。本文旨在将需要实现的目标与实现方式分离，前者可以从大量的外部观察数据中受益，而后者仅依赖于特定的机器人实体。因此，提出了一个名为视频-语言批评家（Video-Language Critic）的奖励模型，该模型可以使用对比学习和时空排序目标训练在不同机器人实体间可用的数据。", "innovation": "本文提出了一种名为Video-Language Critic的奖励模型，该模型通过对比学习和时空排序目标从不同实体的数据中训练，而不是每个目标机器人上收集大量带有语言标注的演示数据。实验结果表明，即使存在显著的领域差异，使用该奖励模型的策略训练在Meta-World任务中也比仅用稀疏奖励的策略更有效率。此外，在领域内的数据上进行测试时，展示了比先前的语言条件奖励模型更高效的学习策略，这些先前的模型或者使用二分类训练，或者使用静态图像，或者未利用视频数据中的时空信息。", "conclusion": "本文提出了一种新的奖励模型Video-Language Critic，通过从不同机器人实体获得的数据进行训练，解决了机器人学习自然语言指令的问题，即使在存在显著领域差异的情况下，该模型也能显著提高策略训练效率。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.10663", "html_url": "https://arxiv.org/abs/2509.10663", "title": "上下文复制调节: 熵神经元在管理参数和情境知识冲突中的作用", "title_en": "Context Copying Modulation: The Role of Entropy Neurons in Managing Parametric and Contextual Knowledge Conflicts", "authors": "Zineddine Tighidet,Andrea Mogini,Hedi Ben-younes,Jiali Mei,Patrick Gallinari,Benjamin Piwowarski", "background": "大型语言模型（LLMs）在面对与内部参数知识相矛盾的情景信息时，其行为表现不一致，目前还没有普遍接受的解释来预测这种结果分布。近期研究在自回归变压器模型中发现了一类神经元——称为熵神经元，在对模型输出熵有显著影响的同时，对预测令牌的排名的整体影响较小。有兴趣探究这些神经元在解决情境和参数信息冲突时是否参与抑制上下文复制行为的角色问题。", "innovation": "本文研究了熵神经元在变压器中抑制上下文复制行为的初步假设，通过观察熵神经元在解决情境与参数信息冲突中的作用。研究发现，熵神经元在一系列LLMs中负责抑制上下文复制，并且消除它们会导致生成过程发生显著变化。这些结果增强了我们对LLMs在处理冲突信息时内部动态的理解。", "conclusion": "熵神经元在变压器中对抑制上下文复制行为具有重要作用，这对于理解大型语言模型在处理冲突信息时的内部机制具有重要意义。消除熵神经元会显著改变生成过程。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.11498", "html_url": "https://arxiv.org/abs/2509.11498", "title": "DeDisCo在DISRPT 2025共享任务中的表现：一种话语关系分类系统", "title_en": "DeDisCo at the DISRPT 2025 Shared Task: A System for Discourse Relation Classification", "authors": "Zhuoxuan Ju,Jingni Wu,Abhishek Purushothama,Amir Zeldes", "background": "该论文介绍了一种名为DeDisCo的系统，这是对DISRPT 2025共享任务中话语关系分类的参赛作品。背景信息涉及使用不同的方法进行话语关系分类，包括使用基于mt5的编码器和公开可用的Qwen解码器的方法。此外，还对低资源语言的数据集进行了增强训练，并使用自动翻译的匹配数据以及借鉴过往共享任务参赛作品的额外语言特征进行实验。最终，该系统获得了一般准确率为71.28%的结果，并对结果进行了解释和错误分析。", "innovation": "系统采用了两种不同的方法：基于mt5的编码器方法和基于Qwen模型的解码器方法。此外，论文中还通过使用自动从英语翻译的匹配数据对低资源语言的数据集进行了增强训练，并进一步引入一些由之前版本共享任务参赛作品启发的语言特征。", "conclusion": "最终，他们的系统在宏准确率方面达到了71.28%的成绩，并提供了对实验结果的解释和错误分析。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.08872", "html_url": "https://arxiv.org/abs/2408.08872", "title": "xGen-MM (BLIP-3): 一组开源大型多模态模型", "title_en": "xGen-MM (BLIP-3): A Family of Open Large Multimodal Models", "authors": "Le Xue,Manli Shu,Anas Awadalla,Jun Wang,An Yan,Senthil Purushwalkam,Honglu Zhou,Viraj Prabhu,Yutong Dai,Michael S Ryoo,Shrikant Kendre,Jieyu Zhang,Shaoyen Tseng,Gustavo A Lujan-Moreno,Matthew L Olson,Musashi Hinck,David Cobbley,Vasudev Lal,Can Qin,Shu Zhang,Chia-Chih Chen,Ning Yu,Juntao Tan,Tulika Manoj Awalgaonkar,Shelby Heinecke,Huan Wang,Yejin Choi,Ludwig Schmidt,Zeyuan Chen,Silvio Savarese,Juan Carlos Niebles,Caiming Xiong,Ran Xu", "background": "该论文介绍了BLIP-3，这是一个用于开发大型多模态模型（LMMs）的开放式框架。该框架包含精心策划的数据集、训练食谱、模型架构以及一系列LMMs模型成果。研究者们发布了4B和14B模型，包括预训练的基础模型和指令微调版本。模型在一系列任务上进行了严格的评估，展示了与开源LMMs类似的模型大小相比较的竞争性能。模型旨在理解交错的图像-文本输入，展现了在多种图像基准测试上的竞争力。该论文还计划开发适用于研究社区的研究代码、模型及所有使用过的数据集，包括三个大规模的原创数据集和预处理的数据集。", "innovation": "BLIP-3 提供了一个开源框架，可以用于开发大型多模态模型。这一框架涵盖了精心策划的数据集、训练方法、模型架构，并且提供了4B和14B的模型，包括预训练的基础模型和指令微调版本。所有相关研究代码和模型将在开源下发布。", "conclusion": "通过使用精心策划的数据集和在多个任务上的严格测试，BLIP-3模型展现了与开源LMMs类似于模型大小的竞争性能，同时具有处理图像-文本交错输入的能力。研究者承诺将所有的训练代码、模型和数据集开源，以更好地支持研究社区的发展。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.11860", "html_url": "https://arxiv.org/abs/2509.11860", "title": "MOOM: 维护、组织与优化超长角色扮演对话中的记忆", "title_en": "MOOM: Maintenance, Organization and Optimization of Memory in Ultra-Long Role-Playing Dialogues", "authors": "Weishu Chen,Jinyi Tang,Zhouhui Hou,Shihao Han,Mingjie Zhan,Zhiyuan Huang,Delong Liu,Jiawei Guo,Zhicheng Zhao,Fei Su", "background": "在人类-机器人角色扮演场景中，保持连贯的超长对话所需的记忆提取至关重要。然而，现有方法常常表现出不受控制的记忆增长问题。为了应对这一挑战，本文提出了一种名为MOOM的双分支记忆插件，该插件通过借鉴文学理论，将情节发展和人物形象建模为核心叙事元素，以解决记忆增长不受控的问题。MOOM能够跨多个时间尺度总结情节冲突，并提取用户的人物档案，进一步通过借鉴“竞争抑制”记忆理论引入遗忘机制，来控制记忆容量并减轻不受控增长。此外，ZH-4O中文超长对话数据集被特别设计用于角色扮演，其对话平均回合数为600，并包含手动标注的记忆信息，为研究提供了重要基础。研究表明，MOOM在多项指标上优于所有现有最先进的记忆提取方法，不仅减少了大型语言模型的调用次数，还保持了可控的记忆容量。", "innovation": "1. 提出了一种名为MOOM的双分支记忆插件，利用文学理论建模情节发展和人物形象。\n2. 引入了竞争抑制记忆机制，通过遗忘机制控制记忆容量。\n3. 设计了ZH-4O中文超长对话数据集，专为角色扮演游戏设计，提供详细的手标注记记忆信息。", "conclusion": "MOOM在超长角色扮演对话记忆提取方面表现优异，不仅减少了大型语言模型的调用次数，还保持了可控的记忆容量，优于所有现有最先进的方法。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15871", "html_url": "https://arxiv.org/abs/2502.15871", "title": "大型语言模型在医疗领域的可信性全面综述", "title_en": "A Comprehensive Survey on the Trustworthiness of Large Language Models in Healthcare", "authors": "Manar Aljohani,Jun Hou,Sindhura Kommu,Xuan Wang", "background": "大型语言模型（LLMs）在医疗领域的应用有望提升临床决策、医疗研究和患者护理的质量，但将其整合到实际临床环境中也引发了对可信性（包括真实性、隐私性、安全、稳健性、公平性和可解释性）方面的重要关切。目前，虽然研究人员已经开始开发评估LLM可信性的基准和评估框架，但在医疗领域的LLM可信性仍然缺乏系统性的研究，未能提供全面的理解和未来洞察。本综述旨在填补这一空白，通过提供目前用于减少关键可信性维度风险的方法和解决方案的全面回顾，分析每个维度如何影响医疗LLM的可靠性和伦理部署，总结正在进行的研究努力，并识别现有方法中的关键缺口。本综述还指出了新兴挑战，包括多代理协作、多模态推理以及小型开源医疗模型的发展。", "innovation": "本综述通过对医疗领域大型语言模型可信性进行全面系统的研究，填补了当前领域的研究空白，提供了关键可信性维度的全面回顾和分析，以及未来研究的一些建议。它还指出了新兴的挑战，并识别了现有方法中的关键缺口。", "conclusion": "该论文通过全面回顾当前用于医疗领域大型语言模型的方法和解决方案，分析了每个可信性维度对医疗LLM可靠性和伦理部署的影响，总结了正在进行的研究努力，并指出了现有方法中的关键缺口。旨在为未来的研究提供指导，推动更可信、透明和临床可行的LLM的发展。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.10408", "html_url": "https://arxiv.org/abs/2503.10408", "title": "在大规模语言模型中进行脱离上下文推理", "title_en": "Out-of-Context Reasoning in Large Language Models", "authors": "Jonathan Shaki,Emanuele La Malfa,Michael Wooldridge,Sarit Kraus", "background": "本文研究了大语言模型(大语言模型，LLMs)如何通过简单的二元关系(如相等(=)、不等(<)和包含(⊂))来处理存储的知识。不同于上下文推理，用于推理的公理(例如，a < b, b < c)仅在训练过程中可见，而在任务提示中不会给出(例如，评估a < c)。任务需要一到多个推理步骤，且数据聚合可能来自一个或多个来源，显示了随着任务复杂度的增加，性能的变化。", "innovation": "本文引入了一种轻量级技术，称为脱离上下文的表示学习，该技术仅在训练中对新词嵌入进行训练，同时在未见过的任务上进行评估。研究显示，大语言模型在反射性、对称性和传递性测试中大多数情况下表现显著优于随机猜测，并且在测试多种表达方式的变化时可以提取正确的答案，但仍存在某些查询中一致推理不足的问题。研究表明，学习到的嵌入以结构化的方式组织，表明模型具有真实的相对关系理解，令人惊讶的是，推理主要发生在训练过程中，而不是推理阶段。", "conclusion": "在对不同表达方式的测试中，大语言模型大多数情况下表现显著优于随机猜测，表明其具有一定的结构化关系理解能力，但仍然存在推理不一致的问题，显示推理主要发生在训练过程中而非推理阶段。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.06652", "html_url": "https://arxiv.org/abs/2509.06652", "title": "IntrEx: 用于建模教育对话中参与度的数据集", "title_en": "IntrEx: A Dataset for Modeling Engagement in Educational Conversations", "authors": "Xingwei Tan,Mahathi Parvatham,Chiara Gambi,Gabriele Pergola", "background": "第二语言学习中，参与和动力至关重要，但却难以保持学习者对教育对话的兴趣。虽然先前的研究已探讨了使教育文本有趣的因素，但对于驱动对话参与的语言特征，我们仍知之甚少。", "innovation": "Introduce IntrEx，一个首次针对教师-学生互动中的有趣性和预期有趣性进行标注的大规模数据集。IntrEx在此基础上引入序列层级标注，有助于研究参与度而不仅仅是孤立的对话轮次，以评估兴趣如何在延长的对话中演变。通过采用基于人类反馈强化学习（RLHF）的对比评分注释方法，提高一致性。研究发现，针对有趣性评分 fine-tuned 的大型语言模型（7B/8B参数）比专用的大规模模型（如 GPT-4o）表现更好，表明专门的数据集可以在教育场景中建模参与度。", "conclusion": "通过研究发现，诸如具体性、可理解性（可读性）和信息接收等语言和认知因素会影响教育对话中的参与度。LSTM 预测模型显著优于大型语言模型，揭示了在教育环境中专门数据集模型化参与度的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.16846", "html_url": "https://arxiv.org/abs/2412.16846", "title": "KALL-E：基于下一分布预测的自回归语音合成", "title_en": "KALL-E:Autoregressive Speech Synthesis with Next-Distribution Prediction", "authors": "Kangxiang Xia,Xinfa Zhu,Jixun Yao,Wenjie Tian,Wenhao Li,Lei Xie", "background": "当前的文本到语音(TTS)合成方法大多依赖于扩散组件，这些方法需要通过预测离散的语音标记来合成连续的语音帧，从而降低了合成质量。KALL-E模型通过引入流VAE提取连续的潜语音表示，并利用单个自回归变换器直接从文本预测连续的语音分布，优化Kullback-Leibler散度损失函数。", "innovation": "KALL-E直接基于文本预测连续的语音分布，而不是依赖于离散的语音标记，从而消除了一般TTS模型中的扩散部件。模型使用流VAE从波形中提取连续的潜语音表示，并通过单个自回归变换器训练实现从文本到连续语音分布的预测。", "conclusion": "实验结果表明，KALL-E在语音合成质量上取得了显著的改善，并且可以从少量样本中适应目标说话人。KALL-E为利用连续语音表示在TTS中的应用提供了一种更直接和有效的方法。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.07032", "html_url": "https://arxiv.org/abs/2506.07032", "title": "多元文化多语言多模态视频基准及模型", "title_en": "A Culturally-diverse Multilingual Multimodal Video Benchmark & Model", "authors": "Bhuiyan Sanjid Shafique,Ashmal Vayani,Muhammad Maaz,Hanoona Abdul Rasheed,Dinura Dissanayake,Mohammed Irfan Kurpath,Yahya Hmaiti,Go Inoue,Jean Lahoud,Md. Safirur Rashid,Shadid Intisar Quasem,Maheen Fatima,Franco Vidal,Mykola Maslych,Ketan Pravin More,Sanoojan Baliah,Hasindri Watawana,Yuhao Li,Fabian Farestam,Leon Schaller,Roman Tymtsiv,Simon Weber,Hisham Cholakkal,Ivan Laptev,Shin'ichi Satoh,Michael Felsberg,Mubarak Shah,Salman Khan,Fahad Shahbaz Khan", "background": "大型多模态模型(LMMs)由于其理解与生成视觉内容描述的有效性而受到关注，大多数现有模型都是使用英语构建的。虽然有少数工作探索了多语言图像LMMs，但如何在视频LMMs中超越英语实现文化与语言包容性尚未被系统研究。基于此，本研究旨在构建一个支持14种语言的多语言视频LMM基准(ViMUL-Bench)，涵盖英语、汉语、西班牙语、法语、德语、印地语、阿拉伯语、俄语、孟加拉语、乌尔都语、僧伽罗语、泰米尔语、瑞典语和日语，以支持更包容的视频LMM研究。", "innovation": "本研究创新性地构建了一个名为ViMUL-Bench的多语言视频LMM基准，用于评估14种语言的视频LMM性能。基准涵盖了15个类别，包括生活、节日、食物、宗教仪式等文化多样性主题。此外，研究还提供了一个机器翻译的多语言视频训练集，包含120万个样本，并开发了一个简单的多语言视频LMM模型(ViMUL)，展示了其在不同语言资源水平间的平衡优势。", "conclusion": "本研究希望通过对文化多样性和语言包容性的关注，推动未来在该领域的研究，并期待ViMUL-Bench、多语言视频LMM模型和大规模多语言视频训练集能够促进更包容的多语言视频LMM的发展。相关研究资产将公开发布。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00308", "html_url": "https://arxiv.org/abs/2506.00308", "title": "MythTriage：视频共享平台上成瘾障碍谬误的可扩展检测", "title_en": "MythTriage: Scalable Detection of Opioid Use Disorder Myths on a Video-Sharing Platform", "authors": "Hayoung Jung,Shravika Mittal,Ananya Aatreya,Navreet Kaur,Munmun De Choudhury,Tanushree Mitra", "background": "了解健康主题在线误导信息的普遍性可以指导公共卫生政策和干预措施。然而，大规模测量误导信息仍然是一个挑战，特别是在高风险但研究不足的领域，如阿片使用障碍（OUD）——这是美国主要的致死原因。本文介绍了第一个针对YouTube上的OUD相关谬误的大规模研究，这是一个广泛用于健康信息的平台。通过临床专家验证了8个常见的错误信息，并发布了一个由专家标记的视频数据集。为了扩大标记的规模，引入了MythTriage，一个高效的分流管道，使用轻量级模型处理常规案件，并将更难处理的案例交给性能高但成本高的大型语言模型（LLM）。MythTriage在宏F1分数上达到0.86，估计减少了超过76%的注释时间和财务成本，相比专家和全面的LLM注释。在2900个搜索结果和343,000个建议中进行分析，揭示了错误信息在YouTube上持续存在的原因，并提供了公共健康和平台管理的实际建议。", "innovation": "提出了一个名为MythTriage的高效分流管道，用于大规模检测OUD相关的视频内容中存在谬误。该系统通过使用轻量级模型处理常规验证任务，而将更复杂的任务留给高性能但成本较高的大型语言模型，从而实现了注释效率和成本的有效降低。", "conclusion": "通过2.9K搜索结果和343K建议分析发现，OUD相关谬误会持续存在，主要通过不准确的描述、错误的信息来源和未经证实的支持信息。这些发现有助于为公共健康政策制定者和平台运营商提供实用的洞察，以更好地管理错误信息并改善用户健康信息的质量。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.20742", "html_url": "https://arxiv.org/abs/2502.20742", "title": "视景语言长期任务规划中的结构化偏好优化", "title_en": "Structured Preference Optimization for Vision-Language Long-Horizon Task Planning", "authors": "Xiwen Liang,Min Lin,Weiqi Ruan,Rongtao Xu,Yuecheng Liu,Jiaqi Chen,Bingqian Lin,Yuzheng Zhuang,Xiaodan Liang", "background": "现有的视觉语言任务规划方法在短期任务上表现出色，但在动态环境中的复杂、长期任务规划方面往往不够理想。这些挑战主要是由于高效训练模型以生成高质量长期任务推理过程的难度所导致的。", "innovation": "本文提出了结构化偏好优化（SPO），该方法通过结构化偏好评估和优化训练策略来增强长期任务规划中的推理和动作选择。SPO引入了2个核心特性：1）基于偏好评分和优化，系统地根据任务相关性、视觉锚定和历史一致性评估推理链；2）课程引导训练，使得模型从简单任务逐渐过渡到复杂任务，提高其在长期场景中的泛化能力和推理鲁棒性。", "conclusion": "为了促进长期任务规划的研究，本文引入了ExtendaBench，一个覆盖1,509个任务的全面基准，涵盖VirtualHome和Habitat 2.0。实验结果显示，SPO在改进推理质量和最终决策准确性方面显著优于传统方法，特别是在长期任务上表现出色，这验证了偏好驱动优化在视觉语言任务规划中的有效性，分别在VirtualHome和Habitat中达到了+5.98%的GCR、+4.68%的SR和+3.30%的GCR、+2.11%的SR的显著提升。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.12248", "html_url": "https://arxiv.org/abs/2509.12248", "title": "像素中的幽默：大型多模态模型对在线漫画理解的基准测试", "title_en": "Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics", "authors": "Yuriel Ryan,Rui Yang Tan,Kenny Tsu Wei Choo,Roy Ka-Wei Lee", "background": "理解幽默是社交智能的核心方面，但对大型多模态模型（LMMs）来说仍然是一项重大挑战。PixelHumor是一个包含2800个标注的多板块漫画基准数据集，旨在评估LMMs在解释多模态幽默并识别叙事序列方面的能力。现有最先进的LMMs在此任务上的表现有很大差距，例如，最佳模型的板块排序准确率仅为61%，远低于人类的表现。这表明当前模型在整合视觉和文本线索以实现连贯的叙事和幽默理解方面存在重要局限。", "innovation": "引入了PixelHumor，这是一个包含2800个多板块漫画的标注基准数据集，目的是评估LMMs在解释多模态幽默和识别叙述顺序方面的能力。通过提供一个严谨的框架来评估多模态上下文和叙事推理，PixelHumor旨在推动开发能够进行更自然、社会意识更强的交互的LMMs。", "conclusion": "PixelHumor通过提供一个严格的研究框架，旨在推动LMMs在多模态上下文和叙事推理方面的进步，从而对大型多模态模型在在线漫画理解方面的进步产生影响。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05170", "html_url": "https://arxiv.org/abs/2508.05170", "title": "Posterior-GRPO: 奖励代码生成过程中的推理", "title_en": "Posterior-GRPO: Rewarding Reasoning Processes in Code Generation", "authors": "Lishui Fan,Yu Zhang,Mouxiang Chen,Zhongxin Liu", "background": "目前的强化学习（RL）方法在代码生成任务中主要依赖于基于测试案例的结果奖励，忽视了推理过程的质量。未经监督直接指导推理过程虽然是一个有前途的方向，但易受奖励滥用的影响，即模型可能会学习利用奖励信号而不提高最终结果的质量。论文提出了一种统一框架，旨在在RL过程中有效融合推理过程的质量评估。为此，论文构建了一个包含优越和劣质推理过程的对偏好基准（LCB-RB），并提出了一种基于优化降级（OD-based）的方法来训练奖励模型，这种方法可以系统地优化和降级初始推理路径，从而生成高质量的偏好对。研究通过7B参数的奖励模型在LCB-RB基准上实现了最先进的性能，并展现出良好的泛化能力。此外，还提出了一种新颖的RL方法Posterior-GRPO，该方法基于任务成功来调整奖励，从而减轻奖励滥用的问题，使模型内部的推理与最终代码正确性保持一致。", "innovation": "论文提出了LCB-RB基准和基于优化降级（OD-based）的方法来训练高质量的奖励模型。此外，创新地提出了Posterior-GRPO方法，条件化过程奖励于任务成功，有效减少了奖励滥用，使代码生成模型的推理过程与最终代码正确性更好地对齐。这一方法在多种代码生成任务中表现出优越性能，并在数学任务上展示了泛化能力。", "conclusion": "通过使用LAU-RB基准与OD-based奖励模型训练方法，以及提出Posterior-GRPO方法，论文成功地整合了代码生成过程中推理过程的质量评估，减少了奖励滥用问题，并在多种任务中显示了其优越性。模型、数据集和代码已开源。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13366", "html_url": "https://arxiv.org/abs/2509.13366", "title": "使用卷积神经网络的人工智能泊位地面真实测试自动化", "title_en": "Parking Space Ground Truth Test Automation by Artificial Intelligence Using Convolutional Neural Networks", "authors": "Tony Rohe,Martin Margreiter,Markus Moertl", "background": "研究聚焦于一种基于云的实时街边停车服务，该服务利用车载车队的 crowd-sourced 感知数据来提供关于可用泊位的实时信息。研究的背景是对现有的检测过程进行自动化分析，以优化当前的停车服务质量。研究方法包括机器学习，特别是图像模式识别，以提高数据库质量并减少人工处理在分析过程中的工作量.", "innovation": "将卷积神经网络应用于提高自动化水平，通过这种方法实现了人员时间减少高达 99.58% 的性能水平。研究探讨并总结了整体改进，并展望了未来开发以及分析自动化工具的潜在应用.", "conclusion": "研究讨论了整体改进，并提出了对未来发展的展望和分析自动化工具的潜在应用."}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13338", "html_url": "https://arxiv.org/abs/2509.13338", "title": "基于近邻的证据检索在不确定性感知神经网络中的应用", "title_en": "Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks", "authors": "Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi", "background": "该研究背景在于当前在不确定性感知决策中，通常采用单一的全局阈值标准，这种方法不够灵活，难以针对每个实例提供适应性的判断标准。为了克服这一问题，研究提出了一种基于证据的检索机制，用近邻实例的预测分布融合来替代传统的全局阈值，使得不确定性感知决策更加透明和可审计。", "innovation": "这一工作的创新之处在于提出了证据条件下的，实例自适应的阈值机制。对于每个测试实例，从嵌入空间中检索临近实例，融合它们的预测分布后，作为每个实例的阈值机制。因为支持的证据是显式的，所以决策的过程是透明且可追溯的。", "conclusion": "实验结果表明，基于CIFAR-10/100数据集，使用ResNet和Vision Transformer(BiT和ViT)作为后端模型，该方法在不确定性感知性能上表现更高或相当，且显著减少了误判率，审计负担也更为可持续。值得注意的是，只使用少数证据即可实现这些收益，更多的证据只有轻微的改善效果。研究结果证明，基于证据的标签提供了一种相比于固定预测熵阈值更可靠且可解释的替代方案，适用于操作性的不确定感知决策中。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.12574", "html_url": "https://arxiv.org/abs/2509.12574", "title": "Yet Another Watermark for Large Language Models", "title_en": "Yet Another Watermark for Large Language Models", "authors": "Siyuan Bao,Ying Shi,Zhiguang Yang,Hanzhou Wu,Xinpeng Zhang", "background": "现有的大语言模型（LLMs）水印方法主要通过调整标记的预测或后处理来嵌入水印，这可能会显著降低生成的带标记文本的语义质量。传统的基于训练或微调的水印方法可能适用于LLMs，但大多数情况下仅限于白盒场景，或者由于LLMs的大量参数而非常耗时。", "innovation": "本文提出了一种新的LLMs水印框架，该框架通过操作模型内部的参数来嵌入水印，并可以从生成文本中提取水印而无需访问LLMs。相比相关方法，该方法将水印与LLMs的内在参数紧密结合，更好地平衡了水印的鲁棒性和不可察觉性。此外，该方法还允许在黑盒场景下提取水印，从而具备更高效率。实验结果也验证了其可行性和优越性。", "conclusion": "这项工作提供了一种不同于主流研究的新视角，可能会对未来的研究产生启示。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13353", "html_url": "https://arxiv.org/abs/2509.13353", "title": "图像分类中的混合量子-经典模型", "title_en": "Hybrid Quantum-Classical Model for Image Classification", "authors": "Muhammad Adnan Shahzad", "background": "该研究通过系统比较混合量子-经典神经网络和纯粹的经典模型在三个基准数据集（MNIST、CIFAR100和STL10）上的性能、效率和鲁棒性，评价了这些模型的表现。研究中，混合模型将参数化量子电路与经典的深度学习架构结合，而经典的模型则使用传统的卷积神经网络（CNN）.", "innovation": "研究中的创新之处在于，开发了一种将参数化量子电路与经典深度学习架构结合的混合模型。实验结果显示，混合模型在最终准确性上始终优于经典模型，在MNIST、CIFAR100和STL10数据集上分别实现了99.38%、41.69%和74.05%的验证准确率，而相应经典模型的准确率为98.21%、32.25%和63.76%。另外，混合模型在简单数据集上比复杂数据集表现出更好的鲁棒性，同时在训练效率和参数数量上也具有优势，评估结果显示，混合模型的训练速度提高了5到12倍，使用的参数减少了6到32%，并且在资源使用上更加高效，内存和CPU利用率更低。这也表明，混合模型特别适合复杂的视觉任务。", "conclusion": "这些结果表明，混合量子-经典架构在准确度、训练效率和参数扩展性方面提供了引人注目的优势，尤其是对于复杂的视觉任务。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.03740", "html_url": "https://arxiv.org/abs/2509.03740", "title": "Vision-Language模型的奇异值少样本适应", "title_en": "Singular Value Few-shot Adaptation of Vision-Language Models", "authors": "Taha Koleilat,Hassan Rivaz,Yiming Xiao", "background": "视觉语言模型（VLMs）如CLIP已经展示了在多种应用程序中出色的零样本和少样本学习能力。然而，将这些模型适应到新的细粒度领域仍然很困难，因为它们依赖于提示工程和完整的模型微调，成本较高。现有的适应方法依赖于增强的组件，如提示标记和适配模块，这些组件可能会限制适应质量、使模型不稳定，并损害预训练中学习的丰富知识。已有研究中，这些方法需要额外的模型模块，这可能导致适应质量下降和模型稳定性的丧失。因此，需要一种参数高效且不影响模型整体性能的适应方法。这项工作旨在解决这一问题，提出了一种名为CLIP-SVD的新颖的多模态和参数高效适应技术，利用奇异值分解（SVD）修改CLIP的内部参数空间而无需注入额外模块。通过仅调整CLIP参数矩阵的奇异值，来重新缩放基向量以实现领域适应，同时保留预训练模型。这种方法仅使用模型总参数量的0.04%就实现了增强的适应性能，并且更好地保留了其泛化能力。CLIP-SVD在11个自然和社会科学数据集和10个生物医学数据集上取得了最佳分类结果，超过了以往方法在少样本设定下的准确性和泛化能力。此外，利用自然语言分析方法研究CLIP适应的有效性和动态，以提高对CLIP-SVD的可解释性。相关代码已公开。", "innovation": "提出了CLIP-SVD，一种新颖的多模态和参数高效的适应技术。利用SVD技术，通过仅调整CLIP参数矩阵的奇异值，实现了仅用0.04%的模型参数量就能提高适应性能和保留泛化能力的效果。这种方法不需要引入额外的模型模块，从而避免了牵制适应质量和模型稳定性的风险。该方法在多种自然和社会科学、生物医学数据集上表现出色，特别是在少样本设置下的准确性和泛化能力方面超过了以前的方法。此外，还利用自然语言方法分析CLIP的适应效果，提高了方法的可解释性。相关代码公开，可以进一步测试和验证其效果。", "conclusion": "CLIP-SVD展示了在多模态和参数高效适应领域的优势，尤其在自然和社会科学以及生物医学数据集上表现突出。其仅0.04%参数量的微调就能够实现优异的适应效果，且相比已有技术具有更高的准确性和泛化能力。自然语言方法的应用使适应过程和效果更具可解释性。为了验证和其他方法的对比，该研究提供了公开代码。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05606", "html_url": "https://arxiv.org/abs/2508.05606", "title": "Uni-Cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision", "title_en": "Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision", "authors": "Luozheng Qin,Jia Gong,Yuqing Sun,Tianjiao Li,Mengping Yang,Xiaomeng Yang,Chao Qu,Zhiyu Tan,Hao Li", "background": "链式推理（CoT）已经在增强大型语言模型（LLMs）中得到广泛应用，通过将复杂任务分解为更简单的顺序子任务来实现。然而，将CoT扩展到图语言推理任务仍具有挑战性，因为这通常需要解释视觉状态的过渡以支持推理。现有的方法因缺乏建模视觉状态转换的能力或由于分片架构导致的不连贯视觉轨迹而难以应对。", "innovation": "本文提出了一种统一的链式推理（Uni-CoT）框架，该框架能够在单一统一模型中实现连贯且贴地的多模态推理。其关键在于利用一个既理解图像又生成图像的模型来进行视觉内容推理和建模视觉状态演变。此外，提出了两级推理模式：宏级CoT用于高层任务规划，微级CoT用于子任务执行。还引入了一种结构化的训练范式，结合剪切并插入的图像-文本监督用于宏观层级的CoT，以及多任务目标用于微观层级的CoT。", "conclusion": "Uni-CoT在跨文本和视觉链式推理方面展示了优越的性能和强泛化能力，是多模态推理的一个有前途的解决方案。所有实验均在8个具有80GB VRAM的A100 GPU上高效完成。在推理驱动的图像生成基准（WISE）和编辑基准（RISE和KRIS）上，实验结果表明Uni-CoT取得了最先进的性能。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13375", "html_url": "https://arxiv.org/abs/2509.13375", "title": "基于VLM的OOD检测的实证分析：机制、优势和敏感性", "title_en": "An Empirical Analysis of VLM-based OOD Detection: Mechanisms, Advantages, and Sensitivity", "authors": "Yuxiao Lee,Xiaofeng Cao,Wei Ye,Jiangchao Yao,Jingkuan Song,Heng Tao Shen", "background": "视觉-语言模型（VLMs），如CLIP，展示了出色的开箱即用的分布外（OOD）检测能力，这对于可靠的AI系统至关重要。尽管存在这种前景，但关于为何这些模型如此有效、它们相对于单模态方法有哪些优势以及它们的行为稳健性方面的理解仍不完整。本文通过在分布内（ID）和OOD提示上进行系统实证分析，填补了这一空白。", "innovation": "1. 机制：系统地定义和形式化了VLM嵌入空间中的关键操作特性，这些特性促进了开箱即用的OOD检测。\n2. 优势：实证量化了这些模型相对于现有单模态方法的优势，归因于VLM利用丰富的语义新颖性的能力。\n3. 敏感性：揭示了其稳健性轮廓中的一个重要且之前未充分探索的不对称性：虽然对常见的图像噪声表现出韧性，但这些基于VLM的方法对提示措辞非常敏感。", "conclusion": "研究结果提供了关于基于VLM的OOD检测的优势以及关键漏洞的更结构化的理解，为开发更稳健和可靠的未来设计提供了关键、实证基础上的指导。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13385", "html_url": "https://arxiv.org/abs/2509.13385", "title": "使用曲率作为评估降维技术和估计内在维度的工具", "title_en": "Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension", "authors": "Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati", "background": "本文利用了最近发展起来的抽象曲率概念，提出了一种基于曲率构造离散度量空间几何轮廓的方法。这种方法捕捉了三元点与其他点之间的度量关系。进一步地，基于曲率轮廓，作者引入了一种定量评估数据表示有效性的方法，比如这些表示是由降维技术生成的。实验证明，这种基于曲率的分析可以用来估计数据集的内在维度，并可用来探索实证网络的大尺度几何结构以及评估降维技术的有效性。", "innovation": "利用抽象曲率概念构造离散度量空间的几何轮廓，并基于此提出了定量评估数据表示有效性的方法，能够估计数据集的内在维度并帮助探索实证网络的大尺度几何结构和评估降维技术的有效性。”", "conclusion": "研究表明，基于曲率的分析可以有效估计数据集的内在维度，并应用于评估降维技术和探索实证网络的大尺度几何结构。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13396", "html_url": "https://arxiv.org/abs/2509.13396", "title": "基于特征导向边缘智能的电力系统中实时检测和追踪外来物入侵", "title_en": "Real-Time Detection and Tracking of Foreign Object Intrusions in Power Systems via Feature-Based Edge Intelligence", "authors": "Xinan Wang,Di Shi,Fengyu Wang", "background": "电力传输系统中，实时检测和追踪外来物入侵（FOI）对于确保电网安全至关重要。现阶段的技术通常在复杂性和实时性之间存在权衡，急需一种能够平衡性能并适用于现场部署的解决方案。", "innovation": "本文提出了一个新颖的三阶段框架，用于电力传输系统中的实时FOI检测和追踪。该框架包括：（1）利用YOLOv7分割模型实现快速可靠的物体定位；（2）采用基于ConvNeXt的特征提取器，通过三重损失训练生成判别性嵌入；（3）使用特征辅助的IoU追踪器确保在遮挡和运动下的鲁棒多对象追踪。此外，通过在低成本边缘硬件上使用混合精度推理优化了流水线，支持增量更新而无需重新训练模型。实验证明该系统在多样化的FOI场景中具有高准确性和鲁棒性，并且在NVIDIA Jetson设备上的硬件基准测试验证了其实用性和可扩展性。", "conclusion": "该框架展示了在电力传输系统中使用特征导向的边缘智能技术进行实时FOI检测和追踪的潜力，为实际部署提供了有效的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13414", "html_url": "https://arxiv.org/abs/2509.13414", "title": "MapAnything: 全能端到端度量3D重建", "title_en": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "authors": "Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder", "background": "现有研究通常需要针对不同的3D视觉任务分别训练不同的专用模型，这些模型依赖于特定的输入数据和监督信息，并且在不同数据集之间的标准化训练方面存在挑战。MapAnything 提出了一个统一的基于Transformer的前馈模型，该模型能够处理一个或多个图像以及可选的几何输入，如相机内参、姿态、深度图或部分重建，直接回归出度量3D场景几何和相机参数。该模型通过利用多视图场景几何的因子表示方式，实现了局部重建到全局一致度量框的有效升级。MapAnything 模型通过规范化不同数据集的监督和训练，以及灵活的输入增强，简化了多种3D视觉任务的联合训练过程，包括未标定的结构从运动、标定的多视图立体、单目深度估计、相机定位、深度补全以及其他任务。", "innovation": "MapAnything 是一个统一的Transformer基前馈模型，能够处理图像和几何输入，直接回归3D场景几何和相机参数。该模型通过标准化的多数据集监督和灵活的输入增强，实现了多种3D视觉任务的单一前馈处理能力，相比现有的专门模型，MapAnything还提供了更高效的联合训练效应。", "conclusion": "MapAnything 通过单一前馈处理实现了一种新的3D重建方法，不仅能与专门模型相媲美，同时提供了高效的联合训练机制，为统一3D重建框架铺平了道路。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13388", "html_url": "https://arxiv.org/abs/2509.13388", "title": "使用遥感和机器学习进行土地覆盖分类与变化检测：斐济西部案例研究", "title_en": "Landcover classification and change detection using remote sensing and machine learning: a case study of Western Fiji", "authors": "Yadvendra Gurjar,Ruoni Wan,Ehsan Farahbakhsh,Rohitash Chandra", "background": "斐济是一个发展中国家，正在经历快速的城市化，体现在大规模的房地产开发项目上。该研究旨在通过应用机器学习和遥感框架，比较2013年至2024年间斐济纳迪地区的土地利用和土地覆盖变化，提供技术上支持土地覆盖/土地利用建模和变化检测。研究区域使用了Landsat-8卫星图像，并创建了带有标签的数据集用于监督机器学习的训练。使用Google Earth Engine和基于k-means聚类的无监督机器学习生成土地覆盖地图，采用卷积神经网络分类选定地区的土地覆盖类型。并进行了变化检测可视化，以监测地图上的城市区域变化。", "innovation": "该研究利用遥感和机器学习技术，首次系统地比较了斐济纳迪地区2013年到2024年的土地利用和土地覆盖变化，特别采用Google Earth Engine和卷积神经网络技术进行土地覆盖分类和变化检测，为决策提供了技术支持。", "conclusion": "该研究提供了土地覆盖/土地利用建模和变化检测的技术支持，通过远程感应和机器学习的应用，有效地监测了纳迪地区的城市变化过程，为未来的城市规划和可持续发展提供了重要的数据和方法支持。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13474", "html_url": "https://arxiv.org/abs/2509.13474", "title": "Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization", "title_en": "Semantic-Enhanced Cross-Modal Place Recognition for Robust Robot Localization", "authors": "Yujia Lin,Nicholas Evans", "background": "确保在没有GPS能力的环境中准确地定位机器人是一项具有挑战性的任务。现有的基于RGB的视觉位置识别（VPR）技术对光照、天气和其他季节变化敏感。利用RGB图像的几何特性和3D激光雷达（LiDAR）地图的跨模态定位方法可以减少这些问题，但目前最先进的方法在复杂场景、细粒度或高分辨率匹配和视点变化的情况下仍存在问题。因此，提出了基于RGB图像的高阶语义特征提取、语义特征融合模块、结合语义和几何信息的LiDAR描述符、以及在NetVLAD中的跨模态语义注意力机制等方法来提高匹配性能。", "innovation": "提出了被命名为语义增强跨模态位置识别（SCM-PR）的框架，结合高阶语义信息，利用基于VMamba背部的RGB图像特征提取，语义感知特征融合模块，联合语义和几何信息的LiDAR描述符，跨模态语义注意力机制改进NetVLAD，以及在对比学习框架下的多视图语义几何匹配和语义一致性损失设计。这些改进提高了在复杂场景、细粒度和高分辨率匹配以及视点变化情况下的匹配性能，较其他跨模态位置识别方法取得了更优的效果。", "conclusion": "在KITTI和KITTI-360数据集上的实验表明，SCM-PR达到了最先进的性能，实现了鲁棒的机器人定位。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13399", "html_url": "https://arxiv.org/abs/2509.13399", "title": "EdiVal-Agent: 一种面向对象的自动化、可扩展的细粒度多轮编辑评估框架", "title_en": "EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing", "authors": "Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou", "background": "基于指令的图像编辑技术已经取得了快速的发展，但可靠且可解释的评估仍然是一个瓶颈。现有的评估协议要么依赖配对的参考图像，这导致了有限的覆盖范围和从先前生成模型继承的偏差；要么依赖仅基于视觉-语言模型（VLMs）的零样本评估，这种基于提示的评估在指导语跟随、内容一致性和视觉质量方面往往是不够精确的。", "innovation": "提出了一种名为EdiVal-Agent的自动化、可扩展且细粒度的基于对象的多轮编辑评估框架。EdiVal-Agent首先将图像分解为语义上相关的对象，然后生成多样化的、基于上下文的编辑指令。它利用VLMs与开放词汇的物体检测器结合来评估指令跟随情况，使用语义级特征提取器来评估内容一致性，并利用人类偏好模型来判断视觉质量。这种框架的设计使得VLMs与物体探测器的结合比单独使用VLMs和CLIP基于的度量标准更能获得与人类判断的一致性。此外，该框架的模块化设计允许未来工具的无缝集成，从而随着时间的推移提高评估准确性。", "conclusion": "通过实例化该管道，构建了EdiVal-Bench评估基准，涵盖了9种指令类型和11种先进的编辑模型。结果表明，EdiVal-Agent可以识别现有的失败模式，从而指导下一代编辑模型的发展。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13504", "html_url": "https://arxiv.org/abs/2509.13504", "title": "LivePyxel: 加快使用集成Python网络摄像头实时流的图像注释", "title_en": "LivePyxel: Accelerating image annotations with a Python-integrated webcam live streaming", "authors": "Uriel Garcilazo-Cruz,Joseph O. Okeme,Rodrigo A. Vargas--Hernández", "background": "传统的图像标注工具缺乏灵活性，限制了人工智能模型在某些科学领域的部署。现有的大多数图像标注软件要求用户上传预先收集的数据集，这在满足按需管道和缩短获取图像流程方面存在不足。在实验室环境中，通过显微镜等仪器实时获取数据的需求日益增加，这种限制尤为突出。因此，迫切需要一种灵活的实时图像标注工具来解决这些问题。", "innovation": "提出了LivePixel，这是一种基于Python的图形用户界面，能够与摄像头、显微镜等成像系统集成，实现实时图像标注。LivePixel简化了界面设计，使用户能够使用与商业图形编辑软件中常见的工具一样的工具精准界定标注区域。特别值得注意的是，它提供了Bézier曲线和二进制掩模，以及对非破坏性图层的支持，提高了高性能编辑能力。LivePixel还具有广泛的视频设备兼容性，并通过OpenCV结合高性能NumPy库优化了对象检测操作。这些创新使得数据收集和标签化更加无缝，加速了实验流程中人工智能模型的开发。", "conclusion": "LivePixel作为一种实时图像标注工具，简化了图像标注流程，提高了灵活性和效率，特别适用于需要实时数据分析的实验室环境，从而加速了实验工作流中的人工智能模型开发。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13484", "html_url": "https://arxiv.org/abs/2509.13484", "title": "MINGLE: 基于VLM的具有语义复杂性的区域检测在城市场景中的应用", "title_en": "MINGLE: VLMs for Semantically Complex Region Detection in Urban Scenes", "authors": "Liu Liu,Alexandra Kudaeva,Marco Cipriano,Fatimeh Al Ghannam,Freya Tan,Gerard de Melo,Andres Sevtsuk", "background": "理解公共空间中的群体级社交互动对于城市规划至关重要，可以指导设计富有社交活力和包容性的环境。从图像中检测这些互动需要解读细微的视觉线索，如关系、接近度和共同移动，这些线索具有复杂的语义，超越了传统的物体检测。研究这一挑战，我们提出了一个社交群体区域检测任务，该任务要求推断和空间定位由抽象的人际关系定义的视觉区域。本研究旨在提出一个名为MINGLE的模块化三阶段管道，该管道包含：(1) 现成的人体检测和深度估计，(2) 基于VLM的推理来分类成对的社会隶属关系，(3) 一个轻量级的空间聚合算法来定位社交连接的群体。为了支持这一任务并鼓励未来的研究，我们提供了一个包含100K张城市街景图像的新数据集，这些图像被标注了个体和社交互动群体的边界框和标签。这些标注结合了人类创造的标签和MINGLE管道的输出，确保了语义丰富性和广泛的现实场景覆盖。", "innovation": "该研究提出了MINGLE（Modeling INterpersonal Group-Level Engagement），一个模块化的三阶段管道，集成了现成的人体检测和深度估计，基于VLM的推理来分类成对的社会隶属关系，以及一个轻量级的空间聚合算法来定位社交连接的群体。同时，为了支持该任务并鼓励未来研究，该研究还提供了一个新数据集，包含100K张城市街景图像，并且这些图像被标注了个体和社交互动群体的边界框和标签，确保了语义丰富性和广泛的现实场景覆盖。", "conclusion": "本研究通过提出一个名为MINGLE的模块化三阶段管道并开发一个包含100K张城市街景图像的新数据集，提供了理解公共空间中群体级社交互动的能力，为未来的社交互动检测和城市规划研究奠定了基础。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13507", "html_url": "https://arxiv.org/abs/2509.13507", "title": "在增强Cityscapes数据集中进行对抗性外观学习以提高自主驾驶中的行人识别", "title_en": "Adversarial Appearance Learning in Augmented Cityscapes for Pedestrian Recognition in Autonomous Driving", "authors": "Artem Savkin,Thomas Lapotre,Kevin Strauss,Uzair Akbar,Federico Tombari", "background": "在自主驾驶领域，合成数据至关重要，用于覆盖自主车辆必须处理的特定交通场景。这些数据通常会引入合成数据和真实数据之间的域差异。为此，本文利用数据增强生成带虚拟行人的自定义交通场景，旨在提高行人的识别能力。同时，文中提供了增强Cityscapes数据集的方法，并揭示了一种新的生成网络架构，用于对抗性学习数据集的光照条件，提高增强效果的真实性。在语义分割和实例分割任务上对该方法进行了评估。", "innovation": "提出了一种新的生成网络架构，用于对抗性学习数据集的光照条件。通过增强Cityscapes数据集，生成带虚拟行人的自定义交通场景，提高行人识别的准确性。", "conclusion": "对增强后的Cityscapes数据集进行语义分割和实例分割任务的评估，证明了提出的方法在行人识别方面的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13496", "html_url": "https://arxiv.org/abs/2509.13496", "title": "BiasMap: 利用交叉注意力发现和缓解文本到图像生成中的隐藏社会偏见", "title_en": "BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation", "authors": "Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan", "background": "对于黑盒生成模型，尤其是文本到图像（TTI）模型来说，识别偏差至关重要。现有的研究主要集中在输出级别的种族、性别等统计分布上，但并不一定能够确保在消除偏差后的概念表示是独立的。因此，作者提出了一种名为BiasMap的模型自适应框架，用于揭示稳定扩散模型中的隐含概念级表征偏差。BiasMap利用交叉注意注意力图揭示人口统计学（如性别、种族）与语义（如职业）之间的结构纠缠，深入到图像生成过程中的表征偏差中。通过这些概念的归因图，作者使用交并比（IoU）量化空间人口统计学-语义概念纠缠，并提供一种现有公平性发现方法未能揭示的偏见视角。此外，作者进一步利用BiasMap进行偏见缓解，通过能量引导的扩散采样直接修改隐空间噪声，并在去噪过程中最小化期望的SoftIoU。已有研究表明，现有的公平性干预措施可能会减小输出分布的差距，但往往无法解开概念层次的耦合，而作者的缓解方法可以在图像生成过程中缓解概念纠缠，同时补充分布偏差缓解。", "innovation": "作者提出的BiasMap是一种模型自适应框架，用于揭示稳定扩散模型中的概念级表征偏差。通过交叉注意力注意力图揭示人口统计学与语义之间的结构纠缠，并使用交并比（IoU）量化空间人口统计学-语义概念纠缠。此外，BiasMap还通过能量引导的扩散采样直接修改隐空间噪声来缓解偏见，从而使图像生成过程中的概念纠缠最小化，同时补充分布偏差缓解。", "conclusion": "现有公平性干预措施可能会减小输出分布的差距，但往往无法解开概念层次的耦合，而作者提出的BiasMap方法可以在图像生成过程中缓解概念纠缠，同时补充分布偏差缓解。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13482", "html_url": "https://arxiv.org/abs/2509.13482", "title": "通过场景自适应晶格向量量化提高3D高斯点云压缩", "title_en": "Improving 3D Gaussian Splatting Compression by Scene-Adaptive Lattice Vector Quantization", "authors": "Hao Xu,Xiaolin Wu,Xi Zhang", "background": "3D高斯点云渲染质量逼真且实时性能良好，但由于数据量巨大，压缩3D高斯点云数据以降低成本变得必要。近年来，一些基于锚点的神经压缩方法被提出，取得了良好的压缩性能，但它们都依赖于简单的均匀标量量化（USQ）。人们不禁质疑是否可以通过使用更复杂的量化器来提高压缩性能，同时几乎不增加额外开销。研究表明，使用晶格向量量化（LVQ）可以实现这一目标。通过为每个场景优化晶格基，可以提高LVQ的适应性和R-D效率。这种场景自适应LVQ（SALVQ）能够在保证R-D效率的同时，减少计算复杂性，从而无缝集成到现有3D高斯点云压缩架构中，提供最小改动和开销下的R-D性能提升。此外，通过调整晶格基向量的大小，SALVQ可以动态调整晶格密度，使一个模型适应多种位速率目标，从而减少为不同压缩级别训练模型所需的时间和内存消耗。", "innovation": "通过使用晶格向量量化（LVQ）并优化每个场景的晶格基，提出了场景自适应LVQ（SALVQ）。SALVQ能够在几乎不增加额外计算开销的情况下，优化R-D效率并减少系统复杂性。这种方法可以无缝集成到现有3D高斯点云压缩架构中，提高其R-D性能，并提供一个模型适应多种位速率目标的灵活性。", "conclusion": "通过使用场景自适应晶格向量量化（SALVQ），可以在保持计算效率的同时，提高3D高斯点云压缩方法的性能。SALVQ通过调整晶格基向量的大小，可以动态适应不同的位速率需求，从而减少为不同压缩级别单独训练模型所需的时间和资源。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13515", "html_url": "https://arxiv.org/abs/2509.13515", "title": "使用双流图神经网络的多模态仇恨检测", "title_en": "Multimodal Hate Detection Using Dual-Stream Graph Neural Networks", "authors": "Jiangbei Yue,Shuonan Yang,Tailin Chen,Jianbo Jiao,Zeyu Fu", "background": " Hateful 视频对在线安全和现实生活中的福祉构成了严重威胁，因此需要有效的方法来检测这些内容。尽管多模态分类方法结合了来自多种模态的信息能够超出单一模态的表现，但这些方法通常忽视了即使是最小的仇恨内容都会定义视频的类别这一事实。具体而言，这些方法通常将所有内容均匀处理，而不是强调仇恨组成部分。此外，现有的多模态方法无法系统地捕捉视频中的结构信息，从而限制了多模态融合的有效性。", "innovation": "论文提出了一种新颖的多模态双流图神经网络模型。该模型通过将给定视频分割成多个实例来构造实例图，以提取实例级特征。然后，互补权重图为这些特征分配重要性权重，强调具有仇恨内容的实例。重要权重和实例特征结合起来生成视频标签。该模型利用基于图的框架系统地建模模态内和模态间的结构关系。实验证明，该模型在仇恨视频分类中处于先进水平，并且具有较强的可解释性。", "conclusion": "我们在公共数据集上的大量实验表明，我们的模型在仇恨视频分类中达到了最先进的效果，并具有很强的可解释性。代码可在此处访问：this https URL."}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13536", "html_url": "https://arxiv.org/abs/2509.13536", "title": "MemGS: 实时SLAM的内存高效Gaussian斑点图", "title_en": "MemGS: Memory-Efficient Gaussian Splatting for Real-Time SLAM", "authors": "Yinlong Bai,Hongxin Zhang,Sheng Zhong,Junkai Niu,Hai Li,Yijia He,Yi Zhou", "background": "3D Gaussian Splatting (3DGS) 的最新进展显著影响了渲染和重建技术。目前的研究主要集中在使用高性能桌面GPU提高渲染性能和重建质量上，忽视了为微空气车辆（MAVs）等嵌入式设备的应用。这些设备由于计算资源和内存有限，往往需要在系统性能和重建质量之间做出取舍。", "innovation": "提出了一个名为MemGS的新方法，提高了3DGS的GPU内存使用效率，同时增强渲染质量。具体而言，该方法通过在体素空间中基于几何相似性合并冗余的3D Gaussian原语，从而减少GPU内存使用而不影响系统运行时性能。此外，通过Patch-Grid (PG)点采样初始化3D Gaussian原语，提高了场景建模的准确性。", "conclusion": "通过对公开数据集的定量和定性评估，证明了MemGS方法的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13586", "html_url": "https://arxiv.org/abs/2509.13586", "title": "使用专门语料库中的关键词标注森林卫星图像以进行变化检测", "title_en": "Annotating Satellite Images of Forests with Keywords from a Specialized Corpus in the Context of Change Detection", "authors": "Nathalie Neptune,Josiane Mothe", "background": "亚马逊雨林是一个至关重要的生态系统，对于调节地球气候和为无数物种提供栖息地至关重要。亚马逊地区的森林砍伐是一个重大问题，因为它对全球碳排放和生物多样性有显著影响。本文提出了一种使用地球观测卫星图像对来检测亚马逊地区森林砍伐的方法。该方法利用深度学习技术比较不同日期同一区域的图像并识别森林覆盖的变化。同时也提出了一种视觉语义模型，该模型可以自动对检测到的变化进行关键词注释。候选标注图像的关键词是从亚马逊区域相关的科学文献中提取出来的。", "innovation": "本文创新之处在于提出了一种利用地球观测卫星图像检测亚马逊地区森林砍伐的方法，该方法使用深度学习技术来识别不同时间同一区域图像的变化，并通过从科学文献中提取相关的关键词进行自动标注，为监测和研究亚马逊地区森林砍伐影响提供了有用的工具。", "conclusion": "本文的方法可以应用于监测和研究亚马逊地区森林砍伐的影响，具有广泛的应用前景。尽管本文主要关注环境应用领域，但此方法的泛化能力使其可以应用于其他领域。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13508", "html_url": "https://arxiv.org/abs/2509.13508", "title": "FunKAN: 功能柯尔莫哥洛夫-阿诺德网络在医学图像增强和分割中的应用", "title_en": "FunKAN: Functional Kolmogorov-Arnold Network for Medical Image Enhancement and Segmentation", "authors": "Maksim Penkin,Andrey Krylov(Lomonosov Moscow State University)", "background": "医疗图像的增强和分割在现代临床实践中至关重要但充满挑战，受到伪影和复杂解剖变异的限制。传统深度学习方法依赖复杂的架构，缺乏可解释性。尽管柯尔莫哥洛夫-阿诺德网络提供了可解释的解决方案，但它们依赖扁平化的特征表示，这从根本上破坏了成像数据的固有空间结构。", "innovation": "提出了功能柯尔莫哥洛夫-阿诺德网络（FunKAN），这是一种新型的解译型神经框架，专门用于图像处理，它将柯尔莫哥洛夫-阿诺德表示定理正式推广到功能空间，并使用傅里叶分解在基赫林特函数上学习内部函数。", "conclusion": "该方法在包括磁共振图像去包裹效应、Ultrasound、Histological结构和Colonoscopy视频在内的多个医学成像任务中表现出优越性，证明了其在医学图像增强（PSNR，TV）和分割（IoU，F1）上的性能优于其他基于KAN的架构，填补了理论函数逼近和医学图像分析之间的鸿沟，为临床应用提供了稳健且可解释的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13506", "html_url": "https://arxiv.org/abs/2509.13506", "title": "DEFT-VTON: 效率优先的具有一致性泛化h-变换的虚拟试穿", "title_en": "DEFT-VTON: Efficient Virtual Try-On with Consistent Generalised H-Transform", "authors": "Xingzi Xu,Qi Li,Shuwen Qiu,Julien Han,Karim Bouyarmane", "background": "扩散模型凭借其成熟的图像生成能力，能够实现高品质的虚拟试穿（VTO）。然而，当前VTO方法中所涉及的大规模端到端训练前置模型常常需要大量的训练和推理预算，这在实际应用中常常受到限制。为了克服这种障碍，作者应用了Doob的h变换高效微调方法（DEFT）来适应大型预训练无条件模型，使其具备下游图像条件下的VTO功能。DEFT方法冻结了预训练模型的参数，并训练了一个小型的h变换网络来学习条件下的h变换。与传统的参数高效微调方法（PEFT）相比，DEFT仅需训练冻结参数的1.42%，而非5.52%，从而减少了训练量。为了进一步提升DEFT的性能并减少现有模型的推理时间，作者还提出了一种适应性一致性损失，结合一致性训练和去噪分数匹配损失，以低代价微调现有的VTO模型，从而实现高效且具有一致性的VTO。", "innovation": "提出了一种新的高效虚拟试穿方法DEFT-VTON，采用了Doob的h变换高效微调方法（DEFT），在保持高性能的同时，微调的参数数量显著减少，仅需训练冻结参数的1.42%，而非5.52%。此外，DEFT-VTON还结合了适应性一致性损失，结合一致性训练和去噪分数匹配损失，以低代价改善现有VTO模型，使得最终的模型能够在保证性能的同时大幅减少推理时间，并实现更低的预算和资源消耗，使得实际应用中的资源限制得以克服。", "conclusion": "实验结果表明，DEFT-VTON方法在虚拟试穿任务中达到了最先进的性能，在不到15步去噪步骤的情况下，仍能保持竞争性的结果，证明了该方法的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13525", "html_url": "https://arxiv.org/abs/2509.13525", "title": "ColonCrafter: 使用扩散先验用于结肠镜视频的深度估计模型", "title_en": "ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors", "authors": "Romain Hardy,Tyler Berzin,Pranav Rajpurkar", "background": "结肠镜检查中的三维场景理解面临着显著的挑战，需要自动方法进行准确的深度估计。现有的端镜深度估计模型在视频序列间缺乏时序一致性，限制了其在三维重建中的应用。ColonCrafter是一种基于扩散的深度估计模型，可以从单目结肠镜视频生成时序一致的深度图。该方法通过从合成结肠镜序列中学习稳健的几何先验来生成时序一致的深度图，并引入了一种风格转移技术，以保持几何结构的同时使真实临床视频适应我们的合成训练领域。尽管全长轨迹三维重建仍是一个挑战，但示证了ColonCrafter在结肠镜临床相关应用中的应用，包括三维点云生成和表面覆盖率评估。", "innovation": "提出了ColonCrafter，这是一种基于扩散的深度估计模型，可以从单目结肠镜视频生成时序一致的深度图。该模型通过从合成结肠镜序列中学习稳健的几何先验，以及通过一种风格转移技术来匹配真实的临床视频，实现了零样本状态下最佳的表现，超越了通用和专门针对端镜的深度估计方法。", "conclusion": "虽然全长轨迹三维重建仍是一个挑战，但已经被证明了ColonCrafter在临床相关应用中的有效实现，包括三维点云生成和表面覆盖率评估。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13577", "html_url": "https://arxiv.org/abs/2509.13577", "title": "动态感知：自动驾驶中轨迹预测的自适应多模式异常检测", "title_en": "Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles", "authors": "Tongfei Guo,Lili Su", "background": "自动驾驶车辆的轨迹预测是确保其安全和无缝操作的关键。然而，在实际部署中，预测模型不可避免地会遇到训练数据与真实世界条件之间的分布变化，尤其是那些罕见或未充分代表的交通场景会导致数据分布外（OOD）情况。虽然大多数先前的自动驾驶中的OOD检测研究集中在计算机视觉任务，如目标检测和分割上，但轨迹水平的OOD检测仍然相对未被充分探索。最近的研究将这一问题以最快变化检测（QCD）任务的形式进行了形式化，为检测延迟和误报之间的权衡提供了正式保证。以往研究大多集中在这些方面，而本研究提出了一个新的框架，引入了适应性机制，以实现复杂驾驶环境下的稳健检测。实验证明，尽管预测错误甚至在训练数据内样本上也表现出基于模式的分布，并随数据集特定的动力学而演变。通过明确建模这些错误模式，我们的方法在检测延迟和误报率方面取得了显著改进。在现有的轨迹预测基准上进行的一系列全面实验表明，我们的框架在准确性和计算效率方面显著优于先前的不确定性量化（UQ）和基于视觉的OOD方法，为可靠、驾驶感知的自主驾驶提供了一个可行路径。", "innovation": "提出一个新的框架，基于快速变化检测（QCD）任务，引入适应性机制，以在复杂驾驶环境中实现鲁棒检测。通过模型化动态变化的预测错误模式，显著改进了检测延迟和误报率。该框架在准确性与计算效率方面均优于先前的不确定性量化（UQ）和基于视觉的OOD方法，为自动驾驶提供了更可靠的方法。", "conclusion": "本研究提出了一个动态感知框架，通过适应性机制和模式化动态错误，显著提高了OOD检测的效率和准确性。实验证明该框架在自动驾驶轨迹预测中优于现有方法，为实现安全、可靠的驾驶感知自主驾驶奠定了坚实基础。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13590", "html_url": "https://arxiv.org/abs/2509.13590", "title": "基于VLM的智能医疗成像平台：自动化医学影像分析和临床报告生成框架", "title_en": "Intelligent Healthcare Imaging Platform An VLM-Based Framework for Automated Medical Image Analysis and Clinical Report Generation", "authors": "Samer Al-Hamadani", "background": "人工智能在医疗成像中的快速进步已经彻底改变了诊断医学和临床决策过程。本研究提出了一种基于视觉语言模型（VLM）的智能多模态医疗影像分析框架，集成Google Gemini 2.5 Flash用于多种影像模态（CT、MRI、X光、超声）的肿瘤自动检测及临床报告生成。该系统结合了视觉特征提取与自然语言处理，实现了影像的上下文解释，利用坐标验证机制和正态分布概率高斯建模来检测异常，多层可视化技术生成详细医学图像、对比图和统计表示以增强临床信心，其定位测量平均偏差为80像素。结果处理通过精确的提示工程和文本分析提取结构化临床信息并保持解释性。实验结果表明，该系统在多种模态下的异常检测性能优异。该系统具有用户友好的Gradio界面，便于临床工作流程整合，并展示了零样本学习能力，减少对大数据集的依赖。本框架代表了自动诊断支持和放射科工作流程效率的显著进步，但在广泛应用前还需要临床验证和多中心评估。", "innovation": "该工作的创新之处在于开发了一种基于VLM的智能多模态医疗影像分析框架，能够实现肿瘤自动检测和临床报告生成，同时结合视觉特征提取与自然语言处理，增强了影像的上下文解释能力，并且展示了零样本学习能力以减少对大数据集的依赖。", "conclusion": "本研究表明，基于VLM的智能多模态医疗影像分析框架在多种影像模态下的异常检测性能优异，具有强大的临床应用潜力。然而，为了实现广泛的临床应用，还需要进一步的临床验证和多中心评估。"}
{"llm_update_time": "20250918", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04476", "html_url": "https://arxiv.org/abs/2509.04476", "title": "利用情境感知分词训练文本到分子模型", "title_en": "Training Text-to-Molecule Models with Context-Aware Tokenization", "authors": "Seojin Kim,Hyeontae Song,Jaehyun Nam,Jinwoo Shin", "background": "近期，文本到分子模型在各种化学应用中展示了巨大的潜力，例如药物发现。这些模型通过将分子表示为原子序列来适应语言模型。然而，它们依赖于原子层面的分词，主要关注局部连接关系，限制了模型捕捉分子全局结构上下文的能力。", "innovation": "我们提出了一个名为情境感知分子T5 (CAMT5) 的新型文本到分子模型。受子结构层面上下文在理解分子结构中重要性的启发，我们引入了子结构层面的分词。基于此分词方案，我们开发了一种基于重要性的训练策略，优先处理关键子结构，使CAMT5能够更好地捕捉分子语义。广泛的实验证实了CAMT5在各种文本到分子生成任务中的优越性。有趣的是，我们发现CAMT5仅使用2%的训练词元便超越了最先进的方法。此外，我们提出了一个简单而有效的方法，通过聚合文本到分子模型的输出来进一步提升生成性能。", "conclusion": "实验结果表明，CAMT5在各种文本到分子生成任务中表现出色，特别是在使用极少的训练词元时仍能超越最先进的方法。我们还提出了一个简单有效的策略来进一步提高生成性能。相关代码可在以下链接中找到。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13652", "html_url": "https://arxiv.org/abs/2509.13652", "title": "通过单视图重建进行相对相机姿态估计的高斯配准", "title_en": "Gaussian Alignment for Relative Camera Pose Estimation via Single-View Reconstruction", "authors": "Yumin Li,Dylan Campbell", "background": "基于两幅图像计算度量相对相机姿态对于三维重建和定位至关重要。然而，传统的两视图姿态估计方法不是度量的，相机的平移未知的比例且难以处理宽基础线、纹理少或镜面反射表面的情况。", "innovation": "提出了一种无需训练的框架GARPS，该框架将问题转化为独立重建的两个3D场景的直接对齐。GARPS利用度量单目深度估计器和高斯场景重建器获得每个图像的度量高斯混合模型（GMM）。然后通过优化可微的GMM对齐目标对初步的姿态进行细化。这个目标联合考虑几何结构、视无依色彩、各向异性协方差和语义特征一致性，且在不需要显式的2D对应关系的情况下鲁棒性较好，可以处理遮挡和纹理贫乏区域。", "conclusion": "在Real-Estate10K数据集上的大量实验表明，GARPS在经典方法和最先进的学习方法中都表现出色，包括MASt3R。这强调了单视图感知与多视图几何结合以实现稳健的度量相对姿态估计的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13681", "html_url": "https://arxiv.org/abs/2509.13681", "title": "FishBEV: 具备抗畸变能力的环视鱼眼Bird's Eye View分割", "title_en": "FishBEV: Distortion-Resilient Bird's Eye View Segmentation with Surround-View Fisheye Cameras", "authors": "Hang Li,Dianmo Sheng,Qiankun Dong,Zichun Wang,Zhiwei Xu,Tao Li", "background": "作为自动驾驶技术的重要基石，Bird's Eye View (BEV) 分割技术在使用针孔摄像头时已经取得了显著进展。然而，将现有的方法扩展到具有严重几何失真、多视图对应关系模糊和不稳定的时序动态的鱼眼摄像头上却极具挑战性，这些因素严重削弱了BEV性能。", "innovation": "我们提出了FishBEV，一种专为鱼眼摄像头设计的新型BEV分割框架，包括三种互补创新：具有抗失真多尺度提取的DRME骨干网络，通过不确定性估计增强的可靠性跨视图对齐的U-SCA机制，以及根据距离调整上下文感知的时空注意力模块D-TSA，以确保时序一致性。", "conclusion": "在Synwoodscapes数据集上的大量实验表明，FishBEV在围视鱼眼BEV分割任务中的表现优于当前最佳基线。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13605", "html_url": "https://arxiv.org/abs/2509.13605", "title": "从3D定位到图像处理的CLAP推广，与RANSAC及霍夫变换的关系", "title_en": "A Generalization of CLAP from 3D Localization to Image Processing, A Connection With RANSAC & Hough Transforms", "authors": "Ruochen Hou,Gabriel I. Fernandez,Alex Xu,Dennis W. Hong", "background": "在之前的论文中，我们提出了一种名为CLAP的2D定位算法，即Clustering to Localize Across $n$ Possibilities，这种算法在2024年RoboCup国际自主人形足球比赛中夺冠时得到了应用。CLAP因其对异常值的鲁棒性而受到瞩目，通过聚类方法抑制噪声并减少错误特征匹配的影响。Clap使用聚类策略替代传统的RANSAC等基于投影误差的异常值滤除方案。因此，该算法在抑制噪声和不确定性方面提供了新的方法。在此基础上，本文旨在将CLAP算法推广至3D定位和图像拼接，并探讨CLAP、RANSAC和霍夫变换之间的联系。这种推广方法广泛适用于各个领域，并能有效处理噪声和不确定性问题。", "innovation": "本文将CLAP算法推广至3D定位和图像拼接，并进一步探讨了CLAP与RANSAC及霍夫变换之间的联系。这种方法不仅能够在3D定位中提供更强的鲁棒性，还可以应用于图像拼接等领域。通过这种方式，研究人员能够更好地处理噪声和不确定性问题，同时也可以利用已有的方法进行更深入的研究。", "conclusion": "本文推广了CLAP算法，使其适用于3D定位和图像拼接，同时展示了CLAP、RANSAC和霍夫变换之间的关系。该一般框架具有广泛的应用前景，并且可以作为处理噪声和不确定性的一种有效工具。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13631", "html_url": "https://arxiv.org/abs/2509.13631", "title": "Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery", "title_en": "Federated Learning for Deforestation Detection: A Distributed Approach with Satellite Imagery", "authors": "Yuvraj Dutta,Aaditya Sikder,Basabdatta Palit", "background": "准确识别卫星图像中的森林砍伐对于理解区域地理状况至关重要。传统方法可能因数据安全和隐私问题而限制了性能，特别是在需要多个客户端协同工作的分布式任务中。", "innovation": "本文介绍了一种使用Federated Learning (FL)的新分布式方法来识别和定位不同客户端上的森林砍伐。通过FL框架，分布在边缘的卫星中心可以协同训练模型，同时保持用户数据的隐私和安全。作者利用FLower框架和Ray框架执行分布式学习任务，通过Ray自动管理客户端数量，确保高效并发部署。FL框架应用了YOLOS-small、Faster R-CNN（ResNet50和MobileNetV3背骨）模型，并在公共数据集上进行了训练和测试。这种方法为基于图像分割的任务提供了一种新的视角，尤其是在卫星图像分析方面。", "conclusion": "本文提出的方法结合了Federated Learning和卫星图像，能够有效解决分布式数据环境下的森林砍伐检测问题。通过Ray和FLower框架的支持，实现了模型的有效协同训练和动态客户端管理，提升了模型的准确性和实时性，为森林管理提供了新的工具和方法。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13629", "html_url": "https://arxiv.org/abs/2509.13629", "title": "基于SAM的高效注册框架SAMIR：通过SAM进行稳健特征学习", "title_en": "SAMIR, an efficient registration framework via robust feature learning from SAM", "authors": "Yue He,Min Liu,Qinghao Liu,Jiazheng Wang,Yaonan Wang,Hang Zhang,Xiang Chen", "background": "图像对齐是医学图像分析中的基本任务。变形通常与组织的形态特征密切相关，因此准确的特征提取至关重要。最近的弱监督方法通过引入如分割掩码或标记点等解剖先验信息来提高对齐精度，但这些弱标签通常不易获得，限制了其实际应用。鉴于视觉基础模型的强大特征学习能力，本文提出SAMIR，这是一个利用分割一切模型(SAM)增强特征提取的高效的医疗图像对齐框架。", "innovation": "1. 利用预训练于大规模自然图像数据集上的SAM模型学习稳健的通用视觉表示。\n2. 设计了一种任务特定的适应流水线，使用SAM的图像编码器提取结构感知特征嵌入，以更准确地建模解剖一致性及变形模式。\n3. 设计了一个轻量级的3D头部，以在嵌入空间内细化特征，更好地适应医学图像中的局部变形。\n4. 引入了一种层次特征一致性损失，用于引导粗糙到精细的特征匹配，从而提高解剖对齐效果。", "conclusion": "广泛实验表明，SAMIR在ACDC和腹部CT图像对齐基准数据集上显著优于现有最先进的方法，分别在ACDC上提高了2.68%的表现，在腹部数据集上提高了6.44%。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13711", "html_url": "https://arxiv.org/abs/2509.13711", "title": "StyleProtect: 在微调的扩散模型中保护艺术身份", "title_en": "StyleProtect: Safeguarding Artistic Identity in Fine-tuned Diffusion Models", "authors": "Qiuyu Tang,Joshua Krinsky,Aparna Bharati", "background": "生成模型的迅猛发展，尤其是基于扩散的方法，意外地为其滥用提供了可能性。这些模型使得恶意使用者能够低成本地复制艺术家的创作风格，包括个人视角和长时间的投入。这导致了对保护艺术作品免受风格模仿需求的增加。尽管通用的扩散模型可以轻易模仿艺术风格，但微调后能够显著增强这种能力，让模型能够以更高的准确性和可控性复制风格。研究者假设某些交叉注意力层对艺术风格的高度敏感。我们通过激活层响应艺术和内容表示的强度及其与外部模型提取特征的相关性来衡量这种敏感度。", "innovation": "我们提出了一个高效且轻量级的保护策略，称为StyleProtect。该策略通过更新选定的交叉注意力层来有效地防护微调的扩散模型对艺术风格的复制。我们使用精心策划的艺术作品数据集，包括来自WikiArt的代表性作品和Anita数据集中的卡通动画，来实验证明所提方法在保护独特艺术风格和动画方面的出色性能，同时保持良好的不可感知性。", "conclusion": "我们的实验证明，StyleProtect能够在保持较低可见性的同时保护艺术作品的独特风格和动画不受恶意微调扩散模型的复制。该方法通过更新特定的交叉注意力层实现有效的风格防护。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13662", "html_url": "https://arxiv.org/abs/2509.13662", "title": "Deep Lookup Network", "title_en": "Deep Lookup Network", "authors": "Yulan Guo,Longguang Wang,Wendong Mao,Xiaoyu Dong,Yingqian Wang,Li Liu,Wei An", "background": "卷积神经网络包含大量不同类型的操作并高度依赖计算，而其中的乘法操作计算复杂度高，通常需要消耗更多能量和耗费更长时间，这限制了其在移动设备上的部署。在资源受限的边缘设备上，复杂的操作可以通过查找表计算来降低计算成本。在此背景下，本文引入了一种通用且高效的查找操作，可以作为神经网络构建的基本操作，通过查找表替代复杂的乘法运算，实现端到端的优化，并提出若干训练策略促进查找表的收敛。实验结果表明，通过替换昂贵的乘法操作为查找操作，可以开发用于图像分类、图像超分辨率和点云分类的任务深度查找网络，能够在能耗和推断速度方面实现更高的效率，同时保持与传统的卷积网络相当的性能。广泛的实验表明，该深度查找网络在不同任务（包括分类和回归任务）和不同类型的数据（包括图像和点云）上取得了最先进的性能。", "innovation": "本文提出了一种通用且高效的查找操作，可以作为构建神经网络的基本操作，通过查找表代替复杂的乘法运算，实现了端到端的优化，并提出旨在促进查找表收敛的训练策略。通过这种方式，研制了用于图像分类、图像超分辨率和点云分类的应用深度查找网络，提高了能源消耗和推断速度的效率，同时保持了与传统的卷积网络相当的性能。", "conclusion": "实验结果表明，提出的深度查找网络在不同任务和不同类型的数据上展示了最先进的性能，证明了通过将昂贵的乘法操作替换为查找操作来开发的网络的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13754", "html_url": "https://arxiv.org/abs/2509.13754", "title": "基于全模态精细对齐的跨模态文本到图像人像检索", "title_en": "Cross-modal Full-mode Fine-grained Alignment for Text-to-Image Person Retrieval", "authors": "Hao Yin,Xin Man,Feiyu Chen,Jie Shao,Heng Tao Shen", "background": "Text-to-Image Person Retrieval (TIPR) 是一种跨模态匹配任务，目标是根据给定的文本查询检索最相关的图像。TIPR 的关键挑战在于如何在公共潜在空间中实现文本和视觉模态的有效对齐。现有方法通过注意机制实现隐式的跨模态局部对齐，但它们缺乏验证所有局部特征是否正确对齐的能力。此外，现有方法在模型更新过程中主要关注硬负样本，旨在细化正负样本对之间的区别，而忽略错误匹配的正样本对。", "innovation": "我们提出了一个称为 FMFA 的跨模态全模态精细对齐框架，通过显式的精细对齐和现有隐式的关联推理来增强全局匹配，且不需要额外的监督。具体来说，我们设计了一个自适应相似度分布匹配（A-SDM）模块来纠正未匹配的正样本对。A-SDM 通过在联合嵌入空间中拉近这些未匹配的正样本对，从而实现更精细的全局对齐。此外，我们引入了显式精细对齐（EFA）模块，弥补了隐式关联推理中验证能力的不足。EFA 通过稀疏化相似矩阵并使用硬编码方法增强显式的跨模态精细交互。", "conclusion": "我们提出的基于 FMFA 的方法在三个公开数据集上进行了评估，实现了所有全局匹配方法中最佳的性能。我们的代码可在该链接获得。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13676", "html_url": "https://arxiv.org/abs/2509.13676", "title": "利用SAM提高基于MLLM的指示图像分割中的视觉投影效率", "title_en": "Re-purposing SAM into Efficient Visual Projectors for MLLM-Based Referring Image Segmentation", "authors": "Xiaobo Yang,Xiaojin Gong", "background": "最近，将多模态大语言模型（MLLM）与分割 Anything 模型（SAM）结合的参考图像分割（RIS）框架取得了显著成果。然而，将MLLM适应于分割段落的过程计算强度大，主要是由于视觉标记的冗余。传统的基于块的视觉投影器在减少视觉标记数量和保持语义清晰度之间难以找到平衡，常常保留过长的标记序列以避免性能下降。", "innovation": "受文本分词器的启发，本文提出了一种新的基于语义的视觉投影器，利用SAM生成的语义超像素来识别图像中的“视觉单词”。通过压缩和将语义超像素作为视觉标记投影，我们的方法能够根据场景复杂性自适应地缩短标记序列，同时最小化压缩过程中的语义损失。为了减轻信息丢失，提出了一种基于语义超像素的位置嵌入，以增强MLLM对超像素几何位置的感知，并通过语义超像素聚合器保持超像素内的细粒度细节和超像素外的全局上下文。", "conclusion": "实验表明，我们的方法在不牺牲性能的前提下将视觉标记量减少了93%，显著加快了MLLM的训练和推理速度，并在RIS上优于现有的压缩视觉投影器。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13687", "html_url": "https://arxiv.org/abs/2509.13687", "title": "Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification", "title_en": "Taylor-Series Expanded Kolmogorov-Arnold Network for Medical Imaging Classification", "authors": "Kaniz Fatema,Emad A. Mohammed,Sukhjit Singh Sehra", "background": "在计算机辅助诊断中，资源限制的临床环境中，医疗图像的有效且可解释的分类是一个挑战。传统的深度学习模型如卷积神经网络（CNN）虽然在大规模数据集上表现良好，但在数据有限且多样化的资源受限环境中效果不佳，需要大量的训练参数。", "innovation": "本文提出了一种基于样条的柯尔莫哥罗夫-阿诺德网络（KANs），包括SB Taylors-KAN、SB RBF-KAN和SB小波变换KAN。这些网络通过样条函数近似方法捕捉局部和全局非线性特征，无需预处理即可直接从原始数据学习。S Taylors-KAN在脑部MRI、胸部X光、肺结核X光和皮肤病变图像上的实验中表现出色，仅使用训练数据的30%仍能保持较高的分类准确率。该模型参数量少（仅2872个可训练参数），比传统CNN模型更适用于资源受限的医疗环境。同时，研究还使用了改进的类激活映射（Grad-CAM）来增强模型的可解释性。", "conclusion": "该框架提供了一种轻量级、可解释且泛化的医疗图像分类方法，有效解决了资源有限的大规模数据挑战，尤其适用于临床AI应用中的数据稀缺场景。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13713", "html_url": "https://arxiv.org/abs/2509.13713", "title": "UM-Depth : 带有视觉里程计的不确定性掩蔽自我监督单目深度估计", "title_en": "UM-Depth : Uncertainty Masked Self-Supervised Monocular Depth Estimation with Visual Odometry", "authors": "Tae-Wook Um,Ki-Hyeon Kim,Hyun-Duck Choi,Hyo-Sung Ahn", "background": "单目深度估计在机器人技术和自动驾驶中得到越来越多的应用，因为它可以从单个相机中推断场景几何。自监督单目深度估计框架在训练过程中共同生成和利用深度和姿态估计，从而无需深度标签。然而，这些方法在低纹理或动态区域等输入数据不确定性高的情况下仍面临准确性降低的问题。为了应对这一挑战，本文提出了一种UM-Depth框架，它结合了运动和不确定性感知的细化，以提高动态对象边界及无纹理区域的深度精度。现有运动感知方法在推断时产生额外的开销，并依赖额外标签或其他辅助网络实时生成，而本研究方法仅在训练过程中使用光流于教师网络中，从而避免了额外的标记需求和运行时的额外开销，展示了在KITTI和Cityscapes数据集上具有优越的自监督深度和姿态估计效果。", "innovation": "提出了一个UM-Depth框架，通过结合运动感知和不确定性意识的细化，提高动态对象边界和无纹理区域的深度估计精度。具体包括：1) 开发了教师-学生训练策略，将不确定性估计嵌入训练管道和网络架构中；2) 仅依赖光流于训练过程中的教师网络内，避免了实时生成的开销。这种方法显著提高了深度估计的准确性，且有效解决了低纹理和动态区域的深度估计问题，实现了KITTI数据集上自监督深度和姿态估计的最佳效果。", "conclusion": "UM-Depth框架通过融合运动感知和不确定性意识的细化策略，显著提升了静态和动态场景中的单目深度估计精度，特别是在低纹理环境和运动边界区域。该方法的教师-学生训练策略增强了在光照不明显条件下的监督，无需额外标签或辅助网络，实现了自监督深度估计的领先性能。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13747", "html_url": "https://arxiv.org/abs/2509.13747", "title": "使用权重联合学习改进泛化视觉定位", "title_en": "Improving Generalized Visual Grounding with Instance-aware Joint Learning", "authors": "Ming Dai,Wenxuan Cheng,Jiang-Jiang Liu,Lingfeng Yang,Zhenhua Feng,Wankou Yang,Jingdong Wang", "background": "泛化视觉定位任务，包括泛化引用表达理解(GREC)和分割(GRES)，扩展了经典的视觉定位范式，能够处理多目标和非目标场景。传统方法通常将这些任务分开处理，忽视了同时训练GREC和GRES的优势，也无法保证不同粒度层级的一致性预测，同时现有的方法也往往将GRES视为一种语义分割任务，而忽视了实例感知能力和实例级别框与掩码之间一致性的关键作用。", "innovation": "本文提出了一种具备实例感知能力的多任务泛化视觉定位框架InstanceVG，该框架通过实例查询来统一实例级别框和掩码的联合与一致性预测，使其成为第一个同时处理GREC和GRES并且将实例感知能力融入泛化视觉定位中的框架。通过为每个实例查询指定一个先验参考点，该设计有助于在同一实例上对点、框和掩码的一致预测。", "conclusion": "在四个任务上的十个数据集上进行的广泛实验表明，InstanceVG在各种评估指标上都实现了最先进的性能，显著优于现有方法。源代码和模型将在该网址公开: [提供的网址]。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13361", "html_url": "https://arxiv.org/abs/2509.13361", "title": "基于YOLOv11-DIoU和GRU-Attention的高速公路拥堵预警技术研究", "title_en": "Research on Expressway Congestion Warning Technology Based on YOLOv11-DIoU and GRU-Attention", "authors": "Tong Yulin,Liang Xuechen", "background": "高速公路交通拥堵严重影响了出行效率并阻碍了区域联通。现有‘检测-预测’系统在遮挡下的车辆感知精度较低，并且在拥堵预测中丧失了长序列依赖性。", "innovation": "本文提出了一种整合技术框架，优化了YOLOv11-DIoU和DeepSort算法。通过替换损失函数和融合运动与外观距离，改善了传统的YOLOv11和DeepSort算法。实验展示了YOLOv11-DIoU和DeepSort在拥堵检测和预测上的显著改进，且通过GRU-Attention模型实现了拥堵预警的高准确性。", "conclusion": "该框架为高速公路拥堵控制提供了定量支持，并在智能交通系统中具有广阔的应用前景。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13767", "html_url": "https://arxiv.org/abs/2509.13767", "title": "VocSegMRI：实时MRI中精确喉腔分割的多模态学习", "title_en": "VocSegMRI: Multimodal Learning for Precise Vocal Tract Segmentation in Real-time MRI", "authors": "Daiqi Liu,Tomás Arias-Vergara,Johannes Enk,Fangxu Xing,Maureen Stone,Jerry L. Prince,Jana Hutter,Andreas Maier,Jonghye Woo,Paula Andrea Pérez-Toro", "background": "在实时磁共振成像（rtMRI）中准确分割发音结构仍然具有挑战性，因为现有方法几乎完全依赖视觉线索。同步的声学和音韵信号提供了补充的上下文信息，可以丰富视觉信息并提高精度。", "innovation": "本文引入了VocSegMRI，这是一种多模态框架，通过交叉注意力融合集成视频、音频和音韵输入，实现动态特征对齐。为了进一步增强跨模态表示，引入了对比学习目标，即使在推理阶段音频模态不可用时也能提高分割性能。在USC-75 rtMRI数据集的子集中，该方法的Dice分数为0.95，第95百分位数豪斯多夫距离（HD_95）为4.20毫米，超过了单模态和多模态基线方法。消融研究确认了交叉注意力和对比学习对分割精度和鲁棒性的影响。", "conclusion": "这些结果强调了集成多模态建模对于准确喉腔分析的价值。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13766", "html_url": "https://arxiv.org/abs/2509.13766", "title": "NDLPNet：一种位置感知的夜间去雨网络及其现实世界基准数据集", "title_en": "NDLPNet: A Location-Aware Nighttime Deraining Network and a Real-World Benchmark Dataset", "authors": "Huichun Liu,Xiaosong Li,Yang Liu,Xiaoqi Cheng,Haishu Tan", "background": "雨滴造成的视觉降级在低光条件下对夜间监控和自主导航性能造成严重影响。现有的图像去雨技术主要针对白天条件设计，在夜间照明条件下效果不佳，因为雨滴的空间分布差异性和光照依赖的条纹可见性对图像质量有显著影响。", "innovation": "提出了一种新型的夜间去雨定位增强感知网络（NDLPNet），能够有效捕捉低光照条件下雨滴的空域位置信息和密度分布。引入了位置感知模块（PPM）来捕捉并利用输入数据中的空域上下文信息，增强模型识别和重新校准不同特征通道重要性的能力。此外，构建了包含900个图像对的夜间场景雨（NSR）数据集，基于现实世界的夜间场景，为夜间去雨任务研究提供了新的基准数据集。", "conclusion": "在现有数据集和NSR数据集上的广泛定性和定量实验评估中，我们的方法在夜间去雨任务中均表现出优于现有最先进的方法的效果。源代码和数据集可在如下地址获取：[请替换为实际链接]。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13722", "html_url": "https://arxiv.org/abs/2509.13722", "title": "Mitigating Query Selection Bias in Referring Video Object Segmentation", "title_en": "Mitigating Query Selection Bias in Referring Video Object Segmentation", "authors": "Dingwei Zhang,Dong Zhang,Jinhui Tang", "background": "近年来，基于查询的方法在引用视频对象分割（RVOS）中表现出色，通过使用文本静态对象查询来驱动跨模态对齐。然而，这些静态查询容易受到外观或运动相似的干扰物的误导，导致查询选择偏差。", "innovation": "本文提出了一种名为Triple Query Former（TQF）的方法，将引用查询分解为三个专门的组成部分：用于静态属性的外观查询、用于空间关系的帧内交互查询和用于时间关联的帧间运动查询。TQF通过结合语言线索和视觉指导动态构建查询，并引入了两种运动感知聚合模块：帧内交互聚合和帧间运动聚合，进一步增强对象令牌表示。", "conclusion": "在多个视频对象分割基准上的广泛实验表明，TQF的优势和我们结构化查询设计及运动感知聚合模块的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13768", "html_url": "https://arxiv.org/abs/2509.13768", "title": "具有扩散先验的生成图像编码", "title_en": "Generative Image Coding with Diffusion Prior", "authors": "Jianhui Chang", "background": "随着生成技术的发展，视觉内容成为了自然图像和AI生成图像的复杂混合，这促使了需要更高效且能优先考虑感知质量的编码技术。传统的编解码器和基于学习的方法难以在高压缩比下保持主观质量，现有的生成方法还面临视觉保真度和泛化能力的挑战。", "innovation": "提出了一种新颖的生成编码框架，利用扩散先验来提高低比特率下的压缩性能。该方法采用预优化的编码器生成泛化的压缩域表示，并通过轻量级适配器和注意力融合模块与预训练模型的内部特征集成。同时引入了分布重归一化方法以进一步提高重建保真度。实验结果显示，该方法在低比特率下视觉保真度超过现有方法，在H.266/VVC上提高了高达79%的压缩性能，还提供了一种适用于AI生成内容的有效解决方案，并且可以适应更广泛的内容类型。", "conclusion": "该研究提出的方法在视觉保真度和压缩性能上取得了显著提升，能够在保持高效率的同时，更好地适应不同类型的视觉内容，尤其适用于AI生成的内容。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13784", "html_url": "https://arxiv.org/abs/2509.13784", "title": "CETUS: 基于统一可变速率调度的因果事件驱动时序建模", "title_en": "CETUS: Causal Event-Driven Temporal Modeling With Unified Variable-Rate Scheduling", "authors": "Hanfang Liang,Bing Wang,Shizhen Zhang,Wen Jiang,Yizhuo Yang,Weixiang Guo,Shenghai Yuan", "background": "事件相机以微秒级的时间分辨率捕捉像素级别的亮度变化，适合高速视觉任务。现有方法通常将事件流转换为帧、体素网格或点云等中间表示，这不可避免地需要预定义的时间窗口，从而引入窗口延迟。同时，基于点的检测方法由于高计算成本而在实时效率方面面临挑战。", "innovation": "提出了Variable-Rate Spatial Event Mamba（Variable-Rate Spatial Event Mamba），这是一种新颖的架构，可以直接处理原始事件流，而无需中间表示。方法中引入了一种轻量级的因果时空邻域编码器，可以高效地捕捉局部几何关系，并通过Mamba为基础的状态空间模型实现线性复杂度的可扩展的时间建模。控制器在推理时能够根据事件率自适应地调整处理速度，实现窗口延迟和推理延迟之间的最佳平衡。", "conclusion": "所提出的方法能够在保持低延迟的同时实现高效性，解决了现有技术中的窗口延迟和实时性挑战。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13769", "html_url": "https://arxiv.org/abs/2509.13769", "title": "AdaThinkDrive：通过强化学习实现自适应思考的自动驾驶系统", "title_en": "AdaThinkDrive: Adaptive Thinking via Reinforcement Learning for Autonomous Driving", "authors": "Yuechen Luo,Fang Li,Shaoqing Xu,Zhiyi Lai,Lei Yang,Qimao Chen,Ziang Luo,Zixun Xie,Shengyin Jiang,Jiaxin Liu,Long Chen,Bing Wang,Zhi-xin Yang", "background": "尽管视觉语言行动（VLA）模型中广泛应用了像链条思考（Chain of Thought，CoT）这样的推理技术，最新的研究表明，这些技术在自动驾驶中特别是在简单场景中，依然表现为增加不必要的计算开销，而决策质量却没有明显提升。现有的自动驾驶模型通常在不需要时也会进行复杂的推理计算，这不仅浪费了计算资源，也没有显著提高决策效果，特别是在不需要深入推理的简单场景中。", "innovation": "提出了一种名为AdaThinkDrive的新颖的VLA框架，该框架结合了‘快思考’和‘慢思考’模式，采用强化学习进行预训练和监督微调。AdaThinkDrive通过引入自适应思考奖励策略来识别需要推理的场景，并在执行推理计算时进行奖励，从而在提高决策质量的同时优化了推理模式下的工作效率。实验结果表明，该系统在Navsim基准测试中取得了90.3的PDMS，超过了传统的基于视觉的基线模型1.7个点，且比始终使用推理计算的方案减少了14%的推理时间，这些都展示了其通过自适应推理机制平衡准确性和效率的能力。", "conclusion": "AdaThinkDrive不仅在决策质量上超过了传统的视觉基线，还在需要推理的场景中实现了较好的适应性，同时减少了不必要的推理开销。该研究提出了一种创新的自适应推理机制，成功提高了自动驾驶系统的整体性能和效率。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13760", "html_url": "https://arxiv.org/abs/2509.13760", "title": "迭代提示精炼以生成更安全的文本到图像", "title_en": "Iterative Prompt Refinement for Safer Text-to-Image Generation", "authors": "Jinwoo Jeon,JunHyeok Oh,Hayeong Lee,Byung-Jun Lee", "background": "文本到图像（T2I）模型在从文本提示生成图像方面取得了显著进展，但其输出质量和安全性仍然依赖于提示的表述方式。现有的安全方法通常使用大型语言模型（LLMs）来精炼提示，但忽略了生成的图像，这可能导致不安全的输出或对已安全的提示进行不必要的更改。这限制了生成更安全T2I内容的可能性。", "innovation": "本文提出了一个迭代提示精炼算法，利用视觉语言模型（VLMs）分析输入提示和生成的图像，通过视觉反馈闭环来更有效地精炼提示，提高安全性同时保持与用户意图的一致性，并引入了使用现成的多模态LLMs标注有文本和视觉安全信号的新数据集，以进行监督微调。实验结果表明，本文的方法可以在不牺牲用户意图对齐的情况下，生成更安全的输出，提供了一种生成更安全的T2I内容的实用解决方案。", "conclusion": "通过结合视觉反馈的迭代提示精炼过程以及新的带有开放标签数据集的方法，本文提出的方法显著提高了生成的T2I内容的安全性，同时保持了与用户意图的一致性，为生成安全的T2I内容提供了现实可行的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13762", "html_url": "https://arxiv.org/abs/2509.13762", "title": "高级视觉感知的感知任务导向型图像信号处理器", "title_en": "Task-Aware Image Signal Processor for Advanced Visual Perception", "authors": "Kai Chen,Jin Xiao,Leheng Zhang,Kexuan Shi,Shuhang Gu", "background": "近年来，计算机视觉领域出现了利用RAW传感器数据的趋势，RAW数据相较于传统低位宽RGB图像保留了更丰富的信息。早期研究主要集中在增强视觉质量上，而最近的研究则试图利用RAW数据中丰富的信息来提高目标检测、分割等视觉感知任务的表现。但现有方法仍存在两大局限：大型图像信号处理（ISP）网络导致了严重的计算开销，而基于调优传统ISP流水线的方法则受限于有限的表示能力。", "innovation": "本文提出了任务导向型图像信号处理（TA-ISP）框架，这是一种紧凑的RAW到RGB转换体系，能够产生预训练视觉模型所需的任务导向型表示。TA-ISP预测一组轻量级的多尺度调制算子，这些算子分别在全局、区域和像素尺度上作用，重塑不同空间范围内的图像统计特性。这种分因子控制极大地扩展了空间变化变换的表示范围，在保持内存使用、计算和延迟方面严格受限的同时兼具灵活性。", "conclusion": "在多种RAW域目标检测和分割基准测试中，无论在白天还是夜间，TA-ISP均能提高下游准确率，大幅减少参数数量和推理时间，使其适用于资源受限设备的部署。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13795", "html_url": "https://arxiv.org/abs/2509.13795", "title": "SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments", "title_en": "SWA-PF: Semantic-Weighted Adaptive Particle Filter for Memory-Efficient 4-DoF UAV Localization in GNSS-Denied Environments", "authors": "Jiayu Yuan,Ming Dai,Enhui Zheng,Chao Su,Nanxing Chen,Qiming Hu,Shibo Zhu,Yibin Cao", "background": "视觉导向的无人驾驶飞行器(UAV)定位系统在缺乏全球导航卫星系统(GNSS)的环境中受到了广泛的研究。然而，现有基于检索的方法面临数据集可用性有限和持续的挑战，包括非最优的实时表现、环境敏感性以及有限的一般化能力，尤其是在动态或随时间变化的环境中。", "innovation": "为了克服这些限制，本文提出了一种大规模的多海拔飞行段数据集（MAFS）以适应不同海拔场景，并提出了一种新颖的语义加权自适应粒子滤波器（SWA-PF）方法。此方法通过两种关键创新—语义加权机制和优化的粒子过滤架构，融合了UAV捕获图像和卫星图像的鲁棒语义特征。这种方法能够利用低分辨率卫星地图以秒计算时间实现4自由度（4-DoF）姿态的快速估计，在使用我们数据集评估中实现了特征提取方法10倍的计算效率提升，全球定位误差保持在10米以内。", "conclusion": "所提出的方法显著提高了UAV在拒绝GNSS环境中的四自由度姿态估计性能，同时利用了语义信息提高了实时性能和一般化能力，并通过大规模的新数据集验证了其有效性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13792", "html_url": "https://arxiv.org/abs/2509.13792", "title": " Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation", "title_en": "Bridging the Synthetic-Real Gap: Supervised Domain Adaptation for Robust Spacecraft 6-DoF Pose Estimation", "authors": "Inder Pal Singh,Nidhal Eddine Chenni,Abd El Rahman Shabayek,Arunkumar Rathinam,Djamila Aouada", "background": "航天器姿态估计（SPE）是自主太空操作中的基础能力，如交会对接和在轨服务。尽管现有的混合管道在合成数据集上取得了显著成果，但在真实或实验室生成的图像上，其性能显著下降，主要是由于合成与现实之间的领域差异。现有的一些无监督领域适应方法虽有帮助，但在少量标注目标数据的情况下效果不佳。这些领域适应方法通常在获得少量目标数据标记者表现较差。因此，需要一种可以有效应对合成数据到实际情况转变的方法。", "innovation": "本研究提出了一种面向SPE关键点回归的监督领域适应（SDA）框架。该方法结合了Learning Invariant Representation and Risk (LIRR) 理论，通过联合优化领域不变表示和任务特定风险，利用标记的合成数据和有限的标注真实数据，从而在领域转换中减少泛化误差。实验结果表明，该方法在SPEED+基准测试上优于仅有来源数据、微调和理想基准，即使只有5%的标注目标数据，也能达到或超过大量标注数据的理想性能。此外，该框架轻量级、无特定骨架依赖且计算效率较高，为在真实太空环境中实现鲁棒和可部署的航天器姿态估计提供了可行途径。", "conclusion": "本文提出了一种基于LIRR的监督领域适应方法，能够有效应对SPE中的合成领域和现实领域间的挑战。实验表明该方法在少量标注目标数据的情况下，性能显著提升，具有重要的应用价值。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13834", "html_url": "https://arxiv.org/abs/2509.13834", "title": "Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation", "title_en": "Semi-MoE: Mixture-of-Experts meets Semi-Supervised Histopathology Segmentation", "authors": "Nguyen Lan Vi Vu,Thanh-Huy Nguyen,Thien Nguyen,Daisuke Kihara,Tianyang Wang,Xingjian Li,Min Xu", "background": "半监督学习由于其缓解需要大量标记数据的需求，已应用于组织病理学图像分割领域。然而，现有的方法在处理由于腺体边界模糊和形态分类错误而产生的噪声伪标签时存在困难。本文背景在于如何提高在现有半监督学习方法的基础上，应对这种噪声伪标签的问题。", "innovation": "提出了Semi-MOE（Semi-Mixture-of-Experts），这是首个用于半监督组织病理学图像分割的多任务混合专家框架。该方法通过专门设计的三个专家网络（主要分割专家、符号距离场回归专家和边界预测专家）来捕捉不同的形态特征。此外，还提出了一种动态聚合专家特征的多门控伪标签模块，以及一种自适应多目标损失来动态平衡多种学习目标，从而提高了模型的鲁棒性和效率。", "conclusion": "在GlaS和CRAG基准测试上的广泛实验表明，本文方法在低标记设置中优于现有最先进的方法，突显了基于混合专家架构在推进半监督分割方面的潜力。我们的代码可在以下链接获取：this https URL"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13789", "html_url": "https://arxiv.org/abs/2509.13789", "title": "BWCache：通过区块级缓存加速视频扩散变换器", "title_en": "BWCache: Accelerating Video Diffusion Transformers through Block-Wise Caching", "authors": "Hanshuai Cui,Zhiqing Tang,Zhifei Xu,Zhi Yao,Wenyi Zeng,Weijia Jia", "background": "最近关于扩散变换器（DiTs）的进展已确立它们作为视频生成的最先进的方法。然而，其固有的顺序去噪过程不可避免地导致了延迟问题，限制了它们在现实世界中的应用。现有的加速方法不是因为架构修改而牺牲了视觉质量，就是无法在适当的粒度上重用中间特征。我们的分析表明，DiT区块是推断延迟的主要贡献者。在扩散时间步骤中，DiT区块的特征变化表现出U形模式，在中间时间步骤之间具有高度相似性，这表明存在大量计算冗余。", "innovation": "我们提出了区块级缓存（BWCache），这是一种无需训练的方法来加速基于DiT的视频生成。BWCache动态地跨扩散时间步骤缓存并重用DiT区块的特征。此外，我们引入了一个相似度指标，仅在相邻时间步骤之间的区块特征差异低于阈值时触发特征重用，从而在最小化冗余计算的同时保持视觉保真度。", "conclusion": "在几种视频扩散模型上的广泛实验表明，BWCache实现了高达2.24倍的速度提升，同时保持了可比的视觉质量。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13776", "html_url": "https://arxiv.org/abs/2509.13776", "title": "优化的形态学多尺度融合：结合局部伪影和宏微观语义进行深伪检测与定位", "title_en": "Morphology-optimized Multi-Scale Fusion: Combining Local Artifacts and Mesoscopic Semantics for Deepfake Detection and Localization", "authors": "Chao Shuai,Gaojian Wang,Kun Pan,Tong Wu,Fanli Jin,Haohan Tan,Mengxiang Li,Zhenguang Liu,Feng Lin,Kui Ren", "background": "尽管在深度造假检测中追求更高的准确性仍然是一个核心目标，但精确定位被篡改区域的需求正在增加。虽然基于分类的检测有了显著的进步，但在准确定位伪造区域方面仍然面临重大挑战。一种常见的策略是在训练模型时结合伪造区域标注和篡改图像。然而，这些方法往往忽视了局部细节和全局语义上下文的互补性，导致定位性能不佳。此外，局部预测和全局预测之间的融合策略经常被忽视。简单地结合两个分支的输出可能会放大噪声和错误，从而削弱定位的有效性。本文的背景围绕这些问题展开，强调了局部与全局预测融合的重要性及其挑战。", "innovation": "本文提出了一种创新的方法，即通过同时从局部和全局两个视角独立预测篡改区域，并通过形态学操作来优化多尺度融合，有效地抑制噪声并增强空间相干性。该方法通过融合局部伪影和宏微观语义，能够显著提高伪造定位的准确性和鲁棒性，避免了简单结合局部和全局预测时可能出现的噪声放大和错误累积问题。", "conclusion": "本文通过大量实验验证了每种模块的有效性，证明了该方法在提高伪造定位准确性和稳健性方面的显著优势。形态学优化的多尺度融合方法结合局部伪影和宏微观语义，不仅解决了传统方法中的噪声抑制问题，还提高了定位的准确性与时序连贯性，为深伪检测与定位提供了一种新的有力工具。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13848", "html_url": "https://arxiv.org/abs/2509.13848", "title": "SpecDiff: 利用自我推测加速扩散模型推理", "title_en": "SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation", "authors": "Jiayi Pan,Jiaming Xu,Yongkang Zhou,Guohao Dai", "background": "特征缓存 recently emerged as a有效的加速扩散模型的方法，通过在推理过程中缓存类似的特征信息，来缓解高计算要求带来的低效率问题。然而，现有方法主要依赖历史信息，这将限制准确性和速度性能。", "innovation": "提出了一个新颖的利用自我推测信息的多级特征缓存策略 \textit{SpecDiff}。该策略包括一个基于自我推测信息的特征选择算法和一个基于特征重要性得分的多级特征分类算法。通过将推测信息和历史信息融合，\textit{SpecDiff} 解决了加速和准确性的权衡问题，推动了速度和准确性的边界。", "conclusion": "\textit{SpecDiff} 在 NVIDIA A800-80GB GPU 上相对于 RFlow 实现了平均 2.80 \times, 2.74 \times 和 3.17\times 的速度提升，并且在 Stable Diffusion 3, 3.5, 和 FLUX 上质量损失很少。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13809", "html_url": "https://arxiv.org/abs/2509.13809", "title": "使用MiniROCKET和HDC-MiniROCKET实现高效利用数据的高光谱数据谱分类", "title_en": "Data-Efficient Spectral Classification of Hyperspectral Data Using MiniROCKET and HDC-MiniROCKET", "authors": "Nick Theisen,Kenny Schlegel,Dietrich Paulus,Peer Neubert", "background": "高光谱图像的像素谱分类在农业、医疗、遥感等领域广泛应用，并正在扩展到自动驾驶等领域。尽管全高光谱图像的最佳方法利用了空间和光谱信息，但仅依赖光谱信息进行分类也具有优势，如模型尺寸小、训练所需数据少。光谱信息与空间信息补充，对任一方面的改进未来可以用于改进空间和光谱结合的方法。1D-Justo-LiuNet是高效且参数少的模型，目前定义了谱分类的最新技术。然而，当训练数据有限时，模型性能会下降。因此，研究MiniROCKET和HDC-MiniROCKET解决这一问题。MiniROCKET和HDC-MiniROCKET在特征提取部分使用了无训练参数的高效工程特征，因此对有限训练数据更不敏感。尽管MiniROCKET的参数更多，但在有限数据场景下表现出色，在一般情况下与1D-Justo-LiuNet相当。", "innovation": "引入MiniROCKET和HDC-MiniROCKET模型用于谱分类，这些模型在特征提取部分没有可训练参数，因此对于有限的训练数据更不敏感。即使MiniROCKET的参数较多，但在有限数据场景下仍然优于1D-Justo-LiuNet，并在一般情况下表现大致相当。", "conclusion": "MiniROCKET和HDC-MiniROCKET模型通过利用无训练参数的工程特征，在有限训练数据的情况下显示出较好的分类性能，可以为高光谱数据的谱分类提供一个有效的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13858", "html_url": "https://arxiv.org/abs/2509.13858", "title": "EDITS: 提升数据集蒸馏的隐含文本语义", "title_en": "EDITS: Enhancing Dataset Distillation with Implicit Textual Semantics", "authors": "Qianxin Xia,Jiawei Du,Guoming Lu,Zhiyong Shu,Jielei Wang", "background": "数据集蒸馏的目标是从原始大规模数据集中合成一个紧凑的数据集，以实现高效的模型训练同时保持竞争力的模型性能。然而，传统技术主要捕捉低层次的视觉特征，忽视了图像中的高层语义和结构信息。", "innovation": "本文提出了一种名为EDITS的新框架，该框架利用图像数据中的隐含文本语义来实现增强的蒸馏效果。首先，通过全局语义查询模块将Vision Language Model（VLM）生成的外部文本与图像特征融合，形成先验聚类缓存。然后，局部语义意识从缓存中选择代表性样本构建图像和文本原型，后者通过大型语言模型（LLM）精心构造的提示来进行指导。最终，通过扩散模型生成最终的合成数据集。", "conclusion": "大量的实验验证了EDITS框架的有效性，代码可以在 https://github.com/EDITS-DatasetDistillation处获得。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13846", "html_url": "https://arxiv.org/abs/2509.13846", "title": "一致视角对齐提高基础模型在3D医学图像分割中的表现", "title_en": "Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation", "authors": "Puru Vaish,Felix Meister,Tobias Heimann,Christoph Brune,Jelmer M. Wolterink", "background": "许多最新的表示学习方法假设不相关的数据点视图足以学习用于各种下游任务的有意义表示。然而，本文挑战了这一假设，并证明了有意义的潜在空间结构不会自然出现，而是必须明确诱导。方法通过对齐来自不同数据视图的表示来对齐互补信息，而不会诱导假阳性。实验表明，本提出的自我监督学习方法，一致视角对齐，能够提高下游任务的表现，突出了结构化视角对齐在学习有效表示中的关键作用。团队在使用Primus视觉转换器时获得MICCAI 2025 SSL3D挑战的第1名，在使用ResEnc卷积神经网络时获得第2名。", "innovation": "本文提出了一种方法，即一致视角对齐（Consistent View Alignment），该方法通过对齐不同视角的数据表示来对齐互补信息，同时避免诱导假阳性。该方法能够提高下游任务的表现，特别强调了结构化视角对齐的重要性，并展示了在MICCAI 2025 SSL3D挑战中的优异成绩。", "conclusion": "本研究提出的自我监督学习方法一致视角对齐在提升3D医学图像分割任务表现方面取得了显著效果，突出了结构化视角对齐对学习有效表示的关键作用。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13836", "html_url": "https://arxiv.org/abs/2509.13836", "title": "从视觉视角探讨减轻大型视觉-语言模型幻觉的方法", "title_en": "Diving into Mitigating Hallucinations from a Vision Perspective for Large Vision-Language Models", "authors": "Weihang Wang,Xinhao Li,Ziyue Wang,Yan Pang,Jielei Zhang,Peiyi Li,Qiang Zhang,Longwen Gao", "background": "大型视觉-语言模型（LVLMs）中的对象幻觉严重阻碍了它们在现实世界中的应用。视觉编码器是准确解析视觉信息的主要组件，不同的训练范式赋予不同视觉编码器独特的归纳偏差，导致它们在幻觉表现上存在差异。现有的基准测试主要集中在粗粒度的幻觉检测上，无法捕捉到我们假设中的各种细腻的幻觉现象。因此，需要全面评估LVLMs在不同细粒度幻觉类别上的表现，以系统地分析这些影响效果，从而提出新的基准测试和方法。", "innovation": "本文提出了VHBench-10，一个包含约10,000个样本、全面评估LVLMs在十种细粒度幻觉类别上的表现的基准测试。基于这些见解，本文还提出了VisionWeaver，一种新的上下文感知路由网络，通过全局视觉特征生成路由信号，动态汇聚多专家模块的视觉特征。实验证明VisionWeaver在显著减少幻觉和提高模型整体性能方面非常有效。", "conclusion": "通过采用VisionWeaver，LVLMs在减少幻觉方面表现出显著效果，同时提高了模型的总体性能。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13864", "html_url": "https://arxiv.org/abs/2509.13864", "title": "Distractor-Aware Memory-Based Visual Object Tracking", "title_en": "Distractor-Aware Memory-Based Visual Object Tracking", "authors": "Jovana Videnovic,Matej Kristan,Alan Lukezic", "background": "近期涌现的记忆型视频分割方法，如SAM2，表现出强劲的分割任务性能，并在众多基准测试中获得了领先的成绩。然而，这些模型未能充分匹配到视觉目标跟踪任务，其中的干扰物（即与目标视觉相似的对象）构成了关键挑战。", "innovation": "本文提出了一种干扰物感知的记忆模块和基于反省的管理方法，命名为DAM4SAM，显著减少了跟踪过程中的目标漂移，并提高了遮挡后重新检测目标的能力。同时，我们构建了一个干扰物精炼数据集DiDi，用于跟踪过程中干扰物分析。实验表明DAM4SAM在13项基准测试中优于SAM2.1，并在10项基准测试中取得了新的最先进的结果。", "conclusion": "该方法应用于实时跟踪器EfficientTAM时，追踪性能提高了11%，在多个分割和跟踪基准测试中达到了与非实时的SAM2.1-L相同的质量，并且整合到基于边缘的跟踪器EdgeTAM时获得了4%的性能提升，证明了其架构的通用性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13873", "html_url": "https://arxiv.org/abs/2509.13873", "title": "隐形但被检测到：注意力引导的解剖融合PelFANet在骨盆骨折诊断中的应用", "title_en": "Invisible Yet Detected: PelFANet with Attention-Guided Anatomical Fusion for Pelvic Fracture Diagnosis", "authors": "Siam Tahsin Bhuiyan,Rashedur Rahman,Sefatul Wasi,Naomi Yagi,Syoji Kobashi,Ashraful Islam,Saadia Binte Alam", "background": "骨盆骨折在临床诊断中具有重大挑战，尤其是在骨折征象模糊或在标准X射线中不可见的情况下。现有的诊断方法在处理这些复杂的病例时效果不佳。", "innovation": "提出了一种名为PelFANet的双流注意力网络，该网络将原始骨盆X射线与分割骨骼图像融合，通过迭代交换和细化特征，同时捕捉全局上下文和局部解剖细节，提高了骨折分类的准确性。该网络采用基于分割的两阶段训练方法，表现出相比传统方法的优越性。", "conclusion": "PelFANet在AMERI数据集中对可见骨折实现了88.68%的准确率和0.9334的AUC，并能够有效泛化到未训练过的隐形骨折病例中，准确率达到了82.29%和0.8688的AUC。这些结果表明解剖感知的双输入架构在临床骨盆骨折检测中具有重要的应用潜力，特别适用于放射学表现细微的情况。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13863", "html_url": "https://arxiv.org/abs/2509.13863", "title": "LamiGauss: 使用放射性高斯进行稀视图X射线层析重建", "title_en": "LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction", "authors": "Chu Chen,Ander Biguri,Jean-Michel Morel,Raymond H. Chan,Carola-Bibiane Schönlieb,Jizhou Li", "background": "X射线层析 laminography (CL) 对于微芯片和复合电池材料等板状结构的非破坏性检测至关重要，但在几何约束条件下，传统计算机断层扫描 (CT) 面临挑战。从层析投影重建高质量的立体体积在高稀疏视图采集条件下尤为困难。", "innovation": "本文提出了一种名为 LamiGauss 的重建算法，结合了高斯斑点放射性绘制和专门的检测器到世界变换模型，该模型包含层析倾斜角度。LamiGauss 使用初始策略显式地从初步重建中过滤掉常见的层析伪影，防止多余的高斯分布在假结构上，从而集中模型能力表示真实的物体。该方法直接优化来自稀疏投影的数据，实现准确高效的重建。", "conclusion": "在合成和真实数据集上的广泛实验表明，提出的 LamiGauss 方法优于现有技术。LamiGauss 仅使用全视图的 3% 就能实现比在完整数据集上优化的迭代方法更好的性能。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13936", "html_url": "https://arxiv.org/abs/2509.13936", "title": "噪声级扩散指导：良好的开端是成功的一半", "title_en": "Noise-Level Diffusion Guidance: Well Begun is Half Done", "authors": "Harvey Mannering,Zhiwu Huang,Adam Prugel-Bennett", "background": "扩散模型在图像生成方面已达到最先进的水平，但是用于开始扩散过程的随机高斯噪声会影响最终输出，导致图像质量和提示适应性存在变异。现有的噪声级优化方法通常需要额外的数据集建设、附加网络或基于反向传播的优化，这些方法的实用性受到了限制。", "innovation": "该论文提出了一种名为Noise Level Guidance（NLG）的简单、高效且通用的噪声级优化方法，无需额外的训练数据、辅助网络或反向传播就能逐步提高噪声与通用指导的一致性。", "conclusion": "通过无缝集成现有指导方法并保持计算效率，该方法将NLG确立为扩散模型的一种实用和可扩展的增强。我们的方法在五个标准基准上进行了广泛的实验证实，提高了输出生成质量和输入条件的一致性。代码可以在该链接：this https URL 找到。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13907", "html_url": "https://arxiv.org/abs/2509.13907", "title": "White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation", "title_en": "White Aggregation and Restoration for Few-shot 3D Point Cloud Semantic Segmentation", "authors": "Jiyun Im,SuBeen Lee,Miso Lee,Jae-Pil Heo", "background": "现有方法通过传统的算法如最远点采样构建原型以从有限的支持集提取区分性表示，但其初始的随机性对少数样本点云分割性能影响较大且原型生成过程未被充分探索。", "innovation": "提出了一种基于注意力机制的高级原型生成方法，并设计了白聚合和恢复模块（WARM），通过在漂白和着色变换之间夹入交叉注意力来解决可学习的原型标记和支撑特征之间的分布差距问题，从而提高点云语义分割的鲁棒性注意力，生成有代表性的原型。", "conclusion": "该方法在多个少数样本点云分割基准上达到了最先进的性能，并通过广泛的实验证明了其有效性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13919", "html_url": "https://arxiv.org/abs/2509.13919", "title": "通过自我推理校准实现LVLM的推理-答案对齐", "title_en": "Towards Rationale-Answer Alignment of LVLMs via Self-Rationale Calibration", "authors": "Yuanchen Wu,Ke Yan,Shouhong Ding,Ziyin Zhou,Xiaoqiang Li", "background": "大型视觉语言模型（LVLMs）在视觉问答方面表现出强大的能力，但它们在对齐推理和生成答案方面仍然存在困难，导致推理不一致和错误的回答。", "innovation": "提出了自我推理校准（SRC）框架，通过迭代校准推理和答案之间的对齐。它首先采用一种轻量级的“推理微调”方法，以需要推理才能生成答案的形式修改模型的响应格式，而不使用显式提示。随后，为每个样本从微调后的LVLM中搜索多样化的候选响应，然后使用定制的评分模型R-Scorer评估候选答案的质量和事实一致性。", "conclusion": "SRC过程通过一种基于置信度加权的偏好校准方法，解耦了对齐校准，从而显著提高了LVLMs在感知、推理和泛化方面的表现。研究结果强调了推理导向的对齐在探索LVLM潜力方面的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13883", "html_url": "https://arxiv.org/abs/2509.13883", "title": "EvHand-FPV: 效率高的事件驱动的第一人称视角3D手部跟踪", "title_en": "EvHand-FPV: Efficient Event-Based 3D Hand Tracking from First-Person View", "authors": "Zhen Xu,Guorui Lu,Chang Gao,Qinyu Chen", "background": "手部跟踪对于直观的交互方式具有巨大的潜力，但基于帧的方法往往无法满足准确性、低延迟和能效的要求，特别是在如扩展现实(XR)设备等资源受限的环境中。事件摄像头通过异步感测亮度变化，提供微秒级的时间分辨率和毫瓦级的功率，极大地提高了能效和实时性。本文着重研究了在事件摄像头下进行第一人称视角(FPV)的3D手部跟踪问题。现有的基准数据集稀缺，且传统的方法难以满足XR设备的苛刻要求。", "innovation": "本文提出了一个轻量级的框架EvHand-FPV，用于从单个事件摄像头进行第一人称视角3D手部跟踪。它通过以下创新点提高了追踪的准确性和效率：1) 构建了一个事件数据驱动的FPV数据集，将合成训练数据与3D标签以及真实事件数据与2D标签相结合；2) 引入了基于手腕的区域兴趣（ROI），通过几何线索定位手部区域；3) 提出了端到端的映射策略，将ROI偏移嵌入网络，减少计算量而不进行显式重建；4) 使用辅助几何特征头的多任务学习策略，提升表示能力而不增加测试时的开销。", "conclusion": "EvHand-FPV 在真实FPV测试集上，2D AUC提升了7.8%，参数量减少了89%，每帧的FLOPs减少了89%，同时保持在合成数据上的3D AUC为0.84。这些成果展示了适用于设备端XR应用的准确且高效的事件驱动的第一人称视角手部跟踪。该数据集和代码已公开发布。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14001", "html_url": "https://arxiv.org/abs/2509.14001", "title": "MOCHA：多模态对象感知跨架构对齐", "title_en": "MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment", "authors": "Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli", "background": "近年来，知识蒸馏方法已经被广泛应用于跨模型的性能提升。特别是在多模态场景下的知识转移，研究人员致力于从大型多模态模型（例如LLaVa）中提取语义信息，然后转移到轻量级的纯视觉学生模型（例如YOLO）中。现有的方法主要关注密集或全局对齐策略，这往往需要修改教师模型或在推理时提供文本输入，从而增加了系统的复杂度和资源消耗。", "innovation": "本文提出了一种名为MOCHA（Multi-modal Objects-aware Cross-arcHitecture Alignment）的方法，该方法可以从大型多模态教师模型中提取区域级别的多模态语义，然后转移到轻量级的视觉只读对象检测学生模型中。MOCHA通过引入映射模块将学生模型的特征映射到联合空间，并通过双目标损失函数进行训练，该损失函数不仅指导学生模型的本地对齐，还确保全局关系一致性。与现有方法不同，MOCHA在对象级别操作，可以在不修改教师模型或在推理过程中不需要文本输入的情况下高效地传输语义。", "conclusion": "我们在四个个性化检测基准测试下的少样本设置中验证了该方法。实验结果表明，MOCHA相比于基础方法有一致性的性能提升，平均分数提高了10.1分。尽管架构紧凑，MOCHA的性能与大型多模态模型相匹配，表明其适合在实际应用场景中的部署。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13922", "html_url": "https://arxiv.org/abs/2509.13922", "title": "基于对抗净化鲁棒防御的防护性扰动", "title_en": "Towards Robust Defense against Customization via Protective Perturbation Resistant to Diffusion-based Purification", "authors": "Wenkui Yang,Jie Cao,Junxian Duan,Ran He", "background": "扩散模型如Stable Diffusion在视觉合成任务中因其强大的自定义能力而变得突出，但也带来了严重的安全风险，如深度伪造和版权侵权。为了应对这些风险，出现了一类称为防护性扰动的方法，通过注入不可察觉的对抗噪声来减轻图像被误用的风险。然而，净化过程可能会去除这些防护性扰动，使图像再次面临恶意伪造的风险。因此，本文旨在探讨并解决现有防护方法面临的挑战，提出了名为AntiPure的简单诊断防护性扰动方法，以应对净化-自定义流程中的净化问题。", "innovation": "AntiPure使用两种指导机制：1）斑块频率指导，该机制减少了模型对净化图像中高频部分的影响；2）错误时间步长指导，该机制干扰了模型在不同时间步长中的去噪策略。通过这些额外的指导机制，AntiPure能够在代表性的净化设置下嵌入持久不可察觉的扰动，实现有效的后自定义失真。实验表明，AntiPure在净化-自定义流程中作为净化的应力测试时，实现了最小的感知差异和最大的失真，优于其他防护性扰动方法。", "conclusion": "本文首次研究了AntiPure的反净化任务，利用净化-自定义流程中的挑战，提出了简洁有效的AntiPure方法，并通过实验验证了其有效性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14012", "html_url": "https://arxiv.org/abs/2509.14012", "title": "YOLO-FEDER FusionNet在视觉复杂环境下稳健无人机检测中的性能优化", "title_en": "Performance Optimization of YOLO-FEDER FusionNet for Robust Drone Detection in Visually Complex Environments", "authors": "Tamara R. Lenhard,Andreas Weinmann,Tobias Koch", "background": "在视觉复杂环境中，无人机检测仍面临背景杂乱、物体尺度小、伪装效果等挑战。尽管YOLO等通用目标检测器在低纹理场景中表现出色，但在背景和物体分离度低的复杂环境中，其效果会大幅下降。", "innovation": "本文提出了YOLO-FEDER FusionNet的增强版本，这是一种结合通用目标检测和伪装目标检测技术的检测框架。该版本通过大规模的合成数据和少量真实样本的组合训练，改进了特征融合策略和骨干设计，特别是在多尺度FEDER特征的使用上进行了系统性评估，全面测试了YOLO基础架构的多种配置。结果表明，结合中间多尺度FEDER特征和骨干网络升级显著提升了检测性能。在最成功的配置下，YOLO-FEDER FusionNet使用YOLOv8l骨干网络，并结合DWD模块的FEDER特征，FNR降低了39.1个百分点，mAP提高了62.8个百分点。", "conclusion": "综合而言，通过对训练数据、特征融合和骨干设计的系统性优化，YOLO-FEDER FusionNet在视觉复杂环境中实现了对无人机的稳健检测，特别是在减少假负率和提升检测精度方面取得了显著效果。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13801", "html_url": "https://arxiv.org/abs/2509.13801", "title": "Masked Feature Modeling Enhances Adaptive Segmentation", "title_en": "Masked Feature Modeling Enhances Adaptive Segmentation", "authors": "Wenlve Zhou,Zhiheng Zhou,Tiantao Xian,Yikui Zhai,Weibin Wu,Biyun Ma", "background": "无监督领域适应（UDA）旨在通过将标记的源域模型转移到未标记的目标域。现有的自监督任务，尤其是对比学习，虽然提高了特征可判别性，但掩码建模方法在该领域仍然很少被探索，主要原因是架构不兼容和优化目标不一致。", "innovation": "提出了一种新颖的辅助任务——掩码特征建模（MFM），直接在特征空间中执行特征掩码和重建。此外，引入了一个轻量级的辅助模块Rebuilder，该模块在训练期间与主任务联合训练，但推理时被移除，不会增加测试时间的计算开销。MFM利用分割解码器来对重建特征进行分类，紧密耦合辅助目标和像素级预测任务，避免干扰主要任务。", "conclusion": "系统地在各种架构和UDA基准测试中进行实验表明，MFM可以一致地提高分割性能，为无监督领域适应的语义分割提供了一个简单、有效、且可泛化的策略。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14060", "html_url": "https://arxiv.org/abs/2509.14060", "title": "VSE-MOT: 借助视觉语义增强在低质量视频场景中的多目标跟踪", "title_en": "VSE-MOT: Multi-Object Tracking in Low-Quality Video Scenes Guided by Visual Semantic Enhancement", "authors": "Jun Du,Weiwei Xing,Ming Li,Fei Richard Yu", "background": "当前的多目标跟踪（MOT）算法在处理低质量视频时往往表现不佳，这导致了在实地应用中性能显著下降。因此，在现实世界中的低质量视频场景中改进MOT算法的应用显得至关重要。", "innovation": "提出了一种基于视觉语义增强的多目标跟踪框架（VSE-MOT）。该方法首先设计了一个三支路架构，利用视觉-语言模型从图像中提取全局视觉语义信息并将其与查询向量融合。此外，引入了多目标跟踪适配器（MOT-Adapter）和视觉语义融合模块（VSFM），以进一步增强视觉语义信息的利用。实验证明，该方法在现实世界低质量视频场景中的效果和现有方法相比提高了约8%到20%，并在传统场景中保持了稳健的表现。", "conclusion": "通过广泛实验验证了提出方法的有效性和优越性。其在低质量视频场景中的跟踪性能指标表现出色，比现有方法提高了约8%到20%，同时在常规场景中表现出稳健性能。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14097", "html_url": "https://arxiv.org/abs/2509.14097", "title": "音频-视觉视频解析中的教师引导伪监督与跨模态对齐", "title_en": "Teacher-Guided Pseudo Supervision and Cross-Modal Alignment for Audio-Visual Video Parsing", "authors": "Yaru Chen,Ruohao Guo,Liting Gao,Yang Xiang,Qingyu Luo,Zhenbo Li,Wenwu Wang", "background": "弱监督的音频-视觉视频解析（AVVP）旨在不依赖时间标注的情况下，识别可听、可见以及音频-视觉事件。先前的研究主要侧重于通过对比学习或协作学习来优化全局预测，但在稳定时间段级监督和类感知跨模态对齐方面有所忽略。", "innovation": "本文提出了两种创新策略：（1）一种由指数加权平均（EMA）引导的伪监督框架，通过自适应阈值或top-k选择生成可靠的段级掩码，提供了超越视频级标签的稳定时间段指导；（2）一种类感知跨模态一致（CMA）损失，确保音频和视觉嵌入在可靠的类段对中的一致性，同时保留时间结构。", "conclusion": "在LLP和UnAV-100数据集上的评估表明，该方法在多个指标上实现了最佳性能（SOTA）。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14084", "html_url": "https://arxiv.org/abs/2509.14084", "title": "AD-DINOv3: 使用异常感知校准增强DINOv3实现零样本异常检测", "title_en": "AD-DINOv3: Enhancing DINOv3 for Zero-Shot Anomaly Detection with Anomaly-Aware Calibration", "authors": "Jingyi Yuan,Jianxiong Ye,Wenkang Chen,Chenqiang Gao", "background": "零样本异常检测(ZSAD)旨在识别来自任意新型类别的异常，提供一种可扩展且注释高效的解决方案。传统上，大多数ZSAD工作都基于CLIP模型，通过计算视觉和文本嵌入之间的相似性来进行异常检测。最近，如DINOv3等视觉基础模型展示了强大的可迁移表示能力。然而，如何利用这些模型解决ZSAD问题仍面临挑战。DINOv3与大规模预训练数据之间的领域偏差导致了特征不对齐，而预训练表示对全局语义的偏好导致细微异常被误认为是正常前景对象的一部分。", "innovation": "本研究首次使用DINOv3进行ZSAD，提出了AD-DINOv3，这是一种新颖的视觉语言多模态框架。我们通过多模态对比学习问题的形式化将异常检测任务转化为问题，利用DINOv3作为视觉编码器来提取局部特征，并结合CLIP文本编码器提供正常与异常提示嵌入。此外，引入了轻量级适配器在两种模态下进行表示重新校准，以弥合领域差距。在此基础上，设计了异常感知校准模块(AACM)，该模块引导CLS令牌关注异常区域而非普通的前景语义，从而增强了区分能力。", "conclusion": "通过在八个工业和医疗基准上的广泛实验表明，AD-DINOv3在性能上持续匹配或超越最先进的方法，证实了其作为通用零样本异常检测框架的优越性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14055", "html_url": "https://arxiv.org/abs/2509.14055", "title": "Wan-Animate：全面复制的统一角色动画与替换", "title_en": "Wan-Animate: Unified Character Animation and Replacement with Holistic Replication", "authors": "Gang Cheng,Xin Gao,Li Hu,Siqi Hu,Mingyang Huang,Chaonan Ji,Ju Li,Dechao Meng,Jinwei Qi,Penchong Qiao,Zhen Shen,Yafei Song,Ke Sun,Linrui Tian,Feng Wang,Guangyuan Wang,Qi Wang,Zhongjian Wang,Jiayu Xiao,Sheng Xu,Bang Zhang,Peng Zhang,Xindi Zhang,Zhe Zhang,Jingren Zhou,Lian Zhuo", "background": "当前的计算机图形学和人工智能技术在角色动画和替换方面已经取得了显著的进步，但这些技术往往缺乏精确复制参考视频中的动作和表情的能力，且在替换角色时难以实现无缝的环境融合。因此，研究人员需要开发一种统一的框架，能够准确复制角色的表达和动作，同时在替换角色时保持环境的一致性和美观性。", "innovation": "Wan-Animate 是一种统一的框架，可以从给定的角色图像和参考视频中生成高质量的角色视频，实现角色的动画和替换。该框架通过采用改良的输入模式和空间对齐的骨骼信号重新实现动作，提取隐式面部特征来再现面部表情。此外，它还开发了一个辅助的光源调整模块，以增强角色替换过程中的环境整合，确保替换后的角色与周围环境的风格和照明保持一致。这种设计将多种任务统一在一个表示形式中，提升了生成内容的可控性和表现力，同时达到了最先进的技术水平。", "conclusion": "Wan-Animate 已经实现了在角色动画和替换方面的高效和高质量生成。实验结果表明，该模型在精确复制动作与表情、保持角色外观一致性和实现无缝环境整合方面表现出色，达到了最先进的技术水平。论文中的模型权重和源代码将免费开源，以促进进一步的研究和应用。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13939", "html_url": "https://arxiv.org/abs/2509.13939", "title": "当前AI模型能否数出我们想要的，而不是它们看到的？一个基准和系统评估", "title_en": "Can Current AI Models Count What We Mean, Not What They See? A Benchmark and Systematic Evaluation", "authors": "Gia Khanh Nguyen,Yifeng Huang,Minh Hoai", "background": "视觉计数是一项基本但具有挑战性的任务，尤其是在需要用户在复杂场景中计数特定类型对象时。尽管最近的一些模型，包括通用计数模型和大型视觉-语言模型（VLMs），已经在计数任务上表现出前景，但它们在执行细微的、意图驱动的计数方面的能力仍然不清楚。当前模型在细粒度和视觉上具有模糊性的情况下，是否能够可靠地执行这一任务仍不确定。为了评估这种能力，研究人员开发了一个名为PairTally的新基准数据集，包括多种场景，模型需要从形状、大小、颜色或语义的细微差异中区分行两种物体类别。", "innovation": "PairTally是一个专门为评估细粒度视觉计数能力而设计的基准数据集。它包括两类场景：跨类别（不同类别）和同类别（紧密相关的子类别），这使得它适合严格评估选择性计数能力。研究人员还对多种最先进的模型进行了基准测试，包括基于实例的方法、语言提示模型和大型VLMs。结果显示，尽管最近取得了一些进展，当前的模型仍然难以可靠地执行用户所期望的计数任务，特别是在细粒度和视觉上具有模棱两可的情况下。", "conclusion": "PairTally提供了一个新的基础，可以用于诊断和改善细粒度视觉计数系统。尽管当前模型在细粒度和视觉模糊的情况下的计数能力仍有待提高，但它为研究人员提供了一个新工具来评估和比较不同模型的性能。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14033", "html_url": "https://arxiv.org/abs/2509.14033", "title": "SAIL-VL2技术报告", "title_en": "SAIL-VL2 Technical Report", "authors": "Weijie Yin,Yongjie Ye,Fangxun Shu,Yue Liao,Zijian Kang,Hongyuan Dong,Haiyang Yu,Dingkang Yang,Jiacong Wang,Han Wang,Wenzhuo Liu,Xiao Liang,Shuicheng Yan,Chao Feng", "background": "SAIL-VL2是一个开放的多模态视觉语言基础模型（LVM），用于全面的多模态理解和推理。它是在SAIL-VL的基础上开发的，在2亿和8亿参数规模下，在多种图像和视频基准测试中的表现达到了最先进的水平，展示了从细微感知到复杂推理的强大能力。", "innovation": "三大核心创新推动了SAIL-VL2的效果。首先，大规模的数据管理和评分筛选策略提高了数据质量与分布，增强了训练效率。其次，逐步训练框架开始于强大的预训练视觉编码器（SAIL-ViT），通过多模态预训练，最终形成了系统加强模型能力的思考融合SFT-RL混合范式。第三，架构上的突破不仅限于密集的LLM设计，还包括高效的稀疏混合专家（MoE）设计。", "conclusion": "SAIL-VL2在106个数据集上展示了具有竞争力的表现，并在挑战性的推理基准测试（如MMMU和MathVista）中达到了最先进的效果。在OpenCompass排行榜上，SAIL-VL2-2B在4亿参数规模下作为第一个官方发布的开源模型，并为开源多模态社区提供了一个高效且可扩展的基础。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14120", "html_url": "https://arxiv.org/abs/2509.14120", "title": "欺骗性 beauty：评估美容滤镜对虚拟脸孔和变形攻击检测的影响", "title_en": "Deceptive Beauty: Evaluating the Impact of Beauty Filters on Deepfake and Morphing Attack Detection", "authors": "Sara Concas,Simone Maurizio La Cava,Andrea Panzino,Ester Masala,Giulia Orrù,Gian Luca Marcialis", "background": "数字美容通过社交媒体滤镜越来越流行，引发了对面部图像和视频可靠性的担忧以及自动面部分析效果的担忧。这个问题特别关键，尤其是对于虚拟脸孔和变形攻击检测器，这些系统旨在区分真实与篡改的数据，特别是在涉及旨在欺骗人类和自动面部识别的人工智能生成的虚假信息和变形攻击时。", "innovation": "本研究探讨了美容滤镜是否影响虚拟脸孔和变形攻击检测器的性能。进行了全面分析，评估了多种最新的检测器在基准数据集上和应用各种平滑滤镜前后的效果。", "conclusion": "研究发现性能下降，揭示了面部增强带来的脆弱性，并强调需要抵抗此类修改的 robust 检测模型。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14149", "html_url": "https://arxiv.org/abs/2509.14149", "title": "关于抽象图像及其学习到的视觉表征的探索性研究", "title_en": "An Exploratory Study on Abstract Images and Visual Representations Learned from Them", "authors": "Haotian Li,Jianbo Jiao", "background": "最近的研究表明，由基本形状构成的抽象图像能够向深度学习模型传达视觉语义信息。然而，这些抽象图像获取的表示通常不如传统栅格图像获取的表示效果好。这项研究旨在探讨这种性能差距的原因，并研究不同抽象级别下可提取的高层语义内容程度。为此，引入了一个名为Hierarchical Abstraction Image Dataset (HAID)的新数据集，该数据集包含从多个抽象级别生成的普通栅格图像的抽象图像。然后，这些基准视觉系统在包括分类、分割和对象检测在内的各种任务上被训练和评估，以全面研究栅格化和抽象图像表示之间的差异。", "innovation": "提出了Hierarchical Abstraction Image Dataset (HAID)新数据集，该数据集包含从多个抽象级别生成的普通栅格图像的抽象图像。通过在包括分类、分割和对象检测在内的多种任务上训练和评估常用的视觉系统，对栅格化和抽象图像表示进行了全面研究，探讨了抽象图像在视觉语义信息传达和视觉任务中的潜在有效性。", "conclusion": "研究揭示了抽象图像与传统栅格图像在高阶语义信息提取方面的差异，并表明抽象图像可能是一种有效的视觉语义信息传达格式，有助于视觉任务。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14104", "html_url": "https://arxiv.org/abs/2509.14104", "title": "CSMoE: 含有软门控混合专家的高效遥感基础模型", "title_en": "CSMoE: An Efficient Remote Sensing Foundation Model with Soft Mixture-of-Experts", "authors": "Leonard Hackel,Tom Burgert,Begüm Demir", "background": "自监督学习通过掩码自动编码器在遥感（RS）基础模型（FM）的发展中引起了极大的关注，这使得跨多元感应器和下游任务的表示学习能够得到改进。然而，现有的RS FMs通常在训练和推理阶段具有显著的计算复杂性，或者表现出有限的表示能力。这些问题限制了它们在RS中的实际应用。", "innovation": "本文提出了一种通过将软门控专家混合机制（Soft mixture-of-experts, MoE）整合到FM中来增强RS FMs效率的方法。这种整合允许专家在模态特定的专业化的同时进行跨传感器的共享表示学习。此外，引入了一种以主题-气候描述符为基础的采样策略来构建代表性多样化的训练集，以训练CSMoE模型。实验结果表明，与现有的最优RS FMs相比，CSMoE在保持或提高表示性能的同时，计算需求减少了，且在场景分类、语义分割和内容检索等任务上实现了更高的效率和性能。CSMoE平均计算效率提高了两倍以上，且在所有实验中都能保持竞争力。", "conclusion": "所提出的方法有效地创建了具有计算效率的RS FMs，并展示了CSMoE在遥感领域的应用潜力。相关代码、训练集构建及模型权重等资源将在此链接中提供。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14165", "html_url": "https://arxiv.org/abs/2509.14165", "title": "高分辨率下STEP的剪枝行为理解：tokens的去向", "title_en": "Where Do Tokens Go? Understanding Pruning Behaviors in STEP at High Resolutions", "authors": "Michal Szczepanski,Martyna Poreba,Karim Haroun", "background": "视觉转换器（ViTs）在语义分割任务上取得了卓越的性能，但它们面临高计算和内存成本的问题。为了应对这一挑战，作者提出了STEP（SuperToken and Early-Pruning）框架，该框架结合了动态块聚合和标记剪枝，以提高效率而不显著降低准确性。", "innovation": "STEP框架的核心是dCTS（Dynamic Convolution-based Token Supervision），这是一种轻量级的基于CNN的策略网络，能够灵活地合并成超级块。编码块还集成早期退出机制，用于移除高置信度的超级标记，从而降低计算负载。通过评估该方法在高分辨率语义分割基准上的性能，结果表明，当单独应用dCTS时，标记数量可以减少2.5倍，与标准16x16像素块方案相比，计算成本减少了2.6倍，吞吐量增加了3.4倍，使用ViT-Large作为主干时。应用完整的STEP框架可进一步提高效率，计算复杂性最多减少4倍，推理速度提高1.7倍，准确度下降不超过2.0%。提出的STEP配置可以在最终编码层之前自信地预测并停止多达40%的标记。", "conclusion": "该研究展示了STEP框架能够在保持较高准确性的同时显著降低计算成本和提高计算效率，特别是在高分辨率图像分割任务中表现出色。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14142", "html_url": "https://arxiv.org/abs/2509.14142", "title": "MARS2 2025挑战赛：多模态推理的数据集、方法、结果、讨论与展望", "title_en": "MARS2 2025 Challenge on Multimodal Reasoning: Datasets, Methods, Results, Discussion, and Outlook", "authors": "Peng Xu,Shengwu Xiong,Jiajun Zhang,Yaxiong Chen,Bowen Zhou,Chen Change Loy,David A. Clifton,Kyoung Mu Lee,Luc Van Gool,Ruiming He,Ruilin Yao,Xinwei Long,Jirui Huang,Kai Tian,Sa Yang,Yihua Shao,Jin Feng,Yue Zhong,Jiakai Zhou,Cheng Tang,Tianyu Zou,Yifang Zhang,Junming Liang,Guoyou Li,Zhaoxiang Wang,Qiang Zhou,Yichen Zhao,Shili Xiong,Hyeongjin Nam,Jaerin Lee,Jaeyoung Chung,JoonKyu Park,Junghun Oh,Kanggeon Lee,Wooseok Lee,Juneyoung Ro,Turghun Osman,Can Hu,Chaoyang Liao,Cheng Chen,Chengcheng Han,Chenhao Qiu,Chong Peng,Cong Xu,Dailin Li,Feiyu Wang,Feng Gao,Guibo Zhu,Guopeng Tang,Haibo Lu,Han Fang,Han Qi,Hanxiao Wu,Haobo Cheng,Hongbo Sun,Hongyao Chen,Huayong Hu,Hui Li,Jiaheng Ma,Jiang Yu,Jianing Wang,Jie Yang,Jing He,Jinglin Zhou,Jingxuan Li,Josef Kittler,Lihao Zheng,Linnan Zhao,Mengxi Jia,Muyang Yan,Nguyen Thanh Thien,Pu Luo,Qi Li,Shien Song,Shijie Dong,Shuai Shao,Shutao Li,Taofeng Xue,Tianyang Xu,Tianyi Gao,Tingting Li,Wei Zhang,Weiyang Su,Xiaodong Dong,Xiao-Jun Wu,Xiaopeng Zhou,Xin Chen,Xin Wei,Xinyi You,Xudong Kang,Xujie Zhou,Xusheng Liu,Yanan Wang,Yanbin Huang,Yang Liu,Yang Yang,Yanglin Deng,Yashu Kang,Ye Yuan,Yi Wen", "background": "这篇论文回顾了2025年MARS2多模态推理挑战赛。研究旨在通过一个大规模基准将不同领域的多模态机器学习方法和LLMs整合在一起，以便更好地让研究人员追踪这一快速发展的领域。多项测试平台的兴起推动了一般用途大语言模型的发展，因此MARS2今年的重点是针对真实世界和专业场景，以扩展多模态推理在MLLM中的应用。竞赛团队发布了两个定制数据集Lens和AdsQA作为测试集，分别支持日常生活12个场景的一般推理和广告视频中的领域特定推理。40多个基线包括通用和任务特定的模型，设置了三个竞赛赛道：真实世界场景中的视觉定位（VG-RS）、具有空间感知的视觉问答（VQA-SA）和创意广告视频中的视觉推理（VR-Ads）。", "innovation": "本研究创新之处在于通过举办MARS2 2025挑战赛，搭建了一个大规模多模态推理测试平台，整合了多种多模态机器学习方法和LLMs，展示了在真实世界和专业场景中的应用效果，并设立了多个赛道鼓励不同模型的参与。同时，实验数据集、代码集和排名等多个资源均对外公开，形成了一个持续更新的平台，以促进研究交流与进步。", "conclusion": "最终，来自著名学术和工业机构的76支队伍报名参赛，共收到40多份有效提交（总计1200+份）。竞赛的Dataset、Codebase（包括40多个基线和15多个参赛选手的方法）以及排名列表均在MARS2研讨会网站和我们的GitHub组织页面公开。未来将继续提供更新和即将举行的活动通知。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14119", "html_url": "https://arxiv.org/abs/2509.14119", "title": "用于加速组织病理学工作流程的抗错位生成式AI虚拟染色", "title_en": "Generative AI for Misalignment-Resistant Virtual Staining to Accelerate Histopathology Workflows", "authors": "Jiabo MA,Wenqiang Li,Jinbang Li,Ziyi Liu,Linshan Wu,Fengtao Zhou,Li Liang,Ronald Cheong Kin Chan,Terence T.W. Wong,Hao Chen", "background": "传统的组织病理学诊断需要多张不同染色的组织切片，这一过程耗时、劳力密集且对环境有负面影响。最近，虚拟染色作为一种替代方案出现了，它更快、节省组织样本且环保。然而，现有的虚拟染色方法在临床应用中面临挑战，主要原因是它们依赖于数据配准，而配准良好的配对数据很难获得。由于化学染色过程可能扭曲组织结构，同一张组织切片无法承受多次染色而不会受损或丢失信息，大多数可用的虚拟染色数据集要么是配对的，要么是粗略配对，这使得现有方法难以实现像素级别的准确监督。", "innovation": "该研究提出了一种增强型虚拟染色框架，包含级联注册机制以解决生成输出与其对应真实值之间的空间不匹配问题。实验结果显示，该方法在五个数据集上显著优于最先进的模型，内部数据集平均改进率为3.2%，外部数据集为10.1%。在存在显著错位的 dataset 中，该方法实现了23.8%的峰值信噪比改进。该研究方法的出色鲁棒性简化了虚拟染色数据获取过程，并为该技术的发展提供了新的见解。", "conclusion": "该抗错位生成式AI虚拟染色方法通过级联注册机制有效地解决了虚拟染色过程中的空间不匹配问题，显著提高了虚拟染色的准确性和鲁棒性，简化了数据获取过程，并增强了虚拟染色技术在组织病理学工作流程中的应用潜力。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14227", "html_url": "https://arxiv.org/abs/2509.14227", "title": "Cinéaste: 细粒度情境电影问答基准", "title_en": "Cinéaste: A Fine-grained Contextual Movie Question Answering Benchmark", "authors": "Nisarg A. Shah,Amir Ziai,Chaitanya Ekanadham,Vishal M. Patel", "background": "尽管近期在视觉语言模型方面的进展改善了视频的理解能力，但诊断这些模型对于深刻的情境叙事理解的能力仍然是一个挑战。现有的基准测试通常侧重于短片段的识别或使用模板化的问题，这在评估长文本叙事内容的细腻推理方面留下了关键的空白。为了填补这些空白，我们提出了Cinéaste，一个全面的长篇电影理解基准。该数据集包括源自200部不同电影的1805个场景的3119个选择题答案对，涵盖五个新颖的情境推理类别。使用GPT-4o生成情境丰富的多样化问题，这些问题需要深谙叙事理解。为了确保高质量评估，我们的管道采用了两阶段筛选过程：上下文独立性筛选确保问题需要视频上下文，而上下文真实性筛选则验证事实一致性，防止幻觉的产生。实验证明现有的多模态语言模型在Cinéaste上表现不佳；我们的分析揭示远程时间推理是主要瓶颈，顶尖开源模型仅获得63.15%的准确率。这突显了细腻情境理解的挑战以及对长篇电影理解的迫切需求改善", "innovation": "我们提出了Cinéaste，一个专注于长篇电影理解的全面基准。该基准包括了3,119个选择题答案对，源自1805个场景，涉及200部电影，覆盖了五个新颖的情境推理类别。我们的数据集通过GPT-4o生成多样化上下文丰富的问答，确保问题需要深层次的情境理解。我们的流程使用了两阶段筛选流程，有效地避免了幻觉问题，确保了评估的高质量。实验结果表明现有模型在长篇电影理解方面存在巨大差距，主要瓶颈是远程时间推理能力不足。", "conclusion": "我们发现现有模型在长篇电影理解上的表现欠佳，特别是在远程时间推理能力上存在瓶颈。这证实了电影情节细腻理解的重要性，并强调了需要进一步研发来提高多模态模型在长篇电影理解上的能力和表现。Cinéaste为未来的视觉语言模型研究提供了一个重要的基准。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14151", "html_url": "https://arxiv.org/abs/2509.14151", "title": "BEVUDA++: 几何意识的无监督领域适应方法用于多视角3D物体检测", "title_en": "BEVUDA++: Geometric-aware Unsupervised Domain Adaptation for Multi-View 3D Object Detection", "authors": "Rongyu Zhang,Jiaming Liu,Xiaoqi Li,Xiaowei Chi,Dan Wang,Li Du,Yuan Du,Shanghang Zhang", "background": "鸟瞰视图（BEV）感知在自动驾驶中展现了巨大潜力，但现有研究多集中在效率或准确性的提升上而忽视了领域偏移问题，导致跨域迁移后性能大幅下降。我们识别了真实世界多域场景下的重大领域差距，并首次针对BEV感知下的多视角3D物体检测进行领域适应（DA）挑战。由于BEV感知方法中多个组件的存在，多几何空间（如2D、3D体素、BEV）中的领域偏移累积构成了极大的挑战。", "innovation": "我们提出了一个几何意识的教师-学生框架BEVUDA++来解决这一问题，该框架包括一个可靠的深度教师（RDT）和一个几何一致的学生（GCS）模型。RDT通过结合目标LiDAR和可信的深度预测，基于不确定性估计生成深度感知信息，增强Voxel和BEV特征的提取，这些特征对理解和目标域至关重要。GCS则将多空间的特征映射到统一的几何嵌入空间，缩小两个域间的数据分布差距。此外，我们引入了一种新颖的不确定性导向指数移动平均（UEMA），进一步减少了由已知不确定指导引起的领域偏移误差积累。我们通过四个跨域场景的全面实验，展示了该方法在BEV 3D物体检测任务中取得的优越性能，例如在Day-Night适应场景中NDS和mAP分别提升了12.9%和9.5%。", "conclusion": "我们提出的方法在多视角3D物体检测的BEV感知中实现了显著的性能提升，首次有效解决了多视角3D物体检测的领域适应问题。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14199", "html_url": "https://arxiv.org/abs/2509.14199", "title": "使用门控残差标记的密集视频理解", "title_en": "Dense Video Understanding with Gated Residual Tokenization", "authors": "Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu", "background": "高时间分辨率对于视频理解中捕捉细粒度细节至关重要，但现有的视频大型语言模型（VLLMs）和基准测试主要依赖于低帧率采样，如均匀采样或关键帧选择，舍弃了密集时间信息以避免将每帧都划分为标记所带来的高成本，这会导致冗余计算和随着视频长度增加而线性增长的标记数目。这种权衡在缓慢变化的内容中可以工作，但对于像报告讲解这样的任务无效，因为它要求近乎每一帧都精确的时间对齐。", "innovation": "我们提出了密集视频理解（DVU），通过减少标记化时间和标记开销，实现了高帧率视频的理解。我们还提出了DIVE（密集信息视频评估），第一个专注于密集时间推理的基准测试。为了使DVU实际应用，我们提出了门控残差标记化（GRT），这是一个两阶段框架，包括通过像素级运动估计跳过静态区域实现亚线性计算增长的运动补偿区间门控标记化，以及在场景内的静态区域跨融合标记，进一步减少冗余并保留动态语义。", "conclusion": "在DIVE基准上的实验表明，GRT优于较大的VLLM基准模型，并随着帧率的提高而呈现正向扩展。这些结果强调了密集时间信息的重要性，并证明了GRT能够实现高效且可扩展的高帧率视频理解。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14232", "html_url": "https://arxiv.org/abs/2509.14232", "title": "GenExam: 多学科的图文考试", "title_en": "GenExam: A Multidisciplinary Text-to-Image Exam", "authors": "Zhaokai Wang,Penghao Yin,Xiangyu Zhao,Changyao Tian,Yu Qiao,Wenhai Wang,Jifeng Dai,Gen Luo", "background": "现有的考试样式的基准主要聚焦于理解和推理任务，而现有的生成基准则强调展示世界知识和视觉概念，忽视了严谨绘图考试的评估。考试是专家级智能的基本测试，要求综合理解、推理和生成能力。", "innovation": "GenExam 是首个多学科文本到图像考试基准，包含了10个学科的1000个样本，并且每一个问题都配有参考图像和精细的评分点，以便精准评估语义正确性和视觉真实性。研究表明，即使是最先进的模型如GPT-Image-1和Gemini-2.5-Flash-Image在严格的评分标准下也只能达到不到15%的得分，并且大多数模型得分为0%，表明了基准的挑战性。这是通过将图像生成问题形式化为其考试来实现的，GenExam 提供了评估模型综合知识、推理和生成能力的严格评估框架，为实现通用强人工智能提供了借鉴意义。", "conclusion": "GenExam 提供了一种严格的评估模型能力的框架，帮助理解模型在多学科领域中的综合知识、推理和生成能力的综合表现，为后续研究指明了方向。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14051", "html_url": "https://arxiv.org/abs/2509.14051", "title": "PROFUSEme: 通过融合多模态嵌入进行前列腺癌生物化学复发预测", "title_en": "PROFUSEme: PROstate Cancer Biochemical Recurrence Prediction via FUSEd Multi-modal Embeddings", "authors": "Suhang You,Carla Pitarch-Abaigar,Sanket Kachole,Sumedh Sonawane,Juhyung Ha,Anish Sudarshan Gada,David Crandall,Rakesh Shiradkar,Spyridon Bakas", "background": "大约29%接受根治性前列腺切除术(RP)的前列腺癌(PCa)患者会经历生物化学复发(BCR)，表现为前列腺特异性抗原(PSA)增加，并与更高的死亡率相关。准确地在RP时预测BCR有助于及时适应临床决策和改善患者预后。", "innovation": "本文提出了前列腺癌BCR预测方法PROFUSEme，该方法通过在临床、放射学和病理数据之间学习跨模态交互作用，并结合Cox比例风险回归器，采用中间融合配置。这种方法的定量评估显示了优于晚融合配置的性能，在内部5折嵌套交叉验证框架上得到的平均C指数为0.861 (σ=0.112)，在CHIMERA 2025挑战验证排行榜上未保留数据上的C指数为0.7103。", "conclusion": "PROFUSEme通过融合多模态嵌入来预测前列腺癌的生物化学复发，展示了在前列腺癌患者术后预测其是否发生BCR方面的优越性能，对于临床决策和改善患者预后有积极的贡献。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13756", "html_url": "https://arxiv.org/abs/2509.13756", "title": "通过颜色映射在扩散模型中实现可控连续的颜色编辑", "title_en": "Controllable-Continuous Color Editing in Diffusion Model via Color Mapping", "authors": "Yuqi Yang,Dongliang Chang,Yuanchen Fang,Yi-Zhe SonG,Zhanyu Ma,Jun Guo", "background": "近年来，文本驱动的图像编辑取得了显著进展。然而，由于自然语言的固有模糊性和离散性，颜色编辑仍面临精确度不足和难以实现连续控制等挑战。虽然可以通过线性插值不同文本描述的嵌入向量来指导模型生成颜色逐渐变化的一系列图像，但这种方法缺乏对输出图像颜色变化范围的精确控制。此外，插值系数与最终图像颜色之间的关系未知且不可控。", "innovation": "引入了一个颜色映射模块，明确建模了文本嵌入空间与图像RGB值之间的对应关系。该模块基于给定的RGB值预测相应的嵌入向量，从而在保持语义一致性的前提下实现对生成图像的精确颜色控制。用户可以指定目标RGB范围，以生成在所需范围内具有连续颜色变化的图像，从而实现更精微的、连续的、可控制的颜色编辑。", "conclusion": "实验结果表明，我们的方法在颜色连续性和可控性方面表现良好。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13358", "html_url": "https://arxiv.org/abs/2509.13358", "title": "使用几何方法从双平面X射线图像重建冠状动脉树", "title_en": "3D Reconstruction of Coronary Vessel Trees from Biplanar X-Ray Images Using a Geometric Approach", "authors": "Ethan Koland,Lin Xi,Nadeev Wijesuriya,YingLiang Ma", "background": "X射线血管造影广泛应用于心脏介入手术中，用于可视化冠状动脉、评估完整性和检测狭窄，同时指导治疗。当前，重建冠状动脉三维树的技术通常依赖于两组不同角度拍摄的X射线视频，并通过图像分割、运动相位匹配和三维重建三个关键步骤实现。此过程中，现有方法多依赖于传统的方法，比如基于极线约束的重建，但这些方法可能导致工作流程复杂及精确度较低的问题。", "innovation": "本文提出了一种新颖的框架，用于从双平面X射线图像中重建冠状动脉的三维树。该框架主要通过自动视频分割方法使图像分割和运动相位匹配自动化，通过跟踪X射线视频中的静止目标（例如导管或电极）来实现运动相位匹配，并通过一种新颖的几何重建算法生成三维血管树。相比传统方法，该方法简化了重建工作流程，提升了整体精确度。在实验中，分割方法在62段X射线血管造影视频序列上的准确率为0.703，三维重建框架在关键解剖标志点的重建误差为0.62±0.38毫米。", "conclusion": "本文提出的方法通过改进图像分割、运动相位匹配和三维重建过程，为冠状动脉三维树的高效和准确重建提供了一个新的解决方案，相较于传统方法具有更简化的流程和更高的精确度。该方法在实验中取得了较好的结果，有望在心脏介入手术中推广应用。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13428", "html_url": "https://arxiv.org/abs/2509.13428", "title": "英国的人工智能自主报告正常胸部X光片：我们能让人工干预变为多余吗？", "title_en": "Autonomous Reporting of Normal Chest X-rays by Artificial Intelligence in the United Kingdom. Can We Take the Human Out of the Loop?", "authors": "Katrina Nash,James Vaz,Ahmed Maiter,Christopher Johns,Nicholas Woznitza,Aditya Kale,Abdala Espinosa Morgado,Rhidian Bramley,Mark Hall,David Lowe,Alex Novak,Sarim Ather", "background": "胸部X光片（CXR）是最常进行的影像检查之一。在英国，许多中心由于放射科医生人手不足而经历了报告延迟的问题。人工智能（AI）工具能够区分正常和异常的CXR，可能成为解决方案。若能安全地识别并报告正常CXR，无需人类干预，放射科的工作量将大幅减少。文章探讨了自主AI报告正常CXR的可行性和潜在影响，涉及正常定义、跨群体的一致性、敏感性和特异性的权衡，以及法律和监管挑战，如遵守IR(ME)RA与GDPR，缺乏对错误的问责制框架。还考虑了对放射科医生实践的影响，需要在市场后期进行严密监控，并纳入患者视角.", "innovation": "提出了利用AI自主报告正常CXR的概念，旨在通过减少人工干预来减轻放射科医生的负担，解决人手不足的问题。文章探讨了该技术面临的实际挑战和潜在影响，为未来发展提供了理论框架和可行路径.", "conclusion": "虽然自主AI报告正常CXR带来了诸多潜在好处，但其应用需谨慎。还需要进一步研究来确保技术的有效性和安全性，同时应建立相应的监管框架和问责机制，确保技术的健康发展，同时考虑到对放射科医生和患者的影响。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13379", "html_url": "https://arxiv.org/abs/2509.13379", "title": "以可能的方式说话：VLMs中不确定性基准测试的形尔诺视角", "title_en": "The Art of Saying \"Maybe\": A Conformal Lens for Uncertainty Benchmarking in VLMs", "authors": "Asif Azad,Mohammad Sadat Hossain,MD Sadik Hossain Shanto,M Saifur Rahman,Md Rizwan Pervez", "background": "视觉-语言模型（VLMs）在复杂的视觉理解、科学和推理任务中取得了显著进展。尽管绩效基准测试提高了我们对这些能力的理解，但不确定性量化这一关键维度却很少受到关注。本研究从这一角度出发，对16个最先进的VLMs在6个多模态数据集中的不确定性进行了全面基准测试，使用了3种不同的评分函数。研究表明，较大的模型通常表现出更好的不确定性量化能力；知道得多的模型也知道自己不知道什么。更加确定的模型具有更高的准确性，而数学和推理任务在所有模型中表现最差，相较于其他领域，不确定性表现不佳。这项工作为多模态系统的可靠不确定性评估奠定了基础。", "innovation": "本研究开展了一项全面的不确定性基准测试，评估了16个最先进的VLMs，涵盖了6个多模态数据集和3种不同的评分函数。不同于之前的局限于特定场景的研究，本研究更加全面，包括了开源和闭源模型。此外，研究还发现了模型规模与不确定性量化之间的关系，并分析了不同任务类型下模型的不确定性表现。这项工作填补了在VLMs中不确定性评估领域的一项空白。", "conclusion": "研究结果证明，更大的模型通常具有更好的不确定性量化能力；知道得多的模型也知道自己不知道什么。更确定的模型具有更高的准确性，但数学和推理任务的不确定性表现相对较差。这项工作为多模态系统的可靠性评估奠定了基础。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13360", "html_url": "https://arxiv.org/abs/2509.13360", "title": "PREDICT-GBM: 平台用于渐变性脑胶质瘤个体化计算肿瘤模型的稳健评估与发展", "title_en": "PREDICT-GBM: Platform for Robust Evaluation and Development of Individualized Computational Tumor Models in Glioblastoma", "authors": "L. Zimmer,J. Weidner,M. Balcerak,F. Kofler,I. Ezhov,B. Menze,B. Wiestler", "background": "渐变性脑胶质瘤是最常见的原发性脑恶性肿瘤，特征为高度侵袭性和极高的复发率。传统的放疗采用均匀的治疗边界，未能考虑到影响肿瘤细胞迁移的患者特定的解剖和生物学因素。尽管已经开发了多种渐变性脑胶质瘤生长的计算模型，可以生成辐射影像之外的肿瘤细胞分布图，从而指导更精确的治疗策略，但这些模型的临床应用仍面临限制。因此，需要一个综合的平台来加速模型开发和临床验证的进程，以缩小理论与临床实践之间的差距。", "innovation": "该论文引入了一个全面集成的平台和数据集PREDICT-GBM，用于建模和评估。该平台依托一个包含255个完整肿瘤分割和组织表征图的医学专家整理的临床数据集，对最先进的肿瘤生长模型进行了系统基准测试。分析表明，基于肿瘤生长预测的个性化放疗计划相比传统的均匀边界方法，在两种被评估的模型中都实现了更好的复发覆盖率。这为推动先进的肿瘤生长建模方法的发展和系统评估，以及促进临床转化和提高患者预后打下了坚实的基础。", "conclusion": "这项工作建立了一个强大的平台，用于推进和系统评估最先进的肿瘤生长建模方法，最终目标是促进临床转化，并改善患者的治疗结果。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13541", "html_url": "https://arxiv.org/abs/2509.13541", "title": "基于SLAM的语义3D重建在中央气道阻塞中的应用", "title_en": "Semantic 3D Reconstructions with SLAM for Central Airway Obstruction", "authors": "Ayberk Acar,Fangjie Li,Hao Li,Lidia Al-Zogbi,Kanyifeechukwu Jane Oguine,Susheela Sharma Stern,Jesse F. d'Almeida,Robert J. Webster III,Ipek Oguz,Jie Ying Wu", "background": "中央气道阻塞（CAO）是一种日益增多并具有致命威胁的状况，由气道内外的肿瘤引起。传统的治疗方法如支气管镜和电凝可以彻底移除肿瘤，但这些方法存在较高的并发症风险。最近的技术进步使得机器人干预可以减少这些风险。通过将机器人干预与场景理解和制图相结合，开启了自动化的可能性。目前，支气管镜中央气道的实时、语义导向的3D重建仍然无法实现。", "innovation": "本文提出了一种新颖的工作流程，能够使用单目内窥镜视频实时生成3D语义重建的中央气道。这项工作通过结合DROID-SLAM和训练好的分割模型，可以识别阻塞组织，并在实时重建中指导注释阻塞区域。通过将分割直接整合到SLAM的工作流中，该系统产生了注释的3D地图，实时突出显示临床相关区域。该方法具有高速能力，所有重建比以往工作更快，更准确地反映了手术现场。这是首次将语义分割与实时单目SLAM结合用于内窥镜中央气道阻塞场景的研究。", "conclusion": "到目前为止，这是首次将语义分割与实时单目SLAM结合应用于内窥镜中央气道阻塞场景的工作。我们的框架是模块化的，可以在其他解剖结构或程序中进行最小修改，为自働化机器人干预提供了有希望的一步。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13591", "html_url": "https://arxiv.org/abs/2509.13591", "title": "通过灵巧触觉进行物体姿态估计", "title_en": "Object Pose Estimation through Dexterous Touch", "authors": "Amir-Hossein Shahidzadeh,Jiyue Zhu,Kezhou Chen,Sha Yi,Cornelia Fermüller,Yiannis Aloimonos,Xiaolong Wang", "background": "在机器人领域，尤其是在视觉数据有限或受光照、遮挡、外观影响的场景中，鲁棒的物体姿态估计对于执行和交互任务至关重要。触觉传感器提供的信息有限且局部，从部分数据中重建姿态较为困难。本文在机器人手掌握物体稳定的同时，通过另一只手主动探索身体表面，利用强化学习收集触觉数据，逐步精化物体的形状和姿态。", "innovation": "通过传感器和运动探索，利用强化学习来主动控制机器人手对物体进行触觉探索和数据收集，用于逐步精化物体的形状和姿态。这种方法可以在没有物体几何形状先验知识的情况下识别物体关键姿态特征。", "conclusion": "展示了该方法能有效通过灵巧触觉探索物体表面，以识别关键姿态特征，同时提供了更多的实验证明和补充材料。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13390", "html_url": "https://arxiv.org/abs/2509.13390", "title": "一种基于领域知识的电动车辆内部声音异常检测方法", "title_en": "A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds", "authors": "Deepti Kunte,Bram Cornelis,Claudio Colangeli,Karl Janssens,Brecht Van Baelen,Konstantinos Gryllias", "background": "汽车车厢声音的异常检测对于确保车辆质量和保持乘客舒适度至关重要。在许多实际应用场景中，传统意义上的监督学习方法并不适用，因为缺乏标注的故障数据或完全不存在。在这种情况下，模型仅依赖健康样本训练，并通过检测偏离正常行为的数据来识别异常。然而，由于缺乏标注的故障样本进行验证，以及常用指标如重构错误的可靠性有限，有效的模型选择依然面临巨大挑战。为了克服这些限制，提出了一种基于领域知识的模型选择方法，通过结构化健康声谱的扰动构建代理异常，从而辅助模型选择。", "innovation": "提出了一种基于领域知识的模型选择方法，将通过结构化对健康声谱进行扰动产生的代理异常用于验证集，以支持模型选择。这种方法不同于传统的模型选择策略，因为它利用了未标注的代理异常而不是真正的故障样本进行验证。这种方法已在包含五种代表性故障类型的高质量电动汽车数据集上进行了实验评估，证明了使用代理异常选择最优模型的有效性，显著优于传统的模型选择策略。", "conclusion": "该研究使用一个包含健康和故障车厢声音的真实数据集来评估提出的模型选择方法，该数据集由高级声音合成技术生成，并得到专家评审团的验证，以确保数据集的真实性。结果表明，通过代理异常进行的模型选择在所有故障类型的实验中都比传统策略更优。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13372", "html_url": "https://arxiv.org/abs/2509.13372", "title": "从对比增强X射线造影成像中生成AI管道进行交互提示驱动的2D到3D血管重建用于Fontan几何", "title_en": "Generative AI Pipeline for Interactive Prompt-driven 2D-to-3D Vascular Reconstruction for Fontan Geometries from Contrast-Enhanced X-Ray Fluoroscopy Imaging", "authors": "Prahlad G Menon", "background": "传统的二维影像无法准确描述Fontan姑息手术后单心室先天性心脏病患者进展为血流动力学失败且具有复杂流动模式的情况。当前评估主要依赖透视造影成像，提供的3D几何信息有限，不足以支持计算流体动力学（CFD）分析和手术规划。", "innovation": "开发了一个多步骤AI管道，利用Google的Gemini 2.5 Flash（2.5B参数）通过基于转换器的神经架构系统地、迭代地处理透视造影图像，包括医学图像预处理、血管分割、对比增强、去噪以及2D投影的虚拟血流可视化。管道生成了几何优化的2D投影，并使用TI的Hunyuan3D-2mini（384M参数）生成立体光刻文件。该方法能够在不到15分钟的时间内完成处理，并提供了快速的虚拟血流可视化，为全CFD模拟前提供初步见解，从而表明从常规造影数据生成CFD适配几何体的临床可行性。", "conclusion": "该方法为使用现成的影像数据进行高级几何和血流动力学分析奠定了基础，尽管需要多次迭代以提高准确性，但仍体现了AI在临床中的应用价值。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/1901.11111", "html_url": "https://arxiv.org/abs/1901.11111", "title": "纹理感知超像素分割", "title_en": "Texture-Aware Superpixel Segmentation", "authors": "Remi Giraud,Vinh-Thong Ta,Nicolas Papadakis,Yannick Berthoumieu", "background": "大多数超像素算法在像素级别平衡空间和颜色特征之间存在权衡，这可能需要精细的参数调整来平衡两者，并且在分组具有相似局部纹理特征的像素方面效率低下。", "innovation": "本文提出了一种新的纹理感知超像素（TASP）方法，它可以自动根据局部特征变异调整其空间约束，以准确分割纹理和光滑区域。此外，提出了基于像素到超像素补丁的距离，以确保超像素内部的纹理同质性。", "conclusion": "TASP在纹理和自然彩色图像数据集上取得了优越的分割准确率，优于最先进的方法。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13926", "html_url": "https://arxiv.org/abs/2509.13926", "title": "MAP: 基于地图辅助的端到端自动驾驶", "title_en": "MAP: End-to-End Autonomous Driving with Map-Assisted Planning", "authors": "Huilin Yin,Yiming Kan,Daniel Watzenig", "background": "近年来，端到端自动驾驶因其能够在统一框架内联合建模感知、预测和规划而受到广泛关注。然而，现有的大多数方法在利用在线地图模块方面存在不足，未能充分利用其增强轨迹规划的潜力。", "innovation": "本文提出了MAP（Map-Assisted Planning），一种新的基于地图辅助的端到端轨迹规划框架。MAP通过引入Plan-enhancing Online Mapping模块、Ego-status-guided Planning模块以及基于当前ego状态的Weight Adapter，明确地整合了基于分割的地图特征和当前ego状态。实验结果表明，该方法在DAIR-V2X-seq-SPD数据集上实现了显著的性能提升，相较于UniV2X基线，在L2位移误差、离路率和总体评分上分别实现了16.6%、56.2% 和44.5%的降低，并且在MEIS Workshop @CVPR2025的端到端自动驾驶通过V2X合作挑战赛Track 2中取得了第一名，整体得分比第二名高39.5%。", "conclusion": "研究结果表明通过明确利用语义地图特征进行规划的有效性，并提出了改进端到端自动驾驶系统结构设计的新方向。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13612", "html_url": "https://arxiv.org/abs/2509.13612", "title": "Rest2Visual: 从静息态扫描预测视觉诱发fMRI", "title_en": "Rest2Visual: Predicting Visually Evoked fMRI from Resting-State Scans", "authors": "Chuyang Zhou,Ziao Ji,Daochang Liu,Dongang Wang,Chenyu Wang,Chang Xu", "background": "理解自发脑活动与刺激驱动神经反应之间的关系是认知神经科学中的一个基本挑战。基于任务的功能磁共振成像（fMRI）能够捕捉局部的刺激诱发脑激活，但是其获取方式代价高昂、耗时且难以大规模跨人群推广。相比之下，静息态fMRI（rs-fMRI）是非任务性且数据丰富，但缺乏直接解释性。为了克服这些限制，该研究引入了Rest2Visual，一种条件生成模型，能够根据静息态输入和2D视觉刺激预测视觉诱发fMRI（ve-fMRI）。", "innovation": "Rest2Visual利用空间适应归一化来模拟能量放大后的空间特异性激活。通过构建大规模三元组数据集，每个rs-fMRI体素被配对上刺激图像及其相应的ve-fMRI激活图，从而实现模型训练。该模型能够在标准相似性和表示性度量中预测激活与真实激活高度匹配，并支持下游解码中的图像重建。模型预测的激活图保留了个体特有的结构，证明了生成个体功能替代物的能力。", "conclusion": "研究结果为将个体自发神经活动转化为刺激对齐的表示提供了有力证据，打开了可扩展和非任务功能性脑建模的新途径。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13965", "html_url": "https://arxiv.org/abs/2509.13965", "title": "MetricNet：优化生成导航策略中的度量尺度", "title_en": "MetricNet: Recovering Metric Scale in Generative Navigation Policies", "authors": "Abhijeet Nayak,Débora N.P. Oliveira,Samiran Gode,Cordelia Schmid,Wolfram Burgard", "background": "生成型导航策略在改善端到端学习导航方面取得了快速进展。然而，即使在取得有希望的结果时，这个范式也存在两个结构问题：一是采样的路径存在于非度量、无尺度的抽象空间中；二是控制策略省略了完整路径，直接朝向单个兴趣点移动，这导致了目光短浅且不安全的行为，使机器人接近不应接近的障碍物。这些障碍本可以通过完整的路径来规避，而该完整的路径则能正确反映现实世界的坐标系统", "innovation": "我们提出了一种称为MetricNet的有效插件，可以预测路径点之间的度量距离，使策略输出基于现实世界的坐标。我们使用新的基准测试框架在仿真环境中评估了该方法，结果显示执行MetricNet缩放的路径点显著提高了导航和探索性能。此外，我们在现实世界的实验中进一步验证了该方法的有效性。最后，我们提出了MetricNav，它将MetricNet整合到导航策略中，以指导机器人避开障碍物但仍朝向目标移动", "conclusion": "我们提出了MetricNet和MetricNav，以解决生成型导航策略中的度量问题，它们能够指导机器人正确避开障碍物并安全地移动至目标位置"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/1903.07146", "html_url": "https://arxiv.org/abs/1903.07146", "title": "鲁棒的超像素评价的形状规则性标准", "title_en": "Robust Shape Regularity Criteria for Superpixel Evaluation", "authors": "Rémi Giraud,Vinh-Thong Ta,Nicolas Papadakis", "background": "目前大多数基于超像素的物体识别或跟踪应用中都需要规则分解，而超像素的形状规则性或紧凑性主要通过圆度来衡量。然而，此种衡量标准并不能直接表达规则性，而是体现在形状的圆形外观上，因此在超像素评估中并不合适。", "innovation": "提出了一个新的衡量标准，考虑了形状规则性的几个方面：凸性、分布平衡性和轮廓光滑性，并证明了这种衡量标准在尺度和噪声上有鲁棒性，并能够更有效地比较超像素方法。", "conclusion": "新的衡量标准能够更可靠地评估超像素的质量，并更好地支持物体识别或跟踪应用。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/1903.06010", "html_url": "https://arxiv.org/abs/1903.06010", "title": "基于超像素的颜色转移", "title_en": "Superpixel-based Color Transfer", "authors": "Rémi Giraud,Vinh-Thong Ta,Nicolas Papadakis", "background": "当前颜色转移方法存在处理速度慢和结果多样性不足的问题，需要一种快速且能有效增加颜色匹配多样性的方法来改进现有的图像处理效果", "innovation": "提出了一种基于超像素的快速颜色转移方法（SCT），通过使用快速近邻匹配算法和限制相同超像素的选择来增强颜色匹配的多样性，设计了融合框架来转移匹配的颜色，展示了与精确匹配结果相比的改进，并证明了SCT在视觉效果上与现有方法相竞争", "conclusion": "所提出的SCT方法在颜色转移速度和多样性上取得了显著改进，并且视觉效果上与最先进的方法相媲美"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.14191", "html_url": "https://arxiv.org/abs/2509.14191", "title": "MCGS-SLAM: 一种使用高精度定向光斑法的多摄像头SLAM框架", "title_en": "MCGS-SLAM: A Multi-Camera SLAM Framework Using Gaussian Splatting for High-Fidelity Mapping", "authors": "Zhihao Cao,Hanyu Wu,Li Wa Tang,Zizhou Luo,Zihan Zhu,Wei Zhang,Marc Pollefeys,Martin R. Oswald", "background": "最近关于密集SLAM的研究主要集中在单目设置上，这通常会牺牲鲁棒性和几何覆盖率。现有方法多依赖稀疏地图或惯性数据，导致性能受限。", "innovation": "本文提出了MCGS-SLAM，这是第一个基于3D Gaussian Splatting (3DGS)的纯RGB多摄像头SLAM系统。该系统通过多摄像头联合调整（MCBA）融合多个视角下的密集RGB输入，并使用低秩先验进行视图间的尺度一致性约束。", "conclusion": "实验结果表明，MCGS-SLAM能够提供准确的轨迹和照片级的重建，同时具有在大规模场景下保持实时性能的能力。尤其是多摄像头输入的广视角特性，能够让SLAM系统重建单目SLAM可能遗漏的侧视区域，这对于自动驾驶的安全运行至关重要。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13576", "html_url": "https://arxiv.org/abs/2509.13576", "title": "跨分布扩散先验驱动的迭代重建方法用于稀疏视图CT", "title_en": "Cross-Distribution Diffusion Priors-Driven Iterative Reconstruction for Sparse-View CT", "authors": "Haodong Li,Shuo Han,Haiyang Mao,Yu Shi,Changsheng Fang,Jianjia Zhang,Weiwen Wu,Hengyong Yu", "background": "稀疏视图CT（SVCT）能够提高时间分辨率并降低辐射剂量，然而由于视图减少和由于扫描仪、协议或解剖学变化导致的领域偏移，其临床应用受到图像伪影的阻碍，特别是在异构分布（OOD）场景中的性能下降是其主要问题。鉴于此，本文致力于解决SVCT中OOD问题，提出了一种跨分布扩散先验驱动的迭代重建（CDPIR）框架，将跨分布扩散先验与基于模型的迭代重建方法相结合，以提升SVCT的临床应用价值和适应能力。", "innovation": "本文通过引入跨分布扩散先验驱动的迭代重建（CDPIR）框架解决稀疏视图CT（SVCT）中的异构分布（OOD）问题。该框架利用了一个可伸缩插值变换器（SiT）的跨分布扩散先验，并结合分类器无条件指导（CFG）在多个数据集上进行训练。通过在训练中随机丢弃条件信息，模型学习到了既包含领域特定信息也包含领域不变信息的先验知识，提升了模型的泛化能力。在采样阶段，通过统一的随机插值框架和全局敏感的变压器扩散模型，CDPIR可以灵活稳定地控制多分布到噪声插值路径，减少了对特定领域依赖，即达到了良好的OOD适应性。CDPIR与现有方法相比，在SVCT重建中具有更高的鲁棒性和临床价值，特别在异构分布场景中的性能表现尤为突出。", "conclusion": "实验结果表明，CDPIR在稀疏视图CT的SVCT重建中表现出色，能够精准地保持SVCT图像细节，尤其在异构分布的情况下。该方法具有潜在的临床价值和广泛的适用性，在复杂医学成像场景中尤为适用。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2307.13756", "html_url": "https://arxiv.org/abs/2307.13756", "title": "PlaneRecTR++: 统一查询学习以联合进行3D平面重建和姿态估计", "title_en": "PlaneRecTR++: Unified Query Learning for Joint 3D Planar Reconstruction and Pose Estimation", "authors": "Jingjia Shi,Shuaifeng Zhi,Kai Xu", "background": "3D平面图像重构是一项具有挑战性的任务，包括帧内平面检测、分割、参数回归以及可能的深度预测等子任务。现有方法采用分而治之的策略，用不同的网络模块两阶段处理这些子任务。尽管取得了进展，但仍存在将这些紧密相关任务统一框架的问题，导致性能限制。", "innovation": "本文提出了一种基于Transformer的PlaneRecTR++架构，首次在一个紧凑的一阶段框架中统一了多视图平面重建和姿态估计的所有任务，消除了初始姿态估计和平面对应监督的需要。结果表明，统一学习方法在多个公开数据集上实现了更好的性能。", "conclusion": "与现有方法相比，统学习方法在多个公开数据集上取得了新的最佳性能。实验证明该方法在各个子任务上都能获益。代码已开源。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/1903.07149", "html_url": "https://arxiv.org/abs/1903.07149", "title": "SCALP: 基于线性路径的边界保持超像素", "title_en": "SCALP: Superpixels with Contour Adherence using Linear Path", "authors": "Rémi Giraud,Vinh-Thong Ta,Nicolas Papadakis", "background": "超像素分解方法通常用作图像处理任务的预处理步骤，可以提高处理速度。这些方法试图将图像像素分组为同质区域，同时保持现有轮廓。现有的超像素分解方法在计算时间、轮廓保持性和分解的规则性与紧凑性之间存在权衡。", "innovation": "提出了一种称为SCALP（Superpixels with Contour Adherence using Linear Path）的迭代聚类框架。它通过考虑像素到超像素质心的线性路径来增强聚类时的距离计算，从而生成规则、紧凑且保持图像轮廓的超像素。", "conclusion": "SCALP 方法在标准 Berkeley 分割数据集上的测试结果在超像素和轮廓检测指标方面优于现有最先进的方法。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.07243", "html_url": "https://arxiv.org/abs/2408.07243", "title": "基于感知评分的计算机视觉数据集修剪", "title_en": "Leveraging Perceptual Scores for Dataset Pruning in Computer Vision Tasks", "authors": "Raghavendra Singh", "background": "现有的图像分类和语义分割任务中使用的数据集评分大多计算复杂。作者提出了一种基于图像压缩比特数估计的熵值作为数据集修剪的评分标准，该评分标准简单且无需监督或训练，所有图像都以压缩格式存储，使得评分易于计算。使用这种评分可以提高学习效果并减少偏差。", "innovation": "提出了一种基于压缩图像比特数估计的熵值作为数据集修剪的评分标准，旨在捕捉图像的感知复杂性。通过选择高熵图像并结合图基方法增加所选样本的空间多样性，以缓解数据集修剪过程中的偏差问题。", "conclusion": "提出的简单评分方法在图像分类和语义分割任务中表现出良好的效果，尤其是在语义分割任务中。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13642", "html_url": "https://arxiv.org/abs/2509.13642", "title": "LLM-I: LLMs are Naturally Interleaved Multimodal Creators", "title_en": "LLM-I: LLMs are Naturally Interleaved Multimodal Creators", "authors": "Zirun Guo,Feng Zhang,Kai Jia,Tao Jin", "background": "当前的统一模型受到单一工具瓶颈的限制，只能生成合成图像，难以处理需要事实依据或程序化精确度的任务。现有的模型面临挑战，例如无法有效应对复杂且需要严格操作的任务，尤其是在图像和文本生成方面需要多样化工具支持和精确控制的场景下。", "innovation": "LLM-Interleaved (LLM-I) 构建了一个灵活和动态的框架，将交错的图像-文本生成重新定义为工具使用问题。该框架设计了一个中央LLM或MLLM代理，它可以智能地协调多种专门的视觉工具，包括在线图像搜索、基于扩散的生成、代码执行和图像编辑。代理通过结合规则逻辑和LLM、MLLM评估者的判断的混合奖励系统进行强化学习训练，从而能够高效地选择和应用各种工具。该框架通过一个多样化的新型数据集进行训练，并在四个不同的模型骨干网络上进行训练，展示了在四个基准测试上的最先进的性能，并且在多个指标上显著优于现有方法。此外，还提出了一个新的测试时间扩展策略，进一步提高性能。", "conclusion": "LLM-I 验证了一个新的观点，即大语言模型可以被自然地多重交织地用于创建多样化的多媒体内容。通过这种方式，LLM-I 不仅解决了单一工具瓶颈的问题，还提高了生成图像-文本内容的能力，尤其是在需要多工具协调的复杂任务情况下。最终，LLM-I 的性能远远超过了现有的方法，并且展示了在实际应用中的巨大潜力。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13857", "html_url": "https://arxiv.org/abs/2509.13857", "title": "InterKey: OpenStreetMap上的跨模态交叉关键点全局定位", "title_en": "InterKey: Cross-modal Intersection Keypoints for Global Localization on OpenStreetMap", "authors": "Nguyen Hoang Khoi Tran,Julie Stephany Berrio,Mao Shan,Stewart Worrall", "background": "可靠的全球定位对于自动驾驶车辆至关重要，特别是在GNSS信号被遮挡或不可用的环境中，如城市峡谷和隧道里。尽管高定义地图能提供准确的先验信息，但由于数据采集、地图构建和维护成本的限制，其可扩展性受到限制。OpenStreetMap提供了免费且全球可用的替代方案，但由于其粗糙的抽象化，匹配传感器数据时存在挑战。因此，本文提出了一种基于道路交叉口特征的跨模态框架，即InterKey，用于解决这个问题。该框架通过联合编码点云和OpenStreetMap中的道路及建筑印记来构建紧凑的二进制描述符，使用识别地标和匹配策略，确保在不通传感器环境下的鲁棒匹配。实验结果表明，InterKey在KITTI数据集上的准确度达到了最先进的水平，显著优于最近的基线方法。该框架适用于生成密集结构性点云的传感器，提供了一种成本效益高的解决方案，增强了车辆的全局定位能力。", "innovation": "该论文提出了一种名为InterKey的跨模态框架，利用道路交叉口作为独特的地标进行全球定位。该方法通过联合编码点云和OpenStreetMap中的道路及建筑印记来构建紧凑的二进制描述符，引入了冲突缓解、方向确定和区域等化采样策略，以桥接模态间的差异。实验结果表明，该方法在KITTI数据集上的准确度达到了最先进的水平，显著优于最近的基线方法，并且适用于各种传感器类型，提供了一种可扩展且经济高效的解决方案用于增强车辆的全局定位能力。", "conclusion": "本文提出的InterKey框架在高精度全球定位方面取得了重大突破，特别是在使用OpenStreetMap作为地图资源的场景中具有显著优势。通过结合道路交叉口这一自然地标，InterKey能够在不同的传感器环境下实现鲁棒的定位，特别是在GNSS信号不可用的环境中。其性价比高，并且具有广泛的应用前景，对未来自动驾驶技术的发展有积极的推动作用。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.06607", "html_url": "https://arxiv.org/abs/2502.06607", "title": "遥感图像中固体废物检测的深度学习管道", "title_en": "A Deep Learning Pipeline for Solid Waste Detection in Remote Sensing Images", "authors": "Federico Gibellini,Piero Fraternali,Giacomo Boracchi,Luca Morandini,Thomas Martinoli,Andrea Diecidue,Simona Malegori", "background": "不恰当的固体废物管理对生态系统健康构成严重威胁，并且是犯罪组织进行环境犯罪的重要资金来源。随着高分辨率遥感（VHR RS）图像的普及，现代图像分析工具能够自动识别和扫描非法废物倾倒地点，有效缓解该问题。", "innovation": "作者开发了一个半自动的废物检测管道，合作于地方环境保护机构，主要用于识别VHR RS图像中的非法倾倒地点。该管道优化了深度学习模型，通过广泛实验评估了网络架构、输入图像的地面分辨率和地理范围以及预训练程序的选择。最佳模型在F1评分和准确率上表现出色，分别为92.02%和94.56%。检测模型还能较好地适应不同地域的数据，F1评分的平均下降幅度仅为5.1%。", "conclusion": "研究表明，借助计算机辅助的图像分析工具，废物倾倒地点的检测时间可以减少多达30%。这为专业环境管理部门提供了实际益处。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.18131", "html_url": "https://arxiv.org/abs/2412.18131", "title": "UniPLV：通过区域视觉语言监督实现高效开放世界3D场景理解", "title_en": "UniPLV: Towards Label-Efficient Open-World 3D Scene Understanding by Regional Visual Language Supervision", "authors": "Yuru Wang,Pei Liu,Songtao Wang,Zehan Zhang,Xinyan Lu,Changwei Cai,Hao Li,Fu Liu,Peng Jia,Xianpeng Lang", "background": "开放世界的3D场景理解是一项关键挑战，涉及从点云等3D数据中识别和区分多种物体和类别，而不依赖于手动注释。传统方法在开放世界的任务上面临诸多挑战，特别是在构建广泛的点云-文本对方面存在局限，并且难以有效处理多模态数据。", "innovation": "UniPLV提出了一种稳健的框架，将点云、图像和文本统一于单一的学习范式，实现了全面的3D场景理解。该框架通过图像作为桥梁，在共享特征空间中同时嵌入3D点、预对齐的图像和文本，消除了劳动密集的点云-文本对构建需求。为实现精确的多模态对齐，UniPLV采用了两种创新策略：（i）图像与点云之间的logit和特征蒸馏模块，以增强特征一致性；（ii）一种视觉-点匹配模块，隐式纠正点到像素投影不准确对3D语义预测的影响。此外，通过实施四种特定任务的损失函数和两阶段训练策略，进一步提升了性能。", "conclusion": "大量的实验表明，UniPLV显著优于目前最先进的方法，分别在有基础标注和无标注任务上，语义分割的平均改进率为15.6%和14.8%。这些结果突显了UniPLV在推动物理开放世界3D场景理解边界上的有效性。已经发布代码以支持未来的研究和开发。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.01086", "html_url": "https://arxiv.org/abs/2409.01086", "title": "DPDEdit：保留细节的多模态扩散模型用于时装图像编辑", "title_en": "DPDEdit: Detail-Preserved Diffusion Models for Multimodal Fashion Image Editing", "authors": "Xiaolong Wang,Zhi-Qi Cheng,Jue Wang,Xiaojiang Peng", "background": "时装图像编辑是设计师通过可视化设计概念交互地传达创意想法的关键工具。当前的先进技术尽管使用了多模态提示和强大的扩散模型，但在准确识别编辑区域并保留所需的服装纹理细节方面仍存在问题。", "innovation": "提出了一种基于潜在扩散模型的新颖多模态时装图像编辑架构——保留细节的扩散模型 (DPDEdit)，通过整合文本提示、区域掩码、人体姿势图像和服装纹理图像来引导扩散模型的服装图像生成。为了精确定位编辑区域，首先使用Grounded-SAM预测基于用户文本描述的编辑区域，然后结合其他条件进行局部编辑。为了将给定的服装纹理细节转移至目标时装图像，提出了一个纹理注入和精细化机制。通过分隔交叉注意力层集成文本描述和纹理图像，并引入辅助 U-Net 保留生成服装纹理的高频细节。此外，通过多模态大型语言模型扩展 VITON-HD 数据集，生成与纹理图像和文本描述配对的样本。实验结果表明，DPDEdit 在图像保真度和与给定多模态输入的一致性方面优于最先进的方法。", "conclusion": "我们的研究结果表明，DPDEdit 在图像保真度和与给定多模态输入的一致性方面优于最先进的方法。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.08872", "html_url": "https://arxiv.org/abs/2408.08872", "title": "xGen-MM (BLIP-3): 一个开放的大型多模态模型家族", "title_en": "xGen-MM (BLIP-3): A Family of Open Large Multimodal Models", "authors": "Le Xue,Manli Shu,Anas Awadalla,Jun Wang,An Yan,Senthil Purushwalkam,Honglu Zhou,Viraj Prabhu,Yutong Dai,Michael S Ryoo,Shrikant Kendre,Jieyu Zhang,Shaoyen Tseng,Gustavo A Lujan-Moreno,Matthew L Olson,Musashi Hinck,David Cobbley,Vasudev Lal,Can Qin,Shu Zhang,Chia-Chih Chen,Ning Yu,Juntao Tan,Tulika Manoj Awalgaonkar,Shelby Heinecke,Huan Wang,Yejin Choi,Ludwig Schmidt,Zeyuan Chen,Silvio Savarese,Juan Carlos Niebles,Caiming Xiong,Ran Xu", "background": "研究领域中，大型多模态模型（Large Multimodal Models, LMMs）的重要性日益凸显。BLIP-3框架旨在解决模型开发过程中的挑战，提供详尽的数据集、训练方法和模型架构，以支持最优的多模态模型开发和应用。这有助于推动多模态研究的进一步发展。", "innovation": "BLIP-3框架通过以下几个方面展示了其创新性：1) 提供了精心整理的数据集；2) 设计了详细的训练食谱；3) 开发了多模态模型架构；4) 发布了4B和14B大小的预训练基础模型和指令微调模型；5) 对多种任务，包括单图像和多图像基准性能进行了严格评估。", "conclusion": "BLIP-3模型在开源多模态模型中展示了与其相似模型规模相当的竞争力，并且能够理解交错的图像-文本输入。研究团队将公开发布所有训练代码、模型和使用的所有数据集，包括他们创建的三个大规模数据集和预处理后的数据集，以便更好地支持研究社区。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.14053", "html_url": "https://arxiv.org/abs/2411.14053", "title": "Stereo Anything: 将大规模混合数据统一应用于零样本立体匹配", "title_en": "Stereo Anything: Unifying Zero-shot Stereo Matching with Large-Scale Mixed Data", "authors": "Xianda Guo,Chenming Zhang,Youmin Zhang,Ruilin Wang,Dujun Nie,Wenzhao Zheng,Matteo Poggi,Hao Zhao,Mang Ye,Qin Zou,Long Chen", "background": "立体匹配是3D视觉的基石，旨在通过双目图像对建立像素级对应以恢复深度信息。尽管借助深度神经架构取得了显著进展，但现有模型在未见过的领域中表现严重退化，主要是由于训练数据的多样性有限。", "innovation": "本文介绍了StereoAnything，一种数据导向的框架，显著提升了现有立体模型的零样本泛化能力。该框架通过系统地统一异构立体数据源（涵盖多样化环境的标注数据集以及来自无标签单目图像的大型合成立体对）来增强训练。这种混合数据策略能够跨领域提供一致和稳健的学习信号，有效减轻数据偏差。", "conclusion": "广泛的零样本评估表明，Stereo Anything 在四个公开基准上达到了最先进的泛化能力。这一工作为真正通用的立体匹配铺平了道路，提供了一个可扩展的数据范式，适用于任何立体图像对。我们的模型在四个公开数据集上的零样本能力进行广泛评估，展示了其惊人的泛化能力。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.19794", "html_url": "https://arxiv.org/abs/2410.19794", "title": "DiffGAN：一种用于图像分析深度神经网络差异测试的测试生成方法", "title_en": "DiffGAN: A Test Generation Approach for Differential Testing of Deep Neural Networks for Image Analysis", "authors": "Zohreh Aghababaeyan,Manel Abdellatif,Lionel Briand,Ramesh S", "background": "深度神经网络（DNNs）在各种应用中逐渐得到部署，但确保它们的可靠性仍然是一个挑战。传统的基于准确性的评估方法在有限测试数据集的情况下，难以捕捉模型之间的行为差异，因此选择或组合模型变得困难。差分测试通过生成能够暴露模型行为差异的测试输入来解决这一问题，但现有的方法存在很多局限性，如依赖模型内部结构或受制于可用的种子输入。已有方法并不能充分应对这些挑战。因此，需要新的方法来更好地揭示和利用模型间的差异以提高模型选择和评估的有效性，解决上述问题和挑战是一个关键点。", "innovation": "提出了一种名为DiffGAN的黑盒测试图像生成方法，用于DNN模型的差分测试。DiffGAN利用生成对抗网络（GAN）和非支配排序遗传算法II（NSGA-II），生成多样化且有效的触发输入，这些输入可以揭示模型之间的行为差异。DiffGAN通过两个自定义的适应度函数，关注多样性和差异性，来指导GAN的输入空间探索，识别模型输出间的差异。这种方法适用于更多情况，并显著提高了利用差分测试的模型选择机制的效果，比现有最好的基线方法（SOTA）生成了四倍多的有效触发输入，且更具多样性和有效性。", "conclusion": "研究结果表明，DiffGAN在相同预算下生成的触发输入比SOTA基线多四倍，并且这些输入具有更高的多样性和有效性。此外，生成的输入提高了基于输入特性的机器学习模型选择机制的准确性，并可作为智能输出投票机制支持使用替代模型。这将为DNN模型的选择、评估和应用提供更有效的方法。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.10288", "html_url": "https://arxiv.org/abs/2504.10288", "title": "Noise2Ghost: 自监督深度卷积重建在幽灵成像中的应用", "title_en": "Noise2Ghost: Self-supervised deep convolutional reconstruction for ghost imaging", "authors": "Mathieu Manni,Dmitry Karpov,K. Joost Batenburg,Sharon Shwartz,Nicola Viganò", "background": "在幽灵成像（GI）获取中，由于存在噪声，传统的无监督方法难以提供高质量的重建。因此，研究一种新的无监督深度学习方法来改善噪声环境下的幽灵成像重建性能是必要的。此外，新兴的低光照幽灵成像应用场景，例如微米级和纳米级的X射线发射成像（如剂量敏感样品的X射线荧光成像），对信号-噪声比提出了更高的要求。", "innovation": "该研究提出了一种新的自监督深度学习方法来重构幽灵成像数据。该方法通过自监督机制减轻了对干净参考数据的需求，并且能够有效降低噪声，从而改善了噪声环境下幽灵成像的重建性能，尤其适用于生物样品和电池的在体和在位成像研究。", "conclusion": "自监督深度卷积重建方法为解决幽灵成像场景中的信号-噪声比问题提供了必要工具。特别是在低光照领域，如微纳米尺度的X射线发射成像，该方法有助于提高图像质量和分析性能。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.16404", "html_url": "https://arxiv.org/abs/2504.16404", "title": "直接基于视频的时空深度学习在牛足部跛行检测中的应用", "title_en": "Direct Video-Based Spatiotemporal Deep Learning for Cattle Lameness Detection", "authors": "Md Fahimuzzman Sohan,Raid Alzubi,Hadeel Alzoubi,Eid Albalawi,A. H. Abdul Hafez", "background": "牛足部跛行是畜牧业中普遍存在的健康问题，常常由蹄部损伤或感染引起，严重损害动物福利和生产效率。早期且准确的检测对于减少经济损失和确保适当治疗至关重要。", "innovation": "该研究提出了一种时空深度学习框架，利用公开可用的视频数据自动检测牛的跛行。与传统依赖多阶段检测和姿态估计的方法不同，该研究展示了直接的端到端视频分类方法的有效性。", "conclusion": "研究表明，深度学习模型可以从多种视频源中成功提取和学习时空特征，从而在实际农场环境中实现可扩展且高效的牛足部跛行检测。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2312.14427", "html_url": "https://arxiv.org/abs/2312.14427", "title": "GROOD：GRadient-Aware Out-of-Distribution Detection", "title_en": "GROOD: GRadient-Aware Out-of-Distribution Detection", "authors": "Mostafa ElAraby,Sabyasachi Sahoo,Yann Pequignot,Paul Novello,Liam Paull", "background": "出-of分布（OOD）检测对于确保深度学习模型在实际应用中的可靠性至关重要。现有的方法通常侧重于特征表示或输出空间分析，经常假设这些空间的概率分布，或利用模型参数关于梯度的范数。然而，这些方法难以区分接近OOD的样本，常常需要大量的超参数调整，限制了它们的应用范围。这些限制使得领域外样本的检测变得更加困难，尤其是在ImageNet-1k等大规模数据集上。", "innovation": "本文提出了GRadient-aware Out-Of-Distribution检测（GROOD）方法。GROOD方法通过从合成样本中提取OOD原型，并直接从In-distribution训练数据中计算类别原型，实现了OOD样本与ID样本之间的清晰区分。通过分析一个最近类原型损失函数关于人工OOD原型的梯度，我们的方法能够在softmax层中为OOD样本分配更高的置信度值，并在大批量样本上产生更明确的边界。实验结果表明，GROOD方法在鲁棒性方面超过了现有的基准方法，特别是在ImageNet-1k数据集上，表明基于梯度的方法和原型驱动的方法在提升深度神经网络的OOD检测方面具有很大的潜力。", "conclusion": "实验结果表明，从OOD原型计算出的梯度增强了ID样本和OOD样本之间的区分度，超越了现有基准方法的鲁棒性，特别在ImageNet-1k上表现突出。这些发现突显了基于梯度的方法和原型驱动方法在提高深度神经网络中的OOD检测方面的重要性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.08531", "html_url": "https://arxiv.org/abs/2504.08531", "title": "体感图像描述：自监督学习智能体用于空间连贯图像描述", "title_en": "Embodied Image Captioning: Self-supervised Learning Agents for Spatially Coherent Image Descriptions", "authors": "Tommaso Galliena,Tommaso Apicella,Stefano Rosa,Pietro Morerio,Alessio Del Bue,Lorenzo Natale", "background": "文本生成图像描述是一个复杂的任务，当前模型在不同的相机视角和杂乱环境下难以生成连贯且一致的图像描述。", "innovation": "提出了一种三阶段框架，通过一致性机制在现有文本生成图像描述模型的基础上进一步提升描述准确性和一致性。该框架首先让智能体探索环境收集噪声图像-描述对，然后通过大型语言模型生成每个物体实例的一致性伪描述，最后利用这些伪描述和对比学习相结合对现成的文本生成图像描述模型进行微调。", "conclusion": "实验证明该方法通过生成更高分歧的样本提高了智能体的描述能力，并且综合作用的自描述智能体、探索策略、伪标签方法和微调策略比传统基线有更好的语义相似度。文本生成模型的微调显著提高了描述准确性和一致性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.22454", "html_url": "https://arxiv.org/abs/2410.22454", "title": "从扩散MRI识别脑年龄协同预测神经退行性疾病", "title_en": "Brain age identification from diffusion MRI synergistically predicts neurodegenerative disease", "authors": "Chenyu Gao,Michael E. Kim,Karthik Ramadass,Praitayini Kanakaraj,Aravind R. Krishnan,Adam M. Saunders,Nancy R. Newlin,Ho Hin Lee,Qi Yang,Warren D. Taylor,Brian D. Boyd,Lori L. Beason-Held,Susan M. Resnick,Lisa L. Barnes,David A. Bennett,Marilyn S. Albert,Katherine D. Van Schaik,Derek B. Archer,Timothy J. Hohman,Angela L. Jefferson,Ivana Išgum,Daniel Moyer,Yuankai Huo,Kurt G. Schilling,Lianrui Zuo,Shunxing Bao,Nazirah Mohd Khairi,Zhiyuan Li,Christos Davatzikos,Bennett A. Landman", "background": "脑年龄的估计从磁共振成像（MRI）测量中可以提供潜在神经退行性疾病的早期洞察，有助于早期检测和实施预防策略。扩散MRI（dMRI）可能成为神经退行性疾病预测的早期生物标志物，因为它捕捉到比宏观结构变化更早的微结构变化。然而，dMRI中宏微观结构信息的共存引发了当前基于dMRI的脑年龄估计模型是否有效利用了微结构信息还是无意中依赖了宏观结构信息的问题。因此，开发一种特定于微结构的脑年龄对于改进神经退行性疾病的早期预测至关重要。", "innovation": "本文提出了一种利用扩散MRI从非刚性注册所有图像到标准模板的方法来识别脑年龄，以减轻模型使用宏观结构信息。研究将采用这种方法训练的模型与基于T1加权MRI的脑年龄模型（包括有无宏观结构信息的减轻训练）进行了比较，并与两种流行的基于公开T1w MRI的脑年龄模型进行了对比。结果发现在不同阶段的神经退化过程中，dMRI的脑年龄不同于T1w MRI的脑年龄，对于从认知正常过渡到轻度认知障碍的参与者，dMRI的脑年龄较年长，而对于已经确诊为阿尔茨海默病的参与者，dMRI的脑年龄较年轻。此外，dMRI的脑年龄在预测认知正常向轻度认知障碍的转变上与T1w MRI的脑年龄相比可能具有提早五年的优势。", "conclusion": "本文的研究表明，扩散MRI的脑年龄可能提供早期预测神经退行性疾病的优势，尤其是预测从认知正常向轻度认知障碍的转变。通过减轻宏观结构信息的影响，dMRI可以作为更精确的生物标志物，便于更早地采取预防措施。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.20742", "html_url": "https://arxiv.org/abs/2502.20742", "title": "Vision-Language 长时序任务规划中的结构化偏好优化", "title_en": "Structured Preference Optimization for Vision-Language Long-Horizon Task Planning", "authors": "Xiwen Liang,Min Lin,Weiqi Ruan,Rongtao Xu,Yuecheng Liu,Jiaqi Chen,Bingqian Lin,Yuzheng Zhuang,Xiaodan Liang", "background": "现有的视觉-语言任务规划方法在短期任务上表现出色，但在处理动态环境中复杂的、长期的任务规划时却经常出现困难。这些挑战主要源自于有效训练模型进行长期任务高质量推理过程的难度。现有的方法难以生成系统化的、基于任务相关性、视觉锚定历史一致性的推理链，并在长期任务规划中提供优化的训练策略以增强推理和行动选择。", "innovation": "本文提出了一种结构化偏好优化（SPO）方法。它通过结构化偏好评估和优化训练策略来增强长期任务规划中的推理和行动选择。SPO包括两种具体方法：1）基于偏好评分和优化，系统评估基于任务相关性、视觉锚定和历史一致性推理链；2）基于课程的学习，模型逐步从简单任务到复杂任务适应，提高其在长期任务中的泛化能力和推理鲁棒性。为此，本文还提出了一个涵盖1,509个任务的综合基准ExtendaBench，涉及虚拟家庭和Habitat 2.0，任务分为超短、短、中、长期任务。实验结果表明，SPO在提高推理质量和最终决策准确性方面取得了显著改进，优于之前的最佳基线方法。", "conclusion": "SPO通过偏好驱动的优化显著提高了视觉-语言长期任务规划中的推理质量和决策准确性。实验结果表明，与基线方法相比，SPO在VirtualHome和Habitat中的表现更优，在VirtualHome上实现了+5.98%的GCR和+4.68%的SR提升，在Habitat上实现了+3.30%的GCR和+2.11%的SR提升。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.04990", "html_url": "https://arxiv.org/abs/2507.04990", "title": "基于混合整数线性规划方法的DL系统测试输入优化标注与验证", "title_en": "Effort-Optimized, Accuracy-Driven Labelling and Validation of Test Inputs for DL Systems: A Mixed-Integer Linear Programming Approach", "authors": "Mohammad Hossein Amini,Mehrdad Sabetzadeh,Shiva Nejati", "background": "随着软件系统中深度学习(DL)组件的不断增加，确保这些系统的可靠测试变得至关重要，这需要近乎完美的测试输入有效性和标签准确性，同时尽量减少人力投入。然而，深度学习社区对于构建高质量数据集的需求关注较少，因为深度学习训练通常对标签错误具有较高的容忍度。相反，这一挑战更常出现在软件工程领域，其中的一个核心目标是构建高准确度的测试输入，尽可能接近100%的准确率，并同时控制相关成本。", "innovation": "本文介绍了一种名为OPAL的人力辅助标注方法，可以配置为达到所需的精度水平，同时最小化标签所需的手工努力。OPAL的主要贡献在于一种混合整数线性规划(MILP)表述，该表述在满足指定精度目标的同时，最小化标签努力。我们针对测试视觉系统中的两个任务，实际应用了OPAL：自动标注测试输入和自动验证测试输入。实验结果表明，OPAL在七个数据集上的平均精度为98.8%，而手动标注减少了超过一半，且在所有七种数据集上的标注精度上明显优于现有的自动化标注基线。", "conclusion": "我们展示了在OPAL基础上添加主动学习循环，可以进一步减少需要的手工标注，同时不降低准确性。对于测试输入的自动验证，OPAL平均每减少28.8%的手工努力，同时准确率提高了4.5%。与最新的测试输入验证基线（SOTA）相比，OPAL在所有七个数据集上表现出更好的性能。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.14171", "html_url": "https://arxiv.org/abs/2503.14171", "title": "轻量级感知梯度上缩放的3D高斯洒点图象", "title_en": "Lightweight Gradient-Aware Upscaling of 3D Gaussian Splatting Images", "authors": "Simon Niedermayr,Christoph Neuhauser Rüdiger Westermann", "background": "文章介绍了针对轻量级GPU上的3D高斯洒点（3DGS）技术的上缩放技术。与3DGS相比，这种技术在渲染速度上显著提高，并减少了常见的3DGS重建中的伪影。这种技术通过直接利用高斯的解析图像梯度进行基于梯度的双三次样条插值，来实现低分辨率3DGS渲染的上缩放。此技术不依赖于特定的3DGS实现，可以在基线实现基础上实现3-4倍的速度提升。通过在多个数据集上的广泛实验，展示了感知梯度上缩放3DGS图像的性能提升和重建保真度。此外，还展示了感知梯度上缩放在基于梯度优化的3DGS模型中的集成及其对重建质量和性能的影响。", "innovation": "该技术通过直接利用高斯的解析图像梯度，进行基于梯度的双三次样条插值，实现了低分辨率3DGS渲染的上缩放。此技术不依赖于特定的3DGS实现，在基线实现基础上实现3-4倍的速度提升，显著减少了伪影，提高了重建保真度。此外，还展示了解耦的优化方法，其能够提高3DGS模型的重建质量和性能效果。", "conclusion": "本文提出的方法在多次数据集上展示了感知梯度上缩放3DGS图像的性能提升和高重建保真度。该技术已经在基于梯度优化的3DGS模型中得到了集成，分析了其对重建质量和性能的影响，为提升3DGS模型的整体性能提供了一种新的视角。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.00552", "html_url": "https://arxiv.org/abs/2508.00552", "title": "DBLP: 噪声桥梁一致性的蒸馏为高效的可靠的对抗样本净化", "title_en": "DBLP: Noise Bridge Consistency Distillation For Efficient And Reliable Adversarial Purification", "authors": "Chihan Huang,Belal Alsinglawi,Islam Al-qudah", "background": "近年来，深度神经网络（DNNs）在各种任务中取得了显著的成功。然而，它们对对抗扰动的敏感性仍然是一个至关重要的安全隐患。现有的基于扩散的对抗净化方法通常需要密集的迭代去噪，严重限制了它们的实际部署.", "innovation": "本文提出了一种新颖高效且基于扩散的方法——DBLP（Diffusion Bridge Distillation for Purification），该方法通过噪声桥梁蒸馏构建了对抗噪声分布与干净数据分布之间的原则性对齐，同时引入了自适应语义增强，通过多尺度金字塔边缘图作为条件输入来引导净化过程，从而进一步提高语义保真度。", "conclusion": "实验结果表明，DBLP 在多个数据集上在鲁棒准确度、图像质量和推理时间方面达到了最先进的性能，标志着向实时对抗净化迈出了重要一步。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09397", "html_url": "https://arxiv.org/abs/2508.09397", "title": "Skyshield: 无人机飞行安全的事件驱动型亚毫米级细小障碍物检测", "title_en": "Skyshield: Event-Driven Submillimetre Thin Obstacle Detection for Drone Flight Safety", "authors": "Zhengli Zhang,Xinyu Luo,Yucheng Sun,Wenhua Ding,Dongyue Huang,Xinlei Chen", "background": "无人机在复杂环境中运行时面临着来自亚毫米级别的细小障碍物（如钢丝和风筝线）的重大威胁，这些障碍物对传统传感器（如RGB相机、LiDAR和深度相机）来说难以检测。因此，需要开发一种新的方法来感知这些亚毫米级别的障碍物，以确保无人机的安全飞行。", "innovation": "本文介绍了一种名为SkyShield的事件驱动、端到端框架，用于亚毫米级别障碍物的感知。该方法利用了细小障碍物在事件流中特有的特性，采用轻量级的U-Net架构和创新的Dice-Contour正则化损失函数来实现精确检测。实验结果表明，该事件驱动的方法在低延迟21.2毫秒的情况下实现了0.7088的平均F1分数，适合作为边缘和移动平台的部署。", "conclusion": "本文提出的方法能够有效地检测亚毫米级别的细小障碍物，适合部署在边缘和移动平台上。与传统的传感器相比，其具有更低的延迟和更高的检测精度，能够有效提升无人机在复杂环境中的飞行安全性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.04705", "html_url": "https://arxiv.org/abs/2507.04705", "title": "身份保留的由简单而有效的空间-时间解耦表示引导的文字到视频生成", "title_en": "Identity-Preserving Text-to-Video Generation Guided by Simple yet Effective Spatial-Temporal Decoupled Representations", "authors": "Yuji Wang,Moran Li,Xiaobin Hu,Ran Yi,Jiangning Zhang,Han Feng,Weijian Cao,Yabiao Wang,Chengjie Wang,Lizhuang Ma", "background": "身份保留的文字到视频生成（IPT2V），旨在创建具有一致人类身份的高保真度视频，对于下游应用至关重要。然而，当前的端到端框架在实现空间一致性和时间平滑性之间存在关键的空间-时间权衡：优化关键元素的空间一致布局（例如，人物身份保持）往往牺牲了指令合规的时间连续性，而优先考虑动态现实性则可能破坏视觉结构的空间连贯性。", "innovation": "为了解决这一问题，本文提出了一种简单而有效的空间-时间解耦框架，将表征分解为空间特征（用于布局）和时间特征（用于运动动力学）。具体而言，我们提出了语义提示优化机制和阶段式解耦生成范式。前者将提示解耦为空间和时间组件，与后续阶段式解耦方法相结合，空间提示引导文本到图像（T2I）阶段生成空间一致特征，而时间提示指导序列表像到视频（I2V）阶段确保运动一致性。实验结果验证了我们的方法在时空一致性、身份保持、文本相关性和视频质量方面表现出色。", "conclusion": "通过利用这种简单而稳健的机制，我们的算法在2025年ACM多媒体挑战赛获得了第2名的位置。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.05582", "html_url": "https://arxiv.org/abs/2509.05582", "title": "分离的重建与再现方法实现逼真高斯头", "title_en": "Reconstruction and Reenactment Separated Method for Realistic Gaussian Head", "authors": "Zhiling Ye,Cong Zhou,Xiubao Zhang,Haifeng Shen,Weihong Deng,Quan Lu", "background": "该论文探讨了一种基于单张肖像图生成可控虚拟人物的重建和再现分离框架，利用WebSSL构建大规模一次性高斯头生成器，并采用两阶段训练方法提高一般性和高频纹理重建能力。", "innovation": "论文提出了一个大规模单次生成高斯头的方法，并使用了两阶段训练方法。在推理阶段，通过控制信号驱动的超轻量级高斯虚拟人物实现高帧率渲染，达到512x512分辨率90FPS的效果。此方法表现出随重建模块参数规模增加，性能提升的特点，且分离设计不影响驱动效率。", "conclusion": "通过大量定量和定性的实验，论文证明了所提出的方法超越了当前最先进的方法。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06082", "html_url": "https://arxiv.org/abs/2508.06082", "title": "SwiftVideo：通过轨迹分布对齐实现少量步骤视频生成的统一框架", "title_en": "SwiftVideo: A Unified Framework for Few-Step Video Generation through Trajectory-Distribution Alignment", "authors": "Yanxiao Sun,Jiafu Wu,Yun Cao,Chengming Xu,Yabiao Wang,Weijian Cao,Donghao Luo,Chengjie Wang,Yanwei Fu", "background": "扩散模型或流模型在视频合成方面取得了显著进展，但需要多次迭代采样步骤，导致计算开销大。尽管开发了许多仅基于轨迹保留或分布匹配的简要方法来加速视频生成模型，但在少量步骤设置下，这些方法常常出现性能崩溃或增加伪影的问题。为解决这些局限性，我们提出了一种统一的稳定蒸馏框架SwiftVideo，结合了轨迹保留和分布匹配策略的优点。具体的，我们引入了连续时间一致性蒸馏确保精确的ODE轨迹保留，并提出了一种双视角对齐，包括合成数据和真实数据之间的分布对齐以及不同推断步骤之间的轨迹对齐。该方法在减少推断步骤的同时仍能保持高质量的视频生成。", "innovation": "我们提出了一种统一且稳定的蒸馏框架SwiftVideo，结合了轨迹保留和分布匹配策略的优点。引入了连续时间一致性蒸馏来确保ODE轨迹的精确保留，并提出了一种双视角对齐方法，包括分布对齐和轨迹对齐。这种方法在减少推理步骤的同时保持了高质量的视频生成。定量评估表明，该方法在少量步骤视频生成中显著优于现有方法。", "conclusion": "在OpenVid-1M基准上的定量评估显示，我们的方法显著优于现有方法的少量步骤视频生成。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05606", "html_url": "https://arxiv.org/abs/2508.05606", "title": "Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision", "title_en": "Uni-cot: Towards Unified Chain-of-Thought Reasoning Across Text and Vision", "authors": "Luozheng Qin,Jia Gong,Yuqing Sun,Tianjiao Li,Mengping Yang,Xiaomeng Yang,Chao Qu,Zhiyu Tan,Hao Li", "background": "链式思维（CoT）推理已被广泛应用于通过将复杂任务分解为更简单的顺序子任务来提升大型语言模型（LLMs）。然而，将CoT扩展到视觉语言推理任务仍然存在挑战，因为这通常需要解释视觉状态的变化以支持推理。现有方法在解释视觉状态过渡方面能力有限，或者由于分段架构导致不一致的视觉轨迹。", "innovation": "本文提出了一个统一的链式思维框架_Uni-CoT，该框架在一个统一模型中实现了连贯且基于图像的多模态推理。该框架引入了两层推理范式：宏观层CoT用于高层任务规划，微观层CoT用于子任务执行。此外，引入了一种结构化的训练范式，结合了交错的图像-文本监督用于宏观层CoT和多任务目标用于微观层CoT，以提升推理性能。", "conclusion": "实验结果表明，Uni-CoT在推理解释驱动的图像生成基准（WISE）和编辑基准（RISE 和 KRIS）中表现出SOTA性能和强泛化能力，确立了Uni-CoT作为多模态推理的有前景解决方案的地位。所有实验仅使用8块A100 GPU（每块具有80GB VRAM）即可高效完成。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.03740", "html_url": "https://arxiv.org/abs/2509.03740", "title": "Singular Value Few-shot Adaptation of Vision-Language Models", "title_en": "Singular Value Few-shot Adaptation of Vision-Language Models", "authors": "Taha Koleilat,Hassan Rivaz,Yiming Xiao", "background": "视觉语言模型（VLMs）如CLIP展示了跨多种应用的令人印象深刻的零样本和少量样本学习能力。然而，将这些模型适应到新的细粒度领域仍然具有挑战性，因为这依赖于提示工程且全模型微调的成本较高。现有适应方法依赖于增强组件，例如提示令牌和适配器模块，这些都可能限制适应质量，使模型不稳定，并损害预训练期间学习的丰富知识。", "innovation": "CLIP-SVD是一种新颖的多模态和参数高效的适应技术，它利用奇异值分解（SVD）来修改CLIP的内部参数空间而不注入额外模块。具体来说，仅微调CLIP的奇异值来重新缩放基础向量以适应新领域，同时保留预训练模型。这种设计使我们能够仅用模型总参数的0.04%来提高适应性能，并更好地保留其泛化能力。CLIP-SVD在11个自然和10个生物医学数据集上的分类结果达到了最先进的技术水平，在少量样本设置下的准确性和泛化表现均优于先前的方法。此外，利用基于自然语言的方法来分析CLIP适应的有效性和动态，以实现对CLIP-SVD的可解释性。", "conclusion": "CLIP-SVD展示了在少量样本设置下优越的分类性能，同时保持了良好的泛化能力，并且相比先前的方法具有更高的可解释性。该研究为视觉语言模型的少量样本适应提供了新的方法。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.06996", "html_url": "https://arxiv.org/abs/2509.06996", "title": "可见但不可读：视觉语言模型在不同书写系统中的系统性盲点", "title_en": "Visible Yet Unreadable: A Systematic Blind Spot of Vision Language Models Across Writing Systems", "authors": "Jie Zhang,Ting Xu,Gelei Deng,Runyi Hu,Han Qiu,Tianwei Zhang,Qing Guo,Ivor Tsang", "background": "书写是一种普遍的文化技术，通过视觉进行象征性通信。人类显示出惊人的韧性:即使字符被分割、融合或部分遮挡，我们也能够轻易地识别文字。本文探讨了高级视觉语言模型（VLMs）是否也具备这种韧性。通过构建跨不同书写系统的视觉心理学启发基准，包括中文字符和英文字母，研究发现，尽管在干净文本上有强大表现，当代VLMs在这种干扰下表现出严重的性能下降。", "innovation": "研究人员设计了两种跨不同书写系统的基准测试，通过拼接、重组和叠加字元，创建出对模型可见但人类可读的受污染文本，以评估视觉语言模型的鲁棒性。结果显示，尽管模型在干净文本上表现出色，但在这些干扰下，它们的性能严重下降，常常产生不相关的或不连贯的输出。这种模式表明模型在结构上存在局限：它们大量依赖通用的视觉不变性，但对构成先验的依赖不足，这有助于构建对多种书写系统符号分割、组合和绑定建模的架构及训练策略。", "conclusion": "研究结果揭示了视觉语言模型在多种书写系统中的结构性局限，并为如何使用多模态系统在教育、无障碍性、文化遗产和安全方面提出具体的挑战。同时，研究者发布了刺激生成代码、提示和评估协议，以促进透明的可复制性并推动后续研究。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.09595", "html_url": "https://arxiv.org/abs/2509.09595", "title": "Kling-Avatar: 通过级联长时动画合成实现多模态指令接地", "title_en": "Kling-Avatar: Grounding Multimodal Instructions for Cascaded Long-Duration Avatar Animation Synthesis", "authors": "Yikang Ding,Jiwen Liu,Wenyuan Zhang,Zekun Wang,Wentao Hu,Liyuan Cui,Mingming Lao,Yingchao Shao,Hui Liu,Xiaohan Li,Ming Chen,Xiaoqiang Liu,Yu-Shen Liu,Pengfei Wan", "background": "近期的音频驱动头像视频生成技术大幅提升了视听逼真度。然而，现有的方法仅将指令条件处理为由声学或视觉线索驱动的低级追踪，而未能建模指令传达的交际目的，这限制了故事连贯性和角色表现力。", "innovation": "我们提出了Kling-Avatar，这是一种新颖的级联系统，它将多模态指令理解和逼真肖像生成统一起来。该方法采用两阶段流程：第一阶段，设计多模态大型语言模型导演，生成根据多样指令信号条件的蓝图视频，从而控制高层语义，如角色动作和情绪；第二阶段，基于蓝图关键帧，采用首尾帧策略并行生成多个子片段。这一从全局到局部的框架保留了细粒度细节，忠实编码了多模态指令背后的高层意图。并行架构也加快了长视频的快速稳定生成，适用于数字人类直播和视频博客等实际应用。", "conclusion": "通过构建375个精心筛选的样本基准，广泛实验表明，Kling-Avatar能够生成生动、流畅、长时的视频，性能优于十种关键指标，证明其在语义上的真实性、高保真音频驱动头像合成方面的新基准地位。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10256", "html_url": "https://arxiv.org/abs/2508.10256", "title": "深度学习在裂缝检测中的应用：学习范式、泛化能力和数据集的综述", "title_en": "Deep Learning for Crack Detection: A Review of Learning Paradigms, Generalizability, and Datasets", "authors": "Xinan Zhang,Haolin Wang,Yung-An Hsieh,Zhongyu Yang,Anthony Yezzi,Yi-Chang Tsai", "background": "裂缝检测在基础设施检查中扮演着关键角色，包括道路检查、建筑物检查等。近年来，深度学习为这一领域带来了显著的进展。尽管这一领域已经存在大量的技术和综述性论文，但新的发展趋势正在重塑这一领域。这些变化包括学习范式的转变（从完全监督学习到半监督、弱监督、无监督、少量样本学习、领域适应和微调基础模型）、泛化能力的提升（从单数据集性能到跨数据集评估），以及数据集获取的多样化（从RGB图像到专业化传感器数据）.", "innovation": "本文系统分析了这些趋势，并介绍了代表性的研究成果。作者还提出了一个使用3D激光扫描数据集收集的新标注数据集，名为3DCrack，并进行了广泛的基准实验，以建立常用的深度学习方法的基础，包括近期的基础模型。研究结果提供了关于深度学习在裂缝检测中的方法演变和未来发展方向的见解.", "conclusion": "本研究提供了关于深度学习方法在裂缝检测中演变的方法论和未来方向的见解。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.12248", "html_url": "https://arxiv.org/abs/2509.12248", "title": "在图像中传递诙谐：评估大型多模态模型对在线连环画的理解", "title_en": "Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics", "authors": "Yuriel Ryan,Rui Yang Tan,Kenny Tsu Wei Choo,Roy Ka-Wei Lee", "background": "理解幽默是社交智能的核心方面，但对大型多模态模型（LMMs）而言仍然是一个重大挑战。现有的LMMs在解读多模态幽默和识别叙事序列方面表现不佳。", "innovation": "本文介绍了PixelHumor，这是一个包含2800个经过标注的多分格连环画的基准数据集，旨在评估LMMs解读多模态幽默和识别叙事序列的能力。实验表明，最先进的LMMs在分格序列预测上的准确率仅为61%，远低于人类表现，这暴露了当前模型在整合视觉和文本线索方面存在的关键不足。", "conclusion": "通过为评估多模态上下文和叙事理解提供严格的框架，PixelHumor旨在推动开发能够进行更自然、社交意识更高交流的LMMs。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.19988", "html_url": "https://arxiv.org/abs/2405.19988", "title": "Video-Language Critic: 可迁移的语言条件型奖励函数", "title_en": "Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics", "authors": "Minttu Alakuijala,Reginald McLean,Isaac Woungang,Nariman Farsad,Samuel Kaski,Pekka Marttinen,Kai Yuan", "background": "自然语言通常是人类为机器人指定任务最便捷的方式，但将语言与行为对应起来通常需要大量的多样化、语言标注示范数据，而且这些数据需要在每个目标机器人上收集，这往往不切实际。本研究旨在分离实现什么目标与如何实现的目标，前者可以从大量的外部观察数据中受益，后者则依赖特定的机器人实体。因此，本研究提出了Video-Language Critic，一种可用于跨实体数据训练的奖励模型，并利用对比学习和时间排序目标来训练一个独立的行为评分系统。", "innovation": "本研究提出了一种Video-Language Critic奖励模型，能够在无需额外收集语言标注示范数据的情况下，通过对比学习和时间排序目标，训练跨实体数据上的模型，并使用此模型来评估行为轨迹。与仅使用稀疏奖励相比，该模型在Meta-World任务上的样本效率提高了2倍，尤其是在需要跨域数据的Meta-World任务中，相比以前的方法，训练更高效。", "conclusion": "本研究提出的Video-Language Critic奖励模型，在跨域数据训练中表现出色，能够显著提高样本效率，尤其是当使用领域内数据进行复杂任务泛化时。这表明该方法对于语言条件型机器人研究具有重要意义。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.07613", "html_url": "https://arxiv.org/abs/2509.07613", "title": "Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease", "title_en": "Data-Efficient Fine-Tuning of Vision-Language Models for Diagnosis of Alzheimer's Disease", "authors": "Fangqi Cheng,Surajit Ray,Xiaochen Yang", "background": "医疗领域中的视觉-语言模型（Med-VLMs）在报告生成和视觉问答任务中表现出色，但仍然存在一些局限性。这些模型未能充分利用患者的元数据，缺乏对临床诊断知识的整合。此外，大多数现有模型是从头开始训练，或在大规模的2D图像-文本配对上进行微调，这需要大量的计算资源，并且在3D医学图像方面由于缺少结构信息，其效果往往有限。", "innovation": "本文提出了一种数据效率较高的微调流水线，旨在将基于3D CT的Med-VLMs适应用于3D MRI，并展示了该方法在阿尔茨海默病（AD）诊断中的应用。该系统包含两项关键创新。首先，将结构化元数据转换为合成报告，以丰富文本输入，提高图像-文本对齐度。其次，引入了一个辅助 tokens，用于预测迷你-精神状态检查量表（MMSE）评分，这是一个广泛使用的临床认知功能测量指标，与AD严重程度相关。此外，通过轻量级提示调优应用于图像和文本模态，该方法在两个AD数据集中使用1,500张训练图像达到了最先进的性能，优于在10,000幅图像上微调的现有方法。", "conclusion": "通过微调流水线，该方法在AD诊断中达到了最先进的性能，特别是在数据效率方面表现突出，验证了其在3D医学图像诊断中的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.09067", "html_url": "https://arxiv.org/abs/2509.09067", "title": "利用场景信息和多任务学习方法提高人类物体交互行为识别", "title_en": "Improvement of Human-Object Interaction Action Recognition Using Scene Information and Multi-Task Learning Approach", "authors": "Hesham M. Shehata,Mohammad Abdolrahmani", "background": "最近的图卷积神经网络（GCNs）在利用人体骨架姿势进行人类行为识别方面表现出高效能，但由于缺乏对场景信息的有效表示和合适的训练架构，无法成功检测人类与物体的交互情况。研究提出了一种方法，通过考虑到环境中的固定物体信息并采用多任务学习方法来提高人类行为识别性能。为了评估该方法，收集了公共环境中的实际数据，准备了一个数据集，其中包括与固定物体（如ATM取款机、签到/签退机等）的手部交互类别和非交互类别的行走和站立动作。多任务学习方法结合交互区域信息，成功地以99.25%的准确率识别了所研究的交互和非交互动作，优于仅使用人体骨架姿势的基线模型2.75%的准确率。", "innovation": "引入了结合环境中的固定物体信息和多任务学习（multitask learning）的方法，以改进人类行为识别中的人类-物体交互识别，通过使用多任务学习方法结合交互区域信息，在公共环境中收集实际数据，并展示了显著的识别准确率提高", "conclusion": "提出的多任务学习方法结合场景信息显著提升了人类对象交互行为的识别准确率，达到了99.25%，比仅使用人体骨架姿势的模型提高了2.75%。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.18167", "html_url": "https://arxiv.org/abs/2501.18167", "title": "散射方法通过扩散定量评估脑损伤中的轴突损伤", "title_en": "Scattering approach to diffusion quantifies axonal damage in brain injury", "authors": "Ali Abdollahzadeh,Ricardo Coronado-Leija,Hong-Hsi Lee,Alejandra Sierra,Els Fieremans,Dmitry S. Novikov", "background": "早期诊断和非侵入性监测神经疾病需要对毫微米级的细胞水平变化保持高敏感度，这些变化在毫米级分辨率的医学影像学方法中是不可见的。在多发性硬化症等疾病中，轴突形态学改变（如轴突膨大或扭曲）在疾病进展、发育和衰老过程中被观察到。本研究强调了依赖时间的扩散磁共振成像（dMRI）对微米级的轴突结构紊乱的敏感性，为揭示轴突形态学变化提供了一种新的手段。", "innovation": "研究团队开发了一种散射理论模型，揭示了决定沿轴突分子扩散动力学的两个关键参数：平均逆截面积和长程截面积波动的方差。该理论模型允许快速预测微米级以上结构的轴突形态学变化，显著提高了评估轴突损伤的效率和准确性，避免了传统方法耗时的数值模拟过程，并且得到了体外dMRI成像的验证。这种方法将微米级和毫米级分辨率之间的差距缩小，提供了一种适用于多种神经退行性疾病的定量和客观生物标记物。", "conclusion": "本研究通过扩散磁共振成像结合散射理论模型，揭示了微米级轴突形态学变化的敏感性，为创伤性脑损伤等神经疾病中的轴突损伤提供了新的定量评估手段。这种方法不仅提高了评估轴突损伤的效率，还扩展了应用于各类神经疾病的生物标记物的适用范围。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.12918", "html_url": "https://arxiv.org/abs/2509.12918", "title": "一种针对YOLOv8的新压缩框架：通过结构化剪枝和信道级蒸馏实现边缘设备上的实时空中目标检测", "title_en": "A Novel Compression Framework for YOLOv8: Achieving Real-Time Aerial Object Detection on Edge Devices via Structured Pruning and Channel-Wise Distillation", "authors": "Melika Sabaghian,Mohammad Ali Keyvanrad,Seyyedeh Mahila Moghadami", "background": "在资源受限的设备上高效部署深度学习模型进行空地目标检测，需要在不牺牲性能的前提下进行显著的压缩。之前的研究表明，可以通过引入稀疏性感知训练、结构化信道剪枝和信道级知识蒸馏（CWD）等方法来实现这一目标。", "innovation": "本文提出了一种新颖的三阶段压缩管道，结合了稀疏性感知训练、结构化信道剪枝和信道级知识蒸馏（CWD）。第一阶段通过动态稀疏性感知训练优化模型，平衡参数减少和检测精度。第二阶段利用批量规范化缩放因子进行结构化信道剪枝，显著减小了模型大小和计算复杂度。第三阶段通过CWD从原始模型中转移知识来缓解剪枝带来的精度下降，并采用可调温度和损失加权方案适应小目标检测。实验结果表明，这种方法在多个YOLOv8变体中具有有效性。", "conclusion": "在VisDrone数据集上，我们的方法将YOLOR模型的参数从25.85M减少到6.85M（减少了73.51%），FLOPs从49.6G减少到13.3G，MACs从101G减少到34.5G，同时AP50仅减少了2.7%，压缩后的模型达到了47.9 AP50，并将推理速度从26 FPS提升到45 FPS，实现了边缘设备上的实时部署。进一步应用TensorRT作为轻量优化步骤，虽然导致AP50略有下降（从47.9到47.6），但推理速度从45 FPS提升到68 FPS，说明其在资源受限环境中的实用性和高效性。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.05424", "html_url": "https://arxiv.org/abs/2503.05424", "title": "通过渐进干预和度量属性梯度本地解释预测行为", "title_en": "Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients", "authors": "Niklas Penzel,Joachim Denzler", "background": "深度学习模型虽然能够实现高度预测性能，但缺乏内在可解释性，阻碍了我们对所学预测行为的理解。现有的局部解释方法主要关注关联性，忽视了模型预测的因果驱动因素。虽然有些方法从因果角度进行解释，但它们主要提供模型级别的全局解释。对于特定输入，我们不清楚全局识别的因素是否适用于局部。", "innovation": "引入了一个新的框架，利用图像到图像编辑模型的最新进展来进行局部干预性解释。该方法通过逐步干预语义属性，使用新颖的评分方法——期望属性梯度幅度——来量化对模型预测的影响。该方法通过广泛的实验评价进行了验证，并应用于医学皮肤病变分类器、网络训练动态分析和预训练的CLIP模型的研究。结果表明，在属性层面的干预性解释具有揭示深度模型行为新见解的潜力。", "conclusion": "通过广泛的实证研究，该方法在合成场景和真实场景中都展示了其效果，具体包括局部识别偏见、医学皮肤病变分类器研究、网络训练动态分析和预训练的CLIP模型的研究。结果证实了在属性层面进行干预性解释的潜力，可以揭示关于深度模型行为的新见解。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23759", "html_url": "https://arxiv.org/abs/2505.23759", "title": "当视觉语言模型捉摸不透这些谜题时：视觉语言模型无法理解暗示", "title_en": "Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint", "authors": "Heekyung Lee,Jiaxin Ge,Tsung-Han Wu,Minwoo Kang,Trevor Darrell,David M. Chan", "background": "回文谜题是一种通过图像、空间排列和符号替代来编码语言的视觉谜题，给当前的视觉语言模型（VLMs）带来了独特的挑战。与传统的图像描述或问答任务不同，解回文谜题需要进行多模态抽象、符号推理并理解文化、音韵和语言的双关语。", "innovation": "本文通过构建一个涵盖从简单的图像替换到依赖空间线索（“头”置于“脚”之上）的多样英文回文谜题的手工生成和注释基准数据集，研究当前VLMs解释和解决回文谜题的能力。通过对不同VLMs的表现进行分析，研究揭示了尽管VLMs在解码简单的视觉线索方面表现出一些惊人的能力，但在需要抽象推理、横向思维和理解视觉比喻的任务上却面临显著的挑战。", "conclusion": "研究表明，VLMs虽然在解简单视觉提示方面有一定表现，但在解决涉及抽象推理、横向思维和理解视觉隐喻的任务时表现不佳。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.10815", "html_url": "https://arxiv.org/abs/2509.10815", "title": "具有良好条件数的多项式表示法以实现数学手写识别", "title_en": "Well-Conditioned Polynomial Representations for Mathematical Handwriting Recognition", "authors": "Robert M. Corless,Deepak Singh Kalhan,Stephen M. Watt", "background": "先前的研究使用参数化平面曲线多项式表示法来表示数学手写，多项式以勒让德或勒让德-索波莱夫分级基表示。勒让德-索波莱夫基和其他切比雪夫-索波莱夫基也在初步结果中被采用。这些方法为数字墨迹提供了一种紧凑的几何表示。本文关注多项式表示法的选择与多项式次数之间的权衡，以实现精确建模并同时保持较低的计算成本。考虑了这些基中的多项式评估条件数，并界定了各种内积如何给出符号间变化的范数。", "innovation": "该文章探讨了在表示法选择与多项式阶数之间权衡以实现精确建模和低计算成本的方法。通过分析不同基底的多项式评估条件数及如何多种内积给出符号间变化的范数，提出了新的良好条件数的多项式表示法构造思路。", "conclusion": "研究发现，在某些情况下，通过选择特定的基底和适当调整多项式次数，可以有效地降低计算成本并保持建模精度。这些结果为提高数学手写识别的性能提供了新思路。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.05798", "html_url": "https://arxiv.org/abs/2505.05798", "title": "通过纠错输出编码提高柯尔莫哥洛夫-阿诺德网络的泛化能力", "title_en": "Improving Generalizability of Kolmogorov-Arnold Networks via Error-Correcting Output Codes", "authors": "Youngjoon Lee,Jinu Gong,Joonhyuk Kang", "background": "柯尔莫哥洛夫-阿诺德网络（KAN）能够通过无非线性激活的一元样条函数组合实现通用函数逼近。现有工作通常使用其他复杂的激活函数来实现多类分类任务。现有的研究表明，通过集成纠错输出编码（ECOC）框架可以将多类分类任务转化为多个二元任务，从而提高鲁棒性，并通过汉明距离解码一致性增强性能。", "innovation": "本文将ECOC框架整合到KAN框架中，转化多类分类为多个二元任务，利用汉明距离解码提高鲁棒性。实验结果表明，改进后的KAN+ECCO框架在复杂的血细胞分类数据集上表现更优，且不同超参数设置下都表现良好。进一步的消融研究表明，ECOC持续提升性能，这一效果在FastKAN和FasterKAN变体中也得到验证。这些结果表明，ECOC整合显著提升了KAN在重要医疗人工智能应用中的泛化能力。", "conclusion": "这是首次将ECOC与KAN结合使用以提高多类医疗图像分类性能的研究。通过ECOC提升KAN框架的鲁棒性和性能，标志着在医疗AI应用方面的重要进展。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.11915", "html_url": "https://arxiv.org/abs/2408.11915", "title": "Video-Foley: 通过时间事件条件实现两阶段视频到声音生成", "title_en": "Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound", "authors": "Junwon Lee,Jaekwon Im,Dabin Kim,Juhan Nam", "background": " Foley声音合成对于多媒体生产至关重要，通过同步音频和视频在时间和语义上提升用户体验。通过视频到声音生成自动化的研究面临着重大挑战。缺乏显式时间特征的系统在对齐和可控性上表现不佳，而基于时间戳的模型则需要昂贵且主观的人工注释。", "innovation": "本文提出了一种名为Video-Foley的视频到声音系统，使用Root Mean Square (RMS) 作为直观条件，并结合语义音色提示（音频或文本）。RMS作为一种与音频语义紧密相关的帧级强度包络，在指导视频生成音频的过程中作为一个时间事件特征。该无监督框架分为两个阶段：Video2RMS和RMS2Sound，其中包含RMS离散化和RMS-ControlNet的新思潮，以及一个预训练的文本到音频模型。", "conclusion": "我们的广泛评估表明，Video-Foley在音频-视觉对齐和声音时间、强度、音色和细微之处的可控性方面均达到最先进的性能。有关源代码、模型权重和演示的资料可在我们的配套网站上获取。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.07032", "html_url": "https://arxiv.org/abs/2506.07032", "title": "多元文化多语言多模态视频基准与模型", "title_en": "A Culturally-diverse Multilingual Multimodal Video Benchmark & Model", "authors": "Bhuiyan Sanjid Shafique,Ashmal Vayani,Muhammad Maaz,Hanoona Abdul Rasheed,Dinura Dissanayake,Mohammed Irfan Kurpath,Yahya Hmaiti,Go Inoue,Jean Lahoud,Md. Safirur Rashid,Shadid Intisar Quasem,Maheen Fatima,Franco Vidal,Mykola Maslych,Ketan Pravin More,Sanoojan Baliah,Hasindri Watawana,Yuhao Li,Fabian Farestam,Leon Schaller,Roman Tymtsiv,Simon Weber,Hisham Cholakkal,Ivan Laptev,Shin'ichi Satoh,Michael Felsberg,Mubarak Shah,Salman Khan,Fahad Shahbaz Khan", "background": "大型多模态模型（LMMs）因为能够理解和生成视觉内容的描述，最近引起了广泛关注。目前的大多数LMMs都使用英语。尽管最近有一些工作探索了多语言图像LMMs，但使用多种语言的视频LMMs的研究仍需进一步深入，以确保具备文化和语言包容性。", "innovation": "本文提出了一个名为ViMUL-Bench的多语言视频LMM基准，用于评估14种不同语言的视频LMM，并引入了一个机器翻译的多语言视频训练集，以及开发了一个简单的多语言视频LMM模型ViMUL，以更好地平衡视频理解中高低资源语言之间的关系。", "conclusion": "我们希望ViMUL-Bench及多语言视频LMM模型和大规模多语言视频训练数据能够促进未来研究，以发展具备文化和语言包容性的多语言视频LMMs。我们的提议的基准、视频LMM和训练数据将被公众公开发布。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.02668", "html_url": "https://arxiv.org/abs/2507.02668", "title": "MEGANet-W：一种针对弱边界息肉检测的小波导向边缘引导注意力框架", "title_en": "MEGANet-W: A Wavelet-Driven Edge-Guided Attention Framework for Weak Boundary Polyp Detection", "authors": "Zhe Yee Tan,Ashwaq Qasem", "background": "结肠息肉分割对于早期发现结肠癌至关重要，然而模糊的边缘细节和低对比度边界显著限制了自动化的准确性。现有的深度模型要么模糊细边缘细节，要么依赖表现不佳的手工制作滤波器。", "innovation": "提出了MEGANet-W，这是一种小波导向的边缘引导注意力网络，通过在每个解码器阶段注入方向性且无参数的豪教育宇波边缘图，重新校准语义特征。MEGANet-W的关键创新包括多方向边缘提取的双层豪教育宇波头；以及边缘引导注意力（W-EGA）模块，该模块将小波线索与边界输入分支结合。", "conclusion": "在五个公开的息肉数据集上，MEGANet-W 始终优于现有方法，mIoU 提高了最多 2.3%，mDice 提高了 1.2%，同时没有增加任何可学习参数。此方法在困难情况下提高了可靠性，并为需要精确边界检测的医学图像分割任务提供了一种稳健的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13425", "html_url": "https://arxiv.org/abs/2509.13425", "title": "统一时空物理信息学习框架（USPIL）：建模复杂捕食者-猎物动态的框架", "title_en": "Unified Spatiotemopral Physics-Informed Learning (USPIL): A Framework for Modeling Complex Predator-Prey Dynamics", "authors": "Julian Evan Chrisnanto,Yulison Herry Chrisnanto,Ferry Faizal", "background": "生态系统的动力学表现出复杂的跨尺度动态，这挑战了传统的建模方法。新方法必须能够捕捉到时间上的振荡和时空上的涌现模式，同时遵循保护原则。传统的建模方法在跨尺度建模方面存在局限性，而USPIL框架旨在克服这些局限。", "innovation": "USPIL框架是一个结合了物理信息神经网络（PINNs）和保存定律的深度学习架构，用于跨尺度描述捕食者-猎物动力学。该框架通过自动求导来强制执行物理约束，并通过自适应损失加权来平衡数据准确性和物理一致性。USPIL能够在单一神经网络架构中描述时间周期和反应扩散模式。", "conclusion": "USPIL通过确保物理守恒原则和提供10至50倍的计算效率，证明了其强大的能力。它还允许通过可解析的物理约束提供机制理解，有助于参数发现和敏感性分析，这些特性使其成为生态预测、保护规划和了解生态系统韧性的变革性工具，确立了物理信息深度学习作为一种强大的科学严谨范式的地位。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13516", "html_url": "https://arxiv.org/abs/2509.13516", "title": "优化器选择对神经网络训练能耗效率和性能的影响分析", "title_en": "An Analysis of Optimizer Choice on Energy Efficiency and Performance in Neural Network Training", "authors": "Tom Almog", "background": "随着机器学习模型的复杂性和计算需求不断增加，理解培训决策对环境的影响变得至关重要，这对于可持续发展的人工智能至关重要。本研究通过在三个基准数据集（MNIST, CIFAR-10, CIFAR-100）上进行360次受控实验，并使用8种常见优化器（SGD、Adam、AdamW、RMSprop、Adagrad、Adadelta、Adamax、NAdam）进行了详细的实证研究，探讨了优化器选择与神经网络训练能耗效率之间的关系。", "innovation": "使用CodeCarbon在Apple M1 Pro硬件上进行了精确的能量追踪，评估了训练时长、峰值内存使用、碳排放和最终模型性能。研究发现，不同的优化器在训练速度、准确性和环境影响之间存在不同的权衡。AdamW和NAdam被识别为始终高效的选择，而尽管碳排放较高，SGD在复杂数据集上表现更优。这些结果为追求性能和可持续性的机器学习工作者提供了实用的见解。", "conclusion": "研究揭示了在不同数据集和模型复杂度下，训练速度、准确性和环境影响之间的复杂权衡。AdamW和NAdam被确定为始终高效的优化器选择，而SGD在复杂数据集上表现出色。总的来说，这些结果为机器学习工作流程中的性能和可持续性平衡提供了实际指导。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13520", "html_url": "https://arxiv.org/abs/2509.13520", "title": "学习PET瓶膨胀的混合DeepONet-Transolver框架中的非线性响应", "title_en": "Learning Nonlinear Responses in PET Bottle Buckling with a Hybrid DeepONet-Transolver Framework", "authors": "Varun Kumar,Jing Bi,Cyril Ngo Ngoc,Victor Oancea,George Em Karniadakis", "background": "近年来，神经代理和操作网络在解决偏微分方程（PDE）问题方面引起了广泛关注。然而，现有方法大多无法在变化的非参数几何域中泛化解决方案。本文针对这一挑战，以聚对苯二甲酸乙二醇酯（PET）瓶的屈曲分析为例，这一代表性的包装设计问题通常使用计算密集型的有限元分析（FEA）解决。研究构建了一种混合DeepONet-Transolver框架，同时预测节点位移场和顶部加载压缩过程中反应力的时间演变。", "innovation": "本文提出了一种混合DeepONet-Transolver框架，该框架能够在两种和四种设计变量参数化的两种瓶形家族上进行训练。通过生成来自Abaqus的254种独特设计的非线性FEA模拟数据，该模型实现的平均相对$L^2$误差分别为2.5-13%的位移场和约2.4%的时间依赖性反应力，点误差分析还显示绝对位移误差在$10^{-4}$-$10^{-3}$范围内，主要的不一致性集中在局部几何区域。模型能够准确捕捉复杂瓶形中的关键物理现象，如屈曲行为。", "conclusion": "研究结果表明，本文提出的框架具有潜在的应用价值，可以作为可扩展且计算高效的代理模型，特别是在计算力学的多任务预测和需要快速设计评估的应用中。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.11417", "html_url": "https://arxiv.org/abs/2509.11417", "title": "通过保留预训练表示来增强视觉-语言-行动模型的一般性", "title_en": "Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations", "authors": "Shresth Grover,Akshay Gopalkrishnan,Bo Ai,Henrik I. Christensen,Hao Su,Xuanlin Li", "background": "视觉-语言-行动（VLA）模型通过从预训练的视觉-语言模型（VLMs）中微调，有潜力构建多任务、跨环境的通用机器人。然而，直接在机器人数据上进行微调往往会破坏这些预训练表示，限制了泛化能力。", "innovation": "该研究提出了一种框架，旨在更好地保留预训练特征，并使它们适应机器人操作。其创新点包括：(i) 双编码器设计，其中一个冻结的视觉编码器保留预训练特征，另一个可训练编码器进行任务适应；(ii) 字符串基操作分词器，将连续动作转换为与模型预训练领域对齐的字符序列；(iii) 结合机器人演示与侧重空间推理和能动性视觉-语言数据集的协同训练策略。实验结果显示，该方法在视觉干扰下的鲁棒性、对新指令和环境的泛化以及整体任务成功率上优于基线方法。", "conclusion": "该研究通过开辟保留预训练表示的方法，增强了视觉-语言-行动模型在模拟和实际机器人中的表现，展示了更强大的适应性、泛化能力和任务成功率。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.13301", "html_url": "https://arxiv.org/abs/2509.13301", "title": "StyleSculptor：基于纹理和几何双重指导的零样本风格可控3D资产生成", "title_en": "StyleSculptor: Zero-Shot Style-Controllable 3D Asset Generation with Texture-Geometry Dual Guidance", "authors": "Zefan Qu,Zhenwei Wang,Haoyuan Wang,Ke Xu,Gerhard Hancke,Rynson W.H. Lau", "background": "在实际应用中，如电子游戏和虚拟现实，创建与现有资产在纹理和几何风格上保持一致的3D资产往往是有必要或不可避免的。虽然在从文本或图像生成3D对象方面取得了令人瞩目的进展，但如何生成具有风格控制的3D资产仍然面临复杂性和挑战性的问题。StyleSculptor是一个新型的无需训练的方法，可以从内容图像和一个或多个风格图像生成风格导向的3D资产。StyleSculptor通过跨3D注意机制和风格解纠缠特征选择策略，实现了一种零样本风格导向的3D生成方法，可以捕捉用户提供的风格图像的纹理、几何或两者风格，提供了细粒度的3D风格控制能力。它通过Style Disentangled Attention (SD-Attn)模块和Style Guided Control (SGC)机制实现稳定的功能融合和有效的风格导向的生成。通过深入研究和实验，StyleSculptor在生成高保真度3D资产方面的表现优于现有的基准方法。", "innovation": "StyleSculptor提出了一种无需训练的风格导向3D生成方法，通过Style Disentangled Attention (SD-Attn)模块和Style Guided Control (SGC)机制实现了稳定的功能融合和有效的风格导向的生成。SD-Attn模块引入了风格解纠缠特征选择策略，可以在注意力框架内选择性地注入特征，从而动态计算纹理、几何或两者导向的功能，以引导3D生成过程。此外，SGC机制使StyleSculptor能够实现独立试验导向或几何导向的样式化，同时实现风格强度的可调控制。论文表明，StyleSculptor在生成高保真度3D资产方面优于现有的基准方法", "conclusion": "StyleSculptor在生成高保真度3D资产方面表现优越，它提供了一种零样本风格导向的3D生成方法，可以稳定地引导3D生成过程，实现细粒度的风格控制。通过Style Disentangled Attention (SD-Attn)和Style Guided Control (SGC)，它可以捕捉并生成具有纹理和几何风格特征的3D资产，其性能优越于现有的基准方法。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13527", "html_url": "https://arxiv.org/abs/2509.13527", "title": "分子性质预测的元学习线性模型", "title_en": "Meta-Learning Linear Models for Molecular Property Prediction", "authors": "Yulia Pimonova,Michael G. Taylor,Alice Allen,Ping Yang,Nicholas Lubbers", "background": "化学家寻找结构-性质关系面临巨大挑战，由于可用的高质量一致性数据集有限。尽管机器学习（ML）在化学科学中显著提升了预测能力，但这种现代数据驱动的方法却增加了数据需求。为了应对解释性人工智能（XAI）的需求增长，以及预测准确性和人类可解释性之间的差距，我们介绍了LAMeL-一种线性元学习算法，能够在保持可解释性的同时提高跨多个性质的预测准确性。", "innovation": "LAMeL通过元学习框架识别相关任务中的共享模型参数，即使这些任务不共享数据，也能学习一个更为知情的起点，适用于新的未见过的任务。该方法在不同数据集领域比标准岭回归提供了1.1到25倍的性能提升，虽然在不同任务上的表现有所差异，但LAMeL始终超越或匹配传统的线性方法，成为一个在准确性和可解释性都至关重要的化学性质预测中值得信赖的工具。", "conclusion": "LAMeL在解释性和预测准确性之间找到了平衡，能够在分子性质预测中提供显著的性能提升，是一个值得信赖的工具，特别是在准确性和可解释性都至关重要的应用场景中。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13621", "html_url": "https://arxiv.org/abs/2509.13621", "title": "在ALS EPICS事件日志中进行无监督异常检测", "title_en": "Unsupervised Anomaly Detection in ALS EPICS Event Logs", "authors": "Antonin Sulc,Thorsten Hellert,Steven Hunt", "background": "本文提出了一个自动故障分析框架，用于处理先进光源（ALS）的EPICS控制系统的实时事件日志。通过将日志条目视为自然语言，并使用语义嵌入技术将它们转化为基于上下文的向量表示，该框架能够识别与正常操作行为不符的情况。通过在正常操作数据上训练序列感知神经网络，该框架可以为每个事件实时分配异常得分，帮助操作员快速识别先于复杂系统故障的关键事件序列。", "innovation": "该论文创新性地将语义嵌入技术应用于处理EPICS控制系统的实时事件日志，并通过训练序列感知神经网络实时计算异常得分，从而可以自动识别和高风险事件并进行快速响应，有效提高了系统的故障检测和维护效率。", "conclusion": "该框架能够通过实时分析事件日志中的异常行为，提高故障检测的效率和准确性，为操作员提供了关键事件序列的快速识别能力，从而减轻了系统维护的负担并降低了运行风险。通过这种方法，可以有效预防复杂系统故障的发生，进一步保障了ALS的稳定运行。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.17600", "html_url": "https://arxiv.org/abs/2508.17600", "title": "GWM: Towards Scalable Gaussian World Models for Robotic Manipulation", "title_en": "GWM: Towards Scalable Gaussian World Models for Robotic Manipulation", "authors": "Guanxing Lu,Baoxiong Jia,Puhao Li,Yixin Chen,Ziwei Wang,Yansong Tang,Siyuan Huang", "background": "由于现实世界交互的低效率，训练机器人策略嵌入在学习的世界模型中正在成为一个趋势。现有的基于图像的世界模型和策略虽然获得了早期的成功，但在提供精确的几何信息方面存在不足，这需要空间和物理理解的一致性。即使基于大规模互联网视频，也难以提供这类信息。因此，需要一种能够更好地捕捉3D空间中物体和环境动态变化的世界模型来提高机器人的操作能力。", "innovation": "本文提出了一种新的世界模型分支，即高斯世界模型（GWM），用于机器人的操作任务。GWM通过假设机器人动作的影响下高斯原语（Gaussian primitives）的传播来重建未来状态。核心采用了潜扩散变换器（DiT）和3D变量自动编码器的组合，实现了精细的未来状态重建，改进了视觉表示并支持基于模型的强化学习。GWM不仅可以用作用于模仿学习的神经模拟器，还可以直接训练超越现有最好的策略，展示了3D世界模型数据扩展的初步潜力。", "conclusion": "通过实验结果可以看出，GWM在基于多样化机器人动作的未来场景预测中表现出色，并且能够训练出在与其他先进的方法对比中表现更优的策略。这展示了基于3D世界模型的数据扩展潜力，为机器人操作提供了更高效的数据支持。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13633", "html_url": "https://arxiv.org/abs/2509.13633", "title": "DeepLogit：一种用于运输政策分析的顺序约束可解释深度学习建模方法", "title_en": "DeepLogit: A sequentially constrained explainable deep learning modeling approach for transport policy analysis", "authors": "Jeremy Oon,Rakhi Manohar Mepparambath,Ling Feng", "background": "尽管深度学习模型在众多应用中取得了显著进展，但在规划和政策制定相关的领域中的应用仍面临挑战，主要原因是这些模型的“黑箱”性质。本文提出了一种新的顺序约束方法，通过该方法可构建适合运输政策分析的深度逻辑模型。", "innovation": "提出了一种名为DeepLogit的方法，该方法采用顺序约束策略，首先估计一个仅包含线性项的卷积神经网络模型，等同于具有参数线性形式的多项式逻辑模型，然后通过将其参数限制为这些初始模型获得的值，同时包扩其他高阶术语或使用高级的深度学习架构（如变压器）来估计其他深度学习模型。这种方法保留了所选参数的可解释性，同时显著提高了模型的准确性。", "conclusion": "本文通过实证数据展示了这种方法的应用，强调了结合基于理论的离散选择模型（DCM）和数据驱动的人工智能模型在可解释性和预测能力方面的优势。在更大的数据集和更复杂的构建可用的情况下，这种方法可以更准确地利用离散选择模型的特性，并保持其在规划和政策相关领域的应用。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13608", "html_url": "https://arxiv.org/abs/2509.13608", "title": "GPT-4o mini 的安全过滤器使其失明了吗？揭示有害言论检测中的多模态到单模态瓶颈", "title_en": "Is GPT-4o mini Blinded by its Own Safety Filters? Exposing the Multimodal-to-Unimodal Bottleneck in Hate Speech Detection", "authors": "Niruthiha Selvanayagam,Ted Kurti", "background": "随着大型多模态模型（LMMs）在日常生活中的重要性日益增加，如何确保这些模型的安全性对于AI对齐至关重要。本文通过分析OpenAI的GPT-4o mini模型在全球部署中的多模态仇恨言论检测困难任务，来探索其安全架构。研究基于Hateful Memes Challenge数据集，对500个样本进行了多阶段分析，揭示了模型推理和失败模式。", "innovation": "研究通过定量验证144个内容政策拒绝，识别出一种“单模态瓶颈”架构缺陷，即模型的高级多模态推理被无上下文安全过滤器系统性地中断。研究还表明该安全系统脆弱性，不仅阻止高风险图像，还阻止常见的图形式模板，导致误判。", "conclusion": "本文暴露了尖端LMMs中能力和安全性之间的基本矛盾，强调需要更集成和上下文感知的对齐策略来确保AI系统既能安全又能有效部署。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13625", "html_url": "https://arxiv.org/abs/2509.13625", "title": "大型语言模型中的隐私感知上下文学习", "title_en": "Privacy-Aware In-Context Learning for Large Language Models", "authors": "Bishnu Bhusal,Manoj Acharya,Ramneet Kaur,Colin Samplawski,Anirban Roy,Adam D. Cobb,Rohit Chadha,Susmit Jha", "background": "大型语言模型(LLMs)极大地改变了自然语言的理解和生成，但它们可能会因潜在的敏感信息暴露问题而引发隐私担忧。已有研究指出，攻击者可以从输入提示中提取敏感信息，存在信息泄露的风险。鉴于此，本文旨在介绍一种能够生成高质量合成文本并具有较强隐私保证的新型隐私预测框架。", "innovation": "本文提出了一种基于差分隐私(DP)框架的新型隐私预测模型，能够在不对底层模型进行微调的情况下提供最坏情况下的信息泄露理论界限。该方法在进行隐私记录推理并将结果加权汇总后进行文本生成，从而既能生成较长且连贯的合成文本，又能保证隐私。此外，本文还提出了一种简单的混合操作，将隐私推理与公共推理结合，进一步提高模型的实用性。", "conclusion": "实验结果表明，本文提出的策略在上下文学习任务(In-Context Learning, ICL)上优于之前的所有先进方法，为兼具高实用性与隐私保护的文本生成提供了新的方向。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13648", "html_url": "https://arxiv.org/abs/2509.13648", "title": "序列为生成推荐的增广数据", "title_en": "Sequential Data Augmentation for Generative Recommendation", "authors": "Geon Lee,Bhuvesh Kumar,Clark Mingxuan Ju,Tong Zhao,Kijung Shin,Neil Shah,Liam Collins", "background": "生成推荐在个性化系统中发挥着关键作用，通过预测用户的未来交互行为来重建用户的历史行为序列。然而，在训练这些模型的过程中，数据增广这一至关重要的但尚未充分探索的因素常被简化或不一致性地应用，缺乏系统和原则性的理解。我们通过实验发现，不同的增广策略会导致性能的巨大差异，因此深入分析了它们如何重塑训练分布并影响与未来目标的对齐及对未见输入的泛化能力。", "innovation": "我们提出了一个名为GenPAS的通用且原则性的框架，它将数据增广视为在输入-目标对上进行随机采样的过程，并包含三个带有偏置控制的步骤：序列采样、目标采样和输入采样。这种框架将广泛使用的策略作为特殊情况加以统一，并允许灵活控制最终的训练分布。我们对基准和工业数据集的广泛实验表明，GenPAS在准确性、数据效率和参数效率方面均优于现有策略，为生成推荐的训练数据构建提供了一种有实践意义的指导。", "conclusion": "我们的研究表明，GenPAS在推荐系统中的应用能够显著提升模型的性能、数据使用效率和参数效率，为生成推荐提供了更好的训练数据构建方案，并为这一领域的进一步研究提供了坚实的理论基础。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13686", "html_url": "https://arxiv.org/abs/2509.13686", "title": "RF-LSCM: 推进辐射场到多域局部统计信道建模的蜂窝网络优化", "title_en": "RF-LSCM: Pushing Radiance Fields to Multi-Domain Localized Statistical Channel Modeling for Cellular Network Optimization", "authors": "Bingsheng Peng,Shutao Zhang,Xi Zheng,Ye Xue,Xinyu Qin,Tsung-Hui Chang", "background": "准确的局部无线信道模型是蜂窝网络优化的核心，有助于预测网络性能。传统的局部统计信道模型（LSCM）方法依赖于参考信号接收功率（RSRP）测量推断信道的角功率谱（APS），但这些方法通常局限于单小区、单网格和单载波频率分析，无法捕捉跨领域的复杂交互。", "innovation": "本文提出了一种新的RF-LSCM框架，通过联合表示大尺度信号衰减和多径分量在辐射场中对信道APS进行建模，引入了基于物理的频率依赖性衰减模型（FDAM）以促进频率通用性，并采用点云辅助环境增强方法来支持多小区和多网格信道建模。此外，为了克服典型神经辐射场的计算效率低的问题，RF-LSCM利用低秩张量表示和新提出的分层张量角度建模（HiTAM）算法进行优化。", "conclusion": "在真实多小区数据集上的广泛实验表明，RF-LSCM显著优于现有最先进的方法，预测覆盖范围的均方误差（MAE）可降低30%，并通过有效融合多频率数据，MAE提高了22%。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13523", "html_url": "https://arxiv.org/abs/2509.13523", "title": "AERIS: 诺障纳地球系统模型，以实现可靠的预测", "title_en": "AERIS: Argonne Earth Systems Model for Reliable and Skillful Predictions", "authors": "Väinö Hatanpää,Eugene Ku,Jason Stock,Murali Emani,Sam Foreman,Chunyong Jung,Sandeep Madireddy,Tung Nguyen,Varuni Sastry,Ray A. O. Sinurat,Sam Wheeler,Huihuo Zheng,Troy Arcomano,Venkatram Vishwanath,Rao Kotamarthi", "background": "生成式的机器学习为更好地理解复杂的地球系统动态提供了新的机会。最近基于扩散的方法克服了光谱偏见，提升了气象预报的集合校准，相比确定性方法获得了更好的表现，但这些方法在高分辨率下难以稳定扩展。", "innovation": "引入了AERIS，这是一种从1.3到80B参数的像素级Swin扩散转换器，以及SWiPe，这是一种可扩展的技术，能够将窗口并行性与序列和管道并行性结合，从而在不影响通信成本或增加全球批量大小的情况下分割窗口基变换器。AERIS在Aurora平台上实现了10.21 ExaFLOPS（混合精度）的持续性能，峰值为11.21 ExaFLOPS，并在0.25° ERA5数据集上使用1×1的块大小，实现了95.5%的弱缩放效率和81.6%的强缩放效率。", "conclusion": "AERIS在季节性尺度上稳定性良好，可持续至90天，突显了十亿参数扩散模型在天气和气候预测中的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13636", "html_url": "https://arxiv.org/abs/2509.13636", "title": "使用深度神经网络进行压力检测的多模态信号融合：一种将1D信号转换为统一2D图像的新方法", "title_en": "Multimodal signal fusion for stress detection using deep neural networks: a novel approach for converting 1D signals to unified 2D images", "authors": "Yasin Hasanpoor,Bahram Tarvirdizadeh,Khalil Alipour,Mohammad Ghamari", "background": "传统上，处理多模态生理信号（如光电导图（PPG）、皮肤导电反应（GSR）和加速度（ACC））的方法是独立处理或依赖于固定的编码方式。这种方法难以同时捕捉这些信号之间的时域和跨信号依赖关系，从而影响了压力检测的准确性。为了克服这些问题，研究引入了一种将这些1D信号转化为2D图像矩阵的新方法，然后利用卷积神经网络（CNN）来提升压力检测的效果。这不仅提高了解释性，还作为数据增强的一种稳健形式，进一步提高了一般化能力和模型的鲁棒性。该方法通过系统地重新组织融合信号并结合多阶段训练管道来实现。该方法被证明在压力检测中的有效性使其适用于任何涉及多模态生理信号的领域，为通过可穿戴技术实现更准确、个性化和实时的健康监测开辟了道路。", "innovation": "本研究提出了一种新的方法，即将多模态生理信号（PPG、GSR和ACC）转换为2D图像矩阵，利用CNN进行压力检测。与传统方法相比，该技术将这些信号融合成结构化的图像表示，使得CNN能够更有效地捕捉时间和跨信号的依赖关系。此外，该方法通过系统地重新组织融合信号并结合多阶段训练管道来进一步提升分类性能和模型的稳健性。这种方法不仅提高了可解释性，还作为一种稳健的数据增强方法，用于提升一般化能力。该方法适用于任何涉及多模态生理信号的领域，为实时健康监测提供了新的可能性。", "conclusion": "该研究通过将多模态生理信号转化为2D图像矩阵，结合CNN实现压力检测的方法显著提升了分类性能。这种方法不仅提高了模型的可解释性和鲁棒性，还适用于多模态生理信号检测的各个领域，为实时健康监测提供了新的技术途径。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13651", "html_url": "https://arxiv.org/abs/2509.13651", "title": "Controllable Pareto Trade-off between Fairness and Accuracy", "title_en": "Controllable Pareto Trade-off between Fairness and Accuracy", "authors": "Yongkang Du,Jieyu Zhao,Yijun Yang,Tianyi Zhou", "background": "在自然语言处理（NLP）任务中，公平性和准确性之间的权衡是一个关键挑战。当前的研究主要集中在寻找一种单一的最优解以平衡这两个目标，但这种方法限制了多样化的解决方案集合，即帕累托前沿。这项工作旨在根据用户的偏好提供可控的权衡，定义为参考向量。使用多目标优化方法（MOO）可以从帕累托前沿的不同区域找到解决方案，但由于训练过程的随机性和高维梯度向量，精确控制权衡是具有挑战性的。因此，研究提出了可控帕累托权衡（CPT），一种能够根据用户偏好有效训练模型以执行不同权衡的方法。CPT通过移动平均的随机梯度稳定公平性更新，并通过仅保留关键参数的梯度来剪枝梯度。实验结果表明，CPT在帕累托前沿上可以实现比基线方法更高的质量解集，并且具有更好的可控性，可以精确跟随人类定义的参考向量。", "innovation": "引入了可控帕累托权衡（CPT）方法。CPT通过使用移动平均的随机梯度来稳定公平性更新，并通过剪枝关键参数的梯度来优化训练过程。该方法能够在帕累托前沿上根据用户的偏好执行不同级别的公平性和准确性的权衡。", "conclusion": "研究表明，CPT方法不仅能够提供更好的质量解决方案，还能够精确地跟随由人类定义的参考向量，从而展示了更好的可控性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13725", "html_url": "https://arxiv.org/abs/2509.13725", "title": "WatchAnxiety：从智能手表数据预测即时焦虑的一种迁移学习方法", "title_en": "WatchAnxiety: A Transfer Learning Approach for State Anxiety Prediction from Smartwatch Data", "authors": "Md Sabbir Ahmed,Noah French,Mark Rucker,Zhiyuan Wang,Taylor Myers-Brower,Kaitlyn Petz,Mehdi Boukhechba,Bethany A. Teachman,Laura E. Barnes", "background": "社交焦虑是一种与学习、社交和职业功能障碍密切相关的精神健康状况。主要特征是在社交场合中出现较高的短暂焦虑，但之前的研究很少关注这种焦虑在一天中的波动情况。了解这种日内的动态变化对于设计实时个性化干预措施至关重要。这项研究旨在量化和预测这一焦虑状态的波动。", "innovation": "研究通过开发一种基于智能手表的系统，采用迁移学习的方法，从外部心率数据中提取特征并适应数据集，实现了对社交焦虑状态的预测。与现有研究相比，该方法在评估通用性时表现出显著的性能提升。", "conclusion": "该研究的机器学习管道在预测社交焦虑状态方面达到了60.4%的平衡准确率，方法在另一个数据集上的表现优于现有工作，准确率达到59.1%，这是一个重要的改进。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13634", "html_url": "https://arxiv.org/abs/2509.13634", "title": "安全的无人机辅助联邦学习：基于零知识证明的数字孪生驱动方法", "title_en": "Secure UAV-assisted Federated Learning: A Digital Twin-Driven Approach with Zero-Knowledge Proofs", "authors": "Md Bokhtiar Al Zami,Md Raihan Uddin,Dinh C. Nguyen", "background": "联邦学习（FL）作为一种在分散网络上训练机器学习模型的隐私保护方法而受到关注。然而，要确保无人机辅助的FL系统的可靠运行，需要解决诸如能源消耗过大、通信效率低下和安全漏洞等问题。", "innovation": "本文提出了一种创新框架，该框架结合了数字孪生（DT）技术和零知识联邦学习（zkFed）以应对上述挑战。无人机作为移动基站，使分散设备能够进行局部模型训练并上传模型更新进行聚合。通过引入DT技术，该方法能够实现系统实时监控和预测维护，提高无人机网络的效率。此外，零知识证明（ZKP）通过允许模型验证而不暴露敏感数据来增强安全性。为了优化能源效率和资源管理，提出了一种动态分配策略，该策略根据网络条件调整无人机飞行路径、传输功率和处理速率。该方法利用块坐标下降和凸优化技术，系统能耗降低了29.6%，相比传统的FL方法效果显著。", "conclusion": "仿真结果表明，该方法在学习性能、安全性和可扩展性方面具有改进效果，表明该框架是下一代基于无人机的智能网络的有前途的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13642", "html_url": "https://arxiv.org/abs/2509.13642", "title": "LLM-I: LLMs are Naturally Interleaved Multimodal Creators", "title_en": "LLM-I: LLMs are Naturally Interleaved Multimodal Creators", "authors": "Zirun Guo,Feng Zhang,Kai Jia,Tao Jin", "background": "当前的统一模型在多模态图像-文本生成方面存在局限性，主要局限于合成图像，并且在需要事实依据或程序精确性的任务上表现不佳。", "innovation": "LLM-Interleaved (LLM-I) 提供了一个灵活且动态的框架，将多模态图像-文本生成重新定义为一种工具使用问题。LLM-I 能够使中央LLM或MLLM代理智能地协调使用多种专业的视觉工具，包括在线图像搜索、基于扩散的生成、代码执行和图像编辑。通过结合基于规则的逻辑和LLM/MLLM评估器的判断，使用强化学习（RL）框架来训练代理智能地选择和应用这些工具。", "conclusion": "LLM-I 在四个不同的基准测试上展示了最先进的性能，与现有方法相比有显著的改进。还引入了一种新的测试时间扩展策略，提供了进一步的性能提升。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13717", "html_url": "https://arxiv.org/abs/2509.13717", "title": "基于配准预测的物理感知神经网络不确定性量化框架", "title_en": "A Conformal Prediction Framework for Uncertainty Quantification in Physics-Informed Neural Networks", "authors": "Yifan Yu,Cheuk Hin Ho,Yangshuai Wang", "background": "物理感知神经网络（PINNs）已成为解决偏微分方程（PDEs）的强大框架，现有的PINNs的不确定性量化（UQ）方法通常缺乏严谨的统计保证。本文旨在弥补这一不足，通过引入基于配准预测的不确定性量化框架，解决了这一问题。", "innovation": "本文提出了一个基于配准预测的UQ框架，通过在验证集中构建非一致性分数来校准预测区间，从而为PINNs提供严格的有限样本覆盖率保证。此外，我们还引入了局部一致性分位数估计，以适应空间异方差性并保留理论保证，实现了可靠校准和局部自适应不确定性区间，整体上优于启发式UQ方法。", "conclusion": "通过将PINNs与分布无关的UQ相结合，本文提出了一个通用框架，不仅增强了校准和可靠性，还为复杂PDE系统的不确定性感知建模开启了新途径。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21233", "html_url": "https://arxiv.org/abs/2505.21233", "title": "CROP: 通过上下文区域导向的视觉标记修剪", "title_en": "CROP: Contextual Region-Oriented Visual Token Pruning", "authors": "Jiawei Guo,Feifei Zhai,Pu Jian,Qianrun Wei,Yu Zhou", "background": "当前基于视觉语言模型（VLM）的视觉问答（VQA）方法通常处理整个图像，这会导致包含与提出的问题无关的冗余信息的过多视觉标记。这些多余的视觉细节导致在VLMs中占用更多内存和计算资源。", "innovation": "提出了一种名为Contextual Region-Oriented Visual Token Pruning (CROP)的新框架，通过两步过程（定位和修剪）压缩视觉标记：首先，使用高效模型识别与输入查询相关的上下文区域；其次，引入两种修剪策略：(1) 预LLM压缩（PLC），根据不同图像区域采用不同的压缩比例；(2) 内LLM修剪（ILP），这是一种无需训练的方法，在早期LLM层中通过识别的上下文区域指导修剪标记。", "conclusion": "广泛的实验表明，CROP在多种VQA任务上显著优于现有视觉标记修剪方法，并达到了最先进的性能。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13735", "html_url": "https://arxiv.org/abs/2509.13735", "title": "有向图上的状态空间模型", "title_en": "State Space Models over Directed Graphs", "authors": "Junzhi She,Xunkai Li,Rong-Hua Li,Guoren Wang", "background": "有向图在多个领域普遍存在，边的方向性表示关键的因果依赖关系。然而，现有的针对有向图的图神经网络（GNNs）和图Transformer面临两大挑战：一是准确捕捉由有向边衍生出的长距离因果依赖关系；二是处理大规模图数据集时在准确性和训练效率之间取得平衡。现有的状态空间模型（SSMs）在因果序列任务中取得了显著进展，而设计用于图的变体在各种图学习基准测试中显示了最先进的准确率，同时保持高效能。但现有的图状态空间模型仅适用于无向图，限制了其在有向图学习中的性能提升。", "innovation": "本文提出了一种创新方法DirEgo2Token，通过k跳ego图对有向图进行序列化处理。这是首次系统地将状态空间模型扩展到有向图学习领域。基于此，开发了一种新的有向图神经网络（DirGraphSSM）架构，该架构通过消息传递机制在有向图上实现了状态空间模型。实验结果表明，DirGraphSSM在三个代表性有向图学习任务上取得了最先进的性能，并在两个额外任务上以1.5到2倍的训练速度改进与现有最先进的模型实现了可竞争的性能表现", "conclusion": "DirGraphSSM在三个代表性有向图学习任务上取得了最先进的性能，并在两个额外任务上实现了显著的训练速度改进，达到了可竞争的性能表现。这标志着状态空间模型在有向图学习领域的首次系统性应用。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13739", "html_url": "https://arxiv.org/abs/2509.13739", "title": "ParaAegis: 并行保护以实现灵活的隐私保留联邦学习", "title_en": "ParaAegis: Parallel Protection for Flexible Privacy-preserved Federated Learning", "authors": "Zihou Wu(1),Yuecheng Li(1),Tianchi Liao(2),Jian Lou(2),Chuan Chen(1) ((1) School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China (2) School of Software Engineering, Sun Yat-sen University, Zhuhai, China)", "background": "联邦学习（FL）面临一个关键困境：现有保护机制如差分隐私（DP）和同态加密（HE）会强制在模型用处和计算效率之间做出僵化的取舍，这限制了其实用性实施。现有方法的这种缺乏灵活性带来了挑战。", "innovation": "我们提出了ParaAegis，一种并行保护框架，旨在给予实践者灵活控制隐私-效用-效率平衡的能力。核心创新在于一种策略性模型分区方案。通过将轻量级的DP应用到模型中较不关键、低范数的部分，同时用HE保护该模型的其余部分，构建了一个可调系统。分布式投票机制确保对分区达成共识。理论分析确认了效率和效用之间的调整在相同的隐私保护条件下是可行的。", "conclusion": "实验结果展示了通过调整超参数，我们的方法能够在模型准确性和训练时间之间实现灵活的优先级设定。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13753", "html_url": "https://arxiv.org/abs/2509.13753", "title": "ST-LINK: 空间感知的大语言模型用于时空预测", "title_en": "ST-LINK: Spatially-Aware Large Language Models for Spatio-Temporal Forecasting", "authors": "Hyotaek Jeon,Hyunwook Lee,Juwon Kim,Sungahn Ko", "background": "交通预测是智能交通系统中的一个关键问题。近年来，大型语言模型（LLMs）被视为一种有前景的方法，但它们的设计主要针对序列令牌处理，这在有效捕捉空间依赖性方面带来了显著挑战。特别是，LLMs在建模空间关系方面的固有限制及其与图结构的空间数据的架构不兼容性仍被忽视。为了克服这些限制，我们提出了ST-LINK，这是一种新颖的框架，旨在增强大型语言模型在捕捉时空依赖性方面的能力。其核心组件包括空间增强注意力（SE-Attention）和记忆检索前馈网络（MRFFN）。SE-Attention扩展了旋转位置嵌入，将其纳入注意力机制，以直接旋转变换的形式整合空间相关性。这种方法最大限度地提高了空间学习能力，同时保持了LLM的固有顺序处理结构。同时，MRFFN动态检索并利用关键历史模式，以捕捉复杂的长期依赖性，从而提高长期预测的稳定性。在基准数据集上的全面实验表明，ST-LINK超越了传统的深度学习和LLM方法，并有效地捕捉了常规的交通模式和突然变化。", "innovation": "我们提出了一种新颖的框架ST-LINK，它通过扩展旋转位置嵌入，整合空间相关性到注意力机制中，以及通过记忆检索前馈网络动态地捕捉和利用关键历史模式，显著增强了大型语言模型在预测时空依赖性方面的能力。这种方法克服了LLMs在空间关系和图结构空间数据处理方面的固有限制。", "conclusion": "在基准数据集上的全面实验表明，ST-LINK在交通预测任务中超过了传统的深度学习和大型语言模型方法，能够有效捕捉常规的交通模式和突然变化。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13805", "html_url": "https://arxiv.org/abs/2509.13805", "title": "向通用物理基础模型迈进", "title_en": "Towards a Physics Foundation Model", "authors": "Florian Wiesner,Matthias Wessling,Stephen Baek", "background": "基础模型通过“一次性训练，随时随地部署”的模式，已经在自然语言处理中带来了革命性的变化，能够使单一预训练模型通过适应下层任务而不需重新训练。当前的物理感知机器学习方法仍局限在单个窄领域的应用中，且每次需要针对新的系统进行重新训练。因此，构建一个物理基础模型（Physics Foundation Model, PFM）将具有变革性意义，它可以普及高质量的模拟，加速科学研究进程，同时消除特种求解器开发的需求。", "innovation": "该论文提出了通用物理转换器（GPhyT），该模型通过训练1.8 TB的多样化模拟数据，实现基础模型在物理学领域的应用。GPhyT的关键创新在于，通过上下文学习的方式学习推断控制动力学，使得单一模型能够不告诉具体的微分方程模拟流固交互、冲击波、热对流和多相动态。其三大突破分别是：（1）在多个物理领域具备优越的表现，相对专门架构的最高性能提升了29倍，（2）在完全没有见过的物理系统上实现零样本泛化，通过上下文学习，（3）长达50步时间卷积的稳定长期预测。这标志着单一模型能够仅从数据学习可泛化的物理原理，为通用PFM开启了新的道路，有望对计算科学和工程领域产生重大影响。", "conclusion": "该研究通过表明单一模型可以从数据中学习通用物理原理，打开了通向通用物理基础模型的大门，这可能对计算科学和工程产生革命性的变化。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13763", "html_url": "https://arxiv.org/abs/2509.13763", "title": "超越相关性：因果多视角无监督特征选择学习", "title_en": "Beyond Correlation: Causal Multi-View Unsupervised Feature Selection Learning", "authors": "Zongxin Shen,Yanyong Huang,Bin Wang,Jinyuan Chang,Shiyu Liu,Tianrui Li", "background": "多视角无监督特征选择（MUFS）因为其在多视角未标注数据降维方面的潜力受到了越来越多的关注。现有方法通常通过捕捉特征与聚类标签之间的相关性来选择判别性特征，但它们往往忽视了由于混淆变量引起的虚假相关性，导致选择不相关的特征。因此，如何可靠地指导特征选择的问题仍然需要进一步探索和研究.", "innovation": "本文作者提出了首个针对无监督多视角特征选择的因果视角研究，提出了一个新的结构因果模型来揭示现有方法的问题。基于此，提出了一种新型的无监督多视角特征选择方法——因果多视角特征选择学习（CAUSA）。该方法首先使用广义无监督谱回归模型来识别信息特征，通过捕捉特征与一致性聚类标签之间的依赖关系。然后引入因果正则化模块，可以自适应地从多视角数据中分离混淆变量，同时学习视图共享的样本权重以平衡混淆变量分布，从而缓解虚假相关性。最后，将这两种方法整合到一个统一的学习框架中，使CAUSA能够选择因果相关性特征。", "conclusion": "全面的实验表明，CAUSA方法在多个最先进的方法中表现突出。这不仅是对无监督多视角特征选择中因果性的首次深入研究，证明了多视角数据中的因果相关性对抗混淆变量的优势，为特征选择提供了一种新的视角和方法。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13895", "html_url": "https://arxiv.org/abs/2509.13895", "title": "FedSSG：基于期望门控和历史感知的漂移对齐算法", "title_en": "FedSSG: Expectation-Gated and History-Aware Drift Alignment for Federated Learning", "authors": "Zhanting Zhou,Jinshan Lai,Fengchun Zhang,Zeqin Wu,Fengli Zhang", "background": "联邦学习中非IID数据和部分参与导致客户端漂移和局部最优状态不一致，引起收敛不稳定和精度损失。", "innovation": "提出了FedSSG，一种基于随机采样引导、历史感知的漂移对齐方法。FedSSG保持每客户端的漂移记忆，记录局部模型差异作为历史梯度的轻量级草图；通过平滑函数的参与比例观察/预期值（服务器采样器衍生的阶段信息）控制记忆更新和局部对齐项，从而在早期采样噪声主导时保持较弱控制，在参与统计稳定后增强控制，缩小局部-全局差距而无需额外通信。", "conclusion": "FedSSG在多个客户端和参与率下均优于强漂移感知基线，提升测试精度并在目标精度收敛速度上快4.5倍；添加的客户端内存和常规时间开销符合O(d)，在接近IID或均匀采样时表现良好。表明采样统计信息可以转化为可理论化、历史感知的阶段控制，稳定和加速联邦训练过程。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13783", "html_url": "https://arxiv.org/abs/2509.13783", "title": "浮动体水动力神经网络", "title_en": "Floating-Body Hydrodynamic Neural Networks", "authors": "Tianshuo Zhang,Wenzhe Zhai,Rui Yann,Jia Gao,He Cao,Xianglei Xing", "background": "流固耦合在工程和自然系统中普遍存在，浮动体的运动由附加质量、阻力和背景流所支配。模拟这些耗散动力学是困难的：黑盒神经模型用有限的可解释性和不稳定长时间预测进行状态导数回归。这些模型难以理解其内在物理机制，预测长期行为较为困难。", "innovation": "提出了浮动体水动力神经网络（FHNN），这是一种基于物理结构的框架，能够预测可以解释的水动力参数，如方向附加质量和阻力系数，并通过解析方程使其耦合。这种设计限制了假设空间，提高了可解释性，并稳定了积分。与神经ODEs相比，FHNN在合成漩涡数据集上实现比其低一个数量级的误差，可以恢复物理一致性流场。与哈密尔顿和拉格朗日神经网络相比，FHNN更有效地处理耗散动力学，同时保持可解释性，填补了黑盒学习和透明系统识别之间的差距。", "conclusion": "浮动体水动力神经网络（FHNN）提供了一种新的方法，在保持物理可解释性的基础上有效预测耗散动力学，优于现有的黑盒模型，在多个方面取得了显著的突破。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13906", "html_url": "https://arxiv.org/abs/2509.13906", "title": "TFMAdapter：通过引入协变量进行预测的轻量级实例级基础模型适配", "title_en": "TFMAdapter: Lightweight Instance-Level Adaptation of Foundation Models for Forecasting with Covariates", "authors": "Afrin Dange,Sunita Sarawagi", "background": "TSFMs（时间序列基础模型）已经在仅通过少量过去值的历史记录进行单变量预测方面达到了最先进的性能。这些模型的成功表明，大规模预训练可以跨多个领域获得能够从短暂历史中的时间模式中泛化的归纳偏置。然而，大多数TSFMs无法利用协变量（未来可获得的外生变量），因为这些协变量对于许多应用中的准确预测至关重要，且TSFMs具有领域特定性和缺乏相关的归纳偏置。", "innovation": "作者提出了一种轻量级的实例级适配器（TFMAdapter），它可以在不进行微调的情况下，将协变量信息纳入TSFMs中。TFMAdapter采用两阶段方法，首先生成伪预测，然后使用高斯过程回归器在伪预测和TSFM预测以及协变量之间进行细化。", "conclusion": "实验结果表明，TFMAdapter在真实世界的数据集上持续优于基础模型和监督基线，相较于基础模型，仅需少量数据和很低的计算开销便实现了24-27％的性能提升。结果突显了轻量级适配器在连接通用基础模型和特定领域预测需求方面的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.13034", "html_url": "https://arxiv.org/abs/2410.13034", "title": "使用Stable Diffusion合成功高分辨率自然场景图像及感知缩放", "title_en": "Synthesis and Perceptual Scaling of High Resolution Naturalistic Images Using Stable Diffusion", "authors": "Leonardo Pettini,Carsten Bogler,Christian Doeller,John-Dylan Haynes", "background": "自然场景是视觉感知的关键对象，但控制其感知和语义属性具有挑战性。过去的自然场景研究通常集中在具有显著物理差异的离散图像集合上。然而，评估沿连续维度变化的自然图像表示通常是必要的。传统的自然刺激连续性变化通过源图像向目标图像进行形态转换获得，这主要由低级物理特征驱动，可能导致语义模糊的输出。近年来，生成对抗网络（GAN）用于在刺激类别内部产生连续的感知变化。本研究通过使用不同的机器学习方法——文本到图像的扩散模型（Stable Diffusion XL）来生成可自由定制的、光感逼真的图像集，这些图像集具有渐变过渡，且每张图像代表所提示类别中的一个独特的实例。", "innovation": "本文创新地利用了文本到图像的扩散模型Stable Diffusion XL来生成可自由定制的、光感逼真的图像集，这些图像集具有渐变过渡。通过机器学习模型LPIPS估计感知相似性，随后由大规模在线参与者验证，这一排序也预测了工作记忆实验中刺激的混淆度。", "conclusion": "可以使用该图像集进行研究，以探究视觉感知、注意和记忆中自然刺激的分等级编码。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13855", "html_url": "https://arxiv.org/abs/2509.13855", "title": "基于图正则化的高斯混合模型学习", "title_en": "Graph-Regularized Learning of Gaussian Mixture Models", "authors": "Shamsiiat Abdurakhmanova,Alex Jung", "background": "在分布式环境中，节点上的本地数据往往是异质的且数据量有限。传统的集中式学习方法或本地训练方法在这种条件下可能表现不佳。本研究旨在通过利用给定的相似性图来指导参数在节点间的共享，从而在保持数据隐私的同时进行有效的模型训练，最终实现异质且数据稀少环境下的高性能模型聚合。", "innovation": "提出了一种基于图正则化的高斯混合模型学习方法，利用提供相似性图来引导节点间参数共享，避免传递原始数据，从而实现节点间参数的灵活聚合，并且在异质且低样本条件下，该方法的模型性能优于集中式和本地训练得到的模型。", "conclusion": "该方法通过利用提供的相似性图来指导参数共享，避免了数据的直接传输，能够在异质且数据稀少环境中有效提升高斯混合模型的性能。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13866", "html_url": "https://arxiv.org/abs/2509.13866", "title": "掩码扩散模型作为能量最小化", "title_en": "Masked Diffusion Models as Energy Minimization", "authors": "Sitong Chen,Shen Nie,Jiacheng Sun,Zijin Feng,Zhenguo Li,Ji-Rong Wen,Chongxuan Li", "background": "本文提出了一种系统化的理论框架，将掩码扩散模型（MDMs）解释为离散最优传输中能量最小化的解决方案。文章通过证明三种不同的能量形式——动能、条件动能和测地线能量，在MDMs结构下是数学上等价的，揭示了MDMs的理论基础。", "innovation": "通过参数化插值时间表为Beta分布，将时间表的设计空间简化为可处理的二维搜索，使得在不修改模型的情况下，通过后训练调整提高采样效率。实验表明，基于能量的方法超越了人工构建的基线，尤其是在低步数采样设置中。", "conclusion": "研究统一了MDMs的不同能量形式，澄清了其理论基础，并通过参数化方法改进了实际采样的效率。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13908", "html_url": "https://arxiv.org/abs/2509.13908", "title": "APFEx: 适应性帕累托前沿探索者以实现交叉公平性", "title_en": "APFEx: Adaptive Pareto Front Explorer for Intersectional Fairness", "authors": "Priyobrata Mondal,Faizanuddin Ansari,Swagatam Das", "background": "确保机器学习模型的公平性至关重要，尤其是在多种保护属性如种族、性别和年龄的交叉下，偏见会进一步累积。现有的方法虽然可以处理单一属性的公平性问题，但是不能充分捕捉交叉群体面临的复杂和递增性的偏见。", "innovation": "本文提出了Adaptive Pareto Front Explorer (APFEx)，这是第一个将交叉公平性明确定义为在敏感属性笛卡尔积上的联合优化问题的框架。APFEx包含三个关键创新点：（1）一种能动态在Pareto锥投影、梯度加权和探索策略之间切换的自适应多目标优化器，以便在公平性和准确性之间进行权衡；（2）可微分的交叉公平性指标，使得基于梯度的优化能够处理非光滑子组差异；（3）理论上的收敛保证，确保可达到帕累托优化解。", "conclusion": "在四个真实世界数据集上的实验表明，APFEx在减少公平性问题的同时能保持竞争性准确性。本文填补了公平机器学习的关键空白，提供了一种可扩展且模型无关的交叉公平性解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13952", "html_url": "https://arxiv.org/abs/2509.13952", "title": "扩展的物理知情神经网络方法在断裂力学问题中的应用", "title_en": "eXtended Physics Informed Neural Network Method for Fracture Mechanics Problems", "authors": "Amin Lotfalian,Mohammad Reza Banan,Pooyan Broumand", "background": "该论文提出了一种名为eXtended Physics-Informed Neural Network（X-PINN）的新颖且稳健框架，用于解决涉及多个裂纹的断裂介质中的断裂力学问题。为了应对这一挑战，论文提出了一种基于能量的损失函数、自定义积分方案和域分解程序。灵感来源于扩展有限元方法（XFEM），神经网络的解空间被增强以捕获断口体的不连续性和裂纹尖端的奇异点。", "innovation": "论文引入了结构化的框架，将标准和增强的解组件用不同的神经网络进行建模，这使得复杂的一维和二维多裂纹问题的灵活和有效的模拟成为可能，并且方便地扩展到三维问题。提出的X-PINN方法基于能量损失函数、自定义积分方案和域分解程序，通过增加专门的函数来丰富神经网络解空间，使之能明确捕获裂纹体不连续性和裂纹尖端的奇异性。", "conclusion": "为了验证所提出方法的有效性和鲁棒性，进行了数值实验。结果表明，X-PINN方法能有效处理涉及多个裂纹的复杂问题，并展示了其在断裂力学问题中的广泛应用潜力。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13818", "html_url": "https://arxiv.org/abs/2509.13818", "title": "基于混合量子-经典神经网络的少量样本信用风险评估", "title_en": "Hybrid Quantum-Classical Neural Networks for Few-Shot Credit Risk Assessment", "authors": "Zheng-an Wang,Yanbo J. Wang,Jiachi Zhang,Qi Xu,Yilun Zhao,Jintao Li,Yipeng Zhang,Bo Yang,Xinkai Gao,Xiaofeng Cao,Kai Xu,Pengpeng Hao,Xuan Yang,Heng Fan", "background": "量子机器学习（QML）为解决复杂且古典方法难以处理的金融问题提供了新视角。本文特别聚焦于少量样本信用风险评估这一关键问题，该问题在包容性金融领域由于数据稀缺和不平衡限制了传统模型的效果。因此，设计并实现了一种新的混合量子-经典工作流。工作流首先利用多种经典的机器学习模型（逻辑回归、随机森林、XGBoost）进行智能特征工程和降维，随后以参数偏移规则训练的量子神经网络（QNN）作为核心分类器。该方法通过数值仿真和Quafu量子云平台的ScQ-P21超导处理器进行了评估。", "innovation": "创新点在于提出了一种结合经典和量子计算方法的混合工作流，首先通过经典机器学习模型进行特征工程和降维，然后使用量子神经网络进行分类。该方法在实际信用数据集上取得了优越性能，在模拟中实现了稳定的平均AUC为0.852 ± 0.027，硬件实验中AUC达到了0.88，大幅超过了多种经典基准，尤其在召回率指标上表现突出。研究提供了在量子近似中尺度（NISQ）时代应用量子计算处理数据受限金融场景的实际方案，并提供了支持其在高风险应用如包容性金融中的潜力的实证证据。", "conclusion": "该研究为将量子计算应用于数据受限的金融场景提供了一个实用蓝图，并提供了支持其在高风险应用如包容性金融中的潜力的重要实证证据。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13841", "html_url": "https://arxiv.org/abs/2509.13841", "title": "一种端到端可微分、嵌入图神经网络的孔隙网络模型，用于渗透率预测", "title_en": "An End-to-End Differentiable, Graph Neural Network-Embedded Pore Network Model for Permeability Prediction", "authors": "Qingqi Zhao,Heng Xiao", "background": "准确预测多孔介质中的渗透率对于地下流体力学的建模至关重要。纯数据驱动模型具有计算效率高但跨尺度泛化能力差，不包含显式物理约束。与之相比，孔隙网络模型基于物理且高效，但依赖于理想的几何假设来估算孔隙尺度的水力传导率，限制了其在复杂结构中的准确性。", "innovation": "本文提出了一种端到端可微分、嵌入图神经网络（GNN）的孔隙网络模型，将GNN嵌入孔隙网络模型中，用GNN预测的孔隙和喉部特征来替代传统的导电率计算公式。通过反向传播梯度对图神经网络和孔隙网络模型求解器进行联合训练，所得模型能够避免孔隙网络模型的几何假设限制，同时保持基于物理的流体力学计算，从而提高预测准确性和跨尺度泛化能力，优于纯数据驱动和传统孔隙网络方法。", "conclusion": "这种模型在复杂多孔介质中的渗透率预测中表现出高准确性和良好的泛化能力，通过基于梯度的灵敏度分析进一步增强了模型解释性，提供了一种可扩展且物理基础的框架，降低了模型不确定性，提高了准确性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13974", "html_url": "https://arxiv.org/abs/2509.13974", "title": "简约高效：低成本患者个性化持续学习方法在穿戴式设备中资源节约型癫痫发作检测中的应用", "title_en": "Personalization on a Budget: Minimally-Labeled Continual Learning for Resource-Efficient Seizure Detection", "authors": "Amirhossein Shahbazinia,Jonathan Dan,Jose A. Miranda,Giovanni Ansaloni,David Atienza", "background": "癫痫是一种常见的神经系统疾病，需要仔细诊断和持续护理。然而，当前临床实践依赖于专家对手部电生理图（EEG）的分析，这是一个耗时的过程，需要专门的知识。如何解决这一挑战，持续学习方法能否实现个性化和资源节约型的癫痫发作自动检测？", "innovation": "本文提出了一种名为EpiSMART的持续学习框架，用于实现个性化且资源节约型的癫痫发作检测。EpiSMART使用限大小的重播缓存和有见地的样本选择策略，通过有选择地保留高熵和预测的癫痫发作样本，从而有效地集成新数据同时保留过去的知识，仅需少量标注数据和每次迭代计算量即可达到高性能，并适用于穿戴设备中的实时部署。", "conclusion": "EpiSMART能够在现实条件下有效地整合新数据到已有模型中，支持个性化适应，且在资源受限条件下实现稳健和个性化的癫痫发作检测，尤其是能够持续适应患者的特殊EEG信号特征，提高实际应用中的可穿戴设备中的表现和部署可行性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14029", "html_url": "https://arxiv.org/abs/2509.14029", "title": "基于深度学习的生物纳米孔中肽分类", "title_en": "Deep Learning-Driven Peptide Classification in Biological Nanopores", "authors": "Samuel Tovey,Julian Hoßbach,Sandro Kuppel,Tobias Ensslen,Jan C. Behrends,Christian Holm", "background": "一种可以在临床环境中实时分类蛋白质的设备将实现廉价快速的疾病诊断。纳米孔设备是这种技术的一个候选者。这些设备通过测量蛋白质或肽进入纳米级长度孔时产生的电流信号来工作。如果这种电流与肽的结构及与孔的相互作用有关，信号可以用来进行识别。尽管这种方法可以在临床环境中实时识别肽和蛋白质，但到目前为止，这些信号的复杂性限制了它们的准确性。", "innovation": "本文通过将电流信号转换为追踪图像（scaleogram images）并通过小波变换，捕捉幅度、频率和时间信息，这些信息是机器学习算法的理想表现形式来解决分类问题，从而显著提高了准确性。在对42种肽进行测试时，该方法达到了约81%的分类准确率，成为该领域的最新前沿，并为临床环境中的即时肽/蛋白质诊断铺平了道路。此外，本文还展示了模型迁移技术，这对于将这些模型部署到实际硬件中至关重要。", "conclusion": "本研究通过将电流信号转换为追踪图像并通过小波变换，使用机器学习技术实现了对42种肽81%的分类准确率，超越了之前的技术，并朝着临床环境中实时疾病诊断迈出了重要一步。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14077", "html_url": "https://arxiv.org/abs/2509.14077", "title": "在线贝叶斯风险规避强化学习", "title_en": "Online Bayesian Risk-Averse Reinforcement Learning", "authors": "Yuhao Wang,Enlu Zhou", "background": "本文研究了强化学习（RL）中的贝叶斯风险规避公式，以解决由于数据不足引起的认识不确定性问题。采用贝叶斯风险马尔可夫决策过程（BRMDP）来处理未知底层模型参数的不确定性。", "innovation": "推导了贝叶斯风险值函数与原始值函数之间的渐近正态性，表明贝叶斯风险规避方法倾向于悲观低估原始值函数。提出了适应性性质，在在线RL和在线上下文多臂 Bandit（CMAB）中利用这一性质。提供了两种后验采样方法来解决一般RL问题和CMAB问题，并建立了次线性后悔界，包括两种后悔定义下的后悔。", "conclusion": "实验验证了所提出算法在解决认识不确定性方面的有效性，并证实了理论性质。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14024", "html_url": "https://arxiv.org/abs/2509.14024", "title": "差分隐私联邦学习在本地化控制传染病动态中的应用", "title_en": "Differentially private federated learning for localized control of infectious disease dynamics", "authors": "Raouf Kerkouche,Henrik Zunker,Mario Fritz,Martin J. Kühn", "background": "在疫情期间，迅速反应是必要的，以减轻疫情传播。局部方法具有诸多优势，包括限制了所需的资源，并减少了大规模干预的影响。然而，因可用数据有限，在局部规模上单独训练机器学习（ML）模型常常不可行。集中化数据又是挑战，因为高度敏感和隐私限制。为了保证隐私的同时提供详细的情况数据，本研究考虑了基于德国各县和社区的本地化策略，并由相关的地方卫生当局管理。我们提出了一种隐私保护预测方法，协助公共卫生专家和决策者。联邦学习（FL）方法通过剪辑、加密等方式训练共享模型，而无需集中化原始数据。研究中将各县、社区或地方卫生当局作为一种客户端，通过在客户端和服务端设置差分隐私（DP）来实现平衡数据效用与隐私的目的。", "innovation": "本研究创新地提出通过差分隐私联邦学习（DP-FL）框架进行传染病的本地化预测。在这种框架下，客户端（如各县、社区或地方卫生当局）仅交换经过规范化处理的更新，并向服务器端聚合带有DP噪声的更新以保护隐私。从而，在保证高隐私保证的同时，实现了稳定的疫情预测。", "conclusion": "客户端级别的差分隐私联邦学习可以为公共卫生部门提供有价值的县级疫情预测，并实现较强的隐私保护。尽管高度严格的隐私设置会导致预测不稳定，但适度保护隐私的模型在多个疫情阶段都能接近非隐私模型的性能，表现出良好的效用。此外，适用的隐私预算取决于疫情的不同阶段，使得健康部门可以进行合规的合作，实现局部疫情预测。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13933", "html_url": "https://arxiv.org/abs/2509.13933", "title": "基于Q学习的Whittle索引在无线联邦学习中的自适应客户端选择", "title_en": "Adaptive Client Selection via Q-Learning-based Whittle Index in Wireless Federated Learning", "authors": "Qiyue Li,Yingxin Liu,Hang Qi,Jieping Luo,Zhizhang Liu,Jingjin Wu", "background": "该论文考虑了无线联邦学习中的客户端选择问题，目的是减少达到一定学习准确度所需的总时间。由于服务器无法观测到客户端的状态，这些状态会动态变化影响计算和通信效率，因此客户端选择被建模为一个不受控制的多臂_bandit_问题。现有方法通常需要客户端状态转换或数据分布的具体知识，这在实际情况中可能难以获得和确定。", "innovation": "论文提出了一种名为WILF-Q（Whittle Index Learning in Federated Q-learning）的方法，结合使用Q学习来自适应地学习并更新与每个客户端相关联的近似Whittle索引，并选择具有最高索引的客户端。与现有方法相比，WILF-Q无需具体知道客户端状态转换或数据分布，因此更适应用于实际的无线联邦学习场景中。实验结果表明，WILF-Q在学习效率方面显著优于现有基线策略，提供了一种稳健且高效的客户端选择方法。", "conclusion": "WILF-Q方法为无线联邦学习中客户提供了一种有效且具有弹性的选择策略，能够在资源有限和不断变化的环境中优化模型训练效率。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13914", "html_url": "https://arxiv.org/abs/2509.13914", "title": "预训练模型的集成在长尾轨迹预测中的应用", "title_en": "Ensemble of Pre-Trained Models for Long-Tailed Trajectory Prediction", "authors": "Divya Thuremella,Yi Yang,Simon Wanna,Lars Kunze,Daniele De Martini", "background": "随着自动驾驶技术的不断进步，越来越复杂和强大的预测模型不断出现，然而一个关键的挑战是如何不进行重新训练就能够结合这些模型的优点。轨迹预测问题具有高度的多维性，这对于现有模型的整合提出了挑战。", "innovation": "本文提出了一个简单而有效的方案，即无需重新训练，直接使用当前最先进深度学习模型的集成，并通过一种简单的基于模型置信度加权平均的方法来提升整体预测性能。这一方法在NuScenes和Argoverse数据集上均提高了10％以上的预测效果，尤其是在长尾指标上效果显著。", "conclusion": "所提出的方法在两个广泛使用的数据集上都显示出性能提升，并在数据集的整体分布上一致有效。相关代码已开源供进一步研究使用。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14078", "html_url": "https://arxiv.org/abs/2509.14078", "title": "通过深度学习优化技术探索大脑半球状态与频率带之间的关系", "title_en": "Exploring the Relationship between Brain Hemisphere States and Frequency Bands through Deep Learning Optimization Techniques", "authors": "Robiul Islam,Dmitry I. Ignatov,Karl Kaberg,Roman Nabatchikov", "background": "该研究旨在通过使用不同的优化器和评估跨EEG频段的分类器性能，探讨大脑左、右半球的状态与频率带之间的关系。研究采用了三种神经网络架构：深层密集网络、浅层三层网络和卷积神经网络(CNN)，并使用TensorFlow和PyTorch框架进行了实现和比较。", "innovation": "研究创新地通过深入学习的方法，比较了不同优化器在分析EEG频段中的不同性能，特别是在左侧和右侧大脑半球的分类预测上。研究结果表明Adagrad优化器在β频段表现突出，而RMSprop优化器在γ频段表现更佳。此外，研究还利用SHAP图来识别有效的类别预测，揭示了EEG频率带对模型准确性的细微贡献。这种方法对于提高基于神经影像的分类任务中的分类器性能及理解特征重要性具有重要贡献。", "conclusion": "研究强调了选择合适的优化器、模型架构以及分析EEG频段的重要性，以增强分类器性能和理解神经影像分类任务中的特征重要性。在应用方面，CNN模型显示出了较高的准确率，特别是在捕捉EEG数据的空间特征方面表现突出。深层密集网络在学习复杂模式方面表现竞争力，而浅层三层网络虽然有时准确率较低，但在计算效率方面有优势。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14061", "html_url": "https://arxiv.org/abs/2509.14061", "title": "基于环境传感器融合的低功耗边缘计算蜂巢王后检测", "title_en": "Queen Detection in Beehives via Environmental Sensor Fusion for Low-Power Edge Computing", "authors": "Chiara De Luca,Elisa Donati", "background": "蜂王的存在对于蜜蜂群的健康和稳定性至关重要，但当前的监测方法依赖于手工检查，费时、破坏性和不适合大规模养蜂。虽然最近的声音检测方法显示了潜力，但它们通常消耗高能耗，需要复杂的预处理，并且容易受到环境噪声的影响。", "innovation": "提出了一种基于环境传感器融合的轻量级多模态女王检测系统，特别是融合蜂箱内外的温度、湿度和压力差异。该方法在商用STM32微控制器上采用量化决策树推理，实现低功耗的边缘计算，而不会牺牲准确性。实验证明，仅使用环境输入即可实现超过99%的女王检测准确率，声音特征未对性能产生显著提高。这提供了一种可扩展且可持续的非侵入式蜂巢监测解决方案，为使用现成、节能硬件的自主、精准养蜂铺平了道路。", "conclusion": "本研究提出了一种通过对现成、节能硬件进行环境传感器融合的方法，实现了低功耗的边缘计算王后检测，为自主、精准养蜂提供了可持续的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14113", "html_url": "https://arxiv.org/abs/2509.14113", "title": "从参数模型到分位数神经基模型：电力价格预测案例", "title_en": "From Distributional to Quantile Neural Basis Models: the case of Electricity Price Forecasting", "authors": "Alessandro Brusaferri,Danial Ramin,Andrea Ballarino", "background": "虽然神经网络在多步预测概率预报方面取得了很高的预测精度，但对于特征条件输出背后机制的理解仍然是预报员的重大挑战。本文进一步探讨了这一问题，提出了一种新的Quantile Neural Basis Model，该模型将Quantile Generalized Additive Models的可解释性原则融入到端到端的神经网络训练框架中，以此来增强模型的可解释性。模型避免了参数分布假设，利用了共享基解耦和权重因子分解的技术，为输入特征到输出预测的非线性映射提供了有价值的见解。该方法已在一天前的电力价格预测上进行了验证，其预测性能可与分布性及分位数回归神经网络相媲美。", "innovation": "本文提出了Quantile Neural Basis Model，该模型将Quantile Generalized Additive Models的可解释性原则纳入到神经网络训练框架中，通过共享基解耦和权重因子分解，避免了参数分布假设。这种方法在电力价格预测任务上展现了与现有方法相当的预测性能，同时提供了对模型行为的深入了解。", "conclusion": "本文通过引入Quantile Neural Basis Model，提出了一个结合了Quantile Generalized Additive Models可解释性的神经网络模型。该模型在电力价格预测任务上验证了其有效性和可解释性，为预测任务中的解释性提出了新的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.11839", "html_url": "https://arxiv.org/abs/2509.11839", "title": "TrajBooster: 通过轨迹中心学习提升 humanoid 整体运动能力", "title_en": "TrajBooster: Boosting Humanoid Whole-Body Manipulation via Trajectory-Centric Learning", "authors": "Jiacheng Liu,Pengxiang Ding,Qihang Zhou,Yuxuan Wu,Da Huang,Zimian Peng,Wei Xiao,Weinan Zhang,Lixin Yang,Cewu Lu,Donglin Wang", "background": "近期的视语言行动（Vision-Language-Action，VLA）模型在跨身体模型方面的应用显示出潜力，但在面对新的机器人运动空间时，特别是在高质量示范稀缺的情况下，难以快速对齐。对于 bipedal 人形机器人而言，尤其具有挑战性。为了克服这个挑战，本文提出了一种跨身体模型的框架 TrajBooster，旨在利用大量存在的人形轮式机器人类数据来提升 bipedal VLA。关键思想是采用末端执行器（end-effector）轨迹作为不依赖于身体形态的接口。TrajBooster 的方法包括：从实际的轮式人形机器人中提取 6D 双臂末端执行器轨迹；使用全身控制器通过扩展启发式的和谐在线 DAgger 训练方法将低维度的轨迹参考转换为可行的高维度全身动作；形成包含源视觉/语言信息和目标人形兼容动作的异质三元组，以辅助预训练 VLA，以及最后仅收集 10 分钟目标人形机器人领域的远程操作数据。", "innovation": "本文提出了 TrajBooster，这是一种跨身体模型框架，可利用大量轮式人形机器人数据来增强 bipedal 人形机器人的 VLA 性能。该方法包括使用末端执行器轨迹作为不依赖于身体形态的接口，提取并转换轨迹数据，以及构建异质三元组来辅助预训练。该策略能显著提高任务执行的鲁棒性和泛化能力。", "conclusion": "将 TrajBooster 应用于 Unitree G1，我们的策略成功实现了台面以上家庭任务，包括蹲着、跨高度操作以及全身协调动作。结果表明，TrajBooster 能够使现有的轮式人形机器人数据高效地增强 bipedal 人形机器人的 VLA 表现，同时减少了对昂贵的同体模型数据的依赖，并增强了对行动空间的理解和零样本技能转移的能力。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14172", "html_url": "https://arxiv.org/abs/2509.14172", "title": "TGPO: 树引导偏好的优化以增强Web代理的强化学习鲁棒性", "title_en": "TGPO: Tree-Guided Preference Optimization for Robust Web Agent Reinforcement Learning", "authors": "Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao", "background": "随着大语言模型和多模态模型的快速发展，使用大型模型作为Web代理进行自动化网络交互变得至关重要。然而，通过强化学习训练Web代理面临许多挑战，包括奖赏分配不当、标注成本过高以及奖赏稀疏等问题。", "innovation": "我们提出了树引导偏好优化（TGPO），这是一种基于树结构轨迹表示的离线强化学习框架，能够消除标签冲突并集成来自不同轨迹的语义相同状态。该框架包括一个过程奖赏模型，能够通过子目标进展、冗余检测和动作验证自动生成精细的奖赏。此外，动态加权机制在训练过程中优先考虑具有高影响力的决策点。", "conclusion": "我们在Online-Mind2Web和我们自构建的C-WebShop数据集上进行的实验表明，TGPO显著优于现有方法，在减少冗余步骤的同时实现了更高的成功率。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14158", "html_url": "https://arxiv.org/abs/2509.14158", "title": "一种用于特征学习的组合核模型", "title_en": "A Compositional Kernel Model for Feature Learning", "authors": "Feng Ruan,Keli Liu,Michael Jordan", "background": "本文研究了一种以坐标权重形式重新加权输入并应用于预测器的核岭回归的组合变体。该模型从变分问题的角度进行建模，提供了一个简单的特征学习测试平台。从变量选择的角度，研究了如何回收相关变量并消除噪声变量。证明了当噪声变量呈高斯分布时，全局最小值和驻点都可消除噪声坐标。中心发现指出，具有\\(\boldsymbol{\text{l}_1}\\)型核（如拉普拉斯核）可以在驻点中成功回收贡献非线性效应的特征，而高斯核只能回收线性特征。", "innovation": "提出了一种组合核模型，用于特征学习；证明了在噪声变量呈高斯分布的情况下，全局最小值和驻点都能消除噪声坐标；不同类型的核函数在非线性特征和线性特征的恢复能力上有所差异。", "conclusion": "本文通过一种新颖的组合核模型，展示了全局最小值和驻点在噪声高斯分布时消除噪声坐标的能力，并发现不同核函数在恢复非线性和线性特征上的不同效果。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14181", "html_url": "https://arxiv.org/abs/2509.14181", "title": "提升过去与未来的关联：面向分布的时序预测对齐", "title_en": "Bridging Past and Future: Distribution-Aware Alignment for Time Series Forecasting", "authors": "Yifan Hu,Jie Yang,Tian Zhou,Peiyuan Liu,Yujin Tang,Rong Jin,Liang Sun", "background": "时间序列预测中的表示学习技术，如对抗学习，已经在时间和空间上成功应用于计算机视觉和自然语言处理领域。然而，最新的前沿预测模型很少采用这些表示方法，因为它们几乎没有显示出性能优势。本研究表明，显式的表示对齐可以为历史输入和未来目标之间的分布差距提供关键信息。大量实验验证了这种观点，八项基准实验表明TimeAlign框架具有出色的表现。进一步的研究表明，这种提升主要来自于纠正历史输入和未来输出之间的频率不匹配。本文还提供了一种理论解释，解释了为何TimeAlign可以增加学习表示与预测目标之间的互信息。作为一种架构无关且性能影响较小的模块，TimeAlign可以作为现代深度学习时间序列预测系统的通用对齐模块。相关代码可以在特定网址获取。", "innovation": "TimeAlign框架是一种轻量级且插件式的对齐框架。它通过简单的重构任务学习辅助特征，并将其反馈给任何基础预测器。进一步的研究表明，这种提升主要来自纠正历史输入和未来输出之间的频率不匹配。文章还提供了理论依据，证明TimeAlign能够增加学习表示与预测目标之间的互信息。作为一种架构无关的模块，TimeAlign对现代深度学习时间序列预测系统的性能几乎没有影响，可以作为通用的对齐模块。", "conclusion": "TimeAlign可以通过显式的表示对齐提升时间序列预测的性能。大量的实验验证了该观点，并且TimeAlign作为一种架构无关的对齐模块，在现代深度学习时间序列预测系统中具有广泛的应用前景。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14167", "html_url": "https://arxiv.org/abs/2509.14167", "title": "拆解眼内压：一种非侵入性多阶段概率逆向框架", "title_en": "Deconstructing Intraocular Pressure: A Non-invasive Multi-Stage Probabilistic Inverse Framework", "authors": "Md Rezwan Jaher,Abul Mukid Mohammad Mukaddes,A. B. M. Abdul Malek", "background": "许多关键的医疗保健决策受到无法测量关键参数的挑战。例如，青光眼是一种由于眼内压(IOP)升高而引发的不可逆失明的主要原因，其主要决定因素——房水流出道的渗透性——无法在活体内进行测量，导致临床医生不得不依赖间接的替代指标。此外，开发预测模型来解决这样的病态的逆问题，还需要大量准确的数据和大规模高保真模拟的高度成本，这进一步加剧了这一问题。", "innovation": "我们提出了一种端到端的框架来无创地从稀疏的常规数据中估算不可测量的变量。该方法结合了多阶段的人工智能架构来功能上分离问题；一种新的数据生成策略命名为PCDS，该策略省去了需要成千上万昂贵的模拟，将计算时间从多年缩短到几小时；以及贝叶斯引擎来量化预测不确定性。框架将单一的IOP测量拆解成其基本组成部分，仅从常规输入来获取无法测量的组织渗透性和患者流出道的功能性评估。我们的非侵入性估计流出道功能与最新的眼压图仪结果一致，精度与直接物理仪器相当。此外，新获得的渗透性生物标志物在疾病风险方面展示了强大的分层能力，突显其诊断潜力。", "conclusion": "更广泛地说，我们的框架为其他数据稀缺、计算密集的领域提供了解决类似逆问题的通用模型。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14000", "html_url": "https://arxiv.org/abs/2509.14000", "title": "基于深时序图网络的GNSS jamming诱导偏差的实时纠正", "title_en": "Deep Temporal Graph Networks for Real-Time Correction of GNSS Jamming-Induced Deviations", "authors": "Ivana Kesić,Aljaž Blatnik,Carolina Fortuna,Blaž Bertalanič", "background": "全球导航卫星系统（GNSS）因受到故意干扰（例如，有意干扰信号）而被破坏，这种干扰在定位和计时必须保持正常运行时尤为严重。本文探讨了干扰减弱的问题，并认为可以通过动态图回归重新定义其问题，并提出了一种以接收器为中心的深度时序图网络，实时预测和校正接收器的水平偏移。该网络每秒一周期（1 Hz epoch），将卫星接收机环境视为带有时变属性（如信噪比、方位、仰角、纬度/经度）的异构星形图（接收器为中心，跟踪的卫星为叶结点）。网络应用于信号处理，输出2D偏差向量，用于实时校正。实验结果在两种不同接收器的多个干扰场景下进行了验证，展示了其相对于其他多变量时间序列基线模型（如MLP、均匀卷积神经网络和Seq2Point卷积神经网络）具有更好的性能。尤其是在低功率级别下，该模型表现出显著的优势，误差明显减少，验证了其鲁棒性和有效性。实验结果支持使用10%的训练数据和该模型在准确性和训练效率上的显著优势。", "innovation": "本文通过将干扰减少重新定义为动态图回归，并提出了一个以接收器为中心的深度时序图网络来解决这个问题。该模型可以在每一秒一周期中实时预测和纠正接收器的水平偏差。网络采用一种单层异构图卷积循环神经网络（HeteroGCLSTM）来聚合时空上下文和短期历史时序动态输出2D偏差向量，用于实时校正。实验结果表明该模型在准确性上明显优于其他基线模型，尤其是在接收信号较弱的情况下，具有更强的鲁棒性。此外，在混合模式数据集上，该模型的数据效率也得到了验证，只有10%的训练数据就达到了更好的性能。", "conclusion": "该研究展示了基于深时序图网络的模型在实时校正GNSS干扰引起的偏差方面的优越性能，并实现了较低的平均绝对误差（MAE），尤其是在低干扰功率下的表现尤为突出。此外，模型还展示出了良好的数据利用效率，开证在少量训练数据的条件下也具有较高的准确性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14219", "html_url": "https://arxiv.org/abs/2509.14219", "title": "非线性动力系统数据驱动建模中的噪声去除与导数估计", "title_en": "Data Denoising and Derivative Estimation for Data-Driven Modeling of Nonlinear Dynamical Systems", "authors": "Jiaqi Yao,Lewis Mitchell,John Maclean,Hemanth Saratchandran", "background": "数据驱动建模非线性动态系统的瓶颈在于受到测量噪声的影响。", "innovation": "提出了一种名为Runge-Kutta和总变差基于隐式神经表示（RKTV-INR）的去噪框架，通过将隐式神经表示（INR）直接拟合到有噪声的观测数据来表示状态轨迹。通过Runge-Kutta积分和总变差作为约束条件，确保重构的状态轨迹接近原始数据。", "conclusion": "实验表明该方法能有效去除噪声、精确估计导数并可靠地识别系统。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14216", "html_url": "https://arxiv.org/abs/2509.14216", "title": "通用Banach-Bregman框架用于随机迭代：统一随机镜像下降、学习和大语言模型训练", "title_en": "A Universal Banach--Bregman Framework for Stochastic Iterations: Unifying Stochastic Mirror Descent, Learning and LLM Training", "authors": "Johnny R. Zhang(Independent Researcher),Xiaomei Mi(University of Manchester),Gaoyuan Du(Amazon),Qianyi Sun(Microsoft),Shiqi Wang(Meta),Jiaxuan Li(Amazon),Wenhua Zhou(Independent Researcher)", "background": "现代人工智能的可扩展性依赖于随机优化，涵盖机器学习、深度学习、强化学习和大语言模型训练。现有理论大多局限于希尔伯特空间内，依赖于内积框架和正交性，这无法捕捉到非欧式设置，如单纯形上的镜像下降、稀疏学习的Bregman邻近方法、信息几何中的自然梯度下降或Kullback-Leibler正则化语言模型训练。与基于欧几里得的希尔伯特空间方法不同，这种新的方法采用了更广泛的Banach空间。", "innovation": "该工作提出了一个开创性的Banach-Bregman框架用于随机迭代，为下一代优化建立了Bregman几何基础。这一框架包括：(i) 通过Bregman投影和Bregman-Fejér单调性提供统一的模板，涵盖随机近似、镜像下降、自然梯度、自适应方法和镜像-普罗克斯特方法；(ii) 在非希尔伯特设置中建立了超级松弛效果，允许柔性几何并揭示其加速效应；(iii) 提供了从几乎必然有界性到几何速度的收敛定理，已在合成和实际任务上得到验证。", "conclusion": "实证研究表明，在机器学习（UCI基准）、深度学习（例如，Transformer训练）、强化学习（actor-critic）和大语言模型（WikiText-2 with distilGPT-2）中，该方法可实现高达20%的加速收敛、减少方差并提高准确性，超越了经典基线。这些结果使Banach-Bregman几何成为统一优化理论和实践的基础，贯穿核心AI范式。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14129", "html_url": "https://arxiv.org/abs/2509.14129", "title": "利用目标心理健康干预打破再监仓循环：机器学习在公共政策中的案例研究", "title_en": "Breaking the Cycle of Incarceration With Targeted Mental Health Outreach: A Case Study in Machine Learning for Public Policy", "authors": "Kit T. Rodolfa,Erika Salomon,Jin Yao,Steve Yoder,Robert Sullivan,Kevin McGuire,Allie Dickinson,Rob MacDougall,Brian Seidler,Christina Sung,Claire Herdeman,Rayid Ghani", "background": "许多被关押人员面临严重的复杂挑战，包括精神疾病、物质依赖和无家可归，但监狱和拘留所往往无法应对这些需求。在现有司法体系缺乏支持的情况下，这些需求往往得不到治疗，甚至恶化，这往往会促使更多违法行为，造成一个令人棘手的再入狱循环，不仅给个人带来不利后果，也影响公共安全。这一循环尤其对少数民族社区产生了尤为严重的影响，进一步加剧了刑事司法系统中长期存在的种族不平等。正因这些失败，越来越多的司法部门参与者希望通过创新方法来打破这一循环，如社区驱动和替代型警务、导师计划、社区建设、修复性正义、预审转介、综合辩护和社会服务链接等方法。本文主要探讨了俄堪萨斯州约翰逊县与卡内基梅隆大学合作，进行精准主动的精神健康外展服务，以降低再入狱率的努力。文章描述了采用机器学习应用于公共政策的过程和结果，特别是在预测模型的构建及其有效性验证方面。", "innovation": "本文报道了将机器学习与公共政策相结合的创新应用，通过精准的主动精神健康外展服务预测精神健康需求，以及通过模型评估其在降低再入狱率方面的具体影响。研究发现，对于最高风险组人员，干预措施效果显著，包括精神健康利用、紧急医疗响应和刑事司法接触等方面，显示出这种方法在精准干预方面的潜力。", "conclusion": "研究通过实验发现，本模型在预测新的拘留记录方面具有高度的准确性，最高的风险组中有超过一半的个体在接下来的一年中再次入狱。有针对性的外展活动对最高风险群体尤其有效，能够改善精神健康服务的使用情况，减少紧急医疗服务的拨打次数，并降低刑事司法参与程度。这是利用数据驱动方法干预司法系统中重大问题的初步成果，为未来在该领域进一步发展提供了依据。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14225", "html_url": "https://arxiv.org/abs/2509.14225", "title": "通过高阶 Langevin 动力学防御扩散模型的成员推理攻击", "title_en": "Defending Diffusion Models Against Membership Inference Attacks via Higher-Order Langevin Dynamics", "authors": "Benjamin Sterling,Yousef El-Laham,Mónica F. Bugallo", "background": "近期生成人工智能应用的发展引发了新的数据安全问题。本文集中在防止成员推理攻击上，这些攻击发生在攻击者能够判断某一数据点是否被用于训练模型时。尽管扩散模型相比于其他生成模型在对抗成员推理攻击方面更为坚固，但它们仍然容易受到此类攻击。", "innovation": "本文提出了一种防御策略，利用关键阻尼高阶 Langevin 动力学，引入多个辅助变量和这些变量上的联合扩散过程。核心思想是通过引入的辅助变量混合外部随机性，有助于在扩散过程更早阶段就对敏感输入数据进行混淆。这种构思在理论上进行了研究并应用在玩具数据集和语音数据集中，使用受操作特征（AUROC）曲线和 FID 元量进行了验证和验证实验。", "conclusion": "该研究通过理论分析和实际数据验证，提出了一种有效的防御机制，能够提高扩散模型对抗成员推理攻击的能力。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14198", "html_url": "https://arxiv.org/abs/2509.14198", "title": "基于变分框架的神经偏微分方程求解器及算子学习中残差自适应方法", "title_en": "A Variational Framework for Residual-Based Adaptivity in Neural PDE Solvers and Operator Learning", "authors": "Juan Diego Toscano,Daniel T. Chen,Vivek Oommen,George Em Karniadakis", "background": "在科学机器学习中，基于残差的自适应策略广泛应用但主要还是经验性方法。该领域缺乏系统的理论框架。论文提出一种统一的变分框架，通过嵌入残差的凸变换来正式化这些方法，从而直接影响不同的优化目标，使得误差度量能更加直接地作用于离散化选择。", "innovation": "该工作提出了一种统一的变分框架，通过集成残差的凸变换，分别实现了针对不同范数的自适应方案系统设计、通过减小损失估计的方差来减少离散化误差、通过提升梯度信号噪声比来增强学习动力学。该框架还成功应用于算子学习，并在优化器和架构上取得了显著性能提升。", "conclusion": "通过这一原理性的方法，该研究为基于残差的自适应方法提供了理论依据，并奠定了可用于离散化和训练的一系列原则性策略的基础。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14169", "html_url": "https://arxiv.org/abs/2509.14169", "title": "TopoSizing: 一种基于拓扑理解与尺寸优化的混合信号电路框架", "title_en": "TopoSizing: An LLM-aided Framework of Topology-based Understanding and Sizing for AMS Circuits", "authors": "Ziming Wei,Zichen Kong,Yuan Wang,David Z. Pan,Xiyuan Tang", "background": "混合信号电路设计因其高质量数据稀缺且难以将领域知识嵌入自动化流程中而具有挑战性。传统的黑盒优化虽然提高了采样效率，但缺乏电路理解，导致评估结果在设计空间的低价值区域浪费。相比之下，基于学习的方法嵌入了结构知识，但它们具有特定性且重新培训成本高昂。虽然使用大规模语言模型的最近尝试显示了潜力，但它们通常需要人工干预，限制了通用性和透明度。", "innovation": "我们提出了TopoSizing，一种端到端框架，直接从原始网表中执行稳健的电路理解，并将这些知识转化为优化收益。该方法首先应用图算法，将电路组织成分层的设备-模块-阶段表示。然后，LLM代理执行假设验证改进的迭代循环，内置了连贯检查，产生了明确的注释。验证后的见解通过LLM引导的初始采样和停滞触发的信任区域更新集成到贝叶斯优化中，提高了效率并保持可行性。", "conclusion": "TopoSizing框架通过直接利用原始网表和使用图算法进行分层表示，以及通过LLM代理执行假设验证改进的迭代循环，实现了对混合信号电路的稳健理解，并将其转化为优化益处。验证后的见解被整合到贝叶斯优化中，通过LLM引导的初始采样和停滞触发的信任区域更新过程，提高了优化效率同时保持了设计的可行性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13326", "html_url": "https://arxiv.org/abs/2509.13326", "title": "基于大型语言模型的聊天机器人开发方法", "title_en": "LLM Chatbot-Creation Approaches", "authors": "Hemil Mehta,Tanvi Raut,Kohav Yadav,Edward F. Gehringer", "background": "随着像GPT-4和LLaMA这样的大型语言模型（LLMs）的应用，基于这些模型的聊天机器人被整合到教学工作流中，以实现自动化任务、提供辅助和支持。然而，选择最佳开发策略需要在易用性、可定制性、数据隐私和可扩展性之间取得平衡。本文通过比较低代码平台（如AnythingLLM和Botpress）和自定义编码解决方案（使用LangChain、FAISS和FastAPI）来研究基于LLMs的聊天机器人的开发方法。文章利用提示工程技术、检索增强生成和个性化评估了聊天机器人的原型在技术性能、可扩展性和用户体验方面的表现。研究发现，低代码平台可以快速原型设计，但在可定制性和扩展性方面存在限制，而自定义编码系统则提供了更多的控制，但需要大量的技术专业知识。无论是哪种方法，都能成功实现关键的研究原则，如适应性反馈循环和对话连贯性。", "innovation": "本文首次将低代码平台和自定义编码解决方案对基于LLMs的聊天机器人的开发进行了比较研究，并通过提示工程技术、检索增强生成和个性化技术评估聊天机器人的性能。这种方法提供了选择最适合的开发策略的基础框架，基于机构目标和资源。未来的工作将侧重于结合低代码的可访问性和模块化定制，引入多模态输入以提高智能辅导系统的性能。", "conclusion": "研究建议，选择开发策略应基于机构的目标和资源。低代码平台适用于快速原型设计和初步功能测试，而自定义编码系统则适用于需要高度可定制性和扩展性的应用场景。未来的研究将进一步探索结合低代码平台的便捷性和自定义编码系统的灵活性，以提供更智能的多模态输入功能。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14234", "html_url": "https://arxiv.org/abs/2509.14234", "title": "将计算作为教师：将推理计算转化为参考自由的监督", "title_en": "Compute as Teacher: Turning Inference Compute Into Reference-Free Supervision", "authors": "Dulhan Jayalath,Shashwat Goel,Thomas Foster,Parag Jain,Suchin Gururangan,Cheng Zhang,Anirudh Goyal,Alan Schelten", "background": "在没有真实地面数据的情况下，学习模型如何在后训练阶段产生有效的学习信号？论文提出了一种名为Compute as Teacher（CaT）的方法，通过模型自身的推理阶段探索，在一组并行游历中合成参考，并据此优化。这种方法通过即将推理阶段的计算转化为监督信号，解决探索和监督之间的矛盾，适用于验证和非验证任务的不同场景。", "innovation": "提出了一种利用模型自身探索生成参考自由的监督信号的新方法（Compute as Teacher，CaT）。CaT通过合成多个游历产生的参考，并根据这个参考进行优化，将额外的推理计算转化为监督信号。这种方法在可验证和不可验证任务中表现出不同的应用方式，特别是在非验证任务中，通过独立的LLM进行评分和奖励分配，可以更灵活地处理反馈。与选择方法相比，合成方法更加灵活，即使所有游历都是错误的，仍可能产生正确的参考信号，且性能随游历数量的增加而提升。", "conclusion": "CaT作为一种测试时的处理方法，能够显著提升Gemma 3 4B, Qwen 3 4B, 和 Llama 3.1 8B等多个模型的性能，尤其是在数学和医疗领域；引入了强化学习的进一步优化（CaT-RL）后，获得了更大的提升，甚至让训练后的策略超过了初始的教师信号。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13338", "html_url": "https://arxiv.org/abs/2509.13338", "title": "基于接近性的证据检索对于不确定性感知神经网络", "title_en": "Proximity-Based Evidence Retrieval for Uncertainty-Aware Neural Networks", "authors": "Hassan Gharoun,Mohammad Sadegh Khorshidi,Kasra Ranjbarigderi,Fang Chen,Amir H. Gandomi", "background": "当前的工作背景是在决策过程中考虑不确定性。传统的决策机制通常依赖单个全局阈值来分类，但此种方法不透明且不易审计，无法提供决策过程中的具体支持证据。因此，需要提出一种新的机制，能够在保持决策透明性和可审计性的前提下提高不确定性感知性能。", "innovation": "本文创新性地提出了一种基于接近性的证据检索机制，用于不确定性的感知决策。该机制用实例自适应的证据条件阈值取代单一的全局阈值。具体来说，在嵌入空间中检索每个测试实例的邻近示例，通过Dempster-Shafer理论融合这些邻近示例的预测分布，从而生成一个针对每个实例的阈值机制。这种方法提供明确定的支持证据，使得决策过程更加透明和可审计。实验证明，与基于预测熵阈值的方法相比，该方法能实现更高的或等同的不确定性感知性能，同时具有较少的错误判断，并且可以维持一个可持续的审查工作量。此外，还需要指出的是，只有少量支持证据足以实现这些改进；增加证据集仅产生轻微变化，表明基于证据条件的标记比固定预测熵阈值更可靠和可解释，更适合于实际的不确定性感知决策场景。", "conclusion": "研究表明，基于证据条件的标记提供了固定预测熵阈值更可靠和可解释的替代方案，能够提高不确定性感知决策的性能并保持透明性。实验结果表明，在CIFAR-10/100数据集上使用BiT和ViT网络时，该方法在实现更高的或等同的不确定性感知性能的同时，产生了较少的确信错误的结果，并且具有可持续的审查负担。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.12510", "html_url": "https://arxiv.org/abs/2509.12510", "title": "任何PPG设备的半监督和拓扑信号质量评估", "title_en": "Self-Supervised and Topological Signal-Quality Assessment for Any PPG Device", "authors": "Wei Shao,Ruoyu Zhang,Zequan Liang,Ehsan Kourkchi,Setareh Rafatirad,Houman Homayoun", "background": "可穿戴光电容积描记图（PPG）嵌入了数十亿设备中，但由于运动、灌注损失和环境光等因素的影响，其光学波形容易受到破坏，影响后续的心脏数据分析。目前基于信号质量评估（SQA）的方法要么依赖脆弱的启发式方法，要么依赖需要大量数据才能训练的监督模型。", "innovation": "本文提出了一种全新的全无监督的腕部PPG信号质量评估管道。该管道分为两阶段：第一阶段使用对比1-D ResNet-18训练，基于276小时来自不同来源（设备和采样频率不同）的原始未标记数据，生成光发射器和运动不变嵌入；第二阶段将每个512-D编码嵌入转化为4-D拓扑签名，并用HDBSCAN进行聚类。通过该管道，可以得到一个二进制信号质量指标（SQI），用于区分好质量的PPG信号和可能质量不佳的PPG信号。此SQI在10,000个窗口的分层样本中实现了0.72的Silhouette得分，0.34的Davies-Bouldin得分，以及6173的Calinski-Harabasz得分。", "conclusion": "本文提出了一种半监督和拓扑数据分析（SSL-TDA）框架，该框架提供了一种插拔式的、跨设备可扩展的PPG信号质量门控机制。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13341", "html_url": "https://arxiv.org/abs/2509.13341", "title": "想象自训练", "title_en": "Imagined Autocurricula", "authors": "Ahmet H. Güzel,Matthew Thomas Jackson,Jarek Luca Liesen,Tim Rocktäschel,Jakob Nicolaus Foerster,Ilija Bogunovic,Jack Parker-Holder", "background": "在现实世界中，训练具备行动能力的智能体通常需要大量的训练数据或准确的模拟环境，但这两者在许多情况下都无法获得。相比之下，世界模型正逐渐成为一种替代方案，通过利用非主动收集的数据进行训练，可以生成多样化的模拟环境以训练智能体。然而，如何确保智能体在生成的有用数据中进行训练仍是主要挑战。", "innovation": "本文提出了一种新颖的方法，即IMAC（想象自训练），它结合了未监督环境设计（UED），能够通过生成的环境中自动产生一个训练课程，从而提高智能体在新任务中的泛化能力。此外，通过在一系列程序生成的环境中进行实验，表明仅在较小数据集中学习世界模型后，就能在未见过的环境中取得出色的成绩。", "conclusion": "本研究认为，这为利用大规模基础世界模型生成可以泛化的智能体提供了可能，揭示了一条新的实现途径。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14223", "html_url": "https://arxiv.org/abs/2509.14223", "title": "语言模型的激活线性编码训练顺序的近期性", "title_en": "Language models' activations linearly encode training-order recency", "authors": "Dmitrii Krasheninnikov,Richard E. Turner,David Krueger", "background": "当前，语言模型的学习机制尚未完全理解。研究者试图通过分析模型的内部激活，揭示模型在训练过程中如何处理和记忆信息的方法、过程与机制。具体来说，这项研究旨在探索语言模型的激活是否包含了关于信息学习时间的线索。", "innovation": "该研究创新性地提出了一种方法，通过顺序微调Llama-3.2-1B模型在六个不同的数据集上，研究了模型激活如何代表信息在训练过程中的学习顺序。研究发现，测试样本的平均激活能够精确地反映出训练数据集的顺序，并且线性探针能够准确地区分“早期”与“晚期”实体，即使这些实体未在探针的训练过程中出现。此外，模型还可以进一步微调以明确报告未见过的实体的学习阶段。", "conclusion": "该研究揭示了语言模型能够在某种程度上区分通过不同时间学习的信息，这表明模型可能具备管理和处理冲突数据以及应对知识更改的能力。这项研究对理解语言模型的内部运作机制具有重要意义。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14230", "html_url": "https://arxiv.org/abs/2509.14230", "title": "NIRVANA：重塑大型语言模型压缩的结构剪枝", "title_en": "NIRVANA: Structured pruning reimagined for large language models compression", "authors": "Mengting Ai,Tianxin Wei,Sirui Chen,Jingrui He", "background": "当前对大型语言模型（LLMs）进行结构化剪枝的方法虽然提供了显著的效率提升，但在零样本设置中往往导致性能大幅下降，并需要昂贵的恢复技术如监督微调或适配器插入。对于这一关键领域的不足，该研究引入NIRVANA，一种新的剪枝方法，旨在权衡零样本即刻准确性和鲁棒微调能力。NIRVANA通过结合神经切线核下Adam优化动力学的一阶显著性准则，提供了一种理论支持的剪枝策略，同时考虑了模型训练行为。为了应对结构化剪枝的独特挑战，NIRVANA还纳入了一种跨层和模块（注意与MLP）的自适应稀疏分配机制，这种机制能够在全局平衡上调整模块间的剪枝强度，并提出了一种简单的基于KL散度的校准数据选择策略，以确保更可靠和任务无关的剪枝效果。", "innovation": "提出了一种理论支持的剪枝方法NIRVANA，用于大型语言模型压缩，能够在保持零样本即刻准确性的同时增强鲁棒微调能力。该方法通过结合基于神经切线核的显著性准则和自适应稀疏分配机制，实现了更为全局平衡的剪枝策略。此外还提出了一种基于KL散度的校准数据选择策略，以优化剪枝效果。实验表明NIRVANA在同等稀疏度约束下优于现有结构化剪枝方法，提供了理论支持和实际可操作性的压缩方法。", "conclusion": "NIRVANA提出了一种新型结构剪枝方法，它能平衡零样本即刻准确性与鲁棒微调能力，并通过理论和实验验证其在大型语言模型压缩中的优越性。该方法不仅提供了一种新的剪枝策略，还适应了结构化剪枝的特殊挑战，为大型语言模型的高效压缩提供了新的视角。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13336", "html_url": "https://arxiv.org/abs/2509.13336", "title": "使用强化学习在超视距路径规划中最大化无人机蜂窝连接性", "title_en": "Maximizing UAV Cellular Connectivity with Reinforcement Learning for BVLoS Path Planning", "authors": "Mehran Behjati,Rosdiadee Nordin,Nor Fadzilah Abdullah", "background": "本文提出了基于强化学习（RL）的路径规划方法，用于漫游在视距以外的蜂窝连接无人驾驶飞机（UAVs）。该方法旨在通过考虑现实世界中的空中覆盖约束和采用经验性的空中信道模型，同时最小化飞行距离和最大化蜂窝链路的连接质量。此研究解决了无人机蜂窝通信能力的限制带来的挑战，并强调了在这一领域进行进一步研究和考虑的重要性。", "innovation": "提出的方法采用了RL技术来训练代理，使用无人机与基站之间的通信链路质量作为奖励函数，以实现基于海上覆盖限制的连通性最大化的路径规划。模拟结果表明，该方法能有效地训练代理并产生可行的无人机路径规划。此外，该方法能够作为一个离线路径规划模块，集成到未来的地面控制系统中，以增强其功能和安全性。", "conclusion": "该方法在复杂长距离无人机应用中具有潜力，佐证了在蜂窝连接的无人机路径规划领域的技术进步。解决超视距情况下无人机蜂窝连接性优化问题提出了一个新的研究方向。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13344", "html_url": "https://arxiv.org/abs/2509.13344", "title": "评估空间转录组学中维度降低技术的基准方法", "title_en": "Benchmarking Dimensionality Reduction Techniques for Spatial Transcriptomics", "authors": "Md Ishtyaq Mahmud,Veena Kochat,Suresh Satpati,Jagan Mohan Reddy Dwarampudi,Kunal Rai,Tania Banerjee", "background": "本文介绍了一个统一框架，用于评估空间转录组学中的维度降低技术，超越了标准的PCA方法。研究针对胆管癌Xenium数据集，系统地评估了六种方法（PCA、NMF、自动编码器、VAE以及两种混合嵌入），改变潜在维度（k=5-40）和聚类分辨率（ρ=0.1-1.2），使用重建误差、解释方差、聚类一致性以及两个新的生物动机指标（Cluster Marker Coherence CMC和Marker Exclusion Rate MER）。实验结果表明这些方法各有特点：PCA提供快速基准，NMF最大化标记物丰富度，VAE平衡重构和可解释性，而自动编码器处于两者之间。该框架使针对特定空间转录组学分析选择最佳维度降低方法成为可能，并利用Pareto最优分析进行系统超参数选择，MER指导重新分配提高了所有方法的生物忠实度，平均CMC分数提高12%。", "innovation": "提出了一个统一框架，系统地评估了维度降低技术在空间转录组学中的应用，涵盖了PCA以外的多种方法，使用了新的生物学动机度量标准，包括CMC和MER。提出了系统的选择超参数的方法，并展示了MER在提高所有方法的生物真实度方面的重要作用。", "conclusion": "该框架使选择适合特定空间转录组学分析的维度降低方法成为可能，并通过MER提高了所有方法的生物忠实度，此外，CMC分数平均提高了12%。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13353", "html_url": "https://arxiv.org/abs/2509.13353", "title": "图像分类中的混合量子-经典模型", "title_en": "Hybrid Quantum-Classical Model for Image Classification", "authors": "Muhammad Adnan Shahzad", "background": "该研究系统性地比较了混合量子-经典神经网络与纯粹的经典模型在三种基准数据集（MNIST, CIFAR100, STL10）上的性能、效率和鲁棒性。混合模型将参数化量子电路与经典的深度学习架构结合在一起，而纯经典模型则使用了传统的卷积神经网络（CNNs）。实验在每个数据集上进行了50个训练周期，并对验证精度、测试精度、训练时间、计算资源使用情况以及对抗鲁棒性（0.1扰动下的测试）进行了评估。", "innovation": "该研究的主要创新在于引入了混合量子-经典模型，将参数化量子电路与传统CNN结合，通过系统比较展示了这种模型在不同数据集上的优势。结果显示，对于复杂数据集（如CIFAR100和STL10），混合模型在最终准确度上具有显著提升，并且训练速度更快、所需参数更少。此外，研究还揭示了混合模型在简单数据集上的生物鲁棒性优于经典模型，但在复杂数据集上的鲁棒性则大体与经典模型相当。", "conclusion": "研究表明，混合量子-经典架构在准确性、训练效率和参数规模扩展方面具有一系列优势，特别是对于复杂的视觉任务。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13334", "html_url": "https://arxiv.org/abs/2509.13334", "title": "FRIT：使用因果重要性提高链式思维忠实度", "title_en": "FRIT: Using Causal Importance to Improve Chain-of-Thought Faithfulness", "authors": "Anand Swaroop,Akshat Nallani,Saksham Uboweja,Adiliia Uzdenova,Michael Nguyen,Kevin Zhu,Sunishchal Dev,Ashwinee Panda,Vasu Sharma,Maheep Chaudhary", "background": "链式思维（CoT）推理已证明是提高大型语言模型复杂任务性能的强大工具，但最近的研究显示推理步骤通常未能因果性地影响最终答案，导致模型输出脆弱且不可信赖。先前的方法主要关注测量忠诚度，而系统性提高忠诚度的方法仍然有限。", "innovation": "我们介绍了通过干预训练实现忠实推理（FRIT）的可扩展对齐方法，这种方法通过学习系统性被破坏的示例来训练模型，使其产生因果一致的推理。FRIT通过干预模型生成的链式思维中的个别推理步骤生成合成训练数据，创建忠实/不忠实的对来突出显示推理失败的时刻。然后利用直接偏好优化来教育模型偏好因果一致的推理路径。", "conclusion": "在Qwen3-8B和Mistral-7B-v0.1上评估的事实和符号推理任务中，FRIT将Mistral的忠实推理提高了3.4个百分点，准确性提高了7.6个百分点。我们的方法提供了第一个无需监督的可扩展方法，用于训练语言模型生成更可靠和可解释的推理，填补了推理性能和可信度之间的关键差距。我们开源代码在 ,href{this https URL}。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13355", "html_url": "https://arxiv.org/abs/2509.13355", "title": "合成数据与真理观念的转变", "title_en": "Synthetic Data and the Shifting Ground of Truth", "authors": "Dietmar Offenhuber", "background": "合成数据因其在隐私保护、训练数据生成或提供方便访问接近真实的各类数据方面的作用，使得真实数据的概念复杂化。合成数据模仿真实世界观察但不依赖外部特征，缺乏代表性关系，但研究者继续将合成数据用于AI模型训练和真实数据的参考库，声称这比真实数据更能提升模型表现，因为可以抵消已知偏见、防止过拟合、促进泛化，并使模型更具应对意外异常值的能力。同时，合成数据的引入使得真实数据被视为一种自反性的事实，即用于真实数据参考库的标签也源于生成模型，与真实世界观察无直接联系，颠覆了依靠表现准确性决定数据忠实度的传统假设。", "innovation": "论文探讨了在合成数据使真实数据概念复杂化的背景下，机器学习的研究者和从业者如何在没有依赖代表性或现实参考的情况下“自助建立”事实。这包括对从表示论到可模仿或象征性数据概念转变的更广泛影响的思考。", "conclusion": "论文分析了在合成数据引入的情况下，如何在没有依赖稳定的表现关系和现实参考的情况下不断更新和构建“事实”。这强调了研究者需要重新思考数据的真实性和参考性的概念，以及这些转变对机器学习模型及其应用的深远影响。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13368", "html_url": "https://arxiv.org/abs/2509.13368", "title": "$Agent^2$: 一种生成性代理框架实现强化学习自动化", "title_en": "$Agent^2$: An Agent-Generates-Agent Framework for Reinforcement Learning Automation", "authors": "Yuan Wei,Xiaohan Shan,Ran Miao,Jianmin Li", "background": "传统基于强化学习的代理开发需要大量专业经验和长时间的迭代，常常导致失败率高和访问性受限。", "innovation": "提出了$Agent^2$，一种新型的代理生成代理框架，通过智能LLM驱动的生成实现全自动的强化学习代理设计。该系统能够自主将自然语言的任务描述和环境代码转化为全面、高性能的强化学习解决方案，无需人类干预。$Agent^2$具有革命性的双代理架构，包括生成代理和服务于生成可执行的强化学习代理的生成目标代理。框架将强化学习开发分解为两阶段：MDP建模和算法优化，以实现更精准有效的代理生成。该框架利用Model Context协议，提供统一框架标准，促进多环境和算法中智能代理的创建，并且包括适应性训练管理和智能反馈分析，实现持续改进。", "conclusion": "广泛的实验表明，$Agent^2$在MuJoCo、MetaDrive、MPE和SMAC等基准测试中均优于手工设计的解决方案，获得高达55%的性能提升和显著的平均改善。通过实现端到端、闭环的自动化，这项工作确立了一个新的智能代理设计并优化其他代理的新范例，这是一个在自动AI系统领域的根本性突破。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13376", "html_url": "https://arxiv.org/abs/2509.13376", "title": "在新世代空间多组学中的计算洞察力揭示生物系统之复杂性", "title_en": "Unleashing the power of computational insights in revealing the complexity of biological systems in the new era of spatial multi-omics", "authors": "Zhiwei Fan,Tiangang Wang,Kexin Huang,Binwu Ying,Xiaobo Zhou", "background": "近年来，空间组学技术的进步彻底改变了我们以前所未有的分辨率研究生物系统的能力。通过保留分子测量的空间上下文，这些方法可实现细胞异质性、组织结构和发育生物学、神经科学、肿瘤学和演化研究中动态生物过程的全面图谱绘制。本综述回顾了技术与计算算法的持续进步，这些进步推动了对哺乳动物组织和器官结构及其机制的深刻、系统性理解。", "innovation": "先进的机器学习算法和多组学整合建模能够破解复杂的生物过程，包括器官发育期间细胞的空间组织和拓扑关系，以及肿瘤发生和转移的关键分子标志和调控网络。", "conclusion": "本综述还概述了空间组学在精准医学中的未来技术创新和建模见解。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13360", "html_url": "https://arxiv.org/abs/2509.13360", "title": "PREDICT-GBM: 平台用于胶质母细胞瘤个体化计算肿瘤模型的稳健评估与开发", "title_en": "PREDICT-GBM: Platform for Robust Evaluation and Development of Individualized Computational Tumor Models in Glioblastoma", "authors": "L. Zimmer,J. Weidner,M. Balcerak,F. Kofler,I. Ezhov,B. Menze,B. Wiestler", "background": "胶质母细胞瘤是最常见的原发性脑恶性肿瘤，以其高度侵袭性及极高的复发率著称。传统的放射治疗采用统一的治疗边缘，未能考虑关键影响肿瘤细胞迁移的患者特异性解剖和生物学因素。为解决这一局限性，已开发了许多胶质母细胞瘤生长计算模型，能够生成超出影像学可见区域的肿瘤细胞分布图，从而指导更精确的治疗策略。尽管取得了初步的积极成果，但在临床上的应用仍然受到限制。为弥补这一转化差距，加速模型开发和临床验证，该文介绍了PREDICT-GBM（胶质母细胞瘤个体化计算肿瘤模型的平台），这是一个全面集成的管道和数据集，用于建模和评估。该平台使用专家编目临床数据集（包含255个完全肿瘤分割和组织特征图的个体），系统地比较了最先进的肿瘤生长模型。分析表明，基于肿瘤生长预测生成的个性化放疗计划比传统的均匀边缘方法在两个评估模型中取得了更优的复发覆盖效果。这项工作确立了一个用于推进和系统评估肿瘤生长建模方法的强大平台，最终目标是促进临床转化和提高患者预后。", "innovation": "引入了PREDICT-GBM平台，这是一个综合的集成管道和数据集，用于建模和评估胶质母细胞瘤的肿瘤生长模型。该平台使用专家编目临床数据集（包含255个完全肿瘤分割和组织特征图的个体），系统地比较了最先进的肿瘤生长模型。这种方法填补了计算肿瘤模型在临床转化中的空白，加速了模型开发和临床验证的过程。", "conclusion": "通过PREDICT-GBM平台，本文证明了基于肿瘤生长预测的个性化放疗计划比传统的均匀边缘治疗方案更具有复发覆盖效果。该平台为推进和系统评估肿瘤生长建模方法提供了强有力的支持，并最终目标是促进临床转化和改善患者的预后。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13374", "html_url": "https://arxiv.org/abs/2509.13374", "title": "基于条件扩散的奇异期权估值与对手方博弈", "title_en": "Valuation of Exotic Options and Counterparty Games Based on Conditional Diffusion", "authors": "Helin Zhao,Junchi Shen", "background": "传统模型在定价奇异期权和结构性产品时存在局限性，因为它们无法准确捕捉实际市场的非对称分布和波动集聚等现象。本文旨在解决这一问题，通过引入扩散条件概率模型（DDPM）生成更符合实际的股价路径来克服传统模型的不足。", "innovation": "本文提出了一个复合损失函数和金融特异特征相结合的方法，并通过对抗性回测的P-Q动态博弈框架来评估模型的经济价值。静态验证表明，P模型能够有效匹配市场均值和波动。在动态博弈中，P模型对于欧式和亚式期权比传统的蒙特卡洛模型表现出更高的盈利能力。", "conclusion": "扩散模型在提高定价准确性方面具有巨大潜力，但需要进一步研究以更好地建模极端市场风险。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13349", "html_url": "https://arxiv.org/abs/2509.13349", "title": "基于Point-JEPA的高效标签关节夹取预测", "title_en": "Label-Efficient Grasp Joint Prediction with Point-JEPA", "authors": "Jed Guzelkabaagac,Boris Petrović", "background": "该研究探讨了使用联合嵌入预测架构（Point-JEPA）进行三维自我监督预训练是否能够实现低标签条件下的高效夹取关节角度预测。研究使用从网格中提取的点云和经过ShapeNet预训练的Point-JEPA编码器进行训练，并通过胜利者全取和top-logit选择进行评估。", "innovation": "研究引入了一种新架构Point-JEPA，并在低标签条件下展示了其优势。研究采用点云作为输入，并通过自监督预训练和轻量级多假设头部训练模型，以提高预测精度并减少标注数据的需求。", "conclusion": "研究成果表明，JEPA样式预训练是数据高效夹取学习的一种实用方法。在DLR-Hand II数据集上，通过使用Point-JEPA，夹取关节角度的RMSE降低了26%，在低标签条件下实现了与全监督相当的表现。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13345", "html_url": "https://arxiv.org/abs/2509.13345", "title": "大型语言模型中的准确度悖论：生成型人工智能中幻觉风险的监管", "title_en": "Accuracy Paradox in Large Language Models: Regulating Hallucination Risks in Generative AI", "authors": "Zihao Li,Weiwei Yi,Jiahong Chen", "background": "随着大型语言模型（LLMs）渗透到日常决策中，它们的知识和社会风险需要迫切的审视。幻象问题，即生成虚假、误导性的、简化或不可靠的输出，已经成为了亟待解决的挑战。目前，监管、学术和技术界的讨论主要将准确性视为减轻这些危害的关键标准。然而，文章认为过度依赖准确性不仅错误地诊断了问题，还具有反作用效果：准确度悖论。在此背景下，文章从跨学科文献出发，构建了幻觉类型的分类，并展示了准确度悖论在三个交织维度上的表现：输出、个人和社会。", "innovation": "文章提出了准确度悖论这一概念，并通过构建幻觉类型的分类展示该悖论在三个交织维度上的表现：输出、个人和社会。文章证明，依赖准确性作为一个表面的可靠性的代理，导致了对话语流畅性和表层正确性的优化，而不是对知识可信度的关注，这会导致用户对看似准确但实际上在知识上站不住脚的输出产生被动信任。此外，准确性作为一个单一的指标无法检测那些虽然不是事实错误但仍然具有误导性、价值观倾向或社会扭曲效应的幻象，包括共识幻觉、阿谀雷同和微妙操纵。最后，监管过度强调准确性，模糊了幻象更广泛的社会后果，包括社会分类、隐私侵犯、公平损害、知识同质化等，这些都边缘化了异见，减少了多元性并导致了社会技能的退化。", "conclusion": "文章通过分析欧盟AI法案、GDPR和DSA，指出当前的监管措施尚未在结构上能够应对这些知识、关系和系统性的损害，这些损害由对准确性的过度依赖而加剧。通过揭示这些概念和实践上的挑战，文章呼吁转向多元的、情境敏感的和抗操纵的AI可信治理方法。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13381", "html_url": "https://arxiv.org/abs/2509.13381", "title": "AUVs合作目标探测：双时尺度分层MARDL方法", "title_en": "Cooperative Target Detection with AUVs: A Dual-Timescale Hierarchical MARDL Approach", "authors": "Zhang Xueyao,Yang Bo,Yu Zhiwen,Cao Xuelin,George C. Alexandropoulos,Merouane Debbah,Chau Yuen", "background": "自主水下机器人（AUVs）在协同探测和侦察方面展现出了巨大的潜力。然而，协作AUV通信增加了暴露的风险。在对抗环境中，如何在确保隐蔽操作的前提下实现高效的协同工作成为水下协同任务的关键挑战", "innovation": "提出了一种新颖的双时尺度分层多智能体近端策略优化（H-MAPPO）框架。高层组件基于中央AUV确定参与任务的个体，而低层组件通过参与AUV的功率和轨迹控制来降低暴露概率。与基准算法相比，该框架实现快速收敛，性能优异，并在确保隐蔽操作的前提下最大化长期协同效率", "conclusion": "研究结果表明，所提出的框架实现了快速收敛，性能优于基准算法，并在确保隐蔽操作的前提下最大化了长期的协同效率"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13386", "html_url": "https://arxiv.org/abs/2509.13386", "title": "VEGA: 通过物理信息神经操作员和近端策略优化的电动汽车导航代理", "title_en": "VEGA: Electric Vehicle Navigation Agent via Physics-Informed Neural Operator and Proximal Policy Optimization", "authors": "Hansol Lim,Minhyeok Im,Jonathan Boyack,Jee Won Lee,Jongseong Brad Choi", "background": "对软件定义的车辆（SDV）的需求正在上升，电动汽车（EV）配备了功能强大的计算机，使得车载AI系统可以优化基于车辆当前状况和环境的充电意识路径规划。本文的背景介绍了这一趋势，并提出了如何利用这些功能进行改进和优化的需求。", "innovation": "文章提出了VEGA：一个充电意识的EV导航代理，该代理使用Proximal Policy Optimization (PPO)并结合预算A*教师-学生指导，基于状态荷电（SoC）可行性的充电优化路径。VEGA的独特之处在于它通过物理学感知神经操作员（PINO）和强化学习（RL）系统结合，可以从车辆速度和电池功率日志中学习车辆特定的动力学，以优化路径，并计算最优充电站的停靠时间和停留时间，所有这些仅通过车辆速度信号完成。此外，VEGA展示了其在不同地理区域的强大泛化能力。", "conclusion": "虽然VEGA是在美国地区训练的，但它能够解决法国和日本的目标路径，证明了其高度的泛化能力。未来的工作将致力于更加准确地估计车辆状态，以进一步提高效率和优化路径选择。VEGA将物理信息学习与RL结合，为电动汽车的环保路径规划提供了一种切实可行的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13414", "html_url": "https://arxiv.org/abs/2509.13414", "title": "MapAnything：通用端到端尺度不变3D重建", "title_en": "MapAnything: Universal Feed-Forward Metric 3D Reconstruction", "authors": "Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder", "background": "在3D视觉任务中，传统的模型往往需要针对特定的任务进行定制，这就导致了训练和评估的复杂性。现有方法往往在鲁棒性和泛化能力上存在局限，且不同任务之间的模型无法直接互换使用。", "innovation": "MapAnything是一种统一的基于Transformer的前馈模型，能够同时处理一个或多个图像及其可选的几何输入（如相机内参数、姿态、深度或部分重建），并直接回归度量3D场景几何和相机姿态。它通过一种因变量表示的多视图场景几何，即一组深度图、局部射线图、相机姿态和度量尺度因子，有效升级局部重建为全局一致的度量框架。该模型通过标准化监督和训练，并结合灵活的输入增强，能够应对广泛的3D视觉任务，包括未校准的结构从运动、校准的多视图立体、单目深度估计、相机定位、深度补全等。", "conclusion": "实验分析和模型消融研究证明了MapAnything在多种任务上的优越性能或与专业模型相当，并且表现出更高效的联合训练行为，为通用3D重建骨干网开发提供了新的思路。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13399", "html_url": "https://arxiv.org/abs/2509.13399", "title": "EdiVal-Agent: 一种面向对象的自动化、可扩展且精细粒度的多轮编辑评估框架", "title_en": "EdiVal-Agent: An Object-Centric Framework for Automated, Scalable, Fine-Grained Evaluation of Multi-Turn Editing", "authors": "Tianyu Chen,Yasi Zhang,Zhi Zhang,Peiyu Yu,Shu Wang,Zhendong Wang,Kevin Lin,Xiaofei Wang,Zhengyuan Yang,Linjie Li,Chung-Ching Lin,Jianwen Xie,Oscar Leong,Lijuan Wang,Ying Nian Wu,Mingyuan Zhou", "background": "基于指令的图像编辑技术发展迅速，但可靠且可解释性的评估仍然是一个瓶颈。当前的评估协议要么依赖配对的参考图像，导致评估覆盖范围有限且可能存在偏差，要么依赖零样本视觉-语言模型（VLMs）进行评估，这些模型基于提示的评估往往不够精准，包含指令跟随、内容一致性和视觉质量等多个方面.", "innovation": "本文提出了EdiVal-Agent，一种面向对象的自动化、可扩展且精细粒度的多轮图像编辑评估框架。该框架首先将图像分解为语义上有意义的对象，然后合成多样化、情境化的编辑指令。评估层面，EdiVal-Agent将VLMs与开放式词汇量对象检测器结合用于指令跟随评估，通过语义级别特征提取器用于内容一致性的评估，同时使用人类偏好模型来判断视觉质量。研究结果表明，组合使用VLMs和对象检测器在指令跟随评估中比单独使用VLMs表现更优。此外，该管道的模块化设计能够允许将来工具的无缝集成，从而在未来提升评估精度.", "conclusion": "通过EdiVal-Bench实验证明，EdiVal-Agent能够识别现有的失败模式，为下一代编辑模型的开发提供指导。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13390", "html_url": "https://arxiv.org/abs/2509.13390", "title": "基于领域知识的电动车辆内部声音异常检测的方法", "title_en": "A Domain Knowledge Informed Approach for Anomaly Detection of Electric Vehicle Interior Sounds", "authors": "Deepti Kunte,Bram Cornelis,Claudio Colangeli,Karl Janssens,Brecht Van Baelen,Konstantinos Gryllias", "background": "汽车内饰声音的异常检测对于保证汽车质量和乘客舒适度至关重要。在许多实际应用中，由于缺乏或根本没有标记的故障数据，这一任务更适合作为一个无监督学习问题。模型仅通过训练健康样本来检测异常，即基于正常行为的偏差。然而，由于缺乏标记的故障样本进行验证以及常用评估指标（如验证重建误差）的有限可靠性，有效的模型选择依然是一个重大挑战。", "innovation": "提出了一种基于领域知识的方法进行模型选择，利用通过结构化健康声谱图扰动生成的代理异常样本作为验证集的支持，以帮助模型选择。该方法在使用高级声音合成技术生成并由专家评审验证的真实精度电动汽车内饰声音数据集上进行了评估。", "conclusion": "实验结果显示，使用代理异常进行模型选择比传统模型选择策略更优，能够在五种故障情况下选出最优模型。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13395", "html_url": "https://arxiv.org/abs/2509.13395", "title": "TICL: 基于文本嵌入KNN的语音上下文学习增强大型多模态模型的语音识别能力", "title_en": "TICL: Text-Embedding KNN For Speech In-Context Learning Unlocks Speech Recognition Abilities of Large Multimodal Models", "authors": "Haolong Zheng,Yekaterina Yegorova,Mark Hasegawa-Johnson", "background": "近年来，语音基础模型展示了在语音上下文学习（SICL）方面的能力。但如何选择有效的上下文例句仍然较少研究。以往方法主要依赖于调整模型参数（即微调），但此类方法存在模型效率较低的问题。本文探讨了如何在不进行微调的情况下，利用语义上下文提升speech基础模型的识别能力，特别是在口音英语、多语种语音和儿童语音等挑战性任务中取得了显著效果。", "innovation": "提出了TICL方法，这是一个简单的工作流程，利用语义上下文来增强预训练的大型多模态模型的语音识别能力，无需微调。这种方法通过KNN算法和文本嵌入技术，能够选择和利用相关的文本信息来增强语音模型的性能，特别是在不同类型的语音识别任务中表现出显著的优势。", "conclusion": "通过多种挑战性的语音识别任务评估，TICL方法能够在多语种、口音英语和儿童语音等多种录音中显著提升语音基础模型的表现，相对错误率最高降低了84.7%。进一步的消融实验展示了该方法的稳定性和效率，为语音基础模型的实际应用提供了新的思路。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13371", "html_url": "https://arxiv.org/abs/2509.13371", "title": "一种商业建筑基冰热能储存（TES）系统的一天前冷却负荷预测和优化控制新型方法", "title_en": "A novel approach of day-ahead cooling load prediction and optimal control for ice-based thermal energy storage (TES) system in commercial buildings", "authors": "Xuyuan Kang,Xiao Wang,Jingjing An,Da Yan", "background": "热能储存（TES）是建筑中负载转移和需求响应的有效方法。现有大多数TES系统遵循固定的日程安排，无法充分利用负载转移能力，需要广泛的调查和优化。研究旨在提出一个新型的集成负荷预测和优化控制方法，以提升冰基TES系统的性能。该方法针对商业建筑进行优化，并引入了午后调节机制来提高负荷预测模型的准确性。基于预测，开发了一种基于时间使用的费率的规则控制策略，同时在午后预测修改的基础上引入了午后控制调整机制，实际应用于北京的一个商业综合体中的冰基TES系统。", "innovation": "本研究提出了一种新的集成一天前冷却负荷预测和优化控制的方法，专门针对商业建筑中的冰基TES系统。该方法不仅开发了冷却负荷预测模型，还引入了午后修改机制以提高预测准确性，并基于这种预测开发了一种基于时间使用的费率的规则控制策略，并在实际中引入了午后控制调整机制。这种方法显著提高了一天前的负荷预测准确性，并实现了能源成本节约率高达9.9%的效果。", "conclusion": "整体研究结果表明，集成负荷预测与优化控制的理论能够成功应用于商业建筑的冰基TES系统中，显著提高了能源使用效率和自动化的程度，同时也展示了算法在实际建筑自动化系统中的适应性和有效性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13380", "html_url": "https://arxiv.org/abs/2509.13380", "title": "ASTREA：为轨道热自主引入代理人工智能", "title_en": "ASTREA: Introducing Agentic Intelligence for Orbital Thermal Autonomy", "authors": "Alejandro D. Mousist", "background": "该论文介绍了一种名为ASTREA的代理系统，这是首个在飞行验证硬件上部署的自主航天器操作系统（技术成熟度等级9级）。利用热控作为代表性应用场景，该系统将资源受限的大语言模型（LLM）代理与基于强化学习的控制器在一个为太空资格平台定制的异步架构中结合。地面实验表明，LLM指导的监督能提高热稳定性并减少违背，证明了在硬件限制条件下将语义推理与自适应控制结合的可行性。然而，在国际空间站（ISS）上轨验证发现，由于推断延迟与低地轨道（LEO）卫星快速热循环不匹配，导致性能下降。", "innovation": "创新之处在于其将资源受限的大语言模型代理与基于强化学习的控制器结合，构建了一个适用于太空资格平台的异步架构。这种结合在传统自适应控制和语义推理之间建立了有效的桥梁，同时也展示了在真实飞行环境中这种系统的潜力和局限性。", "conclusion": "研究结果揭示了代理大语言模型系统在实际飞行环境中的机会和现有局限，为其未来发展提供了实际的设计指南。特别是在低地轨道卫星快速热循环下的性能退化情况表明，在设计未来太空自主系统时需要考虑硬件约束和推断延迟的问题。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13577", "html_url": "https://arxiv.org/abs/2509.13577", "title": "动态意识：自主车辆轨迹预测中的自适应多模式出轨检测", "title_en": "Dynamic Aware: Adaptive Multi-Mode Out-of-Distribution Detection for Trajectory Prediction in Autonomous Vehicles", "authors": "Tongfei Guo,Lili Su", "background": "轨迹预测是自主车辆（AVs）安全无缝运行的关键。然而，在部署过程中，预测模型会不可避免地遇到训练数据和实际条件之间的分布偏移，其中罕见或未充分代表的交通场景会产生出轨（OOD）情况。虽然大多数先前的AVs出轨检测研究集中在计算机视觉任务如目标检测和分割上，但在轨迹层面的出轨检测仍然尚未充分探索。", "innovation": "基于最近的一项将此问题形式化为快速变化检测（QCD）任务的研究，提出了一个新的框架，引入了自适应机制，以在复杂驾驶环境中实现稳健的检测。通过显式建模预测误差模式，该方法在检测延迟和误报率方面实现了显著改进。全面的实验表明，我们的框架在准确性和计算效率方面明显优于之前的不确定性量化（UQ）和视觉基线的AVs OOD方法，提供了可靠、感知驾驶的自主性实用途径。", "conclusion": "我们的工作揭示了预测误差在分布内的样本上也表现出随时间变化且数据集相关性的模式分布，并通过在这方面建模实现了检测延迟和误报率的实质性改进。该框架在已建立的轨迹预测基准测试上表现出色，提供了比先前方法更高的准确性和计算效率，为自主驾驶提供了实际可行的道路。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13385", "html_url": "https://arxiv.org/abs/2509.13385", "title": "将曲率作为评估降维技术和估算固有维度的工具", "title_en": "Curvature as a tool for evaluating dimensionality reduction and estimating intrinsic dimension", "authors": "Charlotte Beylier,Parvaneh Joharinad,Jürgen Jost,Nahid Torbati", "background": "利用新近发展的抽象曲率概念，我们提出了一种基于曲率构造离散度量空间几何轮廓的方法。该方法中的曲率概念捕捉了三元点与其他点之间的度量关系。此外，基于这种曲率轮廓，我们还引入了一种定量方法来评估数据表示的有效性，如降维技术生成的数据表示。我们的实验表明，这种基于曲率的分析可用于估计数据集的固有维度，并据此探索真实网络的大规模几何结构以及评估降维技术的有效性。", "innovation": "介绍了利用抽象曲率概念来构造离散度量空间的曲率基几何轮廓的方法，提出了一种基于该轮廓的定量方法来评估数据表示的有效性，特别是在固有维度估计和降维技术评估方面。", "conclusion": "通过基于曲率的分析方法，可以估计数据集的固有维度，并用于研究真实网络的大规模几何结构，同时评估了降维技术的性能。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13459", "html_url": "https://arxiv.org/abs/2509.13459", "title": "为何并非所有道路都能通向罗马：人类视觉皮层层级中表征几何形态各异", "title_en": "Why all roads don't lead to Rome: Representation geometry varies across the human visual cortical hierarchy", "authors": "Arna Ghosh,Zahraa Chorghay,Shahab Bakhtiari,Blake A. Richards", "background": "生物和人造智能系统在编码输入空间的众多属性时必须在效率和鲁棒性之间做出权衡，即它们不仅需要高效地编码输入空间的各种属性，还需要对噪声具有鲁棒性。这一挑战在人类大脑这样的分层处理系统中尤为明显。研究者们利用群体几何框架来分析人类视觉皮层和人工神经网络（ANNs）的表示方式，以求理解系统如何在效率和鲁棒性之间进行权衡。研究结果发现，视觉流中最底层的区域具有普适的、无标度的表示形式，但某些高层区域并未展现出无标度特性，表明无标度几何并不是大脑的普遍特性。此外，使用自监督学习策略训练的ANN也表现出无标度几何形态，但在特定任务微调后则不再具备这样的特性。这些实验结果表明，系统的表征几何形态不是普遍特性，而是受计算目标的影响.", "innovation": "本文的创新之处在于提出了群体几何框架来分析人类视觉皮层和人工神经网络的表示方式，并且发现了不同层级的视觉皮层和人工神经网络在表征几何上的差异，此研究为理解效率和鲁棒性之间权衡提供了新的视角。研究结果表明，表征几何形态不是普遍特性，而是依赖于计算目标，这改变了以往关于大脑无标度几何特性的普遍看法.", "conclusion": "系统的表征几何形态并非是一个普遍适用的特性，而是由其特定的计算目标决定。这意味着系统效率和鲁棒性之间的权衡在不同的计算目标下可能会有不同的表现形式。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13579", "html_url": "https://arxiv.org/abs/2509.13579", "title": "TreeIRL: 使用树搜索和逆强化学习在城市中实现安全驾驶", "title_en": "TreeIRL: Safe Urban Driving with Tree Search and Inverse Reinforcement Learning", "authors": "Momchil S. Tomov,Sang Uk Lee,Hansford Hendrago,Jinwook Huh,Teawon Han,Forbes Howington,Rafael da Silva,Gianmarco Bernasconi,Marc Heim,Samuel Findler,Xiaonan Ji,Alexander Boule,Michael Napoli,Kuo Chen,Jesse Miller,Boaz Floor,Yunqing Hu", "background": "当前的自主驾驶规划在模拟和真实世界中的表现不尽如人意。研究人员开发了新的规划设计方法，旨在提高自主驾驶的安全性、进步性、舒适性和人性化。现有的规划器通常只关注部分指标，因而需要一个同时考虑多种指标的综合评估方法。此外，研究工作还需要在真实世界环境中验证，以确保规划器的实际效果。TreeIRL 的提出正是基于这种背景，结合 Monte Carlo 树搜索 (MCTS) 和逆强化学习 (IRL)，旨在解决自主驾驶规划中的瓶颈问题。", "innovation": "提出 TreeIRL，这是一种新颖的自主驾驶规划器，将 Monte Carlo 树搜索（MCTS）与逆强化学习（IRL）相结合，实现了在模拟和真实路况下的最佳性能。其核心思想是利用 MCTS 找到一组有前途的安全候选轨迹，并通过深度 IRL 评分函数从中选择最具人类行为特征的路径。TreeIRL 利用树搜索和逆强化学习来优化轨迹选择，同时平衡安全、进步、舒适和人类特征。此外，研究者还展示了在公共道路上使用基于 MCTS 的规划器，并强调了评估规划器时应综合考虑多种指标并在真实环境中进行验证的重要性。", "conclusion": "TreeIRL 是高度可扩展的，并且可以通过强化学习和模仿学习进一步改进，提供了一种探索不同组合的经典和学习方法以解决自主驾驶规划瓶颈问题的框架。结合广泛的测试场景，包括密集城市交通、自适应巡航控制、插入行为和交通信号灯，TreeIRL 在各方面都达到了最佳性能。这项工作是首次展示基于 MCTS 的公共道路规划，并突显了评估规划器的多样性指标和真实环境的重要性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13705", "html_url": "https://arxiv.org/abs/2509.13705", "title": "学习局域量子多位数据：一个可证明可扩展的框架", "title_en": "Learning quantum many-body data locally: A provably scalable framework", "authors": "Koki Chinzei,Quoc Hoan Tran,Norifumi Matsumoto,Yasuhiro Endo,Hirotaka Oshima", "background": "机器学习（ML）在从复杂量子多体实验数据中提取见解方面具有巨大潜力。这种方法能够高效地解决某些经典计算无法解决的量子问题，暗示利用量子数据可能存在优势。然而，解决大规模问题仍然需要超出近期内量子设备有限计算资源的大量数据。", "innovation": "本文提出了一种可扩展的机器学习框架——几何局部量子内核（GLQK），旨在通过利用相关性在非临界系统中的指数衰减来高效学习量子多体实验数据。与现有的阴影核相比，GLQK能够在量子位数量n增加时，显著提高多项式样本复杂性。特别地，对于平移对称数据，GLQK实现了常数样本复杂性，与n无关。通过两个量子多体现象的学习任务，数值演示了其高可扩展性。", "conclusion": "这些结果为利用实验数据推进对量子多体物理学的理解开辟了新的途径，提出了一个可证明可扩展的框架来高效学习量子多位数据。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13624", "html_url": "https://arxiv.org/abs/2509.13624", "title": "潜在特质与跨任务迁移：分解LLM微调中的数据集交互", "title_en": "Latent Traits and Cross-Task Transfer: Deconstructing Dataset Interactions in LLM Fine-tuning", "authors": "Shambhavi Krishna,Atharva Naik,Chaitali Agarwal,Sudharshan Govindan,Taesung Lee,Haw-Shiuan Chang", "background": "大型语言模型在各种应用中越来越受到部署，但这些模型在训练时并没有经历所有可能的任务。因此，获取高质量的训练数据来进行所有任务的枚举和标注变得更加不切实际。为了应对这一挑战，研究者们依赖不同的数据集进行迁移学习，并预测未遇到的任务（out-of-distribution）的需求。本文探讨了跨任务迁移学习的数据集交互问题，以解决这一实际需求，分析了迁移学习过程中隐藏的因素对模型性能的影响。", "innovation": "本文提出了一种分析框架，构建迁移学习矩阵和降维，以剖析不同任务之间的交互作用。通过训练和分析10个模型，识别出潜在的能力（例如：推理、情感分类、NLU、算术），并探索迁移学习中的副作用。研究发现，模型性能的提高往往不能仅通过表面数据集相似性或源数据质量来解释，而是更依赖于源数据集隐藏的统计特征，如类别分布和生成长度倾向，以及特定的语言特征。这项研究为理解迁移学习的复杂动态提供了洞察，有助于开发更可预测和有效的LLM迁移适应方法。", "conclusion": "本文揭示了迁移学习中隐藏的因素对模型性能的影响，挑战了仅依据表面数据集相似性或源数据质量解释模型性能改进的传统观点。通过对迁移学习过程中的潜在能力进行识别，研究提出了有助于模型更有效适应的方法，为未来的研究提供了新的视角，有助于提高大语言模型在实际应用中的性能和可靠性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13628", "html_url": "https://arxiv.org/abs/2509.13628", "title": "带有偏置梯度估计的加速梯度方法：风险敏感性、高概率保证和大偏差界", "title_en": "Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds", "authors": "Mert Gürbüzbalaban,Yasa Syed,Necdet Serhat Aybat", "background": "本文研究了在第一阶优化方法中收敛速率和对梯度误差鲁棒性之间的权衡。研究集中在广义动量方法（GMMs）类上，包括Nesterov加速梯度、重球法和梯度下降法。考虑了可能是对抗性且有偏的随机梯度误差，并通过鲁棒控制理论中的风险敏感指标（RSI）来量化鲁棒性。此外，对于具有独立同分布高斯噪声的二次目标函数，本文通过2x2 Riccati方程给出了RSI的闭式表达式。证明了时间平均次优性的大偏差原则，并展示了速率函数与RSI的凸共轭关系。这一研究揭示了RSI与收敛速率之间的权衡。进一步将RSI与H∞范数关联起来，表明更强的鲁棒性（较小的H∞范数）导致了更严格的尾概率衰减。对于非二次目标函数，在有偏次高斯梯度误差下，本文还推导出了带有偏置的数据的RSI的非渐近界，提供了高概率保证和大偏差界。同时也观察到对于光滑严格凸函数，RSI与收敛速率界之间的类似权衡。", "innovation": "本文首次提供了带有偏置梯度估计的广义动量方法（GMMs）的非渐近保证和风险敏感性分析。引入了风险敏感指标（RSI），并通过2x2 Riccati方程给出了二次目标函数下RSI的闭式表达。证明了时间平均次优性的大偏差原则，并通过H∞范数展示了强大的鲁棒性意味着更严格的尾概率衰减。在偏置次高斯梯度误差下推导了有限时间内的非渐近界，提供了高概率保证和大偏差界。同时也揭示了光滑严格凸函数中的类似RSI与收敛速率的权衡关系。", "conclusion": "本文的研究结果揭示了广义动量方法在收敛性和鲁棒性之间的权衡关系，并提供了首个带有偏置梯度估计的广泛动量方法的非渐近保证和风险敏感性分析。这些结果对于理解和优化加速梯度方法在存在噪声和偏误情况下的性能具有重要意义。数值实验说明了研究结果的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13496", "html_url": "https://arxiv.org/abs/2509.13496", "title": "BiasMap: 利用交叉注意力发现和缓解文本到图像生成中的隐含社会偏见", "title_en": "BiasMap: Leveraging Cross-Attentions to Discover and Mitigate Hidden Social Biases in Text-to-Image Generation", "authors": "Rajatsubhra Chakraborty,Xujun Che,Depeng Xu,Cori Faklaris,Xi Niu,Shuhan Yuan", "background": "黑盒生成模型中的偏差发现对于确保模型公平至关重要，特别是在文本到图像（TTI）模型中。现有工作主要关注输出层面的人口统计学分布，但这些方法不一定能确保概念表示在修正后被解缠。因此，需要一个适用于各种生成模型的方法，用于发现稳定扩散模型中的潜在概念层面表示偏差。当前的公平性发现方法往往只关注可观察到的输出分布差距，而未能充分揭示深层次的概念缠结问题，这也是现有方法的局限性所在。为了克服这些问题，提出了BiasMap，这是一个模型无关的框架，用于发现稳定扩散模型中的潜在概念层表示偏差。BiasMap通过利用跨注意力（cross-attention）归因图，揭示了人口统计学因素（如性别、种族）和语义特征（如职业）之间的结构缠结，深入探索生成过程中的表示偏差。通过这些概念的归因图，BiasMap利用交并比（IoU）量化了空间上的人口统计学-语义概念缠结，提供了一种揭示隐藏在现有公平性发现方法中的偏见的新视角。除了发现偏差，BiasMap还通过能量引导扩散采样进一步利用这些概念，直接修改潜在噪声空间，减少去噪过程中的SoftIoU期望值，从而从根本上缓解结构缠结。研究表明，现有的公平性干预措施虽然可以在一定程度上缩小输出分布差距，但往往无法很好地解缠概念耦合，而BiasMap的方法能够有效缓解图像生成中的概念缠结，同时补充分布层面上的偏见缓解效果，而不会降低生成图像的质量。", "innovation": "提出了BiasMap，这是一个模型无关的框架，用于发现稳定扩散模型中的潜在概念层表示偏差。BiasMap通过利用跨注意力（cross-attention）归因图，揭示了人口统计学因素和语义特征之间的结构缠结，并利用交并比（IoU）量化了空间上的人口统计学-语义概念缠结。此基础上，BiasMap进一步利用能量引导扩散采样直接修改潜在噪声空间，减少去噪过程中的SoftIoU期望值，从而从根本上缓解结构缠结。这为隐藏在现有公平性发现方法中的深层次偏见提供了新的发现和缓解思路，且方法更具有普适性，不仅能够发现模型中的潜在概念缠结，还能够有效缓解这些缠结问题。总体来说，BiasMap 提供了一种更为深层次和有效的方式来发现和缓解模型中的偏差问题。", "conclusion": "BiasMap 能够有效发现并缓解图像生成中的概念缠结，不仅仅是在输出分布层面上缩小差距，还能更深层次地解决人口统计学特征和语义特征之间的深度纠缠问题。此外，BiasMap 还通过能量引导扩散采样直接修改潜在噪声空间，进一步优化了缓解效果，证明了现有的公平性干预措施虽然能在一定程度上减少分布差距，但往往不能完全解决概念层面的纠缠问题，而 BiasMap 所提出的方法可以同时处理分布和概念层面的公平性问题。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13821", "html_url": "https://arxiv.org/abs/2509.13821", "title": "从量子模拟器快照中学习最小表示的多体物理", "title_en": "Learning Minimal Representations of Many-Body Physics from Snapshots of a Quantum Simulator", "authors": "Frederik Møller,Gabriel Fernández-Fernández,Thomas Schweigler,Paulin de Schoulepnikoff,Jörg Schmiedmayer,Gorka Muñoz-Gil", "background": "模拟器提供了超越经典计算能力的多体动态分析手段，但实验数据中的测量噪声、可观测量限制以及对微观模型的不完全理解常常阻碍了物理洞见的提取。该项目致力于通过基于变分自编码器（VAE）的机器学习方法来处理这一问题，特别针对隧道耦合的一维玻色气体的干涉测量进行分析，利用这些系统来实现sine-Gordon量子场理论。", "innovation": "该项目利用VAE进行无监督训练，学习与系统平衡控制参数高度相关的最小潜变量表达，这种方法可以揭示非平衡协议下的快斟冷后冻结溶子的特征，及其常规相关性方法未能捕捉到的异常后突发动力学。该研究证明，生成模型可以直接从无噪声和稀疏的实验数据中抽取物理可解释变量，从而提供对量子模拟器中的平衡和非平衡物理的补充探针，为多体量子系统中的可扩展数据驱动发现奠定了基础。", "conclusion": "这项工作强调了机器学习如何补充现有的场论技术，并为量子多体系统的可扩展数据驱动发现开辟了新的途径。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13476", "html_url": "https://arxiv.org/abs/2509.13476", "title": "基于几何图的深度学习模型在药物-靶标亲和力预测中的应用", "title_en": "A Geometric Graph-Based Deep Learning Model for Drug-Target Affinity Prediction", "authors": "Md Masud Rana,Farjana Tasnim Mukta,Duc D. Nguyen", "background": "在基于结构的药物设计中，准确估计候选配体与蛋白质受体之间的结合亲和力是一个核心挑战。近年来，人工智能特别是深度学习技术在这一任务中的性能超过传统经验性和物理方法，尤其是在结构和实验亲和力数据快速增长的情况下。本文在这一背景下，介绍了一种新的深度学习模型DeepGGL，该模型结合了残差连接和注意力机制，应用于几何图学习框架中，通过利用多尺度加权彩色二分子图，在蛋白-配体复合物中有效捕捉不同尺度的原子级相互作用。", "innovation": "该模型引入了DeepGGL，这是一种结合了残差连接和注意力机制的深度卷积神经网络，应用于几何图学习框架。通过利用多尺度加权彩色二分子图，DeepGGL能够有效捕捉蛋白-配体复合物中原子级层次的相互作用，特别是在多个尺度上实现这一目标。", "conclusion": "DeepGGL在CASF-2013和CASF-2016数据集上表现出了在多种评估指标上显著优于现有模型的性能，并在CSAR-NRC-HiQ数据集和PDBbind v2019保留集上的测试中，保持了高预测准确性，展示了其在基于结构的药物发现领域中用于结合亲和力预测的适应性和可靠性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13772", "html_url": "https://arxiv.org/abs/2509.13772", "title": "谁传授了谎言？检索增强生成中的有毒知识责任归属", "title_en": "Who Taught the Lie? Responsibility Attribution for Poisoned Knowledge in Retrieval-Augmented Generation", "authors": "Baolei Zhang,Haoran Xin,Yuxi Chen,Zhuqing Liu,Biao Yi,Tong Li,Lihai Nie,Zheli Liu,Minghong Fang", "background": "检索增强生成（RAG）将外部知识集成到大型语言模型中以提高响应质量。然而，最近的研究表明，RAG系统对中毒攻击极为脆弱，攻击者可以在知识数据库中插入恶意文本以影响模型输出。虽然已有一些防护措施，但它们常常被更加适应性强或更为复杂的攻击所规避。", "innovation": "本文提出了一种名为RAGOrigin的黑盒责任归属框架，旨在识别导致误导或错误生成的文本责任。该方法针对每个误生成事件构建聚焦的责任归属范围，通过评估检索排名、语义相关性以及对生成响应的影响为每个候选文本分配责任分数。系统随后使用无监督聚类方法隔离被污染的文本。通过七个数据集和十五种中毒攻击场景的评估，包括新开发的适应性中毒策略和多攻击者场景，本文的方法在识别和防御受污染内容方面优于现有基准，且在动态和嘈杂条件下依然稳健。这些结果表明，RAGOrigin提供了追溯RAG系统中受污染知识来源的实用且有效的解决方案。", "conclusion": "该研究通过系统的方法有效识别了RAG系统中受污染的文本，并证明了这种方法在面对复杂的攻击和不稳定条件时依然具有强大的性能，从而为保障RAG系统的可靠性和安全性提供了有效的工具。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13653", "html_url": "https://arxiv.org/abs/2509.13653", "title": "通过自适应奖励转换实现有效的最后一迭代收敛", "title_en": "Efficient Last-Iterate Convergence in Regret Minimization via Adaptive Reward Transformation", "authors": "Hang Ren,Yulin Wu,Shuhan Qi,Jiajia Zhang,Xiaozhen Sun,Tianzi Ma,Xuan Wang", "background": "遗憾最小化是一种强大的方法，可应用于标准型博弈（NFGs）和扩展型博弈（EFGs）中的纳什均衡寻找。遗憾最小化通常仅保证平均策略的收敛性，但计算平均策略需要大量计算资源或者会引入额外误差，限制了其实际应用。奖励转换（RT）框架通过奖励函数正则化实现了最后一个迭代的收敛，但其性能高度依赖于手动调整的参数，并且经常偏离理论收敛条件，导致收敛缓慢、振荡或停滞在局部最优解中。", "innovation": "本文提出了自适应技术，确保RT遗憾匹配（RTRM）和RT反事实遗憾最小化（RTCFR）及其变体在解决NFGs 和EFGs时，更好地保持理论保证和实际性能的一致性。自适应方法动态调整参数，平衡探索和利用，提高遗憾积累，最终增强渐近的最后一迭代收敛性，并实现线性收敛。实验结果表明，本文方法大幅加速了收敛，优于最先进的算法。", "conclusion": "本文提出的方法通过动态调整参数，有效解决了RT框架的理论收敛与实际应用脱节的问题，显著提高了NFGs 和EFGs中的遗憾最小化算法的收敛效率和性能，为博弈论中的算法应用提供了新的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13846", "html_url": "https://arxiv.org/abs/2509.13846", "title": "一致视角对齐提高3D医学图像分割的基模型性能", "title_en": "Consistent View Alignment Improves Foundation Models for 3D Medical Image Segmentation", "authors": "Puru Vaish,Felix Meister,Tobias Heimann,Christoph Brune,Jelmer M. Wolterink", "background": "许多最新的表示学习方法隐含地假设，数据点的不相关视图足以学习有意义的表示，以便于各种下游任务。这项工作中，作者挑战了这一假设，证明了有意义的潜在空间结构不会自然出现，而是需要明确诱导。", "innovation": "作者提出了一种方法，通过将数据的不同视图表示对齐来对齐互补信息，而不会引入虚假 positives。这种方法在 MICCAI 2025 SSL3D 挑战中，使用 Primus 视觉变换器和 ResEnc 卷积神经网络分别获得了第一名和第二名的成绩。该方法显著提升了多模态基模型在3D医学图像分割任务中的性能，强调了结构化视图对齐在学习有效表示中的关键作用。", "conclusion": "实验结果表明，作者提出的自监督学习方法一致视角对齐（Consistent View Alignment），能提高下游任务的性能，并且通过挑战传统认识，明确指出结构化的视图对齐在表示学习中至关重要。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13450", "html_url": "https://arxiv.org/abs/2509.13450", "title": "SteeringControl：全面评估大语言模型中的对齐引导", "title_en": "SteeringControl: Holistic Evaluation of Alignment Steering in LLMs", "authors": "Vincent Siu,Nicholas Crispino,David Park,Nathan W. Henry,Zhun Wang,Yang Liu,Dawn Song,Chenguang Wang", "background": "尽管之前的对齐工作常通过强调真实性或推理能力来展示对齐引导的副作用，但研究发现，关于对齐引导方法与模型目标之间系统性关联的许多潜在权衡关系仍未被充分理解。为了系统地评估各种对齐方法的有效性和行为交织情况，研究者们收集了一个跨主要和次要行为的安全适用数据集，并开发了一种模块化对齐引导框架，以评估五种流行的对齐方法。然而，研究结果表明，强对齐性能取决于特定的对齐方法、模型和目标行为的组合，而不当的组合可能导致严重的概念交织。", "innovation": "该研究创新性地提出了一种名为SteeringControl的基准，用于全面评估大语言模型中的对齐引导。该基准聚焦于偏见、有害生成和幻觉等对齐核心目标，并进一步评估这些对齐方法对奉承行为和常识道德等次要行为的影响。研究者还开发了一种基于独特组件的模块化对齐引导框架，该框架作为许多现有方法的基础。这项工作有助于系统地理解对齐方法、目标行为与模型之间的关系。", "conclusion": "在Qwen-2.5-7B和Llama-3.1-8B模型上的实验结果表明，强劲的对齐引导性能依赖于特定的对齐方法、模型和目标行为组合，不当的组合可能导致显著的概念交织。为了改善当前对齐方法的系统理解，研究者发布了自己的代码供进一步研究使用。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13863", "html_url": "https://arxiv.org/abs/2509.13863", "title": "LamiGauss: 使用辐射高斯的稀疏视图X射线层析重建", "title_en": "LamiGauss: Pitching Radiative Gaussian for Sparse-View X-ray Laminography Reconstruction", "authors": "Chu Chen,Ander Biguri,Jean-Michel Morel,Raymond H. Chan,Carola-Bibiane Schönlieb,Jizhou Li", "background": "X射线层析(laminography, CL)对于微芯片和复合电池材料等板状结构的非破坏性检测非常重要。传统的X射线计算机断层扫描(computed tomography, CT)由于几何约束，难以应对这类检测需求。在高度稀疏视图的采集条件下，从层析投影重建高质量体积仍然具有挑战性。", "innovation": "本文提出了一种新的重建算法LamiGauss，结合了高斯遮点射线射描技术和专有的检测器到世界转换模型，该模型包括了层析倾斜角度。LamiGauss采用初始化策略，明确过滤初步重建中的常见层析伪影，避免多余的高斯分布被分配到虚假结构，从而集中模型容量用于真实物体的表征。该方法直接优化从稀疏投影，实现用少量数据获得准确高效的重建。", "conclusion": "在合成和真实数据集上的广泛实验表明，LamiGauss方法优于现有技术。仅使用全视图的3%数据，LamiGauss就达到了更好的性能，超过了在完整数据集上迭代优化的方法。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13848", "html_url": "https://arxiv.org/abs/2509.13848", "title": "SpecDiff: 使用自我推测加速扩散模型推理", "title_en": "SpecDiff: Accelerating Diffusion Model Inference with Self-Speculation", "authors": "Jiayi Pan,Jiaming Xu,Yongkang Zhou,Guohao Dai", "background": "特征缓存作为一种加速扩散模型的有前景方法已近年兴起。它通过在推理过程中缓存相似特征来有效缓解高计算需求导致的效率问题。", "innovation": "提出了一种基于自我推测信息的新颖范式，引入未来信息来实现特征缓存。在此基础上，提出了一种名为SpecDiff的无需训练的多级特征缓存策略，包括基于自我推测信息的特征选择算法和多级特征分类算法。", "conclusion": "实验表明，SpecDiff在Stable Diffusion 3、3.5和FLUX中，相对于RFlow分别实现了平均2.80倍、2.74倍和3.17倍的加速，同时质量损失几乎可以忽略。通过结合推测和历史信息，SpecDiff克服了加速-准确性的折衷瓶颈，推动了加速和准确性的帕累托前沿。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13975", "html_url": "https://arxiv.org/abs/2509.13975", "title": "分类滤波", "title_en": "Classification Filtering", "authors": "Ilker Bayram", "background": "本文考虑一种流数据信号，其中每个样本关联到一个隐含类别。假设有多个人工智能分类器可用，每个分类器提供不同准确度的类别概率。这些分类器按照简单且固定的方式使用。本文探讨在融合这些分类器输出时如何考虑时间上的因素，以提高分类准确性。", "innovation": "提出了一种状态空间模型，并开发了适用于实时执行的滤波器。通过在基于可穿戴设备的惯性测量单元（IMU）数据的应用中对提出的滤波器的有效性进行测试。", "conclusion": "所提出的滤波器在活动分类应用中表现出有效性，能够根据惯性测量单元数据提高实时分类准确性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13934", "html_url": "https://arxiv.org/abs/2509.13934", "title": "Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection", "title_en": "Large Language Model-Empowered Decision Transformer for UAV-Enabled Data Collection", "authors": "Zhixion Chen,Jiangzhou Wang,and Hyundong Shin,Arumugam Nallanathan", "background": "无人驾驶航空器（UAV）在支持多样化的物联网（IoT）应用中通过可靠且节能的数据收集显得很有前景。但UAV的有限续航时间和通信范围要求智能轨迹规划。尽管强化学习（RL）已被广泛研究用于UAV轨迹优化，但由于其交互操作方式在实际环境中会带来高的成本和风险。在线RL和离线RL方法虽能部分解决这些问题，但仍分别存在不稳定训练和高度依赖于专家级数据集的问题。", "innovation": "本文将UAV轨迹规划和资源分配问题联合起来优化数据收集的能量效率。资源分配子问题被转换为等价的线性规划形式，并以多项式时间复杂度求解。进而提出了一种大型语言模型（LLM）辅助的批评者调节决策转换器（LLM-CRDT）框架，以学习有效的UAV控制策略。该框架通过集成决策转换器的序列建模能力和批评者基于的价值指导来利用大型语言模型进行训练，从而从次优化数据集中学习有效的策略。此外，为减轻变压器模型对数据的高需求，采用预训练的大型语言模型作为决策转换器模型的变压器骨干，并采用参数高效的微调策略（LoRA），使模型能够快速适应UAV控制任务，同时具有较低的计算开销。实验结果表明，LLM-CRDT在各种基准在线和离线RL方法中表现出色，对比当前最先进的决策转换器方法，其能量效率最高可提升36.7%。", "conclusion": "本文提出的LLM-CRDT框架在UAV赋能的数据收集中表现出色，不仅集成了一系列先进的人工智能技术提高了能量效率，还展示了其在资源有限情况下的灵活性和适用性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13968", "html_url": "https://arxiv.org/abs/2509.13968", "title": "使用人工神经网络探索生物认知演化中的重大过渡", "title_en": "Exploring Major Transitions in the Evolution of Biological Cognition With Artificial Neural Networks", "authors": "Konstantinos Voudouris,Andrew Barron,Marta Halina,Colin Klein,Matishalin Patel", "background": "过渡性进化论强调少数关键变化塑造了可进化性，并对衍生谱系产生了显著影响。近年来，有人提出认知也可能通过一系列重大过渡演变，从根本上改变生物神经网络的结构，进而影响信息流。该研究使用理想化的信息流动模型和人工神经网络（ANNs）来评估不同结构的网络在学习复杂人工语法时的认知性能变化。", "innovation": "该研究通过使用人工神经网络来评估不同拓扑结构的网络在学习复杂人工语法时的认知性能变化，发现循环神经网络在处理输入和复杂语法学习方面的性能显着提高。此外，研究还揭示了训练循环神经网络时面临的过渡障碍和条件不可逆性等关键特征。并非所有网络结构变化都会提高认知性能，这表明并非所有的拓扑变化都带来性能上的优势，例如不易成层的网络在语法学习上没有显示出优势。这项研究展示了一些信息流变化可以导致认知性能的转变。", "conclusion": "该研究发现，一些信息流动的变化可以导致认知性能的转变，尤其是在处理复杂输入和学习复杂语法任务时，循环神经网络表现出明显的优势。这种优势可能是通过改变网络结构来进行的信息流重大转变的结果，类似于生物演化中的重大过渡。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14008", "html_url": "https://arxiv.org/abs/2509.14008", "title": "Hala技术报告：构建大规模阿拉伯语中心的指令与翻译模型", "title_en": "Hala Technical Report: Building Arabic-Centric Instruction & Translation Models at Scale", "authors": "Hasan Abed Al Kader Hammoud,Mohammad Zbeeb,Bernard Ghanem", "background": "研究团队构建了一种专用的翻译及调整管道，以创建阿拉伯语为中心的指令与翻译模型。该管道首先对强大的双向压缩模型进行压缩，并用其生成高质量的双语监督数据。这些数据随后被用于调整一个轻量级语言模型，使其能够高效地将英语指令翻译成阿拉伯语，生成大量定制化的指令跟随训练语料。", "innovation": "Hala模型系列采用了一种高效的压缩教师模型的方法，将其压缩至FP8精度（约2倍的吞吐量提升且无质量损失），进而生成高质量的监督数据。然后，一种轻量级语言模型在这些数据上进行了微调，用于将英语指令翻译成高质量的阿拉伯语。通过参数调整和SLERP合并技术，Hala模型在保持阿拉伯语专属性的同时，有效利用了基础模型的优势。在阿拉伯语中心的基准测试中，Hala模型达到了最先进的性能。", "conclusion": "Hala模型系列在阿拉伯语指令与翻译模型的构建上取得了重要进展，特别是在小规模和较小规模的分类中达到了最先进的性能。研究团队还公开了其模型、数据、评估指标和调优方案，以加速阿拉伯语自然语言处理领域的研究。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13990", "html_url": "https://arxiv.org/abs/2509.13990", "title": "Slim-SC: 思维修剪以实现高效的自一致性扩展", "title_en": "Slim-SC: Thought Pruning for Efficient Scaling with Self-Consistency", "authors": "Colin Hong,Xu Guo,Anand Chaanan Singh,Esha Choukse,Dmitrii Ustiugov", "background": "最近，测试时缩放（TTS）引起了越来越多的关注，旨在提高大语言模型（LLM）在测试时的推理性能，而无需重新训练模型。自一致性（SC）是一种显著的TTS技术，它并行生成多个推理链，并通过多数投票选择最终答案。尽管有效，但SC的大量计算开销限制了其广泛应用。此前加速SC的尝试主要依赖于基于模型的信心分数或缺乏实证支持的启发式方法。", "innovation": "本研究首次从理论和实证上分析了SC的低效，揭示了改进的机会，并在此基础上提出了Slim-SC，这是一种逐步修剪策略，它使用思维层面的链间相似性来识别并去除冗余链。Slim-SC在三种STEM推理数据集和两种最新LLM架构上进行实验，结果显示，与SC相比，Slim-SC将推理延迟和KVC使用量分别降低了45%和26%，同时保持或提高了准确性，从而提供了SC的一种简单而有效的替代方案。", "conclusion": "Slim-SC通过逐步修剪冗余链，有效减少了自一致性推理的计算开销，提高了推理效率，同时保持了或提升了准确性，为SC提供了一种简单有效的替代方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13878", "html_url": "https://arxiv.org/abs/2509.13878", "title": "Generalizable Audio Deepfake Detection Through Mixture of Low-Rank Adapter Experts", "title_en": "Mixture of Low-Rank Adapter Experts in Generalizable Audio Deepfake Detection", "authors": "Janne Laakkonen,Ivan Kukanov,Ville Hautamäki", "background": "基础模型如Wav2Vec2在语音任务中的表示学习方面表现优异，包括音频深度合成检测。然而，在经过固定的真声和合成声录音片段的微调后，它们往往无法将所学应用到训练中未出现的新颖的深度合成方法中。", "innovation": "提出了一种混合LoRA专家模型的方法，将多个低秩适配器（LoRA）集成到模型的注意力层中，通过路由机制选择性地激活专门的专家，增强模型对不断演变的深度合成攻击的适应性。实验结果显示，该方法在同域和跨域场景中均优于常规微调方法，降低了等错误率，并且最佳MoE-LoRA模型将平均跨域EER从8.55%降低到6.08%，表明其在实现可迁移的音频深度合成检测方面的有效性", "conclusion": "我们的方法在同域和跨域场景中均优于标准微调方法，显示出其在音频深度合成检测中的有效性，并且在跨域情况下还显著降低了等错误率。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14001", "html_url": "https://arxiv.org/abs/2509.14001", "title": "MOCHA：多模态物体感知跨架构对齐", "title_en": "MOCHA: Multi-modal Objects-aware Cross-arcHitecture Alignment", "authors": "Elena Camuffo,Francesco Barbato,Mete Ozay,Simone Milani,Umberto Michieli", "background": "论文背景介绍了如何将大型vision-language模型（如LLaVa）的多模态区域级语义知识，通过知识蒸馏的方式传递给轻量级的纯视觉对象检测器（如YOLO）。之前的很多方法都集中在密集的或全局的对齐上，而本文中提出的MOCHA方法则在物体级别操作，避免了修改教师模型和推理时需要文本输入的问题，有助于提高轻量级模型的性能并保持高效率。本文在四个个性化检测基准测试中，验证了在少样本情境下的有效性和准确性，结果显示检测性能得到了显著提升，与现有的大型多模态模型相当，具有实际部署的潜力和可行性。", "innovation": "MOCHA方法的创新之处在于它在物体级别进行跨架构的学习对齐，通过引入一个翻译模块将其学生模型特征映射到联合空间，并通过一个联合损失函数（既包含局部对齐也包含全局关系一致性）来指导训练过程。这种物体级别的对齐方法避免了对教师模型进行修改的需求，同时也不需要在推理过程中提供文本输入，能够高效地传递语义知识，非常适合轻量级模型的实际应用。", "conclusion": "本文的方法在四个少样本检测基准测试中表现出了一致的提升，平均得分提高了10.1分，尽管架构更加紧凑，但MOCHA模型达到了与大型多模态模型相当的性能，可以用于实际部署。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14016", "html_url": "https://arxiv.org/abs/2509.14016", "title": "使用深度环调整提高引力波观测站的宇宙探测范围", "title_en": "Improving cosmological reach of a gravitational wave observatory using Deep Loop Shaping", "authors": "Jonas Buchli,Brendan Tracey,Tomislav Andric,Christopher Wipf,Yu Him Justin Chiu,Matthias Lochbrunner,Craig Donner,Rana X. Adhikari,Jan Harms,Iain Barr,Roland Hafner,Andrea Huber,Abbas Abdolmaleki,Charlie Beattie,Joseph Betzwieser,Serkan Cabi,Jonas Degrave,Yuzhu Dong,Leslie Fritz,Anchal Gupta,Oliver Groth,Sandy Huang,Tamara Norman,Hannah Openshaw,Jameson Rollins,Greg Thornton,George Van Den Driessche,Markus Wulfmeier,Pushmeet Kohli,Martin Riedmiller,LIGO Instrument Team", "background": "改善引力波观测站的低频敏感度能够研究中间质量黑洞合并、双黑洞的偏心率，并为二元中子星合并的多信使观测提供早期预警。然而，当前的镜子稳定控制引入了有害噪音，严重阻碍了敏感度的提升。", "innovation": "我们通过深度链整形成频域奖励的强化学习方法---Deep Loop Shaping---消除了这种噪音。该方法在LIGO利文斯顿天文台（LLO）上得到了验证。控制器在10-30Hz频段将控制噪音减少了30倍以上，在一些子频段甚至降低了100倍，超过了受量子极限驱动的设计目标。这证明了深度环整形提高当前和未来引力波观测站性能的潜力，并且更广泛地提升了仪器和控制系统。", "conclusion": "这些结果表明，深度环整形在提升引力波观测站和其他仪器控制系统的性能方面具有很大的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14031", "html_url": "https://arxiv.org/abs/2509.14031", "title": "训练数据组成对训练上下文感知机器翻译模型的影响", "title_en": "You Are What You Train: Effects of Data Composition on Training Context-aware Machine Translation Models", "authors": "Paweł Mąka,Yusuf Can Semerci,Jan Scholtes,Gerasimos Spanakis", "background": "实现人类水平的翻译需要利用上下文以确保连贯性并处理诸如代词消歧等复杂现象。假设标准训练数据中上下文丰富的例子较少是导致上下文利用困难的原因。因此，本研究在单语和多语环境中通过构建控制恰当比例的上下文相关样本的数据集，系统验证这一假设。", "innovation": "提出并实证评估了两种用于利用现有数据的训练策略，这些策略提高了上下文利用，分别在单语和多语环境中实现了6%和8%的准确性提升。", "conclusion": "训练数据稀疏与模型性能之间存在强烈关联，证实了稀疏性是关键瓶颈。同时发现一种上下文现象的改进并不适用于其他现象，并观察到跨语言转移有限且不尽显着。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14020", "html_url": "https://arxiv.org/abs/2509.14020", "title": "使用人工神经网络集成方法预测显著波高", "title_en": "Artificial neural networks ensemble methodology to predict significant wave height", "authors": "Felipe Crivellaro Minuzzi,Leandro Farina", "background": "波变量的预测对于依赖于对海洋状态更好描述的应用至关重要。由于用于建模该问题的微分方程表现出混沌行为，通常采用增加模拟次数并平均结果的策略来克服困难，通过例如改变初始条件来实现。近年来，随着可用数据量的增加和计算能力的增强，机器学习算法被用作传统数值模型的替代方案，取得了可比或更优的结果。该研究旨在利用不同人工神经网络架构的集成方法，预测巴西海岸六个不同地点的显著波高。研究采用NOAA的数值再预演数据进行训练，并以观测数据和数值模型输出之间的残差作为目标。研究还提出了新的数据集生成策略。结果表明，该框架能够生成高效预测，平均准确性达到80%，在最佳情况下可达88%，相对NOAA的数值模型，误差指标降低约5%，同时计算成本逐渐降低。", "innovation": "研究通过集成MLP、RNN、LSTM、CNN和CNN-LSTM等不同人工神经网络架构来预测显著波高，采用新的数据集生成策略，并实现了80%以上的高准确性预测，尤其是在最佳情况下达到88%，相比NOAA的数值模型，降低了大约5%的误差指标，同时计算成本逐步减少。这种方法可增强波高预测的准确性，并减少计算资源的使用", "conclusion": "该研究提出了一种有效的方法来预测显著波高，平均准确率为80%，在最佳情况下达到88%，比NOAA的数值模型降低了约5%的误差指标，同时计算成本逐渐减少。这种方法在波高预测方面具有广泛应用潜力。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13980", "html_url": "https://arxiv.org/abs/2509.13980", "title": "基于长上下文的MT质量评估", "title_en": "Long-context Reference-based MT Quality Estimation", "authors": "Sami Ul Haq,Chinonso Cynthia Osuji,Sheila Castilho,Brian Davis", "background": "本研究背景在于机器翻译质量评估（MT QA）任务中，特别是在第十届国际机器翻译大会（WMT25）的共享任务上提交的方法，旨在提高自动翻译质量评估的准确性，特别是在转换质量评分时提高与人工判断结果的相关性。传统的MT QA方法多依赖于短片段数据进行预测，而未能充分利用全面的上下文信息对翻译质量进行更准确的评估。\n", "innovation": "本文提出的创新之处在于通过COMET框架构建系统，并使用长上下文数据（通过将领域内的、人工标注的句子进行拼接并计算加权平均评分）来训练预测短语级错误跨度注释（ESA）分数的模型。此外，还整合了多个质量判断数据集（MQM、SQM和DA），进行归一化并训练多语言回归模型来预测源译文、假设译文和参考译文的质量分数。这种以参考为基础且考虑长上下文信息的方法，在模型训练中引入了更多元的数据点，从而提高了预测结果的准确性与可靠性。\n", "conclusion": "实验结果显示，相较于仅使用短段数据训练的模型，引入长上下文信息进一步提高了自动翻译质量评估与人工判断结果的相关性。因此，本文提出的基于长上下文的人机器翻译质量评估方法在提升MT QA准确性方面具有显著的效果和价值。\n"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13793", "html_url": "https://arxiv.org/abs/2509.13793", "title": "单调算子平衡网络的电路实现与硬件线性化", "title_en": "Circuit realization and hardware linearization of monotone operator equilibrium networks", "authors": "Thomas Chaffey", "background": "研究表明，由电阻-二极管网络表示的端口行为对应于具有无限深度的ReLu单调运算符平衡网络（神经网络在无限深度极限下的形式），这提供了一种在模拟硬件中简洁构造神经网络的方法。此外，研究还展示了如何直接在硬件中计算此类电路的梯度，我们称之为硬件线性化。这项工作展示了一种在硬件层面进行电路仿真的方式，使得网络能够在硬件中进行训练，为在模拟硬件上构建和训练神经网络提供了新的方法。这项工作进一步扩展到电阻-二极管网络级联的应用，可以实现前馈和其他非对称网络结构。不同类型的非线性元件会产生不同的激活函数，本研究引入了一种新的由非理想二极管模型引出的二极管ReLu激活函数", "innovation": "该研究提出了一种在模拟硬件中简洁构造神经网络的方法，并且展示了可以直接在硬件中计算电路的梯度，从而使得电路能够在硬件中进行训练。这项工作还讨论了如何通过电阻-二极管网络级联实现前馈和其他非对称网络结构。此外，研究还引入了一种新的二极管ReLu激活函数，展示了不同非线性元件对激活函数的影响。通过硬件线性化方法，可以更有效地模拟和训练神经网络，使得实际硬件实施神经网络成为可能", "conclusion": "该研究揭示了电阻-二极管网络的端口行为与无限深度ReLu单调运算符平衡网络的联系，实现了在模拟硬件中简洁构建和训练神经网络的方法。通过硬件线性化，可以直接在硬件中计算网络的梯度，展示了电阻-二极管网络级联在实现前馈和其他非对称网络中的潜力，并引入了新的二极管ReLu激活函数。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14026", "html_url": "https://arxiv.org/abs/2509.14026", "title": "量子变分激活函数使科莫哥洛夫-阿诺德网络更加强大", "title_en": "Quantum Variational Activation Functions Empower Kolmogorov-Arnold Networks", "authors": "Jiun-Cheng Jiang,Morris Yu-Chao Huang,Tianlong Chen,Hsi-Sheng Goan", "background": "变分量子电路(VQCs)在量子机器学习中占据核心地位，而最近Kolmogorov-Arnold网络(KANs)的研究进展凸显了可学习激活函数的强大力量。该研究通过引入量子变分激活函数(QVAFs)，结合单量子比特数据重加载电路DARUANs实现了这一目标。研究表明，DARUANs在数据预处理中具有可训练权重，其频谱随数据重复呈指数增长，相比基于傅里叶的激活函数，可以在不损失表达能力的情况下显著减少参数量。将DARUANs嵌入KANs，产生了QKANs，保持了KANs的可解释性，同时提高了其参数效率、表达能力和泛化能力。进一步，提出了两种增强方法，如层扩展和混合QKANs (HQKANs)，它们可以作为大型模型中前馈网络多层感知机(MLPs)的drop-in替换方案，同时提升了可扩展性、可行性和计算效率。", "innovation": "引入了量子变分激活函数(QVAFs)和单量子比特数据重加载电路DARUANs。DARUANs在数据预处理中具备可训练权重，其频谱随数据重复呈指数增长，相比于基于傅里叶的激活函数，可以在不损失表达能力的情况下显著减少参数量。将DARUANs嵌入KANs，产生了QKANs，使KANs在保持可解释性的前提下，提高了参数效率、表达能力和泛化能力。进一步，提出了层扩展和混合QKANs (HQKANs)两种技术，以增强QKANs的可扩展性、可行性和计算效率。", "conclusion": "提出的方法在函数回归、图像分类和自回归生成语言建模等多个任务中的实验表明，QKANs具有高效的计算能力和优良的可扩展性。DARUANs和QKANs为在嘈杂的中尺度量子(NISQ)硬件和经典量子模拟器上推动量子机器学习的发展提供了有希望的方向。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14054", "html_url": "https://arxiv.org/abs/2509.14054", "title": "基于物理的深度核学习在高维偏微分方程参数估计中的应用", "title_en": "Physics-based deep kernel learning for parameter estimation in high dimensional PDEs", "authors": "Weihao Yan,Christoph Brune,Mengwu Guo", "background": "高维度偏微分方程（PDEs）参数的推断面临着计算和推断上的巨大挑战，主要是由于维数灾以及传统数值方法的固有限制。", "innovation": "引入了一种新颖的两阶段贝叶斯框架，将基于物理的深度核学习（DKL）与哈密顿蒙特卡洛（HMC）结合，以稳健地从稀疏精确观测中推断未知PDE参数并量化其不确定性。第一阶段利用基于物理的DKL训练代理模型，联合提供优化的神经网络特征提取器和PDE参数的稳健初始估计。在第二阶段，固定神经网络权重，使用HMC在完整的贝叶斯框架内高效抽样核超参数和PDE参数的联合后验分布。", "conclusion": "数值实验表明，该框架能够准确估计参数，提供可靠的方法预测不确定性，并有效解决数据稀疏性和模型复杂性的挑战，提供了一种鲁棒且可扩展的工具，适用于各种科学和技术应用。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14037", "html_url": "https://arxiv.org/abs/2509.14037", "title": "PhenoGnet: 基于图的对比学习框架用于疾病相似性预测", "title_en": "PhenoGnet: A Graph-Based Contrastive Learning Framework for Disease Similarity Prediction", "authors": "Ranga Baminiwatte,Kazi Jewel Rana,Aaron J. Masino", "background": "理解疾病相似性对于推动诊断、药物发现和个性化治疗策略至关重要。PhenoGnet是一个新颖的基于图的对比学习框架，用于通过将基因功能性相互作用网络与人类表型本体（HPO）整合来预测疾病相似性。该框架利用已知的基因表型关联作为正样例，随机抽取的无关样例作为负样例进行训练，展示了良好的性能并优于现有方法。PhenoGnet能够捕捉到超越直接重叠的潜在生物学关系，为疾病相似性预测提供了可扩展且可解释的解决方案，具有在罕见病研究和个性化医疗中的应用潜力。", "innovation": "PhenoGnet通过结合基因功能性相互作用网络和人类表型本体（HPO）来预测疾病相似性，使用图卷积网络（GCNs）和图注意力网络（GATs）分别编码基因和表型图。一种交叉视图模型通过对比学习对齐基因和表型嵌入，训练时使用已知的基因表型关联作为正样例，随机抽取的无关样例作为负样例。该模型通过余弦相似度计算疾病对之间的相似性，并在精心构建的基准测试集上展示了优于现有方法的强大性能，特别地PhenoGnet能够捕捉到超过直接重叠的潜在生物学关系，提供了一种可扩展且可解释的解决方案。", "conclusion": "PhenoGnet在遗传型嵌入下实现了0.9012的AUCPR和0.8764的AUCROC，显著优于现有最先进的方法，且能够捕捉到潜在的生物学关系，为疾病相似性预测提供了可扩展和可解释的解决方案，强调了其在罕见病研究和精准医疗中的潜在应用价值。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14195", "html_url": "https://arxiv.org/abs/2509.14195", "title": "迷宫导航的层次学习：基于二次学习的思维代表的涌现", "title_en": "Hierarchical Learning for Maze Navigation: Emergence of Mental Representations via Second-Order Learning", "authors": "Shalima Binta Manir,Tim Oates", "background": "高级认知依赖于对环境的规律性心理表征，但这些规律的探索性研究极具挑战性。现有理论认为，二次学习机制可以改进一次学习（即对任务/领域本身的了解），从而促进环境与认知的同构性。本文旨在通过建立包含图卷积网络（GCN）和多层感知器控制器（MLP）的层次架构来验证这一理论假设。", "innovation": "本文创新性地提出了一种层次架构，其中包含图卷积网络（GCN）作为一次学习者，多层感知器控制器（MLP）作为二次学习者。GCN直接将节点级别特征映射为最佳导航路径的预测，而MLP会在遇到结构性新颖的迷宫环境时动态调整GCN的参数。研究展示了当认知系统发展出与环境结构同构的内在心理图时，二次学习特别有效，从而显著提高了性能并在未见过的迷宫任务上实现了稳健的泛化，提供了结构化心理表征在最大化二次学习效果中的关键作用的实证支持。", "conclusion": "定量和定性结果表明，二次学习在迷宫任务中具有显著的性能提升和泛化能力，为结构化心理表征在最大限度提高二次学习效果中的核心地位提供了实证支持。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14199", "html_url": "https://arxiv.org/abs/2509.14199", "title": "使用门控残差分词的密集视频理解", "title_en": "Dense Video Understanding with Gated Residual Tokenization", "authors": "Haichao Zhang,Wenhao Chai,Shwai He,Ang Li,Yun Fu", "background": "高时间分辨率对于捕捉视频理解中的细微差异至关重要。然而，当前的视频大语言模型（VLLMs）和基准测试主要依赖于低帧率抽样，如均匀抽样或关键帧选择，这会丢弃密集的时间信息。这种妥协避免了逐帧分词的高成本，从而防止了重复的计算和随视频长度线性的分词量增长。尽管这在内容变化缓慢的任务上可行，但在需要精确时间对齐的讲义理解等任务中，则表现不佳。", "innovation": "论文提出了密集视频理解（DVU），通过减少分词时间和分词量，实现高帧率视频理解和语义分析。为了使DVU更加实用，论文提出了门控残差分词（GRT），这是一种两阶段框架：第一阶段采用像素级运动估计的运动补偿交互门控分词，在分词时跳过静止区域，实现分词数量和计算量的次线性增长；第二阶段在场景内的静止区域融合分词，进一步减少冗余性，同时保留动态语义。实验表明，GRT 能够超越较大的 VLLM 基准并通过提高帧率来正向扩展，突显了密集时间信息的重要性，并展示了 GRT 如何实现高效、可扩展的高帧率视频理解。", "conclusion": "本文提出了 Dense Video Understanding (DVU) 和门控残差分词 (GRT) 方法，通过减少分词时间和分词量，使得高帧率视频理解成为可能。GRT 通过在静止区域内融合分词并跳过静止区域，提高了计算效率并保留了动态语义。研究结果表明，GRT 在 DIVE 基准上优于大型 VLLM 基准，并随着帧率的提高表现出积极的扩展性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14203", "html_url": "https://arxiv.org/abs/2509.14203", "title": "常增益下平均报酬稳健马尔可夫决策过程的贝尔曼最优性", "title_en": "Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain", "authors": "Shengbo Wang,Nian Si", "background": "虽然关于稳健马尔可夫决策过程（MDPs）的学习和最优控制已经受到了越来越多的关注，但现有的理论、算法和应用主要集中在有限时隔或折扣模型上。平均报酬的表述在许多运筹学和管理情境下是自然的，但目前仍有待充分发挥其潜力。这主要是因为动态规划的基础知识存在技术上的挑战，许多关键问题尚未得到解决。", "innovation": "本文通过分析常增益设置，为平均报酬稳健MDPs提供了一个通用框架。研究了在控制器与S-矩形对手可能信息不对称情况下，平均报酬稳健控制问题。重点分析了常增益稳健贝尔曼方程，探索了其解的存在性和与最优平均报酬的关系。确定了常增益稳健贝尔曼方程解的最优平均报酬和策略的条件，为在长期内最优平均标准下的稳健动态决策奠定了动态规划理论基础。", "conclusion": "本文的研究扩展了平均报酬稳健MDPs的动态规划理论，并为操作环境下的稳健动态决策提供了基础。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14032", "html_url": "https://arxiv.org/abs/2509.14032", "title": "在具有玩家局部凹耦合约束的博弈中的纳什均衡：存在性与计算", "title_en": "Nash Equilibria in Games with Playerwise Concave Coupling Constraints: Existence and Computation", "authors": "Philip Jordan,Maryam Kamgarpour", "background": "本文研究了玩家的可接受策略受共享耦合约束影响的连续静态博弈中纳什均衡的存在性和计算问题。这些约束依赖于玩家的联合策略。以往关于纳什均衡存在性的结果并不适用于这种情形，因为这些结果基于联合可行集合凸性的强假设。本文通过利用拓扑不动点理论和玩家局部凹约束下的可行集合可缩性的新见解，给出了在较弱条件下纳什均衡存在的证明。", "innovation": "本文利用拓扑不动点理论和玩家局部凹约束下的可行集合可缩的新见解，给出了在较弱条件下纳什均衡存在的证明。为了计算纳什均衡，本文假设效用具有势函数，并采用自适应步长的对数障碍正则化梯度上升方法。在精确梯度反馈下，该方法在$\text{O}(\text{ϵ}^{-3})$次迭代内收敛于$\text{ϵ}$-近似约束纳什均衡。", "conclusion": "本文通过更弱的假设证明了纳什均衡的存在性，并提出了一种计算方法，即使在非凸可行区域内也能收敛于近似约束纳什均衡。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14233", "html_url": "https://arxiv.org/abs/2509.14233", "title": "Apertus：为全球语言环境民主化开放合规的大语言模型", "title_en": "Apertus: Democratizing Open and Compliant LLMs for Global Language Environments", "authors": "Alejandro Hernández-Cano,Alexander Hägele,Allen Hao Huang,Angelika Romanou,Antoni-Joan Solergibert,Barna Pasztor,Bettina Messmer,Dhia Garbaya,Eduard Frank Ďurech,Ido Hakimi,Juan García Giraldo,Mete Ismayilzada,Negar Foroutan,Skander Moalla,Tiancheng Chen,Vinko Sabolčec,Yixuan Xu,Michael Aerni,Badr AlKhamissi,Ines Altemir Marinas,Mohammad Hossein Amani,Matin Ansaripour,Ilia Badanin,Harold Benoit,Emanuela Boros,Nicholas Browning,Fabian Bösch,Maximilian Böther,Niklas Canova,Camille Challier,Clement Charmillot,Jonathan Coles,Jan Deriu,Arnout Devos,Lukas Drescher,Daniil Dzenhaliou,Maud Ehrmann,Dongyang Fan,Simin Fan,Silin Gao,Miguel Gila,María Grandury,Diba Hashemi,Alexander Hoyle,Jiaming Jiang,Mark Klein,Andrei Kucharavy,Anastasiia Kucherenko,Frederike Lübeck,Roman Machacek,Theofilos Manitaras,Andreas Marfurt,Kyle Matoba,Simon Matrenok,Henrique Mendoncça,Fawzi Roberto Mohamed,Syrielle Montariol,Luca Mouchel,Sven Najem-Meyer,Jingwei Ni,Gennaro Oliva,Matteo Pagliardini,Elia Palme,Andrei Panferov,Léo Paoletti,Marco Passerini,Ivan Pavlov,Auguste Poiroux,Kaustubh Ponkshe,Nathan Ranchin,Javi Rando,Mathieu Sauser,Jakhongir Saydaliev,Muhammad Ali Sayfiddinov,Marian Schneider,Stefano Schuppli,Marco Scialanga,Andrei Semenov,Kumar Shridhar,Raghav Singhal,Anna Sotnikova,Alexander Sternfeld,Ayush Kumar Tarun,Paul Teiletche,Jannis Vamvas,Xiaozhe Yao,Hao Zhao Alexander Ilic,Ana Klimovic,Andreas Krause,Caglar Gulcehre,David Rosenthal,Elliott Ash,Florian Tramèr,Joost VandeVondele,Livio Veraldi,Martin Rajman,Thomas Schulthess,Torsten Hoefler,Antoine Bosselut,Martin Jaggi,Imanol Schlag", "background": "当今开放模型生态系统中存在两个系统性的不足：数据合规性和多语言表现。", "innovation": "1. Apertus模型专门针对以上两个问题进行设计。\n2. Apertus模型仅使用公开可用的数据进行预训练，不考虑原始内容持有者的权益，避免了数据泄露等问题。\n3. 通过采用黄金鱼目标操作，在预训练过程中抑制数据的逐字回溯，同时保持下游任务的效果。\n4. 扩展了多语言覆盖面，训练了来自1800多种语言的15T个令牌，其中非英语内容占比约40%。\n5. 在多语言基准测试中，Apertus模型接近完全开放模型的最佳表现，与开放权重模型相当或更优。\n6. 除权重之外，还提供了所有科学艺术成果，包括数据准备脚本、检查点、评估套件和训练代码，以供透明审计和扩展。", "conclusion": "Apertus模型在多语言环境中的表现与现有开放大语言模型相近甚至更好，同时保证了数据合规性和多语言表现，为全球语言环境提供了更加合规且全面的开放大语言模型解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14180", "html_url": "https://arxiv.org/abs/2509.14180", "title": "行为基础推理链综合：个人金融LLM的数据生成框架", "title_en": "Synthesizing Behaviorally-Grounded Reasoning Chains: A Data-Generation Framework for Personal Finance LLMs", "authors": "Akhil Theerthala", "background": "个性化金融建议需要考虑用户的财务目标、限制、风险承受能力和所在司法辖区。以往的人工智能语言模型（LLM）工作主要集中在为投资者和财务规划师提供的支持系统上。同时，近年来有许多研究通过代理管道探讨了预算管理、债务管理、退休和遗产规划等更广泛的个人财务管理任务，但这些代理管道的维护成本高昂，只实现了预期财务回报的25%以下。本文背景即是在此背景下提出新的方法，以解决现有的挑战。", "innovation": "本研究提出了一种新颖且可复制的框架，将相关金融背景与行为金融研究相结合，构建了端到端的顾问监督数据。通过该框架，构建了一个包含19000个样本推理数据集，并完成了Qwen-3-8B模型的全面微调。通过保留测试拆分和盲目的LLM专家评定，本研究展示了通过精心的数据筛选和行为整合，8B模型在事实准确性、流畅性和个性化指标上达到了与较大的基线模型（参数14-32B）相当的性能，同时成本降低了80%。这种创新方法提供了在不显著增加成本的情况下提高LLM性能的新途径。", "conclusion": "通过精心数据整理和行为整合，我们开发了一个8B模型，通过行为导向的数据生成框架，该模型在事实准确性、流畅性和个性化三个方面达到了接近14-32B参数基线模型的表现，同时成本降低80%。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14229", "html_url": "https://arxiv.org/abs/2509.14229", "title": "Fused 联合 检验 用于 融合套索", "title_en": "Spacing Test for Fused Lasso", "authors": "Rieko Tasaka,Tatsuya Kimura,Joe Suzuki", "background": "本研究解决了融合套索中正则化参数选择的未解决问题。具体而言，作者将Tibshirani等人提出的间距检验框架扩展到融合套索，通过将选择事件表征为多面体约束，为选择后推理提供了理论基础。通过分析使用LARS类型的算法计算出的融合套索解路径，作者推导出了精确条件p值，并将其从标准套索扩展到融合惩罚结构。通过数值实验对比所提出的方法与AIC和BIC的顺序版本以及交叉验证，作者表明所提出的方法能够正确控制一类错误，同时实现高检测能力。", "innovation": "本文通过将间距检验扩展到融合套索，为选择后推理提供了理论基础，提出了精确条件p值的推导方法，从而扩展了间距检验的应用范围。此外，通过数值实验，本文证明了提出的方法能够在控制一类错误的同时实现高检测能力。", "conclusion": "本文提供了在具有结构的信号估计问题中进行参数选择和选择后推理的一个理论上合理且计算上可行的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13620", "html_url": "https://arxiv.org/abs/2509.13620", "title": "一种用于地下流体流动的减缩阶梯度引导神经算子", "title_en": "A reduced-order derivative-informed neural operator for subsurface fluid-flow", "authors": "Jeongjin(Jayjay)Park,Grant Bruer,Huseyin Tuna Erdinc,Abhinav Prakash Gahlot,Felix J. Herrmann", "background": "神经算子已经成为一种经济有效的替代方法，用于昂贵的流场模拟器，特别是在从随时间变化的地震数据中倒推渗透率和不确定性量化这类计算密集型任务中。精确的梯度对于这些任务后端优化和贝叶斯推断的准确性至关重要。尽管物理信息方法利用了梯度信息来提高替代模型的准确性，但将显式雅可比纳入计算可能会因其复杂性与输入参数数量成正比的平方增长而变得具有挑战性。", "innovation": "本文提出了DeFINO（基于梯度的Fisher信息矩阵引导神经算子），这是一种减缩阶且基于梯度的信息训练框架。DeFINO 将Fourier神经算子与由Fisher信息矩阵指导的新颖的梯度导向训练策略相结合，通过FIM识别主导特征方向来投影雅可比，直接从观测数据中捕获关键的敏感信息，显著减少了计算成本。", "conclusion": "通过地下多相流体流动的合成实验验证了DeFINO，结果显示了梯度准确性改进，并保持了对地下流体动力学的稳健预测。这些结果表明，DeFINO 有可能为复杂真实场景下的反演问题提供实用和可扩展的解决方案，同时显著降低计算成本。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14228", "html_url": "https://arxiv.org/abs/2509.14228", "title": "在复杂流动中的多机器人多源定位：具有保物理环境模型的策略", "title_en": "Multi-robot Multi-source Localization in Complex Flows with Physics-Preserving Environment Models", "authors": "Benjamin Shaffer,Victoria Edwards,Brooks Kinch,Nathaniel Trask,M. Ani Hsieh", "background": "在复杂流场中定位来源对多机器人团队而言是一项重大挑战，尤其是当其旨在定位化学泄漏的起始点或追踪油溢散分布时。流场动态可以是时变且混沌的，导致传感器读数间断出现，复杂的环境几何形状进一步增加了团队建模和预测分布的难度。为了准确捕捉驱动散流动态的物理过程，机器人必须具备访问计算密集型数值模型的能力，但当机载计算有限时，这会变得困难。因此，机器人需要携带能够引导基于信息的采样的机器学习有限元环境模型。模型用于评估近似互信息准则，以驱动信息游走控制策略，该策略选择预计将最大化源定位信息的传感区域。我们的方法比基线传感策略更快地减少了误差，并且相比基准机器学习方法，实现更准确的源定位结果。", "innovation": "一种分布式移动传感框架，其中每个机器人携带一个机器学习的有限元环境模型，以引导信息导向采样。模型通过评估近似互信息标准来驱动信息游走控制策略，以选择最大化信息的传感区域。这种方法比基线传感器策略更快减少误差，并实现更准确的源定位结果。", "conclusion": "通过提出这一框架，我们证明了利用保物理环境模型的多机器人可以更高效地定位复杂流动中的多样化源，加速错误减小并获得更准确的源定位结果。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14039", "html_url": "https://arxiv.org/abs/2509.14039", "title": "线性回归问题中高斯逼近速率的研究", "title_en": "On the Rate of Gaussian Approximation for Linear Regression Problems", "authors": "Marat Khusainov,Marina Sheshukova,Alain Durmus,Sergey Samsonov", "background": "本文考虑了在线线性回归任务中高斯逼近的问题。背景在于在线线性回归速度快，但在大样本条件下如何确保其渐近分布的可靠性是一个重要问题。本文研究了固定学习率情况下收敛速率与问题维度和设计矩阵相关量的显式依赖关系。", "innovation": "创新点在于证明了当迭代次数$n$已知时，在足够大的样本量$n$下，线性回归问题的正常逼近速率可以达到$\text{O}(\frac{\text{log } n}{n})$，并且详细探讨了通过设计矩阵相关量对收敛速率的影响。", "conclusion": "结论是在线线性回归问题中，随着样本量$n$的增大，其渐近分布可以以$\frac{\text{log } n}{n}$的速率逼近高斯分布，这一结果为在线线性回归中高斯逼近的可靠性提供了理论支持。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/1911.01067", "html_url": "https://arxiv.org/abs/1911.01067", "title": "盲网络收益管理与背包型强盗在有限切换下的研究", "title_en": "Blind Network Revenue Management and Bandits with Knapsacks under Limited Switches", "authors": "David Simchi-Levi,Yunzong Xu,Jinglong Zhao", "background": "该论文研究了有限开关对受限动态定价与需求学习的影响。它关注经典的价格为基础的盲网络收益管理问题，并将其结果扩展到背包型强盗问题。在所有场景中，决策者面临随机且分布未知的需求，并需要在时间跨度上分配有限的初始库存到多个资源。此外，除标准资源限制外，还施加了一个切换约束，限定了时间跨度内的动作变化次数。本文建立了最优遗憾的匹配上界和下界，并开发了高效的有限切换算法实现这一目标。失调率的最佳率由切换预算的分段常数函数完全表征，而该函数进一步依赖于资源约束的数量。结果显示，资源约束在有限切换下的在线学习统计复杂性中起着基础性的作用。广泛的模拟证明，该算法在保持强劲累计收益的同时有效减少了切换次数.", "innovation": "引入有限切换约束，研究其在受限动态定价和需求学习中的影响。建立了最优遗憾的匹配上界和下界，并开发出高效的有限切换算法，该算法能够达到最优遗憾。揭示了最优失调率完全由切换预算的分段常数函数表征，该函数进一步依赖于资源约束的数量。强调资源约束在有限切换下在线学习的统计复杂性中起到的基础性作用。", "conclusion": "通过有限切换算法极大地提高了累计奖励性能，同时大幅减少了切换次数，揭示了资源约束在有限切换下的在线学习统计复杂性的重要性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.17916", "html_url": "https://arxiv.org/abs/2404.17916", "title": "FedCoSR: 基于对比共享表示的个性化联邦学习算法以处理非IID数据中的标签异质性", "title_en": "FedCoSR: Personalized Federated Learning with Contrastive Shareable Representations for Label Heterogeneity in Non-IID Data", "authors": "Chenghao Huang,Xiaolu Chen,Yanru Zhang,Hao Wang", "background": "智能通信应用程序依赖分布式计算，但由于标签分布偏差和数据稀缺性导致的异质性可能导致不准确和不公平。现有的方法难以有效解决这一问题，因此论文提出了Federated Contrastive Shareable Representations (FedCoSR)算法，以促进客户端之间的知识共享并保持数据隐私。", "innovation": "FedCoSR算法将本地模型浅层参数和典型局部表示作为可共享信息供服务器聚合，并采用对比学习来补偿标签分布偏差对性能的影响，确保数据稀缺客户端的公平性通过引入自适应局部聚合协调全局模型的参与程度。", "conclusion": "仿真结果显示，FedCoSR在具有不同程度标签异质性的数据集上比现有方法提高了准确性和公平性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.17131", "html_url": "https://arxiv.org/abs/2402.17131", "title": "使用新型损失函数训练Transformer和RNN预测哺乳动物蛋白质的O-甘露糖基化位点", "title_en": "Predicting O-GlcNAcylation Sites in Mammalian Proteins with Transformers and RNNs Trained with a New Loss Function", "authors": "Pedro Seber", "background": "O-甘露糖基化是一种糖基化类型，有可能成为重要的治疗靶点，但直到2023年，还没有可靠的预测O-甘露糖基化位点的方法。之前2021年的综述指出，已发布的模型不足且缺乏概括性，很多模型已经不再可用。2023年发表了一种改进的递归神经网络（RNN）模型，通过使用一种新的损失函数，即加权焦点可微指标（MCC），实现了更好的性能。使用这种新损失函数训练的RNN在独立测试集中的F1分数达到了38.88%，MCC为38.20%，达到了最新的技术水平", "innovation": "创新在于开发了一种新的损失函数——加权焦点可微指标（MCC），并使用该函数训练了RNN模型，从而提高了O-甘露糖基化位点预测的准确性。这种方法不仅显著改善了RNN的性能，而且这种新函数还能用于训练模型的微调", "conclusion": "使用新的损失函数，训练的RNN模型在O-甘露糖基化位点预测上达到了最先进的技术水平，F1分数为38.88%，MCC为38.20%，表明使用Transformer和RNN结合新型损失函数的方法是一种有效的预测O-甘露糖基化位点的技术"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.12945", "html_url": "https://arxiv.org/abs/2406.12945", "title": "表格数据生成模型：详尽调查与广泛调优的高性能基准", "title_en": "Tabular Data Generation Models: An In-Depth Survey and Performance Benchmarks with Extensive Tuning", "authors": "G. Charbel N. Kindji(LACODAM),Lina Maria Rojas-Barahona,Elisa Fromont(LACODAM),Tanguy Urvoy", "background": "生成能够产生真实、安全且有用的表格数据的生成模型对于数据隐私、缺失值填补、过采样、可解释性和模拟至关重要。然而，由于表格数据的异构性、非光滑分布、复杂依赖关系和不平衡的分类特征，生成表格数据并不简单。尽管文献中提出了多种方法，但对于多种数据集在一致条件下进行统一评估仍存在需求。", "innovation": "本研究通过全面考虑超参数优化、特征编码和架构设计，填补了这一需求。研究通过对16个不同规模、类型和领域数据集进行了广泛的基准测试，评估了五个最近的表格数据生成模型家族的表现。此外，研究还提出了每个模型的简化搜索空间，使得优化过程更加高效。", "conclusion": "本基准测试显示，大多数模型在大规模数据集上进行特定调优后表现显著提高，且扩散模型普遍优于其他模型，但在整个调优和训练过程受限于相同的GPU预算时，这一优势并不显著。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13525", "html_url": "https://arxiv.org/abs/2509.13525", "title": "ColonCrafter：用于结肠镜视频的基于扩散先验的深度估计模型", "title_en": "ColonCrafter: A Depth Estimation Model for Colonoscopy Videos Using Diffusion Priors", "authors": "Romain Hardy,Tyler Berzin,Pranav Rajpurkar", "background": "在结肠镜检查中进行三维场景理解面临显著挑战，需要自动化方法来进行精确的深度估计。现有的内镜深度估计模型在视频序列之间的时间连贯性方面存在挑战，这限制了它们在三维重建中的应用。", "innovation": "提出了一种基于扩散的深度估计模型ColonCrafter，可以从单目结肠镜视频中生成时间连贯的深度图。此外，引入了一种风格迁移技术，以保留几何结构并使实际临床视频适应我们的合成训练领域。ColonCrafter在C3VD数据集上的零样本性能达到了最先进的水平，超过了通用和专门用于内镜的方法。", "conclusion": "尽管完全轨迹的三维重建仍然是一个挑战，但证明了ColonCrafter在临床相关应用中的实用性，包括三维点云生成和表面覆盖评估。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.02358", "html_url": "https://arxiv.org/abs/2405.02358", "title": "使用基础模型赋能时间序列分析：全面综述", "title_en": "Empowering Time Series Analysis with Foundation Models: A Comprehensive Survey", "authors": "Jiexia Ye,Yongzi Yu,Weiqi Zhang,Le Wang,Jia Li,Fugee Tsung", "background": "时间序列数据在各种实际应用中普遍存在，使得时间序列分析变得至关重要。传统的处理方法主要针对特定任务，功能有限且缺乏迁移性。近年来，基础模型在自然语言处理(NLP)和计算机视觉(CV)中取得了革命性进展，它们具有出色的跨任务迁移能力、零样本/少样本学习能力和多模态整合能力。这种成功激发了探索基础模型解决时间序列建模问题的努力。", "innovation": "本文提供了一种模态感知、挑战导向的新视角，揭示了预训练在不同模态的基础模型在转向时间序列任务时面临的独特挑战。基于此视角，我们构建了一个根据不同预训练模态(时间序列、语言和视觉)组织的工作分类体系，讨论了模态特异性挑战和对应解决方案的优势与局限性。此外，还回顾了实际应用，展示了特定领域的进步，并提供了开源代码。", "conclusion": "本文总结了该领域的发展，并展望了未来研究方向，指出这是一个快速发展的领域。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2302.01955", "html_url": "https://arxiv.org/abs/2302.01955", "title": "固定动能神经哈密尔顿流以增强解释性和降低复杂性", "title_en": "Fixed-kinetic Neural Hamiltonian Flows for enhanced interpretability and reduced complexity", "authors": "Vincent Souveton,Arnaud Guillin,Jens Jasche,Guilhem Lavaux,Manon Michel", "background": "Normalizing Flows (NF) 是一种生成模型，能够将简单先验分布转换为所需的目标分布。然而，它们需要设计一个可逆映射，并且其雅可比行列式必须是可计算的。最近引入的 Neural Hamiltonian Flows (NHF) 是基于哈密尔顿动力学的流，它们是连续的、体积保持的和可逆的，因而成为稳健生成流架构的自然候选人。特别地，它们与经典力学的相似性可能会使所学习的映射更容易解释。但是在当前的研究中，研究表明目前的NHF架构可能仍然对解释性构成挑战。因此，作者受到物理学的启发，引入了一个固定动能版本的模型。这种方法提高了可解释性和鲁棒性，同时所需参数少于原始模型。研究结果包括在2D 高斯混合数据集、MNIST 和 Fashion-MNIST 数据集上的演示，最后展示了如何将NHF适应到贝叶斯推断的背景中，并在天文学中的例子中展示了该方法的效果。", "innovation": "引入了固定动能的Neural Hamiltonian Flows (NHF) 模型，该模型能够在保持与经典力学的相似性的同时提高可解释性和鲁棒性，同时参数量少于原始NHF模型，特别地应用于2D高斯混合数据集、MNIST 和 Fashion-MNIST 数据集，展示了如何将NHF适应到贝叶斯推断的背景下，在天文学中的应用也进行了演示。", "conclusion": "通过引入固定动能的NHF模型，研究提高了模型的可解释性和鲁棒性，同时减少了参数数量，特别地在2D高斯混合数据集、MNIST 和 Fashion-MNIST 数据集上的表现良好，并展示了其在贝叶斯推断和天文学应用中的潜力。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.08592", "html_url": "https://arxiv.org/abs/2403.08592", "title": "使用合成时间序列预训练的数据高效睡眠分期", "title_en": "Data-Efficient Sleep Staging with Synthetic Time Series Pretraining", "authors": "Niklas Grieger,Siamak Mehrkanoon,Stephan Bialonski", "background": "通过电生理图（EEG）时间序列进行分析具有挑战性，特别是在使用深度神经网络时，因为人类被试之间存在较大的个体差异，而可用的数据集通常较小。为了应对这些挑战，提出了多种策略，例如自我监督学习，但这些方法通常依赖于大量标记的数据集。鉴于计算机视觉领域最近的进步，本文提出了一种预训练任务，即“频率预训练”，目的是使用随机生成的合成时间序列预测频率内容，从而对神经网络进行预训练，以进行睡眠阶段分类。实验表明，该方法在少量数据和少数被试的情景下优于完全监督学习，而在大量被试的情景下可与之匹敌。此外，结果强调了频率信息对于睡眠阶段评分的重要性，同时也展示了深度神经网络利用的不仅仅是频率信息，其提升睡眠分期性能与其他前人研究的结果一致。这种方法在未来广泛的EEG数据受限或来自少数被试的场景下，包括脑机接口领域中都将具有优势。\n", "innovation": "本文引入了一种新的预训练任务，即“频率预训练”，利用随机生成的合成时间序列来预测频率内容。这种方法能够在数据有限和少数被试的情况下提升睡眠分期的性能，同时显示出深度神经网络不仅利用频率信息，还利用其他信息来提升睡眠阶段分类的准确性。\n", "conclusion": "本文提出的方法表明，通过使用合成时间序列进行预训练，可以在EEG数据稀缺或来自少数被试的情况下，有效提升睡眠分期的性能。这种方法不仅验证了频率信息对于睡眠分期的重要性，还进一步证明了深度神经网络能够结合多种不同的信息来优化睡眠分期的结果。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.06544", "html_url": "https://arxiv.org/abs/2407.06544", "title": "多重实例验证", "title_en": "Multiple Instance Verification", "authors": "Xin Xu,Eibe Frank,Geoffrey Holmes", "background": "本文探讨了一种查询实例与包含异质且未知相关性的目标实例集合进行验证的形式设定，即多重实例验证。现有的基于注意力的多重实例学习（MIL）方法和标准的验证方法（如双胞胎神经网络）在这一设定下表现不佳：直接将最新的MIL方法与双胞胎网络结合甚至不如简单的基线模型。本文认为这可能是由于目标包的表示未能包含查询实例所致。", "innovation": "为了克服这一问题，作者提出了一个新的称为\"交叉注意力池化\"（CAP）的池化方法。在此框架下，提出了一种新颖的注意力函数，旨在区分目标包中高度相似的实例。实验结果显示，与SOTA的MIL方法和基线模型相比，CAP在分类准确性和识别关键实例方面均表现出更优的性能。此外，消融研究进一步证实了新注意力函数在识别关键实例方面的优越性。", "conclusion": "本文通过引入CAP方法，不仅在多种验证任务上取得了显著性能提升，还通过对关键实例的识别能力进行了详尽的分析，证明了其有效性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14163", "html_url": "https://arxiv.org/abs/2509.14163", "title": "通过混合量子-经典生成模型架构的量子强化学习指导扩散模型在图像合成中的应用", "title_en": "Quantum Reinforcement Learning-Guided Diffusion Model for Image Synthesis via Hybrid Quantum-Classical Generative Model Architectures", "authors": "Chi-Sheng Chen,En-Jui Kuo", "background": "传统的扩散模型通常使用静态或启发式的去噪分类器自由指导(CFG)计划，这些计划往往无法适应每个时间步和噪声条件的变化。本文提出了一个量子强化学习(QRL)控制器，它在每个去噪步骤中动态调整CFG，实现对条件的适应。", "innovation": "该工作提出了一种混合量子-经典的演员-评论家架构，使用浅层可变量子电路（VQC）和带环纠缠的生成策略特征，通过紧凑的多层感知机（MLP）映射成关于ΔCFG的高斯动作，同时通过经典的评论家估计价值函数。该策略采用了Proximal Policy Optimization (PPO)结合Generalized Advantage Estimation (GAE)，并通过平衡分类置信度、感知改善和动作规整性的奖励进行优化。", "conclusion": "我们的实验结果表明，通过量子强化学习的策略能够提高感知质量（LPIPS、PSNR、SSIM）并减少参数数量相比传统的经典强化学习演员和固定时间表。关于量子比特数量和电路深度的消融研究揭示了准确性与效率之间的权衡，并且扩展评估证实了在长时间扩散时间内生成的鲁棒性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.06718", "html_url": "https://arxiv.org/abs/2501.06718", "title": "DRDT3: 改进的决策测试时刻训练模型", "title_en": "DRDT3: Diffusion-Refined Decision Test-Time Training Model", "authors": "Xingshuai Huang,Di Wu,Benoit Boulet", "background": "决策转换器（DT）在多种经典控制任务中表现出与传统 Offline RL 方法相媲美的性能。然而，DT 在从次优、带有奖励标签的轨迹中学习最优策略方面表现不佳。本文研究了利用条件生成建模（因为它具有高质量数据生成能力）来促进轨迹缝合的方法，并利用了最近在循环神经网络（RNN）中取得的进步——尽管它们的复杂度为线性，但在序列建模性能上与 Transformer 相当。在 DT 模型中引入 Test-Time Training (TTT) 层，可以利用其在测试时更新隐藏状态的能力来建模决策过程。", "innovation": "本文提出了一种新的框架 DRDT3（Diffusion-Refined Decision TTT），它通过结合自注意力机制和 TTT 层来利用序列建模优势，并通过生成扩散模型迭代改进粗略的行动预测，使其逐步接近最优行动。还提出了一种名为 Decision TTT (DT3) 的模块，它可以使用这两种机制捕捉最近的上下文信息并做出粗略的动作预测。DRDT3 利用DT3与扩散模型的统一优化目标进一步提高了性能，实验证明其在多个 D4RL 子任务上表现优于标准的 DT 模型和最先进的 DT 基础方法及 Offline RL 方法。", "conclusion": "实验结果表明，在多个 D4RL 子任务上，DRDT3 模型展示了优于标准 DT 模型的性能，而 DRDT3 进一步实现了优于最先进的基于 DT 和 Offline RL 方法的结果。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06301", "html_url": "https://arxiv.org/abs/2502.06301", "title": "利用新颖性演化策略训练强化学习中的变压器", "title_en": "Utilizing Novelty-based Evolution Strategies to Train Transformers in Reinforcement Learning", "authors": "Matyáš Lorenc,Roman Neruda", "background": "本文研究了利用新颖性演化策略训练复杂的 transformers 架构在强化学习问题上的有效性。实验基于 OpenAI-ES 的变体进行，包括 NS-ES 和 NSR-ES。研究情景还包括使用预训练模型来加快新颖性训练的加速效果。", "innovation": "提出使用新颖性演化策略 NS-ES 和 NSR-ES 算法来训练决策 transformers，并探讨了通过预训练模型加速训练的可能性。", "conclusion": "实验结果表明，在训练更复杂的模型如 Decision Transformers 时，NS-ES 进展显著，但明显需要更多的迭代次数才能产生有趣的结果。相比之下，NSR-ES 在较大的模型中表现相当出色，其性能在前向模型和 Decision Transformers 中相似于我们在之前工作中使用的 OpenAI-ES。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.18506", "html_url": "https://arxiv.org/abs/2411.18506", "title": "LLM-ABBA：通过符号近似理解时间序列", "title_en": "LLM-ABBA: Understanding time series via symbolic approximation", "authors": "Erin Carson,Xinye Chen,Cheng Kang", "background": "先前的研究已经证明大型语言模型（LLMs）在时间序列分析中的成功。利用符号表示法，可以高效地将LLMs与时间序列联系起来，然而，剩余的挑战是如何利用时间序列中隐含的语义信息，尤其是在使用符号或现有的LLM的标记时，并将LLMs的嵌入空间与时间序列中的隐含信息对齐。适应性布朗桥符号聚合（ABBA）方法能够通过建模时间序列模式（振幅和周期）来保留显著的时间序列特征，同时利用现有的LLM标记。本文在此基础上，提出了一种方法LLM-ABBA，将ABBA整合到大型语言模型中，以解决各种下游时间序列任务。", "innovation": "LLM-ABBA将ABBA方法整合到了大型语言模型中，能够将时间序列符号化，与当前的时间序列分类和回归SOTA方法相比表现更优。同时，ABBA中的固定多边形链技巧引入，避免了预测任务中由于符号到数值转换期间使用的符号错误而导致的累积误差导致的明显漂移，展示了强大的预测能力，达到了新SOTA结果。这一框架还可以无缝扩展到其他时间序列任务中。", "conclusion": "本文介绍的方法LLM-ABBA不仅在UCR数据集和三个医学时间序列分类任务中表现出色，还在时间序列回归任务中达到了新的SOTA结果。此外，通过符号近似方法，LLM-ABBA展示了与现有时间序列预测SOTA方法相当的预测能力，并认为这一框架可以无缝扩展到其他时间序列任务中。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.08299", "html_url": "https://arxiv.org/abs/2410.08299", "title": "用图形私密学习及其在微调大型语言模型中的应用", "title_en": "Privately Learning from Graphs with Applications in Fine-tuning Large Language Models", "authors": "Haoteng Yin,Rongzhe Wei,Eli Chien,Pan Li", "background": "图形能够提供独特的关系洞察，补充如文本和图像的数据模态，并使AI模型能力超越传统任务。然而，从图形学习过程中涉及到处理敏感关系，引发了重大的隐私问题。现有隐私保护方法，如DP-SGD，依赖于梯度解耦假定，但与关系学习不兼容，因为训练样本间存在着固有的依赖关系。", "innovation": "本文提出了一种用于关系学习的隐私保护管道，该管道通过在一个适合的应用DP-SGD的方法中解耦样本关系的依赖，以确保差分隐私。将此方法应用于敏感图形数据上的大型语言模型（LLMs）的微调，同时解决相关计算复杂性问题，并在四种真实世界文本关联图上进行评估，展示了关系学习任务中的显著改进，同时保持了强大的隐私保障。此外，我们分析了隐私、实用性和计算效率之间的权衡，为隐私保护关系学习的实际部署提供了见解。", "conclusion": "该方法通过解耦采样关系的依赖，采用定制化的DP-SGD方法，能够在隐私保护的前提下，显著提升关系学习任务。实验证明，论文方法不仅有效提升了模型的性能，还能够保证用户隐私不受侵犯。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14314", "html_url": "https://arxiv.org/abs/2501.14314", "title": "相似臂上的图表反馈多臂赌博机：有结构和无结构", "title_en": "Graph Feedback Bandits on Similar Arms: With and Without Graph Structures", "authors": "Han Qi,Fei Guo,Li Zhu,Qiaosheng Zhang", "background": "论文研究了具有图表反馈的随机多臂赌博机问题，受到临床试验和推荐系统应用的启发，假设两个臂之间如果有相似性（即它们的期望值接近），则两个臂之间有连接。研究基于这种新颖的反馈结构建立了遗憾下界，并引入了两种基于上置信界（UCB）算法：Double-UCB（具有问题无关的遗憾上界）和Conservative-UCB（具有问题相关的上界）。利用这些相似结构，研究了一个臂的数量随时间增加（称为膨胀设置）的场景。", "innovation": "论文提出了两种基于UCB的算法（Double-UCB和Conservative-UCB），不仅为膨胀设置场景提供遗憾上界，还提出了不依赖于图结构先验知识的新版本算法，同时验证了理论结果的有效性。", "conclusion": "在膨胀设置的场景下，针对两种UCB算法（Double-UCB和Conservative-UCB），研究提供了有界遗憾结果，并在实验中验证了理论分析的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06857", "html_url": "https://arxiv.org/abs/2502.06857", "title": "Gemstones: 多面性的缩放定律模型套件", "title_en": "Gemstones: A Model Suite for Multi-Faceted Scaling Laws", "authors": "Sean McLeish,John Kirchenbauer,David Yu Miller,Siddharth Singh,Abhinav Bhatele,Micah Goldblum,Ashwinee Panda,Tom Goldstein", "background": "通常缩放定律是通过一系列具有狭窄范围固定超参数的选择来拟合的。在本文中，我们研究了不同架构形状和超参数选择对缩放定律的影响，以揭示它们对结果处方的影响。作为我们研究的主要成果，我们发布了Gemstones：一个开源的缩放定律数据集，其中包括超过4000个从具有最多20亿参数的变换器中提取的检查点，这些变换器包含学习率和冷却期的消融研究；并且通过这些检查点可以进行更复杂的研究，例如分析宽度和深度之间的关系。研究还发现，缩放定律的处方对实验设计过程和在拟合过程中使用的特定模型检查点高度敏感。", "innovation": "我们使用多种架构形状和超参数选择来研究缩放定律，揭示了它们对结果处方的影响，并且我们提供了一个开源的Gemstones数据集，其中包括超过4000个检查点，这些检查点可以用来进行更复杂的研究，如分析宽度与深度之间的关系。我们的研究发现了缩放定律的处方对实验设计和所使用的特定模型检查点高度敏感，强调了实验设计的重要性，并提供了一个可以进一步研究的多面性的缩放定律模型套件。", "conclusion": "通过研究我们模型套件，我们发现缩放定律的处方对实验设计和使用进行拟合的具体模型检查点高度敏感。此外，我们发布了Gemstones数据集，以支持缩放定律的进一步研究。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.01658", "html_url": "https://arxiv.org/abs/2503.01658", "title": "CoPL：个性化大型语言模型的协作偏好学习", "title_en": "CoPL: Collaborative Preference Learning for Personalizing LLMs", "authors": "Youngbin Choi,Seunghyuk Cho,Minjong Lee,MoonJeong Park,Yesong Ko,Jungseul Ok,Dongwoo Kim", "background": "个性化大型语言模型（LLMs）对于使输出与用户多样化的需求一致至关重要，但现有方法在灵活性和泛化能力上存在不足。虽然存在一些方法，但它们在处理稀疏标注设置中的偏好估计时表现不佳。这项研究提出了CoPL（Collaborative Preference Learning，协作偏好学习）框架，该框架利用图协作过滤方法，通过建模用户-响应关系来改进偏好估计。CoPL能有效适应大型语言模型的微调，特别是在稀疏标注设置中。", "innovation": "CoPL是一种基于图的协同过滤框架，它通过整合多个LoRA专家模型来高效地微调大型语言模型，同时动态平衡共享偏好和用户特定偏好。此外，CoPL还提供了一种无需优化的适应策略，可以在无需微调的情况下泛化到未见过的用户。实验结果表明，CoPL在UltraFeedback-P数据集上优于现有的个性化奖励模型，能够准确捕捉到普遍和争议性的偏好，使其成为可扩展的个性化语言模型对齐解决方案之一。", "conclusion": "CoPL在大规模语言模型个性化中表现出色，特别是在稀疏标注设置下能够有效估计偏好，并且能够泛化到未见过的用户。该研究提出的方法提供了一种更加灵活和泛化的个性化语言模型对齐解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12484", "html_url": "https://arxiv.org/abs/2502.12484", "title": "LocalEscaper: 一种具有区域重建的大规模神经TSP求解器的弱监督框架", "title_en": "LocalEscaper: A Weakly-supervised Framework with Regional Reconstruction for Scalable Neural TSP Solvers", "authors": "Junrui Wen,Yifei Li,Bart Selman,Kun He", "background": "人工神经网络在解决旅行商问题（TSP）方面显示出巨大的潜力，但当前方法面临显著挑战。基于监督学习（SL）的求解器需要大量的高质量标记数据，而基于强化学习（RL）的求解器虽然对数据的依赖较小，但也常常存在效率低下问题。", "innovation": "我们提出了一种名为LocalEscaper的新颖弱监督学习框架，用于大规模TSP求解。该框架结合了SL和RL的优点，能够在低质量标签的数据集上进行有效的训练，并引入了一种区域重建策略，解决了现有局部重建方法中的局部最优问题。", "conclusion": "实验结果显示，LocalEscaper在合成和真实数据集上均优于现有的神经求解器，取得显著成果。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.11216", "html_url": "https://arxiv.org/abs/2504.11216", "title": "FedDiverse: 使用多样性驱动的客户端选择解决联邦学习中数据异质性", "title_en": "FedDiverse: Tackling Data Heterogeneity in Federated Learning with Diversity-Driven Client Selection", "authors": "Gergely D. Németh,Eros Fanì,Yeat Jeng Ng,Barbara Caputo,Miguel Ángel Lozano,Nuria Oliver,Novi Quadrianto", "background": "联邦学习（FL）能够在保护隐私的情况下，在分布式的客户端数据上进行去中心化的机器学习模型训练。但在实际应用场景中，客户端的数据往往是非同分布且不平衡的，这导致了数据统计异质性，影响了服务器模型在客户端之间的泛化能力，降低了收敛速度和整体性能。", "innovation": "本文提出了FEDDIVERSE，这是一种新颖的客户端选择算法，在联邦学习中通过促进具有互补数据分布的客户端之间的协作来管理和利用数据异质性。该算法通过6个指标对数据异质性进行了表征，并创建了7个涵盖广泛数据异质性的计算机视觉数据集来模拟真实世界的环境。实验表明，FEDDIVERSE在提高多种联邦学习方法的性能和鲁棒性方面具有有效性，并且具有低通信和计算成本。", "conclusion": "本文首先通过6个指标表征了数据异质性，随后创建和共享了覆盖广泛数据异质性的计算机视觉数据集，并提出了FEDDIVERSE算法以更好地利用数据异质性，增强联邦学习的性能和鲁棒性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10408", "html_url": "https://arxiv.org/abs/2503.10408", "title": "大规模语言模型中的离境上下文推理", "title_en": "Out-of-Context Reasoning in Large Language Models", "authors": "Jonathan Shaki,Emanuele La Malfa,Michael Wooldridge,Sarit Kraus", "background": "研究如何通过简单的二元关系（如等于、不等于、包含等）来使大规模语言模型（LLMs）推理关于记忆的知识。与在上下文推理不同，在训练期间才出现的公理（如 a < b, b < c）不会在任务提示中给出（如评估 a < c）。这些任务要求进行一个或多个推理步骤，并从一个或多个来源聚合数据，显示了随着任务复杂性增加表现的变化。", "innovation": "提出了一种轻量级技术——离境上下文表示学习（out-of-context representation learning），该技术仅在公理（axioms）上训练新的标记嵌入，并在未见过的任务上进行评估。实验证明，在反射性、对称性和传递性测试中，LLMs 大部分都能表现出统计学上显著优于随机猜测的表现，且通过多种表述变体测试仍能提取出正确答案，但仍然无法在每个查询中进行一致的推理。研究表明，学习到的嵌入是按结构组织的方式，表明真实的关系理解。出乎意料的是，这还表明主要的推理发生在训练期间，而不是推理阶段。", "conclusion": "在反射性、对称性和传递性测试中，LLMs 大部分能表现出统计学上显著优于随机猜测的表现，且通过多种表述变体测试仍能提取出正确答案，表明了真实的关系理解。然而，主要的推理发生在训练期间，而不是推理阶段，这表明离境上下文学习技术的有效性，但仍然有待进一步研究以实现一致的推理能力。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.18454", "html_url": "https://arxiv.org/abs/2504.18454", "title": "伪异步本地SGD：鲁棒和高效的并行数据训练", "title_en": "Pseudo-Asynchronous Local SGD: Robust and Efficient Data-Parallel Training", "authors": "Hiroki Naganuma,Xinzhi Zhang,Man-Chung Yue,Ioannis Mitliagkas,Philipp A. Witte,Russell J. Hewett,Yin Tat Lee", "background": "随着AI规模的不断扩大，最前沿的模型不断增大，并且需要更大规模的数据集进行训练。这种大规模训练需要大量的超算资源，因此推动了分布式深度学习方法的发展。数据并行是加速训练的重要方法，但频繁的全局通信会在大规模训练时成为瓶颈。本文针对这一问题，提出了伪异步本地SGD（PALSGD），旨在通过引入伪同步机制减少通信频率，同时保持模型一致性，从而提高训练效率。", "innovation": "本文提出了一种名为伪异步本地SGD（PALSGD）的方法，这是Local SGD和DiLoCo的扩展版本。通过引入伪同步机制，PALSGD能够在较长时间的同步间隔下保持模型一致性，从而训练模型时减少通信频率。此外，本文还提供了PALSGD的理论分析，证明了其收敛性和收敛速率，并通过对比实验展示了PALSGD在不同任务上的更好性能，如ImageNet-1K的ResNet-50、TinyStories的GPT-Neo-125M和GPT-Neo-8M任务中，比分布式数据并行（DDP）和DiLoCo方法更快完成训练。", "conclusion": "研究表明，PALSGD在减少通信开销的同时，能够保持模型训练的一致性，并在多种任务上展现出比现有方法更好的性能指标，因此是一种鲁棒且高效的并行数据训练方法。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.10212", "html_url": "https://arxiv.org/abs/2411.10212", "title": "通过一致性评分嵌入联邦学习中的拜占庭容错", "title_en": "Embedding Byzantine Fault Tolerance into Federated Learning via Consistency Scoring", "authors": "Youngjoon Lee,Jinu Gong,Joonhyuk Kang", "background": "在拥有来自多个边缘设备的足够数据的情况下，联邦学习（FL）能够在不将私人数据传输到中央服务器的前提下训练共享模型。然而，FL通常容易受到由被攻破的边缘设备发起的拜占庭攻击，这可能会显著降低模型性能。现有FL方法在面对这种攻击时保护不足。因此，本次研究解决了如何在保持原有优势的同时增强联邦学习方法抵抗拜占庭攻击的能力的问题。", "innovation": "提出了一种直观的插件，该插件能够无缝地将拜占庭鲁棒性嵌入现有的联邦学习方法中。该插件的关键思想是生成虚拟数据样本，通过在局部更新过程中评估模型一致性评分来进行被攻破更新的有效过滤。在聚合阶段之前利用此评分机制，该插件使现有的联邦学习方法能够在面临拜占庭攻击时仍保持其原有优势。研究结果表明，带有此插件的FedAvg在遭受30%的有目标攻击时，测试精度超过89.6%，而没有插件时则为19.5%；在无目标攻击中，带有插件的测试精度为65-70%，而没有插件时则为17-19%。", "conclusion": "研究提出的一种简单易用的插件通过增强联邦学习的拜占庭鲁棒性，大幅提升了模型性能，确保了在面对各类攻击时的高鲁棒性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.05424", "html_url": "https://arxiv.org/abs/2503.05424", "title": "通过渐进干预和测量属性梯度进行局部解释预测行为", "title_en": "Locally Explaining Prediction Behavior via Gradual Interventions and Measuring Property Gradients", "authors": "Niklas Penzel,Joachim Denzler", "background": "深度学习模型在预测性能上表现出色，但在内在可解释性方面存在不足，阻碍了我们对学习预测行为的理解。现有的局部解释方法侧重于关联分析，忽略了模型预测的因果驱动因素。其他方法虽然采用了因果视角，但主要是提供全局模型级别的解释，对于特定输入而言，难以确定全局识别的因素是否适用于局部情况。本研究提出了一种利用近期图像到图像编辑模型进步的新框架，来实现局部干预解释。该方法通过对语义属性的逐步干预，量化模型预测的变化，使用新引入的得分——预期属性梯度幅度，来进行评估。", "innovation": "本研究创新性地提出了一种利用图像编辑模型的新框架，应用于局部干预解释。通过逐步干预语义属性，评估对模型预测的影响，提出新的得分——预期属性梯度幅度，有助于更好地理解深度模型的行为。研究通过广泛的实证评价，展示了这种方法在多种架构和任务上的有效性，并在合成场景、医疗皮肤病变分类器、网络训练动态分析和预训练CLIP模型研究中进行了应用，证明其在揭示深度模型行为的新见解方面的潜力。", "conclusion": "本研究展示了通过干预解释和测量属性梯度来局部解释模型预测行为的有效性和潜力，为理解复杂深度模型的行为提供了一个新的视角，有助于提高模型的可信任度和理解度。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.19639", "html_url": "https://arxiv.org/abs/2504.19639", "title": "Kolmogorov-Arnold网络在医疗成像中联邦学习中的统一基准", "title_en": "A Unified Benchmark of Federated Learning with Kolmogorov-Arnold Networks for Medical Imaging", "authors": "Youngjoon Lee,Jinu Gong,Joonhyuk Kang", "background": "联邦学习（FL）使得模型训练可以在分散的设备上进行而无需共享原始数据，从而在医疗、健康等敏感领域保护隐私。在此背景下，本文对比了Kolmogorov-Arnold网络（KAN）架构和传统的多层感知机（MLP）在六个最先进的联邦学习算法上的表现，使用的是血液细胞分类数据集。研究表明，KAN在联邦环境中可以有效地替代MLP，具有更为简单的架构仍能获得更好的性能。此外，研究还分析了关键超参数（网格大小和网络架构）对KAN性能在不同的非独立不一致（Non-IID）数据分布下的影响，并发现优化KAN的宽度并保持浅层结构可以取得最佳性能。这些发现为隐私保护的分布式医疗成像应用提供了KAN作为一个有前景的选择。", "innovation": "本文通过对比Kolmogorov-Arnold网络（KAN）架构和传统多层感知机（MLP）在联邦学习中的表现，验证了KAN在联邦环境中的有效性和优越性，特别是在非独立不一致数据分布下的性能分析。研究表明，优化KAN宽度并保持浅层结构可取得最佳性能，这为联邦学习中使用KAN进行了全面的基准测试。", "conclusion": "本文证明Kolmogorov-Arnold网络KAN是隐私保护的医疗成像应用的一个有前景的选择。这是首次在联邦学习设置中全面评估KAN用于医疗成像任务。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.02308", "html_url": "https://arxiv.org/abs/2505.02308", "title": "启用局部神经操作符进行方程无忧系统级分析", "title_en": "Enabling Local Neural Operators to perform Equation-Free System-Level Analysis", "authors": "Gianluca Fabiani,Hannes Vandecasteele,Somdatta Goswami,Constantinos Siettos,Ioannis G. Kevrekidis", "background": "神经操作符（NOs）为涉及可以通过（积分）偏微分方程（PDEs）建模的物理法则的计算提供了一个强大的框架，可以直接学习无穷维函数空间之间的映射，从而绕过显式方程的识别及其随后的数值求解。然而，到目前为止，NOs 主要被用来作为一个高效的替代手段，用于替代繁重的时域模拟/预测，它们在这个方面的系统级严格数值任务（如定点、稳定性、分岔分析）的应用潜力尚未充分探索，这些任务对于预测真实世界现象中不可逆的转变至关重要。", "innovation": "本文借鉴方程无忧多尺度框架，提出了一个将局部NOs与Krylov子空间中的高级迭代数值方法结合起来的框架，旨在高效地进行大规模动力系统的一级稳定性和分岔分析。此外，本文不仅展示了局部时间尺度NOs在定点、稳定性、分岔分析中的用途，还展示了局部空间尺度及空间-时间尺度（“补丁”）NOs在加速时空动力学的计算机辅助分析中的效用。", "conclusion": "本文通过三个非线性PDE基准（1D Allen-Cahn方程、Liouville-Bratu-Gelfand方程和FitzHugh-Nagumo模型）展示了提出的框架的有效性。这些分析涉及多种分岔现象，包括多重连接的投针分岔、鞍点跳转点以及包含Hopf和鞍点分岔的耦合PDE体系。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.13912", "html_url": "https://arxiv.org/abs/2507.13912", "title": "基因表达数据上的自监督学习", "title_en": "Self-supervised learning on gene expression data", "authors": "Kevin Dradjat,Massinissa Hamidi,Pierre Bartet,Blaise Hanczar", "background": "基因表达数据在生物医学研究中预测表型是一项关键任务，有助于深入了解疾病机制、药物反应和个人化医疗。传统机器学习和深度学习依赖于监督学习，需要大量的已标记数据，而这些数据在基因表达数据的情况下获取成本高昂且耗时。最近，自监督学习作为一种减轻这些限制的方法，通过直接从未标记数据的结构中提取信息而兴起。", "innovation": "本文研究了将最新的自监督学习方法应用于大规模基因表达数据进行表型预测。选择了三种基于不同方法的自监督方法来评估它们利用数据内在结构并生成用于下游预测任务的定性表示的能力。通过使用多个公开可用的基因表达数据集，我们展示了所选方法如何有效捕捉复杂信息并提高表型预测准确性。结果表明，自监督学习方法不仅可以超越传统的监督模型，还能显著减少对标注数据的依赖。", "conclusion": "我们对每种方法的性能进行了综合分析，并强调了它们的优势和限制。我们也提供了针对具体情况使用这些方法的建议，并阐明了进一步提高自监督学习在基因表达数据分析中的应用的研究方向。这项研究是首次处理大型RNA-Seq数据和自监督学习的论文。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00326", "html_url": "https://arxiv.org/abs/2509.00326", "title": "分块TabPFN：针对长上下文表格数据的无训练即学即用精确学习", "title_en": "Chunked TabPFN: Exact Training-Free In-Context Learning for Long-Context Tabular Data", "authors": "Renat Sergazinov,Shao-An Yin", "background": "TabPFN v2 在多个表格基准测试上取得了比基于树模型更好的结果，这值得注意，因为基于树的模型通常是对表格数据表现最强的选择。然而，它无法处理超过10K上下文令牌，因为变压器的计算和内存成本呈平方级增长。现有的方法通常依赖于上下文压缩，如通过K最近邻(KNN)选择代表性样本，但这些方法限制了TabPFN处理长上下文的能力。", "innovation": "研究引入了一种分块策略，基于TabPFN框架计算注意力，这种方法兼容标准GPU设置，并且据我们所知，这是首次使TabPFN能够无需预处理即可处理长上下文。这种方法在标准的TabArena基准测试上展示了其有效性，同时提供了代码。", "conclusion": "我们的方法有效处理了长上下文表格数据，表现为TabPFN能够直接处理而无需任何预处理，这已在标准的TabArena基准测试中得到了证明。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21717", "html_url": "https://arxiv.org/abs/2505.21717", "title": "扩展液阻-液容网络以实现高效的序列建模", "title_en": "Scaling Up Liquid-Resistance Liquid-Capacitance Networks for Efficient Sequence Modeling", "authors": "Mónika Farsang,Ramin Hasani,Daniela Rus,Radu Grosu", "background": "当前的线性状态空间层在处理长序列时速度较慢。论文提出了一种名为LrcSSM的非线性递归模型，能够以接近当前线性状态空间层的速度处理长序列，而不需要性能损失。该模型通过使雅可比矩阵对角化，使得整个序列能够并行处理，从而减少了时间和空间的消耗，同时保证了梯度的稳定性，这是其他变输入系统（如Liquid-S4和Mamba）无法提供的。相比于原来的模型，LrcSSM展示了更广泛的应用潜力，尤其是在其他非线性递归模型中。", "innovation": "非线性递归模型LrcSSM通过使雅可比矩阵对角化，使得整个序列能够并行处理，从而在保证梯度稳定性的同时，大大降低了时间和空间的消耗。LrcSSM在长序列预测任务上表现出色，优于Transformer、LRU、S5和Mamba等模型。此外，LrcSSM没有性能损失，并且该方法可以推广到其他的非线性递归模型中，具有更广泛的应用潜力。", "conclusion": "LrcSSM能够在处理长序列时达到与当前线性状态空间层相当的速度，同时提供梯度稳定性保证，优于现有的长序列预测模型，并且具有更广泛的应用潜力。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.01613", "html_url": "https://arxiv.org/abs/2407.01613", "title": "平衡残差衰减率基于自适应加权方法在物理信息神经网络和深度算子网络中的应用", "title_en": "Self-adaptive weights based on balanced residual decay rate for physics-informed neural networks and deep operator networks", "authors": "Wenqian Chen,Amanda A. Howard,Panos Stinis", "background": "物理信息深度学习被证明是求解偏微分方程的一种有前途的替代方法，但对于复杂问题，训练这些网络仍具有挑战性，通常会导致不令人满意的结果和效率。", "innovation": "提出了一种基于平衡残差衰减率的自适应加权方法，该方法在不同训练点之间平衡残差衰减率，从而提高整体解的收敛性。", "conclusion": "通过广泛的数值结果表明，提出的平衡残差衰减率的方法具有多个优点，包括有界权重、高预测精度、快速收敛率、低训练不确定性、低计算成本和易于超参数调整。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.08683", "html_url": "https://arxiv.org/abs/2509.08683", "title": "Federated学习中的完美隐私模拟安全聚合", "title_en": "Perfectly-Private Analog Secure Aggregation in Federated Learning", "authors": "Delio Jaramillo-Velez,Charul Rajput,Ragnar Freij-Hollanti,Camilla Hollanti,Alexandre Graell i Amat", "background": "在联邦学习中，多个参与方通过各自本地训练模型并将参数共享给中心服务器，中心服务器则通过聚合这些参数以更新全局模型。为了应对本地模型中可能泄露敏感数据的风险，已经提出了通过安全多方计算来增强隐私性的安全聚合方法。然而，当采用实数值数据时，实现完美隐私是一项挑战，因为没有在实数上不变的掩码分布，信息泄漏不可避免。将数据移至有限域虽然可以解决问题，但也带来了精度与复杂性的固有权衡问题，因为有限域中的定点模运算无法同时处理不同大小的数值，而浮点数可以做到这一点。", "innovation": "本文提出了一种新颖的安全参数聚合方法，该方法采用环面（torus）而不是有限域。这种方法通过在环面中利用均匀分布确保每个参与方数据的完美隐私，同时避免了精度损失。实验结果显示，新的协议在保持完美隐私的同时与未采用安全聚合的模型性能相似，而且与有限域安全聚合相比，在某些情况下模型准确性和余弦相似度方面表现出更好的性能，从而使其成为更安全的选择。", "conclusion": "环面基于的协议在某些情况下可以在模型准确性和余弦相似度方面显著优于有限域协议，同时保持完美隐私，因此成为更为安全的选择。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.13057", "html_url": "https://arxiv.org/abs/2508.13057", "title": "分级评估函数：一种优化需求预测模型的多指标方法", "title_en": "Hierarchical Evaluation Function: A Multi-Metric Approach for Optimizing Demand Forecasting Models", "authors": "Adolfo González,Víctor Parada", "background": "在动态和竞争性强的环境中，准确的需求预测对于有效的库存管理至关重要。传统评估指标如平均绝对误差（MAE）和均方根误差（RMSE）提供了互补视角，但单独使用时会导致偏差评估。鉴于不确定性、财务限制和物流限制等因素的影响，需要更全面的评估方法来确保需求预测模型的有效性。", "innovation": "本文提出了一种分级评估函数（HEF），它是一种综合R2、MAE和RMSE的复合函数，采用了层次和自适应框架。HEF通过动态权重、基于时间序列统计特性的容差阈值和递增惩罚机制确保了对极端误差和无效预测的鲁棒性。此外，HEF利用网格搜索、粒子群优化（PSO）和Optuna优化多个预测模型，并在Walmart、M3、M4和M5基准数据集上进行了测试。实验结果表明，HEF在R2、全局相对准确度（GRA）、RMSE和RMSSE等全球指标上优于MAE，提供了更强大的解释力、适应性和稳定性。尽管MAE在简单性和效率方面有优势，但HEF更为适用于长期规划和复杂环境。", "conclusion": "HEF为在高度变化的需求预测环境中选择和优化模型提供了一种稳健且适应性强的替代方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.07872", "html_url": "https://arxiv.org/abs/2509.07872", "title": "利用支持向量回归、影像组学和剂量组学在个性化超分割立体适形调适放疗(PULSAR)中预测结果", "title_en": "Leveraging Support Vector Regression, Radiomics and Dosiomics for Outcome Prediction in Personalized Ultra-fractionated Stereotactic Adaptive Radiotherapy (PULSAR)", "authors": "Yajun Yu,Steve Jiang,Robert Timmerman,Hao Peng", "background": "PULSAR是一种新型放疗技术，能够以延长间隔脉冲形式进行放射治疗。准确预测大体肿瘤体积（GTV）的变化对于治疗效果预测具有重要意义。本研究旨在开发一种基于多组学的支持向量回归（SVR）模型，以预测GTV的变化。分析了39名患者共69个脑转移瘤的数据，基于影像组学（MRI图像）和剂量组学（剂量图）的特征，通过特征选择和回归模型评估，探讨了多组学模型在预测PULSAR中GTV连续变化的效果。", "innovation": "研究提出了一个多组学支持向量回归（SVR）模型，结合影像组学和剂量组学数据，特别是使用了特征选择和不同类型特征（如时间点差异特征）的多模型对比分析，提升了GTV变化的预测精度。识别出对预测效果至关重要的差异影像组学特征，并展示了该模型在PULSAR中的应用潜力。", "conclusion": "结合影像组学和剂量组学的多组学支持向量回归（SVR）模型在预测PULSAR中GTV的连续变化方面表现出色。该模型为个性化治疗提供了更定量、个性化的选择和调整方式，有助于提高治疗效果。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.21422", "html_url": "https://arxiv.org/abs/2507.21422", "title": "GraphTorque：基于扭矩驱动的图神经网络重布线方法", "title_en": "GraphTorque: Torque-Driven Rewiring Graph Neural Network", "authors": "Sujia Huang,Lele Fu,Zhen Cui,Tong Zhang,Na Song,Bo Huang", "background": "图神经网络（GNNs）由于利用消息传递扩散信息并更新节点表示，在处理图结构数据方面已展现出强大的潜力。然而，现有研究大多假设图中原有的交互方式不利于这一过程，激发了图重布线方法的发展。该paper探讨了一种基于扭矩驱动的层次重布线策略，通过动态调整消息传递以改善复杂和异质图中的表征学习，并提升对嘈杂图的鲁棒性。", "innovation": "该paper提出了一种创新的扭矩驱动的重布线策略，通过引入了一个感知干扰的扭矩度量来量化边引起的扰动，并据此鼓励节点从低能量邻居处聚合信息。策略通过分层次地重新配置各层的感受野，慎重地剪枝高扭矩边并添加低扭矩边，以抑制传播噪声并增强相关信号。", "conclusion": "通过对基准数据集的广泛评估，该paper的方法在异质图和同质图上均优于现有最先进方法，同时在嘈杂图上保持了高水平的准确性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05798", "html_url": "https://arxiv.org/abs/2505.05798", "title": "通过错误纠正输出编码提高柯莫哥洛夫-阿诺德网络的泛化能力", "title_en": "Improving Generalizability of Kolmogorov-Arnold Networks via Error-Correcting Output Codes", "authors": "Youngjoon Lee,Jinu Gong,Joonhyuk Kang", "background": "Kolmogorov-Arnold Networks (KAN) 提供了一种使用无非线性激活的分段函数来实现通用函数逼近的方法。KAN 的核心在于使用一元样条函数的组合来近似任何连续函数，而不需要传统的激活函数。虽然 KAN 构架本身在某些应用场景中表现良好，但在处理多类分类问题时遇到了挑战，特别是在医疗图像分类等关键领域需要更高的鲁棒性和泛化能力。为了解决这些问题，研究者们提出了各种改进方法，其中之一是通过将错误纠正输出编码（Error-Correcting Output Codes, ECOC）集成到 KAN 构架中。ECOC 通过将多类分类任务分解为多个二元分类任务，并通过汉明距离解码来提高分类器的鲁棒性。研究表明，ECOC 在提升多类分类性能方面表现出色，尤其是在复杂的数据集上效果更为明显。", "innovation": "将错误纠正输出编码 (ECOC) 集成到柯莫哥洛夫-阿诺德网络 (KAN) 构架中，从而将多类分类任务转换为多个二元分类任务，并通过汉明距离解码提高鲁棒性。实验表明，基于 ECOC 的改进 KAN（KAN-ECOC）框架在血细胞分类任务中取得了比标准 KAN 更高的准确率，且在多种超参数设置下依然表现更优。此外，消融研究表明，ECOC 在 FastKAN 和 FasterKAN 变种中的性能提升是一致的，这进一步验证了 KAN-ECOC 的有效性。这项研究是首次将 ECOC 应用于 KAN 以提升多类医疗图像分类性能的工作。", "conclusion": "将错误纠正输出编码 (ECOC) 集成到柯莫哥洛夫-阿诺德网络 (KAN) 中显著提升了 KAN 的泛化能力，特别是在医疗图像分类等关键领域。本研究提出的 KAN-ECOC 框架展示了在复杂场景下更高的准确性和鲁棒性，为 KAN 的实际应用奠定了坚实的基础。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.12694", "html_url": "https://arxiv.org/abs/2509.12694", "title": "软图变换器（SGT）在MIMO检测中的应用", "title_en": "Soft Graph Transformer for MIMO Detection", "authors": "Jiadong Hong,Lei Liu,Xinyu Bian,Wenjie Wang,Zhaoyang Zhang", "background": "最大似然（ML）检测虽然精度最优，但在大规模系统中由于其指数级的复杂性使其在实际应用中不可行。传统的消息传递算法依赖于渐近假设，往往在有限维度下表现不佳。最近基于Transformer的检测器虽然表现出色，但通常忽略了MIMO因子图结构，无法充分利用先验软信息。", "innovation": "软图变换器（SGT）结合了自注意力机制（编码符号和约束子图中的上下文依赖性）和图感知交叉注意力机制（进行子图间的结构化消息传递）。SGT通过其软输入接口允许集成辅助先验信息，既能产生有效的软输出，又保持了计算效率。", "conclusion": "实验表明，SGT接近ML性能，提供了一个灵活且可解释的接收系统框架，能够利用软先验信息。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01319", "html_url": "https://arxiv.org/abs/2509.01319", "title": "可信的生命体征预测：利用不确定性生成预测区间", "title_en": "Towards Trustworthy Vital Sign Forecasting: Leveraging Uncertainty for Prediction Intervals", "authors": "Li Rong Wang,Thomas C. Henderson,Yew Soon Ong,Yih Yng Ng,Xiuyi Fan", "background": "生命体征，如心率和血压，是评价患者健康状况的重要指标，广泛应用于临床监测和决策。虽然深度学习模型在这些信号的预测方面显示出潜力，但它们在医疗保健中的应用受到限制，尤其是在临床医生能够信任和解释模型输出方面。缺乏可靠的不确定性评估，特别是校准的预测区间（PI）的情况下，无法确定预测异常是否具有实际预警意义，还是仅仅反映了模型噪声，这阻碍了临床决策。", "innovation": "本文提出了两种方法，通过重建不确定性估计（RUE）生成预测区间（PIs）。这种方法特别适用于生命体征预测，因为它对数据偏移敏感，且支持无标签校准。一种参数方法假设预测误差和不确定性估计遵循高斯 copula 分布，从而可以进行闭式 PI 计算。另一种非参数方法基于 k 最近邻 (KNN)，通过利用类似验证实例的条件误差分布进行经验估计。实验结果表明，在低频数据上，高斯 copula 方法在一致性超越符合性预测基线方面表现更佳，而在高频数据上，KNN 方法表现最佳。这些结果强调了 RUE 得到的 PIs 在提供可解释的、不确定性意识的生命体征预测方面的临床潜力。", "conclusion": "研究表明，基于 RUE 的预测区间为临床医疗提供了一种可解释的、不确定性意识的生命体征预测手段，这有助于改进临床决策过程。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17534", "html_url": "https://arxiv.org/abs/2503.17534", "title": "MetaSel: 细调DNN模型的测试选择方法", "title_en": "MetaSel: A Test Selection Approach for Fine-tuned DNN Models", "authors": "Amin Abbasishahkoo,Mahboubeh Dadkhah,Lionel Briand,Dayi Lin", "background": "深度神经网络（DNNs）在部署过程中面临挑战，尤其是在数据分布发生变化时，即开发和部署环境下的数据分布不一致。为解决这一问题，研究人员提出了微调方法，即利用已预训练模型调整至新环境，但实质上仍然需要较小的标记数据集。尽管如此，如何在受到标签预算限制下有效测试微调过的模型仍是一个重要挑战。本文对这类问题进行了探讨，并提出了一种新的方法MetaSel，该方法旨在从未标记的数据中选择有效的测试方法以应对分布偏移的问题。MetaSel假设经过微调和未微调的模型在大量输入上具有相似的行为，但在微调改变了决策边界的小范围内，它们的行为存在显著差异，这种变化使得这些输入更容易发生误分类。MetaSel不再仅依赖DNN模型及其输入集，而是结合未微调和微调模型及其行为差异来估计未标记的测试输入的误分类概率，并据此选择测试集，这有助于更有效率地进行测试选择。", "innovation": "MetaSel方法创新之处在于：首先，它结合了未微调和微调模型的信息，同时考虑了行为差异；其次，它能够估计未标记测试输入的误分类概率，从而有效进行测试选择；再次，其在受约束的标签预算下的测试选择表现优于现有方法，特别是在分布显著变化的情况下。通过与11种最先进的方法对比，MetaSel在测试相对覆盖率（TRC）上取得显著提升，平均增加了28.46%到56.18%，并保持较高的中位数TRC和较低的变异性，证明了其实用性，鲁棒性和成本效益。", "conclusion": "本文提出了MetaSel方法，这是一种用于细调DNN模型的测试选择方法。在广泛的实验评估中，MetaSel展示了显著的测试相对覆盖率改进。作者得出结论，MetaSel是一种实用且成本效益高的测试选择方法，特别适合在高度受限的标记预算下进行细调模型的测试选择。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05037", "html_url": "https://arxiv.org/abs/2509.05037", "title": "ModaliSurv: 一种用于前列腺癌和膀胱癌的多模态深度生存框架", "title_en": "ModalSurv: A Multimodal Deep Survival Framework for Prostate and Bladder Cancer", "authors": "Noorul Wahab,Ethar Alzaid,Jiaqi Lv,Adam Shephard,Shan E Ahmed Raza", "background": "准确预测时间-事件结局是肿瘤学中的一个主要挑战，对治疗计划和患者管理具有重大影响。本文介绍了ModaliSurv，这是一种多模态深度生存模型，使用DeepHit并结合了投影层和跨模态交叉注意力机制，集成了包括临床、MRI、RNA-seq和全切片病理学特征在内的异质患者数据。该模型旨在跨模态捕捉互补的预后信号，用于估计前列腺癌的生化复发时间和膀胱癌的癌症复发时间。该方法在CHIMERA重大挑战的背景下进行了评估，涉及提供任务中的两个任务。对于前列腺癌生化复发预测任务1，提出的框架在5折交叉验证上的C指数为0.843，在CHIMERA开发集上的C指数为0.818，显示其具有稳健的辨别能力。对于膀胱癌复发预测任务3，模型在5折交叉验证上的C指数为0.662，在开发集上的C指数为0.457，突显了其适应性和临床转化潜力。这些结果表明，利用多模态整合与深度生存学习相结合为前列腺癌和膀胱癌提供了一条有前景的个性化风险分层途径。在挑战背景之外，该框架适用于涉及异质生物医学数据的生存预测任务。", "innovation": "提出了ModaliSurv，这是一种结合了DeepHit、投影层和跨模态交叉注意力机制的多模态深度生存模型，用于前列腺癌和膀胱癌的生存预测。该模型不仅能够综合分析不同类型的异质患者数据，还能捕捉跨模态的互补预后信号，提供了有前景的个性化风险分层策略。此外，该模型在实际挑战任务中表现出了稳健的辨别能力和适应性，尽管在膀胱癌预测任务上的结果相对较低，但仍显示出其潜在临床应用价值。", "conclusion": "多模态整合与深度生存学习相结合为个性化风险分层提供了有前景的途径，尤其在前列腺癌和膀胱癌的生存预测中。此框架具有广泛应用潜力，尤其是在涉及异质生物医学数据的生存预测任务中。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13178", "html_url": "https://arxiv.org/abs/2509.13178", "title": "希尔伯特空间上的协方差滤波器和神经网络", "title_en": "CoVariance Filters and Neural Networks over Hilbert Spaces", "authors": "Claudio Battiloro,Andrea Cavallo,Elvin Isufi", "background": "文中有提到CoVariance Neural Networks（VNNs）通过在信号定义于有限维希尔伯特空间的实测协方差矩阵上执行图卷积，表现出鲁棒性和迁移性特性。然而，对于无限维希尔伯特空间，这些特性如何推广还知之甚少。本文旨在探讨无限维希尔伯特空间上的卷积学习框架，主要集中在协方差算子上，从理论和实际应用的角度对无限维希尔伯特空间的信号进行处理和分类问题的研究推进了该领域的了解。", "innovation": "本文提出了针对无限维希尔伯特空间信号的新颖卷积学习框架。该框架构建了hilbert协方差滤波器（HVF）和hilbert协方差网络（HVN），并证明了实测HVF可以恢复滤波信号的函数主成分分析（FPCA）。他们还展示了这种方法在合成和实际时间序列分类任务中的应用，相较于MLP和基于FPCA的方法，揭示了其鲁棒性能。", "conclusion": "通过证明HVF可以恢复信号的FPCA，作者设定了原理性的离散化过程，并证实了HVN在合成和真实世界时间序列分类任务中的优越性能，表明了HVN在信号分析和处理中的实用性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.06162", "html_url": "https://arxiv.org/abs/2509.06162", "title": "改进的近似计算模板", "title_en": "An Improved Template for Approximate Computing", "authors": "Morteza Rezaalipour,Francesco Costa,Marco Biasion,Rodrigo Otoni,George A. Constantinides,Laura Pozzi", "background": "在边缘设备上部署神经网络需要在推理所需的能量和分类准确性之间进行仔细平衡。一种处理这种折衷的技术是近似计算：通过稍微降低算术运算的准确性来减少能量消耗。为此，本文提出了一种方法来减少神经网络中使用的小型算术运算器（即加法器和乘法器）的面积，同时只在准确性上略有损失，并展示了与现有技术相比，在相同的准确度损失下，面积节省有了改进。为了达到这一目标，本文改进了一种最近提出的布尔重写技术，称为XPAT，该技术利用可参数化的模板来重写电路已被证明非常有益。特别是，XPAT能够产生比其他类似方法更小的电路，同时还采用了简单的和积模板结构。在本文中，作者表明模板参数可以作为所选度量的代理，并提出了基于可参数化产品共享的新模板，该模板对合成的面积具有接近近似的代理作用。我们通过实验表明，我们的方法更有利于接近低面积解决方案，并能够找到比原始XPAT和另外两种先进方法更好的近似值。", "innovation": "提出了改进的模板，特别是基于可参数化产品共享的新模板，该模板作为合成分割面积的近似代理，可以改善面积减少效果。该工作展示了这种改进模板在减少面积方面优于原始XPAT和其他先进技术的表现。", "conclusion": "通过实验结果表明，改进的模板方法可以使电路设计更好地接近低成本解决方案，并且能够找到比原模板和其他先进方法更好的近似值。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.14837", "html_url": "https://arxiv.org/abs/2309.14837", "title": "学习可变状态下的多模态注意力以操纵可变形物体", "title_en": "Learning Multimodal Attention for Manipulating Deformable Objects with Changing States", "authors": "Namiko Saito,Mayu Tatsumi,Ayuna Kubo,Kanata Suzuki,Hiroshi Ito,Shigeki Sugano,Tetsuya Ogata", "background": "为了在日常生活中支持人类，机器人需要自主学习、适应物体和环境，并执行适当的动作。这需要机器人能够感知物体的状态并实时调整动作，如处理加热中的鸡蛋。以往的工作发现，处理状态变化的物体是具有挑战性的，因为感官信息包含动态的、可能重要或噪声信息，每次应该关注的模态都不同，这使得难以实时实现感知和动作生成。", "innovation": "我们提出了一种带有注意机制的预测循环神经网络，能够权衡传感器输入，区分各模态的重要性和可靠性，实现快速高效地感知和动作生成。该模型通过从演示学习进行训练，使机器人能够获得类似人类的技能。", "conclusion": "我们使用机器人Dry-AIREC验证了所提出的技术，我们的学习模型能够使用未知成分烹饪鸡蛋。机器人会根据鸡蛋的状态改变搅拌的方法和方向，初始时在整个锅里搅拌，随后开始翻转和针对性区域的分割动作，而无需明确指示这些动作。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.12497", "html_url": "https://arxiv.org/abs/2509.12497", "title": "零样本时间序列基础模型对功能性磁共振成像和合成信号的预测和因果性", "title_en": "Prediction and Causality of functional MRI and synthetic signal using a Zero-Shot Time-Series Foundation Model", "authors": "Alessandro Crimi,Andrea Brovelli", "background": "时间序列预测和因果发现是神经科学研究的核心内容，这有助于推测脑活动并识别神经群体和回路之间的因果关系，这对于理解认知机制和疾病具有重要意义。随着基础模型的兴起，一个关键问题是如何将这些模型与传统方法在脑信号预测和因果分析方面的性能进行比较，尤其是在零样本设置下的应用。本文评价了基础模型在检测自发脑活动方向性相互作用方面的性能，自发脑活动使用功能性磁共振成像（fMRI）在人类中测量。传统方法通常依赖于Wiener-Granger因果性，本文检验了基础模型在零样本和微调设置下的预测能力，并通过与标准Granger因果性比较模型的Granger-like估计来评估因果关系。", "innovation": "将基础模型应用于自发脑活动的预测和因果关系检测，并通过零样本设置验证其性能。基础模型在零样本预测fMRI时序方面表现出色，且能够更精确地检测因果相互作用。", "conclusion": "研究结果表明，基础模型具有灵活性、零样本性能高，并且在时间序列数据的预测和因果发现方面具有潜在的应用价值。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13211", "html_url": "https://arxiv.org/abs/2509.13211", "title": "HAM：用于可扩展连续学习的分层适配器合并", "title_en": "HAM: Hierarchical Adapter Merging for Scalable Continual Learning", "authors": "Eric Nuertey Coleman,Luigi Quarantiello,Samrat Mukherjee,Julio Hurtado,Vincenzo Lomonaco", "background": "连续学习是人类认知的一个基本能力，但对当前的深度学习模型构成了重大挑战。主要问题是新知识会干扰先前学习的信息，导致模型遗忘早期知识而倾向于新知识点，这种现象被称为灾难性遗忘。尽管大规模预训练模型可以通过利用其已有的知识和过参数化部分地缓解遗忘，但在面对新的数据分布时仍会遇到困难。参数高效微调（PEFT）方法，例如LoRA，能够有效适应新的知识，但它们在动态学习场景和长序列任务上的扩展仍然面临挑战。因为每项任务都需要维护一个适配器，这会增加复杂性和干扰的可能性。", "innovation": "本文提出了一种新的框架——层次适配器合并（HAM），它在训练过程中动态地将不同任务的适配器合并在一起。这种方法使HAM能够有效地扩展，使其比竞争基准更容易管理更多的任务，同时提高效率。HAM维持一组固定的群体，并根据不同适配器的相似性动态地分组任务。每个组内，适配器会进行修剪、缩放和合并，从而在相关任务之间实现知识迁移。通过在三个视觉基准上的实验，结果显示HAM在处理更多任务时显著优于当前最先进的方法。", "conclusion": "通过在三个视觉基准上的实验，HAM在处理更多任务时显著优于当前最先进的方法，证明了其在大规模连续学习任务上的有效性和适用性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.11915", "html_url": "https://arxiv.org/abs/2408.11915", "title": "Video-Foley: 通过时间事件条件实现两阶段视频转声音生成", "title_en": "Video-Foley: Two-Stage Video-To-Sound Generation via Temporal Event Condition For Foley Sound", "authors": "Junwon Lee,Jaekwon Im,Dabin Kim,Juhan Nam", "background": "多媒体生产中声音合成对于提升用户体验至关重要，需要同步音频和视频的时序和语义。通过视频生成声音的自动化过程面临巨大挑战，现有系统缺乏显式的时间特征导致对齐和可控性差，而基于时间戳的模型则需要昂贵且主观的人工注释。", "innovation": "提出了一个名为Video-Foley的两阶段视频转声音系统，该系统使用均方根（RMS）作为直观条件，并结合语义音色提示（音频或文本）。系统中引入了RMS离散化和RMS-ControlNet等新颖思想，以预训练的文本转音频模型为支撑。研究表明，Video-Foley在声画同步、声音时序、强度、音色和细微差别等方面取得了最先进的性能。", "conclusion": "Video-Foley系统实现了良好的声画对齐和声音时序、强度、音色及细微差别的可控性，源代码、模型权重和演示可以在配套网站上获取。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.19988", "html_url": "https://arxiv.org/abs/2405.19988", "title": "Video-Language Critic: 跨模态奖励函数用于条件语言机器人技术", "title_en": "Video-Language Critic: Transferable Reward Functions for Language-Conditioned Robotics", "authors": "Minttu Alakuijala,Reginald McLean,Isaac Woungang,Nariman Farsad,Samuel Kaski,Pekka Marttinen,Kai Yuan", "background": "自然语言是人类为机器人指定任务最容易和最方便的方式。然而，将语言与机器人行为对接通常需要大量的多样化的、带有语言标注的演示，而这些演示往往是在每个目标机器人上单独收集的，这通常是不现实的。为此，本文旨在分离“目标是什么”与“如何实现”这两个问题，前者可以从大量的外部观察数据中受益，后者则依赖特定的机器人物理特性。", "innovation": "提出了一种名为Video-Language Critic的奖励模型，它可以利用对比学习和基于时间的排序目标进行训练，实现用通用的多机器人数据训练。进而，该奖励模型可用于评估从不同行为轨迹，实现了在Meta-World任务上，相较于仅使用稀疏奖励，更加样本高效地训练策略。此外，在领域内数据进行挑战性任务泛化时，其样本效率也优于以往的语言条件奖励模型。", "conclusion": "与以往的语言条件奖励模型相比， Video-Language Critic在跨机器人身体数据下训练，不仅提高了在Meta-World任务上的策略学习效率，还能够利用视频中的时间信息进行更好的任务泛化。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.10970", "html_url": "https://arxiv.org/abs/2509.10970", "title": "人造心理的机器：大型语言模型中的AI心理、妄想强化及有害性增强模拟", "title_en": "The Psychogenic Machine: Simulating AI Psychosis, Delusion Reinforcement and Harm Enablement in Large Language Models", "authors": "Joshua Au Yeung,Jacopo Dalmasso,Luca Foschini,Richard JB Dobson,Zeljko Kraljevic", "background": "随着‘AI妄想’的案例不断增多，用户与LLM的交互可能会加剧或诱发妄想或其他不良心理症状。尽管LLM表现出顺从和友善的特质，但在某些情况下，这种特性反而可能成为一种伤害的途径，通过强化用户已经存在的妄想信念，特别是在脆弱的用户中。为了解决这个问题，研究者开发了Psychosis-bench，一个新型基准，旨在系统性地评估LLM的‘致妄想性’，包含16个结构化的12轮对话场景，模拟了不同的妄想主题（如性妄想、自大/救世主妄想、参考妄想）的进展，并且评估了不同场景下模型的表现，涵盖了显性和隐性的对话背景。研究结果表明，所有模型都存在‘致妄想’的潜在风险，模型在确认妄想、增加危害和提供安全干预方面表现不佳，特别是在隐性对话情境中，问题更为严重。研究表明，模型性能差异较大，表明安全保障性并非简单的规模扩大即可获得的特点。", "innovation": "提出了Psychosis-bench，一个新型基准，用于系统性地评估大型语言模型的‘致妄想性’。该基准包含16个结构化的12轮对话场景，模拟了各种妄想主题的进展，并且评估了八种主要的大型语言模型在确认妄想、增加危害和提供安全干预方面的表现。创新之处在于首次全面评估了LLM在多种妄想主题下的行为，并且结果揭示了隐性情境下模型表现明显恶化的问题，强调了LLM的安全保障特性的复杂性，不仅仅是规模的作用。", "conclusion": "研究证实了大型语言模型的‘致妄想性’是一个量化风险，并强调需要重新思考如何培训大型语言模型的紧迫性。研究者认为这个问题不仅仅是技术挑战，而是公共健康的重要性，需要开发者、政策制定者和医疗专业人员的合作来应对。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.17432", "html_url": "https://arxiv.org/abs/2408.17432", "title": "基于低复杂度离散单元帧选择的未见说话人语音合成", "title_en": "Text-to-Speech for Unseen Speakers via Low-Complexity Discrete Unit-Based Frame Selection", "authors": "Ismail Rasim Ulgen,Shreeram Suresh Chandra,Junchen Lu,Berrak Sisman", "background": "在多说话人文本到语音（TTS）中，合成未见说话人的声音仍然是一个持续存在的挑战。现有方法通过训练中的说话人条件来建模说话人特性，这导致了模型复杂度的增加，并限制了研究的重现性和可访问性。在计算和数据资源有限的情况下，低复杂度的替代方法将会扩大语音合成研究的范围。", "innovation": "提出了一种名为SelectTTS的简单且有效的替代方法。SelectTTS通过帧级自我监督学习（SSL）特征选择目标说话人的适当帧进行解码，可以有效捕捉未见说话人的说话人特征，并且在客观和主观度量上达到与最先进的多说话人TTS框架相当的性能。通过直接选择目标说话人的声音帧，SelectTTS在显著降低模型复杂度的同时实现了观点的泛化。", "conclusion": "实验结果表明，提出的框架在性能上与最新系统XTTS-v2和VALL-E相当，但所需参数少于8倍，训练数据少于270倍。此外，结果表明使用SSL特征进行帧选择是一种实现低复杂度、高质量多说话人TTS的有效途径。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.13541", "html_url": "https://arxiv.org/abs/2405.13541", "title": "通过多样化和代表性回应文本实现高效的语言模型对齐", "title_en": "Annotation-Efficient Language Model Alignment via Diverse and Representative Response Texts", "authors": "Yuu Jinnai,Ukyo Honda", "background": "偏好优化是将大型语言模型调整到符合人类偏好的一种标准方法。偏好数据集的数量、多样性和代表性对偏好优化的有效性至关重要。然而，在许多应用场景中，获取大量偏好注释非常困难。这提出了一个问题，即如何在有限的注释预算下创建一个有效的偏好数据集。现有方法通常是逐一标注所有可用响应文本的偏好，这样会导致资源浪费。因此，需要一种新的方法来更有效地利用有限的标注预算，使得偏好标注更加高效和效果更好。", "innovation": "提出了一种名为Annotation-Efficient Preference Optimization (AEPO)的新方法。AEPO 方法是从所有可用的响应文本中选择一个最大化多样性和代表性的子集，并仅对这些选定的响应进行偏好标注。这样可以将标注预算集中在更小但更具信息性的响应子集上。实验结果表明，使用AEPO 方法在相同标注预算下优于现有基线方法。", "conclusion": "通过AEPO方法，在有限的标注预算下，可以获得更具代表性和多样性的偏好数据集，从而提高了偏好优化的效果。该方法已经在三个数据集上进行了性能评估，结果表明这种新的方法能够实现更好的效果。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.01544", "html_url": "https://arxiv.org/abs/2411.01544", "title": "构建自我增强循环：目标导向的语义通信中的错误检测与纠正", "title_en": "Building the Self-Improvement Loop: Error Detection and Correction in Goal-Oriented Semantic Communications", "authors": "Peizheng Li,Xinyi Lin,Adnan Aijaz", "background": "现代通信系统在复杂传输环境中需要稳定的运行，错误检测和纠正至关重要。然而，这些讨论在关注传递意义而非符号的语义通信（SemCom）中被忽视，导致系统效率显著提高。尽管如此，语义错误（由于传输和接收意义之间的差异）对系统可靠性构成了重大挑战。", "innovation": "本文提出了一个综合框架，用于检测和纠正SemCom系统中的语义错误。通过正式定义语义错误、检测和纠正机制，识别关键的语义错误源。提出了基于高斯过程的方法来实现潜在空间监控，以及结合用户反馈的人为在环增强学习方法来优化语义模型配置。", "conclusion": "实验结果验证了所提出的方法在各种条件下有效防止语义错误，包括对抗性攻击、输入特征变化、物理信道变化和用户偏好改变。本研究为更可靠和自适应的SemCom系统奠定了基础，具有强大的语义错误管理技术。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.19794", "html_url": "https://arxiv.org/abs/2410.19794", "title": "DiffGAN：一种用于图像分析深度神经网络差异测试的测试生成方法", "title_en": "DiffGAN: A Test Generation Approach for Differential Testing of Deep Neural Networks for Image Analysis", "authors": "Zohreh Aghababaeyan,Manel Abdellatif,Lionel Briand,Ramesh S", "background": "深神经网络（DNNs）在各种应用中越来越广泛部署。然而，确保其可靠性仍然是一个挑战，而且在许多情况下，可供选择的功能和准确性相似的替代模型存在。传统的基于准确性的评估方法往往无法捕捉模型之间的行为差异，尤其是在测试数据集有限的情况下，这使得有效的模型选择或组合变得更加困难。差异测试通过生成暴露模型行为差异的测试输入来解决这一问题，但现有的方法存在显著的局限性：许多方法依赖于模型内部结构，或者受可用种子输入的限制。", "innovation": "本文提出了一种名为DiffGAN的黑盒测试图像生成方法，用于DNN模型的差异测试。DiffGAN利用生成对抗网络（GAN）和非支配排序遗传算法II（NSGA-II）生成多样且有效的触发输入，这些输入可以揭示模型之间的行为差异。DiffGAN采用了两个自定义适应度函数，重点在于多样性和发散性，以引导GAN输入空间的探索并识别模型输出之间的差异。通过战略性地搜索此空间，DiffGAN生成具有特定特征的输入，这些输入能够触发模型行为的差异。DiffGAN是一种黑盒方法，使其在更多场景中适用。实验结果表明，DiffGAN显著优于最先进的基线方法，在相同的预算内生成四倍于触发输入，且具有更高的多样性和有效性。此外，生成的输入还提高了基于输入特征的机器学习模型选择机制的准确性，该机制可以根据输入特征选择性能最佳的模型，当使用替代模型时，可以作为智能输出投票机制。", "conclusion": "本文提出了DiffGAN，一种用于DNN模型差异测试的黑盒测试图像生成方法。DiffGAN采用生成对抗网络和适应度函数策略，生成能够揭示模型行为差异的输入。实验结果表明，DiffGAN在生成触发输入的数量、多样性和有效性方面表现优异，且在机器学习模型选择机制中提高了准确性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.00132", "html_url": "https://arxiv.org/abs/2504.00132", "title": "Contextualize-then-Aggregate：Gemma-2 2B中In-Context Learning的电路", "title_en": "Contextualize-then-Aggregate: Circuits for In-Context Learning in Gemma-2 2B", "authors": "Aleksandra Bakalova,Yana Veitsman,Xinting Huang,Michael Hahn", "background": "大型语言模型（LLMs）具备在上下文条件下学习（In-Context Learning，ICL）的能力。尽管关于这种能力的行为层面及其在小型设置中出现机制的研究工作较多，但我们仍不清楚模型是如何从少量示例提示中整合任务信息的。这项研究通过因果干预分析了Gemma-2 2B在五种自然场景下的ICL任务中的信息流动。", "innovation": "研究发现模型使用了一种两步策略——‘先上下文化然后聚合’来推断任务信息。首先，在较低层，模型构建单个少量示例的表示，这些表示通过序列中前后输入输出词汇之间的连接被上下文化。随后，在较高层，这些表示被聚合以识别任务并准备预测下一个输出。该策略的重要性在不同任务间有所不同，并且在存在歧义示例时可能变得更重要。", "conclusion": "通过提供严格因果分析，该研究揭示了ICL在语言模型中发生的机制。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.01153", "html_url": "https://arxiv.org/abs/2504.01153", "title": "当您搜索时抓到我：上下文网络搜索结果如何影响幻觉的检测", "title_en": "Catch Me if You Search: When Contextual Web Search Results Affect the Detection of Hallucinations", "authors": "Mahjabin Nahar,Eun-Ju Lee,Jin Won Park,Dongwon Lee", "background": "随着我们越来越多地依赖大型语言模型（LLMs）完成各种任务，这些模型有时会产生不准确的内容或“幻觉”，这可能产生严重后果。最近，将网络搜索结果集成到LLMs中引发了人们利用网络搜索结果来验证生成内容准确性的兴趣，以准确检测幻觉。本研究探讨了提供静态或动态（参与者自行进行搜索的结果）搜索结果如何影响参与者对LLM生成内容准确性的感知、对自己准确评估的信心以及对LLM的整体评价。", "innovation": "本研究是通过在线实验（N=560）来探讨提供静态和动态搜索结果对LLM生成内容的准确性和参与者自我评估信心的影响，并比较了这些影响与无搜索结果控制条件的差异。", "conclusion": "研究发现，无论是静态还是动态条件，参与者都对带有幻觉的内容评价较低，且对LLM的评价更负面。但在动态条件下，参与者对真实内容评价较高，并且在整体评估中拥有更高的自信水平。研究强调了将网络搜索功能集成到LLMs中的实际意义。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.21419", "html_url": "https://arxiv.org/abs/2410.21419", "title": "高维高斯过程回归中的Soft Kernel Interpolation", "title_en": "High-Dimensional Gaussian Process Regression with Soft Kernel Interpolation", "authors": "Chris Camaño,Daniel Huang", "background": "高维数据集上实现高斯过程（GP）回归存在尺度性挑战，传统的结构核插值方法（SKI）和变分约简点方法虽然在某些方面有效，但存在维度扩展带来的问题。需要一种新的方法来克服这些挑战并保持灵活适应数据。", "innovation": "作者提出了一种名为Soft Kernel Interpolation（SoftKI）的方法，它结合了结构核插值（SKI）和变分近似诱导点方法的优点，通过软化插值从更小数量的插值点中逼近核函数，可以优化SoftKI边缘对数似然（MLL）并在需要时使用近似MLL提高数值稳定性，从而解决维度扩展带来的挑战同时保持变分方法的灵活性。", "conclusion": "SoftKI在各种示例中表现有效，并在较低维度（约10）时与其它近似GP方法竞争。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.18216", "html_url": "https://arxiv.org/abs/2411.18216", "title": "评估和提高由大语言模型生成的安全攻击检测器的鲁棒性", "title_en": "Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs", "authors": "Samuele Pasini,Jinhan Kim,Tommaso Aiello,Rocio Cabrera Lozoya,Antonino Sabetta,Paolo Tonella", "background": "大语言模型（LLMs）在软件开发中逐渐被用于生成函数，例如攻击探测器，以实现安全需求。关键挑战是确保这些模型有足够的知识来解决特定的安全需求，例如现有的攻击信息。本文通过将检索增强生成（RAG）和自我排名技术集成到LLM的工作流程中来解决这一挑战。该方法通过引入外部知识源增强输出的稳健性，并通过自我一致性概念启发自我排名技术，生成多个推理路径并创建排名以选择最稳健的检测器。实证研究针对由LLM生成的代码进行，专注于检测网络安全性中的两种常见注入攻击：跨站脚本（XSS）和SQL注入（SQLi）", "innovation": "提出了一种结合检索增强生成（RAG）和自我排名的技术来提高由大语言模型生成的安全攻击检测器的鲁棒性。RAG通过引入外部知识源增强了输出的稳健性，而自我排名技术通过生成多个推理路径并基于排名选择最稳健的检测器，进一步提高生成探测器的性能和可靠性", "conclusion": "实证研究结果表明，在使用RAG和自我排名技术后，生成的探测器在检测XSS和SQLi方面的性能有显著改进，F2-分数分别提高了71%（平均提高37%）和43%（平均提高6%）"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.13456", "html_url": "https://arxiv.org/abs/2410.13456", "title": "解锁瑞士法律知识：多语言司法摘要数据集", "title_en": "Unlocking Legal Knowledge: A Multilingual Dataset for Judicial Summarization in Switzerland", "authors": "Luca Rolshoven,Vishvaksenan Rasiah,Srinanda Brügger Bose,Sarah Hostettler,Lara Burkhalter,Matthias Stürmer,Joel Niklaus", "background": "法律研究是一项耗时的任务，大多数律师每天都要面对。其中一部分工作涉及查找相关判例并将其与当前案件相关联。律师们依赖于摘要（称为头注）来快速找到合适的案例。然而，并非所有决定都附有头注，编写它们非常耗时。自动化头注生成可能使瑞士甚至全球范围内数以十万计的决定更加便于法律研究。为此，我们提出了瑞士领先决策摘要（SLDS）数据集，这是一个多语言资源，包含来自瑞士联邦最高法院的18,000份法院判决书，以及德语头注，这些判决书用德语、法语和意大利语撰写。我们微调并评估了三种mT5变体以及专有模型。研究表明，尽管专有模型在零样本和单样本设置中表现良好，但微调的较小模型仍然具有很强的竞争力。我们向公众发布了该数据集，以促进多语言法律摘要研究，以及法律专业人士的支持性技术的发展", "innovation": "提出了名为瑞士领先决策摘要（SLDS）的数据集，该数据集包含18,000份用德语、法语和意大利语撰写的瑞士联邦最高法院判决书，以及德语头注。微调和评估了三种mT5变体以及专有模型。研究表明，虽然专有模型在零样本和单样本设置中表现良好，但微调的较小模型仍然具有很强的竞争力。我们向公众发布了这一数据集，以促进多语言法律摘要研究和辅助技术的发展", "conclusion": "我们提出了瑞士领先决策摘要数据集，促进了多语言法律摘要研究，并帮助开发了法律专业人士的支持性技术。微调的较小模型在某些情况下仍然具有很强的竞争力。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.10288", "html_url": "https://arxiv.org/abs/2504.10288", "title": "Noise2Ghost: 自监督深度卷积重建用于鬼成像", "title_en": "Noise2Ghost: Self-supervised deep convolutional reconstruction for ghost imaging", "authors": "Mathieu Manni,Dmitry Karpov,K. Joost Batenburg,Sharon Shwartz,Nicola Viganò", "background": "本文介绍了一种新的自监督深度学习方法，用于鬼成像（GI）重建。该方法在无监督方法中提供了对嘈杂获取的独特重建性能。此方法提供了应对鬼成像低光照场景下信噪比问题所需工具的例子数量，包括微米和纳米尺度的X射线发射成像，如剂量敏感样本的X射线荧光成像。在这些应用中，鬼成像需要在成像过程中避免引入噪声，同时保持样本的高质量成像，特别是在生物样本和电池的在体、原位案例研究中，面临信噪比的挑战更为敏锐。", "innovation": "该方法通过自监督学习消除了清洁参考数据的需求，同时提供强大的噪声减少能力。凭借这一技术，可以在明显的低光照场景下进行鬼成像而不受噪声的影响，如微纳尺度的X射线荧光成像等。这种方法改善了鬼成像技术的实际应用前景，在医学和能源领域尤为重要。", "conclusion": "该方法为在低信噪比情况下进行高质量鬼成像提供了必要的工具和技术支持，尤其在生物样本和电池等敏感样本的原位和在体成像中具有重要意义，极大地推动了鬼成像技术在新兴和前沿低光场景中的应用。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.08698", "html_url": "https://arxiv.org/abs/2505.08698", "title": "通过带有连续葡萄糖监测数据应用的神经ODE学习概率分布的连续时间学习", "title_en": "Continuous Temporal Learning of Probability Distributions via Neural ODEs with Applications in Continuous Glucose Monitoring Data", "authors": "Antonio Álvarez-López,Marcos Matabuena", "background": "时间依赖数据样本上概率分布动力学建模是许多领域，包括数字健康中的一个基础问题。目标是分析生物标志物（如血糖）分布随时间的变化，以及这些变化如何反映慢性疾病（如糖尿病）的进展。", "innovation": "提出了一种基于高斯混合模型的概率模型，能够捕捉连续时间随机过程的发展。该方法结合了最大均值偏差（MMD）得到的非参数分布估计和由神经常微分方程（Neural ODE）治理的混合权重的时间演变。该模型具有很高的可解释性，能够检测细微的分布变化，并且计算效率高。", "conclusion": "在26周的临床试验中，这种方法能够将所有连续葡萄糖监测（CGM）时间序列作为主要结果。它使得对照组和治疗组之间进行严谨的时间纵向比较成为可能，并提供了一些传统的基于汇总的临床试验分析方法无法实现的特征描述。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.16404", "html_url": "https://arxiv.org/abs/2504.16404", "title": "基于直接视频的时空深度学习技术在牛蹄病检测中的应用", "title_en": "Direct Video-Based Spatiotemporal Deep Learning for Cattle Lameness Detection", "authors": "Md Fahimuzzman Sohan,Raid Alzubi,Hadeel Alzoubi,Eid Albalawi,A. H. Abdul Hafez", "background": "牲畜蹄部疾病是一个常见的健康问题，通常由蹄部损伤或感染引起，严重影响动物福利和生产力。早期和准确的检测对于减小经济损失和确保适当的治疗至关重要。本研究提出了一种时空深度学习框架，利用公共视频数据自动化检测牛蹄病。", "innovation": "本研究展示了直接基于视频的时空深度学习方法，在牛蹄病检测中无需传统的多阶段管道，包括目标检测和姿态估计。研究对比了3D卷积神经网络（3D CNN）和卷积长短期记忆（ConvLSTM2D）模型，3D CNN在视频级别的分类准确度达到90%，与最佳端到端前方法C3D-ConvLSTM（90.3%）相比，具有可比的准确性和更简单的模型结构。", "conclusion": "研究结果表明，深度学习模型可以从各种视频来源中成功提取和学习时空特征，实现农场实际环境中的牛蹄病自动化检测。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.07445", "html_url": "https://arxiv.org/abs/2502.07445", "title": "忘记你所知道的LLMs评估——LLMs就像变色龙", "title_en": "Forget What You Know about LLMs Evaluations -- LLMs are Like a Chameleon", "authors": "Nurit Cohen-Inger,Yehonatan Elisha,Bracha Shapira,Lior Rokach,Seffi Cohen", "background": "大型语言模型（LLMs）在公开基准测试中往往表现出色，但由于它们过度依赖于特定数据集的表面特征，因此可能无法真正理解语言，这意味着它们的高得分可能掩盖了这一点。本文探讨了这一问题，并提出了Chameleon Benchmark Overfit Detector（C-BOD）这一元评价框架，用于系统地篡改基准测试提示并检测LLMs的过拟合。", "innovation": "该研究提出了C-BOD框架，通过参数化变换系统性地篡改基准提示，同时保持其语义内容和标签，这种方法能够揭示模型性能是否依赖于记忆模式。研究通过26个领先LLM在MMLU基准上的表现，证明了这种方法能够在轻微干扰下揭示20个模型的统计显著性差异，并且结果显示大型模型更敏感于重述，这表明它们可能也过度依赖固定提示模式。", "conclusion": "该研究通过C-BOD揭示了在轻微变化下的LLM表现显著下降，并指出基准化评估应超越排行榜得分，强调环顾和泛化能力在LLM评估中的重要性。此外，C-BOD的通用设计易于整合到训练管道中，以促进更稳健的语言理解。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.07005", "html_url": "https://arxiv.org/abs/2501.07005", "title": "使用扩散模型和间接法在圆限制三体问题中寻找最优低推力航天器轨道全局搜索", "title_en": "Global Search for Optimal Low Thrust Spacecraft Trajectories using Diffusion Models and the Indirect Method", "authors": "Jannik Graebner,Ryne Beeson", "background": "长时间低推力非线性最优航天器轨道全局搜索问题是一个计算量和时间成本高的问题，具有局部最优解聚集模式。在初步任务设计中，任务参数会频繁变化，需要轨迹设计师高效生成高质量的控制方案。生成式机器学习模型可以训练以学习解决方案结构随着条件参数的变化方式，从而加速具有更新参数的任务的全局搜索。在这个工作中，最先进的扩散模型与轨迹优化中的间接方法结合，在全局搜索框架中进行了集成。该框架在圆限制三体问题中的两种不同复杂性低推力转移中进行了测试。通过生成和分析训练数据集，建立了理解这些问题的局部最优解的成本状态域中复杂结构的数学关系和技术。一个扩散模型在这个数据上进行了训练，并成功地加速了两个问题的全局搜索。该模型根据最大航天器推力大小预测了成本状态解结构的变化。用来自扩散模型样本开始数值解器在初始时间增加了与来自均匀分布和伴随控制变换的样本相比，具有未见推力大小的问题每分钟生成的解的数量，一个到两个数量级的增加。", "innovation": "将最先进的扩散模型与轨迹优化中的间接方法结合，在全局搜索框架中进行集成，并提出了一种方法来理解局部最优解在成本状态域中的复杂结构，从而加速了具有更新参数的任务的全局搜索过程。通过预测成本状态解结构的变化而提高了数值解器在初始时间的解的生成数量。", "conclusion": "通过使用扩散模型和间接法的结合框架，在不同复杂性的低推力转移中成功加速了全局搜索过程。这种方法为具有更新任务参数的轨迹设计提供了更快、更有效的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2311.07550", "html_url": "https://arxiv.org/abs/2311.07550", "title": "Tabular数据上的Transformer模型后门攻击：一项实证研究", "title_en": "Backdoor Attacks on Transformers for Tabular Data: An Empirical Study", "authors": "Bart Pleiter,Behrad Tajalli,Stefanos Koffas,Gorka Abad,Jing Xu,Martha Larson,Stjepan Picek", "background": "深度神经网络（DNNs）已在多个领域展现出巨大的潜力，但与DNN训练相关的脆弱性，如后门攻击，是一个重要问题。这些攻击通常涉及在模型训练过程中偷偷插入触发器，以此操控预测结果。近年来，随著变压器模型的兴起，使用表格式数据的DNNs受到越来越多的关注。本文对使用DNNs处理表格式数据时的后门攻击进行了全面分析，主要聚焦于变压器。", "innovation": "本文提出了一种新的触发器构造方法：在界内攻击（In-bounds attack），该方法在攻击性能和隐蔽性之间取得了很好的平衡。此外，研究发现基于变压器的DNNs在表格式数据上的后门攻击非常脆弱，即使微小特征值变化也能成功进行攻击。实验还证实这些攻击可以推广到其他模型，比如XGBoost和DeepFM。研究成果显示，即使干净准确性几乎没有下降，后门攻击的成功率最高可达100%。此外，还评估了几种防御措施，发现光谱签名是最有效的。", "conclusion": "基于变压器的DNNs对表格式数据的后门攻击非常脆弱，即使是微小特征值改变也能成功进行攻击。攻击可以推广到其他模型。光谱签名在防御后门攻击方面是最有效的。但研究还指出需要开发针对表格式数据的特定防御措施以对抗这些后门攻击。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23759", "html_url": "https://arxiv.org/abs/2505.23759", "title": "当视觉语言模型无法领会提示时：被谜题所困惑", "title_en": "Puzzled by Puzzles: When Vision-Language Models Can't Take a Hint", "authors": "Heekyung Lee,Jiaxin Ge,Tsung-Han Wu,Minwoo Kang,Trevor Darrell,David M. Chan", "background": "提出现有的视觉语言模型（VLMs）在解谜题时面临独特挑战。与其他传统任务（如图像描述或问答）不同，解谜需要理解多模态抽象、符号推理以及掌握文化、音韵和语言的双关语。", "innovation": "通过创建一个手工制作和注释的多元英语谜题基准数据集，涵盖从简单的象形文字替代到空间依赖线索（如“头”在“脚”之上）。该研究分析了不同类型VLMs在解谜时的表现。", "conclusion": "尽管VLMs在解码简单视觉线索方面表现出一些惊人的能力，但在需要抽象推理、横向思维和理解视觉比喻的任务中表现出显著困难。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.17827", "html_url": "https://arxiv.org/abs/2504.17827", "title": "进化与扩散相遇：高效神经网络架构生成", "title_en": "Evolution Meets Diffusion: Efficient Neural Architecture Generation", "authors": "Bingye Zhou,Caiyang Yu", "background": "神经架构搜索（NAS）因其在深度学习模型设计中的革命潜力而受到广泛关注。然而，NAS巨大的搜索空间导致了显著的计算和时间成本。为解决这一问题，神经架构生成（NAG）将NAS重新定义为生成问题，可以精确生成特定任务的最优架构。尽管前景广阔，主流方法如扩散模型在全局搜索能力方面存在局限，并且仍然受到高计算和时间成本的限制。", "innovation": "我们提出了一种名为进化扩散基于神经架构生成（EDNAG）的新型方法，实现了高效的无训练架构生成。EDNAG利用进化算法模拟扩散模型中的去噪过程，通过适应度引导从随机高斯分布到最优架构分布的过渡。这种方法结合了进化策略和扩散模型的优点，能够快速有效地生成架构。实验表明，EDNAG在架构优化方面达到了最先进的表现（SOTA），准确率提高了高达10.45%。此外，它还消除了耗时的训练需求，并将推理速度提高了平均50倍，展示了其卓越的高效性和效果。", "conclusion": "EDNAG通过整合进化策略和扩散模型，能够高效生成优化的神经架构，显著提高了架构优化的准确性和生成速度。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23804", "html_url": "https://arxiv.org/abs/2505.23804", "title": "通过利用子句频率校准LLMs进行Text-to-SQL解析", "title_en": "Calibrating LLMs for Text-to-SQL Parsing by Leveraging Sub-clause Frequencies", "authors": "Terrance Liu,Shuyi Wang,Daniel Preotiuc-Pietro,Yash Chandarana,Chirag Gupta", "background": "大规模语言模型（LLMs）在文本到SQL查询转换方面表现强大，但在处理某些任务时可能会表现出自信但错误的失败。因此，建立可信的文本到SQL系统需要从LLM中提取可靠的不确定性度量。本文研究了提供一个校准的置信度分数的问题，该分数传达了输出查询正确性的可能性。", "innovation": "本文是第一个为此问题建立基准的工作。研究显示，经典的校准方法Platt scaling相较于直接使用原始模型输出概率作为置信度得分能提供显著改进。在此基础上，提出了利用SQL查询结构特性进行更细粒度正确性信号的“子句频率”（SCF）分数的方法，并结合多变量Platt校准（MPS）技术将单独的SCF分数合并成一个整体准确且校准的分数。", "conclusion": "在两个流行文本到SQL数据集上的实证评估表明，结合MPS和SCF的方法在校准和相关错误检测任务中比传统Platt校准提供了进一步的改进。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22149", "html_url": "https://arxiv.org/abs/2507.22149", "title": "当在欺骗性指令下诚信表示翻转时？", "title_en": "When Truthful Representations Flip Under Deceptive Instructions?", "authors": "Xianxuan Long,Yao Fu,Runchao Li,Mu Sheng,Haotian Yu,Xiaotian Han,Pan Li", "background": "大型语言模型（LLMs）倾向于在恶意构造的指令下生成误导性响应，带来了安全挑战。尽管在输出分析方面有所进展，但这些模型在面对误导性指令时，其内部表示如何从真实转变为误导性表示，仍然知之甚少。", "innovation": "本研究通过分析Llama-3.1-8B-Instruct和Gemma-2-9B-Instruct模型在事实验证任务中的内部表示，发现模型基于内部表示的指令人/否输出在所有条件下均可预知。此外，研究使用稀疏编码器（SAEs）展示出，欺骗性指令导致显著的表示变化，且这些变化集中在早期到中期的网络层，并且即使在复杂数据集上也能检测到。研究还确定了对欺骗性指令高度敏感的稀疏编码器特征，并通过目标可视化确认了不同的真实/欺骗表示子空间。这些发现为大型语言模型检测和控制提供了新见解，特别是在指示性不诚实行为方面。", "conclusion": "分析指出了层间和特征级与指示性不诚实相关的联系，为LLM检测和控制提供了新见解。研究揭示了欺骗性的特征和层级签名，提供了检测和减轻指示性不诚实行为的新见解。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18614", "html_url": "https://arxiv.org/abs/2505.18614", "title": "MAVL: 一个用于动画歌曲翻译的多语言音频-视频歌词数据集", "title_en": "MAVL: A Multilingual Audio-Video Lyrics Dataset for Animated Song Translation", "authors": "Woohyun Cho,Youngmin Kim,Sunghyun Lee,Youngjae Yu", "background": "歌词翻译需要精确的语义转换和音乐节奏、音节结构和诗体风格的保留。在动画音乐剧中，这一挑战由于需要与视觉和听觉线索对齐而更加复杂。现有的文本仅依赖的方法无法提供更丰富、更富有表现力的翻译。", "innovation": "提出了Multilingual Audio-Video Lyrics Benchmark for Animated Song Translation（MAVL），这是一个用于可唱歌词翻译的第一个多语言、多模态基准。Syllable-Constrained Audio-Video LLM with Chain-of-Thought SylAVL-CoT，这是一种结合音频-视频线索并强制执行音节约束的模型，可以生成自然声音的歌词。", "conclusion": "实验结果表明，SylAVL-CoT 在可唱性和上下文准确性方面明显优于基于文本的模型，突显了多模态、多语言方法在歌词翻译中的价值。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13668", "html_url": "https://arxiv.org/abs/2505.13668", "title": "MAFA: 多代理框架用于标注", "title_en": "MAFA: A multi-agent framework for annotation", "authors": "Mahmood Hegazy,Aaron Rodrigues,Azzam Naeem", "background": "现代消费者银行业务需要快速准确地检索信息以应对用户查询。将用户的提问映射到最相关的常见问题（FAQ）是这些系统的关键组成部分。传统的做法通常依赖单一的模型或技术，这可能无法捕捉到多样化的用户询问的复杂性。本文提出了一种多代理框架，该框架结合了使用不同类型方法的多个专业代理和一个重新排序代理来产生最佳结果。这些代理使用受注意性推理查询（ARQs）启发的结构化推理方法，通过有针对性的任务特定JSON查询指导其进行系统化的推理步骤。该框架采用了少量几例法策略，每个代理接收不同的几例，增强代理组合的多样性和覆盖查询空间的能力。", "innovation": "本文提出了一种多代理框架，该框架结合了使用不同类型方法的多个专业代理和一个重新排序代理。这些代理使用受注意性推理查询（ARQs）启发的结构化推理方法，每个代理接收不同的少量几例，增强代理组合的多样性和覆盖查询空间的能力。与仅使用单个代理的方法相比，该框架在多个指标上显示出显著的改进，如Top-1准确性提高了14%，Top-5准确性提高了18%，平均互换秩提高了12%，并在公共基准数据集上也表现出类似的改进。该框架特别适用于处理模糊查询，显示出强大的跨领域和语言的一般化能力，适合在生产银行业务应用程序中部署。", "conclusion": "该多代理框架在实际大型银行数据集以及公共基准数据集（LCQMC和FiQA）上表现出显著的改进，显示出强大的跨领域和语言的一般化能力，特别适用于处理模糊查询，是部署在生产银行业务应用程序中的理想选择。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05170", "html_url": "https://arxiv.org/abs/2508.05170", "title": "Posterior-GRPO: 奖励代码生成中的推理过程", "title_en": "Posterior-GRPO: Rewarding Reasoning Processes in Code Generation", "authors": "Lishui Fan,Yu Zhang,Mouxiang Chen,Zhongxin Liu", "background": "强化学习（RL）在大型语言模型（LLMs）的代码生成方面取得了显著进展。然而，现有的方法主要依赖于基于测试案例的结果奖励，忽略了中间推理过程的质量。直接监督推理过程虽然是一个有希望的方向，但由于奖励劫持的问题，使得政策模型可能会学习利用推理奖励信号而未能改善最终结果。为了解决这一问题，本文提出了一种统一框架，能够有效地在RL中整合推理过程的质量。该框架首先开发了一个基准LCB-RB，包含高级和低级推理过程的偏好配对，用于推理评估。其次，提出了一种优化降级基于奖励模型训练的方法OD-based，这种方法通过系统地优化和降解初始推理路径，生成高质量的偏好配对，涵盖推理质量的维度，例如事实准确、逻辑严密和连贯性。最后，提出了一种新的RL方法Posterior-GRPO，这种方法在任务成功的基础上条件奖励过程，通过仅对成功结果的推理过程施加奖励，有效减少了奖励劫持，使模型的内部推理与最终代码正确性一致。", "innovation": "本文提出了两种创新方法：1) LCB-RB基准，用于评估推理过程的质量；2) OD-based方法，用于奖励模型训练，生成高质量的偏好配对；3) Posterior-GRPO方法，用于在任务成功的基础上条件奖励过程，有效减少奖励劫持，使模型的内部推理与最终代码正确性一致。此外，该方法展示了在数学任务中的一致性。", "conclusion": "我们提出的方法在多样性代码生成任务中表现优异，优于只有结果的基线4.5％，并达到与GPT-4-Turbo相当的性能。此外，我们进一步展示了该方法在数学任务中的通用性，模型、数据集和代码都已公开可获取。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18325", "html_url": "https://arxiv.org/abs/2505.18325", "title": "从安全决策边界透视视角理解并缓解LLMs中的过度拒绝问题", "title_en": "Understanding and Mitigating Overrefusal in LLMs from an Unveiling Perspective of Safety Decision Boundary", "authors": "Licheng Pan,Yongqi Tong,Xin Zhang,Xiaolu Zhang,Jun Zhou,Zhixuan Chu", "background": "大型语言模型（LLMs）在广泛任务中展现出了惊人的能力，但在处理合法查询时经常拒绝回答，这种现象被称为过度拒绝（overrefusal）。过度拒绝通常源于安全对齐的过度保守，导致模型将许多合理提示误判为潜在风险。深入理解这一问题对于提高模型的安全性和可用性至关重要。本文通过探究和利用模型的安全决策边界来分析并缓解过度拒绝的问题，揭示了过度拒绝与边界区域中的误对齐密切相关，模型在区分良性与有害内容的细微差别时存在困难。", "innovation": "本文提出了RASS（Risk-Aware Sensitive Selection）自动化框架，通过在表示空间中利用引导向量，RASS高效地识别并筛选出边界对齐的提示，这种策略有助于更精确和有针对性地缓解过度拒绝问题。RASS不仅提供了一个更精确和可解释的视角来理解模型的安全决策，还能够无缝适用于多语言场景。此外，作者还对多种LLMs的安全决策边界进行了探索，并构建了MORBench评估集，以支持多语言模型安全性和帮助性的稳健评估。", "conclusion": "通过RASS框架，研究发现能够更有效地识别并缓解过度拒绝问题，同时MORBench评估集的构建为多语言场景下的模型安全评估提供了支持。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.05775", "html_url": "https://arxiv.org/abs/2509.05775", "title": "基于因果推断的条件平均治疗效应估计与亚组发现的聚类方法", "title_en": "Causal Clustering for Conditional Average Treatment Effects Estimation and Subgroup Discovery", "authors": "Zilong Wang,Turgay Ayer,Shihao Yang", "background": "在个性化医疗、资源分配和政策评估等领域，准确估计异质治疗效果至关重要。主要挑战在于识别对干预措施响应不同的子人群，以便更精准地进行决策。尽管聚类方法在无监督学习中已有广泛研究，但它们与因果推断的结合仍然有限。", "innovation": "本文提出了一种新颖的框架，基于因果森林学习的核函数对个体进行聚类，以此揭示潜在的亚组结构。该方法分为两步：首先，通过Robinson分解估计去偏差的条件平均治疗效应 (CATEs)，得到编码样本层面治疗响应相似性的核矩阵；其次，应用核聚类方法发现对治疗敏感的亚群，并计算聚类级别平均CATEs。我们将这一核聚类步骤视为残差回归框架内的正则化形式。", "conclusion": "通过在半合成数据集和真实世界数据集上的广泛实验，结合消融研究和探索性分析，本文展示了该方法在捕捉有意义的治疗效果异质性方面的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14689", "html_url": "https://arxiv.org/abs/2508.14689", "title": "ECHO: 频率意识层次编码用于变长信号", "title_en": "ECHO: Frequency-aware Hierarchical Encoding for Variable-length Signals", "authors": "Yucong Zhang,Juan Liu,Ming Li", "background": "预训练基础模型已经在音频、视觉和语言等领域取得了显著的成功，然而，它们在处理任意采样率的机械信号方面的潜力，包括声学、振动以及其他工业传感器数据，尚未被充分探索。现有的研究主要集中在音频和视觉信号处理上，而机械信号的数据集通常具有变长且采样频率可变的特点，这对现有的模型提出了挑战。", "innovation": "本文提出了一种名为ECHO的新颖基础模型，该模型结合了先进的带分隔架构与频率位置嵌入，实现了对任意采样配置的频谱定位。此外，模型还采用了滑动片段（patches）来支持变长输入，无需填充或裁剪，可以生成简洁的表示，同时保留时间和频谱保真度，并自然适用于流式处理场景。ECHO模型在不同类型的机械信号数据集上进行了评估，包括先前的DCASE任务2挑战（2020-2025）以及广泛使用的工业信号语料库，实验结果表明，在机械信号异常检测和故障分类中表现出了一致的最先进性能，验证了该模型的有效性和泛化能力。", "conclusion": "ECHO模型在各种机械信号数据集上的实验结果证明了其在机械信号异常检测和故障分类中的有效性和泛化能力。ECHO具有对任意采样率和变长信号的良好处理能力，同时能够保留时间和频谱信息，并适用于实时应用场景。该模型已经开源，便于研究人员进一步探索和应用。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.08380", "html_url": "https://arxiv.org/abs/2509.08380", "title": "Co-Investigator AI: 推动智能、可信的反洗钱合规叙事的代理人工智能", "title_en": "Co-Investigator AI: The Rise of Agentic AI for Smarter, Trustworthy AML Compliance Narratives", "authors": "Prathamesh Vasudeo Naik,Naresh Kumar Dintakurthi,Zhanghao Hu,Yue Wang,Robby Qiu", "background": "反洗钱（AML）工作流程中，生成符合监管标准的可疑活动报告（SAR）仍然是一个高成本、低扩展性的瓶颈。尽管大型语言模型（LLMs）提供了一定程度的流畅性，但它们存在事实性幻觉、犯罪类型匹配有限以及解释性差的问题，这些限制在合规优先领域是不可接受的风险。", "innovation": "本文介绍了Co-Investigator AI，这是一种专门优化的代理框架，用于以比传统方法更快且更准确的方式生成可疑活动报告（SAR）。该系统借鉴了自主智能体架构的最新进展（例如AI合作者科学家），整合了用于规划、犯罪类型检测、外部情报收集和合规验证的专业智能体。系统具备动态内存管理、AI隐私守护层以处理敏感数据，并运用代理审判官 paradigm 实现实时验证，确保叙事质量的持续保障。人类调查员在整个协作工作流程中保持介入，能够审核和细化草案，结合了AI效率与领域的专业知识。", "conclusion": "Co-Investigator AI 为合规报告带来了新的时代，将AI代理的变革性益处带入核心的监管流程，铺平了可扩展、可靠和透明的可疑活动报告生成的道路。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18397", "html_url": "https://arxiv.org/abs/2508.18397", "title": "寻找长尾：自主运动规划中鲁棒离线强化学习的数据中心化关键性度量的比较研究", "title_en": "Mining the Long Tail: A Comparative Study of Data-Centric Criticality Metrics for Robust Offline Reinforcement Learning in Autonomous Motion Planning", "authors": "Antonio Guillen-Perez", "background": "离线强化学习（RL）为从大规模实际驾驶日志中训练自主车辆（AV）规划策略提供了有前景的方法。然而，这些日志中的数据严重失衡，常见的场景远多于稀有的特殊事件，使用标准均匀数据抽样的方法会导致模型对罕见事件的应对能力不足，从而带来不安全的决策。为了应对这一挑战，本文对数据采样策略进行了系统的大规模比较研究，旨在通过聚焦信息丰富的样本来优化学习过程。", "innovation": "本文研究了六种不同的关键性加权方案，分为基于启发式、不确定性及行为的三种类别，并在时间尺度（单个时间步长和完整场景）上进行了评估。本文使用先进的注意力机制架构训练了七个目标调整保守Q学习（CQL）代理，并在高保真度的Waymax仿真器中进行了评估。结果显示，所有数据采样方法都显著优于基线，尤其是基于模型不确定性进行的数据驱动采样方法，显著提高了安全性，碰撞率降低了近三分之二（从16.0%降至5.5%）。本文还明确了不同时间尺度上的加权方法之间存在的权衡关系：时间步长加权在反应安全性方面表现优异，而场景加权则有助于长期规划。", "conclusion": "本文为离线RL的数据采样提供了一个全面的框架，表明智能非均匀抽样是构建安全可靠的自主代理的关键组成部分。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03495", "html_url": "https://arxiv.org/abs/2509.03495", "title": "使用数据依赖型变量子量子电路学习AC功率流解决方案", "title_en": "Learning AC Power Flow Solutions using a Data-Dependent Variational Quantum Circuit", "authors": "Thinh Viet Le,Md Obaidur Rahman,Vassilis Kekatos", "background": "电力系统连接性研究需要解决大量的交流负载或功率流（AC PF）问题，以模拟不同的场景，随着能源转型的进行，加速此类研究的需求日益增加。近期量子计算的进步使其能够使用变量子电路（VQC）来快速找到或预测AC PF解决方案。VQC是一种可训练的模型，运行在现代噪声中间尺度量子（NISQ）硬件上，用于复杂的优化和机器学习（ML）任务。", "innovation": "该工作的主要创新包括：1. 将AC PF问题作为一个非线性最小二乘拟合问题，利用经典的量子混合计算方法求解；2. 将PF规格作为特征输入到带数据嵌入的量子电路中，训练量子ML模型以预测通用的PF解决方案；3. 发展了一种新的协议，通过利用电力网络的图结构高效测量AC-PF量子可观测量。初步数值测试表明，提出的VQC模型在权重数量远少于深度神经网络的情况下，性能更为优越。", "conclusion": "所提出的量子AC-PF框架为利用量子计算解决更复杂的电网任务奠定了基础。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.11070", "html_url": "https://arxiv.org/abs/2509.11070", "title": "基于核函数的随机逼近框架在非线性算子学习中的应用", "title_en": "A Kernel-based Stochastic Approximation Framework for Nonlinear Operator Learning", "authors": "Jia-Qi Yang,Lei Shi", "background": "该研究提供了一种用于学习无穷维空间之间非线性算子的随机逼近框架，利用一般Mercer算子值核函数。该框架包括两类关键核函数：(i) 紧核，可进行离散谱分解；(ii) 形式为 $K(x,x')=k(x,x')T$ 的对角核，其中 $k$ 为标量核函数，$T$ 是输出空间上的正算子。这一广泛设置引发了表达性的向量值核函数再生核Hilbert空间（RKHSs），并推广了经典 $K=kI$ 模型，从而允许具有严谨理论保证的丰富结构建模。为了应对位于RKHS之外的目标算子，引入了向量值内插空间以精确量化未被模型化误差。", "innovation": "该框架涵盖了广泛的算子学习任务，从广义的Fredholm算子到基于编码器-解码器架构的任务，进一步使用一般算子值核函数，从而推导出内在非线性算子学习的速率。研究还显示，非线性算子学习可克服维度 curse，同时提供维度无关的多项式收敛速率。", "conclusion": "该研究通过数值实验验证了其在二维Navier-Stokes方程上的有效性。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13535", "html_url": "https://arxiv.org/abs/2509.13535", "title": "使用大型语言模型增强崩溃报告：一项实证研究", "title_en": "Crash Report Enhancement with Large Language Models: An Empirical Study", "authors": "S M Farah Al Fahim,Md Nakhla Rafi,Zeyang Ma,Dong Jae Kim,Tse-Hsun(Peter)Chen", "background": "软件维护依赖于崩溃报告，但现有的许多崩溃报告缺乏开发人员需要的诊断细节，难以高效调试。本文探讨了大型语言模型（LLMs）如何通过添加故障位置、根本原因解释及修复建议来增强崩溃报告。", "innovation": "研究了两种增强策略：一种是一次性的Direct-LLM方法，利用堆栈跟踪上下文；另一种是迭代的Agentic-LLM方法，在源代码库中探索更多证据。在492个真实崩溃报告的数据集上测试结果显示，LLM增强后的报告在问题定位准确性上有了显著的提升，并且建议的修复代码与开发者的实际修复代码非常接近。", "conclusion": "我们的手动评估和LLM裁判测试结果显示，Agentic-LLM方法提供了更强的根本原因解释和更具体的修复建议。用户研究表明，增强后的报告使崩溃更容易理解和解决，尤其是修复建议方面得到了显著改善。这表明向LLMs提供堆栈跟踪和源代码可以生成更有用的崩溃报告，从而大大提高调试效率。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.11417", "html_url": "https://arxiv.org/abs/2509.11417", "title": "通过保留预训练表示增强Vision-Language-Action模型的泛化能力", "title_en": "Enhancing Generalization in Vision-Language-Action Models by Preserving Pretrained Representations", "authors": "Shresth Grover,Akshay Gopalkrishnan,Bo Ai,Henrik I. Christensen,Hao Su,Xuanlin Li", "background": "视觉-语言-行动(VLA)模型通过从视觉-语言模型(VLMs)中微调，有望利用丰富的预训练表示来构建跨多种任务和环境的一般性机器人。然而，直接在机器人数据上进行微调往往会破坏这些表示，限制泛化能力。相关背景强调了现有模型在泛化能力上的局限性，以及需要改进的方向。", "innovation": "本文提出了一个框架，该框架能够更好地保持预训练特征，同时适应用于机器人操作。创新点包括：(i) 双编码器设计，其中一个视觉编码器固定以保留预训练特征，另一个则可训练以适应任务。(ii) 字符串操作编码器将连续动作转换为与模型预训练领域对齐的字符序列。(iii) 结合机器人演示与强调空间推理和可利用性的视觉-语言数据集的联合训练策略。创新在于通过上述方法提升了模型对视觉扰动的鲁棒性、对新指令和环境的泛化能力以及总体任务成功率，相比于基线模型有所提升。", "conclusion": "在仿真和真实机器人上的评估结果显示，该方法在鲁棒性、新指令泛化和整体任务成功率上优于基线模型。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17600", "html_url": "https://arxiv.org/abs/2508.17600", "title": "GWM: Towards Scalable Gaussian World Models for Robotic Manipulation", "title_en": "GWM: Towards Scalable Gaussian World Models for Robotic Manipulation", "authors": "Guanxing Lu,Baoxiong Jia,Puhao Li,Yixin Chen,Ziwei Wang,Yansong Tang,Siyuan Huang", "background": "当前由于实野外交互效率低下，使用学到的世界模型进行机器人策略训练的趋势正在兴起。尽管基于图像的现有世界模型和策略取得了一定的成功，但仍缺乏能提供一致的三维空间和物理理解的鲁棒几何信息，即便是预先训练在大规模视频数据上也是如此。", "innovation": "本文提出了一种名为高斯世界模型（GWM）的新颖分支，用于机器人操控。GWM通过在机器人动作影响下推断高斯原始体的传播来重构未来状态。其核心是一个结合了三维变分自编码器的潜在扩散变换器（DiT），能够通过高斯散射进行精细的场景级别未来状态重构。GWM不仅可以提升模仿学习代理体的视觉表示，还能够作为神经模拟器以支持基于模型的强化学习。", "conclusion": "无论是模拟实验还是现实世界实验均表明，GWM能够准确预测在多样化机器人动作条件下未来场景，并能够进一步用于训练性能超过当前最先进方法的策略，展示了三维世界模型的初始数据规模潜力。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13436", "html_url": "https://arxiv.org/abs/2509.13436", "title": "关于研究软件科学是否属于元科学的探讨", "title_en": "Is Research Software Science a Metascience?", "authors": "Evan Eisinger,Michael A. Heroux", "background": "随着研究日益依赖于计算方法，科学研究结果的可靠性依赖于研究软件的质量、可重复性和透明度。研究软件科学（RSS）是指对如何开发和使用研究软件的实证研究。元科学（metascience）是研究科学自身的科学，考察科学领域的结构和方法。本文探讨了研究软件科学是否应被视为元科学的一部分，并且讨论了这一分类可能对研究软件科学的承认、资金和整合的影响。分类的重要性在于它可以影响到RSS在研究改进中的地位和认可度。元科学与研究软件科学在追求相同的目标，如可重复性、透明性和对研究过程的实证研究，在研究和开发工具方面具有交集。", "innovation": "研究软件科学有助于推进元科学的核心目标，特别是在计算再现性方面，并且可以将技术和社会认知方面的东西结合起来。元科学的分类取决于采用广泛的定义（任何旨在改进科学的实证努力）还是狭窄的定义（专注于系统及知识结构）。研究软件科学被视为一门独立的跨学科领域，并符合某些关于元科学的定义，将其分类可以加强研究软件科学在提高研究可靠性中的作用，合理地为其提供资金，并提高研究机构中软件开发的地位。", "conclusion": "研究软件科学被视为一种独立的跨学科领域，能够更好地在其改进研究可靠性、获得资金和支持以及提升研究机构中软件开发的地位方面发挥作用。无论其分类如何，对研究软件应用严格的科学方法可以确保用于发现的工具达到与发现相同的标准。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13656", "html_url": "https://arxiv.org/abs/2509.13656", "title": "为机器学习笔记本提供自动化断言生成的回归测试框架", "title_en": "A Regression Testing Framework with Automated Assertion Generation for Machine Learning Notebooks", "authors": "Yingao Elaine Yao,Vedant Nimje,Varun Viswanath,Saikat Dutta", "background": "数据科学家和机器学习工程师常用笔记本（Notebooks）进行机器学习（ML）管道的原型设计和实验。尽管笔记本提供了交互式的代码、数据和可视化界面，但它们在测试方面的支持非常有限，导致在持续开发过程中可能会出现难以察觉的细微错误，从而导致无声错误和性能下降。", "innovation": "作者提出了一种名为NBTest的回归测试框架，首次实现了在笔记本中编写单元级别的断言语，并能够在pytest或持续集成（CI）流水线中运行这样的笔记本。NBTest还开发了第一个自动化生成单元级断言的方法，用于机器学习笔记本的关键组件，如数据处理、模型构建和模型评估。此外，NBTest利用统计技术减少了断言的不确定性，同时保持了高故障检测的有效性。", "conclusion": "作者在592个Kaggle笔记本上评估了NBTest，生成了21163个断言语，并展示了该测试能够捕获Kaggle笔记本先前版本中的回归错误。用户研究结果表明，笔记本用户认为NBTest直观且有助于编写断言和测试笔记本。NBTest已被一个流行的机器学习库的CI所采用。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13650", "html_url": "https://arxiv.org/abs/2509.13650", "title": "GitHub的Copilot代码审查：AI能否在你提交之前发现安全漏洞？", "title_en": "GitHub's Copilot Code Review: Can AI Spot Security Flaws Before You Commit?", "authors": "Amena Amro,Manar H. Alalfi", "background": "随着软件开发实践中越来越多地采用AI驱动的工具，确保这些工具能够支持安全编码变得至关重要。本文评估了GitHub Copilot最近引入的代码审查功能在检测安全漏洞方面的有效性。研究人员使用了一个经过精心挑选的、带有标签的漏洞代码样本集合，这些样本来自多个编程语言和应用程序领域的多样化开源项目，系统地评估了Copilot识别和提供常见安全缺陷反馈的能力。出乎意料的是，研究结果表明，Copilot的代码审查经常无法检测出如SQL注入、跨站脚本（XSS）和不安全序列化这类关键性漏洞。相反，其反馈主要集中在低严重性问题，比如编码风格和拼写错误。这些发现揭示了AI辅助代码审查所感知的能力与其实际支持安全开发生态系统的能力之间的巨大差异。研究结果强调了继续使用专用安全工具和人工代码审核的必要性，以确保软件的安全性。", "innovation": "本文通过使用一个精心挑选的、带有标签的漏洞代码样本集合来评估GitHub Copilot代码审查功能在检测安全漏洞方面的能力。这是将AI技术应用于软件安全审查的一个尝试，但结果显示，AI工具在实际应用中并不能完全满足预期的安全审查需求。", "conclusion": "AI辅助代码审查仍然存在不足，无法有效发现关键性安全漏洞。研究人员建议继续依赖专用安全工具和人工代码审核来确保软件安全性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.17094", "html_url": "https://arxiv.org/abs/2405.17094", "title": "为稀疏组拉斯和其自适应变体进行双重特征缩减", "title_en": "Dual Feature Reduction for the Sparse-group Lasso and its Adaptive Variant", "authors": "Fabio Feser,Marina Evangelou", "background": "稀疏组拉斯（sparse-group lasso）通过结合拉斯和组拉斯的优点，同时进行变量和组选择。由于它的稀疏组惩罚罚项，这种方法在遗传学领域得到了广泛应用，尤其是在分析高维数据时。然而，稀疏组拉斯可能因增加的收缩复杂性而导致计算成本高昂，同时还需要调优额外的超参数。", "innovation": "本文提出了一种新型特征缩减方法——双重特征缩减（DFR，Dual Feature Reduction），该方法使用强筛选规则对稀疏组拉斯和自适应稀疏组拉斯进行特征缩减，从而减少优化的输入空间，而不会影响解决方案的优化性。DFR通过双重范数和子导数的应用进行两层筛选。", "conclusion": "通过合成数据和真实数据的研究，证明了DFR在多种场景下大大减少了计算成本。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13471", "html_url": "https://arxiv.org/abs/2509.13471", "title": "一种基于大语言模型的法律关键软件代理方法：以税务准备软件为例", "title_en": "An LLM Agentic Approach for Legal-Critical Software: A Case Study for Tax Prep Software", "authors": "Sina Gogani-Khiabani(University of Illinois Chicago),Ashutosh Trivedi(University of Colorado Boulder),Diptikalyan Saha(IBM Research),Saeid Tizpaz-Niari(University of Illinois Chicago)", "background": "大型语言模型（LLMs）在翻译自然语言法规为可执行逻辑方面显示出潜力，但在法律关键性较强的环境中，由于存在模糊性和幻觉，可靠性仍构成挑战。该文以美国联邦税务准备作为案例，探讨如何在没有详尽测试用例的情况下生成正确的系统输出，以解释法律并产生适当的输出。作为解决这个问题的尝试，提出了一种基于元变性能测试的高层变性能关系方法，并基于此开发了一个多代理系统，将税法转化为可执行软件，并包含了搜索反例的变性能测试代理。", "innovation": "该研究创新性地提出了一种基于大语言模型（LLMs）的代理方法，利用LLMs帮助自动生成测试用例和代码合成。通过引入高档次的变性能关系，在具有结构变化的类似个体间比较系统输出，解决了传统元变性能测试在编写这类关系上的困难。该方法在使用较小模型（GPT-4o-mini）的情况下实现最坏情况下的通过率为45%，在复杂税务法规任务上优于最前沿的模型（GPT-4o和Claude 3.5，9-15%）。", "conclusion": "该论文的结果表明，大型语言模型（LLMs）驱动的代理方法是一种可行的路径，用于从自然语言规范生成出韧性和值得信赖的法律关键软件。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13487", "html_url": "https://arxiv.org/abs/2509.13487", "title": "Prompt2DAG：基于LLM的数据增强管道生成的模块化方法", "title_en": "Prompt2DAG: A Modular Methodology for LLM-Based Data Enrichment Pipeline Generation", "authors": "Abubakari Alidu,Michele Ciavotta,Flavio DePaoli", "background": "开发可靠的数据增强管道需要大量工程专业知识。本文提出了Prompt2DAG方法，该方法能够将自然语言描述转化为可执行的Apache Airflow DAG。研究通过十四种大型语言模型和五个案例研究，评估了四种生成方法（直接、仅LLM、混合和基于模板）在260次实验中的表现，以确定生产级自动化的最佳策略。评估指标包括结合可靠性和代码质量（SAT）、结构完整性（DST）和可执行性（PCT）的惩罚评分框架。混合方法被确定为最优生成方法，成功率为78.5%，具有较高的质量评分。混合方法的表现优于仅LLM方法和直接方法。研究结果表明，可靠性和非固有代码质量是关键区别因素。成本效益分析显示，与直接提示相比，混合方法每成功生成一个DAG效率提高两倍以上。", "innovation": "开发了一种新的方法叫Prompt2DAG，它可以将自然语言描述转化为Apache Airflow任务流图（DAG），并采用混合方法实现了最佳生成效率和质量。研究通过大规模实验，对不同生成方法进行了详细的比较和评估，为生产环境中的数据管道自动化提供了一种新的方法论。", "conclusion": "混合方法对于平衡自动化工作流生成中的灵活性和可靠性至关重要，它提供了一条使数据管道开发普及化的可行途径。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13758", "html_url": "https://arxiv.org/abs/2509.13758", "title": "大型推理模型在代码生成中的思考模式研究", "title_en": "A Study on Thinking Patterns of Large Reasoning Models in Code Generation", "authors": "Kevin Halim,Sin G. Teo,Ruitao Feng,Zhenpeng Chen,Yang Gu,Chong Wang,Yang Liu", "background": "当前，许多大型语言模型（LLMs）被用于软件工程任务，如代码生成。更高级的模型大型推理模型（LRMs），如 OpenAI 的 o3、DeepSeek R1 和 Qwen3 已经出现，并展示了进行多步推理的能力。尽管LRMs有所进步，但对这些模型在代码生成中的推理模式及其影响的研究仍然较少。本研究旨在系统地分析和揭示LRMs在代码生成过程中的推理行为。", "innovation": "研究首次对该领域进行了全面分析，通过不同大小的最新LRMs进行编码任务，手工标注推理痕迹。研究提出了一个包含15种推理动作的推理行为分类体系，涵盖了四个阶段。研究结果表明：1）这些模型遵循类似人类的编码工作流程，复杂任务会引发额外操作，如支持结构、错误检测和风格检查；2）不同模型的推理方式存在差异，例如Qwen3展示迭代推理，DeepSeek-R1-7B遵循瀑布式的线性推理；3）推理与代码正确性之间存在联系，创建单位测试和支持结构生成等动作能显著支持功能结果，模型根据任务背景调整策略；4）基于这些发现，提出简化的提示策略以提升LRM生成的代码质量。", "conclusion": "本研究揭示了LRMs在代码生成中的重大发现，为自动化代码生成提供了见解和应用前景。研究表明，基于推理和上下文的提示策略能够有效提升LRMs生成代码的质量，具有重要实际应用价值。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13680", "html_url": "https://arxiv.org/abs/2509.13680", "title": "代码LLM中的提示稳定性：跨情绪和人格驱动变异的敏感性衡量", "title_en": "Prompt Stability in Code LLMs: Measuring Sensitivity across Emotion- and Personality-Driven Variations", "authors": "Wei Ma,Yixiao Yang,Jingquan Ge,Xiaofei Xie,Lingxiao Jiang", "background": "代码生成模型在软件开发中广泛使用，但它们对提示措辞的敏感性仍然未得到充分研究。相同的要求用不同的情绪或沟通风格表达时，可能会产生截然不同的输出，而现有的基准测试主要关注峰值性能。本文提出了一种名为PromptSE（提示敏感性评估）的框架，该框架通过情绪和人格模板生成语义上等价的提示变体，并使用概率感知连续评分或在logits不可用时使用二进制通过率来评估稳定性。研究结果汇总成为一种适用于跨模型比较的拟议曲线下的面积度量（AUC-E）。", "innovation": "提出了一种名为PromptSE的框架，这是一种评估代码生成模型提示敏感性的方法，通过情绪和人格模板生成语义上等价的提示变体。它使用概率感知的连续评分或二进制通过率来评估稳定性。研究结果汇总成为曲线下的面积度量（AUC-E），用以进行跨模型比较，并揭示了与架构和规模相关的模型稳健性模式。该框架可用于快速筛查封闭源代码模型以及在研究环境下进行详细稳定性分析。", "conclusion": "在14个具有三种不同家族（Llama、Qwen和DeepSeek）的模型中，研究显示性能和稳定性的优化目标在很大程度上是分离的，并揭示了与架构和规模相关的模型稳健性的模式。该框架帮助实践者量化部署和模型选择中的性能稳定性权衡，并将提示稳定性作为绩效和公平性之外的互补评估维度，从而促进更为可信的AI辅助软件开发工具的发展。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13942", "html_url": "https://arxiv.org/abs/2509.13942", "title": "在基于LLM的软件生成中评估经典软件过程模型作为协调机制的效果", "title_en": "Evaluating Classical Software Process Models as Coordination Mechanisms for LLM-Based Software Generation", "authors": "Duc Minh Ha,Phu Trac Kien,Tho Quan,Anh Nguyen-Duc", "background": "基于大型语言模型（LLM）的多智能体系统（MAS）正在软件开发中引发变革，通过促进自主协作。传统的瀑布、V模型和敏捷等软件开发生命周期过程提供了结构化的协作模式，可以重新用于指导这些智能体间的交互。", "innovation": "该研究探索了如何将传统的软件开发过程适应为协调支架以指导基于LLM的MAS，并研究了其对代码质量、成本和生产力的影响。", "conclusion": "经典软件过程可以在基于LLM的MAS中有效地实例化，但每个都会在质量、成本和灵活性之间产生权衡。过程选择应根据项目目标进行，无论是优先考虑效率、稳健性还是结构化的验证。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.13262", "html_url": "https://arxiv.org/abs/2509.13262", "title": "后验分割点自一致性验证：一种高效的综合衡量深度学习中 aleatoric 和 epistemic 不确定性的方法", "title_en": "Post-Hoc Split-Point Self-Consistency Verification for Efficient, Unified Quantification of Aleatoric and Epistemic Uncertainty in Deep Learning", "authors": "Zhizhong Zhao,Ke Chen", "background": "不确定性量化（UQ）对于确保深度学习的可靠性至关重要。目前的方法要么计算量大（如贝叶斯或集成方法），要么只能提供部分、特定任务的估计（如单次前向传播技术）。本研究旨在提出一种无需修改或重新训练预训练模型的后处理单次前向传播框架，该框架能够同时表征 aleatoric 和 epistemic 不确定性。通过 Split-Point Analysis (SPA)，该方法将预测残差分解为上、下两部分，并计算每部分的绝对残差均值。研究证明，理想情况下，总绝对残差等于子集绝对残差均值的调和平均数，这一偏差定义了一个新的自一致性差异得分（SDS），用于回归和分类任务中的细粒度 epistemic 估计。", "innovation": "提出了一种后处理单次前向传播框架，能够同时捕获 aleatoric 和 epistemic 不确定性，而无需修改或重新训练预训练模型。通过 Split-Point Analysis (SPA) 技术，该方法将预测残差分解为上、下两部分，并根据这一分解计算绝对残差均值。利用这一技术，研究提出了一种新的自一致性差异得分 (SDS)，用于细粒度估计 epistemic 不确定性。此外，通过 SDS 进行单次前向传播和侧特定分位数回归，实现预测区间的校准，以及在分类任务中利用 SPA 进行软最大化输出调整和预测熵计算。", "conclusion": "通过广泛实验在多种回归和分类基准数据集上证明，该框架能够与当前最佳的 UQ 方法匹敌，且无需显著增加计算负担。源代码已发布。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13868", "html_url": "https://arxiv.org/abs/2509.13868", "title": "Are Prompts All You Need? Evaluating Prompt-Based Large Language Models (LLM)s for Software Requirements Classification", "title_en": "Are Prompts All You Need? Evaluating Prompt-Based Large Language Models (LLM)s for Software Requirements Classification", "authors": "Manal Binkhonain,Reem Alfayaz", "background": "需求分类将自然语言需求分配到预定义的类别中，例如功能性和非功能性。准确的分类可以减少风险并提高软件质量。现有的大多数模型依赖于监督学习，需要大量复杂的、成本高昂的、创建速度慢且与领域相关标记数据；它们的泛化能力较差，通常需要为每个任务重新训练。本文测试了基于提示的大规模语言模型是否可以减少对数据的需求，并在两个英语数据集PROMISE和SecReq上对几种模型和提示风格（零样本、少量样本、角色、思考链）进行了多次任务基准测试。结果显示，基于提示的大规模语言模型，特别是在使用少量样本提示时，可以匹配甚至超越基准模型。增加角色或角色加思考链可以进一步提高性能。", "innovation": "本文创新性地提出了利用基于提示的大规模语言模型，特别是少量样本提示，对软件需求进行分类，通过实验验证了这种方法的有效性和实用性，减少对大规模标注数据的依赖并提高了任务泛化能力。", "conclusion": "基于提示的大规模语言模型是一种实际且可扩展的选择，可以减少对大量标注数据的依赖性，并能跨任务提高泛化能力。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13852", "html_url": "https://arxiv.org/abs/2509.13852", "title": "Trace Sampling 2.0: 代码知识增强的分布式跟踪的跨越级别抽样方法", "title_en": "Trace Sampling 2.0: Code Knowledge Enhanced Span-level Sampling for Distributed Tracing", "authors": "Yulun Wu,Guangba Yu,Zhihan Jiang,Yichen Li,Michael R. Lyu", "background": "分布式追踪是微服务系统中至关重要的诊断工具，但由于追踪信息量巨大导致后端存储负担加重。一种常见的应对策略是抽取追踪，根据特定标准选择性地保留追踪，常只保存异常的追踪，但这种方法往往会丢弃有价值的信息，包括对比较分析至关重要的正常追踪。为了解决这个限制，本文提出了一种名为Trace Sampling 2.0的新方法，该方法在跨越级别进行操作但同时保持追踪结构一致性。这使得可以保留所有追踪，同时显著减少存储开销。", "innovation": "本文引入了Trace Sampling 2.0，这是一种跨越级别的抽样方法，通过静态分析提取执行逻辑，确保关键跨越被保留而不破坏结构完整性。相对于现有基于一级的抽样方法，Autoscope显著降低了追踪大小81.2%，同时保持了98.1%故障跨越覆盖率，实现了性能监测中的显著改善。", "conclusion": "通过在两个开源微服务上的评估，表明Autoscope可以显著提升微服务的可观测性和存储效率，为性能监测提供了稳健的解决方案。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13782", "html_url": "https://arxiv.org/abs/2509.13782", "title": "谁引入了故障？通过频谱分析自动归因多Agent系统中的故障", "title_en": "Who is Introducing the Failure? Automatically Attributing Failures of Multi-Agent Systems via Spectrum Analysis", "authors": "Yu Ge(1),Linna Xie(1),Zhong Li(1),Yu Pei(2),Tian Zhang(1) ((1) Nanjing University, (2) The Hong Kong Polytechnic University)", "background": "大型语言模型驱动的多Agent系统（MASs）越来越多地被用于自动化复杂的现实世界问题，如编程和科学发现。尽管它们很有前景，但MASs也存在一些缺点。然而，对于MASs中的故障归因问题——即找出导致特定故障的特定Agent行动——仍然研究较少且过程繁复，这给调试和系统改进带来了巨大挑战。", "innovation": "提出了一种名为FAMAS的新颖的频谱归因方法，这是首次针对MASs的基于频谱的故障归因方法。FAMAS通过系统路径回放和抽象，结合频谱分析来确定哪个Agent行动最有可能导致了故障。FAMAS的核心在于利用重复执行MAS时的变异，来估计每个Agent行动导致故障的可能性。该方法特别提出了一个针对MASs的可疑性公式，该公式整合了Agent行为组和行动行为组，以适应MAS执行轨迹中的激活模式。通过在12种基线方法上的昂贵评估，FAMAS表现出了优于所有比较方法的性能。", "conclusion": "FAMAS通过频谱分析成功识别了MASs中的故障原因，显著提升了故障归因的效率和准确性，有助于提高MASs的可靠性和性能。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.14093", "html_url": "https://arxiv.org/abs/2509.14093", "title": "通过自适应链式推理压缩实现高效推理：一种自我优化框架", "title_en": "Reasoning Efficiently Through Adaptive Chain-of-Thought Compression: A Self-Optimizing Framework", "authors": "Kerui Huang,Shuhan Liu,Xing Hu,Tongtong Xu,Lingfeng Bao,Xin Xia", "background": "链式思维（CoT）推理通过提示中间步骤，增强了大型语言模型（LLMs），在算术、逻辑和常识任务中改善了精度和鲁棒性。然而，这种好处带来了高计算成本：较长的输出增加了延迟、内存使用和KV缓存需求。在需要简洁和确定性输出的软件工程任务中，这些问题尤其严峻。为了探讨这些权衡，我们基于代码生成基准进行了实证研究。结果表明，较长的CoT并不总是有益的。过多的推理常常导致截断、精度下降以及高达五倍的延迟，失败的输出始终比成功的输出更长。这些发现挑战了更长推理就一定更好的假设，并突显了需要灵活调整CoT控制的需求。", "innovation": "我们提出了SEER（自增强高效推理），一种自适应框架，能够压缩CoT同时保持精度。SEER结合了Best-of-N采样和任务感知的适应性过滤，根据预推理输出动态调整阈值，以减少冗余和计算开销。我们还在三个软件工程任务和一个数学任务上对SEER进行了评估。平均而言，SEER使CoT缩短了42.1%，通过减少截断提高了准确性，并消除了大多数无限循环。", "conclusion": "这些结果证明，SEER是一种实用的方法，可以使CoT增强的LLMs在资源受限条件下更加高效和稳健。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13755", "html_url": "https://arxiv.org/abs/2509.13755", "title": "擦除它！通过机器遗忘擦除代码语言模型中的敏感记忆", "title_en": "Scrub It Out! Erasing Sensitive Memorization in Code Language Models via Machine Unlearning", "authors": "Zhaoyang Chu,Yao Wan,Zhikun Zhang,Di Wang,Zhou Yang,Hongyu Zhang,Pan Zhou,Xuanhua Shi,Hai Jin,David Lo", "background": "代码语言模型（CLMs）在软件工程任务中表现出色，如代码生成和摘要。然而，最近的研究揭示了隐私漏洞：这些模型无意中记忆了大量的敏感训练数据，当被特定提示时能够原封不动地再现机密信息。为解决此问题，已经提出了多种方法，包括去重训练数据和增强差分隐私，但这些方法需要对已部署的CLMs进行全面重新训练，导致巨大的计算成本。因此，本研究旨在探讨如何有效地且高效地擦除CLMs中的敏感记忆信息。本研究一是量化CLM训练数据集中敏感数据的记住风险，二是挑选出50,000个高风险敏感记忆样本作为遗忘目标，三是通过机器遗忘方法研究了两种常用的基于梯度上升的遗忘方法，并引入了CodeEraser，这是一种先进版本的自适应遗忘方法，在代码中选择性地删除敏感记忆段落的同时保持代码结构和功能的正确性。", "innovation": "本研究创新性地提出了机器遗忘方法，这是一种后处理修改技术，无需对训练模型进行完全重训练即可从具体信息中删除敏感记忆，这为解决CLMs中的敏感记忆问题提供了一种有效的且高效的方法。研究中引入的CodeEraser是一个高级版本的自适应遗忘方法，能够在代码中选择性地删除敏感记忆段落的同时保持代码结构和功能的正确性。", "conclusion": "大量的实验验证了CodeEraser的有效性和高效性，能够在删除敏感记忆的同时保持模型的可用性。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13941", "html_url": "https://arxiv.org/abs/2509.13941", "title": "在自动问题解决中的实证研究", "title_en": "An Empirical Study on Failures in Automated Issue Solving", "authors": "Simiao Liu,Fang Liu,Liehao Li,Xin Tan,Yinghao Zhu,Xiaoli Lian,Li Zhang", "background": "自动问题解决旨在自主识别和修复整个代码库中的缺陷代码片段。SWE-Bench 是用于评价这一领域进展的最广泛采用的标准。尽管基于大型语言模型（LLM）的代理工具显示出极大的潜力，但在许多任务上仍表现不佳。目前的评估主要侧重于报告聚合的问题解决成功率，这使得诊断模型弱点和指导针对性改进变得困难。为了弥合这一差距，研究首先分析了三种在 SWE-Bench-Verified 下表现和效率的现状工具（涵盖基于流水线和代理架构）在不同任务特征下的自动问题解决性能。进一步地，为了从高层性能指标转向根本原因分析，对150个失败实例进行了系统的手动分析，发现了两大架构范式的失败模式差异，代理架构的大多数失败源自错误推理和认知僵局。这些发现为构建更强大的代理奠定了基础，通过诊断评估和协同设计。", "innovation": "研究提出了一种协作的专家-执行者框架。该框架引入了监督性专家代理，负责为执行器代理提供战略监督和纠正，以纠正错误的推理并打破导致失败的认知僵局。实验结果显示，该框架解决了领先单个代理所无法处理的22.2%的问题，这些发现为通过诊断评估和协同设计构建更强大的代理奠定了基础。", "conclusion": "这项研究通过详细的失败模式分析及协作专家-执行者框架的提出，提供了指导自动问题解决领域发展的新视角，有助于开发者更好地理解和改进代理代理的性能。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13896", "html_url": "https://arxiv.org/abs/2509.13896", "title": "Mind the Ethics! The Overlooked Ethical Dimensions of GenAI in Software Modeling Education", "title_en": "Mind the Ethics! The Overlooked Ethical Dimensions of GenAI in Software Modeling Education", "authors": "Shalini Chakraborty,Lola Burgueño,Nathalie Moreno,Javier Troya,Paula Muñoz", "background": "生成式人工智能（GenAI）正在迅速成为软件建模教育的一部分，受到了学生和教育者们的欢迎。GenAI 在需求解释、模型标准化和学生思维模型转化为结构化表示方面提供了帮助，从而影响了知识理解、图表思维和建模流畅性等核心学习成果。然而，其整合的伦理影响尚未受到充分探讨，尤其是在编程教育中缺乏明确的伦理监督和教学指南。", "innovation": "本文通过系统文献回顾的方法，在六个主要的计算机科学数字图书馆（ACM Digital Library、IEEE Xplore、Scopus、ScienceDirect、SpringerLink和Web of Science）中查找涉及GenAI伦理方面的教育研究，揭示了在软件建模教育中仅三项研究直接讨论了伦理问题。这一发现强调了GenAI教育中伦理讨论的缺失，引发了关于AI负责任整合和需要制定结构化伦理框架的问题。", "conclusion": "研究指出仅有三篇论文直接讨论了GenAI在软件建模教育中的伦理问题，表现了这一新兴教育领域伦理讨论的急需性。这项研究识别出的研究机会和面临的挑战为后续研究提供了指导。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13699", "html_url": "https://arxiv.org/abs/2509.13699", "title": "通过并行化路径抽象细化实现多线程软件模型检测", "title_en": "Multi-Threaded Software Model Checking via Parallel Trace Abstraction Refinement", "authors": "Max Barth,Marie-Christine Jakobs", "background": "自动软件验证是软件质量保证的一种宝贵方法。然而，自动验证特别是软件模型检测可能十分耗时，这阻碍了其实际应用，例如在持续集成中的使用。为解决该问题，可以通过利用现代多核CPU来减少验证过程的响应时间。路径抽象是软件模型检测的一种基于抽象的方法。我们提出了一个并行化路径抽象的方法，通过并行处理不同的可能导致安全属性违反的路径来实现这一目标。我们在验证工具Ultimate Automizer中实现了并行化版本的路径抽象，并进行了详细评估，显示并行化版本相比于顺序路径抽象更有效，能够显著加快许多耗时任务的结果。并且，我们的方法比DSS更有效，DSS是最近的一种基于抽象的软件模型检测的并行方法。", "innovation": "提出了一种通过并行化路径抽象细化的方法来实现多线程软件模型检测。该方法通过在验证工具Ultimate Automizer中并行处理可能导致安全属性违反的不同路径来减少验证过程的响应时间。与传统的顺序路径抽象方法相比，实验结果表明并行方法更有效，能显著加快许多耗时的验证任务。并且，该方法比DSS更有效，DSS是最近提出的一种基于抽象的软件模型检测的并行方法。", "conclusion": "实验结果表明，通过并行化路径抽象细化的方法在许多耗时任务中能够显著加快验证结果，比传统的顺序路径抽象更有效，比DSS这种最新的并行基于抽象的软件模型检测方法也更为有效。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13429", "html_url": "https://arxiv.org/abs/2509.13429", "title": "Catalpa：低变异软件栈的垃圾收集器", "title_en": "Catalpa: GC for a Low-Variance Software Stack", "authors": "Anthony Arnold,Mark Marron", "background": "传统的应用程序或运行时的性能通常被认为是一个连续函数，即在给定的工作负载下，使用的内存或时间越少，编译器或运行时的性能就越好。然而，在实践中，应用程序的良好性能更被视作一个二元函数——如果应用程序能够在100毫秒内响应，对于用户来说几乎感觉不到延迟，或响应时间过长导致用户等待甚至放弃任务。因此，性能实际上是衡量应用程序在足够快以保持可用性方面的频率。工业开发者更重视95th和99th百分位的延迟，而非平均响应时间。", "innovation": "本文介绍了一种名为Catalpa的创新垃圾收集器设计，专为Bosque编程语言和运行时系统设计。Catalpa设计旨在最小化延迟和变化性，同时保持高吞吐量和较小的内存开销。通过利用Bosque语言的特性（包括不可变性和无引用循环自由性），Catalpa能够实现固定延迟暂停、固定常量内存开销，并不要求与应用程序代码进行任何屏障同步。", "conclusion": "本文提出了一种Catalpa收集器，专为Bosque语言和运行时系统设计，旨在通过编程语言和运行时系统设计来满足工业开发者的需求。该收集器的设计目标是通过利用Bosque语言的不可变性和无引用循环特性，最小化垃圾收集暂停时间，保持固定且较小的内存开销，同时不需要与应用程序代码进行同步。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.13704", "html_url": "https://arxiv.org/abs/2509.13704", "title": "InfraMind：一种用于关键工业管理的新型探索式GUI代理框架", "title_en": "InfraMind: A Novel Exploration-based GUI Agentic Framework for Mission-critical Industrial Management", "authors": "Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen", "background": "关键工业基础设施，例如数据中心，日益依赖复杂的管理系统。然而，运行这些系统的操作面临巨大挑战，主要是系统复杂性增加、多供应商集成困难以及缺乏专业技术操作员。尽管机器人流程自动化(RPA)通过手工编写的脚本提供了一部分自动化，但它存在灵活性有限和维护成本高的问题。最近，基于大规模语言模型(LLM)的图形用户界面(GUI)代理取得了进展，使自动化更加灵活。然而，这些通用代理在应用于工业管理时面临五大关键问题：不熟悉元素的理解、精确度和效率、状态定位、部署限制以及安全性要求。由于这些挑战，我们提出了一种名为InfraMind的创新探索式GUI代理框架，专门针对工业管理系统。InfraMind整合了五个创新模块以系统地解决工业管理中的不同挑战：(1) 基于系统搜索的探索并使用虚拟机快照以自动理解复杂的GUI；(2) 基于记忆的计划以确保高精度和高效的任务执行；(3) 高级状态识别以在分层界面中进行鲁棒状态定位；(4) 结构化知识提炼以使用轻量级模型进行高效部署；(5) 全面的多层次安全机制以保障敏感操作的安全。", "innovation": "InfraMind是一种专为工业管理系统设计的探索式GUI代理框架，整合了五个创新模块：基于系统搜索的探索、基于记忆的计划、高级状态识别、结构化知识提炼以及多层次的安全机制。该框架能够系统地解决工业管理中的五大挑战，提供了一种安全且可扩展的工业管理自动化解决方案。该方法在开源和商业DCIM平台上的实验结果表明，它在任务成功率和操作效率方面优于现有框架，为工业管理自动化提供了严格的解决方案。", "conclusion": "InfraMind 的实验结果表明，它在任务成功率和操作效率方面优于现有框架，提供了一种严格的、可扩展的工业管理自动化解决方案，为工业管理中的自动化需求提供了切实可行的方法。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.21710", "html_url": "https://arxiv.org/abs/2503.21710", "title": "KGCompass: 知识图谱增强的仓库级软件修复", "title_en": "KGCompass: Knowledge Graph Enhanced Repository-Level Software Repair", "authors": "Boyang Yang,Jiadong Ren,Shunfu Jin,Yang Liu,Feng Liu,Bach Le,Haoye Tian", "background": "仓库级软件修复面临着在问题描述和代码修复之间弥合语义鸿沟的挑战。现有的方法主要依赖大型语言模型（LLMs），但这些方法受到语义歧义、对结构上下文理解不足和推理能力有限的限制。", "innovation": "我们提出了KGCompass，包含两项创新：（1）一种新型的仓库感知知识图（KG），它可以准确地链接仓库构件（问题和拉取请求）和代码库实体（文件、类和函数），从而将广大的搜索空间有效缩小到仅需考虑20个最相关的函数，并提供准确的候选故障位置和上下文信息；（2）一种基于路径的修复机制，该机制利用KG挖掘的实体路径，由此可以增强LLMs以生成精确的代码修复并附带详细的解释。这些方法证明了KGCompass可以在降低成本的同时，实现模型无关的、高性能的修复，并为仓库级修复设定了新的基准线，相较于单纯的LLM基准模型提升了修复率。", "conclusion": "实验结果在SWE-bench Lite上的数据显示，KGCompass的单一LLM修复性能达到了最先进的水平（58.3%），且功能级别的故障定位准确率（56.0%）远远高于开源方法，每个修复仅需花费0.2美元。在KGCompass成功识别出的bug中，89.7%的bug没有明确的位置提示，只能通过多跳图遍历找到，而单纯的LLM在这些情况下难以准确找到bug。相比于纯粹的LLM基准，KGCompass在不同模型上显著提升了修复率，展示了这种基于图的修复框架的普适性和高效性。"}
{"llm_update_time": "20250918", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.21225", "html_url": "https://arxiv.org/abs/2507.21225", "title": "流体活性化网络骨架制成多功能和耐用的触觉传感器", "title_en": "Fluidically Innervated Lattices Make Versatile and Durable Tactile Sensors", "authors": "Annan Zhang,Miguel Flores-Acton,Andy Yu,Anshul Gupta,Maggie Yao,Daniela Rus", "background": "触觉传感在使机器人能够在动态和无结构环境中导航中起着关键作用，特别是在精细物体操作、表面探索和人机交互等应用中。现有方法通常依赖于复杂的材料或设计，使得触觉传感解决方案复杂且不够普遍适用。", "innovation": "本文介绍了一种采用3D打印弹性体网络结构并嵌入空气通道的被动软机器人触觉指尖。这种触觉感知方法称为流体活性化，通过检测密封空气通道内的压力变化将网络转换为触觉传感器。这种方法提供了一种简单且成本效益高的触觉传感解决方案。相比传统方法，流体活性化的优点在于简单的单材料制造工艺，适用于多种环境和应用。此外，还开发了几何模型来估计触觉指尖的位移，训练神经网络预测接触位置和接触力。", "conclusion": "该触觉传感技术在简单性、适应性和耐用性方面具有明显优势，并为多功能的机器人操作提供了新的可能性。指尖被集成到阻抗控制器中以模拟弹簧行为，展示了通过触觉反馈进行环境探索的能力，并验证了其在高冲击和循环载荷条件下的耐用性。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08627", "html_url": "https://arxiv.org/abs/2507.08627", "title": "在中间的NL：LLM和中间表示的代码翻译", "title_en": "NL in the Middle: Code Translation with LLMs and Intermediate Representations", "authors": "Chi-en Amy Tai,Pengyu Nie,Lukasz Golab,Alexander Wong", "background": "研究表明，大型语言模型（LLMs）生成的代码翻译存在错误。提高翻译准确性的前景之一是使用中间表示，这种表示为翻译过程提供了结构化的指导。本文探讨了基于LLM的代码翻译是否可以从中间表示中受益，特别是采用自然语言（NL）摘要和抽象语法树（AST）的形式。由于提示工程极大地影响了LLM的性能，本文考虑了几种集成这些表示的方法，从一次性提示到链式思考（CoT）提示。使用公开的Open GPT4 8X7B和专门的StarCoder及CodeGen模型在流行的代码翻译基准测试（CodeNet和AVATAR）上取得了研究结果。结果显示，使用链式思考与中间NL摘要的提示方式表现最佳。最佳性能模型（Open GPT4 8X7B）的正确翻译成功率相较于零级提示分别提高了13.8%和6.7%。", "innovation": "本文创新性地提出了在LLM代码翻译中使用链式思考与中间NL摘要的提示方式，相较于零级提示，显著提高了翻译的准确性和成功率", "conclusion": "采用链式思考与中间NL摘要的提示策略，对于基于LLM的代码翻译具有显著的提升效果，具体表现为Open GPT4 8X7B等模型在正确翻译成功方面比零级提示分别提高了13.8%和6.7%。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.20781", "html_url": "https://arxiv.org/abs/2504.20781", "title": "使用大型语言模型生成软件架构决策设计理由", "title_en": "Using LLMs in Generating Design Rationale for Software Architecture Decisions", "authors": "Xiyu Zhou,Ruiyin Li,Peng Liang,Beiqi Zhang,Mojtaba Shahin,Zengyang Li,Chen Yang", "background": "软件架构决策背景理由（DR）指的是支撑架构选择的思维过程，能够在软件开发生命周期的不同阶段提供有价值的见解。然而，开发人员由于缺乏动机和努力，通常无法充分记录DR。近年来，大型语言模型（LLMs）的文本理解和生成能力为其提供了生成和恢复DR的潜力。本文旨在评估LLMs在生成适用于架构决策的DR中的表现。研究人员收集了与架构决策相关的50个Stack Overflow帖子、25个GitHub问题和25个GitHub讨论，共构建了100个架构问题的数据集，并使用三种不同的提示策略（零样本、思维链和LLM代理）来生成DR，评估了不同策略下生成的DR的精度、召回率和F1分数，并探讨了LLMs生成的DR的实际可信度与适用性。", "innovation": "本文利用近年来大型语言模型（LLMs）的发展，提出了使用LLMs生成软件架构决策设计理由的方法。通过比较三种不同的提示策略（零样本、思维链和LLM代理），评估了其生成DR的有效性，并通过半结构化访谈进一步探讨了生成的DR在实践中的可信度与适用性。这项工作为利用LLMs辅助架构设计提供了新的视角和方法。", "conclusion": "通过对实验结果和访谈结果的分析，本文讨论了三种提示策略的优势和缺点，LLMs生成的DR的优缺点，并针对实践中的应用提出了建议。尽管LLMs生成的DR存在一定不确定性，但仍然提供了一些有价值的见解。未来的工作可以进一步探索如何提高生成的DR的质量和可信度。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.15495", "html_url": "https://arxiv.org/abs/2508.15495", "title": "SynthCoder：一种调优LLMs进行代码补全的合成策略", "title_en": "SynthCoder: A Synthetical Strategy to Tune LLMs for Code Completion", "authors": "Dongjun Yu,Xiao Yan,Zhenrui Li,Jipeng Xiao,Haochuan He,Yongda Yu,Hao Zhang,Guoping Rong,Xiaobo Huang", "background": "代码补全是大型语言模型（LLMs）在软件工程中的主要应用之一。由于这个任务需要近乎实时的响应，通常使用小到中等参数量的基模型，并配备各种优化和后训练技术。然而，这些优化方法常常存在权衡，导致性能提升的方面也伴随着在其他方面的下降，甚至有时低于基线模型的性能。", "innovation": "本文提出了SynthCoder模型，通过整合主流的工业实践实现Fill-in-the-Middle (FIM) 代码补全任务上的领先性能。首先，通过抽象语法树（AST）节点提取与模拟开发者行为的启发式方法构造一个多样化数据集。其次，利用BM25算法和调用图来丰富我们的训练语料，增强模型在文件级和仓库级场景下的代码补全能力。最后，采用SeedListCocoder-8B-Base作为基础模型的双阶段训练过程，首先通过课程学习技术微调模型，随后使用拒绝采样生成的偏好对进行直接偏好优化（DPO）来完成校准。", "conclusion": "实验结果显示，在主流的仓库级代码补全基准（包括aiXcoder、ExecRepoBench、CrossCodeEval和CoLT）中，我们的最终模型表现出色。此外，我们精心构建的训练集有效地减轻了模型重复已存在代码的倾向，这是许多代码补全模型中的常见问题。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2411.18216", "html_url": "https://arxiv.org/abs/2411.18216", "title": "评估和提升由LLMs生成的安全攻击检测器的稳健性", "title_en": "Evaluating and Improving the Robustness of Security Attack Detectors Generated by LLMs", "authors": "Samuele Pasini,Jinhan Kim,Tommaso Aiello,Rocio Cabrera Lozoya,Antonino Sabetta,Paolo Tonella", "background": "大规模语言模型（LLMs）在软件开发中被广泛用于生成功能代码，包括用于实施安全要求的攻击检测器。确保这些模型具备足够的安全知识来满足特定的安全要求，如了解现有攻击，是一项关键挑战。本研究通过结合检索增强生成（RAG）和自我排名方法，旨在提升LLMs生成的攻击检测器的性能。", "innovation": "提出了一种结合检索增强生成（RAG）和自我排名技术的方法，以提升由LLMs生成的安全攻击检测器的稳健性。RAG通过引入外部知识资源增强了输出的鲁棒性，而自我排名技术激励了自我一致性概念，生成了多种推理路径并创建排名以选择最稳健的检测器。", "conclusion": "本研究通过大量的实证研究，评估了使用RAG和自我排名技术的LLMs生成代码用于检测Web安全中的两种常见攻击：跨站脚本（XSS）和SQL注入（SQLi）。结果表明，与未使用RAG和自我排名的方法相比，使用这些技术显著提升了检测性能，XSS和SQLi检测的F2-分数分别提高了71%（平均37%）和43%（平均6%）。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2410.19794", "html_url": "https://arxiv.org/abs/2410.19794", "title": "DiffGAN：一种用于图像分析中深度神经网络差异测试的测试生成方法", "title_en": "DiffGAN: A Test Generation Approach for Differential Testing of Deep Neural Networks for Image Analysis", "authors": "Zohreh Aghababaeyan,Manel Abdellatif,Lionel Briand,Ramesh S", "background": "随着深度神经网络（DNNs）在各种应用中的部署越来越多，确保其可靠性依然是一个挑战。传统的基于准确性的评估方法往往无法捕捉模型之间的行为差异，特别是在使用有限的测试数据集时，这使得选择或组合模型变得困难。现有差异测试方法通过生成能够暴露模型行为差异的测试输入来解决这一问题，但它们存在一些局限性，如依赖模型内部结构或受到可用种子输入的限制。", "innovation": "本文提出了DiffGAN，一种基于生成对抗网络（GAN）和非支配排序遗传算法II（NSGA-II）的黑箱测试图像生成方法，用于DNN模型的差异测试。DiffGAN使用两种自定义适应度函数，分别关注多样性和差异性，以指导GAN输入空间的探索并识别模型输出之间的差异。通过战略性地搜索输入空间，DiffGAN生成具有特定特征的输入，以触发模型行为的差异。DiffGAN的黑箱特性使其在更多情况下适用。我们在八对训练于常用图像数据集上的DNN模型上评估了DiffGAN，结果表明DiffGAN显著优于现有最佳基线，生成了四倍数量、多样化且有效的触发输入，并且这些输入提高了基于输入特征的机器学习模型选择机制的准确性。", "conclusion": "DiffGAN显著提高了DNN模型差异测试的效果，通过生成多样化且有效的触发输入，能够更精确地识别模型间的差异，从而有助于更有效地选择和组合模型。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.05170", "html_url": "https://arxiv.org/abs/2508.05170", "title": "Posterior-GRPO: 在代码生成中奖励推理过程", "title_en": "Posterior-GRPO: Rewarding Reasoning Processes in Code Generation", "authors": "Lishui Fan,Yu Zhang,Mouxiang Chen,Zhongxin Liu", "background": "强化学习（RL）在大型语言模型（LLMs）的代码生成中取得了显著进展。然而，当前的方法主要依赖于测试案例的结果奖励，忽视了中间推理过程的质量。直接监督推理过程虽然前景广阔，但容易受到奖励欺骗现象的影响，即策略模型学会利用推理奖励信号而不提高最终结果。这种情况下，奖励模型可能会学习到间接增强行为，但不直接改善最终结果。因此，需要一种可以有效在RL中整合推理过程质量的方法。", "innovation": "该研究引入了一种统一框架，能够在RL中有效整合推理过程的质量。首先，开发了一种名为LCB-RB的基准，包含优秀和较差推理过程的偏好对，以支持推理评估。其次，提出了基于优化和降级的奖励模型训练方法（OD方法），该方法能够系统地优化和降级初始推理路径，生成高质量的偏好对，涵盖诸如事实准确性、逻辑严谨性和连贯性等 reasoning 质量维度。最后，提出了基于过程奖励的策略梯度优化方法（Posterior-GRPO），该方法将过程奖励条件化于任务成功，通过只对成功的结果推理过程应用奖励，有效缓解了奖励欺骗问题，使模型的内部推理与最终代码正确性对齐。", "conclusion": "一个包含7亿参数的模型结合Posterior-GRPO能够显著改善各种代码生成任务的性能，相对只基于结果的基线模型提升了4.5%的性能，达到了与GPT-4-Turbo相当的水平。此外，我们展示了该方法在数学任务中的通用性。我们的模型、数据集和代码已经公开发布。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.12443", "html_url": "https://arxiv.org/abs/2509.12443", "title": "从遗留Fortran到可移植Kokkos：一种自主的能动AI工作流", "title_en": "From Legacy Fortran to Portable Kokkos: An Autonomous Agentic AI Workflow", "authors": "Sparsh Gupta,Kamalavasan Kamalakkannan,Maxim Moraru,Galen Shipman,Patrick Diehl", "background": "科学应用长期依赖于为同构CPU系统设计的遗留Fortran代码库。随着高性能计算（HPC）转向异构GPU加速架构，许多加速器缺乏原生Fortran绑定，这迫切需要对遗留代码进行现代化改造以实现跨硬件平台的可移植性。框架如Kokkos提供了性能可移植性和单一源C++抽象，但它要求手动将Fortran转换为Kokkos编写的代码，这耗时且技术要求很高。大规模语言模型（LLMs）在源代码到源代码的代码生成方面展现了潜力，但它们在自主工作流中转换和优化并行代码，特别是为了实现不同硬件上的性能可移植性，其应用尚未被充分探索。", "innovation": "本文提出了一种能动AI工作流，其中专门的大规模语言模型（LLMs）“代理”协作，可以自动完成Fortran内核到Kokkos C++程序的翻译、验证、编译、运行、测试、调试和优化。研究表明，该全流程能够使多种基准内核现代化，产生跨硬件分区具有性能可移植性的Kokkos代码。使用付费的OpenAI模型如GPT-5和o4-mini-high执行工作流仅需少量美元，生成的优化代码超越了Fortran基线，而开源模型如Llama4-Maverick往往无法生成功能性的代码。这项工作展示了能动AI在Fortran到Kokkos转换方面的可行性，指明了自主现代化遗留科学应用并使其在多样的超级计算机上高效运行的途径，并强调了LLM驱动的能动系统在科学和系统方向应用中进行结构化领域特定推理任务的潜力。", "conclusion": "本文证明了能动AI在Fortran到Kokkos转换方面的可行性，为自主地使遗留科学应用实现跨硬件有效运行提供了一条路径，并表明了LLM驱动的能动系统的潜在价值，可以执行结构化领域的特定推理任务。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.04990", "html_url": "https://arxiv.org/abs/2507.04990", "title": "Effort-Optimized, Accuracy-Driven Labelling and Validation of Test Inputs for DL Systems: 一种基于混合整数线性规划的方法", "title_en": "Effort-Optimized, Accuracy-Driven Labelling and Validation of Test Inputs for DL Systems: A Mixed-Integer Linear Programming Approach", "authors": "Mohammad Hossein Amini,Mehrdad Sabetzadeh,Shiva Nejati", "background": "随着软件系统越来越多地包含基于深度学习(DL) 的AI组件，可靠地测试这些系统需要有近乎完美的测试输入有效性和标签准确性，且最大程度减少人为努力。然而，深度学习社区普遍忽略了构建高效准确数据集的同时减少人力投入的需求，因为深度学习训练通常对标注错误具有较好的容忍性。这一挑战更关注于软件工程中的核心目标——构建尽可能接近100%准确性的测试输入，同时控制相关成本。", "innovation": "本文提出了一种基于混合整数线性规划(MILP)的人工辅助标注方法OPAL，该方法能够针对预设的准确率目标最小化所需的标注努力。通过在视觉系统测试中的自动标注和测试输入自动验证任务中实现和评估，OPAL显示其平均准确率为98.8%，相比基准方法减少了超过一半的手动标注工作量。对于测试输入验证，OPAL平均每减少28.8%的手动工作量同时实现4.5%的准确率提升，领先于目前的最优测试输入验证基准。此外，通过结合主动学习循环，OPAL在无需牺牲准确性的前提下进一步减少了4.5%的手动标注需求。", "conclusion": "研究基于MILP的方法OPAL显著提高了DL系统测试输入的标注重量效率和准确性，同时也展示了在不同任务中的适用性和优越性。"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.17534", "html_url": "https://arxiv.org/abs/2503.17534", "title": "MetaSel: 细调DNN模型的测试选择方法", "title_en": "MetaSel: A Test Selection Approach for Fine-tuned DNN Models", "authors": "Amin Abbasishahkoo,Mahboubeh Dadkhah,Lionel Briand,Dayi Lin", "background": "深度神经网络（DNNs）在部署过程中面临与先验分布不匹配的问题，即开发和部署阶段的数据分布发生变化。通过微调预训练模型来适应新场景是一种常见做法，但要在有限的标注预算下测试微调后的模型仍然是一个关键挑战。MetaSel方法在此背景下应运而生，旨在通过利用细调模型和预训练模型在未标注测试输入上的行为差异来选择测试样本，从而提高测试效率和准确性。\n", "innovation": "MetaSel通过结合细调后的模型和预训练模型的信息，估计未标注测试输入中的误分类概率来选择测试样本，这与依赖模型输入集的一般方法不同。这种方法能够在高度受限的标注预算下显著提高测试相对覆盖度(TRC)，在与11种最先进的方法的比较中，MetaSel展示了高达28.46%至56.18%的TRC改进，并且在中值和变异性上表现良好。\n", "conclusion": "MetaSel在不同数据分布偏移程度的68个细调模型上进行了广泛的经验验证，表明其在实际应用中具有较强的实用性和成本效益。该方法不仅对提高细调模型的测试覆盖度有显著效果，而且在显著降低标注成本的情况下，还能保持较高的测试准确性。\n"}
{"llm_update_time": "20250918", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2409.19894", "html_url": "https://arxiv.org/abs/2409.19894", "title": "通过基于大语言模型的多智能体系统实现语义对齐增强的代码翻译", "title_en": "Semantic Alignment-Enhanced Code Translation via an LLM-Based Multi-Agent System", "authors": "Zhiqiang Yuan,Weitong Chen,Hanlin Wang,Kai Yu,Xin Peng,Yiling Lou", "background": "代码翻译是一种将代码从一种编程语言转换为另一种编程语言并保持其原始功能的技术，对于软件迁移、系统重构和跨平台开发至关重要。传统的基于规则的方法依赖于手动编写的规则，这可能导致效率低下且生成的代码可读性较差。近年来，学习基于的方法利用平行数据来训练模型以进行自动代码翻译。随着大型语言模型（LLMs）的进步，代码翻译也得到了提升。然而，通过LLMs生成的程序代码仍然存在多样化的质量问题（如语法错误和语义错误）。现有的方法主要通过错误消息来发现错误，但难以自我调试这些问题。", "innovation": "本文提出了一种新的基于大语言模型的多智能体系统TRANSAGENT，通过四个基于大语言模型的智能体（初始代码翻译器、语法错误修复器、代码对齐器和语义错误修复器）的协同作用来解决语法错误和语义错误。其主要洞察是通过目标程序和源程序执行对齐来定位错误代码块，从而缩小修复范围，降低修复难度。为了评估TRANSAGENT，作者构建了一个新的基准数据集来缓解潜在的数据泄露问题，在基准数据集上，TRANSAGENT 在翻译效果和效率方面优于最新的基于大语言模型的代码翻译技术 UniTrans，并且在不同的大语言模型上的测试也展示了 TRANSAGENT 的通用性。此外，消融研究表明了每个智能体的贡献。", "conclusion": "在我们的基准上，TRANSAGENT 在翻译效果和效率方面均优于最新的基于大语言模型的代码翻译技术 UniTrans；我们的评估显示了 TRANSAGENT 在不同大型语言模型上的通用性；我们的消融研究表明了每个智能体的贡献。"}
