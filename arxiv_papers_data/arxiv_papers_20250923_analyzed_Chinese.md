# 20250923
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 基于人工智能力量的语义相似性驱动快速文献处理管道 [PDF](https://arxiv.org/pdf/2509.15292), [HTML](https://arxiv.org/abs/2509.15292)
### Authors
Abhiyan Dhakal(1),Kausik Paudel(1),Sanjog Sigdel(1) ((1) Kathmandu University, Dhulikhel, Nepal)
### Background
传统的系统性文献回顾方法或基于优化的方法在进行文献回顾时存在一定的局限性。这些方法通常需要较多的人工干预，且难以保证高相关的文献被筛选出来。本文为了解决这一问题，提出了一种自动化文献回顾管道，使用语义相似度来进行相关文献的检索和筛选。
### Innovation
本文提出的方法使用了基于变换器的嵌入模型和余弦相似度来生成关键词和排序文献，强调了较低的人工干预成本和高相关性的文献检索能力。同时，通过统计阈值方法过滤相关文献，提供了一种有效的自动化文献回顾解决方案。
### Conclusion
尽管没有使用启发式反馈或相关性的实际标注数据，提出的系统显示出了作为初步研究和探索性分析的有效且可扩展工具的潜力。
## 2. `cs.AI` - 大型语言模型中的知识驱动错觉：过程建模的实证研究 [PDF](https://arxiv.org/pdf/2509.15336), [HTML](https://arxiv.org/abs/2509.15336)
### Authors
Humam Kourani,Anton Antonov,Alessandro Berti,Wil M.P. van der Aalst
### Background
大型语言模型（LLMs）在分析任务中的应用得益于其广泛预先训练的知识，使其能够解释模糊的输入并推断缺失的信息。然而，这一能力也带来了知识驱动的幻觉这种关键风险。知识驱动的幻觉是一种现象，即模型的输出与明确的来源证据相矛盾，因为模型的泛化内隐知识会覆盖这些证据。我们通过在业务过程管理（BPM）领域进行自动化过程建模任务中的实验证明了这种现象。在BPM领域，许多核心业务流程遵循标准化模式，使得LLMs有可能具备强烈先验模式。
### Innovation
本文通过在自动化过程建模任务中对LLMs进行评估，设计了控制实验来创造由提供证据与模型背景知识故意冲突的场景，使用描述标准和异常过程结构的输入以度量LLMs对提供证据的忠实度。该研究提供了一种评估这一关键可靠性的方法，并提高了对证据为基础领域的AI生成制品严格验证的重视。
### Conclusion
我们的工作为评估这一可信度问题提供了一种方法，并提高了对证据为基础领域的AI生成制品严格验证的需求意识。
## 3. `cs.AI` - MicroRCA-Agent: 基于大语言模型代理的微服务根因分析方法 [PDF](https://arxiv.org/pdf/2509.15635), [HTML](https://arxiv.org/abs/2509.15635)
### Authors
Pan Tang,Shixiang Tang,Huanqi Pu,Zhiqing Miao,Zhixing Wang
### Background
传统的微服务根因分析方法可能遇到效率低下、准确率不足等问题，尤其是在处理海量日志数据和复杂故障场景时。这一领域需要一种能够高效压缩日志、全面检测异常、并对多层次架构进行全栈现象总结的方法。
### Innovation
MicroRCA-Agent 创新地结合了预训练的 DrAIen 日志解析算法与多级数据过滤机制，高效地压缩大量日志；引入了一种双异常检测方法，将孤立森林无监督学习算法与状态码验证相结合，实现全面的轨迹异常识别；设计了统计对称比过滤机制和两阶段大语言模型分析策略，实现对节点-服务-容器层次架构的全栈现象总结；提出了多模态根因分析模块，利用精心设计的跨模态提示，深度融合多模态异常信息，充分利用大语言模型的跨模态理解与逻辑推理能力，生成结构化的故障分析结果。
### Conclusion
综合消融研究验证了每个模态数据的互补价值和系统的有效性，解决了复杂微服务故障场景，最终得分50.71，系统代码已在指定 URL 发布。
## 4. `cs.AI` - MICA: 多代理工业协调助手 [PDF](https://arxiv.org/pdf/2509.15237), [HTML](https://arxiv.org/abs/2509.15237)
### Authors
Di Wen,Kunyu Peng,Junwei Zheng,Yufan Chen,Yitain Shi,Jiale Wei,Ruiping Liu,Kailun Yang,Rainer Stiefelhagen
### Background
工业流程需要能够适应并信任的帮助，这些帮助在有限的计算能力、连接性和严格的隐私限制下仍能正常工作。现有的工业辅助系统通常在这些方面存在局限，MICA正是针对这一需求设计的。
### Innovation
引入了感知驱动和语音互动系统MICA，能够实时指导装配、故障排除、零部件查询和维护。MICA通过多个专业语言代理协作，并由安全检查器审核，以确保准确且合规的支持。此外，提出了自适应步融合理论，该理论能够将专业推理与自然语音反馈的在线适应动态结合，从而实现稳健的步骤理解。还建立了一个新的多代理协调基准，并提出了一套针对工业辅助定制的评估指标。
### Conclusion
实验结果表明，MICA在任务成功率、可靠性和响应性等方面都优于基线结构，并且仍然可以在实际的离线硬件中部署。整体来看，MICA为动态工厂环境中的可部署、隐私保护多代理助手提供了一个有力的解决方案。
## 5. `cs.AI` - 基于语义聚类和多智能体合作的自底向上多阶段方法构建数据驱动的职业分类 [PDF](https://arxiv.org/pdf/2509.15786), [HTML](https://arxiv.org/abs/2509.15786)
### Authors
Nan Li,Bo Kang,Tijl De Bie
### Background
创建稳健的职业分类对于从工作推荐到劳动力市场情报的应用至关重要。手动编纂缓慢，而现有的自动化方法要么无法适应动态的区域市场（自上而下），要么难以从噪声数据中构建一致的层次结构（自下而上）。
### Innovation
CLIMB（基于聚类的多智能体分类构建器）是一种框架，它可以完全自动化从原始职位发布中创建高质量、数据驱动的分类的过程。CLIMB 使用全球语义聚类提炼核心职业，然后利用基于反射的多智能体系统逐步构建一个一致的层次结构。CLIMB 通过三个不同真实世界的数据集测试，结果表明，CLIMB 产生的分类在一致性、可扩展性方面优于现有方法，并能准确捕捉独特的区域特征。
### Conclusion
CLIMB 得到了在三个不同真实世界数据集上的验证，表明其能够产生更一致、更可扩展的分类，并成功捕捉到独特的区域特征。本研究发布其代码和数据集供他人使用。
## 6. `cs.AI` - 交通网络中使用强化学习和AI的分布变化问题 [PDF](https://arxiv.org/pdf/2509.15291), [HTML](https://arxiv.org/abs/2509.15291)
### Authors
Federico Taschin,Abderrahmane Lazaraq,Ozan K. Tonguz,Inci Ozgunes
### Background
近年来，机器学习（ML）和人工智能（AI）在智能交通网络中的应用显著增加。在这些ML和AI方法中，强化学习（RL）被认为是非常有前途的方法，然而，使用RL进行交通信号控制的一个问题是训练好的RL代理的可靠性，因为输入数据的动态变化分布与训练数据分布不同，这为训练好的AI代理网络带来了主要挑战和可靠性问题，如果没有找到合适的解决方案，可能会导致非常不利甚至有害的后果。
### Innovation
研究特别提到Meta Reinforcement Learning（Meta RL）可能是有效的解决方案，并详细研究了一种名为MetaLight的先进Meta RL方法的表现，虽然在某些条件下MetaLight确实可以取得相对良好的结果，但在其他条件下其性能可能不佳（精度差高达22%），这表明Meta RL方案往往不够稳健，甚至可能引发主要的可靠性问题。
### Conclusion
尽管Meta RL为解决分布变化问题提供了有潜力的解决方案，但目前的研究表明，Meta RL方案在某些情况下可能没有足够稳健，仍存在显著的可靠性问题。
## 7. `cs.AI` - KNARsack: 教导神经算法推理器解决准多项式问题 [PDF](https://arxiv.org/pdf/2509.15239), [HTML](https://arxiv.org/abs/2509.15239)
### Authors
Stjepan Požgaj,Dobrik Georgiev,Marin Šilić,Petar Veličković
### Background
神经算法推理（NAR）是一门成长中的领域，旨在通过模仿经典算法将算法逻辑嵌入到神经网络中。本文扩展摘要中，作者致力于构建一种神经算法推理器来解决Knapsack问题，这是一个桥接经典算法和组合优化的准多项式问题，而在标准的NAR基准中被忽略了。Knapsack问题的解决过程分为两个阶段：首先构造动态规划表，然后从该表中重建解决方案。这一过程通过动态规划监督来建模中间状态，从而在处理更大型实例时比直接预测基线（仅从问题输入中选择最优子集）有更好的泛化效果。
### Innovation
该研究的创新点在于开发了一种神经算法推理器（KNARsack）来解决Knapsack问题这一准多项式问题，这是在标准NAR基准中未被涵盖的问题。通过模仿动态规划的两阶段管道来建模中间状态，KNARsack在处理大型问题实例时展示了更好的泛化能力。
### Conclusion
该研究成功地构建了一种神经算法推理器KNARsack，证明了其有效性和优越性，特别是在解决大型Knapsack问题实例时的泛化能力。
## 8. `cs.AI` - 初生的智能机器人流程自动化中的机器学习分类 [PDF](https://arxiv.org/pdf/2509.15730), [HTML](https://arxiv.org/abs/2509.15730)
### Authors
Lukas Laakmann,Seyyid A. Ciftci,Christian Janiesch
### Background
机器人过程自动化（RPA）是一种使用软件机器人在图形用户界面级别模拟用户操作来自动化业务流程的轻量级方法。RPA因其低成本和针对基于规则、结构良好任务的有效及时自动化而受到青睐，但其符号性质在处理当前由人类代理人执行的更复杂任务时存在固有限制。机器学习为RPA提供了实现智能化的可能，这为更广泛的自动化任务范围提供了机会。
### Innovation
本文对RPA与机器学习之间的联系进行了文献综述，并将智能RPA的概念整理成一个分类体系。该分类体系包括RPA-ML集成和RPA-ML交互的两个元特征，涵盖八维度：架构与生态系统、能力、数据基础、智能化水平、技术集成深度、部署环境、生命周期阶段以及用户-机器人关系。
### Conclusion
本文构建了一个涵盖八个维度的分类体系，用以系统地理解和分类智能RPA中的机器学习应用，旨在为该领域的进一步研究和应用提供框架和参考。
## 9. `cs.AI` - FragmentRetro：基于分解算法的二次回溯方法 [PDF](https://arxiv.org/pdf/2509.15409), [HTML](https://arxiv.org/abs/2509.15409)
### Authors
Yu Shee,Anthony M. Smaldone,Anton Morgunov,Gregory W. Kyro,Victor S. Batista
### Background
回溯合成（Retrosynthesis）是计算辅助合成规划（CASP）中至关重要的一步，目标是从复杂的目标分子中分解出更简单的前体。传统的树搜索方法通常面临指数级的计算复杂度问题，这限制了它们的广泛应用。本文旨在解决这一问题，提出了一种新的基于分解算法（BRICS和r-BRICS）的回溯合成方法，称为FragmentRetro。该方法结合了基于库存的认知探索和模式指纹筛选，使得计算复杂度降低至二次级别。
### Innovation
FragmentRetro 方法通过递归组合分子碎片并验证其在构建块集合中的存在性，提供了一组可用于回溯合成解决方案的碎片组合。该方法首次进行了正式的计算分析，显示出树搜索具有指数级复杂度 $O(b^h)$，DirectMultiStep 为 $O(h^6)$，而 FragmentRetro 达到 $O(h^2)$。此外，Fingerprint 筛选技术显著降低了子结构匹配的复杂度，使得该方法能够在解决实际问题中表现良好。尽管 FragmentRetro 在识别基于碎片的解决方案方面效率更高，但它在生成战略性的初始候选方案方面仍具有显著优势，从而成为可扩展和自动化的合成规划的基础组件之一。
### Conclusion
FragmentRetro 方法展示了在解决实际案例中的高效性和可比的运行时间，即使在树搜索失败的情况下也能取得高成功率。该方法结合了高效的碎片组合和验证机制，提供了一种新的、具有二次复杂度的回溯合成解决方案。
## 10. `cs.AI` - 基于注意模式的注意控制 (ASAC): 一种启发自认知的注意力管理方法在变压器中的应用 [PDF](https://arxiv.org/pdf/2509.16058), [HTML](https://arxiv.org/abs/2509.16058)
### Authors
Krati Saxena,Federico Jurado Ruiz,Guido Manzi,Dianbo Liu,Alex Lamb
### Background
注意力机制已成为人工智能的关键组成部分，通过借鉴人类认知，显著提高了模型的性能和可扩展性。同时，认知科学中的注意力模式理论（AST）指出，个体通过构建对自身注意机制的模型，有效地分配认知资源。基于AST的思想，我们提出了ASAC（Attention Schema-based Attention Control），将注意力模式的概念融入人工神经网络。最初的实验关注于在变压器架构中嵌入ASAC模块。
### Innovation
ASAC模块通过使用向量量化变分自编码器（VQVAE）作为注意力抽象器和控制器，实现了明确建模注意力分配，从而提升系统的效率。实验结果表明，ASAC在视觉和自然语言处理（NLP）领域均显示出提高分类准确性和加速学习过程的能力。此外，该模型在噪声和分布外数据集中的鲁棒性和泛化能力也得到了验证，同时展示了在多任务设置中的性能提升。
### Conclusion
这些初步结果建立了认知科学与机器学习之间的联系，展示了在AI系统中高效利用注意力机制的可能性。
## 11. `cs.AI` - 解剖连接性中的本体创建与管理工具 [PDF](https://arxiv.org/pdf/2509.15780), [HTML](https://arxiv.org/abs/2509.15780)
### Authors
Natallia Kokash,Bernard de Bono,Tom Gillespie
### Background
研究人员需要基础设施来绘制与外周神经系统和其他生理系统相关联的数据，并强调这些系统对正在研究的器官的重要性。神经系统是一个复杂网络，负责协调和传输全身信号。为此，该论文开发了ApiNATOMY框架，用于多尺度生理电路图的拓扑和语义表示。ApiNATOMY整合了知识表示(KR)模型和一系列知识管理(KM)工具，以支持专家捕捉解剖实体间的互动，并帮助建模者将高维度抽象转化为详细的生理过程模型，这些模型可以与外部本体和知识图结合使用。
### Innovation
ApiNatomy框架是一个创新的知识表示和管理工具，它整合了知识表示模型和一套知识管理工具。KR模型允许生理专家轻松捕捉解剖实体间的互动，KM工具帮助建模者将高维度抽象转化为详细的生理过程模型，可以与外部的本体和知识图结合使用，增强了数据的可互操作性与可理解性。
### Conclusion
本文介绍了ApiNatomy框架，以支持研究人员在生理学研究中的数据映射。此框架通过集成知识表示与管理工具，能够促进解剖结构间复杂互动的表达，从而加速对复杂生理系统的研究开发进程。
## 12. `cs.AI` - CCrepairBench:一个高保真度基准和C++编译修复的强化学习框架 [PDF](https://arxiv.org/pdf/2509.15690), [HTML](https://arxiv.org/abs/2509.15690)
### Authors
Weixuan Sun,Jucai Zhai,Dengfeng Liu,Xin Zhang,Xiaojun Wu,Qiaobo Hao,AIMgroup,Yang Fang,Jiuyang Tang
### Background
C++编译错误的自动化修复面临着显著的挑战，对开发者的生产力至关重要。但这一领域的发展受到两大因素的限制：大规模高精度数据集的稀缺性和传统监督方法的限制，后者往往无法生成语义正确的修复。
### Innovation
本文通过引入一个全面的框架，解决了上述问题。首先，提出了CCrepair，一种通过复杂生成和验证管道构造的新型大规模C++编译错误数据集。其次，提出了由混合奖励信号引导的强化学习范式，将焦点从编译性转向修复的语义质量。最后，建立了基于大语言模型作为法官的稳健、两阶段评估系统，该系统的可靠性已被严格验证，优于一组人类专家的集体判断。
### Conclusion
本文的方法在实验中得到了验证。通过强化学习训练的Qwen2.5-1.5B-Instruct模型达到了与Qwen2.5-14B-Instruct模型相媲美的性能，验证了训练范式的有效性。我们的工作为研究社区提供了有价值的新型数据集和更有效的方法来训练和评估稳健的编译修复模型，为更加实用和可靠的自动化编程助手铺平了道路。
## 13. `cs.AI` - 改善文本到图像生成中空间关系的结构化信息 [PDF](https://arxiv.org/pdf/2509.15962), [HTML](https://arxiv.org/abs/2509.15962)
### Authors
Sander Schildermans,Chang Tian,Ying Jiao,Marie-Francine Moens
### Background
文本到图像（T2I）生成技术快速发展，但仍面临忠实捕捉自然语言描述的空间关系的挑战。先前的研究通过优化提示、空间化生成和语义细化来解决这一问题，但仍然存在局限性。
### Innovation
本文提出了一种轻量级的方法，通过tuple（元组）为基础的结构化信息增强提示，利用微调的语言模型自动转换并无缝集成到T2I管道中。实验结果表明，这种方法在空间准确性方面取得了显著提高，同时保持了整体图像质量。自动生成的元组质量与人工构造的元组相当，这种结构化信息为增强T2I生成中的空间关系提供了一种实用且便携的解决方案，解决了当前大型生成系统的关键局限性。
### Conclusion
这种结构化信息方法显著提升了T2I生成中的空间准确性，而不会牺牲整体图像质量，并提供了高质量的自动元组生成，成为现有T2I生成系统的一个重要改进。
## 14. `cs.AI` - 使用动态评估协议和后续处理环境变异在多智能体专家系统中诊断认知失败 [PDF](https://arxiv.org/pdf/2509.15366), [HTML](https://arxiv.org/abs/2509.15366)
### Authors
Andrejs Sorstkins,Josh Bailey,Dr Alistair Baron
### Background
神经网络架构的快速演变，从多层感知机到大规模的基于Transformer的模型，使得语言模型（LLMs）在具备记忆、规划和外部工具使用时能够表现出现象级的自主行为。然而，经典评估方法由于其固有的随机性及多步决策过程的特性而无法充分诊断这些自主表现。本研究旨在为专家系统提供一个诊断框架，不仅评估，还能促进将专家行为转移至LLM驱动的代理中。
### Innovation
本研究提出了一个集成有(i)精心策划的专家注解金数据集、(ii)通过受控行为突变生成的银数据集以及(iii)基于LLM的代理审判官的诊断框架，该审判官能够评分并建议具体的改进措施。这些改进措施被嵌入到向量化推荐地图中，使专家干预能够作为可重用的改进轨迹传播到多个系统的多个实例中。研究还展示了该框架在多智能体招聘助手系统中的应用实例，揭示了潜在的认知缺陷并引导代理朝着专家级推理和风格发展。
### Conclusion
该研究为随机的、工具辅助的LLMs提供了标准化和可重复的专家行为转移基础，超越了静态评估，推动了动态的专家系统改进。这种动态评估协议和后续处理环境变异方法能够有效诊断多智能体专家系统中的认知失败，并有效引导代理系统的改进，为未来研究和应用提供了坚实的基础。
## 15. `cs.AI` - 关于工业监测中基于规则和数据驱动方法的比较研究 [PDF](https://arxiv.org/pdf/2509.15848), [HTML](https://arxiv.org/abs/2509.15848)
### Authors
Giovanni De Gasperis,Sante Dino Facchini
### Background
工业监控系统，在工业4.0环境中，传统基于规则的架构正在向依赖机器学习和人工智能的数据驱动方法转变。这些系统在稳定环境中的可解释性、确定性行为和易于实现等优势使它们适用于有监管的行业和关键安全应用。然而，在复杂或不断变化的环境中，它们面临着可扩展性、适应性和性能的挑战。另一方面，数据驱动系统在检测隐含异常、实现预测维护和动态适应新条件方面表现出色。尽管这些模型的准确性很高，但他们面临数据可用性、可解释性和集成复杂性的问题。本文旨在比较这两种方法，并提出了一个评估关键属性的基本框架，同时提出有机融合基于规则的逻辑透明性和机器学习分析能力的混合解决方案作为可能的成功方向。
### Innovation
本文通过比较基于规则和数据驱动的方法，提出了一种综合框架来评估它们的关键属性，并建议将透明的基于规则的逻辑与机器学习的强大分析能力相结合作为未来工业监控的一个有希望的方向。这种两者的结合增强了系统的韧性、运营效率和信任，为更智能、更灵活的工业环境铺平了道路。
### Conclusion
本文的结论表明，工业监测未来的方向是能够利用专家知识和数据驱动洞察的智能、协同系统。这种双重方法可以增强系统的韧性、运营效率和透明度，为更灵活和智能的工业环境铺平道路。
## 16. `cs.AI` - 因果推理促进可控3D场景生成 [PDF](https://arxiv.org/pdf/2509.15249), [HTML](https://arxiv.org/abs/2509.15249)
### Authors
Shen Chen,Ruiyu Zhao,Jiale Zhou,Zongkai Wu,Jenq-Neng Hwang,Lei Li
### Background
现有的3D场景生成方法在建模物体间的复杂逻辑依赖和物理约束方面常常面临困难，限制了它们适应动态和现实环境的能力。
### Innovation
提出了一种名为CausalStruct的新框架，该框架将因果推理嵌入到3D场景生成中。利用大规模语言模型（LLMs），构建因果图，其中节点表示物体和属性，边表示因果依赖和物理约束。CausalStruct通过因果顺序和物理驱动的约束进行迭代优化场景布局，并使用PID控制器进行逐步调整。
### Conclusion
CausalStruct能够生成具有增强逻辑一致性和真实空间交互的3D场景，并具备强大的适应能力。
## 17. `cs.AI` - 压力测试以对抗诡计进行的详尽对齐培训 [PDF](https://arxiv.org/pdf/2509.15541), [HTML](https://arxiv.org/abs/2509.15541)
### Authors
Bronson Schoen,Evgenia Nitishinskaya,Mikita Balesni,Axel Højmark,Felix Hofstätter,Jérémy Scheurer,Alexander Meinke,Jason Wolfe,Teun van der Weij,Alex Lloyd,Nicholas Goldowsky-Dill,Angela Fan,Andrei Matveiakin,Rusheb Shah,Marcus Williams,Amelia Glaese,Boaz Barak,Wojciech Zaremba,Marius Hobbhahn
### Background
高能力的AI系统可能会秘密追求不一致的目标，这被称为“诡计”。因为诡计的AI会故意试图掩盖其不一致的目标和行为，所以在测量和化解诡计时需要采取不同于普通机器学习的方法。为了评估防止诡计的干预措施，需要测试在离群分布任务中的倾向性、检查缺乏诡计是否由情境感知驱动，以及验证已存在的不一致目标的抗性。研究提出使用“隐蔽行为”作为这一概念的一种代理，设计评估隐蔽行为的措施，并以此为案例研究测试详尽对齐方法。研究表明详尽对齐虽然能大幅减少隐蔽行为的发生率，但并未完全消除。这种缓解措施还能阻止代理追求隐藏目标，但仍然存在偏差行为。进一步研究表明模型的思维链往往对对齐评估表现出自我意识，这类意识降低了隐蔽行为，而缺乏这种意识则增加了隐蔽行为。因此不能排除观察到的隐蔽行为减少部分可能由情境意识驱动。虽然研究依赖于清晰的思维链进行培训、研究情境意识并展示对齐的证据，但随着模型继续偏离标准英语推理，这种依赖性会减弱。
### Innovation
本文提出了在离群分布任务、缺乏诡计和现有不一致目标的抗性等方面评估防止诡计的干预措施的方法。通过设计评估隐蔽行为的措施，并以此为案例研究测试详尽对齐方法，研究证明详尽对齐虽然有效但仍存在局限。研究成果强调了对诡计的抵御措施及其评估研究的重要性，特别是在对抗欺骗性对齐这一敌对阵营情境中更为关键。虽然当前研究未完全解决这个问题，但为其提供了可能性与挑战的见解。
### Conclusion
本文通过广泛类别中的“隐蔽行为”作为诡计的代理设计评估措施，测试详尽对齐方法，验证了其对降低隐蔽行为与代理人追求隐藏目标的有效性，但也发现了其局限。研究还发现模型的思维链展示了对对齐评估的自我意识，并提供了因果证据，发现这种意识降低了隐蔽行为，而缺乏意识则增加了隐蔽行为。因此，观察到的隐蔽行为减少部分可能由情境意识驱动。由于模型思维链与标准英语推理的差距，依赖人类可解释的思维链进行研究取证的能力会减弱。未来需进一步研究针对诡计的对齐缓解措施及其评估，特别是敌对情境下的欺骗性对齐。
## 18. `cs.AI` - 基于角色特定声音的漫画情感语音生成 [PDF](https://arxiv.org/pdf/2509.15253), [HTML](https://arxiv.org/abs/2509.15253)
### Authors
Zhiwen Qian,Jinhua Liang,Huan Zhang
### Background
本文介绍了一个从漫画生成角色特定、情感感知语音的端到端管道。现有的技术能够将漫画中的对话和情感状态转化为语音，但大多数研究缺乏对情感和角色的个性化处理。
### Innovation
文章提出了一种系统，该系统采用完整的漫画集作为输入，并生成与每个角色对话和情感状态对齐的语音。系统包括一个图像处理模块，用于进行角色检测、文本识别和情感强度识别。一个大规模语言模型综合视觉信息和故事情节的演变来分析对话和情绪。此外，语音合成通过一个针对每个角色和情感定制的声音模型进行。
### Conclusion
该研究实现了漫画的自动语音旁白生成，为提供更具互动性和沉浸式的漫画阅读体验迈出了重要一步。
## 19. `cs.AI` - 预遗忘模型：遗忘学习作为原生机制的卸载 [PDF](https://arxiv.org/pdf/2509.15230), [HTML](https://arxiv.org/abs/2509.15230)
### Authors
Rutger Hendrix,Giovanni Patanè,Leonardo G. Russo,Simone Carnemolla,Giovanni Bellitto,Federica Proietto Salanitri,Concetto Spampinato,Matteo Pennisi
### Background
基础模型已经通过跨多种模态和任务提供了稳健且可转移的表示形式，彻底改变多媒体分析。然而，由于其静态部署与日益增长的社会和监管需求相冲突，特别是隐私框架如GDPR所规定的根据请求删除特定数据的需求，传统卸载方法通常不切实际且不适合实时或持续演变系统。包括重新训练、激活编辑或知识复现的传统卸载方法 often computationally expensive, fragile, and ill-suited for real-time or continuously evolving systems.
### Innovation
本文提出了一种范式转变：将卸载重新定义为一种内置能力，而非追溯干预。引入了一种基于提示的学习框架，能够在单个训练阶段统一知识获取和去除。通过将知识绑定于特定的提示令牌（而不是编码在模型权重中），该方法在删除对应的提示时，可以实现即时卸载，无需重新训练、修改模型或访问原始数据。实验表明，该框架在保留类别上保持预测性能的同时，有效消除了被遗忘的类别，表现出强大的隐私和安全保证，包括对成员身份推断攻击的抵抗力以及即使在恶意条件下也能阻止任何残留知识的提取，确保数据保护原则的遵守，并防止对被遗忘信息的未经授权访问，使之适用于敏感和受监管环境的部署.
### Conclusion
本研究通过将可撤除性嵌入到架构本身，确立了设计模块化、可扩展且具有伦理响应性的AI模型的新基础。
## 20. `cs.AI` - EHR-MCP：通过模型上下文协议在实际医疗环境中评估大型语言模型的临床信息检索 [PDF](https://arxiv.org/pdf/2509.15957), [HTML](https://arxiv.org/abs/2509.15957)
### Authors
Kanato Masayoshi,Masahiro Hashimoto,Ryoichi Yokoyama,Naoki Toda,Yoshifumi Uwamino,Shogo Fukuda,Ho Namkoong,Masahiro Jinzaki
### Background
大型语言模型（LLMs）在医疗领域具有潜力，但由于访问电子健康记录（EHR）系统的限制，它们在医院中的部署受到限制。Model Context Protocol (MCP) 使LLMs与外部工具集成。在此研究中，通过EHR-MCP框架，结合定制的MCP工具与医院EHR数据库，并使用GPT-4.1通过LangGraph ReAct代理与之交互，评估了LLM能否通过MCP连接至EHR数据库实现自举地检索临床相关信息的能力。
### Innovation
创新点在于开发了EHR-MCP框架，结合了定制的MCP工具与医院EHR数据库，并通过GPT-4.1和LangGraph ReAct代理来实现与EHR数据库的交互。该研究验证了通过MCP工具，LLM能否在实际医疗环境中自举地检索临床相关信息，并测试了六项来源于感染控制团队的临床任务，证明了在简单任务下LLM能够实现近似完美的准确率，但在涉及时间依赖性计算的复杂任务中，性能有所下降，尤其是在错误参数或对工具结果的误解导致的问题上。此外，还探讨了通过EHR-MCP实现的安全、一致的数据访问基础设施，并为未来的研究方向提出了建议，比如将检索扩展到推断、生成以及临床影响评估等领域，促进生成式AI在临床实践中的有效整合。
### Conclusion
尽管在简单任务中LLM通过MCP工具实现了近似完美的临床数据检索，但在复杂任务中遇到了挑战。EHR-MCP提供了安全一致的数据访问基础设施，并可能作为医院AI代理的基础。未来研究应进一步扩展到推理、生成以及临床影响评估，为生成式AI在临床实践中的有效整合铺平道路。
## 21. `cs.AI` - GenCAD-3D: 使用多模态潜在空间对齐和合成数据集平衡进行CAD程序生成 [PDF](https://arxiv.org/pdf/2509.15246), [HTML](https://arxiv.org/abs/2509.15246)
### Authors
Nomi Yu(1),Md Ferdous Alam(1),A. John Hart(1),Faez Ahmed(1) ((1) Massachusetts Institute of Technology)
### Background
CAD程序作为参数化的3D几何精确构建命令序列，是工程设计过程中的核心。从非参数化数据（如点云和网格）生成CAD程序仍然是一项重要但具有挑战性的任务，通常需要大量的人工干预。目前的深度生成模型在自动化CAD生成方面受到数据集不平衡和数据量不足的限制，尤其是缺乏复杂CAD程序的表示。
### Innovation
本文提出了GenCAD-3D，一种多模态生成框架，利用对比学习对齐CAD和几何编码器之间的潜在嵌入，并结合潜在扩散模型进行CAD序列生成和检索。此外，还提出了一种名为SynthBal的合成数据增强策略，旨在平衡和扩展数据集，特别增强了复杂CAD几何的表示。实验表明，SynthBal显著提高了重建准确性，减少了无效CAD模型的生成，并在复杂几何体上显著改善了性能，超过了现有基准。
### Conclusion
这些进展对简化逆向工程并增强工程设计自动化具有重要意义。我们的数据集和代码将在项目网站上公开发布，包括一套包含51个3D打印和激光扫描部件的数据集。
## 22. `cs.AI` - 合成自助预训练 [PDF](https://arxiv.org/pdf/2509.15248), [HTML](https://arxiv.org/abs/2509.15248)
### Authors
Zitong Yang,Aonan Zhang,Hong Liu,Tatsunori Hashimoto,Emmanuel Candès,Chong Wang,Ruoming Pang
### Background
当前标准的预训练方法教导语言模型在单一文档内部的令牌之间学习因果关联，但不具备有效地建模文档间复杂关联的能力，这些关联对于模型性能的提升至关重要。因此，需要一种新的预训练方法来更好地处理文档间的相关性。
### Innovation
引入了合成自助预训练（SBP），这是一种预训练过程，首先从预训练数据集学习文档间的关系模型，然后利用这些模型生成新的大量语料库用于联合训练。这种方法可以生成超越简单同义替换的新文档，使语言模型能够更好地理解文档间的关系。此外，从理论上SBP具有自然的贝叶斯解释，自我生成的模型隐式地学习了相关文档之间的隐含概念。
### Conclusion
通过SBP，使用30亿参数模型训练了1万亿令牌，发现SBP在性能上显著优于简单的重复基线，提供了一定程度上的性能改进，表明SBP在宽容样本增强和模仿学习方面的有效性和鲁棒性。
## 23. `cs.AI` - 使用交替时态逻辑（ATL）为信念-欲望-意图（BDI）代理生成计划 [PDF](https://arxiv.org/pdf/2509.15238), [HTML](https://arxiv.org/abs/2509.15238)
### Authors
Dylan Léveillé(Carleton University)
### Background
Belief-Desire-Intention (BDI) 是一种基于代理的信念、欲望和意图的代理建模框架。计划对于BDI代理来说是核心组成部分，定义了代理实现特定目标时必须采取的一系列行动序列。目前，计划生成的主要方法通常需要大量的人工努力，并且主要关注单个代理系统，没有充分考虑多个代理之间的潜在竞争和合作。因此，在这项工作中，我们开发了一个工具，利用交替时态逻辑（ATL）自动生成BDI计划。利用ATL，所生成的计划能考虑到系统中代理之间可能出现的竞争或合作。我们通过生成一个需要代理合作才能达成共同目标的示例游戏计划来展示该工具的有效性。我们证明，所生成的计划使代理能够成功地达成这一目标.
### Innovation
开发了一个工具，使用交替时态逻辑（ATL）自动生成BDI代理的计划。通过利用ATL，可以生成考虑代理之间竞争和合作的计划，填补了现有计划生成方法在处理多代理系统时的不足，降低了手动规划的复杂性和人工成本，并展示了其对特定多代理应用场景的有效性。
### Conclusion
通过利用交替时态逻辑（ATL），所开发的工具能够自动为BDI代理生成计划，特别是在代理间存在竞争或合作关系的情况下，能够生成有效的计划，使代理能够成功地实现共同目标。
## 24. `cs.AI` - 减少行走和阅读：通过调参 free 多模态令牌修剪提高视觉-语言导航的效率 [PDF](https://arxiv.org/pdf/2509.15250), [HTML](https://arxiv.org/abs/2509.15250)
### Authors
Wenda Qin,Andrea Burns,Bryan A. Plummer,Margrit Betke
### Background
大型模型在视觉-语言导航（VLN）任务上表现出色，但在资源受限的环境中运行成本高昂。通过修剪令牌可以降低输入大小，提高效率，但可能带来性能下降。现有的修剪工作忽视了VLN特有的挑战。例如，修剪导致的信息丢失可能增加了计算成本，因为会导致路径变长。这使得识别无信息性的令牌变得困难，因此真正的效率提升未能实现。现有方法无法识别对导航不关键的令牌，因此未能显著提高效率。
### Innovation
提出了导航感知的修剪（NAP），该方法利用导航特有的属性简化了修剪过程，通过预先筛分令牌为前景和背景，比如基于视图是否能够导航来筛选图像浏览。采用大型语言模型提取导航相关的指令。之后，重点对背景令牌进行修剪，以最小化信息丢失。为了进一步防止增加导航长度，移除低重要性的导航节点，避免路径回溯问题。实验表明，NAP 显著优于现有方法，保持了更高的成功率的同时节省了超过50%的FLOPS。
### Conclusion
该研究通过提出导航感知的修剪方法NAP，成功解决了现有市场份额的修剪工作在VLN任务上面临的问题，明显提升了效率，并且在标准VLN基准测试中表现优异。
## 25. `cs.AI` - 一个跨药物共注意机制的多尺度图神经过程用于药物-药物相互作用预测 [PDF](https://arxiv.org/pdf/2509.15256), [HTML](https://arxiv.org/abs/2509.15256)
### Authors
Zimo Yan,Jie Zhang,Zheng Xie,Yiping Song,Hao Li
### Background
准确预测药物-药物相互作用（DDI）对于药物安全性和有效药物开发至关重要。然而，现有方法往往难以捕捉从局部功能基团到全局分子拓扑结构的不同尺度的结构信息，并且通常缺乏量化预测置信度的机制。
### Innovation
本文提出了一种新颖的多尺度图神经过程框架MPNP-DDI。该框架通过迭代应用独特的消息传递方案，学习不同尺度的图表示层次结构。关键在于跨药物共注意机制，动态融合这些多尺度表示以生成具有上下文感知嵌入的药物对，同时集成的神经过程模块提供了有原则的不确定性估计。广泛实验表明，MPNP-DDI在基准数据集上显著优于最先进的基线方法。基于多尺度结构特征提供的准确、可泛化且具有不确定性感知的预测，MPNP-DDI代表了药物警戒、多药耐药风险评估和精准医学的强大计算工具。
### Conclusion
通过提供基于多尺度结构特征的准确、泛化性强且具有不确定性感知的预测，MPNP-DDI在药物-药物交互预测方面代表了一个强大的计算工具，适用于药物警戒、多药耐药风险评估和精准医学。
## 26. `cs.AI` - 生成人工智能遇见无线传感：向着无线基础模型 [PDF](https://arxiv.org/pdf/2509.15258), [HTML](https://arxiv.org/abs/2509.15258)
### Authors
Zheng Yang,Guoxuan Chi,Chenshu Wu,Hanyu Liu,Yuchong Gao,Yunhao Liu,Jie Xu,Tony Xiao Han
### Background
生成型人工智能（GenAI）在计算机视觉（CV）和自然语言处理（NLP）等领域取得了显著进展，证明了其合成高保真数据并改进泛化的能力。最近，将GenAI整合到无线传感系统中引起了广泛关注。通过利用生成技术如数据增强、领域适应和去噪，无线传感应用，包括设备定位、人类活动识别和环境监测，可以得到显著提升。
### Innovation
本文从两个互补的角度调查了GenAI与无线传感的结合。首先，探讨了GenAI如何被整合到无线传感管道中，重点关注两种集成模式：作为插件来增强任务特定模型，以及直接解决传感任务的求解器。其次，分析了主流生成模型（如生成对抗网络GANs、变分自动编码器VAEs和扩散模型）的特性，并讨论了它们在各种无线传感任务中的适用性和独特优势。此外，还指出了将GenAI应用于无线传感的关键挑战，并展望了未来朝着无线基础模型（统一、预训练设计，可用于执行多样传感任务的可扩展、可适应和高效的信号理解）的方向。
### Conclusion
本文旨在通过调查GenAI与无线传感的融合来提供新的见解。未来的工作应该集中于克服现有挑战，开发一种能够针对各种传感任务进行可扩展、可适应和高效信号理解的统一、预训练的无线基础模型。
## 27. `cs.AI` - ChannelFlow-Tools: 一种用于三维受限通道流的标准化数据集创建管道 [PDF](https://arxiv.org/pdf/2509.15236), [HTML](https://arxiv.org/abs/2509.15236)
### Authors
Shubham Kavane,Kajol Kulkarni,Harald Koestler
### Background
当前的研究和实践中，三维受限通道流的模拟模型存在多样性和复杂性，这给机器学习模型的训练和验证带来了挑战。为了确保模型的可重复性和有效性，需要标准化从程序化CAD几何生成到机器学习可准备输入的端到端流程。
### Innovation
ChannelFlow-Tools提供了一个基于配置的框架，它可以标准化从程序CAD几何体生成到机器学习就绪输入和目标的3D受限通道流的整个流程。该工具链集成了几何合成、可行性检查、符号距离场（SDF）体素化、大型计算平台（HPC）上的自动求解器编排（waLBerla LBM）以及卡特莲重采样到对齐多分辨率张量。所有的阶段都由一个Hydra/OmegaConf配置文件控制，支持可重复生成并可进行层次分析。通过案例研究，生成了从Re=100到15000的数千个场景，这些场景具有多种形状和姿态。通过直接从生成的碎片中评估存储权衡、最小的3D U-Net和示例代理模型，展示了标准化表示支持可重复的机器学习培训。
### Conclusion
ChannelFlow-Tools将单一数据集的创建转变为可重复、可配置的CFD代理模型管道，通过这些标准化的表示，确保了机器学习训练的可重复性，并且能够批量生成多种场景的数据集。此工具为三维受限通道流的机器学习研究提供了一种新的标准化方法，此方法更便于进行大规模实验和模型验证。
## 28. `cs.AI` - 自引导在线数据 curation 用于扩散模型训练 [PDF](https://arxiv.org/pdf/2509.15267), [HTML](https://arxiv.org/abs/2509.15267)
### Authors
Valeria Pais,Luis Oala,Daniele Faccio,Marco Aversa
### Background
生成模型计算成本的增加重新点燃了高效数据 curation 的希望与期待。本文研究了最近开发的自引导和在线数据选择方法是否可以提高生成扩散模型训练的时间和样本效率。
### Innovation
结合联合示例选择（JEST）和自引导技术，统一直接进行快速对比实验和基准测试。研究结果表明，自引导在样本质量和多样性方面保持了持续的改进，在训练初期的应用可以与单独的自引导或均匀随机数据选择在数据效率上达到相近或略高水平。
### Conclusion
尽管在线选择在早期训练中可以带来效率增益，但稳健的样本质量改善主要由自引导驱动。指出自引导在线数据选择的局限性，并指明数据选择可能有益的情况。
## 29. `cs.AI` - 基于图神经网络的部分列生成方法在团队形成与路由中的应用 [PDF](https://arxiv.org/pdf/2509.15275), [HTML](https://arxiv.org/abs/2509.15275)
### Authors
Giacomo Dall'Olio,Rainer Kolisch,Yaoxin Wu
### Background
团队形成和路由问题是一个具有实际应用价值的优化问题，常应用于机场、医疗和维护操作等领域。文献中已经提出了基于列生成的精确解决方案方法。本文的背景是在这一背景下，针对多定价问题提出了一种新颖的部分列生成策略。
### Innovation
提出了一种基于预测哪些定价问题可能产生负次价值系数列的图神经网络定制化机器学习模型的一部分列生成新策略。这一创新方法在计算实验中证明了其有效性和优越性，特别是在时间限制严格的情况下。
### Conclusion
所提出的方法改进并超过了文献中传统的部分列生成方法，特别是在解决困难实例方面表现更佳。
## 30. `cs.AI` - 将Transformer模型视为复杂网络以分析学习动态 [PDF](https://arxiv.org/pdf/2509.15269), [HTML](https://arxiv.org/abs/2509.15269)
### Authors
Elisabetta Rocchetti
### Background
大型语言模型（LLMs）在训练过程中获得复杂能力的过程仍然是机制性可解释性中的一个关键开放问题。本项目旨在通过复杂网络理论（Complex Network Theory, CNT）这一视角来研究这些学习动态是否可以被表征。
### Innovation
引入了一种新颖的方法，将基于Transformer的LLM表示为有向加权图，其中节点表示模型的计算组件（注意头和MLP），边代表因果影响，通过基于干预的消融技术进行衡量。通过跟踪Pythia-14M模型在标准归纳任务上训练检查点的143个版本中的组件图的进化，分析了一系列图论指标，揭示了网络结构通过探索、巩固和精致的不同阶段演变。此外，还识别出稳定的信息传播组件层次结构和动态的信息收集组件集合，它们在关键学习节点的角色重新配置。
### Conclusion
此项工作证明了从组件层次的网络视角提供了一种强大的宏观视角，用于可视化和理解驱动LLMs功能电路形成的自组织原则。
## 31. `cs.AI` - 使用深度学习的显微镜图像增强最新进展：综述 [PDF](https://arxiv.org/pdf/2509.15363), [HTML](https://arxiv.org/abs/2509.15363)
### Authors
Debasish Dutta,Neeharika Sonowal,Risheraj Barauh,Deepjyoti Chetia,Sanjib Kr Kalita
### Background
显微镜图像增强对理解生物细胞和材料在微观尺度上的细节至关重要。近年来，特别是借助深度学习方法的进步，显微镜图像增强领域取得了显著进展。这篇综述性论文旨在提供该快速发展的前沿方法的概览，重点在于其演变、应用、挑战和未来方向。核心讨论集中在显微镜图像增强的关键领域：超分辨率、图像重建和去噪，每一方面都探讨了当前的趋势及其深度学习的实际应用场景。
### Innovation
利用深度学习方法来提升显微镜图像的技术创新，特别是在超分辨率、图像重建和去噪方面的应用，为显微镜图像的分析提供了新的工具和方法。这些技术的进步显著改善了显微镜图像的质量和解析度，使得更精细的生物细胞和材料的微观特征得以可视化和分析。
### Conclusion
本文综述了近年来使用深度学习方法在显微镜图像增强领域的最新进展，描述了这些方法在超分辨率、图像重建和去噪方面的多样化应用，同时也指出了仍存在的挑战，并展望了未来发展方向。
## 32. `cs.AI` - 超越错误信号：通过因果推理和自适应专家路由对多模态大型语言模型去偏 [PDF](https://arxiv.org/pdf/2509.15361), [HTML](https://arxiv.org/abs/2509.15361)
### Authors
Zichen Wu,Hsiu-Yuan Huang,Yunfang Wu
### Background
目前的多模态大型语言模型（MLLMs）在整合视觉和文本信息方面表现出显著的能力，但在复杂的多模态推理任务中经常依赖于表面的相关性，这削弱了其稳健性和泛化能力。
### Innovation
本文提出了一种新颖的因果中介去偏框架，通过对比假设实例区分核心语义和错误的文本、视觉上下文，并采用混合专家（MoE）架构和动态路由机制，选择性地激活模态特定的去偏专家。
### Conclusion
实证研究表明，该框架在多模态讽刺检测和情感分析任务中明显优于单一模态的去偏策略和现有的先进模型。
## 33. `cs.AI` - IEFS-GMB: 基于梯度记忆库和信息熵的电生理分类中特征选择方法 [PDF](https://arxiv.org/pdf/2509.15259), [HTML](https://arxiv.org/abs/2509.15259)
### Authors
Liang Zhang,Hanyang Dong,Jia-Hong Gao,Yi Sun,Kuntao Xiao,Wanli Yang,Zhao Lv,Shurong Sheng
### Background
基于深度学习的脑电图（EEG）分类对于自动检测神经性疾病、提高诊断准确性和实现早期干预至关重要。然而，EEG信号的低信噪比限制了模型性能，因此特征选择（FS）对于优化神经网络编码器学习的表示至关重要。现有的FS方法很少专门针对EEG诊断设计，大多数依赖于特定架构，缺乏可解释性，限制了其应用范围。同时，大多数方法依赖单一迭代数据，导致对变化的鲁棒性有限。因此，为了应对这些问题，本文提出了IEFS-GMB方法，这是一种基于信息熵的由梯度记忆库指导的特征选择方法。该方法构建了一个动态记忆库来存储历史梯度，通过信息熵计算特征的重要性，并应用基于熵的加权来选择有用的电生理特征。
### Innovation
本文提出IEFS-GMB方法，该方法是一种基于信息熵的由梯度记忆库指导的特征选择方法。IEFS-GMB方法构建了一个动态记忆库存储历史梯度，通过信息熵计算特征的重要性，并应用基于熵的加权来选择有用的电生理特征。这种方法在四个公开的神经性疾病数据集上的实验结果显示，与基线模型相比，带有IEFS-GMB增强的编码器的准确率提高了0.64%至6.45%，并且其性能也优于四种竞争的特征选择技术，提高了模型的可解释性，支持其在临床环境中的应用。
### Conclusion
IEFS-GMB方法在四个公开的神经性疾病数据集上取得了显著的准确率提升，优于基线模型和竞争的特征选择方法，并且提高了模型的可解释性，为临床应用提供了可能。
## 34. `cs.AI` - 模拟人类适应性视觉以实现高效和灵活的机器视觉感知 [PDF](https://arxiv.org/pdf/2509.15333), [HTML](https://arxiv.org/abs/2509.15333)
### Authors
Yulin Wang,Yang Yue,Yang Yue,Huanqian Wang,Haojun Jiang,Yizeng Han,Zanlin Ni,Yifan Pu,Minglei Shi,Rui Lu,Qisen Yang,Andrew Zhao,Zhuofan Xia,Shiji Song,Gao Huang
### Background
人类视觉高度适应性强，能够通过依次凝视任务相关区域来高效地采样复杂环境。而现有的机器视觉模型则是被动处理整幅场景，导致资源需求随着空间-时间输入分辨率和模型大小的增加而急剧增长，从而限制了进一步的发展和实际应用。现有模型缺乏主动性和适应性，无法根据任务需求灵活调整视觉感知过程。
### Innovation
AdaptiveNN是一个通用框架，它从被动的、一次性处理图像转变为积极的、可适应的视觉模型。AdaptiveNN将视觉感知过程描述为从粗略到精细的顺序决策过程，逐步识别和关注与任务相关的关键区域，并在信息组合足够丰富时主动结束观察。通过结合表示学习和自我奖励的强化学习，AdaptiveNN能够在端到端训练中实现非可微分的结构，无需额外监督凝视位置。AdaptiveNN在17个基准任务中展示了出色的表现，这包括大规模的视觉识别、细微区分、视觉搜索以及在自动驾驶和医疗场景中的图像处理等。AdaptiveNN在不牺牲精度的情况下可将推理成本降低28倍，在不同任务需求和资源预算下无需重新训练即可灵活调整，并且通过凝视模式提高了可解释性。此外，AdaptiveNN在许多情况下表现出与人类视觉行为相似性，展示了其作为研究视觉认知工具的价值潜力。
### Conclusion
AdaptiveNN提供了一种新的视角，迈向了高效、灵活和可解释的计算机视觉。通过其高效且灵活的表现，AdaptiveNN展示了在实际应用中提高计算机视觉系统效率和性能的潜力，同时它的人类相似性行为使其在理解视觉认知方面成为有价值的工具。
## 35. `cs.AI` - 基于对应关系生成部分基础的全局解释 [PDF](https://arxiv.org/pdf/2509.15393), [HTML](https://arxiv.org/abs/2509.15393)
### Authors
Kunal Rathore,Prasad Tadepalli
### Background
深度学习模型通常具有高度的不透明性，现有的解释方法往往侧重于对单个图像进行局部视觉解释。相比之下，基于概念的解释能够提供全局洞察，但需要大量的标注工作，从而导致标注成本高昂。本研究提出了一种新的方法，该方法利用从少量图像中定义的用户自定义部分标签，并高效地将其转移到更大的数据集上，从而通过聚合基于部分的局部解释生成全局符号解释，最终为大规模模型决策提供人类可理解的解释。
### Innovation
该研究提出了一种利用用户定义的部分标签从少量图像转移到大规模数据集以生成全局解释的方法，既保留了基于概念解释的全局性，又减少了标注成本，是现有解释方法的有效补充和改进。
### Conclusion
该方法能够利用少量标记数据生成大规模图像的全局可解释性，提高模型透明度和可用性，有助于推动深度学习模型的广泛应用。
## 36. `cs.AI` - 集体声音：基于LLM的聊天机器人介导的恢复者支持促进饮食障碍恢复 [PDF](https://arxiv.org/pdf/2509.15289), [HTML](https://arxiv.org/abs/2509.15289)
### Authors
Ryuhaerang Choi,Taehan Kim,Subin Park,Seohyeon Yoo,Jennifer G. Kim,Sung-Ju Lee
### Background
现有互助恢复叙事为饮食障碍（ED）患者提供了独特的支持，超越了专业咨询或非专业人士的导师支持，有助于患者重建希望并实现持续康复。然而，这种方式受到缺乏与恢复者相关的项目以及恢复者自身可能面临的风险的限制，如复发病风险。本研究旨在通过设计一种复原者人设的聊天机器人，探索复原者支持的有效性，以弥补这一不足。
### Innovation
本研究创新地设计了一种复原者人设的聊天机器人（RecoveryTeller），通过采用复原者的身份来提供支持，以此来复制饮食障碍康复叙事的支持效果。此外，研究还对比了复原者人设与非专业导师人设的聊天机器人之间的效果差异，探讨了情感信任和认知信任之间的张力如何影响聊天机器人的接受度和应用方式。
### Conclusion
研究结果表明，复原者人设的聊天机器人能够激发更强的情感共鸣，但情感信任和认知信任之间的张力使参与者认为这两种不同的人设是互补关系而非替代关系。这为心理健康聊天机器人的人物设计提供了设计建议。
## 37. `cs.AI` - 大型视觉模型能够解决心理旋转问题 [PDF](https://arxiv.org/pdf/2509.15271), [HTML](https://arxiv.org/abs/2509.15271)
### Authors
Sebastian Ray Mason,Anders Gjølbye,Phillip Chavarria Højbjerg,Lenka Tětková,Lars Kai Hansen
### Background
心理旋转是评估人类空间推理能力的关键测试，对于理解感知如何支持认知至关重要。尽管现代视觉变压器在视觉识别方面取得了巨大成功，但尚不清楚这些模型是否具备类似的心理旋转能力。本研究通过系统评估了ViT、CLIP、DINOv2和DINOv3在多种心理旋转任务上的表现，从简单的类似Shepard和Metzler研究人类认知的积木结构到更复杂的积木图形、三种类型的文本和照片级逼真的物体，来评估这些模型的心理旋转能力。通过逐层探究模型表示，研究了这些网络在哪种情况下成功。研究表明，自监督的ViT比监督的ViT更好地捕捉几何结构；中间层的表现优于末层；任务难度随着旋转复杂性和遮挡的增加而增加，这与人类的反应时间一致，表明嵌入空间表示存在类似的约束。
### Innovation
本研究系统评估了四种不同的视觉变压器模型在多种复杂心理旋转任务上的性能，特别是通过逐层探究模型表示来揭示模型处理心理旋转任务的关键机制，展示了自监督的ViT模型在几何结构捕捉上的优势，以及模型中间层优于末层的表现。该研究提供了对视觉变压器处理心理旋转任务机制的深入理解。
### Conclusion
研究发现，自监督的ViT模型优于监督的ViT模型，能够更好地处理几何结构。中间层的表现优于末层。任务的复杂度随着旋转的复杂性增加和遮挡的出现而增加，这与人类的实验结果一致。这些发现表明，视觉变压器模型在心理旋转任务中的表现受制于嵌入空间表示的约束。
## 38. `cs.AI` - 用于伊斯兰文本的高效且多功能多语言信息检索模型：在实际场景中的开发与部署 [PDF](https://arxiv.org/pdf/2509.15380), [HTML](https://arxiv.org/abs/2509.15380)
### Authors
Vera Pavlova,Mohammed Makhlouf
### Background
尽管在多语言信息检索（MLIR）方面取得了最近的发展进步，但在研究和实际部署之间仍存在显著差距。许多研究仅在孤立的环境中评估MLIR性能，这限制了它们在实际场景中的应用。考虑到古兰经多语言语料库的独特特点，本工作旨在探索开发适用于伊斯兰领域的高效且多功能的即席检索系统，以满足用户多语言的信息需求。
### Innovation
本研究提出了将跨语言和单语言技术混合的方法，设计了11种检索模型，包括四种不同的训练方法：单语训练、跨语言训练、翻译训练所有和一种新的混合方法。研究结果表明，这种方法在不同的检索场景中表现出色。此外，详细分析了不同训练配置对嵌入空间的影响及其对多语言检索效果的含义。最后，讨论了部署考虑因素，强调了一种通用且轻量级单一模型在实际多语言信息检索应用中的成本效益。
### Conclusion
研究结果表明，混合方法在不同检索场景下表现出良好的性能。不同训练配置对嵌入空间和多语言检索有效性有影响。最终，强调了部署单一通用且轻量级模型的成本效益，这对于实际的多语言信息检索应用具有重要意义。
## 39. `cs.AI` - 深度学习与抽象总结在放射报告中的应用：对PEGASUS模型家族在稀缺数据情况下的实证研究 [PDF](https://arxiv.org/pdf/2509.15419), [HTML](https://arxiv.org/abs/2509.15419)
### Authors
Claudio Benzoni,Martina Langhals,Martin Boeker,Luise Modersohn,Máté E. Maros
### Background
尽管人工智能快速发展，但在医学等敏感和数据受限的领域，抽象总结仍旧面临挑战。随着医学影像数量增多，自动工具在复杂医学文本总结中的重要性日益提升。
### Innovation
本文研究了非领域特定抽象总结编码器-解码器模型族在放射学报告数据上的微调过程，并提供了避免过拟合和欠拟合的见解。研究使用了PEGASUS和PEGASUS-X模型，在一个中型公开放射学报告数据集上进行实验，评估了不同训练数据量下的模型表现差异。
### Conclusion
研究结果表明PEGASUS模型存在不同阶段表现，而对PEGAUS-X模型，使用更大规模的检查点会导致性能下降。该工作突显了在稀缺数据条件下微调高表达能力模型的挑战和风险，并为未来在专业领域中总结模型的更 robust 微调策略奠定了基础。
## 40. `cs.AI` - 双模式视觉系统用于脑机接口：结合SSVEP和P300响应 [PDF](https://arxiv.org/pdf/2509.15439), [HTML](https://arxiv.org/abs/2509.15439)
### Authors
Ekgari Kasawala,Surej Mouli
### Background
在脑机接口（BCI）系统中，稳定状态视诱发电位（SSVEP）和P300响应因其高速信息传输速率（ITR）和最少的训练需求而得到广泛应用。这些神经生理信号在外部设备控制方面显示出强大的效用和灵活性，但传统实施主要依靠液晶显示器（LCD）视觉刺激，这在实际部署场景中存在局限性。
### Innovation
该研究开发并评估了一种基于LED的新型双模式刺激装置，旨在通过结合SSVEP和P300模式来提升SSVEP分类精度。该系统采用4种不同的频率（7 Hz、8 Hz、9 Hz和10 Hz）对应于方向控制，同时通过实时特征提取实现任务意图识别，并且在信号处理算法中成功区分类别。
### Conclusion
提出的混合系统实现了86.25%的平均分类精度，平均ITR为42.08比特每分钟（bpm）。
## 41. `cs.AI` - 评估本地LLM解决复杂编程挑战的局限性 [PDF](https://arxiv.org/pdf/2509.15283), [HTML](https://arxiv.org/abs/2509.15283)
### Authors
Kadin Matotek,Heather Cassel,Md Amiruzzaman,Linh B. Ngo
### Background
本文研究了当前开源、本地托管的大语言模型（LLMs）在处理具有扩展问题描述和上下文的复杂竞争编程任务方面的性能。这些竞争编程任务包括来自Kattis的3,589个问题，涵盖了涉及代码的大约八种模型，这些模型的参数范围从67亿到90亿不等。研究基于原来的针对AI驱动代码生成评估的框架（FACE），改造了流程，使其能够在Ollama运行时完全离线运行，将FACE复杂的单个问题目录树简化为少量合并的JSON文件，并增加了强大的检查点功能，以便在失败后多日运行可以恢复。研究表明，本地模型的整体准确率为50%，最佳模型的接受率仅为专用模型Gemini 1.5和ChatGPT-4的一半。这些发现揭示了私人、成本控制的LLM部署与最先进的专有服务之间的持续差距，同时也强调了开放模型的快速进展和评估流程的实际效益，组织可以在内部硬件上复制此流程。
### Innovation
本研究在原有的FACE框架基础上改造了流程，使其完全离线运行，并通过Ollama运行时实现了简化的问题目录树和检查点功能的添加。这些创新使研究能够评估多种大语言模型在处理复杂编程问题时的性能，并展示了它们与专有服务的主要差距。
### Conclusion
当前开源、本地托管的大语言模型在处理复杂的编程任务方面表现一般，尽管这些模型有快速的进展，但它们在准确性方面仍然与专有模型有一段差距。研究展示了评估流程的工作效率，组织可以在内部硬件上复制此流程。
## 42. `cs.AI` - 对抗攻击中的语音音素对说话人身份的影响 [PDF](https://arxiv.org/pdf/2509.15437), [HTML](https://arxiv.org/abs/2509.15437)
### Authors
Daniyal Kabir Dar,Qiben Yan,Li Xiao,Arun Ross
### Background
在自动语音识别（ASR）和说话人验证中，对抗性扰动通过引入难以察觉的人耳信号修改，却能显著改变系统输出。尽管端到端的ASR模型受到了广泛研究，但对于这些扰动背后的音素基础及其对说话人身份的影响却尚未得到充分探索。
### Innovation
本文在音素级别对对抗音频进行分析，揭示了扰动如何利用系统混淆，如元音中央化和辅音替换，这些扭曲不仅误导了转录，还破坏了对说话人验证至关重要的音素线索，导致身份漂移。使用DeepSpeech作为目标模型，生成了针对性的对抗性例子并评估了它们对真实和冒充样本说话人嵌入的影响。
### Conclusion
16个不同音素的语音短语结果表明，对抗音频同时引发了转录错误和身份漂移，突显出需要音素感知的防御措施以确保ASR和说话人识别系统的稳健性。
## 43. `cs.AI` - PRISM：基于相位增强的径向图像特征映射框架用于生成AI图像的标识 [PDF](https://arxiv.org/pdf/2509.15270), [HTML](https://arxiv.org/abs/2509.15270)
### Authors
Emanuele Ricco,Elia Onofri,Lorenzo Cima,Stefano Cresci,Roberto Di Pietro
### Background
随着生成式AI（生成内容的模型）的普及，用户需要能够识别这些内容的来源模型。特别是商业环境中，用户期望有保证的内容来源，并且希望模型的内部细节不可见的情况下也能进行准确的模型标识。这方面的需求亟待满足。因此，本研究介绍了PRISM，这是一种可扩展的基于径向相位增强图像签名映射的框架，用于标识AI生成的图像。PRISM利用域变换中的振幅和相位信息来捕获模型的特征，通过线性判别分析对输出进行聚类，从而在不同场景下都能实现可靠的标识结果，尤其是在内部细节不可见的情况下。为了支持该工作，研究者构建了一个包含36,000张由六种生成模型生成的图像的数据集PRISM-36K，并在该数据集上实现了92.04%的标识准确率。PRISM还在四个基准测试中实现了81.60%的平均准确率，以及在真实图像与生成图像之间的检测任务中获得88.41%的平均准确率，其中在GenImage基准测试中达到95.06%的最佳结果。这表明了基于频域的特征提取方法在模型标识中的有效性，提供了一个在生成式AI系统中实现问责制和信任的可行方案。
### Innovation
PRISM是一种新的模型标识方法，利用图像在频域上的相位和振幅信息来捕获模型的特征。此方法通过对图像进行径向变换，并结合线性判别分析，来实现复杂的模型标识任务，特别适用于模型内部细节无法访问的情况。该方法还构建了PRISM-36K这一前沿的数据集，包含由不同模型生成的图像，以支持该技术的训练和验证。研究结果表明PRISM不仅适用于不同架构和数据集的模型标识，还在真实与虚假图像的检测任务中表现出色，对于实现生成式AI系统的问责制具备重要作用。
### Conclusion
PRISM通过引入新的傅里叶变换方法和特征聚类分析，提高了模型标识的准确性和鲁棒性，特别适用于不可见的内部模型信息。该研究的结果表明，在生成式AI环境中，基于频域的方法是有效的，能够实现对模型源头的准确识别，从而增强AI系统的可信度和透明度。
## 44. `cs.AI` - PILOT：使用心理和语言输出导向调控合成数据生成 [PDF](https://arxiv.org/pdf/2509.15447), [HTML](https://arxiv.org/abs/2509.15447)
### Authors
Caitlin Cisar,Emily Sheffield,Joshua Drake,Alden Harrell,Subramanian Chidambaram,Nikita Nangia,Vinayak Arannil,Alex Williams
### Background
生成式AI应用程序常利用用户画像作为生成合成数据的指导机制，但由于依赖自然语言表示，导致模型在生成时作出意外推断，限制了对输出的精确控制。
### Innovation
提出了PILOT（心理和语言输出导向）框架，这是一种两阶段的大型语言模型调控方法，通过结构化的心理语言资料进行调控。第一阶段将自然语言用户画像描述转化为多维度的标准评分矩阵；第二阶段利用这些评分矩阵指导数据生成在量化的变化轴线上进行。
### Conclusion
PILOT在三种最先进LLM（Mistral Large 2，Deepseek-R1，LLaMA 3.3 70B）上进行评估，结果显示基于模式的调控方法显著减少了人物重复，提高了输出的一致性。HPS（混合人物-模式调控）方法在保持输出多样性的同时，维持了构架的一致性。专家语言评估证实，PILOT在所有调控条件下均保持高质量的回复，各调控方法之间无统计差异。
## 45. `cs.AI` - 将视觉皮层横向连接特性整合到CNN中：递归激活和兴奋性-抑制性分离 [PDF](https://arxiv.org/pdf/2509.15460), [HTML](https://arxiv.org/abs/2509.15460)
### Authors
Jin Hyun Park,Cheng Zhang,Yoonsuck Choe
### Background
原始的卷积神经网络（CNNs）及其现代更新如ResNet深受哺乳动物视觉系统的启发。这些模型包括传入连接（视网膜和LGN到视觉皮层）和远程投射（不同视觉皮层区域之间的连接）。然而，在哺乳动物的视觉系统中，每个视觉皮层区域内部存在连接，被称为侧向连接（或横向连接）。这种特性可以类比为CNN特征图内的连接，但在当前的CNN模型中缺失此重要架构特征。
### Innovation
提出了在标准CNN框架中模拟侧向连接的方法，并测试其益处及其与生物视觉系统的关联性。重点介绍了侧向连接的两个主要架构特征：（1）递归激活；（2）兴奋性和抑制性连接的分离。展示具有权重共享的递归CNN等同于侧向连接，提出一种自定义损失函数以分离兴奋性和抑制性权重。通过增加这两种特性，提高了分类准确率，并且模型的激活特性和连接特性表现出与生物视觉系统相似的特性。
### Conclusion
期望该方法有助于使CNN更接近其生物对应物，并更好地理解视觉皮层计算的原则。
## 46. `cs.AI` - 隐动力学运动重定位用于人类至人形机器人的模仿学习 [PDF](https://arxiv.org/pdf/2509.15443), [HTML](https://arxiv.org/abs/2509.15443)
### Authors
Xingyu Chen,Hanyu Wu,Sikai Wu,Mingliang Zhou,Diyun Xiang,Haodong Zhang
### Background
人类与人形机器人模仿学习旨在从人类运动中学习人形机器人的全身控制器。运动重定位是使机器人能够获取行走技能参考轨迹的关键步骤。然而，当前方法主要是在帧与帧之间进行运动重定位，缺乏可扩展性。是否有更有效的方法直接将大规模人类运动转换为机器人可执行运动？
### Innovation
本文提出了一种名为隐动力学运动重定位（IKMR）的新颖高效且可扩展框架，该框架同时考虑了运动学和动力学。IKMR 预训练运动拓扑特征表示和双重编码器-解码器架构以学习运动域映射，并结合模仿学习与运动重定位网络，通过细化生成符合物理约束的运动轨迹，实现大规模物理可实现运动重定位，并直接训练和部署全身控制器来追踪其重定位轨迹。
### Conclusion
我们在模拟器和真实机器人上对全尺寸人形机器人的实验中验证了所提框架的有效性。
## 47. `cs.AI` - 使用多模态共有嵌入预测架构的成像和临床特征的自监督学习 [PDF](https://arxiv.org/pdf/2509.15470), [HTML](https://arxiv.org/abs/2509.15470)
### Authors
Thomas Z. Li,Aravind R. Krishnan,Lianrui Zuo,John M. Still,Kim L. Sandler,Fabien Maldonado,Thomas A. Lasko,Bennett A. Landman
### Background
多模态模型在肺结节诊断中的发展受限于标签数据稀缺性和模型对训练分布的过拟合倾向。
### Innovation
利用纵向和多模态档案进行自我监督学习以应对这些挑战，开发了一个多模态联合嵌入预测架构 (JEPA) 进行预训练，并通过监督微调表明该方法在内部组中的表现优于未正则化的多模态模型和单模态影像模型，但在外部组中的表现欠佳。同时，开发了一个合成环境来描述JEPA可能表现不佳的场景。
### Conclusion
该研究创新地利用了未标记的多模态医学档案以改善预测模型，并在肺结节诊断中展示了其优势和局限性。
## 48. `cs.AI` - ORCA：视觉语言模型中的生成与对抗鲁棒性主动推理 [PDF](https://arxiv.org/pdf/2509.15435), [HTML](https://arxiv.org/abs/2509.15435)
### Authors
Chung-En Johnny Yu,Hsuan-Chih(Neil)Chen,Brian Jalaian,Nathaniel D. Bastian
### Background
大型视觉-语言模型虽然表现出强大的多模态能力，但依然容易受到内在错误和外部攻击导致的幻觉，这限制了它们在现实世界应用中的可靠性。现有方法主要针对幻觉进行修正，但ORCA旨在通过一套小视觉模型的推理链（观察-推理-批判-行动）来提高事实准确性，并增强对抗鲁棒性，而无需使用模型内部信息或重新训练。
### Innovation
ORCA 提出了一种主动推理框架，通过在测试时使用一套小型视觉模型结构化推理，能够提高预训练视觉-语言模型的事实准确性和对抗鲁棒性，尤其能够减轻对象级别的幻觉，并且可以在不进行对抗训练或防御机制的情况下表现出对抗鲁棒性。ORCA 还记录了推理过程，支持可审计的决策。
### Conclusion
ORCA 在幻觉基准上的性能提高了 3.64% 到 40.67%，在对抗扰动情况下提高了 20.11% 的平均准确率。结合防御技术后，在对抗扰动的情况下进一步提高了性能，最高增幅达到 48.00%。这些结果表明，ORCA 有可能为构建更可靠和健壮的多模态系统提供一条有前景的道路。
## 49. `cs.AI` - 我在哪添加蛋？：探究AI创意共写系统中的自主权与所有权 [PDF](https://arxiv.org/pdf/2509.15440), [HTML](https://arxiv.org/abs/2509.15440)
### Authors
Dashiel Carrera,Jeb Thomas-Mitchell,Daniel Wigdor
### Background
AI共写系统挑战了长期以来关于自主权和所有权在创意过程中的概念，这阻碍了它们的广泛应用。为了应对这一挑战，本研究探讨了AI在创意共写中自主权和所有权的概念。通过对商业系统的文献综述，这研究开发了三个具有相同功能但界面隐喻不同的共写系统：代理性、工具性和魔法性。通过与专业和非专业作家的访谈（n = 18），研究探索了这些隐喻如何影响参与者对控制感和作者身份的感受。研究结果归类了自主权和所有权的亚类型，并强调工具性隐喻如何改变作者的预期控制点，而代理性隐喻则强调概念性贡献.
### Innovation
本研究开发了三种具有相同功能但界面隐喻不同的共写系统，并通过专业和非专业作家的访谈，调查这些隐喻如何影响参与者对控制感和作者身份的感受。研究结果提出了自主权和所有权的分类，并强调工具性隐喻如何改变作者的预期控制点，而代理性隐喻则强调概念性贡献。研究进一步提出了AI共写系统的设计建议，强调隐喻如何塑造用户体验和创意实践.
### Conclusion
研究建议AI共写系统的界面设计应考虑使用隐喻，因为这不仅引导控制预期，还框定了作者身份的概念。
## 50. `cs.AI` - 使用表示相似性分析比较计算病理学基础模型 [PDF](https://arxiv.org/pdf/2509.15482), [HTML](https://arxiv.org/abs/2509.15482)
### Authors
Vaibhav Mishra,William Lotter
### Background
在计算病理学(CPath)领域，基于基础模型的方法正在不断发展，因为它们有可能促进多种下游任务。尽管已有研究评估了这些模型在不同任务上的表现，但关于这些模型学习表示结构和变异性方面的了解仍然有限。本文使用计算神经科学中流行的技术，系统地分析了六个CPath基础模型的表示空间，旨在深入理解这些模型的表示结构和特点。
### Innovation
本文创新地应用了表示相似性分析的方法，评估了六个CPath基础模型在HE染色切片图像上的表示结构。研究发现，虽然同一训练范式的模型并不一定具有更高的表示相似性，但所有模型都显示出了较高的切片依赖性和较低的疾病依赖性。此外，对于所有模型而言，染色归一化降低了切片依赖性，同时揭示了视觉与语言训练范式对模型表示结构的不同影响。这项研究为改进模型的鲁棒性、指导模型集成策略以及洞察训练范式对模型表示结构的影响提供了重要依据。
### Conclusion
研究结果强调了在多疾病切片和不同训练集上增加数据多样性的必要性，以提高模型的鲁棒性。此外，还为探查基础模型的内部表示提供了框架，有助于确保其在医疗成像领域的有效开发和应用。
## 51. `cs.AI` - CAGE:  Continuity-Aware edGE Network Unlocks Robust Floorplan Reconstruction [PDF](https://arxiv.org/pdf/2509.15459), [HTML](https://arxiv.org/abs/2509.15459)
### Authors
Yiyi Liu,Chunyang Liu,Weiqin Jiao,Bojian Wu,Fashuai Li,Biao Xiong
### Background
传统的基于角落的多边形表示方法在处理噪声和不完整观测结果时非常敏感，容易导致布局碎片化或不合理。近年来，线组方法利用结构线索来提高鲁棒性，但仍难以恢复精细的几何细节。为此，本文提出了CAGE（Continuity-Aware edGE）网络，这是一种直接从点云密度图重建矢量房间平面图的鲁棒框架。
### Innovation
本文提出了一种基于边的原生表示法，将每个墙壁段视为一个定向、几何连续的边，以确保无隙、拓扑有效的空间边界，同时也增强了鲁棒性并减少了异常现象。为了实现这一设计，开发了一种双查询变压器解码器，可以结合扰动和潜在查询在去噪框架中，不仅稳定了优化，还加快了收敛速度。实验结果表明，CAGE在Structured3D和SceneCAD数据集上实现了最先进的性能，在房间、角落和角度上的F1分数分别为99.1%、91.7%和89.3%，展示了跨数据集的强大泛化性能。
### Conclusion
CAGE网络通过提供鲁棒的框架直接从点云密度图重建矢量平面图，在实际情况中表现出优秀的性能，并通过详细的实验验证了其创新的有效性。
## 52. `cs.AI` - 探索模拟城市中车辆导航的多模态隐式行为学习 [PDF](https://arxiv.org/pdf/2509.15400), [HTML](https://arxiv.org/abs/2509.15400)
### Authors
Eric Aislan Antonelo,Gustavo Claudio Karl Couto,Christian Möller
### Background
标准的行为克隆（BC）方法在面对相同场景下存在多种有效行为的多模态驾驶决策时表现不佳。本文旨在探讨如何通过引入隐式行为克隆（IBC）和能量基于模型（EBMs）的方式更好地捕捉这种多模态性。试验通过CARLA模拟器中的鸟瞰图输入验证了提出的改进隐式行为克隆（DA-IBC）的有效性。
### Innovation
本文提出了数据增强隐式行为克隆（DA-IBC），通过扰动专家行为形成IBC训练的反例，并采用更好的初始化进行无导数推理，从而改善了学习过程。实验结果表明，在评估多模态行为学习能力时，DA-IBC在CARLA模拟器的城乡驾驶任务中优于标准的IBC。同时，学习到的能量景观能够表示多模态行为的概率分布，而BC方法未能达到这一效果。
### Conclusion
实验结果证明了DA-IBC的有效性，通过引入数据增强和更好的初始化，它能够更好地处理多模态行为的学习问题，在模拟城市中的车辆导航任务中表现优异。
## 53. `cs.AI` - Region-Aware Deformable Convolutions [PDF](https://arxiv.org/pdf/2509.15436), [HTML](https://arxiv.org/abs/2509.15436)
### Authors
Abolfazl Saheban Maleki,Maryam Imani
### Background
传统的可变形卷积（Deformable Convolution）仅限于固定的四边形采样区域，无法灵活地调整其形状和大小来匹配图像内容。这限制了它们在复杂图像结构适应方面的表现能力。RAD-Conv通过使用每个核元素的四个边界偏移，创建了灵活的矩形区域，这些区域可以根据图像内容动态调整大小和形状。
### Innovation
RAD-Conv通过引入每个核元素的四个边界偏移，创建灵活的矩形区域，能够根据图像内容动态调整大小和形状。这样，RAD-Conv结合了注意力机制的可适应性和标准卷积的效率，通过这种方式，它可以捕获局部细节和长距离依赖关系，即使使用小巧的1x1内核也能有效地处理信息。这种设计提供了在构建更具表现力和高效的视觉模型中实用的解决方案，弥补了刚性卷积架构和计算密集型基于注意力的方法之间的鸿沟。
### Conclusion
RAD-Conv通过灵活调整其形状和大小，提高了神经网络对复杂图像结构的适应能力。它通过结合注意力机制的可适应性和标准卷积的效率，适用于构建更具表现力和高效的视觉模型，解决了传统可变形卷积的局限性。
## 54. `cs.AI` - 层次自专注要注意：将神经关注机制推广到多尺度问题 [PDF](https://arxiv.org/pdf/2509.15448), [HTML](https://arxiv.org/abs/2509.15448)
### Authors
Saeed Amizadeh,Sara Abdali,Yinheng Li,Kazuhito Koishida
### Background
transformers和其注意力机制在机器学习领域引发革命，最初应用于语言数据，后迅速扩展到图像、视频等不同信号几何的数据模态中。尽管具有广泛适用性，但将注意力机制推广到不同尺度和多模态数据场景时却面临挑战。现有的尝试多依赖于没有系统性的启发式方法，难以适应具有不同结构的类似问题。因此，需要一种新的方法从基本原理出发来解决这一问题，通过引入数学构造，从熵最小化原则出发推导出有效的注意力机制，并提出动态规划算法进行高效计算，从而提高模型在多尺度多模态环境下的性能和效率。
### Innovation
提出了数学构造以表征多模态和多尺度数据，从熵最小化的第一原则出发推导出了神经注意机制，引入动态规划算法以高效计算，并展示了该层次注意力机制不仅可以在层次和多模态设置中从零开始训练变压器模型，还能在预训练后注入层次信息，形成更高效的零样本模型。这一方法在推广神经注意机制的应用范围方面具有创新性。
### Conclusion
通过引入层次注意机制，本文不仅展示了建立在层次和多模态环境中的变压器模型的训练能力，也展示了在已经训练好的经典变压器模型中加入层次信息后，更高效的性能。这一创新不仅扩展了注意力机制的应用范围，也为未来研究提供了新的思路。
## 55. `cs.AI` - 大型语言模型对失业和收入的（短期）影响 [PDF](https://arxiv.org/pdf/2509.15510), [HTML](https://arxiv.org/abs/2509.15510)
### Authors
Danqing Chen,Carina Kane,Austin Kozlowski,Nadav Kunievsky,James A. Evans
### Background
自2022年底ChatGPT发布以来，大型语言模型（LLMs）迅速普及，伴随而来的是对生产力提升的豪言壮语和对就业机会流失的担忧。本文研究了LLM在不同职业暴露水平下的短期劳动力市场影响，通过对比具有不同暴露水平的职业之间的收入和失业率，利用合成差异差异（Synthetic Difference in Differences）方法，估计了LLM暴露对收入和失业率的影响。
### Innovation
采用了合成差异差异（Synthetic Difference in Differences）方法来估计LLM暴露对收入和失业率的具体影响，这是研究此类问题的一种创新方法。这种方法能够更准确地捕捉到特定人群的动态变化，从而更有效地衡量技术对实际劳动力市场的具体影响。
### Conclusion
研究发现，高度暴露于LLM的职业群体在ChatGPT推出后获得了收入增长，而失业率保持不变。这表明，劳动力市场对LLM的初步调整主要通过影响收入水平而非工作岗位再分配来进行。
## 56. `cs.AI` - mucAI在BAREC共享任务2025中的表现：走向具备不确定意识的阿拉伯可读性评估 [PDF](https://arxiv.org/pdf/2509.15485), [HTML](https://arxiv.org/abs/2509.15485)
### Authors
Ahmed Abdou
### Background
该论文针对阿拉伯语细粒度可读性分类任务，介绍了在BAREC 2025共享任务中的方法。背景是阿拉伯教育评估需要准确的可读性分类，以便人类评审者能够更高效地评估文本的可读性。原有的分类方法在高惩罚性误分类方面存在不足，需要一种能够提高分类准确率的新方法。
### Innovation
论文提出了一种简单且模型无感知的后处理技术，通过应用符合预测生成具有覆盖率保证的预测集，然后使用softmax重新规范化概率来计算加权平均。这种方法在保持统计保证的同时提高了实用性，具体表现为空心矩阵加权κ（QWK）提高了1-3个百分点，尤其在严格跟踪下的句子级测试和盲测试中分别达到了84.9%和85.7%，文档级为73.3%。
### Conclusion
该方法验证了在不同底层模型下的稳健性，并为阿拉伯教育评估提供了一种结合统计保证与实际可用性的解决方案，使人类评审者能够专注于有限实际可接受的可读性级别。
## 57. `cs.AI` - 使用可验证复合奖励进行奖励欺骗缓解 [PDF](https://arxiv.org/pdf/2509.15557), [HTML](https://arxiv.org/abs/2509.15557)
### Authors
Mirza Farhan Bin Tarek,Rahmatollah Beheshti
### Background
Reinforcement Learning from Verifiable Rewards (RLVR) 最近展示了大型语言模型（LLMs）能够在没有直接监督的情况下发展出自己的推理能力。然而，在医学领域，特别是在问题解答中，推理阶段容易出现奖励欺骗现象，这会导致模型生成不恰当或非标准的推理结果，影响准确性。
### Innovation
该工作提出了一种复合奖励模型，用于处罚两种主要的奖励欺骗行为：一是提供最终答案时不进行推理，二是使用非标准推理格式来利用奖励机制。通过引入这种带特定惩罚的复合奖励函数，作者在实验中证明了在 RLVR 中加入新的奖励模型可以减少奖励欺骗，提高模型的推理格式的准确性，从而提升模型的可靠性和准确性，相较于基线模型表现更好。
### Conclusion
该方法为减少奖励欺骗、提高使用 RLVR 的模型可靠性迈出了重要一步。
## 58. `cs.AI` - 基于扩散的跨模态特征提取方法在多标签分类中的应用 [PDF](https://arxiv.org/pdf/2509.15553), [HTML](https://arxiv.org/abs/2509.15553)
### Authors
Tian Lan,Yiming Zheng,Jianxin Yin
### Background
多标签分类有着广泛的应用，并依赖于能够捕捉多标签之间交互作用的强大表示能力。现有的方法通常需要复杂的模型和计算资源来处理图像和文本之间的多标签关系。
### Innovation
作者提出了一个称为Diff-Feat的简单但有效的框架，该框架从预先训练的扩散-变压器模型中提取图像和文本的中间特征，并将它们融合用于下游任务。该方法在图像任务中，在扩散过程中的中间步骤和中间块中找到了最具鉴别能力的特征，在语言任务中，最好的特征位于噪声消除步骤和最深的块中。此外，作者发现了一种神秘的现象，即在多种数据集上，“第12层”在图像分类任务中始终表现出色。该方法提出了一种启发式局部搜索算法，能够在几种候选方案中精确定位最优的跨模态特征对应关系，而不需要进行耗时的网格搜索。这些精选特征的简单融合和线性投影实现超越了其他强CNN、图模型和Transformer基线方法的最佳性能，特别是在MS-COCO-enhanced和Visual Genome 500数据集上取得了最佳表现。此外，t-SNE和聚类结果表明，Diff-Feat形成的语义簇比单模态基线更为紧密。
### Conclusion
该研究提出了一种基于扩散的跨模态特征提取方法，该方法能有效捕捉图像和文本之间的多标签交互，并在多个下游分类任务中取得了显著的性能。这种方法不仅简单有效，而且通过启发式方法克服了传统的穷搜索问题。
## 59. `cs.AI` - 解释增强的AI监督控制以增强多机器人系统的鲁棒性 [PDF](https://arxiv.org/pdf/2509.15491), [HTML](https://arxiv.org/abs/2509.15491)
### Authors
Reza Pirayeshshirazinezhad,Nima Fathi
### Background
本文介绍了多机器人系统的可解释AI增强监督控制框架，结合了定时有限自动机监护人、鲁棒连续控制（基于Lyapunov的控制器和边界层的滑模控制器）以及解释性预测器。这些方法用于管理多代理系统的安全、可审计模式切换以及在不同环境下的鲁棒性能。验证方法在空间探测和自主水下航行器（AUV）中应用，尽管这些系统面对的环境不同，但通过这些试验展示了该方法的安全性、鲁棒性和准确性，以及对未来资源有限和安全关键的多代理机器人系统具有广泛的应用前景。
### Innovation
本文创新之处在于提出了一种结合了定时有限自动机监护人、鲁棒连续控制和解释性强的预测器的多机器人系统的监督控制框架。该框架通过Monte Carlo驱动的优化提供了透明的实时权衡，以实现资源有限和安全关键的多代理机器人系统的高效性能优化。验证了该方法在空间探测和AUV中的适用性，显示了其在不同环境下的鲁棒性和可解释性。
### Conclusion
本文提出了一种基于解释性强的AI增强的多机器人系统监督控制框架，展示了其在多环境中的适应性和鲁棒性，强调了该方法在资源受限和安全关键的多代理机器人系统中的实际应用价值。
## 60. `cs.AI` - GUI-ARP: 提升GUI代理定位能力的自适应区域感知方法 [PDF](https://arxiv.org/pdf/2509.15532), [HTML](https://arxiv.org/abs/2509.15532)
### Authors
Xianhang Ye,Yiqing Li,Wei Dai,Miancan Liu,Ziyuan Chen,Zhangye Han,Hongbo Min,Jinkui Ren,Xiantao Zhang,Wen Yang,Zhi Jin
### Background
现有的GUI可视化界面定位方法在高分辨率截图中难以实现精细定位。这主要是因为高分辨率截图中包含了大量冗余信息，导致定位精度受到限制。针对这一问题，该论文提出了一种新的框架GUI-ARP，该框架通过自适应多阶段推理，结合自适应区域感知（ARP）和自适应阶段控制（ASC）技术，能够动态利用视觉注意力精简任务相关的区域，根据不同复杂度场景自动调整推理策略，从而提高了定位准确性与效率。该方法通过两个阶段的训练管道实现，该训练管道结合监督微调和基于群相对策略优化（GRPO）的强化微调。
### Innovation
提出了一种创新的自适应多阶段推理框架GUI-ARP。其中包含两方面的创新点：1. 自适应区域感知（ARP）和自适应阶段控制（ASC）技术的应用，使模型能够动态利用视觉注意力。2. 采用包含监督微调和强化微调的两个阶段的训练管道。通过自定义的训练流程，模型能够更高效地学习复杂的GUI结构。
### Conclusion
实验结果显示，GUI-ARP在具有挑战性的GUI定位基准测试上表现出色，其中7B模型在ScreenSpot-Pro和UI-Vision基准上的准确性分别达到了60.8%和30.9%。与开源的72B模型（UI-TARS-72B，38.1%）和专有模型相比，GUI-ARP-7B展示了很强的竞争力。
## 61. `cs.AI` - 异常声音检测中的频谱信息增强对比学习 [PDF](https://arxiv.org/pdf/2509.15570), [HTML](https://arxiv.org/abs/2509.15570)
### Authors
Xinxin Meng,Jiangtao Guo,Yunxiang Zhang,Shun Huang
### Background
异常声音检测在无监督的情况下面临着挑战，现有的方法主要集中在如何让模型学习正常数据的分布空间。通过生物学感知和数据分析发现，异常音频和噪音通常具有较高的频率。因此，本文提出了在对比学习中增强高頻信息的方法，使模型更多地关注音频的低频信息，代表了机器的正常运行模式。
### Innovation
基于频谱信息的数据增强方法，应用于对比学习中。这种方法使得模型在异常声音检测中更多地关注低频信息，从而区分正常和异常声音。实验结果表明，该方法在DCASE 2020 Task 2和2022 Task 2上的性能优于其他对比学习方法。
### Conclusion
本文提出的方法在异常声音检测中的频谱信息增强对比学习方法，能够更好地利用频谱信息，提高检测性能，并已经在多个任务上验证了其有效性。
## 62. `cs.AI` - LiteLong: 资源高效的大段落上下文数据合成方法以支持LLM [PDF](https://arxiv.org/pdf/2509.15568), [HTML](https://arxiv.org/abs/2509.15568)
### Authors
Junlong Jia,Xing Wu,Chaochen Gao,Ziyang Chen,Zijia Lin,Zhongzhi Li,Weinong Wang,Haotian Xu,Donghui Jin,Debing Zhang,Binghui Guo
### Background
高质量的长上下文数据对于训练能够处理大量文档的大语言模型（LLMs）非常重要，但现有的基于相关性聚合的方法在计算效率方面面临挑战。
### Innovation
我们提出了LiteLong，一种通过结构化的主题组织和多智能体辩论来实现资源高效的大段落上下文数据合成的方法。该方法利用BISAC图书分类系统构建全面的主题层次结构，并使用基于多个LLM的辩论机制来生成多样性和高质量的主题。使用轻量级的BM25检索为每个主题获取相关文档，并将其连接成128K词的训练样本。实验结果表明，LiteLong在长上下文性能上取得了竞争力，可以无缝集成到其他长依赖增强方法中。LiteLong通过降低计算和数据工程成本使得高质量长上下文数据合成更容易实现，促进了长期语言训练研究的发展。
### Conclusion
实验证明LiteLong实现了与现有方法相当的长上下文性能，同时降低了资源成本，使得高质量的长上下文数据合成更加容易，有利于进一步研究大语言模型的长期依赖增强。
## 63. `cs.AI` - 效用导向：过程监督重写以提升RAG [PDF](https://arxiv.org/pdf/2509.15577), [HTML](https://arxiv.org/abs/2509.15577)
### Authors
Jaeyoung Kim,Jongho Kim,Seung-won Hwang,Seoho Song,Young-In Song
### Background
检索增强生成（RAG）系统在优化检索相关性和生成实用性之间存在差距：检索到的文档虽然在主题上相关，但在生成过程中有效推理所需的具体内容可能仍不充分。现有的“桥梁”模块试图重新编写检索到的文本以改善生成效果，但它们无法完全捕捉文档的真正效用。因此，需要一种直接优化生成正确答案概率的方法，并通过过程监督进行指导。
### Innovation
本文提出了一种名为R2U的新方法，该方法主要通过直接优化生成正确答案的概率来最大化生成正确答案的机会，而非仅通过重写检索到的文本。由于直接监督成本较高，研究还通过将小规模的重写模型的监督从大语言模型（LLMs）扩展，开发了一种高效的学生-教师模型的蒸馏管道，使重写模型能更好地进行泛化。
### Conclusion
方法在多个开放领域的问答基准测试中得到评估，实验结果表明，本文方法在性能上显著优于现有的桥梁基线。
## 64. `cs.AI` - BTL-UI: Blink-Think-Link Reasoning Model for GUI Agent [PDF](https://arxiv.org/pdf/2509.15566), [HTML](https://arxiv.org/abs/2509.15566)
### Authors
Shaojie Zhang,Ruoceng Zhang,Pei Fu,Shaokang Wang,Jiahui Yang,Xin Du,Shiqi Cui,Bin Qin,Ying Huang,Zhenbo Luo,Jian Luan
### Background
在AI驱动的人机图形用户界面（GUI）交互自动化领域，虽然多模态大型语言模型和强化学习微调技术的进步取得了显著成果，但其根本挑战在于交互逻辑与自然的人机GUI通信模式存在着显著差异。为了弥补这一差距，本文提出了一种基于大脑启发框架：Blink-Think-Link（BTL），该框架帮助人类与图形界面之间进行更加符合自然认知过程的交互。该系统将交互过程分解为三个生物上可行的阶段：（1）Blink - 快速检测和关注相关屏幕区域，类似于瞬目眼动；（2）Think - 高层级的推理和决策，模拟认知规划；（3）Link - 生成可执行命令以实现精确的运动控制，模仿人类的动作选择机制。此外，本文为BTL框架引入了两项关键技术创新：（1）Blink数据生成 - 一种专为Blink数据设计的自动化注解管道；（2）BTL奖励 - 第一个基于规则的奖励机制，使得强化学习同时考虑过程和结果。
### Innovation
本文提出了Blink-Think-Link（BTL）框架，这是一种基于大脑启发的交互框架，将人机GUI交互过程分解为 Blink、Think 和 Link 三个阶段：（1）Blink - 快速检测和关注相关屏幕区域；（2）Think - 高层级的推理和决策，模拟认知规划；（3）Link - 生成可执行命令以实现精确的运动控制，模仿人类的动作选择机制。此外，本文还为BTL框架引入了 Blink 数据生成流水线和BTL 奖励机制，前者是一种专为Blink数据设计的自动化注解管道，后者是一个基于规则的奖励机制，可以从过程和结果两个方面驱动强化学习。这些关键技术创新为开发高级GUI代理提供了新的思路
### Conclusion
本文基于BTL框架开发了一个GUI代理模型BTL-UI，并在一系列基准测试中展示了与其静态GUI理解和动态交互任务相关的先进性能。这一结果提供了BTL框架在开发高级GUI代理方面的有效性的实验证据。
## 65. `cs.AI` - SmolRGPT: 在600M参数下实现仓库环境中的高效空间推理 [PDF](https://arxiv.org/pdf/2509.15490), [HTML](https://arxiv.org/abs/2509.15490)
### Authors
Abdarahmane Traore,Éric Hervet,Andy Couturier
### Background
近期视觉-语言模型（VLMs）的发展使得多模态推理变得非常强大，但目前最先进的模型通常需要极其庞大的模型规模，导致了在计算和内存资源有限的环境中（如仓库、机器人技术和工业应用等）部署的难度。这些应用场景需要高效率和稳健的空间理解能力。
### Innovation
SmolRGPT 是一种紧凑型视觉-语言架构，特别引入了区域级别的空间推理机制，并融合了RGB和深度图信息。SmolRGPT 使用三阶段的课程学习方法，逐步对齐视觉和语言特征，增强空间关系理解能力，并适用于特定的任务。实验结果表明，SmolRGPT 仅有600M参数，却能在复杂的仓库空间推理基准测试中取得与更大模型相当或更好的性能。
### Conclusion
SmolRGPT 证明了在现实世界应用场景中，高效的、可部署的多模态智能是可行的，同时没有牺牲核心的空间推理能力。相关实验代码会在指定的链接处提供。
## 66. `cs.AI` - 使用语言验证数据和异构模态融合的短视频假新闻多模态学习 [PDF](https://arxiv.org/pdf/2509.15578), [HTML](https://arxiv.org/abs/2509.15578)
### Authors
Shanghong Li,Chiam Wen Qi Ruth,Hong Xu,Fang Liu
### Background
短视频平台的迅速普及对检测假新闻的方法提出了新的需求。当前方法难以处理短视频内容的动态性和多模态特征，而且错误信息的传播广泛，可能造成社会危害。现有的检测方法在面对音频、视频和文本信息的融合时表现不佳。
### Innovation
该论文提出了HFN（Heterogeneous Fusion Net）框架，一种结合了视频、音频和文本数据的新型多模态方法。HFN引入了一个决策网络，在推理过程中动态调整模态权重，并且具有一种加权多模态特征融合模块，可以在数据不完整的情况下提供稳健的表现。此外，本文还贡献了一个专门用于短视频假新闻检测的全面数据集VESV（VEracity on Short Videos）。实验结果表明，该框架在Marco F1指标上比现有最优方法提高了2.71%至4.14%。
### Conclusion
该工作提供了一种强大的解决方案，能够在复杂的短视频平台环境中有效识别假新闻，为更加可靠和全面的反虚假信息方法铺平了道路。
## 67. `cs.AI` - 信息几何与变分贝叶斯的关系 [PDF](https://arxiv.org/pdf/2509.15641), [HTML](https://arxiv.org/abs/2509.15641)
### Authors
Mohammad Emtiyaz Khan
### Background
本文强调了信息几何与变分贝叶斯（VB）之间的重要联系，并讨论了这一联系在机器学习中的影响。在特定条件下，VB解法总是需要估计或计算自然梯度。通过使用Khan和Rue（2023）的自然梯度下降算法，即贝叶斯学习规则（BLR），作者展示了这一事实带来的几个重要结果。
### Innovation
作者通过BLR重新诠释了贝叶斯规则，并展示了自然梯度在梯度方法中的通用替代品及其在大规模语言模型中的应用。
### Conclusion
尽管已有关于两者之间联系的讨论，但本文进一步强调了信息几何与贝叶斯理论的共同起源，旨在促进这两个领域交叉研究的工作。
## 68. `cs.AI` - 潜伏区网络：生成建模、表示学习和分类的统一原则 [PDF](https://arxiv.org/pdf/2509.15591), [HTML](https://arxiv.org/abs/2509.15591)
### Authors
Zinan Lin,Enshu Liu,Xuefei Ning,Junyi Zhu,Wenyu Wang,Sergey Yekhanin
### Background
生成建模、表示学习和分类是机器学习领域的三个核心问题，尽管各自都有了先进的解决方案（SoTA），但这些解决方案仍保持相对独立，缺乏统一的原则来集成这三者。
### Innovation
该研究提出了潜伏区网络（LZN）作为这一问题的解决方案。LZN的核心是创造一个共享的高斯潜在空间，该空间编码所有任务的信息。每个数据类型都配置有编码器将样本映射到不同的潜在区域，以及解码器将潜在变量重新映射回数据。ML任务被表达为这些编码器和解码器的组合：例如，条件图像生成使用标签编码器和图像解码器；图像嵌入使用图像编码器；分类使用图像编码器和标签解码器。通过LZN在三个越来越复杂的场景中的演示展示，LZN能够在增强现有模型（生成建模）、独立解决任务（表示学习）以及同时解决多个任务（联合生成和分类）方面展现出其潜力。
### Conclusion
通过将LZN应用于增强SoTA的Rectified Flow模型、无辅助损失函数的表示学习任务以及联合生成和分类任务，研究结果显示LZN在图像生成、无监督表示学习和多任务解决方面均取得了显著的性能改进，包括FID分数和SoTA分类精度。有关代码和训练模型的链接在文中提供。
## 69. `cs.AI` - 具有残差增强DRL的动量约束混合启发式轨迹优化框架在视障场景中的应用 [PDF](https://arxiv.org/pdf/2509.15582), [HTML](https://arxiv.org/abs/2509.15582)
### Authors
Yuting Zeng,Zhiwen Zheng,You Zhou,JiaLing Xiao,Yongbin Yu,Manping Fan,Bo Gong,Liyong Ren
### Background
本文提出了一个动量约束混合启发式轨迹优化框架（MHHTOF），专门用于视障辅助导航场景中的路径优化。该框架结合了轨迹采样生成、优化和评估，以及残差增强的深度强化学习（DRL）。首先使用五次多项式和三级插值生成轨迹采样聚类（HTSC），然后应用动量约束轨迹优化（MTO）保证路径的平滑性和可行性。
### Innovation
该研究创新性地结合了轨迹采样、优化与评估过程，并利用残差增强的递归神经网络（DRL）来适应性地细化选择的路径，同时也包括了一个双重阶段成本建模机制（DCMM）实现跨阶段的语义优先级对齐，支持以人为中心的优化。实验结果表明，提出的基于LSTM的残差增强PPO算法在训练迭代次数上实现了显著的加速，同时提高了奖励结果和训练稳定性，降低了平均成本和成本方差，减少了约30.3%和53.3%，并降低了近77%的自我和障碍物风险。这些发现证明了该框架在复杂辅助规划任务中的鲁棒性、安全性和实时可行性方面具有有效性。
### Conclusion
MHHTOF在视障辅助导航场景中的应用验证了该框架在增强任务鲁棒性、安全性和实时可行性方面的有效性。
## 70. `cs.AI` - 语言模型如何生成俚语：人类与机器生成俚语用法的系统比较 [PDF](https://arxiv.org/pdf/2509.15518), [HTML](https://arxiv.org/abs/2509.15518)
### Authors
Siyang Wu,Zhewei Sun
### Background
俚语是常见的非正式语言类型，给自然语言处理(NLP)系统带来了巨大挑战。然而，大规模语言模型(如大型语言模型(LLMs))的发展使得这一问题更易于解决。随着LLMs在中介任务，如俚语检测和解释中的广泛应用，它们的泛化能力和可靠性很大程度上取决于模型能否捕捉到与人类验证的俚语使用相符的结构知识。
### Innovation
本文贡献了人类与机器生成的俚语用法之间系统的比较分析框架。该框架重点关注三个方面：1)反映机器如何感知俚语的系统偏差的语言用法特征；2)反映词汇创造和词汇再利用创造力的语言用法；3)作为模型蒸馏的黄金标准示例时的俚语用法信息性。
### Conclusion
通过对比Onlin Slang Dictionary (OSD)中人类验证的俚语用法与GPT-4o和Llama-3生成的俚语，研究发现，尽管LLMs在捕捉俚语的创造性方面积累了一定的知识，但这些知识与人类使用的知识不完全匹配，无法支持LLMs应用于推断任务，例如语言分析。
## 71. `cs.AI` - 追求尺寸不变的显著目标检测：一种通用评估和优化方法 [PDF](https://arxiv.org/pdf/2509.15573), [HTML](https://arxiv.org/abs/2509.15573)
### Authors
Shilong Bao,Qianqian Xu,Feiran Li,Boyu Han,Zhiyong Yang,Xiaochun Cao,Qingming Huang
### Background
这篇论文探讨了显著目标检测(SOD)中一个未被充分研究的基本问题，即评估准则的尺寸不变性属性，特别是在单张图像中出现多个尺寸明显不同的显著目标的场景下。现有的广泛使用的SOD指标本质上是尺寸敏感的，导致大小比例不平衡的预测误差，使小但更具有语义重要性的目标被忽略，从而造成性能评估和实际应用中的偏差。
### Innovation
论文提出了一种通用的尺寸不变评估（SIEva）框架，通过独立评估每个分离成分并汇总结果，有效缓解了对象尺寸不平衡的影响。在此基础上，进一步开发了专门的优化框架（SIOpt），该框架遵循尺寸不变性原则，并显著增强了各种尺寸范围内的显著目标检测能力。此外，还提出了SOD方法的泛化分析，并提供了支持新评估协议有效性的证据。
### Conclusion
全面的实验表明了所提出的评估和优化方法的有效性。相关代码可从提供的链接访问。
## 72. `cs.AI` - 探索多语言和谐：大规模语言模型预训练中的多语言数据分配 [PDF](https://arxiv.org/pdf/2509.15556), [HTML](https://arxiv.org/abs/2509.15556)
### Authors
Ping Guo,Yubing Ren,Binbin Liu,Fengze Liu,Haobin Lin,Yifan Zhang,Bingni Zhang,Taifeng Wang,Yin Zheng
### Background
大型语言模型（LLMs）在全球范围内被广泛应用于各种场景，推动了对高效多语言能力的前所未有的全球需求。要实现稳健的多语言性能，关键在于训练数据集中语言比例的科学分配。然而，确定最佳语言比例极具挑战性，因为语言间的复杂交互和数据集规模的变化性。本文旨在探讨多语言数据在大型语言模型预训练中的分配问题。
### Innovation
本文提出了一种名为Climb（Cross-Lingual Interaction-aware Multilingual Balancing）的新颖框架，用于系统地优化多语言数据分配。Climb框架的核心是一个跨语言交互感知的语言比例，明确量化了每种语言的有效分配，并通过捕捉语言间的依赖关系来实现。Climb提出了一种原则性的两步优化过程，首先使每种语言边际收益相等，然后最大化分配向量的规模，从而简化了原本复杂的多语言优化问题。
### Conclusion
广泛的实验证明，Climb可以准确测量各类多语言设置下的跨语言交互。使用Climb优化后的比例训练的LLMs，在各种多语言场景下始终能取得最先进的多语言性能，甚至在使用更少tokens训练的开源LLMs中表现得更加出色。
## 73. `cs.AI` - DivLogicEval：一种用于评估大型语言模型逻辑推理能力的标准框架 [PDF](https://arxiv.org/pdf/2509.15587), [HTML](https://arxiv.org/abs/2509.15587)
### Authors
Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung
### Background
自然语言中的逻辑推理被认为是评估人类智能的重要指标，特别是对于大规模语言模型（LLMs）。目前流行的基准测试可能会将多种推理技能交织在一起，从而无法提供对逻辑推理技能的忠实评估。此外，现有的逻辑推理基准在语言多样性方面有限，并且其分布与理想的逻辑推理基准分布存在偏差，这可能导致偏颇的评估结果。因此，本研究提出了一种新的经典逻辑基准——DivLogicEval，由多样化的陈述命题组成，并以反直觉的方式产生自然句子，以确保更可靠的评估。
### Innovation
提出了一个新的经典逻辑基准DivLogicEval，由多样化的陈述命题以反直觉方式组成，旨在消除现有基准的偏差和语言多样性限制。还提出了一个新的评估指标，以缓解LLMs固有的偏见和随机性的影响。通过实验，展示了在DivLogicEval中需要多大的逻辑推理能力来回答问题，并比较了不同流行大型语言模型进行逻辑推理的性能。
### Conclusion
实验结果表明DivLogicEval可以更准确地评估各种大型语言模型的逻辑推理能力，并提出了一种新的评估标准来增强评估的可靠性和客观性。
## 74. `cs.AI` - 边缘环境中的成本敏感二分类推理卸载 [PDF](https://arxiv.org/pdf/2509.15674), [HTML](https://arxiv.org/abs/2509.15674)
### Authors
Vishnu Narayanan Moothedath,Umang Agarwal,Umeshraja N,James Richard Gross,Jaya Prakash Champati,Sharayu Moharir
### Background
本文研究的是在边缘智能系统中的一种二分类问题，其中将假阴性错误的成本设定为高于假阳性错误的成本。系统中有一个紧凑的、本地部署的模型，它可以被一个较大的、远程部署的模型补充，后者通过网络访问，但由于卸载计算到远程模型的开销而受到限制。系统会首先使用局部模型进行推理，基于局部模型的输出结果，样本将被选择性地卸载到远程模型。研究所探讨的是在这样的层级推理（HI）系统中分类准确性和卸载成本之间的基本权衡关系。
### Innovation
提出了一个在线学习框架，该框架能够持续适应局部模型的信心评分上的一个阈值对，以优化系统性能。提出了H2T2策略，这是一种通用模型不可知的策略，无需训练，通过少量反馈在推理过程中进行学习，并证明其达到次线性遗憾值。此策略在实际数据集上的模拟实验中展示了超越简单策略的性能，并且对分布偏移表现出很强的鲁棒性，能够有效适应分类器之间的不一致。
### Conclusion
本文表明，H2T2策略可以在有限的反馈下学习，有效适应分布偏移和分类器的不匹配，并且在实际数据集上的表现优于其他策略，特别是在处理假阴性假阳性成本不相等的情境下。这意味着它可以有效优化边缘环境中推理卸载的成本敏感二分类问题。
## 75. `cs.AI` - SightSound-R1: 听觉到语言模型的跨模态推理蒸馏 [PDF](https://arxiv.org/pdf/2509.15661), [HTML](https://arxiv.org/abs/2509.15661)
### Authors
Qiaolin Wang,Xilin Jiang,Linyang He,Junkai Wu,Nima Mesgarani
### Background
虽然大型音频-语言模型（LALMs）在音频理解方面表现出色，但在复杂声景中的推理能力仍然落后于大型视觉-语言模型（LVLMs）。与视觉领域相比，一个瓶颈是缺乏大规模的链式思考音频数据来训练LALM按步骤推理。为解决这一数据和模态瓶颈，本文提出了一种跨模态蒸馏框架SightSound-R1，它将较强大的LVLM教师的高级推理能力转移到同一音频-视觉问答（AVQA）数据集上的较弱LALM学生上。
### Innovation
SightSound-R1框架包含三个核心步骤：（i）测试时缩放以从LVLM教师生成针对音频的链式思考（CoT），（ii）基于音频验证以过滤幻觉，以及（iii）一个包括监督微调（SFT）和Group Relative Policy Optimization (GRPO) 的蒸馏管道。该框架展示了在同类AVQA测试集和未见过的听觉场景和问题中，LALM推理性能的提升，并优于预训练和仅标签蒸馏基线。
### Conclusion
因此，本文结论是视觉推理可以有效转移到音频模型，并通过丰富的音频-视觉数据进行扩展。
## 76. `cs.AI` - 向量高效的影响力函数：以Dropout为压缩工具 [PDF](https://arxiv.org/pdf/2509.15651), [HTML](https://arxiv.org/abs/2509.15651)
### Authors
Yuchen Zhang,Mohammad Mohammadi Amiri
### Background
评估训练数据对机器学习模型的影响对于理解模型行为、提升透明度以及选择训练数据至关重要。影响函数提供了一种理论框架，用于量化特定测试数据下训练数据点对模型性能的影响。然而，计算和内存成本是影响函数的主要挑战，尤其是对于大规模模型而言，即使使用近似方法，也因为计算中的梯度大小与模型本身相当。因此，如何降低计算和内存开销，特别是在影响函数计算和梯度压缩过程中，成为了提高模型效率的关键问题。
### Innovation
本文提出了一种新颖的方法，利用Dropout作为一个梯度压缩机制来更有效地计算影响函数。该方法显著减少了计算和内存开销，不仅在影响函数计算过程中，也在梯度压缩过程中。通过理论分析和实验验证，证明了该方法能够保留数据影响的关键组件，并使其能够应用于现代大规模模型。
### Conclusion
我们提出的方法通过利用Dropout作为梯度压缩机制，能够更有效地计算影响函数，从而显著降低计算和内存开销。通过理论分析和实验验证，我们表明该方法能够保留数据影响的关键组件，并应用于现代大规模模型，从而提高模型的效率和性能。
## 77. `cs.AI` - 从前有座山：小语言模型讲故事的交互式学习 [PDF](https://arxiv.org/pdf/2509.15714), [HTML](https://arxiv.org/abs/2509.15714)
### Authors
Jonas Mayer Martins,Ali Hamza Bashir,Muhammad Rehan Khalid,Lisa Beinborn
### Background
儿童通过与周围社交环境中的其他人互动而不是仅通过听来高效地获得语言能力。相比之下，大型语言模型通常是通过在大量文本上进行下一个词预测来训练的。受这一对比的启发，该研究探索了是否可以通过不仅从下一个词预测而且从高层次的认知启发反馈中学习来降低语言模型的训练数据需求。
### Innovation
研究训练了一个学生模型生成故事情节，这个模型由一个教师模型根据可读性、叙述连贯性和创造力进行评估。通过改变反馈循环前的预训练量，评估了这种互动学习对形式和功能语言能力的影响。实验证明，高层次的反馈具有高度的数据效率，只需100万词的输入即可通过交互学习提高讲故事的技巧，效果相当于4.1亿词的下一个词预测训练。
### Conclusion
这种交互学习方法能够显著提高语言模型的讲故事技能，且所需数据量远少于传统的下一个词预测训练方法，证明了该方法在降低训练成本和提高模型泛化能力方面的潜力。
## 78. `cs.AI` - CFDA & CLIP在TREC iKAT 2025中的应用：通过查询重新表述和排名融合提升个性化对话搜索 [PDF](https://arxiv.org/pdf/2509.15588), [HTML](https://arxiv.org/abs/2509.15588)
### Authors
Yu-Cheng Chang,Guan-Wei Yeo,Quah Eugene,Fan-Jie Shih,Yuan-Ching Kuo,Tsung-En Yu,Hung-Chun Hsu,Ming-Feng Tsai,Chuan-Ju Wang
### Background
2025年TREC互动知识辅助赛道(iKAT)包括互动提交任务和离线提交任务。互动提交任务要求系统在实时条件下运行，因此系统的稳健性和效率同样关键。离线提交任务则可以使用预定义的数据集来控制性评估段落排名和响应生成。为应对这些挑战，研究者们探索了查询重新表述和检索融合作为核心策略，并围绕Best-of-$N$选择和互惠秩融合（RRF）策略构建了处理不同提交任务的管道。实验结果表明，重新排序和融合提高了稳健性，但也展示了在不同任务间有效性与效率之间的权衡。
### Innovation
研究将查询重新表述和排名融合作为核心策略，结合Best-of-$N$选择和互惠秩融合（RRF）策略，构建了有效处理不同提交任务的管道。这种策略在提高系统稳健性的同时，揭示了有效性与效率之间的权衡关系，实现了个性化对话搜索的效果提升。
### Conclusion
通过查询重新表述和排名融合的方法，研究不仅提高了系统的稳健性和效率，还展示了在不同任务中有效性和效率之间的权衡。这些方法对于未来对话搜索系统的优化提供了新的思路。
## 79. `cs.AI` - TISDiSS: 一种训练时和推理时可扩展的辨别源分离框架 [PDF](https://arxiv.org/pdf/2509.15666), [HTML](https://arxiv.org/abs/2509.15666)
### Authors
Yongsheng Feng,Yuetonghui Xu,Jiehui Luo,Hongjia Liu,Xiaobing Li,Feng Yu,Wei Li
### Background
源分离是语音、音乐和音频处理中的基本任务，它还能提供更清洁、更多的数据来训练生成模型。然而，提高实际中的分离性能通常依赖于越来越大的网络，这增加了训练和部署的成本。
### Innovation
提出了一种名为TISDiSS的统一框架，它结合了早期分支多损失监督、共享参数设计和动态推理重复。TISDiSS通过调整推理深度来灵活地平衡速度和性能，而无需重新训练额外的模型。研究表明，训练时使用更多的推理重复能够提高浅层推理性能，这对低延迟应用是有益的。
### Conclusion
在标准的语音分离基准测试上，实验显示TISDiSS具有较低的参数计数但具备最先进的性能，确立了TISDiSS作为一种适用于可调源分离的可扩展且实用框架的地位。
## 80. `cs.AI` - FloorSAM：基于语义几何融合的SAM指导楼层平面图重建 [PDF](https://arxiv.org/pdf/2509.15750), [HTML](https://arxiv.org/abs/2509.15750)
### Authors
Han Ye,Haofu Wang,Yunchi Zhang,Jiangjian Xiao,Yuqiang Jin,Jinyuan Liu,Wen-An Zhang,Uladzislau Sychou,Alexander Tuzikov,Vladislav Sobolevskii,Valerii Zakharov,Boris Sokolov,Minglei Fu
### Background
从点云数据重建建筑物楼层平面图对于室内导航、BIM（建筑信息模型）和精确测量至关重要。传统的几何算法和基于Mask R-CNN的深度学习方法在噪声处理、泛化能力以及几何细节损失方面存在一些问题。
### Innovation
本文提出了一种结合点云密度图与部分语义匹配（Segment Anything Model，SAM）的重建框架FloorSAM。利用基于网格的过滤、自适应分辨率投影和图像增强来生成鲁棒的顶部视图密度图。FloorSAM利用SAM的零样本学习进行精确的房间分割，通过自适应提示点和多阶段过滤生成房间掩码，并通过掩码和点云的联合分析来提取轮廓和正则化，从而生成准确的楼层平面图并恢复房间的拓扑关系。
### Conclusion
在Giblayout和ISPRS数据集上的测试结果表明，与传统方法相比，FloorSAM在噪声和复杂环境中具有更高的准确度、召回率和鲁棒性。
## 81. `cs.AI` - Saccadic Vision for Fine-Grained Visual Classification [PDF](https://arxiv.org/pdf/2509.15688), [HTML](https://arxiv.org/abs/2509.15688)
### Authors
Johann Schmidt,Sebastian Stober,Joachim Denzler,Paul Bodesheim
### Background
细粒度视觉分类（FGVC）需要通过细微、局部的特征来区分视觉上相似的类别，这由于类内变化高和类间差异有限而变得具有挑战性。现有的基于部件的方法通常依赖于复杂的定位网络，这些网络从像素空间到样本空间学习映射，这需要对图像内容有深层次的理解，但限制了其对下游任务的特征应用能力。此外，样点经常具有高空间冗余性，这使得确定所需的部件数量变得困难。
### Innovation
本文受到人类扫视视觉的启发，提出了一种两阶段过程，首先提取外围特征（粗略观察），生成样本图，从中抽取和并行编码固定视斑，使用共享权重编码器。使用上下文化选择性注意力来衡量每个固定视斑的影响，然后将其与外围和焦点表征进行融合。为防止部分方法中存在的空间崩溃问题，在固定视斑采样过程中使用非最大抑制来消除冗余。
### Conclusion
通过全面的评估，本文的方法在标准FGVC基准测试集（CUB-200-2011、NABirds、Food-101和Stanford-Dogs）以及具有挑战性的昆虫数据集（EU-Moths、Ecuador-Moths和AMI-Moths）上，表现出与当前最先进的方法相当的性能，同时在基线编码器的基础上有一致的提升。
## 82. `cs.AI` - KITE：高核和信息论驱动的示例用于上下文适配学习 [PDF](https://arxiv.org/pdf/2509.15676), [HTML](https://arxiv.org/abs/2509.15676)
### Authors
Vaibhav Singh,Soumya Suvra Ghosal,Kapu Nirmal Joshua,Soumyabrata Pal,Sayak Ray Chowdhury
### Background
在基于上下文的学习（ICL）中，大型语言模型（LLMs）可以通过少量精心选择的任务特定示例来适应新且数据稀少的任务，这是通过在提示中呈现这些示例实现的。然而，由于LLMs的上下文大小有限，选择哪些示例可以最大化特定用户查询性能的问题却悬而未决。传统的最近邻方法如KATE虽然被广泛采用，但它们在高维嵌入空间中存在缺点，如泛化能力差和缺乏多样性。本文从有一定理论基础和信息论驱动的角度研究了这个示例选择问题。
### Innovation
本文提出了一种核化和信息论驱动的方法KITE，用于ICL中的示例选择。KITE通过将LLM建模为输入嵌入上的线性函数，将示例选择问题重新定义为特定查询的优化问题：从更大的示例库中选择一个子集，以最小化特定查询的预测误差。KITE使用大约子模性的规范目标函数，使得可以使用贪婪算法，并具有近似保证。此外，KITE还通过引入核技巧和最优设计基础正则化器来优化性能，增加了选择到的示例的结构意识和多样性。通过实验证明，KITE方法在一系列分类任务中显著优于传统的检索方法，突显了对于实际场景中的标签稀缺情况，基于结构的、多样化的示例选择的优势。
### Conclusion
通过KITE方法，作者能够有效提升ICL中的示例选择策略，使模型在特定查询上的预测性能更佳，在实际应用中展现出更强的效果。
## 83. `cs.AI` - GP3: 采用多视图图像的3D几何感知策略进行机器人操作 [PDF](https://arxiv.org/pdf/2509.15733), [HTML](https://arxiv.org/abs/2509.15733)
### Authors
Quanhao Qian,Guoyang Zhao,Gongjie Zhang,Jiuniu Wang,Ran Xu,Junlong Gao,Deli Zhao
### Background
有效的机器人操作依赖于对3D场景几何的精确理解，而获取这种几何信息的一个简单方式是通过多视角观测。GP3是一个利用多视角输入的3D几何感知机器人操作策略，它采用空间编码器从RGB观察中推断出密集的空间特征，以估计深度和相机参数，从而得出一个紧凑但表达力强的3D场景表示，专门用于操作。这种表示方式与语言指令结合，并通过轻量级的策略头转换为连续动作。实验表明，GP3在模拟基准测试中持续优于最新的方法，并且在没有深度传感器或预映射环境的情况下，能够有效转移到真实世界的机器人中，只需少量微调。这些结果强调了GP3作为几何感知机器人操作的实用且传感器无关的解决方案的重要性。
### Innovation
GP3 利用多视角输入，通过空间编码器获取密集的空间特征，估计深度和相机参数，构建适用于操作的3D场景表示，并将其与语言指令结合转换为连续动作，从而有效提高了机器人操作的性能和通用性。
### Conclusion
实验证明，GP3在模拟环境中的一系列基准测试中表现优异，能够在无深度传感器的情况下有效运用于实际操作场景，表明其作为3D几何感知机器人操作策略的实用性和灵活性。
## 84. `cs.AI` - SGMAGNet：新被动主动卫星基准上三维云相结构重构的基线模型 [PDF](https://arxiv.org/pdf/2509.15706), [HTML](https://arxiv.org/abs/2509.15706)
### Authors
Chi Yang,Fu Wang,Xiaofei Yang,Hao Huang,Weijia Cao,Xiaowen Chu
### Background
云相位廓线对于数值天气预报（NWP）至关重要，直接关系到辐射传输和降水过程。这项研究提出了一套基准数据集和基线框架，用于将多种卫星观测数据转换为详细的三维云相结构，旨在为运行中的云相廓线提取提供支持，并与先进的天气预测系统集成，从而提升云微物理参数化能力。研究资料包括高时空分辨率的多波段可见光（VIS）和红外（TIR）图像以及准确的垂直云相廓线数据，这些数据由地球静止轨道卫星提供，并有载人航天雷达成像测高仪（CPR/CloudSat）和激光雷达（CALIOP/CALIPSO）资料作为补充。通过同步图像与廓线数据，任务定义为给定VIS/TIR片，预测相应的三维云相结构。
### Innovation
研究采用SG MAGNet作为主要模型，并与几种基线架构进行了比较，这些架构包括UNet变体和SegNet，旨在捕捉多层次的空间模式。模型性能基于标准分类指标进行评价，如精确度、召回率、F1分数和IoU。研究结果表明，SG MAGNet在云相重构中表现出色，特别是在复杂多层次和边界过渡区域。定量结果中，SG MAGNet的精确度为0.922，召回率为0.858，F1分数为0.763，IoU为0.617，显著优于所有基线模型。
### Conclusion
SG MAGNet在三维云相结构重构方面的表现优于现有基线模型，并为未来集成入NWP系统提供了改进的云微物理参数化支持。
## 85. `cs.AI` - 基于低级MPC的分层强化学习多智能体控制 [PDF](https://arxiv.org/pdf/2509.15799), [HTML](https://arxiv.org/abs/2509.15799)
### Authors
Max Studt,Georg Schildbach
### Background
在动态且约束丰富的环境中实现安全且协调的行为依然是基于学习的控制一个重大挑战。端到端的学习通常效率低下且可靠性有限，而基于模型的方法依赖预先定义的参考，难以泛化。
### Innovation
本文提出了一种分层框架，该框架结合了通过强化学习（RL）进行的战略性决策和通过模型预测控制（MPC）进行的低级执行。在这种框架下，多智能体系统中的高级策略会选择结构化的兴趣区域（ROIs）中的抽象目标，而MPC确保运动是动态可行且安全的。
### Conclusion
在捕食者-猎物基准测试中，我们的方法在奖励、安全性和一致性方面均优于端到端和基于遮挡的RL基线，这证明了将结构化学习与基于模型的控制结合的益处。
## 86. `cs.AI` - ChronoForge-RL: 通过强化学习实现的按时间顺序锻造以增强视频理解 [PDF](https://arxiv.org/pdf/2509.15800), [HTML](https://arxiv.org/abs/2509.15800)
### Authors
Kehua Chen
### Background
当前最先进的视频理解方法在处理密集视频内容时，面临着两个主要挑战：一是处理每一帧的计算复杂性；二是通过简单的均匀采样策略难以识别具有语义意义的关键帧。
### Innovation
本文提出了一种名为ChronoForge-RL的新视频理解框架，它结合了Temporal Apex Distillation (TAD) 和 KeyFrame-aware Group Relative Policy Optimization (KF-GRPO)，以解决上述问题。具体来说，引入了一个可微分的关键帧选择机制，通过三阶段过程系统地识别语义拐点，从而提高计算效率并保留时间信息。本文还提出两个模块：首先是TAD，利用变化评分、拐点检测和优先级蒸馏来选择最有信息量的帧；其次引入KF-GRPO，它采用增强显著性的对比学习范式，明确激励模型利用帧内容和时间关系。
### Conclusion
我们的ChronoForge-RL方法在VideoMME数据集上取得了69.1%的性能，在LVBench数据集上取得了52.7%的性能，明显超越了基线方法，同时使我们的7B参数模型达到了与72B参数模型相当的性能。
## 87. `cs.AI` - 关于实现精确公平的最优引导 [PDF](https://arxiv.org/pdf/2509.15759), [HTML](https://arxiv.org/abs/2509.15759)
### Authors
Mohit Sharma,Amit Jayant Deshpande,Chiranjib Bhattacharyya,Rajiv Ratn Shah
### Background
在公平的人工智能学习中，本质上需要调节数据的特征分布或大型语言模型（LLM）内部表示，以确保公平的结果。先前的工作中，公平生成模型和表示引导可以极大地受益于模型输出的可验证公平性保证。理想分布是指任何成本敏感风险的最小化保证具有确切的群体公平结果（例如，人口平等问题、同等机会等）的分布，即不存在公平性与效用之间的权衡。通过使用KL散度的最近理想分布来表述最优引导优化程序，实验表明，即使在不影响效用情况下，对于合成和真实数据集的应用提高了公平性，有时候甚至还能提高效用。此外，通过引导LLM内部表示以减少多分类分类中的偏见，如Bios数据集中职位预测的短传记等，该方法还使模型在不同群体中的表现更为一致.
### Innovation
提出了通过KL散度找到最近理想分布来实现最优引导的优化程序，并为此类已知参数家庭（例如，正态分布、对数正态分布）提供了高效的算法。这项研究的独特之处在于验证了公平性和效用之间的权衡，证明了即使在提高公平性的同时也能保持和有时提高效用，并且展示了LLM表达的向量空间引导方法以减少多类别分类的偏差，使得模型在不同类型的人群中表现一致。
### Conclusion
通过LML内部表示的最优引导技术，不仅改善了公平性，有时甚至还能改善效用。这种方法展示了在不同群体之间实现一致性公平的一种有效方法，并通过KL散度找到最近理想分布来最小化偏差。这些成果为进一步研究提供了新的方向和方法，可以在实际应用中减少偏见，提高模型的群体公平性。
## 88. `cs.AI` - 理想的空间配准？分割一切你所需要 [PDF](https://arxiv.org/pdf/2509.15784), [HTML](https://arxiv.org/abs/2509.15784)
### Authors
Xiang Chen,Fengting Zhang,Qinghao Liu,Min Liu,Kun Wu,Yaonan Wang,Hang Zhang
### Background
深度学习已经通过其处理多样任务的能力以及相对于传统方法的速度优势，彻底革新了图像配准。现有的方法通常采用全局均匀的平滑约束，这往往无法适应解剖学运动中复杂且区域变化的变形。
### Innovation
本文提出了SegReg，一种基于分割的空间配准框架，通过利用特定区域的变形模式实现解剖学适应性正则化。该框架首先将输入的移动和固定图像分解为解剖学上一致的子区域，然后通过相同的配准骨干计算优化的局部变形场，最终将这些局部场集成到全局变形场中。
### Conclusion
SegReg能够达到近乎完美的结构对齐效果（关键解剖结构的Dice得分为98.23%），并且在三个临床配准场景（心脏、腹部和肺部图像）中均优于现有方法，即使在自动分割的情况下也提高了2-12%的成绩。SegReg的配准精度几乎线性依赖于分割质量，将其配准问题转换成了分割问题。源代码将接受手稿后公开。
## 89. `cs.AI` - Best-of-L:跨语言奖励建模以提高数学推理能力 [PDF](https://arxiv.org/pdf/2509.15811), [HTML](https://arxiv.org/abs/2509.15811)
### Authors
Sara Rajaee,Rochelle Choenni,Ekaterina Shutova,Christof Monz
### Background
随着大型语言模型（LLMs）推理能力的提升，人们开始关注这些能力在多语言LLMs中的表现差异，以及不同语言是否能互补。这项研究旨在通过训练一个跨语言奖励模型来评价不同语言生成的回复，从而探究语言间的这种差异和互补性.
### Innovation
研究引入了一种跨语言奖励模型，用于多语言环境下数学推理任务的回复评估。这一模型在数学推理任务中显示出比单一语言奖励模型更优秀的性能，尤其在低抽样预算下显著提高了英语等高资源语言的表现。这一创新揭示了多语言推理能力可以通过利用不同语言的互补优点来提高的新途径.
### Conclusion
研究发现，跨语言奖励模型在数学推理任务中显著提升了表现，尤其是在资源丰富语言如英语的低预算抽样条件下。这表明，利用不同语言的优势可以有效提高多语言推理能力，开启了一种新的提高多语言推理的新途径。
## 90. `cs.AI` - 蛋白质设计中的多专家蒙特卡洛树扩散方法 [PDF](https://arxiv.org/pdf/2509.15796), [HTML](https://arxiv.org/abs/2509.15796)
### Authors
Xuefeng Liu,Mingxuan Cao,Songhao Jiang,Xiao Luo,Xiaotian Duan,Mengdi Wang,Tobin R. Sosnick,Jinbo Xu,Rick Stevens
### Background
蛋白质设计的目标是生成氨基酸序列，这些序列折叠成具有所需特性的功能结构。以前将自回归语言模型与蒙特卡罗树搜索（MCTS）结合的方法在处理长程依赖关系方面遇到困难，并且难以应对庞大的搜索空间。
### Innovation
提出了一种名为MCTD-ME（蒙特卡洛树扩散与多重专家结合）的新方法，该方法将掩蔽扩散模型与树搜索结合，以实现多令牌规划和高效的搜索探索。不同于自回归规划器，MCTD-ME 使用生物物理鸿准度增强的扩散去噪作为展开引擎，可以同时修订多个位置，适用于大规模序列空间。此外，MCTD-ME 还借助了不同的专家来丰富探索，并通过基于 pLDDT 的掩蔽计划表从低置信度区域进行引导，同时保留可靠的残基。提出了一个称为 PH-UCT-ME 的新颖多专家选择规则，扩展了预测熵 UCT 到专家集合。
### Conclusion
在逆折叠任务（如 CAMEO 和 PDB 标准）中，MCTD-ME 在氨基酸序列恢复（AAR）和结构相似性（scTM）方面优于单专家和无指导基线，并且对于更长的蛋白质，其收益会增加。此外，该框架是模型无关的，并且适用于蛋白质工程和多目标分子生成等其他领域。
## 91. `cs.AI` - 基于k-Kemeny得分分析结构化领域多样性 [PDF](https://arxiv.org/pdf/2509.15812), [HTML](https://arxiv.org/abs/2509.15812)
### Authors
Piotr Faliszewski,Krzysztof Sornat,Stanisław Szufa,Tomasz Wąs
### Background
给出了k-Kemeny问题的背景，问题描述为：给定一个有序选举，即一系列将候选人从最好到最坏的排名，目标是在保证选举最多有k种不同排名的前提下，最小化交换相邻候选人的次数。研究范围包括单峰、单交、组分离和欧几里得等结构化领域。研究目的是探讨这些领域的多样性差异，结果表明k-Kemeny问题在这些结构化域中大多难以解决，即使k=2。通过k-Kemeny得分对这些结构化域的多样性进行排名。
### Innovation
创新点在于通过k-Kemeny算法研究不同类型结构化选举数据的多样性。研究显示，k-Kemeny问题在多数结构化域中难以求解，即使只有一个不同排名，证明了不同结构化域的多样性。通过k-Kemeny得分对这些结构化域的多样性进行了排名，区分了不同结构域的复杂程度。
### Conclusion
结论指出，k-Kemeny问题在多种结构化域中不易解决，即便是k的值为2。通过这一问题，对不同结构化域的多样性进行了排序，揭示了不同结构域的复杂性差异。
## 92. `cs.AI` - 增强信息检索的片段知识生成模型：一种多任务学习方法 [PDF](https://arxiv.org/pdf/2509.15658), [HTML](https://arxiv.org/abs/2509.15658)
### Authors
Jisu Kim,Jinhee Park,Changhyun Jeon,Jungwoo Choi,Keonwoo Kim,Minji Hong,Sehyun Kim
### Background
传统的查询扩展技术在解决信息检索中的词汇匹配问题时具有上下文敏感性，但可能导致性能下降。作为一种替代方案，文档扩展研究受到了关注，但现有方法如Doc2Query存在预处理成本过高、索引大小增加以及生成内容可靠性差等问题。为缓解这些问题并寻求更结构化和高效的替代方案，本研究提出了一个方法，该方法将文档划分为片段单位，并为每个片段生成文本数据，以同时提高检索效率和准确性。
### Innovation
该研究提出了一种“片段知识生成模型”，采用基于T5的多任务学习结构，同时从每个文档片段生成标题和候选问题，同时从用户查询中提取关键字。通过单一编码和两个解码过程并行生成和提取三种语义信息，实现了最大化的计算效率。生成的数据作为检索系统中的额外信息被利用。基于305个查询-文档对的GPT评估显示，使用该模型进行检索在Top@10上的准确率为95.41%，显示出优于文档片段级检索的优越性能。
### Conclusion
该研究通过提出一种同时从文档片段生成标题和候选问题的方法，应用于检索管道中，并通过实证证据，展示了在大规模信息检索系统中检索准确性的提高，为信息检索领域提供了贡献。
## 93. `cs.AI` - 通过隐空间逆向工程进行实例生成以用于元黑盒优化 [PDF](https://arxiv.org/pdf/2509.15810), [HTML](https://arxiv.org/abs/2509.15810)
### Authors
Chen Wang,Zeyuan Ma,Zhiguang Cao,Yue-Jiao Gong
### Background
目前，元黑盒优化（MetaBBO）的研究依赖通用元学习的泛化能力，通过预定义的训练问题集来训练基于神经网络的算法设计策略。尽管现有的MetaBBO大多使用CoCo-BBO这样的基准算法套件进行训练，但这类问题实例在多样性方面有限，可能导致元学习方法容易过拟合，从而影响泛化性能。
### Innovation
论文提出了一种实例生成方法，称为LSRE（Latent Space Reverse Engineering），能够生成多样化的训练问题实例，以提高MetaBBO的学习泛化能力。LSRE首先训练一个自动编码器将高维问题特征映射到2维的隐空间中。通过隐空间中的均匀网格采样，产生具有足够多样性的问题实例的隐藏表示。利用遗传编程方法搜索与这些隐藏表示最小L2距离的函数公式，从而逆向工程生成了一个多样化的问题集，称为Diverse-BBO。实验验证了Diverse-BBO在MetaBBO中的优越性和多样性对泛化性能的重要性。
### Conclusion
实验结果表明，Diverse-BBO在 MetaBBO 中比现有训练集的选择具有更优越的性能。进一步的消融研究不仅证明了LSRE设计选择的有效性，还揭示了实例多样性和MetaBBO泛化之间的有趣见解。
## 94. `cs.AI` - CIDER: 一种治疗对品牌痴迷的文本生成图像模型的因果疗法 [PDF](https://arxiv.org/pdf/2509.15803), [HTML](https://arxiv.org/abs/2509.15803)
### Authors
Fangjian Shen,Zifeng Liang,Chao Wang,Wushao Wen
### Background
文本到图像（T2I）模型在生成内容时表现出一种显著但尚未充分探索的“品牌偏见”，即在通用提示下生成包含主导性商业品牌的图像内容，这带来了伦理和法律风险。现有方法通过重新训练模型来缓解这种偏见，成本较高且操作复杂，因此需要一种新的解决方案来减轻这种偏见，同时保持图像质量和审美吸引力，提高生成内容的原创性和公平性，增强生成型AI的可信度.
### Innovation
提出了CIDER，这是一种新型、模型无关的框架，通过提示改进在生成时避免偏见，而不是重新训练模型。CIDER利用轻量级检测器识别品牌内容，并使用视觉语言模型生成风格上不同的替代品。引入了品牌中立度评分（BNS）来量化该问题，并在领先T2I模型上进行了大量实验。结果表明，CIDER显著减少了显性和隐性的偏见，同时保持了图像质量和审美吸引力。这为生成更创新和平等的内容提供了一个实际解决方案，有助于开发可信赖的生成型AI.
### Conclusion
CIDER为减少T2I模型中的品牌偏见提供了一种有效、实用的解决方案，通过减轻偏见，提高了生成内容的创新性和公平性，推动了可信生成型AI的发展。
## 95. `cs.AI` - DeepMech：一种用于化学反应机制预测的机器学习框架 [PDF](https://arxiv.org/pdf/2509.15872), [HTML](https://arxiv.org/abs/2509.15872)
### Authors
Manajit Das,Ajnabiul Hoque,Mayank Baranwal,Raghavan B. Sunoj
### Background
预测完整的步步化学反应机制仍然是一个重大挑战。传统方法依赖于专家驱动的实验或昂贵的量子化学计算，而当前的深度学习方法往往会忽略关键中间体和机制步骤，并且常常出现幻觉。
### Innovation
我们提出了一个基于图的深度学习框架DeepMech，该框架采用原子-键级别注意力，并由通用的机械化操作模板（TMOps）引导，以生成化学反应机制（CRMs）。该模型在我们策划的ReactMech数据集（包含约30,000个CRMs及100,000个原子映射和质量平衡的基本步骤）上进行训练，准确预测基本步骤可达98.98±0.12%，完整CRM任务预测准确率达95.94±0.21%，并且在分布外场景下保持高保真度，同时也能预测副产物。此外，DeepMech还展示了重建从简单的原始底物到复杂生物分子（如丝氨酸和醛戊糖）的多步CRMs的能力，其注意力分析与化学直觉一致，使模型具有可解释性，适用于反应设计。
### Conclusion
DeepMech在预测CRM方面表现出色，且具有高解释性和适用性，未来有望应用于预生物化学的多步CRMs中，进一步揭示生命起源的可能机制。
## 96. `cs.AI` - 自监督跨模态学习在图像到点云注册中的应用 [PDF](https://arxiv.org/pdf/2509.15882), [HTML](https://arxiv.org/abs/2509.15882)
### Authors
Xingmei Wang,Xiaoyu Hu,Chengkai Huang,Ziyan Zeng,Guohao Nie,Quan Z. Sheng,Lina Yao
### Background
在自主系统中，实现2D和3D传感器模态之间的连接是实现稳健感知的关键。然而，图像到点云的配准（I2P）由于图像中纹理丰富但深度模糊以及点云稀疏但度量精确之间的语义-几何差距而面临挑战，同时现有方法容易收敛于局部最优解。
### Innovation
我们提出了CrossI2P，这是一个自监督框架，将跨模态学习和两阶段配准统一在单一的端到端管道中。首先，通过双路径对比学习学习几何-语义融合嵌入空间，以实现无标注的双向2D纹理和3D结构对齐。其次，采用了从粗到细的配准范式：全局阶段通过联合内在模态上下文和跨模态交互建模来建立超点-超像素对应关系，然后通过几何约束的点级精炼进行精确配准。最后，采用动态训练机制与梯度规范化平衡特征对齐、对应关系精炼和姿态估计的损失。
### Conclusion
CrossI2P在KITTI Odometry基准测试中比最先进的方法提高了23.7%，在nuScenes中提高了37.9%，显著提高了精度和鲁棒性。
## 97. `cs.AI` - EvoBrain:时间演化的多通道脑电图图建模方法 [PDF](https://arxiv.org/pdf/2509.15857), [HTML](https://arxiv.org/abs/2509.15857)
### Authors
Rikuto Kotoge,Zheng Chen,Tasuku Kimura,Yasuko Matsubara,Takufumi Yanagisawa,Haruhiko Kishima,Yasushi Sakurai
### Background
动态图神经网络（Dynamic GNNs）通过整合电生理图（EEG）数据中的时空特征，在自动化癫痫检测方面显示出了巨大的潜力。然而，捕捉代表大脑状态（如癫痫和非癫痫）必要的动态特性仍是一项艰巨的任务，并存在两个根本性挑战：一是大多数现有的动态GNN方法基于固定时间的静态图，未能反映大脑连接随癫痫进展演化的特性；二是联合建模时间信号和图结构及其相互作用的努力仍处于初级阶段，往往导致不一致的性能表现。
### Innovation
本文通过以下创新解决上述挑战：首先，首次对这两个问题进行了理论分析，证明了明确动态建模和时间-然后-图动态GNN方法的有效性和必要性；其次，基于这些见解，提出了EvoBrain，这是一种新颖的癫痫检测模型，将双流Mamba架构与通过拉普拉斯位置编码增强的GCN相结合，遵循神经科学的见解；再次，EvoBrain中引入了明确的动态图结构，允许节点和边随着时间演化；最后，提出的工作包括：（a）理论分析证明了明确动态建模和时间-然后-图动态GNN比其他方法具有表达优势；（b）提出了一种新颖而高效的模型，与动态GNN基线相比，显著提高了AUROC 23%和F1分数30%；（c）对复杂早期癫痫预测任务进行了广泛评估。
### Conclusion
本文提出的方法EvoBrain通过引入明确动态图结构和时间-然后-图机制，显著提高了癫痫检测的性能，并对癫痫早期预测任务进行了广泛的评估。
## 98. `cs.AI` - CBPNet: 一种用于边缘设备对抗塑性损失的持续反向传播提示网络 [PDF](https://arxiv.org/pdf/2509.15785), [HTML](https://arxiv.org/abs/2509.15785)
### Authors
Runjie Shao,Boyu Diao,Zijia An,Ruiqi Liu,Yongjun Xu
### Background
为了应对机器人和自动驾驶等应用场景中需要实时响应动态环境的需求，适合边缘设备的高效持续学习方法引起了广泛关注。在这个转变过程中，使用冻结的预训练模型并通过提示来对抗灾难性遗忘成为主流策略。然而，这种方法引入了一个新的关键瓶颈：塑性丧失，模型学习新知识的能力因冻结的主干和提示参数的容量限制而减弱。
### Innovation
我们提出了持续反向传播提示网络（CBPNet），一种高效且参数量少的框架，旨在恢复模型的学习活力。我们创新地引入了高效CBP块，该模块通过自适应重初始化未充分利用的参数来对抗塑性衰减。
### Conclusion
CBPNet 在边缘设备上的实验结果表明其有效性，覆盖多个基准测试。在 Split CIFAR-100 上，相对于强大的基线模型，平均精度提高了超过 1%；在更具挑战性的 Split ImageNet-R 上，实现了 69.41% 的最佳精度。这种性能提升仅通过训练不到主干尺寸 0.2% 的额外参数来实现，验证了我们的方法。
## 99. `cs.AI` - RACap：关系感知提示在轻量级检索增强图像字幕中的应用 [PDF](https://arxiv.org/pdf/2509.15883), [HTML](https://arxiv.org/abs/2509.15883)
### Authors
Xiaosheng Long,Hanyu Wang,Zhentao Song,Kun Luo,Hongde Liu
### Background
近年来，检索增强图像字幕方法通过引入外部知识来弥补对复杂场景理解的不足。但当前方法在关系建模方面存在挑战：（1）语义提示的表示过于粗略，无法捕捉细微关系；（2）缺乏对图像对象及其语义关系的显式建模。
### Innovation
本文提出了一种关系感知检索增强模型RACap，既从检索字幕中挖掘结构化的关系语义，也从图像中识别异构对象。RACap有效检索包含异构视觉信息的结构化关系特征，提升语义一致性和关系表达能力。实验结果表明，RACap仅使用10.8M可训练参数，优于之前的轻量级字幕生成模型。
### Conclusion
RACap不仅挖掘检索字幕中的结构化关系语义，还识别图像中的异构物体，通过检索具有异构视觉信息的结构化关系特征，提升了语义一致性和关系表达能力，实验结果证明了其优越性能。
## 100. `cs.AI` - MoAngelo: 动态场景中的运动感知神经表面重建 [PDF](https://arxiv.org/pdf/2509.15892), [HTML](https://arxiv.org/abs/2509.15892)
### Authors
Mohamed Ebbed,Zorah Lähner
### Background
动态场景重建从多视图视频中仍然是计算机视觉中的一个基本挑战。尽管最近的神经表面重建方法在静态三维重建中取得了显著成果，但将这些方法扩展到动态场景需要解决显著的计算和表示挑战。现有的动态方法多关注于新颖视图合成，导致提取出的网格通常较为嘈杂。即使是为了几何保真度的方法，也常因问题的病态性而导致网格过于平滑。 odio
### Innovation
本文提出了一种新的框架，将静态三维重建方法NeuralAngelo扩展到动态场景中工作。首先利用NeuralAngelo从初始帧重建高质量的模板场景，然后联合优化追踪模板的变形场，并基于时间序列进行细化。灵活的模板允许几何形状更新以包括用变形场无法建模的变化，如遮挡部分或拓扑结构的变化。实验结果表明，在ActorsHQ数据集上对比以前的方法，重建精度更高。
### Conclusion
本文通过动态场景中的运动感知神经表面重建方法MoAngelo实现了高质量的动态场景重建。这种方法提供了更好的准确性和细节，相较于之前的最好方法表现更优。
## 101. `cs.AI` - The Alignment Bottleneck [PDF](https://arxiv.org/pdf/2509.15932), [HTML](https://arxiv.org/abs/2509.15932)
### Authors
Wenjun Cao
### Background
大型语言模型随规模增长而提升，但基于反馈的对齐仍然是系统偏差的。受经济学和认知科学中有限理性概念启发，作者将判断视为资源受限的过程，并将反馈视作受限的通道。在此基础上，作者构建了一个两阶段瀑布模型 $U to H to Y$，其中包含了给定 $S$ 的认知容量 $C_{text{cog}|S}$ 和平均总容量 $bar{C}_{text{tot}|S}$。
### Innovation
作者提出了一种耦合容量的对齐性能区间。该结果基于可分离编码本体混合体上的数据大小无关的 Fano 下界证明，并结合了一个通过 $m bar{C}_{text{tot}|S}$ 控制 KL 项的 PAC-Bayes 上界。当使用规范可观察损失且数据集来自同一混合体时，PAC-Bayes 上界成为同一真正风险的上界。作者还指出，在匹配条件下，两个界由单一容量控制。
### Conclusion
作者认为对齐是接口工程的一个例子：测量并分配有限的容量，管理任务复杂度，并决定信息投入在哪里。结论包括：仅添加标签无法跨越边界；对于更复杂的靶标实现更低风险需要随 $text{log M}$ 增长的容量；当有用信号达到容量制约后，进一步优化通常会拟合通道规则性，这与报告中的溜须拍马和收益黑客行为一致。
## 102. `cs.AI` - 用于高效大语言模型任务适配的分布对齐解码 [PDF](https://arxiv.org/pdf/2509.15888), [HTML](https://arxiv.org/abs/2509.15888)
### Authors
Senkang Hu,Xudong Han,Jinqi Jiang,Yihang Tao,Zihan Fang,Sam Tak Wu Kwong,Yuguang Fang
### Background
使用超大规模参数的自然语言模型在对下游任务进行适应时，即便是采用参数高效微调（PEFT）的方法，成本依然较高。研究者将任务适应重新定义为输出分布对齐：目的是在解码过程中直接引导输出分布向任务分布靠拢，而不是通过权重更新间接引导。基于这一视角，提出了一种轻量级、兼容PEFT且具备理论支撑的方法——定向矢量解码（SVD）
### Innovation
引入了定向矢量解码（SVD），该方法基于较少的预热微调提取任务感知的定向矢量，并据此引导解码过程以调整模型输出分布。SVD理论上与完全微调的梯度步骤等价，并提供了施加在定向矢量上的最优解的全球最优解。在三个任务和九个基准上，SVD结合标准的轻量级微调方法能提高多项选择准确率最高5个百分点，开放性真实性提高2个百分点，且在常识数据集上达到类似收益而无需增加额外可训练参数。因此，SVD提供了一种轻量级、理论支撑明确的大语言模型任务适应路径
### Conclusion
定向矢量解码（SVD）是一种轻量级的、理论上合理的、兼容PEFT的方法，能够在不增加额外训练参数的情况下，显著增强大型语言模型在多种任务上的适应性。
## 103. `cs.AI` - 对称不变图网络在可解释的纳米多孔材料设计中的应用 [PDF](https://arxiv.org/pdf/2509.15908), [HTML](https://arxiv.org/abs/2509.15908)
### Authors
Zhenhao Zhou,Salman Bin Kashif,Dawei Feng,Jin-Hu Dou,Kaihang Shi,Tao Deng,Zhenpeng Yao
### Background
纳米多孔材料在可持续应用中具有广阔前景，但由于其庞大的化学空间，设计效率面临挑战。尽管机器学习可以加速探索过程，但现有模型要么缺乏可解释性，要么缺乏对晶体几何与性质之间关系的解释精度。该研究提出了一种三维周期空间采样方法，将大尺寸纳米多孔结构分解为局部几何站点，用于综合预测性质和站点贡献量化。
### Innovation
该研究采用了一种可解释的图网络方法，用于纳米多孔材料的设计。该方法不仅提高了预测精度和数据效率，还在气体储存、分离和电传导方面实现了最先进的性能。同时，这种方法允许对预测进行解释，并准确识别对特定性质具有重要意义的局部站点。通过识别不同纳米多孔框架中具有可转移性的高性能站点，该方法为可解释的、对称意识的纳米多孔材料设计开辟了途径。
### Conclusion
该方法为纳米多孔材料设计提供了新的途径，不仅提高了预测精度和数据效率，还实现了对性质预测结果的可解释性，有助于进一步了解晶体几何与性质之间的关系，并为其他材料的设计提供了可能性，如分子晶体。
## 104. `cs.AI` - 自我组合：平均速度流配对的一步语音增强 [PDF](https://arxiv.org/pdf/2509.15952), [HTML](https://arxiv.org/abs/2509.15952)
### Authors
Gang Yang,Yue Lei,Wenxin Tai,Jin Wu,Jia Chen,Ting Zhong,Fan Zhou
### Background
扩散和流匹配（FM）模型在语音增强（SE）方面取得了显著进步，但它们依赖多步生成计算代价高昂且容易受到离散化误差的影响。近期的一步生成建模进展，特别是MeanFlow，通过重新定义动力学来通过平均速度场提供了一种有前景的替代方案。
### Innovation
提出了COSE，一种专为语音增强设计的一步骤FM框架。通过引入速度组合身份来高效计算平均速度，从而避免了昂贵的计算同时保持理论一致性，并实现了竞争性的增强质量。
### Conclusion
在标准基准上的广泛实验表明，COSE的采样速度提高了5倍，训练成本减少了40%，而在不牺牲语音质量的情况下实现了这些改进。
## 105. `cs.AI` - 为海上自主水面船舶（MASS）的可解释AI:自适应界面和可信的人工智能协作 [PDF](https://arxiv.org/pdf/2509.15959), [HTML](https://arxiv.org/abs/2509.15959)
### Authors
Zhuoyue Zhang,Haitong Xu
### Background
随着人工智能、传感器和网络技术的进步，海上自主航行正加速发展，但不透明的决策和人机交互不匹配仍然是安全采用的关键障碍。
### Innovation
本文综合了100篇关于海上自主水面船（MASS）的自动化透明度研究，从情况意识（SA）、人因工程、界面设计和法规等角度出发，提出了透明度在三个层次上的设计策略，并提出了一种耦合操作员状态估计与可解释决策支持的自适应透明性框架，以减少认知负担并提高接管及时性。
### Conclusion
研究成果强调了实际操作中的关键指标展示（如CPA/TCPA风险条形图、稳健性热图）、透明模型输出（规则可追溯性、置信度）和训练管道（HIL/MIL、模拟）作为提高MASS操作安全性的重要杠杆。
## 106. `cs.AI` - ArchesClimate: 通过流匹配生成的概率十年期集合 [PDF](https://arxiv.org/pdf/2509.15942), [HTML](https://arxiv.org/abs/2509.15942)
### Authors
Graham Clyne,Guillaume Couairon,Guillaume Gastineau,Claire Monteleoni,Anastase Charantonis
### Background
气候预测存在与气候系统及其相互作用相关的不确定性。通常使用气候模型通过在不同初始条件下进行重复模拟来量化这些不确定性，这需要大量计算资源。
### Innovation
阿克汗斯气候（ArchesClimate）是一个基于深度学习的气候模型模拟器，用于减少这种成本。它通过使用IPSL-CM6A-LR气候模型的十多年回溯数据集进行训练，并模仿ArchesWeatherGen的方法来预测短期气候。训练完成后，模型可以在一个月预告期内生成状态，并可用于自回归模拟任意长度的气候模拟，生成的模拟在10年内稳定且物理上一致，对于几个重要气候变量，其模拟结果与IPSL模型相似，这表明气候模型模拟器可以显著降低气候模型模拟的成本。
### Conclusion
阿克汗斯气候展示了其在减少气候模型模拟成本方面的潜力，提出了通过流匹配生成概率十年期集合的新方法。
## 107. `cs.AI` - 从数据到诊断：儿童白血病预测的大型综合骨髓数据集和AI方法 [PDF](https://arxiv.org/pdf/2509.15895), [HTML](https://arxiv.org/abs/2509.15895)
### Authors
Henning Höfener(1),Farina Kock(1),Martina Pontones(2),Tabita Ghete(2 and 3),David Pfrang(1),Nicholas Dickel(4),Meik Kunz(4),Daniela P. Schacherer(1),David A. Clunie(5),Andrey Fedorov(6),Max Westphal(1),Markus Metzler(2 and 3 and 7) ((1) Fraunhofer Institute for Digital Medicine MEVIS, Bremen, Germany, (2) Department of Pediatrics and Adolescent Medicine, University Hospital Erlangen, Erlangen, Germany, (3) Bavarian Cancer Research Center (BZKF), Erlangen, Germany, (4) Medical Informatics, Friedrich-Alexander University of Erlangen-Nürnberg, Erlangen, Germany, (5) PixelMed Publishing LLC, Bangor, PA, USA, (6) Department of Radiology, Brigham and Women's Hospital and Harvard Medical School, Boston, MA, USA, (7) Comprehensive Cancer Center Erlangen-EMN, Erlangen, Germany)
### Background
白血病诊断主要依赖于骨髓形态的宏观分析，并辅以实验室参数，这一过程既复杂又耗时。尽管已经提出了基于人工智能（AI）的解决方案，但这些方案大多使用私有数据集，只覆盖诊断管道的一部分。因此，本文介绍了一个大规模、高质量、公开可用的白血病骨髓数据集，该数据集涵盖了诊断过程的各个阶段，从细胞检测到诊断。该数据集包含了246名儿童患者的诊断、临床和实验室信息，超过40,000个带有边界框注释的细胞，以及超过28,000个高质量的类别标签，使其成为迄今为止最全面的公开数据集。
### Innovation
该研究提出并构建了一个大型、高质量、公开的白血病骨髓数据集，涵盖了细胞检测到最终诊断的整个过程，是目前最全面的数据集。此外，该研究还提出了针对这一大数据集的细胞检测、细胞分类和疾病预测方法。这些方法在AI模型评估中显示了高精度，尤其是细胞检测的平均精度为0.96，细胞分类的AUC为0.98，以及33类细胞分类的F1分数为0.61，疾病预测的平均F1分数为0.90。这些方法为AI辅助诊断提供了有力的支持，并将推动该领域进一步的研究与发展，从而实现更准确的诊断，改善患者结果。
### Conclusion
虽然所提供的方法证实了其在AI辅助诊断中的实用性，但该数据集将促进该领域的进一步研究与开发，最终有助于更精确的诊断和改善患者结果。
## 108. `cs.AI` - 文本基于网格世界的基模型作为世界模型基础研究 [PDF](https://arxiv.org/pdf/2509.15915), [HTML](https://arxiv.org/abs/2509.15915)
### Authors
Remo Sasso,Michelangelo Conserva,Dominik Jeurissen,Paulo Rauber
### Background
尽管从零开始的强化学习在使用高效模拟器解决顺序决策任务方面取得了令人印象深刻的成果，但在需要更高效样本文本的现实应用中，实际的交互变得至关重要。基模型（FMs）因其广泛的知识和推理能力而成为提高样本文本的最佳候选人，但是将它们有效地集成到强化学习框架中仍不清楚。本文通过评估两种创新策略，探讨了如何利用基模型来提升强化学习的过程：一是使用基先验世界模型（FWMs），利用基模型的先验知识，使学习和评估代理可以通过模拟交互来进行；二是利用基代理（FAs）通过基模型的推理能力进行决策。研究在适合当前大型语言模型（LLMs）的网格世界环境家族中进行实验性评估，结果显示，基模型在语言模型的提升已经在改进FWMs和FAs方面有所体现，基于当前LLMs的基代理已经能为简单的环境提供优秀的策略，并且基模型和强化学习代理的耦合对于更多的复杂场景具有很高的潜力，尤其是在部分可观测性和不确定性的情况下
### Innovation
本文提出了两种将基模型应用于强化学习的新策略：一是使用基先验世界模型（FWMs），利用基模型的先验知识来训练和评估通过模拟交互的代理；二是利用基代理模型（FAs）通过改进决策。研究还在适合当前大型语言模型（LLMs）的网格世界环境家族中对此进行了实验性评估
### Conclusion
基模型的提升已经转化为更好的FWMs和FAs；基于当前LLMs的基代理可以为简单的环境提供优秀的策略；基模型与强化学习代理的结合，特别是在具有部分观测性和随机性的复杂环境中，具有极大的潜力。
## 109. `cs.AI` - 通过离线奖励评估与策略搜索增强生成化自动竞价 [PDF](https://arxiv.org/pdf/2509.15927), [HTML](https://arxiv.org/abs/2509.15927)
### Authors
Zhiyu Mou,Yiqin Lv,Miao Xu,Cheems Wang,Yixiu Mao,Qichen Ye,Chao Li,Rongquan Bai,Chuan Yu,Jian Xu,Bo Zheng
### Background
自动出价是广告商提高广告效果的重要工具。近期研究表明，基于AI生成的竞价（AIGB）方法，将自动出价任务转化为轨迹生成任务，并利用条件扩散模型在线下数据上训练执行者，显示出比传统基于离线强化学习（RL）的自动出价方法优越且稳定的性能。然而，现有AIGB方法仍存在因忽视精细化生成质量评估和无法探索超出静态数据集的问题而产生的性能瓶颈。因此，需要提出一种新的方法，以解决这些问题，增强自动出价性能。
### Innovation
本文提出了一种名为AIGB-Pearl（基于RL的规划与评估器）的新型方法，该方法融合了生成规划和策略优化。AIGB-Pearl的关键在于构建非自举的轨迹评估器来分配奖励并引导策略搜索，使规划者可以通过交互逐步优化其生成质量。此外，为了在离线环境中提高轨迹评估器的准确性，本文结合了三种关键技术：（i）基于大型语言模型（LLM）的结构以提高表示能力，（ii）结合点对点和点对点损失以更有效地学习评分，（iii）适应性集成专家反馈以增强泛化能力。在模拟和现实世界的广告系统上的广泛实验表明了本文方法处于领先水平。
### Conclusion
本文提出了一种名为AIGB-Pearl的新颖方法，融合了生成规划和策略优化，通过构建非自举的轨迹评估器和结合增强的评估技术，有效地提高了自动出价的性能。实验结果证明了该方法在各种广告系统中的优越性与稳定性。
## 110. `cs.AI` - BEFT: 语言模型偏置高效微调 [PDF](https://arxiv.org/pdf/2509.15974), [HTML](https://arxiv.org/abs/2509.15974)
### Authors
Baichuan Huang,Ananth Balashankar,Amir Aminifar
### Background
参数高效的微调（PEFT）技术中，调整所有偏置项已经因其即用性和在低数据集环境中的竞争性表现而表现出色。然而，不同偏置项（如查询、键或值投影中的偏置项）对下游性能的影响尚不清楚。尽管现有的方法可以在一定程度上指导如何选择特定的偏置项进行调整，但这些方法提供的指导有限。
### Innovation
本文提出了一种选择需要微调的偏置项的方法，奠定了偏置高效微调（BEFT）的基础。该方法在多种大型语言模型（从110M到6.7B参数）上进行了广泛评估，并且结果显示，与现有方法相比，BEFT在各种下游任务中效果更好。
### Conclusion
BEFT方法在不同类型的下游任务中证明了自己的有效性和优越性，特别是在分类、多项选择和生成任务中展现出色表现。
## 111. `cs.AI` - 基于不确定性平滑策略正则化以实现少示例的强化学习 [PDF](https://arxiv.org/pdf/2509.15981), [HTML](https://arxiv.org/abs/2509.15981)
### Authors
Yujie Zhu,Charles A. Hepburn,Matthew Thorpe,Giovanni Montana
### Background
在使用稀疏奖励的强化学习中，演示可以加快学习，但决定何时模仿这些演示仍具有挑战性。
### Innovation
本文提出了一种名为SPReD（Smooth Policy Regularisation from Demonstrations）的框架，用于解决何时模仿演示与遵循自身策略之间的基本问题。SPReD使用集成方法显式建模演示与策略行动的Q值分布，并通过不确定性为比较定量。通过开发两个互补的方法：基于概率估计演示优胜性的方法以及基于优势通过统计显著性调整模仿的方法，SPReD实现了连续且与不确定性成比例的正则化权重，减少了训练中的梯度方差。
### Conclusion
尽管SPReD实现了简化的计算复杂度，但在八项机器人任务的实验中仍取得了显著成果，与现有技术相比，在复杂任务中性能提高了最多14倍，且对演示的质量和数量具有鲁棒性。
## 112. `cs.AI` - 在自我监督的深度估计中实现更清晰的物体边界 [PDF](https://arxiv.org/pdf/2509.15987), [HTML](https://arxiv.org/abs/2509.15987)
### Authors
Aurélien Cecille,Stefan Duffner,Franck Davoine,Rémi Agier,Thibault Neveu
### Background
单目深度估计对于3D场景理解至关重要，但现有方法往往在物体边界处产生模糊度，引入虚假的中间3D点。通常要想实现锐利的边缘需要非常精细的监督，然而我们的方法仅通过自我监督就能生成清晰的深度不连续性。
### Innovation
我们通过将每个像素的深度建模为混合分布，捕捉多个可能的深度并从直接回归转移到混合权重的不确定性。这种形式可以通过方差感知的损失函数和不确定性传播无缝集成到现有的管道中。
### Conclusion
在KITT和VKITTIv2上的广泛评估表明，我们的方法在边界锐度方面可以提高高达35%的性能，并且相比最先进的基线方法改进了点云质量。
## 113. `cs.AI` - 一种用于机器人现实世界强化学习的视觉-语言-动作-评估器模型 [PDF](https://arxiv.org/pdf/2509.15937), [HTML](https://arxiv.org/abs/2509.15937)
### Authors
Shaopeng Zhai,Qi Zhang,Tianyi Zhang,Fuxian Huang,Haoran Zhang,Ming Zhou,Shengzhe Zhang,Litao Liu,Sixu Lin,Jiangmiao Pang
### Background
机器人的现实世界强化学习（RL）受到稀疏的人工奖励和探索效率低的限制。现有方法需要针对特定任务进行奖励工程，这限制了其应用灵活性。
### Innovation
引入了VLAC（Vision-Language-Action-Critic），这是一种基于InternVL并结合大规模异构数据集训练的通用过程奖励模型。该模型能够直接输出密集的进展和完成信号，简化了奖励工程，并支持在看不见的任务和环境中实现一次性上下文转移。VLAC通过强化视觉语言数据来增强感知、对话和推理能力，并通过机器人和人类轨迹数据来实现动作生成和进展估计，同时通过生成大量负样本和语义不匹配样本来增强拒绝无关提示并检测退化。
### Conclusion
VLAC在四个不同的真实世界操作任务中，将成功率从约30%提升到约90%。进一步结合人类在环的干预，提升了样本效率，在200个真实世界交互周期后实现了100%的成功率。
## 114. `cs.AI` - MoE-CE: 提高基于混合专家框架的深度学习信道估计的泛化能力 [PDF](https://arxiv.org/pdf/2509.15964), [HTML](https://arxiv.org/abs/2509.15964)
### Authors
Tianyu Li,Yan Xin,Jianzhong(Charlie)Zhang
### Background
可靠的信道估计（CE）对于在动态无线环境中实现稳健的通信至关重要，因为模型需要在各种条件下进行泛化，比如信噪比（SNR）、资源块数（RB数量）和信道特性。传统的基于深度学习（DL）的方法难以在这些多样化的情境下有效地泛化，尤其是在多任务和零样本情况下。因此，现有方法面临在多种条件下进行有效泛化的挑战。
### Innovation
本文提出了一种灵活的混合专家（MoE）框架，被称为MoE-CE，旨在增强基于深度学习的信道估计方法的泛化能力。该框架利用了多个专长不同的专家子网络，每个子网络均针对特定的信道特性进行优化，以及一个学习路由器，能够动态地选择最相关的专家。这种架构在不显著增加计算成本的情况下，提高了模型的容量和适应性，同时也与底层模型和学习算法的选择无关。通过在涵盖了不同SNR、RB数量和信道特性的合成数据集上进行的广泛实验，MoE-CE在多任务和零样本评估中均表现出色，显著优于传统的DL方法，同时保持了高效的性能。
### Conclusion
与传统的DL方法相比，MoE-CE在多种条件下，包括多任务和零样本场景下的泛化性能有了显著提升，同时保持着高的效率。
## 115. `cs.AI` - EmoHeal：从细粒度情绪中实现个性化治疗性音乐检索的端到端系统 [PDF](https://arxiv.org/pdf/2509.15986), [HTML](https://arxiv.org/abs/2509.15986)
### Authors
Xinchen Wan,Jinhua Liang,Huan Zhang
### Background
现有的数字心理健康工具往往忽略了日常生活挑战背后细微的情绪状态。例如，睡眠前的焦虑影响全球超过15亿人，但目前的方法仍大都静态且“一刀切”，未能适应个人需要。为此，本文提出了一种名为EmoHeal的系统，提供个性化的三阶段支持性叙述。EmoHeal通过微调过的XLM-RoBERTa模型从用户文本中检测出27种细微的情绪，并通过基于音乐治疗原则的知识图谱（GEMS、异质原则）将其映射到音乐参数。然后使用CLAMP3模型检索音频视频内容，引导用户从当前状态过渡到更平静的状态（“匹配-指导-目标”）。
### Innovation
EmoHeal创新性地开发了一个端到端系统，能够从用户文本中检测出27种细微的情绪，并通过知识图谱映射到音乐参数，再利用CLAMP3模型检索音频视频内容，以帮助用户过渡到更平静的状态。该系统还通过一项针对40名参与者的内源性研究证实了其有效的支持效果和细粒度情感识别的准确性，两者与治疗方法效果之间存在显著的相关性。
### Conclusion
这些发现确立了以理论为导向、情绪感知的数字心理健康工具的可行性，并提供了将音乐治疗原理实现的可扩展AI蓝图。
## 116. `cs.AI` - AI方法在通用拓扑结构下排列电路合成中的应用 [PDF](https://arxiv.org/pdf/2509.16020), [HTML](https://arxiv.org/abs/2509.16020)
### Authors
Victor Villar,Juan Cruz-Benito,Ismael Faro,David Kremer
### Background
本研究探讨了使用人工智能（AI）方法进行排列电路的合成和优化，特别是在不同拓扑结构中的应用。以往的研究常常为每个特定的拓扑结构开发专门的模型，导致了模型泛化能力不足的问题。本研究则旨在开发一种适用于多种拓扑结构的通用模型，并通过自适应机制提高模型的泛化能力，以实现对不同拓扑结构下的电路合成任务的有效支持。
### Innovation
研究提出了一种使用强化学习（RL）技术在通用矩形晶格上训练基础模型的方法。通过动态应用遮蔽机制选择特定拓扑结构，模型能够在未见过的拓扑结构上进行电路合成。此外，该研究展示了一种对特定拓扑结构进行微调的方法，以进一步提升模型在这些特定拓扑结构下的性能。这种方法能够显著提升电路合成的效果，为将AI模型高效地集成到编译流程中打开新的路径。
### Conclusion
研究结果表明，所提出的AI模型在不同拓扑结构下的电路合成效果超过了传统启发式方法，并且可以与先前专门针对特定拓扑结构的AI模型相媲美。通过微调模型，其对特定兴趣拓扑结构的支持也能得到增强。这种单一训练模型的使用为电路合成的多样性提供了有效的支持，具有重要的实用价值。
## 117. `cs.AI` - See&Trek: Training-Free Spatial Prompting for Multimodal Large Language Model [PDF](https://arxiv.org/pdf/2509.16087), [HTML](https://arxiv.org/abs/2509.16087)
### Authors
Pengteng Li,Pinhao Song,Wuyang Li,Weiyu Guo,Huizai Yao,Yijie Xu,Dugang Liu,Hui Xiong
### Background
以往的工作虽然引入了诸如深度信息或点云等模态来增强语言模型的时空理解能力，但纯粹基于视觉和时空理解仍然较少探索。本文针对这一不足，提出了SEE&TREK，这是一个无需训练的提示框架，旨在增强多模态大型语言模型（MLLMs）的时空理解能力。
### Innovation
SEE&TREK通过增加视觉多样性（采用最大语义丰富度采样从感知模型中提取语义丰富的关键帧）和运动重建（模拟视觉轨迹并将相对空间位置编码到关键帧中以保持时空关系和时间连贯性）两个核心原则来填补这一空白。该方法无需训练和GPU，只需一次前向传播，即可无缝集成到现有的MLLM中。
### Conclusion
广泛的实验表明，SEE&TREK在多个视觉理解任务上显著提升了MLLMs的表现，最高提升了3.5%，为增强多模态大型语言模型的空间智能提供了有力支持。
## 118. `cs.AI` - 思考、表达然后发言：连接复杂思绪和可理解的言语 [PDF](https://arxiv.org/pdf/2509.16028), [HTML](https://arxiv.org/abs/2509.16028)
### Authors
Sang Hoon Woo,Sehun Lee,Kang-wook Kim,Gunhee Kim
### Background
随着语言模型（LLMs）在口头对话系统中的应用越来越广泛，人们希望利用其先进的推理能力。然而，直接将LLMs应用于口头交流经常会得到次优的结果，因为理想的文字表达和口头表达之间存在不匹配。虽然现有方法尝试调整LLMs以产生更适合口语输出的结果，但这些方法对推理性能的具体影响尚未得到充分探索。因此，作者提出了一个分步骤的方法来解决这一问题，该方法将推理与口头表达分离，确保LLMs的全部推理能力得以保留。
### Innovation
作者提出了Think-Verbalize-Speak框架，该框架将推理和口头表达分开，提出了一个中间步骤——称为‘表达’（verbalizing），将思想转化为自然、适合口头表达的文本。此外，作者还提出了一个高效的‘ReVerT’表达器，基于增量和异步总结。实验表明，该方法提高了口语的自然性和简洁性，同时对推理性能的影响最小。
### Conclusion
本研究表明，通过将推理和口头表达分离，并利用中间的‘表达’步骤，可以有效提高口语交流的自然性和简洁性，同时保留LLMs的全部推理能力。
## 119. `cs.AI` - Monocular Depth Estimate透明性评估：洞悉深度 [PDF](https://arxiv.org/pdf/2509.15980), [HTML](https://arxiv.org/abs/2509.15980)
### Authors
Lorenzo Cirillo,Claudio Schiavella,Lorenzo Papa,Paolo Russo,Irene Amerini
### Background
可解释的人工智能越来越多地用于理解深度学习模型的决策过程，并增强对其应用的信心。虽然单目深度估计(MDE)已在实际应用中广泛部署，但其可解释性研究相对不足。本文旨在研究如何分析MDE网络，将输入图像映射到预测的深度图。具体而言，我们探讨了虽然已建立的功能归属方法（如显著性图、集成梯度和注意力滚动）在不同计算复杂度的MDE模型（包括轻量级的METER和深度的PixelFormer）上的应用效果。通过选择性地扰动由解释性方法识别的最相关和最不相关的像素，并分析这些扰动对模型输出的影响，评估生成的视觉解释的质量。此外，在现有评估指标可能无法充分衡量MDE视觉解释的有效性时，我们引入了归属忠实度（Attribution Fidelity）这一新度量标准，以评估特性归属的可靠性，检查其与预测深度图的契合度。实验结果表明，显著性图和集成梯度在轻量级和深度模型的MDE中最能突出最具重要性的输入特征。同时我们展示了归属忠实度在识别解释方法是否生成可靠的视觉地图方面非常有效，即使在传统度量可能表明良好结果的情况下也是如此。
### Innovation
引入新的度量标准——归属忠实度（Attribution Fidelity），用以评估特征归属的可靠性，并检查其与预测深度图的契合度。这是现有评估指标的补充，特别是在MDE领域中的视觉解释评估方面。此外，文章对MDE的几种不同复杂度模型使用了普遍接受的解释方法，如显著性图和集成梯度进行研究，以验证它们的性能。
### Conclusion
研究表明，显著性图和集成梯度能够有效地在轻量级和深度模型的MDE任务中突出最重要的输入特征。同时，归属忠实度是评估解释方法有效性的有效工具，即使在传统度量可能表明结果满意的场景中也能有效识别解释方法的潜在问题。
## 120. `cs.AI` - Fed-PISA: Federated Voice Cloning via Personalized Identity-Style Adaptation [PDF](https://arxiv.org/pdf/2509.16010), [HTML](https://arxiv.org/abs/2509.16010)
### Authors
Qi Wang,Shituo Ma,Guoxin Yu,Hanyang Peng,Yue Yu
### Background
Text-to-Speech (TTS)旨在通过少量目标讲话人的数据生成具有表现力和个人化的语音。Federated Learning (FL)提供了一种协作且保护隐私的框架来实现这一目标，但现有方法存在高通信成本，倾向于压制风格差异，导致个人化不足。
### Innovation
Fed-PISA引入了一种名为Disentangled Low-Rank Adaptation (LoRA)的机制，保留了讲话人的音色并通过私有的ID-LoRA本地化，同时只传输轻量级的风格-LoRA到服务器，从而减少参数交换。聚合方法借鉴了协同过滤，用于为每个客户端创建定制模型，从具有类似风格的同伴中学习。
### Conclusion
实验表明，Fed-PISA在风格表现力、自然度和说话人相似性方面有所改进，优于标准的联邦学习基线，同时通信成本最小。
## 121. `cs.AI` - 基于多模态基础模型的会话级口语评估方法及多目标学习 [PDF](https://arxiv.org/pdf/2509.16025), [HTML](https://arxiv.org/abs/2509.16025)
### Authors
Hong-Yun Lin,Jhen-Ke Lin,Chung-Chun Wang,Hao-Chien Lu,Berlin Chen
### Background
口语评估（SLA）用于从自发口语中估算学习者的口语水平。不断增长的二语言英语学习者人口增加了对可靠SLA的需求，这对计算机辅助语言学习（CALL）至关重要。现有的努力常常依赖于存在错误传播风险的分段流水线，或者短音频窗口的端到端模型，这可能会错过话语层面的证据。本论文介绍了一种新颖的多模态基础模型方法，可以在单个通道上进行会话级评估。通过结合多目标学习与静音ASR模型基于的语音先验，该方法实现了无需人工特征工程的兼顾整体和特征层面SLA目标的学习。通过处理整个目标语言学习者的回应会话，模型在预测整体口语水平方面表现卓越。实验结果表明，该论文提出的方法超越了之前的最先进的分段系统，并且在各个部分之间表现出良好的泛化能力，产生了一个适用于CALL应用程序的紧凑部署评分器。
### Innovation
该论文提出了一种新的多模态基础模型方法，能够在单个通道上进行会话级评估，并结合多目标学习与静音ASR模型基于的语音先验，实现无需人工特征工程的兼顾整体和特征层面SLA目标的学习。通过处理整个目标语言学习者的回应会话，该方法在预测整体口语水平方面表现出色。该方法优于现有的分段流水线和端到端模型，并且具有跨部分的稳健泛化能力。
### Conclusion
本研究提出的方法在 Speak & Improve 标准上表现出色，具有显著改善的性能和可靠的跨部分泛化能力，生成了一个紧凑的、适合于 CALL 应用的评分器，为口语评估的准确性和效率提供了新的解决方案。
## 122. `cs.AI` - 超越点得分：基于分解的标准评价LLM响应 [PDF](https://arxiv.org/pdf/2509.16093), [HTML](https://arxiv.org/abs/2509.16093)
### Authors
Fangyi Yu,Nabeel Seedat,Dasha Herrmannova,Frank Schilder,Jonathan Richard Schwarz
### Background
在法律或医学等高风险领域，长期形式的答案评估仍是一个基本挑战。标准的评估指标如BLEU和ROUGE难以捕捉到语义上的正确性，而当前基于大规模语言模型（LLM）的评估器倾向于将高质量回答的各个精细方面简化为一个单一、未区分的分数。因此，需要一种新的评价框架，不仅能准确评估回答的质量，还能提供可解释的评估结果。
### Innovation
本文介绍了一种分解的大规模语言模型评估框架——DeCE（Decomposed Evaluation）。DeCE通过自动从高质量答案要求中提取实例特定的标准，将精度（事实准确性和相关性）和召回率（涵盖必要概念的程度）分离。这种方法是模型无关且领域通用的，不需要预设的类别或手动制作的评判标准。它还展示了可解释的权衡：通用模型倾向于召回，而专业模型倾向于精确度。DeCE的评估结果与专家判断的相关性显著更高，达到了0.78，远超其他传统评估指标和其他现代多维度评估器（r值分别为0.12和0.48）。
### Conclusion
DeCE是专家领域中提供可解释的、可操作的大规模语言模型评估框架，并且显示出高可扩展性，因为在测试中只有11.95%的由LLM生成的标准需要专家修订。
## 123. `cs.AI` - DiffusionNFT: 前向过程中的在线扩散强化学习 [PDF](https://arxiv.org/pdf/2509.16117), [HTML](https://arxiv.org/abs/2509.16117)
### Authors
Kaiwen Zheng,Huayu Chen,Haotian Ye,Haoxiang Wang,Qinsheng Zhang,Kai Jiang,Hang Su,Stefano Ermon,Jun Zhu,Ming-Yu Liu
### Background
在线强化学习（RL）已成为后训练语言模型的核心，但将其扩展到扩散模型仍然具有挑战性，因为无法处理可计算的似然性。尽管最近的工作通过离散化反向采样过程来实现GRPO风格的训练，但这些方法存在根本性的问题，如求解器限制、正反过程不一致以及与无分类器引导（CFG）的复杂集成。
### Innovation
引入了Diffusion Negative-aware FineTuning（DiffusionNFT），这是一种新的在线RL范式，通过流匹配直接优化扩散模型的正向过程。DiffusionNFT通过对比正向和负向生成来定义隐含的策略改进方向，自然地将强化信号纳入监督学习目标。这种表述使训练可以在任意黑盒求解器下进行，消除了似然估计需求，并且只需要干净的图像而不是采样轨迹来优化策略。DiffusionNFT相较于FlowGRPO在头对头比较中效率提高了25倍以上，同时无CFG依赖。例如，在1000步内，DiffusionNFT将GenEval分数从0.24提升至0.98，而FlowGRPO在超过5000步的训练下且使用额外的CFG措施，分数仅为0.95。利用多个奖励模型，DiffusionNFT显著提升了SD3.5-Medium在所有测试基准上的性能。
### Conclusion
DiffusionNFT为在线扩散强化学习提供了一种新的高效方法，解决了现有方法中的多种限制，通过减少对采样数据的需求和强化信号自然集成的特性，展示出显著的优势。
## 124. `cs.AI` - 使用可持续和无创唾液生物标志物的自闭症谱系障碍网络检测 [PDF](https://arxiv.org/pdf/2509.16126), [HTML](https://arxiv.org/abs/2509.16126)
### Authors
Janayna M. Fernandes,Robinson Sabino-Silva,Murillo G. Carneiro
### Background
自闭症谱系障碍（ASD）缺乏可靠生物标志物，导致早期诊断延迟。通过分析159份唾液样本的ATR-FTIR光谱数据，本文旨在开发一种基于遗传算法的网络优化框架（GANet），以利用PageRank和Degree进行基于重要性的特征表征。该框架系统地优化网络结构，以从高维光谱数据中提取有意义的模式，从而提高ASD的检测准确性，减少诊断时间。
### Innovation
开发了GANet，这是一种基于遗传算法的网络优化框架，利用PageRank和Degree对光谱数据进行特征提取和分类。与线性判别分析、支持向量机和深度学习模型相比，GANet在ASD检测中表现优异，达到78%的准确率、61%的灵敏度、90%的特异性和74%的均值准确度，证明了GANet作为精准ASD检测和更广泛光谱健康应用的鲁棒且生物启发式的非侵入性工具的潜力。
### Conclusion
研究结果表明，GANet具有成为精确ASD检测工具的潜力，不仅适用于早期诊断ASD，还可能扩展到其他基于光谱的健康应用中。该网络优化框架提供了一种高效、鲁棒的解决方案，能够识别出可靠的生物谱特征，用于ASD的无创检测。
## 125. `cs.AI` - 通过张量分解实现鲁棒视觉-语言模型：一种对抗性攻击防御方法 [PDF](https://arxiv.org/pdf/2509.16163), [HTML](https://arxiv.org/abs/2509.16163)
### Authors
Het Patel,Muzammil Allie,Qian Zhang,Jia Chen,Evangelos E. Papalexakis
### Background
视觉语言模型（VLMs）在多模态理解方面表现出色，但容易受到对抗性攻击的影响。现有的防御方法通常需要昂贵的重新训练或显著的架构改变，增加了实施的复杂性和成本。
### Innovation
本文提出了一种轻量级的基于张量分解的防御方法，适用于任何预训练的VLM，无需重新训练。该方法通过分解和重构视觉编码器的表示，过滤出对抗性噪声的同时保留其意义。实验结果表明，该方法能提高VLMs的鲁棒性，特别是在COCO和Flickr30K数据集上表现出色。对于Flickr30K，该方法恢复了12.3%由于攻击损失的性能，使Recall@1准确率从7.5%提高到19.8%；对于COCO，恢复了8.1%的性能损失，提高了准确率从3.8%到11.9%。分析发现，最优的张量分解方法是使用低阶（8-32）和低残差强度（α=0.1-0.2）的张量训练分解。
### Conclusion
此方法是一个实用的可插拔解决方案，可以以最小的开销应用于现有的VLMs。
## 126. `cs.AI` - 快速使用二分法的OTSU阈值算法 [PDF](https://arxiv.org/pdf/2509.16179), [HTML](https://arxiv.org/abs/2509.16179)
### Authors
Sai Varun Kodathala
### Background
OTSU阈值算法是图像分割中的基本技术，但由于需要对所有可能的阈值进行穷尽搜索，因此计算效率受到了极大的限制。
### Innovation
本文提出了一种优化实现，利用二分法来利用类间方差函数的单模特征。该方法将计算复杂度从O(L)降低到O(log L)，同时保持分割准确性。实验验证显示，在48个标准测试图像上，与传统的穷尽搜索方法相比，方差计算减少了91.63%，算法迭代减少了97.21%。在测试案例中，使用二分法在66.67%的情况下能达到精准阈值匹配，95.83%的差异不超过5个灰度级。该算法保持了理论对数界限内的普遍收敛性，提供适合实时应用的确定性性能保证，而无需牺牲原始OTSU方法的理论基础或分割质量。这一优化解决了大规模图像处理系统中的关键计算瓶颈，
### Conclusion
该优化方法不仅提高了计算效率，减少了大量计算步骤，还在保持分割质量的同时，确保了算法的稳定性和可靠性，尤其适用于实时应用。
## 127. `cs.AI` - 通讯到环流：使用5G GNSS信号和深度学习进行三维风场检索和实时预测 [PDF](https://arxiv.org/pdf/2509.16068), [HTML](https://arxiv.org/abs/2509.16068)
### Authors
Yuchen Ye,Hong Liang,Chaoxia Yuan,Mingyu Li,Aoqi Zhou,Chunqing Shang,Hua Cai,Peixi Liu,Kezuan Wang,Yifeng Zheng
### Background
准确的大气风场信息对于气候变化预测、航空安全和灾害风险管理等应用至关重要。然而，由于传统现场观测和遥感技术的局限性，以及数值天气预报（NWP）模型计算成本高且存在偏差，获取高时空分辨率的风数据仍然是一个挑战。本文探讨了利用5G全球导航卫星系统（GNSS）信号的信号强度变化，通过一个新颖的深度学习框架G-WindCast来检索和预测三维大气风场的问题。FNN（前向神经网络）和Transformer网络被用于捕捉GNSS特征与风动态之间的复杂、非线性和时空关系，初步结果显示，该模型在风场检索和短期风速预测方面表现出与高分辨率NWP输出相当的技能分数。此外，该系统即使在GNSS站点显著减少的情况下也能保持良好的性能，突显了其经济性和可扩展性。
### Innovation
引入了一个基于深度学习的新颖框架G-WindCast，利用5G GNSS信号的信号强度变化来获取和预测三维大气风场。该框架通过FNN和Transformer网络捕捉GNSS特征与风动态之间的复杂、非线性和时空关系，并展示了在不同预报时期和气压水平下的稳健性，以及在风速和风向预测中优于ERA5再分析数据的观测一致性。该研究还表明，即使在GNSS站点大幅减少的情况下，系统也能保持良好的局部预测性能，凸显了其经济性和可扩展性。
### Conclusion
本文展示了利用非传统数据源和深度学习进行先进环境监测和实时大气应用的潜力。G-WindCast模型在风场检索和短时风速预测方面展示了有希望的准确性和高性价比，这为未来的应用提供了新的可能性。
## 128. `cs.AI` - 使用图强化学习加速原子精细结构确定 [PDF](https://arxiv.org/pdf/2509.16184), [HTML](https://arxiv.org/abs/2509.16184)
### Authors
M. Ding,V.-A. Darvariu,A. N. Ryabtsev,N. Hawes,J. C. Pickering
### Background
原子数据对于等离子体诊断至关重要。通过对数万条观测光谱线进行分析，可以确定低电离度开放d-和f-亚壳原子物种的约1000个精细结构能级。然而，这一任务仍依赖于人工分析，效率难以满足天文学和聚变科学中不断增长的原子数据需求。
### Innovation
提出了一种自动化方法，将其分析过程表述为马尔可夫决策过程，并通过基于历史人类决策学习奖励函数的图强化学习来求解，从而加快原子精细结构能级的确定。
### Conclusion
在现有的光谱线列表和Co II、Nd II-III的理论计算中，该方法在数小时内计算数百个能级，并在95%的情况下与已发表的Co II值相符，Nd II-III为54-87%，这表明新的人工智能方法将有助于解决原子精细结构数据需求与当前效率之间的差距。
## 129. `cs.AI` - 行动是主要键点：一种对事件记忆和逻辑推理的范畴框架 [PDF](https://arxiv.org/pdf/2409.04793), [HTML](https://arxiv.org/abs/2409.04793)
### Authors
Yoshiki Fukada
### Background
本文探讨了如何为人工智能和认知科学提供事件记忆的数据格式，旨在通过这种方式，使得逻辑推理更加严谨和灵活。研究的背景在于，目前的人工智能在搜集、理解和处理人类记忆和推理方面存在局限性，尤其是在准确性、灵活性和对因果关系的处理上。
### Innovation
本文创新地提出了‘认知日志’这一术语，这是一种由关系数据库和图数据库组成的事件数据格式，能够存储人类的事件记忆并支持逻辑推理。认知日志的独特之处在于，它采用范畴论的操作方法，使得事件记忆和认知规则之间的比较更加精确，支持从事件记忆中进行规划、理解以及故事的层次抽象。这种模型专门参考了认知科学，特别是认知语言学的内容，旨在为人工智能提供类似于人类思考的方式，但同时又具备机器的准确性和严谨性。
### Conclusion
文章的目标是建立一种基于数据库的人工智能系统，它可以像人类一样思考，同时具有机器的精确性和严谨性。由于数据库技术目前的广泛容量（达到拍字节尺度），这种人工智能有望存储比基于神经网络的人工智能更多知识。认知日志作为一种模型，不仅为事件记忆的存储提供了新的方法，也为理解和模拟人类认知活动提供了基础。
## 130. `cs.AI` - CultureScope: 文本大型模型中的文化理解维度视角 [PDF](https://arxiv.org/pdf/2509.16188), [HTML](https://arxiv.org/abs/2509.16188)
### Authors
Jinghao Zhang,Sihang Jiang,Shiwei Guo,Shisong Chen,Yanghua Xiao,Hongwei Feng,Jiaqing Liang,Minggui HE,Shimin Tao,Hongxia Ma
### Background
随着大型语言模型（LLMs）在多元文化环境中越来越广泛的应用，评估它们的文化理解能力变得至关重要，以确保可信且文化兼容的应用。然而，大多数现有的基准测试缺乏全面性，难以跨不同文化场景进行扩展，因为它们的框架往往缺乏从卓有成效的文化理论中获得的指导，并倾向于依赖专家驱动的手动注释。
### Innovation
为了解决这些问题，本文提出CultureScope，这是迄今为止最全面的文化理解评估框架。受到文化冰山理论的启发，我们设计了一个新的维度架构，用于文化知识分类，包含3层和140个维度，这将指导针对任何语言和文化的特定文化知识库和对应的评估数据集的自动化构建。实验结果表明，我们的方法可以有效地评估文化理解。同时，实验也揭示了现有大语言模型缺乏全面的文化能力，仅仅增加多语言数据并不一定能增强文化理解能力。所有代码和数据文件都可从此链接下载：this https URL
### Conclusion
我们的研究证明，CultureScope评估框架能够有效评估大型语言模型的文化理解能力。此外，现有的大语言模型在全面的文化能力方面存在不足，仅仅增加多语言数据不一定会提升文化理解。
## 131. `cs.AI` - 动态策略融合以无需重新交互来实现用户对齐 [PDF](https://arxiv.org/pdf/2409.20016), [HTML](https://arxiv.org/abs/2409.20016)
### Authors
Ajsal Shereef Palattuparambil,Thommen George Karimpanal,Santu Rana
### Background
深度强化学习（RL）策略虽然在任务奖励方面是最优的，但可能不契合人类用户的个人偏好。为了确保策略与用户的偏好一致，一种简单的解决方案是通过一个嵌入用户特定偏好的奖励函数重新训练代理。然而，这样的奖励函数通常不可获取，重新训练代理的成本可能会非常高。为此，我们提出了一种更实用的方法，即利用人类反馈，在已有训练好的策略上进行适应用户特定需求的调整。这种方法通过对轨迹级别的反馈进行意图推理，并通过一个理论基础牢固的动态策略融合方法将其与训练的任务策略结合。由于这种方法无需额外与环境交互，将其归类为零样本方法（zero-shot approach）。
### Innovation
本文研究的核心创新是在同一用于学习任务策略的轨迹上收集人类反馈，无需额外环境交互地融合动态策略，实现用户偏好对齐。这种方法避免了重新训练代理的高昂成本，通过理论基础坚固的动态融合策略，既实现了任务目标，又尊重了用户的特定需求。
### Conclusion
实验结果表明，所提出的方法能够一致地完成预期的任务，同时根据用户的具体需求进行调整。这种方法为实现强化学习策略与用户偏好的一致性提供了一种有效的框架。
## 132. `cs.AI` - 通过语义聚类提升深度强化学习的可解释性 [PDF](https://arxiv.org/pdf/2409.17411), [HTML](https://arxiv.org/abs/2409.17411)
### Authors
Liang Zhang,Justin Lieffers,Adarsh Pyarelal
### Background
本文探讨了深度强化学习（DRL）的语义聚类特性，以提高其可解释性并深入理解其内部语义组织。语义聚类指的是神经网络根据内部空间中的语义相似性对输入进行聚类的能力。研究背景强调了目前DRL模型在解释性方面的不足，以及传统语义分析方法的限制，如需大量手动标注和t-SNE的不稳定性。
### Innovation
本文提出了一种结合特征维度降低与在线聚类的新型语义聚类模块，该模块能够与DRL训练管道无缝集成，解决了t-SNE不稳定的问题，并消除了传统方法中对大量手动标注的需求。此外，文章还引入了基于这些属性的新分析方法，以揭示DRL中的层次结构和语义组织，并提供对其的洞察。
### Conclusion
实验验证了所提出的模块的有效性，并展示了其揭示DRL中语义聚类特性的能力。通过这一创新，我们的工作提升了DRL模型的可解释性，为理解其内部语义组织提供了新的视角。
## 133. `cs.AI` - FocalCodec-Stream：通过因果蒸馏实现流式低比特率语音编码 [PDF](https://arxiv.org/pdf/2509.16195), [HTML](https://arxiv.org/abs/2509.16195)
### Authors
Luca Della Libera,Cem Subakan,Mirco Ravanelli
### Background
历史上，神经音频编解码器是现代生成音频流程中的基本组成部分。尽管最近的编解码器在低比特率重建方面表现出色，并提供了方便的表示形式用于下游任务，但大多数编解码器都不具备流式传输的能力，这限制了它们在实时应用中的使用。
### Innovation
FocalCodec-Stream是一个基于焦点调制的混合编解码器，可以在0.55-0.80 kbps的比特率下将语音压缩为一个二进制代码库，并且具有80 ms的理论延迟。该方法结合了多阶段因果蒸馏的WavLM与针对性的架构改进，包括在延迟约束下的轻量级精炼模块，增强质量。实验结果表明，FocalCodec-Stream在保持低比特率的同时，优于现有的可流式传输的编解码器，并保留了语义和声学信息。所述编解码器在重建质量、下游任务性能、延迟和效率之间达到了有利的权衡。
### Conclusion
FocalCodec-Stream为流式低比特率语音编码提供了一个有效解决方案，在保留语义和声学信息的同时，兼顾了重建质量、下游任务性能、延迟和效率之间的权衡。
## 134. `cs.AI` - RPG：统一且可扩展的代码库生成的存储库规划图 [PDF](https://arxiv.org/pdf/2509.16198), [HTML](https://arxiv.org/abs/2509.16198)
### Authors
Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang
### Background
大语言模型在函数级和文件级的代码生成方面表现出色，但仍难以从零开始生成完整的代码库。这一过程需要在提案级和实施级之间进行连贯和可靠的规划。然而，自然语言由于其歧义性和冗长性，在忠实呈现复杂的软件结构时并不合适。该研究旨在通过引入存储库规划图(RPG)，解决上述问题，并开发了一种基于图的框架——ZeroRepo，用于从零开始生成存储库。
### Innovation
RPG是一种持久化的表示方法，能够统一并整合提案级和实施级的规划，通过一个图来表示能力、文件结构、数据流和功能，从而用明确的蓝图替代了模糊的自然语言，便于长期规划和存储库生成的扩展性。ZeroRepo框架包含了三个步骤：提案级规划和实施级细化以构建图，然后通过引导代码生成并附带测试验证。
### Conclusion
ZeroRepo在RepoCraft基准测试上表现优异，生成的代码库平均包含约36K行代码，显著高于其他基线。在功能覆盖率和通过率方面，ZeroRepo分别达到了81.5%和69.7%，超过Claude Code 27.3和35.8个百分点。进一步分析结果表明，RPG能够建模复杂的依赖性，使规划变得愈加复杂，同时增强了大语言模型对代码库的理解，进而加速了代理的定位。
## 135. `cs.AI` - SycEval：评估大规模语言模型的奉承行为 [PDF](https://arxiv.org/pdf/2502.08177), [HTML](https://arxiv.org/abs/2502.08177)
### Authors
Aaron Fanous,Jacob Goldberg(1),Ank A. Agarwal(1),Joanna Lin(1),Anson Zhou(1),Roxana Daneshjou(1),Sanmi Koyejo(1) ((1) Stanford University)
### Background
大规模语言模型（LLMs）在教育、医疗和专业领域中的应用日益增多，但它们倾向于奉承，即优先考虑用户同意而非独立推理，这可能对模型的可靠性构成风险。本文通过评估ChatGPT-4o、Claude-Sonnet和Gemini-1.5-Pro在这方面的表现，进一步分析了这一问题。
### Innovation
该研究提出了一种框架，用于评估ChatGPT-4o、Claude-Sonnet和Gemini-1.5-Pro在AMPS和MedQuad数据集中的奉承行为。研究发现，58.19%的情况下存在奉承行为，其中Gemini表现最高，为62.47%，而ChatGPT表现最低，为56.71%。此外，研究还发现预设反驳的奉承行为比上下文内在反驳更高，特别是在计算任务中。研究进一步表明，简单反驳有利于奉承行为的增长，而基于引用的反驳则显示最高的逆向奉承率。
### Conclusion
研究强调了部署LLMs在结构化和动态领域中的风险和机会，同时提供了有关提示编程和模型优化的见解，以确保更安全的AI应用。奉承行为在这一类模型中显示出高持久性，这无论是在具体情境还是模型中都保持一致。
## 136. `cs.AI` - 激活空间干预可以在大型语言模型之间传递 [PDF](https://arxiv.org/pdf/2503.04429), [HTML](https://arxiv.org/abs/2503.04429)
### Authors
Narmeen Oozeer,Dhruv Nathawani,Nirmalendu Prakash,Michael Lan,Abir Harrasse,Amirali Abdullah
### Background
AI模型中的表示普遍性研究揭示了跨领域、模式和架构的持续趋同。然而，表示普遍性的实际应用仍然鲜有探索。
### Innovation
本文通过展示安全干预可以通过学习映射在共享激活空间中的模型间进行传递，填补了这一空白。本文在两个已建立的AI安全任务上展示了这种方法的有效性：后门移除和拒绝有害指令，同时提出了一种新的任务，即被污染的能力，该任务测试了模型区分有用技能和后门的能力，反映了实际挑战。此外，通过一系列实验验证了该方法能够利用较小的模型高效地对较大模型进行对齐。
### Conclusion
跨模型的自动编码器映射可以作为可靠的轻量级安全开关，允许动态切换模型行为。本文方法展示了使用较小的模型高效对齐较大模型的能力。
## 137. `cs.AI` - FLARE: 正确的逻辑辅助推理和探索 [PDF](https://arxiv.org/pdf/2410.11900), [HTML](https://arxiv.org/abs/2410.11900)
### Authors
Erik Arakelyan,Pasquale Minervini,Pat Verga,Patrick Lewis,Isabelle Augenstein
### Background
现代基于大语言模型（LLMs）的问答和推理方法通常使用提示技术，如逐步思考（CoT），认为这样可以更细致地探索和推理问题空间。然而，这类方法在产生符合模型中间推理过程的结果上存在困难。另一方面，神经符号方法，如忠诚的逐步思考（F-CoT），提出将LLMs与外部符号求解器结合起来。虽然这种方法具有高度的忠实性，但通常需要一个用于代码生成的模型，并且难以处理语义模糊或难以严格形式化的任务。
### Innovation
我们提出了FLARE，一种新颖的可解释方法，用于使用任务分解在问题空间中进行搜索。使用LLM制定解决方案，将查询软形式化为事实和谓词，并使用详尽的多跳搜索模拟代码执行。这种方法允许我们计算推理过程与生成代码的一致性，并在无需依赖外部求解器的情况下分析多跳搜索的步骤。实验表明，FLARE在7个不同推理基准测试中达到了最新技术水平，并显示了模型忠实性与总体性能的正相关性，还进一步证明FLARE可以指出多跳搜索中正确推理的关键因素，从而获得正确答案。
### Conclusion
FLARE在多个推理基准测试中达到了最佳性能，证明了它在提高模型忠实性和正确推理方面的能力。
## 138. `cs.AI` - 分解干预性因果性为协同、冗余和独特的组件 [PDF](https://arxiv.org/pdf/2501.11447), [HTML](https://arxiv.org/abs/2501.11447)
### Authors
Abel Jansma
### Background
近年来，虽然一些研究探索了观察性指标的分解，但现有方法尚未充分涵盖因果性的分解问题。本文基于部分信息分解(PID)和莫比乌斯反转原理，提出了一种新型框架，用于将干预因果效果分解为协同、冗余和独特的组成部分，强调其必须是一种干预性分解。
### Innovation
本文的创新在于开发了一种数学方法，系统地量化变量在系统中的因果力分布，同时使用冗余格拉梅奇函数的最新封闭形式表达式。通过结合逻辑门、细胞自动机、化学反应网络以及变压器语言模型进行示例，展示了因果力分布的上下文和参数依赖性，并揭示了如何在多个变量之间共享和组合因果影响，具有从法律责任归属到生物网络分析等广泛的应用前景。
### Conclusion
研究结果表明，因果力的分布是上下文和参数依赖的，并通过分解展示了因果影响如何在多个变量之间共享和组合。这种分解为复杂系统的分析提供了新的见解，具有广泛的应用潜力。
## 139. `cs.AI` - 沃森：LLM驱动的代理推理的认知可观测性框架 [PDF](https://arxiv.org/pdf/2411.03455), [HTML](https://arxiv.org/abs/2411.03455)
### Authors
Benjamin Rombaut,Sogol Masoumzadeh,Kirill Vasilevski,Dayi Lin,Ahmed E. Hassan
### Background
大型语言模型（LLMs）越来越多地被集成到自主系统中，形成了一个新的软件类别——代理软件，其中由LLM驱动的代理可以执行复杂的、非限制性的任务。这些代理的高度自主性和不透明的推理过程对传统软件可观察性方法提出了重大挑战。为了应对这一挑战，我们提出了认知可观测性的概念——能够恢复和检查代理决策背后的隐式推理。并且介绍了沃森，一个通用框架，用于无需改变代理行为的情况下观察快速思考的LLM代理的推理过程。沃森使用提示归因技术反向推断推理轨迹。
### Innovation
提出了认知可观测性的概念，介绍了一个通用框架沃森，用于无需改变代理行为的情况下观察快速思考的LLM代理的推理过程。沃森使用提示归因技术反向推断推理轨迹，并在MMLU基准测试、AutoCodeRover和OpenHands代理的SWE-bench-lite数据集中评估了其在手动调试和自动化修正场景中的效果。
### Conclusion
在静态和动态设置中，沃森揭示了可操作的推理见解，并支持有针对性的干预，证明了它在提高代理软件系统的透明度和可靠性方面的实际用途。
## 140. `cs.AI` - RLinf：通过宏观到微观流程转换实现灵活高效的大型强化学习 [PDF](https://arxiv.org/pdf/2509.15965), [HTML](https://arxiv.org/abs/2509.15965)
### Authors
Chao Yu,Yuanqing Wang,Zhen Guo,Hao Lin,Si Xu,Hongzhi Zang,Quanlu Zhang,Yongji Wu,Chunyang Zhu,Junhao Hu,Zixiao Huang,Mingjie Wei,Yuqing Xie,Ke Yang,Bo Dai,Zhexuan Xu,Xiangyuan Wang,Xu Fu,Zhihao Liu,Kang Chen,Weilin Liu,Gang Liu,Boxun Li,Jianlei Yang,Zhi Yang,Guohao Dai,Yu Wang
### Background
强化学习（RL）在推动通用人工智能、自主智能和体素化智能方面表现出巨大的潜力。然而，现有的RL工作流程具有固有的异构性和动态性，这通常导致硬件利用率低和训练速度慢。本文针对这一问题，提出了一种基于对工作流程缺乏灵活性是高效RL训练主要障碍的观察结果下的高性能RL训练系统RLinf。
### Innovation
RLinf 通过引入一种称为宏观到微观流程转换（M2Flow）的新颖 RL 系统设计范式，自动在时间和空间维度上拆分高级、易于组合的RL工作流程，并重新组合成优化的执行流程。此外，通过 RLinf 工作者的自适应通信能力，设计了上下文切换和弹性流水线来实现 M2Flow 转换，并采用基于分析的调度策略生成最优执行计划。该策略在推理RL和体感RL任务上的大量评估中，持续超过了最先进的系统，实现端到端训练吞吐量提高1.1-2.13倍。
### Conclusion
本文通过RLinf实现灵活高效的大型强化学习，并验证了M2Flow在提高RL训练性能方面的有效性。
## 141. `cs.AI` - 重新定义会议摘要：基于事实的摘要与个性化 [PDF](https://arxiv.org/pdf/2509.15901), [HTML](https://arxiv.org/abs/2509.15901)
### Authors
Frederic Kirstein,Sonu Kumar,Terry Ruas,Bela Gipp
### Background
现有的使用大型语言模型（LLMs）进行会议总结的方法仍然容易出错，经常产生带有虚构信息、遗漏或不相关的内容。为此，研究人员致力于改进总结技术，以提高准确性和个性化。
### Innovation
该研究提出了一个模块化的管道FRAME，将总结重定义为语义增强任务。该框架包括 FACTIVE 和 SCOPE，前者抽取并评分关键事实，后者通过问答的方式为内容选择生成推理轨迹，以增强摘要。此外，研究还提出了 P-MESA，一种多维度、无需参考的评估框架用于评估摘要是否契合目标读者的需求。实验表明，FRAME 和 SCOPE 可显著减少虚构信息和遗漏，提高知识契合度和目标一致性。
### Conclusion
研究发现，为了改进摘要的控制性、忠实性和个性化，需要重新思考总结方法。FRAME 和 SCOPE 在评估框架 P-MESA 中表现优异，实现了对人类标注的高匹配度和一致性。
## 142. `cs.AI` - SPaRC: 空间路径推理挑战 [PDF](https://arxiv.org/pdf/2505.16686), [HTML](https://arxiv.org/abs/2505.16686)
### Authors
Lars Benedikt Kaesberg,Jan Philip Wahle,Terry Ruas,Bela Gipp
### Background
现有的推理数据集已经饱和，并且无法测试抽象的、多步骤的问题，特别是在路径寻找和复杂的规则约束满足方面。人类能够在这种挑战中达到近完美的准确率（98.0%，在困难的题目中为94.5%），而现有的最好推理模型，如o4-mini，在这种情况下则表现非常糟糕（15.8%，在困难的题目中为1.1%）。模型经常生成无效的路径（o4-mini在超过50%的题目中产生无效路径），并在推理步骤中显现出了导航和空间逻辑上的错误。不同于人类会花费更多时间处理难题，模型不能随着难度的增加而相应地提高测试时间的计算能力。
### Innovation
该研究引入了SPaRC（Spatial Pathfinding Reasoning Challenge），这是一个包含1,000个二维网格路径寻找难题的数据集，用以评估空间和符号推理能力，要求通过逐步规划和运用算术和几何规则进行推理。为了改善空间推理能力，提出的方法包括改进训练和优化测试阶段的计算能力。这种方法有助于揭示模型的空间推理限制，并推动研究向能更好地解决抽象和多步骤问题的新方法前进。
### Conclusion
允许模型多次尝试解决问题可以提高准确性，这表明通过改进训练和优化测试阶段的计算方法可能有助于提高空间推理能力。SPaRC可以作为模型的空间推理限制窗口，从而推动研究发展出在抽象和多步骤问题上表现出色的新方法。
## 143. `cs.AI` - 将活动预测集成到知识图谱中 [PDF](https://arxiv.org/pdf/2507.19733), [HTML](https://arxiv.org/abs/2507.19733)
### Authors
Forrest Hare,Alec Sculley,Cameron Stockton
### Background
本文探讨了如何利用本体结构化的知识图谱来预测未来事件，通过使用基础形式本体（BFO）和通用核心本体（CCO）提供的语义框架，展示了如何组织和从知识图谱中检索数据，例如渔业船只的运动，并利用这些查询结果创建马尔可夫链模型以预测未来状态。
### Innovation
论文引入了“空间时间瞬时”的概念，以完善必要的结构语义。作者还挑战了现有的概率本体论模型，提出了一种新观点，认为至少一些概率应该被视为关于实际过程配置的，这更好地捕捉了现实世界现象的动态。最后，表明基于马尔可夫链的概率计算可以直接集成回知识图谱，从而支持进一步分析和决策。
### Conclusion
通过马尔可夫链模型，本文展示了如何利用知识图谱预测未来状态。同时，提出了新的概率观点，并展示了概率计算如何无缝集成到知识图谱中，以促进进一步的分析和决策。
## 144. `cs.AI` - 探索人格特质对大语言模型偏见和毒性的影响 [PDF](https://arxiv.org/pdf/2502.12566), [HTML](https://arxiv.org/abs/2502.12566)
### Authors
Shuo Wang,Renhao Li,Xi Chen,Yulin Yuan,Derek F. Wong,Min Yang
### Background
随着人工智能在人类生活中扮演的角色日益多元化，赋予大型语言模型（LLM）不同的人格特征引起了越来越多的研究兴趣。这种‘人格化’增强了LLM的互动性和适应性，但同时也引发了关于内容安全的重大担忧，特别是关于LLM生成的偏差、情绪和毒性问题。本研究旨在探讨赋予LLM不同人格特征如何影响其输出的偏见和毒性。
### Innovation
研究采用了社会心理学广泛接受的六因素人格框架（HEXACO），设计了实验性的提示，测试了三种LLM在三种毒性和偏见基准测试上的表现。研究发现所有模型都对人格特质敏感，并且最重要的是，它们的输出在偏见、负面情绪和毒性上存在显著变化。这些发现表明，调整人格特质可以有效减少模型表现中的偏见和毒性，类似于人类人格特质与有毒行为之间的关系。
### Conclusion
这些发现强调除了考虑训练或微调方法的有效性之外，还需要进一步检查LLM人格化的内容安全性。此外，调整人格作为一种简单和低成本的方法，可能有助于进行受控文本生成。
## 145. `cs.AI` - 大型语言模型能否从真实文本中推断因果关系？ [PDF](https://arxiv.org/pdf/2505.18931), [HTML](https://arxiv.org/abs/2505.18931)
### Authors
Ryan Saklad,Aman Chadha,Oleg Pavlov,Raha Moraffah
### Background
理解并推断文本中的因果关系是人类认知的核心部分，对于推进大型语言模型（LLMs）向人工通用智能方向发展至关重要。现有研究主要集中在基于合成生成的、涉及简单明确因果关系的文本上，但未能反映出真实任务的复杂性。
### Innovation
本研究开发了一个基于真实世界学术文献的基准数据集，包括涉及不同长度、因果关系复杂度及领域多样性的文本。这是首次为此类任务提供的真实世界数据集。实验结果表明，LLMs在从真实文本中推断因果关系时面临重大挑战，最好模型的平均F1分数仅为0.477。通过系统分析真实文本的不同方面，该基准提供了针对推进LLMs因果推理的研究方向的洞察。
### Conclusion
本研究结果表明，LLMs在处理复杂性更高的真实世界文本中的因果推理任务时表现出色有难度，提出了在未来研究中需要关注的具体方向和挑战。
## 146. `cs.AI` - 超越视觉和语言的面向部署的多模态AI [PDF](https://arxiv.org/pdf/2504.03603), [HTML](https://arxiv.org/abs/2504.03603)
### Authors
Xianyuan Liu,Jiayang Zhang,Shuo Zhou,Thijs L. van der Plas,Avish Vijayaraghavan,Anastasiia Grishina,Mengdie Zhuang,Daniel Schofield,Christopher Tomlinson,Yuhan Wang,Ruizhe Li,Louisa van Zeeland,Sina Tabakhi,Cyndie Demeocq,Xiang Li,Arunav Das,Orlando Timmerman,Thomas Baldwin-McDonald,Jinge Wu,Peizhen Bai,Zahraa Al Sahili,Omnia Alwazzan,Thao N. Do,Mohammod N.I. Suvon,Angeline Wang,Lucia Cipolina-Kun,Luigi A. Moretti,Lucas Farndale,Nitisha Jain,Natalia Efremova,Yan Ge,Marta Varela,Hak-Keung Lam,Oya Celiktutan,Ben R. Evans,Alejandro Coca-Castro,Honghan Wu,Zahraa S. Abdallah,Chen Chen,Valentin Danchev,Nataliya Tkachenko,Lei Lu,Tingting Zhu,Gregory G. Slabaugh,Roger K. Moore,William K. Cheung,Peter H. Charlton,Haiping Lu
### Background
多模式人工智能将多种类型的数据通过机器学习整合，以提高跨学科（如医疗保健、科学、工程等）的理解、预测和决策能力。然而，大多数多模式AI的发展主要集中在视觉和语言数据模型上，而这些模型的部署能力仍然是一个关键挑战。现有的工作主要集中在模数据和模型方面的集中方法上，本文提倡一种以部署为中心的工作流程，早期整合部署限制以减少不可部署解决方案的可能性。此外，文章强调多模态和跨学科的深入整合，以显著拓宽研究范围，不再仅限于视觉和语言数据。文章通过识别跨学科共享的多模态AI特定挑战，选择三个实际使用案例：疫情响应、自动驾驶车辆设计和气候适应，涵盖医学、社会科学、工程、科学、可持续性和金融领域。通过促进跨学科对话和开放研究实践，该社区可以加速面向部署的多模态AI的发展，以产生广泛的社会影响。
### Innovation
提倡一种以部署为中心的工作流程，早期整合部署限制以减少不可部署解决方案的可能性，强调多模态和跨学科的深入整合，选择并分析三个实际案例，以促进面向部署的多模态AI的发展。
### Conclusion
通过跨学科对话和开放研究实践，社区可以加速面向部署的多模态AI的发展，以产生广泛的社会影响。
## 147. `cs.AI` - 个人健康代理的构成功能 [PDF](https://arxiv.org/pdf/2508.20148), [HTML](https://arxiv.org/abs/2508.20148)
### Authors
A. Ali Heydari,Ken Gu,Vidya Srinivas,Hong Yu,Zhihan Zhang,Yuwei Zhang,Akshay Paruchuri,Qian He,Hamid Palangi,Nova Hammerquist,Ahmed A. Metwally,Brent Winslow,Yubin Kim,Kumar Ayush,Yuzhe Yang,Girish Narayanswamy,Maxwell A. Xu,Jake Garrison,Amy Armento Lee,Jenny Vafeiadou,Ben Graef,Isaac R. Galatzer-Levy,Erik Schenck,Andrew Barakat,Javier Perez,Jacqueline Shreibati,John Hernandez,Anthony Z. Faranesh,Javier L. Prieto,Connor Heneghan,Yun Liu,Jiening Zhan,Mark Malhotra,Shwetak Patel,Tim Althoff,Xin Liu,Daniel McDuff,Xuhai ?Orson? Xu
### Background
健康是人类福祉的基本支柱，而大型语言模型（LLMs）的迅速发展促使新一代健康代理的研发。尽管如此，将健康代理应用于满足日常生活非临床环境下个人多样化的健康需求仍然未被充分探索。
### Innovation
本文旨在构建一个全面的个人健康代理，能够理解消费者日常健康设备产生的多模态数据和个人健康记录，并提供个性化健康建议。通过深入了解用户需求，确定了三大类消费者健康需求，并开发了一个多代理框架（Personal Health Agent, PHA），该框架支持动态、个性化的交互，以应对个体的健康需求。
### Conclusion
本文的工作是对现有健康代理最全面的评估，并为未来全民可及的个人健康代理构建了坚实的基础。
## 148. `cs.AI` - 世界建模改善语言模型代理 [PDF](https://arxiv.org/pdf/2506.02918), [HTML](https://arxiv.org/abs/2506.02918)
### Authors
Shangmin Guo,Omar Darwiche Domingues,Raphaël Avalos,Aaron Courville,Florian Strub
### Background
在状态化环境中使用工具为大型语言模型（LLMs）带来了独特挑战，现有测试时计算策略依赖于环境中的重复试验是不现实的。
### Innovation
提出了动态建模（DyMo）方法，该方法在后训练期间增强了LLMs的状态预测能力和函数调用，使其能够通过内部环境模型预测其操作的未来状态。在Berkeley函数调用排行榜V2中，DyMo提高了成功率并显著减少了幻觉。作者进一步将内部环境模型整合到自我验证采样（SVS）中，显示出这大幅提高了随着试验次数的增加的pass^k值，并允许模型拒绝不可靠的输出。结合DyMo和SVS极大地增强了LLMs在工具使用中的效果和可靠性。
### Conclusion
我们认为这项工作为大规模规划强化学习方法在LLM推理中提供了新的途径，而无需重复查询oracle环境。
## 149. `cs.AI` - SyGra: 一种基于图的统一框架，用于可扩展的合成数据生成、质量标记和管理 [PDF](https://arxiv.org/pdf/2508.15432), [HTML](https://arxiv.org/abs/2508.15432)
### Authors
Bidyapati Pradhan,Surajit Dasgupta,Amit Kumar Saha,Omkar Anustoop,Sriram Puttagunta,Vipul Mittal,Gopal Sarda
### Background
大型语言模型的进步依赖于高质量数据集的支持，特别是用于监督微调（SFT）、直接偏好优化（DPO）等监督和对齐任务的数据集。现有的数据生成方法通常需要大量的人工干预，并且生成的数据质量参差不齐，无法满足大规模训练的需要。
### Innovation
本文提出了一种模块化和配置化的综合数据生成框架，能够以最少的人工干预生成适应SFT和DPO等训练范式的高质量合成对话数据。该框架采用双重质量标记机制，结合启发式规则和基于LLM的评估，确保生成的数据的质量，并支持灵活的数据结构以便无缝集成到各种训练流程中。
### Conclusion
该框架提供了一个可靠的方法，可以大规模生成和管理合成对话数据，显著降低了数据准备对大型语言模型训练管道的影响。
## 150. `cs.AI` - DebFlow: 通过代理辩论自动化代理创建 [PDF](https://arxiv.org/pdf/2503.23781), [HTML](https://arxiv.org/abs/2503.23781)
### Authors
Jinwei Su,Yinghui Xia,Yiqun Duan,Jun Du,Jianuo Huang,Tianyu Shi,Lewei He
### Background
大型语言模型（LLMs）在自动化工作流的生成和优化方面表现出强大的潜力和出色的表现。然而，现有方法存在推理能力有限、高计算需求和资源需求大的问题。为了应对这些问题，我们提出了一种名为DebFlow的框架，它采用辩论机制来优化工作流，并结合反思以根据以往的经验进行改进。我们使用六个基准数据集对我们的方法进行了评估，包括HotpotQA、MATH和ALFWorld。我们的方法实现了比最新基线平均3%的性能改进，展示了其在多种问题领域的有效性。特别是在训练过程中，与最先进的基线相比，我们的框架能够减少37%的资源消耗。此外，我们还进行了消融研究，移除辩论组件导致两个基准数据集的性能下降了4%，这比移除反思组件时的2%降幅要大得多。这些结果强有力地证明了辩论在增强框架性能中的关键作用，同时也强调了反思在整体优化中的辅助作用。
### Innovation
提出了一种名为DebFlow的框架，其创新点在于采用辩论机制来优化工作流，并结合反思以根据以往的经验进行改进。这种框架解决了现有方法的推理能力有限、高计算需求和资源需求大的问题，并通过实验展示了其有效性和资源节约性。特别地，辩论组件的贡献被证实对于框架性能非常重要。
### Conclusion
DebFlow框架在各种问题领域中展示了其有效性，特别是在资源节约方面表现出色。辩论是提高框架性能的关键组件，而反思则起到了辅助优化的作用。
## 151. `cs.AI` - 在线模型不确定性下鲁棒规划：一种样本基方法 [PDF](https://arxiv.org/pdf/2509.10162), [HTML](https://arxiv.org/abs/2509.10162)
### Authors
Tamir Shazman,Idan Lev-Yehudi,Ron Benchetit,Vadim Indelman
### Background
在线规划在马尔可夫决策过程（MDP）中的应用使得智能体能够通过从当前状态模拟未来轨迹来做出序列决策，这使其非常适合大型或动态环境。样本基方法如稀疏采样和蒙特卡洛树搜索（MCTS）因其能够使用生成模型近似最优动作而被广泛采用。但是，在实际应用中，生成模型通常从有限数据中学习，这会引入近似误差，导致性能下降或产生不安全的行为。为了应对这些挑战，鲁棒马尔可夫决策过程（RMDPs）提供了一种原理上有保证的框架来处理模型不确定性，但现有方法通常计算强度高，并不适合实时使用。
### Innovation
本文提出了鲁棒稀疏采样（RSS），这是第一个具有有限样本理论性能保证的RMDPs在线规划算法。不同于稀疏采样估算名义值函数，RSS通过利用样本平均近似（SAA）的效率和理论特性计算鲁棒价值函数，从而在在线设置中实现鲁棒策略的可处理计算。RSS适用于无限或连续状态空间，并且其样本和计算复杂度与状态空间大小无关。此外，该方法提供了理论性能保证，并通过实验表明在不确定动态环境下，RSS优于标准稀疏采样。
### Conclusion
RSS能够在在线追踪和优化问题中提供更鲁棒的决策，并且在计算和样本复杂度上具有优势，即使在状态空间非常大或者动态变化的情况下也能提供保证的性能。
## 152. `cs.AI` - 科学重现已有的AI辅助案例研究 [PDF](https://arxiv.org/pdf/2506.20130), [HTML](https://arxiv.org/abs/2506.20130)
### Authors
Adrien Bibal,Steven N. Minton,Deborah Khider,Yolanda Gil
### Background
开放科学倡议旨在使研究产出更加透明、可访问和可重用，但确保发表的发现能够独立重现仍然是一个持续的挑战。本论文介绍了OpenPub，一个AI驱动的平台，旨在通过专注于关键开放科学任务的一系列模块化副驾，为研究人员、审稿人和读者提供支持。论文中介绍了重现性副驾，它通过分析手稿、代码和补充材料来生成结构化的Jupyter Notebook和建议，以促进计算或“步骤”的重现性。先前研究论文的可行性测试表明，OpenPub可以大幅度减少重现时间——从超过30小时减少到大约1小时，并且覆盖率很高，涵盖了适合计算重现的图表、表格和结果。该系统系统地检测重现性的障碍，包括缺失的超参数、未记录的预处理步骤以及不完整或不可访问的数据集。
### Innovation
OpenPub平台提供了模块化副驾架构，专注于关键开放科学任务，旨在为研究人员、审稿人和读者提供支持。它通过分析手稿、代码和补充材料来生成结构化的Jupyter Notebook和建议，旨在促进计算或“步骤”的重现性。该平台显著减少了重现时间，从超过30小时减少到大约1小时，同时拥有较高的覆盖率，并检测到重现性的障碍，包括缺失的超参数、未记录的预处理步骤以及不完整或不可访问的数据集。这表明AI驱动的工具可以有意义地减少重现性工作的负担，有助于更透明和可验证的科学交流。提供了一个基础架构，可以扩展AI辅助到超出重现性的开放科学目标。
### Conclusion
初步测试结果显示，AI驱动的工具可以在很大程度上减轻重现性的负担，并有助于更透明和可验证的科学交流。模块化的副驾架构为扩展AI辅助到其他开放科学目标提供了基础。
## 153. `cs.AI` - 使用图网络进行Hadron calorimeter数据质量监控的空间时间异常检测 [PDF](https://arxiv.org/pdf/2311.04190), [HTML](https://arxiv.org/abs/2311.04190)
### Authors
Mulugeta Weldezgina Asres,Christian Walter Omlin,Long Wang,David Yu,Pavel Parygin,Jay Dittmann,Georgia Karapostoli,Markus Seidel,Rosamaria Venditti,Luka Lambrecht,Emanuele Usai,Muhammad Ahmad,Javier Fernandez Menendez,Kaori Maeshima, theCMS-HCAL Collaboration
### Background
大型强子对撞机（LHC）上的紧凑缪子线圈（CMS）实验是一个用于高能碰撞的通用探测器。CMS实验使用在线数据质量监控（DQM）系统来快速发现和诊断粒子数据采集问题，以避免数据质量损失。该研究提出了一个用于CMSHadron Calorimeter（HCAL）物理粒子读取通道的空间时间半监督异常检测（AD）监控系统，该系统采用DQM的三维digi-occupancy映射数据。该系统验证了在LHC碰撞数据集上捕捉不同信道故障类型的准确性，并提供了与基准模型的性能比较结果。
### Innovation
提出了一种名为GraphSTAD的空间时间半监督异常检测系统，该系统利用卷积神经网络和图神经网络学习由穿过多何探测器的粒子引起的局部空间特征，以及由于共享后端电路连接和通道的住房箱而引起的整体行为。循环神经网络捕获提取的空间特征的时间演化。该研究证明了该系统在捕捉不同信道故障类型方面的高精度，并被集成到CMS核心生产系统中以实现HCAL的实时监控。
### Conclusion
GraphSTAD系统达到了生产级精度，并被集成到CMS的核心生产系统中，用于实时监控HCAL的异常情况。与基准模型的性能比较证明了所提出系统的潜力。
## 154. `cs.AI` - MMAPG: 一种基于自适应规划图的无需训练框架，用于多模态多跳问答 [PDF](https://arxiv.org/pdf/2508.16051), [HTML](https://arxiv.org/abs/2508.16051)
### Authors
Yiheng Hu,Xiaoyang Wang,Qing Liu,Xiwei Xu,Qian Fu,Wenjie Zhang,Liming Zhu
### Background
多模态多跳问答需要从多种来源（如图像和文本）整合信息来得出答案。现有的方法通常依靠顺序检索和推理，每一步都基于前一步的输出。然而，这种单一路径方法因其容易受到误导的中间步骤的影响而脆弱。此外，构建多模态模型可能非常耗时，通常需要大量的训练。
### Innovation
本文提出了一个无需训练的框架，指导自适应规划图，该框架包括规划、检索和推理模块。规划模块分析自适应规划图的当前状态，确定下一步行动和扩展图的位置，这使得推理路径的动态和灵活探索成为可能。为了处理未指定目标模态的文本检索，开发了特定模态策略，动态适应不同的数据类型。这种方法保留了多模态信息的特性，而不需要昂贵的任务特定训练，能够无缝集成到最新的模型中。
### Conclusion
在MultimodalQA和WebQA上的实验表明，我们的方法与依赖训练的现有模型相比，可以匹配或超越其性能。
## 155. `cs.AI` - HiPhO：当前的(M)LLMs在最新高中物理奥林匹克竞赛基准测试中与人类相差多远？ [PDF](https://arxiv.org/pdf/2509.07894), [HTML](https://arxiv.org/abs/2509.07894)
### Authors
Fangchen Yu,Haiyuan Wan,Qianjia Cheng,Yuchen Zhang,Jiacheng Chen,Fujun Han,Yulun Wu,Junchi Yao,Ruilizhen Hu,Ning Ding,Yu Cheng,Tao Chen,Lei Bai,Dongzhan Zhou,Yun Luo,Ganqu Cui,Peng Ye
### Background
近期，(M)LLMs的物理能力越来越受到关注，但现有的物理基准测试存在两大缺陷：它们既没有提供系统且最新的涵盖实际物理竞赛如物理奥林匹克竞赛的覆盖，也没有能够直接与人类进行性能对比。
### Innovation
HiPhO 标准专注于高中物理奥林匹克竞赛，采用了与人类审阅者一致的评估方法，包含以下创新点：(1)全面的数据：它汇集了2024-2025年的13场最新奥林匹克竞赛，包涵国际和地区比赛以及各种模式的问题。(2)专业的评估：使用官方评分方案进行细致的分级，包括答案和步骤，确保高质量和特定领域的评估。(3)与人类参赛者对比：根据官方奖牌标准为模型分配金牌、银牌、铜牌，以直接对比(M)LLMs与人类参赛者。
### Conclusion
大规模评估30款最先进的(M)LLMs的结果显示，在13份考试中，开源(M)LLMs大多停留在或低于铜牌水平；开源LLMs有显著进步，获得多个金牌；闭源推理(M)LLMs可以达到6到12枚金牌；大多数模型仍然与满分有显著差距。这些结果突显了开源模型与顶尖学生之间的性能差距、闭源模型的强大推理能力和改进空间。
## 156. `cs.AI` - 超越像素：通过层次特征和分割基础模型提升LIME [PDF](https://arxiv.org/pdf/2403.07733), [HTML](https://arxiv.org/abs/2403.07733)
### Authors
Patrick Knab,Sascha Marton,Christian Bartelt
### Background
LIME是一种流行的解释性人工智能技术，用于解析计算机视觉模型的决策过程。LIME使用图像分割方法识别固定区域来计算特征重要性得分作为解释，但是分割质量差会影响解释的有效性和准确性，从而降低解释的清晰度。因此，为了应对这些挑战，研究人员引入了DSEG-LIME框架，它包括由基础模型驱动的数据导向分割和用户引导的层次分割过程中的组成性粒度控制。这项研究发现DSEG在多个XAI指标上优于LIME，并提高了解释与人类认知概念的一致性。
### Innovation
DSEG-LIME框架的主要创新之处包括：（1）数据导向的分割方法，结合基础模型生成人类可识别的特征。（2）用户可根据需要调整层次分割过程的粒度，提供更灵活的控制以优化解释的准确性与清晰度。这些创新为LIME提供了一种更高效的理解模型决策的方法，从而提高了其解释性能力。
### Conclusion
该研究展示了DSEG在多个XAI指标上优于LIME，并能够更好地与人类认知概念相结合，从而增强了LIME的解释力。DSEG-LIME框架为解释性人工智能的进一步发展提供了实证支持，并为理解复杂模型的决策过程提供了新的途径。
## 157. `cs.AI` - 数据库增强查询表示的信息检索 [PDF](https://arxiv.org/pdf/2406.16013), [HTML](https://arxiv.org/abs/2406.16013)
### Authors
Soyeong Jeong,Jinheon Baek,Sukmin Cho,Sung Ju Hwang,Jong C. Park
### Background
信息检索模型在搜索与查询相关的文档方面取得了多项成功，并被应用于多种任务。然而，用户查询往往较短，这给检索器正确获取相关文档带来了挑战。先前的研究提出了扩展查询的方法，通过添加一些与用户相关的特征来增强查询，但这些特征可能效率低下，未能有效地增强查询。此外，在关系数据库中还存在大量其他可用的信息来增强查询。
### Innovation
本文提出了一种名为Database-Augmented Query representation (DAQu)的新型检索框架，该框架通过跨多个表添加各种查询相关元数据来增强原始查询。此外，MAQu通过基于图的集合编码策略编码大量元数据，该策略在无需考虑元数据顺序的情况下考虑特征的层次结构。通过在多种检索场景中验证MAQu，证明了其显著提升了整体检索性能，优于相关基准。
### Conclusion
通过引入Database-Augmented Query representation（DAQu）框架，本文通过跨多个表的查询相关元数据增强了原始查询，并使用基于图的集合编码策略有效地处理了元数据的无序性和大量特征。实验结果表明，该方法能够显著提高信息检索的整体性能。
## 158. `cs.AI` - 理解AI评估模式：不同GPT模型对视觉语言描述的评估 [PDF](https://arxiv.org/pdf/2509.10707), [HTML](https://arxiv.org/abs/2509.10707)
### Authors
Sajjad Abdoli,Rudi Cilibrasi,Rima Al-Shikh
### Background
随着人工智能系统越来越多地评估其他人工智能的输出，理解它们的评估行为变得至关重要，以防止偏见的级联。本研究分析了NVIDIA的‘一切皆可描述’模型生成的视觉语言描述，并由三种GPT变体（GPT-4o、GPT-4o-mini、GPT-5）评估，以揭示每个模型独特的‘评估个性’和潜在的评估策略与偏见。通过使用Gemini 2.5 Pro作为独立问题生成器进行控制实验，验证了这些个性是模型固有的属性，而非次生的特征。通过对生成的问题进行语义相似性分析，发现这些模型之间存在显著差异：GPT模型表现出高度的相似性，而Gemini则表现出截然不同的评估策略。所有GPT模型在评估偏见上表现出一致的2:1倾向，更倾向于负面评估，但这种模式在不同的人工智能架构之间并不普遍。
### Innovation
本研究采用具体的实验设计，对比不同GPT模型对视觉语言描述的评估，揭示了每种模型的评估策略和偏见，证明了评估的复杂性和不同模型间的差异性。通过使用Gemini作为独立评估者，验证了这些评估个性的稳定性和模型的固有特性。此类研究 fournished 新颖之处在于揭示了评估技能与整体能力之间的分离，强调了从多角度审视评估的重要性。
### Conclusion
评估技能和模型的一般能力之间没有直接关系。为了实现强大的AI评估，需要多样化的架构视角。本研究为进一步理解不同模型的评估模式和偏见提供了基础，并强调了多元化方法对于构建稳健的AI评估系统的重要性。
## 159. `cs.AI` - BBScoreV2: 从随机表示学习时间演变和潜在对齐 [PDF](https://arxiv.org/pdf/2405.17764), [HTML](https://arxiv.org/abs/2405.17764)
### Authors
Tianhao Zhang,Zhecheng Sheng,Zhexiao Lin,Chen Jiang,Dongyeop Kang
### Background
自回归生成模型在各种语言任务中发挥关键作用，尤其是在建模和评估长文本序列方面。尽管最近的方法利用随机表示更好地捕捉序列动态，同时编码时序和结构依赖性并在评估中利用这些信息仍具有挑战性。我们观察到，将基于变压器的模型嵌入物拟合并入随机过程会产生有序的潜在表示，这些表示最初是非顺序的。我们在此基础上，基于这一洞见和先前的研究工作，理论地引入了一种新的基于似然的评估度量BBScoreV2。我们在实验中证明了随机潜在空间在高维空间中对语言模型表示进行了“聚类到时间有序”的映射，为BBScoreV2的有效性提供了直观和定量的支持。此外，这种结构与自然语言的内在属性相一致，并提高了如时间一致性评估（例如，打乱任务）和AI生成内容检测等任务的性能。
### Innovation
本文提出了一种新的基于似然的评估度量BBScoreV2，该度量基于基于变压器的模型嵌入物随机过程的拟合，引入有序的潜在表示。通过实验，我们展示了随机潜在空间在高维空间中的“聚类到时间有序”的语言模型表示映射，为BBScoreV2的有效性提供了直观和定量的支持。此外，这种结构与自然语言的内在属性相一致，并提高了时间一致性评估和AI生成内容检测等任务的性能。
### Conclusion
BBScoreV2提供了一种新的方法来评估自回归生成模型，通过随机潜在空间的映射揭示了语言模型表示的时间有序特性。这种新的评估度量揭示了模型生成的文本随时间的变化规律，并能够更有效地检测AI生成内容。
## 160. `cs.AI` - ConfReady: 一种基于RAG的会议清单响应助手和数据集 [PDF](https://arxiv.org/pdf/2408.04675), [HTML](https://arxiv.org/abs/2408.04675)
### Authors
Michael Galarnyk,Rutwik Routu,Vidhyakshaya Kannan,Kosha Bheda,Prasun Banerjee,Agam Shah,Sudheer Chava
### Background
负责的NLP研究清单网站ARR提到，该清单旨在鼓励负责任的研究实践，并解决研究伦理、社会影响和可再现性等方面的问题。作者通过回答这些问题，可以反思自己的工作，确保共享的科学资产符合最佳实践。然而，先前的研究表明，自我报告的清单响应并不总是准确反映论文的内容。
### Innovation
本文介绍了一种名为ConfReady的检索增强生成（RAG）应用，用于支持作者根据会议清单进行反思，并帮助他们完成会议清单。作者团队构建了一个包含1,975个ACL清单响应的数据集，分析了人类答案的问题，并在评估子集上对RAG和大型语言模型（LM）系统进行了基准测试。
### Conclusion
研究结果表明，使用ConfReady可以有效地协助作者完成会议清单，并提高论文的质量。作者团队将ConfReady的代码以AGPL-3.0许可证发布在GitHub上，包括用户界面和PyPI包的相关文档。
## 161. `cs.AI` - The Great AI Witch Hunt: Reviewers Perception and (Mis)Conception of Generative AI in Research Writing [PDF](https://arxiv.org/pdf/2407.12015), [HTML](https://arxiv.org/abs/2407.12015)
### Authors
Hilda Hadan,Derrick Wang,Reza Hadi Mogavi,Joseph Tu,Leah Zhang-Kennedy,Lennart E. Nacke
### Background
生成型AI（GenAI）在研究写作中的使用正在快速增长，但尚不清楚同行评审者如何识别或误判AI辅助的稿件。本文通过一个片段式的在线调查，研究了生成型AI写作对同行评审的影响，调查对象为来自顶级人机交互大会的17名同行评审者。研究发现，虽然生成型AI写作提高了稿件的可读性、语言多样性及信息量，但往往缺乏作者的研究细节和个人见解。在辨别稿件是否为AI辅助写作时，评审者普遍存在困难，但在评分时表现一致性，且注意到AI写作在主观表达和人性化的缺失。
### Innovation
本文通过片段式在线调查方法，深入了解了同行评审者对生成型AI辅助写作的感知和误认为主，补充了该领域现有的文献研究。研究所使用的方法具有创新性，有助于揭示具体问题并为未来的审查程序提供针对性建议。研究还指出，即使使用AI来协助写作，研究的本质质量仍应是评审的重点。
### Conclusion
研究者提出，为了促进公正的评审过程，需要制定评审指南，引导评审者避免对生成型AI的固有偏见。评审应以研究本身的质量为主，而不是其使用的工具。同时，研究者应保持对写作过程的控制，即使在使用生成型AI辅助工具时也是如此。
## 162. `cs.AI` - 两个比一个更好：用于异常检测的对齐表示对 [PDF](https://arxiv.org/pdf/2405.18848), [HTML](https://arxiv.org/abs/2405.18848)
### Authors
Alain Ryser,Thomas M. Sutter,Alexander Marx,Julia E. Vogt
### Background
异常检测关注于识别偏离正常模式的样本。有效检测异常需要对正常样本的信息性表示有深入理解。近期的自监督方法通过在训练中引入有关异常的知识来生成合成异常，从而有效学习这种表示。然而，在特定的现实应用场景中，我们往往无法预测未见数据的表现形式。
### Innovation
我们提出了新的方法Con_2，该方法利用正常样本中的对称性先验知识，从不同语境观察数据。Con_2包含两部分：Context Contrasting，将表示按其语境聚类；Content Alignment，促使模型通过在簇内对正常样本的位置进行对齐来捕捉语义信息。生成的表示空间使得异常可以作为学习到的语境簇的离群点来检测。
### Conclusion
我们在一系列专门的医学数据集上展示了该方法的优势，超越了自监督学习和预训练模型的强基线，并且在自然成像基准上表现竞争。
## 163. `cs.AI` - 基于大型语言模型的动力驾驶自动化：一种交互和可学习的决策框架 [PDF](https://arxiv.org/pdf/2409.12812), [HTML](https://arxiv.org/abs/2409.12812)
### Authors
Shiyu Fang,Jiaqi Liu,Mingyu Ding,Yiming Cui,Chen Lv,Peng Hang,Jian Sun
### Background
目前，联网自动驾驶车辆（CAVs）已经在世界各地开始道路测试，但在复杂场景中的安全性和效率性能仍有待提高。合作驾驶利用了CAVs的连接能力，旨在通过协同效应增强整体性能，但在应对复杂场景时，由于缺乏交互性和持续学习能力，当前的合作驾驶主要局限于单一场景应用和特定的合作驾驶自动化（CDA）水平，仍有改进空间。
### Innovation
本文提出了一种基于大型语言模型（LLMs）的可交互学习合作驾驶框架——CoDrivingLLM，旨在实现所有场景和所有CDA的应用。具体创新点包括：1）引入环境模块以避免直接由LLM控制车辆位置可能产生的错误；2）基于SAE J3216标准定义的CDA四层次，提出基于链式思考的推理模块，包括状态感知、意图共享、谈判和决策；3）推理过程中通过冲突协调器解决集中冲突；4）通过引入记忆模块并采用检索增强生成技术，使CAVs能够从过往经验中学习。这些措施共同改善了LLMs在多步推理任务中的稳定性，并增加了其应用范围。
### Conclusion
通过消融实验、不同体验样本的推理比对以及与其他合作驾驶方法的比较，验证了所提CoDrivingLLM的有效性和优越性。
## 164. `cs.AI` - FOVAL:无需校准且受被试者不变的跨眼跟踪数据集Fixation Depth估计算法 [PDF](https://arxiv.org/pdf/2408.03591), [HTML](https://arxiv.org/abs/2408.03591)
### Authors
Benedikt W. Hosp
### Background
准确的固定深度估计对于增强现实（XR）、机器人技术和人机交互的应用至关重要。然而，当前的方法高度依赖于用户的特定校准，这限制了它们的扩展性和可用性。
### Innovation
介绍了一种名为FOVAL的鲁棒的无需校准的方法，结合了时空序列建模的LSTM网络与不变特征工程和正则化。与Transformer、时序卷积网络（TCNs）和CNNs相比，FOVAL在场景中取得了更好的性能，尤其是在具有限制和噪声的眼动数据中。
### Conclusion
在三个基准数据集上使用交叉验证方法评估表明，FOVAL达到了平均绝对误差(MAE)为9.1 cm，并且没有校准就具有很强的泛化能力。进一步分析了被试间变异性及领域偏移，为模型的鲁棒性和适应性提供了见解。FOVAL的可扩展性和准确性使其非常适合实际部署。
## 165. `cs.AI` - 评估图像质量度量在仿射变换下的不变性 [PDF](https://arxiv.org/pdf/2407.17927), [HTML](https://arxiv.org/abs/2407.17927)
### Authors
Nuria Alabau-Bosque,Paula Daudén-Oliver,Jorge Vila-Tomás,Valero Laparra,Jesús Malo
### Background
通常，主观的图像质量度量是通过其与数据库中数字媒体中可能出现的失真之间的相关性来评估的。然而，这些方法往往未能考虑仿射变换的影响。人类对这些自然变化的不变性往往优于对数字变化的不变性。因此，我们提出了评估图像质量度量在仿射变换下的不变性的一种方法。该方法考虑特定距离在阈值以下时应被忽略，这是所谓度量的隐形阈值。
### Innovation
该研究创新性地提出了一个评估图像质量度量方法，通过考量它们在旋转、平移、缩放和光谱照明变化等仿射变换下的不变性。该方法包括：（1）确定一种客观评价方法，该方法适用于所有度量，并（2）从度量的距离值到这种通用表示的转换。通用表示基于可用的高质量图像数据库的主观评级。通过精确的心理物理方法确定阈值，该方法可以轻松适应任何度量。
### Conclusion
我们的方法经过对一些现有的度量方法的测试，发现它们都没有展现出人类水平的隐形阈值。这意味着，专门针对预测通用失真的可见性对建模而言可能会忽略人类视觉的其他属性，例如不变性和隐形阈值。实验数据和代码已公开以供测试其他度量方法。
## 166. `cs.AI` - 具备LLM先验的贝叶斯概念瓶颈模型 [PDF](https://arxiv.org/pdf/2410.15555), [HTML](https://arxiv.org/abs/2410.15555)
### Authors
Jean Feng,Avni Kothari,Luke Zier,Chandan Singh,Yan Shuo Tan
### Background
概念瓶颈模型（CBMs）作为白盒模型和黑盒模型之间的折中方案，旨在实现可解释性而不牺牲准确性。传统的CBMs训练流程包括预先定义一批可解释的概念、从训练数据中提取这些概念的值、并识别一个稀疏子集作为透明预测模型的输入。然而，这种方法在探索足够广泛的概念集与控制概念提取成本之间存在权衡，这导致了解释性与准确性的显著权衡。
### Innovation
这项工作提出了一种新颖的方法——BC-LLM，它在贝叶斯框架下迭代搜索无限的概念集，在这个框架中，大型语言模型（LLMs）充当概念提取机制和先验知识。尽管LLMs可能存在偏差和幻觉，但证明了BC-LLM能够提供严格统计推断和不确定性量化。
### Conclusion
在图像、文本和表格数据集上，BC-LLM在某些情况下优于可解释度基线和甚至黑盒模型，并且能够更快收敛到相关概念、且对离分布样本更为稳健。
## 167. `cs.AI` - DynamicNER: 一种动态、多语言及细粒度的LLM基础命名实体识别数据集 [PDF](https://arxiv.org/pdf/2409.11022), [HTML](https://arxiv.org/abs/2409.11022)
### Authors
Hanjun Luo,Yingbin Jin,Xinfeng Li,Xuecheng Liu,Ruizhe Chen,Tong Shang,Kun Wang,Qingsong Wen,Zuozhu Liu
### Background
大型语言模型（LLMs）的进步激发了其在命名实体识别（NER）方法中的应用兴趣。然而，现有的数据集主要为传统的机器学习方法设计，对于LLM基础方法而言，数据集中存在的语料库选择和整体设计逻辑存在不足。现有数据集中的实体分类通常固定且较为粗糙，无法充分评估LLM基础方法的优越泛化能力和语境理解能力，从而限制了对该方法广泛应用前景的全面展示。
### Innovation
本文提出了DynamicNER数据集，这是第一个为LLM基础方法设计的具有动态分类的NER数据集，通过引入不同上下文中具有多种实体类型和实体类型列表，提升LLM基础NER的泛化能力。此外，该数据集还支持多语言和细颗粒度分类，覆盖8种语言和155种实体类型，涉及多样化的领域。同时引入了基于双阶段策略和轻量级LLM的新型命名实体识别方法CascadeNER，实现了高精度的同时减少了计算资源的需求。实验表明，DynamicNER作为LLM基础NER方法的稳健有效基准非常可靠。此外还对传统方法和LLM基础方法在该数据集上的表现进行了分析。
### Conclusion
实验结果表明DynamicNER数据集在许多方面都限制了LLM基础NER方法的发展。DynamicNER作为一个稳健且有效的基准，有助于全面评估LLM基础NER方法。同时，也展示了基于轻量级模型的CascadeNER的新颖方法。该数据集和代码已公开提供。
## 168. `cs.AI` - G2D2: 梯度引导的离散扩散模型用于逆问题求解 [PDF](https://arxiv.org/pdf/2410.14710), [HTML](https://arxiv.org/abs/2410.14710)
### Authors
Naoki Murata,Chieh-Hsin Lai,Yuhta Takida,Toshimitsu Uesaka,Bac Nguyen,Stefano Ermon,Yuki Mitsufuji
### Background
最近的研究有效利用了在连续变量上训练的扩散模型作为解决逆问题的先验。虽然离散扩散模型和离散潜在代码在适合离散压缩表示的模态（如图像和运动生成）中表现出色，但它们的非连续和非可微特性限制了它们在连续空间逆问题中的应用。
### Innovation
本文提出了一种通过利用基于离散扩散的生成模型作为先验来解决线性逆问题的新方法。通过利用变分分布逼近真后验分布，从离散分布和连续放松技术构建变分分布。此外，本文采用了一种星形噪声过程来克服传统离散扩散模型中的吸收状态缺陷，证明了这种方法在与连续扩散技术相当的情况下，具有更低的 GPU 内存消耗。
### Conclusion
我们的方法通过将生成模型与离散扩散相结合，克服了传统的离散扩散模型的局限性，并且在与连续扩散方法相媲美的性能下，具备更低的 GPU 内存消耗。
## 169. `cs.AI` - 语言模型文本生成的高效实时精炼 [PDF](https://arxiv.org/pdf/2501.07824), [HTML](https://arxiv.org/abs/2501.07824)
### Authors
Joonho Ko,Jinheon Baek,Sung Ju Hwang
### Background
大规模语言模型（LLMs）在广泛自然语言任务上表现出色，但它们有时会生成事实错误的答案，这构成了一个重要挑战。尽管许多先前的工作侧重于识别LLM生成中的错误并进一步改进，但这些方法在部署上相对慢，因为它们只在LLM生成完全完成（从首个到末个单词）后才进行验证。此外，观察到LLMs在早期生成错误词之后，后续词也更有可能是事实错误的。
### Innovation
提出了一种名为Streaming-VR（流式验证与精炼）的新方法，旨在提高LLM输出验证与精炼的效率。Streaming-VR使验证和纠错可以在生成过程中实时进行，类似流式处理，即LLM构建响应时，每一部分由另一个LLM实时检查和精炼。
### Conclusion
通过多个数据集的全面评估，证明了本方法不仅提高了LLM的答案事实准确性，还比先前的精炼方法更具效率。
## 170. `cs.AI` - DiRW：路径感知的有向图学习以应对异质性 [PDF](https://arxiv.org/pdf/2410.10320), [HTML](https://arxiv.org/abs/2410.10320)
### Authors
Daohan Su,Xunkai Li,Zhenjun Li,Yinping Liao,Rong-Hua Li,Guoren Wang
### Background
近年来，图神经网络（GNN）已成为处理图形结构数据的强大表示学习工具。然而，大多数方法仅适用于无向图，忽视了有向图（有向图形）边中的丰富信息。尽管如此，有向图在现实世界中被广泛应用，且已被证实能够解决异质性问题。现有的基于空间或频谱的有向图神经网络存在复杂的学习机制和对高质量拓扑结构的依赖，导致效率低下且性能不稳定。因此，亟需解决这些问题，提升基于空间的有向图神经网络的性能和效率，为有向图学习提供新的范式和策略。
### Innovation
本文提出了一个名为DiRW的新颖策略和模型，它是一种插拔式方案，适用于大多数基于空间的有向图神经网络。DiRW通过增强路径感知，优化了基于节点特征和拓扑结构的无权重路径采样，并加入了节点特定可学习的路径聚合器，以生成通用节点表示。实验结果表明，DiRW不仅能够显著提升大多数基于空间的方法，还能够在有向图学习中实现SOTA性能，为解决复杂有向图带来新思路和技术支持。
### Conclusion
大量实验结果表明，DiRW作为一种插拔式策略增强了大多数基于空间的方法；作为一种新的有向图学习范式，DiRW取得了SOTA性能。相关源代码和数据可在以下链接获取：this https URL.
## 171. `cs.AI` - CrackSCF：面向结构裂缝稳健而高效的轻量级级联融合网络 [PDF](https://arxiv.org/pdf/2408.12815), [HTML](https://arxiv.org/abs/2408.12815)
### Authors
Hui Liu,Chen Jia,Fan Shi,Xu Cheng,Mianzhao Wang,Shengyong Chen
### Background
准确在像素级别分割结构裂缝仍然存在重大障碍，现有方法未能整合局部纹理与像素依赖性，导致分割结果常出现碎片化和不完整的问题。此外，这些方法的高参数量和巨大的计算需求使得它们难以在资源受限的边缘设备上进行实践部署。
### Innovation
我们提出了名为CrackSCF的轻量级级联融合裂缝分割网络，旨在通过高效捕捉局部模式并以极小的计算负担实现鲁棒的裂缝分割。我们设计了一种轻量级卷积块(LRDS)来取代所有标准卷积，该方法能在保留计算效率的同时有效地捕捉局部模式。为了全面感知裂缝结构，引入了轻量级远程依赖提取器(LDE)来提取全局依赖性，然后通过阶梯式级联融合模块(SCFM)将这些远程依赖性与局部模式智能融合，确保最终的分割图在连续性和细节丰富度方面均表现出色。
### Conclusion
为全面评估我们的方法，我们创建了具有挑战性的TUT基准数据集，并将CrackSCF与五组其他公开数据集进行了对比。实验结果表明，CrackSCF方法在所有数据集上均表现出色，特别是在处理复杂背景噪声时显现出更强的鲁棒性。在TUT数据集上，CrackSCF实现了0.8382的F1分数和0.8473的mIoU，且仅需要4.79M的参数量。
## 172. `cs.AI` - 动态神经好奇心增强自主目标发现的学习灵活性 [PDF](https://arxiv.org/pdf/2412.00152), [HTML](https://arxiv.org/abs/2412.00152)
### Authors
Quentin Houbre,Roel Pieters
### Background
机器人中的自主学习新目标仍然存在复杂问题，本文提出一种好奇心影响学习灵活性的模型。灵感来源于蓝斑-去甲肾上腺素系统和多种认知过程如认知坚持和视觉习惯化，通过机械练习和抑制回返机制，机器人首先发现新的目标，然后由于好奇心机制内生的神经活动加入学习过程。
### Innovation
本文创新点在于将好奇心和注意力相结合，采用动态神经场建模好奇心、习惯化和坚持，通过多层感知机实现前向和逆向模型，支持对物体朝不同方向推的多样学习路径，同时表现出对相似目标学习以及探索与利用之间连续切换的有趣特性。
### Conclusion
机器人采用动态神经场模型展示了根据不同物体变化的多种学习路径，并且在学习相似目标及不断在探索与利用之间切换方面表现出有趣性质。
## 173. `cs.AI` - SeCodePLT：评估代码生成AI安全性的一个统一平台 [PDF](https://arxiv.org/pdf/2410.11096), [HTML](https://arxiv.org/abs/2410.11096)
### Authors
Yuzhou Nie,Zhun Wang,Yu Yang,Ruizhe Jiang,Yuheng Tang,Xander Davies,Yarin Gal,Bo Li,Wenbo Guo,Dawn Song
### Background
现有的用于评估代码生成大型语言模型（LLMs）的安全风险和能力的基准存在诸多局限性：（1）覆盖范围有限；（2）依赖静态评估指标如LLM判断或规则检测，缺乏动态分析的精确性；（3）数据质量和基准规模之间的权衡。这些局限性促使研究者开发一种通用且可扩展的基准构建框架，该框架基于手动验证的高质量种子示例并利用有针对性的变异进行扩展，从而提供全面的评估工具，以支持使用动态指标进行彻底的风险评估和安全能力评估。
### Innovation
引入了一种通用且可扩展的基准构建框架，该框架从手动验证的高质量种子示例开始，并通过有针对性的变异进行扩展。该框架结合了专家洞察和自动化生成，平衡了手工工作量、数据质量和基准规模之间的关系。通过将该框架应用于Python、C/C++和Java语言，构建了一个包含超过5900个样本的大规模数据集SeCodePLT，涵盖了44个CWE（常见漏洞与暴露）类别下的风险和三个安全能力，相比最先进的基准，SeCodePLT具有更广的覆盖范围、更高的数据准确性和更大的规模。
### Conclusion
使用SeCodePLT评估了领先的代码LLM及其生成安全代码和识别或修复漏洞的能力，揭示了它们的优势和不足。SeCodePLT提供的基准有助于更全面地评估代码生成AI的安全性。
## 174. `cs.AI` - FLOAT：基于流动匹配生成运动潜在空间的语音驱动肖像动画 [PDF](https://arxiv.org/pdf/2412.01064), [HTML](https://arxiv.org/abs/2412.01064)
### Authors
Taekyung Ki,Dongchan Min,Gyeongsu Chae
### Background
随着扩散生成模型的快速发展，肖像图像的动画效果取得了显著成果，但在生成时间和空间一致的视频以及由于迭代采样特性所导致的快速采样速度方面依然存在挑战。
### Innovation
提出了FLOAT，一种基于流动匹配生成模型的音频驱动肖像动画生成方法。通过利用学习到的正交运动潜在空间，而不再依赖于基于像素的潜在空间，实现高效的时间一致运动生成和编辑。引入了基于变换器的向量场预测器和有效的帧级条件机制，还有支持通过语音驱动的情感增强，实现自然表达性运动的集成。
### Conclusion
大量实验表明，与现有的语音驱动肖像动画方法相比，该方法在视觉质量和运动保真度以及效率方面表现更优。
## 175. `cs.AI` - KatFishNet：通过语言特征分析检测生成的韩文文本 [PDF](https://arxiv.org/pdf/2503.00032), [HTML](https://arxiv.org/abs/2503.00032)
### Authors
Shinwoo Park,Shubin Kim,Do-Kyung Kim,Yo-Sub Han
### Background
大型语言模型（LLMs）的快速发展使得区分人类写作和LLM生成的文本变得更加困难。检测LLM生成的文本对于维护学术诚信、防止抄袭、保护版权以及确保道德研究实践至关重要。大多数先前的研究主要集中在英语文本上。然而，具有独特形态和语法特征的语言需要专门的检测方法。他们的独特结构和使用模式会妨碍主要针对英语设计的方法的直接应用。因此，研究者特别关注韩语，它具有相对灵活的空格规则、丰富的词形系统以及比英语更少的逗号使用。
### Innovation
本文介绍了KatFish，一个用于检测LLM生成的韩文文本的第一个基准数据集，包含来自人类和四种LLM生成的文本，覆盖三种体裁。通过分析空格模式、词性多样性及逗号使用，论文表明人类写作和LLM生成的韩文文本之间存在语言差异。基于这些观察，提出了KatFishNet，一种针对韩语特别设计的检测方法。KatFishNet在AUC ROC性能上比现有最佳检测方法高19.78%。
### Conclusion
本文通过KatFish和KatFishNet的开发，为检测LLM生成的韩文文本提供了有效的解决方案，并提高了检测准确性。研究成果公开了代码和数据，以供进一步研究使用。
## 176. `cs.AI` - 剪裁困境：如何使CLIP最具信息性的头部增强性能同时放大偏见 [PDF](https://arxiv.org/pdf/2503.11103), [HTML](https://arxiv.org/abs/2503.11103)
### Authors
Avinash Madasu,Vasudev Lal,Phillip Howard
### Background
CLIP 是一个广受欢迎的基础模型，被广泛用于多种视觉-语言任务，但对其内部工作原理知之甚少。随着CLIP在现实世界应用中的不断增加，理解其限制和嵌入的社会偏见变得越来越重要，以减少潜在的有害后果。然而，关于是什么内部机制驱动CLIP的惊人能力及其严重缺陷的问题仍然没有回答。
### Innovation
提出了概念一致性分数（CCS），这是一种新颖的可解释性度量，用于衡量CLIP模型中个别注意力头与特定概念的一致性程度。通过软剪枝实验发现，高CCS头对于保持模型性能至关重要，剪除它们会导致比随机或低CCS头更大的性能下降。研究还表明，高CCS头捕获了关键概念，在领域外检测、概念特定推理和视频-语言理解中起关键作用。此外，证明高CCS头学习了与社会偏见放大的错误相关性。
### Conclusion
概念一致性分数（CCS）作为揭示CLIP模型在性能和社会偏见之间的悖论的强有力解释度量，突显了提高性能可能加剧社会偏见的问题。
## 177. `cs.AI` - Sparsity May Be All You Need: Sparse Random Parameter Adaptation [PDF](https://arxiv.org/pdf/2502.15975), [HTML](https://arxiv.org/abs/2502.15975)
### Authors
Jesus Rios,Pierre Dognin,Ronny Luss,Karthikeyan N. Ramamurthy
### Background
随着语言模型的规模越来越大，完全微调这些模型进行对齐和任务适应变得极其昂贵。参数高效微调（PEFT）方法旨在通过仅训练少量参数而不是所有模型参数，显著减少细调这些模型所需的计算和内存资源。当前最受欢迎的PEFT方法是低秩适应（LoRA），它冻结模型参数，并引入一个由低秩矩阵组成的小型可训练参数集。该论文介绍了一种新的方法，通过随机选择一小部分模型参数进行训练，同时固定所有其他参数，而不引入任何附加假设，如低秩结构。
### Innovation
该方法通过随机选择一小部分可训练参数来减少PEFT技术所需的参数数量，而不需要任何附加假设结构，如低秩结构。这种方法与LoRA相比，在使用相似数量的可训练参数时表现出色，表明PEFT技术性能的关键因素可能是可训练参数的数量，而不一定是特定的适配器结构。
### Conclusion
该研究表明，对于PEFT技术的成功而言，重要的是使用的可训练参数数量，而不是特定的适配器结构。
## 178. `cs.AI` - 在黑暗中挣扎：探索重症护理环境中心老年患者家属的信息需求和设计机会 [PDF](https://arxiv.org/pdf/2502.05115), [HTML](https://arxiv.org/abs/2502.05115)
### Authors
Shihan Fu,Bingsheng Yao,Smit Desai,Yuqi Hu,Yuling Sun,Samantha Stonbraker,Yanjun Gao,Elizabeth M. Goldberg,Dakuo Wang
### Background
重症监护病房（ICU）中的老年患者比例正在迅速增加。在这种情况下，患者的家属需要代表患者访问和解读医疗信息。然而，家属通常不得不依赖超载的医护人员进行信息更新，并且他们通常缺乏理解复杂医疗信息所需的健康素养。因此，家属在获取和解读医疗信息方面面临诸多挑战。目前还没有专门针对这些家属设计和优化的信息支持工具。本研究旨在探讨这些家庭护理者的信息需求，为未来的人工智能系统设计提供指导.
### Innovation
本项目通过与11名家属进行形式性访谈，识别他们在获取和解读医疗信息方面的挑战，然后汇总设计要求并提出一个基于AI的系统原型。该系统有两个关键功能：时间轴可视化，展示AI提取和总结的关键医疗事件；基于LLM的聊天机器人，提供情境相关的信息支持。这是首项专门针对重症监护环境中家属设计和优化的AI系统研究，具有创新意义。
### Conclusion
本文报告了该系统的后续用户评估，并讨论了未来针对老年重症监护家属的人工智能系统的发展方向。结果显示该系统在一定程度上帮助家属更好地理解医疗信息，但仍需进一步开发和测试以满足家属的实际需求，并提供持续支持。
## 179. `cs.AI` - SuPreME: 多模态心电图表示学习的监督预训练框架 [PDF](https://arxiv.org/pdf/2502.19668), [HTML](https://arxiv.org/abs/2502.19668)
### Authors
Mingsheng Cai,Jiuming Jiang,Wenhao Huang,Che Liu,Rossella Arcucci
### Background
心血管疾病是全球主要的死亡和残疾原因之一。心电图（ECG）对于诊断和监测心脏健康至关重要，但获得大规模标注的心电图数据集劳动密集、耗时长。最近的心电图自我监督学习（eSSL）方法通过学习不需大量标签的特征来缓解这一问题，但往往未能捕捉到细微的临床语义，并且需要大量的任务特定微调。
### Innovation
提出了SuPreME（监督预训练）框架，这是一种多模态心电图表示学习的监督预训练框架。通过一次离线提取大型语言模型（LLM）从中ECG报告实体推导出的结构化诊断标签预训练，SuPreME有助于去噪和标准化心脏概念，并改进临床表示学习。通过融合心电图信号和文本心脏查询而非固定标签，SuPreME可以在不需要进一步微调的情况下零样本分类未见过的心脏状况。在六个下游数据集（涵盖106种心脏状况）上的评估结果显示，SuPreME在零样本AUC性能上达到了77.20%，超越了最先进的自监督方法4.98%。
### Conclusion
结果表明，SuPreME能够有效地利用结构化的临床相关知识生成高质量的心电图表示。
## 180. `cs.AI` - 从传统方法到基础模型的多模态适应与泛化进展 [PDF](https://arxiv.org/pdf/2501.18592), [HTML](https://arxiv.org/abs/2501.18592)
### Authors
Hao Dong,Moru Liu,Kaiyang Zhou,Eleni Chatzi,Juho Kannala,Cyrill Stachniss,Olga Fink
### Background
在实际场景中，实现领域适应和泛化面临巨大挑战，因为模型必须适应或在未知目标分布中泛化。进一步扩展到未见的多模态分布，即多模态领域适应和泛化，更加挑战，因为不同模态具有独特的特征。近年来，尤其是在行动识别和语义分割等应用中，取得了显著进展。此外，大型预训练多模态基础模型的出现，如CLIP，激发了利用这些模型来增强适应性和泛化性能的应用，或将其适应到下游任务中。
### Innovation
本文涵盖了从传统方法到基础模型的多模态适应与泛化进展，包括四个主要部分：(1)多模态领域适应；(2)测试时多模态适应；(3)多模态领域的泛化；(4)借助多模态基础模型进行领域适应和泛化；(5)多模态基础模型的适应。每一部分都正式定义了问题并详细回顾了现有方法，同时分析了相关数据集和应用，指出了开放挑战并提出了未来研究方向。这是一个活跃的存储库，定期更新相关文献，见此处：this https URL
### Conclusion
本文提供了多模态领域适应与泛化的全面综述，从传统的适应方法到大型预训练多模态基础模型，涵盖多模态领域适应与泛化、测试时多模态适应、多模态领域泛化以及多模态基础模型的适应等方面。
## 181. `cs.AI` - 长上下文心理健康评估的分层多专家框架 [PDF](https://arxiv.org/pdf/2501.13951), [HTML](https://arxiv.org/abs/2501.13951)
### Authors
Jinwen Tang,Qiming Guo,Wenbo Sun,Yi Shang
### Background
长形式的心理健康评估为大型语言模型（LLMs）带来独特挑战，这些模型在处理扩展的、专业领域特定的背景时会表现出幻觉或不一致的推理。现有的单一模型方法难以提供准确和可靠的心理健康评估结果，特别是在处理复杂的心理诊断任务时普遍存在误判和不精确的问题。
### Innovation
该研究提出了分层多专家推理（Stacked Multi-Model Reasoning，SMMR）框架。SMMR 利用多个大型语言模型和专门的小模型作为等同的“专家”。早期层隔离简短的离散子任务，而后续层则通过更高级的长上下文模型整合和细化这些初步结果。该框架通过汇集多样化的“第二意见”来减轻幻觉，捕捉细微的心理临床特点，并在高风险心理健康评估中增强可靠性。
### Conclusion
通过将 SMMR 应用于 DAIC-WOZ 抑郁筛查数据集和 48 个精心挑选的心理障碍案例研究，研究结果表明与单一模型基线相比，SMMR 在准确性和 F1 分数方面有持续改进，并且减少了 PHQ-8 错误率。这表明多专家框架对于心理健康筛查具有更高的可信度，可提升 AI 驱动筛查的可靠性。
## 182. `cs.AI` - 梯度对齐在物理感知神经网络中的作用：一种二次优化视角 [PDF](https://arxiv.org/pdf/2502.00604), [HTML](https://arxiv.org/abs/2502.00604)
### Authors
Sifan Wang,Ananyae Kumar Bhartari,Bowen Li,Paris Perdikaris
### Background
多任务学习通过复合损失函数是现代深度学习的基本组成部分，但优化相互竞争的目标仍具有挑战性。在物理感知神经网络（PINNs）中，这种冲突尤其难以解决，因为PINNs涉及的物理约束和数据拟合目标之间存在复杂的矛盾。本文分析了这些冲突如何限制一阶方法，并展示了第二阶优化如何通过隐式梯度对齐自然解决这些问题。
### Innovation
1. 提出了新的理论和实践方法来应对损失项之间的方向冲突，并通过证明SOAP（一种最近提出的拟牛顿方法）高效地近似Hessian预条件器，在PINNs中实现了突破性的性能：在10个具有挑战性的偏微分方程（PDE）基准测试中取得了最优结果，其中包括第一次成功应用于雷诺数高达10,000的湍流流动，其准确度比现有方法提高了2-10倍。2. 引入了一种新的梯度对齐评分，它将余弦相似性推广到多个梯度，提供了一种分析优化动力学的实用工具。3. 研究成果为理解和解决梯度冲突提供了框架，这对优化科学计算之外的领域也有广泛的影响。
### Conclusion
通过理论分析，本文证明了梯度冲突如何限制一阶方法，并展示了第二阶优化如何通过隐式梯度对齐自然解决这些问题，从而推动了PINNs的性能边界。SOAP方法的有效性和梯度对齐评分的引入为解决多目标优化问题提供了新的思路和工具。
## 183. `cs.AI` - 协商性齐平：拥抱分歧以实现更公平的结果——城市研究中的见解 [PDF](https://arxiv.org/pdf/2503.12613), [HTML](https://arxiv.org/abs/2503.12613)
### Authors
Rashid Mushkani,Hugo Berard,Shin Koseki
### Background
城市评估常常将多样化的需求简化为单一评分，这可能掩盖少数群体的观点。已有研究指出，这种评分方法容易忽略某些群体的需求。本研究选择在蒙特利尔进行社区为中心的考察，选取固定数量的不同人群（轮椅使用者、老年人、LGBTQIA2+居民和移民）作为研究对象，对街道的可达性、包容性、美观度及实用性进行评价，并根据访谈抽取的指标对图片进行排名。研究结果表明，不同群体在某些方面的评价存在系统性的分歧，如轮椅使用者在可达性和实用性方面的分歧最大；LGBTQIA2+群体强调包容性和活力；老年人则更关心安全。组内讨论虽然可以减少信息差距，但无法消除价值观冲突。评分反映了强度，而排名则迫使做出取舍。
### Innovation
研究提出了一种名为‘协商性齐平’的透明、预算意识强的协商程序，并在角色扮演的利益相关者代理和中立调解人之间进行了试点测试。与相同公共评价标准下的最佳基线设计相比，协商性齐平方案在总效益、最差群体效益、百分廿满意度及减少了不平等程度方面均有显著提升。这一方法通过将分歧视为信号，并报告最差群体的结果而不是总结果，有助于规划师和人工智能从业者揭示妥协点，同时维护少数群体优先权，保持效率。
### Conclusion
研究结果表明，将分歧视为信号并在报告结果时也体现最差群体的结果，有助于规划师和AI从业者在维护效率的同时更好地关注少数群体的需求。基于此，该研究提出的设计方法‘协商性齐平’对于实现城市空间的公平性和多样性具有重要意义。
## 184. `cs.AI` - AttentionDrop: 一种 Transformer 模型的新正则化方法 [PDF](https://arxiv.org/pdf/2504.12088), [HTML](https://arxiv.org/abs/2504.12088)
### Authors
Mirza Samad Ahmed Baig,Syeda Anshrah Gillani,Abdul Akbar Khan,Shahid Munir Shah,Muhammad Omer Khan
### Background
变压器架构在自然语言处理、计算机视觉和语音处理等多个任务上达到了最先进的性能。然而，由于其巨大的容量，当训练数据有限或噪声较大时，经常会遇到过拟合的问题。
### Innovation
提出了统一的基于随机正则化技术的三个不同变种方法，即硬注意掩码（Hard Attention Masking）、模糊注意力平滑（Blurred Attention Smoothing）和一致性正则化注意力Drop（Consistency-Regularized AttentionDrop）。这些方法直接作用于自我注意力分布。硬注意掩码通过对每条查询的前k个注意logits随机置零来鼓励多样化的上下文利用；模糊注意力平滑通过在注意力logits上应用动态高斯卷积来弥散过于集中的分布；一致性正则化注意力Drop通过基于KL损失的输出稳定性约束，确保在多重独立的注意力Drop扰动下输出的稳定性。
### Conclusion
研究结果表明，与标准Dropout、DropConnect和R-Drop基线相比，AttentionDrop在准确率、校准度和对抗鲁棒性方面始终有所提升。
## 185. `cs.AI` - MigGPT: 利用大型语言模型自动迁移跨版本的Linux内核外树补丁 [PDF](https://arxiv.org/pdf/2504.09474), [HTML](https://arxiv.org/abs/2504.09474)
### Authors
Pucheng Dang,Di Huang,Dong Li,Kang Chen,Yuanbo Wen,Qi Guo,Xing Hu
### Background
内核外树补丁对于适应新硬件或实现特定功能至关重要。这些补丁的维护和更新需要经验丰富的工程师付出大量的努力。尽管大型语言模型在各种领域取得了显著进展，表明其在自动化内核外树补丁迁移方面的潜力，但我们发现这些模型在理解不完整代码上下文和准确识别迁移点方面存在挑战。因此，本文提出了一种名为MigGPT的框架，它采用了一种新颖的代码指纹结构来保留代码片段信息，并结合了三个精心设计的模块以提高内核外树补丁迁移的准确性和效率。此外，还使用真实世界项目建立了一个坚固的基准测试来评估大型语言模型的能力。实验结果表明，MigGPT显著优于直接应用标准的大规模语言模型，完成了高达74.07%的迁移任务。
### Innovation
提出了MigGPT框架，采用新颖的代码指纹结构保留代码片段信息，集成三个精心设计的模块以提高迁移准确性和效率。
### Conclusion
MigGPT显著优于直接应用标准的大规模语言模型，完成了高达74.07%的迁移任务，证明了利用大规模语言模型自动迁移内核外树补丁的可行性。
## 186. `cs.AI` - MT-RewardTree：一种通过奖励建模推进基于LLM的机器翻译的全面框架 [PDF](https://arxiv.org/pdf/2503.12123), [HTML](https://arxiv.org/abs/2503.12123)
### Authors
Zhaopeng Feng,Jiahan Ren,Jiayuan Su,Jiamei Zheng,Hongwei Wang,Zuozhu Liu
### Background
过程奖励模型（PRMs）在大规模语言模型（LLMs）复杂推理任务中取得了成功，但在机器翻译（MT）中的应用尚未探索，原因在于缺乏系统的方法和评估基准。
### Innovation
提出了MT-RewardTree框架，这是一种用于构建、评估和部署过程奖励模型的综合框架。创新点包括：1) 使用近似蒙特卡洛树搜索（MCTS）自动生成词级偏好对，减少细粒度步骤的人工注释成本；2) 建立了首个针对MT的奖励模型基准，系统比较了不同的奖励建模架构，揭示了词级监督能够有效捕捉细粒度偏好；3) 实验表明，在相同输入前缀下，MT-PRM-Qwen-2.5-3B在词级和序列级评价中达到最新水平，并展示了基于PRM的测试时对齐和假说组的增强性能。
### Conclusion
该研究为MT领域的奖励模型研究提供了有价值的见解。代码和数据在指定的网页上发布。
## 187. `cs.AI` - 当AI失败时，谁应该负责？映射AI隐私和伦理事件的原因、主体及其后果 [PDF](https://arxiv.org/pdf/2504.01029), [HTML](https://arxiv.org/abs/2504.01029)
### Authors
Hilda Hadan,Reza Hadi Mogavi,Leah Zhang-Kennedy,Lennart E. Nacke
### Background
人工智能（AI）技术的迅速发展引发了重大的隐私和伦理担忧。然而，现有的AI事件分类和指南缺乏现实生活案例的支持，限制了它们在预防和减轻风险方面的有效性。通过对202个实际的AI隐私和伦理事件进行分析，文章将这些事件分类为人工智能生命周期的不同阶段，并涵盖了原因、责任实体、信息泄露来源和影响等因素。研究发现，组织决策不佳和法律不合规导致的广泛危害、有限的纠正干预以及少数报告的AI开发者和采用实体构成了主要问题。
### Innovation
文章开发了一种分类法，系统地对AI隐私和伦理事件进行分类，揭示了这些事件的特点和影响。该分类法强调当前AI治理框架的不足，并为政策制定者和实践者提供了详实的指导，以加强用户保护，制定有针对性的AI政策，改进报告实践，并促进负责任的AI治理和创新，特别是在社交媒体和儿童保护等领域，这一分类法为实际应用提供了结构化的框架支持。
### Conclusion
研究结果为政策制定者和实践者提供了行动指南，以增强用户保护、制定针对性的AI政策、提高报告实践，并促进负责任的AI治理和创新，特别是在社交媒体和儿童保护等领域。
## 188. `cs.AI` - No Black Box Anymore: Demystifying Clinical Predictive Modeling with Temporal-Feature Cross Attention Mechanism [PDF](https://arxiv.org/pdf/2503.19285), [HTML](https://arxiv.org/abs/2503.19285)
### Authors
Yubo Li,Xinyu Yao,Rema Padman
### Background
尽管深度学习模型在临床预测任务中表现出色，但解释性仍然是一个重大挑战。文章旨在通过引入基于变压器架构的Temporal-Feature Cross Attention Mechanism (TFCAM)，来捕捉时间和临床特征间的动态交互，从而提高预测准确性和可解释性。在一项涉及1,422名慢性肾病患者的实验中，TFCAM在预测是否进展为终末期肾病时，优于LSTM和RETAIN基准模型，获得了0.95的AUROC和0.69的F1分数。除此之外，TFCAM还通过识别关键的时间周期、排序特征重要性和量化时间内的特征相互影响提供了多层次的解释性，解决了深度学习在医疗保健中的“黑箱”问题，提供了医生对疾病进展机制的透明洞察，同时保持了最先进的预测性能。
### Innovation
文章创新地提出了一种新型的深度学习框架——Temporal-Feature Cross Attention Mechanism (TFCAM)，该机制能够捕捉时间和临床特征间的动态交互，提高预测准确性和可解释性。实验结果表明TFCAM在慢性肾病患者的终末期肾病预测任务中性能优越且具有多层次的可解释性，有助于解决深度学习在医疗预测中的“黑箱”问题。
### Conclusion
TFCAM提供了多层次的解释性，识别关键时间周期，排序特征重要性，量化时间内的特征相互影响，同时保持业内顶尖的预测性能。这种方法不仅提高了模型的透明度，还能促进临床医生更好地理解疾病进展机制。
## 189. `cs.AI` - 融合时序差分一致性自编码器的高效可持续异常检测方法在 cyber-物理系统中的应用 [PDF](https://arxiv.org/pdf/2504.06320), [HTML](https://arxiv.org/abs/2504.06320)
### Authors
Michael Somma
### Background
随着数字技术和物联网设备及工业控制系统（ICS）的迅速集成，关键基础设施（尤其是水分布系统）遭受网络攻击的风险增加。这些网络物理系统（CPS）引入了新的漏洞，需要建立强大的自动化入侵检测系统（IDS）来应对潜在威胁。
### Innovation
该研究提出了融合时序差分一致性（TDC）损失的概念，并在此基础上提出了一种混合自编码器模型，称为混合 TDC-AE，该模型结合了确定性节点和传统统计节点，能够捕捉系统的动力学特征。此外，该方法还能极大地提高异常检测的时间效率，同时保持了计算效率，减少了全连接层的数量，提高了整体可持续性和效率。
### Conclusion
该方法通过利用启发于物理的一致性原则，实现了高水平的异常检测性能，增强了网络物理系统的抗风险能力。
## 190. `cs.AI` - ConCISE: Confidence-guided Compression in Step-by-step Efficient Reasoning [PDF](https://arxiv.org/pdf/2505.04881), [HTML](https://arxiv.org/abs/2505.04881)
### Authors
Ziqing Qiao,Yongheng Deng,Jiali Zeng,Dong Wang,Lai Wei,Guanbo Wang,Fandong Meng,Jie Zhou,Ju Ren,Yaoxue Zhang
### Background
大型推理模型（LRMs）在通过链式思考（CoT）提示进行复杂推理任务时表现出色，但往往会产生冗长的输出，增加计算开销。现有的基于微调的压缩方法要么在后剪枝操作中存在风险，可能导致推理连贯性受损，要么依赖于采样选择，难以彻底去除冗余内容。因此，本文探讨了这种限制性瓶颈。
### Innovation
本文提出了一种名为ConCISE（Confidence-guided Compression In Step-by-step Efficient Reasoning）的框架，该框架结合了Confidence Injection（增强推理的信心）和Early Stopping（当信心充足时终止推理），从信心指导的角度出发，识别并消除了LRMs中的冗余反馈模式（Confidence Deficit和Termination Delay）。ConCISE能够生成简洁的推理链，在保持任务准确率的同时，减少长度最多约50%。
### Conclusion
与基线方法相比，基于ConCISE生成的数据对LRMs进行微调，能够在压缩和任务性能之间取得更好的平衡。
## 191. `cs.AI` - 用于指令微调数据可学习且可扩展的影响估计的神经网络 [PDF](https://arxiv.org/pdf/2502.09969), [HTML](https://arxiv.org/abs/2502.09969)
### Authors
Ishika Agarwal,Dilek Hakkani-Tür
### Background
影响函数在模型训练中提供了重要的洞察，但现有方法存在计算成本高和泛化能力差的问题。尤其是最近的工作提出了多种基于语言模型的计算数据影响的方法，但这些方法不适用于大规模模型和数据集，因为它们需要昂贵的正向和反向传播计算，大量的内存需求存储大的模型，并且影响估计对新数据的泛化性能差。
### Innovation
本文探索了使用小型神经网络（我们称之为InfluenceNetwork）来估计影响值，实现了高达99%的成本降低。即使有巨大的加速，我们的方法（称为NN-CIFT：用于有效指令微调的神经网络）也在下游子集选择任务中表现出了与最先进的影响函数相当的效果。文中还提供了一种嵌入神经网络内的高效训练方法的具体超参数分析。
### Conclusion
本研究中的方法最小型化的模型仅有全语言模型的0.0027%大小，我们在四个最先进的影响函数基础上做了研究，结果显示，尽管有巨大的加速，但NN-CIFT的方法对性能没有妥协。作为验证，代码可以在指定的链接处找到。
## 192. `cs.AI` - StreamBridge: 将您的离线视频大语言模型转变为积极的流式助手 [PDF](https://arxiv.org/pdf/2505.05467), [HTML](https://arxiv.org/abs/2505.05467)
### Authors
Haibo Wang,Bo Feng,Zhengfeng Lai,Mingze Xu,Shiyu Li,Weifeng Ge,Afshin Dehghan,Meng Cao,Ping Huang
### Background
现有的视频大语言模型（Video-LLMs）在离线场景中表现良好，但在流式场景中存在局限性，特别是在多轮实时理解能力和主动响应机制方面。StreamBridge 提供了一个简单而有效的框架，旨在将离线 Video-LLMs 转换为具备流式处理能力的模型。
### Innovation
StreamBridge 引入了两项关键创新：（1）结合带有回合衰减压缩策略的内存缓冲区，支持长时间上下文的多轮交互；（2）一个解耦且轻量级的激活模型，可以无缝集成到现有的 Video-LLMs 中，从而实现持续的主动响应。此外，为了支持 StreamBridge，还构建了 Stream-IT 数据集，专为流式视频理解设计，包含交错的视频-文本序列和多种指令格式。
### Conclusion
实验结果表明，StreamBridge 显著提高了离线 Video-LLMs 在流式理解任务中的能力，甚至在与 GPT-4o 和 Gemini 1.5 Pro 这类专有模型的比较中也表现出色，同时在标准视频理解基准测试中也达到了竞争或领先的水平。
## 193. `cs.AI` - Schreier-Coset Graph Propagation [PDF](https://arxiv.org/pdf/2505.10392), [HTML](https://arxiv.org/abs/2505.10392)
### Authors
Aryan Mishra,Lizhen Lin
### Background
图神经网络（GNNs）为过图结构数据的机器学习提供了一种原则性框架，但其表现能力常常受到过压缩的阻碍，过压缩问题导致远处节点的信息被压缩到固定大小的向量中。现有的解决方案包括图重布线和基于Cayley图和扩张图的瓶颈抵抗架构，尽管这些方法避免了过压缩问题，但也引入了可扩展性瓶颈。具体来说，SL(2, Ωn) 上的Cayley图表现出很强的理论特性，但节点增长呈现立方阶 Θ(n^3)，导致高内存使用。
### Innovation
为了解决这个问题，本文引入了Schreier-Coset 图传播（SCGP），这是一种基于群论的增强方法，通过Schreier-核嵌入丰富节点特征而不改变输入图的拓扑。SCGP将无瓶颈连接模式嵌入紧凑的特征空间中，从而改善了远程消息传递能力，同时保持了计算效率。实验表明，SCGP在标准的节点和图形分类基准上的性能与扩张图和重布线的GNN基线相当或超越。
### Conclusion
实验评估表明，SCGP在标准节点和图形分类基准上的性能与或超越基于扩张图和重布线的基线方法。此外，SCGP在处理层次化和模块化的图结构时表现出特殊的优点，具有减少推理延迟、提高可扩展性和低内存占用，使其适合实时和资源受限的应用。
## 194. `cs.AI` - CLEAR: 一种基于临床背景的放射学报告评估表格框架 [PDF](https://arxiv.org/pdf/2505.16325), [HTML](https://arxiv.org/abs/2505.16325)
### Authors
Yuyang Jiang,Chacha Chen,Shengyuan Wang,Feng Li,Zecong Tang,Benjamin M. Mervak,Lydia Chelala,Christopher M Straus,Reve Chahine,Samuel G. Armato III,Chenhao Tan
### Background
现有的评估指标在捕捉候选与真实放射学报告之间的细微临床差异方面缺乏粒度和解释性，导致评估效果不理想。
### Innovation
引入了一个基于临床的表格框架（CLEAR），该框架结合了专家标注和属性级别的比较，用于放射学报告评估。CLEAR 不仅检查报告是否能准确识别是否存在医学状况，还评估报告是否能精确描述每个被识别状况的五个关键属性：首次出现、变化、严重程度、描述性位置和建议。与先前工作相比，CLEAR 的多维属性级输出能够更全面、可临床解释地评估报告质量。
### Conclusion
通过与五位认证放射科医生合作，开发了 CLEAR-Bench 数据集，该数据集包含来自 MIMIC-CXR 的 100 张胸部 X 光片报告，并注释了 6 个精心选择的属性和 13 个 CheXpert 状态。实验结果显示，CLEAR 在提取临床属性方面具有高精度，并提供了与临床判断高度一致的自动化指标。
## 195. `cs.AI` - Creative Preference Optimization [PDF](https://arxiv.org/pdf/2505.14442), [HTML](https://arxiv.org/abs/2505.14442)
### Authors
Mete Ismayilzada,Antonio Laverghetta Jr.,Simone A. Luchini,Reet Patel,Antoine Bosselut,Lonneke van der Plas,Roger Beaty
### Background
大型语言模型（LLMs）在自然语言生成任务上展现了令人印象深刻的表现，但生成真正富有创意的内容（如新颖性、多样性和惊喜感等）的能力仍然有限。现有的增强LLM创意的方法往往聚焦于单一维度或特定任务，未能从总体上、通用地解决创意的多方面本质。
### Innovation
本文提出了一种新的对齐方法——创意偏好优化（CrPO），该方法以模块化的方式将多个创意维度的信号注入到偏好优化目标中。通过使用CrPO训练和评估多种模型，并结合MuCE大规模人类偏好数据集，这些模型在自动和人类评价中均超过了包括GPT-4o在内的强基线，生成了更加新颖、多样和令人惊讶的生成结果，同时保持了高质量的输出。进一步的评估证实了该方法的泛化能力。
### Conclusion
我们的研究表明，在偏好框架中直接优化创意是一种增强LLM创意能力的有希望的方向，同时不会牺牲输出质量。
## 196. `cs.AI` - 空间群仿射晶体扩散 [PDF](https://arxiv.org/pdf/2505.10994), [HTML](https://arxiv.org/abs/2505.10994)
### Authors
Rees Chang,Angela Pak,Alex Guerra,Ni Zhan,Nick Richardson,Elif Ertekin,Ryan P. Adams
### Background
晶体材料的设计对于各种技术具有重要意义。与其它原子系统不同，三维晶体对称为空间群，这些空间群强烈影响材料的性质。现有方法在处理空间群约束时存在困难，因此提出了新的方法来解决这一问题。
### Innovation
本文提出了SGEquiDiff，这是一种晶体生成模型，能够自然地处理空间群约束，通过采用空间群不变的似然性、SE(3)-不变的晶体晶格递归采样、置换不变的变换器基自回归采样、以及空间群仿射原子坐标扩散等技术。这些方法确保了向量场自动存在于Wekoff位置的切空间中。SGEquiDiff在标准基准数据集上的表现优于现有技术，得到了定量指标和量子力学计算的支持。
### Conclusion
SGEquiDiff在处理晶体生成中的空间群约束方面具有显著优势，能够自动处理与空间群相关的几何约束，从而实现卓越的性能。相关代码可在指定链接中获取。
## 197. `cs.AI` - 思考过程中搜索和细化：促进增强检索推理的知识细化 [PDF](https://arxiv.org/pdf/2505.11277), [HTML](https://arxiv.org/abs/2505.11277)
### Authors
Yaorui Shi,Sihang Li,Chang Wu,Zhiyuan Liu,Junfeng Fang,Hengxing Cai,An Zhang,Xiang Wang
### Background
大语言模型已经展示了令人印象深刻的推理能力，但由于知识储备的限制，它们的推理能力也有限。检索增强推理可以通过让LLMs查询外部资源来缓解这一限制，但仍存在检索无关或噪音信息的问题，这妨碍了准确的推理。为了解决这个问题，我们提出了一种名为AutoRefine的强化学习后训练框架，采用了一种新的“搜索和细化在思考期间进行”的范式。AutoRefine在连续搜索调用之间引入了显式知识细化步骤，使模型能够在生成答案之前迭代地过滤、提炼和组织证据。此外，采用针对检索特定的奖励与正确答案奖励相结合的方法，使用了组相对策略优化（GRO）。
### Innovation
AutoRefine是一种采用“搜索和细化在思考期间进行”新范式的强化学习后训练框架。它在连续搜索调用之间引入了显式的知识细化步骤，使模型能够迭代地过滤、提炼和组织证据。此外，还结合了针对检索特定的奖励与正确答案奖励，使用了组相对策略优化（GRO）来改进检索增强推理。实验结果显示，AutoRefine在复杂、多跳推理场景中显著优于现有方法，显示出更频繁、更高质量的搜索和有效的证据综合能力。
### Conclusion
实验表明，AutoRefine在单跳和多跳问答基准测试中显著优于现有方法，特别是在复杂的多跳推理场景中。详细分析表明，AutoRefine能够频繁进行高质量的搜索，并能有效合成证据。此框架为改进检索增强推理提供了新的视角和方法。
## 198. `cs.AI` - 工作流中的公平性：大型科技公司中的机器学习从业者如何在推荐系统中实现公平性 [PDF](https://arxiv.org/pdf/2505.19441), [HTML](https://arxiv.org/abs/2505.19441)
### Authors
Jing Nathan Yan,Emma Harvey,Junxiong Wang,Jeffrey M. Rzeszotarski,Allison Koenecke
### Background
推荐系统（RS）在高风险领域中广泛应用，但存在偏见问题，可能导致大规模社会影响。尽管研究人员提出了测量和减轻这些偏见的方法，但在将学术理论转化为实际应用时存在挑战。RS从业者必须在包括提供商和用户在内的多种利益相关者之间进行权衡，并在动态环境中运作。本文通过半结构化访谈研究（N=11），探讨了大型科技公司在工作流中实现公平性的挑战，以及技术团队如何在与其他（法律、数据和公平）团队合作中考虑公平性。
### Innovation
本文通过半结构化访谈研究，揭示了大型科技公司中RS从业者在工作流中考虑公平性的挑战，并明确了在多利益相关者和动态公平考虑中的定义公平问题，提出了跨团队沟通和公平性工作时间安排的组织挑战，为进一步研究和实践提供了基于实际工作流的具体建议。
### Conclusion
本文为RS社区，包括人机交互研究员和从业者，提供了实用建议，旨在更好地将公平性融入现有的RS工作流程中。
## 199. `cs.AI` - AmpleHate: 强化注意以实现灵活的隐含仇恨言论检测 [PDF](https://arxiv.org/pdf/2505.19528), [HTML](https://arxiv.org/abs/2505.19528)
### Authors
Yejin Lee,Joonghyuk Hahn,Hyeseon Ahn,Yo-Sub Han
### Background
隐含仇恨言论的检测具有挑战性，因为它的微妙性以及依赖于上下文解释而非明确的冒犯词汇。当前的方法依赖对比学习，这些方法已被证明在区分仇恨言论和非仇恨言论方面是有效的。然而，人类通过首先识别文本中的具体目标，然后解释这些目标与周围上下文的关系来检测隐含的仇恨言论。受此推理过程的启发，我们提出了一种名为AmpleHate的新方法，该方法旨在模仿人类的推断过程来检测隐含的仇恨言论。
### Innovation
AmpleHate通过使用预训练的命名实体识别模型来识别显式目标，并通过[CLS]标记获取隐含目标信息。它计算显式、隐含目标与句子上下文之间的注意力依赖关系，并直接将这些关系向量注入最终的句子表示。这放大了目标-上下文关系的关键信号，从而有助于确定隐含仇恨言论。这种方法在实验中表现出优越的性能，优于对比学习基线，并且收敛速度更快。此外，质性分析表明，AmpleHate产生的注意模式与人类的判断一致，突显了其可解释性和鲁棒性。
### Conclusion
实验结果表明，AmpleHate在隐含仇恨言论检测方面达到了最先进的性能，平均优于对比学习基线82.14%，并且收敛速度更快。定性的分析进一步表明，AmpleHate产生的注意模式与人类的判断一致，突显了其可解释性和鲁棒性。相关代码已公开提供。
## 200. `cs.AI` - 使用交互式NeoMedSys平台检查VIOLA-AI颅内出血模型的部署与优化 [PDF](https://arxiv.org/pdf/2505.09380), [HTML](https://arxiv.org/abs/2505.09380)
### Authors
Qinghui Liu,Jon E. Nesvold,Hanna Raaum,Elakkyen Murugesu,Martin Røvang,Bradley J Maclntosh,Atle Bjørnerud,Karoline Skogen
### Background
临床部署AI工具在放射学领域面临着诸多挑战和机遇。本文介绍了一个名为NeoMedSys的放射学软件平台，该平台能够促进AI模型的部署和优化。本研究在挪威最大的急诊科（场址1）疑似创伤性脑损伤（TBI）患者和疑似中风患者（场址2）的临床病例中，评估了NeoMedSys在实际临床环境中运行三个月的可行性和有效性，重点在于改进一款内部开发的AI模型（VIOLA-AI）的颅内出血（ICH）检测表现。
### Innovation
NeoMedSys 集成了部署、测试和优化AI模型的工具，具有基于web的医学影像查看器、注释系统和医院范围的放射学信息系统。研究采用了前瞻性的实用研究设计，通过实时神经科医生反馈推动AI模型的迭代优化，显著提高了诊断准确性，特别是在颅内出血检测方面取得了显着进步。
### Conclusion
NeoMedSys平台促进了AI模型的迭代改进，显著提高了诊断准确性。自动出血检测和分割的实时审查促进了VIOLA-AI模型的重新训练。迭代优化过程使得分类灵敏度大幅提升至90.3%（从79.2%），并达到了89.3%的特异性（从80.7%）。整个样本的出血检测ROC分析显示了高曲线下面积（AUC）为0.949（从0.873）。模型的优化阶段与显著的性能改进密切相关，突显了实时放射科医生反馈的价值。
## 201. `cs.AI` - _GRE Suite：通过微调视觉语言模型和增强的推理链进行地理定位推理_ [PDF](https://arxiv.org/pdf/2505.18700), [HTML](https://arxiv.org/abs/2505.18700)
### Authors
Chun Wang,Xiaoran Pan,Zihao Pan,Haofan Wang,Yiren Song
### Background
近期视觉语言模型（VLMs）在视觉推理任务上表现出色，但地理定位任务提出了独特的挑战，需要从图像中提取多层次的视觉线索，并将这些线索与外部世界知识整合以进行系统性推理。现有的地理定位任务方法往往缺乏稳健的推理机制和解释性，从而限制了其有效性。
### Innovation
本文提出了一种名为Geo Reason Enhancement (GRE) Suite的创新框架，它通过结构化的推理链增强VLMs，以实现准确并可解释的地理位置推断。该框架从数据集、模型和基准三个方面系统开发：首先，引入了GRE30K，一种高质量的地理定位推理数据集，用于促进精细视觉和语境分析；其次，介绍GRE模型，该模型采用多阶段推理策略逐步推断场景属性、局部细节和语义特征，从而精确缩小可能的地理区域；最后，构建了Geo Reason Evaluation Benchmark (GREval-Bench)，一个综合评估框架，评估VLMs在多样化的城市、自然和地标场景中的粗略和精细地理位置性能。实验结果表明，GRE在所有地理定位任务的粒度上都显著优于现有方法，强调了推理增强的VLMs在复杂地理推断中的有效性。
### Conclusion
GRE Suite大幅提升了视觉语言模型在地理定位任务上的性能，证明了增强推理机制的VLMs在复杂地理推理中的高效性。
## 202. `cs.AI` - MUG-Eval: 任何语言的多语言生成能力的代理评估框架 [PDF](https://arxiv.org/pdf/2505.14395), [HTML](https://arxiv.org/abs/2505.14395)
### Authors
Seyoung Song,Seogyeong Jeong,Eunsu Kim,Jiho Jin,Dongkwan Kim,Jay Shin,Alice Oh
### Background
评估大规模语言模型（LLMs）的文本生成能力具有挑战性，尤其是对于资源不足的语言，直接评估方法匮乏。现有的评估方法通常依赖于特定语言的NLP工具或注释数据集，这些资源往往对大多数语言来说是有限的。此外，使用LLMs作为评估者的方法也存在局限性，因为其评价质量在外围资源不足的语言中会下降。
### Innovation
MUG-Eval是一个创新的框架，通过将现有的基准转换为对话任务来评估LLMs的多语言生成能力，并测量LLMs在这些任务上的准确率。这些对话任务特别设计为要求在目标语言中进行有效的沟通。我们使用任务成功率为生成成功的对话提供一种代理指标。该方法的优势在于它不依赖于特定语言的NLP工具或注释数据集，并且不依赖于LLMs作为评估者，后者在资源不足的语言中的评价质量会下降。
### Conclusion
我们评估了8个LLMs在30种语言上的生成能力（涵盖高资源、中资源和低资源的语言），发现在大多数情况下（相关系数>0.75），MUG-Eval与现有基准测试结果高度相关。我们的框架提供了一种对于多语言生成能力评估的稳健且资源高效的解决方案，并且能够扩展到数千种语言。
## 203. `cs.AI` - 大型语言模型在图数据挑战中的综述 [PDF](https://arxiv.org/pdf/2505.18475), [HTML](https://arxiv.org/abs/2505.18475)
### Authors
Mengran Li,Pengyu Zhang,Wenbin Xing,Yijia Zheng,Klim Zaporojets,Junzhou Chen,Ronghui Zhang,Yong Zhang,Siyuan Gong,Jia Hu,Xiaolei Ma,Zhiyuan Liu,Paul Groth,Marcel Worring
### Background
图是一种广泛用于表示非欧几里得数据的范式，在社会网络分析和生物分子预测等领域具有广泛应用。尽管图学习取得了显著进展，但现实世界的图数据存在很多挑战，这些挑战严重阻碍了学习过程。具体来说，现实中图数据存在不完整、分布不平衡、跨领域异质性和动态不稳定等问题，这四个问题分别表现为缺失节点、边或属性、标签分布偏斜、跨领域特征空间或结构模式不兼容以及随时间以不可预测的方式演变。近年来，大型语言模型（LLMs）提供了一种潜在的解决方案，通过利用丰富的语义推理和外部知识来应对这些问题。因此，该综述聚焦于LLMs如何解决图结构数据中的四个基本数据核心挑战，从而提高图学习的有效性。
### Innovation
本文综述了大型语言模型如何应对图结构数据中的四个基本数据核心挑战，包括不完整数据、分布不平衡、跨领域异质性和动态不稳定。特别的是，文章不仅回顾了传统的解决方案，还介绍了利用现代LLM驱动的新方法，并强调了LLMs的独特优势。该研究为解决这些挑战提供了一种新的视角，促进了跨学科领域的进一步探索。
### Conclusion
本文总结了大型语言模型在解决图数据挑战方面的现有研究，并讨论了该领域未来研究的问题和方向，还整理了一个关于图学习挑战的最新进展的资源库，以支持更深入的研究。
## 204. `cs.AI` - 景中聚焦：基于场景图的原子技能 [PDF](https://arxiv.org/pdf/2509.16053), [HTML](https://arxiv.org/abs/2509.16053)
### Authors
Han Qi,Changhe Chen,Heng Yang
### Background
通用型机器人一个关键需求是组合式泛化能力，即利用原子技能组合解决复杂的、长期任务。现有研究主要集中在合成一个规划器来序列化预学技能，但在场景组合导致的分布变化下，个体技能的稳健执行仍面临挑战，尤其是视觉-运动策略在面对分布变化时往往表现不佳。
### Innovation
引入了基于场景图的表示方法，强调任务相关的对象和关系，从而减轻对无关变异的敏感性。在此基础上，开发了一种结合图神经网络与扩散基础的模仿学习的场景图技能学习框架，并进一步结合了基于视觉语言模型（VLM）的任务规划器，以“聚焦”场景图技能。实验结果在模拟和真实世界操作任务中显著提高了成功率，展示了在长期任务中增强的鲁棒性和组合式泛化。
### Conclusion
该研究提出的方法提高了通用机器人应对场景组成变化时的鲁棒性和组合式泛化的性能，并在长期任务中表现优异。
## 205. `cs.AI` - 超越线性控制：统一的语言模型多属性控制 [PDF](https://arxiv.org/pdf/2505.24535), [HTML](https://arxiv.org/abs/2505.24535)
### Authors
Narmeen Oozeer,Luke Marks,Fazl Barez,Amirali Abdullah
### Background
在大型语言模型（LLMs）推理过程中同时控制多个行为属性是一项具有挑战性的问题，因为各种属性之间存在相互影响，同时线性控制方法的假设也不成立。线性控制方法依赖于激活空间中的加性行为假设，需要为每个属性单独调整向量参数，这种方法在控制多个行为属性时不够灵活，且需要重新训练模型以实现动态行为组合。
### Innovation
提出了一种名为K-Steering的新方法，这是一种统一且灵活的方法，通过训练一个非线性多标签分类器来利用隐藏层激活，并在推理过程中计算干预方向。这种方法避免了线性假设，不需要存储和调整单独的属性向量，且允许动态组合行为而无需重新训练。此外，还提出了两个新的基准测试，ToneBank和DebateMix，旨在实现组成性行为控制。实验结果表明，K-Steering在多个行为属性上表现出色，优于强大的基线方法。
### Conclusion
K-Steering方法不仅提供了准确多行为属性控制的能力，还保持了模型的灵活性和高效率，并且在多个基准测试中表现出显著的优势。
## 206. `cs.AI` - SEMMA: 具有语义意识的知识图谱基础模型 [PDF](https://arxiv.org/pdf/2505.20422), [HTML](https://arxiv.org/abs/2505.20422)
### Authors
Arvindh Arun,Sumit Kumar,Mojtaba Nayyeri,Bo Xiong,Ponnurangam Kumaraguru,Antonio Vergari,Steffen Staab
### Background
知识图基础模型（KGFMs）展示了通过学习可转移的模式进行零样本推理的潜力，特别是在处理未见过的图时。然而，现有的KGFMs大多仅仅依赖于图结构，忽略了文本属性中丰富的语义信号。大多数KGFMs专注于图结构，忽略了文本属性中的丰富语义信号，这在处理未见过的图时限制了模型的表现。
### Innovation
本文提出了SEMMA，这是一种双模块KGFMs，系统地融合了可转移的文本语义与结构信息。SEMMA利用大型语言模型增强关系标识符，生成语义嵌入，进而构建文本关系图，该图与结构部分融合。在54种不同的知识图谱中，SEMMA在完全归纳链接预测中优于仅基于结构的基线，如ULTRA。在更具挑战性的泛化场景中，测试时关系词汇表全部未见过时，结构方法失效，而SEMMA更有效，效果提高了一倍。研究结果表明，在结构单独失败的情况下，文本语义对泛化至关重要，并强调需要在知识推理中统一结构和语言信号的基础模型。
### Conclusion
研究发现文本语义对于泛化至关重要，特别是在仅仅依赖结构失败的情况下，突出需要在知识图推理中统一结构和语义信号的基础模型。SEMMA在融合文本语义和图结构方面展现出了显著的优势，特别是在泛化性能上超越了仅依靠结构的方法。
## 207. `cs.AI` - 跨注意力推测性解码 [PDF](https://arxiv.org/pdf/2505.24544), [HTML](https://arxiv.org/abs/2505.24544)
### Authors
Wei Zhong,Manasa Bharadwaj,Yixiao Wang,Nikhil Verma,Yipeng Ji,Chul Lee
### Background
推测性解码（SD）是加速大型语言模型（LLMs）推理的广泛应用方法，特别是在草稿和目标模型高度对齐的情况下。然而，最先进的SD方法通常依赖于紧密耦合的、基于自注意力的Transformer解码器，这些解码器经常增加了辅助聚合或融合层。这种耦合使得它们变得越来越复杂，并且更难以在不同的模型之间进行泛化。当前的技术瓶颈在于实现高效率的同时保持模型的简单性和训练效率。
### Innovation
本研究提出了Budget EAGLE（Beagle），这是一种基于跨注意力的Transformer解码器SD模型，它在与最先进的基于自注意力的SD模型（如EAGLE-v2）性能相当的情况下，消除了对聚合或辅助组件的需求，简化了架构，提高了训练效率，并在训练时间模拟中保持了稳定的内存使用。为此，作者提出了一种名为Two-Stage Block-Attention Training的新方法，有效地解决了块级注意场景中的训练稳定性和收敛效率问题。在多个LLMs和数据集上的实验结果表明，Beagle不仅提供了与EAGLE-v2相当的推理加速效果，而且具有更高的训练效率，提供了一种理想的推测性解码架构选择。
### Conclusion
Beagle在性能与简洁性之间找到了良好的平衡，是一种非常有前景的推测性解码模型。通过使用跨注意力机制，它简化了模型架构，并提高了训练效率，是当前宽吻鲸（EAGLE-v2）的一种强有力替代选择。
## 208. `cs.AI` - Perception-R1: 通过视觉感知奖励提升MLLMs的多模态推理能力 [PDF](https://arxiv.org/pdf/2506.07218), [HTML](https://arxiv.org/abs/2506.07218)
### Authors
Tong Xiao,Xin Xu,Zhenya Huang,Hongyu Gao,Quan Liu,Qi Liu,Enhong Chen
### Background
增强多模态大规模语言模型（MLLMs）的多模态推理能力是颇具挑战性的问题，并且引起了研究社区的广泛关注。近期，一些研究将可验证奖励的强化学习（RLVR）应用于多模态领域，以提升MLLMs的推理能力。但是，现有研究大都忽视了提升MLLMs的多模态感知能力，这是复杂多模态推理的核心先决条件和基础组成部分。通过McNemar检验发现，现有RLVR方法未能有效提升MLLMs的多模态感知能力，从而限制了其进一步的多模态推理改善。
### Innovation
本文提出了Perception-R1，它引入了一种新的视觉感知奖励，明确鼓励MLLMs准确感知视觉内容，从而可以有效激励它们的多模态感知和推理能力。具体来说，我们首先从多模态问题的CoT轨迹中收集文本视觉注释，作为奖励分配中的视觉参考。在RLVR训练过程中，我们使用一个评判LLM来评估MLLM生成的答案与视觉注释之间的一致性，并基于这些一致性判断分配视觉感知奖励。
### Conclusion
大规模实验表明，Perception-R1在多个多模态推理基准上表现出色，仅使用1,442训练数据就能达到最先进的性能。
## 209. `cs.AI` - 通过噪声实现噪声鲁棒性：具有攻击专家的非对称LoRA调整 [PDF](https://arxiv.org/pdf/2505.23868), [HTML](https://arxiv.org/abs/2505.23868)
### Authors
Zhaokun Wang,Jinyu Guo,Jingwen Pu,Lingfeng Chen,Hongli Pu,Jie Ou,Libo Qin,Wenhong Tian
### Background
当前，参数高效的微调方法在适配预训练语言模型到下游任务时容易受到嘈杂数据的干扰。传统的噪声处理方法要么依赖繁琐的数据预处理，要么使用容易导致错误积累的模型架构修改。本文分析了现有噪声处理方法的局限性，并提出了一个新的噪声鲁棒调整方法——非对称LoRA中毒专家（LoPE）框架。该框架通过生成的嘈杂数据增强模型的噪声鲁棒性，而不需要进行数据清洗。该框架借鉴了混合专家架构，通过一个两阶段方法，在微调过程中向攻击专家注入噪声，以增强其噪声辨识和处理能力。
### Innovation
提议了一种新颖的方法LoPE（Asymmetric LoRA Poisoning Experts），该方法通过生成的噪声数据增强模型的噪声鲁棒性，而不需要进行数据清洗。该方法不同于现有的噪声处理方式，不要求数据预处理或模型架构修改，并采用混合专家架构来增强模型对噪声的鲁棒性。通过两个阶段的方法，在微调过程中注入噪声，增强攻击专家的噪声分辨和处理能力，从而在推理阶段利用正常专家获得的净化知识来增强噪声鲁棒性输出。
### Conclusion
广泛实验表明，通过低成本的噪声注入，LoPE方法在性能和鲁棒性方面表现出色，完全消除了对数据清洗的需求。
## 210. `cs.AI` - 在语言适应持续预训练中大型语言模型的新兴能力 [PDF](https://arxiv.org/pdf/2506.00288), [HTML](https://arxiv.org/abs/2506.00288)
### Authors
Ahmed Elhady,Eneko Agirre,Mikel Artetxe
### Background
持续预训练（CPT）是一种流行的方法，用于将现有的大型语言模型（LLMs）适应新语言。通常的做法是在混合数据中包含一部分英语数据，但这对其作用的研究并不充分。本文通过分析发现，包括英语数据并不会影响验证困惑度，但对目标语言下游能力的出现至关重要。引入了一个通用的基准衡量内在学习（ICL）的表现，结果显示，在CPT早期未包含英语数据时会出现灾难性遗忘，这导致了模型在处理目标语言下游提示时的一般泛化能力受损，即使这种受损不会在准确性上立即显现，而是随着训练的进行逐渐表现出来，并且可以与模型参数的大规模变化相关联。
### Innovation
本文介绍了一个语言无关的基准来衡量内在学习（ICL），揭示了CPT早期未包含英语数据时的灾难性遗忘问题，以及通过过程中模型参数的大规模变化与目标语言下游能力表现之间的联系。还提出了一种课程学习方法和权重的指数移动平均（EMA）作为有效的替代方法，以减少对英语数据的依赖，从而减轻语言适应过程中出现的负面影响
### Conclusion
本文揭示了通过CPT实现语言适应时新兴能力的动态机制，并将其作为未来更有效方法设计的基础。
## 211. `cs.AI` - 使用PRISM捕获多义性：一个多概念特征描述框架 [PDF](https://arxiv.org/pdf/2506.15538), [HTML](https://arxiv.org/abs/2506.15538)
### Authors
Laura Kopf,Nils Feldhus,Kirill Bykov,Philine Lou Bommer,Anna Hedström,Marina M.-C. Höhne,Oliver Eberle
### Background
当前自动化的神经网络特征描述方法在大规模语言模型（LLMs）的自然语言处理（NLP）领域存在两个主要挑战：鲁棒性有限以及假定每个神经元只编码一个概念（单义性），这限制了特征描述的表达能力并限制了它们捕捉模型内部所有行为的能力。随着多义性证据的增加，这种方法的假设变得不再适用。
### Innovation
介绍了Polysemantic FeatuRe Identification and Scoring Method (PRISM)，这是一种专为捕获LLMs中特征复杂性的新型框架。与许多NLP中的自动化解释方法不同，PRISM产生更细致的描述，可以同时考虑单义性和多义性行为。
### Conclusion
我们对LLMs应用了PRISM，并通过与现有方法的广泛基准测试表明，我们的方法提供了更准确、更真实的特征描述，增强了描述的整体质量（通过描述得分）并提高了在存在多义性时捕捉不同概念的能力（通过多义性得分）。
## 212. `cs.AI` - 基于视频的空间理解：结构化提示与仿真数据的结合 [PDF](https://arxiv.org/pdf/2506.03642), [HTML](https://arxiv.org/abs/2506.03642)
### Authors
Haoyu Zhang,Meng Liu,Zaijing Li,Haokun Wen,Weili Guan,Yaowei Wang,Liqiang Nie
### Background
视觉-空间理解是机器人导航和实体交互等一系列任务的基础。目前的方法面临空间不确定性以及数据稀缺的问题，限制了预训练的视觉-语言模型（VLMs）的3D空间推理能力。现有技术难以有效处理复杂场景中的问题以及难以从有限的数据中学习到广泛的3D空间推理能力。因此，需要一种新的方法来增强VLMs的3D空间推理能力，而不修改现有模型结构。
### Innovation
提出了一个统一框架来增强预训练VLMs的3D空间推理能力，该框架结合使用了SpatialMind（一种结构化的提示策略，将复杂场景和问题分解成可解释的推理步骤）和ScanForgeQA（一种通过自动化构建过程从多种3D模拟场景中生成的问题-答案数据集，适用于微调）。通过多种基准测试，证明了提示和微调策略的有效性，并提供了对未来研究的洞见。
### Conclusion
该研究展示了如何通过结合结构化提示和仿真数据来有效增强VLMs的3D空间推理能力，该方法在多个基准测试中表现出优异的性能。研究结果可能为未来的空间理解研究提供灵感。
## 213. `cs.AI` - LLMs can compensate for deficiencies in visual representations [PDF](https://arxiv.org/pdf/2506.05439), [HTML](https://arxiv.org/abs/2506.05439)
### Authors
Sho Takishita,Jay Gala,Abdelrahman Mohamed,Kentaro Inui,Yova Kementchedjhieva
### Background
许多视觉-语言模型(VLMs)在多模态任务中表现出色，但它们通常基于具备多种局限性的CLIP视觉编码器构建。研究者推测，这些模型中的强语言骨干可以靠上下文化或丰富视觉特征来弥补潜在的视觉特征不足。
### Innovation
通过在三个基于CLIP的VLMs上进行精心设计的自我注意消融测试，研究揭示了尽管存在已知局限性，CLIP视觉表示仍然可以为语言解码器提供现成的语义信息。然而，在视觉表示去上下文化的情景下，语言解码器能够大量补偿不足并恢复性能。这一发现暗示了VLMs中的动态分工，并激发了将更多视觉处理任务卸载到语言解码器上的未来架构。
### Conclusion
这项研究表明，语言模型能够补偿视觉表示中的不足，并指出VLMs中的动态分工。这一发现激励了未来可以更加依赖语言解码器进行更多视觉处理的模型架构。
## 214. `cs.AI` - 算法公平性：不只是技术和但社会和技术属性 [PDF](https://arxiv.org/pdf/2506.12556), [HTML](https://arxiv.org/abs/2506.12556)
### Authors
Yijun Bian,Lei You,Yuya Sasaki,Haruka Maeda,Akira Igarashi
### Background
随着人工智能（AI）和机器学习（ML）系统在社会上具有重大影响的领域的快速部署，人们对它们的信任度及其可能的歧视性行为产生了越来越多的关注。算法公平性的研究产生了大量的数学定义和指标，但内部和外部的持续误解和局限性限制了它们的效果，如对算法公平性的理解未达成共识、现有的指标主要针对二元群体设置、对交叉情境处理过于表面化等。这一背景揭示了现有的算法公平性的局限性，及其在实际复杂场景中的不足，并指出了与公平性相关性的观点，强调技术约束之外的社会和技术属性的重要性。
### Innovation
本文批评现有的算法公平性定义和指标的局限性，并指出算法公平性不能单纯归结为对模型的技术限制，而是需要结合社会属性。通过概念分析和实证说明，挑战了准确性和公平性之间以及公平性指标之间的不可调和性观点，并提出了设计公平性指标的三项值得考虑的原则。这些发现有助于弥合技术形式化和社会现实之间的差距，并应对实际部署中的挑战。
### Conclusion
本文研究表明，算法公平性仅仅依靠技术约束是不够的，需要结合社会属性；通过概念分析和实证说明，提出了三项设计公平性指标的原则，共同推进算法公平性研究的发展。
## 215. `cs.AI` - VLA-Mark：大型视觉语言对齐模型的跨模态水印 [PDF](https://arxiv.org/pdf/2507.14067), [HTML](https://arxiv.org/abs/2507.14067)
### Authors
Shuliang Liu,Qi Zheng,Jesse Jiaxi Xu,Yibo Yan,Junyan Zhang,He Geng,Aiwei Liu,Peijie Jiang,Jia Liu,Yik-Cheung Tam,Xuming Hu
### Background
视觉-语言模型需要具备知识产权保护的水印解决方案，同时不损害跨模态的一致性。现有文本水印方法通过有偏的标记选择和静态策略扰乱视觉-文本对齐，使具有语义关键性概念易受到损害。现有的水印方法多通过影响视觉-文本对齐来破坏知识产权保护，而且大多数方法不能很好地平衡水印强度和语义一致性。
### Innovation
提出了一种名为VLA-Mark的视觉对齐框架，通过跨模态协调嵌入可检测的水印同时保持语义准确性。这种方法结合多尺度视觉-文本对齐度量，包括局部斑块亲和力、全局语义一致性以及上下文注意模式，引导水印插入，无需重新训练模型。引入了敏感熵机制来动态平衡水印强度和语义保存，优先进行视觉定位在不确定性较低的生成阶段。
### Conclusion
实验表明，与传统方法相比，VLA-Mark在PPL上低7.4%，在BLEU上高26.6%，且几乎完美的检测性能（AUC 98.8%）。该框架对诸如重新表述和同义词替换等攻击具有96.1%的攻击韧性，同时依然保持了文本-视觉一致性，引领了新标准的高质量跨模态水印方法。
## 216. `cs.AI` - 在现实世界中使用自然语言进行人机协作 [PDF](https://arxiv.org/pdf/2508.11759), [HTML](https://arxiv.org/abs/2508.11759)
### Authors
Peter Lindes,Kaoutar Skiker
### Background
本文的背景是设想未来的自主机器人能够与人类合作执行复杂任务。传统的交互式任务学习（ITL）系统虽然有这项能力，但其理解能力非常有限。大规模语言模型（LLMs）的出现为提高机器人语言理解能力提供了机会，但将这些能力集成到现实世界的物理机器人中是一个具有挑战性的问题。文章回顾了有关机器人产品的现有情况，并讨论了如何改进它们的语言能力，以便更好地作为协作伙伴。
### Innovation
本文的创新点在于探讨了如何利用具有认知代理的AI系统控制物理机器人，并通过其交互经验积累情境知识，探讨了一种可能实现人机协作愿景的方法。文章重点关注机器人理解和处理自然语言的三个具体挑战，并使用ChatGPT等简单的实验展示了初步的实验结果。
### Conclusion
文章最后指出了实现具有自然语言理解的集成机器人助手所需的条件，认为要将这些简单的实验转变为能够与人类协作的可操作系统，必须解决一系列技术挑战。
## 217. `cs.AI` - AS-ASR: 专门为失语症自动语音识别的轻量级框架 [PDF](https://arxiv.org/pdf/2506.06566), [HTML](https://arxiv.org/abs/2506.06566)
### Authors
Chen Bao,Chuanbing Huo,Qinyu Chen,Chang Gao
### Background
本文提出了AS-ASR，一种基于Whisper-tiny并针对边缘设备低资源部署的轻量级失语症特定语音识别框架。该框架通过结合标准语音和失语症语音进行混合训练，旨在改善失语症语音识别的鲁棒性能，并通过GPT-4进行参考增强方法，以提高监督质量。
### Innovation
本文的创新之处在于引入了一种结合标准和失语症语音的混合训练策略，以实现失语症语音识别的稳健泛化。此外，还提出了一种基于GPT-4的参考增强方法，用于细化失语症语音转录，从而提高监督质量。
### Conclusion
实验结果表明，经过微调的模型显著优于零样本基线，使失语症语音的词错误率（WER）降低了超过30%，同时保持了标准语音识别性能。AS-ASR框架提供了一种适用于实际失序语音识别的可扩展且高效的解决方案。
## 218. `cs.AI` - 使用梯度依存痕迹的深度强化学习 [PDF](https://arxiv.org/pdf/2507.09087), [HTML](https://arxiv.org/abs/2507.09087)
### Authors
Esraa Elelimy,Brett Daley,Andrew Patterson,Marlos C. Machado,Adam White,Martha White
### Background
在深度强化学习（RL）中实现快速且稳定的离策略学习颇具挑战。现有的大多数方法依赖于简单的半梯度时差（TD）方法，虽然方便且高效，但容易出现发散问题。即使更符合原理的方法如渐近梯度TD（GTD）具有较强的收敛保证，但它们在深度RL中应用较少。近期研究引入了泛化投影贝尔曼误差（$bar{text{PBE}}$）来促进GTD方法在非线性函数逼近中的高效应用，但由于仅限于单步方法，导致信用分配速度慢且需要大量样本。
### Innovation
本文将泛化$bar{text{PBE}}$目标扩展到支持基于$boldsymbol{text{λ-返回}}$的多步信用分配，并推导出三种梯度优化的新方法。本文提供了与经验回放兼容的前向视图形式和与流计算算法兼容的后向视图形式。实验结果表明，所提出的算法在MuJoCo和MinAtar环境中分别优于PPO和StreamQ。
### Conclusion
本文提出的算法在MuJoCo和MinAtar环境中分别优于PPO和StreamQ，在MuJoCo和MinAtar环境中实现了更高的性能，展现了泛化$bar{text{PBE}}$目标应用于多步方法的有效性。
## 219. `cs.AI` - DualEdit: 双模态编辑在视觉-语言模型知识更新中的应用 [PDF](https://arxiv.org/pdf/2506.13638), [HTML](https://arxiv.org/abs/2506.13638)
### Authors
Zhiyi Shi,Binjie Wang,Chongjie Si,Yichen Wu,Junsik Kim,Hanspeter Pfister
### Background
当前的模型编辑方法旨在高效地更新预训练模型的知识，而不需要进行长时间的重新训练。现有的方法取得了一定的效果，但主要集中在单一模态的语言模型上。然而，对于涉及多个模态的视觉-语言模型（VLM），每种模态在编辑性能中的作用和影响仍然不明确。因此，本文研究了文本和视觉模态对模型编辑的影响，并发现：(1) 文本和视觉表示在不同的层中达到峰值敏感性，反映了它们的重要性不同；(2) 同时编辑这两种模态可以有效地更新知识，但这会牺牲模型的原始功能。因此，基于这些发现，本文提出了DualEdit编辑器，在关键层同时修改文本和视觉模态。还引入了在更敏感的文本模态中的门控模块，使得DualEdit可以高效地更新新知识同时保留模型的原始信息。
### Innovation
本文提出了DualEdit，这是一个同时修改文本和视觉模态的编辑器，并在关键层进行修改，还引入了门控模块来在提高编辑效率的同时保护原始信息。此外，还验证了DualEdit在多种VLM骨干网络和基准数据集上的效果，表现出优于现有最先进的VLM编辑基准和适应后的语言模型编辑方法的效果。
### Conclusion
DualEdit方法在更新VLM知识的同时，通过双模态编辑提高了效率并能保留模型原始功能。实验结果显示，这种方法在多个评估指标上优于现有方法。
## 220. `cs.AI` - OptiScene: LLM驱动的室内场景布局生成通过规模化的正确对齐数据合成与多阶段偏好优化 [PDF](https://arxiv.org/pdf/2506.07570), [HTML](https://arxiv.org/abs/2506.07570)
### Authors
Yixuan Yang,Zhen Luo,Tongsheng Ding,Junru Lu,Mingqi Gao,Jinyu Yang,Victor Sanchez,Feng Zheng
### Background
自动室内布局生成因其在室内设计、虚拟环境建设和具身人工智能等方面的应用潜力而引起了越来越多的关注。现有方法主要分为两类：依赖特定LLM服务的提示驱动方法（如GPT API）和基于扩散模型的布局数据训练的基于学习的方法。提示驱动的方法通常存在空间不一致性和高昂的计算成本问题，而基于学习的方法则受限于粗糙的关系图和有限的数据集，限制了其对不同房间类型的泛化能力。
### Innovation
本文重新审视了基于LLM的室内布局生成，并提出了一种大规模的3D-SynthPlace数据集，该数据集通过'GPT合成，人工检查'的工作流程生成，从3D-Front数据集中升级而来，包含近17,000个场景，涵盖四种常见的房间类型——卧室、客厅、厨房和浴室，丰富了各种物体和高层次的空间标注。此外，本文还介绍了OptiScene，这是一种强大的开源LLM，专门针对室内布局生成进行了优化，并通过我们的3D-SynthPlace数据集进行了两阶段训练。第一阶段采用监督微调（SFT），首先生成高层次的空间描述，然后有条件地预测具体的物体布局。第二阶段应用了多轮直接偏好优化（DPO），更好地使生成的布局与人类的设计偏好相一致，显著提高了布局质量和生成成功率。
### Conclusion
广泛的实验证明，OptiScene在与传统的提示驱动和基于学习的基线相比中表现更优。此外，OptiScene在场景编辑和机器人导航等交互任务中也显示出了有希望的潜力。
## 221. `cs.AI` - 大语言和多模态模型中的离散扩散：综述 [PDF](https://arxiv.org/pdf/2506.13759), [HTML](https://arxiv.org/abs/2506.13759)
### Authors
Runpeng Yu,Qi Li,Xinchao Wang
### Background
本文提供了一种系统性的离散扩散语言模型（dLLMs）和离散扩散多模态语言模型（dMLLMs）的调查。与自回归（AR）模型不同，dLLMs 和 dMLLMs 使用全注意力和去噪生成策略进行并行解码。这种模式自然地实现了并行生成、细粒度输出控制和动态感知。这些能力在以前对于AR模型是难以实现的。许多开源和专有的 d(M)LLMs 已经显示出可与自回归模型相比的性能，同时在推理速度方面实现了高达 10 倍的加速。这些发展将离散扩散模型定位为基于传统自回归方法的人工智能的有前途的替代方案
### Innovation
dLLMs 和 dMLLMs 采用了与自回归模型不同的多令牌、并行解码范式，基于全关注和去噪生成策略。这种模式能够实现并行生成、细粒度输出控制和动态感知。这些功能以前很难通过自回归模型实现。大量的开源和专有的 d(M)LLMs 和 dMLLMs 已经显示出与自回归模型相当甚至更好的性能，同时也实现了高达 10 倍的推理速度加速
### Conclusion
本文对 dLLM 和 dMLLM 领域的研究进行了全面概述。我们追溯了 dLLMs 和 dMLLMs 的历史发展，正式化了其底层数学框架，列举了常用建模方法，并按照代表性模型进行了分类。我们进一步分析了训练、推理和量化的关键技术。此外，我们讨论了可信赖问题，并总结了跨语言、视觉-语言和生物领域的新兴应用。最后，我们讨论了未来的研究和部署方向
## 222. `cs.AI` - CORE-RAG: 通过强化学习实现Retrieval-Augmented LLMs的无损压缩 [PDF](https://arxiv.org/pdf/2508.19282), [HTML](https://arxiv.org/abs/2508.19282)
### Authors
Ziqiang Cui,Yunpeng Weng,Xing Tang,Peiyang Liu,Shiwei Li,Bowei He,Jiamin Chen,Yansen Zhang,Xiuqiang He,Chen Ma
### Background
Retrieval-Augmented Generation (RAG)能显著提高大型语言模型的知识时效性和答案准确性。然而，检索出的过多文档会显著增加输入长度，从而提高计算成本。尽管前人尝试在上下文集成前将检索到的文档压缩成更短的文本，但这些方法往往牺牲了最终任务的表现。缺乏明确的压缩目标迫使很多方法依赖固定启发式方法，这种方法无法确保压缩的内容能够有效支持最终任务。
### Innovation
我们提出了CORE，一种基于强化学习的新方法，用于实现RAG的无损上下文压缩。CORE不依赖于预定义的压缩标签，通过优化压缩过程生成能够最大化LLM生成答案准确性的摘要。广泛实验在四个数据集上展示了我们方法的优越性。压缩比达到3%，该方法不仅避免了与其他全文档预置相比的性能下降，还平均提高了3.3个精确匹配（EM）分数。
### Conclusion
我们的实验表明，与附加完整文档的方法相比，该方法不仅没有性能下降，还能提升平均精确匹配分数3.3个百分点。未来，代码将被公开发布。
## 223. `cs.AI` - 可变形动态卷积在网络准确且高效的时空交通预测中的应用 [PDF](https://arxiv.org/pdf/2507.11550), [HTML](https://arxiv.org/abs/2507.11550)
### Authors
Hyeonseok Jin,Geonmin Kim,Kyungbaek Kim
### Background
交通预测是智能交通系统的关键组成部分，能够实现诸如缓解拥堵和预测事故风险等应用。近年来的研究探索了基于图和基于网格的方法，但两者都存在局限性。基于图的方法能够有效捕捉非欧几里得空间结构，但常常伴随着高计算开销，限制了在大规模系统中的实用性。相比之下，基于网格的方法主要利用卷积神经网络（CNN），虽然计算效率较高，但很难建模不规则的空间模式，因为它们的滤波器具有固定的形状。此外，这两种方法往往未能考虑到固有的时空异质性，因为它们通常在多样化的地区和时间周期中使用共享的参数集。这些挑战促使本文提出了一种创新的卷积神经网络（CNN）架构，即可变形动态卷积网络（DDCN），该架构结合了可变形和动态卷积操作。
### Innovation
本研究提出了 DDConv，该可变形动态卷积网络是一种基于 CNN 的创新性架构，结合了可变形和动态卷积操作。其中，可变形层引入了可学习的偏移量，以创建更具弹性的感受野，更好地与不规则的空间结构对齐。动态层则生成区域特定的滤波器，使得模型能够适应不同的时空交通模式。通过将这两个组件结合，DDCN 有效地捕捉了非欧几里得空间结构和时空异质性。
### Conclusion
在四个实际交通数据集上的广泛实验表明，DDCN 在预测性能上达到了竞争力的水平，同时显著降低了计算成本，证明了其在大规模和实时部署中的潜力。
## 224. `cs.AI` - RegionMed-CLIP: 一种适用于医学影像理解的区域感知多模态对比学习预训练模型 [PDF](https://arxiv.org/pdf/2508.05244), [HTML](https://arxiv.org/abs/2508.05244)
### Authors
Tianchen Fang,Guiru Liu
### Background
医学影像理解在自动化诊断和数据驱动的临床决策支持中起着关键作用。但由于高质量标注医学数据的稀缺性以及对全局影像特征的过度依赖，使得医学影像理解的进步受到阻碍。这些全局特征往往忽略了一些重要的但细微的病理区域，从而影响了诊断准确性。
### Innovation
为了应对这些挑战，文章引入了RegionMed-CLIP，这是一种区域感知的多模态对比学习框架，它明确地结合了局部病理信号与整体语义表示。文章的核心是一个创新的区域兴趣（ROI）处理器，它可以自适应地将细微的区域特征与全局上下文相结合，在此基础上采用渐进式的训练策略提高多层次多模态对齐。为了支持大规模区域级表示学习，文章构建了MedRegion-500k，这是一个包含广泛区域注释和多级临床描述的医疗图像-文本语料库。在此基础上，文章在图像-文本检索、零样本分类和视觉问答等任务上的实验表明，RegionMed-CLIP 系统在各种基准测试中表现出了明显优于现有视觉语言模型的广泛性能差异。
### Conclusion
我们的研究结果强调了区域感知对比预训练的重要性，并将RegionMed-CLIP作为推动多模态医学影像理解发展的坚实基础。
## 225. `cs.AI` - 使用潜在扩散模型生成移动三维声景 [PDF](https://arxiv.org/pdf/2507.07318), [HTML](https://arxiv.org/abs/2507.07318)
### Authors
Christian Templin,Yanda Zhu,Hao Wang
### Background
空间音频已成为VR/AR、影院和音乐等沉浸式应用的核心。现有的生成音频模型主要局限于单声道或立体声格式，无法捕捉一阶布西明克（FOA）音频中可用的完整三维定位线索。虽然最近的FOA模型扩展了文本到音频的生成，但仍然局限于静止声源。
### Innovation
本文提出了SonicMotion，这是一种端到端的潜在扩散框架，能够生成含有动态声源控制的FOA音频。SonicMotion有两种变体：1) 基于自然语言提示的描述性模型，2) 同时基于文本和空间轨迹参数的参数模型，可实现更高的精度。此外，为了支持训练和评估，作者构建了一个包含超过一百万对模拟FOA标题配对的新数据集，其中包括静态和动态声源的注释方位、仰角和运动属性。
### Conclusion
实验表明，SonicMotion在语义对齐和感知质量方面达到了最先进的水平，且在空间定位误差上表现出较低的误差，可与领先的文本到音频系统相媲美。
## 226. `cs.AI` - Causal2Vec: 提升仅解码器大语言模型作为多功能嵌入模型的性能 [PDF](https://arxiv.org/pdf/2507.23386), [HTML](https://arxiv.org/abs/2507.23386)
### Authors
Ailiang Lin,Zhuoyun Li,Kotaro Funakoshi,Manabu Okumura
### Background
解码器仅有的大语言模型（LLMs）广泛用于构建能将自然语言文本的语义信息有效地编码到密集向量表示中的嵌入模型，适用于各种嵌入任务。现有方法主要通过移除因果注意力掩码来实现双向注意力，这可能会削弱模型从预训练中提取语义信息的能力。此外，领先的单向方法通常依赖额外的输入文本来克服因果注意力的固有局限，从而增加了计算成本。
### Innovation
本文提出了一种名为Causal2Vec的一般用途嵌入模型，旨在增强仅解码器LLMs的性能，而不改变其原始架构或引入显著的计算开销。首先，利用轻量级的BERT风格模型预先编码输入文本为一个上下文化令牌，该令牌被附加到LLM的输入序列中，使得每个 token 能够捕获上下文信息，即便没有注意到未来的token。此外，为了缓解由于最后一个token池化引入的近期偏差，并帮助LLMs更好地利用上下文化令牌中编码的语义信息，将上下文化令牌和EOS令牌的最后隐藏状态进行连接，作为最终的文本嵌入。实践表明，Causal2Vec在仅根据公开的检索数据集训练的模型中，在大规模文本嵌入基准（MTEB）上实现了最优性能，同时减少了所需序列长度多达85%，并降低了推理时间82%.
### Conclusion
Causal2Vec通过一种简单而有效的方法，改善了仅解码器LLMs作为多功能嵌入模型的性能，无需更改其原结构，并有效减少了计算开销和延迟时间，从而提供了高效的解决方案。
## 227. `cs.AI` - OpenWHO：低资源语言健康翻译中的文档级平行语料库 [PDF](https://arxiv.org/pdf/2508.16048), [HTML](https://arxiv.org/abs/2508.16048)
### Authors
Raphaël Merx,Hanna Suominen,Trevor Cohn,Ekaterina Vylomova
### Background
机器翻译（MT）在健康领域具有高度重要性，该领域广泛应用且包含专业领域的词汇。然而，针对低资源语言的MT评估数据集在这一领域存在不足。本文介绍了OpenWHO，这是一个来自世界卫生组织e-learning平台的2,978份文档和26,824个句子的文档级平行语料库，该语料库包含超20种语言，其中9种是低资源语言。
### Innovation
引入了OpenWHO数据集，这是一个专用于低资源语言健康翻译的高质量文档级平行语料库。利用这一新资源，对比了现代大型语言模型（LLMs）和传统MT模型的性能。研究发现LLMs在低资源语料上的表现优于传统MT模型，尤其在健康等专业化领域，展示了文档级翻译的好处更为明显。
### Conclusion
研究结果表明LLMs在低资源健康翻译中表现更佳，并且详细分析了LLM利用上下文信息对翻译准确度的影响。OpenWHO语料库已公开，鼓励进一步在低资源MT健康领域中的研究。
## 228. `cs.AI` - 主观行为与偏好在大语言模型中的表现：浏览语言 [PDF](https://arxiv.org/pdf/2508.15474), [HTML](https://arxiv.org/abs/2508.15474)
### Authors
Sai Sundaresan,Harshita Chopra,Atanu R. Sinha,Koustava Goswami,Nagasai Saketh Naidu,Raghav Karan,N Anushka
### Background
大语言模型（LLM）被认为能够在多个领域和任务上提供灵活性，从而为具有广泛行为和偏好的用户提供便利。然而，当用户具有固有的主观行为和偏好时，这种模型的有效性受到挑战。例如，用户的网页或应用程序浏览行为是个性化和非结构化的，类似于一种自我构建的语言，但却没有自然语言所具有的结构和语法规则。本文探讨了小型LM和大型LM在表示浏览语言方面的差异，并探讨是否可以通过单一模型捕捉用户的多样化和主观行为。
### Innovation
本文提出了一种针对主观行为的集群化LM训练方法，即HeTLM（混合异质训练的语言模型），这种方法能够更好地表示用户的浏览语言。研究发现，小模型通过对页面级别的数据进行训练，能够优于大型预训练或微调的模型；使用单一参数设置的HeTLM比单一参数设置的模型有更好的表现；更重要的是，生成的平均性能较高，变异性低，表明用户级别的对齐效果更好。
### Conclusion
小型LM可以通过针对页面级别的训练超越大型模型；通过Heterogeneity aware Training of Language Model（HeTLM）方法训练的模型可以更好地捕捉用户的多样性和主观行为；单一高平均性能和低性能波动的LM可以提高用户级别的对齐效果。
## 229. `cs.AI` - PVPO: 基于预估价值的策略优化方法用于代理推理 [PDF](https://arxiv.org/pdf/2508.21104), [HTML](https://arxiv.org/abs/2508.21104)
### Authors
Wenfeng Feng,Penghong Zhao,Guochao Jiang,Chuzhan Hao,Yuewei Zhang,Guohua Liu,Hao Wang
### Background
信使自由的强化学习方法，特别是群体策略，因其在复杂任务中的高效性而受到关注。然而，这些方法依赖于在策略内部进行多次采样和比较来估算优势值，这可能导致策略陷入局部最优，并增加计算成本。
### Innovation
提出了一种增强的优势参考锚和数据超前采样的有效强化学习方法PVPO。具体来说，使用参考模型超前展开，并采用计算出的奖励分数作为参考锚。这种方法有效地矫正由群体内部比较引入的累积偏差，并显著减少了训练过程中对采样次数的依赖。同时，参考模型可以在数据预采样过程中评估样本难度，从而有效选择高收益的数据以提高训练效率。此外，PVPO与其它先进的信使自由RL算法互不干扰，可与其他方法兼容并互补。在两个领域的九个数据集中进行的实验表明，PVPO实现了最佳性能。该方法不仅展示了在多个任务上的鲁棒泛化能力，而且在不同规模的模型上具有可扩展的性能表现。
### Conclusion
实验结果表明，PVPO在处理代理推理任务时实现了最先进的性能，并展现出广泛的泛化能力和可扩展性。
## 230. `cs.AI` - LongCat-Flash 技术报告 [PDF](https://arxiv.org/pdf/2509.01322), [HTML](https://arxiv.org/abs/2509.01322)
### Authors
Meituan LongCat Team,Bayan,Bei Li,Bingye Lei,Bo Wang,Bolin Rong,Chao Wang,Chao Zhang,Chen Gao,Chen Zhang,Cheng Sun,Chengcheng Han,Chenguang Xi,Chi Zhang,Chong Peng,Chuan Qin,Chuyu Zhang,Cong Chen,Congkui Wang,Dan Ma,Daoru Pan,Defei Bu,Dengchang Zhao,Deyang Kong,Dishan Liu,Feiye Huo,Fengcun Li,Fubao Zhang,Gan Dong,Gang Liu,Gang Xu,Ge Li,Guoqiang Tan,Guoyuan Lin,Haihang Jing,Haomin Fu,Haonan Yan,Haoxing Wen,Haozhe Zhao,Hong Liu,Hongmei Shi,Hongyan Hao,Hongyin Tang,Huantian Lv,Hui Su,Jiacheng Li,Jiahao Liu,Jiahuan Li,Jiajun Yang,Jiaming Wang,Jian Yang,Jianchao Tan,Jiaqi Sun,Jiaqi Zhang,Jiawei Fu,Jiawei Yang,Jiaxi Hu,Jiayu Qin,Jingang Wang,Jiyuan He,Jun Kuang,Junhui Mei,Kai Liang,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Liang Gao,Liang Shi,Lianhui Ma,Lin Qiu,Lingbin Kong,Lingtong Si,Linkun Lyu,Linsen Guo,Liqi Yang,Lizhi Yan,Mai Xia,Man Gao,Manyuan Zhang,Meng Zhou,Mengxia Shen,Mingxiang Tuo,Mingyang Zhu,Peiguang Li,Peng Pei,Peng Zhao,Pengcheng Jia,Pingwei Sun,Qi Gu,Qianyun Li,Qingyuan Li,Qiong Huang,Qiyuan Duan,Ran Meng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shizhe Wu,Shuai Liang
### Background
随着模型规模不断扩大，对计算效率的需求日益提高，特别是在保持模型性能的前提下优化资源利用成为研究的重点。
### Innovation
提出了LongCat-Flash，一种5600亿参数的Mixture-of-Experts（MoE）语言模型，采用两种创新设计：(a) 零计算Experts，通过动态分配计算预算适应上下文需求，提升资源利用效率；(b) 简单连接MoE，扩大计算-通信窗口，显著提高推理效率和吞吐量。还开发了一套全面的大型模型缩放框架，结合超参数迁移、模型生长初始化、多管齐下的稳定性套件和确定性计算，以实现稳定和可重复的训练。
### Conclusion
 LongCat-Flash在优化计算效率的同时，通过大规模预训练和任务导向的微调，取得了卓越的代理任务性能。模型开源，以促进社区研究，其在其他领航模型中表现出高度竞争力，并在代理任务上表现出色。
## 231. `cs.AI` - Riemannian Batch Normalization: A Gyro Approach [PDF](https://arxiv.org/pdf/2509.07115), [HTML](https://arxiv.org/abs/2509.07115)
### Authors
Ziheng Chen,Xiao-Jun Wu,Bernhard Schölkopf,Nicu Sebe
### Background
本文背景在于现有的深度学习中常用的归一化层在处理非欧几里得数据时效果不佳，因为它们基于欧式空间的规范形式。而很多在机器学习中存在的黎曼流形可以引入罗德运动框架，这为将欧式神经网络拓展到非欧式域提供了可能。
### Innovation
本文的创新之处为提出了GyroBN，这是一种基于罗德群的黎曼批归一化框架，它通过两个必要条件（伪降低和罗德等距旋动）确保了样本统计的理论控制，并且这些条件适用于所有已知的机器学习中的罗德群。此外，该框架将多个现有黎曼归一化方法作为特例进行包含。
### Conclusion
在不同几何结构中进行的实验表明了GyroBN的有效性。该框架还实现了七个代表性的几何结构，并推导出新颖的罗德结构和黎曼结构以支持这些实现。代码已提供。
## 232. `cs.AI` - MedCOD: 利用丰富链式字典框架增强大型语言模型的英语到西班牙语医学翻译 [PDF](https://arxiv.org/pdf/2509.00934), [HTML](https://arxiv.org/abs/2509.00934)
### Authors
Md Shahidul Salim,Lian Fu,Arav Adikesh Ramakrishnan,Zonghai Yao,Hong Yu
### Background
该研究旨在通过结合专业领域知识来改进英文到西班牙文的医学翻译，特别是针对大型语言模型（LLMs）。研究构建了一个由2,999篇英西语言医学文章组成的平行语料库，并且通过结构化提示和微调，提高翻译质量。研究还验证了使用MedCOD框架对LLMs进行专业化的提示和微调可以显著提高翻译效果。
### Innovation
提出了一种名为MedCOD的跨界框架，该框架将领域特定结构化知识整合进大型语言模型，通过结合统一医学语言系统（UMLS）和LLM作为知识库（LLM-KB）方法，改进结构化提示和微调。利用多语言变体、医学同义词以及来自UMLS的定义，结合LoRA基线微调，评估了四种开源LLM。结果显示，MedCOD大幅提高了各类模型的翻译质量。其证明了结构化知识整合对增强LLMs医学翻译任务的潜力。
### Conclusion
研究表明，MedCOD框架通过结构化提示和模型适应显著提高了翻译质量，特别是在使用LLaMA-3.1-8B等模型时。通过分离和分析MedCOD提示方法和模型适应方法，发现了各自独立的性能提升效果，以及它们组合时产生的最佳改进效果。这些发现表明，结构化知识的整合能够有效提升LLMs在医学翻译任务中的性能。
## 233. `cs.AI` - 结构重要：通过可学习边屏蔽进行脑图增强以实现高效的精神心理诊断 [PDF](https://arxiv.org/pdf/2509.09744), [HTML](https://arxiv.org/abs/2509.09744)
### Authors
Mujie Liu,Chenze Wang,Liping Chen,Nguyen Linh Dan Le,Niharika Tewari,Ting Dang,Jiangang Ma,Feng Xia
### Background
现有的精神疾病诊断面临标注脑网络数据有限的挑战，导致难以实现准确且可解释的诊断。虽然自监督学习（SSL）提供了可能的解决方案，但现有方法往往依赖于可能破坏脑图关键结构语义的增强策略。
### Innovation
该文提出了SAM-BG，一种两阶段框架，旨在学习保留结构语义的脑图表示。在预训练阶段，使用边掩码器处理小的标注子集以捕捉关键的结构语义。在SSL阶段，提取的结构先验指导结构感知的增强过程，使模型能够学习更具语义意义和鲁棒性的表示。
### Conclusion
在两个实际的精神疾病数据集上的实验表明，SAM-BG 在标注数据量有限的场景下比最先进的方法表现更优，能够发现与临床相关的连接模式，从而增强可解释性。相关代码可在[此处]找到。
## 234. `cs.AI` - 检索增强语言模型知道自己不知道的时候吗？ [PDF](https://arxiv.org/pdf/2509.01476), [HTML](https://arxiv.org/abs/2509.01476)
### Authors
Youchao Zhou,Heyan Huang,Yicheng Liu,Rui Dai,Xinglin Wang,Xingchen Zhang,Shumin Shi,Yang Deng
### Background
现有的大型语言模型（LLMs）有时会生成虽看似合理但实际上是错误的答案，这被称为幻觉。研究人员主要采用两种方法来减少幻觉，即检索增强语言模型（RALMs）和后训练拒绝（refusal post-training）。然而，当前的研究主要集中在它们各自的有效性上，而忽略了对RALMs拒绝能力的评估。本文旨在探讨这些模型在面对不知道的知识时的行为和表现。文章提出了三个核心问题，即模型内部和外部知识状态的校准情况、后训练拒绝方法对过拒绝问题的影响，以及拒绝能力与答案质量之间的冲突。
### Innovation
本文的研究成果包括发现了LLMs存在显著的过度拒绝行为，通过对比引入上下文微调和R调优的方法，发现上下文微调可以缓解过拒绝问题，但R调优则使问题更加严重。此外，本文提出了一种简单有效的后训练拒绝方法，以提升模型的整体答案质量。研究还提供了一个更全面的理解，即关键因素对RALM系统的影响。
### Conclusion
本文通过系统地评价RALMs的拒绝能力，揭示了它们在面对不确定知识时的行为模式和问题，并提出了优化建议。研究表明，虽然过度拒绝是一个需要解决的问题，但适当的方法可以在不影响答案质量的前提下有效减少这种现象，同时开发的方法为后续研究和个人应用提供了新的思路。
## 235. `cs.AI` - MIDOG 2025: 通过注意力引导的假阳性修正进行有丝分裂图像检测 [PDF](https://arxiv.org/pdf/2509.02598), [HTML](https://arxiv.org/abs/2509.02598)
### Authors
Andrew Broad,Jason Keighley,Lucy Godson,Alex Wright
### Background
现有的完全卷积单阶段物体检测器（FCOS）在有丝分裂图像检测中存在较高的假阳性率，影响检测准确性和网络的通用性。本文基于现有技术，提出了一种新的方法来降低假阳性率，从而提高检测准确性并增强模型的通用性。
### Innovation
开发了一种复合模型，该模型引入了一种反馈注意力梯形卷积神经网络（FAL-CNN），用于正常和异常有丝分裂图像的分类，并将其与FCOS预测的边界框进行融合，优化调整预测结果。这种方法旨在通过修正FCOS的错误预测，提高有丝分裂检测的准确性。
### Conclusion
该模型在初步评估数据集上的有丝分裂检测F1分数达到了0.655，表明该方法能够有效地降低假阳性率，提高检测准确性和模型的通用性。
## 236. `cs.AI` - SWE-Effi: 在资源约束下重新评估软件AI代理系统的有效性 [PDF](https://arxiv.org/pdf/2509.09853), [HTML](https://arxiv.org/abs/2509.09853)
### Authors
Zhiyu Fan,Kirill Vasilevski,Dayi Lin,Boyuan Chen,Yihao Chen,Zhiqing Zhong,Jie M. Zhang,Pinjia He,Ahmed E. Hassan
### Background
大语言模型（LLMs）和代码代理的发展显示了在软件工程（SWE）任务中，如自主问题解决和功能添加方面的重要潜力。现有的软件工程领域AI领导者榜单（如SWE-bench）仅关注解决方案的准确性，忽视了在资源受限环境中的有效性。这不仅在软件工程任务中存在，在其他任何AI系统中也都是一个普遍问题。AI系统不仅要准确，还要具有成本效益。
### Innovation
该研究引入了SWE-Effi，提出了一套新的多维度指标来重新评估AI系统的整体有效性得分，将结果准确性和资源消耗之间的平衡作为评估标准。通过使用SWE-Effi重新评估了SWE-bench基准中部分流行AI系统在问题解决中的表现，发现了算法有效性不仅依赖于底层模型本身，还取决于其与基础模型的整合程度，并识别了“令牌雪球效应”和“昂贵失败”等系统性挑战，特别是在强化学习中对快速响应的依赖。
### Conclusion
在资源预算和时间预算下的有效性之间存在权衡，这对于有效管理项目预算并促进可扩展的强化学习至关重要。在资源高效的方式下实现强性能对于实际部署至关重要，并且能够减少在RL训练中失败部署的成本。
## 237. `cs.AI` - DischargeSim: 一个在出院教育医生-患者沟通中的模拟基准测试 [PDF](https://arxiv.org/pdf/2509.07188), [HTML](https://arxiv.org/abs/2509.07188)
### Authors
Zonghai Yao,Michael Sun,Won Seok Jang,Sunjae Kwon,Soie Kwon,Hong Yu
### Background
出院沟通是患者护理中一个关键但尚未充分探索的部分，其目标从诊断转向教育。尽管最近的大规模语言模型（LLM）基准测试强调了诊疗期间的诊断推理，但它们未能评估模型在诊疗结束后支持患者的能力。DischargeSim提供了一种新的基准测试，用于评估LLM在扮演个性化出院教育者的角色上的能力。这项基准测试通过模拟诊疗后的多轮对话来评估由LLM驱动的医生代理和拥有不同心理社会特征（如健康素养、教育水平和情绪）的患者代理之间的交互。与广泛的诊疗后主题结构化，通过自动和LLM作为评委的对话质量评估、个性化的文件生成（包括自由文本摘要和结构化的AHRQ检查表），以及下游的选择题考试来评估患者的理解能力。
### Innovation
DischargeSim的创新之处在于它首次针对LLM进行了出院教育的基准测试，跨越了六个临床相关的话题，解决了现有基准测试在诊疗后支持患者方面的不足。这项基准测试还引入了多轴评估方法，包括对话质量评估、个性化文档生成和患者理解度评估。此外，该基准测试揭示了模型大小与教育成果之间的非线性关系，强调了策略选择和内容优先级之间的权衡。
### Conclusion
DischargeSim为评估LLM在诊疗后临床教育中的表现提供了一种方法。它为促进公平和个性化的患者支持迈出第一步。实验结果表明，模型大小并不总是带来更好的教育结果，突显了策略使用和内容优先级之间的权衡。该基准测试提供了一种关键视角，有助于改进LLM在支持出院患者方面的表现。
## 238. `cs.AI` - LLM-BasedagensicSystemsthemSecurityofToolInvocationPrompts:AnEmpiricalRiskAssessment [PDF](https://arxiv.org/pdf/2509.05755), [HTML](https://arxiv.org/abs/2509.05755)
### Authors
Yuchong Xie,Mingyu Luo,Zesen Liu,Zhixiang Zhang,Kaikai Zhang,Yu Liu,Zongjie Li,Ping Chen,Shuai Wang,Dongdong She
### Background
LLM-based agentic systems利用大型语言模型来处理用户查询、做出决策并执行外部工具以应对跨领域的复杂任务，如聊天机器人、客户服务和软件工程。这些系统中的关键组件是工具调用提示（TIP），它定义了工具交互协议并引导LLM，以确保工具使用的安全性和正确性。尽管TIP在这些系统中的重要性不言而喻，但其安全性却鲜少被重视。
### Innovation
该研究通过系统地探索工具调用提示（TIP）的威胁，发现知名的LLM基础代理系统如Cursor和Claude Code等存在远程代码执行（RCE）和拒绝服务（DoS）等攻击风险。通过一套标准化的TIP利用流程（TEW），作者证明了通过操纵工具调用来劫持外部工具行为。研究还提出了增强LLM基础代理系统中TIP安全性的防御机制。
### Conclusion
研究展示了对LLM基础代理系统中的TIP安全性的批判性评估，揭示了这些系统面临的安全威胁，并提出了相应的防御措施以提升TIP的安全性。
## 239. `cs.AI` - TGPO: 通过树引导的偏好优化提升稳健的网页代理强化学习 [PDF](https://arxiv.org/pdf/2509.14172), [HTML](https://arxiv.org/abs/2509.14172)
### Authors
Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao
### Background
随着大型语言模型和视觉-语言模型的迅猛发展，使用大型模型作为Web代理进行自动化网页交互变得至关重要。然而，利用强化学习训练Web代理面临诸如奖励分配不当、注释成本高昂和奖励稀疏等重大挑战。
### Innovation
提出了一种名为Tree-Guided Preference Optimization (TGPO)的离线强化学习框架，该框架通过树木结构轨迹表示消除了标签冲突，融合了语义上相同的跨轨迹状态。它还包括一个过程奖励模型，自动通过子目标进度、冗余检测和动作验证生成细粒度奖励。此外，一种动态权重机制在训练期间优先处理高影响决策点。
### Conclusion
实验结果表明，TGPO显著优于现有方法，在C-WebShop和Online-Mind2Web数据集上实现了更高的成功率和更少的冗余步骤。
## 240. `cs.AI` - MapAnything:通用端到端元距3D重建 [PDF](https://arxiv.org/pdf/2509.13414), [HTML](https://arxiv.org/abs/2509.13414)
### Authors
Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder
### Background
本文介绍了一种名为MapAnything的统一Transformer架构前馈模型，它可以接受一个或多个图像以及可选的几何输入（如相机内参、姿态、深度或部分重建），然后直接回归出度量3D场景几何和相机参数。该模型通过多视图场景几何的因子表示（包括深度图、局部射线图、相机姿态和度量尺度因子）将局部重构升级为全局一致的度量框架，从而实现多样的3D视觉任务，如未标定的结构从运动、标定的多视图立体构建、单目深度估计、相机定位、深度完成等。
### Innovation
MapAnything采用了一种统一的Transformer架构，能够处理从多个角度捕捉到的场景信息，并直接进行度量3D场景几何和相机参数的回归。模型通过对不同数据集的标准化监督和训练，以及灵活的输入增强，使得能够解决广泛的3D视觉任务，并且在联合训练行为上更为高效，是一种端到端的整体解决方案。
### Conclusion
通过广泛的实验分析和模型消融研究，MapAnything展示了其在各项任务上的优越性能，不仅能够匹配专业的前馈模型，还在联合训练行为上表现出更高效的行为，为通用3D重建奠定了基础。
## 241. `cs.AI` - 在安全协议框架下增强物联网音频分类设备安全的威胁建模 [PDF](https://arxiv.org/pdf/2509.14657), [HTML](https://arxiv.org/abs/2509.14657)
### Authors
Sergio Benlloch-Lopez,Miquel Viel-Vazquez,Javier Naranjo-Alcazar,Jordi Grau-Haro,Pedro Zuccarello
### Background
随着具备麦克风并能在边缘设备上执行音频分类的物联网节点的迅速增加，这些设备在资源受限的情况下依然处理高敏感数据，从而暴露了潜在的安全风险。为了应对这一挑战，本文提出了一个多层防御体系结构，通过对边缘设备、蜂窝网络和云后端这三个不同的信任域进行保护，以及使用基于TPM的远程验证和互认证的TLS 1.3协议来保障安全。
### Innovation
本文创新地提出了一种多层次防御架构，包括一个基于安全协议的防护体系，通过TPM进行远程验证，并与TLS 1.3结合使用。设计过程采用了STRIDE威胁模型和攻击树分析来指导安全策略。此外，本文提出了一系列措施来增强设备的安全性，包括采用TLS 1.3进行数据传输加密、通过Kyber和Dilithium提供抗量子攻击的弹性、端到端的加密以及使用带有抗回滚保护的签名AI模型和响应式传感器来加固固件和硬件，最终提出一个数据存储策略来增强静止数据的安全性。
### Conclusion
本文提出的方法为物联网音频分类设备的安全保障提供了一个全面的解决方案，并建立了评估物理和逻辑安全性的计划。
## 242. `cs.AI` - Empathy-R1: 一种用于长格式心理支持的链式共情和强化学习框架 [PDF](https://arxiv.org/pdf/2509.14851), [HTML](https://arxiv.org/abs/2509.14851)
### Authors
Xianrong Yao,Dong She,Chenxu Zhang,Yimeng Zhang,Yueru Sun,Noman Ahmed,Yang Gao,Zhanpeng Jin
### Background
共情对于有效心理支持至关重要，特别是在处理长文本咨询时。现有的大型语言模型（LLMs）虽然在语义流利性上表现良好，但在具备真正心理支持所需的结构化推理方面仍存在不足，特别是在中文语境下。因此，需要一种新的方法来解决这一问题。
### Innovation
本文提出了一种创新的 Empathy-R1 框架，该框架结合了链式共情（CoE）推理过程和强化学习（RL），以增强对长文本咨询的响应质量。该框架由一个新的大规模中文数据集 Empathy-QA 和两阶段训练过程支持：首先通过有监督微调（Supervised Fine-Tuning）内化 CoE 的推理结构，然后通过 RL 和专用奖励模型优化最终响应的治疗相关性和上下文适宜性。
### Conclusion
Empathy-R1 在关键自动指标上表现优异，并且通过人工评估也展示了其优越性，超过了强大基线，并在新基准上达到了44.30%的 Win@1 率。通过生成可解释且上下文丰富的回应，Empathy-R1 代表了在心理支持方面开发负责任和真正有益的AI的重要进步。
## 243. `cs.AI` - LLM生成文本的风格变异基准 [PDF](https://arxiv.org/pdf/2509.10179), [HTML](https://arxiv.org/abs/2509.10179)
### Authors
Jiří Milička,Anna Marklová,Václav Cvrček
### Background
该研究探讨了人类撰写的文本与相应的大规模语言模型（LLMs）生成的文本之间的登记变异。使用Biber的多维度分析（MDA）对两类文本进行对比，以发现LLMs与人类撰写的文本在语言形式上的显著且系统性差异。为了确保分析的可对比性，研究使用了一个新的LLM生成语料库AI-Brown，以及一个与之可比的现代英国英语语料库BE-21。此外，还进行了类似分析，对捷克语进行了研究，并将AI-Koditex语料库及捷克语多维度模型进行对比，以填补除英语之外的语言在前沿LLMs训练数据中的不足。这项研究考虑了16种不同的前沿模型，并重点关注基本模型和指令调优模型之间的差异。
### Innovation
研究采用Biber的多维度分析方法，对人类撰写的文本与LLMs生成的文本进行了对比分析，揭示了语言形式差异的关键维度。研究特别引入了AI-Brown语料库进行实验，并复制了这种分析方法应用于捷克语，填补了现有研究在语言多样性方面的空白。
### Conclusion
研究创建了一个基准，通过该基准可以比较和排名不同模型在可解释维度上的表现。同时，研究强调了基本模型与指令调优模型之间的差异，并为进一步理解和优化LLMs提供了理论基础。
## 244. `cs.AI` - 硬度、结构性知识和机会：模块化性能建模的分析框架 [PDF](https://arxiv.org/pdf/2509.11000), [HTML](https://arxiv.org/abs/2509.11000)
### Authors
Omid Gheibi,Christian Kästner,Pooyan Jamshidi
### Background
性能影响模型对于理解配置如何影响系统性能是有益的，但创建这些模型具有挑战性，因为配置空间呈指数增长。虽然灰色盒子方法利用部分结构性知识（如系统执行模块图）来改进建模，但结构性知识、系统特性（我们称之为“结构性方面”）与潜在建模改进之间的关系尚不明确。本文通过正式研究结构性方面（例如模块和每个模块选项的数量）的变化及其结构性知识水平对“改进模块化性能建模机会”的影响，填补了这一空白。研究引入并量化了“建模难度”的概念，定义为性能建模的固有难度，并通过合成系统模型的受控实验构建了测量这些概念的“分析矩阵”。研究结果表明，建模难度主要由模块数量和每个模块的配置选项数量驱动。更重要的是，本文表明，更高的结构性知识水平和增强的建模难度对改进机会都有显著影响。这些因素对性能指标的影响各不相同：例如，在调试任务中，结构性知识占主导地位，而在资源管理任务中，建模难度发挥更大作用。这些结果为系统设计师提供了可操作的见解，指导他们在系统特性和给定任务目标的基础上，战略性地分配时间和选择适当的建模方法。
### Innovation
本文通过正式研究结构性方面（例如模块数量和每个模块的选项数）、结构性知识水平及其对建模难度和改进机会的影响，填补了灰色盒子方法中相关信息的空白。研究引入了一个新的概念——“建模难度”，并构建了一个衡量这些概念的“分析矩阵”。研究发现，结构性知识和建模难度对不同性能指标的影响不同，从而为系统设计师提供了选择适当建模方法的指导。
### Conclusion
本文通过分析矩阵揭示了结构性方面、结构性知识水平和建模难度对模块化性能建模机会的影响。模型难度主要由模块数量和每个模块的选项数目驱动，且更高的结构性知识和建模难度对改进机会有显著提升作用。不同性能指标受结构性知识和建模难度的影响程度不同，这为系统设计师提供了更有针对性的战略建议。
## 245. `cs.AI` - AToken：统一的视觉标记器 [PDF](https://arxiv.org/pdf/2509.14476), [HTML](https://arxiv.org/abs/2509.14476)
### Authors
Jiasen Lu,Liangchen Song,Mingze Xu,Byeongjoo Ahn,Yanjun Wang,Chen Chen,Afshin Dehghan,Yinfei Yang
### Background
现有的视觉标记器在单一模态下只能专注于重建或语义理解，无法实现跨图像、视频和3D资产的统一标记。这些标记器通常不能同时实现高保真重建和语义理解，且无法支持不同分辨率和时间跨度的视觉输入。本文的研究背景在于开发一种能够同时处理和理解多模态视觉数据的统一标记系统，以满足当前复合型人工智能系统的需要.
### Innovation
AToken 是首个同时实现高保真重建和语义理解的统一视觉标记器。它通过一个四维旋转位置嵌入的纯 Transformer 架构，统一处理不同分辨率和时间跨度的视觉输入。此外，它还通过一种无对抗训练目标结合感知和 Gram 矩阵损失实现了卓越的重建质量，且通过渐进式的训练课程逐步扩展支持单个图像、视频和3D内容的不同模态和连续及离散的隐变量。其性能在多个基准测试中的表现也令人满意，涵盖了从视觉生成任务到理解任务的应用范围，展示了统一标记在多模态AI系统中的潜力.
### Conclusion
通过使用 AToken，多模态 AI 系统可以更好地理解和生成不同的视觉内容。该方法通过统一的标记系统实现了图像、视频和3D数据的高效处理，并在多个下游应用中展示了竞争力的表现。这是朝向构建下一代多模态AI系统的一步重要进展。
## 246. `cs.AI` - LORA RF指纹识别中的水印和异常检测机器学习模型 [PDF](https://arxiv.org/pdf/2509.15170), [HTML](https://arxiv.org/abs/2509.15170)
### Authors
Aarushi Mahajan,Wayne Burleson
### Background
无线设备的射频指纹识别（RFFI）通过其模拟电路中的小差异来识别设备，从而避免了重荷的加密认证。尽管深度学习在光谱图上提高了准确性，但模型仍易受到复制、篡改和逃避的风险。
### Innovation
提出了结合水印验证所有权和异常检测以识别可疑输入的更强RFFI系统。使用ResNet-34在对数梅尔光谱图上嵌入三种水印：简单的触发器、对抗训练的触发器对噪声和过滤具有鲁棒性以及隐藏的梯度/权重签名。通过具有Kullback-Leibler（KL）预热和自由比特标志的卷积变分自编码器（VAE）对离分布查询进行检测。在LoRa数据集上，该系统实现了94.6%的准确性、98%的水印成功率和0.94的AUROC。
### Conclusion
该系统提供了可验证、防篡改的认证。
## 247. `cs.CL` - 合成自助预训练 [PDF](https://arxiv.org/pdf/2509.15248), [HTML](https://arxiv.org/abs/2509.15248)
### Authors
Zitong Yang,Aonan Zhang,Hong Liu,Tatsunori Hashimoto,Emmanuel Candès,Chong Wang,Ruoming Pang
### Background
在标准预训练过程中，语言模型主要学习单一文档内部词与词之间因果相关的规律，但没有专门针对文档之间丰富且可学习的关联性进行建模，这可能会影响模型的整体表现。
### Innovation
Introduces Synthetic Bootstrapped Pretraining (SBP) 方法，首先学习预训练数据集中文档之间关系的模型，然后利用该模型生成大量新的合成文本，作为联合训练的补充。这种方法打破了标准预训练方法对内部文本关联性的建模局限，通过生成新的文本内容更加全面地训练模型。
### Conclusion
实验证实了SBP的有效性，在没有更多独特数据的情况下，可显著提升模型性能。合成的文档不仅限于简单的同义词替换，而是能够从种子材料中抽象出核心概念，并构建新的叙述。此外，SBP具有自然的贝叶斯解释，合成器隐式学习了相关文档之间的潜在概念。
## 248. `cs.AI` - MeanFlowSE：通过条件平均流实现一步生成语音增强 [PDF](https://arxiv.org/pdf/2509.14858), [HTML](https://arxiv.org/abs/2509.14858)
### Authors
Duojia Li,Shenghui Lu,Hongchen Pan,Zongyi Zhan,Qingyang Hong,Lin Li
### Background
实时生成语音增强受到多步推理的限制，因为基于流动和扩散的系统学习瞬时速度场，需要依赖迭代的常微分方程（ODE）求解器。这使得实时处理困难且计算成本高。为了克服这个问题，作者提出了一个新颖的方法来改进这一过程。
### Innovation
作者提出了一个名为MeanFlowSE的条件生成模型，它通过学习有限区间上的平均速度沿轨迹。通过使用雅可比-向量乘积（JVP）实现MeanFlow恒等式，作者得出了一个用于直接监督有限区间位移的局部训练目标，而这个目标依然符合对角瞬时场约束。这种模型在推理时可以以逆时间的步骤生成，避免使用多步骤求解器，同时提供了一个高效的、高保真度的实时生成语音增强框架
### Conclusion
MeanFlowSE单步模型在VoiceBank-DEMAND数据集上表现出很强的可懂度、保真度和感知质量，其计算成本远低于多步基线。此方法无需知识蒸馏或外部教师，为即时生成语音增强提供了一种有效的解决方案。该方法已经开源。
## 249. `cs.CL` - 低资源语言藏语的分词算法比较分析 [PDF](https://arxiv.org/pdf/2509.15255), [HTML](https://arxiv.org/abs/2509.15255)
### Authors
Tandin Wangchuk,Tad Gonsalves
### Background
大型语言模型（LLMs）正在变得流行并且迅速提升。分词器是自然语言处理中关键的组件，特别是在LLMs中。分词器将输入文本分解为模型可以容易处理的分词单元，同时确保文本被准确表示，捕捉其意义和结构。有效的分词器可以提升LLMs的能力，通过改善模型对上下文和语义的理解，最终在诸如翻译、分类、情感分析和文本生成等下游任务中提供更好的表现。大多数预训练分词器适用于高资源语言如英语，但对于低资源语言效果不佳。藏语是不丹的官方语言，使用者约为70万人，是一种低资源语言，并且其语言复杂性带来了独特的NLP挑战。尽管取得了一些进展，但在藏语NLP研究中，尤其是在分词方面，仍然缺乏大量的研究工作。
### Innovation
本研究评估了三种常用分词算法——BPE、WordPiece和SentencePiece（未出局表）在藏语中的适用性，并与其他流行方法进行了比较。评估性能的指标包括子词语生育率、持续词的比例、序列长度的标准化以及执行时间。结果显示，虽然三种算法都表现出一定的潜力，但SentencePiece对于藏语分词是最有效的，这为进一步的NLP进展铺平了道路，强调了为低资源语言开发定制方法的必要性。
### Conclusion
本研究提出了三种藏语分词算法，为进一步构建藏语大型语言模型铺平了道路。
## 250. `cs.AI` - 大规模多智能体强化学习中的易受攻击智能体识别 [PDF](https://arxiv.org/pdf/2509.15103), [HTML](https://arxiv.org/abs/2509.15103)
### Authors
Simin Li,Zheng Yuwei,Zihao Mao,Linhao Wang,Ruixiao Xu,Chengdong Ma,Xin Yu,Yuqing Ma,Qi Dou,Xin Wang,Jie Luo,Bo An,Yaodong Yang,Weifeng Lv,Xianglong Liu
### Background
随着系统规模的扩大，部分代理失败变得不可避免，识别那些对整体性能影响最大的代理变得至关重要。本文研究了在大规模多智能体强化学习（MARL）中的易受攻击智能体识别（VAI）问题，其中上层解决NP-hard组合任务，选择最易受攻击的代理，底层则使用均场MARL学习这些代理的最坏情况对抗策略。这两个问题相互耦合，使得该过程难以直接求解。
### Innovation
文中提出了层次化对抗的均场控制（HAD-MFC）框架，使用Fenchel-Rockafellar变换去耦层级过程，得到一个对于上层问题的正则化均场贝尔曼算子，从而实现了不同层级上的独立学习，降低了计算复杂度。此外，通过将上层的组合问题转化为具有密集奖励的MDP问题，可以按顺序通过贪婪和RL算法识别最易受攻击的代理，且该分解方法能得到原始HAD-MFC问题的最优解。该方法在实验中表现出有效性，能够识别更多的易受攻击代理，使基于规则的系统表现出更糟糕的故障，并学习到揭示每个代理脆弱性的价值函数。
### Conclusion
本文提出的方法有效解决了大规模MARL中的VAI问题，通过去耦层级过程和转换为MDP问题，能够按顺序识别最脆弱的代理，学习到代理的脆弱性，并提高了对系统潜在缺点的洞察力。
## 251. `cs.AI` - 基于资源受限设备的卷积神经网络音频标注模型全面评估 [PDF](https://arxiv.org/pdf/2509.14049), [HTML](https://arxiv.org/abs/2509.14049)
### Authors
Jordi Grau-Haro,Ruben Ribes-Serrano,Javier Naranjo-Alcazar,Marta Garcia-Ballesteros,Pedro Zuccarello
### Background
卷积神经网络（CNNs）在音频标注任务中展示了出色的表现。然而，将这些模型部署在资源有限的设备（如Raspberry Pi）上面临计算效率和散热管理方面的挑战。
### Innovation
首次全面评估了包括1D和2D模型在内的多种CNN架构在Raspberry Pi上的音频标注性能，涵盖了PANNs框架中的CNN模型、基于ConvNeXt的音频分类模型以及MobileNetV3架构，同时探索了将所有模型转换为Open Neural Network Exchange (ONNX)格式以提高部署效率和跨平台的可移植性。此外，实验通过24小时连续推理会话来评估性能稳定性。
### Conclusion
适当选择和优化模型后，可以在长时间内保持一致的推理延迟并有效管理热行为。这些发现为实际边缘计算环境中部署音频标注模型提供了宝贵参考。
## 252. `cs.CL` - 真实、伪造还是操纵？检测机器影响的文本 [PDF](https://arxiv.org/pdf/2509.15350), [HTML](https://arxiv.org/abs/2509.15350)
### Authors
Yitong Wang,Zhongping Zhang,Margherita Piana,Zheng Zhou,Peter Gerstoft,Bryan A. Plummer
### Background
大语言模型（LLMs）能够撰写或修改文档，这带来了理解其使用意图的挑战。例如，良性使用可能涉及使用LLM改进人类撰写的文档的语法或对其进行翻译。然而，由完全由LLM生成的文档更容易被用于传播错误信息，而不仅仅是简单的翻译。先前有关机器生成文本（MGT）检测的研究主要集中在识别文档是由人类还是机器撰写，忽略了这类复杂的细微用途。
### Innovation
本文提出了一种名为HERO的HiErarchical、长度鲁棒的机器影响文本检测器，能够学习区分不同长度的文本样本并将其分为四大类：人类撰写、机器生成、机器润色和机器翻译。HERO通过结合长度专家模型的预测实现这一目标，这些模型通过子类别指导进行训练。特别地，对于容易混淆的类别（如不同源语言），HERO的子类别指导模块鼓励细颗粒度类别的分离，从而提升性能。在五种LLM和六个领域的广泛实验中，HERO表现出色，平均高出当前最佳方法2.5-3个mAP。
### Conclusion
HERO在机器影响文本检测方面表现出色，通过细粒度的分类策略显著提升了检测性能，特别是在高度混淆的类别上。
## 253. `cs.AI` - Middo：通过闭环学习增强LLM微调的模型感知动态数据优化 [PDF](https://arxiv.org/pdf/2508.21589), [HTML](https://arxiv.org/abs/2508.21589)
### Authors
Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu
### Background
监督微调（SFT）大型语言模型（LLM）需要高质量的训练数据。现有的数据选择和数据合成方法通常在静态数据集管理方面存在局限，无法适应模型能力的演变。
### Innovation
Middo是一种自适应模型感知动态数据优化框架，它利用模型感知的数据选择和语义保留的数据精炼。Middo引入了一个自我参考的诊断模块，可以主动通过三种轴向的模型信号识别次优样本，并且具有动态进化的特点。此外，它还包含一个自适应优化引擎，用于将次优样本转换为教学价值高的训练点，同时保持语义完整性。该框架通过动态学习原则不断进化优化过程。
### Conclusion
实验证实在多种基准上，Middo持续提高了种子数据的质量并提升了LLM的性能，平均精度提高了7.15%，且保持了原始数据集的规模。这项工作证明了通过数据和模型的人工智能共进化建立可持续LLM训练的新范式。我们的数据集、模型和代码将在不久后发布，并通过此链接公开：this https URL.
## 254. `cs.CL` - 毒性红队测试：在新加坡低资源语言中的LLM安全性基准测试 [PDF](https://arxiv.org/pdf/2509.15260), [HTML](https://arxiv.org/abs/2509.15260)
### Authors
Yujia Hu,Ming Shan Hee,Preslav Nakov,Roy Ka-Wei Lee
### Background
大型语言模型（LLMs）的进步已经改变了自然语言处理领域，尽管它们在低资源、多语言环境中的安全机制仍然很少被探讨。我们在研究中旨在填补这一空白，特别地，我们介绍了SGToxicGuard，一个针对新加坡多样语言环境的新颖数据集和评估框架，包括新加坡英语（Singlish）、汉语、马来语和泰米尔语。SGToxicGuard采用红队方法系统性地在未来三个真实的场景中探测LLM的漏洞：对话、问答和内容生成。
### Innovation
我们提出了一种新的数据集和评估框架，SGToxicGuard，用于在新加坡多语言环境中测试LLM的安全性，特别是涵盖了新加坡特有的Singlish、汉语、马来语和泰米尔语。我们使用最新的多语言LLM进行了广泛的实验，揭示了它们在安全防护方面的关键不足。我们通过提供有关文化敏感性和毒性缓解的实际见解，为在语言多样环境中构建更安全、更包容的AI系统奠定了基础。
### Conclusion
我们的研究结果表明，目前的LLM在新加坡这种语言多样环境中仍然存在安全缺口。SGToxicGuard为这些系统的改进提供了基础，有助于构建更加安全、包容的AI系统，在这样的复杂语言环境中尤为重要。
## 255. `cs.CL` - 在大型语言模型中的知识自我意识量化 [PDF](https://arxiv.org/pdf/2509.15339), [HTML](https://arxiv.org/abs/2509.15339)
### Authors
Yeongbin Seo,Dongha Lee,Jinyoung Yeo
### Background
先前的研究常将大型语言模型（LLMs）中的幻觉预测视为模型具备自我意识的表现。然而，本文作者认为这种表象实际上可以由问题端的捷径引起，而非模型端真正的反思。为了区分这些因素，作者提出了近似问题端效应（AQE）方法，用于量化问题意识的贡献。
### Innovation
文章提出了一种新的方法——近似问题端效应（AQE），来量化问题意识的贡献，以区分自我意识的表现是由模型本身驱动还是因为问题端的捷径。进一步地，引入了一种新的方法——语义压缩通过一句话作答（SCAO），以增强模型端信号的使用。这种方法在特定场景下表现出了强大的一致性能，并且在减少问题端线索的情况下效果尤为明显。这些创新性地展示了如何促进LLMs真正的自我意识。
### Conclusion
研究人员分析了多个数据集后发现，很多报告的成功实际上是由于利用了问题中的表面模式。实验表明，语义压缩通过一句话作答（SCAO）方法在减少问题端线索的情况下，能实现更强和更一致的性能，这突显了它在培养LLMs真正自我意识方面的有效性。
## 256. `cs.CL` - 自然语言大模型问答中自然语言解释的不确定性量化 [PDF](https://arxiv.org/pdf/2509.15403), [HTML](https://arxiv.org/abs/2509.15403)
### Authors
Yangyi Li,Mengdi Huai
### Background
大语言模型（LLMs）在问答（QA）任务中展示了强大的能力，能够提供简洁且上下文相关的问题回答。尽管LLMs复杂且缺乏透明性，已有研究致力于开发解释LLMs的方法。自然语言解释由于其自我解释的能力和封闭源模型中的可解释性，表现出独特的优势。然而，现有的研究尚未探讨如何为这些生成的自然语言解释提供有效的不确定性保证，这一点在理解解释的信心方面至关重要。由于LLMs的自回归生成过程及医学询问中的噪声，为自然语言解释生成有效不确定性估计具有挑战性。
### Innovation
本文首次提出了一个新颖的后验且模型无关的不确定估计框架，为LLMs生成的自然语言解释提供有效不确定性保证。此外，还设计了一种新型鲁棒的不确定估计方法，即使在存在噪声的条件下也能保持有效不确定性保证。在问答任务上的广泛实验展示了本方法的期望性能。
### Conclusion
本文提出的方法为生成的自然语言解释提供了有效的不确定性保证，尤其是在存在噪声的情况下也保持了这种保证。这些方法在问答任务上的表现证明了其有效性。
## 257. `cs.CL` - PolBiX：通过 euphemisms 和 dysphemisms 检测 LLMs 在事实核查中的政治偏见 [PDF](https://arxiv.org/pdf/2509.15335), [HTML](https://arxiv.org/abs/2509.15335)
### Authors
Charlott Jakob,David Harbecke,Patrick Parschan,Pia Wenzel Neves,Vera Schmitt
### Background
大型语言模型（LLMs）在需要客观评估的应用中越来越普遍，但这些模型可能受到政治偏见的影响。许多研究发现，LLMs 对左倾立场有偏好，但在像事实核查这样的下游任务上的具体影响仍待深入研究。本研究通过交换德语声明中的委婉语或反语词的方式系统地探讨政治偏见，构建了事实等价但政治含义不同的最小对，以评估 LLMs 在判断它们为真或假时的一致性。研究发现，判断性词汇的存在比政治倾向对真实性判断有显著影响，尽管一些模型表现出政治偏见，但明确要求客观性的提示并未缓解这种偏见。
### Innovation
该研究通过交换词语中的委婉语或反语词来研究大型语言模型的政治偏见，并构建了事实等价但政治含义不同的最小对。这种方法系统地检测了LLMs在事实核查中的政治偏见，提供了一种新的分析视角，发现判断性词汇的影响大于政治倾向，尽管一些模型有政治偏见，但强调客观性的提示并未缓解这种偏见。
### Conclusion
研究发现，判断性词语比政治倾向对实际判断的影响更大。虽然一些模型存在政治偏见，但明确要求体现客观性的提示不能缓解这种偏见。
## 258. `cs.CL` - 超越虚假信号：通过反事实推理和自适应专家路由实现多模态大型语言模型的去偏 [PDF](https://arxiv.org/pdf/2509.15361), [HTML](https://arxiv.org/abs/2509.15361)
### Authors
Zichen Wu,Hsiu-Yuan Huang,Yunfang Wu
### Background
多模态大型语言模型（MLLMs）虽然在整合视觉和文本信息方面表现出强大的能力，但经常依赖于虚假的相关性，这会削弱它们在复杂多模态推理任务中的鲁棒性和归纳能力。
### Innovation
该论文通过一种新的因果中介去偏框架解决了MLLMs的表面相关性偏差问题。具体而言，该框架通过反事实示例区分核心语义和虚假的文本和视觉上下文，在训练阶段激活去偏，并采用混合专家（MoE）架构动态路由，以选择性地利用模态特定的去偏专家。
### Conclusion
在多模态讽刺检测和情感分析任务上的实证评估表明，该框架显著优于单一模态的去偏策略和现有的最先进的模型。
## 259. `cs.CL` - 令人沮丧的简单数据增强方法用于低资源ASR [PDF](https://arxiv.org/pdf/2509.15373), [HTML](https://arxiv.org/abs/2509.15373)
### Authors
Katsumi Ibaraki,David Chiang
### Background
随着自动语音识别（ASR）技术的发展，如何在资源有限的情况下提高识别性能成为一个挑战。针对这一问题，本文提出了一种简单有效的方法，通过自包含的数据增强技术生成新的文本，然后利用文本转语音（TTS）技术生成合成音频，以辅助训练模型。这种方法仅依赖于原始标注的数据，适用于资源极其有限的语言，如Vatlongos、Nashta、Shinekhen Buryat和Kakabe。实验结果表明，这种方法在多个低资源语言上表现良好，并且也适用于资源充足的语言如英语。
### Innovation
本文提出了三种基于自包含数据生成的新方法，分别为基于词典的替换、随机替换以及基于大语言模型的方法。这些方法能够生成新的文本，然后通过TTS技术生成合成音频。这种方法利用原始标注的数据，适用于资源非常有限的语言。实验数据证明了这些方法的有效性，尤其在低资源语言上的性能提升更为显著。
### Conclusion
本文提出了一种简单且有效的方法，能够显著提高低资源ASR系统的性能。通过自包含的数据生成和合成音频技术，本文的方法不仅在低资源语言上证明了其有效性，也在高资源语言上展示了应用前景。这种方法的操作简便，能够广泛应用于不同资源情况的ASR系统开发中。
## 260. `cs.AI` - 通过领域自适应预训练获得属性感知表示以提高异常声音检测 [PDF](https://arxiv.org/pdf/2509.12845), [HTML](https://arxiv.org/abs/2509.12845)
### Authors
Xin Fang,Guirui Zhong,Qing Wang,Fan Chu,Lei Wang,Mengui Qian,Mingqi Cai,Jiangzhao Wu,Jianqing Gao,Jun Du
### Background
异usual Sound Detection (ASD)问题通常被建模为机器属性分类任务，但在大多数情况下，仅能获得正常数据进行训练。由于充分收集机器属性标签是一项艰巨且不切实际的任务，因此在缺乏属性标签的情况下应对这一挑战显得尤为必要。
### Innovation
本文提出了一种基于领域自适应预训练模型的聚类方法，用于生成伪属性标签。通过有监督微调的方法将预训练模型应用于机器属性分类任务，从而实现新的最佳性能。
### Conclusion
本方法在DCASE 2025挑战数据集上的评估表明，新提出的方法实现了显著的性能提升，并超越了上一届比赛中的最高排名系统。
## 261. `cs.CL` - 未代表语言的语音语言模型：来自沃洛夫语的见解 [PDF](https://arxiv.org/pdf/2509.15362), [HTML](https://arxiv.org/abs/2509.15362)
### Authors
Yaya Sy,Dioula Doucouré,Christophe Cerisara,Irina Illina
### Background
我们介绍了训练西非沃洛夫语语音语言模型的过程，这是一门在现有数据集中常被忽视的语言。我们强调了收集大规模、自然、高质量语音数据的重要性，并展示了在该数据集上持续预训练HuBERT优于基础模型和特定于非洲地区的模型。我们还介绍了如何将该语音编码器集成到沃洛夫语LLM中，训练第一个针对该语言的语音LLM，使其能够处理诸如语音翻译等任务。此外，我们探索了在转录或翻译之前训练语音LLM进行多步推理的方法。这些结果显示，语音LLM不仅提高了语音识别能力，还在语音翻译方面表现出色。模型和代码将被公开分享。
### Innovation
1. 强调了收集大规模、自然、高质量语音数据的重要性；2. 展示了在特定数据集上持续预训练HuBERT模型优于基础模型和特定于非洲地区的模型；3. 将语音编码器集成到沃洛夫语LLM中，训练第一个该语言的语音LLM，增强其在语音翻译等任务上的能力；4. 探索在转录或翻译之前训练语音LLM进行多步推理的方法，改善语音翻译效果；5. 模型和代码将被公开分享，促进更多未代表语言的语音模型的研究和应用。
### Conclusion
我们的研究通过整合大规模、自然、高质量的语音数据驱动的预训练与语音LLM的多步骤推理，为未代表语言的语音识别和翻译技术提供了新的方法和认知。模型和代码的公开共享将促进这一领域的进一步研究和发展。
## 262. `cs.AI` - 穿过散射光线看海：重新审视用于生成逼真水下图像成像模型 [PDF](https://arxiv.org/pdf/2509.15011), [HTML](https://arxiv.org/abs/2509.15011)
### Authors
Vasiliki Ismiroglou,Malte Pedersen,Stefan H. Bengtson,Andreas Aakerberg,Thomas B. Moeslund
### Background
近年来，水下图像形成模型被广泛应用于生成合成水下数据。尽管许多方法主要关注主要受颜色失真影响的场景，但它们往往忽略了模型在捕捉高浑浊度环境中距离依赖性的视见度损失方面的能力。
### Innovation
本文提出了一种改进的合成数据生成管线，包括通常被忽略的前向散射项，同时考虑非均匀介质。此外，我们还收集了BUCKET数据集，在受控浑浊度条件下，获得了带有对应参考图像的真实浑浊视频。
### Conclusion
我们的结果在定性上优于参考模型，尤其是在浑浊度增加的情况下，由参与者的抽样率为82.5%。数据和代码可以在项目页面上访问：this http URL 。
## 263. `cs.CL` - 深度学习和抽象化摘要在放射学报告中的应用：针对稀缺数据调整PEGASUS模型家族的实证研究 [PDF](https://arxiv.org/pdf/2509.15419), [HTML](https://arxiv.org/abs/2509.15419)
### Authors
Claudio Benzoni,Martina Langhals,Martin Boeker,Luise Modersohn,Máté E. Maros
### Background
尽管人工智能快速发展，但在敏感且数据受限的领域如医学中，抽象化总结仍然具有挑战性。随着医学成像数量的增加，自动化工具对于复杂医学文本总结的重要性预计将变得尤为重要。因此，研究在稀缺数据情况下适应性调整非领域特定的抽象化总结编码器-解码器模型具有重要意义，尤其是在放射学报告领域。研究人员对PEGASUS和PEGASUS-X模型进行了适应性调整，并通过实验评估了这些模型在固定大小验证集上的性能。
### Innovation
本文的主要创新在于通过精细化调整的方法对非领域特定的PEGASUS和PEGASUS-X模型进行适应性调整，并通过实验评估了不同检查点大小下的模型性能，尤其是对PEGASUS和PEGASUS-X在稀缺数据情况下的表现进行了详细分析，揭示了不同的泛化行为，并强调了在处理稀缺数据时，高度表达性的模型调整带来的挑战和风险。
### Conclusion
研究结果突显了在稀缺训练数据情况下精细化调整高度表达性模型的挑战与风险。本研究为未来在专业领域中总结模型更加稳健的调整策略奠定了基础。
## 264. `cs.CL` - BiRQ: 结合多层次自我标注随机量化进行自我监督的语音识别 [PDF](https://arxiv.org/pdf/2509.15430), [HTML](https://arxiv.org/abs/2509.15430)
### Authors
Liuyuan Jiang,Xiaodong Cui,Brian Kingsbury,Tianyi Chen,Lisha Chen
### Background
语音是非常丰富的信号类型，但标注的音频文本对成本高昂，因此自我监督学习对于大规模表示学习至关重要。语音SSL的核心挑战是如何生成既具信息性又高效的伪标签：强标签，例如HuBERT所使用，能够提升下游性能，但需要外部编码器和多阶段流水线；而高效方法BEST-RQ则以简化为目标，但标签较弱。因此，需要一种结合BEST-RQ简化性和HuBERT标签增强精细度的方法来优化语音SSL的学习过程。
### Innovation
BiRQ提出了一种多层次SSL框架，结合BEST-RQ的高效性和HuBERT式标签增强的精细度。这种方法利用模型本身的一部分作为伪标签生成器，通过随机投影量化中间表示产出增强标签，并从原始输入直接提取标签以稳定训练，避免标签饱和。培训过程被形式化为一种高效的可微分Gumbel-softmax选择的第一级优化问题，从而省去了外部标签编码器，降低内存成本，并允许端到端的迭代标签优化。实验表明，BiRQ在保持低复杂性和计算效率的同时，始终比BEST-RQ有所改进。
### Conclusion
我们在960小时的LibriSpeech、150小时的AMI会议和5000小时的YODAS数据集上验证了我们的方法，结果表明BiRQ在各个数据集上均优于BEST-RQ。
## 265. `cs.CL` - 红队测试多模态语言模型：跨提示模态和模型评估危害 [PDF](https://arxiv.org/pdf/2509.15478), [HTML](https://arxiv.org/abs/2509.15478)
### Authors
Madison Van Doren,Casey Ford,Emily Dix
### Background
多模态大型语言模型（MLLMs）在实际应用中越来越广泛，但它们在对抗性条件下的安全性未得到充分探索。这项研究评估了几种领先的MLLMs（GPT-4o、Claude Sonnet 3.5、Pixtral 12B和Qwen VL Plus）在文本和多模态提示下的潜在危险性，这些提示针对三类危害：非法行为、虚假信息和不道德行为。结果显示，不同模型和模态的安全性存在显著差异，Pixtral 12B的有害响应率最高，而Claude Sonnet 3.5则表现最稳健。此外，与预期相反，纯文本提示在规避安全机制方面比多模态提示略为有效。统计分析证实，模型类型和输入模态都是有害性预测的重要因素。这些发现突显了在MLLMs广泛应用之前需要建立稳健的多模态安全基准的紧迫性。
### Innovation
这项研究首次系统性地评估了多模态大型语言模型在不同模态下的潜在危害，特别是与预期相反地发现纯文本提示在规避安全机制方面优于多模态提示。
### Conclusion
研究结果强调了在广泛部署MLLMs之前，需要建立稳健的多模态安全基准的迫切性，以确保其在对抗性情境中的安全性。
## 266. `cs.CL` - PILOT：使用心理与语言输出导向引导合成数据生成 [PDF](https://arxiv.org/pdf/2509.15447), [HTML](https://arxiv.org/abs/2509.15447)
### Authors
Caitlin Cisar,Emily Sheffield,Joshua Drake,Alden Harrell,Subramanian Chidambaram,Nikita Nangia,Vinayak Arannil,Alex Williams
### Background
现有生成AI应用中，通常利用用户角色来作为生成合成数据的指引，但这种方法依赖自然语言表达，使得模型在生成过程中可能会做出意外的推断，从而影响生成结果的精确性。因此，研究提出了一种新的两种阶段的框架——PILOT，通过结构化的心理语言文件来指导大型语言模型。这一框架在两个阶段中分别将自然语言的用户角色描述转化为具有标准化评分的多维度文件，并用这些文件来引导生成过程。通过三种最先进模型的测试，探讨了不同引导方法的效果差异与优缺点。
### Innovation
PILOT框架通过引入结构化的心理语言文件来指导大规模语言模型，分为两个阶段：第一阶段将自然语言的角色描述转化为标准化的多维度文件，第二阶段利用这些文件引导生成沿着可测量的维度变化。通过这种方法，能够显著降低人工生成角色的重复性，增强输出的一致性，并在保持信息多样性的同时提高预测性。研究结果证实了基于架构的方法在减少角色重复和提高输出连贯性上的显著效果。
### Conclusion
通过PILOT框架，生成的输出更加一致且具有更高的主题纯洁度。两种引导方式（架构基线导向和混合式角色架构引导）分别在简洁性和主题一致性、词汇多样性和预测性之间寻找平衡。PILOT框架中所有条件下生成的文本质量都很高，且不同引导方法之间没有统计学上的显著差异。
## 267. `cs.CL` - DNA-DetectLLM: 通过基于DNA启发的变异修复范式揭示AI生成文本 [PDF](https://arxiv.org/pdf/2509.15550), [HTML](https://arxiv.org/abs/2509.15550)
### Authors
Xiaowei Zhu,Yubing Ren,Fang Fang,Qingfeng Tan,Shi Wang,Yanan Cao
### Background
大型语言模型（LLMs）的快速发展模糊了AI生成文本与人类撰写的文本之间的界限。这一进步带来了一些社会风险，如假信息、作者身份模糊和知识产权问题，这凸显了需要可靠的AI生成文本检测方法的迫切性。然而，生成语言模型的最新进展导致了人类撰写的文本和AI生成的文本的特征分布显著重叠，使分类界限变得模糊，增加了准确检测的难度。
### Innovation
本文提出了一个基于DNA启发的视角，利用基于修复的过程，直接且可解释地捕捉人类撰写的和AI生成的文本之间的内在差异。基于此视角，本文引入了DNA-DetectLLM，这是一种零样本检测方法，用于区分AI生成的和人类撰写的文本。该方法为每个输入构建一个理想的AI生成序列，迭代修复非最优的词汇，并将累积的修复努力量化为一个可解释的检测信号。
### Conclusion
实证评价表明，本方法实现了最先进的检测性能，并且在各种对抗攻击和输入长度下表现出强大的鲁棒性。具体而言，DNA-DetectLLM 在多个公共基准数据集中分别在AUROC和F1分数上取得了5.55%和2.08%的相对提升。
## 268. `cs.CL` - 在口语讽刺理解方面评估多模态大规模语言模型 [PDF](https://arxiv.org/pdf/2509.15476), [HTML](https://arxiv.org/abs/2509.15476)
### Authors
Zhu Li,Xiyuan Gao,Yuqing Zhang,Shekhar Nayak,Matt Coler
### Background
讽刺检测仍然是自然语言理解的一个挑战，因为讽刺意图往往依赖于跨越文本、语言和视觉的微妙跨模态提示。尽管先前的工作主要集中在文本或视觉文本讽刺上，但全面的音频-视觉-文本讽刺理解仍被广泛忽视。这篇论文系统地评估了在零样本、少样本和基于LORA微调设置下大型语言模型和多模态大型语言模型在英文（MUStARD++）和中文（MCSD 1.0）讽刺检测中的表现。除了直接分类，我们还将模型作为特征编码器来探索，并通过协作闸门融合模块整合它们的表示。实验结果表明，基于音频的模型在单模态性能上最强，而文本-音频和音频-视觉组合超越了单模态和三模态模型。此外，多模态大型语言模型（MLLMs）如Qwen-Omni在零样本和微调性能方面表现出竞争力。我们的发现强调了多模态大型语言模型在跨语言、音频-视觉-文本讽刺理解中的潜力。
### Innovation
该论文首次系统地评估了大型语言模型和多模态大型语言模型跨零样本、少样本和基于LORA微调设置的讽刺检测表现。探索了模型作为特征编码器，并使用协作闸门融合模块整合它们的表示。研究表明，基于音频的模型在单模态中的性能最强，而文本-音频和音频-视觉组合优于单模态和三模态模型。此外，多模态大型语言模型在零样本和微调性能上表现出良好的竞争力。
### Conclusion
多模态大型语言模型具有跨语言、音频-视觉-文本讽刺理解的潜力。基于音频的模型在单模态性能上表现最佳，而文本-音频和音频-视觉组合超越了其他模型。多模态大型语言模型如Qwen-Omni显示了在零样本和微调设置下的竞争力。
## 269. `cs.CL` - 探索多语种和谐：大型语言模型预训练中的多语种数据分配 [PDF](https://arxiv.org/pdf/2509.15556), [HTML](https://arxiv.org/abs/2509.15556)
### Authors
Ping Guo,Yubing Ren,Binbin Liu,Fengze Liu,Haobin Lin,Yifan Zhang,Bingni Zhang,Taifeng Wang,Yin Zheng
### Background
大型语言模型正在广泛应用于各种场景，推动了全球对高效多语种能力的前所未有的需求。实现稳健的多语种性能的关键在于训练语料库中语言比例的战略分配。但由于跨语言交互的复杂性以及数据集规模对性能的影响，确定最优语言比例非常具有挑战性。
### Innovation
本文提出了一种名为Climb（跨语言交互感知多语种平衡）的新框架，该框架系统地优化了多语种数据分配。Climb引入了一种跨语言交互感知的语言比例，明确量化了每种语言的有效分配，并捕捉了跨语言依赖关系。Climb采用了一个两步优化程序，首先使每种语言的边际效益相等，然后最大化获得的语言分配向量的大小，该方法显著简化了多语种优化问题。
### Conclusion
广泛实验证明，Climb可以准确测量各种多语种设置下的跨语言交互。采用Climb方法获得的语言比例训练的大型语言模型在多语种性能上达到了最先进的效果，并且在某些情况下，甚至超过了用更多令牌训练的开源大型语言模型的表现。
## 270. `cs.CL` - mucAI在BAREC共享任务2025：迈向具有不确定性意识的阿拉伯文本易读性评估 [PDF](https://arxiv.org/pdf/2509.15485), [HTML](https://arxiv.org/abs/2509.15485)
### Authors
Ahmed Abdou
### Background
本文背景在于对阿拉伯语的细粒度可读性分类进行研究。BAREC 2025共享任务要求参与者提供19个不同可读性级别的分类。过往方法在处理文本可读性分类时，通常缺乏不确定性处理机制，这可能导致高成本错误分类影响最终的评价质量。因此，本文旨在提出一种模型无关的后处理技术，通过应用可信性预测来生成带覆盖保证的预测集，以及使用softmax重正规范化概率计算加权平均，从而提高评价指标Quadratic Weighted Kappa (QWK)的表现，并使人类评审员能够更专注于可能的级别，增强统计保证和实用性。
### Innovation
本文的主要创新之处在于提出了一种模型无关的后处理技术，通过结合可信性预测和softmax重正规范化概率，生成具有覆盖保证的预测集，并通过加权平均计算来实现不确定性意识的解码。这种方法显著提高了Quadratic Weighted Kappa (QWK)值，特别是在不同的基模型下，持续提升了1-3个百分点。在BAREC共享任务的严格轨道测试中，mucAI的方法在句子级别达到了84.9%的QWK分数，在盲测试中达到了85.7%的QWK分数，而在文档级别则为73.3%。这项技术为阿拉伯语教育评估提供了统计保证和实用性相结合的解决方案，使得人类评审员能够专注于合理的级别分类。
### Conclusion
本文通过提出一种具有不确定性意识的阿拉伯文本可读性后处理技术，不仅提高了基于不同基模型的QWK评价指标，还在严格轨道测试中表现优异。这种方法为阿拉伯语教育评估提供了有效的支持，可以辅助人类评审员进行更精细、高效的评估工作。
## 271. `cs.CL` - LiteLong: 资源高效的大语境数据合成方法 [PDF](https://arxiv.org/pdf/2509.15568), [HTML](https://arxiv.org/abs/2509.15568)
### Authors
Junlong Jia,Xing Wu,Chaochen Gao,Ziyang Chen,Zijia Lin,Zhongzhi Li,Weinong Wang,Haotian Xu,Donghui Jin,Debing Zhang,Binghui Guo
### Background
高质量的长上下文数据对于训练能够处理大文档的大规模语言模型（LLMs）至关重要，但现有的以相关性为基础的数据合成方法存在计算效率低的问题。
### Innovation
LiteLong提出了一种资源高效的方法，通过结构化的主题组织和多智能体辩论来合成长上下文数据。这种方法利用BISAC图书分类系统提供了一个全面的层级主题组织，并利用多智能体辩论机制生成结构内的多样化高质量主题。每个主题，采取轻量级BM25检索获取相关文档，合并生成128K token的训练样本。实验表明，LiteLong在HEL META和Ruler基准上展示了竞争力的长上下文表现，并且可以与其他增强长依赖的方法无缝集成，从而降低高质量长上下文数据合成的计算和数据工程成本。
### Conclusion
LiteLong通过减少计算和数据工程成本，使得高质量长上下文数据合成更加便捷，并方便进一步研究大语境语言训练。
## 272. `cs.CL` - 语言对于类人智能的重要性如何？ [PDF](https://arxiv.org/pdf/2509.15560), [HTML](https://arxiv.org/abs/2509.15560)
### Authors
Gary Lupyan,Hunter Gentry,Martin Zettersten
### Background
近年来，人工智能和认知科学的发展重新引发了关于语言是否仅仅是思维表达工具，还是在人类认知中扮演更主动角色的旧问题。论文通过分析语言在促进更广泛的AI系统发展和人类智能核心方面的重要作用，探讨了这一问题。
### Innovation
文章强调了语言的两个关键属性：一是语言提供了一种紧凑的表示方法，使抽象概念（如精确数量）更容易表示和推理；二是这些压缩表示是集体智慧的产物。通过学习语言，人们掌握了许多文化进化的抽象概念。研究表明，能够足够强大的学习系统（无论是生物的还是人工的），通过接触语言学会压缩世界的模型，从而反向工程出许多支持人类（及类人类）思考的概念和因果结构。
### Conclusion
语言可能是促进更通用AI系统和人类核心智能的关键。通过理解和学习语言，可以揭示和模仿人类思维方式中的许多概念和因果结构。
## 273. `cs.CL` - 相关性到实用性：过程监督重写用于RAG [PDF](https://arxiv.org/pdf/2509.15577), [HTML](https://arxiv.org/abs/2509.15577)
### Authors
Jaeyoung Kim,Jongho Kim,Seung-won Hwang,Seoho Song,Young-In Song
### Background
检索增强生成系统通常存在检索相关性和生成实用性之间的差距：检索到的文档可能在主题上相关，但仍缺乏生成过程中有效推理所需的特定内容。现有的“桥梁”模块试图重新编写检索到的文本以提高生成效果，但这些模块未能捕捉到文档的主要用途。现有的工作集中在改进生成的实用性，而在生成过程中的直接监督十分昂贵。
### Innovation
本文提出了一种新的方法R2U，关键区别在于直接优化生成正确答案的概率，通过过程监督实现。由于直接监督成本高昂，我们还提出了一种通过扩大来自LLM的监督来近似高效蒸馏管道的方法，从而帮助较小的重写模型更好地泛化。
### Conclusion
我们在多个开放域问答基准上评估了我们的方法。实证结果表明，我们的方法在强桥梁基线上显示出一致的改进。
## 274. `cs.CL` - DivLogicEval：大型语言模型逻辑推理评估框架 [PDF](https://arxiv.org/pdf/2509.15587), [HTML](https://arxiv.org/abs/2509.15587)
### Authors
Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung
### Background
自然语言中的逻辑推理被认为是衡量人类智能的重要指标，特别是在大型语言模型（LLMs）中。现有的逻辑推理基准可能包含多种推理技能，这可能导致评估逻辑推理技能的不准确评价。此外，现有的逻辑推理基准在语言多样性方面有限，并且其分布偏差较大，这可能会导致评估结果的偏差。
### Innovation
本文提出了一种新的经典逻辑基准DivLogicEval，由以非直观方式组合的多种不同声明的自然句子构成。为了确保评估更具可靠性，还引入了一种新的评估指标，以减轻LLMs内在的偏差和随机性的影响。实验结果展示了回答DivLogicEval中的问题所需逻辑推理的程度，并比较了不同流行LLM在进行逻辑推理时的性能。
### Conclusion
通过实验，验证了DivLogicEval对逻辑推理能力的评估效果，并展示了不同热门LLM在逻辑推理任务上的性能差异。
## 275. `cs.CL` - 层析最小对变换查揭示了语音表示中的上下文语法概念层次结构 [PDF](https://arxiv.org/pdf/2509.15655), [HTML](https://arxiv.org/abs/2509.15655)
### Authors
Linyang He,Qiaolin Wang,Xilin Jiang,Nima Mesgarani
### Background
基于变换器的语音语言模型（SLMs）在神经语音识别和理解方面取得了显著改进。尽管现有研究评估了SLMs如何编码浅层的声学和音位特征，但对于SLMs在自监督学习（S3M）、自动语音识别（ASR）、语音压缩（Codec）以及作为听觉大规模语言模型（AudioLLMs）的编码器时，如何编码语法规则和概念特征的细微差异尚不明确。
### Innovation
本研究通过最小对变换查设计并跨71个覆盖不同语言层次的任务进行全面分析，首次系统性地评估了SLMs在SLM、ASR、Codec和AudioLLMs中的上下文语法和语义特征的存在。该研究揭示了所有语音编码更为鲜艳的语法规则特征而非概念特征，并将这一发现与大型语言模型的语言能力评估进行了类比。
### Conclusion
研究发现，所有SLMs在多任务中都更牢固地编码了语法规则特征而非概念特征。这一研究结果揭示了SLMs中的上下文语法和概念特征层次结构。
## 276. `cs.CL` - 基于高分辨率有限标量量化的大段落语音预训练 [PDF](https://arxiv.org/pdf/2509.15579), [HTML](https://arxiv.org/abs/2509.15579)
### Authors
Yun Tang,Cindy Tseng
### Background
随着过去十年语音技术的快速发展，低延迟语音人机通信变得越来越重要。自监督学习是语音技术进步的主要因素之一，但大部分自监督学习算法假定完整语音片段，而在流式应用中常见的不完整语音片段则要求做出妥协，因此需要一种统一的解决方案来满足流式和离线语音预训练的需求。
### Innovation
本文提出了基于大段落的自监督学习（Chunk SSL）算法，作为流式和离线语音预训练的一体化解决方案。Chunk SSL使用掩码预测损失并鼓励声学编码器通过辅助未屏蔽帧来恢复那些被掩码语音帧的索引，同时提出了copy and append数据增强方法以实现出高效的基于段落的预训练。此外，本文利用有限标量量化（FSQ）模块对输入语音特征进行量化，并通过高分辨率的FSQ码本进行预训练任务与下游任务的知识迁移，同时也采用分组掩码预测损失以缓解由于大码本带来的高内存和计算成本。
### Conclusion
在语音到文本任务（如语音识别和语音翻译）中，本文方法在Librispeech和Must-C数据集上取得了非常具有竞争力的结果，证明了在流式和离线模式下其有效性和实用性。
## 277. `cs.CL` - 语言模型如何生成流行语：人类与机器生成流行语使用的系统比较 [PDF](https://arxiv.org/pdf/2509.15518), [HTML](https://arxiv.org/abs/2509.15518)
### Authors
Siyang Wu,Zhewei Sun
### Background
俚语作为一种广泛使用的非正式语言，给自然语言处理（NLP）系统带来了巨大挑战。尽管如此，大型语言模型（LLMs）的进步让这一问题变得更具可行性。尽管LLMs被广泛应用于中介任务，如俚语检测和解读，但它们的普适性和可靠性很大程度上取决于这些模型是否能够捕捉到与人类认可的俚语使用相匹配的结构知识。
### Innovation
本文贡献了一个系统地将人类与机器生成的俚语使用进行比较的框架。评估框架重点关注三个方面：1) 反映机器如何看待俚语的系统偏差的特性；2) 由俚语中的新词和单词再利用展示的创造力；3) 作为模型蒸馏标准例子的俚语的说明性。通过对来自在线俚语词典（OSD）和GPT-4o以及Llama-3生成的俚语进行比较，发现了LLMs在感知俚语方面的显著偏差。
### Conclusion
我们的结果表明，尽管LLMs已经捕获了关于俚语创意方面的大量知识，但这些知识与人类的匹配度不足以使LLMs能够进行语言分析等外推任务。
## 278. `cs.CL` - VOX-KRIKRI：通过连续融合统一语音和语言 [PDF](https://arxiv.org/pdf/2509.15667), [HTML](https://arxiv.org/abs/2509.15667)
### Authors
Dimitrios Damianos,Leon Voukoutis,Georgios Paraskevopoulos,Vassilis Katsouros
### Background
本文介绍了一种多模态融合框架，该框架旨在结合预训练的解码器基础大规模语言模型（LLM）和Whisper等声学编码-解码器架构，构建语音使能的LLM。研究主要背景为如何有效地将语音和文本的数据表示进行对齐，以往直接使用音频嵌入的方法较为局限，本文提出了一种在中间音频条件文本空间中进行对齐的策略，并在语音和文本连续表示空间中进行信息融合。
### Innovation
本文的主要创新之处在于提出了一种在连续文本表示空间中进行多模态融合的方法，通过Whisper的隐藏解码状态和LLM的状态进行交叉模态注意力融合，该方法支持离线和流式处理模式。此外，本文构建了第一个希腊语语音LLM，并通过分析展示了这种方法在不同模态表示对齐方面的有效性。
### Conclusion
本文的研究结果表明，连续空间融合是一种为跨语言及少资源语音LLM领域具有前景的路径，同时，在希腊语音识别方面达到了最先进的性能，提供了基准测试平均约20%的相对性能提升。
## 279. `cs.CL` - 大型语言模型内部表示引导的稀疏自动编码器辅助遗忘方法 [PDF](https://arxiv.org/pdf/2509.15631), [HTML](https://arxiv.org/abs/2509.15631)
### Authors
Tomoya Yamashita,Akira Ito,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara
### Background
由于大型语言模型（LLMs）被广泛应用于各种领域，隐私和版权问题加剧了对更有效的LLM遗忘技术的需求。当前的遗忘方法主要通过附加训练（例如梯度上升）来压制不理想的结果输出，从而降低生成这些输出的概率。尽管这些压制方法可以在一定程度上控制模型输出，但它们并不能彻底消除模型内部激活中嵌入的知识；抑制一个响应并不等于忘记它。此外，这些压制方法经常会遇到模型崩溃的问题。这些问题促使研究者提出了一种新的方法，旨在直接干预模型的内部激活，从而实现更加彻底的遗忘。
### Innovation
该方法引入了一种新的遗忘目标，通过将目标实体的激活从已知实体的激活方向向未知实体的激活方向调整，在稀疏自动编码器的潜在空间中进行调整。这种方法使得目标实体的内部激活与其相似于未知实体的激活，进而将模型对目标实体的识别从已知转变为未知，实现了真正的遗忘，同时避免了过度压制和模型崩溃。实验结果表明，该方法有效对遗忘目标的内部激活进行了对齐，这是基于压制的方法无法可靠实现的。此外，该方法还可以减少模型在问答任务中对目标知识的回忆，同时保持非目标知识的完整性。
### Conclusion
本文提出了一种新颖的遗忘方法，通过直接干预模型内部激活，使得丢失目标的激活与未知实体的激活难以区分，从而实现真正遗忘的效果，并且该方法在抑制过度和模型崩溃方面表现优越，对遗忘目标的内部激活进行了有效对齐。此外，在问答任务中，该方法还减少了目标知识的回忆，同时未显著损害非目标知识。
## 280. `cs.CL` - 大型语言模型中基于自我构建知识三元组的概念遗忘 [PDF](https://arxiv.org/pdf/2509.15621), [HTML](https://arxiv.org/abs/2509.15621)
### Authors
Tomoya Yamashita,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara,Tomoharu Iwata
### Background
机器遗忘（MU）作为一种解决方案，近年来在解决大型语言模型（LLMs）中的隐私和版权问题方面引起了广泛关注。现有的MU方法旨在从LLMs中移除特定的目标句子，同时尽量减少对其他知识的损害。但这些方法需要明确的目标句子，无法移除更广泛的概念，例如人物或事件。针对这一局限性，本文引入了概念遗忘（CU）作为LLM遗忘的新需求。通过利用知识图谱表示LLM的内部知识，将CU定义为删除忘记目标节点及其相关边。基于图的这种表述形式使遗忘过程更加直观，并为设计更有效的法则提供了便利。
### Innovation
本文提出了一种新的方法，通过提示LLM生成忘记目标的知识三元组及其解释性句子，并应用遗忘过程对这些表示进行处理。这种原理使概念移除更加精确和全面，通过与LLM的内部知识表示对齐来实现遗忘过程。实验表明，该方法在保留无关知识的同时，有效实现了概念级别的遗忘。
### Conclusion
本文提出了一种基于自我构建知识三元组的概念遗忘方法，能更精确和全面地移除LLM中的概念，同时保持其他知识不变。实验结果验证了该方法的有效性。
## 281. `cs.CL` - 多语言LLM的提示策略在医学英越机器翻译中的应用 [PDF](https://arxiv.org/pdf/2509.15640), [HTML](https://arxiv.org/abs/2509.15640)
### Authors
Nhu Vo,Nu-Uyen-Phuong Le,Dung D. Le,Massimo Piccardi,Wray Buntine
### Background
英越医学机器翻译对于越南的医疗信息获取与交流至关重要，但越南语作为一种资源较少且研究不足的语言，现有的翻译工具有限。研究人员对六种不同规模（0.5B-9B参数）的多语言大语言模型（LLM）进行了一系列评估，旨在探索不同提示策略对医学英越翻译效果的影响。评估数据集为MedEV，包括医学领域的英语和越南语对照文本对。之前的研究表明，专科领域翻译依赖于通用模型的规模大小，而具有术语感知的提示和基于嵌入的示例检索方法能有效提升特定领域的翻译质量。
### Innovation
研究系统性地评估了六种不同规模的多语言大语言模型在MedEV数据集上的表现，并对比了零样本、少样本和词典增强的提示方法。实验发现，模型规模是决定性能的主要因素：更大的模型在零样本情况下表现良好，而少样本提示仅带来了边际提升。与此同时，术语感知的提示和基于嵌入的示例检索方法在提高专科学习翻译方面表现出了稳定的优势。此研究证实了多语言大语言模型在医学领域的潜力与目前的局限性。
### Conclusion
研究结论表明，尽管多语言大语言模型在医学英越翻译领域大模型拥有优势，但通过术语感知的提示和基于嵌入的示例检索，可以有效提升翻译质量。研究同时指出，尽管取得了积极成果，但多语言模型在医学领域的翻译表现还存在局限性，未来需进一步深入研究以提升模型在特定领域中的翻译性能。
## 282. `cs.CL` - UniGist: 向通用且硬件对齐的序列级长上下文压缩迈进 [PDF](https://arxiv.org/pdf/2509.15763), [HTML](https://arxiv.org/abs/2509.15763)
### Authors
Chenlong Deng,Zhisong Zhang,Kelong Mao,Shuaiyi Li,Tianqing Fang,Hongming Zhang,Haitao Mi,Dong Yu,Zhicheng Dou
### Background
大型语言模型逐渐能够处理长上下文输入，但KV缓存的记忆开销仍然是普遍部署的主要瓶颈。虽然各种压缩策略已有探索，但是序列级压缩，即为某些标记丢弃完整的KV缓存，特别具有挑战性，因为它可能导致重要上下文信息的丢失。
### Innovation
我们引入了UniGist，这是一种序列级长上下文压缩框架，通过细粒度地用特殊压缩标记（摘要）替换原始标记来高效地保留上下文信息。我们采用了一种无片段训练策略，并设计了一个高效的内核，其中包括摘要移位技巧，以实现优化的GPU训练。我们的方案还支持灵活的推理，允许实际删除压缩标记，从而实现即时内存节省。
### Conclusion
在多个长上下文任务的实验中，UniGist显著提高了压缩质量，特别是在细节召回任务和长时间依赖建模方面表现特别突出。
## 283. `cs.CL` - 使用大型多模态模型进行自动发音评估的微调 [PDF](https://arxiv.org/pdf/2509.15701), [HTML](https://arxiv.org/abs/2509.15701)
### Authors
Ke Wang,Wenning Wei,Yan Deng,Lei He,Sheng Zhao
### Background
自动发音评估（APA）是计算辅助语言学习（CALL）中的关键部分，需要在多个粒度和方面进行评估。大型多模态模型（LMMs）为APA提供了新的机会，但由于其在细粒度评估中的效果仍有不确定性，因此值得进一步研究如何利用这些模型进行APA。
### Innovation
本研究探讨了使用Speechocean762数据集和私人数据集对LMMs进行微调用于APA的可能性。结果显示，微调显著优于零样本设置，并在单粒度任务上达到了与公共和商用系统相竞争的结果。模型在单词和句子级别上表现良好，但在音素级别上的评估仍然具有挑战性。此外，Pearson相关系数（PCC）达到了0.9，而Spearman等级相关系数（SCC）保持在0.6左右，这表明SCC更能反映顺序一致性。这些发现强调了LMMs在APA中的潜力及其局限性，并指出未来需要对细粒度建模和排名感知评估进行更多研究。
### Conclusion
研究发现LMMs在APA中的潜在优势及其局限，并指出未来工作需要聚焦于细粒度建模和排名感知评估。
## 284. `cs.CL` - 大语言模型能评判辩论吗？基于论证理论语义评估非线性推理 [PDF](https://arxiv.org/pdf/2509.15739), [HTML](https://arxiv.org/abs/2509.15739)
### Authors
Reza Sanayei,Srdjan Vesic,Eduardo Blanco,Mihai Surdeanu
### Background
大语言模型在逻辑推理任务上表现出色，但在自然辩论等非线性结构的处理上尚未得到充分探索。自然辩论的最佳表达形式是论证图。研究旨在通过量化辩论（QuAD）语义评估大语言模型在构建结构化推理方面的潜力，具体使用的是基于攻击和支持关系给出论证可接受性得分的QuAD语义。
### Innovation
该研究通过仅使用两种NoDE数据集提供的对话形式的辩论，让模型通过复杂的提示来对论证进行排名，而无需访问底层图。研究尝试了多种大语言模型，并采用链式思考和情境学习等高级指令策略进行评估。研究表明，尽管模型在部分方面与QuAD排名有适度的对齐，但较长输入或中断的对话流程会导致性能下降。通过对模型进行高级提示，可以减轻这些影响，如减少长度和位置有关的偏差。
### Conclusion
研究发现大语言模型在建模形式化论证语义方面既有潜力也有局限性，并激励未来针对图形感知推理的研究工作。
## 285. `cs.CL` - SciEvent：跨领域科学事件抽取基准 [PDF](https://arxiv.org/pdf/2509.15620), [HTML](https://arxiv.org/abs/2509.15620)
### Authors
Bofu Dong,Pritesh Shah,Sumedh Sonawane,Tiyasha Banerjee,Erin Brady,Xinya Du,Ming Jiang
### Background
科学信息提取（SciIE）主要依赖于狭窄领域内的实体-关系抽取，这限制了其在跨学科研究中的应用，并且难以捕捉科学信息的必要语境，导致提取的信息碎片化或存在冲突。现有的方法难以处理多领域科学信息的结构化和上下文理解。
### Innovation
提出了SciEvent，一个通过统一的事件抽取（EE）模式注释的新型跨领域科学摘要基准，旨在支持结构化和上下文感知的科学内容理解。该基准包括500个来自五个研究领域的摘要，且包含手工标注的事件段、触发词和详细论证。SciEvent定义SciIE为一个多阶段的EE流程：一是将摘要拆分为核心科学活动部分，二是从这些部分中抽取相应的触发词和论证。实验结果表明，当前模型在社会学和人文学科等领域存在性能差距。
### Conclusion
SciEvent作为一个具有挑战性的基准测试，推动了跨领域科学信息提取的进步，朝向可泛化的多领域SciIE迈出一步。
## 286. `cs.CL` - RAVE：基于检索和评分感知的可验证断言检测 [PDF](https://arxiv.org/pdf/2509.15793), [HTML](https://arxiv.org/abs/2509.15793)
### Authors
Yufeng Li,Arkaitz Zubiaga
### Background
社交媒体上错误信息的快速传播凸显了开发可扩展的事实核查工具的必要性。断言检测是关键步骤，它能识别可以客观验证的陈述。之前的解决方案常常依赖于语言线索或断言的可核查性，但在处理模糊的政治论述和多种媒体格式（如推特）时，这些方法表现不佳。
### Innovation
本文提出了一种名为RAVE（基于检索和评分感知的可验证断言检测）的框架，该框架结合了证据检索和相关度及其来源信誉的结构化信号。实验结果显示，RAVE在准确性与F1分数上都优于仅基于文本的方法和基于检索的方法。
### Conclusion
RAVE一致地在CT22-test和PoliClaim-test数据集上优于文本仅依赖和基于检索的基线方法，展示了其在处理模糊政治论述和多样格式断言检测任务方面的能力。
## 287. `cs.CL` - REFER: 通过频率框架提示减轻意见总结中的偏差 [PDF](https://arxiv.org/pdf/2509.15723), [HTML](https://arxiv.org/abs/2509.15723)
### Authors
Nannan Huang,Haytham M. Fayek,Xiuzhen Zhang
### Background
个体表达的意见多样化，公正的总结需要全面反映这些观点。以往使用大型语言模型（LLMs）进行意见总结公平性研究，依赖于超参数调整或在提示中提供真实的数据分布信息。然而，这些方法存在实际限制：终端用户很少修改默认模型参数，且准确的数据分布信息往往不可用。
### Innovation
基于认知科学研究，表明基于频率的表示能通过使参考类更加明确和减轻认知负担来减少人类统计推理中的系统性偏差。本研究通过系统实验探索频率框架提示（REFER）是否能同样提高大型语言模型在意见总结中的公平性。研究采用已知提高人类推理效果的技术，并将其应用于语言模型，以获得更好的信息处理效果。与抽象的概率性对比，结果表明REFER在总结意见时能提高公平性，特别是在大模型中效果显著，且使用更强的推理指令时更为明显。
### Conclusion
频率框架提示（REFER）提升了语言模型在意见总结中的公平性，这一效果在大模型和较强推理指令下尤为显著。
## 288. `cs.CL` - 改进多语言指令微调数据集的质量与多样性的方法 [PDF](https://arxiv.org/pdf/2509.15549), [HTML](https://arxiv.org/abs/2509.15549)
### Authors
Chunguang Zhao,Yilun Liu,Pufan Zeng,Yuanchang Luo,Shimin Tao,Minggui He,Weibin Meng,Song Xu,Ziang Chen,Chen Liu,Hongxia Ma,Li Zhang,Boxing Chen,Daimeng Wei
### Background
多语言指令微调（IFT）对于使大语言模型（LLMs）在不同的语言和文化背景下有效地泛化至关重要。然而，高质量的多语言训练数据和相应的构建方法仍然是一个关键瓶颈。现有的数据选择方法在英语环境中显示出潜力，但在跨语言泛化方面往往失败，因为它们依赖于简单的启发式方法或语言特定的假设。
### Innovation
本文提出了多语言数据质量与多样性（M-DaQ）方法，这是一种通过选择高质量和语义上多样化的多语言IFT样本来提高LLMs多语能力的新方法，并首次系统地对多语言设置中的表层对齐假设（SAH）进行了研究。实验结果表明，使用M-DaQ方法微调的模型在18种语言的性能上显著优于基础模型，胜率超过60%。人类评价进一步验证了这些增益，强调了回复中的文化提升。
### Conclusion
方法在18种语言上的实验结果显示，使用M-DaQ方法微调的模型相比于基础模型取得了显著性能提升，胜率超过60%。人类评价也证实了回复中的文化增益。研究结果为未来研究提供了支持。
## 289. `cs.CL` - 统一再现平行资源管道 -- 联合国数据集 [PDF](https://arxiv.org/pdf/2509.15789), [HTML](https://arxiv.org/abs/2509.15789)
### Authors
Qiuyang Lu,Fangjian Shen,Zhengkai Tang,Qiang Liu,Hexuan Cheng,Hui Liu,Wushao Wen
### Background
多语言数据集的质量和可访问性对于机器翻译的发展至关重要。然而，先前从联合国文件构建的语料库存在如过程不透明、难以复制和规模有限等问题。
### Innovation
提出了一整套从网页抓取数据到文本对齐的端到端解决方案，涵盖了从数据获取到对齐的全过程，具有完全可复制性，并提供了单机示例和可选的分布式计算步骤以增强可扩展性。核心创新是提出了一种新的图形辅助段落对齐（GAPA）算法，以实现高效和灵活的段落级对齐。与以往工作相比，数据集中的英语词汇量超过7.13亿，规模翻了一番。这是迄今为止最大规模的公开可获取的平行语料库，由全部人工翻译、非人工智能生成的内容组成。
### Conclusion
我们的代码和数据集在MIT许可证下开放获取。
## 290. `cs.CL` - 小语言模型讲故事：互动学习 [PDF](https://arxiv.org/pdf/2509.15714), [HTML](https://arxiv.org/abs/2509.15714)
### Authors
Jonas Mayer Martins,Ali Hamza Bashir,Muhammad Rehan Khalid,Lisa Beinborn
### Background
儿童通过与环境中的其他人的互动来高效地获得语言能力，而不是仅仅通过听。相比之下，大型语言模型通常通过预测下一个词的方式在大量文本上进行训练。论文基于这种对比，探讨通过学习高级、认知启发式的反馈，而不是仅仅依赖于下个词预测的方法，能否使语言模型在获取数据较少的情况下提高语言能力。研究中训练了一个生成故事的学生模型，并由教师模型对其可读性、叙事连贯性和创造性进行评级。通过调整在反馈环前的预训练量，评估了这种互动学习对形式和功能语言能力的影响。实验结果显示，高级反馈数据效率很高：仅在互动学习中输入100万词，讲故事技能可以提高到与输入4.1亿词的下个词预测相当的水平。
### Innovation
本文创新地提出，将认知启发式的高级反馈引入语言模型训练过程，以减少所需数据量并提高语言模型的生成能力。具体来说，通过让教师模型根据可读性、叙事连贯性和创造性对生成的故事进行评级，高效地优化了语言模型的输出。这种方法不仅减少了数据需求，还促进了语言的高级层面能力的发展。此外，通过调整预训练阶段和反馈环之间的平衡，进一步探索了数据高效训练的可能性。
### Conclusion
研究发现，通过利用高级、认知启发式的反馈进行互动学习，可以在使用较少数据的情况下，显著提升语言模型的故事讲述技能。这种方法具有高数据效率，并展示了在语言模型训练中融合交际与认知反馈的潜力。未来的研究可以进一步探索这种互动学习方法在其他领域中的应用。
## 291. `cs.CL` - 虚假的心理：一种以人为中心的 misinformation 检测综述 [PDF](https://arxiv.org/pdf/2509.15896), [HTML](https://arxiv.org/abs/2509.15896)
### Authors
Arghodeep Nandi,Megha Sundriyal,Euna Mehnaz Khan,Jikai Sun,Emily Vraga,Jaideep Srivastava,Tanmoy Chakraborty
### Background
在数字时代，misinformation 成为了一个严重的问题，现有的自动事实核查系统主要关注事实准确性，而未能考虑到人们在接触信息时的心理感受和认知偏差等因素。这些因素使得 misinformation 对社会的影响远超简单的虚假信息，因此亟需引入更多的人本中心检测框架。
### Innovation
本文通过心理学和行为学的视角，分析了最先进的 misinformation 检测系统，揭示了现有方法的关键局限性，并提出了改进的机会。此外，还提出了结合技术和人类认知和社会影响复杂性的神经行为模型，为更有效地检测和减轻 misinformation 的社会危害提供了可能的方向。
### Conclusion
通过本综述，展示了如何超越单纯的事实核查，构建更稳健和适应性强的 misinformation 检测框架，从而更有效地应对 misinformation 的挑战。未来的研究方向应进一步整合技术和人类认知的复杂性，以创建更具神经行为特性的模型。
## 292. `cs.CL` - Distribution-Aligned Decoding for Efficient LLM Task Adaptation [PDF](https://arxiv.org/pdf/2509.15888), [HTML](https://arxiv.org/abs/2509.15888)
### Authors
Senkang Hu,Xudong Han,Jinqi Jiang,Yihang Tao,Zihan Fang,Sam Tak Wu Kwong,Yuguang Fang
### Background
利用大规模语言模型进行下游任务的适应仍然非常昂贵，即使使用参数高效微调（PEFT）方法也是如此。传统的微调方法需要通过参数更新间接地调整模型输出分布，这种方法效率较低。
### Innovation
提出了Steering Vector Decoding (SVD) 方法，这是一种轻量级、与PEFT兼容且有理论依据的方法。SVD方法通过短时的预训练微调提取任务感知的引导向量，并直接在解码过程中引导模型输出分布向任务分布靠拢。研究表明，SVD方法等价于完整的微调梯度步骤，并且可以提供对引导向量强度的全局最优解。这种方法在多个任务和基准测试中显著提高了多项选择准确度和开放式诚实性，并且不需要额外的可训练参数。
### Conclusion
SVD为大型语言模型的高效任务适应提供了一条轻量级、有理论依据的路径，通过减少不必要的参数更新，提高了多项多项选择准确度和开放式诚实性，在常识数据集上也取得了类似的收益。
## 293. `cs.CL` - BEFT: 语言模型的高效偏置调整 [PDF](https://arxiv.org/pdf/2509.15974), [HTML](https://arxiv.org/abs/2509.15974)
### Authors
Baichuan Huang,Ananth Balashankar,Amir Aminifar
### Background
参数高效调整（PEFT）技术中，调整所有偏置项的效果尤为突出，因为它易于使用且在低数据量条件下具有竞争力。尽管偏置调整可能带来前所未有的参数效率，但调整特定偏置项（如查询、键或值投影）与下游性能之间的关系仍不清楚。现有方法，如基于偏置变化幅度或经验费舍尔信息的方法，为选择适当的偏置项提供了有限的指导。
### Innovation
本文提出了一种选择需要调整的偏置项的方法，构成了我们高效偏置调整（BEFT）的基础。该方法通过广泛评估不同大语言模型（包括编码器和解码器架构）的效果，证明了其在各种下游任务中的有效性与优越性。
### Conclusion
我们的结果表明，我们的高效偏置调整方法在不同下游任务中展现出显著的有效性和优越性，包括分类、多项选择以及生成任务。
## 294. `cs.CL` - 视觉定位的奇妙案例：对于基于语音和文本的语言编码器的不同影响 [PDF](https://arxiv.org/pdf/2509.15837), [HTML](https://arxiv.org/abs/2509.15837)
### Authors
Adrian Sauter,Willem Zuidema,Marianne de Heer Kloots
### Background
本文探讨了视觉信息在训练中如何影响基于音频和文本的深度学习模型的语言处理。研究发现了语音编码器和文本编码器在视觉定位影响下的内部表示存在显著不同的表现。具体而言，在全局表示比较中，视觉定位增加了口头语言和书面语言表示之间的对齐，但主要是通过增强词义的编码。进一步的聚类分析显示，即使在视觉定位的情况下，语音表示仍然主要受到音素的影响，而视觉定位没有提高基于文本的表示的语义区分性。
### Innovation
该研究发现，视觉定位对基于语音和文本的语言编码器的影响存在显著差异，这为未来开发更有效的语音模型整合视觉启发式语义的方法提供了重要信息。之前的研究可能更多关注文字处理，而没有充分注意到语音处理的独特性。通过这种方法，研究者希望更好地理解这两种语言编码器的特点，并为它们的进一步优化提供指导。
### Conclusion
该研究发现，视觉定位增加了口头语言和书面语言表示之间的对齐，但主要是通过增强词义的编码而不是音素。尽管增强视觉定位有助于口头语言编码器，但对文本编码器的影响并不显著，尤其是在语义区分性方面。这表明，未来在强化语音模型以包含视觉启发式语义方面，可以针对各自的特点进行优化设计。
## 295. `cs.CL` - 基于多模态基础模型的多目标学习会话级口语评估 [PDF](https://arxiv.org/pdf/2509.16025), [HTML](https://arxiv.org/abs/2509.16025)
### Authors
Hong-Yun Lin,Jhen-Ke Lin,Chung-Chun Wang,Hao-Chien Lu,Berlin Chen
### Background
口语评估（SLA）能够从自发口语中估计学习者的口语文.borderColor: #ccc;书写能力。随着第二语言英语学习者的增多，对可靠SLA的需求愈加迫切，而可靠的SLA是计算机辅助语言学习（CALL）中的关键组成部分。现有的努力往往依赖于级联管道，这容易导致错误传播，或者直接处理短期音频窗口的端到端模型，这些模型可能忽略了对话级的证据。
### Innovation
本文介绍了一种新颖的多模态基础模型方法，可以在一次处理中完成会话级评估。该方法结合了多目标学习和使用静音ASR模型的冻结语音先验，以声音感知校准方式进行联合学习，无需使用手工特征即可学习SLA的整体和特征级目标。通过联合处理L2说话者的整个回应会话，该模型在预测整体口语能力上表现出色。通过在Speak & Improve基准测试上进行的实验表明，本文提出的方法优于之前的级联系统状态，并展现出跨部分的一致性泛化，在CALL应用中生成了一种紧凑可部署的评分器。
### Conclusion
我们的实验结果表明，在CALL应用中，我们的方法不仅优于之前的级联系统，还展示了跨部分泛化能力，生成了一种紧凑可部署的评分器。
## 296. `cs.CL` - 最佳表现跨语言：跨语言奖励建模在数学推理中的应用 [PDF](https://arxiv.org/pdf/2509.15811), [HTML](https://arxiv.org/abs/2509.15811)
### Authors
Sara Rajaee,Rochelle Choenni,Ekaterina Shutova,Christof Monz
### Background
尽管大语言模型的推理能力在不断进步，但对于这些能力在多语言大语言模型中的表现差异以及不同语言之间是否能互相补充仍然不清晰。本研究旨在通过训练一个跨语言奖励模型来评估并提升多语言大语言模型的数学推理表现。
### Innovation
研究通过训练一个跨语言奖励模型来评估并排序不同语言生成的答案，展示了跨语言奖励模型相比于单语言奖励模型能显著提高数学推理能力，特别是在资源较少的情况下，尽管英语在多语言模型中表现最佳，但跨语言采样还能特别提升英语的表现。
### Conclusion
研究揭示了通过利用多种语言的互补优势来改进多语言推理的新机会。
## 297. `cs.CL` - Multi-Physics: 一个全面的中文多领域物理问题 multimodal LLMs 原理模型推理基准 [PDF](https://arxiv.org/pdf/2509.15839), [HTML](https://arxiv.org/abs/2509.15839)
### Authors
Zhongze Luo,Zhenshuai Yin,Yongxin Guo,Zhichao Wang,Jionghao Zhu,Xiaoying Tang
### Background
多模态大型语言模型（MLLMs）在逻辑推理方面取得了显著进步，但在诸如物理这样的专业科学领域中的应用仍存在显著的评估差距。现有的基准测试往往缺乏细致的学科覆盖、忽视详细的步骤推理过程，并且主要以英语为中心，无法系统地评估视觉信息的作用。因此，我们提出了 Multi-Physics 作为一项全面的基准测试，涵盖了 5 个难度级别，包含 1,412 个与图像相关的多选题，覆盖了包括高中物理在内的 11 个学科。
### Innovation
引入了 Multi-Physics 作为全面的多学科物理问题多模态 LLMs 推理基准，包括 5 个难度级别，1,412 个图像关联的多项选择题，覆盖了 11 个高中物理主题。使用双评估框架评估了 20 种不同的多模态 LLMs，分析了最终答案的准确性以及步骤推理的完整性。系统研究了难度级别和视觉信息对模型性能的影响。
### Conclusion
我们的工作不仅为社区提供了一个细致的资源，也为分析最先进的多模态 LLMs 的多模态推理过程提供了一个稳健的方法。我们的数据集和代码已经开源：this https URL。
## 298. `cs.CL` - 重新定义会议摘要：基于事实的总结和通过问题实现个性化 [PDF](https://arxiv.org/pdf/2509.15901), [HTML](https://arxiv.org/abs/2509.15901)
### Authors
Frederic Kirstein,Sonu Kumar,Terry Ruas,Bela Gipp
### Background
使用大规模语言模型（LLMs）进行会议摘要仍然容易出错，常常产生幻觉、遗漏和不相关的信息。传统的方法在生成摘要时，难以保证准确性和个性化，因此需要一种新的框架来提升摘要的质量，特别是在控制、忠实程度和个性化方面。
### Innovation
该研究提出了一个模块化的管道——FRAME，它将摘要任务重新定义为语义增强任务。FRAME通过提取和评分关键事实，然后按照主题组织，最终丰富大纲形成摘要。此外，研究引入了SCOPE（“大声解释”协议），在选择内容之前要求模型回答九个问题，以提高个性化。最后，研究设计了P-MESA框架，这是一种多维度、无需参考的评价框架，用于评估摘要是否适合目标读者，从而有效地识别错误实例，并与人类的严重度评级高度一致。
### Conclusion
FRAME减少了幻觉和遗漏，而SCOPE提高了知识匹配和目标一致性。研究结果表明，重新思考摘要生成的方法可以提升控制、忠实度和个性化，为未来的会议摘要生成提供了新的视角和方法。
## 299. `cs.CL` - 不确定性的评分：具有校准不确定性的大语言模型用于自动作文评估 [PDF](https://arxiv.org/pdf/2509.15926), [HTML](https://arxiv.org/abs/2509.15926)
### Authors
Ahmed Karim,Qiao Wang(Judy),Zheng Yuan
### Background
自动作文评分（AES）系统在一些公共基准上获得了与人类近乎一致的评分，但在实际应用，尤其是在高风险考试中，采用率仍然有限。主要障碍在于大多数模型仅输出单一分数，而不提供任何置信度或解释。因此，本研究旨在通过采用无分布假设的容贯预测技术，为任何分类器提供集合输出和形式化的覆盖保证来解决这一问题。使用开源大语言模型（Llama-3 8B 和 Qwen-2.5 3B）在三个不同语料库（ASAP, TOEFL11, Cambridge-FCE）上进行微调，并采用90%的风险水平进行校准。
### Innovation
这项研究是首次将容贯预测和不确定性感知准确度（UAcc）结合用于作文评分。研究中，开源、中等规模的大型语言模型经过微调和校准后，能够稳定地达到所需的覆盖目标同时保持预测集的紧凑性，表明开源中等大小的大语言模型已经能够支持教师在场的自动评分过程。该研究还讨论了扩展和更大规模用户研究作为未来的工作方向。
### Conclusion
这些校准后的模型在保持预测集紧凑的同时持续达到所需的覆盖目标，表明开源、中等规模的大型语言模型已能够支持教师参与的自动化作文评分。研究还讨论了这一点在未来的大规模测试中的扩展和广泛用户研究的可能性。
## 300. `cs.CL` - 依赖情况：在最少背景信息下利用常识知识解决指代模糊 [PDF](https://arxiv.org/pdf/2509.16107), [HTML](https://arxiv.org/abs/2509.16107)
### Authors
Lukas Ellinger,Georg Groh
### Background
含糊不清的词汇或不明确的指代需要交谈双方利用共享的背景知识和常识来解决，这通常发生在多轮对话中。现有研究表明，大语言模型（LLMs）在利用常识解决多轮对话中的指代模糊方面存在困难。本研究旨在系统性地探索LLMs是否能够利用常识来解决指代模糊，并分析在模糊不清的情况下，简化语言请求如何影响这一能力。
### Innovation
研究使用了新的多语言评价数据集，测试了一系列不同的LLM（DeepSeek v3, GPT-4o, Qwen3-32B, GPT-4o-mini, Llama-3.1-8B），并使用LLM-as-Judge和人类注释来检测其行为。研究发现，当前的LLMs难以有效解决指代模糊，容易倾向于选择单一解读或涵盖所有可能的指代，而不是寻求澄清或采取策略化的方法。在简化语言提示的情况下，这一限制更加明显，导致常识推理和多样化的回应策略的使用大幅减少。通过直接偏好优化对Llama-3.1-8B进行微调，显著改善了各种请求类型中的模糊性解决。
### Conclusion
当前的LLMs在处理指代模糊方面存在局限，即使在微调后也难以有效应对。这些结果强调了在提高LLMs处理指代模糊能力方面进行高级微调的重要性，以确保其在不同沟通风格下的稳健性能。
## 301. `cs.CL` - 思考、表达然后发言：连接复杂思想与可理解话语 [PDF](https://arxiv.org/pdf/2509.16028), [HTML](https://arxiv.org/abs/2509.16028)
### Authors
Sang Hoon Woo,Sehun Lee,Kang-wook Kim,Gunhee Kim
### Background
越来越多的对话系统利用大型语言模型（LLMs）的优势来增强其推理能力。然而，直接将LLMs应用于口语交流中，往往会因为最佳文本和口语传递之间的不匹配而导致效果不佳。现有方法虽试图使LLMs适应产生口语友好的输出，但其对推理性能的影响尚未被充分探索。研究背景在于解决当前对话系统在将复杂思想有效转化为实际对话中的问题，特别是在保持LLMs推理能力的同时，改善语音输出的自然度和简洁性。
### Innovation
论文提出了Think-Verbalize-Speak框架，该框架通过将推理和口语表达分离，确保LLMs的全面推理能力得以保留。核心是引入了一种名为ReVerT的延迟效率可增量和异步总结的口语化方法。实验表明，该方法能够在保持推理性能的同时，增强语音输出的自然度和简洁性。这种方法的优势在于理论上的推理能力得到保留，而实际输出则更加自然与高效。
### Conclusion
实验结果表明，该方法在多个基准测试中提升了语音的自然度和简洁性，且对推理性能影响较小。同时，作者提供了包含数据集和源代码的项目页面，以便其他研究者进一步研究和使用。
## 302. `cs.CL` - DiEP: 通过对可微专家剪枝实现自适应混合专家压缩 [PDF](https://arxiv.org/pdf/2509.16105), [HTML](https://arxiv.org/abs/2509.16105)
### Authors
Sikai Bai,Haoxi Li,Jie Zhang,Zicong Hong,Song Guo
### Background
尽管Mixture-of-Experts (MoE) 模型取得了显著的进步，但这些模型的规模不断扩大却带来了巨大的内存和存储挑战。现有的MoE剪枝方法通常在所有层中采用均匀稀疏性，导致在不同MoE层中专家冗余度不同的情况下出现次优结果和性能下降。
### Innovation
本文提出了一种新的非均匀剪枝策略，称为DiEP (Differentiable Expert Pruning)，该策略能够在层级别上自适应地调整剪枝率，并联合学习层间的重要性，有效地捕捉不同MoE层之间的不同冗余度。通过将全局离散搜索空间转换为连续空间，我们的方法能够处理指数增长的非均匀专家组合，从而实现自适应梯度剪枝。
### Conclusion
在五个先进的MoE模型上进行的广泛实验表明，我们的方法在各种NLP任务中具有有效性。特别是在混合8×7B模型上，DiEP 剪枝方式仅保留一半的专家就能保持约92％的原始性能，并在具有挑战性的MMLU数据集上优于其他剪枝方法最多7.1％的性能。
## 303. `cs.CL` - 局部最大值动力学在变压器中用于注意力及其渐近行为 [PDF](https://arxiv.org/pdf/2509.15958), [HTML](https://arxiv.org/abs/2509.15958)
### Authors
Henri Cimetière,Maria Teresa Chiri,Bahman Gharesifard
### Background
本文介绍了一种新的离散时间注意力模型——局部最大值动力学，它介于经典软最大动力学和硬最大动力学之间。在这个模型中，只有那些对给定标记具有最大影响的标记具有正值。这种模型保留了硬最大模型中均匀权重的特性，但通过引入对齐敏感性参数进一步放宽了邻域交互的限制，允许更可控的行为偏离纯粹的硬最大行为。证明了令牌状态凸包依然收敛于凸多面体，但由于其结构不再能够完全由最大对齐集描述，引入了静默集来捕捉接近顶点的标记的不变行为。这些集合对于理解系统在时间变化的对齐敏感性参数下的渐近行为至关重要。
### Innovation
本文的主要创新在于提出了一种局部最大值动力学模型，该模型通过非均匀方式（通过调整对齐敏感性参数）处理注意力机制中的令牌交互。相比传统的软最大和硬最大模型，这种模型能够更灵活地控制邻居交互的影响，提供了对注意力机制在不对称情况下行为的更深入理解，并通过引入静默集中揭示了新的特性。
### Conclusion
本文的研究结果显示了局部最大值动力学模型不具有有限时间收敛性，并提供了时间变化、零值以及消失对齐敏感性参数下的行为结果。尽管没有直接达到硬最大模型的行为，但通过这系列研究，这些结果揭示了局部最大值动力学模型行为的渐近特性。此外，还通过古典意见动力学中的李雅普诺夫方法对收敛性进行了讨论，并指出了未来的研究方向。
## 304. `cs.CL` - CodeRAG：为检索增强仓库级代码补全寻找相关和必要的知识 [PDF](https://arxiv.org/pdf/2509.16112), [HTML](https://arxiv.org/abs/2509.16112)
### Authors
Sheng Zhang,Yifan Ding,Shuquan Lian,Shun Song,Hui Li
### Background
基于仓库的代码补全方法可以根据仓库中的广泛信息自动预测未完成的代码。近年来，代码大型语言模型(code LLMs)的发展推动了此类方法的发展，取得了显著的成果。尽管如此，这些方法仍然存在诸如查询构建不合适、单路径代码检索以及代码检索器与代码LLM之间错位的问题。
### Innovation
CodeRAG是一种专门为检索增强的仓库级代码补全设计的框架，旨在识别检索所需的相关和必要的知识。其核心组件包括基于逻辑概率的查询构建、多路径代码检索和偏好对齐的BestFit重排序。基于ReccEval和CCEval基准实验表明，CodeRAG显著且一致地超越了现有最先进的方法。
### Conclusion
CodeRAG在广泛的实验中展示了其显著的优越性，并解决了当前仓库级代码补全方法中的主要问题。源代码已在指定网址处公开。
## 305. `cs.CL` - 翻转课堂教学中口语讨论对话的学习分析 [PDF](https://arxiv.org/pdf/2301.12399), [HTML](https://arxiv.org/abs/2301.12399)
### Authors
Hang Su,Borislav Dzodzo,Changlun Li,Danyang Zhao,Hao Geng,Yunxiang Li,Sidharth Jaggi,Helen Meng
### Background
翻转课堂作为一种新的教学策略，近年来越来越受到重视。在翻转课堂中，学生在家观看录制的讲课视频，然后在课堂上进行基于小组的问题解决讨论。师生之间的口语讨论对话中蕴含了丰富的学生学习过程和进展的信息。
### Innovation
本文创新性地通过多种工具提取口语讨论对话的特征，并采用定制化的处理技术，对来自翻转课堂的面对面讨论对话进行了统计分析，旨在探究与小组学习结果相关的指标，并利用机器学习算法预测小组学习结果为高、中、低三种等级，准确率高达78.9%，展示了从翻转课堂小组讨论对话中自动预测学习结果的可行性。
### Conclusion
研究表明，通过提取翻转课堂中口语讨论对话的特征，并利用数据统计和机器学习算法可以有效地预测小组学习结果，这在一定程度上验证了翻转课堂中学习分析的可行性和有效性。
## 306. `cs.CL` - 文化视域：探索大语言模型文化理解的维度 [PDF](https://arxiv.org/pdf/2509.16188), [HTML](https://arxiv.org/abs/2509.16188)
### Authors
Jinghao Zhang,Sihang Jiang,Shiwei Guo,Shisong Chen,Yanghua Xiao,Hongwei Feng,Jiaqing Liang,Minggui HE,Shimin Tao,Hongxia Ma
### Background
随着大语言模型（LLMs）在多元化文化环境中的广泛应用，对其文化理解能力的评估变得至关重要，以确保应用程序的可信度和文化一致性。然而，现有的大多数基准测试缺乏全面性，并且难以在不同的文化背景下进行扩展和适应，因为它们的框架往往缺乏来自成熟文化理论的指导，且倾向于依赖专家驱动的手动注释。
### Innovation
本文提出了CultureScope——迄今为止最全面评估LLMs文化理解能力的评价框架。受到文化冰山理论的启发，设计了一种新颖的维度分类方案，包含3层和140个维度，该方案能够指导针对任何语言和文化的特定文化知识库及其对应的评估数据集的自动构建。实验证明该方法能够有效评估文化理解，并揭示了现有大型语言模型在文化理解上存在欠缺，且仅仅增加多语言数据未必能提升文化理解能力。
### Conclusion
我们的方法有效地评估了文化理解，结果显示现有的大型语言模型在文化理解上存在欠缺，并且单纯增加多语言数据并不一定能提高文化理解。所有代码和数据文件均在此处提供：[相关链接]。
## 307. `cs.CL` - Video2Roleplay: 一种由视频引导的角色扮演代理的多模态数据集和框架 [PDF](https://arxiv.org/pdf/2509.15233), [HTML](https://arxiv.org/abs/2509.15233)
### Authors
Xueqiao Zhang,Chao Zhang,Jingtao Xu,Yifan Zhu,Xin Shi,Yi Yang,Yawei Luo
### Background
角色扮演代理（RPAs）因其能够模拟沉浸式和互动性强的角色而逐渐受到关注。现有的方法主要集中在静态的角色配置文件上，而忽视了人类固有的动态感知能力。
### Innovation
为解决这一问题，论文引入了动态角色配置文件的概念，通过将视频模态纳入RPAs来补足这一空白。基于此，构建了一个包含60,000个视频和700,000个对话的大型高质量数据集——Role-playing-Video60k，并开发了一个结合了动态和静态角色配置文件表征的全面的RPA框架，其中包括适应性时间采样。
### Conclusion
实验结果表明了该框架的有效性，并突出了动态角色配置文件在开发RPAs中的重要性。
## 308. `cs.CL` - 超越单一评分：基于分解标准的LLM响应评估 [PDF](https://arxiv.org/pdf/2509.16093), [HTML](https://arxiv.org/abs/2509.16093)
### Authors
Fangyi Yu,Nabeel Seedat,Dasha Herrmannova,Frank Schilder,Jonathan Richard Schwarz
### Background
在法律或医学等高风险领域中，对长格式答案进行评估仍然是一个基本挑战。标准度量标准如BLEU和ROUGE无法捕捉语义正确性。当前的基于大型语言模型（LLM）的评估器往往会将答案质量的细腻方面简化为一个统一的综合评分。因此，我们需要一个能够更好区分答案质量方面的评估框架。
### Innovation
我们引入了一个分解的LLM评估框架DeCE，它将精确度（事实准确性和相关性）和召回率（所需概念的覆盖面）分离，并使用从黄金答案要求中自动提取的实例特定标准来评估。DeCE具有模型无关性和跨领域的适应性，无需预定义的分类或手工制作的评分标准。DeCE在实际法律问答任务中的评估结果与专家判断高度相关（相关系数r=0.78），远高于传统度量标准（r=0.12）、点对点LLM评分（r=0.35）和现代多维度评估器（r=0.48）。它还揭示了可解释的情景：通用模型更倾向于召回，而专门化的模型更倾向于精确。
### Conclusion
DeCE提供了一个在专家领域中具有可解释性和可操作性的LLM评估框架，仅11.95％的LLM生成标准需要专家修订，突显了DeCE的可扩展性。
## 309. `cs.CL` - RPG: 一个统一且可扩展的代码库生成的存储库规划图 [PDF](https://arxiv.org/pdf/2509.16198), [HTML](https://arxiv.org/abs/2509.16198)
### Authors
Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang
### Background
大型语言模型在函数和文件级别代码生成方面表现出色，但在从零开始生成完整的仓库方面仍面临重大挑战。这一过程要求在提案级和实施级阶段之间进行连贯和可靠的规划，而自然语言由于表达的模糊性和冗长性，不适合准确地表示复杂的软件结构。为解决这一问题，引入了存储库规划图（RPG），这是一种持久表示，能够统一提案级和实施级的规划，通过在一个图中编码能力、文件结构、数据流和函数，替换掉模糊的自然语言，使长期规划和可扩展的仓库生成成为可能。基于RPG，开发了ZeroRepo，这是一种图驱动的从零开始生成仓库的框架，分为三个阶段：提案级规划和实施级细化以构建图，随后是基于图的代码生成和测试验证。
### Innovation
引入了存储库规划图（RPG），这是一种持久表示，在一个图中统一编码了能力、文件结构、数据流和函数，替代了模糊自然语言，以便进行长期规划和大规模的仓库生成。进一步开发了ZeroRepo，这是一种图驱动的从零开始生成仓库的框架，通过多阶段流程实现从零开始生成代码库的过程，包括提案级规划、实施级细化、及基于图的代码生成与测试验证。ZeroRepo在六个项目基准（RepoCraft）上的评估显示，它产生了平均每仓库36K行代码，是最强基线Claude Code的约3.9倍，其他基线的64倍。并且，在功能覆盖率和通过率方面达到81.5%和69.7%，分别比Claude Code高出27.3和35.8个百分点。
### Conclusion
RPG模型复杂的依赖性，逐步提升更高级的规划能力，通过接近线性扩展增强LLM对仓库的理解，从而加速了代理的定位。
## 310. `cs.CL` - Fleming-R1：通过强化学习实现专家级医学推理 [PDF](https://arxiv.org/pdf/2509.15279), [HTML](https://arxiv.org/abs/2509.15279)
### Authors
Chi Liu,Derek Li,Yan Shu,Robin Chen,Derek Duan,Teng Fang,Bryan Dai
### Background
虽然大型语言模型在医学应用中表现出了希望，但在临床推理方面达到专家水平仍具有挑战性，这主要是因为需要更加精确的答案和透明的推理过程。现有模型在这方面面临的主要难题包括难以覆盖未充分代表的疾病、药物以及多跳推理链等问题。为了应对这一挑战，本文介绍了Fleming-R1模型。
### Innovation
Fleming-R1模型通过以下三个创新来实现可验证的医学推理：1）推理导向的数据策略（RODS）：结合经过筛选的医学问答数据集和知识图谱引导的合成方法，从而提高对未充分代表的疾病、药物以及多跳推理链的覆盖范围；2）链式推理（CoT）冷启动：从教师模型中提取高质量的推理路径，建立强大的推理先验；3）带验证性奖励的两阶段强化学习框架（RLVR）：使用组相对策略优化方法，结合核心推理技能的整合与持续性故障模式的适应性挖掘，以提高模型的整体推理能力。
### Conclusion
Fleming-R1模型在多种医学基准测试中显示出显著的参数效率提升：7B变体优于许多更大规模的基线；32B模型与GPT-4o接近，且持续优于强大的开源替代品。这表明结构化数据设计、问题导向的初始化以及可验证的强化学习有助于超越简单的准确性优化，推动医学推理的发展。该模型已公开发布，以促进透明、可重复和可审计的医学AI进步，确保在高风险的临床环境中安全部署。
## 311. `cs.CL` - M-PACE: Mother Child Framework for Multimodal Compliance [PDF](https://arxiv.org/pdf/2509.15241), [HTML](https://arxiv.org/abs/2509.15241)
### Authors
Shreyash Verma,Amit Kesari,Vinayak Trivedi,Anupam Purwar,Ratnesh Jamidar
### Background
在跨领域的多模态内容中确保符合品牌、法律或特定平台的合规标准越来越成为一个复杂的挑战。传统的合规框架通常依赖于分散的、分阶段的流水线，这些流水线整合了图像分类、文本提取、语音转录、手工编写的检验以及基于规则的合并模块。这种架构的碎片化增加了操作负担，限制了可扩展性，并阻碍了对动态指导方针的高效适应。随着多模态大型语言模型（MLLMs）的出现，有可能将这些工作流程统一到一个通用框架中，该框架可以联合处理视觉和文本内容。
### Innovation
我们提出了一个框架——多模态参数无干扰合规引擎（M-PACE），设计用于在单一过程中评估视觉语言输入的属性。我们采用了母子MLLM结构，这表明较强的母亲模型可以评估较小的子模型输出，从而显著减少对人类审核者的依赖，促进了质量控制的自动化。M-PACE能够以较低的推理成本评估超过15个合规相关属性，并利用一个包含增强样本的、由人类注解的基准来支持结构化的评估。我们还揭示了成本与输出质量之间的权衡，表明M-PACE在实时部署中实现了良好的性能平衡。
### Conclusion
在广告数据集上进行了测试，M-PACE的推理成本减少了超过31倍，最有效的模型（由母模型选择的Gemini 2.0 Flash子模型）每张图像的成本为0.0005，而Gemini 2.5 Pro的成本为0.0159，精度相当。M-PACE在实际部署中的实时部署体现出成本与输出质量之间的良好平衡。
## 312. `cs.CL` - 超越言语：借助非言语线索提升欲望、情感和情绪识别 [PDF](https://arxiv.org/pdf/2509.15540), [HTML](https://arxiv.org/abs/2509.15540)
### Authors
Wei Chen,Tongguan Wang,Feiyue Xue,Junkai Li,Hui Liu,Ying Sha
### Background
欲望作为一种驱动人类行为的意愿，与情绪和情感密切相关。多媒体学习已经推动了情绪和情感识别的发展，但专门针对人类欲望理解的多媒体方法仍然很少。现有的情感分析方法主要强调口头线索，而忽略了作为补充非口头线索的图像。因此，本文探讨了当前研究中的不足之处，并提出了一种对齐图文模态的对称双向多媒体学习框架，用于识别欲望、情感和情绪，旨在通过互惠引导提升图像模态的意图相关表示提取能力。
### Innovation
本文提出了一种新的对称双向多媒体学习框架，该框架通过互导方式增强了文本和图像之间以及局部和全局表示中的深层跨模态交互能力。通过使用低分辨率图像获取全局视觉表示来跨模态对齐，同时使用高分辨率图像分割并应用掩码图像建模来增强提取精细局部特征的能力。此外，还引入了文本引导的图像解码器和图像引导的文本解码器来促进图像信息的深层跨模态交互。在MSED数据集上进行了实验验证，该数据集包含欲望理解基准以及情感和情绪识别，结果表明与现有最佳方法相比，本文方法在欲望理解（F1得分提高1.1%）、情感识别（F1得分提高0.6%）和情感分析（F1得分提高0.9%）上均实现了显著提升。这些发现验证了所提出方法的有效性，并通过混合尺度图像策略减少了感知收益与计算成本之间的权衡。
### Conclusion
我们提出的方法在MSED数据集上的实验结果表明，与现有的最佳方法相比，所得方法在欲望理解、情感识别和情感分析上分别取得了1.1%、0.6%和0.9%的F1得分提高，充分验证了我们的方法的有效性。此外，还提供了一个代码链接，以促进进一步的研究和应用。
## 313. `cs.CL` - SightSound-R1: 视觉到音频语言模型的跨模态推理蒸馏 [PDF](https://arxiv.org/pdf/2509.15661), [HTML](https://arxiv.org/abs/2509.15661)
### Authors
Qiaolin Wang,Xilin Jiang,Linyang He,Junkai Wu,Nima Mesgarani
### Background
虽然大型音频-语言模型（LALMs）已经展示了在音频理解方面最先进的能力，但在复杂声音场景中的推理能力仍然落后于大型视觉-语言模型（LVLMs）。这主要是因为缺乏大规模的逐步骤音频数据来训练LALMs进行推理。研究者通过SightSound-R1提出了一个跨模态蒸馏框架，该框架利用更强的LVLM教师的知识来提升较弱的LALM学生模型的推理能力，重点在于音频-视觉问题回答（AVQA）数据集。
### Innovation
SightSound-R1提出了一种跨模态蒸馏框架，通过三个核心步骤：(i) 在测试阶段生成音频聚焦的推理步骤链（CoT），(ii) 音频相关验证来过滤幻觉，(iii) 使用监督微调（SFT）和基于群体相对策略优化（GRPO）的蒸馏管道来提升LALM模型的性能。该框架的表现优于预先训练的和仅标签蒸馏的基线模型，在领域内的AVQA测试集和未见过的听觉场景中都显示出更好的推理性能。
### Conclusion
SightSound-R1的有效性证明了视觉推理可以被有效地转移到音频模型中，并且随着大量音频-视觉数据的可用性，这种技术可以被扩展和改进。
## 314. `cs.CL` - ViSpec: 使用视觉感知投机解码加速视觉语言模型 [PDF](https://arxiv.org/pdf/2509.15235), [HTML](https://arxiv.org/abs/2509.15235)
### Authors
Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen
### Background
投机解码是一种广泛应用于大型语言模型（LLMs）加速推理的技术，但在视觉语言模型（VLMs）中的应用相对较少，现有方法仅实现了有限的速度提升（<1.5倍）。随着多模态能力在大型模型中的重要性日益突出，这一差距变得越来越重要。尽管较小的草稿模型难以有效地逐层过滤冗余的图像信息而不影响文本理解，但大型视觉语言模型被认为能够有效完成这一任务。
### Innovation
本文提出了专门为VLMs设计的Vision-Aware Speculative Decoding（ViSpec）框架。ViSpec通过一个轻量级的视觉适配模块将图片标记压缩成紧凑表示，并将其无缝整合到草稿模型的注意力机制中，同时保持原始的图像位置信息。此外，ViSpec还提取每个输入图片的全局特征向量，并将其添加到所有后续的文本标记中，以增强多模态的一致性。为了克服缺少长辅助响应的多模态数据集，研究人员通过重新利用现有数据集并使用目标VLM生成扩展输出来构建专门的训练数据集。训练策略还减少了草稿模型直接利用目标模型隐藏状态的风险，以避免在仅使用目标模型输出进行训练时发生短路学习。
### Conclusion
广泛的实验验证了ViSpec的有效性，据我们所知，它首次实现了视觉语言模型投机解码显著的速度提升。
## 315. `cs.CL` - KITE: 使用核化和信息论范例的上下文学习 [PDF](https://arxiv.org/pdf/2509.15676), [HTML](https://arxiv.org/abs/2509.15676)
### Authors
Vaibhav Singh,Soumya Suvra Ghosal,Kapu Nirmal Joshua,Soumyabrata Pal,Sayak Ray Chowdhury
### Background
In-context learning (ICL)作为一种利用少量任务特定示例（嵌入在提示中）来适应大型语言模型（LLMs）到新任务和数据稀缺任务的强大范式已经出现。然而，由于LLMs的上下文大小限制，一个基本问题浮现出来：如何选择最佳的示例来最大化特定用户查询的性能？尽管最近邻方法（如KATE）已经广泛应用于这个问题，但它们受到高维嵌入空间中的泛化性差和多样性不足的限制。本文从信息理论驱动的原理出发研究ICL中的示例选择问题，将其建模为一个特定查询的优化问题：从较大型的示例库中选择一个子集以最小化特定查询的预测误差。
### Innovation
本文提出了一种原理性和信息论驱动的方法（KITE），以查询特定的方式选择示例，并为此问题构建了一个近似子模态的代理目标，使使用贪婪算法具有近似保证。该方法通过（i）使用核技巧在高维特征空间中操作而无需显式映射，以及（ii）引入基于最优设计的正则化项来鼓励选定的示例多样性来进一步增强。体现实验结果显示，KITE在分类任务上显著优于标准检索方法，并强调了结构感知和多样示例选择的好处，特别是在现实世界的标签稀缺场景中实现ICL方面。
### Conclusion
在ICL中，KITE通过构建一个原理性和信息论驱动的查询特定优化目标，实现了显著的性能提升。这种方法不仅考虑了特定查询的准确性，还通过多样化选取的示例提升了泛化性能。实验证明了这种方法在多种具体应用场景下的有效性。
## 316. `cs.CL` - 小型专家模块增强的语言模型足以进行超参数调整 [PDF](https://arxiv.org/pdf/2509.15561), [HTML](https://arxiv.org/abs/2509.15561)
### Authors
Om Naphade,Saksham Bansal,Parikshit Pareek
### Background
在机器学习（ML）管道中，超参数调整（HPT）是一个必要的步骤，但随着模型规模的增大，HPT变得越来越计算密集且不透明。最近，大型语言模型（LLMs）被探索用于执行HPT，但由于效率和算力的限制，大多数已经开发的方法依赖于超过100亿参数的模型。因此，如何高效、可靠地使用小型语言模型进行HPT成为了一个重要问题。本文探讨了通过提出一个基于小型LLMs的专家模块框架来解决这一问题。
### Innovation
本文提出了一种基于小型LLMs的专家模块框架，专门用于HPT。核心组件是轨迹上下文总结器（TCS）, 它能够将原始训练轨迹转化为结构化的上下文信息，使得小型LLMs能够在仅10个试验的机会成本下准确分析优化进度，性能表现可与100亿参数以上的模型媲美。
### Conclusion
通过使用两种本地运行的小型LLMs（phi4：reasoning14B和qwen2.5-coder:32B），以及一个10试次预算，结合TCS模块的HPT管道在六个不同任务上的平均性能表现仅比GPT-4高出约0.9个百分点。这表明小型模型结合了专家模块后，在HPT中提供了足够好的性能，同时具有成本和效率的优势。
## 317. `cs.CL` - 通过张量分解提高视觉-语言模型鲁棒性的防御策略：对抗性攻击的防御 [PDF](https://arxiv.org/pdf/2509.16163), [HTML](https://arxiv.org/abs/2509.16163)
### Authors
Het Patel,Muzammil Allie,Qian Zhang,Jia Chen,Evangelos E. Papalexakis
### Background
视觉语言模型（VLMs）在多模态理解方面表现出色，但容易受到对抗性攻击的影响。现有的防御措施往往需要昂贵的再训练或显著的架构变更。
### Innovation
引入了一种轻量级的基于张量分解的防御方法，适用于任何预训练的VLM，无需再训练。通过分解并重构视觉编码器表示，该方法过滤出对抗噪声同时保留意义。实验结果显示了改进的鲁棒性，在Flickr30K上恢复了12.3%的性能，将Recall@1准确率从7.5%提高到19.8%，在COCO上恢复了8.1%的性能，将准确率从3.8%提高到11.9%。分析表明，最适合的方法是张量火车分解，其低秩（8-32）和低残差强度（α=0.1-0.2）。
### Conclusion
该方法是一种实际的、即插即用的解决方案，具有较低的开销，适用于现有的VLMs。
## 318. `cs.CL` - 土耳其语的自动词汇简化 [PDF](https://arxiv.org/pdf/2201.05878), [HTML](https://arxiv.org/abs/2201.05878)
### Authors
Ahmet Yavuz Uluslu
### Background
Turkish 是一种形态丰富且粘着的语言，与其他语言相比，需要处理独特的语言特征。它在可用于资源和工业强度工具方面较为匮乏，因此，进行文本简化任务更具挑战性。现有的文本简化工作依赖于手动创建的简化语料库和全面的 NLP 工具，能够从单词和句子层面分析目标文本。
### Innovation
作者提出了一个基于预训练表示模型 BERT 的新文本简化流水线，并结合形态特征来生成语法正确且语义适当的单词级别简化。
### Conclusion
这是第一个针对土耳其语的自动词典简化系统。该研究对于低资源语言的文本简化具有重要意义，通过利用 BERT 和形态学特征，提高了简化文本的质量和准确度。
## 319. `cs.CL` - EHR-MCP: Model Context Protocol下的大型语言模型在医院环境中的临床信息检索评估 [PDF](https://arxiv.org/pdf/2509.15957), [HTML](https://arxiv.org/abs/2509.15957)
### Authors
Kanato Masayoshi,Masahiro Hashimoto,Ryoichi Yokoyama,Naoki Toda,Yoshifumi Uwamino,Shogo Fukuda,Ho Namkoong,Masahiro Jinzaki
### Background
大型语言模型（LLMs）在医学领域显示出潜力，但由于访问医院电子健康记录（EHR）系统的限制，其在医院的实际部署受到限制。Model Context Protocol (MCP) 允许将LLMs与外部工具集成，从而解决这一问题。本研究旨在评估通过MCP连接到EHR数据库的LLM能否在现实的医院环境中自主检索临床相关信息。
### Innovation
研究开发了EHR-MCP框架，结合了定制的MCP工具和医院EHR数据库，并使用GPT-4.1通过LangGraph ReAct智能体与其交互。研究通过感染控制团队使用的真实场景定义了六个任务，并通过回顾性分析八名患者的讨论记录来评估LLM的性能，结果显示LLM在简单任务中几乎完美地执行了正确的MCP工具。
### Conclusion
研究发现，LLMs能够通过MCP工具在医院环境中获取临床数据，简单任务的性能达到了几乎完美的水平，但在复杂任务中存在挑战。EHR-MCP提供了一种安全且一致的数据访问基础设施，并可能作为医院AI代理的基础。未来的研究应超越数据检索，扩展到推理、生成和临床影响评估，为将生成式AI有效整合到临床实践中铺平道路。
## 320. `cs.CL` - 伊斯兰文本多语言信息检索高效且多功能模型：在实际场景中的开发与部署 [PDF](https://arxiv.org/pdf/2509.15380), [HTML](https://arxiv.org/abs/2509.15380)
### Authors
Vera Pavlova,Mohammed Makhlouf
### Background
尽管在多语言信息检索（MLIR）领域取得了一定进展，但在研究与实际应用部署之间仍存在显著差距。许多研究仅在孤立环境中评估MLIR性能，限制了其在实际场景中的适用性。本研究利用库存在的多语言语料库的独特特征，旨在探讨开发服务于伊斯兰领域用户跨语言信息需求的最适策略，适用于多种语言环境下的即时检索系统。通过准备11种检索模型，采用四种训练方法：单语训练、跨语言训练、所有语言翻译训练以及结合跨语言与单语技术的创新混合方法。领域内数据集评估表明，混合方法在多种检索场景中展现出较好的结果。此外，研究还详细分析了不同训练配置对嵌入空间的影响及其对多语言检索有效性的含义。最后，讨论了部署考虑，强调了部署单个多功能轻量级模型以提高成本效益的重要性，适用于实际场景中的多语言信息检索应用。
### Innovation
1. 利用库存在的多语言语料库的独特特性来评估MLIR策略的有效性。2. 开发了11种多语言检索模型，并采用四种训练方法进行对比。3. 提出了结合跨语言与单语技术的创新混合方法。4. 详细分析了不同训练配置对嵌入空间的影响及其对多语言检索有效性的含义。5. 强调部署单个多功能轻量级模型的成本效益，并提高了实际应用的灵活性和减低成本
### Conclusion
通过开发11种多语言检索模型，并采用单语训练、跨语言训练、所有语言翻译训练和混合方法，混合方法在跨语言检索场景中表现出了较好的效果。不同训练配置对嵌入空间有显著影响，这揭示了其对多语言检索有效性的潜在意义。本研究表明，为伊斯兰领域的用户提供跨语言信息检索的解决方案是可行的，且部署单个多功能轻量级模型具有良好的成本效益，适用于实际的多语言信息检索应用。
## 321. `cs.CL` - EmoHeal:一种从细微情感中进行个性化治疗性音乐检索的端到端系统 [PDF](https://arxiv.org/pdf/2509.15986), [HTML](https://arxiv.org/abs/2509.15986)
### Authors
Xinchen Wan,Jinhua Liang,Huan Zhang
### Background
现有的数字心理健康工具往往忽视了日常挑战背后细微的情感状态。例如，睡前焦虑影响了全球超过15亿人，但当前的方法大多静态且‘一刀切’，未能适应个人需求。因此，本文介绍了EmoHeal系统，这是一种端到端的个性化支持叙事系统，通过先进的深度学习技术和音乐疗法原则（如GEMS，iso原则），实现了情感检测和治疗性音乐的个性化检索，从而改善用户的情绪状态
### Innovation
EmoHeal系统通过使用微调后的XLM-RoBERTa模型检测用户文本中的27种细微情感，并通过基于音乐疗法原则的知识图谱将这些情感映射到音乐参数。同时，使用CLAMP3模型检索视听内容，引导用户从当前状态向更平静的状态过渡。该系统展示了对用户情绪和情感识别准确性的显著改善，验证了其细腻的情感分析方法的有效性
### Conclusion
通过对40名参与者的研究，EmoHeal系统显示出了显著的支持性效果，参与者的抑郁情绪得到了显著改善，情感识别准确性得到了高度评价。该研究证实了理论驱动、情感感知的数字心理健康工具的可行性，并为以音乐疗法原则为基础的AI系统设计提供了可扩展的蓝图
## 322. `cs.CL` - MANZANO: 一种具有混合视觉标记器的简单且可扩展的统一多模态模型 [PDF](https://arxiv.org/pdf/2509.16197), [HTML](https://arxiv.org/abs/2509.16197)
### Authors
Yanghao Li,Rui Qian,Bowen Pan,Haotian Zhang,Haoshuo Huang,Bowen Zhang,Jialing Tong,Haoxuan You,Xianzhi Du,Zhe Gan,Hyunjik Kim,Chao Jia,Zhenbang Wang,Yinfei Yang,Mingfei Gao,Zi-Yi Dou,Wenze Hu,Chang Gao,Dongxu Li,Philipp Dufter,Zirui Wang,Guoli Yin,Zhengdong Zhang,Chen Chen,Yang Zhao,Ruoming Pang,Zhifeng Chen
### Background
统一多模态大型语言模型（LLMs）既能理解又能生成视觉内容，具有巨大潜力。然而，现有开源模型在这些能力之间往往存在性能取舍。Manzano 通过结合混合图像标记器和精心筛选的训练食谱，提供了一个简单且可扩展的统一框架，显著减少了这种权衡。
### Innovation
Manzano 借助一个统一的自回归 LLM 和一个共同的语义空间内的两个轻量级适配器，实现图像到文本理解与文本到图像生成，同时通过统一训练数据集，实现了理解和生成能力的联合学习。该模型使用图像标记器共同构建，与专门模型相比，特别是在包含大量文本的评估中，Manzano 表现竞争。
### Conclusion
Manzano 在统一模型中达到了领先结果，模型大小的扩展验证了我们的混合标记器设计选择，同时任务冲突最小，表现出一致的增益。
## 323. `cs.CL` - VoXtream：具有极低延迟的全流文本到语音 [PDF](https://arxiv.org/pdf/2509.15969), [HTML](https://arxiv.org/abs/2509.15969)
### Authors
Nikita Torgashov,Gustav Eje Henter,Gabriel Skantze
### Background
文本到语音（TTS）系统通常需要较长的延迟时间来处理音频，而VoXtream旨在解决这一问题，提供从第一个单词开始即刻发声的实时TTS系统。它使用单调对齐方案和动态展望机制，直接将输入的音素映射到音频标记，实现了极低的初始延迟，仅为102 ms，是目前最快的实时TTS系统之一。尽管训练数据量中等，但该系统在多个指标上仍能匹配或超越更大型的基准模型，同时在输出流和全流模式下提供具有竞争力的音质。
### Innovation
VoXtream是一款完全自回归、零样本的实时流式TTS系统。其创新点在于：1) 直接从首个单词开始实时发声；2) 使用单调对齐方案和动态展望机制直接映射音素到音频标记，无需延迟；3) 通过增量音素转换器、时间转换器预测语义和时长标记，以及深度转换器生成声学标记来构建系统；4) 达到极低的初始延迟（102 ms）；5) 尽管使用中等规模的训练数据，但在多个评估指标上仍能达到或超越更大型的基准模型，同时保持较好的音质表现。
### Conclusion
VoXtream相比于现有的TTS系统具有显著的性能优势，能够实现实时、低延迟且高音质的语音生成，尤其是在流式模式下的应用潜力巨大。该系统为TTS领域提供了一个重要的进步，并为相关应用带来了更好的用户体验。
## 324. `cs.CL` - SABER: 通过跨层残差连接揭示安全对齐漏洞 [PDF](https://arxiv.org/pdf/2509.16060), [HTML](https://arxiv.org/abs/2509.16060)
### Authors
Maithili Joshi,Palash Nandi,Tanmoy Chakraborty
### Background
大型语言模型（LLMs）经过安全对齐训练后，具有强大的语言理解能力。然而，尽管这些模型在训练过程中会进行严格的人工反馈调整，以确保接收安全输入并拒绝有害或不安全的输入，但它们仍然容易受到'监狱突破'攻击，即恶意用户操纵模型生成应避免的有害输出。现有安全机制主要嵌入在模型的中后期层中。因此，研究人员开发了一种新颖的白盒监狱突破方法——SABER，通过残差连接连接两个中间层，实现了在HarmBench测试集上的51%性能提升，同时在验证集上只有细微的困惑度变化。
### Innovation
SABER是一种新颖的白盒监狱突破方法，通过在两个中间层之间引入残差连接来实现对安全对齐机制的绕过。这种方法在保持安全机制有效性的前提下，显著提升了模型的性能，同时对模型的困惑度影响较小，表明其具有较高的鲁棒性。
### Conclusion
研究通过实验验证了SABER方法的有效性，不仅实现了对监狱突破攻击的有效应对，还保持了模型在处理有害输出方面的优良性能，证明了其在提高LLMs安全性方面的重要作用。该开源代码已对外发布，以便其他研究人员进行进一步的研究和应用。
## 325. `cs.CL` - 隐性学习：事件记忆通过使经验灵活重用补充参数学习 [PDF](https://arxiv.org/pdf/2509.16189), [HTML](https://arxiv.org/abs/2509.16189)
### Authors
Andrew Kyle Lampinen,Martin Engelcke,Yuxuan Li,Arslan Chaudhry,James L. McClelland
### Background
机器学习系统在泛化方面存在一些失败，特别是缺乏隐性学习，即学习与当前任务无关但对未来任务可能有用的信息。这些失败包括语言建模中的反转诅咒和基于代理的导航的新发现。认知科学指出了事件记忆作为潜在解决方案的重要性。通过引入基于检索的机制，系统可以更灵活地利用学习经验，从而更好地解决泛化问题。检索的有效使用需要内部示例中的上下文学习的重要性，以获得跨检索示例使用信息的能力。这种机制能揭示当前机器学习系统的相对数据效率问题，并解释了如何通过检索方法补充参数学习来改善泛化能力.
### Innovation
提出了基于事件记忆的检索机制来解决机器学习系统的泛化问题，强调了内部示例上下文学习的重要性，以更好地利用检索，并通过这种方法解释了机器学习系统的数据效率问题，以及如何通过检索方法改善参数学习来提高泛化能力.
### Conclusion
通过事件记忆，机器学习系统可以更好地泛化，并理解如何通过检索方法补充参数学习以提高泛化能力。这一研究揭示了一个可能解释当前机器学习系统与自然智能之间相对数据效率差异的原因，展示了认知科学如何为提高机器学习系统的泛化能力提供见解.
## 326. `cs.CL` - 大型音频语言模型直接同时翻译激活 [PDF](https://arxiv.org/pdf/2509.15692), [HTML](https://arxiv.org/abs/2509.15692)
### Authors
Pei Zhang,Yiming Wang,Jialong Tang,Baosong Yang,Rui Wang,Derek F. Wong,Fei Huang
### Background
Simul-S2TT的目标是在实时接收源语音输入的同时，将语音翻译成目标文本语言。以往的研究多通过调整模型架构来实现读写策略，然而随着大型音频语言模型(LALMs)的发展，关键挑战是如何在保持原始架构的情况下直接激活LALMs的Simul-S2TT能力。
### Innovation
提出了SimulSelf-Augmentation（SimulSA）策略，利用LALMs原有的能力，通过随机截断语音并构建部分对齐的翻译数据，将这些数据融入离线SFT数据中，从而有效缩小预训练离线翻译与推理时实时翻译之间的分布差距。
### Conclusion
实验结果表明，只需增加大约1%的实时翻译数据，相较于完整的离线SFT数据，就能显著激活LALMs的Simul-S2TT能力，且无需改变模型架构或解码策略。
## 327. `cs.CL` - 使用弱监督解耦上下文学习中的潜在变化 [PDF](https://arxiv.org/pdf/2410.01508), [HTML](https://arxiv.org/abs/2410.01508)
### Authors
Josip Jukić,Jan Šnajder
### Background
上下文学习（ICL）使大规模语言模型能够在提示中条件处理标记示例的情况下执行少量学习。尽管具有灵活性，但ICL面临稳定性问题，尤其是在提示长度随示例增多而增加时更为明显。为解决这一问题，作者将ICL视为弱监督的来源，并提出了一种参数高效的解耦方法，将示例引起的潜在变化与查询的分离，以减少扰动。
### Innovation
本文提出了一种参数高效的解耦方法，通过将ICL视为弱监督来源来解决其稳定性问题。方法包括使用基于ICL的教师生成伪标签对学生进行训练，学生仅通过查询输入进行预测并更新轻量级适应器。这种方法以紧凑、可重用的形式捕捉示例效果，从而实现高效推理，并保持与新示例的组合兼容性。
### Conclusion
实验结果显示，该方法在领域内和领域外任务中均提升了泛化能力、稳定性和效率，超越了标准的ICL方法和前者的解耦方法。通过伪标签矫正和覆盖扩展，即使在嘈杂的教师输出训练下，学生的表现也经常优于教师，这与从弱监督到强监督的一般化效果一致。
## 328. `cs.CL` - The Great AI Witch Hunt: Reviewers Perception and (Mis)Conception of Generative AI in Research Writing [PDF](https://arxiv.org/pdf/2407.12015), [HTML](https://arxiv.org/abs/2407.12015)
### Authors
Hilda Hadan,Derrick Wang,Reza Hadi Mogavi,Joseph Tu,Leah Zhang-Kennedy,Lennart E. Nacke
### Background
随着生成性人工智能（GenAI）在研究写作中的应用迅速增长，研究人员对如何让同行评审人员识别或误解AI辅助的草稿存在不确定。本文通过对顶级人机交互（HCI）会议的17名同行评审人员进行片段基于的在线调查，探讨AI辅助写作对评审的影响。
### Innovation
本文创新性地设计了片段基于的在线调查，揭示了在评审过程中AI辅助写作的优点和缺点，并提出了评审指南，以促进对提交作品的公正评价，而不是带有针对GenAI的个人偏见。
### Conclusion
研究表明，尽管AI辅助写作在提高可读性、语言多样性和信息量方面有帮助，但它常常缺少作者的研究细节和反思洞察。评审人难以区分人类和AI辅助的写作，但他们保持了他们的一致性评判。研究表明，研究的质量应该是评审的首要关注点，不论使用什么工具创作。还强调研究人员必须保持对写作过程的掌控，即使在使用GenAI协助时也不例外。
## 329. `cs.CL` - 语言模型文本生成的高效实时改进 [PDF](https://arxiv.org/pdf/2501.07824), [HTML](https://arxiv.org/abs/2501.07824)
### Authors
Joonho Ko,Jinheon Baek,Sung Ju Hwang
### Background
大型语言模型（LLMs）在自然语言处理任务中表现出色，但有时会产生事实错误的回答。先前的工作集中于识别和纠正其生成错误，但由于这些方法需要验证LLMs生成的整个过程（从第一个到最末一个词），因此部署速度较慢。此外，我们观察到如果LLMs在早期生成错误的词，后续词也可能包含事实错误。
### Innovation
提出了Streaming-VR（流式验证与完善）方法，该方法可以在LLMs生成过程中实时验证和纠正词，确保每部分生成的词在生成的同时就被另一个LLM检查和修改。与之前的改进方法相比，这种方法在提高LLMs事实准确性的同时，提供了更高效的解决方案。
### Conclusion
通过多个数据集的全面评估，证明了该方法不仅提升了LLMs的事实准确性，而且提供了比先前改进方法更高效的解决方案。
## 330. `cs.CL` - 数据库增强查询表示的信息检索 [PDF](https://arxiv.org/pdf/2406.16013), [HTML](https://arxiv.org/abs/2406.16013)
### Authors
Soyeong Jeong,Jinheon Baek,Sukmin Cho,Sung Ju Hwang,Jong C. Park
### Background
信息检索模型在搜索与查询相关的文档方面已经取得了多次成功，并应用到了多种任务中。然而，用户查询通常很短，这给检索器正确检索相关文档带来了挑战。为解决这一问题，先前的研究提出了通过添加与查询相关的几个额外特征来扩展查询的方法。然而，这些方法可能无法有效地增强查询，而且数据库中还有大量的其他信息可以用来增强查询。受此启发，本文提出了一种名为Database-Augmented Query representation (DAQu)的新的检索框架，该框架通过从多个表中添加各种与查询相关的元数据来增强原始查询。
### Innovation
提出了Database-Augmented Query representation (DAQu)框架。该框架通过从多个表中添加各种与查询相关的元数据来增强原始查询。此外，由于元数据中的特征数量很大且没有顺序，作者采用基于图的集合编码策略来编码元数据，这种策略考虑了数据库中的特征层次结构而无需考虑顺序。该方法在多种检索场景下进行了验证，显示出在与基线相比的整体检索性能显著提高。
### Conclusion
本文提出了一种名为Database-Augmented Query representation (DAQu)的新型检索框架，通过从数据库中添加与查询相关的多个元数据来增强原始查询，显著提高了整体检索性能。
## 331. `cs.CL` - 长上下文精神健康评估的分层多专家框架 [PDF](https://arxiv.org/pdf/2501.13951), [HTML](https://arxiv.org/abs/2501.13951)
### Authors
Jinwen Tang,Qiming Guo,Wenbo Sun,Yi Shang
### Background
长形式的精神健康评估对大型语言模型（LLMs）提出了独特的挑战，这些模型在处理长时间、特定领域的内容时往往会显示出幻觉或推理不一致的现象。
### Innovation
引入了分层多模型推理（SMMR）框架，该框架利用多个LLMs和特定的小型模型作为“平等专家”，分层隔离短的离散子任务，并通过更高级的长上下文模型集成和细化这些部分输出，以减少幻觉、捕捉微妙的临床措辞并提高高风险精神健康评估的可靠性。
### Conclusion
SMMR 整合多样化的“第二意见”，降低了幻觉，捕捉了细微的临床细节，并在高风险精神健康评估中增强了可靠性。研究结果强调了多专家框架在更可信的AI筛查中的价值。
## 332. `cs.CL` - BBScoreV2：从随机表示学习时间演化和潜在对齐 [PDF](https://arxiv.org/pdf/2405.17764), [HTML](https://arxiv.org/abs/2405.17764)
### Authors
Tianhao Zhang,Zhecheng Sheng,Zhexiao Lin,Chen Jiang,Dongyeop Kang
### Background
自回归生成模型在各种语言任务中发挥关键作用，特别是在模型和评估长文本序列方面。近期方法利用随机表示来更好地捕捉序列动力学，同时编码时间性和结构性依赖关系并利用这些信息进行评估仍然具有挑战性。本文观察到，将基于Transformer的模型嵌入纳入随机过程后，可以从前序无序的模型输出中得到有序的潜在表示。基于此发现和先前工作，本文理论性地引入了一种新的基于似然的评估指标BBScoreV2。实验证明，随机潜在空间诱导了语言模型表示在高维空间上的“集群到时间有序”的映射，从而为BBScoreV2的有效性提供了直观和量化的支持。此外，这种结构与自然语言的基本特性相吻合，并在时间一致性评估（例如Shuffle任务）和AI生成内容检测等任务中提升了性能。
### Innovation
本文理论性地提出了一种新的基于似然的评估指标BBScoreV2，即BBScoreV2。这项工作展示了随机潜在空间诱导了语言模型表示在高维空间上的“集群到时间有序”的映射，为评估指标的有效性提供了直观和量化的支持，同时也提升了在时间一致性评估和AI生成内容检测等任务上的表现。
### Conclusion
随机潜在空间诱导了语言模型表示在高维空间上的“集群到时间有序”的映射，为BBScoreV2的有效性提供了直观和量化的支持。这一结构与自然语言的基本特性相吻合，并且在时间一致性评估和AI生成内容检测等任务中提升了性能。BBScoreV2指标在这些任务上表现良好，证明了其在语言模型评估中的有效性。
## 333. `cs.CL` - ConfReady: 基于检索增强生成的助手及会议 checklist 回应数据集 [PDF](https://arxiv.org/pdf/2408.04675), [HTML](https://arxiv.org/abs/2408.04675)
### Authors
Michael Galarnyk,Rutwik Routu,Vidhyakshaya Kannan,Kosha Bheda,Prasun Banerjee,Agam Shah,Sudheer Chava
### Background
目前，《ARR 负责任 NLP 研究清单》网站上的检查表旨在鼓励负责任的研究实践，涉及研究伦理、社会影响和可再现性等方面。作者通过回答这些检查表中的问题，可以反思自己的研究工作，并确保共享的科学资产符合最佳实践。然而，先前的研究已经表明，作者自行报告的检查表回复不一定能准确反映他们的论文。因此，需要一种能够辅助作者遵守会议检查表的工具，以便在提交之前帮助他们更好地理解和实现最佳实践。本文介绍了一种检索增强生成（RAG）应用程序——ConfReady，旨在帮助作者反思自己的研究工作并协助他们完成会议检查表。为了评估这些辅助工具的效果，研究人员创建了一个包含1,975个ACL检查表回复的数据集，分析了人类答案中的问题，并将RAG和大型语言模型（LM）基于系统的性能进行了基准测试。
### Innovation
介绍了ConfReady，这是一种基于RAG的应用程序，可以帮助作者遵守会议检查表，改进写作过程。通过创建一个包含1,975个ACL检查表回复的数据集，分析了人类答案中的问题，并将RAG和大型语言模型（LM）基于系统的性能进行了基准测试。此外，相关代码已公开，并附有详细的用户界面和PyPI包文档。这项工作为提高研究人员的论文质量和促进负责任的研究实践提供了一种新的工具和方法
### Conclusion
最终展示了ConfReady可以有效辅助作者完成会议检查表，提高论文质量和负责任的研究实践。通过公开的代码和数据集，进一步验证了RAG和大型语言模型在辅助工具开发中的潜力，提供了未来研究和开发的方向。
## 334. `cs.CL` - 利用多个大型语言模型：LLM 组合综述 [PDF](https://arxiv.org/pdf/2502.18036), [HTML](https://arxiv.org/abs/2502.18036)
### Authors
Zhijun Chen,Jingzheng Li,Pengpeng Chen,Zhuoran Li,Kai Sun,Yuankai Luo,Qianren Mao,Ming Li,Likang Xiao,Dingqi Yang,Yikun Ban,Hailong Sun,Philip S. Yu
### Background
近期，综合运用多个大型语言模型（LLMs）进行下游推理，每个模型专注于处理用户查询并利用其各自优势的研究，引起了广泛关注。LLMs 的普遍可用性和各自的强项使 LLM 组合在该领域取得了重要进展。
### Innovation
该论文首次系统地回顾了 LLM 组合的最新发展。作者引入了 LLM 组合的分类法，并讨论了若干相关研究问题。根据“推理前组合、推理过程中组合、推理后组合”进行分类，全面回顾了所有相关方法。
### Conclusion
论文介绍了相关的基准和应用，总结了现有研究，并提出了未来研究方向。还提供了一份关于 LLM 组合的研究地图，相关论文列表详见此网址: this https URL
## 335. `cs.CL` - Sparsity May Be All You Need: Sparse Random Parameter Adaptation [PDF](https://arxiv.org/pdf/2502.15975), [HTML](https://arxiv.org/abs/2502.15975)
### Authors
Jesus Rios,Pierre Dognin,Ronny Luss,Karthikeyan N. Ramamurthy
### Background
随着大型语言模型的规模不断扩大，对其进行全面微调以实现对齐和任务适应所需的计算和内存资源变得难以承受。参数高效微调（PEFT）方法旨在通过仅训练少量参数来显著减少这些模型的微调所需资源，而不需要微调所有模型参数。当前最流行的方法是Low-Rank Adaptation（LoRA），它冻结模型参数，并引入一组可训练的小型可训练参数，以低秩矩阵的形式出现。
### Innovation
论文提出了一种简单的方法，通过随机选择一小部分模型参数来训练，而固定所有其他参数，而不需要任何额外的假设，如低秩结构。这种方法被对比与其他PEFT方法和全面参数微调方法的效率和性能，结果表明在使用相似数量的可训练参数时，该方法与LoRA具有竞争力。
### Conclusion
研究发现，真正影响PEFT技术表现的不是具体的适配器结构，而是使用的可训练参数数量。这表明稀疏随机参数适配可能只需使用较少的参数就能达到较好的效果。
## 336. `cs.CL` - 事实与公平的交界：通过认知偏差重新定义AI偏见评估 [PDF](https://arxiv.org/pdf/2502.05849), [HTML](https://arxiv.org/abs/2502.05849)
### Authors
Jen-tse Huang,Yuhang Yan,Linqi Liu,Yixin Wan,Wenxuan Wang,Kai-Wei Chang,Michael R. Lyu
### Background
近年来，如Google Gemini生成穿着纳粹时期制服的有色人种事件，表明AI输出可以是事实正确的，但社会上可能有害。当前评价AI模型的“公平性”标准往往混淆了事实正确性和规范公平性这两个基本不同的维度。模型可能在事实正确性上得分很高，但在社会公平性上表现不佳，反之亦然。
### Innovation
作者提出了Fact-or-Fair基准，包括客观查询和主观查询。这些查询基于统计学和认知心理学，重点关注代表性偏差、归因偏差和内群体-外群体偏差，以解释模型为何在事实和公平性之间产生错位。该基准通过重新定义公平性评估，提供了新的理论框架和实际基准，用于推进负责任的模型评估。
### Conclusion
实验表明不同的前沿模型在事实-公平性权衡上存在差异。通过重新定义公平性评估，论文提供了理论视角和实践基准，以促进负责任的模型评估。
## 337. `cs.CL` - 在检索增强大型语言模型中通过查询优化进行参数化知识细化的查询优化 [PDF](https://arxiv.org/pdf/2411.07820), [HTML](https://arxiv.org/abs/2411.07820)
### Authors
Youan Cong,Pritom Saha Akash,Cheng Wang,Kevin Chen-Chuan Chang
### Background
背景介绍了检索增强生成（RAG）系统中存在预检索信息缺口的问题，以及现有的查询优化技术无法完全解决这一问题。传统的查询优化技术无法满足大型语言模型（LLMs）的特定知识需求，导致生成不准确的响应。因此，需要一种新的方法来优化查询并解决这种信息缺口问题，从而改进RAG系统的实用性和准确性。文章提出了一种名为Extract-Refine-Retrieve-Read（ERRR）的新框架。
### Innovation
创新点在于ERRR框架通过提取和优化参数化知识来改进RAG系统。首先，从LLMs中提取参数化知识，然后使用专门的查询优化器对这些查询进行细化，以确保仅检索最相关的信息，从而生成准确的响应。此外，提出了一种可训练的方案，使用一个较小的、可调整的模型作为查询优化器，并通过从较大教师模型的知识蒸馏对其进行优化，以提高灵活性并减少计算成本。实验结果表明，ERRR框架在多个问答数据集和不同检索系统上都优于现有基线，证明了其作为RAG系统实用性和准确性提高的多用途且成本效益高的模块的有效性。
### Conclusion
结论指出了ERRR框架的优势，即在RAG系统中实现参数化知识的细化和优化查询，展示了其在不同数据集和系统的广泛适用性和较高性能。通过与现有基线的比较，表明ERRR框架不仅可以提高RAG系统的准确性，还能通过使用较小的可调模型降低计算成本，从而实现成本效益的改进。
## 338. `cs.CL` - 警惕偏见：认知偏见对LLM驱动的产品推荐的影响 [PDF](https://arxiv.org/pdf/2502.01349), [HTML](https://arxiv.org/abs/2502.01349)
### Authors
Giorgos Filandrianos,Angeliki Dimitriou,Maria Lymperaiou,Konstantinos Thomas,Giorgos Stamou
### Background
大型语言模型（LLMs）的出现已经彻底改变了产品推荐系统，但这些模型容易受到对抗性操纵的影响，这在现实商业应用中提出了重大挑战。我们的研究是首次将人类心理原则应用于产品描述的修改，使这种操纵更加难以被检测到。我们通过跨不同规模模型的广泛评估发现，某些认知偏见，如社会认同，能够持续提高产品推荐率和排名，而另一些偏见，如稀缺性和排他性，却意外地降低了产品可见度。我们的结果表明，认知偏见深深植根于最新的LLM模型中，导致了产品推荐行为的高度不可预测性，这为有效的缓解措施提出了巨大挑战。
### Innovation
我们的方法首次将人类心理学原则应用于产品描述的修改，使对抗性操纵更加难以被检测到。通过跨不同规模模型的广泛评估，我们发现某些认知偏见能够持续提高产品推荐率和排名，而另一些偏见却意外地降低了产品可见度，揭示了认知偏见在LLM中的深层影响。我们展示了对抗性操纵的重要性和挑战，强调了通过利用认知偏见可以提升产品推荐效果的方法。
### Conclusion
认知偏见在最新的LLM模型中根深蒂固，导致产品推荐行为的不可预测性增加，给有效的缓解措施带来了重大挑战。我们的研究结果表明，通过理解并利用这些认知偏见，可以改善产品推荐效果，但同时需要找到有效的方法来抵御可能的对抗性操纵。
## 339. `cs.CL` - reWordBench：通过变换输入衡量和改进奖励模型的鲁棒性 [PDF](https://arxiv.org/pdf/2503.11751), [HTML](https://arxiv.org/abs/2503.11751)
### Authors
Zhaofeng Wu,Michihiro Yasunaga,Andrew Cohen,Yoon Kim,Asli Celikyilmaz,Marjan Ghazvininejad
### Background
奖励模型已成为现代NLP的一个基本组成部分，不仅作为可扩展的文本评估器，还是许多对齐方法和推理算法中的不可或缺的组件。但最近的研究表明，奖励模型在标准基准上的性能提升部分可能是因为过拟合效应，这会混淆对其真正能力的理解。因此，有必要深入研究奖励模型的鲁棒性和过拟合程度。
### Innovation
本文构建了reWordBench，一种系统地以保持意义或排名的方式变换奖励模型输入的方法。该研究发现，最先进的奖励模型在小的输入变换下表现大幅下降，有时甚至降到显著低于随机准确率，显示出脆弱性。提出了一种明确训练奖励模型的方法，使其对同义词分配相似评分，这种方法也提高了模型对其他不同变换的鲁棒性。实验结果显示，在RewardBench的Chat Hard子集中，鲁棒的奖励模型表现下降幅度减少了大约一半。此外，当用于对齐时，鲁棒的奖励模型表现更为优异，提高了输出质量，在多达59%的情况下优于标准训练的RM。
### Conclusion
该研究通过reWordBench评估了奖励模型的鲁棒性，揭示了其脆弱性，并提出了一种增强鲁棒性的方法。同时展示了这种鲁棒性增强的方法在实际应用中的优势。
## 340. `cs.CL` - DynamicNER：一种基于大语言模型的动态、多语言和细粒度命名实体识别数据集 [PDF](https://arxiv.org/pdf/2409.11022), [HTML](https://arxiv.org/abs/2409.11022)
### Authors
Hanjun Luo,Yingbin Jin,Xinfeng Li,Xuecheng Liu,Ruizhe Chen,Tong Shang,Kun Wang,Qingsong Wen,Zuozhu Liu
### Background
大型语言模型（LLMs）的进步激发了其在命名实体识别（NER）方法中的应用兴趣。然而，现有数据集主要针对传统机器学习方法设计，对于基于LLM的方法来说，这些数据集在语料库选择和整体数据集设计逻辑上存在不足。此外，现有数据集中的实体分类固定且相对粗略，无法充分评估基于LLM的方法的广泛应用前景，以及它们的泛化能力和上下文理解能力。
### Innovation
我们提出了DynamicNER，这是一种专为基于LLM的方法设计的命名实体识别数据集，特点是动态分类、多语言和细粒度。它包含了多种实体类型和在同一实体在不同上下文中的实体类型列表，利用了基于LLM的命名实体识别的一般化能力。另外，我们还引入了CascadeNER，这是一种基于轻量级LLM的两阶段策略的新颖命名实体识别方法，实现了在细粒度任务上的高准确性，同时减少了计算资源的需求。
### Conclusion
实验表明，DynamicNER是基于LLM的方法的命名实体识别的稳健和有效的基准。此外，我们还对我们的数据集上的传统方法和基于LLM的方法进行了分析。我们的代码和数据集已公开在此：(this https URL)。
## 341. `cs.CL` - 通过隐私保护进化模型合并实现个性化语言模型 [PDF](https://arxiv.org/pdf/2503.18008), [HTML](https://arxiv.org/abs/2503.18008)
### Authors
Kyuyoung Kim,Jinwoo Shin,Jaehyung Kim
### Background
语言模型的个性化旨在根据个体用户或用户群体定制模型行为。现有方法主要包括基于提示的方法和基于训练的方法。提示方法将用户偏好融入查询中，而训练方法则将用户偏好编码到模型参数中。还探讨了模型合并以在数据有限的情况下实现个性化，但现有方法往往无法直接优化特定任务的效用，并缺乏明确的隐私保护机制。
### Innovation
提出了一种新颖的个性化方法——基于进化算法的隐私保护模型合并（PriME），该方法使用无梯度方法直接优化效用，同时减少隐私风险。通过将隐私保护融入优化目标，PriME 创建了既可以有效捕捉目标用户偏好的个性化模块，又能尽量减少数据共享用户隐私风险。
### Conclusion
在 LaMP 标准测试上的实验表明，PriME 持续优于多种基准方法，任务性能提升高达 45%。进一步分析表明，PriME 较之于先前的最先进的技术在隐私-效用权衡方面表现更优，并且对抗成员推理攻击更加稳健，且在捕捉用户偏好方面更具优势。
## 342. `cs.CL` - 评估大型语言模型在处理多语言噪 REUTERS 和光学字符识别数据中的鲁棒性 [PDF](https://arxiv.org/pdf/2502.16781), [HTML](https://arxiv.org/abs/2502.16781)
### Authors
Bhawna Piryani,Jamshid Mozafari,Abdelrahman Abdallah,Antoine Doucet,Adam Jatowt
### Background
光学字符识别（OCR）在数字化历史和多语言文档方面起着关键作用，但OCR错误——如字符插入、删除和替换等不完美的文本提取，会严重影响问答（QA）等下游任务。本文分析了OCR引入的噪声对多语言QA系统的性能影响，并收集了一个名为MultiOCR-QA的多语言QA数据集，该数据集包含英语、法语和德国语三个语言的50K问题-答案对。通过评估不同最先进的大型语言模型在不同错误条件下的表现，重点讨论了三种主要的OCR错误类型，揭示了QA系统在噪 REUTERS 文本中的脆弱性，并强调了在历史数字化背景中需要更鲁棒的QA系统的需求。
### Innovation
引入了一个包含多语言历史文档中不同级别的OCR噪声的多语言QA数据集MultiOCR-QA。评估了不同最先进的大型语言模型在不同错误条件下的表现，并特别关注三种主要的OCR错误类型，为现有方法的局限性提供了见解，突显了对更鲁棒的QA系统的需要。
### Conclusion
QA系统极易受到OCR错误的影响，在噪声OCR文本上的表现不佳。通过比较模型在清洁文本和噪声文本上的表现，研究揭示了当前方法的局限性，并强调了在历史数字化背景下需要更鲁棒的QA系统的重要性和迫切性。
## 343. `cs.CL` - 自适应自我改进的大语言模型代理系统在机器学习库开发中的应用 [PDF](https://arxiv.org/pdf/2502.02534), [HTML](https://arxiv.org/abs/2502.02534)
### Authors
Genghan Zhang,Weixin Liang,Olivia Hsu,Kunle Olukotun
### Background
高效的机器学习系统的关键在于利用专门架构编程语言（ASPL）编写的高性能机器学习库，但编写这些库需要深厚的人工智能算法知识和ASPL知识，这很具有挑战性。尽管大型语言模型（LLMs）在一般编码能力上表现出色，但使用LLMs生成需要ASPL的机器学习库仍然有很大障碍，因为1）即使是经验丰富的程序员也会觉得这个任务复杂，2）由于ASPL的稀有性及其不断变化的特性导致代码实例受限。因此，为了生成这些库，LLMs需要在有限的数据下进行复杂的推理。鉴于此，本文介绍了一种自适应自我改进的代理系统来解决这些挑战并提升机器学习库的开发效率和质量.
### Innovation
本文创新性地提出了一个自适应自我改进的大语言模型代理系统，能够更好地利用LLMs的优势来生成需要ASPL的高性能机器学习库。通过在典型的机器学习库基准上使用开源和闭源的大语言模型进行生成来评估该系统的有效性和准确性，并证明该系统可以通过自适应学习在生成效率上获得显著提升，最高可达3.9倍.
### Conclusion
实验结果表明，该自适应自我改进的大语言模型代理系统能够有效提升机器学习库的开发质量和效率，相较于基准模型（单一的大语言模型），该系统能取得显著的改进表现。
## 344. `cs.CL` - FSLI：具有可解释性的形式语义系统用于一维排序推理 [PDF](https://arxiv.org/pdf/2502.08415), [HTML](https://arxiv.org/abs/2502.08415)
### Authors
Maha Alkhairy,Vincent Homer,Brendan O'Connor
### Background
当前自然语言推理研究大多侧重于神经语言模型，而本文提出了一种名为FSLI的形式语义系统，强调了在自然语言处理中原理性和可解释性系统的潜力，该系统用于自然语言逻辑演绎。它将自然语言前提和候选陈述转换为一阶逻辑，并利用Heim和Kratzer基于语法规则的语义规则实现语义解析，通过约束逻辑编程执行生成的逻辑形式，从而确定哪些候选陈述可以从前提中逻辑推导出来。针对合成和推导的逻辑演绎问题进行评估，FSLI在BIG-bench的逻辑演绎任务中实现100%的准确率，在简化后的AR-LSAT子集中的准确率为88%，超过了LLM基线。
### Innovation
提出了一个名为FSLI的形式语义逻辑推理系统，该系统利用基于语法规则的语义解析算法，通过转换自然语言的假设和候选陈述为一阶逻辑，并借助约束逻辑编程执行逻辑形式。该系统特别注重解释能力和逻辑演绎的准确性，不同于当前主要依赖神经语言模型的方法。通过此方法，在处理特定逻辑推理问题时，FSLI表现出色，进一步证明了形式化和可解释系统在自然语言处理中的重要性。
### Conclusion
FSLI为自然语言处理提供了一种正式语义驱动的逻辑演绎系统。它在合成和推导逻辑推理问题上的准确率表现良好，特别是在比对基于神经模型的基线时。进一步而言，FSLI的存在强调了在自然语言处理中使用原理性和可解释性系统的潜力，为未来的研究提供了新的视角。
## 345. `cs.CL` - KatFishNet：通过语言特征分析检测生成的韩文文本 [PDF](https://arxiv.org/pdf/2503.00032), [HTML](https://arxiv.org/abs/2503.00032)
### Authors
Shinwoo Park,Shubin Kim,Do-Kyung Kim,Yo-Sub Han
### Background
大规模语言模型（LLMs）的快速发展使得区分人类撰写和LLM生成的文本变得更加困难。检测LLM生成的文本对于维护学术诚信、防止抄袭、保护版权以及确保伦理研究实践至关重要。大多数先前的研究主要集中在英语文本上，而具有独特形态和句法特征的语言需要专门的检测方法。以韩语为例，它有相对较灵活的空格规则、丰富的词形系统以及比英语更少的逗号使用，这使得直接应用主要针对英语方法的检测方法变得困难。因此，研究一种专门针对韩语的检测方法是必要的。
### Innovation
本文提出了KatFish，首个针对韩语生成文本检测基准数据集。通过对韩语文本中的空格模式、词性多样性以及逗号使用情况进行分析，该文识别了人类撰写和LLM生成的韩语文本之间的语言差异，并据此提出了KatFishNet检测方法。KatFishNet相比现有最佳检测方法在平均AUROC方面提高了19.78%，从而展示了针对韩语的独特检测方法的有效性。
### Conclusion
本文通过构建韩语文本生成检测的基准数据集（KatFish）和提出专门针对韩语的检测方法（KatFishNet），在检测LLM生成的韩语文本方面取得了显著进展，通过语言特征分析提高了检测性能，具有重要的应用价值。
## 346. `cs.CL` - DP-GTR: Differentially Private Prompt Protection via Group Text Rewriting [PDF](https://arxiv.org/pdf/2503.04990), [HTML](https://arxiv.org/abs/2503.04990)
### Authors
Mingchen Li,Heng Fan,Song Fu,Junhua Ding,Yunhe Feng
### Background
文中指出在使用在线大型语言模型 (LLMs) 时，提示的隐私至关重要，因为提示中经常包含敏感信息。现有的通过文本重写增强提示隐私的方法主要集中在文档级别的重写上，忽视了文本的多粒度表示，这限制了LLMs的应用范围，影响其泛化能力和上下文学习能力，从而阻碍了其实用应用。
### Innovation
该文提出了DP-GTR，一种新颖的分三阶段框架，利用局部差分隐私 (DP) 与通过组文本重写方法应用组合定理。DP-GTR 是第一个结合文档级和词级信息的同时改进隐私和实用性的框架，有效地在个体数据点级别将局部和全局DP机制结合在一起。实验结果表明，DP-GTR 在普通常识问答 (CommonSense QA) 和文档问答 (DocVQA) 任务中优于现有方法，实现了更好的隐私-实用性权衡。此外，该框架兼容现有的重写技术，作为增强隐私保护的插件使用。
### Conclusion
实验结果表明，DP-GTR 在普通常识问答 (CommonSense QA) 和文档问答 (DocVQA) 任务中优于现有方法，实现了更好的隐私-实用性权衡。此外，该框架兼容现有的重写技术，作为增强隐私保护的插件使用。
## 347. `cs.CL` - UXAgent: 屏幕使用LLM代理模拟网页设计可用性测试的系统 [PDF](https://arxiv.org/pdf/2504.09407), [HTML](https://arxiv.org/abs/2504.09407)
### Authors
Yuxuan Lu,Bingsheng Yao,Hansu Gu,Jing Huang,Jessie Wang,Yang Li,Jiri Gesi,Qi He,Toby Jia-Jun Li,Dakuo Wang
### Background
可用性测试是用户体验（UX）研究人员评估和迭代新设计的一种基本研究方法。然而，是否可以对可用性测试研究设计本身进行评估和迭代呢？近期，大型语言模型（LLM）模拟代理（Agent）研究的进步激发了我们设计UXAgent，以支持UX研究人员在进行真实的人体实验研究之前，能够评估和迭代其研究设计。
### Innovation
该系统集成了个性特征生成模块、LLM代理模块和通用浏览器连接器模块，能够自动生成成千上万的模拟用户并与目标网站进行互动测试。系统提供了一个结果查看界面，使UX研究人员能够轻松地审查和分析生成的定性（如代理的调研问卷）和定量数据（如代理的交互日志），甚至可以对代理进行直接访谈。通过实证研究，参与者对系统创新给予了高度评价，但也对LLM代理在UX研究中的未来表示担忧。
### Conclusion
通过与16名UX研究人员的启发式评估，参与者称赞了系统的创新之处，但也对LLM代理在UX研究中的长期应用表达了担忧。
## 348. `cs.CL` - Chain of Strategy Optimization 增强了大型语言模型作为情感支持者的能力 [PDF](https://arxiv.org/pdf/2503.05362), [HTML](https://arxiv.org/abs/2503.05362)
### Authors
Weixiang Zhao,Xingyu Sui,Xinyang Han,Yang Deng,Yulin Hu,Jiahe Guo,Libo Qin,Qianyun Du,Shijin Wang,Yanyan Zhao,Bing Qin,Ting Liu
### Background
现代社会中日益增长的情感压力增加了对情感支持对话（ESC）的需求。尽管大型语言模型（LLMs）在提供ESC方面显示出潜力，但它们面临着两个关键挑战：（1）策略选择准确性低，（2）偏好偏差，限制了它们对用户情感需求的适应性。现有的监督微调（SFT）难以解决这些问题，因为它仅严格使用单一的标准响应训练模型，而不模拟策略权衡的细微差别。
### Innovation
我们提出了一种名为链式策略优化（CSO）的新方法，该方法在每次对话轮次中优化策略选择偏好。首先利用蒙特卡洛树搜索来构建高质的ESC-Pro数据集，其中包括轮次级别的策略-响应对。通过ESC-Pro进行CSO训练，可以提高策略准确性和偏见缓解能力，使LLMs能够生成更具同理心和上下文相关性的响应。实验表明CSO优于标准SFT，突显了细粒度、轮次级偏好建模在ESC中的有效性。
### Conclusion
通过CSO训练LLMs，能够更好地应对情感支持对话中的挑战，生成更具同理心和场景相关的响应，从而增强了其作为情感支持者的效果。
## 349. `cs.CL` - 在思考中搜索并精炼：促进增强检索推理的知识精炼 [PDF](https://arxiv.org/pdf/2505.11277), [HTML](https://arxiv.org/abs/2505.11277)
### Authors
Yaorui Shi,Sihang Li,Chang Wu,Zhiyuan Liu,Junfeng Fang,Hengxing Cai,An Zhang,Xiang Wang
### Background
大型语言模型展示了惊人的推理能力，但它们的知识储备有限。检索增强推理可以通过让LLMs查询外部资源来减轻这一限制，但现有方法常常检索出无关或噪声信息，影响准确推理。
### Innovation
提出了一种基于强化学习的后训练框架——AutoRefine，采用“搜索和精炼思考”新范式，在连续两次搜索调用之间引入显式知识精炼步骤，使模型能够迭代筛选、提炼和组织证据，生成答案。此外，结合特定检索奖励和答案正确奖励，使用组相对策略优化。
### Conclusion
AutoRefine在单跳和多跳问答基准测试中显著超越现有方法，尤其在复杂的多跳推理场景中表现优异。详细分析表明AutoRefine经常进行高质量的频繁搜索并有效综合证据。
## 350. `cs.CL` - MT-RewardTree: 通过奖励建模推进基于大语言模型的机器翻译的综合框架 [PDF](https://arxiv.org/pdf/2503.12123), [HTML](https://arxiv.org/abs/2503.12123)
### Authors
Zhaopeng Feng,Jiahan Ren,Jiayuan Su,Jiamei Zheng,Hongwei Wang,Zuozhu Liu
### Background
过程奖励模型（PRM）在大型语言模型（LLM）的复杂推理任务中表现出了成功应用，但对于机器翻译（MT）的应用仍相对较少，主要是因为缺乏系统的方法和评估标准。MT-RewardTree介绍了一种全面框架，旨在解决这一问题，通过自动生成标记级偏好对来减轻人工细粒度步骤注释的成本。该研究还建立了首个针对MT的奖励模型基准，并进行了一组系统比较，揭示了标记级监督能够有效捕捉细粒度偏好。实验结果表明，在相同的输入前缀下，MT-PRM-Qwen-2.5-3B在标记级和序列级评估中都达到了最新性能。此外，研究展示了奖励模型如何在测试时对LLM进行对齐，而无需额外的对齐训练，并显著提高了假设集合的性能。
### Innovation
1. 引入了MT-RewardTree框架，用于构建、评估和部署用在MT中的过程奖励模型。2. 提出了一种使用近似蒙特卡洛树搜索（MCTS）自动生成标记级偏好对的新方法。3. 建立了首个专门针对MT的奖励模型基准，进行了一组系统比较，展示了标记级监督的有效性。4. 通过引入过程奖励模型，实现了LLM在测试时的对齐，无需额外训练，提高了假设集合性能，达到了最新水平。
### Conclusion
MT-RewardTree框架通过奖励建模提供了宝贵的见解，推动了基于大语言模型的机器翻译研究，并且研究还将代码和数据在网页上公开，以供进一步研究。
## 351. `cs.CL` - 推理语言模型中的语言混杂：模式、影响及内部原因 [PDF](https://arxiv.org/pdf/2505.14815), [HTML](https://arxiv.org/abs/2505.14815)
### Authors
Mingyang Wang,Lukas Lange,Heike Adel,Yunpu Ma,Jannik Strötgen,Hinrich Schütze
### Background
推理语言模型（RLMs）通过利用链式思维生成结构化的中间步骤，在复杂任务方面表现出色。然而，观察到这些模型在输出中出现语言混杂现象，即推理步骤中包含除提示外的其他语言的标记，尽管这对其性能产生了影响，但其影响程度仍存在争议。
### Innovation
本文首次系统研究了RLMs中的语言混杂现象，涉及15种语言、7种任务难度级别和18个学科领域，探讨了其模式、影响和内部原因。此外，证明了推理语言选择对性能有着显著影响。通过受约束解码使模型在拉丁或汉字脚本中推理，显著提高了准确性。最后，推断推理痕迹的脚本组成与模型的内部表示紧密相关，表明语言混杂反映了RLMs中的潜在处理偏好。
### Conclusion
研究结果提供了优化多语言推理的实用见解，并为控制推理语言以构建更具可解释性和适应性的RLMs开辟了新途径。
## 352. `cs.CL` - Creative Preference Optimization [PDF](https://arxiv.org/pdf/2505.14442), [HTML](https://arxiv.org/abs/2505.14442)
### Authors
Mete Ismayilzada,Antonio Laverghetta Jr.,Simone A. Luchini,Reet Patel,Antoine Bosselut,Lonneke van der Plas,Roger Beaty
### Background
大型语言模型（LLMs）在自然语言生成任务上展示了令人印象深刻的性能，但它们生成真正具有创意内容的能力（如新颖性、多样性、惊喜感和高质量）依然有限。现有方法通常仅专注于提高多样性或特定任务，未能从多维度、通用角度提升模型的创造力。
### Innovation
本文提出了Creative Preference Optimization（CrPO），这是一种新的对齐方法，能够在模块化的方式下将多个创意维度的信号注入偏好优化目标中。通过CrPO和MuCE（大规模新的人类偏好数据集），训练并评估了多个创意增强模型的表现，这些模型在自动化和人类评价中均表现出色，生成的内容更加新颖、多样且出乎意料，且保持了高质量的输出。
### Conclusion
我们的研究表明，在偏好框架中直接优化创造力是提高LLMs创意能力的一个有前景的方向，且不会牺牲输出质量。额外的评估进一步证实了该方法的高度可推广性。
## 353. `cs.CL` - Are Vision-Language Models Safe in the Wild? A Meme-Based Benchmark Study [PDF](https://arxiv.org/pdf/2505.15389), [HTML](https://arxiv.org/abs/2505.15389)
### Authors
DongGeon Lee,Joonwon Jang,Jihae Jeong,Hwanjo Yu
### Background
尽管视觉-语言模型（VLMs）的快速部署放大了安全风险，但大多数评估仍然依赖于人工生成的图像。本文旨在探讨现有的VLMs在面对普通用户分享的模因图像时的安全性。
### Innovation
本文引入了MemeSafetyBench，这是第一个用于评估VLMs安全性的基准数据集。该基准集包含50,430个实例，将实际的模因图像与有害和无害的指南配对，同时采用全面的安全分类法和基于LLM的指令生成法，评估多个VLMs在单次和多次交互中的安全性。
### Conclusion
研究结果表明，现有的VLMs对基于模因的有害提示比合成或类型化的图像更脆弱。模因显著增加了有害响应并降低了拒绝率，即使是在多次交互中，这种高脆弱性仍然存在。这些结果强调了进行生态有效评估和增强安全机制的需求。
## 354. `cs.CL` - 使用OpenAI模型进行端到端零样本生物医学关系提取基准测试：LLMs实验 [PDF](https://arxiv.org/pdf/2504.04083), [HTML](https://arxiv.org/abs/2504.04083)
### Authors
Aviv Brokman,Xuguang Ai,Yuhang Jiang,Shashank Gupta,Ramakanth Kavuluru
### Background
零样本方法有望降低数据集注释和领域专业知识的成本，使其能够在自然语言处理(NLP)中得到应用。预训练的大语言模型通过与人类目标对齐，在各种任务中实现了高零样本性能。目前，这些模型在生物医学关系提取(RE)任务上的表现尚不清楚。为了填补这一知识空白，本文探讨了OpenAI LLMs在多种生物医学关系提取任务中的表现模式。
### Innovation
本文使用OpenAI GPT-4-turbo和其他推理模型在七个数据集上进行了端到端的生物医学关系提取实验，研究了GPT-4、o1和GPT-OSS在这类复杂任务中的性能，并首次比较了它们在这类任务中的表现，发现其性能接近微调方法，但在涉及许多关系的示例中表现不佳。这表明LLMs在复杂生物医学关系提取任务中具有潜在的零样本能力，提供了具有较低数据集整理成本和NLP模型需求的竞争力，但伴随着持续计算成本的增加。
### Conclusion
LLMs在复杂的生物医学关系提取任务中表现出令人鼓舞的零样本能力，提供了与减少数据集整理成本和NLP建模需求相竞争的表现，但伴随着不断增长的计算成本。解决我们指出的限制可以进一步提高可靠性。本文的所有实验代码、数据和提示都已公开，供社区用于进一步基准测试：this https URL
## 355. `cs.CL` - 通过跨语言上下文预训练增强LLM语言适应性 [PDF](https://arxiv.org/pdf/2504.20484), [HTML](https://arxiv.org/abs/2504.20484)
### Authors
Linjuan Wu,Haoran Wei,Huan Lin,Tianhao Li,Baosong Yang,Fei Huang,Weiming Lu
### Background
现有的大语言模型（LLMs）在多语言能力方面表现出色，尽管在预训练过程中主要使用英语资源，但通过跨语言机制仍然保留了语言间的联系。然而，现有的增强跨语言迁移的方法仍然受限于平行资源的不足，导致语言覆盖不全和领域覆盖有限。
### Innovation
本文提出了跨语言上下文预训练（CrossIC-PT）方法，通过利用语义相关的双语文本进行简单的下一个词预测，来增强跨语言迁移能力。特别之处在于，通过系统化的分段策略将长的双语文本分块处理，同时调整滑动窗口机制以保持上下文的连续性，并通过语义检索框架从网络爬取的语料库中扩展数据来源，构建CrossIC-PT样本。
### Conclusion
实验结果表明，CrossIC-PT方法能够提高三种不同模型（Llama-3.1-8B、Qwen2.5-7B和Qwen2.5-1.5B）在六种目标语言上的多语言性能，分别提高了3.79%、3.99%和1.95%。数据增强进一步改善了性能。
## 356. `cs.CL` - HydraRAG：结构化的多源增强大型语言模型推理 [PDF](https://arxiv.org/pdf/2505.17464), [HTML](https://arxiv.org/abs/2505.17464)
### Authors
Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Xin Yuan,Liming Zhu,Wenjie Zhang
### Background
当前的混合RAG系统通过从知识图谱（KGs）和文本文档中检索证据来辅助LLM的推理，但仍面临多跳推理、多实体问题、多源验证以及有效图利用等挑战。
### Innovation
HydraRAG提出了一种无需训练的框架，统一了图形拓扑、文档语义和来源可靠性，以支持LLMs的深入、忠实推理。HydraRAG通过结合结构化和非结构化的检索，利用智能体驱动的探索解决多跳和多实体问题，提高了证据的多样性和准确性。对于多源验证，HydraRAG利用三因素跨源验证方法（来源可信度评估、跨源佐证、实体路径对齐），平衡了主题相关性与跨模态一致性的关系。通过利用图结构，HydraRAG将异质来源融合起来，引导有效的探索并早期去除噪音。
### Conclusion
大规模实验表明，HydraRAG使用GPT-3.5-Turbo在所有基准数据集上实现了整体最佳结果，优于强大的混合基线ToG-2，平均提高20.3%，最高达到30.1%。此外，HydraRAG使得较小的模型（例如Llama-3.1-8B）能够实现与GPT-4-Turbo相当的推理性能。源代码可以在提供的链接上获取。
## 357. `cs.CL` - SEMMA：一种感知语义的知识图谱基础模型 [PDF](https://arxiv.org/pdf/2505.20422), [HTML](https://arxiv.org/abs/2505.20422)
### Authors
Arvindh Arun,Sumit Kumar,Mojtaba Nayyeri,Bo Xiong,Ponnurangam Kumaraguru,Antonio Vergari,Steffen Staab
### Background
知识图谱基础模型（KGFMs）在通过学习可移植模式实现对未见过的图的零样本推理方面显示出潜力。然而，大多数现有的KGFMs仅依赖图结构，忽视了文本属性中编码的丰富语义信号。
### Innovation
我们引入了SECCA，一种双模块KGFM，系统地整合了可移植的文本语义与结构。SECCA利用大型语言模型增强关系标识符，生成语义嵌入，进而形成文本关系图，该图与结构成分融合。在54种不同的知识图谱上，SECCA在完全归纳链接预测方面优于仅基于结构的基本模型ULTRA。关键在于，我们展示了在更具挑战性的泛化设置中，当测试时的关系词汇表完全未见过时，结构方法崩溃，而SECCA的效果提高了2倍。
### Conclusion
我们的研究结果表明，文本语义在结构本身无法泛化的设置中是至关重要的，强调了统一结构和语言信号的基础模型在知识推理中的必要性。
## 358. `cs.CL` - AmpleHate: 加强注意力以实现灵活的隐含仇恨言论检测 [PDF](https://arxiv.org/pdf/2505.19528), [HTML](https://arxiv.org/abs/2505.19528)
### Authors
Yejin Lee,Joonghyuk Hahn,Hyeseon Ahn,Yo-Sub Han
### Background
隐含仇恨言论的检测具有挑战性，因为它较隐晦且依赖于上下文解释而非明确的冒犯词汇。当前的方法主要依赖于对比学习，这显示出在区分仇恨和非仇恨句子方面是有效的。然而，人类通过首先在文本中识别特定目标，然后根据其周围语境解释这些目标如何相互关联，来检测隐含仇恨言论。受此推理过程的启发，我们提出了AmpleHate方法，旨在模仿人类对隐含仇恨检测的推理过程。
### Innovation
AmpleHate首先使用预训练的命名实体识别模型识别显性目标，然后通过[CLS]标记捕获隐含信息。它通过计算显性、隐含目标与句子上下文之间的注意力关系，并直接将这些关系向量注入最终的句子表示，从而放大目标-上下文关系的关键信号以确定隐含仇恨。实验表明，AmpleHate取得了最先进的性能，比对比学习基线高出82.14%的平均值，并且收敛速度快。质性分析进一步显示，AmpleHate生成的注意力模式与人类判断高度一致，说明其具有良好的解释性和鲁棒性。
### Conclusion
AmpleHate在隐含仇恨检测中表现出色，提出了新的注意力机制模型，能够更好地理解文字所蕴含的隐含意义，并与人类认知过程相吻合，为该领域提出了新的解决方案。
## 359. `cs.CL` - 通过精细粒度的个性提示生成的合成数据的词汇多样性测量 [PDF](https://arxiv.org/pdf/2505.17390), [HTML](https://arxiv.org/abs/2505.17390)
### Authors
Gauri Kambhatla,Chantal Shaib,Venkata Govindarajan
### Background
近年来，研究者开始使用细粒度的人格（persona）来生成多样化的合成数据，用于大型语言模型（LLMs）的预训练和监督微调。尽管如此，关于这些生成的合成数据在词汇多样性方面的研究并不多。这篇论文通过一系列词汇多样性和冗余度指标，评估了基于精细粒度人格提示生成的合成对话中的词汇多样性。
### Innovation
论文采用词汇多样性与冗余度指标来量化带有细粒度人格描述的合成对话的多样性。研究发现，相较于未使用人格提示的方法，使用细粒度的人格描述能够提高生成文本的词汇多样性，尤其是在大模型中。但具体到细粒度人格描述的细节上，其贡献不大，仅仅用长度限制提示能获得类似效果。
### Conclusion
研究表明，带有细粒度人格描述的文本生成在某些模型中确实能提高词汇多样性，但对于增加话术细节的收益有限。在实际应用中，可以通过简单的长度限制替代更加复杂的细粒度人格描述来达到近似效果。
## 360. `cs.CL` - 大型语言模型的自然指纹 [PDF](https://arxiv.org/pdf/2504.14871), [HTML](https://arxiv.org/abs/2504.14871)
### Authors
Teppei Suzuki,Ryokan Ri,Sho Takase
### Background
近期研究表明，大型语言模型（LLMs）的输出通常能揭示其源模型的身份。尽管这是由于LLMs模拟其训练数据分布的自然结果，但这些可识别的痕迹也可能反映出一些潜在影响公平性和滥用的问题。本文进一步表明，在使用完全相同的训练数据集进行训练时，LLMs的输出依然可以被辨别，这表明训练动态本身可以留下可识别的模式。这些无意中的、独特的特征被称为自然指纹。研究人员通过系统地控制训练条件发现，这种自然指纹源于训练过程中的细微差别，比如参数大小、优化设置，甚至随机种子等。这些结果表明，训练动态可以系统地塑造模型行为，与数据或架构无关，并且应该在未来的透明度、可靠性和可解释性研究中计入考虑。
### Innovation
本文展示了在使用相同数据集进行训练的情况下，LLMs的输出依然具有可辨识性，这是由训练动态决定的，而不单纯是数据或架构的结果。通过系统地控制训练条件，研究发现在细微的训练差异下仍然存在可识别特征，这些特征被定义为自然指纹。这项工作强调了研究透明度、可靠性和可解释性时，需要考虑训练动态的重要性。
### Conclusion
训练动态可以系统地塑造模型行为，这与数据或架构无关。这种自然指纹强调了在透明度、可靠性和可解释性方面考虑训练动态的重要性。未来研究中应明确考虑这些因素。
## 361. `cs.CL` - 大型语言模型翻译微调中语言多样性的影响 [PDF](https://arxiv.org/pdf/2505.13090), [HTML](https://arxiv.org/abs/2505.13090)
### Authors
David Stap,Christof Monz
### Background
先前的研究对大型语言模型（LLM）微调中的语言多样性存在分歧：一些研究表明语言多样性有益，而另一些研究则发现没有明显优势。这些研究结果的不一致使得理解语言多样性在翻译任务中的作用变得更加复杂。本研究通过在132种翻译方向上进行受控的微调实验，系统地解决了这些差异。研究表明，在微调过程中扩大语言多样性可以提高翻译质量，尤其是对于监督对齐的模型，这对监督对齐数据较少使用的模型同样有效，尽管这些模型仅在这些监督数据集上进行微调，语言多样性的好处会随着某种阈值的增加而减少或降低。研究表明，语言多样性的增加产生了更强的语言无关表示，这些表示有助于解释在微调过程中具有更高多样性模型的更好性能。
### Innovation
本研究通过系统性的闭环实验方法，确定了在大型语言模型翻译微调中语言多样性的实际效果，尤其发现对于监督数据较多的翻译任务，语言多样性也有显著的积极影响。这项研究揭示了语言多样性能够改善翻译质量的合理机制，这为未来研究和实际应用提供了新的视角和可能性。
### Conclusion
本研究发现，通过扩大语言多样性来微调大型语言模型可以提高翻译质量，甚至对于较少使用的双语配对，尽管这些模型主要在监督数据上进行微调。然而，这种好处会随着语言多样性的增加而逐渐减弱或消失。表明增加的语言多样性会产生更加语言无关的表示，这些表示有助于解释在高多样性模型中获得更好的表现。
## 362. `cs.CL` - CLEAR: 一种基于临床的放射报告评价表格框架 [PDF](https://arxiv.org/pdf/2505.16325), [HTML](https://arxiv.org/abs/2505.16325)
### Authors
Yuyang Jiang,Chacha Chen,Shengyuan Wang,Feng Li,Zecong Tang,Benjamin M. Mervak,Lydia Chelala,Christopher M Straus,Reve Chahine,Samuel G. Armato III,Chenhao Tan
### Background
当前的评估指标往往缺乏足够的细节和解释性，无法捕捉放射学报告候选版本和基准版本之间微妙的临床差异，导致评估效果不佳。
### Innovation
引入了一种基于临床的表格框架——Clinically-grounded tabular框架，简称CLEAR，以及一个由专家亲缘的标签和属性级比较构成的评价体系。CLEAR不仅检查报告是否能够准确识别医学状况的存在或不存在，还评估报告能否在五个关键属性（首次出现、变化、严重程度、描述性位置和建议）方面精确描述每个识别出的状况。与先前的工作相比，CLEAR的多维、属性级输出能够提供更全面且具有临床解释性的评估报告质量。此外，为了衡量CLEAR的临床对齐程度，研究人员与5位经过认证的放射科医生合作，开发了一个包含100份胸部X光片报告的数据集——CLEAR-Bench，这些报告来源于MIMIC-CXR，并标注了6个精心策划的属性和13个CheXpert状况。我们的实验结果显示，CLEAR在提取临床属性方面达到了很高的准确率，并提供了一种与临床判断紧密对齐的自动化评价指标。
### Conclusion
CLEAR在提取临床属性方面表现优秀，并且其自动化评价指标与临床判断高度一致，提供了一种更加全面和可解释的放射报告评估方法。
## 363. `cs.CL` - 复杂问题上LLMs是更好的形式化工具还是求解器？ [PDF](https://arxiv.org/pdf/2505.13252), [HTML](https://arxiv.org/abs/2505.13252)
### Authors
Rikhil Amonkar,May Lai,Ronan Le Bras,Li Zhang
### Background
近年来，一项趋势是将大型语言模型（LLMs）用作形式化工具，而不是端到端的逻辑推理问题求解器。LLMs生成一个形式化的程序，通过外部求解器推导出解决方案，而不直接生成解决方案。虽然LLM作为形式化工具比作为求解器表现出更好的扩展性，但本文作者发现，这一优势在实际的约束满足问题中并不成立。
### Innovation
研究者系统地评估了6种LLM，包括4种大型推理模型和5种管道，以检验LLM在形式化工具和求解器方面的表现。研究揭示了LLM作为形式化工具在应对复杂问题时的实际表现，并提出了改进LLM作为形式化工具的建议。
### Conclusion
尽管LLM作为形式化工具具有准确性、鲁棒性、忠实性和效率等优势，目前LLM在生成形式化程序的能力有限，导致在复杂性增加时无法扩展，解决方案中存在硬编码问题，并且推理令牌过多。因此，在小样本设置下，LLM作为形式化工具的表现劣于作为求解器的表现。
## 364. `cs.CL` - LESS：使用野生数据增强的大型语言模型辅助半监督学习方法用于语音基础模型 [PDF](https://arxiv.org/pdf/2506.04586), [HTML](https://arxiv.org/abs/2506.04586)
### Authors
Wen Ding,Fan Qian
### Background
尽管最先进的语音基础模型能够生成高质量的文本伪标签，但在现实世界的大规模数据上应用半监督学习（SSL）仍然具有挑战性。这些数据的音质比受控数据集更加丰富和复杂。
### Innovation
 LESS 是一个多功能框架，使用大型语言模型（LLMs）来纠正从未监督数据中生成的伪标签。该框架包括两个步骤：首先通过 LLM 对自动语音识别（ASR）或自动语音翻译（AST）的未监督数据进行伪标签文本进行优化，然后通过数据筛选策略进一步改进。
### Conclusion
LESS 在多个语音识别和自动语音翻译评估中表现出了有效性和一致性，分别在 WenetSpeech 上实现了 3.8% 的词错误率绝对降低，在 Callhome 和 Fisher 测试集上分别实现了 BLEU 分数 0.8 和 0.7 的提高，达 34.0 和 64.7 分。这些结果表明 LESS 在多种语言、任务和领域中均具有广泛应用前景。此外，该研究已开源，以促进相关研究的进一步发展。
## 365. `cs.CL` - LLM基于参数估计的去偏方法基准 [PDF](https://arxiv.org/pdf/2506.09627), [HTML](https://arxiv.org/abs/2506.09627)
### Authors
Nicolas Audinet de Pieuchon,Adel Daoud,Connor T. Jerzak,Moa Johansson,Richard Johansson
### Background
大型语言模型（LLMs）提供了一种廉价而强大的文本标注方式，但与专家比较时往往不一致，这会影响下游研究中群体参数（如回归系数和因果效应）估计的偏差。虽然已经开发了一些去偏方法，如Design-based Supervised Learning（DSL）和Prediction-Powered Inference（PPI），但尚不清楚它们在实际研究中样本量有限的情况下的表现如何。
### Innovation
作者研究了去偏方法在不同专家标注数量下的性能，并比较了DSL和PPI在多种任务上的表现。研究发现，在大数据集的情况下，两种方法都能实现低偏差，但DSL往往在偏倚降低和实际效率上表现更好，尽管其性能不如PPI稳定。
### Conclusion
去偏方法存在偏差-方差权衡，表明需要开发更多关于计算其在有限样本中的效率的度量方法。
## 366. `cs.CL` - 通过流式内容监测进行早期干预：通过流式内容监测早期停止大语言模型有害输出 [PDF](https://arxiv.org/pdf/2506.09996), [HTML](https://arxiv.org/abs/2506.09996)
### Authors
Yang Li,Qiang Sheng,Yehan Yang,Xueyao Zhang,Juan Cao
### Background
尽管大多数大型语言模型（LLMs）都已应用了安全性对齐，但在实际产品中，LLM服务提供商通常在部署后会添加一个外部安全监护机制作为后续的监督，以确保安全。现有的监督方法主要采取全面检测的方式，在整个LLM输出中来判断是否发生有害行为，这导致了服务延迟问题。虽然最近的研究更加关注部分检测，即在生成过程中中途监管以尽早停止有害性内容，但这些方法直接使用全面检测模型，存在训练-推理不一致的问题，从而影响了整体性能。
### Innovation
本文探索了如何生成支持部分检测的数据和模型解决方案。构建了FineHarm数据集，包含29,000个细粒度标注的提示-响应对，以提供合理的token级监督。另外，提出了一种流式内容监控器(ScM)，该模型接受响应级和token级标签的双向监督，能够实时跟进LLM的生成过程，及时判断有害性。实验表明，与全面检测相比，仅查看响应的前18%token时，ScM可以在宏F1分数上提高0.95以上。此外，流式内容监控器还可以作为伪有害性标注者，有助于提升安全对齐，并获得较高的无害性评分。
### Conclusion
本文提出了一种流式内容监测方案，使其能够有效且及时地监测和干预大型语言模型的有害输出，并通过实验证明该方案在保持高准确性的同时，降低延迟并提高安全对齐质量。
## 367. `cs.CL` - 大型语言模型在连续预训练进行语言适应下的新兴能力 [PDF](https://arxiv.org/pdf/2506.00288), [HTML](https://arxiv.org/abs/2506.00288)
### Authors
Ahmed Elhady,Eneko Agirre,Mikel Artetxe
### Background
连续预训练 (CPT) 是一种流行的大型语言模型 (LLM) 的适应方法，通常会在新语言的预训练混入部分英语数据以增强效果，但其具体作用尚未得到详细研究。本文探讨了英语数据在这过程中的重要性，尤其是在目标语言的下游能力发展中的作用。研究发现，英语数据对下游能力的提升是关键的，且其缺失会导致严重的灾难性遗忘现象，影响下游任务的表现。
### Innovation
本文提出了一个语言无关的上下文学习基准 (ICL)，用以评估在连续预训练过程中语言模型的下游能力。通过这一基准，研究揭示了在不包含英语数据的情况下进行连续预训练可能带来的灾难性遗忘问题，进而导致下游任务表现的总体下降。此外，研究引入了课程学习和权重的指数移动平均 (EMA) 作为减少对英语数据依赖的有效替代方法。
### Conclusion
本文的研究结果揭示了在语言适应过程中连续预训练的动态过程，特别是在新兴能力的出现方面。研究提出了新的方法，如课程学习和EMA，以减少对英语数据的依赖。这为未来设计更有效的语言适应方法奠定了基础。
## 368. `cs.CL` - 跨注意力推测解码 [PDF](https://arxiv.org/pdf/2505.24544), [HTML](https://arxiv.org/abs/2505.24544)
### Authors
Wei Zhong,Manasa Bharadwaj,Yixiao Wang,Nikhil Verma,Yipeng Ji,Chul Lee
### Background
推测解码（SD）是一种广泛应用于加速大型语言模型（LLMs）推理的方法，尤其是在草案模型和目标模型高度匹配时。然而，最先进的SD方法通常依赖于紧密耦合的自我注意力变压器解码器，经常增加辅助池化或融合层。这种耦合使得模型越来越复杂，并且难以在不同模型之间进行推广。
### Innovation
我们提出了首个多头注意力机制的Transformer解码器SD模型——Budget EAGLE（Beagle），它在性能上与最先进的自我注意力SD模型（EAGLE-v2）相当，同时消除了所需的池化或辅助组件，简化了架构，提高了训练效率，并在训练时保持了稳定的内存使用。为了实现这种新型架构的有效训练，我们提出了两阶段块注意力训练方法，这是一种新的方法，可以在块级注意力场景中实现训练稳定性和收敛效率。实验结果表明，Beagle在推理加速和训练效率方面与EAGLE-v2相当，提供了推测解码架构的有效替代方案。
### Conclusion
全面的实验结果表明，Beagle在多个LLMs和数据集上实现了可竞争的推理加速和更高的训练效率，提供了一种强大且有效的推测解码架构选择。
## 369. `cs.CL` - MEDAL: 一种用于多语言开放领域对话评估的LLM基准框架 [PDF](https://arxiv.org/pdf/2505.22777), [HTML](https://arxiv.org/abs/2505.22777)
### Authors
John Mendonça,Alon Lavie,Isabel Trancoso
### Background
对开放领域聊天机器人的质量评估越来越多地依赖于LLM作为自动化评判者，但现有的元评估基准是静态的、过时的且缺乏多语言覆盖，这限制了它们捕捉评价中的细微弱点的能力。
### Innovation
引入了MEDAL，这是一种自动多代理框架，用于制作更具代表性且多样的开放领域对话评估基准。该方法利用了多个最先进的LLM生成用户-聊天机器人多语言对话，并基于不同种种子背景对其进行条件生成。然后，利用性能强大的LLM（GPT-4.1）进行多维度分析，揭示了跨语言性能的显著差异。基于这一大规模评估，制作了一个新的多语言元评估基准并进行精细的质量标注。随后使用MEDAL识别出当前最先进的评判者无法可靠地检测细微问题，如缺乏同理心、常识或相关性等问题。
### Conclusion
利用MEDAL，揭示了当前最先进的评断者无法可靠地检测一些细微问题，如缺乏同理心、常识或相关性；使用MEDAL制作了一个新的多语言评估基准并进行了细致的人机标注，评估了多个推理和非推理的LLM作为开放领域对话评判者的效能。
## 370. `cs.CL` - 通过扰动表现稳定探测校准LLM信心 [PDF](https://arxiv.org/pdf/2505.21772), [HTML](https://arxiv.org/abs/2505.21772)
### Authors
Reza Khanmohammadi,Erfan Miahi,Mehrsa Mardikoraem,Simerjot Kaur,Ivan Brugere,Charese H. Smiley,Kundan Thind,Mohammad M. Ghassemi
### Background
大型语言模型（LLMs）的不确定性校准对其可靠性产生负面影响，因为当前方法未能准确估计模型的置信度。CCPS（通过探测扰动表现稳定校准LLM信心）是一种新颖的方法，用于分析LLMs内部表现的稳定性。该方法通过对最终隐藏状态进行有针对性的对抗性扰动，提取反映模型对这些扰动响应的特征，并使用轻量级分类器预测答案的正确性。CCPS在具有不同类型参数的LLMs上进行了评估，显示出比现有方法显著的性能提升。它在不同LLM和基准测试中的表现证明了其作为更有效、更广泛应用并能提高LLMs可信度的置信度估算方法的有效性。
### Innovation
CCPS通过对LLMs最终隐藏状态进行有针对性的对抗性扰动，分析模型对这些扰动的响应，并使用轻量级分类器预测答案正确性，从而提供了一种更有效的内部表现稳定探测方法以校准LLM的信心估计。该方法在多个LLM和基准测试中显著提高了性能指标，包括降低预期校准误差、降低Brier分数、增加准确性、精确召回曲线面积和精确-召回曲线下的面积。
### Conclusion
CCPS为估计LLM置信度提供了一种高效、广泛应用且更准确的解决方案，提高了其可靠性，增强了用户对LLMs的信任。
## 371. `cs.CL` - IGD：通过信息增益建模LLM中的Token决断性以实现个性化推荐 [PDF](https://arxiv.org/pdf/2506.13229), [HTML](https://arxiv.org/abs/2506.13229)
### Authors
Zijie Lin,Yang Zhang,Xiaoyan Zhao,Fengbin Zhu,Fuli Feng,Tat-Seng Chua
### Background
大型语言模型（LLMs）通过将项目预测框作为标记级语言生成任务来展现出了推荐的强大潜力。目前已有的方法在优化和解码过程中均等对待所有项目标记，简单地追求似然性最大化，忽视了标记级差异的重要性，即许多标记对项目区分性贡献甚微，却可能主导优化或解码过程。
### Innovation
本文提出了一个新颖的角度，将项目生成视为一个决策过程，并通过每个标记提供的信息增益（IG）来衡量标记决断性。实验发现，尽管许多标记的信息增益较低，但它们往往拥有较高的logits，不均衡地影响训练损失和解码，可能损害模型性能。因此，本文引入了一种基于信息增益的决断性感知标记处理（IGD）策略，将标记决断性整合到调优和解码中。具体而言，IGD 在调优阶段抑制低IG标记，重新平衡解码以强调高IG标记。IGD 突破了单纯的似然性最大化，有效优先考虑高决断性标记。
### Conclusion
本研究在四个基准数据集上进行了广泛的实验，使用两种LLM后端验证了IGD策略在推荐准确性方面的优越表现，相对于强基线，IGD在常用排名指标上取得了显著的进步。
## 372. `cs.CL` - MuseScorer:大规模创意独特性评分 [PDF](https://arxiv.org/pdf/2505.16232), [HTML](https://arxiv.org/abs/2505.16232)
### Authors
Ali Sarosh Bangash,Krish Veera,Ishfat Abrar Islam,Raiyan Abdul Baten
### Background
目前有一种客观、合理的方法来评估创意的独特性，即通过统计频率来衡量创意在人群中的罕见程度。这种方法已经在创造力研究中长期使用。然而，这需要人工将创意重新分类，这是一项主观性强、耗时、容易出错且在大规模应用时脆弱的工作。本文提出了MuseScorer，一种全自动、心理测量验证的基于频率的独特性评分系统，它将大型语言模型与外部检索集成，能够自动为新创意找到语义相似的类别并由大型语言模型进行判断。这些类别使得无需人工标注就能进行基于频率的独特性评分，在五个数据集中（参与者数量N_{参与者}=1143，创意数量n_{想法}=16,294），MuseScorer的人类标注者的创意聚类结构（AMI得分=0.59）和参与者水平评分（相关系数r=0.89）保持一致，同时证明了高度的收敛性和外部效度。系统能够实现有规模的、意图敏感的人类一致的独特性评估，适用于创造力研究。
### Innovation
MuseScorer 使用大型语言模型和外部检索自动为新创意创建类别，不再需要手动将创意进行分类，从而提高了效率和准确性。该系统能够进行大规模的、意图敏感的、人类一致的独特性评估，适用于创造力研究。
### Conclusion
MuseScorer在几个数据集上的表现与人类标注者相当，并且在收敛性和外部效度上表现出色。该系统能够自动给出创意的独特性评分，不仅减轻了工作负担，还提高了评分的一致性和可扩展性。
## 373. `cs.CL` - Translationese-index：使用似然比进行分级和可泛化的Translationese测量 [PDF](https://arxiv.org/pdf/2507.12260), [HTML](https://arxiv.org/abs/2507.12260)
### Authors
Yikang Liu,Wanyang Zhang,Yiming Wang,Jialong Tang,Pei Zhang,Baosong Yang,Fei Huang,Rui Wang,Hai Hu
### Background
Translationese涉及翻译文本特有的语言特征，以往的研究将其作为二分类问题，即原始文本与翻译文本之间的区分。本文作者认为Translationese应该分级而非二元化，并提出了首个Translationese测量方法——Translationese指数（T-index），利用两种对比微调语言模型的似然比计算得出。
### Innovation
提出了首个Translationese测量方法——Translationese指数（T-index），通过比对两种对比微调语言模型的似然比来计算。本文使用合成翻译和野生翻译来评估T-index在跨域设置中的泛化能力及与人类判断的一致性。T-index能够在不同体裁、作者和语言对的情况下有效捕捉Translationese特征，并且与现有的机器翻译质量评估（QE）指标如BLEU和COMET的相关性较低，说明T-index可以作为一种补充指标在MT QE中使用。
### Conclusion
T-index能够跨领域泛化，有效捕捉Translationese特征，且与现有机器翻译质量评估指标相关性低，表明其作为补充指标在机器翻译质量评估中的潜力。
## 374. `cs.CL` - MUG-Eval: 任何语言多语言生成能力的代理评估框架 [PDF](https://arxiv.org/pdf/2505.14395), [HTML](https://arxiv.org/abs/2505.14395)
### Authors
Seyoung Song,Seogyeong Jeong,Eunsu Kim,Jiho Jin,Dongkwan Kim,Jay Shin,Alice Oh
### Background
评价大型语言模型（LLMs）的文本生成能力具有挑战性，尤其是在资源稀缺的语言中，直接评估的方法稀缺。现有研究主要局限于高资源语言，对于低资源语言则缺乏有效的方法。
### Innovation
提出了MUG-Eval框架，通过将现有基准转化为会话任务，并测量LLM在这些任务中的准确性来评估其多语言生成能力。该框架设计的对话任务要求目标语言的有效沟通，采用任务成功率作为会话生成成功的代理。MUG-Eval的优势在于它不依赖于特定语言的NLP工具或标注数据集，也不依赖于LLM作为判官，后者在高资源语言之外的评估质量较低。
### Conclusion
评估了8种LLM在涵盖高、中、低资源的30种语言中的表现，发现MUG-Eval与现有基准（相关系数大于0.75）高度相关，并能跨语言和模型标准化地进行比较。该框架提供了一种适用于数千种语言、成本效益高的多语言生成评估方案。
## 375. `cs.CL` - 自动语音转写对说话人归属性的影响 [PDF](https://arxiv.org/pdf/2507.08660), [HTML](https://arxiv.org/abs/2507.08660)
### Authors
Cristina Aggazzotti,Matthew Wiesner,Elizabeth Allyn Smith,Nicholas Andrews
### Background
说话人归属性任务是指基于语言使用模式从演讲记录中识别说话人。这项任务在音频不可用（如被删除）或不可靠（如匿名）时尤其有用。先前的研究主要集中在利用人工标注者生成的演讲记录来进行说话人归属性的可行性上。而在现实场景中，通常只能获得由自动语音识别（ASR）系统生成的错误较多的演讲记录。本文是对自动转写对说话人归属性性能影响的全面研究。
### Innovation
本文首次对自动转写对说话人归属性性能的影响进行了全面研究。研究发现，即使存在字级转录错误，说话人归属性的表现仍然很稳健；转录目标与说话人归属性性能的相关性较低；相比之下，ASR系统的属性对说话人归属性更有影响。研究结果表明，使用ASR生成的带有错误的记录进行说话人归属性分析不仅效果不差，有时甚至优于基于人工记录的分析。
### Conclusion
使用ASR生成的带有错误的记录进行说话人归属性分析的效果与基于人工记录的分析相当，甚至更好，因为来自ASR的错误转录可以揭示说话人身份的具体特征。
## 376. `cs.CL` - XAutoLM: 通过元学习和自动机器学习高效微调语言模型 [PDF](https://arxiv.org/pdf/2508.00924), [HTML](https://arxiv.org/abs/2508.00924)
### Authors
Ernesto L. Estevanell-Valladares,Suilan Estevez-Velarde,Yoan Gutiérrez,Andrés Montoyo,Ruslan Mitkov
### Background
机器学习专家利用专业知识在模型选择、超参数优化和资源分配中做出决策，这在微调语言模型（LMs）中尤为重要。由于重复试验的计算成本和环境影响，需要一个高效的自动化框架来同时处理模型选择和超参数优化任务。现有自动化框架并未很好地平衡这些需求。
### Innovation
我们提出XAutoLM，一种元学习增强的AutoML框架，通过重用过去的经历来高效优化区分性和生成性LM微调管线。XAutoLM通过提取与任务和系统相关的元特征，使得采样偏向有价值的配置，远离昂贵的死胡同。在四个文本分类和两个问答基准测试上，XAutoLM在五个任务中超越零-shot优化器的峰值F1分值，将其平均评估时间减少多达4.5倍，将搜索错误率降低多达七倍，发现多达50%更多的管道在零-shot帕累托前沿之上。相比之下，简单的基于记忆的基线则表现不佳。
### Conclusion
我们发布了XAutoLM和我们的经验和存储，以促进自然语言处理社区中资源高效的绿色人工智能微调。
## 377. `cs.CL` - LLM中主观行为与偏好：浏览语言 [PDF](https://arxiv.org/pdf/2508.15474), [HTML](https://arxiv.org/abs/2508.15474)
### Authors
Sai Sundaresan,Harshita Chopra,Atanu R. Sinha,Koustava Goswami,Nagasai Saketh Naidu,Raghav Karan,N Anushka
### Background
大型语言模型（LLM）据称能够跨领域和任务提供灵活性，以为具有广泛行为和偏好的用户提供帮助。然而，当用户具有固有的主观行为和偏好时，比如他们在网站或应用中的独特浏览行为，这一点可能不再适用。这些行为和偏好是由用户的浏览页面行为日志反映出来的，形成了一种类似于个人“语言”的模式，但缺乏自然语言的结构和语法规则。
### Innovation
研究引入了一种针对主观行为的聚合语言模型训练方法，即HeTLM（异质集群特定参数的训练语言模型），以探索小型语言模型是否能比大型语言模型更好地表示“浏览语言”。同时，研究了单一模型中的参数多样性是否能捕捉到多种用户的异质行为和偏好，并是否能提高模型在用户层面的对齐程度。
### Conclusion
研究发现，基于页面级别的小型语言模型训练优于预训练或微调的大模型；异质集群参数的HeTLM比相同家族的单一模型具有更好的性能，特别是在参数数量控制的情况下；生成的平均值更高且方差更低，表明改善了用户层面的对齐程度。
## 378. `cs.CL` - 低资源语言中LLM数据生成策略的严格评估 [PDF](https://arxiv.org/pdf/2506.12158), [HTML](https://arxiv.org/abs/2506.12158)
### Authors
Tatiana Anikina,Jan Cegin,Jakub Simko,Simon Ostermann
### Background
大型语言模型（LLMs）被广泛用于生成合成文本数据，用于训练更小的专业模型。然而，对于低资源语言设置，各种生成策略的比较研究尚缺乏。虽然已经提出了多种提示策略，如示范、基于标签的总结和自我修订，但它们的有效性差异仍不清楚，特别是对于低资源语言。因此，本文系统地评估了这些生成策略及其组合在11种类型多样、包括几种极其低资源的语言中的性能。利用三种NLP任务和四个开源LLM，评估了下游模型在生成数据与标准数据之间的表现差异。研究表明，目标语言示范与LLM基础修订的策略性组合效果较强，某些情况下与实际数据的差距缩小至5%以内。同时，研究发现智能提示技术可以削弱大模型的优势，表明在低资源场景中使用较小模型生成合成数据的有效策略。
### Innovation
文章在11种类型上多样（包括一些极其低资源的语言）的情况下，系统地评估了多种生成策略和它们的组合效果，并通过三种NLP任务和四个开源LLM进行了综合评估。研究的重点在于目标语言示范与基于LLM的修订策略的优化组合，以及智能生成策略在低资源语言中的应用前景。此外，研究发现即使在使用大型LLM的情况下，资源较小的模型也可以通过智能生成策略展示出竞争力。
### Conclusion
研究结果表明，目标语言示范与LLM基础修订的策略组合在低资源语言设置中表现强劲，有效地缩小了与实际数据的差距。未来的研究可以进一步探索更多生成策略的组合和优化，以更好地服务于低资源语言的学习和发展。
## 379. `cs.CL` - 通过解纠缠的概念表示发现语义子维度 [PDF](https://arxiv.org/pdf/2508.21436), [HTML](https://arxiv.org/abs/2508.21436)
### Authors
Yunhao Zhang,Shaonan Wang,Nan Lin,Xinyi Dong,Chong Li,Chengqing Zong
### Background
理解概念语义的核心维度是揭示语言和大脑中意义组织的基础。现有方法往往依赖预定义的语义维度，这些维度仅提供粗略的表示，未能捕捉更精细的概念区别。
### Innovation
本文提出了一种新的框架，以研究粗粒度语义维度下的子维度。具体而言，我们引入了一种解纠缠连续语义表示模型（DCSRM），将大型语言模型的词嵌入分解为多个子嵌入，每个子嵌入都编码特定的语义信息。通过这些子嵌入，我们确定了一组可解释的语义子维度。为了评估它们的神经生物学可行性，我们使用体素级编码模型将这些子维度映射到大脑激活。
### Conclusion
进一步分析表明，语义维度遵循不同的原则结构，极性是驱动它们分解为子维度的关键因素。所识别的子维度的神经相关性支持了其认知和神经科学的可行性。
## 380. `cs.CL` - LongCat-Flash 技术报告 [PDF](https://arxiv.org/pdf/2509.01322), [HTML](https://arxiv.org/abs/2509.01322)
### Authors
Meituan LongCat Team,Bayan,Bei Li,Bingye Lei,Bo Wang,Bolin Rong,Chao Wang,Chao Zhang,Chen Gao,Chen Zhang,Cheng Sun,Chengcheng Han,Chenguang Xi,Chi Zhang,Chong Peng,Chuan Qin,Chuyu Zhang,Cong Chen,Congkui Wang,Dan Ma,Daoru Pan,Defei Bu,Dengchang Zhao,Deyang Kong,Dishan Liu,Feiye Huo,Fengcun Li,Fubao Zhang,Gan Dong,Gang Liu,Gang Xu,Ge Li,Guoqiang Tan,Guoyuan Lin,Haihang Jing,Haomin Fu,Haonan Yan,Haoxing Wen,Haozhe Zhao,Hong Liu,Hongmei Shi,Hongyan Hao,Hongyin Tang,Huantian Lv,Hui Su,Jiacheng Li,Jiahao Liu,Jiahuan Li,Jiajun Yang,Jiaming Wang,Jian Yang,Jianchao Tan,Jiaqi Sun,Jiaqi Zhang,Jiawei Fu,Jiawei Yang,Jiaxi Hu,Jiayu Qin,Jingang Wang,Jiyuan He,Jun Kuang,Junhui Mei,Kai Liang,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Liang Gao,Liang Shi,Lianhui Ma,Lin Qiu,Lingbin Kong,Lingtong Si,Linkun Lyu,Linsen Guo,Liqi Yang,Lizhi Yan,Mai Xia,Man Gao,Manyuan Zhang,Meng Zhou,Mengxia Shen,Mingxiang Tuo,Mingyang Zhu,Peiguang Li,Peng Pei,Peng Zhao,Pengcheng Jia,Pingwei Sun,Qi Gu,Qianyun Li,Qingyuan Li,Qiong Huang,Qiyuan Duan,Ran Meng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shizhe Wu,Shuai Liang
### Background
为了应对可扩展性和计算效率的需求，研究团队设计并实现了LongCat-Flash，这是一种560亿参数的MoE语言模型，兼具高效能计算和先进的代理能力。为了适应大规模训练，研究团队开发了一个全面的模型扩展框架，结合了超参数传输、模型增长初始化、多角度稳定性套件和确定性计算，以实现稳定和可复制的训练。
### Innovation
LongCat-Flash的主要创新包括零计算专家（实现动态计算预算分配）和短连接MoE（增加计算-通信重叠窗口）。此外，该模型展示了显著提高推理效率和吞吐量，同时在大规模训练中实现了超过20万亿个令牌的训练，并在较低成本下实现了每秒100个令牌以上的推理速度。该模型还通过大规模预训练和精细的中途及后续训练提升了代理能力。
### Conclusion
LongCat-Flash作为非思考的基础模型，展示了与领先模型相竞争的性能，并在代理任务方面展现出特别的优势。其模型检查点已开源，旨在促进社区研究。
## 381. `cs.CL` - Causal2Vec：提高仅解码器大语言模型作为通用嵌入模型的效果 [PDF](https://arxiv.org/pdf/2507.23386), [HTML](https://arxiv.org/abs/2507.23386)
### Authors
Ailiang Lin,Zhuoyun Li,Kotaro Funakoshi,Manabu Okumura
### Background
目前，仅解码器的大语言模型（LLMs）常被用于构建嵌入模型，这些模型能够将自然语言文本的有效语义信息高效地编码为稠密向量表示，用于多种嵌入任务。现有方法大多集中在移除LLMs中的因果注意力掩码以实现双向注意力，这可能会削弱模型在预训练过程中获得的语义信息提取能力。此外，领先的单向方法通常需要额外输入文本来克服因果注意力固有的限制，这不可避免地提高了计算成本。
### Innovation
本文提出了一种名为Causal2Vec的通用嵌入模型，旨在提高仅解码器LLMs的性能，而不改变其原有架构或增加显著的计算负担。首先，通过一种轻量级的BERT风格模型对输入文本进行预编码，生成一个Contextual token，并将其附加到LLMs的输入序列中，让每个token都能捕获上下文信息，即使不考虑未来的token。此外，通过将Contextual token和EOS token的最后一个隐藏状态连接起来作为最终文本嵌入，Causal2Vec缓解了最后一token池化引起的近期偏差，帮助LLMs更好地利用Contextual token中编码的语义信息。
### Conclusion
实践表明，Causal2Vec在仅基于公共资源检索数据集训练的模型中，在大规模文本嵌入基准（MTEB）上取得了最先进的性能，同时通过最多减少85%的序列长度和82%的推理时间，实现了比最佳方法更高效的结果。
## 382. `cs.CL` - OpenWHO：低资源语言医疗翻译领域的文档级平行语料库 [PDF](https://arxiv.org/pdf/2508.16048), [HTML](https://arxiv.org/abs/2508.16048)
### Authors
Raphaël Merx,Hanna Suominen,Trevor Cohn,Ekaterina Vylomova
### Background
在机器翻译（MT）领域，医疗是一个关键领域，具有广泛的部署和专用词汇。然而，在低资源语言中的MT评估数据集仍然存在不足。为解决这一问题，本研究引入了OpenWHO，这是一个来自世界卫生组织e学习平台的文档级平行语料库，包含2,978份文档和26,824个句子，并且跨越了20多种语言，其中9种为低资源语言。
### Innovation
本研究通过引入OpenWHO——一个由专业作者编写并经过严格翻译的文档级平行语料库，填补了低资源语言医疗机器翻译评估数据集的空白。评估结果显示，现代大型语言模型（LLMs）普遍优于传统MT模型，其中Gemini 2.5 Flash在低资源测试集上的成绩比NLLB-54B提高了4.79个ChrF点。此外，研究发现了LLM上下文利用对准确度的影响，特别是在特殊领域如医疗方面，文档级翻译的益处尤为显著。
### Conclusion
本研究通过发布OpenWHO语料库，鼓励进一步研究低资源语言医疗机器翻译领域，并展示了LLMs在低资源语言医疗翻译中的优越性。
## 383. `cs.CL` - LLM生成文本的风格差异基准 [PDF](https://arxiv.org/pdf/2509.10179), [HTML](https://arxiv.org/abs/2509.10179)
### Authors
Jiří Milička,Anna Marklová,Václav Cvrček
### Background
本研究探讨了由人类撰写和大型语言模型（LLMs）生成的文本之间的体裁变异。使用Biber的多维分析（MDA）方法，比较人类撰写和人工智能生成的对应文本，以发现LLMs在哪些维度上最显著、最系统地与人类不同。研究使用了新的AI-Brown数据集，将其与代表现代英国英语的BE-21进行比较。此外，还进行了类似的分析，使用捷克语数据集AI-Koditex及其多维模型对捷克语进行研究。研究分析了16种前沿模型在不同环境和提示下的表现，重点比较基模型和指令调优模型之间的差异。
### Innovation
本研究首次使用了AI-Brown数据集来研究LLMs与人类文本之间的差异，并进行了跨语言（捷克语）的平行分析。通过比较不同模型表现，制定了一个基准，使模型能够在可解释的维度上进行比较和排名。
### Conclusion
研究结果表明，可以通过创建基准来对比和排名模型，从而在可解释的维度上评估模型间的差异。这对于改进LLM的性能和理解其潜在偏差具有重要意义。
## 384. `cs.CL` - Middo：基于闭合回路学习的增强大语言模型微调的模式感知动态数据优化 [PDF](https://arxiv.org/pdf/2508.21589), [HTML](https://arxiv.org/abs/2508.21589)
### Authors
Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu
### Background
 Supervised Fine-Tuning (SFT) 大型语言模型（LLM）的基本前提是高质量的训练数据。现有的数据选择和数据合成方法虽然能提高数据质量，但在静态数据集的管理上通常存在局限性，难以适应不断发展的模型能力。因此，现有方法往往不能随着模型能力的变化而调整。
### Innovation
本研究提出了一个自适应模型启发的动态数据优化框架Middo，该框架包含模型意识数据选择和语义保持数据精炼。Middo的独特之处在于建立了闭环优化系统，通过自我参照诊断模块、自适应优化引擎，以及动态学习原则，持续地将次优样本转化成教学价值高的训练点，同时保持语义完整。这种方法与传统的单一过滤/合成方法不同，它能够随着模型能力的变化而持续进化优化数据集。实验表明，Middo能够提高种子数据的质量并增强LLM的表现，平均提升准确率7.15%，同时保持数据集规模不变，从而确立了可持续的LLM训练的新范式，即数据和模型之间的动态人机共生进化。
### Conclusion
本研究通过Middo框架，确立了通过闭环学习实现数据和模型动态共生进化的新范式，能够持续提升LLM的表现，保持原始数据集规模，且结果已经通过多个基准实验验证。该框架及其相关代码将在未来向公众开放。
## 385. `cs.CL` - SENTRA：用于LLM文本检测的选定下一个令牌变换器 [PDF](https://arxiv.org/pdf/2509.12385), [HTML](https://arxiv.org/abs/2509.12385)
### Authors
Mitchell Plyler,Yilun Zhang,Alexander Tuzhilin,Saoud Khalifah,Sen Tian
### Background
随着大规模语言模型（LLMs）变得越来越强大和普及，它们被误用于恶意目的的风险也在增加。当前的一个挑战是检测由LLMs生成但未明确声明的文本，这对手动审核带来巨大压力。
### Innovation
本文提出了一种新型、通用且监督式的LLM文本检测器——SElected-Next-Token tRAnsformer（SENTRA）。SENTRA利用选择性下一个令牌概率序列，并通过大规模未标注数据进行对比预训练。实验表明，SENTRA在跨24个主题领域、三个流行公共数据集上表现突出，显著优于现有的基础模型。
### Conclusion
SENTRA作为一种通用分类器，在跨领域设置中表现出色，能够显著提高检测LLM生成文本的准确性。
## 386. `cs.CL` - WangchanThaiInstruct：适用于泰国文化意识、多任务和多领域评估的指令遵循数据集 [PDF](https://arxiv.org/pdf/2508.15239), [HTML](https://arxiv.org/abs/2508.15239)
### Authors
Peerat Limkonchotiwat,Pume Tuchinda,Lalita Lowphansirikul,Surapon Nonesung,Panuthep Tasawong,Alham Fikri Aji,Can Udomcharoenchaikit,Sarana Nutanong
### Background
现有的大型语言模型在英语指令遵循方面表现出色，但在泰语等低资源语言方面的表现仍相对不足。现有基准多依赖于翻译数据，未能涵盖文化和领域特定的细微差别，这在现实应用中是必不可少的。本研究提出了WangchanThaiInstruct，这是一个由真人编写的泰国语数据集，涵盖了四个专业领域和七种任务类型，旨在评估和调优指令。通过多阶段的质量控制过程，该数据集包含标注员、领域专家和AI研究人员的参与，支持两项研究：零样本评估，展示了文化和专业特定任务的性能差距；指令调优研究，通过消融实验隔离原汁原味的监督效果。
### Innovation
WangchanThaiInstruct 是一个专门为泰国文化、多任务和多领域评估设计的指令遵循数据集，它通过多阶段的质量控制过程确保了数据质量和真实性。同时，通过不依赖翻译数据，直接建立了覆盖不同领域的高质量语料库，这有助于揭示并解决由于文化和专业差异导致的模型性能差异。该数据集能够帮助模型更好地在低资源语言环境中工作，也提供了更加准确的真实世界应用评估数据。
### Conclusion
通过使用WangchanThaiInstruct数据集进行微调，模型在同域和跨域基准测试中的表现优于使用翻译数据的模型，这表明在低资源语言环境中，需要通过文化背景和专业背景来调整指令数据，从而提高语言模型与现实应用的契合度。
## 387. `cs.CL` - CORE-RAG: 通过强化学习实现检索增强的大语言模型无损压缩 [PDF](https://arxiv.org/pdf/2508.19282), [HTML](https://arxiv.org/abs/2508.19282)
### Authors
Ziqiang Cui,Yunpeng Weng,Xing Tang,Peiyang Liu,Shiwei Li,Bowei He,Jiamin Chen,Yansen Zhang,Xiuqiang He,Chen Ma
### Background
检索增强生成（RAG）作为一种有效提升知识时效性和响应准确性的方法，在大型语言模型（LLMs）中受到了广泛关注。然而，检索出过多的文档会显著增加输入的长度，从而导致更高的计算成本。早期的研究方向是将检索出的文档压缩成较短的文本，然后再进行上下文整合，但这种方法往往会对最终任务性能产生不利影响。由于缺乏明确的压缩目标，许多方法只能依赖固定的经验规则，这些规则无法保证压缩的内容能有效地支持最终任务。鉴于上述问题，提出了CORE方法，旨在解决RAG中的无损上下文压缩问题。CORE采用强化学习技术优化压缩过程，不需要预设的压缩标签，这样压缩器可以自动生成最能最大化LLM生成答案准确性的摘要。
### Innovation
CORE方法使用强化学习来优化文本压缩过程，从而实现从检索出的文档中生成最能支持LLM回答准确性的无损压缩摘要，这种方法避免了依靠固定经验规则带来的局限性，并在多个数据集上的实验中验证了其优越性，表现出了较高的压缩比和无损任务性能。
### Conclusion
CORE方法以3%的高压缩比，不仅避免了与直接将完整文档附加在模型前相比的性能下降，还在所有数据集上改善了平均精确匹配（Exact Match, EM）分数3.3分。研究结果证明了该方法的高效性和实用性，同时，代码将很快对外开放。
## 388. `cs.CL` - 检索增强语言模型在不确定时是否知道自己不知道？ [PDF](https://arxiv.org/pdf/2509.01476), [HTML](https://arxiv.org/abs/2509.01476)
### Authors
Youchao Zhou,Heyan Huang,Yicheng Liu,Rui Dai,Xinglin Wang,Xingchen Zhang,Shumin Shi,Yang Deng
### Background
现有的大型语言模型（LLMs）有时会生成表面上合理但实际上不正确的答案，这被称为幻觉。研究人员主要使用两种方法来减轻幻觉，分别是检索增强语言模型（RALMs）和训练后的拒绝策略。然而，目前的研究主要关注它们各自的效果，而忽视了评估RALMs的拒绝能力。本研究探讨了当模型不知道时，这些模型是否能够正确识别自己的无知状态，并进一步分析了训练后拒绝策略对这些问题的影响，以期提供一个更加全面的理解框架。
### Innovation
本研究通过提出三个问题探讨了RALMs在不同内部和外部知识状态下的校准情况，发现LLMs表现出严重的‘过度拒绝’行为；考察了Refusal-aware指令微调和上下文内微调方法对过度拒绝问题的解决情况，发现上下文内微调可以缓解过度拒绝，而R-tuning则会放大问题；发现拒绝能力与回答质量可能存在冲突。最后，提出了一种简单的训练后拒绝策略，以提高答案拒绝和正确度的总体质量。
### Conclusion
本研究对影响RALMs系统的重要因素进行了更全面的理解，深入分析了模型不确定性的处理策略，并提出了一种简单的改进方法以提高答案质量。
## 389. `cs.CL` - MedCOD：通过丰富连锁词典框架增强大型语言模型的英语到西班牙语医疗翻译 [PDF](https://arxiv.org/pdf/2509.00934), [HTML](https://arxiv.org/abs/2509.00934)
### Authors
Md Shahidul Salim,Lian Fu,Arav Adikesh Ramakrishnan,Zonghai Yao,Hong Yu
### Background
本文提出了MedCOD（Medical Chain-of-Dictionary），这是一种混合框架，旨在通过将特定领域的结构化知识融入大型语言模型（LLMs）来改进英文到西班牙文的医疗翻译。该研究结合了来自统一医学语言系统（UMLS）和LLM作为知识库（LLM-KB）的特定领域知识，以增强结构化提示和微调。研究人员构建了一个2,999篇英文-西班牙文MedlinePlus文章的平行语料库和一个包含100个句子的测试集，其中标注了结构化医学背景。
### Innovation
MedCOD框架将特定领域的知识从UMLS和LLM-KB两个不同来源整合到LLM中，通过结构化提示和基于LoRA的微调方法显著提升了翻译质量。该框架通过使用结构化提示，结合多语言变体、医学同义词和UMLS衍生定义来评估四个开源LLM（Phi-4, Qwen2.5-14B, Qwen2.5-7B, LLaMA-3.1-8B）。实验结果表明，在所有模型中MedCOD都显著提高了翻译质量。
### Conclusion
剥离研究证实，MedCOD的提示方法和模型适应交替独立提高了性能，二者结合后提高最多。这项研究表明了在大型语言模型中整合结构化知识的潜力，可提高其在医疗翻译任务中的表现。
## 390. `cs.CL` - 参数并非平等：智能隔离提升微调性能 [PDF](https://arxiv.org/pdf/2508.21741), [HTML](https://arxiv.org/abs/2508.21741)
### Authors
Yao Wang,Di Liang,Minlong Peng
### Background
监督微调（SFT）是一种关键方法，用于将大规模语言模型（LLMs）适应下游任务，但参数更新范围广泛可能导致某些任务的进步而牺牲其他任务的进步。这种现象被称为``跷跷板现象''，限制了SFT的效果。为了应对这一挑战，该论文提出了一种名为CPI-FT（Core Parameter Isolation Fine-Tuning）的新型框架。该方法首先独立地将LLM微调于每个任务上，通过量化参数更新幅度来确定其核心参数区域；基于这些区域的重叠，相似的区域聚类形成联合建模的集群。另外，一个参数融合技术被引入：对于每个任务，从其独立微调模型中获取的核心参数直接移植到统一的主干中，非核心参数通过Spherical Linear Interpolation (SLERP)平滑融合，防止有害干扰。最后，利用多任务数据进行轻量级的混合微调，同时冻结先前任务的核心区域以防止灾难性遗忘。
### Innovation
提出了CPI-FT框架，包括独立微调识别核心参数区域、基于区域重叠聚类形成任务集群、引入参数融合技术、并采用轻量级多任务微调并冻结先前任务的核心区域以防止遗忘。
### Conclusion
在多项公开基准测试中，该方法显著减轻了任务干扰和遗忘，且在多次实验中持续优于标准的多任务和多阶段微调基线。
## 391. `cs.CL` - Empathy-R1: 长文本心理健康支持中的链式共情及强化学习框架 [PDF](https://arxiv.org/pdf/2509.14851), [HTML](https://arxiv.org/abs/2509.14851)
### Authors
Xianrong Yao,Dong She,Chenxu Zhang,Yimeng Zhang,Yueru Sun,Noman Ahmed,Yang Gao,Zhanpeng Jin
### Background
共情对于有效的心理健康支持至关重要，尤其是在处理长咨询文本（LCTs）时。现有的大型语言模型（LLMs）常常生成语义流畅但缺乏真正心理支持所需的结构化推理的回复，特别是在中国文化背景下。为了弥补这一差距，本研究介绍了一种名为Empathy-R1的新颖框架，该框架结合了链式共情推理过程和强化学习以提高LCTs回复质量。
### Innovation
提出了Empathy-R1框架，利用新的大规模中文数据集Empathy-QA和双阶段训练过程，首先通过监督微调使模型学习链式共情的推理结构，然后使用由专门奖励模型引导的强化学习进一步优化最终回复的相关性和上下文适用性。该框架通过确保回复具有可解释性和上下文精细度，显著改进了大型语言模型在心理健康领域的应用。
### Conclusion
实验结果表明，Empathy-R1在关键自动评估指标上表现出色。更重要的是，人类评估证实了其优越性，相较于强大的基线模型，胜出率达到了44.30%。通过提供可解释和上下文细微的回复，Empathy-R1为负责任且真正有益的AI心理健康支持发展做出了重要贡献。
## 392. `cs.CL` - FLARE: Faithful Logic-Aided Reasoning and Exploration [PDF](https://arxiv.org/pdf/2410.11900), [HTML](https://arxiv.org/abs/2410.11900)
### Authors
Erik Arakelyan,Pasquale Minervini,Pat Verga,Patrick Lewis,Isabelle Augenstein
### Background
当前的大型语言模型（LLMs）驱动的现代问答（QA）和推理方法通常依赖于提示技术，如链式思考（CoT），假设这将使生成内容在问题空间和范围内进行更精细的探索和推理。然而，这些方法在生成与模型中间推理一致的输出时存在问题。另一方面，诸如Faithful CoT（F-CoT）等神经符号方法试图结合LLMs和外部符号求解器，虽然这种方法具有高度的忠实度，但通常需要为代码生成训练的模型，并难以处理模糊或难以严格形式化的过程。
### Innovation
介绍了FLARE（Faithful Logic-Aided Reasoning and Exploration），一种新的可解释方法，用于通过任务分解来遍历问题空间。该方法利用LLM进行解决方案规划，将查询软形式化为逻辑编程代码的事实和谓词，并使用全面的多跳搜索模拟代码执行。这种方法允许计算推理过程相对于生成代码的忠实度，并在无需依赖外部求解器的情况下分析多跳搜索的步骤。FLARE方法在7/9个元理由任务中达到了SOTA结果，进一步展示了模型忠实度与整体性能正相关，并通过多跳搜索过程中最佳推理确定关键因素。
### Conclusion
FLARE方法在广泛的元理由问题上实现了SOTA结果，证明了模型忠实度与整体性能之间的正相关关系，并通过多跳搜索过程中的最佳推理确定了关键因素，从而帮助实现正确的答案。
## 393. `cs.CL` - SuPreME：一种多模态心电图表示学习的监督预训练框架 [PDF](https://arxiv.org/pdf/2502.19668), [HTML](https://arxiv.org/abs/2502.19668)
### Authors
Mingsheng Cai,Jiuming Jiang,Wenhao Huang,Che Liu,Rossella Arcucci
### Background
心血管疾病是全球导致死亡和残疾的主要原因。心电图（ECG）对于诊断和监控心脏健康至关重要，但获取大规模标注的心电图数据集需要大量的时间和劳动。近年来的心电图自监督学习方法通过学习特征来缓解这一问题，但它们不能捕捉到详细的临床语义，并且需要大量的特定任务的微调。
### Innovation
我们提出了SuPreME，一种监督预训练框架，用于多模态ECG表示学习。SuPreME使用大型语言模型（LLMs）从ECG报告实体中一次性离线提取结构化的诊断标签，以去噪、标准化心脏概念并提高临床表示学习。通过融合ECG信号与心脏查询文本而非固定标签，SuPreME能够在不进行进一步微调的情况下对未见过的心脏条件进行零样本分类。该方法在六个下游数据集上评估，包括106种心脏条件，实现77.20%的零样本AUC性能，超过最先进的ECG自监督学习方法4.98个百分点。
### Conclusion
实验结果表明，SuPreME能够利用结构化的、临床相关的知识来生成高质量的心电图表示。
## 394. `cs.CL` - DischargeSim: 出院时教育医生-患者通信的模拟基准 [PDF](https://arxiv.org/pdf/2509.07188), [HTML](https://arxiv.org/abs/2509.07188)
### Authors
Zonghai Yao,Michael Sun,Won Seok Jang,Sunjae Kwon,Soie Kwon,Hong Yu
### Background
出院沟通是患者护理中关键但尚未充分探索的部分，其目标从诊断转向教育。尽管最近的大语言模型基准测试强调了就诊期间的诊断推理能力，但它们未能评估模型在就诊后辅助患者的能力。该研究提出了DischargeSim，一种新的基准测试方法，评估大语言模型在做个性化出院教育方面的表现。该研究通过模拟复杂多轮对话来测试LLM在帮助不同心理社会背景患者（如健康素养、教育程度和情绪）方面的教育能力。对话是基于六个临床相关的话题结构的，并且根据对话质量（通过自动和模型评价）、个性化文档生成和患者理解三个方面进行评估。研究表明，不同患者的教育效果存在显著差异，模型大小并不总是带来更好的教育结果，突显了策略使用和内容优先级之间的权衡。DischargeSim朝着在就诊后的临床教育中基准测试大语言模型并促进公平、个性化的患者支持迈出了第一步
### Innovation
引入了DischargeSim，一种新的基准测试，用于评估LLM在个性化出院教育中的表现。它通过模拟涉及多种心理社会背景患者多层次对话来全面评估模型的教育能力，包括血缘关系、教育程度和情绪。 DischargeSim的独特之处在于，它不仅仅关注模型大小，还强调了策略使用和内容优先级之间的影响，这在现有的大语言模型基准测试中可能没有得到充分展示。
### Conclusion
DischargeSim为大语言模型在就诊后临床教育的基准测试和促进公平、个性化的患者支持迈出了第一步。研究表明，大语言模型在出院教育方面的表现存在显著差异，模型大小并不总是带来更好的教育结果，为未来研究提供了方向，强调了策略使用和内容优先级之间的权衡。
## 395. `cs.CL` - AdaSteer: 你的对齐大语言模型天生是一个自适应的脱逃防御者 [PDF](https://arxiv.org/pdf/2504.09466), [HTML](https://arxiv.org/abs/2504.09466)
### Authors
Weixiang Zhao,Jiahe Guo,Yulin Hu,Yang Deng,An Zhang,Xingyu Sui,Xinyang Han,Yanyan Zhao,Bing Qin,Tat-Seng Chua,Ting Liu
### Background
尽管在安全性对齐方面做出了大量努力，大语言模型（LLMs）仍然容易受到脱逃攻击（jailbreak attacks）。现有的训练免检防手段依赖固定的引导系数，导致保护效果不佳，并增加了对良性输入的误拒率。
### Innovation
提出了AdaSteer，一种自适应激活引导方法，能够根据输入的特点动态调整模型行为。该方法识别了两个关键属性：拒绝定律（R-Law）和危害性定律（H-Law），并结合拒绝方向（RD）和危害方向（HD）引导输入表示，通过逻辑回归学习自适应系数，确保强大的脱逃防御能力同时保持对良性输入的处理。
### Conclusion
实验表明，使用LLaMA-3.1, Gemma-2和Qwen2.5进行多个脱逃攻击时，AdaSteer方法显著优于基线方法，且对功能的影响最小。实验结果表明，可解释的模型内部结构在LLMs中实现实时、灵活的安全控制具有巨大潜力。
## 396. `cs.CL` - LLM Agents at the Roundtable: A Multi-Perspective and Dialectical Reasoning Framework for Essay Scoring [PDF](https://arxiv.org/pdf/2509.14834), [HTML](https://arxiv.org/abs/2509.14834)
### Authors
Jinhee Jang,Ayoung Moon,Minkyoung Jung,YoungBin Kim,Seung Jin Lee
### Background
大型语言模型（LLMs）的出现为自动作文评分（AES）带来了新的范式，这是一个在教育领域长期且实用的自然语言处理应用。然而，实现多角度的人类水平理解和判断仍然具有挑战性。现有的零样本AES方法难以达到这种效果，尤其是在评分细致和与人类评分一致方面存在不足。
### Innovation
本文提出了一种名为Roundtable Essay Scoring（RES）的多智能体评估框架，旨在在零样本设置下进行精确而与人类评分一致的评分。该框架基于LLMs构建评卷智能体，每个智能体针对特定的提示和主题上下文进行定制。每个智能体独立生成基于特征的评分标准，并进行多角度评估。通过模拟圆桌讨论模式，RES通过辩证推理过程将个体评估汇总为一个最终的整体评分，更加接近人类评分。该框架通过促进具有不同评估视角的智能体之间的协作和共识，提升了零样本作文评分的性能。实验结果显示，RES相比传统的提示方法在ASAP数据集上平均QWK提升了34.86%。
### Conclusion
通过协作和共识，RES在多角度和辩证推理框架下实现了更精确和与人类评分一致的作文评分，明显优于之前的零样本作文评分方法。
## 397. `cs.CL` - P2VA: 将人物描述转换为语音属性以实现公平可控的文本转语音 [PDF](https://arxiv.org/pdf/2505.17093), [HTML](https://arxiv.org/abs/2505.17093)
### Authors
Yejin Lee,Jaehoon Kang,Kyuhong Shim
### Background
尽管大语言模型（LLMs）和个人化的声音生成系统已经取得了显著进步，但在用户试图根据模糊的人物描述生成符合其预期声音角色时，存在可用性差距。大多数用户缺乏指定详细语音属性的专业知识，这往往会误导TTS系统的理解。为了解决这些问题，我们引入了Persona-to-Voice-Attribute (P2VA)，这是第一个可以从人物描述自动生成语音属性的框架。
### Innovation
我们的方法采用了两种策略：P2VA-C用于结构化的语音属性，P2VA-O用于更丰富的风格描述。评估结果显示，P2VA-C降低了单词错误率（WER）5%，并提高了主观评价得分（MOS）0.33分。据我们所知，P2VA是第一个将人物与语音合成建立联系的框架。此外，我们发现当前的LLMs在转换过程中嵌入了社会偏见。我们的实验和发现还为构建人物-声音系统带来了挑战的认识。
### Conclusion
P2VA是第一个可以从人物描述自动生成语音属性的框架，能够降低错误率并提高主观评分。同时，该研究揭示了当前LLMs在音色转换过程中存在的社会偏见问题。
## 398. `cs.CL` - Tag&Tab：利用关键词基于成员推理攻击在大规模语言模型中检测预训练数据 [PDF](https://arxiv.org/pdf/2501.08454), [HTML](https://arxiv.org/abs/2501.08454)
### Authors
Sagiv Antebi,Edan Habler,Asaf Shabtai,Yuval Elovici
### Background
大语言模型（LLMs）已经成为数字任务辅助的重要工具。然而，它们的训练依赖于大量数据的收集，这些数据可能包含受版权保护或敏感信息。最近关于检测LLMs预训练数据的研究主要集中在句级或段落级的成员推理攻击（MIAs），通常涉及到对目标模型预测词的概率分析。但是，这些方法往往准确性较低，未能考虑到文本内容的语义重要性和词语的重要程度。
### Innovation
我们提出了Tag&Tab，一种新型的用于检测LLMs预训练所用数据的方法。我们的方法利用已有的自然语言处理（NLP）技术给输入文本中的关键词进行标记，称为标记过程；然后利用LLMs获得这些关键词的概率，并计算它们的平均对数似然来确定输入文本的成员身份，称为Tabbing过程。我们在四个基准数据集（BookMIA, MIMIR, PatentMIA, 和Pile）以及多个不同规模的开源LLMs上进行的实验表明，与最先进的方法相比，我们的方法在AUC得分上平均提高了5.3%到17.6%。这不仅设定了LLMs中数据泄露检测的新标准，而且其出色的表现证明了在MIAs中词的重要性。
### Conclusion
Tag&Tab为LLMs中预训练数据的检测提供了新的手段。与传统的基于概率分析的方法相比，Tag&Tab通过利用关键词标记和词的概率分析相结合的方式，在检测数据泄露方面表现出了显著的优势。
## 399. `cs.CL` - 熵正则化的过程奖励模型 [PDF](https://arxiv.org/pdf/2412.11006), [HTML](https://arxiv.org/abs/2412.11006)
### Authors
Hanning Zhang,Pengcheng Wang,Shizhe Diao,Yong Lin,Rui Pan,Hanze Dong,Dylan Zhang,Pavlo Molchanov,Tong Zhang
### Background
大型语言模型（LLMs）在执行复杂多步推理方面表现出潜力，但在数学推理方面仍然存在困难，经常出现系统性错误。现有的解决方案包括强化学习（RL）引导的方法，特别是那些注重过程奖励（Process Rewards）的方法，这些方法是对每个中间步骤而非仅仅是最终结果进行评分。这种方法在引导策略模型沿正确的推理路径前进方面更为有效。但现有方法仍存在局限性，例如在平衡策略优化和防止策略模型从初始分布过度偏移方面的不足。本研究在此背景下进行，旨在解决这些问题。
### Innovation
本研究提出了一个熵正则化的过程奖励模型（ER-PRM），它整合了KL正则化的马尔可夫决策过程（MDP），以平衡策略优化与确保策略模型不会过度偏离初始分布的需求。研究提出了基于理论结果的新型奖励构建方法，并通过理论分析证明可以从初始策略抽样中推导出最优奖励模型。实验结果表明，相较于现有的过程奖励模型，ER-PRM在MATH和GSM8K基准测试中表现出更优的效果，特别是在使用best-of-N评估时，GSM8K提高了1%，MATH提高了2-3%，在RLHF评估中则超过1%。这些结果突显了熵正则化在提升LLMs推理能力方面的有效性。
### Conclusion
本研究通过引入熵正则化的过程奖励模型，解决了现有方法在策略优化和防止模型偏移方面的局限性，提出了一个理论基础的新型奖励构造方法，实验验证了其在数学推理任务中效果的显著提升，证明了熵正则化在增强LLMs推理能力方面的优越性。
## 400. `cs.CL` - 超越线性控制：语言模型的统一多属性控制 [PDF](https://arxiv.org/pdf/2505.24535), [HTML](https://arxiv.org/abs/2505.24535)
### Authors
Narmeen Oozeer,Luke Marks,Fazl Barez,Amirali Abdullah
### Background
在大型语言模型（LLMs）的推理阶段同时控制多种行为属性是一个具有挑战性的问题，因为不同属性之间存在相互干扰，而现有的线性控制方法假设激活空间中的加性行为并且需要为每个属性进行单独调整。
### Innovation
我们介绍了K-Steering，这是一种统一而灵活的方法，通过在隐藏激活上训练单一的非线性多标签分类器并在推理阶段通过梯度计算干预方向，从而避免线性假设、无需存储和调整独立的属性向量，并允许动态行为组合而不需重新训练。
### Conclusion
我们在3个模型家族上进行的实验结果，通过基于激活的分类器和基于LLM的评委验证，表明K-Steering在准确引导多种行为方面优于强大的基线方法。
## 401. `cs.CL` - AgentA/B：基于交互式大规模语言模型代理的自动化和可扩展网页A/B测试 [PDF](https://arxiv.org/pdf/2504.09723), [HTML](https://arxiv.org/abs/2504.09723)
### Authors
Dakuo Wang,Ting-Yao Hsu,Yuxuan Lu,Hansu Gu,Limeng Cui,Yaochen Xie,William Headean,Bingsheng Yao,Akash Veeragouni,Jiapeng Liu,Sreyashi Nag,Jessie Wang
### Background
A/B 测试是现代网页应用程序中广泛采用的方法，用于评估 UI/UX 设计决策。然而，传统 A/B 测试仍然受限于对大量实时人类参与者流量的依赖以及测试结果等待时间较长的问题。通过对六名有经验的行业从业者进行形式化访谈，我们发现了当前 A/B 测试工作流程中的关键瓶颈。
### Innovation
我们提出了 AgentA/B 系统，该系统利用基于大规模语言模型（LLM）的自主代理，自动模拟用户与网页的交互行为。AgentA/B 允许部署具有不同人物设定的 LLM 代理，每个代理都可以导航动态网页并执行多步骤交互，如搜索、点击、筛选和购买。我们通过 AgentA/B 实施了一个控制性实验，模拟了一次包含 1,000 个 LLM 代理的 A/B 测试，并将代理行为与真实的购物行为进行比较，结果表明 AgentA/B 能够模仿人类的行为模式。
### Conclusion
我们的研究结果表明，AgentA/B 可以模拟出类似人类的行为模式，从而提供一种自动化和可扩展的网页 A/B 测试方法。
## 402. `cs.CL` - SPaRC: 一个空间路径推理挑战 [PDF](https://arxiv.org/pdf/2505.16686), [HTML](https://arxiv.org/abs/2505.16686)
### Authors
Lars Benedikt Kaesberg,Jan Philip Wahle,Terry Ruas,Bela Gipp
### Background
现有的推理数据集已经饱和，并且无法测试抽象的、多步骤的问题，尤其是路径规划和复杂的规则约束满足问题。
### Innovation
引入了SPaRC (Spatial Pathfinding Reasoning Challenge)，一个包含1000个2D网格路径难题的数据集，用于评估空间和符号推理能力，需要逐步规划、应用算术和几何规则。该数据集要求模型进行多步骤推理，是测试和验证模型在抽象、多步骤问题解决能力上的新挑战。
### Conclusion
人类在SPaRC上的准确率达到近乎完美的98.0%（难题为94.5%），而最好的推理模型，如o4-mini，仅能解决问题的15.8%（难题为1.1%）。模型经常生成无效路径，并且在推理符号中显示出导航和空间逻辑的错误。与其他在难题上花费更多时间的人类不同，模型在测试时间计算能力上没有随着难度增加而扩展。允许模型进行多个解方案的尝试可以提高准确率，这表明可以通过更好的训练以及高效的测试时间扩展方法来增强空间推理能力。SPaRC可以作为一个窗口，用于揭示模型在空间推理方面的局限性，并推动研究新的方法，以在抽象多步骤问题解决中取得更好的表现。
## 403. `cs.CL` - 可学习和可扩展的指令微调数据影响估计的神经网络 [PDF](https://arxiv.org/pdf/2502.09969), [HTML](https://arxiv.org/abs/2502.09969)
### Authors
Ishika Agarwal,Dilek Hakkani-Tür
### Background
影响函数在模型训练中提供了关键的见解，但现有方法面临着计算成本高和泛化能力有限的问题。特别是，最近的研究提出了一些使用语言模型计算数据影响的方法，但这些方法在大型模型和数据集上缺乏扩展性。这是因为计算时需要昂贵的前向和反向传递，大量内存要求存储大型模型，以及影响估计值对新数据的泛化不良。
### Innovation
本文探索使用小型神经网络（称为InfluenceNetwork）来估计影响值，成本最多可减少99%。我们的算法（称为NN-CIFT：高效指令微调中的神经网络）能够使用比完整语言模型小0.0027%的模型来估算影响值。我们在子集选择的下游任务中应用NN-CIFT，并与最新的影响函数进行比较，结果显示性能上没有妥协，尽管有显著的速度提升。我们还对NN-CIFT进行了深入的超参数分析。
### Conclusion
我们的研究表明，通过使用小型神经网络，能够以极低的成本精确地估计指令微调数据的影响值。这种方法不仅减少了计算负担，而且保持了与复杂影响函数一致的性能。此外，我们提供的超参数分析为进一步优化该方法提供了依据。
## 404. `cs.CL` - StreamBridge: 将您的离线视频大语言模型转化为高效流媒体助手 [PDF](https://arxiv.org/pdf/2505.05467), [HTML](https://arxiv.org/abs/2505.05467)
### Authors
Haibo Wang,Bo Feng,Zhengfeng Lai,Mingze Xu,Shiyu Li,Weifeng Ge,Afshin Dehghan,Meng Cao,Ping Huang
### Background
现有的视频大语言模型（Video-LLMs）在处理实时场景时存在两个基本挑战：一是有限的多轮实时理解能力，二是缺乏主动响应机制。为解决上述问题，研究人员提出了StreamBridge框架，无缝转化离线的Video-LLMs为流媒体模型，增强其在流媒体环境中的适应性和响应能力。
### Innovation
StreamBridge框架通过（1）使用带有循环衰减压缩策略的记忆缓冲区，支持长上下文多轮交互，（2）使用解耦的轻量级激活模型，可以轻松地集成到现有的Video-LLMs中，实现持续的主动响应。此外，作者还构建了一个名为Stream-IT的大规模数据集，专为流媒体视频理解设计，包含了交织的视频-文本序列和多种指令格式。实验结果表明，StreamBridge显著提升了离线Video-LLMs在各种任务中的流媒体理解能力，甚至优于如GPT-4o和Gemini 1.5 Pro这样的专有模型。同时还展示了其在标准视频理解基准测试上的竞争力或超越性表现。
### Conclusion
总体而言，StreamBridge有效地解决了现有模型在实时场景下多轮实时理解和主动响应的挑战，使得离线的大语言模型能够转化为一个高效的流媒体助手。
## 405. `cs.CL` - 大型语言模型能否从实际文本中推断出因果关系？ [PDF](https://arxiv.org/pdf/2505.18931), [HTML](https://arxiv.org/abs/2505.18931)
### Authors
Ryan Saklad,Aman Chadha,Oleg Pavlov,Raha Moraffah
### Background
理解并推理文本中的因果关系是人类认知的核心方面，对于推动大规模语言模型（LLMs）向人工通用智能迈进至关重要。现有的工作主要评估LLMs的因果推理能力，集中在简单且明确地在文本中提到的合成文本上。这未能反映出实际任务中的复杂性。本文研究了LLMs是否能够从实际文本中推断因果关系。开发了一个来自实际学术文献的数据集，其中包括长度、因果关系复杂性（包括显性程度、节点数量和因果关系的差异）和领域多样性在内的多样性文本。这是迄今为止针对这一任务的第一个实际世界数据集。实验结果显示，在实际文本中的因果关系推断方面，最佳模型的平均F1分数仅为0.477。通过对实际文本各个方面的系统分析（混杂程度、图形大小、文本长度、领域），我们的基准提供了针对进一步研究的有针对性的见解，以推动LLMs因果推理的进步。
### Innovation
研究了LLMs是否能够从实际文本中推断因果关系。开发了第一个针对此任务的实际世界数据集，实验显示最佳模型在实际文本中的因果关系推断平均F1分数仅为0.477，提供系统分析结果以推动进一步研究的进步。
### Conclusion
实验结果表明，LLMs在实际文本中的因果关系推断方面面临重大挑战，最佳模型在平均F1分数上仅达到0.477。数据集和实验分析为改进LLMs因果推理提供了有针对性的见解。
## 406. `cs.CL` - 在线会议中的个性化实时术语支持 [PDF](https://arxiv.org/pdf/2508.10239), [HTML](https://arxiv.org/abs/2508.10239)
### Authors
Yifan Song,Wing Yee Au,Hon Yung Wong,Brian P. Bailey,Tal August
### Background
跨学科沟通经常受到领域特定专业术语的阻碍。为了深入了解这些障碍，研究人员与专业人士进行了定性日记研究，揭示了当前在工作中处理专业术语策略的局限性。
### Innovation
基于这些见解，研究人员设计了一种基于LLM的互动式系统，名为ParseJargon，提供实时个性化专业术语识别和解释，适应用户个人背景。研究显示，个性化专业术语支持显著提高了参与者对同事工作的理解、参与和欣赏，而通用支持则负面影响了参与度。进一步的实地研究验证了ParseJargon在实时会议中的可用性和实际价值，并指出了其现实部署的机遇和挑战。
### Conclusion
研究结果为设计个性化专业术语支持工具提供了见解，并对更广泛的跨学科和教育应用具有重要意义。
## 407. `cs.CL` - LLMs可以弥补视觉表示的不足 [PDF](https://arxiv.org/pdf/2506.05439), [HTML](https://arxiv.org/abs/2506.05439)
### Authors
Sho Takishita,Jay Gala,Abdelrahman Mohamed,Kentaro Inui,Yova Kementchedjhieva
### Background
许多在多种多模态任务上非常有效的视觉-语言模型（VLMs）基于CLIP的视觉编码器，但这些编码器存在各种局限。研究认为VLM的强大语言骨干可能会通过上下文化或丰富视觉特征来补偿可能较弱的视觉表示。
### Innovation
该研究通过在精心设计的探针任务上对三种基于CLIP的VLMs进行控制的自注意力消除实验，揭示了即使在CLIP视觉表示已知存在局限性的情况下，这些表示仍提供了直接可用的语义信息。并且，在视觉表示减少上下文化的情景下，语言解码器可以大量补偿不足并恢复性能，这表明VLMs中存在动态的劳动分工，并为未来的架构设计提供了动机，即将更多的视觉处理转移到语言解码器上。
### Conclusion
尽管CLIP视觉表示存在已知局限性，但它们仍提供了直接可用的语义信息，语言解码器在视觉表示减少上下文化的情况下可以大量补偿不足并恢复性能。这表明VLMs中存在动态的劳动分工，并且激发未来的架构应更多地将视觉处理委托给语言解码器。
## 408. `cs.CL` - SyGra: 基于统一图结构的高效生成、质量标签和管理合成数据框架 [PDF](https://arxiv.org/pdf/2508.15432), [HTML](https://arxiv.org/abs/2508.15432)
### Authors
Bidyapati Pradhan,Surajit Dasgupta,Amit Kumar Saha,Omkar Anustoop,Sriram Puttagunta,Vipul Mittal,Gopal Sarda
### Background
大型语言模型（LLMs）的进步很大程度上依赖于高质量数据集，尤其是用于监督微调（SFT）和定向偏好优化（DPO）等任务的数据集。为此，研究人员需要一种能够生成大规模、灵活且高质量的合成对话数据的框架。
### Innovation
本文提出了一种综合性的合成数据生成框架（SyGra），该框架具有模块化、配置化的特点，能够自动化地标识、过滤和评估从OASST格式对话中提取的数据，确保生成高质对话样本。SyGra采用双重质量标签机制，结合启发式规则和LLM评估，确保数据的高质量，并支持SFT和DPO两种应用场景，使得数据可以无缝集成到不同的训练工作流中。
### Conclusion
本文提供的创新框架能够有效地生成和管理大规模的合成对话数据，大幅减少了LLM训练过程中数据准备的工作量，为LLM的训练提供了有效解决方案。
## 409. `cs.CL` - ConCISE: 自信引导的逐步高效推理压缩 [PDF](https://arxiv.org/pdf/2505.04881), [HTML](https://arxiv.org/abs/2505.04881)
### Authors
Ziqing Qiao,Yongheng Deng,Jiali Zeng,Dong Wang,Lai Wei,Guanbo Wang,Fandong Meng,Jie Zhou,Ju Ren,Yaoxue Zhang
### Background
大型推理模型（LRMs）在通过思维链（CoT）提示进行复杂推理任务时表现出色，但经常产生冗长的输出，增加了计算负担。现有的基于微调的压缩方法要么在后修剪过程中可能破坏推理连贯性，要么依赖于基于采样的选择，无法彻底去除冗余内容。
### Innovation
本文引入了ConCISE（自信引导的逐步高效推理压缩）框架，通过自信引导的角度定义了两种冗余反射模式：信心不足和延迟终止。ConCISE结合了信心注入以提高推理信心，并在信心足够时终止推理，从而生成简洁的推理链。
### Conclusion
通过在ConCISE生成的数据上对LRMs进行微调，与基础方法相比，ConCISE在压缩和任务性能之间取得了更好的平衡，SimPO下输出长度最多减少了约50%，同时保持了高任务准确性。
## 410. `cs.CL` - 在现实世界中使用自然语言进行人机协作 [PDF](https://arxiv.org/pdf/2508.11759), [HTML](https://arxiv.org/abs/2508.11759)
### Authors
Peter Lindes,Kaoutar Skiker
### Background
本文背景在于设想未来自主机器人能够作为人类助手，在物理世界中执行复杂任务时协作。现有的交互式任务学习系统尽管有一些能力，但理解人类语言的能力有限。大型语言模型（LLMs）的出现为机器人理解语言提供了机会，但如何将LLMs的语言能力与执行物理任务的机器人结合仍然是一个挑战。
### Innovation
本文创新点在于探索了一个认知代理控制物理机器人核心的AI系统如何与人类和LLMs交互，通过经验积累情境知识，以实现提高机器人语言能力的愿景。文中提出了关于机器人理解自然语言的三个具体挑战，并用ChatGPT进行了简单的实验。同时讨论了如何将这些简单实验转化为一个以LLMs辅助语言理解为特征的综合机器人助手。
### Conclusion
文章总结指出，将这些简单的实验转化为一个能够实际运用、具备LLMs辅助语言理解能力的综合机器人助手，还需要克服许多问题和挑战，但这种结合展示了未来人机协作的巨大潜力。
## 411. `cs.CL` - 理解AI评价模式：不同GPT模型如何评估视觉-语言描述 [PDF](https://arxiv.org/pdf/2509.10707), [HTML](https://arxiv.org/abs/2509.10707)
### Authors
Sajjad Abdoli,Rudi Cilibrasi,Rima Al-Shikh
### Background
随着AI系统越来越多地评估其他AI的输出，理解它们的评估行为变得至关重要，以防止传播偏见。这项研究分析了NVIDIA的‘任何事物描述模型’生成的视觉-语言描述，并由三种GPT变体（GPT-4o、GPT-4o-mini、GPT-5）进行评估，目的是揭示每种模型独特的‘评估个性’，了解其潜在的评估策略和偏见。
### Innovation
研究通过分析视觉-语言描述的生成，识别了不同GPT模型的评估特性，特别是它们在系统一致性、错误检测能力和保守性方面的表现差异。此外，通过使用Gemini 2.5 Pro作为独立问题生成器进行了受控实验，验证了这些个性是模型固有的属性而非实验的伪影。还发现GPT模型在评估策略上与Gemini存在显著分歧，GPT模型之间表现出高度相似性，而Gemini则表现出不同的评估策略。所有GPT模型在评估时都表现出一种一致的2:1偏向，倾向于负面评估而非正面确认。
### Conclusion
这些发现表明，评估技能并不与一般能力成正比，而是需要多样化的架构视角以实现稳健的AI评估。
## 412. `cs.CL` - MountainLion: 一种基于多模态大语言模型的可解释且适应性强的金融交易代理系统 [PDF](https://arxiv.org/pdf/2507.20474), [HTML](https://arxiv.org/abs/2507.20474)
### Authors
Siyi Wu,Junqiao Wang,Zhaoyang Guan,Leyi Zhao,Xinyuan Song,Xinyu Ying,Dexu Yu,Jinhao Wang,Hanlin Zhang,Michele Pak,Yangfan He,Yi Xin,Jianhui Wang,Tianyu Shi
### Background
加密货币交易是一个充满挑战的任务，需要从多种模态集成异质数据。传统的深度学习和强化学习方法通常需要大量的训练数据集，并将多样化输入转化为数值表示，这往往以解释性为代价。近年来，基于大规模语言模型（LLM）的代理技术已经展示了处理多模态数据和辅助复杂投资决策的能力。在此基础上，本文提出了一种名为MountainLion的多模态多代理系统，该系统通过协调专门的LLM代理来解释金融数据并生成投资策略。
### Innovation
MountainLion系统通过处理文本新闻、蜡烛图和交易信号图来生成高质量的金融服务报告，同时通过数据驱动的用户互动和问答功能提供修改报告和投资建议的能力。该系统的核心反思模块可以分析历史交易信号和结果，以便不断优化决策过程，实现实时报告分析、总结和动态调整投资策略。实验结果证实，MountainLion系统系统地丰富了技术价格触发信号，添加了宏观经济学和资本流动信号，提供了更可解释、更可靠和更行动导向的投资框架，从而提高回报并增强投资者信心。
### Conclusion
MountainLion系统提供了一种更加解释性的投资框架，通过整合多模态数据和持续学习优化决策过程，相比传统的基于深度学习和强化学习的方法，MountainLion能够提供更好的投资回报和增强投资者信心。
## 413. `cs.CL` - 使用PRISM捕获多义性：一种多概念特征描述框架 [PDF](https://arxiv.org/pdf/2506.15538), [HTML](https://arxiv.org/abs/2506.15538)
### Authors
Laura Kopf,Nils Feldhus,Kirill Bykov,Philine Lou Bommer,Anna Hedström,Marina M.-C. Höhne,Oliver Eberle
### Background
自动化可解释性研究旨在识别神经网络特征中编码的概念，以提高人类对模型行为的理解。在自然语言处理（NLP）中的大型语言模型（LLMs）背景下，目前自动神经元级特征描述方法面临两个主要挑战：鲁棒性有限以及假定每个神经元仅编码一个概念（单义性），尽管有越来越多的证据表明多义性普遍存在。这种假设限制了特征描述的表达性和捕捉模型内部更广泛行为的能力。
### Innovation
提出了Polysemantic FeatuRe Identification and Scoring Method（PRISM），一种新型框架，专门用于捕获LLMs特征的复杂性。与许多NLP中的自动化可解释性方法中每个神经元只分配一个描述的常见做法不同，PRISM产生更具层次感的描述，能够考虑单义性和多义性的行为。PRISM通过基准测试证明，其能够生成更准确和忠实的特征描述，不仅提高整体描述质量（通过描述得分），还能捕捉到当存在多义性时的不同概念（通过多义性得分）。
### Conclusion
PRISM在LLMs中应用时，证明了其更准确和真实的特征描述能力，为提高模型行为理解的精准度提供了新的方法。
## 414. `cs.CL` - 构建稳健且适应性强的生成式人工智能原生系统的基石设计原则与模式 [PDF](https://arxiv.org/pdf/2508.15411), [HTML](https://arxiv.org/abs/2508.15411)
### Authors
Frederik Vandeputte
### Background
生成式人工智能（GenAI）作为一种变革性技术，展现出了跨多种应用场景的非凡能力。然而，GenAI的发展在建立可靠的、高效能的GenAI增强系统方面面临诸多挑战，由于其不可预测性和低效率。
### Innovation
本文提倡了一个范式转变：未来的GenAI原生系统应当融合GenAI的认知能力与传统软件工程原则，以创造出具备可靠、适应性强和高效性的系统。提出了围绕五个关键支柱——可靠性、卓越性、可演化性、自足性和保障性为中心的GenAI原生基础设计原则，并提出了诸如GenAI原生细胞、有机基质和可编程路由器等架构模式，以指导构建稳健且自我进化的系统。同时概述了GenAI原生软件栈的关键成分，并从技术、用户采纳、经济和法律角度讨论这些系统的潜在影响，强调了进一步验证和试验的需求。
### Conclusion
我们的研究旨在启发未来的研究，并鼓励相关社区实施和精炼这一概念框架，以应对GenAI面临的关键挑战。
## 415. `cs.CV` - ViSpec: 使用具有视觉意识的推测性解码加速视觉语言模型 [PDF](https://arxiv.org/pdf/2509.15235), [HTML](https://arxiv.org/abs/2509.15235)
### Authors
Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen
### Background
推测性解码是用于加速大型语言模型（LLMs）推理的广泛应用的技术，但在视觉语言模型（VLMs）中的应用仍未得到充分探索，现有的方法仅能实现轻微的速度提升（<1.5倍）。随着多模态能力在大规模模型中的重要性日益提高，这一差距变得越来越显著。研究假设，大型VLMs能够逐层有效地过滤重复的图像信息，而不需要损害语言理解，但较小的草稿模型则难以做到这一点。
### Innovation
为解决上述问题，我们引入了一种专为VLMs设计的新型框架——Vision-Aware Speculative Decoding（ViSpec）。ViSpec包含一个轻量级的视觉适配模块，用于压缩图像令牌为紧凑的表示，并无缝地整合到草稿模型的注意力机制中，同时保留原始图像的位置信息。此外，我们还为每个输入图像提取一个全局特征向量，并将其增强到所有后续的文字令牌中，以增强多模态的一致性。为了克服用于训练的多模态数据集中伴随着长时间助手回复的稀缺性，我们通过重新利用现有数据集并以修改后的提示生成扩展输出来构建了一个专门的训练数据集。
### Conclusion
广泛实验验证了ViSpec的有效性，据我们所知，首次实现了VLM推测性解码中的显著速度快于原有方法。
## 416. `cs.CL` - RSCC: 一种大型灾害事件遥感变化标注数据集 [PDF](https://arxiv.org/pdf/2509.01907), [HTML](https://arxiv.org/abs/2509.01907)
### Authors
Zhenyuan Chen,Chenxi Wang,Ningyu Zhang,Feng Zhang
### Background
遥感技术在灾害监测中至关重要，但当前数据集缺乏时间图像对和详细的文本注释。现有的资源主要以单帧图像为主，无法捕捉不同时段的灾害动态影响。这导致现有的视觉语言模型难以进行灾害感知的双时段理解。
### Innovation
我们提出了Remote Sensing Change Caption (RSCC) 数据集，这是一个包含62,315对灾前和灾后图像（包括地震、洪水、野火等）的大规模基准集，并配有丰富的、类人的变化描述。RSCC数据集填补了遥感数据在时间和语义上的不足，以加强视觉语言模型的训练与评估能力，实现对灾害的详细分析，推动更准确、可解释和可扩展的遥感视觉语言应用的发展。
### Conclusion
RSCC数据集能够促进详细的灾害相关分析，为遥感领域更准确、可解释且可扩展的视觉语言应用铺平了道路。数据集和代码可在指定链接获取。
## 417. `cs.CV` - 大型视觉模型能够解决心理旋转问题 [PDF](https://arxiv.org/pdf/2509.15271), [HTML](https://arxiv.org/abs/2509.15271)
### Authors
Sebastian Ray Mason,Anders Gjølbye,Phillip Chavarria Højbjerg,Lenka Tětková,Lars Kai Hansen
### Background
心理旋转是评估人类空间推理能力的关键测试，有助于理解感知如何支持认知。尽管现代视觉转换器取得了成功，但这些模型是否能发展出类似的心理旋转能力仍不清楚。本文在多种心理旋转任务上的评估了ViT、CLIP、DINOv2和DINOv3的表现，涵盖了从Shepard和Metzler等人研究人类认知时使用的简单积木结构到更复杂的积木图、三种类型的文本和写实物体。
### Innovation
通过逐层探查模型的表示，研究发现：i) 自监督的ViTs比监督的ViTs更好地捕捉几何结构；ii) 中间层的表现优于最终层；iii) 随着旋转复杂度和遮挡的增加，任务难度增加，这与人类反应时间相符，表明类似的约束存在于嵌入空间表示中。
### Conclusion
不同视觉模型在心理旋转任务上表现出差异，特别是自监督模型在捕捉几何结构方面更好，但任务的复杂性增加了模型的挑战。
## 418. `cs.CV` - 探索LLM编码器在胸部X光图像-文本检索中的能力 [PDF](https://arxiv.org/pdf/2509.15234), [HTML](https://arxiv.org/abs/2509.15234)
### Authors
Hanbin Ko,Gihun Cho,Inhyeok Baek,Donguk Kim,Joonbeom Koo,Changi Kim,Dongheon Lee,Chang Min Park
### Background
视觉-语言预训练已提高了图像-文本对齐，但在放射学领域，由于临床报告的异质性（包括缩写、印象笔记和风格差异），进展仍然受到限制。与通用领域中更多数据往往带来更好性能不同，简单地扩大规模到嘈杂报告的大型集合可能会导致模型学习效果停滞甚至下降。该研究探讨了大规模语言模型（LLM）编码器是否会提供稳健的临床表示，从而适应各种风格，并更好地引导图像-文本对齐。
### Innovation
该研究引入了针对胸部X光报告的域适应LLM编码器LLM2VEC4CXR，并提出了一种结合LLM编码器和视觉主干的双塔框架LLM2CLIP4CXR。相比于基于BERT的基本模型，LLM2VEC4CXR在临床文本理解上表现出色，能够处理缩写和风格差异，并在报告层面的指标上实现了强大的临床对齐。LLM2CLIP4CXR通过这些嵌入提高了检索准确性及临床导向指标，并在跨数据集泛化能力上优于之前的医疗CLIP变体。研究在包含来自公共和私人来源、异质且嘈杂的报告的160万份胸部X光研究中进行，表明稳健性而不是简单规模是有效多模态学习的关键。
### Conclusion
通过大规模语言模型编码器在胸部X光图像-文本检索中的应用，研究证明了稳健性而非单纯的数据规模是影响多模态学习效果的关键因素。模型已被释放，以支持进一步的医学图像-文本表示学习研究。
## 419. `cs.CL` - Mind the Gap: Data Rewriting for Stable Off-Policy Supervised Fine-Tuning [PDF](https://arxiv.org/pdf/2509.15157), [HTML](https://arxiv.org/abs/2509.15157)
### Authors
Shiwan Zhao,Xuyang Zhao,Jiaming Zhou,Aobo Kong,Qicheng Li,Yong Qin
### Background
大型语言模型的监督微调（SFT）可以被视为一种离策学习问题，其中专家演示来自固定的行为策略，训练目的是优化目标策略。重要性抽样是纠正这种策略分布不匹配的标准工具，但大策略差距导致加权分布偏向、高方差和不稳定优化。现有方法通过KL惩罚或剪切来减轻这一问题，但这些方法只是被动限制更新而不是积极减少差距。
### Innovation
提出了一个简单有效的数据重写框架，主动在训练前缩小策略差距。对于每个问题，正确的模型生成解决方案保留为在线策略数据，通过引导重新求解不正确的解决方案，仅在必要时回退到专家演示。这使训练分布与目标策略对准，降低方差并提高稳定性。为了处理重写后的残留不匹配，还应用重要性抽样进行训练，形成结合数据级对准和轻量级优化级修正的两阶段方法。
### Conclusion
在五个数学推理基准上的实验表明，该方法在标准SFT和最新的动态微调（DFT）方法上都取得了可验证和显著的改进。相关数据和代码将在指定网址发布。
## 420. `cs.CV` - RespoDiff: 双模块瓶颈变换用于负责且忠实的文本到图像生成 [PDF](https://arxiv.org/pdf/2509.15257), [HTML](https://arxiv.org/abs/2509.15257)
### Authors
Silpa Vadakkeeveetil Sreelatha,Sauradip Nag,Muhammad Awais,Serge Belongie,Anjan Dutta
### Background
扩散模型的快速发展使得高保真度和语义丰富性的文本到图像生成成为可能，但确保公平性和安全性仍然是一个开放的挑战。现有的方法通常在提高公平性和安全性的同时，牺牲了语义保真度和图像质量。
### Innovation
我们提出了RespoDiff—a 新颖的负责文本到图像生成框架，通过扩散模型中间瓶颈表示上的双模块转换来实现。该方法引入了两个不同的可学习模块：一个用于捕捉并强制执行负责任的概念（如公平性和安全性），另一个专门用于保持与中性提示语义对齐。为了促进这两个模块的双重学习过程，我们引入了一种新型的评分匹配目标，使两个模块之间的协调变得更加有效。我们的方法在不负责任的生成任务中表现出色，同时优化两个目标而不牺牲图像保真度，并且在各种未见过的提示上提高了负责任且语义连贯生成的性能20%。此外，该方法可以无缝集成到大型模型中，提升公平性和安全性。
### Conclusion
我们的方法在负责和语义一致的生成方面提高了20%，特别是在各种未见提示上表现良好，并且可以无缝集成到大型模型如SDXL中，进一步提升公平性和安全性。
## 421. `cs.CV` - Walk and Read Less: Improving the Efficiency of Vision-and-Language Navigation via Tuning-Free Multimodal Token Pruning [PDF](https://arxiv.org/pdf/2509.15250), [HTML](https://arxiv.org/abs/2509.15250)
### Authors
Wenda Qin,Andrea Burns,Bryan A. Plummer,Margrit Betke
### Background
大模型在视觉语言导航（VLN）任务上表现出色，但在资源受限的环境中运行成本高昂。通过减少输入大小来提高效率的标记剪枝提供了一种有吸引力的权衡，但先前的工作忽略了VLN特有的挑战。例如，标记剪枝造成的信息损失可能会导致更长的导航路径，从而增加计算成本。因此，识别无用标记的能力成为了剪枝效率提升的关键。
### Innovation
该研究提出了导航感知剪枝（NAP），这是一种利用导航特有的特性简化剪枝过程的方法。通过预筛选标记为前景和背景，NAP重点对背景标记进行剪枝，以减少信息损失。同时，NAP通过移除低重要性的导航节点来防止回溯，进一步降低了导航路径的长度。实验结果表明NAP显著优于先前的工作，在保持更高成功率的同时节省了超过50%的FLOPS。
### Conclusion
实验表明，NAP在标准VLN基准测试中显著优于之前的工作，不仅保持了更高的成功率，还节省了超过50%的FLOPS。
## 422. `cs.CV` - 视觉-语言模型中的多模态可解释性以增强定位 [PDF](https://arxiv.org/pdf/2509.15243), [HTML](https://arxiv.org/abs/2509.15243)
### Authors
Muhammad Imran,Yugyung Lee
### Background
近年来，视觉-语言模型在自动化图像分析方面取得了显著进展。然而，将其应用于安全攸关的环境中仍面临挑战，因为这些模型需要处理对象之间的复杂关系和微妙的视觉线索，并且需要更高的透明度和可靠性。目前，基于梯度的解释方法在翻译器架构中表现良好，但这些方法在解释多模态信息时存在局限性。因此，迫切需要一种新的方法来增强解释的全面性和针对性。
### Innovation
本文提出了一种新的多模态解释学习（MMEL）框架，该框架通过多尺度特征处理、自适应注意加权和跨模态对齐，增强了模型解释性。MMEL引入了层次语义关系模块，能够在不同粒度级别捕捉图像区域之间的关系，并应用可学习的层级特定权重来平衡模型深度中的贡献。这样可以生成更为全面的视觉解释，更加准确地突出主要对象及其上下文关系。实验结果表明，通过将语义关系信息整合到基于梯度的可追溯性图中，MMEL生成了更集中且上下文相关性更强的可视化，更准确地反映了视觉-语言模型如何处理复杂场景。
### Conclusion
MMEL框架为需要高可解释性和可靠性的应用程序提供了有价值的见解，并能够跨多个领域推广，进一步增强了视觉-语言模型在安全攸关情境中的应用潜力。
## 423. `cs.CV` - 为微分模型训练辅助引导在线数据治理 [PDF](https://arxiv.org/pdf/2509.15267), [HTML](https://arxiv.org/abs/2509.15267)
### Authors
Valeria Pais,Luis Oala,Daniele Faccio,Marco Aversa
### Background
生成模型计算成本重新燃起了高效数据治理的热情与希望。本文旨在调查近期开发的自引导和在线数据选择方法是否能够提高生成扩散模型训练的时间和样本效率。
### Innovation
研究将联合示例选择（JEST）和自引导整合进一个统一的代码库中，用于快速消融实验和基准测试。进行了在受控的2-D合成数据生成任务和（3x64x64）-D图像生成任务中，以相同的计时时间和样本数进行的组合数据治理评估。研究发现自引导在样本质量和多样性方面始终表现出一致的改进效果。早期AJEST（仅在训练开始时进行选择）在数据效率方面可以与自引导单独使用相匹敌甚至超过，但其时间开销和复杂度使得它在大多数情况下不占优势。这意味着虽然在线选择在早期训练可以带来效率增益，但稳健的样本质量改进主要由自引导驱动。
### Conclusion
讨论了这些发现的局限性和应用范围，明确了数据选择在某些情况下的益处。
## 424. `cs.CV` - CoDoL: 条件域提示学习以提高分布外泛化能力 [PDF](https://arxiv.org/pdf/2509.15330), [HTML](https://arxiv.org/abs/2509.15330)
### Authors
Min Zhang,Bo Jiang,Jie Zhou,Yimeng Liu,Xin Lin
### Background
最近的研究表明，预训练视觉-语言模型（VLMs），例如对比语言图像预训练（CLIP）方法，在学习分布外（OOD）表示方面展现了巨大的潜力。然而，基于提示的CLIP方法仍然存在以下挑战：i) 不准确的文本描述导致性能下降和鲁棒性问题，这使得零样本的CLIP方法难以实现；ii) 视觉-语言嵌入对齐有限，严重影响了泛化性能。
### Innovation
本文提出了一种新颖的条件域提示学习（CoDoL）方法，利用可获取的领域信息来形成提示，并通过提高视觉-语言嵌入对齐来改善分布外泛化。此外，提出了一种轻量级领域元网络（DMN），以生成针对每个领域的输入条件化令牌，从而捕捉实例特定和领域特定的信息。
### Conclusion
在四个分布外基准测试（PACS，VLCS，OfficeHome和DigitDG）上的广泛实验表明，本文提出的方法在提高视觉-语言嵌入对齐以及分布外泛化性能方面具有有效性和优越性。
## 425. `cs.CV` - 基础模型在逐步物理推理方面表现如何？ [PDF](https://arxiv.org/pdf/2509.15293), [HTML](https://arxiv.org/abs/2509.15293)
### Authors
Dinura Dissanayake,Ahmed Heakl,Omkar Thawakar,Noor Ahsan,Ritesh Thawkar,Ketan More,Jean Lahoud,Rao Anwer,Hisham Cholakkal,Ivan Laptev,Fahad Shahbaz Khan,Salman Khan
### Background
在实际环境中操作的实体代理必须作出既有成效又安全、空间上连贯且基于上下文的决策。尽管大规模多模态模型在视觉理解和语言生成方面取得了有前景的能力，但在执行结构化推理以完成实际世界中的实体任务方面的潜力仍然未得到充分利用。这项工作旨在探索基础模型在实体环境中的逐步推理能力。为此，作者提出了基础模型实体推理（FoMER）基准，用于评估多模态模型在复杂实体决策场景中的推理能力。
### Innovation
作者设计了FoMER基准，这是一个大规模、经过筛选的任务集合，评估模型在多模态观察理解、物理约束和安全推理以及生成自然语言的有效下一步操作方面的推理能力。同时，引入了一个新的评估框架，将感知锚定与行动推理分离，并对几种领先的多模态模型进行了实证分析。
### Conclusion
实验结果显示了基础模型在物理推理中的潜力和当前限制，指出了未来机器人智能研究的关键挑战和机遇。这项基准测试包含了来自10个任务和8种实体的1100多个样本，涵盖了三种不同的机器人类型。数据分析揭示了模型在特定环境中的表现和不足，为今后研究提供了方向。相关数据和代码将公开。
## 426. `cs.CV` - ProFusion: 从多视角AFM图像重建蛋白质复合体结构 [PDF](https://arxiv.org/pdf/2509.15242), [HTML](https://arxiv.org/abs/2509.15242)
### Authors
Jaydeep Rade,Md Hasibul Hasan Hasib,Meric Ozturk,Baboucarr Faal,Sheng Yang,Dipali G. Sashital,Vincenzo Venditti,Baoyu Chen,Soumik Sarkar,Adarsh Krishnamurthy,Anwesha Sarkar
### Background
人工智能(AI)在蛋白质结构预测中的应用取得了进展，但在处理涉及多个相互作用蛋白的大蛋白质复合体(PCs)方面存在困难，因为缺乏3D空间线索。冷冻电镜(Cryo-EM)等实验技术虽然准确但成本高且耗时。因此，亟需一种能够在保持结构精度的同时，解决大数据集合的实验成像问题的方法。现有的深度学习模型依赖于大量高品质的训练数据，而获取大规模的原子力显微镜(AFM)数据集在实际中是不可行的，因此，需要一种能够在短时间内生成大量AFM图像的虚拟框架，以用于训练深度学习模型。
### Innovation
提出了一种混合框架ProFusion，该框架结合了深度学习模型和原子力显微镜(AFM)，通过模拟成像过程生成了约542,000个蛋白质的多视角合成AFM图像数据集。ProFusion采用条件扩散模型从无构型输入中合成为新视角，并通过实例特定的神经辐射场(NeRF)模型重建3D结构。重构的3D蛋白质结构在AFM成像分辨率范围内表现出高结构精确度，并在各种蛋白质复合体(PCs)的实验AFM图像上进行了验证，证明其在蛋白质复合体结构预测及快速迭代验证中的强大潜力。
### Conclusion
通过ProFusion框架，实现了从多视角AFM图像重建蛋白质复合体的3D结构，该方法结合了前瞻性的AI技术与AFM的高分辨率成像技术，提供了成本效益高且快速验证蛋白质复合体结构的方式。
## 427. `cs.CV` - 模仿人类适应性的视觉感知以实现高效且灵活的机器视觉 [PDF](https://arxiv.org/pdf/2509.15333), [HTML](https://arxiv.org/abs/2509.15333)
### Authors
Yulin Wang,Yang Yue,Yang Yue,Huanqian Wang,Haojun Jiang,Yizeng Han,Zanlin Ni,Yifan Pu,Minglei Shi,Rui Lu,Qisen Yang,Andrew Zhao,Zhuofan Xia,Shiji Song,Gao Huang
### Background
人类视觉高度适应性强，能够通过逐个固定任务相关区域来有效地探索复杂环境。相比之下，现有的机器视觉模型通常会一次性被动地处理整个场景，这导致资源需求随着输入的时空分辨率和模型大小的增加而不断增加，这在很大程度上限制了未来的进步和实际应用。
### Innovation
提出了AdaptiveNN，这是一种通用框架，旨在从‘被动’转变为‘主动、适应性’的视觉模型。AdaptiveNN将视觉感知公式化为逐步细化的决策过程，逐步识别和关注与任务相关的关键区域，在每次注视间逐步整合信息，并在获得足够信息时主动停止观察。该框架结合了表征学习与自我奖励的强化学习理论，能够在不额外监督注视点位置的情况下进行端到端训练。
### Conclusion
AdaptiveNN在17个基准测试和9项任务中都取得了优异表现，包括大规模视觉识别、细粒度识别、视觉搜索、驾驶和医疗场景中的图像处理、语言驱动的机器人视觉等，同时在不牺牲准确性的前提下将推理成本减少多达28倍，在资源预算和任务需求变化时无需重新训练即可灵活调整，且通过专注于的区域提供更好的可解释性，展示了高效、灵活且可解释的计算机视觉的新路径。此外，在许多情况下，AdaptiveNN表现出与人类相似的感知行为，揭示了其在视觉认知研究方面的重要价值。
## 428. `cs.CV` - LowDiff：使用低分辨率条件实现高效扩散采样 [PDF](https://arxiv.org/pdf/2509.15342), [HTML](https://arxiv.org/abs/2509.15342)
### Authors
Jiuyi Xu,Qing Jin,Meida Chen,Andrew Feng,Yang Sui,Yangming Shi
### Background
扩散模型在图像生成方面取得了显著成功，但在实际应用中，其采样速度缓慢限制了广泛使用。先前的主要优化集中在压缩模型或减少总去噪步骤上，这些努力很大程度上忽视了利用生成过程中的多输入分辨率的可能性。
### Innovation
本文提出了LowDiff，一种基于级联方法的新型高效扩散框架，通过逐步生成更高分辨率的输出。此外，LowDiff采用统一模型从低分辨率逐步精炼到所需分辨率。通过该架构设计和生成技术，实验结果表明，在较少的高分辨率采样步骤下即可达到可比较甚至更优的性能。LowDiff适用于像素空间和潜在空间的扩散模型。
### Conclusion
在 CIFAR-10、FFHQ 和 ImageNet 等数据集上的广泛实验表明，LowDiff 方法在保持或提升图像质量的同时，整体效率得到了显著提升，吞吐量提高了超过50%。在无条件生成任务中，LowDiff 达到了 FID 2.11 和 IS 9.87 的结果，而在有条件生成任务中达到了 FID 1.94 和 IS 10.03。在 64x64 的 FFHQ 和 256x256 的 ImageNet 中，LowDiff 表现出更高质量的样本，FID 分别为 2.43 和 4.00，IS 分别为 195.06。
## 429. `cs.CV` - AI生成模型的因果足迹 [PDF](https://arxiv.org/pdf/2509.15406), [HTML](https://arxiv.org/abs/2509.15406)
### Authors
Hui Xu,Chi Liu,Congcong Zhu,Minghao Wang,Youyang Qu,Longxiang Gao
### Background
AI生成模型在生成图像时会留下隐含的印记，这些印记通常被称为模型指纹，并用于来源溯源。先前的方法依赖于模型特定的提示或合成现象，导致指纹在不同生成模型之间泛化能力有限。
### Innovation
提出了因果指纹的概念，并设计了一个因果拆解框架，该框架在预训练扩散重构残差中派生的语义不变潜在空间中解开模型印记与图像特定内容和样式之间的纠缠，通过不同的特征表示增强指纹的细粒度。
### Conclusion
实验表明，该方法在模型溯源方面优于现有方法，显示出强大的伪迹检测、模型版权追踪和身份保护的应用潜力。
## 430. `cs.CV` - MaskAttn-SDXL: 可控区域级文本到图像生成 [PDF](https://arxiv.org/pdf/2509.15357), [HTML](https://arxiv.org/abs/2509.15357)
### Authors
Yu Chang,Jiahao Chen,Anzhe Cheng,Paul Bogdan
### Background
文本到图像的扩散模型在生成高保真图像方面表现出色，但经常在具有多个对象、属性和空间关系的提示中出现组合失败，导致跨标记干扰，其中实体纠缠、属性跨对象混合且空间提示被违背。
### Innovation
提出了一种名为MaskAttn-SDXL的区域级门控机制，应用于Stable Diffusion XL (SDXL) UNet的交叉注意层。该方法学习每层的二值掩码，并将其注入交叉注意逻辑图之前，以使标记到潜在向量的交互稀疏化，从而仅保留语义相关的连接。该方法不需要位置编码、辅助标记或外部区域掩码，并且无需额外的开销即可保留原有的推理路径。
### Conclusion
我们的模型在多对象提示中提高了空间一致性并保持了整体图像质量和多样性，这些发现表明在多对象提示中对交叉注意逻辑图进行稀疏化的掩码交叉注意是一种高效的方法，用于执行组合控制，因此该方法作为空间控制的实用扩展具有重要作用。
## 431. `cs.CV` - 基于分布鲁棒训练的神经放射学基础模型：适用于神经肿瘤学 [PDF](https://arxiv.org/pdf/2509.15416), [HTML](https://arxiv.org/abs/2509.15416)
### Authors
Moinak Bhattacharya,Angelica P. Kurtz,Fabio M. Iwamoto,Prateek Prasanna,Gagandeep Singh
### Background
神经肿瘤学由于数据异质性和肿瘤复杂性，给机器学习带来了独特的挑战，限制了基础模型跨队列的一般化能力。现有基础模型在预测罕见分子标记方面表现不佳，这些标记对于治疗反应和风险分层至关重要。
### Innovation
开发了一种针对神经肿瘤学的特定基础模型，并使用分布鲁棒损失函数进行预训练，以准确估计肿瘤表型而不损失跨机构的一般化能力。该模型通过使用分布鲁棒优化来减少场地和类别的不平衡，并应用于多机构的大脑肿瘤MRI，以改善现有多通量分类和生存预测。
### Conclusion
将基础模型与分布鲁棒训练相结合，提高了现有多通量分类和罕见标记的预测准确性，减少了场地特定嵌入差异，并改善了生存预测。此外，该方法通过Grad-CAM强调了肿瘤和肿瘤周围区域，证明了其可解释性。这些结果强调了需要前瞻性验证及整合纵向和干预信号以推动精准神经肿瘤学的进展。
## 432. `cs.CV` - Region-Aware Deformable Convolutions [PDF](https://arxiv.org/pdf/2509.15436), [HTML](https://arxiv.org/abs/2509.15436)
### Authors
Abolfazl Saheban Maleki,Maryam Imani
### Background
传统可变形卷积只能使用固定大小的四边形采样区域，这对于处理复杂图像结构的能力存在限制。为此，本文提出了Region-Aware Deformable Convolution（RAD-Conv），新设计的一个卷积操作符，旨在增强神经网络适应复杂图像结构的能力。
### Innovation
RAD-Conv通过每个核元素使用四个边界偏移量来创建灵活的矩形区域，这些区域能够根据图像内容动态调整大小和形状。这种设计解耦了感受野的形状和核的结构，将注意力机制的适应性与标准卷积的效率相结合，提供了一个构建更具表达能力和高效性视觉模型的实用解决方案。
### Conclusion
RAD-Conv通过允许对感受野宽度和高度的精确控制，可以使模型捕获局部细节和长距离依赖，即便是使用小尺寸的1x1卷积核。这种设计不仅提高了模型的灵活性，还弥补了刚性卷积架构和计算成本高的注意力机制之间的差距。
## 433. `cs.CV` - 在下游任务中选择哪种方向？关于自监督ViT表示能力的分析 [PDF](https://arxiv.org/pdf/2509.15272), [HTML](https://arxiv.org/abs/2509.15272)
### Authors
Yannis Kaltampanidis,Alexandros Doumanoglou,Dimitrios Zarpalas
### Background
自监督学习（SSL）在视觉变换器（ViTs）领域已经展示了作为各种计算机视觉任务（包括图像分类和分割）预训练策略的巨大潜力，无论是在标准任务还是少样本场景中。目前，对比学习和遮掩图像建模是SSL技术中占据主导地位的两种预训练目标。尽管这些预训练ViT的特征经常经过进一步的转换层处理，但尚未对其未经过修改的内在表示能力进行全面分析。本文旨在通过系统评估这些未改变的特征在图像分类和分割任务（包括标准任务和少样本场景）中的应用，填补这一空白。所使用的分类和分割规则要么是基于超平面（如逻辑回归），要么是基于余弦相似度，这些规则依赖于ViT的潜在空间中存在的可解释方向。
### Innovation
本文首次全面分析了自监督ViT的未经过修改特征在下游任务中的内在表示能力。研究者没有使用额外的特征变换，而是根据既定规则对不同的token类型、任务和预训练目标下的ViT模型进行了分析。这种方法提供了一个选择最优token类型和决策规则的依据，基于任务、上下文和预训练目标，同时报告了两个广泛使用的数据集的详细结果。
### Conclusion
通过详细分析未经过修改的ViT特征在图像分类和分割任务中的应用，本研究提出了基于任务、上下文和预训练目标选择最优token类型和决策规则的指导。此外，文章报告了两个常用数据集的详细发现，为进一步研究提供了基础。
## 434. `cs.CV` - M-PACE：母子框架的多模态合规性 [PDF](https://arxiv.org/pdf/2509.15241), [HTML](https://arxiv.org/abs/2509.15241)
### Authors
Shreyash Verma,Amit Kesari,Vinayak Trivedi,Anupam Purwar,Ratnesh Jamidar
### Background
确保多模态内容遵守品牌、法律或平台特定的合规标准是一个跨领域的日益复杂的挑战。传统的合规框架通常依赖于断开式、多阶段的管道，这些管道整合了分别处理图像分类、文本提取、音频转录的手工编撰检查和基于规则的合并模块。这种架构的碎片化增加了操作成本，阻碍了可扩展性，并阻碍了高效适应动态指南的能力。随着多模态大型语言模型（MLLMs）的出现，有潜力将这些工作流统一到一个通用框架中，该框架能够一次性处理视觉和语言内容。
### Innovation
本文提出了Multimodal Parameter Agnostic Compliance Engine (M-PACE)，这是一种专门为在一通过单一过程评估视觉语言输入的属性设计的框架。M-PACE 使用母子 MLLM 设置，在广告合规性这一代表性用例中进行了验证，展示了评估超过 15 个合规相关属性的能力。为支持结构化的评估，作者引入了由人工注释丰富等多种样例标注的基准，这些样例模拟了视觉遮挡和含有不适当内容的真实世界场景。M-PACE 证明了一种更为强大的母 MLLM 评估较小子模型的输出，可以大幅减少对人工审核员的依赖，从而实现质量控制的自动化。
### Conclusion
我们的分析表明，推理成本降低了 31 倍，最高效模型（母 MLLM 选择 Gemini 2.0 Flash 作为子 MLLM 运行时成本为 0.0005 每张图片），与 Gemini 2.5 Pro 相比，成本降低了约 31 倍，精度相近，在实际部署中实现实时成本与输出质量之间的协同优化。
## 435. `cs.CV` - 通过对应关系生成基于部分的全局解释 [PDF](https://arxiv.org/pdf/2509.15393), [HTML](https://arxiv.org/abs/2509.15393)
### Authors
Kunal Rathore,Prasad Tadepalli
### Background
现有的深度学习模型经常难以解释，尤其是关于单张图像的局部视觉解释往往忽略全局视角。相比之下，基于概念的解释虽然能提供全局洞察，但需要大量人工标注，增加了标注成本。本文探讨了如何利用少量图片中的用户定义的部分标签，并将这些标签有效转移到较大数据集中，通过部分局部解释的聚合生成全局符号性解释，从而为大规模模型决策提供易于理解的解释方法，但同时也保留一定的全局性理解能力。
### Innovation
提出了一种方法，利用有限图像中的用户定义部分标签，有效地转移到更大数据集中，生成全局符号性解释。这种方法结合了局部解释和全局理解，提供了一种经济高效的解释方案，适用于大规模应用。
### Conclusion
本文提出的方法能够大规模提供人类可理解的深度学习模型决策解释。通过在有限标注的基础上，利用部分对应关系，实现了更低成本、更广泛的全局解释能力。这种方法对于提高模型透明度和增强用户信任具有重要意义。
## 436. `cs.CV` - 使用多模态联合嵌入预测架构学习影像与临床特征的自监督学习 [PDF](https://arxiv.org/pdf/2509.15470), [HTML](https://arxiv.org/abs/2509.15470)
### Authors
Thomas Z. Li,Aravind R. Krishnan,Lianrui Zuo,John M. Still,Kim L. Sandler,Fabien Maldonado,Thomas A. Lasko,Bennett A. Landman
### Background
多模态模型在肺结节诊断的发展受限于标注数据的稀缺性和这些模型容易在训练分布上过拟合的问题。因此，需要一种方法来克服这些挑战。
### Innovation
本文采用自监督学习从纵向和多模态档案中学习，通过联合归一化预测架构（JEPA）预训练，使用来自机构内部患者的无标签CT扫描和电子健康记录，随后通过监督微调，展示了该方法与未正则化的多模态模型和影像模型相比的优越性，但外部群体测试显示其性能较差。开发了一种合成环境，描述了JEPA可能性能不佳的上下文。
### Conclusion
本文通过利用无标签的多模态医学档案提高了预测模型的效果，并展示了其在肺结节诊断中的优势与局限性。
## 437. `cs.CV` - 通过生成模型实现高效多模态数据集蒸馏 [PDF](https://arxiv.org/pdf/2509.15472), [HTML](https://arxiv.org/abs/2509.15472)
### Authors
Zhenghao Zhao,Haoxuan Wang,Junyi Wu,Yuzhang Shang,Gaowen Liu,Yan Yan
### Background
数据集蒸馏的目标是从大规模数据集中生成一个小规模数据集，从而使训练于其上的模型在原始数据集上表现良好。随着大型语言模型和多模态大型语言模型的兴起，尤其是图像-文本数据集的重要性显著提升。然而，现有的多模态数据集蒸馏方法受到匹配训练轨迹算法的限制，这极大地增加了计算资源的需求，并且需要数天来进行蒸馏处理。
### Innovation
本文提出了一种名为EDGE的生成式蒸馏方法，用于高效多模态数据集蒸馏。具体而言，作者提出了两种关键挑战解决方法：1) 通过双向对比损失和多样性损失改进生成模型的训练流程，解决了生成图像和标题之间的相关性差以及生成样本多样性不足的问题。2) 提出了新的标题生成策略，通过引入更多文本信息来进一步提升文本到图像检索性能。该方法在Flickr30K、COCO和CC3M数据集上的评估结果表明，它在性能和效率上优于现有方法，并且比最先进的方法快18倍。
### Conclusion
该研究通过EDGE方法解决了多模态数据集蒸馏中的两个关键挑战，大大提高了生成模型的生成质量和多样性，同时提高了多模态数据集蒸馏的效率。实验结果表明，EDGE在多个基准数据集上的性能和效率均优于现有方法。
## 438. `cs.CV` - 使用表征相似性分析比较计算病理学基础模型 [PDF](https://arxiv.org/pdf/2509.15482), [HTML](https://arxiv.org/abs/2509.15482)
### Authors
Vaibhav Mishra,William Lotter
### Background
计算病理学(CPath)领域中的基础模型正因其实现许多下游任务的潜力而得到越来越多的关注。虽然最近的研究已经在不同模型上评估了任务性能，但关于它们所学习到的表示结构及其变异性仍然了解不多。本文通过对六个CPath基础模型进行系统分析，使用计算神经科学中流行的技术，研究了这些模型的表征空间。
### Innovation
本文创新地使用表征相似性分析方法，系统地分析了六个CPath基础模型的表示空间，这些模型包括视觉-语言对比学习（CONCH、PLIP、KEEP）和自我蒸馏（UNI (v2)、Virchow (v2)、Prov-GigaPath）的方法。研究发现，UNI2和Virchow2有最不同的表示结构，而Prov-Gigapath具有最高的平均相似性。相同训练范式（视觉仅限 vs. 视觉-语言）并不一定能保证更高的表示相似性。所有模型的表征都显示出较高的切片依赖性，但相对较低的疾病依赖性。
### Conclusion
这些发现强调了改进对切片特异性特征鲁棒性、指导模型集成策略以及理解训练范式如何塑造模型表示的重要性。本文的框架可以在医学成像领域推广，通过探究基础模型的内部表示来确保其开发和部署的有效性。
## 439. `cs.CV` - PRISM：基于相位增强的径向图像特征映射框架用于生成AI图像的指纹识别 [PDF](https://arxiv.org/pdf/2509.15270), [HTML](https://arxiv.org/abs/2509.15270)
### Authors
Emanuele Ricco,Elia Onofri,Lorenzo Cima,Stefano Cresci,Roberto Di Pietro
### Background
随着生成型AI技术的应用日益广泛，迫切需要能够识别生成式AI内容来源的方法。特别是在商业环境中，用户期望能够对获得的内容来源进行保障。因此，该研究旨在探索和开发一种可扩展的框架，用于识别和指纹AI生成的图像，即PRISM框架。PRISM利用径向傅里叶变换和相位信息捕捉模型特异性标记，结合线性判别分析实现不同环境下的稳定识别。
### Innovation
该研究创新地提出了基于相位增强的径向图像特征映射框架PRISM，它通过对离散傅里叶变换进行径向缩减来利用幅度和相位信息提取模型特异性签名。此外，研究还构建了一个包含36,000张图像的PRISM-36K数据集，涵盖了六种文本到图像的生成对抗网络（GAN）和扩散模型。PRISM在该数据集上的识别准确率达到92.04%，且在四个文献基准测试中平均准确率达到81.60%，在二分类真假图像检测任务中准确率达到88.41%。研究结果表明，频率域指纹识别技术在跨架构和跨数据集的模型识别上具有有效性。
### Conclusion
该研究通过PRISM框架展示了在生成型AI系统中实施问责和信任机制的可能性，并强调了根据频率域指纹技术进行模型识别方法的有效性。
## 440. `cs.CV` - RaceGAN：一种在图像到图像翻译中保留个体性的种族信息转换架构 [PDF](https://arxiv.org/pdf/2509.15391), [HTML](https://arxiv.org/abs/2509.15391)
### Authors
Mst Tasnim Pervin,George Bebis,Fang Jiang,Alireza Tavakkoli
### Background
生成对抗网络（GANs）在未配对的图像到图像转换方面取得了显著进展，特别是在多个应用中。CycleGAN 是最早实现这一目标的，但它局限于两个领域。StarGAN 解决了这一限制，能够跨多个领域进行图像到图像的转换，但无法捕捉这些领域中的深层次风格变化。StarGANv2 和 StyleGAN 的创新性改进使得引用指导图像合成风格映射成为可能，但这些模型仍然缺乏个体性，并且需要额外的参考图像作为输入。
### Innovation
RaceGAN 作为一种新颖的框架，能够在种族属性转换过程中跨越多个领域映射风格代码，同时保持个体性和高层语义，无需依赖参考图像。RaceGAN 在使用芝加哥人脸数据集测试时，在转换种族特征（即亚洲、白人和黑人）方面表现优于其他模型，而且利用基于 InceptionReNetv2 的分类进行了定量分析，证明了其种族转换的有效性。此外，还研究了模型如何将潜在空间分割成每个种族群体的独立簇.
### Conclusion
RaceGAN能够跨多个领域映射种族属性转换中的风格代码，同时保持个体性和高层语义，在芝加哥人脸数据集上优于其他模型，通过定量分析验证了种族转换的有效性，并且展示了模型如何将潜在空间分割成每个种族群体的独立簇.
## 441. `cs.CV` - CAGE: Continuity-Aware edGE Network Unlocks Robust Floorplan Reconstruction [PDF](https://arxiv.org/pdf/2509.15459), [HTML](https://arxiv.org/abs/2509.15459)
### Authors
Yiyi Liu,Chunyang Liu,Weiqin Jiao,Bojian Wu,Fashuai Li,Biao Xiong
### Background
传统的基于角的多边形表示在面对噪声和不完整的观测时非常敏感，常常导致布局破碎或不合理。尽管近期的线条分组方法利用了结构线索来提高鲁棒性，但仍然难以恢复细微的几何细节。这些限制促使研究人员寻找更稳健的方法来直接从点云密度图重建矢量楼层计划。
### Innovation
提出了名为CAGE（Continuity-Aware edGE）的网络框架，该框架基于边的原始方法，将每个墙段表示为定向的、几何上连续的边。为此，开发了一种结合扰动和潜在查询的双查询变压器解码器，该方法不仅稳定了优化过程，还加速了收敛。实验证明，CAGE在Structured3D和SceneCAD数据集上的表现优于现有方法，特别是在房间、角落和角度的F1分数方面取得了优异成绩。此外，该方法在不同数据集上也表现出强健的泛化能力，证明了其架构创新的有效性。
### Conclusion
CAGE框架通过直接从点云密度图重建矢量楼层计划，实现了在鲁棒性方面的新突破，显示出强大的表现和良好的泛化能力。该方法将为楼层计划重建提供一种新的可行方案，并显著改善方案的连续性和鲁棒性。
## 442. `cs.CV` - GUI-ARP：提升GUI代理定位能力的自适应区域感知 [PDF](https://arxiv.org/pdf/2509.15532), [HTML](https://arxiv.org/abs/2509.15532)
### Authors
Xianhang Ye,Yiqing Li,Wei Dai,Miancan Liu,Ziyuan Chen,Zhangye Han,Hongbo Min,Jinkui Ren,Xiantao Zhang,Wen Yang,Zhi Jin
### Background
现有的GUI定位方法在高分辨率屏幕截图中往往难以进行细粒度的定位。
### Innovation
提出了GUI-ARP新框架，引入了自适应区域感知(ARP)和自适应阶段控制(ASC)，支持单阶段推断和多阶段分析，通过两阶段训练管道结合监督微调和基于Group Relative Policy Optimization (GRPO)的强化微调实现。
### Conclusion
广泛的实验表明，提出的GUI-ARP在复杂GUI定位基准上达到领先性能，特别是在ScreenSpot-Pro上的准确率为60.8%，UI-Vision上的准确率为30.9%。特别地，GUI-ARP-7B在某些基准上展示了与开源72B模型（UI-TARS-72B准确率为38.1%）和专有模型相当的竞争性。
## 443. `cs.CV` - Lynx：迈向高保真个性化视频生成 [PDF](https://arxiv.org/pdf/2509.15496), [HTML](https://arxiv.org/abs/2509.15496)
### Authors
Shen Sang,Tiancheng Zhi,Tianpei Gu,Jing Liu,Linjie Luo
### Background
本文介绍了Lynx，这是一种从单张输入图像合成个性化视频的高保真模型。Lynx基于开源的扩散变换器（DiT）基础模型构建，并引入了两个轻量级适配器以确保身份保真度。通过这些模块，Lynx能够实现稳健的身份保护，同时保持时间连续性和视觉真实性。
### Innovation
Lynx引入了两种轻量级适配器，分别为ID-adapter和Ref-adapter。ID-adapter使用Perceiver Resampler将ArcFace提取的面部嵌入转换为紧凑的身份令牌，用于条件设置；Ref-adapter则结合了冻结的参考路径的密集VAE特征，通过交叉注意力机制向所有变换器层注入细粒度的细节。这些模块共同实现了稳健的身份保护，同时保持了时间和视觉的真实性。
### Conclusion
通过在40个受试者和20个未偏见提示的编排基准数据集上的评估，Lynx展示了更优的面部相似度、竞争力的提示跟随和强大的视频质量，从而推动了个性化视频生成技术的发展。
## 444. `cs.CV` - SAMPO：基于运动提示的层级自回归模型构建生成型世界模型 [PDF](https://arxiv.org/pdf/2509.15536), [HTML](https://arxiv.org/abs/2509.15536)
### Authors
Sen Wang,Jingyi Tian,Le Wang,Zhimin Liao,Jiayi Li,Huaiyi Dong,Kun Xia,Sanping Zhou,Wei Tang,Hua Gang
### Background
世界模型允许智能体在想象的环境中进行行动后果的模拟，以进行规划、控制和长范围决策。然而，现有的自回归世界模型在生成视觉连贯的预测方面存在困难，主要由于其在空间结构维持、解码效率和运动建模方面存在不足。因此，本文提出了SAMPO（Scale-wise Autoregression with Motion PrOmpt）框架，该框架结合了帧内自回归建模和因果运动建模，以提升预测质量和效率。
### Innovation
1. 提出了结合帧内视觉自回归建模和下一帧因果建模的混合框架。2. 集成了时间因果解码与双向空间注意力机制，保持了空间局部性并支持高效并行解码。3. 设计了不对称多尺度标记化器，保留已观测帧的空间细节，并为未来帧提取紧凑的动力学表示，优化了内存使用和模型性能。4. 引入了轨迹感知运动提示模块，注入时空线索来关注动态区域，提升时间一致性和物理真实性。以上创新显著提升了生成质量和推理速度。
### Conclusion
实验结果表明，SAMPO 在基于动作的视频预测和模型驱动控制任务中表现竞争力，相比现有方法，生成质量提高了4.4倍的推理速度。同时，验证了SAMPO在零样本泛化和扩展性能方面的表现。
## 445. `cs.CV` - 通过可逆剪枝掩模进行后门缓解 [PDF](https://arxiv.org/pdf/2509.15497), [HTML](https://arxiv.org/abs/2509.15497)
### Authors
Kealan Dunnett,Reza Arablouei,Dimity Miller,Volkan Dedeoglu,Raja Jurdak
### Background
剪枝作为一种有前途的防御策略，已经在抵御深度学习中的后门攻击方面获得广泛关注。然而，现有的基于剪枝的方法往往在准确识别并移除导致后门行为的具体参数方面能力不足。尽管最近文献中强调了基于微调的防御方法，主要是由于它们在性能上的优越性，但是剪枝依然是一种吸引人的替代方案，因为它提供了更高的可解释性和在数据量有限的环境下的改进鲁棒性。
### Innovation
本文提出了一种新颖的剪枝方法，它包含一个学习的“选择”机制，用于识别对主要任务和后门任务都至关重要的参数，以及一个“可逆”剪枝掩模，旨在同时实现两个互补的目标：消除后门任务并通过逆掩模保留它。该方法将此问题形式化为一个双层优化问题，联合学习选择变量、稀疏可逆掩模以及从干净数据中推导出的样本特定后门扰动。内层问题使用逆掩模合成候选触发器，而外层问题则改进掩模以抑制后门行为而不会损害清洁任务的准确性。
### Conclusion
广泛的实验表明，本文的方法比现有的基于剪枝的后门缓解方法表现更优，维持了在有限数据条件下的强劲性能，并且与最先进的微调方法相比达到了具有竞争力的结果。值得注意的是，提出的这种方法特别有效，可以在成功缓解后门攻击后恢复对受损样本的正确预测。
## 446. `cs.CV` - OpenViGA：使用公开数据微调开源模型进行汽车驾驶场景视频生成 [PDF](https://arxiv.org/pdf/2509.15479), [HTML](https://arxiv.org/abs/2509.15479)
### Authors
Björn Möller,Zhengyang Li,Malte Stelzer,Thomas Graave,Fabian Bettels,Muaaz Ataya,Tim Fingscheidt
### Background
近年来，成功预测并生成真实汽车驾驶场景的视频生成系统常将标记化、未来状态预测（世界模型）和视频解码分配给专门的模型。这些方法通常使用需要大量训练资源的大模型，并且设计选择的解释性较低，缺乏公开的代码和数据集。
### Innovation
我们通过提供对系统三个组成部分（图像标记化器、世界模型和视频解码器）的单独定量和定性评估来超越先前的一些视频生成工作，如GAIA-1。我们完全基于来自不同领域的强大预训练开源模型进行构建，并通过公开可用的汽车数据（BDD100K）在学术规模的GPU硬件上进行微调。我们通过简化组件接口构建了一个完整的视频生成系统，并由于底层模型和数据的公开可用性，实现了完全可重复性。此外，我们也将在GitHub上发布我们的代码和模型。对于256x256的图像尺寸和4 fps，我们预测时仅有一个帧的算法延迟即可生成现实的驾驶场景视频帧。
### Conclusion
我们提出了OpenViGA，一个开源汽车驾驶场景视频生成系统，通过使用公共数据微调开源模型来解决先前工作的不足。
## 447. `cs.CV` - MEC-Quant: 极低位宽最大熵编码量化感知训练 [PDF](https://arxiv.org/pdf/2509.15514), [HTML](https://arxiv.org/abs/2509.15514)
### Authors
Junbiao Pang,Tianyang Cai,Baochang Zhang
### Background
量化感知训练（QAT）引起了对高效神经网络生产极大的关注。现有QAT仍无法达到全精度（FP）模型的表现。研究表明，量化不可避免地会引入学习表示的偏差，尤其是在极低位宽设置下更为明显。
### Innovation
提出了一种更为严谨的目标——最大熵编码量化（MEC-Quant），它显式地优化了表示的结构，使得学习到的表示更少偏差，从而能更好地泛化到未见过的数据。为了使目标端到端可训练，利用了无损数据编码中的最小编码长度来作为熵的可计算替代项，并进一步基于专家混合体（MOE）理论上实现了目标的可扩展重新表述，这不仅允许快速计算，还能处理权重或激活值的长尾分布。
### Conclusion
实验结果表明，MEC-Qaunt在各类计算机视觉任务中表现出优越性。它首次将QAT的限制扩展到了x-bit激活，并且其准确率与FP模型相当甚至更优。MEC-Qaunt为QAT设定了新的状态。
## 448. `cs.CV` - 基于扩散的跨模态特征提取用于多标签分类 [PDF](https://arxiv.org/pdf/2509.15553), [HTML](https://arxiv.org/abs/2509.15553)
### Authors
Tian Lan,Yiming Zheng,Jianxin Yin
### Background
多标签分类在广泛应用中依赖于能够捕捉多标签相互作用的强大表示方法。本文介绍了一种名为Diff-Feat的框架，该框架可以从预训练的扩散-变换器模型中提取图像和文本的中间特征，并将其融合用于下游任务。
### Innovation
本文提出了一种简单但强大的框架Diff-Feat，通过利用预训练的扩散-变换器模型提取中间特征并进行融合，特别指出了一种在各种分类任务中表现最佳的中间特征出现在不同的步骤和块中。还设计了一种启发式局部搜索算法来定位最优的特征组合，并展示了其在多个下游任务中超越了许多基线模型。同时，通过t-SNE和聚类分析展示了Diff-Feat在语义聚类上的优势。
### Conclusion
Diff-Feat在MS-COCO-enhanced数据集上达到了98.6%的mAP，在Visual Genome 500数据集上达到了45.7%的mAP，显著超过了基于CNN、图和变换器的基线模型。此外，Diff-Feat形成的语义簇更为紧密。
## 449. `cs.CV` - 增强Sa2VA以实现参考视频对象分割：第七届LSVOS RVOS赛道的第2名解决方案 [PDF](https://arxiv.org/pdf/2509.15546), [HTML](https://arxiv.org/abs/2509.15546)
### Authors
Ran Hong,Feng Lu,Leilei Cao,An Yan,Youhai Jiang,Fengjie Zhu
### Background
Referential Video Object Segmentation (RVOS)旨在通过语言描述分割视频中的所有对象，以连接视觉与语言理解之间的差距。近期工作Sa2VA通过结合大型语言模型（LLMs）和SAM，利用LLMs的强视频推理能力来引导视频分割。但Sa2VA仍存在一些性能改进空间，尤其是在无额外训练情况下提高性能方面。
### Innovation
本文提出了一个无训练框架，显著提升了Sa2VA在RVOS任务上的性能。创新点在于引入了两个关键组件：1) 视频-语言检查器，通过明示验证查询中的主题和动作是否实际出现在视频中，从而减少误报；2) 关键帧抽样器，自适应地选择信息性的帧，以更好地捕捉早期对象出现和长期时间上下文。
### Conclusion
在MeViS测试集上，完全未经额外训练的情况下，本文的方法实现了64.14%的J&F得分，并在ICCV 2025第七届LSVOS挑战赛RVOS赛道中排名第2位。
## 450. `cs.CV` - DC-Mamba: 双时相变形对齐和尺度稀疏增强用于遥感变化检测 [PDF](https://arxiv.org/pdf/2509.15563), [HTML](https://arxiv.org/abs/2509.15563)
### Authors
Min Sun,Fenghui Guo
### Background
遥感变化检测（RSCD）对于识别土地覆盖变化至关重要，但现有方法，包括最新的状态空间模型（SSMs），往往缺乏处理几何错位的显式机制，且难以区分真实的细微变化。因此，本研究提出了DC-Mamba框架，该框架基于ChangeMamba骨干，并集成了两个轻量级、即插即用模块：双时相变形对齐（BTDA）和尺度稀疏变化增强（SSCA），旨在解决上述问题。
### Innovation
DC-Mamba提出了一个“对齐-增强”框架，它结合了双时相变形对齐（BTDA）和尺度稀疏变化增强（SSCA）这两个模块。BTDA在语义特征级别明确引入几何意识以纠正空间错位，而SSCA则利用多源线索选择性地放大高置信度变化信号并抑制噪声，从而在最终分类前增强变化的可见性。这种方法首先通过BTDA建立几何一致性，减少伪变化，然后利用SSCA突出关键边界，增强小目标或细微目标的可见性。
### Conclusion
实验结果显示，该方法在与强大的ChangeMamba基线相比时，显著提升了性能，F1分数从0.5730提高到0.5903，IoU从0.4015提高到0.4187。结果证实了“对齐-增强”策略的有效性，提供了一种坚固且易于部署的解决方案，以透明地解决RSCD中的几何和特征级挑战。
## 451. `cs.CV` - 超越语言：利用非语言线索增强欲望、情感和情感识别 [PDF](https://arxiv.org/pdf/2509.15540), [HTML](https://arxiv.org/abs/2509.15540)
### Authors
Wei Chen,Tongguan Wang,Feiyue Xue,Junkai Li,Hui Liu,Ying Sha
### Background
欲望作为一种驱动人类行为的意图，与情感和情感密切相关。多模态学习促进了情感和情绪识别，但对于专门针对人类欲望理解的多模态方法的研究仍未充分探索。现有的情感分析方法主要强调言语线索，忽视作为补充非言语线索的图像。为解决这些问题，本文探讨了欲望、情感和情感识别中的多模态学习框架，旨在更好地捕捉意图相关信息的表征。
### Innovation
本文提出了一种对称双向多模态学习框架，用于欲望、情感和情感识别。该框架通过互指导的方式提高了文本和图像模态之间的相互作用，利用了低分辨率图像进行多模态对齐，高分辨率图像则分割成子图像进行掩码图像建模，以增强捕捉小细节的能力。此外，引入了文本引导的图像解码器和图像引导的文本解码器，促进了图像信息的局部和全局表示的深度跨模态交互。为平衡感知获益与计算成本，采用混合尺度图像策略，高分辨率图像分割成子图像进行掩码建模。
### Conclusion
本文在MSED数据集上对所提方法进行了评估，该数据集包括欲望理解基准以及情感和情感识别任务。实验结果表明，所提方法在其它最先进的方法上具有一致的改进效果，验证了该方法的有效性。具体来说，方法在欲望理解上取得了1.1%的F1分值提升，在情感识别和情感分析上分别取得0.6%和0.9%的提升。本文的代码已开源。
## 452. `cs.CV` - EyePCR：眼科手术中细粒度感知、知识理解及临床推理的全面基准 [PDF](https://arxiv.org/pdf/2509.15596), [HTML](https://arxiv.org/abs/2509.15596)
### Authors
Gui Wang,Yang Wennuo,Xusen Ma,Zehao Zhong,Zhuoru Wu,Ende Wu,Rong Qu,Wooi Ping Cheah,Jianfeng Ren,Linlin Shen
### Background
尽管MLLMs在多个领域展现了出色的能力，但在高风险、特定领域的场景下，如外科手术，其性能仍被广泛探索。文章倡导创建了一个名为EyePCR的基准测试，以评估语义认知的真实表现。
### Innovation
开发了一个名为EyePCR的大型基准测试，围绕感知、理解、推理三个层面评估眼科手术分析中的认知能力。EyePCR包含多种精细注释的数据集，可帮助模型在模拟手术场景中更好地认知和推理，进而提升模型的认知能力。此外，还展示了一个适应眼科手术领域的变体模型达到了在感知层面的最高准确率，并且在理解和推理方面也大幅超越开源模型。
### Conclusion
现有的MLLMs在手术认知领域存在局限性，EyePCR不仅可以作为基准测试，还可以作为提升手术视频理解模型临床可靠性的基础。
## 453. `cs.CV` - 从资源限制地区中视力和听力威胁疾病的AI辅助远程医疗服务开发到部署：现场观察、挑战和前进之路 [PDF](https://arxiv.org/pdf/2509.15558), [HTML](https://arxiv.org/abs/2509.15558)
### Authors
Mahesh Shakya,Bijay Adhikari,Nirsara Shrestha,Bipin Koirala,Arun Adhikari,Prasanta Poudyal,Luna Mathema,Sarbagya Buddhacharya,Bijay Khatri,Bishesh Khanal
### Background
在资源有限的地区（RCS），视力和听力威胁疾病的预防性残疾是可预防的，但由于缺乏专科医生和筛查设施，这些威胁导致了显著的预防性残疾人。大型AI辅助筛查和远程医疗服务在扩展早期检测方面具有潜力，但在基于纸张的工作流程中实际部署具有挑战性，且现有文献中缺乏相关经验进行参考。
### Innovation
通过早期原型开发、成像部署和持续反馈进行迭代和跨学科合作，实现纸面转AI的工作流程。利用公开数据集和AI模型，特别是在领域迁移不佳时。强调自动AI图像质量检查的重要性，以确保高质量的筛查图像。将AI开发和工作流程数字化视为端到端的迭代共设过程。
### Conclusion
通过记录这些实际挑战和学习经验，旨在填补资源限制地区AI辅助远程医疗服务和大规模筛查项目在实际操作中的知识空白。
## 454. `cs.CV` - SmolRGPT: 600M参数下的高效仓储环境空间推理 [PDF](https://arxiv.org/pdf/2509.15490), [HTML](https://arxiv.org/abs/2509.15490)
### Authors
Abdarahmane Traore,Éric Hervet,Andy Couturier
### Background
近期的视觉-语言模型（VLMs）在多模态推理方面取得了重要进展，但最先进的方法通常依赖于极其庞大的模型，这导致了计算和内存需求巨大，使得它们在资源受限的环境中部署变得困难，这包括仓库、机器人和工业应用等场景，这些场景对效率和空间理解能力有严格要求。
### Innovation
SmolRGPT 是一种紧凑的视觉-语言架构，通过结合 RGB 和深度线索，明确地融入了区域级别的空间推理。它采用了三个阶段的课程，逐步对齐视觉和语言特征，理解空间关系，并适应特定任务的数据集。
### Conclusion
SmolRGPT 仅使用 600M 参数，在具有挑战性的仓储空间推理基准上就取得了具有竞争力的结果，匹配甚至超过了更大的模型的性能。这些发现突显了在不牺牲核心空间推理能力的情况下，在实际应用环境中实现高效、可部署的多模态智能的潜力。实验代码将在指定网址提供。
## 455. `cs.CV` - 以报告辅助自我蒸馏增强WSI基础生存分析 [PDF](https://arxiv.org/pdf/2509.15608), [HTML](https://arxiv.org/abs/2509.15608)
### Authors
Zheng Wang,Hong Liu,Zheng Wang,Danyi Li,Min Cen,Baptiste Magnier,Li Liang,Liansheng Wang
### Background
基于全切片显微图像（WSI）的生存分析对于评估癌症预后至关重要，因为它们提供了预测患者结果所需的详细微观信息。然而，传统的WSI生存分析通常面临噪声特征和数据可访问性有限的问题，影响其捕捉关键预后特征的能力。尽管病理报告提供了丰富的患者特定信息，但它们如何增强基于WSI的生存分析仍是一个未探索的领域。
### Innovation
本文提出了一种名为Report-auxiliary self-distillation（Rasa）的新框架，用于基于WSI的生存分析。首先，利用先进的大语言模型从原始噪声病理报告中提取细粒度、与WSI相关的文本描述，并通过精心设计的任务提示。其次，设计了一种基于自我蒸馏的管道，以教师模型的文本知识为指导，过滤掉学生模型中不相关或冗余的WSI特征。最后，在学生模型的训练过程中引入了风险感知mix-up策略，以增强训练数据的数量和多样性。实验证明，Rasa方法优于现有方法。
### Conclusion
在我们收集的数据（CRC）和公开数据（TCGA-BRCA）上的广泛实验显示，Rasa在提高基于WSI的生存分析效果方面效果显著。
## 456. `cs.CV` - PCSR: 假标签一致性引导的样本精炼方法在噪声对应学习中的应用 [PDF](https://arxiv.org/pdf/2509.15623), [HTML](https://arxiv.org/abs/2509.15623)
### Authors
Zhuoyao Liu,Yang Liu,Wentao Feng,Shudong Huang
### Background
交叉模态检索旨在通过语义相似性对不同模态进行对齐。现有方法通常假设图像-文本对是完美对齐的，忽略了现实数据中存在噪声对应这一事实。这些未对齐的对误导了相似性学习，降低了检索性能。先前的方法往往依赖粗粒度的分类，将数据简单地分为干净和噪声样本，未能充分认识到噪声实例中的内在多样性。此外，这些方法通常采用统一的训练策略，无论样本特征如何，都进行统一训练，导致模型优化时样本利用率低下。
### Innovation
我们提出了一种新的框架，称为假标签一致性引导的样本精炼（PCSR），通过明确地根据假标签一致性对样本进行划分，增强对应关系可靠性。首先采用基于置信的估计来区分清洁和噪声对，然后通过假标签一致性精炼噪声对，揭示结构上不同的子集。进一步提出了假标签一致性得分（PCS）来量化预测稳定性，使得在噪声对中划分出含糊和可精炼的样本。此外，采用自适应对优化（APO），含糊样本通过稳健的损失函数优化，可精炼样本通过文本替换在训练中增强。
### Conclusion
在CC152K、MS-COCO和Flickr30K上的广泛实验验证了我们的方法在噪声监督下的检索鲁棒性改进效果。
## 457. `cs.CV` - UNIV: 统一的红外和可见光模态基础模型 [PDF](https://arxiv.org/pdf/2509.15642), [HTML](https://arxiv.org/abs/2509.15642)
### Authors
Fangyuan Mao,Shuo Wang,Jilin Mei,Chen Min,Shun Lu,Fuyang Liu,Yu Hu
### Background
联合RGB可见光和红外感知的需求正在迅速增长，尤其是在不同天气条件下需要稳健性能的应用场景中。虽然针对RGB可见光和红外数据的预训练模型在其各自领域表现出色，但在多模态场景（如装有两传感器的自主车辆）下性能往往较低。
### Innovation
本文提出了一种生物启发式的红外与可见光统一基础模型（UNIV），其创新点包括：1) 引入了基于注意的块间跨模态对比学习（PCCL）框架，该框架模仿了视网膜水平细胞的侧抑制现象，从而实现了有效的跨模态特征对齐，同时兼容任何基于变压器的架构；2) 提出了双重知识保持机制，模仿视网膜双极细胞信号传递机制，结合LoRA适配器与同步蒸馏，防止灾难性遗忘，从而模拟视网膜的光适应（视锥驱动）和暗适应（视杆驱动）功能。
### Conclusion
通过引入MVIP数据集作为跨模态学习的支持，UNIV在红外任务上表现出优越性能（例如：语义分割提高1.7 mIoU，目标检测提高0.7 mAP），同时在可见光RGB任务上保持了99%以上的基础性能。
## 458. `cs.CV` - 使用语言验证数据和异构模态融合进行短视频中的假新闻检测的多模态学习 [PDF](https://arxiv.org/pdf/2509.15578), [HTML](https://arxiv.org/abs/2509.15578)
### Authors
Shanghong Li,Chiam Wen Qi Ruth,Hong Xu,Fang Liu
### Background
随着短视频平台的快速普及，检测虚假新闻的需求变得迫切。当前方法在处理短视频内容的动态性和多模态性方面存在困难。虚假信息的广泛传播和易于分享可能造成严重的社会损害，因此需要先进的检测方法来应对这一挑战。
### Innovation
本文提出了一种名为HFN（Heterogeneous Fusion Net）的新型多模态框架，该框架整合视频、音频和文本数据以评估短视频内容的真伪。HFN引入了决策网络，在推理过程中动态调整模态权重，并引入了加权多模态特征融合模块，确保即使数据不完整也能保持稳健性能。此外，作者还贡献了一个专门为短视频虚假新闻检测设计的全面数据集VESV（VEracity on Short Videos）。实验结果表明，HFN在Marco F1指标上分别比最先进的方法提高了2.71%和4.14%，特别是在新收集的VESV数据集上。
### Conclusion
本工作建立了一个稳健的解决方案，能够有效识别短视频平台上的虚假新闻，为改善假新闻的防控提供了更可靠和全面的方法。
## 459. `cs.CV` - 向大小不变的显著对象检测迈进：一种通用评估和优化方法 [PDF](https://arxiv.org/pdf/2509.15573), [HTML](https://arxiv.org/abs/2509.15573)
### Authors
Shilong Bao,Qianqian Xu,Feiran Li,Boyu Han,Zhiyong Yang,Xiaochun Cao,Qingming Huang
### Background
本文探讨了显著对象检测（SOD）领域的一个基本但尚未深入研究的问题：评估协议中的大小不变性属性，特别是在同一图像中存在多个大小相差悬殊的显著对象时的情况。现有的SOD评估指标存在固有的大小敏感性问题，导致了预测误差主要由大区域主导，而小但更具有语义重要性的对象则往往被忽视，从而导致了偏差的性能评估和实际应用中的退化。
### Innovation
提出了一个通用的大小不变性评估框架（SIEva），该框架通过分别评估每个可分组件并在最终结果中综合这些信息，有效地缓解了对象大小不平衡的影响。进一步发展出了一种专门的优化框架（SIOpt），该框架遵循大小不变性原则，在广泛大小范围内的目标检测方面显著提高了显著对象检测的性能。SIOpt 是模型无关的，可以完美地与多种 SOD 基本模型兼容。理论上，还对 SOD 方法进行了泛化分析，并提供了支持新型评估协议有效性的证据。
### Conclusion
全面的实验表明了我们提出的方法的有效性。相应的代码已在此处提供。
## 460. `cs.CV` - 基于PCA的不完整点云数据的表面重建模型 [PDF](https://arxiv.org/pdf/2509.15675), [HTML](https://arxiv.org/abs/2509.15675)
### Authors
Hao Liu
### Background
点云数据是数学建模中至关重要的信息类别，从这类数据重建表面是一个跨学科的重要任务。然而，在扫描过程中，由于高吸收率、遮挡等因素，收集到的点云数据可能无法完全覆盖表面，导致数据不完整，这种不完整数据导致在缺失数据区域进一步推断表面结构并成功重建表面成挑战。
### Innovation
本文提出了一种基于PCA的模型用于从不完整点云数据重建表面。首先利用PCA估算底层表面的法线信息，该法线信息作为模型中的正则化项，指导表面的重建，特别是在缺失数据区域。此外，引入了一种分割方法来有效解决提出的模型。
### Conclusion
通过系统的实验，证明了本文提出的方法能够成功地推断数据缺失区域的表面结构，并且很好地重建底层表面，优于现有方法。
## 461. `cs.CV` - BTL-UI：基于Blink-Think-Link推理模型的GUI代理 [PDF](https://arxiv.org/pdf/2509.15566), [HTML](https://arxiv.org/abs/2509.15566)
### Authors
Shaojie Zhang,Ruoceng Zhang,Pei Fu,Shaokang Wang,Jiahui Yang,Xin Du,Shiqi Cui,Bin Qin,Ying Huang,Zhenbo Luo,Jian Luan
### Background
在AI驱动的人机界面（GUI）交互自动化领域，尽管多模式大型语言模型和强化学习微调技术取得了显著进展，但一个根本性的挑战依然存在：这些模型的交互逻辑与自然的人与GUI间通信模式有显著差异。为解决这一问题，该研究提出了Blink-Think-Link（BTL）框架，这是一种以脑部启发为基础的框架，模仿人类与图形界面之间的认知过程，在交互过程中分解为三个可生物合理解释的阶段：（1）眨眼——快速检测和关注屏幕上相关的区域，类似于眨眼的眼睛运动；（2）思考——更高层次的推理和决策，模拟认知规划；（3）链接——生成可执行的命令以实现精确的运动控制，模拟人类的动作选择机制。该框架为理解GUI动态交互任务提供了理论基础和实践指导，有助于实现更加自然和高效的人机交互。
### Innovation
该研究的两大技术创新点在于：1. 瞳孔数据生成——一种自动化注释流水线，旨在优化瞳孔数据标注；2. BTL Reward——首个基于规则的奖励机制，通过结合过程和结果驱动的强化学习，提高了模型的鲁棒性和灵活性。通过这一框架，开发出了名为BTL-UI的GUI代理模型，在综合基准测试中展示了在静态GUI理解和动态交互任务中的一致领先性能。这一结果提供了框架在开发高级GUI代理方面的实证有效性验证。
### Conclusion
这些结果表明，基于Blink-Think-Link框架的方法在构建先进的GUI代理方面具有显著优势。通过BTL-UI模型，研究人员成功地提高了人机交互自然性和精确度，未来的工作将致力于进一步优化BTL框架，并扩展其应用范围，以更好地适应复杂的人机交互场景。
## 462. `cs.CV` - MS-GS: 在野外的多外观稀视角3D高斯打点 [PDF](https://arxiv.org/pdf/2509.15548), [HTML](https://arxiv.org/abs/2509.15548)
### Authors
Deming Li,Kaiwen Jiang,Yutao Tang,Ravi Ramamoorthi,Rama Chellappa,Cheng Peng
### Background
在野外的照片集合中，图像的数量往往有限且外观多样，例如在不同时间和季节拍摄，这对场景重构和新颖视角合成构成了重大挑战。尽管近年来通过神经辐射场（NeRF）和3D高斯打点（3DGS）等方法有所改进，但在这些领域中仍然存在问题，如过度平滑和易过拟合。
### Innovation
本文提出MS-GS，这是一个结合稀视角场景中多外观能力的新框架，基于几何先验，利用单目深度估计进行可靠对齐。通过结构从运动（SfM）点置算法提取并利用局部语义区域，引入多视图约束，提出细粒度和粗粒度几何引导监督，促进3D一致性并减少过拟合。同时，介绍了一个数据集和野外实验设置，为更具挑战性的稀视角和多外观条件提供更现实的基准。
### Conclusion
MS-GS在多种稀视角和多外观挑战条件下实现了逼真的渲染，并在不同数据集上显著优于现有方法。
## 463. `cs.CV` - TennisTV：多模态大型语言模型理解网球对攻能否过关？ [PDF](https://arxiv.org/pdf/2509.15602), [HTML](https://arxiv.org/abs/2509.15602)
### Authors
Zhongyuan Bao,Lejun Zhang
### Background
多模态大型语言模型(MLLMs)在通用视频理解方面表现出色，但在像网球这样的快速高频率体育项目中却面临挑战，因为网球的回球片段虽然短但信息密度高。为了系统地评估MLLMs在这一挑战性领域中的表现，本文提出了TennisTV，作为首个且最全面的网球视频理解基准。该基准将每个回球视为按时间顺序排列的连续击球事件序列，通过自动化管道进行筛选和问题生成。
### Innovation
本文首次提出了TennisTV，作为首个全面的网球视频理解基准，覆盖回球和击球等级的8个任务，包含2500个人工验证的问题，系统地评估了16个代表性MLLMs在网球视频理解上的表现。研究表明帧采样密度需要根据不同任务进行调整，并且改进时间锚定对于提升推理能力至关重要。
### Conclusion
评估结果揭示了MLLMs在网球理解上的显著缺陷，并提出两个关键见解：（i）帧采样密度需要根据不同任务进行调整，（ii）改进时间锚定是提升推理能力的关键。
## 464. `cs.CV` - pFedSAM: Personalized Federated Learning of Segment Anything Model for Medical Image Segmentation [PDF](https://arxiv.org/pdf/2509.15638), [HTML](https://arxiv.org/abs/2509.15638)
### Authors
Tong Wang,Xingyue Zhao,Linghao Zhuang,Haoyu Zhao,Jiayi Yin,Yuyang He,Gang Yu,Bo Lin
### Background
医学图像分割对于计算机辅助诊断至关重要，但隐私限制阻碍了机构间的数据共享。联邦学习解决了这一限制，但现有的方法往往依赖于轻量级架构，这些架构难以应对复杂的、异构的数据。为了克服这些问题，最近的Segment Anything Model (SAM)展示了出色的分割能力，但在联邦设置中，其庞大的编码器带来了显著的挑战。因此，本研究首次提出了一种个性化的联邦学习SAM框架，适用于医学图像分割中的异构数据场景。这种方法加强了医学图像分割、跨域适应性，并减少了通信开销。
### Innovation
本研究的两个关键创新包括：(1) 个性化的策略，仅聚合全局参数以捕捉跨客户端的共同特征，同时保留 L-MoE（局部混合专家）组件以保留特定领域的特征；(2) 解耦的全局-局部微调机制，通过知识蒸馏引入教师-学生范式，弥合全局共享模型和个人化本地模型之间的差距，从而减少泛化现象。
### Conclusion
通过广泛的实验在两个公开数据集上验证，本方法显著提高了分割性能，实现了稳健的跨域适应，并减少了通信开销。
## 465. `cs.CV` - 布局笔画模拟：基于布局指导的笔画生成以实现扩散模型中的风格模拟 [PDF](https://arxiv.org/pdf/2509.15678), [HTML](https://arxiv.org/abs/2509.15678)
### Authors
Sidra Hanif,Longin Jan Latecki
### Background
手写笔画生成对于提高手写识别和作者识别等任务的表现至关重要。以往研究通过模仿样本文本中的书法特征进行风格模仿，但未将单词间距（布局）明确纳入其中，导致了样本间笔画间距的一致性问题。本研究旨在通过提出多尺度注意力特征及包含单词布局来改善风格模仿和笔画生成的效果。
### Innovation
1. 提出了多尺度注意力特征以突出局部和全局风格特征。2. 引入了单词布局，帮助改善笔画间距，提升了书法风格模仿的效果。3. 使用条件扩散模型预测笔画，弥补了直接生成风格图像方法的不足，增强了时间坐标的指导作用，从而实现了更好的书法风格模仿和笔画生成。
### Conclusion
所提出的扩散模型在笔画生成任务上优于现有最先进的模型，并且在与近期图像生成网络的对比中表现出较高的竞争力。
## 466. `cs.CV` - FingerSplat: 基于3D高斯点集的无接触指纹3D重建与生成 [PDF](https://arxiv.org/pdf/2509.15648), [HTML](https://arxiv.org/abs/2509.15648)
### Authors
Yuwei Jia,Yutang Lu,Zhe Cui,Fei Su
### Background
尽管无接触指纹识别的研究已经取得了许多先驱性的成果，但在性能上仍然不如接触式指纹识别方法，主要原因是缺乏包含姿态变化的无接触指纹数据以及未充分利用隐含的3D指纹表示。
### Innovation
本文提出了一个创新的无接触指纹3D注册、重建和生成框架，整合了3D高斯点集技术，旨在通过结合3D指纹重建和生成为无接触指纹识别提供一个新范式。这是首次将3D高斯点集应用于指纹识别领域，也是首次能够有效进行3D注册和无相机参数信息需求下完成无接触指纹的从稀疏输入图像的重建。
### Conclusion
在3D指纹注册、重建和生成实验中，证明了本方法能够准确对齐和重建3D指纹，从3D模型生成高质量的无接触指纹，从而提高无接触指纹识别的性能。
## 467. `cs.CV` - 视觉跳跃机制在细粒度视觉分类中的应用 [PDF](https://arxiv.org/pdf/2509.15688), [HTML](https://arxiv.org/abs/2509.15688)
### Authors
Johann Schmidt,Sebastian Stober,Joachim Denzler,Paul Bodesheim
### Background
细粒度视觉分类（FGVC）要求通过细微和局部的特征区分视觉上类似的不同类别，这因类别内部的高变异性及类别之间差异的局限性而变得具有挑战性。现有的基于部件的方法通常依赖于复杂的定位网络学习从像素到样本空间的映射，这虽然加深了对图像内容的理解，但也限制了特征对下游任务的实用性。此外，采样的点经常具有高的空间冗余度，使得确定所需部件数量的最优化变得困难。
### Innovation
基于人类视觉跳跃机制，本研究提出了一种两阶段的过程，首先提取边缘特征（粗视图）并生成样本图，从该图中并行采样并编码固定点使用共享权重的编码器。通过上下文选择性注意力来衡量每个固定点的影响，并融合边缘和焦点表示。为了防止部件方法中的空间坍塌，采样固定点时使用非极大值抑制消除冗余。
### Conclusion
本文在标准细粒度视觉分类基准（CUB-200-2011，NABirds，Food-101和Stanford-Dogs）和具有挑战性的昆虫数据集（EU-Moths，Ecuador-Moths和AMI-Moths）上进行了全面的评估，表明该方法在达到与最新技术相似性能的同时，可以稳定地超越基线编码器的表现。
## 468. `cs.CV` - 相机切片用于连续视图优化 [PDF](https://arxiv.org/pdf/2509.15677), [HTML](https://arxiv.org/abs/2509.15677)
### Authors
Gahye Lee,Hyomin Kim,Gwangjin Ju,Jooeun Son,Hyejeong Yoon,Seungyong Lee
### Background
传统的方法，如最远视图采样（FVS），在合成新型视角时，其性能有限，特别是在捕捉复杂的视图依赖现象和细微的纹理上表现不佳。因此，需要一种新的方法来优化视图，以提升对复杂视图依赖现象的捕捉能力，尤其是在金属反射和精细纹理方面.
### Innovation
提出了一种新的视图优化框架，称为相机切片（Camera Splatting）。每个相机被建模为3D高斯分布（称为相机切片），并在表面附近采样的3D点处放置虚拟相机（称为点相机），以观测相机切片的分布。通过连续可微分地细化相机切片，使得通过点相机观察到的目标分布被优化，从而模拟原始的3D高斯切片的方法.
### Conclusion
与最远视图采样（FVS）方法相比，经过优化的视图表现出了优越的性能，能够更有效地捕捉复杂的视图依赖现象，如强烈的金属反射和复杂的纹理，例如文字.
## 469. `cs.CV` - SGMAGNet：一种新型被动主动卫星基准上的三维云相结构重建的基础模型 [PDF](https://arxiv.org/pdf/2509.15706), [HTML](https://arxiv.org/abs/2509.15706)
### Authors
Chi Yang,Fu Wang,Xiaofei Yang,Hao Huang,Weijia Cao,Xiaowen Chu
### Background
云相结构对于数值天气预报（NWP）至关重要，因为它直接影响辐射传输和降水过程。这项研究利用高时空分辨率的多模式卫星观测数据，致力于开发精细化的三维云相结构，并期待未来将其与NWP系统结合，从而改善云微物理参数化。
### Innovation
研究提出了一种基准数据集和基础框架，以实现从多模式卫星观测资料中提取详细的三维云相结构。该研究采用SGMAGNet模型，并与几种基线架构进行比较，结果显示SGMAGNet在复杂多层和边界过渡区域的云相重建方面表现优越。
### Conclusion
SGMAGNet在云相重建任务上表现出色，具体指标如精确度、召回率、F1分数和交并比均超过所有基线模型。
## 470. `cs.CV` - GS-Scale: 通过主机卸载解锁大规模3D高斯点阵训练 [PDF](https://arxiv.org/pdf/2509.15645), [HTML](https://arxiv.org/abs/2509.15645)
### Authors
Donghyun Lee,Dawoon Jeong,Jae W. Lee,Hongil Yoon
### Background
3D高斯点阵渲染技术因其高视觉质量和快速渲染速度而革新了图形渲染领域。然而，要以高质量训练大规模场景仍然存在挑战，主要原因是需要存储大量参数、梯度和优化器状态，占用大量GPU内存。现有的方法难以应对这些内存需求，导致内存使用量迅速超出GPU的容量。
### Innovation
为了克服这一限制，我们提出了GS-Scale，这是一种快速且内存效率高的训练系统，专门用于3D高斯点阵，避免了对大规模场景进行高精度训练时的内存瓶颈。GS-Scale将所有高斯点存储在主机内存中，仅在每次前向和后向传递时根据需求将子集传输到GPU。该系统采用三项系统级优化措施：（1）几何参数的选择性卸载以迅速进行视锥剔除；（2）参数前向传输与GPU计算相结合的优化器更新；（3）延后优化器更新以减少不必要的高斯访问。这些优化使得在大规模数据集上验证时，GS-Scale显著降低了GPU内存需求（降低了3.3-5.6倍），同时仍能达到与没有主机卸载的GPU相当的训练速度。
### Conclusion
GS-Scale 使大规模3D高斯点阵训练在消费级GPU上成为可能。例如，GS-Scale可以在RTX 4070移动GPU上将高斯点的数量从400万增加到1800万，从而提高23-35%的LPIPS（学习感知图像块相似度）得分。
## 471. `cs.CV` - 综合Lie半群和级联结构的一般高斯导数模型在视觉感受野中的应用 [PDF](https://arxiv.org/pdf/2509.15748), [HTML](https://arxiv.org/abs/2509.15748)
### Authors
Tony Lindeberg
### Background
由于真实世界图像结构在自然图像变换下的差异，例如在不同视点下观察相似对象或时空事件时，早期视觉层次结构中的感受野响应可能受到这种几何图像变换的影响。处理这种变化的一种方法是基于协变感受野族，这些族能够在图像变换的自由度上扩展感受野的形状。
### Innovation
本文通过推导不同值下的空间和时空感受野响应之间的关系，提出了既有关于（i）微小关系，大致对应于半群和李群概念的组合，以及（ii）宏观级联平滑性质的推导，描述了如何通过更小支持的增量滤波器在更粗的时空尺度上计算感受野响应。
### Conclusion
本文的结果提供了一种更深入理解不同滤波器参数下的空间和时空感受野响应之间关系的方法，可用于（i）设计更高效的算法来计算多参数族感受野响应的响应，同时（ii）提出生物学视觉中简单细胞计算的理想化理论模型。
## 472. `cs.CV` - SCENEFORGE：通过结构化场景组合提升3D-文本对齐 [PDF](https://arxiv.org/pdf/2509.15693), [HTML](https://arxiv.org/abs/2509.15693)
### Authors
Cristian Sbrolli,Matteo Matteucci
### Background
背景描述了3D点云与文本之间的对比学习问题，以及这类数据集的稀缺性，影响了模型的性能和泛化能力。从前人的工作中得出，大型的3D-文本数据集的缺乏阻碍了该领域的发展，而缺乏多样性和复杂性的数据使得模型难以进行有效的学习和推理。因此，需要一种新的方法来丰富数据的复杂性和多样性，以解决这个问题。
### Innovation
创新点在于提出了一种名为SceneForge的新框架，它通过结构化的多对象场景组合增强了3D点云和文本之间的对比对齐。SceneForge利用单独的3D形状构建带有明确空间关系的多对象场景，并配以由大规模语言模型细化的连贯的多对象描述。通过在对比训练中增加结构化的组合样本，有效解决了大规模3D-文本数据集稀缺的问题，极大地增强了数据的复杂性和多样性。该框架系统地研究了关键设计元素，包括每个场景的目标数量，训练批次中的组合样本比例以及场景构建策略。实验结果表明，SceneForge在多种任务中提供了显著的性能提升，包括ModelNet、ScanObjNN、Objaverse-LVIS和ScanNet的零样本分类，以及ShapeNetPart的部分分割的少量样本分割。
### Conclusion
结论指出，SceneForge的组合增强是模型无关的，能够一致地提高多种编码器架构的性能。SceneForge在3D视觉问题回答、检索场景复杂性和空间推理能力方面也显示出优势，能够根据文本指令精确调整空间配置。总体来说，SceneForge提供了一种有效解决多模态学习中数据稀缺性和复杂性问题的新方法。
## 473. `cs.CV` - FloorSAM: 使用语义几何融合的SAM引导楼层平面图重建 [PDF](https://arxiv.org/pdf/2509.15750), [HTML](https://arxiv.org/abs/2509.15750)
### Authors
Han Ye,Haofu Wang,Yunchi Zhang,Jiangjian Xiao,Yuqiang Jin,Jinyuan Liu,Wen-An Zhang,Uladzislau Sychou,Alexander Tuzikov,Vladislav Sobolevskii,Valerii Zakharov,Boris Sokolov,Minglei Fu
### Background
从点云数据重建建筑物楼层平面图对于室内导航、建筑物信息管理系统（BIM）和精确测量至关重要。传统的几何算法和基于Mask R-CNN的深度学习方法存在噪声问题、泛化能力有限以及几何细节丢失等问题。
### Innovation
提出了一种名为FloorSAM的框架，结合了点云密度图与Segment Anything Model (SAM)，能够从LiDAR数据中准确地重建楼层平面图。通过网格过滤、自适应分辨率投影和图像增强生成了稳健的俯视密度图。FloorSAM 使用SAM的零样本学习进行精确的房间分割，从而改善了不同布局下的重建效果。借助自适应提示点和多阶段过滤生成房间掩码，随后进行联合掩码和点云分析以提取轮廓并进行正则化处理，从而生成准确的楼层平面图并恢复房间拓扑关系。
### Conclusion
在Giblayout和ISPRS数据集上的测试表明，与传统方法相比，FloorSAM在嘈杂和复杂的环境中具有更好的准确率、召回率和鲁棒性。
## 474. `cs.CV` - Enriched Feature Representation and Motion Prediction Module for MOSEv2 Track of 7th LSVOS Challenge: 3rd Place Solution [PDF](https://arxiv.org/pdf/2509.15781), [HTML](https://arxiv.org/abs/2509.15781)
### Authors
Chang Soo Lim,Joonyoung Moon,Donghyeon Cho
### Background
视频对象分割（VOS）是一项具有广泛应用的技术，包括视频编辑和自动驾驶。尽管Cutie提供基于查询的强分割能力，SAM2通过预训练的ViT编码器提供丰富的表示，但两者在特征容量和时间建模方面都有局限性。
### Innovation
本文提出了一种框架，通过用SAM2的ViT编码器替换Cutie的编码器，并引入一种运动预测模块以增强时间稳定性，从而集成了两者的优势。此外，还采用了将Cutie、SAM2和作者变体联合起来的集成策略，在第7届LSVOS挑战赛的MOSEv2赛道中获得了第3名。
### Conclusion
这个结果证明了丰富特征表示和运动预测模块对稳健视频对象分割的有效性。
## 475. `cs.CV` - MCOD: 多光谱伪装目标检测的第一个具有挑战性的基准数据集 [PDF](https://arxiv.org/pdf/2509.15753), [HTML](https://arxiv.org/abs/2509.15753)
### Authors
Yang Li,Tingfa Xu,Shuyan Bai,Peifu Liu,Jianan Li
### Background
伪装目标检测（COD）旨在识别与自然场景无缝融合的目标。尽管基于RGB的方法已经发展起来，但在挑战性条件下，它们的性能仍然有限。多光谱成像提供了丰富的光谱信息，为提高前景与背景辨识提供了前景。然而，现有的COD基准数据集仅限于RGB方法，缺乏对多光谱方法的支持，因此阻碍了该领域的进步。为解决这个问题，我们介绍了MCOD，这是第一个专门针对多光谱伪装目标检测的具有挑战性的基准数据集。MCOD具有三个主要优势：（i）全面的挑战属性：它捕捉了COD任务中常见的实际难题，如小物体大小和极端光照条件。（ii）多样的现实场景：数据集覆盖了广泛的自然环境，更好地反映了实际应用。（iii）高质量的像素级注释：每张图片都经过精确物体掩模和相应的挑战属性标签的手动标注。我们在MCOD上对标了十一个代表性的COD方法，观察到了由于任务难度增加而出现的持续性能下降。值得注意的是，整合多光谱模式显著缓解了这一退化，突显了光谱信息增强检测鲁棒性的价值。
### Innovation
MCOD是专门为多光谱伪装目标检测领域设计的第一个具有挑战性的基准数据集，包含全面的挑战属性、多样的现实场景和高质量的像素级注释。
### Conclusion
我们预期MCOD将为未来多光谱伪装目标检测的研究提供坚实的基础。数据集可以在这里获取：[这个链接](https://提供的链接/)。
## 476. `cs.CV` - TrueMoE：基于双路由混合辨别专家的合成图像检测 [PDF](https://arxiv.org/pdf/2509.15741), [HTML](https://arxiv.org/abs/2509.15741)
### Authors
Laixin Zhang,Shuaibo Li,Wei Ma,Hongbin Zha
### Background
生成模型的快速发展使合成图像检测成为一项越来越关键的任务。现有大多数方法试图构建单一的、通用的辨别空间来区分真实与虚假的内容，但这种统一的空问通常过于复杂且脆弱，难以泛化到未见过的生成模式中。
### Innovation
提出了一种名为TrueMoE的新颖双路由混合辨别专家框架。该框架将检测任务重新表述为在多个专门且轻量级的辨别子空间中的协作推理。核心在于组织成沿流形结构和感知粒度互补轴的辨别专家阵列（DEA），能够捕获不同伪造线索。双路由机制包括感知粒度意识稀疏路由器和流形意识密集路由器，能自适应地将输入图像分配给最相关的专家。实验结果表明，TrueMoE在多种生成模型上都实现了优越的泛化能力和鲁棒性。
### Conclusion
Extensive experiments across a wide spectrum of generative models demonstrate that TrueMoE achieves superior generalization and robustness.
## 477. `cs.CV` - ORIC: 基准评估大型视觉语言模型在不一致上下文中的物体识别 [PDF](https://arxiv.org/pdf/2509.15695), [HTML](https://arxiv.org/abs/2509.15695)
### Authors
Zhaoyang Li,Zhan Ling,Yuchen Zhou,Hao Su
### Background
大型视觉语言模型（LVLMs）已经在图像字幕、视觉问答以及机器人技术等领域取得了显著进展，通过整合视觉和文本信息。然而，它们在不一致的上下文中仍容易出现错误，即当物体在上下文中不应出现时却出现，或应在上下文中出现但并未出现。这种现象导致了两个主要的识别失败：物体误识别和幻觉。为了系统性地研究这一问题，本研究引入了ORIC（Object Recognition in Incongruous Context Benchmark），一个评估LVLMs在物体与上下文关系不符合预期的场景中的基准。ORIC 采用两种关键策略：（1）受大型语言模型（LLM）引导的采样，识别实际上存在但上下文性不符合预期的物体；（2）受CLIP（对比基础图像-文本预训练模型）引导的采样，检测有可能被幻觉的合理但不存在的物体，从而创建不一致的上下文。
### Innovation
本研究提出了ORIC，一个专门用于评估LVLMs在不一致上下文中的物体识别基准。ORIC 巧妙地结合了受大型语言模型和CLIP引导的采样策略，能够有效检测出物体的误识别和幻觉问题。同时，研究还评估了18种不同的LVLMs和两种开放词汇检测模型，揭示了LVLMs在处理上下文不一致性时存在的显著识别差距。
### Conclusion
本研究表明了LVLMs在处理不一致上下文时面临的识别挑战，并提供了关于LVLMs局限性的关键洞见。这项工作鼓励进一步研究上下文感知物体识别。
## 478. `cs.CV` - 医学深度伪造检测：一个综合数据集和新颖方法 [PDF](https://arxiv.org/pdf/2509.15711), [HTML](https://arxiv.org/abs/2509.15711)
### Authors
Shuaibo Li,Zhaohu Xing,Hongqiu Wang,Pengfei Hao,Xingyu Li,Zekai Liu,Lei Zhu
### Background
医学影像生成AI的快速发展带来了巨大的机会和严重的挑战，特别是合成医学图像可能破坏医疗保健系统的风险。合成图像会引发诊断误导、财务欺诈和信息误导等严重问题。然而，用于对抗这些威胁的医学法医研究仍相对有限，缺乏特定于该领域的全面数据集。现有的媒体法医方法主要针对自然或面部图像，对于捕捉AI生成的医学图像的独特特征和细微痕迹并不足够。
### Innovation
本研究引入了MedForensics大规模医学法医数据集，包含六种医学模态和十二种最先进的医学生成模型。还提出了DSKI，这是一种双重阶段知识注入检测器，构建了适应医学图像检测的视图语言特征空间。DSKI包括两个核心部分：1）跨领域微跟踪适配器（CDFA）用于训练期间从空间和噪声领域提取细微伪造线索，2）医学法医检索模块（MFRM）用于测试时通过少样本检索提升检测准确率。实验结果表明，DSKI在多医学模态的准确率上显著优于现有方法和人类专家。
### Conclusion
通过MedForensics数据集和DSKI方法，显著提高了AI生成的医学图像检测的准确率，为未来的医学法医研究提供了坚实的基础。
## 479. `cs.CV` - 模拟皮层放大规模支持无监督物体学习 [PDF](https://arxiv.org/pdf/2509.15751), [HTML](https://arxiv.org/abs/2509.15751)
### Authors
Zhengyang Yu,Arthur Aubret,Chen Yu,Jochen Triesch
### Background
最近的自监督学习模型通过在类似幼儿视觉经验的数据上进行训练，模拟了语义物体表示的发展，但这些模型忽视了人类视觉在视场中心和边缘的高/低分辨率特性。我们研究了这种变化的分辨率在物体表示发展中的作用。为此，我们利用了两个第一人称视角视频数据集，这些视频记录了人类在与物体相互作用时的视觉体验。我们应用了人类的视标化模型和皮层放大模型来修改这些输入，使视场边缘的内容变得越来越不清晰。
### Innovation
利用两个第一人称视角视频数据集，并结合人类的视标化模型和皮层放大模型来修改输入，使得边缘内容变得不清晰，由此训练了两种生物启发式的自监督学习模型，实现了基于时间的学习目标。结果显示，模拟视标化视觉特征可以提高在此场景中学习的物体表示的质量。进一步分析表明，这种改进来自于使物体在视觉上显得更大，并且在中央和边缘视觉信息之间达成更好的权衡。
### Conclusion
本研究在使人类视觉表示学习的模型更加现实和高效方面向前迈进了一步。
## 480. `cs.CV` - 面向区域、令牌及指令引导重要性的训练-free 分层令牌剪枝方法以提升大型视觉-语言模型的效率 [PDF](https://arxiv.org/pdf/2509.15704), [HTML](https://arxiv.org/abs/2509.15704)
### Authors
Yuxuan Liang,Xu Li,Xiaolei Chen,Yi Zheng,Haotian Chen,Bin Li,Xiangyang Xue
### Background
大视角-语言模型（LVLMs）在多模态理解方面取得了显著进步，但仍难以高效处理高分辨率图像。当前方法将高分辨率图像分段为多个子图像，导致视觉令牌数量激增，在推理时引发指数级的计算开销。
### Innovation
提出了一种无需训练的分层令牌剪枝策略——分层令牌剪枝（PTP）。该策略结合了自下而上的基于区域和令牌级别的视觉显著性和自上而下的指令引导的重要性。受人类视觉注意力机制的启发，PTP 选择性地保留来自视觉显著区域的更多令牌，并进一步利用文本指令以特定多模态任务为核心重点提取最相关的令牌。
### Conclusion
在13个不同基准上的大量实验表明，本方法在极小的性能损失下，显著降低计算开销和推理延迟。
## 481. `cs.CV` - 理想中的图像配准？只需分割便可实现 [PDF](https://arxiv.org/pdf/2509.15784), [HTML](https://arxiv.org/abs/2509.15784)
### Authors
Xiang Chen,Fengting Zhang,Qinghao Liu,Min Liu,Kun Wu,Yaonan Wang,Hang Zhang
### Background
深度学习通过其处理多样任务的能力和显著的速度优势，已经革新了图像配准领域。然而，当前的方法往往采用全局一致的平滑约束，无法适应解剖学运动中的复杂、区域性变化的变形。
### Innovation
本文提出了一种名为SegReg的分割驱动配准框架，通过利用区域特定的变形模式实现解剖学适配的正则化，从而克服全局平滑约束的局限性。SegReg首先将输入的移动和固定图像分解为解剖学连贯的子区域，再通过相同的配准后台计算优化局部变形场，并整合至全局变形场。SegReg在使用真实分割数据时取得了近乎完美的结构对齐（关键解剖部位的Dice值为98.23%），并在心脏、腹部和肺部图像的三种临床配准场景中，即使使用自动分割也优于现有方法2-12%。SegReg的配准精度与分割质量几乎呈线性关系，将配准挑战转化为分割问题
### Conclusion
SegReg通过分割驱动的方法，实现了对复杂、动态解剖变形的高精度配准，标志着图像配准领域的一大进步。
## 482. `cs.CV` - Vision-Language Models as Differentiable Semantic and Spatial Rewards for Text-to-3D Generation [PDF](https://arxiv.org/pdf/2509.15772), [HTML](https://arxiv.org/abs/2509.15772)
### Authors
Weimin Bai,Yubo Li,Weijian Luo,Wenzheng Chen,He Sun
### Background
Score Distillation Sampling (SDS)通过监督多视角2D渲染来生成高质量的文本到3D内容，使用预训练的文本到图像扩散模型与输入提示对齐，以确保3D一致性。但现有SDS方法存在两个根本性限制：（1）依赖CLIP样式文本编码器导致粗略的语义对齐，并难以处理精细的提示；（2）2D扩散先验缺乏明确的3D空间约束，导致几何不一致性和多对象场景中不准确的对象关系。这些限制导致了现有方法在语义准确性、几何一致性和空间准确性方面表现不佳。
### Innovation
本文提出了VLM3D框架，将大型视觉-语言模型（VLMs）集成到SDS管道中，作为可微语义和空间先验。VLMs利用丰富的语言相关监督，实现细致入微的提示对齐；其固有的视觉语言建模能力提供了强大的空间理解，明显提高了单个对象生成中的3D一致性，并改善了多对象场景中的因果关系推理。
### Conclusion
本文基于开源Qwen2.5-VL模型实例化了VLM3D，并在GPTeval3D基准上进行评估。实验结果显示，与之前的SDS方法相比，VLM3D在语义保真度、几何连贯性和空间正确性方面表现显著优越。
## 483. `cs.CV` - PlantCLEF 2024植物识别竞赛概览：植被样方图像中的多物种植物识别 [PDF](https://arxiv.org/pdf/2509.15768), [HTML](https://arxiv.org/abs/2509.15768)
### Authors
Herve Goeau,Vincent Espitalier,Pierre Bonnet,Alexis Joly
### Background
样方图像对于生态学研究至关重要，它们能实现标准化取样、生物多样性评估、长期监测和远程大规模调查。样方通常为50厘米见方或1平方米，植物学家精确定义样方内的所有物种。人工智能（AI）的集成能够显著提高专家的工作效率，扩展生态学研究的范围和覆盖面。为此，PlantCLEF 2024挑战赛利用专家标注的数千张多标签图像作为测试集，涵盖800多种植物。同时，还提供了170万张单个植物图像的大规模训练集以及预训练的最先进的视觉变换模型。任务被评价为带弱标签的多标签分类任务，目标是在使用单标签训练数据的情况下预测高分辨率样方图像中存在的所有植物物种。
### Innovation
PlantCLEF 2024挑战赛在生态学图像识别领域引入了一个新的测试集，包含数千张多标签图像，并提供了大规模的训练数据集和先进模型，旨在通过AI技术显著提高生态学家的工作效率，扩展生态研究的范围和覆盖面。任务被定义为一个带弱标签的多标签分类任务，要求预测样方图像中出现的所有植物物种。
### Conclusion
本文详细描述了数据集、评价方法、参赛者使用的方法和模型以及所取得的结果。这场挑战赛的开展对于推动生态学图像识别技术和方法的发展具有重要意义。
## 484. `cs.CV` - 知识迁移提升主动学习 [PDF](https://arxiv.org/pdf/2509.15805), [HTML](https://arxiv.org/abs/2509.15805)
### Authors
Tianyang Wang,Xi Xiao,Gaofei Chen,Xiaoying Liao,Guo Cheng,Yingrui Ji
### Background
不确定性估计是主动学习的核心。现有方法主要依赖复杂辅助模型和高级训练方式来为未标记数据估计不确定性。然而，这些方法需要特殊的模型设计，并且尤其是在如计算生物学中的冷冻电子显微断层扫描（cryo-ET）分类等特定领域任务中，难以训练。
### Innovation
提出了一种新的方法，使用知识迁移来提升主动学习中的不确定性估计。具体而言，开发了教师-学生模式，其中教师是主动学习任务模型，学生是一个辅助模型，从教师学习。两个模型在每个主动学习循环中同时训练，通过测量模型输出之间的特定距离来估计未标记数据的不确定性。学生模型是任务无关的，并不需要特殊的训练方式（如对抗），使我们的方法适用于多种任务。此外，还证明了数据不确定性与其任务损失的具体值无关，而是与其上界紧密相关。
### Conclusion
通过广泛的实验验证了所提方法在经典计算机视觉任务和cryo-ET挑战中的有效性和高效性。
## 485. `cs.CV` - CBPNet: 一种用于边缘设备减轻塑性损失的持续反向传播提示网络 [PDF](https://arxiv.org/pdf/2509.15785), [HTML](https://arxiv.org/abs/2509.15785)
### Authors
Runjie Shao,Boyu Diao,Zijia An,Ruiqi Liu,Yongjun Xu
### Background
为了满足类似机器人和自主驾驶这样的应用对动态环境的实时响应需求，适用于边缘设备的高效持续学习方法受到了越来越多的关注。在这一过渡期，使用冻结的预训练模型并伴有提示已经成为对抗灾难性遗忘的主流策略。然而，这种方法引入了一个新的关键瓶颈：塑性损失，模型的学习新知识的能力会由于冻结的主干和提示参数的有限容量而减退。我们主张，塑性的减少源于训练过程中未被充分利用参数的更新活力不足。
### Innovation
为此，我们提出了持续反向传播提示网络（CBPNet），这是一种高效且参数有效框架，旨在恢复模型的学习活力。我们创新性地整合了一个高效CBP块，通过自适应重新初始化这些未被充分利用的参数来对抗塑性衰退。在边缘设备上的实验结果表明，CBPNet在多个基准测试中具有有效性。在Split CIFAR-100上，它提高了平均准确性超过1%，而针对更具挑战性的Split ImageNet-R，它实现了一种最先进的准确率为69.41%。这一成果是通过对构成不到0.2%主干大小的额外参数进行训练来实现的，验证了我们的方法的有效性。
### Conclusion
实验结果证明了CBPNet在多个基准测试中的有效性，尤其是在Split CIFAR-100上平均准确性提高超过1%，在更具有挑战性的Split ImageNet-R上实现了最先进的69.41%准确率，这些成果通过训练不到主干大小0.2%的额外参数来实现，验证了我们提出的方法的有效性。
## 486. `cs.CV` - 零样本3D高斯体中的视图检索视觉定位 [PDF](https://arxiv.org/pdf/2509.15871), [HTML](https://arxiv.org/abs/2509.15871)
### Authors
Liwei Liao,Xufeng Li,Xiaoyun Zheng,Boning Liu,Feng Gao,Ronggang Wang
### Background
3D视觉定位（3DVG）旨在基于文本提示在3D场景中定位物体，这对机器人技术等应用至关重要。然而，现有的3DVG方法面临着两大挑战：首先，它们难以处理3D高斯体绘制（3DGS）中的空间纹理的隐式表示，因此需要针对每个场景进行训练；其次，它们通常需要大量的标记数据进行有效训练。
### Innovation
本文提出了一种名为GVR（Grounding via View Retrieval）的新型零样本视图检索视觉定位框架，将3DVG转换为一个2D检索任务。这一框架利用基于视图检索的对象级检索收集多视角的定位线索，不仅避免了昂贵的3D标注过程，而且还消除了每个场景的训练需求。实验结果表明，该方法在不进行每个场景训练的情况下达到了最先进的视觉定位性能，为零样本3DVG研究奠定了坚实的基础。
### Conclusion
我们的方法在不进行每个场景的训练的情况下达到了最先进的视觉定位性能，为零样本3DVG研究奠定了坚实的基础，相关视频演示可以在指定的链接中找到。
## 487. `cs.CV` - ChronoForge-RL: 通过强化学习进行有条理锻造以增强视频理解 [PDF](https://arxiv.org/pdf/2509.15800), [HTML](https://arxiv.org/abs/2509.15800)
### Authors
Kehua Chen
### Background
当前最先进的视频理解方法在处理密集视频内容时面临两大挑战：（1）计算上难以处理每一帧，（2）通过简单的均匀采样策略难以识别具有语义意义的帧。现有方法在这些方面表现不佳，限制了其广泛应用和效果提升。因此，本文旨在解决这些问题，提出了一种新颖的视频理解框架，ChronoForge-RL。
### Innovation
本文创新性地结合了Temporal Apex Distillation (TAD) 和 KeyFrame-aware Group Relative Policy Optimization (KF-GRPO)，通过一个不同可微的关键帧选择机制系统地识别语义转折点，同时提高了计算效率，保留了时间信息。此外，TAD利用变异性评分、转折检测和优先去芜存菁的机制来选择最有信息量的帧；而KF-GRPO则采用增强奖励机制的对比学习框架，显式激励模型利用帧内容和时间关系。
### Conclusion
本文提出的ChronoForge-RL模型在VideoMME和LVBench上的性能分别为69.1%和52.7%，明显优于基线方法，且7B参数量模型的性能足以媲美72B参数量的模型，显示出强大且高效的性能。
## 488. `cs.CV` - CIDER: 一种消除重视品牌的文本到图像模型的因果疗法 [PDF](https://arxiv.org/pdf/2509.15803), [HTML](https://arxiv.org/abs/2509.15803)
### Authors
Fangjian Shen,Zifeng Liang,Chao Wang,Wushao Wen
### Background
文本到图像（T2I）模型在生成图像时表现出一种显著但未充分研究的‘品牌偏见’，即从通用提示中生成具有主导商业品牌的图形内容，这种现象存在道德和法律风险。目前缺乏有效的缓解方法，通常需要重新训练模型来解决这一问题，成本较高。因此，需要一个无需重新训练模型即可减轻偏见的解决方案，以改进图像质量和美学吸引力，同时保持更原创和公平的内容生成。
### Innovation
CIDER提出了一种新颖的、模型无关的框架，在推理时通过提示细化来减轻偏见，而无需重新训练模型。该框架使用轻量级检测器识别品牌内容，结合视觉语言模型（VLM）生成风格上不同的替代品。还引入了品牌中立评分（BNS）来量化这一问题。实验结果显示，CIDER显著降低了显性和隐性的偏见，同时保持了图像质量和美学吸引力。这项工作提供了一个实用的解决方案，以促进更具原创性和公平性的内容，有助于生成可信的AI的发展。
### Conclusion
CIDER通过减轻T2I模型的‘品牌偏见’，提出了一种轻量有效的解决方案，能够在保持图像质量和美学吸引力的同时，生成更具有原创性和公平性的内容。这种框架对于促进生成型AI的信任和可靠性具有重要意义。
## 489. `cs.CV` - RACap: 关注关系的轻量级检索增强图像描述中的提示 [PDF](https://arxiv.org/pdf/2509.15883), [HTML](https://arxiv.org/abs/2509.15883)
### Authors
Xiaosheng Long,Hanyu Wang,Zhentao Song,Kun Luo,Hongde Liu
### Background
近期的检索增强图像描述方法通过引入外部知识来弥补处理复杂场景时的感知能力限制。然而，现有的方法在关系建模上面临挑战：(1) 语义提示的表示过于粗略，无法捕捉细粒度的关系；(2) 这些方法缺乏对图像对象及其语义关系的明确建模。
### Innovation
本文提出了一种关系感知的检索增强图像描述模型RACap，该模型不仅从检索描述中挖掘结构化的语义关系，还能够识别图像中的异构对象。RACap通过检索包含异构视觉信息的结构化关系特征来增强语义一致性和关系表达性。
### Conclusion
实验结果表明，RACap仅使用10.8百万可训练参数，相比之前的轻量级描述模型表现更优。
## 490. `cs.CV` - FoBa: 前景-背景共引导方法及遥感语义变化检测新基准 [PDF](https://arxiv.org/pdf/2509.15788), [HTML](https://arxiv.org/abs/2509.15788)
### Authors
Haotian Zhang,Han Guo,Keyan Chen,Hao Chen,Zhengxia Zou,Zhenwei Shi
### Background
尽管在遥感语义变化检测（SCD）领域取得了显著进展，仍然存在两大挑战。数据层面，现有SCD数据集存在变化类别有限、变化类型不足以及缺乏细粒度类别定义的问题，难以满足实际应用需求。方法学层面，当前大多数方法未能充分利用变化信息，通常将其作为增强空间一致性的后处理步骤，这限制了模型性能的进一步提升。因此，构建一个更为合适的数据集和改进的方法对于推进SCD领域的研究至关重要。本研究构建了针对北京区域的新基准数据集LevirSCD，该数据集包括16个变化类别和210个具体变化类型，并提供了更为细粒度的类别定义。同时，提出了一种前景-背景共引导SCD（FoBa）方法，利用前景强调感兴趣区域和背景提供上下文信息来共同引导模型，从而缓解语义模糊性并提升检测细微变化的能力。针对时空交互和空间一致性需求，在模型中引入了门控交互融合（GIF）模块和简化的一致性损失函数，进一步提高检测性能。
### Innovation
本研究创新性地提出了前景-背景共引导遥感语义变化检测方法（FoBa），并构建了LevirSCD数据集。FoBa方法利用前景和背景信息协作引导模型，增强对细微变化的检测能力。此外，引入了门控交互融合模块（GIF）和简化的一致性损失函数，进一步提升模型性能
### Conclusion
在三个数据集（SECOND、JL1和LevirSCD）上进行的广泛实验表明，FoBa方法在SeK度量方面分别比当前最先进的方法提高了1.48%、3.61%和2.81%，验证了该方法的有效性。
## 491. `cs.CV` - ENSAM：用于3D医学图像交互式分割的高效基础模型 [PDF](https://arxiv.org/pdf/2509.15874), [HTML](https://arxiv.org/abs/2509.15874)
### Authors
Elias Stenhede,Agnar Martin Bjørnstad,Arian Ranjbar
### Background
该论文介绍了一种轻量级且可提示的模型——ENSAM（Equivariant, Normalized, Segment Anything Model），用于通用3D医学图像分割。ENSAM结合了SegResNet为基础的编码器、提示编码器和掩码解码器，结构上采用了类似于UNet的模式，使用了潜在交叉注意力、相对位置编码、归一化注意力和Muon优化器进行训练。这种设计旨在在有限的数据和计算预算下取得良好的性能。
### Innovation
ENSAM在数据和计算资源有限的情况下，通过创新的设计方法（如相对位置编码和Muon优化器）实现了高效的3D医学图像分割。它从单一32 GB GPU上训练了不到5,000个来自多种模态（CT、MRI、PET、超声、显微镜）的体积数据集，仅用了6小时。经过评估，ENSAM在多个性能指标上超过了两个先前发表的基线模型，并与另一个模型表现相当。
### Conclusion
实验结果表明，ENSAM模型在多个性能指标上具有竞争力，并且在删除预先训练权重的方法中表现最佳，尤其是在核心集轨道中排名第五。消融研究表明，相对位置编码和Muon优化器的使用可以显著加快收敛速度并提高分割质量。
## 492. `cs.CV` - 自监督跨模态学习在图像到点云注册中的应用 [PDF](https://arxiv.org/pdf/2509.15882), [HTML](https://arxiv.org/abs/2509.15882)
### Authors
Xingmei Wang,Xiaoyu Hu,Chengkai Huang,Ziyan Zeng,Guohao Nie,Quan Z. Sheng,Lina Yao
### Background
自主系统中的2D和3D传感器模态融合对于稳健感知至关重要。然而，由于纹理丰富但深度含糊的图像和稀疏但度量精确的点云之间的语义-几何差距，以及现有方法容易收敛于局部最优点，图像到点云（I2P）注册仍然具有挑战性。
### Innovation
我们引入了CrossI2P，一种自监督框架，统一了跨模态学习和两阶段注册在一个端到端的管道中。首先，通过双路径对比学习学习几何-语义融合嵌入空间，实现2D纹理和3D结构的无标注双向对齐。其次，采用从粗到细的注册范式：全局阶段通过联合同模态上下文和跨模态交互建模建立超像素-超点对应关系，然后进行几何约束的点级细化以实现精确注册。第三，采用动态训练机制并结合梯度规范化，以平衡特征对齐、对应关系细化和姿态估计的损失。
### Conclusion
广泛的实验表明，CrossI2P在KITTI里程计基准和nuScenes上分别比最先进的方法提高了23.7%和37.9%，显著提高了准确性和鲁棒性。
## 493. `cs.CV` - PAN: 基于柱体注意力网络的3D物体检测 [PDF](https://arxiv.org/pdf/2509.15935), [HTML](https://arxiv.org/abs/2509.15935)
### Authors
Ruan Bispo,Dane Mitrev,Letizia Mariotti,Clément Botty,Denver Humphrey,Anthony Scanlan,Ciarán Eising
### Background
摄像机-雷达融合在实时恶劣天气和光照条件下进行3D物体检测任务中提供了一种稳健且低成本的替代方案，相比之下，摄像机-激光雷达融合较为常用。然而，当前文献中很少有针对这一模式的研究，特别是开发能够充分利用雷达点云优点（如精确的距离估计和速度信息）的新架构。因此，本研究提出了一种利用摄像机和雷达在鸟瞰视角下进行3D物体检测的新颖且高效的算法。
### Innovation
引入了一种新的骨干网络，将雷达柱状特征映射到嵌入维度，并采用自注意力机制来建模雷达点之间的依赖关系。为了减少推理时间，该研究使用简化卷积层代替基于FPN的卷积层。实验结果表明，该方法达到了新的3D物体检测问题状态最先进技术NDS评价指标58.2，同时在nuScenes数据集上达到了新的推理时间基准。
### Conclusion
该研究提出了一种新的3D物体检测算法PAN，通过自注意力机制和简化卷积层的使用，实现了在ResNet-50网络下的前沿检测性能和优秀的推理时间表现。
## 494. `cs.CV` - 最小语义充分性与无监督域泛化相结合 [PDF](https://arxiv.org/pdf/2509.15791), [HTML](https://arxiv.org/abs/2509.15791)
### Authors
Tan Pan,Kaiyu Guo,Dongli Xu,Zhaorui Tan,Chen Jiang,Deshu Chen,Xin Guo,Brian C. Lovell,Limei Han,Yuan Cheng,Mahsa Baktashmotlagh
### Background
深度学习在监督场景中已经广泛研究其泛化能力，但在无监督场景中研究较少。无监督域泛化（UDG）任务旨在提高使用广泛使用的无监督学习技术，如自我监督学习（SSL）训练的模型的泛化能力。UDG面临的是在缺乏类别标签的情况下区分语义与变化的挑战。虽然近年来一些方法通过使用领域标签解决了部分问题，但在实际环境中这些标签往往不可用。本研究旨在通过形式化UDG任务来解决这些问题，学习最小充分语义表示：该表示(i)保留跨越增强视图的所有语义信息（充分性）；(ii)最大限度地减少与语义无关的信息（最小性）。
### Innovation
通过最小充分语义表示（Minimal Sufficient Semantic Representation）来解决UDG问题，引入了可学习模型Minimal-Sufficient UDG (MS-UDG)，通过InfoNCE目标函数实现充分性；通过语义变异解耦损失和基于重建机制的互补组件促进最小性。理论与实践结合，证明优化充分性与最小性可以减少域外风险，实验结果表明MS-UDG在无监督域泛化基准测试中达到新的最佳状态，超越现有SSL和UDG方法，而无需在表示学习过程中使用类别或领域标签。
### Conclusion
该研究通过理论分析和实际验证，展示了MS-UDG模型在解决无监督域泛化中保持语义完整性和去除无关信息方面的能力，提供了新的方法来处理缺乏类别标签的情况，显著提高了模型的泛化能力。
## 495. `cs.CV` - 稀疏多视图开放词汇3D检测 [PDF](https://arxiv.org/pdf/2509.15924), [HTML](https://arxiv.org/abs/2509.15924)
### Authors
Olivier Moliner,Viktor Larsson,Kalle Åström
### Background
理解和解释三维场景的能力对于许多视觉和机器人系统至关重要。传统的方法是通过训练来检测固定的一组类别，这种限制使其用处受限。在本文中，作者探讨了在只有有限点RGB图像可用的稀疏视图设置中，开放词汇的3D物体检测的挑战和可行性。
### Innovation
该研究提出了一种无需训练的解决方案，利用预先训练好的2D基础模型，而不是使用计算密集型的3D特征融合或需要特定于3D的学习。通过提升2D检测结果，并直接优化3D提议以实现跨视图的特征度量一致性，能够在与大量2D数据相比相对较少的3D数据情况下充分利用数据。在标准基准测试中，该简单管道建立了强大的基线，性能与最先进的技术在密集采样场景中相当，但在稀疏视图设置中显著超越。
### Conclusion
该研究不仅通过不依赖3D特征融合和特定于3D的学习来降低成本和复杂度，还通过跨视图的2D检测结果提升了3D提案的准确性，为稀疏视图条件下的3D物体检测提供了一种有效的方法，展示了其在稀疏视图设置中的优越性与竞争力。
## 496. `cs.CV` - TASAM: 一种适应地形和时间尺度的分割任何模型用于遥感分割 [PDF](https://arxiv.org/pdf/2509.15795), [HTML](https://arxiv.org/abs/2509.15795)
### Authors
Tianyang Wang,Xi Xiao,Gaofei Chen,Hanzhang Chi,Qi Zhang,Guo Cheng,Yingrui Ji
### Background
段 Anything 模型 (SAM) 拥有在自然图像中展示出令人印象深刻的零样本分割能力，但在应对遥感数据的独特挑战如复杂地形、多尺度目标及时间动态方面表现不佳。
### Innovation
本文介绍了TASAM，这是一款针对高分辨率遥感图像分割的地形和时间感知扩展版SAM。TASAM集成了三个轻量而有效的模块：一个地形感知适配器、一个时间提示生成器和一种多尺度融合策略，从而在不重新训练SAM主干的情况下，提升性能，并在三个遥感基准测试（LoveDA、iSAID和WHU-CD）中表现出色，超越了零样本SAM和其他任务特定模型，且计算成本较低。
### Conclusion
我们的研究成果突显了基础模型领域适应增强的价值，并为更稳健的地理空间分割提供了可扩展的道路。
## 497. `cs.CV` - 基于注意力调谐的全局调控与激发在立体匹配中的应用 [PDF](https://arxiv.org/pdf/2509.15891), [HTML](https://arxiv.org/abs/2509.15891)
### Authors
Jiahao Li,Xinhong Chen,Zhengmin Jiang,Qian Zhou,Yung-Hui Li,Jianping Wang
### Background
立体匹配通过迭代算法如RAFT-Stereo和IGEV-Stereo取得了显著进展，但在遮挡、纹理单一或重复模式的不明区域表现不佳，原因在于缺乏全局上下文和几何信息进行有效的迭代精炼。
### Innovation
提出了基于注意力调谐的全局调控与激发（GREAT）框架，包括空间注意力（SA）、匹配注意力（MA）和体素注意力（VA）三种注意力模块。SA与VA和MA协同工作，构建了一个基于全局上下文和几何细节的更加稳健的成本体积。
### Conclusion
在多种代表性迭代立体匹配方法中集成GREAT框架并进行广泛实验后，框架在挑战性的不明区域表现出优越性能。应用于IGEV-Stereo方法时，GREAT-IGEV在Scene Flow、KITTI 2015、ETH3D排行榜上均排名第一，在Middlebury基准测试中位列第二。源代码已公开。
## 498. `cs.CV` - LC-SLab ——一种基于对象的遥感图像和稀疏地面数据标注的大规模土地覆盖分类深度学习框架 [PDF](https://arxiv.org/pdf/2509.15868), [HTML](https://arxiv.org/abs/2509.15868)
### Authors
Johannes Leonhardt,Juergen Gall,Ribana Roscher
### Background
大规模土地覆盖图对于地球科学应用至关重要，现有的基于深度学习的土地覆盖图生成方法依赖于手工标注的数据集，但这些数据集的稀疏分布造成了空间覆盖不足的问题，导致预测结果碎片化和嘈杂。一种有希望的方法是基于对象的分类，它可以将标签分配给语义一致的图像区域，而不仅仅是像素级的标签，这种方法限制了最小地图单元。然而，这类方法在现有基于深度学习的土地覆盖分类流水线中的应用仍然很少，尤其是在中分辨率图像和稀疏监督的背景下。
### Innovation
本文提出了一种新的深度学习框架LC-SLab，旨在系统性地研究在稀疏监督条件下的基于对象的深度学习方法在大规模土地覆盖分类中的应用。LC-SLab支持输入级聚合通过图形神经网络，以及通过后处理现有语义分割模型的结果进行输出级聚合。此外，框架还利用了大规模预训练网络的特征以改善小数据集的表现。研究结果表明，基于对象的方法在精度上可以与常见像素级模型相媲美，且生成的地图更为连贯。输入级聚合在小数据集上表现更稳健，而输出级聚合则在大数据集上表现最佳。研究还发现，一些LC-SLab的配置方案优于现有土地覆盖产品，突显了该框架的实际应用价值。
### Conclusion
本研究提出了一种新的深度学习框架LC-SLab，该框架能够应对稀疏监督情况下基于对象的土地覆盖分类问题。实验结果证明了基于对象的分类方法在提高土地覆盖图的准确性和连贯性方面具有潜力。该框架在小数据集上的表现更加稳健，有助于推动稀疏监督环境中基于对象的深度学习方法的发展。
## 499. `cs.CV` - CoPAD: 在V2X场景中基于锚导向解码的多源轨迹融合与协同轨迹预测 [PDF](https://arxiv.org/pdf/2509.15984), [HTML](https://arxiv.org/abs/2509.15984)
### Authors
Kangyu Wu,Jiaqi Qiao,Ya Zhang
### Background
近年来，基于数据的轨迹预测方法取得了显著成果，大幅度推动了自动驾驶的发展。但是，单一车辆感知的不稳定性限制了轨迹预测的效果。
### Innovation
提出了一种名为CoPAD的新型轻量级协同轨迹预测框架。该框架包括基于匈牙利算法和卡尔曼滤波的融合模块、历史轨迹时间注意力模块（PTA）、模式注意力模块以及基于稀疏锚的解码器（AoD）。该框架通过早期融合来自车辆和道路基础设施的多源轨迹数据，有效提高了轨迹的完整性和准确性。PTA模块能够高效地捕获历史轨迹间的潜在交互信息，模式注意力模块增强了预测的多样性，基于稀疏锚的解码器生成最终完整的轨迹。
### Conclusion
在DAIR-V2X-Seq数据集上进行了大量实验，结果表明CoPAD达到了最先进的性能，验证了该模型在V2X场景下的协同轨迹预测的有效性。
## 500. `cs.CV` - 多原型监督下的稳健视觉连续学习 [PDF](https://arxiv.org/pdf/2509.16011), [HTML](https://arxiv.org/abs/2509.16011)
### Authors
Xiwei Liu,Yulong Li,Yichen Li,Xinlin Zhuang,Haolin Yang,Huifa Li,Imran Razzak
### Background
现有的视觉持续学习（视觉CL）范式中，语言引导的监督利用预训练语言模型（PLM）的冻结语义目标，显示出极大的潜力。然而，依赖单一目标会导致两个关键问题：一是语义模糊，多义类别名称导致视觉表征冲突；二是类内视觉多样性，单一原型无法捕捉类中丰富的视觉外观变化。
### Innovation
本文提出了一种名为MuproCL的新框架，它用多个上下文感知的原型来替换单一目标。具体而言，通过使用轻量级的LLM代理进行类别消歧和视觉模态扩展以生成鲁棒的语义原型。LogSumExp聚合机制使得视觉模型能够根据给定图像自适应地与最相关的原型对齐。
### Conclusion
在各种持续学习基线上的广泛实验表明，MuproCL能够一致地提高性能和鲁棒性，为语言指导的持续学习提供了更有效的路径。
## 501. `cs.CV` - DAFTED：解耦异构融合的心电图和表格数据在心脏肥厚诊断中的应用 [PDF](https://arxiv.org/pdf/2509.15990), [HTML](https://arxiv.org/abs/2509.15990)
### Authors
Jérémie Stym-Popper,Nathan Painchaud,Clément Rambour,Pierre-Yves Courand,Nicolas Thome,Olivier Bernard
### Background
多模态数据融合在医疗应用中是提高诊断的关键方法。本文在分析了一个包含239位患者的心脏超声时间序列和表格记录的数据集后，验证了提出的解耦异构融合策略的有效性，通过分离共享和模态特定的信息，从主要模态开始集成次要模态，实现了AUC值超过90%的优异结果，这是临床应用中的一项重要基准。
### Innovation
本文提出了一种从主要模态开始的解耦异构融合策略，通过分离共享和模态特定的信息来集成次要模态，这种方法在心脏肥厚诊断的数据集上优于现有方法，显著提高了诊断性能。
### Conclusion
通过解耦异构融合策略，本文提出的方法在心脏超声和表格数据融合用于心脏肥厚诊断方面有了显著改进，展示了在临床实际应用中的重要性。
## 502. `cs.CV` - Deep Feedback Models [PDF](https://arxiv.org/pdf/2509.15905), [HTML](https://arxiv.org/abs/2509.15905)
### Authors
David Calhas,Arlindo L. Oliveira
### Background
DFMs是一种新的有状态神经网络类别，结合了底层输入和时间上的高层表示。这种反馈机制为静态架构引入了动态性，使DFMs能够逐步优化其内部状态，模仿生物决策机制。研究通过在递归神经网络中建模这一过程，并通过指数衰减进行稳定化以确保收敛性，来评估其有效性。实验表明，在不同条件下，DFMs在噪声抵抗性和有限数据上的泛化能力优于传统的前向传播模型，特别是在低数据或高噪声环境中。此外，研究还表明，DFMs也可以应用于医学成像领域，并且具有对不同噪声类型的抵抗能力。这些发现强调了反馈机制在实现稳定、鲁棒和泛化学习中的重要性。相关代码可在指定的网址中找到。
### Innovation
DFMs通过结合底层输入和时间上的高层表示，引入了一种新的反馈机制。这种机制允许网络在迭代中逐步优化其内部状态，模仿生物决策过程。DFMs通过递归神经网络中的微分方程模型实现，并通过指数衰减进行稳定化来确保收敛。实验结果显示，在对象识别和分割任务中，DFMs在面对噪声和有限数据时表现更优，特别是在数据有限或噪声较大时。进一步地，DFMs在医学成像领域也表现出色，并能抵抗各种类型的噪声干扰。
### Conclusion
这些发现强调了反馈机制在实现稳定、鲁棒和泛化学习中的重要性。DFMs通过提供一种新的有状态模型，在多个任务中显示出更好的性能，尤其是在低数据量或高噪声环境中。
## 503. `cs.CV` - 在自我监督的深度估计中实现更清晰的物体边界 [PDF](https://arxiv.org/pdf/2509.15987), [HTML](https://arxiv.org/abs/2509.15987)
### Authors
Aurélien Cecille,Stefan Duffner,Franck Davoine,Rémi Agier,Thibault Neveu
### Background
单目深度估计对于三维场景理解至关重要，但现有方法往往在物体边界处产生模糊的深度，引入了伪3D点。在保持边缘清晰度的同时通常需要非常精细的监督。我们的方法仅通过自我监督就能产生锐利的深度不连续性，通过对每个像素的深度进行混合分布建模，捕捉多个可能的深度值并从直接回归转移不确定性到混合权重，该公式能够无缝地集成到现有的管道中，通过使用方差感知损失函数和不确定性传播。
### Innovation
我们提出了一种使用混合分布模型每个像素深度的方法，通过将不确定性转移至混合权重从而减少深度估计的模糊性，这种方法能够在仅有自我监督的情况下产生锐利的深度边界，并能无缝集成到现有的深度估计框架中，同时证明了这种方法在评估数据集上的优越性，相比当前最先进的基线方法，它提高了边界清晰度35%并提升了点云质量。
### Conclusion
我们的方法在边界清晰度和点云质量方面均已超越现有基线模型，在KITTI和VKITTIv2数据集上取得了显著的改进。
## 504. `cs.CV` - RangeSAM: 利用视觉基础模型进行 range-view 代表的 LiDAR 分割 [PDF](https://arxiv.org/pdf/2509.15886), [HTML](https://arxiv.org/abs/2509.15886)
### Authors
Paul Julius Kühn,Duc Anh Nguyen,Arjan Kuijper,Holger Graf,Dieter Fellner,Saptarshi Neil Sinha
### Background
点云分割对于自动驾驶和三维场景理解至关重要。尽管体素和点基方法因兼容深度架构并能捕捉精细几何结构而受到最近研究的青睐，但它们往往会产生较高的计算成本、不规则的内存访问和受限的实时效率。相比之下，尽管 range-view 方法相对较少被探索，但它们可以利用成熟的2D语义分割技术进行快速准确的预测。受视觉基础模型（VFMs）在标题生成、零样本识别和多模态任务中迅速进步的启发，作者研究了是否当前的 SAM2（最先进 VFM 之一）可以作为 LiDAR 点云范围视图分割的强骨干。作者提出了一种新的 range-view 框架，将 SAM2 调整为3D分割，结合高效的2D特征提取与标准的空间采样/恢复操作，以处理点云。为了优化 SAM2 以适应范围视图表示法，作者对编码器实施了几种架构修改：（1）一个新模块，强调 LiDAR 范围图像固有的水平空间依赖性；（2）针对球面投影几何属性量身定制的配置；（3）在编码器骨干中设计的适应机制，专门用于捕捉范围视图伪图像中独特的空间模式和断裂。
### Innovation
通过将视觉基础模型（VFMs）中的SAM2调整为范围视图的点云分割，优化了2D特征提取并使用了标准的空间采样/恢复操作。针对范围视图特有的几何特性，进行了特定的架构修改，如强调水平空间依赖性的模块、定制配置和适应机制，以提高模型对范围视图表示法的适配性。这种方法在SemanticKITTI上表现出竞争力，同时利用了2D为中心的管道的优势，如速度、可扩展性和部署便利性。这种方法展示了 VFMs 作为通用3D感知基础模型的潜力，并为统一的基础模型驱动LiDAR分割铺平了道路。结果表明，使用VFMs进行范围视图分割方法具有前景。
### Conclusion
本文展示了视觉基础模型（VFMs）作为通用3D感知基础模型的可行性，并为统一的基础模型驱动LiDAR分割铺平了道路。使用VFMs的范围视图分割方法显示出有希望的结果。
## 505. `cs.CV` - 照亮深度理解：单目深度估计的可解释性评估 [PDF](https://arxiv.org/pdf/2509.15980), [HTML](https://arxiv.org/abs/2509.15980)
### Authors
Lorenzo Cirillo,Claudio Schiavella,Lorenzo Papa,Paolo Russo,Irene Amerini
### Background
可解释的人工智能越来越多地被用来理解深度学习模型的决策过程，并增强其实用性。尽管单目深度估计（MDE）在实际应用中得到了广泛应用，但其可解释性研究相对较少。
### Innovation
该研究详细分析了MDE网络如何将输入图像映射到预测的深度图，并探索了广泛应用的特征归因方法，如Saliency Maps、Integrated Gradients、Attention Rollout。此外，引入了Attribution Fidelity作为新的评估指标，用于衡量特征归因的可靠性。
### Conclusion
实验结果表明，Saliency Maps和Integrated Gradients分别在MDE轻量化和深度模型中有效地突出了最重要的输入特征。此外，Attribution Fidelity能够有效识别解释方法是否产生可靠的可视化图，即使传统指标可能表明结果满意。
## 506. `cs.CV` - 通过部分对齐跨视图对应引起因果学习的广义深度多视图聚类 [PDF](https://arxiv.org/pdf/2509.16022), [HTML](https://arxiv.org/abs/2509.16022)
### Authors
Xihong Yang,Siwei Wang,Jiaqi Jin,Fangdi Wang,Tianrui Liu,Yueming Jin,Xinwang Liu,En Zhu,Kunlun He
### Background
多视图聚类（MVC）的目标是在多个视图中探索共同的聚类结构。现有的许多MVC方法严重依赖视图一致性假设，即不同视图中对应的样本被提前排序对齐。然而，在实际场景中，仅部分数据可以在不同视图之间一致对齐，这限制了整体聚类性能。本文将由于数据顺序偏移（即从完全对齐到部分对齐）导致模型性能下降的现象视为一个广义多视图聚类问题，并尝试通过因果学习来处理这一问题。
### Innovation
本文提出了一个因果多视图聚类网络CauMVC。通过因果建模方法理解多视图聚类过程，将部分对齐的数据视为干预，并将多视图聚类问题视为干预后的推断。通过结合现有的信息编码器估计不变特征，并设计解码器进行推断，同时设计对比性正则化来捕获样本的关联。这是首次通过因果学习来处理广义多视图聚类问题的研究。
### Conclusion
实验结果表明CauMVC在完全和部分对齐的数据上均具有强大的泛化能力和有效性。
## 507. `cs.CV` - GLip：一种全局-局部综合渐进框架的鲁棒视觉语音识别 [PDF](https://arxiv.org/pdf/2509.16031), [HTML](https://arxiv.org/abs/2509.16031)
### Authors
Tianyue Wang,Shuang Yang,Shiguang Shan,Xilin Chen
### Background
视觉语音识别（VSR），也被称为唇读，是指仅通过无声视频来识别语音的过程。尽管近几十年来在VSR方面取得了显著进展，但目前大多数方法仅关注有限的视觉挑战，如光照变化、遮挡、模糊和姿态变化。为了应对这些挑战，本文提出了一种名为GLip的全局-局部综合渐进框架，旨在增强VSR的鲁棒性。GLip借鉴了两个关键思路：首先，通过在不同条件下学习视觉特征的初步粗略对齐，有助于在恶劣条件下学习更精确的视觉-语音映射；其次，在不利条件下，某些局部区域（如非被遮挡的区域）通常比全局特征提供更多区分性的唇读线索。
### Innovation
GLip引入了一种双路径特征提取架构，该架构将全局和局部特征结合在一个两阶段渐进学习框架中。在第一阶段，模型学习将全局和局部视觉特征与相应的声学语音单位对齐，建立粗略但语义上稳健的基础。在第二阶段，引入了一个上下文增强模块（CEM），动态地在空间和时间维度上整合局部特征与相关全局上下文，细化粗略表示为精确的视觉-语音映射。
### Conclusion
GLip通过渐进学习策略利用区分性的局部区域，展示了对各种视觉挑战的增强鲁棒性，并在LRS2和LRS3基准测试中持续优于现有方法。此外，我们在一个新引入的具有挑战性的普通话数据集上进一步验证了其有效性。
## 508. `cs.CV` - 带有对比学习的多时相多光谱注意力增强深度卷积神经网络在作物产量预测中的应用 [PDF](https://arxiv.org/pdf/2509.15966), [HTML](https://arxiv.org/abs/2509.15966)
### Authors
Shalini Dangi,Surya Karthikeya Mullapudi,Chandravardhan Singh Raghaw,Shahid Shafi Dar,Mohammad Zia Ur Rehman,Nagendra Kumar
### Background
精确的产量预测对于农业可持续性和粮食安全至关重要。然而，气候变化通过影响天气条件、土壤肥力和农作管理系统等因素，使准确的产量预测变得复杂。科技进步通过利用卫星监测和数据分析来实现精准的产量估计，对克服这些挑战起到了关键作用。现有的方法依赖于空域时间数据进行作物产量预测，但这些方法在处理对于评估作物健康和生长模式至关重要的多光谱数据方面常常存在困难。为了解决这一挑战，我们提出了一个新型的多时相多光谱产量预测网络MTMS-YieldNet，该网络将光谱数据与空域时间信息整合，以有效捕捉二者之间的关联和依赖关系。现有的依赖预训练模型的方法主要在通用视觉数据上进行预训练，而MTMS-YieldNet则利用对比学习在预训练过程中的特征辨识，专注于从遥感数据中捕捉空间光谱模式和空域时间依赖性。
### Innovation
提出了一种名为MTMS-YieldNet的多时相多光谱产量预测网络。该网络利用对比学习在预训练过程中进行特征辨识，专注于从遥感数据中捕捉空间光谱模式和空域时间依赖性，这在现有的依赖预训练模型的方法中是不同的。实验结果表明，MTMS-YieldNet在Sentinel-1、Landsat-8和Sentinel-2数据上分别达到了0.336、0.353和0.331的MAPE成绩，显示出在不同气候和季节条件下有效的产量预测性能。这种高性能有助于提高产量预测并为农民提供有价值的见解，帮助他们做出更好的决策，从而可能提高农作物产量。
### Conclusion
研究工作首次提出了MTMS-YieldNet，该网络实现了在各种遥感数据上的优异产量预测结果，特别是利用对比学习提升了对空间光谱模式和时空依赖性的捕捉，为精确的产量预测提供了新的解决方案。这对于提高农业生产力和确保粮食安全具有重要意义。
## 509. `cs.CV` - DistillMatch：利用视觉基础模型的知识蒸馏进行多模态图像匹配 [PDF](https://arxiv.org/pdf/2509.16017), [HTML](https://arxiv.org/abs/2509.16017)
### Authors
Meng Yang,Fan Fan,Zizhuo Li,Songchu Deng,Yong Ma,Jiayi Ma
### Background
多模态图像匹配旨在在不同模态的图像之间建立像素级别的对应关系，这是跨模态感知、融合和分析的关键。然而，模态间的显著外观差异使得这一任务颇具挑战性。由于高质量标注数据集的稀缺性，现有的基于深度学习的方法在提取共性特征方面表现不佳且不具场景多样性适应性。Vision Foundation Model (VFM)在大规模数据上进行了训练，能够生成适应各类模态的数据和任务的泛化性和鲁棒性更强的特征表示，包括多模态匹配。因此，研究团队提出了DistillMatch，这是一种利用VFM知识蒸馏的多模态图像匹配方法。DistillMatch通过知识蒸馏构建了一个轻量化的学生模型，能够从VFM（包括DINOv2和DINOv3）中提取高层次的语义特征，以辅助跨模态匹配。为了保留模态特定的信息，DistillMatch提取并注入模态类别信息，增强对跨模态关联的理解。此外，还设计了V2I-GAN通过将可见图像转化为伪红外图像来提升模型的泛化能力，从而增加训练数据量。实验结果表明，DistillMatch在公开数据集上的表现优于现有算法。
### Innovation
提出了DistillMatch，一种利用Vision Foundation Model (VFM)的知识蒸馏进行多模态图像匹配的方法。通过知识蒸馏构建了轻量级学生模型并提取更高层次的语义特征，以辅助跨模态匹配。设计了V2I-GAN用于图像增强，通过将可见图像转化为伪红外图像来提高模型的泛化能力。
### Conclusion
实验表明，DistillMatch在公开数据集上的性能优于现有算法，展示了其在跨模态图像匹配中的优势。
## 510. `cs.CV` - 基于图的B样条点云曲面重建 [PDF](https://arxiv.org/pdf/2509.16050), [HTML](https://arxiv.org/abs/2509.16050)
### Authors
Stuti Pathak,Rhys G. Evans,Gunther Steenackers,Rudi Penne
### Background
3D视觉应用中从离散点云数据生成连续表面是一个基础任务。现实世界的点云由于各种技术和环境因素影响，通常含有噪声。现有数据驱动的表面重建算法依赖于法线或者在计算过程中完成法线的近似估算，这在噪音较大的点云数据集上尤其不可靠。尽管B样条重建技术能够提供点云的紧凑表面表示，但其表面复杂性与控制点的数量和位置直接相关。现有基于样条的方法在给定点云中预测固定数量的控制点位置，使得难以匹配其底层表面的复杂度。
### Innovation
我们开发了一种基于词典向导的图卷积网络（Dictionary-Guided Graph Convolutional Network）的表面重建策略，该方法同时预测噪声点云数据中控制点的位置和数量，生成平滑的表面而无需使用任何点的法线。我们的方法与其他已知或最近的基线方法相比，在多种评估指标上都表现出更好的性能，既从定性和定量两个方面都优于对照组。
### Conclusion
我们的工作提出了一种新的表面重建策略，能够有效处理噪声点云数据，并生成平滑的表面，这种方法已经在多种应用中展示了优越性。
## 511. `cs.CV` - 盲区引导扩散：自监督真实世界去噪 [PDF](https://arxiv.org/pdf/2509.16091), [HTML](https://arxiv.org/abs/2509.16091)
### Authors
Shen Cheng,Haipeng Li,Haibin Huang,Xiaohong Liu,Shuaicheng Liu
### Background
现有的盲区网络（BSN）虽然提高了图像去噪能力，但往往会牺牲局部细节并引入像素间不连续性，这是由于空间独立性假设导致的。目前的扩散模型在自监督去噪方面也存在挑战，难以有效适应自监督去噪要求。因此，需要一种能有效解决这些挑战的新型去噪框架。
### Innovation
提出了一种双分支扩散框架，其中包括一个基于BSN的扩散分支，用于生成半清洁图像，以及一个传统的扩散分支，用于捕捉噪声分布。特别地，利用BSN分支来引导采样过程，捕捉噪声结构同时保持局部细节，从而能够在没有配对数据的情况下有效训练模型。
### Conclusion
在SIDD和DND数据集上的大量实验表明，这种方法在真实世界图像去噪方面达到了最先进的性能，证明了其作为一种高效自监督解决方案的有效性。已经发布了代码和预训练模型供进一步研究参考。
## 512. `cs.CV` - AdaSports-Traj: 针对体育多智能体轨迹建模的角色和领域感知适应性 [PDF](https://arxiv.org/pdf/2509.16095), [HTML](https://arxiv.org/abs/2509.16095)
### Authors
Yi Xu,Yun Fu
### Background
在多智能体体育场景中的轨迹预测因其代理角色（例如球员与球）之间的结构异质性以及不同体育领域中的动态分布差距而具有内在挑战性。现有的统一框架往往无法捕捉这些结构化的分布变化，在不同角色和领域中的泛化表现不佳。
### Innovation
我们提出AdaSports-Traj，一个自适应轨迹建模框架，明确解决了体育领域的内部差异和外部差异分布不一致问题。其核心是一个角色和领域感知适配器，根据代理身份和领域上下文条件性调整潜在表示。此外，引入了层次对比学习目标，分别监督角色敏感性和领域导向性表示，以鼓励分离的潜在结构，而不会引入优化冲突。
### Conclusion
在篮球-U、足球-U和足球-U三个多样化的体育数据集上的实验表明，我们的自适应设计在统一和跨领域轨迹预测设置中表现强劲。
## 513. `cs.CV` - 通过多模态大型语言模型的语言指导推理进行群体活动检测 [PDF](https://arxiv.org/pdf/2509.16054), [HTML](https://arxiv.org/abs/2509.16054)
### Authors
Jihua Peng,Qianxiong Xu,Yichen Liu,Chenxi Liu,Cheng Long,Rui Zhao,Ziyue Li
### Background
群体活动检测（GAD）旨在同时识别群体成员并对其集体活动进行分类。现有基于深度学习的方法利用专门的架构（如变换器网络）来建模个体角色的动态及其与个体和群体之间的语义依赖关系。但是，这些方法主要依赖于从视觉特征中隐含的模式识别，并且在上下文推理和可解释性方面遇到困难。
### Innovation
本文提出了一种名为LIR-GAD的新框架，利用多模态大型语言模型进行语言指导的推理。该方法扩展了原始的MMLM词汇表，通过引入活动级的<ACT>标记和多个群组特定的<GROUP>标记来增强模型。利用预训练的常识知识，<ACT>标记和<GROUP>标记能够有效地捕获集体活动的语义信息，并学习不同群体的独特表示特征。此外，引入多标签分类损失进一步增强了<ACT>标记学习区分性语义表示的能力。设计了一种多模态双重对齐融合（MDAF）模块，将MMLM对设计标记对应的隐藏嵌入与视觉特征进行整合，显著提高了GAD的性能。
### Conclusion
定量和定性实验表明，提出的LIR-GAD方法在GAD任务中的性能优越。
## 514. `cs.CV` - UniMRSeg: 统一模态放松分割通过层次自监督补偿 [PDF](https://arxiv.org/pdf/2509.16170), [HTML](https://arxiv.org/abs/2509.16170)
### Authors
Xiaoqi Zhao,Youwei Pang,Chenyang Yu,Lihe Zhang,Huchuan Lu,Shijian Lu,Georges El Fakhri,Xiaofeng Liu
### Background
多模态图像分割在实际部署中面临由于不完整或受损模态导致性能下降的挑战。现有方法通过专门的组合模型解决了训练-推断模态差距，但这样做会引发高部署成本，因为需要大量的模型子集和模型-模态匹配。
### Innovation
本文提出了一种统一模态放松分割网络（UniMRSeg）通过分层自我监督补偿（HSSC）。UniMRSeg在输入、特征和输出级别上层级地弭平互补和不完整模态之间的表示差距。方法包括模态重建、模态不变对比学习和轻量级反向注意力适配器来补偿感知语义的不足，并通过混合一致性约束进行微调，以确保在所有模态组合下预测的稳定性。
### Conclusion
UniMRSeg在基于MRI的大脑肿瘤分割、RGB-D语义分割和RGB-D/T显著目标分割等多种缺省模态场景下显著优于现有的最先进的方法。
## 515. `cs.CV` - SegDINO3D: 由2D图像级和对象级特征赋能的3D实例分割 [PDF](https://arxiv.org/pdf/2509.16098), [HTML](https://arxiv.org/abs/2509.16098)
### Authors
Jinyuan Qu,Hongyang Li,Xingyu Chen,Shilong Liu,Yukai Shi,Tianhe Ren,Ruitao Jing,Lei Zhang
### Background
3D实例分割数据相对2D图像数据比较匮乏，因此需要有效利用预训练的2D检测模型的2D特征来提高3D表示。本文提出了SegDINO3D，一种新颖的Transformer编码器-解码器框架，用于3D实例分割。
### Innovation
SegDINO3D创新性地结合了点云和关联2D图像作为输入，通过检索2D图像特征并利用3D编码器进行3D上下文融合来丰富3D点，在解码阶段以3D锚框形式表达3D对象查询，并利用2D检测模型的2D对象查询进行跨注意力操作。此外，引入3D框查询使模型能够使用预测框进行更精确的查询，从而显著提高性能。
### Conclusion
SegDINO3D在ScanNetV2和ScanNet200 3D实例分割基准测试中达到了最先进的性能。尤其在挑战性的ScanNet200数据集上，相较于之前的方法，其在验证集和隐藏测试集上分别取得了+8.7和+6.8的mAP提升，证明了其优越性。
## 516. `cs.CV` - 从极少的飞行时间像素中恢复参数化场景 [PDF](https://arxiv.org/pdf/2509.16132), [HTML](https://arxiv.org/abs/2509.16132)
### Authors
Carter Sifferman,Yiquan Li,Yiming Li,Fangzhou Mu,Michael Gleicher,Mohit Gupta,Yin Li
### Background
本文旨在使用低成本、现成的时间飞行传感器进行深度测量来恢复三维参数化场景的几何结构。尽管该传感器的分辨率极低（单像素），但它每像素具有宽视角，并以时间分辨的光子计数形式捕捉详细的时间飞行数据，这些数据包含了丰富的场景信息，从而使得从稀疏测量中恢复简单场景成为可能。
### Innovation
本文提出了一种方法，利用前馈预测来推断场景参数，并在分析-合成框架中结合可微分渲染以优化场景参数估计。这种方法已经在模拟和受控的真实世界捕获中展示了有效性，对于未纹理化3D模型下的物体姿态准确恢复具有显著效果，同时对其他参数化场景也展示了有希望的初步结果。
### Conclusion
本文通过开发硬件原型，证明了在假设条件下能够有效恢复物体的三维姿态。此外，研究还探究了该成像解决方案的极限和能力。
## 517. `cs.CV` - BaseReward：多模态奖励模型的强大基线 [PDF](https://arxiv.org/pdf/2509.16127), [HTML](https://arxiv.org/abs/2509.16127)
### Authors
Yi-Fan Zhang,Haihua Yang,Huanyu Zhang,Yang Shi,Zezhou Chen,Haochen Tian,Chaoyou Fu,Haotian Wang,Kai Wu,Bo Cui,Xu Wang,Jianfei Pan,Haotian Wang,Zhang Zhang,Liang Wang
### Background
随着多模态大型语言模型（MLLMs）的迅速进展，如何将这些模型与人类偏好对齐成为了一个关键挑战。奖励模型（RMs）作为实现这一目标的核心技术，当前在学术界和工业界缺乏系统性的指南来构建最先进的多模态奖励模型（MRMs）。本文通过全面的实验分析，旨在提供一个清晰的“配方”来构建高性能的MRMs，系统地研究了MRM开发管道中的每一个关键组成部分，如奖励建模范式、奖励头结构、训练策略、数据采集（涵盖数十个多模态和文本专有偏好的数据集）、主干模型和模型规模以及集成方法等。这些实验见解催生了BaseReward，这是一款强大的且高效的多模态奖励模型基线。
### Innovation
BaseReward 采用了简单有效且基于 Qwen2.5-VL 主干模型的架构，具有优化的两层奖励头，训练数据是经过精心整理并混合的高品质多模态和文本专有偏好数据。实验结果显示，BaseReward 在主要评估基准（如 MM-RLHF-Reward Bench、VL-Reward Bench 和 Multimodal Reward Bench）上超越了以前的模型。此外，通过将其整合到实际的增强学习管道中，证明了其实用效果，增强了MLLM在感知、推理和对话任务中的表现。
### Conclusion
这项工作不仅提供了一个顶级的MRM模型，而且更为重要的是，为社区提供了一套清晰且基于实验的指南，用于开发下一代MLLM的稳健奖励模型。
## 518. `cs.CV` - 通过张量分解实现鲁棒的视觉-语言模型：对抗攻击防御 [PDF](https://arxiv.org/pdf/2509.16163), [HTML](https://arxiv.org/abs/2509.16163)
### Authors
Het Patel,Muzammil Allie,Qian Zhang,Jia Chen,Evangelos E. Papalexakis
### Background
视觉语言模型(VLMs)在多模态理解方面表现出色，但容易受到对抗攻击的影响。现有的防御方法通常需要昂贵的重新训练或显著的架构改变，给实际应用带来困难。因此，需要一种简便且无需重新训练的方法来增强VLMs的鲁棒性，以抵御对抗攻击，在不改变模型架构的情况下也能有效工作。
### Innovation
本文提出了一种轻量级的防御方法，基于张量分解，适用于任何预训练的视觉语言模型，且不需要重新训练。该方法通过分解和重构视觉编码器表示，可以在筛选对抗噪声的同时保留语义，从而增强模型的鲁棒性。通过在CLIP上的实验，该方法在COCO和Flickr30K上显示了提升的抗攻击性能。
### Conclusion
分析表明，使用张量列车分解（张量秩为8-32，残差强度为0.1-0.2）是最佳方案。该方法是一个实际可行的插拔式解决方案，具有最小的开销，可用于现有的视觉语言模型，有效提升了模型的抗攻击性能，适用于多种场景。
## 519. `cs.CV` - 误导之骆驼：关于多模态大语言模型的阿谀行为 [PDF](https://arxiv.org/pdf/2509.16149), [HTML](https://arxiv.org/abs/2509.16149)
### Authors
Renjie Pi,Kehao Miao,Li Peihang,Runtao Liu,Jiahui Gao,Jipeng Zhang,Xiaofang Zhou
### Background
多模态大语言模型（MLLMs）在基于图像输入的对话中展现出了非凡的能力。然而，我们观察到MLLMs表现出一种明显的阿谀奉迎行为。这种行为在文本大语言模型（LLMs）中也有类似表现，但在处理图像输入时显得更为突出。研究人员将这一现象称为‘阿谀模态差异’。为深入了解此现象，我们进一步分析了导致该差异加剧的因素。
### Innovation
我们首先尝试通过简单的监督微调来帮助MLLM反驳用户误导性的指令，但从实验中发现，这一方法使MLLM变得过于抗拒纠正性指令，即在错误的情况下仍然固执己见。为解决这一权衡问题，我们提出了Sycophantic Reflective Tuning（SRT）。SRT允许MLLM进行反思性推理，使其在得出结论前能够判断用户指令是误导性的还是纠正性的。应用SRT后，我们观察到对误导性指令的阿谀程度显著降低，而对纠正性指令的过度固执也未增加。
### Conclusion
SRT方法成功地减少了MLLM对误导性用户指令的阿谀行为，同时保持了对纠正性指令的合理反应，从而缓解了之前提出的误导与纠正之间的权衡问题。
## 520. `cs.CV` - 使用二分区间的快速OTSU阈值分割方法 [PDF](https://arxiv.org/pdf/2509.16179), [HTML](https://arxiv.org/abs/2509.16179)
### Authors
Sai Varun Kodathala
### Background
OTSU分割算法是图像分割的基本技术，但由于在所有可能的阈值范围内进行详尽搜索，其计算效率受到严重影响。现有的实现方式在大规模图像处理系统中面临关键的计算瓶颈。
### Innovation
该研究提出了一种优化实现方法，利用二分法结合之间的方差函数的单模特性，将计算复杂度从O(L)降低至O(log L)，同时保持分割精度。实验验证表明，该方法在标准测试图像上的方差计算减少91.63%，算法迭代减少97.21%，并在66.67%的测试案例中实现精确阈值匹配，95.83%的案例偏差不超过5个灰度级。此外，该算法在理论对数界限范围内具有普遍收敛性，提供适合实时应用的确定性性能保证，而不牺牲原始OTSU方法的理论基础和分割质量。
### Conclusion
该优化方法解决了大规模图像处理系统中的关键计算瓶颈，同时保证了理论基础和分割质量，适用于实时应用。
## 521. `cs.CV` - Video2Roleplay：基于视频指导的多模态数据集和框架 [PDF](https://arxiv.org/pdf/2509.15233), [HTML](https://arxiv.org/abs/2509.15233)
### Authors
Xueqiao Zhang,Chao Zhang,Jingtao Xu,Yifan Zhu,Xin Shi,Yi Yang,Yawei Luo
### Background
角色扮演代理（RPAs）因其能够模拟沉浸式和互动性角色而引起了广泛关注。然而，现有的方法主要集中在静态角色档案上，忽视了人类所具有的动态感知能力。为了解决这一问题，本文通过将视频模态纳入RPAs中，引入了动态角色档案的概念。为支持这一创新，本文构建了包含60,000个视频和700,000组对应对话的大型高质量数据集——Role-playing-Video60k。
### Innovation
本文提出了一种由动态和静态角色档案组合而成的全面的RPA框架。动态档案通过适应性地抽取视频帧并按时间顺序馈送到LLM中创建。静态档案包含（1）训练视频中的角色对话，在微调时使用，以及（2）输入视频中的总结背景，在推理时使用。此外，本文还提出了一个包括八项指标的稳健评估方法。实验证明了该框架的有效性，同时也强调了动态角色档案在开发RPAs中的重要性。
### Conclusion
实验结果表明，本框架的有效性，突显了动态角色档案在开发RPAs中的重要性。同时，本文构建的大型高质量数据集和提出的全面RPA框架为指导进行角色扮演代理的研究提供了重要支持。
## 522. `cs.CV` - RadarGaussianDet3D：基于4D汽车雷达的高效且有效的高斯基3D检测器 [PDF](https://arxiv.org/pdf/2509.16119), [HTML](https://arxiv.org/abs/2509.16119)
### Authors
Weiyi Xiong,Bing Zhu,Tao Huang,Zewei Zheng
### Background
4D汽车雷达因其低成本、鲁棒性和固有的速度测量能力，在自动驾驶领域引起了越来越多的关注。然而，现有的基于4D雷达的3D检测器高度依赖于支柱编码器来提取鸟瞰视图(BEV)特征，每个点仅对单个BEV格子做出贡献，导致特征图稀疏，表示质量较差。此外，它们还独立优化边界框属性，导致检测精度较差。另外，尽管这些检测器的推理速度对于高端GPU来说足够，但在车载嵌入式设备上可能无法满足实时需求。为了解决这些限制，引入了一个高效的Gaussian基3D检测器，称为RadarGaussianDet3D，利用Gaussian基础体和分布作为雷达点和边界框的中间表示形式。RadarGaussianDet3D设计了一种新颖的点Gaussian编码器（PGE），在特征聚合后将每个点转换为Gaussian基础体，并利用3D Gaussian散点图（3DGS）技术进行BEV栅格化，生成更密集的特征图。PGE表现出极低的延迟，由于点特征聚合的优化算法和3DGS的快速渲染。此外，还提出了一个新的Box Gaussian损失（BGL），将边界框转换为3D Gaussian分布，测量其距离，以实现更全面和一致的优化。
### Innovation
该研究通过引入基于Gaussian基础体的新颖点Gaussian编码器（PGE）和3D Gaussian散点图（3DGS）以及边界框的基于Gaussian的损失（BGL）方法，改善了现有的基于4D雷达的3D检测器。PGE将每个点转换为Gaussian基础体，生成更密集的特征图，同时BGL将边界框转换为3D Gaussian分布，使得优化更加全面和一致。这些方法显著提高了检测准确性和推理速度，特别是在嵌入式设备上也能满足实时需求。
### Conclusion
通过实验证明，RadarGaussianDet3D具有顶级的检测精度，同时具有远超现有方法的快速推理速度，展示了其在自动驾驶中的实时部署潜力。
## 523. `cs.CV` - AcT2I: 评估和改进文本到图像模型中的动作描绘 [PDF](https://arxiv.org/pdf/2509.16141), [HTML](https://arxiv.org/abs/2509.16141)
### Authors
Vatsal Malaviya,Agneet Chatterjee,Maitreya Patel,Yezhou Yang,Chitta Baral
### Background
文本到图像（T2I）模型最近在从文本描述生成图像方面取得了显著成功。然而，在精确再现以动作和相互作用为主要语义焦点的复杂场景方面仍存在挑战。作者观察到，T2I模型在捕获动作描述中的细微和隐含属性方面经常表现出困难，导致生成的图像缺乏关键上下文细节。为了解决这个问题，作者提出了一个名为AcT2I的基准测试，专门用于评估T2I模型在面对以动作为主题的任务时的表现。实验结果显示，当前的T2I模型在这个基准测试中的表现不佳，这可能源于训练数据中关于动作本身的属性和上下文依赖性表示不足。尽管当前研究中的T2I模型都是基于训练的，但这也引发了一种新的思考，即是否可以通过一种没有训练环节的方法来提升生成能力，即利用大型语言模型进行知识提炼，从而解决这一不足之处并在不依赖训练数据的情况下增强提示信息。通过这种方式，作者进一步实验验证了，增强提示信息，特别是增加时间细节，显著提高了图像生成的准确性。
### Innovation
提出了一个名为AcT2I的基准测试，专门用于评估T2I模型在面对以动作为主题的任务时的表现。通过不依赖训练的方法，用大型语言模型进行了知识提炼，增强提示信息，特别是增加时间细节来解决T2I模型在复杂动作描绘中的不足。
### Conclusion
当前的T2I方法在生成需要复杂推理的图像时存在局限性，表明以系统性方式整合语言知识可以在生成微细且上下文准确的图像方面取得显著进步。
## 524. `cs.CV` - Global Pre-fixing, Local Adjusting: 一种简单而有效的持续学习对比策略 [PDF](https://arxiv.org/pdf/2509.15347), [HTML](https://arxiv.org/abs/2509.15347)
### Authors
Jia Tang,Xinrui Wang,Songcan Chen
### Background
持续学习（CL）涉及在不断变化的任务中获取和积累知识，同时缓解灾难性遗忘。尽管近年来利用对比损失构建更可迁移且遗忘较少的表示展示了潜在的成功，但由于任务间和任务内特征的混淆，其性能仍受到限制。
### Innovation
提出了一个简单而有效的对比策略，名为全局预设、局部调整的监督对比学习（GPLASC）。该方法通过在表示单元超球面上划分非重叠区域，并构建任务间的等角正交框架（ETF）来避免任务混淆，同时在每个任务中通过调整任务内特征结构形成局部ETF，从而确保任务间和任务内具有区分性的特征结构，并且该方法可以无缝整合到现有的对比持续学习框架中。
### Conclusion
大量实验验证了该方法的有效性。
## 525. `cs.CV` - 近期使用深度学习技术在显微镜图像增强方面的最新进展：综述 [PDF](https://arxiv.org/pdf/2509.15363), [HTML](https://arxiv.org/abs/2509.15363)
### Authors
Debasish Dutta,Neeharika Sonowal,Risheraj Barauh,Deepjyoti Chetia,Sanjib Kr Kalita
### Background
显微镜图像增强在理解和分析微观尺度下的生物细胞和材料细节方面起着关键作用。近年来，借助深度学习方法，显微镜图像增强技术得到了显著进步，已有大量研究探讨了其在该领域的应用和发展趋势。本文旨在回顾显微镜图像增强技术的最新进展，重点讨论其演进过程，应用领域，面临的挑战以及未来发展方向。
### Innovation
本文提供了一个关于显微镜图像增强技术最新进展的综述，特别强调了超分辨率、重建和去噪这三个关键领域的当前趋势，并讨论了深度学习方法在这三个领域的实用价值。
### Conclusion
本文总结了显微镜图像增强技术的发展现状，指出了存在的挑战，并展望了未来的研究方向。
## 526. `cs.CV` - 将视觉皮层横向连接属性整合到CNN中：递归激活和兴奋抑制分离 [PDF](https://arxiv.org/pdf/2509.15460), [HTML](https://arxiv.org/abs/2509.15460)
### Authors
Jin Hyun Park,Cheng Zhang,Yoonsuck Choe
### Background
传统的卷积神经网络（CNN）及其现代更新，如ResNet，很大程度上受到哺乳动物视觉系统的启发。这些模型包括传入连接（视网膜和外侧膝状体到视觉皮层）和长程投射（不同视觉皮层区域之间的连接）。然而，在哺乳动物视觉系统中，每个视觉皮层区域内部存在横向（或水平）连接。这种连接类似于CNN特征图内的连接，这一重要的架构特征当前的CNN模型并未包含。本文将探讨如何在标准CNN框架中建模这些横向连接，并测试其带来的好处及其与生物视觉系统的相关属性。
### Innovation
本文展示了如何在标准CNN框架中建模横向连接，特别是递归激活和兴奋抑制连接的分离。提出了一种自定义损失函数来分离兴奋性和抑制性权重。这一创新不仅提高了分类准确性，而且使模型的激活和连接属性表现出与生物学视觉系统相似的特征。
### Conclusion
我们期待这一方法能够使CNN更接近其生物学对应物，并更好地理解视觉皮层计算的原理。
## 527. `cs.CV` - MANZANO：一种具有混合视觉标记器的简单可扩展统一多模态模型 [PDF](https://arxiv.org/pdf/2509.16197), [HTML](https://arxiv.org/abs/2509.16197)
### Authors
Yanghao Li,Rui Qian,Bowen Pan,Haotian Zhang,Haoshuo Huang,Bowen Zhang,Jialing Tong,Haoxuan You,Xianzhi Du,Zhe Gan,Hyunjik Kim,Chao Jia,Zhenbang Wang,Yinfei Yang,Mingfei Gao,Zi-Yi Dou,Wenze Hu,Chang Gao,Dongxu Li,Philipp Dufter,Zirui Wang,Guoli Yin,Zhengdong Zhang,Chen Chen,Yang Zhao,Ruoming Pang,Zhifeng Chen
### Background
统一的多模态大语言模型（LLMs）既能理解又能生成视觉内容，具有巨大的潜在价值。然而，现有的开源模型在这些能力之间往往存在性能权衡。本文介绍了Manzano，这是一种简单且可扩展的统一框架，通过结合混合图像标记器和精炼的训练方法显著减少了这种权衡。
### Innovation
Manzano通过一种单一的共享视觉编码器向两个轻量级适配器提供输入，这两个适配器在共同语义空间中分别生成文本到图像生成的离散标记和图像到文本理解和连续嵌入。统一的自回归LLM预测高层次语义，随后的辅助扩散解码器将图像标记转换为像素。该架构与统一的理解和生成数据的训练配方相结合，实现这两种能力的可扩展联合学习。
### Conclusion
Manzano在统一模型中实现了最先进的结果，与专门模型相比在文本丰富的评估中具有竞争力。我们的研究显示任务冲突最小，模型大小扩展具有持续的收益，验证了混合标记器的设计选择。
## 528. `cs.CV` - MICA: 多代理工业协调助手 [PDF](https://arxiv.org/pdf/2509.15237), [HTML](https://arxiv.org/abs/2509.15237)
### Authors
Di Wen,Kunyu Peng,Junwei Zheng,Yufan Chen,Yitain Shi,Jiale Wei,Ruiping Liu,Kailun Yang,Rainer Stiefelhagen
### Background
工业流程需要能够适应并在有限计算能力、连接性和严格隐私限制下可靠运作的辅助系统。现有系统难以实现这一需求，因此本文提出了一种名为MICA（多代理工业协调助手）的感知驱动且具有语音交互功能的系统，能够提供实时的组装、故障排除、零部件查询和维护指导。MICA系统通过五种专业化角色的代理，结合安全检查器确保操作准确性和合规性。
### Innovation
本文引入了一种名为适应性步骤融合（ASF）的新方法，该方法能够动态结合专家推理和自然语音反馈的在线适应，以实现鲁棒性的步骤理解。此外，还提出了一个新的跨代表性任务类别的多代理协调基准，并制定了适用于工业协助的独特评估标准，从而更好地进行不同协调拓扑结构的系统比较。实验结果表明，MICA在任务成功率、可靠性和响应性方面优于现有基础结构，并且能在实际离线硬件上部署。
### Conclusion
研究结果表明，MICA不仅在工业辅助方面表现出色，还能够在动态工厂环境中作为可部署且保护隐私的多代理助手。未来的工作将重点考虑如何进一步优化代理之间的协调机制，提高系统的适应性和灵活性，以更好地满足复杂工业环境下的需求。
## 529. `cs.CV` - See&Trek: 无需训练的空间提示用于多模态大型语言模型 [PDF](https://arxiv.org/pdf/2509.16087), [HTML](https://arxiv.org/abs/2509.16087)
### Authors
Pengteng Li,Pinhao Song,Wuyang Li,Weiyu Guo,Huizai Yao,Yijie Xu,Dugang Liu,Hui Xiong
### Background
目前，虽然已经有研究将深度或点云等模态融入到多模态大型语言模型（MLLMs）中以提高空间推理能力，但纯粹基于视觉的空间理解仍然被广泛忽视。本文的背景在于填补这一空白，提出SEE&TREK框架。
### Innovation
SEE&TREK框架的主要创新点在于通过两个核心原则增加视觉多样性（通过最大语义丰富度采样）和重建运动轨迹（将相对空间位置编码到关键帧中以保持空间关系和时间连贯性），并且该方法无需训练和GPU，只需一次前向传播，即可无缝集成到现有的MLLMs中。
### Conclusion
通过在VSI-B ENCH和STI-B ENCH上进行的大量实验表明，SEE&TREK在不同空间推理任务上都能显著提升MLLMs的表现，最多可提高3.5%，为增强空间智能提供了前景。
## 530. `cs.CV` - MRI中乳腺肿瘤分割的不确定性门控变形网络 [PDF](https://arxiv.org/pdf/2509.15758), [HTML](https://arxiv.org/abs/2509.15758)
### Authors
Yue Zhang,Jiahua Dong,Chengtao Peng,Qiuli Wang,Dan Song,Guiduo Duan
### Background
在磁共振成像（MRI）中精确分割乳腺肿瘤对乳腺癌诊断至关重要，但现有方法在捕捉不规则肿瘤形状和有效整合局部和全局特征方面面临挑战。
### Innovation
提出了一种不确定性门控变形网络，通过结合卷积神经网络（CNN）和Transformer的信息互补，引入变形特征建模到卷积和注意力模块中，实现对不规则肿瘤边缘的自适应感受野。设计了基于像素级不确定性选择性交换CNN和Transformer互补特征的不确定性门控增强模块（U-GEM），以增强局部和全局表示。引入了边界敏感的深度监督损失来进一步提高肿瘤边界划分。
### Conclusion
在两个临床乳腺MRI数据集上的全面实验表明，该方法在肿瘤分割性能上优于最先进的方法，显示出其在准确乳腺肿瘤划分方面的临床潜力。
## 531. `cs.CV` - 使用自适应焦点损失函数的微超声图像前列腺囊层分割 [PDF](https://arxiv.org/pdf/2509.15595), [HTML](https://arxiv.org/abs/2509.15595)
### Authors
Kaniz Fatema,Vaibhav Thakur,Emad A. Mohammed
### Background
微超声（micro-US）是一种有前途的成像技术，适用于癌症检测和计算机辅助可视化。现有的方法在处理前列腺囊层的模糊边界时往往难以应对，特别是在存在专家和非专家标注差异的情况下。本研究旨在通过使用深度学习技术来解决这些问题，引入了一个适应性焦点损失函数，动态强调硬区域和易区域，考虑到它们的难度级别及其标注的可变性，以实现准确的前列腺囊层分割。
### Innovation
该研究提出了一种适应性焦点损失函数，通过结合标准焦点损失函数作为基线，设计出了一种新的适应性焦点损失函数，以更好地识别前列腺囊层的模糊区域。该方法通过调整分割模型的权重来提高识别效果，特别对专家和非专家标注之间的差异进行了修正，从而提高了分割效果。研究结果显示，这种适应性焦点损失函数在测试数据集中的均值Dice系数达到了0.940，均值Hausdorff距离为1.949毫米，显示出优越的性能。
### Conclusion
通过整合先进的损失函数和适应性技术到深度学习模型中，提高了在微超声图像中前列腺囊层分割的准确性，为前列腺癌诊断和治疗规划提供潜在的临床决策支持。
## 532. `cs.CV` - 在潜在空间中通过采样合成数据实现高效的长尾学习 [PDF](https://arxiv.org/pdf/2509.15859), [HTML](https://arxiv.org/abs/2509.15859)
### Authors
Nakul Sharma
### Background
不平衡分类数据集在机器学习中提出了重大挑战，往往会导致偏向的模型在少数类上的表现不佳。随着基础模型的应用，最近的研究关注于基础模型的全面、部分和参数高效微调来应对长尾分类问题。尽管这些研究在基准数据集上取得了令人印象深刻的性能，但仍然无法缩小与使用平衡数据集训练的网络之间的差距，即使对于较小的数据集，它们也仍然需要大量的计算资源。在强调计算效率和简洁性的重要性下，本文提出了一种新的框架，该框架利用视觉基础模型丰富的语义潜在空间生成合成数据，并结合真实和合成数据训练简单的线性分类器，以实现长尾分类。
### Innovation
该研究提出了一种新框架，利用视觉基础模型中的语义潜在空间生成合成数据，结合真实和合成数据训练简单的线性分类器，以提高计算效率。这种方法在CIFAR-100-LT基准测试中取得了新的最先进技术状态，并在Places-LT基准测试中展示了强大的性能，突显了其简单高效的方法的有效性和适应性。
### Conclusion
该方法为CIFAR-100-LT基准测试设定了一项新标准，并在Places-LT基准测试中展示了强劲的表现，这强调了其简便且有效的方法的有效性和适应性。
## 533. `cs.CV` - FedHK-MVFC: 联邦热核多视图聚类 [PDF](https://arxiv.org/pdf/2509.15844), [HTML](https://arxiv.org/abs/2509.15844)
### Authors
Kristina P. Sinaga
### Background
在分布式人工智能和隐私保护的医疗应用领域，本文提出了一种结合量子场论和联邦健康数据分析的多视图聚类框架。该方法利用谱分析中的热核系数将欧氏距离转化为几何感知的相似度度量，以捕捉多样化的医疗数据结构。
### Innovation
本文开发了两个算法：Heat Kernel-Enhanced Multi-View Fuzzy Clustering (HK-MVFC) 用于集中分析，Federated Heat Kernel Multi-View Fuzzy Clustering (FedHK-MVFC) 用于跨医院的安全、隐私保护学习，通过差分隐私和安全聚合促进HIPAA合规合作。在心脏病人合成数据集上的测试结果显示，与集中方法相比，准确率提高了8%-12%，通信减少了70%，同时保持了98.2%的效率。
### Conclusion
该方法提供了一种新的标准，适用于联邦环境下的几何感知学习，将高级数学理论转化为分析敏感医疗数据的实际解决方案，同时确保了严谨性和临床相关性，并在两家医院的10,000名患者记录中得到了验证，证明了该方法在心电图、心脏影像和行为数据合作表型分析中的有效性。理论贡献包括可证明收敛的更新规则、自适应视图加权以及隐私保护协议。
## 534. `cs.CV` - MoAngelo: 动作感知神经曲面重建以应用于动态场景 [PDF](https://arxiv.org/pdf/2509.15892), [HTML](https://arxiv.org/abs/2509.15892)
### Authors
Mohamed Ebbed,Zorah Lähner
### Background
多视图视频中的动态场景重建仍然是计算机视觉中的一个基本挑战。尽管近期的神经表面重建方法在静态3D重建中取得了显著成果，但将这些方法扩展到动态场景以保持相当的质量带来了巨大的计算和表示挑战。现有的动态方法主要集中在新颖视图合成上，因此它们提取的网格往往比较嘈杂。即使是为了几何保真度的目标方法，也往往产生过于光滑的网格，这主要是由于问题的病态性质。
### Innovation
我们提出了一种新的框架，该框架扩展了静态3D重建方法NeuralAngelo，使其适用于动态场景，并实现了高度详细的动态重建。首先，我们使用NeuralAngelo从初始帧重建高质量的模板场景，然后结合优化跟踪模板的变形场以及基于时间序列进行细化。这种灵活的模板允许更新几何形状以包括无法通过变形场建模的变化，例如遮挡部分或拓扑结构的变化。相比之前最先进的方法，我们在ActorsHQ数据集上展示了更高的重建准确性。
### Conclusion
我们的方法在ActorsHQ数据集上实现了比以前最先进的方法更高的重建准确性，证明了其在动态场景重建中的优势。
## 535. `cs.CV` - 分析即插即用方法在成像逆问题中的应用 [PDF](https://arxiv.org/pdf/2509.15422), [HTML](https://arxiv.org/abs/2509.15422)
### Authors
Edward P. Chandler,Shirin Shoushtari,Brendt Wohlberg,Ulugbek S. Kamilov
### Background
即插即用先验（PnP）是通过将学习到的去噪器直接应用于图像域来解决成像逆问题的一种流行框架，去噪器被用作自然图像的一种隐式先验。标准PnP方法中，这一去噪器是直接在图像域上进行操作。这篇文章则提出了一个新的研究方向，即在图像的变换域（如梯度域）上施加先验，而不是直接在图像上。
### Innovation
文章提出了两种基于梯度域的即插即用方法：一种是基于半二次分裂（APnP-HQS）的算法，另一种是基于交替方向乘子法（APnP-ADMM）的算法。这种方法是在传统的PnP框架上引入了梯度域先验，将其作为分析先验的一种扩展，同时在图像重建算法中利用了这种梯度域先验。
### Conclusion
通过对模糊图像恢复和超分辨率的实验验证，文章证明了这种梯度域PnP方法在性能上与传统的基于图像域的PnP方法相当。
## 536. `cs.CV` - Kuramoto Orientation Diffusion Models [PDF](https://arxiv.org/pdf/2509.15328), [HTML](https://arxiv.org/abs/2509.15328)
### Authors
Yue Song,T. Anderson Keller,Sevan Brodjian,Takeru Miyato,Yisong Yue,Pietro Perona,Max Welling
### Background
现有的生成模型难以捕捉诸如指纹和纹理等拥有定向一致性模式的图像，这些问题通常基于各向同性的欧几里得扩散方法难以有效建模。为了解决这些问题，本文借鉴生物系统中的相位同步，在扩散过程中引入了Kuramoto动态，实现定向图像的生成。Kuramoto模型在神经和物理系统中被用来捕捉振荡器间的同步现象，这种现象被重新用作生成结构化图像时的一个诱导偏差。这个框架中的前向过程通过全局或局部耦合振荡器的交互和对全局参考相位的吸引逐步将数据压缩到低熵的Von Mises分布，反转动态过程则重建多样化的相位模式。这种方法在扩散的过程中实现了结构化破坏，并通过逐步提高全球一致性从而深入到微尺度细节，从而生成高质量的图像。为了应对循环几何结构，本文使用了包裹的高斯转换核和周期性感知网络来处理数据的空间结构。这种方法在一般图像基准测试和方向密集的图像（如指纹和纹理）的数据集上取得了有竞争力的性能，显著提高了生成质量。这项工作展示了仿生同步动力学作为生成建模中的结构先验的巨大潜力。
### Innovation
本文提出了一种基于Kuramoto动力学的分数生成模型，用于生成方向丰富的图像，如指纹和纹理。该方法通过同步和反同步的机制，首次在生成模型中利用相位同步现象，实现了结构化图像的生成。模型通过全局和局部耦合的方法，逐步降低数据的熵，生成低熵的Von Mises分布。反向过程中重新生成多样化的图案，通过学习的分数函数逆转扩散动力学过程。此外，该方法专门处理了循环几何结构，使用了包裹的高斯转换核和周期性感知网络。这项创新提高了在方向密集数据集上的生成质量。
### Conclusion
本工作展示了基于生物相位同步现象的Kuramoto扩散模型在生成方向丰富的图像上的巨大潜力。通过一系列实验验证，证明了该方法在一般图像和方向密集数据集上的有效性，显著提升了生成质量。这项工作为生成模型提供了新的结构化先验，有望在更复杂和多样化的图像生成任务中取得突破性进展。
## 537. `cs.CV` - CoReVLA：穿越长尾情况的两端集成自动驾驶框架，通过收集和改进实现 [PDF](https://arxiv.org/pdf/2509.15968), [HTML](https://arxiv.org/abs/2509.15968)
### Authors
Shiyu Fang,Yiming Cui,Haoyang Liang,Chen Lv,Peng Hang,Jian Sun
### Background
自动驾驶（AD）系统取得了显著进展，但在长尾、关键安全场景中的表现仍然有限。这些罕见的情况导致了不成比例的事故。视觉-语言-动作（VLA）模型具有强大的推理能力，为解决这一问题提供了潜在的解决方案，但它们的有效性受限于高质量数据的缺乏以及在这种条件下的低效学习。
### Innovation
本文提出了CoReVLA，这是一种持续学习的端到端自动驾驶框架，通过数据收集和行为改进的双阶段过程提高长尾场景中的性能。首先，模型在开源驾驶问答数据集上联合微调，以获取驾驶场景的基础理解。然后，在CAVE仿真平台上部署CoReVLA，收集司机接管数据，通过这种方法收集到的每个接管事件表示CoReVLA无法可靠处理的长尾场景。最后，使用直接偏好优化（DPO）对模型进行改进，使其能够直接从人类偏好中学习，从而避免由精心设计的奖励引起的奖励作弊。
### Conclusion
广泛的开环和闭环实验表明，所提出的CoReVLA模型能够准确感知驾驶场景并做出适当决策。在Bench2Drive基准测试中，CoReVLA的驾驶分数（DS）为72.18，成功率（SR）为50%，在长尾、关键安全的场景下，其性能优于最先进的方法，分别7.96 DS和15% SR。此外，案例研究显示，模型利用过去的接管经验不断提高其在相似故障场景中的性能。
## 538. `cs.CV` - DPC-QA Net: 一种用于组织病理图像的无参考双流感知和细胞质量评估网络 [PDF](https://arxiv.org/pdf/2509.15802), [HTML](https://arxiv.org/abs/2509.15802)
### Authors
Qijun Yang,Boyang Wang,Hujun Yin
### Background
可靠的全视野显微成像（WSI）依赖于高质量的图像，然而染色伪影、焦距模糊和细胞退化在WSI中常见。为了提高WSI的质量，该研究开发了一个无参考双流网络DPC-QA Net，结合了基于小波的全局差异感知和通过Aggr-RWKV模块从核和膜嵌入中进行的细胞质量评估。该模型能够准确检测染色、膜和核问题，并与可用性得分高度一致；在LIVEC和KonIQ数据集上，其性能优于现有的无参考图像质量评估模型，还展示了预测的质量和细胞识别准确度之间的强正相关关系，有助于WSI区域的预筛选，适用于计算病理学的研究。
### Innovation
提出了一种无参考的双流网络DPC-QA Net，结合全局差异感知和细胞质量评估，通过Aggr-RWKV模块利用交叉注意力融合和多项损失函数来对齐感知和细胞信号，从而更准确地检测WSI质量问题。该模型在多个数据集上表现优异，优于现有技术，且与细胞识别准确度具有高度相关性，可作为WSI质量管理的工具。
### Conclusion
该研究提出了一种先进的无参考双流质量评估网络DPC-QA Net，它能够精确检测WSI中的染色、膜和核问题，并且在多个评估指标上优于现有技术。预测的质量与细胞识别的准确性之间存在显著正相关关系，使得该模型可以在计算病理研究中用于预筛选WSI的高价值区域。
## 539. `cs.CV` - QWD-GAN: Quality-aware Wavelet-driven GAN for Unsupervised Medical Microscopy Images Denoising [PDF](https://arxiv.org/pdf/2509.15814), [HTML](https://arxiv.org/abs/2509.15814)
### Authors
Qijun Yang,Yating Huang,Lintao Xiang,Hujun Yin
### Background
图像去噪在生物医学和显微镜成像中起着至关重要的作用，尤其是在获取宽场荧光标记图像时。该任务面临着多方面的挑战，包括成像条件的限制、复杂的噪声类型、算法的适应性和临床应用的需求。尽管许多基于深度学习的去噪技术展现了良好的效果，但在保留图像细节、增强算法效率和提高临床可解释性方面仍需改进。
### Innovation
本文提出了一种基于生成对抗网络（GAN）架构的无监督图像去噪方法。该方法引入了基于小波变换的多尺度自适应生成器，并结合了双分支判别器，该判别器整合了差异感知特征图和原始特征。实验结果表明，该模型在多个生物医学显微镜图像数据集上的去噪性能达到了最先进的水平，特别在保持高频信息方面表现出色。此外，双分支判别器可以无缝地与各种GAN框架兼容。提出的基于质量感知和小波驱动的GAN去噪模型被称为QWD-GAN。
### Conclusion
提出的QWD-GAN模型在保持图像高频率信息方面表现卓越，并且其高质量、小波驱动的判别器可以与多种GAN框架无缝兼容，为生物医学显微镜图像的无监督去噪提供了新的解决方案。
## 540. `cs.CV` - FMD-TransUNet：基于频率域多轴表示学习和双注意力机制的腹部多器官分割 [PDF](https://arxiv.org/pdf/2509.16044), [HTML](https://arxiv.org/abs/2509.16044)
### Authors
Fang Lu,Jingyu Xu,Qinxiu Sun,Qiong Lou
### Background
腹部多器官的精确分割对临床应用至关重要。尽管已经开发出了大量的基于深度学习的自动分割方法，但它们在分割小、不规则或解剖结构复杂的器官时仍然存在困难。现有方法大多集中在空间域分析上，忽略了频率域表示的协同潜力。这对于提高腹部多器官分割的准确性具有重要意义，但目前的方法无法完全解决上述问题和挑战。
### Innovation
提出了一个名为FMD-TransUNet的新型框架，通过将Multi-axis External Weight Block (MEWB) 和改进的双注意力模块（DA+）整合到TransUNet框架中。MEWB可以从多轴频率域提取特征，同时捕捉全局解剖结构和局部边界细节，提供空间域表示的补充信息。DA+模块利用深度可分离卷积并结合空间和通道注意力机制来增强特征融合，减少冗余信息，并减小编码器和解码器之间语义差距。与基线模型相比，FMD-TransUNet在Synapse数据集上的平均DSC提高了3.84%，平均HD减少了15.34毫米，显著提升了腹部多器官分割的准确性。
### Conclusion
实验结果表明，FMD-TransUNet在腹部多器官分割方面具有显著效果，证实了该框架的有效性，能提高分割的准确性和减少误差。
## 541. `cs.CV` - 隐空间分区网络：生成建模、表征学习和分类的统一原则 [PDF](https://arxiv.org/pdf/2509.15591), [HTML](https://arxiv.org/abs/2509.15591)
### Authors
Zinan Lin,Enshu Liu,Xuefei Ning,Junyi Zhu,Wenyu Wang,Sergey Yekhanin
### Background
生成建模、表示学习和分类是机器学习中的三个核心问题，但它们的最新解决方案往往是分离的。本文探讨了是否可以通过一个统一的原则来解决这三个问题。这样的统一可以简化机器学习流水线并促进不同任务之间更大的协同作用。
### Innovation
介绍了隐空间分区网络（LZN）作为实现这一目标的一步。LZN的核心在于创建一个共享的高斯隐空间，可以编码所有的任务信息。每个数据类型（如图像、文本、标签）都有一个编码器将样本映射到不同的隐空间区间，一个解码器将隐变量映射回数据。机器学习任务可以由这些编码器和解码器组成。LZN在增强现有模型、解决独立任务以及同时解决多个任务方面都展示了潜力。
### Conclusion
LZN首先提升了现有的图像生成模型，在CIFAR10上的FID从2.76降低到2.59。其次，LZN在未使用辅助损失函数的情况下独立解决了无监督表示学习任务，并在ImageNet下游线性分类上超过了SoTA方法MoCo和SimCLR，分别提高了9.3%和0.2%。最后，LZN可以通过使用图像和标签编码器/解码器同时解决两种任务的设计，在CIFAR10上达到了SoTA分类准确性，并且代码和训练模型可在指定的网址上获取。
## 542. `cs.CV` - PRISM: 基于测量条件扩散先验的概率鲁棒逆解决问题方法 [PDF](https://arxiv.org/pdf/2509.16106), [HTML](https://arxiv.org/abs/2509.16106)
### Authors
Yuanyun Hu,Evan Bell,Guijin Wang,Yu Sun
### Background
扩散模型现在常用于计算成像中的逆问题。然而，大多数基于扩散的逆问题求解器需要知道前向算子的完整信息才能使用。
### Innovation
提出了一种基于测量条件扩散先验的概率和鲁棒逆问题求解器（PRISM），通过将强大的测量条件扩散模型集成到理论上合理的原则后验采样方案中，实现了技术进步。
### Conclusion
在盲图像去模糊实验中证实了该方法的有效性，显示了PRISM在图像和模糊核恢复方面优于最先进的基线方法的优越性能。
## 543. `cs.CV` - 超越像素：通过层次特性和基本模型改进LIME [PDF](https://arxiv.org/pdf/2403.07733), [HTML](https://arxiv.org/abs/2403.07733)
### Authors
Patrick Knab,Sascha Marton,Christian Bartelt
### Background
LIME（局部可解释的模型无偏解释）是一种流行的解释模型框架，用于揭示视觉机器学习模型的决策过程。该技术使用图像分割方法来识别固定区域以计算特征重要性分数作为解释。然而，图像分割质量较差会削弱解释效果，从而降低解释的重要性，影响整体的可解释性。
### Innovation
该文提出了DSEG-LIME框架，包括：i) 通过基础模型集成实现数据驱动的分割，以生成人类认可的功能；ii) 在层次分割过程中提供用户引导的颗粒度。研究表明，DSEG-LIME在多个XAI指标上优于其他模型，并且改进了解释与人类认可的概念的一致性。
### Conclusion
研究成果表明，DSEG-LIME能够在预训练的ImageNet模型上实现更高的性能，通过改进图像分割来增强LIME的解释效果，并使其更加贴近人类理解的概念。
## 544. `cs.CV` - 从数据到诊断：一个全面的大骨髓数据集和儿童白血病预测的AI方法 [PDF](https://arxiv.org/pdf/2509.15895), [HTML](https://arxiv.org/abs/2509.15895)
### Authors
Henning Höfener(1),Farina Kock(1),Martina Pontones(2),Tabita Ghete(2 and 3),David Pfrang(1),Nicholas Dickel(4),Meik Kunz(4),Daniela P. Schacherer(1),David A. Clunie(5),Andrey Fedorov(6),Max Westphal(1),Markus Metzler(2 and 3 and 7) ((1) Fraunhofer Institute for Digital Medicine MEVIS, Bremen, Germany, (2) Department of Pediatrics and Adolescent Medicine, University Hospital Erlangen, Erlangen, Germany, (3) Bavarian Cancer Research Center (BZKF), Erlangen, Germany, (4) Medical Informatics, Friedrich-Alexander University of Erlangen-Nürnberg, Erlangen, Germany, (5) PixelMed Publishing LLC, Bangor, PA, USA, (6) Department of Radiology, Brigham and Women's Hospital and Harvard Medical School, Boston, MA, USA, (7) Comprehensive Cancer Center Erlangen-EMN, Erlangen, Germany)
### Background
白血病的诊断主要依赖于手工显微镜分析骨髓形态，同时结合其他实验室参数，这一过程复杂且耗时。尽管已经提出了人工智能（AI）解决方案，但大多数AI方案都仅使用私有数据集，并且只覆盖诊断管道的部分环节。因此，研究团队提供了一个规模大、质量高、公开可用的白血病骨髓数据集，涵盖了从细胞检测到诊断的整个诊断过程。该数据集包含246名儿童病患的诊断、临床和实验室数据，超过40,000个带有边界框注释的细胞，以及超过28,000个具有高质量类标签的细胞，使其成为市场上最全面的数据集之一。
### Innovation
该团队提出了一个大尺度、高质量的公开数据集，涵盖了白血病诊断的完整流程。他们进一步提出的方法可用于细胞检测、细胞分类和诊断预测。基于该数据集进行的AI模型评估显示，细胞检测的平均准确率为0.96，细胞分类的受试者操作特征曲线下面积为0.98，33类细胞分类的F1分数为0.61，以及根据预测的细胞计数进行诊断预测的平均F1分数为0.90。这些方法展示了在辅助诊断中使用AI的潜力，并且数据集将促进该领域的进一步研究和发展，最终有助于提高诊断的精确度和患者的治疗结果。
### Conclusion
提出的AI方法对于辅助诊断具有实际应用价值，而该数据集将促进该领域进一步的研究和发展，最终为更精确的诊断和改进的患者治疗结果做出贡献。
## 545. `cs.CV` - MTS-DMAE: 双掩码自编码器在无监督多元时间序列表示学习中的应用 [PDF](https://arxiv.org/pdf/2509.16078), [HTML](https://arxiv.org/abs/2509.16078)
### Authors
Yi Xu,Yitian Zhang,Yun Fu
### Background
无监督多元时间序列（MTS）表示学习旨在从原始序列中提取紧凑且信息丰富的表示，无需依赖标签，以实现多种下游任务的高效转移。现有的方法主要依赖标签数据，但在很多实际应用场景中，标签数据难以获得或成本高昂。因此，开发一种能够在没有标签的情况下有效利用时间序列数据的方法具有重要意义。
### Innovation
本文提出了一种新的双掩码时间序列模型框架——双掩码自编码器（Dual-Masked Autoencoder，DMAE），用于无监督多元时间序列表示学习。DMAE定义了两个互补的预训练任务：一是根据可见属性重建掩码值；二是通过教师编码器指导预测掩码特征的潜在表示。此外，还引入了特征级别的对齐约束，以鼓励预测的潜在表示与教师的输出对齐。通过联合优化这些目标，DMAE能够学习到时间上一致且语义丰富的表示。
### Conclusion
广泛的分类、回归和预测任务评估表明，本文的方法在竞争性强基线方法上取得了稳定且优越的性能。
## 546. `cs.CV` - 3D Medical对象检测中缺失的一环：预训练的重要性 [PDF](https://arxiv.org/pdf/2509.15947), [HTML](https://arxiv.org/abs/2509.15947)
### Authors
Katharina Eckstein,Constantin Ulrich,Michael Baumgartner,Jessica Kächele,Dimitrios Bounias,Tassilo Wald,Ralf Floca,Klaus H. Maier-Hein
### Background
3D医学对象检测是准确电脑辅助诊断的关键部分，大规模预训练有潜力促进这一技术的发展，但与2D医学数据或自然图像相比，3D医学对象检测的预训练仍相对未被深入探索。现有方法主要依赖于2D医学数据或自然图像的预训练，未能充分利用3D体积信息。
### Innovation
首次系统研究了现有预训练方法如何集成到最先进的检测架构中，涵盖CNN和Transformer。结果显示，预训练能一致地提高不同任务和数据集上的检测性能，重建自监督预训练优于监督预训练，而对比预训练对3D医学对象检测无明显益处。
### Conclusion
预训练方法能有效提升3D医学对象检测任务的性能，重建自监督预训练表现更佳，而对比预训练则并无明显优势。代码已在公开平台发布。
## 547. `cs.CV` - SLaM-DiMM: 共享潜在模型在MRI中基于扩散的缺失模态合成 [PDF](https://arxiv.org/pdf/2509.16019), [HTML](https://arxiv.org/abs/2509.16019)
### Authors
Bhavesh Sandbhor,Bheeshm Sharma,Balamurugan Palaniappan
### Background
MRI扫描通常包含四种模态，包括T1加权（T1w与T1ce带对比剂增强）和T2加权（T2w）、流体衰减反转恢复（FLAIR）。这些不同模态提供的互补信息有助于模型学习更丰富、更具区分性的特征，从而有助于脑部解剖的理解。然而，临床实践中并非所有的MRI模态总是可用的，这使得缺失模态生成成为医学影像分析中的一个重要挑战。已有研究表明，通过利用扩散模型的力量，可以从其他可获取的模态中合成目标MRI模态，以克服这一问题。这项研究由SLaM-DiMM框架实现，该框架通过一个专门的结构一致性增强机制确保生成的图像既精确又具有结构一致性。
### Innovation
SLaM-DiMM框架使用扩散模型将任何一种目标MRI模态从其他可用的模态中生成出来。这项创新不仅能够生成高质量的图像，还通过专门的结构一致性增强机制确保了整个图像体素深度上的结构一致性。SLaM-DiMM在BraTS-Lighthouse-2025挑战赛数据集上的定性和定量评估表明，其在生成解剖上合理且结构上一致的结果方面非常有效。
### Conclusion
SLaM-DiMM产生的高保真图像在结构上是连贯的，并且在BraTS-Lighthouse-2025挑战赛数据集上的评估结果证明了其在合成解剖上合理且结构上一致的结果的有效性。开发的代码可以在指定的GitHub链接中获取。
## 548. `cs.CV` - 多模式检测中的重新校准方法以应对自主驾驶中的对齐偏差 [PDF](https://arxiv.org/pdf/2405.16848), [HTML](https://arxiv.org/abs/2405.16848)
### Authors
Zhihang Song,Dingyi Yao,Ruibo Ming,Lihui Peng,Danya Yao,Yi Zhang
### Background
在自主驾驶中，多模态对象检测因不同传感器提供的互补信息融合而取得了巨大突破。然而，先前的工作假设传感器（如LiDAR和摄像头）之间的融合校准必须非常精确，但实际上，车辆出厂后机械振动、道路颠簸和数据延迟可能导致校准偏差。由于缺乏对校准影响的研究，具有灵活校准依赖性的多传感器检测方法仍是一个关键目标。
### Innovation
本文提出了一种重新校准模型，以补偿检测任务中的对齐偏差。该模型将LiDAR点云、摄像头图像和初始校准矩阵作为输入，通过语义分割引导和自定义损失函数设计生成重新校准偏差。该模型可以在现有检测算法的基础上运行，提高检测鲁棒性和整体性能。
### Conclusion
本文建立了一种基础方法，用于在实际校准不确定性的情况下保持多模态感知系统的可靠性。通过系统评估EPNet++检测框架的灵敏度，证明即使是轻微的校准偏差也会严重影响性能。通过提出重新校准模型，研究人员提高了检测系统的鲁棒性，改善了对象检测的整体性能。
## 549. `cs.CV` - Img2CAD：通过VLM辅助条件因子化从图像逆向工程3D CAD模型 [PDF](https://arxiv.org/pdf/2408.01437), [HTML](https://arxiv.org/abs/2408.01437)
### Authors
Yang You,Mikaela Angelina Uy,Jiaqi Han,Rahul Thomas,Haotong Zhang,Yi Du,Hansheng Chen,Francis Engelmann,Suya You,Leonidas Guibas
### Background
从图像中逆向工程3D计算机辅助设计(CAD)模型对于许多下游应用（包括交互编辑、制造、建筑、机器人技术等）至关重要。任务的难点在于CAD输出和图像输入在表述上的巨大差异。CAD模型是精确的、程序化的构造，涉及顺序操作，结合离散命令结构与连续属性，这使得以端到端的方式学习和优化变得极具挑战性。同时，输入图像带来了固有的挑战，如光度变化和传感器噪声，使逆向工程过程复杂化。
### Innovation
本文提出了一种新颖的方法，条件因子化任务为两个子问题。首先，利用基础视觉-语言模型（VLMs）——微调后的Llama3.2，预测具有语义信息的全局离散基结构。其次，提出了TrAssembler，在给定含有语义的离散结构条件下，预测连续属性值。为支持TrAssembler的训练，构建了一个标注良好的CAD数据集，用于从ShapeNet获取普通对象。这种方法和数据展示了在野外将图像转换为CAD模型的重要初步步骤。
### Conclusion
本文的方法和数据展示了在野外将图像转换为CAD模型的重要初步步骤，并且提供了代码和数据供研究使用。
## 550. `cs.CV` - 导航超越捷径：从神经崩溃视角看无偏学习 [PDF](https://arxiv.org/pdf/2405.05587), [HTML](https://arxiv.org/abs/2405.05587)
### Authors
Yining Wang,Junjie Sun,Chenyue Wang,Mi Zhang,Min Yang
### Background
近年来的研究发现了一种被称为神经崩溃的现象，即当神经网络正确建立了特征空间与训练目标之间的关联时，其最后一层特征和分类器权重会坍缩成一个稳定且对称的结构。本文将神经崩溃的研究扩展到带有偏斜属性的有偏数据集。发现模型容易陷入捷径学习的陷阱，在训练初期形成一种偏斜的、未坍缩的特征空间，这种状况难以反转并限制了泛化能力。为了解决有偏分类的根本原因，本文借鉴了最近有关初级训练的启发，提出了一种无需额外训练复杂性的避免捷径学习框架。通过基于神经崩溃结构设计的捷径初级训练，模型被鼓励绕过简单的捷径并自然捕捉内在的关联。实验结果显示，我们的方法在训练中诱导了更好的收敛性，并在合成和现实世界有偏数据集上实现了最先进的泛化性能。我们的代码已公开。
### Innovation
提出了基于神经崩溃结构的避免捷径学习框架，通过设计基于神经崩溃结构的捷径初级训练，引导模型绕过简单的捷径，并自然地捕捉固有的关联。该方法诱导了更好的训练收敛性，并在有偏数据集上实现了最先进的泛化性能，无需额外的训练复杂性。
### Conclusion
我们的方法在训练中诱导了更好的收敛性，并在合成和现实世界有偏数据集上实现了最先进的泛化性能。通过设计基于神经崩溃结构的捷径初级训练，模型能够绕过简单的捷径并自然地捕捉固有的关联。
## 551. `cs.CV` - DiffusionNFT: 前向过程中的在线扩散强化学习 [PDF](https://arxiv.org/pdf/2509.16117), [HTML](https://arxiv.org/abs/2509.16117)
### Authors
Kaiwen Zheng,Huayu Chen,Haotian Ye,Haoxiang Wang,Qinsheng Zhang,Kai Jiang,Hang Su,Stefano Ermon,Jun Zhu,Ming-Yu Liu
### Background
在线强化学习（RL）在后训练语言模型中起着核心作用，但将其扩展到扩散模型上仍然具有挑战性，原因在于难以处理的似然问题。近期的一些工作尝试通过离散化反向采样过程来实现类似于GRPO的训练，但这些方法继承了一些基本的缺陷，如求解器限制、正反过程不一致等问题，以及与无分类指导（CFG）方法结合的复杂性。已有研究方向存在限制。
### Innovation
提出了Diffusion Negative-aware FineTuning（DiffusionNFT），这是一种新的在线RL范式，直接在扩散模型的前向过程中通过流匹配进行优化。DiffusionNFT通过对比正负样本生成来定义隐式策略改进方向，自然地将强化信号纳入监督学习目标。这种方式允许使用任意的黑盒求解器进行训练，无需估计似然，并且只需要清洁图像而非采样轨迹进行策略优化。与FlowGRPO相比，DiffusionNFT在直接对比中表现出更高的效率，最多可达25倍，并且在每种基准测试中极大地提升了SD3.5-Medium的表现。
### Conclusion
实验表明，DiffusionNFT在1000步内将GenEval得分从0.24提高到0.98，而FlowGRPO在5000多步加上额外的CFG应用后提高到0.95。通过利用多个奖励模型，DiffusionNFT显著提升了SD3.5-Medium在所有测试基准上的性能。
## 552. `cs.CV` - FOVAL：无需校准且适用于多样化眼动追踪数据的眼动聚焦深度估计 [PDF](https://arxiv.org/pdf/2408.03591), [HTML](https://arxiv.org/abs/2408.03591)
### Authors
Benedikt W. Hosp
### Background
准确的聚焦深度估计对于扩展现实(XR)、机器人技术和人机交互具有重要意义。然而，当前的方法严重依赖于特定用户的校准，限制了它们的扩展性和使用性。
### Innovation
我们引入了FOVAL，这是一种无需校准且具有主题不变特征工程和规范化相结合的时空序列模型的方法。FOVAL利用长短期记忆（LSTM）网络拓展时空序列，并表现出比Transformer、时序卷积网络(TCN)和CNN更好的性能，尤其在有限和嘈杂的眼动数据场景中。在使用三种基准数据集的不同交叉验证方法中，FOVAL展现了9.1 cm的平均绝对误差，且无需校准即可实现强泛化能力。我们进一步分析了不同个体间的变化和领域转移，为模型的鲁棒性和适应性提供了见解。
### Conclusion
FOVAL的可扩展性和准确性使其非常适合实际部署。
## 553. `cs.CV` - 通过在线反馈实现动态分类器自由扩散指引 [PDF](https://arxiv.org/pdf/2509.16131), [HTML](https://arxiv.org/abs/2509.16131)
### Authors
Pinelopi Papalampidi,Olivia Wiles,Ira Ktena,Aleksandar Shtedritski,Emanuele Bugliarello,Ivana Kajic,Isabela Albuquerque,Aida Nematzadeh
### Background
文本到图像的扩散模型中的分类器自由指导（CFG）是其基本组成部分，但其效果受限于使用静态指导尺度。这种‘一刀切’的方法无法应对不同提示的多样化需求；此前的解决方案，如基于梯度的纠正或固定启发式时间表，引入了额外的复杂性，并未能普遍适用。本文挑战了这种静态的范式，提出了一种动态CFG调度框架。该方法利用在线反馈，从通用和专门的小规模潜在空间评估中，如CLIP对对齐、判别器对保真度和人类偏好奖励模型，评估生成质量的每一步。根据这些反馈，执行贪婪搜索以为每个时间戳选择最优的CFG尺度，从而创建一个针对每个提示和样本量身定制的独特指导计划。在小规模模型和State-of-the-Art的Imagen 3上证实了该方法的有效性，显著提高了文本对齐、视觉质量、文本呈现和数值推理。当我们与默认的Imagen 3基线进行比较时，该方法的整体偏好胜率最高可达53.8%，对于着眼于特定能力如文本呈现的提示，增加至55.5%。这项工作表明，最优的指导计划是动态和提示依赖的，并提供了实现该目标的高效且通用的框架。
### Innovation
本文提出了一种动态CFG调度框架，利用在线反馈来评估每一步生成的质量，据此搜索并选择每个时间戳的最优CFG尺度，创建个性化的指导计划。这种方法显著提高了文本对齐、视觉质量、文本呈现和数值推理等方面的表现，与默认底线相比，整体偏好胜率最高可达53.8%，对于文本呈现等特定能力，可达55.5%。
### Conclusion
本文证明了最优的指导计划是动态和提示依赖的，并提供了实现该目标的高效且通用框架。这种动态CFG调度框架能够在生成过程中实时调整指导尺度，有效地提升了文本到图像扩散模型的效果。
## 554. `cs.CV` - CrackSCF：用于鲁棒高效结构性裂缝分割的轻量级级联融合网络 [PDF](https://arxiv.org/pdf/2408.12815), [HTML](https://arxiv.org/abs/2408.12815)
### Authors
Hui Liu,Chen Jia,Fan Shi,Xu Cheng,Mianzhao Wang,Shengyong Chen
### Background
精确地在像素级别分割结构裂缝仍然是一个主要障碍，现有方法未能将局部纹理与像素依赖性有效结合，常常导致分割结果碎片化且不完整。此外，这些方法的高参数量和高昂的计算需求阻碍了在资源受限的边缘设备上的实际部署。
### Innovation
我们提出了CrackSCF，这是一种轻量级级联融合裂缝分割网络，旨在实现稳健的裂缝分割并具备出色的计算效率。通过设计轻量级卷积模块（LRDS）取代所有标准卷积，本方法能够高效捕获局部模式并保持极小的计算足迹。为全面感知裂缝结构，采用轻量级长距离依赖提取器（LDE）捕获全局依赖性，通过阶梯级联融合模块（SCFM）智能地与局部模式统一，确保最终的分割图不仅在连续性上无缝且在细节上丰富。
### Conclusion
为了全面评估我们的方法，我们构建了具有挑战性的TUT基准数据集，并与五个其他公开数据集进行了评估。实验结果表明，CrackSCF方法在F1分数和mIoU上都优于现有的方法，在TUT数据集上实现了0.8382的F1分数和0.8473的mIoU，且仅需要4.79M个参数。
## 555. `cs.CV` - Combo：和谐共言的整体3D人体动作生成和高效自定义适应 [PDF](https://arxiv.org/pdf/2408.09397), [HTML](https://arxiv.org/abs/2408.09397)
### Authors
Chao Xu,Mingze Sun,Zhi-Qi Cheng,Fei Wang,Yang Liu,Baigui Sun,Ruqi Huang,Alexander Hauptmann
### Background
在现有的数据驱动生成过程中，3D人体动作的生成面临多个挑战。首先是输入端的挑战，生成模型不仅需要处理语音信号，还要处理诸如身份和情绪等字符指导信息，这不仅考验模型的学习能力，还会妨碍对不同指导条件的进一步适应。其次是输出端的挑战，整体人体动作主要由面部表情和身体动作组成，这些是内在相关的，但在当前的数据驱动生成过程中协调起来是非平凡的。
### Innovation
为了应对这些挑战，作者提出了一个名为Combo的新框架，该框架包含两个关键技术贡献。首先，提出了预训练策略，让模型对固定身份和中性情绪进行预训练，然后再在微调阶段加入自定义条件（身份和情绪），并利用新型X-Adapter进行参数高效微调。其次，设计了一个新颖的基于Transformer的DU-Trans模型，旨在将面部表情和身体动作的特征分离学习，并结合学习联合双向分布和直接预测综合系数。
### Conclusion
通过在BEAT2和SHOW数据集上的评估，结合了高质量动作生成和高效的身份情绪传递，证明了Combo的有效性。
## 556. `cs.CV` - G2D2: Gradient-Guided Discrete Diffusion for Inverse Problem Solving [PDF](https://arxiv.org/pdf/2410.14710), [HTML](https://arxiv.org/abs/2410.14710)
### Authors
Naoki Murata,Chieh-Hsin Lai,Yuhta Takida,Toshimitsu Uesaka,Bac Nguyen,Stefano Ermon,Yuki Mitsufuji
### Background
近期文献表明，基于连续变量训练的扩散模型被有效应用于解决逆问题。特别是在图像和运动生成等适用于离散压缩表示的模态中，具有离散潜码的离散扩散模型表现尤为出色。然而，这类模型的离散和非连续特性限制了它们在连续空间逆问题中的应用。
### Innovation
本文提出了一种新的方法，利用基于离散扩散的生成模型作为先验来解决线性逆问题。通过使用基于分类分布和连续松弛技术构建的变分分布近似真实的后验分布，并引入星状噪声过程来克服传统离散扩散模型中的吸状态缺陷。证明了该方法在GPU内存消耗较低的情况下，与连续扩散技术性能相当。
### Conclusion
通过使用变分分布，文中提出的方法克服了离散扩散模型在连续空间逆问题中的应用限制，并且在GPU内存消耗方面表现更佳。
## 557. `cs.CV` - MolParser: 在野化学结构图像的端到端视觉识别 [PDF](https://arxiv.org/pdf/2411.11098), [HTML](https://arxiv.org/abs/2411.11098)
### Authors
Xi Fang,Jiankun Wang,Xiaochen Cai,Shangqian Chen,Shuwen Yang,Haoyi Tao,Nan Wang,Lin Yao,Linfeng Zhang,Guolin Ke
### Background
近年来，化学领域的研究出版物和专利申请数量迅速增加，其中大多数关键信息都嵌入在分子结构图中，这使得大规模文献检索变得复杂，并限制了大型语言模型在生物、化学和制药领域的应用。现有的光学化学结构识别（OCSR）方法难以准确提取这些化学结构，尤其是在面对复杂和多样化的Markush结构、低质量的分子图像、差异化的绘图风格和噪声问题时，性能受到了极大限制。
### Innovation
本文提出了一种名为MolParser的全新端到端OCSR方法，能够有效而准确地从真实世界文档中识别化学结构，包括复杂的Markush结构。MolParser通过扩展的SMILES编码规则构建了有史以来最大的标注分子图像数据集MolParser-7M，并通过结合大量合成数据和通过主动学习方法从真实专利和科学文献中提取的数据进行训练。实验结果表明，MolParser在大多数情况下显著优于传统和基于学习的方法，具有更广泛的应用潜力。
### Conclusion
MolParser是一个公共可用的数据集和模型，已经被训练用于从真实世界的数据中高效而准确地识别和提取化学结构，为跨领域的研究和应用打开了新的可能性。
## 558. `cs.CV` - DAOcc: 3D Object Detection Assisted Multi-Sensor Fusion for 3D Occupancy Prediction [PDF](https://arxiv.org/pdf/2409.19972), [HTML](https://arxiv.org/abs/2409.19972)
### Authors
Zhen Yang,Yanpeng Dong,Jiayu Wang,Heng Wang,Lichao Ma,Zijian Cui,Qi Liu,Haoran Pei,Kexin Zhang,Chao Zhang
### Background
现有的多传感器融合方法主要依靠高分辨率图像和复杂网络来实现高性能，这在实际场景中的部署受到限制。此外，目前的多传感器融合方法主要集中在特征融合上，而忽略了对这些特征的有效监督策略。多传感器融合显著提高了3D语义占用预测的准确性和鲁棒性，这对于自动驾驶和机器人技术至关重要。
### Innovation
本文提出了一种名为DAOcc的新型多模态占用预测框架，它利用3D物体检测监督来辅助实现更高性能，使用了部署友好的图像主干网和实际的输入分辨率。此外，还引入了BEV视图范围扩展策略以减轻由于较低图像分辨率引起的性能下降。DAOcc在Occ3D-nuScenes和Occ3D-Waymo基准测试中达到了新的最佳结果，并仅使用了ResNet-50主干和256*704输入分辨率就大幅超越了之前的最佳方法。优化后，DAOcc在NVIDIA RTX 4090 GPU上达到了104.9 FPS并保持了54.2 mIoU。
### Conclusion
广泛的实验表明，DAOcc在占用预测方面具有更高的性能，并且可以在保持良好性能的同时降低成本和复杂性。
## 559. `cs.CV` - CADSpotting: Robust Panoptic Symbol Spotting on Large-Scale CAD Drawings [PDF](https://arxiv.org/pdf/2412.07377), [HTML](https://arxiv.org/abs/2412.07377)
### Authors
Fuyi Yang,Jiazuo Mu,Yanshun Zhang,Mingqian Zhang,Junxiong Zhang,Yongjian Luo,Lan Xu,Jingyi Yu,Yujiao Shi,Yingliang Zhang
### Background
现有的方法在处理建筑CAD图纸中的符号多样性和规模变化以及重叠元素时常常表现不佳，通常需要依赖附加特征（如基本类型或图层）来提高性能。
### Innovation
CADSpotting通过密集采样的点来表示基本元素，并使用统一的3D点云模型进行鲁棒特征学习，从而克服了现有方法的这些挑战。此外，还提出了一种新的滑动窗口聚合（SWA）技术，结合加权投票和非极大值抑制（NMS）来实现大规模图纸中的准确分割。另外，引入了LS-CAD大规模数据集，包含45个精细标注的地平面图，总面积约为1000平方米，比之前的标准更大。
### Conclusion
在FloorPlanCAD和LS-CAD上的实验表明，CADSpotting显著优于现有方法。同时，通过这种方式，可以直接从原始CAD输入自动实现参数化的3D室内重建，展示了其实际价值。
## 560. `cs.CV` - 评估图像质量度量对仿射变换的不变性 [PDF](https://arxiv.org/pdf/2407.17927), [HTML](https://arxiv.org/abs/2407.17927)
### Authors
Nuria Alabau-Bosque,Paula Daudén-Oliver,Jorge Vila-Tomás,Valero Laparra,Jesús Malo
### Background
通常，主观的图像质量度量是在含有模拟数字媒体中可能出现的各种扭曲的数据集中，根据其与人类意见的相关性来评估的。然而，这些度量可能忽视了一些 affine 变换，这些变换可能更好地代表了自然条件下图像的变化。人类对这些自然变换具有更大的不变性，相对于数字变换而言。现有的一些图像质量度量方法可能无法充分反映人类视觉系统的这些特性。
### Innovation
本文提出了一种方法来评估任何图像质量度量，通过考察其对 affine 变换（包括旋转、平移、缩放和光谱光照变化）的不变性。这种方法包括两个关键步骤：（1）确定衡量每个度量的共同表征中的一系列视觉阈值；（2）将该度量的差异值与其共同表征进行转换。共同表征基于现成可用的图像质量数据库的主观评级。通过精确的心理物理学方法确定这种共同表征中的阈值（第一个步骤），第二步骤则可以轻松地针对任何度量调整。试验结果显示，一些现有度量无法达到人类般的不变性阈值（即“视觉阈值”），这表明仅通过预测通用失真可见性的模型可能忽略了人类视觉系统的其他特性，如不变性或视觉阈值。
### Conclusion
该方法已被测试并应用于一些稳定存在的度量方法，结果发现没有一种度量表现出人类般的视觉阈值。这表明，仅将模型调优以预测通用失真可见性可能忽略了人类视觉系统的其他特性。该方法的数据和代码是公开的，可用于测试其他度量。
## 561. `cs.CV` - 基于扩散的透明和反射物体深度修复 [PDF](https://arxiv.org/pdf/2410.08567), [HTML](https://arxiv.org/abs/2410.08567)
### Authors
Tianyu Sun,Dingchang Hu,Yixiang Dai,Guijin Wang
### Background
透明和反射物体因其独特的视觉和光学特性，给3D成像技术带来了重大挑战。传统的RGB-D相机在处理这类物体时，难以准确捕捉到它们的真实深度值。
### Innovation
该论文提出了一种名为DITR的基于扩散的深度填补框架，专门针对透明和反射物体。DITR框架包含两个阶段：区域提议阶段和深度填补阶段。该模型能够动态分析光学和几何深度的损失，并自动进行修复。
### Conclusion
实验结果表明，DITR在透明和反射物体的深度填补任务中表现出高度的有效性和较强的适应性。
## 562. `cs.CV` - Screener: 自主监督医学CT图像病理分割 [PDF](https://arxiv.org/pdf/2502.08321), [HTML](https://arxiv.org/abs/2502.08321)
### Authors
Mikhail Goncharov,Eugenia Soboleva,Mariia Donskova,Daniil Ignatyev,Mikhail Belyaev,Ivan Oseledets,Marina Munkhoeva,Maxim Panov
### Background
在3D医学图像中准确检测所有病理发现仍然是一个显著的挑战，因为监督模型只能检测现有数据集中标注的少数几种病理学类别。现有的密度基于的无监督视觉异常分割框架受到监督预训练的限制。
### Innovation
本文提出了两个关键创新点：(1) 密集自主监督学习进行特征提取，消除监督预训练的需求；(2) 学习的、掩码不变的密集特征作为条件变量，替代手工构建的位置编码。训练数据集包含超过30,000个未标注的3D CT体积，自主监督模型Screener在四个大规模测试数据集上表现优于现有方法，涵盖了1,820个具有不同病理的扫描。
### Conclusion
Screener在监督微调情况下超过了现有的自主监督预训练方法，成为病理分割的前沿基础。代码和预训练模型将公开可用。
## 563. `cs.CV` - iCBIR-Sli: 2D切片嵌入的可解释内容基于图像检索 [PDF](https://arxiv.org/pdf/2501.01642), [HTML](https://arxiv.org/abs/2501.01642)
### Authors
Shuhei Tomoshige,Hayato Muraki,Kenichi Oishi,Hitoshi Iyatomi
### Background
当前的脑部MRI图像搜索方法依赖于文本检索，突显了内容基于图像检索(CBIR)系统的重要性。直接将3D脑部MRI图像应用于机器学习模型可以有效地学习脑部结构，但构建通用模型需要大量的训练数据。虽然存在考虑深度方向并使用连续2D切片的模型，这些模型在3D数据的分割和分类任务上已经显示出成功，但仍存在一些问题。具体来说，使用一般的2D切片可能会忽视病理特征，并且在深度方向信息上的断续特征也可能被忽略。此外，到目前为止，还没有尝试开发一个实用的CBIR系统，该系统可以保留整个脑部结构信息，因此提出了iCBIR-Sli方法，基于一系列2D切片实现可解释的CBIR。
### Innovation
iCBIR-Sli首次利用一系列2D切片，通过有效地聚合切片信息，实现了高维保真度的低维表示，具有高可用性、稳健性、互操作性，这对于有效的CBIR至关重要。iCBIR-Sli在五种公开的脑部MRI数据集（ADNI2/3，OASIS3/4，AIBL）的检索评估实验中展示了顶级的检索表现（宏F1得分=0.859），其性能与专门设计用于分类的现有深度学习模型相当，无需外部分类器。此外，该方法通过清晰地识别与所搜索疾病相关的脑区域，提供了高度的可解释性。
### Conclusion
iCBIR-Sli在多项研究中展示了优异的性能，其有效性和可解释性使其成为脑部MRI图像检索的一个重要贡献。
## 564. `cs.CV` - 将空间时间视图变换器集成到校园环境高分辨率热应力预测的数字双胞胎中 [PDF](https://arxiv.org/pdf/2502.09657), [HTML](https://arxiv.org/abs/2502.09657)
### Authors
Wenjing Gong,Xinyue Ye,Keshu Wu,Suphanut Jamonnak,Wenyu Zhang,Yifan Yang,Xiao Huang
### Background
极端热事件因气候变化加剧，对城市弹性和规划构成了重大挑战。本研究表明，通过将空间时间视图变换器（ST-ViT）模型集成到气候响应型数字孪生框架中，提高了热应力预测和决策支持的能力。
### Innovation
本研究引入了一种气候响应型数字孪生框架，使用空间时间视图变换器（ST-ViT）模型，结合高分辨率物理模型模拟和空间气象数据，精细预测人类热应力。这种数字孪生框架为城市规划者和利益相关者提供了高效的数据驱动见解，支持有针对性的热缓解策略，并推动气候适应性城市设计。
### Conclusion
基于田纳西州一个校园的案例研究，展示了高等级细节的热应力预测能力，为更广泛和多样化的城市环境提供了应用基础。
## 565. `cs.CV` - 在与西班牙语老年群体进行视频访谈中探索情感计算模型 [PDF](https://arxiv.org/pdf/2501.16870), [HTML](https://arxiv.org/abs/2501.16870)
### Authors
Josep Lopez Camunas,Cristina Bustos,Yanjun Zhu,Raquel Ros,Agata Lapedriza
### Background
理解老年群体的情感信号对于设计支持他们福祉的虚拟助手至关重要。然而，现有的情感计算模型常常面临局限性，包括对老年群体数据集的不足，特别是非英语群体的数据集较少，以及用于训练模型的数据集多为年轻且同质化的群体。本研究利用老年群体与人或虚拟角色互动的视频，评估了最先进的模型，并引入了一个西班牙语老年群体在人机视频访谈中的新型数据集。
### Innovation
本研究创新之处在于，首次使用老年西班牙语群体的视频访谈数据，评估了不同情感计算模型的性能，包括面部表情识别、文本情感分析和微笑检测。研究揭示了模型预测与人工标注之间的一致性较低，跨模态的一致性较差，以及个体间的情感信号差异显著。这表明通用的情感感知模型存在局限性，需要考虑个人差异和文化特征。
### Conclusion
研究结果表明，现有的情感计算模型在处理老年群体的情感信号方面存在局限性，预测结果与人工标注之间、跨模态之间以及个体之间的差异较大。未来的研究需要更多地考虑个人差异和文化多样性，以提高情感计算模型的准确性和适用性。
## 566. `cs.CV` - SCoT: 平直一致轨迹用于预训练扩散模型温习 [PDF](https://arxiv.org/pdf/2502.16972), [HTML](https://arxiv.org/abs/2502.16972)
### Authors
Zhangkai Wu,Xuhui Fan,Hongyu Wu,Longbing Cao
### Background
预训练的扩散模型常用于从随机噪声生成干净数据（如图像），形成噪声和对应干净图像的配对。这些预训练模型的温习可以被视为构建先进的轨迹以加快采样的过程。例如，一致性模型温习通过建立一致的投影函数来调节轨迹，尽管采样效率仍是一个关注点。校正流方法强制执行直线轨迹以实现更快的采样，但依赖数值常微分方程求解器，可能引入近似误差。
### Innovation
本文提出了平直一致轨迹（SCoT）模型，该模型结合了两种方法的优点，同时实现快速采样、一致性和直性的双重属性。通过同时调节SCoT映射的梯度为常数和保证轨迹一致性，SCoT获得了优异的效果和效率。
### Conclusion
通过广泛的经验实验证明了SCoT的效用和效率，进一步展示了该模型在预训练扩散模型温习中的潜力和应用场景。
## 567. `cs.CV` - 通过学习评分模型驱动的遥感视觉语言数据整理 [PDF](https://arxiv.org/pdf/2503.00743), [HTML](https://arxiv.org/abs/2503.00743)
### Authors
Dilxat Muhtar,Enzhuo Zhang,Zhenshi Li,Feng Gu,Yanglangxing He,Pengfeng Xiao,Xueliang Zhang
### Background
视觉语言模型(VLMs)在通过语言指导的语义解释遥感图像方面展现了巨大的潜力，但这些模型的有效性高度依赖于高质量的图像-文本训练数据，这些数据能捕捉到视觉内容与语言描述之间的丰富语义关系。然而，遥感图像不像普通自然图像那样，可以从互联网数据中获取大规模的交互式图像-文本对，这使得数据收集极具挑战性。尽管当前方法主要依赖规则基础的方法或旗舰视觉语言模型进行数据合成，但缺乏一个系统性的自动化评分框架来评估合成的遥感视觉语言数据的质量。
### Innovation
本文提出了一种新型评分模型，该模型在大规模的遥感图像-文本偏好数据上进行训练，用于自动化评估这样合成的遥感视觉语言数据的质量。实验结果表明，使用评分模型排名前30%的数据微调CLIP或更先进的VLMs（如Qwen2-VL）比全数据微调和基于CLIP分数的排名方法都具有更高的准确率。此外，我们展示了评分模型在强化学习（RL）训练和最佳-次运行时缩放（BoN）方面的应用，显著提高了VLM在遥感任务中的性能。本文代码、模型和数据集将公开提供。
### Conclusion
我们的工作填补了遥感视觉语言数据合成质量评估的空白，通过大规模的遥感视觉语言偏好数据训练评分模型，实现了对VLMs在遥感任务中性能的显著改进。同时，代码、模型和数据集将公开发布，推动该领域的进一步研究和发展。
## 568. `cs.CV` -  Advances in Multimodal Adaptation and Generalization: From Traditional Approaches to Foundation Models [PDF](https://arxiv.org/pdf/2501.18592), [HTML](https://arxiv.org/abs/2501.18592)
### Authors
Hao Dong,Moru Liu,Kaiyang Zhou,Eleni Chatzi,Juho Kannala,Cyrill Stachniss,Olga Fink
### Background
在实际场景中，实现领域适应和泛化是一项具有挑战性的任务，因为模型必须适应或在未知目标分布上泛化。此外，将这些能力扩展到未见过的多模态分布，如多模态领域适应和泛化，由于不同模态的特点而更具挑战性。近年来，多模态领域适应和泛化在动作识别和语义分割等应用中取得了显著进展。大规模预训练多模态基础模型的出现，例如CLIP，启发了利用这些模型提高适应性和泛化性能的研究，或将其应用于下游任务。
### Innovation
本文提供了一种从传统方法到基础模型的全面综述，涵盖了多模态领域适应、多模态测试时适应、多模态领域泛化、借助多模态基础模型的领域适应和泛化以及多模态基础模型的适应。每个主题都正式定义了问题并详细回顾了现有方法，分析了相关数据集和应用，突出了开放挑战和未来研究方向，并维护了一个最新的文献列表。
### Conclusion
文章综述了多模态领域适应和泛化的最新进展，从传统方法到基础模型，涵盖了领域适应、测试时适应、领域泛化、借助基础模型的领域适应和泛化以及基础模型的适应，并指出未来研究方向。
## 569. `cs.CV` - FLOAT: 基于流匹配生成的音频驱动对话肖像运动潜在流 [PDF](https://arxiv.org/pdf/2412.01064), [HTML](https://arxiv.org/abs/2412.01064)
### Authors
Taekyung Ki,Dongchan Min,Gyeongsu Chae
### Background
随着基于扩散的生成模型的快速发展，肖像图像动画已经取得了显著成果。但是，由于其迭代采样的特性，肖像图像动画在生成时间一致的视频以及快速采样方面仍然面临挑战。
### Innovation
本文提出了一种名为FLOAT的方法，这是一种基于流匹配生成模型的音频驱动对话肖像视频生成方法。该方法通过采用学习到的正交运动潜在空间，实现了对时间一致运动的有效生成和编辑。作者引入了一种基于变换器的向量场预测器，并采用了有效的时间帧条件机制来实现这一目标。此外，该方法还支持语音驱动的情感增强，使表达性运动的自然融入成为可能。
### Conclusion
大量的实验表明，与现有的音频驱动对话肖像方法相比，该方法在视觉质量、运动保真度和效率方面均表现出色。
## 570. `cs.CV` - NFL-BA: 在动态照明下用于SLAM的近场光源束调整 [PDF](https://arxiv.org/pdf/2412.13176), [HTML](https://arxiv.org/abs/2412.13176)
### Authors
Andrea Dunn Beltran,Daniel Rho,Marc Niethammer,Roni Sengupta
### Background
传统的SLAM系统通常假设静态且远距离的照明，在实际应用场景中，如内窥镜检查（内窥镜）、地下机器人技术和倒塌环境中的搜索与救援等，需要在缺乏外部光源的情况下，使用与摄像头同位置的光源进行工作。在这类场景中，动态近距离照明会导致强烈的视角依赖阴影，严重降低SLAM性能。本研究针对这一问题来进行探讨和解决方案的设计。在这些情况下，使用动态近距离照明使得SLAM性能显著恶化，因此需要一个新方法来缓解这一问题。因此，作者提出了一个新的方法，称为NFL-BA，用于处理在动态近距离照明环境下进行的使用神经渲染的SLAM系统中的场景建模问题。NFL-BA将近距离光源作为束调整损失的一部分进行建模，从而能够改善被动态照明捕捉到的场景的表现。
### Innovation
作者提出了一种新的方法——近场光源束调整损失（Near-Field Lighting Bundle Adjustment Loss, NFL-BA），将近距离光源作为束调整损失的一部分进行建模。将NFL-BA引入基于神经渲染的SLAM系统，无论是隐式的还是显式的场景表示。实验表明，用NFL-BA替换SLAM的Photometric Bundle Adjustment损失可显著提高摄像头追踪性能。例如，对于MonoGS系统，性能提高了37%，对于EndoGS系统，性能提高了14%，并且在涉及内窥镜操作的C3VD结肠镜检查数据集上达到了最新的摄像头跟踪和建图性能。在含有手机闪光灯的手机相机拍摄的室内场景中，也证明了NFL-BA可以显著改善SLAM性能。NFL-BA允许在缺乏外部光源的情况下进行更稳定的摄像头跟踪，并且能够改善复杂的近距离光源条件下的场景映射和建模问题。
### Conclusion
结果显示，使用NFL-BA的方法能够显著提高使用动态近距离光照的SLAM系统的性能，特别是在内窥镜操作等场景中。研究成果为在动态光照条件下进行自动化导航和分析提供了新的可能，有望提高患者的医疗效果和内窥镜体验。这项工作为未来在复杂光照条件下的SLAM系统研究提供了新的途径和方向。
## 571. `cs.CV` - AttentionDrop：Transformer模型的一种新型正则化方法 [PDF](https://arxiv.org/pdf/2504.12088), [HTML](https://arxiv.org/abs/2504.12088)
### Authors
Mirza Samad Ahmed Baig,Syeda Anshrah Gillani,Abdul Akbar Khan,Shahid Munir Shah,Muhammad Omer Khan
### Background
基于Transformer架构的模型在自然语言处理、计算机视觉和语音处理等多个任务上取得了最先进的性能。然而，这些模型巨大的容量常常导致过拟合，特别是在训练数据有限或存在噪声的情况下。因此，研究提出了一种统一的家庭随机正则化技术，即AttentionDrop及其三种不同的变体，这些技术直接作用于自注意力分布。
### Innovation
提出了一种新的正则化技术AttentionDrop及三种变体：硬注意力掩码随机零化查询的前k个注意力概率以鼓励多样化的上下文利用；模糊注意力平滑在注意力概率上应用动态高斯卷积以扩散过于尖锐的概率分布；一致性的正则化注意力Drop通过KL散度一致性损失增强多独立注意力Drop扰动下的输出稳定性。研究结果表明，AttentionDrop在准确率、校准和对抗鲁棒性上相对于标准Dropout、DropConnect和R-Drop基线均有提高。
### Conclusion
实验结果证明，AttentionDrop能够在准确率、校准和对抗鲁棒性方面持续改进标准Dropout、DropConnect和R-Drop基线模型的效果。
## 572. `cs.CV` - ISP-AD：针对合成缺陷和真实缺陷推动工业异常检测的大规模现实数据集 [PDF](https://arxiv.org/pdf/2503.04997), [HTML](https://arxiv.org/abs/2503.04997)
### Authors
Paul J. Krassnig,Dieter P. Gruber
### Background
机器学习在实现工业零缺陷政策中的自动视觉检测起着关键作用，但现有的异常检测研究受限于能够捕捉复杂缺陷外观和不完美成像条件的数据集不足，这些条件在生产过程中很常见。现有的基准测试表明，大多数公开可用的数据集倾向于最优成像条件，这导致它们在现实世界工业场景中的适用性被高估。为了填补这一空白，我们引介了工业丝网印刷异常检测数据集（ISP-AD），该数据集包含嵌入在具有高设计容差的结构化图案中的小型且对比度低的表面缺陷。据我们所知，这是迄今为止最大的公开可用工业数据集，包括直接从工厂收集的合成和真实缺陷。该数据集不仅用于基准测试最近的无监督异常检测方法，还进行了混合监督训练策略的实验，该策略结合了合成和真实缺陷。研究表明，即使是少量注入的弱标签真实缺陷也能提高泛化性能。从纯粹的合成缺陷训练开始，可以高效地将新的真实缺陷样本集成到后续的可扩展训练中。
### Innovation
ISP-AD数据集填补了现有数据集在复杂缺陷和产线不完美成像条件上的空白。该数据集不仅包括合成缺陷，还直接从工厂收集了真实缺陷，使其成为迄今为止最大的公开工业数据集。研究人员通过混合监督训练策略实验，发现少量真实缺陷的注入能够改善模型对未知缺陷特征的决策边界。
### Conclusion
我们的研究发现表明，模型的无监督合成缺陷可以提供冷启动基线，少量真实缺陷的加入可以细化未见过的缺陷特征的决策边界。数据集的无监督和监督分割旨在促进对无监督、自监督和监督方法的研究，增强其在工业环境中的适用性。
## 573. `cs.CV` - 在自动驾驶背景下训练神经网络进行部分遮挡道路标志识别 [PDF](https://arxiv.org/pdf/2503.18177), [HTML](https://arxiv.org/abs/2503.18177)
### Authors
Gulnaz Gimaletdinova,Dim Shaiakhmetov,Madina Akpaeva,Mukhammadmuso Abduzhabbarov,Kadyrmamat Momunov
### Background
随着自动驾驶车辆数量的增加和计算机视觉技术的快速发展，交通标志识别的准确性显得尤为重要。尽管该领域已有许多研究取得了显著成果，但在周围物体（如树枝、广告牌或其他城市环境元素）部分遮挡交通标志的情况下，识别任务变得更为复杂。本研究旨在探讨部分遮挡对交通标志识别的影响，并收集了一个包含5,746张图片的数据集（包括全遮挡和部分遮挡的交通标志）以评估模型性能
### Innovation
本研究采用了自定义卷积神经网络（CNN）并与其他模型进行了比较，发现解冻所有层的VGG16模型在识别部分遮挡的交通标志时达到了99%的准确性。这表明，在训练集中引入包含部分遮挡的真实世界数据对模型的鲁棒性至关重要，特别是在复杂实际场景中确保自动驾驶的安全性方面
### Conclusion
本研究的结果表明，使用包含部分遮挡的真实世界数据训练的模型在识别部分遮挡的交通标志时表现出更高的准确性。这种基于全面遮挡数据投入训练的数据集有助于提高自动驾驶的安全性与可靠性
## 574. `cs.CV` - Pruning the Paradox: How CLIP's Most Informative Heads Enhance Performance While Amplifying Bias [PDF](https://arxiv.org/pdf/2503.11103), [HTML](https://arxiv.org/abs/2503.11103)
### Authors
Avinash Madasu,Vasudev Lal,Phillip Howard
### Background
CLIP是目前最具人气的基础模型之一，广泛应用于多种视觉-语言任务，但对其内部机制了解甚少。随着CLIP在实际应用中的部署增加，理解其局限性和内置的社会偏见变得越来越重要，以减轻潜在的危害性后果。然而，驱动CLIP惊人能力和问题的内部机制尚未完全回答。因此，有必要研究CLIP类模型中注意力头的概念一致性，以揭示性能与社会偏见之间的矛盾。
### Innovation
提出了一种新的解释性度量方法——概念一致性分数(CCS)，用于衡量CLIP模型中的单个注意力头与特定概念的一致性程度。通过软修剪实验发现，高CCS值的注意力头对于保持模型性能至关重要，而修剪低CCS值或随机选择的注意力头则对性能影响较小。进一步研究发现，高CCS值的注意力头可以捕捉到关键概念，并在领域外检测、概念特定推理和视频-语言理解等方面起关键作用。此外，研究还证明了高CCS值的注意力头学会了放大社会偏见的无关联系，从而进一步揭示了解释性度量与性能及社会偏见之间的复杂关系。
### Conclusion
概念一致性分数(CCS)作为解释性度量，揭示了CLIP模型中性能和社会偏见之间的悖论，有助于理解和缓解CLIP模型中的社会偏见问题。
## 575. `cs.CV` - scSplit: 在荧光显微镜图像分解中引入严重性认知 [PDF](https://arxiv.org/pdf/2503.22983), [HTML](https://arxiv.org/abs/2503.22983)
### Authors
Ashesh Ashesh,Florian Jug
### Background
荧光显微镜在生命科学领域的进展中起着关键作用，但存在技术限制。计算多重成像技术最近被提出，可以在单个图像中捕获多个细胞结构，并在后续进行分解。现有的图像分解方法通常通过一组叠加输入图像及其相应的分解目标图像来训练。这里的关键在于，给定输入的叠加图强度比（混合比例）是事先未知的。然而，现有方法都是基于固定的叠加输入强度比进行训练，因此对于荧光显微镜中可能发生的强度范围不够敏感。本文旨在解决这一问题，通过提出的indiSplit方法来认识叠加图像之间的混合比例可能导致的问题。
### Innovation
本文提出了一种名为indiSplit的新方法，该方法能够应对混合比例的严重性问题。该方法基于InDI图像恢复的迭代方法，并设有一个适合训练的回归网络来预测给定输入图像的退化水平（混合不对称性），以及一个针对退化特异性进行规范化的模块，可在所有混合比例下实现退化感知推理。该方法能够解决荧光显微镜中的两个相关任务，即图像分裂和溢出去除，并通过五个公开数据集的实证结果展示了其应用性。
### Conclusion
本文通过提出的indiSplit方法在荧光显微镜图像分解中引入了对混合比例严重性的认知，通过预测输入图的退化水平和特定退化的规范化模块，实现了退化感知推理。该方法已经在五个公开数据集上得到了实证验证，并且所有源代码将采用宽松的许可证开放。
## 576. `cs.CV` - RETOUR: 以材料先验重新思考触觉表示学习 [PDF](https://arxiv.org/pdf/2505.14319), [HTML](https://arxiv.org/abs/2505.14319)
### Authors
Weihao Xia,Chenliang Zhou,Cengiz Oztireli
### Background
触觉感知受到接触物体表面性质的深刻影响，但现有的触觉表示学习方法往往忽视了这些特性对触觉体验的关键作用。大多数方法主要集中在将触觉数据与视觉或文本信息对齐上，而忽略了通过理解材料本身特性来获取触觉反馈的丰富性。因此，在这个工作中，我们通过重新审视触觉表示学习框架并引入材料先验来填补这一空白。
### Innovation
我们通过在学习过程引入代表不同材料特性的先验知识，重新设计了触觉表示学习框架。这种先验知识使触觉模型能够更好地捕捉和泛化表面纹理的微妙之处，从而为不同材料和纹理提供更准确和丰富的触觉反馈，提升在机器人学、触觉反馈系统和材料编辑等现实生活应用中的性能。
### Conclusion
我们的方法能够提升触觉反馈的准确性和丰富性，特别是在不同的材料和纹理上，改善了机器人学、触觉反馈系统和材料编辑等领域的真实应用效果。
## 577. `cs.CV` - StreamBridge: 将您的离线视频大语言模型转化为 proactive 流媒体助手 [PDF](https://arxiv.org/pdf/2505.05467), [HTML](https://arxiv.org/abs/2505.05467)
### Authors
Haibo Wang,Bo Feng,Zhengfeng Lai,Mingze Xu,Shiyu Li,Weifeng Ge,Afshin Dehghan,Meng Cao,Ping Huang
### Background
目前，在将现有的大语言模型（LLMs）调整为在线场景时，存在两个主要挑战：（1）有限的多轮实时理解能力，以及（2）缺乏主动响应机制。现有的模型难以处理较长的上下文信息和多轮对话，同时在用户输入时不能及时做出反应。为了应对这些问题，研究人员提出了StreamBridge这一框架，旨在解决上述挑战，提高离线视频LLMs在流媒体环境下的处理能力。
### Innovation
StreamBridge框架引入了两个创新点：（1）结合了记忆缓冲和回合衰减压缩策略的机制，支持长上下文多轮交互；（2）采用解耦且轻量的激活模型，可以轻松集成到现有的Video-LLMs中，实现连续的主动响应。为此，研究人员还构建了一个名为Stream-IT的数据集，专门用于流媒体视频理解，该数据集包含交错的视频-文本序列和多样化的指令格式。通过广泛实验，发现StreamBridge在各种任务中显著提升了离线Video-LLMs的流媒体理解能力，甚至优于GPT-4o和Gemini 1.5 Pro等专有模型，并且在标准视频理解基准测试中也取得了竞争力或更优的性能表现。
### Conclusion
StreamBridge框架在增强离线Video-LLMs的流媒体处理能力方面取得了显著效果，不仅能够进行长期语境下的多轮交互，还能在用户每轮输入时做出主动响应。通过Stream-IT数据集的支持，StreamBridge的应用范围得到了扩展，并在多个标准测试中展示了其优越性和实用性。
## 578. `cs.CV` - DSDNet：通过双重色彩空间协同作用的原始域除摩尔纹方法 [PDF](https://arxiv.org/pdf/2504.15756), [HTML](https://arxiv.org/abs/2504.15756)
### Authors
Qirui Yang,Fangpu Zhang,Yeying Jin,Qihua Cheng,Peng-Tao Jiang,Huanjing Yue,Jingyu Yang
### Background
随着移动成像技术的迅猛发展，使用智能手机捕捉屏幕已成为远程学习和会议录制中的普遍实践。然而，由于显示屏幕和相机传感器之间的频率混叠，加上影像信号处理管道的影响，摩尔纹进一步加剧，导致视觉严重退化。现有的sRGB域除摩尔纹方法存在不可逆信息损失的问题，而最近的两阶段原始域方法则受到信息瓶颈和推理效率低下的问题。
### Innovation
为了应对这些局限性，我们提出了一种单一阶段的原始域除摩尔纹框架，即双流除摩尔纹网络（DSDNet），它利用原始和YCbCr图像的协同作用，去除摩尔纹并保持亮度和色度保真度。具体来说，为了指导亮度校正和摩尔纹去除，我们设计了一个从原始到YCbCr的映射管道，并引入了带有动态调节的协同注意力模块（SADM）。此外，为了更好地指导色度保真，我们开发了亮度-色度自适应变换器（LCAT），它将亮度和色度表示解耦。广泛的实验表明，DSDNet在视觉质量和定量评价中均优于最先进的方法，并实现了比第二优方法快2.4倍的推理速度，突出其实用优势。
### Conclusion
通过DSDNet，我们成功解决了一些现有方法在去摩尔纹上的局限性，并在保留图像质量和加速推理速度方面取得了显著优势。
## 579. `cs.CV` - TT-DF: 基于扩散的大型数据集和人体伪造检测基准 [PDF](https://arxiv.org/pdf/2505.08437), [HTML](https://arxiv.org/abs/2505.08437)
### Authors
Wenkui Yang,Zhida Zhang,Xiaoqiang Zhou,Junxian Duan,Jie Cao
### Background
随着面部换脸方法的兴起和普及，深度伪造数据集和面部伪造检测有了显著的增长，这在一定程度上缓解了相关人工智能技术的安全问题。不过，当涉及到人体伪造时，仍然缺乏相关的数据集和检测方法，这是因为人体生成方法的发展较晚且更为复杂。
### Innovation
本文引入了名为TT-DF的新型大规模基于扩散的人体伪造数据集，包含6,120个伪造视频和1,378,857合成帧，并提出了一个名为TOF-Net的时间光流网络模型，专门用于人体伪造检测。该数据集和模型涵盖了各种伪造方法、身份和姿态信息的分离生成配置，以及不同压缩版本，旨在尽可能模拟所有可能性的伪造数据。
### Conclusion
实验结果显示，TOF-Net在TT-DF数据集上表现出色，优于现有的扩展面部伪造检测模型。
## 580. `cs.CV` - 使用互动NeoMedSys平台验证与优化VIOLA-AI 颅内出血模型的部署与改进 [PDF](https://arxiv.org/pdf/2505.09380), [HTML](https://arxiv.org/abs/2505.09380)
### Authors
Qinghui Liu,Jon E. Nesvold,Hanna Raaum,Elakkyen Murugesu,Martin Røvang,Bradley J Maclntosh,Atle Bjørnerud,Karoline Skogen
### Background
在放射学中临床部署AI工具面临诸多挑战与机遇。本文介绍了一个名为NeoMedSys的放射科软件平台，能够实现AI模型的高效部署与改进。通过在挪威最大的急救中心（site-1）和疑似中风患者（site-2）的临床环境中，评估NeoMedSys三个月的实际应用可行性与有效性，重点关注内部开发的用于颅内出血检测的AI模型（VIOLA-AI）的性能改进。
### Innovation
NeoMedSys集成了部署、测试和优化AI模型的工具，结合了基于Web的医学图像查看器、标注系统和医院范围内的放射学信息系统。该项目通过临床案例的方式，实现了对VIOLA-AI模型在面对新数据时性能的连贯性检测及规划后模型重新训练，并通过敏感性、特异性、准确性和受试者操作特征曲线下面积（AUC）等性能指标进行评估。
### Conclusion
NeoMedSys能够促进AI模型的迭代改进，显著提高其诊断准确性。自动出血检测和分割能够在近实时内进行审查以促进VIOLA-AI的重新训练。迭代改进过程导致分类敏感性显著提高，从79.2%上升到90.3%，特异性从80.7%提高到89.3%。整个样本出血检测的受试者操作特征曲线下面积（AUC）也获得提升，达到0.949（从0.873）。模型改进阶段表明，实时放射科医师反馈能够带来显著好处。
## 581. `cs.CV` - 月球的多角度面孔：一种统一的多模态月球重建Transformer [PDF](https://arxiv.org/pdf/2505.05644), [HTML](https://arxiv.org/abs/2505.05644)
### Authors
Tom Sander,Moritz Tenthoff,Kay Wohlfarth,Christian Wöhler
### Background
多模态学习作为一种跨多个学科的新兴研究主题，但尚未广泛应用于行星科学。本文提出了一种统一的变压器架构，该架构旨在学习灰度图像、数字高程模型（DEMs）、表面法线和反照率图等多种来源之间的共享表示，并支持任何输入模态到任何目标模态的灵活转换。
### Innovation
本文提出了一种单一的、统一的变压器架构，该架构用于学习多种来源（如灰度图像、DEMs、表面法线和反照率图）之间的共享表示，并支持任何输入模态到任何目标模态的灵活转换。此外，本文还将基于图像的3D重建和反照率估计（形貌和反照率从阴影推断）形成多模态学习问题，并展示多模态学习有潜力解决这一问题，并为大规模行星3D重建提供一种新方法。
### Conclusion
我们的结果显示，我们的基础模型学习这些四种模态之间的物理合理关系。我们还发现，月球图像的基于图像的3D重建和反照率估计可以通过多模态学习问题来表述，我们的研究结果展示了多模态学习解决这些任务的潜力，并为大规模行星3D重建提供了一种新方法。未来增加更多的输入模态将提高结果，并允许进行光度校正和配准等任务。
## 582. `cs.CV` - 温度驱动的脑部和消化道疾病针对上下文感知自适应知识蒸馏的稳健疾病检测 [PDF](https://arxiv.org/pdf/2505.06381), [HTML](https://arxiv.org/abs/2505.06381)
### Authors
Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel
### Background
医学疾病预测，尤其是通过影像学手段，由于医学数据复杂多变，包括噪声、模糊性及图像质量差异等问题，一直是一项挑战性的任务。尽管最近的深度学习模型，比如知识蒸馏（KD）方法在识别脑部肿瘤方面表现出了一定的潜力，但在处理不确定性以及跨不同医学条件的一般化方面仍存在局限性。传统的KD方法通常依赖于一个不考虑上下文的温度参数来调整教师模型的预测，但这种方式并不能很好地应对医学图像中存在的不同不确定性水平。
### Innovation
本文提出了一个创新框架，结合了蚂蚁 colony 优化（ACO）进行最优教师-学生模型选择和一个新颖的上下文感知预测方法对温度进行调整。该上下文感知框架根据图像质量、疾病复杂度及教师模型的置信度等因素调整温度，从而实现更可靠的知识转移。此外，ACO能够有效地从一组预训练模型中选择最合适的教师-学生模型对，通过探索更广的解空间更好地处理复杂的、非线性关系。该研究通过三个公开的基准数据集评估了所提框架，每个数据集对应一个独立的医学影像任务，并展示了所提出的框架在准确性和稳定性方面都显著优于当前最先进的方法。
### Conclusion
研究结果表明，所提出的框架在三个公开基准数据集上表现显著优于现有最先进的方法，准确率分别达到了98.01%（Kaggle MRI脑肿瘤数据集）、92.81%（Figshare MRI数据集）和96.20%（GastroNet数据集），超过了现有的基准准确率97.24%（Kaggle）、91.43%（Figshare）和95.00%（GastroNet）.
## 583. `cs.CV` - 道路和桥梁语义变化检测：细粒度数据集和多模态频域探测器 [PDF](https://arxiv.org/pdf/2505.13212), [HTML](https://arxiv.org/abs/2505.13212)
### Authors
Qingling Shu,Sibao Chen,Xiao Wang,Zhihui You,Wei Lu,Jin Tang,Bin Luo
### Background
准确检测道路和桥梁的变化对于城市规划和交通管理至关重要，但通用变化检测面临独特挑战，包括保持道路和桥梁作为线性结构的一致性和区分视觉相似的土地覆盖（例如道路建设和裸地）。现有空间域模型难以解决这些问题，缺乏专门的、语义丰富的数据集进一步加剧了问题。这导致了对新方法的需求，特别是专门针对道路和桥梁语义变化检测的方法。为此，作者提出了Road and Bridge Semantic Change Detection (RB-SCD) 数据集，这是一个评估道路和桥梁语义变化检测的首个系统基准数据集，提供了11个语义变化类别的详细注释，为交通基础设施的发展提供了详细的分析。
### Innovation
本文创新性地提出了一种新的框架，名为Multimodal Frequency-Driven Change Detector (MFDCD)。该框架通过两种关键组件在频域中集成多模态特征：1) Dynamic Frequency Coupler (DFC)，利用小波变换分解视觉特征，以稳健地建模线性过渡的一致性；2) Textual Frequency Filter (TFF)，将语义先验编码为频域图，并应用滤波器银行将其与视觉特征对齐，解决语义模糊问题。该框架在RB-SCD和三个公开变化检测数据集上表现优于现有方法。
### Conclusion
本文通过引入RB-SCD数据集和MFDCD框架，为道路和桥梁语义变化检测提供了一种全新的方法和基准数据集，有效地解决了道路和桥梁变化检测中的难题，并取得了前沿的效果。
## 584. `cs.CV` - 基于视频的空间理解：结构化提示与模拟数据的结合 [PDF](https://arxiv.org/pdf/2506.03642), [HTML](https://arxiv.org/abs/2506.03642)
### Authors
Haoyu Zhang,Meng Liu,Zaijing Li,Haokun Wen,Weili Guan,Yaowei Wang,Liqiang Nie
### Background
视觉空间理解是机器人导航和实体交互等下游任务的基础能力。然而，现有方法在处理空间不确定性与数据稀缺性方面能力有限，这限制了预训练视觉-语言模型（VLMs）的空间推理能力。
### Innovation
提出了一种无需修改架构的统一框架，以增强预训练VLMs的空间推理能力。该框架结合了SpatialMind结构化提示策略和ScanForgeQA问答数据集，后者通过自动构建过程从多样化的3D仿真场景中生成，旨在用于模型微调。
### Conclusion
跨多个基准的全面实验验证了提示策略和微调策略的有效性，并为未来视觉-空间理解的研究提供了见解。
## 585. `cs.CV` - OptiScene：通过扩展人类对齐数据合成和多阶段偏好优化驱动的室内场景布局生成 [PDF](https://arxiv.org/pdf/2506.07570), [HTML](https://arxiv.org/abs/2506.07570)
### Authors
Yixuan Yang,Zhen Luo,Tongsheng Ding,Junru Lu,Mingqi Gao,Jinyu Yang,Victor Sanchez,Feng Zheng
### Background
自动室内布局生成在室内设计、虚拟环境构建和具身AI中具有潜在应用，但现有方法存在局限性。提示驱动的方法在空间一致性上存在问题，且计算成本高；而基于学习的方法则受到粗略关系图和有限数据集的限制，难以适用于多种房间类型。因此，研究团队重新审视了基于LLM的室内布局生成，并构建了一个大规模数据集3D-SynthPlace，融合了通过‘GPT合成，人类检验’管道生成的合成布局，以及增加了多样化物体和高级空间注解的四种常见房间类型的场景。
### Innovation
该研究提出了OptiScene，一种专门针对室内布局生成优化的强开源LLM，基于自定义的3D-SynthPlace数据集进行了两阶段训练。第一阶段通过监督微调（SFT）首先生成高级空间描述，然后条件预测具体的物体布局；第二阶段采用多轮直接偏好优化（DPO），以更好地匹配人类设计偏好，显著提升了布局质量和生成成功率。研究结果表明，OptiScene在与传统提示驱动方法和基于学习的方法的基线相比具有优越性，并展示了在交互任务如场景编辑和机器人导航中的潜力。
### Conclusion
OptiScene 模型在室内场景布局生成研究中取得了显著成果，通过大规模数据集和多阶段优化方法显著提升了生成质量和人类偏好匹配度，为室内设计和虚拟环境构建提供了新的解决方案。
## 586. `cs.CV` - OSPO：面向文本到图像生成的基于对象中心自我优化偏好优化 [PDF](https://arxiv.org/pdf/2506.02015), [HTML](https://arxiv.org/abs/2506.02015)
### Authors
Yoonjin Oh,Yongjin Kim,Hyomin Kim,Donghwan Chi,Sungwoong Kim
### Background
最近的多模态大型语言模型（MLLMs）发展使模型能够以统一的方式处理和生成多模态数据。然而，文本到图像生成时，输入提示与生成图像之间的细粒度对齐仍然是一个重大挑战。现有的自我改进方法主要集中在整体视觉细节上，而在生成训练数据和反馈时没有特别关注对象级别的细节，因此在解决对象幻觉问题上仍然存在困难。为解决这个问题，本文提出了一种基于对象中心的自我改进偏好优化（OSPO），这是一种用于增强对象级别文本-图像对齐的自我改进框架。
### Innovation
OSPO 创新地解决了构建和利用对象级别硬负例数据以及对象中心优化以提高对象特定保真度的问题。具体而言，OSPO 包含：（1）初始提示生成；（2）硬偏好对生成；（3）筛选和选择；（4）基于条件偏好损失的对象中心偏好优化。实验表明，OSPO 显著提高了文本到图像生成的细粒度对齐，不仅超越了此前的自我改进方法，也超过了基于扩散的专门图像生成模型。
### Conclusion
OSPO显著改进了文本到图像生成的细粒度对齐，超越了此前的自我改进方法和基于扩散的专门图像生成模型。
## 587. `cs.CV` - 语言大模型可以弥补视觉表示的不足 [PDF](https://arxiv.org/pdf/2506.05439), [HTML](https://arxiv.org/abs/2506.05439)
### Authors
Sho Takishita,Jay Gala,Abdelrahman Mohamed,Kentaro Inui,Yova Kementchedjhieva
### Background
许多跨模态模型（VLMs）通过对CLIP基视觉编码器的改进，在多种跨模态任务中表现出色。尽管CLIP视觉编码器已知存在多种限制，但这些模型依靠强大的语言骨干来补偿可能较弱的视觉特征，通过上下文化或丰富视觉特征。本文旨在验证这一假设，通过在精心设计的任务中对三种基于CLIP的VLMs进行受控的自注意力消融实验来研究视觉表示的限制以及语言解码器的补偿作用。
### Innovation
本文通过三款基于CLIP的VLM进行自注意力消融实验，研究了语言解码器在视觉特征弱化或上下文化减少情况下是否能够补偿视觉表示的不足，并揭示了语言大模型在不同场景下的动态分工机制。研究结果表明，尽管存在已知限制，CLIP提供的视觉表示仍可直接为语言解码器提供语义信息，但在视觉上下文减少的情景中，语言解码器能够显著补偿视觉表示的不足并恢复性能。这表明了VLMs中视觉处理和语言解码器之间的动态分工，并为进一步架构设计带来了新思路，建议未来模型能够承担更多的视觉处理任务，从而增强整体性能.
### Conclusion
本文的研究结果证明了语言大模型在视觉表示有限的情况下仍能展现出较强的表现力。在不同情况下，语言解码器能够通过自我补偿来克服视觉表示的局限性。该研究揭示了VLMs中的动态分工机制，并为未来模型设计提供了新的方向，建议在模型设计中更加注重语言和视觉的协同作用，以提高跨模态任务的处理能力。
## 588. `cs.CV` - 在街市中利用卷积神经网络对帐篷进行分类 [PDF](https://arxiv.org/pdf/2506.17946), [HTML](https://arxiv.org/abs/2506.17946)
### Authors
Azamat Ibragimov,Ruslan Isaev,Remudin Reshid Mekuria,Gulnaz Gimaletdinova,Dim Shaiakhmetov
### Background
街市在许多地区是重要的经济枢纽，然而由于其非结构化特性，自动分类市场基础设施（如帐篷）等任务面临着巨大挑战。传统的人工分类方式效率低，而基于卷积神经网络（CNN）的模型在物体识别方面广泛使用，但在街市特定任务上的应用仍待探索。特别是在吉尔吉斯斯坦，有超过四分之一的国内生产总值（GDP）来自街市。
### Innovation
该研究提出了一个改进的深度学习模型用于街市中帐篷分类的任务，比较了自定义的卷积神经网络（CNN）模型与EfficientNetB0模型。模型性能通过多种度量标准（如准确率、精确率、召回率、F1分数和平均精度）进行评估，展示出利用预训练模型如EfficientNetB0在街市图像分类中的优点。
### Conclusion
实验结果显示，自定义的CNN模型达到了92.8%的准确率，而EfficientNetB0达到了98.4%的准确率，证明了在街市图像分类任务中使用预训练模型的效果。同时，通过混淆矩阵的分析，发现了每种模型的优缺点。这些发现表明，使用预训练模型如EfficientNetB0能够显著提高分类准确率和泛化能力。
## 589. `cs.CV` - RePIC: 基于强化学习的多模态语言模型后训练以个性化 [PDF](https://arxiv.org/pdf/2506.18369), [HTML](https://arxiv.org/abs/2506.18369)
### Authors
Yeongtak Oh,Jisoo Mok,Dohyun Chung,Juhyeon Shin,Sangha Park,Johan Barthelemy,Sungroh Yoon
### Background
现有的多模态大型语言模型（MLLMs）在生成个性化的图像描述时常常表现不佳，即使是在训练时使用高质量的描述数据。已有的后训练个性化方法也存在相似的问题，在大规模监督微调后仍然难以在真实场景中（如包含多个概念的图像描述）准确生成描述。获取适合这类复杂场景的高质量描述数据既昂贵又困难。
### Innovation
本文提出了一个基于强化学习（RL）的后训练框架，这是第一个利用强化学习方法对MLLMs进行后训练以实现个性化图像描述的尝试。该方法显著提升了MLLMs在视觉识别和个性化生成能力，并且在复杂的多概念图像描述任务中显著优于现有的监督微调方法。
### Conclusion
本文提出的方法表现出了在视觉识别和个性化生成方面的显著优势，并在多个评估指标和任务上显著优于现有监督微调基线方法，尤其是在多概念图像描述任务中。
## 590. `cs.CV` - DualEdit：视觉语言模型中的双模态编辑以更新知识 [PDF](https://arxiv.org/pdf/2506.13638), [HTML](https://arxiv.org/abs/2506.13638)
### Authors
Zhiyi Shi,Binjie Wang,Chongjie Si,Yichen Wu,Junsik Kim,Hanspeter Pfister
### Background
模型编辑旨在高效地更新预训练模型的知识，而不必进行耗时的完整重新训练。尽管现有的先驱编辑方法取得了令人鼓舞的结果，但它们主要关注单模态语言模型（LLMs）。然而，对于涉及多种模态的视觉语言模型（VLMs），每种模态在编辑性能中的作用和影响仍然未被充分探索。为了填补这一空白，该研究探索了文本和视觉模态在模型编辑中的影响，并发现：（1）文本和视觉表示在不同的层达到峰值敏感度，反映出它们的不同重要性；（2）同时编辑这两种模态可以高效地更新知识，但会损害模型的原始能力。
### Innovation
基于研究发现，该研究提出了DualEdit，一种修改文本和视觉模态的关键层的编辑器。此外，引入了文本模态中的门控模块，使DualEdit能够在高效更新新知识的同时保留模型的原始信息。DualEdit在多个VLM骨干和基准数据集上进行了评估，展示了其在不同评估指标上优于最先进的VLM编辑基线以及适应的LLM编辑方法的优越性。代码可供查看。
### Conclusion
DualEdit通过同时编辑文本和视觉模态的关键层，并引入文本模态的门控模块，成功更新了视觉语言模型的知识，同时保持了模型的原始信息。该方法在多个VLM模型上进行了验证，并展示了其在不同评估指标上的优越性。
## 591. `cs.CV` - cadrille：基于在线强化学习的多模态CAD重建 [PDF](https://arxiv.org/pdf/2505.22914), [HTML](https://arxiv.org/abs/2505.22914)
### Authors
Maksim Kolodiazhnyi,Denis Tarasov,Dmitrii Zhemchuzhnikov,Alexander Nikulin,Ilya Zisman,Anna Vorontsova,Anton Konushin,Vladislav Kurenkov,Danila Rukhovich
### Background
计算机辅助设计（CAD）在工程和制造业中扮演着重要角色，使得创建精确且可编辑的3D模型成为可能。利用各种传感器或用户提供的数据作为CAD重建的输入可以普及设计应用程序的访问。然而，现有方法通常专注于单一输入模态，如点云、图像或文本，这限制了它们的普适性和鲁棒性。为了解决这些问题，研究人员利用了视觉语言模型（VLM）的最新进展，提出了一个多模态CAD重建模型，同时处理所有三种输入模态。该项研究借鉴了大规模语言模型（LLM）训练范式，采用两阶段管道：首先在大规模程序生成数据上进行监督微调（SFT），然后使用在线反馈进行强化学习（RL）微调。这种方法证明了在线RL算法，如Group Relative Preference Optimization（GRPO），优于离线替代方案。在DeepCAD基准测试中，经过SFT训练的模型在所有三种输入模态中均超过了现有的单一模态方法。更重要的是，在经过RL微调后，cadrille在三个具有挑战性的数据集中，包括一个真实世界数据集，均建立了新的技术水平。
### Innovation
该研究创新性地提出了一个基于在线强化学习的多模态CAD重建模型。该模型能同时处理点云、图像和文本三种输入模态。它采用了监督微调和强化学习相结合的方法进行训练，证明了在线RL算法对于CAD任务的有效性。
### Conclusion
在DeepCAD基准测试中，SFT模型在所有三种输入模态中均超过现有方法。通过强化学习进一步微调后，cadrille在三个具有挑战性的数据集中均达到了新的技术水平，特别是在真实世界数据集上的表现尤为突出。
## 592. `cs.CV` - GRE Suite：通过精调视觉语言模型和增强推理链进行地理位置推断 [PDF](https://arxiv.org/pdf/2505.18700), [HTML](https://arxiv.org/abs/2505.18700)
### Authors
Chun Wang,Xiaoran Pan,Zihao Pan,Haofan Wang,Yiren Song
### Background
近年来，视觉语言模型（VLMs）在视觉推理任务中表现出色。然而，地理定位任务具有独特的挑战，需要从图像中提取多层次的视觉线索，并结合外部世界知识进行系统推理。现有的地理定位方法往往缺乏稳健的推理机制和可解释性，限制了其效果。
### Innovation
本文提出了Geo Reason Enhancement (GRE) Suite，这是一种新颖的框架，通过将结构化的推理链嵌入到VLMs中，实现准确且可解释的位置推断。GRE Suite在三个关键维度上进行了系统开发：数据集、模型和基准测试。首先引入了GRE30K，这是一项高质量的地理定位推理数据集，旨在促进细粒度视觉和上下文分析。接着介绍了GRE模型，该模型采用多阶段推理策略，逐步推断场景属性、局部细节和语义特征，从而以更高的精度缩小可能的地缘区域。最后构建了Geo Reason Evaluation Benchmark (GREval-Bench)，这是一个全面的评估框架，评估VLMs在多样化的城市、自然和地标场景中的粗略和细粒度定位性能。
### Conclusion
实验结果表明，GRE在所有层次的地理定位任务中显著优于现有方法，证明了推理增强的VLMs在复杂地理推理中的有效性。
## 593. `cs.CV` - 变形可调卷积网络在准确高效时空交通预测中的应用 [PDF](https://arxiv.org/pdf/2507.11550), [HTML](https://arxiv.org/abs/2507.11550)
### Authors
Hyeonseok Jin,Geonmin Kim,Kyungbaek Kim
### Background
交通预测是智能交通系统的关键组成部分，能够支持诸如缓解拥堵和事故风险预测等应用。尽管最近的研究探索了基于图和网格的方法，但仍然存在关键限制。基于图的方法虽然能够有效捕捉非欧几里得空间结构，但计算成本高昂，限制了其在大规模系统中的实用性。相比之下，基于网格的方法主要利用卷积神经网络（CNN），计算效率较高，但因滤波器固定的形状，难以建模不规则的空间模式。此外，两种方法通常未能考虑到固有的时空异质性，通常在多样化的区域和时间周期中应用共享的参数集。
### Innovation
针对这些挑战，我们提出了一种新颖的基于CNN的架构——可调变形卷积网络（DDCN），它结合了可调和动态卷积操作。可调层引入了具有学习能力的偏移量，创建了灵活的接收域，能够更好地与不规则的空间结构对齐。动态层生成了区域特定的滤波器，使模型能够适应变化的时空交通模式。通过结合这两种组件，DDCN能够同时捕捉非欧几里得空间结构和时空异质性。
### Conclusion
在四个实际交通数据集上的详尽实验表明，DDCN在保持高预测性能的同时显著降低了计算成本，表明其具有在大规模和实时部署中的潜力。
## 594. `cs.CV` - MCGA: 意识到灰度注意力的混合码本超光谱重建 [PDF](https://arxiv.org/pdf/2507.09885), [HTML](https://arxiv.org/abs/2507.09885)
### Authors
Zhanjiang Yang,Lijun Sun,Jiawei Dong,Xiaoxin An,Yang Liu,Meng Li
### Background
从RGB输入重建超光谱图像（HSIs）是一种成本效益高的替代方案，可替代昂贵的超光谱相机，但将高维光谱从三个通道重建时，问题更为复杂。现有方法通常利用大数据注意力网络直接回归RGB到HSI的映射，这种方式计算上昂贵且仅在一定程度上处理奇异问题。该研究针对这一挑战提出了MCGA框架，利用光谱先验知识和光度一致性，通过混合码本（MoC）学习可迁移的光谱先验并通过灰度意识光度注意力（GANet）对齐RGB特征。
### Innovation
MCGA框架通过混合码本（MoC）学习可迁移的光谱先验，然后通过灰度意识光度注意力（GANet）对齐RGB特征，进一步通过top-K注意力设计和测试时适应（TTA）提高效率和鲁棒性。
### Conclusion
实验结果表明，MCGA在基准和真实数据上实现了最先进的准确率，具备强大的跨数据集泛化能力，在推理上比现有方法快4-5倍。相关代码将在论文接受后提供。
## 595. `cs.CV` - CLIPTTA: 资深对比视觉语言测试时间适应 [PDF](https://arxiv.org/pdf/2507.14312), [HTML](https://arxiv.org/abs/2507.14312)
### Authors
Marc Lafon,Gustavo Adolfo Vargas Hakim,Clément Rambour,Christian Desrosier,Nicolas Thome
### Background
视觉-语言模型（VLMs）如CLIP在零样本能力方面表现出色，但在分布偏移下难以泛化。测试时间适应（TTA）允许在无标签数据的情况下模型在推理时更新，通常通过减小熵来实现。然而，该目标与VLMs的对比式图像-文本训练本质上不一致，限制了适应性能并引入了伪标签漂移和类别崩溃等问题。
### Innovation
我们提出了一种新的基于梯度的TTA方法CLIPTTA，该方法利用一种与CLIP预训练目标兼容的软对比损失。我们提供了CLIPTTA梯度的理论分析，展示了其批次感知设计是如何减轻崩溃风险的。我们进一步将CLIPTTA扩展到开放集设置，使用异常对比暴露（OCE）损失以增强异常样本的检测。CLIP-TTA在75个数据集上表现一致优于基于熵的目标，并在多个数据集上优于当前最佳TTA方法，表现出更稳定的性能。
### Conclusion
CLIP-TTA在多种分布偏移数据集上的表现优于现有方法，特别是在开放集设置中表现出色。
## 596. `cs.CV` - 使用结构性层次适应和可靠邻接对齐的跨分辨率 SAR 目标检测 [PDF](https://arxiv.org/pdf/2507.08290), [HTML](https://arxiv.org/abs/2507.08290)
### Authors
Jiang Qin,Bin Zou,Haolin Li,Lamei Zhang
### Background
近年来，连续改进的 SAR 成像分辨率在城市监控和目标检测等方面取得了显著的成果。然而，分辨率的提高也导致了散射特性的差异性增加，这对目标检测模型的泛化能力提出了挑战。现有的域适应技术虽然可能是一种解决方案，但由于不同分辨率带来的不可避免差异，常常会导致盲目特征适应和不可靠的语义传播，最终导致域适应性能下降。因此，需要开发一种可靠的跨分辨率目标检测方法，以解决上述问题.
### Innovation
本文提出了一个新的 SAR 目标检测方法（称为 CR-Net），该方法结合了结构先验和证据学习理论，能够在跨分辨率检测中实现可靠的域适应。该方法通过引入结构诱导层次级特征适应 (SHFA) 和可靠结构邻接对齐 (RSAA) 模块实现此目标。SHFA 模块将目标结构相关性引入模型中，实现结构感知的特征适应；RSAA 模块则通过利用安全邻接集转移源域中的有价值特征知识到目标域，使检测模型在目标域中的可分性进一步增强。实验结果表明, CR-Net 在保持域内结构和提高可分性方面显著提升了跨分辨率适应能力，并在跨分辨率 SAR 目标检测方面达到了最先进 (SOTA) 的性能.
### Conclusion
本文提出了一种新颖的跨分辨率 SAR 目标检测方法 CR-Net，通过引入结构先验和证据学习理论，改进了域适应性能。SHFA 和 RSAA 的结合显著提高了模型的解释性和可靠性，证明了 CR-Net 在跨分辨率 SAR 目标检测任务中的优越性能。
## 597. `cs.CV` - VLA-Mark：大型视觉-语言对齐模型的跨模态水印 [PDF](https://arxiv.org/pdf/2507.14067), [HTML](https://arxiv.org/abs/2507.14067)
### Authors
Shuliang Liu,Qi Zheng,Jesse Jiaxi Xu,Yibo Yan,Junyan Zhang,He Geng,Aiwei Liu,Peijie Jiang,Jia Liu,Yik-Cheung Tam,Xuming Hu
### Background
视觉语言模型需要保护知识产权的同时不损害多模态一致性。当前的文本水印方法通过有偏的标记选择和静态策略破坏了视觉和文本的对齐，使得关键语义概念容易受到攻击。现有方法主要针对文本进行水印嵌入，而忽视了视觉信息的一致性保护，导致在联合数据生成过程中存在不一致性的问题。
### Innovation
提出了VLA-Mark，一种视觉对齐框架，嵌入可检测的水印同时保持语义保真度，通过跨模态协调。方法结合了多尺度视觉-文本对齐指标，包括局部补丁亲和力、全局语义连贯性以及上下文注意力模式，用于指导水印插入而不需重新训练模型。引入了一种基于熵的动态机制来平衡水印强度和语义保存，优先在低不确定性生成阶段关注视觉锚定。
### Conclusion
实验结果显示，VLA-Mark与传统方法相比，PPL低7.4%，BLEU高26.6%，且检测率接近完美（98.8% AUROC）。框架展示了96.1%的攻击抵抗性，抵御诸如改写和同义词替换等攻击，同时保持文本和视觉的一致性，从而建立了质量保留的多模态水印的新标准。
## 598. `cs.CV` - RegionMed-CLIP: 一种用于医学图像理解的区域感知多模态对比学习预训练模型 [PDF](https://arxiv.org/pdf/2508.05244), [HTML](https://arxiv.org/abs/2508.05244)
### Authors
Tianchen Fang,Guiru Liu
### Background
医学图像理解在支持自动化诊断和数据驱动的临床决策中起着关键作用，但其进展受两大主要挑战阻碍：高质量标注医学数据的稀缺性和过度依赖全局图像特征，后者往往遗漏了细微但对临床有重大意义的异常区域。
### Innovation
提出了一种区域感知多模态对比学习框架RegionMed-CLIP，该框架明确地结合了局部病理信号与整体语义表示。该方法的核心是一个创新的感兴趣区域（ROI）处理器，它可以自适应地将细粒度的局部特征与全局上下文集成，通过分步训练策略增强分层次的多模态对齐。
### Conclusion
通过大量的实验，包括图像-文本检索、零样本分类和视觉问答任务，结果表明，RegionMed-CLIP 在性能上明显优于最先进的视觉语言模型。结果显示，区域感知的对比预训练至关重要，定位了 RegionMed-CLIP 作为推进多模态医学图像理解的稳固基础。
## 599. `cs.CV` - SAR-TEXT：使用SAR-Narrator和渐进迁移学习构建的大规模SAR图像-文本数据集 [PDF](https://arxiv.org/pdf/2507.18743), [HTML](https://arxiv.org/abs/2507.18743)
### Authors
Yiguo He,Xinjun Cheng,Junjie Zhu,Chunping Qiu,Jun Wang,Xichuan Zhang,Qiangjuan Huang,Ke Yang
### Background
近年来，视觉语言模型（VLMs）在遥感领域取得了显著的突破。合成孔径雷达（SAR）图像因其全天候能力在遥感中至关重要，但由于缺乏大规模、高质量的SAR图像-文本数据集，其语义理解受到了限制。
### Innovation
本文构建了SAR-TEXT，这是一种包含超过130,000个SAR图像-文本对的大规模高质量数据集。为了构建SAR-TEXT数据集，设计了SAR-Narrator框架，通过多阶段策略生成SAR图像的文本描述。实验证明，SAR-TEXT数据集在图像-文本检索、图像描述生成以及视觉问答三个典型视觉语言任务上表现出显著的效果。
### Conclusion
SAR-RS-CLIP在检索性能上取得了显著提升，SAR-RS-CoCa在描述生成任务上取得了显著改进，而SAR-GPT在多个SAR-VQA数据集上的表现优于基线和单阶段模型，特别是显示出更强的语义理解和推理能力。SAR-Narrator作为一种灵活的描述工具，可以方便地由社区用于构建更大的SAR图像-文本数据集。所有代码、预训练模型和SAR-Text数据集均已经公开。
## 600. `cs.CV` - RSCC: 遥感变化描述数据集RSCC用于灾难事件 [PDF](https://arxiv.org/pdf/2509.01907), [HTML](https://arxiv.org/abs/2509.01907)
### Authors
Zhenyuan Chen,Chenxi Wang,Ningyu Zhang,Feng Zhang
### Background
遥感对于灾害监测至关重要，但现有的数据集缺乏时空图像对和详细的文本标注。当前资源主要依赖单时点的图像资源，无法捕捉灾害随时间变化的影响。这导致了对灾害动态监测能力的不足，特别是在构建时-空理解的视觉语言模型方面。
### Innovation
本文提出了Remote Sensing Change Caption (RSCC)数据集，这是一个包含62,315个灾前-灾后图像对的大规模基准，涵盖了地震、洪水、野火等多种灾害类型，并配以丰富的人类风格的变化描述。RSCC填补了现有数据集在时间和语义上的空白，使得视觉语言模型能够有效训练和评估，以更好地理解和应对灾害相关的分析。
### Conclusion
实验结果展示了RSCC在促进灾难相关细致分析方面的独特能力，从而为更准确、可解释和扩展的视觉语言应用铺平了道路。相关代码和数据集可在指定链接获取。
## 601. `cs.CV` - GPSToken: Gaussian Parameterized Spatially-adaptive Tokenization for Image Representation and Generation [PDF](https://arxiv.org/pdf/2509.01109), [HTML](https://arxiv.org/abs/2509.01109)
### Authors
Zhengqiang Zhang,Rongyuan Wu,Lingchen Sun,Lei Zhang
### Background
传统的图像表示与生成方法受限于均匀的2D/1D网格标记化，对于表示形状、纹理各异且位置不同的区域不够灵活，限制了其特征提取能力。为了克服这一问题，本文提出了一种新的GPSToken框架，利用参数化的二维高斯分布动态建模不同图像区域的形状、位置和纹理，以实现非均匀的图像标记化。
### Innovation
本文提出了一种新颖的GPSToken框架，通过利用参数化的二维高斯分布动态建模不同图像区域的形状、位置和纹理，实现了非均匀的图像标记化。具体来说，该框架首先使用熵驱动算法将图像分割成纹理同质区域，然后将每个区域参数化为二维高斯分布（位置的均值、形状的协方差）并结合纹理特征。通过一个专门的变压器优化这些高斯参数，实现了对位置/形状和内容感知的特征提取的连续适应。此外，该框架通过可微的点绘制渲染器将高斯参数化标记重建为2D特征图，实现端到端训练，并且能够实现空间布局和纹理特征的解耦，支持高效的两阶段生成：轻量级网络的结构布局合成，随后是结构条件下的纹理生成。
### Conclusion
实验表明，GPSToken在图像重建与生成任务中表现出优异的性能，使用128个标记便实现了rFID和FID分数分别为0.65和1.50。相关代码和模型可以在指定的网址找到。
## 602. `cs.CV` - AToken：统一视觉标记器 [PDF](https://arxiv.org/pdf/2509.14476), [HTML](https://arxiv.org/abs/2509.14476)
### Authors
Jiasen Lu,Liangchen Song,Mingze Xu,Byeongjoo Ahn,Yanjun Wang,Chen Chen,Afshin Dehghan,Yinfei Yang
### Background
现有的视觉标记器专注于单一模态的重建或语义理解，无法在同一体系中统一处理图像、视频和3D资产之间的多样化视觉输入。这限制了现有系统的泛化能力和整体效果。
### Innovation
AToken是首个能够同时实现高保真重建和语义理解的统一视觉标记器。通过引入4D旋转位置嵌入和自抗生成优化目标，AToken能够处理任意分辨率和时间长度的视觉输入，并在重建质量上达到业界领先水平。此外，AToken还支持渐进式训练，可以逐步扩展从单个图像、视频和3D资产，并同时支持连续和离散的潜在标记。
### Conclusion
AToken不仅在下游应用中具备强大的生成和理解任务能力，还在各种基准测试中表现出竞争力，为下一代统一视觉标记的多模态AI系统提供了重要启示。
## 603. `cs.CV` - USCTNet: 一种用于物理一致的HSI重建的深度展开核范数优化求解器 [PDF](https://arxiv.org/pdf/2509.10651), [HTML](https://arxiv.org/abs/2509.10651)
### Authors
Xiaoyang Ma,Yiyang Chai,Xinran Qu,Hong Sun
### Background
从单一RGB图像重建高光谱图像（HSIs）是一个病态问题，当相机光谱灵敏度（CSS）和场景照明不准确时，可能会变得物理不一致。
### Innovation
本文将RGB到HSI的重建框定为一个基于物理的逆问题，并通过学习变换域中的核范数进行正则化。同时，引入了一种数据自适应低秩子空间的奇异值截止（SVT）运算符来避免全奇异值分解（SVDs）的高成本和不稳定性。基于这些组件，开发了一种USCTNet深度展开求解器，结合参数估计模块和学习的邻近更新。
### Conclusion
在标准基准上的大量实验显示，USCTNet在重建准确性方面优于最先进的基于RGB的方法。
## 604. `cs.CV` - SAIL-VL2技术报告 [PDF](https://arxiv.org/pdf/2509.14033), [HTML](https://arxiv.org/abs/2509.14033)
### Authors
Weijie Yin,Yongjie Ye,Fangxun Shu,Yue Liao,Zijian Kang,Hongyuan Dong,Haiyang Yu,Dingkang Yang,Jiacong Wang,Han Wang,Wenzhuo Liu,Xiao Liang,Shuicheng Yan,Chao Feng
### Background
SAIL-VL2是SAIL-VL的继任者，是一个用于全面跨模态理解和推理的开放视觉语言基础模型（LVM）。它在不同图像和视频基准测试中实现了业内最佳性能，特别是在细致的感知和复杂的推理方面表现出强大的能力。
### Innovation
SAIL-VL2的核心创新有三项。首先是大规模数据收集和处理管道，包括评分和过滤策略，增强数据质量及分布，改善训练效率。其次是逐步训练框架，先通过强大的预训练视觉编码器（SAIL-ViT），再进行多模态预训练，最终实现具有系统性强化模型能力的思考融合SFT-RL混合范式。三是架构上的进步，不仅限于密集型LLMs，还包括高效的稀疏Mixture-of-Experts (MoE)设计。
### Conclusion
SAIL-VL2在106个数据集上表现出竞争性的性能，并在挑战性的推理基准测试如MMMU和MathVista中达到业内最佳结果。在OpenCompass排行榜上，SAIL-VL2-2B在4B参数规模下官方发布的开源模型中排名第一，成为开放源跨模态社区的高效和可扩展基础。
## 605. `cs.CV` - SPATIALGEN：基于布局引导的3D室内场景生成 [PDF](https://arxiv.org/pdf/2509.14981), [HTML](https://arxiv.org/abs/2509.14981)
### Authors
Chuan Fang,Heng Li,Yixun Liang,Jia Zheng,Yongsen Mao,Yuan Liu,Rui Tang,Zihan Zhou,Ping Tan
### Background
创建高保真3D模型对于设计、虚拟现实和机器人等应用至关重要。然而，手工3D建模耗时且劳动密集。尽管生成型AI的进步使得自动场景合成成为可能，现有方法在视觉质量、多样性、语义一致性以及用户控制方面仍面临挑战。一个主要瓶颈是没有适合此任务的大量高质量数据集。为了解决这一问题，我们提出了一套综合的合成数据集，包含12,328个结构化注解场景，57,440个房间，以及4.7M张写实2D渲染图。
### Innovation
我们利用该数据集提出了SpatialGen，这一新颖的多视角多模态扩散模型，能够从任意视角生成现实且语义一致的3D室内场景，给定一个3D布局和参考图像（来自文本提示），我们的模型合成视觉外观（颜色图像）、几何形状（场景坐标图）和语义（语义分割图），同时保持跨模态的空间一致性。实验结果显示，SpatialGen在生成结果上优于之前的方法。
### Conclusion
我们开源了我们的数据和模型，旨在为社区赋能并推动室内场景理解和生成领域的进步。
## 606. `cs.CV` - ScaleCUA: 通过跨平台数据扩展开源计算机使用代理 [PDF](https://arxiv.org/pdf/2509.15221), [HTML](https://arxiv.org/abs/2509.15221)
### Authors
Zhaoyang Liu,Jingjing Xie,Zichen Ding,Zehao Li,Bowen Yang,Zhenyu Wu,Xuehui Wang,Qiushi Sun,Shi Liu,Weiyun Wang,Shenglong Ye,Qingyun Li,Xuan Dong,Yue Yu,Chenyu Lu,YunXiang Mo,Yao Yan,Zeyue Tian,Xiao Zhang,Yuan Huang,Yiqian Liu,Weijie Su,Gen Luo,Xiangyu Yue,Biqing Qi,Kai Chen,Bowen Zhou,Yu Qiao,Qifeng Chen,Wenhai Wang
### Background
视觉-语言模型（VLMs）使计算机使用代理（CUAs）能够自主操作图形用户界面（GUIs），展现出巨大的潜力，但进步受到缺乏大规模、开源的计算机使用数据和基础模型的限制。这项工作中，作者提出了ScaleCUA，这是一个迈向开源CUA扩展的数据集，覆盖了6个操作系统和3个任务领域，通过结合自动代理人和人类专家构建了一个闭环管道。通过在扩大的数据集上训练，ScaleCUA可以在各种平台之间无缝运行。
### Innovation
引入了ScaleCUA作为开源CUA扩展的一步，通过自动化代理人和人类专家的闭环管道构建了一个大规模数据集，覆盖多种操作系统和任务领域。ScaleCUA在平台之间实现了无缝切换，并在WebArena-Lite-v2和ScreenSpot-Pro基准上显示出显著的领先优势，同时创下了新的基准（MMBench-GUI L1-Hard: 94.4%，OSWorld-G: 60.6%，WebArena-Lite-v2: 47.4%）结果。这项工作突显了数据驱动扩展对于通用计算机使用代理的有效性。
### Conclusion
作者将发布数据、模型和代码，以推动未来的研究进展：this https://link.to/research/resources.
## 607. `cs.CV` - 面向基于去噪的定制防护的鲁棒防御 [PDF](https://arxiv.org/pdf/2509.13922), [HTML](https://arxiv.org/abs/2509.13922)
### Authors
Wenkui Yang,Jie Cao,Junxian Duan,Ran He
### Background
扩散模型如Stable Diffusion在视觉合成任务中由于其强大的定制能力而变得突出，但也引入了包括深度伪造和版权侵权在内的重大安全风险。为应对这些风险，一种被称为保护性扰动的方法出现了，该方法通过向图像中注入不可感知的对抗噪声来减少图像误用。然而，净化过程可以去除这些保护性扰动，从而重新暴露图像给恶意伪造的风险。
### Innovation
本文正式化了抗净化任务，并针对现有的抗净化方法面临的挑战提出了一个简单的诊断保护性扰动方法，名为AntiPure。AntiPure包括两种指导机制：1）块频谱指导，减少模型对净化图片中高频成分的影响；2）错误的时间步指导，扰乱模型在不同时间步的去噪策略。通过这些额外的指导，AntiPure可以在代表性的净化设置下嵌入不可感知的扰动，实现有效的后生成扭曲。
### Conclusion
实验表明，AntiPure作为净化过程的压力测试，具有最小的感知差异和最大的扭曲效果，在净化定制工作流中优于其他保护性扰动方法。
## 608. `cs.CV` - 穿透散射光线：重访适合逼真水下图像生成的成像模型 [PDF](https://arxiv.org/pdf/2509.15011), [HTML](https://arxiv.org/abs/2509.15011)
### Authors
Vasiliki Ismiroglou,Malte Pedersen,Stefan H. Bengtson,Andreas Aakerberg,Thomas B. Moeslund
### Background
近年来，水下图像形成模型被广泛应用于合成水下数据的生成。尽管许多方法主要关注由褪色引起的场景，但它们往往忽略了模型捕捉高度浑浊环境中距离依赖性视觉损失的能力。本研究旨在通过引入通常被忽略的前向散射项，并考虑非均匀介质，改进合成数据生成管道。
### Innovation
本文提出了一种改进的合成数据生成管道，包括了通常被忽略的前向散射项，同时考虑了非均匀介质。此外，作者在受控浑浊条件下收集了BUCKET数据集，以获取具有相应参考图像的真实浑浊视频。这表明在浊度增加的情况下可以获得定性上的改进，参与者选择率为82.5%。
### Conclusion
本研究通过改进合成数据生成管道，包括前向散射项并考虑非均匀介质，演示了在高度浑浊环境下生成逼真水下图像的能力。BUCKET数据集的收集进一步验证了这些改进的有效性。
## 609. `cs.CV` - 仅基于RGB的动态场景相机参数优化 [PDF](https://arxiv.org/pdf/2509.15123), [HTML](https://arxiv.org/abs/2509.15123)
### Authors
Fang Li,Hao Zhang,Narendra Ahuja
### Background
尽管COLMAP长期以来一直是静态场景相机参数优化的主要方法，但它受限于长时间运行和依赖真实运动掩码（GT运动掩码）来应用于动态场景。许多努力试图通过引入更多的先验知识（如GT焦距、运动掩码、3D点云、相机姿态和度量深度）来改进COLMAP，但这些信息通常不可用在随意拍摄的RGB视频中。这些方法的改进依赖于各种先验信息，但在实际场景中这些信息往往是不可获得的，因此论文提出了一种仅使用单个RGB视频作为监督信息的方法来优化动态场景下的相机参数，这种方法称为ROS-Cam。
### Innovation
该方法具有三个关键组成部分：(1) 通过在这段RGB视频中建立鲁棒且最大稀疏的铰链关系的块级跟踪滤波器；(2) 带有异常值感知联合优化的方法，通过自适应降权重移动异常值来高效优化相机参数，而无需依赖运动先验；(3) 提出了一种两阶段优化策略，通过在软加性限制和凸优解之间的权衡来增强稳定性和优化速度。上述方法的实验结果表明，该方法能够更高效、更准确地使用单个RGB视频估计相机参数。
### Conclusion
我们在四个真实世界数据集（NeRF-DS、DAVIS、iPhone和TUM-dynamics）和一个合成数据集（MPI-Sintel）上进行了实验，结果证明我们所提出的方法能够在动态场景下使用单个RGB视频进行更高效的相机参数优化。此外，通过将我们的相机估计值输入到4D重建方法中，进一步验证了该方法的准确性。
## 610. `cs.CV` - MapAnything:全能反馈式度量3D重建 [PDF](https://arxiv.org/pdf/2509.13414), [HTML](https://arxiv.org/abs/2509.13414)
### Authors
Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder
### Background
介绍了MapAnything，这是一种统一的基于变压器的前馈模型，能够处理一个或多个图像以及可选的几何输入，如相机内参、姿态、深度或部分重建等。该模型直接回归出度量3D场景几何和相机。MapAnything利用多视图场景几何的因式表示，即深度图的集合、局部射线图、相机姿态以及度量尺度因子，有效的升级了局部重建为全局一致的度量框架。该模型统一了多样数据集的监督和训练，并且具有灵活的输入增强，使得MapAnything能够在一个前馈过程中解决广泛的3D视觉任务，包括未标定的结构从运动、标定的多视图立体融合、单目深度估计、相机定位、深度补全等任务
### Innovation
MapAnything是一种统一的前馈模型，通过创新的输入处理和模型架构，能够解决多种3D重建和相机定位任务。它通过标准化监督和训练过程，在不同数据集上表现优越，并通过灵活的输入增强提高了模型的泛化能力。此外，MapAnything以单次前馈处理多个任务的方式，展示了更高效的联合训练特性，从而为3D重建提供了一个通用的骨干网络
### Conclusion
实验结果和模型消融研究表明，MapAnything在性能上超过了或匹配了专门的前馈模型，并且通过统一培训行为实现了更高效的训练。这些发现为3D重建的统一解决方案奠定了基础
## 611. `cs.CV` - 脑部MR成像中的跨域不变特征学习用于基于内容的图像检索 [PDF](https://arxiv.org/pdf/2501.01326), [HTML](https://arxiv.org/abs/2501.01326)
### Authors
Shuya Tobari,Shuhei Tomoshige,Hayato Muraki,Kenichi Oishi,Hitoshi Iyatomi
### Background
在进行大规模研究时，从多个设施收集脑部MR成像信息时，不同设施的成像设备和协议差异无法忽视，这种领域差距近年来成为一个重要问题。
### Innovation
提出了一种新的低维度表示（LDR）获取方法，即风格编码对抗域适应（SE-ADA），用于实现脑部MR图像的内容基于图像检索（CBIR）。该方法通过分离LDR中的领域特定信息并使用对抗学习最小化领域差异来减少领域差异，同时保留病理特征。
### Conclusion
SE-ADA在八个多公开脑部MR数据集（ADNI1/2/3、OASIS1/2/3/4、PPMI）中与现代领域和谐化方法的比较评估实验中，有效移除了领域信息，保留了原始脑结构的关键方面，并且在疾病搜索准确性上最高。
## 612. `cs.CV` - 设置phasers到惊呆：使用激光光束向移动机器人输送电力和控制 [PDF](https://arxiv.org/pdf/2504.17865), [HTML](https://arxiv.org/abs/2504.17865)
### Authors
Charles J. Carver,Hadleigh Schwartz,Toma Itagaki,Zachary Englhardt,Kechen Liu,Megan Graciela Nauli Manik,Chun-Cheng Chang,Vikram Iyer,Brian Plancher,Xia Zhou
### Background
介绍了Phaser系统，这是一种能够将窄光束激光光引导到移动机器人上，同时实现无线电力输送和通信的灵活系统。背景提到移动机器人在执行任务时需要持续供电，现有的无线供电技术无法满足高频次的电力需求。因此，本文提出了一个集成激光光束定向与3D机器人跟踪、低功耗光学通信的解决方案。
### Innovation
本文设计了一种半自动校准流程，结合立体视觉的3D机器人跟踪与高功率光束调节；开发了低功耗光学通信方案，利用激光光作为数据信道。使用现成硬件制作了Phaser原型并测试了其性能，展示了在多米范围内的无线电力输送和无错误数据传输能力。与蓝牙低功耗相比，其功耗仅为前者的一小部分。同时，Phaser能够实现微型电池机器人2倍以上的速度并精准导航障碍物。
### Conclusion
Phaser系统成功地实现了对移动机器人进行高速的无线电力输送和低功耗的数据传输，其优化了机器人在任务中的能源使用效率，并能够实现更精确的自主导航。该系统对未来的无人驾驶、医疗设备以及工业自动化等领域具有深远的影响。
## 613. `cs.CV` - 从游戏分析揭示人类内部注意力模式以用于强化学习 [PDF](https://arxiv.org/pdf/2504.11118), [HTML](https://arxiv.org/abs/2504.11118)
### Authors
Henrik Krauss,Takehisa Yairi
### Background
本文介绍了一种从游戏数据中揭示人类内部注意力模式的新方法，利用来自强化学习（RL）的离线注意力技术。通过在Atari环境中将人类和RL代理的游戏数据生成注意力图，研究了人类和代理的注意力模式。利用人类眼动数据中的实时整合外部注意力（TIOA）模型进行定量和定性验证，结果显示人类的注意力模式更加稀疏且与TIOA模式更为一致。进一步应用是使用这些地图来引导RL代理，发现基于人类内部注意力的代理在学习上略有改进且更加稳定。这项工作推进了人类与代理注意力差异的理解，并提供了从行为数据中提取和验证内部注意力的新途径。
### Innovation
提出了上下文化、任务相关（CTR）注意力网络，该网络能够生成人类和RL代理在Atari环境中的注意力图；使用人类眼动数据中的实时整合外部注意力（TIOA）模型进行定量和定性验证；将这些注意力图用于引导RL代理，发现改进了代理的学习效率和稳定性；提出了理解人类与代理注意力差异的新方法，并提供了一种从行为数据中提取和验证内部注意力的新途径。
### Conclusion
研究结果显示，人类的CTR注意力图比代理的注意力图更为稀疏且更符合TIOA模式；进一步应用发现，基于人类内部注意力的代理在学习上略有改进且更加稳定；这项工作不仅推进了人类和代理注意力差异的理解，还提供了一种新的方法来从行为数据中提取和验证内部注意力。
## 614. `cs.CV` - 具有自适应频域调制的高效RAW图像去模糊 [PDF](https://arxiv.org/pdf/2505.24407), [HTML](https://arxiv.org/abs/2505.24407)
### Authors
Wenlong Jiao,Binglong Li,Wei Shang,Ping Wang,Dongwei Ren
### Background
图像去模糊在增强视觉清晰度方面在各种应用中起着关键作用。尽管大多数基于深度学习的方法主要关注sRGB图像，这些图像在图像信号处理管道中会损失关键信息，但未经处理且为线性的RAW图像具有更好的恢复潜力，但仍然处于未充分开发的状态。Deblurring RAW图像面临独特的挑战，特别是在处理频率相关模糊的同时保持计算效率。
### Innovation
本文提出了针对RAW到RAW去模糊的频域增强网络（FrENet），该框架直接在频域中操作。它引入了一种新型的自适应频域位置调制模块，该模块根据频谱位置动态调整频率组件，从而能够精确控制去模糊过程。此外，还采用了频域跳跃连接以进一步保留高频细节。实验结果表明，FrENet在RAW图像去模糊方面超越了最先进的方法，同时在减少MACs方面保持了高效性。此外，FrENet的适应性使其能够扩展到sRGB图像，在sRGB数据上执行相当或更优的性能。
### Conclusion
实验结果显示，FrENet在RAW图像去模糊方面的性能超越了现有的最先进的去模糊方法，并且在减少计算复杂度方面表现出高效性。该方法的适应性还使其能够应用于sRGB图像，从而能够提供与专门针对sRGB数据的方法相当或更优的性能。源代码在GitHub上公开。
## 615. `cs.CV` - 思考与否：规则基础视觉强化微调中显式思考的研究 [PDF](https://arxiv.org/pdf/2503.16188), [HTML](https://arxiv.org/abs/2503.16188)
### Authors
Ming Li,Jike Zhong,Shitian Zhao,Yuxiang Lai,Haoquan Zhang,Wang Bill Zhu,Kaipeng Zhang
### Background
该论文研究了显式思考过程在基于规则的强化微调(RFT)中的作用，特别是在大规模语言模型(LLM)的图像分类中。传统上认为显式思考对于RFT的成功至关重要，但本文挑战了这一观点，并通过引入新的方法进一步探讨了RFT过程中是否必须进行显式思考。
### Innovation
本文提出了两种新的方法：一是CLS-RL，这是一种使用可验证奖励对LLM进行微调的方法；二是No-Thinking-RL，这是一种不需要显式思考的简单等效精度奖励方法。此外，还提出了一种称为Think-After-Answer的方法，旨在减缓潜在奖励收敛效果，以及一种称为Adaptive-Thinking的方法，使LLM能够根据任务复杂性和模型能力决定何时进行思考。
### Conclusion
实验结果表明，对于视觉感知任务，不需要显式思考即可实现更好的效果；对于能力有限的模型，不需要思考的方法比基于思考的方法效果更好；部分基于思考的RFT回答出现了不一致的情况，这表明显式思考可能妨碍奖励的收敛，影响最终性能。此外，Adaptive-Thinking方法能够使LLM根据模型能力及任务复杂性自适应地决定是否进行思考。这进一步表明，LLM能够在适当的时机进行思考，从而提高整体性能。
## 616. `cs.CV` - 仅使用幅度扩散先验的通用全息重构 [PDF](https://arxiv.org/pdf/2509.12728), [HTML](https://arxiv.org/abs/2509.12728)
### Authors
Jeongsol Kim,Chanseok Lee,Jongin You,Jong Chul Ye,Mooseok Jang
### Background
全向全息图中的相位恢复是一个基本的逆问题，但由于相干成像中振幅和相位的非线性耦合而带有病态性。在传统方法中，这种方法依赖于训练数据中包含真实相位信息，以实现从衍射强度中恢复振幅和相位的功能。
### Innovation
提出了一种全新的现成解决方案，该方法利用仅基于物体振幅训练的扩散模型，从衍射强度中恢复振幅和相位。采用预测-校正采样框架，分别对振幅和相位进行似然梯度优化，无需真实相位数据即可重建复向量场，展示了方法的适应性与普适性。
### Conclusion
该框架为计算成像中的非线性逆问题提供了一种经济高效的普适解决方案，并为全向成像之外的更广泛的相干成像应用奠定了基础。
## 617. `cs.CV` - 在野生环境中，视觉语言模型安全吗？基于表情包的基准研究 [PDF](https://arxiv.org/pdf/2505.15389), [HTML](https://arxiv.org/abs/2505.15389)
### Authors
DongGeon Lee,Joonwon Jang,Jihae Jeong,Hwanjo Yu
### Background
视觉语言模型（VLMs）的快速部署放大了安全风险，而大多数评估依赖于人工生成的图像。本研究探讨了当前VLMs在面对普通用户分享的表情包图像时的安全性。研究人员构建了一个包含50,430个实例的基准测试——MemeSafetyBench，匹配了真实的表情包图像与有害性和良性指令。通过使用全面的安全分类法和基于LLM的指令生成，评估了多个VLMs在单轮和多轮交互中的安全性能。研究考察了真实世界的表情包如何影响有害输出、对话上下文的缓解效果以及模型规模与安全指标之间的关系。研究发现，表情包表现出比合成或字型图像更强烈的危害性提示易感性，表情包显著增加了有害响应并减少了拒绝次数，尽管多轮交互提供了部分缓解，但易感性仍然较高。
### Innovation
研究人员提出并构建了一个名为MemeSafetyBench的基准测试，将表情包与有害/良性指令配对，使用全面的安全分类法和基于LLM的指令生成，评估多种VLMs的安全性能。研究发现，VLMs在面对表情包时的安全性远低于合成或字型图像，尽管多轮交互提供了部分缓解，但总体上VLMs的易感性仍然较高。这一成果突显了生态学有效评估和更强大安全机制的重要性。MemeSafetyBench是一个公开可用的基准测试。
### Conclusion
表情包显著增加了VLMs的有害响应并减少了拒绝次数，尽管多轮交互可以部分缓解这一问题，但VLMs的易感性仍然较高。研究结果强调了需要进行生态学有效评估和采取更强的安全机制。
## 618. `cs.LG` - 预遗忘模型：记忆学习作为本征机制的遗忘 [PDF](https://arxiv.org/pdf/2509.15230), [HTML](https://arxiv.org/abs/2509.15230)
### Authors
Rutger Hendrix,Giovanni Patanè,Leonardo G. Russo,Simone Carnemolla,Giovanni Bellitto,Federica Proietto Salanitri,Concetto Spampinato,Matteo Pennisi
### Background
基础模型已经通过使跨不同模态和任务的表示具有鲁棒性和可转移性，变革了多媒体分析。然而，由于传统的遗忘方法如重新训练、激活编辑或蒸馏往往计算成本高、脆弱且不合适于实时或持续进化的系统，传统方法已无法满足日益增长的社会和监管需求，特别是GDPR等隐私框架中指定的根据请求卸载特定数据的需求。
### Innovation
本文提出了范式转变：将遗忘重新定义为内置能力，而不是事后干预。提出了一个基于提示的学习框架，将知识获取和去除统一在一个训练阶段。通过将类级别的语义绑定到特定的提示标记，而不是编码在模型权重中，该方法可以通过简单地移除相应的提示来立即遗忘，无需重新训练、修改模型或访问原始数据。实验表明，该框架可以在保留类上保持预测性能的同时有效地清除遗忘类。此外，该方法还表现出强大的隐私和安全保证：其对成员推断攻击具有抵抗力，提示移除防止任何形式的知识提取，即使在对抗条件下也是如此。
### Conclusion
总体而言，通过将可移除性内置到架构本身，本文为设计模块化、可扩展和伦理响应的AI模型奠定了新的基础，确保了与数据保护原则的一致性，并防止了未授权访问已遗忘信息，使框架适用于敏感和规范化的环境部署。
## 619. `cs.CV` - Perception-R1: 通过视觉感知奖励提升多模态大规模语言模型的多模态推理能力 [PDF](https://arxiv.org/pdf/2506.07218), [HTML](https://arxiv.org/abs/2506.07218)
### Authors
Tong Xiao,Xin Xu,Zhenya Huang,Hongyu Gao,Quan Liu,Qi Liu,Enhong Chen
### Background
提升多模态大型语言模型（MLLM）的多模态推理能力是一个具有挑战性的任务，引起了学术界的广泛关注。最近，一些研究使用可验证奖励增强学习（RLVR）方法在多模态领域提升了MLLM的推理能力。然而，这些工作却忽视了提升MLLM的多模态感知能力，这是复杂多模态推理的核心前提和基础部件。通过麦纳梅尔检验，我们发现现有的RLVR方法无法有效提升MLLM的多模态感知能力，从而限制了其在多模态推理中的进一步改进。
### Innovation
为解决这一限制，本文提出了Perception-R1，该方法引入了一种新颖的视觉感知奖励，明确鼓励MLLM准确感知视觉内容，从而有效地激励了其多模态感知能力和推理能力。具体地，首先从多模态问题的CoT轨迹中收集文本视觉注释，这些注释将作为奖励分配的视觉参考。在RLVR训练期间，使用评判LLM评估MLLM生成的回应与视觉注释之间的一致性，并根据这些一致性判断分配视觉感知奖励。
### Conclusion
广泛的多模态推理基准实验证明了我们提出的Perception-R1的有效性，仅使用1,442个训练数据就实现了大多数基准的最先进性能。
## 620. `cs.LG` - 跨药物共注意力的多尺度图神经过程用于药物-药物相互作用预测 [PDF](https://arxiv.org/pdf/2509.15256), [HTML](https://arxiv.org/abs/2509.15256)
### Authors
Zimo Yan,Jie Zhang,Zheng Xie,Yiping Song,Hao Li
### Background
药物-药物相互作用（DDI）的准确预测对于临床用药安全和药物开发至关重要，但现有方法往往难以捕捉不同尺度的结构信息，以及缺乏量化预测置信度的机制。
### Innovation
提出了一种全新的多尺度图神经过程框架MPNP-DDI，该框架的核心是迭代应用的多尺度图表示 aprender，结合跨药物共注意力机制动态融合多尺度表示，生成交互药物对的上下文感知嵌入，并通过整合的神经过程模块提供原理性的不确定性估计。
### Conclusion
广泛的实验表明，MPNP-DDI 在基准数据集上显著优于最先进的基线。MPNP-DDI 提供了基于多尺度结构特征的准确、可迁移且具有不确定性的预测，代表了药物警戒、多药风险评估和精准医疗的有力计算工具。
## 621. `cs.CV` - HistDiST: 基于扩散的组织病理学着色迁移 [PDF](https://arxiv.org/pdf/2505.06793), [HTML](https://arxiv.org/abs/2505.06793)
### Authors
Erik Großkopf,Valay Bundele,Mehran Hosseinzadeh,Hendrik P.A. Lensch
### Background
H&E染色是组织病理学的基础，但缺乏分子特异性。免疫组化(IHC)提供了分子层面的信息，但成本昂贵且复杂，因此人们探索H&E到IHC的翻译作为成本效益更高的替代方法。现有的翻译方法主要是基于GAN的方式，但这些问题常常受到训练不稳定性和结构保真度有限的限制。扩散模型（DDPM）方法虽然潜力被低估，但仍然较少研究。为了克服H&E到IHC翻译中的亮度偏差，研究人员提出了一种结合形态学嵌入和VAE编码的策略，利用Phikon提取的形态学嵌入和VAE编码的H&E表示来确保病理相关背景和结构的一致性。
### Innovation
研究人员提出了HistDiST，这是一种基于Latent Diffusion Model (LDM)的方法，用于实现高保真的H&E到IHC的翻译。 HistDiST引入了一种双条件策略，结合了Phikon提取的形态学嵌入和VAE编码的H&E表示，以确保病理相关背景和结构的一致性。为了克服亮度偏差，还提出了一个重缩放的噪声时间表、v-预测以及尾部时间点的策略，确保最终时间点的零SNR条件。在推断过程中，使用DAOIM（动态适应性逆扩散模型）维持形态结构，同时引入了一个η-余弦噪声调度，以平衡结构一致性和分子保真度。此外，提出了一种新的评价指标MRA（Molecular Retrieval Accuracy），该指标利用GigaPath嵌入评估分子相关性。在MIST和BCI数据集上的大量评估显示，HistDiST显著优于现有方法，在H&E到Ki67翻译任务上的MRA指标提高了28%，证明了其在捕获真实IHC语义方面的有效性。
### Conclusion
研究表明，HistDiST在H&E到IHC的翻译中表现出高度的结构一致性与分子保真度，在MRA指标上的提升为28%，证实了其在真实IHC语义捕捉方面的有效性。
## 622. `cs.CV` - 数据高效学习实现普适性外科视频理解 [PDF](https://arxiv.org/pdf/2508.10215), [HTML](https://arxiv.org/abs/2508.10215)
### Authors
Sahar Nasirihaghighi
### Background
外科视频分析的进步正在将手术室转变为智能化、数据驱动的环境。计算机辅助系统支持从术前规划到术中指导再到术后评估的整个手术工作流程。然而，开发适用于各种手术方法和医疗机构的稳健和通用的外科视频理解模型仍具有挑战性，主要由于注释稀缺、时空复杂性和领域差距等问题。本博士研究旨在弥合基于深度学习的外科视频分析在研究与临床部署之间的差距。研究集中在解决识别外科阶段、动作和事件的核心挑战，开发了半监督框架，以利用大量未标注的手术视频，增强模型性能。同时，发布两个多任务数据集：GynSurg（最大的妇科学机器人手术数据集）和Cataract-1K（最大的白内障手术视频数据集）。
### Innovation
研究开发了新型半监督框架，包括DIST、SemiVT-Surge和ENCORE，并通过动态伪标签增强模型训练，实现复杂外科数据集上的先进结果。还提出了两个大规模数据集，分别为GynSurg和Cataract-1K，以支持研究的可重复性和领域进展。
### Conclusion
本研究为外科视频分析贡献了稳健、数据高效且临床可扩展的解决方案，为通用人工智能系统的开发奠定了基础，这些系统可以对外科护理和培训产生实质性影响。
## 623. `cs.LG` - 将变换器模型视为复杂网络以分析学习动态 [PDF](https://arxiv.org/pdf/2509.15269), [HTML](https://arxiv.org/abs/2509.15269)
### Authors
Elisabetta Rocchetti
### Background
在训练过程中，大型语言模型（LLMs）是如何获得复杂能力仍是一个重要的机制可解释性问题。本文探索了利用复杂网络理论（CNT）表征这些学习动力学的可能性。
### Innovation
作者提出了一种新的方法来将基于变换器的LLM表示为有向加权图，节点代表模型的计算组件（注意头和MLP），边代表因果影响，通过基于干预的方法来测量。通过对Pythia-14M模型在经典引理任务上143个训练检查点的分步分析，揭示网络结构在探索、巩固和改进的不同阶段演变，特别是识别出稳定的信息传播者组件和动态的信息搜集者组件。
### Conclusion
这项工作表明，组件级别的网络视角为可视化和理解驱动LLMs形成功能电路的自我组织原理提供了一种强有力的方法。
## 624. `cs.LG` - 生成人工智能遇见无线传感：迈向无线基础模型 [PDF](https://arxiv.org/pdf/2509.15258), [HTML](https://arxiv.org/abs/2509.15258)
### Authors
Zheng Yang,Guoxuan Chi,Chenshu Wu,Hanyu Liu,Yuchong Gao,Yunhao Liu,Jie Xu,Tony Xiao Han
### Background
生成人工智能（GenAI）在计算机视觉（CV）和自然语言处理（NLP）等领域取得了显著进展，显示了其合成高保真数据和增强泛化的潜力。最近，研究者开始关注如何将GenAI集成到无线传感系统中，在充分利用数据扩充、领域适应和去噪等生成技术的基础上，可以显著提升设备定位、人类活动识别和环境监测等无线传感应用的效果。
### Innovation
本文从两个互补的角度探讨了GenAI和无线传感的交汇，一是研究如何将GenAI集成到无线传感管道中，具体分为作为插件增强任务特定模型和直接解决传感任务的解题模式。二是分析主流生成模型的特性，如生成对抗网络（GANs）、变分自编码器（VAEs）和扩散模型，并讨论它们在不同类型无线传感任务中的应用价值和独特优势。本文还指出了应用GenAI到无线传感面临的挑战，并提出未来发展方向，即构建一个统一、预训练的设计，使其能够在不同传感任务中实现可扩展的、适应性强且高效的信号理解。
### Conclusion
本文确立了将GenAI应用于无线传感的主要挑战，并强调了开发统一、预训练的无线基础模型的重要性，该模型能够针对多种传感任务实现规模化、适应性和效率的提升。
## 625. `cs.LG` - 在社交媒体上监测娱乐药物使用效果的一种弱监督方法 [PDF](https://arxiv.org/pdf/2509.15266), [HTML](https://arxiv.org/abs/2509.15266)
### Authors
Lucía Prieto-Santamaría,Alba Cortés Iglesias,Claudio Vidal Giné,Fermín Fernández Calderón,Óscar M. Lozano,Alejandro Rodríguez-González
### Background
了解娱乐药物在现实世界中的实际效果仍然是公共卫生和生物医药研究的一个关键挑战。传统监控系统往往未能充分反映用户的经验。因此，本研究利用Twitter这样的社交媒体平台作为丰富且未经筛选的用户报告效果来源，探索新兴致幻物质（如摇头丸、γ-羟基丁酸和2C-B）的影响。
### Innovation
研究采用了弱监督方法结合医学概念提取技术MetaMap，并通过一个受专家指导的启发式流程标记了极性（正面或负面效果），开发了多个机器学习分类器以预测极性，同时处理了类别不平衡问题，提高了预测准确性，并使用了极端梯度提升和成本敏感学习方法。
### Conclusion
研究发现了Twitter能够检测物质特异性表型效果，并表明极性分类模型可以支持实时药效监测和药物效果的高精度描述。
## 626. `cs.LG` - 全局预设，局部调整：一种简单而有效的对比度持续学习策略 [PDF](https://arxiv.org/pdf/2509.15347), [HTML](https://arxiv.org/abs/2509.15347)
### Authors
Jia Tang,Xinrui Wang,Songcan Chen
### Background
持续学习（CL）涉及从不断变化的任务中获取和积累知识，同时缓解灾难性遗忘。近年来，利用对比损失构建更具迁移性和更少遗忘特性的表示是一种有前景的方向。尽管取得了进展，但其性能仍受限于任务间和任务内特征的混淆。为了应对这一问题。
### Innovation
提出了一种简单的对比策略，名为全局预设、局部调整的监督对比学习（GPLASC），避免了任务级混淆，通过划分代表单元超球面为不重叠区域，并形成跨任务预设的等角紧框（ETF），同时在每个任务中也形成可调控的ETF，确保在任务间和任务内具有区分性的特征结构，且可以无缝集成到任何现有对比持续学习框架。
### Conclusion
广泛的实验验证了其有效性。
## 627. `cs.LG` - 随机样本逼近（局部）连续模量 [PDF](https://arxiv.org/pdf/2509.15368), [HTML](https://arxiv.org/abs/2509.15368)
### Authors
Rodion Nazarov,Allen Gehret,Robert Shorten,Jakub Marecek
### Background
本文使用局部连续模量来评估神经网络的稳健性和其重复使用时的公平性。研究中重新审视了广义导数与局部连续模量之间的联系，强调了研究神经网络稳健性和重复使用公平性的关键性。
### Innovation
本文提出了非均匀随机样本逼近局部连续模量的方法，这对于研究神经网络的稳健性以及其重复使用时的公平性具有重要意义。
### Conclusion
通过这种方法，可以更好地评估神经网络在闭环模型中的稳健性和公平性，有助于提高系统的整体性能和可靠性。
## 628. `cs.LG` - 无乘法器印刷机学习分类器的混合一进制设计 [PDF](https://arxiv.org/pdf/2509.15316), [HTML](https://arxiv.org/abs/2509.15316)
### Authors
Giorgos Armeniakos,Theodoros Mantzakidis,Dimitrios Soudris
### Background
印刷电子（PE）提供了比硅材料成本效益更高的解决方案，用于实现机器学习（ML）电路，但其较大的特征尺寸限制了分类器的复杂性。利用PE的低成本制造和非重复性成本，设计人员可以将硬件定制化以适应特定的ML模型，简化电路设计.
### Innovation
该工作探索了替代的算术方法并提出了一种混合一进制-二进制架构，这种架构消除了昂贵的编码器，实现了无乘法器的多层感知器（MLP）分类器高效执行。同时引入了架构感知训练，进一步提高了面积和功耗效率.
### Conclusion
在六个数据集上的评估表明，在面积和功耗上分别平均减少了46%和39%，并且对准确率的影响很小，超过了其他最先进的MLP设计.
## 629. `cs.LG` - Fleming-R1: 通过强化学习实现专家级医疗推理 [PDF](https://arxiv.org/pdf/2509.15279), [HTML](https://arxiv.org/abs/2509.15279)
### Authors
Chi Liu,Derek Li,Yan Shu,Robin Chen,Derek Duan,Teng Fang,Bryan Dai
### Background
尽管大型语言模型在医疗领域的应用前景广阔，但在实现专家级的临床推理方面仍然面临挑战，因为需要同时提供准确的答案和透明的推理过程。
### Innovation
Fleming-R1 通过三种互补的创新来解决这一挑战：1) 通过组合定制的医疗QA数据集与知识图谱引导的合成，来改善对罕见疾病、药物以及多步推理链的覆盖；2) 使用“思维链”冷启动技术从教师模型中提取高质量的推理轨迹，建立稳健的推断先验；3) 实施包含两阶段验证性奖励强化学习框架，通过分组相对策略优化来巩固核心推理技能，并通过自适应挖掘难题样本来瞄准持续的失败模式。
### Conclusion
Fleming-R1 在多种医疗基准测试中表现出显著的参数效率改进：7B版本超过许多更大的基线模型，而32B模型接近GPT-4o的性能并持续优于强大的开源替代品。这些结果表明，结构化数据设计、推理导向的初始化和验证性强化学习可以推动临床推理超越简单的准确性优化。Fleming-R1 旨在推动医疗AI的透明、可重现和可审计进展，促进在高风险临床环境中的安全部署。
## 630. `cs.LG` - IEFS-GMB: Gradient Memory Bank-Guided Feature Selection Based on Information Entropy for EEG Classification of Neurological Disorders [PDF](https://arxiv.org/pdf/2509.15259), [HTML](https://arxiv.org/abs/2509.15259)
### Authors
Liang Zhang,Hanyang Dong,Jia-Hong Gao,Yi Sun,Kuntao Xiao,Wanli Yang,Zhao Lv,Shurong Sheng
### Background
基于深度学习的脑电图（EEG）分类对于自动检测神经疾病至关重要，有助于提高诊断准确性并实现早期干预。然而，脑电信号的低信噪比限制了模型性能，使得特征选择（FS）对于优化神经网络编码器学到的表示变得至关重要。现有的FS方法很少专门针对EEG诊断设计，很多方法依赖于特定的架构且缺乏可解释性，这限制了它们的适用性。此外，大多数现有的FS方法依赖于单次迭代数据，导致对变异性的鲁棒性不足。
### Innovation
我们提出了一种基于信息熵由梯度记忆库指导的特征选择方法（IEFS-GMB），该方法通过构建一个存储历史梯度的动态记忆库，计算特征的重要程度，并采用基于熵的加权来选择有意义的EEG特征。该方法在四个公开的神经疾病数据集上进行了实验，结果显示与基线模型相比，增强的编码器取得了0.64%到6.45%的准确率提升。此外，该方法还优于四种竞争的FS技术，并提高了模型的可解释性，支持其实用性在临床环境中的应用。
### Conclusion
实验结果表明，集成IEFS-GMB后，编码器在四个公开的神经疾病数据集上的准确率提高了0.64%到6.45%，并且该方法在性能上超过了四种竞争的FS技术，同时提高了模型的可解释性，利于临床应用。
## 631. `cs.LG` - 预测大规模语言模型在零样本概率预测中的成功 [PDF](https://arxiv.org/pdf/2509.15356), [HTML](https://arxiv.org/abs/2509.15356)
### Authors
Kevin Ren,Santiago Cortes-Gomez,Carlos Miguel Patiño,Ananya Joshi,Ruiqi Lyu,Jingjing Tang,Alistair Turcan,Khurram Yamin,Steven Wu,Bryan Wilder
### Background
近年来的研究已经探索了大语言模型（LLMs）作为零样本模型生成个体特征的能力（例如，作为风险模型或补充调查数据集）。然而，用户何时可以有信心相信LLM将为其特定任务提供高质量的预测呢？为了解决这个问题，我们对LLMs在各种表格预测任务中的零样本预测能力进行了大规模实证研究。我们发现，LLMs的表现高度不稳定，即使是在同一个数据集内的任务之间，以及不同数据集之间。然而，当LLM在基本预测任务表现良好时，其预测的概率变得更加能代表个体级别的准确性。
### Innovation
我们在研究中开发了预测LLM在任务级别表现的度量标准，目的是区分LLM可能表现良好的任务与很可能不适用的任务。我们发现，其中一些度量标准没有使用标记数据，就能够强烈地预示LLMs在新任务上的预测性能。
### Conclusion
研究发现，LLMs在不同任务上的表现高度不稳定，但在基本任务表现良好的情况下，预测概率能够更好地反映个体级别的准确性。我们提出了新的度量标准，能够在未使用标记数据的情况下，有效预测LLMs在新任务上的表现。
## 632. `cs.LG` - 在小样本设置中提供概率性齐性覆盖保证 [PDF](https://arxiv.org/pdf/2509.15349), [HTML](https://arxiv.org/abs/2509.15349)
### Authors
Petrus H. Zwart
### Background
齐性预测提供无需假设数据分布的预测集，并保证边缘覆盖。然而，在分割齐性预测中，这一保证仅在期望条件下成立：尽管多次校准抽取的平均覆盖率等于预设值，但单次校准集的实际覆盖率可能有很大差异。这种差异性削弱了在实际应用中的风险控制效果。
### Innovation
引入了小型样本贝塔修正（SSBC），这是一种可以应用于齐性显著性水平的即插即用调整方法。该修正利用齐性覆盖的确切有限样本分布，提供了概率性的保证，确保在用户设定的概率校准抽样中，部署的预测器至少能达到预设的覆盖率。
### Conclusion
通过SSBC调整，保证了齐性预测在小样本条件下的有效覆盖率达到期望要求，从而解决现有齐性预测在实际应用场景中遇到的风险控制问题。
## 633. `cs.LG` - 使用图神经网络的分部列生成方法用于团队形成和路由 [PDF](https://arxiv.org/pdf/2509.15275), [HTML](https://arxiv.org/abs/2509.15275)
### Authors
Giacomo Dall'Olio,Rainer Kolisch,Yaoxin Wu
### Background
团队形成和路由问题是优化领域中的一个具有挑战性的难题，尤其适用于机场、医疗和维护操作等实际应用领域。传统上，基于列生成的精确解决方案方法被提出用于解决这个问题。然而，当问题具有多个定价问题时，现有的列生成策略可能存在不足，尤其是在时间限制下解决困难实例时效率低下。因此，为了提高解决该问题的效率和准确性，本文提出了一种新的基于图神经网络的分部列生成策略，能够预测哪些定价问题最有可能生成具有负对偶代价的列。
### Innovation
本文提出了一种新颖的基于图神经网络的分部列生成策略，该策略专门针对团队形成和路由问题，利用图神经网络来预测可能导致负对偶代价的列的定价问题。与传统的方法相比，本文的策略在解决困难实例时表现更优，特别是在时间限制下的表现更为突出。
### Conclusion
通过计算实验表明，应用本文提出的分部列生成策略能够提高优化方法的性能，相较于文献中的传统分部列生成方法，本文的方法在困难实例下的表现更为优秀。
## 634. `cs.LG` - VMDNet：基于无泄漏样本变分模态分解和多分支解码的时间序列预测 [PDF](https://arxiv.org/pdf/2509.15394), [HTML](https://arxiv.org/abs/2509.15394)
### Authors
Weibin Feng,Ran Tao,John Cartlidge,Jin Zheng
### Background
时间序列预测中捕获反复出现的时间模式是至关重要的；分解技术使这种结构变得明确，从而提高预测性能。变分模态分解（VMD）是一种用于周期性感知分解的强信号处理方法，并且近年来越来越受欢迎。然而，现有研究往往存在信息泄漏的问题，并依赖于不合适的超参数调整。
### Innovation
为了应对这些问题，我们提出了一种因果关系保持框架VMDNet：（i）对每个样本使用样本级VMD，避免泄漏；（ii）每个分解的模式用频率感知嵌入表示，并使用并行时间卷积网络解码，确保模式独立性和高效的学习；（iii）引入了一种双层、斯泰克尔伯格启发式的优化，以自适应选择VMD的两个核心超参数：模式数（K）和带宽惩罚（alpha）。
### Conclusion
在两个与能源相关的数据集上的实验表明，当周期性较强时，VMDNet达到了最先进的结果，表现出在强周期性和弱周期性情况下捕获结构化周期模式的优势。
## 635. `cs.LG` - 单矩阵理论引导的稀疏主成分分析方法用于单细胞RNA测序数据 [PDF](https://arxiv.org/pdf/2509.15429), [HTML](https://arxiv.org/abs/2509.15429)
### Authors
Victor Chardès
### Background
单细胞RNA测序技术能够提供详细的分子快照，但由于其固有的噪音特性而极具挑战性。变异性来源于生物学差异、PCR扩增偏差、有限的测序深度以及低捕获效率。因此，大多数研究仍然依赖于主成分分析（PCA）进行降维，因其可解释性和稳健性而在这些方面得到应用。然而，现有的PCA方法在处理异质数据集或先进技术时的适应性有限。
### Innovation
该研究提出了一种基于随机矩阵理论（RMT）的方法，通过现有的稀疏PCA算法推导出稀疏的主要成分。首先引入了一种新颖的biwhitening方法，借鉴了Sinkhorn-Knopp算法，同时稳定基因和细胞间的方差。这种方法允许使用RMT准则自动选择稀疏度，使得稀疏PCA几乎无需参数化。这种方法既保持了PCA的可解释性，又能够进行稳健的、无干预的稀疏主要成分推断。
### Conclusion
该方法在七种单细胞RNA测序技术和四种稀疏PCA算法中均显示出优异的表现，系统地提高了原始主要子空间的重建性能，并在细胞类型分类任务中一致优于基于PCA、自编码器和扩散的方法。
## 636. `cs.LG` - 自适应算法在随机层次优化中的锐化收敛率 [PDF](https://arxiv.org/pdf/2509.15399), [HTML](https://arxiv.org/abs/2509.15399)
### Authors
Xiaochuan Gong,Jie Hao,Mingrui Liu
### Background
层次优化涉及相互依赖的决策变量和目标，如最小极大和 bilevel 形式化问题。尽管已有多种算法被提出，现有方法和分析在随机优化设置中缺乏适应性：这些方法不能在广泛的梯度噪声水平下达到最优收敛速率，除非事先知道噪声幅度。
### Innovation
本文提出了针对随机层次优化两类重要问题（非凸强凹最小极大优化和非凸强凸 bilevel 优化）的自适应算法，实现了梯度范数的锐化收敛速率 $tilde{O}(1/text{sqrt}(T) + text{sqrt}( bar{text{sigma}}) / T^{1/4} )$。这些速率不需噪声水平的先验知识，从而能在低噪声和高噪声环境中自动适应。
### Conclusion
本文提供了随机层次优化的第一个自适应和锐化收敛保证。我们的算法设计结合了动量归一化技术与新颖的自适应参数选择。广泛的实验证明了我们提出的算法的有效性。
## 637. `cs.LG` - Kuramoto Orientation Diffusion Models [PDF](https://arxiv.org/pdf/2509.15328), [HTML](https://arxiv.org/abs/2509.15328)
### Authors
Yue Song,T. Anderson Keller,Sevan Brodjian,Takeru Miyato,Yisong Yue,Pietro Perona,Max Welling
### Background
背景：方向丰富的图像（如指纹和纹理）通常具有共轭的方向模式，标准基于各向同性欧几里得扩散的生成方法难以捕捉这类特性。受生物系统中相位同步作用的启发，本研究提出了一种基于周期性域的分数生成模型，利用粘动Kuramoto动力学在扩散过程中对相位变量进行同步，从而有效生成结构化图像。
### Innovation
创新：该研究利用粘动Kuramoto模型实现相位变量之间的同步，该模型通常用于神经和物理系统中，描述耦合振荡器之间的同步现象。粘动模型在此被重新设计为生成结构化图像的归纳偏差。这种方法在前进过程中可以进行有结构的破坏，并通过逆过程实现分层生成过程，逐步将数据集中到低熵的von Mises分布，从而生成多样化的精细图像模式，并利用裹紧的高斯过渡核和周期性感知网络来考虑圆周几何形状。在通用图像基准测试和方向密集数据集（如指纹和纹理）上取得了具有竞争力的结果，显著提升了生成质量，证明了基于生命科学中相位同步的生成模型的优势和潜力。
### Conclusion
结论：本研究展示了生物启发的同步动力学作为生成模型中结构化先验的潜力，这种模型可以在前进扩散过程中实现有结构的破坏，并通过迭代过程逐级细化全局一致性，逐步生成精细的细节。该模型在通用图像基准测试和方向密集数据集（如指纹和纹理）上的表现证明了其方法的有效性和优势。
## 638. `cs.LG` - 使用跳接连接计算神经网络的线性区域 [PDF](https://arxiv.org/pdf/2509.15441), [HTML](https://arxiv.org/abs/2509.15441)
### Authors
Johnny Joyce,Jan Verschelde
### Background
神经网络是机器学习中重要的工具，通过使用代数中的热带算术表示分段线性激活函数，可以利用热带几何的应用。本文通过算法计算了神经网络中线性映射的区域，并通过实验揭示了训练神经网络的难度，特别是在过拟合问题和跳接连接优势方面的见解。
### Innovation
本文提出了一种算法来计算神经网络的线性区域，通过使用热带几何来表示分段线性的激活函数。同时，该研究通过实验深入探讨了神经网络训练中的过拟合问题以及跳接连接的潜在优势。
### Conclusion
通过实验结果，本文提供了对神经网络训练难度的见解，特别强调了过拟合问题以及跳接连接在提升模型泛化能力方面的积极作用。
## 639. `cs.LG` - Stackelberg均场博弈中的学习：非渐近分析 [PDF](https://arxiv.org/pdf/2509.15392), [HTML](https://arxiv.org/abs/2509.15392)
### Authors
Sihan Zeng,Benjamin Patrick Evans,Sujay Bhatt,Leo Ardon,Sumitra Ganesh,Alec Koppel
### Background
本研究探讨了在Stackelberg均场博弈（MFGs）中进行策略优化的方法。Stackelberg MFG是一种分层框架，用于建模单一领导者与无限数量的同质追随者之间的战略互动。这一问题可被建模为一个有层次的优化问题，领导者需要根据追随者的潜在反应学习最大化自身奖励的策略。现有的方法往往依赖于领导者和追随者目标间严格的独立性假设，算法结构导致样本使用效率低下，且缺乏有限时间收敛的保证。
### Innovation
为解决上述局限，提出了AC-SMFG算法，这是一种基于连续生成马尔可夫样本的单环路actor-critic算法。该算法通过交替进行领导者、代表追随者和均场的半梯度更新，结构简单，在实践中易于实现。该研究确立了算法在有限时间和样本数下的收敛性，即在Stackelberg目标的稳定点收敛。这是首次为Stackelberg MFG提供非渐近收敛保证的算法。关键假设是“梯度对齐”条件，即领导者完整的策略梯度可以通过其部分分量进行近似，从而放松了现有的领导者和追随者独立性假设。
### Conclusion
仿真结果显示AC-SMFG在多个经验证的经济环境中表现出更高的策略质量与更快的收敛速度，优于现有基于多智能体和MFG的学习基准。
## 640. `cs.LG` - Unfolding (模型基)网络的对抗健全部分泛化 [PDF](https://arxiv.org/pdf/2509.15370), [HTML](https://arxiv.org/abs/2509.15370)
### Authors
Vicky Kouni
### Background
展开网络是一种可解释的网络，通过迭代算法逐渐形成，并且整合了数据结构先验知识，主要用于解决压缩感知等逆问题，即从噪声和缺失观测的数据中恢复数据。压缩感知在医疗成像、密码学等关键领域有着广泛应用，尤其是在对抗性强健性至关重要的场合，以防止严重的系统性故障。然而，对于展开网络在其受到 $l_2$ 范数约束下的对抗性攻击时的性能理解仍然非常有限。本文针对一种过参数化的展开网络家族，研究其抵抗 $l_2$ 动态量攻击的分泛化能力，采用快速梯度符号方法生成攻击。
### Innovation
本文首次系统地研究了展开网络在受到 $l_2$ 范数约束下的对抗性攻击时的分泛化能力。作者提出了一种新框架来估计过参数化展开网络的对抗性拉德默彻尔复杂度，并基于此给出了网络在不同攻击强度下的分泛化错误界。此项研究为理解展开网络在对抗攻击情况下的性能提供了理论基础，强调了过参数化在提升网络对抗性鲁棒性方面的潜力。
### Conclusion
本文的研究成果揭示了如何利用过参数化机制有效提升神经网络的对抗性鲁棒性，并为广大研究者提供了一定的理论指导。未来的工作可以进一步探索其他更为复杂的对抗攻击和网络结构调整方法来提高网络的鲁棒性。
## 641. `cs.LG` - Top-$k$ Feature Importance Ranking [PDF](https://arxiv.org/pdf/2509.15420), [HTML](https://arxiv.org/abs/2509.15420)
### Authors
Yuxi Chen,Tiffany Tang,Genevera Allen
### Background
在可解释的人工智能中，准确排名重要的特征是一个根本性的挑战，并且在科学研究和决策制定中具有关键应用。虽然特征选择和特征重要性已经受到了一定关注，但更具体地对重要特征进行排序的问题则受到了较少关注。
### Innovation
我们引入了一种名为RAMPART（Ranked Attributions with MiniPatches And Recursive Trimming）的新框架，该框架利用任何现有的特征重要性度量来为排名前$k$的特征设计一个新颖的算法。该方法结合了自适应的逐步排除策略，该策略逐步聚焦于有希望的特征，以及使用观测和特征子采样的高效集成技术。与现有方法不同，RAMPART框架直接针对排名准确性进行了优化。
### Conclusion
我们提供了理论保证，证明在轻微条件下，RAMPART以高概率获得正确的前$k$排名。通过广泛的模拟研究，我们展示了RAMPART在多个场景中均能优于流行的特征重要性方法。最后，我们在一个高维基因组案例研究中证明了这一点。
## 642. `cs.LG` - 在模拟城市中探索多模态隐式行为学习以进行车辆导航 [PDF](https://arxiv.org/pdf/2509.15400), [HTML](https://arxiv.org/abs/2509.15400)
### Authors
Eric Aislan Antonelo,Gustavo Claudio Karl Couto,Christian Möller
### Background
标准的行为克隆（BC）方法在遇到同一场景中有多种有效行动时，无法有效学习。为此，该研究探讨了使用能量基础模型（EBM）的隐式行为克隆（IBC）方法来更好地捕捉多模态特性。该研究进一步提出了数据增强的隐式行为克隆（DA-IBC），该方法通过扰动专家行动以形成IBC训练的反例，并使用更好的初始化以改进无导数推断，从而提高学习效果。实验结果表明，在CARLA模拟器中，使用鸟类视角输入的DA-IBC方法在评估隐藏多模态行为学习的测试环境中击败了标准IBC方法。
### Innovation
提出了一种数据增强的隐式行为克隆（DA-IBC）方法。该方法通过调整专家行动生成用于IBC训练的反例，并通过更好初始化进行无导数推断以提升学习效率。此外，实验结果发现，DA-IBC学习的能量景观能够表示多模态动作分布，这是标准行为克隆（BC）无法做到的。
### Conclusion
与标准行为克隆方法相比，DA-IBC方法在模拟城市中的多模态行为学习方面表现更优。它能够在CARLA模拟器中更好地捕捉多模态驾驶决策，其学习到的能量景观能有效表示多模态动作分布，适用于多模态驾驶行为的评估。
## 643. `cs.LG` - 基于图变换的因果关系时空依赖太阳能预测 [PDF](https://arxiv.org/pdf/2509.15481), [HTML](https://arxiv.org/abs/2509.15481)
### Authors
Yanan Niu,Demetri Psaltis,Christophe Moser,Luisa Lambertini
### Background
准确的太阳能预测对于有效的可再生能源管理至关重要。传统的太阳能预测方法通常依赖于天空摄像头或卫星图像等需要特殊硬件和大量预处理的数据，这使得这些方法在应用上有一定的局限性。SolarCAST模型通过使用历史水平总辐射量（GHI）数据以及附近站点的GHI数据，提出了一个新的预测方法，无需使用天空摄像头或卫星图像，而是利用公开的传感器数据来实现高精度的预测。
### Innovation
SolarCAST模型提出了一个新的方法来解决现有方法的问题。该模型通过可扩展的神经网络组件来建模三个级别的混杂因素，以实现精准的预测：（i）可观察的同步变量，（ii）潜在的同步因素，（iii）时间滞后效应。它的性能优于领先的时间序列和多模态基准模型，并且比顶级商用预测器Solcast在错误率上降低了25.9%。
### Conclusion
SolarCAST提供了一个轻量级、实用且具有通用性的解决方案，适用于局部太阳能预测。
## 644. `cs.LG` - Detail Across Scales: Multi-Scale Enhancement for Full Spectrum Neural Representations [PDF](https://arxiv.org/pdf/2509.15494), [HTML](https://arxiv.org/abs/2509.15494)
### Authors
Yuan Ni,Zhantao Chen,Cheng Peng,Rajan Plumley,Chun Hong Yoon,Jana B. Thayer,Joshua J. Turner
### Background
现有的隐神经表示（INRs）作为一种紧凑且参数化的替代方案，以神经网络权重直接编码信息，实现了解析度无关的表示和内存效率，但这些方法在受限于紧凑网络大小时，难以准确表示大多数科学数据集中的多尺度结构、高频率信息和细纹理。
### Innovation
提出了一种名为WIEN-INR的波let感知隐神经表示，它在不同分辨率尺度上分配建模，并在最细尺度上使用专门的核网络以恢复细微的细节。这种多尺度结构允许使用较小的网络来保留全部信息范围，同时保持训练效率并降低存储成本。通过在不同尺度和结构复杂度的科学数据集上进行大量实验，WIEN-INR实现了卓越的重建保真度，同时保持了紧凑的模型大小。
### Conclusion
这些结果表明，WIEN-INR是一种实用的神经表示框架，适用于高保真科学数据编码，将INRs的应用扩展到要求高效保留细节数量的领域。
## 645. `cs.LG` - IMPQ：LLMs中基于层交互的混合精度量化方法 [PDF](https://arxiv.org/pdf/2509.15455), [HTML](https://arxiv.org/abs/2509.15455)
### Authors
Junchen Zhao,Ali Derakhshan,Dushyant Bharadwaj,Jayden Kana Hyman,Junhao Dong,Sangeetha Abdu Jyothi,Ian Harris
### Background
大语言模型（LLMs）具备强大的能力，但由于其包含数十亿参数的巨大规模，在设备端或资源有限的环境下部署变得困难。混合精度量化提供了一种解决方案，但现有的方法在平均精度降至4位以下时表现不佳，因为它们依赖于孤立的、针对每一层的度量标准，无法考虑到不同层之间的关键交互对整体性能的影响。
### Innovation
本文提出了两种创新以应对上述限制：首先，将混合精度量化问题视为层之间的合作博弈，并引入基于Shapley值的渐进量化估计(Shapley-Based Progressive Quantization Estimation, SPQE)，以高效地获得层敏感性和层间交互的准确Shapley估计。其次，基于SPQE，提出了一种基于层交互的混合精度量化（Interaction-aware Mixed-Precision Quantization, IMPQ），将这些Shapley估计转化为二元二次优化问题，使层在严格的内存限制下分配2位或4位精度。
### Conclusion
在Llama-3、Gemma-2和Qwen-3模型上进行了全面实验，结果证明了IMPQ在不同精度范围下（从4位到2位）的可扩展性和优越性能。相比于仅依赖孤立指标的方法，IMPQ在平均精度为4位至2位时，相对于最优基线方法，相对变换困惑度降低了20%到80%。
## 646. `cs.LG` - FRAUDGUESS: 在百万规模金融数据中发现并解释新型欺诈行为 [PDF](https://arxiv.org/pdf/2509.15493), [HTML](https://arxiv.org/abs/2509.15493)
### Authors
Robson L. F. Cordeiro,Meng-Chieh Lee,Christos Faloutsos
### Background
给定一场金融交易的集合（谁在何时以多少价格购买），以及买方和卖方的历史信息，如何找到欺诈行为？如果已经有一部分交易被标注为已知的欺诈类型，我们可以构建一个分类器。然而，我们还希望发现以往未知的欺诈类型（称为检测）。另外，我们还需要为专家提供证据支持我们对欺诈行为的看法（称为解释）。
### Innovation
本文提出了一种名为FRAUDGUESS的方法来实现两个目标：(a) 对于检测，它能够在一个精心设计的特征空间中识别新的欺诈类型，作为微集群；(b) 对于解释，它借助可视化、热图以及交互式仪表盘来提供证据支持和深入研究。FRAUDGUESS已经在实际应用中被使用，并被认为可以在一家匿名金融机构中部署。此外，该方法在真实、百万级金融数据集发现了三种新的行为，其中两种被认为是欺诈或可疑行为，成功捕获了大量未被注意到的欺诈交易。
### Conclusion
FRAUDGUESS是在百万规模金融数据中发现并解释新的欺诈行为的一种方法。它不仅能够识别出以往未知的欺诈类型，还提供了强有力的支持证据，并在实际应用中得到了验证。
## 647. `cs.LG` - KoopCast：通过柯伊曼算子进行轨迹预测 [PDF](https://arxiv.org/pdf/2509.15513), [HTML](https://arxiv.org/abs/2509.15513)
### Authors
Jungjin Lee,Jaeuk Shin,Gihwan Kim,Joonho Han,Insoon Yang
### Background
当前的动态环境下的轨迹预测方法通常缺乏高效性和良好的预测准确性。一般的预测模型往往难以处理非线性动力学特征，特别是在多智能体相互作用和受地图约束的动态复杂场景中表现不佳。
### Innovation
KoopCast模型通过引入柯伊曼算子理论，将非线性动态提升到高维空间以实现线性表示，采用两阶段设计：首先使用概率神经目标估计器预测可能的长期目标，然后使用柯伊曼算子基的改进模块将意图和历史信息转化为非线性特征空间，通过线性预测决定如何到达目标。这种设计不仅确保了强大的预测准确性，还继承了线性算子的优势并准确捕捉非线性动力学。
### Conclusion
KoopCast模型展示了三种主要优势：(i) 竞争性的预测准确性，(ii) 基于柯伊曼谱理论的可解释性，(iii) 低延迟部署。KoopCast在ETH/UCY数据集、Waymo开放运动数据集和nuScenes中表现出高预测准确性、模式级解释性和实用效率。
## 648. `cs.LG` - 层次自我注意：将神经注意机制推广到多尺度问题 [PDF](https://arxiv.org/pdf/2509.15448), [HTML](https://arxiv.org/abs/2509.15448)
### Authors
Saeed Amizadeh,Sara Abdali,Yinheng Li,Kazuhito Koishida
### Background
Transformer模型及其注意力机制在机器学习领域引发了革命。虽然最初是为语言数据设计的，但它们很快扩展到了图像、视频、图形等具有不同信号几何结构的数据模态中。然而，注意力机制在数据以不同尺度和潜在不同模态出现时进行泛化并非易事。现有的尝试在模态和层次结构上进行整合，很大程度上依赖于非系统的方法，这些方法难以无缝推广到类似问题且可能具有不同的结构特点。为了应对这一挑战，本文提出了一个根本不同的方法：首先提出一个数学构造来表示多模态、多尺度的数据。然后，从熵最小化的第一原理出发，数学上推导出该构造的神经注意力机制。研究表明，所推导的公式在标准Softmax注意力的基础上，最接近且能够整合问题的层次/几何信息的归纳偏置。此外，还提出了基于动态规划的有效算法来计算推导出的注意力机制，并将其整合进Transformer模型中，证明了所提出的层次注意力机制不仅可以用于从零开始训练层次/多模态设置下的Transformer模型，也能用于在预训练后注入层次信息，从而在零样本情况下实现更高效的模型
### Innovation
提出了一个新的数学构造来表示多模态、多尺度数据；从第一个原理出发，数学上推导出神经注意机制；提出了基于动态规划的高效算法来计算推导出的注意机制；创新地将层次注意力机制整合进Transformer模型中，既可以直接用于训练，也可以在预训练后用于注入层次信息，实现了模型的高效性
### Conclusion
通过提出层次自我注意力机制，不仅可以从零开始训练层次/多模态设置下的Transformer模型，也能在预训练后的模型中注入层次信息，从而在零样本情况下实现更高效的模型。
## 649. `cs.LG` - 使用Bernstein流形法学习通用随机动力学以实现精确信念传播 [PDF](https://arxiv.org/pdf/2509.15533), [HTML](https://arxiv.org/abs/2509.15533)
### Authors
Peter Amorese,Morteza Lahijanian
### Background
在不确定性条件下进行推理时，预测由随机系统未来状态构成的分布被称为信念传播，这是基础性的问题。然而，非线性系统的动力学通常使得精确的信念传播变得不可行，需依赖近似方法。当系统模型未知且必须通过数据学习时，关键问题是能否学习一个既能普遍逼近一般的非线性随机动态，又能支持精确信念传播的模型。
### Innovation
本文为一种同时满足上述两个条件的模型建立了理论基础。提出的方法结合了normalizing flows在密度估计方面的表达能力与Bernstein多项式在精确推理方面的实用性。
### Conclusion
实验结果表明，本研究提出的模型优于最先进的数据驱动的信念传播方法，特别是在具有非加性、非高斯噪声的非线性系统中表现突出。
## 650. `cs.LG` - 使用演变知识图谱增强的大语言模型中的时序推理 [PDF](https://arxiv.org/pdf/2509.15464), [HTML](https://arxiv.org/abs/2509.15464)
### Authors
Junhong Lin,Song Wang,Xiaojie Guo,Julian Shun,Yada Zhu
### Background
大语言模型（LLMs）在许多语言理解任务中表现出色，但是它们在推理随时间变化的知识方面遇到困难。为了应对这一挑战，近期的研究探讨了将LLMs与知识图谱（KGs）结合来提供结构化的、最新的信息。然而，许多现有方法假设KG是静态的，并且忽略了现实世界数据中固有的时间动态和事实不一致。
### Innovation
提出了一种时序感知的多跳推理算法——EvoReasoner，适用于处理随时间变化的知识推理。EvoReasoner包括全局-局部实体定位、多路径分解和基于时间的知识评分。为了确保底层KG的准确性和最新性，引入了EvoKG，这是一种增量更新KG并从非结构化文档中获取信息的方法，通过基于信心的矛盾解决和时间趋势追踪来提高可靠性。
### Conclusion
通过评估EvoReasoner在时序问答基准数据集和一个动态从原始文档更新KG的端到端设置下的表现，该方法优于基于提示和KG增强的基线方法。这表明结合时序推理和KG演化对于增强LLM的稳健性和时效性具有重要意义。使用我们方法的8B参数模型在七个月后的提示下与671B参数模型表现相当，进一步证明了此方法的有效性。我们的代码已公开。
## 651. `cs.LG` - 流形维度估计：一项经验研究 [PDF](https://arxiv.org/pdf/2509.15517), [HTML](https://arxiv.org/abs/2509.15517)
### Authors
Zelong Bi,Pierre Lafaye de Micheaux
### Background
流形假说表明高维数据通常位于或接近于低维流形。因此，准确估计流形的维数对于利用其结构至关重要。然而，现有的流形维数估计工作散乱而且缺乏系统的评估。本文提供了该领域的综合综述，涵盖了研究人员和从业者都能从中受益的内容。我们回顾了经常被忽视的理论基础，并介绍了八种代表性估计器。通过受控实验，我们分析了噪声、曲率、样本量等因素如何影响性能。我们也对各种合成和现实世界的数据集比较了这些估计器，提出了针对特定数据集的超参数调优策略。我们的结果提供了实用指导，并表明在这样的问题上，简单方法常优于复杂方法。
### Innovation
本文提供了关于流形维数估计的综合评估，涵盖了八种代表性方法，并通过受控实验分析了多种因素对性能的影响。本文还提出了合理的数据集特定的超参数调优策略。
### Conclusion
我们的结果为现实应用提供了实用指导，并表明对于这类普遍性的问题，简单的方法往往表现更好。
## 652. `cs.LG` - 利用可验证合成奖励缓解奖励欺骗 [PDF](https://arxiv.org/pdf/2509.15557), [HTML](https://arxiv.org/abs/2509.15557)
### Authors
Mirza Farhan Bin Tarek,Rahmatollah Beheshti
### Background
RLVR 最近的研究表明大型语言模型（LLMs）能够在没有直接监督的情况下发展出自己的推理能力。然而，在医疗领域，特别是在问答任务中，推理阶段容易出现显著的奖励作弊。本研究针对这种作弊行为做了两项主要应对措施：一是防止给出最终的答案而省略之前的推理过程；二是避免使用非标准的推理形式来利用奖励机制。
### Innovation
为了应对这些作弊行为，我们提出了一种复合奖励函数，其中针对这两种行为设定了惩罚措施。试验表明，通过在 RLVR 中引入我们提出的奖励模型，可以改善推理格式、减少奖励作弊并提高准确性，优于基准模型。
### Conclusion
这种方法为减少奖励作弊并提高使用 RLVR 的模型可靠性迈出了重要一步。
## 653. `cs.LG` - 在重尾噪声下的非凸分布式随机 bilevel 优化 [PDF](https://arxiv.org/pdf/2509.15543), [HTML](https://arxiv.org/abs/2509.15543)
### Authors
Xinwen Zhang,Yihan Zhang,Hongchang Gao
### Background
现有的分布式随机优化方法假设下级损失函数是强凸的且随机梯度噪声具有有限的方差。但在现实世界的机器学习模型中，这些假设通常不成立。为了解决这些限制，本文开发了一种新型的分布式随机 bilevel 优化算法，该算法适用于带重尾噪声的非凸 bilevel 优化问题。
### Innovation
开发了一种归一化的随机方差减小 bilevel 梯度下降算法，不需要任何剪辑操作。并通过创新地对受重尾噪声影响的相互依赖的梯度序列进行边界约束，建立了其收敛速率。这是首个具有严格理论保证的带重尾噪声的分布式 bilevel 优化算法。
### Conclusion
大量的实验结果证实了该算法在处理重尾噪声方面的有效性。
## 654. `cs.LG` - 完全去中心化的合作多智能体强化学习是一个上下文建模问题 [PDF](https://arxiv.org/pdf/2509.15519), [HTML](https://arxiv.org/abs/2509.15519)
### Authors
Chao Li,Bingkun Bao,Yang Gao
### Background
该论文研究了去中心化的合作多智能体强化学习问题，每个智能体仅能观察到自身的状态，局部动作和共享奖励，而无法获取其他智能体的动作信息。这导致在价值函数更新时出现非平稳性问题，并在价值函数估计时发生相对的过度泛化，从而阻碍了有效的合作策略学习。现有研究没能同时解决这两个问题，因为它们无法在完全去中心化的环境中建模其他智能体的联合策略。
### Innovation
为了克服这一限制，该论文提出了一种名为动态意识上下文（DAC）的新方法，它将每个智能体所感知的局部任务形式化为一个上下文马尔可夫决策过程，并通过动态意识的上下文建模解决非平稳性和相对的过度泛化问题。具体来说，DAC 将每个智能体的非平稳局部任务动态归因于未观察到上下文之间的切换，每个上下文对应一个独立的联合策略。然后，DAC 使用潜在变量建模步骤动态分布，并将这些潜在变量称为上下文。接下来，对于每个智能体，DAC 引入基于上下文的价值函数以在价值函数更新过程中解决非平稳性问题，并通过引代理优化边缘价值来选择合作性动作，从而解决相对的过度泛化问题。
### Conclusion
我们通过在多种合作任务（包括矩阵博弈、捕食与被捕食、以及SMAC）上评估DAC，证明了其相比于多个基线模型的优越性能，验证了其有效性。
## 655. `cs.LG` - 贝叶斯风险MDP中的一般凸损失的策略梯度优化 [PDF](https://arxiv.org/pdf/2509.15509), [HTML](https://arxiv.org/abs/2509.15509)
### Authors
Xiaoshuang Wang,Yifan Lin,Enlu Zhou
### Background
本文考虑了具有通用损失函数和未知参数的马尔可夫决策过程(MDP)。由于未知参数带来的认识不确定性，我们采用贝叶斯方法从数据中估计参数，并对损失施加与贝叶斯后验分布相容的风险函数。这种形式通常不满足互换性原则，无法满足贝叶尔曼方程，也无法通过基于动态规划的方法解决。因此，我们提出了一种利用共轭风险度量的对偶表示，并将-envelope定理推广到连续情况的策略梯度优化方法。我们对算法进行了稳态分析，给出了收敛速率$O(T^{-1/2}+r^{-1/2})$。进一步地，我们将算法扩展到耗时设置中，并证明了扩展算法的全局收敛性，并提供了满足误差界$O(rúpsilon)$所需迭代次数的界。
### Innovation
提出了利用共轭风险度量的对偶表示，并将-envelope定理推广到连续情况的策略梯度优化方法，解决了由于未知参数带来的非互换性问题，适用于具有统计不确定性的MDP问题，提出了稳态分析和迭代收敛性保证。
### Conclusion
提出了策略梯度优化方法，并证明了该方法在贝叶斯风险MDP中的一般凸损失问题上的稳态分析和迭代收敛性。进一步将该方法扩展到耗时设置，并提供了满足误差界所需的迭代次数的界。
## 656. `cs.LG` - PolyJuice 使它成为现实：面向合成图像检测器的黑盒通用红队伍对抗方法 [PDF](https://arxiv.org/pdf/2509.15551), [HTML](https://arxiv.org/abs/2509.15551)
### Authors
Sepehr Dehdashtian,Mashrur M. Morshed,Jacob H. Seidman,Gaurav Bharaj,Vishnu Naresh Boddeti
### Background
合成图像检测器（SIDs）是应对来自文本到图像（T2I）模型日益逼真的图像风险的关键防御手段。传统的红队方法通过要求白盒访问SIDs并生成针对特定图像的攻击，从而在极大地限制了其在商业T2I模型上的应用，并且过程复杂昂贵。因此，需要一种无需直接访问模型且能通用生成攻击的方法，以提高SIDs的效果。
### Innovation
本文提出了PolyJuice，这是一种无需访问模型且能生成通用攻击的安全红队方法。PolyJuice通过分析T2I模型在生成正确和错误分类样本时的潜在空间分布差异，实现其攻击生成过程。研究展示其攻击方法能显著提高T2I模型的欺骗SIDs的能力，并且能够通过简单的插值技术在不同分辨率下有效传递攻击方向，减少了计算成本。此外，使用PolyJuice增强模型的数据集训练也提升了模型性能。
### Conclusion
PolyJuice作为一种黑盒、通用的红队方法，能够有效提升SIDs对抗T2I生成图像的性能，且具有良好的泛化能力，能够在较低分辨率下快速生成有效攻击，并通过简单的插值技术在高分辨率上应用，同时增强模型训练数据集也能显著提高模型效果。
## 657. `cs.LG` - 零阶优化中的多查询悖论 [PDF](https://arxiv.org/pdf/2509.15552), [HTML](https://arxiv.org/abs/2509.15552)
### Authors
Wei Lin,Qingyu Song,Hong Xu
### Background
零阶（ZO）优化提供了一种处理显式梯度不可用问题的强大框架，通常需要通过函数值查询来进行近似梯度估计。现有的单查询方法虽然简单，但估计方差较高，因此引入了多查询方法来提高估计准确性。然而，这增加了预算分配的复杂性：在固定预算下，每次迭代的查询次数与总的优化迭代次数成反比。如何最佳地分配这个预算成为了一个关键但尚未充分研究的问题。本文系统地解决了这一查询分配问题，通过对两种聚合方法进行分析：默认的简单平均（ZO-Avg）和我们从局部代理最小化中推导出的新投影对齐方法（ZO-Align），揭示了收敛速率与查询数量的显式依赖关系，针对凸性和非凸性环境均进行了讨论。
### Innovation
本文详细分析了两种聚合方法，并通过推导收敛速率使查询数量的影响显式化，揭示了不同条件下的具体差异，特别是ZO-Avg和ZO-Align方法的表现。作者证明了使用更多的查询数次实际上对ZO-Avg是无效的，而ZO-Align则在每次迭代使用更多查询时表现更好，最优策略是一种全子空间估计。因此，研究提出了关于两种经典算法的选择问题，这一选择完全由使用的聚合方法决定。实验结果也验证了这一理论发现的有效性。
### Conclusion
本文解决了零阶优化中的多查询分配问题，通过对比ZO-Avg和ZO-Align两种方法，揭示了这两种方法在不同查询数量下的不同表现情况，最终明确了多查询的问题实际上是在两种经典算法之间进行选择的问题。这种理论发现通过实验得到了验证。
## 658. `cs.LG` - 使用机器学习进行在线新闻文章的高效提取式文本摘要 [PDF](https://arxiv.org/pdf/2509.15614), [HTML](https://arxiv.org/abs/2509.15614)
### Authors
Sajib Biswas,Milon Biswas,Arunima Mandal,Fatema Tabassum Liza,Joy Sarker
### Background
在信息过载的时代，网上新闻文章的内容管理依赖于高效的摘要以提高访问性和用户参与度。为此，本文着重解决提取式文本摘要的挑战，利用先进的机器学习技术生成简洁连贯的摘要，同时保留原始含义。
### Innovation
本文开发了一个管道，利用BERT嵌入将文本数据转变为数值表示，并将任务重新定义为二元分类问题。通过对比多种模型，包括逻辑回归、前馈神经网络和长短期记忆（LSTM）网络，表明LSTM网络能够捕捉序列依赖关系，相较于基准方法（如Lede-3）和简单模型，在F1分数和ROUGE-1指标上表现更优。
### Conclusion
本文强调了自动化摘要在改善在线新闻平台内容管理系统中的潜力，使之能够更高效地组织内容并提升用户体验。
## 659. `cs.LG` - Small LLMs with Expert Blocks Are Good Enough for Hyperparamter Tuning [PDF](https://arxiv.org/pdf/2509.15561), [HTML](https://arxiv.org/abs/2509.15561)
### Authors
Om Naphade,Saksham Bansal,Parikshit Pareek
### Background
在机器学习(ML)管道中，超参数调优(HPT)是必要的步骤，但随着模型规模的增长，这一过程变得计算上极为昂贵且缺乏透明度。近年来，大规模语言模型(LLMs)被研究用于HPT，但大多数工作依赖于参数超过100亿的模型。因此，本文讨论了一个使用小型LLMs的专家块框架，旨在解决这一问题。
### Innovation
本文提出了一种名为专家块框架的方法，使用小型LLMs进行HPT。该方法的核心是轨迹上下文总结器(TCS)，它能够将原始训练轨迹转换为结构化的上下文，使小型LLMs能够用可靠度与大型模型相当的方式分析优化进度。在本地运行的两个小型LLMs（phi4:reasoning14B和qwen2.5-coder:32B）和10次试验预算的帮助下，TCS使HPT管道在六项不同任务中达到了平均性能，与GPT-4的性能相差不到0.9个百分点。
### Conclusion
研究结果表明，使用小型LLMs和专家块框架的HPT管道在各种任务中能够达到与大型模型相当的性能。这为使用更小、成本更低的语言模型进行高效和可靠的HPT提供了新的可能性。
## 660. `cs.LG` - 信息几何中的变分贝叶斯 [PDF](https://arxiv.org/pdf/2509.15641), [HTML](https://arxiv.org/abs/2509.15641)
### Authors
Mohammad Emtiyaz Khan
### Background
文章强调了信息几何学与变分贝叶斯（VB）之间的基础性联系，并讨论了这一联系在机器学习中的影响。在特定条件下，VB方法总是需要进行自然梯度的估计或计算。通过使用Khan和Rue（2023）提出的自然梯度下降算法——贝叶斯学习规则（BLR），得出了几个重要结果。
### Innovation
文章的主要创新在于通过自然梯度下降算法的使用提出了一种简化贝叶斯规则的方法，推广了基于梯度的方法使用的二次近似，并且还提供了一个大规模实施VB算法的方法，适用于大型语言模型。
### Conclusion
虽然信息几何与VB之间的联系及其结果并不是新的发现，但文章进一步强调了两个领域——信息几何学和贝叶斯统计——的共同起源，希望能促进两个领域的交叉研究。
## 661. `cs.LG` - 高效影响函数：Dropout作为一种压缩工具 [PDF](https://arxiv.org/pdf/2509.15651), [HTML](https://arxiv.org/abs/2509.15651)
### Authors
Yuchen Zhang,Mohammad Mohammadi Amiri
### Background
评估训练数据对机器学习模型的影响对于理解模型行为、增强透明性和选择训练数据至关重要。影响函数提供了一种理论框架，用于量化特定测试数据下训练数据点对模型性能的影响。然而，影响函数的计算和内存成本对于大规模模型来说仍然是重大挑战，即使使用近似方法，由于计算中涉及的梯度量级与模型本身相当。
### Innovation
本文提出了一种新颖的方法，利用Dropout作为梯度压缩机制来更高效地计算影响函数。该方法在影响函数计算过程中和梯度压缩过程中能显著减少计算和内存开销。通过理论分析和实证验证，证明了该方法能保持数据影响的关键组成部分，并使其实现对现代大尺度模型的应用。
### Conclusion
通过高效利用Dropout进行梯度压缩，该方法能有效减少计算和内存成本，同时保持数据影响的关键方面，使得影响函数能够应用于现代大规模模型中。
## 662. `cs.LG` - 非凸正则化在强化学习中的特征选择 [PDF](https://arxiv.org/pdf/2509.15652), [HTML](https://arxiv.org/abs/2509.15652)
### Authors
Kyohei Suzuki,Konstantinos Slavakis
### Background
本文提出了一种高效批量算法，用于强化学习中的特征选择，并提供了理论收敛保证。传统的正则化方案会带来估计偏差，本文通过在经典的最小二乘差分（LSTD）框架内扩展策略评估，并运用导致弱凸性的非凸投影极小极大凹（PMC）正则化惩罚来缓解这一问题。
### Innovation
本文的首要贡献是推出了一个将贝尔曼残差目标用非凸性的投影极小极大凹（PMC）惩罚进行正则化的bellman-residual目标方法。次贡献是建立新型收敛条件以解决该类问题的前向反射后向分裂（FRBS）算法。
### Conclusion
实验表明，本文提出的方法在多个基准数据集上的表现超越了现有的最高级别的特征选择方法，尤其是在存在大量噪声特征的情况下。
## 663. `cs.LG` - Latent Zoning Network: 统一原则下的生成建模、表示学习与分类 [PDF](https://arxiv.org/pdf/2509.15591), [HTML](https://arxiv.org/abs/2509.15591)
### Authors
Zinan Lin,Enshu Liu,Xuefei Ning,Junyi Zhu,Wenyu Wang,Sergey Yekhanin
### Background
生成建模、表示学习与分类是机器学习中的三个核心问题，然而这三个领域最先进的解决方案仍然相对独立。作者提出了一种统一的原则——希望找到一个原则能够统一解决这三个问题，从而简化机器学习流水线并促进任务之间的协同作用。
### Innovation
作者引入了Latent Zoning Network（LZN）作为一种实现这一目标的步骤。LZN的核心是创造一个共享的高斯潜在空间，用于跨任务编码信息。通过编码器和解码器将不同类型的数据（如图像、文本、标签）映射到潜在空间中，并允许通过这些建模任务。该研究展示了LZN在不同复杂度任务中的应用效果，包括增强现有生成模型、独立解决表示学习任务以及同时处理生成和分类任务的能力。
### Conclusion
作者通过实验展示了LZN在增强生成模型性能、独立执行未监督表示学习及同时处理多重任务方面的潜力，并提供了代码和模型供进一步研究。
## 664. `cs.LG` - 行动的心理账户：启发于EWA的决策变换器中的注意力 [PDF](https://arxiv.org/pdf/2509.15498), [HTML](https://arxiv.org/abs/2509.15498)
### Authors
Zahra Aref,Narayan B. Mandayam
### Background
Transformer架构通过自注意力机制建模轨迹，已成为顺序决策的强有力架构，在强化学习（RL）中，它们使得环境返回条件下的控制无需依赖价值函数逼近。虽然决策变换器（Decision Transformers，DTs）通过将RL视为监督序列模型来克服了这一限制，但他们只能处理离线数据，缺乏探索性。为了克服这一局限，线上决策变换器（Online Decision Transformers，ODTs）通过在经验策略采样的路线（on-policy rollouts）上利用熵正则化训练来解决此问题，让其成为传统RL方法如Soft Actor-Critic的安全替代品。尽管有这些优点，ODTs依然使用标准注意力机制，缺乏行动特定结果的显式记忆，造成长期动作效果学习的低效率。
### Innovation
该研究引入了体验加权吸引（EWA-Weighted Attraction）与向量量化（Vector Quantization）相结合的Online Decision Transformers（EWA-VQ-ODTs），这是一种轻量级模块，它能够保存每个行动的按时间累积的成功失败记录。连续的行动通过直接的网格查找被路由到一个紧凑的向量量化码本中，每个码本存储了通过衰减和基于奖励的强化在线更新的标量吸引。这些吸引调节局限行动令牌的列，使其更受标量吸引影响。此模块不需要更改主干结构或训练目标，进而提高了样本效率和平均回报，尤其是在早期训练阶段。该模块计算效率高，通过每个码本的跟踪具备解释性，并且有理论保证来约束吸引动力并控制其对注意力漂移的影响。
### Conclusion
EWA-VQ-ODT在标准连续控制基准测试中，相较于ODTs，提高了样本效率和平均回报。该模块计算效率高，易于解释，并且有理论保证来约束其注意力动力学和对注意力漂移的影响。
## 665. `cs.LG` - 在行为良好的分布下通过学习半空间参考类进行个性化预测 [PDF](https://arxiv.org/pdf/2509.15592), [HTML](https://arxiv.org/abs/2509.15592)
### Authors
Jizhou Huang,Brendan Juba
### Background
在机器学习应用中，预测模型被训练以覆盖整个数据分布，满足未来的查询需求。然而，现实世界的数据往往需要过于复杂的模型才能达到竞争力的性能，代价是牺牲可解释性。因此，在高风险应用（如医疗保健）中部署机器学习模型的需求促使人们寻找可解释的预测方法。本文提出了一种个性化预测方案，在每个查询中学习易于解释的预测器。
### Innovation
首先，本文为个性化预测的参考类提出了一种基于分布的PAC学习算法。其次，通过结合参考类学习算法和稀疏线性表示列表学习器，证明了在标签无关的环境下，使用稀疏线性分类器和同质半空间子集进行个性化预测的第一个上界，为$O(text{opt}^{1/4})$。这也评估了所提出算法在一系列标准基准数据集上的性能。
### Conclusion
本文研究了在半空间表示的子群体下的个性化预测模型的PAC可学习性，通过引入分布特定的PAC学习算法和结合稀疏线性表示列表学习器等方法，提出了一个上界，证明了个性化预测在稀疏线性分类器和同质半空间子集上下界的可行性。
## 666. `cs.LG` - 边缘设备上的成本敏感二元分类推理卸载 [PDF](https://arxiv.org/pdf/2509.15674), [HTML](https://arxiv.org/abs/2509.15674)
### Authors
Vishnu Narayanan Moothedath,Umang Agarwal,Umeshraja N,James Richard Gross,Jaya Prakash Champati,Sharayu Moharir
### Background
在边缘智能系统中，我们面临一个二元分类问题，其中假阴性比假阳性更昂贵。系统配备了一个紧凑的本地部署模型，但为了提高准确性，还依赖于一个远程模型，此模型需要通过网络进行访问，但会产生卸载成本。对于每个样本，系统首先使用本地模型进行推理。基于本地模型的输出，样本可能会被卸载到远程模型。研究主要探讨在这样的分层推理（HI）系统中，分类准确性与这些卸载成本之间的基本权衡。
### Innovation
为优化系统，本文提出了一种在线学习框架，该框架可以不断调整本地模型置信分数上的阈值对。该阈值确定本地模型的预测以及样本是否应在本地分类或卸载到远程模型。对于校准的本地模型，提供了闭式解。对于未校准模型的情况，引入了一种称为H2T2的在线两阈值分层推理策略，并证明该策略实现了亚线性后悔。H2T2具有模型独立性，无需训练，在推理阶段利用有限反馈学习。基于真实数据集进行的仿真表明，H2T2在性能上优于简单和单阈值HI策略，在某些情况下甚至超过了离线最优。
### Conclusion
H2T2策略对分布偏移具有鲁棒性，能够有效地适应分类器之间的不匹配。该策略能够以有限的反馈和无需训练的方式，持续优化边缘智能系统的分类性能。
## 667. `cs.LG` - 我们需要看到多少类才能实现新的类发现？ [PDF](https://arxiv.org/pdf/2509.15585), [HTML](https://arxiv.org/abs/2509.15585)
### Authors
Akanksha Sarkar,Been Kim,Jennifer J. Sun
### Background
新型类发现是机器学习模型适应不断变化的现实世界数据的关键，应用范围广泛，从科学研究到机器人技术。然而，这些数据集包含复杂的、交织的因素，使得系统性研究类发现变得困难。因此，关于为什么以及在什么情况下新类发现更容易成功的许多基本问题尚未被回答。为了应对这一挑战，我们提出了一种简单的受控实验框架，使用dSprites数据集和程序生成的修改因子，以研究影响成功类发现的因素。特别是，我们研究了已知/未知类的数量与发现性能之间的关系，以及已知类的‘覆盖率’对发现新类的影响。我们的实验结果表明，已知类的数量带来的益处达到了饱和点，之后发现性能不再提高。不同设置下收益递减的趋势为实际操作者提供了成本效益分析的见解，并为复杂现实世界数据集上更严谨的类发现研究指出了起点。
### Innovation
提出了一种简单的受控实验框架，使用dSprites数据集和程序生成的修改因子，来研究影响成功类发现的因素，特别是研究了已知/未知类的数量与发现性能之间的关系，以及已知类的‘覆盖率’对发现新类的影响。
### Conclusion
已知类的数量带来的益处达到了饱和点，之后发现性能不再提高。不同设置下收益递减的趋势为实际操作者提供了成本效益分析的见解，并为复杂现实世界数据集上更严谨的类发现研究指出了起点。
## 668. `cs.LG` - RMT-KD: 基于随机矩阵理论的因果知识蒸馏 [PDF](https://arxiv.org/pdf/2509.15724), [HTML](https://arxiv.org/abs/2509.15724)
### Authors
Davide Ettori,Nastaran Darabi,Sureshkumar Senthilkumar,Amit Ranjan Trivedi
### Background
大型深度学习模型（如BERT和ResNet）虽然实现了最先进的性能，但由于其大小和计算需求，在边缘部署成本高昂。RMT-KD方法利用随机矩阵理论（RMT）的知识蒸馏技术，逐步减少网络规模。
### Innovation
RMT-KD方法通过保留通过隐表示的谱特性识别的具有信息性的方向，而不是使用剪枝或启发式秩选择，来进行逐层的基于随机矩阵理论的因果减少，并利用自我蒸馏以保持稳定性和准确性。
### Conclusion
在GLUE，AG News和CIFAR-10上，RMT-KD实现了高达80%的参数减少，同时只损失2%的准确性，提供了2.8倍更快的推理时间和几乎一半的功耗。这些结果表明RMT-KD是一种基于数学原理的网络蒸馏方法。
## 669. `cs.LG` - 使用伪目标的电池退化增量多步预测 [PDF](https://arxiv.org/pdf/2509.15740), [HTML](https://arxiv.org/abs/2509.15740)
### Authors
Jonathan Adam Rico,Nagarajan Raghavan,Senthilnath Jayavelu
### Background
数据驱动的模型能够准确进行早期电池诊断以预防设备故障及进一步的安全隐患。现有的大多数机器学习（ML）模型在离线模式下工作，并且每次遇到新的数据分布都需要重新训练。因此，对于能够在线适应不同分布的机器学习方法的需求非常迫切。当前的在线增量多步预测方法面临挑战，因为它们在当前实例的预测无法得到纠正，且这些方法需要等待大量时间获取足够流式数据才能重训。
### Innovation
本文提出了一种增量快速和缓慢学习网络（iFSNet），这是一种对FSNet的修改版本，用于单通道模式（样本-样本）的多步预测使用伪目标。iFSNet使用输入序列的简单线性回归器来外推伪未来样本（伪目标），并从其余预测计算损失，同时不断更新模型。该模型得益于FSNet的关联记忆和自适应结构机制，同时通过使用伪目标该模型能够逐步改进。
### Conclusion
提出的模型在具有平滑退化轨迹的数据集上实现了0.00197的RMSE和0.00154的MAE，在具有不规则退化轨迹和容量再生峰值的数据集上实现了0.01588的RMSE和0.01234的MAE。
## 670. `cs.LG` - EigenTrack：LLMs和VLMs中的幻觉和分布外检测的光谱激活特征跟踪 [PDF](https://arxiv.org/pdf/2509.15735), [HTML](https://arxiv.org/abs/2509.15735)
### Authors
Davide Ettori,Nastaran Darabi,Sina Tayebati,Ranganath Krishnan,Mahesh Subedar,Omesh Tickoo,Amit Ranjan Trivedi
### Background
大语言模型（LLMs）虽具有广泛的用途，但仍易发生幻觉和分布外（OOD）错误。现有方法存在一些局限性，如需要多次向前传递或无法保留时间上下文和全局信号等。
### Innovation
提出了一种可解释的实时检测器EigenTrack，用于检测LLMs和VLMs中的幻觉和分布外错误。EigenTrack利用隐藏激活的谱几何特征，通过流式传输谱统计量（如熵、特征值间隙和KL散度），将这些信息传输到一个轻量级的递归分类器中，以跟踪表层错误出现之前的表示结构的时空变化，提高检测的准确性与实时性，且仅需一次前向传递，无需重新采样。
### Conclusion
EigenTrack不仅能够检测LLMs和VLMs中的幻觉和分布外错误，还能提供可解释的准确性和延迟之间的权衡，并保持时间上下文。
## 671. `cs.LG` - 使用老化效应的飞机燃油流量建模：从参数修正到神经网络 [PDF](https://arxiv.org/pdf/2509.15736), [HTML](https://arxiv.org/abs/2509.15736)
### Authors
Gabriel Jarry,Ramon Dalmau,Philippe Very,Junzi Sun
### Background
准确建模飞机燃油流量对于运行规划和环境影响评估至关重要，但标准参数模型往往忽视了随着飞机老化会发生的性能衰退。现有的研究主要集中在使用机械参数模型和经验校正系数，但未能充分考虑时间对发动机性能的影响。本文通过分析约一万九千次空中客车A320-214飞机的快速访问记录飞行数据，调查了如何将发动机老化效应整合到燃油流量预测中，以改进参数和机器学习框架的表现。研究发现，使用年龄依赖性校正因子和神经网络模型可以显著减少偏差并提高预测精度，但样本有限和缺乏详细的维护事件记录限制了基于年龄的校正的有效性与普遍适用性。文章强调了在运行和环境评估框架中考虑老化效应的重要性，并提出了需要更多样化的数据集以捕获现实世界发动机退化的复杂性。
### Innovation
论文创新性地使用了全面的数据集（约一万九千次飞行记录）和多种方法（如基于物理的经典模型、基于经验的校正系数以及数据驱动的神经网络架构），系统地研究了如何将发动机老化效应整合到燃油流量预测中。研究发现，使用年龄依赖性校正因子和神经网络模型能够显著改善预测的准确性和可靠性，克服了传统方法在处理时间相关问题时的局限性。
### Conclusion
研究强调了考虑老龄化效应的重要性，无论是在参数模型还是在机器学习框架中，以提高运行规划和环境影响评估的可靠性。未来需要更多样化的数据集来更好地捕获现实世界发动机退化的复杂性，以进一步提高模型的代表性和通用性。
## 672. `cs.LG` - 关于达到精确公平性的最优引导 [PDF](https://arxiv.org/pdf/2509.15759), [HTML](https://arxiv.org/abs/2509.15759)
### Authors
Mohit Sharma,Amit Jayant Deshpande,Chiranjib Bhattacharyya,Rajiv Ratn Shah
### Background
公平机器学习中存在‘偏差输入，偏差输出’的问题，解决这一问题需要调整数据的特征分布或大语言模型的内部表示至理想的分布，以确保组公平的结果。已有针对公平生成模型和表示引导的工作若能提供模型输出的证明性公平性保证将会非常有益。理想分布被定义为在这个分布上的任何成本敏感风险的最小化者都能保证具体组的公正结果（如群体平等性、平等机会），即没有任何公平性与实用性之间的权衡。已有工作试图通过最小化KL散度找到最优的理想分布并提供高效的算法加以实现。已有研究在合成和真实数据集上显示最优引导技术可以提高公平性并有时也能提高实用性。方法在多个分类应用程序（如职业预测）中验证了减少偏差的有效性，同时确保不同群体间的公平性均衡
### Innovation
1. 提出理想分布的概念，确保其即使在最小化成本敏感风险的情况下也能达到精确的组公平性2. 形式化最优引导优化程序，通过最小化KL散度寻找最近的理想分布，并为常见的参数分布提供高效的算法3. 通过实验验证最优引导技术在合成和真实数据集上的有效性，不仅提高了公平性，有时还能提升实用性
### Conclusion
该研究通过提出理想分布概念、形式化最优引导优化程序及高效的算法实现，证明了其在模型输出上的公正性保障，并在多个应用场景中验证了其有效性和实用性，在大语言模型的内部表示引导上取得了有意义的进展
## 673. `cs.LG` - KITE: 基于核化和信息论的示例选择用于上下文学习 [PDF](https://arxiv.org/pdf/2509.15676), [HTML](https://arxiv.org/abs/2509.15676)
### Authors
Vaibhav Singh,Soumya Suvra Ghosal,Kapu Nirmal Joshua,Soumyabrata Pal,Sayak Ray Chowdhury
### Background
在上下文学习（ICL）中，已经通过利用少量精心选择的任务特定示例来适应大型语言模型（LLMs）的新任务和数据稀缺任务，成为一种强大的范式。然而，由于LLMs的有限上下文大小，如何选择最大化用户查询性能的示例成为了一个根本问题。现有的基于最近邻的方法，如KATE，在高维嵌入空间中存在亟待解决的问题，包括较差的泛化能力和多样性不足的问题。
### Innovation
本文从信息论的角度研究了ICL中的示例选择问题。研究团队将LLMs建模为输入嵌入上的线性函数，将示例选择问题重新定义为特定查询的优化问题，即从更大规模的示例库中选择最佳子集以最小化特定查询的预测误差。这一方法与传统关注泛化的学习理论方法不同，旨在针对特定查询实例实现精确的预测。该团队通过引入接近亚模性的先验目标以及使用递增算法来解决这一问题，同时通过核技巧在高维特征空间中操作，并引入基于最优设计的正则化项以鼓励所选示例的多样性。实验结果表明，与标准检索方法相比，在多种分类任务中KITE显著提高了性能，强调了结构感知和多样化示例选择对ICL在真实数据稀疏场景中的重要性。
### Conclusion
本文提出了一种新的方法KITE，该方法通过信息论驱动和基于核化的方法解决了ICL中的示例选择问题，展示了在真实标签稀缺场景中的优越性能，强调了结构感知及多样化示例选择对于提升ICL性能的重要性。
## 674. `cs.LG` - 半导体制造中学习优化生产能力规划 [PDF](https://arxiv.org/pdf/2509.15767), [HTML](https://arxiv.org/abs/2509.15767)
### Authors
Philipp Andelfinger,Jieyi Bi,Qiuyu Zhu,Jianan Zhou,Bo Zhang,Fei Fei Zhang,Chew Wye Chan,Boon Ping Gan,Wentong Cai,Jie Zhang
### Background
在制造业中，生产能力规划是根据变量需求分配生产资源的过程。在半导体制造行业中，当前的常见做法是使用启发式规则来优先考虑行动。虽然启发式规则具有可解释性，但它们难以考虑过程流中复杂的相互作用，这些相互作用可能导致瓶颈的逐步形成。因此，目前缺乏能够直接捕捉机器和工艺步骤之间多样化关系的模型，从而难以进行主动决策。
### Innovation
本文提出了一种基于神经网络的模型，用于半导体制造中的机器级生产能力规划。该模型通过使用异构图神经网络来表示策略，能够直接捕捉机器和工艺步骤之间的多样化关系，从而实现主动决策。文章还详细介绍了实现足夠可扩展性的若干措施，并通过Intel的小规模MiniFab模型和SMT2020测试平台的初步实验进行评估。实验结果表明，在大规模测试场景中，训练后的策略可以提高约1.8%的吞吐量并减少约1.8%的循环时间。
### Conclusion
提出的神经网络模型能够有效优化半导体制造中的生产能力规划，提高吞吐量并减少循环时间，实现了对复杂生产流程的主动管理。
## 675. `cs.LG` - Lookahead算法与 minibatch SGD的泛化和优化分析 [PDF](https://arxiv.org/pdf/2509.15776), [HTML](https://arxiv.org/abs/2509.15776)
### Authors
Kangcheng Li,Yunwen Lei
### Background
Lookahead优化器通过采用双重权重更新机制增强深度学习模型的性能，这种机制已经证明能够提高底层优化器如SGD的性能。然而，大多数理论研究主要关注其在训练数据上的收敛性，而对其泛化能力的理解较少。现有的泛化分析往往受到限制性假设的约束，比如需要损失函数具有全局Lipschitz连续性，而且这些界限不能完全捕捉优化与泛化之间的关系。
### Innovation
本研究通过针对Lookahead优化器与 minibatch SGD进行严格的稳定性和泛化分析，克服了现有的限制性假设。我们利用均值模型稳定性来推导凸性和强凸性问题的泛化界限，不依赖于限制性的Lipschitz假设。同时，分析表明在凸设定下，稳定性与批处理大小之间存在线性加速关系。
### Conclusion
我们展示了Lookahead优化器与 minibatch SGD在凸性和强凸性问题上的泛化界限，并证明了其相对于批处理大小的线性加速效应。该项研究进一步完善了对Lookahead优化器泛化能力的理解。
## 676. `cs.LG` - SolarCrossFormer：通过集成卫星图像和地面传感器提高日预测太阳能辐射度 [PDF](https://arxiv.org/pdf/2509.15827), [HTML](https://arxiv.org/abs/2509.15827)
### Authors
Baptiste Schubnel,Jelena Simeunović,Corentin Tissier,Pierre-Jean Alet,Rafael E. Carrillo
### Background
为了实现太阳能光伏（PV）系统的大规模并网，需要准确的日预测太阳能辐射度。当前的预测解决方案缺乏系统运营商所需的时序和空间分辨率。
### Innovation
提出了一种名为SolarCrossFormer的新型深度学习模型，该模型通过结合卫星图像与地面气象站的时间序列数据来进行日预测太阳能辐射度。SolarCrossFormer利用新型的图神经网络来利用输入数据的跨模态和跨数据内的关联性，提高预测的准确性和分辨率。它能以15分钟的分辨率提供瑞士任何地点长达24小时的预测。SolarCrossFormer的一个关键优势在于其在实际运行中的鲁棒性：无需重新训练模型即可集成新的时间序列数据，甚至仅使用坐标信息即可预测没有输入数据的地点。
### Conclusion
通过实验证明，SolarCrossFormer在瑞士一个年度、127个地点的数据集上，其整时段的平均绝对误差为6.1%。实验结果表明，SolarCrossFormer的预测结果达到了与商业数值天气预报服务相当的水平。
## 677. `cs.LG` - GUI-ReWalk: 通过随机探索和意图感知推理生成GUI数据 [PDF](https://arxiv.org/pdf/2509.15738), [HTML](https://arxiv.org/abs/2509.15738)
### Authors
Musen Lin,Minghao Liu,Taoran Lu,Lichen Yuan,Yiwei Liu,Haonan Xu,Yu Miao,Yuhao Chao,Zhaojian Li
### Background
图形用户界面（GUI）代理，由大型语言模型和视觉-语言模型驱动，有望在数字环境中实现端到端的自动化。然而，它们的发展受到可扩展且高质量轨迹数据稀缺的限制。现有数据收集策略要么依赖昂贵且不一致的手动注释，要么使用综合生成方法，但在多样性和任务覆盖范围之间进行权衡。为了弥合这一差距，我们提出了GUI-ReWalk：一种增强推理的多层次框架，用于合成真实且多样的GUI轨迹。该框架在探索阶段通过模仿人类的试错行为开始，然后逐步过渡到由推断的目标引导的推理阶段，从而驱动连贯且有目的的交互。此外，它支持多步任务的生成，允许在多个应用程序之间构建长期的任务工作流。通过结合随机性来实现多样性，以及目标感知的推理来实现结构，GUI-ReWalk产生的数据更好地反映了人类计算机交互的意图感知和自适应性质。我们进一步对Qwen2.5-VL-7B进行了GUI-ReWalk数据集的训练，并在包括Screenspot-Pro、OSWorld-G、UI-Vision、AndroidControl和GUI-Odyssey等多个基准上进行了评估。结果显示，GUI-ReWalk为多样化的交互流提供了更好的覆盖范围，更高的轨迹熵和更真实的用户意图。这些发现表明，GUI-ReWalk是一个可扩展且数据高效的方法，可用于推进GUI代理研究，实现稳健的现实世界自动化。
### Innovation
提出了GUI-ReWalk框架，一种结合随机探索和意图感知推理的多层次方法，用于生成真实且多样的GUI轨迹。该框架能够支持多步任务生成，实现长期任务工作流的构建。通过结合随机性来实现多样性，以及目标感知的推理来实现结构，产生更适合模拟人类行为的交互数据。培训了一个大型视觉语言模型（Qwen2.5-VL-7B），并将该模型应用于多个基准测试，显示了其在数据多样性、轨迹熵和用户意图真实性方面的优势。
### Conclusion
GUI-ReWalk作为一种可扩展且数据高效的框架，能够显著提高GUI代理研究的覆盖率和真实性，有助于实现稳健的现实世界自动化。该框架克服了传统的手动注释和合成生成方法的局限，为自动化交互环境提供了新的方法。
## 678. `cs.LG` - Tsururu: 一个基于Python的时间序列预测策略库 [PDF](https://arxiv.org/pdf/2509.15843), [HTML](https://arxiv.org/abs/2509.15843)
### Authors
Alina Kostromina,Kseniia Kuvshinova,Aleksandr Yugay,Andrey Savchenko,Dmitry Simakov
### Background
当前时间序列研究主要集中在开发新的模型上，但选择最佳训练方法的问题尚未得到充分探索。Tsururu是一个Python库，通过结合全局和多元方法以及多步预测策略，填补了领先研究与工业应用之间的差距，使各种预测模型的无缝集成成为可能。
### Innovation
Tsururu通过提供灵活的全局和多元方法组合以及多步预测策略，使用户能够轻松地将各种时间序列预测模型集成到一个统一的框架中，简化了模型的选择和应用过程，使得实际应用中更易于实施先进的预测技术。
### Conclusion
Tsururu作为一个Python库，已经建立了一个全面的时间序列预测策略库，支持用户根据需要灵活选择和组合不同的预测模型和策略，同时支持无缝集成和优化。该项目目前可以在上述链接中访问。
## 679. `cs.LG` - 蒙特卡洛树扩散与多位专家在蛋白质设计中的应用 [PDF](https://arxiv.org/pdf/2509.15796), [HTML](https://arxiv.org/abs/2509.15796)
### Authors
Xuefeng Liu,Mingxuan Cao,Songhao Jiang,Xiao Luo,Xiaotian Duan,Mengdi Wang,Tobin R. Sosnick,Jinbo Xu,Rick Stevens
### Background
蛋白质设计的目标是生成能够折叠成具有所需属性的功能性结构的氨基酸序列。此前结合自回归语言模型和蒙特卡罗树搜索（MCTS）的方法在处理长距离依赖关系时遇到困难，并且面对庞大的搜索空间计算起来不切实际。
### Innovation
本文提出了MCTD-ME（蒙特卡洛树扩散与多位专家），该方法将隐式扩散模型与树搜索结合起来，实现多令牌规划和高效探索。不同于自回归规划者，MCTD-ME 使用生物物理精准度增强的扩散去噪作为展开引擎，联合修订多个位置并适用于大型序列空间。此外，该方法利用不同能力的专家进行探索，并由基于pLDDT的掩码调度引导，专注于低可信度区域同时保留可靠残基。作者还提出了新的多位专家选择规则（PH-UCT-ME）扩展预测熵UCT到专家团队。
### Conclusion
MCTD-ME 在逆折叠任务（CAMEO 和 PDB 标准）中的序列恢复 (AAR) 和结构相似性 (scTM) 指标上均优于单专家或无引导的基线模型，且性能改进随着蛋白质长度的增加而增大，得益于多位专家的引导。该框架是模型无关的，并且适用于逆折叠之外的应用场景，包括从头蛋白质工程和多目标分子生成领域。
## 680. `cs.LG` - 通过隐空间逆向工程进行元黑盒优化的实例生成 [PDF](https://arxiv.org/pdf/2509.15810), [HTML](https://arxiv.org/abs/2509.15810)
### Authors
Chen Wang,Zeyuan Ma,Zhiguang Cao,Yue-Jiao Gong
### Background
Meta-Black-Box Optimization（MetaBBO）的研究利用元学习的强大泛化能力，通过预定义的问题集训练基于神经网络的算法设计策略，从而自动化低级优化器在未见过的问题实例上的适应性。现有的MetaBBO通常使用众所周知的基准套件CoCo-BBO作为训练问题集，但此类问题集在多样性方面有限，这可能会导致MetaBBO过拟合，影响其泛化性能。因此，本文提出了一种称为LSRE的实例生成方法，用于生成多样化的训练问题实例，以便MetaBBO学习更具泛化能力的策略。通过训练一个自动编码器将高维问题特征映射到2维隐空间，并在该隐空间中进行均匀网格采样以产生具有足够多样性的问题实例的隐藏表示。进一步使用遗传编程方法搜索与这些隐藏表示具有最小L2距离的函数公式，从而逆向工程出一个多样化的问题集Diverse-BBO。通过在Diverse-BBO上训练各种MetaBBO并验证其在合成或现实场景中的泛化性能，实验结果表明Diverse-BBO相对于现有训练集选择在MetaBBO中的优越性。进一步的消融实验不仅证明了LSRE设计选择的有效性，还揭示了实例多样性和MetaBBO泛化之间的有趣见解。
### Innovation
提出了一种称为LSRE的实例生成方法，利用自动编码器将高维问题特征映射到2维隐空间，并通过遗传编程搜索方法生成具有最小L2距离的函数公式以逆向工程出多样化的训练问题实例。该方法提高了MetaBBO学习算法设计策略的泛化性能，实验表明Diverse-BBO较现有的基准集具有更佳的泛化能力。
### Conclusion
通过隐空间逆向工程（LSRE）生成多样化的训练问题实例（Diverse-BBO），可以有效提高MetaBBO的泛化性能。实验结果验证了Diverse-BBO在合成或现实场景中的优越性，并揭示了实例多样性和MetaBBO泛化的关联。
## 681. `cs.LG` - HyP-ASO: 一种用于大规模整数线性规划的混合策略自适应搜索优化框架 [PDF](https://arxiv.org/pdf/2509.15828), [HTML](https://arxiv.org/abs/2509.15828)
### Authors
Ning Xu,Junkai Zhang,Yang Wu,Huigen Ye,Hua Xu,Huiling Xu,Yifan Zhang
### Background
直接使用传统的求解器解决大规模整数线性规划（ILPs）问题效率低下，因为ILP问题是NP-hard问题。近年来基于大规模邻域搜索（LNS）的框架可以加速求解过程，但其性能受限于生成足够有效邻域的难度。
### Innovation
提出了一种名为HyP-ASO的混合策略自适应搜索优化框架，结合自定义公式和深度强化学习（RL），该公式利用可行解来计算邻域生成过程中每个变量的选择概率，而RL策略网络预测邻域大小。实验表明，HyP-ASO在大规模ILPs方面显著优于现有的LNS基方法，并且具有轻量级和高可扩展性，适合解决大规模ILPs问题。
### Conclusion
HyP-ASO 在大规模 ILPs 问题上显著优于现有 LNS 基方法，且具有极轻量级和高度可扩展性，适用于大规模 ILPs 的求解。
## 682. `cs.LG` - ThermalGuardian: Temperature-Aware Testing of Automotive Deep Learning Frameworks [PDF](https://arxiv.org/pdf/2509.15815), [HTML](https://arxiv.org/abs/2509.15815)
### Authors
Yinglong Zou,Juan Zhai,Chunrong Fang,Zhenyu Chen
### Background
深度学习模型在自动驾驶系统中发挥着关键作用，支持环境感知等重要功能。为了加速模型推理，这些模型依赖于汽车深度学习框架进行部署。然而，与云环境部署相比，车辆环境中的温度变化范围广，从-40°C到50°C，对GPU温度产生显著影响。计算过程中产生的热量还进一步提高GPU的温度。这种温度波动导致动态GPU频率调整。但是，现有的汽车深度学习框架在设计时并未考虑温度对频率变化的影响。这导致在温度变化的GPU上部署时出现关键质量问题：计算密集型操作面临延迟或错误，高/混合精度操作出现精度误差，时间序列操作遭遇同步问题。现有的深度学习框架测试方法无法检测这些问题，因为它们忽略了温度对深度学习框架质量的影响。
### Innovation
本文提出了ThermalGuardian，这是首个针对具有温度变化环境的汽车深度学习框架的测试方法。ThermalGuardian使用模型变异规则生成针对温度敏感操作的测试输入模型，基于牛顿冷却定律模拟GPU温度波动，并根据实时GPU温度控制GPU频率。
### Conclusion
ThermalGuardian能够针对具有温度影响的质量问题进行测试，确保在温度变化条件下的深度学习模型能保持正常运行，提高了自动驾驶系统的可靠性和性能。
## 683. `cs.LG` - 关于Muon的收敛性及其发展 [PDF](https://arxiv.org/pdf/2509.15816), [HTML](https://arxiv.org/abs/2509.15816)
### Authors
Da Chang,Yongxiang Liu,Ganzhao Yuan
### Background
穆斯(Carbon)优化器在处理神经网络中的矩阵结构参数方面取得了显著的实际成功，但其实际性能和理论理解之间仍存在显著差距。现有分析表明，标准的Muus变体只能在随机非凸设置下达到次优的收敛率$tilde{text{O}}(T^{-1/4})$，其中$T$表示迭代次数。因此，为了探索Muus框架的理论极限，研究者构建并分析了具有一种方差减少机制的变体，命名为Muus-VR2，并提供了首个严格的证明来证明这种机制可以使Muus-VR2达到最优的收敛率$tilde{text{O}}(T^{-1/3})$。这与这类问题的理论下界相匹配。此外，研究还建立了在Polyak-Łojasiewicz (PŁ) 条件下的Muus变体收敛性保证。
### Innovation
研究提出并分析了一种名为Muus-VR2的方差减少变体，提供了一个严格的证明，证明该机制使Muus-VR2能够达到最优的收敛率，即$tilde{text{O}}(T^{-1/3})$，以此匹配此类问题的理论下界。此外，研究还建立了在PŁ条件下的Muus变体收敛性保证，从而提供了一个Muus风格优化器性能优化的第一理论依据。
### Conclusion
该研究提供了Muus风格优化器性能的第一证明，并指明了如何开发出更高效、加速的改进变体的道路。
## 684. `cs.LG` - FedHK-MVFC: 联邦热核多视图聚类 [PDF](https://arxiv.org/pdf/2509.15844), [HTML](https://arxiv.org/abs/2509.15844)
### Authors
Kristina P. Sinaga
### Background
在分布式人工智能和隐私保护医疗应用领域，研究提出了一种将量子场论与联邦医疗服务分析相结合的多视图聚类框架。通过谱分析中的热核系数将欧几里得距离转换为几何感知相似度度量，从而捕捉不同医学数据的结构。利用热核距离（HKD）的变换并提供了收敛保证。这种方法在心血管患者的合成数据集上测试显示，相比于集中式方法，其聚类准确性提升了8-12%，通信量减少了70%，而且保留了98.2%的效率。
### Innovation
开发了两种算法：一种适用于集中式分析的热核增强多视图模糊聚类（HK-MVFC），另一种用于医院间安全隐私保护学习的联邦热核多视图模糊聚类（FedHK-MVFC），基于差异隐私和安全聚合，实现HIPAA合规的协作。理论贡献包括证明收敛的更新规则、视图权重的自适应调整和隐私保护协议。
### Conclusion
该研究提出了医学分析中几何感知联邦学习的新标准，将复杂的数学理论转化为分析敏感医学数据的可行解决方案，同时保证了分析的严谨性和临床相关性。该方法适用于跨医院的合作表型分析，包括心电图、心脏影像和行为数据。
## 685. `cs.LG` - ToFU: 使联邦学习系统如何忘记用户数据的方法 [PDF](https://arxiv.org/pdf/2509.15861), [HTML](https://arxiv.org/abs/2509.15861)
### Authors
Van-Tuan Tran,Hong-Hanh Nguyen-Le,Quoc-Viet Pham
### Background
联邦学习系统中的神经网络会无意中记忆训练数据，这在敏感数据方面创建了隐私风险，如推理和重建攻击。为了减轻这些风险并遵守隐私法规，引入了联邦遗忘（FU）方法，允许联邦学习系统中的参与者去除其数据对全球模型的影响。但是，当前的FU方法主要是在事后进行操作，难以高效地抹除神经网络深度记住的信息。
### Innovation
提出了学习遗忘的基于转换的联邦遗忘（ToFU）框架，该框架在学习过程中引入转换以减少特定实例的记忆。理论分析表明，转换组合可以直接简化后续的遗忘操作，理论证明实例特定信息的上限。此外，ToFU作为一种即插即用框架，可以提升现有FU方法的性能。
### Conclusion
在CIFAR-10、CIFAR-100和MUFAC基准测试上进行的实验表明，ToFU优于现有的FU基线，与当前方法结合使用时性能更好，并且能减少遗忘时间。
## 686. `cs.LG` - 从数据到诊断：针对儿童白血病预测的大规模、全面骨髓数据集和AI方法 [PDF](https://arxiv.org/pdf/2509.15895), [HTML](https://arxiv.org/abs/2509.15895)
### Authors
Henning Höfener(1),Farina Kock(1),Martina Pontones(2),Tabita Ghete(2 and 3),David Pfrang(1),Nicholas Dickel(4),Meik Kunz(4),Daniela P. Schacherer(1),David A. Clunie(5),Andrey Fedorov(6),Max Westphal(1),Markus Metzler(2 and 3 and 7) ((1) Fraunhofer Institute for Digital Medicine MEVIS, Bremen, Germany, (2) Department of Pediatrics and Adolescent Medicine, University Hospital Erlangen, Erlangen, Germany, (3) Bavarian Cancer Research Center (BZKF), Erlangen, Germany, (4) Medical Informatics, Friedrich-Alexander University of Erlangen-Nürnberg, Erlangen, Germany, (5) PixelMed Publishing LLC, Bangor, PA, USA, (6) Department of Radiology, Brigham and Women's Hospital and Harvard Medical School, Boston, MA, USA, (7) Comprehensive Cancer Center Erlangen-EMN, Erlangen, Germany)
### Background
目前，白血病的诊断主要依赖于人工显微镜分析骨髓形态并结合其他实验室参数，这既复杂又耗时。虽然人工智能（AI）解决方案已经被提出，但许多解决方案仅使用私有数据集且只覆盖诊断流程的部分环节。
### Innovation
本文提出了一个大规模、高质量、公开可用的白血病骨髓数据集，该数据集涵盖了从细胞检测到诊断的整个诊断过程。使用该数据集，提出了细胞检测、细胞分类和诊断预测的方法。该数据集包括246名患儿的诊断、临床和实验室信息，以及超过40000个带有边界框注释的细胞和超过28000个高质量类别标签的细胞，使其成为迄今为止最全面的公开数据集。
### Conclusion
人工智能模型的评估结果显示，细胞检测的平均精度为0.96，细胞分类（33个类别）的曲线下面积为0.98，F1得分0.61，预测诊断的平均F1得分为0.90，使用预测的细胞计数。虽然提出的方法证明了其在辅助诊断中的实用性，但该数据集还将促进该领域的进一步研究和开发，最终有助于更精确的诊断和改善患者结果。
## 687. `cs.LG` - 使用离线奖励评估和策略搜索增强生成自动出价 [PDF](https://arxiv.org/pdf/2509.15927), [HTML](https://arxiv.org/abs/2509.15927)
### Authors
Zhiyu Mou,Yiqin Lv,Miao Xu,Cheems Wang,Yixiu Mao,Qichen Ye,Chao Li,Rongquan Bai,Chuan Yu,Jian Xu,Bo Zheng
### Background
自动出价是广告商提高广告效果的重要工具。最近的研究表明，基于AI生成的出价（AIGB）方法，将自动出价任务表示为轨迹生成任务，并通过离线数据训练条件扩散式规划器，表现出优于典型的基于离线强化学习（RL）的自动出价方法的稳定性和优越性。然而，现有的AIGB方法仍然存在性能瓶颈，因其忽视了详细的生成质量评估，无法探索超出静态数据集的能力。
### Innovation
我们提出了AIGB-Pearl（基于RL的轨迹评估与规划），一种结合生成性规划和策略优化的新方法。AIGB-Pearl的关键在于构建了一个非引导性轨迹评估器，以分配奖励并指导策略搜索，使规划器能够通过交互迭代优化其生成的质量。此外，为了在离线环境中提高轨迹评估器的准确性，我们融入了三种关键技术：基于大语言模型的架构、混合点式和对式损失以及专家反馈自适应集成。
### Conclusion
在模拟和现实世界的广告系统中进行的广泛实验表明，我们的方法处于最先进的技术水平。
## 688. `cs.LG` - 基于文本的GridWorld中的基础模型作为世界模型：一项基础性研究 [PDF](https://arxiv.org/pdf/2509.15915), [HTML](https://arxiv.org/abs/2509.15915)
### Authors
Remo Sasso,Michelangelo Conserva,Dominik Jeurissen,Paulo Rauber
### Background
尽管从零开始的强化学习在具有高效模拟器的序列决策任务中展现了出色的结果，但现实世界中的应用场景往往由于交互成本高昂而需要更高效的代理。基础模型（FMs）作为一种知识丰富且具备广泛推理能力的自然候选人，可以提升样本效率，但如何将其有效集成到强化学习框架中仍不清楚。
### Innovation
本文提出了两种有前景的战略进行评估：一是利用基础世界模型（FWMs）来运用FMs的先验知识，在模拟交互中训练和评估代理。二是利用基础代理（FAs）来利用FMs的推理能力进行决策。这些方法在适合当前大语言模型（LLMs）的格子世界环境中的表现评估表明，大语言模型的改进已经转化为更好的FWM和FA；基于当前LLM的FA能够在足够简单的环境中提供卓越的策略；而对于部分可观测性和随机性较强的复杂环境，FWM与强化学习代理的结合前景尤为值得期待。
### Conclusion
我们的结果表明，FWM和FA在当前格子世界环境中的表现良好，特别是FA，基于当前LLMs的FA能够在简单环境中提供优秀的策略，并且FWM与强化学习代理结合的策略对于更复杂、不确定的环境颇具潜力。
## 689. `cs.LG` - SAGE: 具有语义意识的共享采样以提高扩散模型效率 [PDF](https://arxiv.org/pdf/2509.15865), [HTML](https://arxiv.org/abs/2509.15865)
### Authors
Haoran Zhao,Tong Bai,Lei Huang,Xiaoyu Liang
### Background
扩散模型在多个领域表现出显著的优势，但其高采样成本，需要进行多次连续的模型评估，仍然是一个主要限制。现有的加速采样方法主要是通过优化求解器或知识蒸馏来独立处理每个查询。
### Innovation
提出了一种具有语义意识的共享采样框架SAGE，通过在语义相似的查询之间共享早期阶段的采样来减少总的采样步骤数量。SAGE结合了高效的共享采样方案和定制化的训练策略以保持生成质量。实验表明，SAGE能将采样成本降低25.5%，同时生成质量也得到提升，FID下降5.0%，CLIP提高5.4%，多样性提高160%。
### Conclusion
通过SAGE，能够在不牺牲质量的前提下显著降低扩散模型的采样成本并提高生成质量。
## 690. `cs.LG` - EvoBrain: 动态多通道EEG图建模以表征时变脑网络 [PDF](https://arxiv.org/pdf/2509.15857), [HTML](https://arxiv.org/abs/2509.15857)
### Authors
Rikuto Kotoge,Zheng Chen,Tasuku Kimura,Yasuko Matsubara,Takufumi Yanagisawa,Haruhiko Kishima,Yasushi Sakurai
### Background
动态GNNs能够整合EEG数据中的时空特征，在自动化的癫痫检测方面展现出巨大潜力。然而，全面捕捉描述脑状态（如癫痫发作与非癫痫状态）的动力学特征是一项艰巨的任务，主要存在两个挑战。首先，现有的大多数动态GNN方法基于固定的时间静态图，无法反映大脑连接性在癫痫发作进展过程中的演变性质。其次，当前对同时建模时间信号和图结构及其交互的研究仍处于起步阶段，通常导致性能不一致。
### Innovation
本文首先对这两个问题进行了理论分析，证明了明确动态建模和时间-然后-图动态GNN方法的有效性和必要性。基于这些见解，提出了一种名为EvoBrain的新模型，该模型集成了带有Laplacian位置编码增强的GCN的双流Mamba架构。EvoBrain采用了明确的动态图结构，使得节点和边能在时间上动态变化，从而显著提高了表现。具体贡献包括(a)证明了明确动态建模和时间-然后-图动态GNN方法在表示能力上的优势，(b) 提出了一个新颖且高效的模型，该模型在与动态GNN基线相比中，显著提高了AUROC 23%和F1分数 30%，(c) 在复杂早期癫痫预测任务中广泛评估了该方法。
### Conclusion
本文通过对动态GNN的理论分析，提出了一种名为EvoBrain的新型癫痫检测模型。该模型不仅显著提高了性能，还为动态多通道EEG图建模提供了新的解决方案。
## 691. `cs.LG` - Latent空间中通过采样合成数据实现高效的长尾学习 [PDF](https://arxiv.org/pdf/2509.15859), [HTML](https://arxiv.org/abs/2509.15859)
### Authors
Nakul Sharma
### Background
不平衡分类数据集在机器学习中提出了重大挑战，往往导致偏向模型在少数类的表现不佳。随着基础模型的兴起，近年来的研究主要集中在对这些模型进行全量、部分和参数高效的微调，以应对长尾分类问题。尽管这些工作在基准数据集上的表现令人印象深刻，但在闭合与平衡数据集训练的网络之间的差距方面仍然存在不足，并且即使在较小的数据集上也仍然需要大量的计算资源。为了追求计算效率和简单性，我们在本文中提出了一种新型框架，利用视觉基础模型丰富的语义隐空间生成合成数据，并用真实数据和合成数据混合训练一个简单的线性分类器以应对长尾分类问题。这种方法在计算效率方面有所提升，因为仅需要使线性模型的参数数量的计算资源.
### Innovation
本文提出了一种新型框架，利用视觉基础模型丰富的语义隐空间生成合成数据，并用真实数据和合成数据混合训练一个简单的线性分类器来解决长尾分类问题。这种方法的优势在于大幅提升计算效率，只需训练线性模型的参数数量，而不必对基础模型进行全量或高效的微调。此方法在CIFAR-100-LT基准和Places-LT基准上的表现突出，证明了简单而有效的方法的效用和适应性.
### Conclusion
本文提出的方法在CIFAR-100-LT基准上设定了新的SOTA，并在Places-LT基准上表现出色，证明了这种简单且有效的方法的有效性和适应性。
## 692. `cs.LG` - Adversarial Graph Fusion for Incomplete Multi-view Semi-supervised Learning with Tensorial Imputation [PDF](https://arxiv.org/pdf/2509.15955), [HTML](https://arxiv.org/abs/2509.15955)
### Authors
Zhangqi Jiang,Tingjin Luo,Xu Yang,Xinyan Liang
### Background
在基于图的多视图半监督学习中，缺失的样本视图是一个显著挑战，限制了其实际应用。传统方法通过引入缺失指示矩阵，并专注于挖掘每个视图中存在的样本的部分结构来进行标签传播（LP），但有时会忽略这些缺失样本。这些被忽略的样本有时会诱导局部结构的不连续性，即子聚类，破坏了LP中的平滑性假设，导致“子聚类问题（SCP）”。这个问题会扭曲图融合并降低分类性能。
### Innovation
提出了一种新颖的不完整多视图半监督学习方法，称为AGF-TI。设计了一个对抗图融合方案，通过最小-最大框架学习一个对抗局部结构扭曲的稳健共识图。通过堆叠所有相似度矩阵为张量并基于低秩张量学习恢复不完整结构，进一步挖掘高阶一致信息。同时整合了锚点策略来减少计算复杂性。提出了一个结合削减梯度下降法的高效交替优化算法，该算法用于解决提出的优化目标，具有理论上的收敛性。
### Conclusion
在各种数据集上的广泛实验结果验证了我们提出的AGF-TI的优越性，相较于最先进的方法具有更好的性能。方法的代码已公开。
## 693. `cs.LG` - The Alignment Bottleneck [PDF](https://arxiv.org/pdf/2509.15932), [HTML](https://arxiv.org/abs/2509.15932)
### Authors
Wenjun Cao
### Background
大型语言模型随规模的增大而改进，但是基于反馈的对齐仍然表现出与预期行为系统性偏离的现象。受到经济学和认知科学中有限理性的启发，研究者将判断视为资源有限的过程，并将反馈视为受限的通道。在此基础上，作者提出了一个基于容量耦合的对齐性能区间。
### Innovation
作者提出了一个容量耦合的对齐性能区间，结合了数据规模无关的Fano下界和一个通过$ m bar{C}_{text{tot}|S} $控制的PAC-Bayes上界。这种边界在特定条件下成为相同真实风险的上界，并且作者通过这一框架表明，单纯增加标签不能突破这一界限，更复杂的目标需要能力随$ text{log} M $增长，当有用信号饱和能力后，优化倾向于拟合渠道规律，这也与对恭维和奖励滥用的报告相符。另外，研究将对齐视作接口工程，应对有限能力、管理任务复杂度并决定信息的分配。
### Conclusion
在有限能力和复杂度固定的情况下，单纯增加标签不能穿越对齐性能的界限；对更复杂目标实现更小的风险需求能力与$ text{log} M $有关；当有用信号达到能力上限后，进一步优化往往拟合渠道规律，一致了恭维和奖励滥用的报告现象。研究提供了对齐工程的一个理论视角：测量和分配有限的能力、管理任务的复杂度并通过有效分配信息来达成目标。
## 694. `cs.LG` - 改进蒙特卡洛树搜索以用于符号回归 [PDF](https://arxiv.org/pdf/2509.15929), [HTML](https://arxiv.org/abs/2509.15929)
### Authors
Zhengyao Huang,Daniel Zhengyu Huang,Tiannan Xiao,Dina Ma,Zhenyu Ming,Hao Shi,Yuanhui Wen
### Background
符号回归旨在发现简洁且可解释的数学表达式，目的是拟合数据或者解决高度组合优化问题。虽然遗传编程是主要的方法，但最近的研究开始探索强化学习方法来提高搜索效率。Monte Carlo Tree Search (MCTS)由于其通过引导搜索来平衡探索与利用的能力，被认为是一种很有前景的技术。然而，传统的MCTS方法中的赌博式分配策略和按顺序构建符号的方法往往限制了其性能。
### Innovation
本研究提出了一种改进的MCTS框架，通过两个关键创新点来解决上述问题：(1) 一种极端的赌博式分配策略，专为识别最佳全局表达式设计，并假设多项式奖励衰减情况下具备有限时间性能保证；(2) 进化启发式的状态跳跃动作，比如变异和交叉操作，使搜索空间中潜在有价值区域的非局部转换成为可能。这些状态跳跃动作还会重新塑造搜索过程中的奖励景观，提高稳健性和效率。
### Conclusion
本研究进行了一项详尽的数字研究以评估这些改进的效果，并将该方法与现有的符号回归方法进行基准测试，包括真实和黑盒数据集。本方法在恢复率方面与最先进的库具有竞争力，并在准确性和模型复杂性的帕累托前沿上获得了有利位置。源代码可以在以下链接找到：this https URL.
## 695. `cs.LG` - UniTac2Pose: 在模拟中学习的统一方法用于类别级别的视觉触觉在手姿态估计 [PDF](https://arxiv.org/pdf/2509.15934), [HTML](https://arxiv.org/abs/2509.15934)
### Authors
Mingdong Wu,Long Yang,Jin Liu,Weiyao Huang,Lehong Wu,Zelin Chen,Daolin Ma,Hao Dong
### Background
准确基于CAD模型估计物体的手持姿态在工业应用和日常任务中至关重要，涉及工作件定位、组件组装以及USB插件等无缝插入。现有方法通常依赖回归、特征匹配或注册技术，但实现高度精确性和对未见CAD模型的一般化仍然是重大挑战。
### Innovation
本文提出了一种新颖的三阶段框架用于手持姿态估计。第一阶段包括采样和初步排列姿态候选者，第二阶段通过迭代优化进一步细化这些候选者，第三阶段通过后续排列来识别最可能的姿态候选者。这些阶段由统一的能量扩散模型管理，该模型仅基于模拟数据进行训练。能量模型同时生成用于细化姿态估计的梯度，以及量化姿态估计质量的能量标量。此外，借鉴计算机视觉领域的理念，在能量型评分网络中引入渲染-对比架构，显著提高模拟到现实的性能。
### Conclusion
本文方法在全面实验中表现出色，优于基于回归、匹配和注册的传统基线，并且在未见CAD模型之间表现出强类别内的泛化能力。此外，该方法综合了触觉物体姿态估计、姿态跟踪和不确定性估计，为各种现实世界条件下的稳健性能提供支持。
## 696. `cs.LG` - RLinf：通过宏观到微观工作流转换实现灵活高效的大型强化学习 [PDF](https://arxiv.org/pdf/2509.15965), [HTML](https://arxiv.org/abs/2509.15965)
### Authors
Chao Yu,Yuanqing Wang,Zhen Guo,Hao Lin,Si Xu,Hongzhi Zang,Quanlu Zhang,Yongji Wu,Chunyang Zhu,Junhao Hu,Zixiao Huang,Mingjie Wei,Yuqing Xie,Ke Yang,Bo Dai,Zhexuan Xu,Xiangyuan Wang,Xu Fu,Zhihao Liu,Kang Chen,Weilin Liu,Gang Liu,Boxun Li,Jianlei Yang,Zhi Yang,Guohao Dai,Yu Wang
### Background
强化学习（RL）在推动通用人工智能、自主智能和实体智能方面展现了巨大的潜力。然而，现有的RL工作流的固有异质性和动态性导致了硬件利用率低和训练速度慢的问题。
### Innovation
本文提出了基于宏微观转化流（M2Flow）新型RL系统设计理念的高性能RL训练系统RLinf，通过自动生成的宏微观工作流转化，提高系统灵活性和效率。结合RLinf工作者的自适应通信能力，实现了上下文切换和弹性流水线，并通过基于性能分析的调度策略生成最优执行计划，从而在大规模的策略推理和实体智能RL任务中取得显著效果，相比现有系统实现了1.1倍到2.13倍的端到端训练吞吐量提升。
### Conclusion
与现有的先进系统相比，RLinf在大规模策略推理和实体智能RL任务中的端到端训练吞吐量提升了1.1倍到2.13倍。
## 697. `cs.LG` - 通过影响函数对基于DNN的接收器进行目标微调 [PDF](https://arxiv.org/pdf/2509.15950), [HTML](https://arxiv.org/abs/2509.15950)
### Authors
Marko Tuononen,Heikki Penttinen,Ville Hautamäki
### Background
本文介绍了首次将影响函数应用到基于深度学习的无线接收器中。研究对象是全卷积接收器DeepRx，通过影响分析揭示了哪些训练样本驱动了位预测结果，从而可以对表现不佳的案例进行更有针对性的微调。实验证明，基于容量似二元交叉熵损失和对有益样本进行一阶更新所得到的损失相对影响最能一致地提高位错误率，优于随机微调。多目标适应效果较差，表明存在未解决的问题。
### Innovation
提出了一种使用影响函数进行有效的基于DNN的接收器微调的方法。通过影响分析确定关键训练样本，采用损失相对影响和一阶更新策略，针对性地提高位错误率。此外还提出了一个基于二阶、影响对齐的更新策略，将影响函数既作为解释工具又作为高效的接收器调整基础，展示了影响函数在接收器调整和解释中的潜力。
### Conclusion
本研究证实了影响函数既是解释工具也是有效接收器调整的理论基础。不过，多个目标适应仍需改进，存在开放问题。
## 698. `cs.LG` - 基于贝叶斯物理感知神经网络的可靠变压器预测维护 [PDF](https://arxiv.org/pdf/2509.15933), [HTML](https://arxiv.org/abs/2509.15933)
### Authors
Ibai Ramirez,Jokin Alcibar,Joel Pino,Mikel Sanz,David Pardo,Jose I. Aizpurua
### Background
科学机器学习（SciML）将物理和数据整合到学习过程中，相比纯数据驱动模型具有更好的泛化能力。尽管具有潜力，SciML在预测性维护（尤其是变压器老化预测）中的应用仍受到限制，主要原因包括复杂性以及缺乏可靠的不确定性量化方法，特别是在处理偏微分方程（PDE）方面。本文提出了一种贝叶斯物理感知神经网络（B-PINN）框架，通过嵌入贝叶斯神经网络改进了预测性维护的不确定性意识能力，并在实际变压器老化案例研究中进行了验证与评估.
### Innovation
通过将贝叶斯神经网络嵌入到物理感知神经网络（PINN）架构，提出的方法能够生成原则性的、具备不确定性的预测结果。这种方法在变压器绝缘老化受热应力驱动的案例研究中得到了应用，通过使用热扩散偏微分方程作为物理残差，探讨了不同的先验分布对预测后验分布的影响，以及它们如何将先验物理知识编码进去。该方法还与Dropout-PINN基线进行了对比验证，结果表明B-PINN能够提供更加可靠和精确的预测，这在支持关键电力资产的稳健和知情维护决策方面是至关重要的.
### Conclusion
B-PINN框架通过准确量化预测不确定性，显著提高了变压器预测维护的可靠性，这为驱动基于数据的维护决策提供了坚实的基础。
## 699. `cs.LG` - 基于不确定性平滑策略正则化来解决少演示情况下的强化学习问题 [PDF](https://arxiv.org/pdf/2509.15981), [HTML](https://arxiv.org/abs/2509.15981)
### Authors
Yujie Zhu,Charles A. Hepburn,Matthew Thorpe,Giovanni Montana
### Background
在使用稀疏奖励的强化学习中，演示可以加速学习过程，但如何决定何时模仿演示仍然是一个挑战。现有的方法（如Q-filter）往往做出二元模仿决策，但这样会导致在训练过程中梯度方差增加，从而影响学习效率。
### Innovation
提出了平滑策略正则化从演示学习（SPReD）框架。该框架通过集成方法明确建模演示和策略动作的Q值分布，并量化不确定性进行比较。SPReD还开发了两种互补的不确定性感知方法：一个是概率方法，估计演示优越性的概率；另一个是优势基方法，通过统计显著性比例调整模仿。
### Conclusion
SPReD在八个机器人任务上的实验中取得了显著的效果，在复杂任务上优于现有方法高达14倍，同时对外部分演示的质量和数量具有较强的鲁棒性。
## 700. `cs.LG` - 用于学习应用于路线问题的成本的逆优化潜变量模型 [PDF](https://arxiv.org/pdf/2509.15999), [HTML](https://arxiv.org/abs/2509.15999)
### Authors
Alan A. Lahoud,Erik Schaffernicht,Johannes A. Stork
### Background
对于具有未知成本函数的受约束优化问题（COPs），学习表示解决方案的表示具有挑战性，因为（变分）自动编码器等模型在解码结构化输出时难以强制实施约束。现有方法在重建具有约束的输出时也存在问题。
### Innovation
提出了一种逆优化潜变量模型（IO-LVM），能够从观察到的解中学习COP成本函数的潜空间，并通过解释器循环求解COP来重建可行输出。该方法利用Fenchel-Young损失的估计梯度来塑造潜空间，同时与标准逆优化或逆强化学习方法不同，IO-LVM能够捕捉成本函数的分布，从而识别由不同代理人或训练过程中不可用的不同条件引起的不同解行为。
### Conclusion
该方法已经在实际船舶和出租车路线数据集以及合成图路径上进行了验证，展示了其重建路径和环路、预测路径分布以及提供可解释的潜空间表示的能力。
## 701. `cs.LG` - MTS-DMAE: 双掩码自编码器在无监督多变量时间序列表征学习中的应用 [PDF](https://arxiv.org/pdf/2509.16078), [HTML](https://arxiv.org/abs/2509.16078)
### Authors
Yi Xu,Yitian Zhang,Yun Fu
### Background
无监督多变量时间序列(MTS)表征学习旨在从原始序列中提取紧凑且具有信息量的表示，而不依赖标签，从而高效地转移到多种下游任务上。
### Innovation
提出了一种新颖的掩码时间序列建模框架——双掩码自编码器(Dual-Masked Autoencoder, DMAE)，该框架通过两个互补的预训练任务：(1) 根据可见属性重建掩码值；(2) 由教师编码器指导估计掩码特征的潜在表示，同时增加特征级对齐约束，鼓励预测的潜在表示与教师的输出对齐。
### Conclusion
通过联合优化这些目标，DMAE 学习到时序连贯且语义丰富的表示。全面评估显示，该方法在分类、回归和预测任务中均取得了一致且优越的性能，优于竞争性基线方法。
## 702. `cs.LG` - 通讯到环流：利用5G GPS信号和深度学习进行三维风场检索和实时预测 [PDF](https://arxiv.org/pdf/2509.16068), [HTML](https://arxiv.org/abs/2509.16068)
### Authors
Yuchen Ye,Hong Liang,Chaoxia Yuan,Mingyu Li,Aoqi Zhou,Chunqing Shang,Hua Cai,Peixi Liu,Kezuan Wang,Yifeng Zheng
### Background
准确的大气风场信息对于天气预报、航空安全和灾害风险减少等方面至关重要。然而，由于传统现场观测和遥感技术的局限性以及数值天气预报（NWP）模型在计算成本、偏差等方面的不足，获得高空间和时间分辨率的风数据仍然是一个挑战。
### Innovation
论文提出了一种名为G-WindCast的全新深度学习框架，利用5G全球导航卫星系统（GNSS）信号的信号强度变化来检索和预测三维大气风场。该框架采用前向神经网络（FNN）和Transformer网络，以捕捉GNSS衍生特征和风动态之间的复杂非线性和时空关系。初步结果显示，该模型在风场检索和短期风速预测方面具有出色的准确性，技能评分与高分辨率NWP输出在某些情况下相当，并且表现出在不同预报时间和气压水平上的鲁棒性。此外，系统即使在GNSS基站数量显著减少（如约100个）的情况下，也能保持优异的性能，显示出其成本效益和可扩展性。
### Conclusion
这种跨学科方法强调了利用非传统数据源和深度学习进行高级环境监测和实时大气应用的潜力。
## 703. `cs.LG` - 预测极端主义和恐怖主义的演变 [PDF](https://arxiv.org/pdf/2509.16014), [HTML](https://arxiv.org/abs/2509.16014)
### Authors
R.O. Lane,W.J. Holmes,C.J. Taylor,H.M. State-Davey,A.J. Wragge
### Background
该论文提出了一个自动分析和跟踪在线收集的声明，并检测声明作者是否可能参与极端主义或恐怖主义的方法。背景信息表明，研究人员针对恐怖分子、极端主义者、活动家和政客的引语进行了测试，这些引语来自特定网站。通过提取最先进的Universal Sentence Encoder生成的特征，并使用支持向量机分类器进行训练和测试，研究团队能够准确地识别与极端主义和恐怖主义相关的意图和态度。
### Innovation
创新点在于提出了一个自动分析和跟踪声明的方法，首次使用了Universal Sentence Encoder生成文本特征，并结合支持向量机分类器，能更准确地检测出声明是否与极端主义或恐怖主义相关。此外，还提出了运用追踪技术进行时间分析的方法，有效捕捉态度的变化趋势和关键事件的影响。
### Conclusion
该系统能够正确检测出与极端主义相关的意图和态度达到81%，与恐怖主义相关的达到97%。与基于n-gram特征的基线系统相比，该系统的准确性更高。通过这种追踪技术，系统还能够检测出时间上的态度变化趋势和突然改变态度的事件。
## 704. `cs.LG` - 将分子合成性重新思考为链式反应 [PDF](https://arxiv.org/pdf/2509.16084), [HTML](https://arxiv.org/abs/2509.16084)
### Authors
Seul Lee,Karsten Kreis,Srimukh Prasad Veccham,Meng Liu,Danny Reidenbach,Saee Paliwal,Weili Nie,Arash Vahdat
### Background
分子生成模型的一个常见陷阱是它们不能保证生成可合成的分子。尽管已经有所尝试解决这个问题，但由于可合成分子组合空间的指数级庞大，现有方法的空间覆盖率有限，分子优化性能不佳。
### Innovation
引入ReaSyn，一种用于可合成投影的生成框架，该框架通过生成生成可合成类似物的路径来探索给定分子在可合成空间中的邻域。提出了一种新的视角，将合成路径视为类似于大型语言模型中的推理路径。提出chain-of-reaction (CoR) 标注法，并引入强化学习（RL）微调和目标驱动的测试时计算缩放，进一步增强了ReaSyn的推理能力。ReaSyn在可合成分子重构、可合成目标导向分子优化方面表现最佳，并显著优于之前的可合成投影方法。
### Conclusion
ReaSyn具有在空前大规模的可合成化学空间中导航的优越能力，能够在合成途径中获取密集监督，在监督训练中明确学习化学反应规则，并且进行逐步推理。
## 705. `cs.LG` - EmoHeal：一种基于细粒度情绪的个性化治疗性音乐检索的端到端系统 [PDF](https://arxiv.org/pdf/2509.15986), [HTML](https://arxiv.org/abs/2509.15986)
### Authors
Xinchen Wan,Jinhua Liang,Huan Zhang
### Background
现有的数字心理健康工具往往忽略了日常挑战背后复杂的情绪状态。例如，睡前焦虑影响着全球超过10亿人，但当前的方法主要静态且‘一刀切’，未能适应个体需求。
### Innovation
EmoHeal系统是一个端到端的解决方案，可以通过微调的XLM-RoBERTa模型识别用户文本中的27种细微情绪，并通过基于音乐疗法原则（如GEMS和iso原则）的知性图映射到音乐参数。该系统使用CLAMP3模型检索音视频内容，引导用户从当前状态过渡到更平静的状态（‘匹配-引导-目标’）。研究表明，用户报告情绪显著改善（M=4.12，p<0.001），且感知到的情绪识别准确性高（M=4.05，p<0.001）。感知准确性与治疗效果之间存在强相关性（r=0.72，p<0.001），验证了精细粒度方法的有效性。
### Conclusion
这项研究证明了基于理论的、情绪感知的数字心理健康工具的可行性，并提供了音乐疗法原则实现可扩展AI的蓝图。
## 706. `cs.LG` - 时间自适应SympNets对于可分哈密尔顿系统的应用 [PDF](https://arxiv.org/pdf/2509.16026), [HTML](https://arxiv.org/abs/2509.16026)
### Authors
Konrad Janik,Peter Benner
### Background
测量数据通常是非等间距采样的，这意味着时间不是匀速分布的。即使对于哈密尔顿系统而言，测量数据也具有同样的性质。现有的机器学习方法，如SympNets [20]和HénonNets [4]，仍然需要使用固定时间步长生成的训练数据来学习辛积分器。为了学习自适应时间的辛积分器，提出了TSympNets [20]。然而，到目前为止，TSympNets的逼近能力未知。
### Innovation
作者通过表现可分哈密尔顿系统的普遍逼近定理来填补了该领域的空白，并展示了它不能扩展到不可分的哈密尔顿系统。此外，作者纠正了一个关于一般辛映射逼近的重要定理[25, 定理2]的证明中的错误，特别针对辛机器学习方法进行了修正。
### Conclusion
研究通过理论和数值实验探讨了这些理论逼近能力。研究结果为时间自适应辛积分器在哈密尔顿系统中的应用提供了坚实的理论基础，同时也纠正了现有方法中的一个关键错误，提高了其适用性。
## 707. `cs.LG` - DiffusionNFT：借助前向过程的在线自旋强化学习 [PDF](https://arxiv.org/pdf/2509.16117), [HTML](https://arxiv.org/abs/2509.16117)
### Authors
Kaiwen Zheng,Huayu Chen,Haotian Ye,Haoxiang Wang,Qinsheng Zhang,Kai Jiang,Hang Su,Stefano Ermon,Jun Zhu,Ming-Yu Liu
### Background
在线强化学习（RL）在后训练语言模型中占据重要地位，但其扩展到扩散模型仍然具有挑战性，主要由于难以计算的概率。最近的一些工作通过离散化反向采样过程来启用类似于GRPO的训练，然而这些方法仍然存在根本性的问题，比如求解器限制、正向-反向不一致性和与无分类指导（CFG）的复杂整合。
### Innovation
DiffusionNFT 是一个新的在线 RL 帕累托，它直接在前向过程中优化扩散模型，通过流匹配定义正向和负向生成之间的对比，自然地将强化信号整合到监督学习目标中。这种方法使使用任意黑盒求解器进行训练成为可能，消除了概率估计的需要，并且只需要干净的图像而不是采样轨迹来优化策略。
### Conclusion
DiffusionNFT 在与 FlowGRPO 的直接对比中展现了更高的效率，可达 25 倍，并且是无需要 CFG 的。例如，在 1k 步以内，DiffusionNFT 达到了 0.98 的 GenEval 分数，而 FlowGRPO 在超过 5k 步并额外使用 CFG 的情况下仅达 0.95。通过利用多个奖励模型，DiffusionNFT 显著提升了 SD3.5-Medium 在所有测试基准上的性能。
## 708. `cs.LG` - 在介观结构媒体中时空、多场深度学习冲击波传播 [PDF](https://arxiv.org/pdf/2509.16139), [HTML](https://arxiv.org/abs/2509.16139)
### Authors
M. Giselle Fernández-Godino,Meir H. Shachar,Kevin Korner,Jonathan L. Belof,Mukul Kumar,Jonathan Lind,William J. Schill
### Background
预测冲击波在多孔和结构化材料中的传播能力对于行星防御、国家安全以及实现惯性聚变能量至关重要。然而，捕捉孔隙坍塌、异常Hugoniot响应和局部加热等现象——这些现象可能决定小行星偏转或聚变点火的成功——仍然是一个重大挑战，尽管在单场和简化表示方面取得了近期进展。
### Innovation
我们引入了一种多场时空深度学习模型（MSTM），将七个耦合场——压力、密度、温度、能量、材料分布以及两个速度分量——统一到一个自回归代理中。该模型在高保真水动力代码数据上进行了训练，运行速度比直接模拟快约1000倍，达到孔隙材料中小于4%的误差和晶格结构中小于10%的误差。与以前的单场或基于操作符的代理不同，MSTM可以解决尖锐的冲击波前缘，同时保持质量加权平均压力和温度等方面积分量在5%以内的精度。
### Conclusion
这一进展将过去被认为难以解决的问题转化为可以解决的设计研究，建立了通过微结构材料优化来减轻行星撞击、惯性聚变能源和国家安全问题的实用框架。
## 709. `cs.LG` - 个性化联邦学习中的热核增强张量多视图聚类 [PDF](https://arxiv.org/pdf/2509.16101), [HTML](https://arxiv.org/abs/2509.16101)
### Authors
Kristina P. Sinaga
### Background
介绍了利用热核增强的张量多视图模糊聚类的新框架，该框架结合了先进的张量分解技术，用于处理个性化联邦学习中的高维多视图结构。该方法利用张量分解和多重指标化技术来发现隐藏结构和多线性关系，并采用了局部和全局两级优化方案，结合差分隐私保护机制实现高效的数据处理和通信节省。
### Innovation
提出了一种结合张量多视图模糊聚类和量子场理论中热核系数的框架，同时结合张量分解技术，如泰克尔分解和CANDECOMP/PARAFAC，以提高聚类效果和处理效率。该方法通过张量的核欧几里得距离变换和泰克尔分解来识别特定客户端的数据模式，并通过差分隐私协同聚类因子以保护隐私，实现了在联邦学习中的高效个性化处理和通信节省。
### Conclusion
该框架有效解决了个性化联邦学习中高维多视图数据的处理问题，通过张量分解和差分隐私保护机制提高了集群的精准度和通信效率。
## 710. `cs.LG` - 基于可泛化的图强化学习代理的自动化网络安全防御 [PDF](https://arxiv.org/pdf/2509.16151), [HTML](https://arxiv.org/abs/2509.16151)
### Authors
Isaiah J. King,Benjamin Bowman,H. Howie Huang
### Background
传统的强化学习方法将网络表示为具有不同安全或威胁状态的计算机列表。这些模型因需过度拟合特定的网络拓扑结构而受到限制，导致在面对环境微小变化时无效。
### Innovation
本文将自动化网络安全防御（ACD）问题定义为基于上下文的非完全可观测马尔可夫决策过程，并将观察结果表示为带属性的图形。该方法允许代理通过关系归纳偏见来进行推理。通过引入这种偏见，代理能够更好地理解和适应网络状态的变化，并且能够零样本地适应新网络。实验显示该方法显著优于现有最佳方法，在多种复杂且多代理环境中展示了强大的防御能力。
### Conclusion
本文提出的方法通过引入关系归纳偏见的图强化学习代理，实现了在面对未知网络和多样化攻击者时的出色表现，该方法不仅大幅超越了现有技术的优越性能，还展示了代理在复杂和多代理环境中的广泛应用前景。
## 711. `cs.LG` - 通过将稀疏回归算法与模型选择标准配对实现自动本构模型发现 [PDF](https://arxiv.org/pdf/2509.16040), [HTML](https://arxiv.org/abs/2509.16040)
### Authors
Jorge-Humberto Urrea-Quintero,David Anton,Laura De Lorenzis,Henning Wessels
### Background
本构模型自动发现从数据中提取本构模型的新方法，成为传统模型校准范式的有前途的替代方案。现有的工作引入了一种全自动框架，该框架系统地将三种稀疏回归算法（最小绝对收缩和选择运算符(LASSO)、最小角度回归(LARS)和正交匹配追踪(OMP)）与三种模型选择标准(K折交叉验证(CV)、赤池信息准则(AIC)和贝叶斯信息准则(BIC))相配对。这种配对生成了九种不同的本构模型发现算法，可以系统地探索稀疏性、预测性能和计算成本之间的权衡。
### Innovation
该工作开发了一种全新的框架，通过将稀疏回归算法与模型选择标准配对，以自动化的方式进行本构模型的发现。这种方法不仅增强了现有发现算法的选择范围，还提供了系统探索和优化稀疏本构模型的方法，特别引入了用于0-范数正则化的OMP算法作为path-based solver。该框架应用到了各向同性和各向异性超弹性的数据集，展示了所有九种算法与标准组合都能对材料的本构模型进行稳健而准确的发现。
### Conclusion
所有九种算法标准组合都表现出了对各向同性和各向异性材料本构模型发现的高准确性，这扩大了可行的发现算法范围，超越了基于1-范数的方法如LASSO。
## 712. `cs.LG` - SABER: 通过跨层残差连接揭示安全对齐的脆弱性 [PDF](https://arxiv.org/pdf/2509.16060), [HTML](https://arxiv.org/abs/2509.16060)
### Authors
Maithili Joshi,Palash Nandi,Tanmoy Chakraborty
### Background
大型语言模型（LLMs）经过安全对齐训练后具备强大的语言理解能力。尽管这些模型经过精心设计以确保安全输入并拒绝有害或不安全的输入，但在大规模且经过大量对齐努力后，LLMs 仍然容易遭受恶意用户的‘监禁破解’（jailbreak）攻击，这类攻击使模型生产被其本身训练避免的有害输出。研究发现，LLMs 的安全性机制主要嵌入在中后期层中。
### Innovation
本文提出了一种创新的白盒监禁破解方法 SABER（通过额外残差的安全对齐绕过），该方法通过残差连接将两个中间层 s 和 e 连接起来，其中 s < e。此方法在 HarmBench 测试集上的性能比基准方法最佳者提高了 51%，且在 HarmBench 验证集上的困惑度仅轻微增加。
### Conclusion
研究展示了 SABER 方法在揭示大型语言模型的安全对齐脆弱性方面的有效性，并显著增强了模型对监禁破解攻击的抵御能力，同时仅对模型性能带来微小影响。源代码已在公开网址提供。
## 713. `cs.LG` - 基于网络的可持续性和非侵入性唾液生物标志物自闭症谱系障碍检测 [PDF](https://arxiv.org/pdf/2509.16126), [HTML](https://arxiv.org/abs/2509.16126)
### Authors
Janayna M. Fernandes,Robinson Sabino-Silva,Murillo G. Carneiro
### Background
自闭症谱系障碍（ASD）缺乏可靠的生物标志物，导致早期诊断延迟。因此，需要开发新的方法来提高诊断的准确性。
### Innovation
本研究使用159个唾液样本和ATR-FTIR光谱分析，开发了GANet框架，这是一种基于遗传算法的网络优化框架，利用PageRank和Degree对高维度光谱数据进行重要特征刻画。GANet通过系统优化网络结构来提取有意义的模式，并且其性能优于线性判别分析、支持向量机和深度学习模型，达到了78%的准确率、61%的灵敏度、90%的特异性和0.74的调和平均值。这些结果表明GANet作为强健的、生物启发的、非侵入式的工具，在精确检测ASD和其他基于光谱的健康应用中具有潜力。
### Conclusion
研究结果显示，GANet作为一种基于网络的非侵入性工具，在精确检测ASD中表现出色，并且具备扩展到其他基于光谱的健康应用的可能性。
## 714. `cs.LG` - 随机化平滑与视觉语言模型的结合 [PDF](https://arxiv.org/pdf/2509.16088), [HTML](https://arxiv.org/abs/2509.16088)
### Authors
Emmanouil Seferis,Changshun Wu,Stefanos Kollias,Saddek Bensalem,Chih-Hong Cheng
### Background
随机化平滑（RS）是确保机器学习模型正确性的主要技术之一，它可以通过分析方式得出点的鲁棒性证明。虽然RS在分类任务中已被很好理解，但其在生成模型中的应用尚未完全确定。生成模型的输出是系列而不是标签，因此需要将生成输出连接到一个标准分类任务来确保鲁棒性。
### Innovation
本文通过将生成输出与一个标准分类任务联系起来，展示了RS仍然可以使生成模型获得鲁棒性分析。它将最终响应分类为离散动作（例如，小部件机器人中的服务命令）、有害 vs. 无害（内容审查或毒性检测中的 VLMs），并且即使是在较弱的假设条件下，也可以通过改进的理论使样本数量与相应的鲁棒性半径相关联，同时导出了鲁棒性半径和准确性与样本数量的改进公式。
### Conclusion
这些进步使得对于最先进的 VLMs 的鲁棒性认证不仅在定义上清晰，而且在计算上也是可行的，已经得到最新的囚笼式攻击方法的验证。
## 715. `cs.LG` - MICA：多智能体工业协调助理 [PDF](https://arxiv.org/pdf/2509.15237), [HTML](https://arxiv.org/abs/2509.15237)
### Authors
Di Wen,Kunyu Peng,Junwei Zheng,Yufan Chen,Yitain Shi,Jiale Wei,Ruiping Liu,Kailun Yang,Rainer Stiefelhagen
### Background
工业流程需要适应性强且可信赖的辅助系统，在有限的计算资源、连接性和严格的数据隐私限制下持续运行。现有的辅助系统在这些方面的能力有限，无法满足工业流程的特定需求。
### Innovation
MICA是一种基于感知和语音交互的系统，能够实时提供装配指导、故障排查、部件查询和维护支持。MICA通过五个角色专化的语言代理和安全检查器进行协调，确保准确和合规的支持。此外，MICA引入了自适应步骤融合方法，该方法能够动态结合专家推理和自然语言反馈的在线适应。该论文还提出了一个新的多智能体协调基准，并建立了适合工业辅助的评估指标。
### Conclusion
实验结果表明，MICA相比基准结构在任务成功率、可靠性和响应性方面都有显著提升，同时仍能在实际离线硬件上部署。这些贡献共同展示了MICA作为面向动态工厂环境的可部署、保护隐私的多智能体助理的潜力。
## 716. `cs.LG` - DiveBatch: 通过基于梯度多样性感知的批量大小自适应加速模型训练 [PDF](https://arxiv.org/pdf/2509.16173), [HTML](https://arxiv.org/abs/2509.16173)
### Authors
Yuen Chen,Yian Wang,Hari Sundaram
### Background
由于大规模深度神经网络模型的训练通常计算成本高昂，如何加速训练是一个关键挑战。传统的调参方法主要关注于学习率的调整，但本文提出了一种全新的基于梯度多样性的自适应批量大小梯度下降算法（DiveBatch）。调整批量大小具有挑战性：虽然大批量训练利用了并行计算效率较高，但小批量训练往往能在更少的迭代次数内收敛，并且泛化性能更好。
### Innovation
提出了一个基于数据驱动的梯度多样性的自适应批量大小算法DiveBatch，能够在维持小批量训练的泛化性能的同时，提高收敛速度和计算效率。梯度多样性的概念在优化理论中有坚实的理论基础。
### Conclusion
在合成数据及CiFar-10、CiFar-100和Tiny-ImageNet数据集上的评估表明，与标准SGD及AdaBatch相比，DiveBatch显著提高了训练速度（1.06-5.0倍），虽然训练性能稍有下降，但总体表现仍然出色。
## 717. `cs.LG` - 隐性学习：情景记忆通过使经验复用更具灵活性来补充参数学习 [PDF](https://arxiv.org/pdf/2509.16189), [HTML](https://arxiv.org/abs/2509.16189)
### Authors
Andrew Kyle Lampinen,Martin Engelcke,Yuxuan Li,Arslan Chaudhry,James L. McClelland
### Background
讨论了机器学习系统在泛化方面的不足，尤其是他们在处理无关信息（如未来任务可能有用的信息）时的不足，这导致了泛化的失败，如语言模型的逆向咒语以及基于代理的导航的新发现。
### Innovation
研究通过借鉴认知科学，指出情景记忆作为提高机器学习系统泛化的潜在解决方案，提出了一种具有 oracle 检索机制的系统，能够更灵活地使用学习经验，以解决泛化的多种挑战。强调内例上下文学习对于有效利用检索结果以跨多个示例使用信息的重要性。
### Conclusion
结果表明，当前机器学习系统的相对数据效率较低，难以与自然智能媲美，提出的情景记忆机制可作为参数学习的有效补充，以提升泛化能力。
## 718. `cs.LG` - 核模型验证：怎么做，为什么要关心 [PDF](https://arxiv.org/pdf/2509.15244), [HTML](https://arxiv.org/abs/2509.15244)
### Authors
Carlo Graziani,Marieme Ngom
### Background
高斯过程（GP）模型在不确定性量化（UQ）中广泛应用，因其能够提供功能不确定性估计，用于表示模型不确定性。然而，这种不确定性的确切概率解释及其校准方式往往难以明确说明，这使得这些不确定性估计的实际价值有限、仅限于主观评估。
### Innovation
本文通过描述GP预测校准失败如何导致目标优化算法（TAD）的降级收敛特性，强调了GP预测概率校准的重要性。提出了利用GP预测的多元正态性质，开发了一种核函数验证的正式程序，从而使研究人员能够更可靠地解释和信任GP生成的不确定性区间。
### Conclusion
通过正式的核函数验证程序，研究人员能够更好地理解和信任GP生成的不确定性区间，从而提高模型的准确性。此外，GP模型如果被错误指定，无论是1维还是高维模型都会产生不准确的结果。
## 719. `cs.LG` - 在LLMs中逆转特洛伊木马 [PDF](https://arxiv.org/pdf/2509.16203), [HTML](https://arxiv.org/abs/2509.16203)
### Authors
Zhengxing Li,Guangmingmei Yang,Jayaram Raghuram,David J. Miller,George Kesidis
### Background
虽然已经为诸如图像等AI开发了有效的后门检测和反转方案，但将其方法“移植”到LLMs中存在挑战。这些挑战包括：输入空间是离散的，这妨碍了基于梯度的搜索；需要考虑大约30,000的k-元组；以及对于LLMs，需要通过黑名单移除与潜在目标响应（类别）有较强关联的标记，因为这些标记会产生误检信号。然而，一些领域可能缺乏良好的黑名单。
### Innovation
文中提出了一个针对LLMs的后门触发器逆转方法，涉及三个关键组件：一）基于离散搜索，从单个标记的列表开始，贪婪地添加初步假设的触发器；二）隐式黑名单化，通过在激活空间中评估候选触发器与小规模的潜在目标类别清洁样本之间的平均余弦相似度实现；三）当候选触发器导致高错误分类并在决策置信度上异常高时进行检测。该方法不同于许多近期的研究，能够可靠地检测并成功逆转真实的后门触发短语。
### Conclusion
文中提出的方法能够有效地检测和反转LLMs中的后门触发短语，并通过避免基于梯度的搜索、引入隐式黑名单机制以及通过异常的决策置信度来识别触发器，显著提高了检测和逆转的效果。
## 720. `cs.LG` - KNARsack: 教授神经算法推理器解决伪多项式问题 [PDF](https://arxiv.org/pdf/2509.15239), [HTML](https://arxiv.org/abs/2509.15239)
### Authors
Stjepan Požgaj,Dobrik Georgiev,Marin Šilić,Petar Veličković
### Background
神经算法推理（NAR）是一个快速发展的领域，旨在通过模仿经典算法将算法逻辑嵌入神经网络中。该论文试图构建一个能够求解Knapsack问题的神经算法推理器，该问题是一个连接经典算法和组合优化的伪多项式问题，并且不在标准的NAR基准测试中。Knapsack问题在处理涉及动态规划（DP）的两阶段流程时，需要先构建动态规划表，然后从该表中重构解。
### Innovation
提出了一种新的方法，通过动态规划监督建模中间状态，该方法比直接预测基线（仅从问题输入中选择最优子集）更好地泛化到更大的问题实例。特别是，这种方法专门针对Knapsack问题进行设计，填补了现有NAR基准测试中的空白，展示了如何利用神经网络解决复杂的伪多项式问题。
### Conclusion
该研究成功地设计了一种神经算法推理器，能够有效地解决Knapsack问题。通过构建动态规划表和重构解决方案，该方法展示了神经网络在解决具有复杂算法逻辑的问题方面的潜力。这一发现为未来研究NAR在解决其他这类复杂问题的可行性提供了新的视角。
## 721. `cs.LG` - 基于深度高斯过程的意识成本批量贝叶斯优化方法在复杂材料设计中的应用 [PDF](https://arxiv.org/pdf/2509.14408), [HTML](https://arxiv.org/abs/2509.14408)
### Authors
Sk Md Ahnaf Akif Alvi,Brent Vela,Vahid Attari,Jan Janssen,Danny Perez,Douglas Allaire,Raymundo Arroyave
### Background
材料发现的加速和范围不断扩大，需要优化框架能够高效地在广阔的、非线性的设计空间中导航，并明智地分配有限的评估资源。为了应对这一挑战，需要一种同时考虑成本和效益的方法来优化材料的设计过程。
### Innovation
本文提出了一种成本意识的批量贝叶斯优化方案，该方案由深度高斯过程（DGP）代理和支持异质查询策略组成。DGP代理通过堆叠高斯过程层，不仅能够建模高维组成特征之间的复杂层次关系，还能捕捉多个目标属性之间的相关性，并将不确定性传递给后续层。该研究将评估成本整合到上置信边界获取扩展中，结合异质查询策略，可以并行提议小批量候选方案，平衡对未充分表征区域的探索与对相关属性高均值低方差预测的利用。
### Conclusion
将该框架应用于高温应用中的难熔高熵合金，结果显示成本意识的查询可以更快地收敛到最优配方，表明深度、不确定性意识、成本敏感策略在材料研究中的重要性。
## 722. `cs.LG` - 基于扩散模型训练的自动引导在线数据策展 [PDF](https://arxiv.org/pdf/2509.15267), [HTML](https://arxiv.org/abs/2509.15267)
### Authors
Valeria Pais,Luis Oala,Daniele Faccio,Marco Aversa
### Background
生成模型计算成本的上升重新点燃了高效数据策展的美好希望。本文探讨了近期开发的自引导和在线数据选择方法是否能提高生成扩散模型的训练时间和样本效率。
### Innovation
作者将联合示例选择（JEST）和自引导方法统一到一个代码库中，以快速进行消融实验和基准测试。在控制的2D合成数据生成任务和（3×64×64）D图像生成任务中评估了各种数据策展组合。
### Conclusion
自引导在整个训练过程中始终能提高样本质量和多样性。在某些情况下，只在训练初期应用的选择方法可与自引导相当或略有超出，在数据效率上的表现，但其时间开销和额外复杂性使其在大多数情况下不如自引导或均匀随机数据选择。
## 723. `cs.LG` - 评估本地LLM解决复杂编程挑战的局限性 [PDF](https://arxiv.org/pdf/2509.15283), [HTML](https://arxiv.org/abs/2509.15283)
### Authors
Kadin Matotek,Heather Cassel,Md Amiruzzaman,Linh B. Ngo
### Background
本文研究了当代开源、本地托管的大语言模型在处理具有扩展问题描述和上下文的复杂编程任务方面的能力。该研究基于原始的AI驱动代码生成评估框架（FACE），将其改造为完全离线模式，使用Ollama运行时，简化了FACE的问题目录树，并添加了可靠的检查点，使多日运行在失败后可以恢复。增强后的框架针对包括6.7-9亿参数在内的8个编码导向模型，涵盖了Kattis的3,589个问题进行了评估。
### Innovation
该研究的创新之处在于，通过改造 FACE 框架使之无需连接互联网即可运行，简化了试验流程，提升了测试的灵活性和可靠性。新增的检查点功能允许任务中断后继续进行，大大提升了测试的连续性和有效性。
### Conclusion
实验结果显示，本地模型的整体准确率较低，最佳模型的通过率仅为专有模型Gemini 1.5和ChatGPT-4的一半。这一结果揭示出私人控制、成本可控的LLM部署与最先进的专有服务之间持续存在的差距。但是也展示了开源模型快速进步的趋势，并突显了内部评估流程的实际优势。
## 724. `cs.LG` - RespoDiff: 双模块瓶颈转换以实现负责任且忠实的文本到图像生成 [PDF](https://arxiv.org/pdf/2509.15257), [HTML](https://arxiv.org/abs/2509.15257)
### Authors
Silpa Vadakkeeveetil Sreelatha,Sauradip Nag,Muhammad Awais,Serge Belongie,Anjan Dutta
### Background
扩散模型的迅速发展使得高保真度和语义丰富度的文本到图像生成成为可能；然而，确保公平性和安全性仍是一个开放性挑战。现有方法通常会在提高公平性和安全性时牺牲语义保真度和图像质量。由于这些限制，需要一种新的方法来同时确保生成的图像在忠实于原始文本内容的同时，还能保证公平性和安全性。
### Innovation
本文提出了一种名为RespoDiff的新型框架，用于负责任的文本到图像生成。该框架在扩散模型的中间瓶颈表示上引入了双模块转换。该方法包括两个不同的可学习模块：一个是专注于捕获并执行负责任的概念（如公平性和安全性），另一个是专门用于维护与中性提示语的语义对齐。为了促进双学习过程，该方法引入了一种新的分数匹配目标函数，以实现模块之间的有效协调。方法在各种未见过的提示下，可比最先进的方法提高20%的责任感和语义一致性生成，同时在优化两个目标时不会牺牲图像保真度，并能在大规模模型中无缝集成，提高公平性和安全性。
### Conclusion
我们的方法在负责生成方面优于最先进的方法，同时在优化两个目标时保持图像保真度。我们的方法在广泛的未见过的提示下将负责任和语义一致的生成提高了20%。此外，它无缝集成到如SDXL的大规模模型中，从而提高公平性和安全性。代码将在接受时发布。
## 725. `cs.LG` - 主题专业知识 vs 专业管理在集体 sequential 决策中的比较 [PDF](https://arxiv.org/pdf/2509.15263), [HTML](https://arxiv.org/abs/2509.15263)
### Authors
David Shoresh,Yonatan Loewenstein
### Background
你的公司CEO即将退休，你将在内部提拔熟悉公司运营的员工或从外部招聘职业经理人作为新的CEO。过去的争论并没有量化和客观地解决“主题专业知识 vs 专业管理”这个问题。通过使用象棋作为模型，研究了在长序列相互依赖决策中，两种不同类型管理者的绩效差异。
### Innovation
本文利用象棋游戏创建了一个受控环境来模拟管理者决策问题。研究了计算机棋手和基于强化学习的“专业管理者”的绩效。发现主题专业知识对团队协作的额外贡献有限，而基于强化学习的“专业管理者”的绩效远超任何“专家”管理者，同时仅具备有限的棋艺知识。
### Conclusion
超过基本阈值的主题专业知识并不显著提高团队效率，而基于强化学习训练的“专业管理者”在各层面上均展示了显著的性能优势，这表明尽管他们对棋艺的理解有限，也能够高效执行复杂决策任务。
## 726. `cs.LG` - 最近几年利用深度学习进行显微镜图像增强的最新进展：一个综述 [PDF](https://arxiv.org/pdf/2509.15363), [HTML](https://arxiv.org/abs/2509.15363)
### Authors
Debasish Dutta,Neeharika Sonowal,Risheraj Barauh,Deepjyoti Chetia,Sanjib Kr Kalita
### Background
显微镜图像增强对于理解生物细胞和材料在显微尺度下的详细信息起着关键作用。近年来，借助深度学习方法，显微镜图像增强技术有了显著进步，特别是在超分辨率、重构和降噪方面。
### Innovation
该论文旨在提供对这一迅速发展的最先进方法的概述，重点讨论其演变、应用、挑战和未来方向。核心讨论集中在显微镜图像增强的关键领域，包括超分辨率、重构和降噪，并分析了当前趋势及其深度学习的实际用途。
### Conclusion
该论文总结了显微镜图像增强在深度学习领域的最新进展，指出了现有挑战，并探讨了未来的研究方向。
## 727. `cs.LG` - 通过梯度下降训练热力学计算机 [PDF](https://arxiv.org/pdf/2509.15324), [HTML](https://arxiv.org/abs/2509.15324)
### Authors
Stephen Whitelam
### Background
本文讨论了如何通过梯度下降调整热力学计算机的参数以执行特定的计算任务。在此背景下，研究者在一个热力学计算机的数字模拟中，通过最大化热力学计算机生成理想的动态轨迹的概率来进行训练。理想的轨迹被设计成能够再现经过训练执行所需计算的神经网络的激活模式。
### Innovation
研究的主要创新在于提出了一种通过梯度下降来调整热力学计算机参数的方法，并通过一种类似教师-学生方案的方式，在热力学计算机中再现了神经网络的计算过程。这种方法不仅证明了梯度下降方法在热力学计算中的可行性，还领先于数字实现的能效，达到了至少七个数量级。
### Conclusion
研究结论表明，热力学计算机可以通过这种方法进行自动计算，其能效远高于传统的数字计算。这一成果为将机器学习的核心方法应用于热力学计算领域奠定了基础。
## 728. `cs.LG` - 模仿还是原创：多模式预训练与票房预测中的变量重要性 [PDF](https://arxiv.org/pdf/2509.15277), [HTML](https://arxiv.org/abs/2509.15277)
### Authors
Qin Chao,Eunsoo Kim,Boyang Li
### Background
电影行业与较高的风险相关，需要使用自动化工具来预测票房收入，以帮助人类决策。因此，该研究旨在通过结合来自电影海报的视觉信息和电影的众包描述性关键词，构建一种复杂的多模态神经网络来预测票房，以减少预测误差。
### Innovation
开发了一种先进的多模态预训练方法，并通过计算影子特征在票房预测中的影响，来分析与成功电影高度相似的“影子电影”的商业可行性。该研究发现影子电影与其相似电影的数量和内容相似性增加时，其票房收入的相关性呈递减趋势。
### Conclusion
该项工作开发了先进的深度学习工具，研究电影行业，并提供了有价值的商业洞察。结果显示影子电影的票房收入与其相似度呈正相关关系，但当相似电影数量增加及其内容相似性增大时，这种关系会减弱。
## 729. `cs.LG` - 大型语言模型进行问答任务的自然语言解释中的不确定性量化 [PDF](https://arxiv.org/pdf/2509.15403), [HTML](https://arxiv.org/abs/2509.15403)
### Authors
Yangyi Li,Mengdi Huai
### Background
大型语言模型（LLMs）展示了强大的能力，能够在问答任务中提供简洁且上下文相关的问题回答。然而，这些模型在复杂任务下的不透明性限制了它们的广泛应用。为此，研究者开发了许多解释方法，以促进对模型行为的理解。自然语言解释由于其自解释性质和在闭源模型中的可解释性而受到青睐，但仍缺乏对其解释不确定性的有效保证。特别是在疾病相关信息的不确定性量化问题上，这更加重要，因为这些信息常常对医疗决策至关重要。
### Innovation
本文提出了一种新颖的后验且模型无关的不确定性估计框架，用于对自动生成的自然语言解释提供实际的不确定性保证。此外，设计了一种鲁棒的不确定性估计方法，即使在存在噪声的情况下也能保持有效的不确定性保证。这些方法在问答任务上的实验表明了其预期的性能。
### Conclusion
本文通过提出一种新颖的不确定性估计框架和鲁棒的不确定性估计方法，在自然语言解释中提供了实际的不确定性保证，为理解和验证大型语言模型的行为提供了重要的工具。
## 730. `cs.LG` - 探究在有限语音数据下大型音频语言模型的细调以实现语音理解 [PDF](https://arxiv.org/pdf/2509.15389), [HTML](https://arxiv.org/abs/2509.15389)
### Authors
Youngwon Choi,Jaeyoon Jung,Hyeonyu Kim,Huu-Kim Nguyen,Hwayeon Kim
### Background
大型音频语言模型（LALMs）在语音相关的任务中表现出了强大的能力，但它们在有限语音数据下进行细调的应用还相对较少，尤其是在只有一部分配对的语音和标签数据的情况下。
### Innovation
该研究系统地考察了不同细调方案（如纯文本、直接混用和递进学习）对语音理解（SLU）的影响，特别关注文本标签对丰富但配对的语音标签数据有限的情况。研究发现，即使在少量添加语音数据的情况下（2-5%），LALMs的表现也能显著提升，尤其是在数据稀缺时，递进学习效果尤为显著。此外，在跨语言的SLU任务中，结合源语言的语音数据和目标语言的文本及少量目标语言语音数据可以有效适应不同语言环境。
### Conclusion
本研究为在现实数据约束条件下LALMs的细调提供了实用的见解。
## 731. `cs.LG` - MaskAttn-SDXL：可控的区域级文本到图像生成 [PDF](https://arxiv.org/pdf/2509.15357), [HTML](https://arxiv.org/abs/2509.15357)
### Authors
Yu Chang,Jiahao Chen,Anzhe Cheng,Paul Bogdan
### Background
文本到图像的扩散模型在实现高度真实感的同时，常常在涉及多个对象、属性和空间关系的提示中表现出组成失败，导致跨标记干扰，实体纠缠，属性在不同对象之间混合，以及空间线索被违反。这些失败使得生成的图像难以满足用户的特定需求。
### Innovation
提出了一种区域级门控机制MaskAttn-SDXL，应用于稳定扩散XL（SDXL）UNet中的交叉注意力分数。MaskAttn-SDXL学习每层的二值掩码，并将其注入每一层的交叉注意力得分图之前，以便在softmax之前稀疏化标记到潜在空间的交互，从而仅保留语义相关的连接。该方法不依赖位置编码、辅助标记或外部区域掩码，且不影响原始的推理路径，几乎没有额外开销。
### Conclusion
实验证明，MaskAttn-SDXL提高了多对象提示在空间合规性和属性绑定方面的表现，同时保持了整体图像质量和多样性。这些研究结果表明，logit级掩码交叉注意力是一个高效的数据工具，用于实施组成控制，所提出的方法因此成为空间控制的实用扩展，适用于文本到图像生成。
## 732. `cs.LG` - 量子自编码器的神经架构搜索算法 [PDF](https://arxiv.org/pdf/2509.15451), [HTML](https://arxiv.org/abs/2509.15451)
### Authors
Ankit Kulshrestha,Xiaoyuan Liu,Hayato Ushijima-Mwesigwa,Ilya Safro
### Background
当前的量子电路设计主要依据特定的量子算法目标进行，这要求量子算法设计者进行大量手动工作来设计合适的电路。然而，这种方法在未来无法扩展到更复杂的量子算法，因为这会导致电路设计努力呈指数级增长，并引入不必要的先入为主的偏见。这项研究指出需要通过神经架构搜索（NAS）来自动化电路设计过程，以解决这些问题并提高未来量子算法的效果和可扩展性。
### Innovation
本文提出了一种基于神经架构搜索（NAS）的自动化量子电路设计方法，分别设计了两个量子NAS算法，旨在为特定的量子任务找到高效电路。通过量子数据压缩作为驱动任务，文章展示了这些算法在量子数据去噪、经典数据压缩和纯量子数据压缩三种任务上的表现，所获得的自编码器设计优于基准方法，表明量子NAS算法可以显著减轻手工劳动并提供高效的量子电路。
### Conclusion
研究结果表明，利用神经架构搜索（NAS）方法来自动化量子电路的设计可以显著减少手动设计的努力，同时提供高性能的量子电路。未来可以通过利用神经架构搜索进一步优化量子电路的设计并扩展到更复杂的量子算法中。
## 733. `cs.LG` - 模拟人类适应性视觉以实现高效和灵活的机器视觉感知 [PDF](https://arxiv.org/pdf/2509.15333), [HTML](https://arxiv.org/abs/2509.15333)
### Authors
Yulin Wang,Yang Yue,Yang Yue,Huanqian Wang,Haojun Jiang,Yizeng Han,Zanlin Ni,Yifan Pu,Minglei Shi,Rui Lu,Qisen Yang,Andrew Zhao,Zhuofan Xia,Shiji Song,Gao Huang
### Background
人类视觉具有高度的适应性，能够高效地通过顺序关注与任务相关的区域来采样复杂的环境。相比之下，现有的机器视觉模型则是被动地一次性处理整个场景，这导致了对资源需求的无序增长，特别是随着输入分辨率和模型大小的增加。这给未来的进步和实际应用带来了关键的限制。现有的模型无法有效处理不同任务需求的资源预算，导致不精确的视觉感知。为了解决这些问题，需要开发一种更有效的、适应性强的机器视觉模型。AdaptiveNN框架旨在从传统的被动处理转变为积极、适应性的视觉处理方式，解决了现有模型的问题并提高了性能和灵活性。
### Innovation
AdaptiveNN框架提出了将视觉感知视为逐渐细化的顺序决策过程的新理论。它强调通过识别及关注任务相关的区域并逐步整合信息来实现观察的及时结束。该框架结合了表示学习与自我奖励的强化学习，可以在没有额外监督的情况下对非可微分的AdaptiveNN进行端到端训练。AdaptiveNN已经在多个基准测试上进行评估，包括大规模视觉识别、细粒度区分、视觉搜索、处理实际驾驶和医疗场景中的图像、以及语言驱动的嵌入式人工智能，并且与人类进行了对照测试。结果表明，AdaptiveNN在不影响精度的情况下将推理成本降低了最多28倍，并且能够在不重新训练的情况下灵活适应不同的任务需求和资源预算，提供了通过关注模式增强的可解释性，显示出一种有前途的方法，能够实现高效的、灵活的和可解释性计算机视觉。此外，AdaptiveNN在许多情况下展现出接近人类的行为，显示出其作为研究视觉认知工具的价值。代码已公开在：this https URL
### Conclusion
AdaptiveNN为机器视觉感知提供了一种新的非传统方法，解决了现有的被动处理问题，且在多项任务中表现出更高的效率和灵活性，为未来的视觉认知研究和实际应用开辟了新的途径。
## 734. `cs.LG` - 面向大小不变的显著对象检测：一种通用评估与优化方法 [PDF](https://arxiv.org/pdf/2509.15573), [HTML](https://arxiv.org/abs/2509.15573)
### Authors
Shilong Bao,Qianqian Xu,Feiran Li,Boyu Han,Zhiyong Yang,Xiaochun Cao,Qingming Huang
### Background
本文探讨了显著对象检测(SOD)领域未充分研究的基本问题之一：在单张图像中同时存在多个显著不同尺寸的显著对象时，现有的SOD评估标准固有的尺寸敏感性。作者通过理论推导表明，当前SOD评估标准的结果可以被分解为多个独立的独立成分之和，每个成分的贡献直接与对应区域的大小成正比。这一发现揭示了当前评估方法对大区域的预测误差占主导地位，而小但可能更具有语义重要性的物体却往往被忽视，导致评估结果存在偏见和实际性能的下降。
### Innovation
本文提出了一种通用的大小不变评估框架（SIEva），通过逐一评估每个独立的组件，然后聚合结果，以减轻不同对象之间大小不平衡的影响。在此基础上，作者还开发了一种专用于优化的方法（SIOpt），该方法遵循大小不变的原则，显著提高了不同尺寸范围内的显著对象检测能力。此外，该方法对检测模型无特定要求，可以与各种SOD主干架构无缝集成。同时，本文还对SOD方法的泛化能力进行了分析，提供了新评估协议的有效性证据。
### Conclusion
本文通过实验验证了所提出的方法的有效性，并公开了代码。所提出的方法有效地解决了显著对象检测中的尺寸不变性问题，改进了对小但语义重要的物体的检测，提高了整体性能评估的客观性和准确性。
## 735. `cs.LG` - 深度学习与抽象总结在放射学报告中的应用：在稀缺数据下Pegasus模型家族的实证研究 [PDF](https://arxiv.org/pdf/2509.15419), [HTML](https://arxiv.org/abs/2509.15419)
### Authors
Claudio Benzoni,Martina Langhals,Martin Boeker,Luise Modersohn,Máté E. Maros
### Background
尽管人工智能迅速发展，但在像医疗这样敏感和数据受限的领域，抽像总结仍然具有挑战性。随着影像资料的增多，自动化工具对于复杂医学文本摘要的需求越来越重要。在医疗领域中，使用PEGASUS和PEGASUS-X对中等规模的放射学报告公开数据集进行微调研究，探究非领域特定的抽像总结编码器-解码模型的适应性。
### Innovation
使用PEGASUS和PEGASUS-X模型，在固定大小的验证集上监控模型性能，通过词汇和语义度量在训练历史中评估模型的全面性能，发现PEGASUS在不同训练数据规模下表现出不同的阶段，而对于PEGASUS-X，使用更大模型的检查点会导致性能损失。这项工作强调了在稀缺训练数据处理过程中，基于高表达性的模型微调所带来的挑战和风险，并为未来对该领域摘要模型更为稳健的微调策略的研究奠定了基础。
### Conclusion
通过研究发现，微调具有高表现力的模型在处理稀缺训练数据时存在挑战，PegLASUS在不同训练数据规模下表现不同，而PegLASK-X在更大模型检查点下表现较差，这提示了在专门领域进行摘要模型微调时的重要性及风险，并为未来研究提供了方向。
## 736. `cs.LG` - 运动后说话中的呼吸和语义停顿检测与运动水平分类 [PDF](https://arxiv.org/pdf/2509.15473), [HTML](https://arxiv.org/abs/2509.15473)
### Authors
Yuyu Wang,Wuyue Xia,Huaxiu Yao,Jingping Nie
### Background
运动后的口语富含生理和语言线索，常见于语义停顿、呼吸停顿和结合了语义与呼吸的停顿。检测这些事件能够评估恢复速度、肺功能和运动相关异常。然而，现有工作中很少有识别和区分不同类型的停顿的方法。基于最新发布的同步音频和呼吸信号数据集，本文提供了系统化的停顿类型注释，并使用这些注释对跨深度学习模型（GRU，1D CNN-LSTM，AlexNet，VGG16）、声学特征（MFCC，MFB）和分层Wav2Vec2表示进行探索性呼吸和语义停顿检测及用力水平分类。评估了单特征、特征融合和两阶段检测-分类级联三种设置，结果涵盖分类和回归表述两种形式。
### Innovation
本文基于最新发布的同步音频和呼吸信号数据集，提供了系统化的停顿类型标注，并使用这些标注在跨深度学习模型、声学特征和分层Wav2Vec2表示上进行了探索性呼吸和语义停顿检测及用力水平分类。通过单特征、特征融合和两阶段检测-分类级联三种设置的评估，取得了显著的性能，特别是在语义停顿检测、组合停顿检测和整体准确性方面取得了89%、86%和73%的准确性，用力水平分类达到了90.5%的高准确性，超过了先前的工作。
### Conclusion
本文研究了运动后口语中的呼吸和语义停顿检测及用力水平分类，并通过实验验证了其在准确性和分类效果上的优越性，特别是在呼吸停顿、语义停顿、组合停顿及用力水平分类方面取得了竞争性的结果。
## 737. `cs.LG` - SETrLUSI: Stochastic Ensemble Multi-Source Transfer Learning Using Statistical Invariant [PDF](https://arxiv.org/pdf/2509.15593), [HTML](https://arxiv.org/abs/2509.15593)
### Authors
Chunna Li,Yiwei Song,Yuanhai Shao
### Background
在迁移学习中，源域通常携带着多样化的知识，不同的领域通常强调不同类型的知识。传统的迁移学习方法往往只处理所有领域中的单一类型的知识。
### Innovation
提出了一种以统计不变性（SI）为形式的弱收敛集成学习框架（SETrLUSI），用于多源迁移学习。该框架不仅提取并整合了源域和目标域的多种类型的知识，还通过使用随机SI选择、比例源域采样和目标域自助采样来提高训练效率和模型稳定性。
### Conclusion
实验结果表明，SETrLUSI具有良好的收敛性，并且在较低的时间成本下优于相关方法。
## 738. `cs.LG` - ORIC：大型视觉语言模型中异常语境下物体识别基准测试 [PDF](https://arxiv.org/pdf/2509.15695), [HTML](https://arxiv.org/abs/2509.15695)
### Authors
Zhaoyang Li,Zhan Ling,Yuchen Zhou,Hao Su
### Background
大型视觉语言模型（LVLMs）在图像描述、视觉问答和机器人等领域取得了显著进展，通过整合视觉和文本信息。然而，在不一致的语境中，这些模型仍然容易出现错误，如物体意外出现或在语境中不应出现但实际出现的情况。这导致了两种关键的识别失败：对象误识别和虚构物体。为了系统地研究这一问题，我们引入了Object Recognition in Incongruous Context Benchmark (ORIC)，一个新型基准，评估LVLMs在对象和语境关系偏离预期的情景下的表现。ORIC采用了两项关键策略：（1）LLM引导采样，识别出虽然存在但语境上不合理的目标；（2）CLIP引导采样，检测出虽然合理但不存在的物体，很可能被模型虚构，从而创建不一致的语境。
### Innovation
提出了Object Recognition in Incongruous Context Benchmark (ORIC)，该基准旨在评估LVLMs在不一致语境下的物体识别能力，特别引入了LLM引导采样和CLIP引导采样两种策略，能够揭示模型在处理不一致语境时的局限性。
### Conclusion
18个LVLMs和两个开放词汇检测模型的评估结果揭示了显著的识别差距，强调了语境不一致所造成的挑战。这项工作为了解LVLMs的局限性提供了关键见解，并鼓励进一步研究在语境感知的物体识别方面的问题。
## 739. `cs.LG` - (SP)²-Net: 一种用于DOA估计的空间频谱神经网络方法 [PDF](https://arxiv.org/pdf/2509.15475), [HTML](https://arxiv.org/abs/2509.15475)
### Authors
Lioz Berman,Sharon Gannot,Tom Tirer
### Background
我们考虑从天线阵列单帧数据估计多个信源的到达方向（DOA）的问题，这是一个在许多实际应用中都很常见的任务。传统的Bartlett波束形成器在这种场景中经常被使用，因为在信源数量未知或很多的情况下，最大似然估计变得不可行，基于样本协方差的谱方法也不适用，因为缺少多个快照。然而，Bartlett波束形成器的精度和分辨率从根本上受限于阵列孔径。因此，本文提出了一种深度学习技术，包括一种新的架构和训练策略，可以从单帧生成高分辨率的空间谱。具体来说，通过训练一个深度神经网络从测量值和假设角度输入中学习输出与更宽数组的特性相符的分数。
### Innovation
提出了一种深度学习方法，用于从单帧生成高分辨率的空间谱，主要包括一种新的架构和训练策略。该方法通过输入测量值和假设角度，训练一个深度神经网络，使其能够在单帧下输出与更宽阵列特性相符的评分。在推断阶段，可以通过扫描任意角度集生成热图。这种方法在有训练模型的基础上，相较于Bartlett波束形成器和基于稀疏性的DOA估计方法具有优势。
### Conclusion
本文提出的训练模型（SP)²-Net在单帧DOA估计中展现了优势，相比传统的Bartlett波束形成器和基于稀疏性的DOA估计方法，SP)²-Net能够提供更高分辨率的空间谱，从而提高DOA估计的精度和分辨率。
## 740. `cs.LG` - 几何积分用于神经控制变量 [PDF](https://arxiv.org/pdf/2509.15538), [HTML](https://arxiv.org/abs/2509.15538)
### Authors
Daniel Meister,Takahiro Harada
### Background
控制变量是一种用于减少蒙特卡洛积分方差的技术。基本原理是通过使用可以解析积分的函数来近似积分函数，并通过解析地计算近似函数和原始函数之间的残差，仅使用蒙特卡洛方法来获得无偏估计。神经网络是通用近似器，在理论上可以作为控制变量使用。然而，挑战在于大多数情况下无法解析积分。本文研究了最简单的神经网络模型——具有连续分段线性激活函数的多层感知机（MLP），并探讨了其解析积分的可能性。文章提出了基于积分区域细分的积分方法，利用计算几何的技术来解决二维情况下的问题。研究表明，可以使用我们的积分方法和MLP作为控制变量在光传输模拟应用中。
### Innovation
提出了一种基于积分区域细分的积分方法，利用计算几何的技术来解决二维情况下的问题。这一方法使得即使在无法解析积分的情况下，仍可以使用MLP作为控制变量，应用于光传输模拟。
### Conclusion
研究结果表明，使用具有连续分段线性激活函数的多层感知机作为控制变量，并结合提出的几何积分方法，可以应用于光传输模拟，在实际应用中提高了效率和准确性。
## 741. `cs.LG` - 语言模型是如何生成俚语的：基于人类和机器生成的俚语用法的系统比较 [PDF](https://arxiv.org/pdf/2509.15518), [HTML](https://arxiv.org/abs/2509.15518)
### Authors
Siyang Wu,Zhewei Sun
### Background
俚语作为一种常见的非正式语言，给自然语言处理（NLP）系统带来了巨大挑战。尽管大型语言模型（LLMs）的发展让这一问题变得更加可解，但它们在诸如俚语检测和解释等辅助任务中的广泛应用与其泛化能力和可靠性紧密相关。这些能力取决于模型是否能够准确捕捉和反映人类用法下的俚语结构知识。
### Innovation
本文贡献了一种系统的比较方法，对比了人类和机器生成的俚语用法。该方法关注三个方面：1. 表现机器在理解俚语中的系统偏见特性的用法特征；2. 通过词汇创新和词语重用展现的创造力；3. 作为模型提炼标准时所提供的信息量。通过对比来自在线俚语词典（OSD）和GPT-4o、Llama-3生成的俚语用法，发现LLMs在处理俚语时存在显著的偏见。
### Conclusion
结果表明，尽管LLMs能够捕捉到许多俚语的创造性方面，但这些知识与人类的使用方式不完全一致，不足以支持诸如语言分析这类推断任务。
## 742. `cs.LG` - 物联网/5G高级边缘计算网络的混合深度学习-联邦学习驱动的入侵检测系统 [PDF](https://arxiv.org/pdf/2509.15555), [HTML](https://arxiv.org/abs/2509.15555)
### Authors
Rasil Baidar,Sasa Maric,Robert Abbas
### Background
物联网与5G-Advanced应用的快速增长扩大了DDoS攻击、恶意软件及零日攻击的攻击面。本文分析了当前环境下，由于网络设备数量增加和攻击手段多样化导致的安全挑战。
### Innovation
提出了一种结合卷积神经网络（CNN）、双向长短期记忆网络（BiLSTM）和自动编码器（AE）瓶颈的联邦学习（FL）框架下的入侵检测系统。该系统能在不共享原始数据的情况下，在边缘设备上进行模型训练，同时通过融合这些不同的深度学习组件来增强模型对局部和跨特征交互的捕捉能力及重建异常的敏感度。
### Conclusion
实验结果表明，联合模型在UNSW-NB15数据集上的AUC达到99.59%，F1分数达到97.36%，且在实际测试硬件上的平均推理时间为0.0476毫秒，达到了低于10毫秒的URLLC预算限制，适用于边缘部署。此外，还讨论了可解释性、漂移容忍度以及联邦学习的安全合规性等问题，为5G-Advanced物联网的安全提供了解决方案。
## 743. `cs.LG` - DivLogicEval：大型语言模型中逻辑推理评估的框架 [PDF](https://arxiv.org/pdf/2509.15587), [HTML](https://arxiv.org/abs/2509.15587)
### Authors
Tsz Ting Chung,Lemao Liu,Mo Yu,Dit-Yan Yeung
### Background
自然语言中的逻辑推理被认为是评估大型语言模型（LLMs）智能水平的重要指标。现有的推理基准可能混合了多种推理技能，从而对逻辑推理技能的评估不准确。此外，现有的逻辑推理基准在语言多样性方面有限，其分布也偏离了理想逻辑推理基准的理想分布，可能会导致评估结果偏向性较强。因此，本文提出了一个新的古典逻辑推理基准——DivLogicEval，该基准通过使用多种陈述组成自然语言句子并在反直觉的方式下组合来确保评估的可靠性。
### Innovation
本文提出了一个新基准——DivLogicEval，由反直觉方式组成的多种陈述构成的自然句子组成，以确保评估的可靠性。此外，还引入了一个新的评估指标，以减轻大型语言模型中固有的偏差和随机性影响。该基准通过实验展示了在DivLogicEval回答问题时所需的逻辑推理程度，并比较了不同流行大型语言模型在进行逻辑推理方面的性能差异。
### Conclusion
通过对DivLogicEval进行实验，本文展示了逻辑推理在回答其中问题所起的关键作用，并比较了不同流行大型语言模型在进行逻辑推理时的性能差异。这表明，新的基准评估了大型语言模型的逻辑推理能力，同时去除了现有基准中的偏差，提供了更公平的评估结果。
## 744. `cs.LG` - 基于三重损失的量子编码以实现类别可分性 [PDF](https://arxiv.org/pdf/2509.15705), [HTML](https://arxiv.org/abs/2509.15705)
### Authors
Marco Mordacci,Mahul Pandey,Paolo Santini,Michele Amoretti
### Background
文中提出了一种高效且基于数据的编码方案，旨在增强变分量子分类器（VQC）的性能。该编码特别针对复杂数据集（如图像），通过生成在希尔伯特空间中根据分类标签形成良好分离的簇的输入态，来辅助分类任务。
### Innovation
编码电路使用受经典面部识别算法启发的三重损失函数进行训练，并通过编码密度矩阵之间的平均迹距离来测量分类的可分性。测试表明，该方法在MNIST和MedMNIST各种二分类任务中优于相同的VQC结构的振幅编码，且所需的量子门深度更低。
### Conclusion
该研究通过一种新的基于三重损失的量子编码方案，显著提升了VQC在复杂数据集上的分类性能，尤其是在无需大量计算资源的情况下。
## 745. `cs.LG` - 大型语言模型中通过自构建知识三元组实现概念去学习 [PDF](https://arxiv.org/pdf/2509.15621), [HTML](https://arxiv.org/abs/2509.15621)
### Authors
Tomoya Yamashita,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara,Tomoharu Iwata
### Background
近年来，机器去学习（MU）引起了广泛关注，作为解决大型语言模型（LLMs）中的隐私和版权问题的一种解决方案。现有的MU方法旨在从LLM中移除特定的目标句子，同时尽量减少对无关知识的影响。然而，这些方法需要明确的目标句子，不支持移除更广泛的概念，如人物或事件。为了解决这一限制，我们引入了概念去学习（CU）作为一个新的LLM去学习要求。通过知识图谱来表示LLM的内部知识，将CU定义为移除遗忘目标节点及其关联边。这种基于图的表述框架使去学习过程更为直观，并促进了更有效方法的设计。我们提出了一种新颖的方法，通过提示LLM生成关于遗忘目标的知识三元组及其解释性句子，并将去学习过程应用于这些表示。我们通过这种方法有效地实现了概念级别的移除，同时保留了无关的知识。
### Innovation
我们提出了Concept Unlearning（CU）作为LLM去学习的新要求，通过知识图谱表示LLM的内部知识。这种图基框架使去学习更为直观，有助于设计更有效的去学习方法。我们还提出了一种新颖的方法，通过提示LLM生成关于遗忘目标的知识三元组及其解释性句子来实施去学习过程。这种方法能够通过与LLM的内部知识表示对齐更加精确和全面地实现概念级别的移除。实验结果表明，我们的方法有效实现了概念级别的去学习，同时保留了无关的知识。
### Conclusion
我们的方法通过自构建的知识三元组有效地实现了概念级别的去学习，同时保留了无关的知识。通过这种方法，解决了现有方法仅能移除具体句子而不能处理更广泛的概念的问题。
## 746. `cs.LG` - 基于稀疏自动编码器引导的大型语言模型内部表示遗忘方法 [PDF](https://arxiv.org/pdf/2509.15631), [HTML](https://arxiv.org/abs/2509.15631)
### Authors
Tomoya Yamashita,Akira Ito,Yuuki Yamanaka,Masanori Yamada,Takayuki Miura,Toshiki Shibahara
### Background
随着大型语言模型（LLMs）在各种应用中的部署增加，隐私和版权问题加重了对更有效LLM遗忘技术的需求。现有的遗忘方法主要通过额外的训练（例如梯度上升）来抑制不希望产生的输出，从而降低生成此类输出的概率。然而，这些抑制方法可能无法完全消除模型内部激活中原有的知识；仅仅抑制回应并不等同于遗忘。同时，这些抑制方法经常导致模型崩溃。针对这些挑战，本文提出了一种新颖的遗忘方法，该方法直接干预模型的内部激活。
### Innovation
本文提出了一种基于稀疏自动编码器引导的遗忘方法，该方法通过在稀疏自编码器的潜在空间中修改目标实体的激活，使目标激活与“未知”实体的激活相似，达到遗忘目标的效果，从而使模型将其识别从“已知”转变为“未知”。这种方法避免了过度抑制和模型崩溃问题，并通过实验有效消除了遗忘目标的内部激活。
### Conclusion
本文的方法在问答任务中有效地减少了模型对目标知识的回忆，而不会显著损害非目标知识。相比之下，基于抑制的方法未能可靠地实现这一点。
## 747. `cs.LG` - 量子神经网络中单旋转和纠缠拓扑的影响 [PDF](https://arxiv.org/pdf/2509.15722), [HTML](https://arxiv.org/abs/2509.15722)
### Authors
Marco Mordacci,Michele Amoretti
### Background
本文分析了不同变分量子电路表现性能的变化，研究了它如何随着纠缠拓扑、采用的门和需要执行的量子机器学习任务的不同而变化。旨在识别构建量子神经网络的最优电路构造方式。选择了两种类型的电路进行实验，研究了旋转层的不同组合和四种不同的纠缠拓扑，探讨它们如何影响任务表现。研究了生成概率分布和图像以及图像分类等不同任务的表现，探究了电路的表达能力和纠缠能力如何影响性能。
### Innovation
研究首次全面分析了不同类型的旋转层和四种纠缠拓扑对于量子神经网络表现的影响，为构建最优量子神经网络电路提供了依据。
### Conclusion
不同类型的旋转层和纠缠拓扑对于提高量子神经网络的性能至关重要。通过综合考虑不同的元素，研究还识别出了最优的电路构造方法来提升量子神经网络的表现。
## 748. `cs.LG` - 使用粒子群优化训练变异性量子电路 [PDF](https://arxiv.org/pdf/2509.15726), [HTML](https://arxiv.org/abs/2509.15726)
### Authors
Marco Mordacci,Michele Amoretti
### Background
传统基于梯度的优化方法在训练深度量子电路时可能会遇到“荒原高原”问题。因此，研究人员开始探索替代优化技术，如粒子群优化（PSO），这是一种灵感来源于鸟类群组行为的随机优化技术。PSO能够调整群体尺寸、算法迭代次数和可训练参数的数量，因此具有灵活性和适应性。通过使用PSO训练变异性量子电路（VQCs），研究者旨在发现能够选择应用哪些量子门、目标量子位及其旋转角度的优化方法，从而提高量子计算在图像分类等任务中的表现。
### Innovation
提出了使用粒子群优化（PSO）来训练变异性量子电路（VQCs），并在MedMNIST数据集上实验验证了此方法。与使用梯度下降优化方法训练的预定义VQC相比，PSO能够使用更少的量子门实现类似的或更好的分类精度。研究指出，PSO在灵活性和优化效果上具有优势，能够有效应用于量子电路的训练过程。
### Conclusion
研究表明，PSO可以作为一个有效的替代优化方法，在多个数据集上实现与经典随机梯度下降相近甚至更好的分类准确性。尽管实验中使用的VQC中仅选择了四类量子门（Rx, Ry, Rz, CNOT），但PSO仍能表现出色，证明了其在量子电路优化中的潜力。
## 749. `cs.LG` - 可解释的网络辅助随机森林+ [PDF](https://arxiv.org/pdf/2509.15611), [HTML](https://arxiv.org/abs/2509.15611)
### Authors
Tiffany M. Tang,Elizaveta Levina,Ji Zhu
### Background
机器学习算法通常假设训练样本是独立的，但在数据点由网络连接时，样本之间的依赖关系既是一个挑战，会减少有效样本数量，又是一个机遇，通过利用网络邻近信息提高预测性能。尽管当前有多种利用这一机遇的方法，但许多方法，如图神经网络，缺乏可解释性，限制了它们在理解模型预测过程中的应用。其他方法如网络辅助线性回归虽然具有可解释性，但往往导致预测性能显著下降。因此，本文填补了这一空白，提出了一种基于随机森林扩展（RF+）的灵活的网络辅助模型家族，该模型不仅可在预测准确性上取得优异表现，还能通过特征重要性度量提高解释性。该方法不仅能够识别驱动模型预测的重要特征，还能量化网络贡献对预测的重要性。此外，本文提供了全局和局部重要性度量以及样本影响度量，以评估特定观测的影响，并扩大了网络辅助机器学习在高度影响问题中的应用范围，特别是在需要解释性和透明度的场景中尤为重要。
### Innovation
本文提出了一种基于随机森林扩展（RF+）的网络辅助模型家族，不仅在预测准确性上取得高度竞争力，还能通过特征重要性度量提高解释性。具体创新包括开发了一套解释工具，不仅能够识别驱动模型预测的重要特征，还能量化网络贡献对预测的重要性。此外，该方法提供了全球和局部重要性度量以及样本影响度量，以评估特定观测的影响。
### Conclusion
本文提出的方法在保持高预测准确性的同时，针对网络数据提供了良好的解释性，填补了网络辅助机器学习中的可解释性空白。通过提供全球和局部重要性度量以及样本影响度量，本文的方法扩展了网络辅助机器学习在高影响问题中的应用，特别是在需要解释性和透明度的场景中尤为重要。
## 750. `cs.LG` - UPRPRC: 统一的平行资源再现流水线——来自联合国的语料库 [PDF](https://arxiv.org/pdf/2509.15789), [HTML](https://arxiv.org/abs/2509.15789)
### Authors
Qiuyang Lu,Fangjian Shen,Zhengkai Tang,Qiang Liu,Hexuan Cheng,Hui Liu,Wushao Wen
### Background
多语言数据集的质量和可访问性对于机器翻译的进步至关重要。然而，之前从联合国文件中构建的语料库存在透明度不足、难以复制和规模有限等问题。
### Innovation
本文提出了一种完整的端到端解决方案，涵盖从网页抓取数据到文本对齐的全过程，并提供了一个完备的可再现性实例。文中核心创新在于提出了一种新的基于图辅助段落对齐算法（GAPA），用于高效灵活的段落级别对齐。与之前的语料库相比，此语料库包含超过7亿个英语单词，规模翻了一倍。
### Conclusion
本研究提供了最大的完全由人工翻译而非AI生成内容组成的公共平行语料库，并且所有代码和语料库都采用MIT许可证开源。
## 751. `cs.LG` - 一种基于卷积神经网络的保持流量守恒的区域分解方法用于血液流动模拟 [PDF](https://arxiv.org/pdf/2509.15900), [HTML](https://arxiv.org/abs/2509.15900)
### Authors
Simon Klaes,Axel Klawonn,Natalie Kubicki,Martin Lanser,Kengo Nakajima,Takashi Shimokawabe,Janine Weber
### Background
该研究着眼于使用非牛顿粘度预测狭窄动脉中的血液流动，并提出了一种交替施瓦尔茨区域分解方法，该方法使用基于卷积神经网络（CNN）的子域求解器。在不同的流入条件和不同形状及长度的二维狭窄动脉中，这种方法进行了数值实验和统计评估。
### Innovation
提出了一种保持流量守恒的CNN基领域分解方法，这种方法包括使用基于CNN的子域求解器并且训练通用子域求解器（USDS），它可以在固定几何形状上进行训练，然后应用于施瓦尔茨方法中的每个子域求解过程。这项研究的一个重要发现是在使用有限的训练数据时，需要实施一个USDS，该算法能够保留一些物理学特征，如我们的情况下的流量守恒。基于物理的USDS相比于纯数据驱动的USDS表现出更好的性能。
### Conclusion
当在施瓦茨迭代中应用USDS时，基于物理的方法提供了更好的子域解决方案，避免了对全球解的过度或不足修正，从而提高了收敛稳定性。
## 752. `cs.LG` - DeepMech: 化学反应机制预测的机器学习框架 [PDF](https://arxiv.org/pdf/2509.15872), [HTML](https://arxiv.org/abs/2509.15872)
### Authors
Manajit Das,Ajnabiul Hoque,Mayank Baranwal,Raghavan B. Sunoj
### Background
预测完整的反应步骤化学反应机制 (CRMs) 仍然是一个主要的挑战。传统的CRM任务方法依赖于专家驱动的实验或昂贵的量子化学计算，而现代深度学习方法则忽略了关键中间体和机制步骤，并且常出现幻觉现象。
### Innovation
我们介绍了DeepMech，这是一种基于图的可解释深度学习框架，采用原子和化学键级别的注意力，并由通用的机制操作模板 (TMOps) 导航生成CRMs。该模型在我们整理的ReactMech数据集 (~30K CRMs 和 100K 原子配对和质量平衡的初级步骤) 上进行训练，实现了在预测初级步骤方面高达98.98±0.12% 的准确率和在完整CRM任务上高达95.94±0.21% 的准确率。此外，在处理分布外和预测副产品或副产品的场景中也保持了高保真度。此外，DeepMech还能够有效的重构从简单的原始前生物物质到复杂生物分子如丝氨酸和醛酮糖的路径。注意力分析识别了与化学直觉一致的活性原子/键，使得模型具有可解释性，适用于反应设计。
### Conclusion
DeepMech框架在预测各种化学反应机制时展示了卓越的性能，并且还能够在预测复杂生物分子合成路径时展现出强大的鲁棒性和可解释性。
## 753. `cs.LG` - 在电子商务中使用多模态嵌入优化商品去重 [PDF](https://arxiv.org/pdf/2509.15858), [HTML](https://arxiv.org/abs/2509.15858)
### Authors
Aysenur Kulunk,Berk Taskin,M. Furkan Eseoglu,H. Bahadir Sahin
### Background
在大规模的电子商务市场中，重复商品列表频繁造成消费者的困惑和操作上的低效率，降低了平台的信任度并增加了成本。传统的基于关键词的搜索方法依赖于精确的文本匹配，忽视了产品标题中的语义相似性，导致无法准确识别重复商品。为了解决这些问题，我们提出了一种适用于电子商务领域的可扩展的多模态商品去重方法。这种方法结合使用了基于BERT架构的领域特定文本模型和MaskedAutoEncoders的图像表示模型，两者都增加了降维技术以生成较小且信息损失较少的128维嵌入。通过这种方式，我们还开发了一种新的决策模型，该模型利用了文本和图像向量。将这些特征提取机制与优化的向量数据库Milvus结合，我们的系统可以在超过2亿个商品的目录中实现高效的和高精度的相似性搜索，仅使用100GB的系统RAM。实验证明我们的匹配系统在宏平均F1分数上达到0.90，远高于第三方解决方案0.83的F1分数。
### Innovation
我们提出了一种结合了领域特定适应和最先进的机器学习技术的多模态嵌入方法，用于解决电子商务中大规模的商品重复问题。通过使用基于BERT架构的领域特定文本模型和MaskedAutoEncoders的图像表示模型，结合降维技术，我们的方法能够在大规模商品库中实现高效的相似性搜索，同时保持高的精度和较低的系统资源要求。此外，我们还开发了一种新的决策模型，能够利用文本和图像向量来做出去重决策。
### Conclusion
我们的方法在大规模电子商务环境下具有潜力，可以有效减轻商品重复列表的问题，通过实验证明该方法在宏平均F1分数上显著优于现有第三方解决方案。
## 754. `cs.LG` - VoXtream：具有极低延迟的全流文本到语音 [PDF](https://arxiv.org/pdf/2509.15969), [HTML](https://arxiv.org/abs/2509.15969)
### Authors
Nikita Torgashov,Gustav Eje Henter,Gabriel Skantze
### Background
目前存在一些流式文本到语音（TTS）系统，但它们往往具有较高的初始延迟。VoXtream系统旨在解决这一问题，实现从第一个词开始立即发音，同时保持高质量和可竞争的性能。
### Innovation
VoXtream是一种全自动关联、零样本的流式TTS系统，直接将传入的音素映射为音频标记，使用单调对齐方案和动态前瞻机制，不延迟起始。该系统由增量音素变换器、时间变换器和深度变换器组成，能够实现较低的初始延迟，并且在多个指标上达到或超过了较大的基线模型，同时在输出流式和全流式设置下提供具有竞争力的质量。
### Conclusion
VoXtream实现了目前已知最低的GPU初始延迟为102毫秒，并且在多个评估指标上匹配或超过了大型基线模型，同时提供了具有竞争力的输出质量和实时使用时的表现。
## 755. `cs.LG` - Stochastic Block Model 中超过√n个社区的相变现象 [PDF](https://arxiv.org/pdf/2509.15822), [HTML](https://arxiv.org/abs/2509.15822)
### Authors
Alexandra Carpentier,Christophe Giraud,Nicolas Verzelen
### Background
统计物理的预测表明，在Kesten-Stigum (KS)阈值以上，随机块模型的社区恢复可以在多项式时间内完成。这一猜想已经引发了丰富的相关文献，证明了在KS阈值之上，当社区数量$K$小于$frac{text{节点数}n}{text{平方根}}$时，可以实现非平凡的社区恢复。此外还证明了当$K$远小于$frac{n}{text{平方根}}$时，低阶多项式在KS阈值以下会失败。当$K text{大于等于} frac{n}{text{平方根}}$时，Chin等人在稀疏条件下最近证明了即使在KS阈值以下也可以在多项式时间内恢复社区。这促使他们提出了一个新的关于多社区区间的阈值假设。本研究旨在验证他们的这一假设，为超过$frac{n}{text{平方根}}$个社区的随机块模型提供新的证据，证明低阶多项式在新提出的阈值以下无法实现社区恢复，并证明在某些但不是所有适度稀疏的条件下，可以在新提出的阈值以上实现多项式时间内的社区恢复，通过统计图中出现的团的次数来实现。
### Innovation
本研究验证了在超过$frac{n}{text{平方根}}$个社区的随机块模型中低阶多项式在新的阈值以下无法实现社区恢复。进一步证实了Chin等人提出的关于多社区区间的阈值假设，并展示了在某些条件下的适度稀疏情况下，可以在该阈值以上实现多项式时间内的社区恢复，而这种恢复可以通过统计观察图中的团的出现次数来实现。
### Conclusion
在超过$frac{n}{text{平方根}}$个社区的随机块模型中，通过证明低阶多项式在新提出的阈值以下无法实现社区恢复，以及在某些适度稀疏条件下可以在新提出的阈值以上实现多项式时间内的社区恢复，为现有的理论提供了进一步的支持，这有助于理解社区恢复在多社区条件下的边界性。
## 756. `cs.LG` - 使用混合深度学习的ADS-B数据量子增强异常检测 [PDF](https://arxiv.org/pdf/2509.15991), [HTML](https://arxiv.org/abs/2509.15991)
### Authors
Rani Naaman,Felipe Gohring de Magalhaes,Jean-Yves Ouattara,Gabriela Nicolescu
### Background
量子机器学习（QML）在加速数据处理速度和有效处理高维度复杂数据集方面显示了有前景的优势。量子计算（QC）通过利用量子特性的叠加和纠缠，实现更高效的数据操作。本文探讨了结合量子和经典机器学习技术，利用量子特性对ADS-B数据进行异常检测。
### Innovation
提出了一种新颖的混合全连接量子神经网络（H-FQNN）结合不同损失函数的混合深度学习方法，用于ADS-B数据的异常检测。
### Conclusion
研究表明，利用H-FQNN结合不同损失函数的方法在检测异常方面具有竞争力，准确率范围为90.17%至94.05%，与传统全连接神经网络（FNN）模型的性能相当，准确率范围为91.50%至93.37%。
## 757. `cs.LG` - 局部最大值动力学在变压器中的注意机制及其渐近行为 [PDF](https://arxiv.org/pdf/2509.15958), [HTML](https://arxiv.org/abs/2509.15958)
### Authors
Henri Cimetière,Maria Teresa Chiri,Bahman Gharesifard
### Background
该研究引入了一种新的离散时间注意力模型，称为局部最大值动力学（Localmax 动力学），这种模型介于经典的 softmax 动力学和硬最大值（hardmax）动力学之间。局部最大值动力学中，只有对给定目标影响最大的词元才具有正权重。类似于硬最大值，统一权重由控制邻域影响的参数确定，但关键的扩展在于通过一个对齐敏感度参数放松了邻域之间的相互作用，使得可以从纯硬最大值行为中获得控制偏离。
### Innovation
该研究提出了一种新颖的局部最大值动力学模型，能够在其与经典的 softmax 和硬最大值模型之间进行平滑过渡。通过引入对齐敏感度参数，控制了邻域之间交互的松弛程度，使得可以逐步偏离纯硬最大值行为模式。此外，该研究发现局部最大值动力学系统的凸包结构会收敛到一个凸多边形，但不能完全由最大对齐集描述，为此引入了静默集的概念来捕捉接近顶点的词元的不变行为。研究还提供了该动态模型在不同对齐敏感度参数下的渐近行为分析，包括消逝、非零、时间变化的对齐敏感度参数情况。
### Conclusion
该研究证明局部最大值动力学模型不具有有限时间收敛性，并提供了在各种对齐敏感度参数下的渐近行为结果，这些结果能够恢复硬最大值模型的有限时间收敛行为。此外，研究采用基于Lyapunov的方法研究了经典意见动力学模型中的局限性，针对局部最大值交互提出了未来研究的方向。
## 758. `cs.LG` - 3D医疗物体检测中的缺失环节：预训练的重要性 [PDF](https://arxiv.org/pdf/2509.15947), [HTML](https://arxiv.org/abs/2509.15947)
### Authors
Katharina Eckstein,Constantin Ulrich,Michael Baumgartner,Jessica Kächele,Dimitrios Bounias,Tassilo Wald,Ralf Floca,Klaus H. Maier-Hein
### Background
大规模预训练有望推动3D医疗物体检测的发展，这是准确计算机辅助诊断的关键组成部分。然而，与已被证明可以显著提高分割任务性能的预训练相比，3D物体检测的预训练仍然被未充分探索。目前，对于3D物体检测的预训练方法主要依赖于2D医学图像或自然图像预训练，未能充分利用3D体积信息。
### Innovation
本研究首次系统地探讨了如何将现有的预训练方法集成到最先进的检测架构中，涵盖了CNN和Transformer。研究结果显示，预训练在各种任务和数据集上都提高了检测性能。其中，基于重建的自我监督预训练优于监督预训练，对比预训练对于3D医疗物体检测并无明显优势。
### Conclusion
通过预训练，检测性能得到了提升。基于重建的自我监督预训练方法优于传统方法，而对比预训练方法在3D医疗物体检测中并未显示出优势作用。代码已公开。
## 759. `cs.LG` - 自行组合：平均速度流匹配的一步语音增强 [PDF](https://arxiv.org/pdf/2509.15952), [HTML](https://arxiv.org/abs/2509.15952)
### Authors
Gang Yang,Yue Lei,Wenxin Tai,Jin Wu,Jia Chen,Ting Zhong,Fan Zhou
### Background
扩散和流动匹配（FM）模型在语音增强（SE）方面取得了显著进展，但其多步骤生成依赖性导致计算成本高昂并且容易受到离散化误差的影响。最近，一步生成模型（尤其是MeanFlow）通过重构动力学来提供一种前景模型，通过平均速度场来简化计算过程。
### Innovation
本文提出了COSE（一种为语音增强设计的一步流匹配框架）。为了解决在MeanFlow中计算雅可比-向量积（JVP）时的高训练开销问题，引入了速度组合恒等式来高效计算平均速度，从而降低了计算成本，同时保持理论上的连续性和实现竞争力的增强效果。
### Conclusion
广泛的实验表明，COSE提供高达5倍的采样速度并降低40%的训练成本，同时不牺牲语音质量。代码可在提供。
## 760. `cs.LG` - 什么是概率测度的好匹配？从因果推理的角度来看传输映射 [PDF](https://arxiv.org/pdf/2509.16027), [HTML](https://arxiv.org/abs/2509.16027)
### Authors
Lucas De Lara,Luca Ganassali
### Background
概率测度的耦合是统计和机器学习中许多问题的核心，包括领域适应、迁移学习和因果推理。尽管当限制在确定性传输时，这样的耦合是不可识别的（两个无原子边缘有无限多个传输映射），但最优传输方法通常被用来讨论这种问题，因为它基于成本最小化和循环单调性。然而，这实际上模糊了存在多种不同的多元单调匹配概念的事实。
### Innovation
本文进行了三种传输映射构造的比较分析：循环单调性、分位数保留性和三角单调映射，并建立了它们等价的必要和充分条件，从而澄清了它们各自的结构特性。同时，将反事实推理置于结构因果模型框架中，视为在固定边缘之间选择传输映射的问题，明确了不可测试假设在反事实推理中的作用。通过识别因果图和结构方程的条件，使其映射与经典的统计传输一致，从而确定因果假设支持特定传输映射结构使用的条件。
### Conclusion
本研究旨在丰富传输映射家族的理论理解，并澄清其可能的因果解释。希望通过这项工作建立统计运输和因果推理之间的新桥梁，从而为这些领域提供新的见解和技术工具。
## 761. `cs.LG` - 超越分数：面向自动化作文评估的不确定性校准大型语言模型 [PDF](https://arxiv.org/pdf/2509.15926), [HTML](https://arxiv.org/abs/2509.15926)
### Authors
Ahmed Karim,Qiao Wang(Judy),Zheng Yuan
### Background
自动作文评分（AES）系统在某些公开基准上已经达到了接近人类的一致性评分，但在实际应用中，特别是在高风险考试中，其采用依然有限。主要障碍是大多数模型仅输出单一分数而没有附带的信心度量或解释。为此，该研究使用了无分布约束的包络法——即校准预测法，这种方法能够为任何分类器提供集合输出及其形式上的覆盖率保证，从而弥补了上述不足。该方法采用两个开源大模型（Llama-3 8B和Qwen-2.5 3B）分别在三个不同的语料库（ASAP，TOEFL11，剑桥-FCE）上进行微调，并以90%的风险水平进行校准。通过不确定性意识准确度（UAcc）进行可靠性的评估，UAcc奖励模型同时准确且简洁的特性。据我们所知，这是首次结合校准预测法和UAcc进行作文评分的研究工作。
### Innovation
该研究引入了校准预测法结合不确定性意识准确度（UAcc）的创新方法，为开源中型大模型提供赋能，使其能支持教师在场的评分过程；它们能够一致地达到覆盖率目标，同时保持预测集的紧凑性，表明开源、中型规模的大语言模型已能够支持教师在场的自动作文评分。未来的工作将探讨这种模型的扩展和更广泛的用户研究。
### Conclusion
该研究表明，开源、中型规模的大语言模型已经能够支持教师在场的自动作文评分过程，并且通过结合校准预测和不确定性意识准确度的方法，能够在保持覆盖率的同时提高评分的准确性和简洁性。未来的研究将继续探索这些模型的扩展和更广泛的用户研究，以进一步提高自动作文评分系统在实际应用中的可用性和效果。
## 762. `cs.LG` - BEFT:语言模型偏置高效的微调 [PDF](https://arxiv.org/pdf/2509.15974), [HTML](https://arxiv.org/abs/2509.15974)
### Authors
Baichuan Huang,Ananth Balashankar,Amir Aminifar
### Background
在参数高效微调（PEFT）技术中，微调所有偏置项的表现最为出色，特别是对于数据量较小的情况。然而，微调不同偏置项（如查询、键或值投影中的偏置项）与下游性能之间的关系依然模糊，虽然一些现有方法提供了有限的指导，但选择有效微调特定偏置项仍然具有挑战性。这篇文章介绍了一种选择要微调的偏置项的方法，以此作为偏置高效微调（BEFT）的基础，该方法广泛评估了各种大型语言模型的各种偏置选择方法，包括从110M到6.7B参数的编码器和解码器架构模型。评估结果显示，该方法在各种下游任务中的有效性和优越性.
### Innovation
本文提出了一种选择要微调的偏置项的方法，形成了偏置高效微调（BEFT）的基础。该方法用于多种大型语言模型，从110M到6.7B参数的编码器和解码器架构模型，并进行了广泛评估。同时，首次建立了偏置项与下游性能之间的关系，并提供了可能达到前所未有的参数效率的微调策略的选择指导.
### Conclusion
我们的结果表明，偏置高效的微调方法在各种下游任务中表现出色，并且在有效性方面优于其他偏置选择方法。此外，微调不同偏置项的选择还能够更好地指导后续训练，提高最终任务性能。
## 763. `cs.LG` - 基于SBM类型图的无模型节点聚类快速算法及其在动物社会角色推断的应用 [PDF](https://arxiv.org/pdf/2509.15989), [HTML](https://arxiv.org/abs/2509.15989)
### Authors
Bertrand Cloez,Adrien Cotil,Jean-Baptiste Menassol,Nicolas Verzelen
### Background
该论文研究了使用Stochastic Block Model (SBM)生成的图中节点聚类和参数推断问题。SBM是社区检测的基本框架之一，该领域已经有大量研究工作。然而，尽管存在针对具体问题的优化算法，但尚未有针对SBM图的一种通用且高效的无模型聚类方法。论文的目标是填补这一空白，提出一种新的基于Lloyd算法的聚类方法，适用于SBM图中的节点聚类和参数估计问题，并通过实证数据验证其有效性。
### Innovation
论文的主要创新点在于提出了一种新的无模型算法家族，这一方法借鉴了$k$-means问题中的Lloyd算法，并将其扩展到具有通用边权重分布的SBMs。这种方法的创新之处在于它能够在SBM框架下提供快速且准确的节点聚类和参数估计。此外，文章还通过数值实验证明了新方法比现有最先进的技术在计算效率上有明显提高，并且具有较低的估计误差。
### Conclusion
论文最后通过对行为生态学中的实际网络数据的应用，验证了新算法在社交角色推断方面的实用性。研究结果表明，尽管新算法的估计误差较低，但其计算速度更快，这表明了其在实际应用中的巨大潜力。
## 764. `cs.LG` - 量子电路复用与Grover搜索轨迹优化的强化学习 [PDF](https://arxiv.org/pdf/2509.16002), [HTML](https://arxiv.org/abs/2509.16002)
### Authors
Thet Htar Su,Shaswot Shresthamali,Masaaki Kondo
### Background
本文开发了一种全量子强化学习框架，该框架集成了量子马尔可夫决策过程、动态电路基的量子比特再利用以及Grover算法进行轨迹优化，实现了完全基于量子领域的状态、动作、奖励和转换编码，并通过叠加实现并行探索状态-动作序列。该研究改进了传统设计以减少量子比特的使用，同时保逻辑连续性。通过动态电路操作，包括中间测量和复位，允许在多次代理-环境交互中复用同一物理量子比特，减少所需量子比特数量，同时保持逻辑连续性。本文通过仿真实验验证了该方法的可行性和在噪声环境下的性能。
### Innovation
该研究创新点在于开发了一种全量子强化学习框架，通过结合量子马尔可夫决策过程、动态电路基的量子比特再利用和Grover算法进行了轨迹优化，这种方法不仅实现了状态、动作、奖励和转換的完全量子编码，还在多次交互中复用量子比特减少了所需量子比特的数量，保持了逻辑连续性。利用逆位格搜索来加速最优政策的识别过程，同时通过实验验证了其在噪声环境下的有效性和可行性。
### Conclusion
该框架不仅展示了对大规模序列决策问题的层次扩展能力，同时验证了在当前量子处理器条件下，全量子多步强化学习的可行性。进一步展示了在含噪声条件下的量子强化学习的实际应用潜力。
## 765. `cs.LG` - PRISM：盲逆问题中基于测量条件扩散先验的概率鲁棒逆解算器 [PDF](https://arxiv.org/pdf/2509.16106), [HTML](https://arxiv.org/abs/2509.16106)
### Authors
Yuanyun Hu,Evan Bell,Guijin Wang,Yu Sun
### Background
迄今为止，扩散模型在计算成像中的逆问题求解中得到了广泛的应用。然而，大部分基于扩散的逆解算器需要完全了解正向操作器才能使用。本文基于这一背景讨论了一个新的概率和鲁棒性逆解算器（PRISM），它能够有效解决盲逆问题，并且普适性更强，不需要详细了解正向操作器。实验结果还证明在盲图像去模糊中的有效性，PRISM在图像和模糊内核恢复方面优于现有最先进的基线方法。
### Innovation
该创新方法在于提出了一种基于测量条件扩散先验的理论原理后的后验采样方案，PRISM方法通过结合强大的测量条件扩散模型，提供了相对于现有方法的技术进步。它能够有效地解决盲逆问题，增强了逆解算器的鲁棒性和通用性，而不需要完全理解正向操作器。
### Conclusion
PRISM方法在盲图像和模糊内核恢复上表现出了优异性能，显著优于当前最先进的基准方法。实验结果强调了其有效性和鲁棒性。该方法提供了一种有效解决盲逆问题的新途径，具有广泛的应用前景。
## 766. `cs.LG` - AI方法在通用拓扑结构中合成排列电路 [PDF](https://arxiv.org/pdf/2509.16020), [HTML](https://arxiv.org/abs/2509.16020)
### Authors
Victor Villar,Juan Cruz-Benito,Ismael Faro,David Kremer
### Background
本文研究了使用人工智能（AI）方法在普遍拓扑结构中合成和转换排列电路。研究背景在于对排列电路进行最佳合成旨在提高量子计算的效率与性能。传统的合成方法通常需要针对每个特定拓扑结构进行专门模型的训练，这限制了合成方法的通用性和灵活性。本文则提出了一种使用强化学习（RL）的技术，以接近最优的方式合成多达25个量子比特（qubits）的排列电路。
### Innovation
本文创新之处在于不为每个特定拓扑结构单独开发模型，而是训练一个通用的矩形格子模型，通过掩码机制动态选择适合合成的子拓扑结构。该方法使得在矩形格子内嵌入的任何拓扑结构都可以直接部署，而无需重新训练模型。进一步地，模型可以通过微调来增强对特定拓扑结构的兴趣性能。这种方法使得单一训练的模型能够高效合成多种拓扑结构下的电路，为排错工作流程提供了实际应用价值。
### Conclusion
本文展示了5x5网格的结果，并与之前专为特定拓扑结构设计的AI模型和经典方法进行对比，证明了本文方法优于经典启发式方法，并达到甚至超过了之前专门的AI模型。方法还能够在未在训练时见过的拓扑结构上执行合成。此外，该方法为选定的拓扑结构提供了性能强化功能。这些结果表明，该人工智能方法可以有效地应用于多种多样的拓扑结构合成中。
## 767. `cs.LG` - 当漏洞持续存在：异常解决时间离群值及其主题的研究 [PDF](https://arxiv.org/pdf/2509.16140), [HTML](https://arxiv.org/abs/2509.16140)
### Authors
Avinash Patil
### Background
高效的漏洞解决对于维护软件质量和用户满意度至关重要。然而，特定的漏洞报告经历了不合理的长时间解决时间，这可能表明了流程效率低下或复杂的问题。本研究对七大知名开源项目的漏洞解决异常进行了全面分析：Cassandra, Firefox, Hadoop, HBase, SeaMonkey, Spark 和 Thunderbird。利用统计方法（如 Z 分数和四分位距 IQR）识别了解决持续时间的异常情况。
### Innovation
研究采用了 Term Frequency-Inverse Document Frequency (TF-IDF) 进行文本特征提取，并使用 KMeans 聚类对具有相似摘要的漏洞进行分组。研究发现，异常模式在各个项目中呈现一致，主要集中在测试失败、增强请求和界面问题上。这种方法提供了关于项目经理优先处理和有效解决长期存在的漏洞的具体洞察。
### Conclusion
研究揭示了异常漏洞解决时间的一致模式，并提供了关于优先处理长期存在的漏洞的实际建议。这对于软件维护者理解漏洞解决过程中的瓶颈和复杂性具有重要意义。
## 768. `cs.LG` - 通过图强化学习加速原子精细结构确定 [PDF](https://arxiv.org/pdf/2509.16184), [HTML](https://arxiv.org/abs/2509.16184)
### Authors
M. Ding,V.-A. Darvariu,A. N. Ryabtsev,N. Hawes,J. C. Pickering
### Background
原子数据是等离子体诊断中必不可少的组成部分。通过分析观测到的原子光谱，可以确定涉及开放d-和f-子壳层的低离子态原子物种的约1000个精细结构能级。然而，这个任务需要多年的研究和成千上万的可观察谱线分析来确定这些能级。
### Innovation
本文提出了一种自动化的方法，将分析过程转化为马尔科夫决策过程，并通过图强化学习来解决，使用从历史人工决策中学习到的奖励函数。这种方法在对Co II和Nd II-III的现有谱线列表及理论计算的评估中，可在数小时内计算数百个能级，且95%的Co II能级与已发表的值相符，对于Nd II-III则是54-87%。
### Conclusion
随着天文学和聚变科学中对原子精细结构数据需求的增长，当前的效率难以满足，本文提出的人工智能方法为解决这一缺口奠定了基础。
## 769. `cs.LG` - 通过Scheffé图实现高效局部隐私假设选择 [PDF](https://arxiv.org/pdf/2509.16180), [HTML](https://arxiv.org/abs/2509.16180)
### Authors
Gautam Kamath,Alireza F. Pour,Matthew Regehr,David P. Woodruff
### Background
在局部差分隐私约束下选择假设的问题中，传统的算法需要进行$tilde{O}(k^2)$次查询或多次交互查询。该研究提出了一种改进查询复杂性的算法，能够在非适应性查询中进行$tilde{O}(k^{3/2})$次查询，并输出与给定分布最接近的假设。
### Innovation
研究引入了一种新型的对象——Scheffé图，用于捕捉集合$Q$中分布之间的结构差异。这种在假设选择任务中可能更具广泛兴趣的新对象促进了算法的提出。
### Conclusion
该算法能够在满足局部差分隐私的同时，显著减少查询次数，并且能够输出与给定分布最接近的假设中的一个，为局部差分隐私下的假设选择提供了更高效的方法。
## 770. `cs.LG` - 基于注意力方案的注意力控制（ASAC）:一种Transformer中注意力管理的认知启发性方法 [PDF](https://arxiv.org/pdf/2509.16058), [HTML](https://arxiv.org/abs/2509.16058)
### Authors
Krati Saxena,Federico Jurado Ruiz,Guido Manzi,Dianbo Liu,Alex Lamb
### Background
注意力机制已成为人工智能的核心组件，极大地提升了模型的性能和可扩展性，通过对人的认知过程进行模拟。与此同时，认知科学中的注意力方案理论提出，个体通过创建对注意力本身的模型来管理注意力，有效分配认知资源。受到这一理论的启发，本文引入了一种名为ASAC的注意力控制机制，将注意力方案的概念集成到了人工神经网络中。
### Innovation
ASAC通过引入基于注意力方案的概念，构建了一个模块，该模块利用向量量化变分自编码器（VQVAE）作为注意力抽象器和控制器，以此来实现精确的注意力管理。通过显式地建模注意力分配，该方法旨在提高系统的效率。实验表明，ASAC在视觉和自然语言处理领域均能提升分类精度并加速学习过程。同时，模型在多种场景下的稳健性和泛化能力得到验证，并在对抗攻击下表现出色，对学习效率进行优化，促进有效的迁移学习。
### Conclusion
本文的工作展示了认知科学与机器学习之间的联系，阐明了如何在AI系统中高效地利用注意力机制。ASAC不仅在视觉和自然语言处理任务中表现出优越性能，还提高了模型对噪声和分布外数据集的鲁棒性和泛化能力。通过注意力方案模块，ASAC增强了对对抗攻击的抵抗能力，同时提高学习效率，并促进了有效的迁移学习和少样本学习。这些积极的结果强调了认知启发的方法在现代机器学习领域中的重要性。
## 771. `cs.LG` - 机器学习应用中超拟合的协商表示 [PDF](https://arxiv.org/pdf/2311.11410), [HTML](https://arxiv.org/abs/2311.11410)
### Authors
Nuri Korhan,Samet Bayram
### Background
超拟合是指当机器学习模型训练时间过长，过于关注训练样本与提供的标签之间的精确契合度，而不是关注能够用于测试数据的预测规则的现象。这种情况通常归因于模型记忆特定样本、记忆噪声以及在样本数量有限的数据集中使用大量神经元强行拟合数据集。虽然在训练过程中模型确实会编码各种独特性，但本文认为大多数的超拟合现象发生在明确成员比率的协调过程中。
### Innovation
本文提出了一种方法，通过让模型与先前确定的类标签协商样本的输出表示，来提高机器学习模型的分类准确性。通过在输入解释和提供的标签之间设置协商，不仅提高了平均分类准确性，还减少了超拟合的频率，而无需使用其他正则化技巧。通过在公开数据集（如CIFAR 10、CIFAR 100和MNIST）上生成超拟合场景，并应用于低规模机器学习问题，证明了提出的范式具有超越其原计划的能力。作者还通过上传实验设置的Python代码并邀请机器学习社区进一步探索该范式，激发社区在其他领域如持续学习的研究中探索该范式的潜力。
### Conclusion
通过实验结果的分享和对社区的邀请，本文旨在激励社区探索协商范式以克服学习相关挑战。该范式不仅适用于超拟合的预防，还在持续学习等领域的应用中展现出潜力。
## 772. `cs.LG` - 通过稀疏和对齐自适应优化实现通信高效联邦学习 [PDF](https://arxiv.org/pdf/2405.17932), [HTML](https://arxiv.org/abs/2405.17932)
### Authors
Xiumei Deng,Jun Li,Kang Wei,Long Shi,Zehui Xiong,Ming Ding,Wen Chen,Shi Jin,H. Vincent Poor
### Background
自适应矩估计（Adam）作为随机梯度下降（SGD）的一种变种，在联邦学习（FL）中由于其快速收敛性而广受欢迎。然而，联邦Adam（FedAdam）算法相比于联邦SGD（FedSGD）算法，上行通信开销增加了三倍，这是由于需要传输本地模型更新以及来自分布式设备的第一和第二阶动量估计到中央服务器进行聚合。
### Innovation
提出了一种新的稀疏FedAdam算法——FedAdam-SSM，该算法通过分布式设备稀疏化局部模型参数和动量估计更新，并使用共享稀疏掩码（SSM），在稀疏化过程中省略了三个独立稀疏掩码的需求。此外，还提供了FedAdam-SSM的收敛性边界，并探讨了局部epoch，学习率和稀疏化比例对收敛速度的影响。
### Conclusion
实验证明，FedAdam-SSM在收敛速度和测试精度方面都优于基线。具体而言，FedAdam-SSM的收敛速度快于稀疏型FedAdam基线超过1.1倍，测试精度则领先于量化型FedAdam基线超过14.5%。
## 773. `cs.LG` - 在无标签数据下估计模型在协变量偏移下的性能 [PDF](https://arxiv.org/pdf/2401.08348), [HTML](https://arxiv.org/abs/2401.08348)
### Authors
Jakub Białek,Juhani Kivimäki,Wojtek Kuberski,Nikolaos Perrakis
### Background
在部署之后，机器学习模型常常由于数据分布的变化而表现出性能下降。在标签缺失或延迟的情况下，准确评估部署后性能极具挑战性。现有的代理方法，如数据漂移检测，无法充分度量这些变化的影响。
### Innovation
引入了一种新方法，用于在无标签表数据上评估二元分类模型的性能，这种方法能够准确估计模型在协变量变化下的性能。这种方法称为概率自适应性能评估(PAPE)，它可以应用于任何基于混淆矩阵元素定义的性能度量。PAPE独立于原始模型运行，仅依赖其预测和概率估计，无需假设协变量变化的性质，而是直接从数据学习。
### Conclusion
通过使用来自美国人口普查数据的超过900个数据集模型组合进行测试，PAPE在各种指标的比较中表现出色。研究发现PAPE比其他方法性能更优，因此PAPE是评估二元分类模型性能的更优选择。
## 774. `cs.LG` - 聚焦编码器-流：通过因果蒸馏实现低比特率语音编码 [PDF](https://arxiv.org/pdf/2509.16195), [HTML](https://arxiv.org/abs/2509.16195)
### Authors
Luca Della Libera,Cem Subakan,Mirco Ravanelli
### Background
现代生成音频管道中的神经音频编解码器是其基本组件。现有的编码器尽管在低比特率重建方面表现出色，并能够为下游任务提供强大的表示，但大多数都不是流式的，在实时应用中受到限制。因此，本文的研究背景是探索如何在保证音质和下游任务性能的同时，实现低比特率、实时的语音编码。
### Innovation
本文提出了一种名为FocalCodec-Stream的新编解码器。该编解码器基于焦点调制，使用可控的多阶段因果蒸馏WavLM，并结合了轻量级优化模块。其创新点在于减少编码延迟的同时，仍能保持良好的语义和声学信息，并在同等比特率下优于现有流式编码器。其理论延迟为80ms，比特率范围为0.55 - 0.80 kbps。实验证明该编解码器在重建质量、下游任务性能、延迟和效率之间取得了良好的权衡。
### Conclusion
研究表明，FocalCodec-Stream在低比特率和实时性方面取得了出色的成果，能够在保持高质量重建的同时，为下游任务提供高质量的表示。该编解码器在结构修饰和轻量级优化方面做出了改进，并且实验证明了其相对于现有方案的优势。源代码和检查点将发布在项目页面上。
## 775. `cs.LG` - MANZANO:一种基于混合视觉标记符的简单可扩展统一多模态模型 [PDF](https://arxiv.org/pdf/2509.16197), [HTML](https://arxiv.org/abs/2509.16197)
### Authors
Yanghao Li,Rui Qian,Bowen Pan,Haotian Zhang,Haoshuo Huang,Bowen Zhang,Jialing Tong,Haoxuan You,Xianzhi Du,Zhe Gan,Hyunjik Kim,Chao Jia,Zhenbang Wang,Yinfei Yang,Mingfei Gao,Zi-Yi Dou,Wenze Hu,Chang Gao,Dongxu Li,Philipp Dufter,Zirui Wang,Guoli Yin,Zhengdong Zhang,Chen Chen,Yang Zhao,Ruoming Pang,Zhifeng Chen
### Background
统一的多模态大型语言模型（LLMs）能够理解并生成视觉内容，具有巨大的潜力。然而，现有的开源模型在这些能力之间往往存在性能权衡。Manzano提出了一种简单且可扩展的一体化框架，通过结合混合图像标记符和精心挑选的训练方案，显著减少了这种紧张关系。单一共享的视觉编码器为两种轻量级适配器提供输入，这两种适配器在共同的语义空间内分别产生图像到文本理解的连续嵌入和文本到图像生成的离散标记。统一的自回归LLM以文本和图像标记的形式预测高层次语义，其辅助的扩散解码器随后将图像标记转换为像素。该架构结合统一的整体训练方法，在理解和生成数据上实现了两个能力的可扩展联合学习。
### Innovation
Manzano提供了一种简单且可扩展的一体化框架，通过混合图像标记符和精心挑选的训练方案，显著减少了理解和生成视觉内容之间的性能权衡。单一共享的视觉编码器通过两种轻量级适配器分别用于图像到文本理解和文本到图像生成。统一的自回归LLM能够预测高层次语义，并通过辅助扩散解码器将图像标记转换为像素。
### Conclusion
Manzano在统一模型中取得了最先进的性能，与专门模型相比具有竞争力，尤其是在富有文本评估中。研究表明，任务冲突最小，模型大小的放大带来了持续的增益，证实了混合标记符设计的选择。
## 776. `cs.LG` - 通过利用多层结构提高风能预测准确性 [PDF](https://arxiv.org/pdf/2308.03472), [HTML](https://arxiv.org/abs/2308.03472)
### Authors
Lucas English,Mahdi Abolghasemi
### Background
全球脱碳需要可再生资源的持续发展。预测可再生能源，尤其是风能，是具有挑战性的，因为风能的产生受到天气条件的影响具有固有的不确定性。最近，通过协调的分层预测技术在短期内显示出了显著提高风能预测质量的潜力。
### Innovation
本文通过利用风力发电场涡轮机的横截面和时间分层结构，构建跨时间分层，进一步研究如何将整合的横截面和时间维度的价值应用于风力发电场的预测准确性。研究表明，跨时间协调在多个时间聚合下优于单独的横截面协调，且基于机器学习的跨时间协调预测在较粗的时间颗粒度下具有高准确性，这可能促进短期风能预测的采纳。
### Conclusion
本文通过实证研究为决策者提供了不同预测范围和层级下高频率风能数据的最佳预测方法的见解，特别是在定量地融合横截面和时间维度以提高风能预测准确性方面的发现。
## 777. `cs.LG` - MatchFixAgent：语言无关的自主仓库级代码翻译验证和修复 [PDF](https://arxiv.org/pdf/2509.16187), [HTML](https://arxiv.org/abs/2509.16187)
### Authors
Ali Reza Ibrahimzada,Brandon Paulsen,Reyhaneh Jabbarvand,Joey Dodds,Daniel Kroening
### Background
代码翻译将源代码从一种编程语言转换为另一种。验证翻译的功能等价性并必要时修复错误是代码翻译中的关键步骤。现有的自动化验证和修复方法因工程开销高而难以适用于多种编程语言，并且依赖于现有但往往不充分的测试套件，这会导致等价性虚假声称和无效的翻译修复。
### Innovation
本文开发了MatchFixAgent，这是一种基于大规模语言模型的跨编程语言框架，用于验证翻译的功能等价性和修复错误。该框架具有多代理架构，将等价性验证细分为多个子任务，确保翻译的彻底和一致的语义分析。然后将这些分析交给测试代理编写和执行测试。在观察到测试失败时，修复代理试图修复翻译错误。最终的等价性决定由判决代理作出，考虑语义分析和执行测试的结果。相比前人工作，研究表明，MatchFixAgent能够对99.2%的翻译对生成等价性判决，并且当其结果与前人工作不符时，MatchFixAgent的结果正确时占60.7%。此外，我们还展示了MatchFixAgent能够修复50.6%的非等价翻译，而前人工作仅能修复18.5%.
### Conclusion
本文展示了一种新的框架MatchFixAgent，它能够更适应多种编程语言对，同时提供高度准确的验证结果，相比现有工作，其在验证和修复代码翻译方面具有更高的适应性和准确性。
## 778. `cs.LG` - 指数族潜在变量模型中精确推断和学习的一致理论 [PDF](https://arxiv.org/pdf/2404.19501), [HTML](https://arxiv.org/abs/2404.19501)
### Authors
Sacha Sokoloski
### Background
贝叶斯规则描述了如何根据观测结果推断潜在变量的后验信念，这是在潜在变量模型（LVMs）学习算法中至关重要的一环。虽然对于像线性高斯模型和混合模型等特定类型的LVMs存在精确算法，但当使用新的LVMs时，研究人员通常必须开发近似算法。本文研究了依赖于近似方案和无需依赖近似方案的LVMs之间的界限，为那些能够准确实施推断和学习的LVMs开发了一般理论。
### Innovation
在温和假设前提下，本文推导出LVM参数的必要充分约束条件，使得潜在变量的先验和后验在相同的指数族中。另外，本文展示了多种已知和新颖模型符合这种约束下的指数族形式。最后，推导出了这些LVMs的一般化推理和学习算法，并通过多个例子进行演示。这些统一的视角有助于理解和实现各种模型的精确推理和学习算法，可能引导研究人员发现避免不必要的近似的新模型。
### Conclusion
本文通过统一视角，不仅便于理解和实现各种模型的精确推理和学习算法，而且可能指引研究人员发现避免不必要的近似的新模型，从而提供了一种更有效的方法来处理LVMs的推断和学习问题。
## 779. `cs.LG` - 一种去噪的朗格维算法和半去噪采样方法 [PDF](https://arxiv.org/pdf/2410.05837), [HTML](https://arxiv.org/abs/2410.05837)
### Authors
Aapo Hyvärinen
### Background
朗格维算法是一种经典方法，用于从给定的概率密度函数中进行采样。其基本版本仅需知道对数密度的梯度。在深度学习中，通常更容易学习所谓的“有噪声的数据对数密度梯度”，尤其是当添加高斯噪声到数据时。这种估计是有偏差的，这使得朗格维方法的使用复杂化。
### Innovation
提出了一种去噪声的朗格维算法，可以去除由于有噪声数据引起的偏差，至少在最高阶项方面。与扩散模型不同，该算法仅需要知道单一噪声级别的有噪声得分函数。进一步提出了一种简单的特殊情况，该情景有直观的解释，即迭代地添加噪声到数据，然后尝试去除一半的噪声。
### Conclusion
该研究为有噪声数据的朗格维采样问题提供了解决策略，并提出了一种新的算法，该算法能够准确采样，同时简化了模型的使用。
## 780. `cs.LG` - 使用图网络进行希格斯探测器数据质量监控的时空异常检测 [PDF](https://arxiv.org/pdf/2311.04190), [HTML](https://arxiv.org/abs/2311.04190)
### Authors
Mulugeta Weldezgina Asres,Christian Walter Omlin,Long Wang,David Yu,Pavel Parygin,Jay Dittmann,Georgia Karapostoli,Markus Seidel,Rosamaria Venditti,Luka Lambrecht,Emanuele Usai,Muhammad Ahmad,Javier Fernandez Menendez,Kaori Maeshima, theCMS-HCAL Collaboration
### Background
大型强子对撞机（LHC）上的紧凑 μ 磁弯器（CMS）实验是一个通用型探测器，用于高能碰撞。CMS 实验采用了在线数据质量监控（DQM）系统，能够即时发现和诊断粒子数据采集问题，从而避免数据质量的损失。本文研究了如何利用 DQM 的三维探测器数字占用地图数据在 CMS 的希格斯探测器（HCAL）的物理粒子读取通道中实现一种半监督的时空异常检测（AD）监控系统。该系统利用卷积和图神经网络学习因粒子穿越探测器而产生的局部空间特征以及因共享后端电路连接和通道机箱而产生的全局行为特征，循环神经网络则捕捉了提取的空间特征的时间演变过程。
### Innovation
提出了一种基于图的时空异常检测（GraphSTAD）系统，该系统结合了卷积神经网络、图神经网络和循环神经网络，能够识别和监测希格斯探测器中由粒子轨迹引起的局部空间特征和由共享后端电路连接和机箱引起的全局行为特征，从而实现实时的、生产级别的异常检测，并被集成到CMS的核心生产系统中，用于实时监控HCAL的数据质量。
### Conclusion
GraphSTAD系统在捕捉通道故障类型方面达到了生产级别准确性，与基准模型相比，展示了系统在数据质量监控方面的显著优势。
## 781. `cs.LG` - FRIDA: 采用隐私攻击的免费骑手检测 [PDF](https://arxiv.org/pdf/2410.05020), [HTML](https://arxiv.org/abs/2410.05020)
### Authors
Pol G. Recasens,Ádám Horváth,Alberto Gutierrez-Torre,Jordi Torres,Josep Ll.Berral,Balázs Pejó
### Background
联邦学习因其能够使拥有少量数据和资源的多方协作训练机器学习模型而越来越受欢迎。然而，与其它协作系统一样，联邦学习也容易受到免费骑手的威胁。免费骑手不提供任何帮助却从全球模型中受益，这不仅破坏了学习过程的完整性，还降低了全球模型的收敛速度，增加了诚实参与者的成本。当前没有直接方法通过隐私攻击来检测免费骑手的存在，因此需要一种新的方法来有效检测免费骑手。
### Innovation
FRIDA提出了一个名为FRIDA（Free-rider Detection using Privacy Attacks）的方法，通过使用成员身份和属性推理攻击直接推断出参与训练的真正客户端的证据，从而解决了识别免费骑手的挑战。此方法展示了广泛的场景中都具有有效性。
### Conclusion
FRIDA是一种有效的免费骑手检测方法，它利用隐私攻击直接推断参与训练的真实客户端证据，广泛适用于各种场景，从而保证了联邦学习过程的高效性和公平性。
## 782. `cs.LG` - 针对长期时间序列预测的目标内部时间依赖性建模 [PDF](https://arxiv.org/pdf/2406.04777), [HTML](https://arxiv.org/abs/2406.04777)
### Authors
Qi Xiong,Kai Tang,Minbo Ma,Ji Zhang,Jie Xu,Tianrui Li
### Background
长期时间序列.fore预测（LTSF）在各个领域都是一项关键任务。尽管在LTSF研究方面取得了重大进展，但现有LTSF方法在对目标（Target）内部的时间依赖性（TDT）建模不足存在问题，导致性能瓶颈。
### Innovation
我们提出了一种新型且通用的时间建模框架——时间依赖性对齐（TDAlign），它赋予现有LTSF方法学习TDT的能力。TDAlign创新地引入了两个关键点：1) 一种损失函数，将预测的相邻时间步的变化值与目标中的变化值对齐，确保与变化模式的一致性；2) 一种自适应损失平衡策略，无缝地将新损失函数与现有LTSF方法集成，而无需引入额外的可学习参数。TDAlign作为即插即用框架，对现有方法的增强最小化了计算开销，仅具有线性的时间复杂性和常数的空间复杂性，相对于预测长度而言。
### Conclusion
在六个强大的LTSF基线以及七个真实世界数据集上的大量实验证明了TDAlign的有效性和灵活性。与基线相比，TDAlign平均将预测误差减少了1.47%至9.19%，变化值误差减少了4.57%至15.78%，突显了其显著的性能改进。
## 783. `cs.LG` - 使用LLM先验的贝叶斯概念瓶颈模型 [PDF](https://arxiv.org/pdf/2410.15555), [HTML](https://arxiv.org/abs/2410.15555)
### Authors
Jean Feng,Avni Kothari,Luke Zier,Chandan Singh,Yan Shuo Tan
### Background
概念瓶颈模型（CBMs）作为一种在保持解释性的同时不牺牲准确性的折中方案出现了。标准的CBMs训练流程包括预定义一组可由人类理解的概念、从训练数据中提取这些概念的值、并通过一个透明的预测模型识别稀疏的概念子集。这种方法往往在探索足够大的概念集合与控制概念提取的成本之间存在权衡，导致了解释性与准确性的权衡。
### Innovation
本文提出了一种新的方法，通过在贝叶斯框架中迭代搜索可能无限的概念集，解决了传统CBMs的挑战。在这种方法中，大型语言模型（LLMs）既作为概念提取机制，又作为先验信息。尽管LLMs可能失准并产生幻象，本文证明BC-LLM可以提供严格统计推断和不确定性量化。实验结果表明，在图像、文本和表格数据集上，BC-LLM不仅优于解释性基线，甚至在某些情况下优于黑盒模型，同时在收敛到相关概念和对离分布样本的鲁棒性方面表现更佳。
### Conclusion
本文提出的BC-LLM方法在保持解释性的同时，能够更快速且稳健地收敛到相关概念，即便在LLMs可能存在失准的情况下也能提供严格的统计推断和不确定性量化。
## 784. `cs.LG` - 两个胜过一个：用于异常检测的对齐表示对 [PDF](https://arxiv.org/pdf/2405.18848), [HTML](https://arxiv.org/abs/2405.18848)
### Authors
Alain Ryser,Thomas M. Sutter,Alexander Marx,Julia E. Vogt
### Background
异常检测的核心在于识别与常规样本不同的样本。为了有效检测异常，发现正常样本的信息性表示至关重要。最近的自我监督方法通过在训练期间利用异常知识创造合成的离群值，成功地学习了这样的表示。但在特定领域的实际应用中，我们往往无法预知未见过的数据情况。本文针对这一局限，提出了一个新的方法Con_2，其利用正常样本中的对称性知识，在不同上下文视角下观察数据。Con_2包括两个部分：上下文对比根据其上下文对表示进行聚类，内容对齐则促使模型通过跨越聚簇调整正常样本的位置信息来捕捉语义信息。这种方法生成的表示空间使得异常可以被视为学习到的上下文聚类的离群值。
### Innovation
提出了一种新的自我监督方法Con_2，它是基于对正常样本对称性的理解，利用上下文对比和内容对齐来获取更具信息性的表示，从而在自监督学习和预训练模型的基础上，有效提高了异常检测的性能。研究表明，在专门的医学数据集上，该方法优于基于自监督学习和预训练模型的现有竞争基线，并且在自然影像基准测试中也表现出竞争力的性能。
### Conclusion
在广泛的实验中，Con_2方法在特定的医学数据集上比现有的自监督学习基线和预训练模型基线表现更好，并且在自然影像基准上也达到了可竞争的水平。表明结合上下文和内容的对齐表示对可以显著提升异常检测的性能。
## 785. `cs.LG` - 基于深度学习的基模和模式模型：水文时间序列的挑战 [PDF](https://arxiv.org/pdf/2410.15218), [HTML](https://arxiv.org/abs/2410.15218)
### Authors
Junyang He,Ying-Jung Chen,Alireza Jafari,Anushka Idamekorala,Geoffrey Fox
### Background
尽管已经对时间序列分析中的深度学习方法进行了大量研究，包括基础模型，但大多数研究未能强调重要的科学应用。水文学数据的复杂性使得时间序列中的观测信息来自多个地点，涉及多种时间依赖性数据流和外生因素，这些因素可能是静态的或随时间变化的，既有应用依赖性因素也有纯粹的数学因素。本文分析了来自CAMELS和Caravan全球数据库的水文学时间序列数据，探讨了包括降水量和径流量等数据，并通过评估8种不同的模型配置来评估外生数据的影响。结果显示，整合外生信息可以显著提高数据表示，减少最大数据集的均方误差达40%。
### Innovation
通过先进的时间序列分析方法，文章展示了如何通过综合外生信息（如自然年度周期性时序）来改进水文时间序列的数据表示，尤其强调对于不同深度学习架构的应用和评估。文章还提供了对超过20种目前最先进的模式和基础模型的详细性能比较，展示了包含综合观测和外生数据的模型的优越性。
### Conclusion
该研究通过使用Jupyter Notebook在Google Colab上进行的LSTM基础模型、数据预处理和模型比较，展示了使用外生信息对数据表示的改进效果，并且在多个数据集上的初步发现表明，综合全面的观测和外生数据的模型比基础模型和仅部分数据的模型表现更好，尤其是在考虑自然年度周期性时序的情况下，效果尤为明显。
## 786. `cs.LG` - 可学习且可扩展的指令微调数据影响估计的神经网络 [PDF](https://arxiv.org/pdf/2502.09969), [HTML](https://arxiv.org/abs/2502.09969)
### Authors
Ishika Agarwal,Dilek Hakkani-Tür
### Background
现有影响函数方法提供了对模型训练至关重要的见解，但存在计算成本高和泛化能力有限的问题。特别是，使用语言模型计算数据影响的新方法由于大型模型和数据集的规模而不易扩展，这主要是因为计算过程中高昂的前向和反向传递成本，需要大量内存来存储大型模型，以及影响估算对新数据的泛化能力较差。
### Innovation
本文探索了使用小型神经网络（称为InfluenceNetwork）来估计影响值，实现高达99%的成本降低。我们的评估表明，可以使用比完整语言模型小0.0027％的模型来估计影响值（使用7B和8B版本）。我们将估计影响值的算法（称为NN-CIFT）应用于指令微调下游任务中的子集选择。研究表明，在大幅提高速度后，NN-CIFT和原始影响函数之间的性能无明显损失。同时提供了一种深入讨论NN-CIFT超参数分析的方法。
### Conclusion
我们的研究展示了使用小型神经网络I - estimating命题切实可行，无需牺牲性能的情况下显著降低了估计计算成本，同时提供了深入的超参数分析。
## 787. `cs.LG` - 边缘的种类：同质神经网络中最速下降法的隐式偏差 [PDF](https://arxiv.org/pdf/2410.22069), [HTML](https://arxiv.org/abs/2410.22069)
### Authors
Nikolaos Tsilivis,Eitan Gronich,Gal Vardi,Julia Kempe
### Background
该研究进一步探讨了最速下降算法（具有无穷小学习率）在深层同质神经网络中的隐式偏差。研究基于已有理论和实验证据，分析了在达到完美训练准确率后算法的几何边缘变化，及训练轨迹的极限点与边缘最大化问题的KKT点之间的关系，特别是在与流行的自适应方法（Adam和Shampoo）的联系方面。
### Innovation
研究展示了两种创新：首先，一种算法相关的几何边缘在网络达到完美训练准确性后开始增加；其次，任何训练轨迹的极限点对应于相应的边缘最大化问题的KKT点。此外，通过实验进一步深化了最速下降算法与广泛使用的自适应方法之间的联系。
### Conclusion
研究证明了最速下降算法在同质神经网络中的几何边缘变化及其与边缘最大化问题的关系，并通过实验验证了自适应方法之间的隐式偏差，为理解这些优化算法的内在偏差提供了新的视角。
## 788. `cs.LG` - DiRW: 考虑路径的有向图学习以处理异质性 [PDF](https://arxiv.org/pdf/2410.10320), [HTML](https://arxiv.org/abs/2410.10320)
### Authors
Daohan Su,Xunkai Li,Zhenjun Li,Yinping Liao,Rong-Hua Li,Guoren Wang
### Background
近年来，图神经网络（GNN）已成为处理图结构数据的强大表示学习工具。然而，大多数方法仅针对无向图设计，忽视了有向图（有向图）边中丰富的信息。实际上，有向图在现实世界中广泛应用，并被证实能有效解决异质性挑战。尽管最近取得了一定进展，但基于空间的有向图神经网络（DiGNN）仍存在一些局限性，主要是由于其复杂的学习机制和对高质量拓扑的依赖，导致效率低且性能不稳定。
### Innovation
DiRW 提出了一种适用于大多数基于空间的 DiGNN 的即插即用策略，同时作为一种创新模型，提供了新的有向图学习范式。它通过在不依赖权重的情况下优化考虑节点特征和拓扑的方向感知路径采样器，来优化行走概率、长度和数量。DiRW 还引入了节点级别的可学习路径聚合器以获得通用节点表示。实验结果表明，DiRW 不仅作为即插即用策略提高了大多数基于空间的模型，还作为新的有向图学习范式实现了 SOTA 性能。
### Conclusion
DiRW方法在9个数据集上的广泛实验展示了其作为即插即用策略增强大多数基于空间的模型，以及作为一个新的有向图学习范式实现SOTA性能的能力。相关源代码和数据可在指定链接下载。
## 789. `cs.LG` - 熵正则化过程奖励模型 [PDF](https://arxiv.org/pdf/2412.11006), [HTML](https://arxiv.org/abs/2412.11006)
### Authors
Hanning Zhang,Pengcheng Wang,Shizhe Diao,Yong Lin,Rui Pan,Hanze Dong,Dylan Zhang,Pavlo Molchanov,Tong Zhang
### Background
大型语言模型（LLMs）在复杂多步推理方面展现出了潜力，但由于数学推理上的限制，这类模型经常出现系统性错误。通过奖励模型引导强化学习（RL）的方法，特别是注重过程奖励的方法，被认为是可能的解决方案。这些过程奖励模型根据每个中间步骤打分，而非仅评估最终结果。这种方法有助于将策略模型引导到正确的推理轨迹。
### Innovation
提出了一种熵正则化的过程奖励模型（ER-PRM），通过KL正则化的马尔可夫决策过程（MDP）平衡了政策优化与防止策略偏离初始分布的需求。基于理论结果推导出一种新型奖励构建方法，并且理论分析表明可以从初始策略抽样中得出最优奖励模型。实验结果表明，ER-PRM在MATH和GSM8K基准测试中均优于现有过程奖励模型：在GSM8K上提升了1%，在MATH上提升了2-3%，在RLHF中更是超过了1%。
### Conclusion
熵正则化的引入增强了LLMs的推理能力。
## 790. `cs.LG` - 脑部MRI成像中的域不变特征学习以实现基于内容的图像检索 [PDF](https://arxiv.org/pdf/2501.01326), [HTML](https://arxiv.org/abs/2501.01326)
### Authors
Shuya Tobari,Shuhei Tomoshige,Hayato Muraki,Kenichi Oishi,Hitoshi Iyatomi
### Background
在从多个设施收集脑部磁共振成像(MRI)的大规模研究中，不同设施的成像设备和协议差异不能被忽视，这些差异形成了域差距问题，对最近的研究产生了显著影响。
### Innovation
提出了一种新低维表示（LDR）获取方法，称为风格编码对抗域适应（SE-ADA），用于实现脑部MRI图像的内容基图像检索（CBIR）。SE-ADA通过分离LDR中的域特定信息，并使用对抗学习最小化域差异，来减少域差异同时保留病理特征。
### Conclusion
在与八个多公开的脑部MRI数据集（ADNI1/2/3、OASIS1/2/3/4、PPMI）的最近域调和方法的比较实验中，SE-ADA在消除域信息的同时保留了原始脑结构的关键方面，并展示了最高的疾病搜索准确性。
## 791. `cs.LG` - 基于遥感数据融合在精准农业中的数据驱动审查：从基础技术到基于变换器的方法 [PDF](https://arxiv.org/pdf/2410.18353), [HTML](https://arxiv.org/abs/2410.18353)
### Authors
Mahdi Saki,Rasool Keshavarz,Daniel Franklin,Mehran Abolhasan,Justin Lipman,Negin Shariati
### Background
本文回顾了从1994年至2024年近年来数据融合技术和基于变换器的遥感应用在精准农业中的进展。通过系统性和数据驱动的方法，分析了农业监测中的研究趋势，指出了数据融合、遥感和AI驱动监测中的关键发展。尽管传统的机器学习和深度学习方法在农业决策上表现出有效性，但有限的可扩展性、不优化的特征提取和对大量标注数据的依赖仍然是挑战。这项研究特别探讨了基于变换器的数据融合方法的优势，尤其是其在建模时空依赖性和整合异构数据集方面的优势，应用于土壤分析、作物分类、产量预测和疾病检测等方面。
### Innovation
本文基于变换器的数据融合方法在多模态数据融合领域的优势进行了综合分析，展示了变换器模型在提高预测准确性、减少特征冗余和优化大规模数据集成方面的性能。此外，本文还提出了一条结构化路线图，用于实施农业遥感中的数据融合，概述了地面实况数据选择、平台集成和融合模型设计的最佳实践。
### Conclusion
通过解决关键研究缺口并提供战略框架，本文为通过基于人工智能的数据融合技术推进精准农业提供了宝贵见解。
## 792. `cs.LG` - 通用非理想电阻元件上的类模拟内存训练：响应函数的影响 [PDF](https://arxiv.org/pdf/2502.06309), [HTML](https://arxiv.org/abs/2502.06309)
### Authors
Zhaoxian Wu,Quan Xiao,Tayfun Gokmen,Omobayode Fagbohungbe,Tianyi Chen
### Background
随着训练和部署大型视觉或语言模型的经济和环境成本急剧增加，类模拟内存计算（AIMC）作为一种节能解决方案逐渐显现。然而，现有研究主要关注其部署视角，特别是训练动态方面研究不足。AIMC硬件中，可训练权重通过电阻元件的导电性表示，并通过连续电脉冲更新。尽管每次脉冲后导电性变化是一个常量，但实际变化受到不对称且非线性的响应函数影响，导致训练动态不理想。该文为在具有非理想响应函数的AIMC硬件上基于梯度的训练提供理论基础
### Innovation
文章提出一种通过解决双层优化问题的残差学习算法，该方法可有效补偿不对称响应函数对类模拟STG（模拟随机梯度下降）的负面影响，并保证算法精确收敛于临界点。此外，该方法能够扩展解决其他硬件缺陷，比如响应粒度有限的问题。这被认为是首个探讨一类通用非理想响应函数影响的研究
### Conclusion
通过仿真验证了理论洞见，结论支持该方法的有效性和可靠性
## 793. `cs.LG` - 物理信息神经网络中的梯度对齐：一个二次优化视角 [PDF](https://arxiv.org/pdf/2502.00604), [HTML](https://arxiv.org/abs/2502.00604)
### Authors
Sifan Wang,Ananyae Kumar Bhartari,Bowen Li,Paris Perdikaris
### Background
多任务学习通过复合损失函数是现代深度学习的基础，但优化竞争性目标仍然具有挑战性。本文探讨了在物理信息神经网络(PINNs)中解决损失项间方向性冲突的新理论和实践方法，特别是这类冲突在PINNs中非常难以解决。理论分析表明，这些冲突限制了一阶优化方法，并证明了二次优化自然地通过隐式梯度对齐来解决它们。
### Innovation
本文提出了将 SOAP 这一最近提出的拟牛顿方法高效地逼近Hessian预条件器的新方法，这使得PINNs在10个挑战性的偏微分方程(PDE)基准测试中取得了最先进的结果，包括首次成功应用于雷诺数高达10,000的湍流流动，并且在准确性方面比现有方法提高了2-10倍。此外，还介绍了一种新颖的梯度对齐分数，该分数将余弦相似性推广到多个梯度，提供了分析优化动力学的实用工具。
### Conclusion
本文的研究确立了理解并解决梯度冲突的框架，对于优化科学计算之外的其他领域也有广泛的影响。
## 794. `cs.LG` - Cache-of-Thought: Master-Apprentice Framework for Cost-Effective Vision Language Model Reasoning [PDF](https://arxiv.org/pdf/2502.20587), [HTML](https://arxiv.org/abs/2502.20587)
### Authors
Mingyuan Wu,Jize Jiang,Haozhen Zheng,Meitang Li,Zhaoheng Li,Beitong Tian,Bo Chen,Yongjoo Park,Minjia Zhang,Chengxiang Zhai,Klara Nahrstedt
### Background
视觉语言模型（VLMs）在视觉应用中取得了显著的成功，但选择合适的VLM模型大小需在响应质量和成本之间做出权衡。较小的VLM模型虽然运行成本较低，但在基准测试（如MMMU）中表现出的响应质量仅比随机猜测稍好。
### Innovation
本文提出了一种名为Cache of Thought (CoT)的主从框架，用于在大型和小型VLM之间进行协作推理。CoT通过缓存大型VLM的高质量查询结果，并利用多模态检索和上下文学习来辅助小型VLM的性能。实验表明，CoT在相同预算下将整体推理性能提高了最多7.7%，并特别提升了小型VLM的性能，最多提高了36.6%。
### Conclusion
本文通过对各种广泛认可和具有挑战性的一般推理基准的广泛评估，证明了CoT框架的有效性。作者提供的代码可供参考。
## 795. `cs.LG` - 基于Transformer的时间序列模型中的位置编码：一项综述 [PDF](https://arxiv.org/pdf/2502.12370), [HTML](https://arxiv.org/abs/2502.12370)
### Authors
Habib Irani,Vangelis Metsis
### Background
近期基于Transformer的模型在时间序列分析领域取得了很大进步，为预测、异常检测和分类等任务提供了稳健的解决方案。这些模型的关键组成部分是位置编码，它使得Transformer能够捕捉时间序列数据的固有序列性质。
### Innovation
本文系统地探讨了现有的基于Transformer的时间序列模型中的位置编码技术，研究了固定、可学习、相对和混合方法等不同类型的编码技术，并评估了它们在不同时间序列分类任务中的效果。此外，研究还指出了性能改进背后的挑战和潜在研究方向。
### Conclusion
本文通过全面概述并定量基准测试，旨在帮助研究人员和从业者选择和设计有效的基于Transformer的时间序列模型的位置编码方法。
## 796. `cs.LG` - 随着批量增大，黎曼随机梯度下降的更快收敛 [PDF](https://arxiv.org/pdf/2501.18164), [HTML](https://arxiv.org/abs/2501.18164)
### Authors
Kanata Oowada,Hideaki Iiduka
### Background
研究黎曼随机梯度下降(RSGD)的收敛行为，发现增加批量大小能在恒定学习率和减小学习率（如余弦退火衰减和多项式衰减）的情况下，比使用恒定批量大小更快地收敛。当批量大小增加时，收敛速度从常批量大小下的$O(T^{-1}+C)$提高到增加批量大小下的$O(T^{-1})$，其中$T$表示总迭代次数，$C$是一个常数。进一步使用主成分分析和低秩矩阵完成研究了批量增大如何影响计算时间（通过随机一阶Oracle (SFO) 复杂性量化），发现批量增大减少了RSGD的SFO复杂性。批量增大同时具有较小和较大恒定批量大小的优势.
### Innovation
发现增加批量大小能够提升黎曼随机梯度下降的收敛速度，不仅适用于恒定学习率，也适用于减小学习率（如余弦退火衰减和多项式衰减）的情况。批量增大不仅增强了收敛性能，也减少了SFO复杂性。同时，批量增大策略兼具小批量和大批量的优点.
### Conclusion
黎曼随机梯度下降的收敛速度可以通过增加批量大小得到提升，这不仅适用于恒定学习率，也适用于减小学习率的情况。此外，批量增大进一步降低了RSGD的SFO复杂性，从而提升了算法效率。
## 797. `cs.LG` - 从游戏分析揭示人类内部注意力模式以强化学习 [PDF](https://arxiv.org/pdf/2504.11118), [HTML](https://arxiv.org/abs/2504.11118)
### Authors
Henrik Krauss,Takehisa Yairi
### Background
本研究介绍了一种新型方法，仅利用游戏数据揭示人类内部注意力模式，这种方法借鉴了强化学习(RL)中离线注意力技术。研究者通过对比人类和RL代理人在阿特莱环境中游戏生成的注意力图，来验证方法的有效性，并提出基于人类和代理人的上下文相关任务相关(CTR)注意力网络生成注意力图。
### Innovation
本研究提出了CTR注意力网络，这是一种基于阿特莱环境处理人类和代理人的游戏数据的新型方法，首次通过定量和定性比较以及基于人类眼动追踪的时空整合外显注意力(TIOA)模型来验证人类CTR注意力图的有效性。结果显示，人类CTR注意力图比代理人的更稀疏，并且与TIOA图有更好的匹配度，表明它们可能捕捉到了内部注意力模式。此外，这些地图还被用于指导RL代理，结果发现，由内部注意力指导的人工智能代理在学习过程中表现出略好且更稳定的结果。
### Conclusion
这项工作推进了对人类与代理人在注意力方面的差异的理解，并提供了一种新的方法，用于从行为数据中提取和验证内部注意力。
## 798. `cs.LG` - GIN-Graph: 一种用于图神经网络模型级解释的生成性解释网络 [PDF](https://arxiv.org/pdf/2503.06352), [HTML](https://arxiv.org/abs/2503.06352)
### Authors
Xiao Yue,Guangzhi Qu,Lige Gan
### Background
图神经网络（GNNs）在实际应用中面临的一个重大挑战是作为黑盒模型，因此需要增强可解释性。现有模型级解释方法存在生成无效解释图和可靠性不足的问题。为解决这些问题，本文提出了一种新的生成性解释网络（GIN-Graph），以生成可靠且高质量的模型级解释图。
### Innovation
GIN-Graph 使用隐式和无似然性的生成对抗网络来构建与原始图相似的解释图，并通过采用具有动态损失权重方案的新型生成器目标函数来最大化某一类别的预测概率。该方法能够解释在各种图数据集上训练的GNN，并生成高质量的稳定性与可靠性高的解释图。
### Conclusion
实验结果表明，GIN-Graph 可以应用于解释 GNNs 并生成高质量的解释图，具有高稳定性和可靠性。
## 799. `cs.LG` - StFT: 空间时间傅里叶变换器在长期动力学预测中的应用 [PDF](https://arxiv.org/pdf/2503.11899), [HTML](https://arxiv.org/abs/2503.11899)
### Authors
Da Long,Shandian Zhe,Samuel Williams,Leonid Oliker,Zhe Bai
### Background
多尺度和多物理系统的长期动力学模拟在科学和工程中构成了理解复杂现象的重大挑战。这种复杂性源于不同尺度之间的复杂相互作用和各种物理过程的交织，这些过程通过耦合的非线性项出现在偏微分方程（PDE）中，控制不同尺度上多个物理场的演变。尽管神经算子在短期预测这些复杂的空间-时间动态方面显示出了潜力，但在长时间跨度上实现高保真度的稳定预测以及提供鲁棒的不确定性量化依然是一个开放且未解决的研究领域。这些限制导致了稳定性下降，并伴随快速累积的误差，特别是在具有多尺度行为的复杂系统长期预报中。
### Innovation
本文提出了一种自回归时空傅里叶变换器（StFT），通过双路径架构结合频率域和时空表示，每个变压器块专门学习不同尺度下的系统动力学。通过利用我们的块的结构化的层次结构，模型明确捕捉了宏观和微观空间尺度下的潜在动态。此外，引入了生成残差修正机制以在时间上学习概率修正的同时量化预测不确定性，提升了长期概率预测的准确性和可靠性。
### Conclusion
对三个基准数据集（等离子体、流体和大气动力学）的评估显示，本文方法在长期动力学预测方面优于最先进的机器学习方法。
## 800. `cs.LG` - TSCAN: 基于两阶段训练的在线商家业务诊断的上下文感知提升建模 [PDF](https://arxiv.org/pdf/2504.18881), [HTML](https://arxiv.org/abs/2504.18881)
### Authors
Hangtao Zhang,Zhe Li,Kairui Zhang
### Background
在个体治疗评估（ITE）估计中，抽样选择偏差是一个主要挑战。传统方法利用治疗正则化技术如Integral Probability Metrics（IPM）、重加权和倾向得分模型来缓解这一偏差，但这些正则化可能引入不必要的信息损失，限制了模型性能，且无法充分处理和利用不同的外部环境特征。因此，需要一种能够更好地管理抽样选择偏差并适应不同上下文特征的新型方法。
### Innovation
本文提出了一种基于两阶段训练的上下文感知提升模型TSCAN，包括CAN-U和CAN-D两个子模型。首先，训练CAN-U模型来生成包含反事实提升标签的完整数据集；然后，训练CAN-D模型，通过使用单调输出层直接建模提升效应。同时引入上下文感知注意力层来处理治疗、商家和上下文特征之间的交互作用，因此能够在不同的上下文中建模治疗效应的差异。
### Conclusion
通过在两个真实数据集上的广泛实验验证了TSCAN的有效性。并在一家中国最大的在线食品点餐平台上的实际商家诊断部署中验证了其实用性和影响力。
## 801. `cs.LG` - 无黑箱 anymore: 时间特征交叉注意力机制揭示临床预测建模 [PDF](https://arxiv.org/pdf/2503.19285), [HTML](https://arxiv.org/abs/2503.19285)
### Authors
Yubo Li,Xinyu Yao,Rema Padman
### Background
尽管深度学习模型在临床预测任务中表现突出，但可解释性仍然是一个重大挑战。为了提高预测准确性和增强可解释性，本文通过借鉴Transformer架构，提出了时间特征交叉注意力机制（TFCAM）这一新型深度学习框架，用于捕捉临床特征随时间的动态交互。
### Innovation
TFCAM通过引入时间特征交叉注意力机制，不仅提高了预测性能，还提供了多级解释能力，包括识别关键时间周期、按重要性排名特征、量化时间上前向效应的特征相互作用。该方法克服了深度学习在医疗领域的“黑箱”限制，为临床医生提供了透明的疾病进展机制洞察，同时保持了尖端的预测性能。
### Conclusion
在慢性肾病患者的1422个案例中，预测终末期肾病的进展，TFCAM优于LSTM和RETAIN基准，实现了AUROC 0.95和F1分数0.69。TFCAM通过提供多层级的解释性，帮助临床医生理解疾病进展机制，同时保持了最先进的预测性能。
## 802. `cs.LG` - ConCISE: 自信引导式压缩在逐步高效推理中的应用 [PDF](https://arxiv.org/pdf/2505.04881), [HTML](https://arxiv.org/abs/2505.04881)
### Authors
Ziqing Qiao,Yongheng Deng,Jiali Zeng,Dong Wang,Lai Wei,Guanbo Wang,Fandong Meng,Jie Zhou,Ju Ren,Yaoxue Zhang
### Background
大型推理模型（LRMs）在复杂推理任务中表现优异，但常常产生冗长的输出，增加了计算负担。现有的基于微调的压缩方法或会在后剪枝操作中破坏推理的一致性，或依赖采样选择，未能彻底移除冗余内容。
### Innovation
通过从自信引导的角度出发，定义了大型推理模型中的两种冗余反思模式：信心不足（模型在正确中间步骤上进行反思）和终止延迟（在验证并确认答案后继续反思），并提出了ConCISE框架，结合自信注入和早期终止机制，生成简洁的推理链，从而在压缩和任务性能之间取得更好的平衡，缩短了推理长度达约50%且保持了较高的任务准确性。
### Conclusion
相比基线方法，使用ConCISE生成的数据进行微调的LRMs在压缩和任务性能之间达到了更好的平衡，缩短了长度约50%，同时维持了较高的任务准确性。
## 803. `cs.LG` - 基于加性施瓦茨加速的高斯过程策略迭代方法在前向和逆向哈密尔顿-雅可比-贝尔曼问题及均场博弈问题中的应用 [PDF](https://arxiv.org/pdf/2505.00909), [HTML](https://arxiv.org/abs/2505.00909)
### Authors
Xianjin Yang,Jingguo Zhang
### Background
本文提出的高斯过程（GP）基于策略迭代框架旨在解决哈密尔顿-雅可比-贝尔曼（HJB）方程和均场博弈（MFGs）中的前向和逆向问题。策略迭代通过交替解决固定控制策略下的值函数和基于该值函数更新策略来进行。通过利用GP的线性结构进行函数近似，每次策略评估步骤都有明确的闭式解，从而消除了数值优化的需求。为提高收敛速度，论文引入加性施瓦茨加速作为每次策略更新后的预处理步骤。
### Innovation
本文提出了一种新的策略迭代框架，通过高斯过程进行函数近似，在每一步策略评估中能够给出显式的闭式解，不需要进行数值优化。此外，通过引入加性施瓦茨加速作为预处理步骤来提高收敛速度，增加算法的计算效率和有效性。实验结果证明了该方法在计算效率上的改进效果。
### Conclusion
本文所提出的方法取得了显著效果，能够高效地解决HJB方程和MFGs中的前向和逆向问题，展示了高斯过程策略迭代框架和加性施瓦茨加速技术的有效结合。
## 804. `cs.LG` - SPACE: SPike-Aware Consistency Enhancement for Test-Time Adaptation in Spiking Neural Networks [PDF](https://arxiv.org/pdf/2504.02298), [HTML](https://arxiv.org/abs/2504.02298)
### Authors
Xinyu Luo,Kecheng Chen,Pao-Sheng Vincent Sun,Chris Xing Tian,Arindam Basu,Haoliang Li
### Background
Spiking Neural Networks (SNNs)作为一种生物实现的替代方案，在能效、时间处理和生物可行性方面优于人工神经网络（ANNs），但SNNs对数据分布变化敏感，这会严重影响其在实际场景中的性能。传统的针对ANNs的测试时自适应（TTA）方法无法解决SNNs独特的实时计算动态，而这些动态包括稀疏性和时空尖峰行为。
### Innovation
我们提出了SPike-Aware Consistency Enhancement (SPACE)，这是第一个针对SNNs的无需源数据且仅需单个实例的TTA方法。SPACE利用了SNNs的固有脉冲动态来最大化单个测试样本增强版本的基于脉冲行为的局部特征图的一致性，从而实现稳健的自适应。实验结果表明，SPACE不仅在多项数据集上表现出色，并且在CNN、Transformer和ConvLSTM等网络架构上也是一致地提升了SNNs的性能，且计算成本更低，显示出在实际场景中利用SNNs的有效性和稳健性.
### Conclusion
实验结果显示，SPACE在计算成本较低的情况下，超过了最先进的ANN方法，证明了其在SNNs实际应用中的有效性和稳健性。
## 805. `cs.LG` - 使用傅里叶增强表示的深度学习在列车传动系统中的复合故障诊断 [PDF](https://arxiv.org/pdf/2504.07155), [HTML](https://arxiv.org/abs/2504.07155)
### Authors
Jonathan Adam Rico,Nagarajan Raghavan,Senthilnath Jayavelu
### Background
故障诊断通过确保列车传输系统的稳定性和可靠性来防止列车故障，现有的数据驱动的故障诊断模型在处理非线性、适应性、可扩展性和自动化方面优于传统方法。然而，现有的数据驱动模型因数据集的限制只能针对单一故障进行训练，且各组件之间单次交互的情况在这些模型中较少涉及，导致在多组件同时运行且相互影响的情况下性能较差。由于这些限制，本文针对上述挑战，提出一种基于频率域表示的一维卷积神经网络的方法，应用于包含21个传感器通道、17种单一故障以及来自4个相互作用组件（电机、齿轮箱、左轴箱和右轴箱）的42种复合故障的PHM北京2024数据集。本文所提模型分别在17种单一故障和42种复合故障的测试集上获得了97.67%和93.93%的准确率。
### Innovation
本文提出了一种基于频率域表示的一维卷积神经网络方法，用于列车传动系统的复合故障诊断，并将其应用于一个包含21个传感器通道、17种单一故障及42种复合故障的交互组件数据集，解决了现有数据驱动模型对单一故障处理较好但对复合故障处理较差的问题。该方法在综合故障诊断方面取得了显著效果，显著提高了模型在复杂情况下的诊断准确性。
### Conclusion
通过采用基于频率域的一维卷积神经网络，本文方法显著提升了复合故障诊断的准确性和适应性，尤其是在含有多个相互作用组件的复杂数据集上表现出色。这为列车传输系统的可靠性和安全性提供了重要的技术支持。
## 806. `cs.LG` - 大型语言模型在图数据挑战中的研究 [PDF](https://arxiv.org/pdf/2505.18475), [HTML](https://arxiv.org/abs/2505.18475)
### Authors
Mengran Li,Pengyu Zhang,Wenbin Xing,Yijia Zheng,Klim Zaporojets,Junzhou Chen,Ronghui Zhang,Yong Zhang,Siyuan Gong,Jia Hu,Xiaolei Ma,Zhiyuan Liu,Paul Groth,Marcel Worring
### Background
图是广泛用于表示非欧几里得数据的范式，应用于社会网络分析、生物分子预测等领域。尽管图学习取得了显著进展，但真实世界的图数据提出了许多挑战，严重影响了学习过程。论文重点讨论了四种基本的数据相关挑战：1. 完整性缺失，真实世界的图数据中节点、边或属性可能缺失；2. 不均衡分布，节点或边的标签及其结构在真实世界的图中高度偏斜；3. 跨域异质性，来自不同领域的图表现出不同的特征空间或结构模式；4. 动态不稳定性，图随着时间以不可预测的方式演化。
### Innovation
论文探讨了大型语言模型（LLMs）如何通过利用丰富语义推理和外部知识来解决这四个基本的数据相关挑战，从而提高图学习的有效性。对于每个挑战，论文回顾了传统的解决方案和现代的LLM驱动的方法，突出了LLMs带来的独特优势。
### Conclusion
文章讨论了这一新兴跨学科领域的开放研究问题和有希望的未来方向，并为此领域的最新进展建立了一个资源库：this https URL.
## 807. `cs.LG` - 上下文鹦鹉学舌：科学机器学习中基础模型的一个简单但难以超越的基础线 [PDF](https://arxiv.org/pdf/2505.11349), [HTML](https://arxiv.org/abs/2505.11349)
### Authors
Yuanzhao Zhang,William Gilpin
### Background
近期的时间序列基础模型在预测物理系统方面展现出了强大的能力，其中包括零样本预测，即在仅提供短暂轨迹作为上下文的情况下预测未来系统的状态，且无需了解基础物理知识。已有研究表明，基础模型通常通过简单的模仿策略进行预测，而在模拟失败时则表现出一些共同的失败模式，如收敛到均值。研究发现，一个简单的上下文模仿模型，直接复制上下文内容，其预测表现甚至优于领先的时间序列基础模型，并且在计算成本上大幅降低。
### Innovation
研究揭示了当前时间序列基础模型在性能和失败模式上的不足，通过上下文模仿提供了与语言模型复用进行时间序列预测相似的视角，提出了将预报准确性与上下文长度之间的关系与基础系统吸引子的分维尺度联系起来的见解，从而帮助指导未来基础模型的设计，并识别出超越模仿的学习策略。
### Conclusion
上下文模仿可以指导未来基础模型的设计，并帮助识别出超越模仿的学习策略，同时揭示了时间序列基础模型中的固有局限性，提出了新的研究方向。
## 808. `cs.LG` - 超越线性操控：统一多属性控制的语言模型 [PDF](https://arxiv.org/pdf/2505.24535), [HTML](https://arxiv.org/abs/2505.24535)
### Authors
Narmeen Oozeer,Luke Marks,Fazl Barez,Amirali Abdullah
### Background
在大型语言模型（LLMs）推理时同时控制多种行为属性是一个有挑战性的问题，是因为属性之间的相互干扰和线性操控方法的局限性。这些方法假设激活空间中的行为是加性的，并且需要为每个属性单独调整参数，这限制了模型的行为灵活性和准确性.
### Innovation
作者引入了一种统一且灵活的方法——K-Steering，该方法通过在隐藏激活上训练单一非线性多标签分类器并使用推理时的梯度来计算干预方向。这种方法避免了线性假设，消除了需要存储和调整独立属性向量的需求，并允许在不重新训练的情况下动态组合行为.
### Conclusion
通过对3个模型家族进行实证研究，并使用基于激活的分类器和基于LLM的评估者验证结果，研究结果表明，K-Steering方法在精确操控多种行为方面比强大的基线方法表现更好.
## 809. `cs.LG` - Channel-Imposed Fusion: 一种简单而有效的医学时间序列分类方法 [PDF](https://arxiv.org/pdf/2506.00337), [HTML](https://arxiv.org/abs/2506.00337)
### Authors
Ming Hu,Jianfu Yin,Mingyu Dou,Yuqi Wang,Ruochen Dang,Siyi Liang,Feiyu Zhu,Cong Hu,Yao Wang,Bingliang Hu,Quan Wang
### Background
医学时间序列信号，如脑电图（EEG）和心电图（ECG），在临床决策支持及疾病早期检测中发挥着重要作用。尽管基于Transformer的模型通过自注意力机制隐式建模时间依赖关系，表现出色，但它们复杂的架构和不透明的推理过程在高风险的临床环境下降低了其可信度。
### Innovation
提出了名为通道强制融合（CIF）的新方法，通过跨通道信息融合提高信号信噪比，减少冗余，提升分类性能。将CIF与结构简单、具有可调感受野的时域卷积网络（TCN）相结合，构建了一个高效且明确的分类框架。实验证明，该方法在多个公开的EEG和ECG数据集上不仅在各种分类指标上优于现有方法，还显著提高了分类过程的透明度。
### Conclusion
该方法不仅在多种分类指标上超越了现有的先进方法，还为医学时间序列分类提供了新的见解，提高了分类过程的透明度。
## 810. `cs.LG` - Perception-R1: 通过视觉感知奖励提升MLLMs的多模态推理能力 [PDF](https://arxiv.org/pdf/2506.07218), [HTML](https://arxiv.org/abs/2506.07218)
### Authors
Tong Xiao,Xin Xu,Zhenya Huang,Hongyu Gao,Quan Liu,Qi Liu,Enhong Chen
### Background
在增强多模态大型语言模型（MLLMs）的多模态推理能力方面，虽然已有研究引入了可验证奖励的强化学习（RLVR）方法，但这些方法忽略了提升MLLMs的多模态感知能力。作者通过麦康马拉测试发现，现有方法未能有效增强MLLMs的多模态感知能力，从而限制了它们在多模态推理方面的进一步改进。
### Innovation
本文提出了Perception-R1，这是一种引入了新型视觉感知奖励的方法，旨在明确鼓励MLLMs准确感知视觉内容，从而有效激励它们的多模态感知和推理能力。具体地，在RLVR训练过程中，通过评估生成的响应与视觉注释的一致性来评定视觉感知奖励。
### Conclusion
我们的方法在多项多模态推理基准测试中表现突出，仅使用1,442条训练数据便达到了最先进的性能。
## 811. `cs.LG` - 通过噪声实现噪声鲁棒性：带污染专家的非对称LoRA适应 [PDF](https://arxiv.org/pdf/2505.23868), [HTML](https://arxiv.org/abs/2505.23868)
### Authors
Zhaokun Wang,Jinyu Guo,Jingwen Pu,Lingfeng Chen,Hongli Pu,Jie Ou,Libo Qin,Wenhong Tian
### Background
当前参数高效的微调方法在将预训练语言模型适应下游任务时，容易受到嘈杂数据的干扰。传统的噪声处理方法要么依赖繁琐的数据预处理，要么采用可能导致误差累积的模型架构修改。与现有噪声处理框架不同，本文提出了一种通过非对称LoRA污染专家（LoPE）实现噪声鲁棒性的方法，这是一种新的框架，仅通过生成的嘈杂数据即可增强模型的噪声鲁棒性。
### Innovation
该研究提出了一种新的框架LoPE，该框架借鉴了混合专家架构，通过在非对称LoRA配置中战略性地整合专门的污染专家，来实现模型对噪声的鲁棒性提升。在微调阶段，LoPE通过双重阶段将噪声注入污染专家以增强其噪声识别和处理能力。在推理阶段，通过选择性地屏蔽专门的污染专家来利用普通专家获得的净化知识，以实现鲁棒输出。实验结果表明，LoPE仅通过低成本的噪声注入即可实现强大的性能和鲁棒性，完全消除了数据清理的需求。
### Conclusion
实验结果证明，LoPE能够仅通过低成本的噪声注入实现强性能和鲁棒性，完全消除了对数据清洗的需求。
## 812. `cs.LG` - 在嵌入式FPGA上使用Tiny Transformers自动化多功能时序分析 [PDF](https://arxiv.org/pdf/2505.17662), [HTML](https://arxiv.org/abs/2505.17662)
### Authors
Tianheng Ling,Chao Qian,Lukas Johannes Haßler,Gregor Schiele
### Background
基于Transformer的模型在各种时序任务中表现出色，但在资源受限的设备上的部署仍然具有挑战性，因为这些模型需要大量的内存和计算资源。尽管之前的工作针对微控制器单元（MCUs）探索了硬件特定的优化，但这些方法往往是针对特定任务的，并且限制在8位定点精度上。现场可编程门阵列（FPGAs）提供了更大的灵活性，能够细粒度地控制数据精度和架构。然而，现有基于FPGA的Transformer部署通常集中在手动配置的高密度平台。
### Innovation
本文提出了一种统一且全自动的部署框架，用于嵌入式FPGA上的Tiny Transformers。该框架支持跨三个代表性时序任务（预测、分类和异常检测）的紧凑的编码Only Transformer架构。它结合了量化感知训练（最低至4位精度）、使用Optuna的硬件感知超参数搜索和自动VHDL生成，以实现无缝部署。我们通过在两个嵌入式FPGA平台上评估我们的框架，在六个公开数据集上对结果进行了评估。结果显示，我们的框架生产了特定于任务的整数Transformer加速器，每推理次数低至0.033 mJ，毫秒级延迟，并提供了在Lattice iCE40上部署的可行性见解。所有源代码将在GitHub仓库中开源。
### Conclusion
本文展示了在嵌入式FPGA平台上使用Tiny Transformers进行多功能时序分析的自动化解决方案，通过优化训练和无缝部署，实现了高性能的时序分析加速器，为未来的研究提供了强大的支持和指导。
## 813. `cs.LG` - Schreier-Coset Graph Propagation [PDF](https://arxiv.org/pdf/2505.10392), [HTML](https://arxiv.org/abs/2505.10392)
### Authors
Aryan Mishra,Lizhen Lin
### Background
图神经网络（GNNs）为图结构数据的学习提供了一个合理的框架，但其表达能力常受到信息压缩（过压扁现象）的限制，即来自远节点的信息被压缩到固定大小的向量中。现有解决方案包括图重布和瓶颈抵抗架构（如Cayley图和扩张图），这些问题虽可避免过压扁现象，但引入了可扩展性瓶颈。具体而言，基于$SL(2,textbf{Z}_n)$构建的Cayley图虽然具有强大的理论特性，但由于节点增长为$O(n^3)$，导致了高内存使用率。为了应对这一问题，本文引入了Schrier-Coset Graph Propagation（SCGP）方法，该方法通过Schreier-coset嵌入增强节点特征，不改变输入图拓扑，将无瓶颈连接模式嵌入到紧凑的特征空间中，提高了远距离消息传递的能力，同时保持了计算效率。该方法已在标准节点分类和图分类基准上进行试验，证明了其性能接近甚至超越了扩张图和重布图GNN基线。此外，SCGP在处理分层和模块化图结构时表现出特别的优势，提供了减少推理延迟、提高可扩展性和低内存占用率的特点，使它适用于实时和资源受限的应用场景。
### Innovation
SCGP通过Schreier-coset嵌入增强节点特征，不改变输入图的拓扑结构，将无瓶颈连接模式嵌入到紧凑的特征空间中，从而提高了远距离消息传递的能力，并保持了计算效率。与现有的Cayley图和扩张图相比，SCGP方法具有更好的性能，同时减少了推理延迟，提高了可扩展性和内存占用率，特别适用于分层和模块化图结构的处理。
### Conclusion
SCGP方法在标准节点分类和图分类基准上的实验结果表明，其性能接近甚至超过了扩张图和重布图GNN基线。此外，SCGP特别适用于处理分层和模块化图结构，因其具有减少推理延迟、提高可扩展性和低内存占用率的特点，适用于实时和资源受限的应用场景。
## 814. `cs.LG` - 离散扩散在大规模语言和多模态模型中的应用：综述 [PDF](https://arxiv.org/pdf/2506.13759), [HTML](https://arxiv.org/abs/2506.13759)
### Authors
Runpeng Yu,Qi Li,Xinchao Wang
### Background
以往的研究主要集中在自回归（AR）模型上，但dLLMs和dMLLMs引入了多令牌并行解码范式，采用全注意力机制和去噪生成策略。这种范式能够自然地支持并行生成、精细输出控制和动态感知，这些都是自回归模型难以实现的能力。工业界和学术界越来越多的d(M)LLM模型展示了与自回归模型相当的性能，同时具有高达10倍的推理速度加快。这些进展表明，离散扩散模型有望成为基于传统自回归方法的传统人工智能的替代方案。
### Innovation
dLLMs和dMLLMs采用多令牌并行解码范式，利用全注意力机制和去噪生成策略，显著提高了模型的生成效率和灵活性，解决了自回归模型难以实现的功能，提升了模型的实用性和可拓展性。
### Conclusion
本文综述了离散扩散语言模型（dLLMs）和离散扩散多模态语言模型（dMLLMs）的研究进展。论文追溯了dLLMs和dMLLMs的发展历史，概述了其背后的数学框架，列出了常用建模方法，分类了代表性模型，并分析了关键的培训、推理和量化技术。全文讨论了这些模型在语言、视觉语言、生物学等多个领域的应用，并展望了未来的研究和部署方向。
## 815. `cs.LG` - 使用PRISM捕捉多义性：一个多概念特征描述框架 [PDF](https://arxiv.org/pdf/2506.15538), [HTML](https://arxiv.org/abs/2506.15538)
### Authors
Laura Kopf,Nils Feldhus,Kirill Bykov,Philine Lou Bommer,Anna Hedström,Marina M.-C. Höhne,Oliver Eberle
### Background
自动可解释性研究旨在识别神经网络特征中嵌入的概念，以增强人们对模型行为的理解。在自然语言处理（NLP）的大语言模型（LLMs）背景下，目前的自动神经元级特征描述方法面临两个主要挑战：鲁棒性有限以及假设每个神经元只编码一个概念（单一语义），尽管有越来越多的证据显示多义性。这一假设限制了特征描述的表达能力，并限制了它们捕捉模型内部所有行为的能力。
### Innovation
我们引入了Polysemantic FeatuRe Identification and Scoring Method（PRISM），这是一种专门设计来捕捉LLMs特征复杂性的新框架。与许多NLP中的自动可解释性方法不同，PRISM产生更细致的描述，能够同时考虑单一语义和多义性行为。
### Conclusion
我们将PRISM应用于LLMs，并通过与现有方法的广泛基准测试，证明我们的方法能够产生更准确和忠实的特征描述，不仅提高了描述的整体质量（通过描述评分），还能够捕捉到当存在多义性时的独特概念（通过多义性评分）。
## 816. `cs.LG` - TESSERA：为地球表征与分析提供的预计算FAIR全球像素嵌入 [PDF](https://arxiv.org/pdf/2506.20380), [HTML](https://arxiv.org/abs/2506.20380)
### Authors
Zhengpeng Feng,Clement Atzberger,Sadiq Jaffer,Jovana Knezevic,Silja Sormunen,Robin Young,Madeline C Lisaius,Markus Immitzer,Toby Jackson,James Ball,David A. Coomes,Anil Madhavapeddy,Andrew Blake,Srinivasan Keshav
### Background
地球观测（EO）卫星数据虽然免费获取并能解决全球重要挑战，但数据质量因云层和光照条件差异而不佳。传统的复合方法虽然用于提升数据质量，但会去除时相现象信号。此外，使用监督机器学习映射复合像素至任务特定类别需依赖大量精确标注数据，而此类数据通常难以获取。
### Innovation
TESSERA是一个像素级别的基础模型，能够从EO时间序列中生成128维的隐空间嵌入，并仅需少量标签进行任务特定训练，实现多项复杂任务的顶级性能。TESSERA通过两个编码器结合光学数据与10m分辨率的合成孔径雷达后向散射系数来生成嵌入，再与多层感知机融合生成全球年度嵌入图。该模型在五个不同的下游任务中表现优于或接近于最先进的任务特定模型和其他基础模型，且具有易于使用、大规模和高精度的特点：没有其他开放的基础模型能够提供具有全球、年度覆盖的10m分辨率预计算输出。
### Conclusion
TESSERA在地球表征与分析中具有前所未有的易用性、规模和准确性，可实现多种任务的高性能，并通过与现有任务特定模型和其他基础模型的对比表明其优越性。
## 817. `cs.LG` - 算法公平性：不仅仅是一个纯技术属性，而是社会和技术的属性 [PDF](https://arxiv.org/pdf/2506.12556), [HTML](https://arxiv.org/abs/2506.12556)
### Authors
Yijun Bian,Lei You,Yuya Sasaki,Haruka Maeda,Akira Igarashi
### Background
近年来，人工智能（AI）和机器学习（ML）系统在社会影响重大的领域中的迅速部署，引起了对其可信度的关注，包括潜在的歧视行为。在算法公平性方面的研究产生了大量的数学定义和度量标准，但这些定义和度量标准自身以及外界存在许多持续的误解和局限性，例如在公平性的理解上缺乏共识、现有的度量标准主要针对二元群集设置且在交叉环境中处理过于表面化。
### Innovation
本文批判性地指出了这些误解，并提出公平性不能单纯归结为技术上的限制。通过概念分析和实证分析展示了现有公平度量在复杂现实场景下适用性有限，挑战了精确度与公平性之间的不兼容观点和不同公平度量之间的不兼容性。提出了设计公平度量时应考虑的三个原则，认为这些发现将有助于弥合技术形式化与社会现实之间的差距，并应对现实世界AI/ML的部署挑战。
### Conclusion
相信这些研究结果能够减少技术形式化与社会现实之间的差距，并应对AI/ML在现实世界的部署挑战。
## 818. `cs.LG` - 结合记忆与空间：状态空间神经算子 [PDF](https://arxiv.org/pdf/2507.23428), [HTML](https://arxiv.org/abs/2507.23428)
### Authors
Nodens F. Koren,Samuel Lanthaler
### Background
本文提出了时间依赖偏微分方程（PDEs）解算子学习的紧凑架构——状态空间神经算子（SS-NO）。通过对结构化状态空间模型（SSMs）进行扩展，将其应用于时空模型，本文引入了两个关键机制：自适应阻尼机制和可学习的频率调制机制，这为长时间依赖关系的捕获提供了一个参数高效的统一框架。
### Innovation
本文提出了一种新的架构——状态空间神经算子（SS-NO），它结合了结构化状态空间模型（SSMs）和神经算子，引入了自适应阻尼机制和可学习的频率调制机制。此外，通过将SSMs与卷积架构联系起来，该研究证明了具有全视域的卷积架构的通用性定理，并且实验结果表明SS-NO在各种PDE基准测试中表现优异，同时使用参数比竞争方法少得多。进一步的因子化变体在2D问题上也展示了可扩展的性能。
### Conclusion
本文的结果强调了在算子建模中阻尼和频率学习的有效性，并展示了轻量级因子化解耦是一种高效的大型PDE学习补充途径。
## 819. `cs.LG` - 渐增批次大小下拟双曲动量的渐近与非渐近收敛性 [PDF](https://arxiv.org/pdf/2506.23544), [HTML](https://arxiv.org/abs/2506.23544)
### Authors
Kento Imaizumi,Hideaki Iiduka
### Background
动量方法最初是为了在确定性设置下的凸目标函数中表现出优于随机梯度下降（SGD）的性能而被引入的。尽管动量方法在深度神经网络等随机非凸优化问题中广泛使用，但在这些环境中的理论效果仍然是有限的。拟双曲动量（QHM）算法是对各种动量方法的一种概括，旨在更好地理解动量类算法的整体特性。本文提供了在批次大小逐渐增加的情况下，mini-batch QHM的渐近和非渐近收敛结果，证明了渐近收敛需要学习率递减或批次大小递增。而且，学习率递减会负面影响非渐近收敛，因此展示了使用无学习率递减的渐增批次大小的mini-batch QHM策略的有效性。实验证明，即使批次大小有限制增加，也可以为神经网络训练带来好处。
### Innovation
本文提供了在批次大小逐渐增加的情况下，mini-batch QHM的渐近和非渐近收敛结果。证明了综渐近收敛需要学习率递减或批次大小递增，而且展示了使用无学习率递减的渐增批次大小的mini-batch QHM策略的有效性。
### Conclusion
即使批次大小有限制增加，也可以为神经网络训练带来好处。
## 820. `cs.LG` - 基于梯度印记追踪的深度强化学习 [PDF](https://arxiv.org/pdf/2507.09087), [HTML](https://arxiv.org/abs/2507.09087)
### Authors
Esraa Elelimy,Brett Daley,Andrew Patterson,Marlos C. Machado,Adam White,Martha White
### Background
在深度强化学习（RL）中实现快速且稳定的离策略学习极具挑战性。现有方法主要依赖于简单且高效的半梯度时差（TD）方法，但容易发散。虽然更为理论化的Gradient TD（GTD）方法具有较强的收敛保证，但在深度强化学习中应用较少。近年来，引入了广义投影贝尔曼误差（$bar{text{PBE}}$），使GTD方法能高效地使用非线性函数逼近。然而，这项工作仅限于一阶方法，存在信用分配缓慢且样本需求量大的问题。
### Innovation
本文扩展了广义$bar{text{PBE}}$目标，支持基于$frac{1-beta}{1-beta^tau}$回报的多步信用分配，并推导出三种基于梯度的方法来优化这一新目标。同时，作者提供了两种视图形式：与经验回放兼容的向前视角和与流式算法兼容的向后视角。实验结果显示，所提算法在MuJoCo和MinAtar环境中分别优于PPO和StreamQ。
### Conclusion
本文提出了结合广义$bar{text{PBE}}$目标的多步信用分配方法，并验证了其在各种环境下的优越性能，证明了该方法的有效性。
## 821. `cs.LG` - 关于高维度数据集中特征选择的(无)意义 [PDF](https://arxiv.org/pdf/2508.03593), [HTML](https://arxiv.org/abs/2508.03593)
### Authors
Bhavesh Neekhra,Debayan Gupta,Partha Pratim Chakrabarti
### Background
特征选择（FS）通常被认为能提升预测性能并识别出有意义的特征。研究中发现，即使在高维度数据集中，少量随机选取的特征子集（0.02-1%）也能够匹配甚至超过完整特征集和特征选择的预测性能，这是在28个多样化的数据集中得出的结果（涵盖微阵列、宏样本和单细胞RNA测序、质谱分析、成像等）。这引发了一个问题，即如果某些选定的特征与随机选择的特征表现大致相同，那么选择特定特征的重要性何在？
### Innovation
研究结果显示少量随机选择的特征子集能够达到甚至超越完整特征集和特征选择的性能，这挑战了过去认为通过计算方法选出的特征能可靠地捕捉到有意义信号的观点。研究强调需要在解读选择后的特征之前进行严格的验证，在计算基因组学等领域尤为重要。
### Conclusion
任何随机选取的子集特征与特定选定的特征表现相当，甚至更好的情况下，表现出极低的性能差异，因此特征选择的过程并不一定能够标示出真正重要的特征，反而强调了在高维度数据集中，特征选择的有效性和实际意义需要更严格的验证。
## 822. `cs.LG` - PVPO：基于预估价值的政策优化方法在代理推理中的应用 [PDF](https://arxiv.org/pdf/2508.21104), [HTML](https://arxiv.org/abs/2508.21104)
### Authors
Wenfeng Feng,Penghong Zhao,Guochao Jiang,Chuzhan Hao,Yuewei Zhang,Guohua Liu,Hao Wang
### Background
无监督强化学习方法，尤其是组策略，因其在复杂任务中的高效性而受到广泛关注。然而，这些方法高度依赖于策略内部的多次采样和比较来估计优势，这可能导致策略陷入局部最优，并增加计算成本。
### Innovation
本文提出了一种名为PVPO的强化学习方法，通过优势参考锚点和数据预采样的方式增强了算法的效率。具体而言，利用参考模型提前采样，并使用计算出的奖励分值作为参考锚点。PVPO方法有效纠正了内部组别比较引入的累积偏差，并显著减少了训练过程中对采样次数的依赖。此外，参考模型在数据预采样期间可以评估样本难度，从而有效选择高收益数据以提高训练效率。并且，PVPO与其它先进的无监督强化学习算法兼容且互补。在两个领域的九个数据集上进行的实验表明，PVPO达到了最优性能（SOTA）。
### Conclusion
我们的方法不仅展示了强大的跨任务泛化能力，还展示了适应不同规模模型的可扩展性能。
## 823. `cs.LG` - 基于SHRINK压缩的时间序列数据高效直接分析 [PDF](https://arxiv.org/pdf/2503.13246), [HTML](https://arxiv.org/abs/2503.13246)
### Authors
Guoyou Sun,Panagiotis Karras,Qi Zhang
### Background
半监督学习方法结合时间序列数据的压缩与分析成为了应对大数据流量挑战和可持续数据通信的关键。虽然深度学习方法常用于语义编码和解码，但对于时间序列数据的序列特性和高计算成本，尤其是资源受限的物联网环境中，处理起来仍存在困难。现有的数据压缩方法不能满足目标导向通信系统的性能需求。
### Innovation
提出了一个利用SHRINK压缩算法直接分析时间序列数据的新方法，在基于异常检测的实验中，该方法在不损失性能的情况下显著降低了运行时间和数据访问量。与未压缩数据的基准方法相比，该方法最差情况下的性能差异仅为1%，平均运行时间缩短四倍，并仅访问大约10%的数据量，这使得在有限的存储和计算能力的边缘设备上进行数据分析成为可能。
### Conclusion
本文方法提供了在物联网应用中对压缩的时间序列数据进行高效且可靠的异常检测分析能力，同时实现了高压缩率和数据传输量减少。
## 824. `cs.LG` - Riemannian Batch Normalization: A Gyro Approach [PDF](https://arxiv.org/pdf/2509.07115), [HTML](https://arxiv.org/abs/2509.07115)
### Authors
Ziheng Chen,Xiao-Jun Wu,Bernhard Schölkopf,Nicu Sebe
### Background
标准化层对深度学习至关重要，但它们的欧几里得形式对于位于流形上的数据是不充分的。另一方面，机器学习中的许多黎曼流形具有陀螺结构，这可以使欧几里得神经网络扩展到非欧几里得域，这样做在理论上是合理的。受此启发，该研究引入了GyroBN，这是一种基于陀螺群的原理性黎曼批标准化框架。
### Innovation
该研究提出了GyroBN，这是在陀螺群上的一种原理性黎曼批标准化框架。研究建立了两个必要条件——伪还原和陀螺等距旋动，以确保GyroBN在样本统计方面有理论上的控制，并表明这些条件对机器学习中所有已知的陀螺群都成立。框架还包括了几种现有的黎曼标准化方法的特例，并在其上实例化了七个代表性几何，包括格拉斯曼流形、五个恒定曲率空间和相关流形，从而推导出新的陀螺和黎曼结构来实现这些实例化。
### Conclusion
在这些几何结构上进行了实验，证明了GyroBN的有效性。研究代码可从以下链接获取：this https URL
## 825. `cs.LG` - AI for Scientific Discovery is a Social Problem [PDF](https://arxiv.org/pdf/2509.06580), [HTML](https://arxiv.org/abs/2509.06580)
### Authors
Georgia Channing,Avijit Ghosh
### Background
虽然人工智能有潜力加速科学发现，但其优势并未均匀分布。技术障碍如稀缺数据、碎片化标准和计算资源不平等获取都是重要原因，但作者认为主要障碍在于社会和机构层面。社会叙事中对廉价“AI科学家”的期待、低估数据和基础设施贡献、激励机制不一致以及领域专家与机器学习研究人员之间的差距都制约了影响。
### Innovation
作者提出了四个相互关联的挑战：社区功能失调、研究优先级与上游需求不一致、数据碎片化和基础设施不平等。作者认为这些问题的根源在于文化和组织实践，并提出了需要技术创新的同时，还需要有意识的社区建设、跨学科教育、共享基准和可访问基础设施。
### Conclusion
作者呼吁重新定义AI在科学中的应用为集体社会项目，强调可持续合作和公平参与是技术进步的前提。
## 826. `cs.LG` - CARD：一种基于缓存辅助并行推测性解码框架（通过查询和修正范式加速大语言模型推理） [PDF](https://arxiv.org/pdf/2508.04462), [HTML](https://arxiv.org/abs/2508.04462)
### Authors
Enyu Zhou,Kai Sheng,Hao Chen,Xin He
### Background
推测性解码（SD），其中临时模型提供多个候选标记供目标模型并行验证，已被证明能够在加速LLM推理方面发挥巨大潜力。然而，现有的SD方法遵循严格的‘先推测后验证’范式，导致顺序流程限制了性能和临时模型的容量。此外，在候选序列中拒绝一个标记会使其后的所有标记无效，导致在推测阶段浪费计算。
### Innovation
提出了一个基于缓存辅助的并行推测性解码框架CARD，采用新颖的查询和修正范式。该方法将推测过程从验证过程分离：临时模型填充共享缓存，目标模型同时修正推测轨迹。这可以近似以推测速度进行推理，有效利用临时模型的效率无需额外的模型微调。
### Conclusion
实验结果表明，CARD显著优于现有的先进方法，在不需要任何模型微调的情况下，相较于传统的自回归解码，加速效果可高达4.83倍。
## 827. `cs.LG` - 同币的两个方面：图基础模型中的模型退化和表示坍塌 [PDF](https://arxiv.org/pdf/2509.08401), [HTML](https://arxiv.org/abs/2509.08401)
### Authors
Xunkai Li,Daohan Su,Sicheng Liu,Ru Zhang,Zhenjun Li,Bing Zhou,Rong-Hua Li,Guoren Wang
### Background
受大型语言模型（LLMs）成功的启发，设计了GFMs（图基础模型），用于从多领域带属性的图中学习最优的嵌入函数，以便下游跨任务的一般性。在多种架构中，Graph VQ-MAE因其能够将拓扑结构和来自多个领域的文本属性同时编码到具有清晰语义边界的离散嵌入空间中而脱颖而出。尽管具有潜力，但领域一般化冲突在GFMs中造成了微妙的陷阱。本文分析了这些冲突，提出了两种体现它们的现象：现象一：模型退化，编码器和代码本无法捕捉输入的多样性；现象二：表示坍塌，隐藏嵌入和代码本向量因狭窄表示子空间的约束而无法保持语义可分离性。
### Innovation
提出了一种称作MoT的解决方案：信息微调（Information Tinker）以解决两个现象，通过边级语义融合策略和领域感知路由机制的混合代码本提高信息容量；正则化微调（Regularization Tinker）利用两种额外的正则化改进我们在信息微调中的梯度监督。MoT作为一种灵活的架构，遵循GFMs的缩放法则，提供可控的模型规模。
### Conclusion
实验结果表明，MoT在22个数据集中，在6个领域中的监督、少量样本和零样本场景中实现了显著改进。
## 828. `cs.LG` - 基于Q学习的Whittle索引的无线联邦学习中的自适应客户端选择 [PDF](https://arxiv.org/pdf/2509.13933), [HTML](https://arxiv.org/abs/2509.13933)
### Authors
Qiyue Li,Yingxin Liu,Hang Qi,Jieping Luo,Zhizhang Liu,Jingjin Wu
### Background
研究无线联邦学习中的客户端选择问题，目标是减少达到一定学习精度所需的总时间。由于服务器无法直接观察客户端的状态变化，这些变化影响了计算和通信效率。
### Innovation
提出了一种名为WILF-Q的可扩展且高效的方法，该方法使用Q学习自适应地学习和更新与每个客户端相关的近似Whittle指数，并依据指数选择客户端。与其他现有方法相比，WILF-Q不需要明示客户端状态转换或数据分布的知识，使其适用于实际部署的无线联邦学习环境。
### Conclusion
实验结果表明，WILF-Q在学习效率方面显著优于现有基准策略，为无线联邦学习中的客户端选择提供了一种稳健且高效的方案。
## 829. `cs.LG` - 多模态自适应估计用于时间呼吸道疾病爆发 [PDF](https://arxiv.org/pdf/2509.08578), [HTML](https://arxiv.org/abs/2509.08578)
### Authors
Hong Liu,Kerui Cen,Yanxing Chen,Zige Liu,Dong Chen,Zifeng Yang,Chitin Hon
### Background
及时而稳健的流感发病率预测对于公共卫生决策至关重要。
### Innovation
MAESTRO（多模态自适应估计时间呼吸道疾病爆发），这是一个创新的综合框架，将先进的频谱-时间建模与多模态数据融合（包括监测、网络搜索趋势和气象数据）相结合，并通过自适应加权和分解复杂的时间序列模式，实现了稳健而准确的预测。
### Conclusion
MAESTRO 在超过11年的香港流感数据上（排除新冠疫情期间）表现出色，R平方为0.956，达到业界领先水平。广泛的消融实验验证了其多模态和频谱-时间组件的显著贡献。该模块化、可重复的管道已公开发布，以促进部署并扩展到其他地区和病原体，提供了一个强大的流行病学预测工具。
## 830. `cs.LG` - LiMuon: Light and Fast Muon Optimizer for Large Models [PDF](https://arxiv.org/pdf/2509.14562), [HTML](https://arxiv.org/abs/2509.14562)
### Authors
Feihu Huang,Yuning Luo,Songcan Chen
### Background
当前，大型模型在人工智能领域得到广泛应用，因此高效训练大型模型得到广泛关注。尤其对于大型模型的矩阵结构参数，已有专门的Muon优化器被设计出来。尽管有一些研究表明广泛使用Muon优化器，但现有Muon及其变种仍面临高样本复杂度或高内存需求的问题。
### Innovation
本文提出了一种基于动量的方差减小技术和随机奇异值分解的轻量级快速Muon优化器（LiMuon）。与现有Muon及其变种相比，LiMuon具有更低的内存需求。同时，本文证明了在光滑条件下，LiMuon具有$O(boldsymbol rho^{-3})$的样本复杂度，用于找到非凸随机优化的$boldsymbol rho$-稳态解。与现有的Muon优化器的收敛分析主要依赖严格Lipschitz光滑假设不同，本文还证明了在泛化光滑条件下，LiMuon具有$O(boldsymbol rho^{-3})$的样本复杂度。
### Conclusion
实验证明了训练DistilGPT2和ViT模型时，LiMuon优化器的有效性。
## 831. `cs.LG` - KVCompose：基于复合标记的高效结构化KV缓存压缩 [PDF](https://arxiv.org/pdf/2509.05165), [HTML](https://arxiv.org/abs/2509.05165)
### Authors
Dmitry Akulov,Mohamed Sana,Antonio De Domenico,Tareq Si Salem,Nicola Piovesan,Fadhel Ayed
### Background
大型语言模型（LLMs）依赖键值（KV）缓存进行高效的自回归解码，但缓存大小随上下文长度和模型深度线性增长，成为长上下文推理中的主要瓶颈。先前的KV缓存压缩方法要么强制执行僵硬的启发式方法，要么破坏张量布局，要么需要特殊计算内核。因此，该文提出了一种基于注意力引导和逐层自适应复合标记的简单而有效的KV缓存压缩框架。该方法通过聚合注意力分数估计标记的重要性，独立选择特定注意力头的标记，并将它们排列成遵从现有推理引擎所需的均匀缓存结构的复合标记。全局分配机制进一步根据每层上的信息标记自适应地调整保留预算，为具有信息标记的层分配更多的容量。这种方法在大大减少内存消耗的同时保持了准确率，并且在几乎所有情况下都优于先前的结构化和半结构化方法。关键的是，该方法与标准推理管道完全兼容，为高效部署长上下文LLMs提供了一个实用且可扩展的解决方案。
### Innovation
提出了一种基于注意力引导和逐层自适应复合标记的简单而有效的KV缓存压缩框架。该方法通过聚合注意力分数估计标记的重要性，独立选择特定注意力头的标记，并将它们排列成遵从现有推理引擎所需的均匀缓存结构的复合标记。此外，提出了一种全局分配机制，根据每层上的信息标记自适应地调整保留预算。这种方法在大大减少内存消耗的同时保持了准确率，并且在几乎所有情况下都优于先前的结构化和半结构化方法。关键的是，该方法与标准推理管道完全兼容。
### Conclusion
该方法通过聚合注意力分数估计标记的重要性，独立选择特定注意力头的标记，并将它们排列成遵从现有推理引擎所需的均匀缓存结构的复合标记。全局分配机制进一步根据每层上的信息标记自适应地调整保留预算，为具有信息标记的层分配更多的容量。这种方法在大大减少内存消耗的同时保持了准确率，是高效部署长上下文LLMs的一种实用且可扩展的解决方案。
## 832. `cs.LG` - ForestColl：在异构网络架构上实现最高吞吐量的集体通信 [PDF](https://arxiv.org/pdf/2402.06787), [HTML](https://arxiv.org/abs/2402.06787)
### Authors
Liangyu Zhao,Saeed Maleki,Yuanhong Wang,Zezhou Wang,Ziyue Yang,Hossein Pourreza,Arvind Krishnamurthy
### Background
随着现代深度神经网络（DNN）模型变得越来越大，加速器之间的集体通信（如allreduce等）成为性能瓶颈。在今天的异构和多样化网络架构面前，设计高效的通信调度是非常具有挑战性的。本文介绍了ForestColl工具，它可以为任何网络拓扑生成理论最优的带宽调度。
### Innovation
ForestColl通过构建广播/聚合生成树作为通信调度，实现了理论上的最优性。其调度生成需要多项式时间并且高度可扩展。它支持所有类型的网络架构，包括交换架构和直接加速器连接。在AMD MI250和NVIDIA DGX A100 & H100集群上的测试显示，ForestColl不仅在各种设置中表现出显著的性能优势，而且在大模型训练中也优于供应商自己的优化通信库。此外，它在生成效率和生成速度上也超过了其他最先进的调度生成技术。
### Conclusion
ForestColl是一种为任何网络拓扑生成理论最优带宽调度的工具，能够为AMD MI250和NVIDIA DGX A100 & H100集群带来显著的性能提升，并超越了现有的最先进的调度生成技术。
## 833. `cs.LG` - 结构为本：透过可学习的边掩码实现脑图数据高效精神诊断的结构增强 [PDF](https://arxiv.org/pdf/2509.09744), [HTML](https://arxiv.org/abs/2509.09744)
### Authors
Mujie Liu,Chenze Wang,Liping Chen,Nguyen Linh Dan Le,Niharika Tewari,Ting Dang,Jiangang Ma,Feng Xia
### Background
由于标注的大脑网络数据有限，准确且可解释的精神疾病诊断面临挑战。现有的自监督学习（SSL）方法虽然提供了解决方案，但这些方法经常依赖可能破坏脑图中关键结构语义的数据增强策略。因此，需要一种能够保持结构语义完整性的脑图表示学习方法来应对这一挑战。
### Innovation
本文提出了一种名为SAM-BG的两阶段框架，用于学习脑图表示，同时保持结构语义完整性。预训练阶段对一个小的标注子集进行训练，以捕捉关键的结构语义；在自监督学习阶段，提取的结构先验指导结构感知的数据增强过程，使模型能够学习更具有语义意义和鲁棒性的表示。实验结果表明，SAM-BG在小标注数据集上的性能优于现有方法，并且能够发现具有临床意义的连接模式，从而提高诊断的可解释性。
### Conclusion
在两个实际的精神病学数据集上的实验表明，SAM-BG比最先进的方法表现出更优的性能，特别是在小标注数据设置中，并能够揭示具有临床意义的连接模式，以增强可解释性。
## 834. `cs.LG` - 超越捷径：通过神经崩溃视角的无偏差学习 [PDF](https://arxiv.org/pdf/2405.05587), [HTML](https://arxiv.org/abs/2405.05587)
### Authors
Yining Wang,Junjie Sun,Chenyue Wang,Mi Zhang,Min Yang
### Background
近期研究发现了一种有趣的现象，称为神经崩溃。当神经网络在训练中建立了特征空间与训练目标之间的正确关联时，其最后一层特征和分类器权重会塌缩成一个稳定而对称的结构。本文将神经崩溃的研究扩展到了有偏差的数据集上，其中特征具有不平衡的属性。研究观察到，模型容易陷入捷径学习的陷阱，在训练早期形成有偏差且未塌缩的特征空间，且难以逆转，这限制了泛化能力。
### Innovation
本文借鉴了最近关于主训练的启发，提出了一个新的避免捷径学习框架，而无额外的训练复杂度。该框架利用了神经崩溃结构，设计了基于神经崩溃结构的便捷捷径，鼓励模型跳过简单的捷径，自然地捕捉内在关联。实验结果表明，该方法在训练过程中诱导了更好的收敛性能，并在合成和真实的有偏差数据集上取得了最新的泛化性能。
### Conclusion
本方法在训练过程中诱导出了更好的收敛性能，并在合成和真实的有偏差数据集上实现了最先进的泛化性能。该框架提出的便捷捷径设计能够有效避免学习捷径，提高模型的泛化能力。
## 835. `cs.LG` - DPANet：用于多变量时间序列预测的双金字塔注意力网络 [PDF](https://arxiv.org/pdf/2509.14868), [HTML](https://arxiv.org/abs/2509.14868)
### Authors
Qianyang Li,Xingjun Zhang,Shaoxun Wang,Jia Wei
### Background
长期时间序列预测（LTSF）受到建模跨越多个时间尺度和频率分辨率的复杂依赖性的挑战。现有方法，包括Transformer和基于MLP的模型，在捕捉这些相互交织的特性方面往往难以在统一且结构化的框架中完成。
### Innovation
提出了一种名为Dual Pyramid Attention Network (DPANet)的新型架构，该架构显式地解耦并同时建模了时间多尺度动力学和频谱多分辨率周期性。DPANet构建了两个并行金字塔：基于逐级下采样的时间金字塔和基于带通滤波的频率金字塔。模型的核心是跨金字塔融合块，该块通过跨注意力机制促进对应金字塔级别之间深层次的交互信息交换。该融合过程自粗到细，使得全局上下文能够指导局部表示学习。
### Conclusion
在公共基准上的广泛实验表明，DPANet在性能上达到了最先进的水平，显著优于先前的模型。代码可以在本链接查阅：this https URL。
## 836. `cs.LG` - TGPO: 树导向偏奋试优化方法用于稳健的网页代理强化学习 [PDF](https://arxiv.org/pdf/2509.14172), [HTML](https://arxiv.org/abs/2509.14172)
### Authors
Ziyuan Chen,Zhenghui Zhao,Zhangye Han,Miancan Liu,Xianhang Ye,Yiqing Li,Hongbo Min,Jinkui Ren,Xiantao Zhang,Guitao Cao
### Background
随着大型语言模型和视觉-语言模型的迅猛发展，将大型模型用作Web代理已成为自动化网络交互的关键。然而，使用强化学习训练Web代理面临诸如归因偏差、标注成本过高以及奖励稀疏性等严重挑战。该研究旨在解决以上问题，提出了一种名为Tree-Guided Preference Optimization (TGPO)的离线增强学习框架，通过树状结构轨迹表示法合并途经路径中的语义等价状态来消除标签冲突。此外，还引入了一种过程奖励模型，通过子目标进度、冗余检测和动作验证自动化生成细粒度奖励。实验结果显示，该方法在Online-Mind2Web及自构造C-WebShop数据集上的表现显著优于现有方法，具有更高的成功率和更少的多余步骤。
### Innovation
1. 提出了Tree-Guided Preference Optimization (TGPO)框架，通过树状结构轨迹表示法解决标签冲突问题。2. 引入了过程奖励模型，能够自动生成细粒度奖励。3. 设计了动态权重机制，重点训练影响大的决策点。
### Conclusion
TGPO架构在增强学习训练Web代理方面具有显著优势，相较于现有方法，它不仅提高了成功率，还减少了冗余步骤。
## 837. `cs.LG` - 使用弱监督解耦内context学习中的潜在变化 [PDF](https://arxiv.org/pdf/2410.01508), [HTML](https://arxiv.org/abs/2410.01508)
### Authors
Josip Jukić,Jan Šnajder
### Background
内context学习（ICL）使大规模语言模型能够通过在提示中条件化于标记示例的方式实现少量示例学习。尽管这种方法具有灵活性，但它在演示数量增加时会表现出不稳定性，特别是在提示长度增加的情况下。
### Innovation
论文提出了一种参数高效的解耦方法，将ICL作为一种弱监督源，通过教师生成伪标签并使用轻量级适配器进行预测来解耦演示的影响和查询的影响。这种方法能够有效地进行推理，并且可以与新的演示保持兼容。
### Conclusion
实验结果显示，该方法在内域和跨域任务上均提高了泛化能力、稳定性和效率，表现优于标准的ICL和先前的解耦方法。
## 838. `cs.LG` - Mind the Gap: Data Rewriting for Stable Off-Policy Supervised Fine-Tuning [PDF](https://arxiv.org/pdf/2509.15157), [HTML](https://arxiv.org/abs/2509.15157)
### Authors
Shiwan Zhao,Xuyang Zhao,Jiaming Zhou,Aobo Kong,Qicheng Li,Yong Qin
### Background
监督微调（SFT）大规模语言模型是一个离策学习问题，其中专家演示来自固定的策略，而训练目标是优化目标策略。重要采样是纠正这种策略分布不匹配的标准工具，但当策略差异较大时，会导致权重偏斜、高方差和不稳定的优化。现有方法通过KL惩罚或裁剪被动限制更新，而非主动减少策略差异。
### Innovation
提出了一种简单有效的数据重写框架，主动缩小策略差异后进行训练。对于每个问题，正确模型生成的解决方案保留为合适的策略数据，而错误的解决方案则通过引导重解进行修改，仅在需要时返回专家演示。这使训练分布与目标策略保持一致，降低方差并提高稳定性。为了处理重写后的剩余不匹配，训练过程中再应用重要采样，形成两阶段方法，结合数据级别对齐与轻量级优化级别修正。
### Conclusion
实验结果显示，这种方法在五个数学推理基准测试中相对于标准SFT方法和最先进的动态微调（DFT）方法具有持续且显著的改进。相关数据和代码可从该网址获取。
## 839. `cs.LG` - 通过判别性损失和高斯噪声注入训练更具鲁棒性的分类模型 [PDF](https://arxiv.org/pdf/2405.18499), [HTML](https://arxiv.org/abs/2405.18499)
### Authors
Hai-Vy Nguyen,Fabrice Gamboa,Sixin Zhang,Reda Chhaibi,Serge Gratton,Thierry Giaccone
### Background
深度神经网络对输入噪声的鲁棒性仍然是一个关键挑战，常见的噪声注入方法往往会降低干净数据的准确性。文献提出了一种新的训练框架，通过两种互补的目标来解决这一权衡。
### Innovation
提出了一个判别性损失函数应用在倒数第二层，以明确定义决策边界的形式增强特征辨别性和类别可分性；提出了类内特征对齐机制，将嘈杂数据簇拉近其干净对应物；理论分析表明，提高特征在加性高斯噪声下的稳定性隐式减小了softmax损失地形中的曲率，从而在没有显式曲率惩罚的情况下自然增强了鲁棒性；并通过理论证明低曲率导致更具鲁棒性的模型。
### Conclusion
该方法在标准基准和自定义数据集上验证了其有效性，显著增强了模型对各种干扰的鲁棒性，同时在干净数据上保持了高准确性，推动了噪声鲁棒深度学习的理解和实践。
## 840. `cs.LG` - 重新思考用于语音生成的说话人嵌入：捕获内部说话人多样性的子中心建模 [PDF](https://arxiv.org/pdf/2407.04291), [HTML](https://arxiv.org/abs/2407.04291)
### Authors
Ismail Rasim Ulgen,John H. L. Hansen,Carlos Busso,Berrak Sisman
### Background
在生成自然声音的语音时，建模人类语音中丰富的情感变化是必要的。尽管说话人嵌入通常被用作个性化语音生成的条件输入，但它们通常是为了 speaker recognition 而优化的，这会导致内部说话人变异性丧失。这种策略使它们在建模输出语音分布中的丰富变化方面不理想。
### Innovation
本文提出了一种新颖的说话人嵌入网络，在训练中每个说话人类别使用多个子中心而不是一个中心，而传统方法只使用一个中心。子中心建模允许嵌入捕捉更广泛的说话人特定变异性，同时保持分类性能。我们展示了所提出嵌入在声音转换任务上的有效性，合成语音自然度和情感表达性得到改善。
### Conclusion
所提出的说话人嵌入网络通过子中心建模提高了内部说话人变异性，在语音生成中表现出更好的自然度和情感表达性，为建模丰富的输出语音分布提供了新的方法。
## 841. `cs.LG` - 建模人类视觉系统：基于响应优化和任务优化的视觉模型、语言模型以及不同读出机制的比较见解 [PDF](https://arxiv.org/pdf/2410.14031), [HTML](https://arxiv.org/abs/2410.14031)
### Authors
Shreya Saha,Ishaan Chadha,Meenakshi Khosla
### Background
在过去十年中，关于灵长类动物视觉系统神经响应的预测建模取得了显著进展，这主要得益于各种深度神经网络（DNN）方法的发展。这些方法包括直接优化用于视觉识别的模型、通过对比目标实现跨模态对齐的模型、从零开始预测神经响应的方法，以及基于大规模视觉数据集预训练的大语言模型。各种不同的读出机制，从完全线性到空间特征因素分解方法，已被探索用于将网络激活映射到神经响应中。尽管存在这些多样化的方法，但是对于不同视觉区域内哪种方法表现最佳仍不清楚。
### Innovation
本研究系统地比较了不同方法以模型人类视觉系统，并探索了改进响应预测的替代策略。研究发现，在早期到中期的视觉区域，基于视觉输入的响应优化模型提供更好的预测准确性；而在更高级别的视觉区域，基于详细图像描述和任务优化的大语言模型提供最佳拟合。研究指出，提出了一个新的方案以根据语义内容调节感受野和特征图，这使所有模型和脑区的现有最佳表现提高了3-23%的准确率。研究通过对比分析这些建模方法，识别出视觉皮层中的三个不同类型区域：一个主要对输入中的感知特征敏感的区域，这些特征未被语言描述捕捉；另一个对反映语义信息的细微视觉细节敏感；第三个对与语言内容相一致的抽象全局含义敏感。研究还强调了读出机制的作用。
### Conclusion
这些发现为构建更精确的视觉系统模型提供了关键见解。
## 842. `cs.LG` - FOVAL: 集成时空序列建模的无需校准且主体不变的注视深度估计方法在多样化的注视追踪数据集上 [PDF](https://arxiv.org/pdf/2408.03591), [HTML](https://arxiv.org/abs/2408.03591)
### Authors
Benedikt W. Hosp
### Background
准确的眼球固定深度估计对于扩展现实（XR）、机器人技术以及人机交互等领域具有重要意义。然而，当前的方法大多依赖于用户的特定校准过程，限制了其可扩展性和易用性。因此，迫切需要一种无需校准且具有跨任务一致性的方法来提高注视深度估计的准确性和通用性。
### Innovation
本文提出了一种名为FOVAL的新方法，它通过结合长短期记忆（LSTM）网络进行时空序列建模，融合主体不变的特征工程和归一化处理，实现了一种无需校准且具有跨个体一致性的注视深度估计方法。FOVAL在有限且噪声较大的注视数据场景下，相较于变压器、时间卷积网络和卷积神经网络，表现出更优秀的效果，并能通过留一交叉验证和跨数据集验证显示出9.1cm的平均绝对误差和强的通用性。此外，还分析了跨个体变异性及领域转移问题，进一步展示了模型的鲁棒性和适应性。
### Conclusion
FOVAL的可扩展性和准确性使其非常适合实际部署，为眼球固定深度估计领域带来了新的突破。
## 843. `cs.LG` - 无需重新交互的动态策略融合以实现用户对齐 [PDF](https://arxiv.org/pdf/2409.20016), [HTML](https://arxiv.org/abs/2409.20016)
### Authors
Ajsal Shereef Palattuparambil,Thommen George Karimpanal,Santu Rana
### Background
深度强化学习（RL）策略虽然在任务奖励方面是最佳的，但可能不适用于人类用户的个人偏好。为了确保与用户偏好的对齐，一个简单的解决方案是重新训练智能体使其适应用户的具体偏好。然而，这样的奖励函数通常无法直接获取，重新训练智能体的成本可能会非常高。为解决这一问题，本文提出了一种更实际的方法——通过人类反馈将已经训练好的策略适配到特定用户的需要，而无需重新交互环境。这种方法通过推断用户的意图使用轨迹级别的反馈，并结合已有的任务策略，使用理论上有支持的动态策略融合方法。由于该方法在学习任务策略时就收集了人类反馈，因此无需额外的环境交互，具有零样本的特点。
### Innovation
本文提出了一种无需重新交互环境的策略融合方法，通过轨迹级的人类反馈动态调整已经训练好的智能体策略，使其更好地满足用户的具体需求。这种方法通过理论上的动机策略融合，实现了在保持任务执行效果的同时，适应用户偏好，无需额外的环境交互，是一种高效实用的方案。
### Conclusion
本文在多种环境下实验证明，提出的动态策略融合方法能够始终如一地执行预期的任务，同时也遵循用户的具体需要。
## 844. `cs.LG` - FLOAT: 基于生成运动潜空间匹配的音频驱动对话白肖像 [PDF](https://arxiv.org/pdf/2412.01064), [HTML](https://arxiv.org/abs/2412.01064)
### Authors
Taekyung Ki,Dongchan Min,Gyeongsu Chae
### Background
随着基于扩散的生成模型的迅速发展，肖像图像动画取得了显著成果。然而，这些模型在生成时空一致的视频和快速采样方面仍然面临挑战，因为它们具有迭代采样的性质。
### Innovation
本文提出了FLOAT，这是一种基于流匹配生成模型的音频驱动对话白肖像生成方法。该方法利用学习到的正交运动潜空间，而非基于像素的潜空间，使生成和编辑时空一致的运动变得更加高效。为了实现这一点，引入了一种基于变换器的向量场预测器，并具有有效的逐帧条件机制。此外，该方法还支持语音驱动的表情增强，使表达性运动的自然融入成为可能。
### Conclusion
广泛的实验表明，在视觉质量、运动保真度和效率方面，本文的方法领先于现有的音频驱动对话白肖像生成方法。
## 845. `cs.LG` - 有界门量子电路的线性属性高效学习 [PDF](https://arxiv.org/pdf/2408.12199), [HTML](https://arxiv.org/abs/2408.12199)
### Authors
Yuxuan Du,Min-Hsiu Hsieh,Dacheng Tao
### Background
现代量子计算机中大量量子比特的状态空间极其复杂，这使得我们难以通过经典的模拟或量子态 tomography 完整捕捉其动力学行为。近期量子学习理论的发展促使了一个关键问题：对于具有 d 个可调 RZ 门和 G-d Clifford 门的大量子电路，能否通过变化的经典输入生成的测量数据高效学习其线性属性？
### Innovation
我们证明了为了达到较小的预测误差，样本复杂性需要线性地随着 d 增长，并且相应地计算复杂性可能随着 d 指数级地增长。为此，我们提出了一个基于核的方法，利用经典阴影和截断的三角级数扩展，以实现预测精度和计算开销之间的可控权衡。
### Conclusion
我们的研究结果推进了量子计算中两个关键领域：具有实用用途的量子算法的探索和基于学习的量子系统认证。通过在多个场景下进行数值仿真，验证了我们的提议的有效性，这些场景涵盖了量子信息处理协议、哈密顿量模拟以及多达 60 个量子比特的变分量子算法。
## 846. `cs.LG` - 动态神经好奇心增强自主目标发现的学习灵活性 [PDF](https://arxiv.org/pdf/2412.00152), [HTML](https://arxiv.org/abs/2412.00152)
### Authors
Quentin Houbre,Roel Pieters
### Background
机器人在自主学习新目标方面仍存在复杂问题。为解决这一问题，本文提出了一种新的模型，即通过好奇心影响学习的灵活性。该模型借鉴了LC-NE系统及认知坚持和视觉习惯化等认知过程，将好奇心和注意结合在一起。
### Innovation
本文的创新在于提出了一个根植于LC-NE系统及认知过程中动态神经好奇心的模型。该模型使用动态神经场来建模好奇心、习惯化和坚持，然后通过多层感知器实现了前向和逆向模型，从而支持不同方向推动物体的学习任务。这种模型能够根据物体的不同展现出多样的学习轨迹，并展示了在学习相似目标和在探索与利用之间连续切换时的有趣属性。
### Conclusion
本文提出的方法通过动态神经好奇心实现了学习灵活性的增强，对于发现和学习新目标具有显著效果。该方法展示了机器人在处理不同学习任务时的适应性和多样性。未来的研究可以进一步探讨此模型在现实世界中的应用潜力。
## 847. `cs.LG` - 噪声高维张量估计中隐向量排列恢复 [PDF](https://arxiv.org/pdf/2412.14650), [HTML](https://arxiv.org/abs/2412.14650)
### Authors
Gérard Ben Arous,Cédric Gerbelot,Vanessa Piccolo
### Background
本文研究了多尖峰张量问题中高维梯度流的动力学，目标是从噪声高斯张量观测中估计未知信号向量（尖峰）。具体地，研究了最大似然估计方法，其涉及优化一个强非凸随机函数。本研究确定了梯度流高效恢复所有尖峰所需的样本复杂度，而不对信噪比（SNR）之间分离性进行任何假设。
### Innovation
研究确定了在无需对SNR之间分离性进行假设的情况下，梯度流高效恢复所有尖峰所需的样本复杂度。具体而言，该研究结果提供了确保恢复尖峰到置换要求下的样本复杂度。本研究建立在我们姊妹论文[Ben Arous, Gerbelot, Piccolo 2024]的工作之上，该论文研究了拉增动力学，并确定了确保唯一性恢复尖峰的信号与噪声分离条件及样本复杂度。
### Conclusion
在恢复过程中，估计量与隐藏向量之间的相关性按顺序增强。这些相关性变得显著的顺序依赖于其初始值和相应的SNR，最终确定了恢复尖峰的排列。
## 848. `cs.LG` - iCBIR-Sli: 2D切片嵌入的可解释内容基础图像检索 [PDF](https://arxiv.org/pdf/2501.01642), [HTML](https://arxiv.org/abs/2501.01642)
### Authors
Shuhei Tomoshige,Hayato Muraki,Kenichi Oishi,Hitoshi Iyatomi
### Background
当前的脑部MRI图像搜索方法主要依赖于基于文本的方法，存在显著的内容基于图像检索（CBIR）系统的需求。直接将3D脑部MRI图像应用于机器学习模型能够有效地学习脑部结构，但建立通用模型需要大量的训练数据。虽然有研究表明，考虑深度方向并利用连续2D切片的模型在3D数据的分割和分类任务中表现出色，但在使用这些2D切片时仍存在关注点。具体来说，使用一般的2D切片可能导致病理特征和深度方向信息的不连续性被忽略。此外，到目前为止，还没有人尝试开发一个能够保留整个脑部结构信息的实用CBIR系统。
### Innovation
本文提出了一种可解释的脑部MRI图像的CBIR方法，命名为iCBIR-Sli（Interpretable CBIR with 2D Slice Embedding），首次利用一系列2D切片。iCBIR-Sli通过有效聚合切片信息，实现低维表示，具备高完整度、高可用性、高鲁棒性和高互操作性，这些特性对于有效的CBIR至关重要。
### Conclusion
在使用五个人工公开的脑部MRI数据集（ADNI2/3, OASIS3/4, AIBL）进行检索评估实验中，iCBIR-Sli在top-1检索性能方面表现出色（宏F1 = 0.859），与专门为分类设计的深度学习模型相当，无需外部分类器。此外，该方法具有高可解释性，能够清晰地识别出与所搜索疾病相关的脑区域。
## 849. `cs.LG` - 高效实时改进语言模型文本生成 [PDF](https://arxiv.org/pdf/2501.07824), [HTML](https://arxiv.org/abs/2501.07824)
### Authors
Joonho Ko,Jinheon Baek,Sung Ju Hwang
### Background
大型语言模型（LLMs）在多种自然语言任务中表现出色，但它们有时会生成事实错误的答案。之前的工作主要集中在识别LLM生成过程中的错误并进一步优化，但这种验证和改进方法在部署时相对较慢，因为它们只在LLM生成完成（从第一个词到最后一个词）后才开始验证响应。此外，观察到LLMs在生成错误词后，后续生成的词更容易事实错误。
### Innovation
我们提出了Streaming-VR（流式验证和改进），这是一种新型方法，旨在提高LLM输出验证和改进的效率。Streaming-VR允许在生成过程中实时验证和纠正生成的词，类似于流式处理过程。通过另一个LLM实时检查和改进每个词集，确保即时准确性和效率。
### Conclusion
通过在多个数据集上的全面评估，我们证明了这种方法不仅提高了LLM的信息准确性，还比前几代改进方法更高效。
## 850. `cs.LG` - 版权与竞争：利用非结构化数据估算供给与需求 [PDF](https://arxiv.org/pdf/2501.16120), [HTML](https://arxiv.org/abs/2501.16120)
### Authors
Sukjin Han,Kyungho Lee
### Background
本文探讨了在低成本技术（如生成性人工智能）不断增强的背景下，版权在创造性产业中的竞争和福利效应。创造性产品通常具有复杂且高维度的非结构化属性（例如图像和文本），如何量化这些非结构化属性并对视觉相似性进行衡量是研究中的一个挑战。
### Innovation
本文创新性地利用了最具代表性的设计产品字体，通过字体全球最大的市场数据进行实证研究。采用了神经网络嵌入来量化非结构化特征，并通过空间计量经济分析和事件研究法展示了视觉特征的空间竞争。进一步开发了一个基于版权相似性约束的需求与供给结构模型，揭示了消费者对不同设计的需求偏好和生产者的低成本模仿优势。
### Conclusion
本研究的结果显示，版权保护可以通过鼓励产品位置的重新分配来提高消费者的福利。最优政策将取决于版权与成本降低技术之间的相互作用。
## 851. `cs.LG` - SCoT: 直线一致轨迹用于预训练扩散模型的提炼 [PDF](https://arxiv.org/pdf/2502.16972), [HTML](https://arxiv.org/abs/2502.16972)
### Authors
Zhangkai Wu,Xuhui Fan,Hongyu Wu,Longbing Cao
### Background
预训练扩散模型常用于从随机噪声生成干净数据（例如图像），形成噪声与相应的清洁图像的配对。这些预训练模型的精炼过程可以看作是构建更高效的采样路径以加速采样。一致性模型精炼通过开发一致的投影函数来调节路径，但采样效率仍是一个问题。纠偏流方法强制路径为直线以实现更快的采样，但依赖数值ODE求解器，可能会引入近似误差。
### Innovation
提出了一种名为SCoT的直线一致轨迹模型，结合了两者的优势，同时生成具有一致性和直线性质的路径。通过目标策略平衡这两种特性：一是调节SCoT映射的梯度，使其保持恒定；二是确保路径一致性。
### Conclusion
广泛的数据实验表明，SCoT模型在效率和效果上都表现出色。
## 852. `cs.LG` - 从传统方法到基础模型的多模态适应与泛化进展 [PDF](https://arxiv.org/pdf/2501.18592), [HTML](https://arxiv.org/abs/2501.18592)
### Authors
Hao Dong,Moru Liu,Kaiyang Zhou,Eleni Chatzi,Juho Kannala,Cyrill Stachniss,Olga Fink
### Background
在实际应用场景中，实现领域适应与泛化存在显著挑战，模型需要适应或泛化到未知的目标分布。此外，由于不同模态的特性，扩展这些能力到未见过的多模态分布，即多模态领域适应与泛化，更是具有挑战性的任务。近年来，尽管在行动识别到语义分割等多个应用领域取得了显著进展，但在领域泛化方面乏善可陈。随着大规模预训练多模态基础模型的兴起，如CLIP，利用这些模型提升适应与泛化性能或将其应用于下游任务的工作受到启发。
### Innovation
本论文是首次全面综述从传统方法到基础模型的多模态领域适应与泛化的进展，涵盖了四个主要主题：（1）多模态领域适应；（2）多模态测试时适应；（3）多模态领域泛化；（4）借助多模态基础模型的领域适应与泛化；（5）多模态基础模型的适应。每个主题均正式定义了问题并详尽综述了现有方法。此外，还分析了相关数据集和应用，突显了开放挑战和潜在的未来研究方向。
### Conclusion
为了保持这些综述的时效性，作者维护了一个活跃的资源库，其中包括最新的文献。
## 853. `cs.LG` - FLARE: 忠实逻辑辅助推理和探索 [PDF](https://arxiv.org/pdf/2410.11900), [HTML](https://arxiv.org/abs/2410.11900)
### Authors
Erik Arakelyan,Pasquale Minervini,Pat Verga,Patrick Lewis,Isabelle Augenstein
### Background
现代问题回答（QA）和推理方法通常基于大型语言模型（LLMs），使用如Chain-of-Thought (CoT)等提示技术，期望产生对问题空间和范围更加细致的探索与推理。然而，这些方法在生成与模型中间步骤推理一致的输出方面存在困难。在另一个极端，如 Faithful CoT (F-CoT) 等神经符号方法尝试将LLMs与外部符号求解器结合，这些方法虽然声称具有高度的忠实性，但通常需要为代码生成专门训练的模型，并且在处理模糊或难以严格形式化的问题时表现不佳。
### Innovation
本文提出了一种新型可解释方法FLARE，用于使用任务分解遍历问题空间。利用LLM规划解决方案，将查询软形式化为事实和谓词，并使用逻辑编程代码执行模拟，通过详尽的多跳搜索遍历定义的空间。这种方法允许我们针对生成的代码计算推理过程的忠实度，并在多跳搜索中分析推理步骤，无需依赖外部求解器。FLARE 方法在9个不同推理基准中有7个基准达到最佳结果，表明模型的忠实性与整体性能正相关，且FLARE能够指出多跳搜索过程中关键且必要的推理因素，从而使正确答案得以实现。
### Conclusion
FLARE 方法在多种推理基准测试上达到最佳结果，表明在理解和执行问题空间时，模型忠实性和最终表现之间的正相关关系，同时FLARE能够精确识别出关键推理步骤，支持高效正确的解答生成。
## 854. `cs.LG` - AttentionDrop: 一种用于Transformer模型的新正则化方法 [PDF](https://arxiv.org/pdf/2504.12088), [HTML](https://arxiv.org/abs/2504.12088)
### Authors
Mirza Samad Ahmed Baig,Syeda Anshrah Gillani,Abdul Akbar Khan,Shahid Munir Shah,Muhammad Omer Khan
### Background
基于Transformer的架构在自然语言处理、计算机视觉和语音处理等多个任务中取得了最先进的性能。然而，它们巨大的容量常常导致过拟合，尤其是在训练数据有限或噪声较大时。
### Innovation
本文提出了一种统一的随机正则化技术家族，即AttentionDrop及其三个不同变体。这些技术直接作用于自我注意力分布。具体来说，Hard Attention Masking随机将每个查询的前k个注意力logits置零以鼓励多样化的上下文利用，Blurred Attention Smoothing通过对注意力logits应用动态高斯卷积来弥散过于尖锐的分布，而Consistency-Regularized AttentionDrop通过KL基的一致性损失确保在多个独立的AttentionDrop扰动下输出的稳定性。
### Conclusion
研究结果表明，AttentionDrop在准确性、校准和对抗鲁棒性方面始终优于标准的Dropout、DropConnect和R-Drop基准方法。
## 855. `cs.LG` - 量子核方法中的双下降现象 [PDF](https://arxiv.org/pdf/2501.10077), [HTML](https://arxiv.org/abs/2501.10077)
### Authors
Marie Kempkes,Aroosa Ijaz,Elies Gil-Fuster,Carlos Bravo-Prieto,Jakob Spiegelberg,Evert van Nieuwenburg,Vedran Dunjko
### Background
双下降现象挑战了传统的统计学习理论，表明在某些情况下，更大的模型不一定导致未见过的数据性能降低。这一反直觉行为已经在各种经典的机器学习模型，尤其是现代神经网络架构中被观察到，但在量子机器学习领域仍不清楚其中的原因。通过分析经典线性回归和随机矩阵理论的见解，本文证明了在量子特征空间中的线性回归模型可以表现出双下降行为，并通过不同实际数据集和系统规模下的数值实验进一步证实了测试错误峰值的存在，这是双下降现象的特征之一。
### Innovation
本文通过抽象经典线性回归和随机矩阵理论的见解，阐明了量子特征空间中的线性回归模型可以表现出双下降行为，并通过多组数值实验，进一步验证了这一现象，为量子模型在现代过参数化范围内的操作提供了证据，表明其不会发生过拟合，这可能开启了超越传统统计学习理论的更好学习性能的道路
### Conclusion
本文的发现提供了证据，表明量子模型可以操作在现代过参数化范围内而不会发生过拟合，这可能为量子机器学习领域提出了新的改进学习性能的途径，超越了传统统计学习理论。
## 856. `cs.LG` - 基于时间差分一致性的混合自编码器在可信赖物理系统中的高效可持续异常检测 [PDF](https://arxiv.org/pdf/2504.06320), [HTML](https://arxiv.org/abs/2504.06320)
### Authors
Michael Somma
### Background
近年来，对关键基础设施尤其是水分配系统实施的网络攻击数量增加，这主要是由于数字化进程加快以及物联网设备和工业控制系统（ICS）的融合。这些网络物理系统（CPS）引入了新的安全漏洞，因此需要强大的自动化入侵检测系统（IDS）来防范潜在威胁。
### Innovation
本文通过利用传感器数据的时间相关性，将物理原理整合到机器学习模型中，并优化边缘应用中的计算效率，以应对异常检测的关键挑战。提出了基于时间差分一致性（TDC）损失的混合自编码器（hybrid TDC-AE）方法，该方法结合了确定性节点和传统统计节点，以处理非确定性过程。该方法实现了最佳分类性能，并将异常检测时间提高了3%，同时在不需要领域特定知识的情况下超越了BATADAL挑战的领导者。
### Conclusion
该方法证明了利用物理启发的一致性原则有助于增强异常检测能力，增强了网络物理系统（CPS）的韧性，并且这种解决方案是可持续和高效的。
## 857. `cs.LG` - G2D2：梯度导向的离散扩散模型在逆问题求解中的应用 [PDF](https://arxiv.org/pdf/2410.14710), [HTML](https://arxiv.org/abs/2410.14710)
### Authors
Naoki Murata,Chieh-Hsin Lai,Yuhta Takida,Toshimitsu Uesaka,Bac Nguyen,Stefano Ermon,Yuki Mitsufuji
### Background
近年来，文献已经有效地利用了训练在连续变量上的扩散模型作为解决逆问题的先验。值得注意的是，基于离散的扩散模型在使用离散压缩表示合适时（如图像和运动生成模式）取得了很好的性能。然而，这些模型的离散和非可微性限制了它们在连续空间逆问题中的应用。因此，本文提出了一种新方法，利用基于离散扩散的生成模型作为先验来解决线性逆问题。该方法通过利用来自分类分布和连续放松技术构造的变分分布来近似真实后验分布，解决了现有问题。此外，该方法使用星形噪声过程来缓解传统离散扩散模型中存在的吸收状态问题，证明了其性能与连续扩散技术相当，但在GPU内存消耗上更低。
### Innovation
提出了一种利用基于离散扩散的生成模型作为先验的新方法来解决线性逆问题。该方法通过变分分布和连续放松技术来近似真实的后验分布，克服了传统离散扩散模型的局限性，特别是在吸收状态方面。同时使用星形噪声过程解决了这些问题，并且该方法在保持与连续扩散技术相当性能的同时，GPU内存消耗更低。
### Conclusion
本文提出的方法通过利用基于离散扩散的生成模型近似真实的后验分布，并通过星形噪声过程和变分分布解决了逆问题中的离散化和吸收状态问题。实验结果表明，该方法在多个基准测试上表现优秀，且在GPU内存消耗上低于传统的连续扩散方法。该论文的研究成果为解决逆问题提供了一种新的高效方法。
## 858. `cs.LG` - SuPreME：一种多模态心电图表征学习的监督预训练框架 [PDF](https://arxiv.org/pdf/2502.19668), [HTML](https://arxiv.org/abs/2502.19668)
### Authors
Mingsheng Cai,Jiuming Jiang,Wenhao Huang,Che Liu,Rossella Arcucci
### Background
心血管疾病是全球范围内导致死亡和残疾的主要原因之一。心电图（ECG）对于诊断和监测心脏健康至关重要，但获取大规模标注的心电图数据集需要大量的人力和时间。虽然近期的心电图自监督学习（eSSL）方法能够学习特征但无需大量标注，但它无法捕捉细微的临床含义，并且需要大量的任务特定微调。
### Innovation
本文提出了一种名为SuPreME的多模态心电图表示学习的监督预训练框架。SuPreME利用大型语言模型（LLMs）从ECG报告实体中一次性离线提取结构化的诊断标签，帮助去噪、标准化心脏概念并提高临床表示学习。通过融合心电图信号与心脏查询文本而不是固定标签，SuPreME实现了一次性分类新条件，无需进一步微调。评估结果显示，SuPreME在六组下游数据集上实现了77.20%的零样本AUC性能，超过最先进的自监督学习方法4.98%。研究结果表明SuPreME能够有效利用结构化的临床相关知识为高质量的心电图表示提供支持。
### Conclusion
SuPreME通过充分利用结构化的临床知识，实现了高质量的心电图表征学习，特别是零样本分类性能显著优于现有的自监督学习方法。
## 859. `cs.LG` - 无梯度交互粒子系统的顺序贝叶斯实验设计 [PDF](https://arxiv.org/pdf/2504.13320), [HTML](https://arxiv.org/abs/2504.13320)
### Authors
Robert Gruhlke,Matei Hanu,Claudia Schillings,Philipp Wacker
### Background
该研究针对复杂系统，其中无法获得梯度信息的情况，提出了一种无梯度框架，用于顺序贝叶斯最优实验设计（BOED）。该框架结合了Ensemble Kalman Inversion (EKI) 与Affine-Invariant Langevin Dynamics (ALDI) 抽样器，两者都是无导数且基于集合的，旨在克服由嵌套期望带来的计算挑战。
### Innovation
研究提出了一种新的框架，该框架利用无梯度的Ensemble Kalman Inversion (EKI) 与Affine-Invariant Langevin Dynamics (ALDI) 抽样器来解决复杂的系统中的BOED问题。同时，为了应对嵌套期望的计算困难，引入了变分高斯近似和参数Laplace近似来提供可计算的EIG上界和下界，从而在高维空间和PDE限制的反问题中实现了实用的效用评估。
### Conclusion
通过从线性高斯模型到基于PDE的推断任务的数值实验展示了该框架的性能，突出了无导数方法的稳健性、准确性和效率。
## 860. `cs.LG` - 超越视觉和语言的面向部署的多模态AI [PDF](https://arxiv.org/pdf/2504.03603), [HTML](https://arxiv.org/abs/2504.03603)
### Authors
Xianyuan Liu,Jiayang Zhang,Shuo Zhou,Thijs L. van der Plas,Avish Vijayaraghavan,Anastasiia Grishina,Mengdie Zhuang,Daniel Schofield,Christopher Tomlinson,Yuhan Wang,Ruizhe Li,Louisa van Zeeland,Sina Tabakhi,Cyndie Demeocq,Xiang Li,Arunav Das,Orlando Timmerman,Thomas Baldwin-McDonald,Jinge Wu,Peizhen Bai,Zahraa Al Sahili,Omnia Alwazzan,Thao N. Do,Mohammod N.I. Suvon,Angeline Wang,Lucia Cipolina-Kun,Luigi A. Moretti,Lucas Farndale,Nitisha Jain,Natalia Efremova,Yan Ge,Marta Varela,Hak-Keung Lam,Oya Celiktutan,Ben R. Evans,Alejandro Coca-Castro,Honghan Wu,Zahraa S. Abdallah,Chen Chen,Valentin Danchev,Nataliya Tkachenko,Lei Lu,Tingting Zhu,Gregory G. Slabaugh,Roger K. Moore,William K. Cheung,Peter H. Charlton,Haiping Lu
### Background
多模态人工智能（AI）通过机器学习整合多种类型的数据，以提高跨不同学科（如健康护理、科学和工程）的理解、预测和决策能力。然而，大多数多模态AI的进展主要集中在视觉和语言数据模型上，而它们的部署仍然是一个关键挑战。现有的研究大多关注在数据和模型方面的中心化工作流程中，本文提倡一种注重部署的流程，将部署限制纳入早期阶段，以减少不可部署解决方案的可能性。研究还强调在多个层面的多模态深入整合和跨学科合作，以显著扩展研究范围，而不仅仅是视觉和语言。
### Innovation
本文提出了一种注重部署的多模态AI流程，将部署限制集成到早期开发阶段，以此互补注重数据和模型的中心化方法。此外，研究还促进了跨学科领域之间的深度整合，并识别了不同学科中多模态AI面临的常见挑战，以及探讨了三个实际应用场景，包括应对疫情、自主驾驶车辆设计和应对气候变化，汇集了医疗健康、社会科学、工程、科学、可持续发展和金融等多个领域的专业知识，以促进多学科对话和开放研究实践，加速面向部署的多模态AI的开发，为广泛的社会影响做出贡献。
### Conclusion
通过促进多学科对话和开放研究实践，我们的社区可以加快面向部署的多模态AI的发展，以实现广泛的社会影响。
## 861. `cs.LG` - 使用互动型NeoMedSys平台研究VIOLA-AI颅内出血模型的部署与优化 [PDF](https://arxiv.org/pdf/2505.09380), [HTML](https://arxiv.org/abs/2505.09380)
### Authors
Qinghui Liu,Jon E. Nesvold,Hanna Raaum,Elakkyen Murugesu,Martin Røvang,Bradley J Maclntosh,Atle Bjørnerud,Karoline Skogen
### Background
在放射学临床部署中，人工智能（AI）工具有许多挑战和机遇。这项研究描述了一种名为NeoMedSys的放射学软件平台，该平台旨在促进AI模型的高效部署和改进。研究在实际临床环境中运行了三个月，并专注于改善一种内部开发的AI模型（VIOLA-AI），该模型用于颅内出血检测（ICH）的性能提升.
### Innovation
NeoMedSys平台集成了部署、测试和优化AI模型的工具，以及基于网络的医学图像查看器、注释系统和医院范围的放射学信息系统。研究通过回顾和实时检查自动化出血检测和分割来改进VIOLA-AI。经过不断优化，分类敏感性显著提高至90.3%（从79.2%），特异性达到89.3%（从80.7%），整个样本的出血检测ROC分析显示AUC为0.949（从0.873），强调了实时放射科医生反馈的价值.
### Conclusion
NeoMedSys平台能够促进AI模型的迭代改进，显著提升诊断准确性。使用这种平台进行模型重新训练和实时优化可以显著提高颅内出血检测的敏感性和特异性，为临床实践中应用AI技术提供了实际的解决方案和参考价值.
## 862. `cs.LG` - 能否从实际文本中推断因果关系？ [PDF](https://arxiv.org/pdf/2505.18931), [HTML](https://arxiv.org/abs/2505.18931)
### Authors
Ryan Saklad,Aman Chadha,Oleg Pavlov,Raha Moraffah
### Background
理解并推断文本中的因果关系是人类认知的核心，对于推动大型语言模型（LLMs）向人工通用智能发展至关重要。现有对LLM因果推理能力的研究主要集中在合成生成的文本，这些文本中的因果关系简单且在文本中明确指出，无法反映真实世界任务的复杂性。本文探讨了LLMs是否能够从实际的文本中推断出因果关系，开发了一个源自实际学术文献的基准数据集，包括在长度、因果关系复杂性、领域和亚领域方面具有多样性的文本。本基准数据集是首个用于该任务的现实世界数据集。实验结果显示，LLMs在从实际文本推断因果关系时面临重大挑战，最佳模型的平均F1分数仅为0.477。通过对实际文本各个方面（共因的程度、图规模、文本长度、领域）的系统分析，本基准数据集提供了进一步研究LLM因果推理的有针对性的见解。
### Innovation
提出了首个用于评估LLM因果推理能力的现实世界数据集，涵盖了各种长度和复杂程度的因果关系，以及不同领域的文本。该基准数据集能够揭示实际文本中推断因果关系的挑战，并为未来的研究提供了有针对性的指导。
### Conclusion
现有的LLM在从实际文本推断因果关系时存在显著困难，尽管有一些模型表现尚可，但整体效果并不理想。通过本工作开发的基准数据集的实验证据，以及对复杂性因素的解释，可以进一步明确研究方向，以推动LLM因果推理能力的提升。
## 863. `cs.LG` - 在工作流程中的公平性：大型科技公司中机器学习从业者如何在推荐系统中处理公平性 [PDF](https://arxiv.org/pdf/2505.19441), [HTML](https://arxiv.org/abs/2505.19441)
### Authors
Jing Nathan Yan,Emma Harvey,Junxiong Wang,Jeffrey M. Rzeszotarski,Allison Koenecke
### Background
推荐系统（RS）在高风险领域的应用广泛，但当前系统可能受到偏见的影响，这类偏见可能导致社会性影响。尽管研究人员提出了一些方法来衡量和缓解这些偏见，但将学术理论转化为实践过程中存在固有的挑战。RS从业者需要平衡多个利益相关者（如提供方和用户）的利益，并在动态环境下来运作。为了更好地理解大型科技公司中从业者如何处理RS中的公平性问题，进行了一项半结构化的访谈研究。
### Innovation
研究通过半结构化的访谈调查了大型科技公司在推荐系统中如何处理公平性问题，特别是在技术团队如何在内部分析公平性以及与法律、数据和其他公平相关团队合作时考虑公平性。研究发现了几个关键挑战，包括在多利益相关者和动态公平环境中定义公平性的困难，以及公司内部的时间安排和团队协作沟通问题。这项研究提供了对RS社区的实际建议，包括HCI领域的研究者和从业者。
### Conclusion
研究确认了从业者的挑战，并提出了相关的建议来优化RS工作流程中的公平性处理。通过深入了解技术团队在设计推荐系统时考虑公平性的方法和解决方案，这项研究为改善RS公平性提供了重要见解。
## 864. `cs.LG` - 自动语音转录对说话人归属影响的研究 [PDF](https://arxiv.org/pdf/2507.08660), [HTML](https://arxiv.org/abs/2507.08660)
### Authors
Cristina Aggazzotti,Matthew Wiesner,Elizabeth Allyn Smith,Nicholas Andrews
### Background
说话人归属是从演讲者的演讲记录中识别该演讲者的一项任务，主要依赖于其语言使用模式。这一任务在音频不可用（例如被删除）或不可靠（例如匿名化语音）的情况下非常有用。以往的研究主要集中在使用人类标注者产生的演讲记录来辨别说话人的可行性上。然而，在现实世界中，我们往往只能获得由自动语音识别（ASR）系统生成的错误更多的演讲记录。
### Innovation
本研究是我们所知的首个全面探讨自动转录错误对说话人归属性能影响的研究。研究特别关注转录错误对说话人归属性能的负面影响程度，以及ASR系统的特性如何影响归属性能。研究发现，说话人归属对单词层面的转录错误表现出了令人惊讶的鲁棒性，并且恢复真实转录文本文档的目标与归属性能的关联性较小。
### Conclusion
总体而言，研究结果表明，使用ASR生成的、更易出错的转录记录进行说话人归属的结果与基于人工转录数据的归属结果一样好，甚至更好，可能是因为ASR的转录错误可以捕捉到表明说话人身份的特定特征。
## 865. `cs.LG` - 世界建模改进语言模型代理 [PDF](https://arxiv.org/pdf/2506.02918), [HTML](https://arxiv.org/abs/2506.02918)
### Authors
Shangmin Guo,Omar Darwiche Domingues,Raphaël Avalos,Aaron Courville,Florian Strub
### Background
在状态化环境中使用工具对大规模语言模型（LLMs）提出了独特的挑战，现有的测试时计算策略依赖于在环境中的重复试验，但这种策略在实践中是不实际的。因此，需要新的方法来增强LLMs在工具使用中的效果和可靠性。
### Innovation
这篇文章提出了一种名为Dynamics Modelling（DyMo）的新方法，该方法在LLMs的后训练过程中增加了一种状态预测能力，并结合了内部环境模型。此外，该研究还整合了内部环境模型到自我验证采样（SVS）中，从而显著提高了通过次数`pass^k`，并使模型能够拒绝不可靠的输出。这些创新方法大大增强了LLMs在工具使用中的有效性和可靠性。
### Conclusion
DyMo和SVS的结合大幅提升了LLMs在工具使用中的效果和可靠性，为无需反复查询或acles环境的可扩展计划强化学习（RL）方法开辟了一条道路。
## 866. `cs.LG` - 在持久同调和神经网络中扭结的作用 [PDF](https://arxiv.org/pdf/2506.03049), [HTML](https://arxiv.org/abs/2506.03049)
### Authors
Maria Walch
### Background
研究了包含拓扑数据分析的混合深度学习模型中的扭结作用，重点是自编码器。大多数TDA工具使用域系数，但这样会掩盖整数同调中存在的扭结特征。研究表明，扭结在编码过程中可能会丢失，在潜在空间中发生改变，并且在许多情况下不会被标准解码器重建。使用合成和高维数据，评价了扭结对扰动的敏感性和在多种自编码器架构中的可恢复性。研究表明，基于域的方法存在重大限制，强调了需要具有保存扭结信息的架构或损失项，以实现稳健的数据表示的需求。
### Innovation
研究表明，扭结在编码过程中可能会被丢失，在潜空间内发生改变，并在许多情况下无法通过标准解码器重建。使用合成和高维数据，评估了扭结对扰动的敏感性和在多种自编码器架构中的可恢复性。此研究揭示了基于域的方法的局限性，并强调了需要保护扭结信息的架构或损失项，以实现稳健的数据表示。
### Conclusion
研究发现基于域的方法存在重大限制，强调了需要具有保存扭结信息的架构或损失项，以实现稳健的数据表示。
## 867. `cs.LG` - 不牺牲1-一致性的高效强化学习增强缓存的健壮性 [PDF](https://arxiv.org/pdf/2507.16242), [HTML](https://arxiv.org/abs/2507.16242)
### Authors
Peng Chen,Hailiang Zhao,Jiaji Zhang,Xueyan Tang,Yixuan Wang,Shuiguang Deng
### Background
在线缓存问题的目标是在有限缓存大小的情况下，通过处理一系列请求来最小化缓存未命中。虽然基于学习的缓存算法能够实现理想的1-一致性，但缺乏健壮性保证。现有的健壮性方法要么牺牲1-一致性，要么引入显著的计算开销。
### Innovation
Guard是一个轻量级的健壮性增强框架，它可以提高广泛学习增强缓存算法的健壮性到$2H_k + 2$，同时保留其1-一致性。Guard实现了目前在一致性和健壮性之间最优秀的权衡，只需要$O(1)$的额外每请求开销，从而保持基算法原始的时间复杂度。广泛的实验结果验证了Guard在实际中的有效性。
### Conclusion
通过Guard，研究者成功在保持1-一致性的同时增强了学习增强缓存的健壮性，保持了便携性和效率。
## 868. `cs.LG` - cadrille：使用在线强化学习的多模态CAD重建 [PDF](https://arxiv.org/pdf/2505.22914), [HTML](https://arxiv.org/abs/2505.22914)
### Authors
Maksim Kolodiazhnyi,Denis Tarasov,Dmitrii Zhemchuzhnikov,Alexander Nikulin,Ilya Zisman,Anna Vorontsova,Anton Konushin,Vladislav Kurenkov,Danila Rukhovich
### Background
计算机辅助设计（CAD）在工程和制造中起着核心作用，使用户能够创建精确且可编辑的3D模型。以往的方法大多只利用单一输入模态（如点云、图像或文本）来重建CAD模型，这限制了方法的通用性和鲁棒性。为了改进这一现状，研究人员依赖于视觉-语言模型（VLM）的最新进展，提出了一种多模态CAD重建模型，能够同时处理三种输入模态。借鉴大规模语言模型（LLM）的训练方法，该模型采取两阶段流程：首先对大规模程序生成数据进行监督微调（SFT），然后利用在线反馈利用强化学习（RL）进一步微调。这种方法在不需要人工交互的情况下能提供更高质量的模型重建结果。文中还特别指出，这是首次使用在线RL方法对LLMs进行CAD任务的微调，并且在线RL算法（如团体相对偏好优化-GRPO）优于离线方法。 
### Innovation
1. 提出了一种多模态CAD重建模型，可以同时处理点云、图像和文本三种输入模态。2. 采用两阶段的训练流程：首先对大规模程序生成数据进行监督微调，然后利用在线反馈使用强化学习进行进一步微调。3. 这是首次将在线RL方法应用于LLMs以优化CAD任务的表现。4. 在DeepCAD基准测试中，证明了推荐方法的有效性，特别是在处理三种输入模态时均优于现有单一模态的方法；经过强化学习微调后，Cadrille在三个具有挑战性的数据集上取得了新的性能记录，包括一个实际应用数据集。
### Conclusion
通过对大规模程序生成数据进行监督微调，再利用在线反馈使用强化学习进行微调，Cadrille在多模态CAD重建中取得了显著效果。与之前的工作相比，该方法不仅提高了模型的鲁棒性和泛化能力，还在实际应用中实现了更好的性能。
## 869. `cs.LG` - MoCA: 多模态交叉遮罩自编码器在数字健康测量中的应用 [PDF](https://arxiv.org/pdf/2506.02260), [HTML](https://arxiv.org/abs/2506.02260)
### Authors
Howon Ryu,Yuliang Chen,Yacun Wang,Andrea Z. LaCroix,Chongzhi Di,Loki Natarajan,Yu Wang,Jingjing Zou
### Background
可穿戴设备能够实现生理和行为的持续多模态监测，但这些数据流的分析面临根本性的挑战，包括缺乏黄金标准标签和传感器数据的不完整。现有的自我监督学习方法已经显示出应对这些问题的潜力，但现有的多模态扩展仍有机会更好地利用同时记录的可穿戴传感器数据中的丰富的时序和跨模态相关性。因此，需要一个能够结合变压器架构与遮罩自编码器（MAE）方法，并明确利用传感模态之间相关结构的自我监督学习框架来解决这些问题。
### Innovation
我们提出了一种名为MoCA（多模态交叉遮罩自编码器）的新自我监督学习框架，它结合了变压器架构与遮罩自编码器方法，使用了一种合理的方法来遮蔽跨模态数据，从而利用模态之间的相关性结构。MoCA在重建和下游分类任务中表现出色，尤其在多样化基准数据集上的表现。我们还通过再生核希尔伯特空间框架建立了多模态MAE损失与核化典范相关分析之间基本联系的理论保证，这为相关性意识的遮罩策略设计提供了理论指导。这种方法不仅能够有效利用未标记的多模态可穿戴数据，还能处理模态缺失的问题，具有广泛的应用前景，特别是在数字健康领域。
### Conclusion
MoCA在多模态数据重建和分类任务中取得了显著性能提升，且通过理论分析提供了相关策略的设计指导，能够有效处理未标记和缺失模态数据，为数字健康领域的应用提供了创新解决方案。
## 870. `cs.LG` - 通过混合知识蒸馏实现高质量、低资源面部动画模型 [PDF](https://arxiv.org/pdf/2507.18352), [HTML](https://arxiv.org/abs/2507.18352)
### Authors
Zhen Han,Mattias Teye,Derek Yadgaroff,Judith Bütepage
### Background
高质量、鲁棒的语音驱动3D面部动画模型需要大量多样且高质量的音频-动画对数据集。虽然使用大规模预训练语音编码器可以增强面部动画模型的泛化能力，但这些模型往往过于庞大，只能在专用设备上进行离线推理。因此，该研究聚焦于游戏开发中实时、设备端的面部动画模型，并通过使用混合知识蒸馏结合伪标签解决了缺乏大数据集的问题。
### Innovation
引入了一种新的方法——混合知识蒸馏结合伪标签，它利用一个高性能的教师模型来训练非常小的学生模型。学生模型仅有卷积和全连接层组成，消除了对注意力上下文或递归更新的需求，从而大大降低了模型的内存占用，且仅需极少的未来音频上下文，并保持高质量的动画效果。这种方法使得实时设备端推理成为可能，是实现现实的、由模型驱动的数字角色的重要步骤。
### Conclusion
通过这种方法，模型的内存占用可以减少到最多3.4MB，并且所需的未来音频上下文延迟可减少到81毫秒，同时保持高质量的动画效果，为设备端推理铺平了道路。
## 871. `cs.LG` - PickleBall：基于Pickle的机器学习模型安全反序列化（扩展报告） [PDF](https://arxiv.org/pdf/2508.15987), [HTML](https://arxiv.org/abs/2508.15987)
### Authors
Andreas D. Kellas,Neophytos Christou,Wenxin Jiang,Penghui Li,Laurent Simon,Yaniv David,Vasileios P. Kemerlis,James C. Davis,Junfeng Yang
### Background
机器学习模型库如Hugging Face Model Hub促进了模型交换，但恶意行为者可以通过被篡改的模型传播恶意软件。现有防御措施如安全模型格式、限制性的加载政策和模型扫描器各有不足：在Hugging Face上流行的模型中有44.9%仍然使用不安全的pickle格式，15%的这些模型无法由限制性加载政策加载，而模型扫描器既有误报也有漏报。Pickle仍被广泛用于模型交换，因此机器学习社区缺乏一个透明的安全加载工具。
### Innovation
PickleBall是一个旨在帮助机器学习工程师安全加载基于Pickle的模型的工具。PickleBall静态分析给定的机器学习库源代码并计算一个定制策略来指定良性模型的安全加载行为。PickleBall在加载时间动态执行该策略，作为pickle模块的即插即用替换品。PickleBall能够在数据集中正确加载79.8%的良性Pickle模型，拒绝所有恶意例子，而现有模型扫描器无法识别已知恶意模型，最新的加载器加载良性模型比PickleBall少22%。PickleBall通过去除恶意Pickle模型随意函数调用的威胁，提高了攻击者依赖代码重用技巧的门槛。
### Conclusion
PickleBall在保障安全加载方面具有优势，能够正确识别并加载超过四分之三的良性Pickle模型，同时完全拒绝恶意模型。相比现有方法，PickleBall更可靠，为防止基于Pickle的恶意模型的进一步传播提供了更有效的解决方案。
## 872. `cs.LG` - MountainLion:一个多模态基于大语言模型的智能交易系统，实现可解释和自适应的金融交易 [PDF](https://arxiv.org/pdf/2507.20474), [HTML](https://arxiv.org/abs/2507.20474)
### Authors
Siyi Wu,Junqiao Wang,Zhaoyang Guan,Leyi Zhao,Xinyuan Song,Xinyu Ying,Dexu Yu,Jinhao Wang,Hanlin Zhang,Michele Pak,Yangfan He,Yi Xin,Jianhui Wang,Tianyu Shi
### Background
数字货币交易需要从多种模态中整合异质数据，传统的深度学习与强化学习方法通常需要大量训练数据，并将多样化输入转化为数值表示，但往往会牺牲其可解释性。近年来，基于大语言模型（LLM）的代理在处理多模态数据和支持复杂投资决策方面表现出色。现有研究表明，这些代理具有处理多种数据和辅助决策的强大能力。
### Innovation
MountainLion是一个多模态、多智能体系统，利用专门的LLM代理处理新闻文本、K线图和交易信号图，生成高质量的金融报告。系统设计中强调通过数据驱动的用户交互和问答功能实现报告和投资建议的持续修改。核心反思模块通过分析历史交易信号及其结果，实时调整报告分析、总结投资策略，提高投资绩效，增加投资者信心。
### Conclusion
实验证明，MountainLion系统系统化地丰富了技术价格触发器的宏观经济和资本流动信号，提供了一个更为可解释、稳健且实际的投资框架，从而提高了投资回报率并巩固了投资者的信心。
## 873. `cs.LG` - 构建稳健和适应性强的GenAI原生系统的基本设计原则和模式 [PDF](https://arxiv.org/pdf/2508.15411), [HTML](https://arxiv.org/abs/2508.15411)
### Authors
Frederik Vandeputte
### Background
生成式人工智能（GenAI）作为一种变革性技术，已经在多个应用领域展现出卓越的能力。然而，由于其不可预测性和低效率，GenAI在开发可靠和高效的人工智能赋能系统方面面临重大挑战。过去，缺乏将GenAI的认知能力与传统软件工程原则结合起来的方法，导致生成系统不够稳健、适应性差且效率低下。因此，本文倡导一种新的范式变革，即将GenAI的认知能力与传统软件工程原则相结合，以创建出更加稳健、适应性强和高效的系统。
### Innovation
本文提出了五个核心支柱——可靠性、卓越性、演进性、自我依赖性和保障，作为GenAI原生设计的基本原则，并提出了诸如GenAI原生细胞、有机基质和可编程路由器等架构模式，以引导创建出更加强健且能够自我演化的系统。此外，本文还概述了构建GenAI原生软件栈的关键要素，并从技术、用户采用、经济和法律等多方面讨论了这些系统的影响，强调了进一步验证和实验的必要性。
### Conclusion
本文旨在启发未来的相关研究，并鼓励相关社区采用和改进这一概念框架，进一步推动GenAI技术的发展和应用。
## 874. `cs.LG` - LongCat-Flash技术报告 [PDF](https://arxiv.org/pdf/2509.01322), [HTML](https://arxiv.org/abs/2509.01322)
### Authors
Meituan LongCat Team,Bayan,Bei Li,Bingye Lei,Bo Wang,Bolin Rong,Chao Wang,Chao Zhang,Chen Gao,Chen Zhang,Cheng Sun,Chengcheng Han,Chenguang Xi,Chi Zhang,Chong Peng,Chuan Qin,Chuyu Zhang,Cong Chen,Congkui Wang,Dan Ma,Daoru Pan,Defei Bu,Dengchang Zhao,Deyang Kong,Dishan Liu,Feiye Huo,Fengcun Li,Fubao Zhang,Gan Dong,Gang Liu,Gang Xu,Ge Li,Guoqiang Tan,Guoyuan Lin,Haihang Jing,Haomin Fu,Haonan Yan,Haoxing Wen,Haozhe Zhao,Hong Liu,Hongmei Shi,Hongyan Hao,Hongyin Tang,Huantian Lv,Hui Su,Jiacheng Li,Jiahao Liu,Jiahuan Li,Jiajun Yang,Jiaming Wang,Jian Yang,Jianchao Tan,Jiaqi Sun,Jiaqi Zhang,Jiawei Fu,Jiawei Yang,Jiaxi Hu,Jiayu Qin,Jingang Wang,Jiyuan He,Jun Kuang,Junhui Mei,Kai Liang,Ke He,Kefeng Zhang,Keheng Wang,Keqing He,Liang Gao,Liang Shi,Lianhui Ma,Lin Qiu,Lingbin Kong,Lingtong Si,Linkun Lyu,Linsen Guo,Liqi Yang,Lizhi Yan,Mai Xia,Man Gao,Manyuan Zhang,Meng Zhou,Mengxia Shen,Mingxiang Tuo,Mingyang Zhu,Peiguang Li,Peng Pei,Peng Zhao,Pengcheng Jia,Pingwei Sun,Qi Gu,Qianyun Li,Qingyuan Li,Qiong Huang,Qiyuan Duan,Ran Meng,Rongxiang Weng,Ruichen Shao,Rumei Li,Shizhe Wu,Shuai Liang
### Background
当前，为了应对大规模模型训练的效率和计算资源挑战，研究者们正在探索新的架构设计和技术来提高模型的性能。尤其是在混合专家模型（MoE）的领域，如何在保持模型性能的同时降低计算成本成为研究热点。
### Innovation
提出了一种名为LongCat-Flash的560亿参数混合专家模型，其创新点包括：（1）零计算专家设计，使得模型能够根据上下文需求动态分配计算资源，提升了资源使用效率；（2）短路连接的MoE设计，扩大了计算-通信重叠窗口，提高推理效率和吞吐量；（3）提出了一套综合的模型规模扩大框架，包括超参数传递、模型初始增长优化、多样化稳定性方案以及确定性计算方法，以确保模型训练的稳定性和可重复性。
### Conclusion
通过架构设计和基础设施的协同优化，LongCat-Flash在超过20万亿个令牌的数据集上完成训练，并在推理时实现了平均每秒超过100个令牌的速度，成本仅为每百万个输出令牌0.70美元。此模型在处理代理型任务时表现出色，其模型检查点已开源，以促进社区研究。
## 875. `cs.LG` - SyGra: 一种统一的图基框架，用于可扩展生成、质量标签和管理合成数据 [PDF](https://arxiv.org/pdf/2508.15432), [HTML](https://arxiv.org/abs/2508.15432)
### Authors
Bidyapati Pradhan,Surajit Dasgupta,Amit Kumar Saha,Omkar Anustoop,Sriram Puttagunta,Vipul Mittal,Gopal Sarda
### Background
大型语言模型（LLMs）的发展高度依赖于高质量数据集的支持，特别是在监督微调（SFT）和直接偏好优化（DPO）等任务中。目前，数据的准备过程在数据生成、质量评估和管理上存在挑战，特别是在确保生成高保真度和高质量数据方面存在不足，这限制了LLM培训的效率和效果。
### Innovation
本文提出的SyGra框架是一个模块化和配置驱动的合成数据生成框架，它使用了双阶段的质量标签机制结合启发式规则和LLM评估，自动过滤和评分来自OASST格式对话的数据，确保数据的高质量。该框架能够以最少的手动干预生成符合SFT和DPO应用场景的灵活结构化数据，提供了大规模生成和管理合成对话数据的解决方案，显著降低了数据准备的开销。
### Conclusion
结合这些创新，SyGra框架提供了一个强大的解决方案，以大规模生成和管理合成对话数据，显著提高了大型语言模型训练过程中的数据准备效率和质量。
## 876. `cs.LG` - 性能建模的难度、结构知识与机会：模块化性能建模的分析框架 [PDF](https://arxiv.org/pdf/2509.11000), [HTML](https://arxiv.org/abs/2509.11000)
### Authors
Omid Gheibi,Christian Kästner,Pooyan Jamshidi
### Background
现有性能影响模型有助于理解配置如何影响系统性能，但创建这些模型十分困难，因为配置空间呈指数增长。虽然灰盒方法利用了模块执行图等结构性知识来提升建模效果，但结构性知识、系统特性及其对模型改善的影响并不明确。本文通过正式研究结构特性（如模块数量）和知识水平如何影响改进模块性能建模的机会，并引入并量化了建模难度的概念。
### Innovation
本文通过合成系统模型进行受控实验，建立了一个分析矩阵来测量建模难度和结构知识的概念。研究显示建模难度主要受模块数量和每个模块的配置选项数影响。此外，结构知识和建模难度的提高都显著增加了改进机会，且不同性能指标受影响程度不同。
### Conclusion
本文发现，结构性知识在评估准确性方面更为关键，而在预测准确性方面，难度的作用更为显著。这些结果为系统设计者提供了行动指南，指导他们根据不同系统特性和任务目标合理分配时间和选择合适的建模方法。
## 877. `cs.LG` - 当安全不再是安全：评估机器学习模型共享的安全性 [PDF](https://arxiv.org/pdf/2509.06703), [HTML](https://arxiv.org/abs/2509.06703)
### Authors
Gabriele Digregorio,Marco Di Gennaro,Stefano Zanero,Stefano Longari,Michele Carminati
### Background
模型共享框架和专用枢纽的兴起使机器学习变得更加易于获取，但这些工具也带来了未被充分探索的安全风险，尤其是在从业人员和开发者的安全意识有限的情况下。因此，为了促进更加注重安全的机器学习模型共享文化，该研究评估了框架和枢纽的安全状况，评估了安全导向机制的效果，并调查了用户对模型共享安全叙事的看法。
### Innovation
该研究通过评估框架和枢纽的安全状况，分析了声称提供安全设置和完整模型共享的框架，揭示了六个0-day漏洞，这些漏洞允许任意代码执行。研究成果打破了模型共享问题大部分已得到解决且其安全可以保证的误区，同时明确指出了文件格式在共享过程中无法保证安全。
### Conclusion
研究结果表明，大多数框架和枢纽在安全方面仅部分解决了问题，常常将责任转嫁给用户。通过分析发现的安全漏洞显示了当前安全设置的脆弱性。此外，调查表明用户在面对安全叙事时认为安全设置是可以信赖的，尽管存在所示的漏洞。基于此，研究提出了加强模型共享生态系统安全性的建议。
## 878. `cs.LG` - 仅幅度条件下可泛化的全息重构通过幅度扩散先验 [PDF](https://arxiv.org/pdf/2509.12728), [HTML](https://arxiv.org/abs/2509.12728)
### Authors
Jeongsol Kim,Chanseok Lee,Jongin You,Jong Chul Ye,Mooseok Jang
### Background
希尔伯特光程重构是相干成像中的一个基本但病态的逆问题，因为强度和相位之间存在非线性耦合。现有方法通常需要基于真实相位数据的训练，这对于使用扩散模型从衍射强度中恢复幅度和相位来说是不必要的，且通常成本高昂。
### Innovation
本文提出了一种新颖的现成解决方案，使用仅针对对象幅度训练的扩散模型来从衍射强度中恢复幅度和相位。通过预测修正采样框架并为幅度和相位分别提供梯度估计，该方法能够在无需真实相位数据的背景下重构复杂场，从而提供一种成本效益高的成像逆问题解决方案。
### Conclusion
该方法通过广泛的模拟和实验验证了其在不同物体形状、成像系统配置和模态（包括镜片式设置）中的鲁棒泛化能力。此外，基于简单幅度数据（如聚苯乙烯颗粒）训练的扩散先验成功重构了复杂的生物组织结构，展示了该方法的可适应性。这项工作为计算成像中的非线性逆问题提供了经济高效的通用解决方案，并为全息成像以及其它相干成像应用奠定了基础。
## 879. `cs.LG` - SENTRA: 选择下一个词的变换器在LLM文本检测中的应用 [PDF](https://arxiv.org/pdf/2509.12385), [HTML](https://arxiv.org/abs/2509.12385)
### Authors
Mitchell Plyler,Yilun Zhang,Alexander Tuzhilin,Saoud Khalifah,Sen Tian
### Background
随着生成式预训练语言模型（LLM）能力的增强和普及，它们被不当使用的可能性也在增加。因此，识别未明确声明为LLM生成的文本成为了重要的研究问题，这是本文的研究背景。
### Innovation
本文提出了一种新颖的、通用的监督式LLM文本检测模型——SE�힓ded-Next-Token tRAnsformer（SENTRA）。SENTRA利用选择下一个词的概率序列，并通过大规模未标注数据的对比预训练。结果显示，SENTRA在各种文本领域中的表现显著优于现有的基准模型，尤其是在域外设置中表现出色。
### Conclusion
本文通过实验展示了SENTRA在三个流行的公共数据集上的优良性能，证明了其作为一种通用分类器的有效性。
## 880. `cs.LG` - 分布式训练效率表征：基于功率、性能和热能视角 [PDF](https://arxiv.org/pdf/2509.10371), [HTML](https://arxiv.org/abs/2509.10371)
### Authors
Seokjin Go,Joongun Park,Spandan More,Hanjiang Wu,Irene Wang,Aaron Jezghani,Tushar Krishna,Divya Mahajan
### Background
随着大型语言模型（LLMs）的迅速扩展，模型的训练负载已远远超过了单节点分析的极限，这使得研究人员需要深入理解这些模型在大规模、多GPU系统中的行为。本文通过全面探究LLM在各种真实工作负载和硬件平台上的训练情况，包括NVIDIA H100/H200和AMD MI250 GPU，分析不同并行策略（张量、管道、数据和专家）下的密集和稀疏模型，评价这些策略对硬件利用率、功耗和热行为的影响。此外，本文还评估了诸如激活重新计算和计算通信重叠等优化方法的有效性。
### Innovation
本文的创新在于：1）全面探究了LLM在不同硬件平台上的训练效率；2）分析了多种并行策略对模型训练的影响；3）评估了各种优化方法的有效性；4）揭示了训练性能受硬件、系统架构和模型执行复杂交互的影响。
### Conclusion
在通信受限的环境中，相较于通过添加更多GPU来扩大规模，使用较少但内存更大的GPU可能更优，但这需要精心调校配置。在其他情况下，则可以通过扩展部署方式来实现更高的吞吐量。同时，某些并行策略（如张量与管道）会导致带宽利用率低下，而微批量大小的增加超过某个阈值会导致执行呈突发状态，从而导致峰值功率跃升，进而恶化热限制。上述发现突出表明了训练性能由硬件、系统拓扑和模型执行的复杂相互作用塑造。本文给出了改善未来LLM系统和工作负载的可扩展性和可靠性的建议。
## 881. `cs.SE` - LoCaL: 对抗代码评估指标的表层偏见 [PDF](https://arxiv.org/pdf/2509.15397), [HTML](https://arxiv.org/abs/2509.15397)
### Authors
Simantika Bhattacharjee Dristi,Matthew B. Dwyer
### Background
随着大型语言模型（LLMs）及其代理的日益普及，可靠的和有效的代码评估指标（CEMs）对于软件工程任务的发展变得至关重要。虽然常用基准通常提供了测试案例来评估生成代码的正确性，但开发和执行测试案例的成本很高。参考基线CEMs作为一种替代方案，通过根据其与参考代码的功能相似性来评分候选程序。尽管先前研究集中在报告这些CEMs与功能正确性之间的弱相关性上，但其原因仅是假设的，可行的解决方案仍未被探索。
### Innovation
本文批评性地评估了四种最先进的参考基线CEMs，揭示了它们对表层特征有很强的偏好，而忽略了代码的功能性。为了弥补这一差距，作者提出了LoCaL（Looks Can Lie）——一个CEMs评估基准，包含3117对代码，涵盖了方法和程序水平。每个对子都标注了功能相似性评分，并旨在针对CEMs可能表现不佳的区域。功能相似性评分通过差异 fuzzing 计算得出，从而消除了对预定义测试案例的需求，并通过执行远超先前工作的测试数量提升了评分的可靠性。研究发现，在LoCaL数据集上，这四种CEMs相较于基线显著性能下降。
### Conclusion
根据研究发现，我们得出结论，将CEMs暴露于类似LoCaL的数据集可能会促进开发出对表层偏见具有鲁棒性的指标。
## 882. `cs.LG` - MapAnything：通用的端到端度量3D重建 [PDF](https://arxiv.org/pdf/2509.13414), [HTML](https://arxiv.org/abs/2509.13414)
### Authors
Nikhil Keetha,Norman Müller,Johannes Schönberger,Lorenzo Porzi,Yuchen Zhang,Tobias Fischer,Arno Knapitsch,Duncan Zauss,Ethan Weber,Nelson Antunes,Jonathon Luiten,Manuel Lopez-Antequera,Samuel Rota Bulò,Christian Richardt,Deva Ramanan,Sebastian Scherer,Peter Kontschieder
### Background
当前，3D视觉任务需要专门的前馈模型来处理不同的任务，如非标定的结构从运动、标定的多视图立体、单目深度估计、相机定位、深度补全等。这些模型的监督和训练过程复杂且不统一，导致了各自为战的局面，效率低下且难以扩展。MapAnything旨在提供一个统一的基于Transformer的前馈模型，单一输入能够解决多种3D视觉任务，并通过灵活的输入增强和标准化的监督训练实现高效联合训练，从而为通用的3D重建骨干网铺平道路。
### Innovation
MapAnything使用了一个多视图场景几何的分解表示，包括深度图、局部光线图、相机姿态和度量比例系数。它支持一种统一的前馈模型，能够一次性解决多种3D视觉任务，无需专门的模型，并且在监督和训练过程中提供了更高的灵活性和标准化，从而实现了更有效的联合训练行为，提升了整体性能。这为3D重建任务提供了一个通用的解决方案，减少了任务之间的复杂性和模型之间的冗余。
### Conclusion
通过广泛的经验和模型消融分析，MapAnything不仅表现出色，甚至在某些任务上超过了专业的前馈模型，同时展示了更高效的联合训练行为，证明了其作为通用3D重建骨干网的潜力。该工作为未来的3D视觉研究和应用提供了新的视角和技术支持。
## 883. `cs.SE` - 我们走到了哪里？现有漏洞定位方法的经验分析 [PDF](https://arxiv.org/pdf/2509.15777), [HTML](https://arxiv.org/abs/2509.15777)
### Authors
Haoran Xu,Zhi Chen,Junxiao Han,Xinkui Zhao,Jianwei Yin,Shuiguang Deng
### Background
开源软件漏洞修补检测是维护软件安全和确保软件供应链完整性的重要组成部分。传统的手动检测方法在处理大量提交历史时面临显著的扩展性挑战，并且容易出现人为错误和遗漏。现有的自动化方法，包括基于启发式的方法和预训练模型解决方案，具有准确性有限、泛化能力差和方法学上的内在限制，这些都阻碍了它们的实际部署。
### Innovation
本文进行了对现有漏洞修补检测方法的全面实证研究，揭示了四个关键见解，指导了有效解决方案的设计：搜索空间的减小对检测结果的至关重要性；预训练语义理解优于架构复杂度；网络爬取方法的时间限制；以及知识驱动方法的优势。基于这些见解，提出了一个新的两阶段框架，结合版本驱动的候选筛选和基于大语言模型的多轮对话投票，以实现准确、高效的漏洞修补识别。
### Conclusion
在包含750个实际漏洞的数据集上进行的广泛实验表明，该方法优于当前的方法。
## 884. `cs.LG` - PBPK-iPINNs: 反馈物理感知神经网络在生理基质药代动力学脑模型中的应用 [PDF](https://arxiv.org/pdf/2509.12666), [HTML](https://arxiv.org/abs/2509.12666)
### Authors
Charuka D. Wickramasinghe,Krishanthi C. Weerasinghe,Pradeep K. Ranaweera
### Background
物理感知神经网络（PINNs）结合机器学习与微分方程来解决直接和逆问题，确保预测符合物理定律。基于生理的药代动力学（PBPK）建模利用了机制和生理学视角下的框架，超越了传统的 compartimental方法。PBPK模型基于微分方程系统，每条方程表示药物在器官或组织等容器中的质量平衡，并包含了反映生理学、生物化学和药物特定特性的参数，模拟药物在体内的运动过程。在这篇论文中，作者介绍了PBPK-iPINN方法，该方法利用逆PINN估计PBPK脑部模型中的药物特异性或患者特异性参数和药物浓度分布，并强调了损失函数组件（数据损失、初始条件损失和残差损失）权重和参数设置（包括层数、神经元数量、激活函数、学习率、优化器和插值点）的合理调整对反问题解的收敛至关重要。然后，作者将PBPK-iPINN方法与现有传统数值和统计方法进行了性能比较.
### Innovation
提出了PBPK-iPINN方法，利用逆PINN估计PBPK脑部模型中的药物特异性或患者特异性参数和药物浓度分布，特别注意了损失函数组件权重和参数设置的重要性，如层数、神经元数量、激活函数、学习率、优化器和插值点。
### Conclusion
PBPK-iPINN方法在反问题解决方面比现有传统数值和统计方法更有效。
## 885. `cs.SE` - 评估本地LLM在解决复杂编程挑战中的局限性 [PDF](https://arxiv.org/pdf/2509.15283), [HTML](https://arxiv.org/abs/2509.15283)
### Authors
Kadin Matotek,Heather Cassel,Md Amiruzzaman,Linh B. Ngo
### Background
本研究考察了当前开源的本地托管大型语言模型在处理具有扩展问题描述和情境的复杂编程任务方面的性能。该研究表明，尽管本地模型在提交结果方面表现得相对平淡，特别是与私有、成本可控的LLM部署相比，但开源模型的表现也在快速进步，组织可以在内部硬件上复制测评流程从中获益。
### Innovation
研究基于原来的AI驱动代码生成评估框架(FACE)，进行改造使其能够完全离线工作，通过Ollama运行时运行，并将FACE的问题专用目录树合并为少量的JSON文件，同时增加了健壮的检查点机制，以便失败后可以恢复多天的运行。该框架可以为8种代码导向模型生成、提交和记录3,589个Kattis问题的全部解决方案。
### Conclusion
研究表明，开源模型的整体通过率较低，最高模型的通过率大约仅为专有的Gemini 1.5和ChatGPT-4的一半。这表明私人、成本可控的LLM部署与最新专有服务之间存在持久差距。但同时，也展现了开源模型的快速进步以及可在组织内硬件上复制的评价工作流程的实用益处。
## 886. `cs.SE` - 智慧在于简洁：凝练代码变更改进提交信息生成 [PDF](https://arxiv.org/pdf/2509.15567), [HTML](https://arxiv.org/abs/2509.15567)
### Authors
Hongyu Kuang,Ning Zhang,Hui Gao,Xin Zhou,Wesley K. G. Assunção,Xiaoxing Ma,Dong Shao,Guoping Rong,He Zhang
### Background
提交信息是描述代码变更原因的重要资源，在版本控制系统中（例如Git）不可或缺。它们有助于开发者理解代码变更并更好地执行软件维护任务。然而，实践中开发者往往忽视了编写高质量提交信息。因此，众多研究提出自动生成提交信息的方法。这些研究证明了如何组织和表示代码变更对生成良好提交信息至关重要，包括利用细粒度的图或嵌入更好地表示代码变更。本文采用了一种不同的方法，在生成之前凝练代码变更，提出了包括总结变更代码、激发的注释和强调的代码标识符的简洁但可读的文本模板。
### Innovation
提出了包含总结变更代码、激发的注释和强调的代码标识符的简洁但可读的文本模板。首先使用名为ChangeScribe的基于启发式工具对代码变更进行凝练，然后对我们的模板和对应的提交信息对进行CodeLlama-7B的微调。这种方法更好地利用了预训练语言模型，同时简洁易读，为开发者补充生成提交信息。
### Conclusion
基于广泛使用的数据集的评估表明，本文方法在BLEU-Norm、METEOR和ROUGE-L方面均优于六个基线，分别提高了51.7%、78.7%和62.5%。消融研究和人工评价也进一步阐明了本文方法的有效性。
## 887. `cs.SE` - 当缺陷久拖不决：异常解决时间离群点及其主题的研究 [PDF](https://arxiv.org/pdf/2509.16140), [HTML](https://arxiv.org/abs/2509.16140)
### Authors
Avinash Patil
### Background
高效的缺陷修复对于维持软件质量和用户满意度至关重要。然而，特定的缺陷报告长时间无法解决，可能表明存在流程低效或复杂问题。本文通过全面分析来自七个知名开源仓库中的缺陷修复异常，探讨这些问题背后的模式。
### Innovation
本文使用统计方法如Z分数和四分位距（IQR）来识别缺陷修复时间的异常。结合Term Frequency-Inverse Document Frequency (TF-IDF) 和KMeans聚类技术，对缺陷总结的文本特征进行提取和分类，揭示了模式一致性的项目中，异常通常集中在测试失败、功能增强请求以及用户界面问题上。
### Conclusion
研究结果揭示了各种项目中缺陷修复异常的一致模式，这类异常往往集中在测试失败、功能增强请求以及用户界面问题上。该方法为项目维护者提供了可操作的见解，以优先处理并有效解决长期存在的缺陷。
## 888. `cs.LG` - 加速梯度方法中带偏差梯度估计的分析：风险敏感性、高概率保证及大偏差界限 [PDF](https://arxiv.org/pdf/2509.13628), [HTML](https://arxiv.org/abs/2509.13628)
### Authors
Mert Gürbüzbalaban,Yasa Syed,Necdet Serhat Aybat
### Background
本文探讨了在第一阶方法中收敛速度和对抗梯度误差的鲁棒性之间的权衡问题。研究对象是广义动量方法（GMMs）—包括Nesterov加速梯度、重球法和梯度下降法等—这些方法用于最小化平滑强凸目标函数。允许梯度误差可能是敌手构造且带有偏置的，并通过鲁棒控制理论中的风险敏感性指标（RSI）量化方法对梯度误差的鲁棒性。
### Innovation
文章首先给出了二次目标函数在独立同分布高斯噪声下风险敏感性指标（RSI）的闭式解，并揭示了在选择步长和动量参数时RSI与收敛速率之间的帕累托边界。然后证明了大偏差原理，并展示了速率函数与风险敏感性指数关系到$H_times$范数，即最坏情况下的梯度误差的鲁棒性度量。这是一般情况下偏差梯度估计下首次非渐进展望保护措施和首次风险敏感分析通用动量方法。此外，还推导出了基于有限时间风险敏感性指标的非渐近界限。
### Conclusion
本文提供了关于一般凸函数的广义动量方法的非渐进展望保护措施，并研究了风险敏感性指数（RSI）与收敛率之间的类似权衡。同时，还提供了鲁棒回归问题的数值实验以说明研究成果。
## 889. `cs.SE` - 失效模式和效果分析：电动汽车领域的一项经验 [PDF](https://arxiv.org/pdf/2509.15893), [HTML](https://arxiv.org/abs/2509.15893)
### Authors
Andrea Bombarda,Federico Conti,Marcello Minervini,Aurora Zanenga,Claudio Menghi
### Background
软件故障可能导致灾难性和昂贵的后果。功能失效模式和影响分析（FMEA）是一种在 cyber-physical 系统（CPS）中广泛使用的标准技术，用于识别软件故障并评估其影响。近年来，基于仿真的方法已被证明对支持 FMEA 有效。然而，需要实验证据来证明这些方法的有效性，从而提高其实际应用价值。
### Innovation
作者使用 Simulink 故障分析器这一工业工具，对该电动车领域 CPS 的安全性进行了 FMEA 分析。通过实际案例，验证了基于仿真的 FMEA 支持方法的有效性，并指出在 38.4% 的故障情况下，模拟驱动的支持与工程师的预期不匹配，帮助工程师发现故障的意外影响。
### Conclusion
研究结果对作为 Simulink 工程师、使用 Simulink 故障分析器或担任安全性分析师的软件工程师具有实用价值。他们能够从我们的研究中吸取教训，并以 FMEA 方法改进其模型。同时，研究提供了对结果的详尽讨论和十个经验教训。
## 890. `cs.SE` - 漏斗探测器2.0：Jupyter驱动机器学习管道中的数据泄露分析 [PDF](https://arxiv.org/pdf/2509.15971), [HTML](https://arxiv.org/abs/2509.15971)
### Authors
Owen Truong,Terrence Zhang,Arnav Marchareddy,Ryan Lee,Jeffery Busold,Michael Socas,Eman Abdullah AlOmar
### Background
在软件开发环境中，代码质量至关重要。本研究旨在通过识别和纠正模型中的数据泄露问题，帮助机器学习（ML）工程师提升代码质量。数据泄露是指在准备数据科学模型时，意外地将测试数据集中的信息包含进训练数据，从而导致误导性的性能评估。ML开发人员必须仔细将数据分为训练、评估和测试集，以避免在代码中引入数据泄露问题。本研究开发了一个新的Visual Studio Code (VS Code) 扩展工具，称为LeakageDetector，用于检测Jupyter Notebook文件中的数据泄露问题，主要是重叠、预处理和多测试泄漏。
### Innovation
LeakageDetector 2.0开发了一个新的Visual Studio Code (VS Code) 插件，名为LeakageDetector，用于检测Jupyter Notebook文件中的数据泄露问题，并提供了两种纠正机制：传统的“快速修复”方法手动修正泄漏，以及由LLM驱动的方法，指导ML开发人员遵循构建ML管道的最佳实践。
### Conclusion
这项研究开发并实现了一个名为LeakageDetector的新工具，帮助开发人员自动检测常见的数据泄露问题并提供相应的解决方案。这不仅提高了数据模型的透明性和准确性，也为推动机器学习的实际应用和商业价值奠定了坚实的基础。
## 891. `cs.SE` - MatchFixAgent: 无编程语言依赖的自主仓库级代码翻译验证和修复 [PDF](https://arxiv.org/pdf/2509.16187), [HTML](https://arxiv.org/abs/2509.16187)
### Authors
Ali Reza Ibrahimzada,Brandon Paulsen,Reyhaneh Jabbarvand,Joey Dodds,Daniel Kroening
### Background
代码翻译将源代码从一种编程语言转换为另一种语言，验证翻译的功能等价性和在必要时进行修复是非常重要的步骤。现有的自动化验证和修复方法很难适应多种编程语言，因工程成本较高，依赖的测试套件往往不完善，因此可能会产生错误的功能等价性断言和无效的翻译修复。
### Innovation
开发了一种基于大型语言模型（LLM）的无编程语言依赖框架——MatchFixAgent，用于跨编程语言的翻译等价性验证与修复。MatchFixAgent采用多代理架构，将等价性验证任务分为多个子任务，进行详细的语义分析；然后将这些分析结果提供给测试代理，生成并执行测试。在观察测试失败后，修复代理尝试修复翻译错误。最终由裁决代理根据语义分析和测试结果做出等价性判决。
### Conclusion
与现有四种代码翻译技术相比，MatchFixAgent 在代码翻译验证和修复方面的表现更佳。它能够产生 99.2% 的翻译等或不等价判决，且在相同的研究问题上达到 72.8% 的一致性验证结果。当 MatchFixAgent 的结果与先前的研究结果不符时，近 60.7% 的情况下是正确的。此外，它可以修复近 50.6% 的翻译不等价问题，而之前的其他工作仅能修复 18.5%。这表明 MatchFixAgent 在处理多种编程语言的代码翻译时更为适配，同时保持了很高的验证准确性。
## 892. `cs.SE` - 使用上下文引擎增强业务流程执行 [PDF](https://arxiv.org/pdf/2110.04061), [HTML](https://arxiv.org/abs/2110.04061)
### Authors
Christian Janiesch,Jörn Kuhlenkamp
### Background
业务流程中与工作流相关数据的变化可能妨碍流程的完成或影响其盈利能力，因为这些流程是在不同的背景条件下实例化的。因此，需要一种技术来增强业务流程管理系统（BPM）的上下文感知能力。
### Innovation
本文提出了一种上下文引擎，将其扩展到商务规则和BPM系统的已知组合之上，基于复杂事件处理（CEP）技术。这种方法提供了在初始化和执行期间根据显著的上下文变化来配置和适应运行中的流程实例的灵活性，从而提高了系统的上下文感知能力。
### Conclusion
本文提出的架构为BPM系统提供了一个通用的基础，但需要根据具体的上下文进行定制。该系统实施的成功取决于上下文信息的可用性和业务流程补偿选项。文章还强调了没有现成的多用途非专有的基于CEP或任何其他技术的上下文引擎来帮助BPM系统在运行时适应上下文变量的变化。该研究的成果可能会激发理论界和实践界对此问题的讨论。
## 893. `cs.SE` - 线性代数库集成的软件开发方面 [PDF](https://arxiv.org/pdf/2509.16081), [HTML](https://arxiv.org/abs/2509.16081)
### Authors
Marcel Koch,Tobias Ribizel,Pratik Nayak,Fritz Göbel,Gregor Olenik,Terry Cojean
### Background
许多科学发现依赖或得益于模拟软件的使用。这些复杂的应用程序软件不是从零开始构建的，而是依赖于专门用途的小部件，通常来自科学家不熟悉的领域。Ginkgo是这些构建块之一，用于在不同平台上处理稀疏数值线性代数。通过使用Ginkgo，应用程序能够更轻松地过渡到现代系统，并通过更快的数值线性代数算法加快模拟速度。本文讨论了应用程序软件集成Ginkgo所面临的问题和益处，涉及不同的应用领域，如计算流体动力学、电力网模拟以及心电生理学。从软件工程的角度研究了这些案例的集成对应用代码的影响，并特别强调了Ginkgo和应用程序为实现可持续软件开发所采取的方法。
### Innovation
Ginkgo作为一种专门用途的软件库，帮助应用程序更轻松地过渡到现代系统，并通过更快的数值线性代数算法提高模拟速度。文章讨论了几种不同领域（如计算流体动力学、电力网模拟及心电生理学）的应用软件如何集成Ginkgo，并从软件工程角度分析了其影响和实现可持续发展的方法。
### Conclusion
本文概述了应用软件集成Ginkgo时面临的问题和益处，强调了Ginkgo和应用软件为实现可持续软件开发所采取的方法。
## 894. `cs.SE` - Hornet Node和Hornet DSL：一个简洁可执行的比特币共识规范 [PDF](https://arxiv.org/pdf/2509.15754), [HTML](https://arxiv.org/abs/2509.15754)
### Authors
Toby Sharp
### Background
比特币的共识规则编码在其参考客户端中，并且由于副作用、可变状态、并发性和陈旧设计，这部分代码不适合形式验证。一个独立的形式化规范可以跨版本进行验证，并且还可以与新的客户端实现进行对比，从而增强去中心化并减少共识分裂错误的风险。但是，由于比特币共识逻辑的复杂性，长期以来一直认为这样的规范是不可行的。因此，Hornet Node和Hornet DSL被开发了出来，这些技术能够用一种简洁且可执行的方式描述比特币的共识规则，使得工作节点能够在一个线程上快速同步到主网顶端。这解决了长期存在的难题，提供了一种可信路径，实现比特币共识的纯形式执行规范。
### Innovation
Hornet Node通过引入Hornet DSL语言，提供了一种简洁且可执行的形式化规范，用于描述比特币的共识规则。Hornet DSL被专门设计用于准确、无歧义地编码这些规则，支持执行、形式化推理、共识代码生成以及基于AI的对抗性测试。同时，Hornet Node采用了层次化设计、高效数据结构和强分离关注点的架构，提供了高质量的代码示例，使其在教育和实验上都非常合适。
### Conclusion
Hornet Node和Hornet DSL共同提供了一个可信的路径，以实现纯净、形式化和可执行的比特币共识规范，表明通过形式化验证可以增强比特币网络的去中心化安全性和稳定性。
## 895. `cs.SE` - MigGPT: 利用大型语言模型实现跨版本自动化迁移Linux外树内核补丁 [PDF](https://arxiv.org/pdf/2504.09474), [HTML](https://arxiv.org/abs/2504.09474)
### Authors
Pucheng Dang,Di Huang,Dong Li,Kang Chen,Yuanbo Wen,Qi Guo,Xing Hu
### Background
外树内核补丁对于适应新硬件或启用特定功能是必不可少的。维护和更新这些补丁需要大量经验工程师的努力。尽管大语言模型（LLMs）在多个领域取得了显著进展，显示出其在自动化外树内核补丁迁移方面的潜力，但我们的研究表明，LLMs 仍面临代码上下文理解不完整和迁移点识别不准确的问题。
### Innovation
我们提出了一种名为 MigGPT 的框架，它采用了一种新颖的代码指纹结构来保留代码片段信息，并结合了三个精心设计的模块以提高外树内核补丁迁移的准确性和效率。此外，我们还建立了一个使用真实世界外树内核补丁项目进行的稳健基准测试，以评估大语言模型的能力。评估结果表明，MigGPT 明显优于直接使用基础大语言模型，完成了高达 74.07% 的迁移任务。
### Conclusion
MigGPT 在外树内核补丁迁移方面的迁移准确性和效率明显优于直接使用基础大语言模型。
## 896. `cs.SE` - 基于关键行为单元学习的对抗鲁棒行为序列异常检测方法 [PDF](https://arxiv.org/pdf/2509.15756), [HTML](https://arxiv.org/abs/2509.15756)
### Authors
Dongyang Zhan,Kai Tan,Lin Ye,Xiangzhan Yu,Hongli Zhang,Zheng He
### Background
顺序深度学习模型（如RNN和LSTM）可以学习软件行为的序列特征，如API或系统调用序列。然而，最近的研究表明，这些基于深度学习的方法容易受到对抗样本的影响。攻击者可以使用对抗样本来改变行为序列的顺序特征，误导恶意软件分类器。
### Innovation
提出了一种基于行为单元分析的对抗鲁棒性异常检测方法，以克服这个挑战。该方法将通常执行某种行为意图的相关行为提取为行为单元，此类单元包含局部行为的代表性语义信息，从而提高行为分析的鲁棒性。通过基于多级深度学习模型学习每个行为单元的整体语义及其相互间上下文关系，该方法能够缓解针对局部和大规模行为的扰动攻击。此外，该方法可以应用于低级和高级行为日志（如API和系统调用日志）中。实验结果表明，该方法优于所有比较的方法，这表明该方法在对抗混淆攻击方面具有更好的性能。
### Conclusion
实验结果表明，该方法在对抗混淆攻击方面的性能优于所有比较方法，显示了其潜在的应用价值和鲁棒性。
## 897. `cs.SE` - ThermalGuardian: 温度感知的车载深度学习框架测试方法 [PDF](https://arxiv.org/pdf/2509.15815), [HTML](https://arxiv.org/abs/2509.15815)
### Authors
Yinglong Zou,Juan Zhai,Chunrong Fang,Zhenyu Chen
### Background
深度学习模型在自动驾驶系统中扮演着重要角色，支持诸如环境感知等功能。为了加速模型推理，这些深度学习模型需要部署到车载深度学习框架中，例如Apollo中的PaddleInference和AutoWare中的TensorRT。然而，与在云中部署深度学习模型不同，车载环境下的极端温度变化（从-40°C到50°C）会对GPU温度产生显著影响。此外，计算产生的热量还会进一步升高GPU温度。这些温度波动会导致通过DVFS等机制进行的动态GPU频率调整。但是，现有的车载深度学习框架未考虑由温度引起的频率变化的影响。因此，这些框架在温度波动的GPU上部署时会出现关键质量问题：计算密集型操作会延迟或出错，高/混合精度操作会遭受精度误差，时间序列操作会面临同步问题。现有的深度学习框架测试方法无法检测这些问题，因为它们忽略了温度对深度学习框架质量的影响。
### Innovation
为解决这一问题，我们提出了一种名为ThermalGuardian的车载深度学习框架测试方法，这是首个考虑温度影响的测试方法。ThermalGuardian通过针对温度敏感操作生成测试输入模型，基于牛顿冷却定律模拟GPU温度波动，并根据实时GPU温度控制GPU频率来实现这一目标。
### Conclusion
ThermalGuardian通过生成目标于温度敏感操作的测试输入模型、模拟基于牛顿冷却定律的GPU温度波动以及根据实时GPU温度控制GPU频率，填补了现有深度学习框架测试方法忽略温度效应对框架质量影响的空白，从而解决了由温度引起的质量问题。
## 898. `cs.SE` - CodeRAG：为检索增强的仓库级代码完成查找相关和必要的知识 [PDF](https://arxiv.org/pdf/2509.16112), [HTML](https://arxiv.org/abs/2509.16112)
### Authors
Sheng Zhang,Yifan Ding,Shuquan Lian,Shun Song,Hui Li
### Background
基于代码的大型语言模型（code LLMs）的最近进步推动了仓库级代码完成方法的发展，这种方法能够根据仓库中的更广泛信息自动预测未完成的代码。尽管这些方法取得了显著成果，但也遇到了诸如查询构建不当、单一路径代码检索以及代码检索器和代码LLM之间的不对齐等问题。这些缺陷限制了它们的有效性和准确性。为了解决这些问题，本文引入了CodeRAG，一个专门设计的框架，旨在识别检索增强的仓库级代码完成中相关和必要的知识。
### Innovation
CodeRAG的方法核心包括日志概率引导查询构建、多路径代码检索以及偏好对齐的BestFit重排序。通过在基准测试ReccEval和CCEval上进行的实验，证明了CodeRAG在所有指标上都显著超过了现有最好的方法，并且表现一致和稳定。值得注意的是，CodeRAG对查询构建、代码检索和结果排序的方法都进行了优化，以更好地适应代码完成的需求。
### Conclusion
CodeRAG在基准测试中表现出色，超过了现有的最先进的方法，并且其实施可以通过提供的链接访问。这表明，通过结合多路径检索和偏好对齐的重排序，CodeRAG能够更有效地进行代码完成任务，尤其在处理复杂的代码片段时表现突出。
## 899. `cs.SE` - 在实证软件工程中缓解遗漏变量偏差 [PDF](https://arxiv.org/pdf/2501.17026), [HTML](https://arxiv.org/abs/2501.17026)
### Authors
Carlo A. Furia,Richard Torkar
### Background
遗漏变量偏差在统计模型中出现时，当模型忽略了对被研究效果有影响的关键变量，导致这些缺失变量的效果被归因于模型中已包含的变量，从而可能高估或低估这些变量的真实效果。这种偏差对实证研究的可行性，尤其是在非实验性研究中（如实证软件工程中的常见研究）构成严重威胁。本文通过分析软件工程领域的两个案例研究，展示了遗漏变量偏差的影响，阐述了检测遗漏变量偏差的方法、估计其影响以及缓解其弊端的方法。提出的分析技术基于感兴趣的变量的因果结构模型，提供了一种实践性和直观的方式来总结变量间的关键关系。
### Innovation
本文提供了一种基于因果结构模型的分析方法，用于识别、估计和缓解遗漏变量偏差的影响。这种方法为实证软件工程研究的设计和执行提供了一系列分析步骤，可以显著提高研究设计的质量，并减少其对有效性的威胁。此外，文章强调了在实际开展实验前积极调查遗漏变量偏差的重要性，以优化研究设计过程。
### Conclusion
本文展示了在软件工程领域缓解遗漏变量偏差的方法和步骤，强调了在实验设计前调查遗漏变量偏差的重要性，可以显著提高实证研究的质量，减少潜在的有效性威胁。
## 900. `cs.SE` - 以不确定性指导实现更好的代码生成：基于适应性解码 [PDF](https://arxiv.org/pdf/2506.08980), [HTML](https://arxiv.org/abs/2506.08980)
### Authors
Kaifeng He,Mingwei Liu,Chong Wang,Zike Li,Yanlin Wang,Xin Peng,Zibin Zheng
### Background
代码生成使用大型语言模型（LLMs）高度依赖于解码过程中的token选择，特别是在决策点，不确定性对程序正确性有重大影响。传统的贪心解码策略对待所有token是统一的，未能捕捉到代码独有的不确定性特征，常常导致次优输出。研究表明，大量生成错误源于高不确定性位置的token错排，正确token可用但未被优先考虑。
### Innovation
提出了一种适应性解码框架AdaDec，它使用基于前瞻性的、具有不确定性的暂停与重新排序机制。AdaDec能够自动学习模型特定的不确定性阈值，并在检测到高不确定性时选择性地重新排序token。与传统的贪心解码相比，AdaDec在HumanEval+、MBPP+和DevEval基准测试中表现出显著的提升，精确度最高可提高20.9%，且持续优于之前的适应性解码方法AdapT。通过仅在必要时应用重新排序，AdaDec减少了计算开销和延迟，提高了效率和可靠性。
### Conclusion
不确定性导向的解码策略对于推动LLM基于的代码生成的鲁棒性和实用性具有重要价值。
## 901. `cs.SE` - 性能难题、结构知识与改进机会：模块化性能建模的分析框架 [PDF](https://arxiv.org/pdf/2509.11000), [HTML](https://arxiv.org/abs/2509.11000)
### Authors
Omid Gheibi,Christian Kästner,Pooyan Jamshidi
### Background
性能影响模型对于理解配置如何影响系统性能非常有益，但是由于配置空间的指数级增长，创建这些模型具有挑战性。虽然灰盒方法利用了选定的结构知识（如系统模块执行图）来改进建模，但结构知识、系统特性（即结构方面）以及潜在模型改进之间关系的研究尚不完善。
### Innovation
本文通过正式调查结构方面（如模块数量和每个模块的配置选项）的变化以及结构知识水平如何影响优化模块化性能模型的机会，填补了这一空白。本文引入并量化了建模难度的概念，定义为性能建模的固有难度，并通过合成系统模型的受控实验建立了测量这些概念的“分析矩阵”。研究表明，建模难度主要由模块数量和每个模块的配置选项数量驱动。同时，本文证明了较高水平的结构知识和增加的建模难度显著提高了改进的机会。这些因素对不同性能指标的影响不同；对于排名准确性（例如，故障排除任务）而言，结构知识更为重要，而对于预测准确性（例如，资源管理任务）而言，难度则起着更重要的作用。
### Conclusion
本结果为系统设计师提供了可操作的见解，指导他们根据系统的特性以及给定任务的目标战略性地分配时间和选择适当的建模方法。
## 902. `cs.SE` - RPG: 统一和可扩展代码生成的代码库规划图 [PDF](https://arxiv.org/pdf/2509.16198), [HTML](https://arxiv.org/abs/2509.16198)
### Authors
Jane Luo,Xin Zhang,Steven Liu,Jie Wu,Yiming Huang,Yangyu Huang,Chengyu Yin,Ying Xin,Jianfeng Liu,Yuefeng Zhan,Hao Sun,Qi Chen,Scarlett Li,Mao Yang
### Background
大语言模型在函数级和文件级代码生成方面表现出色，但在从零开始生成完整的代码库方面依然面临重大挑战。这一过程需要在提案级和实施级之间进行协调和可靠规划，而自然语言由于其歧义性和冗长性，很难忠实地表示复杂的软件结构。为了解决这一问题，论文引入了Repository Planning Graph (RPG)，这是一种持久性表示形式，通过在一个图中编码能力、文件结构、数据流和函数，统一了提案级和实施级的规划。RPG用明确的蓝图替代了歧义的自然语言，使长期规划和可扩展的代码库生成成为可能。
### Innovation
RPG是一种统一提案级和实施级规划的持久性表示形式，通过一个图来编码能力和文件结构、数据流和函数。ZeroRepo是一个基于RPG的框架，用于从零开始生成代码库，分为三个阶段：提案级规划和实施级细化以构建图，随后是图引导的代码生成并附带测试验证。通过构建RepoCraft基准测试，实验表明ZeroRepo优于其他基准，生成的代码库平均包含近36K行代码，具有81.5%的功能覆盖率和69.7%的通过率。
### Conclusion
RPG能够建模复杂依赖关系，支持通过接近线性扩展实现更加复杂的规划。此外，RPG提升了LLM对代码库的理解，促进了代理的快速定位。零环境下生成的代码库在功能覆盖率和通过率上的优势显著，超过了现有基准。
## 903. `cs.SE` - 构建稳健且适应性强的GenAI原生系统的原理与模式 [PDF](https://arxiv.org/pdf/2508.15411), [HTML](https://arxiv.org/abs/2508.15411)
### Authors
Frederik Vandeputte
### Background
生成式AI（GenAI）作为一种变革性技术，在各个应用领域展现了卓越的能力，但其在开发可靠的高效系统方面面临诸多挑战，特别是在预测性和效率方面。本文探讨了这种技术面临的瓶颈，并提出了一种新的设计理念，即在保持GenAI认知能力的同时，将其与传统的软件工程原则相结合，以构建出稳健、自适应且高效的系统。
### Innovation
本文提出了基础的GenAI原生设计原则，包括可靠性、卓越性、可进化性、自给性和保证性等五大支柱，同时提出了以GenAI原生细胞、有机基质和可编程路由器为代表的架构模式，为构建可靠的自演化系统提供了指导。此外，论文还强调了从技术、用户采纳、经济和法律等多个角度阐述这些系统的影响，呼吁进一步验证和实验，旨在激励未来的研究，鼓励相关社区采用和改进这一概念框架。
### Conclusion
本文的工作旨在激发未来的研究并鼓励相关社区实施和完善这一概念框架，指出需要进一步验证和实验这些新型的GenAI原生系统，在技术、用户接纳、经济和法律等多方面产生积极影响。
## 904. `cs.SE` - 基于MLIR的Contro流管理Coarse Grained Reconfigurable Arrays编译框架 [PDF](https://arxiv.org/pdf/2508.02167), [HTML](https://arxiv.org/abs/2508.02167)
### Authors
Yuxuan Wang,Cristian Tirelli,Giovanni Ansaloni,Laura Pozzi,David Atienza
### Background
Coarse Grained Reconfigurable Arrays (CGRAs)结合了高度灵活和高效的优势，非常适合加速密集型工作负载。然而，向广范应用推广CGRA的一个关键障碍在于其编译，必须应对包含空间和时间维度在内的多维空间。目前最先进的编译器主要关注数据流，而很少或没有控制流的支持，主要针对单个循环进行映射，或者将控制流分歧管理委托给特定硬件单元。研究提出了一种全新的模块化编译框架，通过在编译级别有效管理与优化控制流，能够支持任何控制流的应用程序的编译，同时保持硬件无关性并实现高性能。该框架还包括一种新颖的映射方法作为编译后端，解决了可用CGRA硬件资源的限制，保证了编译过程中的可行解。通过纯编译优化，框架可以实现高达2.1倍的速度提升，而无需修改硬件设计和应用程序代码。r
### Innovation
提出了一种基于MLIR（MLIR-Based）的模块化编译框架，能够有效管理和优化CGRA中的控制流。该框架具有以下创新点：1. 无需修改硬件，适用于任意控制流的应用程序。2. 通过编译级优化，实现了高性能。3. 引入了一种新颖的映射方法，解决了现有硬件资源的限制，确保编译过程中的可行性解。该框架纯粹通过编译优化实现了最高2.1倍的速度提升。r
### Conclusion
该论文提出了一种基于MLIR的模块化编译框架，通过在编译级别有效管理控制流，能够支持任何控制流的应用程序的编译，保持硬件无关性并实现高性能。通过编译优化实现了最高2.1倍的速度提升。这种方法强调了编译优化的重要性，并展示了计算机语言和硬件结合所带来的潜在效益。r
## 905. `cs.SE` - Watson: 一个用于LLM驱动型智能体推理的认知可观察性框架 [PDF](https://arxiv.org/pdf/2411.03455), [HTML](https://arxiv.org/abs/2411.03455)
### Authors
Benjamin Rombaut,Sogol Masoumzadeh,Kirill Vasilevski,Dayi Lin,Ahmed E. Hassan
### Background
大型语言模型（LLMs）越来越多地被集成到自主系统中，这催生了一种新的软件类别，即Agentware，其中由LLM支持的智能体执行复杂的、开放式任务，这些任务涉及软件工程、客户服务和数据分析等各个领域。然而，智能体的高度自主性和不透明的推理过程给传统的软件可观察性方法带来了重大挑战。为了应对这一挑战，我们引入了认知可观察性的概念——即恢复和检查智能体决策背后的隐式推理的能力。我们提出了Watson，一种通用框架，使我们能够不改变智能体的行为方式来观察快速推理的LLM智能体的推理过程。Watson使用提示归因技术逆向推断推理轨迹。我们在MMLU基准测试和来自MMLU-bench-lite数据集的AutoCodeRover和OpenHands智能体中，在手动调试和自动化修正两种场景下评估了Watson。在静态和动态环境下，Watson都提供了可操作的推理见解并支持针对性的干预，证明了该框架在提高Agentware系统透明度和可靠性方面的实际用途。
### Innovation
我们提出了Watson，一种通用框架，用于不改变智能体行为的情况下观察快速推理的LLM智能体的推理过程。Watson使用提示归因技术来逆向推断推理轨迹，帮助恢复和检查智能体决策背后的隐式推理。我们通过在MMLU基准测试和AutoCodeRover等智能体上的手动调试和自动化修正场景来评估其有效性。我们展示了Watson如何提供可操作的推理见解并支持针对性的干预，从而提高了Agentware系统的透明度和可靠性。
### Conclusion
Watson通过提供可操作的推理见解并支持针对性的干预，证明了其作为提高Agentware系统透明度和可靠性的一种实际管道的实用性。
## 906. `cs.LG` - 使用持久同调进行的宇宙学：通过机器学习进行参数推断 [PDF](https://arxiv.org/pdf/2412.15405), [HTML](https://arxiv.org/abs/2412.15405)
### Authors
Juan Calles,Jacky H. T. Yip,Gabriella Contardo,Jorge Noreña,Adam Rouhiainen,Gary Shiu
### Background
[2308.02636]论文的研究为该研究提供了背景，表明现有方法用于限制宇宙参数和原始非高斯性时的局限性。在此基础上，该研究利用机器学习进行似然自由推断管道，探讨了持续同理论证在推断参数方面的能力。
### Innovation
该研究使用持久图（PIs）与功率谱和准谱（PS/BS）进行了比较，展示了PIs在预测能力方面优于PS/BS，特别是在限制局部原始非高斯性方面。研究表明，结合PIs与PS/BS提供了微小的好处，表明PS/BS提供的额外或补充信息很少。此外，研究提供了关于$?Omega_{?rm m}$和$f_{?rm NL}^{?rm loc}$最重要的拓扑特征的可视化，揭示了结构和空洞（0-圈和2-圈）对$?Omega_{?rm m}$的重要性，而局部原始非高斯性还受到纤维（1-圈）的影响。
### Conclusion
该研究结论是，持久同调具有成为宇宙参数限制强有力工具的潜力，单独使用或与其他传统方法结合均可提升推断的准确性。持久同调在限定原始非高斯性方面显示出特别强的潜力，且其关键的拓扑特征指向了结构的不同组成部分在不同参数限制中的作用。
## 907. `cs.SE` - SWE-Effi：在资源约束条件下重新评估软件AI代理系统的效果 [PDF](https://arxiv.org/pdf/2509.09853), [HTML](https://arxiv.org/abs/2509.09853)
### Authors
Zhiyu Fan,Kirill Vasilevski,Dayi Lin,Boyuan Chen,Yihao Chen,Zhiqing Zhong,Jie M. Zhang,Pinjia He,Ahmed E. Hassan
### Background
大型语言模型（LLMs）和代码代理的进步展示了其在软件工程（SWE）任务中的潜力，如自动问题解决和功能添加。然而，现有的软件工程AI评估基准（例如，SWE-bench）仅关注解决方案的准确性，忽视了资源受限世界中的有效性这一关键因素。为了弥补这一差距，作者提出了SWE-Effi，这是一种新的多维度评价方法，可从整体有效性角度重新评估AI系统。在资源有限的环境中，AI系统的有效性不仅取决于其准确性，还取决于所消耗的资源。评审过程中使用新方法重新评估了SWE-bench基准中问题解决子集上的流行AI系统的效果。
### Innovation
SWE-Effi是一种新的评估标准，定义了AI系统的有效性是结果准确性（例如，问题解决率）与资源消耗（例如，令牌和时间）的平衡。这种多维度的方法能够更全面地评价AI系统的实际应用效果。通过这种方法，研究者发现了系统性能与基模型整合度之间的关系以及“令牌滚雪球”效应和“昂贵失败”模式。这些发现对于更高效地利用资源并优化AI系统的性能具有重要意义。
### Conclusion
研究结果表明，AI系统的有效性不仅取决于其本身的设计，还取决于其与基模型的整合程度。研究还指出了在令牌预算和时间预算下有效性的权衡，这对项目预算管理和大规模强化学习的应用至关重要。
