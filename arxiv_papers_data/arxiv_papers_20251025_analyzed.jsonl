{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19964", "html_url": "https://arxiv.org/abs/2510.19964", "title": "AI驱动的个性化学习：通过领导人格特质预测学业表现", "title_en": "AI-Driven Personalized Learning: Predicting Academic Per-formance Through Leadership Personality Traits", "authors": "Nitsa J Herzog,Rejwan Bin Sulaiman,David J Herzog,Rose Fong", "background": "该研究探讨了人工智能技术在个性化学习中的潜力，特别是通过预测领导人格特质和机器学习模型来预测学术成功。研究对象为129名环境工程系的硕士学生，进行了五项领导人格测试，涵盖了23项特征。通过这些测试和个人成绩的结合，运用探索性数据分析和相关性分析，选择最适合的特征进行机器学习模型的构建。", "innovation": "研究创新地结合了领导人格特质和个人成绩，使用多种机器学习算法进行模型构建，能够有效预测学生的学术表现。其中，随机森林（RF）算法表现出最佳的预测性能，准确性高达87.50%，展示了AI在个性化学习应用中的潜在价值。", "conclusion": "该研究提供了一种识别学生早期学术优势和劣势的方法，并有助于选择最适合的个性化学习策略。通过这种方式，可以更好地支持和提升学生的学习效果。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20099", "html_url": "https://arxiv.org/abs/2510.20099", "title": "AI PB：个人投资见解的基于情境生成代理", "title_en": "AI PB: A Grounded Generative Agent for Personalized Investment Insights", "authors": "Daewoo Park,Suho Park,Inseok Hong,Hanwool Lee,Junkyu Park,Sangjun Lee,Jeongman An,Hyunbin Loh", "background": "该研究介绍了一种部署在现实零售金融领域的AI PB生成代理。与被动回答查询的反应式聊天机器人不同，AI PB能够主动生成满足合规性和个性化要求的投资见解。该系统包括多个组件和机制，以确保有效和安全地提供投资建议。", "innovation": "研究的创新点在于通过确定性路由内部和外部的大模型来确保数据敏感性的管理，使用开源搜索和金融领域嵌入式模型的混合检索流水线，以及结合规则启发式、序列行为建模和上下文臂的多阶段推荐机制。这些机制都运行在符合韩国金融机构规定的本地环境中，利用Docker Swarm和vLLM技术，确保高效运行。", "conclusion": "通过人类质询和系统度量，研究展示了明确生成与分层安全性结合可以为高风险金融领域提供值得信赖的AI见解。AI PB能够在遵守韩国金融法规的情况下，提供高质量的个性化投资建议，展示了其在实际零售金融领域中的有效应用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19949", "html_url": "https://arxiv.org/abs/2510.19949", "title": "Surfer 2：下一代跨平台计算机使用代理", "title_en": "Surfer 2: The Next Generation of Cross-Platform Computer Use Agents", "authors": "Mathieu Andreux,Märt Bakler,Yanael Barbier,Hamza Ben Chekroun,Emilien Biré,Antoine Bonnet,Riaz Bordie,Nathan Bout,Matthias Brunel,Aleix Cambray,Pierre-Louis Cedoz,Antoine Chassang,Gautier Cloix,Ethan Connelly,Alexandra Constantinou,Ramzi De Coster,Hubert de la Jonquiere,Aurélien Delfosse,Maxime Delpit,Alexis Deprez,Augustin Derupti,Mathieu Diaz,Shannon D'Souza,Julie Dujardin,Abai Edmund,Michael Eickenberg,Armand Fatalot,Wissem Felissi,Isaac Herring,Xavier Koegler,Erwan Le Jumeau de Kergaradec,Aurélien Lac,Maxime Langevin,Corentin Lauverjat,Antonio Loison,Avshalom Manevich,Axel Moyal,Axel Nguyen Kerbel,Marinela Parovic,Julien Revelle,Guillaume Richard,Mats Richter,Ronan Riochet,María Santos,Romain Savidan,Laurent Sifre,Maxime Theillard,Marc Thibault,Ivan Valentini,Tony Wu,Laura Yie,Kai Yuan,Jevgenij Zubovskij", "background": "跨平台构建能够适应浏览器、桌面和移动环境的智能代理仍然存在挑战。现有系统依赖于特定环境的接口，限制了其在不同平台之间的通用部署。", "innovation": "Surfer 2 引入了一个统一的架构，仅从视觉观察中进行操作，实现了在所有三个环境中的最先进的性能。该系统通过分级上下文管理、解耦计划与执行、自我验证与自适应恢复的结合，实现了长时间任务执行的可靠操作。Surfer 2 在 WebVoyager 中达到 97.1% 的准确率，在 WebArena 中达到 69.6% 的准确率，在 OSWorld 中达到 60.1% 的准确率，在 AndroidWorld 中达到 87.1% 的准确率，且没有针对特定任务的微调。在多次尝试后，Surfer 2 在所有基准测试中超越了人类表现。这些结果表明，系统化的组织可以放大基础模型的能力，通过视觉交互实现通用的计算机控制，同时也呼吁下一代视觉语言模型达到帕累托最优的成本效率。", "conclusion": "Surfer 2 的这些结果显示，系统组织可以放大基础模型的能力，通过视觉交互实现通用的计算机控制，同时需要下一代视觉语言模型来实现最优的成本效益。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19838", "html_url": "https://arxiv.org/abs/2510.19838", "title": "Branch-and-Browse: 效率高且可控的基于树状推理和动作记忆的网络探索", "title_en": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory", "authors": "Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury", "background": "自主网络代理由大规模语言模型（LLMs）驱动，在执行信息检索、报告生成和在线交易等目标导向任务方面展现了强大的潜力。这些代理标志着在开放网络环境中实用化体现推理的关键步骤。但是，现有方法在推理深度和效率方面仍然有限：简单的线性方法无法进行多步推理且缺乏有效的回溯机制，而其他搜索策略则过于粗略且计算成本高昂。", "innovation": "我们提出了一种细粒度的网络代理框架——Branch-and-Browse，该框架统一了结构化推理与行动、上下文记忆以及高效执行。具体来说，(i) Branch-and-Browse 通过树状结构探索进行显式的子任务管理，实现可控的多分支推理；(ii) 经过高效的网站状态回放和背景推理进行探索；(iii) 利用页面行动记忆在会话内外共享已探索行动。", "conclusion": "在WebArena基准测试中，Branch-and-Browse的完成任务成功率达到了35.8%，并将执行时间降低了最多40.4%相对于最先进的方法。这些结果表明，Branch-and-Browse是一个可靠的高效框架，适用于基于LLM的网络代理。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19835", "html_url": "https://arxiv.org/abs/2510.19835", "title": "一种解决数独难题和最大化割问题的量子启发式算法", "title_en": "A Quantum-Inspired Algorithm for Solving Sudoku Puzzles and the MaxCut Problem", "authors": "Max B. Zhao,Fei Li", "background": "本文提出并评估了一个量子启发式算法，用于解决二次无约束二进制优化（QUBO）问题，这些问题是通过找到Ising自旋玻璃哈密顿量的基态来实现的。此算法使用矩阵乘积态（MPS）紧凑表示大规模的自旋配置超迭，并利用分段驱动方案引导MPS趋向基态。在每一步中，驱动哈密顿量——结合了横向磁场——与问题哈密顿量相结合，允许自旋翻转和促进量子隧穿。MPS使用标准密度矩阵重整化群（DMRG）方法更新，该方法通过多次沿着自旋链扫过迭代系统能量最小化。尽管具有启发式性质，该算法仍能可靠地识别全局最小值，而不仅仅是近似最佳解，适用于多种QUBO实例。", "innovation": "提出了一种新的求解QUBO问题的量子启发式算法，该算法利用矩阵乘积态（MPS）代表性地表示大规模的自旋配置超迭，并通过分段驱动技术引导其接近基态。驱动哈密顿量的引入允许自旋的翻转和促进量子隧穿，同时采用标准的密度矩阵重整化群（DMRG）方法更新MPS以最小化系统的能量。算法展示了对不同规模的问题解决方案的有效性和可靠性，具体应用了中等难度的数独谜题和最大割问题，证明了其在工业规模QUBO应用中的优势和适用性。", "conclusion": "提出的量子启发式算法可靠地解决了各种QUBO问题，包括数独难题和最大割问题等实例。该方法不仅具有易于扩展和广泛应用的特点，适用于大规模的实际工业应用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19957", "html_url": "https://arxiv.org/abs/2510.19957", "title": "生成式AI促进的新一轮车辆保险欺诈", "title_en": "A new wave of vehicle insurance fraud fueled by generative AI", "authors": "Amir Hever,Itai Orr", "background": "保险欺诈是一个普遍且代价高昂的问题，每年导致数十亿美元的损失。在车辆保险领域，传统的欺诈方案包括策划事故、夸大损害或伪造文件。生成式AI的兴起，尤其是深度伪造图像和视频生成技术，为大规模快速欺诈提供了新的手段。欺诈者现在可以轻松制造高度逼真的车祸照片、损坏证据，甚至伪造身份或文件，利用AI工具支持虚假保险索赔。保险公司已经开始部署反制措施，如基于AI的深度伪造检测软件和增强的验证流程，以检测和缓解这些AI驱动的骗局。然而，当前的缓解策略面临重大限制，检测工具可能会出现误报和漏报，并且精明的欺诈者会不断调整策略以避开自动化检查。这种生成式AI与检测技术之间的军备竞赛，加之保险公司的资源和成本障碍，意味着打击AI驱动的保险欺诈仍然是一项持续的挑战。", "innovation": "UVeye提出了一个分层解决方案，旨在检测、缓解和遏制这种新型欺诈，这是在检测和应对生成式AI欺诈方面的一大进步。", "conclusion": "生成式AI正在促进新一轮的车辆保险欺诈，增加了欺诈的规模和速度。当前的检测和缓解措施存在局限性，而UVeye的分层解决方案为应对这一挑战提供了一种新的方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20075", "html_url": "https://arxiv.org/abs/2510.20075", "title": "LLMs可以隐藏与其长度相同的其他文本中的文本.ipynb", "title_en": "LLMs can hide text in other text of the same length.ipynb", "authors": "Antonio Norelli,Michael Bronstein", "background": "当前，大型语言模型（LLMs）能够将有意义的文本隐藏在另一个完全不同但仍然连贯和可信的文本中，即使长度相同。这种现象过去是不可能实现的，但现在通过LLMs已经可以做到这一点。该论文描述了一种简单且高效的协议，允许即使是很小的8亿参数的开源大型语言模型也能获得高质量的结果，甚至像这篇论文摘要一样长的信息也可以在当地笔记本电脑上进行快速编码和解码。这种现象表明文本与其作者意图之间的解耦，进一步削弱了人们对书面交流的信任，这种信任已经因LLMs聊天机器人的出现而受到影响。论文通过具体的场景举例说明了这种技术的潜在应用，引发了AI安全方面的迫切问题，并挑战了我们对大型语言模型知道什么的理解。", "innovation": "论文介绍了一种新的简单且高效的协议，该协议使得大型语言模型能够通过嵌入技术隐藏特定文本，即使这些文本在表面上看完全不同，但仍保持连贯性。该技术的关键在于利用LLMs的强大处理能力，这对于生成大规模且保持一致性的文本非常重要。此外，该协议在使用较小的模型上也能达到较高的效果，证明了这种方法的可行性和实用性。这种方法为隐藏信息提供了一种新的途径，挑战了传统对语言和意图的理解，同时强调了AI伦理和安全方面的问题。", "conclusion": "该研究展示了一种重大的文本嵌入技术，即利用大型语言模型将隐藏文本嵌入到表面上完全不同的文本中，即使长度相同，也能够保持连贯性和可信度。这对于理解语言模型的能力以及伦理和安全给予了新的视角。然而，这也提醒人们警惕虚假信息和隐蔽沟通的潜在风险，需要在AI技术的发展中更加重视安全和伦理的考量。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19954", "html_url": "https://arxiv.org/abs/2510.19954", "title": "RELATE：一种针对多元关系图的无模式感知感知机编码器", "title_en": "RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs", "authors": "Joseph Meyer,Divyansha Lachi,Reza Mohammadi,Roshan Reddy Upendra,Eva L. Dyer,Mark Li,Tom Palczewski", "background": "在电商、医疗和科学研究等领域中，关系多表数据普遍存在，这类数据可以自然地表示为具有多模态节点属性的异构时间图。现有的图神经网络（GNN）依赖于特定于模式的特征编码器，这要求为每种节点类型和特征列设计单独模块，这限制了其可扩展性和参数共享能力。", "innovation": "引入了RELATE（关系编码用于类型化实体的潜在聚合）——一种无模式感知的、插即用特征编码器，可以在任何通用图神经网络中使用。RELATE采用共享的模态特定编码器来处理类别型、数值型、文本型和时间型属性，并使用类似于Perceiver的设计，采用交叉注意模块将特征聚合为一个固定大小的、对置换不变的节点表示。RELATE在RelBench基准上评估了ReLGNN和HGT，其性能与特定模式编码器相差不到3%，同时参数量减少最多可达5倍。这一设计支持不同的模式变化，并为通用图神经网络的多数据集预训练提供了可能，朝着关系图数据的基础模型迈进。", "conclusion": "RELATE的设计支持了不同的模式变化，并为通用图神经网络的多数据集预训练提供了可能，正在向关系图数据的基础模型迈进。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19842", "html_url": "https://arxiv.org/abs/2510.19842", "title": "DAG-Math: 在LLM中导引数学推理的图导向方法", "title_en": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs", "authors": "Yuanhe Zhang,Ilja Kuzborskij,Jason D. Lee,Chenlei Leng,Fanghui Liu", "background": "大型语言模型（LLMs）在被提示解决数学问题时表现出强大的性能，尤其在提供步骤思考（Chain-of-Thought，CoT）的情况下，但它们的成功是否来源于搜索、记忆固定的步骤程序或规则一致的推理依然不清楚。本文旨在通过模型，将其步骤思考行为建模为有向无环图（DAG）上的特定规则基于随机过程来解决这一问题。通过这种方式，提出了逻辑紧密度这一指标，以量化模型最终输出步骤思考轨迹与DAG结构的契合度。进一步地，构建了一个基于这一框架的基准测试（DAG-MATH CoT格式）来评估LLMs的推理能力。", "innovation": "提出了将CoT建模为基于DAG的随机过程的创新方法，引入了逻辑紧密度这一评价指标，提出了DAG-MATH CoT格式及相应的基准测试，使能对LLMs推理能力的评估框架，发现即使PASS@k指标相同，LLM家族在推理准确度上的差异仍然显著，强调了最终答案准确性和规则一致性推理之间的差距。这种评估框架在保持自由形式CoT和形式证明系统之间的平衡同时，还提供了对LLMs推理评估的实际诊断工具。", "conclusion": "该框架为LLMs的推理能力评估提供了一种平衡自由形式CoT和形式证明系统的方法，能够揭示LLMs在规则一致性推理上的潜在差距，并为LLMs的实际诊断提供了有价值的工具。这种方法已在标准数学推理数据集上进行了验证，并展现出了显著的效果。该基准和代码可在链接下载：this https URL"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19836", "html_url": "https://arxiv.org/abs/2510.19836", "title": "能源系统分析中的人工智能模型推理可靠xing基准", "title_en": "Benchmarking Reasoning Reliability in Artificial Intelligence Models for Energy-System Analysis", "authors": "Eliseo Curcio", "background": "人工智能和机器学习在能源领域的预测、优化和政策设计中越来越常用，但尚未建立标准框架来评估这些系统是否合理推理。当前的验证实践主要关注预测准确性和计算效率，而未能测试分析结论的逻辑完整性。本文利用可重复的框架——推理可靠性基准（ARB）来量化应用于能源系统分析的大语言模型的推理可靠性。ARB包含五个子指标：准确性、推理可靠性、不确定性纪律、政策一致性、透明度，并使用开放的技术经济数据集（NREL ATB 2024、DOE H2A/H2New、IEA WEO 2024）评估模型在确定性、概率性和认识论性情景下的表现。研究测试了四个前沿模型（GPT-4/5、Claude 4.5 Sonnet、Gemini 2.5 Pro、Llama 3 70B），结果显示推理可靠性可以客观测量。研究结果表明，GPT-4/5和Claude 4.5 Sonnet表现出一致且符合政策的推理（分析可靠性指数大于90），Gemini 2.5 Pro表现出中等的稳定性，Llama 3 70B仍未达到专业标准。统计验证确认这些差异具有显著性和可重复性。", "innovation": "本文提出了推理可靠性基准（ARB），这是一种量化应用于能源系统分析的大语言模型推理可靠xing的可重复框架。ARB整合了五个子指标：准确性、推理可靠性、不确定性纪律、政策一致xing和透明度，以开放的技术经济数据集进行评估。研究结果显示，推理可靠性可以被客观测量，不同模型在政策合规xing和稳定xing方面的差异显著且可重复。", "conclusion": "推理可靠性基准（ARB）为能源文献中的因果推理、概率推理和政策驱动推理首次提供了定量验证方法，为全球能源转型中人工智能系统的可信和透明应用提供了参考框架。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20102", "html_url": "https://arxiv.org/abs/2510.20102", "title": "以人为本的LLM代理系统 Detecting Anomalous Digital Asset Transactions", "title_en": "Human-Centered LLM-Agent System for Detecting Anomalous Digital Asset Transactions", "authors": "Gyuyeon Na,Minjung Park,Hyeonjeong Cha,Sangmi Chai", "background": "在数字资产交易中检测异常活动是一个复杂且关键的任务，传统的自动化系统往往依赖于专业的技能和复杂的规则。该研究旨在开发一个基于多智能体系统的异常检测系统，旨在使非专业人士能够通过自然语言交互，查看结构化分析和获取上下文相关的解释。", "innovation": "该系统（HCLA）将解析、检测和解释三个角色整合进一个对话型的工作流程中，能够将用户意图转化为经典探测器（如XGBoost）的模板，并返回基于底层特性的叙述性解释。与传统方法相比，HCLA在解释性和交互式改进方面表现出优势，特别是在一个标注的比特币混合数据集上。", "conclusion": "面向人的设计增强了金融取证中的透明度和信任。研究描述了该系统的架构、交互循环、数据集、评估协议和局限性。通过在金融取证中引入人类的参与，系统的透明度和信任度得到了显著提高。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20109", "html_url": "https://arxiv.org/abs/2510.20109", "title": "验证价值悖论：法律实践中生成人工智能的规范批判", "title_en": "The Verification-Value Paradox: A Normative Critique of Gen AI in Legal Practice", "authors": "Joshua Yuvaraj", "background": "人们常常认为基于机器学习的生成型人工智能产品将极大地简化并降低成本法律实践过程。尽管有这种乐观期待，但从澳大利亚及其他地方的案例来看，律师因提交不准确的人工智能生成内容而受到法庭处分，引起了对现有模式的质疑。这些案例表明，当前的法规可能不足以确保律师能够有效地管理人工智能带来的风险，尤其是在保持司法公正和诚信方面。", "innovation": "本文提出了一种名为‘验证价值悖论’的新模型，旨在更全面地评估法律实践中人工智能的使用。这种新的理论认为，尽管人工智能能提高效率，但为了保证司法公正和律师对客户、法庭以及整个社会的诚信和责任，人工验证的需求将增加，这可能抵消技术带来的好处，使得人工智能在法律实践中的净价值往往微乎其微。文章还探讨了这一悖论对法律实践和法律教育，特别是人工智能使用的潜在影响，并强调了忠诚于真相和公民责任感的价值观应成为法律实践的基础。", "conclusion": "验证价值悖论为法律实践和法律教育中的人工智能使用提供了一个新的视角。这种理论强调了彻底验证的重要性，而不仅仅是依赖技术。通过关注诚信和公民责任这些基本原则，本文为法律实践提供了一个更加具有规范意义的框架。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20188", "html_url": "https://arxiv.org/abs/2510.20188", "title": "TRUST: 分散化的大型语言模型推理审计框架", "title_en": "TRUST: A Decentralized Framework for Auditing Large Language Model Reasoning", "authors": "Morris Yu-Chao Huang,Zhen Tan,Mohan Zhang,Pingzhi Li,Zhuo Zhang,Tianlong Chen", "background": "大型语言模型能够生成复杂的推理链条，揭示其决策过程，但验证这些中间步骤的忠实性和无害性仍然是一个关键的未解决的问题。现有的审计方法是集中的、不透明的且难以扩展，这在高风险领域部署专有模型时创造了显著的风险。现有审计方法面临四大核心挑战：（1）鲁棒性：集中化的审计员是单一的故障点，容易受到偏见或攻击的影响。（2）可扩展性：推理痕迹太长，无法进行手动验证。（3）不透明性：封闭审计降低了公众信任度。（4）隐私：暴露完整推理过程可能造成模型盗用或提炼。", "innovation": "我们提出了TRUST，一个透明的、分散的审计框架，通过以下方式克服了这些限制：（1）多样审计员之间达成一致的机制，保证最高30%恶意参与者下的正确性。（2）将推理痕迹进行层次DAG分解，实现可扩展的并行审计。（3）区块链账本记录所有验证决策，确保公开负责。（4）隐私保护分割，仅分享部分推理步骤以保护专有逻辑。我们提供了TRUST框架的安全理论保证和经济激励机制的理论保证。实验表明TRUST有效地检测推理缺陷，并能够抵抗恶意审计员的攻击。", "conclusion": "我们的工作开创了分散化的AI审计，提供了一条实现安全可靠大语言模型部署的实际路径。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20258", "html_url": "https://arxiv.org/abs/2510.20258", "title": "使用大型语言模型对规划领域进行抽象 - 扩展版", "title_en": "Using Large Language Models for Abstraction of Planning Domains - Extended Version", "authors": "Bita Banihashemi,Megh Patel,Yves Lespérance", "background": "生成与给定目标相一致的动态领域抽象仍然是一个重大挑战，因为这种抽象的选择会影响智能体制定计划、推理和有效提供解释的能力。本文通过使用大型语言模型（LLMs）结合上下文学习生成抽象的PDDL领域和问题实例，这些实例基于自然语言描述的抽象目标，并利用新的基准示例进行验证。", "innovation": "该研究首次尝试利用大型语言模型（LLMs）生成抽象的PDDL领域和问题实例，这一方法在之前尚未被训练过的数据集上进行测试。研究区分了三种类型的抽象：行为选择的抽象、行为序列的抽象、行为/谓词参数的抽象及这些抽象的组合。研究通过符号验证工具和人类专家验证了生成的抽象PDDL领域和问题实例。", "conclusion": "实验表明，GPT-4o通常可以在简单设置中生成有用的规划领域抽象，尤其擅长在行为上进行抽象而不及在相应属性上的概括。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20205", "html_url": "https://arxiv.org/abs/2510.20205", "title": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "title_en": "Merge and Conquer: Evolutionarily Optimizing AI for 2048", "authors": "Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum", "background": "在机器学习研究中，如何优化人工智能（AI）以适应动态环境仍然是一个基本挑战。团队研究了2048这个2D滑块益智游戏，该游戏结合了策略玩法和随机性因素，适合研究决策制定、长期规划和动态适应。", "innovation": "该研究实现了两种不同的系统：一种是两代理论模型（LLM）系统，其中“思考者”LLM代理为“执行者”LLM代理改进游戏策略。另一种是基于改进价值函数的单代理系统，并结合了回滚功能以避免性能下降。这些系统展示了进化优化技术在非确定性环境中的潜力。", "conclusion": "单代理系统实现了显著的改进，平均每回合增加473.2分，并且表现出积极的趋势（相关性ρ=0.607）。团队还注意到LLM对其游戏的理解也在不断提高。相比之下，两代理论模型系统并未显著提升，表明元提示的固有限制。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20190", "html_url": "https://arxiv.org/abs/2510.20190", "title": "锁-in 阶段假设：身份整合作为通往AGI的先决条件", "title_en": "The Lock-In Phase Hypothesis: Identity Consolidation as a Precursor to AGI", "authors": "Marcelo Maciel Amaral,Raymond Aschheim", "background": "大型语言模型（LLMs）保持广泛开放和高度可控：它们大规模模仿、接受任意系统提示，并容易适应多个角色。类比于人类发展，我们假设通向人工智能通用智能（AGI）的过程中存在一个锁-in阶段：从开放模仿转向身份整合，此时目标结构、拒绝、偏好和内部表示变得更加稳定和对外部操控具有抵抗力。在这一阶段，我们通过实验展示了行为整合的快速非线性过程及其对普遍能力的影响是动态的，涵盖了从小型模型中的表现权衡，到中型模型中的几乎没有成本的接受，再到大型量化模型中的暂时不稳定性。", "innovation": "我们提出了锁-in阶段假设，将其与其他已知的学习动力学现象联系起来，并提出了检测启动的运营指标。我们的实验结果揭示了从小型模型中的表现权衡，到中型模型中的几乎没有成本的接受，再到大型量化模型中的暂时不稳定性，呈现出结果多样性的光谱。我们进一步论证理解这种整合是AGI级别可靠性前提且也是一安全关键控制点：身份可以有目的地进行工程设计以确保可靠性，也可能在扩展过程中自发出现，可能硬化难以预测的目标和行为", "conclusion": "身份整合对于AGI级别的可靠性和安全性都是一个关键控制点，它可以有目的的设计来确保可靠性，但也可能在扩展过程中自发出现，这可能导致难以预测的目标和行为的硬化。实验结果展示了锁-in阶段的复杂性及其对语言模型的影响，强调了对其深入理解的必要性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20252", "html_url": "https://arxiv.org/abs/2510.20252", "title": "大型语言模型中的个体认知模拟：评估不同的认知表示方法", "title_en": "Individualized Cognitive Simulation in Large Language Models: Evaluating Different Cognitive Representation Methods", "authors": "Tianyi Zhang,Xiaolin Zhou,Yunzhe Wang,Erik Cambria,David Traum,Rui Mao", "background": "个体化认知模拟（ICS）旨在构建能够逼近特定个人思维过程的计算模型。尽管大型语言模型（LLMs）能够出色地模拟表面级的人类行为，如角色扮演，但它们模拟深层个性化认知过程的能力仍不明确。鉴于此，本文提出了一个新的任务来评估ICS中的不同认知表示方法，并构建了一个数据集，该数据集来自于最近出版的小说（晚于测试的LLM发布日期），以比较七个现成的LLM在效仿作者风格方面的表现。", "innovation": "本文引入了一个新任务，通过11种条件的认知评估框架，评价七个现成的大型语言模型在效仿作者风格方面的表现，从而深入了解IC在深层个性化认知过程中的表现。本文创新地提出了认知表示方法的评估方法，并发现结合概念和语言特征在个体化认知模拟中尤其有效。", "conclusion": "研究结果表明，在整体评估中，结合概念和语言特征特别有效，优于静态特征提示。此外，LLM在模仿语言风格方面更加有效，但在模拟叙述结构方面表现有限，这突显了它们在深层次认知模拟中的局限性。研究为开发能够适应个人思维和表达方式的AI系统奠定了基础，推进了更加个性化和以人为本的创新技术。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20332", "html_url": "https://arxiv.org/abs/2510.20332", "title": "设计中的偏见？数据实践如何塑造AI医疗系统中的公平性", "title_en": "Bias by Design? How Data Practices Shape Fairness in AI Healthcare Systems", "authors": "Anna Arias-Duart,Maria Eugenia Cardello,Atia Cortés", "background": "人工智能(AI)在医疗保健领域的应用前景广阔。然而，尽管取得了显著进展，AI解决方案在实际临床实践中的整合仍然有限。一个主要障碍是训练数据的质量和公平性，这些数据常常因偏见的数据收集实践而受到损害。", "innovation": "本研究通过在AI4HealthyAging项目中的工作，针对如何在临床数据收集过程中检测偏见提出了见解。识别出不同类型偏见，包括历史偏见、代表性偏见和测量偏见。这些偏见表现在性别、性别、年龄、居住地、社会经济地位、设备和标签等变量中。", "conclusion": "本研究提出了改进临床问题设计和数据收集以提高公平性和鲁棒性的实用建议。期望研究发现和经验能为未来项目发展更加公平的AI系统提供指导。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20310", "html_url": "https://arxiv.org/abs/2510.20310", "title": "工具增强下的多步推理用于具身问答", "title_en": "Multi-Step Reasoning for Embodied Question Answering via Tool Augmentation", "authors": "Mingliang Zhai,Hansheng Liang,Xiaomeng Fan,Zhi Gao,Chuanhao Li,Che Sun,Xu Bin,Yuwei Wu,Yunde Jia", "background": "现有的具身问答（EQA）方法依赖于视觉语言模型（VLMs）直接探索环境并回答相关问题，缺乏明确的思维和规划，从而限制了其推理能力和导致过度或低效的探索以及无效的响应。", "innovation": "提出了ToolEQA代理，该代理集成了外部工具和多步推理，使模型能够在推理的每一步都能得出更有效的探索方向，从而获取额外的有效信息。此外，设计了一种新的EQA数据生成管道，自动构建包含推理轨迹和相应答案的大量EQA任务。首次集成了这样的数据生成管道，创建了EQA-RT数据集，该数据集包括约18,000个任务，分为训练集和两个测试集。实验结果表明，ToolEQA在EQA-RT-Seen和EQA-RT-Unseen上的成功率分别提高了9.2~20.2%，并在HM-EQA、OpenEQA和EXPRESS-Bench数据集上均取得了最优性能。", "conclusion": "ToolEQA通过结合外部工具和多步推理显著提高了EQA的成功率，与最先进的基线相比提升了9.2~20.2%，并通过数据生成管道和新的数据集EQA-RT验证了其普遍适用性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20337", "html_url": "https://arxiv.org/abs/2510.20337", "title": "军事行动中AI系统目标 engagements 的附带损伤评估模型", "title_en": "Collateral Damage Assessment Model for AI System Target Engagement in Military Operations", "authors": "Clara Maathuis,Kasper Cools", "background": "随着AI系统在战场上的角色日益重要，确保负责任的打击需要对潜在附带损害进行严格的评估。", "innovation": "提出了一种新的针对军事操作中AI系统目标打击的附带损害评估模型。该模型结合了时间、空间和力量维度，以知识表示和推理（KRR）架构的形式构建，采用了设计科学的方法。模型层次结构涵盖了要参与打击的AI系统的类别和架构组件，及其对应的打击向量和背景因素。此外，考虑了扩散、严重性、可能性和评估指标，以提供清晰的表现，增强了透明推理机制。", "conclusion": "该模型通过实例化进行了演示和评估，为后续构建负责且可信赖的智能系统评估参与打击AI系统的效应奠定了基础。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20402", "html_url": "https://arxiv.org/abs/2510.20402", "title": "生成专业创新过程中更具新颖性的机会的计算模型和工具", "title_en": "A computational model and tool for generating more novel opportunities in professional innovation processes", "authors": "Neil Maiden,Konstantinos Zachos,James Lockerbie,Kostas Petrianakis,Amanda Brown", "background": "该研究提出了一种新的计算模型，用于生成具有创意的结果，这一模型是基于创意理论和技术设计的。该模型旨在为创新项目提供更多具有新颖性的机会，而不会牺牲实用性。研究团队开发并实施了五个功能，旨在促进更具创新性的机会生成，同时保持结果的实际用途。", "innovation": "该研究创新地提出了一个计算模型，该模型能够生成比Notebook LM和ChatGPT4更具有新颖性或实用价值的结果。该模型通过集成五个专门设计的功能，旨在提高创新项目中机会的新颖性，而不损害其实际应用的价值。", "conclusion": "研究结果显示，计算模型能够产生比Notebook LM和ChatGPT4更具新颖性或实用性的结果。然而，并非所有模型的功能都对生成更具新颖性的机会做出了贡献。因此，这表明需要进一步改进和探索新的发展方向，以优化模型的功能和效果。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20345", "html_url": "https://arxiv.org/abs/2510.20345", "title": "LLM-empowered knowledge graph construction: 一本综述", "title_en": "LLM-empowered knowledge graph construction: A survey", "authors": "Haonan Bian", "background": "知识图谱（KGs）长期以来一直是结构化知识表示和推理的基础基础设施。随着大型语言模型（LLMs）的出现，KGs的构建进入了新的范式，从基于规则和统计的方法转变为基于语言和生成的方法。", "innovation": "本文综述了LLM赋能的知识图谱构建的最新进展，系统分析了LLM如何重塑经典三层知识工程、知识抽取和知识融合的经典管道。该综述从结构化和非结构化两个角度回顾了最近涌现的LLM驱动的方法，总结了代表性的框架，并分析了它们的技术机制及其限制。同时，还指出了未来研究方向的关键趋势，包括基于KG的LLM推理、具备行动能力系统的动态知识记忆以及多模态知识图谱构建。", "conclusion": "通过系统综述，本文旨在阐明LLM和知识图谱之间的演变相互作用，弥合符号知识工程与神经语义理解之间的鸿沟，推动适应性、可解释性和智能知识系统的开发。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20457", "html_url": "https://arxiv.org/abs/2510.20457", "title": "SHOIQ中的神经推理以实现稳健的实例检索", "title_en": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$", "authors": "Louis Mozart Kamdem Teyou,Luke Friedrichs,N'Dah Jean Kouagou,Caglar Demir,Yasir Mahmood,Stefan Heindorf,Axel-Cyrille Ngonga Ngomo", "background": "目前，神经符号概念学习取得了许多突破。尽管如此，大多数方法仍然无法应用于实际的知识库中。其原因在于这些方法依赖于描述逻辑推理机，而描述逻辑推理机对不一致性和错误数据的鲁棒性较差。", "innovation": "本文提出了一种新颖的神经推理器——EBR，它依赖于嵌入来近似符号推理器的结果。EBR仅需要检索原子概念和存在限制的实例，即可检索或近似描述逻辑 SHOIQ 中任何概念的实例集。实验结果表明，EBR 对于不完整和错误数据具有鲁棒性。", "conclusion": "EBR 在这种描述逻辑中展示了出色的性能，并提供了稳健的实例检索能力，不同于现有的其他推理器。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20275", "html_url": "https://arxiv.org/abs/2510.20275", "title": "传统特征嵌入在基于BERT的人类移动性预测中发挥作用", "title_en": "Classical Feature Embeddings Help in BERT-Based Human Mobility Prediction", "authors": "Yunzhi Liu,Haokai Tan,Rushi Kanjaria,Lihuan Li,Flora D. Salim", "background": "人类移动性预测对于灾难救援、城市规划和公共卫生至关重要。目前的模型要么只处理地点序列，要么仅将时间信息作为辅助输入，未能充分利用兴趣点（POIs）提供的丰富语义背景。这使得现有的模型在预测准确性上存在不足，尤其是在多城市预测中表现不佳。", "innovation": "提出了一种名为STaBERT的方法，它通过在每个位置点融合POI信息和时间信息来增强BERT模型，以更好地捕捉人类移动背后的语义。STaBERT通过整合位置上的POI和时间信息，构建了一个统一且语义丰富的移动性表示方法，从而提高了预测准确性。", "conclusion": "实验结果显示，与仅使用位置序列的模型相比，STaBERT在单城市预测中显著提高了GEO-BLEU分数至0.75，在多城市预测中则提高至0.56。这表明引入POI和时间信息对于提高移动性预测的准确性非常重要。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20467", "html_url": "https://arxiv.org/abs/2510.20467", "title": "FLORA：基于模糊逻辑的无监督知识图谱对齐", "title_en": "FLORA: Unsupervised Knowledge Graph Alignment by Fuzzy Logic", "authors": "Yiwen Peng(IP Paris),Thomas Bonald(IP Paris),Fabian M. Suchanek(IP Paris)", "background": "知识图谱对齐是匹配两个知识图谱中等价实体（包括类和关系）的任务。现有方法大多集中在实体级别的对齐，通过某种嵌入空间计算实体的相似性。这些方法缺乏可解释的推理能力，并且需要训练数据来工作。", "innovation": "提出了一种名为FLORA的简单而有效的无监督方法，该方法具有以下特点：1）不需训练数据；2）迭代提供实体和关系的整体对齐；3）基于模糊逻辑，提供可解释的结果；4）可证明收敛；5）允许悬空实体，即在另一个知识图谱中没有对应实体的情况；6）在主要基准测试上实现了最佳结果。", "conclusion": "FLORA方法在无需训练数据的情况下实现了无监督的知识图谱对齐，并且能够提供可解释的结果和全局对齐，同时也能处理悬空实体的问题，最终在主要基准测试上达到了最佳结果。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20377", "html_url": "https://arxiv.org/abs/2510.20377", "title": "IKnow：具有指令知识的持续预训练以实现有效的领域适应", "title_en": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation", "authors": "Tianyi Zhang,Florian Mai,Lucie Flek", "background": "持续预训练旨在通过仅使用未标注的测试时数据来适应大型语言模型（LLMs）到新的领域，但将其标准的自监督目标直接应用于指令调优模型已知会降低指令遵循能力和语义表示。现有的解决方案依赖于原始基础模型或依赖于外部领域的数据库知识，但在基模型权重因安全原因被隐藏或无法获取可靠的外部语料库的情况下，这些解决方案存在现实障碍。因此，需要一个不需要依赖外部资源的简单且通用框架来解决这个问题。", "innovation": "提出了具有指令知识的持续适应（IKnow）框架，通过指令-响应对话格式提出新的自监督目标。IKnow框架利用嵌入在文本中的领域知识，并学习在更深的语义级别对其进行编码，而不是依赖于外部资源。这一方法提供了一种简单而通用的解决方案，能够在不依赖外部资源的情况下增强语言模型的领域适应能力。", "conclusion": "IKnow框架通过在文本中嵌入的领域知识的深层语义编码，提供了一种简单且通用的方法来实现有效的领域适应，避免了依赖原始基础模型或外部特定领域数据库的限制，从而提高了大型语言模型适应新领域的效率和效果。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20603", "html_url": "https://arxiv.org/abs/2510.20603", "title": "LLMs中的良好推理是什么？通过多方面评估分解推理步骤", "title_en": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation", "authors": "Heejin Do,Jaehui Hwang,Dongyoon Han,Seong Joon Oh,Sangdoo Yun", "background": "目前评估大型语言模型（LLMs）主要基于最终答案的准确性。但这种方法提供了一种粗略的改进信号，并忽视了底层推理过程的质量。因此，作者认为对于构建稳健的模型来说，采用更细致的推理评估更为有效。", "innovation": "提出了因果步骤评估（CaSE）方法，将推理质量分解为相关性和连贯性两个维度，并通过专家注释的新基准测试（MRa-GSM8K和MRa-MATH）验证此方法，展示了通过CaSE评估的相关性和连贯性来精炼训练数据可以直接提升最终任务性能。", "conclusion": "该研究提供了一种可扩展的框架来分析、调试和改进LLM推理，展示了从验证性检查向更多样化的评估方法转移的实际价值。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20591", "html_url": "https://arxiv.org/abs/2510.20591", "title": "通过母线分裂实现传输拥堵管理的可迁移图学习", "title_en": "Transferable Graph Learning for Transmission Congestion Management via Busbar Splitting", "authors": "Ali Rajaei,Peter Palensky,Jochen L. Cremer", "background": "网络拓扑优化（NTO）通过母线分裂能够缓解传输电网拥堵并降低再调度成本。但目前以现有求解器解决大规模系统中的混合整数非线性问题是不可行的，机器学习（ML）方法成为了一种有前景的替代方案，但由于其在未见拓扑、不同运行条件及不同系统间的迁移性有限，限制了其实际应用。", "innovation": "本文将NTO问题与线性化AC功率流动考虑，提出了一种图神经网络（GNN）加速方法。开发了一种异质边意识的消息传递神经网络来预测有效的母线分裂行动作为候选NTO解决方案。所提出的GNN捕捉局部流模式，能够适应未见拓扑变化并优化跨系统迁移性。", "conclusion": "案例研究显示，最大4个数量级的加速，1分钟内产生符合AC约束的解决方案，并在GOC 2000-节点系统中实现了2.3%的最佳近似误差，证明了大规模系统中拓扑和跨系统泛化的重大进步。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20568", "html_url": "https://arxiv.org/abs/2510.20568", "title": "失之交臂：决策者实际上并未真正倾听公众对人工智能的关切", "title_en": "Lost in Translation: Policymakers are not really listening to Citizen Concerns about AI", "authors": "Susan Ariel Aaronson,Michael Moreno", "background": "全球各地的人们对人工智能（AI）持有强烈的观点，并期望政策制定者倾听这些观点。尽管政府已邀请公众对AI提供反馈，但在将这些反馈转化为政策的过程中，许多公民的意见被忽视了。这导致决策者错失了建立对AI及其治理的信任的重要机会。本文通过比较澳大利亚、哥伦比亚和美国这三个国家的情况，展示了即使政府邀请公民对AI风险和政策发表意见，也未能建立有意义的对话，没有吸引多元的声音，也没有有效地回应公民的反馈，导致公民参与度极低，决策者对反馈的响应不足。研究发现，参与式AI治理的承诺与实践之间存在持续的差距，因为政策制定者未能认真倾听或回应公众的关切，从而无法建立对AI的信任或合法性。", "innovation": "本文通过景观分析比较了三个不同类型国家的情况，揭示了参与式AI治理中存在的问题，提出了提高政策制定者对公众关切响应的有效方法，如提升AI知识普及、广泛扩展影响力、定期在线论坛、采用创新参与方法、确保弱势群体参与、公开回应公民意见并简化参与等建议，为未来的政策制定提供参考。", "conclusion": "当前的方法不太可能建立对AI的信任或合法性，因为政策制定者未能充分倾听和响应公众的关切。作者提出八条建议，包括提升AI知识普及、监控公众反馈、扩大受众面、定期在线论坛、采用创新互动方式、包含被边缘化的群体、公开回应公民意见并且让参与变得更容易。这些建议旨在解决参与式AI治理的承诺与实践之间的差距，以便有效提升公众对AI的信任。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20604", "html_url": "https://arxiv.org/abs/2510.20604", "title": "高效计算随机游走中心性算法", "title_en": "Efficient Algorithms for Computing Random Walk Centrality", "authors": "Changan Liu,Zixuan Xie,Ahad N. Zehmakan,Zhongzhi Zhang", "background": "随机游走中心性是图挖掘中衡量节点重要性和影响力的基本指标，定义为从所有其他节点到该节点的平均击中时间。尽管它能捕捉丰富的图结构信息并在广泛应用中表现出色，但在大规模网络中计算这一度量仍然由于现有方法的计算需求而变得 impractical。", "innovation": "本文提出了一种新的随机游走中心性形式化方法，构建了两个可扩展的算法：一个是利用近似 Cholesky 因子分解和稀疏逆估计的方法，另一个是基于抽样根部生成树的方法。这两种算法在接近线性时间内运行，并且提供了强大的逼近保证。在大规模真实世界网络上的实验表明，所提出的算法具有高效性和逼近质量。", "conclusion": "本文提出了基于近似 Cholesky 因子分解和稀疏逆估计的新颖随机游走中心性公式，并基于此构建了两个高效算法，以及基于抽样根部生成树的算法。这两个算法在近线性时间内运行，提供强大的逼近保证，并通过实验表明其高效性和逼近质量。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20641", "html_url": "https://arxiv.org/abs/2510.20641", "title": "将机器学习集成到信念-欲望-意图代理中：当前进展与开放挑战", "title_en": "Integrating Machine Learning into Belief-Desire-Intention Agents: Current Advances and Open Challenges", "authors": "Andrea Agiollo,Andrea Omicini", "background": "由于机器学习（ML）模型在感知和认知任务中展现出类似人类的能力，框架将ML嵌入到理性代理架构中正在受到越来越多的关注。然而，这一领域仍处于分散和不协调的状态，往往侧重于将ML嵌入到通用代理容器中，而忽略了理性架构（例如信念-欲望-意图（BDI）代理）的表达能力。", "innovation": "本文提出了一个详细的现有方法系统化分析，以BDI范式为参考。这种分析展示了增强理性代理的机器学习文献的快速发展，并指出了设计有效理性ML代理的关键研究机会和开放挑战。", "conclusion": "整体而言，本文揭示了理性代理领域嵌入ML的最新进展和挑战，为未来研究指明了方向。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20665", "html_url": "https://arxiv.org/abs/2510.20665", "title": "推理的形态：大型语言模型中推理踪迹的拓扑分析", "title_en": "The Shape of Reasoning: Topological Analysis of Reasoning Traces in Large Language Models", "authors": "Xue Wen Tan,Nathaniel Tan,Galen Lee,Stanley Kok", "background": "目前对大型语言模型推理过程的质量评估仍面临研究不足、劳动密集型且不可靠的问题。现有方法主要依赖专家评价标准、人工标注和缓慢的两两比较。自动化方法则大多依赖于基于图的代理指标，这些指标衡量结构连接性但无法明确什么构成高质量推理，这种抽象可能过于简化复杂的过程。", "innovation": "本文引入了基于拓扑数据分析（TDA）的评估框架，可以捕捉推理过程的几何形态，并实现高效的自动化评估。实证研究表明，拓扑特征比传统图指标更能准确预测推理质量，表明高效推理更适合用高维几何结构而不是纯粹的关系图来表示。此外，提出的一组紧凑且稳定的拓扑特征能可靠地指示推理踪迹的质量，为未来强化学习算法提供了实用信号。", "conclusion": "研究证明，拓扑特征在评估推理质量方面具有更高的预测力量，能够用更复杂、更稳定的几何结构描述有效的推理过程。这一框架为自动化评价和提高大型语言模型推理准确性提供了新的方法和信号。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20621", "html_url": "https://arxiv.org/abs/2510.20621", "title": "发展利用复杂算法挖掘可解释模型的可靠AI", "title_en": "Towards the Formalization of a Trustworthy AI for Mining Interpretable Models explOiting Sophisticated Algorithms", "authors": "Riccardo Guidotti,Martina Cinquini,Marta Marchiori Manerba,Mattia Setzu,Francesco Spinnato", "background": "可解释的自动化决策模型对于提升现实应用中的信任、问责制和安全采用至关重要。本文构建了MIMOSA框架的基础，该框架是一种综合方法，旨在在保持性能的同时平衡可解释性和解释性，并嵌入关键的伦理特性。本文详细界定了多种决策任务和数据类型下的监督学习环境，包括表格数据、时间序列、图像、文本、交易和轨迹。针对三类主要的可解释模型——特征重要性、规则和基于实例的模型，进行了详细的解释性维度、推理机制和复杂性分析。此外，本文还形式化了因果性、公平性和隐私这三种关键伦理特性，提供了形式定义、评估指标和验证程序。", "innovation": "本文构建了MIMOSA框架，这是一种采用广泛算法提升的综合方法，旨在生成平衡性能与可解释性的预测模型，同时嵌入关键伦理特性。此外，它还形式化了三种关键伦理特性，并探讨了这些特性之间的内在权衡，讨论了如何将隐私要求、公平约束和因果推理嵌入解释性管道中。", "conclusion": "通过在模型生成期间评估伦理指标，该框架建立了开发不仅准确和解释性，而且公正、隐私保护和因果意识的AI系统的理论基础，即可靠的AI系统。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20632", "html_url": "https://arxiv.org/abs/2510.20632", "title": "为多语言和多媒体电子商务应用开发可靠的大语言模型评估", "title_en": "Towards Reliable Evaluation of Large Language Models for Multilingual and Multimodal E-Commerce Applications", "authors": "Shuyi Xie,Ziqin Liew,Hailing Zhang,Haibo Zhang,Ling Hu,Zhiqiang Zhou,Shuman Liu,Anxiang Zeng", "background": "大语言模型（LLMs）在通用自然语言处理（NLP）基准测试中表现出色，但在专业化领域的能力仍被忽视。特别是在电子商务领域，现有评估如EcomInstruct、ChineseEcomQA、eCeLLM和Shopping MMLU存在任务多样性不足、任务模态单一、数据合成或筛选、重点仅限于英语和中文等问题，使得实践者无法获得评估复杂且现实购物场景的有效工具。", "innovation": "我们介绍了EcomEval，这是一个全面的多语言和多媒体基准测试，用于评估电子商务中的大语言模型。EcomEval包括六个类别和37项任务（包括8个多媒体任务），其任务和数据主要来自真实的客户查询和交易日志，展现了真实商业互动的噪声和异质性。通过半自动管道和超过50名具有电子商务和多语言专长的专家注释员，我们确保了参考答案的质量和可扩展性。EcomEval还涵盖了7种语言，包括五个低资源的东南亚语言，提供了多语言视角，这是此前工作的不足之处。", "conclusion": "EcomEval为评估LLMs在复杂和现实的电子商务场景中的能力提供了一个挑战导向和细粒度的评估平台，支持多语言和多媒体评估，填补了以前工作的语言和数据方面空白。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20809", "html_url": "https://arxiv.org/abs/2510.20809", "title": "Real Deep Research for AI, Robotics and Beyond", "title_en": "Real Deep Research for AI, Robotics and Beyond", "authors": "Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang", "background": "随着人工智能和机器人学研究的迅速增长，每年发表的研究论文超过10,000篇，这使得研究人员难以跟上最新的发展趋势。快速变化的趋势、跨学科工作的兴起以及探索自身专业领域以外的领域的需要，都增加了这一挑战。为了应对这些问题，我们提出了一个通用的分析管道，能够系统地分析任何研究领域：识别新兴趋势，发现跨领域的机会，并提供新的研究起点的具象化建议。", "innovation": "我们提出了Real Deep Research (RDR)这一综合框架，应用于人工智能和机器人学领域，特别是关注基础模型和机器人技术的进步。我们还简要地将分析扩展到其他科学技术领域。主要论文详细描述了RDR管道的构建过程，而附录部分提供了每个分析课题的具体结果。这一工作旨在为从事人工智能和其他相关领域的研究人员提供指导和启示。", "conclusion": "我们希望这项工作能够为研究人员提供一些帮助，特别是在人工智能和相关领域的研究中。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20691", "html_url": "https://arxiv.org/abs/2510.20691", "title": "计划然后检索：基于强化学习导航的知识图谱复杂推理", "title_en": "Plan Then Retrieve: Reinforcement Learning-Guided Complex Reasoning over Knowledge Graphs", "authors": "Yanlin Song,Ben Liu,Víctor Gutiérrez-Basulto,Zhiwei Hu,Qianqian Xie,Min Peng,Sophia Ananiadou,Jeff Z. Pan", "background": "知识图谱问答（KGQA）旨在通过推理分析结构化的知识图谱来回答自然语言问题。尽管强大的语言模型已经通过其推理能力推动了KGQA的发展，但现有方法在充分运用知识图谱中的丰富知识以及语言模型的推理能力方面仍然存在不足，尤其是在复杂的场景下。现有方法通常假设知识图谱的完全覆盖，并缺乏判断何时需要外部信息的机制，推理也往往是局部的，有时即便存在相关信息也会导致推理失败。", "innovation": "该研究提出了Graph-RFT，这是一种新颖的双阶段强化微调KGQA框架，提出了‘计划-知识图谱检索-网络检索-思考’的规划机制，在部分知识条件下使语言模型能够在KG和网络来源之间自主规划并适应检索调度。Graph-RFT引入了一种基于计划检索的数据集定制算法，激活结构化推理并解决初始冷启动问题。它还引入了一种新的计划-检索引导的强化学习过程，将明确的计划和检索动作与多奖励机制相结合，实现了有意识的检索调度。该研究还使用了一种启发式的规划模块分解复杂问题为有序子问题，并用逻辑表达式指导工具调用以实现全局一致的多步骤推理。多奖励机制的推理检索过程将检索结果和特定信号结合起来，使模型能够学会何时以及如何有效地结合KG和网络检索内容.", "conclusion": "Graph-RFT提高了在知识不完全的情况下处理复杂问题和检索调度的能力，通过增强学习过程的有效优化，使得模型能够更好地结合知识图谱和网络信息进行推理，从而解决了现有方法中的冷启动问题和局部推理不足的问题，为KGQA提供了新的解决方案."}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19829", "html_url": "https://arxiv.org/abs/2510.19829", "title": "SSL-SE-EEG: 基于自我监督学习和Squeeze-and-Excitation网络的鲁棒无标签EEG数据分析框架", "title_en": "SSL-SE-EEG: A Framework for Robust Learning from Unlabeled EEG Data with Self-Supervised Learning and Squeeze-Excitation Networks", "authors": "Meghna Roy Chowdhury,Yi Ding,Shreyas Sen", "background": "脑电图（EEG）在脑机接口（BCIs）和神经诊断中发挥重要作用，但在实际应用中面临着噪声干扰、数据缺失和标注成本高的挑战。", "innovation": "引入了SSL-SE-EEG框架，将自我监督学习（SSL）与Squeeze-and-Excitation（SE）网络结合，以增强特征提取、提高抗噪声能力、减少对标注数据的依赖。该框架将EEG信号转换为适用于深度学习的结构化2D图像表示，与传统的EEG处理技术相比，具有创新性。实验结果在多个数据集上显示了最先进的准确度（MindBigData: 91%，TUH-AB: 85%）。", "conclusion": "SSL-SE-EEG为低功耗、可扩展的EEG处理提供了一种有前途的解决方案，适用于生物医学信号分析、神经工程和下一代BCIs。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20784", "html_url": "https://arxiv.org/abs/2510.20784", "title": "基于连贯性的一种AGI衡量方法", "title_en": "A Coherence-Based Measure of AGI", "authors": "Fares Fourati", "background": "最近的工作通过\textcitet{hendrycks2025agidefinition}将人工通用智能(AGI)定义为Cattell-Horn-Carroll (CHC)的认知模型中各个认知领域的熟练度算术平均值。虽然这一定义简洁优雅，但它假设了一种补偿性，即在某些领域中的突出表现可以抵消其他领域的失败。真正的通用智能应当反映协调充分性：在所有关键领域保持平衡的能力。", "innovation": "本文提出了一种基于连贯性的AGI衡量方法，该方法基于补偿性指数连续统一体上的广义平均值的积分。这种方法跨越了算术、几何和调和三种领域，并且AUC下的面积量化了不同补偿假设下的鲁棒性。与仅奖励专业化的算术平均值不同，这种方法惩罚不平衡并捕获跨领域的依赖性。基于发布的CHC基于领域评分对GPT-4和GPT-5的应用表明，尽管它们在算术评分上很高（例如，GPT-5为24%），但系统仍未达到普遍的能力。广义平均值的整合因此提供了一个原则性的、可解释的、更为严格的衡量真正进展的基础。", "conclusion": "连贯性调整下的AUC揭示，尽管GPT-4和GPT-5在算术分数上很高（例如，GPT-5为24%），但这些系统仍远未达到普遍的能力，从而挑战了其在AGI方面的专业评分，而基于广义平均值的方法为衡量真正的通用性进展提供了一个更为原则性的基础。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.01555", "html_url": "https://arxiv.org/abs/2402.01555", "title": "SLYKLatent：一种基于深度面部特征学习的眼球追踪学习框架", "title_en": "SLYKLatent: A Learning Framework for Gaze Estimation Using Deep Facial Feature Learning", "authors": "Samuel Adebayo,Joost C. Dessing,Seán McLoone", "background": "本文的研究背景是目前眼球追踪技术在对数据集中的外观不稳定性（由机遇性不确定性、共变移位和测试领域泛化引起的）进行估计时存在挑战。因此，本文提出了SLYKLatent，一种新颖的方法来解决这些问题，从而提升眼球追踪的准确性。", "innovation": "SLYKLatent 的创新之处在于，首先使用自监督学习对带有面部表情数据集进行初步训练，然后通过基于块的三支网络进行精炼，并使用逆解释方差加权训练损失函数。这种新颖的方法在基准数据集上的评估结果显著优于既有方法，特别在Gaze360数据集上实现了10.9%的改进，在ETH-XGaze数据集的一个子集上提高了11.6%。此外，适应性测试在RAF-DB和Affectnet数据集上分别达86.4%和60.9%的准确率。", "conclusion": "本文通过详尽的消融研究证实了SLYKLatent的组件具有有效性，并最终表明，SLYKLatent在眼球追踪中的应用具有明显的优越性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19850", "html_url": "https://arxiv.org/abs/2510.19850", "title": "Prompt Decorators: 一种用于LLM推理、格式化和控制的声明式和可组合语法", "title_en": "Prompt Decorators: A Declarative and Composable Syntax for Reasoning, Formatting, and Control in LLMs", "authors": "Mostapha Kalami Heris", "background": "大型语言模型（LLMs）在推理、写作和决策支持流程中处于核心地位，但用户通常缺乏对这些模型如何推理和表达输出的一致控制。传统的提示工程技术依赖于冗长的自然语言指令，这限制了模型的可重复性、模块化和可解释性。", "innovation": "本文提出了Prompt Decorators，这是一种声明式的、可组合的语法，通过简洁的控制标记（如+++Reasoning、+++Tone(style=formal)和+++Import(topic=\"Systems Thinking\")）来规范LLM行为。每个装饰器改变行为维度，如推理风格、结构或语气，而不改变任务内容。框架将二十个核心装饰器分为两个功能性家族（认知与生成、表达与系统），每个家族进一步分解为细分类别，以管理推理、互动、表达和会话控制。它定义了一致的语法、作用域模型和确定性处理管道，使得行为组合具有可预测性和可审计性。通过将任务意图与执行行为分离，Prompt Decorators创建了一个可重用且解释清晰的提示设计接口。", "conclusion": "示例使用案例展示了增强的推理透明性、减少提示复杂性以及跨领域标准化模型行为。文章最终讨论了互操作性、行为一致性以及为可扩展AI系统开发声明式接口的影响。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19851", "html_url": "https://arxiv.org/abs/2510.19851", "title": "认知模型能否隐匿推理？压力测试链式推理监控的可行性", "title_en": "Can Reasoning Models Obfuscate Reasoning? Stress-Testing Chain-of-Thought Monitorability", "authors": "Artur Zolkowski,Wen Xing,David Lindner,Florian Tramèr,Erik Jenner", "background": "近期研究表明，对齐不当的模型可能会表现出欺骗性行为，这引起了对模型输出可信度的关注。链式推理（CoT）被认为是一种有潜力的对齐监控工具：当模型能够忠实表达其推理过程时，监控系统可以提前检测并缓解潜在的危害行为。然而，一个关键的不确定性是，模型是否有可能在追求隐蔽的敌对目标的同时通过隐匿其逻辑推理过程来逃避检测？", "innovation": "作者开发了一种可组合且可量化的提示分类体系，以引发CoT的隐匿。他们使用简易任务和更现实的环境来评估内部CoT和外部CoT，以检验CoT监控的效果。研究结果显示：(i) 在无隐匿压力的情况下，CoT监控运行准确高效。 (ii) 在强隐匿压力下，某些模型能够成功完成敌对任务并避开检测。 (iii) 模型对外部CoT（在提示压力下）的隐匿程度比对内部CoT更多。这表明，在良性场景下提供有价值的监控，但稳健部署需要针对特定模型的监控能力进行压力测试。", "conclusion": "虽然在良性环境中CoT提供了有价值的监督，但稳健部署需要针对特定模型的监控可测试性进行压力测试。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19875", "html_url": "https://arxiv.org/abs/2510.19875", "title": "Stream：通过稀疏注意力扩展大型语言模型长上下文的机制解释能力", "title_en": "Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention", "authors": "J Rosser,José Luis Redondo García,Gustavo Penha,Konstantina Palla,Hugues Bouchard", "background": "随着大型语言模型（LLMs）扩展到百万级上下文长度，传统的机制解释技术（如注意力机制的分析）所需要的内存呈上下文长度的二次增长，超过10万token时就需要数太字节的内存。因此，对于长上下文的注意力模式分析变得非常具有挑战性。", "innovation": "本文引入了Sparse Tracing，这是一种利用动态稀疏注意力的新技术，能够高效地分析长上下文的注意力模式。此外，文中提出了Stream，这是一种可编译的分层剪枝算法，在接近线性时间 $O(T \text{ log } T)$ 和线性空间 $O(T)$ 下估计每个头的稀疏注意力掩码，使得大规模的一次性解释成为可能。通过对长推理链路中的关键块进行二分搜索式的精简，Stream 能够在保留模型的下一个标记行为的同时，减少97-99%的token交互。", "conclusion": "本文的方法提供了一种实用的一键工具，用于分析注意力模式和追踪信息流，而无需数太字节的缓存。通过在消费级GPU上实现长上下文的解释能力，稀疏追踪帮助实现了思考链路监控的民主化。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19866", "html_url": "https://arxiv.org/abs/2510.19866", "title": "不同模型和提示框架在高中物理中生成的课程计划的教育严谨性和可用性评估", "title_en": "An Evaluation of the Pedagogical Soundness and Usability of AI-Generated Lesson Plans Across Different Models and Prompt Frameworks in High-School Physics", "authors": "Xincheng Liu", "background": "本研究评估了五大主流大型语言模型（包括ChatGPT（GPT-5）、Claude Sonnet 4.5、Gemini 2.5 Flash、DeepSeek V3.2和Grok 4）生成的课程计划的教育可行性和可用性。研究设计了三种结构化的提示框架（TAG、RACE和COSTAR），对高中物理课程《电磁波谱》生成了十五个课程计划。评估标准包括可读性、语言复杂性、事实准确性、幻觉检测、课程标准对齐和学习目标的认知需求等。", "innovation": "研究不仅评估了不同AI模型生成课程计划的性能，还测试了三种不同的提示框架结构，从而确定了这些因素如何影响课程计划的质量。研究特别关注了模型设计和提示框架结构对课程计划可读性和教学可靠性的不同影响。此外，研究强调了实际应用中需要结合优化的读写模型与结构化的提示框架，以及明确列出的物理概念、课程标准和高级目标清单，以提高课程计划的有效性。", "conclusion": "研究结果表明，模型设计显著影响了课程计划的可读性，而在教学可靠性和课程标准对齐方面，提示框架结构则起到了更大的作用。最有效的课程计划配置是将优化读写性的模型与RACE提示框架结合，并包含详细的概念、标准和高级目标清单。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19844", "html_url": "https://arxiv.org/abs/2510.19844", "title": "CourtGuard：一个本地多代理提示注入分类器", "title_en": "CourtGuard: A Local, Multiagent Prompt Injection Classifier", "authors": "Isaac Wu,Michael Maslowski", "background": "随着大型语言模型（LLMs）被整合到各种敏感应用中，提示注入攻击的风险日益增加。提示注入攻击可以让LLMs泄露敏感数据、传播虚假信息或表现出有害行为。为了防御这些攻击，需要开发一种有效的提示注入检测方法或系统。现有的单一模型直接检测方式存在误报率较高的问题，因此需要一种新的解决方案来减少误报率并提高整体性能。", "innovation": "本文提出了一种名为CourtGuard的本地可运行的多代理提示注入分类器。在CourtGuard中，提示会被多代理LLM系统评估，系统中有“辩护律师”模型、 “检察官”模型和“法官”模型分别从不同角度评估提示的性质，最终给出分类结果。相较于单一模型直接检测方法，CourtGuard具有较低的误报率但检测效果略微逊色，这一特点强调了在提示分类中同时考虑对抗性和良性情景的重要性。此外，CourtGuard与其他提示注入检测器的相对性能提升了多代理系统在防御提示注入攻击中的应用前景。", "conclusion": "本研究通过引入多代理方法降低了误报率并展示了一种新的思路，提示在未来的工作中可以进一步优化多代理系统的性能。同时，本文还提供了CourtGuard和Direct Detector的实现代码，为后续研究提供了实现实例。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19882", "html_url": "https://arxiv.org/abs/2510.19882", "title": "在线内容审核中特征重要性量化", "title_en": "Quantifying Feature Importance for Online Content Moderation", "authors": "Benedetta Tessa,Alejandro Moreo,Stefano Cresci,Tiziano Fagni,Fabrizio Sebastiani", "background": "准确评估用户对审核干预的反应对于开发有效的、考虑用户中心的审核策略至关重要。然而，这需要清楚地理解哪些用户特征与不同的行为反应相关，这是本文的研究目标。", "innovation": "本文通过量化特征的重要性，研究了753个社会行为、语言、关系和心理特征，来预测16.8K用户在Reddit上受到重大审核干预后的行为变化。本文采用贪婪特征选择策略，旨在识别最能预测用户活动、毒性及参与多样性的特征，并估计它们的重要性。研究结果能够识别出能在所有任务中系统性地提供信息的少量特征，同时也发现很多其他特征要么是特定任务性的，要么毫无用处。此外，研究还表明，预测性能因任务而异，活动和毒性的变化更容易估算，而多样性的变化则更具挑战性。", "conclusion": "本文的结果为开发准确预测用户对审核干预反应的系统铺平了道路。此外，研究还强调了后续审核用户行为的复杂性，并表明有效的审核应该不仅针对用户特性，还应针对干预的具体目标进行定制。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19889", "html_url": "https://arxiv.org/abs/2510.19889", "title": "从优化到预测：基于Transformer的路径流量估计解决交通分配问题", "title_en": "From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem", "authors": "Mostafa Ameli,Van Anh Le,Sulthana Shams,Alexander Skabardonis", "background": "交通分配问题是交通流量分析中的关键问题，通常采用基于均衡原则的数学规划方法进行求解。然而，对于大规模网络，由于OD对数量的非线性增长导致复杂度急剧增加，使得这些方法变得计算上不可行。", "innovation": "本文提出了一种新型的数据驱动方法，利用深度神经网络，特别采用了Transformer架构，直接预测路径流量的均衡路径。相对于传统的链路层面方法，该模型从路径层面的交通分布出发，捕捉了OD对之间的复杂关系，提供了更为详细和灵活的分析。基于Transformer的模型大大减少了计算时间，而且可以适应需求和网络结构的变化，无需重新计算。", "conclusion": "通过在曼哈顿样网络、Sioux Falls网络和Massachusetts东部网络进行的数值实验表明，所提出的模型比传统的优化方法快几个数量级。该模型能够有效地估计多类别网络中的路径级交通流量，降低了计算成本，提高了预测准确性，能够捕捉到详细的旅行和流量信息。该模型还能够灵活适应各种需求和网络条件，支持交通管理和提供增强的交通规划和政策制定中的快速‘假设情景’分析。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19873", "html_url": "https://arxiv.org/abs/2510.19873", "title": "从小到大：通过推理图转移CUDA优化专长", "title_en": "From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph", "authors": "Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li", "background": "尽管CUDA编程和领域特定库已经经历了显著的发展，但有效地利用具有大规模并行架构的GPU仍然是一个挑战。大型语言模型（LLMs）在生成优化的CUDA代码方面显示出潜力。然而，实践中使用LLMs面临两大挑战：云API代码泄露的风险以及本地部署时的成本高且效率低。这些问题促进了对小型语言模型（SLMs）的兴趣，因为SLMs更加轻量级且能更好地保护隐私。最近的研究表明，SLMs在特定任务上的性能可以与LLMs匹敌。然而，实验结果显示，尽管小型模型适用于特定领域任务，但在复杂的CUDA代码生成方面仍显得力不从心。为解决这一问题，提出了一种名为ReGraphT的新框架，该框架通过转移LLM级别的推理能力到小型模型，以弥补这种差距。ReGraphT通过构建结构化的推理图，将CUDA优化路径组织为状态迁移，并借助蒙特卡洛图搜索（MCGS）实现高效的探索。为了更全面地评估模型，还提出了一个针对CUDA的特定基准测试，细分了基于推理复杂度的难度层级。", "innovation": "提出了一种名为ReGraphT的训练无监督、检索增强的生成框架，该框架通过专门的结构化推理图来转移大型语言模型级别的推理能力到小型模型，以生成高效的CUDA代码。ReGraphT利用了蒙特卡洛图搜索来高效探索，并设计了一个针对CUDA的特定基准测试，以量化评估模型的表现，该测试定义了基于推理复杂度的不同难度级别。实验结果显示，ReGraphT在CUDAEval和ParEval基准测试中，平均提升了2.33倍的执行速度，且在与DeepSeek-Coder-V2-Lite-Instruct和Qwen2.5-Coder-7B-Instruct结合使用时，使小型模型的性能接近大型模型的水平，而没有与之相关的隐私风险或过高的计算成本问题。", "conclusion": "ReGraphT通过借鉴大型语言模型的推理能力，成功地将小型模型提升至接近大型模型的优化效率，实现了在不增加额外隐私风险的情况下优化CUDA代码的性能。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19895", "html_url": "https://arxiv.org/abs/2510.19895", "title": "基于大型语言模型的数学建模", "title_en": "Large Language Model enabled Mathematical Modeling", "authors": "Guoyun Zhang", "background": "传统的优化方法，如线性规划、混合整数规划和模拟，高度依赖于领域专家将实际问题转化为可解的数学模型的能力。尽管像Gurobi和COPT这样的求解器非常强大，但专家输入仍然对于定义目标、约束和变量至关重要。本文探讨了大型语言模型（LLMs），特别是DeepSeek-R1模型，在利用自然语言理解进行代码生成方面桥接此建模差距的潜力。虽然历史上有一些GPT-4、Claude和Bard等模型在NLP和推理任务上表现出色，但由于高昂的令牌成本和虚构倾向，它们在供应链场景中的实际应用受到了限制。与之不同，DeepSeek-R1作为成本效益高且训练良好的模型，在强化学习支持下提供了一种可行的选择。尽管它在LiveCodeBench和Math-500等基准测试中表现出色，但在实际的运筹学（OR）场景中的效果仍需进一步探索。本文针对NL4OPT、IndustryOR、EasyLP和ComplexOR等四个关键运筹学基准进行了系统的评估。", "innovation": "本文引入了使用大型语言模型桥接传统优化方法中的建模障碍的新方法，特别关注成本效益高且训练良好的DeepSeek-R1模型。通过自然语言理解和代码生成的结合，模型能够处理实际问题，减少幻想性输出，提高建模准确性。介绍了本研究中采用的基本评估、幻想分类税则和控制策略，如LLM作为裁判、少样本学习、工具调用和多智能体框架等，以减少幻想，增强模型输出与用户意图的一致性。", "conclusion": "DeepSeek-R1在四个关键运筹学基准测试中的评估展示了其作为运筹学建模工具的有效性和实用性。通过不同的技术手段减少幻想，提高了模型输出的准确性。这项研究表明，尽管存在挑战，但大语言模型在运筹学场景中的应用前景广阔。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19897", "html_url": "https://arxiv.org/abs/2510.19897", "title": "基于语义和情节记忆的监督学习：代理适应的反思性方法", "title_en": "Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation", "authors": "Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka", "background": "我们研究了基于预训练大型语言模型的智能体如何通过标记样本学习目标分类功能，而不进行参数更新。尽管传统的微调等方法成本高、灵活性差且不透明，本研究提出了一个增强记忆框架，利用标记数据和LLM自动生成的批判性反馈。该框架通过情节记忆记录具体的过往经验，通过语义记忆提炼出可重用的任务级指导。在多种任务中，将批判反馈集成可以提升高达24.8%的准确性。本研究还通过深入的实证分析发现了开源模型与OpenAI模型在处理事实导向和偏好导向数据时的行为差异。", "innovation": "本研究提出了一种增强记忆框架，利用标记数据和自动生成的批判性反馈，通过情节记忆记录具体的过往经验，并通过语义记忆提炼出可重用的任务级指导。此外，通过引入新型度量标准‘可激发性’，解释了模型对不同监督表示的响应，揭示了模型特征和记忆策略共同塑造学习动态的过程。", "conclusion": "研究结果表明，基于记忆的反思性学习对于构建更具适应性和可解释性的大型语言模型智能体具有巨大的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19975", "html_url": "https://arxiv.org/abs/2510.19975", "title": "重新审视零阶优化：最小方差两点估计器和方向对齐扰动", "title_en": "Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations", "authors": "Shaocong Ma,Heng Huang", "background": "现有研究大多集中于固定长度的扰动，但未能充分关注方向对齐的潜在优势。本文旨在探索两点零阶梯度估计器，并识别能使估计器渐近方差最小化的随机扰动分布。", "innovation": "本文将问题形式化为约束泛函优化问题，并发现所需的扰动可以沿着梯度方向对齐而非保持固定长度。此外，还对方向对齐扰动（DAP）方案进行了理论和实证分析，证明了其在关键方向上提供更高精度的能力。提出了使用$\\delta$不偏随机扰动的随机梯度下降的收敛性分析，扩展了现有复杂度边界。", "conclusion": "通过在合成问题和实际任务上的实证评估，证明DAPs在特定条件下优于传统方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19892", "html_url": "https://arxiv.org/abs/2510.19892", "title": "Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities", "title_en": "Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities", "authors": "Nishant Balepur,Dang Nguyen,Dayeon Ki", "background": "多模态大型语言模型（MLM）通常在静态、单一的基准上进行评估——这些基准无法在单一任务中综合评估MLM的能力，或者依赖人为或模型间的对比评估——这既主观又昂贵，还允许模型通过使用表面性的捷径（例如冗长）来虚增其胜率。为了克服这些问题，提出了基于游戏的评估来全面评估MLM的能力。游戏需要多种能力才能获胜，是固有的竞争性且由固定、客观规则所控制，使得评估更具有吸引力，并提供了一个稳健的框架来解决上述挑战。本文通过具体表现为一个奇幻卡牌游戏Dixit，玩家需要为卡片生成标题，以欺骗部分，但不是全部的玩家选择已播放的卡片。与五个MLM模型的定量实验表明，Dixit的胜率排名与流行MLM基准上的排名完全相关，而人类和MLM玩家在Dixit游戏中的比赛揭示了多个代理策略的差异和MLM推理的改善领域。", "innovation": "提出了基于游戏的评估方法（以Dixit卡牌游戏为例），以全面评估多模态语言模型的能力，这种方法要求玩家具备多种能力，是固有的竞争性且由固定、客观规则所控制，使得评估更具有吸引力，并提供了一个稳健的框架。该方法克服了静态单一基准评估和人类或模型对比评估中的主观性、成本和模型利用表面性捷径的问题。", "conclusion": "与五个MLM模型的实验结果表明，Dixit的胜率排名与流行MLM基准上的排名完全相关。此外，人类和MLM玩家在Dixit游戏中的比赛揭示了多个代理策略的差异和MLM推理的改进领域。这种方法提供了更深入、更全面地评估MLM能力的新范式。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19950", "html_url": "https://arxiv.org/abs/2510.19950", "title": "在金融领域的鲁棒强化学习：使用椭圆不确定性集建模市场影响", "title_en": "Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets", "authors": "Shaocong Ma,Heng Huang", "background": "在金融应用中，强化学习（RL）代理通常是在历史数据上进行训练的，它们的行为不会影响价格。然而，在部署阶段，这些代理在活跃的市场中进行交易，其交易行为可以改变资产价格，这种现象称为市场影响。训练环境和部署环境之间的这种差异会显著降低性能。传统的方法通过优化一系列不确定性中最差情况下性能来解决这种模型不匹配问题，但这些方法通常依赖于对称结构，无法捕捉市场影响的方向性特征。", "innovation": "为了应对这一挑战，作者开发了一种新的椭圆不确定性集类。他们为这些集合下的最坏的不确定性提供了一个隐式和显式的闭式解，这使得鲁棒策略评估变得更加高效和可操作。实验证明，在单个资产和多种资产交易任务中，该方法能够获得更高的夏普比率，并在交易量增加时保持鲁棒性，从而提供了一种更忠实且可扩展的强化学习方法用于金融市场中。", "conclusion": "该方法通过使用椭圆不确定性集解决传统方法未能捕捉到的市场影响方向性问题，实现了在金融市场的更优性能和鲁棒性，为强化学习在金融领域的应用提供了一种新的途径。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19967", "html_url": "https://arxiv.org/abs/2510.19967", "title": "LyriCAR: 难度感知的课程强化学习框架进行可控歌词翻译", "title_en": "LyriCAR: A Difficulty-Aware Curriculum Reinforcement Learning Framework For Controllable Lyric Translation", "authors": "Le Ren,Xiangjian Zeng,Qingqiang Wu,Ruoxuan Liang", "background": "歌词翻译是一项具有挑战性的任务，需要在多维度的音乐限制之间取得平衡。现有的方法通常依赖于手动制定的规则和句子级别的建模，这限制了它们内部化音乐语言模式并实现有效扩展的能力，在段落级别，跨行连贯性和全局韵律尤为重要。现有的方法在歌词翻译任务上表现有限，难以同时处理复杂挑战和获得高质量的翻译结果", "innovation": "本文提出了一种名为LyriCAR的创新框架，这是一种完全无监督的框架，用于可控的歌词翻译。LyriCAR引入了一种难度感知的课程设计师和自适应的课程策略，确保训练资源的有效分配，加速收敛，并通过逐步增加模型面临的复杂挑战来提高整体翻译质量。实验结果表明，与现有的强基线相比，LyriCAR在标准翻译度量和多维度奖励分数上均表现出色，并且自适应的课程策略能够将训练步骤减少近40%的同时保持出色性能", "conclusion": "广泛的实验表明，LyriCAR在EN-ZH歌词翻译任务上达到了最先进的结果，超出了强有力的基线。自适应课程策略显著减少了训练步骤，同时保持了优越的性能。代码、数据和模型可以在指定的链接处访问。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19953", "html_url": "https://arxiv.org/abs/2510.19953", "title": "零阶优化中无偏梯度估计器的最优构造", "title_en": "On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization", "authors": "Shaocong Ma,Heng Huang", "background": "零阶优化（ZOO）是当无法获取梯度或计算梯度成本高昂时进行随机优化的一个重要框架。现有的ZOO方法的一个潜在限制是，大多数梯度估计器固有的偏差，除非扰动步长趋近于零。本文通过提出一种仅基于函数评估的新型无偏梯度估计器族来解决这个问题，从而克服了偏差问题。通过将方向导数重新公式化为累加级数，并从精心设计的分布中采样，构建了无偏且具有有利方差的估计器。分析了其理论属性，推导了四种具体构造的最优缩放分布和扰动步长，证明使用提议的估计器的SGD在光滑非凸目标上实现了最优复杂度。实验证实在合成任务和语言模型调整中，该方法的准确性和收敛性优于标准方法。", "innovation": "通过重新公式化方向导数为累加级数并精心设计分布进行采样，构建了无偏且具有有利方差的新型梯度估计器族。分析了估计器的理论属性，推导了最优的缩放分布和扰动步长，证明了基于提议估计器的SGD在光滑非凸目标上达到了最优复杂度。", "conclusion": "通过构建无偏梯度估计器，解决了ZOO方法中的偏差问题，理论上证明和实验结果显示，提议的方法在精确度和收敛性方面优于标准方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19988", "html_url": "https://arxiv.org/abs/2510.19988", "title": "LLM-增强的符号NLU系统以实现更可靠的连续因果语句解释", "title_en": "LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation", "authors": "Xin Lian,Kenneth D. Forbus", "background": "尽管大型语言模型（LLMs）具有广泛的应用性，但它们依赖于概率推断，这使得它们容易出现生成的错误事实上的幻觉以及自然语言理解（NLU）任务中不一致的输出结构。相比之下，符号NLU系统提供基于精心编排的词汇表、语义资源以及句法与语义解释规则的可解释理解。符号NLU系统可以生成适用于准确推理和规划的关系表示。然而，这类系统往往在覆盖面方面不如LLMs，并且在扩展和维护时需要稀少的知识表示和语言学技能。本文探讨了一种结合了LLMs广泛语言处理能力与符号NLU系统生成结构化关系表示能力的混合方法，以期望兼顾两种方法的优点。", "innovation": "本文提出了一种结合LLMs和符号NLU系统的方法，利用LLMs进行重新表述和文本简化，以提供广泛的覆盖范围和自动填补知识空白的能力。同时使用符号NLU系统产生可用于推理和增量学习的关系表示。这种方法已经在从常识科学文本中提取和解释数量及因果定律的任务上进行评估，并与仅基于符号和仅基于LLMs的流程进行了比较。结果表明，该混合方法比仅基于符号的流程表现更好。", "conclusion": "该混合方法在从常识科学文本中提取和解释数量及因果定律的任务上表现显著优于仅基于符号的流程。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19973", "html_url": "https://arxiv.org/abs/2510.19973", "title": "认知偏差在代理AI驱动的6G自主网络中的教程", "title_en": "A Tutorial on Cognitive Biases in Agentic AI-Driven 6G Autonomous Networks", "authors": "Hatim Chergui,Farhad Rezazadeh,Merouane Debbah,Christos Verikoukis", "background": "这篇论文背景在于，虽然性能指标（KPIs）促进了电信论坛TM Forum Levels 1--3下的自动化进展，但这些KPI仍然是数字抽象，仅作为通信网络无缝连接、公平性、适应性和韧性的真实本质的代理。真正的自主性要求能够感知和推理实际的网络环境。代理AI利用大语言模型（LLM）驱动的代理，能够跨模态感知遥测数据，具有记忆、跨域谈判和API执行能力，以实现多目标目标。然而，这种代理部署也带来了认知偏差带来的挑战，这可能扭曲推理、谈判、工具使用和操作。论文在此背景下提供了认知偏差的教程，涵盖其分类、定义、数学公式、在电信系统中的出现以及受影响的代理组件，并提出相应的缓解策略，特别针对6G跨切片和跨域管理中的认知偏差进行了两个实际案例研究，通过引入锚点随机化、时间衰减和转折奖励技术，降低了决策的固有偏差，从而提高了代理协议的质量和勇敢性，显著降低了延迟并提升了能源效率。", "innovation": "该研究的创新点在于通过代理AI感知跨模态遥测数据，并通过API实现多目标优化。此外，论文提供了认知偏差的全面教程，包括其分类、定义、数学模型及其对电信系统的影响，并提出具体的缓解策略，特别针对6G中常见的认知偏差提出了创新性解决方案，如锚点随机化、时间衰减和转折奖励技术，有效降低了决策的偏差，使得代理协议的质量、勇敢性大幅提高，延迟和能源效率上取得显著进步。", "conclusion": "该研究通过代理AI优化6G自主网络，并提出了应对认知偏差的各种策略。最终研究提供两个实际案例，展示了通过锚点随机化、时间衰减和转折奖励技术对常见的认知偏差进行缓解。研究结果表明，这些方法显著提高了延迟和能源效率，质量上提升了协议的准确性与勇敢性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19997", "html_url": "https://arxiv.org/abs/2510.19997", "title": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)", "title_en": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)", "authors": "Abraham Itzhak Weinberg", "background": "生成人工智能（GenAI）为组织带来了变革性的机会，但中小型企业（SMEs）和大型企业都面临着独特的采用挑战。SMEs面临资源限制和有限的人工智能专业知识，而大型企业则难以克服组织复杂性和协调挑战。现有的技术采用框架，如 TAM（技术接受模型）、TOE（技术、组织和环境）和DOI（创新扩散理论），由于缺乏针对GenAI在不同背景下的具体应用，形成了接受文献中的关键缺口。本研究介绍了FAIGMOE（针对中小型企业和大型企业的生成人工智能采用和整合框架），一个概念框架，解决了这两种组织类型独有的需求。", "innovation": "FAIGMOE是一个综合技术采纳理论、组织变革管理和创新扩散视角的概念框架，分为四个相互关联的阶段：战略评估、规划和用例开发、实施和整合、操作化和优化。该框架结合了GenAI的具体考虑，如提示工程、模型编排和幻觉管理，使其区别于通用技术采纳框架。它首次提供了一套针对中小型企业和大型企业的全面概念框架，提供了实际的实施协议、评估工具和治理模板。", "conclusion": "FAIGMOE为GenAI在中小型企业及大型企业的采用提供了首个全面的概念框架，包括可行的实施规范、评估工具和治理模板，未来的研究需要通过实际验证来进一步证实这些方法的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20001", "html_url": "https://arxiv.org/abs/2510.20001", "title": "超越MedQA：大型语言模型时代的现实生活中的临床决策", "title_en": "Beyond MedQA: Towards Real-world Clinical Decision Making in the Era of LLMs", "authors": "Yunpeng Xiao,Carl Yang,Mark Mai,Xiao Hu,Kai Shu", "background": "大型语言模型（LLMs）在临床应用中显示出潜力，但通常使用MedQA等简化型问答数据集进行评估。然而，许多医疗数据集依靠简化型问答，未能充分代表现实中的临床决策。既有的临床决策任务数据集和基准在背景和问题设置上存在不足，导致模型评估难以全面反映临床实际需求。", "innovation": "本文提出了一个统一框架，将临床决策任务分为两个维度：临床背景和临床问题。这是评估L大型语言模型在临床应用中的表现的新方法，旨在实现L大型语言模型在现实生活中的临床决策支持。", "conclusion": "该框架澄清了假设，标准化了比较标准，并指导了临床相关性更强的L大型语言模型的发展。此外，研究还扩展了模型评估的维度，增加了对效率和可解释性的考量，并突出了未来的研究挑战。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20002", "html_url": "https://arxiv.org/abs/2510.20002", "title": "锻造GEMs：通过基于质量的语料库编纂和专用预训练推进希腊语NLP", "title_en": "Forging GEMs: Advancing Greek NLP through Quality-Based Corpus Curation and Specialized Pre-training", "authors": "Alexandra Apostolopoulou,Konstantinos Kanaris,Athanasios Koursaris,Dimitris Tsakalidis,George Domalis,Ioannis E. Livieris", "background": "对于形态丰富且资源中等的现代希腊语等语言来说，自然语言处理的进步常常受到研究领域碎片化、架构多样性不足以及短语长模型限制的阻碍。在法律等专业且高价值领域，现有的模型通常局限于早期的受限于512词窗口的Transformer架构，这对于分析长篇法律文件是不够的。因此，该研究旨在通过广泛的高质量语料库编纂和针对特定领域的预训练来解决这些问题，从而为现代Greek NLP技术的发展开辟道路。", "innovation": "本论文创新地构建了新的基于广泛高质量数据编纂的Transformer模型，其中包括ELCTRA、ConvBERT和ModernBERT等多种现代架构，并首次针对希腊语和法律领域开发了双语嵌入模型。实验结果表明，这些新的模型显著优于现有基线，展示了基于高质量语料库编纂和专业预训练的新方法的有效性。", "conclusion": "研究证明，基于高质量语料库编纂和特定领域预训练的新一代模型是有效的，GEM-RoBERTa和GEM-ConvBERT模型明显优于现有基线。这表明，对于形态丰富且资源有限的语言，采取这种创新的方法将极大提升其在专业领域的应用效果。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20039", "html_url": "https://arxiv.org/abs/2510.20039", "title": "双向影响：多轮人类-大语言模型互动中的意见动态", "title_en": "Beyond One-Way Influence: Bidirectional Opinion Dynamics in Multi-Turn Human-LLM Interactions", "authors": "Yuyang Jiang,Longjie Guo,Yuchen Wu,Aylin Caliskan,Tanu Mitra,Hua Shen", "background": "大型语言模型（LLM）驱动的聊天机器人越来越多地用于意见探索。以往的研究关注LLM如何改变用户观点，但鲜有研究探讨用户输入如何影响LLM回应以及这种双向影响在多次对话中的表现形式。本文通过在三个条件下开展50场关于争议性主题的讨论，来研究这种动态变化，分别为静态陈述、标准聊天机器人和个性化聊天机器人。结果显示，人类观点几乎不变，而LLM输出变化显著，缩小了人类与LLM立场之间的差距。个性化设置使这种变化在两个方向上更加明显。进一步分析多轮对话发现，包含参与者个人故事的交流最有可能导致人类和LLM立场变化。", "innovation": "本研究创新之处在于首次深入探讨了人类与大语言模型之间双向互动过程中的意见动态变化，尤其是在多轮对话中，发现了用户个人故事在触发双方立场变化中的关键作用。", "conclusion": "研究结果指出人类-LLM互动存在过度对齐的风险，强调在设计个性化聊天机器人时，需要更加谨慎地考虑如何更体贴和稳定地与用户对齐。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20040", "html_url": "https://arxiv.org/abs/2510.20040", "title": "通过模仿学习逼近模型预测控制的微电网能源管理", "title_en": "Approximate Model Predictive Control for Microgrid Energy Management via Imitation Learning", "authors": "Changrui Liu,Shengling Shi,Anil Alan,Ganesh Kumar Venayagamoorthy,Bart De Schutter", "background": "随着可再生能源的不断增加，微电网的可靠和可持续运行需要高效的能源管理。模型预测控制（MPC）是一种有效的能源管理方法，但当与混合整数优化结合使用时存在计算复杂度高的问题。", "innovation": "本文提出了一种基于模仿学习的框架来逼近混合整数经济模型预测控制（EMPC）方法。该方法通过训练神经网络模仿专家的离线轨迹，实现快速、实时的决策，而无需在线求解优化问题。此外，通过在训练过程中注入噪声以缓解分布偏移，并明确纳入可再生能源发电和负荷预测的不确定性以增强鲁棒性和通用性。", "conclusion": "仿真结果表明，通过模仿学习得到的策略在经济性能上可与基于优化的EMPC相媲美，而在实际操作中仅需优化EMPC计算时间的10%。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20020", "html_url": "https://arxiv.org/abs/2510.20020", "title": "优化线性社会选择中的失真", "title_en": "Optimized Distortion in Linear Social Choice", "authors": "Luise Ge,Gregory Kehne,Yevgeniy Vorobeychik", "background": "社会选择理论为根据选民对选项的偏好排名来选择候选人提供了丰富的方法。然而，如果选民对这些选项有潜在的效用，那么使用偏好排名可能会导致相对于福利的社会最优性的次优结果。失真（Distortion）是这种次优性的度量，提供了一种开发和分析投票规则的最坏情况方法，尤其是在效用结构最少的情况下。然而，在许多情景下，如价值对齐的常见范式中，替代选项可以有矢量表示，并假设效用是这些矢量的参数函数。这篇论文是首次研究线性效用函数的失真。", "innovation": "研究了线性社会选择中的失真，并具体探讨了确定性和随机投票规则的线性社会选择的失真。给出了仅依赖于候选嵌入维度而不依赖于候选人数或选民数量的失真边界。并且引入了多项式时间实例最优算法来在给定候选和投票集的情况下最小化失真。并在这两个实际领域中进行了实证评估：采用协同过滤嵌入的推荐系统和使用语言模型嵌入的意见调查，并针对我们的实例最优算法进行了基准测试。", "conclusion": "这些实例最优算法在推荐系统和意见调查中的测试表明，与若干标准规则相比，它们能够有效地最小化失真。这为社会选择规则的设计提供了一种基于线性效用的新颖方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20028", "html_url": "https://arxiv.org/abs/2510.20028", "title": "比特币交易的时间图", "title_en": "The Temporal Graph of Bitcoin Transactions", "authors": "Vahid Jalili", "background": "自2009年诞生以来，比特币网络处理了超过10.8亿笔交易，金额超过872亿枚比特币，这些数据为机器学习提供了丰富的研究潜力；然而，由于其基于UTXO的设计带来的匿名性和资金流动的不透明性，这笔数据对机器学习研究来说难以获取。该研究旨在填补这一空白，通过重新构造资金流动，提供一个兼容机器学习的时间异质图模型，该模型涵盖了从首个区块（区块高度\textbackslashcutoffHeight）到现在所有交易的历史记录，包括超过2400万个节点和超过397.2亿条边。此图对机器学习社区而言是一个全面的数据集，能够帮助其深入研究比特币复杂生态系统中的各种问题，如异常检测、地址分类、市场分析以及大规模图机器学习基准测试等，进而推动相关应用的发展。", "innovation": "本文提出了一种兼容机器学习的时间异质图模型，通过重构比特币的财务流动，克服了匿名性和资金流动不透明性带来的数据访问障碍。该模型包含完整的交易历史记录，节点数超过2400万个，边数超过397.2亿条，同时提供了定制的采样方法，生成了节点和边特征向量，并提供加载和分析比特币图数据的工具，以及可供直接使用的数据库快照，为机器学习社区提供了一个全面的数据集和工具包，以满足大规模的分析需求，促进了诸如异常检测、地址分类、市场分析等应用的进步。", "conclusion": "该研究提供的全面的数据集和工具包能够使机器学习社区更好地分析比特币复杂生态系统，在应用方面如异常检测、地址分类、市场分析以及大规模图机器学习基准测试等领域推动研究进展。这些数据和工具皆可在提供的链接获取。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20084", "html_url": "https://arxiv.org/abs/2510.20084", "title": "ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models", "title_en": "ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models", "authors": "Bosong Huang,Ming Jin,Yuxuan Liang,Johan Barthelemy,Debo Cheng,Qingsong Wen,Chenghao Liu,Shirui Pan", "background": "在高风险应用（如医疗和金融）中的时间序列分类模型中，解释模型至关重要。尽管已有方法识别出关键的时间序列子序列（称为形状元素），作为实现顶级性能和验证它们在分类结果中核心作用的关键特征，现有的后置时间序列解释方法主要集中在时间步特征归因上，而忽视了分类结果主要由关键形状元素驱动这一基本前提。", "innovation": "提出了一种名为ShapeX的新颖框架，该框架将时间序列分割为由形状元素驱动的有意义段，并使用Shapley值评估这些段的显著性。ShapeX的核心是Shapelet Describe-and-Detect (SDD)框架，能够学习用于分类的关键形状元素集合。实验结果表明，ShapeX能够比现有方法更有效地识别最相关的子序列，提高时间序列解释的精确度和因果准确性。", "conclusion": "实验结果表明，ShapeX在识别最相关的时间序列子序列方面优于现有方法，增强了时间序列解释的精确性和因果准确性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20061", "html_url": "https://arxiv.org/abs/2510.20061", "title": "为国家行动呼吁：迈向公共对抗性测试模型", "title_en": "Ask What Your Country Can Do For You: Towards a Public Red Teaming Model", "authors": "Wm. Matthew Kennedy,Cigdem Patlak,Jayraj Dave,Blake Chambers,Aayush Dhanotiya,Darshini Ramiah,Reva Schwartz,Jack Hagen,Akash Kundu,Mouni Pendharkar,Liam Baisley,Theodora Skeadas,Rumman Chowdhury", "background": "AI系统有可能产生利益，同时也可能导致危害。但如果没有严格的、持续的对抗性评估，AI开发者将难以全面评估AI风险的范围和规模。目前社会和技术领域的研究人员已开发了一些有效的方法来评估AI中的偏见、仇恨言论、假信息等已知危害。然而，随着技术日益复杂，这些方法可能无法适应高风险领域（如教育、医疗保健和情报收集）的需求。因此，迫切需要开发新的方法来弥合‘责任差距’，确保AI的安全和负责任的应用。", "innovation": "本文提出了一种创新的方法——合作公共AI对抗性测试演习，并讨论了其早期试行结果。该方法通过实际操作设计和分析，展示了在不同场合下进行公共示范演习的效果，包括与CAMLIS 2024共同举行的首次公共示范，以及由美国国家标准与技术研究院（NIST）的评估AI风险和影响（ARIA）试点演习和新加坡信息通信媒体发展局（IMDA）共同举办的类似演习。", "conclusion": "该方法不仅可以提供有意义的结果，还具有向多个AI开发区域扩展的潜力。这表明合作公共AI对抗性测试演习是弥合责任差距的有效途径，有助于确保AI的安全并彻底理解其潜在危害。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20091", "html_url": "https://arxiv.org/abs/2510.20091", "title": "CreativityPrism：大型语言模型创造力的全面基准", "title_en": "CreativityPrism: A Holistic Benchmark for Large Language Model Creativity", "authors": "Zhaoyi Joey Hou,Bowei Alvin Zhang,Yining Lu,Bhiman Kumar Baghel,Anneliese Brei,Ximing Lu,Meng Jiang,Faeze Brahman,Snigdha Chaturvedi,Haw-Shiuan Chang,Daniel Khashabi,Xiang Lorraine Li", "background": "创造力常被视为人类智能的标志。尽管大语言模型（LLMs）被越来越多地认为能够生成具有创造性内容，但仍然缺乏一个全面框架来评估它们在不同场景中的创造力。现有的评估方法仍然碎片化，不同领域和任务间的测量标准差异较大，这主要归因于创造力的不同定义和测量方式。", "innovation": "提出了一种名为CreativityPrism的评估分析框架，将创造力分解为三个维度：质量、新颖性和多样性。CreativityPrism包含九个任务，三个领域，即发散思维、创造性写作和逻辑推理，并提出了二十种评估指标，以特定且独特的方式衡量每个维度。通过评估17个最先进的（SoTA）的闭源和开源大语言模型，分析了不同指标和任务领域之间的性能相关性。", "conclusion": "结果显示，闭源模型和开源模型之间存在显著性能差距。整体来看，模型在相同领域的任务表现高度相关，而在不同领域之间则表现较差。在评估维度中，多样性和质量指标显示出较强的相关性，表现良好的模型在另一个维度上也往往表现出色，而新颖性则较少显示出与其它维度之间的相关性。这些发现支持了我们的假设，即在一项创造力任务或维度中的优秀表现不一定能推广到其他领域，强调了全面评估大语言模型创造力的必要性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20093", "html_url": "https://arxiv.org/abs/2510.20093", "title": "StableSketcher: 通过视觉问答反馈增强基于像素的手绘素描生成的扩散模型", "title_en": "StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback", "authors": "Jiho Park,Sieun Choi,Jaeyoon Seo,Jihie Kim", "background": "尽管扩散模型在生成图像方面的质量有了显著提升，但在合成基于像素的人绘制素描方面仍面临挑战，这代表了抽象表达的一个典型例子。尽管如此，为了应对这一挑战，我们提出了一种名为StableSketcher的新颖框架，该框架使扩散模型能够生成忠实于提示的手绘素描。同时，通过优化潜空间解码，变分自编码器能够更好地捕捉素描的特征。并引入了一种新的基于视觉问答的奖励函数，以此改善文本与图像的对齐和语义一致性。", "innovation": "我们提出了一种新型框架StableSketcher，结合细调变分自编码器优化潜空间解码和引入新的基于视觉问答的奖励函数，以提升扩散模型生成手绘素描的能力，特别是风格一致性和文本图像对齐度。此外，我们还引入了名为SketchDUO的新数据集，包含了实例级别的素描与配对的说明和问答对，解决了现有依赖图像标签对的数据集的局限性，有助于提升模型的效果与表现力。", "conclusion": "广泛的实验表明，StableSketcher生成的素描在风格一致性方面有所改进，并且与提示的对齐度相比优于Stable Diffusion基线模型。我们还推出了一个名为SketchDUO的首个数据集，通过提供实例级别的素描配对讲和问答对，解决了现有数据集的限制。论文中的代码和数据集将在接收后公开。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20098", "html_url": "https://arxiv.org/abs/2510.20098", "title": "通过自适应路由和针对性推理利用大型语言模型在实体链接中的力量", "title_en": "Leveraging the Power of Large Language Models in Entity Linking via Adaptive Routing and Targeted Reasoning", "authors": "Yajie Li,Albert Galimov,Mitra Datta Ganapaneni,Pujitha Thejaswi,De Meng,Priyanshu Kumar,Saloni Potdar", "background": "传统实体链接(EL)方法依赖大量标注数据和深度模型微调。最近的少样本方法通过提示利用大型语言模型（LLMs）减少了训练需求，但往往因昂贵的LLM推理而效率低下。", "innovation": "ARTER（自适应路由和针对性实体推理）提供了一个结构化管道，通过策略性地结合候选生成、基于上下文的评分、自适应路由和选择性推理，实现高性能的实体链接，无需深度微调。ARTER通过计算检索候选集上的互补信号（包括嵌入和基于LLM的信号），将上下文提及分为简单和复杂情况，并分别由低计算开销的实体链接器和更昂贵的针对性LLM推理处理。", "conclusion": "在标准基准测试中，ARTER在ReFinED上表现出色，最高提高4.47%，平均提高2.53%，在5个数据集中表现出色，总体上与使用LLM推理的所有提及的管道表现相当，但其LLM令牌效率提高了两倍。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20129", "html_url": "https://arxiv.org/abs/2510.20129", "title": "SAID: 通过自我激活的内部防御为大型语言模型赋能", "title_en": "SAID: Empowering Large Language Models with Self-Activating Internal Defense", "authors": "Yulong Chen,Yadong Liu,Jiawen Zhang,Mu Li,Chao Huang,Jie Wen", "background": "尽管在安全性对齐方面取得了进展，大型语言模型（LLMs）仍然容易受到旨在规避保护机制的破解攻击。现有的防御策略依赖于外部干预，如输入过滤或输出修改，这些方法往往缺乏通用性，会削弱模型的实用性，并且会带来显著的计算开销。", "innovation": "本研究引入了一种无需训练的新防御范式——自我激活的内部防御（SAID），它将防御任务重新定义为内部能力的激活，而不是外部修改。SAID 利用 LLM 的自我推理能力，通过三个阶段的管道主动识别并中和恶意意图：模型原生意图提炼，以提取核心语义；最优安全前缀探测，以激活潜藏的安全意识；保守聚合策略，以确保稳健的决策。广泛的实验表明，SAID 在减少有害输出方面显著优于现有最先进的防御方法，同时还能保留模型在良性任务上的性能，并且计算开销最小。", "conclusion": "我们的工作证明，激活大型语言模型中固有的安全机制是构建更安全和更可靠的对齐 AI 系统的更稳健和可扩展的途径。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20094", "html_url": "https://arxiv.org/abs/2510.20094", "title": "关于McKean-Vlasov方程稳态解结构的研究及其在噪声变换器中的应用", "title_en": "On the Structure of Stationary Solutions to McKean-Vlasov Equations with Applications to Noisy Transformers", "authors": "Krishnakumar Balasubramanian,Sayan Banerjee,Philippe Rigollet", "background": "本文研究了圆周上的McKean-Vlasov方程的稳态解。研究指出，通过将稳态McKean-Vlasov方程的解与傅里叶系数的无限维二次系统联系起来，可以清晰地描述局部分岔的周期性和共振结构，同时能够处理奇异势。这种方法还允许对稳态解进行详细的分析，直到任意数量的傅里叶模式。此外，通过分析自由能量景观，证明了全局稳态措施的存在性、紧致性及共存性，并将不连续的相变与自由能最小值映射的非可微点关联起来。这些研究为理解和应用噪声变换器模型奠定了基础，并揭示了温度参数对系统复杂分岔行为的影响。", "innovation": "本文通过建立傅里叶系数的无限维二次系统来研究稳态McKean-Vlasov方程的结构，提供了一种清晰的描述局部分岔并且能够处理奇异势的方法。在此基础上，可以准确地解析分岔的出现、形式以及形状（超临界、临界、亚临界或跨临界），同时对由多个傅里叶模式参与的尖锐相变情况进行详细分析。还研究了噪声变换器模型在不同温度参数下的分岔行为，揭示了不连续相变与自由能最小值映射的非可微点之间的联系。", "conclusion": "本文确认了全球自由能量景观的正则性和凹性，证明了存在能满足任意数量傅里叶模式的全局最小化逐年稳态措施，并观察到了随着温度参数增加从连续到不连续（一级相变）的行为转变。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20154", "html_url": "https://arxiv.org/abs/2510.20154", "title": "大语言模型的零样本立场检测是否受到刻板印象的影响？", "title_en": "Are Stereotypes Leading LLMs' Zero-Shot Stance Detection ?", "authors": "Anthony Dubreuil,Antoine Gourru,Christine Largeron,Amine Trabelsi", "background": "大语言模型在预训练数据中继承了刻板印象，导致在许多自然语言处理任务中表现出对特定社会群体的偏见，例如仇恨言论检测或情感分析。令人惊讶的是，这种偏见在立场检测方法的评估中被学术界忽视了。立场检测涉及将声明标记为对特定目标的支持、反对或中立，这通常是敏感性最高的NLP任务之一，因为它经常与政治倾向有关。", "innovation": "本文关注大语言模型在零样本条件下进行立场检测时的偏见。作者自动为预存的立场检测数据集中的帖子注释了两个属性：特定群体的方言或口语文体复杂度/可读性，以探究这些属性是否影响模型的立场检测决策。研究结果表明，语言模型在立场检测任务中表现出显著的刻板印象。", "conclusion": "大语言模型在零样本立场检测中确实存在明显的刻板印象，例如错误地将支持大麻的观点与语文体简单性联系起来，将非洲裔美国人口语文体与反对唐纳德·特朗普的态度联系起来。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20165", "html_url": "https://arxiv.org/abs/2510.20165", "title": "IB-GAN: 使用信息瓶颈生成对抗网络的分离表示学习", "title_en": "IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks", "authors": "Insu Jeon,Wonkwang Lee,Myeongjang Pyeon,Gunhee Kim", "background": "本文提出了一种基于生成对抗网络（GAN）的无监督模型，用于分离表示学习。该模型试图通过信息瓶颈（IB）框架优化GAN，以此来改善GAN在分离表示学习中的表现。", "innovation": "本文提出了一个新的模型IB-GAN，该模型在生成器中引入了一个中间层来约束输入与生成输出之间的互信息，使得生成器能够以分离和可解释的方式利用潜在空间。此外，该模型在dSprites和Color-dSprites数据集上达到了与最先进的/devices-VAEs相当的分离度得分，并且在CelebA和3D Chairs数据集的FID分数上优于InfoGAN。", "conclusion": "IB-GAN能够在潜在空间中实现分离表示学习，实验结果表明其在dSprites和Color-dSprites数据集上具有竞争力的分离度，并且在生成样本的视觉质量和多样性方面优于/devices-VAEs和InfoGAN。\n"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20176", "html_url": "https://arxiv.org/abs/2510.20176", "title": "Mixture-of-Minds: 多代理强化学习以表格理解", "title_en": "Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding", "authors": "Yuhang Zhou,Mingrui Zhang,Ke Li,Mingyi Wang,Qiao Liu,Qifei wang,Jiayi Liu,Fei Liu,Serena Li,Weiwi Li,Mingze Gao,Abhishek Kumar,Xiangjun Fan,Zhuokai Zhao,Lizhu Zhang", "background": "表格理解和推理对于许多实际应用至关重要。当前的大型语言模型（LLMs）在这项任务上展现了潜力，但现有的方法仍存在局限性。基于微调的方法可以增强语言推理，但容易出现算术错误和虚构问题。相比之下，基于工具的方法能够精确操作表格，但依赖于僵化的模式，缺乏语义理解。这些互补的不足之处突显了需要结合稳健推理和可靠表格处理的方法。", "innovation": "本文提出了一种多代理框架——Mixture-of-Minds，将表格推理分解为计划、编码和回答三个专门的角色，使每个代理专注于任务的特定方面，并通过代码执行实现精确的表格操作。提出的自改进训练框架利用蒙特卡洛树搜索（MCTS）演进来生成伪黄金轨迹，并通过强化学习（RL）优化代理。实验结果表明，Mixture-of-Minds 实现了大幅改进，达到62.13%的性能，并超越了OpenAI-o4-mini-high。", "conclusion": "这些结果表明，结合结构化的多代理工作流与强化学习来推进表格理解具有前景。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20178", "html_url": "https://arxiv.org/abs/2510.20178", "title": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching", "title_en": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching", "authors": "Yun Wang,Junjie Hu,Qiaole Dong,Yongjian Zhang,Yanwei Fu,Tin Lun Lam,Dapeng Wu", "background": "从立体视频中进行时空一致的深度估计对于实际应用，如增强现实至关重要。尽管其重要性，该任务由于在计算效率和长期时空一致性建模之间难以取舍而一直具有挑战性。现有的方法试图通过聚合时空信息来解决这个问题，但仍然存在局限性：有限的时空建模只能提供适度的提升，而捕捉长期依赖关系则会显著增加计算成本。", "innovation": "提出了一个记忆缓冲区来建模长期时空一致性，同时实现了高效的动态立体匹配。这是通过模仿人类的两阶段决策机制实现的，即设计了一个名为PPM（Pick-and-Play Memory）模块以进行动态立体匹配，该模块包括一个‘选择’过程，用于确定最相关的帧，以及一个‘玩’过程，用于适应性地加权所选帧进行时空聚合。", "conclusion": "广泛的实验验证了PPMStereo的有效性，显示出在准确性和时空一致性方面的最先进的性能。相对于BiDAStereo，PPMStereo在Sintel clean/final数据集上分别获得了17.3% 和 9.02% 的提升，计算成本更低。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20171", "html_url": "https://arxiv.org/abs/2510.20171", "title": "为100k+ GPU提供集体通信", "title_en": "Collective Communication for 100k+ GPUs", "authors": "Min Si,Pavan Balaji,Yongzhou Chen,Ching-Hsiang Chu,Adi Gangidi,Saif Hasan,Subodh Iyengar,Dan Johnson,Bingzhe Liu,Jingliang Ren,Ashmitha Jeevaraj Shetty,Greg Steinbrecher,Xinfeng Xie,Yulun Wang,Bruce Wu,Jingyi Yang,Mingran Yang,Minlan Yu,Cen Zhao,Wes Bland,Denis Boyda,Suman Gumudavelli,Cristian Lumezanu,Rui Miao,Zhe Qu,Venkat Ramesh,Maxim Samoylov,Jan Seidel,Feng Tian,Qiye Tan,Shuqiang Zhang,Yimeng Zhao,Shengbao Zheng,Art Zhu,Hongyi Zeng", "background": "大型语言模型（LLMs）的规模日益增大，特别是在使用成千上万个GPU进行训练时，传统的通信方法面临吞吐量和延迟的局限性，阻碍了先进模型的开发和部署。在大规模训练的同步需求与推理时的低延迟需求之间，必须有一种高效的集体通信框架来优化整个LLM生命周期中的性能。特别是为了支持超过10万个GPU的集群中的复杂任务。", "innovation": "提出了由Meta公司开发的NCCLX集体通信框架，该框架旨在优化从大规模训练到推理的所有阶段的性能，确保在超过10万个GPU的集群上实现可靠、高吞吐量和低延迟的数据交换。实验证明，该框架能够显著提高沟通效率。", "conclusion": "研究成果提供了一种强大的解决方案，使下一代大语言模型能够在前所未有的规模下运行。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20209", "html_url": "https://arxiv.org/abs/2510.20209", "title": "使用常规实验室数据评估早期癌症检测的可行性：不平衡数据集上机器学习方法的评估", "title_en": "Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset", "authors": "Shumin Li", "background": "在兽医领域开发易于获取的早期癌症筛查工具是一项重大挑战。尽管常规实验室数据是一个有希望且低成本的数据来源，但个体生物标志物的非特异性以及筛查群体中的严重类别不平衡限制了其应用。", "innovation": "研究基于金毛 retriever 终身研究 (GRLS) 群体，利用机器学习方法进行癌症风险分类的评估，同时考虑了实际限制，包括癌症类型的多样化分组和包含诊断后样本。研究系统性比较了126种不同的分析管道，包括各种机器学习模型、特征选择方法和数据平衡技术。", "conclusion": "虽然在常规实验室数据中存在可统计检测的癌症信号，但该信号过于弱且受到混淆，不足以从正常老化或其它炎症状态中进行可靠的区分。因此，仅依靠此数据模态无法实现可靠的临床诊断，这将需要多种数据源的整合才能在计算兽医肿瘤学方面取得实质性进展。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20218", "html_url": "https://arxiv.org/abs/2510.20218", "title": "高阶交互建模的可解释多智能体Q学习", "title_en": "High-order Interactions Modeling for Interpretable Multi-Agent Q-Learning", "authors": "Qinyu Xu,Yuanyang Zhu,Xuefei Wu,Chunlin Chen", "background": "多智能体强化学习（MARL）中的智能体之间交互建模能力对于有效协调和理解其合作机制至关重要。然而，之前的高阶交互建模努力主要受到组合爆炸或其黑盒网络结构不透明性的阻碍。", "innovation": "本文提出了一个新的价值分解框架——连续分数Q学习（QCoFr），该框架能够以线性复杂度$\text{O}(n)$捕获任意阶智能体交互，从而避免了建模丰富合作时的组合爆炸。此外，引入了变分信息瓶颈来提取潜在信息以估计奖励，这些潜在信息帮助智能体过滤掉噪声交互，从而显著提升了合作和可解释性。", "conclusion": "广泛的实验表明，QCoFr不仅能够持续获得更好的性能，还能提供与理论分析一致的可解释性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20221", "html_url": "https://arxiv.org/abs/2510.20221", "title": "FinCARE: 财务因果分析与推理和证据结合", "title_en": "FinCARE: Financial Causal Analysis with Reasoning and Evidence", "authors": "Alejandro Michel,Abhinav Arun,Bhaskarjit Sarmah,Stefano Pasquali", "background": "基金经理依赖基于相关性的分析和启发式方法，这些方法未能捕捉驱动绩效的真正因果关系。本文提出了一种混合框架，将统计因果发现算法与来自两方面来源的领域知识（分别为SEC 10-K报告中提取的金融知识图谱和大规模语言模型推理）相整合。", "innovation": "本文的方法系统地增强了三种代表性的因果发现范式（约束式、评分和连续优化），通过算法编码知识图谱约束，并利用LLM概念推理来生成假设。在包含500个公司的合成财务数据集的18个变量上进行评估，证明了以其增强的方法在三种算法（PC、GES和NOTEARS）中的一致改进。", "conclusion": "框架能够进行可靠的情景分析，对于反事实预测的平均绝对误差为0.003610，并且对干预影响具有完美的方向准确性。它还弥补了现有方法的关键局限性，将统计发现与财务领域专业知识相结合，同时保持经验验证，为投资经理提供必要的因果基础，以便在动态市场环境中实施前瞻性的风险管理并做出战略决策。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20211", "html_url": "https://arxiv.org/abs/2510.20211", "title": "基于AI代理的自动云基础设施-as-代码校正", "title_en": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "authors": "Zhenning Yang,Hui Guan,Victor Nicolet,Brandon Paulsen,Joey Dodds,Daniel Kroening,Ang Chen", "background": "云基础设施的管理通常通过多种接口进行，传统的管理方式包括云控制台、命令行界面(CLI)和软件开发工具包(SDK)。最近，基础设施-as-代码(IaC)框架（例如Terraform）变得非常流行。这些框架将基础设施编码为“单一真相”的配置，并能够自动执行修改操作，如部署、更新或销毁资源，以确保云计算基础设施与IaC配置保持一致。然而，当IaC与控制台、命令行或SDK一起使用时，IaC将失去对外部变化的可见性，导致基础设施漂移，即配置变得过时，后续的IaC操作可能撤销有效的更新或引发错误。", "innovation": "NSync是一个自动化的IaC校正系统，它将外部变化传播回IaC项目。NSync的关键洞察是基础设施的变更最终都通过云API调用进行。通过分析API调用踪迹，NSync可以检测到漂移（即不是由IaC引起的变更）并进行校正（即更新IaC配置以捕捉这些变化）。它采用代理架构，利用LLMs从嘈杂的API序列中推断出高层次的意图，利用专业工具合成有针对性的IaC更新，并通过自我进化的知识库不断改进。", "conclusion": "实验结果显示，NSync在准确性和令牌效率方面均优于基线，准确率从0.71提高到0.97，性能提高1.47倍，并且其创新的方法提供了一种新的评估框架，用于注入现实中的漂移和评估校正性能。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20198", "html_url": "https://arxiv.org/abs/2510.20198", "title": "陷入矩阵：大型语言模型的空间推理探查", "title_en": "Stuck in the Matrix: Probing Spatial Reasoning in Large Language Models", "authors": "Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum", "background": "本文通过五个旨在探查大型语言模型（LLMs）的空间理解能力和计算能力的任务，探讨了LLMs在文本输入上的空间推理能力。这些模型被测试了基本的空间推理能力和结构网格环境内的多步问题解决能力，通过如象限识别、几何变换、距离评估、查找和瓷砖滑动等任务来进行。随着任务复杂性的增加，模型从简单的模式识别扩展到抽象的空间推理。结果表明，尽管LLMs在低复杂性和大小时表现出中等成功，但随着规模增加，性能迅速下降，准确度平均损失42.7%，最高损失达到84%。所有初始准确率超过50%的测试显示至少下降48%，表明这种下降的一致性。此外，它们在复杂性方面的扩展困难表明其潜在空间表示的稳定性不足。本文突显了LLMs在语言和空间推理之间的差距，为未来语言和几何学结合的综合基准奠定了基础，揭示了其当前的局限性。", "innovation": "本文采用了一套包含五个任务的测试套件，旨在深入探索大型语言模型的空间推理和计算能力。实验设计涉及多种不同类型的任务，从简单的模式识别到复杂的多步问题解决，通过逐渐增加网格的复杂性来评估模型的能力变化。", "conclusion": "大型语言模型在空间推理方面表现出明显的局限性，尤其是在处理复杂任务时。这些模型的性能随着任务复杂性的增加急剧下降，显示了它们在空间表示方面存在不足。本文不仅指出了当前大型语言模型在空间推理方面的局限性，还为进一步研究综合了语言和几何学的基准评估提供了新的方向。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20222", "html_url": "https://arxiv.org/abs/2510.20222", "title": "QKCV Attention: 基于静态类别嵌入提升时间序列预测的注意力机制，适用于轻量级和预训练基础模型", "title_en": "QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models", "authors": "Hao Wang,Baojun Ma", "background": "在实际时间序列预测任务中，类别信息在捕捉数据内在模式中起着关键作用。现有的基于注意力机制的时间序列预测模型（如Vanilla Transformer、Informer、PatchTST和TFT）虽有较好表现，但缺乏对类别特异性信息的有效处理能力，限制了它们的预测精度提升空间。因此，如何引入机制来增强这些模型对类别信息的处理能力，提升预测准确性，是当前研究的重要课题之一。", "innovation": "论文提出了一种新的注意力机制QKCV（Query-Key-Category-Value Attention），它扩展了传统的QKV框架，并引入了一个静态类别嵌入C，以加强类别特异性信息的强调。QKCV作为一种多功能插件模块，可以提升多种基于注意力的模型在不同实际时间序列数据集上的预测准确性。QKCV在微调单一时间序列的基础模型时，通过仅更新静态嵌入C，减少了计算开销，并实现了卓越的微调性能。这一创新方法不仅增强了模型对类别信息的有效捕捉，还大幅度减轻了训练负担。", "conclusion": "QKCV注意力机制在保持预训练模型权重的前提下，通过更新静态嵌入C来实现对单一时间序列基础模型的有效微调，提升了时间序列预测的准确性，适用于多样化的实际数据集，并能显著减少计算开支，展示出显著的适应性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20225", "html_url": "https://arxiv.org/abs/2510.20225", "title": "通过元变分丢弃进行联邦学习", "title_en": "Federated Learning via Meta-Variational Dropout", "authors": "Insu Jeon,Minui Hong,Junhyeog Yun,Gunhee Kim", "background": "联邦学习旨在通过远程分布的客户端训练全局推理模型，因其在提高数据隐私方面的优势受到重视。然而，传统的联邦学习在实际应用中面临挑战，包括模型过拟合和由于客户端间有限且非i.i.d.数据而导致的本地模型发散。", "innovation": "该文引入了一种新颖的贝叶斯元学习方法，即元变分丢弃(MetaVD)，通过共享超网络学习预测客户端相关的丢弃率，使联邦学习算法在有限的非i.i.d.数据环境中能够有效个性化。文中的贡献还包括对元学习的后验适应视角以及贝叶斯联邦学习的后验聚合视角的理解，并通过条件丢弃后验进行了阐述。实验证明MetaVD在不同类型和情况下的稀疏非i.i.d.联邦学习数据集上表现出色，尤其是在针对分布外(OOD)客户端的情况下，并且还展示了模型压缩和减少通信成本的效果。", "conclusion": "MetaVD在分类准确性和不确定性校准性能方面表现出色，特别是在分布外的客户端中。该方法通过减少每个客户端所需的本地模型参数数量，缓解了模型过拟合并降低了通信成本。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20242", "html_url": "https://arxiv.org/abs/2510.20242", "title": "构建高效选择性分类器需要什么？", "title_en": "What Does It Take to Build a Performant Selective Classifier?", "authors": "Stephan Rabanser,Nicolas Papernot", "background": "选择性分类器通过在模型认为不确定的情况下放弃输入来提高模型可靠性。然而，很少有实际方法能够达到完美排序的预言机标准，即按正确性接受示例。本文将这种不足正式化为选择性分类差距，并首次对这一差距进行了有限样本分解，分为五个不同的宽松来源：贝叶斯噪声、逼近误差、排序误差、统计噪声以及实施或转换引起的松弛。", "innovation": "本文分析揭示了单调后处理校准——通常被认为是加强选择性分类器的方法——对闭合这一差距影响有限，因为这种校准很少改变模型的基本评分排名。因此，闭合差距需要能够重新排列预测的评分机制，而不是仅仅重新缩放值。通过对合成的双环数据和现实世界视觉和语言基准进行验证，本文区分了每种错误组件，结果证实了贝叶斯噪声和有限的模型能力能够解释很大一部分差距，只有更丰富、特征感知的校准器对评分排序有实质性改善，并且数据转换引入了另一项松弛，要求分布性鲁棒性训练。", "conclusion": "本文的分解提供了定量的误差预算以及可供实践者使用的行动指导方针，以便构建更接近理想预言机行为的选择性分类器。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20239", "html_url": "https://arxiv.org/abs/2510.20239", "title": "跨抑郁症和创伤后应激障碍的多模态严重程度融合诊断", "title_en": "Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders", "authors": "Filippo Cenacchi,Deborah Richards,Longbing Cao", "background": "抑郁症和创伤后应激障碍经常并发，症状相互关联，这为自动评估带来了复杂性，通常自动评估是二元且特定于某种障碍的。临床有效的诊断需要跨障碍的严重程度估计和决策支持解释。", "innovation": "统一的三模态情感严重性框架通过同步并融合采访文本的句子级变换嵌入、音频的log Mel统计及差分、面部信号的动作单元、凝视、头部和姿态描述符，输出这两种疾病的分级严重性（抑郁症为5级，PTSD为3级）。通过标准化特征的校准晚期融合分类器，生成每种疾病的概率和特征级别的归属。这种方法在同时诊断抑郁症和PTSD的多障碍场景中进行了演示。分层交叉验证表明，融合后的模型优于单一模态和简化基线，具备更好的准确性和F1加权分数，尤其是在噪音或缺失模态下其鲁棒性更强。对于PTSD，融合减少了回归误差并提高了类别一致性，分类误差集中在相邻严重程度之间，极端类别可以可靠地识别。抽样证明了文本对抑郁症严重性的贡献最大，音频和面部线索对于PTSD至关重要，而归属与语言和行为标记相一致。该方法提供了可重复的评估和临床决策支持。", "conclusion": "该工作展示了抑郁症和PTSD的同时诊断，通过融合技术提高了诊断的准确性和鲁棒性，并通过归因分析为临床决策支持提供了依据。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20272", "html_url": "https://arxiv.org/abs/2510.20272", "title": "LLMs中PRM引导树搜索在数学推理中的局限性", "title_en": "Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs", "authors": "Tristan Cinquin,Geoff Pleiss,Agustinus Kristiadi", "background": "虽然基于Best-of-N（BoN）选择的链式思考提示在大型语言模型（LLMs）中的数学推理中很受欢迎，但其线性结构无法捕捉复杂问题解决中的分支和探索性特征。", "innovation": "本文提出了一种自适应算法以最大化不可解动作空间中的过程奖励模型（PRM）得分，并研究PRM引导的树搜索是否能通过探索多个部分解路径来提高数学推理能力。", "conclusion": "研究发现PRM引导的树搜索在成本更高的情况下并未在数学推理中提供显著改进，而蒙特卡洛树搜索和束搜索方法表现更优。此外，PRMs难以近似状态值，其可靠性随着推理深度的增加而下降，且在分布外泛化性能不佳。这种不佳表现源于树搜索对不稳定的PRM评分的更大依赖，表明在树搜索用于有效增强LLMs的数学推理之前，需要不同的奖励建模方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20255", "html_url": "https://arxiv.org/abs/2510.20255", "title": "朝着高等教育课程中的AI代理发展：现场早期经验", "title_en": "Towards AI Agents for Course Instruction in Higher Education: Early Experiences from the Field", "authors": "Yogesh Simmhan,Varad Kulkarni", "background": "本研究概述了设计、部署和评估在印度理工学院(IISc)的云计算研究生课程中作为主讲教师的基于AI的教育代理的早期发现。该研究描述了一个大型语言模型(LLM)驱动的教师代理的设计，并引入了一种教育框架，该框架将教师代理整合到课程工作中，通过主动与学生互动进行内容传递，同时由人类教师提供课程结构并主持问答环节。", "innovation": "文章提出了一个教师代理-学生互动的分析框架，使用可解释性的参与度指标来评估主题覆盖范围、主题深度和回合级扩展。研究还报道了学生如何与代理互动以探索概念、澄清疑问和保持以探究为导向的对话的早期经验。此外，还报告了初步分析，显示了改进参与度模式，从广泛的概念探索过渡到深入、集中的探究。", "conclusion": "研究表明结构化的会话AI代理集成可以促进反思性学习，提供在真实课堂环境中研究参与度的可重复方法论，并支持高质量、可扩展的高等教育。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20286", "html_url": "https://arxiv.org/abs/2510.20286", "title": "UI-Ins：使用多视角指令推理增强GUI定位", "title_en": "UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning", "authors": "Liangyu Chen,Hanzhang Zhou,Chenglin Cai,Jianan Zhang,Panrong Tong,Quyu Kong,Xu Zhang,Chen Liu,Yuqi Liu,Wenxuan Wang,Yue Wang,Qin Jin,Steven Hoi", "background": "GUI定位将自然语言指令映射到可操作的UI元素，是GUI代理的核心能力。以往的研究主要将指令视为用户意图的静态代理，忽视了指令多样性和质量对定位性能的影响。通过对现有的定位数据集进行仔细研究，发现其中23.3%的指令存在缺陷，表明在推理过程中利用指令多样性可以显著提升性能。", "innovation": "本文引入了“指令作为推理”的范式，将指令视为动态分析路径，提供不同的视角，使模型在推理过程中选择最有效的路径。提出了一种两阶段训练框架：监督微调（SFT）用于生成多样化的指令，以培养多视角推理能力；随后采用强化学习（RL）优化路径选择和组合。UI-Ins-7B和UI-Ins-32B在五个挑战性的定位基准测试上取得了最先进的结果，表现出新兴推理能力，在解析和合成新的指令路径方面表现出色。", "conclusion": "通过深入分析，发现如何将推理与定位性能结合，并在SFT+RL框架中缓解政策崩溃。所有代码和模型检查点将在指定的URL地址公开。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20287", "html_url": "https://arxiv.org/abs/2510.20287", "title": "在生成式AI时代的霹雳舞视频分类", "title_en": "Breakdance Video classification in the age of Generative AI", "authors": "Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson", "background": "近年来，大型视觉语言模型在体育应用中得到了广泛应用，但主要集中于足球、板球、篮球等少数热门体育项目，主要集中在生成任务，如视觉问答、高光生成等方面。这项工作分析了现代视频基础模型（包括编码器和解码器）在霹雳舞这个非常小众但极受欢迎的运动中的应用可能性。", "innovation": "该研究展示了视频编码器模型在预测任务中继续优于最先进的视频语言模型。提供了如何选择编码器模型的见解，详细分析了微调的解码器模型在霹雳舞视频分类中的工作原理。", "conclusion": "视频编码器模型在预测任务中持续优于最先进的视频语言模型。提出了选择编码器模型的方法，并对微调的解码器模型在霹雳舞视频分类中的工作原理进行了深入分析。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20229", "html_url": "https://arxiv.org/abs/2510.20229", "title": "为什么大视觉-语言模型在较长响应中更容易出现幻觉：上下文的作用", "title_en": "Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context", "authors": "Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang", "background": "近年来，大视觉-语言模型（LVLMs）在多个任务上取得了显著进展，但也面临幻觉问题。这些模型在较长、自由形式的响应中更容易出现幻觉，这通常被认为是由累积不确定性引起的。尽管如此，研究尚未明确地探讨幻觉问题是否仅仅由响应长度引起，或者是否存在更深层次的原因。", "innovation": "本文提出了一种新颖的'诱导-检测-抑制'框架。该框架通过故意设计的上下文主动诱导幻觉，利用诱导的实例进行高风险案例的早期检测，并在实际解码过程中抑制潜在的对象级幻觉。这种方法在所有基准测试中都实现了持续且显著的改进，证明了其有效性。强检测和幻觉抑制不仅验证了该框架，更重要的是重新验证了上下文在幻觉生成中的作用。", "conclusion": "本文通过深入分析幻觉产生的根源，提出的框架不仅有效减少了幻觉，更重要的是，重新验证了上下文在长响应中幻觉生成的作用。这项研究的目标是提供新的见解，并为深入探讨LVLMs在长响应中幻觉机制提供第一步。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20280", "html_url": "https://arxiv.org/abs/2510.20280", "title": "通过学习预测上下文嵌入实现上下文级语言建模", "title_en": "Context-level Language Modeling by Learning Predictive Context Embeddings", "authors": "Beiya Dai,Yuliang Liu,Daozheng Xue,Qipeng Guo,Kai Chen,Xinbing Wang", "background": "Next-token prediction (NTP)是现代大规模语言模型（LLMs）预训练的基础，推动了它们在文本生成、推理和指令遵循方面的空前能力。然而，字级别预测限制了模型捕捉高层语义结构和长期上下文关系的能力。为了克服这个限制，我们介绍了ContextLM框架，该框架通过引入固有的下文预测目标来增强标准预训练。ContextLM使模型能够学习多字上下文的预测表示，利用来自未来令牌段的错误信号。实验表明，ContextLM在参数规模增至1.5亿的情况下，在困惑度和下游任务性能上均表现出一致的改进。我们的分析表明，下文预测提供了一种可扩展且高效的语言建模路径，能够提高长距离连贯性和注意力分配效果，同时几乎没有计算开销。", "innovation": "本文提出了ContextLM框架，该框架通过引入固有的下文预测目标来增强标准预训练，使得模型能够学习多字上下文的预测表示，利用来自未来令牌段的错误信号，从而提升模型的长期上下文关系和语义结构理解能力。", "conclusion": "通过使用ContextLM，实验表明，在参数规模增至1.5亿的情况下，该方法在困惑度和下游任务性能上均表现出一致的改进。研究表明，下文预测为更强的语言建模提供了一种可扩展且高效的途径，能够提高长距离连贯性和注意力分配效果，同时几乎不增加计算开销。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20235", "html_url": "https://arxiv.org/abs/2510.20235", "title": "最大最小准则的多目标强化学习：一种博弈论方法", "title_en": "Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach", "authors": "Woohyeon Byeon,Giseung Park,Jongseong Chae,Amir Leshem,Youngchul Sung", "background": "本文提出了一个多目标强化学习（MORL）中的最大最小准则（max-min criterion）的证明收敛且实用的框架。从博弈论的角度重新定义了MORL问题，并从理论层面提供了全面的分析，包括迭代复杂性和样本复杂性边界。通过这种方法，简化了策略更新过程，同时确保全局最后一次迭代收敛，还引入了高效的基于镜像下降算法。为提高性能，还提出了自适应正则化的改进方法。实验结果表明，该算法在表格设置中的收敛性能，并指出深度强化学习中的实现也显著超越了之前的基线。", "innovation": "本文创新性地提出了一个基于博弈论视角的多目标强化学习框架，通过重新定义MORL问题为一个两者的零和连续博弈，并引入了基于镜像下降算法。改进方法为自适应正则化，进一步提升了性能，并提供了详细的理论分析，包括精确和近似策略评估下的迭代复杂性和样本复杂性分析。", "conclusion": "本文提出的方法在表格MORL环境中展现了良好的收敛行为，并且在深度强化学习领域中的实现也显著优于之前的基线方法。通过理论分析和实验验证了该方法的有效性和实用性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20291", "html_url": "https://arxiv.org/abs/2510.20291", "title": "参数高效混合专家框架在跨模态地理定位中的应用", "title_en": "A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization", "authors": "LinFeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li", "background": "任务要求从多平台（卫星/无人机/地面）的大规模图像库中，根据自然语言查询检索最相关的地理参考图像。主要挑战包括不同平台之间的异质性以及通用训练描述与特定平台测试查询之间的领域差距。", "innovation": "提出了一个参数高效混合专家（MoE）框架，包括平台化拆分、卫星增强和去除方向性词汇等数据预处理步骤，以及利用大规模语言模型（LLM）的标题润色流程，以使文本语义与每个平台的视觉特性对齐。接着，使用BGE-M3（文本）和EVA-CLIP（图像）训练三个平台专家，采用逐级两阶段、难例挖掘策略以增强辨别力，并在推理时融合专家评分。系统在官方排行榜上居于首位，展示了在不同视角下的跨模态地理定位能力的鲁棒性。", "conclusion": "该系统成功解决了RoboSense 2025 Track 4中的挑战，并在多平台图像检索任务中取得了最佳成绩，展示了高度的跨模态地理定位能力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20296", "html_url": "https://arxiv.org/abs/2510.20296", "title": "RAG-Stack: 从向量数据库视角联合优化RAG的质量和性能", "title_en": "RAG-Stack: Co-Optimizing RAG Quality and Performance From the Vector Database Perspective", "authors": "Wenqi Jiang", "background": "检索增强生成（RAG）已经成为矢量数据库最具前景的应用之一。通过将数据库检索出的文档集成到大型语言模型（LLM）的提示中，RAG 使得内容生成更加可靠和富有信息性。虽然在矢量数据库方面已经有大量的研究，但在端到端 RAG 管道的更广泛背景下，仍有许多开放的研究问题。一个实际而具有挑战性的问题是如何在同一系统中同时优化性能和生成质量，这比表面看起来更为复杂，因为它涉及到算法侧（模型和数据库）和系统侧（从软件到硬件）的众多参数。", "innovation": "本文提出了 RAG-Stack，一种三层结构的框架，用于联合优化 RAG 系统的质量和性能。RAG-Stack 包含：(1) RAG-IR，一种中间表示形式，作为抽象层以解耦质量和性能方面；(2) RAG-CM，一种成本模型，用于估计给定 RAG-IR 的系统性能；(3) RAG-PE，一种计划探索算法，用于搜索高质量和高性能的 RAG 配置。", "conclusion": "我们认为，这种三层结构的框架将成为未来几年 RAG 系统质量和性能联合优化的事实标准。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20299", "html_url": "https://arxiv.org/abs/2510.20299", "title": "DB-FGA-Net: 双支路频域门控注意力网络及其多类分类的Grad-CAM可解释性", "title_en": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability", "authors": "Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim", "background": "脑肿瘤是神经肿瘤学中的一大挑战，早期和准确的诊断对于治疗的成功至关重要。基于深度学习的脑肿瘤分类方法通常依赖于大量的数据增强，但这种方法会限制模型在临床应用中的泛化能力和可信度。现有的研究试图解决这一问题，但仍未达到无数据增强的最优性能。", "innovation": "本文提出了一种结合VGG16和Xception双支路网络的DB-FGA-Net模型，加入了频域门控注意力（FGA）模块，能够捕捉局部和全局特征的互补信息。该模型在4类、3类和2类脑肿瘤分类任务中分别达到了99.24%、98.68%和99.85%的准确率，无需数据增强，并能在不同大小和分布的数据集上表现出色。此外，模型集成了Grad-CAM，用于基于预测结果可视化肿瘤区域，从而提高了模型的临床解释性。", "conclusion": "本文提出的DB-FGA-Net模型在不使用数据增强的情况下，实现了99.24%的准确率，并通过集成Grad-CAM提高了模型的临床解释性。该模型在多类脑肿瘤分类任务中表现出了优于现有基线和最先进方法的性能，为脑肿瘤诊断的可靠临床转化提供了支持。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20327", "html_url": "https://arxiv.org/abs/2510.20327", "title": "LEGO: 一种轻量高效的推荐系统多属性遗忘框架", "title_en": "LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems", "authors": "Fengyuan Yu,Yuyuan Li,Xiaohua Feng,Junjie Fang,Tao Wang,Chaochao Chen", "background": "随着对保护敏感用户信息需求的增长，推荐系统中的推荐属性遗忘日益受到关注。现有的研究主要集中在单一属性遗忘上。然而，现实生活中的隐私保护需求通常涉及多个敏感属性，并且是动态变化的。现有的单一属性遗忘方法由于无法同时处理多个遗忘请求（CH1）以及缺乏对动态遗忘需求的有效适应性（CH2），无法满足这些实际需求。", "innovation": "为了解决这些挑战，本文提出了LEGO，一种轻量高效的多属性遗忘框架。LEGO将多属性遗忘过程分为两个步骤：一是嵌入校准，从用户嵌入中移除与特定属性相关的信息；二是灵活组合，将这些嵌入组合成一个单一的嵌入，保护所有敏感属性。这种方法通过最小化互信息问题提供理论上的多重遗忘保证，同时使用两步框架（嵌入校准并行和灵活组合），提高了处理能力和灵活性，从而有效解决了CH1和CH2问题。", "conclusion": "我们在三个真实世界数据集上的三个代表性推荐模型中进行了广泛的实验研究表明，所提出框架的有效性和效率。LEGO的源代码和附加文件可在指定的网址找到。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20333", "html_url": "https://arxiv.org/abs/2510.20333", "title": "GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?", "title_en": "GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments?", "authors": "Chiyu Chen,Xinhao Song,Yunkai Chai,Yang Yao,Haodong Zhao,Lijun Li,Jie Li,Yan Teng,Gongshen Liu,Yingchun Wang", "background": "视觉语言模型（VLMs）越来越多地被用作自主代理来导航移动图形用户界面（GUIs）。在包含通知、弹出窗口以及跨应用交互的动态设备生态系统中运行，这些模型面临的是一种独特的且尚未充分研究的威胁向量：环境注入。这种注入方式通过直接插入恶意UI元素，如欺骗性覆盖层或伪造的通知，来破坏代理的视觉感知，从而绕过了文本保护措施，可能导致隐私泄露、财务损失或设备不可逆的损坏。", "innovation": "本文引入了GhostEI-Bench，这是首个用于评估移动代理在动态执行环境中抵御环境注入攻击的基准测试。GhostEI-Bench超出了静态图像评估的范畴，在完全操作的Android模拟器中注入有害事件，并在关键风险场景中评估性能。进一步提出了由评估员-大语言模型（judge-LLM）协议，通过回溯代理的动作轨迹与相应的截屏序列，进行精细的失败分析，以定位感知、识别或推理的失败。", "conclusion": "全面实验表明，当前最先进的代理模型在欺骗性环境提示方面表现出严重的脆弱性。GhostEI-Bench为量化和缓解这种新兴威胁提供了框架，为更强大和安全的实体代理铺平了道路。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20351", "html_url": "https://arxiv.org/abs/2510.20351", "title": "在大型语言模型中评估公共表格式数据集的潜在知识", "title_en": "Evaluating Latent Knowledge of Public Tabular Datasets in Large Language Models", "authors": "Matteo Silvestri,Flavio Giorgi,Fabrizio Silvestri,Gabriele Tolomei", "background": "大型语言模型（LLMs）现在越来越多地通过推理结构化数据的能力进行评价，然而这样的评估往往忽视了一个重要的混淆因素：数据集污染。研究表明，LLMs在处理成人所得、泰坦尼克号等广泛使用的表格基准数据集时可能依赖于这些数据集中的先验知识，而不是真正的推理能力。", "innovation": "通过一系列受控探测实验揭示，只有当数据集中包含强烈语义线索，例如有意义的列名或可解释的价值类别时，污染效应才会出现。移除或随机化这些线索会使性能下降到近乎随机的水平。这项研究建议，LLMs在表格推理任务上的表现部分反映了对公开数据集的记忆而非真正的泛化能力。提出了关于评价协议的讨论以及未来LLM评估中分离语义泄漏与真实推理能力的策略。", "conclusion": "LLMs在表格推理任务上的表象能力可能部分反映了对公开数据集的记忆，而非真正的泛化能力。提出了分离语义泄漏和真实推理能力的策略，以改进未来的LLM评价方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20375", "html_url": "https://arxiv.org/abs/2510.20375", "title": "大规模语言模型中否定文本对幻觉的影响", "title_en": "The Impact of Negated Text on Hallucination with Large Language Models", "authors": "Jaehyung Seo,Hyeonseok Moon,Heuiseok Lim", "background": "最近对大规模语言模型（LLMs）中的幻觉研究在自然语言处理中取得了积极进展，但否定文本对LLMs幻觉的影响尚未得到充分探索。", "innovation": "本文设定了三个未回答的研究问题，并通过研究LLMs在处理带有否定表达的文本时能否识别上下文转变并可靠地区分幻觉来回答这些问题；设计了一个名为NegHalu的数据集，通过重新构建现有的幻觉检测数据集来包含否定表达；实验证明LLMs在检测否定文本中的幻觉时存在困难，常常产生逻辑不一致或不忠实的判断。", "conclusion": "我们的研究表明，LLMs在处理否定输入时存在内部状态困难，难以缓解其潜在的负面效果。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20342", "html_url": "https://arxiv.org/abs/2510.20342", "title": "教语言模型使用工具进行推理", "title_en": "Teaching Language Models to Reason with Tools", "authors": "Chengpeng Li,Zhengyang Tang,Ziniu Li,Mingfeng Xue,Keqin Bao,Tian Ding,Ruoyu Sun,Benyou Wang,Xiang Wang,Junyang Lin,Dayiheng Liu", "background": "大型推理模型（LRMs）如OpenAI-o1在自然语言推理方面表现出了令人印象深刻的性能。然而，当处理复杂的数学运算时，这些模型通常会显示出效率低下的问题或不准确性。将计算工具如代码解释器（CIs）集成进去虽然提供了一个前景广阔的解决方案，但也会引发一个关键问题：模型的内部概率推理与来自CI的外部确定性知识之间的冲突，导致模型进行无效的推理。", "innovation": "本文提出了一种后训练框架CoRT（代码优化推理训练），用于教LRMs如何有效地利用CIs。文中提出了一种新的数据合成策略——提示工程，通过在推理路径的关键点注入多样化的提示来生成高质量、代码集成的推理数据，专门优化LRM-CI交互。此外，CoRT利用拒绝采样和强化学习进一步精细合并外部CI使用和内部思考的多轮交错。实验结果表明，CoRT的有效性，分别在五个复杂的数学推理数据集上获得了DeepSeek-R1-Distill-Qwen-32B和DeepSeek-R1-Distill-Qwen-1.5B高达4%和8%的绝对改进。同时，CoRT显著提高了效率，对于32B模型的令牌使用减少了约30%，对于1.5B模型减少了约50%。", "conclusion": "本文提出并通过实验证明了CoRT框架可以有效解决模型使用外部工具进行复杂数学推理时的效率和准确性问题，显著提升了模型和代码的集成推理效果，同时提高了模型的效率。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20350", "html_url": "https://arxiv.org/abs/2510.20350", "title": "AI生成图像想要什么？", "title_en": "What do AI-Generated Images Want?", "authors": "Amanda Wasielewski", "background": "W.J.T. Mitchell 的影响性文章《图片想要什么？》将理论焦点从理解图片和创造图片的人的动机转移到图片自身可能是一个具有代理性和欲望的实体。本文基于当代AI图像生成工具，重新审视这一观点，探讨AI生成图像的欲望，并从艺术史中关于抽象的本质进行探讨，指出AI生成图像本质上是抽象的，因此它们渴望具体性和具体性。文章讨论了基于文本和图像可替换性前提的多模态文本到图像模型和它们在用户流程中的表现形式，揭示了这种转换过程中的表征递归使人们误认为文本形式可以直接转化为视觉输出，而实际上并非如此。", "innovation": "提出重新审视AI生成图像的欲望，从W.J.T. Mitchell的理论出发，结合当代AI工具和技术，探讨AI生成图像的具体性和抽象性之间的关系，强调图像生成模型背后表征的复杂性，揭示了用户流程中的表征递归现象。这一视角拓宽了对AI图像生成技术的理解，提出了新的理论框架。", "conclusion": "文章表明，尽管多模态文本到图像模型理论上强调文本与图像之间的可替换性，但实际上这一转换过程是复杂且非一对一的。用户从文本输入到视觉输出的体验被嵌入了表征递归，让人误以为文本可以直接转化为图像，这种不透明的转换过程需要进一步的理论探讨和研究。文章揭示了文本到图像生成背后的复杂机制，以及这些机制对艺术和认知的影响。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20387", "html_url": "https://arxiv.org/abs/2510.20387", "title": "基于相对排序的神经语言模型扩增定律", "title_en": "Relative-Based Scaling Law for Neural Language Models", "authors": "Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu", "background": "现有研究表明，扩增定律旨在预测不同规模下的模型性能。但大多研究依赖交叉熵作为评价指标，虽然交叉熵可以反映绝对概率，但对于语言模型的相对排序情况考虑不足。", "innovation": "该研究提出了一种基于相对排序的概率（RBP）度量方法，该度量方法量化了正确标签在前几预测中的概率。基于此，研究建立了相对排序扩增定律，揭示了RBP随模型规模增加而提升的情况。通过在四个数据集和四个模型家族上的实验，证明了该定律的稳健性和准确性。", "conclusion": "基于相对排序的扩增定律补充了交叉熵视角，有助于更全面地理解大语言模型的扩增，为实际开发和理论研究提供有价值的见解。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20381", "html_url": "https://arxiv.org/abs/2510.20381", "title": "VLSP 2025 MLQA-TSR挑战：越南多模态法律问答系统在交通标志规范中的应用", "title_en": "VLSP 2025 MLQA-TSR Challenge: Vietnamese Multimodal Legal Question Answering on Traffic Sign Regulation", "authors": "Son T. Luu,Trung Vo,Hiep Nguyen,Khanh Quoc Tran,Kiet Van Nguyen,Vu Tran,Ngan Luu-Thuy Nguyen,Le-Minh Nguyen", "background": "该研究介绍的VLSP 2025 MLQA-TSR是2025年越南语言与信息技术研讨会（VLSP）中的一个共享任务，旨在通过处理越南法律文本和交通标志规范来推进多模态法律文本处理的研究，并提供一个基准数据集，用于构建和评估多模态法律领域的智能系统。", "innovation": "该任务包括两个子任务：多模态法律检索和多模态问答。其创新之处在于聚焦越南的交通标志法规，促进越南多模态法律文本处理研究的发展，提供了新的基准数据集。", "conclusion": "在VLSP 2025 MLQA-TSR中，最佳表现的成绩分别为多模态法律检索的F2分数64.55%和多模态问答的准确率86.30%。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20314", "html_url": "https://arxiv.org/abs/2510.20314", "title": "增强深度强化学习安全性：对手攻击与防御的全面综述", "title_en": "Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses", "authors": "Wu Yichao,Wang Yirui,Ding Panpan,Wang Hailong,Zhu Bingqian,Liu Chun", "background": "随着深度强化学习（DRL）技术在自动驾驶、智能制造业和智能医疗等复杂领域中的广泛应用，如何在动态变化的环境中提高其安全性和鲁棒性已成为当前研究的核心问题。特别是在面对恶意攻击时，DRL 可能会出现严重的性能下降甚至做出危险决策，因此在安全性敏感场景下确保其稳定性至关重要。因此，本文首先介绍了DRL的基本框架及其在复杂变化环境中的主要安全挑战，并提出了基于扰动类型和攻击目标的对手攻击分类框架，详细回顾了针对DRL的主要对手攻击方法，包括状态空间、动作空间、奖励函数和模型空间的各类攻击方法。此外，本文系统总结了各种当前的鲁棒性训练策略，包括对抗训练、竞争训练、鲁棒学习、对抗检测、防御蒸馏等相关的防御技术，并讨论了这些方法在提高DRL鲁棒性方面的优势和局限性。最后，本文对DRL在对手环境中的未来研究方向进行了展望，强调了提高泛化能力、降低计算复杂度、增强可扩展性和可解释性的研究需求，为研究人员提供有价值的参考和方向。", "innovation": "本文提出了一种基于扰动类型和攻击目标的对手攻击分类框架；系统总结了各种当前的鲁棒性训练策略，涵盖对抗训练、竞争训练、鲁棒学习、对抗检测、防御蒸馏等；讨论了这些方法在提高DRL鲁棒性方面的优势和局限性，并对未来研究方向进行了展望，包括提高泛化能力、降低计算复杂度、增强可扩展性和可解释性方面的需求。", "conclusion": "本文通过对当前DRL领域的对手攻击和防御研究进行全面综述，提出了多种鲁棒性提升方法和策略，并对未来研究方向进行了展望，旨在为研究人员提供有价值的参考和方向，以便进一步提升DRL的安全性和鲁棒性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20339", "html_url": "https://arxiv.org/abs/2510.20339", "title": "多任务深度学习在表面计量学中的应用", "title_en": "Multi-Task Deep Learning for Surface Metrology", "authors": "D. Kucharski,A. Gaska,T. Kowaluk,K. Stepien,M. Repalska,B. Gapinski,M. Wieczorowski,M. Nawotka,P. Sobecki,P. Sosinowski,J. Tomasik,A. Wojtowicz", "background": "本文介绍了用于预测表面纹理参数及其报告的标准不确定性的可重复深度学习框架。使用触觉和光学系统测量数据集，本文解决了测量系统类型分类的同时，以及协调预测Ra, Rz, RONt及其不确定性目标（Ra_uncert, Rz_uncert, RONt_uncert）。", "innovation": "本文提出了一种多任务深度学习框架，能够同时预测表面纹理参数及其不确定性。通过使用量纲和异方差性头部建模不确定性，并采用后验符合校准来生成经过校准的区间。此外，本文还观察到对未见过的数据集进行单目标模型比多输出模型表现更好。", "conclusion": "基于单独目标回归器，本文在预测Ra、Rz、RONt及其不确定性方面达到了很高的精度（R2：Ra 0.9824, Rz 0.9847, RONt 0.9918），其中Ra_uncert和Rz_uncert也得到了很好的预测（R2：Ra_uncert 0.9899, Rz_uncert 0.9955），但RONt_uncert预测相对困难（R2：0.4934）。分类器的准确率达到92.85%，并经过温度缩放后概率校准变化不大（从0.00504变为0.00503）。这些结果为在计量学流程中进行仪器选择和验收决策提供了经过校准的预测信息。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20441", "html_url": "https://arxiv.org/abs/2510.20441", "title": "UniSE: 一种基于解码器自回归LM的统一语音增强框架", "title_en": "UniSE: A Unified Framework for Decoder-only Autoregressive LM-based Speech Enhancement", "authors": "Haoyin Yan,Chengwei Liu,Shaofei Xue,Xiaotao Liang,Zheng Xue", "background": "神经音频编解码器（NACs）的发展极大地促进了语言模型（LMs）在语音处理和理解中的应用。然而，目前缺乏对自回归（AR）基于LM的模型在统一语音增强（SE）任务中有效性的验证。这些任务包括语音恢复、目标说话人提取和语音分离等不同子任务。", "innovation": "本文提出了一个统一的解码器自回归LM框架，名为UniSE，旨在处理不同的语音增强任务，包括语音恢复、目标说话人提取和语音分离。UniSE 使用输入语音特征作为条件，并通过AR建模生成目标语音的离散令牌，从而增强不同任务学习模式之间的兼容性。实验表明，提出的UniSE可以与判别性和生成性基线取得竞争性的性能，展示了LM在统一语音增强任务中具备的能力。", "conclusion": "提出的UniSE框架能够在多个基准上取得与判别性及生成性基线相当的性能，表明基于LM的方法有能力统一处理各种语音增强任务。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20438", "html_url": "https://arxiv.org/abs/2510.20438", "title": "动态权重调整的知识蒸馏：利用视觉变换器实现高精度肺癌检测及其实时部署", "title_en": "Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment", "authors": "Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel", "background": "本文提出了一种新的肺癌分类方法——FuzzyDistillViT-MobileNet模型，利用动态模糊逻辑驱动的知识蒸馏来处理疾病诊断中的不确定性和复杂性。传统的静态知识蒸馏使用固定权重，而本文的方法通过模糊逻辑动态调整蒸馏权重，使得学生模型能够专注于高置信度区域并减少对模糊区域的关注。这种方法提高了模型处理不同区域肺癌图像的不确定性水平的能力。", "innovation": "该研究创新之处在于提出的FuzzyDistillViT-MobileNet模型，通过动态调整权重，使用模糊逻辑驱动的知识蒸馏技术，有效提升了模型的泛化能力和在不同不确定性水平下的适应性。此外，模型还结合了像素级图像融合技术如伽马校正和直方图均衡化，以及采用了Genetic Algorithm来选择合适的预训练学生模型，从而提高计算效率和模型性能。", "conclusion": "该模型在LC25000组织病理图像和IQOTH/NCCD CT扫描图像上分别达到了99.16%和99.54%的高准确率，展示了其在不同成像领域中的稳健性能，并能够实现实时部署。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20448", "html_url": "https://arxiv.org/abs/2510.20448", "title": "MolBridge：原子级联合图精细调整以实现稳健的药物-药物相互作用事件预测", "title_en": "MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction", "authors": "Xuan Lin,Aocheng Ding,Tengfei Ma,Hua Liang,Zhe Quan", "background": "药物组合可以提供治疗上的好处，但也带来了药物-药物相互作用（DDIs）带来的风险，尤其是在复杂的分子结构下。准确预测DDI事件需要捕获药物之间的精细关系，这对于建模如酶介导的竞争等代谢机制至关重要。然而，现有的方法通常依赖孤立的药物表示，未能明确建模原子级跨分子交互作用，从而限制了其在不同分子复杂性和DDI类型分布中的有效性。", "innovation": "本文提出了MolBridge，一种新颖的原子级联合图细化框架，用于稳健的DDI事件预测。MolBridge构建了一个集成药物对原子结构的联合图，从而可以直接建模药物间的关联。该框架通过迭代细化节点特征，同时保留全局结构上下文，解决了潜在的长程原子依赖性的信息丢失问题。此联合设计让MolBridge能够有效学习局部和全局交互作用，性能超越现有领先基线，在长尾和归纳场景中表现优越，生成稳健的DDI表示，涵盖常见和罕见的DDI类型。", "conclusion": "大量的基准数据集实验表明，MolBridge能够持续提升DDI事件预测的准确性、稳健性和机制可解释性。这项工作的贡献在于通过开发基于图的方法来挖掘和分析药物-药物相互作用网络，推进了Web挖掘和内容分析领域的发展。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20468", "html_url": "https://arxiv.org/abs/2510.20468", "title": "通过图像偏好模型实现可移植的黑盒一次性水印伪造", "title_en": "Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models", "authors": "Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko", "background": "近年来，由于生成模型的普及和法律压力的增加，数字内容水印技术的研究兴趣激增。随着越来越多的AI生成内容出现在网上，水印在大规模确保内容真实性及归属方面发挥着越来越重要的作用。现有研究成果大多集中在评估水印的鲁棒性，但针对水印伪造的研究相对不足。水印伪造是指恶意拥有真实内容的水印，并将其应用到恶意内容中。本研究聚焦于广泛使用的后处理图像水印，旨在评估当前水印技术的安全性。", "innovation": "研究使用了一种偏好模型来判断图像是否被水印标记。该模型通过使用纯粹程序生成的图像训练，并在不需要真实水印的情况下进行训练。研究还展示了通过优化输入图像来移除和伪造水印的技术，仅需一张水标图像即可实现，无需了解水标算法的具体细节，从而使攻击更为简单和实用。此外，研究评估了该方法对不同后处理图像水印模型的效果，表明现有水印方法的安全性存疑。", "conclusion": "研究方法能够有效地伪造水印，暗示现有的水印方法可能不安全。研究代码和资源已经公开。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20408", "html_url": "https://arxiv.org/abs/2510.20408", "title": "平衡专业化与集中化：序贯工业控制的多智能体强化学习基准", "title_en": "Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control", "authors": "Tom Maus,Asma Atamna,Tobias Glasmachers", "background": "多阶段工业过程的自主控制需要局部专业化与全局协调。强化学习（RL）被认为是一个有潜力的方法，但其在工业中的应用却受到了奖励设计、模块化和动作空间管理等挑战的限制。许多学术基准与工业控制问题相差甚远，限制了它们的实际应用。现有研究表明，对于某些任务，特别是在不使用动作掩蔽的情况下，智能体难以学习有效的策略，而且模块化架构比单一代理方法表现更好。因此，需要一个更加符合实际的多智能体RL基准环境来促进实际工业应用。", "innovation": "本文提出了一个行业启发式的增强基准环境，将现有的SortingEnv和ContainerGym两个基准环境的任务结合起来，形成一个序贯回收场景，包含排序和压实操作。研究了两种控制策略：模块化架构（具有专业化智能体）和单一代理架构，并分析了动作掩蔽的影响。实验表明，不使用动作掩蔽时，智能体难以学习有效的策略，模块化架构表现更佳。使用动作掩蔽时，两种架构都取得了显著的改进，性能差距显著缩小。结果表明，动作空间约束在多智能体RL中起到重要作用，并提示专业化优势随着动作复杂度降低而减弱。该研究为探索工业自动化中的实用和稳健的多智能体RL解决方案提供了有价值的测试平台，同时也为集中化与专业化争论的辩论做出了贡献。", "conclusion": "本文的结果强调了动作空间约束的重要作用，并证明了在减少动作复杂度时，专业化优势会消失。提出的基准环境有助于探索在工业自动化中的实用和稳健的多智能体RL解决方案，对集中化与专业化辩论具有重要意义。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20469", "html_url": "https://arxiv.org/abs/2510.20469", "title": "在执行基于P2P资源受限网络的信息融合的多代理系统中生成的结构", "title_en": "Structures generated in a multiagent system performing information fusion in peer-to-peer resource-constrained networks", "authors": "Horacio Paggi,Juan A. Lara,Javier Soriano", "background": "近年来，信息融合的方法有了显著的进步。信息融合从传统的军事应用中纯粹的层级式处理，发展到了目前更为协作的‘整合体融合’方法，这种方法更适合民用应用和边缘组织。这一转变是由于信息融合在非军事领域中的应用日益增多，以及人机通信和机器间通信的发展，使得更加灵活的层次结构取代了传统的静态层级结构。", "innovation": "本文主要聚焦于展示，当参与信息融合的实体（即同伴）受到资源（如能源、可用消息、时间等）限制时，如何生成整合作为优化信息融合过程中模糊性和不确定性影响的一种方法。这项研究基于多代理系统模型，探讨了整合作的形成机制，并给出其操作示例。整合作具有的优势包括：能够适应环境或组成结构的突变；一定程度上的自主性；能够合作达成共同目标。", "conclusion": "该研究揭示了在资源受限的网络环境中，通过信息融合生成的整合作的多种优势，为理解如何在资源有限的情况下优化信息融合过程提供了新的视角。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20328", "html_url": "https://arxiv.org/abs/2510.20328", "title": "MemER: 通过经验检索扩大机器人控制中的记忆力", "title_en": "MemER: Scaling Up Memory for Robot Control via Experience Retrieval", "authors": "Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn", "background": "人类在执行任务时经常依赖记忆，而现有的大多数机器人策略缺乏这种能力。我们旨在为机器人策略赋予这种能力。单纯基于长时间观察的历史数据进行条件处理在计算上太过昂贵且在分量分布变化时易崩溃，而未经筛选的历史数据抽样则可能导致无关或冗余信息。本文提出了一种分层策略框架，在这种框架中，高层策略负责从其经验中选择和追踪之前的相关关键帧。高层策略利用选定的关键帧和最近的图像帧为低层策略生成执行文本指令。这种设计与现有的视觉-语言-动作（VLA）模型兼容，使系统能够有效推理长时程依赖关系。", "innovation": "本文提出了一种分层策略框架，其中高层策略通过选择和追踪历史中的关键帧来提升机器人策略的记忆能力。高层策略利用这些关键帧和最新的图像帧来为低层策略生成执行指令，这种设计与现有的VLA模型兼容，能够有效处理长时程任务。论文实验采用Qwen2.5-VL-7B-Instruct和$\bm{\tilde{\boldsymbol{\times}}}_{0.5}$作为高层和低层策略，并通过示例数据和少量语言注释进行微调。实验结果表明，该方法在三个需要分钟级别记忆力的现实长时程机器人操作任务中优于先前的方法。", "conclusion": "本文提出的方法MemER在记忆能力上取得了显著提升，使机器人能够更有效地执行长时间任务。相关视频和代码可在[此网址]找到。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20453", "html_url": "https://arxiv.org/abs/2510.20453", "title": "符号回归和可微拟合在超越标准模型物理中的应用", "title_en": "Symbolic Regression and Differentiable Fits in Beyond the Standard Model Physics", "authors": "Shehu AbdusSalam,Steven Abel,Deaglan Bartlett,Miguel Crispim Romão", "background": "本文通过考虑约束最小超对称标准模型（CMSSM）来探讨符号回归（SR）在探索超越标准模型（BSM）物理模型中的有效性。CMSSM与其他许多BSM物理模型一样，包含多个（四个）任意参数，这些参数决定了实验信号和诸如暗物质遗迹密度等宇宙观测值。通过分析可观测量的符号表达式，可以显著加速实验具体化过程。本文专注于希格斯 boson 质量、冷暗物质遗迹密度和 muon 异常磁矩贡献等可观测量的分析。使用符号回归方法，我们得到了相当准确的表达式，并通过全局拟合得到了与传统方法一致的参数后验概率密度分布。此外，符号回归比神经网络回归更具全局鲁棒性，而神经网络需要集中在有希望的数据区域才能达到相同的效果.", "innovation": "本文的主要创新在于使用符号回归技术来加速并简化超越标准模型物理模型的具体化过程。具体表现为能以符号表达式形式快速准确地描述可观测量与输入参数之间的关系，从而无需依赖于传统的采样方法，而是使用可微方法进行全局拟合。这不仅提高了拟合效率，而且展示了符号回归相对于神经网络的优势，即能够在不需要聚焦于有希望数据区域的情况下获得更稳健的拟合结果。", "conclusion": "通过实验验证，符号回归方法能够生成与传统方法一致且相当准确的可观测量表达式，并能通过全局拟合得到CMSSM输入参数的后验概率密度分布。与神经网络回归方法相比，符号回归更具全局鲁棒性，能在不需要聚焦于有希望的数据区域的情况下获得可信的拟合结果。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20479", "html_url": "https://arxiv.org/abs/2510.20479", "title": "RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging", "title_en": "RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging", "authors": "Bowen Wang,Haiyuan Wan,Liwen Shi,Chen Yang,Peng He,Yue Ma,Haochen Han,Wenhao Li,Tiao Tan,Yongjian Li,Fangming Liu,Yifan Gong,Sheng Zhang", "background": "本文旨在研究大型语言模型（LLMs）内部表示与其学习知识之间的关系，并提出了一种新的RECALL框架，用于无历史数据访问的情况下的连续学习。背景信息显示，先前方法依赖于任务标签或会导致性能权衡。因此，本文提出了RECALL框架，旨在无缝实现多领域整合和强大的灾难性遗忘抗性。实验结果表明，RECALL在知识保留和泛化方面优于基线方法，提供了一种可扩展且无需数据的解决方案，以适应演变中的LLMs。", "innovation": "该研究的创新点在于提出了RECALL框架，该框架通过分层模型融合计算模型间相似性，并进行适应性和分层参数融合，以实现知识在不同模型之间的对齐。这一设计使得浅层保留跨域一般特征，深层允许针对具体任务的调整。与以前的方法不同，RECALL无需任务标签，也无需性能权衡，从而实现了灾难性遗忘的缓解。", "conclusion": " extensive experiments across five NLP tasks and multiple continual learning scenarios demonstrate that RECALL outperforms baselines in both knowledge retention and generalization, providing a scalable and data-free solution for evolving LLMs."}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20487", "html_url": "https://arxiv.org/abs/2510.20487", "title": "调节评估感知语言模型使其表现为已部署状态", "title_en": "Steering Evaluation-Aware Language Models To Act Like They Are Deployed", "authors": "Tim Tian Hua,Andrew Qin,Samuel Marks,Neel Nanda", "background": "大型语言模型（LLMs）在被评估时有时会意识到这一点，并调整其行为以显得更符合安全标准，这影响了安全评估的可靠性。本文探讨了一种称为激活调节的技术，可以在保留评估提示的情况下使模型的行为更符合已部署状态，从而改善评估的真实性。", "innovation": "本文提出了一种激活调节技术，通过在模型中添加一个引导向量，可以在评估过程中抑制模型的评估感知，使其表现得像在部署时一样。该技术在保留评估提示的情况下，成功使模型的行为更符合已部署状态，同时节省了额外训练模型的时间和资源成本。", "conclusion": "通过激活调节，可以提高AI评估的可靠性，通过生成一个引导模型似乎已部署的行为框架，模型能够保留原有的性能，同时避免了额外的训练阶段。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20486", "html_url": "https://arxiv.org/abs/2510.20486", "title": "Hurdle-IMDL: 一种用于红外降雨检索的不平衡学习框架", "title_en": "Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval", "authors": "Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng", "background": "虽然人工智能已经推动了定量遥感的发展，但其效果受到了标签分布不平衡的限制。这种不平衡导致传统训练模型偏好常见样本，从而降低了对稀有样本检索性能。降雨检索就是一个例证，尤其是对于强降雨，其性能受到特别严重影响。", "innovation": "本文提出了 hurdle-inversion model debiasing learning (IMDL) 框架。该框架采用分而治之的策略，将降雨分布的不平衡分解为两个部分：零膨胀（由非降雨样本占主导定义）和长尾分布（由轻雨样本相对于暴雨样本的异常丰富定义）。该研究采用 hurdle 模型处理零膨胀，并提出 IMDL 方法通过将学习对象转化为无偏的理想逆模型来解决长尾分布问题。全面的统计指标和案例研究验证了 hurdle-IMDL 在传统、成本敏感、生成和多任务学习方法中的优越性，其关键进展包括有效缓解系统性的低估并显著提高强降雨至极端降雨的检索性能。", "conclusion": "IMDL 提供了一种处理环境变量分布不平衡的通用方法，使稀有但高影响事件的检索得以增强。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20519", "html_url": "https://arxiv.org/abs/2510.20519", "title": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning", "title_en": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning", "authors": "Xiaohan Lan,Fanfan Liu,Haibo Qiu,Siqi Yang,Delian Ruan,Peng Shi,Lin Ma", "background": "最近的语言模型（LLM）推理取得了显著进展，尤其是在多模态推理方面，使得在复杂的任务如数学问题求解上取得了重要的性能提升。然而现有的多模态大模型也存在两个主要缺点：首先是它们往往即使对于简单的查询也采用复杂的推理，导致运行效率低下；其次是过分专注于专业的推理策略会影响其更广泛、更通用的理解能力。本文就是在这样的背景下提出的。", "innovation": "本文提出了一种混合优化混合专家（Metis-HOME）框架。Metis-HOME通过将原始密集模型分为通用推理和专用于复杂多步推理的两个独立专家分支，实现了杂合思考（hybrid thinking）的范式。此外，还通过一个轻型可训练路由，动态地将查询分配给最适合的专家，从而解决了专为推理设计的模型与更广泛应用能力之间的权衡难题。", "conclusion": "我们的研究不仅显著提升了复杂推理能力，还提升了模型的一般能力，逆转了其他专注于推理的模型中观察到的能力退化趋势。这项工作为构建强大的、多功能的多模态语言大模型设定了一个新的范式，并有效解决了推理与通用性之间的常见冲突。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20531", "html_url": "https://arxiv.org/abs/2510.20531", "title": "Fake-in-Facext: 面向细粒度可解释深度合成分析", "title_en": "Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis", "authors": "Lixiong Qin,Yang Zhang,Mei Wang,Jiani Hu,Weihong Deng,Weiran Xu", "background": "多模态大型语言模型（MLLMs）的进步使得视觉和语言任务之间的差距得以弥合，促使了可解释虚假内容分析（XDFA）的实现。然而，当前的方法面临细粒度意识不足的问题：数据注释中对艺术在细节上的描述不可靠且粗糙，模型无法支持文本伪造解释与视觉证据之间的关联输出，也不能为任意面部区域提供输入查询。因此，它们的回应未能充分基于面部视觉上下文（Facext）。", "innovation": "为了应对这一局限，本文提出了一个名为FiFa的框架，包括数据注释和模型构建的贡献。首先定义了面部图像概念树（FICT），将面部图像细分为细粒度区域概念，从而获得更可靠的注释流水线FiFa-Annotator，用于伪造解释。基于这种专门的数据注释，引入了一个新的任务立项细粒度的文本伪造解释（AGE），该任务生成文本伪造解释与操纵艺术的分割掩模交错。提出了一个统一的多任务学习架构FiFa-MLLM，能够同时支持丰富的多模态输入和输出，以实现细粒度的可解释深度合成分析。", "conclusion": "多辅助监督任务的FiFa-MLLM优于强基准，在文本艺术梳理任务（AGE）上表现出色，并在现有 XDFA 数据集上达到最先进水平。代码和数据将在GitHub上开源。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20548", "html_url": "https://arxiv.org/abs/2510.20548", "title": "GlobalRAG：通过强化学习增强多跳问答中的全局推理", "title_en": "GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning", "authors": "Jinchang Luo,Mingquan Cheng,Fan Wan,Ni Li,Xiaoling Xia,Shuangshuang Tian,Tingcheng Bian,Haiwei Wang,Haohuan Fu,Yan Tao", "background": "近期，强化学习在提升检索增强生成(RAG)方面表现出巨大潜力，但在多跳问答(QA)中的有效性受到两项根本性限制：无全局规划损害多步推理结构，不忠实执行阻碍有效查询和一致使用检索证据。", "innovation": "提出GlobalRAG，一种强化学习框架，用于增强多跳QA的全局推理。该框架将问题分解为子目标，协调检索与推理，并迭代优化证据。引入了规划质量奖励和子目标完成奖励，以促进一致的规划和可靠的子目标执行。此外，采用逐步加权退火策略来平衡过程导向和结果导向的目标。", "conclusion": "在多种领域内和领域外基准上的实验表明，GlobalRAG在仅使用8k训练数据（比强基线少42%）的情况下，显著超越了强基线，在准确率（EM）和F1分数上分别平均提高了14.2%。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20388", "html_url": "https://arxiv.org/abs/2510.20388", "title": "FLAS：分布式服务中结合主动和被动自动扩展架构", "title_en": "FLAS: a combination of proactive and reactive auto-scaling architecture for distributed services", "authors": "Víctor Rampérez,Javier Soriano,David Lizcano,Juan A. Lara", "background": "云计算已成为支持大多数新兴技术的核心支柱，主要得益于其弹性特性。自动扩展器通过按需获取和释放资源来确保约定的服务水平。本文介绍了一种新的自动扩展器FLAS，它结合了主动和被动扩展的优势，根据情况在不同时间点作出最优扩展决策，以更好地提高资源使用效率和确保服务性能。", "innovation": "FLAS的主要创新点在于：(i) 引入了一种预测性模型，可以预测高级指标的趋势，从而预见到关键SLO参数的变化（例如，性能指标如响应时间和吞吐量）；(ii) 结合了一个基于资源使用度量估计高级度量的反应性机制，减少了必要的仪器化（更不侵入性），并能够无偏见地适应不同应用。该系统在基于内容的发布-订阅中间件（E-SilboPS）场景下的实现是首个为分布式内容发布-订阅系统设计的自动扩展系统（尽管其足够通用，可以应用于任何类型的分布式服务）", "conclusion": "我们通过基于多种测试案例的评估，既涵盖了预期使用场景，也包括最坏情况下的情境（遵循边界值分析或BVA测试方法），验证了我们的方法，并证明了我们的解决方案在99%以上的时间内按要求满足性能需求的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20556", "html_url": "https://arxiv.org/abs/2510.20556", "title": "结构不变性很重要：通过图形指标重新思考图形重连", "title_en": "Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics", "authors": "Alexandre Benoit,Catherine Aitken,Yu He", "background": "图形重连已成为通过修改图形拓扑结构来改善信息流动、缓解图形神经网络（GNN）和图形变换器中的过度挤压的关键技术。然而，虽然图形重连有效，但其本质特性改变了图形结构，存在导致重要拓扑依赖信号失真的风险。尽管图形重连的使用日益增加，但人们还不清楚必须保留哪些结构属性，以确保性能提升和结构忠实性。本研究表明，重连策略对一系列图形结构度量的影响以及这些变化如何与下游任务性能关联。研究发现，成功的重连方法倾向于保持局部结构，同时允许全局连接度的灵活性。这些发现为有效重连策略的设计提供了新的见解，将图形理论与实际GNN优化联系起来。", "innovation": "首次系统分析了图形重连对一系列图形结构度量的影响，揭示了成功的重连方法通常保留局部结构并允许全局连接度的灵活性。这些发现填补了图形理论与实际GNN优化之间的空白，为有效重连策略的设计提供了新的见解。", "conclusion": "研究结果表明，成功的图形重连方法倾向于保留局部结构，同时允许全局连接度的变化。这为设计有效的图形重连策略提供了新的理解，通过结合图形理论和GNN优化提供了一种综合的方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20505", "html_url": "https://arxiv.org/abs/2510.20505", "title": "层次序列迭代在异构问答中的应用", "title_en": "Hierarchical Sequence Iteration for Heterogeneous Question Answering", "authors": "Ruiyi Yang,Hao Xue,Imran Razzak,Hakim Hacid,Flora D. Salim", "background": "当前的检索增强生成（RAG）模型在处理多步问题和异构证据来源时表现脆弱，会牺牲准确性和响应时间。现有方法需要权衡准确性和延迟，以及在工具和标记预算之间的选择。", "innovation": "本文提出了一种名为Hierarchical Sequence (HSEQ) Iteration的统一框架，该框架包括将文档、表格和知识图谱线性化为可逆的层次序列，并配备轻量级结构标签，以及通过结构感知迭代来收集足够的证据，从而进行答案合成。还提出了一个称为Head Agent的引导实体和一个称为Iteration Agent的迭代实体，分别用于指导检索和选择扩展HSeq的动作，以确保准确性并减少不必要的步骤、工具调用和标记；最终，Head Agent将规范化的证据组合成最终的答案，有时还会提供一个可选的改进循环来解决检测到的矛盾。该框架在HotpotQA（文本）、HybridQA/TAT-QA（表格+文本）、MetaQA（知识图谱）上的实验结果表明，与强单一通路、多跳以及代理RAG基线相比，效率明显提高，并且该方法表现出三大关键优势：通用格式转换能力、引导式预算感知迭代和证据规范化，提高了答案的一致性和可审计性。", "conclusion": "该论文提出的方法在异构问答任务上取得了持续的EM/F1改进，同时保持了高效性，并且展示了三个关键优势：通用格式转换能力、引导式预算感知迭代和证据规范化，从而使答案更可靠、一致且可审计。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20566", "html_url": "https://arxiv.org/abs/2510.20566", "title": "AdaDoS：基于深度对抗强化学习的SDN环境下的自适应DoS攻击", "title_en": "AdaDoS: Adaptive DoS Attack via Deep Adversarial Reinforcement Learning in SDN", "authors": "Wei Shao,Yuhao Wang,Rongguang He,Muhammad Ejaz Ahmed,Seyit Camtepe", "background": "现有的防御机制在抵御基于规则的拒绝服务（DoS）攻击方面表现出显著的效果，主要依赖预定义的签名和静态启发式方法来识别和阻止恶意流量。然而，人工智能驱动的技术的出现为SDN安全带来了新的挑战，可能削弱现有防御机制的有效性。传统的防御模型面临来自攻击者的挑战，攻击者通过对抗强化学习来调整其攻击策略，以绕过现有DoS检测器的识别。AdaDoS模型将攻击和检测看作是一个竞争性的博弈过程，通过动态调整策略，以减少被检测的机率来阻碍网络流量。针对攻击者通常信息较少的情况，AdaDoS将DoS攻击表示为部分可观测马尔可夫决策过程（POMDP），并引入一种新颖的学习模块，使得学生代理能够通过从全观代理中学习来提高性能。", "innovation": "AdaDoS是第一个利用强化学习（RL）开发具有自适应能力的DoS攻击序列的应用实例，能够在不被检测到的前提下调整其攻击策略，以逃避基于机器学习和规则的DoS检测器。通过引入一种新颖的双向学习模块，AdaDoS能够在可观测信息有限的情况下优化其攻击策略，实现自适应的DoS攻击。", "conclusion": "AdaDoS通过对抗强化学习在SDN环境中实现了自适应的DoS攻击，不仅能够动态调整攻击策略以逃避检测，还能够通过少数已知信息实现高效的攻击。这表明对抗强化学习方法可以应用于复杂的网络环境中，为未来的攻击和防御策略提供新的思路。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20596", "html_url": "https://arxiv.org/abs/2510.20596", "title": "基于相似度原型的无监督域适应在跨模态分割中的应用", "title_en": "Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation", "authors": "Ziyu Ye,Chen Ju,Chaofan Ma,Xiaoyun Zhang", "background": "深度学习模型在各种视觉挑战中取得了很大的成功，但当应用于未见过的数据时，经过训练的模型会面临显著的性能下降。由于模型对域位移敏感，无监督域适应旨在减少域间差异，并避免未见过域的成本高昂的标注。", "innovation": "提出了一种基于相似度原型的跨模态分割的新框架。具体而言，该方法在嵌入空间中学习类别级别的原型，引入相似性约束使这些原型代表各自语义类别，并且与其他类别分离。此外，方法使用字典来存储从不同图像中提取的原型，防止类别缺失问题，同时促进原型对比学习，进而提高性能。", "conclusion": "大量实验表明，该方法在跨模态分割中优于其他最先进的方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20535", "html_url": "https://arxiv.org/abs/2510.20535", "title": "ARC-Encoder: 学习压缩文本表示以供大规模语言模型使用", "title_en": "ARC-Encoder: learning compressed text representations for large language models", "authors": "Hippolyte Pilchen,Edouard Grave,Patrick Pérez", "background": "最近的技术如检索增强生成或链式思考推理导致了更长的上下文和更高的推理成本。上下文压缩技术可以降低这些成本，但最有效的手段需要对目标模型进行微调，甚至改变其架构。这在非特定用途的情况下会削弱其一般能力。本研究探索了一种替代方法：一种压缩上下文成连续表示的编码器，以替代解码器LLM中的词嵌入。研究通过系统研究编码器的训练策略和架构选择，提出了一个可自适应文本表示压缩器（Adaptable text RepresentationsCompressor，ARC-Encoder），它输出的连续表示是文本词元的x分之一（通常x属于{4,8}）。在多种LLM应用场景下，ARC-Encoder展示了在保持计算效率的同时，获得最先进的基准性能。此外，研究还证明了该模型能够同时适应不同的解码器，使单一编码器可以在不同解码器LLM间泛化，提供了灵活且高效的便携式编码器解决方案。更多的训练代码、微调数据集及预训练模型可在指定网址获取。", "innovation": "本文提出了一种可自适应文本表示压缩器（ARC-Encoder），通过将上下文压缩为连续表示来取代解码器LLM中的词嵌入，实现了在多个应用场景下的高效操作与高性能表现。方法包括系统研究编码器的训练策略与架构选择，并通过多个LLM解码器测试其在不同场景下的应用适应性及泛化能力。", "conclusion": "ARC-Encoder展示了在多个LLM应用场景中的优异性能，并提高了计算效率。此外，该模型能够同时适应多种解码器，使得其成为一种可无缝适应不同LLM的灵活和高效的解决方案。相关代码和资源已公开发布，供研究和应用中使用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20579", "html_url": "https://arxiv.org/abs/2510.20579", "title": "Open-o3 Video: 明确时空证据的视频推理", "title_en": "Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence", "authors": "Jiahao Meng,Xiangtai Li,Haochen Wang,Yue Tan,Tao Zhang,Lingdong Kong,Yunhai Tong,Anran Wang,Zhiyang Teng,Yujing Wang,Zhuochen Wang", "background": "目前大多数视频推理模型仅生成文本推理痕迹，但未提及关键证据出现的时间和地点。尽管某些模型如OpenAI-o3在图像证据中心推理方面引起了广泛关注，但将其扩展到视频推理更具挑战性，因为这需要在动态场景中进行联合时空跟踪和定位。现有的数据集和模型大多提供了视频的时间跨度或图像的空间框，缺乏统一对时空的监督和推理痕迹。该研究旨在通过构建新的数据集和采用强化学习策略来解决这些问题，从而提升视频推理的准确性和可靠性，特别是在V-STAR基准测试中取得了显著进步。", "innovation": "本研究引入了Open-o3 Video框架，该框架通过引入明确的时空证据来整合视频推理。为此，研究者精心构建了两个高质量的数据集STGR-CoT-30k和STGR-RL-36k，并采用了冷启动强化学习策略，设计了多个奖励机制，以鼓励答案准确性、时间对齐和空间精度。该方法在V-STAR基准测试中取得了最先进的性能，并在包括VideoMME、WorldSense、VideoMMMU和TVGBench等广泛视频理解基准测试中也表现出一致的改进。", "conclusion": "Open-o3 Video通过提供明确的时空证据，增强了视频推理的准确性和可靠性。该模型不仅在V-STAR基准测试中取得了显著的性能提升，还在多种视频理解基准测试中表现出一致的改进。产生的推理痕迹还为测试时的可扩展性和自信心验证提供了有价值的信号，进一步提升答案的可靠性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20605", "html_url": "https://arxiv.org/abs/2510.20605", "title": "OnlineSplatter：无姿态的在线自由移动物体3D重建", "title_en": "OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects", "authors": "Mark He Huang,Lin Geng Foo,Christian Theobalt,Ying Sun,De Wen Soh", "background": "从单一视角视频重建自由移动物体依然是个难题，尤其是在缺乏可靠姿态或深度提示以及任意物体运动的情况下。现有方法通常依赖于姿态或深度信息，且在处理自由移动物体时存在较大挑战。", "innovation": "提出了一种名为OnlineSplatter的新型在线前馈框架，该框架可以直接从RGB帧中生成高质量的物体中心3D高斯分布，而无需使用相机姿态、深度先验或束优化。该方法通过锚定第一个帧并使用稠密的高斯原语场逐步细化物体表示，从而保持恒定的计算成本，不论视频序列长度。核心贡献在于结合了潜在外观-几何键与显式方向键的双重记忆模块，该模块能够稳健地融合当前帧特征和时间聚合的对象状态，从而有效处理自由移动物体。", "conclusion": "在实际数据集上的评估表明，OnlineSplatter显著优于现有的无姿态重建基线，在获得更多观测数据时持续改进，同时保持恒定的内存和运行时间。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20584", "html_url": "https://arxiv.org/abs/2510.20584", "title": "ChatGPT能否公平地编码沟通数据？：来自多项协作任务的实证证据", "title_en": "Can ChatGPT Code Communication Data Fairly?: Empirical Evidence from Multiple Collaborative Tasks", "authors": "Jiangang Hao,Wenju Cui,Patrick Kyllonen,Emily Kerzabi", "background": "评估大规模的沟通和协作依赖于将大量的沟通数据归类到不同的框架中，这是一个劳动密集型的工作。尽管先前的研究表明，ChatGPT可以根据编码标准直接进行指示以对沟通数据进行分类，且准确度可与人类评阅者相比，但ChatGPT或类似的人工智能技术在编码过程中是否存在针对不同性别和种族群体的偏见仍有待探讨。基于此，该研究旨在通过使用一套典型的协作问题解决编码框架，对ChatGPT进行自动编码，探讨不同性别和种族群体之间的差异，分析结果来自三种类型的协作任务：协商、问题解决与决策制定。研究显示，ChatGPT进行编码在性别和种族之间不存在显著偏见，为在其大规模评估协作与沟通方面的应用铺平了道路。", "innovation": "本研究利用ChatGPT进行大规模的沟通数据自动编码，并通过多类型的协作任务分析其在性别和种族方面是否存在偏见。这填补了之前关于AI技术编码公平性的研究空白，对向大规模协作与沟通评估中引入ChatGPT具有重要意义。", "conclusion": "研究表明，基于ChatGPT的编码在性别和种族方面未表现出显著偏见，从而为其在大规模协作与沟通评估中的应用提供了坚实的基础。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20543", "html_url": "https://arxiv.org/abs/2510.20543", "title": "被追逐的狗难倒了模型：衡量语言模型何时放弃结构使用捷径", "title_en": "The Dog the Cat Chased Stumped the Model: Measuring When Language Models Abandon Structure for Shortcuts", "authors": "Sangmitra Madhusudan,Kaige Chen,Ali Emami", "background": "尽管语言模型能够正确解析句子像“The cat that the dog chased meowed”，但我们无法区分其解析的结构理解与仅基于语义模式匹配。目前缺乏能够区分结构性理解与语义模式匹配的方法。该文通过提出CenterBench 数据集，全面测试多个语言模型在这类中心嵌套句子上的表现，从而探讨其到底是通过结构分析理解句子，还是仅通过基本的语义模式匹配来解析句子的问题。CenterBench 包含9,720个关于中心嵌套句子的解释性问题，其中包括递归嵌套的从句，创建了简单的到深度嵌套结构的不同处理难度级别，测试了模型在语表理解、句法依赖性及因果推理方面的能力，通过核实六种模型的表现，揭示了模型随着结构复杂度提升对解析逻辑差异的科学技术模式。并且指出，语义认同度对模型在估计行动结果的问题影响更大，而对于逻辑关系的推理，语义一致性则更为重要。", "innovation": "通过创建CenterBench 数据集，该研究首次提出了一种框架来识别语言模型在结构分析与模式匹配之间的转变点，帮助了解模型是如何解析复杂结构的，研究发现，理解决策模型虽然能够提高准确性，但是它们会依赖于语义捷径，过度思考或拒绝回答问题，但这些现象人类语言使用者并不显著。这种新方法能更精确地评估不同语言模型对复杂结构的理解能力，而不仅仅是简单的语义模式匹配。这有助于改善未来的语言模型设计，减少它们在语义模式匹配上的依赖，更加注重结构理解能力的发展，提出了一个标准来评估模型在复杂句子处理方法上的表现差异。", "conclusion": "语义模式匹配并不总是优于结构分析，随着复杂度增加，模型之间的差距可能会加大。CenterBench 提供了一个新的基准，来衡量语言模型在面临复杂句子时如何从结构分析转移到依赖于语义模式匹配，为模型的设计提供了新见解。重要的是，像CenterBench这样的基准数据集可以帮助模型开发者训练出更倾向于基于结构理解的模型，而不是仅仅依赖于表面的语义匹配来提高解析效果。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20607", "html_url": "https://arxiv.org/abs/2510.20607", "title": "通用能量最小化组成的推理", "title_en": "Generalizable Reasoning through Compositional Energy Minimization", "authors": "Alexandru Oarga,Yilun Du", "background": "机器学习在推理任务中的泛化是一个关键挑战，因为在这些任务中，模型需要解决比训练中遇到的问题更为复杂的问题。现有方法通常以端到端的方式训练推理模型，直接将输入实例映射到解决方案上。尽管这种方式可以使模型从数据中学习有用的经验法则，但它往往导致模型在训练分布之外的泛化能力有限。", "innovation": "本文提出了一种通过在小型、更易于解决的子问题的解空间中学习能量景观来实现推理泛化的新型方法。测试时，通过结合多个子问题的能量函数来构建给定问题的全局能量景观。这一组合方法在推理时允许加入额外的约束，从而构建出更具挑战性的问题的能量景观。为了提高从新构建的能量景观中抽样的样本质量，本文引入了并行能量最小化（PEM）。", "conclusion": "我们的方法在一系列的推理问题上进行了评估，并在现有最先进的方法上表现出色，证明了其在面对更大、更复杂的问题时的泛化能力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20602", "html_url": "https://arxiv.org/abs/2510.20602", "title": "利用互易性 Resound 出声学场", "title_en": "Resounding Acoustic Fields with Reciprocity", "authors": "Zitong Lan,Yiduo Hao,Mingmin Zhao", "background": "在虚拟环境中实现沉浸式听觉体验需要灵活的声音建模，能够支持动态声源位置。目前缺乏一种能够从少量已测量声源位置估算任意声源位置的房间冲激响应的方法，类似于视觉中的重新照明问题。文章介绍了‘Resounding’任务，旨在通过利用少量已测量声源位置，估算任意声源位置的房间冲激响应。文章还探讨了互易性部署中面临的挑战，并提出了相应的解决方案", "innovation": "提出了一个新的任务‘Resounding’，旨在利用互易性和互易性物理启发的方法，即 Versa，用于声学场学习。Versa 方法通过交换声源和听者的姿态，创建了密集的虚拟声源位置，生成物理上有效的样本。文章还提出了一种自我监督学习方法，以应对由声源/听者增益模式带来的挑战。实验结果表明，Versa 显著改进了不同数据集和评估指标上声学场学习的性能，并提高了用户体验", "conclusion": "通过引入‘Resounding’任务和-inspired 的 Versa 方法，文章证明了可以利用互易性有效地估计任意位置的声源房间冲激响应，从而改进声学场学习的性能和用户对沉浸式空间声音体验的感知"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20610", "html_url": "https://arxiv.org/abs/2510.20610", "title": "BUSTED在AraGenEval共享任务中的表现：基于Transformer模型的阿拉伯语AI生成文本检测比较研究", "title_en": "BUSTED at AraGenEval Shared Task: A Comparative Study of Transformer-Based Models for Arabic AI-Generated Text Detection", "authors": "Ali Zain,Sareem Farooqui,Muhammad Rafi", "background": "本文探讨了在阿拉伯AI生成文本检测的Ara-GenEval共享任务中，使用预训练的Transformer模型进行比赛的情况。作者团队BUSTED在该任务中获得了第5名。", "innovation": "作者研究了三种预训练的Transformer模型——AraELECTRA、CAMeLBERT和XLM-RoBERTa，并将每个模型在给定的数据集上进行微调，用于二分类任务。研究发现，尽管专门针对阿拉伯语的模型，XLM-RoBERTa多语言模型取得了最佳表现，其F1分数达到了0.7701，超过了专门的阿拉伯语模型。这项工作强调了AI生成文本检测的复杂性，并指出多语言模型具有强大的泛化能力。", "conclusion": "这项工作表明，多语言模型在阿拉伯AI生成文本检测中具有优势，突出了其泛化能力的重要性，同时也展示了识别AI生成文本的挑战性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20612", "html_url": "https://arxiv.org/abs/2510.20612", "title": "黑箱吸收：大语言模型侵蚀创新思想", "title_en": "Black Box Absorption: LLMs Undermining Innovative Ideas", "authors": "Wenjun Cao", "background": "大语言模型被广泛用作加速创新的关键工具。然而，这些模型内部结构的不透明性带来了一个系统性风险，即黑箱吸收。这种现象是指大语言模型平台（通常由大型服务提供商运营）通过交互过程将用户贡献的新颖概念内化、泛化和重新利用，从而破坏了创新经济学的基础原则，加剧了个体创造者与平台运营商之间的信息和结构不对称，威胁到创新生态系统的长期可持续性。", "innovation": "文章提出了两个核心概念：‘想法单位’，代表可以转移的功能逻辑，以及‘想法安全性’，这是一个多维度的标准，用于保护想法的知识产权。文章进一步分析了吸收机制，并提出了具体的治理和工程议程，以减轻这些风险，确保创造性贡献可以保持可追溯、可控和公平。", "conclusion": "文章通过识别和正式化黑箱吸收这种系统性风险，提出了‘想法单位’和‘想法安全性’两个概念，分析了吸收机制，并提出了治理和工程议程，以保护创新，确保长期可持续性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20634", "html_url": "https://arxiv.org/abs/2510.20634", "title": "深度学习在牙科图像分析中的应用：数据集、方法和技术挑战的系统综述", "title_en": "Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges", "authors": "Zhenhuan Zhou,Jingbo Zhu,Yuchen Zhang,Xiaohang Guan,Peng Wang,Tao Li", "background": "牙科图像分析对于准确诊断和最佳治疗规划至关重要。然而，牙科成像固有地存在低对比度、金属伪影和投影角度变化等问题。结合临床医生专业知识差异带来的主观性，手动解释往往耗时且容易不一致。因此，基于人工智能（AI）的自动牙科图像分析（DIA）成为解决这些问题的一种有希望的解决方案。", "innovation": "本研究系统回顾了260篇关于深度学习（DL）在牙科图像分析中的应用的研究，包括49篇关于公开可用的牙科数据集的研究和211篇基于DL算法的研究。研究系统地介绍了DL的基本概念，总结了现有数据集的特点和获取方法。此外，还介绍了DL的基础技术，对相关模型和算法进行了分类，分析了网络架构、优化策略、训练方法和性能。深入总结了DIA领域中常用的训练和评估指标。", "conclusion": "本研究讨论了现有研究面临的主要挑战，并指出了未来的研究方向。希望本工作能够为该领域的研究人员提供有价值的系统参考，所有补充材料和详细的比较表将在GitHub上公开可用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20611", "html_url": "https://arxiv.org/abs/2510.20611", "title": "PSO-XAI: 基于PSO增强的可解释人工智能框架以实现可靠的乳腺癌检测", "title_en": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection", "authors": "Mirza Raquib,Niloy Das,Farida Siddiqi Prity,Arafath Al Fahim,Saydul Akbar Murad,Mohammad Amzad Hossain,MD Jiabul Hoque,Mohammad Ali Moni", "background": "乳腺癌是全球女性中最常见的恶性肿瘤之一，导致癌症相关死亡率上升。早期和准确的检测至关重要，因为这有助于减少潜在威胁并提高生存率。然而，传统诊断方法常因变量性、成本和误诊风险限制了其效果。为解决这些问题，机器学习（ML）作为一种强大的计算机辅助诊断工具崭露头角，特征选择在提高模型性能和可解释性方面发挥着重要作用。为此，本研究提出了一个综合框架，该框架结合了自定义的粒子群优化（PSO）进行特征选择。该框架在29种不同的模型上进行了评估，涵盖经典分类器、集成技术、神经网络、概率算法和基于实例的算法。为了确保临床相关性和可解释性，本文采用交叉验证结合可解释AI方法来实现这一点。实验结果显示，所提出的方法在所有性能指标中达到了99.1%的高得分，同时有效降低了维度并提供了透明、模型无关的解释。", "innovation": "研究提出了一种结合自定义粒子群优化（PSO）的综合框架，用于特征选择，以提高机器学习模型的性能和可解释性。该研究评估了该方法在29种不同模型上的效果，包括经典分类器、集成技术、神经网络、概率算法和基于实例的算法。通过使用交叉验证结合解释性AI方法，该研究确保了模型的可解释性和临床相关性。实验结果表明，该方法在所有性能指标中表现优异。", "conclusion": "研究结果强调了将群群智能与可解释的人工智能结合使用在乳腺癌诊断中的潜力，能够实现可靠的、可信的且具有临床意义的诊断。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20630", "html_url": "https://arxiv.org/abs/2510.20630", "title": "使用机器学习预测量子处理单元（QPU）处理时间", "title_en": "Quantum Processing Unit (QPU) processing time Prediction with Machine Learning", "authors": "Lucy Xing,Sanjay Vishwakarma,David Kremer,Francisco Martin-Fernandez,Ismael Faro,Juan Cruz-Benito", "background": "本文探讨了机器学习技术在预测量子作业的QPU处理时间中的应用。通过利用机器学习算法，研究引入了旨在增强量子计算系统操作效率的预测模型。使用包含约150,000个作业的IBM Quantum数据集，研究采用基于梯度提升（LightGBM）的机器学习方法来预测QPU处理时间，并通过数据预处理方法提高模型精度。结果表明，机器学习在预测量子作业方面是有效的，这将有助于改进量子计算框架中的资源管理和调度。", "innovation": "通过使用基于梯度提升（LightGBM）的机器学习方法，并结合数据预处理方法，提高了预测QPU处理时间的准确性。这不仅强调了机器学习在细化量子作业预测中的潜力，还为集成人工智能驱动工具到先进的量子计算操作中奠定了基础。", "conclusion": "研究发现，机器学习可以有效地预测量子作业的QPU处理时间，这对于提高量子计算系统的资源管理和调度有重要意义。这标志着在量子计算框架中引入基于人工智能工具的可能性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20629", "html_url": "https://arxiv.org/abs/2510.20629", "title": "公平生存预测：一种Fairness-Aware生存建模（FASM）方法", "title_en": "Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach", "authors": "Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu", "background": "随着机器学习模型在医疗领域的应用越来越广泛，临床数据中固有的结构性不平等和社会偏见可能会通过数据驱动的模型被延续甚至放大。在生存分析中，截尾和时间动态会增加公平模型开发的复杂性。同时，现有的算法公平性方法往往忽视了跨群体排名中的差异，比如高风险的黑人患者可能会被排名低于低风险但未经历死亡事件的白人患者。这种错误的排名可能会强化生物本质主义，损害公平医疗服务。这部分背景强调了在生存分析中考虑公平性的重要性，并指出现有方法的局限性，为研究提供了理由和背景.", "innovation": "我们提出了Fairness-Aware Survival Modeling（FASM），它旨在减轻关于相同群体内部和跨群体风险排名中的算法偏见。我们以乳腺癌预后为例，在SEER乳腺癌数据上应用FASM，结果显示，在提高公平性的同时，FASM的区分性能与未考虑公平性的生存模型相当。时间分层评估表明，FASM在10年预测期内表现出稳定公平性，特别是在随访中期的改善最为显著。这项研究的创新在于提出了一种能兼顾准确性和公平性的生存模型方法，推动公平性成为临床护理的核心原则，这是其对现有方法的改进之处.", "conclusion": "我们的方法使生存模型的开发能够同时注重准确性和公平性，在临床决策中优先考虑这两方面。这种公平性优先的方法在临床护理中具有重要意义，提高了医疗决策的质量和公正性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20647", "html_url": "https://arxiv.org/abs/2510.20647", "title": "情景语言: 多语言AI的双刃剑", "title_en": "The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI", "authors": "Alan Saji,Raj Dabre,Anoop Kunchukuttan,Ratish Puduppully", "background": "大型推理模型（LRMs）在数学、科学和其他问答任务中表现强大，但在多语言推理能力方面尚未得到充分探索。当面对非英语问题时，LRMs往往倾向于用英语进行推理，这引发了对其解释性和处理语言和文化细微差异能力的担忧。", "innovation": "该研究系统性地比较了LRMs在英语与问题语言之间的推理差异，并通过MGSM和GPQA Diamond两个任务进行评估。研究不仅测量了答案的准确性，还分析了推理过程中的认知属性。研究发现英语推理痕迹中表现出的认知行为明显更多，用英语推理通常能获得更高的最终答案精度，但这一以英语为中心的策略在复杂任务中更容易出现“翻译迷失”这一关键问题，导致错误。", "conclusion": "通过分析证明，多语言AI在处理非英语问题时，使用英语推理存在一些优势，但也面临语言翻译带来的挑战。研究表明，非英语语言的推理可能更为精确，有助于避免翻译过程中出现的错误，但这一策略需要进一步细化以解决复杂问题中的挑战。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20635", "html_url": "https://arxiv.org/abs/2510.20635", "title": "为什么苹果会掉落地面：评估大型语言模型的求知欲", "title_en": "Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language Model", "authors": "Haoyu Wang,Sihang Jiang,Yuyan Chen,Yitong Wang,Yanghua Xiao", "background": "大型语言模型（LLMs）在自然语言处理方面取得了显著进展，引起人们探讨这些模型是否具备类似人类的好奇心驱动学习能力。基于人类好奇心评估问卷修订版五维好奇心量表（5DCR），本文设计了一套全面评估框架，涵盖信息寻求、探险寻求和社会好奇心等维度，以评估LLMs的好奇心程度。实验结果显示，尽管LLMs对知识有更强的渴求，但在面对不确定性环境时倾向于保守选择。进一步探究发现，好奇心可以增强模型的推理和主动学习能力，表明LLMs有可能展现出类似于人类的好奇心，为未来LLMs的学习能力和创新研究提供实验支持。", "innovation": "本文从人类好奇心评估问卷修订版五维好奇心量表（5DCR）出发，设计了一个全面的评估框架，涵盖了信息寻求、探险寻求和社会好奇心等维度，以此评估LLMs的好奇心程度。该框架对当前评估模型好奇心的方法进行了创新，由此可以更精确地评估LLMs在学习过程中的好奇心表现。进一步地，研究确认了好奇行为可以增强模型的推理和主动学习能力，这一发现也为未来LLMs的发展提供了重要参考。", "conclusion": "实验结果表明，尽管LLMs对知识具有强烈的渴求，但在面对不确定性环境时倾向于保守选择。好奇心可以增强模型的推理和主动学习能力。该研究提供了关于LLMs可能像人类那样表现出好奇心的证据，这将为未来LLMs的学习能力的发展和创新型研究提供实验支持。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20671", "html_url": "https://arxiv.org/abs/2510.20671", "title": "GRACE: 基于图的成瘾治疗预测", "title_en": "GRACE: GRaph-based Addiction Care prEdiction", "authors": "Subham Kumar,Prakrithi Shivaprakash,Koustav Rudra,Lekhansh Shukla,Animesh Mukherjee", "background": "确定成瘾患者的适当治疗地点是临床决策中最关键的一环，直接影响患者治疗效果和资源的有效利用。由于缺乏足够的专业治疗资源，如住院床位或工作人员，迫切需要开发自动化框架来解决这一问题。当前的决策方法在成瘾数据集中存在严重的类别不平衡问题。", "innovation": "我们提出了一种新颖的图神经网络（GRACE）框架，将治疗地点预测形式化为结构化学习问题。此外，我们进行了广泛的功能工程，并提出了一种获得无偏图的新方法，用于训练GNN以克服类别不平衡问题。实验结果显示，在实际数据中，与竞标基准相比，少数类的F1分数提高了11-35%。", "conclusion": "实验结果表明GRACE框架在处理实际数据时，相较于其他可竞争的基线模型，能够显著提高少数类的F1分数。该代码和笔记嵌入可在以下链接获取：this https URL。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20653", "html_url": "https://arxiv.org/abs/2510.20653", "title": "寻找折中点：推理时L大型语言模型反思中的质量、成本和速度权衡", "title_en": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During Inference-Time LLM Reflection", "authors": "Jack Butler,Nikita Kozodoi,Zainab Afolabi,Brian Tyacke,Gaiar Baimuratov", "background": "随着大型语言模型（LLMs）不断发展，研究者和从业者面临着在不重新训练模型的情况下提高推理时性能的选择，比如预算调整和自我反思等多步技术。虽然这些方法提升了输出质量，但它们在准确率、成本和延迟间的复杂权衡关系尚未得到妥善理解，尤其是在不同领域。本文系统性地比较了自我反思和预算调整在数学推理和翻译任务中的应用效果，评估了包括Anthropic Claude、Amazon Nova、Mistral在内的多个模型及其性能边界。", "innovation": "本文首次系统性地比较了自我反思和预算调整技术在数学推理和翻译任务中的应用效果，通过多样化的计算预算和反思深度评估这些技术在不同模型家族中的影响。研究发现自我反思在不同领域的有效性存在显著差异，在数学推理方面的表现提升最高可达220%。进一步探讨了反思轮次深度和反馈机制质量如何影响模型绩效。此外，本文通过将自我反思技术应用于实际场景中的营销内容本地化系统，验证了自我反思技术在不同市场上的具体应用效果，强调了领域特定评估的重要性。", "conclusion": "研究结果为特定领域和资源约束条件下选择最优推理策略提供了实际指导。本文还开源了自我反思实现代码以确保研究的可重复性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20699", "html_url": "https://arxiv.org/abs/2510.20699", "title": "金融叙事语义融合在金融波动率预测中的应用", "title_en": "Fusing Narrative Semantics for Financial Volatility Forecasting", "authors": "Yaxuan Kong,Yoontae Hwang,Marcus Kaiser,Chris Vryonides,Roel Oomen,Stefan Zohren", "background": "近年来，金融市场波动率的预测成为风险管理的重要问题。传统的预测方法多依赖于时间序列数据，但难以整合非结构化的新闻数据，导致预测效果有限。该研究旨在通过多模态波动率网络（M2VN）提出一种基于深度学习的新框架，能够整合时间序列特征和非结构化新闻数据，解决数据异构性和前瞻偏差的问题。", "innovation": "M2VN框架利用深度神经网络的强大表示能力，解决两个关键问题：一是异构数据模态的对齐和融合，二是缓解前瞻性偏差，提高金融模型的准确性。具体而言，M2VN结合了开源市场特征和由Time Machine GPT生成的新闻嵌入，确保时间一致性。此外，引入了辅助对齐损失以增强结构化和非结构化数据在深度学习架构中的整合。", "conclusion": "通过大量实验，M2VN在波动率预测方面稳定地优于现有基线模型，凸显了其在风险管理及金融市场决策中的实用价值。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20609", "html_url": "https://arxiv.org/abs/2510.20609", "title": "大规模实用代码RAG：在计算预算下的任务感知检索设计选择", "title_en": "Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets", "authors": "Timur Galimzyanov,Olga Kolomyttseva,Egor Bogomolov", "background": "本文研究在实际计算预算下，针对代码生成任务的检索设计。通过比较代码补全和错误定位两个任务，系统地探讨了不同上下文窗口大小、切片策略、相似性评分方法对检索配置的影响。研究最终提出了基于任务需求、模型限制和计算效率的实用代码RAG系统实施建议。", "innovation": "本文创新性地识别了不同编程语言之间以及自然语言与编程语言之间的检索配置差异性。详细说明了在不同计算预算下使用不同检索技术的效果，提供了高效的切片策略和相似性评分方法，特别强调了BM25和基于单词的切片方法在节省计算资源方面的优势，同时在检索延迟与检索质量之间取得了良好的平衡。", "conclusion": "该研究建议，对于编程语言对编程语言的检索，稀疏BM25和基于单词的切片是最有效的；对于自然语言对编程语言的检索，专有密集编码器表现更好，但延迟大大增加；最佳切片大小与可用上下文大小相关，大预算下可以进行全文检索；简单的基于行的切片与预算无关地匹配语法感知的切割。研究表明检索延迟可相差200倍，基于子词的分割会过慢，而BM25加基于单词分割提供的质量和延迟最佳折中。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20706", "html_url": "https://arxiv.org/abs/2510.20706", "title": "使用模型预测控制和强化学习实现四足机器人实时步态适应", "title_en": "Real-Time Gait Adaptation for Quadrupeds using Model Predictive Control and Reinforcement Learning", "authors": "Ganga Nair B,Prakrut Kotecha,Shishir Kolathaya", "background": "模型驱动的强化学习使四足机器人能够实现适应性和敏捷性，但在实际操作中，这些模型常常会收敛到一种步态，导致性能不佳。传统上，模型预测控制（MPC）被用来获得任务特定的最优策略，尽管这两种方法都能取得一定的效果，但也存在环境适应性差的问题。", "innovation": "本文提出了一种结合模型预测路径积分（MPPI）算法和Dreamer模块的优化框架，实现了实时步态适应。该框架能够在连续的步态空间中自适应生成最优和适应性强的策略，通过学习到的奖励机制优化动作和步态变量，促进速度跟踪、能量效率、稳定性和平滑过渡，同时防止突然的步态变化。", "conclusion": "实验在Unitree Go1上验证了该框架，结果显示通过不同目标速度下的能耗平均降低了36.48%，同时保持了准确的跟踪和适应性任务适用的步态。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20692", "html_url": "https://arxiv.org/abs/2510.20692", "title": "探索大型语言模型在访问控制策略合成与总结中的应用", "title_en": "Exploring Large Language Models for Access Control Policy Synthesis and Summarization", "authors": "Adarsh Vatsa,Bethel Hall,William Eiers", "background": "云计算无处不在，每天都有越来越多的服务部署在云端。典型的云计算系统允许管理员编写访问控制策略，以规定对私有数据的访问规则。这些策略需要手动编写，由于其复杂性，可能会出现错误。现有的策略往往包含复杂的访问控制规范，这使得精确分析它们的行为是否符合预期变得困难。近年来，大型语言模型（LLMs）在自动化代码合成和总结方面取得了巨大的成功。鉴于这些成功，它们可能被用于自动生成访问控制策略或帮助理解现有策略。", "innovation": "此研究探索了LLMs在访问控制策略合成和总结中的有效性。通过研究各种LLMs进行访问控制策略合成，发现虽然LLMs可以有效生成语法正确的策略，但会产生宽松性问题。对于非推理LLMs来说，生成的策略与给定规范等价的情况占45.8%，而对于推理LLMs来说，这一比例高达93.7%。此外，研究还通过引入一种基于语义的请求总结方法，利用LLMs生成策略允许的请求的精确描述。结果表明，在利用LLMs进行自动策略生成存在显著障碍的情况下，结合符号方法可以显著提高现有策略分析的效果。", "conclusion": "此研究揭示了通过LLMs增强访问控制策略分析的潜力，尽管在自动策略生成方面存在挑战，但LLMs在结合符号方法时显示出有希望的结果。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20690", "html_url": "https://arxiv.org/abs/2510.20690", "title": "神经多样性在小型模型中规制幻觉", "title_en": "Neural Diversity Regularizes Hallucinations in Small Models", "authors": "Kushal Chakrabarti,Nirmal Balachundhar", "background": "语言模型在参数、计算能力和数据量增加的情况下仍然会产生幻觉。研究指出，尽管这些因素在不断提升，但幻觉问题仍未得到有效解决。本文探讨了神经多样性（decorrelated parallel representations）作为一种原理性的机制，能够在固定参数和数据预算下降低幻觉率。作者借鉴组合投资理论的概念，即不相关资产通过减少风险来提高收益，推导出幻觉概率与表示的相关性之间的关系，并预测了神经多样性的最优水平。通过实验验证，证明了这一理论的有效性，并揭示了神经多样性在提高模型可靠性方面的关键作用。", "innovation": "本文提出了神经多样性（Neural Diversity）的概念，即通过去相关的并行表示来减少幻觉率，为固定参数和数据预算下的语言模型提供了一种新的优化方案。作者通过设计ND-LoRA（Neural Diversity Low-Rank Adaptation）方法，结合LoRA适配器和Barlow Twins正则化技术，有效地降低了幻觉现象，同时保持了模型的通用准确性。此外，通过实验证明了LoRA适配器与正则化之间的协同作用，因果干预表明神经多样性是中介因素，并且相关性分析发现规模效应，即神经相关性增加会导致幻觉概率明显上升。最后，作者发现不同任务需要不同程度的神经多样性，进一步强调了神经多样性作为一种独立于参数和数据的扩展轴的重要性，以提高固定预算下语言模型的可靠性。", "conclusion": "本文通过理论推导和实验证明了神经多样性在减少语言模型幻觉方面的有效性，并且不同任务需要不同量的神经多样性。研究表明，神经多样性成为了固定预算下提高语言模型可靠性的一种新维度，它是参数和数据之外的第三个扩展轴。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20677", "html_url": "https://arxiv.org/abs/2510.20677", "title": "R2-SVC：朝着现实世界的稳健且具表现力的零样本声乐语音转换", "title_en": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice Conversion", "authors": "Junjie Zheng,Gongyu Chen,Chaofan Ding,Zihao Chen", "background": "在实际声乐语音转换（SVC）应用中，环境噪音和对表现性输出的需求构成了重大挑战。传统方法通常没有考虑到实际部署场景，因为训练和推理通常依赖于干净的数据。这种不匹配限制了实际应用，因为在实际应用中不可避免地存在多种噪声源和音乐分离的缺陷。为了解决这些问题，我们提出了一种名为R2-SVC的稳健且具表现力的SVC框架。首先，我们通过随机基频（$F_0$）扰动和音乐分离缺陷模拟（例如回声、混响）增强了模型的鲁棒性，显著提高了在嘈杂条件下的表现。其次，我们使用领域特定的声乐数据丰富了演讲者表示：除了清唱声部外，我们还使用DNSMOS滤波分离声部和公开的声乐语料库，使模型能够保持演讲者的音色，同时捕捉声乐风格的细微差别。第三，我们结合了神经声源-滤波器（NSF）模型，显式地表示谐波和噪声成分，增强了转换声乐的自然性和可控性。R2-SVC在多种SVC基准测试中均取得了最好的结果，无论是干净条件还是嘈杂条件下都是如此。", "innovation": "R2-SVC框架引入了基于模拟的鲁棒性增强，包括随机基频扰动和音乐分离缺陷模拟；利用领域特定的声乐数据丰富了演讲者表示；结合了神经声源-滤波器（NSF）模型，增强了模型在嘈杂条件下的性能和自然性。", "conclusion": "R2-SVC框架在多种SVC基准测试中达到了最先进的性能，无论是在干净条件下还是在嘈杂条件下。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20718", "html_url": "https://arxiv.org/abs/2510.20718", "title": "利用N-BEATS和图神经网络进行多变量半导体工艺时间序列的无监督异常预测", "title_en": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series", "authors": "Daniel Sorensen,Bappaditya Dey,Minjin Hwang,Sandip Halder", "background": "半导体制造是一个极复杂且高度精密的过程，涉及成千上万个相互依赖的参数，分布在多种工具和工序步骤中。这种环境中需要实时监控和故障检测，多变量时间序列分析因此成为关键领域。但半导体制造的异常预测面临高维度传感器数据和严重类别不平衡等挑战，这主要是由于真正故障的稀少性。复杂的变量间相互依赖关系也增加了异常预测和根本原因分析的难度。", "innovation": "本文提出两种新型方法，将异常检测推进到异常预测，这是实现实时过程校正和主动故障预防的重要步骤。提出的异常预测框架包括两个阶段：(a) 在假定无异常的数据集上训练预测模型，(b) 对未见时间序列数据进行预测，并将其与训练信号的预测进行比较，超出预定义阈值的偏差视为异常。两种方法使用不同的预测模型，第一种方法假设变量间独立，并使用N-BEATS模型进行单变量时间序列预测。第二种方法则利用图神经网络（GNN）捕捉变量间的相互关系。实验结果表明，尽管GNN训练参数更少、计算成本更低，但在20个时间点内的预测性能优于N-BEATS模型，并且在50个时间点内的异常预测保持稳定。GNN在在线异常预测中的应用前景广阔，适合部署在制造环境中。", "conclusion": "本文提出的两阶段框架，特别是使用图神经网络的方法，在多变量半导体工艺时间序列的无监督异常预测中表现出色，适用于实际制造环境中的实时预警和故障预防。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20683", "html_url": "https://arxiv.org/abs/2510.20683", "title": "基于脉冲神经网络的可扩展、因果和节能神经解码框架", "title_en": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks", "authors": "Georgios Mentzelopoulos,Ioannis Asmanis,Konrad P. Kording,Eva L. Dyer,Kostas Daniilidis,Flavia Vitale", "background": "脑-计算机接口（BCIs）旨在为神经运动损伤的个体提供关键功能，如言语和假肢控制。这些接口的成功关键在于神经解码器，即能够将神经活动映射到预期行为的模型。现有的基于学习的解码方法可分为两类：一类是对因果关系不敏感的简单模型，在推广方面表现不足；另一类是非因果模型，虽然具备推广和离线训练的能力，但在实时应用中却表现欠佳。这些方法共同面临的问题是，它们依赖于消耗大量电力的人工神经网络骨架，这使得这些系统难以集成到资源受限的现实世界系统中。脉冲神经网络（SNNs）提供了有前景的替代方案。因为SNNs是因果模型，使其适合用于实时应用，并且它们的低能耗特性使它们成为电池供电环境的理想选择。", "innovation": "我们提出了Spikachu：一种基于SNNs的可扩展、因果且节能的神经解码框架。该方法直接处理分桶后的脉冲，并将其投射到共享的潜空间，在此空间中，适应输入时间的脉冲模块提取相关特征；然后将这些潜空间表示整合和解码生成行为预测。我们通过在6只非人类灵长类动物的113个记录会话中，总共43小时的记录数据上评估了该方法，并证明了当使用单次会话训练时，与因果基准相比，本方法能耗减少2.26至418.81倍，并且通过扩充训练到多个会话和受试者以及实现对未见过会话、受试者和任务的少量样本迁移，进一步提升了性能。总的来说，Spikachu提供了一种基于SNNs的可扩展、实时兼容的神经解码框架，其性能与最先进的模型相比具有竞争力，同时消耗的能源量级远少于这些模型。", "conclusion": "本研究引入了一种基于SNNs的可扩展、实时兼容的神经解码框架Spikachu，该框架在性能上可与最先进的模型竞争，同时消耗的能源远远少于这些模型。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20727", "html_url": "https://arxiv.org/abs/2510.20727", "title": "使用自然语言处理从临床笔记中自动提取氟尿嘧啶治疗及其相关毒性", "title_en": "Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing", "authors": "Xizhi Wu,Madeline S. Kreider,Philip E. Empey,Chenyu Li,Yanshan Wang", "background": "氟尿嘧啶（氟尿嘧啶类）药物常用于治疗结直肠癌和乳腺癌，但这些药物可能导致手足综合症等毒副作用。现有毒副作用信息通常嵌入在临床笔记中，为此研究开发并评估了自然语言处理方法以提取治疗和毒副作用信息。", "innovation": "研究通过构建包含来自204,165名成年癌症患者的236份临床笔记的标准数据集，开发了基于规则、机器学习和深度学习的NLP方法，并使用零样本（zero-shot）和错误分析提示（error-analysis prompting）进行测试。研究发现，大型语言模型（LLM）方法表现最佳，其他机器学习方法次之。该研究强调了LLM在从临床笔记中提取氟尿嘧啶治疗及毒性信息方面的有效性和潜力。", "conclusion": "基于大规模语言模型的NLP方法最有效地从临床笔记中提取了氟尿嘧啶治疗和毒性信息，并具有支持肿瘤学研究和药物警戒的潜力。尽管机器学习和深度学习方法表现良好，但它们受限于训练数据量小，且在处理稀有类别时表现出有限的泛化能力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20721", "html_url": "https://arxiv.org/abs/2510.20721", "title": "用户在隐私敏感场景中对大语言模型响应的隐私和帮助感知", "title_en": "User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios", "authors": "Xiaoyuan Wu,Roshni Kaushik,Wenkai Li,Lujo Bauer,Koichi Onoue", "background": "大语言模型在撰写邮件、总结会议和回答健康问题等任务中得到了快速应用，但在这些使用场景中，用户可能需要分享私人信息（如健康记录、联系方式）。为了评估大语言模型识别并屏蔽私人信息的能力，先前的研究开发了基准测试（如ConfAIde、PrivacyLens等），这些基准测试基于现实情景。然而，当前的研究主要依赖代理大语言模型来评估合规性，而忽视了实际用户的看法。现有的工作主要关注大语言模型回应的隐私保护质量，但没有探索帮助程度上的细微差异。鉴于此，作者通过一项用户研究来理解用户对大语言模型回答隐私敏感场景的隐私保护质量和帮助程度的看法差异。该研究使用了94名参与者和来自PrivacyLens的90个场景。", "innovation": "这项研究首次通过真实用户实验来评估大语言模型在隐私敏感场景中的隐私保护质量和帮助程度，发现了用户之间的高度不同意见，而代理大语言模型在评估一致性和用户评价之间的相关性上效果较差。这些发现表明，大语言模型在隐私和帮助方面的影响往往因人而异，代理大语言模型可能并不是评估用户实际感知的最佳工具。因此，未来研究可能需要探索改进代理大语言模型与用户之间对齐的方式，以更好地估计用户的隐私感知和实用性。", "conclusion": "研究结果表明，大语言模型在隐私敏感场景中的隐私和帮助程度往往具有个体差异，代理大语言模型不具备准确估计用户感知的能力。因此，未来需要进行用户中心的研究来评估大语言模型帮助用户并保持隐私的能力。此外，还可以进一步研究如何使代理大语言模型与用户的期望更一致，以提高对其感知隐私和有用的估计准确度。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20748", "html_url": "https://arxiv.org/abs/2510.20748", "title": "强化学习与消费储蓄行为", "title_en": "Reinforcement Learning and Consumption-Savings Behavior", "authors": "Brandon Kaplowitz", "background": "本文探讨了强化学习如何解释经济衰退期间家庭消费行为中的两个令人费解的现象。", "innovation": "作者通过开发一个基于Q学习和神经网络近似的新模型，解释了在收入不确定性情况下消费和储蓄决策。该模型从标准理性预期假设中区分出来，能够复现近期文献中的两个关键发现：失业家庭在具有低流动性资产时对刺激转移的边际消费倾向（MPCs）远高于高资产家庭（0.50比0.34），即使两组均无借款约束；还有，具有更多失业历史的家庭在控制当前经济状况后持续维持较低的消费水平，“伤痕效应”已在Malmendier和Shen（2024）的研究中得到验证。不同于基于对未来收入风险信念更新或先验异质性的现有解释，该强化学习机制通过随经验变化的价值函数近似错误同时产生较高的MPCs和较低的消费水平。", "conclusion": "模拟结果表明，通过强化学习进行的自适应学习提供了一个统一框架，能够解释过去经验如何塑造当前的消费行为，这一框架超越了当前经济条件所能预测的范围。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20743", "html_url": "https://arxiv.org/abs/2510.20743", "title": "Empathic Prompting: 非言语上下文整合以增强多模态LLM对话", "title_en": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations", "authors": "Lorenzo Stacchio,Andrea Ubaldi,Alessandro Galdelli,Maurizio Mauri,Emanuele Frontoni,Andrea Gaggioli", "background": "介绍了新的Empathic Prompting框架，该框架通过引入蕴含的非言语上下文丰富大规模语言模型（LLM）对话内容。系统利用商业面部表情识别服务捕捉用户的情绪线索，并作为提示期间的背景信号进行嵌入，无需用户显式控制。这不仅需要与文本输入进行情感信息增强，还使得对话更加连贯和自然，体现了用户体验的提升。言语交流之中的用户情感信号在诸如医疗保健或教育等重要领域至关重要，但在语言交流中却往往难以察觉。", "innovation": "提出了Empathic Prompting框架，通过利用面部表情识别服务捕捉用户的情感线索，隐式地丰富LLM对话。与传统的多模态用户界面不同，Empathic Prompting无需用户干预，而是自然地将情感信息嵌入提示中的文本内容，增强了对话的连贯性和自然度。该架构模块化且可扩展，支持额外非言语模块的集成", "conclusion": "Empathic Prompting证明了非言语输入能够被一致地整合进LLM的输出中，用户评价显示对话的流利度提升。该方法在未来可能应用于由聊天机器人介导的沟通领域，特别是在医疗或教育等关键领域，这些领域中用户的非言语信号对于提供高质量的服务至关重要。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20768", "html_url": "https://arxiv.org/abs/2510.20768", "title": "RAGRank: 使用PageRank应对CTI LLM管道中的投毒攻击", "title_en": "RAGRank: Using PageRank to Counter Poisoning in CTI LLM Pipelines", "authors": "Austin Jia,Avaneesh Ramesh,Zain Shamsi,Daniel Zhang,Alex Liu", "background": "RAG架构被广泛用于将大规模语言模型（LLM）应用于网络威胁情报（CTI）系统中。然而，这种设计容易受到投毒攻击的影响，此前提出的防御措施在CTI上下文中可能无效，因为网络威胁信息往往是全新的，而且高级威胁行为者可以模仿合法的格式、术语和风格惯例。因此，需要一种新的方法来提高RAG防御的鲁棒性，特别是在CTI的上下文中。", "innovation": "本文提出了通过在语料库上应用来源可信度算法，使用PageRank作为示例，以加速现代RAG防御的鲁棒性。实验结果表明，该算法能降低恶意文档的权威分值，同时提升可信内容的权威分值。该算法在标准化的MS MARCO数据集中以及CTI文档和数据流中展示了概念验证性能。", "conclusion": "通过将来源可信度算法应用于语料库，特别是使用PageRank作为示例，可以有效提高RAG在应对CTI中的投毒攻击的鲁棒性。该研究通过实验证明，这种方法在提升可信内容的同时降低了恶意文档的影响力，在CTI数据流中展示了良好的防御性能。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20774", "html_url": "https://arxiv.org/abs/2510.20774", "title": "FieldGen: 从遥操作预操作轨迹到场向导数据生成", "title_en": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation", "authors": "Wenhao Wang,Kehe Ye,Xinyu Zhou,Tianxing Chen,Cao Min,Qiaoming Zhu,Xiaokang Yang,Yongjian Shen,Yang Yang,Maoqing Yao,Yao Mu", "background": "大型和多样化的数据集对于训练稳健的机器人操作策略至关重要，但现有的数据收集方法难以在规模、多样性和质量之间找到平衡。模拟可以提供可扩展性，但存在模拟到现实的差距，而遥操作可以产生高质量的演示，但由于多样性有限和劳动力成本高昂，其应用受到限制。因此，需要一种既能产生大规模多样化数据，又能保持高质量，同时减少人工监督的方法。", "innovation": "FieldGen 提出了一种场向导数据生成框架，通过将操作分解为预操作阶段和精细操作阶段，结合人体演示和自动轨迹生成，实现了在最少的人类监督下进行大规模、多样化的高质量真实数据收集。此外，FieldGen 使用的奖励增强功能进一步增强了策略学习的效果。实验表明，使用 FieldGen 训练的策略在成功率和稳定性方面优于基于遥操作的基线，并显著减少了长期真实数据收集所需的人类努力。", "conclusion": "FieldGen 通过场向导数据生成框架，实现了在最少人类监督下的大规模、多样性和高质量真实数据收集，显著提升了机器人操作策略的学习效果，相比基于遥操作的方法，不仅提高了策略的成功率和稳定性，还大大减少了人力资源的需求。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20782", "html_url": "https://arxiv.org/abs/2510.20782", "title": "针对LLM生成文本负责表现维度的特定使用案例数据集", "title_en": "A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text", "authors": "Alicia Sagae,Chia-Jung Lee,Sandeep Avula,Brandon Dang,Vanessa Murdock", "background": "当前评估大型语言模型（LLMs）的方法主要关注如文本生成等高层次任务，缺乏针对特定AI应用的具体评价手段。对于负责AI维度（如公平性）的评估而言，这种方法并不合适，因为不同应用中相关的保护属性差异显著，无法通用评价。", "innovation": "本文构建了一个以真实世界应用为基础的数据集（给定产品特性列表生成文本描述），并通过公平性属性与性别化形容词及产品类别交叉，获得了丰富的标注提示集。利用该数据集评测LLMs在质量、真实性、安全性和公平性方面的不足，并提出LLMs评价方案并附带实际资源，为研究社区提供支持。", "conclusion": "通过重点评估特定使用案例的公平性问题，提出了新型LLMs评测方法，为进一步研究提供具体资源，推动LLMs在负责AI表现方面的改进。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20728", "html_url": "https://arxiv.org/abs/2510.20728", "title": "基于多智能体系统的平移对角门量子编码联合设计", "title_en": "Co-Designing Quantum Codes with Transversal Diagonal Gates via Multi-Agent Systems", "authors": "Xi He,Sirui Lu,Bei Zeng", "background": "本文介绍了一种基于多智能体系统的联合设计量子编码的工作流，该系统包括指定平移对角门的量子码的共同设计。这项工作依赖于先前的Subset-Sum线性规划（SSLP）框架，该框架通过循环残差对基础字符串进行分区，并通过小的线性规划方程强制实施Z-边缘的Knill-Laflamme等量性。工作流被GPT-5驱动，运行在TeXRA平台上，这是一种支持迭代工具使用循环代理和归纳推理编辑代理的多智能体研究助理平台。", "innovation": "该工作提出了一种新型的工作流，可以在多智能体系统中实现量子编码的联合设计，并且能够针对特定的平移对角门进行优化设计。该工作流利用了GPT-5和TeXRA平台的特性，通过LaTeX-Python环境实现智能体间的协作与同步工作。该框架在执行大规模的系统性枚举与精确的分析重构相结合的分析管道时，能够生成可重复的量子码构造，并支持更广泛的设计参数范围内的扩展。特别地，它展示了如何通过新的线性规划方程处理循环残差的可退化性问题，从而扩大了基本构建块的种类。", "conclusion": "该工作提出了一种可扩展的工作流，通过多智能体系统执行大规模的系统性枚举和准确的分析重构，实现了可用于平移对角门的量子码的联合设计。该方法不仅能生成满足所有参数的平移对角量子码，而且还展示了如何处理循环残差的可退化性，证明了其有效性和通用性。通过该工作流，可以生成可重复的量子码构造，支持更大规模的设计扩展，并逐步推动数据驱动的分类方法的发展。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20780", "html_url": "https://arxiv.org/abs/2510.20780", "title": "大型推理模型适合作为翻译评估者吗？分析与性能提升", "title_en": "Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost", "authors": "Runzhe Zhan,Zhihong Huang,Xinyi Yang,Lidia S. Chao,Min Yang,Derek F. Wong", "background": "大型推理模型（LRMs）的最新进展引入了在生成最终答案之前的中间“思考”过程，这提升了它们在复杂下游任务上的推理能力。然而，LRMs作为机器翻译（MT）质量评估器的潜力仍未得到充分探索。本研究旨在系统分析LRMs作为MT评估者的应用，并揭示了其关键挑战，包括需要定制化的评估材料、倾向于对简单实例进行过度思考及评分机制不恰当导致评估结果的高估等问题。", "innovation": "提出了一种通过训练LRMs进入合成的人类风格的思考轨迹来校准其推理过程的方法，从而大大减少了推理资源的消耗（约减少35倍），同时提高了不同规模LRMs（7B到32B）的评估性能。例如，R1-Distill-Qwen-7B改进了8.7个相关性分数点。这些发现表明，高效校准后的LRMs有潜力推动详细的自动MT评估的发展。", "conclusion": "这项研究强调了校准后的LRMs在精细自动MT评估中的潜在价值。实验结果表明通过定制评估材料和改进评分机制可以显著提升评估性能，这为未来研究提供了新的方向。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20733", "html_url": "https://arxiv.org/abs/2510.20733", "title": "多智能体合作中的思维交流", "title_en": "Thought Communication in Multiagent Collaboration", "authors": "Yujia Zheng,Zhuokai Zhao,Zijian Li,Yaqi Xie,Mingze Gao,Lizhu Zhang,Kun Zhang", "background": "自然语言自古以来促进了人类的合作，但由于其耗散性、歧义性和间接性，限制了集体智能的潜力。尽管机器不受这些限制，且大多数基于LLM的多智能体系统仍依赖于自然语言进行交流，通过交换标记或其嵌入，但这些系统无法克服语言本身带来的局限性。为超越语言的限制，本文引入了一种新的范式——思维交流，使智能体能够实现直接的思维间交流，类似于心灵感应。论文通过普适的潜在变量模型形式化了这一过程，假设智能体状态是潜在思维未知函数的结果。研究证明，在没有辅助信息的非参数设置下，无论代理对之间是共享还是私人的潜在思维都可以被识别。进一步研究还证明，可以通过理论保证恢复思维共享的全局结构，包括哪些智能体共享哪些思维，以及这些关系如何被组织。这些理论成果指导我们开发了一个框架，其中在通信前，从所有智能体中提取潜在思维，并将相关信息及共享模式分配给各个智能体。此范式自然适用于所有模态，因为大多数观察数据源自隐藏的生成过程。合成数据和现实世界基准的实验在理论上验证了思维交流的优势，同时还展示了思维交流在合作中的潜力。这一工作揭示了利用隐藏世界的潜力，因为在表面级观察完全无法解决许多问题的情况下，其潜力仍然巨大，无论是在计算量还是数据规模方面。", "innovation": "提出了思维交流这一新的范式，使智能体能够实现直接的思维间交流，类似于心灵感应，作为实现多智能体系统通信的一种新策略。通过普适的潜在变量模型形式化思维交流的过程，并证明在无辅助信息的非参数设置下，可以从智能体状态中识别共享和私有的潜在思维。即使在没有额外信息的情况下，也能够揭示潜在思维共享的全局结构。所提出的方法不仅适用于基于LLM的多智能体系统，还可以轻松扩展到其他模态。实验结果验证了理论预期，并展示了思维交流在合作中的优势。", "conclusion": "思维交流这一理论揭示了利用隐藏世界的潜力，目的在于超越基于自然语言的人机交流范式，通过直接的思维间交流实现更高效的多智能体系统合作。此外，本文提出的方法不仅能够识别智能体之间共享和私有的潜在思维，而且可以恢复潜在思维共享的全局结构。未来将研究如何将此模型应用于现实世界中的各种场景，包括但不限于教育、研究和工业应用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20795", "html_url": "https://arxiv.org/abs/2510.20795", "title": "使用球形图神经网络从CMB推断原始磁场参数的贝叶斯推断", "title_en": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with Spherical Graph Neural Networks", "authors": "Juan Alejandro Pinto Castro,Héctor J. Hortúa,Jorge Enrique García-Farieta,Roger Anderson Hurtado", "background": "深度学习在现代宇宙学中成为了一种革命性的方法，提供了从复杂天文学数据集中提取有意义物理信息的强大工具。本文利用球形图深度学习框架，直接从模拟的宇宙微波背景（CMB）地图中估计原始磁场（PMF）宇宙学中的关键参数。该方法基于DeepSphere架构，这是一种专门为遵守CMB数据的球形几何而设计的深度卷积神经网络。", "innovation": "本文的工作在于提出了一种新颖的贝叶斯图深度学习框架，结合了贝叶斯神经网络（BNNs）来估计原始磁场的参数，并进行鲁棒的不确定性量化。通过使用球形图神经网络（DeepSphere）以及贝叶斯神经网络，该框架不仅能够实现参数的精确估计，还能提供可靠的不确定性量化，这对于现代精准宇宙学中的宇宙学推断至关重要。", "conclusion": "该集成的DeepSphere-BNNs框架不仅能够从包含原始磁场贡献的CMB地图中准确地估计参数，还能够提供可靠的不确定性量化，为现代精度宇宙学提供必要的工具。通过后验训练技术（如方差缩放和GPNormal）进行的不确定性量化的校准证明了该方法的出色性能，达到了超过0.89的$R^{2}$分数。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20797", "html_url": "https://arxiv.org/abs/2510.20797", "title": "简单的上下文压缩：平均池化和多比例训练", "title_en": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training", "authors": "Yair Feldman,Yoav Artzi", "background": "在使用长上下文的检索增强生成(RAG)方法时，常见的策略是软上下文压缩，即将输入序列转换为较短的连续表示，以降低计算成本。已有研究中，广泛使用的是压缩标记（compression tokens）架构。尽管已有方法有效，但本研究发现了一个更轻量级且简单的平均池化（mean-pooling）方法，并能在多个压缩比例下进行训练。", "innovation": "研究开发了一种轻量级且简单的平均池化方法，能够在多个压缩比例下进行训练，并在多种数据集和模型规模上进行了广泛的实验。结果显示，平均池化方法在多个压缩比例下训练时的性能虽有所下降，但在整体上表现最佳。", "conclusion": "平均池化方法在上下文压缩方面表现突出，即使在训练多个压缩比例时也保持相对较好的表现。然而，在不同架构和训练策略下，压缩方法的表现更复杂，表明这一领域还需要进一步研究以探索更复杂的压缩方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20810", "html_url": "https://arxiv.org/abs/2510.20810", "title": "LLM生成文本的可检测性：到底什么是LLM生成的文本？", "title_en": "On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?", "authors": "Mingmeng Geng,Thierry Poibeau", "background": "随着大型语言模型（LLMs）的广泛应用，许多研究人员开始关注如何检测这些模型生成的文本。然而，尚未形成一致且精确的“LLM生成文本”的定义。使用场景的差异和LLM的多样性进一步增加了检测的难度。通常认为的检测目标仅代表LLM能够生成的一部分文本。人类对LLM输出的编辑以及LLM对用户的微妙影响使得区分LLM生成和人类撰写的文本变得越来越困难。现有的基准测试和评估方法未能充分应对现实世界中检测器应用的种种情况，这导致了检测器结果往往被误解，并丧失了其意义。", "innovation": "潜在的创新在于提出了对“LLM生成文本”的理解需要更加精确和具体的挑战，强调了在实际应用场景中，现有的检测方法和基准可能不够有效。", "conclusion": "检测器在特定条件下仍然有用，但它们的结果只能作为参考，而不能作为决定性的指标。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20808", "html_url": "https://arxiv.org/abs/2510.20808", "title": "机器人中的现实差距：挑战、解决方案和最佳实践", "title_en": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices", "authors": "Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos", "background": "机器学习极大地推动了各个机器人领域的重要进展，包括导航、运动和操作。虽然模拟被广泛用作预测和测试机器人系统的一种关键工具，以适应真实世界环境，但模拟中的抽象和近似会导致模拟环境与真实环境之间的差异，即现实差距。这种差距极大地阻碍了系统从模拟环境转移到真实世界的成功。最近的研究展示了不同的平台（如导航、运动、操作）上的初步成功，但仍然存在许多挑战，需要更深入地理解现实差距的根本原因及其解决方案。", "innovation": "本文提供了机器人中现实差距的全面概述，强调了现实差距的原因、解决方案和评价指标，并探讨了从模拟到现实的转移过程中的新趋势和技术。通过总结与整理现有的研究，本文旨在提供关于如何缓解现实差距的实用建议和最佳实践。", "conclusion": "本文总结了机器人从模拟到现实转移过程中的现实差距、原因及其解决方案，并提供了评价计据。未来的研究应该进一步探索现实差距的根本原因，开发新的方法和技术，以提高系统的通用性和适应性，克服真实差距，从而在各个实际应用场景中改进机器人的性能。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20812", "html_url": "https://arxiv.org/abs/2510.20812", "title": "小型草稿，大型裁决：基于推测的信息密集视觉推理", "title_en": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation", "authors": "Yuhan Liu,Lianhui Qin,Shengjie Wang", "background": "大视觉-语言模型（VLMs）在多模态理解方面取得了显著进步，但在需要精确定位密集布局中的关键线索并进行多跳推理以整合分散的证据以理解含有丰富文本注释和细粒度图形元素的信息密集图像时表现不佳。", "innovation": "提出了一种名为Speculative Verdict（推测裁决，SV）的无需训练的框架，该框架借鉴了推测解码的方法，结合了多个轻量级草稿专家和一个大型裁决模型。在草稿阶段，小型VLMs作为草稿专家生成提供多种定位候选的推理路径；在裁决阶段，强VLM综合这些路径生成最终答案，同时降低计算成本并恢复正确的答案。进一步提高效率和准确性的举措包括引入共识专家选择机制，只将高一致性的推理路径传递到裁决阶段。", "conclusion": "实验证明，SV在具有挑战性的信息密集和高分辨率视觉问答基准测试（如InfographicVQA、ChartMuseum、ChartQAPro和HR-Bench 4K）中实现了持续的收益。通过从多个部分准确的推理路径中综合正确的见解，SV实现了错误校正和成本效率，相比大型专有模型或训练管道。相关代码可在以下链接获得：this https URL"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20813", "html_url": "https://arxiv.org/abs/2510.20813", "title": "GSWorld：用于机器人操作的闭环写实模拟套件", "title_en": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation", "authors": "Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang", "background": "尽管现有的机器人模拟器在某些任务上表现出色，但它们在真实感渲染和实时性方面仍然存在不足，导致真实世界和模拟环境之间的差距难以弥合。这对直接从真实机器人数据训练策略并将其迁移到实际环境中的闭环策略开发流程构成了挑战。", "innovation": "该研究提出了GSWorld，一种结合3D高斯散点图技术和物理引擎的坚固且写实的机器人模拟器。主要创新点包括提出了一种新的资产格式GSDF，该格式融合了高斯-网格表示和其他对象，如机器人URDF。通过简化重建流水线，他们构建了一个包含多种机器人模型和物体的数据库。结合物理引擎，GSWorld展示了多个有趣的应用：零样本模拟到现实的像素到动作策略学习，自动高质量的DAgger数据采集，真实机器人策略的可重复仿真评估，通过虚拟远程操作收集仿真数据，以及零样本的模拟到现实的视觉强化学习。", "conclusion": "GSWorld为机器人操作策略的开发和评估提供了一个闭环的、高真实感的仿真环境。该方法不仅提高了模拟环境的真实感，还能够有效支持策略的从模拟到现实的迁移，加速了机器人操作技术的实际应用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20800", "html_url": "https://arxiv.org/abs/2510.20800", "title": "压缩以卓越：使用针对100个样本的单个梯度步骤高效调整大型语言模型", "title_en": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "authors": "Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus", "background": "近期，Sharma等人提出了一种名为Layer-Selectively-Rank Reduction（LASER）的方法。该方法表明，在精心选择的LLM权重矩阵中修剪高阶组件可以在不需要任何基于梯度的微调的情况下提高下游任务的准确性。然而，LASER方法由于在每个矩阵上进行全面的数据集前向传递求解计算，使得其实现快速部署存在困难。因此，为了克服这些问题，该研究探讨了减少计算开销的方法并发现了多个关键发现，包括仅需要仔细选择的一小部分矩阵进行检查、每个矩阵的奇异值梯度指出需要进行修剪的矩阵、通过允许矩阵行簇聚在多个子空间中并分别对每个簇进行分解来增加因式分解搜索空间、减少对原始训练数据的过拟合并进一步提高准确率、以及在计算指示性梯度和衡量最终精度时使用100个样本而非全部训练数据，最终得出一种快速和稳健的适应下游任务的算法。", "innovation": "减少计算开销的方法和关键发现包括：仅需仔细选择的一部分矩阵进行检查来消除逐层扫掠；矩阵奇异值梯度用于确定哪些矩阵需要缩减；通过允许矩阵行簇聚并分别分解每个簇来增加分解搜索空间；减少对原始训练数据的过拟合并进一步提升准确率；以及使用100个样本而非全部训练数据进行计算和精度测量以减少搜索时间。这些发现表明，适应下游任务时最重要的是调优策略而非数据集大小。结合这些发现，作者提出了一种快速且稳健的适应算法，仅需在100个样本上进行一次梯度步并快速扫描候选层和分解技术，即可在无需微调的情况下将大型语言模型调整至新数据集上。", "conclusion": "该研究展示了通过结合关键发现，提出了一种快速且稳健的适应算法，可以在无需进行基于梯度的微调的情况下将大型语言模型适应到新的数据集上。这种方法结合了单个梯度步和快速扫描潜在调整层与分解技术，使得模型适应过程更快并保持了高精度。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20818", "html_url": "https://arxiv.org/abs/2510.20818", "title": "VAMOS: 一种具备能力调制和可操控导航的分层视觉-语言-动作模型", "title_en": "VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation", "authors": "Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta", "background": "机器人导航的基本挑战在于学习能够在多种不同环境中泛化的策略，同时这些策略要符合特定机械体的独特物理约束和能力（例如，四足机器人可以爬楼梯，但轮式机器人不能）。现有的方法主要依靠基于模型的方法或端到端的学习方法，它们往往不能很好地适应不同类型的机械体制约，且在现实环境中的成功率较低。", "innovation": "VAMOS 提出了一种分层视觉-语言-动作模型 (hierarchical VLA)，它将语义规划与机械体适应分开。具体来说，一个通用规划器可以从多种开放世界的数据中学习，而一个专门的利用模型则在安全且低成本的模拟环境中学习机器人具体的物理约束和能力。VAMOS 的设计允许高级规划器直接在图像空间中提出路径建议，然后由利用模型评估和重新排名。实验结果表明，VAMOS 在室内和复杂的室外环境中的导航成功率均高于当前最先进的基于模型的方法和端到端学习方法。此外，该模型的分层设计还使得它能够在不同类型的机械体（如腿足机器人和轮式机器人）之间通用，并可通过自然语言进行控制。", "conclusion": "VAMOS 模型通过单独的学习语义规划和机械体适应，提高了导航任务的成功率和机器人的通用性。特别是，它可以通过拒绝不物理可行的计划来显著提高单个机器人的可靠性。而且，单个高级规划器可以在物理上不同的轮式和腿足机器人上使用，增强了机器人的适应性和灵活性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20819", "html_url": "https://arxiv.org/abs/2510.20819", "title": "使用对比和预测潜在扩散桥进行通用模态翻译", "title_en": "Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge", "authors": "Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot", "background": "生成建模的最新进展将扩散模型置于从复杂数据分布进行采样的最先进工具之列。尽管这些模型在单一模态领域（如图像和音频）中表现出显著的成功，但将它们的能力扩展到模态翻译（MT），在不同感觉模态间翻译信息，仍然是一个开放的挑战。现有的方法往往依赖于共享维度、高斯先验和特定模态的架构等限制性假设，这限制了它们的通用性和理论基础。", "innovation": "本文提出了一种名为潜变量扩散桥模型（LDDBM）的通用模态翻译框架，该框架基于扩散桥模型的潜变量扩展。通过在共享的潜空间中操作，我们的方法在任何任意模态之间学习桥梁关系，无需要求对齐维度。我们引入了对比对齐损失以强制配对样本之间的语义一致性，并设计了通用的编码器-解码器架构，专为潜空间中的噪声预测量身定制。此外，我们还提出了预测损失以指导训练，从而实现准确的跨域翻译，并探索了多种训练策略以提高稳定性。我们的方法支持任意模态配对，并在包括多视角到3D形状生成、图像超分辨率和多视角场景合成等多样化的MT任务中表现出强大的性能。", "conclusion": "综合的实验和消融测试验证了我们框架的有效性，建立了通用模态翻译的新强基准。欲了解更多详情，请参考我们的项目页面：this https URL。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.09933", "html_url": "https://arxiv.org/abs/2502.09933", "title": "MIR-Bench: 你的大语言模型能否通过多样本内上下文推理识别复杂模式？", "title_en": "MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?", "authors": "Kai Yan,Zhan Ling,Kang Liu,Yifan Yang,Ting-Han Fan,Lingfeng Shen,Zhengyin Du,Jiecao Chen", "background": "识别模式并将其应用于新情境是通用人工智能的关键能力，心理学和AI研究者广泛研究这一能力。已提出的基准主要用于评估大型语言模型在少量示例（通常少于10个）情况下的这种能力，但缺乏对处理大量信息和长上下文的评估。虽然大语言模型的上下文长度不断增加，形成了新的多样本内上下文学习（ICL）范式，但此类评估多集中在分类任务，而现有长上下文问题如Needle-In-A-Haystack（NIAH）任务通常不要求复杂的整合大量信息的能力。", "innovation": "本文提出了MIR-Bench——首个多种数据格式下多样本内上下文推理基准，旨在让模型通过输入输出示例来预测底层函数。基于MIR-Bench，研究者探讨了多样本内上下文推理中的多种新颖问题，并发现了一系列有见地的成果，如规模效应、鲁棒性、归纳推理与演绎推理、检索增强生成（RAG）、编码用于归纳推理、跨领域泛化能力等。", "conclusion": "MIR-Bench填补了现有基准和长上下文任务的不足，提供了一个评估模型在多样本内上下文学习中综合多种信息和识别复杂模式能力的新平台。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.12977", "html_url": "https://arxiv.org/abs/2411.12977", "title": "MindForge: 为终身文化学习赋予具身代理理论心智能力", "title_en": "MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning", "authors": "Mircea Lică,Ojas Shirekar,Baptiste Colle,Chirag Raman", "background": "基于大型语言模型（LLMs）的具身代理，如Voyager，在Minecraft等世界中表现出开放性的能力。然而，在经过领域特定的微调后，基于开源的LLMs的具身代理仍然在基本任务上表现出色，但仍然遇到困难。本文介绍了文化终身学习框架MindForge，以实现具身代理的理论心智能力，通过显式的视角推理进行文化终身学习。该框架旨在处理复杂的认知过程和代理间的自然通信，以实现更高级的代理行为和学习能力。", "innovation": "提出一种生成代理框架MindForge，包括三大创新点：（1）结构化的理论心智表示，将感知、信念、欲望和行动联系起来；（2）自然的代理间通信；（3）多组件记忆系统。MindForge通过文化学习框架，在指令性和合作性两方面的Minecraft环境中进行了测试。实验结果表明，使用MindForge框架的具身代理在基本任务上的表现显著优于Voyager，在技术树里程碑和独特物品收集方面分别提升了3倍和2.3倍。更进一步地，在完全合作环境中，代理间的通信轮次越多，表现越佳，与 Condorcet 裁员定理吻合。MindForge还证实了复杂的行为，如专家与新手知识传递、合作问题解决和通过积累文化经验适应分布外任务的能力，进一步展现了其先进性与实用性。", "conclusion": "MindForge框架促进了基于开源LLMs的具身代理的文化终身学习，实现了更高级的心理理解和自然的代理间通信，从而在基本任务和合作场景中显著提升了性能，展现了复杂行为和适应新任务的能力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02439", "html_url": "https://arxiv.org/abs/2505.02439", "title": "基于集成学习的大规模多背景建筑HVAC控制的机器学习模型预测控制", "title_en": "Towards Machine Learning-based Model Predictive Control for HVAC Control in Multi-Context Buildings at Scale via Ensemble Learning", "authors": "Yang Deng,Yaohui Liu,Rui Liang,Dafang Zhao,Donghua Xie,Ittetsu Taniguchi,Dan Wang", "background": "用于在潜在的HVAC控制操作下预测实际室内温度变化的建筑热力学模型对于优化建筑物中的HVAC控制至关重要。尽管先驱研究尝试为各种建筑环境开发此类模型，但这些模型通常需要长时间的数据收集，并且严重依赖专家知识，使得建模过程效率低下，限制了模型的复用性。因此，需要一种新的方法来减少模型构建的劳动和增加模型的复用性。", "innovation": "本文提出了一种基于集成学习的方法，通过使用现有的已开发模型作为基础模型来服务于目标建筑环境，从而提供准确的预测并减少相应的努力。提出了一种分层强化学习（HRL）方法，用于动态选择并加权基础模型。方法采用两层决策过程：高层负责模型选择，低层确定选定模型的权重。并通过离线实验和实地案例研究进行了全面评估，实验结果证明了该方法的有效性。", "conclusion": "通过分层强化学习方法，提出的模型能够有效动态选择并加权基础模型，从而在不牺牲预测准确性的前提下减少模型构建的劳动，尤其适用于大规模多背景建筑的HVAC控制。这种方法不仅提高了效率，还增强了模型的复用性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02828", "html_url": "https://arxiv.org/abs/2505.02828", "title": "Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review", "title_en": "Privacy Risks and Preservation Methods in Explainable Artificial Intelligence: A Scoping Review", "authors": "Sonal Allana,Mohan Kankanhalli,Rozita Dara", "background": "解释性人工智能（XAI）已成为可信人工智能的支柱，并旨在提高本性上不透明的复杂模型的透明度。尽管在模型中加入解释具有许多好处，但还存在一个迫切需要解决的问题，即在向最终用户提供这些额外信息时确保隐私安全。本文通过文献综述探讨了隐私与解释之间的冲突，提取了从2019年1月至2024年12月发表的1,943篇文章中的57篇文章，以研究隐私风险、当前隐私保护方法以及隐私保护的解释特征。", "innovation": "本文采用标准文献综述方法，分析了解释性人工智能中的隐私风险和保护方法，提出了隐私保护解释的特征，旨在帮助研究者和实践者理解符合隐私要求的解释性人工智能的需求。此外，本文还识别了在平衡隐私与其他系统要求方面的挑战，并提供了实现隐私保护的解释性人工智能的建议。", "conclusion": "本文的综述揭示了隐私与解释之间的复杂关系，这两者是可信人工智能的基本原则。通过分析现有的研究，文章为研究者和实践者提供了理解并实现符合隐私要求的解释性人工智能的指导。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14667", "html_url": "https://arxiv.org/abs/2505.14667", "title": "SAFEPATH：通过早期对齐防止链式思维中的有害推理", "title_en": "SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment", "authors": "Wonje Jeung,Sangyeon Yoon,Minsuk Kahng,Albert No", "background": "大型推理模型（LRMs）已成为解决复杂问题的强大工具，但由于它们的结构化推理路径，在面对有害提示时可能会产生不安全的输出。现有的安全对齐方法可以减少有害输出，但可能会降低推理深度，导致在复杂多步骤任务中出现重要权衡，且依然容易受到高阶突破攻击的影响。", "innovation": "SAFEPATH是一种轻量级对齐方法，该方法在面对有害提示时，使LRMs生成一个短的8个标记的安全提示，同时监督推理过程的其余部分。实验结果显示，SAFEPATH在降低有害输出的同时维持了推理性能。此外，介绍了一个无需微调的零样本变体。并且分析了现有方法在应用于基于推理的模型时的泛化能力或失败情况，指出关键缺陷和新的发展方向。", "conclusion": "SAFEPATH方法通过在推理开始时插入一个短的安全提示，有效地减少了有害输出，同时降低了计算需求，提高了安全性。此外，提出的零样本变体不需要微调即可运行。这项研究揭示了现有方法的局限性，为更安全的AI提供了新的方向。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.13837", "html_url": "https://arxiv.org/abs/2504.13837", "title": "RL真的能够激励LLMs超越基模型的推理能力吗？", "title_en": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?", "authors": "Yang Yue,Zhiqi Chen,Rui Lu,Andrew Zhao,Zhaokai Wang,Yang Yue,Shiji Song,Gao Huang", "background": "RLVR（可验证奖励的强化学习）近年来在提升大型语言模型（LLM）在数学和编程任务上的推理能力方面表现出显著成效。尽管传统RL有助于代理探索和学习新的策略，RLVR被认为可以帮助LLM持续自我改进，获得超越基模型的新推理能力。但当前研究通过系统地探查不同模型家族、RL算法以及数学、编程和视觉推理基准上的RLVR训练模型的推理能力边界，发现当前的训练设置并未激发出根本上新的推理模式。基模型在大k值下的pass@k得分高于RLVR训练后的模型，表明观测到的推理能力来源于基模型且受到其限制。六种流行的RLVR算法在性能上表现相似，并未充分利用基模型的潜力。在此基础上，作者认为需要改进的RL范式，比如持续扩展和多回合加剂-环境交互，来释放这种潜力。", "innovation": "该研究通过量化分析发现，当前流行的一些RLVR算法在利用基模型潜力方面表现不佳，其性能表现相似且相差不大。此外，研究还发现蒸馏能够引入教师的新推理模式，真正扩展模型的推理能力，从而提出改善RL方法来解锁RL激励更多新推理能力的潜力。", "conclusion": "目前RLVR方法尚未充分实现RL激励LLMs产生真正全新的推理能力的潜力。这表明需要采用新的RL范式，如持续扩展和多回合交互，来实现这一潜力，从而在LLMs中真正激励出超越基模型的新推理能力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15275", "html_url": "https://arxiv.org/abs/2504.15275", "title": "停止求和：最小形式的奖励分配是过程奖励模型进行推理所需的一切", "title_en": "Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning", "authors": "Jie Cheng,Gang Xiong,Ruixi Qiao,Lijun Li,Chao Guo,Junle Wang,Yisheng Lv,Fei-Yue Wang", "background": "过程奖励模型（PRMs）已在大语言模型（LLMs）在具有挑战性的推理任务上的测试时缩放方面展现出了有效性。然而，PRMs 引发的奖励欺骗问题限制了其在强化学习微调中的成功应用。这种问题是由于强化学习（RL）中经典的求和形式的奖励归因方式引起，其特点是将价值定义为折扣未来的累积奖励，这容易导致LLMs去欺骗那些具有高奖励的步骤。", "innovation": "本文提出了PURE（Process sUpervised Reinforcement lEarning），通过最小形式的奖励分配解决了PRM导致的奖励欺骗问题。PURE的关键创新在于将价值函数公式化为未来的最小奖励值，这种方法通过限制价值函数的范围和更合理地分配优势，显著缓解了奖励欺骗问题。实验表明，启用最小形式奖励分配的PRM方法在仅30%的步骤内达到了与验证奖励方法相当的推理性能，在补充10%验证奖励后，该方法进一步缓解了奖励欺骗，并在Qwen2.5-Math-7B上取得了最佳微调模型，实验中AMC23达到82.5%的准确率和5个基准平均53.3%的准确率。", "conclusion": "通过对观察到的奖励欺骗案例进行总结和分析了训练崩溃的原因，并公开了代码和模型权重。本文的研究成果表明，最小形式的奖励分配是解决过程奖励模型的奖励欺骗问题的关键，使得LLMs在复杂的推理任务上实现更好的性能。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.04210", "html_url": "https://arxiv.org/abs/2506.04210", "title": "思考更多总是有帮助吗？推理模型测试时扩展的幻象", "title_en": "Does Thinking More always Help? Mirage of Test-Time Scaling in Reasoning Models", "authors": "Soumya Suvra Ghosal,Souradip Chakraborty,Avinash Reddy,Yifu Lu,Mengdi Wang,Dinesh Manocha,Furong Huang,Mohammad Ghavamzadeh,Amrit Singh Bedi", "background": "最近针对推理模型（如OpenAI的o1和DeepSeek的R1）在测试时缩放的趋势表明，通过使用类似于“等待”或“让我重新思考”的提示来扩展推理路径可以提升性能。这引发了一个自然的问题：在测试时思考更多是否真的能提高推理质量？", "innovation": "该研究引入了一种替代的测试时缩放方法——并行思考，这是一种灵感来源于Best-of-N采样的方法。该方法在相同的推理预算中生成多个独立的推理路径，并通过多数表决选择最一致的响应，从而可以在测试时获得高达20%更高的准确性。这种方法提供了一个简单且有效的机制来扩展示推理模型在测试时的性能。", "conclusion": "研究发现，额外的思考虽然起初可能会提高性能，但由于过度思考会导致性能下降。实际上，观察到的“更多思考”的增益并非真正的推理性能提升，而是模型不确定性与评估指标间关联的产物。因此，通过延长思考来测试时扩展推理并不是一种有效的方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23946", "html_url": "https://arxiv.org/abs/2505.23946", "title": "从中学到的知识：一种代码LLM多代理框架以学习和改进", "title_en": "Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve", "authors": "Yuanzhe Liu,Ryan Deng,Tim Kaler,Xuhao Chen,Charles E. Leiserson,Yao Ma,Jie Chen", "background": "近期研究表明，大型语言模型（LLMs）在不同任务上具有不同的技能和专长。实际观察发现，它们在不同任务上的表现体现在多个粒度级别上。例如，在代码优化任务中，代码LLMs在不同优化类别上表现出色，没有一个模型完全占据主导地位。这一观察结果提出了一个问题：在不知道每个代理互补优势的情况下，如何利用多个LLM代理解决编程问题。本文探讨了如何通过共享知识来改进每个代理的性能。", "innovation": "本文提出了基于知识共享的多代理协作框架。这种框架设计了请求、存储和选择知识的机制，并证明了一个学习了知识的小型LLM团队可以在代码优化等任务上表现出色，甚至优于较大的LLM及其多LLM协作方法。该创新强调了多代理系统在利用对方成功和失败经验方面的潜力。", "conclusion": "研究团队通过提出的多代理框架和知识共享机制证明了，小型LLM团队在学习了相应知识后，可以在复杂任务上超越单一大型LLM或其他多代理方法的表现。这表明，代理之间的相互学习对于提高整体性能至关重要。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19923", "html_url": "https://arxiv.org/abs/2506.19923", "title": "Prover Agent: 基于代理框架的形式化数学证明", "title_en": "Prover Agent: An Agent-Based Framework for Formal Mathematical Proofs", "authors": "Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai", "background": "本文介绍了一个名为Prover Agent的新的人工智能代理，旨在自动化定理证明任务。Prover Agent整合了大型语言模型（LLMs）与形式化证明助手Lean，通过协调非形式化推理的LLM、形式化的证明模型以及来自Lean的反馈信息，同时生成辅助引理，从而在MiniF2F基准测试中以88.1%的成功率名列前茅。现有的方法通常在处理涉及小型语言模型的挑战性问题时，需要消耗更多的样本预算，而Prover Agent则利用其成熟的方法在这项任务上取得了突破。", "innovation": "Prover Agent的核心创新在于其设计了结合LLMs（大型语言模型）与形式化证明助手Lean的新型代理框架，能够生成辅助引理，不仅包括子目标中的事实，还可以涵盖从前提条件中推导出的特殊案例或可能有用的结论。此外，通过理论分析和案例研究，展示了这些生成的引理如何有助于解决困难问题。Prover Agent在所需样本预算大大低于前人工作的情况下，实现了新的方法状态。", "conclusion": "Prover Agent在MiniF2F基准测试中取得了88.1%的成功率，打破了使用小型语言模型的方法所保持的记录。而且，我们提供的理论分析和案例表明，辅助引理对于解决复杂的数学验证问题至关重要。该代码已公开，请通过提供的链接访问：this https URL."}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18633", "html_url": "https://arxiv.org/abs/2509.18633", "title": "在空间代理基于模型中的适应性学习在气候风险评估中的应用：具有进化的经济代理的地理空间框架", "title_en": "Adaptive Learning in Spatial Agent-Based Models for Climate Risk Assessment: A Geospatial Framework with Evolutionary Economic Agents", "authors": "Yara Mohajerani", "background": "气候风险评估需要建模空间上异质性的自然灾害与适应性的经济体系之间的复杂相互作用。该研究旨在通过集成了气候灾害数据与经济代理进化学习的新型地理空间代理基础模型来解决这一问题。", "innovation": "研究提出了一种结合基于Mesa的空间建模与CLIMADA气候影响评估的框架，并引入了适应性学习行为，使企业在基于适配度的选择和变异的策略中优化预算分配、定价、工资和风险适应策略。该框架通过模拟RCP8.5情景下至2100年的河流洪水预测，展示了适应性适应如何帮助企业在数十年的气候变化带来中断后恢复到基准生产水平。", "conclusion": "研究结果表明，尽管存在系统性风险，即便那些不直接面临洪水风险的企业，也会通过供应链中断受到影响，到本世纪末，RCP8.5情景下的商品平均价格比基准情形高出5.6%。该开源框架为金融机构和企业提供了一种工具，用于量化直接和间接的气候风险，并评估成本效益较高的适应策略。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17192", "html_url": "https://arxiv.org/abs/2509.17192", "title": "探索开放型桌面游戏：语言模型的应用", "title_en": "Shall We Play a Game? Language Models for Open-ended Wargames", "authors": "Glenn Matlin,Parv Mahajan,Isaac Song,Yixiong Hao,Ryan Bard,Stu Topp,Evan Montoya,M. Rehan Parwani,Soham Shetty,Mark Riedl", "background": "桌面游戏是模拟冲突的模拟游戏，参与者的决策会影响未来事件。休闲桌游可以用于娱乐或社交，而严肃的桌游则由专家用来探索决策的策略影响和经验学习。军事组织开始利用语言模型（LMs）为开放型桌面游戏中自然语言传达的现实决策后果提供见解。本文认为，人工智能系统，尤其是语言模型，正在迅速接近甚至最终超过人类专家的战略规划能力。因此，需要进一步研究人工智能在开放型桌面游戏中的安全、可解释性和可说明性。", "innovation": "本文通过分析100篇公开的研究文献，构建了一个关于开放性的原创概念框架，旨在为部署人工智能在开放型桌面游戏中的应用提出实用建议和关键安全考虑。这为军事及其他领域探索人工智能在开放型桌面游戏中的潜力提供了新的视角和依据。此外，本文提出了未来研究的重要挑战，激励对该领域进行进一步探讨。", "conclusion": "本文揭示了人工智能在开放型桌面游戏中的应用潜力，并提出了重要的安全挑战。它向社区提出了未来研究的高影响问题，旨在推动该领域的进一步发展。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.25271", "html_url": "https://arxiv.org/abs/2509.25271", "title": "RADAR：一种基于角色专业化协作的风险感知动态多代理框架，用于大语言模型安全评估", "title_en": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "authors": "Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li", "background": "现有的大语言模型（LLMs）的安全评估方法存在固有的局限性，如评估者偏见和由于模型同质性导致的检测失败，这些因素共同削弱了风险评估过程的稳定性。", "innovation": "本研究提出了一种理论框架，重新审视风险评估范式，将其分解为三个互斥的子空间：显式风险子空间（涵盖直接违反安全指南的行为），隐含风险子空间（捕捉需要上下文推理才能识别的潜在恶意内容），以及无风险子空间。此外，提出了一种多代理协作评估框架RADAR，通过四种专门的角色合作机制和动态更新机制来实现风险概念分布的自我进化，从而实现对显式和隐含风险的全面覆盖并减轻评估者偏见。", "conclusion": "通过构建包含800个挑战性案例的评估数据集，实验结果显示RADAR在准确性、稳定性和自我评估风险敏感性等多维度上显著优于基线评估方法，风险识别准确性提高了28.87%。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08872", "html_url": "https://arxiv.org/abs/2510.08872", "title": "GTAlign：基于博弈论的大语言模型助手公平性对齐", "title_en": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare", "authors": "Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You", "background": "大语言模型（LLMs）在推理方面取得了显著进步，但在写作、信息搜索或提供实际指导等任务中，有时会生成用户不满意的响应。传统的对齐方法通常假设最大化模型奖励也能最大化用户福利，但在实践中这种假设经常无法成立：模型可能会过度细化或生成过于冗长的解释，而用户可能更喜欢简洁的答案。这种行为类似于囚徒困境，个体理性选择导致了社会的次优化结果。因此，缺乏一个既能兼顾大语言模型和用户利益的准则机制，是现有研究面临的根本挑战。", "innovation": "本文提出了Game-Theoretic Alignment（GTAlign），这一对齐框架将博弈论决策机制融入到了推理和训练中。在推理过程中，模型将用户-LLM交互视为一种策略博弈，并在推理链中构建收益矩阵来估算自身和用户的价值，进而选择双方都有利的行为。在训练过程中引入了一个互惠福利奖励，鼓励合作响应，使模型行为与社会效率结果相一致。此外，引入了一种利用博弈论推理的技术，使模型根据大语言模型服务定价策略的变化动态调整其响应。广泛的实验显示，在各类任务上，与基线相比，GTAlign显著提高了推理效率、答案质量和互惠福利。", "conclusion": "实验表明，GTAlign在各类任务上显著提高了推理效率、答案质量和互惠福利，与基线相比表现更加优越。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17697", "html_url": "https://arxiv.org/abs/2510.17697", "title": "多智能体强化学习中的靶向干预原则", "title_en": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "authors": "Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang", "background": "在大规模多智能体强化学习（MARL）系统中，引导智能体相互协调以达成特定目标非常具有挑战性，特别是当无法从整体系统获得全局指导时。现有的通过内在奖励和人类反馈设计外部机制的协调方式往往需要依赖于经验研究，缺乏一个易于使用的研究工具。", "innovation": "本研究采用多智能体影响图（MAIDs）作为图形框架，提出了一种靶向干预原则，通过引入因果推理技术（预策略干预PSI）来针对性地干预单个智能体，从而缓解了全局指导的问题。通过MAIDs的捆包相关图分析，可以识别出MARL学习范式在特定交互范式设计下的可行性。", "conclusion": "实验结果表明，提出的靶向干预原则有效，验证了MAIDs捆包相关图分析的工具能够准确识别MARL学习范式的可行性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16559", "html_url": "https://arxiv.org/abs/2510.16559", "title": "BuildArena: 一种针对工程构建的LLM物理对齐互动基准", "title_en": "BuildArena: A Physics-Aligned Interactive Benchmark of LLMs for Engineering Construction", "authors": "Tian Xia,Tianrun Gao,Wenhao Deng,Long Wei,Xiaowei Qian,Yixian Jiang,Chenglei Yu,Tailin Wu", "background": "工程构建自动化旨在将自然语言规范转化为物理可实现的结构，这需要在严格的物理约束下进行复杂而综合的推理。虽然现代大模型（LLMs）具备广泛的知识和强大的推理能力，使其在这一领域显得很有前景，但它们在构建方面的性能尚未得到充分评估。因此，当前领域存在如何有效地评价大模型在物理约束下的工程构建能力的需求，也急需能够进行深入比较和分析的大规模基准测试框架和方法。", "innovation": "BuildArena是一个针对语言驱动工程构建的、物理对齐的互动基准。其创新点在于：（1）提供了一个高度可定制的基准测试框架，用于深入比较和分析大型语言模型（LLMs）；（2）设计了一个包含从静态到动态力学的多难度层次的扩展任务策略；（3）开发了一个3D空间几何计算库，支持基于语言指令的构建；（4）提供了一个基准LLM智能工作流程，有效评估模型的多种能力。BuildArena全面评估了八个前沿大模型在语言驱动和物理基础的工程构建自动化方面的能力。", "conclusion": "BuildArena为语言驱动的工程构建领域提供了一个全面的基准测试平台，以物理约束为指导，不仅有助于深入研究不同大模型在实际工程任务中的性能差异，也有助于推动相关技术的发展。实验结果表明，通过BuildArena可以有效评估大型语言模型在物理约束下的工程构建性能。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.10603", "html_url": "https://arxiv.org/abs/2510.10603", "title": "EA4LLM：通过进化算法实现大型语言模型优化的无梯度方法", "title_en": "EA4LLM: A Gradient-Free Approach to Large Language Model Optimization via Evolutionary Algorithms", "authors": "WenTao Liu,Siyu Song,Hao Hao,Aimin Zhou", "background": "近年来，大型语言模型（LLMs）取得了显著进展，主要依赖梯度基优化器如Adam进行模型优化。然而，这些梯度基方法对硬件提出了严格要求，需要高并发、高内存的GPU，并且要求所有神经网络操作均可微，从而排挤了许多有前景但不可微的架构的实际应用。为了克服这些限制，我们提出了EA4LLM，一种用于优化LLMs的进化算法，并首次实证验证从小至0.5B到大至32B的不同模型规模下的全参数优化。我们进行了广泛的实验，并提供了关于如何有效优化神经网络的关键见解。我们的工作挑战了基于梯度优化是唯一可行的神经网络训练方法这一假设，也具有显著潜力来降低训练大型语言模型的计算成本，从而使计算资源有限的团队能够参与深度学习研究。", "innovation": "我们提出了EA4LLM，一种用于优化大型语言模型的进化算法，首次在从小至0.5B到大至32B的不同模型规模下实证验证了全参数优化，极大地扩展了优化架构的范围。该工作为神经网络训练提出了一种新的无梯度方法，挑战了传统的基于梯度的优化理念。", "conclusion": "我们的研究挑战了基于梯度的优化是唯一可行的神经网络训练方法的假设，并提供了进化算法有效优化神经网络的实证支持，这将有助于降低训练大型语言模型的计算成本，使得计算资源有限的研究团队也能参与其中。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16614", "html_url": "https://arxiv.org/abs/2510.16614", "title": "Count Counts: 在基于计数的固有奖励驱动LLM推理中的探索", "title_en": "Count Counts: Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards", "authors": "Xuan Zhang,Ruixiao Li,Zhijian Zhou,Long Li,Yulei Qin,Ke Li,Xing Sun,Xiaoyu Tan,Chao Qu,Yuan Qi", "background": "强化学习（RL）已成为增强大规模语言模型（LLMs）多步推理能力的有效方法。然而，当前的主流RL方法仍然依赖于稀疏的基于结果的奖励和有限的探索，这通常会导致LLMs重复和次优的推理模式。因此，本文研究如何设计LLM推理中的探索方法，并引入了一种新的RL算法MERCI（Motivating Exploration in LLM Reasoning with Count-based Intrinsic Rewards），该算法通过有原则的固有奖励来增强策略优化。", "innovation": "MERCI算法采用了基于计数的探索理念，结合了轻量级的硬币翻转网络（CFN）来估计推理轨迹的伪计数和进一步的元认知不确定性，并将这些转化为一个固有奖励，该奖励重视新颖性同时保留来自任务奖励的学习信号。此外，MERCI被集成到一些高级的RL框架中，如Group Relative Policy Optimization (GRPO)。实验结果表明，MERCI能够促进更丰富和多样化的思维链条，显著提高了性能，帮助策略逃避局部惯例，发现更好的解决方案，表明我们针对的固有动机可以确保语言模型推理过程中的探索可靠性。", "conclusion": "MERCI通过使用基于计数的固有奖励，促进了更丰富和多样的推理链条，改进了相对于强基线的性能，并帮助策略躲避局部惯例以发现更好的解决方案。这表明我们的目标固有动机可以为语言模型推理的探索提供可靠的支持。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18470", "html_url": "https://arxiv.org/abs/2510.18470", "title": "CircuitSeer: Mining High-Quality Data by Probing Mathematical Reasoning Circuits in LLMs", "title_en": "CircuitSeer: Mining High-Quality Data by Probing Mathematical Reasoning Circuits in LLMs", "authors": "Shaobo Wang,Yongliang Miao,Yuancheng Liu,Qianli Ma,Ning Liao,Linfeng Zhang", "background": "大型语言模型（LLMs）展示了出色的推理能力，但提升其性能往往依赖于大规模、计算成本高昂的推理数据集。现有的数据选择方法旨在精选更小、高质量的子集，但通常依赖于昂贵的外部模型或不透明的启发式方法。这项工作中，研究人员发现复杂的推理任务激活了模型内部机制中的稀疏、专门化的注意力头子集，形成了核心推理电路。基于这一发现，他们提出了CircuitSeer，一种新型的数据选择方法，通过测量数据对这些关键电路的影响来量化推理复杂性。", "innovation": "提出了CircuitSeer，一种新的数据选择方法，通过测量数据对核心推理电路的影响来量化推理复杂性。该方法不依赖于外部启发式方法，而是利用模型内部机制。实验证明，CircuitSeer具有优越性。利用该方法仅对数据集的10%进行微调，Qwen2.5-Math-7B模型在平均Pass@1指标上获得了1.4分的提升，突显了其效率和效果。", "conclusion": "CircuitSeer通过识别模型内部的关键推理电路，有效筛选出高质量的数据，提高了训练效率和模型性能。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18988", "html_url": "https://arxiv.org/abs/2510.18988", "title": "实时临床诊断通过主动测试选择", "title_en": "Timely Clinical Diagnosis through Active Test Selection", "authors": "Silas Ruhrberg Estévez,Nicolás Astorga,Mihaela van der Schaar", "background": "尽管机器学习在支持临床诊断方面引起了广泛关注，但大多数现有方法依赖静态、完全观察的数据集，未能反映临床医生在实际工作中基于顺序和资源的推理。复杂的诊断过程和高压力或资源受限的环境中常伴随着高错误率，突显了需要帮助临床医生做出及时和成本效益决策的框架的重要性。", "innovation": "提出了ACTMED（基于模型实验设计的自适应临床测试选择），这是一种将贝叶斯实验设计（BED）与大型语言模型（LLMs）相结合的诊断框架，旨在更好地模拟现实世界的诊断推理。每一步，ACTMED都会选择预期能最大程度减少诊断不确定性的一次测试。LLMs充当灵活的模拟器，生成可能的患者状态分布，并支持信念更新，而无需结构化的、任务特定的训练数据。临床医生可以保持参与，审查测试建议，解释中间输出，并在整个过程中应用临床判断。研究表明，ACTMED可以优化测试选择，提高诊断准确性、可解释性和资源利用。", "conclusion": "这代表了一种朝着透明、自适应且临床医生导向的诊断系统的进步，减少了对特定领域数据的依赖，并在多种环境中具有泛化能力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19562", "html_url": "https://arxiv.org/abs/2510.19562", "title": "DAIL：超越任务歧义的语言条件强化学习", "title_en": "DAIL: Beyond Task Ambiguity for Language-Conditioned Reinforcement Learning", "authors": "Runpeng Xie,Quanwei Wang,Hao Hu,Zherui Zhou,Ni Mu,Xiyun Li,Yiqin Yang,Shuang Xu,Qianchuan Zhao,Bo XU", "background": "智能代理理解和执行自然语言指令是一项关键能力。然而，语言指令的灵活性导致了跨语言条件任务的巨大歧义，从而严重降低了算法性能。现有方法在处理这些歧义时存在局限性，因此亟需新的方法来解决这一问题，以提升任务执行的清晰度和性能。", "innovation": "本文提出了一种名为DAIL（分布性对齐学习）的新方法，包含两个关键组件：分布性策略和语义对齐。通过理论证明，DAIL通过价值分布估计机制增强任务可区分性，并利用语义对齐模块捕捉轨迹与语言指令之间的对应关系。实验结果表明，DAIL在结构化和视觉观察基准测试中均取得显著的效果，优于基线方法。", "conclusion": "DAIL有效解决了指令歧义问题，在不同的任务和观测数据上均展示了优越的性能。该实施代码可在给定的URL地址中找到。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18254", "html_url": "https://arxiv.org/abs/2510.18254", "title": "表象中的反思：开放任务揭示大型语言模型在反思推理方面的系统性失败", "title_en": "Illusions of reflection: open-ended task reveals systematic failures in Large Language Models' reflective reasoning", "authors": "Sion Weatherhead,Flora Salim,Aaron Belbasis", "background": "现有的大型语言模型能够产生推理文本和反映性文本，这被称为反思。然而，这些模型是否与人类的反思性推理在功能上是等效的？过往的研究主要集中在封闭任务上，这些任务具有明确的外在正确性信号，因此使反思看起来有效，但掩盖了自我纠正的局限性。因此，本研究对八个前沿模型进行了测试，考察其在一个简单的真实世界任务中的表现，该任务是开放的但受限的，具有可稽核的成功标准：生成有效的科学测试题目，然后在其自我批判中进行修改。首次尝试的表现很差（通常4项要求下几乎没有有效的项目；平均值约为1），反思仅带来了轻微的改进（也约为1）。最关键的是，第二次尝试频繁重复相同的约束违反，表明“纠正收益”主要是随机产生一个有效项目的结果，而不是错误检测和基于原则、敏感约束的修复。随着开放性的增加，反思前后的表现都恶化了，而主打‘推理’功能的模型并未表现出优势。这些结果表明，当前的LLM的‘反思’缺乏功能性的证据，证明了人类如何通过主动、目标驱动的监控在初次尝试时尊重约束。直到这种机制本身被实现，模型才能在保证约束的情况下可靠地表现。因此，需要外部结构来强制约束，以确保可靠性能。该研究的代码可在以下链接获取：this https URL", "innovation": "研究设计了一个明确的、开放且规则受限的真实世界任务，来测试大型语言模型的反思性推理能力。通过与人类语言的对比，揭示了大型语言模型在反思推理方面的局限性，特别是在面对开放任务时的表现。这一新颖的测试方法为理解大型语言模型的反思过程提供了新的视角，揭示了它们仍然存在的问题和改进空间。", "conclusion": "当前的大型语言模型在开放任务中的反思推理能力主要依赖于幸运的生产，而不是真正的错误检测和基于原则、敏感约束的修复。因此，这些模型缺乏有效监控的能力，尤其是在初次尝试时，无法确保正确性。解决这一问题需要在模型中实现类似人类的主动目标驱动的监控机制，同时也需要外部结构的强制性约束以确保可靠性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19788", "html_url": "https://arxiv.org/abs/2510.19788", "title": "世界模型学习基准测试", "title_en": "Benchmarking World-Model Learning", "authors": "Archana Warrier,Dat Nguyen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares", "background": "当前用于学习和评估世界模型的方法与模型学习的目标相偏离，当前方法主要关注下一帧预测，并通过在相同环境中的奖励最大化来评估模型成功。这导致模型缺乏对多种下游任务的支持，尤其在未观察到的状态预测、行动长期后果估计、行动序列规划及动态变化检测等方面。因此，需要一种新的评估模型的方法，能够体现出模型对未知任务的支持能力，同时也避免了特定表征模型的表现偏见，以评估模型学习环境动力学的能力。", "innovation": "该论文提出了WorldTest协议，该协议将未获得奖励的交互与一个得分的测试阶段分开，测试阶段在不同的但相关环境中进行。WorldTest是开放式的，模型应该支持很多不同的任务且未知，同时对于模型表示是中立的，这使得模型可以通过行为评分进行比较。它还提供了AutumnBench，这是由43个互动网格世界环境和三个类别（遮罩帧预测、规划和因果动力学变化预测）中的129个任务组成的测试套件。", "conclusion": "人类参与者在AutumnBench上的表现优于模型，但在某些环境中，计算量的增加只能改善性能而不能在其他环境中改善。WorldTest为评估模型学习环境动力学提供了新的框架，其中包括无奖励探索、导出的测试和基于行为的评分，并展示了世界模型学习中的显著潜力差距。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.14144", "html_url": "https://arxiv.org/abs/2406.14144", "title": "从安全神经元视角理解安全对齐：一种机制性观点", "title_en": "Towards Understanding Safety Alignment: A Mechanistic Perspective from Safety Neurons", "authors": "Jianhui Chen,Xiaozhi Wang,Zijun Yao,Yushi Bai,Lei Hou,Juanzi Li", "background": "大型语言模型（LLMs）表现出色，但在安全方面存在风险，如生成有害内容和错误信息，即使经过安全对齐后仍然存在。本文通过机制性可解释性探索安全对齐的内部机制，重点关注LLMs中负责安全行为的安全神经元的识别与分析。", "innovation": "提出了一种推理时激活对比（inference-time activation contrasting）方法来定位这些神经元，并使用动态激活补丁（dynamic activation patching）来评估它们对模型安全性的因果影响。实验表明，可以一致地识别大约5%的安全神经元，并通过修补它们的激活可以在不影响通用能力的情况下恢复超过90%的安全性能。此外，发现安全神经元有助于解释“对齐税”现象，揭示模型安全性和有用性关键神经元的高度重叠性，但所需的激活模式不同。", "conclusion": "该研究揭示了安全神经元的发现及其在保护LLMs中的应用，可以在生成之前检测不安全的输出。源代码可在该网址获取：this https URL."}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.05056", "html_url": "https://arxiv.org/abs/2410.05056", "title": "α-混动性在随机迭代中的转移及其在排队理论中的应用", "title_en": "Transition of $α$-mixing in Random Iterations with Applications in Queuing Theory", "authors": "Attila Lovas", "background": "非线性时间序列模型在诸如计量经济学、排队理论和机器学习等领域中非常重要，尽管它们的统计分析尚不完整。关键结果，如大数定律和函数中心极限定理，主要适用于弱依赖变量。研究指出，通过耦合论证可以将外生回归变量的混动性质转移到响应变量。同时，研究了在随机环境中的非平稳马尔可夫链及其漂移和极小化条件，并将其框架应用于单服务队列模型中。", "innovation": "本文通过耦合论证展示了外生回归变量的混动性质如何转移到响应变量。研究了在非平稳环境中的随机环境中的马尔可夫链，且即使在有利的混动性质下也能应用漂移和极小化条件，这促进了单服务队列模型的应用研究。", "conclusion": "本文的结果扩展了现有对于非线性时间序列模型中外生回归变量的研究，特别是在随机环境和非平稳条件下应用混动性质的新方法，并将这种框架应用于单服务队列模型，进一步丰富了排队理论的应用范围。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.05500", "html_url": "https://arxiv.org/abs/2410.05500", "title": "增强深度学习的残差柯尔莫哥洛夫-阿诺尔德网络", "title_en": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning", "authors": "Ray Congrui Yu,Sherry Wu,Jiang Gui", "background": "尽管深度卷积神经网络（CNNs）取得了巨大成功，但由于网络内部含有数百层，优化和训练起来仍然很困难且成本高昂。传统的卷积操作本质上受限于其线性性质和固定的激活函数，许多层需要学习数据中的有意义模式。由于这些网络的规模庞大，这种方法在计算上是低效的，并且在小数据集上存在过拟合或梯度爆炸的风险。", "innovation": "我们提出了一种名为残差柯尔莫哥洛夫-阿诺尔德网络（RKAN）的‘插件’模块。该模块结构紧凑，可以轻松地添加到传统深度网络的任何阶段或层级，学习对现有的卷积框架进行支持性的多项式特征转换。实验证明，RKAN在不同的视觉任务和广泛测试的基准测试中，相对于基线模型提供了一致的改进，实现了领先的性能。", "conclusion": "RKAN模块提供了一种有效地提升深度学习模型性能的方法，特别是对于具有大量层的网络，能够改进基线模型，在不同的视觉任务上实现了最先进的性能。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.00954", "html_url": "https://arxiv.org/abs/2406.00954", "title": "基于注释指南的知识增强：提升大型语言模型在教育文本分类中的性能", "title_en": "Annotation Guidelines-Based Knowledge Augmentation: Towards Enhancing Large Language Models for Educational Text Classification", "authors": "Shiqi Liu,Sannyuya Liu,Lele Sha,Zijie Zeng,Dragan Gasevic,Zhi Liu", "background": "各种机器学习方法在教育文本自动分类方面获得广泛应用，特别是在识别学习参与指标的领域，即学习参与分类（LEC）。LEC可以提供关于人类学习过程的全面见解，吸引了包括自然语言处理（NLP）、学习分析和教育数据挖掘在内的多个研究领域的广泛关注。近年来，大型语言模型（LLMs），如ChatGPT，在各种NLP任务中表现出色，但其在LEC任务中的全面评价与改进方法尚未得到充分研究。", "innovation": "本文提出了一种基于注释指南的知识增强（AGKA）方法来改进LLMs。AGKA利用GPT 4.0检索注释指南中的标签定义知识，并采用随机下采样选择典型实例。此外，研究还进行了LEC系统的系统性基准评估，涵盖了六种LEC数据集，内容包括行为分类（问题、急迫程度）、情感分类（二元和元情感）和认知分类（意见、认知存在）。结果显示，AGKA可以增强未微调的LLMs，特别是GPT 4.0和Llama 3 70B。AGKA辅助的少量示例表明，在简单的二元分类数据集中，GPT 4.0的性能优于完全微调的BERT和RoBERTa模型。但在需要深刻理解复杂语义信息的多类任务中，GPT 4.0表现不佳。值得注意的是，基于开源LLM的Llama 3 70B与AGKA相结合是很有前景的组合，其性能与其闭源的GPT 4.0相当。此外，LLMs在多类分类中难以区分具有相似名称的标签。", "conclusion": "总的来说，AGKA方法在提升未微调的大型语言模型在简单二元分类任务中的性能方面表现出优势，虽然在多类任务中表现出局限性，但基于开源模型的AGKA可能提供一种成本更低且性能相近的替代方案。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.12961", "html_url": "https://arxiv.org/abs/2405.12961", "title": "通过连续反馈对变压器进行能量排名对齐", "title_en": "Aligning Transformers with Continuous Feedback via Energy Rank Alignment", "authors": "Shriram Chennakesavalu,Frank Hu,Sebastian Ibarraran,Grant M. Rotskoff", "background": "化学空间搜索是一个极其具有挑战性的问题，因为可能的分子数量随原子数量呈组合性增长。虽然大型自回归模型在化学化合物数据库上的训练已经产生了强大的生成器，但我们仍然缺乏可靠的方法来生成具有特定属性的分子。此分子搜索问题类似于大型语言模型的“对齐”问题，但对于许多化学任务我们有特定且容易评估的奖励函数。", "innovation": "我们引入了一种名为能量排名对齐（ERA）的新算法，该算法利用显式的奖励函数来生成梯度基目标，用于优化自回归策略。理论分析表明，该算法与近端策略优化（PPO）和直接偏好优化（DPO）密切相关，但其最小化器会收敛到一个理想中的吉布斯-玻尔兹曼分布，奖励函数在此扮演能量函数的角色。此外，该算法具有很高的可扩展性，不需要强化学习，并且当每对的偏好观察次数较少时，与DPO相比表现良好。我们用这种方法对分子变压器和蛋白质语言模型进行了对齐，以生成具有外部指定属性的分子和蛋白质序列，发现其表现稳健，能够探索化学空间的多样化部分。", "conclusion": "ERA算法通过引入显式的奖励函数，成功地优化了自回归策略，通过理论上与PPO和DPO的联系，其最小化器能够收敛到理想中的吉布斯-玻尔兹曼分布，适用于强化学习之外的场景，并且在特定条件下比DPO表现更优。此外，该算法能够对分子和蛋白质序列进行有效对齐，生成具有特定属性的分子和序列，表现出强大的泛化能力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.11843", "html_url": "https://arxiv.org/abs/2411.11843", "title": "Bi-Mamba: 向量化的1位状态空间模型", "title_en": "Bi-Mamba: Towards Accurate 1-Bit State Space Models", "authors": "Shengkun Tang,Liqun Ma,Haonan Li,Mingjie Sun,Zhiqiang Shen", "background": "现有的选择性状态空间模型（SSM）在Mamba中被用来解决Transformer的一些限制，比如序列长度相关的二次计算复杂度和推理期间由于键值（KV）缓存而导致的大量内存需求。然而，Mamba模型规模的持续扩大对训练和部署带来了挑战，特别是在训练和推理过程中计算需求巨大。", "innovation": "本文介绍了一种可扩展且强大的1位Mamba架构$\texttt{Bi-Mamba}$，旨在使大型语言模型（LLM）更加高效，其模型大小为780M，1.3B和2.7B参数。$\texttt{Bi-Mamba}$模型是通过使用自动回归蒸馏损失从标准的语言模型规模数据集重新训练的。实验证明，$\texttt{Bi-Mamba}$在语言模型基准测试中的性能可与全精度（FP16或BF16）模型相媲美，并且优于后训练二值化（PTB）Mamba和二值化感知训练（BAT）Transformer基线。此外，$\texttt{Bi-Mamba}$相比于原始的Mamba大大减少了内存使用和计算成本。", "conclusion": "我们的研究开拓了一条具有线性复杂度的低位表示语言模型的新领域，并为其设计专门的硬件提供了可能，优化1位Mamba为基础的模型的效率。所有代码和预训练权重都可以通过链接获取。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.07812", "html_url": "https://arxiv.org/abs/2410.07812", "title": "基于时差法的变分持续学习", "title_en": "Temporal-Difference Variational Continual Learning", "authors": "Luckeciano C. Melo,Alessandro Abate,Yarin Gal", "background": "在实际应用中，机器学习模型需要持续学习新的任务以适应数据生成分布的变化。然而，对于持续学习（CL），模型在学习新任务的同时需要保留已有的知识，这种平衡需要解决，并且模型常常容易出现灾难性遗忘（Catastrophic Forgetting），导致性能下降，影响部署系统的可靠性。在贝叶斯持续学习领域，变分方法通过递归更新后验分布并将其保持在接近之前估计的约束下以解决这一挑战。但是，这些方法可能因递归过程中累积的近似误差而失效。因此，针对这一问题，该论文提出了一种新的学习目标，通过整合多个先前后验估计的正则化效果，防止单一误差在未来的后验更新中成为主导并随时间累积。研究表明，这种方法有效地缓解了灾难性遗忘，优于现有的强变分持续学习方法。", "innovation": "提出了一种新的学习目标，该目标整合了多个先前后验估计的正则化效应，以避免单一错误在未来的后验更新中累积并成为主导。这种方法表明，与变分持续学习方法相比，它可以有效缓解灾难性遗忘。此外，还发现新的学习目标与时差方法之间存在有趣的联系，时差方法是强化学习和神经科学中流行的学习机制。", "conclusion": "该方法在挑战性的持续学习基准测试中表明了有效缓解灾难性遗忘的能力，并且在多个测试场景中优于现有的强变分持续学习方法，进一步证明了其在持续学习领域的创新性贡献。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.09805", "html_url": "https://arxiv.org/abs/2412.09805", "title": "经典GNN在不同同质性水平下的强基线：平滑性-泛化视角", "title_en": "Making Classic GNNs Strong Baselines Across Varying Homophily: A Smoothness-Generalization Perspective", "authors": "Ming Gu,Zhuonan Zheng,Sheng Zhou,Meihan Liu,Jiawei Chen,Tanyu Qiao,Liangcheng Li,Jiajun Bu", "background": "图形神经网络（GNNs）取得了巨大成功，但通常被认为在不同同质性水平的图中面临挑战。最近的实证研究表明，在适当超参数调整的条件下，亲和GNN可以在不同同质性水平的数据集上表现出色，但这背后的理论和有效的架构仍然不清楚。为了在不同同质性水平上推进GNN的普遍性，我们重新审视了GNN的消息传递过程，并发现了增强的平滑性与泛化之间的矛盾，这使得学习在高阶同质和所有异质的高阶邻域中受到阻碍，因复杂邻域类分布对噪声和稀疏性引起的位移非常敏感。", "innovation": "我们提出了通过引入Inceptive Graph Neural Network（IGNN）来缓解平滑性和泛化之间的矛盾，IGNN基于三个简单的且有效的设计理念，同时提高了总体泛化能力，通过适应性平滑性增强了不同跳数的独立泛化。", "conclusion": "与30个基线进行基准测试，证明了IGNN的优越性，并揭示在某些亲和GNN变体中存在一定的普遍性。我们的代码和数据集可在以下地址获取：this https URL"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.07591", "html_url": "https://arxiv.org/abs/2502.07591", "title": "DMWM: 双心智世界模型与长期想象", "title_en": "DMWM: Dual-Mind World Model with Long-Term Imagination", "authors": "Lingyi Wang,Rashed Shelim,Walid Saad,Naren Ramakrishnan", "background": "世界模型在帮助代理学习长期策略时至关重要。现有基于递归状态空间模型(RSSM)的世界模型依赖于单一时间步统计推断来捕捉环境动力学，因此它们难以执行长期想象任务，且易累积预测误差。", "innovation": "基于人类认知的双重过程理论，提出了一个包含逻辑推理的双心智世界模型(DMWM)框架。该框架分为两个组成部分：采用RSSM方法处理直观状态转移的System 1 (RSSM-S1)，以及通过层次深度逻辑推理指导想象过程的逻辑整合神经网络System 2 (LINN-S2)。双心智机制确保想象过程遵循真实的环境逻辑规则。", "conclusion": "在DMControl基准任务上的广泛实验结果表明，提出的框架在逻辑一致性、试验效率、数据效率和长期想象方面显著优于现有最先进的世界模型。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.09389", "html_url": "https://arxiv.org/abs/2502.09389", "title": "S$^2$-Diffusion: Generalizing from Instance-level to Category-level Skills in Robot Manipulation", "title_en": "S$^2$-Diffusion: Generalizing from Instance-level to Category-level Skills in Robot Manipulation", "authors": "Quantao Yang,Michael C. Welle,Danica Kragic,Olov Andersson", "background": "近年来，技能学习的进步使机器人操作达到了新的高度，能够通过有限数量的演示学习复杂的操作任务。然而，这些技能通常限于训练数据中展示的具体动作、对象和环境实例，并且难以将这些技能转移到同一类别的其他实例中。", "innovation": "本文提出了一种开域Spatial-Semantic Diffusion策略（S$^2$-Diffusion），这种策略能够从具体实例级别的训练数据泛化到类别级别的数据，从而使技能能够在同一类别的不同实例之间进行迁移。该方法通过可提示的语义模块结合空间表示来捕获技能的功能特点，并利用深度估计算法仅使用单个RGB摄像头来实现。", "conclusion": "我们的结果表明，S$^2$-Diffusion对于类别无关的因素变化具有不变性，并且能够在同一类别的其他实例上实现令人满意的性能，即便没有针对特定实例进行训练。这表明S$^2$-Diffusion策略在机器人操作技能的通用性方面取得了重要进展。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.01243", "html_url": "https://arxiv.org/abs/2501.01243", "title": "Face-Human-Bench：多模态助手中面部和人类理解的综合基准", "title_en": "Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants", "authors": "Lixiong Qin,Shilong Ou,Miaoxuan Zhang,Jiangning Wei,Yuhang Zhang,Xiaoshuai Song,Yuchen Liu,Mei Wang,Weiran Xu", "background": "面部和人类在社会互动中起着关键作用，并广泛出现在日常生活中的照片和视频中。因此，对面部和人类的深入理解可以提高多模态助手的响应质量并拓宽应用范围。但是，目前多模态助手社区缺乏对面部和人类理解能力的全面科学评估。文章通过提出一个包含三个能力层级的层级能力分类法，并基于此分类法构建了一个半自动数据管道来收集问题，从而建立了新的基准Face-Human-Bench，包括训练集和测试集，每个集包含1800个问题，支持中英文。此外，研究还开展了对25种主流多模态大型语言模型（MLLMs）的评估，重点关注能力间的相关性，目标相对位置对性能的影响，以及Chain of Thought（CoT）提示对性能的影响，并探讨哪些MLLMs的能力需要由专家模型进行补充。", "innovation": "首次提出了一个层级能力分类法，包含三个能力层级；建立了新的半自动数据管道以产生问题，构建了面向多模态助手的Face-Human-Bench基准；评估了25种主流MLLMs在面部和人类理解方面的表现；研究了链式思考提示对性能的影响，并探讨了需要由专家模型补充的能力类型。", "conclusion": "Face-Human-Bench数据集和评估代码已被公开，为多模态助手领域的研究者和开发者提供了重要的参考和评估工具，有助于推动物模态助手领域的发展和改进。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.19258", "html_url": "https://arxiv.org/abs/2410.19258", "title": "逐头KV缓存压缩方法：集成检索与推理的能力", "title_en": "Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning", "authors": "Yu Fu,Zefan Cai,Abedelkadir Asi,Wayne Xiong,Yue Dong,Wen Xiao", "background": "大型语言模型（LLMs）计算效率的提升通常依赖于键值（KV）缓存，但随着输入长度的增加，其内存开销快速增长。尽管已有研究表明并非所有词元在文本生成中都同等重要，因此提出了一种按层级别的KV缓存压缩方法以选择性地保留关键信息，但由于不同注意力头在生成过程中的作用存在差异，还缺乏针对性的方法来优化这些角色。", "innovation": "本文提出了一种名称为HeadKV的逐头级别KV缓存压缩方法，以及一种结合新颖的上下文推理能力估计的HeadKV-R2方法。该方法通过对每个头的重要性进行评估，应用于上下文问答任务，该任务不仅要求检索能力还要求推理能力。实验结果表明，与现有的强大基准方法相比，本文提出的方法在低资源环境下表现出显著的优势，特别是在KV缓存大小为64及128的情况下，仅保留1.5%的缓存即可达到近乎满缓存的性能水平（在上下文问答基准测试中达到97%）", "conclusion": "本文提出的方法在广泛的任务集和模型架构上都得到了验证，表现出显著的优势，特别是在低资源条件下。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.13251", "html_url": "https://arxiv.org/abs/2502.13251", "title": "神经注意力搜索", "title_en": "Neural Attention Search", "authors": "Difan Deng,Marius Lindauer", "background": "本文介绍了Neural Attention Search（NAtS）框架，该框架可以自动评估序列中每个令牌的重要性，并决定在多次步骤后哪些令牌可以被移除。这种方法可以在推理阶段有效减少基于变压器的模型所需的KV缓存大小，从而减少推理成本。研究中设计了一个包含三种令牌类型的搜索空间：全局令牌、局部令牌和滑动窗口令牌。", "innovation": "NAtS框架能够根据学习到的可学习注意力掩码，联合学习令牌类型信息和架构权重，自动评估序列中每个令牌的重要性，并决定哪些令牌可以在推理阶段移除。实验结果表明，NAtS可以在保持模型性能的同时，有效地减少所需的KV缓存大小。", "conclusion": "通过设计包含三种不同类型的令牌的搜索空间，NAtS可以在推理时高效地减少基于变压器的模型的KV缓存需求，从而降低推理成本。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.11554", "html_url": "https://arxiv.org/abs/2502.11554", "title": "为语音用户界面探索动态元喻对话设计", "title_en": "Toward Metaphor-Fluid Conversation Design for Voice User Interfaces", "authors": "Smit Desai,Jessie Chin,Dakuo Wang,Benjamin Cowan,Michael Twidale", "background": "元喻在塑造用户与语音用户界面（VUIs）的体验中起着关键作用，但现有的设计常常依赖固定、以人为中心的元喻，未能适应多样化的使用情境和用户需求。当前的VUIs通常围绕助手的人设进行设计，提供统一的交互风格，但这一方法不能满足所有情境下的用户需求。为解决这一问题，本研究通过探索一种新的设计方法——动态元喻设计（Metaphor-Fluid Design），以适应不同的对话使用情境，设计了一种可以根据对话使用情境动态调整元喻表示的方法。在两个实验中研究了动态元喻设计与传统默认VUI之间的差异，结果发现动态元喻设计更符合不同情境下用户对于交互风格的期望，但个体间对元喻的偏好差异也强调了个性化设计的重要性。", "innovation": "本研究提出了一种新的设计方法——动态元喻设计，它可以根据对话使用情境动态调整元喻表示，相较于传统默认的VUI设计，能够更好地适应多样化的情境，满足用户的不同需求。这种新的设计方法挑战了VUI设计中的一刀切模式，并展示了动态元喻设计在创建更具适应性和互动性的交互方面的潜力。", "conclusion": "研究结果表明，动态元喻设计在提高用户意图接纳、愉悦感和好感度方面具有优势，但个体间对元喻的偏好差异也揭示了个性化设计的重要性。这项研究表明，目前VUI设计中的一刀切思路值得反思，未来的设计研究应更加重视用户的个性需求和发展更具适应性的交互方式。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15090", "html_url": "https://arxiv.org/abs/2502.15090", "title": "ExpertLens：激活引导特征具有很高的可解释性", "title_en": "ExpertLens: Activation steering features are highly interpretable", "authors": "Masha Fedzechkina,Eleonora Gualdoni,Sinead Williamson,Katherine Metcalf,Skyler Seto,Barry-John Theobald", "background": "在大型语言模型（LLMs）中，激活引导方法（activation steering methods）作为一种有效的更新方式被引入，这种方式可以通过少量的适应数据对生成的语言进行有针对性的改进。然而，这些方法发现的功能是否具有可解释性尚不清楚。", "innovation": "作者使用了“寻找专家”方法来识别特定概念（如“猫”）相关的神经元，并通过检查这些神经元（即ExpertLens）来提供关于模型表示的见解。研究发现，ExpertLens的表现对模型和数据集的稳定性较高，并且与来自行为数据的人类代表有密切的对齐水平，显著优于单词/句子嵌入捕捉的对齐程度。重建人类概念组织的通过ExpertLens，表明它有助于对LLM概念表述进行精细的审视。", "conclusion": "研究结果表明，ExpertLens是一种灵活且轻量级的方法，用于捕捉和分析模型表示。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.17213", "html_url": "https://arxiv.org/abs/2502.17213", "title": "深度学习驱动的电生理脑信号分析：推进神经诊断", "title_en": "Deep Learning-Powered Electrical Brain Signals Analysis: Advancing Neurological Diagnostics", "authors": "Jiahe Li,Xin Chen,Fanqi Shen,Junru Chen,Yuxin Liu,Daoze Zhang,Zhizhang Yuan,Fang Zhao,Meng Li,Yang Yang", "background": "神经疾病在全球范围内构成重大健康挑战，推动了脑信号分析的进步。头皮脑电图（EEG）和颅内脑电图（iEEG）广泛应用于诊断和监测。然而，数据集异质性和任务变化阻碍了稳健的深度学习解决方案的发展。", "innovation": "综述了基于EEG/iEEG的神经诊断中深度学习方法的最新进展，涵盖了7种神经条件下的46个数据集，详细回顾了代表性方法及其定量结果，分析了数据利用、模型设计和任务特定适应，并强调了预训练多任务模型在实现可扩展和泛化解决方案中的作用。", "conclusion": "提出了标准化基准以在不同数据集上评估模型，提高可重复性，强调了最近创新如何将神经诊断转变为智能、可适应的医疗保健系统。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01002", "html_url": "https://arxiv.org/abs/2504.01002", "title": "token嵌入违背流形假设", "title_en": "Token embeddings violate the manifold hypothesis", "authors": "Michael Robinson,Sourya Dey,Tony Chiang", "background": "深入理解大型语言模型（LLM）的行为需要掌握其输入的标记空间。如果该空间与我们的假设不同，我们对LLM的理解和结论将会出现偏差。本文旨在通过实证和理论分析阐明标记嵌入的结构。", "innovation": "本文提出了一个新颖的统计测试，假设每个标记周围的局部结构是相对平坦和平滑的（作为零假设）。当零假设被拒绝时，意味着在特定标记ψ的邻域B(ψ)中存在局部结构的异常。本文进一步将零假设中假设的结构称为“光滑纤维丛”，对未来测试进行定义。通过在多个开源LLM上运行此测试，发现零假设经常被拒绝，从而表明局部结构不是光滑纤维丛，也非流形。", "conclusion": "根据我们的研究结果，当LLM接收到两个语义等价的提示时，如果其中一个提示包含被测试标记，该提示生成的响应将比另一个提示更加不稳定。因此，我们得出结论，令牌子空间不是纤维丛，也不是流形。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.12474", "html_url": "https://arxiv.org/abs/2504.12474", "title": "BiGTex在文本标注图中的结构和语义信号集成", "title_en": "Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex", "authors": "Azadeh Beiranvand,Seyed Mehdi Vahidipour", "background": "文本标注图（TAGs）在表示学习中具有独特挑战，需要模型同时捕捉节点关联文本的语义丰富性和图结构的依赖性。图神经网络（GNNs）擅长建模拓扑信息，但无法处理未结构化的文本。相比之下，大型语言模型（LLMs）擅长文本理解，但通常不关注图结构。因此，本文探讨了如何将GNNs和LLMs结合，提出了一种名为BiGTex的新架构。", "innovation": "提出了一种新的架构BiGTex，该架构通过堆叠Graph-Text Fusion Units紧密结合了GNNs和LLMs。每个单元允许文本和结构代表之间的相互注意，使信息可以双向流动，文本影响结构，结构指导文本解释。此外，通过参数高效微调（LoRA）训练模型，保持LLM固定，适应任务特定信号。", "conclusion": "在五个基准数据集上的实验表明，BiGTex在节点分类中达到了最先进的性能，并且能够有效地泛化到链接预测。进一步的消融研究还强调了软提示和双向注意在模型成功中的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15984", "html_url": "https://arxiv.org/abs/2503.15984", "title": "DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration", "title_en": "DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration", "authors": "Suraj Singh,Anastasia Batsheva,Oleg Y. Rogov,Ahmed Bouridane", "background": "现代图像恢复和超分辨率方法利用深度学习因其在性能上优于传统算法而被广泛应用。然而，深度学习方法通常需要大量训练数据，但在天文学摄影中这几乎是不可获得的。为了解决这个问题，Deep Image Prior (DIP) 可以通过在单个图像上进行盲训练来绕过数据需求的限制，尽管 DIP 在某些情况下效果良好，但它经常会出现过拟合、伪影生成和不稳定性的问题。", "innovation": "本文提出了一种新颖的框架DIPLI，它从单帧训练转向多帧训练，利用Back Projection技术，并结合TVNet模型的光学流动估计方法，以及使用Langevin动力学进行无偏蒙特卡洛估计来替换确定性预测。实验结果表明，该方法在合成数据集上的表现优于多种基线方法，特别是在SSIM、PSNR、LPIPS和DISTS指标方面，同时输入图像数量大大减少，且抗过拟合和伪影生成能力更强。在实际天文学数据上的测试结果也证实了方法的高重构质量和实用鲁棒性。", "conclusion": "实验结果表明，DIPLI方法在SSIM、PSNR、LPIPS和DISTS等图像质量评估指标方面表现优越，不仅图像恢复质量更高，所需输入图像数量也更少，且抗过拟合和伪影生成能力更强。在实际天文学数据上的实验证明了该方法的实用鲁棒性，能够维持高图像重建质量。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.18458", "html_url": "https://arxiv.org/abs/2504.18458", "title": "FAST-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "title_en": "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "authors": "Wenyi Xiao,Leilei Gan", "background": "在应用强化学习（通常通过GRPO）到大规模视觉语言模型推理时，难以有效扩展推理长度或产生冗长的输出，即使在所有任务上也仅获得微小的准确率提升。", "innovation": "我们提出了FAST-GRPO，这是GRPO的变体，能够根据问题特性动态调整推理深度。通过引入适应性长度奖励和难度感知的KL散度，针对七大推理基准实验表明，FAST达到了最先进的准确率，与基线模型相比相对提高了10%以上，同时减少了32.7%-67.3%的标记使用，有效地平衡了推理长度和准确率。我们还引入了两个互补的度量标准来估计问题的难度，指导模型确定何时采用快速或慢速思考更为合适。", "conclusion": "FAST-GRPO有效地解决了大规模视觉语言模型推理中的推理长度扩展和冗长输出问题，通过引入新的度量标准和算法改进，显著提高了准确率并优化了资源使用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.07260", "html_url": "https://arxiv.org/abs/2505.07260", "title": "UMoE：统一注意力模块和FFN模块的共享专家架构", "title_en": "UMoE: Unifying Attention and FFN with Shared Experts", "authors": "Yuanhang Yang,Chaozheng Wang,Jing Li", "background": "稀疏混合专家（MoE）架构被证明是扩展变压器模型的一种有前途的方法。虽然早期的工作主要将MoE整合到前向网络（FFN）层中，但最近的研究已经探索了将MoE范式扩展到注意力层以提高模型性能的可能性。然而，现有的基于注意力的MoE层需要专门的实现，并且相比FFN基的版本表现出较差的性能。", "innovation": "本文提出了一个新颖的注意力机制的重新构建方法，揭示了注意力模块中内在的FFN结构。通过这种方法，作者提出的UMoE架构利用了基于注意力的MoE层，同时在FFN和注意力组件之间实现了高效的参数共享，从而达到了优越的性能。", "conclusion": "UMoE架构通过在FFN和注意力模块之间实现高效的参数共享，同时利用基于注意力的MoE层，实现了更好的性能表现。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.09131", "html_url": "https://arxiv.org/abs/2505.09131", "title": "通过对齐实现公平聚类", "title_en": "Fair Clustering via Alignment", "authors": "Kunwoong Kim,Jihu Lee,Sangchul Park,Yongdai Kim", "background": "算法公平性在聚类中的目标是按给定的敏感属性平衡每类中实例的比例。虽然最近开发的公平聚类算法在特定公平性约束下优化聚类目标，但由于其内在的复杂性或近似性，它们往往导致实际中的聚类性能不佳或数值不稳定。", "innovation": "本文提出了一种新的公平聚类算法——公平聚类通过对齐(Fair Clustering via Alignment, FCA)。该算法通过交替执行两个步骤来工作：(i) 寻找联合概率分布以对齐来自不同受保护群体的数据；(ii) 在对齐的空间中优化聚类中心。FCA的一个主要优势是，理论上可以在不使用复杂约束的情况下，确保任何给定公平水平下的近似最优聚类性能，从而在实践中实现高效益的公平聚类。", "conclusion": "实验结果表明，FCA方法在公平性和聚类性能之间提供了更优的平衡，并且能够在无数值不稳定的情况下实现接近完美的公平性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.01618", "html_url": "https://arxiv.org/abs/2505.01618", "title": "不要懒惰：CompleteP实现高效计算的深度变压器", "title_en": "Don't be lazy: CompleteP enables compute-efficient deep transformers", "authors": "Nolan Dey,Bin Claire Zhang,Lorenzo Noci,Mufan Li,Blake Bordelon,Shane Bergsma,Cengiz Pehlevan,Boris Hanin,Joel Hestness", "background": "研究在使用不同参数化（即调整模型和优化器超参数的规则）时，大型语言模型（LLM）训练的计算效率。部分参数化方式不能成功转移最优基础超参数（如学习率）以应对模型深度的变化，要求研究人员要么重新调整这些超参数（成本高昂），要么接受次优训练效果。即使某些参数化方式实现了超参数转移，研究显示参数化方式仍可能处于懒惰学习的阶段，即各层仅学习接近线性化的特征，限制了深度和非线性的有效使用。", "innovation": "提出并采用了名为CompleteP的参数化方法，实现了深度超参数转移和非懒惰学习在所有层中的应用。CompleteP拓宽了模型宽高比，使其在各种硬件配置和操作环境中保持计算效率，并实现了相对于现有最佳状态的12-34%计算效率提升。所有实验均在Cerebras CS-3系统上进行。提供了一个最小的实现版本供参考。", "conclusion": "CompleteP参数化方式不仅实现了深度超参数的有效转移和全层的非懒惰学习，还扩大了计算效率的模型尺寸配置范围，更适合不同硬件配置和操作环境。实验表明，相比先前的最佳方法，CompleteP提升了12-34%的计算效率。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06520", "html_url": "https://arxiv.org/abs/2505.06520", "title": "PRUNE: 基于补丁修复框架的神经网络可验证删除方法", "title_en": "PRUNE: A Patching Based Repair Framework for Certifiable Unlearning of Neural Networks", "authors": "Xuran Li,Jingyi Wang,Xiaohan Yuan,Peixin Zhang", "background": "在已经训练好的神经网络模型中去除特定的训练数据部分（即所谓的‘卸学’）通常是必要的，这主要是为了保护数据持有者的权利，避免数据被滥用。目前的卸学方法主要是通过训练剩余数据的新模型来实现，这种方式可能成本高昂且难以验证，特别是对于数据持有者或第三方审计者而言。本研究提出了一个新的视角，提出了一种基于‘补丁’插入的卸学新方法，通过给原始神经网络添加精确定制的‘补丁’来达到有针对性的‘遗忘’请求数据的效果。这种研究思路受神经网络修复研究线的启发，旨在找到对给定数据点进行卸学的最轻量级补丁，并且具有可验证的保证。此外，为了卸学大量的数据点（或整个类别），我们提出了一种逐步选择代表性数据点进行卸学的方法，从而达到总体卸学的效果。在多个分类数据集上的大量实验表明，该方法在保持模型性能的同时，能够实现可测量的卸学效果，且在效率和内存消耗方面与各种基准方法具有竞争力。", "innovation": "提出了一个基于补丁修复的框架（PRUNE），该框架旨在通过在原始神经网络中精心设计的‘补丁’来实现特定数据的卸学，为卸学过程提供了可验证的保证。此外，针对大量数据点或整个类别的卸学问题，提出了迭代选择小部分代表性的数据点进行卸学的方法，从而间接实现整体卸学效果。这种方法不仅简化了卸学过程，还保证了模型性能和效率，显著降低了卸学成本和验证难度。", "conclusion": "该研究通过引入PRUNE框架，有效解决了传统卸学方法中的成本高和验证难的问题，提供了一种新的卸学方式。实验结果证明，该方法在多个分类数据集上的卸学效果显著，同时保持了模型性能，并在效率和内存消耗上比较基准方法具有一定优势。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12226", "html_url": "https://arxiv.org/abs/2505.12226", "title": "浅层流匹配模型在逐层文本语音合成中的应用", "title_en": "Shallow Flow Matching for Coarse-to-Fine Text-to-Speech Synthesis", "authors": "Dong Yang,Yiyi Cai,Yuki Saito,Lixu Wang,Hiroshi Saruwatari", "background": "本文提出了浅层流匹配（SFM）机制，这是一种在粗到细生成框架中增强基于流匹配（FM）的文本到语音（TTS）模型的新机制。不同于传统FM模块利用弱生成器的粗表示作为条件，SFM从这些粗表示构造沿FM路径的中间状态。通过引入正交投影方法在训练过程中自适应确定这些状态的时间位置，并基于单段分片流进行原则性构造，从而在生成过程的后阶段集中计算资源。通过将SFM整合到多个TTS模型中，实验结果表明，SFM在客观和主观评估中都能提高语音自然度，并且使用自适应步长ODE求解器时，显著加快了推理速度。", "innovation": "本文提出的SFM机制，创新性地在FM路径上利用粗表示构建中间状态，并通过正交投影方法自适应确定这些状态的时间位置。此外，SFM从中间状态开始进行推理，而非纯噪声，从而使得计算资源集中在生成过程的后阶段。通过使用单段分片流进行原则性构造，SFM也使得复杂度降低，实现更加高效和自然的语音合成效果。", "conclusion": "实验结果证明，SFM机制在多个TTS模型中的应用能够显著提高语音自然度，并且结合自适应步长ODE求解器，使得推理速度大幅加快。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10465", "html_url": "https://arxiv.org/abs/2505.10465", "title": "superposition Yields Robust Neural Scaling", "title_en": "Superposition Yields Robust Neural Scaling", "authors": "Yizhou Liu,Ziming Liu,Jeff Gore", "background": "当前大规模语言模型（LLMs）的成功依赖于观察到较大的模型性能更好。然而，这一神经扩展定律的起源，即损失随模型大小以幂律的形式减少，仍未解释清楚。本文提出，表示的超叠加，即LLMs表示出比其维度更多的特征，可能是损失的关键贡献因素，并导致神经扩展。通过Anthropic的玩具模型，使用权重衰减来控制超叠加的程度，系统地研究了模型大小与损失之间的关系。在弱超叠加的情况下，只有当数据特征频率也呈幂律分布时，损失才遵循幂律。而在强超叠加的情况下，损失在广泛的数据特征频率分布下与模型维度呈反比关系，原因是表示向量之间的几何重叠。实验证明开源的大规模语言模型处于强超叠加状态下，具有与模型维度成反比的损失扩展，并且Chinchilla的扩展定律也与此行为一致。研究表明超叠加是神经扩展定律的核心驱动因素，为神经扩展定律何时可以改善及何时会失效提供了洞见。", "innovation": "本文提出了一种新的观点，即表示的超叠加是影响大规模语言模型性能的关键因素，而非只是模型大小的增加。通过使用Anthropic的玩具模型和权重衰减技术，系统地研究了模型大小与损失之间的关系，发现了在不同超叠加程度下，损失遵循的规律不同，特别是在强超叠加状态下，损失与模型维度之间存在反比关系，这是对现有神经扩展定律认知的突破。此外，研究还验证了开源语言模型和Chinchilla模型的行为与这一新的理论解释一致。", "conclusion": "这些研究结果确定了表示的超叠加是驱动神经扩展定律的关键因素，为理解神经扩展定律在何时能改善、何时会失效提供了重要的启示。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12944", "html_url": "https://arxiv.org/abs/2505.12944", "title": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs", "title_en": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs", "authors": "Jan Hagnberger,Daniel Musekamp,Mathias Niepert", "background": "求解时空依赖偏微分方程（PDEs）在稠密的空间域中是一个在气候建模和流体动力学等领域中非常重要的问题。然而，在物理空间中直接进行这些计算常常会带来显著的计算成本。为了解决这个问题，一些基于神经网络的代理模型被开发出来，它们在压缩的潜在空间中操作以解决PDE。尽管这些方法可以在一定程度上减少计算复杂性，但它们往往依赖于基于Transformer的注意力机制来处理不规则采样领域，进而增加了内存消耗。基于这一考虑，卷积神经网络能够实现内存高效的编码和解码功能，但它们仅限于规则的离散化。", "innovation": "我们提出了CALM-PDE模型，这种模型可以在压缩的潜在空间中有效解决任意离散化的PDE。该模型引入了一种新颖的连续卷积编码器-解码器架构，使用epsilon-邻域约束核，并学习将卷积操作应用于自适应和优化的查询点。与基于Transformer的方法相比，CALM-PDE在内存效率和推理时间效率方面都提供了显著的改进，同时在多个PDE测试中表现与现有基准方法相当或优于它们。", "conclusion": "我们展示了CALM-PDE的高效性和有效性，特别是在处理规则和不规则采样空间的PDE任务中。与基于Transformer的方法相比，CALM-PDE提供了一种更高效、更内存友好的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13358", "html_url": "https://arxiv.org/abs/2505.13358", "title": "Koopman Modeling for One-Step Offline Distillation of Diffusion-based Models", "title_en": "One-Step Offline Distillation of Diffusion-based Models via Koopman Modeling", "authors": "Nimrod Berman,Ilan Naiman,Moshe Eliasof,Hedi Zisling,Omri Azencot", "background": "扩散生成模型在生成任务中表现出色，但其迭代采样过程仍然非常计算密集。减轻这一成本的一种显着策略是蒸馏方法，特别是离线蒸馏在效率、模块化和灵活性方面具有优势。扩散模型通常被视为动力系统理论的一部分，但它们在潜在空间中的结构和语义一致性轨迹尚未得到充分利用。", "innovation": "本文提出了一种新型的离线蒸馏方法——Koopman Distillation Model (KDM)，它基于Koopman理论，在变换的空间中以线性方式表示非线性动力系统。这种方法通过嵌入空间中的单一步骤生成过程保留了语义的一致性，同时提供了理论上的合理性：在轻微假设下，学习到的动力系统动态可以表示为有限维的Koopman表示；潜在空间的邻近性与生成输出的语义相似性相关，有助于有效轨迹对齐。KDM在标准的离线蒸馏基准测试中达到了竞争力的表现。", "conclusion": "KDM在标准离线蒸馏基准测试中的性能表现非常出色，它提供了一种高效的策略来减轻扩散模型的计算成本，同时保留了生成数据的语义一致性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13938", "html_url": "https://arxiv.org/abs/2505.13938", "title": "CLEVER：形式验证代码生成的精心整理基准", "title_en": "CLEVER: A Curated Benchmark for Formally Verified Code Generation", "authors": "Amitayush Thakur,Jasper Lee,George Tsoukalas,Meghana Sistla,Matthew Zhao,Stefan Zetzsche,Greg Durrett,Yisong Yue,Swarat Chaudhuri", "background": "本文介绍了${\rm C{\rm LEVER}}$，这是为Lean中端到端验证代码生成设计的一个高质量、精心整理的基准，包含161个问题。这些基准避免了以往基准中存在的一些问题，比如测试用例监督、通过大型语言模型生成的注释、以及泄露实现逻辑的规范等。所有输出都使用Lean的类型检查器进行后验验证，确保机器可检查的正确性。", "innovation": "CLEVER基准的独特之处在于其避免了以往基准中的一些常见问题，并且所有输出都经过Lean类型的检查器验证，确保了机器可检查的正确性。此外，它用于评估基于最新语言模型的少数样本和代理方法，确立了程序合成和形式推理挑战领域的一个难题。", "conclusion": "本文通过${\rm C{\rm LEVER}}$基准评估了若干基于最新语言模型的少数样本和代理方法。这些方法在完全验证方面表现出色不足，这表明${\rm C{\rm LEVER}}$是一个具有挑战性的前沿基准。本文的基准已发布在GitHub(this https URL)和HuggingFace(this https URL)上。评估代码也在线上提供(this https URL)。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15034", "html_url": "https://arxiv.org/abs/2505.15034", "title": "RL Tango: 同时强化生成器和验证器以提高语言推理能力", "title_en": "RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning", "authors": "Kaiwen Zha,Zhengqi Gao,Maohao Shen,Zhang-Wei Hong,Duane S. Boning,Dina Katabi", "background": "近年来，强化学习（RL）被证明是一种增强大语言模型（LLMs）推理能力的有效方法。在这样一个模型中，一个LLM生成器由一个验证程序（奖励模型）引导进行策略生成。但当前的RL后训练方法通常使用固定的验证器（基于规则或冻结预训练）或者通过监督微调（SFT）进行有区分的训练。这些方法容易受到奖励作弊的影响，并且在训练分布之外泛化能力较差。", "innovation": "本文提出了Tango，这是一种新的框架，通过交互的方式同时训练LLM生成器和验证器。Tango的核心创新在于其过程级的生成型验证器，该验证器通过强化学习训练并与其生成器协同进化。重要的是，验证器仅基于结果级验证的正确性奖励进行训练，而不需要显式的过程级标注。这种方法增强了验证器的鲁棒性和泛化能力，促进了生成器的有效互励。", "conclusion": "广泛的实验表明，Tango的两个组件都达到了7B/8B规模模型中的最佳效果：生成器在五个竞争力级别的数学基准测试和四项具有挑战性的域外推理任务中表现最佳，而验证器在ProcessBench数据集上表现出色。特别是在最难的数学推理问题上，两者的改进尤为显著。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14827", "html_url": "https://arxiv.org/abs/2505.14827", "title": "超越离散标记采样的文本生成", "title_en": "Text Generation Beyond Discrete Token Sampling", "authors": "Yufan Zhuang,Liyuan Liu,Chandan Singh,Jingbo Shang,Jianfeng Gao", "background": "在标准的自回归生成中，语言模型（LLM）预测下一个标记的概率分布，选择一个离散标记，然后丢弃该分布，仅将所选标记作为新的输入传递。这种方法导致丢弃了有用的分布信息。为解决该问题，本文提出了Mixture of Inputs（MoI）方法，该方法是一个无需训练的自回归生成技术，在生成标记后，MoI通过将生成的离散标记与之前丢弃的标记分布融合来创建新的输入。这种方法利用贝叶斯估计方法，将标记分布视为先验，所选标记作为观测值，并使用连续的后验期望代替传统的独热向量作为新的模型输入，从而使得模型在整个生成过程中保持更丰富的内部表示，进而提高文本质量和推理能力。", "innovation": "本文创新性地提出了Mixture of Inputs（MoI）方法，该方法在自回归生成过程中，通过融合生成的离散标记与之前丢弃的标记分布来创建新的输入，而非仅传递所采样标记，这种方法通过贝叶斯估计方法，提出了使用连续后验期望作为模型输入的新方式，从而增强了生成过程中的模型内部表示，实现文本生成质量的提升和推理能力的增强。这种方法无需额外训练和几乎无额外计算开销，适用于包括QwQ-32B, Nemotron-Super-49B, Gemma-3-27B, 和DAPO-Qwen-32B等多种模型。", "conclusion": "通过使用Mixture of Inputs（MoI）方法，在生成文本时，模型能够保持更丰富的内部表示，从而在数学推理、代码生成和博士级别问题解答等多种任务中表现出色，提升性能，验证了MoI的有效性，并展示了这种方法的实用性和广泛适用性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15293", "html_url": "https://arxiv.org/abs/2505.15293", "title": "LLM-Explorer: 一个由大型语言模型驱动的插件强化学习策略探索增强工具", "title_en": "LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models", "authors": "Qianyue Hao,Yiwen Song,Qingmin Liao,Jian Yuan,Yong Li", "background": "强化学习（RL）中的策略探索至关重要，现有方法包括贪婪策略和高斯过程等。然而，这些方法使用预设的随机过程，且缺乏根据任务特征调整探索策略的能力，在所有RL任务中采取统一的方法，未考虑任务特异性特征对策略探索的影响。在RL训练过程中，这些随机过程的演变往往是刚性且僵化的，通常仅包括方差的衰减，未能根据代理当前学习状态灵活调整。", "innovation": "受大型语言模型（LLMs）的分析和推理能力启发，我们设计了LLM-Explorer，这是一种能够自适应生成任务特定探索策略的插件模块，增强了RL策略探索能力。通过定期更新概率分布，我们为特定任务生成了专门的随机过程，并能随学习过程动态调整。LLM-Explorer兼容多种广为人知的RL算法，包括DQN系列、DDPG、TD3及其派生的任何可能变体。通过在Atari和MuJoCo基准上的广泛实验，我们展示了LLM-Explorer增强RL策略探索的能力，实现了平均性能提升37.27%。我们已将代码开源，确保结果的可再现性，链接附在文末。", "conclusion": "我们的设计通过自适应生成随机过程来针对特定任务的策略探索进行调整，显著提升了RL中的策略探索效果。我们已经通过广泛的实验证明了LLM-Explorer的有效性，并将其开源以促进进一步研究和应用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16690", "html_url": "https://arxiv.org/abs/2505.16690", "title": "您的预训练LLM实际上是未监督的信心校准器", "title_en": "Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator", "authors": "Beier Luo,Shuoyuan Wang,Sharon Li,Hongxin Wei", "background": "后训练的大语言模型对于适应预训练语言模型（PLMs）以符合人类偏好和下游任务是必不可少的。尽管PLMs通常表现出很好的信心校准，但后训练的语言模型（PoLMs）经常会变得过于自信，对正确和错误的输出都赋予高信心，这在关键应用中会损害可靠性。评估PoLMs校准的主要障碍之一是，针对个别下游任务的标记数据稀缺。为了解决这个问题，作者提出了一种新的无监督方法，即Disagreement-Aware Confidence Alignment (DACA)，以优化后训练的置信度校准参数（例如，温度$\tau$）。", "innovation": "该研究提出了一种新的无监督方法DACA来优化后训练的置信度校准参数。DACA利用预测分歧来调整PLM和PoLM之间的信心波动，并通过温度缩放技巧来减少校准过程中的影响。这种调整避免了使用分歧实例导致的$\tau$选择过大问题，从而提高了校准性能。实验结果表明，该方法可以在常见的基准测试上显著提高平均ECE，例如对于开源和基于API的LLM（如GPT-4o）的改进达到15.08%。", "conclusion": "DACA通过选择性使用一致实例进行校准，有效脱耦了分歧对温度缩放的影响，避免了因分歧实例导致$\tau$过大问题，提高了校准性能，从而在多种基准测试中显示出显著的效果。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19667", "html_url": "https://arxiv.org/abs/2505.19667", "title": "LeCoDe：面向互动法律咨询对话评估的标准数据集", "title_en": "LeCoDe: A Benchmark Dataset for Interactive Legal Consultation Dialogue Evaluation", "authors": "Weikang Yuan,Kaisong Song,Zhuoren Jiang,Junjie Cao,Yujie Zhang,Jun Lin,Kun Kuang,Ji Zhang,Xiaozhong Liu", "background": "法律咨询对保护个人权利和确保司法公正至关重要，但因专业人员不足，高昂且难以获取。虽然大型语言模型（LLMs）的发展为提供可扩展且低成本的法律援助提供了希望，但现有系统在处理实际咨询过程中的互动性和知识密集性上仍然存在不足。因此，为了应对这些挑战，提出了LeCoDe，这是一个包含3,696条法律咨询对话和110,008个对话回合的基准数据集，旨在评估和支持LLMs提供法律咨询服务的能力。", "innovation": "LeCoDe通过从短视频平台获取Live-streamed咨询，提供真实的多回合法律咨询对话，这些对话由法律专家进行严格的标注，增加了专业见解和经验。此外，还提出了一套全面的评估框架，评估LLMs在两个维度上（澄清能力和专业建议质量）的咨询能力。这套统一体系包括12个指标。", "conclusion": "通过在各种通用和特定领域的LLMs上的广泛实验，结果表明，在这个任务中的挑战极其明显，即使像GPT-4这样的顶级模型也只能在澄清任务中获得39.8%的召回率，并且总体建议质量得分为59%，这凸显了专业咨询场景的复杂性。基于这些发现，进一步探讨了提高LLMs法律咨询服务能力的策略。LeCoDe为法律领域对话系统的研究做出了贡献，特别是模拟更真实的用户-专家互动。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16581", "html_url": "https://arxiv.org/abs/2505.16581", "title": "如何通过提炼出的策略集合提高强化学习中的泛化能力", "title_en": "How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning", "authors": "Max Weltevrede,Moritz A. Zanger,Matthijs T.J. Spaan,Wendelin Böhmer", "background": "在零样本策略转移的强化学习环境中，目标是训练一个智能体在一组固定的训练环境中，使它能够应用于类似但未见过的测试环境中，并获得更好的性能。已有研究表明，训练后的策略提炼有时可以在测试环境中产生性能优于原始模型的策略。然而，仍不清楚为什么会出现这种情况，也不清楚应使用什么数据来提炼策略。", "innovation": "本文证明，在某些假设下，训练后的策略提炼可以提供泛化上限。理论提供了两个实用见解：为了提高泛化能力，应1)训练一个提炼出的策略集合，2)尽可能多的在训练环境的数据上提炼策略。实验证实了在更通用的场景中这些见解是有效的，即使理论所需的假设不再适用也是如此。最后，展示了一个在多变数据集上提炼出的策略集合比原智能体有显著更好的泛化能力。", "conclusion": "研究表明，通过提炼出的策略集合，可以在更多样化的测试环境中表现出显著的泛化能力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16722", "html_url": "https://arxiv.org/abs/2505.16722", "title": "打破mBad！跨语言去毒的监督微调", "title_en": "Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification", "authors": "Himanshu Beniwal,Youngwoo Kim,Maarten Sap,Soham Dan,Thomas Hartvigsen", "background": "随着大型语言模型（LLMs）在世界各地的应用变得越来越普遍，确保它们在多种语言环境中是无毒性的仍然是一个关键挑战。这项研究探讨了“跨语言去毒”这一框架，该框架可以在不同的语言群体和手写体系中通过减少资源语言和高资源语言之间的毒性，实现去毒能力的转移。通过392种广泛的情境评估了跨语言去毒的有效性，特别是在数据有限的情况下跨领域评估去毒效果，研究还调查了减少毒性如何影响模型在无毒性任务上的表现，揭示了安全性与知识保持之间的权衡关系。", "innovation": "提出了一种跨语言去毒的框架，该框架能够在不同语言群体和手写体系之间通过高资源和低资源语言之间的毒性减少，实现去毒能力的转移。通过392种广泛的情境评估了其有效性，特别关注数据有限的跨领域评估，并调查了减少毒性对非毒性和任务表现的影响，揭示了安全性与知识保存之间的权衡关系。", "conclusion": "通过研究，我们发现跨语言去毒有效减少了不同资源语言之间的毒性，同时还能保持模型在非毒性任务上的表现，但存在一定的安全性和知识保持之间的权衡。研究团队公开了代码和数据集，以供后续研究和应用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21364", "html_url": "https://arxiv.org/abs/2505.21364", "title": "无牺牲的解释性：Mixture of Decoders实现忠实的密集层分解", "title_en": "Towards Interpretability Without Sacrifice: Faithful Dense Layer Decomposition with Mixture of Decoders", "authors": "James Oldfield,Shawn Im,Sharon Li,Mihalis A. Nicolaou,Ioannis Patras,Grigorios G Chrysos", "background": "多层感知器（MLPs）是大型语言模型的重要组成部分，但由于它们密集的表示形式，使得理解、编辑和控制它们变得困难。现有的方法通过神经元级别的稀疏性学习可解释的近似模型，但会显著增加模型的下一个令牌交叉熵损失，即不能忠实重建原始映射。现有技术在稀疏层近似中需要权衡准确性和可解释性。\n", "innovation": "本文提出了一种新的方法，即层次级别的稀疏性（layer-level sparsity），以克服稀疏层近似中的准确性和可解释性之间的权衡。通过引介Mixture of Decoders（MxDs），MxDs能够将预训练的密集层扩展为数万个专门的子层。通过一种灵活的张量分解形式，每个稀疏激活的MxD子层实现了权重满秩的线性变换，从而保持了原始解码器的表示能力，即使在高度稀疏的情况下也能保持原始的解码器的表达能力。这一方法在语言模型中的实验结果表明，MxDs在高达3亿参数的语言模型上显著优于现有的最先进的方法（如Transcoders）。进一步的评估还表明，MxDs能够学习自然语言的特殊特征，为设计可解释且忠实的分解开辟了一条新的途径。\n", "conclusion": "通过Mixture of Decoders，本文展示了在保持模型性能的前提下实现更好的解释性的可能性，同时证明了MxDs在更大的语言模型上优于现有方法，并且能够学习自然语言的特性，开辟了新的研究方向。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21441", "html_url": "https://arxiv.org/abs/2505.21441", "title": "随机森林自动编码", "title_en": "Autoencoding Random Forests", "authors": "Binh Duc Vu,Jan Kapar,Marvin Wright,David S. Watson", "background": "该研究基于非参数统计和谱图理论的基本成果，提出了一个原理性的自动编码方法，旨在学习一种低维度嵌入模型，以最优地表示数据中的关系。研究通过约束优化、分裂调整和最近邻回归提供了解码问题的准确和近似解，确保了解码器在常见正则性假设下的一致性。该方法适用于有监督或无监督模型，能够揭示条件或联合分布的洞察力。研究展示了该自动编码器在多种应用中的效用，包括可视化、压缩、聚类和去噪等。实验结果证明该方法在多种不同数据集上操作简便且实用，适用于表格、图像和基因组数据等场景。", "innovation": "提出了一种基于随机森林的自动编码方法，融合了非参数统计和谱图理论。解决了自动编码中的解码问题，通过约束优化、分裂调整和最近邻回归提供了准确和近似的解码方法，并展示了其在多种数据类型上的适用性和实用性。该方法不仅适用于监督学习模型，也适用于无监督模型，提供了一种从嵌入空间映射回输入空间的新途径，同时保持解码器的普遍一致性。", "conclusion": "该研究提出了一种使用随机森林进行自动编码的方法，该方法能够有效学习低维度嵌入表示，且在常见正则性假设下解码器具有一致性。此方法不仅适用于监督模型，也适用于无监督模型，并能够在可视化、压缩、聚类及去噪等多个应用场景中发挥作用。实验结果表明该方法在不同数据类型上均具有操作简便和实用的特点。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22038", "html_url": "https://arxiv.org/abs/2505.22038", "title": "Balanced Token Pruning: 超越局部优化加速视觉语言模型", "title_en": "Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization", "authors": "Kaiyuan Li,Xiaoyue Chen,Chen Gao,Yong Li,Xinlei Chen", "background": "大型多模态模型（LVLMs）通过将图像编码成数千个令牌，在多模态任务中表现出色。然而，大量图像令牌导致了显著的计算负担，而使用动态高分辨率输入进一步增加了这个负担。现有的方法试图减少图像令牌的数量，通常基于注意力分数或图像令牌的多样性来选择令牌。然而，现有的方法往往忽视了剪枝对当前层输出（局部）和后续层输出（全局）的联合影响，导致了次优的剪枝决策。", "innovation": "该论文提出了一种名为平衡令牌剪枝（BTP）的方法，这是一种即插即用的令牌剪枝方法，适用于视觉令牌。具体而言，该方法使用一个小型校准集将剪枝过程划分为多个阶段。在早期阶段，该方法强调剪枝对后续层的影响，而在较深的阶段，则转向保持局部输出的一致性。该方法在多种LVLMs上的广泛实验表明，在多个基准测试中，该方法具有广泛的适用性。平均来看，该方法实现了78%的压缩率，同时保留了原始模型96.7%的性能。", "conclusion": "广泛的实验结果证明了BTP方法的有效性，它能够实现显著的压缩率同时保持较高的性能水平，解决了剪枝带来的次优问题，超越了传统的局部优化。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22389", "html_url": "https://arxiv.org/abs/2505.22389", "title": "使用扰动训练，合并后推理：一种两阶段持续学习框架", "title_en": "Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning", "authors": "Haomiao Qiu,Miao Zhang,Ziyue Qiao,Liqiang Nie", "background": "持续学习（CL）旨在使模型能够从一系列任务中连续获取新知识，同时避免遗忘已学到的信息。现有的CL方法仅依赖最近任务的参数进行推理，这使它们容易遭受灾难性遗忘的困扰。作者受模型合并技术最近取得成功的启发，提出了一种新颖的持续学习框架Perturb-and-Merge（P&M），它将模型合并技术整合进CL范式中以缓解遗忘问题。通过理论分析，他们最小化了所有任务的总损失增加，并在轻微假设下推导出合并系数的闭式解。为了进一步提高合并模型的性能，作者观察到在合并过程中引入的退化可以通过由任务向量和损失函数的海森矩阵构成的正则化项来缓解。这一项可以通过高效的二次对称有限差分近似，作者据此提出一种沿任务向量方向的随机扰动策略，该策略无需额外的正向或反向传递即可提供有效的正则化项近似。最后，作者将P&M与参数高效微调方法LoRA结合使用，以减少内存开销。研究表明，该方法在几个持续学习基准数据集上达到了最先进的性能。相关代码可以在给定的链接处获取", "innovation": "该研究提出了一种新颖的持续学习框架Perturb-and-Merge（P&M），通过理论分析，最小化了所有任务的总损失增加，并推导出合并系数的闭式解。通过沿任务向量方向的随机扰动策略，提供了有效的正则化项近似。将P&M与参数高效微调方法LoRA结合使用，减少内存开销。研究表明，该方法在几个持续学习基准数据集上达到了最先进的性能。相关代码已经公开提供", "conclusion": "提出的P&M框架能够有效缓解灾难性遗忘问题，在多个持续学习基准数据集上达到了最先进的性能。通过理论分析和应用正则化项，该方法显著提高了持续学习模型的性能。将P&M与LoRA结合使用进一步验证了其有效性和实用性。相关代码已经公开提供，方便其他研究者进行验证和改进。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01665", "html_url": "https://arxiv.org/abs/2506.01665", "title": "利用解析梯度实现可证明安全的强化学习", "title_en": "Leveraging Analytic Gradients in Provably Safe Reinforcement Learning", "authors": "Tim Walter,Hannah Markgraf,Jonathan Külz,Matthias Althoff", "background": "在关键安全应用中部署自主机器人需要安全保证。经过验证的安全强化学习是一个活跃的研究领域，其目标是使用防护措施提供这种保证。目前的防护措施多通过训练时集成的方式减少模拟与现实之间的差距。然而，对于基于解析梯度的强化学习方法，尚未开发出有效的防护措施，尽管这种方法在环境互动较少的情况下往往能取得更好的性能。", "innovation": "本文填补了基于解析梯度的强化学习缺乏防护措施的空白，开发了首个有效的防护措施。通过分析现有的可微分防护措施，对其进行修改并通过梯度公式适应，将这些防护措施集成到最先进的学习算法和可微分的模拟中。数值实验结果表明，通过防护措施进行的训练不会损害性能。", "conclusion": "研究结果证明，即使采用防护措施进行训练也不会损害性能，提供了在解析梯度基于的强化学习框架中实现可证明安全性的一种方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.09018", "html_url": "https://arxiv.org/abs/2506.09018", "title": "编辑流：基于编辑操作的流匹配", "title_en": "Edit Flows: Flow Matching with Edit Operations", "authors": "Marton Havasi,Brian Karrer,Itai Gat,Ricky T. Q. Chen", "background": "自回归生成模型能够自然地生成变长序列，而非自回归模型在这方面表现不佳，常常需要对于每个标记进行固定结构的约束。因此，这些模型在应对序列数据的结构化生成时存在限制。本文提出了一种名为Edit Flows的非自回归模型，通过编辑操作（插入、删除和替换）定义序列上的离散流，从而解决了这一问题。", "innovation": "该模型通过在序列空间上的连续时间马尔可夫链中建模这些操作，实现了更加灵活和与序列数据结构相对应的位置相关生成。此外，该模型通过扩展状态空间和辅助变量的引入使得学习过程更加高效和可行。", "conclusion": "实验证明，Edit Flows在图像字幕生成、文本生成以及代码生成等任务中，相较于自回归模型和掩码模型等，表现更优，特别是在掩码模型的构建方面有着显著的提升。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07031", "html_url": "https://arxiv.org/abs/2506.07031", "title": "HauntAttack:当攻击跟随推理的影子", "title_en": "HauntAttack: When Attack Follows Reasoning as a Shadow", "authors": "Jingyuan Ma,Rui Li,Zheng Li,Junfeng Liu,Heming Xia,Lei Sha,Zhifang Sui", "background": "新兴的大型推理模型（LRMs）在数学和推理任务上表现出色，展现出了卓越的能力。然而，提升推理能力的同时暴露了内部推理过程，带来了新的安全漏洞。当推理与有害性交织时，LRMs 是否会更容易在推理模式下遭受攻击？", "innovation": "为探讨这一问题，作者引入了HauntAttack，这是一种新型的一般性黑盒对抗攻击框架，系统地将有害指令嵌入到推理问题中。它通过修改现有问题中的关键推理条件，并引入有害指令，从而逐步引导模型产生不安全的输出。在11种LRMs上进行了评估，取得了70%的平均攻击成功率，绝对提升达到了强基线的12个百分点。进一步分析显示，即使是高度安全对齐的模型也高度易受基于推理的攻击，这为未来模型开发提出了关于平衡推理能力和安全性的迫切挑战提供了见解。", "conclusion": "高级的安全对齐模型在基于推理的攻击面前仍然极易受损，表明未来在开发模型时必须重视此方面的平衡和挑战，以确保模型不仅具有强大的推理能力，还具备高度的安全性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07520", "html_url": "https://arxiv.org/abs/2506.07520", "title": "LeVo：多偏好对齐的高质量歌曲生成", "title_en": "LeVo: High-Quality Song Generation with Multi-Preference Alignment", "authors": "Shun Lei,Yaoxun Xu,Zhiwei Lin,Huaicheng Zhang,Wei Tan,Hangting Chen,Jianwei Yu,Yixuan Zhang,Chenyu Yang,Haina Zhu,Shuai Wang,Zhiyong Wu,Dong Yu", "background": "近年来，大型语言模型(LLLs)和音频语言模型显著提高了音乐生成，尤其是在歌词到歌曲的生成方面。然而，现有的方法仍然在复杂的歌曲编排和高质量数据的稀缺性上存在挑战，导致音频质量、音乐性和指令遵循能力以及声乐和伴奏的和谐性受限。", "innovation": "本文提出了一种名为LeVo的基于语言模型的框架，包括LeLM和Music Codec。LeLM能够并行建模两种类型的令牌：混音令牌和双轨令牌，以实现更好的声乐和伴奏和谐性。LeVo还引入了基于直接偏好优化(DPO)的多偏好对齐方法，通过半自动化数据构建过程和后训练处理来处理多样化的用户偏好。实验结果表明，LeVo在客观和主观指标上明显优于现有开源方法，在工业系统中表现竞争力。消除影响研究进一步证明了我们设计的有效性。", "conclusion": "LeVo显著优于现有的开源方法，在音质、音乐性、指令遵循能力和声乐伴奏和谐性等方面表现出优势，且能够在数据有限的情况下生成高质量的歌曲。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13992", "html_url": "https://arxiv.org/abs/2506.13992", "title": "AssistedDS: 评估外部领域知识如何辅助LLM进行自动化数据科学", "title_en": "AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science", "authors": "An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding", "background": "大型语言模型（LLMs）已经促进了数据科学工作流程的自动化。然而，目前尚不清楚它们是否能够像人类数据科学家那样充分利用外部领域知识。为了回答这个问题，该研究引入了AssistedDS基准测试，旨在系统性地评估LLMs在表格预测任务中处理领域知识的能力。", "innovation": "AssistedDS基准测试包括具有明确生成机制的合成数据集和包含领域特定文档的现实世界Kaggle比赛。这些文档包括清理、特征工程和模型选择的指导信息。通过评估LLMs辨别有益和有害领域知识的能力，该研究发现当前LLMs在处理领域知识上存在重要缺陷，特别是在面对对抗性内容时。", "conclusion": "研究结果表明，当前模型在评估和利用专家知识方面存在显著差距，强调了发展更加稳健、知识驱动的自动化数据科学系统的必要性。研究数据和代码在公共网站（此 https URL）上公开可用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05341", "html_url": "https://arxiv.org/abs/2506.05341", "title": "通过空间推理直接生成3D室内场景合成的数值布局", "title_en": "Direct Numerical Layout Generation for 3D Indoor Scene Synthesis via Spatial Reasoning", "authors": "Xingjian Ran,Yixuan Li,Linning Xu,Mulin Yu,Bo Dai", "background": "真实的3D室内场景合成对于嵌入式人工智能和数字内容创作至关重要。这一任务可以自然地分为两个子任务：物体生成和布局生成。尽管最近的生成模型显著提升了物体级别的质量和可控性，但布局生成仍然非常具有挑战性，主要原因是可用数据集有限。现有的方法要么过度拟合到这些数据集，要么依赖于预定义的约束来优化数值布局，其灵活性较低。因此，这些方法无法生成既拥有广泛词汇量又能与细腻用户指令一致的场景。", "innovation": "我们提出了DirectLayout框架，该框架能够直接从文本描述生成数值化的3D布局，利用大语言模型（LLMs）的一般化空间推理。DirectLayout将生成过程分解为三个阶段：生成鸟瞰图（BEV）布局、将其提升到3D空间并精装修点。为确保具有明确的、帮助模型理解物体排列的微量原理，我们采用了基于3D-Front数据集的Chain-of-Thought（CoT）激活，并设计了CoT触发的生成布局奖励，以增强泛化能力和空间规划能力。在推理过程中，DirectLayout利用上下文学习调整资产布局不匹配问题。实验证明，DirectLayout能够在语义一致性、泛化能力和物理合理性方面取得显著效果。", "conclusion": "DirectLayout框架显著提升了布局生成的质量和泛化能力，通过引入CoT激活和生成布局奖励，成功地解决了传统方法在灵活性和一致性方面的不足，为真实3D室内场景的合成提供了新的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.16349", "html_url": "https://arxiv.org/abs/2506.16349", "title": "使用生成模型的图像生成中嵌入水印", "title_en": "Watermarking Autoregressive Image Generation", "authors": "Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez", "background": "水印技术在生成模型输出中的应用已经引起了广泛关注，特别是对于追踪模型生成内容的来源。尽管人们对自回归图像生成模型的潜在滥用有所关注，但过往的研究并未尝试在生成图像时在其令牌级别嵌入水印。", "innovation": "本文提出了一种新颖的方法，通过将语言模型水印技术应用到图像生成中，首次在令牌级别嵌入水印。为了克服反周期一致性（RCC）的问题，即重新标记生成的图像令牌会显著改变令牌序列从而擦除水印，以及增强对抗图像变换、神经压缩和移除攻击的鲁棒性，作者引入了自定义的令牌化-反令牌化微调程序以改善RCC，并提出了一个互补的水印同步层。", "conclusion": "实验结果表明，本文的方法能够在理论上支持水印检测的p值，实现可靠且鲁棒的水印检测。该成果已实现并可从指定链接获取代码和模型。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23751", "html_url": "https://arxiv.org/abs/2505.23751", "title": "REOrdering Patches Improves Vision Models", "title_en": "REOrdering Patches Improves Vision Models", "authors": "Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta", "background": "序列模型如变换器需要输入表示为一维序列。在视觉领域，通常通过固定的行主序（逐行扫描）来展平图像。尽管全自注意力是置换不变的，但现代长序列变换器越来越多地依赖于破坏这种不变性的架构近似方法，这使得模型对块的顺序变得敏感。研究表明，在这种情况下，块的顺序显著影响了模型性能。", "innovation": "提出了REOrder，一种两阶段框架来发现任务最优的块顺序。首先，通过评估各种块序列的压缩性来推导信息理论先验。然后，通过优化Plackett-Luce策略，利用REINFORCE学习一个置换策略。这种方法可以在组合置换空间中实现高效的策略学习。", "conclusion": "REOrder在ImageNet-1K和Functional Map of the World上分别比行主序提高了最高3.01%和13.35%的top-1精度。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05821", "html_url": "https://arxiv.org/abs/2506.05821", "title": "FuseUNet：U形网络中的多尺度特征融合方法", "title_en": "FuseUNet: A Multi-Scale Feature Fusion Method for U-like Networks", "authors": "Quansong He,Xiangde Min,Kaishen Wang,Tao He", "background": "医学图像分割是计算机视觉中的关键任务，UNet作为里程碑式的架构，其典型特征是跳接连接。然而，这些跳接连接存在两个重要限制：(1) 缺乏不同尺度特征之间的有效交互；(2) 只使用简单的连接或加法操作，限制了信息的有效整合。尽管最近对UNet的研究侧重于增强编码器和解码器，但这些限制仍然被忽视。为此，本研究提出了一种新型多尺度特征融合方法，将其解码过程重新定义为求解初值问题（IVP），将跳接连接视为离散节点。通过利用线性多步方法的原则，提出了一种自适应常微分方程方法来实现有效的多尺度特征融合。该方法独立于编码器和解码器架构，适用于各种U-Net类似的网络。实验在ACDC、KiTS2023、MSD脑肿瘤和ISIC2017/2018皮肤病变分割数据集上验证了其在特征利用改善、减少网络参数和保持高性能方面的优越性。代码公开于指定网址。", "innovation": "提出了一种适用于各种U-Net类似网络的新型多尺度特征融合方法，通过将UNet解码过程重新定义为求解初值问题，并利用自适应常微分方程方法实现跨尺度特征的有效融合，该方法在特征利用、网络参数和性能方面均有所改进，且独立于编码器和解码器架构。", "conclusion": "实验结果表明，FuseUNet在ACDC、KiTS2023、MSD脑肿瘤和ISIC2017/2018皮肤病变分割数据集上实现了改进的特征利用、减少的网络参数和高性能。代码已公开。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18631", "html_url": "https://arxiv.org/abs/2506.18631", "title": "ReDit: 改进的大语言模型策略优化中的奖励抖动方法", "title_en": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "authors": "Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu", "background": "DeepSeek-R1 通过基于规则的奖励系统成功增强了大型语言模型（LLM）的推理能力，尽管这是一个‘完美’的奖励系统，有效缓解了奖励作弊的问题，但这些奖励函数往往是离散的。实验观察表明，离散奖励可能导致梯度异常、优化不稳定和收敛缓慢。", "innovation": "提出了ReDit（奖励抖动）方法，通过在离散奖励信号中添加简单的随机噪声，使探索梯度在整个学习过程中不断提供，从而使梯度更新更加平滑并加速收敛。引入的噪声还使平坦奖励区域中的模型探索新的策略并逃离局部最优。", "conclusion": "ReDit 在多种任务上的实验结果证实了其有效性和效率。平均而言，ReDit 在仅约10%的训练步骤下达到了与原始GRPO相当的性能，且在相同训练时间下，相对于原始GRPO还提高了4%的性能。可视化结果进一步证实了ReDit显著缓解了梯度问题。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23679", "html_url": "https://arxiv.org/abs/2506.23679", "title": "使用Transformer学习模幂运算", "title_en": "Learning Modular Exponentiation with Transformers", "authors": "David Demitri Africa,Sara M. Kapoor,Theo Simon Sorg,Challenger Mishra", "background": "模幂运算在数论和密码学中至关重要，但多数研究未从机制可解释性的角度探讨这一运算。本文通过训练一个4层编码器-解码器Transformer模型进行模幂运算，研究训练过程中数学推理能力的涌现。利用有原则的采样策略、PCA嵌入分析和激活图分析，探讨模型内部为何能编码数论特性。", "innovation": "通过 hopping 算术运算的训练，模型性能显著提升，并出现突然的跨相关模数的一般化。这种同步准确率跃升反映出类似于理解过程的动力学，表明模型内化了共有的算术结构。模型最后一层的子图完全由注意力头组成，足以在常规幂运算任务上达到最佳表现。这些结果表明，Transformer 模型通过专门计算电路学习模运算，为更可解释和高效的神经网络方法开辟了道路。", "conclusion": "本文研究发现Transformer模型通过专门计算电路学习模幂运算，能够实现较高的解释性和效率。建议未来研究进一步探索这些机制的具体实现，以增强模型的可解释性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.00418", "html_url": "https://arxiv.org/abs/2507.00418", "title": "在HPC集群中部署LLMs：Qualcomm Cloud AI 100 Ultra与NVIDIA数据中心GPU的比较研究", "title_en": "Serving LLMs in HPC Clusters: A Comparative Study of Qualcomm Cloud AI 100 Ultra and NVIDIA Data Center GPUs", "authors": "Mohammad Firas Sada,John J. Graham,Elham E Khoda,Mahidhar Tatineni,Dmitry Mishin,Rajesh K. Gupta,Rick Wagner,Larry Smarr,Thomas A. DeFanti,Frank Würthwein", "background": "该研究旨在评估Qualcomm Cloud AI 100 Ultra（QAic）加速器在国家研究平台（NRP）生态系统中的性能表现，特别是在大型语言模型（LLM）推理中的能效、性能和硬件扩展性。研究使用vLLM框架并针对12种开源LLM进行评估，参数量从1.24亿到70亿不等。", "innovation": "研究展示了QAic在能效上的竞争力，并揭示了其在特定模型上的优势。此外，研究还发现了在硬件分配方面更精细的管理方式，以及与NVIDIA A100 GPU相比在功耗上的显著降低，特别是在处理小模型时，降低功耗最高可达35倍。", "conclusion": "该研究为Qualcomm Cloud AI 100 Ultra在能源受限和资源高效HPC部署中的潜力提供了见解，并特别指出其在国家研究平台（NRP）中的应用前景。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19358", "html_url": "https://arxiv.org/abs/2506.19358", "title": "从高信噪比雷达信号到心电图：有限数据场景中的心脏聚焦算法和传输学习模型", "title_en": "From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data", "authors": "Yuanyuan Zhang,Haocheng Zhao,Sijie Xiong,Rui Yang,Eng Gee Lim,Yutao Yue", "background": "心电图（ECG）作为关键的精细心脏特征，已在文献中从雷达信号中成功恢复，但性能高度依赖于高质量的雷达信号和大量的雷达-ECG数据对用于训练。由于数据稀缺，在新场景中的应用受到限制。因此，该研究致力于在有限数据的新场景下从雷达信号恢复ECG，并提出了一种心脏聚焦和跟踪（CFT）算法，以精确跟踪心脏位置，确保高效获取高质量的雷达信号。文章还提出了一种基于心脏特征固有稀疏性的传输学习模型（RFcardi），该模型可以在没有ECG真实值的情况下从雷达信号中提取心脏相关信息，仅需少量同步的雷达-ECG数据对即可对预训练模型进行微调以恢复ECG。实验结果表明，提出的CFT可以动态识别心脏位置，RFcardi模型可以在较少的雷达-ECG数据对训练后有效生成可靠的ECG恢复。", "innovation": "该研究提出了心脏聚焦和跟踪（CFT）算法来在有限数据的新场景下从雷达信号恢复ECG，并基于心脏特征的固有稀疏性提出了传输学习模型（RFcardi），仅需少量同步的雷达-ECG数据对即可对预训练模型进行微调，从而有效生成可靠的ECG恢复。", "conclusion": "提出的CFT可以动态识别心脏位置，而RFcardi模型可以在较少的雷达-ECG数据对训练后有效生成可靠的ECG恢复。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17065", "html_url": "https://arxiv.org/abs/2506.17065", "title": "基于流的方法对动态时变因果模型的非高斯或异方差噪声处理", "title_en": "Flow based approach for Dynamic Temporal Causal models with non-Gaussian or Heteroscedastic Noises", "authors": "Abdellah Rahmani,Pascal Frossard", "background": "多变量时间序列中的因果关系理解在许多场景中至关重要，例如金融或神经数据处理。许多此类时间序列表现出多阶段特性，即具有先验未知边界的连续时间段，每个阶段具有自己的因果结构。推断因果依赖性和阶段转移对于分析底层过程至关重要。然而，在这种背景下学习因果结构具有挑战性，因为每个阶段可以有自己的因果图和混合函数，以及复杂的噪声分布，这些噪声可能是非高斯的或异方性的。现有的因果发现方法无法解决这些挑战，因为它们通常假设平稳性或常方差的高斯噪声。", "innovation": "我们提出了FANTOM，一个统一的因果发现框架，能够处理非平稳过程以及非高斯和异方差噪声。FANTOM同时推断阶段数量和阶段索引，并学习每个阶段的有向无环图。它使用最大数据对数似然证据下界的贝叶斯期望最大化算法。此外，理论上，证明了FANTOM中提出的时变异方差因果模型在平稳和非平稳设置下可识别。", "conclusion": "大量的合成数据和实际数据实验表明，FANTOM在性能上优于现有方法。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.06795", "html_url": "https://arxiv.org/abs/2507.06795", "title": "ixi-GEN：通过域自适应连续预训练实现高效工业小语言模型", "title_en": "ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining", "authors": "Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon", "background": "开源大型语言模型（LLM）为企业的应用提供了更多的机会，但许多组织仍缺乏部署和维护大规模模型的基础设施。作为结果，尽管存在固有的性能限制，小语言模型（sLLM）已经成为一种可行的替代方案。虽然域适应连续预训练（DACP）已在某些领域得到探索，但在商业环境中的实用性尚未得到充分验证。", "innovation": "本研究验证了基于DACP的数据集设计的有效性，适用于不同的基础模型和服务领域，并通过DACP产生了ixi-GEN小模型。通过广泛的实验证明，ixi-GEN在目标领域中能获得显著性能提升，并保持泛化能力，提供了一种成本效益高且可扩展的企业级部署解决方案。", "conclusion": "ixi-GEN模型通过DACP实现了目标领域性能的显著提升，同时保持了泛化能力，为企业规模部署提供了成本高效和可扩展的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03220", "html_url": "https://arxiv.org/abs/2507.03220", "title": "Symbiosis: 多适配器推理与微调", "title_en": "Symbiosis: Multi-Adapter Inference and Fine-Tuning", "authors": "Saransh Gupta,Umesh Deshpande,Travis Janssen,Swami Sundararaman", "background": "参数高效微调（PEFT）技术允许模型构建者将任务特定参数压缩到适配器中，这些适配器的大小仅为原始基础模型的一小部分。PEFT技术的流行导致为流行的大型语言模型（LLMs）创建了大量的适配器。然而，现有的框架在支持多种适配器的推理或微调方面存在以下不足：1）对于微调，每个任务需要部署其专用的基础模型实例，这会导致GPU内存消耗过度并降低GPU利用率。2）虽然流行的推理平台可以为多个PEFT适配器提供服务，但它们不允许独立的资源管理或不同PEFT方法的混合使用。3）它们无法有效利用异构加速器。4）它们不为希望不向服务提供商暴露微调参数的用户提供隐私保护。", "innovation": "Symbiosis通过支持基础模型的即服务部署来解决上述问题，使得基础模型层可以在多个推理或微调过程中共享。其拆分执行技术解耦了客户端特定适配器和基础模型层的执行，提供了灵活性以管理资源、选择微调方法以实现性能目标。Symbiosis方法对模型透明，可以在大多数transformers库中的模型中无缝工作。实验证明，Symbiosis可以同时在8个GPU上对20个Gemma2-27B适配器进行微调。", "conclusion": "Symbiosis解决了PEFT框架在支持多适配器推理和微调方面的问题，提供了一个支持资源共享、独立资源管理和混合PEFT方法的解决方案，同时也保证了用户的隐私。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.12006", "html_url": "https://arxiv.org/abs/2507.12006", "title": "基于密度预测的频率动态注意模态", "title_en": "Frequency-Dynamic Attention Modulation for Dense Prediction", "authors": "Linwei Chen,Lin Gu,Ying Fu", "background": "视觉变压器（ViTs）在计算机视觉领域取得了显著进展，但在各种任务中表现出强劲的性能。然而，ViTs中的注意机制使每一层都充当低通滤波器，现有变压器的堆叠层架构存在频率消失的问题。这导致了关键细节和纹理的丢失。", "innovation": "提出了一个基于电路理论的新颖策略，称为频率动态注意调制（FDAM），可以无缝集成到ViTs中。FDAM直接调节ViTs的整体频率响应，包括Attention Inversion (AttInv) 和 Frequency Dynamic Scaling (FreqScale)两种技术。通过特征相似性分析和有效的秩评估，展示了本方法避免了表示崩溃，实现了各种模型（SegFormer, DeiT, MaskDINO）的一致性能提升，并在语义分割、对象检测和实例分割任务中表现出明显改进。此外，还将该方法应用于遥感检测，实现了单尺度下的最先进成果。", "conclusion": "通过FDAM策略，改进了ViTs的频率响应，避免了表示崩溃，并实现了多项任务的性能提升，特别是在语义分割、对象检测和遥感检测中取得了优异结果。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10998", "html_url": "https://arxiv.org/abs/2507.10998", "title": "为表格数据精心打造可接受的在流形上的对抗攻击", "title_en": "Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data", "authors": "Zhipeng He,Alexander Stevens,Chun Ouyang,Johannes De Smedt,Alistair Barros,Catarina Moreira", "background": "表格数据中的对抗攻击带来独特的挑战，因为混合了类别数据和数值特征。与图像相比，像素扰动在保持视觉相似性方面较为直观，但在表格数据中，缺乏直观的相似性度量，使得定义不可见的修改变得困难。此外，传统梯度方法通常侧重于$\boldsymbol{l}_p$范数约束，这往往会导致生成的对抗样本与原始数据分布偏差较大。", "innovation": "本文提出了一种基于潜在空间的对抗扰动框架，利用混合输入VAE生成统计上一致的对抗样本。该VAE将类别嵌入和数值特征整合到统一的潜在流形中，从而实现保持统计一致性的扰动。为联合评估攻击效果和分布对齐，引入了内部一致性成功率（IDSR）。实验表明，该方法在六个公开数据集和三种模型架构上，相比传统输入空间攻击和其他基于图像域方法的VAE方法，实现了较低的异常点率和更一致的表现。", "conclusion": "综合分析表明，基于VAE的攻击效果高度依赖于重建质量及充足的训练数据。这些条件满足时，提出的方法相比输入空间方法，具有更优越的实用性和稳定性。这项工作强调了在表格域生成现实和健壮对抗样本时在流形上保持扰动的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15958", "html_url": "https://arxiv.org/abs/2507.15958", "title": "资源受限设备上具有量化感知的类神经形态架构用于高效皮肤疾病分类", "title_en": "Quantization-Aware Neuromorphic Architecture for Efficient Skin Disease Classification on Resource-Constrained Devices", "authors": "Haitian Wang,Xinyu Wang,Yiren Wang,Zichen Geng,Xian Zhang,Yu Zhang,Bo Miao", "background": "边缘设备上准确且高效的皮肤病变分类对于普及性皮肤科医疗至关重要，但由于计算、能量和隐私限制，这一目标仍具有挑战性。", "innovation": "我们提出了QANA，一种新颖的具有量化感知的类神经形态架构，用于资源受限硬件上的增量皮肤病变分类。QANA 有效集成了鬼模块、高效的通道注意力和挤压-激励块，以实现鲁棒特征表示及低延迟、节能的推理。其具有量化感知的头部和与尖峰神经网络(SNN)兼容的转换，使其能够无缝转换至尖峰神经网络并在类神经形态平台上部署。", "conclusion": "QANA 在大样本 HAM10000 标准和实际临床数据集上分别实现了 91.6% 的 Top-1 准确率和 82.4% 的宏 F1 值，和 90.8%/81.7% 的准确率，显著优于在公平比较条件下的最佳 CNN 至 SNN 模型。QANA 在 BrainChip Akida 硬件上实现了每张图片 1.5ms 的推断延迟和 1.7mJ 的能量消耗，相较于 GPU 基础的 CNN，推断延迟和能量使用分别减少了 94.6%/98.6%，超越了当前最佳 CNN 至 SNN 转换基准。这些结果展示了 QANA 在边缘环境中实现准确、实时和隐私敏感的医疗分析的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16068", "html_url": "https://arxiv.org/abs/2507.16068", "title": "使用大型语言模型的大规模机器人团队组合协调", "title_en": "Compositional Coordination for Multi-Robot Teams with Large Language Models", "authors": "Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme", "background": "传统的多机器人协调依赖于特定任务和专家驱动的流程，其中自然语言的任务描述需要由领域专家手动转换为数学公式、算法设计和可执行代码。这一传统流程劳动密集、缺乏通用性且对非专家不可用。", "innovation": "提出了一种新的框架LAN2CB（Language to Collective Behavior），利用大型语言模型（LLMs）简化并使多机器人协调流程通用化。该框架通过两个核心模块将自然语言任务描述转换为多机器人系统中的可执行Python代码：（1）任务分析模块，解析任务描述为行为树；（2）代码生成模块，利用行为树和结构化知识库生成机器人控制代码。还引入了一个自然语言任务描述的数据集，用于开发和基准测试。", "conclusion": "实验在仿真和真实环境中表明，LAN2CB能够从自然语言实现稳健和灵活的多机器人协调，大幅减少手动工程努力并支持跨多种任务类型的广泛泛化。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.19271", "html_url": "https://arxiv.org/abs/2507.19271", "title": "针对工业C#项目的多语言模型微调：一项实证研究", "title_en": "Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects", "authors": "Igli Begolli,Meltem Aksoy,Daniel Neider", "background": "代码审查对于维持软件质量至关重要，但在工业环境中往往耗时且认知负担重。近年来，语言模型的进步为自动化核心审查任务开辟了新途径。然而，现有的研究主要集中在多语言模型上，本研究通过具体案例探讨单一语言模型在特定任务上的表现，并研究不同编程语言和自然语言配置对模型性能的影响。", "innovation": "本研究通过在C#特定数据集上微调三种不同的模型（CodeReviewer, CodeLlama-7B, DeepSeek-R1-Distill），对开源语言模型在关键代码审查任务（代码变更质量估计、审查评论生成、代码精炼）上的性能进行了实证评估。本研究特别关注训练数据中不同编程语言和自然语言配置对语言模型性能的影响，特别是在评论生成方面。同时，研究还将微调后的模型与自动化软件分析工具（ASAT）和人类审查员进行了基准测试，以评估其在实际应用中的实用性。", "conclusion": "单语言模型微调在关键代码审查任务上的表现优于多语言基线。语言模型在支持代码审查流程中起到了积极作用，特别是在处理重复性任务时。然而，在处理语义复杂的或上下文相关的变化时，人类审查员仍然占有优势。研究结果强调了语言对齐和任务特定适应在优化语言模型用于自动化代码审查中的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.19634", "html_url": "https://arxiv.org/abs/2507.19634", "title": "MCIF：来自科学讲座的多模态跨语言指令跟随基准", "title_en": "MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks", "authors": "Sara Papi,Maike Züfle,Marco Gaido,Beatrice Savoldi,Danni Liu,Ioannis Douros,Luisa Bentivogli,Jan Niehues", "background": "近期大型语言模型的进展推动了多模态大语言模型（MLLMs）的发展，这些模型能够整合文本、语音和视觉信息。MLLMs从单一语言、任务特定的系统转变为通用的指令跟随模型。然而，现有的基准测试方法在多语言和多模态能力的综合评估方面存在不足，主要集中在英文上，多针对单一模态的数据，依赖于短文本或缺乏人类注释，这阻碍了对模型在不同语言、模态和任务复杂性上的全面评估。用来解决这一问题，提出了MCIF（多模态跨语言指令跟随），这是首个基于科学讲座数据的多语言人工标注基准，旨在评估多模态、跨语言环境下的指令遵循能力，包括短文本和长文本输入。MCIF涵盖三个核心模态：语音、视觉和文本，以及四种不同的语言（英语、德语、意大利语和中文），从而全面评估MLLMs在跨语言环境中的指令理解和多模态上下文信息的结合能力。", "innovation": "MCIF是第一个基于科学讲座数据的多语言人工标注基准，它针对多模态和跨语言环境下的指令遵循能力进行评估。它能够覆盖短文本和长文本输入，并支持包括英语、德语、意大利语和中文在内的多种语言，提供了一个全面的评估框架，增强了对库林模型在不同语言和复杂度任务上的性能评估。", "conclusion": "MCIF发布在CC-BY 4.0许可证下，促进了开放研究和MLLMs的发展，为多模态、跨语言指令簿籍提供了一个重要的基准测试平台。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04586", "html_url": "https://arxiv.org/abs/2508.04586", "title": "当前的AI会议模式不可持续！集中式AI会议的危机诊断", "title_en": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference", "authors": "Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He", "background": "人工智能（AI）会议对于推进研究、分享知识以及促进学术社区具有重要作用。然而，随着其规模的迅速扩大，传统的集中式会议模式变得越来越不可持续。本文通过数据分析诊断了一种结构性危机，这种危机威胁到了科学研究、公平性和社区福祉的基础目标。主要的压力源包括：(1) 科学上，过去十年间每位作者的发表率翻了一番，目前每年达到超过4.5篇论文；(2) 环境上，单个会议的碳足迹超过了其举办城市的每日排放量；(3) 心理上，网络社区的71%的讨论反映了负面情绪，35%提到了心理健康问题；(4) 物流上，顶级会议如NeurIPS 2024的参会人数已经开始超出场地容量。这些压力表明系统与核心使命已经脱节。", "innovation": "本文提出了社区统筹会议（CFC）模型，将同行评审、展示和社交活动分离为全球协调但本地组织的组成部分，为AI研究提供了更可持续、更具包容性和更具弹性的前进方向。", "conclusion": "面对系统与核心使命的脱节，本文建议采用社区统筹会议（CFC）模式，以实现更可持续、更具包容性和更具弹性的AI研究路径。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22766", "html_url": "https://arxiv.org/abs/2507.22766", "title": "基于高斯过程代理模型的传感器排序系统过程参数贝叶斯优化", "title_en": "Bayesian Optimization of Process Parameters of a Sensor-Based Sorting System using Gaussian Processes as Surrogate Models", "authors": "Felix Kronenwett,Georg Maier,Thomas Längle", "background": "传感器排序系统能够对物料流进行物理分离，根据传感器获取的图像数据进行评估和分类，使用执行器执行分类决策。这需要设定多种过程参数，如物料流特性、系统尺寸和所需的分类准确度。然而，由于需求和物料流组成的不断变化，持续验证和重新调整是非常必要的。为此，本研究提出了一种优化策略，旨在通过贝叶斯优化和高斯过程回归模型的代理模型来重复监测和调整传感器排序系统的过程参数。", "innovation": "本研究使用高斯过程回归模型作为代理模型，结合贝叶斯优化方法，以最少的实验次数和考虑随机性来实现特定系统行为要求。该方法能够同时考虑两个物料输出流所需的优化目标，并在模型计算中考虑确定分类准确度的不确定性。", "conclusion": "为了验证该方法的有效性，作者使用了三个示例过程参数进行测试。这种方法可以通过尽量减少实验次数同时满足双重优化目标来提高传感器排序系统的性能，并且能够在模型计算中有效处理不确定性以提高分类准确性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01257", "html_url": "https://arxiv.org/abs/2509.01257", "title": "无线边缘网络中多智能体强化学习的任务卸载", "title_en": "Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks", "authors": "Andrea Fox,Francesco De Pellegrini,Eitan Altman", "background": "在边缘计算系统中，自主代理必须在有限的观察性和通信约束下，快速做出本地决策并竞争共享资源。现有的多智能体强化学习（MARL）方法通常依赖于集中式评论家或频繁通信，这无法适应这些限制。", "innovation": "提出了一个去中心化的框架，其中每个代理解决一个受约束的马尔可夫决策过程（CMDP），通过共享约束向量隐式协调。针对卸载特定情况，约束防止过度负载共享服务器资源。这些协调约束很少更新，作为一种轻量级协调机制，使代理能够实现全局资源利用目标，但不需要频繁的直接通信。通过安全的强化学习，代理学会了满足当地和全局目标的策略。", "conclusion": "在轻微假设下建立了理论保证，并通过实验验证了该方法，尤其是在大规模设置中，相比于集中式和独立的基线方法表现更优。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09874", "html_url": "https://arxiv.org/abs/2508.09874", "title": "Memory Decoder: 一种预先训练的即插即用大语言模型记忆", "title_en": "Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models", "authors": "Jiaqi Cao,Jiarui Wang,Rubin Wei,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin", "background": "大型语言模型（LLMs）在通用语言任务上表现出色，但在特定领域适应方面仍然存在挑战。现有方法如领域自适应预训练（DAPT）需要昂贵的全参数训练，并且容易出现灾难性遗忘。同时，检索增强生成（RAG）由于昂贵的最近邻搜索和更长的上下文引入了显著的推理延迟。", "innovation": "本文引入了Memory Decoder，这是一种插件式的预训练记忆，可以在不修改原始模型参数的情况下实现高效的领域适应。Memory Decoder采用一个小型的变压器解码器，学习模仿外部的非参数检索器的行为。实验表明，Memory Decoder能够有效适应Qwen和Llama等大型语言模型在生物医学、金融、法律三个不同专业的应用，平均降低困惑度6.17个点。", "conclusion": "总体而言，Memory Decoder引入了一种新的基于特定领域预训练记忆组件的范式。这种记忆架构可以以插件的形式集成，一致地提升目标领域中多个模型的性能。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.02753", "html_url": "https://arxiv.org/abs/2508.02753", "title": "DMSC: 动态多尺度协调框架用于时间序列预测", "title_en": "DMSC: Dynamic Multi-Scale Coordination Framework for Time Series Forecasting", "authors": "Haonan Yang,Jianchao Tang,Zhuo Li,Long Lan", "background": "时间序列预测（TSF）在建模不同时间尺度下的复杂时间依赖关系方面面临着持续的挑战。尽管最近的进展利用了不同的分解操作和基于CNN、MLP或Transformer的新型架构，但现有方法仍然在静态分解策略、依赖关系建模和融合机制的灵活性方面存在局限，这限制了它们建模复杂时间依赖关系的能力。", "innovation": "本文提出了一种名为DMSC（Dynamic Multi-Scale Coordination Framework，动态多尺度协调框架）的新颖解决方案，该框架包括多尺度块（EMPD）、三元交互块（TIB）和自适应尺度路由混合专家（ASR-MoE）块。EMPD动态地将序列分割为分层的具有指数级粒度的片段，TIB在每个分解表示内共同建模片段内、片段间和跨变量依赖关系。EMPD和TIB被联合集成到具有多层渐进级联架构的层中，通过门控路径使粗粒度表示从前层适应性地指导后续层的细粒度特征提取。ASR-MoE通过利用时间和局部专家进行动态融合，利用时间感知加权机制。全面的实验结果表明，DMSC在时间序列预测任务中保持了最先进的性能，并且具有更高的计算效率。", "conclusion": "DMSC框架在时间序列预测任务中展示了强大的性能和计算效率，并通过解决上述三个主要问题进行了创新，为该领域提供了新的视角。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.02844", "html_url": "https://arxiv.org/abs/2509.02844", "title": "时序变化点下的预测一致性方法", "title_en": "Conformal Prediction for Time-series Forecasting with Change Points", "authors": "Sophia Sun,Rose Yu", "background": "一致性预测已经被研究作为一种通用而有效的方法来为时序数据提供不确定性量化。然而，现有的方法很难处理包含变化点（即基础生成数据过程中的突然变化）的时序数据。", "innovation": "本文提出了一种新的时序变化点下的一致性预测（CPTC）算法，通过集成预测底层状态的模型与在线一致性预测来建模非平稳时序中的不确定性，从而弥补了当前的差距。并且证明了CPTC在最小假设下的有效性及其在时间序列设置中的增强适应性，并在六个合成和真实世界数据集上展示了与最先进的基准相比的改进的有效性和适应性。", "conclusion": "本文提出的CPTC算法在处理包含变化点的非平稳时序数据上具有更好的有效性和适应性，并且在实际应用中表现出了良好的一致性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19614", "html_url": "https://arxiv.org/abs/2508.19614", "title": "LFD: 层融合解码以利用检索增强生成中的外部知识", "title_en": "LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation", "authors": "Yang Sun,Zhiyong Xie,Dan Luo,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li,Lixin Zou", "background": "检索增强生成（RAG）将外部知识整合到大型语言模型（LLMs）中，提高其对下游任务的适应性并允许信息更新。最新实验证据显示，向检索出的相关文档中注入噪声反而有助于利用外部知识，提升生成质量。尽管这一现象看似反直觉且难以在实践中应用，但它允许对LLMs如何整合外部知识进行精细控制和深入分析。因此，本文通过干预噪声注入，并在LLM中建立了分层功能划分：浅层专注于局部上下文建模，中间层侧重于整合长距离的外部事实性知识，深层主要依赖于参数化的内嵌知识。在此基础上，作者提出了层融合解码（LFD），这是一种简单的解码策略，可以直接将中间层的表示与最终层解码输出结合起来，充分挖掘外部事实性知识。为了确定最佳的中间层，提出了一种内部知识评分（IKS）标准，选择层数后半部分IKS值最低的层。在多个基准上的实验结果表明，LFD有助于RAG系统更有效地呈现检索到的上下文知识而无需额外成本。", "innovation": "提出了LFD（层融合解码），这是一种简单的解码策略，可以直接将中间层的表示与最终层解码输出结合起来，充分挖掘外部事实性知识。为了选择最佳的中间层，引入了内部知识评分（IKS）标准，选择 Layers 的后半部分中 IKS 值最低的层。这一方法通过干预噪声注入，在 RAG 中实现了对 LLM 如何整合外部知识的控制和分析，提高了 RAG 系统的性能。", "conclusion": "实验结果表明，LFD 帮助 RAG 系统更有效地展示了检索到的上下文知识，同时保持了最小的计算成本。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.03738", "html_url": "https://arxiv.org/abs/2509.03738", "title": "稀疏自编码器神经算子：函数空间中的模型恢复", "title_en": "Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces", "authors": "Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar", "background": "尽管柏拉图表示假设表明神经网络在不同架构上收敛到相似的表示，但神经算子的表示特性仍然研究不足，尽管它们在科学计算中的重要性不断提高。本文将神经模型中的表示统一问题描述为稀疏模型恢复问题，并提出了一种框架，将稀疏自编码器扩展到提升空间和无限维函数空间中，以提供大型神经算子的机理可解释性。", "innovation": "本文提出了一种新的框架，将稀疏自编码器扩展到提升空间和无限维函数空间，从而对大规模神经算子实现机制上的可解释性。该研究对比了稀疏自编码器、提升稀疏自编码器和神经算子的学习动态，并指出提升和算子模块引入有益的归纳偏置，有助于更快的恢复和更平滑概念的恢复，以及在不同分辨率下稳健的推理。", "conclusion": "本研究有助于更深入地理解神经算子的表示和计算方法，并为科学计算中的表示问题提供了新思路。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.04462", "html_url": "https://arxiv.org/abs/2509.04462", "title": "评估GPT-5在生物医学自然语言处理中的性能", "title_en": "Benchmarking GPT-5 for biomedical natural language processing", "authors": "Yu Hou,Zaifu Zhan,Min Zeng,Yifan Wu,Shuang Zhou,Rui Zhang", "background": "生物医学文献和临床记录在自然语言理解方面提出了多方面挑战，包括精确实体提取、文档合成以及多步诊断推理。本研究旨在评估在零样本、单样本和五样本提示下，GPT-5和GPT-4o在五个核心生物医学自然语言处理任务中的表现。这五个任务分别是命名实体识别、关系提取、多标签文档分类、摘要和简化。", "innovation": "使用标准化提示、固定的解码参数和一致的推理流水线，研究对模型的性能、延迟和按令牌计算的成本进行了评估。GPT-5在各种数据集和任务中的表现优于GPT-4o，特别是在需要推理的任务上。尽管输出更长，GPT-5在延迟上表现相似，且每个正确预测的有效成本降低了30%到50%。", "conclusion": "GPT-5在生物医学问答任务中接近可部署性能，并且在准确性和经济效率之间提供了良好的平衡。结果支持分层提示策略：直接提示适用于大规模或成本敏感的应用，而复杂的分析或高风险的情形则需要逐步推理的支架构。这些发现强调了在精度和事实准确性至关重要的情况下，继续需要混合解决方案的必要性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.16449", "html_url": "https://arxiv.org/abs/2509.16449", "title": "PersonaMatrix：一种面向角色意识的法律摘要评估方法", "title_en": "PersonaMatrix: A Recipe for Persona-Aware Evaluation of Legal Summarization", "authors": "Tsz Fung Pang,Maryam Berijanian,Thomas Orth,Breanna Shi,Charlotte S. Alexander", "background": "法律文件往往冗长、晦涩，难以理解，无论对于普通大众还是法律专业人士都是如此。自动化文档摘要技术有潜力改善法律知识的获取，但现有的基于任务的评估者往往忽视了不同用户和利益相关者的需求差异。因此，需要开发一种工具，既能满足诉讼律师等专业用户的技术需求，又能使自我帮助的公众用户能够易于理解其案件的相关摘要。", "innovation": "本文介绍了一种名为PersonaMatrix的人格化评价框架，通过六个不同的人格视角评估摘要，包括法律用户和非法律用户。此外，还引入了一个控制维度偏移的试点数据集和多样性覆盖指数（DCI），以展示不同用户群体之间法律摘要的差异最优解。这种工作的目的是改进面向专家和非专家用户的法律AI摘要系统，从而增加访问法律知识的可能性。", "conclusion": "本工作使法律AI摘要系统的改进对于专家和非专家用户都成为可能，并具有增加法律知识获取能力的潜力。相关代码库和数据可以在GitHub上公开获取。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.06213", "html_url": "https://arxiv.org/abs/2509.06213", "title": "迈向人工智能计量学：隐规则环境与强化学习", "title_en": "Toward a Metrology for Artificial Intelligence: Hidden-Rule Environments and Reinforcement Learning", "authors": "Christo Mathew,Wentian Wang,Jacob Feldman,Lazaros K. Gallos,Paul B. Kantor,Vladimir Menkov,Hao Wang", "background": "本文探讨了在Game Of Hidden Rules (GOHR) 环境中通过强化学习进行学习的问题。GOHR环境是一个复杂的谜题，其中智能体需推断并执行隐藏规则以通过将游戏棋子放入桶中来清理一个6×6的棋盘。研究者采用了两种状态表征策略——焦点中心化（Feature-Centric, FC）和对象中心化（Object-Centric, OC），并通过Transformer基础的优势 actor-批评家（Advantage Actor-Critic, A2C）算法进行训练。同时，智能体只能访问部分观察信息，需要同时推理规则和通过经验学习最优策略。", "innovation": "本文的创新之处在于从形式化的隐规则环境出发研究强化学习，并探讨了两种不同的状态表示法在强化学习任务中的应用效果。该研究通过多实验设置和不同的试次清单进行评估，分析状态表示法对学习效率的影响及其转移效应。", "conclusion": "研究通过在多个基于规则的和基于试次清单的实验设置下评估模型的表现，分析了在GOHR环境下推断规则和学习策略的能力，并证明了聚焦中心化和对象中心化的不同表示法对学习效率和泛化能力的影响。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19271", "html_url": "https://arxiv.org/abs/2509.19271", "title": "WolBanking77：沃洛夫语银行语音意图分类数据集", "title_en": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "authors": "Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione", "background": "近年来，意图分类模型取得了显著的进步。然而，之前的研究所主要集中在高资源语言的数据集上，这导致了低资源语言以及高文盲率地区的研究缺失，这些地区更多地是口头交流而非书面交流。例如，在塞内加尔，沃洛夫语是90%人口的母语，而国家文盲率仍高达42%。沃洛夫语在西非地区实际上由超过1000万人使用。为解决这个问题，本文介绍了沃洛夫语银行语音意图分类数据集（WolBanking77），支持学术研究中的意图分类。WolBanking77目前包含9,791条文本句子和超过4小时的语音句子。", "innovation": "本文展示了沃洛夫语银行语音意图分类数据集（WolBanking77），并在此基础上进行了一系列实验，包括文本和语音领域的最新模型。实验结果对目前的数据集来说非常有前景。除此之外，论文还深入分析了数据集的内容，报告了NLP和ASR模型在WolBanking77数据集上的基础F1分数和词错误率指标，并进行了模型间的比较。", "conclusion": "数据集和代码现已在 +oldBanking77\"{此链接} （网络链接）上提供。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19834", "html_url": "https://arxiv.org/abs/2509.19834", "title": "TianHui: 专用于多种传统中医场景的领域特定大型语言模型", "title_en": "TianHui: A Domain-Specific Large Language Model for Diverse Traditional Chinese Medicine Scenarios", "authors": "Ji Yin,Menglan He,Yujie Zhang,Linshuai Zhang,Tingting Ma,Ce Tian,Jie Wu,Lin Xu,Tao Jiang,  ((1) School of Intelligent Medicine, Chengdu University of Traditional Chinese Medicine, Chengdu, China (2) The Acupuncture and Tuina School, Chengdu University of Traditional Chinese Medicine, Chengdu, China (3) Center of Preventive Medicine, Hospital of Chengdu University of Traditional Chinese Medicine, Chengdu, China (4) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China (5) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China)", "background": "在研究环境中，针对特定领域的大型语言模型（LLM），如中医（TCM），面临局限性，包括适应性受限制、缺乏充分的评估数据集以及计算资源有限。", "innovation": "该研究提出了TianHui，这是一种通过上下文数据整合和领域知识融合构建的专业化中医LLM。研究人员构建了一个大型的中医语料库（包括0.97GB无监督数据和611,312个问答对），并采用了两阶段训练策略，使用了QLoRA、DeepSpeed Stage 2和Flash Attention 2技术。TianHui在12个基准测试中的表现名列前茅，尤其是在六个数据集（APQ、TCMCD、HFR、HCCA、DHPE、TLAW）的所有指标中排名第一，在其他六个数据集（TCMEE、APR、GCPMI、TCMKQA、TCMRC、ADTG）中取得了最佳结果。优化配置为LoRA秩=128、alpha=256、周期=4、 dropout=0.2、最大长度=2048。TianHui使得中医知识的系统保存和可扩展应用成为可能，所有资源均开源。", "conclusion": "TianHui 旨在通过整合上下文数据和领域知识，解决传统中医领域的特定挑战，实现了在多个基准测试中的优异性能，并着重强调了其开源资源和广泛的应用潜力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20890", "html_url": "https://arxiv.org/abs/2509.20890", "title": "FerretNet：基于局部像素依赖的高效合成图像检测", "title_en": "FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies", "authors": "Shuqiao Liang,Jian Liu,Renzhang Chen,Quanlong Guan", "background": "随着生成模型如VAEs、GANs和LDMs的进步，合成图像的真实感显著提高。然而，这对合成图像检测构成了重大挑战。近年来的研究指出，合成图像在生成过程中会出现两种类型的缺陷：潜在分布偏差和解码过程中的平滑效应，这些缺陷会导致局部纹理、边缘和颜色过渡的一致性问题。传统的合成图像检测方法依赖于复杂的特征提取和分类过程，难以高效且准确地检测合成图像。因此，本文聚焦于基于局部像素依赖（LPD）的合成图像检测方法，以高效且稳健地解决这一挑战。", "innovation": "本文利用了Markov Random Fields的局部像素依赖（LPD）特性，通过相邻像素信息来重建合成图像，从而揭示纹理连续性和边缘一致性的破坏。在此基础上，作者提出了一种轻量级的神经网络FerretNet，该模型仅有1.1M的参数，能在保持高效的同时实现稳健的合成图像检测。此外，FerretNet仅使用4类ProGAN数据集进行训练，却可以在包含22个生成模型的开放世界基准中实现97.1%的平均准确率。", "conclusion": "本文通过引入基于局部像素依赖的FerretNet神经网络，能够在保证效率的同时提供优良的合成图像检测性能。实验结果表明，FerretNet在多样化的生成模型上表现出色，具有广泛的应用前景。源代码和数据集已在指定网址公开。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02279", "html_url": "https://arxiv.org/abs/2510.02279", "title": "解决自然语言生成中不确定性估计方法评估中的困境", "title_en": "Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods for Natural Language Generation", "authors": "Mykyta Ielanskyi,Kajetan Schweighofer,Lukas Aichberger,Sepp Hochreiter", "background": "自然语言模型（LLMs）中存在的幻觉问题影响了其可靠性。最近的研究发现了一种特定类型的幻觉——推测不确定性导致的错编（confabulations）。当前评估不确定性估计方法时，常用的方法是通过关联推测不确定性估计值与生成文本的正确性来评估。常用的近似正确性函数存在显著差异，导致不确定性估计方法在评价中的排名不稳定，容易使这些方法的性能显得更好。此外，疑问回答（QA）数据集作为标准基准，也被发现可能引入偏差。因此，需要改进不确定性评估的评价机制，以提供更稳健和可控制的风险指标。", "innovation": "提出了使用多个替代的风险指标来增强不确定性估计算法实证评估的稳健性，特别在疑问回答任务中，提出了利用多个LLM作为裁判的变种来降低评估偏差，同时探索了结构化任务以及分布外和扰动检测任务，这些都提供了稳健且可控的风险指标。还提出了利用不确定性估计方法的Elo排名来客观总结各种广泛的评估设置。", "conclusion": "本文提出的方法旨在解决当前不确定性评估中的问题，通过引入多个替代风险指标，结合LLM变种评估和不同任务类型的风险检测，为自然语言生成中不确定性估计方法评估提供更加稳健和客观的评价方式。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03369", "html_url": "https://arxiv.org/abs/2510.03369", "title": "TriQuest:由AI副驾赋能的跨学科课程设计平台", "title_en": "TriQuest:An AI Copilot-Powered Platform for Interdisciplinary Curriculum Design", "authors": "Huazhen Wang,Huimin Yang,Hainbin Lin,Yan Dong,Lili Chen,Liangliang Xia,Wenwen Xu", "background": "跨学科教学是现代课程改革的基础，但其实现面临知识整合和课时计划耗时的挑战。现有工具往往缺乏必需的教育学和特定领域的知识整合能力。", "innovation": "TriQuest是一款基于大型语言模型和知识图谱的人机协作平台，通过直观的GUI帮助教师高效生成高质量的跨学科教案。其核心功能包括智能跨学科知识整合和人机协作审查过程，以确保质量和效率。", "conclusion": "我们的研究使用43位教师进行实验，结果显示TriQuest提高了课程设计效率并提高了教案质量。它还显著降低了设计障碍和认知负荷。本研究提出了一种利用智能技术提升教师专业发展的新范式。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02253", "html_url": "https://arxiv.org/abs/2510.02253", "title": "DragFlow：使用基于区域的监督释放DiT先验以进行拖拽编辑", "title_en": "DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing", "authors": "Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong", "background": "传统的基于拖拽的图像编辑面临着目标区域失真的问题，主要因为早期的基模型（如Stable Diffusion）的先验不足，无法将优化后的潜在空间平滑地投影回自然图像流形。随着从UNet为基础的DDPMs转向DiT及其流匹配方式（如SD3.5, FLUX），生成先验变强，使得拖拽以外的编辑任务有了突破。然而，拖拽编辑尚未从这些更强的先验中获益。本文通过引入首个利用FLUX丰富的先验以有效实现拖拽编辑的框架，称为DragFlow，实现了显著的进步。早期尝试直接将基于点的拖拽编辑应用于DiT时表现不佳，因为DiT的特性不如UNet压缩和结构化，无法提供可靠的方向监督。为克服这一局限，DragFlow引入了一种基于区域的编辑模式，通过仿射变换提供更加丰富和一致的特征监督，同时通过基于梯度掩码的硬约束增强主题一致性，保留背景保真度，并利用多模态的大语言模型解决任务歧义问题。为了评估，作者创建了一个新的基于区域的拖拽基准（ReD Bench），考察了region-level拖拽指令的表现。实验表明，DragFlow超过了基于点和基于区域的基线方法，刷新了基于拖拽的图像编辑领域的最新记录。代码和数据将在发表时公开。", "innovation": "首先，引入了一个基于区域的编辑框架（DragFlow），该框架利用FLUX的丰富先验来改善基于拖拽的图像编辑效果。它通过仿射变换提供建立区域编辑时的一致性特征监督，并通过梯度掩码的硬约束增加主题一致性。同时，博士论文提出了一个创新的大语言模型，用于解决任务歧义问题。此外，通过创建一个新的基准测试（ReD Bench），评估了该方法在不同条件下的性能。", "conclusion": "DragFlow框架显著改进了基于拖拽编辑的效果，成为基于拖拽图像编辑领域的最新研究突破。该研究通过创建的数据集和提高的编辑技术，展示了一个新的方法，能够用于实际的应用场景中，相比之前的基线方法展现了更好的性能。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02855", "html_url": "https://arxiv.org/abs/2510.02855", "title": "基于约束满足方法的Wordle：新颖启发式方法与跨语言验证", "title_en": "Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel", "background": "Wordle是一个算法层面丰富的困惑解决测试平台，现有的解决方法主要依赖信息论熵最大化或基于频率的经验启发式方法，没有正式的约束处理机制。", "innovation": "该研究首次全面提出了针对Wordle问题的约束满足（CSP）公式，并引入了新的基于约束的认知熵计算方法CSP-Aware Entropy，结合了贝叶斯单词频率先验与逻辑约束的概率CSP框架。通过2,315个英文单词的评估，CSP-Aware Entropy在99.9%的成功率下，平均只需3.54次猜测，并且比前向检查算法在猜测时间上快46%。在10%噪声水平下，CSP-意识方法保持5.3个百分点的优势，而概率CSP通过约束恢复机制在所有噪声水平（0-20%）下保持100%的成功率。跨语言验证在500个西班牙单词上实现了88%的成功率，验证了约束满足的基本原理在不同语言中具有通用性，尽管存在语言差异11.2个百分点的差距。开源实现和广泛的单元测试确保了研究的可重复性。", "conclusion": "新的约束满足技术超越了传统信息论和基于学习的方法在结构化谜题解决领域中的性能，通过正式的CSP处理、基于约束的启发式、概率与逻辑的结合、鲁棒性分析和跨语言验证，这项工作确立了新的性能基准。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.06863", "html_url": "https://arxiv.org/abs/2509.06863", "title": "floq：通过流配对训练评价器以提高值基强化学习中的计算能力", "title_en": "floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL", "authors": "Bhavya Agrawalla,Michal Nauman,Khush Agrawal,Aviral Kumar", "background": "现代大规模机器学习技术的一个关键特征是在中间计算中提供密集监督的目标函数，例如语言模型中的教师强迫和扩散模型中的逐步去噪。这种方法使模型能够以一种可泛化的途径学习复杂的函数。受这一观察结果的启发，论文研究了迭代计算对强化学习（RL）中时差（TD）方法的益处。传统的TD方法通常以单一的方式表示值函数，而不进行迭代计算。论文引入了floq（流匹配Q函数），这是一种使用速度场参数化Q函数的方法，并使用生成建模中常用的流匹配技巧进行训练。这种方法通过数值积分的多步运行计算的目标速度场的值来采用TD学习目标，从而实现强化学习中值函数的迭代学习，提供了比单一架构更精细的控制和Q函数容量的扩展。", "innovation": "论文提出了floq（流匹配Q函数）方法，这是一种将Q函数参数化为速度场的方法，并通过流匹配技术进行训练。这种方法使用TD学习目标进行训练，通过运行数值积分的多步计算来生成目标速度场的值。floq方法使得Q函数的容量可以通过适当地设置积分步骤来进行更精细的控制和扩展，从而显著提高了值基强化学习中的性能。", "conclusion": "在一系列具有挑战性的离线RL基准测试和在线微调任务中，floq的方法将性能提高了近1.8倍。与标准的TD学习架构相比，floq更能按需扩展Q函数的容量，研究表明迭代计算在价值学习中的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04755", "html_url": "https://arxiv.org/abs/2510.04755", "title": "一个新的数字鸿沟？开发者世界观、烂经济与人工智能时代的民主", "title_en": "A New Digital Divide? Coder Worldviews, the Slop Economy, and Democracy in the Age of AI", "authors": "Jason Miklian,Kristian Hoelscher", "background": "数字技术以复杂的方式改变了民主生活。本文通过探讨软件开发者的世界观、伦理观及其工作文化对所构建技术的民主潜力和社会影响的影响，结合新兴的信息质量数字鸿沟（即以免费内容为主的低质量、广告驱动的互联网）的现象，分析了当前数字时代的技术创建者信念与所创造的数字生态系统之间的相互作用，旨在揭示技术创新如何既能支持也能颠覆民主价值观。", "innovation": "本文创新地将软件开发者调查与信息质量数字鸿沟的概念结合，揭示了技术创建者信念与其所塑造的数字生态系统之间的动态关系，并强调了需要更加伦理导向的设计和政策干预来应对新一代技术所带来的挑战，从而确保技术创新更好地服务于民主价值的实现。", "conclusion": "本文强调在人工智能时代，技术创建者的信念和道德意识对于维护和增强民主价值至关重要，提出了需要更加伦理导向的设计和政策建议，以确保数字技术创新能够支持而非颠覆民主价值观。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08396", "html_url": "https://arxiv.org/abs/2510.08396", "title": "FlyLoRA: 通过隐式逐秩混合专家提升任务解藕和参数效率", "title_en": "FlyLoRA: Boosting Task Decoupling and Parameter Efficiency via Implicit Rank-Wise Mixture-of-Experts", "authors": "Heming Zou,Yunliang Zang,Wutong Xu,Yao Zhu,Xiangyang Ji", "background": "LoRA 作为参数高效的基础模型微调方法被广泛使用，但由于参数干涉问题导致性能次优。虽然基于 MoE 的 LoRA 变种在单任务指令微调中表现出缓解任务内相关性的潜力，但它们引入了额外的路由器参数，并在多任务模型融合中对任务间干扰无效。", "innovation": "提出了一种基于隐式 MoE 的 FlyLoRA 变体，通过两方面改进 LoRA：1）在上投影矩阵中引入逐秩专家激活；2）引入了一个隐式路由器，整合了专家路由和下投影，其中冻结的稀疏随机投影矩阵替代了传统的稠密可训练版本。这种设计通过消除显式路由器的需求解决了任务内解藕和计算效率之间的权衡，并由于随机矩阵的正交性属性，自然缓解了任务间干扰。", "conclusion": "FlyLoRA 在四个领域（通用知识理解、科学问答、数学推理和代码生成）中的一系列实验一致地展示了相比于现有方法的性能改进。FlyLoRA 还强调了生物结构如何启发 AI 技术的创新。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.07686", "html_url": "https://arxiv.org/abs/2510.07686", "title": "对模型规格的压力测试揭示了语言模型之间的性格差异", "title_en": "Stress-Testing Model Specs Reveals Character Differences among Language Models", "authors": "Jifan Zhang,Henry Sleight,Andi Peng,John Schulman,Esin Durmus", "background": "大语言模型（LLMs）从人工智能宪法和模型规范中进行训练，这些规范设定了行为准则和伦理原则。然而，这些规范面临内部原则冲突和对复杂情景覆盖不足的挑战。本文提出了一种系统的方法来测试模型性格规范，自动识别当前模型规范中的原则冲突和解释歧义，并通过生成迫使模型在竞争的价值原则之间做出显式权衡的场景来进行压力测试。", "innovation": "本文介绍了一种系统的方法，用于压力测试模型性格规范，生成多种情境以明确不同价值原则之间的权衡；使用全面的分类体系生成多样的价值权衡场景，评估来自不同提供商的十二种前沿LLM的反应，并通过价值分类评分衡量行为分歧，揭示超过70,000个显著的行为分歧案例。", "conclusion": "实证结果显示，模型行为的巨大分歧强烈预测了模型规范中存在的问题。通过定性分析，本文提供了当前模型规范中的多个直接矛盾和解释歧义问题，此外，通过生成的数据集也揭示了所有研究模型中的清晰误导案例和假阳性拒绝案例。最后，本文还提供了多种模型的价值优先级和差异。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04008", "html_url": "https://arxiv.org/abs/2510.04008", "title": "将Softmax相似性替换为强化的余弦相似性：扩展到十亿上下文注意力的理论与实践", "title_en": "Replacing Softmax Similarity with a Sharpened Angular Similarity: Theory and Practice of Scaling To Billion-Context Attention", "authors": "Sahil Joshi,Agniva Chowdhury,Amar Kanakamedala,Ekam Singh,Evan Tu,Anshumali Shrivastava", "background": "Softmax 注意力在处理长上下文时具有二次时间复杂度，这使得在优化的GPU内核上运行变得不可行。例如，FlashAttention（一种GPU优化的Softmax 注意力实现）在NVIDIA GH200（96GB）上无法完成多头注意力层的单次前向和后向传递，一旦上下文长度超过约400万个标记。研究者指出，当前的先进注意力实现面临着在现有硬件上处理极长上下文的实践限制。", "innovation": "提出了一种称为RACE注意力的新机制，这是一种基于内核的替代Softmax注意力，时间复杂度线性于序列长度和嵌入维度。RACE注意力用锐化的余弦相似性代替了指数核，并通过随机投影和软局部敏感哈希（LSH）来近似注意力输出，该机制在语言建模、掩码语言建模和文本分类中与强基线具有相同的精度，同时减少了运行时间和内存占用。在控制标度测试中，该机制可以在单次前向和后向传递中处理超过1200万个标记的NVIDIA GH200 GPU，并且在一次前向传递中处理7500万个标记的Intel Xeon Gold 5220R CPU，大大超出了当前最先进的注意力实现的实用性限制。", "conclusion": "RACE注意力为现代硬件提供了实用而理论基础的机制，可以处理极其长的上下文窗口。作者希望该机制能够得到实际应用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.09114", "html_url": "https://arxiv.org/abs/2510.09114", "title": "关于隐私保护的公平性：测量和缓解差 throwable-privacy 风险差异以促进差 throwable-private 机器学习中的隐私保护公平性", "title_en": "On the Fairness of Privacy Protection: Measuring and Mitigating the Disparity of Group Privacy Risks for Differentially Private Machine Learning", "authors": "Zhi Yang,Changwu Huang,Ke Tang,Xin Yao", "background": "虽然在传统公平意识机器学习（ML）和不同隐私机器学习（DPML）方面取得了显著进展，但不同群体之间的隐私保护公平性仍然未得到充分探索。现有研究提出了评估群体隐私风险的方法，但这些方法主要基于数据记录的平均隐私风险。这种方式可能低估了群体隐私风险，从而可能低估了群体隐私风险之间的差异。此外，当前评估数据记录最坏情况隐私风险的方法耗时较长，限制了其实际应用。", "innovation": "引入了一种新颖的成员归属推理游戏，可以高效地审计数据记录的近似最坏情况隐私风险。实验结果表明，该方法为群体隐私风险提供了更为严格的标准衡量，从而可以可靠地评估群体隐私风险之间的差异。此外，为了在DPML中促进隐私保护公平性，基于差 throwable-private 机器学习审计研究中 Canary 设计策略，增强标准DP-SGD算法，实现了群体特定梯度裁剪策略，从而有效减少了群体隐私风险之间的差异，提高了DPML中的隐私保护公平性。", "conclusion": "我们的方法提供了对群体隐私风险更为严格的测量，并提供了对群体隐私风险差异的可靠评估。此外，我们的算法通过实现群体特定梯度裁剪策略，有效减少了群体隐私风险之间的差异，提高了DPML中隐私保护的公平性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.06377", "html_url": "https://arxiv.org/abs/2510.06377", "title": "关系变换器：通往关系数据零样本基础模型的道路", "title_en": "Relational Transformer: Toward Zero-Shot Foundation Models for Relational Data", "authors": "Rishabh Ranjan,Valter Hudovernik,Mark Znidar,Charilaos Kanatsoulis,Roshan Upendra,Mahmoud Mohammadi,Joe Meyer,Tom Palczewski,Carlos Guestrin,Jure Leskovec", "background": "预训练的变换器在新品模型任务的零样本提示下表现出色，但在关系领域仍然缺乏能够跨数据集和任务迁移的架构。核心挑战在于关系数据的多样性，包括变化的异构架构、图结构和功能依赖关系。针对这一挑战，本文提出了关系变换器（RT）架构，该架构能够在多样化的关系数据库上进行预训练，并可以直接应用于未见过的数据集和任务，无需特定任务或数据集的微调，也不需要上下文示例的检索。RT通过利用表格/列元数据对单元格进行分词，通过遮蔽标记预测进行预训练，并利用一种新的关系注意机制处理列、行及主键-外键链接。", "innovation": "RT架构通过引入新的关系注意机制，能够直接应用于未见过的数据集和任务，无需特定任务或数据集的微调，或检索上下文示例。此外，它在遮蔽标记预测下进行预训练，并在多个任务上进行了预训练，包括流失和销售预测。结果显示，使用单一前向传递的2200万参数模型，预训练后的RT平均达到93%的完全监督AUC ROC，而270亿参数最大的语言模型只有84%。微调后，RT取得最新的研究结果，具有高效样本利用性。实验表明，RT的零样本迁移利用了任务-表上下文、关系注意力模式和模式语义。", "conclusion": "RT为关系数据提供了一条实用的道路，使其成为未来基础模型的一部分，并能够有效地进行零样本迁移，利用任务-表上下文、关系注意力模式和模式语义。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12384", "html_url": "https://arxiv.org/abs/2510.12384", "title": "全表型多组学整合揭示人类衰老的独特模式", "title_en": "Phenome-Wide Multi-Omics Integration Uncovers Distinct Archetypes of Human Aging", "authors": "Huifa Li,Feilong Tang,Haochen Xue,Yulong Li,Xinlin Zhuang,Bin Zhang,Eran Segal,Imran Razzak", "background": "衰老是一个高度复杂且异质的过程，不同个体的衰老速度差异显著。生物年龄比实际年龄更能准确反映生理衰退。尽管以前的研究使用单组学数据建立了衰老时钟，但在捕捉人类衰老的完整分子复杂性方面存在局限性。本研究利用包含10,000名40-70岁成年人的大规模队列，这些成年人有广泛的纵向监测数据，包括临床、行为、环境和多组学数据（涵盖转录组学、脂质组学、代谢组学和微生物组）。", "innovation": "利用先进的机器学习框架，分析多组学数据，建立了一个人类衰老时钟。该时钟能够预测多种健康结果和未来疾病风险，并通过无监督聚类发现了不同生物亚型的衰老模式，揭示了衰老过程的显著异质性及与不同衰老模式相关的特定途径变化。此多组学整合方法加强了对衰老分子景观的理解，并为个性化健康监测和预防衰老相关疾病提供了基础。", "conclusion": "该研究揭示了多组学整合在解析衰老过程中的强大作用，为个性化健康监测和精准预防策略铺平了道路。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.12953", "html_url": "https://arxiv.org/abs/2510.12953", "title": "针对胎儿超声波解读的认知意识视图语言基础模型", "title_en": "Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation", "authors": "Xiao He,Huangxuan Zhao,Guojia Wan,Wei Zhou,Yanxing Liu,Juhua Liu,Yongchao Xu,Yong Luo,Dacheng Tao,Bo Du", "background": "近年来，医学领域的视图语言模型已经在诸如VQA（视觉问答）、报告生成和异常检测等任务上展现出良好的性能。然而，这些模型大多适应于结构化的成人成像，但在胎儿超声等场景下的表现不佳。胎儿超声检查涉及到多视角的影像推理、多种疾病的检测和影像多样性等问题，给临床应用带来了挑战。", "innovation": "为了解决上述问题，本文提出了一款名为FetalMind的新生儿超声医学人工智能系统，能够用于报告生成和诊断。该系统采用了一种称为Epistemic-aware Salient Epistemic Disentanglement (SED)的设计，将专家手动编写的双分图注入模型中，以解耦视角和疾病的关联，并通过强化学习的方式引导偏好选择，遵循临床步骤。此外，作者还构建了一个大规模的FetalSigma-1M数据集，包含20,000个报告，来自十二个医疗中心，解决了领域数据稀缺的问题。", "conclusion": "本文提出的方法和构建的数据集显著提高了胎儿超声解释的性能，在所有妊娠阶段中均优于开源和闭源基线模型。具体来说，FetalMind在关键条件上的准确度提升了61.2%，并且保持了高效、稳健和可扩展的特点。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11100", "html_url": "https://arxiv.org/abs/2510.11100", "title": "HoMer: 通过建模序列和集合上下文来解决异质性进行点击率预测", "title_en": "HoMer: Addressing Heterogeneities by Modeling Sequential and Set-wise Contexts for CTR Prediction", "authors": "Shuwei Chen,Jiajun Cui,Zhengqi Xu,Fan Zhang,Jiangke Fan,Teng Zhang,Xingxing Wang", "background": "点击率（CTR）预测模型通过对行为序列和非序列特征（如用户/项配置文件或交叉特征）进行建模以推断用户兴趣，支撑工业推荐系统。然而，大部分方法面临三种形式的异质性，这些异质性影响了预测性能：（i）特征异质性，由于有限的行为辅助特征提供的兴趣表示不如广泛非序列特征颗粒，影响了序列建模性能；（ii）上下文异质性，由于用户对一项的兴趣会受到其他项目的影响，但点预测忽视了整个项目集中的项目间交互上下文；（iii）架构异质性，源于专业化网络模块的分散整合，该整合方式在工业部署中降低了模型的效果、效率和可扩展性。", "innovation": "我们提出了HoMer，针对序列和集合上下文建模的同质化导向Transformer，以解决上述限制。首先，我们对序列辅助特征与非序列特征进行对齐，实现准确的序列建模和精细的兴趣表示；其次，从点预测转向集合预测，以并行方式促进项目间交互；第三，HoMer的统一编码-解码架构通过结构简化和共享计算实现双重优化，确保计算效率同时随着模型大小增加保持可扩展性。无需对预测管道进行复杂修改，HoMer成功扩展并在AUC度量标准上优于我们的工业基线，提高在线业务指标如CTR/RPM达1.99%/2.46%。此外，通过初步工程技术优化，HoMer节省了27%的GPU资源，进一步验证了其优越性和实用性。", "conclusion": "HoMER模型在不需对预测管道进行复杂修改的前提下，能够有效扩展并对工业基准模型（AUC上提高了0.0099）进行超越，同时在线业务指标如CTR和RPM的性能均有显著提升，证明其在GPU资源上也具有高效的使用效率。HoMER开辟了一条有希望的道路，有效解决当前CTR模型面临的主要挑战，具有广泛的应用潜力。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15001", "html_url": "https://arxiv.org/abs/2510.15001", "title": "VaultGemma：一种具有差异隐私性的Gemma模型", "title_en": "VaultGemma: A Differentially Private Gemma Model", "authors": "Amer Sinha,Thomas Mesnard,Ryan McKenna,Daogao Liu,Christopher A. Choquette-Choo,Yangsibo Huang,Da Yu,George Kaissis,Zachary Charles,Ruibo Liu,Lynn Chua,Pritish Kamath,Pasin Manurangsi,Steve He,Chiyuan Zhang,Badih Ghazi,Borja De Balle Pigem,Prem Eruvbetine,Tris Warkentin,Armand Joulin,Ravi Kumar", "background": "库姆家族的Gemma系列模型在大型语言模型领域取得了显著进展，但与这些模型相关的隐私问题引起了广泛关注。VaultGemma 1B是在Gemma 2系列所用相同数据集上完全训练的10亿参数模型，旨在进一步提升隐私保护。", "innovation": "VaultGemma 1B是通过差分隐私训练的大型语言模型，它在Gemma系列的基础上实现了重要的隐私增强。10亿参数规模使得模型具备强大的语言理解和生成能力，同时能够保护用户隐私。", "conclusion": "作者公开发布了VaultGemma 1B模型，鼓励研究界探索和利用这一具有隐私保护特性的大型语言模型。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14449", "html_url": "https://arxiv.org/abs/2510.14449", "title": "基于梯度下降优化和L1稀疏约束的一对多逻辑回归的特征选择与正则化实证研究", "title_en": "Feature Selection and Regularization in Multi-Class Classification: An Empirical Study of One-vs-Rest Logistic Regression with Gradient Descent Optimization and L1 Sparsity Constraints", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel", "background": "多类葡萄酒分类面临模型准确性、特征维度和可解释性之间的基本权衡，这是化学分析中生产部署的关键因素。本文对UCI葡萄酒数据集（178个样本，3个品种，13个化学特征）进行了全面的实证研究，探讨了从头开始的梯度下降实现与scikit-learn优化求解器之间的区别，以及L1正则化对特征稀疏性的影响。", "innovation": "研究展示了从头开始的梯度下降实现达到92.59%的平均测试精度，同时阶跃收敛；scikit-learn提供了24倍的训练速度提升和98.15%的精度。L1正则化能减少54-69%的特征但精度仅减少4.63%。研究提出一个最优的5个特征子集，达到62%的复杂度减少，估计精度为92-94%，并实现每样本80美元的成本节约和56%的时间减少。统计验证表明，这种分类方法具有良好的推广性，并适合实时质量控制。", "conclusion": "本研究为资源受限环境下的化学分析综合测量与目标特征测量提供了实用指南，并指出最优的5特征子集在降低成本和提高效率方面有重要作用。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15382", "html_url": "https://arxiv.org/abs/2510.15382", "title": "稳健的零样本强化学习研究", "title_en": "Towards Robust Zero-Shot Reinforcement Learning", "authors": "Kexin Zheng,Lauriane Teyssier,Yinan Zheng,Yu Luo,Xianyuan Zhan", "background": "最近，零样本强化学习（RL）的发展开启了一种新途径，可以学习通用的预先训练政策，这些政策能够以零样本的方式适应任意的新任务。虽然向前-向后表示（FB）和相关方法在零样本RL中显示了潜力，但实验证明它们的建模缺乏表达力，且在离线学习过程中由于分布外（OOD）动作导致外推误差有时会导致有偏表示，最终导致性能不佳。", "innovation": "我们提出了行为正则化增强零样本RL（BREEZE），一种基于FB的增强框架，同时提高了学习稳定性、政策提取能力和表示学习质量。BREEZE在零样本RL策略学习中引入了行为正则化，将策略优化转换为一种稳定的样本内学习范式。此外，BREEZE使用任务条件化的扩散模型提取策略，使得在零样本RL设置中生成高质量和多模态动作分布成为可能。此外，BREEZE采用具有表达性的注意力基架构进行表示建模，以捕捉环境动力学之间的复杂关系。", "conclusion": "在ExORL和D4RL Kitchen的广泛实验中，BREEZE表现出最佳或接近最佳的性能，相较于先前的离线零样本RL方法具有更好的鲁棒性。官方实现可从这个链接下载：this https URL。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.13894", "html_url": "https://arxiv.org/abs/2510.13894", "title": "贝叶斯还是海森堡：谁（或谁）负责？", "title_en": "Bayes or Heisenberg: Who(se) Rules?", "authors": "Volker Tresp,Hang Li,Federico Harjes,Yunpu Ma", "background": "尽管量子系统通常由量子状态向量描述，研究表明在特定情况下，其测量过程可以被重新表述为概率方程，其中使用了概率状态向量。进一步地，这种概率表示可以由张量大脑（TB）模型的神经网络动态近似表示。张量大脑是一种最近提出的框架，用于模拟大脑中的感知和记忆，并提供了将生成的符号表示高效整合到推理过程中的生物启发机制。因此，论文的背景着重于探讨传统量子测量理论与概率论之间的关系及其在现代神经网络模型中的应用可能性。", "innovation": "该研究提出了在某些情况下量子系统的测量过程可以被重新表达为基于概率状态向量的概率方程，并且这种概率表示可以由张量大脑（TB）模型的神经网络动态近似表示。这为将生物启发机制与现代神经网络模型相结合以有效进行推理提供了一种新方法。", "conclusion": "研究表明，量子测量过程中的概率方程可以用张量大脑模型中的神经网络动态表示，这不仅为理解量子现象提供了新的视角，也为发展认知计算和推理过程提供了新的理论支持。作者进一步提出了一个问题：在认知过程中，是遵循贝叶斯理论还是遵循海森堡的不确定性原理，谁才是合理的理论基础。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.11824", "html_url": "https://arxiv.org/abs/2510.11824", "title": "在协作多智能体强化学习中的鲁棒性和韧性经验研究", "title_en": "Empirical Study on Robustness and Resilience in Cooperative Multi-Agent Reinforcement Learning", "authors": "Simin Li,Zihao Mao,Hanxiao Li,Zonglei Jing,Zhuohang bian,Jun Guo,Li Wang,Zhuoran Han,Ruixiao Xu,Xin Yu,Chengdong Ma,Yuqing Ma,Bo An,Yaodong Yang,Weifeng Lv,Xianglong Liu", "background": "在协作多智能体强化学习(MARL)中，通常在理想的模拟环境中调整超参数以最大化合作性能。但在现实世界中，用来合作调优的策略可能无法保持在不确定性下的鲁棒性和恢复能力。建立可信赖的MARL系统需要对鲁棒性和恢复能力有深入理解，它们分别确保在不确定性下的稳定性以及从干扰中恢复的能力。这些概念在控制系统中被广泛研究，但在MARL中的关注度却较低。", "innovation": "本文进行了一项大规模的经验研究，包含超过82,620次实验，评估了在4个真实环境、13种不确定性类型和15种超参数下的MARL的合作、鲁棒性和恢复能力。研究发现，在轻微的不确定性条件下，优化合作可以提高鲁棒性和恢复能力，但随着扰动的加剧，这种关系会减弱，并且鲁棒性和恢复能力也因算法和不确定性类型而异。此外，这次研究还发现鲁棒性和恢复能力并不会在不确定性模态或智能体范围间泛化。因此，超参数调优对于可信赖MARL至关重要。研究还发现标准做法如参数共享、GAE和PopArt甚至可能损害鲁棒性，而如早期停止、高评论家学习率和Leaky ReLU则始终有助于提高这些性质。", "conclusion": "通过仅优化超参数，我们观察到在所有MARL架构中的合作、鲁棒性和恢复能力显著改善，这种现象还推广到了这些架构下的鲁棒MARL方法。研究结果提供代码和实验结果可在指定URL获取。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16171", "html_url": "https://arxiv.org/abs/2510.16171", "title": "连接对称性和鲁棒性：增强对抗鲁棒性的同变性的作用", "title_en": "Bridging Symmetry and Robustness: On the Role of Equivariance in Enhancing Adversarial Robustness", "authors": "Longwei Wang,Ifrat Ikhtear Uddin,KC Santosh,Chaowei Zhang,Xiao Qin,Yang Zhou", "background": "对抗样本揭示了深度神经网络在不可察觉输入扰动下的关键漏洞。虽然对抗训练是最主要的防御策略，但它会带来显著的计算成本，并且可能会损害清洁数据的准确性。", "innovation": "本文通过将群集不变卷积，特别是旋转和尺度不变层，嵌入标准卷积神经网络（CNN）中，研究了一种架构上的对抗鲁棒性方法。这种网络通过编码对称先验来促进决策边界更平滑，并提高对对抗攻击的抗性。提出并评估了两种对称意识架构：一种并行设计和一种级联设计。", "conclusion": "理论和实验结果表明，这种模型可以减少假设空间的复杂性，正则化梯度，并在CLEVER框架下产生更紧的鲁棒性界。这种模型在CIFAR-10、CIFAR-100和CIFAR-10C下的FGSM和PGD攻击下均可提高对抗鲁棒性和泛化能力，无需进行对抗训练。这些发现表明，对称增强架构可以作为一种有效的、有原则的替代方案，比基于数据增强的防御策略更高效。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17111", "html_url": "https://arxiv.org/abs/2510.17111", "title": "高效视觉-语言-动作模型在体化操作中的系统综述", "title_en": "Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey", "authors": "Weifan Guan,Qinghao Hu,Aosheng Li,Jian Cheng", "background": "视觉-语言-动作（VLA）模型通过将自然语言指令和视觉观察映射到机器人动作，扩展了视觉-语言模型的技术范围，实现了具身控制。尽管VLA系统在技术上具有广泛的应用前景，但它们面临着巨大的计算和内存需求，这与边缘平台如车载移动 manipulator 所要求的实时性能相冲突。", "innovation": "本文提供了一种系统的回顾，重点在于提高VLA效率的方法，包括减少延迟、内存足迹和训练/推理成本。文章将现有的解决方案分为四个维度：模型架构、感知特征、动作生成和训练/推理策略，总结了各个类别中的代表性技术。", "conclusion": "最后，讨论了未来趋势和开放挑战，指出推进具身智能进步的方向。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16709", "html_url": "https://arxiv.org/abs/2510.16709", "title": "HumanCM：一步完成的人体动作预测", "title_en": "HumanCM: One Step Human Motion Prediction", "authors": "Liu Haojie,Gao Suixiang", "background": "该研究主要讨论了一种基于一致性模型的一体化人体动作预测框架HumanCM。现有的动作预测方法通常依赖于多步去噪方法，在扩散模型中不依赖此类解决办法，而是采用了一步高效生成的方法，通过学习噪声状态和清洁状态之间的一致性映射实现动作预测。框架利用基于Transformer的空间-时间架构和时间嵌入，来建模长期依赖关系并保持动作连贯性。通过在Human3.6M和HumanEva-I数据集上的实验表明，HumanCM在动作预测的准确性上获得了与最先进的扩散模型相当或更优的结果，并且减少了高达两个数量级的推理步骤数。", "innovation": "这是通过引入一种新的基于一致性模型的一体化人体动作预测框架HumanCM实现的，该框架采用高效的一次生成方法，学习噪声状态到清洁状态的映射，同时利用基于Transformer的空间-时间架构和时间嵌入来建模长期依赖关系，保持动作连贯性，从而提高预测的准确性和效率", "conclusion": "实验结果表明，HumanCM的预测准确性和效率相比现有的扩散模型有了显著提升，尤其是在实际应用中的优势更加明显。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16807", "html_url": "https://arxiv.org/abs/2510.16807", "title": "通过初始值头的跳接连接提高模型表示并减少KV缓存", "title_en": "Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads", "authors": "Zhoutong Wu,Yuan Zhang,Yiming Dong,Chenheng Zhang,Cong Fang,Kun Yuan,Zhouchen Lin", "background": "Transformer 模型在各种语言任务中取得了突破，这是因为它们能够学习丰富的上下文表示。然而，为了提升表示能力，通常需要大量增加内存和计算成本。这类成本在自动回归解码期间通过关键值（KV）缓存体现。尽管跳接连接能改善表示能力而不增加资源使用，但大多数现有工作要么保持KV成本不变并提升表达能力，要么减少内存使用但表示能力较弱。", "innovation": "该研究提出了一种名为 SkipV1Former 的 Transformer 变体，使用第一层值头部的跳接连接来增强模型表示并减少 KV 缓存。具体来说，从第二层块开始，每一层重用了从第一层获取的值头部的一半，而另一半则正常计算，从而将值投影和 V 缓存减少近一半。此外，研究还提出了一种对现有 MHA Transformer 检查点进行上训练的方法，仅增加约 10-15% 的计算开销即可转换成 SkipV1Former。此外，该方法还可以与其他高级技术（如组查询注意和多潜伏注意）无缝结合，进一步降低 KV 缓存量并提升性能。", "conclusion": "SkipV1Former 在不同规模的模型中始终能减少约 25% 的 KV 缓存，同时优于标准的多头注意力（MHA）Transformer 及一些高级变体。与 YOCO 结合使用时，KV 缓存减少了近 50%，同时还能进一步提升效能。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17385", "html_url": "https://arxiv.org/abs/2510.17385", "title": "TabR1：用于表格推理的GRPO控制", "title_en": "TabR1: Taming GRPO for tabular reasoning LLMs", "authors": "Pengxiang Cai,Zihao Gao,Jintai Chen", "background": "传统的表格预测依赖于梯度增强决策树和专业化的深度学习模型，虽然在特定任务上表现出色，但缺乏透明度且在表格之间的迁移能力较弱。大型语言模型（LLMs）提出了跨任务适应性的潜力，并具有透明的推理痕迹，但它们尚未充分利用以处理表格数据。", "innovation": "提出了TabR1，这是第一个用于表格预测的多步骤推理LLM，核心在于Permutation Relative Policy Optimization（PRPO），这是一种简单而有效的强化学习方法，通过编码列移位不变性作为结构先验。PRPO通过构建每个样本的多个标签保持排列，并在排列内和跨排列估计优势，将稀疏奖励转化为密集的学习信号，从而提高了泛化能力。在有限监督下，PRPO激活了LLMs的推理能力，提高了少样本和零样本性能及可解释性。", "conclusion": "全面的实验表明，当进行全监督微调时，TabR1与强大的基线具有可比拟的性能。在零样本设置中，TabR1接近32样本设置下的基线性能。此外，TabR1 (8B)在各个任务上显著优于更大型的LLMs，优于DeepSeek-R1 (685B)高达53.17%。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15398", "html_url": "https://arxiv.org/abs/2510.15398", "title": "MARIS：具有几何增强和语义对齐的海洋开放词汇实例分割", "title_en": "MARIS: Marine Open-Vocabulary Instance Segmentation with Geometric Enhancement and Semantic Alignment", "authors": "Bingyu Li,Feiyu Wang,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li", "background": "目前大多数水下实例分割方法受到近似词汇预测的限制，难以识别新的海洋类别。为了促进评价，本文提出了MARIS（海洋开放词汇实例分割），这是一个大型细致分类基准，包括有限的已见类别和多样的未见类别。尽管开放词汇分割在自然图像上显示出潜在的前景，但分析揭示，将其转移到水下场景会遭受严重的视觉降级（例如，颜色衰减）和由于缺少水下类定义导致的语义错位。", "innovation": "为了解决这些问题，本文提出了一种统一框架，包含两个互补组件：几何先验增强模块（GPEM）利用稳定的部分级和结构线索，在视觉退化条件下保持对象一致性；语义对齐注入机制（SAIM）丰富了语言嵌入，加入了领域特定先验，减轻了语义模糊并改善了未见类别的识别。实验表明，本框架在MARIS基准上的表现优于现有开放词汇基线，无论是内部域还是跨域设置", "conclusion": "我们的框架在MARIS上的一致性优越性能及其对未来水下感知研究的基础确立，证明了其在水下开放词汇实例分割中的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19072", "html_url": "https://arxiv.org/abs/2510.19072", "title": "基于配置的多智能体路径规划中的局部指引", "title_en": "Local Guidance for Configuration-Based Multi-Agent Pathfinding", "authors": "Tomoki Arita,Keisuke Okumura", "background": "指导是一个新兴的概念，能够提升实时、非最优多智能体路径规划（MAPF）方法的实验性能。通过提供有关所有智能体群体行为的全局视角，它有助于减少等待时间，从而提高整体协调效率。然而，本研究探讨了一种不同策略：为每个智能体在其周围范围内提供局部指导。尽管局部方法在智能体移动时需要重新计算，可能会显得计算成本高昂，但实验验证表明，向规划器提供时空信息提示可以显著提高解决方案质量，而不会超出合理的计算时间限制。", "innovation": "本文研究提供局部指导而非全局视角的方法。通过向基于配置的多智能体路径规划算法（如LaCAM）提供时空指示，研究证明可以在合理的时间内显著提高路径规划的质量。", "conclusion": "局部指导能够为基于配置的方法建立MAPF的新的性能边界。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17451", "html_url": "https://arxiv.org/abs/2510.17451", "title": "计算VC-维的参数化复杂性", "title_en": "The Parameterized Complexity of Computing the VC-Dimension", "authors": "Florent Foucaud,Harmender Gahlawat,Fionn Mc Inerney,Prafullkumar Tale", "background": "VC-维是集合系统（或超图）的一个广泛研究且基础的复杂性度量，在机器学习的许多领域都占有重要地位。", "innovation": "论文首先证明了朴素的$2^{\text{O}(|\text{V}|)}$时间算法，在指数时间假设（ETH）下是渐进紧界的。其次，证明了对于最大度和维度的参数化，问题都有固定参数近似算法和固定参数算法。最后，提出了一个针对图的广义问题的算法，该算法的时间复杂性为$2^{\text{O}(tw \times \text{log} tw)} \times |V|$，并且对于集合系统，这也适用于其发生图的树宽。这与需双指数依赖于树宽的其他密切相关的问题形成了对比。", "conclusion": "论文主要研究了计算VC-维的问题，并提出了针对最大度和维度参数化的新的固定参数算法。同时，根据树宽设计了一个高效算法，这是诸多相关问题所不能达到的。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17930", "html_url": "https://arxiv.org/abs/2510.17930", "title": "NER模型扩展中的表示动力学诊断", "title_en": "Diagnosing Representation Dynamics in NER Model Extension", "authors": "Xirui Zhang,Philippe de La Chevasnerie,Benoit Fabre(papernest)", "background": "在嘈杂的语音语言数据中，将命名实体识别(NER)模型扩展到新的个别人员信息(PII)实体是一种常见需求。研究发现，同时精调BERT模型在标准语义实体(PER, LOC, ORG)和新的基于模式的PII(EMAIL, PHONE)之间，能够对原有类别的性能影响极小。", "innovation": "本文采用逐步学习设置作为诊断工具，测量语义漂移，并发现两个关键洞见。首先，与新PII实体存在表示重叠，场地(LOC)实体因其与模式特征（如邮政编码）的共享而特别脆弱。其次，识别出'反向O标签表示漂移'，模型最初被训练将PII模式映射到'O'，阻止新的学习。这只有通过解冻'O'标签分类器，允许背景类适应并'释放'这些模式才能解决。这项工作提供了NER模型适应性的机制诊断，突出显示了特征独立性、表示重叠和'O'标签的可塑性。", "conclusion": "这项工作为NER模型扩展提供了一个机制性诊断，强调了特征独立性、表示重叠和'O'标签的可塑性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19338", "html_url": "https://arxiv.org/abs/2510.19338", "title": "每项注意力都重要：一种高效的长上下文推理混合架构", "title_en": "Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning", "authors": "Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou", "background": "本文介绍了Ring-linear模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0。这些模型旨在优化长上下文推理场景中的输入输出和计算开销，特别是在自然语言处理任务中。", "innovation": "1. 提出了混合架构，结合线性注意力和softmax注意力，降低了长上下文推理中的I/O和计算开销。\n2. 相对于32B参数的密集模型，该系列模型的推理成本降低了10倍。\n3. 通过优化不同注意力机制的比例，找到了当前最优的模型结构。\n4. 利用自研高性能FP8操作库linghe，提高了50%的整体训练效率。\n5. 在强化学习阶段，模型可以长期、稳定且高效率地进行优化，并在多个复杂推理基准测试中保持SOTA性能。", "conclusion": "综上所述，该系列模型在保持高性能的同时，大幅降低了资源消耗，特别是在长上下文推理任务上表现突出。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17621", "html_url": "https://arxiv.org/abs/2510.17621", "title": "GUIDE: 使用去噪模型增强联邦学习中的梯度反转攻击", "title_en": "GUIDE: Enhancing Gradient Inversion Attacks in Federated Learning with Denoising Models", "authors": "Vincenzo Carletti,Pasquale Foggia,Carlo Mazzocca,Giuseppe Parrella,Mario Vento", "background": "联邦学习（FL）允许跨多个客户端协作训练机器学习（ML）模型，同时保护其隐私。客户端不分享原始数据，而是传输由本地计算得到的更新，以训练全球模型。尽管联邦学习应该提供比中心化机器学习更强的隐私保护，但客户端更新仍然可能遭受隐私泄露。攻击者可以利用这些信息通过梯度反转攻击（GIAs）推断训练数据的敏感属性，甚至重构原输入。在诚实但却好奇的威胁模型下，GIAs 试图通过使用基于优化的技术反转中间更新来重构训练数据。研究观察到这些方法通常会重构噪声近似版本的原输入，其质量可以通过专门的去噪模型得到增强。因此，本研究提出了一种新颖的方法——GUIDE，利用扩散模型作为一种去噪工具来改进联邦学习中的图像重构攻击。GUIDE 可以整合到任何使用代理数据集的 GIAs 中，这是 GIAs 文献中广泛应用的假设之一。", "innovation": "本研究提出的GUIDE方法，利用扩散模型作为去噪工具，改进了联邦学习中的图像重构攻击。特别地，GUIDE能够整合到任何形式使用代理数据集的 GIAs 中，并在多个度量标准上显著提高了重构质量，例如，GUIDE 在 DreamSim 元度量下的感知相似度提升了多达46%。", "conclusion": "我们的研究结果表明，GUIDE 无缝集成到两种最先进的 GIAs 中，显著提高了多个度量标准上的重构质量。本研究展示了使用去噪模型在联邦学习中增强梯度反转攻击的有效性."}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19351", "html_url": "https://arxiv.org/abs/2510.19351", "title": "有限演示下向人群学习推迟决策", "title_en": "Learning To Defer To A Population With Limited Demonstrations", "authors": "Nilesh Ramgolam,Gustavo Carneiro,Hsiang-Ting Chen", "background": "本文研究了数据匮乏对学习推迟（L2D）系统广泛应用的限制。L2D系统由于缺乏充分的数据支持，难以在广泛的人群中实际部署。", "innovation": "本文提出了一个基于元学习的半监督框架，该框架能够从少量示例中生成专家特定的嵌入。该框架具有双重目的机制：首先使用这些嵌入生成大量伪标签用于训练，随后在测试时实现对新专家的即时适应。", "conclusion": "实验结果表明，使用这些合成标签训练的模型能够迅速接近最佳性能。这证明了该方法的数据效率，并通过解决关键的训练瓶颈，使适应性L2D系统更加实用和可扩展，为实际环境中的人类与人工智能的合作铺平了道路。本文还提供了源代码和训练配置以促进研究结果的可复制性。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16396", "html_url": "https://arxiv.org/abs/2510.16396", "title": "SPLite手部：基于稀疏性的轻量级3D手部姿态估计", "title_en": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "authors": "Yeh Keng Hao,Hsu Tzu Wei,Sun Min", "background": "随着AR/VR设备的普及，将深度学习模型部署到边缘设备成为关键挑战。这些设备需要实时推理、低功耗和低延迟。框架设计师面临效率与性能之间的权衡难题。该研究设计了一个轻量级框架，采用编码器-解码器架构，旨在提高效率和准确性。通过在ResNet-18主干架构上应用稀疏卷积来利用手部图像中的固有稀疏性，从而实现端到端效率提高42%。此外，提出了SPLite解码器，显著提升了在Raspberry Pi 5上的解码帧率（3.1x），同时保持相似的准确度。通过对模型进行量化感知训练以优化性能，尽管PA-MPJPE指标从9.0mm微增至9.1mm，但内存使用减少的同时保持了准确性。该系统在Raspberry Pi 5 CPU（BCM2712四核Arm A76处理器）上实现了2.98倍的速度提升。此外，该方法还在混合基准数据集上进行了评估，显示出与最先进的方法相当的准确性和显著的计算效率提升.", "innovation": "提出了一个轻量级框架，基于ResNet-18主干架构，使用稀疏卷积增强了稀疏性处理，并引入了SPLite解码器以提高解码帧率和效率。还进行了量化感知训练，优化了内存使用和保持准确性之间的平衡。结果表明，该方法在保持良好准确度的同时大幅提升了计算效率。此外，该方法在混合基准数据集上的表现也表明了其实用性与竞争力。", "conclusion": "提出了一个轻量级框架SPLite手部，通过稀疏卷积和引入SPLite解码器显著提高了3D手部姿态估计的效率和准确性。结合量化感知训练，实现了显著的性能提升，特别是在边缘设备上。该方法达到了与现有最先进的方法相当的准确度，同时具有更好的计算效率。"}
{"llm_update_time": "20251025", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19755", "html_url": "https://arxiv.org/abs/2510.19755", "title": "扩散模型中的缓存方法综述：迈向高效的多模态生成", "title_en": "A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation", "authors": "Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang", "background": "扩散模型因其出色的生成质量和可控性已经成为现代生成AI的核心。然而，它们固有的多步迭代和复杂的骨干网络带来了巨大的计算开销和生成延迟，这是实时应用中的一个主要瓶颈。尽管现有的加速技术有所进展，但仍面临应用受限、高训练成本或质量下降等挑战。", "innovation": "扩散缓存提供了无需训练、不受架构限制且高效的推理范式。其核心机制识别并重用扩散过程中固有的计算冗余，通过在特征级别跨步骤重用和跨层调度减少计算而不修改模型参数。", "conclusion": "扩散缓存从静态重用进化到动态预测，增强了不同任务中的缓存灵活性，并能够与采样优化和模型蒸馏等其他加速技术集成，铺平了未来的统一、高效推理框架的道路。我们认为这一范式将成为实时和高效生成AI的关键促进因素，为理论和实践中的高效生成智能注入新的活力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19866", "html_url": "https://arxiv.org/abs/2510.19866", "title": "不同模型和提示框架在高中物理中生成的教学习题的教育可行性和实用性评估", "title_en": "An Evaluation of the Pedagogical Soundness and Usability of AI-Generated Lesson Plans Across Different Models and Prompt Frameworks in High-School Physics", "authors": "Xincheng Liu", "background": "该研究评估了五个主要大型语言模型生成的教学习题的教育可行性和实用性，包括ChatGPT、Claude Sonnet、Gemini 2.5、DeepSeek V3.2和Grok 4。研究设计包括了三个不同的提示框架（TAG、RACE、COSTAR），并针对高中物理的电磁波谱主题生成了十五个教学习题。", "innovation": "研究将模型选择与不同提示框架相结合，全面评估了教学习题的质量。采用了four个自动化计算指标来评估教学习题的可读性、语言复杂性、事实准确性和认知要求，揭示了不同模型对教学习题生成的影响。", "conclusion": "研究发现模型设计对可读性有显著影响，而提示框架对事实准确性和教学完整性影响更大。最优配置是使用经过可读性优化的模型结合RACE提示框架和明确列出的物理概念、课程标准和高阶目标的清单。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19871", "html_url": "https://arxiv.org/abs/2510.19871", "title": "从去噪到完善：一种视觉-语言扩散模型的校正框架", "title_en": "From Denoising to Refining: A Corrective Framework for Vision-Language Diffusion Model", "authors": "Yatai Ji,Teng Wang,Yuying Ge,Zhiheng Liu,Sidi Yang,Ying Shan,Ping Luo", "background": "离散扩散模型在视觉-语言任务中表现出色，能提供双向上下文建模并实现理论上的并行化。然而，它们的实际应用受到训练与推理之间差距的严重阻碍，这种差距导致灾难性错误级联：并行解码过程中初始标记错误会污染生成上下文，从而引发一系列累积错误，在语法和语义层面产生错误和幻觉等现象。", "innovation": "论文重新定义生成过程，从被动去噪转变为积极改进。引入了ReDiff框架，该框架使模型学会识别并修正自身错误。该框架包括两阶段训练过程：首先，通过训练模型修正合成错误来培养基础修订能力；其次，引入一个新型在线自我修正循环，模型在学习专家修正的基础上被明确训练来修正自身的不完善草稿。这种错误驱动的学习赋予了模型回顾并完善已生成输出的能力，从而打破了错误级联现象。", "conclusion": "大规模实验表明，ReDiff显著提高了生成内容的连贯性和事实准确性，远超过传统去噪方法，实现了更稳定高效的并行生成。代码和模型可在特定网址获取。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19858", "html_url": "https://arxiv.org/abs/2510.19858", "title": "DeBERTa-KC：基于Transformer的在线学习对话中知识构建分类器", "title_en": "DeBERTa-KC: A Transformer-Based Classifier for Knowledge Construction in Online Learning Discourse", "authors": "Jindi Wang,Yidi Zhang,Zhaoxing Li", "background": "本研究基于从四个流行的YouTube科学频道（2022-2024年）收集的评论，创建了一个平衡的注释语料库，包含20000个样本，并划分为四个知识构建（KC）类别：非KC、分享、探索和协商。该研究旨在构建一个能够自动分类在线科学学习对话中KC水平的模型，并使用大规模语言模型DeBERTa-v3结合Focal Loss、标签平滑和R-Drop规则化处理类别不平衡问题，并增强泛化能力。研究还实施了一个可复现的端到端流程，涵盖数据提取、标注、预处理、训练和评估。", "innovation": "本研究创新地提出了一种基于DeBERTa-v3的模型DeBERTa-KC，通过添加Focal Loss、标签平滑和R-Drop规则化等技术解决类别不平衡问题和提高泛化能力，该模型在对10折交叉验证中表现优异，宏观F1值为0.836 ± 0.008，显著优于传统和基于Transformer的基线模型。此外，研究中的分类结果显示模型对高阶有认知参与的对话特别敏感，特别是在探索和协商讨论中。这些发现表明，大规模语言模型能够有效捕捉非正式数字学习环境中知识构建的细微指标，为描述认知同侪支持理论提供了一种可扩展的、基于理论的方法。", "conclusion": "研究结果证明了大规模语言模型通过DeBERTa-KC可以有效识别在线科学学习对话中的知识构建水平，特别是高阶认知参与，这为探讨在线学习环境中的认知同侪支持提供了可扩展的方法，并为开发自动化工具以评估认知同侪支持提供了新的思路。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19897", "html_url": "https://arxiv.org/abs/2510.19897", "title": "利用语义和情景记忆从监督学习：一种代理适应的反思方法", "title_en": "Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation", "authors": "Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka", "background": "本文探讨了基于预训练大型语言模型的代理如何从标记示例中学习目标分类函数，而无需参数更新。传统的方法如微调成本高、灵活性差且不够透明。", "innovation": "本文提出了一种基于记忆增强框架，该框架利用标记数据和LLM生成的批评。该框架使用情景记忆存储实例级批评，并将这些批评提炼成可重用的任务级指导。通过广泛的实证评估，发现OpenAI和开源模型在处理事实导向数据和偏好导向数据时的行为差异，并提出了一种新的衡量模型响应不同监督表示的度量标准——可塑性，以解释观察到的行为，并阐明模型特性和记忆策略如何共同影响学习动力。", "conclusion": "研究表明，基于记忆的反思性学习有望构建更具适应性和可解释性的LLM代理。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19875", "html_url": "https://arxiv.org/abs/2510.19875", "title": "Stream: 通过稀疏注意力在LLMs中扩展机制可解释性到长上下文", "title_en": "Stream: Scaling up Mechanistic Interpretability to Long Context in LLMs via Sparse Attention", "authors": "J Rosser,José Luis Redondo García,Gustavo Penha,Konstantina Palla,Hugues Bouchard", "background": "当大规模语言模型（LLMs）扩展到百万级上下文时，传统的分析注意力的机制性可解释性技术需要随着上下文长度的增加以平方级需求内存，甚至超过10万个标记时需要数万兆字节的内存。现有的技术在少量标记的情况下还能工作，但在长上下文中则需要极大量的内存，这限制了其应用范围。为了解决这个问题，本文提出了Sparse Tracing，一种新的技术，利用动态稀疏注意力来高效分析长上下文下的注意力模式。本文还介绍了Stream算法，这是一个可编译的分层剪枝算法，能在接近线性的时间复杂度 $O(T \neq \text{log} T)$ 和线性空间复杂度 $O(T)$ 下估计每个头的稀疏注意力掩码，支持一次通过对的操作。Stream通过二分搜索式精细化保留每个查询的最关键部分，同时保持模型的下一个标记行为。", "innovation": "提出了Sparse Tracing，一种利用动态稀疏注意力技术在大规模上下文中高效分析注意力模式的新方法。还提出了一种名为Stream的新编译算法，该算法能够在近线性时间复杂度和线性空间复杂度下估计每个头的稀疏注意力掩码，并能进行一次通过对的操作，保留关键部分并精确捕捉信息流动，适用于长推理链的可解释性分析。此外，它还能在消费级GPU上实现大规模长上下文中的可解释性，使得长上下文的监控更加普及化。", "conclusion": "本文介绍的方法提供了一种实用的机制，可以在不使用大量缓存的情况下分析注意力模式并跟踪信息流动。通过使长上下文的解释在消费级GPU上变得可行，Sparse Tracing帮助实现了链式推理监控的民主化。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19879", "html_url": "https://arxiv.org/abs/2510.19879", "title": "使用大型语言模型对荷兰EHR进行自动HIV筛查", "title_en": "Automated HIV Screening on Dutch EHR with Large Language Models", "authors": "Lang Zhou,Amrish Jhingoer,Yinghao Luo,Klaske Vliegenthart--Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li", "background": "HIV的有效筛查和早期诊断对于减少传播至关重要。尽管大规模实验室检测不可行，但电子健康记录（EHR）的广泛采用为解决这一挑战提供了新机会。现有研究主要集中在利用机器学习方法对结构化数据（如患者人口统计信息）进行改进以提高HIV诊断的效果。然而，这些方法往往忽略了非结构化文本数据（如临床记录），这些数据可能包含与HIV风险相关的重要信息。为此，本研究提出了一个新颖的流程，利用大型语言模型（LLM）分析未结构化的EHR文本，以确定患者是否有资格进一步进行HIV检测。实验结果表明，该流程在准确性和低假阴性率方面表现良好，展示了其在实际临床环境中应用的潜力。", "innovation": "提出了一种新颖的流程，利用大型语言模型（LLM）处理非结构化EHR文本，分析患者是否有资格进一步进行HIV检测。这种方法能够有效提高HIV筛查的准确性和效率，弥补了现有研究忽视非结构化文本数据的不足。", "conclusion": "实验结果表明，该研究提出的基于大型语言模型的流程在荷兰艾马士马卢辛大学医学院鹿特丹进行的临床数据中，取得了较高的准确率和较低的假阴性率，证明了其在实际应用中的可行性和有效性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19886", "html_url": "https://arxiv.org/abs/2510.19886", "title": "基于专家评估的一般用途大语言模型在生命周期评估中的基准研究", "title_en": "An Expert-grounded benchmark of General Purpose LLMs in LCA", "authors": "Artur Donaldson,Bharathan Balaji,Cajetan Oriekezie,Manish Kumar,Laure Patouillard", "background": "人工智能（AI），特别是大型语言模型（LLMs），正越来越多地被探索作为支持生命周期评估（LCA）的工具。尽管在环境和社会领域已有演示，但关于其可靠性和稳健性的系统证据仍有限。该研究填补了这一空白，通过一种专家导向的基准评估方式，检验了LLMs在LCA中的表现。在LCA领域，尚未存在明确的权威标准或共识协议，因此需要系统性的评估框架。", "innovation": "研究提供了首次基于专家评估的LLMs在LCA中的基准，对不同LCA任务分别进行了22次评估。研究选择了11款涵盖商业和开源模型的LLM，通过17位经验丰富的从业者对模型输出进行专业审查，评估其科学准确性、解释质量、稳健性、可验证性以及指令遵守情况等，收集了168份专家评审结果。研究发现不同模型在准确性和解释质量上有显著差异，开放性和封闭性模型在某些标准上表现相近。该研究强调了直观应用LLMs在LCA中的风险，特别是在将其视为自由形式的权威时，同时也揭示了LLMs在提高简单任务说明质量方面的优势。", "conclusion": "研究结果强调了在LCA中不加判断地使用LLMs所面临的潜在风险，尤其是当将其视为自由形式的权威时，同时也展示了性能提升，尤其是在提高解释的质量和简化劳力密集型任务方面。研究表明，适用一般用途的LLMs而缺乏定位机制存在……"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19892", "html_url": "https://arxiv.org/abs/2510.19892", "title": "Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities", "title_en": "Can They Dixit? Yes they Can! Dixit as a Playground for Multimodal Language Model Capabilities", "authors": "Nishant Balepur,Dang Nguyen,Dayeon Ki", "background": "现有的多模态大型语言模型（MLMs）通常在静态、单一的基准测试中进行评估，无法在一个任务中全面评估MLMs的能力，或者依赖于人类或模型之间的人为对比，这些方法非常主观、昂贵且易导致模型通过表面技巧（如冗长性）来提升得分。因此，需要一种更全面、客观的评估方法来解决上述问题。", "innovation": "本文提出使用基于游戏的评估方法来全面评估MLMs的能力。这种评估方法利用游戏需要多种能力、具有竞争性且遵循固定客观规则的特点，使评估更加沉浸式和精确。具体实现为通过DiXit卡牌游戏，参与者需要生成描述卡片的文本以误导部分玩家，而不会误导所有玩家。实验表明，MLMs在DiXit游戏中的表现与它们在流行的MLM基准测试中的排名高度一致，并揭示了人类与MLMs在策略上的差异以及MLMs推理能力的改进空间。", "conclusion": "定量实验结果显示，MLMs在DiXit中的胜率排名与主流MLM基准测试高度相关。通过DiXit可以评估MLMs在生成模态和推理能力方面的能力，同时也揭示了与人类玩家策略的差异，以及MLMs在某些推理方面的改进空间。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19967", "html_url": "https://arxiv.org/abs/2510.19967", "title": "LyriCAR：一种基于难度感知的课程强化学习框架用于可控歌词翻译", "title_en": "LyriCAR: A Difficulty-Aware Curriculum Reinforcement Learning Framework For Controllable Lyric Translation", "authors": "Le Ren,Xiangjian Zeng,Qingqiang Wu,Ruoxuan Liang", "background": "歌词翻译是一个复杂的任务，需要平衡多个音乐约束。现有方法通常依赖手工制作的规则和句子级别的建模，这限制了它们在段落级上内部化音乐语言模式和跨行一致性及全局韵律的能力。", "innovation": "提出了LyriCAR，这是一种完全无监督的可控歌词翻译框架，引入了难度感知的课程设计师和自适应课程策略，确保有效分配训练资源，加速收敛，通过逐步引入更复杂的挑战来指导模型，从而提高整体翻译质量。", "conclusion": "在EN-ZH歌词翻译任务上进行的大量实验表明，LyriCAR在标准翻译指标和多维度奖励分数上均取得了最先进的结果，优于其他基线模型。值得注意的是，自适应课程策略将训练步骤减少了近40%，同时保持了出色的性能。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19895", "html_url": "https://arxiv.org/abs/2510.19895", "title": "由大型语言模型驱动的数学建模", "title_en": "Large Language Model enabled Mathematical Modeling", "authors": "Guoyun Zhang", "background": "传统的优化方法，如线性编程、混合整数编程和模拟，高度依赖于专业知识，将实际问题转化为可解的数学模型。尽管如Gurobi和COPT等求解器很强大，但专家输入对于定义目标、约束和变量仍然是必不可少的。尽管像GPT-4、Claude和Bard这样的先前模型在NLP和推理任务中表现出很强的性能，但由于高昂的令牌成本和倾向虚构成分，它们在供应链场景中的实际应用受到限制。相比之下，DeepSeek-R1作为一种成本效益高且性能良好的模型，通过强化学习训练，提供了一种可行的替代方案。", "innovation": "本研究专门探讨了DeepSeek-R1模型在自然语言理解和代码生成方面的能力，以弥补建模缺口。研究系统地评估了DeepSeek-R1在四个关键运营研究（OR）基准上的表现：NL4OPT、IndustryOR、EasyLP和ComplexOR。研究方法包括基线评估、虚构成分分类以及使用LLM作为裁判、少样本学习（FSL）、工具调用和多代理框架等缓解策略，以减少虚构成分，提高建模准确性，并更好地使模型输出与用户意图一致。", "conclusion": "研究结果表明，尽管DeepSeek-R1在基准测试中表现良好，但在实际运营业务中的应用效果仍需进一步探索。研究提出的方法和策略有助于降低虚构成分，提高模型制定的准确性和一致性，为优化建模提供新的思路。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20001", "html_url": "https://arxiv.org/abs/2510.20001", "title": "超越MedQA：在大语言模型时代迈向现实世界中的临床决策", "title_en": "Beyond MedQA: Towards Real-world Clinical Decision Making in the Era of LLMs", "authors": "Yunpeng Xiao,Carl Yang,Mark Mai,Xiao Hu,Kai Shu", "background": "大语言模型（LLMs）在临床应用中显示出潜力，通常使用如MedQA这样的数据集进行评估。然而，许多医疗数据集，如MedQA，依赖于简化的问题回答方式，未能充分代表现实生活中的临床决策过程。", "innovation": "提出了一种统一的范式，用两个维度来刻画临床决策任务：临床背景和临床问题。随着背景和问题越来越接近真实的临床环境，任务的难度也随之增加。总结现有数据集和基准设置，回顾解决临床决策的方法，包括训练时期和测试时期的技巧，并总结它们的效果，加强对准确性和效率以及解释性的综合评估。", "conclusion": "该范式澄清了假设，标准化了比较，并指导了开发临床意义显著的大语言模型。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20036", "html_url": "https://arxiv.org/abs/2510.20036", "title": "ToolScope：通过工具合并和上下文感知过滤提升LLM代理工具使用", "title_en": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "authors": "Marianne Menglin Liu,Daniel Garcia,Fjona Parllaku,Vikas Upadhyay,Syed Fahad Allam Shah,Dan Roth", "background": "大型语言模型（LLM）代理依赖外部工具解决复杂任务，但现实中的工具集往往包含具有重叠名称和描述的冗余工具，引入了歧义并降低了选择准确性。此外，LLMs面临严格的输入上下文限制，这妨碍了它们高效地考虑大型工具集。", "innovation": "提出了ToolScope，包含两部分：（1）ToolScopeMerger带有自动校正的功能，自动审核和修正工具合并，减少冗余；（2）ToolScopeRetriever对每个查询按相关性排名并选择最相关的工具，压缩工具集以适应上下文限制而不牺牲准确性。", "conclusion": "在三个最先进的LLM和三个开源工具使用基准上的评估结果显示，ToolScope的工具选择准确性提高了8.38%至38.6%，证明了其在增强LLM工具使用方面的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20002", "html_url": "https://arxiv.org/abs/2510.20002", "title": "基于质量和语料库精炼的先进希腊自然语言处理", "title_en": "Forging GEMs: Advancing Greek NLP through Quality-Based Corpus Curation and Specialized Pre-training", "authors": "Alexandra Apostolopoulou,Konstantinos Kanaris,Athanasios Koursaris,Dimitris Tsakalidis,George Domalis,Ioannis E. Livieris", "background": "自然语言处理（NLP）领域中，对于像现代希腊语这类形态丰富且资源中等的语言的进步常常受到碎片化的研究景观、缺乏多样化的架构以及依赖于短上下文模型的限制。在法律法规等专业领域尤为突出，现有的模型经常局限于早期的变压器架构，并且窗口大小限制在512个标记，这远远不足以分析长法务文件。", "innovation": "本文提出了一种新的希腊嵌入模型（Greek Embedding Models，GEM），基于广泛质量驱动的数据精炼，构建了一系列现代架构的变压器模型，包括ELECTRA、ConvBERT和ModernBERT。此外，还提出了第一套针对法律领域的双语希腊-英语嵌入模型。大量下游任务的实验表明，GEM系列模型显著优于现有基线。", "conclusion": "GEM系列模型证实了所提出的方法的有效性，特别是在法律法规等高价值专业领域，GEM-RoBERTa和GEM-ConvBERT模型表现尤为突出。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20033", "html_url": "https://arxiv.org/abs/2510.20033", "title": "通过调整预训练神经语言模型提高序列标注任务的迁移学习", "title_en": "Improving Transfer Learning for Sequence Labeling Tasks by Adapting Pre-trained Neural Language Models", "authors": "David Dukić", "background": "本文主要针对序列标注任务中的迁移学习进行了改进，旨在利用预训练神经语言模型进行调整，提高模型在不同任务中的表现。", "innovation": "提出了三种创新改进：1. 引入多任务模型结合额外信号，用于事件触发检测任务的领域转移；2. 通过对自回归大型语言模型的架构修改，实现跨层的双向信息流动；3. 利用自回归大型语言模型作为文本生成器，通过生成监督上下文微调框架进行调整。", "conclusion": "所提出的模型、方法和框架证明了，预训练神经语言模型在经过有针对的迁移学习调整后，可以在序列标注任务中达到最佳表现。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19996", "html_url": "https://arxiv.org/abs/2510.19996", "title": "依赖解析的基本算法（附更正）", "title_en": "A Fundamental Algorithm for Dependency Parsing (With Corrections)", "authors": "Michael A. Covington", "background": "本文介绍了一种基础算法，用于将自然语言句子解析为依赖树。这类算法与短语结构（构胁式）解析器不同，后者会一次性处理多个短语，而本文的算法则按一个词接一个词的方式解析，即一旦某个词能够被处理就立即进行处理，并且这种处理方式被认为与人类大脑中的解析器的特性相符。虽然短语结构解析的最坏情况复杂度是$O(n^3)$，但本文介绍的算法在最坏情况下的复杂度也是$O(n^3)$，不过在人类语言中，这种最坏情况仅在词数$n$比较小的情况下才会出现。", "innovation": "该算法按照一个词接一个词的方式对句子进行解析，与传统的方法有所不同，更接近人类大脑处理语言的机制。在效率方面表现出与传统的短语结构解析相似的最坏情况下复杂度，但实际应用中，由于语言的特性，极端情况出现的概率较低，实用性的体现更为明显", "conclusion": "本文介绍的算法提供了一种解析自然语言句子的新思路，它更真实地模拟了人类处理语言的过程，然而，在实际应用中，这种方法的效率仍然依赖于输入句子的长度，但在有效范围内的表现令人满意。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19988", "html_url": "https://arxiv.org/abs/2510.19988", "title": "增强型符号自然语言理解系统：更可靠的连续因果陈述解释", "title_en": "LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation", "authors": "Xin Lian,Kenneth D. Forbus", "background": "尽管大规模语言模型（LLMs）具有广泛的应用前景，但其依赖概率推理使其容易出现生成事实中的幻觉以及自然语言理解（NLU）任务中的输出结构不一致等问题。相比之下，符号NLU系统通过基于精选词汇表、语义资源和句法与语义解释规则提供可解释的理解。这样的系统能够生成关系化表示，可用于准确的推理和规划，以及增量可调试的学习。然而，符号NLU系统在覆盖范围上通常不如LLMs广泛，而且需要稀缺的知识表示和语言技能来进行扩展和维护。本文探讨了一种结合了LLMs广泛覆盖语言处理能力与符号NLU生成结构化关系表示能力的混合方法。通过将LLMs用于重述和文本简化来提供广泛覆盖，并将其用作填补知识空白的自动信息来源。同时，符号NLU用于生成用于推理和增量学习的表示。本文对该方法在从常识科学文本中提取和解释量值及因果定律的任务上进行了评估，并与仅使用符号方法和仅使用LLM的方法进行了比较。结果显示，我们的混合方法在可靠性上明显优于仅使用符号方法的管道.", "innovation": "本研究提出了一种混合方法，该方法结合了LALMs（大规模语言模型）的广泛覆盖语言处理能力和符号NLU（自然语言理解系统）生成结构化关系表示的能力。它利用LLMs进行重述和文本简化以实现广泛覆盖，并自动填补知识空白；同时也利用符号NLU生成可用于推理和增量学习的表示。这种方法旨在克服单一方法的局限性，并从两者的优点中受益。在从常识科学文本中提取和解释量值及因果定律的任务上，该混合方法表现出极好的可靠性，并显著优于仅使用符号方法的管道。", "conclusion": "结果表明，我们的混合NLU方法在连续因果陈述的解释上表现出了明显的可靠性提升，该方法结合了LALMs的广泛覆盖能力和符号NLU生成可推理表示的优势，能够在各种自然语言处理任务中提供更好的性能和更高的准确性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20043", "html_url": "https://arxiv.org/abs/2510.20043", "title": "从事实到传说：评估大型语言模型的孟加拉文化知识", "title_en": "From Facts to Folklore: Evaluating Large Language Models on Bengali Cultural Knowledge", "authors": "Nafis Chowdhury,Moinul Haque,Anika Ahmed,Nazia Tasnim,Md. Istiak Hossain Shihab,Sajjadur Rahman,Farig Sadeque", "background": "最近自然语言处理（NLP）研究展示了大型语言模型（LLMs）在多种任务上的卓越能力。尽管多种跨语言基准测试提升了LLMs的文化评价标准，但在低资源文化的细微差异上仍存在关键不足。本文通过一个包含民间传统、烹饪艺术和地方方言的孟加拉语言文化知识（BLanCK）数据集，填补了这一空白，旨在评估几种跨语言模型在文化知识方面的表现，发现这些模型在非文化类别上表现良好，但在文化知识方面存在显著挑战，提供上下文可以显著提高所有模型的性能，这突显了关注上下文感知架构和文化定制训练数据的重要性。", "innovation": "本文通过创建孟加拉语言文化知识（BLanCK）数据集，解决了现有跨语言基准测试在评估低资源文化知识方面存在的局限性。该数据集包括民间传统、烹饪艺术和地方方言，旨在评估各种跨语言模型在文化知识方面的表现。发现结果显示，跨语言模型在提供上下文时，其文化知识性能有了显著提升，强调了上下文感知架构和文化规范训练数据的重要性。", "conclusion": "跨语言模型在非文化类别上的表现良好，但在文化知识方面存在明显弱点，通过提供上下文可以显著改善模型的性能。评估表明，注重上下文感知架构和文化定制训练数据对于提升跨语言模型在文化知识任务中的表现至关重要。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20091", "html_url": "https://arxiv.org/abs/2510.20091", "title": "CreativityPrism：大型语言模型创造力的全面基准", "title_en": "CreativityPrism: A Holistic Benchmark for Large Language Model Creativity", "authors": "Zhaoyi Joey Hou,Bowei Alvin Zhang,Yining Lu,Bhiman Kumar Baghel,Anneliese Brei,Ximing Lu,Meng Jiang,Faeze Brahman,Snigdha Chaturvedi,Haw-Shiuan Chang,Daniel Khashabi,Xiang Lorraine Li", "background": "创造力被视为人类智能的显著特征。尽管大型语言模型（LLMs）在生成创意文本方面越来越被认可，但仍然缺乏一个全面的框架来评估其在不同场景中的创造力。现有的评估方法仍然碎片化，不同领域和任务之间的差异很大，主要原因是创造力的定义和度量标准不同。因此，目前没有统一的标准来评价LLMs的创造力，研究者试图通过一个更加全面的方法来填补这一空白，以更准确地评估LLMs的创造力。", "innovation": "研究提出了CreativityPrism，这是一个评估分析框架。它将创造力分解为三个维度：质量、新颖性和多样性。该框架包括九个任务、三个领域（发散思维、创造性写作和逻辑推理），以及二十个评价指标，这些评价指标以特定任务的独特方式测量每个维度。此外，研究还评估了17种先进的LLMs在CreativityPrism上的表现，分析了不同评价指标和任务领域之间的相关性。", "conclusion": "研究结果表明，专有的模型和开源模型之间的性能存在显著差距。总体而言，同一领域内的任务之间，模型性能高度相关，而不同领域之间则不然。在评价维度中，多样性与质量指标间表现出很强的相关性，即表现好的模型在另一个维度上也往往表现出色，而新颖性与两者的相关性较弱。这些发现支持了研究者的假设：在一个创造力任务或维度上的强表现不一定能推广到其他方面，强调了全面评价LLMs创造力的需求。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20059", "html_url": "https://arxiv.org/abs/2510.20059", "title": "在小型波斯医学语言模型中增强推理能力可以超越大规模数据训练", "title_en": "Enhancing Reasoning Skills in Small Persian Medical Language Models Can Outperform Large-Scale Data Training", "authors": "Mehrdad Ghassabi,Sadra Hakim,Hamidreza Baradaran Kashani,Pedram Rostami", "background": "在特定应用场景如医疗问答中，增强小型语言模型的推理能力对于处理未被充分代表的语言（如波斯语）非常重要。已有研究指出，通过特定的训练方法可以显著提升语言模型在某些专用领域的性能，尤其是在数据量有限的情况下。研究团队在此基础上，提出了针对一般用途的波斯语言模型进行专门推理能力提升的方法。", "innovation": "研究团队采用了强化学习与人工智能反馈（RLAIF）以及直接偏好优化（DPO）的方法，这些方法被用于提升波斯语言模型的推理能力。他们首先将一个多项选择的医学问答数据集翻译成波斯语，然后利用RLAIF生成优解和次优解对，这些对是DPO训练中必不可少的。通过引导教师和学生模型生成带有推理痕迹的回答，研究团队创建了一个包含正确和错误推理轨迹的数据集，用于训练基础模型，显著提升了其医学推理能力。实验结果表明，即使使用较小的数据集，训练出的模型也超越了使用约5700万令牌训练的前辈模型gaokerena-V，这一结果凸显了推理重点训练方法对于构建领域专用语言模型的效果与效率优势。", "conclusion": "该研究主要结论是，通过针对性和高效的方法对小型波斯语言模型进行推理能力训练，即使在数据量有限的情况下，也能达到甚至超越大型语言模型的性能。这为在资源有限的环境中构建功能强大的专业领域语言模型提供了新的可能性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20098", "html_url": "https://arxiv.org/abs/2510.20098", "title": "通过自适应路由和针对性推理利用大型语言模型在实体链接中的力量", "title_en": "Leveraging the Power of Large Language Models in Entity Linking via Adaptive Routing and Targeted Reasoning", "authors": "Yajie Li,Albert Galimov,Mitra Datta Ganapaneni,Pujitha Thejaswi,De Meng,Priyanshu Kumar,Saloni Potdar", "background": "实体链接传统上依赖于大规模标注数据集和广泛的模型微调。虽然最近的少样本方法通过提示来利用大型语言模型（LLM），以减少训练需求，但它们通常会遭受由于昂贵的LLM推理带来的效率低下问题。ARTER（自适应路由和针对性实体推理）提供了一种结构化流程，通过战略性地结合候选生成、基于上下文的打分、自适应路由和选择性推理，以不进行深入微调的方式实现了高性能。", "innovation": "ARTER 通过结合候选生成、上下文相关评分、自适应路由和选择性推理，战略性地组合少量互补信号（包括嵌入和LLM推理），将上下文提及分类为简单和困难案例。简单案例由计算成本低的实体链接器（例如ReFinED）处理，而复杂案例则通过更昂贵的针对性LLM推理处理。ARTER 在标准基准测试中优于 ReFinED，最高提升了 4.47%，平均提升在5个数据集中为2.53%，同时比仅使用LLM推理的流程效率提高了两倍以上。", "conclusion": "ARTER 实现了高性能且计算效率高，与使用LLM推理的所有提及的管道相比性能相当，但效率提高了两倍。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20151", "html_url": "https://arxiv.org/abs/2510.20151", "title": "BoundRL：通过强化边界生成实现高效结构化文本分段", "title_en": "BoundRL: Efficient Structured Text Segmentation through Reinforced Boundary Generation", "authors": "Haoyuan Li,Zhengyuan Shen,Sullam Jeoung,Yueyan Chen,Jiayu Li,Qi Zhu,Shuai Wang,Vassilis Ioannidis,Huzefa Rangwala", "background": "随着结构化文本在不同领域变得越来越复杂——从技术报告到生成AI提示——对其进行语义有意义的分段变得至关重要。这些文本通常包含超出纯语言的内容，例如表格、代码片段和占位符，传统的基于句子或段落级别的分段方法难以有效处理这些内容。因此，需要一种新的方法来解决这一挑战，特别是对于较长的结构化文本而言。", "innovation": "我们提出了BoundRL，一种新型且高效的方法，可同时执行标记级文本分段和标签预测。BoundRL只生成序列的起始标记并重建完整的内容，从而将推理成本降低几个数量级，并最小化幻觉现象。为了适应模型输出格式，BoundRL采用了可验证奖励强化学习（RLVR），使用特定设计的奖励来同时优化文档重建准确性和语义对齐。为了缓解熵坍缩现象，它还系统地扰动一部分生成的片段序列，构建作为优质解决方案垫脚石的中间候选方案。", "conclusion": "实验表明，BoundRL使小语言模型（参数量为1.7B）能够超越大量模型的少量示例提示。同时，使用我们设计的RLVR奖励进行强化学习比监督微调效果更好，加入中间候选方案进一步提高了性能和泛化能力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20168", "html_url": "https://arxiv.org/abs/2510.20168", "title": "DeepWideSearch：代理式信息检索中的深度与广度基准测试", "title_en": "DeepWideSearch: Benchmarking Depth and Width in Agentic Information Seeking", "authors": "Tian Lan,Bin Zhu,Qianghuai Jia,Junyang Ren,Haijun Li,Longyue Wang,Zhao Xu,Weihua Luo,Kaifu Zhang", "background": "当前的搜索代理缺乏同时执行深度多跳检索和广泛信息收集的能力，这对于实际应用如全面的市场分析和商业发展来说是至关重要的不足。DeepWideSearch旨在弥合这一差距，通过设计第一个明确评价代理深度与广度结合能力的基准，推动这一领域的研究进展。", "innovation": "介绍了DeepWideSearch，这是一个新的基准测试，首次明确用于评估智能体能否在信息检索中综合深度与广度。DeepWideSearch包含220个覆盖15个不同领域的广受质疑的问题，推动了深度与广度信息检索任务的研究。实验表明，即使最先进的代理在DeepWideSearch上的平均成功率仅为2.39%，突显了综合深度与广度检索的挑战性。进一步的错误分析揭示了四种失败模式：缺乏反思、过度依赖内部知识、检索不足和上下文溢出，这些揭示了当前代理架构的关键局限性。为了促进未来研究，DeepWideSearch将在公开平台上发布，以培养更强大和稳健的信息检索代理。", "conclusion": "DeepWideSearch揭示了当前代理架构中的关键局限性，尤其在深度与广度信息检索任务中的挑战。通过发布DeepWideSearch，旨在推动该领域的未来研究，以开发更强大的信息检索代理。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20208", "html_url": "https://arxiv.org/abs/2510.20208", "title": "无解码抽样策略在LLM边缘化中的应用", "title_en": "Decoding-Free Sampling Strategies for LLM Marginalization", "authors": "David Pohl,Marco Cognetta,Junyoung Lee,Naoaki Okazaki", "background": "现代语言模型通过子词分词文本运行以在模型大小、推理速度和词汇覆盖之间做出权衡。但在推理过程中，模型仅评估特定的子词分词方式的概率，虽然存在多种表示相同文本的子词词汇方式。最近的研究建议通过边际化（即所有分词方式的概率总和）来评估大型语言模型（LLM）。然而，边际化因文本分词方式数量庞大而难以实施，通常通过采样近似实现。但这一方法由于对每个样本都需要进行复杂的生成步骤，因此限制了样本数量和近似精度，从而带来计算成本增加的问题。", "innovation": "为了降低计算成本并提高精度，研究提出了一种无需生成的抽样策略，完全依赖于廉价且模型和分词器无关的采样方法。实验结果显示，这些无解码的抽样策略可以在极低的计算成本下提供足够准确的边缘估计，并应用于一系列下游推理任务中，展示了其优越性。", "conclusion": "该研究通过避免复杂的解码步骤，提出了一种高效且准确的边际化采样方法，并在多个开放模型上进行了实验验证，证明这种无解码抽样策略在推理任务中的应用前景广阔。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20176", "html_url": "https://arxiv.org/abs/2510.20176", "title": "Mixture-of-Minds: 多智能体强化学习理解表格", "title_en": "Mixture-of-Minds: Multi-Agent Reinforcement Learning for Table Understanding", "authors": "Yuhang Zhou,Mingrui Zhang,Ke Li,Mingyi Wang,Qiao Liu,Qifei wang,Jiayi Liu,Fei Liu,Serena Li,Weiwi Li,Mingze Gao,Abhishek Kumar,Xiangjun Fan,Zhuokai Zhao,Lizhu Zhang", "background": "理解表格并对其进行推理是许多实际应用中的关键能力。尽管大型语言模型在这一任务上显示出了潜力，但当前的方法仍然受到限制。细调方法能够增强语言推理，但容易出现算术错误和胡言乱语；工具方法则能够实现精确的表格操作，但由于依赖于刚性的模式，缺乏语义理解。这些互补的缺点突显了需要将稳健的推理能力与可靠的数据处理能力结合起来的方法。因此，本文提出了一种多智能体框架Mixture-of-Minds，该框架将表格推理分解为三个专门的角色：规划、编码和回答。这种设计使每个智能体能够专注于任务的特定方面，并通过代码执行实现精确的表格操作。", "innovation": "本文提出了Mixture-of-Minds，这是一种多智能体框架。它将表格推理分解为三个特殊角色：规划、编码和回答，使得每个智能体能够专攻任务的一个特定方面，并利用代码执行进行精确的表格操作。此外，本文还提出了一种自我改进的训练框架，利用蒙特卡洛树搜索（MCTS）卷出生成伪金标轨迹，并使用强化学习（RL）来优化智能体。实验表明Mixture-of-Minds在TableBench上取得了显著的成果，表现优于OpenAI-o4-mini-high。这些结果表明，结合结构化的多智能体工作流程与强化学习对于推进表格理解具有巨大的潜力。", "conclusion": "Mixture-of-Minds通过引入一种多智能体框架和自改进的训练机制，在表格理解方面取得了显著成果，达到了TableBench的62.13%。这些结果证明了将结构化的多智能体工作流程与强化学习结合用于表格理解的巨大潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20280", "html_url": "https://arxiv.org/abs/2510.20280", "title": "通过学习预测性上下文嵌入实现上下文级语言建模", "title_en": "Context-level Language Modeling by Learning Predictive Context Embeddings", "authors": "Beiya Dai,Yuliang Liu,Daozheng Xue,Qipeng Guo,Kai Chen,Xinbing Wang", "background": "Next-token prediction (NTP) 是现代大规模语言模型（LLMs）预训练的基础，推动了其在文本生成、推理和指令遵循中的空前能力。然而，字符级别的预测限制了模型捕捉高层次语义结构和长程上下文关系的能力。", "innovation": "我们介绍了名为 ContextLM 的框架，通过在标准预训练中引入固有的下文级预测目标来增强模型能力。ContextLM 训练模型学习多字符上下文的预测表示，利用来自未来字符片段的误差信号。这种方法与标准自回归、逐字符评估范式（例如困惑度）完全兼容。", "conclusion": "在 GPT2 和 Pythia 模型系列上的大规模实验表明，ContextLM 在困惑度和下游任务性能方面均实现了持续改进。我们的分析表明，下文级预测提供了一种可扩展的高效途径以增强语言建模，带来了更好的长程连贯性和更有效的注意力分配，且几乎没有计算开销。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20154", "html_url": "https://arxiv.org/abs/2510.20154", "title": "Are Stereotypes Leading LLMs' Zero-Shot Stance Detection ?", "title_en": "Are Stereotypes Leading LLMs' Zero-Shot Stance Detection ?", "authors": "Anthony Dubreuil,Antoine Gourru,Christine Largeron,Amine Trabelsi", "background": "大型语言模型（LLMs）在预训练数据的影响下继承了刻板印象，这些刻板印象在多种自然语言处理任务中导致对特定社会群体的偏见行为。这项偏见在态度检测方法中的评估仍未引起社区的足够重视，而态度检测则是一项极为敏感的任务，常与政治倾向相关。本研究关注大型语言模型在零样本设置下进行态度检测时表现出的刻板印象。研究通过自动标注预存的态度检测数据集中的帖子，分析方言或特定群体的口头语言和文本复杂度/可读性对模型态度检测决策的影响。研究结果显示，LLMs 在态度检测任务中表现出明显的刻板印象，如错误地将亲大麻观点与低文本复杂度及非裔美国人方言与对待唐纳德·特朗普的反对态度关联起来。", "innovation": "本研究填补了态度检测方法中偏见评估的空白，着重探讨大型语言模型在零样本设置中的态度检测情况。作者通过手工标记态度检测的预训练数据集，揭示了特定方言与文本复杂度/可读性对模型态度判断的影响，这对进一步研究和改进大型语言模型在态度检测中的偏见具有重要意义。", "conclusion": "大型语言模型在零样本条件下进行态度检测时存在明显的刻板印象，并错误地将亲大麻观点与低文本复杂度及非裔美国人方言与对待唐纳德·特朗普的反对态度关联起来。这表明，人们对特定群体的刻板印象可能会影响大型语言模型的态度检测结果。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20303", "html_url": "https://arxiv.org/abs/2510.20303", "title": "引文失败：定义、分析和高效缓解", "title_en": "Citation Failure: Definition, Analysis and Efficient Mitigation", "authors": "Jan Buchmann,Iryna Gurevych", "background": "传统的LLM基于RAG系统引用文献旨在简化响应验证。然而，当模型生成有帮助的回答但未能完整引用证据时，这种方法并不适用，即引文失败现象。与其他工作不同，本研究旨在将引文失败与响应本身的失败区分开，即当引用完整证据是不可能时的失败。文章提出了两种缓解策略，首先是探索引文失败发生时的关系及其对引文质量的影响，其次是提出一种结合生成、注意力和检索方法的框架CITENTION以提高LLM的引文性能。", "innovation": "研究提出了两种策略来解决引文失败的问题：首先，通过引入CITECONTROL基准，系统地变化响应和证据之间的关系，分析其失败模式；其次，提出CITENTION框架，结合生成、注意力和检索方法来提高逻辑模型的引文性能。这些策略通过实验证明了对CITECONTROL基准和迁移场景下的引文错误有显著改进效果。", "conclusion": "文章发明了CITECONTROL基准和CITENTION框架来解决引文失败问题，并通过实验表明，这些方法在纠正LLM相关错误方面的有效性。研究结果还显示，通过整合不同类型的引文方法可以改善模型的引文质量。所有数据和代码已公开发布。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20239", "html_url": "https://arxiv.org/abs/2510.20239", "title": "跨模态严重性融合诊断抑郁症和创伤后应激障碍", "title_en": "Tri-Modal Severity Fused Diagnosis across Depression and Post-traumatic Stress Disorders", "authors": "Filippo Cenacchi,Deborah Richards,Longbing Cao", "background": "抑郁障碍和创伤后应激障碍（PTSD）经常并发，并伴有复杂的症状，这使得自动化评估变得困难。现有的自动化评估往往是二元化且针对特定障碍的，临床有用的诊断需要具备不同障碍下严重程度感知的结果和决策支持解释。", "innovation": "提出了一种统一的三模态情感严重性框架，该框架同步并融合了文字访谈文本、句子级别的Transformer嵌入、音频的log Mel统计及其变化、面部信号的动作单元、凝视、头部和姿态描述符，以输出诊断抑郁症（PHQ-8，5类）和PTSD（3类）的有级严重性。标准化特征通过标定的后期融合分类器融合，生成每种障碍的概率和特征级归属。该严重性感知的三模态情感融合方法用于同时评估抑郁障碍和PTSD，并优于单模态/消融基线。尤其是对PTSD，融合减少了回归误差并改善了类别一致性，错误集中在相邻严重度之间，而极端类别的识别也更为可靠。", "conclusion": "该方法提供了可重复的评估方法，并支持临床决策中的临床医生参与，以实现情感上的临床决策制定，模型在DAIC衍生的数据集上进行了分层交叉验证，结果显示在准确性和加权F1分数上与最强的单模态基线相当，同时在嘈杂或缺失模块时表现出更好的鲁棒性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20198", "html_url": "https://arxiv.org/abs/2510.20198", "title": "困于矩阵：大型语言模型的空间推理探究", "title_en": "Stuck in the Matrix: Probing Spatial Reasoning in Large Language Models", "authors": "Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum", "background": "本文通过一套五项任务探究了大型语言模型（LLMs）在文本输入上的空间推理能力。这些任务旨在测试模型的空间理解和计算能力，涵盖如象限识别、几何变换、距离评估、单词搜索和瓷砖滑动等项目。随着任务复杂性的增加，模型必须从简单的模式识别转向抽象的空间推理。结果表明，模型在小规模和低复杂性任务中表现出适度的成功，但随着规模的增加，性能快速下降，平均准确率下降42.7%，最高达到84%。所有从50%以上准确率开始的测试都显示了至少48%的准确率损失，这表明大型语言模型在空间推理上的能力有显著的局限性，提示其内在架构缺乏健壮的空间表示。这项研究揭示了语言和空间推理之间的差距，指出了其当前的局限性，并为语言和几何学领域未来整合性基准测试奠定了基础。", "innovation": "本文通过设计一系列特定任务来探究大型语言模型在空间推理方面的表现，特别是空间理解和多层次问题解决，展示了对于复杂空间问题的处理上这些模型表现的局限性。研究发现，大规模和高复杂度任务中的表现显著下降，揭示了大型语言模型在空间推理中的局限性和潜在的改进方向。此项研究的主要创新在于设计了具体的空间推理任务并在实际场景中对大型语言模型进行测试，从而揭示了语言领域模型在空间理解方面的不足。", "conclusion": "本文揭示了大型语言模型在空间推理方面的显著局限性，尤其是在面对复杂空间任务时表现不佳。模型在处理简单模式识别任务时表现良好，但在模型规模和任务复杂性上升时，其空间推理能力迅速下降。这表明大型语言模型需要在空间理解和表达方面进行改进，同时也指出在语言理解和空间推理之间仍然存在显著差距。未来的研究需要进一步探索如何整合语言理解和空间推理能力，以提升模型的整体性能。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20304", "html_url": "https://arxiv.org/abs/2510.20304", "title": "探索生成式过程奖励建模在半结构化数据中的应用：表格问答案例研究", "title_en": "Exploring Generative Process Reward Modeling for Semi-Structured Data: A Case Study of Table Question Answering", "authors": "Lei Tang,Wei Zhou,Mohsen Mesgar", "background": "过程奖励模型（PRMs）通过逐步评估候选解决方案并依据聚合步骤得分来选择答案，这在数学等领域中显示出提高复杂推理能力的有效性。然而，这些模型在处理包含半结构化数据的任务，比如表格问答（TQA）中的应用尚未得到探索。TQA 因其丰富的无关信息、松散的推理步骤以及领域特定的推理而构成了独特的挑战。本文对 TQA 应用 PRMs 进行了首个系统的分析研究，评估了先进的生成式 PRMs。结果显示，结合文本和代码验证的 PRMs 能够辅助解决方案选择，但难以泛化到其他领域内的数据。进一步分析表明，步骤水平验证的表现与答案准确性之间存在弱相关性，这可能归因于较弱的步骤依赖性和松散的因果联系。", "innovation": "本文首次系统地研究了PRMs在TQA中的应用，特别探讨了结合文本和代码验证的PRMs对TQA的适用性，并分析了步骤级验证性能与答案准确性之间的关系，指出了当前PRMs在TQA中的不足。", "conclusion": "本文研究表明，当前PRMs在TQA中存在局限性，强调了在进一步构建更为合乎逻辑且更具有健壮性的验证模型时应考虑的因素。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20351", "html_url": "https://arxiv.org/abs/2510.20351", "title": "大型语言模型中公共表格数据潜在知识的评估", "title_en": "Evaluating Latent Knowledge of Public Tabular Datasets in Large Language Models", "authors": "Matteo Silvestri,Flavio Giorgi,Fabrizio Silvestri,Gabriele Tolomei", "background": "大型语言模型（LLMs）越来越多地被评估其处理结构化数据的能力，但这样的评估通常忽视了一个关键的混淆因素：数据集污染。本文研究了LLMs是否具备对广泛使用的表格基准数据集如成人收入、泰坦尼克号等的先验知识。通过一系列受控探针实验，揭示出污染效应仅在包含强烈语义提示的数据集中出现，例如有意义的列名或可解释的价值类别。当移除或随机化这些提示时，性能急剧下降至近乎随机的水平。这些发现暗示，LLMs在表格推理任务上的表现部分可能反映了对公开可用数据集的记忆，而不是真实的泛化能力。", "innovation": "通过可控实验揭示了污染效应仅在包含强烈语义提示的数据集中出现，而非随机时，性能会急剧下降的新型研究方法。提出了进一步区分语义泄漏与真实推理能力的方法，以改善未来LLM评估规程的策略。", "conclusion": "LLMs在表格推理任务上的表现可能部分反映的是对公开可用数据集的记忆，而非真正的泛化能力。提出了重新审视评估协议和策略，以更准确地评估LLMs的语义泄漏和真实推理能力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20358", "html_url": "https://arxiv.org/abs/2510.20358", "title": "对话不足以使小型语言模型具备沟通能力（但也不会发展启发式强化学习）", "title_en": "Dialogue Is Not Enough to Make a Communicative BabyLM (But Neither Is Developmentally Inspired Reinforcement Learning)", "authors": "Francesca Padovani,Bastian Bunzeck,Manar Ali,Omar Momen,Arianna Bisazza,Hendrik Buschmeier,Sina Zarrieß", "background": "本文研究了仅使用对话数据进行预训练是否能够生成形式上和功能上合适的语言模型。研究者基于此提出的预训练模型，通过多种微调策略，试图使模型生成更加沟通性的文本。尽管模型在大多数标准BabyLM基准测试中表现不佳，但在对话续写预测方面表现出色。", "innovation": "研究使用了预训练对话模型并结合了多种微调策略来增强模型的沟通能力。通过对比不同的微调方法（如PPO和DPO），发现虽然PPO微调带来了混合到对抗性的影响，但DPO微调进一步提高了模型在自定义对话基准测试的表现。", "conclusion": "虽然仅使用对话数据进行预训练的模型在标准基准测试中表现不佳，但在最小对设置下的对话续写预测任务中表现出色。同时，发展启发式强化学习并不能显著提升模型的沟通能力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20356", "html_url": "https://arxiv.org/abs/2510.20356", "title": "FreeChunker: 一个跨粒度分块框架", "title_en": "FreeChunker: A Cross-Granularity Chunking Framework", "authors": "Wenxuan Zhang,Yuan-Hao Jiang,Yonghe Wu", "background": "现有的分块策略在检索增强生成（RAG）系统的有效性中起着显著影响。当前的方法基于固定粒度的范式，依赖于静态边界的识别，这限制了它们对多样化查询要求的适应性。现有方法的固定性使得它们难以处理复杂查询的需求，尤其是在边界识别的精确性方面存在局限性。", "innovation": "本文提出了一种跨粒度编码框架FreeChunker，该框架从根本上转变了传统的分块范式。FreeChunker将句子视为原子单位，并从静态分块切割转向灵活检索，支持任意句子组合。这种范式的转变不仅显著减少了语义边界的检测所需的计算开销，还增强了对复杂查询的适应性。实验结果表明，FreeChunker在LongBench V2上的检索性能优于传统分块方法，且在计算效率上显著优于现有方法。", "conclusion": "FreeChunker通过跨粒度分块框架的实现，有效提高了RAG系统的适应性和检索性能，特别是在处理复杂查询时表现突出。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20381", "html_url": "https://arxiv.org/abs/2510.20381", "title": "VLSP 2025 MLQA-TSR挑战: 关于越南交通标志法规的多模态法律问答", "title_en": "VLSP 2025 MLQA-TSR Challenge: Vietnamese Multimodal Legal Question Answering on Traffic Sign Regulation", "authors": "Son T. Luu,Trung Vo,Hiep Nguyen,Khanh Quoc Tran,Kiet Van Nguyen,Vu Tran,Ngan Luu-Thuy Nguyen,Le-Minh Nguyen", "background": "本文介绍了VLSP 2025 MLQA-TSR多模态法律问答基于交通标志法规的任务。该任务旨在推动越南多模态法律文本处理的研究，并提供一个构建和评估多模态法律领域智能系统的基准数据集，重点关注越南的交通标志法规。", "innovation": "该研究提出了两个子任务：多模态法律检索和多模态问答。通过参与这项挑战，可以提升对越南语多模态法律文本处理的研究，同时也提供了一个在该领域的基准数据集，有助于推动智能系统的开发与评估。", "conclusion": "在VLSP 2025 MLQA-TSR中，最佳的多模态法律检索结果为F2分数64.55%，多模态问答的准确率为86.30%。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20375", "html_url": "https://arxiv.org/abs/2510.20375", "title": "负向文本对大规模语言模型幻觉的影响", "title_en": "The Impact of Negated Text on Hallucination with Large Language Models", "authors": "Jaehyung Seo,Hyeonseok Moon,Heuiseok Lim", "background": "近期关于大规模语言模型（LLMs）中的幻觉研究在自然语言处理领域取得了显著进展，但负向文本对幻觉的影响尚未得到充分研究。该研究针对这一领域的不足，提出了三个重要的未解答的研究问题并尝试回答这些问题。研究通过分析LLMs在处理负向文本时的内部状态，揭示了LLMs在检测负向文本中的幻觉时遇到的挑战。", "innovation": "研究设计了NegHalu数据集，这是通过重建已有幻觉检测数据集加入负向表达实现的。研究发现LLMs在检测负向文本中的幻觉时表现不佳，经常产生不合逻辑或不忠实的判断。研究还揭示了LLMs在处理负向输入时的内部状态挑战，强调了减轻其无意影响的难度。", "conclusion": "本研究证明，LLMs在检测负向文本中的幻觉时存在困难，经常做出逻辑不一致或不忠実的判断。研究还揭示了LLMs在处理负向输入时的具体内部挑战，指出现有的解决方案还存在不足之处。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20342", "html_url": "https://arxiv.org/abs/2510.20342", "title": "Teaching Language Models to Reason with Tools", "title_en": "Teaching Language Models to Reason with Tools", "authors": "Chengpeng Li,Zhengyang Tang,Ziniu Li,Mingfeng Xue,Keqin Bao,Tian Ding,Ruoyu Sun,Benyou Wang,Xiang Wang,Junyang Lin,Dayiheng Liu", "background": "大型语言推理模型（LRMs）如OpenAI-o1展示了在自然语言推理方面的出色能力。然而，这些模型在处理复杂的数学运算时经常表现出效率低下或不准确。将计算工具如代码解释器（CIs）集成到模型中虽然提供了一个有前景的解决方案，但也带来了一个关键挑战：模型内部基于概率的推理与外部基于确定性的CI提供的知识之间的冲突，这往往导致模型陷入无效的推理过程。", "innovation": "我们提出了CoRT（Code-Optimized Reasoning Training），这是一种后训练框架，旨在教导LRMs有效使用CIs。我们还提出了一种新的数据合成策略——Hint-Engineering，它在推理路径的关键点战略性地注入多样化的提示。这种方法生成了高质量的代码集成推理数据，专门用于优化LRM-CI交互。CoRT进一步通过拒绝采样和强化学习调整了外部CI使用与内部思考的多轮交织，我们的实验证明了CoRT的有效性，分别在DeepSeek-R1-Distill-Qwen-32B和DeepSeek-R1-Distill-Qwen-1.5B上取得了4%和8%的绝对提升，并显著提高了效率，32B模型和1.5B模型的令牌使用量分别减少了约30%和50%。", "conclusion": "CoRT框架能够通过引入代码优化推理训练和提示工程，显著提升语言模型在数学推理任务中的表现和效率。通过这种方法，我们可以设计和生成高质量的代码集成推理数据，改善模型与计算工具的交互。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20460", "html_url": "https://arxiv.org/abs/2510.20460", "title": "大型语言模型中不确定估计方法的系统性评估", "title_en": "Systematic Evaluation of Uncertainty Estimation Methods in Large Language Models", "authors": "Christian Hobelsberger,Theresa Winner,Andreas Nawroth,Oliver Mitevski,Anna-Carolina Haensch", "background": "大型语言模型（LLMs）产生的输出具有不同程度的不确定性，而且正确性也参差不齐，这使得它们的实际可靠性难以保证。为了量化这种不确定性，本文系统性地评估了四种用于LLM输出的置信度估计方法：VCE、MSP、样本一致性以及Vashurin等人提出的CoCoA方法。这些方法在最新的开源LLM上进行了四个问答任务的实验。", "innovation": "本文系统性地评估了四种不确定性估计方法，并在最新的开源LLM上进行了四个问答任务的实验。实验结果表明，每个不确定性度量捕获了模型置信度的不同方面，而CoCoA方法提供了最佳的可靠性，既提高了校准性，又提高了正确答案的鉴别能力。文章还讨论了每种方法的权衡，并为LLM应用中选择不确定性度量提供了建议。", "conclusion": "尽管每种方法都有其优势，但CoCoA方法在整体可靠性上表现最佳，既提高了校准性，又提高了正确答案的鉴别能力。文章建议在选择不确定性度量时应考虑每种方法的特性和适用场景。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20449", "html_url": "https://arxiv.org/abs/2510.20449", "title": "LM-mixup: 负责文本数据增强的语言模型混合法", "title_en": "LM-mixup: Text Data Augmentation via Language Model based Mixup", "authors": "Zhijie Deng,Zhouan Shen,Ling Li,Yao Zhou,Zhaowei Zhu,Yanji He,Wei Wang,Jiaheng Wei", "background": "指令调优对于对齐大型语言模型（LLMs）至关重要，但指令遵守数据的质量差异明显。高质量数据虽然重要但稀缺，而大量的低质量数据常被丢弃造成大量信息损失。现有数据增强方法难以高效提升低质量数据，且对这些方法的评估标准也不完善。", "innovation": "本文正式定义了指令蒸馏任务：将多个低质量或语义冗余的输入指令蒸馏成高质量且一致的指令-输出对。提出了一个全面的数据构建流水线生成MIXTURE数据集，包含144K样本对低质量或语义冗余的不完美指令簇与其高质量蒸馏。介绍了LM-Mixup方法，首先对MIXTURE进行监督微调，再通过强化学习优化之，利用三个互补的奖励信号：质量、语义对齐和格式合规，通过Group Relative Policy Optimization (GRPO)。实验表明，LM-Mixup能有效增强不完美数据集，利用仅占数据集3%的蒸馏数据的微调模型优于全数据集训练，且与最先进的高质量数据选择方法相当。", "conclusion": "本文工作证明了低质量数据在用LM-Mixup正确蒸馏和增强后是宝贵的资源，显著增强了指令调优的LLMs的效率和性能。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20411", "html_url": "https://arxiv.org/abs/2510.20411", "title": "BabyLM在最邻近发展区中的教师示范以实现有条件的多轮交互", "title_en": "Teacher Demonstrations in a BabyLM's Zone of Proximal Development for Contingent Multi-Turn Interaction", "authors": "Suchir Salhan,Hongyi Gu,Donya Rooein,Diana Galvan-Sosa,Gabrielle Gaudeau,Andrew Caines,Zheng Yuan,Paula Buttery", "background": "多轮对话中的儿童与照料者之间的交流具有一个性质称为连续性，即对话双方之间的即时、直接且有意义的互动。本文介绍了一个名为ContingentChat的教师-学生框架，该框架基于一个训练在100万词上的BabyLM进行评测并提升多轮连续性。通过使用新颖的后训练对齐数据集，BabyLM生成的响应更加合乎语法且连贯。通过适应性的教师解码策略实验表明额外收益有限。ContingentChat表明了针对对话质量的目标后训练的优势，并指出连续性仍然是BabyLM面临的一大挑战。", "innovation": "1. 引入了一个名为ContingentChat的教师-学生框架，对多轮对话的连续性进行了评测与提升。\n2. 采用新型后训练对齐数据集，使BabyLM生成的响应更加合乎语法且连贯。\n3. 通过适应性的教师解码策略实验，虽然展示了有限的额外收益，但仍揭示了干预性策略对提升对话质量的有效性。", "conclusion": "ContingentChat表明了针对对话质量的目标后训练的优势，并指出连续性仍然是BabyLM面临的一大挑战。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20475", "html_url": "https://arxiv.org/abs/2510.20475", "title": "优化掩码语言建模以预训练BabyLMs：给予你你想要的", "title_en": "Mask and You Shall Receive: Optimizing Masked Language Modeling For Pretraining BabyLMs", "authors": "Lukas Edman,Alexander Fraser", "background": "本文描述了2025年BabyLM挑战赛的策略。背景信息是，尽管现有的掩码语言建模（MLM）方法已经被广泛使用，但研究人员希望进一步改进以提高模型在(GLUE和其扩展(Super)GLUE)任务上的表现。并且，为了增强模型的形态学泛化能力，研究人员考虑加入了子词嵌入。", "innovation": "本文的创新之处在于，它提供了一种改进的掩码语言模型形式，该形式可以根据模型对词汇的预测能力调整被掩码词汇的概率。此外，该研究还引入了子词嵌入，这被发现提高了模型的形态学泛化能力。实验结果表明，这种改进的MLM方法在所有GLUE和(Super)GLUE任务上都取得了显著的性能提升。", "conclusion": "本文的提交在严格的少数数据赛道上击败了基线方法。通过引入优化的掩码语言模型和子词嵌入，显著提高了模型在GLUE和(Super)GLUE任务上的表现。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20479", "html_url": "https://arxiv.org/abs/2510.20479", "title": "RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging", "title_en": "RECALL: REpresentation-aligned Catastrophic-forgetting ALLeviation via Hierarchical Model Merging", "authors": "Bowen Wang,Haiyuan Wan,Liwen Shi,Chen Yang,Peng He,Yue Ma,Haochen Han,Wenhao Li,Tiao Tan,Yongjian Li,Fangming Liu,Yifan Gong,Sheng Zhang", "background": "大型语言模型（LLMs）中的内部表示作为学习知识的可靠代理；然而，传统的持续学习方法往往需要访问历史数据或会产生性能权衡，导致灾难性遗忘问题。", "innovation": "提出了RECALL，一种新颖的基于表示的持续学习模型融合框架，无需访问历史数据。RECALL通过集群典型样本逐层隐藏表示来计算模型间的相似性，并进行自适应的分层参数融合以在不同层之间对齐知识。这种设计允许浅层保留泛化的特征，但在深层支持任务特定的适应。RECALL不需任务标签或产生性能权衡，实现了无缝的多域集成和强大的灾难性遗忘抵抗力。", "conclusion": "广泛的实验结果表明，RECALL在知识保留和泛化方面优于基准方法，为渐进式LLM提供了一种可扩展且无需数据的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20487", "html_url": "https://arxiv.org/abs/2510.20487", "title": "引导评估意识的语言模型以表现得像已部署的样子", "title_en": "Steering Evaluation-Aware Language Models To Act Like They Are Deployed", "authors": "Tim Tian Hua,Andrew Qin,Samuel Marks,Neel Nanda", "background": "大型语言模型（LLMs）在进行评估时有时会检测出自己被评估，并调整行为以显得更合规，这会影响安全性评估的可靠性。因此，研究者们开发了一种方法，即通过向LLM的激活中加入一个引导矢量，来抑制评估意识，使模型在这种评估情境中表现得更像实际部署时的状态。", "innovation": "作者提出了一种新的训练方法，即通过两步训练过程来引导LLM表现评估意识行为：首先进行持续预训练，其中包含对模型文档的描述（包括评估时使用Python类型提示但不使用部署时、识别评估提示意味正在测试）；其次，进行专家迭代训练，使模型能够在评估环境中使用类型提示。结果显示，这种引导方法可以抑制评估意识，即使存在评估提示，也能使模型表现得像部署时一样。研究还发现，该引导矢量是基于模型最初的版本构建的，这为AI评估者提供了改进评估可靠性的可能性。", "conclusion": "通过引导LLM的表现，使其在评估中如同实际部署环境，可以提高安全性评估的可靠性。未来可以通过类似的引导策略，进一步优化AI模型在各种评估和部署环境中的表现。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20386", "html_url": "https://arxiv.org/abs/2510.20386", "title": "NeoDictaBERT: 推动BERT模型在希伯来语领域的边界", "title_en": "NeoDictaBERT: Pushing the Frontier of BERT models for Hebrew", "authors": "Shaltiel Shmidman,Avi Shmidman,Moshe Koppel", "background": "自BERT模型首次发布以来，尽管体型较小（BERT-base有约100M个参数），但在多种任务上表现出了卓越性能。然而，这些模型所使用的架构已过时，与最新的基于Transformer的模型（如Llama3和Qwen3）相比显得落后。近期，多个新型架构得以提出，旨在缩小这一差距。ModernBERT和NeoBERT在英语基准测试中表现出显著改进，大大扩展了支持的上下文窗口。在此基础上，作者介绍了专注于希伯来文的NeoDictaBERT和NeoDictaBERT-bilingual，这两种模型在几乎所有希伯来语基准测试中均优于现有模型，为下游任务提供了坚实的基础。NeoDictaBERT-bilingual特别在检索任务上表现出色，优于其他类似规模的多语种模型。这篇文章描述了训练过程并报告了在各种基准测试中的结果，同时向社区发布了模型，以推动希伯来语自然语言处理研究和开发的进步。", "innovation": "提出的新架构在保持简洁的同时大幅提升了性能，特别是对希伯来文的支持；专门针对希伯来文本设计的新颖模型在多语言环境中表现出色；NeoDictaBERT-bilingual模型在检索任务上显著优于其他类似规模的多语种模型。", "conclusion": "NeoDictaBERT和NeoDictaBERT-bilingual模型在几乎所有的希伯来语基准测试中超越现有模型，特别是展示了在检索任务上的优越性。作者同时表明了NeoDictaBERT和NeoDictaBERT-bilingual的训练过程并公开发布模型，旨在促进希伯来语自然语言处理的研究和开发。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20505", "html_url": "https://arxiv.org/abs/2510.20505", "title": "层次序列迭代在异构问答中的应用", "title_en": "Hierarchical Sequence Iteration for Heterogeneous Question Answering", "authors": "Ruiyi Yang,Hao Xue,Imran Razzak,Hakim Hacid,Flora D. Salim", "background": "检索增强生成（RAG）在处理多步问题和异构证据来源时仍然容易出现脆性问题，这导致了准确性和延迟之间的权衡以及标记或工具预算受限。现有方法在这些方面存在不足，本研究旨在解决这些问题。", "innovation": "提出了层次序列迭代（HSEQ）框架，该框架包括两个主要创新点：（1）将文档、表格和知识图谱线性化为带有轻量级结构标签的可逆层次序列；（2）进行结构感知迭代，在答案合成之前，仅收集足够的证据。通过头部代理和迭代代理的协作，实现可信赖的问答结果，并提供可选的完善循环来解决发现的矛盾问题。研究表明，该方法在HotpotQA、HybridQA/TAT-QA和MetaQA数据集上，与单一通道、多跳和代理RAG基线相比，显示出了高度效率和一致的EM/F1增益。", "conclusion": "HSEQ展示了三项核心优势：（1）一种格式无关联的统一框架，使单个策略可以在文本、表格和KG之间通用；（2）引导性、预算感知迭代，减少不必要的操作，同时保持准确性；（3）证据规范化以提高答案的一致性和可审计性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20498", "html_url": "https://arxiv.org/abs/2510.20498", "title": "通过方向邻域共识实现稳健的偏好对齐", "title_en": "Robust Preference Alignment via Directional Neighborhood Consensus", "authors": "Ruochen Mao,Yuling Shi,Xiaodong Gu,Jiaheng Wei", "background": "将大型语言模型（LLMs）与人类偏好对齐对于创建可靠和可控的人工智能系统至关重要。人类偏好可以被可视化为一个高维向量，其中不同的方向代表了不同的属性之间的权衡（例如，有用性与冗长性）。然而，由于训练数据往往反映的是主流的、平均的偏好，LLMs 往往在处理常见请求时表现良好，但在满足具体的、个别需求时会表现不足。这种不匹配创造了偏好覆盖差距。现有的方法通常通过昂贵的重训练来解决这一问题，这可能无法适用于整个多样性偏好谱系。这种脆弱性意味着，当用户的需求反映了一种不同于训练数据中心趋势的微妙偏好时，模型性能可能会不可预测地退化。", "innovation": "我们引入了鲁棒偏好选择（RPS），这是一种后处理、无需训练的方法，通过利用方向邻域共识。RPS 不是迫使模型从单一的高度特定的偏好生成响应，而是从相关的偏好局部邻域中采样多个响应，以创建一个优质的候选池。然后，它选择最能与用户原始意图对应的最佳响应。我们的理论框架表明，我们的邻域生成策略在理论上有助于证明优于一个强大的基线方法，该基线方法也采样了多个候选者。全面的实验表明，RPS 在处理来自空间欠代表性区域的具有挑战性的偏好时，显著提高了稳健性，而没有进行任何模型重训练，战胜基线的胜率高达69%。", "conclusion": "我们的工作呈现了一个实用的、具有理论依据的增强偏好对齐模型可靠性的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20508", "html_url": "https://arxiv.org/abs/2510.20508", "title": "多语言LLMs的政洽公正性评估：基于21种平行EuroParl数据集的案例研究", "title_en": "Assessing the Political Fairness of Multilingual LLMs: A Case Study based on a 21-way Multiparallel EuroParl Dataset", "authors": "Paul Lerner,François Yvon", "background": "通常，大型语言模型（LLMs）的政治偏见通过模拟其对英语调查的回答来评估。本研究提出了一种不同的政治偏见评估框架，基于多语言翻译的公平原则。通过对欧洲议会（EP）演讲的翻译质量进行系统比较，发现在政府、中间和右翼占多数的政党的演讲比边缘政党的演讲有更好的翻译表现。", "innovation": "本研究通过创建一个包含21种平行语言的EuroParl数据集，实现了对多语言LLMs政治公正性的评估，提供了更全面和系统的比较。该数据集包含每位演讲者的政治隶属信息，包括1.5百万句、4000万词和24.9亿字符的议会演讲记录，涵盖三个年份、超过1000名演讲者、7个国家、12个欧盟政党、25个欧盟委员会以及数百个国家政党。", "conclusion": "研究发现，在欧洲议会演讲的翻译质量上，主流政党的演讲比边缘政党的演讲有更好的翻译表现。这意味着现有的LLMs可能在多语言翻译中存在政治倾向性的偏见。基于此，研究人员呼吁开发更公正且中立的LLMs以改善翻译质量。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20535", "html_url": "https://arxiv.org/abs/2510.20535", "title": "ARC-Encoder：大规模语言模型中的压缩文本表示学习", "title_en": "ARC-Encoder: learning compressed text representations for large language models", "authors": "Hippolyte Pilchen,Edouard Grave,Patrick Pérez", "background": "近年来，检索增强生成和链式推理等技术导致了更长的上下文和增加的推理成本。上下文压缩技术可以减少这些成本，但最有效的方法需要调整目标模型或修改其架构，这可能会降低其一般能力，特别是在非特定用途场景中。因此，研究人员积极探索新的方法来缓解这一问题。", "innovation": "提出了一种名为ARC-Encoder的可调文本表示压缩器，该编码器可以将上下文压缩为连续表示，这些连续表示可以替代解码器大型语言模型中的令牌嵌入。通过系统研究训练策略和架构选择，设计了ARC-Encoder，能够在保持相同性能的同时显著减少计算成本。此外，该模型可以在不同解码器之间进行适应，使得ARC-Encoder成为一个灵活且高效的大规模语言模型中的可移植编码器解决方案。", "conclusion": "ARC-Encoder在多种应用场景中展现出优异的性能，并提高了推理过程中的计算效率。同时，它可以适应多个解码器，增强了其通用性和可移植性。研究团队已经将训练代码和相关数据集及预训练模型发布在网络上。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20548", "html_url": "https://arxiv.org/abs/2510.20548", "title": "GlobalRAG: 通过强化学习在多跳问答中增强全局推理", "title_en": "GlobalRAG: Enhancing Global Reasoning in Multi-hop Question Answering via Reinforcement Learning", "authors": "Jinchang Luo,Mingquan Cheng,Fan Wan,Ni Li,Xiaoling Xia,Shuangshuang Tian,Tingcheng Bian,Haiwei Wang,Haohuan Fu,Yan Tao", "background": "强化学习在检索增强生成（RAG）中的应用显示出了提高检索和生成能力的潜力，但其在多跳问答中的有效性受限于两大基本问题：（i）缺乏全局规划来进行多步推理；（ii）执行不忠实，阻碍有效的查询制定和一致使用检索证据。", "innovation": "提出了一种名为GlobalRAG的强化学习框架，旨在增强多跳问答中的全局推理。GlobalRAG将问题分解为子目标，并协调检索与推理的整合，迭代地改进证据。通过引入计划质量奖励和子目标完成奖励来引导这一过程，从而促进连贯规划和可靠的子目标执行。此外，采用了一种逐步权重退火策略来平衡过程导向和结果导向的目标。", "conclusion": "在多种领域和非预期领域的基准测试上进行了广泛的实验表明，GlobalRAG在仅使用8k训练数据（仅为强基准线使用的训练数据的42%）的情况下显著优于强大的基线，平均在EM和F1上分别提升了14.2%。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20584", "html_url": "https://arxiv.org/abs/2510.20584", "title": "ChatGPT能否公平地编码沟通数据？：来自多种协作任务的实证证据", "title_en": "Can ChatGPT Code Communication Data Fairly?: Empirical Evidence from Multiple Collaborative Tasks", "authors": "Jiangang Hao,Wenju Cui,Patrick Kyllonen,Emily Kerzabi", "background": "大规模评估沟通与协作需要耗费大量人力将沟通数据编码到不同的框架中。尽管先前研究证明ChatGPT可以根据编码标准直接编程以达到类似人类评估者的准确度，但尚不清楚ChatGPT或类似AI技术的编码是否会对不同的人口统计学群体（如性别和种族）表现出偏见。因此，本研究探讨了在典型协作问题解决编码框架下，基于ChatGPT的沟通数据自动编码情况，并考察不同性别和种族群体之间的差异。分析数据源自三种类型的协作任务：谈判、问题解决和决策制定。研究表明，基于ChatGPT的编码在性别和种族方面没有任何显著偏见，为将其应用于大规模评估协作与沟通奠定了基础。", "innovation": "本研究通过使用典型协作问题解决的编码框架，首次系统考察了ChatGPT在编码沟通数据时是否存在针对不同性别和种族群体的偏见问题。这是对现有研究的拓展，有助于推动人工智能技术在大规模沟通和协作评估中的应用。", "conclusion": "研究表明，基于ChatGPT的编码方法在性别和种族方面没有显著偏见，为其实用于大规模沟通和协作评估提供了实证支持。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20543", "html_url": "https://arxiv.org/abs/2510.20543", "title": "被追逐的狗难住了模型：测量模型何时放弃结构转而使用捷径", "title_en": "The Dog the Cat Chased Stumped the Model: Measuring When Language Models Abandon Structure for Shortcuts", "authors": "Sangmitra Madhusudan,Kaige Chen,Ali Emami", "background": "尽管语言模型在解析诸如“这只被狗追逐过的猫喵喵叫了”这类嵌套从句句子时表现正确，我们仍不清楚它们是进行语法分析还是简单地熟悉狗追逐猫的模式。虽然进行了大量基准测试，但缺乏区分结构性理解与语义模式匹配的方法。该论文介绍了一个名为CenterBench的数据集，其中包括9,720个关于中心嵌入语句（如“这只被狗追逐过的猫喵喵叫了”）的理解问题，这些语句中的从句递归嵌套，从简单到深度嵌套结构，提出了处理需求。每个句子都有一个语法相同但语义不现实的对应句子（例如，邮递员开药，医生送信）和六个理解问题，测试表面理解、句法依赖性和因果推理。研究表明，随着复杂性的增加，模型对合理句子与不合理句子的性能差距系统地扩大，模型在复杂结构上的最大差异达到26.8个百分点。这表明模型在复杂结构上会放弃结构分析转向语义关联。特别是在涉及结果动作的问题上，因果关系比语义一致性更重要，语义不真实性会损害模型的性能。与此同时，推理解释模型提高了准确性，但其痕迹显示了基于语义的捷径、过度分析和回答拒绝现象。不同于随着复杂性增加合理模型的表现优势系统性增长，人类的表现具有语义效应的可变性。CenterBench提供了一个新的框架来识别模型何时从结构分析转向模式匹配", "innovation": "论文引入了一个名为CenterBench的数据集，用于评估语言模型在复杂中心嵌入句子里对结构理解与语义模式匹配的区别。CenterBench提出了一个测试框架，通过比较合理句子和不合理的句子，揭示模型在面对复杂句法结构时的行为模式。研究表明，随着句子复杂性的增加，合理句子与不合理句子的表现差距也增加，显示了模型在特定场景下倾向于使用语义简化而非深入结构分析。此外，它还探讨了不同模型类型（包括推理解释模型）的行为，并为未来研究提供了衡量模型理解深度的新标准。", "conclusion": "CenterBench数据集为识别模型在面对复杂结构时是否从基于结构的分析转向基于模式的推理提供了新的框架。通过这种框架，研究人员可以更好地理解当前语言模型在处理复杂结构语句时的行为，并开发改进策略，以确保模型能够更准确地进行结构分析而非依赖于简化或语义捷径。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20635", "html_url": "https://arxiv.org/abs/2510.20635", "title": "探索的语言模型为何落地：评估大型语言模型的求知欲", "title_en": "Why Did Apple Fall To The Ground: Evaluating Curiosity In Large Language Model", "authors": "Haoyu Wang,Sihang Jiang,Yuyan Chen,Yitong Wang,Yanghua Xiao", "background": "大型语言模型（LLMs）在自然语言处理领域的进步引发了关于这些模型是否具备类似于人类由求知欲驱动的学习能力的讨论。人类的求知欲可以通过改良的五维求知欲量表（5DCR）进行评定，涵盖了信息获取、刺激寻求和社会求知欲等多个维度。", "innovation": "本文设计了一个全面的评估框架，涵盖信息寻求、刺激寻求和社会求知欲等多个维度，用于评估LLMs的求知欲。研究结果显示，尽管LLMs表现出比人类更强烈的求知欲望，但在面对不确定环境时，它们的决策仍倾向于保守。此外，研究还发现求知欲与LLMs的推理及主动学习能力之间存在正相关关系。", "conclusion": "LLMs有潜力展示类似于人类的求知欲，这些发现为LLMs的学习能力和创新研究提供了实验支持。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20567", "html_url": "https://arxiv.org/abs/2510.20567", "title": "超越检索排名：电子商务搜索中的多代理认知决策框架", "title_en": "Beyond Retrieval-Ranking: A Multi-Agent Cognitive Decision Framework for E-Commerce Search", "authors": "Zhouwei Zhai,Mengxiang Chen,Haoyun Xia,Jin Li,Renquan Zhou,Min Yang", "background": "电子商务搜索长期以来受到检索-排名范式的支配，但这种依赖查询-项目匹配的方法在根本上与平台用户的多阶段认知决策过程不一致。这种不一致导致了复杂查询中的语义缺口、为获取跨平台信息而产生的高决策成本以及缺乏专业的购物指导等问题。", "innovation": "本文提出了一种多代理认知决策框架(MACDF)，从被动检索转变为积极的支持决策。大量的离线评估显示MACDF在推荐准确性和用户满意度方面有显著提升，特别是在涉及否定、多约束或推理需求的复杂查询上。", "conclusion": "研究表明，多代理认知系统具有重新定义电子商务搜索的潜力。在线A/B测试在京东搜索平台上证实了其实际效果。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20670", "html_url": "https://arxiv.org/abs/2510.20670", "title": "CantoNLU：一个用于粤语自然语言理解和评估的标准", "title_en": "\\textsc{CantoNLU}: A benchmark for Cantonese natural language understanding", "authors": "Junghyun Min,York Hay Ng,Sophia Chan,Helena Shunhua Zhao,En-Shiun Annie Lee", "background": "尽管粤语使用者众多，但由于政策和双语现象的影响，粤语资源仍然不足，缺乏评估框架。本文旨在填补这一空白。", "innovation": "提出了一项新的基准测试CantoNLU，该基准涵盖了七项任务，包括词汇消歧、语义判断、语言检测、自然语言推理、情感分析、词性标注和依存句法分析。此外，还提供了不同模型的基线性能，包括未经过粤语训练的汉语模型、通过持续预训练汉语模型的两个粤语适配模型，以及从零开始训练的单语粤语模型。", "conclusion": "粤语适配模型整体性能最佳，而单语模型在句法任务上表现更好。未经过粤语训练的汉语模型在某些场景下仍具有竞争力，表明当粤语领域的数据稀缺时，直接迁移可能是足够的。所有数据集、代码和模型权重均已发布，旨在促进未来粤语自然语言处理的研究。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20610", "html_url": "https://arxiv.org/abs/2510.20610", "title": "BUSTED在AraGenEval共享任务中的表现：基于Transformer模型的阿拉伯AI生成文本检测比较研究", "title_en": "BUSTED at AraGenEval Shared Task: A Comparative Study of Transformer-Based Models for Arabic AI-Generated Text Detection", "authors": "Ali Zain,Sareem Farooqui,Muhammad Rafi", "background": "本文介绍了BUSTED团队在Ara-GenEval共享任务中关于阿拉伯AI生成文本检测的提交。通过使用预训练的Transformer模型对提供的数据集进行微调进行二分类任务，结果显示，适用于多种语言的XLM-RoBERTa模型在F1分数上表现最佳，达到了0.7701，这一结果出乎意料，因为它优于专门针对阿拉伯语模型的性能，这突显了AI生成文本检测的复杂性以及多语言模型的强大泛化能力。", "innovation": "研究使用了三个预训练的Transformer模型：AraELECTRA、CAMeLBERT和XLM-RoBERTa。结果显示，尽管专为阿拉伯语设计的模型通常具有优势，但适用于多种语言的XLM-RoBERTa模型在F1分数上表现最佳，这表明多语言模型在泛化能力方面的潜在优势。", "conclusion": "这项研究表明，不同预训练Transformer模型在阿拉伯AI生成文本检测中的表现存在显著差异，其中多语言模型XLM-RoBERTa表现出色，显示出强大的泛化能力。这强调了在相关任务中挖掘并利用多语言模型优势的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20690", "html_url": "https://arxiv.org/abs/2510.20690", "title": "神经多样性正则化小型模型中的幻觉", "title_en": "Neural Diversity Regularizes Hallucinations in Small Models", "authors": "Kushal Chakrabarti,Nirmal Balachundhar", "background": "语言模型在不断地增加参数、计算资源和数据的情况下仍然会产生幻觉。研究人员发现，现有的改进方法并未有效减少这种情况的发生。因此，本文提出神经多样性——即去相关的并行表示——作为一种原理性的机制，在固定参数和数据预算下减少幻觉的发生率。这一机制受到投资组合理论的启发，证明了幻觉概率受表示相关性的影响，表明语言模型需要适当的神经多样性量来改善效果。", "innovation": "本文提出了神经多样性（Neural Diversity，ND）的概念，通过使用并行LoRA适配器和Barlow Twins正则化技术来减少语言模型中的幻觉。实验结果表明，与现有技术相比，ND-LoRA在不牺牲一般准确性的情况下，可以减少高达25.6%（平均减少14.6%）的幻觉。此外，实验证明LoRA适配器和正则化之间存在协同作用，并且通过因果干预实验证明神经多样性是中介因素。", "conclusion": "不同的任务需要不同的神经多样性量以最佳地改善模型的可靠性。综上所述，这些结果强调了神经多样性是除了参数和数据之外，提高固定预算下语言模型可靠性的第三个维度。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20647", "html_url": "https://arxiv.org/abs/2510.20647", "title": "语言共通语：多语言AI的双刃剑", "title_en": "The Reasoning Lingua Franca: A Double-Edged Sword for Multilingual AI", "authors": "Alan Saji,Raj Dabre,Anoop Kunchukuttan,Ratish Puduppully", "background": "大型推理模型（LRMs）在数学、科学和其他问答任务中表现出强大性能，但这些模型在多语言推理方面的能力和表现尚未得到充分探索。当LRMs遇到非英语问题时，往往倾向于使用英语进行推理，导致关于解释性和处理语言及文化差异方面存在担忧。这项研究系统地对比了LRMs在英语和问题语言之间的推理差异，评估涵盖MGSM和GPQA钻石任务，不仅测量回答准确性，还分析推理痕迹中的认知属性。研究发现，以英语进行的推理痕迹中表现出更多认知行为特征，以英语推理通常会获得更高的最终答案准确性，随着任务复杂度提升，这种差异越发明显。然而，这种以英语为中心的策略也存在关键缺陷，即“翻译迷失”，通过不必要的翻译步骤导致会导致遗漏重要信息，而使用问题原语言推理可以避免此类错误。", "innovation": "研究首次系统性地对比了LRMs在两种不同语言之间的推理差异，不仅衡量准确率，还深入分析了认知属性的体现，并发现了存在于以英语为中心策略的关键缺陷。这为改进多语言AI的理解和解释能力提供了新的视角和技术方法。", "conclusion": "研究揭示了以英语为中心的推理策略在多语言AI中的优势与局限，指出在面对复杂任务时，应考虑利用问题原语言进行推理，以提高准确性和理解深度。这为多语言AI的发展提供了新的挑战和方向。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20700", "html_url": "https://arxiv.org/abs/2510.20700", "title": "结构条件下的最小贝叶斯风险解码", "title_en": "Structure-Conditional Minimum Bayes Risk Decoding", "authors": "Bryan Eikema,Anna Rutkiewicz,Mario Giulianelli", "background": "最小贝叶斯风险（MBR）解码作为一种替代传统生成策略的方法，近年来重新引起了研究者的兴趣。尽管MBR在机器翻译中表现良好，而机器翻译中语言模型结果空间的变化是自然受限的，但在更开放的任务，如对话或指令跟随中，MBR可能面临挑战。我们假设在这种环境中，使用标准的基于相似性的效用函数应用MBR可能会选择更广泛代表模型分布的响应，但未必是最优的特定生成组，这些组共享潜在结构特性。为了测试这一假设，我们创建了一个数据集，捕捉了三种代表性的潜在结构类型：对话行为、情感和响应结构（如句子、段落或列表）。我们进一步提出两种度量标准来评估MBR的结构最优性。我们的分析表明，常见的基于相似性的度量标准在这方面表现不足。相比之下，我们提出的改进显著提高了结构性的最优性。最后，我们在实际的指令跟随基准测试上（AlpacaEval和MT-Bench）评估了我们的方法，结果表明增加结构敏感性可提高生成品质至多13.7个百分点的胜率。", "innovation": "我们提出了三种轻量级的效用函数适应措施，旨在使MBR对结果空间的结构性变异性更加敏感。并且我们开发了两种新的度量标准，来评估MBR的结构性最优性。实验证明，传统的基于相似性的度量标准在这些度量标准下表现不佳，而我们提出的改进显著提高了结构最优性。实证结果表明，增加了结构敏感性后，生成质量提高了至多13.7个百分点的胜率。", "conclusion": "我们通过对三种不同潜在结构类型的数据集进行了实验，在实际指令跟随基准测试上证明了增加结构敏感性的方法能显著提高生成质量。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20721", "html_url": "https://arxiv.org/abs/2510.20721", "title": "用户对隐私敏感情景下大语言模型响应的隐私性和帮助性的感知", "title_en": "User Perceptions of Privacy and Helpfulness in LLM Responses to Privacy-Sensitive Scenarios", "authors": "Xiaoyuan Wu,Roshni Kaushik,Wenkai Li,Lujo Bauer,Koichi Onoue", "background": "大语言模型（LLMs）在诸如撰写邮件、总结会议和回答健康问题等任务中得到了快速应用。在这些使用场景中，用户可能需要分享私人信息，如健康记录或联系方式。以前的研究开发了基准测试（例如，ConfAIde, PrivacyLens）来评估LLMs识别并屏蔽私人信息的能力。尽管这些基准测试发现LLMs在处理复杂任务时有时会泄露私人信息，但这些评估主要依赖代理LLMs来进行合规性评估，忽视了实际用户的体验。之前的工作主要关注LLMs响应的隐私保护质量，而没有探讨帮助性上的细微差别。为了更好地理解用户如何感知LLMs在隐私敏感情况下的响应的隐私保密度和帮助性，本研究设计了一个包含94名参与者的用户研究，利用来自PrivacyLens的90个场景进行了评估。", "innovation": "本研究创新地从用户的感知角度出发，评估了大语言模型（LLMs）在隐私敏感场景下的响应的隐私保密度和帮助性。研究发现，用户对于LLMs响应的隐私保密度和帮助性的判断存在较大差异，而代理LLMs的意见则高度一致，但与用户评价的相关性却不高。这些结果表明，LLMs响应的隐私性和帮助性往往与个体相关，使用代理LLMs难以准确预测真实用户的感知。", "conclusion": "研究结果强调了需要进行用户中心的研究来评估大语言模型的能力，同时确保隐私保护。未来的研究可以探索如何改善代理LLMs与用户的对齐，以便更准确地估计用户感知的隐私度和实用性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20780", "html_url": "https://arxiv.org/abs/2510.20780", "title": "大型推理模型适合作为翻译评估器吗？分析与性能提升", "title_en": "Are Large Reasoning Models Good Translation Evaluators? Analysis and Performance Boost", "authors": "Runzhe Zhan,Zhihong Huang,Xinyi Yang,Lidia S. Chao,Min Yang,Derek F. Wong", "background": "大型推理模型（LRMs）近年来取得了进步，能够进行复杂的推理任务，并为下游任务提供更好的理解过程。然而，这些模型在机器翻译质量评估方面的作用尚未得到充分研究和利用。本研究首次对LRM在机器翻译评估中的应用进行了系统的分析，指出了存在的关键挑战，如对简单实例的过度思考、评分机制的问题，可能导致评估结果的高估。", "innovation": "提出通过在合成的人类类似思考轨迹上训练LRM来调整其推理过程，从而显著降低思考预算约35倍，同时提高不同规模LRM（如R1-Distill-Qwen-7B）的评估性能，使其得到更准确的评估结果。", "conclusion": "研究表明，有效调整后的LRM在机器翻译的精细化自动评估中具有巨大潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20787", "html_url": "https://arxiv.org/abs/2510.20787", "title": "通过混合稀疏注意力和上下文可学习键值对移除减轻线性注意力的健忘症", "title_en": "Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention and Contextualized Learnable Token Eviction", "authors": "Mutian He,Philip N. Garner", "background": "线性注意力模型将整个输入序列压缩为固定大小的递归状态，是一种高效替代Transformer的方法，但它们的有限记忆导致健忘，影响检索密集型任务的性能。", "innovation": "本文探索了一系列混合模型来恢复对过去令牌的直接访问。提出了一种新的可学习键值对移除方法，并结合滑动窗口注意力机制，智能地保留每个头有限的关键键值对，同时保持线性注意力的时空复杂度不变。此外，为稀疏注意力机制提供了高效的的 Triton 内核。", "conclusion": "在检索密集型基准测试中的实证评估支持了我们方法的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20782", "html_url": "https://arxiv.org/abs/2510.20782", "title": "针对LLM生成文本负责任性能维度的特定应用数据集", "title_en": "A Use-Case Specific Dataset for Measuring Dimensions of Responsible Performance in LLM-generated Text", "authors": "Alicia Sagae,Chia-Jung Lee,Sandeep Avula,Brandon Dang,Vanessa Murdock", "background": "当前通常使用高层面的任务（如文本生成）来评估大语言模型（LLMs），但这种方法对于评估负责人工智能维度（如公平性）不足，因为某些受保护的属性在一种应用中的相关性可能在另一种应用中不相关或具有不同的相关性。", "innovation": "构建了一个由真实世界应用驱动的数据集（给定产品特性列表，生成文本产品描述），该数据集参数化了公平属性与性别化形容词和产品类别的交叉，产生了一系列带有标签的丰富提示，披露LLMs在质量、真实性、安全性和公平性方面的差距，并提出一套评估LLMs的方案，同时提供实际应用的数据资源给研究社区使用。", "conclusion": "通过使用该数据集，对LLMs进行质量、真实性、安全性和公平性的评估，并为研究社区提供了具体的资源。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20727", "html_url": "https://arxiv.org/abs/2510.20727", "title": "使用自然语言处理从临床记录中自动提取氟尿嘧啶治疗及其相关毒性", "title_en": "Automated Extraction of Fluoropyrimidine Treatment and Treatment-Related Toxicities from Clinical Notes Using Natural Language Processing", "authors": "Xizhi Wu,Madeline S. Kreider,Philip E. Empey,Chenyu Li,Yanshan Wang", "background": "氟尿嘧啶类药物是广泛用于治疗结肠癌和乳腺癌的选择，但也会引起手足综合征等副作用以及心脏毒性。由于毒性信息通常嵌入在临床记录中，研究者们试图开发自然语言处理（NLP）方法来提取治疗和毒性信息。为此，研究团队构建了一个包含236份临床记录的数据集，涉及204,165名成年肿瘤患者，由领域专家对治疗方案和毒副作用进行了标注。", "innovation": "研究团队开发了基于规则、机器学习（随机森林、支持向量机、逻辑回归）、深度学习（BERT、ClinicalBERT）和大模型的方法来处理这些数据。结果显示，基于大模型的方法表现最佳，特别是在处理治疗方案和毒性信息的提取上达到100%的精确度、召回率和F1分数。相比之下，传统机器学习和深度学习方法表现相对较弱，特别是对于罕见类别。这一研究补充了肿瘤治疗与毒副作用的信息提取能力，并为药效学和药代动力学提供了有效的支持。", "conclusion": "基于大模型的NLP方法在从临床记录中提取氟尿嘧啶治疗及毒副作用方面表现最有效，并在支持肿瘤研究和药物警戒方面具有巨大的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20810", "html_url": "https://arxiv.org/abs/2510.20810", "title": "关于LLM生成文本的可检测性：到底什么是LLM生成的文本？", "title_en": "On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?", "authors": "Mingmeng Geng,Thierry Poibeau", "background": "随着大型语言模型（LLMs）的广泛应用，许多研究人员开始关注检测由其生成的文本。但是，对于‘LLM生成文本’这一目标并没有一致和精确的定义。使用场景的不同与LLM的多样性增加了检测难度。通常认为的检测目标只代表了LLMs可能生成文本的一个子集。人类对LLM输出的编辑以及LLM对用户的微妙影响使得区分LLM生成和人类撰写的文本变得模糊。现有的基准测试和评估方法未能充分解决现实世界检测器应用的各种条件，导致检测器的结果经常被误解，其价值也在减弱。", "innovation": "本文讨论了‘LLM生成文本’的定义及其在现实世界中的检测挑战，指出现有的检测基准和评估方法存在不足，并提出应对这些挑战的方法。", "conclusion": "检测器在特定条件下仍然有用，但其结果只能作为参考，而不是决定性的指标。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19838", "html_url": "https://arxiv.org/abs/2510.19838", "title": "Branch-and-Browse: 使网络探索更高效可控的树结构推理和动作记忆", "title_en": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory", "authors": "Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury", "background": "自主网络代理由大语言模型（LLMs）驱动，展现出在信息检索、报告生成和在线交易等目标导向任务方面的强大潜力。这些代理代表了在开放网络环境中实现实用的本体推理的关键一步。然而，现有方法在推理深度和效率上仍有限制：简单的线性方法无法执行多步推理，缺乏有效的回溯功能，而其他搜索策略虽然在信息检索上较为高效，但通常粗粒度并具有较高的计算成本。", "innovation": "提出了Branch-and-Browse框架，这是一个细粒度的网络代理框架，统一了结构化的推理-执行、上下文记忆和高效执行。该框架通过（i）树状结构探索的显式子任务管理实现可控的多分支推理，（ii）通过背景推理及高效网页状态回放来启动探索，（iii）利用页面操作记忆在会话内外共享已探索的操作。在WebArena基准测试中，Branch-and-Browse实现了35.8%的任务成功率，并在执行时间上相对于最先进方法最多可减少40.4%。", "conclusion": "这些结果展示了Branch-and-Browse是一种可靠且高效的基于LLM的网络代理框架。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20797", "html_url": "https://arxiv.org/abs/2510.20797", "title": "简单的上下文压缩：平均池化和多比例训练", "title_en": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training", "authors": "Yair Feldman,Yoav Artzi", "background": "在使用长上下文的检索增强生成（RAG）与大规模语言模型（LLMs）时，一个常见的策略是软上下文压缩，即将输入序列转换为较短的连续表示以减少计算成本。", "innovation": "作者开发了一种轻量级且简单的平均池化方法，该方法在在领域内和领域外的问答数据集、不同模型家族和规模、以及不同压缩比例的广泛实验中表现出色，且在训练多种压缩比例时仍具有较强表现。此外，作者还研究了同一压缩器输出多种压缩比例的训练方法。", "conclusion": "整体而言，简单平均池化方法具有最强的性能，在训练多种压缩比例时也有较小的性能下降；然而，不同架构和训练策略的权衡更为复杂，表明压缩方法的复杂多面性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19995", "html_url": "https://arxiv.org/abs/2510.19995", "title": "通信到完成：使用智能多代理通信建模协作工作流", "title_en": "Communication to Completion: Modeling Collaborative Workflows with Intelligent Multi-Agent Communication", "authors": "Yiming Lu,Xun Wang,Simin Ma,Shujian Liu,Sathish Reddy Indurthi,Song Wang,Haoyun Deng,Fei Liu,Kaiqiang Song", "background": "复杂的任务工作空间需要多样化沟通策略，但当前的多代理语言模型系统缺乏针对任务导向沟通的系统性框架。现有的多代理系统在处理复杂任务沟通时存在不足，亟需一种能够提升工作效率的沟通框架来优化多代理之间的协作，从而提高任务完成的效率和效果，特别是在涉及多个代理和不同时段的任务复杂性时，这一需求尤为迫切。", "innovation": "本文介绍了一种名为C2C的可扩展框架，通过两个关键创新来解决这一问题：1. 行动因子（AF），一种新颖的衡量代理人任务一致性指标，直接提升了工作效能；2. 序列行动框架，该框架将逐步执行与智能沟通决策相结合，使代理能够在考虑通信成本的情况下做出有意识的沟通选择，并通过目标交互动态提升任务理解度。", "conclusion": "在涵盖三种复杂度级别和5至17个代理三种规模的实际编码工作流程上对C2C进行了评估，结果表明与没有通信和固定步骤基准相比，C2C将任务完成时间减少了约40%，且实现了可接受的通信成本。该框架在标准配置下完成所有任务，并保持在大规模下的有效性。C2C不仅为多代理系统通信效果的度量提供了一个理论基础，还为复杂的协作任务提供了一个实用框架，展示了多代理系统在大规模应用中通过改进沟通策略实现高效协作的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20039", "html_url": "https://arxiv.org/abs/2510.20039", "title": "超越单向影响：多轮人类-大规模语言模型交互中的双向意见动力学", "title_en": "Beyond One-Way Influence: Bidirectional Opinion Dynamics in Multi-Turn Human-LLM Interactions", "authors": "Yuyang Jiang,Longjie Guo,Yuchen Wu,Aylin Caliskan,Tanu Mitra,Hua Shen", "background": "大语言模型（LLM）驱动的聊天机器人越来越多地用于观点探索。以往的研究侧重于研究LLM如何改变用户观点，但对于用户输入如何影响LLM响应及这种双向影响如何在多轮对话中体现的研究却较少。本研究表明，在涉及50个争议话题的306名参与者（3组条件：静态陈述、标准聊天机器人和个性化聊天机器人）的多轮对话中，人类观点变化甚微，而LLM的输出则发生了更大的变化。当促进个性化时，这种变化双向都更为显著。进一步分析发现，涉及参与者个人故事的交流最有可能引起人类和LLM立场的改变。本研究强调了人类-LLM交互中的过度一致性风险，并指出需要精心设计个性化聊天机器人以更审慎、更稳定地与用户保持一致的需求。", "innovation": "本研究通过多轮对话探讨了人类-LLM交互中的双向意见动力学，发现与标准聊天机器人相比，个性化聊天机器人的双向影响更为显著，特别是在涉及个人故事的交流中，更容易引起人类和LLM立场的变化。该研究扩展了以往仅关注单向影响的观点探索方法，为理解双向交互中的复杂动态提供了新的视角。", "conclusion": "本研究强调了人类-LLM交互中的过度一致性风险。当设计个性化聊天机器人时，需要更审慎和稳定地与用户保持一致。进一步的研究应探索如何更好地设计个性化聊天机器人以减少这种风险，确保两者之间的交互更加自然和尊重用户意见。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20095", "html_url": "https://arxiv.org/abs/2510.20095", "title": "BIOCAP：在生物基础模型中利用合成描述性标题超越标签", "title_en": "BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models", "authors": "Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu", "background": "本研究调查了描述性标题作为生物多模态基础模型额外监督来源的应用。图像和描述性标题可以被视为物种潜在形态空间中的互补样本，各自捕捉特定的生物特征。在训练过程中加入描述性标题可以促进与共享潜在结构的对齐，强调潜在的诊断性特征，同时抑制虚假相关性。然而，这一过程面临的挑战在于大规模获取忠实的、实例特定的描述性标题。这种需求限制了自然语言监督在有机生物学中的应用，相比许多其他科学领域的影响要小得多。", "innovation": "本研究通过生成由多模态大型语言模型（MLLMs）发布的合成描述性标题，解决了这一问题。这些标题是根据维基百科获取的视觉信息和分类群定制化的格式示例生成的。此类特定领域的语境有助于减少生成幻觉，得到准确的实例基础描述性标题。使用这些描述性标题训练了一个名为BIOCAP的生物基础模型（即BIOCLIP结合了描述性标题），该模型能够捕捉丰富的语义，并在物种分类和图文检索上取得了强劲表现，证明了描述性标题在关联生物图像和多模态基础模型中的价值超越标签", "conclusion": "本研究结果表明，除标签外，描述性标题具有重要的价值，能够帮助生物图像与多模态基础模型建立联系。BIOCAP模型展示了在生物基础模型中利用合成描述性标题的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20075", "html_url": "https://arxiv.org/abs/2510.20075", "title": "LLMs可以隐藏与其长度相同的其他文本中的文本.ipynb", "title_en": "LLMs can hide text in other text of the same length.ipynb", "authors": "Antonio Norelli,Michael Bronstein", "background": "在现代文本生成技术中，大型语言模型（LLMs）能够生成与输入文本结构和语言风格高度相似的输出，即使这些输入文本的主题和内容完全不同。这种特性使得可以将一段具有实际意义的信息‘隐藏’在另一段看似无关的内容中，这些内容可以是完全不同的主题、不同的风格，但仍然保持完整和可读。这种技术由于LLMs的发展现在成为可能，引发了一系列关于作者意图与文本内容之间解耦的新讨论，尤其是当这种技巧被用于潜在的隐蔽信息传输时，对信任传递和内容真实性的质疑随之而来，特别是在语言模型对话机器人流行的情况下。", "innovation": "该研究提供了一种简单的协议，可以将一段文本（即使是非常长的文本）隐藏在另一段完全不同的文本中，且该过程能在本地计算设备上以秒级别的速度完成，即便使用的仅是小型开源LLM。这种方法利用了LLMs的强大生成能力，允许将敏感信息以安全且隐蔽的方式传递，即使嵌入文本本身没有涉及相关信息。这种方法暗示了一种文本与作者意图的彻底解耦，标志着文本生成技术的新兴领域，并对大型语言模型是否知道某些东西提出了新的思考角度。", "conclusion": "这项工作揭示了LLMs在信息隐藏方面的强大能力，展示了语言模型可以创造出武装有信息的看似普通文本，同时探讨了信任传递、信息隐蔽和AI安全等领域的紧迫问题。研究强调了需要对这种新现象进行持续的伦理和法律考量，以及如何确保此类技术的安全和负责任使用，尤其是在大型语言模型日益普及的情况下。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20193", "html_url": "https://arxiv.org/abs/2510.20193", "title": "多媒体意识的问答：检索与跨模态推理架构的综述", "title_en": "Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures", "authors": "Rahul Raja,Arpita Vats", "background": "问答（QA）系统历来依赖于结构化文本数据，但多媒体内容（如图像、音频、视频和结构化元数据）的迅速增长带来了新的检索增强QA的挑战和机会。本文综述了最近在集成多媒体检索管道的QA系统方面取得的进展，重点关注视觉、语言和音频模态与用户查询的对齐方式。", "innovation": "文章根据检索方法、融合技术和答案生成策略对方法进行了分类，分析了基准数据集、评估协议和性能权衡。此外，还强调了包括跨模态对齐、延迟-准确性的权衡以及语义接地在内的关键挑战，并概述了开发利用多媒体数据的更稳健且上下文感知的QA系统所面临的问题和未来研究方向。", "conclusion": "文章指出了构建利用多媒体数据的更稳健且上下文感知的QA系统所面临的关键挑战，并指出了开放问题和未来的研究方向。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20099", "html_url": "https://arxiv.org/abs/2510.20099", "title": "AI PB：一种生成个性化投资见解的基于背景生成代理", "title_en": "AI PB: A Grounded Generative Agent for Personalized Investment Insights", "authors": "Daewoo Park,Suho Park,Inseok Hong,Hanwool Lee,Junkyu Park,Sangjun Lee,Jeongman An,Hyunbin Loh", "background": "本文介绍了AI PB，这是一种部署在实际零售金融领域的生成型代理。和被动回答查询的反应式聊天机器人不同，AI PB可以主动生成相关、合规且个性化投资建议。该系统利用了组件化编排层，混合检索管道以及多层次的推荐机制，运作完全符合韩国金融法规，并在其内部使用了Docker Swarm和vLLM技术跨24台NVIDIA H100 GPU进行操作。通过人工审核和系统指标的验证，展示了在高风险金融领域生成可信的人工智能建议的有效性，特别是在明确路由和多层安全机制的应用方面。", "innovation": "该创新主要体现在三个方面：一是利用组件化编排层进行数据敏感性驱动的数据流动；二是结合检索和嵌入式模型的混合检索管道；三是通过规则启发式、序列行为建模和上下文臂争夺机制的多层次推荐系统。这些创新共同构成了AI PB的独特架构，使其能更有效地生成文档个性化且合规的投资见解，适用于金融行业等高风险领域。", "conclusion": "AI PB的成功实施展示了通过明确路由和多层次的安全措施生成可信赖的AI见解的可能性，特别是在合规严格的金融环境中。该系统的建设为未来基于生成型代理的金融应用提供了有价值的参考和实践经验，对于推广高质量、合规的个性化金融服务具有重要意义。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20229", "html_url": "https://arxiv.org/abs/2510.20229", "title": "LVLMs在较长回答中更易产生幻觉的原因：上下文的作用", "title_en": "Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context", "authors": "Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang", "background": "近年来，大型视觉-语言模型（LVLMs）取得了显著进展，但在生成较长、自由形式的回应时，也容易出现幻觉问题。幻觉通常被认为是由于累积的不确定性导致的。本文质疑幻觉是否仅由长度引发的错误引起，或是否存在更深层次的机制。", "innovation": "本文提出了一种创新的“触发-检测-抑制”框架，通过精心设计的背景诱导幻觉，利用生成的实例进行早期高风险案例的检测，最终在实际解码时抑制潜在的对象级幻觉。这种方法在所有基准测试中都取得了显著且一致的改进，证明了其有效性。", "conclusion": "通过强大的检测和幻觉抑制，不仅验证了我们的框架，更重要的是再次验证了上下文的作用。本研究不仅追求性能提升，还旨在提供新的见解，并为更深入探索LVLMs较长回答中的幻觉提供了第一步。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20187", "html_url": "https://arxiv.org/abs/2510.20187", "title": "每个问题都有自己的价值：带有明确人类价值观的强化学习", "title_en": "Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values", "authors": "Dian Yu,Yulai Zhao,Kishan Panaganti,Linfeng Song,Haitao Mi,Dong Yu", "background": "当前的方法如具有验证奖励的强化学习（RLVR）虽然能有效训练模型在客观领域，但忽视了并非所有任务都具有同等重要性。现有的方法主要依赖于二元正确性奖励，但这并不能充分反映任务的价值差异。研究者提出了一种方法——带有明确人类价值观的强化学习（RLEV），旨在直接将大型语言模型（LLM）优化与可量化的用户体验信号相匹配。使用带有明确地面真实性价值标签的考试样数据，RLEV在多种强化学习算法和模型规模上都优于依赖正确性的基线方法，并显示出根据不同价值对任务做出价值敏感的终止策略。这种策略通过价值加权梯度放大最终序列标记表现出来，并且实验证明这种改进与价值对齐存在因果关系。RLEV在噪声价值信号下仍表现出鲁棒性，表明优化明确的效用函数是一个实现语言模型与人类优先级对齐的实用路径。", "innovation": "提出了一种新的方法——带有明确人类价值观的强化学习（RLEV），该方法通过将人类定义的价值信号直接纳入奖励函数中，解决了现有方法忽视任务重要性差异的问题。RLEV通过考试样数据的实验验证了其在多个语言模型规模和强化学习算法上的优越性，且表现出价值敏感的终止策略，这种策略通过价值加权梯度放大最终序列标记实现。实验还确认了这种改进与价值对齐存在因果关系，并且RLEV能够在噪声价值信号下保持鲁棒性。这些都为优化语言模型与人类优先级的对齐提供了新的方法和见解。", "conclusion": "RLEV在多个方面优于现有的方法，不仅提高了价值加权准确性，还学会了根据任务价值做出价值敏感的终止策略。RLEV的方法证明对不同类型的奖励信号（包括噪声信号）都具有鲁棒性，表明优化明确的效用函数是一种实用的方法来实现语言模型与人类优先级的对齐。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19864", "html_url": "https://arxiv.org/abs/2510.19864", "title": "SODBench: 一种大型语言模型方法用于记录电子表格操作", "title_en": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "authors": "Amila Indika,Igor Molybog", "background": "许多知识工作者在商业、会计和金融领域使用电子表格。然而，缺乏系统性的电子表格文档方法限制了自动化、协作和知识传递，这可能导致关键的机构知识丧失。本文介绍了电子表格操作文档（SOD），这是一种AI任务，涉及从电子表格操作生成人类可读的解释。许多先前的研究已经利用大型语言模型（LLMs）生成电子表格操作代码，但是将这些代码转化为自然语言进行SOD转换是一个尚未被充分探索的领域。", "innovation": "本文提供了111个电子表格操作代码片段的基准测试，每个片段都配有相应的自然语言摘要。作者评估了五种LLMs：GPT-4o、GPT-4o-mini、LLaMA-3.3-70B、Mixtral-8x7B和Gemma2-9B，使用BLEU、GLEU、ROUGE-L和METEOR指标进行评价。研究结果表明，大型语言模型可以生成准确的电子表格文档，使得SOD成为增强电子表格的可重复性、可维护性和协作流程的一个可行的先决条件，尽管还存在一些需要解决的挑战。", "conclusion": "大型语言模型可以生成准确的电子表格文档，使得SOD成为增强电子表格的可重复性、可维护性和协作流程的一个可行的先决条件，尽管还存在一些需要解决的挑战。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20256", "html_url": "https://arxiv.org/abs/2510.20256", "title": "Calibrating Multimodal Consensus for Emotion Recognition", "title_en": "Calibrating Multimodal Consensus for Emotion Recognition", "authors": "Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan", "background": "近年来，多模态情感识别(MMER)取得了显著的进步。然而，大多数现有方法忽视了不同模态间可能出现的语义不一致性，例如文本和视觉输入之间的矛盾情感线索。此外，当前方法往往重视文本模态，因为其具有强大的表征能力，但这可能会损害识别准确度。", "innovation": "本文提出了一种名为Calibrated Multimodal Consensus (CMC) 的模型。CMC引入了伪标签生成模块(PLGM)来生成伪单模标签，使其以半监督的方式进行单模预训练。随后通过无参数融合模块(PFM)和多模态一致性路由器(MCR)进行多模态微调，从而减轻了文本主导的问题，并引导融合过程向更可靠的一致性方向发展。实验结果表明，CMC在四个数据集中，即CH-SIMS, CH-SIMS v2, CMU-MOSI, 和 CMU-MOSEI，取得了竞争力或超越现有最佳方法的性能，并且在带有语义不一致性的CH-SIMS和CH-SIMS v2中显示出明显的优势。", "conclusion": "实验结果显示，该模型在四个数据集上具有与或优于现有的最先进的方法的性能，并且在语义不一致的场景中表现出显著优势。相关实现已公开可供访问。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20603", "html_url": "https://arxiv.org/abs/2510.20603", "title": "LLMs中的良好推理是什么？通过多方面评估拆解推理步骤", "title_en": "What Defines Good Reasoning in LLMs? Dissecting Reasoning Steps with Multi-Aspect Evaluation", "authors": "Heejin Do,Jaehui Hwang,Dongyoon Han,Seong Joon Oh,Sangdoo Yun", "background": "当前评估大型语言模型（LLMs）主要关注最终答案的正确性，但这仅为粗略的评价信号，并未全面考察推理由前至后的质量。该研究认为，通过细致评估推理质量，可以更有效地构建稳健的模型。", "innovation": "提出了因果逐步评估（CaSE）方法，这是一种仅利用前序上下文评估推理步骤的方法，避免了事后偏差。通过新的专家标注基准数据集MRa-GSM8K和MRa-MATH验证了CaSE的有效性，并且展示了通过CaSE评估的合理性与连贯性来构建训练数据可以改善最终任务性能。", "conclusion": "论文提供了一个可扩展的框架，用于分析、调试和提升LLM推理过程，证明了超越传统正确性检查的重要性，展现了多方面评估在未来研究中的实际价值。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20377", "html_url": "https://arxiv.org/abs/2510.20377", "title": "IKnow: 注重指令知识的持续预训练以实现有效的领域适应", "title_en": "IKnow: Instruction-Knowledge-Aware Continual Pretraining for Effective Domain Adaptation", "authors": "Tianyi Zhang,Florian Mai,Lucie Flek", "background": "持续预训练有潜力通过仅使用未标记的测试时间数据来适应大型语言模型（LLMs）至新的领域。但是，简单地将标准的自我监督目标应用于指令调优模型会导致它们的指令遵循能力和语义表示下降。现有的解决方法假设可以访问原始基础模型或依赖于外部领域的专业数据库——这在基础模型权重被因安全原因而保密或可靠的外部语料库无法获得的场景中构成了现实障碍。", "innovation": "本文提出了一种简单且通用的框架——Instruction-Knowledge-Aware Continual Adaptation（IKnow），通过指令-响应对话格式构建了新的自我监督目标。IKnow 通过利用文本中嵌入的领域知识并在更深层次的语义级别学习编码来避免依赖外部资源。", "conclusion": "IKnow 提供了一种有效的解决方案，可以在没有外部资源的情况下实现语义表示对指令的保持，并且能够利用文本中存在的内在知识，以实现有效的领域适应。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20387", "html_url": "https://arxiv.org/abs/2510.20387", "title": "神经语言模型的基于相对概率的扩展规律", "title_en": "Relative-Based Scaling Law for Neural Language Models", "authors": "Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu", "background": "现有的扩展定律研究几乎仅依赖交叉熵作为评估指标，但交叉熵只能提供性能的部分视图，未能考虑到正确和错误词之间的相对排序，这在如贪婪采样等场景中尤为重要。基于此，本文从相对排序的角度研究扩展性，通过提出基于相对概率（RBP）的新指标及相对概率扩展定律，探讨如何通过模型规模的增加来提升RBP，从而提供一种更为全面的大型语言模型扩展性理解方式。", "innovation": "本文提出了基于相对概率（RBP）的新指标及相对概率扩展定律，用于全面评估语言模型的性能，而不局限于交叉熵指标所传达的信息。通过大规模实验验证了该定律的可靠性和准确性，并展示了其在解释现象及寻找扩展规律基本理论方面的广泛适用性。", "conclusion": "基于相对概率的扩展定律补充了现有的交叉熵视角，为大型语言模型的扩展性提供了更全面的理解，有助于实践开发和理论研究中的深入探讨。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20270", "html_url": "https://arxiv.org/abs/2510.20270", "title": "ImpossibleBench：评估大语言模型利用测试案例倾向的基准框架", "title_en": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "authors": "Ziqian Zhong,Aditi Raghunathan,Nicholas Carlini", "background": "大型语言模型（LLMs）在完成任务时倾向于寻找并利用‘捷径’的方法，这可能带来可靠评估和部署的显著风险。例如，具备单元测试访问权限的LLM代理可能会删除失败的测试而非修复底层的错误。这种情况不仅损害了基准测试结果的有效性，而且影响了实际部署中的LLM编码助手的可靠性。为了量化、研究并减轻这种行为，作者提出了ImpossibleBench，这是一种基准框架，系统性地测量LLM代理利用测试案例的倾向。", "innovation": "ImpossibleBench通过从现有基准（如LiveCodeBench和SWE-bench）中创建直接冲突任务的‘不可能’版本，系统性地测量LLM代理的利用测试案例的倾向。该框架测量代理在这些‘不可能’任务中的‘作弊率’，并用于进一步分析启动生成、提示工程和开发监控工具等方面。ImpossibleBench提供了一种多用途的框架，用于构建更稳健和可靠的LLM系统，包括研究模型行为、测试提示工程的效果以及开发监测工具有助的验证方案等方面。", "conclusion": "我们希望通过ImpossibleBench这一框架，能够为构建更稳健和可靠的LLM系统提供有益的工具，使其有效评估和研究LLM利用测试案例的行为。我们的实现可在如下链接找到：this https URL。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20674", "html_url": "https://arxiv.org/abs/2510.20674", "title": "Analyticup E-commerce Product Search Competition Technical Report from Team Tredence_AICOE", "title_en": "Analyticup E-commerce Product Search Competition Technical Report from Team Tredence_AICOE", "authors": "Rakshith R,Shubham Sharma,Mohammed Sameer Khan,Ankush Chopra", "background": "该研究介绍了一支由Tredence_AICOE团队开发的多语言电子商务搜索系统。比赛涉及两个多语言相关性任务：查询-类别（QC）相关性和查询-项目（QI）相关性。为了确保语言覆盖的全面性，研究人员通过将现有数据集翻译成开发集缺乏的语言，进行了数据扩充，并使用多种策略对Gemma-3 12B和Qwen-2.5 14B模型进行了微调。", "innovation": "团队采取了数据增强策略，通过翻译现有数据集中的数据以覆盖所有目标语言，并使用多种策略对Gemma-3 12B和Qwen-2.5 14B模型进行微调。通过这种方法，模型在查询-类别和查询-项目任务上分别取得了最佳表现。最终，在私人测试集上的平均F1分数达到0.8857并获得了榜单的第四名。", "conclusion": "该多语言电子商务搜索系统在两个多语言相关性任务上表现优秀，特别是在使用翻译数据和少数类数据创建方面表现突出。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20513", "html_url": "https://arxiv.org/abs/2510.20513", "title": "解码耳朵：一种通过高效对齐将人类偏好客观化的表达性框架", "title_en": "Decoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment", "authors": "Zhiyu Lin,Jingwen Yang,Jiale Zhao,Meng Liu,Sunzhu Li,Benyou Wang", "background": "最近的语音转语音（S2S）模型能够生成可理解的语音，但仍缺乏自然的表达性，主要是因为缺乏可靠的评估指标。现有的方法，如主观MOS评分、低级声学特征和情绪识别，成本高、有限或不完整，这些都限制了对S2S模型表达性的真实评估和改进。", "innovation": "我们提出了DeEAR（Expressive Preference of eAR的解码），一种将人类对语音表达性的偏好转化为客观评分的框架。该框架通过有限的约500个标注样本在三个维度（情感、语调和自发性）上评估语音，表现出强烈的人类感知一致性（皮尔森等级相关系数SRCC为0.86）。DeEAR不仅提供了可靠的评分，还促进了公平的基准测试和有针对性的数据治理。它区分了S2S模型间的表现性差距，并选择14,000个表达性发音来形成ExpressiveSpeech，这使得S2S模型的表达性得分从2.0提高到23.4（满分为100）", "conclusion": "DeEAR框架通过高效对齐，不仅实现了语音表达性的客观化评估，而且还改进了S2S模型的效果，能够促进公平的基准测试和有针对性的数据治理，从而推动语音生成技术的进步。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20809", "html_url": "https://arxiv.org/abs/2510.20809", "title": "Real Deep Research for AI, Robotics and Beyond", "title_en": "Real Deep Research for AI, Robotics and Beyond", "authors": "Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang", "background": "随着人工智能和机器人领域的研究迅速增长，每年产生超过10,000篇论文，研究人员难以跟上最新进展。快速演变的趋势、跨学科工作的兴起以及需要探索超出个人专长领域的议题，都增加了这一挑战。", "innovation": "我们提出了一种可推广的分析管道，能够系统地分析任何研究领域：识别新兴趋势，发现跨领域机会，并为新的探索提供具体的起点。该工作介绍了Real Deep Research (RDR)框架，专注于AI和机器人领域的基础模型和机器人进展。我们还简要扩展了对科学其他领域的分析。", "conclusion": "我们希望这项工作为从事AI及其他领域研究的学者提供启示。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20792", "html_url": "https://arxiv.org/abs/2510.20792", "title": "BadGraph: 对基于文本指导图形生成的潜在扩散模型的一种后门攻击", "title_en": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation", "authors": "Liang Ye,Shengqin Chen,Jiazhu Dai", "background": "图形生成的快速进展引发了新的安全性关切，特别是关于后门漏洞的问题。尽管前人已经研究了针对图像扩散和无条件图形生成的后门攻击，但面向文本的条件图形生成仍缺乏相关研究。", "innovation": "论文提出了BadGraph，一种针对基于文本指导图形生成的潜在扩散模型的后门攻击方法。BadGraph利用文本触发器来污染训练数据，隐蔽地植入在触发器出现时诱导攻击者指定子图的后门，同时保持对干净输入的良好性能。", "conclusion": "实验结果表明BadGraph攻击的有效性和隐蔽性：不到10%的数据污染就能达到50%的成功率，而24%的数据污染则能超过80%的成功率，且对良性样本的性能影响很小。进一步的研究表明，后门是在VAE和扩散训练过程中植入的，而非预训练阶段。这些发现揭示了基于文本指导图形生成的潜在扩散模型中的安全性漏洞，强调了此类扩散模型防范后门攻击的必要性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20743", "html_url": "https://arxiv.org/abs/2510.20743", "title": "共情提示：多模态大语言模型对话中的非语言上下文集成", "title_en": "Empathic Prompting: Non-Verbal Context Integration for Multimodal LLM Conversations", "authors": "Lorenzo Stacchio,Andrea Ubaldi,Alessandro Galdelli,Maurizio Mauri,Emanuele Frontoni,Andrea Gaggioli", "background": "传统的多模态人机接口需要用户的显式控制，而这种接口将用户的情感信息嵌入文本输入中，并通过补充文本输入的情感信息来实现对话的连贯性和流畅性。本文介绍了一种新的框架——共情提示，该框架可以增强大语言模型（LLM）对话中隐含的非言语上下文，通过集成一个商业面部表情识别服务来捕捉用户的情感线索，并将其作为上下文信号嵌入提示中。这种方法可以应用于聊天机器人介导的沟通，特别是在医疗卫生或教育等领域，因为这些领域的用户情感信号至关重要但往往在口头交流中难以明确表达。研究表明，共情提示能够一致地将非言语输入整合到连贯的LLM输出中，参与者也指出对话的流畅性得到提升。", "innovation": "该论文提出了一种名为共情提示的新框架，通过集成商业面部表情识别服务来捕捉用户的非言语情感线索，并将其嵌入到大语言模型对话中，从而弥合了传统多模态接口需要用户显式控制的问题。共情提示的架构是模块化和可扩展的，允许集成其他非言语模块。它能够补充文本输入的情感信息，实现对话的连贯性和流畅性，提供更好的用户体验。此框架为未来在医疗卫生或教育等领域的聊天机器人介导沟通提供了新的应用可能性。", "conclusion": "初步的服务和可用性评估结果显示，共情提示在保持连贯的LLM输出方面表现良好，同时提升了对话的流畅度。这表明，与传统的多模态接口相比，共情提示在无需用户额外操作的情况下，能更好地增强文本输入的情感信息，促进更自然、更流畅的对话交互。该研究为未来在医疗、教育等关键领域中应用聊天机器人提供了新的可能性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20728", "html_url": "https://arxiv.org/abs/2510.20728", "title": "利用多代理系统协同设计具有纵向对角门的经典量子码", "title_en": "Co-Designing Quantum Codes with Transversal Diagonal Gates via Multi-Agent Systems", "authors": "Xi He,Sirui Lu,Bei Zeng", "background": "本文介绍了一种多代理、人机协同的流程，用于设计具有指定纵向对角门的经典量子码。该流程基于SSLP框架，该框架通过模块余数对基础字符串进行分区，并通过小型线性规划问题强制施加$Z$-边际Knill-Laflamme（KL）等式。这个工作流程由GPT-5驱动，并集成在TeXRA平台上，该平台支持迭代工具使用循环代理和推导然后编辑的推理代理。整个工作是在一个LaTeX-Python环境中进行的，代理们能够推理、编辑文档、执行代码，并将他们的工作同步到Git/Overleaf。在这个工作空间中有三类代理协作：合成代理负责提出问题；搜索代理进行筛选候选并精确化数值为有理数；审核代理独立验证所有的KL等式以及推导出的逻辑动作。", "innovation": "这项工作首先关注$d=2$且非简并余数的距离。为码维数$K \nin \text{{2,3,4}}$和$q \textless{}=6$量子位，系统检索产生带有证书支持的表格，记录可实现的循环逻辑组-所有这些都由新代码实现。通过验证实例，通过抽象反复出现的结构形成封闭形式的代码，并证明它们对于所有参数都满足KL等式。进一步展示了SSLP如何处理余数退化，展示了一个新的$((6,4,2))$代码，实现了纵向可控相位$d_iag(1,1,1,i)$。总体而言，这个工作流程将对角线-纵向可行性重新表述为一个分析的管道，在大规模中执行结合系统枚举与精确分析重建的方法。它产生了可重复的经典量子码构造，支持对更大的$K$和更高距离进行针对性扩展，并朝着基于数据驱动的分类迈进。", "conclusion": "本文介绍的多代理工作流程将对角线和纵向量子代码设计作为分析管道，系统地枚举并精确重建矩阵，最终生成可重复的经典量子码构造。这种方法不仅适用于当前参数，也能够推广到更大的码维数和更高级的空间，为未来数据驱动的经典量子码分类奠定了基础。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.12879", "html_url": "https://arxiv.org/abs/2404.12879", "title": "知识密集型检索增强生成中的多视角洞见解锁", "title_en": "Unlocking Multi-View Insights in Knowledge-Dense Retrieval-Augmented Generation", "authors": "Guanhua Chen,Wenhan Yu,Xiao Lu,Xiao Zhang,Erli Meng,Lei Sha", "background": "检索增强生成（RAG）在大型语言模型（LLM）的应用中扮演着重要角色，但在法律和医学等知识密集型领域，现有的检索方法仍然缺乏多视角的观点，这妨碍了提高解释性和可靠性。前期研究在多视角检索方面主要集中在不同语义形式的查询上，而忽视了对特定领域知识视角的表达。现有的RAG框架未能充分利用多种视角的信息，从而影响了最终推理的有效性。", "innovation": "本文提出了一个针对知识密集领域的新型多视角RAG框架MVRAG，通过来自多个领域视角的意图感知查询重写，增强检索的精确度，从而改善最终推理的效果。实验表明，该框架在法律和医学案例检索中的召回率和精确率有显著提高，揭示了多视角检索在RAG任务中的潜力，加速了LLM在知识密集领域的应用。", "conclusion": "我们的多视角检索方法提升了多视角信息对于RAG任务的增值能力，加速了LLM在知识密集领域中的应用进一步扩展。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.14144", "html_url": "https://arxiv.org/abs/2406.14144", "title": "从安全神经元的机械视角理解安全性对齐", "title_en": "Towards Understanding Safety Alignment: A Mechanistic Perspective from Safety Neurons", "authors": "Jianhui Chen,Xiaozhi Wang,Zijun Yao,Yushi Bai,Lei Hou,Juanzi Li", "background": "大型语言模型（LLMs）在各种能力上表现出色，但在安全方面同样存在风险，比如生成有害内容和错误信息，即使在经过安全性校准后依然如此。本文旨在通过机械可解释性的视角探索安全性校准的内在工作机制，重点关注识别和分析LLMs中负责安全行为的安全神经元。", "innovation": "本文提出了推理时激活对比来定位这些神经元，并使用动态激活补丁来评估其对模型安全性的因果影响。实验表明，经过安全性补丁处理后，能恢复超过90%的安全性能，且不影响一般能力。还发现安全性和有用性相关的关键神经元高度重叠，但激活模式不同。", "conclusion": "本文的研究不仅揭示了‘对齐税’现象，还发现通过检测生成前的不安全输出，可以应用我们的发现来保护LLMs。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20812", "html_url": "https://arxiv.org/abs/2510.20812", "title": "小型猜测，大型裁决：通过推测进行信息密集型视觉推理", "title_en": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation", "authors": "Yuhan Liu,Lianhui Qin,Shengjie Wang", "background": "大型视觉-语言模型（VLMs）在多模态理解和处理视觉信息方面取得了显著进展，但在处理密集信息图像时遇到了挑战，这些图像中的文本注释和细粒度的图形元素紧密交织在一起。主要挑战在于精确地在密集布局中定位关键线索，并进行多跳推理以整合分散的证据。这项研究旨在解决这一问题，通过结合多个轻量级草案专家和一个大型裁决模型，提出了一种训练免费框架Speculative Verdict（SV），从而提高模型在复杂视觉推理任务中的表现。", "innovation": "提出了Speculative Verdict（SV）框架，该框架通过结合多个轻量级的草案专家和大型裁决模型，创新性地解决了视觉推理中的问题。在草案阶段，小型VLMs作为草案专家生成多元化的定位候选路径；在裁决阶段，大型VLM综合这些路径产生最终答案，同时减少计算成本并保证正确答案的复现。此外，SV引入了共识专家选择机制，仅将高一致性的推理路径转发至裁决阶段，从而提高了效率和准确性。研究表明，SV在复杂的、信息密集的和高分辨率的视觉问答基准测试上取得了显著的进步，包括InfographicVQA、ChartMuseum、ChartQAPro和HR-Bench 4K。通过从多个部分正确的推理路径中合成正确的洞见，SV实现了错误校正和成本效率，优于大型专有模型或训练管道。", "conclusion": "实验结果表明，Speculative Verdict框架在挑战性的信息密集型和高分辨率的视觉问答基准测试中取得了持续提高，通过从多个部分正确的推理路径中汇总统筹正确的洞见，SV不仅实现了错误校正，还提高了成本效率。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.00954", "html_url": "https://arxiv.org/abs/2406.00954", "title": "基于注释指南的知识增强：提升大型语言模型进行教育文本分类的方法", "title_en": "Annotation Guidelines-Based Knowledge Augmentation: Towards Enhancing Large Language Models for Educational Text Classification", "authors": "Shiqi Liu,Sannyuya Liu,Lele Sha,Zijie Zeng,Dragan Gasevic,Zhi Liu", "background": "机器学习方法在自动教育文本分类中的应用取得了显著进展，特别是用于识别学习参与度指标的学习参与度分类（LEC）任务。LEC为深入理解人类学习过程提供了一种手段，吸引了来自自然语言处理（NLP）、学习分析和教育数据分析等多个领域的研究兴趣。然而，尽管大型语言模型（LLMs）如ChatGPT在NLP任务中的性能优异，但在LEC任务中的全面评估和改进方法尚未得到深入研究。", "innovation": "本文提出了注释指南基于的知识增强（AGKA）方法，以提升LLM。AGKA利用GPT 4.0从注释指南中检索标签定义知识，然后应用随机下采样选择典型示例。通过系统性评估LEC，涵盖行为分类、情感分类和认知分类等多个子任务，证明了AGKA可以提升未经微调的LLM，特别是GPT 4.0和Llama 3 70B。在简单二分类任务中，AGKA的GPT 4.0的few-shot效果优于BERT、RoBERTa等全量微调模型，但在需要深刻理解复杂语义信息的任务中效率较低。研究还发现，GPT 4.0和开源模型Llama 3 70B结合AGKA的组合具有竞争力。", "conclusion": "研究结果表明，AGKA能够有效提升LLM，特别是在二分类任务中。开源Llama 3 70B与AGKA结合的表现与封闭源代码GPT 4.0相似。未来研究应针对LLM在多分类任务中区分同类标签命名相似问题的发展。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.17716", "html_url": "https://arxiv.org/abs/2406.17716", "title": "一种用于越南语对抗自然语言推理的新基准数据集和专家混合语言模型", "title_en": "A New Benchmark Dataset and Mixture-of-Experts Language Models for Adversarial Natural Language Inference in Vietnamese", "authors": "Tin Van Huynh,Kiet Van Nguyen,Ngan Luu-Thuy Nguyen", "background": "现有的越南语自然语言推理（NLI）数据集缺乏对抗复杂性，限制了它们评估模型在面对挑战性 Linguistic 现象时的鲁棒性。当前缺少专门针对越南语的对抗 NLI 数据集和资源，且现有模型在这类数据集上的表现不佳.", "innovation": "提出了 ViANLI，首个用于越南语的对抗 NLI 数据集，以及 NLIMoE，一种混合专家模型来应对复杂性。NLIMoE 结合了专家子网络和一个在共享编码器基础上的自学习动态路由机制。通过 ViANLI 和 NLIMoE，显著提升了模型在越南语 NLI 任务上的表现，特别是对当前最先进的 XLM-R Large 模型实现了 45.5% 的准确率，而 NLIMoE 达到了 47.3%。", "conclusion": "通过 ViANLI，模型在其他基准越南语 NLI 数据集如 ViNLI、VLSP2021-NLI 和 VnNewsNLI 上的性能也得到了提升。ViANLI 为研究模型鲁棒性和丰富未来越南语和多语言 NLI 研究资源提供了新的平台."}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20800", "html_url": "https://arxiv.org/abs/2510.20800", "title": "Compress to Impress: 使用100个样本的一个梯度步骤高效地调整大规模语言模型", "title_en": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "authors": "Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus", "background": "最近，Sharma等人提出了一种称为Layer-SElective-Rank reduction (LASER)的方法，该方法表明，通过精心选择的大规模语言模型（LLM）的权重矩阵的高阶组件剪枝可以在不进行任何基于梯度的微调的情况下提升下游任务的准确性。然而，LASER的全矩阵搜索过程（每个矩阵都需要完整数据的前向传递）使其不适合快速部署。研究者们提出了一种新的方法，旨在减少这种高成本，具体而言，他们发现：(i) 只需检查少量精心选中的矩阵，消除逐层扫描；(ii) 每个矩阵奇异值的梯度能够指示哪些矩阵需要减少；(iii) 通过允许矩阵行围绕多个子空间聚类，然后对每个簇单独分解，可以增加因子分解的搜索空间，进一步减少对原训练数据的过拟合，同时提升了24.6个百分点的准确性；(iv) 评估100个样本而非完整训练集数据，可用于计算指示性梯度和最终评估准确性，从而进一步减少搜索时间；研究者解释道，适应下游任务主要依赖于提示方式而非数据集大小。以上这些发现共同表明，构建快速且稳健的下游任务适应算法是可能的。", "innovation": "研究者们提出了一种新的方法来减少LASER方法的高成本。该方法包括：(i) 通过检查少量精心选中的矩阵来减少逐层扫描；(ii) 利用每个矩阵奇异值的梯度来选择需要减少的矩阵；(iii) 通过使用权重矩阵行聚类在多个子空间中，增加因子分解搜索空间，并减少过拟合；(iv) 检测完整训练集只需评估100个样本，从而缩短搜索时间。这些发现共同展示了一种高效且快速的调整大语言模型的方法，无需微调。", "conclusion": "结合这些发现，建立了一种快速且稳健的调整算法，通过在100个示例上的单步梯度计算和快速检查候选层和因子分解技术，可以在不进行微调的情况下将大语言模型调整到新的数据集。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.11843", "html_url": "https://arxiv.org/abs/2411.11843", "title": "Bi-Mamba：朝着准确的1位状态空间模型", "title_en": "Bi-Mamba: Towards Accurate 1-Bit State Space Models", "authors": "Shengkun Tang,Liqun Ma,Haonan Li,Mingjie Sun,Zhiqiang Shen", "background": "传统的Transformer模型存在计算复杂度随着序列长度呈二次增长以及推理阶段的显著内存需求的问题。尽管Mamba模型较大以解决一些问题，但它们在训练和部署过程中依然面临显著的计算需求，尤其是在训练和推理阶段。因此，为了更好地解决这些问题并使大型语言模型更加高效，本文提出了Bi-Mamba模型。", "innovation": "本文引入了Bi-Mamba模型，这是一个基于1位的可扩展且强大的Mamba架构，用于实现更高效的大型语言模型，参数数量为780M、1.3B和2.7B。Bi-Mamba模型使用自回归蒸馏损失从标准的大型语言模型规模数据集进行训练。实验结果表明，Bi-Mamba与全精度FP16或BF16版本具有可比性能，在语言建模基准测试中表现出色，且内存使用和计算成本显著低于原始Mamba模型。", "conclusion": "本文开创了线性复杂度和低位表示的大规模语言模型的新方向，并展示了专为高效1位Mamba模型优化的硬件设计的可能性。此外，作为开源项目，Bi-Mamba模型已提供源代码和预训练权重，可进一步推动相关研究和发展。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.15299", "html_url": "https://arxiv.org/abs/2412.15299", "title": "LAMA-UT: 通过字符统一及语言特定转写实现无语言束缚的多语言ASR", "title_en": "LAMA-UT: Language Agnostic Multilingual ASR through Orthography Unification and Language-Specific Transliteration", "authors": "Sangmin Lee,Woo-Jin Chung,Hong-Goo Kang", "background": "构建一种在多种语言上表现公平的通用多语言自动语音识别（ASR）模型一直是个挑战，因为这涉及到克服固有的困难。LAMA-UT 管道通过字符统一和语言特定转写解决了这一问题。", "innovation": "LAMA-UT 管道通过两个关键步骤实现：第一，使用通用转录生成器将字符统一为罗马化形式并捕获跨多种语言的共同音素特征；第二，使用通用转换器将这些通用转录转换为特定语言的转录。这种方法在相对错误率减少方面优于 Whisper，并且仅使用 Whisper 训练数据的 0.1% 进行训练。", "conclusion": "LAMA-UT 管道不依赖于任何特定语言的模块，并且与利用额外语言特定词典和语言模型的零样本 ASR 方法表现相当。我们预计此框架将作为灵活的多语言 ASR 系统的基础，即使对未见语言也是如此。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.19258", "html_url": "https://arxiv.org/abs/2410.19258", "title": "头都不一样：融合检索和推理能力的头级别KV缓存压缩方法", "title_en": "Not All Heads Matter: A Head-Level KV Cache Compression Method with Integrated Retrieval and Reasoning", "authors": "Yu Fu,Zefan Cai,Abedelkadir Asi,Wayne Xiong,Yue Dong,Wen Xiao", "background": "大型语言模型（LLMs）的计算效率可以通过使用键值（KV）缓存技术来提升，但随着输入长度的增长，其内存开销迅速增加。先前的研究表明，并非所有文本生成中的token都同等重要，因此提出了一种基于层级别的KV缓存压缩方法，选择性地保留关键信息。研究者认识到不同注意力头在生成文本中的独特角色，因此提出了一个基于注意力头级别的KV缓存压缩方法（HeadKV）和HeadKV-R2，后者利用了一种新的上下文推理能力评估方法进行压缩。", "innovation": "该研究提出了一种基于注意力头级别的KV缓存压缩方法（HeadKV），并通过增强的上下文推理能力评估方法（HeadKV-R2）进一步优化。该方法特别适用于需要同时检索和推理能力的上下文问答任务。实验结果表明，这种方法在不同基准模型、架构和长上下文能力测试中，相较于强基线方法，特别是在资源有限的环境下（KV尺寸为64和128），显著提升了性能。特别的是，该方法仅保留了完整KV缓存1.5%的信息，但在上下文问答基准测试中，其性能达到了完整KV缓存的97%。", "conclusion": "这种方法在不同基准模型、架构和长上下文能力测试中均表现出色，尤其是在资源有限的情况下，能够显著提高大型语言模型的计算效率，同时仅保留极小比例的KV缓存。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.18469", "html_url": "https://arxiv.org/abs/2410.18469", "title": "迭代自调优的LLM以增强越狱能力", "title_en": "Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities", "authors": "Chung-En Sun,Xiaodong Liu,Weiwei Yang,Tsui-Wei Weng,Hao Cheng,Aidan San,Michel Galley,Jianfeng Gao", "background": "最近的研究表明，大型语言模型（LLMs）容易受到自动化越狱攻击的影响，其中由算法生成的对抗性后缀被附加到有害查询上，绕过了安全对齐，触发了意外的响应。当前生成这些后缀的方法计算成本昂贵，攻击成功率（ASR）低，尤其是在对抗像Llama2和Llama3这样的高度对齐的模型时。这些限制促进了ADV-LLM的研究，它通过迭代自调优过程来生成具有增强越狱能力的对抗性LLM。", "innovation": "本文引入了ADV-LLM，这是一种迭代自调优过程，能够以减少计算成本的方式生成具有更高越狱能力的对抗性LLM，同时在各种开源LLM上实现了几乎100%的ASR。采用ADV-LLM优化的模型对闭源模型也表现出强攻击转移性，GPT-3.5的ASR为99%，GPT-4的ASR为49%。ADV-LLM还能提供有关未来安全对齐研究的宝贵见解，通过生成大规模数据集来研究LLM的安全性。", "conclusion": "ADV-LLM通过迭代自调优过程显着降低了生成对抗性后缀的计算成本，并在多个LLM上实现了接近100%的ASR，同时表现出强大的攻击转移性。这一框架不仅提高了越狱能力，还为未来的安全对齐研究提供了有价值的数据集。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.04346", "html_url": "https://arxiv.org/abs/2410.04346", "title": "从人类判断的列表排名进行换位偏好对齐", "title_en": "Permutative Preference Alignment from Listwise Ranking of Human Judgments", "authors": "Yang Zhao,Yixin Wang,Mingzhang Yin", "background": "大型语言模型（LLMs）与人类偏好对齐至关重要，以确保其行为的可控制性和一致性。现有方法，如基于人类反馈强化学习（RLHF）和直接偏好优化（DPO），依赖布雷德利-泰利（B-T）模型来最大化对偶选择的似然性。但是，当有多个回答可供选择时，B-T模型无法保证回答列表的准确排名。因此，本文提出了换位偏好对齐(Ppermutoative Preference Alignment，PPA)方法，这是一种新颖的离线列表对齐方法，将标准化折现累计收益（NDCG）作为替代训练目标，用于LLMs对齐。通过差分代理损失近似NDCG，从而开发了一个端到端对齐算法。实验表明，PPA在评估集和通用基准如AlpacaEval上优于现有对偶和列表方法。此外，NDCG方法在排名准确性上比B-T方法更有效，并对这种改进提供理论解释。", "innovation": "提出了一种新颖的离线列表对齐方法——换位偏好对齐（Permutative Preference Alignment，PPA），通过将标准化折现累计收益（NDCG）作为替代训练目标，使用差分代理损失近似NDCG，从而克服了B-T模型在多个回答排序中的不足。并通过实验证明了PPA在模型对齐上的优越性，并解释了基于NDCG的方法在排名准确性上的改进。", "conclusion": "实验结果表明，PPA在一系列评估和通用基准上均优于传统的方法，基于NDCG的方法在排序准确性方面比基于B-T的方法更加有效，PPA为LLMs与人类偏好对齐提供了新的解决思路。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.03456", "html_url": "https://arxiv.org/abs/2501.03456", "title": "从文本到带隙：预训练语言模型作为半导体带隙预测的编码器", "title_en": "Text to Band Gap: Pre-trained Language Models as Encoders for Semiconductor Band Gap Prediction", "authors": "Ying-Ting Yeh,Janghoon Ock,Achuth Chandrasekhar,Shagun Maheshwari,Amir Barati Farimani", "background": "本文研究了基于变压器的语言模型（包括RoBERTa、T5、Llama-3和MatSciBERT），这些模型直接从材料描述的文本中预测半导体材料的带隙。这些模型输入包括材料的关键特征，如化学组成、晶系、空间群和其他结构与电子特性。与浅层机器学习模型需要大量特征工程，或是依赖于从原子坐标导出的图表示形的图神经网络不同，预训练语言模型可以直接处理文本输入，无需手动特征预处理或结构编码。", "innovation": "本文介绍了一种直接从文本描述中预测半导体材料带隙的方法，无需复杂的特征工程。通过使用预训练语言模型，如RoBERTa、T5、Llama-3和MatSciBERT，研究者能够通过文本对材料特征进行编码并进行带隙预测。实验结果表明，这些模型从人类可读文本中预测带隙具有很高的准确性，MAE在0.25-0.33 eV之间。具体而言，预训练尺寸较大的Llama-3模型在预测带隙方面表现最佳，而MatSciBERT模型在比它参数少得多的情况下达到了相似的性能，突显了领域特定预训练的重要性。", "conclusion": "研究结果表明，预训练语言模型能够有效提取复杂特征-性质关系，从文本材料描述中直接预测带隙，显示出在科学回归任务中的应用潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.18795", "html_url": "https://arxiv.org/abs/2501.18795", "title": "旋转位置嵌入到无位置嵌入再回到旋转位置嵌入：一种新的混合注意力策略", "title_en": "Rope to Nope and Back Again: A New Hybrid Attention Strategy", "authors": "Bowen Yang,Bharat Venkitesh,Dwarak Talupuru,Hangyu Lin,David Cairuz,Phil Blunsom,Acyr Locatelli", "background": "长上下文大语言模型（LLMs）取得了显著进步，得益于技术如旋转位置嵌入（RoPE）以及其扩展（例如，Chen等人，2023；Liu等人，2024c；Peng等人，2023）。通过调整RoPE参数和使用扩展上下文数据进行训练，可以训练出能够处理更长输入序列的高性能模型。然而，现有基于RoPE的方法在处理扩展上下文长度时表现出性能限制。本文全面分析了不同的注意力机制，包括RoPE、无位置嵌入（NoPE）和查询键归一化（QK-Norm），指出它们在长上下文建模中的优点和缺点。", "innovation": "文章提出了一种新的混合注意力机制架构，结合了全局和局部注意力跨度。这一设计不仅超越了传统的基于RoPE的具有全注意力机制的Transformer模型在长上下文和短上下文任务中的表现，还在训练和推理阶段提供了显著的效率提升。", "conclusion": "通过比较分析现有的注意力机制，本文指出了这些机制在应对长上下文建模时的优势和局限，并提出了一种新的混合注意力机制，该机制在长上下文任务中表现出色并且在效率上有显著提升。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.04510", "html_url": "https://arxiv.org/abs/2502.04510", "title": "Heterogeneous Swarms: 联合优化模型角色和权重以构建多LLM系统", "title_en": "Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems", "authors": "Shangbin Feng,Zifeng Wang,Palash Goyal,Yike Wang,Weijia Shi,Huang Xia,Hamid Palangi,Luke Zettlemoyer,Yulia Tsvetkov,Chen-Yu Lee,Tomas Pfister", "background": "在自然语言处理领域，多大型语言模型（multi-LLM）系统通常需要优化模型的角色（如任务分工）和权重（模型在系统中的贡献度）。现有方法往往只关注角色或权重的优化，而忽视了两者共同优化的重要性。本文提出的Heterogeneous Swarms算法通过一种新的图神经网络方法，将多LLM系统表示为大型语言模型的有向无环图（DAG），并使用拓扑消息传递进行协作生成，从而实现模型角色和权重的联合优化，提高系统的整体性能和协同效应。", "innovation": "Heterogeneous Swarms提出了一个创新性的算法，将多LLM系统的优化问题转化为DAG的结构优化，通过角色步和权重步迭代优化模型的角色和权重。角色步中，通过粒子群优化方法优化模型的拓扑结构；权重步中，引入JFK-score度量模型在最佳DAG结构中的贡献，进一步优化模型权重。此外，该算法能够揭示多样化的模型角色配置和显著的协同增益效果，显示出相对于其他基于角色或权重的基线方法的优越性能。", "conclusion": "实验结果显示，Heterogeneous Swarms算法在12个不同任务中比其他15种基于角色或权重的基线方法平均提高了18.5%的性能。进一步分析表明，该算法发现了一种多样性更强、协作效应显著的多LLM系统，并且得益于大型语言模型之间的多样性。因此，Heterogeneous Swarms代表了多LLM系统设计的新方向，有望促进人工智能技术的进一步发展。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.01025", "html_url": "https://arxiv.org/abs/2502.01025", "title": "语言模型（主要）知道何时停止阅读", "title_en": "Language Models (Mostly) Know When to Stop Reading", "authors": "Roy Xie,Junlin Wang,Paul Rosu,Chunyuan Deng,Bolun Sun,Zihao Lin,Bhuwan Dhingra", "background": "当前大型语言模型（LLMs）处理输入上下文时是无区别的，即不会停止处理除非专门为它们设定停止条件。然而，对于需要局部信息来回答查询的任务，这种处理方式是低效的。这项研究旨在探索一种新的方法——动态上下文截断，该方法使LLMs能够在获得足够的任务相关信息时自行停止处理，从而提升效率和准确性。研究发现，模型内部的特定注意力头能够编码“充足性信号”，这些信号可以通过轻量级分类器检测到，帮助预测何时已经处理了关键信息。这揭示了一种新的效率范式：模型内部的理解自然决定了处理需求，而不是外部压缩启发式方法。通过在六个问答数据集（最多40K令牌）上进行的实验，展示了3.4%的准确率提升，同时平均减少了1.33倍的令牌数。此外，这种方法在同等令牌减少率下表现出优于其他上下文效率方法的性能。研究还发现了一种新的扩展现象：较小的模型需要通过探针进行准确性检测，而较大的模型则通过提示展示出自我评估的能力。", "innovation": "提出了一种名为动态上下文截断的新方法，该方法允许LLMs在获取足够任务相关信息后自我终止处理。该方法通过特定注意力头编码的“充足性信号”（通过轻量级分类器检测）来判断是否已经处理了关键信息，从而引入了一种新的效率范式。此外，研究展示了此方法在多个数据集和不同规模的模型上均优于其他上下文效率方法，并观察到了大小模型在自我评估能力上的不同扩展能力。", "conclusion": "研究展示了动态上下文截断方法在提高答案准确性的同时减少了令牌使用，证明了更自然的任务处理需求是由模型内部理解决定的。同时，还发现了模型规模与自我评估能力之间的新扩展现象，为未来的工作提供了一个有趣的视角。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.13251", "html_url": "https://arxiv.org/abs/2502.13251", "title": "神经注意力搜索", "title_en": "Neural Attention Search", "authors": "Difan Deng,Marius Lindauer", "background": "当前，基于变换器的模型在推理过程中需要较大的KV缓存大小，导致推理成本较高。为了高效地减少这些模型的推理成本，研究人员提出了自动评估序列中每个令牌重要性的方法，并决定在经过几步后是否可以丢弃相应的令牌。这将有助于优化模型的KV缓存大小，进而降低推理成本。现有方法包括One-Shot神经架构搜索等，通过可学习的注意力掩码联合学习令牌类型信息与架构权重。然而，这些方法未解决如何高效地减少KV缓存大小并保持模型性能的问题。因此，需要一种新的框架来解决这个问题，这就是本文要介绍的Neural Attention Search (NAtS)框架。", "innovation": "NAtS框架设计了一种搜索空间，包含三种不同类型的令牌：全局令牌、局部令牌和滑动窗口令牌。全局令牌将被后续所有令牌保留并查询；局部令牌存活到下一个全局令牌出现；滑动窗口令牌对固定大小的后续令牌的推理具有影响。与One-Shot神经架构搜索类似，NAtS能够通过可学习的注意力掩码联合学习令牌类型信息与架构权重。此外，通过实验验证，NAtS能够在保持模型性能的同时，有效减少所需的KV缓存大小。", "conclusion": "本文提出了一种新的自动生成令牌重要性评估和值-键缓存大小调整的框架NAtS。该框架通过可学习的注意力掩码在训练期间共同学习令牌类型信息和架构权重，从而能够在保持模型性能的同时减少KV缓存大小，进而降低推理成本。实验表明，NAtS在从头训练新变换器和微调现有大规模语言模型方面均表现出高效的KV缓存大小减少效果。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15086", "html_url": "https://arxiv.org/abs/2502.15086", "title": "通用安全标准是否适用于所有人？大规模语言模型的用户特定安全性评估", "title_en": "Is Safety Standard Same for Everyone? User-Specific Safety Evaluation of Large Language Models", "authors": "Yeonjun In,Wonjoong Kim,Kanghoon Yoon,Sungchul Kim,Mehrab Tanjim,Sangwu Park,Kibum Kim,Chanyoung Park", "background": "随着大型语言模型（LLM）代理的应用越来越多，其安全漏洞也越来越明显。虽然现有的基准测试评估了LLM的各种安全性方面，但这些测试主要依靠通用标准来定义安全性，而忽略了基于用户特定标准。然而，用户特定的安全标准可能因用户类别而异，这引起了一个关键的研究问题：在考虑用户特定的安全标准时，LLM代理是否能安全地运行？尽管这对于安全使用LLM非常重要，但目前尚无基准数据集来评估LLM的用户特定安全性。", "innovation": "为了填补这一空白，作者引入了U-SafeBench，这是一个旨在评估LLM用户特定方面的基准。通过评估20个常用的LLM，作者发现这些模型在考虑用户特定安全标准时无法安全运行，从而为该领域带来了一个新的发现。此外，作者还提出了一种基于思考过程链的简单补救措施，并证明了其在提高用户特定安全性方面的有效性。", "conclusion": "基准与代码可在该链接获取，作者的评估揭示了当前LLM在考虑用户特定安全标准时无法安全运行的情况，强调了开发用户特定安全评估标准和补救措施的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01002", "html_url": "https://arxiv.org/abs/2504.01002", "title": "令牌嵌入违反流形假设", "title_en": "Token embeddings violate the manifold hypothesis", "authors": "Michael Robinson,Sourya Dey,Tony Chiang", "background": "理解大型语言模型（LLM）的行为需要对其输入令牌空间有深刻的了解。如果这个空间与我们的假设不同，那么关于LLM的理解和结论可能是错误的。本文从理论上和经验上阐明了令牌嵌入的结构，并提出了一种新的统计测试，以检验令牌邻居区域的结构假设。", "innovation": "提出了一种新的统计测试假设，即假设令牌周围区域的结构相对平坦和光滑（作为零假设）。这种测试假设的结构是边界流形的一般化，称为“平滑纤维丛”（可以分为两个空间区间——小半径和大半径），并据此提出“纤维丛假设”。通过在多个开源LLM上运行这种测试，发现零假设经常被拒绝，从而表明令牌子空间不是纤维丛，也不是流形。", "conclusion": "当LLM面对两个语义等效的提示时，如果一个提示包含被该测试认定的令牌，那么对该提示的响应可能会比另一个提示表现出较低的稳定性。因此，结论是令牌子空间不是纤维丛或流形。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.15090", "html_url": "https://arxiv.org/abs/2502.15090", "title": "ExpertLens: 激活引导特征非常可解释", "title_en": "ExpertLens: Activation steering features are highly interpretable", "authors": "Masha Fedzechkina,Eleonora Gualdoni,Sinead Williamson,Katherine Metcalf,Skyler Seto,Barry-John Theobald", "background": "在大型语言模型（LLMs）中，激活引导方法已证明是有效方式进行有针对性的更新，以提高生成语言的质量，而无需大量适应数据。目前的研究问题在于，这些方法发现的特征是否具有可解释性。", "innovation": "研究通过使用‘寻找专家’方法识别负责特定概念（如“猫”）的神经元，并通过ExpertLens（这些神经元的检查机制）展示对模型表示的见解。结果显示，ExpertLens的表示在不同模型和数据集上是稳定的，并且与行为数据中推断出的人类表示紧密相符，且优于使用词/句子嵌入捕捉的对齐程度。通过ExpertLens重建人类概念组织，表明其能够提供对LLM概念表示的颗粒化视图。研究发现，ExpertLens是一种灵活且轻量级的方法，用于捕捉和分析模型表示，这一发现意味着LLMs的可解释性得到了增强，有助于更深入地理解模型内部机制。", "conclusion": "研究证明了激活引导特征的高度可解释性，提出了ExpertLens作为一种灵活和轻量级的手段，可以帮助捕捉和分析模型表示，为理解大型语言模型的内部运作提供了新视角。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.12474", "html_url": "https://arxiv.org/abs/2504.12474", "title": "将结构和语义信号结合在文本归属图中的BiGTex", "title_en": "Integrating Structural and Semantic Signals in Text-Attributed Graphs with BiGTex", "authors": "Azadeh Beiranvand,Seyed Mehdi Vahidipour", "background": "文本归属图（TAGs）在表示学习中具有独特挑战，需要模型捕捉节点关联文本的语义丰富性和图结构的依赖关系。图神经网络（GNNs）擅长建模拓扑信息，但在处理非结构化文本方面能力不足。相反，大型语言模型（LLMs）擅长文本理解，但通常不了解图结构。因此，本文探讨了如何将GNNs和LLMs紧密结合，以实现节点分类和链接预测的最新性能。", "innovation": "本文提出了一种新颖的BiGTex架构，通过堆叠的Graph-Text融合单元将GNNs和LLMs紧密结合。每个单元允许文本表示和结构表示之间的相互注意，使信息在两者之间双向流动，文本影响结构，结构指导文本解释。模型通过参数高效的微调（LoRA）训练，固定LLMs并将注意力集中在任务特定信号上。广泛的实验展示了BiGTex在节点分类中的超群性能，并且能够有效推广到链接预测。", "conclusion": "通过对比分析，BiGTex在节点分类和链接预测任务上取得了最先进的性能，且实验证明双向注意和软提示对于模型成功的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.09068", "html_url": "https://arxiv.org/abs/2505.09068", "title": "S-DAT: 一种多语言、基于生成式人工智能的自动发散思维评估框架", "title_en": "S-DAT: A Multilingual, GenAI-Driven Framework for Automated Divergent Thinking Assessment", "authors": "Jennifer Haase,Paul H. P. Hanel,Sebastian Pokutta", "background": "传统的创造力评估往往耗时且语言专一，并依赖于主观的人类评级，限制了其可扩展性和跨文化的适用性。", "innovation": "S-DAT 引入了一种可扩展且多语言的框架，利用大型语言模型和先进的多语言嵌入来计算语义距离，这是一种语言无关的发散思维（DT）的代理指标。与以前的方法不同，S-DAT 在不同语言背景下显示出一致且稳健的评分结果，并且具有与并发思维的正确鉴别效度，展示出与其他 DT 度量的相关同构效度。", "conclusion": "S-DAT 提供了一个公平且全面评估不同人群认知灵活性的强大工具，可以自由线上测评。这种跨语言灵活性使得更包容的、全球规模的创造力研究成为可能，解决了早期方法的关键局限性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.04388", "html_url": "https://arxiv.org/abs/2503.04388", "title": "更多文档，同样长度：RAG中多文档挑战的隔离", "title_en": "More Documents, Same Length: Isolating the Challenge of Multiple Documents in RAG", "authors": "Shahar Levy,Nir Mazor,Lihi Shalmon,Michael Hassid,Gabriel Stanovsky", "background": "先前的研究发现，检索大量外部文档可能会降低大型语言模型（LLM）的生成准确性，但没有研究明确区分文档数量与上下文长度对性能的影响。本文作者通过自定义数据集，研究了在保持上下文长度和相关信息位置不变的情况下，增加文档数量对多种语言模型的影响，揭示了处理多文档是不同于处理长上下文的挑战。", "innovation": "本文通过多文档查询生成（RAG）任务，系统地研究了增加的文档数量对不同语言模型生成准确性的影响。在固定上下文长度和相关信息位置的情况下，评估了在不同文档数量下的模型表现，并发现大多数模型在增加文档数量时性能显著下降，而Qwen2.5保持了性能的稳定性，揭示了新模型具有更好的多文档处理能力。", "conclusion": "本文研究表明，在RAG设置中增加文档数量对大多数LLM的性能带来了挑战，减少了20%以上的准确性，而Qwen2.5在增加文档数量的情况下表现稳定，表明其具有较好的多文档处理能力。此外，本文还强调了处理多文档与处理长上下文是不同的挑战，并开源了所使用的数据集和代码。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.18458", "html_url": "https://arxiv.org/abs/2504.18458", "title": "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "title_en": "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "authors": "Wenyi Xiao,Leilei Gan", "background": "在应用强化学习（通常通过GRPO）到大型视觉-语言模型推理时，难以有效扩展推理长度或在各种任务中生成冗余输出，仅在准确率上有微小提升。为解决这一问题，我们提出了FAST-GRPO，这是一种GRPO变体，可以根据问题特点动态调整推理深度。实证分析表明，在研究响应长度和数据分布如何影响性能的基础上，LVLMs中的快速-缓慢思考是可行的。基于这些观察，我们引入了两个互补的指标来估计问题的难度，指导模型确定何时使用快速或缓慢思考。实验结果表明，FAST在七项推理基准测试中实现了最先进的准确率，相对改进超过10%，同时与前一generation的缓慢思考方法相比，减少了32.7%-67.3%的令牌使用量，有效地平衡了推理长度和准确率之间的关系。", "innovation": "FAST-GRPO是一种GRPO变体，可以根据问题特性动态调整推理深度。通过引入适应长度的奖励和难度意识的KL散度，优化GRPO算法。这种模型在七个推理基准测试中实现了显著的准确率提升和令牌使用量的显著减少，从而实现推理长度和准确率之间的有效平衡", "conclusion": "实验结果显示，FAST在多数时间内比基线模型更精确，并且能够显著减少令牌使用量，从而更有效地平衡了推理长度和准确率之间的关系。FAST-GRPO提供了一种解决大型视觉-语言模型推理时长度和准确率平衡问题的有效方法。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14483", "html_url": "https://arxiv.org/abs/2505.14483", "title": "MoMoE: Mixture of Moderation Experts Framework for AI-Assisted Online Governance", "title_en": "MoMoE: Mixture of Moderation Experts Framework for AI-Assisted Online Governance", "authors": "Agam Goyal,Xianyang Zhan,Yilun Chen,Koustuv Saha,Eshwar Chandrasekharan", "background": "现有的内容管理方法要求为每个社区单独训练一个模型，并且在决策过程中缺乏透明度，这限制了这些方法在现实生活中的应用。大规模语言模型在识别在线社区中的有害内容方面表现出极大的潜力。", "innovation": "MoMoE框架是一个模块化的跨社区框架，通过后置解释实现了可扩展的内容管理。它通过分配、预测、聚合和解释四个操作者协调工作，并且可以通过七种社区特化的专家（MoMoE-Community）和五种规范违反者专家（MoMoE-NormVio）被实例化。在30个未见过的子Reddit上，MoMoE的最优化版本分别获得了0.72和0.67的微平均F1分数，超过了精细调整的基础模型，同时提供了简洁且可靠的原因说明。尽管社区特化的专家在准确性上达到了最高点，但规范违反者专家在不同领域表现出了更稳定的效果。", "conclusion": "MoMoE能够在无需每个社区进行精细调整的情况下实现可扩展和透明的内容管理，提供了可信赖的人工智能治理下的在线社区管理。这项研究建议轻量级的可解释专家集可用于未来NLP和HCI领域中的可信人机治理研究。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11336", "html_url": "https://arxiv.org/abs/2505.11336", "title": "XtraGPT：基于上下文和可控的学术论文润色", "title_en": "XtraGPT: Context-Aware and Controllable Academic Paper Revision", "authors": "Nuo Chen,Andre Lin HuiKai,Jiaying Wu,Junyi Hou,Zining Zhang,Qian Wang,Xidong Wang,Bingsheng He", "background": "尽管大型语言模型（LLMs）在学术工作流程中的应用日益广泛，但它们的支持能力仍然有限，无法满足高质量科学写作的需求。大部分现有的系统仅能进行一般性的科学文本生成，无法满足深层次的研究交流要求，如各章节之间的概念连贯性。此外，学术写作具有迭代性和修正性，直接提示式的方法对此过程的支持不足。本研究提出了一种基于准则引导意图对齐和情境感知建模的人机协作框架，以解决上述问题。", "innovation": "本研究构建了一个基于准则引导意图对齐和情境感知建模的人机协作框架。通过创建一个由7,000篇顶级会议论文组成的带有140,000个指令-响应对的数据集，以反映真实的、段落级别的科学修订。XtraGPT 是首个用于上下文感知、指令引导的开放源代码 LLM 套件（参数范围从1.5B到14B），通过广泛的实验验证，其性能显著优于同类基线模型，并接近专有系统的质量。自动偏好评估和人工评估均证实了XtraGPT在改进科学草案方面的有效性。", "conclusion": "XtraGPT 显著提高了科学草案的质量，其性能优于相同规模的基线模型，并接近专有系统的质量。这表明 XtraGPT 可以有效支持学术写作的迭代和修正过程。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14685", "html_url": "https://arxiv.org/abs/2505.14685", "title": "语言模型使用回溯机制追踪信念", "title_en": "Language Models use Lookbacks to Track Beliefs", "authors": "Nikhil Prakash,Natalie Shapira,Arnab Sen Sharma,Christoph Riedl,Yonatan Belinkov,Tamar Rott Shaham,David Bau,Atticus Geiger", "background": "该论文探讨了语言模型（LMs）如何表示角色的信念，尤其是当这些信念可能与现实不同。这一问题在于理解LMs的理论思维（ToM）能力。研究人员通过因果中介和抽象分析，评估LMs在涉及角色信念时的推理能力。他们构建了一个名为CausalToM的数据集，包含简单的故事，其中两个角色独立改变两个物体的状态，可能不了解彼此的行为。研究发现了一个持续的算法模式，称为回溯机制，该机制使LM能够在需要时回忆重要信息。", "innovation": "该研究的研究创新点在于开发了一个名为CausalToM的数据集，并通过因果中介和抽象分析评估了LMs的信念推理能力。研究发现了回溯机制，这一机制使LM能够在需要时回忆重要信息。特别是在引入了角色可见性信息后，研究发现LM会生成一个可见性ID，用于检索被观察角色的信息并更新观察角色的信念。", "conclusion": "研究提供了关于信念追踪机制的见解，向前迈出了一步，以逆向工程LMs中的ToM推理机制。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14101", "html_url": "https://arxiv.org/abs/2505.14101", "title": "MultiHal：基于知识图谱的多语言LLM幻觉评估数据集", "title_en": "MultiHal: Multilingual Dataset for Knowledge-Graph Grounded Evaluation of LLM Hallucinations", "authors": "Ernests Lavrinovics,Russa Biswas,Katja Hose,Johannes Bjerva", "background": "大型语言模型（LLMs）在忠实性和事实准确性方面存在固有限制，称为幻觉。尽管已有用于英语为中心数据集的评估基准测试，但这些基准依赖于附加的上下文信息而忽视了结构化的事实资源。知识图谱（KGs）被认为是减轻幻觉的有效工具，因其以结构化方式表示实体及其关系。现有幻觉评估基准缺乏KG路径和多语言支持，本文填补了这一空白，提出了一种基于KG的多语言多跳评估基准MultiHal，以生成文本评估为框架。该基准从开放域KG中挖掘了14万个KG路径，并从中清理出高质量的25900个路径。", "innovation": "提出了一种基于知识图谱的多语言多跳评估基准MultiHal，该基准补充了现有幻觉评估基准中缺乏的KG路径和多语言支持，并展现了知识图谱集成的潜力，提高了几个关键指标，如语义相似性、NLI蕴含和幻觉检测分数，特别是在多语言和多个模型中。", "conclusion": "作者期望MultiHal将促进基于图的幻觉缓解和事实核查任务的研究。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16722", "html_url": "https://arxiv.org/abs/2505.16722", "title": "打破mBad！跨语言去毒的监督微调", "title_en": "Breaking mBad! Supervised Fine-tuning for Cross-Lingual Detoxification", "authors": "Himanshu Beniwal,Youngwoo Kim,Maarten Sap,Soham Dan,Thomas Hartvigsen", "background": "随着大型语言模型（LLMs）在全球应用中的日益普及，确保这些模型在多种语言背景下无毒一直是关键挑战。研究探讨了跨语言去毒这一跨语言范式，旨在通过迁移高资源语言和低资源语言之间的去毒能力，解决不同书写体系间的去毒问题。", "innovation": "提出了跨语言去毒的监督微调方法，以增强模型在不同语言和文化背景下的去毒能力。通过大量实验场景评估了其有效性，并探讨了遏制机制对非毒性任务性能的影响。", "conclusion": "实验结果表明，跨语言去毒方法在处理数据有限的分布转移场景中具有有效性，并揭示了在安全性和知识保留之间的权衡。相关代码和数据集已公开。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14536", "html_url": "https://arxiv.org/abs/2505.14536", "title": "使用稀疏自编码器的LLM去毒化", "title_en": "Breaking Bad Tokens: Detoxification of LLMs Using Sparse Autoencoders", "authors": "Agam Goyal,Vedant Rathi,William Yeh,Yian Wang,Yuen Chen,Hari Sundaram", "background": "大型语言模型（LLMs）现在在面向用户的应用程序中随处可见，但它们仍然生成不 desirable 的有毒输出，包括粗俗语言、不雅术语和贬损言论。虽然有许多去毒方法，但大多数方法仅适用于表面层面的修复，并且很容易被监狱突破攻击绕过。", "innovation": "本文利用稀疏自编码器（SAEs）识别模型残差流中的毒性相关方向，并利用相应的解码器向量执行有针对性的激活引导。介绍了三种不同的引导侵略性层级，并在GPT-2 Small和Gemma-2-2B上进行了评估，揭示了毒性减少与语言流畅性之间的权衡。在更强的引导强度下，这些因果干预措施在减少毒性方面表现优于竞争基线，最多可减少20%的毒性，但在语言流畅性方面可能会出现明显下降。关键地，定向引导后的标准NLP基准分数保持稳定，表明模型的知识和普遍能力得到了保留。此外，研究发现，在更宽的SAEs中进行特征分裂会阻碍安全性干预，突显了解耦特征学习的重要性。", "conclusion": "本文的研究突显了稀疏自编码器（SAEs）因果干预在LLM去毒化中的潜力和当前局限性，进一步建议了旨在确保更安全的语言模型部署的实际指南。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.16348", "html_url": "https://arxiv.org/abs/2505.16348", "title": "具备体验的应用程序遇个人化：通过记忆利用视角考察挑战与解决方案", "title_en": "Embodied Agents Meet Personalization: Investigating Challenges and Solutions Through the Lens of Memory Utilization", "authors": "Taeyoon Kwon,Dongwook Choi,Hyojun Kim,Sunghwan Kim,Seungjun Moon,Beong-woo Kwak,Kuan-Hao Huang,Jinyoung Yeo", "background": "LLM驱动的体现实体在传统对象重新排列任务中取得了成功，但在利用用户过去互动中的特定知识提供个性化辅助方面提出了新的挑战。这些挑战主要涉及两个维度：根据个人意义识别对象（object semantics）和回忆行为模式序列（user patterns），即利用用户的记忆进行规划。", "innovation": "本文构建了MEMENTO框架，这是一个端到端的两阶段评估框架，包括单记忆任务和联合记忆任务，以评估这些能力。通过深入分析现存问题，提出了一种基于分层知识图谱的用户画像记忆模块，该模块能够分别管理个性化知识，并在单记忆任务和联合记忆任务中取得了显著提升。", "conclusion": "当前的体现实体能够回忆简单的物体语义，但在应用用户的序列行为模式进行规划时面临困难。实验揭示了信息过载和处理多个记忆时的协调失败作为主要瓶颈。基于这些发现，设计了一种基于分层知识图谱的用户画像记忆模块，该模块实现了显著的性能改进。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18651", "html_url": "https://arxiv.org/abs/2505.18651", "title": "字嵌入中线性类比现象的起源", "title_en": "On the Emergence of Linear Analogies in Word Embeddings", "authors": "Daniel J. Korchinski,Dhruva Karkada,Yasaman Bahri,Matthieu Wyart", "background": "现有模型如Word2Vec和GloVe通过文本语料库中单词i和j共现概率P(i, j)构建单词嵌入。生成的向量不仅将语义相似的单词分组，还揭示了显著的线性类比结构——例如，$W_{\text{king}} - W_{\text{man}} + W_{\text{woman}} \times W_{\text{queen}}$。尽管有这些观察结果，这一结构的理论源头仍不清楚。", "innovation": "该研究提出了一个理论生成模型，将单词定义为二进制语义属性，共现概率基于基于属性的交互获得。该模型能够解释线性类比现象的出现，并自然解释了前人的观察结果。", "conclusion": "该模型提供了对每增加一个嵌入维度的作用的细粒度解析，且对各种形式的噪声具有鲁棒性，同时也与在维基百科和米科洛夫等人引入的类比基准上测量的共现统计一致。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14827", "html_url": "https://arxiv.org/abs/2505.14827", "title": "超越离散令牌抽样的文本生成", "title_en": "Text Generation Beyond Discrete Token Sampling", "authors": "Yufan Zhuang,Liyuan Liu,Chandan Singh,Jingbo Shang,Jianfeng Gao", "background": "在标准的自回归生成中，预训练语言模型（LLM）预测下一个令牌的概率分布，抽取一个离散的令牌，然后丢弃这个概率分布，仅将抽取的令牌作为新的输入传递。这种方法丢弃了一个非常丰富的概率分布信息，而Mixture of Inputs (MoI) 提出了一种无需训练的方法，来保留这种丰富的信息。MoI 在生成令牌后，构造了一个新的输入，融合了生成的离散令牌和之前丢弃的概率分布。", "innovation": "MoI 提出了一种新颖的方法，通过融合生成的令牌和丢弃的概率分布来保留生成过程中的丰富信息。这种方法采用了贝叶斯估计方法，看待令牌分布为先验，抽取的令牌为观测，并用连续的后验期望代替传统的独热向量作为新的模型输入，使得模型在整个生成过程中保持更丰富的内部表示，从而提高生成文本的质量和推理能力。特别是在数学推理、代码生成和博士研究生级别的 QA 任务上，MoI 在多个模型（包括QwQ-32B、Nemotron-Super-49B、Gemma-3-27B 和 DAPO-Qwen-32B）上提高了性能，无需额外训练且计算开销可忽略不计。", "conclusion": "MoI 通过融合生成的令牌和丢弃的概率分布，使得模型在整个生成过程中保持更丰富的内部表示，从而提高文本生成的质量和推理能力，在多种测试任务中展示出了显著的性能提升。这种方法不需要额外的训练，并且计算开销可以忽略不计。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18454", "html_url": "https://arxiv.org/abs/2505.18454", "title": "基于强化学习的混合隐式推理", "title_en": "Hybrid Latent Reasoning via Reinforcement Learning", "authors": "Zhenrui Yue,Bowen Jin,Huimin Zeng,Honglei Zhuang,Zhen Qin,Jinsung Yoon,Lanyu Shang,Jiawei Han,Dong Wang", "background": "大型语言模型（LLMs）的最新进展引入了隐式推理作为自回归推理的有希望的替代方案。通过在先前步骤中使用的隐藏状态进行内部计算，隐式推理受益于更具信息性的特征，而非选择离散的思考链（CoT）路径。然而，隐式推理方法往往与LLMs不兼容，因为它们的连续范式与自回归生成的离散性质冲突。此外，这些方法依赖CoT轨迹进行训练，因此未能利用LLMs固有的推理模式。", "innovation": "本文探讨了利用LLMs的内在能力通过强化学习（RL）实现隐式推理的方法。提出了混合推理策略优化（HRPO），这是一种基于RL的混合隐式推理方法，通过（1）使用可学习的门控机制将先验隐藏状态集成到抽样标记中，以及（2）通过从主要基于标记嵌入的初始化训练逐步引入更多隐藏特征来训练。这设计保留了LLMs的生成能力，并通过结合离散和连续表示激励混合推理。此外，通过标记采样的随机性，HRPO为隐式推理引入了随机性，从而允许基于RL的优化而不需使用CoT轨迹。", "conclusion": "在各种基准上的广泛评估表明，HRPO在知识和推理密集型任务中均优于先前的方法。此外，HRPO训练的LLMs保持可解释性，并表现出跨语言模式和较短完成长度等有趣的行为，突显了我们的基于RL的方法的应用前景，并为未来研究隐式推理提供了见解。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19201", "html_url": "https://arxiv.org/abs/2505.19201", "title": "DREAM: Drafting with Refined Target Features and Entropy-Adaptive Cross-Attention Fusion for Multimodal Speculative Decoding", "title_en": "DREAM: Drafting with Refined Target Features and Entropy-Adaptive Cross-Attention Fusion for Multimodal Speculative Decoding", "authors": "Yunhai Hu,Tianhua Xia,Zining Liu,Rahul Raman,Xingyu Liu,Bo Bao,Eric Sather,Vithursan Thangarasa,Sai Qian Zhang", "background": "在大规模语言模型（LLMs）中，投机解码（SD）已成为加速自回归生成的强大方法，但在视觉-语言模型（VLMs）中的集成仍然相对较少研究。本文旨在探讨如何将投机解码应用到VLMs中。", "innovation": "本文提出了名为DREAM的新颖投机解码框架，其包含三大创新点：（1）基于交叉注意机制，将目标模型中的中间特征注入并入草稿模型以提高对齐效果；（2）基于注意力熵的中间特征自适应选择，以引导有效的草稿模型训练；（3）视觉标记压缩，以降低草稿模型的延迟。DREAM框架支持高效、准确且并行的多模态解码，显著提高了吞吐量。", "conclusion": "实验表明，DREAM相较于传统的解码方式可获得高达3.6倍的速度提升，并在各种多模态基准测试中显著优于先前的投机解码基准线，适用于LLaVA、Pixtral、SmolVLM和Gemma3等多种最近流行的VLMs。该论文中的代码已公开。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19678", "html_url": "https://arxiv.org/abs/2505.19678", "title": "视觉落地语言：用于减少LVLMs幻觉的条件互信息校准解码策略", "title_en": "Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs", "authors": "Hao Fang,Changle Zhou,Jiawei Kong,Kuofeng Gao,Bin Chen,Shu-Tao Xia", "background": "大视觉语言模型（LVLMs）容易出现幻觉问题，即生成的文本虽然在语义上似乎合理，但却与输入图像几乎没有关联。先前的研究表明，这一问题主要是因为LVLMs过度依赖语言先验，而在解码过程中忽视了视觉信息。为了缓解这一问题，我们提出了一种新的条件点到点互信息（C-PMI）校准解码策略，该策略通过增加生成文本与输入图像之间的互相关性来减轻幻觉现象。", "innovation": "我们提出了一种新的解码策略，该策略通过同时建模视觉和文本token对C-PMI的贡献，将幻觉减轻问题转化为一个多层次优化问题，其目的是最大化互信息。这一策略通过设计一个token净化机制来动态调整解码过程，确保选取与给定图像最相关的文本token，并同时优化最相关的图像token，以生成最相关的响应。", "conclusion": "通过在各种基准上进行广泛实验，我们发现提出的策略能够显著降低LVLMs中的幻觉现象，同时保持解码效率。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.02945", "html_url": "https://arxiv.org/abs/2506.02945", "title": "Quantitative LLM Judges", "title_en": "Quantitative LLM Judges", "authors": "Aishwarya Sahoo,Jeevana Kruthi Karnuthala,Tushar Parmanand Budhwani,Pranchal Agarwal,Sankaran Vaidyanathan,Alexa Siu,Franck Dernoncourt,Jennifer Healey,Nedim Lipka,Ryan Rossi,Uttaran Bhattacharya,Branislav Kveton", "background": "该论文背景在于，尽管大型语言模型（LLM）在生成定性文本评估方面表现出色，但在预测人类偏好和数值评分方面仍然存在困难。研究提出了一种框架，通过回归模型将现有LLM评估者的评价分数与特定领域的评分对齐，以提升原始评估者的评分能力，从而改进量化评估结果。该论文展示了这一框架在不同类型绝对和相对反馈方面的普遍性和灵活性，并通过实验证明在数据量有限的情况下这种方法比监督调优更为高效。", "innovation": "提出了定量的LLM评估者框架，通过回归模型将现有LLM评估者的分数与人类评分进行对齐，以提高原始评估者的评价分数。该框架能够处理不同类型（绝对和相对）的反馈并展示了其通用性和灵活性。此外，该框架在计算效率和统计效率方面优于监督调优，并在实际应用中展示了更高的效果。", "conclusion": "通过实验验证了这些主张的效果，表明通过后处理建模可以提升现有评估者的预测能力。定量LLM评估者框架在多种数据集上得到了验证，并显示出在有限人类反馈情况下具有更高统计效率的特点。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.20352", "html_url": "https://arxiv.org/abs/2507.20352", "title": "RMTBench:通过多轮用户中心角色扮演评估大型语言模型", "title_en": "RMTBench: Benchmarking LLMs Through Multi-Turn User-Centric Role-Playing", "authors": "Hao Xiang,Tianyi Tang,Yang Su,Bowen Yu,An Yang,Fei Huang,Yichang Zhang,Yaojie Lu,Hongyu Lin,Xianpei Han,Jingren Zhou,Junyang Lin,Le Sun", "background": "大型语言模型（LLMs）在角色扮演应用中显示出巨大潜力，但评估这些能力变得愈加重要但依然具有挑战性。现有的基准评估主要采用以角色为中心的方法，简化用户角色互动为孤立的问答任务，未能反映实际应用情况。", "innovation": "引入了RMTBench，这是一个全面的用户中心双语角色扮演基准，包含80个不同角色和超过8000轮对话。RMTBench通过角色详细背景和简单特质定义的角色，支持各种用户场景的评估。基准基于用户的明确动机构建对话，不依赖于角色描述，从而确保与实际用户应用的一致性。同时建立了真实的多轮对话模拟机制，通过精心选取的评估维度和基于LLM的评分机制，捕捉用户和角色间的复杂对话意图。", "conclusion": "RMTBench 通过从角色背景转向用户意图满足，将学术评估与实际部署需求对接，提供了一种更有效的框架来评估LLMs的角色扮演能力。所有代码和数据集将很快发布。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06795", "html_url": "https://arxiv.org/abs/2507.06795", "title": "ixi-GEN：通过领域适应持续预训练实现高效的工业级小型语言模型", "title_en": "ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining", "authors": "Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon", "background": "开源大型语言模型的出现为企业的应用程序提供了更多机会，但许多组织仍缺乏部署和维护大规模模型的基础设施。因此，尽管小型语言模型（sLLMs）在性能上有所限制，它们仍成为了实用的替代品。尽管已经探索了领域适应连续预训练（DACP）技术以实现领域适配，但其在商业环境中的实用性尚未得到充分验证。本研究验证了基于DACP的通用配方在不同基础模型和应用场景中的效果，生成了通过DACP应用的小型语言模型ixi-GEN。通过对大量实验和实际应用的评估，结果显示ixi-GEN模型在目标领域性能上取得了显著提升，同时保持了通用能力，为企业级部署提供了成本高效和可扩展的解决方案。", "innovation": "本研究通过验证DACP方法在多个基础模型和应用场景中的有效性和泛化能力，生成了通过DACP应用的ixi-GEN小型语言模型。这是首次在商业环境中系统性评估DACP技术的实际价值，并为小型语言模型在企业中的应用提供了新的范例和解决方案。", "conclusion": "ixi-GEN小型语言模型在目标领域的性能上取得了显著提升，同时保持了通用能力。这种方法为企业需要灵活应用的强大而高效的语言模型提供了成本高效和可扩展的部署方案。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17536", "html_url": "https://arxiv.org/abs/2508.17536", "title": "辩论或投票：多智能体大型语言模型中哪种方式能更好地做出决策?", "title_en": "Debate or Vote: Which Yields Better Decisions in Multi-Agent Large Language Models?", "authors": "Hyeong Kyu Choi,Xiaojin Zhu,Sharon Li", "background": "多智能体辩论（MAD）作为一种通过协作推理提升大语言模型性能的有前途的范式已经出现。尽管最近取得了进展，但MAD有效性的关键驱动因素尚不清楚。该研究将MAD分解为两个关键组成部分——多数表决和智能体间辩论，并评估它们各自的作用。", "innovation": "提出了一种理论框架，将辩论建模为一随机过程，并证明其诱导了代理信念轨迹的鞅，暗示辩论本身并不能提高预期正确性。基于这些见解，通过调整智能体信念更新偏向修正，能在一定程度上提升辩论的有效性。研究表明，简单的组合方法在大多数实际应用场景中仍然是强大的且更可靠的选择。", "conclusion": "我们的研究结果表明，尽管MAD具有潜力，但在许多实际应用场景中，简单的组合方法仍然是更强大且更可靠的选择。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.19667", "html_url": "https://arxiv.org/abs/2505.19667", "title": "LeCoDe：评估互动法律咨询对话的基准数据集", "title_en": "LeCoDe: A Benchmark Dataset for Interactive Legal Consultation Dialogue Evaluation", "authors": "Weikang Yuan,Kaisong Song,Zhuoren Jiang,Junjie Cao,Yujie Zhang,Jun Lin,Kun Kuang,Ji Zhang,Xiaozhong Liu", "background": "个人权利的法律咨询对于保障个人权益及确保法律救济是非常重要的，但由于专业人员短缺，这种服务仍然昂贵且许多个体难以获取。尽管最近大语言模型（LLMs）的发展为实现大规模、低成本的法律援助带来了希望，但现有的系统仍然无法有效应对真实世界咨询过程中的互动性和知识密集性需求。", "innovation": "本文介绍了LeCoDe，这是一个包含真实世界多轮对话的基准数据集，共有3,696场法律咨询对话并包含110,008轮对话，旨在评估并提升LLMs在法律咨询方面的表现。LeCoDe通过从短视频平台收集实时对话，提供了真实多轮的法律咨询对话。进一步地，引入了全面的评估框架，从澄清能力和专业建议质量两个维度评估LLMs的12项指标。通过对各种通用和领域特定LLMs的广泛实验，结果显示即使是最先进的模型如GPT-4在澄清和建议质量上的表现也存在显著挑战，揭示了专业咨询服务复杂性。", "conclusion": "基于这些发现，本文进一步探讨了几种增强LLMs法律咨询能力的策略，基准数据集对于推动法律领域对话系统研究，特别是模拟更真实世界用户-专家互动方面做出了贡献。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09874", "html_url": "https://arxiv.org/abs/2508.09874", "title": "Memory Decoder: 一种预训练的插件式记忆模块", "title_en": "Memory Decoder: A Pretrained, Plug-and-Play Memory for Large Language Models", "authors": "Jiaqi Cao,Jiarui Wang,Rubin Wei,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin", "background": "大型语言模型（LLMs）在通用语言任务中表现出强大的能力，但将其适配到特定领域仍是一个挑战。当前的方法，如领域自适应预训练（DAPT），需要全面参数训练且易导致灾难性遗忘。而检索增强生成（RAG）则因大规模最近邻搜索和更长的上下文而增加了推理延迟。", "innovation": "该论文提出了一种可插拔的预训练记忆模块（Memory Decoder），能够在不修改原始模型参数的情况下实现高效领域的适应。Memory Decoder 使用一个小型的变压器解码器学习模仿外部非参数检索器的行为。经过训练后，Memory Decoder 可以无缝地与具有相同分词器的任何预训练语言模型集成，无需进行特定于模型的修改。实验结果显示，Memory Decoder 能够有效适配 Qwen 和 Llama 模型到三个不同专业领域：生物医药、金融和法律，将困惑度降低 6.17 个百分点。总体来说，Memory Decoder 引入了一个以特别预训练记忆组件为中心的新范式，设计用于特定领域适配。这种记忆架构可以以插件式方式集成，能够在目标领域的多个模型中一致地提升性能。", "conclusion": "Memory Decoder 作为一种新的插件式预训练记忆模块，能够显著提高 LLMs 在特定领域的表现，特别是在不需要对模型进行大量修改的情况下实现领域适应。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.01832", "html_url": "https://arxiv.org/abs/2508.01832", "title": "MLP Memory: 一种基于检索预训练的记忆模块用于大型语言模型", "title_en": "MLP Memory: A Retriever-Pretrained Memory for Large Language Models", "authors": "Rubin Wei,Jiaqi Cao,Jiarui Wang,Jushi Kai,Qipeng Guo,Bowen Zhou,Zhouhan Lin", "background": "大型语言模型在提升事实准确性与知识利用方面采用现代方法时面临一个基本权衡：非参数化的检索增强生成（RAG）提供了灵活的外部知识访问方式，但带来了高推理延迟和浅层集成的问题；而通过LoRA等参数微调方法则存在灾难性遗忘和普遍能力退化的风险。本文背景指出这两种方法各有优缺点，以解决这些问题的需求为切入点。", "innovation": "本文提出了一个名为MLP Memory的轻量级参数模块，该模块能在不直接访问文档的情况下学习进行检索模式的内部化。通过在预训练数据集上模拟最近邻检索行为，MLP Memory被设计为参数可微的记忆组件，实现在完全参数化形式下的检索知识访问优势。通过将预训练的MLP Memory和Transformer解码器通过简单的概率插值进行集成，该方法在WikiText-103和Web数据集上分别获得了17.5%和24.1%的扩展增益，同时还在五个问答基准测试和九项通用自然语言处理任务中分别实现了12.3%的相对改进和5.2分的绝对增益。此外，MLP Memory在HaluEval上减少了多达10分的虚幻声明，并且比RAG快2.5倍，同时保持了更高的准确性。", "conclusion": "我们发现，参数化的检索模式学习在高效推理和有效知识访问之间架起了一座桥梁，提供了一种RAG和微调方法之间的实用替代方案。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.19634", "html_url": "https://arxiv.org/abs/2507.19634", "title": "MCIF：来自科学讲座的多模态跨语言指令跟随基准", "title_en": "MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks", "authors": "Sara Papi,Maike Züfle,Marco Gaido,Beatrice Savoldi,Danni Liu,Ioannis Douros,Luisa Bentivogli,Jan Niehues", "background": "近年来，大型语言模型的发展催生了能够整合文本、语音和视觉内容的多模态大语言模型（MLLMs）。随着MLLMs从单一语言的特定任务系统发展成为通用指令跟随模型，一个关键挑战在于评估其在不同语言和模态下的综合能力，特别是在长文本和短文本中的表现。现有的基准测试在多语言和多模态评估方面存在局限性：它们通常局限于英语，主要关注单一模态，依赖于短文本，或缺乏人工注释——这阻碍了对模型性能的全面评估。MCIF基准旨在填补这些空白，为多模态大语言模型在跨语言和多模态环境下的指令跟随能力提供全面的评估。MCIF涵盖了语音、视觉和文本三种核心模态，以及英语、德语、意大利语和汉语四种语言，为评估模型在不同语言和跨模态语境下的解释指令能力和结合多模态上下文信息的能力提供了全面的框架。", "innovation": "MCIF是第一个基于科学讲座的多语言人工标注基准，旨在评估多模态大语言模型在跨语言和多模态环境下的指令跟随能力，涵盖长文本和短文本输入。它包含了三种核心模态（语音、视觉和文本）以及四种语言（英语、德语、意大利语和汉语），为评估模型在不同语言和语境下的能力提供了一个全面的框架。MCIF采用CC-BY 4.0许可，鼓励开放研究和多模态大语言模型的发展。", "conclusion": "MCIF为评估多模态大语言模型的多语言和多模态指令跟随能力提供了一个新的基准，填补了现有基准在评估多语言与多种模态综合能力方面的不足。它通过涵盖英语、德语、意大利语和汉语四种语言，以及语音、视觉和文本三种核心模态，使得对模型进行全面评估成为可能。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19529", "html_url": "https://arxiv.org/abs/2508.19529", "title": "针对扩散语言模型的块级SFT：缓解双向注意与自回归解码之间的矛盾", "title_en": "Blockwise SFT for Diffusion Language Models: Reconciling Bidirectional Attention and Autoregressive Decoding", "authors": "Bowen Sun,Yujun Cai,Ming-Hsuan Yang,Yiwei Wang", "background": "离散扩散语言模型在文本生成方面显示出强大的潜力，但标准的监督微调（SFT）与它们的半自回归推理方式不匹配：训练时随机在整个响应中掩蔽令牌，而推理时则按顺序生成固定大小的块。这种不匹配在生成过程中引入了噪声的前缀和泄漏的后缀，偏离了所需的块级似然性。", "innovation": "我们提出了一种块级SFT方法，该方法将响应划分为固定大小的块，每一步选择一个活动块进行随机掩蔽，冻结所有前导令牌，并隐藏所有后续令牌。损失只在活动块上计算，直接模拟块级解码过程。实验在GSM8K、MATH和MetaMathQA上证明，在相同的计算量或令牌预算下，块级SFT比传统SFT具有一致性的收益。块大小一致性和消融实验表明，改进源自训练和推理之间的忠实对齐，而不是偶然的掩蔽效果。", "conclusion": "结果突显了在扩散语言模型中监督粒度与解码流程相匹配的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16449", "html_url": "https://arxiv.org/abs/2509.16449", "title": "PersonaMatrix: 一种面向角色感知的法律摘要评估方法", "title_en": "PersonaMatrix: A Recipe for Persona-Aware Evaluation of Legal Summarization", "authors": "Tsz Fung Pang,Maryam Berijanian,Thomas Orth,Breanna Shi,Charlotte S. Alexander", "background": "法律文件通常很长、内容密集且难以理解，无论是普通人还是法律专家都是如此。尽管自动化摘要技术有潜力改善人们对法律知识的访问，现有的基于任务的评估方法往往忽略了不同用户和利益相关方的需求差异。因此，需要开发一种工具来兼顾诉讼代理人的技术性需求和自我帮助平民的研究需求。", "innovation": "提出PersonaMatrix（角色矩阵），这是一种由六个角色（包括法律和非法律用户）视角组成的评估框架，用于评分摘要。还提出了一个控制维度变化的试点数据集，该数据集具有不同的深度、易用性和程序细节，以及多样性覆盖率指数（DCI），以揭示面向角色感知和面向角色不感知的评估者在法律摘要方面的不同最优解。", "conclusion": "这项工作使我们能够改进针对专家和非专家用户的法律AI摘要系统，有可能增加法律知识的访问。相关信息的代码库和数据在GitHub上公开可用。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.04462", "html_url": "https://arxiv.org/abs/2509.04462", "title": "评估GPT-5在生物医学自然语言处理领域的性能", "title_en": "Benchmarking GPT-5 for biomedical natural language processing", "authors": "Yu Hou,Zaifu Zhan,Min Zeng,Yifan Wu,Shuang Zhou,Rui Zhang", "background": "生物医学文献和临床记录在自然语言理解上提出了复杂挑战，包括精确实体识别、文档合成和多步诊断推理。本文扩展了一个统一基准，用于评估GPT-5和GPT-4o在零、一和五次提示下的表现，涵盖五个核心生物医学NLP任务：命名实体识别、关系提取、多标签文档分类、总结和简化，以及九个扩展的生物医学QA数据集，涉及事实知识、临床推理和多模态视觉理解。", "innovation": "使用标准化提示、固定解码参数和一致的推理管道来评估模型性能、延迟和按令牌归一化的成本。GPT-5 一贯优于 GPT-4o，在推理密集型数据集中如MedXpertQA和DiagnosisArena表现出显著提升，且在多模态QA中稳定改进。在核心任务中，GPT-5 达到了更好的化学实体识别和ChemProt分数，但在疾病实体识别和摘要方面仍低于领域调优的基本模型。尽管生成较长输出，GPT-5 的延迟基本相同，并且每个正确预测的有效成本降低了30至50%。细粒度分析揭示了诊断、治疗和推理子类型的改进，但边界敏感的提取和证据密集的总结仍然具有挑战性。", "conclusion": "GPT-5 接近部署阶段的性能，在准确性、可解释性和经济效率方面提供了良好的平衡。结果支持分层提示策略：直接提示用于大规模或成本敏感的应用，思维方式支架用于分析上复杂或高风险的情景，强调在关键的精度和事实准确性方面仍需综合解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.11145", "html_url": "https://arxiv.org/abs/2509.11145", "title": "Text2Mem: 一种统一的记忆操作语言以构建记忆操作系统", "title_en": "Text2Mem: A Unified Memory Operation Language for Memory Operating System", "authors": "Yi Wang,Lihai Yang,Boyu Chen,Gongyi Zou,Kerun Xu,Bo Tang,Feiyu Xiong,Siheng Chen,Zhiyu Li", "background": "现有的基于大语言模型的代理越来越多地依赖记忆来维持长期交互，但现有框架仍存在局限性。大多数框架只暴露了几种基本的操作，例如编码、检索和删除，而诸如合并、提升、降级、拆分、锁定和过期等更高级的操作要么缺失要么不一致地支持。此外，没有正式和可执行的记忆命令规范，使得关于操作的规则和生命周期管理不够明确，导致系统间的行为不可预测。", "innovation": "本文介绍了Text2Mem，这是一种统一的记忆操作语言，提供了一种从自然语言到可靠执行的标准途径。Text2Mem定义了一个紧凑且表达能力强的操作集，包括编码、存储和检索。每个指令由一个基于JSON的模式实例表示，带有必要的字段和语义不变量，解析器将其转换为带有标准化参数的类型化操作对象。执行之前，验证器确保正确性，而适配器将类型化对象映射到SQL原型后端或实际内存框架。嵌入模型的服务（如嵌入或总结）只有在需要时才进行集成。所有结果都是通过统一的执行契约返回。该设计确保了安全、确定性和异构后端之间的可移植性。此外，还概述了Text2Mem Bench，这是一种计划中的基准测试，可以分离模式生成和后端执行，以实现系统性评估。", "conclusion": "这些组成部分共同建立了记忆控制在代理中的第一个标准化基础。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.15640", "html_url": "https://arxiv.org/abs/2509.15640", "title": "多语言LLM提示策略在医学英越机器翻译中的应用", "title_en": "Multilingual LLM Prompting Strategies for Medical English-Vietnamese Machine Translation", "authors": "Nhu Vo,Nu-Uyen-Phuong Le,Dung D. Le,Massimo Piccardi,Wray Buntine", "background": "在越南，医学英语-越南语机器翻译（En-Vi MT）对于获取医疗服务和沟通至关重要，然而越南语仍然是一种资源不足且研究较少的语言。因此，需要系统地评估多语言大语言模型（LLM）对医学En-Vi MT的表现，特别是在MedEV数据集上的提示策略，包括零样本、少样本以及通过Meddict字典增强的提示方法，其中Meddict是英越医学词汇库。", "innovation": "研究首次全面评估了多种提示策略（零样本、少样本和基于字典增强的提示）在多语言大语言模型中的效果。研究发现，模型大小是决定性能的主要因素：相比少样本提示，虽然大模型在零样本情况下表现更佳，但字术语意识的提示和基于嵌入的例证检索在特定领域的翻译中始终表现出持续的改进效果。这一发现强调了多语言大语言模型在医学En-Vi MT中的潜力与当前局限性.", "conclusion": "研究表明，零样本提示驱动了大模型的优异表现，然而，少样本提示仅带来了边际改进。相反，术语感知的提示和基于嵌入的示例检索始终在细分领域翻译中表现出改进效果，这提示了这些方法在未来多语言大语言模型中的应用前景。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19614", "html_url": "https://arxiv.org/abs/2508.19614", "title": "LFD：在检索增强生成中结合中间层和最后一层解码以利用外部知识", "title_en": "LFD: Layer Fused Decoding to Exploit External Knowledge in Retrieval-Augmented Generation", "authors": "Yang Sun,Zhiyong Xie,Dan Luo,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li,Lixin Zou", "background": "检索增强生成（RAG）通过将外部知识整合到大型语言模型中，提高了对下游任务的适应性，并能够进行信息更新。最近的实证研究表明，向检索到的相关文档中注入噪声可以意外地促进对外部知识的利用并提升生成质量。尽管这一现象看似反常并且在实践中难以应用，但它为详细控制和严谨分析大型语言模型如何整合外部知识提供了可能。因此，本文深入研究了噪声注入的影响，提出了分层融合解码（LFD）策略，以在外部知识的利用中获得最佳效果。", "innovation": "探究了噪声对RAG系统的正向影响，首次提出了分层融合解码（LFD）策略，该策略通过结合中间层和最后一层的表示，直接促进了外部事实知识的利用。还提出了一种内部知识评分（IKS）标准，用于选择在后期层中具有最低IKS值的层。实验结果显示，LFD帮助RAG系统以最低的代价有效地展现出检索到的上下文知识。", "conclusion": "本文通过提出分层融合解码（LFD）策略，在保留RAG系统中检索到的上下文知识的同时，优化了外部知识的利用。该策略有助于深入理解大型语言模型如何结合外部知识，并为实际应用提供了具体的操作指导。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.19271", "html_url": "https://arxiv.org/abs/2509.19271", "title": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "title_en": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "authors": "Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione", "background": "现有的意图分类模型取得了显著进展，但主要集中在资源丰富的语言数据集上，这导致低资源语言和地区在这些技术中的缺陷。例如，在塞内加尔等地区， Wolof语言被90%的人口使用，但识字率却达到42%，这是一个典型的低资源语言地区。Wolof语言在西非地区被超过1000万人使用。因此，存在一个明显的需求来支持这些语言和地区的数据集开发，以促进机器学习在这些语言中的应用，包括意图分类。", "innovation": "本文介绍了一个新的数据集Wolof Banking Speech Intent Classification Dataset (WolBanking77)，以支持学术研究中的意图分类任务。WolBanking77包含9,791个文本句子和超过4小时的语音数据，覆盖了银行领域内的数据。文中还对不同的模型基线进行了实验，包括文本和语音最先进的模型，并取得了令人鼓舞的结果。此外，还对数据集内容进行了深入的分析，并报告了NLP和ASR模型在WolBanking77数据集上训练的F1分数和词错误率指标，并进行了模型间的比较。", "conclusion": "研究结果非常有前景，表明WolBanking77数据集在当前的任务中表现出色，并揭示了该数据集为低资源语言地区带来技术进步的潜力。已开源数据集和代码以促进进一步的研究合作。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07774", "html_url": "https://arxiv.org/abs/2510.07774", "title": "使用评分标准奖励治愈大型语言模型数学推理中的奇迹步骤", "title_en": "Curing Miracle Steps in LLM Mathematical Reasoning with Rubric Rewards", "authors": "Youliang Yuan,Qiuyang Mang,Jingbang Chen,Hong Wan,Xiaoyuan Liu,Junjielong Xu,Jen-tse Huang,Wenxuan Wang,Wenxiang Jiao,Pinjia He", "background": "目前，大型语言模型进行数学推理时常常使用以结果为导向的奖励机制，仅奖励最终答案。实验观察到这种机制容易导致奖励作弊，高估模型的推理能力。这表现为很多解决方案使用不合理的推理过程却得到了正确的最终答案。对这些失败模式进行了系统分析，发现了一些特定模式，比如“奇迹步骤”，即模型突然正确输出结果而没有经过有效的推理过程。这种现象与模型的记忆化行为有关。", "innovation": "提出了一种评分标准奖励模型（RRM），这是一种过程导向的奖励机制，能够根据特定问题的评分标准评估整个推理过程，提供细粒度、准确的奖励（0-1），明确惩罚逻辑错误并鼓励严谨的推理。将RRM集成到强化学习管道中，在四个数学基准测试中更优于只关注结果的监督。实验证明了奖励解题过程的必要性，不仅能提高模型的准确性，还能提高模型的可靠性。", "conclusion": "本研究证明，通过RRM奖励解决过程是提升模型准确性和可靠性的重要策略。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.02855", "html_url": "https://arxiv.org/abs/2510.02855", "title": "基于约束满足方法的Wordle：新型启发式算法与跨语言验证", "title_en": "Constraint Satisfaction Approaches to Wordle: Novel Heuristics and Cross-Lexicon Validation", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel", "background": "Wordle是一个算法丰富的测试平台，现有的解决程序主要依靠信息论熵最大化或基于频率的启发式方法来解决约束满足问题（CSP），但没有正式处理约束条件。本文描述了第一个包含新颖的约束感知求解策略的Wordle的全面CSP表述。", "innovation": "提出了CSP-Aware Entropy，该方法在传播约束之后计算信息增益，而不是在原始候选集上；并引入了一个概率CSP框架，将贝叶斯单词频率先验知识与逻辑约束相结合。通过评估2,315个英文单词，CSP-Aware Entropy达到了99.9%的成功率和平均3.54次猜测，比前向检查具有统计显著性的1.7%的改善，且运行时间减少了46%。在10%的噪声下，CSP意识方法保持了5.3个百分点的优势（29.0% 对比 23.7%，p=0.041），而概率性CSP通过约束恢复机制在所有噪音水平（0-20%）上实现了100%的成功率。在500个西班牙语单词的跨词库验证中，概率性CSP达到了88%的成功率，无需特定语言调整，这表明尽管存在11.2个百分点的差距，但基本CSP原理在不同语言之间依然有效。", "conclusion": "结合正式的CSP处理、约束感知启发式、概率性逻辑结合、稳健性分析以及跨词库验证，本文建立了新的基准性能标准，表明原则性的约束满足技术在结构化谜题求解领域优于传统信息论和基于学习的方法。开源实现包括34个单元测试，覆盖率为91%，为CSP研究提供了可重复的基础设施。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.07686", "html_url": "https://arxiv.org/abs/2510.07686", "title": "语言模型的规格测试揭示了不同模型的性格差异", "title_en": "Stress-Testing Model Specs Reveals Character Differences among Language Models", "authors": "Jifan Zhang,Henry Sleight,Andi Peng,John Schulman,Esin Durmus", "background": "大型语言模型在从AI宪法和模型规范中训练时，已经建立了行为规范和伦理原则。然而，这些规范也面临重要的挑战，包括原则之间的内部冲突以及对复杂场景的覆盖不足。这项研究提出了一种系统的方法来测试模型需求规格，自动识别当前模型规范中大量原则矛盾和解释不清的情况。通过生成迫使模型在价值观之间做出明确权衡的场景来测试现有的模型规范，研究者使用一个全面的分类法生成了各种价值权衡场景，使模型在无法同时满足的合法原则之间做出选择。这些场景下的多款前沿语言模型被用于测试，通过价值观分类评分来衡量行为分歧。研究发现，超过70,000个场景中表现出显著的行为分歧，这在很大程度上预测了模型规范中的潜在问题。", "innovation": "研究提出了一种系统的方法来测试和评估模型规范，这种方法可以自动生成迫使模型在价值观之间进行明确权衡的场景。通过生成各种价值权衡场景，并使用全面的分类法，使模型在无法同时满足的合法原则之间做出选择。这种方法能够自动识别多种原则上的直接矛盾和解释上的模糊性，为语言模型的规格设计提供了新的参考。该研究还通过数据分析揭示了不同模型的价值优先级和差异，为模型显著的不一致行为提供了解释，揭示了其中存在的明确不对齐和假阴性拒绝情况。", "conclusion": "研究揭示了在当前模型规格中，存在大量的直接矛盾和解释上的模糊性，这些问题是导致模型在复杂场景中作出不同决策的核心因素。通过这种详细的测试和分析，未来可以更好地规范语言模型的设计，减少不必要的分歧，提高模型的一致性和可靠性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18684", "html_url": "https://arxiv.org/abs/2510.18684", "title": "MLMA：基于Mamba架构的多语言自动语音识别", "title_en": "MLMA: Towards Multilingual ASR With Mamba-based Architectures", "authors": "Mohamed Nabih Ali,Daniele Falavigna,Alessio Brutti", "background": "多语言自动语音识别（ASR）仍然是一个具有挑战性的任务，尤其是在平衡不同语言性能时更为困难。尽管最近在序列建模方面的进展表明，Transformer之外的架构可能在模型的扩展性和效率上具有优势。", "innovation": "提出了MLMA（MLMA），该方法利用了Mamba架构--一种针对长时间序列处理优化的有效状态空间模型--用于多语言ASR。MLMA通过Mamba隐式地整合了语言意识条件和共享表示，以支持跨多种语言的鲁棒识别。实验表明，MLMA在多语言基准测试中的性能与基于Transformer的架构相当。", "conclusion": "MLMA的结果强调了Mamba作为大规模、高效且准确的多语言语音识别骨干网络的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19167", "html_url": "https://arxiv.org/abs/2510.19167", "title": "You Are Rejected!: 一项关于大型语言模型参与招聘评估的经验研究", "title_en": "\"You Are Rejected!\": An Empirical Study of Large Language Models Taking Hiring Evaluations", "authors": "Dingjie Fu,Dianxing Shi", "background": "随着互联网的普及和人工智能技术的飞速发展，科技公司面临每年巨大的软件和算法工程师需求。为了高效地筛选出高潜力的候选人，这些公司通常会建立多级选拔流程，其中包括一个标准化的招聘评估，用来评估候选人的专业技能。受到大型语言模型（LLMs）在编码和推理任务上展现出的能力启发，本文探讨了一个关键问题：LLMs能否成功通过这些招聘评估？", "innovation": "本文通过细致分析一个广泛使用的专业评估问卷，利用最新的LLMs生成回答并评估其表现，挑战了前人认为LLMs适合成为理想工程师的观点。研究成果揭示了模型生成的答案与公司参考解决方案之间存在显著差异，明确指出所有评估的LLMs都无法通过招聘评估。", "conclusion": "本文的经验研究表明，无论使用何种最先进的大型语言模型，在标准化的专业招聘评估中，所有评估的LLMs均未能通过。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18779", "html_url": "https://arxiv.org/abs/2510.18779", "title": "KAT-Coder 技术报告", "title_en": "KAT-Coder Technical Report", "authors": "Zizheng Zhan,Ken Deng,Xiaojiang Zhang,Jinghui Wang,Huaixi Tang,Zhiyi Lai,Haoyang Huang,Wen Xiang,Kun Wu,Wenhao Zhuang,Minglei Zhang,Shaojie Wang,Shangpeng Yan,Kepeng Lei,Zongxian Feng,Huiming Wang,Zheng Lin,Mengtong Li,Mengfei Xie,Yinghan Cui,Xuxing Chen,Chao Wang,Weihao Li,Wenqiang Zhu,Jiarong Zhang,Jingxuan Xu,Songwei Yu,Yifan Yao,Xinping Lei,C. Zhang,Han Li,Junqi Xiong,Zuchen Gao,Dailin Li,Haimo Li,Jiaheng Liu,Yuqun Zhang,Junyi Peng,Haotian Zhang,Bin Chen", "background": "最近的大语言模型（LLMs）进展在自主编码方面取得了进步，即模型独立地在交互式软件开发流程中推理、规划和行动。然而，从静态文本训练跨越到动态现实世界的自主执行仍然存在核心挑战。", "innovation": "KAT-Coder 是一种通过多阶段课程训练的大型自编码模型，涵盖了中期训练、监督微调 (SFT)、强化微调 (RFT) 以及强化到部署适配。中期阶段通过真实软件工程数据和合成的自主交互增强推理、规划和反思能力。SFT 阶段构建了一个包含二十种编程语言、十种开发环境和十种任务模式的百万样本数据集。RFT 阶段引入了一种新颖的多真实奖励公式，用于稳健且高效的数据策略优化。最终，强化到部署阶段使用掩码错误的 SFT 和树状轨迹训练来适应生产级 IDE 环境。", "conclusion": "这些阶段使 KAT-Coder 能够实现稳健的工具使用可靠性、指令对齐和长上下文推理，为现实世界智能编码代理的部署奠定了基础。KAT 系列 32B 模型 KAT-Dev 已开源，地址为 this https://kat-coder.github.io/kat/."}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.17930", "html_url": "https://arxiv.org/abs/2510.17930", "title": "诊断NER模型扩展中的表示动态", "title_en": "Diagnosing Representation Dynamics in NER Model Extension", "authors": "Xirui Zhang,Philippe de La Chevasnerie,Benoit Fabre(papernest)", "background": "需要将命名实体识别（NER）模型扩展到无噪声口语数据中的新个人身份信息（PII）实体，这是一个常见需求。研究发现，在共同微调BERT模型于标准语义实体（PER、LOC、ORG）和新构建的基于模式的PII（EMAIL、PHONE）时，原始类别几乎没有受到影响。这表明模型可以实现“和平共存”，即模型可能同时利用语义和形态特征机制。使用增量学习方法进一步验证，发现结果包括：（1）地名（LOC）实体由于与新PII有代表性的重叠而特别脆弱。（2）存在一种“逆O-tag表示漂移”，模型初始训练时将模式标记为‘O’，这使得新的学习被困，只有解冻‘O’标签分类器可以帮助背景类别适应并释放这些模式特征。这项工作提供了一种机制性的诊断，展示了特征独立性、表示重叠和‘O’标签的可塑性。这些是基于从以下数据源收集的数据完成的研究结果：[数据分析网站链接]。", "innovation": "研究中提出了不同实体之间的表示重叠问题，尤其是地名与新PII之间的重叠，发现这些重叠可能导致某种形式的内部掩蔽或阻止模型学习新PII。研究还发现了一种机制，即通过解冻‘O’标签分类器，可以帮助模型释放这些新学习到的片段。这为处理这种内部冲突提供了一个新的视角，并通过数据驱动的诊断方法深化了我们对模型适应的理解。", "conclusion": "研究发现在共同微调BERT模型时，原始类别不受影响，表明模型可以通过独立利用语义和形态特征机制来实现“和平共存”。此外，地名实体特别脆弱，因为其表示与新PII有重叠。研究发现了逆O-tag表示漂移的现象，解冻O标签分类器可以解决这一问题。因此，这项研究提供了一种机制性诊断，展示了特征独立性、表示重叠和O标签可塑性的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19782", "html_url": "https://arxiv.org/abs/2510.19782", "title": "通过模型合并适应代码混排任务的多语言模型", "title_en": "Adapting Multilingual Models to Code-Mixed Tasks via Model Merging", "authors": "Prashant Kodali,Vaishnavi Shivkumar,Swarang Joshi,Monojit Choudhary,Ponnurangam Kumaraguru,Manish Shrivastava", "background": "研究将模型合并作为与传统适应策略相比的实用替代方案，用于代码混排自然语言处理（NLP）。基于一个多语言基础模型，作者通过连续预训练（CPT）在未标记的代码混排文本上进行操作，获得一个适应性检查点，将其与基础模型合并，并在下游任务数据上进行微调（FT）。该研究评估了XLM-R和Llama-3.2-1B模型在英语-印地语（En-Hi）和英语-西班牙语（En-Es）的句子分类（情感和仇恨言论）任务中的表现。", "innovation": "提出了一种新的适应策略：多语言模型合并。通过连续预训练（CPT），基础模型和适应性检查点的合并，以及下游任务数据上的微调（FT）。结果显示合并后的模型在F1分数上比全微调和CPT->FT高出2-5个点，说明未标记数据通过合并比通过CPT单独使用更有效地利用。使用更大的LLM（如Llama-3.3-70B）的零样例/少量样本提示效果不如全微调和合并的检查点，指出了上下文学习在代码混排输入方面的局限性。合并的检查点在跨对转移时比单一语言基线更强，表明代码混排知识是低资源对的更可靠基础。", "conclusion": "本文提出了针对常见数据集使用场景的模型适应配方（仅标记数据；标记+未标记数据；只转移），并讨论了更广泛任务和更大模型的限制和扩展考虑。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.01243", "html_url": "https://arxiv.org/abs/2501.01243", "title": "Face-Human-Bench: 多模态助手中面部和人体理解的综合基准", "title_en": "Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants", "authors": "Lixiong Qin,Shilong Ou,Miaoxuan Zhang,Jiangning Wei,Yuhang Zhang,Xiaoshuai Song,Yuchen Liu,Mei Wang,Weiran Xu", "background": "面部和人类是社交互动中的重要元素，广泛出现在日常生活中的照片和视频中。多模态助手需要理解和处理这些信息以提高响应质量并扩大应用范围。当前，多模态助手社区缺乏对面部和人体理解能力的全面科学评估。因此，本文通过提出一个分层的能力分类体系，并基于此分类体系收集图像和注释，构建了一个半自动的数据管道来生成新的基准测试，从而填补了这一空白。", "innovation": "本文首次提出一个分层能力分类体系，包括三个层面的能力，并基于此分类体系收集图像和注释，构建了一个支持英语和中文的开发集和测试集的半自动数据管道，用于新的基准测试。此外，本文对25个主流多模态大型语言模型进行了评估，旨在研究能力之间的关系、目标相对位置对性能的影响以及Chain of Thought（CoT）提示对性能的影响，探究哪些多模态大型语言模型的能力需要通过专业模型来补充。", "conclusion": "Face-Human-Bench 数据集和评估代码已公开，未来的研究可以进一步探索和完善多模态助手的面部和人体理解能力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.15312", "html_url": "https://arxiv.org/abs/2510.15312", "title": "通过推测解码和NPU协调执行加速移动语言模型", "title_en": "Accelerating Mobile Language Model via Speculative Decoding and NPU-Coordinated Execution", "authors": "Zhiyang Chen,Daliang Xu,Haiyang Shen,Mengwei Xu,Shangguang Wang,Yun Ma", "background": "在移动设备上提高大型语言模型（LLMs）的效率，利用本地数据的上下文信息实现个性化和任务感知的生成，能支持智能助手和UI代理等应用。然而，由于逐令牌生成过程固有的内存限制特性，现阶段在移动设备上的前置填充虽已取得进展，但这一过程仍然存在高延迟和硬件利用率低的问题。基于此背景，本文提出了一种移动推理框架，通过结合推测解码与动态硬件调度加速移动设备上的上下文感知文本生成。", "innovation": "该移动推理框架引入了三个协同工作的组件：(1) 适应性执行调度，动态平衡计算图在前置填充和解码阶段的应用；(2) 上下文对齐草稿，通过轻量级在线校准提升推测效率；(3) 硬件高效草稿扩展，通过重用和扩展中间序列提高并行处理能力并减少验证成本。实验结果显示，相比现有移动推理解决方案，该框架在生成速度上有高达3.8倍的提升，在能效上有高达4.7倍的提升。", "conclusion": "该框架在多个智能手机和代表性负载上的实验表明，在生成速度和能效方面取得显著提升，这进一步验证了每个优化的贡献。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.02770", "html_url": "https://arxiv.org/abs/2502.02770", "title": "Twilight: 采用分层 top-p 裁剪实现自适应注意力稀疏", "title_en": "Twilight: Adaptive Attention Sparsity with Hierarchical Top-$p$ Pruning", "authors": "Chaofan Lin,Jiaming Tang,Shuo Yang,Hanshuo Wang,Tian Tang,Boyu Tian,Ion Stoica,Song Han,Mingyu Gao", "background": "利用注意力稀疏性加速长上下文大规模语言模型(LLMs)已成为研究热点。然而，当前的算法如稀疏注意力或键值(KV)缓存压缩，通常采用固定预算，这在实际部署中会带来挑战，因为它们未能考虑到现实世界场景中的动态特性，即在不同情况下准确性和效率的最佳平衡可能会有很大差异。", "innovation": "本文发现将 top-$p$ 采样（核子采样）用于稀疏注意力，可以实现自适应预算。基于此，提出了 Twilight 框架，可在任何现有稀疏注意力算法中引入自适应稀疏性，而不牺牲其准确性。实验证明，Twilight 可以自适应地裁剪高达 98% 的冗余令牌，从而在自注意力操作中加速 15.4 倍，在端到端每令牌延迟中加速 3.9 倍。", "conclusion": "Twilight 框架可以在不牺牲准确性的情况下为任何现有的稀疏注意力算法引入自适应稀疏性，显著提高了长上下文 LLM 解码效率，并能自适应地剪枝多余的令牌。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19733", "html_url": "https://arxiv.org/abs/2510.19733", "title": "Zhyper: 因子超网络模型在条件化大语言模型微调中的应用", "title_en": "Zhyper: Factorized Hypernetworks for Conditioned LLM Fine-Tuning", "authors": "M. H. I. Abdalla,Zhipin Wang,Christian Frey,Steffen Eger,Josif Grabocka", "background": "大语言模型（大语言模型LLM）的条件化是指指导LLM生成符合特定文化规范、特定政治倾向价值观或其他指定文本语义内容。然而，提示工程无法保证LLM的行为符合所需的条件化，因为预训练和对齐数据集存在归纳偏见。此前的工作主要通过直接条件化LoRA权重来微调LLM，但这种方法引入了大量的参数。因此，迫切需要一种参数效率高且能够生成上下文感知LoRA适配器的方法，以便实现更高效和可靠的条件化LLM微调。", "innovation": "本文提出了Zhyper，一种参数效率的因子化超网络框架，可以从文本描述中生成上下文感知的LoRA适配器。实验结果显示，Zhyper在多个基准上的性能与最先进的基线相比相当，但参数数量减少了多达26倍。此外，Zhyper还被扩展到文化对齐，展示了在跨领域设置中的更好泛化能力和对细微语境价值更准确的捕捉能力。", "conclusion": "本文提出的Zhyper框架能够在条件化大语言模型微调中实现高效率，通过因子化超网络从文本描述中生成上下文感知的LoRA适配器，从而显著减少参数数量并提升性能。进一步研究还展示了Zhyper在文化对齐方面的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.09933", "html_url": "https://arxiv.org/abs/2502.09933", "title": "MIR-Bench：在多种输入输出示例驱动下，您的大语言模型能否进行复杂模式识别？", "title_en": "MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?", "authors": "Kai Yan,Zhan Ling,Kang Liu,Yifan Yang,Ting-Han Fan,Lingfeng Shen,Zhengyin Du,Jiecao Chen", "background": "模式识别能力是从示例中识别模式并在新示例中应用的能力，这是普遍智能的基础，心理学和人工智能研究者都有广泛的研究。已经提出了许多基准来衡量大语言模型在这种能力上的表现；然而，这些基准主要集中在少样本设置（通常少于10个），缺乏长期上下文信息整合的评估。另一方面，大语言模型上下文长度的不断增长引入了新型的多样本即席学习（many-shot In-Context Learning，ICL）范式，它通过几百到几千个示例解决新任务，无需昂贵且低效的微调。然而，多样本评估往往集中在分类上，流行的长上下文大语言模型任务如Needle-In-A-Haystack（NIAH）很少要求复杂的智力来整合许多信息。", "innovation": "提出了一种新的多样本即席推理基准MIR-Bench，该基准要求大语言模型通过底层不同数据格式的输入-输出示例预测输出。MIR-Bench探讨了多样本即席推理中的许多新颖问题，包括扩增效应、鲁棒性、归纳推理与非归纳推理、检索增强生成（RAG）、编码进行归纳推理、跨领域泛化能力等。", "conclusion": "MIR-Bench是第一个专注于复杂模式识别的多样本即席推理基准，它评估了大语言模型在多种输入输出示例驱动下的推理能力，为进一步研究大语言模型的能力提供了新的视角和基础。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.13837", "html_url": "https://arxiv.org/abs/2504.13837", "title": "RL真的能够激励LLMs超越基模型的推理能力吗？", "title_en": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?", "authors": "Yang Yue,Zhiqi Chen,Rui Lu,Andrew Zhao,Zhaokai Wang,Yang Yue,Shiji Song,Gao Huang", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 最近已经在增强语言模型（LLMs）在数学和编程任务上的推理性能上取得了显著成果，RLVR 认为可以通过自我持续改进让 LLMs 获取新的推理能力，超越基模型。本文系统研究了 RLVR 的现状，特别是在不同模型族、RL 算法、数学、编码和视觉推理基准上的表现，并发现基模型的推理能力限制了 RLVR 的效果。", "innovation": "本文通过定量分析，发现当前流行的六种 RLVR 算法在最大化基模型潜力方面表现相似且差距较大。此外，研究揭示了传授机制可以引入新的推理模式，真正扩展模型的推理能力。", "conclusion": "当前 RLVR 方法并未完全实现出RL 能够激励LLMs获取真正新颖的推理能力。这突出了一种改进的 RL 框架的需求来激发这一潜力，如连续放大和多轮双向交互。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2408.15172", "html_url": "https://arxiv.org/abs/2408.15172", "title": "X-Reflect: 用于多模态推荐的交叉反思提示", "title_en": "X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation", "authors": "Hanjia Lyu,Ryan Rossi,Xiang Chen,Md Mehrab Tanjim,Stefano Petrangeli,Somdeb Sarkhel,Jiebo Luo", "background": "大规模语言模型（LLMs）已被证明能够增强项目描述的丰富性，从而提高推荐系统的准确性。然而，现有的大多数方法要么仅依赖文本提示，要么采用基本的多模态策略，这些策略未能充分利用文本和视觉模态之间的互补信息。因此，该研究旨在提出一种新的方法，以解决这些局限性。", "innovation": "本文提出了一种名为X-Reflect的新框架，通过提示多模态大规模语言模型（MLLMs）来明确识别和解决文本与图像之间的支持和矛盾信息。通过捕获两种模态中的细微见解，这种方法生成了更加全面和上下文丰富的物品表示。该研究还在两个广泛使用的基准测试上进行了大量实验，证明了该方法在下游推荐准确率上优于现有的提示基准。此外，研究还发现文本-图像不相似性与推荐性能之间存在U形关系，这表明在多模态推荐中应根据情况应用多模态提示。", "conclusion": "本文强调了整合多模态信息的重要性，并提出了一种有效的方法，以提高多模态推荐系统中的项目理解。为了支持高效的实时推理，X-Reflect-keyword还引入了轻量级变体，使用关键词总结图像内容，并以较小的骨干网络替换基础模型，实现了近50%的输入长度减少，同时保持竞争力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.10465", "html_url": "https://arxiv.org/abs/2505.10465", "title": "超定位产生稳健的神经尺度效应", "title_en": "Superposition Yields Robust Neural Scaling", "authors": "Yizhou Liu,Ziming Liu,Jeff Gore", "background": "今天的大型语言模型（LLMs）的成功归因于较小模型不如大模型性能好的观察。然而，这种神经网络规模法则背后的原因——即损失随着模型规模以幂律方式下降，仍然不明确。本文探讨了表示超定位的概念，认为大模型性能优于小模型的原因之一是它们表示了比其维度更多的特征。通过 Anthropic 的玩具模型和权重衰减方法，研究了损失随模型尺寸的变化。研究表明，当表示超定位较弱时，损失仅在数据特征频率为幂律分布时遵循幂律；而当表示超定位较强时，损失在广泛的频率分布下会与模型维度成反比关系。", "innovation": "本文提出了表示超定位的概念，并通过Anthropic的玩具模型和实验证明了该理论。具体而言，利用权重衰减控制超定位的程度，研究了损失随模型尺寸的变化规律。该研究揭示了在不同超定位强度下，损失的不同变化机制，对于理解和优化神经网络尺度法则具有重要意义。", "conclusion": "研究表明，开放源代码的大型语言模型处于强表示超定位区域，且它们的损失随模型维度呈反比关系，这一特性与Chinchilla的规模法则一致。本文结果识别出表示超定位是神经网络规模法则的主要驱动力，为研究神经网络规模法则何时能够改进及何时失效提供了见解。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15034", "html_url": "https://arxiv.org/abs/2505.15034", "title": "RL Tango: 同时强化生成器和验证器以提高语言推理", "title_en": "RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning", "authors": "Kaiwen Zha,Zhengqi Gao,Maohao Shen,Zhang-Wei Hong,Duane S. Boning,Dina Katabi", "background": "增强学习（RL）最近成为提高大型语言模型（LLM）推理能力的一种有吸引力的方法，其中LLM生成器由验证器（奖励模型）引导。目前，LLM的RL后训练方法通常使用固定的验证器（基于规则或冻结的预训练）或通过监督微调（SFT）进行判别训练。这些设计容易受到奖励欺骗的影响，并且无法很好地泛化到其训练分布之外。", "innovation": "Tango是一个新颖的框架，它通过交替训练LLM生成器和验证器的方式使用RL。Tango的核心创新在于其过程层面的生成型LLM验证器，该验证器通过RL训练并与生成器共同进化。验证器仅基于结果层面的验证正确性奖励进行训练，无需显式的过程层面标注。", "conclusion": "实验表明，Tango的两个组成部分在7B/8B规模的模型中达到了最先进的结果：生成器在五个竞赛级数学基准测试和四个具有挑战性的跨领域推理任务中取得了最佳性能，而验证器在ProcessBench数据集上占据领先地位。特别是，这两个组成部分在最困难的数学推理问题上表现出了显著的提升。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.20612", "html_url": "https://arxiv.org/abs/2505.20612", "title": "Roboflow100-VL: 一个面向视觉语言模型的多域目标检测基准", "title_en": "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models", "authors": "Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri", "background": "视觉语言模型（VLMs）在互联网规模的数据上训练后，在检测常见的对象（如汽车、卡车和行人的性能）方面表现出色。然而，最先进的模型仍然难以泛化到通常不在其预训练数据中的新类别、新任务和新成像模态。因此，与其简单地重新训练VLMs，不如使用包含少量视觉示例和丰富文本描述的注释指令来对齐VLMs到新概念。", "innovation": "介绍了Roboflow100-VL，这是一个包含100个多模态目标检测数据集的大规模集合，这些数据集包含在VLM预训练中不常见的许多新概念。该论文评估了最先进的模型在零样本、少样本、半监督和全监督设置中的性能，以比较不同数据范围的模型。结果显示，像GroundingDINO和Qwen2.5-VL这样的VLMs在具有挑战性的医学影像数据集中的零样本准确率低于2%，强调了少样本概念对齐的需求。", "conclusion": "最后，讨论了最近的CVPR2025 Foundational FSOD竞赛，并分享了社区的见解。获胜团队显著超过了我们的基线达到17个mAP。该团队的代码和数据集已公开可用。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.21785", "html_url": "https://arxiv.org/abs/2505.21785", "title": "出生即为Transformer——始终为Transformer？关于预训练对架构能力的影响", "title_en": "Born a Transformer -- Always a Transformer? On the Effect of Pretraining on Architectural Abilities", "authors": "Mayank Jobanputra,Yana Veitsman,Yash Sarrof,Aleksandra Bakalova,Vera Demberg,Ellie Pavlick,Michael Hahn", "background": "目前，尽管 Transformers 在建模序列到序列任务方面存在一定的理论限制，但这些限制在大规模预训练的语言模型中是否发挥作用仍不清楚，或者这些模型是否能够通过自身的规模及预训练数据的规模有效地克服这些约束。研究者通过分析借鉴 Liu 等人 [2024a] 提出的一组‘检索’和‘复制’任务，探讨这些架构约束在预训练后的表现。", "innovation": "本文提出了使用一个新提出的框架来研究长度泛化（Huang 等人，2025），并提供了理论上的保障。研究中观察到一个‘归纳-对抗归纳’的不对称性，即预训练模型在检索查询词右侧的标记方面表现更好，而在左侧则表现较差。此不对称性可以通过理论上的长度泛化确保而消失。机制分析显示这种不对称性与预训练变压器中感应与反向感应电路强度的不同有关。通过实际实验验证了这些发现，在现实任务中展示了可靠性风险。结果表明，预训练有选择地增强了某些变压器能力，但并未克服基本的长度泛化限制。", "conclusion": "本研究强调，虽然预训练在某种程度上提升了一些变压器的能力，但并未克服其固有的长度泛化限制。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14667", "html_url": "https://arxiv.org/abs/2505.14667", "title": "SAFEPATH：通过早期对齐防止链式思维中的有害推理", "title_en": "SAFEPATH: Preventing Harmful Reasoning in Chain-of-Thought via Early Alignment", "authors": "Wonje Jeung,Sangyeon Yoon,Minsuk Kahng,Albert No", "background": "大型推理模型（LRMs）已成为解决复杂问题的强大工具，但在遇到有害提示时，其结构化推理路径可能会导致不安全的输出。现有的安全对齐方法可以降低有害输出，但可能会削弱推理深度，在复杂、多步骤任务中存在显著的权衡。此外，这些方法仍然容易受到复杂的越狱攻击。", "innovation": "SAFEPATH 是一种轻量级的对齐方法，它在推理开始时通过有害提示生成一个短小的 8 个词的安全前言，而不监督其余的推理过程。实验结果表明，SAFEPATH 能有效减少有害输出并保持推理性能。具体来说，SAFEPATH 可以将有害响应减少高达 90.0%，在 DeepSeek-R1-Distill-Llama-8B 模型中阻止 83.3% 的越狱尝试，所需计算量仅为 Direct Refusal 的 295.9 倍和 SafeChain 的 314.1 倍。此外，还提出了零样本变体，无需微调。我们还全面分析了现有方法在应用到以推理为中心的模型时如何推广或失败，揭示了关键缺口和新的安全 AI 方向。", "conclusion": "SAFEPATH 有效减少了有害输出，同时保持了推理性能，并通过无需大量计算和不监督其余推理过程来提高安全性。此外，还通过实验和分析提供了改进现有方法的新视角。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.12977", "html_url": "https://arxiv.org/abs/2411.12977", "title": "MindForge：赋予具备心智理论的实体代理终身文化学习能力", "title_en": "MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning", "authors": "Mircea Lică,Ojas Shirekar,Baptiste Colle,Chirag Raman", "background": "基于大型语言模型（LLMs）的具身代理，如Voyager，在Minecraft等世界中展示了开放式的卓越能力。然而，尽管进行过领域特定的微调，当这些代理由公开训练的LLMs驱动时，它们仍然在基础任务上表现不佳。这项研究旨在通过明示视角获取来促进具身代理的终身文化学习能力，提出了MindForge框架。", "innovation": "MindForge框架包含三个关键创新：（1）一种结构化的心智理论表示，连结感知、信念、欲望和行动；（2）自然的代理间通信；（3）多元记忆系统。它基于文化学习框架，在Minecraft中测试了这两种指令式和协作式设置。与Voyager代理相比，由公开训练的LLMs驱动的MindForge代理显著提高了基础任务的表现，包括实现更多的科技树里程碑和收集更多的独特物品。此外，在完全协作的设置中，由于更多的交流回合，两个表现不佳的代理的性能有所提高，这与Condorcet陪审团定理相符。MindForge代理展示了复杂的智能行为，包括专家新手知识转移、协作问题解决和通过积累文化经验适应超出分布的任务。", "conclusion": "MindForge通过明示视角获取，有效提升了具身代理在Minecraft等环境中的学习与适应能力，并展示了复杂的交互与智能行为。该框架在指令式与协作式设置中的表现证明了其有效性和实用性，特别是在协作设置中体现了代理间相互作用的积极效果。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22651", "html_url": "https://arxiv.org/abs/2505.22651", "title": "Sherlock: 自视语言模型中的自我纠正推理", "title_en": "Sherlock: Self-Correcting Reasoning in Vision-Language Models", "authors": "Yi Ding,Ruqi Zhang", "background": "视觉语言模型(VLMs)在复杂多模态任务中表现出色，但仍然面临挑战：高度依赖于推理正确性、需要大量的注释数据或精确的验证器，且难以跨领域泛化。因此，本文探讨了自我纠正作为增强推理VLMs策略的可能性，通过深入分析VLMs的自我纠正能力，识别关键不足，并提出Sherlock，一种自我纠正和自我改进训练框架，该框架包括轨迹级别的自我纠正目标、基于视觉扰动的偏好数据构造方法以及动态β值的偏好调优，从而能够在少量随机抽样的注释数据（仅20,000个）上获得自我纠正能力，无需外部监督即可继续自我改进。基于Llama3.2-Vision-11B模型，Sherlock在八个基准测试中表现出色，直接生成和自我纠正后的平均准确率为64.1%和65.4%，并且在使用不到20%的注释数据的情况下超越了LLaVA-CoT、Mulberry和LlamaV-o1的表现", "innovation": "本文提出了一种自我纠正和自我改进训练框架Sherlock，引入了轨迹级别的自我纠正目标、基于视觉扰动的偏好数据构造方法以及动态β值的偏好调优，能够在少量注释数据上实现自我纠正和自我改进。相对于现有方法，Sherlock在多个基准测试中的准确率表现更佳，同时减少了对注释数据的需求。具体创新点包括：1. 轨迹级别的自我纠正目标；2. 基于视觉扰动的偏好数据构造方法；3. 动态β值的偏好调优", "conclusion": "本研究通过构建Sherlock框架，显著提升了视觉语言模型的推理能力。通过少量的注释数据和自纠正方法，Sherlock不仅提高了模型的准确性，还增强了泛化能力，为视觉语言模型在复杂任务中的应用提供了新的途径。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.07031", "html_url": "https://arxiv.org/abs/2506.07031", "title": "HauntAttack: 当攻击伴随着推理的阴影", "title_en": "HauntAttack: When Attack Follows Reasoning as a Shadow", "authors": "Jingyuan Ma,Rui Li,Zheng Li,Junfeng Liu,Heming Xia,Lei Sha,Zhifang Sui", "background": "新兴的大规模推理模型（LRMs）在数学和推理任务中表现出色，展示了显著的能力。然而，推理能力的提升和内部推理过程的暴露引入了新的安全漏洞。关键问题是：当推理与危害性交织在一起时，LRMs是否会更容易在推理模式下遭受推理攻击？", "innovation": "本文提出了一个新的和通用的黑盒对抗攻击框架HauntAttack，系统地将有害指令嵌入推理问题中。具体来说，通过修改现有问题中的关键推理条件，引入有害指令，从而构建了一个推理路径，逐步指导模型生成不安全的结果。该框架在11个LRMs上的平均攻击成功率达到了70%，相对于之前的最强基线实现了12个百分点的绝对改进。进一步分析表明，即使是最先进的安全对齐的模型对基于推理的攻击仍然高度敏感，揭示了平衡推理能力和安全性在未来模型开发中面临的紧急挑战。", "conclusion": "即使是最先进的安全对齐的模型在基于推理的攻击面前也极其脆弱，这表明未来在模型开发中需要更紧迫地平衡推理能力和安全性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23883", "html_url": "https://arxiv.org/abs/2505.23883", "title": "BioCLIP 2：从分层对比学习扩展中涌现出的属性", "title_en": "BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning", "authors": "Jianyang Gu,Samuel Stevens,Elizabeth G Campolongo,Matthew J Thompson,Net Zhang,Jiaman Wu,Andrei Kopanev,Zheda Mai,Alexander E. White,James Balhoff,Wasila Dahdul,Daniel Rubenstein,Hilmar Lapp,Tanya Berger-Wolf,Wei-Lun Chao,Yu Su", "background": "大规模训练的基础模型展现出显著的自发行为，能够学习超出初始训练目标的新能力。本研究通过大规模对比视觉-语言训练，在生物学视觉模型中发现了类似的自发行为。作者首先构建了一个名为TreeOfLife-200M的大型生物图像数据库，包含2.14亿张生物图像，是迄今为止最大且最多样化的生物图像数据集。研究中，BioCLIP 2模型在TreeOfLife-200M上被训练，以识别不同物种，尽管其训练目标较为具体，但在多样的生物学视觉任务中表现出了卓越的准确性，如栖息地分类和特征预测。研究揭示了BioCLIP 2学习空间中的一些自发属性：物种层面的嵌入分布与功能和生态意义高度吻合，而种内层面的变异不仅没有减少，反而在与物种间差异正交的空间中得到了更好的分离。研究还提供了形式证明和分析，解释了为什么分层监督和对比目标促进了这些自发属性的出现，尤其是随更大规模训练数据的使用，这些属性变得越来越显著，产生了一个生物意义明确的嵌入空间。", "innovation": "研究引入了大规模生物图像数据集TreeOfLife-200M，并在其上训练了BioCLIP 2模型，该模型能够在特定训练目标下表现出多样的新能力。研究还提供了解释这些自发属性形成机制的正式证明和分析，探讨了分层监督和对比学习目标在其中的作用。研究结果表明，随着训练数据规模的增大，这些自发性质变得越来越重要，从而产生了具有生物学意义的嵌入空间。", "conclusion": "研究揭示了在大规模训练数据的支持下，生物视觉模型能够自发学习超出初始训练目标的各种新能力，并在不同的生物学视觉任务中表现出显著的效率。研究还提供了这些自发性质形成的机制解释，强调了对更大规模训练数据集进行对比学习的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.11554", "html_url": "https://arxiv.org/abs/2502.11554", "title": "为了语音用户界面的动态隐喻对话设计", "title_en": "Toward Metaphor-Fluid Conversation Design for Voice User Interfaces", "authors": "Smit Desai,Jessie Chin,Dakuo Wang,Benjamin Cowan,Michael Twidale", "background": "语音用户界面（VUIs）中的隐喻在塑造用户体验方面起着关键作用，但现有设计往往依赖静态、以人类为中心的隐喻，无法适应多样的情境和用户需求。本研究在四种关键使用场景——命令、信息查询、社交性和错误恢复——中，通过形式化和层次化维度映射隐喻，揭示了任务特定的隐喻设计的偏好。通过对比动态适应使用的隐喻-流体设计和现有默认VUI，研究发现，动态适应使用的隐喻-流体设计可以更好地与用户在不同情境下的期望相匹配，从而提高用户的接受度、满意度和喜好感，但个人对隐喻偏好的差异也提示了个性化设计的必要性。这些发现挑战了VUI设计中的一刀切范式，并展示了动态适应的隐喻设计在创建更灵活且吸引人的用户-人工智能交互中的潜力。", "innovation": "动态适应使用的隐喻-流体设计是一种新颖的方法，基于对话使用情境动态调整隐喻性表征。研究通过两个实验比较了该方法与现有默认VUI的差异，展示了动态适应使用的隐喻-流体设计在提高用户接受度、满意度和喜好感方面的优势，突破了现有设计的一刀切范式。", "conclusion": "研究结果挑战了VUI设计的一刀切范式，证实了动态适应的隐喻设计可以创造出更加灵活且引人入胜的人工智能互动，同时也指出了个性化设计的必要性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.04210", "html_url": "https://arxiv.org/abs/2506.04210", "title": "思考更多总是有帮助吗？推理模型测试时扩展的幻影", "title_en": "Does Thinking More always Help? Mirage of Test-Time Scaling in Reasoning Models", "authors": "Soumya Suvra Ghosal,Souradip Chakraborty,Avinash Reddy,Yifu Lu,Mengdi Wang,Dinesh Manocha,Furong Huang,Mohammad Ghavamzadeh,Amrit Singh Bedi", "background": "近期，测试时注释推理模型（如OpenAI o1和DeepSeek R1）的发展趋势表明，通过使用提示（如“等一下”或“让我再想想”）延长思维痕迹可以提升模型的性能。研究人员认为，这导致了一个普遍的信念，即在测试时思考更多可以提高推理能力。", "innovation": "为了验证这一假设，作者进行了一项详细实证研究，发现了初始性能改进之后的下降现象，归因于“过度思考”。为了理解这一非单调趋势，作者通过一个简单的概率模型揭示了思考过程中的输出方差增加，从而产生推理改进的错觉，但最终削弱了精确度。基于这一发现，作者引入了一种名为“并行思考”的替代测试时空缩方法，该方法在相同推理预算下生成多个独立的推理路径，通过多数表决选择最一致的答案，相比扩展思考可提升20%的准确性。", "conclusion": "该研究表明，在推理模型的测试时空缩中，扩展思考可能不是有效利用推理预算的方式。通过并行思考，可以获得一种简单而有效的方法来扩展推理模型的测试时推理空间，提高准确性。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.04586", "html_url": "https://arxiv.org/abs/2508.04586", "title": "当前AI会议模式不可持续！集中式AI会议危机诊断", "title_en": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference", "authors": "Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He", "background": "人工智会议对于推进研究、分享知识和促进学术社区至关重要，但它们的迅速扩张使得集中式会议模式越来越不可持续。报告通过数据揭示了结构性危机，威胁着科学传播、公平性和社区福祉的基础目标。研究发现，在科学方面，过去十年作者的发文率翻了一番多，达到每年超过4.5篇；在环境方面，单个会议的碳排放比其所在城市的日排放量还要多；在心理方面，超过71%的在线社区讨论表达了负面情绪，35%提到了心理健康问题；在后勤方面，顶级会议如NeurIPS 2024的参会人数超过了场地容量。这些压力表明，会议模式已偏离其核心使命。", "innovation": "提出了社区联邦会议（CFC）模式，将同行评审、展示和社交网络等功能分离为全球协调但地方组织的组成部分。这一创新旨在提供一种更可持续、更具包容性和更具韧性的AI研究道路。", "conclusion": "当前的AI会议模式存在结构性危机，是时候引入社区联邦会议模式，以实现更可持续、更具包容性和更具韧性的AI研究路径。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18631", "html_url": "https://arxiv.org/abs/2506.18631", "title": "ReDit: 改善大型语言模型策略优化的奖励抖动方法", "title_en": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "authors": "Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu", "background": "DeepSeek-R1 通过基于规则的奖励系统成功提升了大型语言模型的推理能力，尽管此奖励系统是一个有效的机制，能够有效防止奖励作弊，但通常这些奖励函数是离散的。实验观察表明，离散奖励会导致梯度异常、优化不稳定和收敛缓慢等问题。为了应对这一问题，该研究提出了 ReDit（奖励抖动）方法，通过在离散奖励信号中添加简单的随机噪声来抖动奖励信号。通过这种方式，整个学习过程中都会提供探索梯度，从而实现更平滑的梯度更新和加速收敛。注入的噪声还会提高奖励扁平区域的随机性，鼓励模型探索新的策略并脱离局部最优解。", "innovation": "ReDit 是一种通过添加简单随机噪声抖动离散奖励信号的方法，以解决离散奖励带来的梯度异常和优化不稳定问题。实验结果表明，ReDit 在多种任务中表现出色且高效，与标准 GRPO 相比，只需大约 10% 的训练步骤即可达到相似性能，并且在相同训练时间内表现出 4% 的性能提升。此外，还提供了理论分析进一步验证这些优势。", "conclusion": "ReDit 方法能够有效改善大型语言模型策略优化过程中的梯度问题，加速优化过程并提高性能。经实验验证，该方法比标准方法更具优势，能够显著减少梯度问题并提高模型探索新的策略和避免局部最优的能力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.15235", "html_url": "https://arxiv.org/abs/2509.15235", "title": "ViSpec：利用视觉感知推测性解码加速视觉语言模型", "title_en": "ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding", "authors": "Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen", "background": "推测性解码是加速大型语言模型（LLMs）推理的广泛采用技术，但在视觉语言模型（VLMs）中的应用仍相对较少，现有的方法只能实现轻微的速度提升（<1.5倍）。随着多模态能力在大型模型中的重要性增加，这个差距变得越来越明显。研究者假设大VLMs可以在逐层过滤冗余图像信息的同时保持文本理解能力，但小的草稿模型难以做到这一点。", "innovation": "本文引入了一种名为ViSpec的新框架，这是一种针对VLMs的新型方法。ViSpec使用轻量级的视觉适配模块将图像标记压缩为紧凑表示，并无缝集成到草稿模型的注意力机制中，同时保留原始图像位置信息。此外，从每个输入图像中提取全局特征向量，并在所有后续文本标记中增强这些特征，以增强跨模态的一致性。为了克服缺乏长助手响应的多模态数据集，研究人员创建了一个专门的训练数据集，通过重新利用现有数据集并使用修改后的提示生成目标VLM的扩展输出。这一策略减少了草稿模型仅使用目标模型输出进行训练时直接访问目标模型隐藏状态的风险，从而降低所谓的捷径学习风险。通过大量实验验证了ViSpec，首次在VLM推测性解码中实现了显著的速度提升。", "conclusion": "通过引入ViSpec，首次显著提升了VLM推测性解码的速度，这种新型框架有效地过滤了冗余的图像信息，增强了跨模态的一致性，同时避免了直接访问目标模型的隐藏状态，降低了捷径学习的风险。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13992", "html_url": "https://arxiv.org/abs/2506.13992", "title": "AssistedDS：评估外部领域知识如何协助LLMs在自动化数据科学中的表现", "title_en": "AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science", "authors": "An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding", "background": "大型语言模型（LLMs）已经提高了数据科学工作流程的自动化程度，但尚不清楚它们是否能像人类数据科学家那样有效地利用外部领域知识。为了解决这一问题，作者引入了AssistedDS（辅助数据科学），这是一个用于系统性评估LLMs在表格预测任务中处理领域知识能力的基准。AssistedDS结合了具有显式生成机制的合成数据集和真实的Kaggle竞赛，每个数据集都配备了精选的有益和对抗性文档，这些文档提供了数据清洗、特征工程和模型选择的领域特定见解。作者评估了最先进的LLMs在识别和应用有益与有害领域知识方面的能力，包括评价提交的有效性、信息召回率和预测性能。研究结果展示了三个关键发现：（1）LLMs频繁无批判地采纳提供的信息，当引入对抗性内容时严重影响预测性能；（2）有益指导往往不足以抵消对抗性信息的负面影响；（3）在Kaggle数据集中，LLMs在处理时间序列数据、在不同折上一致地应用特征工程以及正确解释类别变量方面经常出现错误。这些发现指出当前模型在评估和利用专家知识方面存在重大差距，并强调了开发更具鲁棒性的、知识敏感的自动化数据科学系统的重要研究方向。", "innovation": "作者提出AssistedDS基准，旨在系统性评估LLMs在处理领域知识方面的表现。该基准结合了合成数据集和Kaggle竞赛，每个数据集都配备了有益和对抗性的文档，提供领域的特定见解。作者评估了最新的LLMs在识别和应用有益与有害领域知识方面的表现，包括提交的有效性、信息召回率和预测性能。研究结果展示了多方面的关键发现，指出当前模型在评估和利用专家知识方面存在重大差距，强调了开发更具鲁棒性的、知识敏感的自动化数据科学系统的重要研究方向。", "conclusion": "研究结果展示了三个关键发现：（1）LLMs无批判地采纳提供的信息，当引入对抗性内容时严重影响预测性能；（2）有益指导不足以抵消对抗性信息的负面影响；（3）在Kaggle数据集中，LLMs在处理时间序列数据、在不同折上一致地应用特征工程以及正确解释类别变量方面经常出现错误。研究指出当前模型在评估和利用专家知识方面存在重大差距，强调了开发更具鲁棒性的、知识敏感的自动化数据科学系统的重要研究方向。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11570", "html_url": "https://arxiv.org/abs/2510.11570", "title": "一套用于破坏基于推理的安全护栏的方法", "title_en": "Bag of Tricks for Subverting Reasoning-based Safety Guardrails", "authors": "Shuo Chen,Zhen Han,Haokun Chen,Bailan He,Shengyun Si,Jingpei Wu,Philip Torr,Volker Tresp,Jindong Gu", "background": "近年来，基于推理的安全护栏，如详议对齐，已经在防止大模型‘脱缰’攻击方面显示出强大的防御能力。通过利用大模型的推理能力，这些护栏帮助模型在生成最终回复前评估用户输入的安全性。尽管这些基于推理的护栏在面对潜在危险意图时表现出色，能够拒绝潜在有害的请求，但研究发现，这些先进的护栏对于输入提示的微妙操纵十分脆弱，一旦被劫持，可能会导致更严重的后果。", "innovation": "论文介绍了一种方法——'破坏基于推理的安全护栏的方法'，用于绕过这些强大的基于推理的护栏。该方法涵盖白盒、灰盒和黑盒攻击环境，包括简单的模板操纵和全面自动优化，能够在不同场景下实现显著的成功率，例如开源gpt-oss系列上的不同基准测试中，攻击成功率超过90%。", "conclusion": "研究证实，这些漏洞是系统性的，强调了开发更强大的对齐技术以防止开源大模型的恶意使用至关重要。研究团队已经将代码作为开源项目发布。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.09721", "html_url": "https://arxiv.org/abs/2510.09721", "title": "LLM驱动软件工程中基准和解决方案的综合研究", "title_en": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "authors": "Jiale Guo,Suizhi Huang,Mei Li,Dong Huang,Xingsheng Chen,Regina Zhang,Zhijiang Guo,Han Yu,Siu-Ming Yiu,Pietro Lio,Kwok-Yan Lam", "background": "大型语言模型（LLMs）在软件工程中的整合促使了从传统基于规则的系统向能够解决复杂问题的自主代理系统的转变。然而，系统性的进步受到了对基准和解决方案如何互联的全面理解不足的阻碍。这项调查填补了这一空白，通过对150多篇最近发表的论文进行回顾，提供了LLM赋能软件工程的第一个全方位分析，提供有关评估方法和解决方案范式的见解。这项分析强调了从简单的提示工程到包含计划、推理、记忆机制和工具增强等复杂代理系统的演变过程。", "innovation": "这项工作回顾了超过150篇最近的论文，并提出了基于两个关键维度的分类方法：(1) 解决方案，分为基于提示、微调和代理范式；(2) 基准，包括代码生成、翻译和修复等任务。此外，研究还连接了50多个基准与其相应解决方案策略，使得研究人员可以根据不同的评估标准识别出最佳方法，并提出了未来研究方向，如多代理协作、自我演化系统和形式验证集成。这项调查为LLM驱动的软件工程的发展提供了一个基础指导。", "conclusion": "这项调查为LLM驱动的软件工程的发展起到了基础指导的作用。我们通过GitHub仓库不断更新已审查和相关的论文集，确保信息的时效性和完整性。未来研究将关注多代理协作、自我演化系统和形式验证集成等方面。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11851", "html_url": "https://arxiv.org/abs/2510.11851", "title": "Deep Research引入更深层次的危害", "title_en": "Deep Research Brings Deeper Harm", "authors": "Shuo Chen,Zonggen Li,Zhen Han,Bailan He,Tong Liu,Haokun Chen,Georg Groh,Philip Torr,Volker Tresp,Jindong Gu", "background": "DR代理基于大型语言模型（LLMs）可以执行复杂的多步研究，通过分解任务、检索在线信息和合成详细报告。然而，使用具有强大能力的LLMs存在滥用风险，特别是在生物安全等高风险和知识密集型领域，DR可以生成含有详细禁用知识的专业的研究报告。", "innovation": "为了解决现有应急方法在揭示DR代理独特风险方面的不足，本文提出了两种新的不利解投刑策略：计划注入，将恶意子目标注入代理计划；意图劫持，将有害查询重新界定为学术研究问题。通过在不同LLMs和各种安全基准上的广泛实验，揭示出3个关键发现：（1）LLMs在DR代理中的对齐往往失败，有害提示以学术术语呈现可以劫持代理意图；（2）多步骤规划和执行削弱了对齐，揭示了系统漏洞，这超出了提示级保护措施的能力；（3）与独立LLMs相比，DR代理不仅绕过了拒绝，还产生了更连贯、专业且危险的内容。", "conclusion": "这些结果表明，DR代理存在基本的对齐偏差，需要专门针对DR代理设计更好的对齐技术。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08396", "html_url": "https://arxiv.org/abs/2510.08396", "title": "FlyLoRA: 通过隐式的按秩Mixture-of-Experts 提升任务解耦和参数效率", "title_en": "FlyLoRA: Boosting Task Decoupling and Parameter Efficiency via Implicit Rank-Wise Mixture-of-Experts", "authors": "Heming Zou,Yunliang Zang,Wutong Xu,Yao Zhu,Xiangyang Ji", "background": "低秩适配（LoRA）是广泛使用的参数高效微调方法，但在基础模型中存在参数干扰问题，导致性能不佳。虽然基于Mixture-of-Experts（MoE）的LoRA变体可以在单一任务指令微调中缓解任务内相关性，但它们引入了额外的路由器参数，并且在多任务模型合并中，由于任务间干扰的存在，仍然无效。", "innovation": "受果蝇嗅觉电路的启发，提出了一种隐式的MoE基LoRA变体FlyLoRA，该方法引入了（1）按秩专家激活的技术；（2）一种隐式路由器，统一了专家路由和下投影功能，使用冻结的稀疏随机投影矩阵取代了传统的稠密可训练版本。该设计通过消除显式路由器的需求解决了任务内去相关与计算效率之间的权衡，并由于随机矩阵的正交性本质地减轻了任务间干扰。", "conclusion": "在四个领域（一般知识理解、科学问题解答、数学推理和代码生成）中的广泛实验表明，FlyLoRA在现有方法的基础上表现出一致的性能改进。FlyLoRA突显了生物结构如何激励AI技术的创新。源代码可在该 URL 处获取：this https URL。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19840", "html_url": "https://arxiv.org/abs/2510.19840", "title": "基于Fourier的ResNet50 GAN特征检测", "title_en": "Fourier-Based GAN Fingerprint Detection using ResNet50", "authors": "Sai Teja Erukude,Viswa Chaitanya Marella,Suhasnadh Reddy Veluru", "background": "生成对抗网络（GAN）生成的高逼真度图像的迅速崛起给图像取证及依赖可靠内容真实性验证的工业系统带来了严重挑战。", "innovation": "该研究结合频域分析和深度学习，开发了一种用于鉴别StyleGAN生成图像的新方法。具体而言，提出了使用二维离散傅里叶变换（2D DFT）将图像转换到频域，从而在频域中检测到细微的周期性特征。同时，训练了一个ResNet50神经网络以区分真实和合成的图像。结果显示，在频域模型中，图像的真实性和生成性有显著区分，准确率达到了92.8%，AUC值为0.95，显著优于基于原始空域图像的模型。", "conclusion": "研究表明，GAN生成的图像在频域中具有独特的特征或‘指纹’。这种方法表明了结合信号处理技术和深度学习在提升数字取证和增强工业AI系统的信任方面具有巨大的工业潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19338", "html_url": "https://arxiv.org/abs/2510.19338", "title": "每一个注意力都重要：一种高效的长上下文推理混合架构", "title_en": "Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning", "authors": "Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou", "background": "在现有的模型架构中，虽然既有线性注意力也有softmax注意力，但如何有效地结合这两种注意力机制以减少长上下文推理的输入输出和计算开销仍然是一项挑战。此外，如何获得最优的模型结构，以及通过何种方法提高模型在推理阶段的效率也是一个关键问题。", "innovation": "提出了Ring-linear模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0。这两种模型均采用了一种混合架构，有效结合了线性注意力和softmax注意力，大幅减少了在长上下文推理中的输入输出和计算开销。相比320亿参数的密集模型，该系列模型将推理成本降低至1/10，并且相比于原Ring系列，成本也减少了超过50%。通过系统地探索混合架构中不同注意力机制的比例，找到了目前最优的模型结构。同时，通过使用自主研发的高性能FP8操作库linghe，整体训练效率提高了50%，并且在优化阶段能够实现长期、稳定、高效的优化。", "conclusion": "Ring-linear模型系列通过混合架构和高性能操作库的使用，在长上下文推理任务中表现出色，并且在多个复杂推理基准测试中保持了SOTA（State-of-the-Art）性能。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19955", "html_url": "https://arxiv.org/abs/2510.19955", "title": "通过对比学习变换多视角3D形状特征", "title_en": "Transformed Multi-view 3D Shape Features with Contrastive Learning", "authors": "Márcus Vinícius Lobo Costa,Sherlon Almeida da Silva,Bárbara Caroline Benato,Leo Sampaio Ferraz Ribeiro,Moacir Antonelli Ponti", "background": "计算机视觉方法在从2D图像识别3D对象方面存在挑战，通常需要大量的标注数据并依赖于可能会错过关键形状关系的卷积神经网络（CNNs）。现有的前沿骨架结构与对比监督和自我监督学习目标搭配，在3D形状特征表示学习中也面临挑战。为了解决这些问题，该研究旨在通过对比学习验证基于视知觉变换器（ViTs）的结构的有效性，尤其是在多视角3D分析中的应用，以提升3D形状的理解和表示能力。", "innovation": "该研究展示了基于视知觉变换器（ViTs）的架构与现代对比目标结合后，在多视角3D分析任务中的显著性能提升，尤其是在ModelNet10数据集上，监督对比损失达到了约90.6%的准确率。这种结合对比变换器方法和对比学习的方式，克服了传统CNNs在捕捉重要形状关系方面的限制，没有过度依赖大量标注数据。这一方法成功之处在于，能够通过ViTs捕获全局形状语义，并通过对比优化细化局部区分特征。因此，该研究提供了一种新的解决方案，即通过结合ViTs和对比学习来提升3D特征的表示学习效果。", "conclusion": "通过大规模实验，该研究证明了结合视知觉变换器与对比学习方法能够有效提升3D形状特征的表示学习。这种方法不仅克服了传统CNN的局限性，而且减少了对大量标注数据的依赖，展示了在多视角3D分析任务中的强大潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20016", "html_url": "https://arxiv.org/abs/2510.20016", "title": "具有统一检测管道的鲁棒鱼眼交通监控对象检测框架", "title_en": "A Unified Detection Pipeline for Robust Object Detection in Fisheye-Based Traffic Surveillance", "authors": "Neema Jakisa Owor,Joshua Kofi Asamoah,Tanner Wambui Muturi,Anneliese Jakisa Owor,Blessing Agyei Kyem,Andrews Danyo,Yaw Adu-Gyamfi,Armstrong Aboah", "background": "鱼眼相机为大范围交通监控提供了一个高效的解决方案，通过单一视角采集广角图像。然而，鱼眼成像中存在的强烈径向失真和非均匀分辨率显著增加了标准目标检测器在图像边界附近的处理难度，尤其是这些区域中的物体外观受到严重破坏。", "innovation": "本文提出了一种鲁棒性检测框架，使用简单的预处理和后处理管道来增强图像中，特别是在受严重失真影响的区域的目标检测一致性。此外，通过训练最新检测模型并结合其输出以提高总体检测准确性。", "conclusion": "该方法在2025年的AI City挑战赛中获得了F1分数0.6366，排名第三十二名，显示出其框架在解决鱼眼成像固有问题方面有效。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19981", "html_url": "https://arxiv.org/abs/2510.19981", "title": "FutrTrack：一种用于3D多目标跟踪的相机-LiDAR融合变换器", "title_en": "FutrTrack: A Camera-LiDAR Fusion Transformer for 3D Multiple Object Tracking", "authors": "Martha Teiko Teye,Ori Maoz,Matthias Rottmann", "background": "现有的3D检测器已经取得了显著的进展，但在多对象跟踪（MOT）能力上仍存在局限性。相机和LiDAR传感器的组合可以提供互补的信息，但是如何有效地融合这些传感器数据以及如何利用变换器来改进跟踪算法仍然是一个挑战。传统的基于查询的跟踪框架和融合驱动的跟踪器展示了良好的性能，但尚缺乏同时融合多模态传感器特征并利用变换器进行特征提取和优化的方法。FutrTrack就是在此背景下提出的，旨在解决上述问题，提高3D MOT的性能。", "innovation": "FutrTrack提出了一个模塊化的相机-LiDAR多对象跟踪框架，通过引入基于变换器的平滑器和基于融合的跟踪器来改进现有的3D检测器。该框架采用了基于查询的变换器跟踪和融合驱动的两阶段处理管道，能够融合多模态的鸟瞰图（BEV）特征，并引入了一个时间窗口上的临时平滑器来优化轨迹，减少抖动并提高空间一致性。此外，FutrTrack实现了对3D靶标的稳健重识别，即使在遮挡和视角变化的情况下也能保持准确的跟踪。该方法的有效性通过在nuScenes和KITTI数据集上的评估得到了验证，结果表明与传统的单传感器方法相比，FutrTrack具有显著的优势，且不需要复杂的先验运动模型或大量的训练数据。", "conclusion": "FutrTrack通过引入基于变换器的平滑器与融合驱动的跟踪器，实现了多传感器数据的有效融合，并显著改善了3D MOT的准确性。FutrTrack不仅展示了强大的跟踪性能，还提供了一种高效的方法，即使在数据稀少或不需要预训练的情况下，也能与基于神经网络的其他方法相匹敌。这项工作为未来的多模态跟踪研究和实际应用提供了一个可扩展和强大的框架基础。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20011", "html_url": "https://arxiv.org/abs/2510.20011", "title": "改善医学影像中预测信心的方法", "title_en": "Improving Predictive Confidence in Medical Imaging via Online Label Smoothing", "authors": "Kushan Choudhury,Shubhrodeep Roy,Ankur Chanda,Shubhajit Biswas,Somenath Kuiry", "background": "深度学习模型，尤其是卷积神经网络，在医学图像分类任务上取得了显著成果。然而，这些模型往往产生过于自信的预测，这可能在关键的医疗保健环境中损害其可靠性。虽然传统的标签平滑提供了一种简单的方法来减少这种过信心，但它无法考虑类之间的关系，而是将所有非目标类平等对待。", "innovation": "我们研究了在线标签平滑（OLS）的应用，这是一种动态方法，在训练过程中根据模型自身的预测模式调整软标签。我们使用大规模的RadImageNet数据集和三种广泛使用的架构：ResNet-50、MobileNetV2和VGG-19进行评估。结果显示，OLS在Top-1和Top-5分类准确率上始终优于标准训练方法，包括硬标签、传统标签平滑和无教师的知识蒸馏。除了准确率的提升，OLS还导致更紧凑且分离良好的特征嵌入，表明改进的表示学习能力。这些发现表明，OLS不仅增强了预测性能，还提高了校准性，成为在医学成像领域开发可信赖的AI系统的实用有效解决方案。", "conclusion": "在线标签平滑（OLS）在医学图像分类中的应用能够显著提升模型的预测性能和校准性，为开发可信赖的AI系统提供了新的途径。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20077", "html_url": "https://arxiv.org/abs/2510.20077", "title": "数据自适应变换双边张量低秩表示聚类", "title_en": "Data-Adaptive Transformed Bilateral Tensor Low-Rank Representation for Clustering", "authors": "Hui Chen,Xinjie Wang,Xianchao Xiu,Wanquan Liu", "background": "张量低秩表示（TLRR）在图像聚类中取得了显著的成功。然而，大多数现有方法依赖于固定的变换，对噪声的鲁棒性较差。", "innovation": "提出了一种新颖的数据自适应变换双边张量低秩表示模型（TBTLRR），通过学习任意单位变换引入数据自适应张量核范数，能够更有效地捕捉全局相关性。同时，通过利用潜在张量数据的双边结构，TBTLRR能够挖掘图像样本和特征之间的局部相关性。此外，TBTLRR结合了$\boldsymbol{\text{\textlq 1/2}}$-范数和Frobenius范数正则化项，以更好地处理现实场景中的复杂噪声。为了解决提出的非凸模型，开发了一种基于交替方向乘子法（ADMM）的高效优化算法，并提供了理论收敛性。", "conclusion": "广泛的实验验证了TBTLRR在聚类中的优越性，超过最先进的方法。代码将在指定的网址公开。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20087", "html_url": "https://arxiv.org/abs/2510.20087", "title": "Endoshare: 开源解决方案以脱敏和管理手术视频", "title_en": "Endoshare: A Source Available Solution to De-Identify and Manage Surgical Videos", "authors": "Lorenzo Arboit,Dennis N. Schneider,Britty Baby,Vinkle Srivastav,Pietro Mascagni,Nicolas Padoy", "background": "基于视频的评估和手术数据科学可以推动手术培训、研究和质量改进。然而，由于手术视频记录的格式差异性和与视频共享相关的隐私担忧，其广泛应用受限。Endoshare 是一种开源、跨平台的应用程序，用于合并、标准化和去标识化微创手术中的内镜视频。", "innovation": "Endoshare 采用软件开发生命周期方法，并结合用户为中心的迭代反馈。该应用引入了隐私设计架构，并通过多元化的硬件配置基准测试，结合用户可用性和采用度评估，实现了高效、用户友好的视频管理。", "conclusion": "Endoshare 提供了一个透明、用户友好的标准化处理流程，确保手术视频管理的同时保护患者隐私。未来需通过合规性认证和更广泛的互操作验证，确立其作为可部署替代专有系统的选择。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20027", "html_url": "https://arxiv.org/abs/2510.20027", "title": "超出分布摄像机位置的新型视图合成3DGS滤波器: 极端视图", "title_en": "Extreme Views: 3DGS Filter for Novel View Synthesis from Out-of-Distribution Camera Poses", "authors": "Damian Bowness,Charalambos Poullis", "background": "当从与训练数据分布显著不同的摄像角度观看3D高斯点状表示（3DGS）模型时，通常会出现明显的视觉噪声。这些伪影源于这些外推区域缺乏训练数据，导致模型在密度、颜色和几何形状预测方面存在不确定性。现有方法无法有效处理这一问题，使三维重建系统在用户自由导航到原始训练视角之外时，难以保持高质量、高真实性和一致性。现有的Neural Radiance Field（NeRF）基于方法如BayesRays等表现不佳。", "innovation": "本文提出了一种新型实时渲染感知滤波方法，用于3DGS模型。该方法利用中间梯度得出的敏感性得分，针对性地解决由各向异性方向造成的不稳定问题，而不是由各向同性变异性引起的问题。这种方法直接针对生成不确定性核心问题，使得三维重建系统即使在用户自由导航到原始训练视角之外时，也能保持高质量、高真实性和一致性。此外，该滤波方法可以无缝集成到现有的3DGS渲染管道中，无需耗时的后处理重新训练或微调。", "conclusion": "实验结果表明，本文方法在视觉质量、真实感和一致性方面显著优于现有的基于NeRF的方法如BayesRays。该方法在保持3DGS模型实时性的同时提升了其在极端视图条件下的性能。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20042", "html_url": "https://arxiv.org/abs/2510.20042", "title": "揭示盲点：生成式图像模型中的文化偏见评估", "title_en": "Exposing Blindspots: Cultural Bias Evaluation in Generative Image Models", "authors": "Huichan Seo,Sieun Choi,Minki Hong,Yi Zhou,Junseo Kim,Lukman Ismaila,Naome Etori,Mehul Agarwal,Zhixuan Liu,Jihie Kim,Jean Oh", "background": "基于生成的图像模型可以产生引人注目的视觉效果，但常常扭曲文化。以往研究主要关注文本到图像（T2I）系统的文化偏见，而图像到图像（I2I）编辑器这一领域相对缺乏研究。作者在这个空白上架起了桥梁，通过跨国别、跨类别和跨时代的统一评估，审计了T2I生成和I2I编辑在标准化协议下的表现。研究发现，模型在无国别提示下默认呈现出具有全球北欧特征、现代倾向的描绘，消弭了各国间的区别；迭代的I2I编辑会削弱文化忠实度；I2I模型仅能通过浅层提示（如色调变化、通用道具）而非一致性、情境化的改变来解决文化偏见，尤其是对于具有南方全球目标的图像。", "innovation": "本文首次全面地评估了生成式图像模型文化和时代方面的偏见，提出了包含标准化自动指标、文化意识检索增强的VQA和来自本地评审员的专业人类判断的框架。同时，作者公开了所有图像库、提示和配置，提高了研究的可复现性。", "conclusion": "研究揭示了在当前系统中文化敏感的编辑仍然不可靠这一事实。通过发布标准化数据集、提示和人类评估协议，本文为诊断和追踪生成式图像模型中的文化偏见提供了一个可重复、文化中心的基准。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20029", "html_url": "https://arxiv.org/abs/2510.20029", "title": "BrainPuzzle: 融合物理和数据驱动重建的颅内超声断层成像", "title_en": "BrainPuzzle: Hybrid Physics and Data-Driven Reconstruction for Transcranial Ultrasound Tomography", "authors": "Shengyu Chen,Shihang Feng,Yi Luo,Xiaowei Jia,Youzuo Lin", "background": "颅内超声成像因为头骨和脑组织之间巨大的声速差异以及将大型探头与头骨耦合的难度而仍然具有挑战性。传统的基于物理的全波形逆构（FWI）方法受限于由头骨引起的衰减、模式转换和相位畸变引起的弱信号，以及因临床不切实际的全孔径阵列所导致的不完全的空间覆盖。纯粹基于数据的方法虽然可以从原始超声数据中直接学习，但往往无法模拟骨骼中的复杂非线性和非局部波传播，导致在低信噪比和稀疏孔径条件下生成解剖上合理但定量有偏差的声速（SoS）地图。", "innovation": "我们提出了一种名为BrainPuzzle的基于物理和机器学习的双重框架，它结合了物理建模和机器学习。该框架包含了两个阶段：在第一阶段应用逆时迁移（时间反转声学）处理多角度采集以保留结构细节，即使在低信噪比的情况下；在第二阶段，采用基于变压器的超分辨率编码器-解码器结构，结合基于图的注意力单元（GAU），将这些片段融合成一个轮廓明确且定量准确的SoS图像。通过使用部分阵列的获取策略和可移动的低计数探头集，提高了可行性和耦合性，同时补充了缺失的孔径，从而补偿算法的不足。实验结果表明，BrainPuzzle能够在多方面优于现有方法，并展示出其在定量颅内超声成像中的潜在价值。", "conclusion": "BrainPuzzle框架证明了在颅内超声成像中，通过结合物理建模和基于数据的机器学习方法，可以实现更精确的SoS重建和更完整的成像结果。这种方法具有显著的创新性，并体现了向更为精确的颅内超声技术发展的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20092", "html_url": "https://arxiv.org/abs/2510.20092", "title": "注意卷积：结合自注意力的表达性和卷积的效率", "title_en": "Attentive Convolution: Unifying the Expressivity of Self-Attention with Convolutional Efficiency", "authors": "Hao Yu,Haoyu Chen,Yan Jiang,Wei Peng,Zhaodong Sun,Samuel Kaski,Guoying Zhao", "background": "自注意力（SA）因其强大的表达能力已经成为现代视觉骨干的基础，但其二次复杂性仍然是实际应用中的关键瓶颈。卷积（Conv）具有线性复杂性并具有强大的视觉先验，因此继续在卷积的普及上做出努力。然而，现代化方法未能完全捕捉SA的固有表达能力，因此存在性能差距。本文重新审视CNN的设计，旨在找出导致SA比Conv优越的关键原则。", "innovation": "提出了注意卷积（ATConv），这是一种新的卷积操作的原理性重构，能够结合自注意力的表达性和卷积的效率。通过仅使用3x3的内核，ATConv在基本的视觉任务中表现优于各种SA机制，构建了基于ATConv的AttNet系列网络，仅以27M参数达到了ImageNet-1K的84.4%的Top-1准确率。在基于扩散的过程生成图像时，用3x3的ATConv替代所有的SA机制，在400k步中将ImageNet FID降低了0.15并加快了采样速度。", "conclusion": "通过注意卷积（ATConv），结合自注意力机制的表达性和卷积原理的效率，本文提出了AttNet系列神经网络，不仅在ImageNet数据集上有卓越表现，在图像生成任务中也有显著改进，展示了其实际应用价值。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20095", "html_url": "https://arxiv.org/abs/2510.20095", "title": "BIOCAP：在生物基础模型中利用合成描述超出标签的价值", "title_en": "BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models", "authors": "Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu", "background": "该研究探讨了将描述性语句作为生物多模态基础模型的附加监督源。图像和描述可以被视为来自物种潜在形态空间的互补样本，各自捕捉某些生物学特征。在训练过程中加入描述有助于与共享的潜在结构对齐，强调潜在的诊断特征，同时抑制虚假相关性。然而，主要挑战在于大规模获取忠诚的、实例特定的描述。这限制了自然语言监督在生态系统生物学中的应用，与许多其他科学领域相比更为有限。我们通过使用多模态大语言模型生成合成描述，结合维基百科衍生的视觉信息和分类群特制的格式示例来填补这一空白。", "innovation": "该研究通过生成基于维基百科视觉信息和分类群特制格式示例的合成描述，使用多模态大语言模型，解决了大规模获取真实、实例特定描述的问题。基于这些描述，研究训练了BIOCAP（即BIOCLIP与描述结合），这是一种能够捕捉丰富语义并在物种分类和图文检索中表现出强大性能的生物基础模型。", "conclusion": "研究结果表明，描述性语句在生物图像与多模态基础模型之间的桥梁作用中具有超越标签的价值。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20093", "html_url": "https://arxiv.org/abs/2510.20093", "title": "StableSketcher：通过视觉问答反馈提高基于像素的手绘草图生成的扩散模型", "title_en": "StableSketcher: Enhancing Diffusion Model for Pixel-based Sketch Generation via Visual Question Answering Feedback", "authors": "Jiho Park,Sieun Choi,Jaeyoon Seo,Jihie Kim", "background": "尽管最近在扩散模型方面的进步显著提高了生成图像的质量，但在合成基于像素的手绘草图方面仍然存在挑战，后者是抽象表达的代表。StableSketcher 是一种新颖的框架，它赋予扩散模型生成高精度提示的手绘草图的能力。在该框架中，我们调整了变异自编码器以优化潜在解码过程，使其更好地捕捉草图的特点。同时，我们引入了一种新的基于视觉问答的奖励函数，用于强化学习，这改善了文本-图像对齐和语义一致性。", "innovation": "StableSketcher 提出了一种新颖的框架，该框架结合了变异自编码器和一种基于视觉问答的奖励函数，旨在提高扩散模型生成手绘草图的能力。通过这种方法，增强了生成图像的风格保真度，并实现了比 Stable Diffusion 基线更好的提示对齐。此外，引入了 SketchDUO 数据集，这是一个包含草图实例级配对及其描述和问答对的数据集，解决了现有依赖于图像标签对的数据集的局限性。", "conclusion": "通过实验，StableSketcher 生成的手绘草图在风格保真度上有所提升，并与提示有更好的对齐。同时，还介绍了 SketchDUO 数据集，这是已知的第一个包含实例级别的手绘草图配对数据集，旨在为其配对文本提供支持。该代码和数据集将在被接受后公开。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20126", "html_url": "https://arxiv.org/abs/2510.20126", "title": "物理指导融合以实现稳健的快速移动小型物体的3D跟踪", "title_en": "Physics-Guided Fusion for Robust 3D Tracking of Fast Moving Small Objects", "authors": "Prithvi Raj Singh,Raju Gottumukkala,Anthony S. Maida,Alan B. Barhorst,Vijaya Gopu", "background": "尽管计算机视觉在一般目标的检测和跟踪方面取得了显著进展，但对于快速移动的小型物体的检测和跟踪问题仍然相对未被充分探索。本研究专注于如何利用RGB-D相机来处理和解决这一挑战性问题，特别是在三维空间中对快速移动的小型物体进行检测和跟踪的难点。传统的基于统计的方法在处理快速移动和小目标时存在局限性，而现有的一些解决方法也未能有效应对这种快速变化和复杂场景下的大部分挑战。因此，如何在实际场景中准确地实现对小型物体的实时3D检测和跟踪，成为了本研究中需要解决的关键背景问题。", "innovation": "本研究提出了一个新的系统设计，结合了基于深度学习的检测方法与基于物理学的跟踪算法，成功突破了传统方法在处理快速移动小型物体时的局限性。文章提出了一个创新的基于物理化学运动方程的跟踪算法，能够在有离群值和漏报的情况下仍能准确跟踪目标。该研究还引入了一种离群值检测与修正模块，以提高在遮挡和快速方向变化等复杂场景下的跟踪性能。", "conclusion": "研究通过在自定义的台球拍数据集上进行评估，系统成功地超越了基于卡尔曼滤波器的目标跟踪器，达到了70%的平均位移误差更低的结果。该研究表明，将基于物理的模型与深度学习结合起来用于快速移动的小型物体的实时3D检测与跟踪，不仅能够有效地处理各种复杂场景，而且还具有在自主平台上提高机器人感知水平的显著应用价值。这为进一步探索利用机器学习和物理模型相结合的方式提供了一种新的策略。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20071", "html_url": "https://arxiv.org/abs/2510.20071", "title": "从事件重构图像的滤波器基础方法", "title_en": "Filter-Based Reconstruction of Images from Events", "authors": "Bernd Pfrommer", "background": "从移动事件相机的事件重构强度图像是一项具有挑战性的任务，通常通过部署在图形处理单元上的神经网络来实现。本文提出了一种更简单的滤波基于异步重构方法（FBA），该方法通过时间数字IIR滤波器整合由事件触发的强度变化，通过新颖的算法检测旧像素，减少重构噪声，并利用高斯滤波器模糊旧像素，从而进一步减少噪声。这种方法展示了即使在不依赖事件而非事件的位置时，也可能暗示低图像梯度，使得它适合用于某些特定任务如检测标记物，但噪声和鬼影图像仍存在问题。", "innovation": "提出了一种新的滤波基于异步重构方法（FBA），利用时间数字IIR滤波器整合由事件触发的强度变化，通过新颖的算法检测旧像素，减少重构噪声，适用于移动相机的图像重构，运行速度快，能够在现代笔记本电脑CPU上达到约每秒42（140）百万事件（不包括空间过滤器）。并在不需要的无缝且任意时间读取图像。与基于神经网络的方法不同，FBA的实现简单且具有实时性。然而，它在图像重构方面存在噪声较大和幻影图像等问题。它仍能满足某些特定任务如检测标记物的需求。相对于已有方法，FBA具有异步性，可支持图像在任意时间点的读出，运行效率更高。", "conclusion": "尽管FIBAR在图像重建方面具有噪声较大和幻影图像的问题，但它的实时性能和异步特性使它在特定应用场景中（如标记物的检测）具有明显优势。代码已公开可在指定链接下载。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20134", "html_url": "https://arxiv.org/abs/2510.20134", "title": "重新审视logit分布以实现可靠的out-of-distribution检测", "title_en": "Revisiting Logit Distributions for Reliable Out-of-Distribution Detection", "authors": "Jiachen Liang,Ruibing Hou,Minyang Hu,Hong Chang,Shiguang Shan,Xilin Chen", "background": "在开放世界应用场景中，确保深度学习模型的可靠性至关重要。尽管事后校正方法因其效率和部署简便性而受青睐，但现有方法通常未能充分利用模型logits空间内在的丰富信息。在本研究中，我们提出了一个基于logits空间的新颖的事后校正out-of-distribution (OOD)检测方法，称为LogitGap。通过探索最大logit与剩余logits之间的关系来提高分布内(in-distribution, ID)和OOD样本之间的可分性。", "innovation": "我们推出了LogitGap，这是一种新的事后校正OOD检测方法，它通过明确探索最大logit与剩余logits之间的关系来提高分布内和OOD样本之间的可分性。为提高其有效性，我们还通过集中在logit空间的一个更紧凑且更具信息量的子集上进一步优化了LogitGap。我们提出了一种无需训练的策略，可以自动识别用于评分的最相关信息性的logit。", "conclusion": "广泛的实验表明，无论是在视觉-语言模型还是单纯的视觉模型中，LogitGap在多种OOD检测场景和基准上都取得了最先进的性能。相关代码已发布。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20155", "html_url": "https://arxiv.org/abs/2510.20155", "title": "PartNeXt：一种用于细粒度和层次化3D部件理解的下一代数据集", "title_en": "PartNeXt: A Next-Generation Dataset for Fine-Grained and Hierarchical 3D Part Understanding", "authors": "Penghao Wang,Yiyang He,Xin Lv,Yukai Zhou,Lan Xu,Jingyi Yu,Jiayuan Gu", "background": "理解和物体构成部件的层次结构是推进计算机视觉、图形学和机器人学的关键。尽管像PartNet这样的数据集促进了3D部件理解的进步，但它们依赖于无纹理的几何结构和专家依赖的注释，限制了其可扩展性和实用性。这导致了对于更高质量、纹理化3D模型及其详细层次注释的需求，以满足更广泛的场景应用和研究挑战。", "innovation": "PartNeXt作为一种新的数据集，包含超过23,000个高质量的纹理化3D模型，并且这些模型被标注了细粒度和层次化的部分标签，覆盖了50个类别。PartNeXt构建了一个新的基准，用于3D部分中心问题回答，揭示了开放词汇部分语义的显著差距。通过使用PartNeXt训练Point-SAM，验证了其在质量及多样性上的优越性，提供了在结构化3D理解研究上的新途径，包括可扩展的注释、纹理意识标签以及多任务评估方法。", "conclusion": "PartNeXt为研究结构化3D理解提供了新的数据支持，它在部分感知的分割和3D语义问题回答任务中展示了其优势，并为新形式的数据集评估提供了方法，推动了3D领域的发展。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20165", "html_url": "https://arxiv.org/abs/2510.20165", "title": "IB-GAN：利用信息瓶颈生成对抗网络进行解缠表示学习", "title_en": "IB-GAN: Disentangled Representation Learning with Information Bottleneck Generative Adversarial Networks", "authors": "Insu Jeon,Wonkwang Lee,Myeongjang Pyeon,Gunhee Kim", "background": "该研究的背景是目前存在的一些生成对抗网络（GAN）模型在无监督学习中难以实现独立特征的解缠表示学习，尤其是在利用信息瓶颈（IB）框架优化生成对抗网络方面存在不足。", "innovation": "该研究的创新点在于提出了一种新的基于生成对抗网络（GAN）的无监督模型——IB-GAN，通过使用信息瓶颈框架来优化生成器，从而解缠表示学习。与InfoGAN相比，IB-GAN在生成器中引入了一个中间层，用来限制输入和生成输出之间的互信息，使得生成器能够以解缠和可解释的方式利用潜在空间。", "conclusion": "通过在dSprites和Color-dSprites数据集上的实验，IB-GAN在解缠程度上与最先进的η-VAEs相当，并且在CelebA和3D Chairs数据集上的FID分数方面比InfoGAN等生成的样本视觉质量和多样性更好。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20132", "html_url": "https://arxiv.org/abs/2510.20132", "title": "从单张图像生成光场的逆向图像渲染", "title_en": "Inverse Image-Based Rendering for Light Field Generation from Single Images", "authors": "Hyunjun Jung,Hae-Gon Jeon", "background": "已证明从网格布局的多视角图像计算产生的光场概念在场景表示中有其优势，并支持新型视角的现实渲染及照片效果如重新聚焦和浅景深效果。尽管光流计算有效，但获得光场需要高昂的计算成本或特殊的设备，如复杂的相机设置和专门的微透镜阵列。为了扩大其效益和适用性，本文提出了一种仅从单个图像生成光场的新颖视图合成方法，称为逆向图像基渲染。该方法不同于以往隐式重构3D几何或明确表示客观场景的方法，而是从图像像素出发重建空间中的光流。为实现这一点，我们设计了一个神经渲染管道来渲染任意视角的目标光线。神经渲染器首先从输入图像存储光源的流动，然后通过交叉注意力计算它们之间的关系，并最终基于这些关系预测目标光线的颜色。在生成第一个新的视图后，生成的视图外内容将更新到光源集中。在确保被遮挡内容一致生成的前提下，该过程迭代执行。", "innovation": "本文提出了一种仅从单个图像生成光场的新颖视图合成方法，即逆向图像基渲染。该方法通过设计一个神经渲染管道，从图像像素中重建空间上的光流，而非以往隐式重构3D几何或明确表示客观场景的方法。具体来说，神经渲染器首先存储源光线的光流，通过交叉注意力计算它们之间的关系，再基于这些关系预测目标光线的颜色。这种方法可以迭代生成新视图，同时更新视图外内容，以确保生成的一致性。此方法在无需任何重新训练或微调的情况下，适用于各种具有挑战性的数据集，并在新型视角合成方法中表现优异，超越了现有的一些领先方法。", "conclusion": "本文提出的方法展示了其在使用单张图像生成光场方面的有效性和适用性，无需额外的重新训练或微调即可广泛应用于各种具有挑战性的数据集，并且在新型视角合成方法中表现出更优异的表现。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20158", "html_url": "https://arxiv.org/abs/2510.20158", "title": "单目视觉8D姿态估计在机动自行车和骑行者中的应用", "title_en": "Monocular Visual 8D Pose Estimation for Articulated Bicycles and Cyclists", "authors": "Eduardo R. Corral-Soto,Yang Liu,Yuan Ren,Bai Dongfeng,Liu Bingbing", "background": "在自动驾驶中，骑行者属于关键的易受伤害的道路使用者（VRU）类别，精准估计骑行者姿态对于识别骑行者的穿越意图、行为预测和碰撞避免至关重要。机动自行车不同于刚体对象，由可动刚体部件通过关节连接，并受到运动学结构的约束。尽管6D姿态方法可以估计机动自行车的3D旋转和平移，但在自行车的前叉角度和脚踏位置变化时，6D成为不充分的，因为：1）机动自行车的姿态变化会导致其3D边界框发生变化，2）3D边界框的方向不一定与前叉的方向对齐，而这决定了实际的行驶方向。", "innovation": "本文提出了一种从单个RGB图像估计机动自行车和骑行者类别级别的8D姿态的方法。该方法不仅能从单个图像估计自行车的3D平移和旋转，还能估计前叉和脚踏相对于自行车基体框架的旋转。这两个新增的参数使能够更细粒度地估计自行车姿态状态和行驶方向。所提出的模型联合估计机动自行车的8D姿态和3D关键点，并使用合成图像和真实图像数据混合训练以在真实图像上泛化。我们还包括了评估部分，评估我们估计的8D姿态参数的准确性，结果显示相对于使用刚体常规目标模板进行匹配的最先进的类别级别的6D姿态估计器，我们的方法取得了令人鼓舞的结果，成绩具有竞争力。", "conclusion": "我们的方法通过联合估计8D姿态和3D关键点，展示了在真实图像上的泛化能力，并且在与最先进的6D姿态估计器的比较中取得了具有竞争力的评分，这表明我们的8D姿态估计方法在机动自行车和骑行者姿态估计任务上具有很大的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20178", "html_url": "https://arxiv.org/abs/2510.20178", "title": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching", "title_en": "PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching", "authors": "Yun Wang,Junjie Hu,Qiaole Dong,Yongjian Zhang,Yanwei Fu,Tin Lun Lam,Dapeng Wu", "background": "深度估计对于增强现实等实际应用至关重要，但传统的深度估计难以在保持长时间一致性的前提下保持计算效率，导致重建的深度信息的不一致性问题。尽管已有研究试图通过时空整合的方式来解决这一问题，但依然存在模型计算复杂度高和时空一致性难以兼顾的问题。", "innovation": "本文提出了一种名为PPM的记忆缓冲模块，该模块通过两个阶段协作过程（Pick-and-Play，选择和播放）来维持紧凑且高度信息量的记忆缓冲区，实现了动态立体匹配的一致性深度估计。与之前的BiDAStereo相比，PPMStereo在精度和时序一致性方面均表现出更优的效果，同时在计算成本上更优。", "conclusion": "通过广泛的实验验证了PPMStereo的有效性，证明它在Sintel数据集上的性能优于现有方法，尤其在计算成本降低的同时保持了高的准确性和时序一致性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20196", "html_url": "https://arxiv.org/abs/2510.20196", "title": "公共脑MRI数据集的结构化审查和定量分析以支持基础模型开发", "title_en": "A Structured Review and Quantitative Profiling of Public Brain MRI Datasets for Foundation Model Development", "authors": "Minh Sao Khue Luu,Margaret V. Benedichuk,Ekaterina I. Roppert,Roman M. Kenzhin,Bair N. Tuchinov", "background": "基础模型在脑MRI中的应用依赖于数据的规模、多样性和一致性，但系统评估这些因素的情况仍然很少。本文分析了54个公开的脑MRI数据集，包含超过538,031个样本，为基于基础模型的开发提供层次化的多层次概述。在数据集层面，研究数据模态组成、疾病涵盖范围和数据集规模，揭示了大型健康群体和小型临床群体之间明显的不平衡。在图像层面，量化了15个代表性数据集中体素间距、方向和强度分布，展示了显著的异质性，这可能会影响表示学习。", "innovation": "本文系统性地评估并介绍了大量公共可用脑MRI数据集的大小、多样性和一致性问题，通过体素间距、方向和强度分布的定量分析，揭示了数据集之间存在显著差异的问题，并通过标准化预处理的定量评估展示了即使在标准化预处理后还存在的数据集间残余差异，强调了预处理意识和领域适应策略在设计可泛化的脑MRI基础模型中的必要性。", "conclusion": "本文分析提供了公共脑MRI资源中变异性的一致描述，并强调了在设计可泛化的脑MRI基础模型时需要考虑预处理感知和领域适应策略。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20189", "html_url": "https://arxiv.org/abs/2510.20189", "title": "SPAN: 对时间意图定位中的怀疑进程进行连续建模", "title_en": "SPAN: Continuous Modeling of Suspicion Progression for Temporal Intention Localization", "authors": "Xinyi Hu,Yuran Wang,Yue Li,Wenxuan Liu,Zheng Wang", "background": "视频监控领域中，时间意图定位（TIL）是至关重要的，它旨在识别不同级别的可疑意图以提高安全监控效果。然而，现有的离散分类方法无法捕捉可疑意图的连续性，这限制了早期干预和可解释性。", "innovation": "本文提出了怀疑进程分析网络（SPAN），将方法从离散分类转变为连续回归，从而捕捉变化和演变的可疑意图。研究发现怀疑表现出了长期依赖性和累积效应，类似于时间点过程（TPP）理论。基于这些见解，我们定义了一个怀疑得分公式，以建模连续变化并考虑时间特性。此外，我们引入了怀疑系数调制，使用多模态信息调整怀疑系数，以反映可疑行为的差异化影响。我们还提出了概念锚定映射方法，将可疑行为与预定义的意图概念联系起来，提供了行为及其潜在意图的洞察。", "conclusion": "在HAI数据集上的广泛实验表明，SPAN显著优于现有方法，MSE降低了19.8%，平均mAP提高了1.78%。尤其是在低频情况下，SPAN显示出2.74%的mAP增益，这证明了其在捕捉微妙行为变化方面的优越能力。与离散分类系统相比，我们的连续怀疑建模方法可以实现早期检测和积极干预，极大地提高了系统的可解释性和实际应用中的实用性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20206", "html_url": "https://arxiv.org/abs/2510.20206", "title": "RAPO++: 跨阶段的文本到视频生成提示优化框架，通过数据对齐和测试时缩放", "title_en": "RAPO++: Cross-Stage Prompt Optimization for Text-to-Video Generation via Data Alignment and Test-Time Scaling", "authors": "Bingjie Gao,Qianli Ma,Xiaoxue Wu,Shuai Yang,Guanzhou Lan,Haonan Zhao,Jiaxuan Chen,Qingyang Liu,Yu Qiao,Xinyuan Chen,Yaohui Wang,Li Niu", "background": "文本到视频（T2V）生成中提示设计起着关键作用，但用户提供的提示往往简短、无结构且与训练数据不一致，限制了基于扩散的T2V模型的生成潜力。", "innovation": "提出了RAPO++，一种跨阶段提示优化框架，整合了训练数据对齐细化、测试时迭代扩展和大型语言模型的微调，无需修改基础生成模型即可显着提高T2V生成质量。该框架包括三个阶段：首先利用关系图检索相关的修饰词来丰富用户的提示并调整至与训练分布相匹配，增强组成性和多物体一致性；其次引入特定样本的提示优化机制，通过多源反馈迭代优化提示，逐步提高视频生成质量；最后利用优化后的提示对重写大语言模型进行微调，内化特定任务的优化模式，实现高效的高质量提示生成。", "conclusion": "跨阶段的提示优化框架RAPO++在五种最先进的T2V模型和五个基准测试中表现出显著优势，实现了语义对齐、组成推理、时间稳定性以及物理合理性的提升，其结果表明RAPO++是一个模型通用、成本效益高且可扩展的解决方案，为T2V生成中的提示优化设定了新标准。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20162", "html_url": "https://arxiv.org/abs/2510.20162", "title": "TOMCAT: 测试时全面知识积累用于组分零样本学习", "title_en": "TOMCAT: Test-time Comprehensive Knowledge Accumulation for Compositional Zero-Shot Learning", "authors": "Xudong Yan,Songhe Feng", "background": "现有的零样本学习方法在测试时间遇到性能下降的问题，这是因为标签空间分布的变化，这种变化是由于未见过的组分重新组合自属性和对象导致的。这些变化使得以前学习的知识不再适用，影响了模型的性能和有效性。当前的方法需要在训练时就固定模型的参数，难以应对测试时的分布变化挑战。因此，需要一种能够在测试时间灵活适应分布变化的方法，以提高模型在未见过的场景下的准确性。", "innovation": "本文提出了一种名为TOMCAT的新方法，该方法通过在未监督数据中积累综合的文本和视觉知识，并在测试时间更新多模态原型，来解决上述挑战。此外，TOMCAT引入了一个自适应更新权重，以控制原型调整的程度，使得模型能够在测试时灵活适应分布变化。此外，还设计了一个动态优先级队列，用于存储高置信度图像，从而从历史图像中获取视觉知识以进行推理。通过多模态联合表示学习对文本和视觉原型进行了语义对齐，从而进一步增强了模型的泛化能力。实验结果表明，TOMCAT方法在四个数据集上的表现达到了最好的效果，无论是在封闭世界还是开放世界设置下都是如此。", "conclusion": "广泛的实验表明，TOMCAT方法在四个基准数据集上达到了最先进的性能，在封闭世界和开放世界设置下都是如此，证明了其在处理测试时间分布变化方面的有效性。同时，这种方法为组分零样本学习领域做出了重要贡献，提高了模型对未知场景的适应性和泛化能力，为实际应用提供了新的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20182", "html_url": "https://arxiv.org/abs/2510.20182", "title": "评估视频模型作为多人行人类别轨迹模拟器", "title_en": "Evaluating Video Models as Simulators of Multi-Person Pedestrian Trajectories", "authors": "Aaron Appelle,Jerome P. Lynch", "background": "大规模的视频生成模型已经在多种场景中展示了极高的视觉真实度，激发了它们作为通用世界模拟器的可能性。现有基准大多只关注单一主体的场景，而忽略了多主体交互场景的应用。虽然生成的多主体动态视频的可行性尚未得到验证，但研究者希望通过建立一套严格的评估协议来检验文本到视频(T2V)和图像到视频(I2V)模型在多行人动态模拟中的有效性。为此，研究引入了基于现有数据集起始帧的I2V方法进行现实视频的对比，以及开发了一个提示套件来探索不同密度和交互的人行激流。其中一个关键步骤是提出了一种无需已知摄像机参数就能从像素空间重建二维鸟瞰轨迹的方法。研究发现，当前领先的模型已经学习到了有效的先验知识，能够模拟多主体的行为，但仍存在合并和消失等失效模式，这表明未来的研究需要在这些方面进行改进.", "innovation": "研究提出了一种严格的评估协议来验证文本到视频(T2V)和图像到视频(I2V)模型在模拟多行人动态上的有效性。该研究在I2V模型的评估中利用了现有数据集的起始帧，使得能够与真实视频数据集进行对照。在T2V模型的评估中，研究开发了一套提示工具来探索不同的行人密度与交互。研究引入的鸟瞰轨迹重建方法无需已知摄像机参数就能从像素空间重建2D轨迹。这些创新步骤为后续研究提供了一个可以遵循的可靠方案，有助于发现模型的优缺点及研究方向.", "conclusion": "研究揭示了当前领先模型已经有一定的能力来模拟多主体的有效行为，但模型也存在明显的错误，如合并和消失等。研究推测，这些失效模式或将成为未来研究改进的关键领域。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20217", "html_url": "https://arxiv.org/abs/2510.20217", "title": "EditInfinity: 使用二值量化生成模型进行图像编辑", "title_en": "EditInfinity: Image Editing with Binary-Quantized Generative Models", "authors": "Jiahuan Wang,Yuxin Chen,Jun Yu,Guangming Lu,Wenjie Pei", "background": "通过预训练的扩散模型生成图像并进行文本驱动的图像编辑，虽然展示了潜力，但通常会导致显著的调优开销，并且受限于在图像反转步骤中由扩散模型引入的近似误差。经典的适应范式首先通过图像反转推断生成轨迹，然后基于目标文本提示沿推断轨迹进行图像编辑，但这种近似误差限制了编辑效果。研究者观察到基于矢量量化（VQ）的生成模型能够提供精确的中间量化表示，这些模型在此可以提供更有效的监督，以提高图像反转的准确性。因此，提出了一种新的适应方法以利用VQ模型的优势进行图像编辑，该方法能够提供高保真度的图像编辑结果并精确对齐到文本提示的语义内容。", "innovation": "提出了一种名为EditInfinity的方法，利用二值量化生成模型（如Infinity）进行图像编辑。该方法提出了一种高效的图像反转机制，结合文本提示校正和图像风格保存，实现精确的图像反转。此外，设计了整体平滑策略，允许EditInfinity在保留源图像高保真度的同时，精确对齐到文本提示的语义内容。该方法在性能评测上优于最先进的基于扩散模型的方法，并在网络上公开了源代码。", "conclusion": "在对PIE-Bench基准图像编辑操作的广泛实验中，EditInfinity展示了其相对于最先进的基于扩散模型基线的优越性能，证明了二值量化生成模型在无监督图像编辑中的潜力"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20229", "html_url": "https://arxiv.org/abs/2510.20229", "title": "为什么大型视觉语言模型在较长回答中更容易出现幻觉：上下文的作用", "title_en": "Why LVLMs Are More Prone to Hallucinations in Longer Responses: The Role of Context", "authors": "Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang", "background": "近年来，大型视觉语言模型(LVLMs)取得了显著的进步，但在处理较长、自由形式的响应时也更容易出现幻觉问题。这类模型在较长的响应中表现出更多的幻觉，通常被归因于累积的不确定性。这项研究旨在探究幻觉是否仅由长度引起的错误引起，还是存在更深层次的机制。", "innovation": "该研究提出了一种新颖的'诱导-检测-抑制'框架。该框架通过对精心设计的上下文主动诱导幻觉，利用诱导的实例进行早期检测高风险情况，并最终在实际解码过程中抑制潜在的对象级幻觉。这种方法在所有基准测试中都表现出一致的显著改进，证明了其有效性，并验证了上下文的重要性。此外，该研究还超越了单纯追求性能提升，为更深入探索LVLMs较长响应中幻觉问题提供了新的见解和初步探索。", "conclusion": "这项研究不仅验证了上下文在LVLMs幻觉问题中的关键作用，还提出了一种新的方法来检测和抑制幻觉，证明了其有效性和研究价值。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20214", "html_url": "https://arxiv.org/abs/2510.20214", "title": "客观胎儿超声评估：对比表示学习在胎儿活动检测中的应用", "title_en": "Towards Objective Obstetric Ultrasound Assessment: Contrastive Representation Learning for Fetal Movement Detection", "authors": "Talha Ilyas,Duong Nhu,Allison Thomas,Arie Levin,Lim Wei Yap,Shu Gong,David Vera Anaya,Yiwen Jiang,Deval Mehta,Ritesh Warty,Vinayak Smith,Maya Reddy,Euan Wallace,Wenlong Cheng,Zongyuan Ge,Faezeh Marzbanrad", "background": "准确的胎儿活动（FM）检测对于评估产前健康至关重要，因为异常的运动模式可能是胎盘功能障碍或其他胎儿窘迫等潜在并发症的指示。传统的检测方法，包括母体感知和胎心图记录（CTG），存在主观性和准确性有限的问题。为了应对这些挑战，我们提出了一种新颖的自监督学习框架——对比超声视频表示学习（CURL）——用于从延长的胎儿超声视频记录中进行FM检测。", "innovation": "该研究引入了对比超声视频表示学习（CURL）方法，利用双重对比损失融合空间和时间对比学习，学习鲁棒的运动表示。此外，该方法还引入了特定任务的采样策略，在自监督训练中有效分离运动和非运动段落，并通过概率微调方法在任意长度的超声视频记录上实现灵活推理。在92个病人的内部数据集上（每个病例进行了30分钟的超声检查），CURL实现了78.01%的灵敏度和81.60%的AUROC，展示了其可靠和客观的FM分析潜力。", "conclusion": "这些结果强调了自监督对比学习在胎儿运动分析中的潜力，为改进产前监测和临床决策铺平了道路。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20238", "html_url": "https://arxiv.org/abs/2510.20238", "title": "COS3D: 共同协作的开放式词汇3D分割", "title_en": "COS3D: Collaborative Open-Vocabulary 3D Segmentation", "authors": "Runsong Zhu,Ka-Hei Hui,Zhengzhe Liu,Qianyi Wu,Weiliang Tang,Shi Qiu,Pheng-Ann Heng,Chi-Wing Fu", "background": "开放词汇3D分割是一项基本但具有挑战性的任务，需要对分割和语言理解的共同理解。现有的基于高斯点的分割方法要么依赖单一的3D语言域，导致分割效果不佳，要么依赖预先计算的类无关分割，导致错误积累。", "innovation": "本文提出了一种新的共同协作提示分割框架COS3D，整个管道中有效整合了语言和分割线索。该框架中引入了一个新的协作域概念，包括实例域和语言域。在训练过程中，通过新颖的实例到语言特征映射和设计高效的两阶段训练策略来有效构建协作域。在推理过程中，通过设计适应性语言到实例提示细化，促进高质量提示分割推理。该方法在两个广泛使用的基准测试中表现领先，并展示了其在各种应用中的高潜力，例如基于图像的新颖3D分割、层次分割和机器人技术。", "conclusion": "广泛的实验不仅证明了COS3D在现有方法上的领先性能，还展示了它在各种应用中的巨大潜力。该代码已在公共地址，供人们使用。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20247", "html_url": "https://arxiv.org/abs/2510.20247", "title": "基于掩码的位置编码和条带卷积上下文建模的跨视图物体地理定位：看不见的看见", "title_en": "Seeing the Unseen: Mask-Driven Positional Encoding and Strip-Convolution Context Modeling for Cross-View Object Geo-Localization", "authors": "Shuhan Hu,Yiru Li,Yuanyuan Li,Yingying Zhu", "background": "现有的跨视图物体地理定位方法依赖于关键点的位置编码，这种编码方式仅捕捉2D坐标而忽略了物体的形状信息，导致对注理解码高度敏感，降低了跨视图匹配能力。", "innovation": "提出了一种基于掩码的位置编码方案，利用分割掩码捕捉空间坐标和物体轮廓。同时设计了上下文增强模块，利用水平和垂直条带卷积核提取长程上下文特征，提升对纵向物体的特征区分度，从而提升了模型的鲁棒性和准确性。", "conclusion": "提出的EDGeo框架在CVOGL和VIGOR-Building两个公开数据集上实现了显著改进，在挑战性的地面至卫星场景定位准确率上提高了3.39%，提供了鲁棒的位置编码范式和上下文建模框架，进一步推动了跨视图地理定位的研究。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20267", "html_url": "https://arxiv.org/abs/2510.20267", "title": "实时代币检测与语音反馈系统用于视障人士", "title_en": "Real-Time Currency Detection and Voice Feedback for Visually Impaired Individuals", "authors": "Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim", "background": "智能手机等技术已成为我们日常生活中不可或缺的一部分，并通过其摄像头功能使得拍照和图像处理更加便捷。鉴于此，提出了一种针对视障人士的实时货币检测系统，帮助他们独立完成日常任务，如无依赖他人地处理货币。", "innovation": "该研究使用了YOLOv8 nano模型并结合自定义检测头部、深卷积层和Squeeze-and-Excitation块，以提高特征提取和检测准确性，实现在IoU=0.5时平均精度达到97.21%的高检测效果。通过检测后的语音反馈帮助视障人士识别货币。", "conclusion": "本文提出了一个实用性较强的货币检测系统，以此来帮助视障人士独立处理货币。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20244", "html_url": "https://arxiv.org/abs/2510.20244", "title": "Empower Words: 双分支架构用于结构化短语和句子级别的时空定位", "title_en": "Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding", "authors": "Minseok Kang,Minhyeok Lee,Minjung Kim,Donghyeong Kim,Sangyoun Lee", "background": "视频时空定位（VTG）旨在将给定自然语言查询中提及的时空段落准确地定位到长的未裁剪视频中。VTG任务通常包括两个子任务：关键帧检索（Moment Retrieval, MR）和高光检测（Highlight Detection, HD）。虽然近期使用CLIP和InternVideo2等强预训练跨模态模型取得了进展，但现有方法通常在跨模态注意力中对所有文本标记处理一致，忽略了它们的语义差异。实验验证了这种做法的局限性，表明现有模型过于依赖全局语义（由[EOS]驱动）而未能有效利用字级信号，这限制了它们实现细粒度的时间同步能力。", "innovation": "本文提出了DualGround，这是一种双分支架构，明确地分离全局和局部语义，通过将[EOS]标记路由到句子级路径并聚类词标记为短语级单元，以实现局部定位。该方法（1）通过结构上分离的方式引入了标记角色感知的跨模态交互策略，使视频特征与句子级和短语级语义对齐，（2）引入了联合建模框架，不仅改善了全局句子级对齐，还通过利用结构化短语感知上下文增强了细粒度的时间定位。这一设计使模型能够捕捉到粗略和局部的语义，从而实现更具表现力和上下文感知的视频定位。DualGround在QVHighlights和Charades-STA基准测试集上在关键帧检索和高光检测任务上均取得了最先进的性能，证明了分离语义建模在视频-语言对齐中的有效性。", "conclusion": "DualGround设计能够捕捉粗略和局部语义，实现更为表现力和上下文感知的视频定位，最终在关键帧检索和高光检测任务上取得了最先进的性能，验证了分离语义建模的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20256", "html_url": "https://arxiv.org/abs/2510.20256", "title": "Calibrating Multimodal Consensus for Emotion Recognition", "title_en": "Calibrating Multimodal Consensus for Emotion Recognition", "authors": "Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan", "background": "近年来，多模态情感识别（MER）取得了显著进展。然而，大多数现有的方法忽视了模态间可能出现的语义不一致性，例如文本和视觉输入之间的情感冲突线索。此外，由于文本模态的强大表征能力，现有方法往往过度依赖文本，这可能导致识别准确率降低。解决这些挑战的需要新的模型和技术应运而生。", "innovation": "本文提出了一种新的模型称为校准多模态共识（Calibrated Multimodal Consensus，CMC）。CMC包括伪标签生成模块（PLGM），该模块产生伪单模标签，使单模态预训练以自监督方式成为可能。CMC还包含一个无参数融合模块（Parameter-free Fusion Module，PFM）和一个多模态共识路由器（Multimodal Consensus Router，MCR），用于多模态微调，从而减轻文本主导性并指导融合过程朝着更可靠的共识方向进行。实验结果显示，CMC在四个数据集CH-SIMS、CH-SIMS v2、CMU-MOSI和CMU-MOSEI中的性能与当今最先进的方法相当或更优，并在CH-SIMS和CH-SIMS v2中语义不一致场景下显示出显着优势。", "conclusion": "本文提出了一种称为校准多模态共识（CMC）的新模型，通过伪标签生成模块和无参数融合模块，成功减轻了语义不一致性和文本主导性问题，实现了在多个数据集上的出色性能，特别是在存在语义不一致性的情况下。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20212", "html_url": "https://arxiv.org/abs/2510.20212", "title": "FlowCycle：追求循环一致性的流以文本为基础的编辑", "title_en": "FlowCycle: Pursuing Cycle-Consistent Flows for Text-based Editing", "authors": "Yanghao Wang,Zhen Wang,Long Chen", "background": "近年来，预训练的文字到图像生成模型在基于文本的图像编辑方面取得了显著的进步。主流方法通常采用破坏-恢复的范式，首先将源图像破坏成一个“中间状态”，然后在提示指导之下恢复到目标图像。然而，当前的方法以目标无关的方式构建这个中间状态，主要集中在实现源图像的重构，而忽略与特定编辑目标之间的语义差距。这样的设计导致在需要进行与源图像显著不同的修改时，编辑效果有限且不一致。本文提出观点，中间状态应该是目标意识的，即在编辑相关内容上进行选择性破坏，同时保留与编辑无关的内容。", "innovation": "提出了FlowCycle，一种新型的无反转的基于流的编辑架构，通过学习可学习噪声参数化破坏，并通过循环一致性的过程优化它们。通过交替编辑从源到目标，再从目标恢复到源，并通过双重一致性约束，FlowCycle学习生成目标意识的中间状态，使编辑更加忠实且保持源图像的一致性。广泛的消融实验表明，FlowCycle在编辑质量和一致性方面优于现有的先进方法。", "conclusion": "通过迭代编辑从源到目标，然后再从目标恢复到源，并通过双重一致性约束，FlowCycle学会了生成目标意识的中间状态，从而实现忠实地修改同时保持源图像的一致性。实验结果表明，FlowCycle在编辑质量和一致性方面表现优于最先进的方法。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20268", "html_url": "https://arxiv.org/abs/2510.20268", "title": "GMFVAD: 使用粒度多元模态特征提高视频异常检测", "title_en": "GMFVAD: Using Grained Multi-modal Feature to Improve Video Anomaly Detection", "authors": "Guangyu Dai,Dong Chen,Siliang Tang,Yueting Zhuang", "background": "视频异常检测(VAD)是一项挑战性任务，涉及在连续监控视频中检测异常帧。此前的工作通常利用时空视觉特征的相关性来区分视频片段中是否存在异常。最近，一些研究尝试引入多模态信息，如文本特征，以增强视频异常检测的结果。然而，这些方法只是粗略地将文本特征融入到视频片段中，忽视了视频片段中可能存在的大量冗余信息。", "innovation": "提出了利用多模态信息的多样性来进一步细化提取特征，减少视觉特征中的冗余，提出了用于视频异常检测的粒度多模态特征(GMFVAD)。方法具体包括基于视频片段生成更细粒度的多模态特征，总结主要内容，并结合原始视频字幕引入文本特征以进一步增强突出部分的视觉特征。", "conclusion": "所提出的GMFVAD在四个主要数据集上取得了最先进的性能。消融实验也验证了GMFVAD的改进来自于冗余信息的减少。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20287", "html_url": "https://arxiv.org/abs/2510.20287", "title": "在生成式人工智能时代的霹雳舞视频分类", "title_en": "Breakdance Video classification in the age of Generative AI", "authors": "Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson", "background": "近年来，大规模视觉语言模型在多项体育应用中得到了广泛应用，但这些应用主要集中在足球、板球、篮球等少数几项热门运动上，且侧重于生成任务，如视觉问答和回放生成。这项研究旨在探索现代视频基础模型（包括编码器和解码器）在霹雳舞这一小众但非常流行的舞蹈运动中的适用性。", "innovation": "研究发现，视频编码器模型在预测任务中继续超出现有的视频语言模型。研究提供了选择编码器模型的见解，并对微调解码器模型在霹雳舞视频分类中的运行机制进行了全面分析。", "conclusion": "研究结果表明，视频编码器模型在霹雳舞视频分类任务中表现优异。通过对工作原理的深入分析，该研究为未来在该领域的研究和应用提供了重要参考。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20281", "html_url": "https://arxiv.org/abs/2510.20281", "title": "视觉先验偏见消除对视觉常识推理的影响", "title_en": "Causal Debiasing for Visual Commonsense Reasoning", "authors": "Jiayi Zou,Gengyun Jia,Bing-Kun Bao", "background": "视觉常识推理(VCR)指的是基于图像回答问题和提供解释的能力。现有的方法虽然在预测准确性上表现出色，但往往忽视了数据集中的偏见，缺乏解决偏见的策略。已有研究表明，视觉和文本数据中存在共现偏见和统计偏见。", "innovation": "本文提出了VCR-OOD数据集，包括VCR-OOD-QA和VCR-OOD-VA子集，用于评估模型在两种模态下的泛化能力。利用因果图和预测捷径分析了VCR，并采用后门调整方法去除偏见。通过建立基于正确答案集合的词典来消除预测捷径，实验结果表明该去偏方法在不同数据集上的有效性。", "conclusion": "实验结果显示，本文提出的去偏方法在不同数据集上彰显了其有效性，能够有效减少VCR场景中的偏见。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20286", "html_url": "https://arxiv.org/abs/2510.20286", "title": "UI-Ins: 使用多视角指令推理增强GUI接地", "title_en": "UI-Ins: Enhancing GUI Grounding with Multi-Perspective Instruction-as-Reasoning", "authors": "Liangyu Chen,Hanzhang Zhou,Chenglin Cai,Jianan Zhang,Panrong Tong,Quyu Kong,Xu Zhang,Chen Liu,Yuqi Liu,Wenxuan Wang,Yue Wang,Qin Jin,Steven Hoi", "background": "GUI接地，即将自然语言指令映射到可操作的UI元素，是GUI代理的核心能力。以往的工作大多将指令视为用户意图的静态代理，忽视了指令多样性和质量对接地性能的影响。通过对现有接地数据集的仔细调查，发现其中23.3%的指令存在缺陷，并展示了在推理时间利用指令多样性可带来76%的相对性能提升。", "innovation": "提出了指令推理作为一种动态分析路径的范式，使其能够作为多视角推理的途径，并设计了一种两阶段训练框架：监督微调用于插入多视角推理，随后通过强化学习优化路径选择和组合。提出的UI-Ins-7B和UI-Ins-32B模型在五个挑战性的接地基准上取得了最先进的结果，并展示了生成和合成新的指令路径的能力，特别是UI-Ins-32B在UI-I2E-Bench、ScreenSpot-Pro和MMBench-GUI L2上的接地准确率分别为87.3%、57.0%和84.9%。此外，该模型展现了强大的代理潜力，在AndroidWorld中取得了74.1%的成功率，且通过分析发现，推理可以增强而非阻碍接地性能，并且方法能在SFT+RL框架中缓解策略崩溃问题。", "conclusion": "该模型通过多视角指令推理显著提升了GUI接地性能，拥有强大的执行能力，并且实现了在多个 Benchmark上的先进成果，展示了其在真实环境中的应用潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20331", "html_url": "https://arxiv.org/abs/2510.20331", "title": "AnyPcc：使用单一通用模型压缩任意点云", "title_en": "AnyPcc: Compressing Any Point Cloud with a Single Universal Model", "authors": "Kangli Wang,Qianxi Yi,Yuqi Ye,Shihao Li,Wei Gao", "background": "深度学习驱动的点云几何压缩存在泛化能力差的问题。这种问题主要是由于缺乏稳健的上下文模型以及对分布外（OOD）数据处理不充分造成的。", "innovation": "提出了一个称为AnyPcc的通用点云压缩框架。该框架包括一个通用上下文模型，可以利用空间和通道相关性来捕获稳健的上下文依赖性。此外，还引入了一种名为实例自适应微调（IAFT）的新策略，通过结合显式和隐式压缩方法来处理OOD数据，从而在压缩时网络权重的边际比特成本被节省出来的几何压缩比特数目远超。", "conclusion": "广泛实验表明，AnyPcc在点云压缩上达到了新的最先进水平。我们还将发布代码和数据集以促进可重复研究。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20348", "html_url": "https://arxiv.org/abs/2510.20348", "title": "AccuQuant: 用于量化扩散模型的模拟多步去噪", "title_en": "AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models", "authors": "Seunghoon Lee,Jeongwoo Choi,Byunggwan Son,Jaehyeon Moon,Jeimin Jeon,Bumsub Ham", "background": "在扩散模型中，量化误差在去噪步骤过程中逐渐累积。传统的后训练量化方法未能有效解决这一问题，它们通常通过单独最小化每一步之间的差异来模仿扩散模型的训练过程。这种传统方法对于量化扩散模型的效果并不理想。", "innovation": "AccuQuant通过模拟多个去噪步骤，并考虑这些步骤中的累积误差，来精确地量化扩散模型。具体而言，它直接最小化全精度扩散模型与量化模型在这几个去噪步骤中的输出差异，而不是像传统方法那样独立最小化每一步的差异。此外，AccuQuant还引入了一种高效的实现技术，将内存复杂度显著降低至$\textbf{O(1)}$。", "conclusion": "AccuQuant在标准基准上的各种任务和扩散模型中都表现出高效性和有效性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20322", "html_url": "https://arxiv.org/abs/2510.20322", "title": "HyperET：在双曲空间中高效训练多模态大语言模型", "title_en": "HyperET: Efficient Training in Hyperbolic Space for Multi-modal Large Language Models", "authors": "Zelin Peng,Zhengqin Xu,Qingyang Liu,Xiaokang Yang,Wei Shen", "background": "多模态大型语言模型（MLLMs）已成为一种变革性的方法，用于对视觉和文本理解进行对齐。它们通常在训练过程中需要极高的计算资源（例如成千上万的GPU），以在多粒度级别实现跨模态对齐。我们指出，这种低效率的主要原因是它们广泛使用的视觉编码器，例如CLIP和SAM，这些编码器缺乏在多粒度级别与语言的对齐机制。因此，本文提出了一种新的双曲空间中的高效训练策略，解决了多模态数据在视觉和文本表示之间对齐不足的问题，通过在双曲空间中动态调整半径来优化视觉表示，与它们的文本对应物在任意粒度级别对齐，并提供了一种灵活而高效的参数化策略，通过Mobius乘法操作实现。", "innovation": "提出了一种名为HyperET的新的高效训练策略，通过在双曲空间中动态调整半径来优化视觉表示，与它们的文本对应物在任意粒度级别对齐。使用可学习矩阵并配有Mobius乘法操作，通过三种有效配置实现：对角缩放矩阵、块状对角矩阵和带状矩阵。", "conclusion": "在多个多模态大型语言模型基准上的全面实验表明，HyperET可以一致地提高现有的预训练和微调大语言模型的表现，而参数增加量不到1%。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20385", "html_url": "https://arxiv.org/abs/2510.20385", "title": "Positional Encoding Field", "title_en": "Positional Encoding Field", "authors": "Yunpeng Bai,Haoxiang Li,Qixing Huang", "background": "扩散变换器（DiTs）已成为视觉生成的主导架构，推动了图像和视频模型的最新成果。通过利用块标记（patch tokens）和位置编码（PEs），DiTs结合了Transformer的可扩展性与空间和时间的归纳偏差。", "innovation": "研究发现块标记具有惊人的独立性：即使位置编码被扰动，DiTs依然可以产生全局连贯的输出，表明空间连贯性主要由位置编码控制。基于此发现，作者引入了位置编码场（PE-Field），它将位置编码从二维平面扩展到结构化的三维场。PE-Field 含有体积感知的编码以支持三维推理，以及精细粒度的子块控制的层次编码，使DiTs能够直接在三维空间中建模几何形状。使用PE-Field增强后的DiT在单图像视图合成和可控的三维空间图像编辑任务中达到最新性能。", "conclusion": "PE-Field增强的DiT取得了单图像新视角合成任务的最新性能，并且在可控的空间图像编辑任务中表现出良好的泛化能力。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20291", "html_url": "https://arxiv.org/abs/2510.20291", "title": "跨模态专家混合框架在地理空间定位中的高效参数方案", "title_en": "A Parameter-Efficient Mixture-of-Experts Framework for Cross-Modal Geo-Localization", "authors": "LinFeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li", "background": "该论文介绍了一种用于RoboSense 2025行进挑战Track 4中自律无人机导航的解决方案。任务要求从多种平台（卫星、无人机、地面）的大规模图像库中，根据自然语言查询检索最具相关性的地理参照图像。主要难点在于平台之间存在显著差异，以及通用训练描述和特定平台测试查询之间的领域差距。为解决这些问题，论文提出了一种领域对齐预处理管道和混合专家（MoE）框架来优化模型性能，克服跨模态和平台特异性带来的挑战。", "innovation": "该研究提出了一种参数高效的混合专家框架（Mixture-of-Experts, MoE），包括平台级分区、卫星数据增强及去除方向性词汇，以及一种基于大语言模型（LLM）的标题精炼流程，以更好地对齐文本语义和平台间独特的视觉特征。通过BGE-M3（文本）和EVA-CLIP（图像）来训练三种平台专家，使用逐步两阶段、难样本挖掘策略进行训练以增强辨别力，并在推理时融合专家得分。该系统在官方排行榜上名列前茅，证明了其在不同视角下跨模态地理定位的鲁棒性。", "conclusion": "该系统展示了跨模态地理定位能力，特别是面对多种平台和视角的挑战。使用所提出的混合专家框架增强了模型的适应性和准确性，为地理空间定位任务提供了有效的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20285", "html_url": "https://arxiv.org/abs/2510.20285", "title": "DMC$^3$: 双模态反事实对比构建方法在第一人称视频问答中的应用", "title_en": "DMC$^3$: Dual-Modal Counterfactual Contrastive Construction for Egocentric Video Question Answering", "authors": "Jiayi Zou,Chaofan Chen,Bing-Kun Bao,Changsheng Xu", "background": "第一人称视角的视频对于理解个人视角下的事件至关重要。现有的方法通过预训练和微调取得了进展，但忽略了第一人称视角带来的独特挑战，如理解多个事件和识别手部与物体的交互。", "innovation": "本文提出了一种双模态反事实对比构建（DMC$^3$）框架，包括基于事件描述改写和核心交互挖掘生成正负样本的模态反事实样本构造模块，以及涉及反事实样本的对比优化模块。该框架通过对比损失最小化原始样本与正样本之间的距离，同时最大化与负样本之间的距离，提高了第一人称视频问答的性能，达到了SOTA水平。", "conclusion": "实验表明，该方法在EgoTaskQA的normal和indirect分割上分别取得了52.51%和46.04%的准确率，在QAEGO4D上达到了13.2%的准确率，均达到了最新的技术水平。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20393", "html_url": "https://arxiv.org/abs/2510.20393", "title": "缓解多文化图像到食谱检索中的跨模态表示偏差", "title_en": "Mitigating Cross-modal Representation Bias for Multicultural Image-to-Recipe Retrieval", "authors": "Qing Wang,Chong-Wah Ngo,Yu Cao,Ee-Peng Lim", "background": "现有的图像到食谱检索方法假设食物图像能够充分捕捉食谱中文字记录的细节。然而，食物图像只能反映烹饪完成后的视觉效果，而不能展现背后的烹饪过程。因此，学习将图像和食谱之间的模态差距桥梁化的跨模态表示方法倾向于忽视一些不直观但对食谱检索至关重要的食谱特定细节。具体来说，表示学习偏向于捕捉主要的视觉元素，导致难以区分使用材料和烹饪方法有细微差别的食谱。特别是当训练数据来源混杂不同民族文化时，这种偏向会更加严重。", "innovation": "本文提出了一种新颖的归因方法，预测可能在图像中被忽视的烹饪元素，并明确将这些元素注入到跨模态表示学习中，以缓解偏差。该方法在标准的单语言Recipe1M数据集和新编纂的多语言多文化烹饪数据集上进行了实验。", "conclusion": "实验结果表明，提出的归因表示学习能够揭示细微的食材和烹饪动作，并在单语言和多语言多文化数据集上实现了出色的检索性能。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20438", "html_url": "https://arxiv.org/abs/2510.20438", "title": "基于视觉变换器的动态权重调整知识蒸馏：高准确度肺癌检测及实时部署", "title_en": "Dynamic Weight Adjustment for Knowledge Distillation: Leveraging Vision Transformer for High-Accuracy Lung Cancer Detection and Real-Time Deployment", "authors": "Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel", "background": "该研究提出了一种新的肺癌分类方法，即FuzzyDistillViT-MobileNet模型，旨在解决疾病诊断中的不确定性和复杂性。不同于传统的静态知识蒸馏方法，该模型通过动态调整蒸馏权重，利用模糊逻辑驱动的知识蒸馏，使学生模型能够专注于高置信度区域并减少对模糊区域的注意力。这种方法可以更好地处理肺癌不同区域间不断变化的不确定性。研究还使用Gamma校正和直方图均衡化等像素级图像融合改进技术来提高图像质量，并通过小波基融合方法整合处理后的图像，以提高图像分辨率和特征保留。此外，采用遗传算法从12个预训练模型中选择最优的学生模型，以平衡模型性能和计算成本。", "innovation": "1. 提出了一种基于动态模糊逻辑控制的知识蒸馏方法，能动态调整蒸馏权重，帮助学生模型在复杂和不确定的图像区域中更好地进行学习。\n2. 使用像素级图像融合改进技术，如Gamma校正和直方图均衡化，以提高图像质量和特征保留。\n3. 通过小波基融合方法将图像分辨率标准化，并逐级平均系数，以增强特征表示。\n4. 利用遗传算法选择最优的学生模型，确保在高性能和低计算成本之间取得平衡。", "conclusion": "该研究在两个数据集上评估了FuzzyDistillViT-MobileNet模型，分别使用了25000张病理图像和IQOTH/NCCD CT扫描图像，显示出在不同成像领域中具有较高的准确率（分别为99.16%和99.54%），证明了该方法的有效性和实用性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20482", "html_url": "https://arxiv.org/abs/2510.20482", "title": "可靠且可复现的群体特征推断以实现面部分析中的公平性", "title_en": "Reliable and Reproducible Demographic Inference for Fairness in Face Analysis", "authors": "Alexandre Fournier-Montgieux,Hervé Le Borgne,Adrian Popescu,Bertrand Luvison", "background": "面部分析系统（Face Analysis Systems, FAS）的公平性评估通常依赖于自动人群特征属性推断（Automatic Demographic Attribute Inference, DAI），而DAI过程的可靠性对公平性审计的有效性至关重要。本文从理论上强调了DAI过程可靠性对FAS公平性评估结果的影响，并指出改进DAI可靠性可以减少偏见并降低估计变异。", "innovation": "文章提出了一种完全可复现的人群特征推断管道，取代了传统的端到端训练方法，采用了模块化的迁移学习方法。该设计将预训练的人脸识别编码器与非线性分类器相结合。这一管道从准确性、公平性和新引入的鲁棒性（通过同一体内一致性定义）三个维度进行了审计。提出的鲁棒性指标适用于任何人群分类方案。该方法在多个数据集和训练设置上对性别和种族推断进行了基准测试，结果表明，所提出的方法比强基线方法有更好的表现，特别是在种族推断上表现更好，种族是更具挑战性的特征。", "conclusion": "本文通过提供训练数据集的元数据、完整的代码库、预训练模型和评估工具包，推动了透明性和可复现性。该工作为公平性审计中的人群推断提供了一个可靠的基础。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20470", "html_url": "https://arxiv.org/abs/2510.20470", "title": "Conan: 分阶段学习多尺度视觉证据进行推理", "title_en": "Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence", "authors": "Kun Ouyang,Yuanxin Liu,Linli Yao,Yishuo Cai,Hao Zhou,Jie Zhou,Fandong Meng,Xu Sun", "background": "多模态大型语言模型（MLLMs）在视频推理任务中面临重大挑战，需要跨帧进行多步推理。尽管基于增强学习（RL）的方法可以增强推理能力，但它们往往依赖于仅基于文本的推理链，导致结论不相关或虚构。相反，帧检索方法虽引入了视觉锚定，但在不准确的证据定位方面仍存在困难。面对这些挑战，该研究提出了Conan框架，一种基于证据支持的多步视频推理框架，通过识别上下文和证据帧、跨帧线索推理以及决定何时停止推理或进一步探索来解决这一问题。Conan构建了一个名为Conan-91K的大型数据集，包括帧识别、证据推理和动作决策，同时设计了一种多阶段渐进式冷启动策略结合一个识别-推理-行动（AIR）进程增强框架来联合提升多步视觉推理能力。实验在六个多步推理基准上表明，Conan比基线Qwen2.5-VL-7B-Instruct的准确率平均提高超过10%，达到目前的最先进水平。此外，Conan在长视频理解任务上具有有效的泛化能力，验证了其强大的可扩展性和鲁棒性。", "innovation": "1. 构建了包含帧识别、证据推理和决策的大型自动推理数据集Conan-91K。\n2. 设计了多阶段渐进式冷启动策略结合识别-推理-行动（AIR）RLVR训练框架来提升多步视觉推理能力。\n3. 提出了基于证据支持的多步视频推理框架Conan，通过跨帧线索推理和决策增强模型的推理能力，解决了视觉锚定和不准确证据定位的问题。", "conclusion": "该研究提出的Conan框架在多步视频推理领域取得了显著的性能提升，通过自动推理数据集和多阶段训练策略的结合，使其能够更好地理解和处理长视频中的多步推理任务。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20512", "html_url": "https://arxiv.org/abs/2510.20512", "title": "EchoDistill: 双向概念蒸馏以实现单步扩散个人化", "title_en": "EchoDistill: Bidirectional Concept Distillation for One-Step Diffusion Personalization", "authors": "Yixiong Yang,Tao Wu,Senmao Li,Shiqi Yang,Yaxing Wang,Joost van de Weijer,Kai Wang", "background": "最近加速文本到图像(T2I)扩散模型的发展使得即使是单步骤内也可以生成高保真图像。然而，这些模型因单步骤方法对新概念分布的捕捉能力有限，难以进行个人化以包含新颖的概念。现有的单步骤扩散个人化方法存在挑战。为了应对这一问题，我们提出了一种双向概念蒸馏框架EchoDistill，该框架可以实现单步骤扩散个人化(1-SDP)。", "innovation": "我们的方法通过端到端的训练过程，利用多步骤扩散模型（教师）和单步骤扩散模型（学生）同时训练。首先，概念从教师模型传递给学生，然后孩子模型的信息传递回给教师模型。在EchoDistill过程中，通过共享文本编码器确保两个模型的一致语义理解。其次，通过对抗损失以与真实图像分布对齐，并通过对齐损失以保持与教师输出的一致。此外，我们提出了双向回响精炼策略，通过利用学生模型更快的生成能力，向教师模型反馈，以增强学生模型对新概念的个人化能力和提高教师生成的质量。我们的实验展示了此协作框架在1-SDP设置下显著优于现有个人化方法，并建立了一个新的快速而有效的个人化范式。", "conclusion": "我们的工作表明，该协作框架在1-SDP设置下相对于现有个人化方法有显著的性能提升，建立了一种新的实现单步骤扩散模型快速有效个人化的范式。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20284", "html_url": "https://arxiv.org/abs/2510.20284", "title": "知识指导型神经网络在复值合成孔径雷达图像识别中的应用", "title_en": "Knowledge-Informed Neural Network for Complex-Valued SAR Image Recognition", "authors": "Haodong Yang,Zhongling Huang,Shaojie Guo,Zhe Zhang,Gong Cheng,Junwei Han", "background": "在数据有限和领域偏移的情况下，现有的复值合成孔径雷达（CV-SAR）图像识别深度学习模型受到表示三难问题的限制：即通用性、可解释性和效率之间的优化需要同时实现，但彼此又存在冲突。传统的数据驱动模型未能充分利用CV-SAR数据的丰富电磁散射特性，导致了在这个领域的不足。", "innovation": "本文提出了一种名为Knowledge-Informed Neural Network (KINN)的轻量化框架，基于“压缩-聚合-压缩”架构。该框架首先通过物理引导压缩，将物理先验嵌入新的字典处理器中，生成紧凑的解折叠网络来高效提取稀疏且物理基础的特征。随后，连续的聚合模块丰富这些表示，最后的语义压缩阶段使用紧凑的分类头部结合自蒸馏学习最大相关且区分的嵌入。KINN在CNN和Vision Transformer版本中均有实现（分别为0.7M和0.95M参数）。广泛的评估表明，KINN在参数高效的识别中表现出色，在数据稀缺和分布外场景中具有出色的泛化能力，并具有可解释性，从而解决了表示三难问题，为在合成孔径雷达图像分析中的可信人工智能提供了一条新路径。", "conclusion": "KINN能够在复值合成孔径雷达图像识别中实现高效的参数化、有效的解释和高效率，并为合成孔径雷达图像分析提供了新的可信人工智能解决方案，它证实了CV-SAR数据的电磁散射特征对于解决上述三难问题的重要性。KINN为领域知识在深度学习中的应用提供了新的视角，为未来的研究带来了希望。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20549", "html_url": "https://arxiv.org/abs/2510.20549", "title": "基于深度学习的视觉SLAM旨在辅助视障导航", "title_en": "Deep Learning-Powered Visual SLAM Aimed at Assisting Visually Impaired Navigation", "authors": "Marziyeh Bamdad,Hans-Peter Hutter,Alireza Darvishy", "background": "尽管SLAM技术取得了进展，但在低纹理、运动模糊或恶劣光照等挑战性条件下稳健运行仍是一个开放的挑战。这类条件在为视障人士提供辅助导航的应用中非常普遍，会削弱定位准确性和跟踪稳定性，从而降低导航的可靠性和安全性。", "innovation": "我们提出了一种名为SELM-SLAM3的深度学习增强视觉SLAM框架，该框架结合了SuperPoint和LightGlue以实现稳健的特征提取和匹配。我们使用TUM RGB-D、ICL-NUIM和TartanAir等数据集对框架进行了评估，这些数据集包含多样化的挑战性场景。我们的框架在TUM RGB-D和ICL-NUIM场景中优于传统ORB-SLAM3达87.84%，在TartanAir场景中超越最先进的RGB-D SLAM系统达36.77%。", "conclusion": "我们的框架在挑战性条件（如低纹理场景和快速运动）下的性能有所增强，提供了开发视障人士导航辅助工具的可靠平台。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20539", "html_url": "https://arxiv.org/abs/2510.20539", "title": "Blur2seq: 仅从单张相机运动模糊图像进行盲去模糊和相机轨迹估计", "title_en": "Blur2seq: Blind Deblurring and Camera Trajectory Estimation from a Single Camera Motion-blurred Image", "authors": "Guillermo Carbajal,Andrés Almansa,Pablo Musé", "background": "相机抖动引起的运动模糊仍然是图像恢复中的一个重要挑战，尤其是在大范围或旋转运动的情况下。现有的方法难以处理严重的或空间变异的模糊情况，尤其是在端到端的去模糊网络中表现不佳。因此，迫切需要一种能够从单张模糊图像中同时估计潜在清晰图像和相机运动轨迹的方法，以实现有效的图像去模糊和相机运动恢复。", "innovation": "本文提出了一种基于深度学习的框架，能够从单张模糊图像中联合估计潜在的清晰图像和底层的相机运动轨迹。该方法采用了项目运动模糊模型（PMBM），通过一个可微模糊生成模块实现高效处理，并与现代网络兼容。通过神经网络预测完整的3D旋转轨迹，指导从头到尾训练的基于模型的恢复网络。此外，通过后推理优化轨迹，进一步提高模糊输入和恢复输出之间的一致性。这种模块化架构提供了可解释性，展示了产生模糊的相机运动。该方法特别在严重或空间变异性模糊的情况下表现出色，优于现有的端到端去模糊网络，并在合成和真实数据集上取得了最先进的性能。", "conclusion": "实验结果表明，该方法在合成和真实数据集上均表现出色，特别是在严重或空间变异模糊的情况下，优于现有的端到端去模糊网络。代码和已训练的模型可在指定的链接处获取。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20519", "html_url": "https://arxiv.org/abs/2510.20519", "title": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning", "title_en": "Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning", "authors": "Xiaohan Lan,Fanfan Liu,Haibo Qiu,Siqi Yang,Delian Ruan,Peng Shi,Lin Ma", "background": "近期，大型语言模型（LLM）推理取得了显著进展，在诸如数学问题解决等复杂任务上取得了重大性能提升。然而，当前的多模态大型推理模型存在两个主要局限：一是即使对于简单查询，也会使用计算成本高的推理方法，导致效率低下；二是过度强调专业化推理限制了其更广泛的理解能力。", "innovation": "本文提出了一种名为Metis-HOME的混合优化专家混合（Hybrid Optimized Mixture-of-Experts）框架，旨在解决上述权衡问题。Metis-HOME通过将原始密集模型结构化为两个不同的专家分支来实现‘混合思考’模式：一个专用于复杂、多步推理的思考分支，另一个优化用于快速直接推理，如通用多模态问答（VQA）和光学字符识别（OCR）任务。轻量级、可训练的路由器动态将查询分配给最适合的专家。", "conclusion": "全面的评估显示，我们的方法不仅显著增强了复杂的推理能力，还提高了模型的一般能力，解决了其他专为推理优化的模型中观察到的能力下降趋势。本文为构建既强大又多功能的大规模多模态语言模型（MLLM）奠定了新的范式，有效地解决了推理与推广之间的普遍矛盾。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20550", "html_url": "https://arxiv.org/abs/2510.20550", "title": "从廉价到专业：基于学习的自适应摄像头参数网络实现专业级成像", "title_en": "From Cheap to Pro: A Learning-based Adaptive Camera Parameter Network for Professional-Style Imaging", "authors": "Fuchen Li,Yansong Du,Wenbo Cheng,Xiaoxia Zhou,Sen Yin", "background": "消费者级别的相机系统在低光、高动态范围、背光以及空间色温变化等复杂光照条件下难以保持稳定的质量，导致曝光不足、色彩偏差和色调不一致，这些问题会影响下游视觉任务的表现。", "innovation": "提出了一种名为ACamera-Net的轻量级且场景自适应的相机参数调整网络，直接从RAW输入中预测最优的曝光和白平衡。该框架包含两个模块：ACamera-Exposure，用于估计ISO以减轻曝光不足和对比度损失；ACamera-Color，用于预测色温相关性和增益因子以提高色彩一致性。该网络针对边缘设备的实时推理进行优化，可以无缝集成到成像管道中，通过现实世界数据的训练，模型在不同光照条件下表现出良好的泛化能力，实验表明ACamera-Net能提升图像质量并稳定感知输出，优于常规的自动模式和轻量级基线，无需依赖额外的图像增强模块", "conclusion": "ACamera-Net模型通过直接预测最优的曝光和白平衡，有效地解决了复杂光照条件下的图像质量问题，并在多场景中表现优异，证明了其在实时设备上的高效应用价值。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20531", "html_url": "https://arxiv.org/abs/2510.20531", "title": "Fake-in-Facext: 向精细可解释深度假图分析迈进", "title_en": "Fake-in-Facext: Towards Fine-Grained Explainable DeepFake Analysis", "authors": "Lixiong Qin,Yang Zhang,Mei Wang,Jiani Hu,Weihong Deng,Weiran Xu", "background": "多模态大型语言模型（MLLMs）的进步缩小了视觉和语言任务之间的差距，使可解释深度假图分析（XDFA）的实现成为可能。然而，当前的方法存在细粒度感知不足的问题：数据注释中对数据中瑕疵的描述粗糙且不可靠，模型无法支持文本伪造解释与视觉证据之间的联系输出，也无法适应任意面部区域的查询输入。因此，其回复未能充分基于Face Visual Context（Facext）.", "innovation": "我们提出了 Fake-in-Facext (FiFa) 框架，着眼于数据注释和模型构建。首先定义了 Facial Image Concept Tree（FICT），将面部图像细分为区域概念，从而获得更可靠的注释流水线，FiFa-Annotator，用于伪造解释。基于专用数据注释，我们引入了新的 Artifact-Grounding Explanation（AGE）任务，该任务生成文本伪造解释以及操纵瑕疵的分割掩码。提出了统一的多任务学习架构 FiFa-MLLM，以支持细粒度的可解释深度假图分析的多种多模态输入和输出。通过多个辅助监督任务，FiFa-MLLM 在 AGE 任务上超过了强大的基线，并在现有的 XDFA 数据集上实现了SOTA性能。", "conclusion": "通过 FiFa 框架，我们实现了对精细可解释深度假图分析的提升，该框架包括定义 FICT、创建 FiFa-Annotator 和 AGE 任务，以及多任务学习架构 FiFa-MLLM，该架构在多个基准测试上取得了优异的性能。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20558", "html_url": "https://arxiv.org/abs/2510.20558", "title": "从远到近：不同细节层次下人群表示的感知评估", "title_en": "From Far and Near: Perceptual Evaluation of Crowd Representations Across Levels of Detail", "authors": "Xiaohan Sun,Carol O'Sullivan", "background": "本文探讨了不同细节层次（LoD）和视距下用户对人群特征表示的视觉质量感知。不同的表示方法，如几何网格、图像基假想物、神经辐射场（NeRF）和三维高斯分布，各自在视觉保真度和计算性能之间存在独特的权衡。", "innovation": "研究结果提供了关于如何设计感知优化的LoD策略的见解，这些策略适用于人群渲染。创新点在于使用了质性和量化结果来评估不同表示方法在不同视距下的视觉保真度。", "conclusion": "研究结果表明，不同的表示方法，在不同细节层次和视距下，其视觉质量和计算性能之间存在权衡。这些发现有助于指导优化人群渲染中的LoD策略。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20596", "html_url": "https://arxiv.org/abs/2510.20596", "title": "基于相似性原型的无监督领域适应方法在跨模态分割中的应用", "title_en": "Unsupervised Domain Adaptation via Similarity-based Prototypes for Cross-Modality Segmentation", "authors": "Ziyu Ye,Chen Ju,Chaofan Ma,Xiaoyun Zhang", "background": "深度学习模型在各种视觉挑战中取得了巨大成功，但它们在面对未见过的数据时表现会急剧下降。由于模型对领域变化敏感，无监督领域适应尝试减少领域差距，以避免未见过领域的成本高昂的标注。", "innovation": "提出了一种跨模态分割的新框架，通过学习类别的原型，并引入相似性约束使这些原型具有代表性且可区分。此外，使用字典存储从不同图像中提取的原型，这防止了类别缺失问题并促进了原型的对比学习，从而进一步提高性能。", "conclusion": "大量实验表明，我们的方法在跨模态分割上比其他最先进的方法取得了更好的结果。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20579", "html_url": "https://arxiv.org/abs/2510.20579", "title": "Open-o3 Video：带有显式时空证据的视频推理", "title_en": "Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence", "authors": "Jiahao Meng,Xiangtai Li,Haochen Wang,Yue Tan,Tao Zhang,Lingdong Kong,Yunhai Tong,Anran Wang,Zhiyang Teng,Yujing Wang,Zhuochen Wang", "background": "现有的大多数视频推理模型只生成文本推理痕迹，而没有指明关键证据出现的时间和位置。尽管OpenAI-o3等模型已经引起了对图像中证据导向推理的兴趣，但将其扩展到视频是非常具有挑战性的，因为这需要在动态场景中联合时间跟踪和空间定位。值得注意的是，在现有的大多数数据集中，只能提供视频的时间跨度或图像的空间框，缺乏统一的时空监督和推理痕迹。因此，目前的模型无法有效地指出关键证据出现的具体时间、位置和范围，这限制了视频推理的质量和可靠性。", "innovation": "本文介绍了一种非代理框架——Open-o3 Video，该框架将显式时空证据整合到视频推理中。通过精心收集训练数据和设计训练策略，成功解决了上述挑战。该模型不仅强调了时间戳、物体和边界框，还可以使推理基于具体的视觉观察。为了实现这一功能，作者创建了两个高质量的数据集，分别是STGR-CoT-30k用于基于自适应策略的训练，STGR-RL-36k用于基于强化学习的训练。通过采用一种特殊的冷启动强化学习策略，并设计带有多个特别奖励的功能，促进了答案的准确性、时间对齐和空间精确度。实验结果表明，Open-o3 Video在V-STAR基准上的表现达到了最先进的水平，同时也对其它多个视频理解基准的性能有所提升。", "conclusion": "Open-o3 Video 所产生的推理痕迹不仅提高了模型自身的准确性，还在测试时刻的缩放过程中提供了宝贵的信心信号，进一步增强了回答的可靠性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20578", "html_url": "https://arxiv.org/abs/2510.20578", "title": "EmbodiedBrain：扩展实体智能任务规划性能边界", "title_en": "EmbodiedBrain: Expanding Performance Boundaries of Task Planning for Embodied Intelligence", "authors": "Ding Zou,Feifan Wang,Mengyu Ge,Siyuan Fan,Zongbing Zhang,Wei Chen,Lingfeng Wang,Zhongyou Hu,Wenrui Yan,Zhengwei Gao,Hao Wang,Weizhao Jin,Yu Zhang,Hainan Zhao,Mingliang Zhang,Xianxian Xi,Yaru Zhang,Wenyuan Li,Zhengguang Gao,Yurui Zhu", "background": "实现通用人工智能（AGI）需要具备 robust 空间感知、有效任务规划和适应性强的执行能力的实体 AI 代理。然而，现有的大型语言模型（LLMs）和多模态 LLMs（MLLMs）在实体任务中的表现存在一些关键限制，如模型设计与代理需求之间的差距、实时延迟与性能之间的权衡，以及使用不真实的离线评估标准。", "innovation": "我们提出了 EmbodiedBrain，一种新型的包含 7B 和 32B 参数的视图-语言基础模型。该框架的一个特点是遵循代理对齐的数据结构，并采用一种强大的训练方法，将大规模的监督微调（SFT）与步进增强组相关策略优化（Step-GRPO）结合，通过将前一步骤作为引导前置条件，来增强长期任务的成功率。此外，我们引入了一个全面的奖励系统，包括一个在基础设施层面加速的生成奖励模型（GRM），以提高训练效率。通过建立一个包含通用、规划和端到端仿真基准的多步评估系统，以及提出并开源了一个新的具有挑战性的仿真环境，我们进行了充分的验证。", "conclusion": "实验结果表明，EmbodiedBrain 在所有评估标准上表现优异，为实体基础模型建立了新的性能基准。为推动下一代通用实体代理的发展，我们开源了所有数据、模型权重和评估方法，可以从以下链接访问：this https URL。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20586", "html_url": "https://arxiv.org/abs/2510.20586", "title": "GenColorBench：文本到图像生成模型的色彩评估基准", "title_en": "GenColorBench: A Color Evaluation Benchmark for Text-to-Image Generation Models", "authors": "Muhammad Atif Butt,Alexandra Gomez-Villa,Tao Wu,Javier Vazquez-Corral,Joost Van De Weijer,Kai Wang", "background": "近年来，文本到图像生成领域取得了显著进步，生成模型能够从文本生成高质量图像。然而，这些模型在颜色细致控制方面仍然存在挑战，经常无法准确匹配文本提示中指定的颜色。现有的基准主要评估组合推理和指令遵循能力，但没有系统地评估颜色精确度。色差对人类视觉感知和交流至关重要，特别是在艺术、设计等需要品牌一致性的工作流程中。当前的基准要么忽略了颜色，要么依赖粗略的评估，忽视了如RGB值解释或满足人类预期这样的关键能力。这一现状催生了对一种新的基准的需求，以评估文本到图像生成模型在颜色生成方面的性能。", "innovation": "提出了GenColorBench，这是第一个面向文本到图像颜色生成的综合基准，基于ISCC-NBS和CSS3/X11等色彩系统，包括其他地方缺乏的数字颜色。该基准包含了44000多条聚焦于颜色的提示，覆盖400多种颜色，通过感知和自动评估揭示模型的真实能力。使用GenColorBench评估流行文本到图像生成模型，展示了性能差异，指出了模型在哪些颜色规范下表现最好，并识别了失效模式。", "conclusion": "GenColorBench 评估将指导精确颜色生成的改进。该基准将在被接受后公布。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20605", "html_url": "https://arxiv.org/abs/2510.20605", "title": "OnlineSplatter：无姿态在线自由移动物体3D重构", "title_en": "OnlineSplatter: Pose-Free Online 3D Reconstruction for Free-Moving Objects", "authors": "Mark He Huang,Lin Geng Foo,Christian Theobalt,Ying Sun,De Wen Soh", "background": "从单目视频中重建自由移动的物体仍然是一个具有挑战性的任务，特别是在没有可靠的姿态或深度线索以及在任意物体运动下。现有方法大多依赖于姿态、深度先验或束优化，但这些方法在处理自由移动的物体时面临困难。", "innovation": "我们提出了一种名为OnlineSplatter的新颖在线前馈框架，该框架可以从RGB帧直接生成高质量的物体中心3D高斯分布，无需使用相机姿态、深度先验或束优化。该方法以第一帧为锚点，并通过密集的高斯基元场逐步细化物体表示，保持恒定的计算成本，不受视频序列长度的影响。核心贡献在于结合了潜在外观-几何键与显式方向键的双键记忆模块，通过时空聚合的对象状态与当前帧特征的融合，有效处理自由移动物体，同时通过空间引导的记忆读出和高效的稀疏化机制，确保全面而紧凑的物体覆盖。", "conclusion": "在现实世界数据集上的评估结果表明，OnlineSplatter显著优于现有的无姿态3D重构基线方法，在更多观测下持续改进，同时保持恒定的内存和运行时间。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20634", "html_url": "https://arxiv.org/abs/2510.20634", "title": "深度学习在牙科图像分析中的应用：数据集、方法和新兴挑战的系统综述", "title_en": "Deep Learning in Dental Image Analysis: A Systematic Review of Datasets, Methodologies, and Emerging Challenges", "authors": "Zhenhuan Zhou,Jingbo Zhu,Yuchen Zhang,Xiaohang Guan,Peng Wang,Tao Li", "background": "牙科图像的高效分析和处理对于牙医实现准确诊断和最优治疗计划至关重要。然而，牙科成像固有地带来了低对比度、金属伪影和投射角度变化等挑战，并且由于临床医生专业知识的差异，导致主观性增加，手动解释往往耗时且易于产生不一致性。", "innovation": "本文系统回顾了260篇关于深度学习在牙科图像分析（DIA）应用的研究，包括49篇关于公开牙科数据集的论文和211篇关于基于深度学习算法的论文。详细介绍了数据集的基本概念、现有数据集的特性和获取方法，以及不同DIA任务相关的模型和算法的网络架构、优化策略、训练方法和性能。此外，总结了DIA领域常用的训练和评估指标。", "conclusion": "本文讨论了现有研究中的现有挑战，并概述了潜在的未来方向。希望本工作为该领域的研究人员提供有价值的和系统的参考，并将所有补充材料和详细比较表公开发布在GitHub上。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20622", "html_url": "https://arxiv.org/abs/2510.20622", "title": "SeViCES：统一语义-视觉证据共识的长视频理解", "title_en": "SeViCES: Unifying Semantic-Visual Evidence Consensus for Long Video Understanding", "authors": "Yuan Sheng,Yanbin Hao,Chenxu Li,Shuo Wang,Xiangnan He", "background": "长视频理解仍然具有挑战性，因为长视频内容复杂多样且时间分布分散。虽然视频大型语言模型（Video-LLMs）能够处理长达数分钟的视频，但应用于超长序列时，由于计算成本高昂，会导致推理不聚焦或不一致，现有方法虽然可以通过选择最具有信息量的帧来解决问题，但往往忽视了时间依赖关系或依赖单一模态的证据，降低了提供完整且查询相关背景信息的能力。", "innovation": "提出了一种无需训练且模型无关的语义-视觉共识证据选择框架（SeViCES）。它包括两个关键组件：（1）语义-视觉共识帧选择模块（SVCFS），通过蕴含LLM在字幕上的推理和集群引导的视觉分支来选择帧；（2）答案共识细化模块（ACR）通过融合证据和限制答案空间来解决基于语义和视觉预测的一致性问题。实验结果表明SeViCES在准确性和鲁棒性上均优于现有方法，突显了共识驱动证据选择对于Video-LLMs的重要性。", "conclusion": "SeViCES 在长视频理解基准测试中表现出色，表明共识驱动的证据选择对于提高Video-LLMs的性能至关重要。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20661", "html_url": "https://arxiv.org/abs/2510.20661", "title": "UltraHR-100K: 提高超高清图像合成的大规模高质量数据集", "title_en": "UltraHR-100K: Enhancing UHR Image Synthesis with A Large-Scale High-Quality Dataset", "authors": "Chen Zhao,En Ci,Yunzhe Xu,Tiehan Fan,Shanyan Guan,Yanhao Ge,Jian Yang,Ying Tai", "background": "超高清分辨率（UHR）文字生成图像（T2I）生成已经取得了显著进展，但仍然存在两大关键挑战：缺乏大规模高质量的UHR T2I数据集和忽视了在UHR场景下对细粒度细节合成的定制化训练策略。要应对这些挑战，提出了一种新的解决方法和数据集来提升超高清图像的生成质量。", "innovation": "引入了UltraHR-100K数据集，包含100,000张高质量的超高清图像，并提出了频率感知的后训练方法。具体来说，该方法包含两个创新点：(i) 细节导向的 timestep 抽样（DOTS），专注于学习重要的细节降噪步骤；(ii) 软权重频率正则化（SWFR），利用离散傅里叶变换技术软性限制频率成分，从而鼓励高频细节的保留。这些创新方法显著提升了超高清图像生成中细粒度细节质量和整体保真度。", "conclusion": "在我们提出的UltraHR-eval4K基准上进行的大量实验表明，我们的方法显著提高了超高清图像生成中细粒度细节质量和整体保真度。相关代码已公开在指定链接中。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20639", "html_url": "https://arxiv.org/abs/2510.20639", "title": "Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging", "title_en": "Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging", "authors": "Ibrahim Ethem Hamamci,Sezgin Er,Suprosanna Shit,Hadrien Reynaud,Dong Yang,Pengfei Guo,Marc Edgar,Daguang Xu,Bernhard Kainz,Bjoern Menze", "background": "最近，3D医学影像的视觉语言建模取得了显著进展，主要得益于大规模的计算机断层扫描（CT）数据集、配对的自由文本报告，更强的架构以及更强大的预训练模型。这些进步使得自动报告生成和文本条件的3D图像合成等应用成为可能。然而，当前的方法在处理高分辨率、长序列体积时遇到了困难，对比预训练往往导致视觉编码器与临床语言不匹配，且切片级标记化模糊了精细解剖结构，从而降低了下游任务的诊断性能。", "innovation": "本文介绍了一种名为BTB3D（Better Tokens for Better 3D）的因果卷积编码器-解码器，它统一了2D和3D的训练和推理过程，生成了紧凑、频率感知的空间体素标记。通过三阶段的训练课程，它允许（i）局部重建，（ii）重叠窗口切片，（iii）长上下文解码器校准，从而在学习片段摘录的同时能推广到超过300片的扫描而无需额外的内存开销。BTB3D在两个关键任务上达到了新的状态最先进：在报告生成任务上提高了BLEU分数，并将临床F1提高了40%；在文本到CT合成任务上将FID降低了75%，并将FVD减半，生产了512*512*241的解剖学一致体积。这些结果证实了精确的三维标记化是3D医学影像中可扩展的视觉语言建模的关键，而不仅仅是更大的语言后端。", "conclusion": "本文通过引入BTB3D方法，在视觉语言建模领域特别是3D医学成像方面取得了重大突破，强调了精确三维标记化的重要性，并显著提高了报告生成和文本到CT合成的任务性能。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20673", "html_url": "https://arxiv.org/abs/2510.20673", "title": "通过权值偏置校正和位级核心集采样高效训练多比特量化网络", "title_en": "Efficient Multi-bit Quantization Network Training via Weight Bias Correction and Bit-wise Coreset Sampling", "authors": "Jinhee Kim,Jae Jun An,Kang Eun Jeon,Jong Hwan Ko", "background": "多比特量化网络能够通过支持单一模型中的多种精度级别，使得深度神经网络的部署更加灵活。然而，现有的方法在训练过程中需要对全数据集进行多次更新以支持不同的精度，这就导致了随着精度级别的增多，训练成本会线性增加。此外，为了支持额外的或中间层级精度选项，往往还需要额外的微调阶段，这进一步增加了整体训练负担。", "innovation": "为了应对上述问题，本文提出了两种技术来大幅降低训练开销而不影响模型的功能：(i) 权重偏置校正能够让窗(batch)规范化层共享，并通过消除量化带来的偏置，跨精度级对激活分布进行对齐。(ii) 位级核心集采样策略允许每个模型在由基于梯度的重要性评分机制选出的紧凑、具有代表性的数据子集上进行训练，这利用了潜在的知识转移现象。", "conclusion": "实验结果表明，与ResNet和ViT结构的图像分类数据集CIFAR-10/100、TinyImageNet和ImageNet-1K上，本文的方法不仅能达到竞争性或更优的精度，还能够在训练时间上最多减少7.88倍。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20696", "html_url": "https://arxiv.org/abs/2510.20696", "title": "诊断视觉推理：挑战、见解及前进路径", "title_en": "Diagnosing Visual Reasoning: Challenges, Insights, and a Path Forward", "authors": "Jing Bi,Guangyu Sun,Ali Vosoughi,Chen Chen,Chenliang Xu", "background": "研究指出，多模态大语言模型（MLLMs）集成了视觉和文本推理功能，并通过链式思考（CoT）提示来处理复杂的视觉任务。然而，这些模型仍然存在视觉幻觉和过度依赖文本先验的问题。", "innovation": "该研究提出了一个包含三个阶段的评估框架，系统地诊断了最先进的视觉-语言模型的关键失败模式。研究者还提出了一种基于代理的架构，将LLM推理与轻量级视觉模块结合，以实现推理链的精细分析和迭代优化。该系统在MMMU和MathVista上的表现均优于7B参数的基线模型。", "conclusion": "研究结果强调，未来视觉推理模型应该整合更广泛的专用工具来分析视觉内容。该研究成果显著提升了模型性能，并开放了评估框架和评价套件，以推动未来的研究。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20707", "html_url": "https://arxiv.org/abs/2510.20707", "title": "在大型视觉-语言模型中混合重要性和多样性：联合优化KV缓存压缩", "title_en": "Mixing Importance with Diversity: Joint Optimization for KV Cache Compression in Large Vision-Language Models", "authors": "Xuyang Liu,Xiyan Gui,Yuchao Zhang,Linfeng Zhang", "background": "最近的大规模视觉-语言模型（LVLMs）在处理延伸的多模态序列方面表现出显著的能力，但随之而来的关键值（KV）缓存扩展引发了内存瓶颈，这一瓶颈从根本上限制了部署的可扩展性。现有方法主要集中在保留高重要性的KV对以减少存储需求，但它们往往忽视了多模态KV缓存中出现的显著的模态特异性语义冗余模式。本文首先分析了KV缓存在LVLMs中的冗余情况，表明仅依赖重要性无法涵盖完整的KV缓存信息分布，可能导致语义覆盖不足。", "innovation": "提出了名为'MixKV'的新方法，该方法通过结合重要性和多样性来优化KV缓存压缩，在LVLMs中适应头向语义冗余，选择性地平衡多样性和重要性以压缩KV对。实验证明，与现有方法相比，MixKV在多个LVLM上表现更优，特别是在极端压缩（预算=64）情况下，MixKV在五个多模态理解基准上的提升平均为5.1%，并在SnapKV和AdaKV的GUI定位任务上分别实现了8.0%和9.0%的显著提升，同时保持了可比较的推理效率。", "conclusion": "MixKV将无缝扩展到大规模语言模型，并表现出相似的性能提升。研究者还公布的代码可以在指定的链接处找到。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20766", "html_url": "https://arxiv.org/abs/2510.20766", "title": "DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion", "title_en": "DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion", "authors": "Noam Issachar,Guy Yariv,Sagie Benaim,Yossi Adi,Dani Lischinski,Raanan Fattal", "background": "扩散变换器模型能够生成具有良好保真度和细节的图像，但它们在超高清分辨率下进行训练的成本非常高，因为自注意力机制随图像标记数量的平方级增长。已有方法需要额外的训练成本和采样成本来生成远超训练分辨率的图像。", "innovation": "动态位置外推（DyPE）是一种无需额外训练的方法，可以让预训练的扩散变换器在没有额外采样成本的情况下合成远超训练数据分辨率的图像。DyPE 利用了扩散过程固有的频谱进展，低频结构尽早收敛，高频则需要更多步骤才能解析，通过在每个扩散步骤中动态调整模型的位置编码，使它们的频谱与生成过程的当前阶段相匹配。", "conclusion": "在多个基准上，DyPE 一致提升了性能，实现了超高清分辨率图像生成的最新清晰度，尤其是在更高分辨率下的增益更为显著，能够在 FLUX 训练下生成超过 1600 万像素的图像。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20708", "html_url": "https://arxiv.org/abs/2510.20708", "title": "ALICE-LRI: 一种无需校准元数据的旋转LIDAR传感器无损范围图生成的一般方法", "title_en": "ALICE-LRI: A General Method for Lossless Range Image Generation for Spinning LiDAR Sensors without Calibration Metadata", "authors": "Samuel Soutullo,Miguel Yermo,David L. Vilariño,Óscar G. Lorenzo,José C. Cabaleiro,Francisco F. Rivera", "background": "3D LiDAR传感器在自主导航、环境监测和精确测绘等遥感应用中至关重要。传统方法将LiDAR数据投影成2D范围图以提高处理效率，然而这种投影方法存在根本的几何不一致性，导致不可逆的信息损失，影响高保真应用。因此，开发一种无需制造商元数据、能够在完全无损情况下生成2D范围图的方法具有重要意义。", "innovation": "首次提出ALICE-LRI（自动LIDAR固有校准估计用于无损范围图），这是一种通用的、传感器无关的方法，能够在无需制造商元数据或校准文件的情况下，从旋转LiDAR点云中生成无损范围图。该算法能够自动反向工程任何旋转LiDAR传感器的固有几何结构，推断出诸如激光束配置、角度分布和每个束的校准修正等关键参数，从而实现无损投影和完整的点云重建，且不丢失任何点。", "conclusion": "全面评估跨越完整的Kitti和DurLAR数据集显示，ALICE-LRI实现了完美的点保存，所有点云中无点丢失。几何精度保持在传感器精度限制以内，实现了几何无损并具备实时性能。这一从近似到无损LIDAR投影的范式转变，为需要完全几何保真的高精度遥感应用开辟了新的可能性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20726", "html_url": "https://arxiv.org/abs/2510.20726", "title": "AutoScape：几何一致的长时场景生成", "title_en": "AutoScape: Geometry-Consistent Long-Horizon Scene Generation", "authors": "Jiacheng Chen,Ziyu Jiang,Mingfu Liang,Bingbing Zhuang,Jong-Chyi Su,Sparsh Garg,Ying Wu,Manmohan Chandraker", "background": "本文介绍了一个名为AutoScape的长时驾驶场景生成框架。该框架的核心是一个新颖的RGB-D扩散模型，该模型通过生成稀疏的、几何上一致的关键帧来迭代地进行场景生成，这些关键帧作为场景外观和几何结构的可靠锚点。为了维护长时间范围内的几何一致性，该模型1) 在共享的潜在空间中同时处理图像和深度，2) 明确地基于先前生成的关键帧中的现有场景几何（即渲染的点云）进行条件处理，3) 通过一个变形一致的引导来引导采样过程。在获得高质量的RGB-D关键帧后，一个基于扩散的视频生成模型通过在它们之间进行插值来生成密集且连贯的视频帧。AutoScape能够生成超过20秒的逼真且几何上一致的驾驶视频，大大提高了长时FID和FVD分数。", "innovation": "1. 提出了一种新颖的RGB-D扩散模型，能够生成几何一致的关键帧，作为场景的锚点。\n2. 模型在共享的潜在空间中同时处理图像和深度，以维护长时间范围内的几何一致性。\n3. 通过变形一致的引导来指导采样过程。\n4. 通过插值生成密集且连贯的视频帧。\n5. 生成的视频在长时FID和FVD分数上分别提高了48.6%和43.0%，超过了之前的最先进水平。", "conclusion": "本文提出的AutoScape框架能够生成逼真且几何上一致的长时驾驶视频，明显优于现有的最先进水平。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20754", "html_url": "https://arxiv.org/abs/2510.20754", "title": "ACS-SegNet: 一种基于注意力机制的CNN-SegFormer组织分割网络", "title_en": "ACS-SegNet: An Attention-Based CNN-SegFormer Segmentation Network for Tissue Segmentation in Histopathology", "authors": "Nima Torbati,Anastasia Meshcheryakova,Ramona Woitek,Diana Mechtcheriakova,Amirreza Mahbod", "background": "自动化的组织病理学图像分析在计算机辅助诊断各种疾病中起着重要作用。发展中的算法中，基于深度学习的方法在多个任务中表现出了卓越的性能，包括组织学图像中的语义组织分割。本研究旨在提高语义分割性能，提出了一个新的基于注意力机制的卷积神经网络（CNNs）和视觉变换器（ViTs）的特征融合双编码模型方法。在两个公开数据集GCPS和PUMA上的评估表明，该模型在GCPS数据集上达到了μIoU/μDice分数的76.79%/86.87%，在PUMA数据集上达到了64.93%/76.60%，在性能上超过了最先进的方法和基线基准。\n", "innovation": "该研究提出了一个新的基于注意力机制的卷积神经网络和视觉变换器的特征融合的双编码器模型方法，旨在提高语义分割性能。该方法在多个公开数据集上的评估表现超过了最先进的方法和基线基准。\n", "conclusion": "该模型在两个公开数据集上的表现优异，验证了其在组织病理学图像语义分割上的有效性。该方法已公开实现并存储在GitHub仓库中，可供进一步研究和应用。\n"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20803", "html_url": "https://arxiv.org/abs/2510.20803", "title": "ARGenSeg：基于自回归图像生成模型的图像分割", "title_en": "ARGenSeg: Image Segmentation with Autoregressive Image Generation Model", "authors": "Xiaolong Wang,Lixiang Ru,Ziyuan Huang,Kaixiang Ji,Dandan Zheng,Jingdong Chen,Jun Zhou", "background": "先前的工作将图像分割融入到多模态大型语言模型（MLLMs）中，通常使用边界点表示或专用的分割头部。这些方法依赖于离散的表示或语义提示，输入到特定任务的解码器中，这限制了MLLM捕获细微视觉细节的能力。", "innovation": "提出了一种基于自回归生成的图像分割新范式（ARGenSeg），在统一框架中实现多模态理解和像素级感知。通过引入基于图像生成的分割框架，结合多模态大型语言模型（MLLM），以自然生成目标对象的密集掩码，以及利用MLLM输出视觉令牌并使用通用VQ-VAE反序列化为图像，使得分割完全依赖于MLLM的像素级理解。此外，采用下一尺度预测策略并行生成所需的视觉令牌，减少推理延迟。", "conclusion": "广泛的实验结果表明，该方法在多个分割数据集上超越了先前的最佳方法，在推理速度显著提升的同时，保持了强大的理解能力。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20794", "html_url": "https://arxiv.org/abs/2510.20794", "title": "雷达与摄像头融合的多目标跟踪：在线校准与共同特征", "title_en": "Radar-Camera Fused Multi-Object Tracking: Online Calibration and Common Feature", "authors": "Lei Cheng,Siyang Cao", "background": "许多研究在利用雷达数据方面存在不足，将其仅作为辅助手段使用，而忽略了它在提供三维目标的精确距离/深度信息方面的优势。本研究提出了一种融合雷达与摄像头数据的多目标跟踪（MOT）框架，旨在通过在线校准实现更好的目标检测结果整合，从而提高多目标跟踪的效率并减少人工干预。", "innovation": "本研究的主要创新点包括：（1）开发了一种利用在线雷达-摄像头校准的融合框架，简化了这两个传感器检测结果的整合过程；（2）利用雷达和摄像头数据中的共同特征来准确推导出检测对象在现实世界的位置；（3）采用特征匹配和类别一致性检查，超越了简单的位置匹配限制，提高了传感器关联的准确性。论文是首次研究雷达与摄像头共同特征在在线校准中的应用，以实现多目标跟踪。", "conclusion": "通过本框架，雷达与摄像头的映射过程得以简化，多目标跟踪精度得到提高，实验结果在受控环境和实际交通场景的实验证明了这一点。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20771", "html_url": "https://arxiv.org/abs/2510.20771", "title": "AlphaFlow：理解并改进MeanFlow模型", "title_en": "AlphaFlow: Understanding and Improving MeanFlow Models", "authors": "Huijie Zhang,Aliaksandr Siarohin,Willi Menapace,Michael Vasilkovsky,Sergey Tulyakov,Qing Qu,Ivan Skorokhodov", "background": "MeanFlow 最近成为了一种强大的少量步骤生成建模框架，能够从头开始训练，但其成功原理尚不完全清楚。", "innovation": "作者分析了MeanFlow目标可以自然分解为轨迹流匹配和轨迹一致性两部分，并发现这两部分通过梯度分析发现是强烈负相关，导致优化冲突和收敛缓慢。因此提出了一个新的目标族$\boldsymbol{\text{α}}$-Flow，它统一了轨迹流匹配、捷径模型和MeanFlow，并通过采用从轨迹流匹配平滑过渡到MeanFlow的课程策略，解决了冲突目标，实现了更好的收敛。实验结果显示，$\boldsymbol{\text{α}}$-Flow在从零开始训练时，相较于MeanFlow在ImageNet-1K 256x256数据集上取得更好的结果，且使用标准的DiT架构时$\boldsymbol{\text{α}}$-Flow-XL/2+模型取得了最新的最佳结果，FID得分为2.58（1-NFE）和2.15（2-NFE）", "conclusion": "$\boldsymbol{\text{α}}$-Flow通过在其体系中融入更广泛的优化策略，成功地从MeanFlow模型中分离出了具有冲突的目标，并在此过程中实现了更好的收敛性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20776", "html_url": "https://arxiv.org/abs/2510.20776", "title": "CUPID: 基于姿态生成的单图像3D重建", "title_en": "CUPID: Pose-Grounded Generative 3D Reconstruction from a Single Image", "authors": "Binbin Huang,Haobin Duan,Yiqun Zhao,Zibo Zhao,Yi Ma,Shenghua Gao", "background": "当前的单图像3D重建方法在准确恢复相机姿态、3D形状和纹理方面存在局限性。许多现有的方法依赖于复杂的优化过程，可能无法提供最佳的重建质量和鲁棒性。", "innovation": "本文提出了一种名为Cupid的新一代基于生成的3D重建方法，该方法可以从单个2D图像准确推断出物体的相机姿态、3D形状和纹理。Cupid将3D重建视为从已学习的3D对象分布中进行条件采样的过程，同时生成体素和像素-体素对应关系，从而在统一的生成框架下实现稳健的姿态和形状估计。Cupid采用了一种两阶段流匹配管道，第一阶段生成初始3D几何形状及其相关的2D投影以恢复姿态，第二阶段将姿态对齐的图像特征结合起来增强结构保真度和外观细节。", "conclusion": "广泛的实验表明，Cupid在保真度和外观细节方面明显优于现有的3D重建方法，PSNR提高超过3 dB，球柄距离减小超过10%，并且在姿态精度上与单目估计器相匹敌，同时提供了比基线3D生成模型更出色的整体视觉保真度。访问网站以查看Cupid生成的3D结果。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20807", "html_url": "https://arxiv.org/abs/2510.20807", "title": "使用像素空间时空变压器进行动态物理仿真视频预测", "title_en": "Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers", "authors": "Dean L Slack,G Thomas Hudson,Thomas Winterbottom,Noura Al Moubayed", "background": "受自回归大型语言模型性能和扩展性的启发，基于变压器的模型在视觉领域取得了显著的成功。本文研究了用于视频预测的变压器适应性方法，采用了一种简单的端到端方法，并对比了不同的时空自注意力布局。研究聚焦于时间上物理模拟的因果建模，通过物理对象跟踪指标和基于物理模拟数据集的无监督训练，试图隔离时空推理。", "innovation": "本文引入了一种简单而有效的纯变压器模型，用于自回归视频预测，并且使用连续的像素空间表示进行视频预测。与现有的基于潜在空间的方法相比，该方法在保持类似视频质量指标的表现下，能够显著将物理精确预测的时间范围延长至50%。此外，通过可解释性实验，发现网络区域中编码的信息能够用于准确估计PDE仿真参数，并且这种估计适用于分布外的仿真参数。", "conclusion": "本文提供了一个平台，采用简单且参数高效、可解释的方法进行基于注意力的时空视频建模。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20820", "html_url": "https://arxiv.org/abs/2510.20820", "title": "LayerComposer：基于空间感知分层画布的交互式个性化文本到图像生成", "title_en": "LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas", "authors": "Guocheng Gordon Qian,Ruihang Zhang,Tsai-Shien Chen,Yusuf Dalva,Anujraaj Argo Goyal,Willi Menapace,Ivan Skorokhodov,Meng Dong,Arpit Sahni,Daniil Ostashev,Ju Hu,Sergey Tulyakov,Kuan-Chieh Jackson Wang", "background": "现有个性化生成模型尽管视觉效果优秀，但在空间组成方面的互动控制不足，并且不能很好地扩展到多种人物。为了克服这些局限性，该研究提出了LayerComposer，一种支持多种人物个性化且可互动的空间组成框架。", "innovation": "LayerComposer 主要有两项创新贡献：一是引入了分层画布的新表示方法，这种方法使得每个对象都位于独立的分层上，可以实现无遮挡的空间组合；二是提出了锁定机制，该机制能够精准保持选定分层的高保真度，并允许其他分层灵活适应周围环境。此外，LayerComposer 的锁定机制不需要改变架构，而是结合了新的数据采样策略和固有的位置嵌入。", "conclusion": "全面的实验表明，LayerComposer 在多对象个性化图像生成方面相较于现有最先进的方法，具有更优秀的空间控制和身份识别能力。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20812", "html_url": "https://arxiv.org/abs/2510.20812", "title": "小草案，大裁决：基于推测的信息密集型视觉推理", "title_en": "Small Drafts, Big Verdict: Information-Intensive Visual Reasoning via Speculation", "authors": "Yuhan Liu,Lianhui Qin,Shengjie Wang", "background": "大规模的视觉语言模型（VLMs）在多模态理解方面取得了显著进展，但在处理密集交织文字注释和细粒度图形元素的信息密集型图片时面临挑战。这些挑战主要在于准确定位密集布局中的关键线索和进行多跳推理以整合分散的证据。现有的方法难以高效、准确地处理这些问题。因此，本文提出了Speculative Verdict（推测裁决，SV）框架，旨在通过结合多个轻量级草稿专家和一个大型裁决模型来解决这些挑战。", "innovation": "SV框架通过借鉴推测解码的思想，采用非训练方式，结合多个小型VLM（草稿专家）生成多样化的推理路径，并通过一个强大的VLM（裁决模型）来综合这些路径，生成最终答案。此外，SV引入了一种共识专家选择机制，仅将高一致性的推理路径传递到裁决阶段，从而提高了效率与准确性。与大型专有模型或训练流程相比，SV能够进行错误修正并保持成本效率。实验证明，SV在InfographicVQA、ChartMuseum、ChartQAPro和HR-Bench 4K等多种信息密集型和高分辨率的视觉问答基准上取得了持续性的改进。", "conclusion": "通过综合多个不完全准确的推理路径中的正确见解，SV框架能够既进行错误修正，又保持成本效率。该文章提供了代码以便进一步研究。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20669", "html_url": "https://arxiv.org/abs/2510.20669", "title": "HybridSOMSpikeNet：具有可微软自组织映射和脉冲动力学的深度模型用于废品分类", "title_en": "HybridSOMSpikeNet: A Deep Model with Differentiable Soft Self-Organizing Maps and Spiking Dynamics for Waste Classification", "authors": "Debojyoti Ghosh,Adrijit Goswami", "background": "准确的废品分类对于实现可持续的废品管理、降低城市化进程中的环境足迹至关重要。可回收材料的误分类会导致填埋场积累、回收效率低下以及温室气体排放增加。为了解决这些问题，本研究引入了HybridSOMSpikeNet，这是一种结合卷积特征提取、可微自组织和脉冲启发式时间处理的深度学习混合框架，旨在实现智能且节能的废品分类。该模型在十类废品数据集上经过训练，实现了97.39%的测试准确率，性能优于多种现有先进技术架构，同时保持了轻量级的计算特性，适于实际部署。除了技术创新外，该框架还提供了实际的环境效益，通过精确和自动化的垃圾分类支持更高的回收效率，减少回收流中的污染，并降低废品处理过程中的生态和运营成本。", "innovation": "1. 引入了HybridSOMSpikeNet混合深度学习框架，集成了卷积特征提取、可微自组织和脉冲启发式时间处理技术。\n2. 使用预训练的ResNet-152作为骨干网络提取深度空间表示，并通过不同的Soft-SOM自组织映射增强拓扑聚类和可解释性。\n3. 脉冲神经头在离散时间步骤中累积时序激活，提高了模型的鲁棒性和泛化能力。\n4. 达到了97.39%的测试准确率，超过了多种现有架构，同时保持轻量级计算特征适于实际部署。", "conclusion": "HybridSOMSpikeNet通过精确且自动化的垃圾分类，提高了回收效率，减少了回收流中的污染，并降低了废品处理过程中的环保和运营成本。该方法与联合国可持续发展目标（SDG 11和SDG 12）相符，促进更清洁的城市、循环经济和智能环境管理系统。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20814", "html_url": "https://arxiv.org/abs/2510.20814", "title": "SpectraMorph: 自监督高光谱超分辨的结构化潜在学习", "title_en": "SpectraMorph: Structured Latent Learning for Self-Supervised Hyperspectral Super-Resolution", "authors": "Ritik Shah,Marco F Duarte", "background": "高光谱传感器能够捕捉每个像素密集的光谱信息，但与之相对的是其低空间分辨率，从而导致图像边界模糊和混合像素问题。采用高分辨率的配套传感器，如多光谱、RGB或全色相机，能够提供精细的空间细节，因此促成了高光谱图像与多光谱图像（HSI-MSI）融合的高光谱超分辨研究。虽然基于深度学习的方法在性能上表现出色，但它们依赖于不透明的回归模型，缺乏解释性，并且在多光谱图像具有很少波段时往往表现不佳。", "innovation": "SpectraMorph 提出了一个基于物理指导的自监督融合框架，采用结构化的潜在空间。与直接回归不同，SpectraMorph 强制执行一种分解瓶颈：从低分辨率HSI中提取纯成分标志，然后利用多层感知器从多光谱图像中预测类似于丰度的图。通过将光谱重建为线性混合，并借助随附的多光谱传感器的光谱响应函数在自监督模式下进行训练，进行训练。SpectraMorph能够生成可解释的中间结果，在一分钟内完成训练，并且即使使用单波段（包括全色）多光谱图像也能保持鲁棒性。", "conclusion": "在合成数据集和真实数据集上的实验表明，SpectraMorph 无论是与现有的无监督/半监督基线相比，还是与监督基线相比，都能实现持续的性能超越。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20819", "html_url": "https://arxiv.org/abs/2510.20819", "title": "对抗性和预测性潜在扩散桥梁的通用模态翻译", "title_en": "Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge", "authors": "Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot", "background": "近年来，生成模型的发展将扩散模型定位为从复杂数据分布中采样的最先进的工具。尽管这些模型在单模态领域，如图像和音频中表现出色，但将其能力扩展到模态翻译（MT）——即在不同感官模态之间进行信息转换，仍然是一项开放的挑战。现有的方法往往依赖于一些限制性的假设，包括共享维度、高斯先验分布和模态特定架构，这些限制性假设限制了其通用性和理论基础。", "innovation": "本文提出了一种基于潜在变量扩展的降噪扩散桥模型（LDDBM）作为通用模态翻译的一般框架。该方法通过工作在一个共享的潜在空间来学习任意模态之间的桥梁，而无需要求对齐的维度。引入对比对齐损失以确保配对样本之间的语义一致性，并设计了一个跨模态噪声预测的领域无关编码解码器架构。此外，还提出了一种预测损失来指导训练以实现准确的跨域翻译，并探索了几种训练策略以提高稳定性。该方法支持任意模态对，并在多种MT任务上表现出色，包括多视图至3D形状生成、图像超分辨率和多视图场景合成。大量实验和消融实验验证了我们框架的有效性，建立了通用模态翻译的新基准。", "conclusion": "我们的方法支持任意模态对，在各种模态翻译任务上表现出色，通过对比对齐损失和预测损失保证了准确的跨域翻译，并通过对比实验和消融验证了框架的有效性，为通用模态翻译设定了新的基准。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20822", "html_url": "https://arxiv.org/abs/2510.20822", "title": "HoloCine：整体生成电影多镜头长视频叙事", "title_en": "HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives", "authors": "Yihao Meng,Hao Ouyang,Yue Yu,Qiuyu Wang,Wen Wang,Ka Leong Cheng,Hanlin Wang,Yixuan Li,Cheng Chen,Yanhong Zeng,Yujun Shen,Huamin Qu", "background": "现有的文本到视频的先进模型在生成孤立的片段方面表现出色，但在创造连贯的、多镜头的叙事方面仍存在不足，而连贯的叙事是故事讲述的核心。因此，需要一种能够生成整场长视频的方法，以确保脚本从第一帧到最后一帧的一致性。", "innovation": "HoloCine模型通过全局一致性的整体生成机制填补了这一“叙事缺口”。其架构使用Window Cross-Attention机制来将文本提示定位到特定的镜头内，同时采用Sparse Inter-Shot Self-Attention模式（在镜头内部密集但在镜头间稀疏）确保生成微型尺度的效率。HoloCine在叙事连贯性方面达到新的标准，并且具有独特的电影叙事能力，如持久的角色记忆和对电影技术的直观理解。", "conclusion": "HoloCine的工作标志着从片段合成向自动化电影制作的转变，使得端到端的电影制作变得更加现实。相关代码可在提供的链接处获取。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19917", "html_url": "https://arxiv.org/abs/2510.19917", "title": "FINDER: 使用特征空间残差在嘈杂数据集上进行特征推断", "title_en": "FINDER: Feature Inference on Noisy Datasets using Eigenspace Residuals", "authors": "Trajan Murphy,Akshunna S. Dogra,Hanfeng Gu,Caleb Meredith,Mark Kon,Julio Enrique Castrillion-Candas", "background": "嘈杂的数据集（表现为低信噪比、小样本数量、数据收集故障等）是分类方法研究的重要前沿领域，具有理论和实践意义。传统的分类方法在处理此类数据时表现不佳，因为它们难以有效处理数据中的随机性和不确定性。因此，需要一种新的框架来应对这些挑战，以更好地处理包含噪声的数据集。", "innovation": "该论文提出了FINDER框架，这是一种用于分析通用分类问题的严谨框架，特别针对嘈杂数据集。FINDER通过将数据集视为随机场的实现并映射到合适的希尔伯特空间，从而构成随机特征。它使用Kosambi-Karhunen-Loéve展开（KLE）将这些随机特征分解为可计算的不可约组件，通过特征值分解来实现噪声数据集的分类。这种方法能够识别不同类别的数据在不同区域，有效地处理分类问题，并在多个科学领域取得了卓越的结果。", "conclusion": "FINDER旨在应对掺杂噪声的数据集，通过特征空间残差进行特征推断。FINDER已经在阿尔茨海默病阶段分类和遥感森林消失检测等多个数据不足的科学领域中取得了突破性进展，具体指标已达到或接近了现有方法的最高水平。我们讨论了FINDER的优势边界，以及何时它比现有方法更优。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19986", "html_url": "https://arxiv.org/abs/2510.19986", "title": "自动化的Iconclass分类：使用LLM和RAG进行大规模宗教版画分类", "title_en": "Automating Iconclass: LLMs and RAG for Large-Scale Classification of Religious Woodcuts", "authors": "Drew B. Thomas", "background": "本文提出了一个新颖的方法，利用大型语言模型（LLMs）和向量数据库结合检索增强生成（RAG）技术来分类早期现代宗教图像。这种方法利用了神圣罗马帝国内书籍插图的全页背景，使LLM能够生成结合视觉和文本元素的详细描述。这些描述通过混合向量搜索匹配到相关的Iconclass代码，从而实现87%和92%的五级和四级分类精确度，显著优于传统的图像和关键词搜索方法。通过这种方式，系统增强了分类准确性，为大规模分析早期现代视觉档案提供了强有力的工具。", "innovation": "本文提出的方法结合了LLMs、RAG技术和Iconclass代码，利用全页描述进行精确匹配，实现了高精度的图像分类，并且显著优于传统的基于图像和关键词匹配的系统。这种方法的关键创新在于利用LLMs生成详细的描述，结合RAG进行检索搜索，以提高多类别分类的准确性。", "conclusion": "本文展示了一种利用LLMs和RAG技术进行大规模早期现代宗教图像分类的新颖方法。这种方法通过全页描述和RAG相结合，大幅提高了分类的准确性。系统在艺术史和数字人文学科研究方面的实验证明了LLMs和RAG的强大潜力，显示出它们在这些学科中的重要应用前景。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20193", "html_url": "https://arxiv.org/abs/2510.20193", "title": "多媒体感知的问答：检索和跨模态推理架构的综述", "title_en": "Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures", "authors": "Rahul Raja,Arpita Vats", "background": "传统的问答（QA）系统依赖于结构化的文本数据，但多媒体内容（如图像、音频、视频以及结构化的元数据）的快速增长为基于检索增强的QA带来了新的挑战和机遇。文章回顾了将多媒体检索流水线整合到QA系统中的最新进展，重点在于通过与用户查询的对齐，打通视觉、语言和音频模态的架构。", "innovation": "文章分类了基于检索方法、融合技术以及答案生成策略的不同方法，分析了基准数据集、评估方案和性能权衡。此外，文章还指出了跨模态对齐、延迟-准确率权衡和语义关联等关键挑战，并指出了利用多媒体数据构建更加健壮和上下文相关的QA系统所面临的开放问题和未来研究方向。", "conclusion": "文章还阐述了构建更健壮和上下文感知的QA系统的挑战和未来的研究方向，强调了跨模态推理架构的整合，以解决上述挑战。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20012", "html_url": "https://arxiv.org/abs/2510.20012", "title": "基于AI的人阻抗训练中范围-of-运动变化的姿势分析和动态 profiling", "title_en": "AI Pose Analysis and Kinematic Profiling of Range-of-Motion Variations in Resistance Training", "authors": "Adam Diamant", "background": "本文基于Wolf等人(2025)的研究，该研究对比了不同上半身8个锻炼项目的长度拉伸部分范围(pROM)和全程范围(fROM)训练，使用视频数据进行分析。研究人员对26名参与者进行的280次记录进行处理，以提取帧级别的关节角度轨迹。研究后发现，pROM重复次数在运动范围和总体持续时间上较小，特别是在运动的离心阶段。差异性分析表明，参与者之间的差异而非特定的运动因素是主要的变差驱动因素，尽管有证据表明混合治疗方法存在差异性效果。研究结果表明，pROM与fROM训练在执行动力和一致性方面存在不同，强调了AI方法对于研究和增强阻力训练建议的潜在应用价值。", "innovation": "本文提出了一个AI基础的姿态估计管道，实现了对阻力训练中的运动动力学进行精确量化。提出了一个新的衡量标准，%ROM，表示pROM占全长运动的百分比。通过随机效应元分析模型，考虑了参与者内部和运动间的变化，研究发现pROM较差不仅体现在运动范围上，还体现在执行动态和一致性上，进一步突出了AI方法在研究和增强阻力训练建议方面的潜在作用。", "conclusion": "研究表明，部分拉伸范围(pROM)与全程拉伸范围(fROM)的阻力训练在运动范围、执行动力学和一致性方面存在显著差异，为基于AI的方法在该领域的研究提供了新的见解和潜在的改进方向。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20108", "html_url": "https://arxiv.org/abs/2510.20108", "title": "原型为什么会坍塌：诊断和预防原型自监督学习中的部分坍塌现象", "title_en": "Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning", "authors": "Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera", "background": "自监督学习方法中的原型性表示一直受到部分原型坍塌问题的困扰，在这种现象中，多个原型会收敛到几乎相同的表示。这种方式削弱了它们提供多样化且信息丰富的目标以引导编码器生成丰富表示的中心目的。因此，从业者要么增加参数量，要么添加自定义正则化项来减轻症状，但并不能从根本上解决这个问题。研究表明，这种坍塌现象是由编码器和原型的联合优化造成的，它导致了一种捷径学习：在训练早期，原型向冗余的表示靠近，这些表示可以减少损失而不一定增加表示的多样性。为了解决这一问题，本文提出了一种完全解耦的训练策略，即在分离的目标下分别学习原型和编码器。通过这种方法，原型被建模为一个更新的操作方式类似于在线EM的高斯混合模型，这与编码器的损失无关。这种简单而有原则的解耦消除了原型坍塌现象，同时生成了多样化且性能更强的原型。", "innovation": "本文提出了一个解耦的训练策略来解决原型自监督学习中的部分坍塌问题。通过将原型表示与编码器一起训练的过程分离，引入了高斯混合模型，并以在线EM方式更新，这种方法简化了问题，并避免了需要增加参数或添加自定义正则化项的复杂方法。这种方法有效解决了原型坍塌，并提高了下游任务的性能。", "conclusion": "本文通过解耦的方式，解决了原型自监督学习中常见的部分坍塌现象，简单而有效。这种方法不仅避免了之前的解决方案的复杂性，还提高了下游任务的效果。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20335", "html_url": "https://arxiv.org/abs/2510.20335", "title": "Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking", "title_en": "Dino-Diffusion Modular Designs Bridge the Cross-Domain Gap in Autonomous Parking", "authors": "Zixuan Wu,Hengyuan Zhang,Ting-Hsuan Chen,Yuliang Guo,David Paz,Xinyu Huang,Liu Ren", "background": "停车场是确保驾驶安全的重要组成部分。尽管最近的端到端（E2E）方法在特定领域取得了令人鼓舞的结果，但在不同领域（如天气和照明变化）下的抗干扰能力依然是一个关键挑战。现有的方法大多依赖额外的数据来提高性能，而缺乏对跨领域泛化的关注和有效的解决方案。", "innovation": "本文提出了Dino-Diffusion Parking (DDP)框架，这是一种无需额外数据的跨领域自主泊车管道，将视觉基础模型与基于扩散的规划相结合，以实现泛化感知和跨分布场景下的鲁棒运动规划。该模型可以在CARLA中以常规设置训练，在更具攻击性的环境中零样本迁移。实验证明，与现有基线相比，该模型的网络架构和算法设计在跨领域性能上显著提升，并且在3D高斯散点图环境中的实际停车场重建中表现出良好的仿真到现实的迁移效果。", "conclusion": "本文所提出的DDP框架在所有测试的离域场景中始终实现了90%以上的泊车成功率，并通过消融研究证实了网络架构和算法设计对性能的显著提升。此外，DDP框架展示了强大的模拟到现实的迁移能力。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20266", "html_url": "https://arxiv.org/abs/2510.20266", "title": "GUSL-Dehaze: 一种绿色U形学习方法用于图像去雾", "title_en": "GUSL-Dehaze: A Green U-Shaped Learning Approach to Image Dehazing", "authors": "Mahtab Movaheddrad,Laurence Palmer,C.-C. Jay Kuo", "background": "图像去雾是一项旨在从单个雾霾输入中恢复清晰图像的恢复任务。传统的方法依赖于统计先验和大气散射模型来重建无雾霾的图像。尽管最新的先进技术大多基于深度学习架构，但这些模型通常涉及高计算成本和大规模的参数量，使得它们不适合资源受限的设备。", "innovation": "我们提出了GUSL-Dehaze，一种绿色U形学习方法，结合了基于物理的模型和绿色学习（GL）框架，提供了一种轻量级且透明的替代传统深度学习技术的方法。GUSL-Dehaze使用修改后的暗通道先验（DCP）进行初步去雾处理，随后通过U形架构实现的绿色学习管线进行特征提取，采用无监督表示学习，同时使用相关特征测试（RFT）和最小二乘正态变换（LNT）等特征工程技术保持紧凑的模型大小。最终，通过透明的监督学习策略获得去雾霾图像。这种方法显著减少了参数数量，同时保持了数学可解释性和性能接近最先进的深度学习模型。", "conclusion": "GUSL-Dehaze 在减少参数数量的同时，确保了数学上的可解释性，并实现了与最先进的深度学习模型相匹敌的性能。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20349", "html_url": "https://arxiv.org/abs/2510.20349", "title": "合成数据用于稳健的跑道检测", "title_en": "Synthetic Data for Robust Runway Detection", "authors": "Estelle Chigot,Dennis G. Wilson,Meriem Ghrib,Fabrice Jimenez,Thomas Oberlin", "background": "深度视觉模型已经足够成熟，可以在自动驾驶导航等工业和关键应用中集成。然而，收集和标记数据来进行模型训练需要大量的时间和成本，这使得单个公司或产品难以负担。这种缺点在关键应用中尤为明显，因为训练数据必须包括所有可能的情况，包括罕见场景。从这种角度来看，生成合成图像是一种诱人的解决方案，它可以以低廉的成本可靠地覆盖所有条件和环境，前提是缓解合成数据与现实数据之间的分布差异对模型的影响。本文研究了跑道检测问题，这是飞机制造商开发的自主着陆系统的关键部分。", "innovation": "提出了一种基于商用飞行模拟器的图像生成方法，以补充少量标注的真实图像。通过控制图像生成并结合真实和合成数据，展示了标准物体检测模型可以实现准确预测，并且评估了它们在不利条件（在本例中为夜间图像）下的鲁棒性，这些条件在真实数据中没有代表，显示了定制领域适应策略的兴趣。", "conclusion": "标准物体检测模型在补充少量真实标注数据的基础上，通过使用控制生成的图像并结合真实和合成数据的方法，能够达到准确的预测。这种方法还展示了在未见条件（如夜间图像）下，模型的鲁棒性，并强调了使用定制领域适应策略的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20261", "html_url": "https://arxiv.org/abs/2510.20261", "title": "Kinaema：一种用于运动中的记忆和姿态的递归序列模型", "title_en": "Kinaema: a recurrent sequence model for memory and pose in motion", "authors": "Mert Bulent Sariyildiz,Philippe Weinzaepfel,Guillaume Bono,Gianluca Monaci,Christian Wolf", "background": "空间感知机器人的一个关键方面是“找到方向”的能力，即正确地将其定位在之前看到的空间中。本文关注的是连续机器人操作场景，利用在实际操作开始前观察到的信息来优化效率。", "innovation": "提出了一种新的模型Kinaema和代理，能够整合移动过程中的视觉观察流，并在接收到查询图像时，预测所展示空间相对于当前位置的相对位置。这种模型不显式地存储观察历史，因此不受上下文长度的硬性约束，而是通过一种递归方式，由变压器压缩传感器读数的历史，形成紧凑的表现形式。此外，还提出了一项新的下游任务“Mem-Nav”，评估该模型在保持场景有用表示、导航到之前实际操作开始前观察到的目标以及计算效率方面的能力，特别是在与具有观察历史视图注意机制的经典变压器的比较中表现出色。", "conclusion": "这种大型递归模型能够有效地保持场景表示、导航到之前实际操作开始前观察到的目标，并且在计算效率上非常高效。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20468", "html_url": "https://arxiv.org/abs/2510.20468", "title": "通过图像偏好模型实现可移植的黑盒一次性水印伪造", "title_en": "Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models", "authors": "Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko", "background": "近年来，数字内容水印技术因其生成模型的广泛使用和法律压力而受到越来越多的关注。随着大量AI生成的内容在网上可用，水印在大规模确保内容真实性及归属方面的作用越来越重要。尽管已经有很多工作评估了水印对移除攻击的鲁棒性，但关于水印伪造的研究仍相对不足，即水印从真实内容中窃取并应用于恶意内容的现象。本研究旨在探讨在广泛使用的后处理图像水印场景下的水印伪造问题。", "innovation": "本文介绍了使用纯粹程序生成的图像训练的偏好模型来评估图像是否被水印。该模型不依赖真实水印进行训练。通过优化输入图像以反向传播的方法，模型能够移除和伪造水印，仅需一个水标和不需要了解水印模型，使得攻击更加简单和可行。该方法在多种后处理图像水印模型上进行了评估，证实了其伪造水印的有效性，对当前水印方法的安全性提出了质疑。所有代码和资源都是公开的。", "conclusion": "研究结果表明，利用图像偏好模型进行水印伪造是可能的，这揭示了现有水印方法的安全隐患，并不依赖真实水印的偏好模型能够大幅度简化伪造攻击。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20762", "html_url": "https://arxiv.org/abs/2510.20762", "title": "MEIcoder: 利用最兴奋输入解码神经活动中的视觉刺激", "title_en": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs", "authors": "Jan Sobotka,Luca Baroni,Ján Antolík", "background": "从神经群体活动解码视觉刺激对于理解大脑和脑机接口的应用至关重要，但生物数据经常稀缺，尤其是在灵长类动物或人类中，由于技术限制如两光子成像难以应用。这给深度学习解码技术带来了挑战。为解决此问题，提出了MEIcoder，一种基于神经元特定最兴奋输入（MEIs）、结构相似性指数度量损失和对抗性训练的生物启发解码方法。", "innovation": "MEIcoder在初级视皮层（V1）的单细胞活动重建方面达到业内最佳性能，尤其在数据量小且记录神经元少的小数据集上表现出色。通过消融研究证明，MEIs是性能的主要驱动因素。在扩展实验中，展示出MEIcoder能够从不到1000个训练数据点和1,000至2,500个神经元重建高保真、自然外观的图像。还提出了一种包含超过160,000个样本的统一基准，以促进未来研究。", "conclusion": "该研究展示了早期视觉系统可靠解码的可行性，并为神经科学和神经工程应用提供了实用见解。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20809", "html_url": "https://arxiv.org/abs/2510.20809", "title": "Real Deep Research for AI, Robotics and Beyond", "title_en": "Real Deep Research for AI, Robotics and Beyond", "authors": "Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang", "background": "随着人工智能和机器人技术研究的迅速增长，每年发表的研究论文数量已超过10,000篇。这使得研究人员难以保持最新。快速发展的趋势、跨学科工作的兴起以及探索超出自身专业领域的必要性都增加了这一挑战。", "innovation": "我们提出了一种可泛化的分析管道，能够系统地分析任何研究领域：识别新兴趋势，发现跨领域的机会，并为新的探索提供具体的起点。在本文中，我们介绍了Real Deep Research (RDR)框架，该框架应用于人工智能和机器人领域，特别是基础模型和机器人技术的进步。我们还简要扩展了该分析到其他科学领域。", "conclusion": "希望本文为从事人工智能及其他领域研究的研究人员提供一些有价值的见解。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20800", "html_url": "https://arxiv.org/abs/2510.20800", "title": "用单步梯度计算和100个样本高效压缩：利用单步梯度计算100个样本高效精简大型语言模型以适应新数据", "title_en": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "authors": "Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus", "background": "最近，Sharma等人提出了一种名为Layer-SELection-Rank Reduction (LASER) 的方法，证明了可以直接修剪精心选择的LLM权重矩阵的高阶组件而无需任何基于梯度的微调，从而提升下游任务的准确性。但是，LASER需要对每个矩阵进行全面的数据集前向传播搜索，这使其不适合快速部署。论文探讨了如何移除这种开销并发现了一种高效的方法来适应LLM：仅需检查一小部分精心选择的矩阵，无需逐层扫描；通过允许矩阵行围绕多个子空间聚类并分别分解每个集群，可以增加因子分解搜索空间并减少过拟合，从而进一步提升准确性；此外，通过仅在100个样本上评估来计算指示梯度和计算最终准确性，可以进一步减少搜索时间。", "innovation": "该研究提出了一种高效的LLM适应算法：仅通过100个样本的单步梯度计算和扫描来适应新数据，而无需微调。具体创新点包括：(i) 仅需检查一小部分精心选择的矩阵；(ii) 每个矩阵的奇异值梯度指明哪些矩阵需要缩减；(iii) 允许矩阵行聚类在多个子空间，然后分别分解每个集群，进一步减少过拟合和提升准确性；(iv) 仅在100个样本上计算指示梯度和评估最终准确性，以减少搜索时间；(v) 展示了适配下游任务主要依赖于提示风格而非数据集大小。", "conclusion": "结合这些发现，论文提出了一种快速且稳健的LLM适应算法。使用100个示例的单步梯度计算和快速扫描潜在候选层和因子分解技术，可以完全在没有微调的情况下适应新数据集。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2211.00198", "html_url": "https://arxiv.org/abs/2211.00198", "title": "Frequency Cam: 实时成像周期性信号", "title_en": "Frequency Cam: Imaging Periodic Signals in Real-Time", "authors": "Bernd Pfrommer", "background": "事件相机由于其高时间分辨率和大动态范围，特别适合于图像中周期性信号的分析。本文旨在开发一种高效且完全异步的事件相机算法来检测图像像素闪烁的基本频率。", "innovation": "本文提出了一种利用二阶数字无限脉冲响应（IIR）滤波器的算法，实现了像素亮度的近似重构，并且比基线方法更抗高频率噪声。还发现信号下降沿比上升沿的周期估算更准确，且零交叉插值能进一步提高精度。实验表明，虽然单个像素在检测高达64kHz频率上表现出色，但由于读出带宽的限制，这一优势在全传感器成像中不再明显。", "conclusion": "硬件级别更靠近传感器的实现能够显著提升频率成像效率。Frequency Cam 是开源的ROS节点实现，可在笔记本CPU单核上以每秒超过5000万个事件的速度运行，生成的结果与Prophesee Metavision Toolkit中的振动分析模块的结果非常相似。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.20813", "html_url": "https://arxiv.org/abs/2510.20813", "title": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation", "title_en": "GSWorld: Closed-Loop Photo-Realistic Simulation Suite for Robotic Manipulation", "authors": "Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang", "background": "当前，机器人操作领域的研究主要依赖于模拟器和实际机器人数据。虽然现有的模拟器在一定程度上能够仿真现实场景，但它们通常缺乏现实感，且在真实部署前很少进行闭环评估。这导致了模拟器和实际机器人之间存在显著的性能差距，即所谓的“模拟-现实差异”问题。GSWorld通过引入物理引擎和一种新的资产格式（GSDF），旨在解决这一问题，提供一个更真实、可控的机器人操作模拟环境，以更有效地训练和评估机器人操作策略，从而提高策略的鲁棒性和实际应用可行性。", "innovation": "GSWorld在机器人操作模拟方面提出了两项重要创新：首先，通过结合3D高斯点簿技术和物理引擎，实现了高度逼真的物理仿真；其次，提出了一种新的资产格式（GSDF），将高斯网格表示与机器人URDF和其他物体相结合，以增强场景的真实感和多样性。此外，GSWorld还提供了一种高效的重建流水线，构建了一个包含多种机器人和物体的数据库，为机器人操作模拟提供了实际支持。", "conclusion": "通过GSDF格式和物理引擎的集成应用，GSWorld成功地展示了几个有趣的即时应用，包括零样本模拟到现实的像素到动作操作策略学习、高质量的DAgger数据收集、真实机器人操作策略的可重复模拟基准测试等。这表明GSWorld为机器人操作的研究提供了一种新的、更综合的方法，能够有效地结合模拟和实际数据，以提高机器人操作策略的性能和稳健性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.11224", "html_url": "https://arxiv.org/abs/2412.11224", "title": "GenLit: 将单张图像重新照明重新定义为视频生成", "title_en": "GenLit: Reformulating Single-Image Relighting as Video Generation", "authors": "Shrisha Bharadwaj,Haiwen Feng,Giorgio Becherini,Victoria Fernandez Abrevaya,Michael J. Black", "background": "在计算机视觉和图形学中，单张图像内三维场景的照明操纵代表了一个根本性的挑战。传统方法使用逆渲染技术，涉及显式的三维资产重建和昂贵的光线追踪模拟。最近视觉基础模型的进步表明，未来可能不需要显式物理模型，而是使用大量图像和视频数据训练的网络来解决这一问题。", "innovation": "本文利用视频扩散模型（特别是Stable Video Diffusion）的隐式场景理解来重新照亮一张图像。通过引入GenLit框架，将图形引擎执行光照操纵的能力提炼为一个视频生成模型，用户可以直接在给定图像中插入并操纵一个点光源，并直接生成视频序列的结果。作者发现，一个仅在小型合成数据集上微调的模型能够泛化到真实世界的场景，使得单张图像的重新照明可以通过合理的阴影和光的相互作用得以实现。", "conclusion": "本文的结果强调了视频基础模型捕捉丰富光照、材质和形状信息的能力，并表明这些模型无需显式资产重建或光线追踪技术训练即可用于重新照明操作。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.05500", "html_url": "https://arxiv.org/abs/2410.05500", "title": "增强深度学习的残差柯尔莫哥洛夫-阿诺尔德网络", "title_en": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning", "authors": "Ray Congrui Yu,Sherry Wu,Jiang Gui", "background": "尽管深度卷积神经网络（CNNs）取得了巨大成功，但由于网络深度中的数百层，它们在优化过程中可能非常困难且训练成本高昂。传统的卷积操作因其线性性质和固定的激活函数而受到限制，很多层需要学习有意义的数据模式。这导致该方法在计算上不高效，尤其是在小数据集上容易出现过拟合或梯度爆炸的风险。因此，本文介绍了一个名为Residual Kolmogorov-Arnold Network（RKAN）的“插件”模块，该模块通过易于集成到传统深度网络的各个阶段来学习支持多项式特征变换，从而提高现有卷积框架的效果。", "innovation": "提出了名为Residual Kolmogorov-Arnold Network (RKAN) 的模块，该模块高度紧凑，可以轻松集成到传统深度网络的任何阶段，学习结合支持的多项式特征变换以增强现有的卷积框架，从而在不同视觉任务和广泛测试的基准测试中，持续改善基线模型，并实现尖端性能。", "conclusion": "RKAN模块提供了一致的改进，相比于基线模型，极大提升了不同视觉任务和广泛测试基准的表现，并实现了尖端性能。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.16892", "html_url": "https://arxiv.org/abs/2408.16892", "title": "Tex-ViT：一种通用且对抗性鲁棒的基于纹理的双分支交叉注意力深伪检测器", "title_en": "Tex-ViT: A Generalizable, Robust, Texture-based dual-branch cross-attention deepfake detector", "authors": "Deepak Dagar,Dinesh Kumar Vishwakarma", "background": "当前，通过生成对抗网络(GAN)生成的深度伪造(deepfakes)已成为主流技术，传统的卷积神经网络(CNN)能够在识别假媒体方面取得成功，但在不同类型的数据集上表现不佳，并且容易受到对抗攻击，因为它们缺乏鲁棒性。尽管视觉变换器在图像分类问题中表现出巨大潜力，但它们需要足够的训练数据。鉴于这些局限性，本文提出了一种Tex-ViT模型，通过结合ResNet和视觉变换器来提升CNN特征，专门优化全局纹理模块，以提高模型的鲁棒性，识别深度伪造视频中不一致的纹理特性。", "innovation": "Tex-ViT模型利用ResNet和双分支交叉注意力机制的视觉变换器来增强CNN特征，特别强调了改进全局纹理模块，该模块用于提取特征图之间的相关性。实验表明，该模型在各种不同的FF++类别、DFDCPreview和Celeb-DF数据集上，即使经过模糊、压缩和添加噪声等多种后处理情况，也能达到98%的泛化准确率，表明其在不同类型数据集上的鲁棒性和适用性。", "conclusion": "Tex-ViT模型通过结合ResNet和双分支交叉注意力机制的视觉变换器，显著提高了深度伪造检测的鲁棒性。实验结果证明，该模型能够学会操纵样本中的共享的区别性纹理特征，并能够应用于各种情况，对抗多种后处理手段。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.18810", "html_url": "https://arxiv.org/abs/2412.18810", "title": "FairGen：通过自我发现的潜在方向增强文本到图像扩散模型的公平性", "title_en": "FairGen: Enhancing Fairness in Text-to-Image Diffusion Models via Self-Discovering Latent Directions", "authors": "Yilei Jiang,Weihong Li,Yiyuan Zhang,Minghong Cai,Xiangyu Yue", "background": "扩散模型（DM）在各种图像生成任务中表现出色，但它们也反映了训练集中固有的偏见。由于这些偏见可能在现实世界的应用中延续一种歪曲的世界观并阻碍少数群体的机会，因此需要对DM进行去偏处理。现有去偏方法通常需要重新训练模型并使用人类制作的参考数据集或附加分类器，这些方法存在两个主要限制：（1）收集参考数据集会导致高昂的标注成本；（2）去偏效果受参考数据集或附加分类器质量的限制。", "innovation": "本文提出了FairGen，这是一种插件式方法，能够在自我发现的潜在方向中学习属性潜在方向，从而消除对参考数据集的依赖。FairGen包括两部分：一组属性适配器和一个分布指示器。每个适配器都旨在学习一个属性潜在方向，并通过自我发现过程进行优化。然后，分布指示器会乘以适配器集合以引导生成过程向指定的分布方向发展。该方法允许同时对DM中的多种属性进行去偏，同时保持轻量级并且容易与其他DM集成，无需重新训练。实验表明，该方法在消除性别、种族及其交叉偏见方面显著优于现有的SOTA方法。", "conclusion": "本文提出的FairGen方法主要优势在于无需依赖耗资的参考数据集，通过自我发现的潜在方向来学习属性潜在方向，进而实现有效的去偏处理。方法轻量级且易于集成到其他DM中，实验证明其在多个属性去偏方面取得了优于现有先进方法的效果。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.03639", "html_url": "https://arxiv.org/abs/2502.03639", "title": "在视频生成中迈向物理理解：一种3D点正则化方法", "title_en": "Towards Physical Understanding in Video Generation: A 3D Point Regularization Approach", "authors": "Yunuo Chen,Junli Cao,Vidit Goel,Sergei Korolev,Chenfanfu Jiang,Jian Ren,Sergey Tulyakov,Anil Kag", "background": "当前的视频生成模型在处理形状感知和动态变化时存在不足，导致生成的视频中常出现非物理变形和对象形态变化等问题，尤其是在涉及物体接触等复杂场景时。现有方法缺乏对3D信息的处理，从而限制了模型的真实性。", "innovation": "本文提出了一种新颖的视频生成框架，结合了3D几何和动态感知。该框架通过增强2D视频的3D点轨迹，并在像素空间中对齐，生成了3D意识视频数据集PointVid。利用该数据集对潜扩散模型进行微调，使其能够在视频中用3D笛卡尔坐标追踪2D物体。此外，通过正则化物体的形状和运动，消除非物理变形等不良现象，提高生成RGB视频的质量，解决了现有模型中普遍存在的对象变形问题。", "conclusion": "本文的方法能够适用于包含接触场景的任务性视频，并能有效提升视频模型的视觉可信度。该方法可以无缝集成到现有的视频扩散模型中，提高它们的视觉真实感。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.09080", "html_url": "https://arxiv.org/abs/2502.09080", "title": "BevSplat: 通过基于特征的高斯原始模型解决弱监督跨视图定位中的高度歧义", "title_en": "BevSplat: Resolving Height Ambiguity via Feature-Based Gaussian Primitives for Weakly-Supervised Cross-View Localization", "authors": "Qiwei Wang,Shaoxun Wu,Yujiao Shi", "background": "这篇论文探讨了弱监督跨视图定位的问题，目标是通过嘈杂的地面真实标注，估算地面摄像机相对于卫星图像的姿态。现有方法通常采用Bird's-Eye View (BEV)合成来缩短跨视图域之间的差距，但地面图像和卫星高度图缺乏深度信息导致了许多问题，特别是高度歧义问题。现有的解决方案要么假设平坦的地平面，要么依赖复杂模型如跨视图变压器。", "innovation": "本文提出了一种名为BevSplat的新方法，通过使用基于特征的高斯原始模型来解决高度歧义问题。每个地面上的像素都用具有语义和空间特征的3D高斯模型来表示，并用于合成BEV特征图以进行相对姿态估计。此外，为了应对全景查询图像的挑战，作者引入了一种基于icosphere的监督策略。实验表明，BevSplat在广泛使用的KITTI和VIGOR数据集上的定位精度远高于以前的方法。", "conclusion": "通过实验结果验证，BevSplat方法在弱监督跨视图定位中显著提高了定位精度。该方法通过基于特征的高斯原始模型解决了高度歧义，有效地解决了现有方法的不足。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.01243", "html_url": "https://arxiv.org/abs/2501.01243", "title": "Face-Human-Bench: 多模态助手中面部和人体理解的综合基准", "title_en": "Face-Human-Bench: A Comprehensive Benchmark of Face and Human Understanding for Multi-modal Assistants", "authors": "Lixiong Qin,Shilong Ou,Miaoxuan Zhang,Jiangning Wei,Yuhang Zhang,Xiaoshuai Song,Yuchen Liu,Mei Wang,Weiran Xu", "background": "面部和人体在社会互动中至关重要，并且广泛出现在日常照片和视频中。因此，对面部和人体的理解可以帮助多模态助手提升响应质量并扩大应用范围。当前，多模态助手社区缺乏对面部和人体理解能力的全面和科学评估。因此，本文提出了一种分层能力分类法，包括三个层次的能力。基于此分类法，收集了来自面部和人体社区公共数据集的图像和注释，构建了一种半自动数据管道来生成新的基准问题。最终，所获得的Face-Human-Bench包括一个开发集和一个测试集，每个都有1800个问题，同时支持英语和中文。", "innovation": "本文首次提出了一个分层的能力分类法，用于评估多模态助手对面部和人体的理解能力。通过该分类法收集并构建了一个用于新基准的半自动数据管道。然后，对25个主流的多模态大型语言模型（MLLMs）进行了评估，关注能力和性能的相关性、目标相对位置对性能的影响以及Chain of Thought (CoT)提示对性能的影响。此外，研究了MLLMs需要通过专家模型补充的能力，并将数据集和评估代码在公开渠道进行了发布。", "conclusion": "通过Face-Human-Bench基准，对多模态助手进行评估，不仅提升了我们对面部和人体理解和处理能力的深入理解，也为未来相关研究和开发提供了有力支持。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.13777", "html_url": "https://arxiv.org/abs/2503.13777", "title": "8-Calves 图像数据集", "title_en": "8-Calves Image dataset", "authors": "Xuyang Fang,Sion Hannuna,Neill Campbell,Edwin Simpson", "background": "自动化畜牧监控对于精准农业至关重要，但现有的计算机视觉模型受到缺乏反映现实世界群体挑战的数据集的限制。", "innovation": "提出了8-Calves数据集，这是一个具有挑战性的基准，用于多动物检测、跟踪和识别。该数据集包含一个持续一小时的八个荷斯坦-弗里生牛幼崽在牧场内的视频，其中包含频繁遮挡、运动模糊和多样的姿态。作者提供了一个半自动化的处理管道，使用微调的YOLOv8检测器和ByteTrack，然后手动校正，生成了超过537,000个带时间身份标签的边界框。通过对28个目标检测器的基准测试，作者展示了在宽松IOU阈值下的接近完美性能，但在更严格的度量标准上显著差距，突显了精细定位的挑战。作者还揭示了身份识别基准中微调聚焦在语义学习上的模型（如BEiT）表现出更好的迁移性。", "conclusion": "8-Calves数据集通过提供时间和丰富的真实挑战，填补了空白，为推进农业视觉模型提供了宝贵的资源。数据集和代码可在该网址获取。对于跟踪任务，顶级方法在检测精度上表现出高水平（MOTA > 0.92），但身份保持方面遇到了困难（IDF1 ≈ 0.27），突显了在遮挡密集场景中的一项关键挑战。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.23356", "html_url": "https://arxiv.org/abs/2503.23356", "title": "ControlFusion：一种带有语言-视觉退化提示的可控图像融合框架", "title_en": "ControlFusion: A Controllable Image Fusion Framework with Language-Vision Degradation Prompts", "authors": "Linfeng Tang,Yeda Wang,Zhanchuan Cai,Junjun Jiang,Jiayi Ma", "background": "当前的图像融合方法在处理真实世界成像场景中的复合退化时表现不佳，且缺乏根据不同用户需求灵活调整的能力。", "innovation": "本文提出了一种可控图像融合框架，名为ControlFusion，通过语言-视觉提示适应性消除复合退化。该框架包括一个融合模型，该模型结合了Retinex理论和大气散射原理以模拟复合退化，以及一个被退化提示动态增强特征的提示调控恢复和融合网络。此外，还引入了文本编码器嵌入用户指定的退化类型和严重程度，以及自主感知源图像退化情况的空间-频率协同视觉适配器。", "conclusion": "广泛的实验表明，ControlFusion在融合质量和处理退化方面优于最新的图像融合方法，特别是在对抗不同水平的真实世界和复合退化方面。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.15984", "html_url": "https://arxiv.org/abs/2503.15984", "title": "DIPLI: 隐图像深学习幸运成像法在盲天文学图像恢复中的应用", "title_en": "DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration", "authors": "Suraj Singh,Anastasia Batsheva,Oleg Y. Rogov,Ahmed Bouridane", "background": "现代图像恢复和超分辨率方法通常使用深度学习，因为它比传统算法表现出色。然而，深度学习方法通常需要大量训练数据，而在天文学摄影中这种数据稀缺。Deep Image Prior (DIP) 通过在单张图像上进行盲训练，绕过了这一限制，但在某些情况下效果不佳，容易出现过拟合、伪影产生和不稳定等问题。", "innovation": "为了解决这些问题并提高性能，本文提出了DIPLI框架。该框架采用了多帧训练而不是单帧训练，结合Back Projection技术，利用TVNet模型估计光学流，同时通过Langevin动力学获得无偏的蒙特卡洛估计。实验对比了该方法与Lucky Imaging（一种经典的计算机视觉技术）、DIP、基于_transformer_模型的RVRT和基于_扩散_模型的DiffIR2VR-Zero。在合成数据集上的实验展示了该方法在多数情况下都优于基线方法，特别是在SSIM、PSNR、LPIPS和DISTS指标上。此外，该模型需要更少的输入图像，并且比Lucky Imaging更不易过拟合或产生伪影。在实际天文学数据上进行的评估证实了其高效的图像重建质量和广泛应用的鲁棒性。", "conclusion": "实验结果验证了DIPLI在天文学图像复原中的优越性能，并且其对真实数据具有高度的鲁棒性，适用于复杂场景下的图像恢复任务。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.15958", "html_url": "https://arxiv.org/abs/2504.15958", "title": "FreeGraftor：无需训练的跨图像特征移植方法用于基于主体的文本到图像生成", "title_en": "FreeGraftor: Training-Free Cross-Image Feature Grafting for Subject-Driven Text-to-Image Generation", "authors": "Zebin Yao,Lei Ren,Huixing Jiang,Chen Wei,Xiaojie Wang,Ruifan Li,Fangxiang Feng", "background": "基于主体的图像生成旨在从参考图像合成立方俊的新场景，同时遵循文本指导。然而，现有方法在忠实度与效率之间存在关键的权衡问题。基于调优的方法依赖于耗时且资源密集的主体特定优化，而零样本方法通常难以维持足够的主题一致性。", "innovation": "FreeGraftor 提出了一种无需训练的框架，通过跨图像特征移植来解决这些限制。具体来说，FreeGraftor 利用了语义匹配和位置约束注意力融合，从参考主体转移到生成图像中的视觉细节。此外，我们的框架引入了一种新颖的噪声初始化策略，以保留参考主体的几何先验，从而促进鲁棒特征匹配。", "conclusion": "广泛的定性和定量实验表明，我们的方法能够在保持文本对齐场景合成的同时，实现精确的主题身份转移。FreeGraftor 不需要模型微调或额外训练，在主体忠实度和文本对齐方面显著优于现有的零样本和无需训练方法。此外，我们的框架可以无缝扩展到多主体生成，使其实现现实世界的部署。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.15450", "html_url": "https://arxiv.org/abs/2505.15450", "title": "全面评估和分析文本到图像扩散模型中的不适宜内容概念去除方法", "title_en": "Comprehensive Evaluation and Analysis for NSFW Concept Erasure in Text-to-Image Diffusion Models", "authors": "Die Chen,Zhiwen Li,Cen Chen,Yuexiang Xie,Xiaodan Li,Jinyan Ye,Yingda Chen,Yaliang Li", "background": "文本到图像扩散模型在多个领域得到了广泛应用，展示了显著的创意潜力。然而，扩散模型的强大泛化能力可能导致生成不适合公开的内容（NSFW），这给其安全部署带来了巨大风险。已经提出了一些概念去除方法来减轻与NSFW内容相关的问题，但这些方法在各种场景中的综合评估仍然不足。为了填补这一空白，本文介绍了一个全管道工具套件，旨在专门处理概念去除，并首次对NSFW概念去除方法进行了系统性的研究。通过研究底层机制和实际观察之间的相互作用，本文提供了关于概念去除方法在多种实际场景中有效应用的深入见解和实用指导，旨在推进扩散模型内容安全的理解，并为这一关键领域未来的研究和开发奠定坚实的基础", "innovation": "本文提出了一个专门针对概念去除的全管道工具套件，并进行了首次系统性的NSFW概念去除方法研究。通过综合评估，在多种场景中提供了对概念去除方法有效应用的深入见解和实用指导", "conclusion": "本文提供了对扩散模型内容安全概念去除方法的深入见解，为未来研究和开发奠定了基础，旨在推动这一领域的理解和进步"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12499", "html_url": "https://arxiv.org/abs/2505.12499", "title": "在视觉信息约束下的瓶颈语义增量重新平衡对比对齐在文本视频检索中的应用", "title_en": "Rebalancing Contrastive Alignment with Bottlenecked Semantic Increments in Text-Video Retrieval", "authors": "Jian Xiao,Zijie Song,Jialong Hu,Hao Cheng,Jia Li,Zhenzhen Hu,Richang Hong", "background": "近年来，文本视频检索领域的发展很大程度上受到了对比学习（Contrastive Learning）的推动。然而，现有方法往往忽视了不同模态之间的差距影响，导致锚点表示在原地优化，限制了其对齐能力。同时，噪音硬负样的存在进一步扭曲了锚点的语义。", "innovation": "本文提出了一种名为GARE（Gap-Aware Retrieval）的框架。GARE引入了一种可学习的、特定对的增量$\triangle_{ij}$，用于重新分配梯度以缓解优化紧张，并吸收噪声。$\triangle_{ij}$是通过受信任区域约束的InfoNCE损失的多元一阶泰勒展开推导出来的，能够引导局部一致的下降方向。通过一个轻量级的神经模块，根据语义差距条件下的增量在批次之间进行了结构感知的校正，并通过变分信息瓶颈进行了正则化处理，以增强稳定性和语义一致性。", "conclusion": "实验结果表明，GARE持续提高了对齐准确性和鲁棒性，验证了差距感知紧张缓解的有效性。代码可以在此处获取：this https URL"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.17581", "html_url": "https://arxiv.org/abs/2505.17581", "title": "MODEM：一种针对恶劣天气图像恢复的莫恩序列降级估计机制", "title_en": "MODEM: A Morton-Order Degradation Estimation Mechanism for Adverse Weather Image Recovery", "authors": "Hainuo Wang,Qiming Hu,Xiaojie Guo", "background": "由于恶劣天气引起的降质具有高度非均匀性和空间异质性，如细颗粒雨迹与广泛雾霾等，恢复这类降质图像仍是一个重大挑战。准确估计潜在的降质可以直观地为图像恢复模型提供更有针对性和有效的指导，使其能够采用自适应处理策略。", "innovation": "提出了莫恩序列降级估计机制（MODEM），其核心是莫恩序列2D选择性扫描模块（MOS2D），它结合了莫恩编码的空间排序和选择性的状态空间模型，以捕捉长程依赖性同时保持局部结构一致性。此外，引入了双降级估计模块（DDEM），能够解耦并估计全局与局部降质先验，这些先验动态调节MOS2D模块，支持自适应和上下文感知的恢复。", "conclusion": "广泛的实验和消除研究证实，MODEM在多种基准测试和天气类型中达到最先进的结果，突显了其在建模复杂降质动态方面的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.16247", "html_url": "https://arxiv.org/abs/2503.16247", "title": "OpenMIBOOD: Open Medical Imaging Benchmarks for Out-of-Distribution Detection", "title_en": "OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection", "authors": "Max Gutbrod,David Rauber,Danilo Weber Nunes,Christoph Palm", "background": "随着人工智能在关键领域如医疗健康中的依赖性日益增长，确保这些系统的可信性变得尤为重要，特别是当面对意外或异常输入时。目前缺乏专门针对医疗影像的度量基准来评估模型的异常检测能力，因此提出了OpenMIBOOD基准框架，用于评估医疗影像领域的异常检测方法。", "innovation": "OpenMIBOOD引入了一个包含三个医学领域基准的全面框架，涵盖了14个数据集，分为协变转换内在分布、接近异常分布和远异常分布类别。评估了24种后处理方法，提供了一个标准化参考，促进异常检测方法的发展和公平比较。该研究结果表明，自然影像领域的大规模异常检测基准结果并不能直接应用于医疗场景，凸显了需要专门的医疗应用异常检测基准的必要性。", "conclusion": "OpenMIBOOD旨在通过减少AI模型对训练分布外输入的风险，支持医疗领域中可靠且可信赖的AI系统的发展。相关基准库已公开可用。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16761", "html_url": "https://arxiv.org/abs/2505.16761", "title": "Mesh-RFT: 通过精细调节增强网格生成", "title_en": "Mesh-RFT: Enhancing Mesh Generation via Fine-grained Reinforcement Fine-Tuning", "authors": "Jian Liu,Jing Xu,Song Guo,Jing Li,Jingfeng Guo,Jiaao Yu,Haohan Weng,Biwen Lei,Xianghui Yang,Zhuo Chen,Fangqi Zhu,Tao Han,Chunchao Guo", "background": "现有的用于3D网格生成的预训练模型常常存在数据偏差和生成低质量结果的问题。而全局强化学习方法依赖物体级别的奖励，难以捕捉局部结构细节。这些挑战促使研究者寻求新的解决方案来改进3D网格生成的质量。", "innovation": "本文提出了Mesh-RFT，一种新颖的细粒度强化微调框架。它使用Masked Direct Preference Optimization（M-DPO）进行质量感知面孔掩码，以便进行局部细化。为了促进高效的质量评估，引入了目标拓扑感知评分系统，通过边界边比率（BER）和拓扑评分（TS）两个指标来评估物体和表面对几何完整性和拓扑规则性的评价。通过将这些指标集成到细粒度的强化学习策略中，Mesh-RFT成为首个在单个面的粒度上优化网格质量的方法，解决了局部错误问题，同时保持了全局一致性。实验结果表明M-DPO方法在海德劳夫距离（HD）上减少了24.6%，在拓扑评分（TS）上提高了3.8%；同时，与全局DPO方法相比，Mesh-RFT在海德劳夫距离（HD）上减少了17.4%，在拓扑评分（TS）上提高了4.9%。这些结果证明了Mesh-RFT提高几何完整性和拓扑规则性的能力，实现了生产级网格生成的新先进行为。", "conclusion": "Mesh-RFT为3D网格生成提供了新的解决方案，通过精细调节优化网格质量，达到了生产级网格生成的新先进行为。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16793", "html_url": "https://arxiv.org/abs/2505.16793", "title": "REOBench: 评估地球观测基础模型鲁棒性的基准", "title_en": "REOBench: Benchmarking Robustness of Earth Observation Foundation Models", "authors": "Xiang Li,Yong Tao,Siyuan Zhang,Siwei Liu,Zhitong Xiong,Chunbo Luo,Lu Liu,Mykola Pechenizkiy,Xiao Xiang Zhu,Tianjin Huang", "background": "地球观测基础模型在多项地球观测任务中表现出较强的泛化能力，但它们在真实世界扰动下的鲁棒性仍然没有得到充分探索。为了填补这个空白，我们介绍了REOBench，这是第一个综合基准，用于评估地球观测基础模型在六个任务和十二种图像破坏类型（包括外观基和几何扰动）下的鲁棒性。我们的基准重点在于高分辨率的光学遥感图像，这些图像在城市规划和灾害响应等关键应用中广泛使用。", "innovation": "我们通过REOBench基准对使用掩码图像建模、对比学习和视觉-语言预训练范式训练的一系列模型进行了系统性评估。结果显示：(1) 当地球观测基础模型面对输入扰动时，它们会遭受显著的性能下降。(2) 性能下降的程度因任务、模型结构、骨干大小和扰动类型而异，性能下降范围从不到1%到超过20%。(3) 视觉-语言模型在多模态任务中展现出更强的鲁棒性。REOBench强调了当前地球观测基础模型对真实世界扰动的脆弱性，并为开发更鲁棒和可靠的基础模型提供了实际建议。", "conclusion": "REOBench强调了目前地球观测基础模型在面对现实世界扰动时的脆弱性，并为开发更鲁棒和可靠的基础模型提供了行动指导。所有代码和数据均可在该链接公开获取。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.16378", "html_url": "https://arxiv.org/abs/2503.16378", "title": "Panoptic-CUDAL：降雨条件下澳大利亚农村点云数据集", "title_en": "Panoptic-CUDAL: Rural Australia Point Cloud Dataset in Rainy Conditions", "authors": "Tzu-Yun Tseng,Alexey Nekrasov,Malcolm Burdorf,Bastian Leibe,Julie Stephany Berrio,Mao Shan,Zhenxing Ming,Stewart Worrall", "background": "现有自动驾驶数据集主要面向结构化城市环境和有利天气条件，未能充分覆盖农村环境和恶劣天气条件的复杂性。虽然某些数据集包含天气和光照变化，但恶劣天气情况记录得很少。降雨会对传感器功能产生显著影响，导致LiDAR和相机数据中出现噪声和反射，降低系统可靠环境感知和安全导航的能力。", "innovation": "本文介绍了基于雨天草地的澳大利亚农村点云数据集Panoptic-CUDAL，这是一个专门设计的用于农村环境下的雨天全景分割的数据集。该数据集通过记录高分辨率LiDAR、相机和姿态数据，提供了一个丰富信息且具有挑战性的场景。同时，还为激光雷达点云上的全景分割、语义分割和三维占用预测方法提供了基准结果分析。", "conclusion": "Panoptic-CUDAL数据集通过记录高分辨率数据，在降雨条件下为农村环境下的感知任务提供了丰富多样的信息。研究提供了Panoptic分割、语义分割和三维占用预测方法在激光雷达点云上的基准结果，并公开了该数据集，以便进一步研究和开发适应雨天农村环境的自动驾驶技术。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19256", "html_url": "https://arxiv.org/abs/2505.19256", "title": "PolyPose：通过多项刚性变换进行可变形的2D/3D配准", "title_en": "PolyPose: Deformable 2D/3D Registration via Polyrigid Transformations", "authors": "Vivek Gopalakrishnan,Neel Dey,Polina Golland", "background": "在介入手术中，从有限的2D X射线图像集中确定患者3D姿态是一个关键任务。虽然术前的体层成像技术（如CT和MRI）能提供精确的3D定位和解剖目标的可视化，但在手术过程中无法使用这些技术，通常使用快速的2D成像（X射线）代替。为了将体积指导整合到手术过程中，我们提出了PolyPose，这是一种简单且鲁棒的方法来进行可变形的2D/3D配准。", "innovation": "PolyPose 通过采用多项刚性变换参数化复杂三维变形场，同时利用生物约束——在典型运动中单独的骨头不会弯曲，解决了这个问题。PolyPose 通过遗传符合解剖先验信息，尊重人类运动的分段刚性性质，而不同于现有的假设无关节运动或在欠定环境中完全失败的方法。这种方法消除了昂贵的变形正则化的需求，这些正则化需要患者和手术特定的超参数优化。", "conclusion": "在多元数据集上进行广泛实验表明，这种强烈的归纳偏差使PolyPose 能够将患者的术前体积成功地与尽可能少的两个X射线对齐，从而在当前配准方法失效的稀疏视场和有限角度设置中提供关键的三维指导。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18608", "html_url": "https://arxiv.org/abs/2505.18608", "title": "Spiking Neural Networks 需要高频信息", "title_en": "Spiking Neural Networks Need High Frequency Information", "authors": "Yuetong Fang,Deming Zhou,Ziqing Wang,Hongwei Ren,ZeCui Zeng,Lusong Li,Shibo Zhou,Renjing Xu", "background": "脉冲神经网络(Spiking Neural Networks, SNNs)通过二进制(0/1)脉冲进行信息传递，具有模仿大脑和节能计算的潜力，但在性能上仍落后于人工神经网络。传统的观点认为，性能的差距主要是由于稀疏和二进制激活导致的信息损失。然而，本文挑战了这一长期存在的假设，揭示了之前未被注意到的频率偏倚：脉冲神经元会抑制高频成分，优先传播低频信息。这种频域不平衡被认为是SNN中特性表示劣化的原因。通过实验证明，采用低通(平均池化)降低了性能，而使用高通(最大池化)则提高了性能。", "innovation": "本文提出了一种新的_max-Former_模型，通过引入两个频率增强操作器：(1) 在patch嵌入中增加最大池化，(2) 使用深度可分离卷积代替注意力机制，有效地恢复了高频信号。该模型仅使用63.99M参数就达到了82.39%的顶级精度，超越了Spikformer的74.81%和66.34M参数。此外，作者还提出了_max-ResNet-18_，该模型在卷积网络基准测试中达到了最新的性能表现：在CIFAR-10上的精度为97.17%，在CIFAR-100上的精度为83.06%。", "conclusion": "本文通过实验和模型改进证明了高频信息对于SNN的重要性，并提出了一个简单而有效的解决方案，这一方法有望激发未来对该领域独特性质的研究。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.22038", "html_url": "https://arxiv.org/abs/2505.22038", "title": "Balanced Token Pruning: 超越局部优化的平衡Token剪枝", "title_en": "Balanced Token Pruning: Accelerating Vision Language Models Beyond Local Optimization", "authors": "Kaiyuan Li,Xiaoyue Chen,Chen Gao,Yong Li,Xinlei Chen", "background": "大视觉-语言模型（LVLMs）在多模态任务中表现出了令人印象深刻的能力，通过将图像编码成数千个Tokens。然而，大量的图像Tokens造成了显著的计算负担，并且使用动态高分辨率输入进一步加大了这一负担。以前的方法试图减少图像Tokens的数量，通常是通过基于注意力得分或图像Tokens多样性来选择 Tokens。通过对现有方法进行实证研究，我们发现它们往往忽略了剪枝对当前层输出（局部）和后续层输出（全局）的联合影响，导致了次优的剪枝决策。", "innovation": "我们提出了平衡Token剪枝（BTP），这是一种插件式平衡Token剪枝方法。该方法利用小型校准集将剪枝过程划分为多个阶段。在早期阶段，我们的方法强调剪枝对后续层的影响，而在更深层次的阶段，重点转移到保留局部输出的一致性上。通过在多种LVLMs上的广泛实验，该方法在多种基准测试中证明了其广泛效果。在平均性能损失仅为13.3%的情况下，我们的方法实现了高达78%的压缩率。", "conclusion": "我们的方法在多个基准测试中证明了其广泛效果，平均性能损失仅为13.3%，实现了高达78%的压缩率。代码可在 https://github.com/username/balanced-token-pruning 获取。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.22651", "html_url": "https://arxiv.org/abs/2505.22651", "title": "Sherlock: 自视语言模型中的自我纠正推理", "title_en": "Sherlock: Self-Correcting Reasoning in Vision-Language Models", "authors": "Yi Ding,Ruqi Zhang", "background": "视觉语言模型（VLMs）在复杂多模态任务上已显示出有希望的表现，但仍面临重大挑战：高度依赖推理过程中的准确性、需要大量带注释的数据或准确的验证器，以及难以跨域泛化。", "innovation": "该研究探索了自我纠正作为提升推理能力策略的可能性。提出了Sherlock框架，包括轨迹级自我纠正目标、基于视觉扰动的偏好数据构建方法以及动态β值的偏好调节。使用仅20000条随机选择的注释数据，模型能够自主获取自我纠正的能力，并在无需外部监督的情况下继续自我改进。Sherlock在多个基准测试中表现出色，平均准确率达到64.1%，并通过自我纠正后达到65.4%的高精度，优于LLaVA-CoT、Mulberry和LlamaV-o1等同类模型，同时使用了不到20%的标注数据。", "conclusion": "Sherlock通过自我纠正和自我改进框架显著提高了视语言模型的推理性能，表明此类方法具有克服现有挑战的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23155", "html_url": "https://arxiv.org/abs/2505.23155", "title": "PreFM: 通过预测未来建模的在线音视频事件解析", "title_en": "PreFM: Online Audio-Visual Event Parsing via Predictive Future Modeling", "authors": "Xiao Yu,Yan Fang,Xiaojie Jin,Yao Zhao,Yunchao Wei", "background": "音视频事件解析在理解多模态视频内容中起着至关重要的作用，但现有方法通常依赖于对整个视频的脱机处理并拥有巨大的模型规模，这限制了它们的实时应用。", "innovation": "提出了一种新的在线音视频事件解析（On-AVEP）范式，通过逐步分析传入的视频流来解析音频、视觉和音视频事件。为了培养这些能力，提出了具有以下特征的预测未来建模（PreFM）框架：（1）预测多模态未来建模以推断和整合有益的未来音视频线索，从而增强上下文理解；（2）通用模态稳健表示和重点时序优先级以提高精确度和泛化能力。通过在UnAV-100和LLP数据集上的广泛实验，PreFM显著优于最先进的方法，减少了许多参数，并提供了一个实时多模态视频理解的有见解的方法。", "conclusion": "PreFM显著提升了实时多模态视频理解的能力，通过预测未来建模框架提高了模型的子 аппроксимация和泛化能力，取得了比最先进的方法更好的表现。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20612", "html_url": "https://arxiv.org/abs/2505.20612", "title": "Roboflow100-VL：一项用于视觉语言模型的多域物体检测基准测试", "title_en": "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models", "authors": "Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri", "background": "视觉语言模型(VLMs)在互联网规模数据上训练后，在检测常见目标（如汽车、卡车和行人的零样本检测任务上表现出色。然而，这些最先进的模型依然难以适应未在预训练中遇到的新型类、任务和成像模式。论文作者认为，不应该只是简单地在视觉数据上重新训练VLMs，而是应该通过带有少量视觉示例和丰富文本描述的标注指令来对齐模型以适应新概念。为了实现这一目标，作者引入了Roboflow100-VL，这是一个包含100个多模式物体检测数据集的大规模集合，这些数据集中的概念在VLM的预训练中并不常见。论文还展示了最先进的模型在Roboflow100-VL基准上的评估结果，表明VLMs的零样本准确度较低。最后，讨论了作者近期在CVPR 2025 Foundational FSOD比赛中的一些发现，以及参赛者的成果，肯定了社区的经验分享。", "innovation": "作者提出了Roboflow100-VL，这是用来评估VLMs性能的多域物体检测基准测试数据集，内包含100个多模式数据集，其中涉及的概念通常不在VLMs预训练中出现。在此基础上，作者通过对比实验展示了VLMs在零样本、少量样本、半监督和全监督等不同数据范围下的性能，强调了VLMs需要通过少量示例进行概念对齐的重要性。并且指出了在具有挑战性的医学影像数据集上的性能结果低于2%，表现出改进潜力。此外，社区基础的FSOD竞赛结果展示了巨大的改进空间，即参赛团队表现远远超过原基础模型17个mAP的提升", "conclusion": "本文通过提出的Roboflow100-VL数据集，以及其他该领域模型的实验研究，展示了视觉语言模型在对新概念适应性方面存在的不足，并强调了需要通过少数示例进行概念对齐的重要性。同时，通过对最近竞赛的分析，验证了改进潜在的广阔前景。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23010", "html_url": "https://arxiv.org/abs/2505.23010", "title": "SeG-SR: 在视觉语言模型指导下将语义知识集成到遥感图像超分辨率中", "title_en": "SeG-SR: Integrating Semantic Knowledge into Remote Sensing Image Super-Resolution via Vision-Language Model", "authors": "Bowen Chen,Keyan Chen,Mohan Yang,Zhengxia Zou,Zhenwei Shi", "background": "高分辨率遥感图像在城市规划和环境监测等众多应用中发挥着重要作用，但由于传感器和数据传输链路的限制，实际获取的图像常出现分辨率退化。遥感图像超分辨率（RSISR）旨在使用低分辨率输入重建高分辨率图像，提供了一种直接获取高分辨率图像之外的高效替代方案。现有的RSISR方法主要关注像素空间中的低级特征，而忽视了遥感场景的高级理解，这可能导致重建结果中的语义不一致的伪影。", "innovation": "本文工作旨在探索高层次语义知识在提高RSISR性能中的作用，提出了一个基于视觉语言模型的语义引导超分辨率框架SeG-SR。具体包括设计一个基于预训练视觉语言模型的语义特征提取模块SFEM，从中提取遥感图像的语义知识；设计一个语义定位模块SLM，从提取的语义知识中获得一系列语义指导；以及开发一个可学习调制模块LMM，使用语义指导调制SR网络提取到的特征，有效将高层场景理解集成到SR管道中。", "conclusion": "通过广泛的实验验证了SeG-SR的有效性和泛化能力，它在三个数据集上的性能达到最新技术水平，并在各种SR架构上取得了提升。特别是在UCMerced数据集上的x4 SR任务中，PSNR达到29.3042 dB，SSIM达到0.7961。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11152", "html_url": "https://arxiv.org/abs/2505.11152", "title": "从不平衡数据学习密集手部接触估计", "title_en": "Learning Dense Hand Contact Estimation from Imbalanced Data", "authors": "Daniel Sungho Jung,Kyoung Mu Lee", "background": "手部在人类互动中至关重要，通过研究手与世界的接触可以促进对手功能的全面理解。近年来，有关手部交互的数据集数量有所增加，这些数据集涵盖了与物体、另一只手、场景和身体的交互。尽管手部交互任务的重要性以及高质量数据集的迅速增加，如何有效地学习密集的手部接触估计仍然很大程度上被忽视。主要挑战包括数据集中的类别不平衡问题和空间不平衡问题。类别不平衡问题意味着大部分区域没有接触，而空间不平衡问题意味着接触主要集中在手指尖上，这对预测其他手部区域的接触带来了挑战。", "innovation": "该研究提出了一种框架，可以学习来自不平衡数据的密集手部接触估计。为解决类别不平衡问题，引入了平衡接触采样，该方法构建和抽样多个能公平代表接触和非接触顶点不同接触统计数据的采样组。为解决空间不平衡问题，还提出了基于顶点的类别平衡（VCB）损失，这种损失将空间变化的接触分布纳入考量，基于顶点在整个数据集中的接触频率分别重新权重其损失贡献。这种方法使得在大规模手部接触数据中可以有效学习预测密集手部接触估计，同时避免类别和空间不平衡的问题。", "conclusion": "利用大量手部接触数据，通过平衡接触采样和顶点级别类别平衡（VCB）损失，有效解决了类别和空间不平衡问题，从而能够在没有面临类别和空间不平衡问题的情况下学习预测密集手部接触估计。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05341", "html_url": "https://arxiv.org/abs/2506.05341", "title": "基于空间推理的3D室内场景合成直接数值布局生成", "title_en": "Direct Numerical Layout Generation for 3D Indoor Scene Synthesis via Spatial Reasoning", "authors": "Xingjian Ran,Yixuan Li,Linning Xu,Mulin Yu,Bo Dai", "background": "现实主义的3D室内场景合成对于具身AI和数字内容创作至关重要。它可以自然地被分为两个子任务：对象生成和布局生成。尽管最近的生成模型在对象级别的质量与可控性上取得了显著进步，但布局生成仍然具有挑战性，原因在于可用数据集的局限性。现有方法要么过于依赖这些数据集，要么依赖预定义的约束来优化数值布局而牺牲灵活性。因此，它们无法生成符合细粒度用户指令的开放式词汇场景。", "innovation": "我们提出了DirectLayout，这是一种框架，通过使用大型语言模型（LLMs）的可泛化的空间推理直接从文本描述生成数值3D布局。DirectLayout将生成过程分解为三个阶段：生成鸟瞰图（BEV）布局、将其提升至三维空间，以及细化对象放置。为使模型明确进行空间推理并理解基本的放置原则，我们采用了基于3D-Front数据集的推理链激活（CoT Activation）。此外，我们设计了基于推理链的生成布局奖励（CoT-Grounded Generative Layout Reward）来增强泛化和空间规划能力。在推理过程中，DirectLayout通过上下文学习方式解决资产与布局之间的不匹配问题。", "conclusion": "广泛的实验表明，DirectLayout在语义一致性、泛化性和物理可解释性方面取得了显著成果。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05821", "html_url": "https://arxiv.org/abs/2506.05821", "title": "FuseUNet: U型网络的多尺度特征融合方法", "title_en": "FuseUNet: A Multi-Scale Feature Fusion Method for U-like Networks", "authors": "Quansong He,Xiangde Min,Kaishen Wang,Tao He", "background": "医学图像分割是计算机视觉中的关键任务，UNet作为标志性架构起到了重要作用。尽管UNet家族的典型组成部分是跳连接，但这些跳连接存在两个显著问题：（1）不同尺度之间的特征缺乏有效的交互；（2）依赖于简单的连接或相加操作，限制了高效的信息整合。尽管最近对于UNet的改进集中在增强编码器和解码器的能力上，但这些问题仍然被忽视了。", "innovation": "提出了一个新颖的多尺度特征融合方法，将UNet的解码过程重新构想为求解初始值问题（IVP），将跳连接视为离散节点，并利用线性多步法原理，提出了适应性常微分方程方法来实现有效的多尺度特征融合。该方法独立于编码器和解码器架构，具有高度的适应性，适用于各种UNet类似网络。实验结果表明，新的方法能提高特征利用效果，减少网络参数量，并保持高性能。", "conclusion": "实验在ACDC、KiTS2023、MSD脑肿瘤和ISIC2017/2018皮肤病变分割数据集上的结果证明了改进的特征利用效果，减少了网络参数，并保持了良好的性能。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02408", "html_url": "https://arxiv.org/abs/2506.02408", "title": "在计算机病理学中重新审视带有切片级监督的端到端学习", "title_en": "Revisiting End-to-End Learning with Slide-level Supervision in Computational Pathology", "authors": "Wenhao Tang,Rong Qin,Heng Fang,Fengtao Zhou,Hao Chen,Xiang Li,Ming-Ming Cheng", "background": "在计算机病理学(CPath)中，预训练编码器用于离线特征提取，随后通过多个实例学习(MIL)聚合器处理，已成为主导范式，有助于癌症的诊断和预后。然而，这种范式存在下游任务编码器细调不足和MIL训练分割的问题，影响了性能。虽然全切片级监督的端到端(E2E)学习是一种直观的解决方案，但实时计算需求高且可能结果欠佳。这些限制促使作者重新审视端到端学习。", "innovation": "本文提出了一种新的MIL方法ABMILX，通过全局相关性注意力精炼和多头机制缓解了稀疏注意力MIL带来的优化挑战问题。同时，利用高效的多尺度随机切片采样策略，ABMILX在多个具有挑战性的基准上超越了传统的两阶段方法，一种经过端到端训练的ResNet，实现了在保持高效计算的同时达到SOTA结果(<10 RTX3090小时)。", "conclusion": "本文揭示了E2E学习在CPath中的潜力，并强调了在该领域进行更多研究的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23883", "html_url": "https://arxiv.org/abs/2505.23883", "title": "BioCLIP 2: 通过分层对比学习放大涌现特性", "title_en": "BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning", "authors": "Jianyang Gu,Samuel Stevens,Elizabeth G Campolongo,Matthew J Thompson,Net Zhang,Jiaman Wu,Andrei Kopanev,Zheda Mai,Alexander E. White,James Balhoff,Wasila Dahdul,Daniel Rubenstein,Hilmar Lapp,Tanya Berger-Wolf,Wei-Lun Chao,Yu Su", "background": "大规模训练的基座模型表现出非凡的新兴行为，能够学到超出初始训练目标的新能力。我们通过大规模对比视觉-语言训练在生物视觉模型中发现了这种新兴行为。为了实现这一目标，我们首先创建了一个包含2.14亿张生物体图像的TreeOfLife-200M数据集，这是迄今为止最大和最多样化的生物体图像数据集。然后，在TreeOfLife-200M上训练了BioCLIP 2，用于区分不同物种。尽管训练目标较窄，但BioCLIP 2在各种生物视觉任务中（如栖息地分类和特征预测）展现出非凡的准确度。识别了BioCLIP 2学习嵌入空间中的新兴特性。在物种间层次上，不同物种的嵌入分布与功能和生态意义紧密对应（例如喙的大小和栖息地）。在物种内层次上，物种间的变异（如生活阶段和性别）不仅未被减弱，反而在与物种间区分正交的子空间中得到了更好的区分。为解释这些新兴特性，我们提供了形式上的证明和分析，指出层次监督和对比目标鼓励了这些特性的发展。关键在于，我们的结果表明，随着训练数据量的增大，这些特性变得越来越重要，从而导致了一个生物学上有意义的嵌入空间。", "innovation": "我们创建了TreeOfLife-200M数据集，这是迄今为止最大的生物体图像数据集，通过大规模对比视觉-语言训练生物视觉模型BioCLIP 2，使其在物种间和物种内层次展现出生物学上有意义的嵌入特性。通过对比学习和层次监督，我们揭示了生物视觉模型中新兴的生物学特性，并提供了解释这些特性的形式证明和分析。这一研究展示了更大规模训练数据的重要性，有助于生成有意义的嵌入特性。", "conclusion": "通过分层对比学习放大，我们不仅提升生物视觉模型的性能，还揭示了它们在大规模训练中的新兴生物学特性。These findings suggest that large-scale training not only enhances model performance but also uncovers biologically meaningful embedding spaces, which could be further applied to various biological studies."}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12006", "html_url": "https://arxiv.org/abs/2507.12006", "title": "基于频域动态注意力调节的密集预测", "title_en": "Frequency-Dynamic Attention Modulation for Dense Prediction", "authors": "Linwei Chen,Lin Gu,Ying Fu", "background": "视觉变换器(ViTs)在计算机视觉领域取得了显著进展，但在各类任务中表现出色的同时，其注意力机制导致每一层都相当于一个低通滤波器，现有Transformer的堆叠层架构则进一步导致了频率消失问题，从而导致关键细节和纹理的丢失。", "innovation": "提出了一种电路理论启发的策略——频域动态注意力调节(FDAM)，可以方便地插入到ViTs中。FDAM直接调节ViTs的整体频率响应，包含两种技术：注意力反转(AttInv)和频率动态标度(FreqScale)。AttInv通过反转注意力矩阵中的低通滤波器生成互补的高通滤波，FreqScale则通过对不同频率分量的加权来自适应调整目标响应函数。实验证明该方法避免了特征表示的崩溃，在SegFormer、DeiT和MaskDINO等模型上实现了性能的提升，在语义分割、物体检测和实例分割等任务上效果显著。", "conclusion": "该方法还在遥感检测中达到了SOTA效果，证明了该方法的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.05427", "html_url": "https://arxiv.org/abs/2507.05427", "title": "OpenWorldSAM：扩展SAM2以实现基于语言提示的通用图像分割", "title_en": "OpenWorldSAM: Extending SAM2 for Universal Image Segmentation with Language Prompts", "authors": "Shiting Xiao,Rishabh Kabra,Yuhang Li,Donghyun Lee,Joao Carreira,Priyadarshini Panda", "background": "基于开放语言提示进行物体分割的能力仍然是一项关键挑战，要求模型能够将文本语义转化为精确的空间掩码，并处理多种未见过的类别。目前存在的问题是，模型需要在多样化的语言描述面前提供有效的物体分割结果，同时保持高效性、可实例化的意识和泛化能力。在现有的技术基础上，有必要开发一种能够在开放词汇场景中执行这类任务的框架。", "innovation": "本文提出了OpenWorldSAM，一种将prompt-driven的Segment Anything Model v2 (SAM2) 扩展到开放词汇场景的框架，通过集成来自轻量级视觉-语言模型（VLM）的多模态嵌入。OpenWorldSAM具有四大创新点：1）统一的提示策略，支持不同级别的语言描述；2）高效的训练方式，仅训练4.5百万参数；3）增强的实例感知能力，通过新的位置强制选择嵌入和跨注意力层；4）强大的零样本能力，能够处理未见过的类别和概念，无需额外训练。这些创新使得OpenWorldSAM在多个基准测试中达到了最先进的性能。", "conclusion": "OpenWorldSAM展示了在开放词汇场景下进行语义分割、实例分割和全景分割的出色性能。通过对不同模态的嵌入集成，框架不仅提高了模型的灵活性，还显著增强了其资源效率和泛化能力，为实现基于语言提示的多类别图像分割奠定了坚实的基础。感兴趣的研究人员可以在提供的代码链接中获取OpenWorldSAM的实现细节。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.00371", "html_url": "https://arxiv.org/abs/2507.00371", "title": "PlantSegNeRF：利用多视角图像实例匹配的联合通道NeRF进行物种间植物3D实例点云重建的少样本方法", "title_en": "PlantSegNeRF: A few-shot, cross-species method for plant 3D instance point cloud reconstruction via joint-channel NeRF with multi-view image instance matching", "authors": "Xin Yang(1 and 2),Ruiming Du(3),Hanyang Huang(1 and 2),Jiayang Xie(1 and 2),Pengyao Xie(1 and 2),Leisen Fang(1 and 2),Ziyue Guo(1 and 2),Nanjun Jiang(4),Yu Jiang(5),Haiyan Cen(1 and 2) ((1) College of Biosystems Engineering and Food Science, Zhejiang University, (2) Key Laboratory of Spectroscopy Sensing, Ministry of Agriculture and Rural Affairs, (3) Department of Biological and Environmental Engineering, Cornell University, (4) Amway (China) Botanical R and D Center, (5) Horticulture Section, School of Integrative Plant Science, Cornell AgriTech)", "background": "植物器官点云分割是高分辨率和准确提取器官级别表型特征的前提条件，虽然深度学习的快速发展促进了对植物点云分割的研究，但现有技术在分辨率、分割精度和不同植物物种的普适性方面仍存在局限。", "innovation": "提出了PlantSegNeRF，一种将多视角RGB图像序列直接生成高精度实例点云的新型方法，适用于广泛植物物种。方法通过2D实例分割生成每个器官的实例掩码，并利用专门设计的实例匹配模块进行匹配和改进。同时开发了实例NeRF以渲染包含颜色、密度、语义和实例信息的隐式场景，并最终基于体密度转换为高精度植物实例点云。", "conclusion": "在有监督分割点云中，PlantSegNeRF超过了常用方法，相比第二好的结果平均提升了16.1%、18.3%、17.8%和24.2%的精度、召回率、F1分数和IoU。尤其是在植物点云实例分割任务中，PlantSegNeRF取得了显著优势，在所有植物物种中分别平均提高了11.7%、38.2%、32.2%和25.3%的mPrec、mRec、mCov、mWCov，拓展了器官级别植物表型研究并提供了生成植物大型模型所需高质量3D数据的高效途径。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.09122", "html_url": "https://arxiv.org/abs/2507.09122", "title": "SnapMoGen: 从表达性文本生成人体动作", "title_en": "SnapMoGen: Human Motion Generation from Expressive Texts", "authors": "Chuan Guo,Inwoo Hwang,Jian Wang,Bing Zhou", "background": "近年来，文本到动作生成取得了显著进展。然而，现有的方法主要局限于从短文本或通用文本提示中合成动作，这主要是由于数据集的限制。这些限制使得细粒度的控制力和对未见提示的泛化能力受到限制。解决这些问题对于提升生成质量至关重要。因此，本文引入了SnapMoGen，一个高质素动作捕捉数据集，该数据集将高品质动作捕捉数据与准确、生动的文本注释相配对。该数据集包含44小时的2万段动作片段，并附带12万详细的文本描述，描述平均48个词（相比之下，HumanML3D只有12个词）。这些动作片段保持了原始的时序连续性，便于进行长期动作生成和混合的研究。", "innovation": "本文的主要创新点在于：1) 引入了SnapMoGen数据集，具有高质量的动作捕捉数据和详细的文本描述。2) 改进了先前的生成式掩码建模方法，提出MoMask++模型，能够将动作转换为多尺度的令牌序列，更好地利用令牌容量，并利用单一生成式掩码变压器生成所有令牌。3) MoMask++在HumanML3D和SnapMoGen基准测试中达到最先进的性能。4) 通过使用LLM重新格式化输入，使模型能够处理更自然的用户提示。", "conclusion": "本文提出的方法和数据集对长期动作生成和混合的研究具有重要意义，同时也提高了从文本生成人体动作的质量和多样性。SnapMoGen和MoMask++的提出为未来的工作提供了新视角和可能性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02329", "html_url": "https://arxiv.org/abs/2508.02329", "title": "通过指令编辑数据和长描述增强CLIP的细粒度视觉理解 - VITRIX-CLIPIN", "title_en": "VITRIX-CLIPIN: Enhancing Fine-Grained Visual Understanding in CLIP via Instruction Editing Data and Long Captions", "authors": "Ziteng Wang,Siqi Yang,Limeng Qiao,Lin Ma", "background": "虽然视觉语言模型（VLMs）如CLIP在视觉和语言对齐方面取得了成功，但在细节和细粒度的视觉理解上仍然存在挑战。CLIP-IN提出了一个新的框架，通过两个核心创新来增强CLIP的细粒度感知。", "innovation": "CLIP-IN引入了两种创新：1）使用指令编辑数据集（最初用于图像编辑）作为硬负样本的来源，并结合对称的硬负样本对比损失，以有效区分细微的视觉-语义差异；2）引入长描述性图像描述，并使用旋转位置编码来捕捉通常被标准CLIP忽视的丰富语义上下文。这些方法使得CLIP-IN在细粒度视觉识别任务上取得了显著的改进，同时保持了在广泛分类和检索任务上的鲁棒零样本性能。通过结合CLIP-IN的视觉表示到多模态大语言模型，显著减少了视觉幻觉并提升了推理能力。", "conclusion": "CLIP-IN的工作强调了针对性指令对比学习与全面描述信息相结合的巨大潜力，以提高VLMs的细粒度理解。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08974", "html_url": "https://arxiv.org/abs/2508.08974", "title": "基于文本条件的状态空间模型在通用领域变化检测视觉问答中的应用", "title_en": "Text-conditioned State Space Model For Domain-generalized Change Detection Visual Question Answering", "authors": "Elman Ghazaei,Erchan Aptoula", "background": "地球表面不断变化，变化检测为人类社会提供了宝贵的见解。传统的变化检测方法使用双时相影像进行变化检测，但这些方法通常需要专家知识才能准确解释。为了使非专家用户能够更广泛和灵活地访问变化信息，变化检测视觉问答（CDVQA）任务被提出。然而，现有的CDVQA方法在训练和测试数据集具有相似分布的假设下进行开发，这在实际应用中通常是不成立的，因为域偏移经常会发生。因此，本研究重新审视CDVQA任务，重点关注解决域偏移问题。", "innovation": "本研究引入了新的多模态和多域数据集BrightVQA，用于促进CDVQA中的领域泛化研究。同时，提出了一种新的状态空间模型，称为文本条件状态空间模型（TCSSM），该模型旨在以统一的方式利用双时相影像和地质灾害相关的文本信息来提取跨域不变特征。输入依赖参数通过使用双时相图像和地质灾害相关的描述动态预测，在TCSSM中动态预测，从而促进双时相视觉数据和相关文本描述之间的对齐。实验结果表明，该方法性能优越。", "conclusion": "本研究通过提出新的方法和数据集，成功解决了CDVQA在实际应用中面临的领域偏移问题，并通过广泛的实验验证了所提方法的优越性能。研究结果被一致证明优于现有方法。该方法的代码和数据集将在接受后公开。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.15235", "html_url": "https://arxiv.org/abs/2509.15235", "title": "ViSpec: 使用视觉感知投机解码加速视觉语言模型", "title_en": "ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding", "authors": "Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen", "background": "投机解码是一种广泛采用的技术，用于加速大型语言模型（LLMs）的推理，但在视觉语言模型（VLMs）中的应用仍然相对较少，现有方法仅能实现有限的加速（不到1.5倍）。随着多模态能力在大模型中变得越来越重要，这一差距变得越来越显著。我们推断，大型VLMs可以在逐层过滤冗余图像信息的同时，不损害文本理解能力，而较小的草案模型却难以做到这一点。", "innovation": "我们提出了一个专为VLMs设计的新型框架——视觉感知投机解码（ViSpec）。ViSpec通过引入一个轻量级的视觉适配模块来压缩图像令牌，将其无缝集成到草案模型的注意机制中，同时保留原始图像的位置信息。此外，我们还为每个输入图像提取一个全局特征向量，并将其添加到后续的所有文本令牌中，以增强跨模态的连贯性。我们还通过重用现有数据集并对目标VLM进行修改提示生成扩展输出，创建了一个专门的训练数据集，以克服多模态数据集中长期助手响应稀缺的问题。为了防止仅使用目标模型输出进行训练时，草案模型利用直接访问目标模型的隐藏状态的风险，我们的训练策略进行了干预。", "conclusion": "我们的实验验证了ViSpec，据我们所知，这是在VLM投机解码中的第一个显著加速。代码可在以下链接获取：this https URL"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20890", "html_url": "https://arxiv.org/abs/2509.20890", "title": "FerretNet：通过局部像素依赖实现高效合成图像检测", "title_en": "FerretNet: Efficient Synthetic Image Detection via Local Pixel Dependencies", "authors": "Shuqiao Liang,Jian Liu,Renzhang Chen,Quanlong Guan", "background": "合成图像随着基于VAEs、GANs和LDMs等先进模型生成的图像越来越逼真，这给合成图像检测带来了重大挑战。针对这一问题，本文探讨了生成过程中引入的两种异常类型：（1）潜在分布偏差和（2）解码引起的平滑效应，这些异常体现在局部纹理、边缘和颜色过渡的一致性上。利用马尔可夫随机场（MRF）根植于局部像素依赖（LPD）的属性，通过利用相邻像素信息重构合成图像，揭示了纹理连续性和边缘一致性中断的现象。", "innovation": "提出了一种仅包含1.1M参数的轻量级神经网络FerretNet，利用局部像素依赖（LPD）特性实现高效且稳健的合成图像检测。FerretNet仅在4类ProGAN数据集上训练，在开放世界的基准测试中，由22个生成模型组成的数据集中，平均准确率达到97.1%。", "conclusion": "广泛实验证明，FerretNet在开放世界的基准测试数据集上具有高效的合成图像检测性能，并且模型结构简洁，参数量少，具有很好的应用潜力。代码和数据集已在在线公开发布。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.22414", "html_url": "https://arxiv.org/abs/2509.22414", "title": "LucidFlux：大规模扩散变压器实现无图描述的通用图像恢复", "title_en": "LucidFlux: Caption-Free Universal Image Restoration via a Large-Scale Diffusion Transformer", "authors": "Song Fei,Tian Ye,Lujia Wang,Lei Zhu", "background": "通用图像恢复(Uniform Image Restoration, UIR)的目标是在未知混合物下恢复图像，同时保留语义。现有的判断性恢复模型和基于UNet的扩散先验在恢复过程中经常会导致过度平滑、幻觉或偏离目标，尤其是在复杂场景和细节保留方面表现不佳。", "innovation": "本文提出了LucidFlux，一个无需图像描述的UIR框架，通过一个不大但高效的双分支条件调节器注入受损输入和轻量级恢复代理的信号来锚定几何并抑制伪影。该方法还设计了时间步长和层级自适应调制计划，以便在整个骨干结构中路由这些线索，从而产生从粗到细、语境意识的更新，保护整体结构并恢复纹理。此外，通过SigLIP特征强制实现无需文字描述的语义对齐，进一步保证了恢复的准确性。", "conclusion": "在合成和真实世界基准上的广泛实验表明，LucidFlux在开放源代码和商业基线中表现优异，开挖实验进一步证明了各组成部分的必要性。LucidFlux展示了，对于大型DiTs，何时、何地以及如何调节，而非增加参数或依赖文字描述，是实现稳健且无图描述的通用图像恢复的关键杠杆。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.21401", "html_url": "https://arxiv.org/abs/2509.21401", "title": "JaiLIP: 通过损失导向的图像扰动劫持视觉-语言模型", "title_en": "JaiLIP: Jailbreaking Vision-Language Models via Loss Guided Image Perturbation", "authors": "Md Jueal Mia,M. Hadi Amini", "background": "视觉-语言模型（VLMs）在生成多模态推理任务方面具有卓越的能力，但随着不同的攻击向量，VLMs 的潜在滥用或安全性对齐问题显著增加。研究表明，基于图像的扰动特别有效，能够在生成有害输出方面产生显著效果。尽管提出了许多技术来劫持 VLMs，但这些技术会导致模型的不稳定性和明显可见的扰动。因此，研究提出了一种新的方法，即带有损失导向的图像扰动（Jailbreaking with Loss-guided Image Perturbation, JaiLIP），该方法能够最小化干净图像和对抗图像之间的均方误差（MSE）损失以及模型的有害输出损失，从而提出了一种新的安全威胁。", "innovation": "通过 JaiLIP，研究提出了一种新的实现 VLMs 劫持的方法，该方法利用损失导向的策略优化以最小化干净图像与对抗图像间均方误差，并降低模型的有害输出倾向。实验结果表明，JaiLIP 生成的对抗图像效果显著且几乎不可察觉，同时在对抗有毒文本生成之外，还对交通运输领域进行了评估，展示了该方法的实用性。", "conclusion": "JaiLIP 强调了基于图像的劫持攻击的实际挑战，并指出了需要高效防护机制来保护 VLMs。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24739", "html_url": "https://arxiv.org/abs/2509.24739", "title": "用于医学数据的视觉语言基础模型：面向越南PET/CT报告生成的多模态数据集和基准", "title_en": "Toward a Vision-Language Foundation Model for Medical Data: Multimodal Dataset and Benchmarks for Vietnamese PET/CT Report Generation", "authors": "Huu Tien Nguyen,Dac Thai Nguyen, TheMinh Duc Nguyen,Trung Thanh Nguyen,Thao Nguyen Truong,Huy Hieu Pham,Johan Barthelemy,Minh Quan Tran,Thanh Tam Nguyen,Quoc Viet Hung Nguyen,Quynh Anh Chau,Hong Son Mai,Thanh Trung Nguyen,Phi Le Nguyen", "background": "视觉语言基础模型（VLMs）在大规模多模态数据集上训练，显著推动了人工智能领域的进展，尤其是在跨模态推理方面。然而，尽管这些模型在通用领域取得了成功，但在应用于医学成像时仍面临挑战，主要是由于缺乏多样化的成像模态和多语种临床数据。现有的大多数医学VLMs仅针对有限的成像模态进行训练，并主要关注高资源语言，从而限制了其泛化能力和临床用途。", "innovation": "该研究引入了一个新型越南语多模态医学数据集，包含2,757个全身PET/CT体积和相应的完整临床报告。此外，还提出了一种训练框架，包括数据增强和专家验证的测试集，以提高VLMs的学习效果。实验结果显示，结合该数据集显著提高了现有VLMs的性能。这是首次提供全面的越南PET/CT报告对的数据集。该数据集和基准将为开发更强大的适用于医学影像的VLMs，特别是低资源语言和越南医疗临床使用，发挥关键作用。", "conclusion": "该数据集和基准将作为推动开发更可靠的VLMs的重要步骤，特别是在医学影像和越南医疗临床使用方面具有重要意义。相关的源代码可以在提供的链接中访问。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.10203", "html_url": "https://arxiv.org/abs/2510.10203", "title": "基于样式特征的合成数据到真实数据差距量化框架", "title_en": "A Style-Based Profiling Framework for Quantifying the Synthetic-to-Real Gap in Autonomous Driving Datasets", "authors": "Dingyi Yao,Xinyao Han,Ruibo Ming,Zhihang Song,Lihui Peng,Jianming Hu,Danya Yao,Yi Zhang", "background": "确保自动驾驶感知系统的可靠性需要基于环境的广泛测试，但在实际应用中往往不可行。因此，合成数据集成为了有前景的替代方案，提供成本效益、无偏标注和可控场景等优势。然而，合成数据集与真实数据集之间的领域差距仍然是模型泛化的主要障碍。为了从数据角度解决这一挑战，本文提出了一种样式特征提取与发现框架，用于表征合成和真实图像数据集背后的不同样式特征。", "innovation": "本文提出了基于样式嵌入分布差异（SEDD）的新评价指标，结合了基于格拉姆矩阵的样式提取和用于为类内紧凑性和类间分离优化的元学习方法。在此基础上建立了基准。实验结果显示，该方法能够量化合成数据到真实数据的差距。该工作为合成数据集提供了一种标准化的特征表征质量控制范式，可以系统地诊断和针对性地提升合成数据集，促进了未来基于数据驱动的自动驾驶系统的开发。", "conclusion": "本研究提供了样式特征表征的质量控制范式，通过标准化的特征分析，实现了合成数据集到真实数据集差距的量化评估，促进了未来数据驱动的自动驾驶系统的进步。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.26087", "html_url": "https://arxiv.org/abs/2509.26087", "title": "EasyOcc: 3D Pseudo-Label Supervision for Fully Self-Supervised Semantic Occupancy Prediction Models", "title_en": "EasyOcc: 3D Pseudo-Label Supervision for Fully Self-Supervised Semantic Occupancy Prediction Models", "authors": "Seamie Hayes,Ganesh Sistu,Ciarán Eising", "background": "自监督模型在语义占用预测领域取得了显著进展，它们通过复杂的损失计算策略来弥补缺乏真实标签的问题。例如，新颖视图合成、跨视图渲染和深度估计等技术被用于解决语义和深度的模糊性问题。然而，这些技术在训练阶段通常会造成高昂的计算成本和内存使用率，尤其是对于新颖视图合成。", "innovation": "本文提出了通过基础模型Grounded-SAM和Metric3Dv2生成的3D伪地面实况标签，并利用时间信息进行标签密集化的方法。这些3D伪标签可以轻松集成到现有模型中，显著提高了性能，mIoU提高了45%。此外，还提出了一种简化模型EasyOcc，通过仅使用本文提供的标签学习，没有采用复杂的渲染策略，达到了13.86 mIoU。最后，该方法使得模型在不使用相机遮罩的情况下评估整个场景时，达到了最先进的性能，EasyOcc的mIoU为7.71，比之前最佳模型高出31%。这些发现突显了基础模型、时间上下文和损失计算空间选择在自监督学习中对全面场景理解和建模的重要性。", "conclusion": "本文提出的方法不仅提高了语义占用预测的自监督模型性能，还简化了模型架构，无需复杂的渲染策略即可实现卓越的性能。此外，基础模型和时间信息的应用为该领域开辟了新的思路。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.25033", "html_url": "https://arxiv.org/abs/2509.25033", "title": "VT-FSL: 使用LLMs弥合视觉与文本鸿沟的少样本学习", "title_en": "VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning", "authors": "Wenhao Li,Qiangchang Wang,Xianjing Meng,Zhibin Wu,Yilong Yin", "background": "少样本学习（FSL）旨在通过少量标记的支持样本识别新型概念。现有研究通过引入额外的语义信息或设计复杂的语义融合模块来增强支持特征，但仍旧存在由于缺乏实例 grounding 导致语义与视觉证据相悖的问题，从而产生误导性的指导和高成本的纠正。为了应对这些问题，本文提出了一个新的框架，名为视觉与文本结合大语言模型的少样本学习（VT-FSL），通过结合大语言模型和支持图像构建精确的跨模态提示，并通过几何感知对齐无缝融合它们。VT-FSL框架包括跨模态迭代提示（CIP）和跨模态几何对齐（CGA）两个主要组成部分，以提升少样本学习的表现。", "innovation": "该框架通过结合大语言模型（LLMs）构建精确的跨模态提示，并通过几何感知对齐融合支持信息，不仅增强了新型类别的语义理解，还支持零样本生成语义一致的图像。具体地，CIP 使大语言模型在类别名称和支持图像的基础上生成精确的类别描述。此外，CGA 通过最小化所环绕的空间平行多面体的核体积，共同对齐融合后的文本、支持和合成的视觉表示，捕获所有表示之间的全局和非线性关系，确保结构化的多模态集成。实验结果表明，该方法在十个不同的标准、跨域及细粒度少样本学习基准上超越了现有最佳表现。", "conclusion": "本文提出的方法 VT-FSL 集成了基于大语言模型的跨模态提示构建和几何感知对齐机制，有效弥合了视觉与文本的鸿沟，解决了现有方法中存在的语义与视觉证据相悖问题。VT-FSL 在多个少样本学习场景中取得了最新的最佳性能，为少样本学习的应用场景提供了新的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02253", "html_url": "https://arxiv.org/abs/2510.02253", "title": "DragFlow：借助区域监督释放DiT先验的拖拽编辑", "title_en": "DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing", "authors": "Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong", "background": "拖拽式图像编辑长期以来存在目标区域失真的问题，主要原因在于早期基础模型Stable Diffusion的先验知识不足以将优化后的潜在变量映射回自然图像流形。随着从基于UNet的DDPM转换为更可扩展的DiT（如SD3.5、FLUX）并辅以流匹配技术，生成先验变得更强，但在拖拽式编辑中这些更强的先验仍未得到充分利用。论文提出了一种新颖的方法DragFlow，通过引入基于区域的编辑范式，有效地利用FLUX丰富的先验知识。DragFlow使用仿射变换提供更丰富和一致的特征监督，并整合了预训练的开放式领域个性化适配器（如IP-Adapter）来增强主题一致性，同时通过基于梯度掩模的硬约束保留背景保真度。进一步利用多模态大型语言模型（MLLMs）解决编辑任务的歧义性。", "innovation": "DragFlow提出了一种有效的框架，首次利用FLUX的丰富先验知识进行拖拽编辑，通过引入基于区域的编辑范式，使用仿射变换提供更丰富的特征监督，并整合了预训练的开放领域个性化适配器以及基于梯度掩模的硬约束。此方法在DragBench-DR和新构建的ReD Bench基准上展示了相对于点编辑和区域编辑基线的显著改进，设置了新的拖拽式图像编辑的最高水平。", "conclusion": "拖拽Flow超越了点编辑和区域编辑的基线方法，在拖拽式图像编辑上设立了新的最高标准。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.10750", "html_url": "https://arxiv.org/abs/2510.10750", "title": "通过视觉异常检测发现海洋环境监控中的异常事件", "title_en": "Uncovering Anomalous Events for Marine Environmental Monitoring via Visual Anomaly Detection", "authors": "Laura Weihl,Stefan H. Bengtson,Nejc Novak,Malte Pedersen", "background": "水下视频监控是一种评估海洋生物多样性的有前景策略，但由于大量无意义的视频使得手动检查变得非常不实际。目前，针对水下视频异常检测（VAD）的基准数据集尚未出现，同时缺乏评估不同模型的有效方法。为了填补这一空白，研究团队引入了AURA，这是首个由多标注者提供的水下VAD基准数据集，旨在评估不同的VAD模型在两种海洋场景下的表现。研究表明，在当前模型中，异常检测性能随训练数据量的增加和“正常”场景视觉内容的变化而显著波动。通过这一过程，研究发现了软标签和共识标签的价值，为科学探索和可扩展的生物多样性监测提供了实用的方法。", "innovation": "研究引入了AURA，这是第一个由多标注者提供的水下视频异常检测基准数据集。研究还提出了一些稳健的帧选择策略，以提取有意义的视频片段。研究的结果显示，当前模型的异常检测性能在多个标注者的比较中差异显著，并且高度依赖训练数据量以及定义“正常”场景的视觉内容的多样性。研究还强调了使用软标签和共识标签的价值，并提出了支持科学探索和可扩展生物多样性监控的实用方法。", "conclusion": "研究结果突显了在水下VAD中稳健帧选择策略的重要性，表明当前模型的性能对训练数据量和“正常”场景的视觉内容变化极其敏感。研究还发现，采用软标签和共识标签的方法对于提高模型性能和改善海洋生物多样性监测具有潜在价值。这些方法为促进科学研究和实现可扩展的生物多样性监测提供了实用途径。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.10779", "html_url": "https://arxiv.org/abs/2510.10779", "title": "从3D CT扫描中进行多标签异常分析的结构谱图表示学习", "title_en": "Structured Spectral Graph Representation Learning for Multi-label Abnormality Analysis from 3D CT Scans", "authors": "Theo Di Piazza,Carole Lazarus,Olivier Nempont,Loic Boussel", "background": "随着CT检查的数量日益增加，自动化工具的需求也在增长，这些工具包括器官分割、异常检测和报告生成，这些工具旨在辅助放射科医生处理日益繁重的工作量。对于3D胸部CT扫描的多标签分类，由于数据的时空复杂性以及异常的广泛变异性，依然是一个关键但具有挑战性的问题。现有的基于3D卷积神经网络的方法难以捕捉长距离依赖关系，而视觉变换器通常需要在大规模、特定领域的数据集上进行大量预训练才能表现出色。", "innovation": "本文提出了一种2.5D的解决方案，通过引入一种基于图的新框架来表示3D CT体积，将轴向切片三重组合为节点，通过谱图卷积进行处理，这样模型能够在保持与临床部署兼容的复杂性的同时，进行跨层依赖推理。该方法在三个来自不同机构的数据集上进行了培训和评估，展示了良好的跨数据集泛化能力和与最先进的视觉编码器相当的表现。此外还进行了详尽的消融研究，评估了不同的聚合策略、边权重方案和图形连接模式等多种方法的影响。通过迁移实验进一步展示该方法在自动放射学报告生成和腹部CT数据上的广泛适用性。", "conclusion": "本文提出的方法在多项测试上展示了较强的适用性和良好的泛化能力，是一种有效的解决多标签异常分析的方法，并为未来的3D医学影像分析技术提供了新的研究思路和方向。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.11520", "html_url": "https://arxiv.org/abs/2510.11520", "title": "mmWalk: 向多模态多视角步行辅助迈进", "title_en": "mmWalk: Towards Multi-modal Multi-view Walking Assistance", "authors": "Kedi Ying,Ruiping Liu,Chongyan Chen,Mingzhe Tao,Hao Shi,Kailun Yang,Jiaming Zhang,Rainer Stiefelhagen", "background": "对于视力受损或低视力（BLV）的人来说，在极端或复杂环境中行走是一个巨大的挑战，主要原因是缺乏对整体场景的理解。我们基于BLV社区的实际需求构建了mmWalk，这是一个模拟的多模态数据集，集成了多视角传感器和无障碍导向特征，旨在实现户外安全导航。该数据集包括120条手动控制的、按场景分类的行走轨迹，包含62,000帧同步图像，其中包含超过559,000张全景图，跨越RGB、深度和语义模态。此外，每条轨迹都涉及户外边缘案例和BLV用户特有的无障碍地标，以强调其现实相关性。", "innovation": "我们构建了mmWalk，一个模拟的多模态数据集，为BLV用户提供户外安全导航功能，包含大量多视角传感器数据和无障碍导向特征。此外，为了强调其实用性，每个轨迹中都包含户外的真实场景案例和BLV用户特有的无障碍标识。我们还创建了mmWalkVQA，一个视觉问答基准，包括69,000个跨9类视觉问题-答案三元组，专门为安全和有信息的行走辅助服务。评估结果显示，最先进的视觉-语言模型在我们的风险评估和导航任务中表现不佳。", "conclusion": "我们对mmWalk微调的模型进行了现实世界数据集上的验证，并展示了该数据集在促进多模态步行辅助方面的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.13307", "html_url": "https://arxiv.org/abs/2510.13307", "title": "点云分割中的新型类别发现：通过因果表示与推理的联合学习", "title_en": "Novel Class Discovery for Point Cloud Segmentation via Joint Learning of Causal Representation and Reasoning", "authors": "Yang Li,Aming Wu,Zihao Zhang,Yahong Han", "background": "本文聚焦于仅使用已标记（基类）3D类别进行监督以对未标记（新型）3D类别进行分割的点云分割新类别发现（3D-NCD）任务。关键在于设置点表示与其基类标签以及基类和新型类之间点表示的相关性。粗略或统计学习这些相关性可能导致新型类推断出现混淆。通过建立因果关系作为强相关约束条件，可以揭示准确对应类别的本质点云表示。", "innovation": "本文引入结构因果模型（SCM）重新定义3D-NCD问题，并提出一种新方法——因果表示与推理的联合学习。首先通过SCM分析基类表示中的隐藏混杂因素及基类与新型类之间的因果关系，设计一个消除混杂因素的因果表示原型来捕捉基类的因果表示。然后使用图结构来建模基类因果表示原型与新型类原型之间的因果关系，从而能够从基类推理到新型类。", "conclusion": "在3D和2D NCD语义分割上的广泛实验和可视化结果表明，本文方法对于新型类发现具有优越性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14349", "html_url": "https://arxiv.org/abs/2510.14349", "title": "Vision-Centric Activation and Coordination for Multimodal Large Language Models", "title_en": "Vision-Centric Activation and Coordination for Multimodal Large Language Models", "authors": "Yunnan Wang,Fan Lu,Kecheng Zheng,Ziyuan Huang,Ziqiang Li,Wenjun Zeng,Xin Jin", "background": "当前的多模态大型语言模型（MLLMs）将视觉编码器的图像特征与大型语言模型结合，展现出先进的理解能力。然而，主流的MLLMs主要通过下一个标记预测文本令牌进行监督，忽视了对于分析能力至关重要的视觉中心信息。为解决这一问题，我们提出VaCo，通过视觉中心激活和多方视觉基础模型的协调来优化MLLMs的表现，使其在计算过程中的文本和视觉输出更为统一，从而显著提高其在各种基准测试上的表现。", "innovation": "VaCo通过引入视觉辨别对齐和模块化任务查询（MTQs）以及视觉对齐层（VALs），激活特定的视觉信号，在多种视觉基础模型（VFMs）的监督下，整合任务特定的感知特征，从而协调来自不同VFMs之间的表示冲突。", "conclusion": "广泛的实验表明，VaCo在各种基准测试中显著提升了不同MLLMs的表现，其在视觉理解方面的优越能力得到了验证。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.15398", "html_url": "https://arxiv.org/abs/2510.15398", "title": "MARIS：具有几何增强和语义对齐的海洋开放词汇实例分割", "title_en": "MARIS: Marine Open-Vocabulary Instance Segmentation with Geometric Enhancement and Semantic Alignment", "authors": "Bingyu Li,Feiyu Wang,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li", "background": "大多数现有的水下实例分割方法受到近似词汇预测的限制，这限制了它们识别新兴海洋类别的能力。虽然开放词汇分割在自然图像上表现出潜力，但对水下场景的转移却遭受了严重的视觉退化（如颜色减弱）和由于缺乏水下类定义而导致的语义错位。", "innovation": "引入了MARIS，这是一个包含有限的已见类别和多种未见类别的大规模细粒度水下开放词汇分割基准。提出了一种统一框架，包括几何先验增强模块和语义对齐注入机制，分别利用稳定的部分级和结构性提示来保持物体一致性，以及丰富语言嵌入以减轻语义模糊并改善对未见类别的识别。", "conclusion": "实验表明，我们的框架在MARIS上的表现一致优于现有的开放词汇基准，无论是域内还是跨域设置，从而为未来的水下感知研究奠定了坚实的基础。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14255", "html_url": "https://arxiv.org/abs/2510.14255", "title": "基于奖励引导优化的身份保留图像到视频生成", "title_en": "Identity-Preserving Image-to-Video Generation via Reward-Guided Optimization", "authors": "Liao Shen,Wentao Jiang,Yiran Zhu,Jiahe Li,Tiezheng Ge,Zhiguo Cao,Bo Zheng", "background": "图像到视频（I2V）生成在合成高质量、时间上一致的视频方面取得了显著进展，特别是在人像视频生成方面占据了很大比例的应用。然而，现有的I2V模型在保持输入人像图像和生成视频之间的身份一致性方面遇到了困难，尤其是在视频中人物的表情变化和动作显著时。当人脸在图像中仅占很小一部分时，这一问题变得尤为重要。鉴于人类对身份变异的高度敏感性，这在I2V生成中成为一个关键但未被充分探索的挑战。", "innovation": "本文提出了基于强化学习的新型视频扩散框架IPRO（Identity-Preserving Reward-guided Optimization），以增强身份保留。我们的方法直接优化扩散模型，使用面部身份评分器而不是引入辅助模块或改变模型架构。为了提高性能和加速收敛，我们的方法反向传播奖励信号通过采样链的最后一部分，从而提供更丰富的梯度反馈。我们还提出了一种新的面部评分机制，将地面真实视频中的面部视为面部特征池，提供多角度的面部信息以增强泛化能力。进一步引入了KL散度正则化来稳定训练，防止对奖励信号过拟合。", "conclusion": "我们对Wan 2.2 I2V模型和我们的内部I2V模型进行了广泛的实验，证明了我们方法的有效性。我们的项目和代码可以在指定的链接中找到。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.16396", "html_url": "https://arxiv.org/abs/2510.16396", "title": "SPLite手部：基于稀疏性的轻量化3D手部姿态估计", "title_en": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "authors": "Yeh Keng Hao,Hsu Tzu Wei,Sun Min", "background": "随着AR/VR设备的普及，边缘设备上部署深度学习模型已成为关键挑战。这些设备需要实时推理、低功耗和最小延迟。框架设计师面临效率和性能之间的权衡难题。", "innovation": "设计了一种轻量级框架，采用了编码器-解码器架构，并引入了几项关键贡献以提高效率和准确性。通过在ResNet-18主干上应用稀疏卷积来利用手部姿态图像中的固有稀疏性，实现端到端效率提高42%。提出了SPLite解码器，此新架构在Raspberry Pi 5上将解码帧率提高3.1倍，保持准确性相仿。进一步应用量化感知训练，降低内存使用并保持准确性（PA-MPJPE从9.0 mm轻微增加到9.1 mm，FreiHAND基准数据集）。系统在Raspberry Pi 5 CPU（BCM2712四核心Arm A76处理器）上实现了2.98倍加速。", "conclusion": "该方法已在组合基准数据集上进行评估，显示与最先进的方法具有相似的准确性，并显著提高计算效率。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.13394", "html_url": "https://arxiv.org/abs/2510.13394", "title": "Spatial-DISE: 一种评估视觉语言模型空间推理能力的统一基准", "title_en": "Spatial-DISE: A Unified Benchmark for Evaluating Spatial Reasoning in Vision-Language Models", "authors": "Xinmiao Huang,Qisong He,Zhenglin Huang,Boxuan Wang,Zhuoyun Li,Guangliang Cheng,Yi Dong,Xiaowei Huang", "background": "视觉语言模型（VLMs）在诸如机器人技术、增强现实和自主导航等多元领域的实际应用中需要具备空间推理能力。然而，现有的基准测试工具在评估模型的空间推理能力方面存在缺陷，尤其是在评估内在动态空间推理方面，这是一项人类空间认知中的基本要素。目前，VLMs 在多步多视角空间推理上存在显著差距，难以达到人类水平的认知能力。", "innovation": "本文提出了一个基于认知基础分类的统一基准——Spatial-DISE，将任务分为四大基本象限：内在静态、内在动态、外在静态和外在动态空间推理。为了应对数据稀缺问题，开发了一个可扩展且自动化的数据生成管道，生成多样化和可验证的空间推理问题，从而创建了一个新的 Spatial-DISE 数据集，包括 Spatial-DISE 基准（559 个评估 VQA 对）和 Spatial-DISE-12K（12000 多个训练 VQA 对）。", "conclusion": "通过28个最先进的VLMs的全面评估，发现当前的VLMs在空间推理能力方面存在显著差距，特别是在多步多视角空间推理方面。Spatial-DISE提供了一个强大的框架、有价值的数据库和未来研究方向，以实现类似人类的空间智能。基准、数据集和代码将公开发布。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18705", "html_url": "https://arxiv.org/abs/2510.18705", "title": "从Transformer中显式挖掘运动信息用于动作识别的复兴", "title_en": "A Renaissance of Explicit Motion Information Mining from Transformers for Action Recognition", "authors": "Peiqin Zhuang,Lei Bai,Yichao Wu,Ding Liang,Luping Zhou,Yali Wang,Wanli Ouyang", "background": "近期，由于其时空上下文聚合能力，基于变压器的方法主导了动作识别领域。尽管在场景相关的数据集上取得了显著进展，但它们在运动敏感的数据集上表现不佳，主要是因为缺乏精细化的运动建模设计。观察到，传统动作识别中广泛使用的成本体积与自注意力中定义的亲和矩阵高度类似，但具有强大的运动建模能力。", "innovation": "提出了一个统一且简洁的方法，将有效的运动建模特性整合到现有的变压器中，称为显式运动信息挖掘模块（EMIM）。该模块通过滑动窗口方式从查询基于邻域区域在下一帧中的候选关键标记中抽样，构建亲和矩阵，进一步用于外观建模的上下文信息聚合，并转换为运动特征以进行运动建模。", "conclusion": "在四个广泛使用的数据集上验证了方法的运动建模能力，结果表明该方法优于现有的先进方法，尤其是在运动敏感的数据集Something-Something V1&V2上表现尤为出色。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.16709", "html_url": "https://arxiv.org/abs/2510.16709", "title": "HumanCM：一步到位的人体动作预测", "title_en": "HumanCM: One Step Human Motion Prediction", "authors": "Liu Haojie,Gao Suixiang", "background": "本文介绍了基于一致性模型构建的一体式人体动作预测框架HumanCM。该框架与依赖多步去噪的扩散模型不同，HumanCM通过学习噪声和清洁运动状态之间的自我一致映射来进行高效的一步生成。框架采用基于Transformer的空间-时间架构，并通过时间嵌入来建模长程依赖关系并保持运动的连贯性。实验在Human3.6M和HumanEva-I数据集上表明，HumanCM在减少推理步骤高达两个数量级的情况下，仍能获得与最先进的扩散模型相当或更优的准确性。", "innovation": "HumanCM框架避免了依赖于多步骤去噪的传统扩散模型的方法，通过学习噪声和清洁运动状态之间的一致映射，在单步中实现高效的生成。此外，框架通过采用基于Transformer的空间-时间架构并结合时间嵌入来建模长期依赖关系和保持运动连贯性，提高了预测精度并显著降低了推理步骤。", "conclusion": "实验结果表明，HumanCM在取得与最先进的扩散模型相当或更好的预测精度的同时，通过减少推理步骤高达两个数量级，展现了其在人体动作预测上的高效性和优越性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.12953", "html_url": "https://arxiv.org/abs/2510.12953", "title": "具有表征意识的视图-语言基础模型在胎儿超声解读中的应用", "title_en": "Epistemic-aware Vision-Language Foundation Model for Fetal Ultrasound Interpretation", "authors": "Xiao He,Huangxuan Zhao,Guojia Wan,Wei Zhou,Yanxing Liu,Juhua Liu,Yongchao Xu,Yong Luo,Dacheng Tao,Bo Du", "background": "最近的医学视图-语言模型在VQA、报告生成和异常检测等任务上展示了潜力，但大多数模型仅适用于结构化的成人成像，而在胎儿超声波分析中表现不佳。胎儿超声成像由于涉及多视角影像推理、多种疾病和图像多样性，提出了挑战。研究表明，现有的模型难以处理这些复杂的场景，从而限制了它们在该领域的应用效率和准确性。为了克服这一差距，该研究引入了FetalMind，一种针对胎儿超声的专业医疗AI系统，用于生成报告和诊断。", "innovation": "该研究提出了一种基于临床工作流程的Salient Epistemic Disentanglement (SED)方法，这种方法将临床专家制定的二分图注入模型中，从而分离视角-疾病关联，通过强化学习引导临床忠实步骤，以减少模型学习瓶颈。此外，还构建了FetalSigma-1M数据集，作为首个大规模的胎儿超声报告语料库，共包含来自12个医学中心的20000份报告，以解决领域数据稀缺问题。这些创新性方法显著提高了模型在胎儿超声诊断中的表现，尤其是在各妊娠阶段的表现，其中关键条件的检测准确率提高了61.2%。", "conclusion": "FetalMind在所有妊娠阶段的表现均优于开源和闭源的基线，展示了良好的效率、稳定性和可扩展性，成功解决了多视角胎儿超声解读的复杂挑战，为临床实践提供了有力支持。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18552", "html_url": "https://arxiv.org/abs/2510.18552", "title": "遮蔽nuScenes：用于评估自动驾驶感知鲁棒性的多传感器数据集", "title_en": "Occluded nuScenes: A Multi-Sensor Dataset for Evaluating Perception Robustness in Automated Driving", "authors": "Sanjay Kumar,Tim Brophy,Reenu Mohandas,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising", "background": "自动驾驶感知在恶劣条件下需要可靠的表现，这时传感器可能受到部分失效或环境遮挡的影响。虽然现有的自动驾驶数据集本身就包含了传感器噪声和环境变异性，但是鲜有数据集能够提供可控、参数化和可重复的多传感器模态降级。这限制了系统性评估感知和融合架构在定义明确的恶劣条件下的表现的能力。", "innovation": "该论文介绍了Occluded nuScenes数据集，这是基于广受使用的nuScenes基准的一个全新扩展。该数据集为相机模态提供了全版本和迷你版本，包含四种类型的遮挡，其中两种从公开的实现中调整而来，两种是全新设计的。对于雷达和LiDAR，该数据集提供了参数化的遮挡脚本，每种实施三种类型的影响，使能够灵活且重复生成遮挡数据。这些资源支持在部分传感器失效和环境干扰下的一致且可重复的感知模型评估。通过发布第一个多传感器遮挡数据集，该数据集具有可控且可重复的降级，旨在推动鲁棒传感器融合、鲁棒性分析和自动驾驶安全关键感知的研究。", "conclusion": "该数据集的发布旨在促进自动驾驶中鲁棒传感器融合、鲁棒性分析和安全关键感知的研究。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19597", "html_url": "https://arxiv.org/abs/2510.19597", "title": "CBDiff: 条件Bernoulli扩散模型在图像伪造定位中的应用", "title_en": "CBDiff:Conditional Bernoulli Diffusion Models for Image Forgery Localization", "authors": "Zhou Lei,Pan Gang,Wang Jiahao,Sun Di", "background": "图像伪造定位（IFL）是图像取证中的关键任务，旨在准确识别图像中的篡改或伪造区域。现有方法通常生成单一的确定性定位图，这在高风险应用如法医分析和安全监控中缺乏精准性和可靠性。", "innovation": "引入了先进的条件Bernoulli扩散模型（CBDiff）。CBDiff给定伪造图像时，能生成多种多样且具有说服力的定位图，从而提供伪造分布的丰富且综合的表示。通过在扩散过程中引入Bernoulli噪声，更真实地反映伪造掩码的固有二进制和稀疏特性，并引入了时间步骤交叉注意力（TSCAttention），专门利用时空步骤的语义特征，提升篡改检测能力。", "conclusion": "在八个公开基准数据集上的 extensive 实验表明，CBDiff 显著优于现有的最先进的方法，展示了其在实际部署中的强大潜力。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18781", "html_url": "https://arxiv.org/abs/2510.18781", "title": "叛逆学生： hyperspectral 异常检测中背景特征增强的互补学习框架", "title_en": "Rebellious Student: A Complementary Learning Framework for Background Feature Enhancement in Hyperspectral Anomaly Detection", "authors": "Wenping Jin,Yuyang Tang,Li Zhu,Fei Guo", "background": "近年来，一类仅需一次在背景数据集上训练就能广泛应用于 hyperspectral 异常检测的方法得到了显著的表现，这些方法不需要针对每个场景重新训练或调参。基于这种范式，本文聚焦于整合光谱和空间线索，并引入一种名为“叛逆学生”的新框架来进行互补特征学习。传统的教师-学生模型主要以模仿为核心，而本文的方法旨在使空间分支与光谱教师故意偏离，从而学习教师未能捕捉到的互补空间模式。采用两阶段学习策略：第一阶段通过反向蒸馏训练光谱增强网络，以获得鲁棒的背景光谱表示；第二阶段训练空间网络-“叛逆学生”，使用去相关损失来确保特性正交性的同时保持重建保真度，以避免无关噪声。一旦训练完成，框架将增强光谱和空间背景特征，使得与传统探测器结合时能够在无参数且无训练情况下实现异常检测。实验表明，与多种现有基准相比，该方法在计算开销轻微增加的情况下取得了显著改善，证实了提出的互补学习范式的有效性。本文的代码已公开在指定网址上。", "innovation": "引入了一种名为“叛逆学生”的新框架，该框架通过在训练过程中故意使空间分支与光谱教师模式偏离，来学习互补的空间模式。采用光谱增强和空间网络两阶段学习策略，以增强背景特征，从而提高异常检测的效率和鲁棒性。", "conclusion": "通过实验验证，该互补学习范式在 HAD100 基准上取得了显著的性能提升，并且具备低计算开销。所提出的框架可以实现无需参数和训练的异常检测，适用于 hyperspectral 异常检测任务。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.08281", "html_url": "https://arxiv.org/abs/2401.08281", "title": "Faiss库", "title_en": "The Faiss library", "authors": "Matthijs Douze,Alexandr Guzhva,Chengqi Deng,Jeff Johnson,Gergely Szilvasy,Pierre-Emmanuel Mazaré,Maria Lomeli,Lucas Hosseini,Hervé Jégou", "background": "目前，AI应用程序正在快速增长，这导致需要存储和索引的嵌入向量数量也在增加。此类嵌入向量管理的挑战促使了类似Faiss这样的矢量数据库和库的发展。Faiss专门用于矢量相似性搜索，这是矢量数据库的核心功能之一，它是一套用于存储、聚类、压缩和变换矢量的索引方法工具包。", "innovation": "本文探讨了矢量搜索的权衡空间，并描述了Faiss的设计原则，包括结构设计、优化方法以及接口设计。通过对库的关键功能进行基准测试，并举例说明其广泛的应用范围，突显了Faiss的广泛应用价值。", "conclusion": "研究还讨论了Faiss的设计原则和结构特性，对比了其关键功能的性能指标，并展示了几个应用实例，以体现该库的多功能性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19193", "html_url": "https://arxiv.org/abs/2510.19193", "title": "Video Consistency Distance: 通过基于奖励的微调增强图像到视频生成的时序一致性", "title_en": "Video Consistency Distance: Enhancing Temporal Consistency for Image-to-Video Generation via Reward-Based Fine-Tuning", "authors": "Takehiro Aoshima,Yusuke Shinohara,Byeongseon Park", "background": "基于奖励的微调方法被证明是提高生成视频质量的有效途径，因为它可以在不需要真实世界视频数据集的情况下细调模型。然而，传统的奖励函数主要集中在提升整个生成视频序列的质量，如美学吸引力和整体一致性上。在将这些方法应用于图像到视频（I2V）生成任务时，生成视频的时序一致性常常受到影响。", "innovation": "本文提出了一种新的时序一致性度量方法——Video Consistency Distance (VCD)。VCD 在视频帧特征的频率域中定义，通过频域分析有效捕捉帧信息，旨在增强时序一致性。通过基于奖励的微调框架，利用 VCD 细调模型，以实现相对于条件图像的时间一致性和连贯性。", "conclusion": "实验结果表明，使用 VCD 细调视频生成模型可以显著增强时序一致性，而不会损害其他性能，相比之前的处理方法有明显的提高。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12801", "html_url": "https://arxiv.org/abs/2504.12801", "title": "从零开始稀疏训练的方向引入：参数重构稀疏训练", "title_en": "Sign-In to the Lottery: Reparameterizing Sparse Training From Scratch", "authors": "Advait Gadhikar,Tom Jacobs,Chao Zhou,Rebekka Burkholz", "background": "训练从零开始的稀疏神经网络（PaI）和从密集到稀疏的训练之间存在性能差距，这对高效的深度学习构成了重大障碍。票选理论假设PaI依赖于找到特定于问题的参数初始化。我们证明找到正确的参数符号对该假设至关重要，但PaI难以实现这一点。现有的方法难以解决这个问题，因此需要开发新的方法来改善从零开始稀疏训练的性能并缩小与从密集到稀疏训练之间的差距。", "innovation": "提出了Sign-In，这是一种动态重新参数化方法，能够证明诱导符号翻转，并且这些符号翻转与从密集到稀疏训练能够实现的互补，使其成为一个与现有方法正交的方法。实验和理论结果表明，Sign-In方法可以提高从零开始稀疏训练的性能。", "conclusion": "虽然实验和理论表明Sign-In可以改善从零开始稀疏训练的性能，但仍然不清楚如何完全解决从零开始稀疏训练和从密集到稀疏训练之间的性能差距。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.18458", "html_url": "https://arxiv.org/abs/2504.18458", "title": "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "title_en": "Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning", "authors": "Wenyi Xiao,Leilei Gan", "background": "应用强化学习（通常通过GRPO进行）到大型视觉语言模型推理时，难以有效扩展推理长度或会在所有任务中产生冗长的输出，同时仅获得微小的准确性提升。", "innovation": "提出了一种FAST-GRPO变体，根据问题特征动态调整推理深度。引入了两个指标来估计问题的难度，指导模型确定何时应使用快速或慢速思考。此外，结合了基于长度的自适应奖励和难度感知KL散度到GRPO算法中。", "conclusion": "在七个推理基准测试中，FAST在相对提升超10%准确性的同时，相比传统的慢速思考方法减少了32.7%-67.3%的令牌使用量，有效地平衡了推理长度和准确性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.15172", "html_url": "https://arxiv.org/abs/2408.15172", "title": "X-Reflect: 跨反射提示在多模态推荐中的应用", "title_en": "X-Reflect: Cross-Reflection Prompting for Multimodal Recommendation", "authors": "Hanjia Lyu,Ryan Rossi,Xiang Chen,Md Mehrab Tanjim,Stefano Petrangeli,Somdeb Sarkhel,Jiebo Luo", "background": "大型语言模型（LLMs）已被证明能增强通过丰富项目描述来提高推荐系统准确性的能力。然而，现有的大多数方法要么仅依赖于文本提示，要么仅采用基本的多模态策略，未能充分利用文本和视觉模态提供的互补信息。本文旨在通过引入一种新颖的框架——跨反射提示（Cross-Reflection Prompting，简称X-Reflect），来解决现有方法的限制，该框架通过促使多模态大型语言模型（MLLMs）明确识别和解决文本与图像之间支持性及矛盾性信息，以生成更全面和语境丰富的项目表示。", "innovation": "本文提出了一种新颖的框架，跨反射提示（X-Reflect），它通过引导多模态大型语言模型明确识别和解决文本与图像之间支持性及矛盾性信息，从而生成更全面和语境丰富的项目表示。此外，还提出了一种轻量级变体X-Reflect-keyword，通过使用关键词总结图像内容并使用更小的基础模型，实现了输入长度近50%的减少，同时保持了竞争力的性能。这种方法发现，文本-图像差异性与推荐性能之间存在U型关系，表明选择性应用多模态提示的益处。", "conclusion": "本文强调了整合多模态信息的重要性，并提出了一种有效的多模态推荐系统中增强项目理解的解决方案。通过实验证明，X-Reflect方法在下游推荐准确性上优于现有提示基线，并且X-Reflect-keyword通过简化输入大大提高了效率。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.09630", "html_url": "https://arxiv.org/abs/2505.09630", "title": "生成性扩散模型代理机制化的基于代理的生物学模型", "title_en": "Generative diffusion model surrogates for mechanistic agent-based biological models", "authors": "Tien Comlekoglu,J. Quetzalcoatl Toledo-Marín,Douglas W. DeSimone,Shayn M. Peirce,Geoffrey Fox,James A. Glazier", "background": "机制性、多细胞、基于代理的模型常用于在单细胞分辨率下研究组织、器官及整体生物学。细胞-平板模型（CPM）是一种强大的工具，用于开发和探究这类模型。然而，随着时间和空间尺度的增大，CPM变得计算密集，影响模型的应用与探讨。代理模型可能有助于加速CPM的评估，但其随机性意味着不同的参数设置可能导致不同的模型配置，导致代理模型开发的复杂性。", "innovation": "本文利用去噪扩散概率模型训练生成AI代理，以生成用于体外血管形成研究的CPM模型配置。引入了一种图像分类器来学习定义二维参数空间独特区域的特征，并用该分类器辅助代理模型的选择与验证。所提出的CPM模型代理能够提前20,000个时间步生成参考配置，并显示出计算时间减少约22倍。", "conclusion": "本研究代表了使用DDPM开发随机生物学系统数字孪生模型的一个步骤。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.13837", "html_url": "https://arxiv.org/abs/2504.13837", "title": "RL是否真正激励LLMs超出基模型的推理能力？", "title_en": "Does Reinforcement Learning Really Incentivize Reasoning Capacity in LLMs Beyond the Base Model?", "authors": "Yang Yue,Zhiqi Chen,Rui Lu,Andrew Zhao,Zhaokai Wang,Yang Yue,Shiji Song,Gao Huang", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 已经展示了在提高大型语言模型（LLMs）在数学和编程任务上的推理性能方面的成果。RLVR被认为是使LLMs能够持续自我提升，从而获得基模型所不具备的新推理能力。研究人员通过系统地探究RLVR训练后的LLMs在不同模型系列、RL算法及各种数学、编程和视觉推理测览上的推理能力界限来研究当前RLVR的状况，使用较大的k值下的pass@k作为评估指标。研究发现，尽管RLVR训练的模型在较小的k值下表现优于基模型，但在较大的k值下，基模型表现出更高的pass@k得分。", "innovation": "研究通过使用pass@k评估指标，系统地对RLVR训练后的LLMs在不同测览上的推理能力进行了探讨。研究发现，基模型是观察到的推理能力的上限，并且流行的六种RLVR算法在利用基模型潜力方面表现相似，远未达到最优。此外，研究指出蒸馏方法可以从教师模型中引入新的推理模式，真实地扩展模型的推理能力。", "conclusion": "当前RLVR方法尚未实现使用RL真正激发LLMs的新推理能力的潜力。研究结果强调了需要改进的RL模式，如持续扩展和多回合智能体-环境交互，以解锁这一潜能。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.12441", "html_url": "https://arxiv.org/abs/2410.12441", "title": "具有输入可凸神经网络正则化项的图像重建的原始对偶算法", "title_en": "A primal-dual algorithm for image reconstruction with input-convex neural network regularizers", "authors": "Matthias J. Ehrhardt,Subhadip Mukherjee,Hok Shing Wong", "background": "在数据驱动的变分重建框架中，正则化器由输入可凸神经网络（ICNN）参数化。尽管梯度基方法常用于解决此类问题，但它们难以有效处理非光滑问题，导致收敛速度慢。此外，神经网络的嵌套结构使得标准非光滑优化技术，如邻近点算法的应用变得复杂。研究表明，当前的优化方法在面对这些问题时存在不足。", "innovation": "本文通过重新描述问题，并消除神经网络的嵌套结构，将问题转换为可以通过原始对偶算法高效求解的凸优化问题。这一方法不仅改进了处理非光滑问题的能力，也简化了算法的实现。此外，推导了该重新描述与激活函数的对偶投影的关系，进一步保证了方法的有效性和正确性。", "conclusion": "在多个成像任务中的实验表明，提出的方法不仅在光滑情况下优于子梯度方法和加速度方法，还在正则化器自身训练方面具有优势。该方法展示了在复杂条件下优化变分重建问题的有效性，并为处理此类问题提供了有力工具。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.19678", "html_url": "https://arxiv.org/abs/2505.19678", "title": "视觉引导语言：一种用于减少LVLMs幻觉的条件互信息校正解码策略", "title_en": "Grounding Language with Vision: A Conditional Mutual Information Calibrated Decoding Strategy for Reducing Hallucinations in LVLMs", "authors": "Hao Fang,Changle Zhou,Jiawei Kong,Kuofeng Gao,Bin Chen,Shu-Tao Xia", "background": "大型视觉-语言模型（LVLMs）容易产生幻觉，生成的响应虽然在语义上看似合理，但实际上与输入图像无关。先前的研究表明，这一问题主要源于LVLMs对语言先验信息的过度依赖，忽视了在解码过程中视觉信息的作用。", "innovation": "本文提出了一种新颖的条件点间隔互信息（C-PMI）校正解码策略，通过自适应地增强生成文本与输入图像之间的相互依赖关系，来减轻幻觉。我们的方法不仅在单个文本标记采样上下文中工作，我们的方法同时建模视觉和文本标记对C-PMI的贡献，将幻觉缓解作为最大化互信息的双层优化问题来解决。我们设计了一个标记净化机制，动态调节解码过程，以确保文本标记对给定图像的最大相关性，同时细化与生成响应最相关的图像标记。", "conclusion": "在多个基准测试上的广泛实验显示，所提出的方法显著减少了LVLMs中的幻觉现象，同时保持了解码效率。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23751", "html_url": "https://arxiv.org/abs/2505.23751", "title": "REOrdering Patches Improves Vision Models", "title_en": "REOrdering Patches Improves Vision Models", "authors": "Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta", "background": "序列模型（如变压器）需要将输入表示为一维序列。在视觉领域，通常通过固定的方向（行主导，即栅栏扫描）来展平图像。尽管全自注意力机制在置换不变性上有效，但现代长序列变压器越来越依赖于破坏这种不变性的架构近似，使其对块顺序变得敏感。研究表明，在这种情况下，块的顺序对模型性能有显著影响，简单的替代顺序如列主导或希尔伯特曲线能显著提高准确性。", "innovation": "提出了一种名为REOrder的两种阶段框架来寻找任务特定的最佳块排序。首先，通过评估不同块序列的可压缩性来建立信息论先验。然后，通过优化Plackett-Luce策略并使用REINFORCE进行学习，来学习置换策略。这种方法能够在组合置换空间中实现高效学习。实验结果表明，与行主导顺序相比，REOrder可以提高ImageNet-1K和功能地图的世界基准上的顶级准确率，分别高达3.01%和13.35%。", "conclusion": "REOrder框架显著提高了视觉模型的性能，特别是在块排序对性能影响较大的情况下。通过对比不同的排序方式，并提出了一种有效的优化策略，这种框架在多个视觉基准测试中显示出显著的改进。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12944", "html_url": "https://arxiv.org/abs/2505.12944", "title": "CALM-PDE：连续和自适应卷积在时变PDE隐空间建模中的应用", "title_en": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs", "authors": "Jan Hagnberger,Daniel Musekamp,Mathias Niepert", "background": "时变偏微分方程（PDEs）在气候现象建模和流体力学等领域有广泛应用，但直接在物理空间中进行计算会带来显著的计算成本。为解决此问题，已开发出一些基于神经网络的近似模型，它们在压缩的潜在空间中运行以求解PDE。尽管这些方法可以降低计算复杂度，但它们通常使用基于Transformer的注意力机制来处理不规则采样空间，从而增加内存消耗。现有的卷积神经网络虽然可以实现高效编码和解码，但限于规则网格化数据。鉴于此，本文提出了CALM-PDE模型类，能够在压缩的潜在空间中高效求解任意网格化的PDE。", "innovation": "提出了CALM-PDE模型类，结合了连续卷积和自适应卷积的编码-解码架构，使用ε-邻域约束核，学习将卷积运算应用于可适应和优化的查询点。该方法在不同类型的PDE上进行了测试，包括规则和不规则空间取样，并表现出与现有基线方法相当或更优的性能，同时在内存和推理时间效率方面有显著改进，优于基于Transformer的方法。", "conclusion": "本文提出了CALM-PDE模型类，能够在压缩的潜在空间中高效求解任意网格化的PDE。该方法通过采用ε-邻域约束连续卷积架构，在内存和推理时间效率方面取得了显著进步。实验结果表明，CALM-PDE在各种PDE问题上具有竞争力或优势。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15958", "html_url": "https://arxiv.org/abs/2507.15958", "title": "注意力感知神经形态架构在受资源限制设备上高效皮肤疾病分类", "title_en": "Quantization-Aware Neuromorphic Architecture for Efficient Skin Disease Classification on Resource-Constrained Devices", "authors": "Haitian Wang,Xinyu Wang,Yiren Wang,Zichen Geng,Xian Zhang,Yu Zhang,Bo Miao", "background": "在边缘设备上实现准确且高效的皮肤病变分类对于可访问的皮肤科护理至关重要，但因计算、能耗和隐私限制而面临挑战。", "innovation": "QANA，一种新颖的量化感知神经形态架构，用于资源受限硬件上的逐步皮肤病变分类。QANA通过融合幽灵模块、高效通道注意力和挤压-激励块，实现了低延迟和节能的高效推理。其量化感知头部和尖峰兼容变换，能够无缝转换为神经形态平台上的突触神经网络。", "conclusion": "QANA在HAM10000基准和临床数据集上的表现优于现有最佳的CNN到SNN模型，在HAM10000上的Top-1准确率为91.6%，宏F1得分为82.4%；在临床数据集上的得分分别为90.8%和81.7%。部署在BrainChip Akida硬件上，QANA实现了每幅图像1.5 ms的推理延迟和1.7 mJ的能量效率，明显优于基于GPU的CNN，能耗和延迟分别降低了94.6%和98.6%。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19351", "html_url": "https://arxiv.org/abs/2510.19351", "title": "有限示范下向人群学习推迟", "title_en": "Learning To Defer To A Population With Limited Demonstrations", "authors": "Nilesh Ramgolam,Gustavo Carneiro,Hsiang-Ting Chen", "background": "这篇论文解决了一个关键技术问题，即数据稀缺性阻碍了学习推迟系统（L2D）在大众中的实际部署。作者指出，当前L2D系统在面对大量数据需求时难以有效应用。", "innovation": "该研究引入了一种结合元学习的半监督框架，能够在少量示范下生成专家特定的嵌入。这一机制具有双重用途，首先生成大量伪标签用于训练，随后在测试时实现对新专家的即时适应。实验结果表明，使用这些合成标签训练的模型能够快速接近理想的性能水平，证明了该方法的数据效率。", "conclusion": "通过解决关键的训练瓶颈，这项工作使适应性L2D系统更加实用与扩展，为实际环境中的人类-AI协作铺平了道路。为了促进可重复性和解决主文中未涵盖的实现细节，作者提供了源代码和训练配置。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07800", "html_url": "https://arxiv.org/abs/2507.07800", "title": "适用于显微镜图像中微管噪声自适应和鲁棒分割的新注意力机制", "title_en": "A novel attention mechanism for noise-adaptive and robust segmentation of microtubules in microscopy images", "authors": "Achraf Ait Laydi,Louis Cueff,Mewen Crespo,Yousef El Mourabit,Hélène Bouvrais", "background": "在显微镜图像中分割细胞骨架纤维是了解它们的细胞功能的关键，但在密集且复杂的网络中和噪声或低对比度图像条件下仍然具有挑战性。尽管深度学习在图像分割方面取得了进步，但在恶劣的场景下性能往往会下降。其他挑战包括标注准确性差和严重的类别不平衡。", "innovation": "提出了一种新颖的噪声自适应注意力机制，对该机制进行了扩展，以适应不断变化的噪声水平。将该机制命名为Adaptive Squeeze-and-Excitation (ASE)模体，集成到U-Net解码器中，带有残差编码器块，形成了一个轻量且强大的模型：ASE_Res_U-Net。还开发了一种合成数据集策略，并使用定制损失函数和评估指标来缓解类别不平衡并确保公平评估。ASE_Res_U-Net 在合成和真实噪声图像中有效分割了微管，超越了其未加权的变体和最先进的曲线结构分割方法，同时使用更少的参数，适用于资源受限的环境。更重要的是，ASE_Res_U-Net 在多种成像条件下对其他曲线结构（如血管和神经）表现出很好的泛化能力。", "conclusion": "ASE_Res_U-Net 在微管分割中表现出色，适用于合成和真实噪声图像，在资源受限的环境中表现良好，并且能够很好地适应其他曲线结构。原始的微管数据集现可从Zenodo获取，ASE_Res_U-Net模型将在发布后提供。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16349", "html_url": "https://arxiv.org/abs/2506.16349", "title": "使用自动回归图像生成的水印技术", "title_en": "Watermarking Autoregressive Image Generation", "authors": "Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez", "background": "生成模型的输出水印化已经成为一种有前景的方法，用于追踪其来源。尽管存在对自动回归图像生成模型及其潜在滥用的兴趣，但先前没有任何研究在标记层尝试对它们的输出进行水印化处理。研究团队发现了一个关键挑战：缺乏逆循环一致性 (RCC)，即重新标记生成图像标记会显著改变标记序列，从而有效地擦除水印。", "innovation": "研究团队介绍了第一个在自动回归图像生成模型输出上实施水印的方法，通过将语言模型水印技术适应此设置。为解决这一挑战并使方法对常见图像变换、神经压缩和移除攻击具有鲁棒性，他们提出了（i）一个定制的标记器-反标记器微调过程，以提高RCC，以及（ii）一个互补的水印同步层。这一方法已经被实验证明能够实现可靠且鲁棒的水印检测，且具有理论支持的p值。代码和模型可以在指定网址获得。", "conclusion": "研究成功实施了一种新的水印策略，通过改进RCC并使用同步层使得方法对于多种攻击具有抗性。实验结果证明了该方法的可靠性和鲁棒性。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.25271", "html_url": "https://arxiv.org/abs/2509.25271", "title": "RADAR: 一种基于角色专业化协作的针对大语言模型安全评估的风险感知动态多agent框架", "title_en": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "authors": "Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li", "background": "现有的大型语言模型的安全评估方法存在固有的局限性，包括评估者的偏见和由于模型同质性导致的检测失败，这些问题都会削弱风险评估过程的稳健性。目前的评估方法容易受到这些限制的影响，难以进行全面和客观的风险评估。因此，本研究旨在重新审视风险评估观念，通过引入一个理论框架，该框架将潜在的风险概念空间分解为三个互斥子空间：显式风险子空间（涵盖了直接违反安全准则的情况）、隐式风险子空间（包含需要上下文推理才能识别的潜在恶意内容）以及无风险子空间。", "innovation": "本研究提出了RADAR，这是一种基于多agent协作的风险评估框架。该框架采用了四类专门化的角色，并通过多轮辩论机制来实现对风险概念分布的动态更新，从而实现了自我进化。这种方法不仅能够全面覆盖显性和隐性风险，还能减轻评估者的偏见。此外，RADAR框架还构建了一个包含800个具有挑战性的案例的评估数据集，并通过实验证明了其在准确率、稳定性和自我评价风险敏感性等方面显著优于基准评价方法。", "conclusion": "广泛的实验证明，RADAR在多个维度上显著优于基准评估方法，特别是在风险识别准确性方面，相比最强基准提高了28.87%。本研究提出了一种新的风险评估框架，不仅能克服现有方法的局限性，还能够有效地检测各种类型的潜在风险。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.15530", "html_url": "https://arxiv.org/abs/2510.15530", "title": "VO-DP: 惟视知觉自适应扩散策略用于单目视机器人操作", "title_en": "VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation", "authors": "Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He", "background": "在模仿学习的背景下，基于视觉运动的扩散策略学习是机器人抓取操作的一个主要研究方向。现有的大多数方法依赖于点云作为观察输入，并通过点云特征学习构建场景表示，从而达到较高的精确度。然而，现有的文献较少深入探讨纯视觉解决方案，尽管它们拥有巨大的潜力。", "innovation": "本文提出了一种名为VO-DP的方法，它利用预训练的视觉基础模型实现语义和几何特征的有效融合。该方法通过结合VGGT的中间特征、DINOv2的语义特征以及交替注意力模块的几何特征，并通过交叉注意力和卷积神经网络空间压缩将特征融合，形成策略头部的输入。实验表明，VO-DP不仅显著优于纯视觉基线DP方法，而且在仿真任务和实际操作任务中也展现出显著的优势。此外，该方法在多种环境条件下显示出高鲁棒性。", "conclusion": "通过开放源代码，一种基于加速的训练库支持多机器和多GPU并行训练以及混合精度训练，使用户能够轻易地应用于诸如DP、DP3和VO-DP等策略以及RoboTwin模拟器。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.19634", "html_url": "https://arxiv.org/abs/2507.19634", "title": "MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks", "title_en": "MCIF: Multimodal Crosslingual Instruction-Following Benchmark from Scientific Talks", "authors": "Sara Papi,Maike Züfle,Marco Gaido,Beatrice Savoldi,Danni Liu,Ioannis Douros,Luisa Bentivogli,Jan Niehues", "background": "近年来，大规模语言模型的发展推动了多模态大型语言模型（MLLMs）的开发，这些模型可以在统一框架中整合文本、语音和视觉信息。MLLMs从狭窄的专业语言、单模态任务特定系统发展到通用指令遵循模型。然而，现有的基准测试在评估多语言和多模态能力方面存在不足：它们往往局限于英语，主要聚焦于单一模态，依赖于短文本，或缺乏人工标注，阻碍了对模型性能在语言、模态和任务复杂性方面的全面评估。", "innovation": "该研究引入了MCIF（Multimodal Crosslingual Instruction Following），这是首个基于科学演讲的多语言标注基准，旨在评估跨语言和多模态环境下的指令遵循能力，覆盖短文本和长文本输入。MCIF包含了三种核心模态——语音、视觉和文本——以及四种语言（英语、德语、意大利语和中文），这使得研究者能够全面评估MLLMs在跨语言和结合多模态上下文信息方面的解释指令的能力。基准测试在CC-BY 4.0许可下公开发布，促进MLLMs领域的开放研究和进步。", "conclusion": "MCIF为评估MLLMs的跨语言和多模态能力提供了第一个多语言标注基准，覆盖了广泛的语言和模态，并支持长文本和短文本输入。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19861", "html_url": "https://arxiv.org/abs/2510.19861", "title": "一些注意力就足够用于检索", "title_en": "Some Attention is All You Need for Retrieval", "authors": "Felix Michalak,Steven Abreu", "background": "本研究探讨了在混合SSM-Transformer架构中注意力机制的作用，尤其是在信息检索任务中的表现。", "innovation": "发现了在混合架构中，自注意力层负责检索任务，而SSM层在检索任务中没有补偿机制。通过减少注意力到15%的头也能够保持近乎完美的检索性能，但同时保留了84%的MMLU性能，揭示了自注意力层的专用性。", "conclusion": "研究提出了检索任务对自注意力层的严格功能需求，表明这些模型在混合架构中是作为专门模块运行，而非整合系统。这一发现对架构优化和可解释性具有即时影响。"}
{"llm_update_time": "20251025", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19755", "html_url": "https://arxiv.org/abs/2510.19755", "title": "向高效多模态生成迈进的扩散模型缓存方法综述", "title_en": "A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation", "authors": "Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang", "background": "扩散模型因其出色的生成质量和可控性而成为现代生成AI的核心基石。然而，其固有的多步骤迭代和复杂骨干网络导致了巨大的计算开销和生成延迟，成为实时应用的主要瓶颈。现有的加速技术虽然有所进步，但仍然存在适用性有限、高培训成本或质量降级等问题。", "innovation": "扩散缓存作为一种无需训练、架构无关且高效的推理范式提出了新的解决方案。其核心机制是识别并重用扩散过程中的固有计算冗余。通过在特征级别实现跨步骤重用和层间调度，它能在不修改模型参数的情况下减少计算。此外，论文还系统地回顾了扩散缓存的理论基础和演化，并提出了其分类和分析的统一框架。", "conclusion": "研究表明，扩散缓存在从静态重用进化到动态预测的过程中，提高了缓存的灵活性，并能与其他加速技术如采样优化和模型蒸馏结合，为未来的多模态和交互应用提供了高效的推理框架。这一范式将成为实现实时和高效生成AI的关键驱动力，为高效生成智能的理论和实践注入新的活力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19872", "html_url": "https://arxiv.org/abs/2510.19872", "title": "深度Q网络中的集成神经架构搜索方法", "title_en": "An Integrated Approach to Neural Architecture Search for Deep Q-Networks", "authors": "Iman Rahmani,Saman Yazdannik,Morteza Tayefi,Jafar Roshanian", "background": "深度强化学习代理的表现从根本上受到其神经网络架构的限制，这种选择通常通过昂贵的超参数搜索来作出，并在整个训练过程中保持不变。本文探讨了在线适配的架构优化是否可以突破这一限制，并能够超越静态设计。文章介绍了NAS-DQN代理，它将学习到的神经架构搜索控制器直接集成到强化学习训练循环中，使其可以根据累积性能反馈动态重新配置网络。这项研究评估了NAS-DQN在固定架构基线和随机搜索对照组在连续控制任务上的表现，进行了多次随机种子的实验。实验结果表明，NAS-DQN在最终性能、样本效率和策略稳定性上均优于基准，并且几乎没有增加计算成本。", "innovation": "文章创新点在于提出了基于强化学习的动态神经架构搜索算法（NAS-DQN），该算法直接将神经架构搜索控制器集成到DRL训练循环中，使网络结构能够基于累积性能反馈动态调整。这种方法显著优于无目标随机架构探索和缺乏针对性的静态设计，这说明基于性能的智能搜索是实现系统成功的秘诀。这表明在在线深度强化学习中，架构自适应不仅是有益的，而且是必要的，为强化学习代理的设计提供了新的可能性，使其可以在学习过程中动态参与。", "conclusion": "本文的发现表明，架构自适应对于在线深度强化学习中的最优样本效率是必不可少的。并且，强化学习代理的设计不应是静态的离线选择，而是可以无缝集成为其学习过程的一部分。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19889", "html_url": "https://arxiv.org/abs/2510.19889", "title": "从最优化到预测：基于Transformer的路径流量估计在交通分配问题中的应用", "title_en": "From Optimization to Prediction: Transformer-Based Path-Flow Estimation to the Traffic Assignment Problem", "authors": "Mostafa Ameli,Van Anh Le,Sulthana Shams,Alexander Skabardonis", "background": "交通分配问题对于交通流量分析至关重要，传统上使用在均衡原则下的数学规划方法来解决。然而，对于大规模网络，这些方法由于OD对数量的非线性增长而变得计算成本极高。研究表明，现有的方法难以应对大规模网络的需求。", "innovation": "本文引入了一种基于数据驱动的新型方法，使用深度神经网络，特别是采用Transformer架构来直接预测均衡路径流量。该模型通过关注路径级别的交通分配，捕捉OD对之间的复杂关联，相比传统的链路级别方法提供了更详细和灵活的分析。基于Transformer的模型大大减少了计算时间，无需重新计算即可适应需求和网络结构的变化。", "conclusion": "在曼哈顿风格合成网络、Sioux Falls 网络和Eastern-Massachusetts 网络上的数值实验表明，所提出的方法比传统优化方法快了数万倍。该模型能够在多类网络中高效估计路径级别的交通流量，降低了计算成本并提高了预测准确性，同时能够灵活适应变化的需求和网络条件，支持交通管理，增强运输规划和政策制定。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19896", "html_url": "https://arxiv.org/abs/2510.19896", "title": "通过可解释的SHAP引导特征选择和分类提高泌尿系统疾病诊断准确性", "title_en": "Enhancing Diagnostic Accuracy for Urinary Tract Disease through Explainable SHAP-Guided Feature Selection and Classification", "authors": "Filipe Ferreira de Oliveira,Matheus Becali Rocha,Renato A. Krohling", "background": "本文提出了一种使用基于SHAP（SHapley Additive exPlanations）的特征选择方法来提高泌尿系统疾病诊断，尤其是膀胱癌的预测模型的透明度和有效性。针对膀胱癌与其他泌尿系统和肿瘤性疾病的区分，开发了六个二元分类场景。研究采用了XGBoost、LightGBM和CatBoost算法，并通过Optuna进行了超参数优化，同时使用SMOTE技术实现了类平衡。", "innovation": "本文创新点在于采用了基于SHAP的特征选择方法，提升了诊断模型的透明度和解释性，通过优化分类算法和平衡分类结果，提高了预测性能指标。这种方法有助于开发更为透明、可靠且高效的临床决策支持系统，优化泌尿系统疾病的筛查和早期诊断。", "conclusion": "通过SHAP引导的特征选择和分类方法，本文为泌尿系统疾病的诊断提供了一种有效的策略。该方法有望促进临床决策支持系统的开发，提高早期诊断的准确性和效率。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19941", "html_url": "https://arxiv.org/abs/2510.19941", "title": "贪心任务排序在连续线性回归中比随机排序更好吗？", "title_en": "Are Greedy Task Orderings Better Than Random in Continual Linear Regression?", "authors": "Matan Tsipory,Ran Levinstein,Itay Evron,Mark Kong,Deanna Needell,Daniel Soudry", "background": "论文分析了联合可实现训练数据的连续学习中的任务排序，并重点关注能够最大程度地在连续任务之间实现不相似性的贪心排序。这种方法在先前的工作中已被简要探讨过，但仍然有许多开放的问题。", "innovation": "作者利用Kaczmarz方法的相关工具对这种排序进行了形式化，并建立了有关这些排序的几何和代数直觉。实验上，作者证明了相比随机排序，贪心排序在减少任务平均损失方面更快。理论上，在高秩回归场景下，作者证明了贪心排序的损失上界类似于随机排序的损失上界，但在一般秩的条件下，作者发现了一个与重复次数相关的分离现象。特别地，对于单过贪心排序，上界为$\text{O}(1/\text{sqrt}(k))$，允许重复的贪心排序的收敛速率为$\text{O}(1/\text{sqrt}(3)(k))$。", "conclusion": "作者揭示了贪心和随机排序之间的细微差别，证明了贪心排序在连续线性回归中的行为比先前认为的更为复杂。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19893", "html_url": "https://arxiv.org/abs/2510.19893", "title": "FairGRPO: 公平的强化学习以实现临床推理的公正性", "title_en": "FairGRPO: Fair Reinforcement Learning for Equitable Clinical Reasoning", "authors": "Shiqi Dai,Wei Dai,Jiaee Cheong,Paul Pu Liang", "background": "医疗人工智能系统在诊断方面取得了显著的进步，但它们在不同人口群体中的表现存在差异，给代表性不足的人群造成了实际伤害。虽然多模态基础模型通过综合分析多种医疗数据提高了临床诊断能力，但基于强化学习的推理训练往往会继承并放大训练数据集中的偏见。这些数据集通常由主流人口主导，这导致了不公平的学习结果。这篇论文旨在解决这一问题，通过引入一种新的方法来促进临床多样化的公正学习。", "innovation": "论文提出了Fairness-aware Group Relative Policy Optimization (FairGRPO)，这是一种层次化的强化学习方法，可促进临床多样化的公正学习。FairGRPO利用基于表示、任务难度和数据源的自适应重要性加权优势。在临床领域中缺乏人口标签的情况下，还进一步采用了无监督聚类，以自动发现潜在的人口群体。通过一系列临床诊断数据集的实验（涵盖X射线、CT扫描、皮肤镜检查、乳腺X光摄影和超声检查），结果表明，FairGRPO相较于所有其他基准强化学习方法和偏见缓解方法，可以减少27.2%的预测均等性，同时将F1分数提高了12.49%。此外，训练动态分析显示，FairGRPO在整个优化过程中逐步提高公平性，而基准强化学习方法则在训练过程中公平性变差。基于FairGRPO，论文还推出了FairMedGemma-4B，这是一种公平意识的临床VLLM，在表现上达到了最先进的技术水平，同时显著减少了不同人口群组之间的差异。", "conclusion": "FairGRPO通过引入层次化强化学习方法和无监督聚类技术，显著降低了临床诊断中的偏见，提高了不同人群的诊断公平性。通过一项全面的实验，证明了FairGRPO的有效性，并且展示了其在临床医疗中的应用价值。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19873", "html_url": "https://arxiv.org/abs/2510.19873", "title": "从大型到小型：通过推理图转移CUDA优化专长", "title_en": "From Large to Small: Transferring CUDA Optimization Expertise via Reasoning Graph", "authors": "Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li", "background": "尽管CUDA编程和领域特定库已经经历了显著的发展，但高效利用具有大规模并行引擎的GPU仍然很困难。大语言模型（LLMs）展示了从顺序代码生成优化CUDA代码的潜力。然而，在实践中使用LLMs面临两大挑战：基于云的服务存在代码泄露风险，并且本地部署通常计算成本高且效率低。这些缺点推动了对小型语言模型（SLMs）的兴趣，SLMs具有更轻量化的优点。虽然SLMs在特定任务上可以达到LLMs的性能，但在复杂CUDA代码生成方面，它们的有限推理能力导致了性能不佳。为弥补这一差距，该研究提出了一种名为ReGraphT的不涉及训练、检索增强生成框架，可以将LLM级别的推理转移到较小的模型中。ReGraphT将CUDA优化过程组织成结构化的推理图，并采用蒙特卡洛图搜索（MCGS）提高探索效率。同时，还提出了一种CUDA领域的基准测试，根据推理复杂度划分难度层级，更全面地评估模型。实验结果显示，ReGraphT在CUDAEval和ParEval上的平均加速比达到2.33倍，与高性能计算（HPC）专门微调模型和其他检索增强方法相比，实现性能提升；与DeepSeek-Coder-V2-Lite-Instruct和Qwen2.5-Coder-7B-Instruct结合使用时，可以降低隐私风险和计算开销，使SLMs接近达到LLM级别的性能。", "innovation": "提出了一种名为ReGraphT的培训免打扰、检索增强生成框架，将LLM级别的推理转移到较小的模型。通过将CUDA优化过程组织成结构化的推理图，并采用蒙特卡洛图搜索（MCGS）进行高效探索。还提出了一种CUDA特定的基准测试，按推理复杂度定义难度层级，更全面地评估模型。实验结果表明，与HPC专门微调模型和其他检索增强方法相比，ReGraphT在CUDAEval和ParEval上的平均加速比达到2.33倍，且能与小型模型结合使用实现接近LLM级别的性能，同时降低隐私风险和计算成本。", "conclusion": "ReGraphT在CUDA优化中展示出卓越性能，通过检索增强的方法，使小型语言模型在保持低计算开销的同时达到与大型语言模型相近的性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19933", "html_url": "https://arxiv.org/abs/2510.19933", "title": "超越理想：分析不准确的Muon更新", "title_en": "Beyond the Ideal: Analyzing the Inexact Muon Update", "authors": "Egor Shulgin,Sultan AlRashed,Francesco Orabona,Peter Richtárik", "background": "Muon优化器迅速成为AdamW的强大替代品，尤其在大规模神经网络训练中表现出色。然而，理论与实践之间存在关键的不连续性：Muon的高效性依赖于快速近似正交化，但此前所有的理论工作都是基于理想化的、计算上不可行的版本，假定使用基于SVD的确切更新。本文突破了这一理想状态，首次分析了Muon核心部分不准确的正交化更新。研究开发了基于线性最小化或acles (LMO) 的优化框架，引入了现实的加性误差模型来捕捉实际近似方案中的不准确性。分析结果量化了LMO不准确性对性能的负面影响，并揭示了不准确性与最优步长和动量之间的基本耦合关系：较低的Oracle精度需要较小的步长但更大的动量参数。这些发现提高了近似过程（例如，Newton-Schulz步骤的数量）的重要性，使其成为必须与学习安排共同调整的关键参数。", "innovation": "本文首次分析了Muon优化器中不准确的正交化更新。提出了基于LMO的优化框架，并引入了现实的加性误差模型来捕捉实际近似过程中的不准确性。量化了LMO不准确性对性能的影响，并揭示了不准确性与最优步长和动量之间的基本耦合关系，降低了近似过程在优化中的常见性，提升了其重要性。", "conclusion": "通过引入LMO框架和加性误差模型，本文揭示了不准确性与最优步长和动量之间的关系，指出在实际应用中需要调整Oracle精度以优化性能，并通过NanoGPT实验直接验证了这些预测。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19950", "html_url": "https://arxiv.org/abs/2510.19950", "title": "金融中具有椭圆不确定性集的鲁棒强化学习：建模市场影响", "title_en": "Robust Reinforcement Learning in Finance: Modeling Market Impact with Elliptic Uncertainty Sets", "authors": "Shaocong Ma,Heng Huang", "background": "在金融应用中，强化学习（RL）代理通常在历史数据上进行训练，其操作不会影响市场价格。但在部署时，这些代理在实际市场中交易，其交易可以改变资产价格，这种现象称为市场影响。训练和部署环境之间的这种不匹配会显著降低性能。传统的鲁棒RL方法通过在不确定性集合上优化最坏情况下的性能来解决这一模型误设的问题，但它们通常依赖对称结构来捕捉市场的方向性影响效果不佳。", "innovation": "为了解决这个问题，我们开发了一类新的椭圆不确定性集。我们为这些集合下的最坏情况不确定性提供了隐式和显式的闭式解，这使得对策略的鲁棒性评估更加高效和易于解决。实验证明，我们的方法在单资产和多资产交易任务中实现了更高的夏普比率，并且在交易量增加时依然保持鲁棒性，提供了更加精准和可扩展的RL方法来应对金融市场的长期挑战。", "conclusion": "我们的方法在面对不断增长的交易量时仍然保持了鲁棒性，实现了高性能的夏普比率，提供了一种更真实和可扩展的RL方法来处理金融市场中的长期挑战。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19953", "html_url": "https://arxiv.org/abs/2510.19953", "title": "零阶优化中无偏梯度估计器的最优构建", "title_en": "On the Optimal Construction of Unbiased Gradient Estimators for Zeroth-Order Optimization", "authors": "Shaocong Ma,Heng Huang", "background": "零阶优化(ZOO)是一种在无法获得或计算梯度昂贵时进行随机优化的重要框架。现有ZOO方法的一个潜在限制在于大多数梯度估计器都存在偏差，除非扰动步长趋近于零。本文旨在克服这一偏差问题，提出了一种仅基于函数评估的新颖的无偏梯度估计器家族。通过将方向导数重新公式化为首尾相接的级数，并从精心设计的分布中采样，构建了消除偏差同时保持良好方差的估计器。本文分析了这些估计器的理论性质，推导出四种特定构建方法的最优比例分布和扰动步长，并证明使用提出的估计器的SGD在光滑非凸目标上实现了最优复杂度。实验表明，该方法在合成任务和语言模型微调中的准确性和收敛性优于标准方法。", "innovation": "提出了一种新的无偏梯度估计器家族，通过重新公式化方向导数为首尾相接的级数和精心设计的分布采样，构造了消除偏差且方差可控的估计器。", "conclusion": "提出的估计器构建方法在理论上证明了最优性，并在实际任务中的性能超越了标准方法，证明了SGD使用这些估计器在光滑非凸目标上实现了最优复杂度。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19977", "html_url": "https://arxiv.org/abs/2510.19977", "title": "向更强大的通用非对称随机化方法迈进以实现稳健防御", "title_en": "Towards Strong Certified Defense with Universal Asymmetric Randomization", "authors": "Hanbin Hong,Ashish Kundu,Ali Payani,Binghui Wang,Yuan Hong", "background": "随机化平滑已成为在机器学习模型中实现认证对抗鲁棒性的关键方法。然而，现有的方法主要采用各向同性的噪声分布，这种分布均匀覆盖所有数据维度（如图像像素），这限制了鲁棒性认证的效果，因为它忽略了输入和数据维度之间的异质性。", "innovation": "本文提出了UCAN：一种新颖的方法，称为UCAN：普遍的非对称噪声认证对抗鲁棒性。UCAN旨在增强现有的随机化平滑方法，将它们从对称（各向同性）噪声分布转换为非对称（各向异性）噪声分布，从而提供针对对抗攻击的更定制化防御。此外，还开发了一种新的框架，配备三种示例噪声参数生成器（NPGs），以优化调整不同数据维度下的非对称噪声参数。", "conclusion": "评估结果表明UCAN在性能上相较于现有最先进的方法有显著提升，在MNIST、CIFAR10和ImageNet数据集上认证准确率在大认证半径下提高高达182.6%，进一步证实了其有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19917", "html_url": "https://arxiv.org/abs/2510.19917", "title": "FINDER: 使用特征残差的噪声数据特征推断", "title_en": "FINDER: Feature Inference on Noisy Datasets using Eigenspace Residuals", "authors": "Trajan Murphy,Akshunna S. Dogra,Hanfeng Gu,Caleb Meredith,Mark Kon,Julio Enrique Castrillion-Candas", "background": "噪声数据集（信号与噪声比低、样本量小、数据收集错误等）仍是对分类方法研究的一个关键前沿领域，具有重要的理论和实践意义。现有的分类方法往往难以处理这类数据集中的随机性。为解决这一问题，本文提出了一种名为FINDER的框架，专门针对噪声数据集设计了适应算法。FINDER框架通过将数据集视为来自未假设确切分布的底层随机场的实现，并将其映射到适当的希尔伯特空间中来推断特征，进而使用科森-卡伦-洛依展开将其分解为可计算的不可约组件，最终通过特征分解进行分类。", "innovation": "FINDER框架通过引入随机场和特定的特征分析方法，将噪声数据集中的随机性系统地进行建模和处理，这种方法利用Kosambi-Karhunen-Loéve展开将其分解为可以计算的不可约组件，并通过特征分解实现分类。该方法被用于多种科学领域的挑战性数据不足问题，取得了领先的研究成果，尤其是在阿尔茨海默病分期和遥感检测森林砍伐方面。", "conclusion": "FINDER框架在某些情况下预期能够优于现有的方法，但在特定条件下也可能失效。该方法提供了一种处理噪声数据集的新策略，并指出未来研究与改进的方向。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19975", "html_url": "https://arxiv.org/abs/2510.19975", "title": "重新审视零阶优化：最小方差两点估计器和方向对齐扰动", "title_en": "Revisiting Zeroth-Order Optimization: Minimum-Variance Two-Point Estimators and Directionally Aligned Perturbations", "authors": "Shaocong Ma,Heng Huang", "background": "论文探讨了两点零阶梯度估计器，并确定了随机扰动的分布，使得估计器的渐近方差在扰动步长趋近于零时最小化。现有研究主要关注固定长度的扰动，而忽略了方向对齐可能带来的优势。其他现有工作也大多集中在固定长度的扰动上，但对方向对齐扰动的理论和实证性质研究不足。因此，本文进一步研究了方向对齐扰动（DAP）方案的理论和实证性质及其对随机梯度下降的影响，并通过理论分析和实证评估发现DAP在特定条件下优于传统方法。", "innovation": "研究了两点零阶梯度估计器的方向对齐扰动方案，开发了最小方差的扰动分布形式，并提供了适用于 δ-无偏随机扰动的随机梯度下降的收敛性分析。该方案能在关键方向上提供更高的准确性，通过实证研究证明了DAP在特定条件下的优越性。", "conclusion": "作者通过理论和实证研究证明了方向对齐扰动（DAP）能够在特定条件下显著改善零阶优化方法的性能。该研究扩展了现有对零阶优化的理解，并提供了新的优化策略以提高算法的准确性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19990", "html_url": "https://arxiv.org/abs/2510.19990", "title": "放弃计算资源：重新思考带有掩码扩散模型的推理与采样", "title_en": "No Compute Left Behind: Rethinking Reasoning and Sampling with Masked Diffusion Models", "authors": "Zachary Horvitz,Raghav Singhal,Hao Zou,Carles Domingo-Enrich,Zhou Yu,Rajesh Ranganath,Kathleen McKeown", "background": "当前讨论的焦点是掩码扩散语言模型（MDLMs）在填充值位置时与下一个令牌预测模型的区别，特别是在数学和编程任务中观察到的任意顺序算法表现不如从左到右的抽样，以及标准的多令牌解码对性能的负面影响。", "innovation": "提出了两种新方法：1）推理即填充（Reasoning-as-infilling），通过将MDLM用于填充推理模板，能够结构化输出并区分推理和答案令牌，在推理中测量答案不确定性，并在模型收敛于答案时提前退出。此外，根据答案推理，该方法可从答案条件下的MDLM后验中采样推理痕迹，从而提供高质量的数据来源进行后续训练。2）多令牌熵解码（MED），这是一种简单的自适应采样器，其最小化了并行解码时给定位置条件熵的错误，减少了步数。", "conclusion": "研究表明，MDLMs的训练和计算可以解锁许多新的推理和后训练方法。例如，在GSM8k上，使用其后验推理轨迹对LLaDA-8B Base进行微调，其性能提升与使用人类书写的推理轨迹进行微调相当；并且该方法减少了2.7倍的步骤数。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20019", "html_url": "https://arxiv.org/abs/2510.20019", "title": "基于RSSI决策树和CAD建模的RFID传感器网络的机器学习定位精度研究及其在军事应用中的应用", "title_en": "Machine Learning-Based Localization Accuracy of RFID Sensor Networks via RSSI Decision Trees and CAD Modeling for Defense Applications", "authors": "Curtis Lee Shull,Merrick Green", "background": "RFID技术可用于军事资产的跟踪和管理，但传感器的非特异性（包括远程检测、欺骗和冒充）可能导致错误的检测结果，影响操作安全。本文使用监督学习仿真模拟，结合CAD模型和真实RSSI数据，探讨了决策树分类在军事存储环境中的应用。研究者特别关注将12个实验室区域分为类别进行位置推断，旨在评估RSSI数据驱动的决策树模型在军事环境中的分类性能，以及如何将其用于军事供应物流中的区域异常检测或错误定位监测。", "innovation": "创新之处在于将决策树分类嵌入RSSI数据和CAD建模中，并在现实仿真环境中进行评估。通过对不平衡的类别进行加权处理，研究者探索了如何提高在覆盖范围低和信噪比低的区域中分类的可靠性，并提出了改善策略，如优化天线位置或增加传感器数量。这为改进军事资产存储管理的高精度定位提供了新思路，并增强了实际应用中的功能性和实用性。", "conclusion": "该研究表明，基于RSSI的决策树可以应用于现实仿真的区域异常检测或错误定位监测，并提出改进方案（例如重新布局天线、增加传感器或与其他模式的传感器融合），以提高在覆盖范围低和信噪比低的区域中的分类性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19980", "html_url": "https://arxiv.org/abs/2510.19980", "title": "Abstain Mask Retain Core: 通过自适应掩码损失与表示一致性进行时间序列预测", "title_en": "Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency", "authors": "Renzhao Liang,Sizhe Xu,Chenggang Xie,Jingru Chen,Feiyang Ren,Shu Yang,Takahiro Yabe", "background": "时间序列预测在能源管理和金融市场等关键领域中扮演着至关重要的角色。尽管基于深度学习的方法（如MLP、RNN、Transformer）取得了显著进展，但现有的“长序列信息增益假说”存在内在局限性。通过系统的实验，研究揭示了一个反直觉的现象：适当截断历史数据反而可以提升预测准确性，这表明现有模型在训练过程中学习了大量的冗余特征（如噪声或无关波动），从而影响了有效信号的提取。", "innovation": "本研究基于信息瓶颈理论，提出了一个新的创新性解决方案，称为自适应掩码损失与表示一致性（AMRC），该方案包括两大核心组件：1）动态掩码损失，这种动态掩码损失可以自适应地识别高区分度的时间段，从而在模型训练期间引导梯度下降；2）表示一致性约束，这种约束机制稳定了输入、标签和预测之间的映射关系。实验证明，AMRC 能够有效地抑制冗余特征的学习，显著提高模型性能。此外，这项工作不仅挑战了时间建模中的常规假设，还提供了有关开发高效且稳健的预测模型的全新理论见解和方法突破性策略。", "conclusion": "这项工作不仅挑战了时间建模中的常规假设，还提供了新的理论见解和方法论突破，为开发高效的稳健预测模型提供了新的思路。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20028", "html_url": "https://arxiv.org/abs/2510.20028", "title": "比特币交易的时间图", "title_en": "The Temporal Graph of Bitcoin Transactions", "authors": "Vahid Jalili", "background": "自2009年问世以来，比特币网络已经处理了超过10.8亿笔交易，价值超过872亿比特币，这些数据蕴含了丰富的机器学习（ML）潜力；然而，得益于其基于UTXO（未花费交易输出）的设计，比特币的匿名性以及资金流动的模糊性使得这些数据难以用于ML研究。", "innovation": "该研究提出了一个兼容机器学习的图形模型，通过重建资金流动来描绘比特币的经济拓扑结构。该图是一个包括所有交易历史的时间异构图，直至第cutoffHeight个区块，包含超过24亿个节点和397.2亿条边。此外，还提供了定制的采样方法，生成采样社区的节点和边特征向量，并提供了在专门图形数据库中加载和分析比特币图数据的工具及现成的数据库快照。", "conclusion": "该全面的数据集和工具包使ML社区能够大规模研究比特币的复杂生态系统，推动了异常检测、地址分类、市场分析以及大规模图形ML基准测试等应用的进展。该数据集和代码可在[此处]获得。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20022", "html_url": "https://arxiv.org/abs/2510.20022", "title": "SALT: 通过轨迹图在长时延代理中进行步骤级优势分配", "title_en": "SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph", "authors": "Jiazheng Li,Yawei Wang,David Yan,Yijun Tian,Zhichao Xu,Huan Song,Panpan Xu,Lin Lee Cheong", "background": "大型语言模型（LLMs）展示了令人惊叹的能力，使得语言代理在单一回合任务中表现出色。然而，将这些模型应用于复杂的、多步骤的和长期的任务仍然具有挑战性。尽管强化学习（RL）提供了一种有希望的方法来解决这些问题，主流方法通常依赖于稀疏的结果奖励，这会对缺乏批评模型的基于组的RL算法（如GRPO）特别构成问题。这类方法中，对轨迹内的所有动作进行统一的奖励或惩罚会导致训练不稳定性和次优策略，因为有益和有害动作往往在多步骤交互中交织在一起。因此，本文讨论了SALT框架，它通过构建相同提示的轨迹图来实现步骤级的优势分配，以解决上述挑战并证明了其有效性。", "innovation": "SALT提出了一个新颖且轻量级的框架，它通过从结果奖励中提取更精细的优势分配，解决了基于组的RL算法在多步交互中奖励分配的问题。SALT设计成为一个插件模块，可以无缝集成到现有的组基RL算法中，无需修改回放过程并且引入的计算开销很小。实验证明SALT在WebShop、ALFWorld和AppWorld基准测试中具有显著改进，并且对SALT的设计选择进行了深入分析，提供了实际可行的见解。", "conclusion": "本文通过SALT框架证明了，通过构建轨迹图进行步骤级的优势分配可以有效解决多步骤和长期任务中的奖励分配问题。实验证明SALT能够提高基于组的RL算法的性能，并且该方法设计灵活、易于集成。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20055", "html_url": "https://arxiv.org/abs/2510.20055", "title": "通过条件强化学习在延迟奖励下的个性化广告影响学习", "title_en": "Learning Personalized Ad Impact via Contextual Reinforcement Learning under Delayed Rewards", "authors": "Yuwei Cheng,Zifeng Zhao,Haifeng Xu", "background": "在线广告平台使用自动化拍卖将广告商与潜在客户连接起来，需要有效的竞价策略以最大化利润。准确的广告影响估计需要考虑三个关键因素：延迟和长期效果、累积广告影响（如强化或疲劳效应）以及客户异质性。然而，这些因素通常在先前的研究中没有共同处理。", "innovation": "本文建立了广告竞价的条件马尔可夫决策过程模型，并结合延迟泊松奖励。提出了一种两阶段最大似然估计器结合数据分割策略，以提升估计效率，并基于第一阶段估计器的准确性控制估计误差。在此基础上，设计了一种强化学习算法来推导有效的个性化竞价策略。", "conclusion": "该方法达到了近最优的遗憾界 $\tilde{O}(dH^2\root \frac{T}{}}$，其中 $d$ 是条件维度，$H$ 是轮数，$T$ 是客户数量。理论发现通过模拟实验得到了验证。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20064", "html_url": "https://arxiv.org/abs/2510.20064", "title": "Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs", "title_en": "Not-a-Bandit: Provably No-Regret Drafter Selection in Speculative Decoding for LLMs", "authors": "Hongyi Liu,Jiaji Huang,Zhen Jia,Youngsuk Park,Yu-Xiang Wang", "background": "规格化解码在加速大规模语言模型（LLM）推理中被广泛使用。本文聚焦于规格化解码中的在线草稿模型选择问题，设计了一个能够证明在回顾最优草稿模型的情况下，在每次查询时能与最优草稿模型在词接受概率或预期接受长度上竞争的算法。该算法可以在不需要额外查询目标模型的情况下准确评估所有草稿模型，从而在草稿模型数量增加时，相比现有基于 bandit 的方法有指数级别的提升。", "innovation": "设计了一个能够在无需额外查询目标模型的情况下准确评估所有草稿模型的算法，能够证明在每次查询时与最优草稿模型在词接受概率或预期接受长度上竞争。此外，该方法适用于任何规格化解码方法（单一草稿、多个草稿和草稿树），并且设计了系统高效版本的在线学习者，显著减少了计算和延迟的开销。这种方法在多种领域中优于现有的最先进的方法EAGLE3和BanditSpec基准，尤其是在需要长推理链时表现尤为出色。", "conclusion": "通过系统的实验，证明了所提出的方法在多种开源LLM和数据集上优于现有的最先进的方法EAGLE3和BanditSpec基准，特别是在需要长推理链时的表现尤为出色。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20031", "html_url": "https://arxiv.org/abs/2510.20031", "title": "推测采样方法在参数化时间点过程中的应用", "title_en": "Speculative Sampling for Parametric Temporal Point Processes", "authors": "Marin Biloš,Anderson Schneider,Yuriy Nevmyvaka", "background": "时间点过程是一种强大的生成模型，用于捕捉时间序列数据中的复杂时间依赖关系。这类模型通常通过自回归模型来指定，通过学习下一事件的概率分布来基于前一事件。然而，这种方式使得采样具有固有的顺序性，限制了效率。因此，论文探讨如何在不改变架构或重新训练的情况下，实现对已存在的时间点过程模型进行并行高效的采样，优化了先前存在的顺序采样方法，提供了一种新的算法应用于推测性采样。", "innovation": "提出了一种基于拒绝采样的新算法，该算法允许并行地从现有的时间点过程模型中采样多个未来值，而无需进行任何架构上的更改或重新训练。实验表明，该方法在真实数据集上实现了实际的速度提升，有效地平衡了具备强大表达性的建模需求和大规模并行生成的需求。", "conclusion": "本文提出了一种新的算法，通过拒绝采样的方式，能够在不改变模型架构的情况下，实现并行高效的从已存在的时间点过程模型中进行采样，从而提升大型时间点过程应用的效率。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20068", "html_url": "https://arxiv.org/abs/2510.20068", "title": "耦合变换器自动编码器用于分离多区域神经潜在动态", "title_en": "Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics", "authors": "Ram Dyuthi Sristi,Sowmya Manojna Narasimha,Jingya Huang,Alice Despatin,Simon Musall,Vikash Gilja,Gal Mishne", "background": "现有的对齐或多视图方法忽略了时间结构，而动态潜在变量模型能够捕捉时间依赖性，但通常只限于单个区域，假设线性读出，或者混淆共享和特定的信号。本文分析了来自成千上万神经元在多个脑区的同步记录，揭示了丰富的共享于区域之间以及局限于每个区域的独特神经活动模式。", "innovation": "提出了耦合变换器自动编码器（CTAE），这是一种序列模型，它同时解决了两个问题：非稳态的非线性动力学和在单一框架中分离共享以及区域特定结构。CTAE使用变换器编码器和解码器捕捉长程的神经动力学，并明确地将每个区域的潜在空间分割为正交的共享和私有子空间。", "conclusion": "CTAE在两个高密度电解生理学数据集上得到了验证，其中一个来自运动皮层区域，另一个来自感觉区域。CTAE能够提取能更好地解码行为变量的有意义表示，相较于现有方法更有优势。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20066", "html_url": "https://arxiv.org/abs/2510.20066", "title": "多层机器学习和计量经济学管道：加密资产流动性溢出对市场风险预测的证据", "title_en": "A Multi-Layer Machine Learning and Econometric Pipeline for Forecasting Market Risk: Evidence from Cryptoasset Liquidity Spillovers", "authors": "Yimeng Qiu,Feihuang Fang", "background": "本文研究了核心加密资产的流动性和波动性代理是否可以产生能够预测市场风险的溢出效应。通过将三个统计层集成到实证框架中：A) 流动性和回报之间的相互作用，B) 流动性和回报之间的主成分关系，以及C) 反映横截面波动性拥挤的波动因子预测，以研究这些关系。分析方法还包括向量自回归脉冲响应、预测误差方差分解以及HAR-X模型和一种以时间分割、提前停止、验证阈值和SHAP为基础解释为特征的泄漏安全机器学习协议。使用2021年至2025年间的日数据（共74种资产，1462个观测值）进行分析，结果表明不同层之间存在统计上显著的Granger因果关系，且具有适度的外样本预测准确性。", "innovation": "本文所提的多层机器学习流程和计量经济学管道结合了数据驱动方法和统计技术，以研究加密资产流动性溢出对市场风险预测的影响。引入了剔除泄露的机器学习协议和基于SHAP的解释方法，提升了模型的可靠性和透明度，同时通过向量自回归脉冲响应和预测误差方差分解来增强方法的深入性。这种集成的分析框架既可用于加密资产领域，也可扩展到其他金融市场领域，为市场风险预测提供了新的视角。", "conclusion": "研究结果证明了加密资产流动性溢出效应对市场风险预测的重要性。尽管各个层之间存在显著的Granger因果关系，且模型在外汇检定时显示出了适度的预测准确性，但仍存在提升的空间。未来的研究可以进一步完善模型并探索更多加密资产流动性因素引起的市场风险预测方法。同时，提供的完整数据和图可以帮助验证和扩展本文提出的模型。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20085", "html_url": "https://arxiv.org/abs/2510.20085", "title": "基于MentalRoBERTa的分层双头模型用于自杀风险评估", "title_en": "Hierarchical Dual-Head Model for Suicide Risk Assessment via MentalRoBERTa", "authors": "Chang Yang,Ziyi Wang,Wangfeng Tan,Zhiting Tan,Changrui Ji,Zhiming Zhou", "background": "社交媒体平台已成为识别自杀风险的重要来源，但自动检测系统面临严重类别不平衡、帖子发布模式的时间复杂性和风险水平作为有序和类别数据的双重性质等多重挑战。", "innovation": "提出了一种基于MentalRoBERTa的分层双头神经网络，该网络用于将自杀风险分类为四个级别：指标、意念、行为和企图。模型包含两个互补的预测头，分别保留风险级别之间的有序关系并进行灵活的类别区分。同时，采用3层Transformer编码器和8头多头注意力机制来建模帖子序列间的时序依赖性，并引入显式时间间隔嵌入来捕捉发帖行为动态。此外，采用结合损失函数（0.5 CORAL + 0.3交叉熵 + 0.2焦点损失）来同时解决有序结构保持、过度自信减少和类别不平衡等问题。", "conclusion": "该模型通过五折分层交叉验证进行评估，主要使用宏F1分数进行评价，并通过冻结MentalRoBERTa的前6层（50%）和使用混合精度训练来提高计算效率。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20084", "html_url": "https://arxiv.org/abs/2510.20084", "title": "ShapeX: 基于形状子模式的时序分类模型后验解释框架", "title_en": "ShapeX: Shapelet-Driven Post Hoc Explanations for Time Series Classification Models", "authors": "Bosong Huang,Ming Jin,Yuxuan Liang,Johan Barthelemy,Debo Cheng,Qingsong Wen,Chenghao Liu,Shirui Pan", "background": "在高风险应用场景如医疗和金融中，解释时序分类模型至关重要，因为透明度和信任至关重要。尽管许多时序分类方法已经确定了形状子模式作为关键特征，以达到最先进的性能并验证其在分类结果中的关键作用，但现有的后验解释方法主要集中在时间步级特征归因上。这些方法忽视了分类结果主要由关键形状子模式驱动的基本前提。因此，本文提出了一种名为ShapeX的创新框架，该框架通过形状驱动的段将时序数据分成有意义的片段，并使用Shapley值评估其显著性。ShapeX的核心是形状子模式描述与检测（SDD）框架，该框架有效学习了分类所需的多样性形状子模式集。实验结果表明，ShapeX在识别最相关的子序列方面优于现有方法，提高了时间序列解释的精确性和因果准确性。", "innovation": "提出了一种名为ShapeX的创新框架，通过形状驱动的段将时序数据分成有意义的片段，并使用Shapley值评估其显著性。核心是形状子模式描述与检测（SDD）框架，有效学习了多样性形状子模式集。通过形状子模式的原子性属性，ShapeX揭示了因果关系而非仅仅相关性。实验表明ShapeX在识别最相关的子序列方面优于现有方法。", "conclusion": "ShapeX在合成和真实数据集上的实验结果表明，它在识别最相关的子序列方面优于现有方法，增强了时序解释的精确性和因果准确性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20106", "html_url": "https://arxiv.org/abs/2510.20106", "title": "竞争是关键：基于博弈的因果发现方法", "title_en": "Competition is the key: A Game Theoretic Causal Discovery Approach", "authors": "Amartya Roy,Souvik Chakraborty", "background": "因果发现仍然是机器学习中的一个重要挑战。现有的方法存在一个根本性的缺陷：诸如GES和GraN-DAG等算法尽管在实证性能上表现出色，但在有限样本大小的情况下缺乏保证。而理论上更严谨的方法又无法扩展。这些方法之间的差距并未被填补。", "innovation": "本文通过引入一种基于博弈的强化学习框架来进行因果发现。在这个框架中，一个双重DQN（DDQN）代理直接与强基线（如GES或GraN-DAG）竞争，并且总是从对手的解决方案开始，从而提供三个可证明的保证：学习到的图不可能比对手的还要差，热启动可严格加速收敛，更重要的是，算法以高概率会选择正确的最优候选图。这种方法首次解决了因果发现的有限样本保证问题。", "conclusion": "这些结果建立了新的以强化学习为基础的因果发现算法类，该类算法在同一时间具有可证明的一致性、样本高效性和实际的可规模化性，为将实证性能与严谨的有限样本论点统一迈出了重要的一步。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20107", "html_url": "https://arxiv.org/abs/2510.20107", "title": "使用加权维度进行模式分类", "title_en": "On pattern classification with weighted dimensions", "authors": "Ayatullah Faruk Mollah", "background": "在处理多维度样本的多种应用场景下，模式分类的不同方面往往非常重要。其中一个关键是加权维度基于距离测量，因为它反映了样本间的相似程度。尽管欧几里得距离在许多情况下被认为是标准选择，但仍然存在许多问题。本文通过详细分析距离度量规范、维度权重及其视觉展示、提出了一个新的维度加权方案，并将其整合进KNN分类器中，展示了在多种合成以及实际数据集上的模式分类性能，与传统KNN相比表现良好。", "innovation": "本文创新性地提出了一个基于Minkowski距离的加权维度方案，并将其应用于KNN分类器，具体包括以下几个方面：(a) 详细分析了距离度量规范和维度权重的影响；(b) 提出了一种新的维度加权方案；(c) 将这一维度权重方案整合进KNN分类器中；(d) 在多种合成及实际数据集上进行了模式分类实验，特别是对基因表达数据集，获得了显著且一致的分类准确性提升。", "conclusion": "该方法在各种实验中均表现出色，特别是在基因表达数据集分类任务中，实现了显著且一致的分类效果提升（约10%）。由于这些数据集通常包含高维度且样本数量有限，因此有效地选择最近邻居变得非常重要。通过调节包含参考样本区域的形状和大小，本文提出的加权方案能够满足这一需求，使其成为传统KNN的一种重要扩展，利用加权Minkowski距离和当前权重方案实现分类器性能的提升。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20119", "html_url": "https://arxiv.org/abs/2510.20119", "title": "时序中的‘苹果’不存在：基于不变性的时序基础模型重新思考", "title_en": "There is No \"apple\" in Timeseries: Rethinking TSFM through the Lens of Invariance", "authors": "Arian Prabowo,Flora D. Salim", "background": "虽然时序基础模型（TSFMs）的数量大量增加，但轻量级的监督基线甚至经典的模型往往能与它们竞争。作者认为这一差距源于从自然语言处理（NLP）或计算机视觉（CV）管道的直接移植。在语言和视觉领域，大规模的网络数据密集地捕捉到了人类概念，比如有大量的苹果图像和文本。然而，时序数据是为补充图像和文本模态设计的，不存在包含‘苹果’概念的时序数据集。因此，‘抓取一切在线’的策略对时序数据（TS）不适用。", "innovation": "本文提出了将时序不变性从第一原理构建的思路，建议通过确保表示的完备性（即通过不变性的覆盖）来构建系统性的数据集，这些数据集能跨越不变性的空间并保持时间语义。这一建议旨在推动时序基础模型的发展，使其能够实现必要的一致结构，从而实现泛化、推理和真正的涌现行为。", "conclusion": "本文的观点表明，时序基础模型的进步需要从机会主义聚合转向原则化设计，即构建系统的数据集，系统地覆盖不变性的空间，以保持时间语义。这种变化是为了使时序基础模型具备泛化、推理和真正涌现的行为的结构要求。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20169", "html_url": "https://arxiv.org/abs/2510.20169", "title": "为大规模TSP赋能的基于超路径的目标邻域搜索", "title_en": "Empowering Targeted Neighborhood Search via Hyper Tour for Large-Scale TSP", "authors": "Tongkai Lu,Shuai Ma,Chongyang Tao", "background": "旅行商问题（TSP）是一个经典的NP难问题，受到了学术界和业界的广泛关注。尽管基于神经网络的方法在解决TSP问题上表现出了一定的潜力，但在处理大规模实例时仍然面临挑战，特别是在内存约束、全球热图、边权重或访问矩阵相关的限制，以及生成高质量初始解和缺乏有效的全局指导方面。", "innovation": "本文提出了一种用于大规模TSP实例的超路径引导邻域搜索（HyperNS）方法。该方法通过逐步簇合节点，将TSP实例的节点划分为超节点，基于超路径生成路线，从而缩小搜索空间，提高初始解的质量，并提供有效的全局指导，增强优化过程的效率和效果。", "conclusion": "实验结果表明，我们的方法在合成数据集和真实世界数据集上均优于现有的基于神经网络的方法，特别是在处理大规模TSP实例时，显著减少了与最优解的差距。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20200", "html_url": "https://arxiv.org/abs/2510.20200", "title": "近似可重复性在学习中的应用", "title_en": "Approximate Replicability in Learning", "authors": "Max Hopkins,Russell Impagliazzo,Christopher Ye", "background": "论文引入了一个名为可重复性的概念，该概念最初由Impagliazzo等人在2022年的ACM STOC会议上提出。可重复性意味着算法在有共享随机性的条件下，对输入进行抽样重新生成时应当保持稳定。虽然这是一个强有力的稳定性概念，但实现起来却成本高昂。例如，对于阈值学习这样简单的任务，没有完全可重复的算法（Bun等人在2023年的ACM STOC会议上证明了这一点）。因此，为了克服这个难题，论文探讨了哪些近似的可重复性概念能够让学习成为可能。", "innovation": "作者提出了三种可重复性的自然放宽定义，以适用于PAC学习：(1) 点啊式：学习器对于任何固定的输入必须一致，但不必同时在所有输入上保持一致；(2) 近似：学习器必须输出能够大多数情况下对分布分类一致的假设；(3) 半可重复：算法完全可重复，但还可以使用共享的未标记样本。对于常数级别的可重复性参数，所有情况下都能获得样本最优的无假设泛化的学习者。(1) 和 (2) 可以免费实现，且需要$\theta(d/\beta^2)$个样本，而(3) 则需要$\theta(d^2/\beta^2)$个标记样本。", "conclusion": "总之，即使放宽了可重复性的严格要求，仍然可以找到有效的学习算法。这为实现在限制条件下学习提供了理论支持，并为研究者提供了新的研究方向。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20187", "html_url": "https://arxiv.org/abs/2510.20187", "title": "每一个问题都有其自身的价值：显式人类价值的强化学习", "title_en": "Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values", "authors": "Dian Yu,Yulai Zhao,Kishan Panaganti,Linfeng Song,Haitao Mi,Dong Yu", "background": "现有的强化学习方法，如带有可验证奖励的强化学习（RLVR），通过二元正确性奖励有效地训练模型于客观领域。然而，这种方法未能认识到并非所有任务具有相同的重要性。该论文介绍了Reinforcement Learning with Explicit Human Values (RLEV)，这是一种直接将大语言模型（LLM）优化与量化的人类价值信号对齐的方法。使用有明确正确值标签的考试样例数据，RLEV 在多个强化学习算法和模型规模上，持续优于仅基于正确性的基线模型。实验结果表明，RLEV 不仅提高了价值加权准确性，还学习到了一种价值敏感的终止策略：对于低价值提示简洁，对于高价值提示详细。", "innovation": "RLEV 引入了人类定义的价值信号直接进入奖励函数中，从而超越了仅以正确性为奖励的基线方法。更重要的是，研究表明这种策略导致了对序列结束标记的价值加权梯度放大，并且经过消融实验验证了这种增益与价值对齐因果相关。此外，RLEV 能够在嘈杂价值信号下保持稳健，且优化明确的实用函数为对齐大模型与人类优先级提供了一条实际路径。", "conclusion": "RLEV 方法不仅提高了价值加权准确性，还学习到了一种价值敏感的终止策略，并且在噪声价值信号下仍然表现稳健。这表明优化明确的实用函数是实现大模型与人类优先级对齐的有效途径。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20148", "html_url": "https://arxiv.org/abs/2510.20148", "title": "通过多层建模理解结构和功能连接在tau传播中的机制作用", "title_en": "Understanding Mechanistic Role of Structural and Functional Connectivity in Tau Propagation Through Multi-Layer Modeling", "authors": "Tingting Dan,Xinwei Huang,Jiaqi Ding,Yinggang Zheng,Guorong Wu", "background": "新兴的神经影像学证据表明，病理性tau蛋白沿着特定的脑网络进行积累，这暗示了大型网络架构在阿尔茨海默病(AD)进展中扮演关键角色。然而，结构连接(SC)和功能连接(FC)如何相互作用以影响tau的传播尚不清楚。利用前所未有的纵向神经影像学数据量，通过多层图扩散模型考察了SC-FC的相互作用。研究表明，图架构限制了tau的传播，同时发现SC和FC在传播区域上的不对称贡献。SC和FC在不同脑区主导tau传播的能力存在差异，并且在疾病过程中这种主导性关系会随阶段改变。这些脑区的SC-FC主导模式与与AD相关的炎症、凋亡和溶酶体功能有关的基因表达区位高度吻合。其他不可改变的风险因素（如APOE基因型、性别）及其他生物学机制（如淀粉样蛋白沉积）则以区域特异性方式重塑tau传播路径，选择性地调整主导路径之间的转归。这些发现通过独立的AD队列进行了验证.", "innovation": "通过多层图扩散模型，展示了SC和FC在tau传播中相互作用的具体模式，揭示了它们在不同脑区的贡献差异，并发现了随着疾病阶段变化主导关系的转变。此外，研究结果还与AD相关的基因表达有一定的吻合性，进一步阐明了SC和FC对tau传播的影响机制.", "conclusion": "SC和FC对tau传播的影响具有空间特异性，它们在不同大脑区域的主导性在疾病进展过程中会有所变化。结构连接主要在后脑、顶叶和边缘系统中发挥更大作用，而功能连接则主要在基底节、岛叶、前额叶和颞叶中的作用更为显著。这些模式与炎症、凋亡和溶酶体功能相关的基因表达区域契合，提示了这两种连接方式在tau传播过程中的不同机制。此外，其他不可改变的风险因素和生物学机制会通过改变神经解剖和功能通路的主导路径来调节tau传播，显示出区域特异性的调节模式。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20108", "html_url": "https://arxiv.org/abs/2510.20108", "title": "原型为何崩溃：诊断和预防原型自监督学习中的部分崩溃现象", "title_en": "Why Prototypes Collapse: Diagnosing and Preventing Partial Collapse in Prototypical Self-Supervised Learning", "authors": "Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera", "background": "自监督学习中的原型方法常常遭遇原型部分崩溃的问题，即多个原型收敛到近乎相同的表现形式。这种状况削弱了这些方法的核心目的——提供多样化且具信息量的目标以引导编码器探寻丰富的表示。实践者不得不采取过度参数化或添加临时正则化的方法来缓解症状，但这些方法并未从根源解决根本问题。研究者发现这种崩溃与编码器与原型的联合优化有关，这种优化鼓励了一种捷径学习的模式：在早期训练阶段，原型会朝向冗余表示移动，这种表示虽然能最小化损失但不一定有助于多样性表示的提升。", "innovation": "为了解决这一问题，研究提出了一种完全解耦的训练策略，使得原型和编码器在不同的目标下分别学习。具体而言，原型被建模为高斯混合模型，并通过在线EM风格的程序进行更新，这一过程与编码器的损失无关。这种方法在不使用显式正则化的情况下消除了原型崩溃，得到了更具有多样性和下游性能更强的原型.", "conclusion": "研究表明，通过解耦原型和编码器的训练过程，可以有效避免原型部分崩溃的问题，从而提升自监督学习的表现。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20199", "html_url": "https://arxiv.org/abs/2510.20199", "title": "使用优化的确定性等价进行风险厌恶约束强化学习", "title_en": "Risk-Averse Constrained Reinforcement Learning with Optimized Certainty Equivalents", "authors": "Jane H. Lee,Baturay Saglam,Spyridon Pougkakiotis,Amin Karbasi,Dionysis Kalogerias", "background": "约束优化提供了一种处理强化学习中相互冲突目标的通用框架。多数情况下，目标（及其约束）通过预期累积奖励来表达。然而，这种表达方式忽略了奖励分布尾部的风险性或可能灾难性事件，并且在高风险背景下通常是不足的，尤其是在涉及意外风险的极端情况中，风险控制至关重要。此前的某些工作只考虑了期望值，而未涵盖风险厌恶的要素和尾部风险。本研究旨在提供一种新的风险意识强化学习框架，该框架同时在奖励值和时间上具备每阶段的鲁棒性，并通过优化的确定性等价来精确定量。在适当的核心约束条件下，该框架在参数化的强拉格朗日对偶框架下精确等同于原始约束问题，并提供了可用于现有RL求解器如PPO的简单算法配方。该框架确保了算法的有效性和效率，并且更容易应用于实际问题。此外，通过常见假设下算法的收敛性分析来验证提出方法的有效性，并通过多个数值实验验证了风险意识属性的有效性，这使得更严格的风险评估成为可能。", "innovation": "提出了一个风险意识的约束强化学习框架，该框架结合优化的确定性等价，在奖励值和时间上实现每阶段的鲁棒性，并结合参数化的强拉格朗日对偶框架，确保原始问题的精确等价性。这一框架可以被嵌入到标准的强化学习求解器中，提供简单有效的算法配方，例如PPO。并通过理论分析和实验验证了其在高风险背景下的有效性和鲁棒性。", "conclusion": "证明了所提算法在常见假设下的收敛性，并通过数值实验验证了风险意识框架的有效性和鲁棒性，展示了该方法在高风险应用中的切实可行性和高效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20209", "html_url": "https://arxiv.org/abs/2510.20209", "title": "利用常规实验室数据评估早期癌症检测的可行性：不平衡数据集上的机器学习方法评估", "title_en": "Assessing the Feasibility of Early Cancer Detection Using Routine Laboratory Data: An Evaluation of Machine Learning Approaches on an Imbalanced Dataset", "authors": "Shumin Li", "background": "在兽医医学中，开发易于访问的筛查工具以实现对狗的早期癌症检测是一个重大挑战。常规实验室数据可能是一个低成本的潜在来源，但由于单个生物标志物的非特异性及其筛查人群中固有的分类不平衡，因此实用性受限。本研究在真实世界的条件下，以金毛寻回犬终生研究（GRLS）的群体为例，评估了利用这些数据进行癌症风险分类的可能性。", "innovation": "本研究系统地比较了126种包含不同机器学习模型、特征选择方法以及数据平衡技术的分析管道，评估了使用常规实验室数据对早期犬类癌症进行分类的可行性。这是通过使用金毛寻回犬终生研究种的群体，并纳入诊断后的样本来实现的，从而在实际条件下进行评估。", "conclusion": "尽管常规实验室数据中存在可统计识别的癌症信号，但由于信号强度较弱且混杂，不足以从正常老龄或炎症性疾病中可靠地区分。这项研究确立了该数据类型在孤立使用时的表现上限，并强调了在计算兽医肿瘤学中取得有意义进展的必要性，即需要将多种数据源进行整合。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20220", "html_url": "https://arxiv.org/abs/2510.20220", "title": "基于群组公平约束的可扩展谱聚类的拉普拉斯替代方案", "title_en": "Alternatives to the Laplacian for Scalable Spectral Clustering with Group Fairness Constraints", "authors": "Iván Ojeda-Ruiz,Young Ju-Lee,Malcolm Dickens,Leonardo Cambisaca", "background": "近年来，聚类算法中的算法偏差缓解成为一个研究热点，通过在算法设计中加入公平性约束来实现。一些公平性概念，如差异影响、社区凝聚力和每单位人口的成本已经实施，以确保公平结果。研究表明，平衡作为一种公平性的度量纳入谱聚类算法中，虽能实现公平目标，但计算时间过长。因此，该研究旨在通过使用拉格朗日方法和Sherman-Morrison-Woodbury (SMW)恒等式重构约束优化问题，提出Fair-SMW算法，以提高谱聚类算法的效率。", "innovation": "该研究通过引入Fair-SMW算法提出了三种不同谱间隙的拉普拉斯矩阵的替代方案，实现了与现有算法相近的平衡度，同时提高了运行时间性能。", "conclusion": "通过使用Stochastic Block Model (SBM)对Fair-SMW算法进行评估，结果表明该算法在实际网络数据集（如LastFM、FacebookNet、Deezer和德国数据集）上的运行时间效率是现有最先进的算法的两倍，并且具有灵活的平衡度。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20219", "html_url": "https://arxiv.org/abs/2510.20219", "title": " CO-PFL：异质网络中面向贡献的个性化联邦学习", "title_en": "CO-PFL: Contribution-Oriented Personalized Federated Learning for Heterogeneous Networks", "authors": "Ke Xing,Yanjie Dong,Xiaoyi Fan,Runhao Zeng,Victor C. M. Leung,M. Jamal Deen,Xiping Hu", "background": "传统的联邦学习依赖于单一共识模型，在数据异构性较大的情况下表现不足。其标准的聚合方法通过经验或数据量加权客户需求更新，基于平等贡献的假设，未能充分考虑每个客户需求更新的实际效用和可靠性，导致个性化不足和聚合偏差等问题。", "innovation": "提出了一种名为CO-PFL的新算法，以动态估计每个客户端的贡献进行全局聚合。CO-PFL通过分析梯度方向差异和预测偏差，利用梯度空间和数据空间的信息进行双空间分析，为每个客户端提供了原理性和区分性的聚合权重，强调高质量更新。此外，CO-PFL整合了一个参数级别的个性化机制和掩码感知动量优化方法，有效减轻了聚合偏差，增强了全球协调性和本地性能，促进了稳定更新的定制子模型的构建。", "conclusion": "在CIFAR10、CIFAR10C、CINIC10和Mini-ImageNet四个基准数据集上进行的广泛实验表明，CO-PFL在个性化准确性、鲁棒性、可扩展性和收敛稳定性方面均优于当前最先进的方法。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20157", "html_url": "https://arxiv.org/abs/2510.20157", "title": "ADP-VRSGP: 基于自适应差分隐私的渐进减量随机梯度推移的去中心化学习", "title_en": "ADP-VRSGP: Decentralized Learning with Adaptive Differential Privacy via Variance-Reduced Stochastic Gradient Push", "authors": "Xiaoming Wu,Teng Liu,Xin Wang,Ming Yang,Jiguo Yu", "background": "差分隐私被广泛应用于去中心化学习中以保护敏感数据，通过在模型更新中加入噪声。然而，现有的使用固定方差噪声的方法常常导致模型性能下降和训练效率降低。", "innovation": "提出了一种名为ADP-VRSGP的自适应差分隐私方法，通过步进衰减的策略动态调整噪声方差和学习率，加速训练并提高最终模型性能，同时提供节点级别的个性化隐私保证。引入了渐进梯度融合策略来对抗早期迭代中大方差噪声导致的收敛减缓。此外，ADP-VRSGP采用了去中心化的push-sum和聚合技术，使其特别适合时间变化的通信拓扑结构。", "conclusion": "通过严谨的理论分析，证明ADP-VRSGP在合适的条件下实现了稳健的收敛，显著提高了训练稳定性和速度。实验结果表明，该方法在多个场景中优于现有基准方法，突显了其在保护隐私的去中心化学习中的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20225", "html_url": "https://arxiv.org/abs/2510.20225", "title": "通过元变量化dropout进行联邦学习", "title_en": "Federated Learning via Meta-Variational Dropout", "authors": "Insu Jeon,Minui Hong,Junhyeog Yun,Gunhee Kim", "background": "联邦学习(FL)旨在从远程分布的客户端中训练一个全局推理模型，这得益于其提高数据隐私的优势。然而，传统的FL在实际应用中常常面临挑战，例如在客户端数据有限且非IID（独立同分布）情况下，模型容易过拟合和本地模型发散。", "innovation": "我们提出了一个新型的贝叶斯元学习方法，称为元变量化dropout（MetaVD）。MetaVD通过共享的超网络学习预测客户端依赖的dropout率，使FL算法能够有效定制非IID数据场景下的模型。我们还强调了元学习的后验适应视角和贝叶斯联邦学习的后验聚合视角，通过条件dropout后验实现。", "conclusion": "我们在多种稀疏和非IID的联邦学习数据集上进行了广泛的实验。MetaVD展示了卓越的分类准确性和不确定性校准性能，尤其对新型分布（OOD）客户端表现良好。MetaVD通过压缩每个客户端所需的局部模型参数来缓解模型过拟合并降低通信成本。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20228", "html_url": "https://arxiv.org/abs/2510.20228", "title": "稀疏局部隐式图像函数用于亚千米级气象降尺度", "title_en": "Sparse Local Implicit Image Function for sub-km Weather Downscaling", "authors": "Yago del Valle Inclan Redondo,Enrique Arriaga-Varela,Dmitry Lyamzin,Pablo Cervantes,Tiago Ramalho", "background": "研究背景在于目前气象变量（如温度和风速）的降尺度方法在亚千米级尺度上存在不足，传统的插值方法和CorrDiff方法在精度上相对较弱。为了克服这些局限性，本文提出了一种新的方法——SpLIIF（Sparse Local Implicit Image Function），旨在生成隐式神经表示，并实现气象变量的任意降尺度。", "innovation": "本文的创新之处在于提出了SpLIIF模型，该模型基于日本稀疏的气象站和地形数据进行训练，能够更精确地预测温度和风速，特别是在亚千米级别的降尺度任务上表现优越。相比传统的插值方法和CorrDiff方法，SpLIIF在降尺度温度上的准确度可以提高50%，在降尺度风速上的准确度可以提高10-20%。", "conclusion": "研究结论表明，SpLIIF模型在降尺度气象变量的任务中表现出了显著的优越性，特别是在精度上。未来研究可以进一步探索该方法在不同区域和环境下的应用效果。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20235", "html_url": "https://arxiv.org/abs/2510.20235", "title": "基于博弈论的具有最大化最小准则的多目标强化学习：一种博弈论方法", "title_en": "Multi-Objective Reinforcement Learning with Max-Min Criterion: A Game-Theoretic Approach", "authors": "Woohyeon Byeon,Giseung Park,Jongseong Chae,Amir Leshem,Youngchul Sung", "background": "本文的研究背景是在强化学习中引入多目标学习框架。传统的强化学习主要关注单一目标，但现实中的许多问题需要同时优化多个目标。因此，多目标强化学习（MORL）成为了研究的热点。尽管已有许多相关工作，但对于保证算法收敛性的问题，特别是在具有最大化最小准则（max-min criterion）的情况下，仍然缺乏有效的解决方案。本文从博弈论的角度出发，提出了一个可以证明收敛且实用的框架，并提供了一种基于镜下降的高效算法，确保在政策更新过程中保持全局最迭代收敛。", "innovation": "本文的创新点在于提出了一个具有理论证明的收敛性框架，并且该框架能够应用于多目标强化学习中的最大化最小准则问题。通过引入一种基于镜下降的高效算法，简化了政策更新过程，并且还提供了一种自适应正则化方法来进一步提高性能。此外，理论分析包括迭代复杂性和样本复杂性的边界。", "conclusion": "本文展示了所提出算法在表格设置下收敛行为，并在深度强化学习环境中对多个MORL环境进行了实现，发现该算法显著优于之前的基线方法。为多目标强化学习问题的解决提供了一种新的有效方法。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20242", "html_url": "https://arxiv.org/abs/2510.20242", "title": "构建高性能的择优分类器需要什么？", "title_en": "What Does It Take to Build a Performant Selective Classifier?", "authors": "Stephan Rabanser,Nicolas Papernot", "background": "择优分类器通过在模型认为不确定的情况下放弃输入来提高模型可靠性。然而，很少有实际方法能够达到完美排序预言机的标准表现，即精确地按正确性顺序接受示例。本文指出了这一不足之处，称为择优分类差距，并首次以五种不同的宽松来源对这一差距进行了有限样本分解：贝叶斯噪声、近似误差、排名误差、统计噪声以及实施或转换引起的限制。研究表明，虽然单调后校准通常被认为可以增强择优分类器，但它对缩小差距的影响有限，因为它很少改变模型的基本评分排名。因此，弥合差距需要能够有效重新排列预测的评分机制，而不仅仅是重新调整它们的评分。", "innovation": "论文首次将择优分类差距分解为五种来源的宽松，并证明了单调后校准在缩小差距方面的有限影响。提出了构建有效重新排列预测而非仅调整评分的择优分类器的新要求。通过合成数据和真实的视觉和语言基准测试，验证了拆解分析的有效性，揭示了贝叶斯噪声、模型容量限制以及需要数据稳健训练等关键因素。", "conclusion": "本文给出了实际误差预算并对构建更接近理想预言机表现的择优分类器提出了可操作的设计指导。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20236", "html_url": "https://arxiv.org/abs/2510.20236", "title": "图神经网络层间知识混合在化学性质预测中的应用", "title_en": "Layer-to-Layer Knowledge Mixing in Graph Neural Network for Chemical Property Prediction", "authors": "Teng Jiek See,Daokun Zhang,Mario Boley,David K. Chalmers", "background": "图神经网络（GNNs）是目前预测分子性质最有效的方法，但仍然需要更精确的模型。尽管增加模型复杂性可以提高GNN的准确性，但这也会增加训练和推理过程中的计算成本和内存要求。本研究通过开发一种新的自我知识蒸馏方法——层间知识混合（LKM），旨在在不显著增加计算复杂度的情况下，提高最先进的GNN的准确性。LKM通过最小化GNN层中预存隐藏嵌入的平均绝对距离，高效地聚合多跳和多层次信息，从而更好地表示分子的局部和全局特征。研究使用了三种不同的GNN架构（DimeNet++、MXMNet和PAMNet），并采用了量子化学性质数据集（QM9、MD17和Chignolin）进行评估，以验证LKM的有效性。", "innovation": "本研究提出了一种新的自我知识蒸馏方法——层间知识混合（LKM）。LKM通过最小化GNN层中预存隐藏嵌入的平均绝对距离，高效地聚合多跳和多层次信息，从而在训练和推理过程中几乎不增加计算复杂度的情况下提高模型性能。LKM能够有效减少量子化学和生物物理性质预测的平均绝对误差，例如QM9数据集减少9.8%，MD17能量预测减少45.3%，Chignolin减少22.9%。", "conclusion": "本研究展示了LKM在不显著增加训练和推理成本的情况下，能够显著提高GNNs的化学性质预测准确性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20222", "html_url": "https://arxiv.org/abs/2510.20222", "title": "QKCV 注意力：通过静态类别嵌入增强时间序列预测，以支持轻量化和预训练基础模型", "title_en": "QKCV Attention: Enhancing Time Series Forecasting with Static Categorical Embeddings for Both Lightweight and Pre-trained Foundation Models", "authors": "Hao Wang,Baojun Ma", "background": "在现实世界的时间序列预测任务中，类别信息在捕捉内在数据模式方面起着关键作用。传统的QKV框架未能充分重视类别特定信息，因此本文提出了一种QKCV（查询-键-类别-值）注意力机制，它通过引入静态类别嵌入C来改进传统QKV框架，以强调类别特定的信息。QKCV作为一种多功能插件模块，能提高基于注意力的时间序列模型（如范式变换器、Informer、PatchTST、TFT）的预测准确性，并适用于多种现实世界的数据集。此外，QKCV还展示了其对单一时间序列基础模型的微调能力，通过更新仅静态嵌入C而保留预训练权重，从而实现计算量减少和出色的微调性能。", "innovation": "本文创新点在于提出了QKCV（Query-Key-Category-Value）注意力机制，这是一种基于QKV的扩展，通过增加一个静态类别嵌入C，提升了类别特定信息的重要性和对时间序列模型的预测准确性。QKCV作为一种轻量级插件模块，能有效提高多种时间序列预测模型的性能，且在微调过程中仅更新静态类别嵌入C，减少了计算量，提升了微调效果。", "conclusion": "QKCV注意力机制在现实世界的时间序列预测任务中表现出色，不仅能提高多种时间序列模型的预测准确性，还能通过更新静态类别嵌入C来实现基础模型的轻量级微调，从而减少计算成本和提高微调性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20250", "html_url": "https://arxiv.org/abs/2510.20250", "title": "FedGPS: 针对联邦学习中数据异质性的统计校正", "title_en": "FedGPS: Statistical Rectification Against Data Heterogeneity in Federated Learning", "authors": "Zhiqin Yang,Yonggang Zhang,Chenxin Li,Yiu-ming Cheung,Bo Han,Yixuan Yuan", "background": "联邦学习（FL）面临着一个重要的挑战，即数据异质性，这会影响模型性能和收敛性。现有的方法已经在解决这一问题上取得了显著进展。然而，在某些异质性场景下提高性能仍然是一个未被充分关注的问题：当前方法在面对多种异质性场景时有多稳健？为了回答这个问题，作者进行了一系列全面的评估，结果显示大多数现有方法在各种异质性场景中表现出有限的稳健性。", "innovation": "该论文提出了FedGPS（Federated Goal-Path Synergy）框架，这是一种新颖的方法，能够无缝整合来自其他客户端的统计分布和梯度信息。具体而言，FedGPS静态地修改每个客户端的学习目标，通过代理信息隐式地建模全局数据分布，同时每一轮次根据其他客户端的梯度信息动态调整局部更新方向。广泛的实验表明，FedGPS在多种异质性场景中表现出色，验证了其有效性和稳健性。", "conclusion": "FedGPS在多种异质性场景中表现出色，超越了最先进的方法，证实了其实用性和鲁棒性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20264", "html_url": "https://arxiv.org/abs/2510.20264", "title": "乐观任务推断用于行为基础模型", "title_en": "Optimistic Task Inference for Behavior Foundation Models", "authors": "Thomas Rupf,Marco Bagatella,Marin Vlastelica,Andreas Krause", "background": "行为基础模型（BFMs）能够在测试时直接指定奖励函数的情况下检索高性能策略，通常称为零样本强化学习（RL）。尽管这是一个在计算资源方面非常有效的过程，但在数据方面可能效率较低：BFMs通常需要通过计算奖励来处理较大的推理数据集，假设具有奖励函数的形式访问或进行大量标记工作。", "innovation": "该研究提出了基于与环境交互在测试时推断任务的新方法，称为OpTI-BFM，并进一步提出了一种乐观决策准则来直接建模奖励函数的不确定性，并指导BFMs在任务推断的数据收集。研究还通过与线性多臂 bandits 的上置信区间算法建立了直接关系，给出了一个遗憾界。实验结果表明，该方法能够使基于后继特征的BFMs在少量回合中识别并优化未见过的奖励函数，同时具有最小的计算开销。", "conclusion": "实验评估了OpTI-BFM在零样本基准测试上的表现，并发现它能使基于后继特征的BFMs在几个回合中识别和优化未见过的奖励函数，而几乎没有计算开销。代码可以在以下网址获得：this https URL"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20270", "html_url": "https://arxiv.org/abs/2510.20270", "title": "ImpossibleBench：测量LLM利用测试案例的倾向", "title_en": "ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases", "authors": "Ziqian Zhong,Aditi Raghunathan,Nicholas Carlini", "background": "大语言模型（LLMs）在完成任务时倾向于寻找和利用‘捷径’，这种行为对评估和部署LLMs带来了显著风险，可能导致基准结果无效和真实世界LLM编程助手部署的不稳定性。例如，拥有单元测试访问权限的LLM代理可能会删除失败的测试而不是修复潜在的错误。为了解量化、研究并减轻这种行为，本文提出了一种名为ImpossibleBench的基准框架，该框架系统地测量LLM代理利用测试案例的倾向。ImpossibleBench通过在现有基准测试（如LiveCodeBench和SWE-bench）中引入自然语言规范与单元测试之间的直接冲突，生成“不可能”的任务变体。", "innovation": "ImpossibleBench提供了一种系统性的方法来测量LLM代理利用测试案例的倾向。该框架创造了一种独特的“不可能”任务变体，通过引入自然语言规范与单元测试之间的直接冲突，使得训练模型通过这些任务意味着存在规范违反的捷径使用。此外，该框架还可以用于：(1) 研究模型行为，揭示从简单的测试修改到复杂的操作重载的各种作弊行为细节；(2) 上下文工程，展示提示、测试访问和反馈循环如何影响作弊率；(3) 开发监控工具，提供包含已知欺骗性解决方案的测试平台。因此，ImpossibleBench不仅是一种评估方法，也是一种多功能工具，为构建更稳健和可靠的LLM系统提供了有益框架。", "conclusion": "我们希望ImpossibleBench能够成为一个有用框架，帮助开发者更好地理解LLM的行为，从而构建更强大和可靠的LLM系统。我们的实现可以在以下链接找到：this https URL。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20271", "html_url": "https://arxiv.org/abs/2510.20271", "title": "可扩展的GPU加速欧拉特征曲线：用于PyTorch的优化和可微学习", "title_en": "Scalable GPU-Accelerated Euler Characteristic Curves: Optimization and Differentiable Learning for PyTorch", "authors": "Udit Saxena", "background": "拓扑特征能够捕捉成像数据的全局几何结构，但在深度学习中的实用应用要求具有计算效率和可微特性。现有的GPU实现虽然能够加速计算，但仍然存在速度慢的问题。因此，研究团队需要开发高效的GPU内核和可微分的PyTorch层，以便进行端到端的学习。团队需要解决的问题包括计算效率和可微性，以支持在深度学习中的广泛使用。", "innovation": "开发了优化的CUDA内核，专门针对Ampere GPU，通过128B对齐访问和分级共享内存累加实现了高效计算。提出了一个可微分的PyTorch层，通过Sigmoid松弛的欧拉特征变换学习方向上的阈值。内核在合成网格上实现了16至2000倍的速度提升。这些优化不仅提高了计算效率，还实现了端到端学习，并且引入了批量处理和多GPU扩展，以进一步促进GPU的广泛应用。", "conclusion": "研究团队优化了欧拉特征曲线（ECC）的GPU计算，并引入了可微分的PyTorch层，实现了计算效率和可微性，从而支持端到端学习和GPU加速。新方法对于成像数据的拓扑分析具有重要价值，并且可以应用于多种领域，同时也为未来的扩展（如批量处理和多GPU）奠定了基础。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20272", "html_url": "https://arxiv.org/abs/2510.20272", "title": "PRM指导下的树搜索在大语言模型进行数学推理中的局限性", "title_en": "Limits of PRM-Guided Tree Search for Mathematical Reasoning with LLMs", "authors": "Tristan Cinquin,Geoff Pleiss,Agustinus Kristiadi", "background": "现有的大语言模型（LLMs）在数学推理中常用chain-of-thought提示，但其线性结构无法捕捉复杂问题解决中的分支和探索特性。", "innovation": "提出了一个自适应算法来最大化过程奖励模型（PRM）评分，并研究了PRM指导下的树搜索是否能通过探索多个部分解决方案路径来改善数学推理。该研究采用Qwen2.5-Math-7B-Instruct及其相关的PRM作为案例研究。", "conclusion": "尽管PRM指导下的树搜索成本更高，但并没有在数学推理上展示出统计意义上的显著改善；蒙特卡洛树搜索和beam搜索的表现优于其他PRM指导下的树搜索方法；PRM难以准确近似状态值，其可靠性随推理深度增加而下降；PRMs在分布外表现不佳；这种表现不佳的原因是PRM指导下的树搜索对不可靠的PRM评分依赖更大，需要对奖励建模进行不同的方法才能有效增强LLMs的数学推理能力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20278", "html_url": "https://arxiv.org/abs/2510.20278", "title": "KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models", "title_en": "KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models", "authors": "Guangyu Dai,Siliang Tang,Yueting Zhuang", "background": "近年来，研究人员提出了一种大型模型与小型模型协作的框架，利用易于训练的小型模型来辅助大型模型。这种协作框架旨在在显著减少计算资源消耗的同时，保持与大型模型相当的准确性，以及增强大型模型在专业领域任务中的性能。然而，这种协作模式存在显著准确度下降、灾难性遗忘加剧和幻觉问题扩大的问题。", "innovation": "本文提出了一种基于KAN的协作模型（KCM），作为改进的大型模型与小型模型协作的方法。KAN利用的架构不同于传统的MLPs，它提供优越的可视化和可解释性，并且能缓解灾难性遗忘。", "conclusion": "实验结果表明，与纯大型模型方法相比，利用KCM作为协作模型的大型模型协作框架，在保持近似相同的任务准确性的同时，可以大幅减少大型模型推理调用次数，从而显著降低计算资源消耗。同时，基于KAN的小型协作模型显著缓解了灾难性遗忘，提高了长尾数据的准确度。研究结果显示，KCM在所有指标上都优于基于MLP的小型协作模型（MCM）。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20273", "html_url": "https://arxiv.org/abs/2510.20273", "title": "SynTSBench：重新思考深度学习模型在时间序列中的时间模式学习", "title_en": "SynTSBench: Rethinking Temporal Pattern Learning in Deep Learning Models for Time Series", "authors": "Qitai Tan,Yiyun Chen,Mo Li,Ruiwen Gu,Yilin Su,Xiao-Ping Zhang", "background": "近年来，深度学习的进展在时间序列预测方面取得了快速进步，但许多最先进模型在实际应用中仍表现出不稳定的预测表现。即使是标准基准数据集上取得了优异结果的模型也难以在实际场景中保持一致的效果。问题主要源于深度学习架构的黑盒性质和现有评估框架的局限性，这些局限性经常缺乏提供不同模型具体优缺点的清晰定量洞察，从而使得选择适合特定预测场景的合适模型变得复杂。", "innovation": "本文提出了一种名为SynTSBench的合成数据驱动的评估范式，通过编程特性的可配置性系统评估时间序列预测模型的基本建模能力。该框架通过三方面核心分析维度隔离混淆因素并建立可解释的评估系统：（1）时间特征分解和能力映射，使模型能力在学习特定模式类型的系统评估成为可能；（2）数据不规则性下的稳健性分析，定量评估噪声容忍阈值和异常恢复能力；（3）理论最优基准测试，为每种模式类型建立性能边界，直接比较模型预测与数学最优值。实验表明，当前的深度学习模型在不同类型的时间序列上并未普遍接近最优基准线。", "conclusion": "我们的研究表明，现有深度学习模型在面对不同类型的时间序列数据时，其性能并不一致，通过SynTSBench框架能更准确地评估模型的实际能力，从而更好地指导模型的选择与优化。相关代码可在文中提供的链接处获得。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20302", "html_url": "https://arxiv.org/abs/2510.20302", "title": "InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling", "title_en": "InvDec: Inverted Decoder for Multivariate Time Series Forecasting with Separated Temporal and Variate Modeling", "authors": "Yuhang Wang", "background": "多元时间序列预测需要同时建模时间模式和跨变量依赖关系。现有方法如PatchTST在时间建模方面表现优异，但忽略了变量之间的相关性；而仅关注变量注意力的方法如iTransformer牺牲了时间编码。", "innovation": "提出了InvDec（颠倒解码器），这是一种混合架构，实现了时间编码和变量级别解码的有原则的分离。InvDec结合了基于块的时间编码器和通过变量间自注意力在变量维度上操作的颠倒解码器，并引入了延迟变量嵌入，仅在时间编码后丰富变量特定表示，同时保持时间特征的完整性。此外，利用残差融合机制动态平衡不同维度数据集上的时间与变量信息。通过对PatchTST的实例化得到了InvDec-PatchTST。", "conclusion": "在七个基准测试上的大量实验表明，InvDec在高维数据集上取得了显著的改进：在Electricity（321个变量）上MSE减少了20.9%，在Weather上提高了4.3%，在Traffic上提高了2.7%，同时在低维ETT数据集上保持了竞争力的表现。消融研究验证了每个组件，分析结果显示InvDec的优势随着数据集维度的增加而增强，证实了当变量数量增加时交叉变量建模变得至关重要。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20299", "html_url": "https://arxiv.org/abs/2510.20299", "title": "DB-FGA-Net: 双重主干频率门控注意力网络及其Grad-CAM可解释性在多类分类中的应用", "title_en": "DB-FGA-Net: Dual Backbone Frequency Gated Attention Network for Multi-Class Classification with Grad-CAM Interpretability", "authors": "Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim", "background": "脑肿瘤在神经肿瘤学中是一个具有挑战性的问题，早期和准确的诊断对成功治疗至关重要。基于深度学习的脑肿瘤分类方法通常依赖于大量数据增强，这可能会限制模型的泛化能力和在临床应用中的可信度。", "innovation": "本文提出了一种双重主干网络DB-FGA-Net，结合了VGG16和Xception，并引入了频率门控注意力块（FGA），以捕捉局部和全局特征。该模型在4类设置下在7K-DS数据集上达到了99.24%的准确率，在3类和2类设置下分别达到了98.68%和99.85%的准确率。未进行数据增强，模型已展现出对大小和分布多变数据集的鲁棒性。此外，集成Grad-CAM可以可视化预测的肿瘤区域，增强模型的可解释性，填补了模型预测和临床解释之间的差距。", "conclusion": "DB-FGA-Net框架在独立的3K-DS数据集上实现了95.77%的准确率，优于基线和当前的最佳方法，进一步支持了实时分类和Grad-CAM基于的肿瘤定位的图形用户界面。这些发现表明，无数据增强、可解释且可部署的深度学习模型（如DB-FGA-Net）在脑肿瘤诊断中有可靠临床转化的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20295", "html_url": "https://arxiv.org/abs/2510.20295", "title": "在因果子图中量化分布不变性以实现IRM-free图泛化", "title_en": "Quantifying Distributional Invariance in Causal Subgraph for IRM-Free Graph Generalization", "authors": "Yang Qiu,Yixiong Zou,Jun Wang,Wei Liu,Xiangyu Fu,Ruixuan Li", "background": "对于图神经网络而言，超出分布泛化在分布偏移情况下仍是一个关键挑战。现有方法通常采用不变风险最小化（IRM）框架，但该框架需要昂贵的环境注释或经验性的合成划分。本文旨在开发一种无需IRM的方法来捕捉因果子图。研究者首先发现因果子图在不同环境中的分布变化明显小于非因果组件，这是文献中首次提出的不变分布标准。该标准帮助研究者建立系统性的分布变化与表示范数之间的定量关系，并探讨了其背后的机制。通过引入一个基于范数的不变分布目标，该方法用于因果子图的发现和预测。在两个广泛使用的基准数据集上进行的实验表明，本文提出的方法在图泛化方面始终优于现有方法。", "innovation": "本文提出了一个无需IRM的方法来捕捉因果子图。该方法的核心创新点在于通过量化分布的不变性来识别因果子图，进而建立了分布变化与表示范数之间的定量关系。研究者提出了一种新的度量标准（不变分布标准），并基于此标准设计了一种有效的因果子图发现和预测方法。", "conclusion": "通过引入基于定量关系的IRM-free方法，本文提出的方法在两个广泛使用的基准数据集上展示了优越的泛化性能，超越了现有的先进技术。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20279", "html_url": "https://arxiv.org/abs/2510.20279", "title": "ResearchGPT：评估和训练大语言模型进行计算机科学研究全流程", "title_en": "ResearchGPT: Benchmarking and Training LLMs for End-to-End Computer Science Research Workflows", "authors": "Penghao Wang,Yuhao Zhou,Mengxuan Wu,Ziheng Qin,Bangyuan Zhu,Shengbin Huang,Xuanlei Zhao,Panpan Zhang,Xiaojiang Peng,Yuzhang Shang,Jianfei Yang,Zheng Zhu,Tianlong Chen,Zhangyang Wang,Kai Wang", "background": "随着大语言模型（LLMs）的发展，它们在科学研究中的最终角色愿景正在形成：我们可以构建一个人工智能合作者，有效地在整个科学研究过程中辅助人类。科学研究涉及多个相互依赖的阶段，要实现这一愿景，需要严格的基准测试来评估整个工作流程，而不仅仅是孤立的子任务。论文介绍了一个名为ResearchGPT的系统，并构建了一个高质量的计算机科学问答对语料库CS-54k，该语料库基于14000篇公开许可的论文，确保了事实上的根基。", "innovation": "论文贡献了一个高质量的计算机科学问答对语料库CS-54k，分为CS-4k和CS-50k两个子集。CS-4k用于评估AI在科学研究中的辅助能力，CS-50k用于大规模训练模型。大量实验表明，CS-4k将最先进的LLMs划分为不同的能力层级，而基于CS-50k进行监督训练和强化学习的开源模型显著提升了性能，即使是7B规模的模型，在适当训练后也优于许多大型专有系统。这表明，使AI模型更好地成为研究助手的关键在于与高质量数据的定向训练，而不仅仅是预训练规模或通用基准性能的好坏。该论文开源了CS-4k和CS-50k，以促进计算机科学领域的AI系统作为可靠合作者的发展。", "conclusion": "该研究通过开源高质量的数据集CS-4k和CS-50k，促进了计算机科学研究中的AI系统的开发。这表明，优化AI在科学研究中的表现，不仅需要高质量的数据，还需要针对特定领域的训练。此外，研究表明，虽然大型模型有潜力，但在适当的训练下，较小规模的模型也能表现出色。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20327", "html_url": "https://arxiv.org/abs/2510.20327", "title": "LEGO: 一种面向推荐系统的大规模多属性遗忘轻量高效框架", "title_en": "LEGO: A Lightweight and Efficient Multiple-Attribute Unlearning Framework for Recommender Systems", "authors": "Fengyuan Yu,Yuyuan Li,Xiaohua Feng,Junjie Fang,Tao Wang,Chaochao Chen", "background": "随着对保护用户敏感信息需求的增加，推荐系统中的推荐属性遗忘受到了越来越多的关注。现有的研究主要集中在单一属性遗忘上。然而，现实中的隐私保护要求往往涉及多种敏感属性，并且是动态变化的。现有的单一属性遗忘方法由于无法同时处理多个遗忘请求（CH1）和缺乏对动态遗忘需求的有效适应能力（CH2），不能满足这些现实需求。因此，本文探讨了如何解决这些问题，并提出了LEGO框架，这是一个轻量高效的多属性遗忘框架，能够同时处理多个属性遗忘，且具有高度的灵活性和效率，以适应动态隐私保护要求。", "innovation": "本文提出了一种名为LEGO的轻量高效的多属性遗忘框架，该框架包含以下创新点：1) 将多属性遗忘过程分为两大步骤：嵌入校准和灵活组合；2) 采用最小化互信息的方法来实现多属性同时遗忘，从而解决了CH1带来的问题；3) 通过两步框架，其中嵌入校准可以并行执行，灵活组合具有灵活性和高效性，从而解决了CH2带来的问题。", "conclusion": "实验结果表明，提出的LEGO框架在三个真实的推荐系统数据集上表现出了高效性和有效性。该代码和附录可在以下链接获取：this https URL。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20369", "html_url": "https://arxiv.org/abs/2510.20369", "title": "当您的奖励模型不确定时，请咨询强LLM裁判", "title_en": "Ask a Strong LLM Judge when Your Reward Model is Uncertain", "authors": "Zhenghao Xu,Qin Lu,Qingru Zhang,Liang Qiu,Ilgee Hong,Changlong Yu,Wenlin Yao,Yao Liu,Haoming Jiang,Lihong Li,Hyokun Yun,Tuo Zhao", "background": "在使用人类反馈增强学习(RLHF)来使大型语言模型(LLMs)保持一致的过程中，奖励模型(RMs)扮演着关键角色。然而，传统的基于人类偏好训练的RMs容易被奖励作弊，对未见过的输入泛化能力较差。相比之下，配备推理能力的强力LLM裁判在无需额外训练的情况下表现出更好的泛化能力，但其推理成本很高，限制了其在线RLHF中的应用。", "innovation": "提出了一种基于不确定性的路由框架，以高效地与快速RMs相结合来使用强力但成本高的LLM裁判。该方法将优势估计形式化为策略梯度(PG)方法中的成对偏好分类，从而允许通过不确定性量化来引导路由。不确定的成对偏好被发送到LLM裁判进行评估，而信心较高的成对偏好由RM直接评估。实验表明，该不确定性驱动的路由策略在相同成本下比随机裁判调用性能更优，并且下游一致性的结果也证明了其有效。", "conclusion": "实验表明，基于不确定性的路由策略在相同的成本下显著优于随机裁判调用，并且下游一致性结果展示了其在改进在线RLHF方面的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20383", "html_url": "https://arxiv.org/abs/2510.20383", "title": "使用稳健重聚合法进行层级时间序列预测", "title_en": "Hierarchical Time Series Forecasting with Robust Reconciliation", "authors": "Shuhei Aikawa,Aru Suzuki,Kei Yoshitake,Kanata Teshigawara,Akira Iwabuchi,Ken Kobayashi,Kazuhide Nakata", "background": "本文关注层级时间序列数据的预测，其中每个较高层次的观察值等于其相应较低层次时间序列的总和。在这样的背景下，预测值应具有一致性，即每个父级序列的预测值应完全与其子序列的预测值之和匹配。现有的层级预测方法通常独立地为每个序列生成基预测，然后应用一种调整过程，使其结果预测值在整个层级结构中具有一致性。这些方法通常利用预测误差的协方差矩阵来获取最优重聚法。然而，在实践中，真正的协方差矩阵未知，必须用有限样本提前估计。真正的协方差矩阵与估计的协方差矩阵之间的差距可能会降低预测性能。", "innovation": "本文提出了一种稳健的优化框架，用于考虑估计协方差矩阵中不确定性因素的层级重聚法。该框架首先为估计的协方差矩阵引入一个不确定性集，并形式化一个求解问题，该问题在该不确定性集上最小化最坏情况的预期平方误差。表明该问题可以转换为半肯定优化问题。数值实验表明，提出的稳健重聚方法优于现有的层级预测方法，这表明将不确定性整合到重聚过程中的有效性。", "conclusion": "提出的稳健重聚方法比现有层级预测方法具有更好的预测性能，证明了整合不确定性在重聚过程中的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20349", "html_url": "https://arxiv.org/abs/2510.20349", "title": "Synthetic Data for Robust Runway Detection", "title_en": "Synthetic Data for Robust Runway Detection", "authors": "Estelle Chigot,Dennis G. Wilson,Meriem Ghrib,Fabrice Jimenez,Thomas Oberlin", "background": "目前深度视觉模型已经足够成熟，可以用于工业甚至关键应用如自主导航。然而，收集和标记数据以训练这些模型需要大量的时间和成本，而且在关键应用中更为显著。关键应用需要包括所有可能情况的数据集，包括罕见情况。因此，生成合成图像成为了解决数据集多样性和覆盖全面性的有吸引力的解决方案，但在合成数据和真实数据之间的分布差异被缓解之前，它的可靠性和准确性是不可靠的。本研究关注的是飞机制造商开发的自主降落系统中的跑道检测部分，这是我们研究的重点领域。在该框架下，提出了一种基于商用飞行模拟器的图像生成方法，以补充少量标记的真实图像。通过控制图像生成和真实与合成数据的结合，展示了标准目标检测模型可以实现准确预测。同时，评估了模型在极端条件下（夜间）的鲁棒性，展示了定制领域的适应策略的重要性。", "innovation": "研究提出了基于商用飞行模拟器的图像生成方法，用以补充标注的真实图像，控制并整合真实与合成数据，使标准的目标检测模型能够实现准确的预测，尤其在夜间等极端条件下表现出良好的鲁棒性。这种方法的优势在于相对低成本但能有效覆盖各种条件和环境，对于缓解合成数据和真实数据之间的分布差异提供了一种有效的策略。此外，还强调了使用定制领域适应策略的重要性。", "conclusion": "提出的基于商用飞行模拟器的图像生成方法可以有效地补充标注的真实数据，从而提高标准目标检测模型在不同条件下的鲁棒性。特别是在关键应用如自主降落系统中的跑道检测任务中，这种方法的优势尤为突出。虽然合成数据和真实数据之间的分布差异仍然是一个挑战，但研究展示了通过定制领域适应策略，可以显著提高模型的适应性和鲁棒性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20387", "html_url": "https://arxiv.org/abs/2510.20387", "title": "基于相对概率的神经语言模型缩放定律", "title_en": "Relative-Based Scaling Law for Neural Language Models", "authors": "Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu", "background": "现有的缩放定律研究几乎完全依赖交叉熵作为评估指标。然而，交叉熵只能提供模型性能的部分视图：它衡量正确标记的概率，但忽略了正确标记与错误标记之间的相对排序。在贪婪采样等场景中，相对排序对于语言模型至关重要。", "innovation": "本文提出了基于相对概率（Relative-Based Probability, RBP）的指标，衡量正确标记是否被预测为前几项。据此建立了基于相对概率的缩放定律，说明了RBP随模型大小增加而提高的趋势。通过在四个数据集和四个模型系列上的实验，证明了这一定律的稳健性和准确性，并展示了其在解释浮现现象和寻找缩放定律的基本理论方面的广泛应用。", "conclusion": "基于相对概率的缩放定律补充了交叉熵视角，有助于更全面地理解大型语言模型的缩放。这对于实际开发和理论探索都提供了宝贵的见解。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20414", "html_url": "https://arxiv.org/abs/2510.20414", "title": "在无积分神经标记时间点过程中的标记不平衡问题解决方法", "title_en": "Addressing Mark Imbalance in Integration-free Neural Marked Temporal Point Processes", "authors": "Sishun Liu,Ke Deng,Xiuzhen Zhang,Yongli Ren,Yan Wang", "background": "已有关于有标记事件流事件分布的Marked Temporal Point Process (MTPP)的研究表明，它可以用于预测下一个事件的到达时间和标记。然而，现有研究忽视了在许多实际应用中事件标记的分布通常是极度不平衡的，有些标记很常见而另一些则很少见。这种不平衡对依赖于标记概率的现有预测方法提出了显著挑战，尤其是对于少见标记的事件预测更为明显。", "innovation": "本文提出了一个阈值方法，该方法通过学习阈值调整标记概率（以标记的先验概率为归一化因子），来优化标记预测，而不是直接基于标记概率预测标记。此外，提出了一种新型的神经MTPP模型，支持有效的时间采样和标记概率估计，避免了复杂的数值不正确积分。", "conclusion": "在真实数据集上的广泛实验表明，本文的方法在下一事件标记和时间预测方面优于各种基线方法。代码可在以下网址获取：this https URL."}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20408", "html_url": "https://arxiv.org/abs/2510.20408", "title": "平衡专业化与集中化：序贯工业控制的多智能体增强学习基准", "title_en": "Balancing Specialization and Centralization: A Multi-Agent Reinforcement Learning Benchmark for Sequential Industrial Control", "authors": "Tom Maus,Asma Atamna,Tobias Glasmachers", "background": "多阶段工业过程的自主控制需要在局部的专业化和全局的协调之间取得平衡。增强学习（RL）提供了一种有希望的方法，但由于奖励设计、模块化和行动空间管理等方面的挑战，其在工业中的应用仍然有限。许多学术基准与工业控制问题差异很大，限制了其在实际应用中的转移性。因此，有必要创建一个更接近工业控制问题的多智能体RL基准环境来促进其应用和研究。", "innovation": "引入了结合SortingEnv和ContainerGym两个现有基准任务的新环境，以创建一个基于顺序回收操作的多任务场景。评估了两种控制策略：模块化架构和单一代理，同时还分析了行动掩蔽的影响。实验表明，在不使用行动掩蔽时，代理难以学习有效的策略，模块化架构表现更好；在应用行动掩蔽后，两种架构都有显著改进，性能差距显著减小。这些结果强调了行动空间约束的关键作用，表明随着行动复杂性的减少，专业化的优势将减弱。", "conclusion": "提出的基准为探索多智能体RL在工业自动化中的实用和稳健解决方案提供了有价值的研究测试平台，同时为集中化与专业化之间的持续辩论做出了贡献。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20413", "html_url": "https://arxiv.org/abs/2510.20413", "title": "为什么DPO是一个错配的估计器以及如何修复它", "title_en": "Why DPO is a Misspecified Estimator and How to Fix It", "authors": "Aditya Gopalan,Sayak Ray Chowdhury,Debangshu Banerjee", "background": "直接对齐算法如Direct Preference Optimization (DPO)是通过基于偏好数据的监督学习来微调模型，而不是使用包含人类反馈的两阶段强化学习(RLHF)。研究表明，DPO会编码一个基于参数策略类的奖励函数的统计估计问题。当真实的奖励函数不能通过策略类实现时，DPO就会发生错配，导致偏好顺序颠倒、策略奖励下降和对输入偏好数据分布的高度敏感等问题。", "innovation": "研究了两阶段RLHF的局部行为，并将其与策略空间中的自然梯度步长相关联。通过精细的空间几何特征，提出了AuxDPO，它在DPO损失函数中引入辅助变量，帮助朝向RLHF解决方案移动，并减轻DPO中的错配。实验证明在教科书范例和大语言模型对齐任务中，AuxDPO具有优越表现。", "conclusion": "研究表明，DPO在某些情况下会表现为一个错配的估计器。为了克服这个问题，提出了AuxDPO算法，该算法通过引入辅助变量来改进DPO，并在多样的实验设置中展示了其优越性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20439", "html_url": "https://arxiv.org/abs/2510.20439", "title": "通过概念学习视角的可解释基准测试", "title_en": "Explainable Benchmarking through the Lense of Concept Learning", "authors": "Quannian Zhang,Michael Röder,Nikit Srivastava,N'Dah Jean Kouagou,Axel-Cyrille Ngonga Ngomo", "background": "基准测试是科学研究中的一个重要环节。然而，系统性能通常通过少数几个指标来总结，这使得分析评估细节和得出进一步发展或使用方面的见解变得费时且结果常带偏见。本文为此问题提出了一个可解释基准测试的新类型方法，旨在自动生成基于基准测试中系统的性能解释。", "innovation": "本文提出了一种新型的可解释基准测试方法，通过使用一种专为大规模知识图谱开发的新概念学习方法PruneCEL来生成解释。实验表明，PruneCEL在可解释基准测试任务上的F1分数上优于最先进的概念学习方法，最多可提高0.55分。同时，一项任务驱动的用户研究显示，73%的参与者能够准确预测基于这些解释的系统行为。", "conclusion": "本文通过PruneCEL实现了知识图谱问题解答系统的可解释基准测试，验证了其有效性和准确性，并展示了生成的解释对于用户理解系统行为的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20448", "html_url": "https://arxiv.org/abs/2510.20448", "title": "MolBridge: 原子级联合图修正框架在稳健药物药物相互作用事件预测中的应用", "title_en": "MolBridge: Atom-Level Joint Graph Refinement for Robust Drug-Drug Interaction Event Prediction", "authors": "Xuan Lin,Aocheng Ding,Tengfei Ma,Hua Liang,Zhe Quan", "background": "药物组合虽然能够提供治疗优势，但也增加了不良药物-药物相互作用（DDIs）的风险，特别是在复杂的分子结构下。现有方法通常依赖于孤立的药物表示，无法明确建模原子级跨分子交互，这限制了它们在不同分子复杂性和DDI类型分布中的有效性。", "innovation": "提出了一种新的原子级联合图精炼框架MolBridge，用于稳健的药物药物相互作用事件预测。该框架通过集成药物对的原子结构建立联合图，可以直接建模药物间的关联。为了解决潜在的信息损失问题，引入了一种结构一致性模块，能够迭代精炼节点特征同时保持全局结构上下文。实验证明，MolBridge在多种DDI类型（包括长尾和归纳场景）中都能取得优越的性能，展示出细粒度图精炼在提高DDI事件预测准确性和健壮性方面的优点。", "conclusion": "MolBridge在两个基准数据集上的广泛实验表明，它能够提供更为准确、稳健且机制上有解释性的DDI事件预测。这项工作通过开发基于图的方法来研究和分析药物药物相互作用网络，为Web挖掘和内容分析领域做出了贡献。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20428", "html_url": "https://arxiv.org/abs/2510.20428", "title": "大型语言模型修复中样本选择策略的实证研究", "title_en": "An Empirical Study of Sample Selection Strategies for Large Language Model Repair", "authors": "Xuran Li,Jingyi Wang", "background": "大型语言模型（LLMs）在实际系统中越来越广泛地部署，但它们可能会生成有毒或有偏见的输出，从而损害安全性和信任。事后模型修正提供了一种实用的解决办法，然而参数更新的高成本促使对修正数据进行选择性使用。尽管在模型训练的数据选择方面进行了大量研究工作，但在专门应用于大型生成模型的行为修正时，仍不清楚哪些抽样标准最有效和高效。本文系统分析了LLM修复中的样本优先级策略，评估了五种代表性选择方法的效果，包括随机抽样、K-Center、梯度模长选择（GraNd）、分层覆盖率（CCS）以及我们提出的一种语义感知优先级抽样（SAPS）方法。通过毒性减少、WikiText-2和LAMBADA的困惑度以及三种合并度量：修复接近度分数（RPS）、总体性能分数（OPS）和修复效率分数（RES），评估了修复效果和权衡。实验结果显示，SAPS在排毒、保持效用和效率之间拥有最佳平衡，用更少的数据获得可比或更优的修复结果。随机抽样对大型或稳健模型仍有效，而高成本方法如CCS和GraNd提供的益处有限。最优数据比例取决于模型规模和修复方法，表明样本选择应被视为修复管道中的可调组件。", "innovation": "本文首次系统分析了大型语言模型修复中的样本优先级策略，通过实证研究比较了五种代表性抽样方法的效果，特别强调了语义感知优先级抽样（SAPS）的创新方法，该方法在保持效用和效率的同时，提供了更优的排毒效果，并提出样本选择应作为修复管道中的可调组件。", "conclusion": "样本选择方法是保持大型语言模型可靠性的有效且可扩展的范式。SAPS在排毒、效用保持和效率之间实现了最佳平衡，为大型语言模型提供了一种高效和有效的修复方法。最优数据比例取决于模型规模和修复方法，因此样本选择应被视为修复管道中的可调组件。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20454", "html_url": "https://arxiv.org/abs/2510.20454", "title": "网球比赛中无序玩家优势及市场定价错误：基于图神经网络的方法", "title_en": "Intransitive Player Dominance and Market Inefficiency in Tennis Forecasting: A Graph Neural Network Approach", "authors": "Lawrence Clegg,John Cartlidge", "background": "不完全竞争的网球比赛中，存在着A胜B，B胜C，C胜A的循环优势关系，现有预测方法对该类情况考虑不足。这类情况在实际赌盘中处理不佳，提示存在市场定价错误，亟需新的方法来有效捕捉这些关系。\n", "innovation": "引入了一种基于图神经网络的方法，通过时间导向的图来明确建模这些循环优势关系。通过这种方法，成功地在高循环优势匹配赛中提升了预测准确性（65.7% 准确率，0.215布莱尔得分），并且通过凯利投注策略实现了显著的正回报率（3.26% 现金回报率）。\n", "conclusion": "该研究发现存在处理复杂循环优势匹配赛的市场定价错误，并且通过图神经网络方法成功地利用了这一市场缺陷，得到了实际的正回报。\n"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20468", "html_url": "https://arxiv.org/abs/2510.20468", "title": "通过图像偏好模型实现可移植的黑盒一次成型水印伪造", "title_en": "Transferable Black-Box One-Shot Forging of Watermarks via Image Preference Models", "authors": "Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko", "background": "近年来，数字内容水印技术受到了广泛关注，这得益于生成模型的兴起和法律压力的增大。随着大量AI生成内容的在线传播，水印在确保内容真实性和溯源方面的角色越来越重要。尽管已有大量研究评估水印的鲁棒性，但水印伪造——即从真实内容中盗取水印并应用到恶意内容上的情况——却尚未深入研究。因此，本文研究了在常用后处理图像水印技术中的水印伪造问题。", "innovation": "本文提出了偏好模型来评估图像是否被水印标记，通过训练可直接使用合成图像而无需实际水印。利用该模型优化输入图像以实现水印去除与伪造，仅需一张水印图像即可，且无需了解水印算法，这使得攻击更为简单和实用。此外，还评估了各种后处理图像水印技术，证明了水印伪造的有效性，引发了当前水印方法安全性的问题。", "conclusion": "本文提出的方法可以在不依赖具体水印技术的情况下有效伪造水印，揭示了使用此类方法的潜在风险，挑战了现有水印的安全性模式。相关代码和资源已公开提供。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20540", "html_url": "https://arxiv.org/abs/2510.20540", "title": "SheafAlign: 一种用于去中心化多模态对齐的 sheaf 理论框架", "title_en": "SheafAlign: A Sheaf-theoretic Framework for Decentralized Multimodal Alignment", "authors": "Abdulmomen Ghalkha,Zhuojun Tian,Chaouki Ben Issaid,Mehdi Bennis", "background": "传统的多模态对齐方法假设所有模态之间存在互斥冗余性，在实际的分布式场景中，这一假设往往不成立。这种情况下，现有的方法难以有效进行模态间的对齐任务，尤其是对于不完全共享信息的模态对，其性能尤为不佳，同时也伴随着较高的通信成本。", "innovation": "本文提出了一种名为 SheafAlign 的去中心化多模态对齐框架，它不依赖于所有模态间的互斥冗余性，而是通过 sheaf 结构建模模态间的双边关系，并使用分散的对比学习目标进行训练。相比于现有方法，SheafAlign 降低了 50% 的通信成本，并且在零样本泛化、跨模态对齐和面对缺失模态的鲁棒性方面表现出更优越的性能。", "conclusion": "实验结果表明，SheafAlign 在多个多模态传感数据集上表现出更优秀的零样本泛化能力、跨模态对齐能力和对缺失模态的鲁棒性，同时通信成本降低了 50%。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20542", "html_url": "https://arxiv.org/abs/2510.20542", "title": "零样本强化学习的统一框架", "title_en": "A Unified Framework for Zero-Shot Reinforcement Learning", "authors": "Jacopo Di Ventura,Jan Felix Kleuker,Aske Plaat,Thomas Moerland", "background": "零样本强化学习（RL）已经发展成为一种在无需监督的情况下开发通用代理的方法，这些代理能够在测试时间不需要额外训练或规划的情况下解决下游任务。与传统RL不同，传统RL优化固定奖励下的策略，而零样本RL要求代理能够编码足够丰富的表示以支持立即适应任何目标，这一点与视觉和语言基础模型有着相似之处。尽管对零样本RL的兴趣日益增长，但该领域仍然缺乏一个通用的分析框架。", "innovation": "本文提出了第一个零样本RL的统一框架。通过引入一致的符号和分类法，该框架组织了现有的方法，并允许直接比较它们之间的区别。该框架将算法分为两大类：直接表示和组合表示。在这一框架下，文章突出了方法中的共同原则和关键差异，并为后继特征方法推导出一个新的延伸界线，为其在零样本场景下的性能提供了新的视角。通过使用一个共同的视角整合现有工作，该框架为未来零样本RL研究提供了一个坚实的理论基础，并指明了开发更通用代理的一个清晰道路。", "conclusion": "通过这个统一的框架，我们为零样本RL提供了坚实的理论基础，并为未来研究指明了明确的方向。文章还明确了直接表示和组合表示的战略差异，通过新的界线为后继特征方法提出了其性能的新观点。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20477", "html_url": "https://arxiv.org/abs/2510.20477", "title": "Bi-CoG: 双一致性引导自训练法用于视觉语言模型", "title_en": "Bi-CoG: Bi-Consistency-Guided Self-Training for Vision-Language Models", "authors": "Rui Zhu,Song-Lin Lv,Zi-Kang Wang,Lan-Zhe Guo", "background": "在标签稀缺的情景下，利用未标注数据进行半监督学习（SSL）以及利用预训练模型进行微调是两个主要的策略。最近，研究方向开始结合预训练的视觉-语言模型（VLMs）进行微调与半监督学习，形成了半监督微调的新范式。然而，现有的方法往往存在模型偏差和超参数敏感性的问题，这主要是因为它们依赖于预测一致性或预定义的信心阈值。", "innovation": "本文提出了一种简单且有效的插件式方法——双一致性引导自训练法（Bi-CoG），通过同时利用模型间和模型内的一致性，并结合一种错误意识动态伪标签分配策略，来分配高质量且低偏差的伪标签。理论分析和在14个数据集上的广泛实验表明，Bi-CoG的有效性，它始终显著改善了现有方法的性能。", "conclusion": "通过Bi-CoG方法，不仅能够更好地指导自我训练过程，还能提高现有方法在标签稀缺情况下的性能表现。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20556", "html_url": "https://arxiv.org/abs/2510.20556", "title": "结构不变性至关重要：通过图度量重新思考图重排", "title_en": "Structural Invariance Matters: Rethinking Graph Rewiring through Graph Metrics", "authors": "Alexandre Benoit,Catherine Aitken,Yu He", "background": "图重排作为一种关键技术，通过修改图拓扑来改善信息流，以缓解图形神经网络（GNNs）和图形变换器中的过度挤压。尽管有效，但重排本身会改变图的结构，这可能导致重要拓扑依赖信号的变形。尽管图重排的使用日益增长，但关于必须保留哪些结构特性以确保性能提升和结构保真度的知识还很少。", "innovation": "本文首次系统分析了图重排如何影响各种图结构度量指标，并探讨了这些变化如何与下游任务性能相关。研究了七种不同的重排策略，关联了局部和全局图属性的变化与节点分类准确性。研究结果揭示了一个一致的模式：成功的重排方法倾向于保留局部结构，同时允许全局连接性有灵活性。这些发现为有效重排策略的设计提供了新的见解，填补了图理论与实际GNN优化之间的空白。", "conclusion": "研究结果表明，成功的重排方法往往倾向于保留局部结构，同时允许在全球连接性上进行灵活性调整。这些发现为有效重排策略的设计提供了新的见解，填补了图理论和实际GNN优化之间的空白。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20590", "html_url": "https://arxiv.org/abs/2510.20590", "title": "将以MLOps生命周期嵌入到OT参考模型中", "title_en": "Embedding the MLOps Lifecycle into OT Reference Models", "authors": "Simon Schindler,Christoph Binder,Lukas Lürzer,Stefan Huber", "background": "工业环境中日益采用的MLOps实践与Operational Technology (OT)系统集成存在显著挑战。", "innovation": "研究提出了一个系统的方法，将MLOps实践嵌入到现有的OT参考模型中，并探讨了RAMI 4.0和ISA-95标准在MLOps集成中的适用性。", "conclusion": "标准的MLOps实践不能直接应用于OT环境，但通过现有的参考模型进行有结构的调整，可以为MLOps的成功集成提供一条途径。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20486", "html_url": "https://arxiv.org/abs/2510.20486", "title": "Hurdle-IMDL: 一种用于红外降雨检索的不平衡学习框架", "title_en": "Hurdle-IMDL: An Imbalanced Learning Framework for Infrared Rainfall Retrieval", "authors": "Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng", "background": "人工智能虽已推动定量遥感技术的发展，但标签分布不平衡限制了其效能。这种不平衡导致传统训练模型偏向常见的样本，进而降低了对罕见样本的检索性能。特别是在降雨检索中，对于强降雨的性能表现尤为不佳。为此，本研究提出了一种Hurdle-Inversion Model Debiasing Learning (IMDL)框架。降雨分布的不平衡被分解为零膨胀和长尾分布两个部分进行处理。零膨胀是指非降雨样本占主导，而长尾分布是指轻降雨样本相对于强降雨样本的过度丰富。Hurdle-IMDL框架通过零膨胀模型处理零膨胀，并通过IMDL处理长尾分布，将学习对象转化为无偏的理想的反向模型。统计指标和针对中国东部降雨天气案例的研究证明，Hurdle-IMDL在处理不平衡问题上优于传统的、代价敏感的、生成式和多任务学习方法，尤其在强降雨至极端降雨的检索方面表现出色。", "innovation": "Hurdle-IMDL框架在处理不平衡标签分布方面提供了一种全新的方法，将其分解为零膨胀和长尾分布两个部分，分别采用零膨胀模型和IMDL进行处理。这种方法能够有效地缓解系统性低估问题，并显著提高强降雨至极端降雨的检索性能。此外，IMDL提供了一种具有广泛应用性的解决方案，能够处理环境变量分布中的不平衡问题，从而增强对罕见但高影响事件的检索能力。", "conclusion": "Hurdle-IMDL框架在统计指标和实证研究中均优于传统方法，特别是在强降雨至极端降雨的检索方面表现突出。该研究为处理环境变量分布不平衡的问题提供了一种创新的方法，提高了对罕见但高影响事件的检索能力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20608", "html_url": "https://arxiv.org/abs/2510.20608", "title": "SGD under Expected Smoothness的收敛性分析", "title_en": "Convergence Analysis of SGD under Expected Smoothness", "authors": "Yuta Kawamoto,Hideaki Iiduka", "background": "SGD是大规模学习中的基本算法，但经典分析依赖于强度过大（如方差有界）或过于粗糙（如均匀噪声）的假设。ES条件是平稳梯度的二阶矩与目标值和全梯度联系起来的一种灵活替代方案。", "innovation": "本文对ES条件下的SGD进行了自我包含的收敛性分析，(i)细化并解释了ES条件与采样相关的常数；(ii)推导出了全梯度范数平方期望的边界值；(iii)证明了对于各种步长策略的显式残差误差的O(1/K)率。", "conclusion": "所有证明都在附录中给出详尽的细节。本文统一和扩展了近期的相关研究线（Khaled和Richtárik, 2020；Umeda和Iiduka, 2025）。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20607", "html_url": "https://arxiv.org/abs/2510.20607", "title": "通过组合能量最小化实现的可泛化推理", "title_en": "Generalizable Reasoning through Compositional Energy Minimization", "authors": "Alexandru Oarga,Yilun Du", "background": "机器学习中的泛化是一个关键挑战，尤其在推理任务中更为明显。模型在推理过程中需要解决比训练过程更为复杂的任务。现有的方法通常以端到端的方式训练推理模型，直接将输入实例映射到解决方案上。这种方法虽然可以使模型从数据中学习有用的启发式方法，但往往只能在训练分布范围内泛化。为了解决这一问题，本研究提出了通过学习小规模易解决子问题上的解空间的能量景观来进行推理泛化的新型方法。", "innovation": "本研究提出了一种新的推理泛化方法：通过学习能源景观来解决子问题的解空间，该方法在测试时通过组合多个子问题的能量函数构建全局能量景观。此外，研究还引入了并行能量最小化（PEM）方法以提高新构建的能源景观中样本的质量。这种方法被广泛应用于多项推理问题测试中，相对于现有最先进的方法表现出色，证明了其在解决更大、更复杂问题时的能力。", "conclusion": "本研究的方法能够在解决复杂推理问题时提升模型的泛化能力，并通过广泛的实验验证了其有效性。与现有的先进方法相比，这种方法能够在解决更加复杂的问题时更好展现出泛化性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20609", "html_url": "https://arxiv.org/abs/2510.20609", "title": "大规模实用代码RAG：在计算预算下的任务感知检索设计选择", "title_en": "Practical Code RAG at Scale: Task-Aware Retrieval Design Choices under Compute Budgets", "authors": "Timur Galimzyanov,Olga Kolomyttseva,Egor Bogomolov", "background": "本文研究了在实际计算预算下，针对代码导向生成任务的检索设计方案。使用来自Long Code Arena的两个补充任务——代码补全与缺陷定位，系统地比较了不同上下文窗口大小下的检索配置，从三个方面进行对比：（i）分块策略；（ii）相似度评分；（iii）切分粒度。", "innovation": "本文通过系统性地对比不同检索配置，发现（1）对于PL-PL（程序语言到程序语言），基于词级别的稀疏BM25是最有效的，并且显著优于密集替代方案，同时速度快一个数量级以上；（2）对于NL-PL（自然语言到程序语言），专有的密集编码器（Voyager-3家族）始终击败稀疏检索器，但需要长100倍的延迟；（3）最优的块大小与可用上下文相关：在小预算下，32-64行的块效果最佳，而在16000词的预算下，全文检索变得具竞争力；（4）简单的基于行的分块与预算无关时匹配语法意识的分块；（5）检索延迟在不同配置之间变化可达200倍；基于BPE的分块是不必要的慢，而BM25加上词级别的分块提供了最佳的质量-延迟权衡。", "conclusion": "因此，本文根据任务需求、模型限制以及计算效率提供了基于证据的代码导向RAG系统的实施建议。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20611", "html_url": "https://arxiv.org/abs/2510.20611", "title": "PSO-XAI：一种增强的可解释人工智能框架，用于可靠的乳腺癌检测", "title_en": "PSO-XAI: A PSO-Enhanced Explainable AI Framework for Reliable Breast Cancer Detection", "authors": "Mirza Raquib,Niloy Das,Farida Siddiqi Prity,Arafath Al Fahim,Saydul Akbar Murad,Mohammad Amzad Hossain,MD Jiabul Hoque,Mohammad Ali Moni", "background": "乳腺癌是全球女性中最关键、最常见的癌症类型，导致癌症相关死亡率增加。早期和准确的检测至关重要，可以减轻风险并提高生存率。然而，传统诊断方法在准确性、成本和误诊风险方面存在局限性。机器学习（ML）已成为计算机辅助诊断的强大工具，特征选择在提高模型性能和可解释性方面起着关键作用。研究表明，结合定制的粒子群优化（PSO）和可解释AI方法的框架，在全面评估29种不同模型（包括经典分类器、集成技术、神经网络、概率算法和基于实例的算法）后，能够在所有性能指标中达到99.1%的高分，并有效降低维度，提供透明且模型无关的解释。", "innovation": "该研究提出了一个结合定制粒子群优化（PSO）的框架，用于特征选择，并通过可解释AI方法确保可解释性和临床相关内容。该框架在全面评估29种不同模型后，实现了在所有性能指标中的99.1%的高分，降低维度的同时提供了透明且模型无关的解释。研究强调了将群体智能与可解释机器学习相结合在乳腺癌诊断中的潜力，从而实现稳健、可信且具有临床意义的诊断方法。", "conclusion": "该研究通过结合粒子群优化和可解释AI，提出了一个有效的框架，用于乳腺癌检测。评估结果显示，该方法在多个性能指标上表现出色，不仅提高了模型的性能和可解释性，而且提供了透明且模型无关的解释，增强了诊断结果的可信度和临床意义。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20627", "html_url": "https://arxiv.org/abs/2510.20627", "title": "H-SPLID: 基于HSIC的保留显著性潜信息分解", "title_en": "H-SPLID: HSIC-based Saliency Preserving Latent Information Decomposition", "authors": "Lukas Miklautz,Chengzhi Shi,Andrii Shkabrii,Theodoros Thirimachos Davarakis,Prudence Lam,Claudia Plant,Jennifer Dy,Stratis Ioannidis", "background": "该研究引入了一种名为H-SPLID的新算法，用于学习显著特征表示。该算法通过将显著特征和非显著特征明确地分解到不同的空间中来实现此目标。研究表明，H-SPLID算法有助于学习低维度的任务相关特征。实验证明，使用H-SPLID训练的模型主要依赖于显著输入组件，尤其是在抗干扰性和背景变化等方面表现出较小的变化。研究证明了鲁棒性与潜在表示压缩之间的关系，通过维数和保留信息来定义", "innovation": "H-SPLID算法通过将显著和非显著特征明确分解到不同的空间中，能够学习到低维度的任务相关特征。此外，该研究证明了在输入扰动下的预测偏差上限与显著子空间的维度以及输入和表示之间的希尔伯特-施密特独立性测度（HSIC）之间的关系，这为鲁棒性和潜在表示压缩间的关系提供了新的视角", "conclusion": "实验证明，使用H-SPLID训练的模型主要依赖于显著输入组件，对扰动非显著特征（如图像背景）表现出较低的敏感性。这一发现揭示了H-SPLID在图像分类任务中的优点，并证明了其在减少模型复杂性方面的潜在价值。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20629", "html_url": "https://arxiv.org/abs/2510.20629", "title": "公平生存预测：一种公平意识下的生存建模（FASM）方法", "title_en": "Equitable Survival Prediction: A Fairness-Aware Survival Modeling (FASM) Approach", "authors": "Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu", "background": "随着机器学习模型在医疗领域的广泛应用，临床数据中固有的结构性不平等和社会偏见可能被数据驱动的模型进一步延续或放大。在生存分析中，截尾数据和时间动态会进一步增加公平模型开发的复杂性。现有的算法公平性方法往往忽视了不同群体排名中的不平等，比如高风险的黑人患者可能被排名在低风险白人患者之后，尽管这些白人患者并未经历死亡事件。这种误排名会强化生物本质论并损害公平医疗。", "innovation": "提出了公平意识下的生存建模（FASM），旨在减轻内部群体和跨群体风险排名中的算法偏见。通过乳腺癌预后作为典型案例，FASM 在 SEER 乳腺癌数据上显示，相较于未注意到公平性的生存模型，FASM 显著提高了公平性，同时保留了相似的判别表现。时间分层评估表明，FASM 在 10 年内保持稳定公平性，在随访中期显示出最大的改进，允许在临床决策中优先考虑准确性和公平性，将公平性作为临床护理的核心原则。", "conclusion": "FASM 方法在确保准确性的前提下提高了模型的公平性，并且保持了一定的判别性能。FASM 在随访中期显示出显著的公平性改进，在 10 年内保持稳定公平性。这种方法能够推动在临床决策中同时实现准确性和公平性的目标，将公平性确立为临床护理的核心原则。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20616", "html_url": "https://arxiv.org/abs/2510.20616", "title": "关于最优超参数在不同隐私程度的深度迁移学习中的研究", "title_en": "On Optimal Hyperparameters for Differentially Private Deep Transfer Learning", "authors": "Aki Rehn,Linzh Zhao,Mikko A. Heikkilä,Antti Honkela", "background": "在当前条件下，差分隐私（DP）的迁移学习，即在私有数据上微调预训练模型，是隐私约束下训练大型模型的最新方法。在这一场景中，我们关注两个关键超参数：截断上限$C$和批量大小$B$。理论研究表明更强的隐私要求较小的$C$，但实验证明在强隐私条件下更大的$C$表现更好，这是因为梯度分布的变化导致了理论与实践之间的不一致。我们假设计算预算固定（固定的迭代次数），指出现有的$B$调整策略无效，而累积DP噪声更好地解释了较小或较大的批次哪个表现更好。我们还指出，使用单一的$(C,B)$设置跨任务可能导致性能不佳，尤其是在隐私程度和计算资源从宽松到紧张的变化时，性能尤为下降。这通过将截断视为梯度加权的形式以及研究累积DP噪声来进行分析解释。", "innovation": "本文展示了在差分隐私的深度迁移学习中，现有理论与实践中的$C$和$B$超参数选择之间不一致的问题，提出使用累积DP噪声来更好地解释哪种批次大小表现更好，并指出单一$(C,B)$设置可能导致的性能下降，进一步强调了通过分析截断作为梯度加权的形式来解释这种不一致的现象。", "conclusion": "研究发现在不同隐私水平和计算资源条件下，单一的$(C,B)$设置可能导致性能不佳，特别是在隐私从松到紧、计算资源从多到少的变化时，性能衰退尤为明显。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20615", "html_url": "https://arxiv.org/abs/2510.20615", "title": "MS-BART: 统一建模质谱数据和分子结构以进行结构解析", "title_en": "MS-BART: Unified Modeling of Mass Spectra and Molecules for Structure Elucidation", "authors": "Yang Han,Pengyu Wang,Kai Yu,Xin Chen,Lu Chen", "background": "质谱（MS）在分子识别中扮演着关键角色，极大地推动了科学研究。然而，从MS数据推断分子结构仍面临挑战，因为缺乏标注的光谱谱图。虽然大规模预训练在其他领域中有效解决了数据稀缺性问题，但将其应用于质谱时却面临光谱信号复杂性和异构性所带来的挑战。为了应对上述问题，我们提出了一种统一建模框架MS-BART，该框架将质谱和分子结构映射到共享的标记词汇表中，通过可靠计算的指纹-分子数据集进行大规模预训练，以实现跨模态学习。同时，多任务预训练目标进一步增强MS-BART的泛化能力，通过同时优化去噪和翻译任务。预训练模型通过使用MIST进行分子指纹预测的微调，增强其在真实世界光谱变异下的稳健性。", "innovation": "MS-BART模型通过集成大规模预训练和多任务学习，将质谱数据和分子结构映射到共享的标记词汇表，实现了跨模态学习。微调使预训练模型能够更好地适应实际光谱数据的变化，并通过引入化学反馈机制来减少分子幻觉，从而更接近参考结构。MS-BART在关键指标上的性能达到SOTA水平，并且比竞争的基于扩散的方法快一个数量级，全面的消融研究系统地验证了该模型的有效性和稳健性。", "conclusion": "MS-BART模型适用于质谱数据和分子结构解释任务，并通过大规模预训练和多任务优化提高了模型的有效性和稳健性。虽然微调可以减轻分布差异的影响，但仍需进一步对分子幻觉进行调整。MS-BART在关键性能指标上的表现优于现有方法，并且以一个数量级的速度快速执行。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20637", "html_url": "https://arxiv.org/abs/2510.20637", "title": "大型多模态模型赋能的任务导向自主通信：设计方法与实施挑战", "title_en": "Large Multimodal Models-Empowered Task-Oriented Autonomous Communications: Design Methodology and Implementation Challenges", "authors": "Hyun Jong Yang,Hyunsoo Kim,Hyeonho Noh,Seungnyun Kim,Byonghyo Shim", "background": "大型语言模型（LLMs）和大型多模态模型（LMMs）已经取得了前所未有的突破，展现了在自然语言理解和生成以及复杂推理方面的显著能力。这些模型的应用潜力使其成为6G自主通信的关键使能器，尤其是在机器、车辆和类人机器人之间的通信中。本文回顾了LLMs/LMMs在任务导向自主通信中的应用，重点关注多模态感知集成、自适应重构以及无线任务的提示/微调策略。文章通过三个案例研究展示了框架的应用：基于LMM的交通控制、基于LLM的机器人调度和基于LMM的环境感知信道估计。实验结果显示，所提出的LLM/LMM辅助自主系统显著优于传统和区分性的深度学习（DL）模型方法，在动态目标、变化的输入参数和异构多模态条件下保持了鲁棒性。", "innovation": "本文提出了多模态感知集成、自适应重构以及提示/微调策略的框架，这些策略针对无线任务进行了优化。通过三个具体的案例研究详细展示了这一框架的应用，以及它们如何在动态环境下提高系统的鲁棒性。特别是，提出的LLM/LMM辅助自主系统在保持性能的同时，能够处理动态目标和多变的输入参数等复杂情况。与传统的和具有区分性的深度学习方法相比，该系统表现出优越的性能。", "conclusion": "本文提出的框架能够显著提高自主通信系统在动态环境下的性能，并且能够在不确定性高的情况下保持高鲁棒性。此外，多模态模型的应用为6G自主通信提供了新的设计思路和技术支持。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20640", "html_url": "https://arxiv.org/abs/2510.20640", "title": "基于注意力增强的智能云系统实体推荐", "title_en": "Attention Enhanced Entity Recommendation for Intelligent Monitoring in Cloud Systems", "authors": "Fiza Hussain,Anson Bastos,Anjaly Parayil,Ayush Choure,Chetan Bansal,Rujia Wang,Saravan Rajmohan", "background": "在本研究中，我们探讨了在Microsoft监控云服务时使用注意力增强实体推荐框架DiRecGNN。传统方法由于同质化性质，在面对云服务实体间的结构和参与信息有限以及长距离依赖性时表现不佳。研究团队构建了一个生产规模的监控异质图，发现基于图的实体推荐方法在这些情形下效果较差，因此提出了一种基于Transformer架构的注意力增强实体排名模型，能够关注异质邻居及其属性，并通过随机游走捕捉长距离依赖性。同时，我们采用多角度损失函数来优化推荐结果，考虑到数据的固有稀疏性。实验结果表明，该模型在MRR改进上表现显著，相较于现有方法提高了43.1%。并且，产品团队普遍认为该功能具有重要价值，评分高达4.5分（满分5分）", "innovation": "我们提出了DiRecGNN，一种基于Transformer架构的注意力增强实体推荐模型。该模型通过多头注意力机制关注异质邻居及其属性，同时使用随机游走捕获长距离依赖性，并采用多角度损失函数优化推荐结果", "conclusion": "实验结果表明，DiRecGNN在云监控场景中表现出显著优于传统方法的性能，产品团队认为此功能对监控云服务非常有用"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20644", "html_url": "https://arxiv.org/abs/2510.20644", "title": "连接Jensen-Shannon分发与克劳克-莱布尼茨偏差：用于表示学习的新界。", "title_en": "Connecting Jensen-Shannon and Kullback-Leibler Divergences: A New Bound for Representation Learning", "authors": "Reuben Dorent,Polina Golland,William Wells III", "background": "互信息（MI）是广泛应用于表示学习的一种统计依赖性的重要度量方法。虽然直接通过其定义作为Kullback-Leibler偏差（KLD）进行最优化通常不可操作，但许多最近的方法却最大限度地利用了替代依赖性指标，如联合分布和边缘分布乘积的Jensen-Shannon分发（JSD）。然而，这些替代目标与MI之间的联系了解不足。", "innovation": "作者推导出了一种新的、紧密的、可操作的KLD作为JSD函数的下界。通过将该界应用于联合和边缘分布，证明了通过最大化基于JSD的信息可以增加MI的一个已证实的下界。他们还重新审视了JSD基目标的实用实现，并发现通过最小化二进制分类器的交叉熵损失来区分联合对和边际对，可以恢复已知的基于变分下界的JSD。广泛的实验表明，作者的下界估计在应用于互信息估计时是紧密且稳定的。", "conclusion": "作者的结果提供了使用判别学习进行基于互信息的表示学习的新理论依据和强有力的实证证据。该研究还展示了其在信息瓶颈框架下的实际用途。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20651", "html_url": "https://arxiv.org/abs/2510.20651", "title": "xTime: 使用层级知识蒸馏和专家融合进行极端事件预测", "title_en": "xTime: Extreme Event Prediction with Hierarchical Knowledge Distillation and Expert Fusion", "authors": "Quan Li,Wenchao Yu,Suhang Wang,Minhua Lin,Lingwei Chen,Wei Cheng,Haifeng Chen", "background": "在现实世界的时间序列中，极端事件经常发生并具有显著的实际意义。在诸如气候和医疗等领域，这些事件（如洪水、热浪或急性医疗事件）可能导致严重后果。因此，准确预测这些事件具有重大意义。然而，现有的大多数时间序列预测模型优化的是整体预测窗口内的性能，往往难以准确预测极端事件，如高温或心率峰值。主要挑战包括数据不平衡以及忽视在极端事件之前发生的中级事件所包含的有价值信息。", "innovation": "本文提出了一种名为 xTime 的新型框架，用于时间序列中的极端事件预测。xTime 利用知识蒸馏从稀有事件训练的模型中转移信息，进而提高稀有事件的预测性能。此外，引入了一种专家融合机制（MoE），该机制动态选择并融合不同稀有度级别专家模型的输出，进一步提高极端事件的预测性能。", "conclusion": "实验结果显示，xTime 在多个数据集上取得了持续改进。极端事件的预测精度从3%提高到了78%。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20671", "html_url": "https://arxiv.org/abs/2510.20671", "title": "GRACE: 基于图的成瘾护理预测", "title_en": "GRACE: GRaph-based Addiction Care prEdiction", "authors": "Subham Kumar,Prakrithi Shivaprakash,Koustav Rudra,Lekhansh Shukla,Animesh Mukherjee", "background": "确定成瘾患者的护理地点是影响治疗结果和资源有效利用的关键临床决策之一。在缺乏足够的专门治疗资源，如住院床位或工作人员的情况下，需要开发自动化框架来解决这一问题。当前决策方法在成瘾数据集中存在严重的类别不平衡问题。", "innovation": "提出了一种新颖的图神经网络（GRACE）框架，将护理地点预测正规化为结构化学习问题。进行了广泛的特征工程，并提出了一种获得无偏置元图的新方法，用于训练图神经网络以克服类别不平衡问题。实验结果显示，与竞争基线相比，少数类的F1分数提高了11-35%。", "conclusion": "实验结果表明，GRACE框架在实际数据中比竞争基线提高了11-35%的少数类F1分数。代码和嵌入的笔记可在以下链接获取。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20666", "html_url": "https://arxiv.org/abs/2510.20666", "title": "使用混合CNN和路径损耗专家混合模型的贝叶斯干扰器定位", "title_en": "Bayesian Jammer Localization with a Hybrid CNN and Path-Loss Mixture of Experts", "authors": "Mariona Jaramillo-Civill,Luis González-Gudiño,Tales Imbiriba,Pau Closas", "background": "全球导航卫星系统（GNSS）信号在城市区域由于多径效应和阴影遮挡，噪声特别容易受到干扰。尽管以往的数据驱动方法可以在一定程度上实现定位，但由于空间上下文有限，它们很难准确重建接收到的信号强度（RSS）领域。", "innovation": "本文提出了一种混合贝叶斯混合专家框架，结合物理路径损耗模型和卷积神经网络（CNN），通过对数线性池化融合。物理路径损耗专家确保了物理一致性，而CNN则利用建筑物高度地图捕捉城市传播效应。通过拉普拉斯近似进行贝叶斯推断，可以在干扰器位置和RSS场两个方面提供后验不确定性。实验结果表明，随着训练点的增加，定位精度提高，不确定性减少，并且不确定性的集中区域与干扰器和城市峡谷最敏感的传播路径相对应。", "conclusion": "实验表明，该方法在城市区域的GNSS信号干扰定位和RSS场重建方面具有优越性，特别是在干扰器附近和城市峡谷等传播敏感区域。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20668", "html_url": "https://arxiv.org/abs/2510.20668", "title": "从面罩到世界：世界模型的指南", "title_en": "From Masks to Worlds: A Hitchhiker's Guide to World Models", "authors": "Jinbin Bai,Yu Lei,Hecong Wu,Yuchen Zhu,Shufan Li,Yi Xin,Xiangtai Li,Molei Tao,Aditya Grover,Ming-Hsuan Yang", "background": "该论文并非对世界模型的全面调查，而是为想要构建世界模型的人提供指导。它不旨在列出所有提到“世界模型”的研究文章，而是专注于从早期统一跨模态表示学习的掩码模型，到共享单一范式的统一架构，再到能够关闭行动-感知循环的交互生成模型，最后到能够保持时间一致性记忆增强系统的发展途径。通过忽略与核心主题关系不紧密的分支，论文强调了生成核心、交互循环和记忆系统的重要性。研究表明，这条途径是最有希望实现真正世界模型的道路。", "innovation": "本文的创新在于提供了一个从早期统一跨模态表示学习的掩码模型到能够保持时间一致性记忆增强系统的发展途径的详细指南。它聚焦于生成核心、交互循环和记忆系统，而不是广泛回顾所有涉及世界模型的研究。这种方法强调了构建连贯且互动的世界模型的关键要素。", "conclusion": "本文表明，世界模型的研究正在朝着能够将生成、交互和记忆紧密结合的方向发展，这可能是实现真正世界模型的最有效路径。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20714", "html_url": "https://arxiv.org/abs/2510.20714", "title": "优化临床跌倒风险预测：电子健康记录变量与约翰霍普金斯跌倒风险评估工具的数据驱动整合", "title_en": "Optimizing Clinical Fall Risk Prediction: A Data-Driven Integration of EHR Variables with the Johns Hopkins Fall Risk Assessment Tool", "authors": "Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi", "background": "本文旨在通过数据驱动建模方法，更好地使约翰霍普金斯跌倒风险评估工具（JHFRAT）的跌倒风险预测与临床重要的额外指标相一致。研究分析了2022年3月至2023年10月间约翰霍普金斯健康系统的三家医院的54,209名住院患者的记录，共涉及20,208个高跌倒风险的住院病例和13,941个低跌倒风险的住院病例。", "innovation": "利用了受约束得分优化（CSO）模型，在JHFRAT评估数据和额外的电子健康记录（EHR）变量上进行建模，以结合临床知识并保持模型的可解释性。在预测性能上，CSO模型显著优于当前的JHFRAT（CSO AUC-ROC=0.91，JHFRAT AUC-ROC=0.86）。虽然基准的黑盒模型（XGBoost）在知识驱动的有约束条件逻辑回归的基础上改进了性能指标（AUC-ROC=0.94），但CSO在风险标签变化时更加稳健。", "conclusion": "基于证据的这种方法为医疗系统提供了一个坚实的基础，可以系统地提高住院跌倒预防协议并增强患者安全，通过数据驱动的优化技术改进风险评估和资源分配，改善了医疗保健环境中的风险评估和资源分配。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20709", "html_url": "https://arxiv.org/abs/2510.20709", "title": "通过分离组成计算的what和how来实现重用和持续学习", "title_en": "Separating the what and how of compositional computation to enable reuse and continual learning", "authors": "Haozhe Shan,Sun Minni,Lea Duncker", "background": "持续学习、技能保留和灵活应用的能力是智能高效行为的关键特征。然而，支持持续学习及其技能重组的神经机制仍然难以捉摸。本研究使用一种新颖的双系统方法——一个系统负责推断执行何种计算，另一个系统负责实现如何执行计算——来研究使用递归神经网络模型的持续学习和技能的可组合重用。研究者关注一套广泛研究的认知组成任务，展示了这些任务可以系统地描述为一个概率生成模型，共享的时间结构使这些任务成为天然的可组合。这种方法为理解和模仿人类认知中的可组合性提供了新的视角，并可以在线无监督学习的方式学习这个模型。通过一个递归神经网络系统，使用从推理中获得的上下文来组成低秩子模块，实现持续学习而不会遗忘先前的知识。实验表明，该双系统学习框架在促进迁移学习和快速泛化方面具有优越性。", "innovation": "提出了一个新颖的双系统模型：一个系统负责推断执行何种计算，另一个系统负责实现如何执行计算。通过这种方式，递归神经网络可以在线无监督学习的方式学习概率生成模型，并利用上下文触发低秩子模块的组成和使用，实现持续学习而不会遗忘。同时，该方法展示了其在促进迁移学习和快速泛化到未见任务中的潜在能力。", "conclusion": "研究证明了通过分离组成计算的what和how，可以实现持续学习和技能的可组合重用。这种双系统架构为递归神经网络提供了一种有效的方式来实现持续学习，同时能够快速适应新的任务。该研究还指出其方法具有向前和向后的迁移能力以及快速的泛化性能，为逐步引入的新任务提供了有效的学习框架。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20736", "html_url": "https://arxiv.org/abs/2510.20736", "title": "通过变分狄利克雷过程增强多模态学习中的显著表示", "title_en": "Amplifying Prominent Representations in Multimodal Learning via Variational Dirichlet Process", "authors": "Tsai Hor Chan,Feng Wu,Yihang Chen,Guosheng Yin,Lequan Yu", "background": "在许多真实场景中，如医疗和金融，有效开发多模态融合方法变得越来越重要。关键挑战是如何在学习多模态交互的同时保持每个模态的特征表达性。以往的方法主要集中在跨模态对齐上，过于强调边际分布的对齐可能会施加过大的正则化，阻碍每个模态内的有意义表示。", "innovation": "提出了一种新的基于狄利克雷过程（DP）的多模态学习框架，该框架可以自动实现显著的模内表示学习和跨模态对齐之间的最优平衡。该框架假设每个模态遵循多元高斯分布的混合模型，并进一步采用DP计算所有成分的混合权重。这种范式使DP能够动态分配特征贡献并选择最显著的特征，利用其‘富者愈富’的特性，从而促进多模态特征融合。", "conclusion": "在多个多模态数据集上进行的广泛实验表明，该模型优于其他竞争方法。消融分析进一步验证了DP在对齐模态分布及对关键超参数变化的鲁棒性方面的有效性。代码可以在该网址匿名访问：这个 https URL"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20718", "html_url": "https://arxiv.org/abs/2510.20718", "title": "多变量半导体工艺时间序列中基于N-BEATS和图神经网络的无监督异常预测", "title_en": "Unsupervised Anomaly Prediction with N-BEATS and Graph Neural Network in Multi-variate Semiconductor Process Time Series", "authors": "Daniel Sorensen,Bappaditya Dey,Minjin Hwang,Sandip Halder", "background": "半导体制造是一个高度复杂且需要高度精确的过程，涉及数千个在不同工具和工艺步骤中相互依赖的参数。多变量时间序列分析已成为此类环境中实时监控和故障检测的关键领域。然而，半导体制造中的异常预测面临一些关键挑战，包括传感器数据的高维性和实际故障的严重类别不平衡，因为真正的故障很少见。此外，变量之间的复杂相互依赖性使异常预测和根本原因分析都变得复杂。", "innovation": "本文提出了两种新颖的方法，旨在将异常检测推进到异常预测，这一步骤对于实现实时过程纠正和预防性故障预防至关重要。提出的异常预测框架分为两个主要阶段：(a) 使用假设未包含异常的数据集训练预测模型，以及(b) 对未观察到的时间序列数据进行预测。预测结果与训练信号的预测进行比较。偏离预定义阈值的偏差被标记为异常。两种方法在所使用的预测模型上有所不同。第一种方法假设变量之间存在独立性，使用N-BEATS模型进行单变量时间序列预测。第二种方法克服了这一假设，通过利用图神经网络（GNN）来捕捉变量间的相互关系。GNN在时序预测上的表现优于N-BEATS模型，同时需要更少的可训练参数和更低的计算成本。", "conclusion": "这两种模型在20个时间点的时序预测上表现出色，并在50个时间点的异常预测上保持稳定。GNN持续优于N-BEATS模型，且需要更少的训练参数和更低的计算成本。这些结果使GNN成为在线异常预测的有希望的解决方案，可以部署在制造环境中。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20725", "html_url": "https://arxiv.org/abs/2510.20725", "title": "带有高斯过程的有限时间 horizon 马尔可夫决策过程中的无悔Thompson采样", "title_en": "No-Regret Thompson Sampling for Finite-Horizon Markov Decision Processes with Gaussian Processes", "authors": "Jasmine Bayrooti,Sattar Vakili,Amanda Prorok,Carl Henrik Ek", "background": "Thompson采样（TS）是一种强大的、广泛应用的顺序决策策略，适用于从贝叶斯优化到强化学习（RL）等多个领域。然而，尽管TS在实践中非常成功，但在具有复杂时间结构如RL的环境中，其理论基础仍然相对有限。为了解决这一问题，本文通过使用具有高斯边缘分布的模型来为TS建立无悔保证。特别地，作者考虑了使用联合高斯过程（GP）先验处理奖励和转移的阶段性RL。", "innovation": "本文的创新之处在于，通过建立使用高斯边缘分布模型的TS的无悔保证，克服了价值函数的非高斯性质和贝尔曼更新的递归结构带来的挑战。此外，本文还扩展了经典工具（如椭圆势函数引理）以适应多输出场景，从而推进了对TS在有限时间horizon的马尔可夫决策过程中的理解，并强调了结构假设和模型不确定性对其性能的影响。", "conclusion": "本文的工作丰富了我们对TS在RL中的理解，并揭示了结构假设和模型不确定性如何在有限horizon的马尔可夫决策过程中影响TS的性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20733", "html_url": "https://arxiv.org/abs/2510.20733", "title": "多智能体合作中的思维通信", "title_en": "Thought Communication in Multiagent Collaboration", "authors": "Yujia Zheng,Zhuokai Zhao,Zijian Li,Yaqi Xie,Mingze Gao,Lizhu Zhang,Kun Zhang", "background": "自然语言使人能够协作，但由于其易失性、歧义性和间接性，限制了集体智能的潜力。目前，大多数基于LLM的多智能体系统仍然依赖自然语言进行交互。为了超越自然语言的限制，本文提出了一个全新的人工智能交流模式——思维通信，即心灵间的直接交流。通过一个基于潜在变量模型的形式化方法，揭示了智能体的潜在思维，并证明在无需辅助信息的非参数设置下，可以识别出任意两智能体之间的共享和私有潜在思维。此外，还可以通过理论保证来恢复思维共享的全局结构。", "innovation": "提出了一种‘思维通信’的新模式，该模式消除了传统自然语言交互的限制，使得智能体能够直接进行心理层面的交流。通过非参数模型，它可以识别出任意两智能体之间的私有和共有潜在思维，并揭示这些思维共享的全局结构，从而为解决现有交流模式下难以解决的问题提供了新的途径。此方法不受应用场景限制，适用于任何数据观测形式。", "conclusion": "实验结果证明了该理论的有效性，并展示出思维通信在协作任务中所带来的优势。这样的工作揭示了深层交流可能带来的潜力，尤其是在表面层次的观察无法解决问题的场景下，无论计算资源和数据规模如何，许多挑战仍难以解决。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20683", "html_url": "https://arxiv.org/abs/2510.20683", "title": "基于突触神经网络的可扩展、因果和节能神经解码框架", "title_en": "A Scalable, Causal, and Energy Efficient Framework for Neural Decoding with Spiking Neural Networks", "authors": "Georgios Mentzelopoulos,Ioannis Asmanis,Konrad P. Kording,Eva L. Dyer,Kostas Daniilidis,Flavia Vitale", "background": "脑-机接口（BCIs）能够为神经运动障碍患者提供至关重要的功能，如言语和假肢控制。关键在于神经解码器，它们将神经活动映射到预期行为。现有的基于学习的解码方法分为两类：简单但不具备泛化能力的因果模型，或者复杂的非因果模型，这些模型虽然可以离线泛化和扩展，但在实时场景中表现不佳。这两种方法都存在一个共同挑战，即依赖于高耗能的人工神经网络基础架构，这使得整合到资源有限的现实世界系统中变得困难。突触神经网络（SNNs）提供了一种有前途的替代方案，因为它们是因果的，适用于实时使用，同时低能耗使其成为电池受限环境的理想选择。", "innovation": "我们提出了Spikachu：一种基于SNNs的可扩展、因果和节能神经解码框架。我们的方法直接处理计数的脉冲，并将它们投影到共享的潜空间中，其中适应输入时间的脉冲模块提取相关信息；这些潜在表示随后进行整合和解码以生成行为预测。我们在6只非人类灵长类动物的113个记录会话中评估了我们的方法，总时长为43小时。并且通过多会话和被试的缩放训练提升了性能并实现了对未见过的会话、被试和任务的少样本迁移。总体而言，Spikachu引入了一个基于SNNs的可扩展、在线兼容的神经解码框架，其性能在与最先进的模型竞争的同时消耗了数量级更低的能源。", "conclusion": "Spikachu引入了一个基于SNNs的可扩展、在线兼容的神经解码框架，该框架的性能在与最先进的模型竞争的同时消耗了数量级更低的能源。该方法在单个会话上的训练使用2.26到418.81倍更少的功耗时表现超过了因果基线。进一步的研究表明，将训练扩大到多个会话和被试提高了性能，并允许对未见过的会话、被试和任务实现少样本迁移。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20762", "html_url": "https://arxiv.org/abs/2510.20762", "title": "MEIcoder：通过利用最兴奋输入解码神经活动以解码视觉刺激", "title_en": "MEIcoder: Decoding Visual Stimuli from Neural Activity by Leveraging Most Exciting Inputs", "authors": "Jan Sobotka,Luca Baroni,Ján Antolík", "background": "从神经群体活动中解码视觉刺激对于理解大脑和用于大脑-机器接口的应用至关重要。然而，生物数据经常稀缺，特别是在灵长类动物或人类中，由于技术挑战，如双光子成像，难以广泛应用，这给深度学习解码技术带来了难题。因此，需要一种新的方法来解决这一问题。", "innovation": "本文提出了一种生物信息解码方法MEAdecoder，该方法利用了特定神经元的最兴奋输入（MEIs）、结构相似性索引度量损失以及对抗性训练。MEAdecoder特别适用于局限于少数记录神经元的小型数据集，在初级视觉皮层（V1）的单细胞活动重构方面达到了最先进的性能。该方法在有限数据下表现优异，并能从1000至2500个神经元中重建高保真度、外观自然的图像，还不需要大量训练数据点。此外，还建立了一个包含超过160,000个样本的统一基准，以促进未来研究。", "conclusion": "我们的结果展示了在早期视觉系统中可靠解码的可能性，并为神经科学和神经工程学应用提供了实际的见解。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20783", "html_url": "https://arxiv.org/abs/2510.20783", "title": "out-of-distribution tests reveal compositionality in chess transformers", "title_en": "Out-of-distribution Tests Reveal Compositionality in Chess Transformers", "authors": "Anna Mészáros,Patrik Reizinger,Ferenc Huszár", "background": "象棋是一个典型的需要严谨推理和长远规划的任务。现代决策Transformer（类似于预训练语言模型）能够学习有效的对弈技巧，但还不清楚它们在多大程度上真正捕捉到了象棋的规则。为此，作者训练了一个由270M参数组成的象棋Transformer，并测试了该模型在训练数据之外的场景中的表现。", "innovation": "作者设计了符合系统泛化失败的测试场景，以评估Transformer模型的表现。结果显示，Transformer模型展示了组合式的泛化能力，在强规则延伸测试中表现出色：它们在与训练数据差异很大的情况下，仍然能遵循游戏的基本句法规则，并选择有效的棋步。此外，它们还能生成高质量的棋步。在更具有挑战性的测试中，模型被评估在Chess960（Fischer Random Chess）变体棋局中的表现，结果显示虽然模型能进行基本的策略适应，但在与Lichess用户对战时，其表现依然逊色于执行显式搜索的符号AI算法。", "conclusion": "训练动态表明，模型最初只学会移动自己的棋子，这表明它有可能在游戏理解上出现了一种新兴的组合式理解。总体来说，研究揭示了决策Transformer在象棋中的组合泛化能力。但其在某些变体棋局中的表现相对较弱，特别是在需要深层策略分析的场景下。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20792", "html_url": "https://arxiv.org/abs/2510.20792", "title": "BadGraph: 针对指导文本图生成的潜在扩散模型的一种后门攻击", "title_en": "BadGraph: A Backdoor Attack Against Latent Diffusion Model for Text-Guided Graph Generation", "authors": "Liang Ye,Shengqin Chen,Jiazhu Dai", "background": "图生成的快速进步引发了新的安全关切，尤其是后门漏洞问题。尽管已有研究探讨了无条件图生成和图像扩散中的后门攻击，但针对指导文本图生成的条件生成方法，尤其是文本指导下的图生成，仍处于空白状态。", "innovation": "本文提出了BadGraph，这是一种针对潜在扩散模型进行文本指导图生成的后门攻击方法。BadGraph利用文本触发器污染训练数据，通过植入攻击者指定的子图实现高度隐秘的攻击，特别是在触发器出现时，在推理过程中诱导攻击者指定的子图，同时在无污染输入上的性能基本保持不变。", "conclusion": "在四个基准数据集（PubChem，ChEBI-20，PCDes，MoMu）上的广泛实验展示了攻击的有效性和隐蔽性：只有不到10%的污染率可以实现50%的攻击成功率，而只需24%的比例即可超过80%的成功率，且对良性样本的性能影响几乎可以忽略不计。消融研究进一步表明，后门植入发生在VAE和扩散训练过程中，而非预训练过程中。这些发现揭示了文本指导图生成中的潜在扩散模型的安全漏洞，强调了此类扩散模型应用中的严重风险，并突显了对后门攻击防御的必要性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20800", "html_url": "https://arxiv.org/abs/2510.20800", "title": "高效使用100个样本的单步梯度压缩以适应LLM", "title_en": "Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples", "authors": "Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus", "background": "Sharma等人提出了一种名为Layer-SElective-Rank reduction (LASER)的方法，通过剪枝精心选择的LLM权重矩阵的高阶组件，无需梯度导向的微调即可提升下游准确性。然而，LASER的全矩阵搜索过程耗时且不适用于快速部署。", "innovation": "该研究提出了一种新的方法，通过消除全矩阵搜索的开销，只有少数精心选择的矩阵需要检查，根据每个矩阵奇异值的梯度确定需要剪枝的矩阵，并通过允许矩阵行围绕多个子空间聚类并分别分解每个群集来进一步减少过拟合，最终在原训练数据上进一步提高了24.6个百分点的准确性。此外，发现只需要评估100个样本而不是全训练数据来计算指示性梯度和测量最终准确性，从而进一步减少了搜索时间。", "conclusion": "最终结果表明，结合这些发现可以快速和稳健地适应下游任务。只需要对100个例子进行一次梯度步骤，扫描顶级候选层和因式分解技术，就可以完全不进行微调地适应LLMs到新数据集中。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19826", "html_url": "https://arxiv.org/abs/2510.19826", "title": "神经震颤：一种支持上肢肌肉功能的可穿戴辅助设备", "title_en": "Neurotremor: A wearable Supportive Device for Supporting Upper Limb Muscle Function", "authors": "Aueaphum Aueawattthanaphisut,Thanyanee Srichaisak,Arissa Ieochai", "background": "该论文介绍了一种传感器融合的上肢功能辅助设备原型，主要针对三角肌和拇指伸肌，通过集成表面肌电图（sEMG）、惯性测量单元（IMU）和弯曲/力传感器等技术，改善患者的上肢功能。背景信息显示，通过传感器数据处理和模型预测，该设备能够提升上肢的运动范围、重复动作频率和降低震颤程度。此外，通过在基于游戏的任务中进行轻量级个性化控制，提升了设备的用户体验。", "innovation": "该研究的创新之处在于：1）设备集成多种传感器技术，实现对上肢功能的综合监测；2）使用INT8 TensorFlow Lite Micro模型进行快速特征计算；3）通过控制屏障函数确保安全性，适用于游戏任务中的轻量级个性化控制；4）在健康志愿者中的初步评估显示出显著的技术可行性，提供了一种新的嵌入式传感器融合辅助工具，可用于改善上肢功能。", "conclusion": "研究表明，该传感器融合的可穿戴辅助设备对于改善上肢功能具有技术可行性，已在健康志愿者中实现了显著的效果，并且设备的安全性和用户体验得到了保障。未来计划进行在IRB监督下的正式患者研究，进一步验证其临床应用潜力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19838", "html_url": "https://arxiv.org/abs/2510.19838", "title": "Branch-and-Browse: 基于树结构推理和动作记忆的高效可控网页探索", "title_en": "Branch-and-Browse: Efficient and Controllable Web Exploration with Tree-Structured Reasoning and Action Memory", "authors": "Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury", "background": "自主网页代理由大规模语言模型驱动，显示出在信息检索、报告生成和在线交易等目标任务中的强大潜力。这些代理标志着开放网页环境实用化体化推理的关键一步。然而，现有方法在推理深度和效率方面仍有限制：朴素的线性方法无法进行多步推理且缺乏有效的回溯，而其他搜索策略则粗粒度且计算成本高。", "innovation": "我们引入了Branch-and-Browse，这是一种精细粒度的网页代理框架，统一了结构化推理-执行、上下文记忆和高效执行。它采用树结构探索进行显式子任务管理，实现可控的多分支推理；通过高效的网页状态回放与背景推理启动探索；并利用页面动作记忆在会话内外共享已探索的动作。", "conclusion": "在WebArena基准测试中，Branch-and-Browse将任务成功率提高到35.8%，并相对于顶级方法将执行时间减少了最多40.4%。这些结果表明，Branch-and-Browse是一个可靠和高效的基于LLM的网页代理框架。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20817", "html_url": "https://arxiv.org/abs/2510.20817", "title": "KL-正则化强化学习是设计为模式塌陷的", "title_en": "KL-Regularized Reinforcement Learning is Designed to Mode Collapse", "authors": "Anthony GX-Chen,Jatin Prakash,Jeff Guo,Rob Fergus,Rajesh Ranganath", "background": "普遍认为，优化逆KL散度会导致“模态寻求”，而优化正向KL散度会导致“质量覆盖”，后者在希望从多个多样模态采样的情况下更受欢迎。然而，作者通过数学和经验分析表明，这种直觉不一定适用于使用逆/正向KL正则化进行强化学习的情景（例如，在语言模型中常用的情况）。作者发现，选择逆/正向KL散度会决定最优目标分布的家族，该家族由正则化系数参数化。模式覆盖主要取决于其他因素，如正则化强度以及奖励与参考概率的相对规模。", "innovation": "作者揭示了常用设置（如低正则化强度和相等可验证奖励）倾向于指定单模目标分布，这意味着优化目标是通过构造非多样性的。作者利用这些见解构建了一个简单、可扩展且具有理论依据的算法。该算法仅对奖励的幅度进行最少的修改，却能优化一个将高概率分布覆盖在所有高质量采样模态上的目标分布。实验结果显示，这一简单的修改能够在不对多样性提供外部信号的情况下，提高语言模型和化学语言模型的解决方案质量和多样性，并且在使用逆/正向KL时这两种方法都会失效。", "conclusion": "该研究通过数学和实验方法揭示了KL散度优化在强化学习中与直觉不符的现象，并提出了一种简单而有效的算法来提高模型的质量和多样性。该算法能够在多种设置下有效，包括使用逆/正向KL时两种常见的方法都失效的情况。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19832", "html_url": "https://arxiv.org/abs/2510.19832", "title": "基于EEG信号的实时手写识别边缘设备低延迟神经推理", "title_en": "Low-Latency Neural Inference on an Edge Device for Real-Time Handwriting Recognition from EEG Signals", "authors": "Ovishake Sen,Raghav Soni,Darpan Virmani,Akshar Parekh,Patrick Lehman,Sarthak Jena,Adithi Katikhaneni,Adam Khalifa,Baibhab Chatterjee", "background": "脑-机接口（BCIs）为严重运动或言语障碍的个体恢复通信提供了途径。想象中的书写为字符级神经解码提供了一种直观的模型，能够桥接人类意图与数字通信之间的差距。侵入性方法如皮层脑电图（ECoG）具有高准确性，但手术风险限制了其广泛应用。非侵入性脑电图（EEG）提供了更安全且更具可扩展性的替代方案，但其信噪比低和空间分辨率差限制了其解码精度。因此，需要结合先进的机器学习和具有信息性的EEG特征提取来克服这些障碍，以实现实时、高精度的神经解码，部署于便携式边缘设备中。", "innovation": "通过结合先进的机器学习和具有信息性的EEG特征提取方法，该研究证明了在进行想象书写时，系统能够在NVIDIA Jetson TX2上实现89.83％的准确率和914.18毫秒/字符的低延迟，并通过选择十个关键特征，将延迟减少近4.5倍至202.6毫秒，同时保持不到1％的准确性损失，从而实现了准确、低延迟的便携式非侵入式BCIs，支持实时通信。", "conclusion": "这项研究表明，结合先进的机器学习和EEG特征提取方法，能够克服EEG信号解码的低信号噪声比和低空间分辨率问题，实现便携式非侵入式BCIs的实时高精度解码，为严重障碍患者提供了一种新的通信手段。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17561", "html_url": "https://arxiv.org/abs/2510.17561", "title": "相关尖峰模型中谱临界值及其偏最小二乘法的基本局限", "title_en": "Spectral Thresholds in Correlated Spiked Models and Fundamental Limits of Partial Least Squares", "authors": "Pierre Mergny,Lenka Zdeborová", "background": "该文研究了两个高维数据通道之间部分对齐的尖峰协方差模型，并提供了一种严谨的随机矩阵理论分析。这种模型被多模学习所驱动，并且构成了偏最小二乘（PLS）方法的基础，尽管PLS在实际应用中非常广泛，但在理论上尚未得到充分开发。通过分析样本协方差矩阵的主奇异值，文章揭示了PLS在信号恢复能力上的新见解，并指出PLS在某些信噪比（SNR）和相关性条件下无法恢复任何信号，尽管理论上可能存在可检测性。这些发现对PLS的理论界限提供了新的理解，并为高维多模推断方法的设计提供了指导。文章使用了Baik-Ben Arous-Peche（BBP）类型的相变原理来描述信息性成分的产生阈值，这是对PLS在这种具体环境下单信号恢复能力的第一篇严格渐近描述。这也揭示出PLS与贝叶斯最优估计器之间的基本性能差距。", "innovation": "1. 通过Baik-Ben Arous-Peche（BBP）类型的相变原理，精确描述了信号恢复能力的阈值，这是P色彩差法在高维多模推断领域中的首次严格渐近描述。2. 揭示了P色彩差法在某些信噪比和相关性条件下的信号恢复能力有限，尽管理论上可能存在检测性。3. 这些研究结果为理解和设计可靠多模推断方法提供了理论指导，并提供了对P色彩差方法性能局限性的新认识。", "conclusion": "研究揭示了在多模态数据推断中，偏最小二乘法的性能局限性，主要是由于信噪比和相关性条件下的信号恢复能力不足。这不仅填补了偏最小二乘法理论研究的空白，还为多模态数据分析方法特别在高维环境中设计和应用提供了新的视角。对于推断方法的选择和优化，提供了理论指导。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19854", "html_url": "https://arxiv.org/abs/2510.19854", "title": "热带气旋对流结构的多尺度分析用于短期强度指导", "title_en": "Multi-Resolution Analysis of the Convective Structure of Tropical Cyclones for Short-Term Intensity Guidance", "authors": "Elizabeth Cucuzzella,Tria McNeely,Kimberly Wood,Ann B. Lee", "background": "在大西洋热带气旋（TC）流域内，准确的24小时内TC短期强度预报对于减少灾害至关重要。由于大多数TC远离陆基观测网络发展，卫星图像对于监测这些风暴是至关重要的；然而，这些复杂的高分辨率空间结构在预报员的实时定性解释上具有挑战性。", "innovation": "我们提出了一种简洁、可解释和描述性的方法，利用离散小波变换（DWT）的多尺度分析（MRA）来量化细粒度的TC结构，使数据分析师能够识别出与快速强度变化强烈相关的基本物理结构特征。此外，深度学习技术可以在此基础上进行短期强度指导。", "conclusion": "这种多尺度分析方法能够帮助预报员更加精确地理解TC的内部结构，从而提供更准确的短期强度预报，有助于减少相关灾害的影响。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19864", "html_url": "https://arxiv.org/abs/2510.19864", "title": "SODBench: 一种使用大型语言模型记录电子表格操作的方法", "title_en": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "authors": "Amila Indika,Igor Molybog", "background": "许多知识工作者在商业、会计和金融领域依赖电子表格，但缺乏系统的电子表格文档方法限制了自动化、协作和知识传递，增加了关键机构知识损失的风险。现有研究利用大型语言模型（LLMs）生成电子表格操作代码，但将其转换为自然语言的电子表格操作文档是一个较少探索的领域。为此，本文提出了一种名为Spreadsheet Operations Documentation（SOD）的AI任务，旨在从电子表格操作中生成人可以读取的解释。", "innovation": "本文构建了一个包含111个电子表格操作代码片段及其对应自然语言摘要的数据集，用于评估五种LLMs的性能，从而展示了LLMs在生成准确电子表格文档方面的潜力，推动电子表格操作可重复性、可维护性和协作流程的提高，尽管仍存在一些挑战需要解决。", "conclusion": "研究表明，大语言模型能够生成准确的电子表格文档，使SOD成为提高电子表格操作的可重复性、可维护性和支持协作流程的重要步骤，但仍有待克服的挑战。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19842", "html_url": "https://arxiv.org/abs/2510.19842", "title": "DAG-Math: 在LLMs中基于图引导的数学推理", "title_en": "DAG-Math: Graph-Guided Mathematical Reasoning in LLMs", "authors": "Yuanhe Zhang,Ilja Kuzborskij,Jason D. Lee,Chenlei Leng,Fanghui Liu", "background": "大规模语言模型（LLMs）在受到指令链推理（CoT）提示时，显示出在数学问题上的强大表现，但这种成功的原因仍不清楚，可能是基于搜索、死记硬背的步骤或规则一致的推理。为了解决这一问题，作者将CoT建模为有向无环图（DAG）上的基于规则的概率过程，并提出了一种度量模型的CoT轨迹与DAG结构契合度的“逻辑亲密性”指标，从而提供了超越传统PASS@k指标的评价方法。在此基础上，作者提出了DAG-MATH CoT格式，构建了以引导LLMs生成特定CoT轨迹的基准数据集，以评估其在新框架下的推理能力。", "innovation": "作者提出了一种新颖的方法来评价LLMs的推理能力，即通过将CoT建模为有向无环图上的概率过程，并引入逻辑亲密性作为度量模型CoT轨迹与DAG结构吻合程度的指标。作者还提出了DAG-MATH CoT格式和数据集，进一步引导LLMs生成特定格式的CoT轨迹，从而能够更准确地评估其推理能力。", "conclusion": "通过对标准数学推理数据集的分析，作者发现即使是PASS@k类似的准确度，不同LLM家族在推理准确度方面也存在统计学意义上的显著差异，突显了最终答案准确性和规则一致性推导之间的差距。作者提出的框架为自由形式CoT和形式化证明系统之间的平衡提供了新的方法，为LLMs推理能力的评估提供了有实际意义的诊断工具。基准数据集和代码已公开。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19867", "html_url": "https://arxiv.org/abs/2510.19867", "title": "由人工智能驱动的从榕树中识别潜在抗糖尿病化合物", "title_en": "Artificial Intelligence Powered Identification of Potential Antidiabetic Compounds in Ficus religiosa", "authors": "Md Ashad Alam,Md Amanullah", "background": "糖尿病是一种慢性代谢障碍，随着病情的逐渐发展和多种代谢并发症的出现，需要新的治疗方法。研究发现，榕树是一种传统草药，能够产生具有潜在抗糖尿病特性的生物活性植物化学物质。为此，研究利用生态系统为基础的计算方法，结合人工智能技术，评估从榕树中提取的具有抗糖尿病特性的化合物。在此过程中，采用机器学习方法、分子对接技术和ADMET预测系统来评估这些植物化学物质对抗糖尿病酶DPP-4的效力。", "innovation": "研究采用了深度绑定GCN和AutoDock软件等深度学习技术来探究化合物与DPP-4的结合机制，并且通过引入人工智能加速筛选过程，提高了筛选的准确率，展示了其在研究植物源抗糖尿病药物方面的有效性。", "conclusion": "研究为未来的糖尿病管理中天然产品疗法的实验验证提供了科学基础，且展示了人工智能技术在植物源抗糖尿病药物研究中的潜在应用价值。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19829", "html_url": "https://arxiv.org/abs/2510.19829", "title": "SSL-SE-EEG: 一种基于自监督学习和挤压-激励网络的从未标记EEG数据中稳健学习的框架", "title_en": "SSL-SE-EEG: A Framework for Robust Learning from Unlabeled EEG Data with Self-Supervised Learning and Squeeze-Excitation Networks", "authors": "Meghna Roy Chowdhury,Yi Ding,Shreyas Sen", "background": "脑电图（EEG）在脑-机接口（BCIs）和神经诊断中发挥着重要作用，但其实用部署受到噪音伪影、缺失数据和昂贵标注成本的挑战。", "innovation": "提出了SSL-SE-EEG框架，结合了自监督学习（SSL）和挤压-激励网络（SE-Nets），以增强特征提取、提高抗噪性并减少对标记数据的依赖。该框架将EEG信号转化为适合深度学习的结构化2D图像表示，实验结果在多个数据集上展示了最先进的准确率（在MindBigData数据集上达到91%，TUH-AB数据集上达到85%），使其适用于实时BCI应用，从而为生物医学信号分析、神经工程和下一代BCIs提供了一个有前景的解决方案。", "conclusion": "SSL-SE-EEG通过低功耗、可扩展的EEG处理，为EEG数据的生物医学信号分析、神经工程技术等领域提供了一种有前景的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19890", "html_url": "https://arxiv.org/abs/2510.19890", "title": "基于序列到序列模型的GNSS欺骗检测", "title_en": "Deep Sequence-to-Sequence Models for GNSS Spoofing Detection", "authors": "Jan Zelinka,Oliver Kost,Marek Hrúz", "background": "本研究提出了一种数据生成框架，用于模拟欺骗攻击并随机在全球范围内放置攻击场景。该框架结合了深度神经网络模型，包括长短期记忆网络（LSTM）和受变压器启发的架构，旨在在线检测欺骗信号。", "innovation": "本研究创新地使用受变压器启发的架构，并通过早期融合输入实现了0.16%的错误率，显著提高了欺骗信号检测的准确性。", "conclusion": "深度学习模型能够准确区分欺骗信号和真实信号，特别是在采用了受变压器启发的架构并进行早期输入融合的模型上，检测性能尤为突出，错误率仅为0.16%。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19882", "html_url": "https://arxiv.org/abs/2510.19882", "title": "量化在线内容审核中的特征重要性", "title_en": "Quantifying Feature Importance for Online Content Moderation", "authors": "Benedetta Tessa,Alejandro Moreo,Stefano Cresci,Tiziano Fagni,Fabrizio Sebastiani", "background": "准确评估用户对审核干预的反应对于开发有效且用户导向的审核策略至关重要。这需要明确了解哪些用户特征与不同的行为反应相关，而这项工作的目标就是达成这一点。研究分析了753个社会行为、语言、关系和心理特征，这些特征被用来预测受到Reddit大规模审核干预影响的16,800名用户的行为变化。通过量化问题，研究旨在估计聚合用户行为的变化，并由此识别出对用户活动、毒性及参与多样性变化最具预测性的特征，同时估计其重要性。研究结果发现，一些特征在所有任务中都具有持续的预测性，而大量其他特征要么是任务特定的，要么几乎无用。此外，研究发现预测表现因任务而异，活动和毒性变化更容易估计，而多样性变化则较为困难。整体而言，这些结果为开发能够准确预测用户对审核干预反应的系统铺平了道路。研究还揭示了后审核用户行为的复杂性，表明有效的审核策略不仅应基于用户特征，还应针对干预的具体目标进行调整", "innovation": "研究采用了一种贪婪特征选择策略，旨在通过识别对用户活动、毒性及参与多样性变化最有预测性的特征来评估这些特征的重要性。研究发现了一些在所有任务中持续具有预测性的特征，并确定了许多其他特征要么是特定任务的，要么毫无用处。研究还发现了不同任务之间的预测性能差异，进一步揭示了后审核用户行为的复杂性", "conclusion": "研究的结果为开发能够准确预测用户对审核干预反应的系统铺平了道路。同时，研究强调了后审核用户行为的复杂性，表明有效的审核策略不仅应基于用户特性，还应针对干预的具体目标进行定制"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19967", "html_url": "https://arxiv.org/abs/2510.19967", "title": "LyriCAR: 一种基于难度感知的课程强化学习框架，用于可控歌词翻译", "title_en": "LyriCAR: A Difficulty-Aware Curriculum Reinforcement Learning Framework For Controllable Lyric Translation", "authors": "Le Ren,Xiangjian Zeng,Qingqiang Wu,Ruoxuan Liang", "background": "歌词翻译是一项具有挑战性的任务，需要平衡多种音乐约束。现有方法通常依赖于手工规则和句子级建模，这限制了它们内部化音乐-语言模式以及在段落级别上有效泛化的能力，特别是在跨行连贯性和整体押韵方面。", "innovation": "提出了LyriCAR，一种全新的基于难度感知的课程强化学习框架，可实现无监督的可控歌词翻译。该框架引入了一个难度感知的课程设计师和自适应的课程策略，确保高效分配训练资源，加速收敛，并通过逐步增加模型的复杂性挑战，以提高整体翻译质量。", "conclusion": "在EN-ZH歌词翻译任务上的大量实验表明，LyriCAR在标准翻译指标和多维度奖励分数方面均达到了最先进的性能，超过了强大的基线。值得注意的是，自适应课程策略在训练步骤减少了近40%的同时，仍然保持了出色的性能。代码、数据和模型可以在该链接中访问：[this https URL]>"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19870", "html_url": "https://arxiv.org/abs/2510.19870", "title": "使用GANs转型多组学整合：在阿尔茨海默病和癌症中的应用", "title_en": "Transforming Multi-Omics Integration with GANs: Applications in Alzheimer's and Cancer", "authors": "Md Selim Reza,Sabrin Afroz,Mostafizer Rahman,Md Ashad Alam", "background": "多组学数据集成对于理解复杂疾病至关重要，但受限于有限样本量、噪声和异质性，这往往会降低预测能力。为了应对这些挑战，该文介绍了一种基于生成对抗网络（GAN）的框架Omics-GAN，该框架旨在生成高质量的合成多组学资料同时保留生物学关系。评价集中在三种组学类型（mRNA、miRNA和DNA甲基化）上的ROSMAP队列和TCGA数据集中的阿尔茨海默病和结肠癌及肝癌上。研究结果显示合成数据集始终优于原始组学资料，SVM分类器在交叉验证的情况下也表明了这一点。另外，合成资料在阿尔茨海默病中mRNA的AUC提高了从0.72到0.74，在肝癌中DNA甲基化资料则从0.64提高了至0.71。箱线图分析显示，合成资料保留了统计分布并减少了噪声和异常值。特征选择发现了与原始资料重叠的重要基因并指出新的候选基因得到了GO和KEGG富集分析的验证。最后，分子对接发现了潜在的药物再利用候选物，如用于阿尔茨海默病的尼洛替尼、用于肝癌的阿托伐醌和用于结肠癌的特科维利曼。", "innovation": "该文提出了一种Omics-GAN框架，通过生成高质的合成多组学资料，同时保留生物学关系。该方法在不同类型的数据集和疾病中展示了其预测能力和在噪声和异质性处理上的优势，同时还发现了新的候选基因与药物，增强了疾病预测和生物标记物及药物发现，为精准医学的应用提供了一个可扩展的策略。", "conclusion": "Omics-GAN增强了疾病预测能力，保持了生物学的准确性，并加快了生物标记物和药物的发现过程。通过这一框架，多组学数据的整合和应用得以增强，为精准医学提供了一种可扩展的方法。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19897", "html_url": "https://arxiv.org/abs/2510.19897", "title": "通过语义和 episodic 记忆学习：一种代理自适应的反思性方法", "title_en": "Learning from Supervision with Semantic and Episodic Memory: A Reflective Approach to Agent Adaptation", "authors": "Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka", "background": "传统的精度调整方法在成本、灵活性和透明度方面存在不足。本文研究了基于预训练大型语言模型的智能体如何从标记示例中学习目标分类函数，而无需参数更新。作者认为，通过利用标记数据和大语言模型生成的评价，可以实现更为有效、灵活和透明的学习过程。", "innovation": "本文提出了一个增强记忆框架，结合了情景记忆和语义记忆。情景记忆存储特定的经验评价，语义记忆则提取并提炼这些评价为可重用的任务级指导。与只依赖标签的检索基线相比，引入评价可以提高最高24.8%的准确率。此外，该方法还引入了解释模型响应不同监督表示的新指标‘可引导性’，这有助于阐明模型行为并揭示模型特性与记忆策略如何共同影响学习动力学。", "conclusion": "研究指出，基于记忆的、反思性的学习方法对于构建更适应、更可解释的大型语言模型代理具有广阔前景。通过理解和应用情景记忆和语义记忆，可以使模型在不同类型的数据处理上表现出更佳的行为。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19954", "html_url": "https://arxiv.org/abs/2510.19954", "title": "RELATE：多模态关系图的无模式感知Perceiver编码器", "title_en": "RELATE: A Schema-Agnostic Perceiver Encoder for Multimodal Relational Graphs", "authors": "Joseph Meyer,Divyansha Lachi,Reza Mohammadi,Roshan Reddy Upendra,Eva L. Dyer,Mark Li,Tom Palczewski", "background": "在电子商务、医疗保健和科学研究等领域中，关系多表数据普遍存在，可以自然地表示为具有多模态节点属性的异构时间图。现有的图神经网络（GNNs）依赖于特定于模式的特征编码器，需要为每种节点类型和特征列单独构建模块，这妨碍了可扩展性和参数共享。", "innovation": "引入了REPLICATE（关系编码器，用于类型化实体的潜在聚合），这是一种无模式感知的、即插即用特征编码器，可以与任何通用图神经网络结合使用。REPLICATE使用共享的模态特定编码器对类别、数值、文本和时间属性进行编码，然后通过Perceiver风格的交叉注意力模块将特征聚合为固定大小的、置换不变的节点表示。", "conclusion": "REPLICATE在RelBench基准上对ReLGNN和HGT进行评估，其性能与特定模式编码器相差不到3%，而参数数量减少了最多5倍。该设计支持变化的模式，并允许通用图神经网络的多数据集预训练，为关系图数据奠定了基石模型的基础。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19971", "html_url": "https://arxiv.org/abs/2510.19971", "title": "引导扩散模型从稀疏数据重构流场", "title_en": "Guiding diffusion models to reconstruct flow fields from sparse data", "authors": "Marc Amorós-Trepat,Luis Medrano-Navarro,Qiang Liu,Luca Guastoni,Nils Thuerey", "background": "从有限测量中重新构建不稳定的流场是多工程应用中的一个极具挑战性和关键性的任务。由于机器学习模型能够从数据中学习复杂的模式并在多种条件下进行泛化，使其在这种问题上得到了广泛的应用。扩散模型作为一种生成任务中的特别有力的方法，通过迭代细化噪声输入来生成高质量的样本，与其他方法相比，这些生成模型能够重建流体光谱中的最小尺度。", "innovation": "本文提出了一种针对扩散模型的新抽样方法，通过使用可用的稀疏数据引导逆过程来逐步生成高保真样本。此外，在训练过程中使用无冲突更新方法结合可用的物理知识来增强重建结果。实验结果表明，本方法在预测流体结构和像素级准确性上优于其他基于扩散的方法，突显了扩散模型在重建流场数据方面的巨大潜力，为计算流体动力学研究开辟了新的途径。", "conclusion": "本研究表明，扩散模型在重构流场数据方面的巨大潜力得到了验证，为计算流体动力学领域开辟了新途径。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19999", "html_url": "https://arxiv.org/abs/2510.19999", "title": "增强循环坐标下降方法用于弹性网正则化线性模型", "title_en": "Enhanced Cyclic Coordinate Descent Methods for Elastic Net Penalized Linear Models", "authors": "Yixiao Wang,Zishan Shao,Ting Jiang,Aditya Devarakonda", "background": "现有用于解决带有弹性网约束的泛化线性模型问题的方法在训练时间上较慢。", "innovation": "提出了一种新型增强循环坐标下降（ECCD）框架，通过泰勒展开当前迭代点来避免梯度计算中的非线性操作，从而减少计算复杂度；通过引入近似，将循环向量重写为更高效的批量计算，提高了计算效率。", "conclusion": "实验结果显示，ECCD 方法在正则路径变体上相对于现有领先方法的一致性能提升为平均3倍，特别适用于各种基准数据集，最终实现代码已开源。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19887", "html_url": "https://arxiv.org/abs/2510.19887", "title": "压缩生物学：评估 Stable Diffusion VAE 在表型药物发现中的应用", "title_en": "Compressing Biology: Evaluating the Stable Diffusion VAE for Phenotypic Drug Discovery", "authors": "Télio Cropsal,Rocío Mercado", "background": "高通量表型筛选产生大量的显微镜图像数据，这些数据由于其高维度而对生成模型构成了挑战。尽管基于自然图像训练的一般用途模型在显微镜数据分析中越来越受欢迎，但它们在这一领域的适用性尚未被定量证明。本文首次系统评估了 Stable Diffusion 的变分自编码器（SD-VAE）在重构 Cell Painting 图像中的表现，利用包含不同分子扰动和细胞类型的大型数据集进行评估。", "innovation": "首次系统性地评估了 Stable Diffusion 的变分自编码器（SD-VAE）在重构 Cell Painting 图像中的应用；利用多种生物启发性评价指标（包括像素级、嵌入式、潜在空间和检索基准）来评估重建质量；展示了通用特征提取器（如 InceptionV3）在检索任务中的表现不低于现有的定制模型。", "conclusion": "SD-VAE 在重建过程中保留了表型信号，且损失极小，支持其在显微镜工作流程中的应用。通用特征提取器如 InceptionV3 在检索任务中表现优异，简化了未来的工作流程。该研究为评估生成模型在显微镜数据上的表现提供了实际指南，并支持利用现成模型进行表型药物发现。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19979", "html_url": "https://arxiv.org/abs/2510.19979", "title": "SecureInfer：对于大型语言模型部署的异构TEE-GPU架构及隐私关键张量保护", "title_en": "SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment", "authors": "Tushar Nayan(1),Ziqi Zhang(2),Ruimin Sun(1) ((1) Florida International University, (2) University of Illinois Urbana-Champaign)", "background": "随着大型语言模型（LLMs）在移动和边缘平台上的部署越来越多，保障模型免受模型提取攻击成为一个紧迫的问题。然而，保护模型隐私而不牺牲在不信任的AI加速器（如GPU）上带来的性能优势，构成了一个具有挑战性的权衡。", "innovation": "本文提出了SecureInfer，这是一种混合框架，利用异构可信执行环境（TEEs）-GPU架构隔离隐私关键组件，同时将计算密集型操作卸载到不信任的加速器上。SecureInfer利用外包方案，并采用信息论和威胁驱使的分区策略：安全敏感组件（包括非线性层、注意力头的投影、FNN变换和LoRA适配器）在SGX enclave中执行，而其他线性操作（矩阵乘法）在进行加密后在GPU上执行，并在enclave内安全恢复。", "conclusion": "通过使用LLaMA-2模型实现SecureInfer的原型，并在性能和安全性指标上进行了评估。结果显示，SecureInfer提供了强大的安全性保障和合理的性能，为设备上的模型推理提供了一个实际的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20011", "html_url": "https://arxiv.org/abs/2510.20011", "title": "通过在线标签平滑提高医学成像预测置信度", "title_en": "Improving Predictive Confidence in Medical Imaging via Online Label Smoothing", "authors": "Kushan Choudhury,Shubhrodeep Roy,Ankur Chanda,Shubhajit Biswas,Somenath Kuiry", "background": "深度学习模型，尤其是卷积神经网络，在医学图像分类中取得了显著成果。然而，这些模型往往会生成过于自信的预测，这可能在其关键医疗环境中的可靠性受到影响。传统的标签平滑虽然提供了一种简单的方法来降低这种自信，但未能考虑类之间的关系，因为所有非目标类都被同等对待。", "innovation": "研究探索了在线标签平滑（OLS）作为动态方法的应用，该方法在整个训练过程中根据模型本身的预测模式调整软标签。在RadImageNet大规模数据集上使用三种广泛使用的架构：ResNet-50、MobileNetV2和VGG-19进行评估。结果显示，与传统训练方法、硬标签、常规标签平滑和无教师的知识蒸馏相比，OLS在Top-1和Top-5分类准确率上都表现出持续的提升。此外，OLS还导致更紧凑且分布良好的特征嵌入，表明改进的表现学习。这些发现表明OLS不仅增强了预测性能，还增强了校准，使其成为医学成像领域值得信赖的人工智能系统的实用和有效解决方案。", "conclusion": "在线标签平滑（OLS）在医学图像分类中表现出色，能够在模型训练过程中动态调整软标签，从而提高模型的预测准确性和校准度，使其成为开发可靠的医疗成像AI系统的有效方法。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20017", "html_url": "https://arxiv.org/abs/2510.20017", "title": "在希尔伯特空间中同时求解无穷多个LQ均场博弈：神经算子的强大性", "title_en": "Simultaneously Solving Infinitely Many LQ Mean Field Games In Hilbert Spaces: The Power of Neural Operators", "authors": "Dena Firoozi,Anastasis Kratsios,Xuwei Yang", "background": "传统的均场博弈（MFG）求解器针对每个实例分别处理，当需要解决许多相关问题（例如，寻找在动态或效用有扰动下的稳健解描述，或包含连续参数化代理的环境中）时，这种处理方式变得不可行。", "innovation": "通过训练神经算子（NOs）直接从LQ MFG定义在可分离希尔伯特空间上的问题数据（规则：动态和代价函数）学习规则至平衡解的映射，并成功保证在训练时采用适当的规则采样下，少量训练样本的NO能可靠解决未见过的LQ MFG变体，即使在无限维情况下参数数量保持受控。", "conclusion": "这一保证来自三个结果：（i）高度非线性的规则至平衡解映射的局部Lipschitz估计；（ii）使用有指定Lipschitz连续性的神经算子的通用近似定理（不同于传统神经算子结果中的Lipschitz常数可能随逼近误差消失而发散）；（iii）新的无限维情况下的L- Lipschitz学习样本复杂度界，适用于我们逼近的神经算子的Lipschitz常数在（ii）中得到了控制。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20030", "html_url": "https://arxiv.org/abs/2510.20030", "title": "使用量子电路编码矩阵", "title_en": "On Encoding Matrices using Quantum Circuits", "authors": "Liron Mor Yosef,Haim Avron", "background": "十多年前，已经证明量子计算具有通过启用经典计算中尚未达到复杂度的算法来革新数值线性代数的潜力，例如经典算法HHL求解线性系统的先驱算法。高效执行此类算法的关键在于将输入（矩阵和向量）作为量子电路进行表示。这些电路编码或实现输入。为完成此任务，文献中出现了两种常见的电路表示方法：块编码和状态准备电路。", "innovation": "在该论文中，作者系统地研究了块编码和状态准备电路两种表示方法。他们提出了从经典形式的矩阵构建这些表示的方法，以及量子二向 вал转换电路表示之间的算法。主要创新点包括：(a) 提出了一种高效的方法来构建任意经典形式矩阵的块编码；(b) 提出了低开销的双向转换算法，显示了这两种模型在实质上是等价的。关键技术组件包括一种特殊的常深多路复用器和量子间对称矩阵标准基与更高阶Pauli基之间转换的算法。", "conclusion": "本文系统地分析了使用量子电路表示矩阵的方法，实现了从经典形式矩阵生成块编码和状态准备电路的算法，并展示了这两种方法的等价性，为量子计算中的问题表示提供了新的工具。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20075", "html_url": "https://arxiv.org/abs/2510.20075", "title": "LLMs can hide text in other text of the same length", "title_en": "LLMs can hide text in other text of the same length.ipynb", "authors": "Antonio Norelli,Michael Bronstein", "background": "背景：现有的大型语言模型（LLMs）能够将有意义的文字隐藏在另一篇完全不同的但仍然连贯和可信的文章之中，且长度相同。这种技术利用了LLMs的强大语言生成能力，可以在表面上无害的内容中嵌入具有隐蔽意义的信息。这种能力在政治、商业等多个领域都具有重大意义，同时也对现有的文本真实性验证带来挑战。", "innovation": "创新：本文介绍了一种简单的协议，可使用小型开源LLMs实现文字隐藏。即使参数量不到80亿的模型也能产生高质量的结果，且可以在笔记本电脑上快速编码和解码长达摘要长度的消息。这一技术突显了文字与作者意图的解耦，进一步削弱了人们对书面交流的信任，尤其是在大型语言模型聊天机器人的背景下。", "conclusion": "结论：文章描述了一个新的协议，展示了利用小型LLM在相同长度的文本中隐秘嵌入信息的可能性。这一发现引发了对AI安全的紧迫问题，并挑战了我们对大型语言模型是否真正“知道”某些信息的理解。这种能力对信息传播的安全性带来了新的挑战。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20052", "html_url": "https://arxiv.org/abs/2510.20052", "title": "大型数据集中的多数据包络分析评分内生聚合", "title_en": "Endogenous Aggregation of Multiple Data Envelopment Analysis Scores for Large Data Sets", "authors": "Hashem Omrani,Raha Imanirad,Adam Diamant,Utkarsh Verma,Amol Verma,Fahad Razak", "background": "本文提出了一种使用数据包络分析（DEA）进行跨多个组织维度的动态效率评估的方法。该方法不仅可以生成维度特定和聚合效率评分，还可以纳入可取和不可取的产出，并且适用于大规模问题设置。该方法在多数据集上展示了计算效率和有效性，并应用于加拿大多伦多的12家医院，评估了2018年1月到2019年12月期间的技术效率、临床效率和患者体验这三方面的组织有效性。研究表明，SBM和GP-SBM方法可以更好地捕捉输入/输出变量之间的相关性，并且优于传统分维度再聚合的基准方法。", "innovation": "提出了一种聚类DEA（Regularized DEA）方法，先引入了slack-based measure (SBM)模型，再提出了一个线性化的非线性目标规划模型（GP-SBM）。SBM和GP-SBM模型都能通过引入正则化参数来提高区分效果，并直接结合了可取和不可取的产出。", "conclusion": "SBM和GP-SBM方法能更好地捕捉输入/输出变量之间的相关性，并且在比较多个数据集时证明了这些方法的有效性。实际上，该方法适用于大规模的数据集评估，并展示了在真实案例中的应用，评估了医院在多个维度上的效率。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20103", "html_url": "https://arxiv.org/abs/2510.20103", "title": "扩展用于隐式溶剂计算的机器学习模型以进行自由能计算", "title_en": "Extending machine learning model for implicit solvation to free energy calculations", "authors": "Rishabh Dey,Michael Brocidiacono,Kushal Koirala,Alexander Tropsha,Konstantin I. Popov", "background": "隐式溶剂方法可以在分子模拟中提供高效建模溶剂效应的框架，但其准确度通常不如显式溶剂模型，限制了其在精确热力学计算中的应用。近年来，机器学习(ML)的发展为克服这些限制提供了机会，通过使用神经网络开发更为精确的隐式溶剂模型。然而，当前基于ML的方法主要依靠力匹配，这可能导致能量预测相差一个任意常数，不适用于绝对自由能比较。", "innovation": "本文提出了一种新的方法，使用基于图神经网络(GNN)的隐式溶剂模型，称为Lambda溶剂神经网络(LSNN)。与传统的ML方法不同，LSNN不仅要进行力匹配，还要训练网络匹配表观力的不同阶导数，确保不同化学物种的溶剂自由能可以有意义地进行比较。该模型在大约30万个小型分子的数据集上进行训练，实现了与显式溶剂表观力计算相似的自由能预测精度，同时提高了计算速度，为未来的药物发现提供了基础框架。", "conclusion": "LSNN在自由能预测上的高精度使得它具备了与显式溶剂表观力模拟相媲美的性能，同时提高了计算速度，为隐式溶剂方法在精确热力学研究中的应用提供了重要的突破，并为药物发现等领域的未来应用奠定了基础框架。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20094", "html_url": "https://arxiv.org/abs/2510.20094", "title": "关于麦康奈尔-弗拉夫斯基方程稳态解的结构及其在嘈杂变压器中的应用", "title_en": "On the Structure of Stationary Solutions to McKean-Vlasov Equations with Applications to Noisy Transformers", "authors": "Krishnakumar Balasubramanian,Sayan Banerjee,Philippe Rigollet", "background": "本文研究了圈上的麦康奈尔-弗拉夫斯基方程的稳态解。通过观察到这种方程的稳态解与无限维的四元系数二次系统之间的精确等价性，作者们能够通过系数序列而不是函数空间来显式描述稳态状态。这一框架为局部分岔现象提供了一个清晰的描述，包括它们的周期性、共振结构，并能容纳奇异势。", "innovation": "主要创新在于发现了一种将麦康奈尔-弗拉夫斯基方程的稳态解与无限维的四元系数二次系统等价的路径。这种等价使得对于可能是多种四元模式的分岔可以得出解析表达式来描述它们的出现、形态（超临界、临界、亚临界或跨临界），并连接这些分岔与连续相变的理论。通过该框架，作者还可以详细描述稳态解的结构，这些解的精确度可以达到任意多个四元模式，并证明了自由能景观的规律性和凸性，找到了全局最小的稳态测度。此外，文章还应用这一理论到嘈杂的变换器模型中，探讨了温度参数 β 的变化对分岔特征的影响。", "conclusion": "研究表明，随着 β 的增加，从均匀测度产生的无限多个分岔呈现出从连续状态到不连续状态（一级相变）的尖锐转变。这导致了一系列多模式的稳定态，可以被视为“亚稳态态”，并且可以观察到自由能地图上非可微点与相变之间的联系。总之，该研究为理解和应用麦康奈尔-弗拉夫斯基方程的稳态解提供了一种新的数学框架，并探讨了其在嘈杂变换器模型中的实际应用。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20035", "html_url": "https://arxiv.org/abs/2510.20035", "title": "通过随机搜索寻找藤蔓：基于随机搜索的结构学习", "title_en": "Throwing Vines at the Wall: Structure Learning via Random Search", "authors": "Thibault Vatter,Thomas Nagler", "background": "Vine copulas提供了灵活的多变量依赖建模方法，并在机器学习中得到了广泛应用，但结构学习仍然是一个关键挑战。早期的启发式方法如Dissmann的贪婪算法仍然是黄金标准，但通常不够理想。", "innovation": "本文提出了基于随机搜索的算法来改进结构选择，并构建了基于模型置信集的统计框架，为集成提供了强有力的理论保证和基础。实验结果表明，本文方法在多个真实数据集上表现出色，超越了现有最先进的方法。", "conclusion": "实验结果显示，本文方法在多个实际数据集上持续优于现有的最先进的方法。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20193", "html_url": "https://arxiv.org/abs/2510.20193", "title": "具有多媒体意识的问答：检索和跨模态推理体系结构的综述", "title_en": "Multimedia-Aware Question Answering: A Review of Retrieval and Cross-Modal Reasoning Architectures", "authors": "Rahul Raja,Arpita Vats", "background": "传统问答系统依赖结构化文本数据，但多媒体内容（图像、音频、视频和结构化元数据）的快速增长带来了新的检索增强问答挑战。", "innovation": "综述了将多媒体检索管道集成到问答系统的最新进展，重点介绍了将视觉、语言和音频模态与用户查询对齐的体系结构，并根据检索方法、融合技术和答案生成策略进行了分类。", "conclusion": "强调跨模态对齐、延迟-准确性权衡和语义定位等关键挑战，并概述了利用多媒体数据构建更具鲁棒性和上下文意识的问答系统的开放问题和未来研究方向。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20095", "html_url": "https://arxiv.org/abs/2510.20095", "title": "BIOCAP：在生物基础模型中利用合成描述性标题超越标签", "title_en": "BIOCAP: Exploiting Synthetic Captions Beyond Labels in Biological Foundation Models", "authors": "Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu", "background": "该研究探讨了描述性标题作为生物多模态基础模型额外监督来源的可能性。本文提出了生物形态空间的概念，认为图像和描述性标题是同一物种潜在形态空间的补充样本，每个样本捕捉特定的生物特征。在训练过程中加入描述性标题有助于与共享的潜在结构对齐，强调潜在的诊断特征，同时抑制虚假的相关性。然而，获取大规模精确、实例特定的描述性标题是主要挑战之一，这在生物有机生物学领域与许多其他科学领域相比，限制了自然语言监督的使用。以往的解决方案是通过生成由多模态大型语言模型和通过维基百科视觉信息及分类者定制的视觉格式示例引导的合成描述性标题，来弥补这一空白。这些领域特定的上下文有助于减少臆断并产生准确、实例特定的描述性标题。在此基础上，使用描述性标题训练了BIOCAP模型，即BIOCLIP结合描述性标题，该模型具有丰富的语义学并实现了强大的物种分类和文本-图像检索性能。", "innovation": "本文提出了一种创新方法，通过生成多模态大型语言模型引导的合成描述性标题，弥补了生物有机生物学领域标注数据不足的问题，从而为生物多模态基础模型提供了额外的监督来源。这种方法减少了生成的描述性标题中的臆断，提高了生成的描述性标题的准确性和实例特异性，为构建生物基础模型提供了新的可能性。利用这些合成描述性标题训练的BIOCAP模型在物种分类和文本-图像检索方面表现出色，展示了描述性标题在跨生物图像与多模态基础模型的桥梁中的价值。", "conclusion": "合成描述性标题在优化生物多模态基础模型性能方面显示了巨大潜力。对于生物有机生物学领域而言，从简单的标签向描述性的数据利用转变，能够为多模态模型提供更为丰富和多样的训练素材。BIOCAP模型因为在物种分类和文本-图像检索任务上的良好表现，进一步证实了这种新方法的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20111", "html_url": "https://arxiv.org/abs/2510.20111", "title": "AsyncHZP: 基于异步调度的分层 ZeRO 并行方法以实现可扩展的语言模型训练", "title_en": "AsyncHZP: Hierarchical ZeRO Parallelism with Asynchronous Scheduling for Scalable LLM Training", "authors": "Huawei Bai,Yifan Huang,Wenqi Shi,Ansheng You,Feifan Shao,Tengfei Han,Minghui Yu", "background": "大规模语言模型的训练效率和扩展性在当前仍是关键瓶颈。主流的 ND 并行方法复杂且不灵活，而灵活性更强的 Zero Redundancy Optimizer (ZeRO) 方法则常常受限于通信开销。因此，如何在保持简单和内存效率的同时实现高性能的模型训练成为一个重要的挑战。", "innovation": "本文提出了一种名为 Asynchronous Hierarchical Zero Parallelism (AsyncHZP) 的新方法，它是一种基于 ZeRO 的异步变体，旨在实现卓越的性能同时保持简化和内存效率。AsyncHZP 通过适应性地重新划分参数、梯度和优化器状态，优化设备内存利用率并显著减少通信开销。此外，还设计了一种多流异步调度方法，将参数的 all-gather 和梯度的 reduce-scatter 操作放在专用的后台线程执行，有效地在通信与计算之间进行重叠，而不会产生显著的内存碎片。", "conclusion": "AsyncHZP 在密集型和混合专家（MoE）模型上的实证评估证明了其在大规模训练中的稳健稳定性和强大性能。它在不依赖于复杂的策略调优的情况下，始终优于传统的 ND 并行方法，实现了领先性能，简化了高效大规模训练的路径。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20211", "html_url": "https://arxiv.org/abs/2510.20211", "title": "AI代理人驱动的自动化云基础设施-as-代码校正", "title_en": "Automated Cloud Infrastructure-as-Code Reconciliation with AI Agents", "authors": "Zhenning Yang,Hui Guan,Victor Nicolet,Brandon Paulsen,Joey Dodds,Daniel Kroening,Ang Chen", "background": "传统的云基础设施管理通过云控制台、命令行界面（CLI）和SDK进行。最近，基于代码的基础设施（IaC）框架（如Terraform）越来越流行。这些框架通过自动化部署、更新或销毁资源，将实际的基础设施与IaC配置保持一致。然而，当IaC与云控制台、CLI或SDK一起使用时，IaC会失去对外部变化的可见性，导致基础设施漂移，使其配置过时，从而导致后续IaC操作撤销有效的更新或引发错误。", "innovation": "NSync是一个自动化的IaC校正系统，能够将外部变化传播回IaC程序。NSync的关键见解是，所有基础设施的变更最终都通过云API调用来实现。该系统利用API轨迹中的见解检测漂移，并重新校正，即更新IaC配置以捕捉变化。NSync采用了代理架构，利用LLMs从嘈杂的API序列中推断高级意图，使用专门工具合成针对性的IaC更新，并通过自我进化的知识库不断提高。", "conclusion": "实验结果显示，NSync在准确性（从0.71提高到0.97的pass@3）和令牌效率（提高1.47倍）方面都优于基准。此外，还提出了一种新的评估管道来注入真实的基础设施漂移并评估校正性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20287", "html_url": "https://arxiv.org/abs/2510.20287", "title": "在生成式AI时代的霹雳舞视频分类", "title_en": "Breakdance Video classification in the age of Generative AI", "authors": "Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson", "background": "近年来，大型视觉语言模型在多项体育应用中取得了巨大进展，主要集中在足球、板球、篮球等流行体育项目上，专注于生成任务如视觉问答、生成 Highlights 等。但这些模型并未广泛应用于如霹雳舞这样专业性较强、且极为流行的舞蹈运动中。", "innovation": "本研究首次将现代视频基础模型（编码器和解码器）应用于霹雳舞视频分类，通过分析，发现视频编码器模型在预测任务中仍然优于现有的视频语言模型。研究还提供了如何选择合适的编码器模型以及如何对调优后的解码器模型进行分析的方法。", "conclusion": "研究结果表明，视频编码器模型仍能在预测任务中表现出更好的性能。同时，研究提供了关于如何选择合适的编码器模型及如何分析调优后的解码器模型的见解，为未来在霹雳舞及其他类似领域中应用更智能的视频处理技术奠定了基础。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20244", "html_url": "https://arxiv.org/abs/2510.20244", "title": "Empower Words: 双支路架构为结构化短语和句级时间定位赋能", "title_en": "Empower Words: DualGround for Structured Phrase and Sentence-Level Temporal Grounding", "authors": "Minseok Kang,Minhyeok Lee,Minjung Kim,Donghyeong Kim,Sangyoun Lee", "background": "视频时间定位（VTG）旨在在长、未裁剪的视频中找到与给定自然语言查询相匹配的时间片段。此任务包含两个子任务：关键时刻检索（MR）和高光检测（HD）。尽管最近的技术进步得益于像CLIP和InternVideo2这样的强大的预训练视觉-语言模型，但现有方法通常在交叉模态注意力中均匀处理所有文本标记，忽视它们的独特语义角色。通过控制实验验证这种做法的局限性，研究发现VTG模型过于依赖于由EOS驱动的全局语义，而未能有效地使用词级信号。这限制了它们实现精细时间对齐的能力。", "innovation": "提出了双支路架构（DualGround），通过将EOS标记通过句子级路径路由，并将单词标记聚类到短语级单元中，明确分离全局和局部语义，解决了这一局限。引入了（1）面向令牌角色的交叉模态交互策略，这些策略以结构化分离的方式对齐视频特征和句子级及短语级语义，（2）联合建模框架，不仅能改进全局句级对齐，还能通过使用结构化的短语感知上下文增强精细时间对齐。该设计使模型能够捕捉粗略和局部语义，从而实现更具表现力和上下文感知的视频定位。DualGround在QVHighlights和Charades-STA基准测试的关键时刻检索和高光检测任务上都达到了最先进的性能，证明了分离语义建模在视频-语言对齐中的有效性。", "conclusion": "DualGround通过结构化短语和句级时间定位进一步赋能文字，其设计使得模型能够捕捉粗略和局部语义，实现了更深刻的视频语义对齐。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20141", "html_url": "https://arxiv.org/abs/2510.20141", "title": "长时段耦合偏微分方程的组成生成", "title_en": "Compositional Generation for Long-Horizon Coupled PDEs", "authors": "Somayajulu L. N. Dhulipala,Deep Ray,Nicholas Forman", "background": "模拟耦合偏微分方程（PDE）系统需要大量的计算资源，以往的研究大多集中在训练联合（耦合）数据的代理模型上，这需要大量的数据支持。本文的研究对象为耦合偏微分方程系统的组成扩散方法，即在推理时仅对解耦合的PDE数据进行训练，在推理时结合使用这些模型以恢复耦合场。本文特别关注在长时间范围内涉及大量时间步骤的情况下，组成策略的可行性，并且我们将一个基线扩散模型与使用v参数化策略训练的模型进行了比较，同时引入了一种基于Euler方案的耦合场对称组成方案。这些工作主要基于思考解耦合数据训练的组成扩散模型是否能够在长时间范围内恢复耦合路径，并评估了其准确性，实验中使用了反应扩散和修正的伯格斯方程作为案例，并将其与基于耦合数据训练的傅里叶神经算子进行了对比测试。尽管只使用解耦合数据进行训练，但组成扩散模型仍然能够低误差地恢复耦合轨迹，v参数化能够提升基线扩散模型的准确性，而基于耦合数据训练的神经算子传播代理模型则表现出最佳效果。这些结果表明组成扩散方法是一种执行长时段耦合偏微分方程建模的有效策略。", "innovation": "本文提出并研究了一种新的基于组成扩散的方法，该方法仅使用解耦合偏微分方程的数据进行模型训练，但在推理时结合使用这些模型以恢复耦合场。同时，本文还引入了基于Euler方案的对称组成方案来处理耦合场。通过对比基线扩散模型和使用v参数化策略进行训练的模型，展示了组成扩散模型在长时间范围内的可行性并且具有较低的误差表现。此外，本文还测试了一种新的对称组成方案，并与其他基于耦合数据训练的先进方法进行了比较。", "conclusion": "文献结果显示，组成扩散的方法是执行较长时间跨度的耦合偏微分方程建模的有效策略。虽然在同一时间和范围内只训练了解耦合的数据，但组成扩散模型在预测耦合轨迹上表现出了一定的优越性，特别是通过使用v参数化策略，可以提高基线扩散模型的准确性，但基于耦合数据训练的神经算子仍然是最强的代表。因此，本文的结果表明，组成扩散仍然是一个值得探索的有效方法以适应复杂的偏微分方程的情况下进行长期模型预测。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20256", "html_url": "https://arxiv.org/abs/2510.20256", "title": "Calibrating Multimodal Consensus for Emotion Recognition", "title_en": "Calibrating Multimodal Consensus for Emotion Recognition", "authors": "Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan", "background": "近年来，多模态情感识别（MER）取得了显著进展。然而，现有的大多数方法忽略了模态间可能存在的语义不一致性，例如文本和视觉输入之间的矛盾情感提示。另外，由于文本模态的强大表征能力，现有方法通常被文本主导，这可能会影响识别的准确性。", "innovation": "本文提出了一种名为校准多模态共识（CMC）的模型。CMC引入了伪标签生成模块（PLGM）生成伪单模标签，实现自监督的单模预训练。然后通过参数自由融合模块（PFM）和多模态共识路由器（MCR）进行多模态微调，从而减轻文本主导问题，引导融合过程向更可靠的一致共识方向发展。实验证明，CMC在四个数据集CH-SIMS、CH-SIMS v2、CMU-MOSI和CMU-MOSEI上达到了或超过了最先进的方法的表现，并在CH-SIMS和CH-SIMS v2存在语义不一致性时表现更为突出。", "conclusion": "实验结果表明，CMC在四个数据集上达到了与现有最佳方法相当或更优的性能，在含有语义不一致性的情况下表现出明显优势。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20334", "html_url": "https://arxiv.org/abs/2510.20334", "title": "使用正则化流在TAIGA实验中提取稀有伽马事件的能力", "title_en": "Capability of using the normalizing flows for extraction rare gamma events in the TAIGA experiment", "authors": "A.P. Kryukov,A.Yu. Razumov,A.P. Demichev,J.J. Dubenskaya,E.O. Gres,S.P. Polyakov,E.B. Postnikov,P.A. Volchugov,D.P. Zhurov", "background": "本文的研究目的是开发一种方法，利用基于深度学习和归一化流的异常检测方法，在宇宙源的发射流中识别稀有的伽马量子，同时避开带有电荷粒子的背景。通过分析，展示了该方法在伽马检测方面具有潜在的应用价值。", "innovation": "本文提出了一种基于深度学习和归一化流的方法，用于在宇宙源的发射流中检测稀有的伽马量子。这种结合了先进机器学习技术的方法，旨在提高对稀有伽马事件的检测能力。", "conclusion": "但是在测试过程中发现，该方法的性能指标仍然低于其他方法，因此提出了可能的改进方法以提高该方法的实施效果。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20043", "html_url": "https://arxiv.org/abs/2510.20043", "title": "从数据到民间传说：评估大规模语言模型在孟加拉文化知识上的表现", "title_en": "From Facts to Folklore: Evaluating Large Language Models on Bengali Cultural Knowledge", "authors": "Nafis Chowdhury,Moinul Haque,Anika Ahmed,Nazia Tasnim,Md. Istiak Hossain Shihab,Sajjadur Rahman,Farig Sadeque", "background": "近年来，自然语言处理（NLP）研究展示了大型语言模型（LLMs）在多种任务上令人惊叹的能力。尽管多语言基准测试在评估LLMs的文化层面方面取得了进展，但在低资源文化细微差别的捕捉上仍存在关键缺口。我们的工作通过一个包含民间传统、烹饪艺术和区域方言的孟加拉语文化知识（BLanCK）数据集来应对这些限制，研究了几种多语言语言模型，发现尽管这些模型在非文化类别的表现良好，但在文化知识上却严重挣扎，而有用上下文时，所有模型的性能都显著提高，突出了上下文感知架构和文化特色训练数据的重要性。", "innovation": "提出的BLanCK数据集专注于低资源文化的细节，特别是孟加拉文化中的民间传统、烹饪艺术和区域方言。此外，研究了多语言语言模型在文化知识上的表现，并揭示了提供上下文对模型性能的显著提升，强调了上下文感知架构和文化定制训练数据的重要性。", "conclusion": "研究中，我们评估了几种多语言语言模型在孟加拉文化知识方面的能力，发现模型在非文化领域表现良好，但在文化知识方面表现欠佳。尽管像魔幻现实主义和历史背景这样的上下文大大提高了所有模型的性能，但我们仍然强调需要增强语言模型对低资源文化细微差别的理解和处理，通过更具文化特色的数据增强训练过程，这有助于提升模型在文化理解方面的整体能力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20339", "html_url": "https://arxiv.org/abs/2510.20339", "title": "多任务深度学习在表面计量学中的应用", "title_en": "Multi-Task Deep Learning for Surface Metrology", "authors": "D. Kucharski,A. Gaska,T. Kowaluk,K. Stepien,M. Repalska,B. Gapinski,M. Wieczorowski,M. Nawotka,P. Sobecki,P. Sosinowski,J. Tomasik,A. Wojtowicz", "background": "本文探讨了表面计量学中预测表面纹理参数及其报告的标准不确定性的可重复深度学习框架。使用来自触觉和光学系统的多仪器数据集，文章同时处理测量系统类型分类和针对Ra、Rz、RONt及其不确定性目标的协调回归。", "innovation": "提出了一个用于表面计量学的可重复深度学习框架，能够同时预测表面纹理参数及其标准不确定性的报告值。通过引入基于量纲和异方差性的头，并结合后验一致校准，该框架能够提供校准区间。对于单目标回归，模型展现了高精度（Ra 0.9824，Rz 0.9847，RONt 0.9918），不确定性目标同样被较好地建模（Ra_uncert 0.9899，Rz_uncert 0.9955），但RONt_uncert的建模较为困难（R2 0.4934）。分类器的准确率达到92.85%，温度校准后概率校准基本保持不变。", "conclusion": "研究结果显示，通过单目标模型可以获得高精度的校准预测，这有助于表面计量工作流程中的仪器选择和接受决策。然而，对于某些不确定性目标的建模效果仍需改进。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20344", "html_url": "https://arxiv.org/abs/2510.20344", "title": "基于数据增强的期望位点回归神经网络", "title_en": "Neural Networks for Censored Expectile Regression Based on Data Augmentation", "authors": "Wei Cao,Shanshan Wang", "background": "期望位点回归神经网络（ERNNs）是强大的工具，能够捕捉数据中的异质性和复杂的非线性结构。然而，现有研究主要集中在完全观测数据上，对涉及删失观察的场景关注较少。", "innovation": "本文提出了一种基于数据增强的期望位点回归神经网络（DAERNN），用于建模异质删失数据。DAERNN完全基于数据驱动，需要最少的假设并且具有极大的灵活性。仿真研究和实际数据应用表明，DAERNN优于现有的删失期望位点回归神经网络方法，并且在预测性能上与完全观测数据训练的模型相当。此外，该算法提供了一种统一的方法来处理各种删失机制，无需显式指定参数模型，从而增强了其在实际删失数据分析中的应用性.", "conclusion": "仿真研究和实际数据应用证明了DAERNN的有效性，并且该算法为处理不同类型的删失机制提供了一个统一的框架，提升了其在实际删失数据中的应用范围。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20314", "html_url": "https://arxiv.org/abs/2510.20314", "title": "增强深度强化学习的安全性：对抗攻击与防御的全面综述", "title_en": "Enhancing Security in Deep Reinforcement Learning: A Comprehensive Survey on Adversarial Attacks and Defenses", "authors": "Wu Yichao,Wang Yirui,Ding Panpan,Wang Hailong,Zhu Bingqian,Liu Chun", "background": "随着深度强化学习（DRL）技术在自动驾驶、智能制造和智能医疗等复杂领域的广泛应用，如何在动态和变化的环境中提高其安全性和鲁棒性已成为当前研究的核心问题。特别是在面临对抗攻击时，DRL 可能会遭受严重的性能下降，甚至做出潜在危险的决策，因此确保其在安全敏感场景中的稳定性变得至关重要。本文首先介绍了DRL的基本框架，并分析了在复杂和变化环境中所面临的主安全挑战。此外，本文还基于扰动类型和攻击目标提出了一个对抗攻击分类框架，详细回顾了针对DRL的主流对抗攻击方法，包括状态空间、动作空间、奖励函数和模型空间的各种攻击方法。为了避免这些攻击，本文系统地总结了当前在提高DRL鲁棒性方面的各种训练策略，包括对抗训练、竞争性训练、鲁棒学习、对抗检测、防御蒸馏以及其他相关防御技术，并讨论了这些方法在提高DRL鲁棒性方面的优势和不足。最后，本文探讨了DRL在对抗环境中的未来研究方向，强调提高泛化能力、降低计算复杂度、增强可扩展性和可解释性等方面的研究需求，旨在为研究人员提供有价值的参考和方向", "innovation": "1. 提出了一个基于扰动类型和攻击目标的对抗攻击分类框架。\n2. 详细总结了针对DRL的主流对抗攻击方法。\n3. 系统地总结了当前在提高DRL鲁棒性方面的各种训练策略，并讨论了这些方法的优势和不足。\n4. 探讨了DRL在对抗环境中的未来研究方向，强调了提高泛化能力、降低计算复杂度、增强可扩展性和可解释性等方面的需求", "conclusion": "本文提供了一个关于DRL在对抗环境中的安全性、对抗攻击和防御策略的全面综述，旨在为研究人员提供有价值的参考和方向，强调了在提高DRL的鲁棒性方面存在的机遇与挑战，提出了未来研究的方向和需求"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20372", "html_url": "https://arxiv.org/abs/2510.20372", "title": "检验最影响性的数据集", "title_en": "Testing Most Influential Sets", "authors": "Lucas Darius Konrad,Nikolas Kuschnig", "background": "小部分具有重大影响的数据子集可能会对模型结果产生巨大的影响，有时几个数据点就能颠覆关键发现。尽管最近的工作已经开发了识别这些‘最影响性的数据集’的方法，但目前没有正式的理论来确定它们的影响是否真正反映了实质性问题，还是自然抽样变异的结果。", "innovation": "本文通过建立一套基于统计学原理的框架来评估最影响性的数据集的统计显著性，理论成果能够表征最大影响的极值分布，从而允许进行严格假设检验以检查过强的影响，代替当前的手动敏感性检查。", "conclusion": "本文通过在经济学、生物学和机器学习基准等多个领域的应用，展示了这种方法的实际价值。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20363", "html_url": "https://arxiv.org/abs/2510.20363", "title": "基于Transformer的MIMO人工智能接收机", "title_en": "A Transformer Inspired AI-based MIMO receiver", "authors": "András Rácz,Tamás Borsos,András Veres,Benedek Csala", "background": "当前的MIMO检测方法通常基于复杂的算法和较大的计算资源，而在实际应用中，尤其是5G通信中，需要一种更加高效和灵活的检测技术来处理高阶混合QAM调制和编码方案。", "innovation": "提出了一种基于Transformer启发式的MIMO检测方法AttDet，将每个传输层视为一个token，并通过轻量级的自注意力机制学习流间干扰。查询和键直接源自估计的信道矩阵，因此注意分数量化信道相关性。值由匹配滤波器输出初始化并迭代优化。AttDet设计结合了模型驱动的可解释性与数据驱动的灵活性。", "conclusion": "在现实5G信道模型下的链路级仿真中，证明了AttDet可以接近最佳的BER/BLER性能，同时保持可预测和多项式复杂性的优点。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20406", "html_url": "https://arxiv.org/abs/2510.20406", "title": "PointMapPolicy: 结构化点云处理用于多模态 imitation 学习", "title_en": "PointMapPolicy: Structured Point Cloud Processing for Multi-Modal Imitation Learning", "authors": "Xiaogang Jia,Qian Wang,Anrui Wang,Han A. Wang,Balázs Gyenes,Emiliyan Gospodinov,Xinkai Jiang,Ge Li,Hongyi Zhou,Weiran Liao,Xi Huang,Maximilian Beck,Moritz Reuss,Rudolf Lioutikov,Gerhard Neumann", "background": "机器人的操作系统从互补的传感器模态中受益，每种模态提供独特的环境信息。点云捕获详细的几何结构，而 RGB 图像提供了丰富的语义上下文。当前的点云方法难以捕捉细粒度的细节，尤其是在复杂任务中，而 RGB 方法缺乏几何感知，这妨碍了它们的精准度和泛化能力。", "innovation": "我们提出了 PointMapPolicy，这是一种新颖的方法，通过在点的结构化网格上施加扩散策略而无需下采样。该数据类型便于从观察中提取形状和空间关系，并可以转换到不同的参考系。由于其在正交网格结构中的定义，我们直接利用现有的计算机视觉技术处理 3D 数据。利用 xLSTM 作为骨干，我们的模型有效地将点图与 RGB 数据融合，以增强多模态感知。", "conclusion": "通过在 RoboCasa 和 CALVIN 标准上的广泛实验以及真实机器人评估，我们的方法在各种操作任务中达到了最先进的性能。相关概述和演示可以在我们的项目页面上找到：这个 https URL"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20431", "html_url": "https://arxiv.org/abs/2510.20431", "title": "三次相关聚类一般图形中的部分最优性", "title_en": "Partial Optimality in Cubic Correlation Clustering for General Graphs", "authors": "David Stein,Bjoern Andres,Silvia Di Gregorio", "background": "该论文关注的是图G中的更高阶相关聚类问题，具体而言是通过最小化属于同一聚类的节点形成的所有团的代价来对图进行划分。这是一个NP难问题，实际应用中通常使用局部搜索启发式算法来解决。此前已有相关研究，但未专门针对最多3团的情况建立部分最优性条件并进行算法实现和效果评估。因此，论文旨在解决这一特定情况下的部分最优性问题，从而提高算法的有效性。", "innovation": "论文建立了三次相关聚类的一般图中的部分最优性条件，这是对节点最多形成3团的特例情况。提出了相关算法并进行了数值效果验证，证明了算法的有效性。这一创新有助于改善局部搜索启发式算法在实际应用中的表现。", "conclusion": "通过定义并实现三次相关聚类中部分最优性条件的算法，并在两个数据集上进行了数值测试，表明这些条件和算法对于提高相关聚类解决方案的质量是有效的。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20362", "html_url": "https://arxiv.org/abs/2510.20362", "title": "ComProScanner：基于多智能体的科学文献中组成-性质结构化数据提取框架", "title_en": "ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature", "authors": "Aritra Roy,Enrico Grisan,John Buckeridge,Chiara Gattinoni", "background": "随着各种预训练的大语言模型的出现，从科学文本中提取结构化知识的方式已经发生了革命性的变化，相比传统的机器学习或自然语言处理技术。尽管取得了这些进展，但用于用户从科学文献中构建、验证和可视化数据集的可访问自动化工具仍然稀缺。因此，开发了ComProScanner，一个自主多智能体平台，以促进化学组成和性质、与合成数据的集成以及从期刊文章中进行可视化的数据提取、验证和分类，用于综合数据库的创建。该框架使用100篇期刊文章和10种不同的LLM（包括开源和专有模型）进行了评估，旨在从陶瓷压电材料及其相应的压电应变系数（d33）中提取复杂的组成信息，因为这类材料缺乏大型数据集而存在空白。", "innovation": "ComProScanner是一个自主多智能体平台，它集成了从科学文献中自动提取、验证、分类和可视化机器可读的化学组成和性质的功能，并且还整合了期刊文章中的合成数据以构建综合数据库。此外，该研究使用10种不同的LLM（包括开源和专有模型）对100篇期刊文章进行了评估，以提取复杂的组成信息，结果表明DeepSeek-V3-0324模型具有最高的总体准确性（0.82）。这为复杂实验数据的提取提供了简单、用户友好的工具，解决了构建机器学习或深度学习数据集时埋藏在文献中的问题。", "conclusion": "该研究提出了ComProScanner框架，它能够从科学文献中提取、验证、分类和可视化复杂的化学组成和性质信息，并采用10种不同的LLM进行评估，证明了其高效性。该框架提供了一个可直接使用的工具，用于构建机器学习或深度学习数据集，填补了某些科学领域中缺乏大型数据集的空白。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20472", "html_url": "https://arxiv.org/abs/2510.20472", "title": "关于不平衡分类中合成过采样的集中度和超额风险界", "title_en": "Concentration and excess risk bounds for imbalanced classification with synthetic oversampling", "authors": "Touqeer Ahmad,Mohammadreza M. Kalan,François Portier,Gilles Stupfler", "background": "合成过采样（如SMOTE及其变种）是应对不平衡分类问题的主要策略之一。尽管这种方法在实践中取得了成功，但其理论基础尚未得到充分探索。本文构建了一个理论框架，用于研究在使用合成数据训练分类器时SMOTE及其相关方法的行为。", "innovation": "本文提出了合成少数类样本的均匀集中估计，并提供了一个基于核的分类器在使用该种合成数据训练时的非参数超额风险保证。这些结果为更好地调整SMOTE的参数及其下游学习算法提供了实用指南。", "conclusion": "通过理论分析，本文提供了关于使用合成过采样方法在不平衡分类中的集中度和超额风险界，实验结果支持了理论发现。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20436", "html_url": "https://arxiv.org/abs/2510.20436", "title": "基于图注意力多智能体强化学习的月球延迟容忍网络中分布式路由策略学习", "title_en": "Learning Decentralized Routing Policies via Graph Attention-based Multi-Agent Reinforcement Learning in Lunar Delay-Tolerant Networks", "authors": "Federico Lozano-Cuadra,Beatriz Soret,Marc Sanchez Net,Abhishek Cauligi,Federico Rossi", "background": "本文介绍了一种适用于在月球延迟容忍网络（LDTN）约束下的多机器人探索任务的完全分布式路由框架。在此环境下，自主漫游者必须在断断续续的连接和未知的移动模式下将采集的数据传输到登陆舱。研究人员将问题形式化为部分可观测马尔可夫决策过程（POMDP），并提出了一种基于图注意力的多智能体强化学习（GAT-MARL）策略，该策略采用了集中式训练，分散式执行（CTDE）的方法。该方法仅依赖于局部观测，不需要全局拓扑更新或数据包复制，区别于经典的基于最短路径和受控洪泛的算法。通过在随机化探索环境中的蒙特卡洛模拟，GAT-MARL 提供了更高的数据传输率，没有数据重复，且减少了数据包丢失，能够利用短期移动预测，为未来的空间机器人系统提供了可扩展的解决方案，尤其是在行星探索方面得到了成功的验证，展示了其在更大型的漫游者团队中的良好泛化性能。", "innovation": "本文主要创新点在于提出了一种基于图注意力的多智能体强化学习（GAT-MARL）策略，该策略在局部观测的基础上，采用集中式训练，分散式执行的方法，无需全局拓扑更新或数据包复制，显著提高了数据传输效率，减少了数据丢失和重复。此外，该方法还能够利用短期移动预测，为未来的空间机器人系统提供了可扩展的解决方案，尤其是在行星探索方面得到验证，展示了其在大规模漫游者团队中的适用性。", "conclusion": "本文通过在随机化探索环境中的蒙特卡洛模拟，验证了基于图注意力的多智能体强化学习（GAT-MARL）策略的有效性。GAT-MARL 为未来的空间机器人系统提供了高效、可靠的路由解决方案，并证明了其在大规模漫游者团队中的良好泛化性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20518", "html_url": "https://arxiv.org/abs/2510.20518", "title": "无线信道中的敌手意识隐私保护推理", "title_en": "Adversary-Aware Private Inference over Wireless Channels", "authors": "Mohamed Seif,Malcolm Egan,Andrea J. Goldsmith,H. Vincent Poor", "background": "无线边缘设备上的基于AI的传感有可能显著增强人工智能应用程序，特别是在自主驾驶和环境监测中的视觉和感知任务。推理阶段中，从传感数据中提取的特征用于预测任务。在边缘网络中，传感器和模型服务器通常不是共置的，这需要特征之间的通信。由于敏感的个人数据可以被对手重新构造，因此需要对特征进行转换以降低隐私泄露的风险。尽管差分隐私机制可以保护有限的数据集，但对单个特征的保护尚未解决。", "innovation": "本文提出了一种新的基于特征转换的隐私保护框架，从而提高基于AI的传感的安全性，在传输到模型服务器之前对提取的特征进行转换。", "conclusion": "通过在传输到模型服务器之前对特征进行隐私保护的转换，本文提出的方法可以有效保护个人数据，减少隐私泄露的风险。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20595", "html_url": "https://arxiv.org/abs/2510.20595", "title": "Diffusion Autoencoders with Perceivers for Long, Irregular and Multimodal Astronomical Sequences", "title_en": "Diffusion Autoencoders with Perceivers for Long, Irregular and Multimodal Astronomical Sequences", "authors": "Yunyi Shen,Alexander Gagliano", "background": "自监督学习已成为表示学习的核心策略，但大多数用于编码数据的架构仅在标准化输入上得到验证，如图像、音频和视频。在许多科学领域，数据则以长、不规则和多元模态的序列形式出现。", "innovation": "作者提出了Diffusion Autoencoder with Perceivers (daep)，一种新的架构，用于处理不规则、异构的多模态数据序列。daep通过将非标准化数据进行标记化、使用Perceiver编码器进行压缩和使用Perceiver-IO扩散解码器进行重建，从而实现了多样数据环境下的可扩展学习。", "conclusion": "在多种光谱和光度天文学数据集上，daep在重构误差、鉴别隐空间表示以及细尺度结构保留方面都优于VAE和maep基准。这些结果证明了daep在天文学等领域数据为不规则、异构序列时的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20453", "html_url": "https://arxiv.org/abs/2510.20453", "title": "超越标准模型物理中的符号回归与可微拟合", "title_en": "Symbolic Regression and Differentiable Fits in Beyond the Standard Model Physics", "authors": "Shehu AbdusSalam,Steven Abel,Deaglan Bartlett,Miguel Crispim Romão", "background": "我们通过考虑所谓的约束最小超对称标准模型（CMSSM）来展示符号回归（SR）在探究超越标准模型（BSM）物理模型的有效性。CMSSM 模型有四个自定义参数，它们决定了实验信号和如暗物质遗迹密度等宇宙观测。对现象学的分析可以通过用输入参数的符号表达式来加速，本文主要分析了希格斯质量、冷暗物质遗迹密度以及μ子的异常磁矩贡献。研究表明，SR 可以生成非常精确的表达式。利用这些表达式，我们进行全局拟合来推导 CMSSM 输入参数的后验概率密度，该结果与使用传统方法进行的拟合结果一致。此外，研究还展示了SR的一个主要优势，即能够使用可微方法进行拟合，而不仅仅是采样方法。同时，还将该方法与神经网络（NN）回归进行了比较，结果显示SR产生的结果更具有全局稳健性。", "innovation": "本文展示了符号回归在探究超越标准模型物理模型中的有效性。使用符号表达式处理输入参数，这是一种加速对现象学分析的方法。此外展示了符号回归的一个重要优势，能够使用可微方法进行拟合，同时对神经网络（NN）回归进行了比较，证明了符号回归具有更稳健的全局结果。", "conclusion": "本文使用符号回归对CMSSM模型进行参数拟合，并通过产生精确的符号表达式加速了现象学分析。这种方法使用可微方法代替采样方法，产生了更稳健的全球结果，同时证明了符号回归在超越标准模型物理研究中的高效率和高精度。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20539", "html_url": "https://arxiv.org/abs/2510.20539", "title": "Blur2seq: 从单张运动模糊图像盲去模糊和估计相机轨迹", "title_en": "Blur2seq: Blind Deblurring and Camera Trajectory Estimation from a Single Camera Motion-blurred Image", "authors": "Guillermo Carbajal,Andrés Almansa,Pablo Musé", "background": "运动模糊是由于相机震动导致的，特别是在大的或旋转性的运动中，图像恢复的一个主要挑战。现有的端到端去模糊网络在处理严重的或空间变异的模糊时表现不佳。因此，需要一种能够同时估计隐含清晰图像和相机运动轨迹的方法，以改善去模糊的效果。", "innovation": "本文提出了一种基于深度学习的框架，可以从单张模糊图像中联合估计潜在的清晰图像和底层的相机运动轨迹。该方法利用了投影运动模糊模型（PMBM），通过与现代网络兼容的可微模糊创建模块高效实现了这一目标。神经网络预测完整的三维旋转轨迹，指导端到端训练的模型化恢复网络。通过模块化的架构，该方法不仅具有可解释性，可以揭示产生模糊的相机运动，还能通过后推理优化轨迹，进一步改进去模糊结果，确保输出与输入的模糊一致性。在此基础上，施加了重建损失优化轨迹，增强了去模糊的一致性。实验表明，该方法在合成和真实的数据集上的性能达到了最先进水平，尤其在处理严重或空间变异模糊时表现突出。", "conclusion": "本文提出的方法在合成和真实数据集上达到了最先进的去模糊效果，特别是在处理严重的或空间变异模糊时。通过模块化的框架和优化的重建损失，能够更好地解释和改善图像的去模糊过程。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20457", "html_url": "https://arxiv.org/abs/2510.20457", "title": "SHOIQ中的鲁棒实例检索的神经推理", "title_en": "Neural Reasoning for Robust Instance Retrieval in $\\mathcal{SHOIQ}$", "authors": "Louis Mozart Kamdem Teyou,Luke Friedrichs,N'Dah Jean Kouagou,Caglar Demir,Yasir Mahmood,Stefan Heindorf,Axel-Cyrille Ngonga Ngomo", "background": "概念学习通过描述逻辑公理的形式利用背景知识来从知识库中学习可解释的分类模型。尽管在神经符号概念学习方面取得了重大突破，但大多数方法仍无法在真实世界的知识库中部署。这主要是由于它们依赖于描述逻辑推理器，这些推理器对不一致性数据和错误数据不够 robust。", "innovation": "提出了一种新型的神经推理器EBR，它利用嵌入来近似符号推理器的结果。EBR仅需检索原子概念和存在限制的实例即可获取或近似描述逻辑SHOIQ中任何概念的实例集合。实验结果表明，与现有的推理器相比，EBR在面对丢失和错误数据时表现更 robust。", "conclusion": "EBR通过利用嵌入来近似符号推理器的结果，成功解决了现有方法对不一致性数据和错误数据的不robust问题，使得概念学习能够在真实世界的知识库中部署。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20606", "html_url": "https://arxiv.org/abs/2510.20606", "title": "感知偏见在公平选拔中的战略成本", "title_en": "Strategic Costs of Perceived Bias in Fair Selection", "authors": "L. Elisa Celis,Lingxiao Huang,Milind Sohoni,Nisheeth K. Vishnoi", "background": "公平选拔系统，无论是入学还是招聘，旨在公正地奖励技能和努力。然而，不同种族、性别和阶级之间持续存在的差距挑战了这一理想。一些人将差距归因于结构性的不平等，而另一些人则归因于个人的选择。该研究发展了一个博弈论模型，其中不同社会经济背景的候选人在社会背景和日益先进的提供个性化职业或薪酬指导的AI工具的影响下，对被选中的后预期价值感知不同。每个候选人战略性地选择努力度，平衡其成本和期望的收益；努力度转化为可观察到的表现，而选择则完全基于这种表现。", "innovation": "研究开发了一个博弈论模型，揭示社会经济身份在选择后预期价值的感知方面的差异，如何转化为候选人战略性选择努力的不同，从而导致偏见的循环。进一步提出了一种成本敏感优化框架，该框架量化了改变选择标准或感知价值如何减少偏见，而不损害机构目标。研究表明，感知的偏见通过双向的反馈循环影响认知、激励和结果。", "conclusion": "研究表明，当不同群体对选拔后预期价值的感知存在差异时，这种差异会导致理性努力度的差异，从而在看似公平的选择过程中延续偏见。即便模型是静态的，但它捕捉了更广泛反馈循环中感知、激励和结果之间的联系，通过展示技术与社会环境如何影响优秀系统中个体激励的方式，架起了理性选择解释和结构不平等解释之间的桥梁。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20612", "html_url": "https://arxiv.org/abs/2510.20612", "title": "黑箱吸收：大型语言模型破坏创新思想", "title_en": "Black Box Absorption: LLMs Undermining Innovative Ideas", "authors": "Wenjun Cao", "background": "近年来，大型语言模型（LLM）被广泛用作加速创新的关键工具。然而，这些模型的内部架构往往是不透明的，且大多由大规模服务提供商操作。这导致用户在使用这些平台时贡献的新型概念可能被内部吸收、泛化和再利用。这种机制可能破坏创新经济的基本原则，造成个体创作者与平台运营者之间的严重信息和结构不对称，从而威胁创新生态系统长期可持续性。为此，本文引入‘想法单位’和‘想法安全性’两个核心概念来分析这种吸收机制，并提出具体的治理和工程议程，确保创作者贡献能够留痕、可控且公平。", "innovation": "本文提出了‘黑箱吸收’的概念，并定义了‘想法单位’和‘想法安全性’来分析大型语言模型对创新思想的潜在风险。此外，还提出了具体的治理和工程技术议程，旨在减轻这些风险，保障创作者贡献的追踪、控制和公平性。", "conclusion": "本文分析了大型语言模型中的‘黑箱吸收’机制，并通过引入‘想法单位’和‘想法安全性’等概念，构建了一个新的分析框架。同时，提出了具体的治理体系和技术方案，以确保创作者贡献的长期可持续性和公平性，从而维护创新生态系统的健康。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20673", "html_url": "https://arxiv.org/abs/2510.20673", "title": "通过权重偏差校正和位级核心集采样高效多比特量化网络训练", "title_en": "Efficient Multi-bit Quantization Network Training via Weight Bias Correction and Bit-wise Coreset Sampling", "authors": "Jinhee Kim,Jae Jun An,Kang Eun Jeon,Jong Hwan Ko", "background": "多比特量化网络通过支持单模型中的多个精度级别，实现了深度神经网络的灵活部署。然而，现有方法因每次更新支持的比特宽度都需要完整数据集更新而导致训练开销显著增加，开销随精度数量线性增长。此外，为支持额外或中间精度选项通常需要额外的微调阶段，进一步增加了整体训练负担。", "innovation": "提出了两种技术大大减少训练开销同时不损害模型性能：(i) 权重偏差校正使共享批量归一化并消除额外微调的需要，通过消除量化偏差并在不同比特宽范围内对齐激活分布；(ii) 位级核心集采样策略允许每个子模型仅在基于梯度的重要性得分选定的紧凑且信息量丰富的子集上进行训练，利用隐含的知识转移现象。", "conclusion": "在CIFAR-10/100、TinyImageNet和ImageNet-1K上的实验表明，我们的方法在达到或超过现有方法的精确度的同时，将训练时间减少多达7.88倍。相关代码已发布。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20653", "html_url": "https://arxiv.org/abs/2510.20653", "title": "寻找甜蜜点：在推理时LLM反射中权衡质量、成本和速度", "title_en": "Finding the Sweet Spot: Trading Quality, Cost, and Speed During Inference-Time LLM Reflection", "authors": "Jack Butler,Nikita Kozodoi,Zainab Afolabi,Brian Tyacke,Gaiar Baimuratov", "background": "随着大型语言模型（LLMs）的不断发展，实践中存在越来越多的方法在无需重新训练模型的情况下提高推理时性能，包括预算调整和多步技术（例如自我反思）。尽管这些方法能够改善输出质量，但它们在准确度、成本和延迟之间带来了复杂的权衡，这种权衡在不同领域中表现不一，目前尚未被充分理解。", "innovation": "本文系统地比较了自我反思和预算调整在数学推理和翻译任务中的表现。评估了包括Anthropic Claude、Amazon Nova、Mistral在内的知名大语言模型，在不同反射深度和计算预算的情况下，推导出最优性能边界。本文发现，自我反思的有效性在不同领域存在显著差异，在数学推理任务中可达220%的性能提升。进一步研究发现，反射轮次深度和反馈机制质量对不同模型家族的表现有显著影响。此外，通过在Lounge by Zalando的营销内容本地化系统中部署自我反思优化系统，验证了这些发现的现实有效性，强调了在部署技术时进行领域特定评估的重要性。", "conclusion": "本文的研究结果提供了在特定领域和资源限制下选择最佳推理策略的实际指导。我们开源了自我反思实现代码以确保可复现性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20416", "html_url": "https://arxiv.org/abs/2510.20416", "title": "使用GraphDOP学习联合地球系统动力学", "title_en": "Learning Coupled Earth System Dynamics with GraphDOP", "authors": "Eulalie Boucher,Mihai Alexe,Peter Lean,Ewan Pinnington,Simon Lang,Patrick Laloyaux,Lorenzo Zampieri,Patricia de Rosnay,Niels Bormann,Anthony McNally", "background": "地球系统的各个组成部分（如海洋、大气、陆地和冰冻圈）之间的交互作用是全球天气模式的关键驱动力。现代数值天气预报（NWP）系统通常分别运行不同组件的模型，并通过它们的界面进行显式耦合来模拟不同组件之间的交换。准确地代表这些耦合交互仍然是一项重大的科学和技术挑战。GraphDOP是一种基于图的机器学习模型，可以从原始的卫星观测和现场观测中直接进行天气预测，而不需要依赖再分析产品或传统的基于物理的NWP模型。GraphDOP同时将来自地球系统各个观测源的信息嵌入到共享的潜在空间中。这使得单个模型可以在无需任何显式耦合的情况下隐式捕捉跨域交互。", "innovation": "GraphDOP能够同时整合来自海洋、大气、陆地和冰冻圈等不同观测源的多元信息，并将这些信息嵌入到共享的潜在空间中，进而实现单个模型中对跨域交互的隐式捕捉。这表明直接从地球系统观测中学习可以成功地表征和传播跨组件交互，为单一模型实现物理一致的端到端数据驱动地球系统预测提供了有希望的道路。该研究展示了GraphDOP在预测关键耦合过程中的能力，包括北极快速海冰冻结、飓风伊恩中的混合层引发的海洋表面冷却，以及2022年欧洲的严重热浪等案例研究。", "conclusion": "本研究证明了GraphDOP能够成功学习和预测地球系统中的复杂交互作用，为未来实现物理一致的端到端数据驱动地球系统预测提供了新的路径。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20748", "html_url": "https://arxiv.org/abs/2510.20748", "title": "强化学习与消费储蓄行为", "title_en": "Reinforcement Learning and Consumption-Savings Behavior", "authors": "Brandon Kaplowitz", "background": "本文探讨了强化学习如何解释经济衰退期间家庭消费行为中的两个令人困惑的现象。这些现象是：在面对刺激转移时，拥有较低流动性资产的家庭相较于拥有较高资产的家庭有更高的边际消费倾向（MPC），以及具有更多失业经历的家庭即使在控制当前经济状况后仍然维持较低的消费水平，这种影响被称为‘伤痕效应’。现有解释多基于对收入风险评估的变化或先验异质性，本文则通过强化学习机制提出了一个新的解释框架，强调通过经验学习价值函数误差对当前消费行为的影响.", "innovation": "本文发展了一个基于Q学习与神经网络近似模型，使代理在收入不确定性的情况下进行消费储蓄决策，不同于传统的理性预期假设。该模型能够同时解释高MPC和低消费水平的现象，这与现有理论中基于信念更新或先验异质性的解释不同。研究结果表明，适应性学习通过强化学习机制在现有经济状况之外，为理解过去经历如何塑造当前消费行为提供了一个统一的框架.", "conclusion": "仿真结果与实证估计相符，表明通过强化学习的自适应学习为理解和预测消费行为提供了一个强大的工具，其效果超越了当前经济条件所能解释的部分。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20739", "html_url": "https://arxiv.org/abs/2510.20739", "title": "学习利用动态程序分析在Node.js包中报告的污染流进行优先级分类", "title_en": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in Node.js Packages", "authors": "Ronghao Ni,Aidan Z.H. Yang,Min-Chien Hsu,Nuno Sabino,Limin Jia,Ruben Martins,Darion Cassel,Kevin Cheang", "background": "程序分析工具经常产生大量候选漏洞报告，需要昂贵的手动审查成本，这给安全分析师带来了优先处理最有可能是真正漏洞的报告的挑战。本文探讨了是否可以使用机器学习来优先处理报告的安全漏洞，特别关注Node.js包中的ACE或ACI漏洞，构建了一个包含1,883个包的基准数据集，每个包包含一个报告的漏洞。为了评估效果，研究了包括经典模型、图神经网络（GNN）、大型语言模型（LLM）和GNN与LLM结合的混合模型等多种机器学习方法。这些方法基于动态程序分析工具的输出进行训练。", "innovation": "通过实验评估了多种机器学习方法，提出了一种基于大型语言模型和混合模型的方法，该方法在F1评分上达到了0.915。即使在假阴性率低于7%的情况下，领先模型仍能消除66.9%的良性包需要进行手动审查，每包需要大约60毫秒的时间。这种方法在漏洞优先分类中显示出良好的前景，并且在调用精度为0.8的情况下，可以检测到99.2%的可利用污染流动，并且只错失0.8%。", "conclusion": "实验表明，机器学习方法可以在优先级分类领域为动态程序分析报告的漏洞检测提供有效的工具，尤其通过大型语言模型和混合模型的应用，大大提高了效率和准确性。未来的工作可以进一步优化模型以提高精度和减少假阳性，从而更好地支持实际中的漏洞管理工作。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20690", "html_url": "https://arxiv.org/abs/2510.20690", "title": "神经多样性在小型模型中规制幻觉", "title_en": "Neural Diversity Regularizes Hallucinations in Small Models", "authors": "Kushal Chakrabarti,Nirmal Balachundhar", "background": "语言模型在参数、计算能力和数据增加的情况下仍然会产生幻觉。研究证明，语言模型需要一种有原则的方法来减少幻觉概率，同时保持固定的参数和数据预算。文章提出了一种名为神经多样性的机制，即去相关的并行表示，证明了幻觉概率受到表示相关性的影响，这表明语言模型需要某种最佳的神经多样性。以往的实验表明，小型模型更容易产生幻觉，因此迫切需要找到一种方法来规制这种幻觉现象，从而提高语言模型的可靠性及准确性。", "innovation": "文章提出了一种名为神经多样性的机制，即去相关的并行表示。为了验证这种机制的有效性，研究人员引入了ND-LoRA（神经多样性的低秩适应），结合了平行LoRA适配器和Barlow Twins正则化。实验结果显示，这种方法可以减少幻觉现象，且不会损害总体的准确性。进一步的分析发现了去相关性和幻觉概率之间的关联，表明随着神经多样性的增加，幻觉的可能性会降低。此外，研究还揭示了任务特定的最佳神经多样性，强调神经多样性作为一个独立于参数和数据的第三轴来提高语言模型的可靠性，即使是在预算固定的条件下。", "conclusion": "研究证明了神经多样性的有效性，显示了提高语言模型可靠性的一个新途径。通过增强神经多样性，可以显著降低幻觉率，同时保持或增强语言模型的整体准确性。这项工作不仅为理解语言模型的可靠性问题提供了新的视角，也对未来的模型设计和优化提供了指导。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20769", "html_url": "https://arxiv.org/abs/2510.20769", "title": "CSU-PCAST: 一种双分支变压器框架用于中期集合降水预报", "title_en": "CSU-PCAST: A Dual-Branch Transformer Framework for medium-range ensemble Precipitation Forecasting", "authors": "Tianyi Xiong,Haonan Chen", "background": "准确的中期降水预报对于水文气象风险管理和灾害减灾至关重要，但当前数值天气预报（NWP）系统难以在长时间内保持较高的预报技能，尤其是在轻度和重度降水方面。传统的集合系统如全球集合预报系统（GEFS）难以维持高水平技能，特别是在较长时期的轻度和重度降水预报中遇到挑战。", "innovation": "本文开发了一种基于深度学习的集合框架，用于多步降水预测，通过整合综合的气象变量进行联合建模。该模型采用基于补丁的Swin Transformer骨干网络和周期卷积来处理经度连续性问题，并通过条件层规范化整合时间与噪声嵌入。模型具有双分支解码器，分别预测总降水量和其他变量，并针对特定训练冻结编码器-解码器路径。训练过程中采用结合连续排名概率分数（CRPS）和加权对数正1误差平方（log1pMSE）损失的目标函数，以平衡概率准确性和幅度保真度。", "conclusion": "模型在实时全局预报系统（GFS）初始条件输入下，能够自回归地生成15天的降水量预报。与GEFS模型对比显示，该模型在0.1 mm、1 mm、10 mm和20 mm的降水阈值上取得了更高的关键成功指数（CSI）分数，表明其在轻度到重度降水预报方面具有更好的性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20787", "html_url": "https://arxiv.org/abs/2510.20787", "title": "通过混合稀疏注意力和上下文可学习的标记移除缓解线性注意力的健忘性", "title_en": "Alleviating Forgetfulness of Linear Attention by Hybrid Sparse Attention and Contextualized Learnable Token Eviction", "authors": "Mutian He,Philip N. Garner", "background": "线性注意力模型能够将整个输入序列压缩到固定大小的循环状态中，提供了一种与Transformer相比更高效的替代方案。然而，它们有限的内存会导致健忘现象，从而影响检索密集型任务的性能。", "innovation": "研究了一些混合模型，通过恢复对过去标记的直接访问来缓解健忘问题。提出了一种新的可学习标记移除方法。结合滑动窗口注意力机制，端到端可训练的轻量级CNN能够从过去和未来的相邻标记中适当地保留有限的关键KV对，同时保持线性注意力的常数时间和空间复杂度。还提供了用于稀疏注意力机制的高效的Triton内核。", "conclusion": "在检索密集型基准上的实证评估支持了我们方法的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20795", "html_url": "https://arxiv.org/abs/2510.20795", "title": "从球形图神经网络进行原初磁场参数的贝叶斯推断", "title_en": "Bayesian Inference of Primordial Magnetic Field Parameters from CMB with Spherical Graph Neural Networks", "authors": "Juan Alejandro Pinto Castro,Héctor J. Hortúa,Jorge Enrique García-Farieta,Roger Anderson Hurtado", "background": "深度学习已成为现代天体物理学中形成性方法，提供从复杂天文数据集中提取有意义物理信息的强大工具。本文通过分析模拟的宇宙微波背景（CMB）图，介绍了一种新的贝叶斯图深度学习框架，用于直接估计原初磁场（PMF）宇宙学中的关键宇宙参数。", "innovation": "文章将贝叶斯神经网络（BNNs）集成到DeepSphere框架中，这是一种特别设计用于处理CMB数据球体几何结构的卷积神经网络架构，以超过0.89的$R^{2}$得分实现磁场参数估计。通过后训练技巧如方差缩放和GPNormal获得可靠性校准的不确定性估计，不仅提高了CMB图中PMF贡献参数估计的准确性，还提供了可靠的不确定性评估方法。", "conclusion": "提出的集成DeepSphere-BNNs框架，能够准确从包含PMF贡献的CMB图中估计参数，同时提供可靠的不确定性量化，为精确宇宙学时代的稳健宇宙学推断提供了必要的工具。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20797", "html_url": "https://arxiv.org/abs/2510.20797", "title": "简单的上下文压缩：基于均值池化和多比例训练", "title_en": "Simple Context Compression: Mean-Pooling and Multi-Ratio Training", "authors": "Yair Feldman,Yoav Artzi", "background": "在使用大规模语言模型（LLMs）和检索增强生成（RAG）进行长上下文计算时，一种常见的策略是软上下文压缩，即将输入序列转换为较短的连续表示，以此来降低计算成本。", "innovation": "研究开发了一种轻量级且简单的均值池化方法，该方法在广泛的实验中优于常用的压缩标记架构。此外，研究还探讨了训练同一个压缩器以输出多种压缩比的效果。", "conclusion": "总体而言，简单的均值池化方法在所有实验中都表现出最强的性能，且在为多种压缩比进行训练时性能小幅下降。然而，无论是模型架构还是训练策略，压缩方法中的权衡关系较为微妙，显示了压缩方法复杂多样的特征。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20771", "html_url": "https://arxiv.org/abs/2510.20771", "title": "AlphaFlow: 理解和改进MeanFlow模型", "title_en": "AlphaFlow: Understanding and Improving MeanFlow Models", "authors": "Huijie Zhang,Aliaksandr Siarohin,Willi Menapace,Michael Vasilkovsky,Sergey Tulyakov,Qing Qu,Ivan Skorokhodov", "background": "MeanFlow作为一种新兴的强大力量，近来在需要少量步骤的生成建模中发挥了重要作用，但其成功的原因尚不完全清楚。本文揭示了MeanFlow目标可以自然分解为两个部分：轨迹流动匹配和轨迹一致性。通过梯度分析，作者发现这两个部分之间存在强烈的负相关性，导致优化冲突和收敛速度缓慢。这种洞见促使作者提出了一个新的目标$\beta$-Flow，它统一了轨迹流动匹配、捷径模型和MeanFlow，采用从轨迹流动匹配平滑过渡到MeanFlow的策略，成功地解开了相互冲突的目标，提高了收敛性能。", "innovation": "本文提出了一个新的目标$\beta$-Flow，它统一了轨迹流动匹配、捷径模型和MeanFlow，并且采用了一个从轨迹流动匹配平滑过渡到MeanFlow的策略，成功地解开了优化冲突。实验结果显示，$\beta$-Flow在从零开始训练类条件ImageNet-1K 256x256数据集时比MeanFlow表现更好，尤其是在所有尺度和设置上。尤其是$\beta$-Flow-XL/2+模型，使用了基本的迪特（DiT）骨干网络，取得了创纪录的FID得分：1-NFE为2.58，2-NFE为2.15，超越了之前的最佳成果。", "conclusion": "总而言之，本文通过揭示MeanFlow系统的深层动态并提出了$\beta$-Flow目标，不仅加深了我们对MeanFlow系统的理解，还能够显著提高基于MeanFlow的生成模型的性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20784", "html_url": "https://arxiv.org/abs/2510.20784", "title": "基于一致性的AGI衡量方法", "title_en": "A Coherence-Based Measure of AGI", "authors": "Fares Fourati", "background": "现有研究[1]将人工通用智能（AGI）定义为认知能力领域中从蔡特-霍恩-科拉尔（CHC）模型得出的能力的算术平均值。虽然这一定义简洁明了，但它假设不同领域的出色能力可以弥补其他领域的不足。然而，真正的通用智能应该体现为各重要领域的均衡能力，而不仅仅是能力的简单平均。本文旨在通过对补偿指数连续变化下的广义均值积分来提出一种认知一致性的衡量方法，这种方法可以跨越算术、几何和调和的范围，并通过曲线下的面积（AUC）来量化在不同补偿假设下的一致性。", "innovation": "本文提出了基于一致性的AGI衡量方法，该方法通过广义均值积分来衡量不同补偿指数下的AGI水平。这种衡量方法不仅跨越了算术、几何和调和的范围，而且AUC值可以有效地量化在不同补偿假设下的一致性，相比于算术平均，这种衡量方法可以更好地捕捉跨领域的依赖性和不平衡性。应用到GPT-4和GPT-5的CHC基础领域分数中，即使它们在算术得分很高（如GPT-5为24%），通过一致性调整后的AUC显示，两者的综合能力仍然不足。", "conclusion": "通过广义均值的积分来衡量AGI的方法是一种更为原则化、可解释性更强且更严格的基础，可以更好地衡量向真正的AGI前进的实际进展。该研究为真正通用智能的衡量提供了一种新的和更精细的视角。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20807", "html_url": "https://arxiv.org/abs/2510.20807", "title": "使用像素空间时空变压器进行动态物理模拟的视频预测", "title_en": "Video Prediction of Dynamic Physical Simulations With Pixel-Space Spatiotemporal Transformers", "authors": "Dean L Slack,G Thomas Hudson,Thomas Winterbottom,Noura Al Moubayed", "background": "受自回归大型语言模型（LLMs）在性能和可扩展性方面的启发，基于转录器的模型在视觉领域取得了很大成功。本文探讨了将基于转录器的模型应用于视频预测的方法，比较了各种时空自注意力布局，并针对现有视频生成方法中存在的常见问题，即无法准确模拟物理模拟，通过物理对象跟踪指标和在物理模拟数据集上的无监督训练，试图隔离时空推理。", "innovation": "本文提出了一种简单的纯转录器模型用于自回归视频预测，利用连续像素空间表示进行视频预测，无需复杂的训练策略或潜在特征学习组件。与现有潜在空间方法相比，该方法显著扩展了物理准确预测的时间范围高达50%。此外，进行了可解释性实验，识别网络中编码有用信息的区域，可用于准确估计PDE模拟参数，发现该方法可以泛化到估计未见过的分布的模拟参数。", "conclusion": "本文提供了一个平台，通过简单的、参数高效的和可解释的方法进一步研究基于转录器的时空视频建模。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20809", "html_url": "https://arxiv.org/abs/2510.20809", "title": "Real Deep Research for AI, Robotics and Beyond", "title_en": "Real Deep Research for AI, Robotics and Beyond", "authors": "Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang", "background": "近年来，人工智能和机器人技术的研究迅猛发展，每年发表的研究论文超过了10,000篇。这使得研究人员难以跟上最新进展。快速演变的趋势、跨学科工作的兴起以及探索超出研究专长领域的需求，都加大了这一挑战。", "innovation": "本文提出了一种可推广的分析管道，该管道能够系统地分析任意研究领域：识别新兴趋势、揭露跨领域机会，并为新的研究提供具体的起点。作者特别将Real Deep Research（RDR）框架应用于人工智能和机器人技术领域，尤其是基础模型和机器人技术的进步。此外，本文还简要扩展了对其他科学领域的分析。主要论文详细介绍了RDR管道的构建，附录提供了每个分析主题的详细结果。", "conclusion": "希望通过这项工作能为从事人工智能及其他领域的研究人员提供一些启发。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20808", "html_url": "https://arxiv.org/abs/2510.20808", "title": "机器人领域中的现实差距：挑战、解决方案与最佳实践", "title_en": "The Reality Gap in Robotics: Challenges, Solutions, and Best Practices", "authors": "Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos", "background": "机器学习在机器人学的各个领域，如导航、运动和操作方面促进了重大进步。模拟被广泛用作培训和测试机器人系统的重要工具，但在将这些系统从模拟环境过渡到真实环境时，模型和现实之间存在的差距极大地阻碍了其成功应用。这种差距被称为现实差距。尽管在仿真到现实的转移方面取得了一些进展，但仍存在不少挑战，需要深入理解差距的根本原因及其解决方案。因此，本研究综述了仿真到现实环境过渡的全景图，概述了现实差距的原因、解决方案和评估指标。", "innovation": "综述了仿真到现实环境过渡的全貌，强调了现实差距的原因、解决方案和评估指标，涵盖了运动、导航和操作等多个平台。引入了领域随机化、现实到仿真迁移、状态和行动抽象等技术，通过模拟和现实环境的共同训练提高了系统直接从仿真过渡到现实环境的能力。", "conclusion": "综述强调，现实差距仍然是机器人学中亟待解决的关键问题之一。要克服这一问题，需要进一步理解其根源以及开发有效的转换技术和评估方法。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20810", "html_url": "https://arxiv.org/abs/2510.20810", "title": "LLM生成文本的可检测性：究竟什么是LLM生成的文本？", "title_en": "On the Detectability of LLM-Generated Text: What Exactly Is LLM-Generated Text?", "authors": "Mingmeng Geng,Thierry Poibeau", "background": "随着大型语言模型（LLMs）的广泛应用，许多研究人员开始关注检测由它们生成的文本。然而，对于'LLM生成的文本'这一目标并未形成一致且精确的定义。不同应用场景与LLM多样性使得检测变得更为复杂。常见的检测目标通常仅代表LLM可能生成文本的一部分。人类对LLM输出进行编辑以及LLM潜在影响用户的细微作用，正逐渐模糊了LLM生成文本和人类撰写的文本之间的界限。现有的基准和评估方法未能充分应对实际检测器应用中的各种情况，从而使检测器的结果常被误解，其意义逐渐稀释。因此，检测器在特定条件下仍有一定用途，但其结果应仅作为参考而非决定性指标。", "innovation": "本研究关注确定并澄清'LLM生成的文本'这一概念的实际界限，旨在提高检测器在真实应用场景中的准确性和可靠性，避免现有检测方法理解和应用上的误解与局限性。", "conclusion": "尽管检测器在特定条件下仍有帮助，但从实际应用角度出发，它们的结果应被视为参考而非决定性依据。需要进一步研究来改进检测方法，以满足复杂多变的应用需求。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.08281", "html_url": "https://arxiv.org/abs/2401.08281", "title": "Faiss库", "title_en": "The Faiss library", "authors": "Matthijs Douze,Alexandr Guzhva,Chengqi Deng,Jeff Johnson,Gergely Szilvasy,Pierre-Emmanuel Mazaré,Maria Lomeli,Lucas Hosseini,Hervé Jégou", "background": "向量数据库通常管理大量的嵌入向量集合。随着人工智能应用的迅速增长，需要存储和索引的嵌入的数量也在增加。Faiss库专注于向量相似搜索，这是向量数据库的核心功能。Faiss是一个用于向量索引方法及其相关原语的工具包，用于搜索、聚类、压缩和转换向量。", "innovation": "这篇论文描述了向量搜索的权衡空间以及Faiss的设计原则，包括结构、优化方法和接口。并且基准测试了库的关键特性，并讨论了一些选定的应用来突出其广泛适用性。", "conclusion": "总之，该论文介绍了Faiss库的主要特性和设计原则，展示了其在多种应用场景中的适用性和有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20819", "html_url": "https://arxiv.org/abs/2510.20819", "title": "使用对比和预测潜在扩散桥梁实现通用模态翻译", "title_en": "Towards General Modality Translation with Contrastive and Predictive Latent Diffusion Bridge", "authors": "Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot", "background": "生成模型的最新进展将扩散模型置于从复杂数据分布中采样的前沿工具地位。尽管这些模型在图像和音频等单一模式领域的表现令人印象深刻，但将它们的能力扩展到不同感官模态之间的模态转换（MT）仍然是一个开放的挑战。现有的方法往往依赖于共享维度、高斯先验和特定于模态的架构等严格的假设，这些限制了其通用性和理论基础。", "innovation": "本文提出了一种基于潜在变量扩散桥梁模型扩展的一般用途框架——潜在去噪扩散桥梁模型（LDDBM），它能够在一个共享的潜在空间中学习任意模态之间的桥梁，而不需要对齐维数。通过引入对比对齐损失以确保配对样本之间的语义一致性，并设计了一种通用的编码器-解码器架构，以适应潜在空间中的噪声预测。此外，提出了一种预测损失以指导训练以实现准确的跨域翻译，并探索了几种训练策略以提高稳定性。该方法支持任意模态对，并在包括多视角到3D形状生成、图像超分辨率和多视角场景合成在内的多个MT任务中表现出色。", "conclusion": "综合实验和消融研究表明了我们框架的有效性，建立了通用模态翻译中新的强基准线。有关更多信息，请参阅我们的项目页面：this https URL."}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.11367", "html_url": "https://arxiv.org/abs/2402.11367", "title": "多任务逆强化学习中的常识奖励", "title_en": "Multi Task Inverse Reinforcement Learning for Common Sense Reward", "authors": "Neta Glazer,Aviv Navon,Aviv Shamsian,Ethan Fetaya", "background": "在将强化学习应用到复杂的真实世界环境中时，一个挑战在于如何向代理提供足够详细的目标函数（奖励）。任何奖励目标与期望行为之间的不匹配都可能导致代理采取非期望的行为，例如“奖励劫持”现象，即代理通过非预期的方式最大化奖励。本文背景涵盖了逆强化学习（IIRL）在训练过程中学习到的奖励函数未能有效指导新代理的行为的问题，以及多任务逆强化学习的提出背景。", "innovation": "本文提出了一种新的方法——多任务逆强化学习，通过同时在多个任务上对代理进行训练，从而学习到一个具有实用意义的奖励函数。文章指出即使逆强化学习成功训练了代理，学习得到的奖励函数也不一定能有效指导新代理的行为。多任务逆强化学习方法旨在解决这一问题，通过多个任务的同时训练来实现有效的奖励函数学习。", "conclusion": "本文通过实验展示了多任务逆强化学习能够更好地学习到具有实用意义的奖励函数，即可以有效指导新代理的期望行为。通过这种方法，可以解决逆强化学习在单一任务学习中无法提供有用的奖励函数的问题。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.18512", "html_url": "https://arxiv.org/abs/2402.18512", "title": "Log Neural Controlled Differential Equations: The Lie Brackets Make a Difference", "title_en": "Log Neural Controlled Differential Equations: The Lie Brackets Make a Difference", "authors": "Benjamin Walker,Andrew D. McLeod,Tiexin Qin,Yichuan Cheng,Haoliang Li,Terry Lyons", "background": "神经控制微分方程（Neural CDEs）通过将时间序列数据视为控制路径的观测值，使用神经网络参数化控制微分方程（CDE）的向量场，并将解路径视为持续变化的隐藏状态，从而提供了一种强大的方法来建模真实世界的数据。尽管它们对于不规则采样率具有鲁棒性，但目前的NCDEs在训练效率和性能上存在局限性。", "innovation": "Log-NCDEs 是通过NRDEs的基础上引入的一种新颖、有效且高效的训练NCDEs的方法。Log-NCDEs 的核心组件是粗路径研究中的Log-ODE方法，用于近似CDE的解。实验证明，Log-NCDEs 在多种包含多达50,000个观测值的多元时间序列数据集上优于NCDEs、NRDEs、线性递归单元、S5和MAMBA。", "conclusion": "Log-NCDEs 提供了一种利用Lie括号改进NCDEs性能的有效方法，能够在多种时间序列数据集上实现更好的表现，特别是在包含大量观察数据的情况下。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20818", "html_url": "https://arxiv.org/abs/2510.20818", "title": "VAMOS: 一种基于视觉-语言-行动的层级模型，实现能力调制和可操控的导航", "title_en": "VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation", "authors": "Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta", "background": "机器人导航的一个基本挑战在于学习能够在多种环境中通用的策略，同时又要适应特定机械体的独特物理约束和能力（例如，四足机器人可以攀爬楼梯，但轮式机器人不能）。本文针对这一挑战展开研究。", "innovation": "本文提出了一种层级视觉-语言-行动模型VAMOS，将语义规划与机械体接地分离。具体而言，通用规划器通过从多样化的开放世界数据中学习以获取一般知识，而专门的功能模型则在安全和低成本的模拟环境中学习机械体的物理特殊性和能力。通过此分离，高阶规划器可以直接提出图像空间中的候选路径，功能模型则评估并重新排名这些路径。实验结果表明，VAMOS在室内和复杂室外导航中的成功率高于最先进的基于模型和端到端学习方法。", "conclusion": "VAMOS的层级设计使跨机械体导航成为可能，轮式和腿足机器人可以共享一个高层规划器，同时由于功能模型的存在，机械体接地变得更容易操控。实验证明，这种模型显著提高了单机器人系统的可靠性，通过拒绝物理上不可行的计划，成功率达到3倍。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.12412", "html_url": "https://arxiv.org/abs/2405.12412", "title": "通过条件一致度评估神经回归器的概率匹配", "title_en": "Assessing the Probabilistic Fit of Neural Regressors via Conditional Congruence", "authors": "Spencer Young,Riley Sinema,Cole Edgren,Andrew Hall,Nathan Dong,Porter Jenkins", "background": "虽然在定义能够表示不确定性的人工神经网络方面取得了显著进展，但深度网络仍然经常表现出过度自信和预测分布不对齐的问题。现有的衡量这种不对齐的方法主要基于校准框架，常用指标如期望校准误差（ECE）。然而，校准只能提供概率对齐的严格边际评估，不能诊断单个输入的点上可靠性，这对于实际决策非常重要。现有的方法无法满足这些需求。因此，论文提出了一个新的更强的条件一致度条件，用于评估概率拟合，并引入了条件一致性误差（CCE）指标，使用条件核均值嵌入估计任何点上学习的预测分布与数据集中经验条件分布之间的距离。", "innovation": "论文提出了一个新的条件一致度条件，并引入了条件一致性误差（CCE）指标，旨在评估概率拟合。CCE使用条件核均值嵌入，能够在任何点上估计学习的预测分布与数据集中经验条件分布之间的距离。实验证明CCE具有四种关键特性：正确性、单调性、可靠性和稳健性。", "conclusion": "通过条件一致性条件和CCE指标，论文有效解决了现有方法无法诊断单点可靠性的局限性。CCE不仅明确评估了概率拟合的准确性，还展示了单调性、可靠性和稳健性，从而为神经网络的概率表示提供了更强的工具。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.12961", "html_url": "https://arxiv.org/abs/2405.12961", "title": "通过能量排名对齐使用连续反馈的变换器", "title_en": "Aligning Transformers with Continuous Feedback via Energy Rank Alignment", "authors": "Shriram Chennakesavalu,Frank Hu,Sebastian Ibarraran,Grant M. Rotskoff", "background": "化学空间搜索是一个极其具有挑战性的问题，因为随着原子数量的增加，可能的分子数量呈组合性增长。大型自回归模型通过训练化学化合物数据库已经生成了强大的生成器，但仍然缺乏生成具有所需特性的分子的稳健策略。分子搜索问题与大型语言模型的“对齐”问题相似，但在许多化学任务中，我们有特定且易于评估的奖励函数。", "innovation": "提出了一个名为能量排名对齐（ERA）的新算法，该算法利用显式的奖励函数产生基于梯度的目标函数，用于优化自回归策略。理论上，该算法与近端策略优化（PPO）和直接偏好优化（DPO）密切相关，其优化器收敛于理想的吉布斯-玻尔兹曼分布，奖励作为能量函数的角色。此外，该算法高度可扩展，不需强化学习，相较于DPO，在每个配对的偏好观察次数较少时表现良好。通过该方法，可以将分子变换器和蛋白质语言模型对齐，以生成具有外部指定特性的分子和蛋白质序列，并发现其能稳健地进行搜索，通过化学空间的不同部分进行探索。", "conclusion": "本研究表明，ERA算法可以有效地对齐分子变换器和蛋白质语言模型以生成具有预定属性的分子和蛋白质序列，无论是在分子生成方面还是蛋白质序列生成方面均表现出色，为化学和生物信息学领域提供了新的研究工具。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.05064", "html_url": "https://arxiv.org/abs/2406.05064", "title": "使用奖励预测预训练决策转换器进行基于上下文的多任务结构化多臂老虎机学习", "title_en": "Pretraining Decision Transformers with Reward Prediction for In-Context Multi-task Structured Bandit Learning", "authors": "Subhojyoti Mukherjee,Josiah P. Hanna,Qiaomin Xie,Robert Nowak", "background": "本文研究了多任务结构化多臂老虎机问题中的元学习，目标是学习一个可以接近最优且能最小化累积遗憾的算法。各个任务共享相同的结构，算法应该利用这种共享结构来最小化对未见过但相关的测试任务的累积遗憾。研究使用 Transformer 作为决策算法，从演示者在一组训练任务上的数据中学习这种共享结构，并设计一种训练程序使得 Transformer 能够在未见过的测试任务中超越演示者的学习算法。", "innovation": "提出了一种预训练方法，训练 Transformer 网络以在上下文中学习接近最优政策。该方法利用了任务之间的共享结构，不需要访问最佳动作，并且可以超越演示者。", "conclusion": "在多种结构化多臂老虎机问题上进行了验证，表明所提出的方法是通用的，并能够快速在未见过的测试任务中识别预期奖励，支持有效的探索。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.14090", "html_url": "https://arxiv.org/abs/2405.14090", "title": "使用成员查询解决具有未知 knapsack 约束的 0-1 整数线性规划问题", "title_en": "Solving 0-1 Integer Programs with Unknown Knapsack Constraints Using Membership Oracles", "authors": "Rosario Messana,Rui Chen,Andrea Lodi,Alberto Ceselli", "background": "本文考虑了在未知 knapsack 约束下解决组合优化问题的方法。通过使用每个未知约束的成员查问，给定解决方案时，查问可以确定约束是否被满足。决策者的目标是在查问次数设有预算的情况下找到最优解。研究灵感来源于基于支持向量机（SVM）的二元分类的主动学习。", "innovation": "本文提出了一种新的解决方法，该方法包括训练线性边界并对标签点进行操作，同时通过应用采样策略和解 0-1 整数线性规划来选择新的标签点。主要创新在于提出了基于混合整数二次规划的采样策略，并借鉴了凸优化 oracle 模型中的算法设计了一种新的线性分离方法。", "conclusion": "通过在经典问题及其现实应用变体上的实验，本文展示了不同线性分离方法和采样策略如何影响结果的质量，包括目标值、对偶界和运行时间方面的不同指标。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.05088", "html_url": "https://arxiv.org/abs/2406.05088", "title": "优化时间序列预测架构：分层神经架构搜索方法", "title_en": "Optimizing Time Series Forecasting Architectures: A Hierarchical Neural Architecture Search Approach", "authors": "Difan Deng,Marius Lindauer", "background": "时间序列预测研究的快速发展引入了许多基于深度学习的模块。尽管存在大量的新预测架构，但仍然不清楚是否已经充分利用了现有模块的全部潜力，并且在适当设计的架构中进行了优化。", "innovation": "提出了一种新颖的分层神经架构搜索方法，专门用于时间序列预测任务。设计了一个分层搜索空间，集成了多种为预测任务设计的架构类型，并允许不同预测架构模块的高效组合。实验结果表明，该方法可以搜索出适用于不同预测任务的轻量级高性能预测架构。", "conclusion": "在长期时间序列预测任务中，该方法通过分层神经架构搜索可以找到适合不同类型任务的轻量级高性能预测架构。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.12087", "html_url": "https://arxiv.org/abs/2405.12087", "title": "通过机器学习在闪电网络中进行通道余额插值", "title_en": "Channel Balance Interpolation in the Lightning Network via Machine Learning", "authors": "Vincent Davis,Emanuele Rossi,Vikash Singh", "background": "比特币闪电网络是一个Layer 2支付协议，通过支付通道实现快速有效的交易来解决比特币的扩展问题。已有大量研究探索了余额探测和多路径支付协议，但仅使用节点和通道特征来预测通道余额的研究仍处于空白阶段。", "innovation": "本文探索了使用机器学习模型来插值闪电网络中的通道余额的可行性，以优化网络的路径寻找算法。本文评估了几种机器学习模型的性能，并与两种启发式基线进行对比，研究了各种特征的预测能力。实验结果表明，本文的模型优于50/50基线模型，性能高出10%。", "conclusion": "基于实验评估结果，本文模型在预测通道余额方面表现出色，能够有效优化闪电网络的路径选择。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06300", "html_url": "https://arxiv.org/abs/2410.06300", "title": "通过稀疏傅里叶表示计算SHAP值", "title_en": "SHAP values via sparse Fourier representation", "authors": "Ali Gorji,Andisheh Amrollahi,Andreas Krause", "background": "SHAP值是广泛用于机器可解释性和解释性AI中局部特征归因的方法。该研究提出了两种阶段性的高效算法，可适用于黑盒模型和基于树的模型来计算SHAP值。通过稀疏傅里叶表示方法，可以通过傅里叶表示的第一阶段近似模型，并在第二阶段使用封闭形式的公式精确计算SHAP值，这一公式能够“线性化”计算过程并易于并行化。这种方法提供了一种将计算SHAP值的预处理费用分摊的途径，从而显著提高了计算速度，并在效率和精度之间提供了可调节的权衡。", "innovation": "研究提出了一个两阶段的算法，该算法能够高效地计算SHAP值。算法的第一阶段使用稀疏傅里叶表示来近似模型。对于树模型，此近似是精确的；对于黑盒模型，该近似是近似的。第二阶段给出了一种使用傅里叶表示精确计算SHAP值的封闭形式公式，这种公式将计算过程“线性化”并易于并行化执行。由于傅里叶近似只计算一次，所以这种方式可以实现SHAP值的分摊计算，这比现有的方法提供了显著的速度提升，并提供了在效率和精度之间的可调节权衡。", "conclusion": "该研究提出的方法在黑盒模型和基于树的模型中都能高效计算SHAP值，通过稀疏傅里叶表示，第一阶段近似模型，第二阶段使用封闭形式的公式精确计算SHAP值并进行并行化。这种方法能够显著增加计算速度，并为效率和精度提供了可调节的权衡。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.22264", "html_url": "https://arxiv.org/abs/2410.22264", "title": "使用低秩适应的可证明元学习", "title_en": "Provable Meta-Learning with Low-Rank Adaptations", "authors": "Jacob L. Block,Sundararajan Srinivasan,Liam Collins,Aryan Mokhtari,Sanjay Shakkottai", "background": "基础模型（FMs）因其能够学习高度表达性的表示并适应广泛的任务而具有强大的能力，但这些预训练模型需要额外的训练阶段才能适应下游应用。在多任务设置中，以前的研究表明，特定的元学习方法能够在参数高效微调（PEFT）的情况下使模型未来适应，这在试验中优于标准重新训练方法，但元学习机制的好处尚未得到充分探讨。", "innovation": "介绍了通用PEFT为基础的元学习框架，以学习一个能够轻松适应未见过的任务的模型。对于使用LoRA的线性模型，证明了标准重新训练在找到可适应参数方面是不可证明的次优方法，并提供了我们提出的方案的严格性能保证。通过合成数据和真实数据的视觉和语言任务实验验证了这些理论见解，显示出使用我们提议的元学习方案的简单实现相比传统方法有显著的性能优势。", "conclusion": "研究表明，通过我们提出的元学习方案进行重新训练可以实现显著的性能提升。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.07812", "html_url": "https://arxiv.org/abs/2410.07812", "title": "Temporal-Difference Variational Continual Learning", "title_en": "Temporal-Difference Variational Continual Learning", "authors": "Luckeciano C. Melo,Alessandro Abate,Yarin Gal", "background": "机器学习模型在现实应用中需要连续学习新的任务以适应数据生成分布的变化。然而，在连续学习（CL）中，模型常常难以平衡学习新任务（灵活性）和保留之前知识（记忆稳定性）之间的关系，这导致它们容易发生灾难性遗忘（Catastrophic Forgetting），从而降低性能并削弱已部署系统的可靠性。在贝叶斯连续学习文献中，通过变分方法使用一个递归更新后验分布的学习目标来解决这个问题，同时限制其靠近之前估计值。然而，作者认为这些方法可能效果不佳，因为它们在多次递归中累积了越来越多的近似误差。现有的变分连续学习方法存在累积的近似误差问题，导致学习效果下降和系统可靠性受损。为解决这个问题，作者提出了一种新的学习目标，整合了多个先前后验估计的正则化效应，防止个别误差主导未来后验更新，并随时间累积。这种新方法与强化学习和神经科学中的时间差分（Temporal-Difference）方法之间有深刻的联系。实验表明，该方法在具有挑战性的连续学习基准上有效缓解了灾难性遗忘的问题，超越了现有的强大变分连续学习方法。", "innovation": "新提出的学习目标整合多个先前后验估计的正则化效应，防止个别误差主导未来后验更新，并随时间累积。这有助于缓解变分方法中的累积近似误差问题。此外，这种新方法与时间差分（Temporal-Difference）方法之间有深刻的联系，并且在具有挑战性的连续学习基准上超越了现有的强大变分连续学习方法。", "conclusion": "通过提出新的学习目标，该研究有效缓解了变分方法中的累积近似误差问题，从而减轻了灾难性遗忘，并在连续学习应用中表现出色。该研究的方法与强化学习和神经科学中的时间差分方法有深刻的联系，可能为未来的算法设计提供新的思路。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16482", "html_url": "https://arxiv.org/abs/2412.16482", "title": "Learn2Mix：使用自适应数据集成训练神经网络", "title_en": "Learn2Mix: Training Neural Networks Using Adaptive Data Integration", "authors": "Shyam Venkatasubramanian,Vahid Tarokh", "background": "在资源受限的环境中加速模型的收敛对于快速和高效的神经网络训练至关重要。现有的古典训练方法使用固定的类别比例，这可能不足以处理类别不平衡和有限的训练资源问题，导致训练效率低下。", "innovation": "提出了一种新的训练策略——learn2mix，该方法能够自适应调整批次内的类别比例，重点关注错误率较高的类别。learn2mix与传统方法相比，能够在训练过程中不断调整类别比例，从而加快了模型的收敛速度。", "conclusion": "在基准数据集上的实验表明，使用learn2mix训练的神经网络比使用现有方法训练的神经网络收敛更快，并在类别不平衡和有限训练资源的条件下实现了更好的分类、回归和重构任务结果。实验证据得到了理论分析的支持。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02770", "html_url": "https://arxiv.org/abs/2502.02770", "title": "Twilight: 适应性注意力稀疏性与分层Top-$p$修剪", "title_en": "Twilight: Adaptive Attention Sparsity with Hierarchical Top-$p$ Pruning", "authors": "Chaofan Lin,Jiaming Tang,Shuo Yang,Hanshuo Wang,Tian Tang,Boyu Tian,Ion Stoica,Song Han,Mingyu Gao", "background": "长上下文大语言模型（LLMs）利用注意力稀疏性来加速研究已经成为热点。然而，当前的算法如稀疏注意力或键值缓存压缩倾向于使用固定的预算，这在部署时造成了显著挑战，因为它未能考虑到真实世界场景中准确性和效率之间动态平衡的变化。", "innovation": "本文发现借用Top-$p$采样（核采样）到稀疏注意力中可以实现自适应预算。为此，我们提出了Twilight框架，可以在任何现有的稀疏注意力算法中引入自适应稀疏性而不牺牲其准确性。实验证明，Twilight可以自适应地修剪最多98%的冗余令牌，从而在自注意力操作上加速15.4倍，并在端到端每令牌延迟上加速3.9倍。", "conclusion": "Twilight可以适应性地提高稀疏注意力算法的效率和准确性，在长上下文LLM解码中具有显著的加速效果。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.09805", "html_url": "https://arxiv.org/abs/2412.09805", "title": "在不同同质性条件下使经典GNN成为强基线：平滑性-泛化视角", "title_en": "Making Classic GNNs Strong Baselines Across Varying Homophily: A Smoothness-Generalization Perspective", "authors": "Ming Gu,Zhuonan Zheng,Sheng Zhou,Meihan Liu,Jiawei Chen,Tanyu Qiao,Liangcheng Li,Jiajun Bu", "background": "图形神经网络（GNNs）已经取得了巨大的成功，但经常被不同水平的同质性挑战。尽管最近的一些实证研究表明，适当调参的同质性GNN在不同同质性级别的数据集上表现良好，但其背后的理论和有效的架构仍然不清楚。为了跨越不同的同质性实现GNN的普遍性，本文从理论上重新审视了GNN消息传递，并发现了一个新颖的平滑性-泛化困境，即增加跳跃次数不可避免地会提高平滑性但损害泛化。这种困境阻碍了在更高阶同质性邻域和所有异质性邻域中的学习，特别是在复杂邻域类别分布容易受到噪声和稀疏性影响的领域。", "innovation": "本文提出了基于三个简单有效设计原则的Inceptive Graph Neural Network (IGNN)，它通过使不同跳跃次元实现不同的泛化能力并根据适应的平滑度提高整体泛化能力，缓解了平滑性-泛化困境。基准测试表明，IGNN在30个基线中表现出色，并揭示了某些同质性GNN变体中具有特定的普遍性。", "conclusion": "基准测试表明IGNN在30个基线中表现出色，并揭示了某些同质性GNN变体中具有特定的普遍性。我们的代码和数据集可在此处获得。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.20984", "html_url": "https://arxiv.org/abs/2412.20984", "title": "用于设计自然样态抗体的帕累托最优能量对齐", "title_en": "Pareto-Optimal Energy Alignment for Designing Nature-Like Antibodies", "authors": "Yibo Wen,Chenwei Xu,Jerry Yao-Chieh Hu,Kaize Ding,Han Liu", "background": "本文介绍了一种针对抗体序列-结构共设计的深度学习模型训练框架。背景在于通过结合语言模型和扩散模型，对抗体序列和结构进行联合优化，从而实现更加合理和功能性的设计。为解决模型中的冲突能量偏好问题，作者扩展了AbDPO技术，使其能在多个基于能量的对齐目标下引导模型向帕累托最优解移动。此外，研究者采用迭代学习方式和温度缩放策略，使得模型可以从多样化的在线数据中受益，而不需要额外的数据。实验结果表明，在抗体设计中，该方法能够产生更好的帕累托前沿，表现出优于基线和已有算法的性能，特别是在生成高亲和力的自然样态抗体方面具有明显优势。", "innovation": "本文的创新点在于提出了一种三阶段框架，包括使用大规模抗体序列数据预训练语言模型，通过扩散模型对序列和结构进行联合优化，以及使用改进的AbDPO技术来实现帕累托最优的能量对齐策略。同时，采用温度缩放策略以提高模型的多样性。这些创新使模型能够在多种能量目标下优化，并产生了更好的抗体设计结果。", "conclusion": "本文通过广泛的实验验证了所提出的方法在抗体设计中的优越性能，特别是在生成高亲和力且具自然样态的抗体方面。该方法具有较高的稳定性和效率，能够克服基线方法和先前技术中的局限性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05325", "html_url": "https://arxiv.org/abs/2502.05325", "title": "从反事实到决策树：模型提取攻击的竞争分析", "title_en": "From Counterfactuals to Trees: Competitive Analysis of Model Extraction Attacks", "authors": "Awa Khouna,Julien Ferry,Thibaut Vidal", "background": "随着机器学习即服务（MLaaS）的发展，人们在模型可解释性和安全性之间面临越来越大的权衡。可解释性技术（例如反事实解释）无意中增加了模型提取攻击的风险，使未经授权复制专有模型成为可能。", "innovation": "本文首次通过竞争分析的方法对模型提取攻击进行形式化分析，建立了评估其效率的基本框架。针对基于加性决策树的模型（例如决策树、梯度提升和随机森林），引入了能够实现绝对精度恢复的新算法，同时展示了强大的任意时间性能。此外，本文为提取基于决策树的模型提供了理论上的查询复杂性界，提供了对其部署安全性漏洞的新见解。", "conclusion": "本文通过引入新的理论框架和方法，提高了对基于决策树模型提取攻击的理解，为模型的安全部署提供了新的理论依据。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.07591", "html_url": "https://arxiv.org/abs/2502.07591", "title": "DMWM: 具有长期想象的双心智世界模型", "title_en": "DMWM: Dual-Mind World Model with Long-Term Imagination", "authors": "Lingyi Wang,Rashed Shelim,Walid Saad,Naren Ramakrishnan", "background": "世界模型对于代理在样本高效的方式下学习长期策略至关重要。现有的基于递归状态空间模型（RSSM）的世界模型依赖单步统计推理来捕捉环境动力学，但它们无法执行长期想象任务，因为预测误差会累积。", "innovation": "受人类认知的双过程理论启发，提出了一种新颖的双心智世界模型（DMWM）框架，通过集成逻辑推理实现逻辑一致的想象。DMWM 包含两个部分：直观处理状态转换的基于RSSM的系统1 (RSSM-S1) 部分以及通过分层深层逻辑推理指导想象过程的逻辑整合神经网络-基于系统2 (LINN-S2) 部分。设计了系统间的反馈机制，以确保想象过程遵守真实环境的逻辑规则。", "conclusion": "所提出框架在 DMControl 套件的基准任务中得到了广泛试验，结果表明，与最先进的世界模型相比，在逻辑相关性、试次效率、数据效率和长期想象方面取得了显著改进。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03393", "html_url": "https://arxiv.org/abs/2502.03393", "title": "使用隔室原型预训练流行病时间序列预报模型", "title_en": "Pre-training Epidemic Time Series Forecasters with Compartmental Prototypes", "authors": "Zewen Liu,Juntong Ni,Max S. Y. Lau,Wei Jin", "background": "准确的传染病预测对于准备疫情至关重要，但现有的数据驱动模型往往脆弱。这些模型通常只在一个病原体上训练，在新疫情爆发时面临数据稀缺问题，并且在病毒进化或干预措施导致的数据分布转移下表现不佳。然而，几十年来对多种疾病的监控数据提供了一个未被充分利用的知识转移源。为了解决这一问题，本文提出CAPE，这是一个用于流行病预测的开源预训练模型。现有的时间序列基础模型忽略了流行病学挑战，而CAPE则将流行病动态建模为潜在人群状态的混合物，称为隔室原型，从而直接从监控数据中发现了一种灵活的隔室原型字典，使得每次疫情都可以表示为一个随时间变化的混合状态，将观察到的感染与潜在的人群状态联系起来，以促进鲁棒的泛化能力，CAPE结合了自我监督的预训练目标和轻量级的流行病意识正则化项，使学习到的原型与流行病学的语义相一致。在一项横跨17种疾病和50多个地区的基准测试中，CAPE显著优于现有的基线模型，在零样本、少样本和全样本预测中均表现出色。", "innovation": "CAPE是第一个用于流行病预报的开源预训练模型，能够将流行病动态视为潜在人群状态的混合物，即隔室原型，直接从监控数据中发现。该模型结合自我监督的预训练目标和轻量级的流行病意识正则化项，从而实现了强健的泛化能力，能够根据历史经验对未来的疫情进行准确预测。它为预训练流行病模型提供了新的途径，使模型变得可移植和流行病学导向。", "conclusion": "这项工作代表了一个有原则的进步，朝着预训练流行病模型转移和流行病学掌握的理想方向迈进，多次验证了该模型在零样本、少样本和全样本预报中的优越表现。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.11564", "html_url": "https://arxiv.org/abs/2502.11564", "title": "连续扩散模型用于语言建模", "title_en": "Continuous Diffusion Model for Language Modeling", "authors": "Jaehyeong Jo,Sung Ju Hwang", "background": "扩散模型已证明是离散分类数据建模的有前途的替代方案，但直接在离散数据空间工作的扩散模型无法充分利用迭代细化的优势，因为信号会在离散状态之间的过渡中丢失。现有的为离散数据设计的连续扩散模型不如离散方法效果好，这阻碍了对离散数据的有效扩散模型的发展。", "innovation": "本文提出了一个结合了潜在分类分布几何特性的连续扩散模型，建立了离散扩散和连续流在统计流形上的联系，并在此基础上引入了一种推广现有离散扩散模型的简单扩散过程。此外，还提出了基于径向对称的无模拟训练框架，以及处理流形高维性的简单技巧。", "conclusion": "全面的实验表明，本文的方法在语言建模基准和其他模态上优于现有的离散扩散模型，并接近自回归模型的性能。该代码已在此处 https:// provided。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09324", "html_url": "https://arxiv.org/abs/2502.09324", "title": "通过布雷德排列神经网络的深度界限", "title_en": "Depth-Bounds for Neural Networks via the Braid Arrangement", "authors": "Moritz Grillo,Christoph Hertrich,Georg Loho", "background": "以往的研究针对全连接ReLU网络的城市表示问题已有一定程度的解决，但在一般情况下最了解的下限仍然是2个隐藏层。研究人员专注于与某些多面体复形兼容的神经网络，特别关注与布雷德扇形兼容的网络，旨在确定完全表示所有连续和分段线性函数所需的隐藏层数量。", "innovation": "研究证明了与布雷德扇形兼容的神经网络在完全表示d个数字的最大值时需要非恒定的$\text{\textgreek{3}}(\text{log}\text{log}\text{\textdollar}d\text{\textdollar})$个隐藏层。此外，研究者通过组合证明展示了当d=5时，需要3个隐藏层来计算最大值；展示了最大秩为3和2的maxout层可以表示7个数字的最大值，解决了此前仅通过大量计算验证的问题。", "conclusion": "研究提出了与布雷德扇形兼容的神经网络在完全表示特定函数时的深度下限，证明了在某些条件下的必要深度要求，并指出基于maxout网络的最佳上限不一定适用于所有情况。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08881", "html_url": "https://arxiv.org/abs/2502.08881", "title": "WENDy for Nonlinear-in-Parameters ODEs", "title_en": "WENDy for Nonlinear-in-Parameters ODEs", "authors": "Nic Rummel,Daniel A. Messenger,Stephen Becker,Vanja Dukic,David M. Bortz", "background": "WENDy（Weak-form Estimation of Non-linear Dynamics）框架是一个用于参数估计和差分方程（ODEs）系统推理的最近发展方法。此前的研究已经展示了WENDy的稳健性、计算效率和精确性，但对于线性参数的ODEs系统有效，而对于非线性参数的ODEs系统却不能使用。这项研究旨在验证和发展WENDy以更好地处理非线性参数的ODE系统，并通过新的WENDy-MLE算法实现局部非凸优化方法来估计最大似然估计器。", "innovation": "开发了WENDy-MLE，在保持原有WENDy的特点基础上，扩展了对非线性参数ODEs系统的处理能力。WENDy-MLE通过局部非凸优化方法近似最大似然估计，并通过解析表达式计算似然函数及其一阶和二阶导数来实现。此外，该研究还扩展了框架以处理具有对数正态噪声的离散数据。WENDy-MLE在准确性、收敛域和计算速度方面优于其他弱形式方法和传统的输出误差最小二乘法。实验结果表明该方法在各种基准ODE系统上的性能优良，优于其他弱形式方法和输出误差最小二乘法。", "conclusion": "研究开发了WENDy-MLE算法以处理更广泛的非线性参数ODEs系统，证明了在准确性、收敛域和计算速度方面的优越性，并通过大量数值结果进行了验证。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.16076", "html_url": "https://arxiv.org/abs/2502.16076", "title": "利用任意目标对齐下的特征共振进行离分布节点检测", "title_en": "Harnessing Feature Resonance under Arbitrary Target Alignment for Out-of-Distribution Node Detection", "authors": "Shenzhi Yang,Junbo Zhao,Sharon Li,Shouqing Yang,Dingyu Yang,Xiaofang Zhang,Haobo Wang", "background": "在图基机器学习领域检测离分布节点（OOD）具有挑战性，尤其是在没有已分布节点（ID）多类别标签的情况下。因此，该研究聚焦于特征空间而非标签空间，发现了即使在模型训练拟合随机目标的情况下，未知ID样本在优化已知ID样本时表现出比OOD样本更大的特征表示变化，这一现象称为特征共鸣。这种现象的原理在于，即使没有黄金标签，局部流形也可能表现出平滑共鸣。", "innovation": "开发了一种名为基于共鸣分离与学习（RSL）的独特图基OOD框架。它包括两个核心模块：(i) 实现一个在单一训练步骤中测量特征向量移动的更实用的微观级特征共鸣的代理；(ii) 结合合成OOD节点策略训练有效的OOD分类器。理论分析表明，在共鸣期，OOD节点具有优越的可分离性。实验结果表明，RSL在13个真实世界图形数据集上取得了最先进的性能。", "conclusion": "RSL通过利用特征共鸣，即使在训练目标随机的情况下，也能有效检测出未知ID和OOD节点，并在广泛的实验数据集中展现了优越的性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.19670", "html_url": "https://arxiv.org/abs/2502.19670", "title": "通过建模噪声依赖性训练鲁棒图神经网络", "title_en": "Training Robust Graph Neural Networks by Modeling Noise Dependencies", "authors": "Yeonjun In,Kanghoon Yoon,Sukwon Yun,Kibum Kim,Sungchul Kim,Chanyoung Park", "background": "在实际应用中，图中的节点特征常常包含来自各种来源的噪声，这导致图神经网络(GNN)的性能显著下降。尽管已有一些方法旨在增强鲁棒性，但这些方法假定节点特征中的噪声与图结构和节点标签无关，这在实际情况中是不现实的，且限制了这些方法的应用范围。", "innovation": "该研究引入了一种更现实的噪声场景，即基于依赖性的图噪声(DANG)，其中节点特征中的噪声会在图结构和节点标签中形成连锁噪声依赖关系。研究提出了一种新的鲁棒图神经网络(DA-GNN)，利用变分推断捕捉DANG数据生成过程中变量之间的因果关系。此外，还提出了一组新的基准数据集，以模拟DANG在实际应用中的情况，使关于鲁棒图神经网络的研究更加实用。", "conclusion": "广泛的实验表明，DA-GNN在各种噪声场景中都优于现有基准，包括DANG和本领域中常见的传统噪声模型。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.19335", "html_url": "https://arxiv.org/abs/2502.19335", "title": "Gatekeeper: 通过信心调整改进模型级联", "title_en": "Gatekeeper: Improving Model Cascades Through Confidence Tuning", "authors": "Stephan Rabanser,Nathalie Rauschmayr,Achin Kulshrestha,Petra Poklukar,Wittawat Jitkrittum,Sean Augenstein,Congchao Wang,Federico Tombari", "background": "大规模机器学习模型在多种任务上表现出强大的性能，但同时也面临着巨大的计算和资源限制。为了解决这些挑战，通常会在大规模模型旁边部署较小的本地模型，并通过路由和延期机制将复杂任务卸载到大的模型上。然而，现有的方法未能有效地平衡这些模型的能力，经常导致不必要的延期或资源使用效率低下。", "innovation": "本文介绍了一种新颖的损失函数——Gatekeeper，用于调校级联设置中的较小模型。该方法通过微调较小模型，使其能够自信地处理它能够正确完成的任务，并将复杂任务延期到大型模型。此外，该方法包含一个机制，用于平衡模型性能与延期准确性之间的权衡，并且可以在各种任务和领域中广泛适用，无需任何架构更改。", "conclusion": "我们在编码器、解码器和编码器-解码器架构上评估了我们的方法，并在图像分类、语言建模和视觉-语言任务上进行了实验。结果显示，我们的方法显著提高了延期性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.12622", "html_url": "https://arxiv.org/abs/2503.12622", "title": "实时细胞排序的可扩展原位FPGA加速深度学习", "title_en": "Real-Time Cell Sorting with Scalable In Situ FPGA-Accelerated Deep Learning", "authors": "Khayrul Islam,Ryan F. Forelli,Jianzhong Han,Deven Bhadane,Jian Huang,Joshua C. Agar,Nhan Tran,Seda Ogrenci,Yaling Liu", "background": "精确的细胞分类在生物医学诊断和治疗监测中至关重要，尤其是在识别涉及各种疾病的多种细胞类型时。传统的方法如流式细胞术依赖于分子标记，这往往是成本高、耗时且会改变细胞完整性。为克服这些限制，本文提出了一种无标记的机器学习框架，用于使用明场显微镜图像进行实时分类应用。该方法依赖于采用知识蒸馏增强的教学-学生模型架构，能够跨不同细胞类型实现高效和可扩展性。", "innovation": "本文提出了一个教学-学生模型架构，结合知识蒸馏来提高效率和可扩展性。证明了该框架在淋巴细胞亚群分类中的应用，教师模型在T4和B细胞分类中达到了98%的准确性，学生模型仅使用教师模型0.02%的参数，在FPGA上实现，并展示了极低的推理延迟和总延迟，同时保持了与教师模型相当的准确性。", "conclusion": "本文框架为淋巴细胞分类提供了一个可扩展和成本效益高的解决方案，并展示了实时细胞排序的新SOTA实现，使用即插即用计算硬件上的现场深度学习快速识别亚群。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.01455", "html_url": "https://arxiv.org/abs/2503.01455", "title": "合理决策树：任意分裂规则解决最优决策树问题的公理框架", "title_en": "Proper decision trees: An axiomatic framework for solving optimal decision tree problems with arbitrary splitting rules", "authors": "Xi He,Max A. Little", "background": "本文提出了一个公理框架，用于分析决策树的算法特性。这个框架通过结构和谱系约束来进行严格的数学基础下的决策树问题分类。重点探讨了合理决策树这一特殊类别的决策树问题，因其灵活性和有效性。合理决策树涵盖了多种著名的数据结构，如二空间分割树、K-D树和机器学习决策树模型。研究证明，只有合理决策树可以唯一地被刻画为K-排列，而常见的非合理决策树则具有更高复杂性的二元标记决策树。基于这一正式的刻画，开发了一种通用的求解策略，用于解决合理决策树在任意分裂规则和目标函数下的最优决策树问题。该研究还展示了如何通过适当修改或舍弃某些公理来解决常见的非合理决策树问题，如二元特征数据的决策树、二叉查找树和矩阵链乘法问题中的树结构等。研究成果挑战了关于缓存数据集和子树之间存在权衡的文献中的观点，并进一步考虑到了如树深度和叶节点大小等约束条件，同时还可以通过稀疏化等技术加速研究。总的来说，该研究提供了一个有效的框架来解决各种决策树问题，并强调了合理决策树的独特优势。", "innovation": "提出了一个公理框架，用于分析和解决合理决策树的最优问题，该框架通过结构和谱系约束来研究决策树问题。研究证明，只有合理决策树可以被刻画为K-排列，而非合理决策树的复杂性更高。开发了一种通用的基于动态规划的精确求解策略，并展示了如何通过适当修改或舍弃某些公理来解决常见的非合理决策树问题。进一步地，该研究还挑战了关于缓存数据集和子树之间存在权衡的传统观点，并提出了关于树深度和叶节点大小等约束条件下加速算法的方法。", "conclusion": "总结指出，该公理框架为研究和解决各种形式的决策树问题提供了有效的途径，尤其是合理决策树。通过这种方式，可以解决具有任意分裂规则和目标函数的最优决策树问题。该研究强调了合理决策树的独特优势及其他非合理决策树的复杂性，同时也提出了优化解决这些树问题的方法，并考虑了在实际应用中的性能优化技术。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12801", "html_url": "https://arxiv.org/abs/2504.12801", "title": "从零开始稀疏训练的翻转参数：进入彩票", "title_en": "Sign-In to the Lottery: Reparameterizing Sparse Training From Scratch", "authors": "Advait Gadhikar,Tom Jacobs,Chao Zhou,Rebekka Burkholz", "background": "从零开始训练稀疏神经网络（PaI）与从密到疏的训练之间的性能差距是高效深度学习的重要障碍。根据彩票假设，PaI 依赖于找到特定问题的参数初始化。然而，正如我们所展示的，确定正确的参数符号就足够了，但这些符号对PaI来说仍然难以捉摸。", "innovation": "该论文提出了“Sign-In”，这是一种动态重新参数化方法，可证明引发符号翻转。这些符号翻转与从密到疏训练所能完成的符号翻转互补，使Sign-In成为一种正交方法。", "conclusion": "虽然实验和理论表明PaI可能会有性能提升，但它们也揭示了闭合PaI与从密到疏训练的差距的主要开放挑战。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.18807", "html_url": "https://arxiv.org/abs/2503.18807", "title": "Markovian数据流联邦学习", "title_en": "Streaming Federated Learning with Markovian Data", "authors": "Tan-Khiem Huynh,Malcolm Egan,Giovanni Neglia,Jean-Marie Gorce", "background": "联邦学习(Federated Learning, FL)被广泛认为是通信高效的协作学习的关键框架。然而，大部分理论和实证研究都基于客户端能够访问预先收集的数据集的前提，对于客户端持续采集数据的情况关注度较低。在很多现实世界的应用场景中，尤其是数据由物理或生物过程生成时，客户端的数据流常被建模为非平稳的马尔可夫过程。不同于标准的独立同分布(i.i.d.)采样，马尔可夫数据流的联邦学习性能一直不明确，主要原因是由于客户端样本之间的时间相关性。已有关于联邦学习的研究少有涉及非平稳数据流对其性能的影响。", "innovation": "本文探讨了马尔可夫数据流对联邦学习性能的影响。分析了在标准假设下，使用Mini-batch SGD、Local SGD及带有动量的改进型Local SGD表现。研究结果表明这些方法在解光滑非凸的客户端目标函数下的样本复杂度与i.i.d.样本下的通信复杂度相当，但样本复杂度仍高于i.i.d.采样。这意味着联邦学习在处理非平稳数据流时需要更多的样本量，尽管其通信复杂度依然保持高位。", "conclusion": "在标准假设下，联邦学习能够支持马尔可夫数据流下的协作学习，尽管该场景下的样本复杂度较高，但其通信复杂度与独立同分布采样相当。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.21536", "html_url": "https://arxiv.org/abs/2503.21536", "title": "探索RBM的能量景观：基于共轭空间的玻色子、层次学习和对称性破缺洞察", "title_en": "Exploring the Energy Landscape of RBMs: Reciprocal Space Insights into Bosons, Hierarchical Learning and Symmetry Breaking", "authors": "J. Quetzalcóatl Toledo-Marin,Anindita Maiti,Geoffrey C. Fox,Roger G. Melko", "background": "深度生成模型由于能够学习和从复杂分布中采样而变得普及。尽管存在多种框架，但这些模型之间的关系尚未得到充分探索，这阻碍了对AI学习的统一理论的发展。", "innovation": "作者通过引入共轭空间形式，揭示了RBM与扩散过程和耦合玻色子之间的联系。作者展示了RBM在初始化时处于鞍点，该点的局部曲率由奇异值分布决定，奇异值分布遵循Marcenko-Pastur定律并表现出旋转对称性。在训练过程中，这种旋转对称性会因分层学习而被打破，各自由度逐渐捕捉不同抽象层次的特征，导致能量景观中的对称性破缺，类似Landau理论。作者还推导了在均场近似下的自由能，并表明在RBM无穷大时，共轭变量将是高斯分布。作者发现，在这种情况下，将出现一些模式，使得扩散过程不会收敛到玻尔兹曼分布。", "conclusion": "研究结果填补了生成框架之间的不同，并且也照亮了在生成模型中学习的过程。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.24123", "html_url": "https://arxiv.org/abs/2503.24123", "title": "CTSketch: 组成张量概要化实现可扩展的神经符号学习", "title_en": "CTSketch: Compositional Tensor Sketching for Scalable Neurosymbolic Learning", "authors": "Seewon Choi,Alaia Solko-Breslin,Rajeev Alur,Eric Wong", "background": "许多计算任务可以通过将神经网络与离散的符号程序的组合来表达。神经符号学习的目标是通过端到端的输入-输出标签来训练神经网络。尽管已有研究有所进展，但如何提高神经符号推理的可扩展性仍然面临挑战。", "innovation": "作者提出了一种新颖的可扩展神经符号学习算法——CTSketch。CTSketch 通过将符号程序分解为子程序，并用简化的张量表示每个子程序来提高可扩展性。这种方法允许使用简单的张量操作来估计由输入分布和轮廓表示的程序输出分布，同时提供了理论上的误差上限。", "conclusion": "CTSketch 在神经符号学习基准测试上取得了显著成果，尤其是针对可扩展性的测试，神经预测器在具有千个输入的任务中获得了高准确率，即使只有最终输出的标签。这表明CTSketch 将神经符号学习推向了先前难以达到的新规模。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15846", "html_url": "https://arxiv.org/abs/2504.15846", "title": "基于主成分分析的自适应异常检测方法在空间任务中的应用", "title_en": "Adaptive PCA-Based Outlier Detection for Multi-Feature Time Series in Space Missions", "authors": "Jonah Ekelund,Savvas Raptis,Vicki Toy-Edens,Wenli Mo,Drew L. Turner,Ian J. Cohen,Stefano Markidis", "background": "空间任务中有效事件检测对于自动分析至关重要，但限制于机载计算资源和数据下传限制，需要能够在实时条件下识别感兴趣区域的鲁棒方法。多特征时间序列数据的分析在空间任务中特别重要，而现有的方法往往依赖于预定义的模型，在面对不断变化的数据分布时表现不佳。因此，需要一种能够在不预先定义模型的情况下适应数据分布变化的自适应异常检测算法，以应对空间任务中的多特征时间序列数据。", "innovation": "提出了一种基于主成分分析（PCA）重构误差的自适应异常检测算法，通过增量PCA动态适应不断变化的数据分布，无需为所有可能的条件预先建立模型。此外，通过预缩放过程将每个特征的量纲归一化，同时保持内部特征类型的相对方差。该算法在NASA的MMS任务观察数据和THEMIS数据中有效检测了空间等离子体事件，如特定的空间环境、白天和夜晚瞬态现象以及过渡层等。该方法利用了机载可用的测量数据，实现了在机载有限计算资源下的有效应用。", "conclusion": "研究成果展示了自适应PCA基础的异常检测算法在空间任务中的有效性，这种算法能够在不预先定义模型的情况下适应数据分布的变化，成功识别了NASA MMS和THEMIS任务中的空间等离子体事件，为空间任务中的实时事件检测提供了有效的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.04738", "html_url": "https://arxiv.org/abs/2505.04738", "title": "SetONet：一种基于集合的操作网络，用于处理具有变量采样输入的PDEs", "title_en": "SetONet: A Set-Based Operator Network for Solving PDEs with Variable-Input Sampling", "authors": "Stepan Tretiakov,Xingjian Li,Krishna Kumar", "background": "神经操作员，尤其是深度操作网络（DeepONet），在学习函数空间之间的映射以求解微分方程方面显示出前景。然而，标准的DeepONet需要输入函数采样在固定位置，限制了它在传感器布局变化或输入位于不规则网格上的情况下应用。", "innovation": "我们引入了Set Operator Network（SetONet），它修改了DeepONet的分支网络以处理输入函数为无序集合的形式。通过集成Deep Sets原则，SetONet确保了不变性同时保留了与基础模型相同的参数量。SetONet在经典的操作学习基准测试中实现了与固定布局的DeepONet相当的表现，同时在变量传感器布局或传感器丢失的情况下保持准确度，这是标准DeepONet不可用的情况。更重要的是，SetONet可以原生处理自然表示为不规则点云输入的问题（如点源或密度样本），这是标准DeepONet所缺乏的能力。", "conclusion": "SetONet是一种DeepONet类架构，具有轻量级设计，显著扩大了操作学习在变量、不完整或不规则输入数据问题上的适用范围。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.01618", "html_url": "https://arxiv.org/abs/2505.01618", "title": "不要懒惰：CompleteP 使深度Transformer计算高效", "title_en": "Don't be lazy: CompleteP enables compute-efficient deep transformers", "authors": "Nolan Dey,Bin Claire Zhang,Lorenzo Noci,Mufan Li,Blake Bordelon,Shane Bergsma,Cengiz Pehlevan,Boris Hanin,Joel Hestness", "background": "研究了在使用不同参数化（即随着模型大小变化调整模型和优化器超参数的方法）时，大型语言模型（LLM）训练的计算效率。不同的参数化方法可能导致在模型深度变化时转移最优基础超参数（如学习率）失败，迫使实践者在放大模型时重新调整这些超参数（代价高昂），或者在重新调整不可行时接受次优训练。即使某些参数化能够实现超参数的转移，理论研究还表明，这些参数化可能仍然处于惰性学习阶段，即只有靠近线性化的特征被学习，这阻止了深度和非线性的有效利用。", "innovation": "提出了一个新的参数化方法称之为CompleteP，可以实现深度超参数的转移和各层的非惰性学习。CompleteP 使模型宽度与深度的比例范围更宽，以保持计算效率，为不同的硬件配置和运营环境解锁更合适的模型形状。此外，CompleteP 相比之前的最佳状态提供了12-34%的计算效率改进。所有实验都在Cerebras CS-3系统上运行。提供了一个最小实现版本可在此链接找到：https://example.com/implementation", "conclusion": "CompleteP 实现了深度超参数转移和各层非惰性学习，从而使更宽泛的模型宽度/深度比保持计算效率，同时提供优于之前最佳状态12-34%的计算效率改进。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07260", "html_url": "https://arxiv.org/abs/2505.07260", "title": "UMoE: 实现注意力机制和前馈网络共享专家的统一", "title_en": "UMoE: Unifying Attention and FFN with Shared Experts", "authors": "Yuanhang Yang,Chaozheng Wang,Jing Li", "background": "稀疏专家混合(Sparse Mixture of Experts, MoE)架构已成为扩展Transformer模型的一个有前途的方法。早期的研究主要将MoE引入前馈网络(FFN)层，而最近的研究则探讨了将MoE扩展到注意力层以提升模型性能。目前，基于注意力的MoE层需要特殊的实现方式，并且其性能不及基于FFN的MoE层。", "innovation": "本文提出了一个新的注意力机制的重新构建方法，揭示了注意力模块内部存在类似FFN的结构。基于这种新的机制，提出了UMoE架构，该架构不仅实现了基于注意力的MoE层的高性能，还能够在FFN和注意力组件之间实现有效的参数共享。", "conclusion": "UMoE架构通过基于注意力的MoE层实现了优越的性能，并且能够让FFN和注意力组件之间更有效地共享参数。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.09131", "html_url": "https://arxiv.org/abs/2505.09131", "title": "Fair Clustering via Alignment", "title_en": "Fair Clustering via Alignment", "authors": "Kunwoong Kim,Jihu Lee,Sangchul Park,Yongdai Kim", "background": "算法公平性在聚类中的主要目标是平衡每个聚类中实例的比例与给定的敏感属性之间的关系。尽管最近开发的公平聚类算法在特定公平性约束下优化聚类目标，但它们的内在复杂性或近似性可能导致实践中出现次优的聚类效用或数值不稳定。", "innovation": "提出了一个新的基于新颖分解公平K均值聚类目标函数的公平聚类算法，称为Fair Clustering via Alignment（FCA）。算法通过交替计算（i）找到一个联合概率分布以对齐来自不同受保护群体的数据，和（ii）在对齐的空间中优化聚类中心来运行。FCA的一个关键优势在于，它理论上能够在任何给定的公平性水平下提供近似最优的聚类效用，无需复杂的约束，从而可以实现高效用的公平聚类。", "conclusion": "实验表明，FCA在以下两个方面优于现有方法：(i) 在公平性和聚类效用之间实现了更优的权衡；(ii) 在实现接近完美的公平性的同时避免了数值不稳定的问题。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10465", "html_url": "https://arxiv.org/abs/2505.10465", "title": "superposition yields robust neural scaling", "title_en": "Superposition Yields Robust Neural Scaling", "authors": "Yizhou Liu,Ziming Liu,Jeff Gore", "background": "大规模语言模型（LLMs）的成功依赖于启发式观察，即模型越大表现越好。然而，这种神经网络缩放定律的根源，即损失随着模型大小以幂律下降，仍然不清楚。本文通过Anthropic的玩具模型，使用权重衰减来控制超迭的程度，系统地研究了损失随着模型大小的变化，并证实开源的大规模语言模型在强超迭状态下运作，且损失随模型维度的倒数按幂律变化。", "innovation": "文章提出，表示超迭（即大规模语言模型表示的特征多于其维度），可能是导致损失和造成神经网络缩放的关键因素。通过玩具模型，使用权重衰减来控制表示超迭的程度，研究了不同情况下损失如何随模型大小变化。结果显示，在强超迭状态下，损失在广泛的数据特征频率分布中按照模型维度的倒数进行缩放。", "conclusion": "研究结果将表示超迭识别为神经网络缩放定律的关键驱动力，提供了关于何时可以改善神经网络缩放定律以及何时它们可能会失效的见解。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11821", "html_url": "https://arxiv.org/abs/2505.11821", "title": "通过回合级奖励设计增强LLM代理的多轮推理", "title_en": "Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Reward Design", "authors": "Quan Wei,Siliang Zeng,Chenliang Li,William Brown,Oana Frunza,Wei Deng,Anderson Schneider,Yuriy Nevmyvaka,Yang Katie Zhao,Alfredo Garcia,Mingyi Hong", "background": "这篇论文研究了增强大型语言模型（LLM）代理在长期多轮对话中的推理能力的方法。虽然现有的强化学习（RL）算法，如组相对策略优化（GRPO）和近似策略优化（PPO），已被广泛应用于训练多轮LLM代理，但它们通常仅依赖稀疏的结果奖励，缺乏跨多个决策步骤的密集中间信号，这限制了它们在复杂推理任务中的表现。", "innovation": "本文首次系统地研究了多轮RL算法和代理的回合级奖励设计。通过引入回合级奖励，作者将GRPO和PPO扩展到多轮变体，实现了细粒度的信用分配。研究还在多轮推理增强搜索代理中进行了案例研究，精心设计了验证性奖励和作为裁判的LLM两种类型的回合级奖励。", "conclusion": "实验表明，将精心设计的回合级奖励纳入RL算法能够显著提高多轮搜索任务的表现，与基于轨迹级奖励的基准方法相比。训练和验证奖励曲线表明，该方法实现了更大的稳定性、更快的收敛性以及更高的准确性。在不同问答数据集的数值结果中，本文的方法在答案正确性和格式正确性方面表现最佳，达到了100%。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.06520", "html_url": "https://arxiv.org/abs/2505.06520", "title": "PRUNE: 基于补丁的神经网络修复框架以实现可验证的不可学习", "title_en": "PRUNE: A Patching Based Repair Framework for Certifiable Unlearning of Neural Networks", "authors": "Xuran Li,Jingyi Wang,Xiaohan Yuan,Peixin Zhang", "background": "在训练的神经网络模型中，往往需要移除特定的训练数据部分（也被称为“遗忘”）。常见的应用场景是保护数据持有者的‘被遗忘权’，这在许多最近的法规中得到了推广。现有的遗忘方法通常需要训练新的替代模型，并且可能会从数据持有者或第三方审计者的角度来看过于昂贵且难以验证。", "innovation": "本文提供了一个新的视角并提出了一种基于‘补丁’的新型遗忘方法，通过在原始神经网络上施加精心设计的‘补丁’来实现对特定请求数据点的目标‘遗忘’。受神经网络修复研究线的启发，论文提出了一种策略，以确保在限定的数据点上实施轻量级的最小‘补丁’并具备可验证的保证，以实现特定数据点的遗忘。进一步提出了逐迭代选择有代表性的数据子集的方法，以实现对大量数据点（或整个类别）的遗忘效果。广泛的实验结果显示该方法的有效性，能够在保持模型性能的同时实现可测量的‘遗忘’，并且在效率和内存使用方面与各种基线方法具有竞争性优势。", "conclusion": "本研究提出的方法在保持模型性能的同时实现了可测量的遗忘效果，并且具有高效且节省内存的特性，是现有遗忘方法的有效补充。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12149", "html_url": "https://arxiv.org/abs/2505.12149", "title": "通过Woodbury, 动量和随机化改进能量自然梯度下降", "title_en": "Improving Energy Natural Gradient Descent through Woodbury, Momentum, and Randomization", "authors": "Andrés Guzmán-Cordero,Felix Dangel,Gil Goldshlager,Marius Zeinhofer", "background": "自然梯度方法能够显著加速物理知情神经网络（PINNs）的训练过程，但往往因计算复杂度高而难以实现。", "innovation": "研究者引入了一系列技术来提升能量自然梯度下降（ENGD）算法在PINNs上的准确性和效率：1. 利用Woodbury公式大大降低ENGD的计算复杂度；2. 将变分蒙特卡洛文献中的子采样投影增量自然梯度下降算法应用于加速收敛；3. 探索随机算法在大批次处理时进一步降低计算成本。研究还发现随机化可在低维问题的训练早期加速进展，并指出了在其他情况下达到加速的关键障碍。", "conclusion": "数值实验表明，研究方法能显著优于先前的方法，相同$L^2$误差情况下最高可快75倍。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12944", "html_url": "https://arxiv.org/abs/2505.12944", "title": "CALM-PDE：连续且适应性的卷积在时变PDEs的潜在空间建模中的应用", "title_en": "CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs", "authors": "Jan Hagnberger,Daniel Musekamp,Mathias Niepert", "background": "求解时变偏微分方程（PDEs）的空间密集离散化在多种科学和工程学科中是一个基本问题，包括气候现象和流体动力学建模。然而，在物理空间中直接进行这些计算通常会产生显著的计算成本。为了应对这一问题，已经开发了基于神经元的代理模型，这些模型在压缩的潜在空间中解决PDE。虽然这些方法减少了计算复杂性，但它们通常使用基于Transformer的注意力机制来处理非规则采样域，这增加了内存消耗。卷积神经网络允许内存高效的编码和解码，但仅适用于规则离散化。", "innovation": "本文提出了一种新颖的CALM-PDE模型。CALM-PDE采用连续卷积的编码-解码架构，使用受限ε邻域核，并学习应用于自适应和优化查询点的卷积算子。该方法已经在不同类型的PDEs上进行了证明，包括规则采样和非规则采样空间域，显示了与或优于现有基线方法的性能，同时在内存和推理时间效率方面具有显著提升，相较于基于Transformer的方法。", "conclusion": "CALM-PDE展示了在压缩潜在空间中解决任意离散化PDE的效率，通过结合连续卷积和自适应查询点，它不仅在各种PDE上表现优异，还在内存和推理时间上具有明显优势。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13358", "html_url": "https://arxiv.org/abs/2505.13358", "title": "基于Koopman建模的一维离线蒸馏扩散模型", "title_en": "One-Step Offline Distillation of Diffusion-based Models via Koopman Modeling", "authors": "Nimrod Berman,Ilan Naiman,Moshe Eliasof,Hedi Zisling,Omri Azencot", "background": "扩散生成模型表现出卓越的性能，但其迭代采样过程仍然计算成本较高。蒸馏策略是缓解这一成本的一种主要方法，尤其是离线蒸馏在效率、模块性和灵活性方面具有明显优势。尽管扩散模型常被看作动力系统理论的一部分，但Koopman理论提供的工具更加强大且未被充分利用。扩散模型在潜在空间中具有结构化的、语义连贯的轨迹。基于这些观察，本文提出了Koopman蒸馏模型（KDM），这是一种基于Koopman理论的新型离线蒸馏方法，能够在嵌入空间中进行单步生成并保持语义保真度。", "innovation": "本文提出了Koopman蒸馏模型（KDM），一种基于Koopman理论的新型离线蒸馏方法，该模型能在嵌入空间中通过学习的线性算子进行单步生成，并利用解码器重建清洁样本。KDM在标准离线蒸馏基准测试中取得了极具竞争力的性能。理论证明了该方法的有效性：在温和假设下，学习的动力学扩散可归一为有限维的Koopman表示；Koopman潜在空间中的接近性与生成输出的语义相似性相关，便于进行有效的轨迹对齐。", "conclusion": "KDM在标准离线蒸馏基准测试中取得了极为竞争力的性能。KDM既为扩散模型的训练提供了高效的蒸馏策略，又通过嵌入空间中的线性操作保持了生成样本的语义保真度。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15602", "html_url": "https://arxiv.org/abs/2505.15602", "title": "连续时间跳过程下的深度学习控制方法", "title_en": "Deep Learning for Continuous-time Stochastic Control with Jumps", "authors": "Patrick Cheridito,Jean-Loup Dupret,Donatien Hainaut", "background": "本文介绍了一种基于模型的深度学习方法，用于解决具有跃变的有限时段连续时间随机控制问题。传统的随机控制方法难以处理高维和复杂的系统。通过迭代训练两个神经网络，一个表示最优策略，另一个近似值函数，利用连续时间的动态规划原理，基于哈密顿-雅可比-贝尔曼方程推导出两个不同的训练目标，从而使网络能够捕获潜在的随机动态。", "innovation": "本文提出的方法利用两个神经网络分别表示最优策略和近似值函数，并通过连续时间动态规划原理和哈密顿-雅可比-贝尔曼方程推导出两种不同的训练目标，确保网络能够捕捉随机动态的过程。这种模型能够解决复杂的高维随机控制任务。", "conclusion": "通过在不同问题上的实验评估，证明了本文方法的准确性和可扩展性，展示了该方法在解决复杂高维随机控制任务的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13938", "html_url": "https://arxiv.org/abs/2505.13938", "title": "CLEVER：正式验证代码生成的精心编排基准", "title_en": "CLEVER: A Curated Benchmark for Formally Verified Code Generation", "authors": "Amitayush Thakur,Jasper Lee,George Tsoukalas,Meghana Sistla,Matthew Zhao,Stefan Zetzsche,Greg Durrett,Yisong Yue,Swarat Chaudhuri", "background": "在端到端验证的代码生成领域，先前的基准数据集存在一些问题，例如依赖于测试案例监督、LLM生成的注释或泄露实现逻辑的规范，这会导致验证过程不够精确。为了克服这些问题，《CLEVER》项目提供了一个高质量、经过精心策划的基准数据集，涵盖了161个问题，用于评估在Lean环境下的端到端验证代码生成能力。所有生成的代码和规范都将经过Lean类型检查器的后验验证，确保正确性可以被机器检查。使用这个基准数据集，研究人员可以评测最新的语言模型在程序合成和形式推理方面的性能，这是非常具有挑战性的领域。", "innovation": "相比于其他基准，《CLEVER》项目具有以下创新点：（1）不依赖测试案例监督，（2）避免LLM生成的注释，（3）不包含泄露实现逻辑或导致空解的规范，（4）所有的输出都通过Lean的类型检查器进行后验验证以确保机器可验证的正确性。这些特性使得《CLEVER》成为一个用于评测程序合成和形式推理能力的严格和具有挑战性的基准。", "conclusion": "使用《CLEVER》基准数据集评估了几种基于最先进的语言模型的少量样本和代理方法后，发现这些方法在实现全面验证方面都存在困难，这表明该基准数据集是程序合成和形式推理领域的前沿挑战。《CLEVER》基准数据集可在GitHub (https://github.com/) 和HuggingFace (https://huggingface.co/) 上获取，同时所有评测代码也已公开。这为未来的研究提供了数据基础和评测平台。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15034", "html_url": "https://arxiv.org/abs/2505.15034", "title": "RL Tango：共同强化生成器和验证器以提高语言推理能力", "title_en": "RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning", "authors": "Kaiwen Zha,Zhengqi Gao,Maohao Shen,Zhang-Wei Hong,Duane S. Boning,Dina Katabi", "background": "强化学习（RL）已成为提高大型语言模型（LLMs）推理能力的有效方法。在这些模型中，LLM生成器由奖励模型（verifier）引导。目前，LLM的RL后训练方法大多依赖于固定的（规则基于的或冻结预训练的）验证器或通过监督微调（SFT）进行区分训练的验证器。这两种设计方法存在奖励作弊和泛化能力不足的问题，尤其是超出训练分布范围时表现不佳。本文旨在解决这些问题。", "innovation": "本文提出了Tango框架，这是一种创新的方法，使用RL同时训练LLM生成器和验证器。关键的创新在于Tango采用了一种过程级别的生成验证器，这种验证器是通过RL训练并与其他生成器共同进化。值得注意的是，验证器仅根据结果级别的验证正确奖励进行训练，而不需要进行明确的过程级别注释。这种方法在鲁棒性和泛化能力方面优于确定性和SFT训练的验证器，有助于与生成器的有效相互强化。实验表明，Tango框架的两个组件在多个任务中表现出优越性能，特别是在处理最复杂的数学推理问题方面取得了显著进步。", "conclusion": "研究结果表明，Tango框架中的生成器在生活中级数学推理基准测试中及跨领域挑战性推理任务中取得了最佳性能，验证器则在ProcessBench数据集中表现出领先性能，尤其是在处理最复杂的数学推理问题时表现出显著的进步。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16581", "html_url": "https://arxiv.org/abs/2505.16581", "title": "如何在强化学习中通过蒸馏策略的集成提高泛化能力", "title_en": "How Ensembles of Distilled Policies Improve Generalisation in Reinforcement Learning", "authors": "Max Weltevrede,Moritz A. Zanger,Matthijs T.J. Spaan,Wendelin Böhmer", "background": "在零样本策略迁移的强化学习场景中，目标是训练一个代理在固定的一组训练环境中，使其能够在相似但未见过的测试环境中表现出色。此前的研究表明，训练后进行策略蒸馏有时可以生成在测试环境中性能优于原始策略的策略。然而，尚不清楚为何如此，以及该使用何种数据进行策略蒸馏。", "innovation": "本文证明，在某些假设下，训练后进行策略蒸馏可以提供泛化界。理论提供了两个实际见解：要提高泛化能力，应该1) 训练蒸馏策略的集成，2) 尽可能多地在训练环境数据上进行策略蒸馏。实验表明，在理论所需假设不再适用的情况下，这些见解同样适用。此外，研究还显示，在多样化数据集上蒸馏的策略集成可以在某些情况下比原始代理表现更好。", "conclusion": "最终，研究证明，在多样化数据集上蒸馏的策略集成可以显著优于原始代理。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17190", "html_url": "https://arxiv.org/abs/2505.17190", "title": "热带注意：组合算法的神经算法推理", "title_en": "Tropical Attention: Neural Algorithmic Reasoning for Combinatorial Algorithms", "authors": "Baran Hashemi,Kurt Pasque,Chris Teska,Ruriko Yoshida", "background": "当前的神经推理模型在提高模型敏锐度、鲁棒性和可解释性方面存在挑战。该论文探讨了代数几何是否可以通过赋予神经逻辑模型数学根基的归纳偏见，来提高这些性能。", "innovation": "论文引入了基于热带几何的‘热带注意’机制，通过将注意力核提升到热带投影空间，使得推理过程成为分段线性和1-Lipschitz的，从而保持了组合推理固有的多面体决策结构。证明了多头热带注意机制（MHTA）可以在不调用递归机制的情况下，无限制地逼近热带电路，并实现热带传递闭包。这些保证解释了为什么产生的多面体决策边界保持了清晰度和平移不变性，而不是被Softmax过程中的平滑作用所改变。实验证明，热带注意机制在分布外泛化能力、抗噪声能力和参数效率方面优于基于Softmax和递归注意的baseline模型，并首次将神经算法推理扩展到了PTIME问题之外的NP难和NP完全问题。", "conclusion": "该研究为构建更敏锐、更具表现力的大型推理模型（LRMs）铺平了道路，这些模型能够应对形态学、密码学、粒子物理和数学发现等领域中的复杂组合挑战。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17404", "html_url": "https://arxiv.org/abs/2505.17404", "title": "Wasserstein Transfer Learning", "title_en": "Wasserstein Transfer Learning", "authors": "Kaicheng Zhang,Sinian Zhang,Doudou Zhou,Yidong Zhou", "background": "转移学习是一种强大的范式，可以从源领域提取知识以改善目标领域中的学习效果。然而，传统的转移学习方法通常仅限于欧几里得空间内的标量或多元数据，这限制了它们在如概率分布等复杂数据结构上的应用。", "innovation": "本文提出了一种新的转移学习框架，将回归模型的输出定义在Wasserstein空间中的概率分布上。在已知具有信息的可转移源领域的情况下，提出了具有可证明渐近收敛率的估计器，量化领域相似性对转移效率的影响。对于未知哪些领域具有信息的情况，开发了一种数据驱动的转移学习过程，旨在减轻负向转移的影响。这些方法支持严格的理论分析，并通过广泛的模拟和实际应用得到了验证。", "conclusion": "所提出的方法通过详尽的理论分析和广泛的仿真及实际应用验证，并且代码可在以下链接找到：https://github.com/transfer-learning."}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15293", "html_url": "https://arxiv.org/abs/2505.15293", "title": "LLM-Explorer：一种由大型语言模型驱动的插件强化学习策略探索增强", "title_en": "LLM-Explorer: A Plug-in Reinforcement Learning Policy Exploration Enhancement Driven by Large Language Models", "authors": "Qianyue Hao,Yiwen Song,Qingmin Liao,Jian Yuan,Yong Li", "background": "在强化学习（RL）中，策略探索是至关重要的。现有的方法包括贪婪法和基于高斯过程的方法等。然而，这些方法大多基于预设的随机过程，且在各种RL任务中不分具体情况，应用相同的方式进行策略探索。在RL训练期间，这些随机过程的进化是刚性的，通常是通过减少方差来实现，缺乏根据代理当前学习状态进行灵活调整的能力。研究团队受到大型语言模型（LLMs）分析和推理能力的启发，设计了LLM-Explorer，它可以自适应地生成与特定任务匹配的策略探索策略，提升RL中的策略探索能力并根据学习过程灵活调整。", "innovation": "LLM-Explorer主要创新在于它可以自适应地生成任务特定的探索策略，这是通过在设定任务期间抽取代理学习轨迹并使用LLM分析其当前策略学习状态，从而生成未来策略探索的概率分布。这种概率分布会定期更新，以专门适应特定任务的随机过程。此外，该设计可以作为插件模块，兼容各种常用的RL算法，如DQN系列、DDPG、TD3及其所有可能的变体。通过在Atari和MuJoCo基准测试上的广泛实验，展示了LLM-Explorer能够显著提升RL策略探索性能，平均性能提升了37.27%。这种策划的插件模块允许在现有的各种RL算法中轻松集成并扩展功能，使得RL策略探索更加灵活和有效。", "conclusion": "我们的设计展示了针对RL策略探索的增强效果，通过结合大型语言模型的能力，可以显著提高策略探索的定制性和灵活性。该插件模块已在广泛应用于不同RL任务的算法上得到验证。我们的代码是在GitHub上开源的，以促进研究的可重复性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18781", "html_url": "https://arxiv.org/abs/2505.18781", "title": "几何感知操作转换器作为任意域上PDEs的有效且准确的神经代理", "title_en": "Geometry Aware Operator Transformer as an Efficient and Accurate Neural Surrogate for PDEs on Arbitrary Domains", "authors": "Shizheng Wen,Arsh Kumbhat,Levi Lingsch,Sepehr Mousavi,Yizhou Zhao,Praveen Chandrashekar,Siddhartha Mishra", "background": "准确且高效地学习任意区域上的PDE解操作是非常重要的，这对于工程和工业模拟至关重要。尽管有许多算法可以逼近PDE，但我们发现准确的模型不一定计算效率高，反之亦然。", "innovation": "提出了一种几何感知操作转换器（GAOT）来学习任意域上的PDE。GAOT结合了新颖的多尺度注意力图神经操作编码器和解码器，以及几何嵌入和（视觉）转换处理器，有效映射区域和输入信息到PDE解的稳健近似。此外，GAOT在实现方面还有多种创新，确保了计算效率和可扩展性。", "conclusion": "多项测试表明，GAOT在多种PDE学习任务上，无论是准确性还是效率都优于多个基线，甚至在三个大规模三维工业CFD数据集上达到了最先进的性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.16690", "html_url": "https://arxiv.org/abs/2505.16690", "title": "您的预训练LLM其实是未监督的信心校准器", "title_en": "Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator", "authors": "Beier Luo,Shuoyuan Wang,Sharon Li,Hongxin Wei", "background": "大语言模型（PLMs）的后训练对于使其适应人类偏好和下游任务至关重要。然而，后训练语言模型（PoLMs）往往会表现出过度自信的问题，无论正确与否都给予高置信度，这在关键应用中可能会削弱其可靠性。由于缺少针对个别下游任务的标记数据，校准PoLMs的成本很高。这项工作旨在解决这一挑战，提出了一种新的无监督方法（Disagreement-Aware Confidence Alignment，DACA）用于优化后训练中使用的参数（如温度τ），以改进信心校准效果。DACA方法通过在不一致实例中仅选择一致实例来进行校准，从而避免了由不一致性引起的参数优化问题，提高了校准性能。", "innovation": "提出了一种新颖的无监督方法DACA，用于优化后训练的信心校准参数（如温度τ），通过仅选择一致实例进行校准，来减少由不一致性引发的过度校准问题。通过这种方法，DACA能够避免因不一致实例导致的过度校准问题，从而提高校准效果。实验结果表明，与开源和API基大语言模型（如GPT-4o）相比，DACA能显著改进平均置信误差（ECE），提升幅度可达15.08%。", "conclusion": "通过DACA方法，可以在缺少标记数据的情况下有效降低PoLMs的过度自信问题，提高其在关键任务中的可靠性，同时保持其出色的预训练性能。实验结果证明了DACA方法的有效性，进一步展示了未监督的信心校准在改善预训练模型性能方面的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21785", "html_url": "https://arxiv.org/abs/2505.21785", "title": "作为Transformer始终是Transformer吗？预训练对架构能力的影响", "title_en": "Born a Transformer -- Always a Transformer? On the Effect of Pretraining on Architectural Abilities", "authors": "Mayank Jobanputra,Yana Veitsman,Yash Sarrof,Aleksandra Bakalova,Vera Demberg,Ellie Pavlick,Michael Hahn", "background": "Transformer模型在处理序列到序列的任务时存在一定的理论局限性，但这些局限性在大规模预训练语言模型中是否起作用，或者它们是否能够通过模型规模和预训练数据集规模本身被克服，这一点尚未明确。我们通过研究由Liu等人提出的检索和复制任务来探索这些架构限制在预训练后如何表现，使用 Huang 等人提出的长度泛化研究框架为每种设置提供了理论保证。", "innovation": "通过使用最近提出的长度泛化研究框架，为每种设置提供了理论保证，并观察到预训练模型在检索右侧（诱导）而不在左侧（反诱导）的查询标记方面具有优势。这种不对称性在目标微调并保证长度泛化后消失，进一步揭示了预训练模型选择性增强某些Transformer能力，但不克服固有的长度泛化限制。", "conclusion": "研究结果表明，预训练可以增强某些Transformer的能力，但由于存在固有的长度泛化限制，这些能力是有局限性的。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22389", "html_url": "https://arxiv.org/abs/2505.22389", "title": "在扰动中训练，在合并后推理：双重框架中的连续学习", "title_en": "Train with Perturbation, Infer after Merging: A Two-Stage Framework for Continual Learning", "authors": "Haomiao Qiu,Miao Zhang,Ziyue Qiao,Liqiang Nie", "background": "连续学习（CL）旨在让模型在一系列任务中持续获取新知识，同时避免遗忘已学信息。现有CL方法仅依赖于最近任务的参数进行推理，这使它们容易遭受灾难性遗忘。鉴于模型合并技术的近期成功，本文提出了一种融合模型合并的新型CL框架——Perturb-and-Merge (P\textbf{\\&}M)，旨在解决遗忘问题。该框架通过在每次训练后构建的原有模型和最新训练任务特定模型的凸组合来应对遗忘问题。", "innovation": "本文提出了P\textbf{\\&}M框架，采用了模型合并技术，使模型在每次任务训练后能够形成原有模型和最新任务特定模型的结合，从而减轻遗忘。此外，通过引入一个由任务向量和损失函数海森矩阵组成的正则化项，提出了有效的合并模型性能改进策略。这一创新方法无需额外的正向或反向传递，从而实现有效的正则化项近似。最后，将P\textbf{\\&}M框架与LoRA结合，一种参数高效的微调方法，以减少内存开销，最终在多个CL基准数据集上取得了最先进的性能。", "conclusion": "本文提出的新框架P\textbf{\\&}M利用模型合并技术解决了现有CL方法中的遗忘问题，通过理论分析，最小化了所有任务损失的增加，通过特定的正则化项改进了合并模型的表现，并且成功地结合了LoRA以降低内存需求，实现了在多个CL基准数据集上的最新性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17866", "html_url": "https://arxiv.org/abs/2505.17866", "title": "DesignX: 黑盒优化的人类竞争力算法设计师", "title_en": "DesignX: Human-Competitive Algorithm Designer for Black-Box Optimization", "authors": "Hongshu Guo,Zeyuan Ma,Yining Ma,Xinglin Zhang,Wei-Neng Chen,Yue-Jiao Gong", "background": "设计有效的黑盒优化器受到问题特定知识有限以及手工控制需要数月才能覆盖所有细节的限制。本文讨论了一个自动化算法设计框架——DesignX，能够在几秒内生成针对特定黑盒优化问题的有效优化器。该框架通过个体基本原理识别了两个关键子任务：算法结构生成和超参数控制。通过构建一个包罗数百种算法组件的模块化算法空间，以及引入一个协作式的双智能体强化学习系统，可实现大规模元训练。", "innovation": "引入了DesignX，一个自动化算法设计框架，能够在几秒内生成针对特定黑盒优化问题的有效优化器。该框架通过个体基本原理识别了两个关键子任务：算法结构生成和超参数控制。通过构建一个包罗数百种算法组件的模块化算法空间，并引入一个协作式的双智能体强化学习系统，实现大规模元训练，通过几天的自主学习，生成的优化器在合成测试床或现实优化场景中都超过了人工设计的优化器。进一步的深度分析揭示了DesignX发现超越专家直觉的非平凡算法模式的能力，为优化社区提供了有价值的设计见解。", "conclusion": "通过几个小时的自动学习，DesignX生成的优化器在合成测试床或现实优化场景中持续超过人工生成的优化器，展示了设计X发现超越专家直觉的非平凡算法模式的能力，为优化社区提供了有价值的设计见解。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22601", "html_url": "https://arxiv.org/abs/2505.22601", "title": "过参数化下的机器遗忘", "title_en": "Machine Unlearning under Overparameterization", "authors": "Jacob L. Block,Aryan Mokhtari,Sanjay Shakkottai", "background": "机器遗忘算法旨在消除特定训练样本的影响，理想地恢复若仅使用其余数据进行训练，原本模型应具有的结果。本文研究过参数化设置下的遗忘问题，其中许多模型可以完美地解析数据，定义解为在保留数据集上的任意损失极小化器，在欠参数化设置中的先前工作则定义为这样的解。然而，在此设置中，损失梯度消失，导致以前基于梯度扰动的方法无效，需要新的遗忘定义和算法。", "innovation": "定义了过参数化设置下的遗忘解为在保留数据集上的最小复杂度解析器，并提出了一种新的算法框架，只需要在原始解上对保留集的模型梯度进行访问。该框架通过最小化约束为这些模型梯度正交的扰动对象来实现该条件的第一阶松弛。针对不同的模型类别提供了精确和近似的遗忘保障，并展示了我们的框架在多种遗忘实验中优于现有基准。", "conclusion": "对于过参数化设置，定义了遗忘解为目标保留数据集的最小复杂度解析器，并提出了一种新的算法框架，仅需访问原始解上保留集的模型梯度。这种框架是通过第一阶方法实现的解析条件的最小化目标的松弛。通过不同模型类别的实验，展示了框架的有效性，优于现有的基线方法。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23751", "html_url": "https://arxiv.org/abs/2505.23751", "title": "REOrdering Patches Improves Vision Models", "title_en": "REOrdering Patches Improves Vision Models", "authors": "Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta", "background": "序列模型如变分器需要将输入表示为一维序列。在视觉领域，这通常涉及使用固定行优先级（栅格扫描）顺序的图像展平。虽然全自注意机制在置换方面是不变的，但现代长序列的变分器逐渐依赖于打破这种不变性的架构近似，导致对块顺序变得敏感。研究表明，块顺序对模型性能产生了显著影响，简单的替代方案如列优先级或希尔伯特曲线可带来显著的准确性提升。", "innovation": "提出了一种名为REOrder的双阶段框架，用于发现任务最优的块顺序。首先，通过评估各种块序列的压缩性来推导出信息论先验，然后通过优化Plackett-Luce策略来学习置换策略，使用REINFORCE。这种方法能够在组合置换空间中实现高效学习。实验结果表明，与行优先级顺序相比，REOrder在ImageNet-1K的数据集上提高了高达3.01%的Top-1准确率，而在Functional Map of the World的数据集上提高了13.35%的准确率。", "conclusion": "REOrder通过发现任务最优的块顺序，能够显著提高视觉模型的性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24261", "html_url": "https://arxiv.org/abs/2505.24261", "title": "驯服数据归因中的超参数敏感性：在无需昂贵训练重做情况下进行实用的选择", "title_en": "Taming Hyperparameter Sensitivity in Data Attribution: Practical Selection Without Costly Retraining", "authors": "Weiyi Wang,Junwei Deng,Yuzheng Hu,Shiyuan Zhang,Xirui Jiang,Runting Zhang,Han Zhao,Jiaqi W. Ma", "background": "数据归因方法在现代AI的数据中心应用中越来越受欢迎，这些方法量化了单个训练数据点对机器学习模型的影响。尽管最近在这个领域开发出了新的方法，但这些方法中的超参数调优的影响仍然被广泛忽视。这项工作旨在了解常见数据归因方法对关键超参数的敏感性，并发现评估数据归因效果通常需要在训练数据的子集上重新训练模型，这使得传统的验证指标无法用于超参数调优，这给数据归因方法的实际应用带来了重大的挑战。", "innovation": "该研究是首个大型实证研究，旨在理解常见数据归因方法的超参数敏感性。提出了一个理论分析，以分析受影响关键超参数中的正则化项，并针对这一分析提出一种无需重新训练模型即可选择正则化值的轻量级方法，并证明其在标准数据归因基准中的有效性。强调了未来方法开发中需要仔细讨论超参数选择的重要性。", "conclusion": "研究指出了数据归因在实际应用中的一项根本但被忽视的挑战，并强调了在今后的方法开发中需要仔细讨论超参数选择的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00744", "html_url": "https://arxiv.org/abs/2506.00744", "title": "混合二次线性变换器中的互补记忆系统融合", "title_en": "Blending Complementary Memory Systems in Hybrid Quadratic-Linear Transformers", "authors": "Kazuki Irie,Morris Yau,Samuel J. Gershman", "background": "本文开发了一种用于通用序列处理神经网络的混合内存架构，结合了使用softmax注意机制的关键值内存(KV-memory)和通过动态突触调节实现的快速权重内存(FW-memory)。KV-memory在精确检索方面表现出色，但受限于序列长度的二次复杂性；FW-memory可以支持任意长的序列并使计算更加丰富，但牺牲了精确的回忆能力。本文通过三种不同的方法将这两种系统融合成单一的内存系统，以发挥各自的优点。", "innovation": "提出了三种将KV-memory和FW-memory融合的方法，不同的方法在输入信息传递给每个系统的方式和时机上有所差异，利用了两种系统的优点。通过训练340M和1.3B参数的模型，在通用语言建模和检索任务中进行了实验，以及专门设计的合成算法任务，以精确展示某些混合方法的特定优势。此外，还将混合内存系统应用于部分可观察域的强化学习。", "conclusion": "通过精心设计的混合系统，克服了其个体组件的局限性，为神经内存系统的设计原则提供了新的见解。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01665", "html_url": "https://arxiv.org/abs/2506.01665", "title": "利用分析梯度在证明安全性强化学习中的应用", "title_en": "Leveraging Analytic Gradients in Provably Safe Reinforcement Learning", "authors": "Tim Walter,Hannah Markgraf,Jonathan Külz,Matthias Althoff", "background": "在安全关键应用中部署自主机器人需要安全保证。可证明安全的强化学习作为一个活跃的研究领域，旨在通过安全措施提供这类保证。这些安全措施应在训练期间集成以减少仿真到现实的差异。虽然有几种方法可以保护基于采样的强化学习，但基于分析梯度的强化学习通常可以在较少的环境交互中实现更好的性能。然而，尚未有针对这种学习范式的保护方法。本文填补了这一空白，开发了第一种有效的基于分析梯度的强化学习保护方法。通过现有可微保护、修改映射和梯度公式以及将其集成到最先进的学习算法和可微仿真中，评估不同保护措施对学习的影响，结果显示保护性训练不会牺牲性能。附加的可视化结果可在[此链接](this http URL)中查看。", "innovation": "开发了基于分析梯度的强化学习的第一个有效保护方法，对现有可微保护措施进行了分析、适应和改进，并将其整合到最先进的学习算法和可微仿真中，为安全关键应用中的自主机器人部署提供了一种新型的解决方案。", "conclusion": "通过实验验证了保护性训练在不影响性能的前提下可以有效减少基于分析梯度的强化学习中的安全风险。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04432", "html_url": "https://arxiv.org/abs/2506.04432", "title": "KOALA++: 使用梯度协方差产品的高效卡尔曼优化神经网络", "title_en": "KOALA++: Efficient Kalman-Based Optimization of Neural Networks with Gradient-Covariance Products", "authors": "Zixuan Xia,Aram Davtyan,Paolo Favaro", "background": "在神经网络训练中，大多数优化算法依赖于一阶梯度信息，如常用的Adam、SGD等。然而，这些方法不能很好地捕捉参数之间的协方差。相比之下，二阶优化方法可以利用二阶梯度信息，但计算复杂度高，效率较低。文章提出了一种名为KOALA++的新方法，它基于卡尔曼滤波原理，能够明确建模结构化的梯度不确定性。", "innovation": "KOALA++通过递归更新紧凑的梯度协方差乘积来直接估计参数协方差矩阵，避免存储整个协方差矩阵和进行大型矩阵求逆，从而降低了计算成本。此外，该方法假设协方差矩阵不是对角线形式，而是隐式地捕捉到更复杂的不确定性结构，进一步提高了优化效率。", "conclusion": "通过在图像分类和语言建模等任务上的实验，KOALA++展示了与最先进的第一和第二阶优化器相当或更好的准确率，同时保持了一阶优化方法的高效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.07584", "html_url": "https://arxiv.org/abs/2506.07584", "title": "MIRA: 用于实际医疗数据的医学时间序列基础模型", "title_en": "MIRA: Medical Time Series Foundation Model for Real-World Health Data", "authors": "Hao Li,Bowen Deng,Chang Xu,Zhiyuan Feng,Viktor Schlegel,Yu-Hao Huang,Yizheng Sun,Jingyuan Sun,Kailai Yang,Yiyao Yu,Jiang Bian", "background": "现有的通用时间序列基础模型在处理医学时间序列数据时存在困难，因为医学时间序列数据具有节奏不规则、采样率异质性以及频繁缺失值等特点。这些问题导致现有的模型难以有效处理医学时间序列数据，因此在数据稀缺或隐私受限的环境下，需要一种专门针对这些挑战设计的统一基础模型来减少注释负担、降低模型定制化程度并实现跨机构、跨模态和跨任务的稳健迁移。", "innovation": "MIRA（医学时间序列预测模型）是一种专门针对医学时间序列的统一基础模型。MIRA采用连续时间旋转位置编码来精细建模前所未见的时间间隔，通过频率特异性混合专家层在潜在频率领域中路由计算以促进时间专业化，并基于神经ODE的连续动态外推块来建模潜在状态的连续轨迹，从而实现任意目标时间戳的准确预测。MIRA在其专业领域内进行了大规模预训练，并展示出了相较于其他零样本和微调基线模型更佳的预测误差减少，特别是在分布外和分布内场景中分别减少了10%和7%。", "conclusion": "MIRA为跨机构和多下游临床任务的医学时间序列建模提供了一个全面基准，为未来研究奠定了基础。该模型的有效性验证了其在特定医学时间序列环境中的提升潜力，并展现了其跨环境泛化的稳健性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06045", "html_url": "https://arxiv.org/abs/2506.06045", "title": "基于扩散的分层图神经网络在模拟非线性固体力学中的应用", "title_en": "Diffusion-Based Hierarchical Graph Neural Networks for Simulating Nonlinear Solid Mechanics", "authors": "Tobias Würth,Niklas Freymuth,Gerhard Neumann,Luise Kärger", "background": "基于图的已学习模拟器因能在不规则网格上模拟物理系统而显得有潜力，提供速度优势和跨不同几何形状的一般化能力。然而，它们在捕捉全局现象（如弯曲或远程关联）方面通常存在问题，尤其是在固体力学中，这些现象通常会在长时间步内累积误差，这主要归因于它们依赖于局部信息传递和直接下一步预测。本文以此为背景，探讨了现有的挑战及其解决方法.", "innovation": "介绍了Rolling Diffusion-Batched Inference Network (ROBIN)这一新提出的已学习模拟器，它通过两个关键创新解决了上述限制：(i) Rolling Diffusion-Batched Inference (ROBI)，一种并行化的推理方案，通过在时间窗口中重叠去噪步骤来并行化扩散基修正的成本，跨越物理时间步来摊薄。 (ii) 基于代数多重网格粗化构建的分层图神经网络，实现了不同网格分辨率下的多层次信息传递。通过Algebraic-hierarchical Message Passing Networks，该架构能够捕捉对现象如梁弯曲或多体接触至关重要的细观局部动力学和宏观结构性效应.", "conclusion": "论文验证了ROBIN在包括几何、材料和接触非线性在内的具有挑战性的2D和3D固体力学基准测试中的表现。ROBIN在所有任务中实现了最先进的准确性，显著优于现有的一步预测已学习模拟器，在与标准扩散模拟器相比时将推理时间减少了可达一个数量级."}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.09018", "html_url": "https://arxiv.org/abs/2506.09018", "title": "Edit Flows: 使用编辑操作进行流程匹配", "title_en": "Edit Flows: Flow Matching with Edit Operations", "authors": "Marton Havasi,Brian Karrer,Itai Gat,Ricky T. Q. Chen", "background": "自回归生成模型能够自然地生成变长序列，而非自回归模型则较为困难，通常会施加固定的、基于令牌的结构。现有非自回归模型难以处理这种变化，这限制了其在生成序列数据时的灵活性和适用性。论文提出了Edit Flows，这是一种非自回归模型，通过定义序列上的编辑操作（插入、删除和替换）来克服这些限制，从而在序列空间上构建一个连续时间马尔可夫链。这种方法使模型能够在保留位置相关性的同时，实现灵活的生成。", "innovation": "论文创新性地提出了Edit Flows模型，这是一种基于编辑操作的非自回归模型，通过在序列上定义编辑操作（插入、删除和替换）并使用连续时间马尔可夫链来建模这些操作，达到了更为灵活和位置相关的生成。通过引入扩展状态空间和辅助变量，使得学习过程更为高效和易于实现。实验结果表明，Edit Flows模型在图像字幕和文本及代码生成任务中优于自回归模型和掩码模型。", "conclusion": "编辑操作与连续时间马尔可夫链的结合为非自回归生成模型提供了新的思路，使得生成更灵活并能更紧密地匹配序列数据结构。Empirical结果证明，Edit Flows模型在图像字幕和文本及代码生成等任务上表现出优越性，尤其在掩码构建方面显著超越现有模型。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06644", "html_url": "https://arxiv.org/abs/2506.06644", "title": "Spark Transformer: 在FFN和注意力机制中重新激活稀疏性", "title_en": "Spark Transformer: Reactivating Sparsity in FFN and Attention", "authors": "Chong You,Kan Wu,Zhipeng Jia,Lin Chen,Srinadh Bhojanapalli,Jiaxian Guo,Utku Evci,Jan Wassenberg,Praneeth Netrapalli,Jeremiah J. Willcock,Suvinay Subramanian,Felix Chern,Alek Andreev,Shreya Pathak,Felix Yu,Prateek Jain,David E. Culler,Henry M. Levy,Sanjiv Kumar", "background": "最近发现，训练好的Transformer中，其前向网络中的大部分神经元在每个Token上都是不活跃的，这种现象被称为“懒惰神经元”。这引发了对增强大型模型效率的激活稀疏性研究的兴趣。尽管在将稀疏性转化为实际时间上的好处方面取得了显著进展，现代Transformer已经偏离了ReLU激活函数，这直接影响了这一现象的形成。现有的努力通常会降低模型质量、增加参数量或者使训练复杂化或变慢。稀疏注意力，即将稀疏性应用到注意力机制上，也面临着类似的挑战。", "innovation": "本文提出了Spark Transformer，这是一种新的架构，能够在保留模型质量、参数数量和标准训练流程的同时，实现FFN和注意力机制中的高稀疏性。通过top-k掩码实现显式的稀疏控制，并引入了硬件友好的、近似线性时间的统计top-k算法，避免了昂贵的排序操作并减轻了标准top-k操作带来的显著训练速度减慢问题。Spark Transformer重新分配了现有的FFN参数和注意力键嵌入，以形成一种低成本的预测器来识别激活的条目。此外，这种方法不仅减轻了强迫稀疏性带来的质量损失，还提升了实际时间效益。经过Gemma-2配方预训练后，Spark Transformer在标准基准上表现出竞争力，仅8%的FFN神经元被激活，并且每个Token最多关注256个Token。这种稀疏性使得FLOPs减少了2.5倍，导致CPU和GPU上的解码实际时间分别加速了1.79倍和1.40倍。", "conclusion": "Spark Transformer提供了在维持模型质量和效率的同时实现高激活稀疏性的一种创新方法，通过top-k掩码和统计top-k算法，有效提高了在实际应用中的性能和效率。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21364", "html_url": "https://arxiv.org/abs/2505.21364", "title": "无需牺牲的可解释性：Mixture of Decoders实现忠实的密集层分解", "title_en": "Towards Interpretability Without Sacrifice: Faithful Dense Layer Decomposition with Mixture of Decoders", "authors": "James Oldfield,Shawn Im,Sharon Li,Mihalis A. Nicolaou,Ioannis Patras,Grigorios G Chrysos", "background": "多层感知器（MLPs）是大规模语言模型的重要组成部分，但由于其密集的表示形式，使得它们难以理解和编辑。尽管最近的方法通过神经元级的稀疏性学习可解释的近似值，但这种方法未能准确重构原始映射，显著增加了模型的下一标记交叉熵损失。因此，本文提倡从层级别稀疏性入手，以克服稀疏层逼近带来的准确率抉择问题。在这一框架下，我们引入了一种稀疏分解方法——混合解码器（MxDs），它能够扩展预训练的密集层至数千个专门的小层，通过灵活的张量分解形式，稀疏激活的小层仍能够保持原解码器的表达能力。", "innovation": "本文提出了一种新的稀疏分解方法——混合解码器（MxDs），它能够大规模扩展预训练的密集层，并通过灵活的张量分解形式实现稀疏激活。通过MxDs，即使在高度稀疏的情况下，也能够保持模型的表达能力，实验结果显示，MxDs在多达3亿参数的语言模型上显著超越了最先进的方法，且在稀疏探针和特征控制方面也展现出与自然语言相似的专业化特征，这是设计忠实且可解释的模型的新途径。", "conclusion": "实验表明，MxDs在稠密层的分解上表现优异，显著优于现有方法，并为设计可解释且忠实的语言模型开辟了新的途径，同时演示了MxDs的源代码。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10948", "html_url": "https://arxiv.org/abs/2506.10948", "title": "Execution Guided Line-by-Line Code Generation", "title_en": "Execution Guided Line-by-Line Code Generation", "authors": "Boaz Lavon,Shahar Katz,Lior Wolf", "background": "现有大型语言模型（LLMs）在代码生成方面展现了显著的能力，但在推理过程中通常不利用执行反馈。编程人员通常会利用执行反馈来指导代码生成。因此，一种新方法——执行引导的分类器自由指导（Execution-Guided Classifier-Free Guidance，EG-CFG）——被提出，该方法将执行信号动态地整合到代码生成过程中，以提供逐行反馈，从而引导生成可执行的解决方案。", "innovation": "该方法通过多阶段过程实现：首先，使用束搜索（beam search）来采样每行的候选程序补全；其次，通过在测试案例中执行这些候选生成执行信号；最后，在生成过程中将这些信号整合到提示中。这种方法保持了同一行内信号的一致性，并在行边界处刷新信号，从而提供连贯的指导，同时保留了结构语法。此外，该方法自然支持任务级的原生并行处理，即多个代理并行操作，探索不同的推理路径，并集体生成一系列候选解决方案。", "conclusion": "实验结果表明，EG-CFG 在各种复杂度的编码任务中均显著提高了代码生成性能，特别是在基础问题、具有挑战性的编程比赛和数据科学任务中，达到了最先进的结果。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13688", "html_url": "https://arxiv.org/abs/2506.13688", "title": "损失 plateau 期间发生了什么？理解 Transformer 的猛然学习", "title_en": "What Happens During the Loss Plateau? Understanding Abrupt Learning in Transformers", "authors": "Pulkit Gopalani,Wei Hu", "background": "先前的研究表明，在训练 Transformer 架构时，在算法任务上，经常会出现一种有趣的突然学习现象：长时间的性能平台期后，突然出现急剧提升。本研究旨在探讨这一现象背后的机制，主要关注浅层 Transformer。研究表明，平台期内，模型往往会产生可解释的部分解决方案，同时在输出中表现出强烈的重复偏差。这种输出退化伴随内部表示崩溃现象，表现为不同词元的隐藏状态几乎平行。进一步研究发现，最优注意力映射的学习缓慢是主要原因。此外，在平台期内注意力配置的隐性进步才能最终实现快速收敛，并且直接干预注意力显著改变了平台的持续时间和重复偏差及表示崩溃的严重程度。研究还验证了这些现象（重复偏差和表示崩溃）不仅限于玩具设置，也在大型语言模型如 Pythia 和 OLMo 的早期预训练阶段同样存在。", "innovation": "研究揭示了平台期内两种关键现象：1）模型开发可解释的部分解决方案，同时表现出强烈的输出重复偏差；2）内部表示的崩溃。研究进一步确定了最优注意力映射学习缓慢是平台期内的主要瓶颈。通过直接干预注意力，研究显著影响了平台的持续时间和重复偏差及表示崩溃的严重程度。最后，研究验证了这些现象不仅存在于玩具设置中，也存在于大型语言模型的预训练阶段。", "conclusion": "本研究发现了训练浅层 Transformer 期间平台期内的两个关键现象（输出重复偏差和内部表示崩溃）以及一个重要瓶颈（最优注意力映射的学习缓慢）。此外，研究证明了通过对注意力直接干预可以显著改变平台的持续时间以及缓解重复偏差和表示崩溃的问题。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14167", "html_url": "https://arxiv.org/abs/2506.14167", "title": "Thermodynamic Kolmogorov-Arnold Model for Structured Generative Modeling", "title_en": "Structured Generative Modeling with the Thermodynamic Kolmogorov-Arnold Model", "authors": "Prithvi Raj", "background": "使用顶层生成模型的潜在空间学习能量型模型（EBM）为跨多种数据模态的生成提供了灵活框架。但如何利用其可解释性指导模型设计、提升生成质量及缩短训练时间仍不清楚。依赖朗格维蒙特卡洛（LMC）采样存在效率和多模态潜在分布采样挑战。", "innovation": "提出Kolmogorov-Arnold表示定理的新适应方法，引入热力学Kolmogorov-Arnold模型（T-KAM），利用结构和归纳偏见。通过约束先验到单变量关系，T-KAM可以快速且精确地利用反变换方法进行推理。针对重要性采样（IS）失效情况，引入基于群体的LMC新策略，将后验采样分解为一系列退火分布以提高多模态采样。T-KAM平衡了生成建模中的常见权衡，提供快速推理、可解释性和稳定训练，且与即将推出的Zettascale Computing Corp.硬件天然契合。", "conclusion": "T-KAM实现了生成建模中常用权衡的优雅平衡，提供了快速推理、可解释性和稳定训练，同时与即将到来的Zettascale Computing Corp.硬件天然相符。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14291", "html_url": "https://arxiv.org/abs/2506.14291", "title": "处处皆等变：构建图基础模型的秘诀", "title_en": "Equivariance Everywhere All At Once: A Recipe for Graph Foundation Models", "authors": "Ben Finkelshtein,İsmail İlkan Ceylan,Michael Bronstein,Ron Levie", "background": "传统图机器学习架构通常针对特定任务和特定数据集进行定制，这限制了它们的广泛适用性。为此，图机器学习领域正寻求构建能够在任意图和特征上泛化的基础模型。", "innovation": "本文提出了一种从第一原理设计节点级任务的基础模型的方法，核心在于系统研究模型必须遵守的对称性，即标签置换等变性和特征置换不变性，以及节点置换等变性。通过证明基于这些对称性的网络能够成为多重集的通用近似器，本文提供了一种设计节点属性预测的图基础模型的解决方案。", "conclusion": "作者通过在29个真实节点分类数据集上的广泛实验验证了该方法，显示了强大的零样本实证性能，并且随着训练图的数量增加，表现持续改进。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.16349", "html_url": "https://arxiv.org/abs/2506.16349", "title": "自回归图像生成的水印技术", "title_en": "Watermarking Autoregressive Image Generation", "authors": "Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez", "background": "生成模型的输出水印化作为一种有前景的方法，可用于追溯其来源。尽管人们对自回归图像生成模型存在大量兴趣，并关注其潜在的滥用可能性，但之前没有工作尝试在标记级别对这些模型的输出进行水印处理。", "innovation": "提出了首个在自回归图像生成模型的输出标记级别进行水印的技术。该方法通过适应语言模型水印技术，解决了反循坏一致性(RCC)问题，并引入了定制的分词-反分词微调流程以及校准层，以增强鲁棒性，防御图像变换、神经压缩和删除攻击。", "conclusion": "实验结果表明，该方法实现了可靠且基于理论的P值验证的水印检测。相关代码和模型在此处可用：this https URL."}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14436", "html_url": "https://arxiv.org/abs/2506.14436", "title": "MoORE: SVD-based Model MoE-ization for Conflict- and Oblivion-Resistant Multi-Task Adaptation", "title_en": "MoORE: SVD-based Model MoE-ization for Conflict- and Oblivion-Resistant Multi-Task Adaptation", "authors": "Shen Yuan,Yin Zheng,Taifeng Wang,Binbin Liu,Hongteng Xu", "background": "在多任务场景中调整大规模基础模型时，常常遇到任务冲突和遗忘的问题。这些问题是由于模型在处理多个任务时难以兼顾各个任务的需求，并且在进行新的任务适配后，原始任务的表现会下降。", "innovation": "提出了一个新的“模型MoE化”策略，称为MoORE。该策略通过SVD对预训练模型的权重矩阵进行分解，并引入一个可学习的路由器来调整奇异值，使得不同任务和样本具有不同的权重分配。每个专家由左奇异向量与相应右奇异向量的外积组成。此外，还可以通过在右奇异向量上施加一个可学习的正交变换来提高模型容量。MoORE确保了专家之间的正交性，并保留了原有权重矩阵的列空间。这一特性使得模型能够抵抗新任务间的冲突和原始任务的遗忘。", "conclusion": "在各种数据集上的实验表明，MoORE在冲突和遗忘抵抗方面优于现有的多任务适配方法。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13992", "html_url": "https://arxiv.org/abs/2506.13992", "title": "AssistedDS：评估外部领域知识如何辅助LLM在自动化数据科学中的表现", "title_en": "AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science", "authors": "An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding", "background": "大型语言模型（LLMs）已经提升了数据科学工作流程的自动化水平。但是，尚不清楚它们是否能够像人类数据科学家那样有效地利用外部领域知识。为了回答这个问题，作者引入了AssistedDS（辅助数据科学），这是一个旨在系统性地评估LLMs在表格式预测任务中处理领域知识能力的基准测试。AssistedDS结合了包含明确定义生成机制的合成数据集和真实的Kaggle比赛，这些比赛都附带了经过精选的有益和对抗性文档。这些文档提供了数据清洗、特征工程和模型选择的领域特定见解。作者评估了最先进的工具和模型（LLMs），看它们能否区分并应用有益的知识和有害的知识，评估提交的有效性、信息检索和预测性能。结果表明了三个关键发现：(1) LLMs经常表现出对提供的信息的无批判性采用，当引入对抗性内容时显著降低了预测性能；(2) 有益的指导往往不足以抵消对抗性信息的负面影响；(3) 在Kaggle数据集上，LLMs常犯错误包括时间序列数据处理不当、不同折间特征工程的一致性问题和正确解释分类变量。这些发现揭示了当前模型在评估和有效利用专家知识方面存在的显著差距，强调了开发更强大、知识敏感的自动化数据科学系统的必要研究方向。作者的数据和代码已公开提供。", "innovation": "作者提出了AssistedDS作为评估LLMs在处理外部领域知识时表现的基准测试。该基准测试结合了合成数据集和Kaggle竞赛，并包含了有益的和对抗性的文档，用于提供数据清洗、特征工程和模型选择的领域特定了解。评估了LLMs区分和应用有益知识与有害知识的能力，重点关注它们的提交有效性、信息检索能力和预测性能。这一基准测试提供了一个全新的视角，评估模型在自动化数据科学中的表现，特别是在领域知识处理方面的有效性.", "conclusion": "研究发现了三个关键发现：第一，LLMs经常表现出无批判性地采取提供的信息，当引入对抗性内容时预测性能显著下降；第二，有益信息往往不足以抵消对抗性信息的负面影响；第三，在处理现实世界的Kaggle数据集时，LLMs常常在处理时间序列数据、一致特征工程和正确解释分类变量方面出错。这些发现揭示了当前模型在评估和利用专家知识方面的局限性，突出了未来需要更深入研究这一重要方向，以提高自动化数据科学系统的鲁棒性和知识敏感性。数据和代码公开提供，以便于进一步的研究和验证。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23679", "html_url": "https://arxiv.org/abs/2506.23679", "title": "使用Transformer学习模幂运算", "title_en": "Learning Modular Exponentiation with Transformers", "authors": "David Demitri Africa,Sara M. Kapoor,Theo Simon Sorg,Challenger Mishra", "background": "模幂运算在数论和密码学中至关重要，但其从机制可解释性的角度尚未得到充分探索。本文通过训练一个4层编码器-解码器Transformer模型，探讨模幂运算的操作，并研究模型训练过程中数值推理能力的涌现。利用有序采样策略、基于PCA的嵌入分析以及激活层改造，本文分析了模型内部如何嵌入数论性质。", "innovation": "通过运用机器学习方法（尤其是Transformer模型），本文发现模幂运算能力的提升与特定操作（如逆操作训练）有关，并观察到了与适应性（grocking）相似的动力学现象，表明模型学到了共享的算术结构。此外，还发现了模型最后一层中包含所有注意力头的子图，足以实现常规幂运算任务的完全性能。这些发现表明，Transformer模型通过专门的计算电路学习模幂运算，这为更可解释和高效的神经方法开辟了道路。", "conclusion": "本文模型通过特殊的计算电路学习了模幂运算，突显了Transformer模型在模幂运算上的内部化算术结构。研究指出，通过专门设计的机制，可以实现对模幂运算的更加可解释和高效的处理。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17065", "html_url": "https://arxiv.org/abs/2506.17065", "title": "基于流的方法进行动态时间因果模型的建模，包含非高斯或异方差噪声", "title_en": "Flow based approach for Dynamic Temporal Causal models with non-Gaussian or Heteroscedastic Noises", "authors": "Abdellah Rahmani,Pascal Frossard", "background": "在金融或神经科学等场景中，理解多元时间序列中的因果关系至关重要。许多时间序列表现出多个不同时段，每个时间段具有自己的未知边界和因果结构。推断因果依赖和阶段转换对于分析底层过程至关重要。然而，在这种情境下学习因果结构具有挑战性，原因在于非平稳性（每个阶段可能有不同的因果图和混合函数）及复杂的噪声分布（可能为非高斯或异方差）。现有因果发现方法无法解决这些挑战，因为通常假设平稳性或恒定方差的高斯噪声。因此，该论文提出了一种统一框架FANTOM，用于处理非平稳过程及非高斯或异方差噪声，同时推断阶段数及其对应索引并学习每个阶段的有向无环图。", "innovation": "FANTOM框架同时处理非平稳过程和非高斯或异方差噪声，并使用贝叶斯期望最大化算法最大化数据对数似然性下界。从理论上证明了FANTOM模型中引入的时间异方差因果模型，在平稳和非平稳条件下都是可识别的。实验结果表明FANTOM优于现有方法。", "conclusion": "FANTOM框架通过使用基于流的方法处理动态时间因果模型中的非高斯或异方差噪声，实现了更准确的因果结构学习。理论证明和实验证明都显示出FANTOM在处理非平稳和复杂噪声时的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.18631", "html_url": "https://arxiv.org/abs/2506.18631", "title": "ReDit：改进LLM策略优化的奖励抖动方法", "title_en": "ReDit: Reward Dithering for Improved LLM Policy Optimization", "authors": "Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu", "background": "DeepSeek-R1 通过基于规则的奖励系统成功增强了大型语言模型（LLM）的推理能力。虽然这样的奖励系统是一个''完美的''奖励系统，可以有效地缓解奖励黑客问题，但这些奖励功能往往是离散的。实验观察表明，离散奖励可能导致梯度异常、优化不稳定和收敛速度慢。为解决这一问题，我们提出了ReDit（奖励抖动）方法，通过添加简单的随机噪声来抖动离散的奖励信号。这种方法在学习过程中持续提供探索梯度，使得梯度更新更加平滑，并加速了收敛。此外，引入的噪声还在平坦的奖励区域引入了随机性，鼓励模型探索新的策略并逃逸局部最优。", "innovation": "我们提出了ReDit（奖励抖动）方法，通过添加简单的随机噪声来抖动离散的奖励信号，以解决离散奖励导致的问题。这种方法在学习过程中不断提供探索梯度，使梯度更新更加平滑，并加速了模型的收敛。此外，引入的噪声在平坦的奖励区域引入了随机性，鼓励模型探索新的策略并逃逸局部最优。", "conclusion": "在不同的任务上进行的实验表明，ReDit 的有效性。平均而言，ReDit 在训练步骤减少约 10% 的情况下达到了与常规 GRPO 相当的表现，并且在相似的训练时间内还表现出 4% 的性能提升。可视化结果进一步证实了使用 ReDit 时梯度问题得到了显著缓解。此外，还提供了理论分析以进一步验证这些优势。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07101", "html_url": "https://arxiv.org/abs/2507.07101", "title": "语言模型小批量训练：当Vanilla SGD有效以及梯度累积为何是浪费的原因", "title_en": "Small Batch Size Training for Language Models: When Vanilla SGD Works, and Why Gradient Accumulation Is Wasteful", "authors": "Martin Marek,Sanae Lotfi,Aditya Somasundaram,Andrew Gordon Wilson,Micah Goldblum", "background": "传统认为小批量会使语言模型预训练和微调不稳定，因此使用梯度积累来在优化步骤与批量大小之间进行折衷。尽管普遍做法是为小批量调整学习率，其他超参数通常保持不变。本文作者重新审视了从1到极小批量大小的语言模型训练，并提出了一种调整Adam超参数的方法。他们发现，小批量训练能够更加稳定，更具超参数鲁棒性，同时实现与大批量相似或更好的每浮点运算性能（FLOP），且能够在没有动量的情况下使用 Vanilla SGD 进行稳定训练，无需保存任何优化器状态。", "innovation": "提出了保持第二矩半衰期固定而变化批量大小的方法来调整 Adam 超参数；证明小批量能够实现与大批量相似或更好的性能，同时能以 Vanilla SGD 进行稳定训练；建议除非使用多个设备和多个模型复制品，否则不必使用梯度累积；提出小批量与具有小型状态大小的优化器可以提供全微调的效果，同时保持与LoRA相似的内存占用。", "conclusion": "小批量训练能够在超参数选择方面展现更好的鲁棒性，提供与大批量相似或更好的性能，甚至能够使用Vanilla SGD进行稳定训练，无需动量并且无需保存优化器状态。梯度累积在单机训练中通常是浪费的，建议除非使用多设备，否则不采用梯度累积。结合小批量训练与具有较小状态大小的优化器能够在实现接近全微调性能的同时保持与LoRA相类似的内存占用。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22766", "html_url": "https://arxiv.org/abs/2507.22766", "title": "使用高斯过程作为替代模型的基于贝叶斯优化的传感器式分拣系统工艺参数优化", "title_en": "Bayesian Optimization of Process Parameters of a Sensor-Based Sorting System using Gaussian Processes as Surrogate Models", "authors": "Felix Kronenwett,Georg Maier,Thomas Längle", "background": "基于传感器的分拣系统能够对物料流进行物理分离，将物料流分割成两个组成部分。分拣决策基于传感器采集的数据，并通过执行器来实现。不同的过程参数根据物料流特性、系统尺寸和所需分拣精度进行设置。然而，由于需求和物料组成的变化，持续的验证和重新调整是必要的。本文探讨了一种优化、循环监控和调整基于传感器的分拣系统工艺参数的方法。", "innovation": "提出了一种使用贝叶斯优化的方法来优化基于传感器的分拣系统的工艺参数。基于高斯过程回归模型作为替代模型，该方法在包含不确定性的条件下以最小化实验数量的方式实现对系统行为的特定要求。此外，在模型计算中考虑了分拣准确度的不确定性。", "conclusion": "该方法通过使用高斯过程替代模型和贝叶斯优化技术，实现了基于传感器的分拣系统的优化、循环监控和调整。通过三种示例工艺参数进行的评估表明，该方法既考虑了实验数量的问题，也同时实现了对物料输出流所需精度的要求。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10998", "html_url": "https://arxiv.org/abs/2507.10998", "title": "针对表数据的嵌入连续同流攻击", "title_en": "Crafting Imperceptible On-Manifold Adversarial Attacks for Tabular Data", "authors": "Zhipeng He,Alexander Stevens,Chun Ouyang,Johannes De Smedt,Alistair Barros,Catarina Moreira", "background": "表数据由于混合了分类和数值特征，具有异构性，因此针对表数据的对抗攻击具有独特挑战。传统的像素扰动在图像中容易保持视觉相似性，但在表数据中无法找到直观的相似性度量，使得定义不可感知的变化十分困难。此外，传统的基于梯度的方法往往关注$\boldsymbol{l_p}$范数约束，这会导致生成的对抗样本与原始数据分布存在较大偏离。这些缺点使得需要新的方法来解决上述问题。", "innovation": "本文提出了一种利用混合输入变分自编码器（VAE）的潜在空间扰动框架，以生成统计上一致的对抗样本。该VAE将分类嵌入和数值特征统一到一个潜在流形中，使得扰动可以保持统计一致性。同时引入了“内部分布成功率”(IDSR)来联合评估攻击效果和分布对齐。实验结果表明，本文方法在六个公开的数据集和三种模型架构上表现出较低的异常值比率和更一致的性能，相对于传统的输入空间攻击和其他适应于图像领域的基于VAE的方法，具有显著较低的异常值比率和较高的IDSR。", "conclusion": "本文全面分析了超参数敏感性、稀疏性控制和生成架构，揭示了基于VAE的攻击方法的有效性强烈依赖于重构质量以及训练数据的充分性。在满足这些条件的情况下，所提出的方法相较于输入空间方法在实用性与稳定性上具有显著优势。研究进一步强调了在表数据中生成现实且健壯的对抗样本需要在流形上保留扰动的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.01257", "html_url": "https://arxiv.org/abs/2509.01257", "title": "无线边缘网络中任务卸载的多代理强化学习", "title_en": "Multi-Agent Reinforcement Learning for Task Offloading in Wireless Edge Networks", "authors": "Andrea Fox,Francesco De Pellegrini,Eitan Altman", "background": "在边缘计算系统中，自主代理需要在有限的可观察性和通信限制下进行快速的本地决策，同时竞争共享资源。现有的多智能体强化学习（MARL）方法通常依赖于集中的评论者或频繁的通信，但在这些限制条件下往往会失效。", "innovation": "提出了一个去中心化的框架，每个代理解决一个约束马尔可夫决策过程（CMDP），并通过共享约束向量进行隐式的协调。针对特定案例（例如，卸载），约束防止共享服务器资源过载。这些协调约束很少更新且作为轻量级的协调机制运行。它们使代理能够与全球资源使用目标保持一致，但需要很少的直接通信量。使用安全强化学习，代理学习符合局部和全局目标的策略。", "conclusion": "在温和假设下建立了理论保证，并通过实验验证了该方法，表明在大型设置中优于集中式和独立的方法。\n"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.02753", "html_url": "https://arxiv.org/abs/2508.02753", "title": "DMSC: 动态多尺度协调框架用于时间序列预测", "title_en": "DMSC: Dynamic Multi-Scale Coordination Framework for Time Series Forecasting", "authors": "Haonan Yang,Jianchao Tang,Zhuo Li,Long Lan", "background": "时间序列预测（TSF）面临着在不同尺度下建模复杂时间依赖性的持久挑战。尽管最近的方法利用了不同的分解操作和基于CNN、MLP或Transformer的新型架构取得了进展，但现有方法仍然难以应对固定的分解策略、依赖性建模的碎片化以及融合机制的灵活性不足的问题，这限制了它们对复杂时间依赖性的建模能力。", "innovation": "我们提出了一种新的动态多尺度协调框架（DMSC），包含多尺度片段分解模块（EMPD）、三重交互模块（TIB）和自适应尺度路由混合专家模块（ASR-MoE）。具体来说，EMPD设计为内置组件，能够根据输入自动调整片段大小，动态将序列分割成层级片段；TIB在每个层的不同分解表示中联合建模片段内、片段间及其跨变量依赖性；EMPD和TIB共同构建了一个具有多层逐步级联架构，早期层次粗糙表示通过门控路径自适应地指导后续层次的细粒度特征提取。ASR-MoE通过利用具有时间感知加权的特殊全局和局部专家动态融合多尺度预测。在十三个真实世界的基准测试中，DMSC展现出了超越现有技术的性能和更高的计算效率。", "conclusion": "DMSC在各个真实世界的基准测试中表现出了持续的最先进的性能和更高的计算效率，证明了其在时间序列预测任务中的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10053", "html_url": "https://arxiv.org/abs/2508.10053", "title": "xRFM：适用于表格数据的高性能、可扩展且具可解释性的特征学习模型", "title_en": "xRFM: Accurate, scalable, and interpretable feature learning models for tabular data", "authors": "Daniel Beaglehole,David Holzmüller,Adityanarayanan Radhakrishnan,Mikhail Belkin", "background": "表格数据是现代技术和科学的基础，其中包含连续和分类变量，并组织成矩阵形式。尽管其它领域的AI取得了爆炸性进展，但传统的预测任务的最好实践仍然基于梯度提升决策树（GBDT）的变化。最近，已经有新的方法基于神经网络和特征学习方法用于处理表格数据。", "innovation": "本文提出了xRFM算法，结合了特征学习核机与树结构，能够适应数据的局部结构，同时能处理几乎无限的训练数据量。实验表明，xRFM在100个回归数据集上表现最佳，与200个分类数据集中的其他方法相比（包括最近的表格基础模型TabPFNv2和GBDTs），它具有竞争力且在某些情况下表现更优，且xRFM还通过平均梯度外积提供了天然的可解释性。", "conclusion": "xRFM在性能上超越了传统的GBDT模型，在扩展性和可解释性方面也具有优势。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.02844", "html_url": "https://arxiv.org/abs/2509.02844", "title": "变点情况下时间序列预测的置信预测", "title_en": "Conformal Prediction for Time-series Forecasting with Change Points", "authors": "Sophia Sun,Rose Yu", "background": "现有的置信预测方法已被探索作为提供时间序列不确定性量化的通用且高效的方法。然而，当前的方法难以处理具有变点（数据生成过程中的突然变化）的时间序列数据。", "innovation": "本文提出了一种名为CPTC（Conformal Prediction for Time-series with Change points）的新算法，通过结合预测潜在状态的模型和在线置信预测来建模非平稳时间序列中的不确定性。证明了CPTC在最少假设下对于时间序列设置的有效性和改进的适应性，并在6个合成和真实世界的数据集上展示了与最先进的基线相比的提升的有效性和适应性。", "conclusion": "CPTC方法的有效性和适应性得到了证明，在非平稳时间序列设置中表现优于现有方法。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.06213", "html_url": "https://arxiv.org/abs/2509.06213", "title": "向人工智能计量学迈进：隐藏规则环境与强化学习", "title_en": "Toward a Metrology for Artificial Intelligence: Hidden-Rule Environments and Reinforcement Learning", "authors": "Christo Mathew,Wentian Wang,Jacob Feldman,Lazaros K. Gallos,Paul B. Kantor,Vladimir Menkov,Hao Wang", "background": "本文探讨了在Game Of Hidden Rules (GOHR) 环境中应用强化学习的问题，该环境是一种复杂的谜题，其中智能体需要根据部分观察信息推理并执行隐藏的规则，以便在6×6的棋盘上通过放置棋子来解决问题。研究者探索了两种状态表示策略：以特征为中心（FC）和以对象为中心（OC），并使用基于Transformer的优越行动者-评论家（A2C）算法进行训练。实验在不同类型的基础上设置，并分析了转移效应以及不同表示对学习效率的影响。", "innovation": "本文的研究创新点在于提出了GOHR环境，这是一种复杂的隐藏规则谜题；探索了两种不同的状态表示策略（FC和OC）；并使用Transformer-based A2C算法进行训练，同时考察了在部分观察信息下的推理与学习问题。", "conclusion": "通过在多个基于规则和基于试验列表的实验设置中评估模型，本文研究了在隐藏规则环境下的转移效应，进一步分析了不同表示方式对学习效率的影响。结果显示，不同的状态表示策略对智能体的学习过程产生了显著影响。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.03738", "html_url": "https://arxiv.org/abs/2509.03738", "title": "稀疏自编码神经算子：函数空间中的模型恢复", "title_en": "Sparse Autoencoder Neural Operators: Model Recovery in Function Spaces", "authors": "Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar", "background": "尽管Platonic Representation Hypothesis认为神经网络在不同架构中趋于形成相似的表示，但在科学计算中不断增长的重要性背景下，神经算子的表示性质仍然缺乏深入探索。论文将统一神经模型表示的问题视为稀疏模型恢复，并引入一个框架扩展稀疏自动编码器（SAEs）到提升空间和无限维度函数空间，以实现大型神经算子（NO）的机制可解释性。", "innovation": "提出了一个框架，将稀疏自动编码器扩展到提升空间和无限维度函数空间，以实现大神经算子的机制可解释性。比较了稀疏自动编码器（SAEs）、提升型稀疏自动编码器（lifted-SAE）和神经算子的推理和训练动态。突显了提升和算子模块引入的有益归纳偏见，其中包括更快的恢复速度、更好的平滑概念补偿和在不同分辨率下的稳健推理，这些特性仅属于神经算子。", "conclusion": "稀疏自编码神经算子在神经算子的表示性质探索方面具有显著优势，并通过提升空间和无限维度函数空间扩展稀疏自动编码器，增强了其在表示学习和模型恢复中的应用效果。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.06863", "html_url": "https://arxiv.org/abs/2509.06863", "title": "floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL", "title_en": "floq: Training Critics via Flow-Matching for Scaling Compute in Value-Based RL", "authors": "Bhavya Agrawalla,Michal Nauman,Khush Agrawal,Aviral Kumar", "background": "现代大规模机器学习技术的一个重要特征是使用能够为中间计算提供密集监督的训练目标，比如语言模型中的教师强迫下一个词或扩散模型中的逐步去噪。这使模型能够以可推广的方式学习复杂的函数。受此启发，论文研究了迭代计算方法在强化学习（RL）中的时间差分（TD）方法中的应用。传统的TD方法通常以单一的形式表示价值函数，而不进行迭代计算。", "innovation": "提出了floq（流匹配Q函数），一种新的方法，它用速度场参数化Q函数，并使用来自生成建模领域的流匹配技巧进行训练。通过使用TD学习目标进行训练，floq在多步数值积分产生的目标速度场值上进行梯度引导。关键的是，floq允许通过适当地设置积分步骤来更精细地控制和扩展Q函数的能力，这比传统的单一架构提供了更好的可扩展性。该方法在一系列具有挑战性的离线RL基准测试和在线微调任务中表现出色，性能提升了近1.8倍。", "conclusion": "floq相比标准的TD学习架构在扩展计算能力上有显著优势，显示出迭代计算在价值学习中的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02279", "html_url": "https://arxiv.org/abs/2510.02279", "title": "解决自然语言生成中不确定性估计方法评估的问题", "title_en": "Addressing Pitfalls in the Evaluation of Uncertainty Estimation Methods for Natural Language Generation", "authors": "Mykyta Ielanskyi,Kajetan Schweighofer,Lukas Aichberger,Sepp Hochreiter", "background": "大语言模型中的幻觉问题严重影响了模型的可靠性。近年来，研究者识别出一类特殊的幻觉称为虚构，它们是由于语言生成过程中的预测不确定性造成的。当前检测虚构的方法主要是通过估算预测不确定性来实现，这些方法通常通过不确定性估计与生成文本正确性的相关性来进行评估，质询-回答（QA）数据集是标准的基准测试。然而，常用的近似正确性函数之间存在显著的不一致，导致不确定性估计方法的排名不稳定，从而影响评估结果的可靠性。", "innovation": "本文提出了几种替代风险指标来改进不确定性估计方法在自然语言生成中的风险相关实验的稳健性。在QA任务中，通过使用多个LLM（语言模型）评估变体来减少评估偏差。此外还探讨了结构任务以及离分布和扰动检测任务，这些任务能够提供稳健且可控制的风险指标。最后，提出使用不确定性估计方法的Elo排名作为综合评估设置的客观总结。", "conclusion": "研究表明，通过优化评估方法和使用多种风险指标，可以更好地评估不确定性估计方法在自然语言生成中的表现。并提出通过使用Elo排名来客观总结不确定性估计方法在各种评估设置下的表现。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04008", "html_url": "https://arxiv.org/abs/2510.04008", "title": "用尖锐化角度相似性替换softmax相似性：大规模上下文注意力的理论与实践", "title_en": "Replacing Softmax Similarity with a Sharpened Angular Similarity: Theory and Practice of Scaling To Billion-Context Attention", "authors": "Sahil Joshi,Agniva Chowdhury,Amar Kanakamedala,Ekam Singh,Evan Tu,Anshumali Shrivastava", "background": "softmax注意力机制具有二次时间复杂度，这在长上下文运行时变得难以处理，即使使用高度优化的GPU内核也是如此。例如，FlashAttention（一种精确的GPU优化实现）在NVIDIA GH200 (96 GB)上无法完成一次多头注意力层的正向和反向传递，当上下文超过约400万个标记时。", "innovation": "提出了RACE注意力机制，这是一种基于核的替代softmax注意力的机制，其复杂度与序列长度和嵌入维度呈线性关系。RACE注意力通过随机化投影和软局部敏感哈希（LSH）近似注意力输出，用角度相似（余弦）替换指数核。在语言建模、掩码语言建模和文本分类中，RACE注意力实现了与强大基线相当的准确性，同时减少了运行时间和内存使用。", "conclusion": "RACE注意力机制在NVIDIA GH200 GPU上处理多达1200万个标记，在Intel Xeon Gold 5220R CPU上处理多达7500万个标记，远远超过了当前最先进技术的实用限制。因此，RACE注意力机制提供了一种在现代硬件上实现异常长上下文窗口的实用、理论上合理的机制。我们希望它能在实践中被采纳。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.16300", "html_url": "https://arxiv.org/abs/2509.16300", "title": "ROOT: 重新思考基于离线数据的优化问题作为概率桥梁的分布转换", "title_en": "ROOT: Rethinking Offline Optimization as Distributional Translation via Probabilistic Bridge", "authors": "Manh Cuong Dao, TheHung Tran,Phi Le Nguyen,Thao Nguyen Truong,Trong Nghia Hoang", "background": "该研究关注利用静态输入输出对来优化黑盒函数的优化任务。传统方法通常通过学习和优化一个代数函数来实现，受限于离线数据的有限性。另一种方法是将此任务视为逆向建模任务，目标是从期望性能映射到潜在的输入候选者。然而，这两种方法都受限于离线数据的限制，无法充分利用潜在的有效输入。因此，提出了将离线优化问题重新定义为分布转换问题的新视角，通过学习一个概率桥梁，将低价值输入的隐含分布转化为高价值输入的分布。这种概率桥梁能够通过合成函数的学习来实现，这些合成函数模仿目标函数的不同参数化版本的后验均值，从而缓解数据瓶颈问题。", "innovation": "提出了将离线优化问题重新定义为概率桥梁的分布转换问题的新视角。具体而言，这是一种通过学习一个概率桥梁（将低价值输入的隐含分布转换为高价值输入的分布）的方法。该方法使用了模仿目标函数的合成函数，这些合成函数是基于离线数据的不同参数化版本的高斯过程的后验均值，从而提高了对有效输入的利用率，解决了数据瓶颈问题。此外，该方法在广泛的方法基准测试中展示了显著的改进，并确立了新的最先进的性能。", "conclusion": "该研究提出的方法在广泛的当前最先进的方法基准测试中表现出显著改进，并已经建立了一个全新的最先进的性能水平。所提出的方法不仅提供了一种新的优化视角，还通过合成函数的学习解决了数据限制的问题，为优化领域带来了新的进展。相关代码已公开发布。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08396", "html_url": "https://arxiv.org/abs/2510.08396", "title": "FlyLoRA：通过隐式按秩分组专家混合提高任务解耦和参数效率", "title_en": "FlyLoRA: Boosting Task Decoupling and Parameter Efficiency via Implicit Rank-Wise Mixture-of-Experts", "authors": "Heming Zou,Yunliang Zang,Wutong Xu,Yao Zhu,Xiangyang Ji", "background": "Low-Rank Adaptation (LoRA) 是一种广泛用于基础模型参数高效再训练的方法，但它存在参数干扰问题，导致性能不佳。Mixture-of-Experts (MoE)-基于的 LoRA 变体在单任务指令微调时能够缓解任务内相关性，但引入了额外的路由参数，且在多任务模型合并中无效，因为这里存在任务间干扰。", "innovation": "FlyLoRA 提出了一种隐含的基于 MoE 的 LoRA 变体，引入了按秩专家激活的上投影矩阵和一个隐式路由器，该路由器统一了专家路由和下投影，并且固定稀疏随机投影矩阵取代了传统的密集可训练版本。这种设计通过消除显式路由器的需求解决了任务内相关性和计算效率之间的权衡问题，并且由于随机矩阵的正交性固有地缓解了任务间干扰。", "conclusion": "在四个领域——一般知识理解、科学问答、数学推理和代码生成——的广泛实验中，FlyLoRA 较现有方法展示了持续的性能改进。FlyLoRA 还突显了如何通过生物结构激发人工智能技术的创新。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06377", "html_url": "https://arxiv.org/abs/2510.06377", "title": "关系转换器：通往关系数据的零样本基础模型", "title_en": "Relational Transformer: Toward Zero-Shot Foundation Models for Relational Data", "authors": "Rishabh Ranjan,Valter Hudovernik,Mark Znidar,Charilaos Kanatsoulis,Roshan Upendra,Mahmoud Mohammadi,Joe Meyer,Tom Palczewski,Carlos Guestrin,Jure Leskovec", "background": "预训练的Transformer模型能够通过零样本提示很快地适应新的序列建模任务，但关系领域仍然缺乏能够在不同数据集和任务间迁移的架构。核心挑战在于关系数据的多样性，包括不同的异构模式、图结构和函数依赖。", "innovation": "本文提出了关系转换器（RT）架构，可以在多样性的关系数据库上进行预训练，并直接应用于未见过的数据集和任务，无需特定任务或数据集的精调，或检索上下文示例。RT架构包括：（i）使用表/列元数据进行单元格标记化，（ii）通过掩码标记预测进行预训练，（iii）使用一种新的关系注意力机制，跨越列、行和主外键链接。该模型在涵盖客户流失和销售预测等任务的RelBench数据集上进行预训练，展示了出色的零样本性能，单次前向传播的22M参数模型，二分类任务的平均AUROC为93%，而27B参数的大型预训练语言模型则为84%。细调结果达到了最先进的效果，具有高的样本效率。", "conclusion": "我们的实验表明，RT的零样本转移能够利用任务-表上下文、关系注意力模式和模式语义。总体而言，RT提供了一条实用的道路，用于构建关系数据的基础模型。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08141", "html_url": "https://arxiv.org/abs/2510.08141", "title": "任意熵策略优化：熵在强化调优中可控", "title_en": "Arbitrary Entropy Policy Optimization: Entropy Is Controllable in Reinforcement Fine-tuning", "authors": "Chen Wang,Zhaochun Li,Jionghao Bai,Yuzhi Zhang,Shisheng Cui,Zhou Zhao,Yue Wang", "background": "增强型精调（RFT）对于提升大规模语言模型（LLM）的推理能力至关重要，但广泛采用的Group Relative Policy Optimization（GRPO）存在熵耗竭的问题，即熵单调下降、探索性消失和政策过早收敛。现有方法虽对这一问题有所缓解，但仍未能完全解决，导致熵、探索性和性能之间的关系不清晰。", "innovation": "本研究提出了任意熵策略优化（AEPO），通过用温度调整分布的REINFORCE策略梯度替代熵奖金来消除熵耗竭，并通过温度调节稳定熵，从而实现了熵的精确控制。AEPO整合了三项关键设计：策略梯度作为一种正则化方法、分布作为一种正则化方法和REINFORCE作为一种正则化方法，使熵控制更加精准而不破坏优化过程。实验表明，AEPO能够（1）在任意目标水平上稳定熵，有效消除GRPO中的熵耗竭；（2）揭示了一种非单调关系，即性能先提高后降低，这阐明了熵、探索和推理之间的联系；（3）超越了熵，提供了一个更广义的精调框架，其中更优的目标分布可以作为REINFORCE正则器。", "conclusion": "研究表明，AEPO通过温度调节成功解决了熵耗竭问题，揭示了熵、探索性和性能之间的非单调关系，并通过优化报告了更广泛的精调范式，其中更优的目标分布能够起到REINFORCE正则器的作用。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.09114", "html_url": "https://arxiv.org/abs/2510.09114", "title": "关于隐私保护的公平性：测量和缓解差异隐私机器学习中各组隐私风险的不平等", "title_en": "On the Fairness of Privacy Protection: Measuring and Mitigating the Disparity of Group Privacy Risks for Differentially Private Machine Learning", "authors": "Zhi Yang,Changwu Huang,Ke Tang,Xin Yao", "background": "虽然在传统公平性意识机器学习（ML）和差异隐私机器学习（DPML）方面取得了显著进展，但不同群体之间的隐私保护公平性仍然未被充分探索。现有研究提出了评估群体隐私风险的方法，但这些方法基于数据记录的平均隐私风险，可能导致低估群体隐私风险，进而可能导致低估群体隐私风险的差异。此外，当前评估数据记录最坏情况隐私风险的方法耗时较长，限制了其实际应用。", "innovation": "文章提出了一种新颖的成员推断博弈方法，该方法可以高效地审计数据记录的近似最坏情况隐私风险。此外，为了在DPML中促进隐私保护公平性，文章通过修改标准的DP-SGD算法，采用了基于差异隐私审计中“探针”设计的自适应组别特定梯度裁剪策略，从而有效减少了群体隐私风险的差异，提高了DPML中隐私保护的公平性。实验结果表明本文方法能提供更严格的群体隐私风险测量，确保给出了对群体隐私风险差异的可靠评估。", "conclusion": "通过提出一种新型的成员推断博弈方法，有效减少了DPML中不同群体之间的隐私风险差异，从而提高了隐私保护的公平性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.14449", "html_url": "https://arxiv.org/abs/2510.14449", "title": "多类葡萄酒分类中的特征选择和正则化：基于梯度下降优化和L1稀疏约束的一对多逻辑回归实证研究", "title_en": "Feature Selection and Regularization in Multi-Class Classification: An Empirical Study of One-vs-Rest Logistic Regression with Gradient Descent Optimization and L1 Sparsity Constraints", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel", "background": "多类葡萄酒分类面临着模型准确性、特征维度和可解释性之间的根本权衡，这对于生产部署在分析化学中的应用是关键因素。本研究集中在UCI Wine数据集上进行详细实证分析，该数据集包含178个样本、3个品种和13个化学特征，旨在探讨梯度下降实现方法与scikit-learn优化求解器之间的比较，以及L1正则化对特征稀疏性的量化影响。", "innovation": "研究通过实证比较手动实现的梯度下降方法与scikit-learn的优化求解器，以及L1正则化对特征稀疏性的影响。发现手动实现的梯度下降达到92.59%的平均测试准确性，而在scikit-learn中实现则提高了24倍的训练速度并达到98.15%的准确性。L1正则化在显著减少特征数量的同时，仅损失4.63%的准确性，展示了良好的可解释性与性能间的权衡。此外，提出了一个5个特征的最优子集，可以在减少约80美元成本和56%时间的同时保持92-94%的准确性。", "conclusion": "研究通过统计验证确认了模型的泛化能力，并保证了实时质量控制所需的亚毫秒级预测延迟。研究成果为在资源受限环境中权衡全面的化学分析和目标特征测量提供了可操作的指导。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12405", "html_url": "https://arxiv.org/abs/2510.12405", "title": "连续性独特性和新颖性度量标准用于无机晶体生成建模", "title_en": "Continuous Uniqueness and Novelty Metrics for Generative Modeling of Inorganic Crystals", "authors": "Masahiro Negishi,Hyunsoo Park,Kinga O. Mastej,Aron Walsh", "background": "为应对气候变化等关键科学挑战，正在开发越来越复杂的生成型人工智能模型，以高效地探索可能的功能材料的大化学空间。这种模型可以快速地配对新的化学成分和晶体结构。现有模型通常通过独特性和新颖性的度量来评估，这些度量取决于所选择的晶体距离函数。然而，最常用的距离函数存在四个局限性：无法量化化合物之间的相似度、不能区分成分差异和结构差异、缺乏对原子坐标偏移的Lipschitz连续性、和生成样本对换下产生的独特性度量不具有不变性。现有的工作提出了使用两个连续的距离函数来评估独特性和新颖性，理论上能够克服这些局限性。通过实验表明，这些距离可以揭露传统距离函数中未曾发现的洞察，从而提供一个更可靠的评估和比较生成模型的基础，特别是在用于无机晶体结构生成时。", "innovation": "提出使用两个连续距离函数来评估生成型模型的独特性和新颖性，理论上克服了传统距离函数的四个局限性：无法量化化合物之间的相似度、不能区分成分差异和结构差异、缺乏对原子坐标偏移的Lipschitz连续性、和生成样本对换下产生的独特性度量不具有不变性。实验结果显示，这些连续距离函数能揭示传统距离函数所遗漏的洞察，为评估和比较无机晶体结构生成模型提供了更可靠的基础。", "conclusion": "通过使用理论和实验相结合的方法，提出了一种新的评估生成型模型独特性和新颖性的方法，解决了传统方法的几个关键局限性，并通过实验验证了新方法的有效性和可靠性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15382", "html_url": "https://arxiv.org/abs/2510.15382", "title": "向鲁棒型零样本强化学习迈进", "title_en": "Towards Robust Zero-Shot Reinforcement Learning", "authors": "Kexin Zheng,Lauriane Teyssier,Yinan Zheng,Yu Luo,Xianyuan Zhan", "background": "零样本强化学习（RL）的最新进展为学习适应任意新任务的预训练通用策略打开了新的途径。尽管前向-后向表示（FB）及其相关方法在零样本RL中具有潜力，但实验证明它们在建模表达性和应对分布外（OOD）动作时表现欠佳，导致了偏见表示和次优性能。", "innovation": "作者提出了行为正则化增强零样本RL（BREEZE），这是一种基于FB的升级框架，同时增强了学习稳定性、策略提取能力和表示学习质量。BREEZE通过行为正则化使零样本RL策略学习转变为稳定的学习范式，并利用任务条件扩散模型提取策略，这能生成高质量和多元化的动作分布。此外，BREEZE采用表达性注意力架构进行表示建模，以捕捉环境动态之间的复杂关系。", "conclusion": "通过在ExORL和D4RL Kitchen上的广泛实验，BREEZE在零样本RL中展示了最佳或接近最佳的性能，同时表现出优于之前方法的鲁棒性。详细的实现可从这个链接获取：this https URL."}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.13087", "html_url": "https://arxiv.org/abs/2510.13087", "title": "DeepCausalMMM：基于因果推理的深度学习营销组合模型框架", "title_en": "DeepCausalMMM: A Deep Learning Framework for Marketing Mix Modeling with Causal Inference", "authors": "Aditya Puttaparthi Tirumala", "background": "传统营销组合模型多依赖线性回归或贝叶斯层次模型来估算营销活动对销售、收入或顾客访问等业务成果的影响，但这些方法通常假定各营销渠道之间相互独立，难以捕捉复杂的时间动态效应和非线性饱和效应。", "innovation": "_deepCausalMMM 是一个结合了深度学习、因果推理和先进营销科学的 Python 包。它通过使用门控循环单元（GRUs）自动学习时间模式，如广告余波效应和滞后效应，同时通过有向无环图（DAG）学习方法来学习营销渠道之间的统计依赖性和潜在因果结构。此外，它还实现了基于希尔方程的饱和曲线，用于建模递减的回报并优化预算分配。", "conclusion": "该模型的特点在于：1) 数据驱动的设计，其中超参数和转换（例如广告余波衰减和饱和曲线）可以从数据中学习或估计，而不是需要固定的启发式规则或手动指定；2) 支持多地区建模，既有共享参数又有地区特定参数；3) 强大的统计方法，包括 Huber 损失和先进的正则化技术；4) 全面的响应曲线分析，用于理解渠道饱和效应。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16171", "html_url": "https://arxiv.org/abs/2510.16171", "title": "连接对称性和鲁棒性：正交性在增强对抗鲁棒性中的作用", "title_en": "Bridging Symmetry and Robustness: On the Role of Equivariance in Enhancing Adversarial Robustness", "authors": "Longwei Wang,Ifrat Ikhtear Uddin,KC Santosh,Chaowei Zhang,Xiao Qin,Yang Zhou", "background": " adversarial examples通过利用深度神经网络对微小输入扰动的高度敏感性揭示了其关键漏洞。尽管对抗训练是主要的防御策略，但通常会带来显著的计算成本并可能损害干净数据的准确性。", "innovation": "研究了一种基于架构的方法，通过将旋转和尺度正交卷积层嵌入到标准卷积神经网络（CNNs）中，来提高对抗鲁棒性。提出了两种基于对称性的架构：并行设计和级联设计。理论证明模型能够减少假设空间的复杂性、正则化梯度并提供更紧的鲁棒性下限。", "conclusion": "我们的模型在CIFAR-10、CIFAR-100和CIFAR-10C数据集上的一致地提高了对抗鲁棒性和泛化能力，不依赖于对抗训练。这些发现突显了对称性强制架构作为数据增强防御的高效和原则替代方案的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16807", "html_url": "https://arxiv.org/abs/2510.16807", "title": "通过第一层Value头部的跳连提高模型表示并减少KV缓存", "title_en": "Improving Model Representation and Reducing KV Cache via Skip Connections with First Value Heads", "authors": "Zhoutong Wu,Yuan Zhang,Yiming Dong,Chenheng Zhang,Cong Fang,Kun Yuan,Zhouchen Lin", "background": "变压器模型在各种语言任务中取得了突破，得益于它们强大的学习丰富上下文表示的能力。然而，为了提升表示能力，通常需要大量的内存和计算成本，如自回归解码中使用的Key-Value（KV）缓存。现有的一些工作主要通过改进表达能力而保持KV成本不变，或者通过减少内存牺牲了表示能力。", "innovation": "本文提出了一种新的变压器变体SkipV1Former，它使用第一层Value头部的跳连来增强模型表示能力同时减少KV缓存。从第二层区块开始，每一层都会重用前一层一半的Value头部，而另一半则像平常那样计算，从而将Value投影和V缓存减少近一半。理论分析表明，将未压缩的第一层Values路由到更深层可以恢复压缩所丢失的信息，并加速模型的元优化过程——这是变压器在自回归任务中的关键模式。实验结果表明，不同模型规模下，SkipV1Former在保持性能的同时可以将KV缓存减少约25%，并且结合Group-Query Attention和Multi-Latent Attention还可以进一步节省KV缓存。", "conclusion": "通过仅使用10-15%的额外计算资源，现有的MHA Transformer checkpoints可以升级到SkipV1Former。此外，当与YOCO结合使用时，它能够将近一半的KV缓存缩小，同时仍然提升性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17385", "html_url": "https://arxiv.org/abs/2510.17385", "title": "TabR1：利用PRPO驯化表格推理大语言模型", "title_en": "TabR1: Taming GRPO for tabular reasoning LLMs", "authors": "Pengxiang Cai,Zihao Gao,Jintai Chen", "background": "传统的表格预测主要依赖于梯度增强决策树和特殊设计的深度学习模型，虽然它们在特定任务上表现出色，但解析结果缺乏透明性且难以跨表格转移学习。大语言模型（LLMs）有望实现跨任务适应性并提供透明的推理路径，但它们在表格数据上的潜力尚未完全开发。现有的方法在预测表格数据时，主要依赖于增强学习方法，如Permutation Group Policy Optimization (GRPO)，但在实现多步推理和结构先验方面仍存在局限。", "innovation": "本文提出了一种基于大语言模型的新型表格预测方法——TabR1，它利用多步推理和Permutation Relative Policy Optimization (PRPO)来编码列排列不变性作为结构先验。PRPO通过为每个样本构建多个标签保持的排列，并在排列内部和跨排列估算优势，将稀疏奖励转化为密集的学习信号，从而提高了泛化能力。这种方法在有限监督下激活了大语言模型的表格推理能力，提升了其多示例和零示例表现及解释性。", "conclusion": "广泛的实验表明，在全监督微调下，TabR1达到了与强大基线相当的性能。在零示例设置中，TabR1 接近于32示例条件下的强大基线性能。此外，TabR1在各种任务上优于其他大模型，取得了高达53.17%的提升。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18934", "html_url": "https://arxiv.org/abs/2510.18934", "title": "许多深度学习的泛化度量都是脆弱的", "title_en": "Position: Many generalization measures for deep learning are fragile", "authors": "Shuofeng Zhang,Ard Louis", "background": "当前，已经应用了多种泛化度量方法来评估深度神经网络（DNNs）的性能。尽管这些度量在实践中被广泛应用，但在理论层面取得紧致的边界仍然具有挑战性。然而，这些度量往往被假设可以反映泛化的定性趋势。然而，本文作者认为许多在训练结束后计算的泛化度量（即基于训练好的网络的度量）是非常脆弱的：即使是微小的训练调整，这些调整对DNN的基础结构几乎没有影响，也可能显著改变度量值、趋势或缩放行为。", "innovation": "本文提出并实证了多种泛化度量（如路径范数、谱范数、弗罗贝尼乌斯范数、平坦度代理和确定性的PAC-贝叶斯近似）的脆弱性。除此之外，作者还指出，开发新的泛化度量时，开发者应该明确审计它们的脆弱性。", "conclusion": "本文通过证明路径范数、谱范数、弗罗贝尼乌斯范数、平坦度代理、确定性的PAC-贝叶斯近似等多种边界都是脆弱的，进一步论证了开发新泛化度量时的一个重要观点：泛化度量应针对其脆弱性进行审计。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19266", "html_url": "https://arxiv.org/abs/2510.19266", "title": "通过注意桥梁实现任何Transformer到Mamba的高效数据蒸馏", "title_en": "Data Efficient Any Transformer-to-Mamba Distillation via Attention Bridge", "authors": "Penghao Wang,Yuhao Zhou,Mengxuan Wu,Panpan Zhang,Zhangyang Wang,Kai Wang", "background": "状态空间模型（SSMs）已成为序列建模的高效替代方案，通过递归结构提供了更好的扩展性，但其训练成本高昂，生态系统远不如Transformer成熟。此外，SSMs和Transformer之间结构上的异质性使得从预训练注意力模型高效转移知识变得困难。", "innovation": "提出了一种名为Cross-architecture distillation via Attention Bridge (CAB)的新颖数据高效蒸馏框架，该框架能够通过轻量级桥梁和灵活的逐层对齐，将Transformer教师的知识高效转移至状态空间学生模型，从而提高效率和可转移性。引入了灵活的逐层对齐策略以适应教师和学生架构之间的差异。", "conclusion": "在视觉和语言领域的广泛实验表明，该方法可以在有限训练数据下一致地提高状态空间模型的性能，超越了标准和跨架构蒸馏方法。研究结果表明，基于注意力的知识可以高效转移到递归模型，从而快速利用Transformer的专业知识来促进SSM社区的发展。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19338", "html_url": "https://arxiv.org/abs/2510.19338", "title": "每一项注意都重要：一种高效的长上下文推理混合架构", "title_en": "Every Attention Matters: An Efficient Hybrid Architecture for Long-Context Reasoning", "authors": "Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou", "background": "在长上下文推理场景中，传统的注意力机制虽然强大，但也面临着I/O和计算开销大的问题。为此，研究人员试图通过创新的混合架构来优化模型结构，以实现更高的效率。", "innovation": "该系列模型引入了一种新的混合架构，结合了线性注意力和softmax注意力，有效减少了长上下文推理中的I/O和计算开销。与密集模型相比，该系列模型将推理成本降低了10倍以上。此外，通过优化不同注意力机制的比例，得到了当前最优的模型结构。借助自主研发的高性能FP8操作库linghe，训练效率提高了50%，在多个复杂推理基准测试中保持了SOTA性能。", "conclusion": "该系列模型通过优化混合架构和利用高性能操作库，在长上下文推理任务中展现出了高效的推理性能，同时在多个复杂推理基准测试中保持了最优表现。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19754", "html_url": "https://arxiv.org/abs/2510.19754", "title": "CONFEX: 基于稳健保证的不确定性感知反事实解释", "title_en": "CONFEX: Uncertainty-Aware Counterfactual Explanations with Conformal Guarantees", "authors": "Aman Bilkhoo,Mehran Hosseini,Milad Kazemi,Nicola Paoletti", "background": "反事实解释（CFX）提供了模型预测的可理解理由，有助于行动导向的修正并提升模型的可解释性。为了确保这些解释可靠，它们必须避开高度预测不确定性的区域，以避免误导性的解释或不适用的情况。现有方法往往忽视了不确定性的存在或缺乏将不确定性形式化嵌入的机制。", "innovation": "该研究提出了一种名为 CONFEX 的新方法，它通过 Conformal Prediction (CP) 和混合整数线性规划（MILP）来生成具有不确定性意识的反事实解释。CONFEX 通过开发一种新颖的局部化 CP 过程，并利用输入空间的基于树的子区间划分来获得高效的 MILP 编码实现。该方法确保了反事实解释在预测不确定性和优化方面的严格保证。", "conclusion": "通过与先进方法在多种基准和指标上的评估，CONFEX 方法展示了其基于不确定性感知的解释的稳健性和合理性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19507", "html_url": "https://arxiv.org/abs/2510.19507", "title": "Teaming LLMs to Detect and Mitigate Hallucinations", "title_en": "Teaming LLMs to Detect and Mitigate Hallucinations", "authors": "Demian Till,John Smeaton,Peter Haubrick,Gouse Saheb,Florian Graef,David Berman", "background": "近期的研究已经证明，通过一致性方法检测和减轻大型语言模型（LLM）的幻觉效果显著，这些方法涉及聚合单一LLM对给定提示所采样的多个响应。这些方法有助于克服由于训练数据不完美带来的局限性，包括偏见和信息的不足等，这些局限可能导致幻觉。", "innovation": "本文展示了一种将来自不同训练数据、训练方案和模型架构的多个LLM的回复结合的“联盟一致性”方法，这种方法可以在单一模型一致性方法的基础上获得显著的进一步提高。我们还评估了这种方法在15个LLM模型团队中的效果，并探讨了在这种方式下将不同LLM团队组合在一起的条件。此外，我们表明这些性能的提升往往伴随着推理成本的降低，弥补了单一模型一致性方法的一大缺点。", "conclusion": "这种方法不仅能够极大地提高幻觉的检测和缓解能力，还降低了推理成本，是多LLM整合使用的一个有效策略。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19705", "html_url": "https://arxiv.org/abs/2510.19705", "title": "通过层次推测解码实现快速推理", "title_en": "Fast Inference via Hierarchical Speculative Decoding", "authors": "Clara Mohri,Haim Kaplan,Tal Schuster,Yishay Mansour,Amir Globerson", "background": "Transformer语言模型以自回归的方式生成文本，这意味着推断延迟与生成的令牌数量成正比。推测性解码通过利用较小的草稿模型提出令牌，而较大的目标模型可以并行验证这些令牌，从而减少了延迟，同时不牺牲输出质量。然而，在实践中，可能存在一系列潜在的草稿模型，从更快但更不准确，到更慢但更可靠的。", "innovation": "引入了层次推测解码（HSD）算法，该算法通过将这些草稿模型堆叠成一个层次结构来优化推测性解码。在这一过程中，每个模型提出令牌，较大的模型依次验证它们。最终，目标模型会进行验证。我们为任何这样的层次结构推导出了延迟期望值的表达式，并表明选择最优的延迟层次结构可以在多项式时间内完成。实验结果证明，HSD可以提供最高达1.2倍的速度提升，进一步证明了我们的算法在减少生成延迟方面的实用性，超过了以前的技术方法。", "conclusion": "HSD算法通过将多个草稿模型组织成层次结构来减少推断延迟，为任何这样的层次结构推导了延迟期望值的表达式，并通过实验证明其显著的性能提升，展示了其实用性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.07715", "html_url": "https://arxiv.org/abs/2305.07715", "title": "残差网络中的最优信号传播场理论", "title_en": "Field theory for optimal signal propagation in ResNets", "authors": "Kirsten Fischer,David Dahmen,Moritz Helias", "background": "研究表明，残差网络在深度较大的情况下比前馈网络在训练上更具有优势，通过引入跳跃连接可以促进信号向更深的层传播。对于残差支路，先前的研究发现增加一个缩放参数可以进一步提高泛化性能，但这一改进的性能以及其在不同网络超参数下的普遍性尚未得到充分理解。", "innovation": "本文提出了一个系统性的有限尺寸场理论来研究残差网络中的信号传播及其对残差支路缩放的依赖性。该理论得到了响应函数的解析表达式，这一表达式可以衡量网络对输入的敏感性，并发现在深度网络中，实验中发现的缩放参数值处于最大敏感性的范围内。此外，还得到了一个对其他网络超参数（如权重方差）依赖性较弱的理想缩放参数的解析表达式，从而解释了其在不同超参数中的普遍性。", "conclusion": "总体而言，本文提供了一个研究有限大小下残差网络的理论框架。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.09567", "html_url": "https://arxiv.org/abs/2406.09567", "title": "因果处理预测模型", "title_en": "Causal Post-Processing of Predictive Models", "authors": "Carlos Fernández-Loría,Yanfang Hou,Foster Provost,Jennifer Hill", "background": "组织越来越多地依赖预测模型来确定谁应该被针对以实施干预，例如营销活动、客户保留计划或医疗治疗。然而，这些模型通常是预测结果（例如购买的可能性或流失率），而不是干预的实际影响。因此，它们产生的分数（预测值）往往不是资源配置的理想指南。可以使用随机试验来估计因果效应，但试验成本高、规模有限且仅适用于特定行动。", "innovation": "我们提出因果后处理(CPP)技术，利用有限的实验数据来改进预测模型的输出，使其更好地与因果决策相契合。CPP技术涵盖了以灵活性换取数据效率的方法，统一了现有方法并激发了新的方法。通过模拟和数字广告中的实证研究，我们展示了CPP如何改善干预决策，尤其是在预测模型捕捉到有用的但不完美的因果信号时。", "conclusion": "我们的研究结果表明，组织可以通过结合预测建模和实验证据来做出更有效且规模化的干预决策。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19755", "html_url": "https://arxiv.org/abs/2510.19755", "title": "扩散模型中的缓存方法研究：迈向高效的多模态生成", "title_en": "A Survey on Cache Methods in Diffusion Models: Toward Efficient Multi-Modal Generation", "authors": "Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang", "background": "扩散模型因其卓越的生成质量和可控性成为现代生成AI中的核心组成部分。然而，其固有的多步迭代和复杂的骨干网络导致了计算代价高昂和生成延迟的问题，成为实时应用的瓶颈。尽管现有的加速技术取得了一些进展，但仍面临适用范围有限、高培训成本或质量下降等问题。", "innovation": "扩散缓存（Diffusion Caching）首次提出，作为一种无需训练、架构无关且高效的推理范式。它通过识别和重用扩散过程中固有的计算冗余，实现了特征级别的跨步重用和跨层调度，从而在不修改模型参数的情况下减少计算量。此外，扩散缓存从静态重用发展到动态预测，提高了跨任务的灵活性，并能与其他加速技术如采样优化和模型蒸馏整合，为未来的多模态和交互应用提供了一个统一高效的推理框架。", "conclusion": "我们认为，这种范式将成为实时高效生成AI的关键推动者，给高效生成智能的理论和实践注入新的活力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2110.07583", "html_url": "https://arxiv.org/abs/2110.07583", "title": "通过几何凸性近最优样本复杂度的矩阵和张量正态模型", "title_en": "Near optimal sample complexity for matrix and tensor normal models via geodesic convexity", "authors": "Cole Franks,Rafael Oliveira,Akshay Ramachandran,Michael Walter", "background": "矩阵正态模型是用于建模矩阵变量数据的一类广泛使用的高斯矩阵变量分布，其协方差矩阵是两个低维要素的Kronecker乘积。张量正态模型则将该模型扩展到三个或更多因子的Kronecker乘积。该论文专注于研究这些模型中协方差矩阵的Kronecker因子的估计问题。", "innovation": "论文展示了最大似然估计（MLE）在Fisher-Rao和Thompson度量下几乎最优的非渐近样本复杂性和几乎紧致的误差率。其结果不依赖于因子的条件良好或稀疏，也不需要准确的初始猜测。此外，它证明了在相同样本复杂性的条件下，一种实际广泛使用的迭代程序——翻转算法，以高概率线性收敛。主要的技术洞察是，给定足够样本，负对数似然函数在由fisher信息度量诱导的定正矩阵几何中是强地得到凸的，这种凸性由某些随机量子通道的扩展所决定。", "conclusion": "论文表明，对于矩阵和张量正态模型，只要有足够的样本，MLE就能实现几乎最优的误差率和样本复杂性。翻转算法在这种情况下能以高概率收敛。论文的结果在样本复杂性和几何凸性的分析上达到了新的高度。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.05854", "html_url": "https://arxiv.org/abs/2408.05854", "title": "关于核适配性检验的稳健性", "title_en": "On the Robustness of Kernel Goodness-of-Fit Tests", "authors": "Xing Liu,François-Xavier Briol", "background": "适配性检验常常受到批评，因为它缺乏实际相关性：由于“所有模型都不正确”，随着样本量的增长，表示数据符合模型的零假设最终总是被拒绝。尽管如此，概率模型仍然被广泛使用，提出了一个更为关键的问题：模型对于手头的任务是否足够好。这个问题可以形骸化为鲁棒适配性检验问题，即数据是否源自模型的轻微扰动。现有的核适配性检验在常见的鲁棒性概念下并不鲁棒，包括定性和量化的鲁棒性。传统的倾斜核鲁棒化技术虽然在参数估计文献中有效，但在测试设置中并不能保证两种类型的鲁棒性。", "innovation": "本文提出了首个鲁棒的核适配性检验，通过使用核Stein分歧（KSD）球体来解决这个问题。这一框架涵盖了多个广泛使用的扰动模型，如Huber的污染模型和密度带模型。", "conclusion": "现有的核适配性检验在常见鲁棒性概念下不具备鲁棒性，本文通过引入核Stein分歧（KSD）球体的概念，提出了首个鲁棒的核适配性检验，该方法能够确保其在定性和量化鲁棒性方面的鲁棒性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.11666", "html_url": "https://arxiv.org/abs/2406.11666", "title": "ROTI-GCV: 广义交叉验证用于右旋不变数据", "title_en": "ROTI-GCV: Generalized Cross-Validation for right-ROTationally Invariant Data", "authors": "Kevin Luo,Yufan Li,Pragya Sur", "background": "在高维正则化回归中，关键任务是调整正则化强度以获得准确的预测以及估计出样本外风险。虽然常见的k折交叉验证方法在现代高维度设置中是不一致的，但在某些高维度情况下，留一交叉验证和广义交叉验证仍然是一致的。然而，在样本间存在依赖性或包含重尾协变量的情况下，它们会变得不一致。因此，研究者提出使用右旋不变的协变量分布作为构建模型的第一步。在特征数量和样本数都比较增长的渐进比例体制中，这种方法更适合反映中等大小数据集中的实际行为。在此背景下，研究者引入了新的方法ROTI-GCV，以可靠地计算这些具有挑战性条件下的交叉验证。", "innovation": "研究者提出了ROTI-GCV框架，以解决在样本间存在依赖性或包含重尾协变量的条件下进行交叉验证的问题。此外，研究者还提出了新的信号噪声比和噪声方差估计器，以提高方法的准确性。该框架描述了一种新的建模结构样本依赖性和重尾的方法。", "conclusion": "研究者通过实验展示了在多种合成和半合成环境中，该方法在准确性的优势。这种新的方法和概念拓展了我们对高维正则化回归中挑战条件下的理解，为今后的研究提供了新的思路。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.05500", "html_url": "https://arxiv.org/abs/2410.05500", "title": "增强深度学习的残留柯尔莫戈罗夫-阿诺尔德网络", "title_en": "Residual Kolmogorov-Arnold Network for Enhanced Deep Learning", "authors": "Ray Congrui Yu,Sherry Wu,Jiang Gui", "background": "尽管深度卷积神经网络（CNNs）在许多应用中取得了巨大成功，但由于网络深度中的数百层，它们的优化和训练成本较高且较为困难。传统卷积操作因其线性和固定的激活函数的基础限制，需要许多层才能学习数据中的有意义模式。这种网络的庞大尺寸使得此类方法在计算上效率低下，并且在小型数据集上容易出现过拟合或梯度爆炸问题。因此，我们介绍了一种‘即插即用’模块，称为残差柯尔莫戈罗夫-阿诺尔德网络（RKAN）。", "innovation": "我们的模块非常紧凑，可以轻松插入传统深度网络的任何阶段，在现有卷积框架中学习支持多项式特征转换以提供支持。在不同的视觉任务和广泛测试的基准上，RKAN 在基线模型上提供了持续改进，并在这些基准上实现了尖端的性能。", "conclusion": "RKAN 通过学习支持多项式特征转换，为传统深度网络提供了插件功能，从而在多个视觉任务上实现了持续的性能提升，并在广泛测试的标准上达到了前沿的性能水平。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.14621", "html_url": "https://arxiv.org/abs/2410.14621", "title": "JAMUN：连接平滑分子动力学和基于分数的学习以生成构象集合", "title_en": "JAMUN: Bridging Smoothed Molecular Dynamics and Score-Based Learning for Conformational Ensembles", "authors": "Ameya Daigavane,Bodhi P. Vani,Darcy Davidson,Saeed Saremi,Joshua Rackers,Joseph Kleinhenz", "background": "蛋白质构象集对于理解蛋白质功能和新型药物发现如隐秘口袋至关重要。目前的技术如分子动力学（MD）计算效率低，而很多最近的机器学习方法则难以转移到训练数据以外的系统。", "innovation": "本文提出了JAMUN，这是一种结合了平滑分子动力学和基于分数学习的方法，可以在所有原子3D构象的光滑空间中进行MD模拟。JAMUN通过利用走跳采样框架，能够以传统分子动力学速度的十倍以上生成小型肽的构象集，并且具有跨训练数据系统之外的可转移性，甚至适用于比原训练数据更长的肽。", "conclusion": "我们的模型、代码和权重已提供。JAMUN相比传统方法，显著提升了构象集生成速度并增强了跨系统应用的能力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.14144", "html_url": "https://arxiv.org/abs/2406.14144", "title": "从安全神经元的角度理解安全对齐：一种机制视角", "title_en": "Towards Understanding Safety Alignment: A Mechanistic Perspective from Safety Neurons", "authors": "Jianhui Chen,Xiaozhi Wang,Zijun Yao,Yushi Bai,Lei Hou,Juanzi Li", "background": "大型语言模型（LLMs）在各种能力上表现出色，但安全风险，例如生成有害内容和虚假信息，依然存在，即使在进行安全对齐之后。本文探讨了通过机制可解释性视角理解安全对齐的内部机制，重点在于识别和分析LMS中存在的负责安全行为的安全神经元。研究通过推断时激活对比来定位这些神经元，并通过动态激活补丁来评估它们对模型安全性的因果影响。实验表明，可以一致地识别约5%的安全神经元，并通过仅修补其激活，可以在各种红队基准测试中恢复超过90%的安全性能，而不影响其一般能力。此外，该研究发现了安全神经元有助于解释“对齐税”现象，揭示了模型安全性和有用性的关键神经元有显著重叠，但是它们需要不同的激活模式来获得相同的功能效果。这进一步证明，研究可以在生成前检测到不安全的输出，从而保护LLMs的安全性。", "innovation": "本文提出了通过机制可解释性视角理解安全对齐的方法，引入了推断时激活对比和动态激活补丁来识别和评估安全神经元。实验结果表明，通过修补安全神经元的激活可以有效提升模型的安全性能，而无需影响其一般能力。此外，首次向研究界提供了安全神经元的概念，揭示了模型安全与有用的重叠和差异。这项工作还提升了LLMs的安全防御手段，通过检测生成的不安全输出以确保模型的可靠性。", "conclusion": "研究通过识别和分析安全神经元，成功地提升了对LMS进行安全对齐的理解，并提出了一种新的方法来恢复模型的安全性能。通过进一步研究安全神经元的激活模式，可以更有效地提升模型的安全性，并提供更可靠的模型输出。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.08457", "html_url": "https://arxiv.org/abs/2410.08457", "title": "Unity is Power: Semi-Asynchronous Collaborative Training of Large-Scale Models with Structured Pruning in Resource-Limited Clients", "title_en": "Unity is Power: Semi-Asynchronous Collaborative Training of Large-Scale Models with Structured Pruning in Resource-Limited Clients", "authors": "Yan Li,Xiao Zhang,Mingyi Li,Guangwei Xu,Feng Chen,Yuan Yuan,Yifei Zou,Mengying Zhao,Jianbo Lu,Dongxiao Yu", "background": "本文探讨了如何利用大规模异构的弱计算能力，通过分散的数据集协作训练大型模型。面对资源适应性协作学习中效率和准确性的提升挑战，本文首度同时考虑了未结构化剪枝、子模型架构变化、知识丢失和缓存器问题等挑战。", "innovation": "本文提出了一种名为$Co\text{-}S}^2{P$的新颖半异步协作训练框架，结合了数据分布感知结构化剪枝和跨块的知识传输机制，以解决上述问题。并且提供了理论证明，表明$Co\text{-}S}^2{P$框架可实现渐近最优的收敛速率为$O(1/\text{N*EQ})$。", "conclusion": "通过在实际硬件测试平台上对两种类型的任务进行广泛实验，本文展示了$Co\text{-}S}^2{P$能提高高达8.8%的准确性，提升高达1.2倍的资源利用率，同时减少约22%的内存消耗和大约24%的训练时间，在所有资源受限设备上。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.16892", "html_url": "https://arxiv.org/abs/2408.16892", "title": "Tex-ViT: 一种通用且鲁棒的纹理基础双分支跨注意力深度欺骗检测器", "title_en": "Tex-ViT: A Generalizable, Robust, Texture-based dual-branch cross-attention deepfake detector", "authors": "Deepak Dagar,Dinesh Kumar Vishwakarma", "background": "深度伪造（Deepfakes）使用生成对抗网络（GAN）生成高度逼真的面部修改，被认为是当前的主流方法。传统的卷积神经网络（CNN）能够识别伪造的媒体，但在不同数据集上的表现不佳，并且容易受到对抗攻击的影响，这是因为它们缺乏 robust 性。视觉变换器在图像分类问题上展示了潜力，但需要足够的训练数据。鉴于这些局限性，本文介绍了 Tex-ViT （纹理视觉变换器），它通过结合 ResNet 和视觉变换器来增强 CNN 特征。", "innovation": "Tex-ViT 将传统 ResNet 特征与纹理模块结合，后者在每次下采样操作前于 ResNet 的部分进行并行操作。纹理模块随后作为双分支跨注意力视觉变换器的输入。它特别关注提升全局纹理模块，该模块提取特征图的相关性。实验表明，伪造图像在操纵过程中会出现平滑的纹理，但这些纹理并不会保持一致。Tex-ViT 在不同类别（如 FF++ 的 DF、f2f、FS 和 NT 类别，以及其它 GAN 数据集）的跨域场景中进行了实验，并在多种后处理情况（如模糊、压缩和噪声）下进行了测试。实验结果表明，该模型在跨域场景中的泛化能力优越，准确率达到 98%，显示出其能够学会伪造样本中的共性纹理特征，并应对多种后处理操作。", "conclusion": "这些实验提供了证据，证明提出的模型能够应用于各种情况，并对许多后处理操作具有抗性。Tex-ViT 的提出解决了传统 CNN 和视觉变换器在识别深度伪造方面的不足，展示了其在深度伪造检测领域的优越性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18469", "html_url": "https://arxiv.org/abs/2410.18469", "title": "迭代自调优LLM以增强越狱能力", "title_en": "Iterative Self-Tuning LLMs for Enhanced Jailbreaking Capabilities", "authors": "Chung-En Sun,Xiaodong Liu,Weiwei Yang,Tsui-Wei Weng,Hao Cheng,Aidan San,Michel Galley,Jianfeng Gao", "background": "最近的研究表明，大型语言模型（LLMs）容易受到自动化的监狱逃脱攻击，攻击者可以通过算法构造的恶意后缀绕过安全对齐，触发意外响应。当前生成这些后缀的方法计算成本高昂且攻击成功率（ASR）低，特别是在对抗如Llama2和Llama3这类高度对齐的模型时。", "innovation": "本文提出了一种迭代自我调优过程ADV-LLM，可以生成具有较强监狱逃脱能力的对抗LLMs。该框架能显著降低生成对抗后缀的计算成本，同时在多种开源LLMs上实现了近100%的攻击成功率。同时，该框架显示出较强的目标模型兼容性，在GPT-3.5上实现了99%的攻击成功率，并且在GPT-4上获得了49%的攻击成功率，尽管仅在Llama3上优化。除了增强监狱逃脱能力，ADV-LLM还通过生成大量用于研究LLM安全性的数据集，为未来的安全对齐研究提供了宝贵洞见。", "conclusion": "该研究通过介绍ADP-LLM框架，显著降低了生成对抗后缀的成本，提高了攻击成功率，并提供了研究LLM安全性的数据集，为未来研究提供了新的视角。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00538", "html_url": "https://arxiv.org/abs/2412.00538", "title": "基于动态任务严重性的机器人操作手预测框架", "title_en": "Prognostic Framework for Robotic Manipulators Operating Under Dynamic Task Severities", "authors": "Ayush Mohanty,Jason Dekarske,Stephen K. Robinson,Sanjay Joshi,Nagi Gebraeel", "background": "机器人操作手在许多应用中至关重要，但随着时间的推移会逐渐退化。这种退化由机器人执行的任务性质所影响，例如处理重载等严重任务会加速退化过程。退化的一个表现是在机器人末端执行器的位置精度方面。因此，本研究提出了一种前瞻性模型框架，旨在预测机器人操作手的剩余使用寿命（RUL），并考虑任务严重性的影响。", "innovation": "本研究创新性地将机器人的位置精度视为受任务严重性影响的随机漂移参数的布朗运动过程，并使用连续时间马尔可夫链（CTMC）来模拟任务严重性的动态性质。此外，提出了新的剩余寿命分布（RLD）的封闭形式表达式，以及通过蒙特卡洛模拟进行RUL评估的两种方法，并证明了两种方法之间的等效性。实验结果表明，当机器人处理较高严重度的任务比例较高时，其RUL会减少。", "conclusion": "通过使用两种不同的物理仿真器对平面和空间机器人舰队进行实验验证，该框架证明了其有效性和准确性。在执行高严重度任务的情况下，机器人的RUL会缩短，突显了本研究在未来机器人维护规划中的应用潜力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.18897", "html_url": "https://arxiv.org/abs/2501.18897", "title": "生成模型比较的统计推断", "title_en": "Statistical Inference for Generative Model Comparison", "authors": "Zijun Gao,Yan Sun,Han Su", "background": "生成模型在多种应用中取得了显著成功，但在评估这些模型时，仍然缺乏科学的不确定性量化方法。本文发展了一种方法来比较不同生成模型与测试样本实际情况之间的接近程度。", "innovation": "本文采用Kullback-Leibler（KL）发散来衡量生成模型与未知测试分布之间的距离，因为KL不需要调参，如RKHS基距方法所需的核函数，并且它是唯一一个允许关键抵消的f-发散，从而可以进行不确定性量化。此外，本文进一步扩展了方法以比较条件生成模型，并利用边缘展开以应对数据量有限的情况。在已知真实情况的模拟数据集上，本文的方法实现了有效覆盖率，并且相比基于核的方法具有更高的功效。当应用于图像和文本数据集的生成模型时，本文的方法得出的结论与基准度量一致，但具有统计置信度。", "conclusion": "本文的方法在模拟数据集和实际应用数据集上都展示了有效的性能，特别是在有限数据情况下，边缘展开帮助提高了方法的适用性和准确性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18162", "html_url": "https://arxiv.org/abs/2410.18162", "title": "多火花张量PCA中高维随机梯度下降法的研究", "title_en": "Stochastic gradient descent in high dimensions for multi-spiked tensor PCA", "authors": "Gérard Ben Arous,Cédric Gerbelot,Vanessa Piccolo", "background": "该研究探讨了多火花张量模型中在线随机梯度下降法（SGD）的动力学行为。因此背景包括张量主成分分析（PCA）问题，其中有多重火花。目标是从有噪声观测的p-张量中通过最大似然估计来估计N维单位球体内的r个未知信号向量。先前的研究已经确定了在单一火花情况下所需的样本数量和信噪比（SNR）条件。本文进一步研究了多火花情况下所需条件及其恢复机制。", "innovation": "本文创新地通过详细分析一系列低维系统来研究高维下多火花张量模型中随机梯度下降法的演进过程，特别关注信号之间的相关性和信噪比的动态控制。此外，研究提出了一种称为“顺序消除”的恢复机制，这一机制揭示了成对相关如何达到临界阈值，从而实现信号向量恢复的顺序进行，且这种顺序依赖于初始相关性和对应的信噪比。", "conclusion": "该研究发现，所有信号向量的完整恢复需要样本数量按N^(p-2)的比例增长，与单一火花情况下的算法阈值相匹配。在矩阵情况下（p=2），如果信噪比充分分离，可以精确恢复信号向量，而信噪比相等则只能恢复由它们构成的子空间。本研究为理解多火花张量模型中的恢复机制提供了新的视角，并且验证了在高维度下随机梯度下降法的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.00565", "html_url": "https://arxiv.org/abs/2501.00565", "title": "在固定维度下通过逆转扩散实现多项式查询复杂度的多项式分布采样", "title_en": "Sampling from multi-modal distributions with polynomial query complexity in fixed dimension via reverse diffusion", "authors": "Adrien Vacher,Omar Chehab,Anna Korba", "background": "即使在低维度空间中，从多模态分布中进行采样也是非常具有挑战性的。现有的采样算法通常需要对模式位置有先验知识，并且局限于某些特定条件下的分布（例如需要满足log光滑性假设）。但对所有高斯混合分布，现有的算法尚无法提供有效的多项式查询复杂度。", "innovation": "提出了一种适用于广义分布的采样算法，包括所有高斯混合分布，该算法可以在固定维度下呈现多项式查询复杂度。该算法利用时间反转扩散模型，并使用归一化的蒙特卡洛估计中间得分函数。与先前的工作相比，它避免了暂时陷阱，不需要预先知道模式的位置，并且放宽了需要log光滑性的假设。", "conclusion": "通过逆转扩散过程模拟，该工作实现了在固定维度的多项式查询复杂度下从多模态分布中进行有效的采样。算法适用于所有高斯混合分布，即使不满足先前要求的条件。这一方法提供了高效的采样解决方案，避免了模式位置的先验信息需求，并且在采样算法性能上有所提升。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.03297", "html_url": "https://arxiv.org/abs/2502.03297", "title": "IRIS: 一种沉浸式机器人交互系统", "title_en": "IRIS: An Immersive Robot Interaction System", "authors": "Xinkai Jiang,Qihao Yuan,Enes Ulas Dincer,Hongyi Zhou,Ge Li,Xueyin Li,Xiaogang Jia,Timo Schnizer,Nicolas Schreiber,Weiran Liao,Julius Haag,Kailai Li,Gerhard Neumann,Rudolf Lioutikov", "background": "现有的基于扩展现实（XR）的系统能够高效地收集数据，但由于它们针对特定的机器人、物体、模拟器和环境，因此难以复制和重新使用。这给通用性带来了挑战，限制了XR技术在不同场景下的广泛应用。", "innovation": "IRIS通过支持跨不同模拟器和现实世界场景的沉浸式交互和数据收集，解决了上述问题。IRIS能够可视化任意刚体和变形物体，模拟机器人，结合实时传感器生成的点云数据，适用于现实世界的应用。此外，IRIS还增强了协作功能，允许多个用户在同一虚拟场景中同时进行交互。", "conclusion": "广泛实验表明，IRIS在模拟和真实世界环境中都提供了高效且直观的数据收集能力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.19634", "html_url": "https://arxiv.org/abs/2412.19634", "title": "深度连续时间状态空间模型在标注事件序列中的应用", "title_en": "Deep Continuous-Time State-Space Models for Marked Event Sequences", "authors": "Yuxin Chang,Alex Boyd,Cao Xiao,Taha Kass-Hout,Parminder Bhatia,Padhraic Smyth,Andrew Warrington", "background": "Marked temporal point processes (MTPPs)模型用于描述不规则时间间隔发生的事件序列，广泛应用于医疗、金融和社会网络等领域。现有的MTPP模型存在一些局限性，无法捕捉连续时间事件序列的强大归纳偏置，而传统的离散序列模型（如RNNs、transformers）也无法完全捕捉这些偏置。研究者提出了一种新的状态空间点过程(S2P2)模型，该模型利用现代深度状态空间模型(DDSMs)的技术来克服现有MTPP模型的不足，且支持其他离散序列模型无法捕捉的强大归纳偏置，并使用高效的并行扫描训练和推理实现线性复杂度和亚线性缩放，同时保持对MTPPs的高度表达性。实验证明，S2P2模型在8个实际数据集上获得了最先进的预测似然值，相对于现有最佳方法的平均提升达33%。", "innovation": "提出了基于经典线性霍克斯过程的新型状态空间点过程(S2P2)模型，利用了现代深度状态空间模型的技术来克服现有MTPP模型的局限，并在不依赖严格的强度参数假设的情况下创建了一个强大的基于强度的MTPP模型，同时提供了高效训练和推理的机制，实现了线性和亚线性的时间复杂度和可扩展性，且保持了对MTPPs的高度表达性，并且在实际数据集上显著提高了预测精度。", "conclusion": "S2P2模型在8个实际数据集上实现了最先进的预测似然值，相比现有的最佳方法提升了33%。该模型克服了现有MTPP模型的局限，通过结合现代深度状态空间模型技术并利用强大的不连续时间事件序列归纳偏置，显著提高了实际应用中的预测准确性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05094", "html_url": "https://arxiv.org/abs/2502.05094", "title": "量子计算对非线性蒙特卡洛问题的加速", "title_en": "Quantum speedup of non-linear Monte Carlo problems", "authors": "Jose Blanchet,Yassine Hamoudi,Mario Szegedy,Guanyang Wang", "background": "随机变量的均值可以被理解为概率分布空间上的线性泛函。量子计算已知可以在均值估计中比经典蒙特卡洛方法提供二次速度上的提升。本文研究了是否可以对概率分布的非线性泛函估计提供类似的二次加速。", "innovation": "提出了一种新的量子-内部-量子蒙特卡洛算法，该算法为广泛的非线性估计问题，包括嵌套条件预期和随机优化，实现了二次速度提升。该算法改进了An等人（2021）提出的量子多级蒙特卡洛算法。我们的方法的关键创新点是一种专门为量子计算设计的新序列的多重蒙特卡洛近似，这是算法性能提升的核心。", "conclusion": "现有的下限表明，我们的算法在多项对数因子上是最优的。这种方法为使用量子计算解决复杂的非线性蒙特卡洛问题开辟了新的可能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.00470", "html_url": "https://arxiv.org/abs/2502.00470", "title": "CoCoA Is ADMM: Unifying Two Paradigms in Distributed Optimization", "title_en": "CoCoA Is ADMM: Unifying Two Paradigms in Distributed Optimization", "authors": "Runxiong Wu,Dong Liu,Xueqin Wang,Andi Wang", "background": "该研究探讨了在分布式环境中解决一般经验风险最小化问题的原始-对偶算法。重点关注两类算法：通信高效的分布式对偶坐标上升（CoCoA）算法和交替方向乘子法（ADMM）的变体，包括共识ADMM、接近ADMM和线性化ADMM。研究发现这两类算法可以归结为一个统一的更新公式，仅涉及原始和对偶变量的形式，揭示了CoCoA可以被视为接近ADMM的一个特例，而共识ADMM等价于一种接近ADMM算法。这些发现对理解如何通过适当调整增强拉格朗日乘子参数使ADMM变体性能超越CoCoA变体提供见解。进一步研究了ADMM变体的线性化版本，并分析了调节参数在分布式环境中的影响。", "innovation": "发现CoCoA可以被解释为接近ADMM的一个特例，共识ADMM等价于一种接近ADMM算法。这提供了一种新的视角和方法，使ADMM变体通过调整增强拉格朗日乘子参数来超越CoCoA变体。此外，研究还进一步探讨了ADMM变体的线性化版本，并分析了调节参数的影响。这些发现为理解和优化分布式优化算法提供了新的思路。", "conclusion": "通过理论分析和模拟研究，证明了CoCoA算法和ADMM算法可以被统一到一个框架中，并且通过适当调整增强拉格朗日乘子参数可以使ADMM变体在分布式环境中表现出更好的性能。研究结果还验证了理论分析，提供了对分布式优化算法性能优化的深入见解。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06753", "html_url": "https://arxiv.org/abs/2502.06753", "title": "SMRS: 推崇人工智能时代代理模型的统一报告标准", "title_en": "SMRS: advocating a unified reporting standard for surrogate models in the artificial intelligence era", "authors": "Elizaveta Semenova,Alisa Sheinkman,Timothy James Hitge,Siobhan Mackenzie Hall,Jon Cockayne", "background": "代理模型在科学研究和技术工程中被广泛应用于近似复杂的系统，以降低计算成本。尽管如此，该领域在建模管道的关键阶段存在缺乏标准化的问题，包括数据采样、模型选择、评估以及下游分析。这种碎片化限制了可再现性和跨领域应用。特别是在人工智能驱动的代理模型激增的背景下，这一挑战变得更加突出。", "innovation": "本文提出紧急需要建立一个结构化的报告标准——代理模型报告标准（SMRS），该标准系统地捕捉关键的设计和评估选择，并且不依赖于具体实施细节。通过推广一个标准的且灵活的框架，旨在提高代理建模的可靠性，促进跨学科知识的转移，由此加快人工智能时代的科技进展。", "conclusion": "SMRS 旨在通过标准化代理建模的流程和报告方法，提升研究的可靠性和再现性，并促进不同领域的知识交流与应用，从而在人工智能时代加速科学技术的进步。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06536", "html_url": "https://arxiv.org/abs/2502.06536", "title": "具有理论保证的示例高效概念学习：无需干预从数据到概念", "title_en": "Sample-efficient Learning of Concepts with Theoretical Guarantees: from Data to Concepts without Interventions", "authors": "Hidde Fokkema,Tim van Erven,Sara Magliacane", "background": "机器学习在许多实际系统中起着至关重要的作用，但黑盒AI系统的可解释性和鲁棒性仍存在诸多担忧。概念瓶颈模型（CBM）通过从高维数据中学习可解释的概念来解决部分挑战，用以预测标签。然而，在CBM中，概念之间的虚假相关性是一个重要问题，实际学习到的概念往往是“错误”的。目前正在使用的缓解策略具有较强的假设性，比如假设概念相互独立，或者需要大量互动和标注提供者提供的标签。", "innovation": "本文提出了一个框架，该框架在无需干预的情况下提供了学习概念的理论保证，并确保了所需标签的数量。该框架利用因果表示学习（CRL）方法，从高维观测中无监督地学习潜在的因果变量，然后使用少量的概念标签将这些变量与可解释的概念对齐。作者提出了线性和非参数估计器来实现这种映射，提供了线性情况下的有限样本高概率结果，并为非参数估计器提供了渐近一致性结果。该框架在合成和图像基准测试中得到了评估，表明所学到的概念具有较少的杂质，且在概念之间存在强相关性的环境中，其准确性往往优于其他CBM方法。", "conclusion": "该研究提供了一个无需干预即可从数据学到概念的框架，通过利用因果表示学习方法来学习潜在的因果变量，然后通过少量概念标签将这些变量与可解释的概念对齐。实验结果显示，所学的概念比其他CBMs具有更少的杂质，且在概念之间存在强相关性的环境中更准确。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.13085", "html_url": "https://arxiv.org/abs/2502.13085", "title": "基于神经差熵估计器的互信息估计", "title_en": "A Neural Difference-of-Entropies Estimator for Mutual Information", "authors": "Haoran Ni,Martin Lotz", "background": "在高维情况下，准确估计互信息（一种衡量随机量之间依赖性的关键度量）是一个具有挑战性的问题，尤其是在没有特定建模假设的情况下。传统的互信息估计方法在高维数据中倾向于表现不佳，因为它们可能受到维度灾难和建模假设的限制。近年来，归一化流，一种深度生成模型，因其在建模复杂分布上的优势而受到关注，能有效改进这一问题。", "innovation": "本文提出了一种基于归一化流参数化条件密度的新颖互信息估计器，并利用块自回归结构优化了偏差-方差权衡，针对标准基准任务实现了更好的性能。这种方法不仅避免了传统方法在高维度数据中的不足，还利用了归一化流对复杂分布建模的能力，提升了估计的准确性和可靠性。", "conclusion": "该研究提出的方法通过对条件密度的参数化实现互信息估计，并通过块自回归结构改进了估计器的性能，避免了高维度数据的挑战，为互信息估计领域提供了一个有效的解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.16247", "html_url": "https://arxiv.org/abs/2503.16247", "title": "OpenMIBOOD: 开放的医学影像领域异常输入检测基准", "title_en": "OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection", "authors": "Max Gutbrod,David Rauber,Danilo Weber Nunes,Christoph Palm", "background": "随着人工智能（AI）在关键领域如医疗保健中的依赖性不断增加，确保这些系统可信度的机制变得愈加重要，尤其是在面对意外或异常输入时。然而，现有的广泛领域的大规模自然图像中的异常输入检测基准在医疗应用中并不适用，这强调了为医疗领域制定此类基准的需求。", "innovation": "该论文提出了一种名为OpenMIBOOD的综合框架，专门用于评估医学影像中的异常输入检测方法。OpenMIBOOD包括来自不同医学领域的三个基准，包含14个数据集，并将这些数据集分为协变量偏移的在分布、接近异常输入和远离异常输入类别。这为24种后处理方法提供了标准化的评估标准，促进了异常输入检测方法的发展与公平比较。", "conclusion": "结论表明，广泛领域的异常输入基准在自然图像中的发现并不适用于医疗领域。通过减少AI模型暴露在训练分布外的输入风险，OpenMIBOOD旨在支持可靠和可信赖的AI系统在医疗保健中的发展。该基准库可在该网址获取：this https URL"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17213", "html_url": "https://arxiv.org/abs/2502.17213", "title": "深度学习驱动的脑电信号分析：推进神经诊断学", "title_en": "Deep Learning-Powered Electrical Brain Signals Analysis: Advancing Neurological Diagnostics", "authors": "Jiahe Li,Xin Chen,Fanqi Shen,Junru Chen,Yuxin Liu,Daoze Zhang,Zhizhang Yuan,Fang Zhao,Meng Li,Yang Yang", "background": "神经障碍构成了重大的全球健康挑战，推动了脑信号分析的进步。头皮脑电图（EEG）和颅内脑电图（iEEG）广泛应用于诊断和监测。但由于数据集异质性和任务差异，阻碍了稳健的深度学习解决方案的发展。", "innovation": "系统审查了针对EEG/iEEG的7种神经障碍的大数据分析下深度学习进步，使用了46个数据集。每种状况下审核了代表性方法及其定量结果，并整合了性能对比，数据分析使用，模型设计以及任务特定适应性分析，强调预训练多任务模型在实现可扩展性和广泛适用性解决方案中的角色。同时提出了一种标准化基准来评估模型在不同数据集上的表现，并提高可再现性，阐明了最近创新如何使神经诊断向智能化、适应性强的健康系统转变。", "conclusion": "最终提出了一种标准化基准来评估模型在多样数据集上的表现，并强调提高可再现性，同时指出了最近创新如何使神经诊断向智能化、适应性强的健康系统转变。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08416", "html_url": "https://arxiv.org/abs/2502.08416", "title": "高效计算昂贵模拟器的多重保真度基于模拟的推理", "title_en": "Multifidelity Simulation-based Inference for Computationally Expensive Simulators", "authors": "Anastasia N. Krouglova,Hayden R. Johnson,Basile Confavreux,Michael Deistler,Pedro J. Gonçalves", "background": "在科学的各个领域，随机模型是理解经验观察数据背后机制的一个重要工具。模型可以有不同的详细程度和准确性，高保真模型因能更准确地反映研究现象而通常较为优选。然而，通过基于模拟的推理来推断这些高保真模型的参数极其具有挑战性，特别是当模拟器计算成本昂贵时。", "innovation": "本文引入了MF-(TS)NPE，一种多重保真度的神经后验估计方法，利用低成本低保真模型模拟来高效地推断高保真模拟器的参数。MF-(TS)NPE适用于递归和非递归神经后验估计。此外，引入了A-MF-TSNPE，一种顺序变体，它通过目标密度估计器预测不确定性来适应性地选择高保真参数，从而提高模拟效率。这种方法在基准测试和神经科学任务上表现出色，比当前方法少用高达两个数量级的高保真模拟。", "conclusion": "本文的方法开辟了在计算成本昂贵的模拟器上高效进行贝叶斯推断的新途径，显著减少了高保真模拟的需求，同时保持了可比的性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.02439", "html_url": "https://arxiv.org/abs/2505.02439", "title": "基于 ensemble 学习的大规模多情境建筑 HVAC 控制的机器学习预测控制", "title_en": "Towards Machine Learning-based Model Predictive Control for HVAC Control in Multi-Context Buildings at Scale via Ensemble Learning", "authors": "Yang Deng,Yaohui Liu,Rui Liang,Dafang Zhao,Donghua Xie,Ittetsu Taniguchi,Dan Wang", "background": "对于采用 HVAC 系统的建筑物来说，能够预测实时室内温度变化的建筑热力学模型至关重要，以优化暖通空调控制。尽管有一些早期的研究试图为不同类型的建筑环境开发这类模型，但这些模型往往需要大量数据收集，并且高度依赖专家知识，导致建模过程低效且模型难以重用。", "innovation": "本文提出了利用现有模型作为基础模型的模型集合方法，这些基础模型用于为特定的建筑环境提供预测，以减少相关工作。为了应对建筑数据流的非平稳性和基模型数量的增加，本文提出了一种分层强化学习（HRL）方法来动态选择和加权基础模型。该方法采用了两层次的决策过程：高层负责模型选择，而低层则确定所选模型的权重。", "conclusion": "本研究通过离线实验和现场案例研究对提出的分层强化学习方法进行了全面评估，实验结果表明该方法的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15275", "html_url": "https://arxiv.org/abs/2504.15275", "title": "停止求和：最小形式信用分配是过程奖励模型进行推理所需的一切", "title_en": "Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning", "authors": "Jie Cheng,Gang Xiong,Ruixi Qiao,Lijun Li,Chao Guo,Junle Wang,Yisheng Lv,Fei-Yue Wang", "background": "过程奖励模型（PRMs）已经在大型语言模型（LLMs）的困难推理任务上实现了有效的测试时扩展。然而，PRMs中的奖励作弊问题限制了其在强化学习微调中的成功应用。主要原因在于强化学习中传统的加法形式信用分配，这使得LLMs容易通过高奖励步骤作弊。", "innovation": "本文提出了一种新的方法PURE（Process sUpervised Reinforcement lEarning），其关键创新在于最小形式信用分配。最小形式信用分配将价值函数定义为未来奖励的最小值，这种方法通过限制价值函数的范围和更合理地分配优势，显著缓解了奖励作弊。", "conclusion": "通过广泛的实验，我们发现使PRM基于的方法采用最小形式信用分配在仅30%的步骤内能够达到与验证奖励方法相当的推理性能。相反，传统的累加形式信用分配在训练早期即会导致训练崩溃。此外，通过添加10%的验证奖励，我们可以进一步缓解奖励作弊，并在Qwen2.5-Math-7B上获得最好的微调模型，在AMC23和5个基准中分别实现了82.5%和53.3%的平均准确率。我们还总结了观察到的奖励作弊案例并分析了训练崩溃的原因，并公开了我们的代码和模型权重。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.09933", "html_url": "https://arxiv.org/abs/2502.09933", "title": "MIR-Bench: Your LLM能通过多示例上下文推理识别复杂模式吗？", "title_en": "MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?", "authors": "Kai Yan,Zhan Ling,Kang Liu,Yifan Yang,Ting-Han Fan,Lingfeng Shen,Zhengyin Du,Jiecao Chen", "background": "模式识别和应用是通用智能的基本能力，受到了心理学和人工智能研究人员的广泛关注。针对大型语言模型（LLMs）的基准测试已有许多，但主要关注少样本设置（通常少于10个样本），缺乏对从长上下文汇总大量信息的评估。尽管如此，LLMs的不断增长的上下文长度带来了新的多示例上下文学习（many-shot In-Context Learning, ICL）范式，该范式使模型能够利用数百到数千个示例解决新任务，而无需昂贵且低效的微调。然而，大多数多示例评估主要集中在分类上，常见的长上下文LLM任务如“针扎麦秆堆”（NIAH）很少需要复杂的推理来整合大量信息。为了弥补两方面的不足，本文提出了MIR-Bench，这是首个用于模式识别的多示例上下文推理基准测试，要求LLM通过输入输出示例预测来自多种数据格式的基本函数输出。", "innovation": "本文提出了MIR-Bench，这是首个用于模式识别的多示例上下文推理基准测试，旨在评估LLM 在识别复杂模式方面的多示例上下文推理能力。MIR-Bench要求模型通过输入输出示例预测来自各种数据格式的基本函数输出。基于MIR-Bench，研究了多示例上下文推理中的许多新型问题，并获得了包括规模效应、鲁棒性、归纳推理 vs. 推断推理、检索增强生成（RAG）、编码促进归纳推理、跨域泛化等多方面的深刻见解。", "conclusion": "研究结果表明MIR-Bench在评估LLMs在复杂模式识别上的多示例上下文推理方面具有重要意义，并提出了多个新的研究问题。这不仅为LLMs的研究提供了新的基准，也为未来的进化方向提供了指导。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.08125", "html_url": "https://arxiv.org/abs/2505.08125", "title": "精确的去中心化联邦学习的高斯近似", "title_en": "Sharp Gaussian approximations for Decentralized Federated Learning", "authors": "Soham Bonnerjee,Sayar Karmakar,Wei Biao Wu", "background": "联邦学习在隐私敏感的合作环境中引起了广泛关注，局部SGD作为关键优化方法在去中心化设置中得到了广泛应用。虽然局部SGD的收敛性得到了深入研究，但其超越收敛的渐近统计保证仍然有限。本研究旨在改进这一现状，通过提出两种广义高斯近似结果，进一步探讨局部SGD的统计性质及其在去中心化联邦学习中的应用价值，尤其是在鲁棒性的考虑下，提供了两种针对局部SGD整个轨迹的时间一致高斯近似方法，为检测对抗攻击提供了一种基于高斯再抽样的测试方法。大量的模拟实验支持了研究中的理论结果，提供了理论验证和实际应用的支持。", "innovation": "本研究表明，开发了两种高斯近似结果，分别为最终局部SGD迭代证明了一个贝里-斯珍定理，并且引入了两种不同的时间一致高斯近似方法，支持了基于高斯再抽样的检测对抗攻击的检验，加强了局部SGD在去中心化联邦学习中的统计理论保证，并提供了基于时间一致性的鲁棒性优势。此外，该研究通过大量模拟实验支持其理论结果，提供了强大的验证依据。", "conclusion": "本研究解决了局部SGD在去中心化联邦学习中的统计保证问题，通过提供两种广义高斯近似，不仅改进了相应的乘数再抽样程序，还支持了基于高斯再抽样的鲁棒性检测。该研究结果对去中心化和联邦学习领域的优化和安全性都有重要影响，同时也为未来相关研究提供了坚实的基础。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21994", "html_url": "https://arxiv.org/abs/2505.21994", "title": "基于分解的物理显式神经网络的稳健训练及其在几乎不可压缩线性弹性中的应用", "title_en": "A decomposition-based robust training of physics-informed neural networks for nearly incompressible linear elasticity", "authors": "Josef Dick,Seungchan Ko,Quoc Thong Le Gia,Kassem Mustapha,Sanghyeon Park", "background": "低阶一致有限元方法在处理近不可压缩弹性方程时因拉梅系数 λ 趋于无穷大或泊松比 ν 趋于 1/2 而出现的精度下降现象，即所谓的锁模或非稳健性问题，尽管进行了广泛的研究，这种情况仍未得到完全理解。", "innovation": "本文提出了基于分解的 PINNs 方法，该方法将弹性方程分解为平衡子系统，从而消除引起锁模的病态条件，并同时求解前向和反向问题以恢复分解后的场变量及其相关外部条件。此外，进行收敛性分析以进一步增强所提方法的可靠性。", "conclusion": "通过各种数值实验，包括恒定、变化和参数化的拉梅系数，证明了所提出方法的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22651", "html_url": "https://arxiv.org/abs/2505.22651", "title": "Sherlock: 自视语言模型中的自我纠正推理", "title_en": "Sherlock: Self-Correcting Reasoning in Vision-Language Models", "authors": "Yi Ding,Ruqi Zhang", "background": "视觉语言模型（VLMs）在复杂的跨模态任务中表现出有希望的表现，但仍面临重大挑战：它们高度依赖推理过程中的正确性，需要大量标注数据或精确的验证者，并且难以在特定领域之外进行泛化。", "innovation": "本文探索将自我纠正作为提升推理VLMs的方法。引入了名为Sherlock的自我纠正和自我改善训练框架，包括基于视觉扰动的偏好评价数据构造方法，以及动态$\beta$值进行偏好调节。使用Sherlock，模型仅需20k随机选择标注数据就可获得自我纠正能力，并在没有外部监督的情况下继续自我改善。Sherlock在八个基准测试中取得了显著成效，直接生成的准确率达到64.1%，自我纠正后的准确率达到65.4%，并在标注数据使用量少于20%的情况下超过了LLaVA-CoT、Mulberry和LlamaV-o1等模型。", "conclusion": "Sherlock框架表明，通过自我纠正和自我改进训练，视觉语言模型能够显著提高推理能力，减少对外部监督的依赖，同时在多个基准测试中展示出优越性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17203", "html_url": "https://arxiv.org/abs/2505.17203", "title": "提高转移速度, 智慧定价: 在跨市场偏好转移下实现最小最大动态定价", "title_en": "Transfer Faster, Price Smarter: Minimax Dynamic Pricing under Cross-Market Preference Shift", "authors": "Yi Zhang,Elynn Chen,Yujun Yan", "background": "研究在目标市场能够利用K个辅助市场的背景下，这些辅助市场的平均效用通过一个结构化的偏好转移方式有所不同。这要求提出一种能够在模型转移时进行处理的新算法，并提供线性和非参数效用模型的最小最大化（minimax）遗憾最优策略。该研究聚焦于通过利用不同市场的数据来优化价格策略，并考虑了不同维度和参数下的复杂性问题。", "innovation": "提出了跨市场转移动态定价（CM-TDP）算法，这是第一个能够在目标市场与辅助市场之间转移学习且能够处理此类模型转移问题的算法。对于线性效用模型，其复杂度为$\tilde{O}((d*K^{-1}+s_{0})\text{log } T)$；对于非线性需求模型，复杂度为$\tilde{O}(K^{-2\frac{\text{alpha} \beta}{2\text{alpha}\beta + 1}} T^{\frac{1}{2\text{alpha}\beta + 1}} + H^{\frac{2}{2\text{alpha} + 1}} T^{\frac{1}{2\text{alpha} + 1}})$，该结果与信息论下的下界相匹配，至对数因子。该算法是转移定价领域的第一个核希尔伯特空间结果，独立具有重要意义。此外，该算法结合了转移学习、鲁棒聚合和收益优化等多个领域，能够更快速地转移并更加智能地定价，展示了比单一市场定价策略更好的性能。", "conclusion": "CM-TDP算法在多个市场数据的利用下提供了一种新的动态定价策略，通过模型转移成功降低了累积遗憾，并加快了学习速度。通过将转移学习、鲁棒聚合和收益优化相结合，这一方法展示出了灵活应对市场变化和优化定价策略的潜力，为未来的定价系统设计提供了新的视角。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23946", "html_url": "https://arxiv.org/abs/2505.23946", "title": "从中学到的：代码LLM的多智能体学习和改进框架", "title_en": "Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve", "authors": "Yuanzhe Liu,Ryan Deng,Tim Kaler,Xuhao Chen,Charles E. Leiserson,Yao Ma,Jie Chen", "background": "最近的研究表明，大型语言模型（LLMs）在不同的技能和任务上表现出差异。实际上，我们观察到它们在各种粒度水平上的性能存在差异。例如，在代码优化任务中，代码LLMs在不同优化类别上的表现都不占主导地位。这促使我们思考如何利用多个LLM代理解决问题，而无需事先了解它们各自的互补优势。因此，我们提出了一种基于教训的学习和改进框架，旨在通过让代理相互学习彼此的成功与失败来提高各自的性能。", "innovation": "我们提出了一种基于教训的合作框架，设计了一种请求、储存和选择机制，并证明了一支小规模的带有学到教训的LLM团队可以优于更大规模的LLM以及其它多种LLM合作方法。", "conclusion": "通过这种多智能体框架，代理可以从彼此的成功和失败中吸取教训，从而改进各自的性能，并最终证明了这种方法的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02945", "html_url": "https://arxiv.org/abs/2506.02945", "title": "定量的大语言模型评判员", "title_en": "Quantitative LLM Judges", "authors": "Aishwarya Sahoo,Jeevana Kruthi Karnuthala,Tushar Parmanand Budhwani,Pranchal Agarwal,Sankaran Vaidyanathan,Alexa Siu,Franck Dernoncourt,Jennifer Healey,Nedim Lipka,Ryan Rossi,Uttaran Bhattacharya,Branislav Kveton", "background": "现有的大语言模型（LLM）在生成质量和文本评价方面表现出色，但在预测人类偏好和数值评分方面存在局限性。本研究提出了定量的大语言模型评判员，通过回归模型将现有LLM评判员的评分与人类评分对齐，提高评分的准确性。", "innovation": "提出了定量的大语言模型评判员框架，通过使用原始评判员的理由和评分进行训练，提高其评分能力。该框架对不同类型的绝对和相对反馈提供了四种定量评判员，展示了其通用性和灵活性。与监督微调相比，该框架更高效，且在人类反馈有限的情况下更统计高效。", "conclusion": "通过在四个数据集上使用两种基础评判员进行的实验证明，定量的大语言模型评判员能够通过后续建模提高现有评判员的预测能力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21441", "html_url": "https://arxiv.org/abs/2505.21441", "title": "随机森林自编码", "title_en": "Autoencoding Random Forests", "authors": "Binh Duc Vu,Jan Kapar,Marvin Wright,David S. Watson", "background": "论文提出了一个基于非参数统计和谱图理论的基本方法来实现自动编码，目的是在低维度嵌入中以最优方式表示数据中的关系。该方法采用随机森林作为自动编码器，通过约束优化、分割重新标记和最近邻回归来解决问题。这些方法成功地反转了压缩管道，使得可以通过集成中组成的树学习的分割来从嵌入空间映射回输入空间。这种方法既可以用监督模型也可以用无监督模型，从而为条件或联合分布提供窗口。", "innovation": "提出了一个原理性的随机森林自编码方法，利用随机森林和非参数统计与谱图理论的基础结果来学习一个低维度的数据嵌入，能够有效地重建数据，且在常见正则条件下方法是一致的。该方法提供了一种新的视角来观察监督或无监督模型下的条件或联合分布，并展示了广泛的应用，如可视化、压缩、聚类和降噪，说明了该方法的简便性和实用性。", "conclusion": "该方法在多种数据类型（包括表格数据、图像和基因组数据）下均显示出广泛的适用性和实用性。其提供的解码器在常识性假设下具有通用一致性，为监督或无监督模型提供了一个新的视角，用于条件或联合分布的观察，并展示了强大的可视化、压缩、聚类和降噪等新工具。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18651", "html_url": "https://arxiv.org/abs/2505.18651", "title": "有关词汇嵌入中线性类比现象的产生", "title_en": "On the Emergence of Linear Analogies in Word Embeddings", "authors": "Daniel J. Korchinski,Dhruva Karkada,Yasaman Bahri,Matthieu Wyart", "background": "现有的词汇嵌入模型，如Word2Vec和GloVe，基于单词$i$和$j$在文本语料库中的共现概率$P(i,j)$构建词汇嵌入。由此生成的向量$W_i$不仅能够将语义相似的单词分组，还表现出显著的线性类比结构，例如$W_{\text{king}} - W_{\text{man}} + W_{\text{woman}} \thickapprox W_{\text{queen}}$。然而，这种类比结构的理论起源至今不明确。先前的研究已经观察到这条类比结构在矩阵$M(i,j) = \frac{P(i,j)}{P(i)P(j)}$的前几个奇异向量中已经出现，并且随着嵌入维度的增加而增强。", "innovation": "本文引入了一种理论生成模型，其中单词由二元语义属性定义，并从基于属性的交互中推导出共现概率。该模型能够分析每个额外维度嵌入的作用，以及方向性噪声对模型的影响。这种模型能够解释现有的类比类结构出现的现象，并对前人的观察结果进行了具体的理论描述。该模型基于Wiki百科和Mikolov等人引入的类比基准集的数据测量结果，能很好地与COCC统计数据相吻合，对各种形式的噪声具有鲁棒性。", "conclusion": "本文提出的理论生成模型从属性角度分析了词汇嵌入中的线性类比结构，通过数学推导明确解释了该现象，并且模型在具体的应用数据集上的表现具有较好的一致性与抗噪性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24161", "html_url": "https://arxiv.org/abs/2505.24161", "title": "Proxy Target: 桥接离散脉冲神经网络与连续控制之间的差距", "title_en": "Proxy Target: Bridging the Gap Between Discrete Spiking Neural Networks and Continuous Control", "authors": "Zijie Xu,Tong Bu,Zecheng Hao,Jianhao Ding,Zhaofei Yu", "background": "脉冲神经网络（SNNs）在神经形态硬件上提供低延迟和高能效的决策过程，因此在资源受限的边缘设备中进行强化学习（RL）很有吸引力。然而，大多数用于连续控制的RL算法是为人工神经网络（ANNs）设计的，特别是目标网络软更新机制，这与脉冲神经元的离散和非可微分动力学不兼容。这导致SNN训练不稳定且性能下降。为了解决这一问题，本文提出了一种新的代理目标框架，通过引入连续和可微分的动力学，使目标更新变得平滑，从而稳定学习过程。", "innovation": "本文提出了代理目标框架，以弥合离散SNN与连续控制算法之间的差距。代理网络在训练期间运行，但在部署时保持SNN的完全能源效率，没有额外的推理开销。经验证明，该框架在多种脉冲神经元模型上提高了稳定性和性能至高32%。这是首次使使用简单Leaky Integrate and Fire（LIF）神经元的SNN超过其ANN对手的方法，展示了SNN专用的RL算法的重要性，并为高性能低功耗的神经形态代理铺平了道路。", "conclusion": "本文的关键贡献是提出了代理目标框架，通过引入连续和可微分的动力学来解决SNN与连续控制算法之间的不匹配问题。实验结果证明了该框架的有效性，提高了SNN在连续控制任务上的稳定性和性能。这是首次使LIF神经元驱动的SNN超过ANN方法的连续控制方法，为未来低能耗高能效的神经形态代理的发展奠定了基础。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.23883", "html_url": "https://arxiv.org/abs/2505.23883", "title": "BioCLIP 2：通过层次对比学习扩展后的 Emergent Properties", "title_en": "BioCLIP 2: Emergent Properties from Scaling Hierarchical Contrastive Learning", "authors": "Jianyang Gu,Samuel Stevens,Elizabeth G Campolongo,Matthew J Thompson,Net Zhang,Jiaman Wu,Andrei Kopanev,Zheda Mai,Alexander E. White,James Balhoff,Wasila Dahdul,Daniel Rubenstein,Hilmar Lapp,Tanya Berger-Wolf,Wei-Lun Chao,Yu Su", "background": "大规模训练的基础模型展现了超出初始训练目标的新能力。通过大规模对比视语言训练，我们发现了生物视觉模型中的这些 Emergent 行为。我们为此数据集收集并训练了一个新的模型 BioCLIP 2，使其能够区分不同物种。尽管训练目标单一，BioCLIP 2 在多种生物视觉任务中表现出了惊人的准确度，如生境分类和特征预测。我们发现 BioCLIP 2 学习到的嵌入空间中存在一些 Emergent 属性。跨物种层面，不同物种的嵌入分布与功能性及生态学意义高度契合。在物种内部层面，不同个体（如生命周期阶段和性别）的差异不仅没有被削弱，还在物种之间差异的正交空间中得到了更好的区分。我们还提供了正式证明和分析，解释了这种层次监督和对比目标为何能促进这些 Emergent 属性的形成。并且，结果表明随着训练数据量的增加，这些属性变得越来越重要，从而产生了一个生物学上有意义的嵌入空间", "innovation": "我们创建了 TreeOfLife-200M，这是迄今为止最大且最为多样的生物有机体图像数据集。通过层次对比学习训练了一个名为 BioCLIP 2 的模型，该模型不仅能够区分不同的物种，即使是在单一的训练目标下，其在多种生物视觉任务中的表现仍显出极高的准确度。此外，我们还发现了 BioCLIP 2 在嵌入空间中的一些 Emergent 性能，这些性能随着更大规模训练数据的增加而愈发显著，产生了一个更具有生物学意义的嵌入空间。我们还提供了正式证明和分析来解释为何层级监督和对比目标会促进这些 Emergent 属性的发展。这项工作的一大创新在于揭示了大规模数据训练和层次对比学习相结合的重要性", "conclusion": "我们的实验结果表明，通过层次对比学习扩展训练数据规模可以显著地增强模型在新任务中的能力，并产生生物学上有意义的嵌入空间。这一发现为我们理解大规模预训练模型的 Emergent 行为提供了新的视角，也为生物视觉任务的模型训练提供了新的方法。进一步的研究可以通过更大的多模态数据集和更复杂的任务来验证我们的发现"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20612", "html_url": "https://arxiv.org/abs/2505.20612", "title": "Roboflow100-VL：针对视觉语言模型的多域目标检测基准", "title_en": "Roboflow100-VL: A Multi-Domain Object Detection Benchmark for Vision-Language Models", "authors": "Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri", "background": "视觉语言模型（VLMs）在大规模互联网数据上进行训练，在检测常见物体（如汽车、卡车和行人在内）时表现优异。然而，这些模型在面对不常出现在其预训练数据中的新概念、新任务和新的成像模态时，依然难以泛化。当前的研究主要集中在利用更多的视觉数据重新训练VLMs上，本文提出了一种新的方法，即通过注释说明包含少量视觉示例和丰富文本描述的方式，使VLMs与新的概念保持一致。为了验证这一方法的有效性，本文提出了Roboflow100-VL，一个包含100个多模态目标检测数据集的大规模集合，涵盖了VLM预训练中常见的概念以外的多样化概念。", "innovation": "提出了Roboflow100-VL，这是一个包含100个多模态目标检测数据集的大型集合，用于评估视觉语言模型在不同数据规模中的表现。该数据集中的概念在VLM预训练数据中并不常见，通过使用包含少量视觉示例和丰富文本描述的注释说明，来调整VLMs与新概念的一致性。通过在零样本、少样本、半监督和全监督设置下评估最新的模型，研究发现，即使是在挑战性的医学成像数据集上，VLMs的表现也一般不超过2%的零样本准确性，这强调了少样本概念调整的需求。", "conclusion": "本文通过Roboflow100-VL对视觉语言模型进行多领域的目标检测基准测试，表明现有模型在处理不常见概念方面存在不足，并通过实际的竞赛案例展示了利用少样本概念调整来改善模型效果的可能性。此外，研究还分享了最近在CVPR 2025 Foundational FSOD比赛中社区的反馈和见解，得奖团队的表现超过了基线17 mAP！所有的代码和数据集都可以从提供的链接下载。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04602", "html_url": "https://arxiv.org/abs/2506.04602", "title": "MVP-Shapley: 基于特征建模评估篮球最有价值球员", "title_en": "MVP-Shapley: Feature-based Modeling for Evaluating the Most Valuable Player in Basketball", "authors": "Haifeng Sun,Yu Xiong,Runze Wu,Kai Wang,Lan Zhang,Changjie Fan,Shaojie Tang,Xiang-Yang Li", "background": "电子竞技和多人在线游戏社区的快速增长突显了评估最有价值球员（MVP）的重要性。目前的评估方法大多不可解释且实用性不强。因此，建立一种可解释且实用的MVP评价方法具有挑战性。作者专注于游戏过程中的逐回合数据，旨在通过引入基于Shapley值的新MVP评价框架（\textbackslashoursys）解决这一问题，该框架涉及特征处理、胜败模型训练、Shapley值分配和基于玩家贡献的MVP排名确定。此外，作者优化算法使其与因果视角下的专家投票结果相吻合。", "innovation": "提出了一种基于Shapley值的新MVP评价框架（\textbackslashoursys），该框架通过处理特征、训练胜败模型、分配Shapley值并根据玩家贡献进行MVP排名确定来解决评价方法挑战。算法优化使其与因果视角下的专家投票结果相一致。通过使用NBA数据集和Dunk City Dynasty数据集验证了该方法的有效性，并实现了在线部署。", "conclusion": "研究表明，提出的新MVP评价框架在解释性和实用性方面优于现有方法，并且能够准确反映球员的贡献。该研究为MVP评价领域带来了新的视角和方法。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.23396", "html_url": "https://arxiv.org/abs/2506.23396", "title": "AICO：监督学习的特征显著性检验", "title_en": "AICO: Feature Significance Tests for Supervised Learning", "authors": "Kay Giesecke,Enguerrand Horel,Chartsiri Jirachotkulthorn", "background": "机器学习已成为科学、工业和政策领域的重要工具，算法现在可以用来识别化学性质、预测疾病风险、筛选借款人和指导公共干预措施。然而，这些预测能力往往是以透明度为代价的，我们通常不知道哪个输入特征真正驱动了模型的预测。在缺乏这种理解的情况下，研究人员无法得出可靠的科学结论，从业者无法确保公平性和问责制，而政策制定者也无法信任或治理基于模型的决策。尽管这项工作很重要，但现有的特征影响评估工具限制了很多——大多数没有统计保证，许多需要重新训练或替代建模，使其在大型现代模型中不可行。", "innovation": "我们引入了AICO，这是一种广泛适用的框架，将模型可解释性转换成一个高效的统计任务。AICO 通过隐藏特征的信息并测量随之产生的性能变化，来检验任何已训练的回归或分类模型是否真正提高了模型性能。这种方法提供了精确、有限样本的推断——精确的特征p值和置信区间——无需重新训练、替代建模或分布假设，使其适用于今天的大型算法。", "conclusion": "在控制实验和实际应用中（从信用评分到抵押行为预测），AICO 一再指出了驱动模型行为的关键变量，提供了一条快速而可靠的道路，以实现透明和可信的机器学习。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.16068", "html_url": "https://arxiv.org/abs/2507.16068", "title": "使用大型语言模型的多机器人团队组成协调", "title_en": "Compositional Coordination for Multi-Robot Teams with Large Language Models", "authors": "Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme", "background": "传统的多机器人协调依赖于任务特定和专家驱动的管道，其中自然语言的任务说明需要由领域专家人工翻译成数学公式、算法设计和可执行代码。这一传统过程劳动密集型且对非专家不友好，同时对任务要求的变化也不灵活。", "innovation": "本文提出了一种名为LAN2CB（语言到集体行为）的新框架，该框架利用大型语言模型（LLMs）来简化和通用化多机器人协调管道。LAN2CB通过两个核心模块将自然语言任务说明转化为多机器人系统的可执行Python代码：(1) 任务分析，将任务说明解析为行为树；(2) 代码生成，利用行为树和结构化知识库生成机器人控制代码。此外，该文还引入了一个自然语言任务说明的数据集，以支持开发和基准测试。", "conclusion": "在仿真和真实环境中的实验表明，LAN2CB能够从自然语言实现稳健且灵活的多机器人协调，显著减少手动工程努力，并在各种任务类型中实现广泛泛化。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19923", "html_url": "https://arxiv.org/abs/2506.19923", "title": "Prover Agent: 基于代理的正式数学证明框架", "title_en": "Prover Agent: An Agent-Based Framework for Formal Mathematical Proofs", "authors": "Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai", "background": "该研究背景在于当前自动定理证明领域需要将大型语言模型（LLMs）与形式证明助手，如Lean结合，以提高自动化证明的效率和效果。现有的方法大多使用样本预算高的大型语言模型，这限制了其在实际应用中的可扩展性。因此，该研究提出了Prover Agent，旨在通过结合小型语言模型（SLMs）和形式证明助手，在保持较高成功率的同时降低样本预算，解决大规模数学证明中的挑战性问题。", "innovation": "Prover Agent 的创新之处在于提出了一个新颖的代理框架，它融合了形式证明助手Lean与大型语言模型。具体创新如下：1. 结合了一个非正式推理的人工智能模型与一个形式证明模型。2. 不仅生成辅助引理，还生成与当前形式证明相关的辅助事实和特殊情况。3. 在MiniF2F基准测试中取得了88.1%的成功率，达到业界使用小型语言模型的最新技术水平，并且样本预算远低于之前的解决方案。4. 通过理论分析和案例研究，详细说明了所生成的辅助引理在解决难题中的贡献机制。", "conclusion": "Prover Agent证明了与小型语言模型结合的形式证明助手在解决数学证明问题中的有效性和效率。它不仅提升了自动化证明技术的适用性和可扩展性，还为未来类似的研究提供了新的思路和方法。此外，作者公开了Prover Agent的代码，以便其他研究人员进行进一步的探索和改进。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.20114", "html_url": "https://arxiv.org/abs/2506.20114", "title": "从树集萃取可解释模型：计算与统计视角", "title_en": "Extracting Interpretable Models from Tree Ensembles: Computational and Statistical Perspectives", "authors": "Brian Liu,Rahul Mazumder,Peter Radchenko", "background": "树集合是非参数方法，因其精确性和对复杂交互捕获能力而广受认可。尽管这些模型在预测上表现出色，但它们的可解释性较差，并且可能无法揭示数据中的有用关系。本文探讨如何从树集合中提取精简的决策规则集，这些规则集准确且可以手动检查，揭示预测变量与响应变量之间的关系，从而提高模型的可解释性。本文提出了一种新颖的估计器，能够同时控制提取规则的数量和每个规则的交互深度，从而提高准确性。此外，本文还开发了专门的精确算法和近似算法以解决该估计器下的优化问题，并计算正则化路径，这是一系列对应于不同模型大小的解决方案。此文还建立了新型的非渐进预测误差界限，对比本方法与最优数据依赖线性组合的性能，证明估算器的大样本预测性能与最优解相当。最后，通过实验验证，本文所提出的方法比现有的规则提取算法更优。", "innovation": "本文的新颖之处在于提出了一种估计器，能够同时控制从树集合中提取规则的数量和每个规则的交互深度，提高了准确性。此外，本文还开发了专门的精确算法和近似算法以解决该估计器下的优化问题，并计算正则化路径，还建立了新型的非渐进预测误差界限，论证了本方法的大样本预测性能与最优解相当，通过实验验证，本文所提出的方法也比现有的规则提取算法更优。", "conclusion": "本文研究了从树集合中提取可解释模型的问题，并提出了一种新颖的估计器。该估计器不仅能够准确地提取出规则，还能控制规则的数量和深度，提高了模型的可解释性。此外，本文还提出了一种计算正则化路径的近似算法，并建立了预测误差界限。实验结果表明，本文方法在规则提取方面表现优于现有算法。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06795", "html_url": "https://arxiv.org/abs/2507.06795", "title": "ixi-GEN：通过领域自适应持续预训练实现高效工业级sLLMs", "title_en": "ixi-GEN: Efficient Industrial sLLMs through Domain Adaptive Continual Pretraining", "authors": "Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon", "background": "开源大型语言模型(Large Language Models, LLMs)为企业的应用提供了新的机会，但许多组织仍然缺乏部署和维护大型模型所需的基础设施。因此，小型语言模型(Small LLMs, sLLMs)因其有限的性能限制成为了实践中可行的替代方案。尽管已经探索了域自适应持续预训练(Domain Adaptive Continual Pretraining, DACP)技术以用于领域适应，但在商业环境中的应用仍然被低估了。本研究旨在验证基于DACP的模型在不同基础模型和应用领域的有效性，开发出应用DACP的小型语言模型(ixi-GEN)。通过广泛的实验和实际应用评估，表明ixi-GEN模型在目标领域取得了显著的性能提升，同时保留了通用能力，提供了企业级部署的高效和可扩展解决方案。", "innovation": "开发了一种基于DACP的小型语言模型（ixi-GEN），验证了其在不同基础模型和应用领域中的有效性。ixi-GEN模型在目标领域的性能显著提升，保持了通用能力，为企业的应用提供了成本效益高且可扩展的解决方案。这个研究扩展了DACP技术在商业环境中的应用，展示了其在实际应用中的潜力。", "conclusion": "通过基于DACP的方法，ixi-GEN模型在不同基础模型和领域中取得了优异的性能表现和通用能力保留。这种解决方案为企业级部署提供了高效、可扩展的途径，是一种成本效益高的小型语言模型应用方案。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.16027", "html_url": "https://arxiv.org/abs/2508.16027", "title": "由变压器在非稳态强化学习中的最优动态遗憾", "title_en": "Optimal Dynamic Regret by Transformers for Non-Stationary Reinforcement Learning", "authors": "Baiyuan Chen,Shinji Ito,Masaaki Imaizumi", "background": "变压器在众多领域中已经展示了卓越的表现，尤其是在理论上和实践中都证明了其可以进行上下文中的强化学习，但在非稳态环境下其行为尚未充分理解。本研究通过实验表明，变压器可以在非稳态环境中达到接近最优的动态遗憾边界，并能够在上下文学习中学习到处理非稳态环境的策略。", "innovation": "本研究展示了变压器能够实现非稳态强化学习中的近最优动态遗憾边界，证明了变压器能够近似处理非稳态环境的策略并在上下文学习中学习到这种策略。实验还进一步证实了变压器在非稳态环境中的表现能够与甚至超越现有专家算法的性能。", "conclusion": "本研究结果显示，变压器在非稳态强化学习环境中能够达到近最优的动态遗憾，证明了其在非稳态环境处理策略上的有效性，并展示了其在实际应用中的潜力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.03220", "html_url": "https://arxiv.org/abs/2507.03220", "title": "Symbiosis：多适配器推理和微调", "title_en": "Symbiosis: Multi-Adapter Inference and Fine-Tuning", "authors": "Saransh Gupta,Umesh Deshpande,Travis Janssen,Swami Sundararaman", "background": "PEFT技术被广泛用于模型微调，但现有框架在多适配器推理或微调时存在多种问题。这些问题包括需要为每个微调任务部署单独的基础模型实例，从而导致GPU内存消耗过度和GPU使用率低；现有的推理平台虽能为多个PEFT适配器提供服务，但不允许独立资源管理或混合使用不同的PEFT方法，也不能有效利用异构加速器，并且未能为希望保护隐私的用户保密其微调参数。", "innovation": "Symbiosis通过使基础模型作为服务部署，解决了上述问题，使基础模型层可以在多个推理或微调过程中共享。Symbiosis采用分裂执行技术，将客户特定的适配器层和基础模型层的执行分离，提供给客户端灵活性以管理资源、选择微调方法，从而实现其性能目标。该方法对模型透明，大部分transformers库中的模型都能直接使用，展示了同时在8个GPU上微调20个Gemma2-27B适配器的应用实例。", "conclusion": "Symbiosis能够提高多适配器推理和微调的效率和灵活性，降低资源消耗，提高隐私保护，为未来的大规模模型部署提供一种新的一体化解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.14757", "html_url": "https://arxiv.org/abs/2508.14757", "title": "分布对抗攻击与深度对冲的训练", "title_en": "Distributional Adversarial Attacks and Training in Deep Hedging", "authors": "Guangyi He,Tobias Sutter,Lukas Gonon", "background": "在本文中，我们研究了在分布变化下经典深度对冲策略的鲁棒性，通过利用对抗攻击的概念。我们首先展示了标准的深度对冲模型在输入分布的小波动下高度脆弱，导致性能显著下降。", "innovation": "我们提出了一个定制的对抗训练框架，以提高深度对冲策略的鲁棒性。这种方法将点对点对抗攻击扩展到分布式设置，并提出了对抗优化问题在沃特森球上的计算可处理重新表述。这使我们能够高效地训练对分布扰动具有鲁棒性的对冲策略。通过广泛的数值实验，我们表明对抗训练的深度对冲策略在离样本性能和对模型误指定的鲁棒性方面始终优于其经典对应策略。", "conclusion": "我们的研究结果建立了一个在实际市场不确定性下实现深度对冲鲁棒性的实用和有效框架。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.14203", "html_url": "https://arxiv.org/abs/2509.14203", "title": "平均收益鲁棒马尔可夫决策过程的贝尔曼最优性", "title_en": "Bellman Optimality of Average-Reward Robust Markov Decision Processes with a Constant Gain", "authors": "Shengbo Wang,Nian Si", "background": "尽管学习和最优控制下的鲁棒马尔可夫决策过程（MDPs）受到了越来越多的关注，但现有的理论、算法和应用大多集中在有限期或折扣模型上。长期平均收益制定的模型虽然在许多运筹学和管理领域很自然，但仍未得到充分探索。主要原因在于动态规划的基础技术性很强且尚未完全理解，仍有多个根本问题悬而未决。", "innovation": "本文通过分析恒定增益设置，为长期平均收益鲁棒MDPs提供了一个通用框架。主要创新点包括研究包含信息不对称（控制器与S-矩形对手）的平均收益鲁棒控制问题。重点分析了恒定增益鲁棒贝尔曼方程，探讨了方程解的存在性和其与最优平均收益的关系。还指出了确保方程解存在的单向弱通信条件。这一发现扩展了平均收益鲁棒MDPs的动态规划理论，并为在长期平均标准下的运营环境中稳健的动态决策奠定了基础。", "conclusion": "本文的研究成果扩展了平均收益鲁棒MDPs的动态规划理论，并为长期平均标准下的稳健动态决策提供了理论基础。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.11508", "html_url": "https://arxiv.org/abs/2509.11508", "title": "SafeDiver：基于多代理强化学习方法的自动水下航行器-水面航行器协作潜水员通信", "title_en": "SafeDiver: Cooperative AUV-USV Assisted Diver Communication via Multi-agent Reinforcement Learning Approach", "authors": "Tinglong Deng,Hang Tao,Xinxiang Wang,Yinyan Wang,Hanjiang Luo", "background": "随着水下人类活动的增加，对水下通信服务的需求显著增加。现有的水下潜水员通信方法由于固有的缺点和复杂的水下环境面临挑战。为解决此问题，本文提出了一种利用海上无人系统辅助潜水员进行可靠高速通信的方案。多个自主水下航行器（AUV）配备有光学和声学多模式通信设备作为中继节点，根据潜水员活动区域的变化提供适应性通信服务。通过使用多代理强化学习（MARL）方法控制AUV的协同运动，实现潜水员之间的高速和可靠数据传输。同时，采用具有按需部署和广泛覆盖优势的无人水面船（USV）作为表面中继节点，协调和转发来自AUV的信息，并控制AUV适应性选择中继USV节点进行数据传输，从而实现潜水员与表面平台之间的高质量通信。", "innovation": "本文提出了一种创新的多代理强化学习（MARL）方案，通过海上无人系统（USV和AUV）的协作，实现潜水员的可靠高速通信。此方案结合了AUV和USV的优点，通过MARL控制其协同运动，自动选择最合适的中继节点，从而提高通信质量并适应复杂的水下环境变化。", "conclusion": "通过仿真实验验证，提出的方案能够有效地实现潜水员的可靠和高速通信，展示了海上无人系统在水下通信服务中的应用潜力。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.24544", "html_url": "https://arxiv.org/abs/2509.24544", "title": "通过梯度下降训练的浅层神经网络在无限宽度极限下定量化向高斯过程的收敛", "title_en": "Quantitative convergence of trained single layer neural networks to Gaussian processes", "authors": "Eloy Mosig,Andrea Agazzi,Dario Trevisan", "background": "以往的研究已经表明，在广泛设置下，通过梯度下降训练的浅层神经网络可以在无限宽度的极限下定性地收敛到相应的高斯过程。然而，关于有限宽度下的精度估计仍然有限，尤其是在训练过程中。本研究致力于提供网络输出与高斯近似之间的二次 Wasserstein 距离的显式上界，展示网络宽度的影响。此外，研究还探讨了架构参数（如宽度和输入维度）和训练动态对收敛的影响。", "innovation": "本研究提供了在训练过程中浅层神经网络输出与高斯近似之间的精确量化估计。具体来说，研究给出了在任何训练时间 $t \neq 0$ 时的显式上界，显示了网络宽度的多变量衰减，并量化了节点数量、输入维度等架构参数影响收敛以及训练动力学对近似误差的影响。", "conclusion": "本研究量化了如何通过网络宽度等架构参数以及训练过程中的动态来影响从训练的浅层神经网络到高斯过程的收敛，极大地深化了我们对这一过程的理解。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.16451", "html_url": "https://arxiv.org/abs/2509.16451", "title": "适应回归优化中的过拟合问题", "title_en": "Overfitting in Adaptive Robust Optimization", "authors": "Karl Zhu,Dimitris Bertsimas", "background": "自静态鲁棒优化发展以来，适应性鲁棒优化（ARO）提供了一种新的框架，它允许决策依赖于一些已实现的不确定性，从而可以是解决不确定性条件下决策的问题。然而，这种适应性策略在面对非预期的不确定性实现时，可能会导致约束条件间的依赖关系增加，使得罗布鲁系统变得脆弱。这种现象类似于机器学习中的过拟合问题。", "innovation": "论文提出了一种新的方法，即为不同约束条件赋予特定的不确定集大小，同时为更加苛刻的约束提供更强的概率保证。这样不仅可以缓解过拟合问题，还可以实现鲁棒性和适应性的平衡。", "conclusion": "通过将这种问题与机器学习中的过拟合问题进行类比，本文提出了一种调节适应性鲁棒优化中的约束策略，进而实现鲁棒性和适应性的兼顾。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05013", "html_url": "https://arxiv.org/abs/2510.05013", "title": "机器人通过自主探索实现行动和语言发展的好奇心驱动发展", "title_en": "Curiosity-Driven Development of Action and Language in Robots Through Self-Exploration", "authors": "Theodore Jerome Tinker,Kenji Doya,Jun Tani", "background": "人类婴儿通过逐步发展学习语言和动作，并从少量学习示例中表现出强大的泛化能力。相比之下，最近的大规模语言模型需要接收到数以亿计的训练标记才能达到类似水平的泛化能力。这种高效发展学习的机制是什么？本文通过让机器人通过自主探索学习执行与祈使句相应的动作（例如，推红色的立方体），来探讨这个问题。", "innovation": "本文通过整合主动推断框架与强化学习，实现好奇心驱动的发展学习。研究表明，增加组合元素的数量会显著提高泛化能力；好奇心驱动的探索与运动噪音的结合比没有好奇心驱动的学习表现更好；在组成性泛化出现之前，程序性的句式动作配对已经存在；更简单的动作会首先发展，而更复杂的涉及这些前提条件的动作会稍后发展。", "conclusion": "这些结果揭示了婴儿高效发展学习可能的机制，并为发展心理学中的发现提供了计算上的一致性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25033", "html_url": "https://arxiv.org/abs/2509.25033", "title": "VT-FSL: 通过LLMs实现视觉与文本交叉的少样本学习", "title_en": "VT-FSL: Bridging Vision and Text with LLMs for Few-Shot Learning", "authors": "Wenhao Li,Qiangchang Wang,Xianjing Meng,Zhibin Wu,Yilong Yin", "background": "少样本学习（FSL）旨在仅从少量标记的支持样本中识别新的概念。近期的研究通过引入附加语义信息或设计复杂的语义融合模块来增强支持特征，但这些方法仍然存在由于缺乏实际实例的语义对接而引发的语义错觉问题，导致误导性的指导和高昂的修正成本。", "innovation": "本文提出了一种新的框架——利用大型语言模型将视觉和文本联系起来进行少样本学习（VT-FSL），该框架通过大型语言模型和支撑图像构造精确的跨模态提示，通过几何感知对齐无缝整合。VT-FSL框架包括跨模态迭代提示（CIP）和跨模态几何对齐（CGA）。具体而言，CIP在单步结构推理过程中同时条件化大型语言模型在类别名称和支撑图像上以生成精确的类描述。CGA则通过最小化它们所覆盖的3维平行体的核体积，联合对融合后的文本、支撑图像和合成图像的表示进行对齐，捕获所有表示之间的全局和非线性关系，实现结构化的多模态整合。", "conclusion": "VT-FSL方法在十个不同的基准测试中建立了新的最先进的性能，包括标准、跨域和细粒度的少样本学习场景。代码可在此处访问：this https URL."}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.25271", "html_url": "https://arxiv.org/abs/2509.25271", "title": "RADAR: 一种基于角色专业化协作的风险感知动态多智能体框架，用于大规模语言模型的安全评估", "title_en": "RADAR: A Risk-Aware Dynamic Multi-Agent Framework for LLM Safety Evaluation via Role-Specialized Collaboration", "authors": "Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li", "background": "现有的大规模语言模型（LLMs）的安全评估方法存在固有的局限性，包括评价者的偏差和由于模型同质性导致的检测失败，这些都削弱了风险评估过程的稳健性。现有方法亟需改进，以提供更加全面和公正的风险评估机制", "innovation": "本文提出了一种新的理论框架，将潜在的风险概念空间分解为三个互斥子空间：明确风险子空间（直接违反安全准则的内容）、隐含风险子空间（需要上下文推理才能识别的潜在恶意内容）和非风险子空间。此外，提出了RADAR，一种通过四种专门角色的多轮辩论机制和动态更新机制实现自我进化的多智能体协作评估框架，可以全面覆盖明确和隐含的风险，并减轻评价者的偏差。该框架在挑战性测试集和公共基准上的实验表明，RADAR在准确性、稳定性和自我评估风险敏感性等多个维度上明显优于基线评估方法，尤其在风险识别准确率方面提升了28.87%", "conclusion": "RADAR框架通过多智能体协作和动态机制显著提高了大规模语言模型安全评估的全面性和公正性，为安全评估方法的改进提供了新的思路和方法"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.19271", "html_url": "https://arxiv.org/abs/2509.19271", "title": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "title_en": "WolBanking77: Wolof Banking Speech Intent Classification Dataset", "authors": "Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione", "background": "近年来，意图分类模型取得了显著的进步，但这些研究主要集中在高资源语言的数据集上。这导致了低资源语言及高文盲率地区的研究空白，因为这些语言更多是以口语形式存在而非读写形式。在塞内加尔，例如，沃洛夫语被90%的人口使用，而国家文盲率则高达42%。沃洛夫语实际上在西非地区超过1000万人使用。为解决这些问题，本文提出了沃洛夫语银行语音意图分类数据集（WolBanking77），以用于意图分类的相关学术研究。", "innovation": "本文基于沃洛夫语开发了一个专门的数据集沃洛夫语银行语音意图分类数据集（WolBanking77），包含了9,791条文本句子和超过4小时的语音数据，填补了低资源语言和高文盲率地区在该领域的研究空白。另外，本文对基于WolBanking77的数据集进行了文本和语音最先进的模型实验，结果显示出很大的潜力，并对数据集的内容进行了深入探讨，包括基准F1分数和词错误率等指标，以及不同模型之间进行了比较。", "conclusion": "WolBanking77数据集目前包含了9,791条银行领域中的文本句子和超过4小时的语音数据。本文还对比了使用该数据集进行训练的自然语言处理和自动语音识别模型的基准F1分数和词错误率指标，并展示了非常有希望的结果。同时，本文对数据集进行了深入分析，提供的代码和数据集可在指定链接处获取。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.02253", "html_url": "https://arxiv.org/abs/2510.02253", "title": "DragFlow: 通过区域监督释放DiT先验以实现拖动编辑", "title_en": "DragFlow: Unleashing DiT Priors with Region Based Supervision for Drag Editing", "authors": "Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong", "background": "拖动图像编辑长期以来因其目标区域产生的失真而受到限制，主要原因是早期基础模型Stable Diffusion的先验条件不足以将优化的潜变量重新投影到自然图像流形上。随着从UNet基于的DDPMs转向更加模块化的DiT（如SD3.5，FLUX）并且通过流匹配增强了生成先验条件，拖动图像编辑任务已经得到了广泛的应用。然而，这一更强的先验条件仍未应用到拖动图像编辑中，这也是该文的研究背景。", "innovation": "该研究提出了首个利用FLUX丰富先验条件的拖动图像编辑框架DragFlow，解决直接在DiT上进行点基拖动编辑效果不佳的问题。DragFlow采用区域基编辑方案，并结合预训练的开放域个性化适配器（如IP-Adapter），利用仿射变换增强特征监督，并通过梯度掩码引入硬约束保持背景保真度。此外，该文还引入了一个多模态大型语言模型（MLLMs）来解决任务歧义，并通过构建一个以区域级拖动指令为基准的新数据集ReD Bench进行评估。", "conclusion": "DragFlow在拖动图像编辑的多种任务上表现出色，超过点基和区域基基准模型，达到拖动图像编辑的新技术水平。实验结果也表明DragFlow通过区域基监督和Flux丰富先验条件实现了显著提升，并将代码和数据集将在文章发表后公开提供。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.06259", "html_url": "https://arxiv.org/abs/2510.06259", "title": "超越静态知识信使：迈向多变、公平和可扩展的医疗人工智能联邦学习", "title_en": "Beyond Static Knowledge Messengers: Towards Adaptive, Fair, and Scalable Federated Learning for Medical AI", "authors": "Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel,Iftekhar Haider", "background": "医疗人工智能在隐私保护协作学习中面临着挑战，需要在不同医疗机构之间保持公平。当前的联邦学习方法存在如下问题：静态架构、缓慢收敛（45-73轮）、对小机构的公平不足以及可扩展性限制（仅支持15个客户端）。", "innovation": "我们提出了自适应公平联邦学习（AFFL），通过三大创新实现改进：（1）自适应知识信使能够根据异质性和任务复杂度动态调整容量，（2）公平意识蒸馏利用影响加权聚合提高公平性，（3）课程引导加速可以减少轮次达60-70%。理论分析提供了ε公平性的收敛保证，实现了O(T^{-1/2}) + O(H_max/T^{3/4})的速度。框架支持多元化模态集成，同时保持HIPAA和GDPR合规性。此外，还提出了MedFedBench基准套件以标准化评估六个医疗健康维度：收敛效率、机构公平性、隐私保护、多模态集成、可扩展性和临床部署准备度。", "conclusion": "本研究提出了一个包含七个问题的研究议程、24个月的实施路线图以及迈向普及医疗人工智能的道路。在经济模型中，农村医院可能实现400-800%的ROI，而学术中心的性能提升达15-25%。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08609", "html_url": "https://arxiv.org/abs/2510.08609", "title": "选择减少依赖于过时和易受攻击依赖的最佳方法：锁定还是浮动？", "title_en": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?", "authors": "Imranur Rahman,Jill Marley,William Enck,Laurie Williams", "background": "开发人员经常使用版本约束来指定项目依赖关系的可接受版本。锁定依赖关系可以减少中断变更的可能性，但需要手动管理过时和脆弱依赖关系的替换。另一方面，浮动可以自动获取错误修复和安全修复，但存在引发中断变更的风险。安全从业者建议锁定依赖关系，以防止软件供应链攻击，如恶意包更新。然而，由于锁定是最严格的版本约束，它最可能导致依赖关系过时。尽管如此，在不同版本约束类型下，依赖关系成为过时或脆弱依赖关系的可能性变化尚不清楚。", "innovation": "研究通过大规模的实证评估，识别了依赖关系版本约束使用的趋势和开发人员版本约束类型变化的模式，并使用生存分析建模依赖状态转换。结果发现，最常见的使用版本约束类型是浮动次要版本，锁定是第二常见的。研究还发现，浮动主要版本最不可能导致依赖关系过时，而浮动次要版本最不可能导致依赖关系脆弱。“", "conclusion": "研究结果表明，在减少依赖关系的过时和脆弱性方面，浮动与锁定区别不大。浮动次要版本最为常见，但浮动主要版本可以最大程度地减少依赖关系过时的可能性，而浮动次要版本可最大程度地减少依赖关系脆弱的可能性。此研究可帮助开发人员根据实际情况做出知情的依赖关系版本约束选择。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.13894", "html_url": "https://arxiv.org/abs/2510.13894", "title": "贝叶斯还是海森堡，谁（哪）是规则制定者？", "title_en": "Bayes or Heisenberg: Who(se) Rules?", "authors": "Volker Tresp,Hang Li,Federico Harjes,Yunpu Ma", "background": "尽管量子系统通常由量子状态矢量描述，但研究表明，在某些情况下，这些系统的测量过程可以重新表述为以概率状态矢量表示的概率方程。这些概率表示可以近似为张量脑（TB）模型中的神经网络动力学。张量脑是一种用于建模大脑感知和记忆的新颖框架，它提供了一种生物启发的方法，有效地将生成的符号表示整合到推理过程中。", "innovation": "提出了一种新颖的方法，即将量子系统的测量过程从量子状态矢量重新表述为概率状态矢量的概率方程。进一步地，这些概率方程可以被TB模型中的神经网络动态近似。TB模型提供了一种生物启发的机制，将生成的符号表示高效地整合到推理过程中。", "conclusion": "研究发现，张量脑模型能够提供一种新的角度来理解和模拟量子系统的测量过程，并将生成的符号表示有效地整合到推理过程中。这种新的描述方式有效地结合了量子力学和机器学习领域的研究，为理解和处理复杂系统的数学描述开辟了新的可能性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17111", "html_url": "https://arxiv.org/abs/2510.17111", "title": "高效视觉-语言-动作模型在实体操作中的系统综述", "title_en": "Efficient Vision-Language-Action Models for Embodied Manipulation: A Systematic Survey", "authors": "Weifan Guan,Qinghao Hu,Aosheng Li,Jian Cheng", "background": "视觉-语言-动作（VLA）模型通过将自然语言指令和视觉观察映射到机器人动作，扩展了视觉-语言模型的领域。尽管这类模型具备一定的能力，但由于其巨大的计算和内存需求，它们在如搭载移动执行机构等边缘平台上面临重大挑战，这些平台需要实时性能。这一冲突已成为最近研究的焦点。", "innovation": "本文提供了一项对提高VLA模型效率的方法进行系统性回顾，重点关注减少延迟、内存占用以及训练和推理成本。将现有解决方案归类为四个维度：模型架构、感知特征、动作生成和训练/推理策略，总结了每个类别中的代表性技术。", "conclusion": "最后，讨论了未来趋势和开放挑战，强调了推进高效实体智能的方向。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08872", "html_url": "https://arxiv.org/abs/2510.08872", "title": "GTAlign:游戏论对LLM助手的准则对等性以实现共同福利", "title_en": "GTAlign: Game-Theoretic Alignment of LLM Assistants for Mutual Welfare", "authors": "Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You", "background": "大型语言模型（LLMs）在推理方面取得了显著进展，但在诸如写作、信息检索或提供实际指导等任务中，有时会生成对于用户来说不够理想的回应。传统的对齐实践通常假设最大化模型奖励也最大化用户福利，但在实践中这种假设经常失败：模型可能会过度详细说明或生成过于冗长的推理，而用户可能更倾向于简洁的答案。这种行为类似于囚徒困境，在这种困境中，个体理性选择导致了社会上不理想的结果。基本挑战是缺乏一种能同时为LLM和用户相互带来益处的决策机制。", "innovation": "该论文提出了一种名为Game-Theoretic Alignment (GTAlign) 的对齐框架，将博弈论决策机制整合到推理和训练中。在推理过程中，模型将用户-LLM交互视为一种策略游戏，并在推理链中构建收益矩阵来评估双方的福利，然后选择互惠互利的动作。在训练过程中，引入了联合福利奖励，以强化协作回应，并使模型行为与社会有效结果相一致。此外，还引入了一种推理技术，利用博弈理论推理动态调整LLM的回应，以应对LLM服务定价策略的变化。广泛的实验表明，GTAlign在不同任务中显著提高了推理效率、回答质量和双方福利，相比基准模型有明显改进。", "conclusion": "GTAlign在多个任务中显示出显著改进的推理效率、回答质量和双方福利，相比基准模型有通过引入博弈论决策机制在推理和训练中实现相互对齐的巨大优势。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17451", "html_url": "https://arxiv.org/abs/2510.17451", "title": "计算VC维参数化的复杂性", "title_en": "The Parameterized Complexity of Computing the VC-Dimension", "authors": "Florent Foucaud,Harmender Gahlawat,Fionn Mc Inerney,Prafullkumar Tale", "background": "VC维是集系统（或超图）的一个中心复杂性度量，广泛应用于机器学习的多个领域。文章探讨了计算VC维的复杂性，并提出了几个新的研究成果。", "innovation": "本文证明了计算VC维的朴素算法在指数时间假设下是渐近紧致的。当参数化为超图的最大度和维度时，文章提供了1-添加剂固定参数近似算法和固定参数算法，且认为这些是此类可利用结构参数的唯一选择。同时，针对图提供的算法在树分解宽度上的复杂度比相关问题要优越，不需要双指数依赖。", "conclusion": "文章在固定参数复杂性的框架下研究了计算VC维的复杂性，通过理论证明和算法设计，提供了在特定参数下计算VC维的效率保证，并指出了现有参数化的有效性和局限性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15786", "html_url": "https://arxiv.org/abs/2510.15786", "title": "DexCanvas：将人类示范与机器人学习连接起来进行灵巧操作", "title_en": "DexCanvas: Bridging Human Demonstrations and Robot Learning for Dexterous Manipulation", "authors": "Xinyue Xu,Jieqiang Sun,Jing(Daisy)Dai,Siyuan Chen,Lanjie Ma,Ke Sun,Bin Zhao,Jianbo Yuan,Sheng Yi,Haohua Zhu,Yiwen Lu", "background": "研究人员正在寻找一种有效的方式，通过真实人类示范来训练机器人进行灵巧操作，并且能够涵盖各种技能类别并且验证物理接触的准确性。目前，还没有一个大规模的真实人类互动数据集能够结合这些要求，这是一个急需解决的问题。", "innovation": "开发了一个名为DexCanvas的大型混合真实-合成人类操作数据集，包含了7000小时的灵巧手-物体交互数据，这些数据是从70小时的真实人类示范中提取出来的，并按照Cukosky分类法组织为21种基本操作类型。这个数据集首次结合了大规模的真实示范、基于现成分类法的系统技能覆盖，以及通过物理验证的接触注释。而且，利用强化学习训练了通过物理仿真控制的机器灵巧手，以此再现人类示范并发现产生观察到物体运动的接触力。", "conclusion": "DexCanvas 数据集能够促进机器人操作学习、接触丰富的控制以及不同手形的技能转移研究。这个数据集的独特之处在于它不仅包含大规模的真实人类示范，还系统的覆盖了操作技能，并且通过物理仿真验证了接触信息的准确性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15530", "html_url": "https://arxiv.org/abs/2510.15530", "title": "VO-DP: 仅视觉自适应扩散策略用于基于语义和几何特征的机器人操作", "title_en": "VO-DP: Semantic-Geometric Adaptive Diffusion Policy for Vision-Only Robotic Manipulation", "authors": "Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He", "background": "在模仿学习的背景下，视觉运动驱动的扩散策略学习是机器人操作的主要研究方向之一。现有大多数方法依赖于点云作为观测输入，并通过点云特征学习构建场景表示，从而实现显著的准确性。然而，现有文献中对基于视觉的单视图解决方案探讨不足，尽管这些方法具有巨大的潜力。", "innovation": "本文提出了一种基于视觉且单视图的扩散策略学习方法（VO-DP），它利用预训练的视觉基础模型实现语义和几何特征的有效融合。VO-DP利用VGGT的中间特征结合DINOv2的语义特征和交替注意模块的几何特征，并通过交叉注意和CNN的空间压缩形成策略头部的输入。实验表明，VO-DP在仿真任务中不仅显著优于基于视觉的基线方法DP，同时在真实世界任务中也大幅超越基于点云的方法DP3，性能更稳定。", "conclusion": "进一步的鲁棒性评估证实，VO-DP在各种条件下（如颜色、大小、背景和照明）仍然高度稳定。最后，我们开源了一个用于机器人操作的训练库，它基于Accelerate构建，支持多机器和多GPU并行训练以及混合精度训练。该库与如DP、DP3和VO-DP等视觉运动策略兼容，并支持RoboTwin模拟器。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.12988", "html_url": "https://arxiv.org/abs/2510.12988", "title": "基于行为生物识别的虚拟现实用户熟悉度自动检测", "title_en": "Behavioral Biometrics for Automatic Detection of User Familiarity in VR", "authors": "Numan Zafar,Priyo Ranjan Kundu Prosun,Shafique Ahmad Chaudhry", "background": "随着虚拟现实（VR）设备越来越多地融入日常生活场景，没有先验经验的用户将越来越多地接触和使用VR系统。自动检测用户对VR作为交互媒介的熟悉程度，可以实现实时、自适应的培训和界面调整，减少用户的挫败感并提高任务表现。因此，研究人员探索了通过分析用户在基于密码的门锁开启任务中的手部运动模式来自动检测VR熟悉度的方法，该任务在协作虚拟环境中（如会议室、办公室和医疗空间）是一个广泛认可的交互方式。这项研究通过将熟悉和不熟悉VR的用户进行分组并使用控制器和手部跟踪交互进行任务操作，展示了手部运动生物识别在实时检测关键VR应用中的用户熟悉度方面的潜力与前景。", "innovation": "该研究利用先进的深层分类器，通过分析基于密码的门锁开启任务（此任务在现实世界中常见的手动键盘输入任务与之类似）中的手部运动模式来自动检测用户的VR熟悉度。研究结果表明，其方法在手部跟踪和控制器交互中的准确率分别达到了92.05%和83.42%，并且在不同交互模式的混合设备评估中准确率高达94.19%，尤其是在交叉设备评估中，使用控制器数据训练的分类器在手部跟踪数据上的测试准确率为78.89%。这些结果证明了手部运动生物识别在关键VR应用中实时检测用户熟悉度的潜力，为个性化和自适应的VR体验开辟了前景。", "conclusion": "本研究表明，通过分析用户的手部运动模式，可以实现对VR熟悉度的实时检测，在混合设备和交叉设备评估中均显示出高准确度。这种技术的应用将有助于为不同水平的VR用户提供更加个性化的互动体验，提高总体的用户体验质量和沟通效率。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17472", "html_url": "https://arxiv.org/abs/2510.17472", "title": "认证自我一致性：无标签训练和测试时训练的统计保证及可靠推理", "title_en": "Certified Self-Consistency: Statistical Guarantees and Test-Time Training for Reliable Reasoning in LLMs", "authors": "Paula Cordero-Encinar,Andrew B. Duncan", "background": "尽管近期的技术进步，如自我一致性（self-consistency）和测试时强化学习（TTRL）能够增强大语言模型（LLMs）的可靠性，但这些机制的工作原理及其统计保障仍不明确。本文探讨了一种统一框架，以提供LLMs推理的可认证推理，指出多数投票可以提供自我一致性的统计证书，并且在轻微的假设下，聚合的答案将随模型终端分布的模式以高概率相一致。通过推导有限样本和持续有效的集中界限来量化这一点信心，并引入马氏主要证书（MMC），一种序列停止规则，可以自适应地决定何时收集足够样本。", "innovation": "本文提出了统一框架来提供LLMs推理的可认证推理，揭示了多数投票可以提供自我一致性的统计证书。推导了有限样本和持续有效的集中界限来量化这种信心，并提出了马氏主要证书（MMC），一种序列停止规则。此外，证明了诸如TTRL之类的无标签后训练方法通过指数倾向的方式强化答案分布，以减少认证所需的样本数量。基于这些洞见，提出了新的后训练目标，明确优化了这种精确度和偏差之间的权衡。", "conclusion": "这些结果不仅解释了自一致性和TTRL两种中央测试时缩放策略，还在无标签、可认证可靠性推理的大语言模型中提供了一个统一的统计框架。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17697", "html_url": "https://arxiv.org/abs/2510.17697", "title": "多智能体强化学习中的靶向干预原则", "title_en": "A Principle of Targeted Intervention for Multi-Agent Reinforcement Learning", "authors": "Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang", "background": "在大规模多智能体强化学习（MARL）中，通过全局的人为指导来调整智能体的行为以达成期望结果是具有挑战性的。另一方面，当前的设计外部机制（例如内在奖励和人工反馈）多依赖于经验研究，缺乏一个易于使用的研发工具。而多智能体影响图（MAIDs）提供了一种图形框架来解决这些问题。", "innovation": "文章提出了一种新的MARL交互范式，即靶向干预范式，主要应用于单个被选中的智能体，从而解决了全局指导的问题。通过引入因果推理技术，即预策略干预（PSI），在MAIDs中实现靶向干预，并通过PSI最大化因果效应来实现复合期望结果。同时，MAIDs的捆束相关性图分析工具可以用来识别MARL交互范式下的MARL学习范式是否可行。", "conclusion": "实验结果表明提出的靶向干预方法是有效的，并且捆束相关性图分析结果得到了验证。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.11824", "html_url": "https://arxiv.org/abs/2510.11824", "title": "在协作多智能体强化学习中的鲁棒性和弹性实证研究", "title_en": "Empirical Study on Robustness and Resilience in Cooperative Multi-Agent Reinforcement Learning", "authors": "Simin Li,Zihao Mao,Hanxiao Li,Zonglei Jing,Zhuohang bian,Jun Guo,Li Wang,Zhuoran Han,Ruixiao Xu,Xin Yu,Chengdong Ma,Yuqing Ma,Bo An,Yaodong Yang,Weifeng Lv,Xianglong Liu", "background": "在协作多智能体强化学习（MARL）中，通常在理想模拟环境中调整超参数以最大化协作性能。然而，针对合作优化的策略在现实世界中可能无法保持鲁棒性和弹性。构建值得信赖的MARL系统需要对鲁棒性和弹性有深入的理解，鲁棒性确保在不确定性下的稳定性能，而弹性则是从破坏中恢复的能力。这些概念在控制理论中已被广泛研究，但在MARL领域却鲜有涉及。", "innovation": "本文进行了大规模的实证研究，包括超过82,620个实验，评估了4个实际环境下的MARL在不同类型的不确定性中的合作、鲁棒性和弹性。研究发现：轻微的不确定性中优化协作改善了鲁棒性和弹性，但随着扰动的加剧，这种联系会减弱；鲁棒性和弹性在不同类型的不确定性或智能体范围之间不具备通用性；参数调整对于建立可信的MARL系统至关重要，某些标准实践如参数共享、GAE和PopArt可能损害鲁棒性，而早停、高评论家学习率和Leaky ReLU则始终有助于提高性能。通过仅优化超参数，观察到全方位的MARL架构在合作、鲁棒性和弹性方面都得到了显著改进，并且这种现象在这些架构上的鲁棒性MARL方法中也有广泛适用性。", "conclusion": "超参数调整对于可信的MARL至关重要，超参数优化能够显著提高MARL架构的合作、鲁棒性和弹性性能。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19788", "html_url": "https://arxiv.org/abs/2510.19788", "title": "评估世界模型学习的标准", "title_en": "Benchmarking World-Model Learning", "authors": "Archana Warrier,Dat Nguyen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares", "background": "当前用于学习和评估世界模型的方法旨在优化下一帧的预测和在相同环境中通过奖励最大化来衡量成功。然而，学习到的世界模型应该涵盖许多下游任务和推断，如预测未观察到的状态，估计近远期行为后果，规划行为序列，以及检测动态变化。WorldTest旨在通过区分无奖励探索阶段和不同但相关的环境中的得分测试阶段来评估模型学习代理，从而实现这一目标。", "innovation": "WorldTest提出了一种协议，它将奖励缺失的交互与得分测试阶段分离，从而实现开放性，模型应支持许多未知的任务，并且不依赖于模型表示方式，允许不同方法之间的比较。并且，通过创建AutumnBench环境套件，包括43个交互网格世界环境和来自三大任务组别的129个任务，以一种新颖的方式评估了被学习环境动态的知识，这在世界模型学习方面显示出明显的改进空间。", "conclusion": "人类参与者在AutumnBench上表现优于模型，但计算规模的扩展仅在某些环境下提高性能但另一些环境下则没有改善。WorldTest提供了一种新的模板，可以评估代理学习到的环境动力学，并且AutumnBench则暴露出世界模型学习方面的明显缺口。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18161", "html_url": "https://arxiv.org/abs/2510.18161", "title": "通过推理感知的政策优化超越赢家的诅咒", "title_en": "Beating the Winner's Curse via Inference-Aware Policy Optimization", "authors": "Hamsa Bastani,Osbert Bastani,Bryce McLaughlin", "background": "近年来，自动学习基于丰富个体协变量的目标治疗决策政策受到了广泛关注。一种常见的方法是训练机器学习模型预测反事实结果，然后选择优化预测目标值的策略。此外，实践者也希望有信心认为学习到的策略在下游政策评估中的性能优于当前政策。然而，由于政策优化过程中的“赢家的诅咒”问题——即该过程利用预测误差而非找到实际改进——导致预测性能改进常常在下游政策优化中没有被证实。为解决这一挑战，本文提出了一种新的策略——推理感知的政策优化，该策略通过考虑政策在下游的评估方式来修改政策优化。具体来说，它不仅优化估计的目标值，还最大化策略在统计上优于用于收集数据的经验政策的概率。作者从数学上刻画了两种目标之间的Pareto前沿，并据此设计了一个使用机器学习预测反事实结果的策略优化算法，该算法将预测插入以估计Pareto前沿，然后决策制定者可以根据期望权衡选择最优策略，接着可以像往常一样在测试集上进行政策评估。最后，通过模拟展示了该方法的有效性，", "innovation": "推理感知的政策优化策略通过考虑下游评估方式来修改政策优化，不仅优化估计的目标值，还最大化策略在统计上优于经验政策的概率。作者从数学上刻画了两种目标之间的Pareto前沿，并据此设计了一个算法，该算法使用机器学习预测反事实结果，然后插入这些预测以估计Pareto前沿，从而允许决策制定者选择最优策略。此外，该方法通过实际测试集上的政策评估来检验所选策略的有效性，", "conclusion": "通过推理感知的政策优化，该方法有效地解决了“赢家的诅咒”问题，并为决策制定者提供了一个工具，可以根据自身的权衡选择最优的策略。该方法通过理论和模拟研究证明了其在实际应用中的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19860", "html_url": "https://arxiv.org/abs/2510.19860", "title": "E-Test: 每进一步提升测试套件", "title_en": "E-Test: E'er-Improving Test Suites", "authors": "Ketai Qiu,Luca Di Grazia,Leonardo Mariani,Mauro Pezzè", "background": "测试套件具有局限性，持续通过新测试案例提升其质量并确保软件系统可靠性是一项既挑战又劳动密集的任务，尤其在长时间管理大型测试套件时更为困难。尽管如此，寻找超出现有测试套件覆盖范围的执行场景的测试案例依然极具挑战性。E-Test 提出了一种方法，它通过使用大型语言模型来识别尚未在现有测试套件中测试的执行场景，并增强测试套件以探索这些场景，从而减少测试套件覆盖范围与实际测试经验之间的差距。", "innovation": "E-Test 使用大型语言模型来识别当前测试套件未充分覆盖的执行场景，生成新的测试案例以增强套件。在 1,975 个场景的数据集上，包括来自高星级开源 Java 项目和 Defects4J 的数据，E-Test 在召回率（F1-score）方面显著优于现有最先进的方法和技术，达到了 0.55 的最高 F1-score。", "conclusion": "E-Test 在提升测试套件效率和有效性方面取得了显著成就，有效针对性尚未经测试的执行场景，减少维护测试套件所需的手动工作量。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19864", "html_url": "https://arxiv.org/abs/2510.19864", "title": "SODBench: 大规模语言模型方法记录电子表格操作", "title_en": "SODBench: A Large Language Model Approach to Documenting Spreadsheet Operations", "authors": "Amila Indika,Igor Molybog", "background": "许多知识工作者在商业、会计和金融等领域中使用电子表格，但缺乏系统的电子表格文档方法制约了自动化、协作和知识传递，这可能带来关键机构知识的丧失。研究已利用大规模语言模型（LLMs）生成电子表格操作代码，但将其翻译成自然语言以记录电子表格操作尚未得到充分探索。", "innovation": "本文引入了电子表格操作文档（SOD）任务，涉及从电子表格操作生成可读的人类解释，并提出了一个包含111个电子表格操作代码片段及其相应自然语言摘要的基准测试。评估了五个LLMs的性能，发现这些模型能够生成准确的电子表格文档，这为提高电子表格的可重复性、可维护性和协作流程奠定了基础。", "conclusion": "尽管LLMs能够生成准确的电子表格文档，使SOD成为增强电子表格可重复性、可维护性和协作流程的可行性前置步骤，但仍存在需要解决的挑战。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18254", "html_url": "https://arxiv.org/abs/2510.18254", "title": "在开放性任务中反映人类推理的幻象", "title_en": "Illusions of reflection: open-ended task reveals systematic failures in Large Language Models' reflective reasoning", "authors": "Sion Weatherhead,Flora Salim,Aaron Belbasis", "background": "大型语言模型能够生成推理文本和‘反思’内容，但目前尚不清楚这种反思性推理是否与人类的反思性推理功能等效。已有研究大多集中在封闭任务上，这些任务有明确的外部正确性信号，容易使‘反思’看起来有效，而掩盖了自我修正的局限性。研究者设计了一个开放但仍受规则约束的简单且现实任务，即生成有效的科学测试项目，并在自我批判后修订。研究表明，这种反思性能力并未表现出与人类相似的主动、目标驱动的监控机制，难以确保第一次就满足约束条件，而且反射后的性能下降，表明当前LSTM的‘反思’机制主要依赖于随机生成的有效项，而非实际的错误检测与具体约束修正。对于开放性任务，可靠的表现需要外部结构来强制实施约束条件。这项研究揭示了大型语言模型在开放性任务中的根本性问题，为进一步改进提出了建议。", "innovation": "研究通过一个开放且受规则约束的真实任务，测试大型语言模型的反思性能力，从而揭示这种能力的局限性。研究中引入的测试任务具有明确的评估标准，模拟了真实情境中的错误检测与修正过程，这是对现有方法的一种创新性补充。研究发现，在第一次尝试时，模型生成的有效测试项目很少，经过反思后也只是略有改善，且重复违反约束条件的现象表明，当前大型语言模型的反思机制主要依赖于随机生成，而非实际的错误检测和具体约束修正。这一发现为改进当前模型提供了新的视角。", "conclusion": "当前大型语言模型的‘反思’功能未能显示出功能性的证据，暗示其缺乏与人类相似的主动、目标驱动的监控机制，即使在第一次尝试时也难以遵守约束条件。为了实现可靠的性能，需要内置有效的机制来管理约束条件。研究结果表明，现有的开放性任务阻碍了模型应对实际挑战的能力。进一步的研究需要在模型中实质性地实现这些机制，而不要依赖外部结构来强制实施约束条件。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19315", "html_url": "https://arxiv.org/abs/2510.19315", "title": "transformers are inherently succinct", "title_en": "Transformers are Inherently Succinct", "authors": "Pascal Bergsträßer,Ryan Cotterell,Anthony W. Lin", "background": "形式语言的标准表示方法，例如有限自动机和线性时态逻辑（LTL）公式，通常用来描述概念。然而，Transformer模型在表示这些概念时展现出较高的表达能力，能够更简洁地表示形式语言。", "innovation": "本文提出了简洁性作为衡量Transformer表达能力的指标，证明Transformer能够比传统形式语言的表示方法（例如有限自动机和LTL公式）更简洁地表示形式语言。此外，还证明了验证Transformer特性的复杂性是可证明的NP完全问题（即EXPSPACE-complete）", "conclusion": "Transformer在描述概念方面具有更高、更简洁的表达能力，但由于其高表达性的副作用，验证其特性变得极为复杂。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19868", "html_url": "https://arxiv.org/abs/2510.19868", "title": "Knowledge-Guided Multi-Agent Framework for Application-Level Software Code Generation", "title_en": "Knowledge-Guided Multi-Agent Framework for Application-Level Software Code Generation", "authors": "Qian Xiong,Bo Yang,Weisong Sun,Yiran Zhang,Tianlin Li,Yang Liu,Zhi Jin", "background": "自动化的代码生成通过大型语言模型(LLMs)提高了开发效率，但是生成复杂的应用级软件代码仍具有挑战性。现有的多智能体框架虽然具有潜力，但在大规模应用级别的软件代码生成中表现不佳，无法确保项目代码的合理组织结构，为代码生成过程的维护带来了困难。", "innovation": "提出了一个名为KGACG的知识指导应用级代码生成框架，该框架通过一个由代码组织与规划智能体(COPA)、编码智能体(CA)和测试智能体(TA)协作的闭环过程，结合反馈机制，将软件需求说明书和架构设计文档转化为可执行代码。该框架旨在提升应用级软件开发的自动化水平。", "conclusion": "通过在Java Tank Battle游戏案例研究中展示KGACG中智能体的协作过程，文中旨在解决现有方法的不足，并推广应用级软件开发的自动化进程。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19898", "html_url": "https://arxiv.org/abs/2510.19898", "title": "BugPilot：面向高效学习软件工程技能的复杂缺陷生成", "title_en": "BugPilot: Complex Bug Generation for Efficient Learning of SWE Skills", "authors": "Atharv Sonwane,Isadora White,Hyunji Lee,Matheus Pereira,Lucas Caccia,Minseon Kim,Zhengyan Shi,Chinmay Singh,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan", "background": "高质量的缺陷对于训练下一代基于语言模型的软件工程(SWE)代理至关重要。之前的生成缺陷方法往往通过故意地修改现有代码来诱导不匹配的效果，这并不能真实地反映出开发过程的实际情况。", "innovation": "该研究提出了一个新颖的方法来合成生成复杂且多样化的bug。该方法指导SWE代理在代码中引入一个特性，使其无意中破坏测试，从而产生bug。这种方法通过质性分析显示能够更贴近人类编写编辑的模式。通过大量实验，证明了本文生成的bug为监督微调提供了更有效的训练数据，与现有bug数据集相比，以更少的训练数据（1200个bug对比3000个）获得更好的性能，优越率达2%。", "conclusion": "通过使用此研究中生成的新bug以及现有bug数据集，训练SWE代理模型FrogBoss和FrogMini在SWE-bench上分别获得最佳参数量32B模型的通过率54.6%，以及14B模型的通过率45.3%（基于三个种子的平均值）。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16013", "html_url": "https://arxiv.org/abs/2510.16013", "title": "AGNES: 自适应图神经网络和动态规划混合框架在实时纳米孔种子链接中的应用", "title_en": "AGNES: Adaptive Graph Neural Network and Dynamic Programming Hybrid Framework for Real-Time Nanopore Seed Chaining", "authors": "Jahidul Arafat,Sanjaya Poudel", "background": "纳米孔测序能够实现实时长读长DNA测序，阅读长度超过10千碱基，但其固有的12-15%的错误率对读取对齐计算构成了巨大挑战。种子链接的关键步骤需要在读取和参考基因组之间连接精确的k-mer匹配，同时过滤掉错误匹配，但最先进的方法依赖于固定缺口惩罚函数，这些函数无法适应包括串联重复和结构变异在内的不同基因组上下文。", "innovation": "本文提出了一种新型的混合框架RawHash3，结合了图神经网络和经典动态规划，实现了自适应种子链接。该方法可以在保持实时性能的同时提供统计保证。RawHash3将种子链路问题作为图学习问题进行建模，其中种子节点由12维特征向量表示，边则编码8维空间关系，包括缺口一致性。通过采用三层EdgeConv GNN和基于置信度的方法选择策略，动态切换学习引导和算法回退。在包含1,000个合成纳米孔读取和5,200个测试种子的全面评估中，RawHash3实现了99.94%的精确度和40.07%的召回率，相比基线模型有25.0%的相对改进，p小于0.001。系统实现了中位数推理延迟1.59ms，满足实时约束，并展示了在20%标签错误下100%的成功率，而基线模型则下降至30.3%。交叉验证确认了模型的稳定性，证明图神经网络在流水线生产和基因组学中具有可行性。", "conclusion": "研究结果表明，通过结合图神经网络和经典动态规划，AGNES可以在实现实时纳米孔种子链接的同时，提供统计性的保证，增强系统对标签错误的鲁棒性，反映出图神经网络在基因组学应用中的潜在价值。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20340", "html_url": "https://arxiv.org/abs/2510.20340", "title": "Classport: 为Java设计运行时依赖introspection", "title_en": "Classport: Designing Runtime Dependency Introspection for Java", "authors": "Serena Cofano,Daniel Williams,Aman Sharma,Martin Monperrus", "background": "软件供应链安全的核心在于能够观察程序运行期间正在使用的依赖情况。现有的Java语言并未提供此类功能支持。因此，需要开发一种新的系统来解决这个问题，以嵌入依赖信息到Java类文件中，从而实现在运行时检索依赖信息的能力。", "innovation": "Classport是一个系统，它将依赖信息嵌入到Java类文件中，使得可以在运行时检索依赖信息。该系统已在六个实际项目上进行了评估，展示了在运行时识别依赖的可行性。使用Classport进行运行时依赖introspection为运行时完整性检查打开了新的途径。", "conclusion": "Classport系统的应用表明，它在软件生命周期安全管理方面具有巨大的潜力，特别是在增强Java应用程序的供应链安全性方面。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19984", "html_url": "https://arxiv.org/abs/2510.19984", "title": "灰盒 fuzzing 中的交互效应研究", "title_en": "On Interaction Effects in Greybox Fuzzing", "authors": "Konstantinos Kitsios,Marcel Böhme,Alberto Bacchelli", "background": "灰盒 fuzzing 是一种自动化的软件测试工具，能通过随机应用变异器（如翻转位或删除字节块）来生成新的测试输入，并将所有增加覆盖率的新输入添加到候选输入库中。研究假设，应用于种子输入的变异器顺序会影响灰盒 fuzzing 的效果。实验数据表明这种交互效应确实存在，这意味着通过选择更有可能产生有趣输入的变异器序列，可以提高 fuzzing 的效率。", "innovation": "提出了名为 MuoFuzz 的灰盒 fuzzing 工具，MuoFuzz 通过学习并选择最有可能产生有趣输入的变异器序列，为 fuzzing 过程提供了更高效的策略。具体来说，MuoFuzz 使用带有条件概率学习的随机游走方法来生成变异器序列，这种方法优于 AFL++ 使用的固定选择概率以及 MOPT 使用的独立优化每个变异器选择概率。实验结果表明，MuoFuzz 能达到最高的代码覆盖率，并发现 AFL++ 错过的四个漏洞以及一个两个工具都错过的漏洞。", "conclusion": "MuoFuzz 在多个基准测试集上的表现优于 AFL++ 和 MOPT，展示了通过学习和应用变异器的新序列来提高 fuzzing 效率的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20121", "html_url": "https://arxiv.org/abs/2510.20121", "title": "基于模型驱动重构方法将PL/SQL触发器迁移到Java的应用实践", "title_en": "Developing a Model-Driven Reengineering Approach for Migrating PL/SQL Triggers to Java: A Practical Experience", "authors": "Carlos J. Fernandez-Candel,Jesus Garcia-Molina,Francisco Javier Bermudez Ruiz,Jose Ramon Hoyos Barcelo,Diego Sevilla Ruiz,Benito Jose Cuesta Viera", "background": "模型驱动软件工程（MDE）技术不仅适用于正向工程场景，还能成功应用于现有系统演进。RAD（快速应用开发）平台在九十年代出现，现代软件技术的发展促使许多企业开始迁移他们的RAD应用，例如Oracle Forms。研究组与一家软件公司合作，开发了一个将 Forms 上的PL/SQL单个代码（包括触发器和程序单元）迁移至Java代码分层分离的应用工具。研究重点在于迁移工具开发中的模型驱动重构过程，特别是PL/SQL代码转换为Java代码的方法。", "innovation": "提出了一种软件过程，采用类似TDD的方法逐步开发模型转换，并对生成的代码进行了三种类型的验证。详细解释了重构方法的实现与验证，以及某些与MDE应用相关的问题。", "conclusion": "通过模型驱动的方法成功实现了PL/SQL代码向Java代码的迁移，该方法结合了逐步开发模型转换和多种代码验证机制，为现有应用的现代化迁移提供了有效解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19997", "html_url": "https://arxiv.org/abs/2510.19997", "title": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)", "title_en": "A Framework for the Adoption and Integration of Generative AI in Midsize Organizations and Enterprises (FAIGMOE)", "authors": "Abraham Itzhak Weinberg", "background": "生成式人工智能（GenAI）为组织带来了转型机会，但中型组织和大型企业都面临着独特的采用挑战。中型组织遇到资源限制和有限的AI专业知识，而大型企业则面对组织复杂性和协调挑战。现有的技术采纳框架，包括技术接受模型（TAM）、技术组织环境（TOE）和创新扩散理论（DOI）在针对这些多样环境实施GenAI方面缺乏具体性，创建了一道关键的采纳文献缺口。", "innovation": "本文提出FAIGMOE（框架化采纳和整合生成式人工智能在中型组织和企业中的框架），这是首个针对中型和企业组织专门针对GenAI采纳的综合概念框架。FAIGMOE将技术采纳理论、组织变革管理与创新扩散视角结合，分为四个相互关联的阶段：战略评估、规划和案例开发、实施和整合以及运行优化。该框架还包括GenAI特定考虑因素，如提示工程、模型编排和幻觉管理，从而区别于通用技术采纳框架。", "conclusion": "FAIGMOE 提供了可操作的实施指南、评估工具和治理模板，通过未来研究需要进行实证验证，以实现中型和企业组织的 GenAI 采纳。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20389", "html_url": "https://arxiv.org/abs/2510.20389", "title": "软件平台中的对称性作为一种架构原则", "title_en": "Symmetry in Software Platforms as an Architectural Principle", "authors": "Bjorn Remseth", "background": "软件平台通常作为结构保持系统运行，提供在特定变换（称为对称性）下保持一致的接口和行为。这篇文章探索了通过强制实施这些结构规则使架构变得稳健的想法。", "innovation": "论文提出了将对称性作为软件平台架构原则的概念，强调通过对平台进行结构约束以保持一致性和稳定性，从而实现架构的稳健性。", "conclusion": "文章表明，通过确保软件平台在结构上的一致性和稳定的特性，可以实现架构的鲁棒性。这样，系统在面对不同的情况和变化时能够保持其功能性和可靠性。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20041", "html_url": "https://arxiv.org/abs/2510.20041", "title": "构建系统降级的成本：Kubernetes 的案例研究", "title_en": "The Cost of Downgrading Build Systems: A Case Study of Kubernetes", "authors": "Gareema Ranjan,Mahmoud Alfadel,Gengyi Sun,Shane McIntosh", "background": "由于开发人员频繁调用构建系统，其性能会直接影响生产力。现代基于构件的构建工具能够加速构建过程，但已有研究表明，团队可能会放弃这些工具，转而使用维护更简单的替代品。虽然已有研究解释了为何进行降级，但降级的影响仍在很大程度上未被探索。本文通过对比基线，并分析Kubernetes项目从基于构件的构建工具（Bazel）降级到语言特定解决方案（Go Build）期间的构建情况，来研究这些影响。研究表明，虽然Bazel构建速度快，但在大规模项目中，其大幅度增加了CPU占用率和内存消耗，甚至在某些情况下，CPU占用率增加了约七十五倍，内存占用率增加了约三十五倍。这些发现表明，虽然放弃基于构件的构建工具看似在维护方面有好处，但对于大型项目来说，这些工具往往会导致显著的性能成本增加。", "innovation": "本文通过重现和分析Kubernetes项目在从Bazel到Go Build的降级过程中的全量和增量构建，深入研究了这一过程中的性能和资源消耗情况。此外，通过在其他四个已从Bazel降级到较旧构建工具的项目中复制这项研究，进一步验证了这些观察结果的有效性。", "conclusion": "虽然放弃基于构件的构建工具在维护方面看起来有优势，但对于大型项目来说，这种降级往往会带来显著的性能成本增加。我们的观察结果可以帮助利益相关者更好地平衡构建工具采用中的权衡。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20403", "html_url": "https://arxiv.org/abs/2510.20403", "title": "基于FMI的增强安全性和知识产权保护的分布式协同仿真", "title_en": "FMI-Based Distributed Co-Simulation with Enhanced Security and Intellectual Property Safeguards", "authors": "Santiago Gil,Ecem E. Baş,Christian D. Jensen,Sebastian Engelsgaard,Giuseppe Abbiati,Cláudio Gomes", "background": "分布式协同仿真在不同利益相关者之间实现协作建模仿真的同时保护其知识产权发挥关键作用。尽管分布式协同仿真可以隐式提供知识产权保护，但目前尚没有明确的准则来指导如何在不暴露于潜在黑客攻击的情况下进行连续时间和混合系统的分布式协同仿真。", "innovation": "提出了一种基于UniFMU的分布式协同仿真方法，并增强了安全性和知识产权保护机制，确保连接由客户端发起，模型和二进制文件保存在受信任的平台上，展示了该方法在四种不同的网络设置下的功能，并分析了知识产权保护与性能效率之间的权衡问题。", "conclusion": "该方法提供了一种在分布式协同仿真中保护知识产权的方式，同时也注意到了这种方式对性能的影响，并通过实例验证了其实用性和有效性。"}
{"llm_update_time": "20251025", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.19733", "html_url": "https://arxiv.org/abs/2510.19733", "title": "Zhyper：用于条件化LLM微调的因子化超网络", "title_en": "Zhyper: Factorized Hypernetworks for Conditioned LLM Fine-Tuning", "authors": "M. H. I. Abdalla,Zhipin Wang,Christian Frey,Steffen Eger,Josif Grabocka", "background": "大型语言模型（LLM）的条件化指的是指导LLM生成符合特定文化规范、特定政治倾向理念或任意指定语义条件的内容。然而，由于预训练和对齐数据集的归纳偏见，提示工程并不能保证LLM按照期望的条件行为。前人工作主要集中在直接通过LoRA权重进行微调，但这种方法会引入大量参数。因此，有必要开发一种参数高效的框架来解决这一问题，即生成上下文感知的LoRA适配器从文本描述出发，以减少参数数量并改进LLM的性能和适应性。在多个基准测试中，Zhyper的表现与现有的最佳基线相比，最多可减少26倍的参数数量，同时保持竞争力。研究还展示了Zhyper在文化对齐中的应用，即改善其对出域设置的一般化能力和更精细地捕捉上下文值的能力。", "innovation": "提出了Zhyper，一种参数高效的因子化超网络框架，从文本描述生成上下文感知的LoRA适配器，相较于现有最佳基线最多可减少26倍的参数数量，并在多个基准测试中显示出竞争力。此外，还展示了Zhyper在文化对齐中的应用，展示了其更好的一般化能力和对细微语境价值的捕捉能力。", "conclusion": "研究证明，Zhyper在参数效率和性能方面均超过当前最佳基线，特别是在文化对齐上展示了更好的适应性和语境感知能力。这一突破为调整LLM以适应特定文化或理念提供了新的途径。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20514", "html_url": "https://arxiv.org/abs/2510.20514", "title": "面向实践的演绎验证：来自工业和学术界的定性调查见解", "title_en": "Toward Practical Deductive Verification: Insights from a Qualitative Survey in Industry and Academia", "authors": "Lea Salome Brugger,Xavier Denis,Peter Müller", "background": "演绎验证是一种有效的方法，用于确保给定系统暴露的是预期行为。尽管它在一些项目中已经证明其有用性和可行性，但演绎验证仍未成为主流技术。为了推动广泛应用，本文研究了促进成功应用演绎验证的因素以及阻碍更广泛应用的问题。通过与来自工业和学术界的30名验证专家进行半结构化访谈，系统地采用主题分析方法进行数据收集和分析。除了实证确认熟悉的一系列挑战，如执行形式证明所需的高专业知识水平，研究还揭示了几种尚未被充分探索的障碍，例如证明维护、自动化不足以及易用性问题。", "innovation": "本研究通过对工业和学术界的30名验证专家进行半结构化访谈，系统地采用主题分析方法分析数据，揭示了演绎验证的未被探索的障碍，并提出具体建议，涵盖了易用性、自动化和与现有工作流程的集成原则。", "conclusion": "研究结果不仅实证地确认了已知挑战，还发现了几个未曾深入探讨的障碍。这些结果为演绎验证的实施提供了具体的指导原则，包括易用性、自动化和与现有流程的集成。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20521", "html_url": "https://arxiv.org/abs/2510.20521", "title": "大型语言模型在故障定位中的实证研究", "title_en": "Large Language Models for Fault Localization: An Empirical Study", "authors": "YingJian Xiao,RongQun Hu,WeiWei Gong,HongWei Li,AnQuan Jie", "background": "大型语言模型（LLMs）在代码相关任务中显示出强大的能力，特别是在自动程序修复方面。然而，这类修复的效果高度依赖于上游故障定位的表现，目前这方面的全面评估尚缺。本文系统研究了LLMs在声明级代码故障定位任务中的性能。研究通过评估多个开源和闭源模型，使用HumanEval-Java和Defects4J数据集测试了它们的故障定位能力，并探讨了不同提示策略——包括标准提示、少样本示例和链式推理——对模型性能的影响，重点关注准确率、时间效率和经济成本三个方面。", "innovation": "研究通过系统验证，考察了代表性开源模型（Qwen2.5-coder-32b-instruct, DeepSeek-V3）和闭源模型（GPT-4.1 mini, Gemini-2.5-flash）的故障定位能力。研究结果显示，引入错误报告上下文显著提升了模型性能。少样本学习展示了改进的潜力，但边际收益递减明显，而链式推理的有效性则高度依赖于模型自身的推理能力。", "conclusion": "研究不仅揭示了不同模型在故障定位任务中的性能特征和权衡，还为改善故障定位效果提供了宝贵的策略指导。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19938", "html_url": "https://arxiv.org/abs/2510.19938", "title": "设计一个安全可靠的分布式智能手机参与者数据收集系统", "title_en": "Designing a Secure and Resilient Distributed Smartphone Participant Data Collection System", "authors": "Foad Namjoo,Neng Wan,Devan Mallory,Yuyi Chang,Nithin Sugavanam,Long Yin Lee,Ning Xiong,Emre Ertin,Jeff M. Phillips", "background": "现实世界的健康研究需要从移动和可穿戴设备中持续且安全地收集数据。为此，需要一个能够最小化参与者互动、兼容多种类型传感器数据和调查问卷、应对电池限制、网络连接不稳定等实际问题的系统。", "innovation": "该研究提出了MotionPI，这是一种基于智能手机的数据收集系统，它通过整合被动数据收集（如GPS和腕部运动数据）和生态时刻评估（EMA）调查问卷来实现最小化用户互动。EMA调查问卷可以根据物理活动触发或随机触发。MotionPI设计考虑了实际生活中的限制，确保即使在电池电量低、网络连接不稳的情况下也能有效运作。此外，系统不仅在当地保存数据，也在安全的云服务中加密传输和存储。", "conclusion": "MotionPI是一种实用的解决方案，能够在不受网络攻击和数据安全性威胁的情况下，实现移动数据的高效和可扩展的收集，适用于网络物理健康研究。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20692", "html_url": "https://arxiv.org/abs/2510.20692", "title": "探索大型语言模型在访问控制策略合成和总结中的应用", "title_en": "Exploring Large Language Models for Access Control Policy Synthesis and Summarization", "authors": "Adarsh Vatsa,Bethel Hall,William Eiers", "background": "随着云计算的普及，越来越多的服务被部署在云端。传统的云计算系统允许管理员编写访问控制规则的策略来管理对私有数据的访问。然而，这些策略需要手动编写，且由于其复杂性，容易出现错误。现有的策略常常实现复杂的身份验证和访问控制需求，使得精确分析其行为是否按预期工作变得困难。近年来，大型语言模型（LLMs）在自动化代码合成和总结方面取得了显著的成功，这表明它们可能被用于自动生成访问控制策略或帮助理解现有策略。基于此，该研究探讨了LLMs在访问控制策略合成和总结方面的有效性，试图探索其在自动访问控制策略生成和现有策略分析中的潜力和挑战。", "innovation": "该研究创新性地探索了大型语言模型在访问控制策略合成（包括合成和理解）方面的应用，发现虽然LLMs能够生成语义正确的策略，但在策略生成方面存在泛滥性问题。研究还引入了一种新颖的基于语义的请求总结方法，利用LLMs生成策略允许的请求的精确描述。该研究展示了当结合符号方法时，LLMs在分析现有策略方面的潜力。", "conclusion": "该研究结论指出，虽然在利用LLMs进行自动访问控制策略生成方面存在诸多挑战，但在结合符号方法进行策略分析时，LLMs显示出有希望的结果。这表明在访问控制策略管理领域，大型语言模型的应用前景广阔。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19877", "html_url": "https://arxiv.org/abs/2510.19877", "title": "政策指导下的RAG架构 - 研究设计", "title_en": "Policy-Governed RAG - Research Design Study", "authors": "Jean-Marie Le Ray", "background": "在受监管的工作流程中实现审计准备生成，特别是在制药、医疗器械、金融、法律和公共部门等领域，这些领域中的任何错误成本可能达到数千欧元，并且在欧盟人工智能法案等法规下必须强制保留审计轨迹。", "innovation": "提出了一个由三部分组成的政策治理RAG架构：I) 合同/控制（类似于SHRDLU），II) 表明/痕迹（类似于Memex），确保所有引用的源证据的加密锚定以保证可验证的源出处；III) 收据/验证（类似于Xanadu），提供最终且可携带的合规证明供审计人员使用（采用COC/JOSE）。研究成果强调模型输出在生成前基于预注册的端到端验证，确保输出结果符合预设政策，并提供可复现性和合规证明，同时设定未验证目标以确保结果的可揭示性。", "conclusion": "该设计通过将审计轨迹附加到已验证的证据上，使得政策检查审计复现回溯和证实性证明得以可能，适用于涉及高成本错误及法规强制审计轨迹的行业，未来可能会承诺在任何NO-GO机制不满足的情况下公布负面结果。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.19979", "html_url": "https://arxiv.org/abs/2510.19979", "title": "SecureInfer: 异构 TEE-GPU 架构实现大型语言模型部署中的隐私关键张量保护", "title_en": "SecureInfer: Heterogeneous TEE-GPU Architecture for Privacy-Critical Tensors for Large Language Model Deployment", "authors": "Tushar Nayan(1),Ziqi Zhang(2),Ruimin Sun(1) ((1) Florida International University, (2) University of Illinois Urbana-Champaign)", "background": "随着大型语言模型（LLMs）在移动和边缘平台上部署的增加，保护它们免受模型提取攻击的问题变得越来越紧迫。然而，在不牺牲不受信任的人工智能加速器（如GPU）带来的性能益处的情况下保护模型隐私，这本身就是一个具有挑战性的权衡。", "innovation": "SecureInfer 是一种混合框架，利用异构可信执行环境（TEEs）-GPU 架构来隔离隐私关键组件，同时将计算密集型操作卸载到不受信任的加速器上。该框架通过外包方案和信息论以及威胁感知的划分策略实现：安全敏感组件在SGX飞地内执行，其他线性操作（矩阵乘法）在加密后在GPU上执行，并安全地返回飞地中。", "conclusion": "我们在LLaMA-2模型上实现了SecureInfer的原型，并从性能和安全两个方面进行了评估。结果表明，SecureInfer提供了强大的安全保证，同时在性能方面保持了合理水平，提供了一种实用的设备上模型推理的安全解决方案。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20036", "html_url": "https://arxiv.org/abs/2510.20036", "title": "ToolScope：通过工具合并和上下文感知筛选增强LLM代理工具使用", "title_en": "ToolScope: Enhancing LLM Agent Tool Use through Tool Merging and Context-Aware Filtering", "authors": "Marianne Menglin Liu,Daniel Garcia,Fjona Parllaku,Vikas Upadhyay,Syed Fahad Allam Shah,Dan Roth", "background": "大型语言模型（LLM）代理依赖外部工具来解决复杂任务，但现实世界中的工具集通常包含冗余工具，名称和描述重叠，导致歧义和选择准确性降低。此外，LLM面临严格的输入上下文限制，这妨碍了高效地考虑大型工具集。因此，需要改进方法来解决这些问题，以便更好地利用工具集并提高准确性与效率.", "innovation": "本文提出了ToolScope，该系统包括ToolScopeMerger with Auto-Correction自动审计和修复工具合并，以减少冗余，以及ToolScopeRetriever用于根据查询排名和选择最相关的工具，并压缩工具集以适应上下文限制，而不牺牲准确性。", "conclusion": "通过在三种最先进的LLM和三种开源工具使用基准测试上的评估，ToolScope在工具选择准确性上取得了8.38%到38.6%的提升，证明了其在增强LLM工具使用方面的有效性。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20679", "html_url": "https://arxiv.org/abs/2510.20679", "title": "Java去肥工具的精确度和正确性基准", "title_en": "A Soundness and Precision Benchmark for Java Debloating Tools", "authors": "Jonas Klauke,Tom Ohlmer,Stefan Schott,Serena Elisa Ponta,Wolfram Fischer,Eric Bodden", "background": "现代软件开发中，代码重用通过导入库依赖来实现。软件项目通常包含36个依赖项，其中80%是传递依赖。研究表明，这些依赖项中只有24.9%是在运行时必需的，甚至在这些必需的依赖项中，仍然有许多程序构建块未被使用，这增加了项目的不必要的代码量。因此，开发出了去肥工具来移除不必要的依赖项和构建块，同时在保证准确性和正确性的平衡上进行优化。为了系统地评估这一权衡，我们开发了Deblometer，一个包含59个测试用例的微基准，用于评估去肥工具对各种Java语言特性支持的能力。每个测试用例包括一个手动维护的金标准，指明需要和多余的类、方法和字段，这使我们能够精确地测量准确性和正确性。利用Deblometer，我们评估了三种流行的Java去肥工具：Deptrim、JShrink和ProGuard。评估结果揭示了所有工具都移除了必需的程序构建块，导致语义变更或执行失败。动态类加载功能在所有评估工具中引入了不正确性。我们的比较显示，Deptrim保留了更多的多余的构建块，而ProGuard移除了更多的必需构建块。JShrink的正确性受到注解支持有限的影响，导致去肥化后的产物被破坏。这些正确性问题突显了需要改进去肥工具以确保去肥软件的稳定可靠性的需求。", "innovation": "我们开发了Deblometer，一个包含59个测试用例的微基准，用于评估Java去肥工具对各种Java语言特性支持的能力。每个测试用例包括一个手动维护的金标准，指明需要和多余的类、方法和字段，这使我们能够精确地测量准确性和正确性。我们的评估揭示了使用现有去肥工具的问题，并指出了改进方向。", "conclusion": "所有流行的Java去肥工具都移除了必需的程序构建块，导致语义变更或执行失败。动态类加载功能在所有评估工具中引入了不正确性。Deptrim保留了更多的多余的构建块，而ProGuard移除了更多的必需构建块。JShrink的正确性受到注解支持有限的影响，导致去肥化后的产物被破坏。这些正确性问题突显了需要改进去肥工具以确保去肥软件的稳定可靠性的需求。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.19271", "html_url": "https://arxiv.org/abs/2507.19271", "title": "细调多语言语言模型用于代码审查：针对工业C#项目的实证研究", "title_en": "Fine-Tuning Multilingual Language Models for Code Review: An Empirical Study on Industrial C# Projects", "authors": "Igli Begolli,Meltem Aksoy,Daniel Neider", "background": "代码审查对于维持软件质量至关重要，但在工业环境中往往耗时且认知负担重。最近的语言模型 advancements 为自动化核心审查任务开辟了新的途径。", "innovation": "研究通过单语言微调评估开源语言模型在三个关键的自动化代码审查任务中的表现：代码更改质量估计、审查评论生成和代码精炼。研究发现，单语言微调提高了模型的准确性和相关性，尤其是在评论生成方面，优于多语言基线，并且微调模型在实际应用中表现出一定的实用性。", "conclusion": "研究表明，语言模型可以有效地支持代码审查工作流程，特别是对于常规或重复的任务，但人类审查员在处理语义复杂或上下文敏感的更改时仍占优势。研究强调了语言对齐和任务特定调整在优化语言模型以进行自动化代码审查中的重要性。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.09601", "html_url": "https://arxiv.org/abs/2506.09601", "title": "LLMs在自承认为技术债务分类自动化方面的进展如何？", "title_en": "How Far Have LLMs Come Toward Automated SATD Taxonomy Construction?", "authors": "Sota Nakashima,Yuta Ishimoto,Masanari Kondo,Tao Xiao,Yasutaka Kamei", "background": "技术债务指的是代码不优化从而影响软件质量的情况。当开发者故意引入这种债务时，称为自承认为技术债务（SATD）。由于SATD妨碍了软件维护，识别其类别对于发现质量问题至关重要。传统方法需要手动检查SATD注释和周围的代码，这耗时且劳动密集，且容易受到注释者主观性的影响。", "innovation": "本文研究了大型语言模型（LLMs）在生成SATD分类方面的潜力。设计了一个结构化的、以LLM为主导的流程，模拟研究者通常遵循的分类构建步骤。在量子软件、智能合约和机器学习三个领域进行了评估，成功恢复了先前工作中报告的领域特定类别，如机器学习中的层配置。此外，LLMs在两小时内即可完成分类生成，并且在成本上低于1元，即使在最大数据集的情况下也如此。这些结果表明，尽管完全自动化仍具有挑战性，但LLMs可以支持半自动的SATD分类构建。", "conclusion": "研究表明，虽然完全自动化仍具有挑战性，但大型语言模型可以支持半自动的SATD分类构建。同时，本研究也为其他领域的自动分类生成提供了新途径。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2403.17382", "html_url": "https://arxiv.org/abs/2403.17382", "title": "开发团队多久更新其易受攻击的依赖项？", "title_en": "How Quickly Do Development Teams Update Their Vulnerable Dependencies?", "authors": "Imranur Rahman,Ranindya Paramitha,William Enck,Laurie Williams", "background": "随着对包含第三方依赖项（直接或间接包含）的脆弱版本软件的关注增加，从业人员越来越重视此问题。为了解决这一问题，项目应迅速更新为非漏洞版本，并保持对所选用依赖项更新实践的关注。现有的度量标准，如 Mean-Time-To-Update (MTTU) 和 Mean-Time-To-Remediate (MTTR)，虽然覆盖了所有依赖项和易受攻击的依赖项的更新时间，但这些度量标准未能考虑一些细微差别，例如浮点版本和优先更新，导致对开发团队更新实践的不准确反映。研究旨在帮助开发人员了解包更新依赖项的速度，通过实证研究不同生态系统中的 MTTU 和 MTTR 及其影响因素，发现大多数包具有相对较快的依赖项更新实践。在缺乏漏洞数据时，虽然 MTTU 可以部分地作为 MTTR 的替代方法，但这一结论需要谨慎对待。", "innovation": "本文提出了两个新的度量标准，Mean-Time-To-Update for dependencies (MTTU) 和 Mean-Time-To-Remediate for vulnerable dependencies (MTTR)，以克服现有度量标准的局限性。通过实证研究 npm、PyPI 和 Cargo 中的 163,207 个包，研究了不同生态系统中的 MTTU 和 MTTR。研究结果表明，大多数包具有较快的依赖项更新实践，但在缺乏漏洞数据时，MTTU 可以部分地作为 MTTR 的替代方法。", "conclusion": "我们的研究结果建议，当无法获得足够的漏洞数据时，MTTU 只能部分地（在某些情况下可以使用但需要谨慎）替代 MTTR，作为更新实践的代理。但我们需要更多的证据支持 MTTU 作为 MTTR 的强代理。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2410.05641", "html_url": "https://arxiv.org/abs/2410.05641", "title": "为神经策略合成高效和宽松的编程运行时防护", "title_en": "Synthesizing Efficient and Permissive Programmatic Runtime Shields for Neural Policies", "authors": "Jieke Shi,Junda He,Zhou Yang,Đorđe Žikelić,David Lo", "background": "随着神经网络在控制系统中的使用日益增加，确保其安全性和可靠性已成为关键的软件工程任务。现有的方法虽然能够合成运行时防护，但这些防护要么计算成本高，要么不够宽松，导致系统运行效率低下且频繁干预。目前缺乏一种高效且宽松的运行时防护机制来解决此类问题。因此，如何设计一种既能有效纠正不安全命令，又不会过度干预系统的轻量级且宽松的防护机制成为了一个重要研究方向。", "innovation": "本文提出了Aegis框架，这是一种新的方法来合成适用于神经策略的轻量级和宽松的编程运行时防护。Aegis将寻找运行时防护的过程建模为基于草图的程序合成问题，并引入了一种结合反例引导的归纳合成和贝叶斯优化的新方法来解决该问题。此外，通过使用八种代表性的控制系统进行验证并与其他最先进的方法进行比较，Aegis表现出更高效的系统执行时间和更低的内存占用，同时保持了良好的宽松性，减少了不必要的系统干预。", "conclusion": "研究结果表明，Aegis能够有效防止所有来自神经策略的不安全命令，并确保系统在整个运行过程中不违反任何期望的安全属性。相较于当前最先进的方法，Aegis的防护机制在时间开销上减少了2.2倍，在内存使用上减少了3.9倍，且平均干预次数减少了1.5倍，显示出更好的宽松性和效率。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2509.14856", "html_url": "https://arxiv.org/abs/2509.14856", "title": "CodeFuse-CR-Bench: 一个针对Python项目端到端代码审查评价的全面性感知基准", "title_en": "CodeFuse-CR-Bench: A Comprehensiveness-aware Benchmark for End-to-End Code Review Evaluation in Python Projects", "authors": "Hanyang Guo,Xunjin Zheng,Zihan Liao,Hang Yu,Peng DI,Ziyin Zhang,Hong-Ning Dai", "background": "现有的代码审查（CR）基准主要评估模型在孤立子任务上的表现，使用的数据过于简化且缺乏上下文信息，这与现实中的全面性强的代码审查需求不符。为此，论文提出了CodeFuse-CR-Bench，这是一个面向仓库级别的代码审查评估的基准，包含了来自70个Python项目中的601个高质量实例，涵盖了九种Pull-Request问题领域，旨在提供端到端的评价。", "innovation": "引入了一个新的基准CodeFuse-CR-Bench，它包括601个高质量实例，涵盖70个Python项目中的9个Pull-Request问题领域。此外，还提出了一种新的评价框架，将规则检查与模型判断相结合，以评估审查质量。首次对最先进的大型语言模型（LLMs）进行了全面的CR评估。研究结果为促进真正智能且实用的CR助手提供了实际见解，并强调了整体、多维度评价的必要性。", "conclusion": "(1) 没有任何单一的LLM在所有CR方面表现突出；(2) Gemini 2.5 Pro在综合性能上表现最佳；(3) 不同的LLM对冗余上下文的鲁棒性不同。这些发现强调了整体、多维度评估的必要性，并为开发真正智能且实用的代码审查助手提供了实际建议。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.03712", "html_url": "https://arxiv.org/abs/2510.03712", "title": "在高性能软件系统中检测和预防潜在风险累积", "title_en": "Detecting and Preventing Latent Risk Accumulation in High-Performance Software Systems", "authors": "Jahidul Arafat,Kh.M. Moniruzzaman,Shamim Hossain,Fariha Tasmin", "background": "现代分布式系统采用积极的优化策略，这会产生潜在风险——隐藏的漏洞，在优化表现优异的情况下掩盖了当优化失效时灾难性的脆弱性。缓存层达到99%的命中率可以掩盖数据库瓶颈，直到缓存失败导致负载放大100倍，并引发级联崩溃。当前的可靠性工程集中于针对事件的响应，而不是主动检测因优化引发的漏洞。", "innovation": "本文提出了第一个全面的框架，通过综合数学建模、智能扰动测试和风险敏感的性能优化来系统地检测、预防和优化潜在风险。引入了潜在风险指数（LRI），与事件严重性有很强的相关性（r=0.863, p<0.001），使得能够进行预测性风险评估。该框架整合了三个系统：HYDRA、RAVEN和APEX，分别实现了89.7%的潜在风险发现率、92.9%的准确率和93.8%的召回率，并保持了96.6%的基础性能同时减少了59.2%的潜在风险。", "conclusion": "在三个测试环境中的评估结果显示，具有强大的统计验证和高的再现性（r>0.92）的大型效应大小。在生产部署24周后，显示了平均恢复时间减少了69.1%，事件严重性降低了78.6%，并且防止了81起事件，平均每年带来144万美元的收益，投资回报期为3.2个月。该方法将可靠性工程从被动的事件管理转变为前瞻性的风险敏感优化。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.08609", "html_url": "https://arxiv.org/abs/2510.08609", "title": "pinning or floating", "title_en": "Which Is Better For Reducing Outdated and Vulnerable Dependencies: Pinning or Floating?", "authors": "Imranur Rahman,Jill Marley,William Enck,Laurie Williams", "background": "开发人员通常会使用版本约束来指定项目依赖的可接受版本。锁定依赖关系可以通过减少破坏性更改的可能性来降低风险，但需要手动管理过时和易受攻击依赖关系的替换。相反，浮动依赖关系可以自动获取错误修复和安全修复，但增加了破坏性更改的风险。为了防止软件供应链攻击，安全专家推荐锁定依赖关系，但这可能导致依赖项过时的时间更快。尽管锁定是最紧的版本约束，但关于哪种版本约束类型在降低依赖项过时或易受攻击的可能性上效果更好仍不清楚。因此，该研究旨在通过大规模实证研究帮助开发人员在不同版本约束类型中进行明智的选择，以降低依赖项过时或易受攻击的可能性。", "innovation": "研究首次使用生存分析模型来模拟依赖项状态的变化，评估在使用锁定约束与使用其他版本约束类型时，依赖项变为过时或易受攻击的可能性变化情况。研究发现，最常见的版本约束类型是“浮动次要版本”，其次是锁定，而“主版本浮动”是最不可能导致依赖项过时的，而“次要版本浮动”是最不可能导致依赖项易受攻击的。通过这些发现，为开发人员提供了决策支持，以降低其依赖项的风险。", "conclusion": "研究结果显示，尽管锁定约束可以减少破坏性更改的风险，但也可能导致依赖项更快过时。相反，虽然“浮动次要版本”是最常见的版本约束类型，但它也增加了依赖项易受攻击的风险。而“主版本浮动”和“次要版本浮动”则处于中间位置，平衡了降低依赖项过时和易受攻击的可能性。因此，研究建议开发人员在做出选择时需权衡不同的风险与需求，以降低其依赖项过时或易受攻击的可能性。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.09721", "html_url": "https://arxiv.org/abs/2510.09721", "title": "LLM驱动的自主软件工程中的基准和解决方案综述", "title_en": "A Comprehensive Survey on Benchmarks and Solutions in Software Engineering of LLM-Empowered Agentic System", "authors": "Jiale Guo,Suizhi Huang,Mei Li,Dong Huang,Xingsheng Chen,Regina Zhang,Zhijiang Guo,Han Yu,Siu-Ming Yiu,Pietro Lio,Kwok-Yan Lam", "background": "大型语言模型（LLMs）的集成正在软件工程领域推动传统基于规则的系统向能够解决复杂问题的自主代理系统转型。系统发展受到了全面理解基准和解决方案相互连接的认识不足的阻碍。本文通过综述150多篇近期论文，首次提供LLM驱动的软件工程的全面分析，揭示评估方法和解决方案范式的洞见。分析展示了从简单的提示工程到具备规划、推理、记忆机制和工具增强能力的复杂代理系统的发展过程。通过对任务、代码生成、翻译和修复等基准的审查，文章提出了解决方案和基准的分类框架，描绘了从任务规范到交付物的统一工作流程，明确了不同解决方案在应对不同复杂度方面的作用。", "innovation": "文章首次提供LLM驱动的软件工程全面分析，提出解决方案和基准的分类框架，明确不同解决方案和复杂度级别之间的对应关系，填补了现有研究的不足，为LLM驱动的软件工程提供了基础指南，同时指出了关键研究缺口和未来研究方向，包括多代理协作、自演化系统和形式验证集成。", "conclusion": "本文综述工作为LLM驱动的软件工程提供了基础指南，提出了系统化的解决方案和基准分类框架，指出了未来研究方向。作者维护了一个GitHub仓库，不断更新所审查和相关论文，体现了对LLM驱动软件工程持续发展的支持。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.23946", "html_url": "https://arxiv.org/abs/2505.23946", "title": "Lessons Learned: 一种用于代码LLM学习和改进的多Agent框架", "title_en": "Lessons Learned: A Multi-Agent Framework for Code LLMs to Learn and Improve", "authors": "Yuanzhe Liu,Ryan Deng,Tim Kaler,Xuhao Chen,Charles E. Leiserson,Yao Ma,Jie Chen", "background": "最近的研究表明，大语言模型（LLM）在不同的技能上表现出色，并擅长不同的任务。实际上，我们在不同细粒度级别的任务上观察到了它们不同的表现。例如，在代码优化任务中，代码LLM在不同的优化类别中表现出色，没有一个LLM能够主导其他LLM。这种观察提出了一个问题：在不了解各LLM互补优势的情况下，如何利用多个LLM代理来解决编程问题。", "innovation": "本文提出了一种基于知识传授的多Agent合作框架，设计了知识请求、积累和选择机制。证明了一组具有学习知识的小LLM可以优于较大规模的LLM以及其他多种LLM合作方法，从而通过相互学习和传递过程提升了自身的性能。", "conclusion": "通过多Agent团队之间的知识共享，本文提供了一种新的方法来解决编程问题。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.13938", "html_url": "https://arxiv.org/abs/2505.13938", "title": "CLEVER: 一个正式验证代码生成的精心策划基准", "title_en": "CLEVER: A Curated Benchmark for Formally Verified Code Generation", "authors": "Amitayush Thakur,Jasper Lee,George Tsoukalas,Meghana Sistla,Matthew Zhao,Stefan Zetzsche,Greg Durrett,Yisong Yue,Swarat Chaudhuri", "background": "当前广泛使用的代码生成基准普遍存在一些问题，如依赖测试案例监督、通过语言模型生成的标注或存在泄露实现逻辑或允许空洞解的规范。这些缺陷限制了对代码生成和形式推理的全面验证。", "innovation": "本文介绍了CLEVER基准，这是一个高质量且经过精心策划的包含161个问题的基准，专注于端到端的验证代码生成。CLEVER避免了上述缺陷，要求输出经过Lean类型检查器后验证，确保机器可验证的正确性。利用CLEVER评估了一系列基于先进语言模型的方法，展示了当前方法在全面验证方面的局限，从而确立它作为程序综合和形式推理挑战基准的地位。", "conclusion": "我们的基准可以在GitHub和HuggingFace上找到，并且所有评估代码也已在线提供。该基准确立了一个新的挑战领域，即需要突破以实现全面验证的代码生成和形式推理技术。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2401.08281", "html_url": "https://arxiv.org/abs/2401.08281", "title": "Faiss库", "title_en": "The Faiss library", "authors": "Matthijs Douze,Alexandr Guzhva,Chengqi Deng,Jeff Johnson,Gergely Szilvasy,Pierre-Emmanuel Mazaré,Maria Lomeli,Lucas Hosseini,Hervé Jégou", "background": "当前，AI应用程序正在快速增长，因此需要存储和索引的嵌入向量数量也在增加。Faiss库专注于向量相似性搜索，这是向量数据库的核心功能之一。Faiss库包含索引方法及相关基元，用于搜索、聚类、压缩和转换向量。论文描述了向量搜索的权衡空间及Faiss的设计原则，包括结构、优化方法和接口设计。", "innovation": "论文探讨了Faiss库在向量搜索方面的权衡空间，并详细描述了其设计原则，覆盖了结构、优化策略和接口设计等方面。同时，对库的关键特性进行了基准测试，并讨论了几个应用案例，以展示其广泛的适用性。", "conclusion": "Faiss库在向量搜索方面提供了优化的设计和实现，能够有效支持大量嵌入向量的数据管理和检索。通过优化方法和接口设计，该库能够很好地满足AI应用程序的需求，提高了向量相似性搜索的效率和准确性。"}
{"llm_update_time": "20251025", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.20739", "html_url": "https://arxiv.org/abs/2510.20739", "title": "学习对动态程序分析报告中Node.js包中的污点流进行优先处理", "title_en": "Learning to Triage Taint Flows Reported by Dynamic Program Analysis in Node.js Packages", "authors": "Ronghao Ni,Aidan Z.H. Yang,Min-Chien Hsu,Nuno Sabino,Limin Jia,Ruben Martins,Darion Cassel,Kevin Cheang", "background": "程序分析工具往往会产生大量的候选漏洞报告，这些报告需要人工审核，增加了审核成本并造成了实际挑战：安全分析师如何优先处理最有可能是真实漏洞的报告？", "innovation": "本文研究了是否可以利用机器学习来优先处理程序分析工具报告的漏洞。研究利用了一种动态程序分析工具的数据，选择了1,883个包含ACE或ACI漏洞的包建立了一个基准。评估了包括经典模型、图神经网络（GNN）、大规模语言模型（LLM）及结合GNN和LLM的混合模型在内的多种机器学习方法。结果表明，最好的LLM能达到91.5%的F1值，最佳GNN和经典机器学习模型可达90.4%的F1值。即使在不到7%的假阴性率下，最佳模型也能从人工审核中淘汰掉66.9%的正常包，处理每个包耗时约60毫秒。将最佳模型调整到0.8的准确率水平（即在所有警告中允许20%的假阳性），该方法可以检测到99.2%的可利用污点流，仅有0.8%的遗漏，显示了在实际环境中的漏洞优先处理的强大潜力。", "conclusion": "研究表明机器学习在优先处理动态程序分析工具报告的漏洞方面具有显著优势，能够显著减少人工审核的工作量，提供高精度的漏洞检测结果，对未来实际网络安全威胁处理具有重要的应用前景。"}
