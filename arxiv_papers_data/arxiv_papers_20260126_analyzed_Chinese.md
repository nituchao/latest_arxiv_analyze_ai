# 20260126
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - Prometheus Mind: 将记忆融入冻结的语言模型 [PDF](https://arxiv.org/pdf/2601.15324), [HTML](https://arxiv.org/abs/2601.15324)
### Authors
Mark Wind
### Background
将预训练语言模型与记忆结合通常需要进行架构改动或权重修改。该研究旨在介绍一种新的方法，使用11个模块化适配器（530MB，7%的开销）将记忆植入冻结的Qwen3-4B中，这些适配器完全可以通过移除它们来撤销。
### Innovation
该研究解决了四个关键问题：（1）提取：开发了对比方向发现（CDD），通过最小成对样本找到语义方向，无需标签数据；（2）训练：端到端优化受到影响，分阶段训练每种适配器在简单的代理任务上成功；（3）注入：学习到的编码器无法泛化，发现基础行已经提供了所需映射，无需额外训练；（4）隐藏状态崩溃：Transformer使“妻子”和“兄弟”高度相似，训练投影以恢复区分度（0.98变为0.09）。在PrometheusExtract-132数据集上，系统在清晰输入时达到94.4%的检索成功率（n=54，95%置信区间：[84.9%, 98.1%]），但在非正式输入（n=36）时下降至19.4%，主要瓶颈在于关系分类，准确率为47.3%。
### Conclusion
该系统展示了如何在不改变现有结构的情况下，通过分阶段训练和适配器注入的方法高效地重用记忆，特别是在语言理解和提取方面表现出色。
## 2. `cs.AI` - 可重放的金融代理：一种用于工具使用大语言模型代理的确定性-忠实性保障框架 [PDF](https://arxiv.org/pdf/2601.15322), [HTML](https://arxiv.org/abs/2601.15322)
### Authors
Raffi Khatchadourian
### Background
LLM代理在面对重复审计回放任务时表现出一致性问题，尤其是在要求其在给出相同输入的情况下复现已标记的交易决策时，大多数部署未能返回一致结果。这项研究旨在开发一种框架，以衡量金融服务业部署中的工具使用代理的轨迹确定性和条件证据忠实性。
### Innovation
该论文引入了‘确定性-忠实性保障框架’（DFAH），一种衡量金融服务业中工具使用代理轨迹确定性和条件证据忠实性的框架。研究发现，不同参数量的模型在非代理基线实验中表现不同，大参数量模型需要更大的验证样本才能达到与小参数量模型相当的统计可靠性。此外，研究揭示了确定性和忠实性之间的正相关关系。
### Conclusion
在三种金融基准测试（合规分类、投资组合约束、数据运营异常；每个包含50个案例）下，在DFAH评估环境中，采用方案优先架构的顶级模型达到了符合审计回放要求的一致性水平。
## 3. `cs.AI` - Gated Sparse Attention: Combining Computational Efficiency with Training Stability for Long-Context Language Models [PDF](https://arxiv.org/pdf/2601.15305), [HTML](https://arxiv.org/abs/2601.15305)
### Authors
Alfred Shen,Aaron Shen
### Background
长上下文语言模型的注意力机制计算负担促使了两种独立的研究方向：稀疏注意力机制通过关注选定的令牌减少复杂性，以及门控注意力变体提高训练稳定性并缓解注意力陷阱现象。
### Innovation
本文提出了一种名为Gated Sparse Attention (GSA)的新架构，结合了门控和稀疏注意力的优点。GSA包括sigmoid激活的门控快速索引器、自适应稀疏控制器以及双重门控机制。此外，论文为该方法建立了理论基础，包括复杂性分析、表现力结果和收敛保证。
### Conclusion
在1.7B参数模型、400B令牌训练的实验中，GSA不仅提高了效率（在128K上下文中相对基线12-16倍的速度提升），还提高了与门控注意力相关的质量，如困惑度减少了0.33，RULER得分几乎翻倍，第一个令牌的注意力比率减少了超过47%。同时，训练的稳定性显著提高，损失峰值减少了98%。
## 4. `cs.AI` - DeepSurvey-Bench: 评估自动生成科学调查的学术价值 [PDF](https://arxiv.org/pdf/2601.15307), [HTML](https://arxiv.org/abs/2601.15307)
### Authors
Guo-Biao Zhang,Ding-Yuan Liu,Da-Yi Wu,Tian Lan,Heyan Huang,Zhijing Wu,Xian-Ling Mao
### Background
自动化科学调查生成技术的快速发展使得建立全面的基准以评估生成的调查质量变得日益重要。然而，现有的评估基准依赖于引文数量和结构一致性等缺陷标准来选择人类撰写的问卷作为真实数据集，并仅通过表面的质量度量如结构质量和参考相关性来评估生成的答卷。这些基准存在的两个关键问题在于：1）由于缺乏学术维度注释，真实数据集不可靠；2）评估指标仅关注问卷的表面质量，如逻辑一致性。这些缺陷导致现有的基准无法评估生成调查的深层次学术价值，例如核心研究目标和对不同研究的批判性分析。
### Innovation
为了应对这些问题，作者提出了DeepSurvey-Bench，这是一种新颖的基准设计，旨在全面评估生成调查的学术价值。该基准提出了一个包含三个维度的全面的学术价值评估标准：信息价值、学术交流价值和研究指导价值。基于这一标准，作者建立了具有学术价值注释的可靠数据集，并评估了生成调查的深层次学术价值。
### Conclusion
广泛的实验证明，该基准与人类评估生成调查的学术价值表现高度一致。
## 5. `cs.AI` - GeMM-GAN: 一种基于病理科图像和临床描述的多模态生成模型用于基因表达谱生成 [PDF](https://arxiv.org/pdf/2601.15392), [HTML](https://arxiv.org/abs/2601.15392)
### Authors
Francesca Pia Panaccione,Carlo Sgaravatti,Pietro Pinoli
### Background
生物医学研究越来越依赖于整合多种数据模态，包括基因表达谱、医学影像和临床元数据。虽然医学影像和临床元数据在临床实践中常规收集，但基因表达数据由于严格的隐私法规和昂贵的实验室实验，在广泛应用中面临挑战。为了应对这些限制，我们提出了GeMM-GAN，这是一种新型生成对抗网络，通过病理科组织切片和临床元数据条件化，并设计用于合成逼真的基因表达谱。
### Innovation
GeMM-GAN结合了一个Transformer Encoder用于图像补丁，并在补丁和文本代词之间加入了一个最终的交叉注意力机制。这些组件共同产生一个条件向量，以指导生成模型生成生物上一致的基因表达谱。我们的方法在TCGA数据集上进行了评估，证明了该框架比标准生成模型具有更好的性能，产生更真实的且功能上更有意义的基因表达谱，相较于当前最先进的生成模型提高了超过11%的下游疾病类型预测准确性。
### Conclusion
我们的方法在TCGA数据集上表现更好，生成的基因表达谱更真实、功能上更有意义。与现有最先进的生成模型相比，在下游疾病类型预测上的准确率提高了超过11%。代码将在指定的网址公开。
## 6. `cs.AI` - 知识图网络及其在医疗领域中的逻辑编程应用 [PDF](https://arxiv.org/pdf/2601.15347), [HTML](https://arxiv.org/abs/2601.15347)
### Authors
Chuanqing Wang,Zhenmin Zhao,Shanshan Du,Chaoqun Fei,Songmao Zhang,Ruqian Lu
### Background
知识图的研究快速发展，对其在许多领域的应用，包括医疗健康领域，带来了巨大的推动作用。但是，我们发现一些主要的信息处理技术在知识图的应用上仍存在不足，表现在未能充分利用先进的逻辑推理、人工智能技术、专用编程语言、现代概率和统计理论等。尤其是多知识图的合作和竞争技术未能获得足够的研究关注。
### Innovation
本文开发了一个系统的理论、技术和知识图网络的应用概念以及其在医疗领域的应用。研究涵盖了知识图网络在模糊、不确定、多模态、向量化、分布式、联邦等多种情况下的定义、发展、推理、计算和应用，并提供了真实数据示例和实验结果。
### Conclusion
总结了创新之处，即系统地发展了知识图网络的理论和技术，并将其应用于医疗领域。
## 7. `cs.AI` - 通过代理变量揭示基于LLM的急诊科分流中的潜在偏见 [PDF](https://arxiv.org/pdf/2601.15306), [HTML](https://arxiv.org/abs/2601.15306)
### Authors
Ethan Zhang
### Background
最近，大型语言模型（LLMs）在临床决策中的集成取得了进展，但它们普遍存在的针对不同种族、社会经济地位和临床背景患者的隐性偏见问题仍然存在。这项研究旨在调查这些基于LLM的医疗人工智能系统在急诊科分诊中的偏见现象。
### Innovation
研究使用了32个患者层面的代理变量，这些变量通过正向和负向限定词对来表示，并利用公共数据集（MIMIC-IV-ED Demo，MIMIC-IV Demo）和受限访问域（MIMIC-IV-ED，MIMIC-IV）进行评估。研究发现，AI系统存在通过代理变量在急诊科分诊场景中表现出的歧视性行为，以及系统倾向于在输入文本中出现特定标记时修改患者严重程度的系统性倾向，无论这些标记是正面还是负面表达的。
### Conclusion
研究表明AI系统在临床设置中的安全和负责任部署仍存在不足，背后的信号往往是噪声且非因果的，不能可靠反映患者的真实急性程度。因此，急需改进以保证AI技术在临床环境中的应用安全与负责任。
## 8. `cs.AI` - 大范式转变：大型视觉语言模型在多模态假新闻检测中的综合调查 [PDF](https://arxiv.org/pdf/2601.15316), [HTML](https://arxiv.org/abs/2601.15316)
### Authors
Wei Ai,Yilong Tan,Yuntao Shou,Tao Meng,Haowen Chen,Zhixiong He,Keqin Li
### Background
近年来，大规模视觉-语言模型（LVLMs）的快速发展推动了多模态假新闻检测（MFND）范式的转变，从传统的特征工程方法转向统一的端到端多模态推理框架。早期方法主要依赖浅层融合技术来捕捉文本和图像之间的相关性，但难以实现高层次语义理解和复杂跨模态交互。随着LVLMs的出现，这一领域经历了根本性变化，使视觉和语言的联合建模成为可能，从而增强检测利用文本叙述和视觉内容的信息的能力。
### Innovation
本文首次提供了综合性调查，追溯了多模态假新闻检测从传统多模态检测管道到基于基础模型的范式的演变，建立了一个结构化的分类体系涵盖模型架构、数据集和性能基准，分析了可解释性、时间推理和领域泛化的技术挑战，并为下一个阶段的范式转变指明了未来研究方向。
### Conclusion
此论文是首个系统地记录和分析LVLMs在对抗多模态假新闻中的变革作用的调查。现有的方法总结可以在我们的Github: [this https URL]上找到。
## 9. `cs.AI` - 超越提示：通过逻辑空间整合实现高效稳健的语音LLM上下文偏向（LOGIC） [PDF](https://arxiv.org/pdf/2601.15397), [HTML](https://arxiv.org/abs/2601.15397)
### Authors
Peidong Wang
### Background
新实体的迅速涌现，受到文化转变、趋势演变和个人用户数据的影响，对现有的语音大型语言模型（Speech LLMs）构成了重大挑战。尽管这些模型在通用对话任务表现优秀，但它们静态的训练知识限制了它们识别领域特定术语（如联系人名字、播放列表或技术术语）的能力。现有的解决方案主要依赖于提示，但提示方法存在规模性差的问题：随着实体列表的增长，提示遇到了上下文窗口限制、增加的推理延迟以及“失之交臂”的现象。另一种方法生成错误校正（GEC）试图通过后处理重写脚本，但常常会出现过度校正的现象，引入未被说出的实体幻象。
### Innovation
本文提出了一种高效且稳健的框架LOGIC（逻辑空间整合用于上下文偏置），直接在解码层运行。与提示方法不同，LOGIC将上下文插入与输入处理解耦，保证了相对于提示长度的恒定时间复杂性。通过在多语言的11个本地域使用Phi-4-MM模型进行全面的实验，结果显示LOGIC在实体错误率（Entity WER）上实现了平均9%的相对减少，与此同时误报率仅增加了0.30%。
### Conclusion
实验结果表明，LOGIC在处理实体识别任务时既高效又可靠，提供了相较于一成不变的提示方法更为灵活且具有竞争力的解决方案。
## 10. `cs.AI` - Aeon: 高性能神经符号化内存管理机制用于长期目标语言模型代理 [PDF](https://arxiv.org/pdf/2601.15311), [HTML](https://arxiv.org/abs/2601.15311)
### Authors
Mustafa Arslan
### Background
大型语言模型（LLMs）受到自我注意的二次计算成本的限制，并且随着上下文窗口的扩大，推理能力会下降，这被称为“迷失在中间现象”。“平躺RAG”架构依赖于向量数据库，这种简单的向量嵌入集合方法无法捕捉长期交互中的层次结构和时间结构，从而导致“向量迷雾”，即检索到不连续的事实且缺乏情景连续性。
### Innovation
Aeon 提出了一个神经符号认知操作系统，重新定义了内存不仅为静态存储库，还作为管理的OS资源。Aeon 将记忆结构化为一个“记忆宫”（通过Atlas实现的空间索引，一种SIMD加速的页聚集向量索引，结合了小世界图导航和B+树风格的磁盘局部性以最小化读取放大）和“印记”（一种神经符号情景图）。Aeon 引入了语义旁路缓冲（SLB），这是一种预测性缓存机制，利用对话局部性以实现亚毫秒级的检索延迟。实验证明，对于对话任务，Aeon 实现了小于1毫秒的检索延迟，同时通过零拷贝C++/Python桥梁确保了状态一致性，从而有效地为自主代理提供了持久的结构化内存。
### Conclusion
Aeon 成功地实现了毫秒级的对话检索延迟，同时保持了状态一致性，为长期目标的LLM代理提供了一种高效的、结构化的持久内存管理机制。
## 11. `cs.AI` - 值得信赖、安全且用户友好的心理健康聊天机器人清单 [PDF](https://arxiv.org/pdf/2601.15412), [HTML](https://arxiv.org/abs/2601.15412)
### Authors
Shreya Haran,Samiha Thatikonda,Dong Whi Yoo,Koustuv Saha
### Background
全球心理健康问题日益严重，导致对心理健康服务的需求增加，但由于服务供不应求，人们越来越多地依赖技术来应对这一挑战。在此背景下，心理健康聊天机器人作为一种有前景的解决方案日益受到关注，但这些聊天机器人的使用尚未经过充分测试，因此引起了对安全性和潜在危害的担忧。
### Innovation
本文通过文献调研识别出心理健康聊天机器人设计和实现的重要缺口，并贡献了一个操作性检查清单，旨在指导开发更值得信赖、更安全、更用户友好的聊天机器人。该清单既是一个开发框架，也是一个审核工具，以确保聊天机器人的伦理设计和有效应用。
### Conclusion
本文提出的检查清单是促进更负责任设计实践和为社会和技术上合适的心理健康数字工具设定新标准的重要步骤。
## 12. `cs.AI` - OmniSpectra: 统一的用于原始分辨率天文学光谱的基石模型 [PDF](https://arxiv.org/pdf/2601.15351), [HTML](https://arxiv.org/abs/2601.15351)
### Authors
Md Khairul Islam,Judy Fox
### Background
天文学领域的光谱数据量庞大且多样化，但现有的基石模型通常局限于固定波长范围和特定仪器。OmniSpectra 是首款能够处理任意长度原始大小光谱的基石模型，无需重新采样或插值。
### Innovation
OmniSpectra 通过创新的架构实现多变长适应切片、正弦全局波长编码、深度可分离卷积中的局部位置嵌入，以及有效性意识的自注意力掩码，从而能够学习多尺度空间模式并跳过无效片段的注意力。即使训练样本有限，OmniSpectra 也展示了出色的零样本泛化能力，特别是在星系和恒星的分类、红移估计和属性预测任务中。
### Conclusion
OmniSpectra 改变了需要为不同任务从头训练不同模型的需求，标志着下一代天文学基石模型的到来，适用于各种天文学任务，并且其迁移学习能力使其成为众多天文学任务的最先进的模型。
## 13. `cs.AI` - 超越固定的心理画像：状态胜过特质，但语言模型对状态视而不见 [PDF](https://arxiv.org/pdf/2601.15395), [HTML](https://arxiv.org/abs/2601.15395)
### Authors
Tamunotonye Harry,Ivoline Ngong,Chima Nweke,Yuanyuan Feng,Joseph Near
### Background
用户与语言模型的交互会因用户的静态属性（特质）和具体的交互情境（状态）而有所不同。现有的人格画像数据集（如PersonaChat、PANDORA等）仅捕捉到用户的静态特质，并忽略了情境的影响。为解决这一问题，作者构建了Chameleon数据集，包含1667位Reddit用户的5001个情境心理学画像，并通过该数据集进行了三项关键发现。
### Innovation
1. 作者通过潜状态特质理论，将方差分解，发现74%的差异来自个体内部而只有26%来自个体之间。2. 作者观察到大型语言模型（LLMs）未能识别用户状态，只关注用户的静态特质，因此产生的回应不随情境变动。3. 文本奖励模型能够响应用户状态，但反应不一致，不同的模型对于同一用户的偏好或惩罚方向相反。
### Conclusion
作者释放了Chameleon数据集，旨在支持情感计算、个性化对话系统以及基于人类反馈的强化学习（RLHF）的对学生状态的兴趣的研究。
## 14. `cs.AI` - 连续吸引子网络中离散继嗣过渡的学习：涌现、极限及拓扑约束 [PDF](https://arxiv.org/pdf/2601.15336), [HTML](https://arxiv.org/abs/2601.15336)
### Authors
Daniel Brownell
### Background
连续吸引子网络（CANs）是一种广泛接受的模型，用于表示低维度的连续变量，如头部方向、空间位置和相位。在传统的空间域中，沿着吸引子流形的过渡由如角速度提供的传感器运动信号驱动。当没有外部提供明确的位移信号时，不清楚CAN是否能可靠地获得支持稳定状态过渡的反复动态，还是其他预测策略占主导地位。
### Innovation
本文提出了一个实验框架，用于训练CANs在没有外部位移信号的情况下执行类似继嗣的转换。通过对比两种不同的循环拓扑结构——环状圆和折叠蛇形流形，并系统地改变稳定性评估的时间框架，研究发现了短期内CANs会收敛到脉冲驱动的联想解决方案，但缺乏持久的吸引子动态。只有在稳定性需在长时间期内明确保持时，真正的吸引子基态间转换动态才会出现。研究结果还表明，拓扑结构严格限制了学习过渡的能力。
### Conclusion
这种结果表明，绕道解决方案是局部学习的默认结果，而吸引子动态代表了一个受到限制的区域，而不是一般的结果。进一步研究表明，拓扑结构严格限制了学习过渡的能力，虽然环状连续拓扑结构可以在长期内实现完美稳定性，但折叠蛇形拓扑结构则存在在流形不连续性处的几何极限问题，无法通过课程学习或基底节启发的门控机制完全克服。
## 15. `cs.AI` - 使用GenAI和大语言模型（LLMs）转变具有侮辱性内容的音乐和歌词 [PDF](https://arxiv.org/pdf/2601.15348), [HTML](https://arxiv.org/abs/2601.15348)
### Authors
Jiyang Choi,Rohitash Chandra
### Background
暴露在暴力和虐待性内容的音乐和歌词中可能会影响听众的情绪和行为，甚至正常化暴力或强化有害刻板印象。本文探讨了使用生成式人工智能（GenAI）和大语言模型（LLMs）自动转换流行音乐中的侮辱性词汇和歌词内容的方法。这种方法不仅仅是为了替代某个单词，而是改变语气、强度和情感，因此不仅仅是歌词的改变，也是其表达方式的改变。
### Innovation
这篇文章提出了一种新型的方法，通过使用GenAI和LLMs来自动转换流行音乐中的侮辱性词汇和歌词，这种技术不仅可以改变音色、音强和情感，还能保持音乐的连贯性，并减少有害信息的影响。这种方法比传统的内容过滤更为有效，因为它避免了触发“禁果效应”，即被屏蔽的内容因为被限制反而更具有吸引力。
### Conclusion
GenAI显著减少了演唱的攻击性，通过声学分析显示在谐波到噪声比、倒谱峰显着性和音颤方面有所改善。情感分析表明，不同艺术家在不同的部分攻击性减少了63.3%到85.6%，特别是在合唱部分，最多减少了88.6%。转换后版本在保持音乐连贯性的同时减少了有害内容，提供了一种不触发“禁果效应”的内容过滤替代方案，即通过限制反而使内容更吸引人。
## 16. `cs.AI` - 转录迷失：转写错误如何破坏代码理解 [PDF](https://arxiv.org/pdf/2601.15339), [HTML](https://arxiv.org/abs/2601.15339)
### Authors
Jayant Havare,Ashish Mittal,Srikanth Tamilselvam,Ganesh Ramakrishnan
### Background
软件工程工具和开发者工作流中的代码理解是一个基础能力，但大多数现有系统是为英语使用者设计的，只能通过键盘交互，这限制了在多语言和语音优先设置中的可访问性，尤其是在如印度等地区。基于语音的接口更具有包容性，但由于代码中的非标准英语用法、领域特定词汇、以及变量和函数名等自定义标识符的存在，语音查询的代码实现带来了独特挑战。在本研究中，我们开发了一个多语言、基于语音的框架，旨在接受用户的母语语音查询，使用自动语音识别（ASR）进行转录，并利用大型语言模型（LLM）对ASR输出进行代码感知的校正，最终通过CodeSearchNet、CoRNStack和CodeQA等基准模型实现代码问题回答和代码检索等任务。
### Innovation
我们系统地研究了转写错误如何影响下游任务性能，并首次提出了使用大型语言模型（LLM）对ASR输出进行校正的方法，从而显著改善了转写和代码理解的性能。并且，我们的工作强调了在语音界面中需要进行代码敏感的适应性改进，为构建稳健的多语言语音驱动编程工具提供了实践解决方案。
### Conclusion
我们的研究揭示了语音接口中代码适应性改进的必要性，并提供了一个实用的方法来构建多语言语音驱动编程工具，这对提高广泛使用的印度语言（包括印地语等）在编程中的可用性具有重要意义。
## 17. `cs.AI` - Q-Probe: 通过上下文感知自主探测方法扩大图像质量评估 [PDF](https://arxiv.org/pdf/2601.15356), [HTML](https://arxiv.org/abs/2601.15356)
### Authors
Xiang Li,XueHeng Li,Yu Wang,XuanHua He,ZhangChi Hu,WeiWei Yu,ChengJun Xie
### Background
现有基于强化学习（RL）的多模态大型语言模型（MLLMs）在图像质量评估（IQA）中能够实现接近人类的偏好对齐。然而，这些模型通常依赖粗粒度的全局视图，无法有效捕捉高分辨率场景中的细腻局部损害。同时，新兴的“借助图像思考”范式通过缩放机制实现了多尺度的视觉感知，但直接应用于IQA会导致虚假的“裁剪意味着降质”偏见，并将自然景深误认为伪影。
### Innovation
本文提出了Q-Probe，这是一种针对高分辨率图像质量评估的先驱性自主探测框架。它包括一个专门用于高分辨率细粒度局部降解分析的Vista-Bench基准测试。同时，Q-Probe采用了三阶段训练范式，逐步将模型与人类偏好对齐，并通过一种新颖的上下文感知裁剪策略消除因果偏见。
### Conclusion
大量的实验表明，Q-Probe在高分辨率设置中达到了最先进的性能，同时在不同分辨率尺度上保持了卓越的效率。
## 18. `cs.AI` - CURE: 以课程指导多任务训练以生成可靠的解剖学定向报告 [PDF](https://arxiv.org/pdf/2601.15408), [HTML](https://arxiv.org/abs/2601.15408)
### Authors
Pablo Messina,Andrés Villa,Juan León Alcázar,Karen Sánchez,Carlos Hinojosa,Denis Parra,Álvaro Soto,Bernard Ghanem
### Background
医疗视觉-语义模型可以自动化生成放射学报告，但存在准确视觉对接和事实一致性方面的问题。现有模型经常无法使文本结果与视觉证据对齐，导致预测不可靠或缺乏与图形内容的联系。
### Innovation
CURE 是一种错误感知的课程学习框架，它可以在没有额外数据的情况下提升对接精度和报告质量。CURE 通过多层次的课程训练对多模态指令模型进行微调，并根据模型性能动态调整采样以更好地对齐空间和文本。
### Conclusion
CURE 提高了对接精度 (+0.37 IoU)、提升了报告质量 (+0.188 CXRFEScore) 并将幻觉现象减少了 18.6%。CURE 是一个数据高效的框架，能够同时提升对接精度和报告可靠性。相关代码和模型权重可在提供的链接下载。
## 19. `cs.AI` - OpenVision 3：一种用于理解和生成的统一视觉编码器系列 [PDF](https://arxiv.org/pdf/2601.15369), [HTML](https://arxiv.org/abs/2601.15369)
### Authors
Letian Zhang,Sucheng Ren,Yanqing Liu,Xianhang Li,Zeyu Wang,Yuyin Zhou,Huaxiu Yao,Zeyu Zheng,Weili Nie,Guilin Liu,Zhiding Yu,Cihang Xie
### Background
本文介绍了一种先进的视觉编码器家族，OpenVision 3，它学习单一、统一的视觉表示，既可以用于图像理解，又可以用于图像生成。
### Innovation
核心架构简单，通过将VAE压缩的图像潜在变量输入ViT编码器，并训练其输出以支持两个互补角色。具体而言，编码器的输出被传递给ViT-VAE解码器来重建原始图像，鼓励表示捕捉生成结构。同时，相同的表示使用对比学习和图像配对学习目标进行优化，增强语义特征。通过在共享潜在空间中联合优化重建和语义驱动的信号，编码器学会了既能很好地协同工作也能泛化的表示。
### Conclusion
本文通过细致的下游验证显示了这一统一设计的有效性。在多模态理解方面，OpenVision 3在LLaVA-1.5框架中表现出与标准CLIP视觉编码器相当的性能。在生成方面，它也超越了基于CLIP的标准配对编码器。作者希望通过这项工作激发未来对统一建模的研究。
## 20. `cs.AI` - 通过组合权重稀疏性和数据稀疏性提高MoE的计算效率 [PDF](https://arxiv.org/pdf/2601.15370), [HTML](https://arxiv.org/abs/2601.15370)
### Authors
Maciej Kilian,Oleg Mkrtchyan,Luke Zettlemoyer,Akshat Shrivastava,Armen Aghajanyan
### Background
MoE（混合专家）层通过权重稀疏性实现计算效率，每个tokens仅激活一部分专家。数据稀疏性也提供了互补的维度，即每个专家仅处理一部分tokens。在因果token选择MoE中，直接实现数据稀疏性（专家选择路由）会破坏自回归模型的因果关系，导致训练与推断间的不对齐。本研究利用零计算（null）专家来解决这个问题，同时保持了计算效率。
### Innovation
通过在路由池中使用零计算专家，本研究克服了因果token选择MoE中的因果关系问题，既实现了数据稀疏性又保持了计算效率。标准的负载均衡目标训练模型使所有专家（包括实和null）均匀使用，从而在无因果关系破坏的情况下实现了数据稀疏性。本研究在视觉-语言模型训练中进行了评估，显示在匹配的预期FLOPs下，组合权重和数据稀疏性比单独使用权重稀疏性具有更高的计算效率，并且在训练损失和下游任务性能上也有所提升。
### Conclusion
在视觉-语言模型训练中，通过组合权重和数据稀疏性可以构建一个更加计算高效的前沿，这比单独使用权重稀疏性具有更高的训练损失和下游任务性能。模型通过自我学习实现了模态感知的分配策略，更频繁地将视觉tokens路由到null专家，而文本tokens则较少如此。
## 21. `cs.LG` - DECOR: 带有方向鲁棒性的深度嵌入聚类 [PDF](https://arxiv.org/pdf/2510.03328), [HTML](https://arxiv.org/abs/2510.03328)
### Authors
Fiona Victoria Stanley Jothiraj,Arunaggiri Pandian Karunanidhi,Seth A. Eichmeyer
### Background
在半导体制造中，早期检测晶圆缺陷对于优化产品产量至关重要。然而，晶圆质量检测中的原始晶圆数据往往复杂、未标注、不平衡且单个晶圆上可能存在多种缺陷，因此设计能够在这些不完美数据条件下依然可靠的聚类方法至关重要。
### Innovation
我们提出了DECOR，一种具有方向鲁棒性的深度聚类框架，能够将晶圆图中的复杂缺陷模式分组成一致的簇。我们的方法在开源的MixedWM38数据集上进行了评估，展示了其无需手动调优即可发现簇的能力。DECOR明确考虑了晶圆图中的方向变化，确保了空间上相似的缺陷能够在旋转或对齐时不一致地聚类。
### Conclusion
实验表明，我们的方法优于现有的聚类基准方法，从而提供了在自动化视觉检测系统中可靠且可扩展的解决方案。
## 22. `cs.LG` - Likelihood Matching for Diffusion Models [PDF](https://arxiv.org/pdf/2508.03636), [HTML](https://arxiv.org/abs/2508.03636)
### Authors
Lei Qian,Wu Su,Yanqi Huang,Song Xi Chen
### Background
该研究提出了一种通过将目标数据分布的似然性与逆向扩散路径上的似然性建立等价性来训练扩散模型的方法。为了高效地计算逆向样本似然性，作者考虑用高斯分布来近似每个逆向转移密度，使得条件均值和方差匹配。这种方法估计扩散生成过程中的分数和Hessian函数，从而确保任意两个时间点之间转移的前两阶矩一致匹配。
### Innovation
研究提出了一种新的训练扩散模型的方法，称为似然匹配方法。这种方法通过将目标数据分布的似然性与逆向扩散路径上的似然性接近来实现。为了高效地估计逆向样本似然性，作者引入了一个准似然方法，利用分数和Hessian函数的估计来近似每个逆向转移密度。此外，研究还引入了一种随机采样器来利用这些估计的信息来提高计算效率。
### Conclusion
研究证明了准最大似然估计的一致性，并提供了所提采样器的非渐进收敛保证，量化了由于分数和Hessian估计、维度和扩散步骤数量导致的近似误差率。实证和模拟评估表明，所提出的似然匹配方法有效地提高了扩散模型的训练效果，并验证了理论结果。
## 23. `cs.LG` - 协作、审辩、评估：LLM对协调多智能体结果的影响 [PDF](https://arxiv.org/pdf/2509.05882), [HTML](https://arxiv.org/abs/2509.05882)
### Authors
Abhijnan Nath,Carine Graff,Nikhil Krishnaswamy
### Background
随着大语言模型（LLMs）被整合到各种工作流程中，它们逐渐被视为与人类合作的“同事”，并需要与其他AI系统协调工作。为了可靠地协调与人类或其他AI的合作行为，必须了解LLMs在多回合交互中的属性和行为。因此，本文探讨了不同的对齐方法如何影响LLM代理作为多回合多边合作伙伴的有效性。
### Innovation
本文基于修改动作MDP的理论视角，展示了现有对齐技术无法考虑长时间多边交互的动力学。提出了一个新颖的角色扮演模拟方法，通过对LLM根据不同方法进行对齐后部署在协作任务对话中，量化干预如何影响团队合作轨迹、信念对齐和协调。结果显示，对动作修改具有鲁棒性的干预代理显著优于常见的对齐基准线，有助于实现正确的任务结果。
### Conclusion
干预代理对于任务的成功执行具有重大影响，特别是对于长时间的多边互动。通过不同的对齐方法，可以显著改善多智能体协作的协调性和效率，从而支持正确的任务结果。
## 24. `cs.LG` - 公共数据上高效单阶段训练的竞争性音频-语言模型 [PDF](https://arxiv.org/pdf/2509.07526), [HTML](https://arxiv.org/abs/2509.07526)
### Authors
Gokul Karthik Kumar,Rishabh Saraf,Ludovick Lepauloux,Abdul Muneer,Billel Mokeddem,Hakim Hacid
### Background
尽管大型语言模型（LLMs）在自然语言处理（NLP）中取得了重大进展，但它们与音频的整合仍然相对空白，尽管音频对人类交流至关重要。目前，大多数LLMs主要处理文本，而音频数据的利用尚未充分探索。
### Innovation
本文介绍了Falcon3-Audio，这是一种基于指令调优的LLM和Whisper编码器构建的音频-语言模型（ALMs）家族。通过少量公开音频数据（不到30K小时，5K个唯一样本），Falcon3-Audio-7B在MMAU基准测试中达到了64.14的得分，与R1-AQA持平，同时展示了更好的数据和参数效率、单阶段训练和透明性。小到1B的模型也表现出与2B至13B参数的开放模型相当的竞争能力。研究发现，常用的复杂技术如渐进学习、多个音频编码器和复杂的跨注意力连接器并非实现高性能所必需的。
### Conclusion
通过广泛的消融测试，确认了常用复杂性的非必要性，即使与超过50万小时音频数据训练的模型相比，也证明了小模型的可靠性和效率。
## 25. `cs.LG` - VeriLLM：一种轻量级的可公开验证的分布式推理框架 [PDF](https://arxiv.org/pdf/2509.24257), [HTML](https://arxiv.org/abs/2509.24257)
### Authors
Ke Wang,Zishuo Zhao,Xinyuan Song,Zelin Li,Libin Xia,Chris Tong,Bill Shi,Wenjie Qu,Eric Yang,Lynn Ai
### Background
去中心化的推理提供了一种可扩展和鲁棒的方式，用于提供大型语言模型（LLMs），它允许全球资源碎片化利用，减少对集中式提供者的依赖。然而，在没有可信节点的开放环境中，确保模型输出的正确性仍然是一个核心挑战。
### Innovation
我们引入了VeriLLM，这是一种可公开验证的去中心化LLM推理协议，实现了安全性保证的同时保持了实际的效率。VeriLLM结合了轻量级的实证重跑与最小的链上检查，限制了搭便车行为，允许验证者在大约1%的基础推理成本下验证结果，通过挖掘预取和自回归解码之间的结构分离。为了防止验证瓶颈，我们设计了一个等效推理-验证架构，通过在相同的GPU工作程序上复用推理和验证角色，此设计（i）提高了GPU利用率和整体吞吐量，（ii）扩大了有效的验证者集，增强了可靠性和活力，（iii）通过防止任务区分来阻止节点特定的优化或选择性行为。
### Conclusion
通过理论分析和系统层面的评估，我们证明了VeriLLM实现了可靠且具有最小开销的公共可验证性，为可信和可扩展的去中心化LLM推理提供了实用的基础。
## 26. `cs.LG` - 离散吸引子神经网络中稠密模式的动力学稳定性 [PDF](https://arxiv.org/pdf/2507.10383), [HTML](https://arxiv.org/abs/2507.10383)
### Authors
Uri Cohen,Máté Lengyel
### Background
神经网络存储多个离散吸引子是生物记忆的经典模型。此前，这样的网络的动力学稳定性只能在极其限制的条件下得到保证。
### Innovation
作者推导出了一种理论，分析了一类具有分级神经活动和噪声的网络中离散固定点的局部稳定性。通过直接分析雅可比谱的总体和异常值，发现固定点在低于某个关键负载时是稳定的，该负载与经典的关键容量不同，并依赖于固定点中神经活动的统计特性和单个神经元的激活函数。
### Conclusion
分析突出了阈值线性激活和类似稀疏模式的计算优势。
## 27. `cs.LG` - 恶意AI蜂群如何威胁民主：具有代理AI和LLM的信息战争新前沿 [PDF](https://arxiv.org/pdf/2506.06299), [HTML](https://arxiv.org/abs/2506.06299)
### Authors
Daniel Thilo Schroeder,Meeyoung Cha,Andrea Baronchelli,Nick Bostrom,Nicholas A. Christakis,David Garcia,Amit Goldenberg,Yara Kyrychenko,Kevin Leyton-Brown,Nina Lutz,Gary Marcus,Filippo Menczer,Gordon Pennycook,David G. Rand,Maria Ressa,Frank Schweitzer,Dawn Song,Christopher Summerfield,Audrey Tang,Jay J. Van Bavel,Sander van der Linden,Jonas R. Kunst
### Background
AI的进步使得大规模操控人群的信念和行为成为可能。大型语言模型和自主代理允许影响运动达到前所未有的规模和精准度。生成式工具能够无损可信度地扩展宣传输出，并且可以廉价地创造更为人类化的虚假信息，其真实性甚至超过人类创作的内容。旨在提升AI推理技巧的方法，例如链式思考提示，同样能够生成更令人信服的虚假内容。这一能力促使一种颠覆性的威胁浮现：协作、恶意的AI代理系统。
### Innovation
融合大型语言模型（LLM）推理与多代理架构，这种系统能够自主协调、潜入社区并高效制造共识。通过适应性地模仿人类社会动态，这种系统对民主构成威胁。
### Conclusion
由于这些危害源自设计、商业激励和治理，文章建议在多个干预点上采取措施，而不是依赖于自愿合规。
## 28. `cs.LG` - LLM基础推荐系统上的成员推理攻击 [PDF](https://arxiv.org/pdf/2508.18665), [HTML](https://arxiv.org/abs/2508.18665)
### Authors
Jiajie He,Min-Chun Chen,Xintong Chen,Xinyang Fang,Yuechun Gu,Keke Chen
### Background
大型语言模型（LLMs）基于推荐系统（RecSys）能够灵活适应不同的领域。利用上下文学习（ICL），即提示，可以定制推荐功能，包括敏感的历史用户特定项目交互，这些交互可以包含隐式反馈如点击的项目和显式的产品评论。但是，这些私人信息可能会受到新型隐私攻击的影响，目前还没有对此类问题进行过研究。
### Innovation
设计了针对系统提示中受害者历史交互的多种成员推理攻击（MIAs），包括相似性攻击、记忆化攻击、质询攻击和污染攻击。这些攻击利用了LLMs的独特功能或RecSys的特性。在五个最新的开源LLMs和三个知名RecSys基准数据集上进行了详细评估。结果表明，这些MIAs的威胁是真实的：质询和污染攻击显示出显著高的攻击优势。
### Conclusion
成员推理攻击对LLM推荐系统的威胁是现实的，质询和污染攻击显示出显著高的攻击优势。进一步讨论了解决这种威胁的方法，并分析了影响这些攻击的因素，包括系统提示中的射击数量、受害者在射击中的位置以及提示中的污染项目数量等因素。
## 29. `cs.LG` - Behind the Scenes: Mechanistic Interpretability of LoRA-adapted Whisper for Speech Emotion Recognition [PDF](https://arxiv.org/pdf/2509.08454), [HTML](https://arxiv.org/abs/2509.08454)
### Authors
Yujian Ma,Xikun Lu,Jinqiu Sang,Xianquan Jiang,Ruizhe Li
### Background
大型预训练语音模型，如Whisper，表现出强大的泛化能力，但对资源高效的适配提出了巨大挑战。低秩适应（LoRA）成为一种流行的参数高效微调方法，但在语音任务中的基本机制仍然不甚了解。这项研究首次系统地研究了LoRA在Whisper编码器中的机制解释性，特别是在语音情绪识别（SER）中的应用。
### Innovation
通过使用一系列分析工具，包括层级贡献探针、logit-lens检查以及通过奇异值分解（SVD）和中心核对齐（CKA）的表示相似性，揭示了两个关键机制：一种延迟的专业化进程，保持早期层中的通用特征，然后整合特定任务信息；以及LoRA矩阵间前向对齐、后向差分动态。这些发现阐明了LoRA如何重新塑造编码器层次结构，并为设计高效和解释性适应策略提供了实证见解和深入的机制理解。
### Conclusion
研究表明LoRA通过重塑编码器层次结构，对大型语音模型的高效和解释性适应策略提供了深刻理解，为未来的研究和应用设计提供了指导。相关代码可从此处获取。
## 30. `cs.LG` - 基于动态探索的分段建议图管状中心线追踪 [PDF](https://arxiv.org/pdf/2506.18930), [HTML](https://arxiv.org/abs/2506.18930)
### Authors
Chong Di,Jinglin Zhang,Zhenjiang Li,Jean-Marie Mirebeau,Da Chen,Laurent D. Cohen
### Background
现有的管状中心线追踪方法，如点式方法（例如最小路径法），虽然理论上有很好的美感，但在复杂场景下容易出现捷径和短分枝组合的问题。而非局部的分段式方法通过将预先提取的中心线片段映射到分段建议图上，在该抽象空间中进行优化，并从结果中的最佳路径恢复目标管状中心线。然而，这些现有的分段式方法在构建图时是静态的，需要预先计算所有边及其权重，即图必须在搜索之前足够完整。否则，真正的路径可能不存在于候选空间中，导致搜索失败。
### Innovation
本文提出了一种动态探索方案，用于构建分段建议图。该图是在搜索最优路径期间按需构建的。通过将问题形式化为马尔可夫决策过程并应用Q学习，仅对访问过的过渡计算边权重，并在连通性不足时自适应地扩展动作空间。在视网膜血管、道路和河流上的实验结果证明了本方法在准确性和效率上都优于现有最先进的方法。
### Conclusion
本文提出的基于动态探索的分段建议图的管状中心线追踪方法，在准确性和效率上都优于现有的方法，特别是在复杂场景下对捷径和短分枝问题有更好的处理能力。通过动态构建图结构，能够更好地寻找真实的路径，避免因图的不完善而导致的搜索失败问题。
