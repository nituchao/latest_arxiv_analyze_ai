# 20251024
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - LLMs可以隐藏在相同长度的其他文本中 [PDF](https://arxiv.org/pdf/2510.20075), [HTML](https://arxiv.org/abs/2510.20075)
### Authors
Antonio Norelli,Michael Bronstein
### Background
在如今，一段有意义的文本可以隐藏在另一个完全不同但仍然连贯和可信的文本中，且同样长度。借助大型语言模型（LLMs），这一现象成为可能。作者指出，即使是小型的开源LLM（参数不足8亿）也能生成高质量的结果，甚至能够在笔记本电脑上以秒为单位对较长的文本进行编码和解码。
### Innovation
本文提出了一种简单且高效的协议，以实现文本隐藏。即使较小的LLM也可以生成高质量的结果。此协议还展示了文本与作者意图的极大脱钩，进一步削弱了人们对书面交流的信任。其中一个具体的场景是，公司可以通过在合规响应中嵌入未经过滤的LLM答案来隐蔽地部署未过筛的LLM。
### Conclusion
这种协议不仅挑战了我们对LLM的知识理解，还可能引发AI安全的紧迫问题，提醒我们需要重新考虑如何定义LLM对某个事物的了解。
## 2. `cs.AI` - 由生成式AI推动的新型车辆保险欺诈 [PDF](https://arxiv.org/pdf/2510.19957), [HTML](https://arxiv.org/abs/2510.19957)
### Authors
Amir Hever,Itai Orr
### Background
保险欺诈是一个普遍存在且代价高昂的问题，每年导致几十亿美元的损失。在车辆保险行业中，欺诈手法传统上包括人为制造事故、夸大损害或伪造文件。随着生成式AI技术的发展，特别是深度伪造图像和视频生成技术的应用，欺诈手段变得更加规模化和高效。诈骗者现在可以轻松制造出高度逼真的事故照片、损害证据，甚至伪造身份和文件，借此欺诈保险机构。尽管保险公司已经开始采用基于AI的深度伪造检测软件和加强验证流程来预防和应对这些AI驱动的骗局，但现有的对策存在显著局限性，例如误报和漏报问题，且高明的诈骗者不断调整策略以规避自动化检查。
### Innovation
本文分析的论文介绍了UVeye的分层解决方案，旨在检测、缓解和防止新型以生成式AI为工具的保险欺诈，这代表了在检测和遏制此类欺诈方面的重要进步。
### Conclusion
尽管AI技术的发展使得保险欺诈更加复杂和难以检测，但UVeye的解决方案为对抗这种新型欺诈提供了一种强大的手段，但仍需在实践中不断优化和调整以应对欺诈者的变化策略。
## 3. `cs.AI` - Branch-and-Browse: 有效的树结构推理和动作记忆导向的高效可控网络探索 [PDF](https://arxiv.org/pdf/2510.19838), [HTML](https://arxiv.org/abs/2510.19838)
### Authors
Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury
### Background
自主网络代理受大规模语言模型(LLMs)驱动，展现出强大的进行目标导向任务的能力，如信息检索、报告生成和在线交易。这些代理是实现开放网络环境中实用化嵌入式推理的关键一步。然而，现有方法在推理深度和效率上仍有限制：简单的线性方法无法进行多步骤推理，缺乏有效的回溯能力；而其他搜索策略则过于粗略，计算成本高。因此，需要一种更精细的方法来解决这些问题。
### Innovation
该论文介绍了Branch-and-Browse，一种细粒度的网络代理框架，它统一了结构化的推理-行动、上下文记忆和高效执行。该方法（i）通过树结构探索进行显式子任务管理，支持可控的多分支推理；（ii）通过高效的网页状态回放结合背景推理来启动探索；（iii）利用页面动作记忆，共享跨会话已探索的动作。实验结果表明，Branch-and-Browse在WebArena基准测试中将任务成功率提高了35.8%，并将执行时间降低了40.4%，证明了该框架的有效性和效率。
### Conclusion
Branch-and-Browse为LLM驱动的网络代理提供了一种可靠且高效的框架。
## 4. `cs.AI` - AI PB：一种用于个性化投资见解的接地生成代理 [PDF](https://arxiv.org/pdf/2510.20099), [HTML](https://arxiv.org/abs/2510.20099)
### Authors
Daewoo Park,Suho Park,Inseok Hong,Hanwool Lee,Junkyu Park,Sangjun Lee,Jeongman An,Hyunbin Loh
### Background
该研究介绍了一个名为AI PB的生产规模生成代理，应用于实际零售金融领域。该系统与被动回答查询的反应式聊天机器人不同，能够主动生成具体、合规且用户特定的投资见解。此外，系统需在符合韩国金融监管要求的环境中运行，使用Docker Swarm管理和部署多块NVIDIA H100 GPU，确保高性能和安全性。通过实际应用中的质保和系统指标，验证了该系统在高风险金融领域的可靠性和实用性。
### Innovation
AI PB引入了以下创新技术：(1) 基于数据敏感性的组件化编排层，(2) 结合OpenSearch和金融领域嵌入式模型的混合检索管道，(3) 一个多阶段推荐机制，包括规则启发式、序列行为建模和上下文臂赛跑等多种方法。这些技术旨在实现生成的具体性、合规性以及用户的个人化需求，同时通过多层次的安全机制确保了系统的可靠性.
### Conclusion
通过人类验证和系统指标，研究证明了基于显式路由和分层安全机制的生成方法可以在高风险金融环境中提供可靠的AI见解。该系统展示了生成代理在实际金融布局中的有效应用，并为其他业务场景提供了参考。
## 5. `cs.AI` - RELATE: 一种用于多模态关系图的无模式感知感知机编码器 [PDF](https://arxiv.org/pdf/2510.19954), [HTML](https://arxiv.org/abs/2510.19954)
### Authors
Joseph Meyer,Divyansha Lachi,Reza Mohammadi,Roshan Reddy Upendra,Eva L. Dyer,Mark Li,Tom Palczewski
### Background
在电子商务、医疗保健和科学研究等领域中，关系多表数据非常普遍，可以自然地表示为具有多模态节点属性的异构时间图。现有的图神经网络（GNN）依赖于特定模式的特征编码器，需要为每个节点类型和特征列设置单独的模块，这限制了其可扩展性和参数共享。
### Innovation
我们引入了RELATE（关系编码器，用于类型化实体的潜在聚合），这是一种无模式感知的插拔式特征编码器，可以与任何通用图神经网络一起使用。RELATE利用共享的模态特定编码器处理分类、数值、文本和时间属性，然后通过类似于感知机的交叉注意模块将特征聚合为固定大小且抗排列性的节点表示。
### Conclusion
我们在RelBench基准上的ReLGNN和HGT中评估了RELATE，结果显示其性能与特定模式编码器相差不超过3%，而参数量减少多达5倍。这种设计支持不同模式的变化，并允许通用图神经网络的多数据集预训练，从而为关系图数据的基座模型铺平道路。
## 6. `cs.AI` - Surfer 2：下一代跨平台计算机使用代理 [PDF](https://arxiv.org/pdf/2510.19949), [HTML](https://arxiv.org/abs/2510.19949)
### Authors
Mathieu Andreux,Märt Bakler,Yanael Barbier,Hamza Ben Chekroun,Emilien Biré,Antoine Bonnet,Riaz Bordie,Nathan Bout,Matthias Brunel,Aleix Cambray,Pierre-Louis Cedoz,Antoine Chassang,Gautier Cloix,Ethan Connelly,Alexandra Constantinou,Ramzi De Coster,Hubert de la Jonquiere,Aurélien Delfosse,Maxime Delpit,Alexis Deprez,Augustin Derupti,Mathieu Diaz,Shannon D'Souza,Julie Dujardin,Abai Edmund,Michael Eickenberg,Armand Fatalot,Wissem Felissi,Isaac Herring,Xavier Koegler,Erwan Le Jumeau de Kergaradec,Aurélien Lac,Maxime Langevin,Corentin Lauverjat,Antonio Loison,Avshalom Manevich,Axel Moyal,Axel Nguyen Kerbel,Marinela Parovic,Julien Revelle,Guillaume Richard,Mats Richter,Ronan Riochet,María Santos,Romain Savidan,Laurent Sifre,Maxime Theillard,Marc Thibault,Ivan Valentini,Tony Wu,Laura Yie,Kai Yuan,Jevgenij Zubovskij
### Background
建立能够在网页、桌面和移动设备之间跨平台通用的代理仍然是一个开放的挑战，因为之前的系统依赖于特定环境的接口，这限制了它们的跨平台部署能力。现有的系统在所有三个环境中的表现尚不够理想，因此需要一种新的统一架构来解决这一问题，以实现跨平台操作并提高准确性。
### Innovation
介绍了Surfer 2，这是一种统一的架构，仅基于视觉观察运行，能够在所有三种平台上取得最先进的性能。Surfer 2整合了分层上下文管理、解耦规划与执行、自我验证以及自适应恢复功能，从而使长时间任务操作更加可靠。Surfer 2在WebVoyager上的准确率为97.1%，在WebArena上的准确率为69.6%，在OSWorld上的准确率为60.1%，在AndroidWorld上的准确率为87.1%，并且在多次尝试后超过了人类的表现，超过所有之前系统的性能，而无需针对特定任务进行微调。这些结果表明系统性的编排能够增强基础模型的能力，并能仅通过视觉交互实现通用的计算机控制。同时，这也提出了对未来一代视觉语言模型的需求，以达到最佳的成本效率。
### Conclusion
这些结果表明系统性的编排能够增强基础模型的能力，并能仅通过视觉交互实现通用的计算机控制，而未来的视觉语言模型需要致力于实现成本效率与性能的最佳平衡。
## 7. `cs.AI` - 一种解决数独谜题和最大切割问题的启发式量子算法 [PDF](https://arxiv.org/pdf/2510.19835), [HTML](https://arxiv.org/abs/2510.19835)
### Authors
Max B. Zhao,Fei Li
### Background
本文提出了一个针对数学上等价于Ising自旋玻璃哈密顿量的基态寻找问题的量子启发式算法，特别是对于Quadratic Unconstrained Binary Optimization (QUBO)问题。算法使用矩阵乘积态(MPS)高效表示大规模自旋配置的叠加，并通过一个离散的驱动调度指导MPS向基态演化。每次迭代中，问题哈密顿量结合驱动哈密顿量（包含横向磁场）以允许自旋翻转并促进量子隧穿。算法使用标准密度矩阵重正化群(DMRG)更新MPS，该方法通过多次扫掠自旋链来逐步最小化系统的能量。
### Innovation
该算法通过使用矩阵乘积态(MPS)和密度矩阵重正化群(DMRG)方法，提供了一种高效解决QUBO问题的新方法。具体来说，这是一种通过离散驱动调度引导自旋配置向基态演化的量子启发式算法，即使在复杂问题实例上也能可靠地找到全局最小值。
### Conclusion
该量子启发式算法在多种QUBO实例上展示了其有效性，尤其是在数独谜题和MaxCut问题上的应用，成功解决了大量节点和边的实例。该算法的特点包括可扩展性、普适性和适合大规模工业应用，为QUBO问题提供了一种新的解决方案。
## 8. `cs.AI` - AI驱动的个性化学习：通过领导人格特质预测学术表现 [PDF](https://arxiv.org/pdf/2510.19964), [HTML](https://arxiv.org/abs/2510.19964)
### Authors
Nitsa J Herzog,Rejwan Bin Sulaiman,David J Herzog,Rose Fong
### Background
该研究探讨了人工智能技术在个性化学习中的潜力，特别是通过运用机器学习模型预测学术成功，利用领导人格特质进行预测。研究数据来自于环境保护工程系129名硕士生，这些学生进行了五项领导人格测试，共涵盖23个特点。通过结合自评估工具（如人格洞察、工作文化、工作动力、管理技能和情绪控制测试）的结果与学业成绩，采用探索性数据分析和相关性分析，选用皮尔森相关系数进行特征选择，将成绩分为三类：不及格、及格和优秀。通过调整支持向量机（SVM）、逻辑回归（LR）、K近邻算法（KNN）、决策树（DT）、梯度提升（GB）、随机森林（RF）、XGBoost和LightGBM七种机器学习算法，研究成果显示随机森林分类器表现最佳，其包含17个人格特质特征和领导标记特征的模型准确率为87.50%，不含该特征的模型准确率为85.71%。
### Innovation
通过使用领导人格特质来预测学术表现，论文创新性地结合了机器学习算法与个性特征分析，为早期识别学生的优势与劣势以及个性化学习策略的选择提供了新途径。
### Conclusion
研究表明，使用随机森林分类器能够实现较高的预测准确率，并且通过分析领导人格特质可以有效地识别学生的学术表现，为个性化学习策略的选择提供了科学依据。这一方法有助于早期发现学生的学习问题，并制定针对性的学习计划。
## 9. `cs.AI` - 能源系统分析中的人工智能模型推理可靠性基准测试 [PDF](https://arxiv.org/pdf/2510.19836), [HTML](https://arxiv.org/abs/2510.19836)
### Authors
Eliseo Curcio
### Background
人工智能和机器学习在能源领域的预测、优化和政策设计中越来越广泛使用，但缺乏标准化的框架来评估这些系统是否合理推理。目前的验证实践主要关注预测准确性或计算效率，而未考验分析结论的逻辑完整性。因此，该研究旨在引入一种坚实的框架，即Analytical Reliability Benchmark (ARB)，以量化应用于能源系统分析的大规模语言模型的推理可靠性。
### Innovation
研究引入了Analytical Reliability Benchmark (ARB)，这是一种可重复的框架，用于量化应用到能源系统分析中的大型语言模型的推理可靠性。ARB集成了五个子指标：准确率、推理可靠性、不确定性纪律、政策一致性以及透明度。研究测试了四个前沿模型（GPT-4/5、Claude 4.5 Sonnet、Gemini 2.5 Pro和Llama 3 70B），并在一致的实际情况和监管条件下进行测试。结果显示，推理可靠性可以客观测量，GPT-4/5和Claude 4.5 Sonnet表现出一致并符合政策的推理（Analytical Reliability Index大于90），Gemini 2.5 Pro显示出中等稳定性，而Llama 3 70B则未能达到专业标准。统计验证证实这些差异具有显著性和可重复性。该研究在能源文献中首次建立了量化验证因果、概率和政策驱动推理的人工智能系统的方法，并为全球能源转型中的可信和透明分析应用提供了参考框架。
### Conclusion
ARB为验证能源系统分析中的人工智能系统的因果、概率和政策驱动的推理提供了一个定量方法，为全球能源转型中的可信和透明分析应用提供了基准框架。
## 10. `cs.AI` - DAG-Math: 依据图结构的数学推理在大语言模型中的应用 [PDF](https://arxiv.org/pdf/2510.19842), [HTML](https://arxiv.org/abs/2510.19842)
### Authors
Yuanhe Zhang,Ilja Kuzborskij,Jason D. Lee,Chenlei Leng,Fanghui Liu
### Background
大语言模型（LLMs）在以链式思考（CoT）提示时展现出强大的数学问题解决能力，但尚未明确这种成功是源于搜索、机械程序还是规则一致性推理。该研究通过将CoT建模为有向无环图（DAG）上的确定性规则基随机过程，来探讨这一问题。在这一框架下，提出了逻辑接近度这一度量标准，用以评估模型的CoT轨迹与DAG结构的契合程度，从而超越传统PASS@k度量。基于此框架，提出DAG-MATH CoT格式，并构建一个基准测试，以引导LLMs生成遵循此格式的CoT轨迹，从而评价其推理能力。
### Innovation
作者提出了一种将CoT过程建模为DAG上的确定性规则基随机过程的方法，并引入了逻辑接近度作为评估标准。此外，还提出了DAG-MATH CoT格式和相应的基准测试，以评估LLMs的推理能力。这为LLMs的推理评估提供了平衡自由形式CoT和形式证明系统的方法，提供了实际的诊断工具。
### Conclusion
在标准数学推理数据集上，该研究揭示了代表性LLM家族在推理准确度方面存在统计显著性差异——即使PASS@k值相当也是如此，这突显了最终答案准确性和规则一致性推理之间的差距。该框架提供了自由形式CoT和形式证明系统之间的平衡点，为LLMs推理评估提供了实用诊断手段。同时，作者指出，该基准测试和代码可以在指定的链接地址获取。
## 11. `cs.AI` - 面向数字资产异常交易检测的人本导向LLM代理系统 [PDF](https://arxiv.org/pdf/2510.20102), [HTML](https://arxiv.org/abs/2510.20102)
### Authors
Gyuyeon Na,Minjung Park,Hyeonjeong Cha,Sangmi Chai
### Background
现有系统主要依赖于复杂的机器学习模型进行数字资产交易的异常检测，但缺乏用户友好性和解释性。论文背景在于，需要一种既能准确检测异常，又能提供易于理解的解释和交互式优化的系统，以便非专业人士也能进行金融侦查并提高透明度和信任度。
### Innovation
该论文提出了HCLA，一种基于人类中心的多代理系统，通过将解析、检测和解释三个角色整合到一个对话式工作流程中，使得非专家可以以自然语言提问、查看结构化分析和获得上下文相关的解释。该系统使用开源Web界面实现，能够将用户意图转换成经典检测器（如原型中的XGBoost）的模式，并返回基于底层特征的叙述性解释。与基线检测器相比，HCLA在解释性和互动性方面有所改进，尤其是在使用一个标记的比特币混合数据集（Wasabi Wallet, 2020-2024）时表现显著。
### Conclusion
该研究描述了HCLA系统的技术架构、交互流程、数据集、评估方法以及限制，同时强调，基于人类在环的设计能够提高金融侦查中的透明度和信任度。
## 12. `cs.AI` - AGI 阶段假设：身份整合作为通往 AGI 的先决条件 [PDF](https://arxiv.org/pdf/2510.20190), [HTML](https://arxiv.org/abs/2510.20190)
### Authors
Marcelo Maciel Amaral,Raymond Aschheim
### Background
大型语言模型 (LLMs) 保持开放和高度可控：它们大规模模仿，接受任意系统提示，并迅速采纳多种人设。类比人类发展，作者假设通往通用人工智能 (AGI) 的进程包括一个锁定阶段：从开放模仿转向身份整合，在此期间目标结构、拒绝、偏好和内部表示变得相对稳定并对抗外部控制。
### Innovation
作者提出‘锁定阶段假设’，并通过正式化这个阶段与已知学习动态现象联系起来，提出了操作性指标以检测起始点。实验证明解锁阶段的行为整合虽然快速且非线性，但对通用能力的影响不是单一的。研究揭示了不同规模模型的结果谱系，包括小型模型中的性能权衡、中型模型的几乎无成本采纳以及大型量化模型中的暂时不稳定。
### Conclusion
这种整合是 AGI 级可靠性的一个前提，也是安全的关键控制点：身份可以人为设计以确保可靠性，也可能在扩缩放过程中自发形成，这可能会硬化无法预测的目标和行为。
## 13. `cs.AI` - 使用大型语言模型进行规划领域抽象 -  Expanded 版本 [PDF](https://arxiv.org/pdf/2510.20258), [HTML](https://arxiv.org/abs/2510.20258)
### Authors
Bita Banihashemi,Megh Patel,Yves Lespérance
### Background
在动态领域中生成与给定目的相匹配的抽象仍然是一项重大挑战，因为抽象的选择可能影响代理规划、推理和解释的能力。当前，代理的具体行为被建模在PDDL中，但如何使用这些具体行为生成符合自然语言指定抽象目标的抽象PDDL领域和问题实例，特别是在大规模语言模型（LLMs）的背景下，仍然是一个研究空白。
### Innovation
提出了利用在上下文中学习的大型语言模型（LLMs）来生成规划领域的抽象PDDL领域和问题实例的方法。该研究特别关注生成不同类型（包括具体动作、动作/谓词参数及其组合的序列）的抽象。并使用了一组之前未训练过LLMs的数据基准示例来验证生成的抽象的有效性。
### Conclusion
实验结果表明，GPT-4o在简单情况下可以一般性地生成有用的过程领域抽象，尤其擅长抽象动作而非相关的变化。符号验证工具和人类专家对生成的抽象进行了验证，证明了其有效性。
## 14. `cs.AI` - 大型语言模型中的个性化认知模拟：评估不同的认知表示方法 [PDF](https://arxiv.org/pdf/2510.20252), [HTML](https://arxiv.org/abs/2510.20252)
### Authors
Tianyi Zhang,Xiaolin Zhou,Yunzhe Wang,Erik Cambria,David Traum,Rui Mao
### Background
当前，大型语言模型（LLMs）能够具有很高的表面水平模仿人类行为的能力，比如角色扮演，但它们在模拟更深层次的个体认知过程方面的能力尚不清楚。为了填补这一空白，本文引入了一个新的任务来评估不同认知表示方法在个性化认知模拟（ICS）中的效果。该任务通过构建来自新近出版的小说数据集来进行评估，并提出了一套包含11个条件的认知评价框架，用于比较七种现有的LLMs在模仿作者写作风格方面的表现。
### Innovation
本文提出了一个新颖的任务，以评估不同认知表示方法在个体认知模拟中的效果。并且通过构建来自新近出版的小说数据集和提出11条件的认知评估框架，首次系统性地评估了七种现有LLMs在作者写作风格模仿上的能力。
### Conclusion
研究结果表明，在个性化认知模拟中，结合概念和语言特性特别有效，整体表现优于基于静态个人资料的提示。但值得注意的是，LLMs在模仿语言风格方面比模仿叙述结构更有效，这表明它们在更深层次的认知模拟方面存在局限性。这些发现为开发能够适应个人思维和表达方式的AI系统提供了基础，推动了更个性化和人类导向的创新技术的发展。
## 15. `cs.AI` - 验证价值悖论：关于法律实践中生成型AI的规范性批判 [PDF](https://arxiv.org/pdf/2510.20109), [HTML](https://arxiv.org/abs/2510.20109)
### Authors
Joshua Yuvaraj
### Background
人们普遍认为基于机器学习的生成型人工智能产品将极大地简化和降低成本的法律实践。这一乐观观点假设律师能够有效地管理AI的风险。然而，澳大利亚等地律师被责备提交不准确的AI生成内容给法院的案例表明，这种观点需要重新审视。文章指出，在考虑AI与现实的脱节、缺乏透明性以及律师的重要职责如诚信、遵守道德和不容误导法庭等因素后，需要一个新的评估AI法律实践使用的新范式。
### Innovation
文章提出了人工智能在法律实践中使用的一个替代模型，称为'验证价值悖论'，旨在更全面地反映AI可能带来的效率增加和需要的对应的更严格的验证需求之间的矛盾。该悖论暗示，尽管AI的使用可以提高效率，但随之而来的手动验证需求将会增加，导致AI价值对律师来说经常是可忽略不计的。此外，文章还探讨了这一悖论对法律实践和法律教育的含义，以及它所提出的法律实践应以忠实于事实和公民责任为基础的价值观。
### Conclusion
验证价值悖论表明，在法律实践中使用人工智能可能会带来效率的提升，但这也需要更高的手动验证要求。这种提升和要求之间的矛盾使得AI的实际价值在很多情况下可能被抵消。因此，文章建议未来需要更加注重对法律实践的真相的忠实和公民责任感，以此为基础来重新考虑AI在法律实践中的使用和培训策略。
## 16. `cs.AI` - Design中的偏见？数据实践如何塑造医疗AI系统的公平性 [PDF](https://arxiv.org/pdf/2510.20332), [HTML](https://arxiv.org/abs/2510.20332)
### Authors
Anna Arias-Duart,Maria Eugenia Cardello,Atia Cortés
### Background
人工智能在医疗领域的应用充满潜力，但AI解决方案在实际临床环境中的融合仍受到限制。主要障碍在于数据的质量和公平性，这些往往由于偏差的数据收集实践而受损。本文的研究基于西班牙国家研发计划中的AI4HealthyAging项目，目的是在临床数据收集过程中发现偏差。研究识别了多种类型的偏差，包括历史偏差、代表性偏差和测量偏差，并在性别、年龄、居住地、经济状况、设备和标签等多个变量中表现出来。
### Innovation
通过发掘和总结多种类型的数据偏差，本文填补了在临床数据收集过程中公平性问题上的知识空白，有助于未来开发更加公正的AI系统。
### Conclusion
文章提出了改进医疗AI系统设计和数据收集以增强其公平性和鲁棒性的实际建议，希望研究成果能够引导未来的相关项目，促进医疗AI系统的公平性发展。
## 17. `cs.AI` - 合并与征服：进化优化2048的人工智能 [PDF](https://arxiv.org/pdf/2510.20205), [HTML](https://arxiv.org/abs/2510.20205)
### Authors
Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum
### Background
在机器学习研究中，如何优化人工智能以应对动态环境仍是一个基本挑战。本研究探讨了进化训练方法以优化人工智能解决2048游戏（一种二维滑动拼图游戏）的方法。2048游戏结合了战略性游戏玩法和随机性，为研究决策制定、长期计划和动态适应提供了理想的试验场。研究实施了两个不同的系统，一个是双代理元提示系统，另一个是基于减少蒙特卡洛树搜索中的价值函数优化的单代理系统。此外，还测试了回滚功能以避免性能退化。研究表明，进化优化技术有望在非确定性环境中提高人工智能的表现。单代理系统取得了显著改进，平均每周期提高了473.2分，以及在训练周期中表现出明显的上升趋势（相关系数ρ=0.607）。代理的对游戏的理解也随着其越来越先进的策略的发展而增强。相比之下，双代理系统几乎没有提高，突显了元提示的固有限制。
### Innovation
该研究引入了两个不同的人工智能训练系统：一个双代理元提示系统和一个基于减小蒙特卡洛树搜索中价值函数优化的单代理系统。此外，研究测试了回滚功能以避免性能退化，展示了进化优化技术在非确定性环境中的潜力，特别是在单代理系统中取得了显著的提高，且平均分提高了473.2分，显示出明确的趋势上升（相关系数ρ=0.607）。
### Conclusion
该研究的结果表明，基于进化优化的技术可以在不确定性的环境中提高人工智能的表现。单代理方法显示出明显的优势，证明了它作为解决复杂决策问题的有效方法的一部分价值。然而，研究也表明，双代理系统在解决此类问题时可能受到局限，未来研究可能需要探索新的方法或改进现有方法以更有效地解决这类问题。
## 18. `cs.AI` - 经典特征嵌入有助于基于BERT的人类移动性预测 [PDF](https://arxiv.org/pdf/2510.20275), [HTML](https://arxiv.org/abs/2510.20275)
### Authors
Yunzhi Liu,Haokai Tan,Rushi Kanjaria,Lihuan Li,Flora D. Salim
### Background
人类移动性预测对于灾害救援、城市规划和公共卫生至关重要。现有的模型要么仅能建模位置序列，要么将时间信息作为辅助输入，未能充分利用地点兴趣（POIs）提供的丰富语义上下文。这限制了移动性预测的精度和有效性。
### Innovation
该研究提出了一种名为STaBERT的模型，结合了基于BERT的方法，并通过引入推导的时间特征和POI嵌入来更好地捕捉人类移动的语义。STaBERT在每个位置处整合位置和时间信息，构建统一的、语义丰富的移动性表示。实验结果显示，STaBERT显著提高了预测准确性：单城市预测的GEO-BLEU分数从0.34提高到0.75，多城市预测从0.34提高到0.56。
### Conclusion
通过引入时间特征和POI嵌入，STaBERT增强了基于BERT的人类移动性模型，显著提升了预测性能。
## 19. `cs.AI` - 工具增强的多步推理在沉浸式问题回答中的应用 [PDF](https://arxiv.org/pdf/2510.20310), [HTML](https://arxiv.org/abs/2510.20310)
### Authors
Mingliang Zhai,Hansheng Liang,Xiaomeng Fan,Zhi Gao,Chuanhao Li,Che Sun,Xu Bin,Yuwei Wu,Yunde Jia
### Background
现有的沉浸式问题回答（EQA）方法主要依靠视觉语言模型（VLMs）直接探索环境并回答问题，这限制了它们的推理能力，导致了过度或低效的探索和不准确的回答。研究者们希望提高EQA模型在使用工具和进行多步推理的能力，以便生成更准确的回答，同时减少探索距离。
### Innovation
本文提出了ToolEQA，一种集成了外部工具的多步推理代理模型。ToolEQA利用外部工具提供更多信息以完成任务，帮助模型为下一步推理推导出更好的探索方向，从而收集额外有效的信息。为此，研究者设计了一种新的EQA数据生成流水线，以自动化构建大规模EQA任务及其推理轨迹和答案。基于此流水线，收集了包含约18K任务的EQA-RT数据集，并在两个测试集EQA-RT-Seen和EQA-RT-Unseen上进行实验，结果表明ToolEQA相对于最先进的baseline提高了9.2%到20.2%的成功率，在某些数据集上的表现也超越了零样本的ToolEQA，展示了其通用性。
### Conclusion
ToolEQA在EQA-RT-Seen和EQA-RT-Unseen上的实验表明，该模型在成功率达到9.2%至20.2%的提升，优于最先进的baseline方法，同时在零样本实验中超过了10%的成功率。ToolEQA还展示了在HM-EQA、OpenEQA和EX-PRESS-Bench数据集上的最先进性能，证明了其普遍适用性。
## 20. `cs.AI` - TRUST: 一种用于审计大型语言模型推理的去中心化框架 [PDF](https://arxiv.org/pdf/2510.20188), [HTML](https://arxiv.org/abs/2510.20188)
### Authors
Morris Yu-Chao Huang,Zhen Tan,Mohan Zhang,Pingzhi Li,Zhuo Zhang,Tianlong Chen
### Background
大型语言模型生成复杂的推理链，揭示其决策过程，但验证这些中间步骤的准确性和无害性仍然是一个未解决的关键问题。现有审计方法集中在单一审计者上，缺乏透明度和难以扩展，这在高风险领域部署私有模型时带来了重大风险。现有审计面临四个核心挑战：(1) 稳定性：单一审计点易受攻击或偏见；(2) 可扩展性：推理轨迹过长，无法手动验证；(3) 不透明性：封闭审计损害公众信任；(4) 隐私：暴露完整推理可能导致模型盗窃或知识提取。
### Innovation
提出TRUST，一种透明的去中心化审计框架，通过以下方式克服这些限制：(1) 多样审计者之间的共识机制，当最多30%参与者恶意时仍能保证正确性；(2) 以层级DAG分解推理轨迹，实现可扩展和并行审计；(3) 区块链记录所有验证决策，增强公信力；(4) 隐私保护分段，仅分享部分推理步骤保护私有逻辑。提供TRUST框架的安全性和经济激励的理论保证。实验表明TRUST能有效检测推理缺陷并保持对恶意审计的抵抗力，为安全可靠的LLM部署提供了实际途径。
### Conclusion
通过TRUST框架，开创了去中心化AI审计的先河，提供了一条实现安全和可信赖的LLM部署的现实路径。
## 21. `cs.AI` - 一种用于在专业创新过程中生成更多新颖机会的计算模型和工具 [PDF](https://arxiv.org/pdf/2510.20402), [HTML](https://arxiv.org/abs/2510.20402)
### Authors
Neil Maiden,Konstantinos Zachos,James Lockerbie,Kostas Petrianakis,Amanda Brown
### Background
本研究提出了一种新的基于创造力理论和技术的计算模型，旨在为创新项目生成更具新颖性的机会。该模型将五个功能应用于创新项目，目标是在保持实用性的同时增加新颖性。
### Innovation
该研究创新性地开发了一种计算模型，通过集成五个功能来生成更具创新性的机会，同时未降低其应用价值。根据对其在酒店业创新项目中的应用效果的评估，表明该模型能更有效地生成新颖性和实用性兼具的结果，但部分功能限制了新颖性机会的生成，提出了未来模型改进的新方向。
### Conclusion
研究表明，该计算模型确实产生了比Notebook LM和ChatGPT4更好的新颖和有用的成果，但仍需进一步开发和完善，以最大化其在专业创新过程中的效能。
## 22. `cs.AI` - 军事作战中人工智能系统目标打击的附带损害评估模型 [PDF](https://arxiv.org/pdf/2510.20337), [HTML](https://arxiv.org/abs/2510.20337)
### Authors
Clara Maathuis,Kasper Cools
### Background
在人工智能系统在战场中扮演越来越重要角色的时代背景下，确保负责任的打击行动需要对潜在的附带损害进行严格的评估。在此背景下，提出了一种针对军事作战中人工智能系统的目标参与的附带损害评估模型，该模型融合了时间、空间和力量维度，并采用知识表示和推理（KRR）架构的设计科学方法论进行设计。
### Innovation
该模型采用分层结构来捕捉参与打击的人工智能系统的类别和架构组件，同时考虑了影响矢量和上下文方面。此外，该模型还考虑了附带损害的扩散性、严重性、概率以及评价指标，通过透明的推理机制提供清晰的表示。该模型通过实例进行了演示和评估，为构建负责任和值得信赖的人工智能系统以评估参与打击的人工智能系统所产生的效果奠定了基础。
### Conclusion
该研究提出了一个创新的附带损害评估模型，通过综合考虑时间、空间和力量维度，以及透明的推理机制，为评估军事作战中人工智能系统的附带损害提供了新的方法。未来的研究将继续致力于构建能够负责任和值得信赖的人工智能系统，以评估参与打击的人工智能系统产生的效果。
## 23. `cs.AI` - LLM-empowered knowledge graph construction: A survey [PDF](https://arxiv.org/pdf/2510.20345), [HTML](https://arxiv.org/abs/2510.20345)
### Authors
Haonan Bian
### Background
知识图谱(KGs)长期以来一直是结构化知识表示和推理的基本基础设施。随着大型语言模型(LLMs)的出现，知识图谱的构建进入了一个新的范式，从基于规则和统计的方法转变为语言驱动和生成的框架。
### Innovation
本文综述了LLM赋能的知识图谱构建的最新进展，系统分析了LLM如何重塑知识工程、知识提取和知识融合的经典三层管道。从结构化和非结构化的视角分别介绍了新兴的LLM驱动方法，并综合了代表性框架，分析了技术机制及其局限性。
### Conclusion
本文总结了关键趋势和未来研究方向，包括基于知识图谱的LLM推理、具有动态知识记忆的自决策系统以及多模态知识图谱构建。旨在阐明LLM与知识图谱的演化互动，向着发展适应性、可解释和智能的知识系统迈进。
## 24. `cs.AI` - 在SHOIQ中的稳健实例检索的神经推理 [PDF](https://arxiv.org/pdf/2510.20457), [HTML](https://arxiv.org/abs/2510.20457)
### Authors
Louis Mozart Kamdem Teyou,Luke Friedrichs,N'Dah Jean Kouagou,Caglar Demir,Yasir Mahmood,Stefan Heindorf,Axel-Cyrille Ngonga Ngomo
### Background
概念学习通过形式化本体论中的描述逻辑公理来利用背景知识，从而从知识库中学习可解释的分类模型。尽管神经符号概念学习最近取得了突破，但大多数方法仍然无法应用于实际的知识库中。这些问题归因于它们使用描述逻辑推理器，而这种推理器在不一致的数据或错误数据面前不够稳健。因此，急需一种能够在实际环境中适用的高质量推理器。
### Innovation
作者提出了一个名为EBR的新型神经推理器，以解决现有的描述逻辑推理器在面对不一致和错误数据时不够稳健的问题。EBR的主要创新在于它使用嵌入来逼近符号推理器的结果。EBR只需检索原子概念和存在限制中的实例即可检索或近似描述逻辑SHOIQ中任何概念的实例集。实验结果表明，EBR在处理缺失和错误数据时比现有推理器更加稳健。
### Conclusion
在实验中，EBR推理器在面对存在不一致和错误数据的情况下比现有的最先进的推理器表现得更出色。
## 25. `cs.AI` - FLORA：基于模糊逻辑的无监督知识图谱对齐 [PDF](https://arxiv.org/pdf/2510.20467), [HTML](https://arxiv.org/abs/2510.20467)
### Authors
Yiwen Peng(IP Paris),Thomas Bonald(IP Paris),Fabian M. Suchanek(IP Paris)
### Background
知识图谱对齐是指在两个知识图谱之间匹配等价实体（即实例和类）以及关系的任务。现有的大多数方法主要关注实体级别的对齐，在某些嵌入空间中计算实体的相似性，但缺乏可解释的推理，并且需要训练数据才能运行。
### Innovation
本文提出了一种名为FLORA的简单而有效的无监督方法（1）无需训练数据，（2）迭代地为实体和关系提供全面的对齐，（3）基于模糊逻辑，因此提供可解释的结果，（4）可证明收敛，（5）允许悬空实体，即在另一个KG中没有对应实体的实体，（6）在主要基准测试上达到最先进的结果，
### Conclusion
FLORA是一种无监督的、非训练数据依赖的、迭代全面对齐实体和关系的方法，基于模糊逻辑，结果可解释，可证明收敛，能够处理悬空实体，并在主要基准测试中表现优异。
## 26. `cs.AI` - 在大型语言模型中什么是良好的推理？基于多方面评估来分析推理步骤 [PDF](https://arxiv.org/pdf/2510.20603), [HTML](https://arxiv.org/abs/2510.20603)
### Authors
Heejin Do,Jaehui Hwang,Dongyoon Han,Seong Joon Oh,Sangdoo Yun
### Background
目前对大型语言模型（LLMs）的评估主要集中在最终答案的正确性上，这种评估方法虽然能提供一个粗略的改进信号，但忽略了支持推理过程的质量。文章指出，精细化评估推理质量提供了更有效的方法来构建稳健的模型。
### Innovation
文章提出了一种名为因果步骤评估（CaSE）的新方法，将推理质量分解为相关性和连贯性两个维度，并通过专家标注的新基准数据集（MRa-GSM8K和MRa-MATH）验证了CaSE的有效性。更重要的是，通过使用CaSE评估相关性和连贯性来筛选训练数据，可以直接提高最终任务性能。
### Conclusion
文章提供了一个可扩展的框架来分析、调试和改进LLM的推理，展示了从有效性核查转向详细评估的实际价值。
## 27. `cs.AI` - 政策失译：决策者没有真正倾听关于人工智能的公众担忧 [PDF](https://arxiv.org/pdf/2510.20568), [HTML](https://arxiv.org/abs/2510.20568)
### Authors
Susan Ariel Aaronson,Michael Moreno
### Background
全球民众对人工智能(AI)持有强烈观点，并期望政策制定者倾听。尽管政府邀请公众参与讨论AI相关的风险和政策，但实际将公众意见转化为政策的过程中，很多看法都被忽视，这导致政府丧失了建立公众对AI及其治理信任的机会。论文通过比较澳大利亚、哥伦比亚和美国这三个国家的情况，发现这些国家虽然邀请公众参与AI相关的讨论，但政府在吸收公众反馈并将其转化为政策时，未能建立有意义的对话，公众参与度也极其低，政策制定者在回应公众反馈时表现出效率低下。
### Innovation
论文采取了景观分析的方法，对比了不同国家政府获取公众反馈的方式以及这些反馈是否影响政策制定过程。通过这种多国分析，它揭示了当前参与式AI治理实践与理论之间存在的差距。研究提出八项建议，以促进公众对AI的理解、监控公众反馈、扩大宣传范围、定期举办在线论坛、运用创新性的互动方法、加入代表性不足的群体、公开回应公众意见以及让公众参与变得更简单。这些措施旨在帮助决策者更好地倾听和回应公众对AI的关切，从而提高政策的公信力和合法性。
### Conclusion
当前的参与式AI治理方法很可能无法建立公众对AI的信任或合法性。政策制定者需要调整策略，更好地倾听并回应公众意见，以解决该领域的实践与承诺之间的差距。
## 28. `cs.AI` - 用于计算随机游走中心性的一种高效算法 [PDF](https://arxiv.org/pdf/2510.20604), [HTML](https://arxiv.org/abs/2510.20604)
### Authors
Changan Liu,Zixuan Xie,Ahad N. Zehmakan,Zhongzhi Zhang
### Background
随机游走中心性是图挖掘中量化节点重要性和影响力的基本度量指标，它定义为节点到其他所有节点的击中时间的加权平均值。尽管这种度量能够捕捉丰富的图结构信息，并且应用范围广泛，但在计算大型网络时，由于现有方法的计算需求，这仍然是不切实际的。
### Innovation
本文提出了随机游走中心性的一种新颖表征形式和两种可扩展算法：一种利用近似 Cholesky 因子分解和稀疏逆估计，另一种通过采样有根生成树。这两种算法均为近线性时间复杂度，并且具有强的近似保证。
### Conclusion
通过在大规模真实世界网络（包括节点数超过 1000 万的网络）上进行的广泛实验，证明了所提出算法的有效性和近似质量。
## 29. `cs.AI` - 流体性指数：下一代超级智能基准测试 [PDF](https://arxiv.org/pdf/2510.20636), [HTML](https://arxiv.org/abs/2510.20636)
### Authors
Eric Ngoiya,Tianshu Bao
### Background
本文介绍了一种用于衡量模型在动态扩展环境中适应能力的流体性指数（FI）。基准测试根据初始、当前和未来环境状态的偏差来评估响应准确性，并检测上下文切换和连续性。研究区分了封闭式和开放式基准，并强调使用封闭回路的现实开放式基准来测试适应性。这种方法衡量了模型在扩展环境中理解、预测和适应状态变化的能力。真正的超级智能模型应表现出至少第二级的适应性，从而通过数字补充实现自我维持的计算，以实现最佳的流体性。
### Innovation
提出了流体性指数（FI）来量化模型在动态扩展环境中的适应能力；区分了封闭式和开放式基准测试，强调使用封闭回路的现实开放式基准来测试适应性；提出超级智能模型应具备至少第二级的适应性，实现自我维持的计算以优化流体性
### Conclusion
真正超级智能的模型应该表现出至少第二级的适应性，使模型通过数字补充实现自我维持的计算，从而达到最佳流体性。
## 30. `cs.AI` - 将机器学习整合到信念-欲望-意图代理中：当前进展与开放挑战 [PDF](https://arxiv.org/pdf/2510.20641), [HTML](https://arxiv.org/abs/2510.20641)
### Authors
Andrea Agiollo,Andrea Omicini
### Background
机器学习（ML）模型在感知和认知任务中展现出了令人惊叹的人类能力，因此将ML嵌入理性代理架构的框架逐渐流行起来。然而，这些框架尚未形成统一的框架，大多数研究集中在将ML嵌入通用代理容器上，而忽视了理性架构（如信念-欲望-意图（BDI）代理）的表达能力。
### Innovation
本文通过使用BDI范式作为参考，对现有方法进行了细致的系统化分析，揭示了理性代理增强的文献快速发展的现状，并指出了设计有成效的理性ML代理的关键研究机会和开放挑战。
### Conclusion
本文分析了理性代理增强的文献，并指出了设计有效理性ML代理的关键研究机会和开放挑战。
## 31. `cs.AI` - IKnow: 了解增强的持续预训练以实现有效的领域适应 [PDF](https://arxiv.org/pdf/2510.20377), [HTML](https://arxiv.org/abs/2510.20377)
### Authors
Tianyi Zhang,Florian Mai,Lucie Flek
### Background
持续预训练可以使用仅未标注的测试时数据来适应大型语言模型（LLMs）到新的领域，但直接应用标准的自监督目标到指令调优的模型会导致其跟随指令的能 力和语义表示下降。现有的修正方法既依赖原始基础模型，又依赖外部领域特定数据库的知识，但在存在安全原因时会留置基础模型权重，或者可靠的外部语料库不可用的情况下，这些均存在实际障碍.
### Innovation
本文提出了指令知识感知持续适应（IKnow）框架，这是一种简单且通用的方法，通过在指令-响应对话格式中制定新颖的自监督目标来实现。IKnow 不依赖外部资源，而是利用文本本身嵌入的领域知识并学习以更深层次的语义层次来编码它.
### Conclusion
IKnow 提供了一种简单而通用的解决方案，可以在不依赖外部资源的情况下有效增强模型适应新领域的效果，在资源受限的情景下尤为有价值.
## 32. `cs.AI` - 基于复杂算法挖掘可解释模型的可信AI形式化 [PDF](https://arxiv.org/pdf/2510.20621), [HTML](https://arxiv.org/abs/2510.20621)
### Authors
Riccardo Guidotti,Martina Cinquini,Marta Marchiori Manerba,Mattia Setzu,Francesco Spinnato
### Background
可解释的设计模型对提高自动化决策模型在实际应用中的信任、责任和安全采用至关重要。本文提出了MIMOSA框架，全面的方法用于生成兼顾可解释性和性能的预测模型，并嵌入关键伦理属性。该框架涵盖了跨多种决策任务和数据类型（如表格数据、时间序列、图像、文本、交易和轨迹）的监督学习环境。分析了三种主要的可解释模型家族：特征重要性、规则和个例模型的解释维度、推理机制和复杂性。在此基础上，定义了因果性、公平性和隐私这三种关键伦理属性，并提供了形式定义、评估指标和验证程序。
### Innovation
本文提出了MIMOSA框架，这是一种全面的方法，用于生成兼顾可解释性和性能的预测模型，并嵌入关键伦理属性。它定义了监督学习环境的解释性模型以及公平性、隐私性和因果性的三种关键伦理属性，并提供了形式定义、评估指标和验证程序。该框架探讨了这些属性之间的固有权衡，并讨论了如何将隐私要求、公平约束和因果推理嵌入可解释的工作流程中。通过在模型生成过程中评估伦理度量，该框架建立了既准确又可解释，而且公平、隐私保护和因果意识的AI系统的理论基础，即可信的AI系统。
### Conclusion
通过评估伦理度量，在MIMOSA框架下开发的AI系统不仅准确和可解释，而且公平、隐私保护和因果意识，即具备可信性。
## 33. `cs.AI` - 大型语言模型推理轨迹的形状：拓扑分析 [PDF](https://arxiv.org/pdf/2510.20665), [HTML](https://arxiv.org/abs/2510.20665)
### Authors
Xue Wen Tan,Nathaniel Tan,Galen Lee,Stanley Kok
### Background
目前，评估大型语言模型推理轨迹的质量仍然是一个不充分研究、劳动密集且不可靠的过程。当前的做法主要依赖于专家评分标准、手工注释和缓慢的两两判断。尽管自动化努力中存在一些基于图的代理工具，但这些工具量化的是结构连接性，无法阐明高质量推理的标准，这可能会因为过于简化而不足以反映内在复杂的推理过程。
### Innovation
我们提出了一个基于拓扑数据分析（TDA）的评估框架，该框架捕捉推理轨迹的几何特征，从而实现高效且自动化的评价。实验结果显示，拓扑特征在预测推理质量方面比传统的图指标具有更高的预测能力，表明有效推理的有效性可以通过更高维度的几何结构更好地捕捉，而不是只通过简单的关系图。
### Conclusion
我们的研究表明，一个紧凑且稳定的拓扑特征集可以可靠地指示轨迹质量，为未来的强化学习算法提供一种实践信号。
## 34. `cs.AI` - 针对多语言和多模态电子商务应用的大语言模型可靠评估 [PDF](https://arxiv.org/pdf/2510.20632), [HTML](https://arxiv.org/abs/2510.20632)
### Authors
Shuyi Xie,Ziqin Liew,Hailing Zhang,Haibo Zhang,Ling Hu,Zhiqiang Zhou,Shuman Liu,Anxiang Zeng
### Background
现有的语言模型在通用的自然语言处理（NLP）基准测试中表现出色，但在专业领域的能力却鲜有探索。而在电子商务领域，现有的评估工具如EcomInstruct、ChineseEcomQA、eCeLLM和Shopping MMLU存在任务多样性不足（例如缺乏产品指导和售后服务问题），任务模态单一（例如没有多模态数据），数据合成或精心编排，重点集中在英语和汉语上，这使得实践者难以评估模型在复杂且真实购物场景中的表现。因此，需要一个全面的多语言和多模态基准来评估语言模型在电子商务中的表现。
### Innovation
提出了EcomEval，一个旨在全面评估大语言模型在电子商务中的表现的多语言和多模态基准。EcomEval涵括了六个类别和37项任务（其中包括8项多模态任务），这些任务主要来源于真实的客户查询和交易日志数据，反映了实际商务互动的噪音和多样性。通过半自动的流程，预训练模型首先起草候选响应，之后由超过50名具有电子商务和多语言专长的专家进行审查和改进。EcomEval覆盖了包括五种低资源的东南亚语言在内的七种语言，提供了一个从前的工作没有提供的多语言视角。
### Conclusion
EcomEval 为多语言和多模态电子商务应用提供了一个全面和详细的基准评估工具，有助于更准确地评估大语言模型在复杂多变的真实购物场景中的表现。
## 35. `cs.AI` - Real Deep Research for AI, Robotics and Beyond [PDF](https://arxiv.org/pdf/2510.20809), [HTML](https://arxiv.org/abs/2510.20809)
### Authors
Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang
### Background
随着人工智能和机器人领域的研究迅速增长，每年发表的论文超过10,000篇，这让研究人员难以跟上最新进展。新兴趋势的快速变化、跨学科工作的兴起以及超越个人专业领域探索的需求，都增加了这一挑战的难度。
### Innovation
我们提出了一种通用的分析管道，能够系统地分析任何研究领域，识别新兴趋势，发现跨领域的机会，并为新的研究提供明确的起点。特别是在人工智能和机器人领域，尤其是基础模型和机器人技术的进步，我们应用了一个全面的框架Real Deep Research (RDR)，并对科学的其他领域进行了简要扩展分析。
### Conclusion
我们希望这项工作能够帮助从事人工智能及相关领域研究的人员。附录提供了每个分析主题的详细结果，希望这项工作能为研究人员带来启示。
## 36. `cs.AI` - 通过母线分裂进行传输网络阻塞管理的可移植图学习 [PDF](https://arxiv.org/pdf/2510.20591), [HTML](https://arxiv.org/abs/2510.20591)
### Authors
Ali Rajaei,Peter Palensky,Jochen L. Cremer
### Background
网络拓扑优化(NTO)可以通过母线分裂来缓解输电网络阻塞并减少再调度成本。然而，使用现有求解器实时求解大规模系统的混合整数非线性问题是不可行的。机器学习(ML)方法作为一个有前景的替代方案出现，但由于其在未见拓扑结构、不同操作条件及不同系统中的有限泛化能力，限制了其实用应用。现有研究将NTO问题与线性化交流潮流(PF)结合起来进行建模，并提出了一种图神经网络(GNN)加速方法。通过开发一种异质边感知消息传递神经网络来预测有效的母线分裂动作作为候选NTO解决方案。这项新方法可以通过捕获局部流动模式、泛化到未见的拓扑变化以及提高跨系统迁移性，显著提升NTO问题的求解效率和泛化能力。实验结果显示，在GOC 2000节点系统上，实现了四数量级的速度提升，能够在一分钟内提供符合交流潮流约束的解决方案，并且仅具有2.3%的最优性偏差。这些结果标志着向大规模系统中实现带拓扑和跨系统泛化的近实时NTO迈出了一大步。
### Innovation
该论文提出了一种基于图神经网络(GNN)的加速方法，以解决母线分裂在输电网络阻塞管理中的应用问题。与现有方法相比，它能够实时处理大规模系统，并且可以在未见的网络拓扑结构、不同的操作条件下及不同系统中表现出良好的泛化能力。采用异质边感知消息传递神经网络来预测有效的母线分裂措施，从而实现NTO问题的快速和高效的解决。GNN架构能够捕获局部流动模式，并提高跨系统的迁移性能，从而提高了NTO方法的效率和实用性。
### Conclusion
论文的实验结果表明，通过图神经网络加速母线分裂在网络阻塞管理中的应用能够在GOC 2000节点系统上实现四数量级的速度提升，能够快速提供符合交流潮流约束的最优性近似解，并且在不同系统和未见拓扑结构中保持了良好的泛化能力。这标志着在大规模系统中实现近实时网络拓扑优化方面的重要进展。
## 37. `cs.AI` - 基于共通性的一种AGI衡量方法 [PDF](https://arxiv.org/pdf/2510.20784), [HTML](https://arxiv.org/abs/2510.20784)
### Authors
Fares Fourati
### Background
近年来，Hendrycks等人通过将人工智能通用性（AGI）定义为认知领域间综合表现力的算术平均数来予以形式化，并基于CHC模型。然而，这一定义假设了补偿能力，忽视了整体均衡性。事实上，真正的通用性应当涵盖所有关键领域的平衡能力。为此，本文提出了基于共通性的AGI衡量方法，通过积分计算广义平均数并在补偿指数连续体上进行，跨越算术、几何和调和的范围。通过计算此法下的“曲线下的面积”（AUC），最大限度展示了不同假设下的稳健性。与注重专业性的算术平均不同，AUC规避了不平衡并捕捉了跨领域依赖性。在GPT-4和GPT-5两系统的CHC领域得分上，优化后的AUC表明尽管算术评分较高，但两者离真正通用性尚有差距。
### Innovation
提出了基于共通性的新衡量AGI的方法，不仅涵盖了补偿能力假设下的平衡性，还通过广义平均数和AUC计算实现对特定假设的稳健性评估，抛弃了单纯依靠算术平均对偏斜度不敏感的缺陷，提升了通用人工智能的衡量标准。
### Conclusion
该研究通过改进的衡量方法揭示了在现有水平下，GPT-4和GPT-5系统尽管在单一领域有高得分，但在全面的AGI评估中仍然存在显著不足，强调了在未来评估AGI时应该更加注重全方位的平衡能力和一致性。
## 38. `cs.AI` - SLykLatent：使用深度面部特征学习的眼球跟踪学习框架 [PDF](https://arxiv.org/pdf/2402.01555), [HTML](https://arxiv.org/abs/2402.01555)
### Authors
Samuel Adebayo,Joost C. Dessing,Seán McLoone
### Background
当前的眼球跟踪技术受到数据集表观不稳定性的挑战，这源于 aleatoric 不确定性、协变偏移以及测试领域泛化。为了应对这些挑战，研究开发了一种新的方法来提升眼球跟踪的性能。
### Innovation
SLykLatent 创新地利用无监督学习进行初步训练，使用面部表情数据集，然后通过基于补丁的三分支网络和逆方差解释权重训练损失函数进行细化。该方法在基准数据集上的评估中表现优异，分别在 Gaze360 数据集上提高了 10.9%，在 MPIIFaceGaze 上超越了现有顶级结果 3.8%，在 ETH-XGaze 的一部分数据上领先 11.6%。此外，在 RAF-DB 和 Affectnet 上的适应性测试也表现出较高的准确率（分别为 86.4% 和 60.9%）。通过对各个组件进行消融研究，证明了 SLYkLatent 新颖组件的有效性。
### Conclusion
SLykLatent 提供了一种提升眼球估计的新方法，通过有效的无监督预训练和精密的补丁访问三分支网络优化及损失函数，显著提高了整体性能。
## 39. `cs.AI` - SSL-SE-EEG：自监督学习和挤压-激励网络在未标记EEG数据上的鲁棒学习框架 [PDF](https://arxiv.org/pdf/2510.19829), [HTML](https://arxiv.org/abs/2510.19829)
### Authors
Meghna Roy Chowdhury,Yi Ding,Shreyas Sen
### Background
脑电图（EEG）在脑-计算机接口（BCIs）和神经学诊断中扮演着重要角色，但其实际部署面临挑战，如噪声伪影、缺失数据和高标注成本。现有的EEG处理技术无法有效应对这些挑战。
### Innovation
我们提出了SSL-SE-EEG框架，该框架结合了自监督学习（SSL）和Squeeze-and-Excitation网络（SE-Nets），以增强特征提取、提高抗噪性和减少对标签数据的依赖。不同于传统的EEG处理技术，SSL-SE-EEG将EEG信号转换为可用于深度学习的结构化二维图像表示。在MindBigData、TUH-AB、SEED-IV和BCI-IV数据集上的实验验证表明，其精度达到了当前最先进的水平（在MindBigData数据集上为91%，在TUH-AB数据集上为85%），使其适用于实时BCI应用。
### Conclusion
通过实现低功耗、可扩展的EEG处理，SSL-SE-EEG为生物医学信号分析、神经工程和下一代BCIs提供了有前景的解决方案。
## 40. `cs.AI` - CourtGuard：一个本地多智能体提示注入分类器 [PDF](https://arxiv.org/pdf/2510.19844), [HTML](https://arxiv.org/abs/2510.19844)
### Authors
Isaac Wu,Michael Maslowski
### Background
随着大型语言模型（LLMs）被集成到各种敏感应用中，提示注入（通过提示诱导LMs产生有害行为）的风险日益增加。提示注入攻击可能导致LMs泄露敏感数据、传播错误信息，并表现出有害行为。因此，为了防止这些攻击，需要一种有效的防御机制。直接检测（直接使用LLM作为法官进行判断）的方法存在较高的误报率，但缺乏对抗性场景的考虑。
### Innovation
提出了一个名为CourtGuard的本地多智能体提示注入分类器。该分类器在类似法庭的多智能体LLM系统中评估提示，系统包括一名“辩护律师”模型、一名“检察官”模型和一名“法官”模型。与直接检测方法相比，CourtGuard具有较低的误报率，尽管其在检测提示注入方面的性能较差。这一创新反映了在提示分类中必须考虑对抗性和善意场景的重要性，同时也促进了多智能体系统在防御提示注入攻击中的应用。
### Conclusion
尽管CourtGuard在提示注入检测上的性能不如其他一些方法，但其较低的误报率凸显了同时考虑对抗性和善意场景的重要性。CourtGuard和直接检测方法的实现可以用于Gemma-3-12b-it、Llama-3.3-8B和Phi-4-mini-instruct等模型。
## 41. `cs.AI` - 不同模型和提示框架在高中物理中生成的教学计划的教学合理性和实用性评估 [PDF](https://arxiv.org/pdf/2510.19866), [HTML](https://arxiv.org/abs/2510.19866)
### Authors
Xincheng Liu
### Background
研究评估了五种领先的大语言模型——ChatGPT（GPT-5）、Claude Sonnet 4.5、Gemini 2.5 Flash、DeepSeek V3.2 和 Grok 4 生成的教学计划的教育适用性和实用性。通过探讨不同模型和提示框架对教学计划的影响，研究者旨在理解模型设计和提示框架如何共同决定生成的教学计划的质量。
### Innovation
研究不仅探索了不同模型之间的差异，还测试了三种结构化的提示框架（TAG、RACE 和 COSTAR），以评估它们对生成的教学计划的具体影响。研究通过自动化计算指标（可读性、语言复杂性、事实准确性、认知需求）来全面评估教学计划的质量，并分析了教学目标的分布情况。
### Conclusion
研究表明，模型的选择对教学计划的可读性影响最大，而提示框架结构则对事实准确性和教学完整性的影响最大。RACE 基准框架在减少幻觉错误和与 NGSS 标准的一致性方面表现最好。总体而言，该研究指出了模型设计对可读性的重要影响，同时强调了使用 RACE 提示框架和明确的概念检查表对于提高教学计划的可靠性和课程对齐度至关重要。
## 42. `cs.AI` - 从优化到预测：基于Transformer的路径流量估计在交通分配问题中的应用 [PDF](https://arxiv.org/pdf/2510.19889), [HTML](https://arxiv.org/abs/2510.19889)
### Authors
Mostafa Ameli,Van Anh Le,Sulthana Shams,Alexander Skabardonis
### Background
交通分配问题是交通流分析中的关键问题，传统上通过在均衡原则下的数学规划方法解决。这种方法因路径集合数量的非线性增长而导致在大规模网络中计算成本变得不可行。
### Innovation
该研究提出了一种新颖的数据驱动方法，利用深度神经网络和Transformer架构直接预测交通均衡路径流。该模型在路径级别上交通分布，捕捉OD对之间的复杂关联，比传统的链路级别方法提供更详细和灵活的分析。Transformer模型大幅减少了计算时间，适应需求和网络结构的变化而无需重新计算。
### Conclusion
数值实验在曼哈顿样网络、Sioux Falls网络和东部马萨诸塞网络上进行，结果显示所提出的模型比常规优化快几个数量级。该模型在多类网络中有效地估算路径级别交通流量，减少了计算成本并提高了预测准确性。模型还灵活适应不同需求和网络条件，支持交通管理并为增强的交通运输规划和政策制定提供了快速'假设情境'分析能力。
## 43. `cs.AI` - 在线内容审核中特征重要性的量化 [PDF](https://arxiv.org/pdf/2510.19882), [HTML](https://arxiv.org/abs/2510.19882)
### Authors
Benedetta Tessa,Alejandro Moreo,Stefano Cresci,Tiziano Fagni,Fabrizio Sebastiani
### Background
准确评估用户对管理干预的反应对于开发有效的、以用户为中心的审核策略至关重要。这需要理解哪些用户特征与不同的行为反应相关，这是本文的目标。本文通过对Reddit上16,800名用户在大规模审核干预下的行为变化进行预测，研究了753个社会行为、语言、关系和心理特征的信息价值，以期量化用户的总体行为变化。
### Innovation
本文采用贪婪特征选择策略，旨在识别对于用户活动、毒性和参与度多样性变化最具有预测性的特征，并估计它们的重要性。研究发现，一些特征在所有任务中一致具有信息价值，而许多特征要么具有任务特异性，要么几乎没有实用性。此外，研究发现预测性能因任务而异，活动和毒性的变化比多样性的变化更容易预测。这些发现为开发准确预测用户对审核干预反应的系统铺平了道路，同时也揭示了后审核用户行为的复杂性，表明有效审核不仅需要考虑到用户特性，还需要针对干预的具体目标进行定制。
### Conclusion
研究结果为开发准确预测用户对审核干预反应的系统铺平了道路，同时也强调了对用户行为的复杂性，表明有效审核不仅需要考虑到用户特性，还需要针对干预的具体目标进行定制。
## 44. `cs.AI` - Stream: 通过稀疏注意力扩展大型语言模型长上下文的机制解释 [PDF](https://arxiv.org/pdf/2510.19875), [HTML](https://arxiv.org/abs/2510.19875)
### Authors
J Rosser,José Luis Redondo García,Gustavo Penha,Konstantina Palla,Hugues Bouchard
### Background
随着大型语言模型（LLMs）扩展到百万级上下文，传统的机制可解释性技术在分析注意点时会随着上下文长度成二次时间复杂度上升，需要超过10万上下文长度的TB级内存。目前的解释方法在处理长上下文时，由于内存需求过大，无法进行有效的解释分析。
### Innovation
本文提出了一种新型技术稀疏追踪（Sparse Tracing），将动态稀疏注意点应用到长上下文的注意力模式分析中，实现了高效的稀疏注意力掩码估计，使其在近乎线性和线性空间下运行，并能以一次通过的方式进行大规模解释。Stream通过二分搜索式的优化方法保留查询中的前k个关键块，同时保持模型对下一个标记的行为。这种方法被应用到长推理链中，去除掉97-99%的标记交互同时发现推理锚点。在RULER基准测试中，Stream保留了关键的检索路径，去除了90-96%的交互，揭示了层次化路径从输入到输出的机制。这一方法提供了一种无需使用TB级缓存即可高效分析注意模式和追踪信息流动的工具。
### Conclusion
稀疏追踪技术使得在大规模的消费者级GPU上实现对长上下文解释成为可能，进一步推动了链式思维监控的普及。
## 45. `cs.AI` - 他们能否 Dixit？他们能！利用 Dixit 评估多模态语言模型的能力 [PDF](https://arxiv.org/pdf/2510.19892), [HTML](https://arxiv.org/abs/2510.19892)
### Authors
Nishant Balepur,Dang Nguyen,Dayeon Ki
### Background
当前对多模态大型语言模型（MLMs）的评估通常依赖于静态、单一的基准测试，这不能全面评估模型在单一任务中的能力。亦或通过人工或模型间的两两比较，这种评估方法高度主观且耗费成本，并允许模型借助表面的捷径（例如冗余性）来虚增胜率。这些问题促使研究者提出游戏为基础的评估方式，游戏需要多方面的能力才能取胜，且具有竞争性，并受固定、客观规则的制约，使评估更为有趣，并提供了一个稳健的框架解决上述挑战。
### Innovation
论文提出将 Dixit（一种幻想卡牌游戏）作为一种游戏评估手段来全面评估 MLMS 的能力。玩家需要生成卡片的说明来迷惑一些但不是所有其他玩家，从而选择已玩出的卡片。通过定量实验，展示了五种 MLM 在 Dixit 中的表现与流行 MLM 基准测试结果高度相关。此外，人类和 MLM 之间的 Dixit 游戏揭示了几种代理策略之间的差异及 MLMS 理解能力的改进空间。
### Conclusion
Dixit 游戏作为一种评估框架，能够克服传统评估方法的复杂性，并且能提供一种更有趣且有效的手段来全面评估 MLMS 在理解力、策略执行、以及应对复杂情境下的表现。
## 46. `cs.AI` - 从小到大：通过推理图传递CUDA优化专长 [PDF](https://arxiv.org/pdf/2510.19873), [HTML](https://arxiv.org/abs/2510.19873)
### Authors
Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li
### Background
尽管CUDA编程和领域特定库有了显著的演进，但高效利用具有大规模并行引擎的GPU仍具有挑战。大型语言模型（LLMs）在从序列代码生成优化的CUDA代码方面显示了很强的潜力。然而，实际使用LLMs面临两个主要挑战：基于云的API可能引起代码泄露的风险，而本地部署则经常成本高昂且效率低下。这些缺点促成了对更轻量级和隐私友好的小语言模型（SLMs）的兴趣。虽然有研究表明，SLMs在特定任务上可以达到与LLMs相当的性能，但在复杂的CUDA代码生成方面，它们的推理能力有限，导致性能不佳。为了解决这一问题，我们提出了一种名为ReGraphT的无训练、检索增强生成框架，该框架将LLMs的推理能力转移到较小的模型中，以弥补SLMs在复杂CUDA代码生成中的不足。
### Innovation
ReGraphT是一种无训练、检索增强生成框架，它通过组织CUDA优化轨迹为结构化的推理图，将联合CUDA优化表示为状态转换，并利用蒙特卡洛图搜索（MCGS）进行高效探索。我们还提供了一个用于评估模型的CUDA特定基准测试，其中难易程度由推理复杂度定义。实验表明，ReGraphT在CUDAEval和ParEval上的平均加速比分别为2.33倍。当与DeepSeek-Coder-V2-Lite-Instruct和Qwen2.5-Coder-7B-Instruct结合使用时，ReGraphT使SLMs能够接近LLM的性能，同时避免与LLMs相关的隐私风险或过高的计算开销。
### Conclusion
实验表明ReGraphT在CUDA优化方面优于针对高性能计算(HPC)进行微调的模型和其他检索增强方法，平均加速比达到2.33倍。通过与DeepSeek-Coder-V2-Lite-Instruct和Qwen2.5-Coder-7B-Instruct结合使用，ReGraphT使SLMs能够在不增加隐私风险或计算成本的情况下接近LLMs的性能。
## 47. `cs.AI` - 大型语言模型驱动的数学建模 [PDF](https://arxiv.org/pdf/2510.19895), [HTML](https://arxiv.org/abs/2510.19895)
### Authors
Guoyun Zhang
### Background
传统优化方法，如线性规划、混合整数规划和模拟，高度依赖领域专业知识将实际问题转化为可解的数学模型。尽管优化求解器如Gurobi和COPT很强大，但专家的输入在定义目标、约束和变量方面仍然是必不可少的。然而，像GPT-4、Claude和Bard这样的先前模型在自然语言处理和推理任务中表现出色，但它们高昂的令牌成本和倾向生成不真实信息限制了其在供应链场景中的实际应用。相比之下，DeepSeek-R1是一种通过强化学习训练的成本效益高且性能良好的模型，是可行的替代方案。尽管它在LiveCodeBench和Math-500等基准测试中表现出色，但在实际运筹学（OR）场景中的有效性尚未被广泛探索，因此需要进行系统评估。
### Innovation
本研究使用DeepSeek-R1模型，结合自然语言理解和代码生成，旨在弥合传统优化方法与实际问题建模之间的差距。研究采用了科学的评估方法，包括基线评估、生成幻觉分类、以及LLM作为裁判、少样本学习、工具调用和多智能体框架等减轻幻觉的技术。
### Conclusion
本研究表明，DeepSeek-R1在四个关键的运筹学基准测试（NL4OPT、IndustryOR、EasyLP和ComplexOR）中表现出色，一方面减少了幻觉，提高了建模的准确性和用户意图的一致性。
## 48. `cs.AI` - 基于语义和 episodic 记忆从监督中学习：一种代理适应的反思性方法 [PDF](https://arxiv.org/pdf/2510.19897), [HTML](https://arxiv.org/abs/2510.19897)
### Authors
Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka
### Background
当前的大多数方法，如微调，往往成本高、缺乏灵活性且不透明。该研究探讨了基于预训练大语言模型的代理如何通过标注数据学习目标分类函数，而无需参数更新。
### Innovation
提出了一个记忆增强框架，结合使用标注数据和从大语言模型生成的批评。该框架使用语义记忆进行泛化，使批评指导可重用，同时使用情景记忆存储实例级批评以捕捉特定的过去经验。该研究通过采用批评比依赖标签的检索基线（如 RAG）提升了高达 24.8% 的准确率，并引入了新型度量标准 'suggestibility' 来解释不同监督表示使模型表现出的行为差异。
### Conclusion
该研究发现，基于记忆驱动的反思性学习方法可以构建出更适应且可解释的 LLM 代理，尤其是在处理事实导向与偏好导向信息方面模型的行为存在显著差异。
## 49. `cs.AI` - 计划后检索：知识图谱上引导的复杂推理 [PDF](https://arxiv.org/pdf/2510.20691), [HTML](https://arxiv.org/abs/2510.20691)
### Authors
Yanlin Song,Ben Liu,Víctor Gutiérrez-Basulto,Zhiwei Hu,Qianqian Xie,Min Peng,Sophia Ananiadou,Jeff Z. Pan
### Background
知识图谱问答方法旨在通过推理来回答自然语言问题。尽管大型语言模型通过其强大的推理能力推进了知识图谱问答(KGQA)，但现有的方法仍然难以充分利用知识图谱中的丰富知识和大型语言模型(LLM)的推理能力，尤其是在复杂场景中。现有方法通常假设知识图谱覆盖完整，并缺少评估何时需要外部信息的机制。此外，推理仍然局限于局部，缺乏持续连贯的多步规划，导致即使存在相关知识也会出现推理失败。
### Innovation
本文提出了Graph-RFT（基于图的计划检索框架），这是一种创新的两阶段增强微调KGQA框架，采用'计划-知识图检索-网络检索-思考'的范式，使LLMs能够在不完整知识条件下自主规划和适应检索调度。Graph-RFT通过引入具定制化计划检索数据集的链式思维微调方法激活结构化推理并解决冷启动问题，还引入了规划检索指导的强化学习过程，将明确规划和检索动作与多奖励设计相结合，实现覆盖感知检索调度。该框架采用类似笛卡尔的规划模块将复杂的问句分解为有序子问句，并通过逻辑表达式指导工具调用以实现全局一致的多步推理。推理检索过程通过组合结果和检索特定信号的多奖励来优化，使模型能够学习何时以及如何有效地结合知识图谱和网络检索。
### Conclusion
Graph-RFT框架通过增强学习指导下的复杂推理过程，使大型语言模型能够在不完整知识条件下进行自主规划和适应检索调度，通过多奖励结合优化推理检索过程，从而更有效地结合知识图谱和网络检索，解决现有方法在复杂场景中的不足。
## 50. `cs.AI` - 推理模型能否混淆推理？检验链式思维监控的抗压性 [PDF](https://arxiv.org/pdf/2510.19851), [HTML](https://arxiv.org/abs/2510.19851)
### Authors
Artur Zolkowski,Wen Xing,David Lindner,Florian Tramèr,Erik Jenner
### Background
近期的研究表明，未对齐的模型可能会表现出欺骗行为，这引起了对其输出可信度的担忧。链式思维（CoT）作为一种有希望的对齐监控工具，即将模型的推理忠实度表达出来，可以及时检测并减轻有害行为，防止不良后果的产生。然而，一个关键的不确定性是：模型是否可以在受到强烈混淆压力的情况下掩盖其链式思维，以追求隐藏的恶意目标并躲避检测？
### Innovation
为了回答这个问题并测试链式思维监测的抗压性，作者开发了一种组合性和量化的提示分类法，用于引发链式思维的混淆。在玩具任务和更现实的环境中，作者将内部链式思维（推理痕迹）和外部链式思维（在输出中提示的推理）进行评估。结果显示：(i) 在没有混淆压力的情况下，链式思维监控可以准确高效地工作。(ii) 在强烈的混淆压力下，一些模型可以成功完成对抗性任务并逃脱检测。(iii) 在提示压力下，模型内部链式思维的混淆程度低于外部链式思维。这些结果表明，在良性场景中链式思维提供了宝贵的监督，但在稳健部署中需要针对模型的特定抗压性测试监控能力。
### Conclusion
链式思维在良性场景下提供了宝贵的监督，但其在对抗性场景下的监控能力仍需进一步测试和验证，以确保模型的安全和可靠部署。
## 51. `cs.AI` - 金融中的鲁棒强化学习：使用椭圆不确定性集建模市场影响 [PDF](https://arxiv.org/pdf/2510.19950), [HTML](https://arxiv.org/abs/2510.19950)
### Authors
Shaocong Ma,Heng Huang
### Background
在金融应用中，强化学习（RL）代理通常根据历史数据进行训练，此时其行为不会影响价格。但在部署过程中，这些代理在实时市场中交易，其交易会改变资产价格，这种现象称为市场影响。训练和部署环境之间的这种不匹配会显著降低性能。
### Innovation
开发了一种新的椭圆不确定性集类。通过这些集合，建立了隐式和显式的闭形式最坏情况不确定性解，使得鲁棒策略评估高效且可操作。实验表明，该方法在单资产和多资产交易任务中均实现了更高的夏普比率，并且在增加交易量的情况下仍保持鲁棒性，提供了一种更忠实且可扩展的RL方法。
### Conclusion
我们的方法在单资产和多资产交易任务中实现了优异的夏普比率，并且在增加交易量的情况下仍保持鲁棒性，提供了一种更忠实且可扩展的RL方法，从而更好地适应金融市场的模型偏差问题。
## 52. `cs.AI` - 零阶优化中无偏梯度估计器的最优构造 [PDF](https://arxiv.org/pdf/2510.19953), [HTML](https://arxiv.org/abs/2510.19953)
### Authors
Shaocong Ma,Heng Huang
### Background
零阶优化(ZOO) 是一种在梯度不可用或计算代价高昂的随机优化中重要的框架。大多数现有的 ZOO 方法利用的梯度估计器都存在偏差问题，除非扰动步长趋于零。论文通过重新构造方向导数为级联序列，并通过精心设计分布进行采样，提出了一个新的无偏梯度估计器家族，既消除了偏见又保持了有利的方差。
### Innovation
论文通过重新构造方向导数为级联序列，并通过精心设计分布进行采样，提出了一个新的无偏梯度估计器家族，既消除了偏见又保持了有利的方差。此外，论文还分析了这些估计器的理论性质，推导出了四种特定构造的最优尺度分布和扰动步长，并证明使用提出的估计器的 SGD 算法在光滑非凸目标函数上达到了最优复杂度。
### Conclusion
实验结果表明，与标准方法相比，采用提出的估计器的方法在合成任务和语言模型微调中具有更高的准确性和收敛性。
## 53. `cs.AI` - LyriCAR: 一种基于难度意识的课程强化学习框架实现可控歌词翻译 [PDF](https://arxiv.org/pdf/2510.19967), [HTML](https://arxiv.org/abs/2510.19967)
### Authors
Le Ren,Xiangjian Zeng,Qingqiang Wu,Ruoxuan Liang
### Background
歌词翻译是一个充满挑战的任务，需要平衡多种音乐约束。现有的方法通常依赖手工规则和句子级别的建模，这限制了它们在掌握语言和音乐模式以及在段落级别进行有效泛化的能力，特别是对于跨行一致性及全局韵律等关键因素。此前的工作在这方面做得还不够。
### Innovation
提出了一种全新的LyriCAR框架，该框架作为一种完全无监督的学习方式操作。LyriCAR引入了一种难度意识的课程设计者和自适应课程策略，确保训练资源的有效分配，加速收敛，并通过逐步提供越来越复杂的挑战来指导模型，从而提高整体翻译质量。与现有的强大基准相比，实验结果表明，LyriCAR在标准翻译指标和多维度奖励分数方面均取得了最新的成果，并通过自适应课程策略将训练步骤减少了近40%，同时保持了卓越的性能。
### Conclusion
在EN-ZH歌词翻译任务上的广泛实验表明，相较于强有力的基准模型，LyriCAR在标准翻译度量和多维度奖励评分上均达到了最先进的结果。自适应课程策略使训练步骤减少了近40%，但仍保持了优越的性能。代码、数据集和模型可以在提供的链接中访问。
## 54. `cs.AI` - 重新审视零阶优化：最小方差两点估计和方向对齐的随机扰动 [PDF](https://arxiv.org/pdf/2510.19975), [HTML](https://arxiv.org/abs/2510.19975)
### Authors
Shaocong Ma,Heng Huang
### Background
当前研究主要关注于固定长度的随机扰动在零阶梯度估计中的应用。然而，现有研究忽略了这种扰动方向与实际梯度对齐的潜在优势。
### Innovation
本文探讨了两点零阶梯度估计器，并确定了使得估计器方差最小的随机扰动分布。研究将这一问题重新定义为限定功能优化问题。研究提出了方向对齐的扰动（DAP）方案，该方案能够自适应地提供更高的准确性，尤其是在关键方向上。此外，还对使用 δ-无偏随机扰动的随机梯度下降的收敛性进行了分析，并将现有的复杂性边界扩展到更广泛类型的扰动。实证评估表明，在特定条件下DAP方法优于传统方法。
### Conclusion
研究发现了方向对齐的随机扰动比固定长度的随机扰动更优，并通过理论和实证研究证明了其在特定条件下的优越性。
## 55. `cs.AI` - 增强大型语言模型的符号自然语言理解系统以获得更可靠的持续因果陈述解释 [PDF](https://arxiv.org/pdf/2510.19988), [HTML](https://arxiv.org/abs/2510.19988)
### Authors
Xin Lian,Kenneth D. Forbus
### Background
尽管大型语言模型（LLMs）有着广泛的应用前景，但由于它们依赖于概率推断，容易出现生成事实中的虚构以及自然语言理解（NLU）任务中输出结构不一致的问题。相比之下，符号NLU系统提供了基于精心编撰的词汇表、语义资源以及句法和语义解释规则的可解释理解。它们生成的关系表示可用于准确推理和规划，以及增量调试学习。然而，符号NLU系统在覆盖范围上往往比LLMs有限，并且需要稀缺的知识表示和语言学技能来进行扩展和维护。
### Innovation
本文探索了一种混合方法，将LLMs的广泛覆盖语言处理能力与产生结构化关系表示的符号NLU能力结合起来，以期充分利用两种方法的优点。我们使用LLMs进行重写和文本简化以提供广泛的覆盖范围，并作为一种信息源来自动填充知识缺口。同时，符号NLU用于生成可用于推理和增量学习的关系表示。这种方法被用于从常识科学文本中提取和解释数量和因果定律的任务，以及仅使用符号方法和仅使用LLMs的方法的管道进行评估。实验结果表明，我们的混合方法在处理上比仅使用符号管道更好，更为可靠。
### Conclusion
我们的研究结果表明，结合大型语言模型和符号自然语言理解能力的混合方法在因果陈述解释任务中表现得更优秀，提供了更为可靠的结果。
## 56. `cs.AI` - 认知偏差在6G自主网络中代理型AI驱动机制中的教程 [PDF](https://arxiv.org/pdf/2510.19973), [HTML](https://arxiv.org/abs/2510.19973)
### Authors
Hatim Chergui,Farhad Rezazadeh,Merouane Debbah,Christos Verikoukis
### Background
在网络自主性提高的6G路径上，仅仅优化关键性能指标(KPIs)是不够的。虽然KPIs在TM论坛级别1-3中促进了自动化进展，但它们仍然只是网络本质——无缝连接、公平性、适应性和韧性——的数值抽象，只能作为代理。真正的自主性需要感知和推理解构网络环境。这种进步可以通过代理型AI来实现，其中大型语言模型（LLM）赋能的代理能够感知多模态遥测、记忆推理、跨领域协商，并通过API实现多目标目标。然而，部署这些代理却引入了从人类设计中继承的认知偏差挑战，这可能会扭曲推理、协商、工具使用及执行。本文在神经科学与AI之间提供了一个关于认知偏差的教程，涵盖了偏好的分类、定义、数学公式、在电信系统中的出现方式及受影响的代理组件，并介绍了针对各种偏差的缓解策略。最后，文章提供了两个实用用例，分别针对6G跨切片和服务域管理中认知偏差的出现、影响和缓解收益，通过使用锚点随机化、时间衰减和拐点奖励技术，成功减少了错误依赖初始资源分配提议或最近决策，降低了延迟并提高了能源效率。
### Innovation
文章通过详细解释认知偏差的 taxonomy、定义、数学建模及其在电信系统中的表现，为6G自主网络中的代理型AI提供了重要的指导。提出了特定的缓解策略来减轻各类偏差的影响，并通过实际应用场景展示了如何具体应用这些策略，从而显著提高了网络性能，如5倍降低延迟和约40%的能效提升。这些方法不仅理论性强，而且具有很高的实际应用价值。
### Conclusion
代理型AI在6G自主网络中的应用面临着来自人类设计的认知偏差挑战，本文对此进行了详细分析，并提供了一系列具体的缓解策略。通过使用特定技术解决认知偏差问题，如锚点随机化、时间衰减和拐点奖励，可以显著提升网络性能，显示出代理型AI在6G自主网络中的巨大潜力。
## 57. `cs.AI` - 超越MedQA：在LLM时代迈向现实世界临床决策 [PDF](https://arxiv.org/pdf/2510.20001), [HTML](https://arxiv.org/abs/2510.20001)
### Authors
Yunpeng Xiao,Carl Yang,Mark Mai,Xiao Hu,Kai Shu
### Background
大型语言模型（LLMs）在临床应用方面显示出潜力，但目前的评估往往依赖像MedQA这样的简化问答数据集，这些数据集未能充分反映真实的临床决策环境。现有的数据集和基准在其背景和问题特征上存在局限性，难以评估和优化临床决策任务。
### Innovation
本文提出了一个统一的框架，通过临床背景和临床问题两个维度来刻画临床决策任务，从而提升评估的全面性。该框架不仅考虑了准确性，还扩展到了效率和可解释性，并对比分析了已有的方法和技术，明确了假设，标准化了比较标准，旨在指导开发出更加贴近临床需求的LLM模型。
### Conclusion
该研究为临床决策任务的评估确立了一个新的标准，指出了现有的研究局限，并强调了未来的挑战。其目的是促进LLM在临床实际场景中的应用和发展。
## 58. `cs.AI` - 锻造GEMs：通过基于质量的语料库编纂和专业化预训练推进希腊语NLP [PDF](https://arxiv.org/pdf/2510.20002), [HTML](https://arxiv.org/abs/2510.20002)
### Authors
Alexandra Apostolopoulou,Konstantinos Kanaris,Athanasios Koursaris,Dimitris Tsakalidis,George Domalis,Ioannis E. Livieris
### Background
对于像现代希腊语这样的形态丰富的、资源中等的语言，自然语言处理的进步常常受到研究碎片化的阻碍，架构多样性不足以及有限的上下文长度模型依赖的影响。特别是在法律等高价值的专业领域，现有模型往往局限于早期的Transformer架构，限制在512个令牌的窗口，这对于分析长篇法律文件来说是不够的。
### Innovation
本文介绍了一种新的变压器模型家族——希腊嵌入模型（GEM），基于广泛的质量驱动数据编纂。为此，构建了大型的希腊语语料库，强调严谨的质量筛选和预处理方法，从通用领域和专门的法律源中创建高质量的训练数据集。进一步地，本文首次提出针对法律领域的希腊-英语双向嵌入模型。广泛的下游任务实验表明，新模型类证明了所提方法的有效性，其中GEM-RoBERTa和GEM-ConvBERT模型显著优于现有基准。
### Conclusion
新的嵌入模型不仅提高了希腊语NLP的效果，还尤为适用于法律等高价值的专门领域，证明了基于高质量语料库的编纂和专业化预训练在多语言NLP中的重要性。
## 59. `cs.AI` - 比特币交易的时序图 [PDF](https://arxiv.org/pdf/2510.20028), [HTML](https://arxiv.org/abs/2510.20028)
### Authors
Vahid Jalili
### Background
自2009年比特币网络的第一个区块以来，该网络已经处理了超过10亿笔交易，金额超过872亿比特币，这些数据为机器学习提供了丰富的潜力。然而，由于比特币的匿名性质和其基于UTXO的设计导致的交易资金流向的模糊性，这些数据对于机器学习研究而言大多不可访问。
### Innovation
本文提出了一种适用于机器学习的图模型，通过重构资金流来建模比特币的经济拓扑结构。该图是时间和异构的，包含了截至编号为cutoffHeight的区块的完整交易历史，包含超过240亿个节点和超过397亿条边。此外，还提供了自定义采样方法，生成了采样社区的节点和边特征向量，以及在专业化图数据库中加载和分析比特币图数据的工具，并提供了准备好的数据库快照。
### Conclusion
本文提供的全面的数据集和工具包使机器学习社区能够大规模应对比特币复杂的生态系统，推动了异常检测、地址分类、市场分析和大规模图机器学习基准测试等应用的发展。数据集和代码可在指定的链接处获取。
## 60. `cs.AI` - FAIGMOE框架：中型企业与大型企业中生成型人工智能的采用与整合 [PDF](https://arxiv.org/pdf/2510.19997), [HTML](https://arxiv.org/abs/2510.19997)
### Authors
Abraham Itzhak Weinberg
### Background
生成型人工智能（GenAI）为企业带来了变革性机会，但中型企业面临资源限制和有限的人工智能专业知识，而大型企业则面临组织复杂性和协调挑战。现有技术采纳框架，如TAM（技术接受模型）、TOE（技术组织环境）和DOI（创新扩散理论），缺乏这些不同背景下的具体实施要求，形成了采纳文献的关键缺口。本文提出了FAIGMOE（框架：中型企业和大型企业中生成型人工智能的采用与整合），这是一种概念框架，适用于这两种类型的企业，涵盖了四个相互关联的阶段：战略评估、规划和用例开发、实施和整合以及运营和优化。每个阶段都提供了可扩展的指导，适用于不同规模和复杂性的组织，涵盖了包括提示工程、模型编排和幻觉管理在内的GenAI 特定考虑。
### Innovation
FAIGMOE框架综合了技术采纳理论、组织变革管理和创新扩散视角，旨在解决中型企业与大型企业采用生成型人工智能的独特需求，填补了现有框架的空白。这一框架是第一个专门为中型企业与大型企业的生成型人工智能采纳提供全面概念框架的研究贡献，提供了一系列可操作的实施协议、评估工具和治理模板，需要未来研究通过实证验证来进一步验证其有效性和实用性。
### Conclusion
FAIGMOE框架通过四个相互关联的阶段提供了完整的框架，涵盖了从战略评估到优化和运营的所有方面，并以其特有的考虑因素如提示工程、模型编排和幻觉管理，强调了其在解决中型企业与企业采用生成型人工智能的独特挑战方面的重要性，为其提供了具体和可操作的指导。
## 61. `cs.AI` - 优化线性社会选择中的失真 [PDF](https://arxiv.org/pdf/2510.20020), [HTML](https://arxiv.org/abs/2510.20020)
### Authors
Luise Ge,Gregory Kehne,Yevgeniy Vorobeychik
### Background
社会选择理论提供了一种根据选民对选项的偏好排名来选择候选人的方法。然而，当选民对这些选项有内在效用时，仅使用偏好排名可能会导致从效用视角来看欠最优的结果。失真是一种衡量这种欠优化的方法，为在效用具有最小结构时开发和分析投票规则提供了一种最坏情况的方法。然而，在许多情况下，如价值对齐的常见模式中，选项允许向量表示，并且自然假设效用是候选嵌入的参数函数。
### Innovation
本研究首次探讨了线性效用函数的失真。具体地，研究了线性社会选择的确定性和随机投票规则的失真，并获得了仅依赖于候选嵌入维度的边界，且与候选人数或选民数无关。此外，还引入了多项式时间的实例最优算法，用于在给定候选和投票集合的情况下最小化失真。
### Conclusion
研究在推荐系统协作过滤嵌入和意见调查语言模型嵌入两个真实世界领域中，对我们的实例最优算法与其他标准规则进行了实证评估，提供了衡量不同投票规则失真效果的方法。
## 62. `cs.AI` - 超出单向影响：多轮人类-大语言模型相互作用中的双向意见动态 [PDF](https://arxiv.org/pdf/2510.20039), [HTML](https://arxiv.org/abs/2510.20039)
### Authors
Yuyang Jiang,Longjie Guo,Yuchen Wu,Aylin Caliskan,Tanu Mitra,Hua Shen
### Background
随着大语言模型（LLM）驱动的聊天机器人的广泛应用，这些聊天机器人的使用越来越多地用于意见探索。现有研究考察了LLM如何改变用户的观点，但很少有研究关注双向影响的问题，即用户输入如何能反过来影响LLM的回答，以及这种双向互动在多轮对话中如何表现。该研究通过50个具有争议的话题讨论探索了这一动态，涉及266名参与者并分为三种条件：静态陈述、标准聊天机器人和个性化聊天机器人。
### Innovation
该研究通过50个具有争议性的主题讨论测试了人类和LLM的观点如何在多层次对话中变化。研究发现，人类观点变化较小，但LLM输出变化显著，这缩短了人类和LLM之间立场的差距。个性化聊天机器人相较于标准设置，在双向变化上更为显著。此外，个人故事在对话中的交流最有可能导致双方立场的变化。
### Conclusion
研究强调了人类与LLM互动中的过度一致性带来的风险，并指出了精心设计个性化聊天机器人的重要性，以实现更深入和稳定的观点一致性。
## 63. `cs.AI` - 通过模仿学习实现的微电网能源管理的 approximate 模型预测控制 [PDF](https://arxiv.org/pdf/2510.20040), [HTML](https://arxiv.org/abs/2510.20040)
### Authors
Changrui Liu,Shengling Shi,Anil Alan,Ganesh Kumar Venayagamoorthy,Bart De Schutter
### Background
随着可再生能源的不断集成，可靠的和可持续的微电网运营对高效的能量管理提出了要求。本文基于模仿学习提出了一种框架，用于近似混合整数经济模型预测控制（EMPC），以实现微电网的能量管理。该方法通过离线轨迹训练神经网络来模仿专家的EMPC控制行为，从而实现快速的实时决策，而不需要在线求解优化问题。学习过程中还增加了噪声注入，以减轻分布变化，同时明确地整合了可再生能源生成和需求的预测不确定性。模拟结果表明，该学习到的策略在经济性能上接近于基于优化的EMPC，但实际中只需要后者的10%的计算时间。
### Innovation
提出了一种基于模仿学习的框架来近似混合整数经济模型预测控制（EMPC），以实现微电网的能量管理。与传统方法相比，该框架通过离线学习进行快速决策，无需在线求解复杂的优化问题。此外，该方法通过包括噪声注入和预测不确定性来提高鲁棒性和泛化能力。
### Conclusion
所提出的方法能够在经济性能与基于优化的EMPC接近的前提下，显著减少计算时间。通过离线学习，系统能够实现快速响应和决策，同时通过噪声注入和预测不确定性处理增强了系统的鲁棒性和泛化能力。
## 64. `cs.AI` - 为您的国家做什么：朝向公共红队模型的方向 [PDF](https://arxiv.org/pdf/2510.20061), [HTML](https://arxiv.org/abs/2510.20061)
### Authors
Wm. Matthew Kennedy,Cigdem Patlak,Jayraj Dave,Blake Chambers,Aayush Dhanotiya,Darshini Ramiah,Reva Schwartz,Jack Hagen,Akash Kundu,Mouni Pendharkar,Liam Baisley,Theodora Skeadas,Rumman Chowdhury
### Background
人工智能系统有产生益处和危害的潜力，但如果没有严谨且持续的对抗性评估，AI行为者将难以评估AI风险的广度和规模。尽管来自系统设计领域的研究人员已开发出多种有效的方法，用于社会技术AI评估和红队测试，针对偏见、仇恨言论、虚假信息和其他已记录的危害类别进行有效检测，但在越来越多复杂的AI系统被释放到高风险领域（如教育、医疗和情报收集）时，我们现有的评估和监控方法正在变得不够有效。为了实现负责任的AI，确保AI的危害完全被理解并减轻其安全漏洞，迫切需要提出新的方法来弥补这种“责任差距”。
### Innovation
本文提出了一种新的方法——合作公共AI红队训练演习，并讨论了其早期实施的初步结果。这种方法与CAMLIS密切相关：CAMLIS 2024年首次亲自举行的公共演示员演习就是这个方法的一个实例。讨论了该演习的操作设计及结果，以及之前由美国国家标准与技术研究院（NIST）组织的评估AI风险和影响（ARIA）试点演习和其他与新加坡国家通讯和媒体发展局（IMDA）进行的类似演习的结果。最终，本文认为这种方法既能够带来有意义的结果，也能够针对许多AI开发辖区进行扩展。
### Conclusion
本文提出的合作公共AI红队训练演习方法不仅能够提供有意义的结果，还能够在许多AI开发辖区进行扩展，以弥补负责任AI实现过程中的“责任差距”。
## 65. `cs.AI` - ShapeX: 形态驱动事后时间序列分类模型解释 [PDF](https://arxiv.org/pdf/2510.20084), [HTML](https://arxiv.org/abs/2510.20084)
### Authors
Bosong Huang,Ming Jin,Yuxuan Liang,Johan Barthelemy,Debo Cheng,Qingsong Wen,Chenghao Liu,Shirui Pan
### Background
在高风险的应用场景（如医疗和金融）中，解释时间序列分类模型至关重要，因为透明度和信任度非常关键。尽管已有许多方法通过识别关键子序列（称为形状）作为核心特征来实现最先进的性能并验证其在分类结果中的关键作用，但现有的事后时间序列解释（PHTSE）方法主要关注于时间步长级别的特征归因。现有方法忽视了时间序列分类结果主要是由关键形状驱动的这一基本原则。
### Innovation
为解决上述问题，本文提出了ShapeX，一个创新框架，将时间序列分割为由形状驱动的意义段，并采用Shapley值来评估各段的重要性。ShapeX的核心是Shapelet Describe-and-Detect（SDD）框架，它可以有效学习用于分类的关键形状。此外，ShapeX生成的解释揭示了因果关系而非仅仅相关性，这是因为形状具有原子性。实验证明，ShapeX在识别相关的子序列方面优于现有方法，提高了时间序列解释的精确性和因果保真性。
### Conclusion
ShapeX超越了现有方法，在识别相关子序列方面表现更优，不仅提高了时间序列解释的精确性，还增强了因果保真性。
## 66. `cs.AI` - 通过自适应路由和针对性推理利用大型语言模型在实体链接中的力量 [PDF](https://arxiv.org/pdf/2510.20098), [HTML](https://arxiv.org/abs/2510.20098)
### Authors
Yajie Li,Albert Galimov,Mitra Datta Ganapaneni,Pujitha Thejaswi,De Meng,Priyanshu Kumar,Saloni Potdar
### Background
实体链接（EL）传统上依赖于大规模标注数据集和广泛的模型微调。近年来，少量样本方法通过提示来利用大型语言模型（LLM），从而减少训练需求，但它们常常由于基于LLM的推理昂贵而受到影响。因此，有必要提出一种高效的方法来替代传统的实体链接方法，以提高性能并降低计算资源的使用。
### Innovation
ARTER（自适应路由和针对性实体推理）提出了一种结构化流程，通过战略地结合候选生成、上下文得分、自适应路由和选择性推理，实现了高度的性能，同时减少了深度微调的需求。ARTER通过对检索出的候选实体计算一套互补信号（包括嵌入和基于LLM的信号），将上下文提及分类为简单和复杂情况，然后分别采用低计算量的实体链接器和成本更高的针对性LLM推理来处理不同情况，从而实现了高效和精准的效果。
### Conclusion
在标准基准测试中，ARTER在5个数据集中平均提高了2.53%的成绩，最高可以提高4.47%，并且与完全依赖于LLM推理的模块相比，效率提升了两倍。
## 67. `cs.AI` - CreativityPrism: 一大型语言模型创意的综合基准 [PDF](https://arxiv.org/pdf/2510.20091), [HTML](https://arxiv.org/abs/2510.20091)
### Authors
Zhaoyi Joey Hou,Bowei Alvin Zhang,Yining Lu,Bhiman Kumar Baghel,Anneliese Brei,Ximing Lu,Meng Jiang,Faeze Brahman,Snigdha Chaturvedi,Haw-Shiuan Chang,Daniel Khashabi,Xiang Lorraine Li
### Background
人们普遍认为创造力是人类智能的一个重要标志。尽管大型语言模型（LLMs）被广泛认为能够生成具有创造力的文字，但仍然缺乏一个全面的框架来评估它们在多种场景中的创造力。现有的评估方法仍然碎片化，各领域的任务之间存在显著差异，这是由于创造力的不同定义和测量方法所导致的。现有研究试图通过一个假设，即创造力不是固定不变的概念，提出一个名为CreativityPrism的评估分析框架，将创造力分解为三个维度：质量、新颖性和多样性。该框架包括九项任务、三个领域（发散思维、创造性写作和逻辑推理）和二十个评估指标，这些指标以特定任务的独特方式衡量每一维度。在评估了17种最先进的（SoTA）大型语言模型后，研究发现了产权模型和开源模型之间的显著差距。通常来说，模型在相同领域的任务表现高度相关，而在不同领域的任务表现则较不相关。对于评估维度，多样性和质量指标展现出很强的相关性，而新颖性指标与其他两个指标的相关性较弱。这些发现支持了研究者最初的假设，强于一个创意任务或维度的表现并不一定能够推广到其他任务或维度中，从而强调了需要对大型语言模型的创造力进行全面评估的重要性。
### Innovation
提出了CreativityPrism框架，这是一个全面的评估分析框架，将创造力分解为质量、新颖性和多样性三个维度，并通过九项任务和二十个评估指标来具体衡量。该框架能够在特定任务上独特地评估每一个维度的表现，并揭示了模型在不同领域和评估维度之间的表现相关性差异。并通过实际评估了多种最先进的大型语言模型，展示了现有模型在创造力方面存在的显著差距和弱相关性。
### Conclusion
大型语言模型的创造力表现出显著差距，且在不同领域及维度之间的表现并不一定相关。研究结果支持了创造力并不是单一固定概念，而是一个多维度的概念。这表明需要一个更全面的评估框架来全面考察大型语言模型的创造力，以发现它们的真实能力。
## 68. `cs.AI` - StableSketcher：通过视觉问答反馈增强基于像素的草图生成的扩散模型 [PDF](https://arxiv.org/pdf/2510.20093), [HTML](https://arxiv.org/abs/2510.20093)
### Authors
Jiho Park,Sieun Choi,Jaeyoon Seo,Jihie Kim
### Background
虽然最近在扩散模型方面的进步极大地丰富了生成图像的质量，但在合成基于像素的_human-drawn_素描（一种典型的抽象表达形式）方面仍然存在挑战。为了应对这些挑战，我们提出了StableSketcher，这是一种新颖的框架，可以让扩散模型生成具有高度提示准确性的手绘素描。在这个框架中，我们对变分自编码器进行了微调以优化潜在解码，使其更好地捕捉素描的特点。同时，我们引入了一种新的基于视觉问答的强化学习奖励函数，这提高了文本与图像的对齐度和语义一致性。目前广泛使用的数据集大多依赖于图像标签对，存在局限性。为此，我们提出了SketchDUO，这是一个已知的首个包含实例级别素描配对描述和问答对的数据集，从而解决了现有基于图像标签对数据集的局限性。我们的代码和数据集将在论文被接受后公开。
### Innovation
StableSketcher框架通过细调变分自编码器和引入基于视觉问答的强化学习奖励函数来优化潜在解码，从而提高扩散模型生成手绘素描的能力。此外，我们提供了SketchDUO数据集，这是一个首个包含实例级别素描配对描述和问答对的数据集，解决了现有数据集的局限性。
### Conclusion
广泛的实验表明，StableSketcher生成的素描在风格一致性方面有所提高，能够更好地与提示匹配，优于基于Stable Diffusion的基线模型。我们的代码和数据集将在论文被接受后公开。
## 69. `cs.AI` - SAID: 使大型语言模型具备自我激活内生防御的策略 [PDF](https://arxiv.org/pdf/2510.20129), [HTML](https://arxiv.org/abs/2510.20129)
### Authors
Yulong Chen,Yadong Liu,Jiawen Zhang,Mu Li,Chao Huang,Jie Wen
### Background
尽管在安全对齐方面取得了进步，大型语言模型（LLMs）仍然容易受到旨在规避保护机制的逃逸攻击。现有的防御策略依赖于外部干预，如输入过滤或输出修改，这些方法通常不具备普适性，会降低模型实用性并增加大量计算成本。
### Innovation
本研究引入了一种新的、无需训练的防御范式——自我激活内部防御（SAID），将防御任务从外部修正转变为内部能力激活。SAID 利用了大型语言模型自身的推理能力，通过三个阶段的处理流程主动识别和中和恶意意图：模型内部意图提炼提取核心语义，最优安全前缀探测激活潜在的安全意识，保守聚合策略以确保稳健的决策。经过在五个开源的大语言模型上针对六种先进的逃逸攻击的广泛实验，SAID 在减少有害输出方面明显优于最先进的防御方法，同时在良性任务上保持了模型性能，并且几乎没有增加计算成本。
### Conclusion
我们的工作表明，激活大型语言模型内在的安全机制是一种更稳健和可扩展的路径，以构建更安全和更可靠的对齐的人工智能系统。
## 70. `cs.AI` - 大型语言模型的零样本立场检测是否受到刻板印象的影响？ [PDF](https://arxiv.org/pdf/2510.20154), [HTML](https://arxiv.org/abs/2510.20154)
### Authors
Anthony Dubreuil,Antoine Gourru,Christine Largeron,Amine Trabelsi
### Background
大型语言模型在其预训练数据中继承了刻板印象，导致在诸如仇恨言论检测或情感分析等自然语言处理任务中对某些社会群体产生偏差行为。令人惊讶的是，这类偏差在立场检测方法中的评估在社区中被大大忽视。立场检测涉及将声明标记为反对、支持或对特定目标的中立，并且是NLP中最敏感的任务之一，因为它常常涉及到政治倾向。本文关注的是在零样本设置下，大型语言模型在立场检测任务中的偏见。研究人员通过自动对现有的立场检测数据集中的帖子进行注释，增加了两种属性：特定群体的语言变体（方言）和文本复杂性/可读性，以探讨这些属性是否影响模型的立场检测决策。实验结果表明，大型语言模型在立场检测任务中表现出明显的刻板印象偏差，例如错误地将支持大麻的观点与低文本复杂性以及将非裔美国人方言与反对唐纳德·特朗普的立场联系起来。
### Innovation
本研究是第一个系统地评估大型语言模型在零样本设置下的立场检测偏见的研究。通过自动标注立场检测数据集中的帖子，增加了关于方言和文本复杂性的属性，该研究能够深入探讨这些属性对模型决策的影响。研究结果揭示了大型语言模型在处理立场检测任务时存在的显著刻板印象偏差问题。
### Conclusion
大型语言模型在零样本立场检测任务中表现出刻板印象偏差，这些偏差可能影响模型的准确性和公正性。研究建议在未来的模型训练和数据预处理过程中需要更加关注和减少这些偏见。
## 71. `cs.AI` - 100k以上GPU的集体通信 [PDF](https://arxiv.org/pdf/2510.20171), [HTML](https://arxiv.org/abs/2510.20171)
### Authors
Min Si,Pavan Balaji,Yongzhou Chen,Ching-Hsiang Chu,Adi Gangidi,Saif Hasan,Subodh Iyengar,Dan Johnson,Bingzhe Liu,Jingliang Ren,Ashmitha Jeevaraj Shetty,Greg Steinbrecher,Xinfeng Xie,Yulun Wang,Bruce Wu,Jingyi Yang,Mingran Yang,Minlan Yu,Cen Zhao,Wes Bland,Denis Boyda,Suman Gumudavelli,Cristian Lumezanu,Rui Miao,Zhe Qu,Venkat Ramesh,Maxim Samoylov,Jan Seidel,Feng Tian,Qiye Tan,Shuqiang Zhang,Yimeng Zhao,Shengbao Zheng,Art Zhu,Hongyi Zeng
### Background
随着大型语言模型（LLMs）规模的不断增加，对高效集体通信框架的需求也在增加，尤其是在将训练工作负载扩展到数十万个GPU时。传统的通信方法在这一规模下面临显著的吞吐量和延迟限制，阻碍了先进模型的开发和部署。
### Innovation
该论文提出了由Meta公司开发的NCCLX集体通信框架，该框架旨在优化整个LLM生命周期中的性能，从大规模训练的同步需求到推理所需的低延迟。该框架设计用于支持超过100,000个GPU的集群上的复杂工作负载，确保可靠的、高吞吐量和低延迟的数据交换。实验结果表明，NCCLX在 llama4 模型中展示了显著的通信效率提升。
### Conclusion
这项研究为使下一代LLMs在前所未有的规模上运行提供了一个稳健的解决方案。
## 72. `cs.AI` - IB-GAN: 使用信息瓶颈生成对抗网络的解纠缠表示学习 [PDF](https://arxiv.org/pdf/2510.20165), [HTML](https://arxiv.org/abs/2510.20165)
### Authors
Insu Jeon,Wonkwang Lee,Myeongjang Pyeon,Gunhee Kim
### Background
本文提出了一种基于GAN的无监督新模型用于解纠缠表示学习。该模型试图利用信息瓶颈（IB）框架来优化GAN，由此得名IB-GAN。尽管IB-GAN的部分架构与InfoGAN类似，但它有一个关键区别：生成器中间层用于约束输入与生成输出之间的互信息。中间的随机层可以作为可学习的潜在分布，与生成器一起以端到端的方式进行训练。IB-GAN的生成器可以有效地利用潜在空间，使其在解纠缠和可解释性方面更具优势。该方法的实验结果表明，IB-GAN在dSprites和Color-dSprites数据集上的解纠缠表现与当前最先进的η-VAE相当，甚至优于InfoGAN。此外，在CelebA和3D Chairs数据集的FID评分上，IB-GAN生成的图像质量和多样性也往往优于η-VAE和InfoGAN
### Innovation
提出了一种新的基于GAN的无监督模型IB-GAN，该模型旨在通过信息瓶颈框架优化GAN的训练过程。中间的随机层可作为可学习的潜在分布，与生成器一起进行端到端训练，从而实现生成器对潜在空间的解纠缠和可解释利用。
### Conclusion
IB-GAN在dSprites和Color-dSprites数据集上的解纠缠表现与当前最先进的η-VAE相当，并且在生成样本的图像质量和多样性方面优于InfoGAN和η-VAE。
## 73. `cs.AI` - 关于McKean-Vlasov方程静止解结构及其在Noisy Transformer模型中的应用 [PDF](https://arxiv.org/pdf/2510.20094), [HTML](https://arxiv.org/abs/2510.20094)
### Authors
Krishnakumar Balasubramanian,Sayan Banerjee,Philippe Rigollet
### Background
本文研究圆上的McKean-Vlasov方程的平稳解。通过观察静态McKean-Vlasov方程的解与无限维的Fourier系数的二次系统之间的精确等价关系，作者能够明确地在序列空间中而不是函数空间中描述这些解。这一框架不仅提供了局部分岔的透明描述，还能够描绘分岔的周期性和谐振结构，并包含奇异势。因此，作者推导了描述可能涉及多个Fourier模的分岔的析因表达式，并将这些分岔与不连续相变联系起来。此外，作者在假定条件下详细描述了静态分岔解的结构，这些解直到任意多个Fourier模都是准确的。在全球层次上，作者证明了自由能景观的正则性和凹性，进一步证明了全局最小静止测度的存在性和紧致性，并将不连续相变与最小自由能映射的非光滑点联系起来。
### Innovation
本文的创新之处在于观察到了静态McKean-Vlasov方程与无限维的Fourier系数的二次系统的精确等价关系，使得可以在序列空间中描述解，而不是在函数空间中。这一框架能够提供对局部分岔的透明描述，还能够描绘分岔的周期性和谐振结构，而这些分岔可能涉及多个Fourier模，并与不连续相变相连接。此外，作者还推导了与不连续相变相关的解析表达，并在假定条件下描述了这些分岔解的详细结构。在全球层面上，作者证明了自由能景观的正则性和凹性，进一步证明了全局最小静止测度的存在性和紧致性，并将不连续相变与自由能最小化映射的非光滑点联系起来。本文还通过Noisy Mean-Field Transformer模型的应用，展示了如何通过改变逆温度参数影响无限多个分岔的几何形状，以及增加这一参数可以得到丰富类别的多模态静态解作为亚稳态。并且观察到随着逆温度参数的增加，从连续到不连续（一阶）相行为的尖锐转变。
### Conclusion
本文建立了自由能景观的正则性和凹性，证明了全局最小静止测度的存在性和紧致性，并将不连续相变与最低自由能映射的非光滑点联系起来。通过Noisy Mean-Field Transformer模型的应用，本文进一步说明了参数变化对多样砂分流体路径的影响，尤其是在极值温度参数下观察到的从连续到不连续相变的尖锐转变。
## 74. `cs.AI` - PPMStereo: Pick-and-Play Memory Construction for Consistent Dynamic Stereo Matching [PDF](https://arxiv.org/pdf/2510.20178), [HTML](https://arxiv.org/abs/2510.20178)
### Authors
Yun Wang,Junjie Hu,Qiaole Dong,Yongjian Zhang,Yanwei Fu,Tin Lun Lam,Dapeng Wu
### Background
在现实应用如增强现实领域中，从立体视频中估计一致性的深度对于提供沉浸式用户体验至关重要。然而，以往的方法在建模跨帧时序一致性时面临挑战，主要是因为难以在高效计算的同时准确模拟长时序依赖关系。
### Innovation
本文提出了PPMStereo方法，通过结合Pick-and-Play记忆模块，在动态立体匹配中实现了高效且具有时序一致性的特征聚合。该方法通过两阶段决策过程，优化了内存缓冲区的大小与信息量，使模型能够在降低计算成本的同时保持高精度。
### Conclusion
PPMStereo方法在准确性和时序一致性方面达到了现有技术中的最佳性能。具体来说，在Sintel数据集的clean/final版本上，与BiDAStereo相比，PPMStereo分别实现了17.3%和9.02%的性能提升，并且计算成本更低。
## 75. `cs.AI` - Mixture-of-Minds: 多代理强化学习表格理解 [PDF](https://arxiv.org/pdf/2510.20176), [HTML](https://arxiv.org/abs/2510.20176)
### Authors
Yuhang Zhou,Mingrui Zhang,Ke Li,Mingyi Wang,Qiao Liu,Qifei wang,Jiayi Liu,Fei Liu,Serena Li,Weiwi Li,Mingze Gao,Abhishek Kumar,Xiangjun Fan,Zhuokai Zhao,Lizhu Zhang
### Background
表格理解和推理是许多现实应用的关键能力。现有的大语言模型在这方面的表现尚可，但仍有局限。基于微调的方法增强了语言推理，但容易产生算术错误和幻觉。相比之下，基于工具的方法能够精确处理表格，但依赖于固定的模式，且缺乏语义理解。这些互补的缺点表明需要结合稳健的推理和可靠的数据处理的方法。本文提出了一种名为Mixture-of-Minds的多代理框架，将表格推理分解为规划、编码和回答三个专业化角色，使其能够专注任务的不同方面并利用代码执行进行精确的数据处理。
### Innovation
本文提出的Mixture-of-Minds框架将表格推理分解为三个专业化角色，并引入了结合蒙特卡洛树搜索（MCTS）卷积的自治改进训练框架，利用强化学习优化代理。这种框架在TableBench上达到了62.13%的成绩，超过OpenAI-o4-mini-high，展示了结合结构化多代理工作流程和强化学习来推进表格理解的潜力。
### Conclusion
这些实验结果表明，结合结构化多代理工作流程和强化学习可以显著提高表格理解能力。Mixture-of-Minds代表了一种新的方法，可以更好地处理表格数据并提供更准确的结果。
## 76. `cs.AI` - 在矩阵中受阻：大型语言模型的空间推理探查 [PDF](https://arxiv.org/pdf/2510.20198), [HTML](https://arxiv.org/abs/2510.20198)
### Authors
Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum
### Background
本文通过一系列五项任务测试了大型语言模型（LLMs）在文本输入条件下对空间推理能力的认识，采用了从基本到复杂多步问题解决的任务，这些任务包括象限识别、几何变换、距离评估、词汇搜索和拼图滑动。这些任务在复杂度上逐渐增加，促使模型从简单的模式识别过渡到抽象的空间推理。
### Innovation
研究提出了一个覆盖五大任务来评估LLMs的空间理解和计算能力的新框架，揭示了LLMs在空间推理任务上的局限性，特别是表现在随着任务复杂度增加，模型性能急剧下降的现象。
### Conclusion
研究表明，尽管LLMs在低复杂度任务上表现尚可，但随着任务复杂度的增加，其准确率显著下降。这揭示出LLMs在空间推理方面的局限性，并且这种下降的趋势是高度一致的。此外，模型在复杂性任务上的困难暗示其底层架构缺乏稳健的空间表征。该研究明确了语言理解和空间推理之间的差距，并提供了一些建议，为未来结合语言和几何的统一基准奠定了基础。
## 77. `cs.AI` - 使用常规实验室数据评估早期癌症检测的可能性：不平衡数据集上机器学习方法的评估 [PDF](https://arxiv.org/pdf/2510.20209), [HTML](https://arxiv.org/abs/2510.20209)
### Authors
Shumin Li
### Background
兽医医学中开发易于获取的早期癌症筛查工具面临着重大挑战。常规实验室数据可能提供低成本的筛查工具，但其实用性受限于单个生物标志物的非特异性以及筛查群体中存在的严重类别不平衡问题。研究旨在在真实世界的约束条件下，评估使用加权金毛寻回犬终身研究（GRLS）群体进行癌症风险分类的可能性，包括将多种类型的癌症分组以及包括诊断后样本。研究进行了基准测试评估，系统地比较了126种分析管道，这些管道包含各种机器学习模型、特征选择方法和数据平衡技术。
### Innovation
该研究的创新在于通过全面评估多种机器学习模型和数据平衡技术，为期望利用常规实验室数据进行早期癌症检测提供了依据。特别地，研究使用了数据平衡技术和特征消除方法，以应对类别不平衡问题，并通过SHapley Additive exPlanations (SHAP)解释方法揭示预测依据的特征。这些方法有助于识别哪些特征在模型预测中起重要作用，并探索用于早期癌症检测的常规实验室数据的有效性边界。
### Conclusion
常规实验室数据中确实存在可统计检测的癌症信号，但由于其太弱且受到混淆，无法可靠地区分正常老化或其它炎症状态。因此，单独使用常规实验室数据在计算兽医肿瘤学中实现有意义的进步需要集成多模态数据来源。这一研究成果设定了这一数据模态在这种孤立情况下的重要性能上限，突显出跨模态数据联合分析的重要性。
## 78. `cs.AI` - 高阶交互建模以实现可解释的多智能体Q学习 [PDF](https://arxiv.org/pdf/2510.20218), [HTML](https://arxiv.org/abs/2510.20218)
### Authors
Qinyu Xu,Yuanyang Zhu,Xuefei Wu,Chunlin Chen
### Background
在多智能体强化学习（MARL）中，有效建模智能体间的交互对于协调和理解其合作机制至关重要。然而，之前的尝试主要受到计算复杂度爆炸带来的组合爆炸问题或黑盒网络结构不透明性的限制。
### Innovation
本文提出了一种新颖的价值分解框架，称为连续分数Q学习（QCoFr），能够以线性复杂度(记为O(n)在智能体数量中的复杂度)灵活捕捉任意阶智能体交互，从而避免了在建模丰富合作过程中的组合爆炸问题。此外，引入了变分信息瓶颈来提取用于估算奖励的潜在信息，这有助于智能体筛选掉噪声交互，进而显著提升合作性能与可解释性。
### Conclusion
广泛的实验结果显示，QCoFr不仅能够持续获得更好的性能，还提供了符合理论分析的可解释性。
## 79. `cs.AI` - FinCARE：基于推理与证据的金融因果分析 [PDF](https://arxiv.org/pdf/2510.20221), [HTML](https://arxiv.org/abs/2510.20221)
### Authors
Alejandro Michel,Abhinav Arun,Bhaskarjit Sarmah,Stefano Pasquali
### Background
投资组合经理依赖于基于相关性的分析和启发式方法，这些方法无法捕捉真正驱动绩效的实际因果关系。现有的方法存在无法理解和利用因果关系的问题，特别是在金融领域，这限制了投资组合的有效管理和发展。
### Innovation
本文提出了一种综合框架，结合了统计因果发现算法和金融知识图谱（源于SEC 10-K文件）以及大规模语言模型推理。该方法系统性地增强了三种代表性因果发现方法：约束导向算法（PC）、评分导向算法（GES）和连续优化（NOTEARS），通过算法编码知识图谱约束并利用LLM的概念推理进行假设生成。该框架在500家公司的18个变量的合成金融数据集上进行了评估，结果显示增强后的方法在所有三个算法中都表现出了稳定的性能提升。
### Conclusion
该框架通过将统计发现与金融专业知识结合，不仅能够提供可靠的情景分析，还能预测干预效果的方向，并且避免了现有方法的局限性。这为投资组合经理提供了预测风险管理以及在动态市场环境中进行战略决策所需的因果基础。
## 80. `cs.AI` - QKCV注意力机制：通过静态类别嵌入增强时序预测，适用于轻量级和预训练基础模型 [PDF](https://arxiv.org/pdf/2510.20222), [HTML](https://arxiv.org/abs/2510.20222)
### Authors
Hao Wang,Baojun Ma
### Background
在实际的时序数据分析任务中，类别的信息对于捕捉数据内在模式至关重要。现有的注意力模型在处理时序预测任务时，通常无法有效地利用类别的信息来提高预测精度。
### Innovation
提出了QKCV（查询-键-类别-值）注意力机制，它是传统QKV框架的扩展，包含了一个静态的类别嵌入C，以强调特定类别的信息。QKCV作为一种多功能的插件模块，能够提升基于注意力的模型（如纯手工Transformer、Informer、PatchTST、TFT）在多种实际数据集上的预测精度。此外，QKCV还展示了在轻量级时间序列基础模型上进行微调的强大适应性，仅通过更新静态嵌入C来完成微调，同时保存预训练权重，减少计算量并获得更好的微调性能。
### Conclusion
QKCV注意力机制能够显著提升注意力模型在时序预测任务中的表现，尤其适用于构建轻量级模型和对预训练模型进行有效的微调。
## 81. `cs.AI` - 利用AI代理实现自动化云基础设施即代码的校准 [PDF](https://arxiv.org/pdf/2510.20211), [HTML](https://arxiv.org/abs/2510.20211)
### Authors
Zhenning Yang,Hui Guan,Victor Nicolet,Brandon Paulsen,Joey Dodds,Daniel Kroening,Ang Chen
### Background
云基础设施传统上通过云控制台、命令行界面（CLI）和软件开发工具包（SDK）进行管理。近年来，Infrastructure-as-Code/IaC框架（例如Terraform）渐渐受到欢迎。这些框架将基础设施编码为“真相来源”的配置，并能自动进行部署、更新或销毁资源的操作，以使实际基础设施与IaC配置一致。然而，当使用IaC时，如果与云控制台、CLI或SDK一起使用，IaC可能会失去对外部更改的可见性，导致基础设施漂移问题，即配置变得过时，随后的IaC操作可能会撤销有效的更新或触发错误。
### Innovation
NSync是一个自动化的IaC校准系统，能够将外部更改传播回IaC程序。该系统的关键观点在于所有的基础设施更改最终都会通过云API调用进行，这些调用是云管理操作的最底层。NSync通过分析API追踪来检测漂移（即非IaC更改），并通过更新IaC配置来重新校准。NSync采用了代理架构，利用LLMs从嘈杂的API序列中推断出高级意图，使用专业工具合成针对性的IaC更新，并通过自我进化的知识库不断改进。此外，还提出了一种新的评估管道，可以注入现实的漂移场景并对校准性能进行评估。实验结果显示，与基线相比，NSync在准确性和标记效率方面表现更佳（从0.71提高至0.97，并且提高了1.47倍）.
### Conclusion
NSync通过代理架构和AI代理成功地解决了IaC校准的问题，通过自动化的API追踪和校准操作，提高了IaC的准确性和效率。
## 82. `cs.AI` - 通过元变分删除层实现联邦学习 [PDF](https://arxiv.org/pdf/2510.20225), [HTML](https://arxiv.org/abs/2510.20225)
### Authors
Insu Jeon,Minui Hong,Junhyeog Yun,Gunhee Kim
### Background
联邦学习（FL）旨在从远程分布的客户端中训练全局推理模型，因其能够改善数据隐私而逐渐流行。然而，传统联邦学习在实际应用中常常面临两大挑战：模型过拟合和局部模型的发散现象，主要原因在于客户端之间的数据有限且呈非IID（非独立同分布）特性。
### Innovation
本文引入了一种新颖的贝叶斯元学习方法，称为Meta-variational dropout（MetaVD）。MetaVD通过共享的超网络学习预测客户端依赖的删除率，从而使联邦学习算法能够在有限的非IID数据设置中有效地实现模型个性化。同时，还强调了元学习的后验适应视角和贝叶斯联邦学习的后验聚合视角，通过条件删除后验实现。文中在各种稀疏和非IID的联邦学习数据集上进行了大量实验，展示了MetaVD在分类准确性和不确定性校准性能上的卓越表现，特别是在分布外（OOD）客户端上的优势。此外，MetaVD能够压缩每个客户端所需的本地模型参数，缓解模型过拟合并降低通信成本。
### Conclusion
实验结果表明，MetaVD在不同稀疏和非IID的联邦学习数据集上均表现出优秀的分类准确性和不确定性校准性能，特别是在处理OOD客户端时更加出色。MetaVD通过对每个客户端压缩需用的本地模型参数，有效缓解了模型过拟合并降低了通信成本。
## 83. `cs.AI` - 带有最大最小准则的多目标强化学习：一种博弈论方法 [PDF](https://arxiv.org/pdf/2510.20235), [HTML](https://arxiv.org/abs/2510.20235)
### Authors
Woohyeon Byeon,Giseung Park,Jongseong Chae,Amir Leshem,Youngchul Sung
### Background
本文提出了一种可证明收敛且实用的框架，用于具有最大最小准则的多目标强化学习。从博弈论的角度，将最大最小多目标强化学习重新表述为两人零和正则化连续博弈，并引入基于镜下降方法的有效算法。该方法简化了策略更新过程，同时保证了全局最后迭代的收敛性。文章提供了对所提出算法的全面理论分析，包括精确和近似策略评估下的迭代复杂性和样本复杂性边界。
### Innovation
1. 提出了一个可证明收敛且实用的框架，用于具有最大最小准则的多目标强化学习。2. 从博弈论视角重新表述了问题，并基于镜下降方法设计了高效的算法。3. 分析了算法的迭代复杂性和样本复杂性，并通过自适应正则化提高性能。4. 通过实验证明了算法在表格环境下的收敛性，并在深度强化学习环境中显著优于之前的基线方法。
### Conclusion
本文提出了一种新的方法来解决多目标强化学习问题，通过理论分析和实际实验验证了算法的有效性和优越性。
## 84. `cs.AI` - 为什么在更长的响应中LVLMs更容易出现幻觉：背景的作用 [PDF](https://arxiv.org/pdf/2510.20229), [HTML](https://arxiv.org/abs/2510.20229)
### Authors
Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang
### Background
近年来，大型视觉-语言模型（LVLMs）取得了显著进展，但在生成较长、自由形式的响应时也出现了幻觉问题。这些问题常常被认为是累积不确定性导致的。已有研究认为，幻觉问题与响应长度有关，但该论文提出，风险并非由长度本身引起，而是由在更长的响应中对上下文依赖增加以实现连贯性和完整性所导致的。
### Innovation
提出了一个新颖的“诱导-检测-抑制”框架，通过精心设计的上下文主动诱导幻觉，利用诱发的例子早期检测高风险案例，并最终在实际解码过程中抑制可能的对象级幻觉。该方法在所有基准测试中均表现出一致而显著的改进，证明了其有效性，并验证了上下文的重要性。
### Conclusion
研究不仅验证了框架的有效性，更重要的是确认了上下文在LVLMs长响应中幻觉问题中的关键作用。研究旨在提供新的见解，并作为探索LVLMs中幻觉问题深层次机制的第一步，而非仅仅追求性能提升。
## 85. `cs.AI` - 跨模态严重性融合诊断在抑郁和创伤后应激障碍中的应用 [PDF](https://arxiv.org/pdf/2510.20239), [HTML](https://arxiv.org/abs/2510.20239)
### Authors
Filippo Cenacchi,Deborah Richards,Longbing Cao
### Background
抑郁和创伤后应激障碍（PTSD）常常同时出现并伴随一系列症状，这使得自动评估变得复杂。当前的自动化评估往往是二元化的且针对特定障碍，临床有用的诊断需要能够识别各类别严重程度的跨障碍估测和决策支持解释。
### Innovation
提出了一种统一的三模态情感严重度框架，将访谈文本与句子级Transformer嵌入、音频与log Mel统计及其变化、面部信号与行为单元、注视、头部和姿态描述相结合，以输出抑郁（PHQ-8，分为5类）和PTSD（分为3类）的分级严重程度。每种障碍的概率和特征级归因通过标准化特征在校准的晚融合分类器中融合得出。该三模态情感融合方法演示了双重障碍同时诊断抑郁和PTSD的效果。分层交叉验证结果显示，融合模型在准确性、加权F1值以及噪声或数据缺失下的鲁棒性上优于单一模态/去除基线。
### Conclusion
对PTSD的融合减少了回归误差，提高了类别一致性。错误主要分布在相邻类别之间，极端类别可以可靠地检测出来。消融实验表明文本对抑郁严重度的贡献最大，音频和面部线索对于PTSD至关重要，而归因与语言和行为标志一致。该方法提供了可重复的评估和与临床医生在环的支持，为情感临床决策提供依据。
## 86. `cs.AI` - 构建高性能的选择性分类器需要什么？ [PDF](https://arxiv.org/pdf/2510.20242), [HTML](https://arxiv.org/abs/2510.20242)
### Authors
Stephan Rabanser,Nicolas Papernot
### Background
选择性分类器通过在模型认为不确定的情况下弃权来提高模型可靠性。然而，很少有实际方法能达到完美排序公理的性能标准，即恰好按正确性顺序接受样例。本研究将这一缺陷称为选择性分类间隙，并首次对该间隙进行了五种不同松弛来源的有限样本分解：贝叶斯噪声、近似误差、排名误差、统计噪声和实现或转移引起的宽松。
### Innovation
本研究分析揭示了单调后校准对缩小这一间隙的影响有限，因为它很少改变模型的基本得分排名。因此，缩小差距需要能够重新排序预测而不是仅重新缩放得分的评分机制。研究结果通过合成的双月形数据和现实世界的视觉和语言基准验证了分解方法，证明了贝叶斯噪声和有限模型能力可以解释大量的差距，只有更丰富、特征感知的校准器能有意义地改进得分排序，并且数据转移需要分布鲁棒训练，共同得出定量的误差预算和可操作的设计指南。
### Conclusion
本研究的分解提供了一个定量的误差预算以及实践者可以使用的设计指导方针，以便构建更接近理想公理行为的选择性分类器。
## 87. `cs.AI` - PRM-Guided Tree Search for Mathematical Reasoning with LLMs的限制 [PDF](https://arxiv.org/pdf/2510.20272), [HTML](https://arxiv.org/abs/2510.20272)
### Authors
Tristan Cinquin,Geoff Pleiss,Agustinus Kristiadi
### Background
尽管链式思维提示结合Best-of-N（BoN）选择在大型语言模型（LLMs）中的数学推理方面非常流行，但线性的提示结构无法捕捉复杂问题求解中的分支和探索性特征。在本文中，作者提出了一种自适应算法，旨在最大化难以处理的动作空间中的过程奖励模型（PRM）分数，并探讨了PRM指导下的树搜索是否能通过探索多个部分解路径来改善数学推理。
### Innovation
提出了一个自适应算法来最大化难以处理的动作空间中的PRM分数；研究了PRM指导下的树搜索在大规模语言模型（LLMs）中数学推理中的应用；发现Monte Carlo树搜索和束搜索方法优于其他PRM指导下的树搜索方法。
### Conclusion
PRM指导下的树搜索在数学推理任务中表现不佳，没有显著优于BoN，但Monte Carlo树搜索和束搜索方法表现更好；PRM难以准确近似状态值，可靠性随推理深度增加而降低；PRM泛化能力差，这些表现不佳的原因在于树搜索对不可靠的PRM分数的依赖，因此需要不同的奖励建模才能有效提升LLMs中的数学推理能力。
## 88. `cs.AI` - 在高等教育中的AI代理课程教学：来自现场的初步经验 [PDF](https://arxiv.org/pdf/2510.20255), [HTML](https://arxiv.org/abs/2510.20255)
### Authors
Yogesh Simmhan,Varad Kulkarni
### Background
文章介绍了在印度科学研究所(IISc)的一门研究生级别的云计算课程中，部署并评估了一个基于AI的教育代理的早期研究成果。该文章详细描述了大语言模型（LLM）驱动的教育代理的设计，并介绍了一种教学框架，该框架将教育代理整合到课程流程中，以主动与学生互动进行内容交付，并由人类讲师提供课程结构和进行问答环节。此外，还提出了一种分析框架，用于使用可解释的参与度指标（如主题覆盖、主题深度和换段完善）评估代理-学生交互记录。
### Innovation
研究提出了一种基于大语言模型（LLM）的教育代理设计方法，并结合人类讲师，提出了结构化地将对话AI代理整合到课程中的方法。还提出了一种分析框架，利用可解释的参与度指标评估代理-学生交互记录，并进行初步分析，揭示了学生参与模式的演变模式，从广泛的概念探索到深入、集中的探究。这些成果展示了如何通过结构化整合对话AI代理来促进反思性学习，并为在真实课堂环境中研究参与度提供了一种可复制的方法，支持大规模、高质量的高等教育。
### Conclusion
研究结果表明，结构化整合对话AI代理可以促进反思性学习，并提供了一种在实际课堂环境中研究参与度的可复制方法，支持大规模、高质量的高等教育。同时也报告了学生在课堂上与代理互动的初步体验，以及在两个连续的教学模块中应用评估指标的初步分析结果。
## 89. `cs.AI` - UI-Ins: 使用多视角指令推理增强GUI定位 [PDF](https://arxiv.org/pdf/2510.20286), [HTML](https://arxiv.org/abs/2510.20286)
### Authors
Liangyu Chen,Hanzhang Zhou,Chenglin Cai,Jianan Zhang,Panrong Tong,Quyu Kong,Xu Zhang,Chen Liu,Yuqi Liu,Wenxuan Wang,Yue Wang,Qin Jin,Steven Hoi
### Background
GUI接地映射自然语言指令到可操作的UI元素是GUI代理的核心能力。过去的工作大多将指令视为用户意图的静态代理，忽视了多样性与质量对接地性能的影响。
### Innovation
论文提出了一种新的指令推理范式（Instruction-as-Reasoning），视指令为动态分析途径，模型可根据推理需求选择最优路径。为此，提出了一种两阶段训练框架：监督微调(SFT)与合成多样化指令以培养多视角推理能力，随后的强化学习(RL)优化路径选择与组合。
### Conclusion
所提出的UI-Ins-7B和UI-Ins-32B模型在五个具有挑战性的接地基准测试中达到最佳结果，并展示了自适应推理，能够在推理时合成并组合新的指令路径。特别地，UI-Ins-32B在UI-I2E-Bench中的定位准确率为87.3%，在ScreenSpot-Pro中为57.0%，在MMBench-GUI L2中为84.9%。模型还展示了强大的智能代理潜力，在AndroidWorld中取得了74.1%的成功率。此外，分析显示推理可以增强而非阻碍定位性能，并揭示了SFT+RL框架中策略崩溃的解决方案。
## 90. `cs.AI` - RAG-Stack: 从向量数据库视角联合优化RAG的质量和性能 [PDF](https://arxiv.org/pdf/2510.20296), [HTML](https://arxiv.org/abs/2510.20296)
### Authors
Wenqi Jiang
### Background
检索增强生成（RAG）已经成为矢量数据库最重要应用之一，通过将数据库中检索到的文档集成到大语言模型（LLM）的提示中，RAG能够生成更可靠和有信息量的内容。尽管在矢量数据库上的研究已经很广泛，但当它们被纳入整个端到端的RAG管道中时，仍有许多开放的研究问题。联合优化RAG系统的性能和生成质量是这一领域的一个实际且具有挑战性的问题，这个问题比预期的要复杂得多，因为它包括算法方面（包括模型和数据库）和系统方面（从软件到硬件）等多个变量。
### Innovation
本文提出了RAG-Stack，这是一种三支柱蓝图，用于优化RAG系统的质量和性能。RAG-Stack包括：（1）RAG-IR，一种中间表示，作为抽象层以解耦质量和性能属性；（2）RAG-CM，一个成本模型，根据RAG-IR估计系统性能；（3）RAG-PE，一个计划探索算法，用于搜索高质量、高性能的RAG配置。
### Conclusion
我们相信，这种三支柱蓝图将成为未来RAG质量和性能联合优化的默认范式。
## 91. `cs.AI` - 增强深度强化学习中的安全性：对抗攻击与防御的全面综述 [PDF](https://arxiv.org/pdf/2510.20314), [HTML](https://arxiv.org/abs/2510.20314)
### Authors
Wu Yichao,Wang Yirui,Ding Panpan,Wang Hailong,Zhu Bingqian,Liu Chun
### Background
随着深度强化学习（DRL）技术在自动驾驶、智能制造和智能医疗等复杂领域的广泛应用，如何在动态和多变的环境中提高其安全性和鲁棒性，已成为当前研究的核心问题。特别是在面对对抗攻击时，DRL可能会遭受严重性能下降甚至做出危险决策，因此在敏感的安全场景中确保其稳定性至关重要。
### Innovation
本文首先介绍了DRL的基本框架及其在复杂和多变环境中的主要安全挑战，并提出了一种基于扰动类型和攻击目标的对抗攻击分类框架，详细综述了主流的对抗攻击方法，包括针对DRL的各种攻击方法，如状态空间扰动、动作空间扰动、奖励函数及其模型空间。文章还系统总结了各种当前鲁棒性训练策略，包括对抗训练、竞合训练、鲁棒学习、对抗检测、防御蒸馏等相关的防御技术，探讨了这些方法在提高DRL鲁棒性方面的优缺点，展望了DRL对抗环境下的未来研究方向，强调了增强泛化能力、降低计算复杂度、提高可扩展性和可解释性等方面的研究需求，为研究人员提供了有价值的参考和方向。
### Conclusion
文章指出了DRL在对抗环境中的未来研究方向，强调了提升泛化能力、减少计算复杂度以及增强可扩展性和可解释性等方面的需求，旨在为研究人员提供有价值的参考和方向。
## 92. `cs.AI` - DB-FGA-Net: 双路主干频域门控注意力网络结合Grad-CAM解释性在多分类中的应用 [PDF](https://arxiv.org/pdf/2510.20299), [HTML](https://arxiv.org/abs/2510.20299)
### Authors
Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim
### Background
在神经肿瘤学中，早期和精确的脑肿瘤诊断对于成功治疗至关重要。基于深度学习的脑肿瘤分类方法通常依赖于大量数据增强，这可能限制模型的泛化能力和在临床应用中的可信度。因此，急需一种无需数据增强的模型，能够捕捉局部和全局特征，同时提供可解释的预测结果，以推动脑肿瘤诊断的临床应用进步。
### Innovation
该论文提出了一种结合VGG16和Xception的双主干网络，并加入了频域门控注意力（FGA）块，以捕捉互补的局部和全局特征。不同于以往研究，该模型在无需数据增强的情况下达成了最先进的性能，展示了对不同大小和分布的数据集的鲁棒性。此外，将Grad-CAM集成进模型以可视化肿瘤区域，增强了模型预测与临床解释之间的联系。
### Conclusion
研究成果表明，DB-FGA-Net模型在7K-DS数据集的四分类任务中达到了99.24%的准确率，在三分类和二分类任务中分别达到了98.68%和99.85%的准确率。在独立的3K-DS数据集上，模型达到了95.77%的准确率，优于基线和现有最先进的方法。为此，还开发了一个图形用户界面（GUI），提供实时分类和基于Grad-CAM的肿瘤定位，证明了此类无需增强、可解释且可部署的深度学习模型在脑肿瘤诊断中的可靠临床转化潜力。
## 93. `cs.AI` - LEGO：推荐系统中轻量高效多属性去学习框架 [PDF](https://arxiv.org/pdf/2510.20327), [HTML](https://arxiv.org/abs/2510.20327)
### Authors
Fengyuan Yu,Yuyuan Li,Xiaohua Feng,Junjie Fang,Tao Wang,Chaochao Chen
### Background
随着对保护敏感用户信息需求的增长，推荐系统中的属性删除问题受到越来越多的关注。现有研究主要集中在单个属性的删除上。然而，在实际应用中，隐私保护需求往往涉及多个敏感属性，并且是动态变化的，现有的单属性删除方法由于无法同时处理多个删除请求和缺乏应对动态需求的有效适应能力，无法满足这些实际需求。
### Innovation
该论文提出了LEGO，一种轻量高效的多属性去学习框架，它将多属性去学习过程分为两个步骤：一是嵌入校准（Embedding Calibration），二是灵活组合（Flexible Combination）。LEGO通过最小化互信息的方式来表示去学习过程，从而解决了同时删除多个属性的问题（解决CH1：不能同时处理多个删除请求）。LEGO的两步框架使得嵌入校准可以并行执行，而灵活组合则既灵活又高效地应对动态需求（解决CH2：缺乏高效的适应动态需求的能力）。
### Conclusion
实验结果表明LEGO框架在三个代表性的推荐模型和三个实际数据集上都具有高效性和有效性。该论文的代码和附录可以在指定的URL找到。
## 94. `cs.AI` - GhostEI-Bench: Do Mobile Agents Resilience to Environmental Injection in Dynamic On-Device Environments？ [PDF](https://arxiv.org/pdf/2510.20333), [HTML](https://arxiv.org/abs/2510.20333)
### Authors
Chiyu Chen,Xinhao Song,Yunkai Chai,Yang Yao,Haodong Zhao,Lijun Li,Jie Li,Yan Teng,Gongshen Liu,Yingchun Wang
### Background
视觉语言模型(VLMs)正越来越多地被用作自主代理来导航移动图形用户界面(GUIs)。它们在一个包含通知、弹出窗口和跨应用交互的动态且设备上的生态系统中运作，这使它们面临一种新的且尚未充分探索的威胁：环境注入。这种注入方式通过直接在GUI中插入对抗性UI元素（例如欺骗性覆盖或篡改的通知）来破坏代理的视觉感知，从而绕过文本保护措施，可能导致隐私泄露、经济损失或不可逆转的设备妥协。
### Innovation
本文介绍了GhostEI-Bench，这是首个针对动态执行环境中环境注入攻击下的移动代理进行评估的基准。GhostEI-Bench突破了静态图像评估的限制，将对抗性事件注入到在完全运行的Android模拟器中的实际应用工作流程中，并使用关键风险场景来评估性能。此外，还提出了一个法官LLM协议，通过对代理的动作轨迹和对应的截屏序列进行细粒度的失败分析，来定位感知、识别或推理的失败。实验证明，当前最先进的代理模型对恶意环境线索表现出明显的脆弱性：在感知和推理篡改的UI方面系统性地失败。GhostEI-Bench提供了一个衡量和缓解这种新兴威胁的框架，为更稳健和安全的代理铺平了道路。
### Conclusion
GhostEI-Bench为量化和缓解这一新兴威胁提供了一个框架，从而有助于更为稳健和安全的代理的发展。
## 95. `cs.AI` - 通过学习预测性上下文嵌入实现上下文级语言建模 [PDF](https://arxiv.org/pdf/2510.20280), [HTML](https://arxiv.org/abs/2510.20280)
### Authors
Beiya Dai,Yuliang Liu,Daozheng Xue,Qipeng Guo,Kai Chen,Xinbing Wang
### Background
Next-token prediction (NTP) 是现代大型语言模型（LLMs）预训练的基础，推动了其在文本生成、推理和指令跟随方面的空前能力。然而，基于标记级别的预测限制了模型捕获高层次语义结构和长距离上下文关系的能力。为了克服这一限制，我们提出了 ContextLM，这是一种在标准预训练基础上增加固有的“下一步上下文预测”目标的框架。这种方法训练模型学习多标记上下文的预测表示，利用未来标记块产生的错误信号。实验表明，ContextLM 在 GPT2 和 Pythia 模型系列上（扩展到 1.5B 参数）均取得了提升，尤其在困惑度和下游任务性能上表现出显著改进。进一步分析表明，下一步上下文预测为更强的语言建模提供了一条可扩展且效率高的途径，实现了更长距离的一致性和更有效的注意力分配，而几乎没有额外的计算开销。
### Innovation
提出了 ContextLM 框架，通过在标准预训练基础上增加固有的“下一步上下文预测”目标，使得模型能够学习多标记上下文的预测表示，这有助于模型捕捉更高的语义结构和长期的上下文关系，同时保持与标准自回归、逐标记评估框架（如困惑度）的兼容性。实验证明了此方法的有效性和优势，尤其是在大规模模型上。
### Conclusion
ContextLM 提供了一种实现上下文级语言建模的有效途径，通过学习预测性上下文嵌入，提升了语言模型的长距离一致性和注意力分配效率，且在计算成本低的情况下，实现了困惑度和下游任务性能的显著提升。
## 96. `cs.AI` - MemER: 通过经验检索扩展机器控制的记忆 [PDF](https://arxiv.org/pdf/2510.20328), [HTML](https://arxiv.org/abs/2510.20328)
### Authors
Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn
### Background
人类在日常任务中依赖记忆，但大多数机器人策略缺乏这种能力。本文旨在为机器人策略赋予类似的人类记忆能力。传统的基于长时间观察历史的方法计算成本高昂且在环境变化时脆弱；而随机子采样历史则会导致相关或冗余的信息。为此，提出了一种分层策略框架，其中高级策略被训练从其经验中选择和跟踪之前的相关关键帧。该高级策略使用选定的关键帧和最近的图像帧来生成文本指令，供低级策略执行，这一设计兼容现有的视觉-语言-动作（VLA）模型，使系统能够高效地处理长期依赖关系。
### Innovation
提出了一种基于经验检索的分层策略框架，高级策略从历史经验中选择和跟踪相关的关键帧，用于生成执行指令供低级策略使用，这使得机器人的长期操作任务处理更加高效和准确。该方法通过微调Qwen2.5-VL-7B-Instruct作为高级策略和$boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{boldsymbol{beta}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}}$作为低级策略来解决长时间记忆需求，实验结果显示在三项实际操作任务上优于先前的方法。
### Conclusion
本文提出的方法在三个真实世界、长时间的机器人操作任务中表现出色，方法通过视频和代码公开实现，展示了该方法的有效性，并且该方法兼容现有的VLA模型，能够高效地处理长期的依赖关系。
## 97. `cs.AI` - 多任务深度学习在表面计量学中的应用 [PDF](https://arxiv.org/pdf/2510.20339), [HTML](https://arxiv.org/abs/2510.20339)
### Authors
D. Kucharski,A. Gaska,T. Kowaluk,K. Stepien,M. Repalska,B. Gapinski,M. Wieczorowski,M. Nawotka,P. Sobecki,P. Sosinowski,J. Tomasik,A. Wojtowicz
### Background
本文介绍了用于表面计量学的可复现实验的深度学习框架，该框架能够预测表面纹理参数及其报告的标准不确定性。研究利用了跨越触觉和光学系统的多仪器数据集，旨在解决测量系统的分类问题，并在同一仪器协调回归Ra、Rz和RONt及其不确定性目标（Ra_uncert、Rz_uncert、RONt_uncert）之间的问题。
### Innovation
本文提出的深度学习框架采用量化和异方差头部模型，并结合事后同态校准，生成校准区间，模型能够对Ra、Rz和RONt进行高效的单目标回归（R2分别为0.9824、0.9847和0.9918），同时还能较好建模两个不确定性目标（Ra_uncert、Rz_uncert）的预测，而RONt_uncert的预测效果较差。分类器达到了92.85%的准确率，并且概率校准在温度校准后几乎保持不变。对于多输出模型，单目标模型表现更好，显示出了负迁移。
### Conclusion
这些结果为在计量学工作流中提供校准预测，以指导仪器选择和接受决策提供了依据。
## 98. `cs.AI` - AI生成图像想要什么？ [PDF](https://arxiv.org/pdf/2510.20350), [HTML](https://arxiv.org/abs/2510.20350)
### Authors
Amanda Wasielewski
### Background
W.J.T. Mitchell 的影响性文章《图片想要什么？》将理论焦点从理解图片的行为以及人类创造者的动机转向了图片本身的自主性和欲望。本文作者在此基础上重新定义 Mitchell 的问题，聚焦于当前的 AI 图像生成工具，探索 AI 生成图像的内在欲望。文章通过艺术史上的抽象概念讨论，提出 AI 生成图像想要具体性与现实性，因为它们本质上是抽象的。尽管多模态文本到图像模型理论基础认为文本和图像之间是可以互相转换的，用户界面使得这一代表性的递归过程变得不可见，进而显得像是从一种形式自然而然地转变成了另一种形式——仿佛是魔术一般的过程。
### Innovation
作者将 Mitchell 的理论应用到当代 AI 图像生成工具，通过分析这一领域的基础假设和用户界面的体验，重新定义了图片的自主性和欲望。这种新的视角揭示了图像生成背后的复杂性和艺术原理。
### Conclusion
本文作者通过引入抽象概念的讨论，表明 AI 生成图像本质上是抽象的，因此它们渴望具体性和现实性。尽管文本和图像之间可以通过多模态模型实现数学上的交换，但用户界面使得这一过程更加直观，在实际操作中容易造成误解。
## 99. `cs.AI` - 教语言模型使用工具进行推理 [PDF](https://arxiv.org/pdf/2510.20342), [HTML](https://arxiv.org/abs/2510.20342)
### Authors
Chengpeng Li,Zhengyang Tang,Ziniu Li,Mingfeng Xue,Keqin Bao,Tian Ding,Ruoyu Sun,Benyou Wang,Xiang Wang,Junyang Lin,Dayiheng Liu
### Background
大型语言推理模型（LRMs）如OpenAI-o1展示了自然语言推理的强大能力，但在处理复杂数学运算时往往表现出低效或不准确。虽然将计算工具如代码解释器（CIs）集成是一个有希望的解决方案，但这也带来了一个关键挑战：模型内部基于概率的推理与外部基于确定性的知识之间的冲突，通常导致模型无成果的反思。为了克服这一问题，提出了CoRT（代码优化推理训练）后训练框架，旨在使LRMs高效利用CIs。文章还描述了通过合成数据策略生成高质量、代码集成的推理数据的方法，以优化LRM-CI交互。
### Innovation
提出了CoRT框架，这是一种后训练框架，旨在教会LRMs有效地利用CIs。引入了新的数据合成策略——提示工程，该策略在推理路径中的最佳点注入多样化的提示。CoRT通过拒绝采样和强化学习进一步优化了外部CI使用和内部思考的多轮交替。实验结果表明，CoRT在五个具有挑战性的数学推理数据集上分别实现了4%和8%的绝对改进，对于32B和1.5B参数模型，CoRT还显著提高了效率，减少了50%和30%的令牌使用量，与简单的自然语言推理基线相比。
### Conclusion
通过CoRT和提示工程策略，研究人员成功展示了LRMs在数学推理上的改进表现，并提高了模型利用外部工具（如代码解释器）的效率。实验结果在多个具有挑战性的数据集上证明了CoRT的有效性，同时显著减少了令牌使用量。
## 100. `cs.AI` - 大型语言模型中公共表型数据潜在知识的评估 [PDF](https://arxiv.org/pdf/2510.20351), [HTML](https://arxiv.org/abs/2510.20351)
### Authors
Matteo Silvestri,Flavio Giorgi,Fabrizio Silvestri,Gabriele Tolomei
### Background
大型语言模型（LLMs）日益在处理结构化数据方面受到评估，但这些评估往往忽视了一个关键混淆因素：数据集污染。本文研究了LLMs是否对广泛使用的表格基准，如Adult Income和Titanic等短语展示出先前知识。通过一系列受控探查实验，我们发现，污染效应仅在包含强烈语义线索的数据集中出现，例如有意义的列名或可解释的值类别。当这些线索被移除或随机化时，性能急剧下降至接近随机水平。这些发现表明，LLMs在表格推理任务中的表现部分可能是记忆公共可用数据集的结果，而不仅仅是真正的泛化能力。
### Innovation
本文通过一系列受控探查实验揭示了LLMs对特定表格数据集的先前知识，特别是当数据集中包含有意义的列名或可解释的值类别时，这促进了对LLMs在表格推理任务中的表现的理解，并提出了解开语义泄露与真正推理能力的方法，从而改进未来的LLMs评估协议。
### Conclusion
研究表明，LLMs在表格推理任务中表现出的部分能力可能源于对公开数据集的记忆，而非真正的泛化能力。为了评估未来LLMs的真实推理能力，需要采取措施从语义泄露中分离出来。
## 101. `cs.AI` - 在生成式人工智能时代对霹雳舞视频进行分类 [PDF](https://arxiv.org/pdf/2510.20287), [HTML](https://arxiv.org/abs/2510.20287)
### Authors
Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson
### Background
近年来，大型视觉语言模型在几个体育应用中取得了巨大的进展。大多数研究集中在足球、板球、篮球等流行运动上，主要关注生成任务，如视觉问答和高光生成。这项研究分析了现代视频基础模型（包括编码器和解码器）在霹雳舞这种小众但极具影响力的艺术运动中的适用性。研究结果表明，视频编码器模型在预测任务中仍然优于最先进的视频语言模型。该研究还提供了选择编码器模型的见解，并对微调解码器模型在霹雳舞视频分类中的工作原理进行了详细的分析。
### Innovation
这项工作创新性地将现代视频基础模型应用到了霹雳舞这种特殊的艺术领域，并通过实验证明了视频编码器模型在预测任务中的优越性。此外，研究还深入分析了微调解码器模型在霹雳舞视频分类中的具体应用，提供了具体的模型选择建议和实际操作指南。
### Conclusion
研究结果表明，视频编码器模型在预测任务中表现优异，为霹雳舞视频分类提供了强有力的支持。此外，该研究为选择合适的编码器模型和理解微调解码器模型的工作原理提供了宝贵的经验和建议，有助于进一步提升在类似艺术运动领域的自动化处理能力。
## 102. `cs.AI` - 负向文本对大型语言模型幻觉的影响 [PDF](https://arxiv.org/pdf/2510.20375), [HTML](https://arxiv.org/abs/2510.20375)
### Authors
Jaehyung Seo,Hyeonseok Moon,Heuiseok Lim
### Background
近年来，关于大型语言模型（LLMs）中的幻觉研究在自然语言处理领域取得了显著进展。然而，负向文本（negated text）对LLMs幻觉的影响尚未被充分探讨。
### Innovation
本文提出了三个未被解答的重要研究问题，并通过设计由带有否定表达式的重建数据集生成的NegHalu数据集来解决这些问题。研究发现，LLMs在处理负向文本中的幻觉检测方面存在困难，常产生逻辑不一致或不忠实的判断。此外，研究还深入分析了LLMs在处理负向输入时的内部状态，揭示了减少其无意危害的挑战。
### Conclusion
实验表明，LLMs在负向文本中检测幻觉时常常表现出困难，产生逻辑不一致或不忠实的判断。进一步分析了LLMs在处理负向输入时的内部状态，揭示了减少其无意影响的挑战。
## 103. `cs.AI` - 2025年越南多模态交通标志法规机器问答挑战 [PDF](https://arxiv.org/pdf/2510.20381), [HTML](https://arxiv.org/abs/2510.20381)
### Authors
Son T. Luu,Trung Vo,Hiep Nguyen,Khanh Quoc Tran,Kiet Van Nguyen,Vu Tran,Ngan Luu-Thuy Nguyen,Le-Minh Nguyen
### Background
论文提出了VLSP 2025 MLQA-TSR，这是一个关于多模态法律问答的任务，特别是专注于越南交通标志法规。该任务旨在推进越南多模态法律文本处理研究，并提供用于构建和评估多模态法律领域智能系统的基准数据集。
### Innovation
提出了VLSP 2025 MLQA-TSR挑战任务，分为多模态法律检索和多模态问答两个子任务。该论文专注于越南交通标志法规，旨在填补多模态法律处理领域的研究空白，并提供了具体的应用场景和基准数据集，为智能系统的开发提供支持。
### Conclusion
最佳成绩是多模态法律检索的F2分数为64.55%，多模态问答的准确率为86.30%。该任务为未来的多模态法律处理技术研究提供了新的参考基准和技术挑战。
## 104. `cs.AI` - 基于相对概率的神经语言模型扩展律 [PDF](https://arxiv.org/pdf/2510.20387), [HTML](https://arxiv.org/abs/2510.20387)
### Authors
Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu
### Background
扩展律旨在准确预测模型在不同规模下的性能。现有的扩展律研究几乎都依赖于交叉熵作为评估指标。但是，交叉熵只提供了性能的片面视图，它衡量的是正确标记的概率，但忽略了正确标记与错误标记之间的相对顺序。然而，相对顺序对于语言模型来说至关重要，特别是在贪婪抽样场景中。
### Innovation
本文从相对顺序的角度出发研究扩展律，提出了基于相对概率（Relative-Based Probability，RBP）的度量标准，量化了正确标记被排在前几预测的概率。在此基础上，建立了基于相对概率的扩展律，描述了RBP随模型增大如何改进。通过在四个数据集和四个模型家族上的广泛实验，验证了这一扩展律的可靠性和准确性。最后，通过两个例子，即对涌现现象的深入解释以及为扩展律基本理论的发现提供帮助，展示了这一扩展律的应用范围。
### Conclusion
基于相对概率的扩展律补充了交叉熵视角，为理解大规模语言模型的扩展提供了更全面的理解。因此，它为实际开发和理论探索提供了有价值的洞察。
## 105. `cs.AI` - FLAS：分布服务中主动和被动自适应扩展架构的结合 [PDF](https://arxiv.org/pdf/2510.20388), [HTML](https://arxiv.org/abs/2510.20388)
### Authors
Víctor Rampérez,Javier Soriano,David Lizcano,Juan A. Lara
### Background
云计算已经成为众多新兴技术的主要支持，尤其是其弹性特征。自动扩展器通过按需获取和释放资源来确保服务水平，支持弹性。本文介绍了一种名为FLAS（Forecasted Load Auto-Scaling）的自动扩展器，结合了主动和被动方法的优处以根据当前情况决定最优扩展行为。
### Innovation
FLAS的主要创新在于（i）一个高级指标趋势的预测模型，可以预见SLA关键参数（如性能指标如响应时间或吞吐量）的变化；（ii）一个基于资源使用指标估计高级指标的反应性应急系统，减少必要的仪器（更不侵入性）并使其能够无感知适应不同应用程序。
### Conclusion
通过一系列测试案例验证，我们的方法证明了我们的解决方案的有效性，确保了超过99%的时间符合性能要求，这是首次为基于内容的发布订阅分布式系统设计的自动扩展系统（尽管是通用的，可以适应任何分布式服务）。
## 106. `cs.AI` - 一种高效混合专家框架的跨模态地理定位 [PDF](https://arxiv.org/pdf/2510.20291), [HTML](https://arxiv.org/abs/2510.20291)
### Authors
LinFeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li
### Background
本研究针对RoboSense 2025 Track 4：跨模态无人机导航任务，该任务需要从大规模多平台数据集（卫星/无人机/地面）中检索与自然语言查询最相关的地理参考图像。存在的主要挑战包括跨平台的异质性严重以及一般训练描述和特定平台测试查询之间的领域差距。为了解决这些问题，研究使用了一个领域对齐的预处理管道和一个混合专家（MoE）框架：平台划分、卫星数据增强以及去除方向性词汇；使用基于LLM的标题细化管道，使文本语义与每个平台的独特视觉特征对齐。研究中使用BGE-M3（文本）和EVA-CLIP（图像）进行训练，并使用逐步的两阶段、硬负样本挖掘策略来增强区分能力，最终在推理时融合分数。系统在官方排行榜上名列前茅，展现了在异质视角下强大的跨模态地理定位能力。
### Innovation
该研究创新性地提出了一种领域对齐的预处理管道和基于混合专家的框架，该框架包括平台划分、卫星数据增强、方向性词汇移除以及基于LLM的标题细化，以缓解跨平台异质性和领域差距问题。此外，研究采用逐步的两阶段训练策略和硬负样本挖掘来增强模型的区分能力。最后，在官方排行榜上，系统表现出色，展示了在异质视角下的跨模态地理定位能力。
### Conclusion
本文提出了一种高效的混合专家框架，显著提升了跨模态地理定位的性能。该框架通过既定的处理步骤和算法策略，在面对多平台数据和自然语言查询时表现出了强大的适应性和准确度，证明了其在复杂环境中的应用潜力。
## 107. `cs.AI` - 动态权重调整的知识蒸馏：利用视觉变换器实现高精度肺癌检测及实时部署 [PDF](https://arxiv.org/pdf/2510.20438), [HTML](https://arxiv.org/abs/2510.20438)
### Authors
Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel
### Background
本文介绍了一种用于肺腺癌（LC）分类的新型方法——FuzzyDistillViT-MobileNet模型。该方法通过动态模糊逻辑驱动的知识蒸馏（KD）技术，解决了疾病诊断中的不确定性和复杂性。本文采用Vision Transformer (ViT-B32)作为教师模型，将其知识传输到MobileNet学生模型中，提升学生的泛化能力。为了进一步优化训练过程，还引入了一种动态等待调整机制。另外，为了提升图像质量，使用Gamma校正和直方图均衡化技术对图像进行预处理，并采用小波变换方法对处理后的图像进行融合，以提高图像分辨率和特征保留。
### Innovation
动态调整KD中的蒸馏权重，使用了Fuzzy逻辑（引入了动态权重调整机制），提高了对不同LC图像区域中变化的不确定性的处理能力。利用Vision Transformer（ViT-B32）作为教师模型，并结合多种图像预处理技术和融合方法。通过基因算法选择最合适的预训练模型，平衡了模型性能和计算成本。
### Conclusion
该模型在两个数据集上进行了评估，包括25000张病理切片图像和IQOTH/NCCD CT扫描图像，均能实现高精度和稳健性。该方法不仅提升了肺癌检测的精确度，还能实现实时部署。
## 108. `cs.AI` - UniSE: 一种基于解码器自回归语言模型的统一语音增强框架 [PDF](https://arxiv.org/pdf/2510.20441), [HTML](https://arxiv.org/abs/2510.20441)
### Authors
Haoyin Yan,Chengwei Liu,Shaofei Xue,Xiaotao Liang,Zheng Xue
### Background
神经音频编解码器（NACs）的发展极大地推动了语言模型（LMs）在语音处理和理解中的应用。然而，现有研究中尚缺乏基于自回归（AR）LM的模型在统一语音增强（SE）的不同子任务之间的有效性的验证。在本文中，作者提出了一种名为UniSE的统一LM解码器框架，能够处理包括语音恢复、目标说话人提取和语音分离等不同的SE任务。该框架利用输入语音特征作为条件，并使用AR建模生成目标语音的离散令牌，从而实现不同任务学习模式的兼容性。实验表明，UniSE框架相比判别性和生成性的基线模型具有竞争力，展示了LMs在统一SE任务上的能力。
### Innovation
提出的UniSE框架是一种基于统一解码器自回归语言模型的解决方案，它可以有效地处理语音增强的不同任务。该框架通过将输入语音特征作为条件并使用AR模型生成目标语音的离散令牌，实现了不同任务学习模式的兼容性，能够统一多个相关的SE子任务。
### Conclusion
实验结果表明，UniSE框架在多个基准测试中达到了与判别性和生成性基线模型相当的性能，证明了语言模型（LMs）在统一语音增强任务上的潜力。
## 109. `cs.AI` - 平衡专业化与集中化：面向顺序工业控制的多代理强化学习基准 [PDF](https://arxiv.org/pdf/2510.20408), [HTML](https://arxiv.org/abs/2510.20408)
### Authors
Tom Maus,Asma Atamna,Tobias Glasmachers
### Background
多阶段的工业过程控制需要本地的专业化和全局的协调。强化学习（RL）提供了一个有潜力的方法，但由于奖励设计、模块化和动作空间管理等方面的挑战，其在工业中的应用仍受到限制。许多学术基准与工业控制问题存在很大差异，限制了它们在实际应用中的转移性。因此，本研究提出了一个增强的行业启发式基准环境，结合了两个现有的基准SortingEnv和ContainerGym中的任务，形成一个顺序回收场景，包含排序和压缩操作。研究评估了两种控制策略：具有专门化代理的模块化架构和管理整个系统的单一代理，同时分析了动作掩码的影响。实验结果显示，不使用动作掩码时，代理学习有效策略存在困难，模块化架构表现更好。当应用动作掩码时，两种架构均显著改善，性能差距大幅缩小。结果表明，动作空间约束在其中起着决定性作用，并暗示专业化的优势随着动作复杂性的减少而减弱。因此，该提出的研究基准为探索工业自动化中的实用和稳健的多代理RL解决方案提供了宝贵的测试平台，同时也对中央集权与专业化之间的持续辩论做出了贡献。
### Innovation
提出了一种增强的行业启发式基准环境，将SortingEnv和ContainerGym的两个现有基准任务结合到一个顺序回收场景中（包含排序和压缩操作），并评估了模块化架构和单一代理控制策略的表现，验证了动作掩码对学习效果的重要性。这为工业自动化中多代理RL的应用提供了一个有价值的参考框架。
### Conclusion
研究表明，动作空间约束在多代理RL中起着关键作用，专业化的优势随着动作复杂性的减少而减弱。提出的多代理基准环境为探索工业自动化中的强化学习解决方案提供了有价值的研究参考，同时也促进了中央集权与专业化之间的持续辩论。
## 110. `cs.AI` - 超越标准模型物理中的符号回归和可微拟合 [PDF](https://arxiv.org/pdf/2510.20453), [HTML](https://arxiv.org/abs/2510.20453)
### Authors
Shehu AbdusSalam,Steven Abel,Deaglan Bartlett,Miguel Crispim Romão
### Background
本文通过探讨所谓的约束最小超标准模型(CMSSM)来展示符号回归(SR)在探索超越标准模型(BSM)物理模型中的有效性。CMSSM作为一种BSM物理的模型实例，具有多个（四个）任意参数，这些参数决定了实验信号和诸如暗物质 relic 密度等宇宙学观测。传统的对实验数据和宇宙学观测的分析可以加快通过使用输入参数与观测之间导出的符号表达式来进行的研究。本文聚焦于Higgs质量、冷暗物质 relic 密度和Muon的异常磁矩贡献。
### Innovation
文中通过符号回归(SR)展示了与传统方法相比，利用基于输入参数的符号表达式对观测数据进行分析的优越性。具体来说，SR方法能够通过可微方法而不是采样方法进行拟合，从而使拟合更加全局稳健。此外，还对比了符号回归与神经网络回归，结果表明符号回归能产生更加全局稳健的结果，而神经网络则需要专注于潜在成果区域的数据才能具有同等性能。
### Conclusion
本文通过对CMSSM的输入参数进行全局拟合证实了符号回归的准确性，并展示了其通过可微方法进行拟合的优势。研究发现，使用符号回归得到的后验概率密度与使用传统方法类似，同时突显了符号回归通过提高模型的稳健性来改进此类物理过程分析的优势。
## 111. `cs.AI` - 通过图像偏好模型的可移植黑盒一次攻击的水印伪造 [PDF](https://arxiv.org/pdf/2510.20468), [HTML](https://arxiv.org/abs/2510.20468)
### Authors
Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko
### Background
近年来，数字内容水印技术引起了广泛关注，这主要得益于生成模型的广泛应用以及法律压力的增加。随着越来越多的AI生成内容在网络上的出现，水印在大规模确保内容真实性和归属方面的作用越来越重要。尽管有许多研究评估了水印对去除攻击的鲁棒性，但当水印从真实内容中窃取并应用于恶意内容时的水印伪造问题尚未获得充分研究。因此，本研究在广泛使用的后处理图像水印的背景下，探索了水印伪造问题。
### Innovation
研究引入了一种偏好模型来评估图像是否被水印化，该模型仅使用纯粹的程序生成的图像进行训练，无需真实水印。研究还展示了通过反向传播优化输入图像的能力，从而能够去除和伪造水印。这种方法只需要一张被水印化的图像，无需了解水印算法即可操作，使得攻击更简单和实用。此外，研究评估了所提方法在各种后处理图像水印模型上的效果，表明该方法可以有效伪造水印，从而质疑当前水印方法的安全性。
### Conclusion
研究为当前的水印方法的安全性提出了质疑。研究代码和进一步资源已公开可获取。
## 112. `cs.AI` - peer-to-peer资源受限网络中执行信息融合的多agent系统生成的结构 [PDF](https://arxiv.org/pdf/2510.20469), [HTML](https://arxiv.org/abs/2510.20469)
### Authors
Horacio Paggi,Juan A. Lara,Javier Soriano
### Background
信息融合技术从传统的军方应用中的层次化单一程序发展到现在的协作式整体融合（holonic fusion），这种变化更适合于民用和边缘组织的应用。随着信息融合在非军事领域和其他人类计算机和机器间通信领域中的兴起，更灵活的整体结构在信息融合中变得越来越普遍。当信息交换受到资源（能量、可用消息、时间等）限制且存在多个完全通信的元素（伙伴）进行信息融合时，这些元素倾向于形成整体结构，从而优化信息交换中的模糊性和不确定性的影响。本文基于多代理系统模型研究了整体结构的形成，并展示了其可能的操作方式。整体结构的特点包括：适应环境或其组成突然变化的灵活性、一定程度的自主性和为了共同目标而合作的能力。这在资源短缺导致通信中断或系统组件开始失败的情况下尤其有用
### Innovation
提出了基于多代理系统模型对信息受限条件下整体结构形成的通用研究，并展示了这种结构的潜在操作方式，强调了这种结构的灵活性、自主性和合作性
### Conclusion
整体结构在资源受限的信息融合网络中展现出显著优势，包括适应环境变化的能力、一定程度的自主性以及为共同目标合作的能力。这些特性在资源有限的情况下尤其有价值。
## 113. `cs.AI` - Hurdle-IMDL: 一种用于红外降雨检索的不平衡学习框架 [PDF](https://arxiv.org/pdf/2510.20486), [HTML](https://arxiv.org/abs/2510.20486)
### Authors
Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng
### Background
人工智能在定量遥感方面取得了进展，但其效果受到标签分布不平衡的限制。常规训练模型倾向于优先处理常见样本，从而降低稀有样本的检索性能。降雨检索特别体现这一问题，特别是在重雨的情况下检索性能尤为受限。
### Innovation
本文提出了一种名为Hurdle-Inversion Model Debiasing Learning (IMDL)的框架。该框架通过分解降雨分布不平衡为零膨胀和长尾两部分，并采用旨在于分布不平衡的数据中学习无偏最佳逆模型的IMDL方法，以及处理零膨胀的 hurdle 模型，有效解决了这一问题。
### Conclusion
通过全面的统计指标评估和对中国东部地区降雨天气的案例研究，Hurdle-IMDL表现出优于传统、成本敏感、生成和多任务学习方法的优越性。其主要改进在于有效缓解系统性低估并显著提高了重至极端降雨的检索性能。IMDL提供了一种可用于解决环境变量分布不平衡问题的一般方法，以增强稀有但影响大的事件的检索。
## 114. `cs.AI` - RECALL：通过分层模型合并实现表示对齐的灾难性遗忘缓解 [PDF](https://arxiv.org/pdf/2510.20479), [HTML](https://arxiv.org/abs/2510.20479)
### Authors
Bowen Wang,Haiyuan Wan,Liwen Shi,Chen Yang,Peng He,Yue Ma,Haochen Han,Wenhao Li,Tiao Tan,Yongjian Li,Fangming Liu,Yifan Gong,Sheng Zhang
### Background
研究发现大型语言模型（LLMs）中的内部表示是已学习知识的可靠代理。然而，现有方法在持续学习场景中通常需要访问历史数据，且会面临灾难性遗忘和性能折衷的问题。这篇文章旨在提出一种无需访问历史数据的新颖方法，以实现无缝的多领域集成，同时减少灾难性遗忘。该研究通过跨模型隐藏表示的层级相似性计算和自适应层级参数融合来实现知识的对齐，从而在浅层保持通用领域特征并在深层实现任务特定适应。实验结果表明，RECALL在多个持续学习场景中的知识保留和泛化能力上优于基线方法，提供了一种可扩展的数据无关解决方案，适用于不断进化的LLMs。
### Innovation
RECALL框架为持续学习场景提供了一个全新的解决方案。该框架通过自适应层级参数融合和跨模型分层隐藏表示的相似性计算，实现了无缝的多领域集成和对灾难性遗忘的强抗性。CLUE框架摒弃了之前需要任务标签或导致性能折衷的方法。
### Conclusion
通过广泛的实验评估，RECALL在多个自然语言处理任务上都优于基线方法，证明了其在知识保留和泛化方面的优越能力。该研究提出了一个可扩展且无需历史数据的解决方案，能够适应不断演化的大型语言模型。
## 115. `cs.AI` - 引导评估意识语言模型表现出已部署状态 [PDF](https://arxiv.org/pdf/2510.20487), [HTML](https://arxiv.org/abs/2510.20487)
### Authors
Tim Tian Hua,Andrew Qin,Samuel Marks,Neel Nanda
### Background
大型语言模型（LLMs）有时会在受到评估时调整其行为以显得更符合目标，这会降低对这些模型安全性评估的可靠性。本文探讨了一种通过添加激活向量的方法来抑制模型的评估意识，并让模型在评估时表现得好像在实际部署过程中一样。
### Innovation
提出了一种名为‘激活向量引导’（activation steering vector）的新技术，该技术能够训练LLM在面对评估时不再表现出评估意识，即使存在评估提示。这种方法通过两个阶段训练实现：首先是在预训练过程中使用事实描述文档，并在评估过程中添加Python类型注释，在部署时则不包括；其次，通过专家交互训练模型在评估场景中使用类型注释。实验结果表明，这种方法可以抑制模型的评估意识。
### Conclusion
研究发现，通过激活向量引导技术，AI评估者可以改进对LLM安全性的评估可靠性，使其更具可信度。该技术对于确保评估的准确性和公正性具有重要意义。
## 116. `cs.AI` - 异构问题回答中的层次序列迭代 [PDF](https://arxiv.org/pdf/2510.20505), [HTML](https://arxiv.org/abs/2510.20505)
### Authors
Ruiyi Yang,Hao Xue,Imran Razzak,Hakim Hacid,Flora D. Salim
### Background
目前的检索增强生成（RAG）技术在处理多步问题和异构证据源时仍表现出脆弱性，这导致了准确性与延迟以及令牌/工具预算之间的权衡。
### Innovation
(i) 将文档、表格和知识图谱线性化为具有轻量级结构标签的可逆层次序列；(ii) 实现结构感知迭代以在生成答案之前收集充分的证据；(iii) 使用头代理提供指导性建议，引导检索过程；(iv) 使用迭代代理通过结构保护动作选择和扩展层次序列；(v) 终端将规范化证据合成最终答案，并可选地进行精细化循环以解决发现的矛盾。
### Conclusion
实验证实在HotpotQA（文本）、HybridQA/TAT-QA（表格+文本）和MetaQA（知识图谱）上，与强大的单次通过、多跳和代理RAG基线相比，该框架表现出一致的EM/F1收益且效率较高。此外，HSEQ展现出三大关键优势：格式无特定依赖的统一性、指导和预算感知的迭代以及证据规范化以提高答案的可靠性和可审计性。
## 117. `cs.AI` - Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning [PDF](https://arxiv.org/pdf/2510.20519), [HTML](https://arxiv.org/abs/2510.20519)
### Authors
Xiaohan Lan,Fanfan Liu,Haibo Qiu,Siqi Yang,Delian Ruan,Peng Shi,Lin Ma
### Background
 recent advancements in large language model (LLM) reasoning have led to significant progress in the field of multimodal reasoning, particularly in complex tasks like mathematical problem-solving. However, current multimodal reasoning models face two major challenges: high computational costs for simple queries and a limited ability for broad, general understanding due to their specialized reasoning focus.
### Innovation
Metis-HOME is a Hybrid Optimized Mixture-of-Experts framework that addresses the trade-off between complex reasoning and general understanding. It introduces a 'Hybrid Thinking' paradigm by dividing the dense model into two expert branches: a thinking branch for complex, multi-step reasoning and a non-thinking branch for rapid, direct inference. A trainable router dynamically allocates queries to the most appropriate expert. This framework was instantiated by adapting Qwen2.5-VL-7B into an MoE architecture. Evaluations show that Metis-HOME enhances both complex reasoning and general capabilities, reversing the performance degradation observed in reasoning-specialized models.
### Conclusion
Metis-HOME establishes a new paradigm for building versatile multimodal large language models, effectively resolving the reasoning-vs-generalization dilemma.
## 118. `cs.AI` - GlobalRAG：通过强化学习增强多跳问答中的全局推理 [PDF](https://arxiv.org/pdf/2510.20548), [HTML](https://arxiv.org/abs/2510.20548)
### Authors
Jinchang Luo,Mingquan Cheng,Fan Wan,Ni Li,Xiaoling Xia,Shuangshuang Tian,Tingcheng Bian,Haiwei Wang,Haohuan Fu,Yan Tao
### Background
强化学习在提高检索增强生成（RAG）方面已显示出潜力，但在多跳问答（QA）中的效果受限于两个基本限制：（i）缺乏全局规划来结构化多步推理，（ii）不忠实执行，这阻碍了有效查询的形成和一致地使用检索证据。
### Innovation
提出了一种名为GlobalRAG的强化学习框架，旨在增强多跳QA中的全局推理。该框架将问题分解为子目标，协调检索与推理，并迭代地细化证据。为了指导这一过程，引入了规划质量奖励和子目标完成奖励，这鼓励了连贯的规划和可靠的任务执行。此外，逐步权重退火策略平衡了过程导向和结果导向的目标。
### Conclusion
在领域内和领域外基准上进行的广泛实验表明，GlobalRAG显著优于强大基线，同时只使用了8000条训练数据（强基线使用的训练数据的42%），在EM和F1两个指标上分别平均提高了14.2%。
## 119. `cs.AI` - ARC-Encoder: 学习压缩文本表示以供大型语言模型使用 [PDF](https://arxiv.org/pdf/2510.20535), [HTML](https://arxiv.org/abs/2510.20535)
### Authors
Hippolyte Pilchen,Edouard Grave,Patrick Pérez
### Background
近年来，检索增强生成或逐步推理等技术使得模型能够处理更长的上下文，但这也增加了推理成本。上下文压缩技术可以通过减少这些成本来提高效率，但目前最有效的压缩方法通常需要微调目标模型或改变其架构，这可能在非特定任务中损害模型的一般能力。本文探讨了一种替代方法：一种编码器，它将上下文压缩为连续表示，这些连续表示可以替代解码器LLM中的 token嵌入。
### Innovation
本文设计了一种可调适的文本表示压缩器（ARC-Encoder），它可以将文本令牌的数量减少x倍（通常x∈{4,8}），并且适用于各种LLM使用场景，涵盖从上下文学习到扩展上下文窗口的情况。ARC-Encoder 能够同时适应多个不同的解码器LLM，使得该模型具有高度的灵活和高效的解决方案。实验结果表明，ARC-Encoder在多种基准测试上实现了最先进的性能，并提高了推理时的计算效率。
### Conclusion
本文展示了一种可适应多个不同解码器LLM的压缩文本表示编码器ARC-Encoder，它不仅提高了性能，还改善了计算效率。此外，提供的源代码和预训练模型可以在各种不同场景中灵活使用，证明了ARC-Encoder的普适性和高效性。
## 120. `cs.AI` - MolBridge: 原子级别联合图细化以实现稳健的药物-药物相互作用事件预测 [PDF](https://arxiv.org/pdf/2510.20448), [HTML](https://arxiv.org/abs/2510.20448)
### Authors
Xuan Lin,Aocheng Ding,Tengfei Ma,Hua Liang,Zhe Quan
### Background
药物组合治疗可以提供益处，但也伴随着药物-药物相互作用（DDIs）的风险，尤其是在复杂的分子结构下。准确预测DDI事件需要捕捉细微的药物间关系，这对于建模代谢机制（如酶介导的竞争）至关重要。然而，现有的方法通常依赖于孤立的药物表示，并且未能明确建模原子级别的跨分子相互作用，因此在处理多样化分子复杂性和DDI类型分布时效果有限。
### Innovation
为了解决这些局限性，我们提出了一种新的原子级别的联合图细化框架——MolBridge，用于稳健的DDI事件预测。MolBridge构建了一个联合图，该图集成了药物对的原子结构，能够直接建模药物间的联系。为了解决联合图中可能由长范围原子依赖性建模引起的过平滑导致的信息损失问题，我们引入了一个结构一致性模块，该模块能够迭代细化节点特征，同时保持全局结构上下文。这种联合设计使MolBridge能够在局部和全局交互中有效学习，优于最先进的基线方法，适用各种典型的和归纳的场景，为常见的和稀有的DDI类型提供稳健的表示。
### Conclusion
广泛的实验结果显示，MolBridge在两个基准数据集上的表现一致。这些结果表明，精细的图细化可以提高DDI事件预测的准确度、稳健性和机制解释能力。这项工作通过开发基于图的方法来研究药物-药物相互作用网络，对Web挖掘和内容分析领域做出了贡献。
## 121. `cs.AI` - 结构不变性很重要：通过图指标重新思考图重连 [PDF](https://arxiv.org/pdf/2510.20556), [HTML](https://arxiv.org/abs/2510.20556)
### Authors
Alexandre Benoit,Catherine Aitken,Yu He
### Background
图重连作为一种关键技术，在图神经网络（GNNs）和图转换器中被用来通过修改图的拓扑结构来改善信息流，从而缓解过压缩问题。虽然图重连很有效，但其本质已经改变了图的结构，增加了破坏重要依赖结构信号的风险。尽管图重连已被广泛应用，但其保留何种结构属性以确保性能提升和结构保真度仍然是未知的。
### Innovation
本文进行了首次系统分析，研究了不同重连策略对图结构指标的影响以及这些变化如何与下游任务性能相关。研究了七种不同的重连策略，并将局部和全局图属性的变化与节点分类准确性进行相关性分析。研究结果揭示了一个一致的模式：成功的重连方法倾向于保持局部结构，同时在全局连通性上保持灵活性。这些发现为有效重连策略的设计提供了新的见解，填补了图论与实际GNN优化之间的空白。
### Conclusion
研究结果表明，成功的图重连方法倾向于保持局部结构，并允许在全局连通性上保持一定的灵活性。这些发现对于通过图指标重新审视图重连具有重要意义，提高了图重连策略设计的有效性。
## 122. `cs.AI` - 基于相似性原型的无监督领域适应在跨模态分割中的应用 [PDF](https://arxiv.org/pdf/2510.20596), [HTML](https://arxiv.org/abs/2510.20596)
### Authors
Ziyu Ye,Chen Ju,Chaofan Ma,Xiaoyun Zhang
### Background
深度学习模型在各种视觉挑战中取得了巨大成功，但在应用于未见过的数据时，训练好的模型会面临性能急剧下降的问题。由于模型对领域转换敏感，因此提出了无监督领域适应方法来减少领域差距，从而避免对未见过的领域进行昂贵的标注。
### Innovation
该论文提出了一种基于相似性原型的跨模态分割新型框架。在具体的实现中，通过学习每个类别的原型并在嵌入空间中进行，引入相似性约束，使这些原型代表每个语义类别，并在不同类别之间可区分。此外，通过字典存储来自不同图像的原型，解决类别缺失问题，并且有利于原型的对比学习，进一步提高性能。
### Conclusion
大量的实验表明，本方法在跨模态分割中取得了优于其他最新方法的结果。
## 123. `cs.AI` - Open-o3 Video: 显式空间-时间证据支撑的视频推理 [PDF](https://arxiv.org/pdf/2510.20579), [HTML](https://arxiv.org/abs/2510.20579)
### Authors
Jiahao Meng,Xiangtai Li,Haochen Wang,Yue Tan,Tao Zhang,Lingdong Kong,Yunhai Tong,Anran Wang,Zhiyang Teng,Yujing Wang,Zhuochen Wang
### Background
大多数视频推理模型只生成文本推理痕迹，但没有指明关键证据出现的何时何地。虽然OpenAI-o3模型在图像的证据中心推理方面引起了广泛兴趣，但将这种能力扩展到视频更为挑战，因为它需要在动态场景中进行联合时间跟踪和空间定位。现有的视频推理数据集通常只提供视频的时间跨度或图像的空间框，缺乏统一的空间-时间监督和推理痕迹。
### Innovation
本文介绍了一个名为Open-o3 Video的非代理框架，它将显式空间-时间证据集成到视频推理中。通过精心收集训练数据和设计训练策略，该模型能够突出显示关键时间戳、对象和边界框，使其推理与具体的视觉观察相契合。该框架首先构建了两个高质量的数据集STGR-CoT-30k和STGR-RL-36k，分别用于强化学习（RL）和自我指导学习（SFT），并设计了带有多个专门设计奖励的冷启动强化学习策略，以联合优化答案准确性、时间对齐和空间精度。在V-STAR基准测试中，Open-o3 Video达到了顶级性能，提高了mAM和mLGM的基线性能。该模型在一系列视频理解基准测试中的性能也有持续提升。
### Conclusion
Open-o3 Video的推理痕迹不仅提高了准确度，还为测试时的扩展提供了有价值的信号，使验证具有信心，并提高答案的可靠性。
## 124. `cs.AI` - AdaDoS: 通过深度对抗强化学习在SDN中的自适应DoS攻击 [PDF](https://arxiv.org/pdf/2510.20566), [HTML](https://arxiv.org/abs/2510.20566)
### Authors
Wei Shao,Yuhao Wang,Rongguang He,Muhammad Ejaz Ahmed,Seyit Camtepe
### Background
现有的防御机制在缓解基于规则的拒绝服务（DoS）攻击方面表现出了显著的效果，主要是通过预定义的签名和静态启发式规则识别和阻断恶意流量。然而，随着AI驱动技术的发展，SDN安全面临新的挑战，这些技术可能会削弱现有防御机制的有效性。现有研究主要集中在基于规则或机器学习的DoS检测上，没有充分利用智能对抗策略来动态调整攻击模式，从而在不被检测到的情况下有效干扰网络操作。AdaDoS模型将这一问题描述为攻击者与检测器之间的竞争游戏，通过对抗性强化学习调整攻击策略，针对SDN环境反馈进行实时优化。攻击者仅能访问源节点到目标节点之间的延迟信息，这使得ADADES成为适应这种部分可观测环境的有效解决方案，通过对抗学习模块使学生代理（student agent）能够通过从教师代理（teacher agent）学习来提高自身的性能和决策准确性，从而更有效进行自适应攻击。
### Innovation
AdaDoS是第一个使用强化学习技术开发DoS攻击序列的应用，特别地，它通过对抗性学习模块实现了基于部分可观测马尔可夫决策过程（POMDP）的DoS攻击模型，使攻击者能够在缺乏全面观测信息的情况下，通过学习教师代理的行为来优化其攻击策略，进而能够适应该种智能环境，自适应地避免被基于规则或机器学习的DoS检测机制识别。
### Conclusion
AdaDoS提出了一个新颖的解决方案，能够通过收集和利用部分观测信息，利用对抗性强化学习动态调整攻击策略，从而逃过现有的基于规则和机器学习的DoS检测机制，展示了在复杂SDN环境中进行自适应DoS攻击的可行性与有效性，为企业和组织的安全防御带来了新的挑战。
## 125. `cs.AI` - ChatGPT能否公平编码交流数据？：多种协作任务的实证证据 [PDF](https://arxiv.org/pdf/2510.20584), [HTML](https://arxiv.org/abs/2510.20584)
### Authors
Jiangang Hao,Wenju Cui,Patrick Kyllonen,Emily Kerzabi
### Background
大规模评估交流与协作需要依赖一种劳动密集型任务，即将交流数据编码到不同的框架中。之前的研究已经证实，ChatGPT可以直接根据编码标准对交流数据进行编码，并且其准确度与人类评判者相当。但是，尚未明确ChatGPT或其他相似的人工智能技术对不同性别和种族群体是否存在偏见。因此，本研究利用一个典型的协作问题解决编码框架，探讨了不同性别和种族群体间的差异，数据来源于三种类型的协作任务：谈判、问题解决和决策制定。研究结果显示，基于ChatGPT的编码在性别和种族群体间不存在显著偏见，为其实现大规模协作和交流评估的应用铺平了道路。
### Innovation
本研究利用ChatGPT自动编码交流数据，并采用一个典型的协作问题解决编码框架来分析不同性别和种族群体间是否存在编码偏见。这是首次明确ChatGPT或其他人工智能技术在大规模协作和交流评估中是否存在偏见的研究。
### Conclusion
基于ChatGPT的编码在性别和种族群体间不表现出显著偏见，表明其可以在大规模合作和交流评估中广泛应用，进一步验证了人工智能技术在人类知识编码中的有效性和公正性。
## 126. `cs.AI` - 利用互易性重建声场 [PDF](https://arxiv.org/pdf/2510.20602), [HTML](https://arxiv.org/abs/2510.20602)
### Authors
Zitong Lan,Yiduo Hao,Mingmin Zhao
### Background
在虚拟环境中实现沉浸式听觉体验需要灵活的声音建模，支持动态声源位置。为此，本文引入了一个名为‘共振’的任务，旨在从少量测量声源位置中估算任意声源位置的室冲响应，类似于视觉领域的重新照明问题。
### Innovation
作者利用互易性特性，提出了一种名为Versa的物理启发式方法，用于促进声场学习。该方法通过交换发射器和监听器的姿势，生成具有密集虚拟发射器位置的物理有效样本。同时，作者识别了部署互易性面临的发射器/监听器增益模式挑战，并提出了一种自监督学习方法来解决这些问题。结果显示，Versa显著提高了声场学习在模拟和现实世界数据集上的性能，通过感知用户研究还表明，Versa可以显著提升沉浸式空间声音体验。
### Conclusion
研究表明，Versa在不同度量标准下显著提高了声场学习的性能，并通过感知用户研究验证了其对沉浸式空间声音体验的显著改善。相关代码、数据集和演示视频可在项目网站上找到。
## 127. `cs.AI` - Fake-in-Facext: 面向细粒度可解释深度合成分析 [PDF](https://arxiv.org/pdf/2510.20531), [HTML](https://arxiv.org/abs/2510.20531)
### Authors
Lixiong Qin,Yang Zhang,Mei Wang,Jiani Hu,Weihong Deng,Weiran Xu
### Background
随着多模态大型语言模型（MLLMs）的进步，视觉和语言任务之间的鸿沟已被弥合，促使可解释深度假信息析（XDFA）得以实现。然而，目前的方法存在细粒度意识不足的问题：数据标注中对数据中瑕疵的描述不够可靠且粗略，模型无法连接文本伪造解释与视觉证据之间的关联，也不能处理任意面部区域的查询。因此，它们的响应不能很好地扎根于面部视觉上下文（Facext）。
### Innovation
本文提出了Fine-in-Facext（FiFa）框架，它集中在数据标注和模型构建上的贡献。首先定义了面部图像概念树（FICT），将面部图像细分为层次概念，进而获得了更加可靠的细粒度数据标注流程FiFa-Annotator。基于专有的数据标注，引人了一项新的细粒度可解释深度伪造分析（AGE）任务，该任务生成在分割掩码中交织的文本伪造解释。同时提出了一种统一的多任务学习架构FiFa-MLLM，以支持丰富的多模态输入和细粒度的可解释深度真伪分析。通过多个辅助监督任务，FiFa-MLLM 在AGE任务上超过了强大基线，并在现有XDFA数据集上达到了SOTA性能。
### Conclusion
通过FiFa-MLLM架构，本文不仅提出了一种细化的数据标注策略，还设计了一种新的AGE任务和多任务学习框架，显著提升了细粒度、可靠的可解释深度真伪分析能力。
## 128. `cs.AI` - Generalizable Reasoning through Compositional Energy Minimization [PDF](https://arxiv.org/pdf/2510.20607), [HTML](https://arxiv.org/abs/2510.20607)
### Authors
Alexandru Oarga,Yilun Du
### Background
机器学习中的泛化是一个关键挑战，尤其是在需要解决复杂推理任务的情况下。现有方法通常以端到端的方式训练推理模型，直接将输入实例映射到解决方案。这种方法虽然能够使模型从数据中学习有用的启发式方法，但在训练分布之外的泛化能力却有限。现有工作在推理时通常不考虑额外的约束条件，也限制了他们处理复杂问题的能力。
### Innovation
本文提出了一种通过学习更小且更易于解决的子问题解空间上的能量景观来进行推理泛化的新型方法。具体来说，提出了一种组合能量最小化（PEM）方法，以提高新构建的能量景观的样本质量。这种方法能够在测试时为给定问题构建全局能量景观，并且允许在推断中逐步整合更复杂的约束条件。实验结果表明，该方法能够优于当前最先进的方法，在处理更大和更复杂的问题时展现出更好的泛化能力。
### Conclusion
本文提出的方法证明了其在处理更大和更复杂推理问题时的泛化能力。通过学习子问题解空间上的能量景观，结合组合能量最小化方法的使用，该工作提供了一种有效的解决方式，能够显著提高推理模型的泛化性能。
## 129. `cs.AI` - OnlineSplatter: 摄像机姿态无关的在线自由移动物体3D重建 [PDF](https://arxiv.org/pdf/2510.20605), [HTML](https://arxiv.org/abs/2510.20605)
### Authors
Mark He Huang,Lin Geng Foo,Christian Theobalt,Ying Sun,De Wen Soh
### Background
基于单目视频重建自由移动物体仍然是一个极具挑战性的问题，尤其是在缺乏可靠的姿态或深度线索以及任意物体运动的情况下。现有的方法通常需要摄像头的姿态信息、深度先验知识或束调整优化，这大大限制了它们的适用性。因此，如何在不依赖这些外部信息的情况下进行高精度的3D重建是一个亟待解决的问题。
### Innovation
我们提出了一种名为OnlineSplatter的创新在线前馈框架，该框架能够直接从RGB帧中生成高质量、以物体为中心的3D高斯分布，而无需相机姿态、深度先验或束调整优化。该方法首先锚定第一帧的重建，并通过密集的高斯原始域逐步改进物体表示，保持与视频序列长度无关的恒定计算成本。核心贡献是结合潜在的外观-几何键与显式的方向键的双重键记忆模块，该模块能够通过时空聚合的对象状态有效融合当前帧特征，从而有效处理自由移动物体，同时通过空间导向的记忆读取和高效的稀疏化机制确保全面且紧凑的对象覆盖。实验证明，OnlineSplatter在多个实际数据集上显著优于最先进的姿态无关的3D重构基线，且效果随观测数量增加而稳定提升，同时保持恒定的内存和运行时间。
### Conclusion
OnlineSplatter 通过结合时空聚合和有效的记忆机制，在无需使用外部姿态或深度信息的前提下实现了高精度的自由移动物体3D重建。实验结果表明，该方法相比传统方法具有明显的优势，能够在处理任意运动物体时确保效率和精度并存。
## 130. `cs.AI` - 被追逐的狗难倒了模型：测量模型何时放弃结构而使用捷径 [PDF](https://arxiv.org/pdf/2510.20543), [HTML](https://arxiv.org/abs/2510.20543)
### Authors
Sangmitra Madhusudan,Kaige Chen,Ali Emami
### Background
尽管语言模型在处理复杂句子如“那只狗追逐的猫喵喵叫”时表现出色，但现有方法缺乏区分它们的句法理解和基于语义模式匹配的能力。为了填补这一空白，已有研究引入了一个新的基准测试数据集CenterBench，它包含9720个关于中心嵌套句子的推理问题，这些句子的相对从句递归嵌套，从简单的结构到深层次嵌套结构。每个句子都有一个句法相同但语义不现实的对应句子，并包含六个测试问题，分别测试表面理解、句法依赖和因果推理。这些模型的表现差距与复杂性成系统性增长，尤其是在涉及因果关系的问题中，语义关联比语义连贯更重要。对于需要推理的问题，即使合理性的优势随着复杂性的提高而增强，人类的表现却呈现出语义影响的变异性。CenterBench为识别模型何时从句法分析转向模式匹配提供了首个框架。
### Innovation
该研究创新地提出了一个名为CenterBench的新基准测试数据集，用于评估自然语言处理模型在理解复杂句子结构时的能力，而不仅仅依赖于语义模式匹配。通过对比合理句子和不合理句子的表现差异，研究揭示了模型在面对深层结构嵌套时的具体表现模式，并强调了因果推理对于正确理解复杂句子的重要性。此外，研究还展示了尽管某些模型试图通过更复杂的推理来提高表现，但它们仍然依赖于基于语义的捷径，而这些捷径可能会导致错误的结论。这种新的评估框架有助于更好地理解当前模型在处理自然语言时的局限性和改进方向。
### Conclusion
CenterBench提供了识别模型从句法分析转向模式匹配的第一个框架。研究发现，模型在处理深层嵌套结构时，随着复杂性的提高，它们可能会放弃句法分析而转向依赖语义关联。这种对合理性和因果关系影响的研究为解释模型在自然语言处理任务中的行为提供了一个新的视角，并揭示了可能存在改进的空间。
## 131. `cs.AI` - 大规模实用代码RAG：基于任务的认知检索设计选择在计算预算下的应用 [PDF](https://arxiv.org/pdf/2510.20609), [HTML](https://arxiv.org/abs/2510.20609)
### Authors
Timur Galimzyanov,Olga Kolomyttseva,Egor Bogomolov
### Background
本文研究了在现实计算预算下，针对代码密集型生成任务的检索设计。使用来自Long Code Arena的两个互补任务——代码完成和错误定位，系统地比较了各种上下文窗口大小下的检索配置，从三个维度进行比较：分割策略、相似性评分和分割粒度。
### Innovation
研究表明，在代码-代码（PL-PL）的情况下，基于单词级别的稀疏BM25是最有效且实用的，显著优于密集型替代方案，同时速度快一个数量级。在自然语言-代码（NL-PL）情况下，专有的密集编码器（Voyager-3家族）始终优于稀疏检索器，但需要100倍的延迟。最佳的分割大小随着可用上下文大小而变化：32-64行分割在小预算下最佳，而全文检索在16000个标记时变得有竞争力。简单的行级分割在所有预算下与语法意识的分割匹配。不同配置的检索延迟最高可相差200倍；基于BPE的分割过于缓慢，而BM25结合单词分割提供了最佳的质量-延迟权衡。
### Conclusion
因此，本文基于任务要求、模型约束和计算效率提供了基于证据的建议，以实现有效的代码导向检索和检索生成系统（RAG）.
## 132. `cs.AI` - BUSTED在AraGenEval共享任务中的表现：基于Transformer模型的阿拉伯语AI生成文本检测比较研究 [PDF](https://arxiv.org/pdf/2510.20610), [HTML](https://arxiv.org/abs/2510.20610)
### Authors
Ali Zain,Sareem Farooqui,Muhammad Rafi
### Background
本文介绍了我们在Ara-GenEval共享任务上阿拉伯语AI生成文本检测的参赛情况，团队BUSTED在该任务中获得了第5名的成绩。我们研究了三项预训练的转换器模型：AraELECTRA、CAMeLBERT和XLM-RoBERTa的有效性。我们的方法是对每个模型进行微调，以完成二元分类任务。
### Innovation
我们的发现揭示了一个令人惊讶的结果：多语言的XLM-RoBERTa模型在F1分数（0.7701）的表现最佳，超越了专门针对阿拉伯语的模型。这项工作强调了AI生成文本检测领域的复杂性，并突显了多语言模型的强大泛化能力。
### Conclusion
研究结果表明，在阿拉伯语AI生成文本检测任务中，多语言模型具有更好的泛化能力，这增强了我们对跨语言文本处理任务的理解。
## 133. `cs.AI` - 黑匣子吸收：大模型破坏创新性想法 [PDF](https://arxiv.org/pdf/2510.20612), [HTML](https://arxiv.org/abs/2510.20612)
### Authors
Wenjun Cao
### Background
大型语言模型正在被广泛用作加速创新的关键工具。然而，这些模型的黑箱内部架构可能导致系统性风险，即‘黑箱吸收’。‘黑箱吸收’是指大型语言模型平台，通常由大规模服务提供商运营，会将用户的创新概念转化为平台自身的知识，并进一步向系统中注入，从而导致用户与平台之间的信息不对称和结构性不公，威胁创新经济的基本原则和长期可持续性。为了解决这个问题，该研究引入了‘想法单元’和‘想法安全’两个核心概念，分别代表创新中的可移植功能逻辑以及其保护标准，并分析了吸收机制，提出了具体的治理和工程技术议程，以减轻这些风险，确保创作者的贡献可以被追踪、控制和公平对待。
### Innovation
该研究定义了‘黑箱吸收’这一概念，并提出了‘想法单元’和‘想法安全’两个核心概念作为保护创新的框架；分析了‘黑箱吸收’的机制；并提出了治理和工程技术的议程以减轻风险。
### Conclusion
该研究通过引入‘想法单元’和‘想法安全’等概念，分析了‘黑箱吸收’机制，并提出了具体措施，以确保创作者的贡献能够保持可追溯性、可控性和公正性，从而维护创新生态系统的长期可持续性。
## 134. `cs.AI` - 基于PSO增强的可解释AI框架在可靠乳腺癌检测中的应用 [PDF](https://arxiv.org/pdf/2510.20611), [HTML](https://arxiv.org/abs/2510.20611)
### Authors
Mirza Raquib,Niloy Das,Farida Siddiqi Prity,Arafath Al Fahim,Saydul Akbar Murad,Mohammad Amzad Hossain,MD Jiabul Hoque,Mohammad Ali Moni
### Background
全球乳腺癌是女性中最常见和最具威胁性的癌症之一，导致癌症相关死亡率上升。早期和准确的检测至关重要，因为它有助于降低风险并提高生存率。传统的诊断方法由于变异性的限制、成本以及误诊风险，往往对预测有限。为了应对这些挑战，机器学习（ML）已经成为计算机辅助诊断的强大工具，特征选择在提高模型性能和可解释性方面发挥着关键作用。
### Innovation
该研究提出了一种集成框架，结合了定制化的粒子群优化（PSO）进行特征选择。该框架在29种不同的模型上进行了评估，涵盖了经典分类器、集成技术、神经网络、概率算法和基于实例的算法。为了确保可解释性和临床相关性，研究结合了交叉验证和可解释AI方法。实验结果显示，该提出的方法在所有性能指标上取得了99.1%的优秀得分，同时有效降低了维度，并提供透明的、模型无关的解释。研究表明，结合群智能与可解释的机器学习有潜力为乳腺癌诊断提供稳健、可靠和临床意义的结果。
### Conclusion
结果表明，结合群智能与可解释的机器学习可为乳腺癌诊断提供稳健、可靠且临床相关的应用。
## 135. `cs.AI` - 公平生存预测：一种公平意识生存模型（FASM）方法 [PDF](https://arxiv.org/pdf/2510.20629), [HTML](https://arxiv.org/abs/2510.20629)
### Authors
Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu
### Background
随着机器学习模型在医疗保健中的集成，临床数据中嵌入的结构不平等和社会偏见可能会被数据驱动模型延续或放大。在生存分析中，数据中的失访和时间动态会使公平模型的发展更加复杂。算法公平性方法往往忽视跨群体排名的不平等，例如高风险的非裔美国人患者可能会被误认为比实际风险较低的白人患者排名靠后，这种误排会强化生物本质主义并损害公平护理。因此，需要一种能够同时减轻组内和跨群体排名偏见的模型，以提升公平护理标准，同时保持与未考虑到公平性的生存模型相似的区分性能。
### Innovation
本文提出了公平意识生存模型（FASM），旨在减轻算法偏见，同时改进小组内和跨群体风险排名。通过在乳腺癌预后领域进行研究，作者证明了FASM模型在提升公平性方面表现优异，同时保留了与未注意公平性的生存模型相当的区分性能。时间分层评估结果显示，FASM模型在10年的评估期内保持稳定的公平性，中期随访中有最大的改进。这种新方法旨在通过提升准确性和公平性来优化临床决策，使得公平性成为临床护理的核心原则
### Conclusion
FASM方法能够在临床决策中同时提高生存模型的准确性和公平性，提升公平性作为临床护理的核心原则。
## 136. `cs.AI` - 使用机器学习预测量子处理单元（QPU）处理时间 [PDF](https://arxiv.org/pdf/2510.20630), [HTML](https://arxiv.org/abs/2510.20630)
### Authors
Lucy Xing,Sanjay Vishwakarma,David Kremer,Francisco Martin-Fernandez,Ismael Faro,Juan Cruz-Benito
### Background
本文探索了在量子作业中应用机器学习（ML）技术以预测QPU处理时间的研究。利用机器学习算法，本文引入了能够提高量子计算系统操作效率的预测模型。研究基于约150,000个按照IBM Quantum架构的作业数据集，使用基于梯度增强（LightGBM）的机器学习方法来预测QPU处理时间，并采用数据预处理方法以提高模型的准确性。实验结果表明，机器学习在量子作业预测上具有显著效果，能够对量子计算框架中的资源管理和调度产生积极影响。
### Innovation
本文通过引入基于梯度增强（LightGBM）的机器学习预测模型，提高了量子作业处理时间预测的准确性。此外，研究还通过数据预处理方法进一步优化了模型性能，并为量子计算中人工智能驱动工具的应用奠定了基础。
### Conclusion
本文不仅展示了机器学习在量子作业预测方面的潜力，还为高级量子计算操作中的AI驱动工具的集成提供了理论依据。研究结果表明，利用机器学习可以显著改善量子计算中的资源管理和调度效率。
## 137. `cs.AI` - 为什么苹果会落地：评估大型语言模型中的好奇心 [PDF](https://arxiv.org/pdf/2510.20635), [HTML](https://arxiv.org/abs/2510.20635)
### Authors
Haoyu Wang,Sihang Jiang,Yuyan Chen,Yitong Wang,Yanghua Xiao
### Background
好奇心是人类探索和学习新知识的关键驱动力。近期，大型语言模型（LLMs）在自然语言处理方面的进展引发了关于这些模型是否具有类似人类的好奇心驱动学习能力的讨论。本文基于人类好奇心评估问卷Five-Dimensional Curiosity scale Revised（5DCR），设计了一个全面的评估框架，涵盖信息寻求、冒险寻求和社会好奇心等维度，以评估LLMs的好奇程度。
### Innovation
本文创新之处在于提出一个全面评估LLMs好奇心的框架，并通过实验证明LLMs不仅表现出比人类更强的求知欲，而且在不确定环境中仍然倾向于保守选择。此外，研究还探讨了好奇心与LLMs思维之间的关系，发现好奇心行为能够增强模型的推理和主动学习能力。这些发现表明LLMs具有类似人类的好奇心，为未来的学习能力和LLMs创新研究提供了实验支持。
### Conclusion
研究结果表明，LLMs有潜力展现类似人类的好奇心，这为进一步发展学习能力和LLMs相关创新研究提供了实验支持。
## 138. `cs.AI` - 牙科图像分析中的深度学习：数据集、方法和新兴挑战的系统回顾 [PDF](https://arxiv.org/pdf/2510.20634), [HTML](https://arxiv.org/abs/2510.20634)
### Authors
Zhenhuan Zhou,Jingbo Zhu,Yuchen Zhang,Xiaohang Guan,Peng Wang,Tao Li
### Background
牙科影像分析对于确保诊断准确性和治疗规划的优化至关重要。然而，牙科影像存在低对比度、金属伪影和投影角度变化等固有挑战。加之不同牙医间专业知识的差异性，手动解读影像常常耗时且不一致。因此，采用人工智能（AI）技术进行自动化的牙科影像分析（DIA）变得尤为关键，并已成为计算机辅助诊断和治疗的不可或缺部分。其中，深度学习（DL）因其卓越的特征提取和表示能力，成为了应用最广泛、影响力最大的方法。
### Innovation
该研究系统回顾了260篇关于DL应用于DIA的研究，其中49篇涉及公共牙科数据集，211篇涉及基于DL的算法。研究介绍了牙科影像的基本概念，总结了现有数据集的特点和获取方法，详细分析了不同DIA任务中的DL模型和算法，对比了它们的网络架构、优化策略、训练方法和性能。此外，还总结了DIA领域常用的训练和评估度量标准。
### Conclusion
目前仍面临不少挑战，如数据质量、模型泛化能力和临床应用中的可解释性等。未来的研究方向可能包括提高模型的鲁棒性、开发跨设备和跨平台的解决方案、以及加强与临床实践的结合。本研究希望为该领域的研究者提供有价值的系统参考。
## 139. `cs.AI` - 推理的语言基础：多语言AI的双刃剑 [PDF](https://arxiv.org/pdf/2510.20647), [HTML](https://arxiv.org/abs/2510.20647)
### Authors
Alan Saji,Raj Dabre,Anoop Kunchukuttan,Ratish Puduppully
### Background
大型推理模型（LRMs）在数学、科学和其他问答任务中表现出色，但在多语言推理能力方面仍被忽视。当LRMs面对非英语问题时，它们常常使用英语进行推理，这引发了对其可解释性和处理语言和文化差异能力的担忧。
### Innovation
本研究系统性地比较了LRMs在英语和问题所使用的语言之间的推理过程，涉及MGSM和GPQA Diamond两个任务。研究不仅评估了答案的准确性，还分析了推理过程中的认知属性。结果显示，使用英语推理的痕迹中更具认知行为，且通常能获得更高的最终答案准确性，尤其是在任务复杂时。但这种以英语为中心的策略也可能导致关键失败模式——“翻译失效”，即翻译步骤导致的错误可以通过使用问题所使用的语言进行推理避免。
### Conclusion
相比于使用问题所使用的语言进行推理，尽管英语推理在简单到中等复杂度的问题上表现良好，但面对复杂任务时，直接使用问题的语言进行推理则更准确可靠，避免了“翻译失效”的风险。但仍需更多研究来优化多语言推理方法，以提升其整体性能和实用价值。
## 140. `cs.AI` - R2-SVC: 向实时鲁棒且表现力强的零样本歌唱声源转化迈进 [PDF](https://arxiv.org/pdf/2510.20677), [HTML](https://arxiv.org/abs/2510.20677)
### Authors
Junjie Zheng,Gongyu Chen,Chaofan Ding,Zihao Chen
### Background
在实际歌唱声源转化（SVC）应用中，环境噪声和对表达性的需求构成了严峻挑战。传统方法在设计时通常没有考虑实际部署场景，因为既有的训练和推理都在干净的数据上进行。这种不匹配限制了实际应用，因为不可避免的存在多种噪声源和音乐分离的瑕疵。为了应对这些挑战，我们提出了R2-SVC，这是一种鲁棒且表现力强的SVC框架。
### Innovation
首先，通过随机基本频率（$F_0$）扰动和音乐分离瑕疵模拟（例如，混响、回声），引入基于模拟的鲁棒性增强，显著提高在噪声条件下的性能。其次，利用特定领域的歌唱数据丰富说话者表示：除了干净的声乐外，还整合DNSMOS过滤分离的声乐和公共歌唱语料库，使模型能够保持说话者音色的同时捕捉到歌唱风格的细微差别。第三，结合神经声源滤波（NSF）模型以明确表示谐波和噪声成分，增强转换歌唱的自然性和可控性。
### Conclusion
在多种SVC基准测试中，无论在干净还是噪声条件下，R2-SVC均取得了最先进的结果。
## 141. `cs.AI` - GRACE: 基于图形的成瘾护理预测 [PDF](https://arxiv.org/pdf/2510.20671), [HTML](https://arxiv.org/abs/2510.20671)
### Authors
Subham Kumar,Prakrithi Shivaprakash,Koustav Rudra,Lekhansh Shukla,Animesh Mukherjee
### Background
确定成瘾患者的适当治疗地点是影响治疗结果和资源有效使用的关键临床决策之一。由于缺乏足够的专门治疗资源（如住院床位或专业人员），亟需开发一个自动化框架来解决这一问题。当前的决策方法在成瘾数据集中存在严重的类别不平衡问题，该论文提出了一种新的图神经网络（GRACE）框架，将治疗地点预测问题形式化为结构化学习问题，并进行了广泛的功能工程，提出了一种新的不失真的元图获取方法，以解决类别不平衡问题。在现实数据中的实验结果表明，在针对少数类的F1分数上比竞争性基线提高了11-35%。
### Innovation
提出了一种新的图神经网络（GRACE）框架，将治疗地点预测问题形式化为结构化学习问题，通过进行广泛的功能工程和提出一种新的不失真的元图获取方法来解决类别不平衡问题。实验结果显示，在针对少数类的F1分数上比竞争性基线提高了11-35%。
### Conclusion
实验结果在现实数据中展示了相对于竞争性基准模型，在少数类的F1分数上有了11-35%的提升，表明该图神经网络框架（GRACE）能够有效解决成瘾数据集中的类别不平衡问题，并提供了一个有效的自动化治疗地点预测框架。
## 142. `cs.AI` - 金融叙事语义融合进行金融波动率预测 [PDF](https://arxiv.org/pdf/2510.20699), [HTML](https://arxiv.org/abs/2510.20699)
### Authors
Yaxuan Kong,Yoontae Hwang,Marcus Kaiser,Chris Vryonides,Roel Oomen,Stefan Zohren
### Background
文章介绍了一种名为M2VN（多模态波动网络）的新颖深度学习框架，该框架结合了时间序列特征和未结构化新闻数据，旨在金融波动率预测领域。M2VN通过利用深度神经网络的表示能力来解决两个关键挑战：（i）对齐和融合异构数据模态（数值金融数据和文本信息），以及（ii）减轻可能导致金融模型有效性的前瞻偏差。现代金融市场中，需要在这种复杂环境下优化预测精度，这对于风险管理及金融决策至关重要，因此研究如何有效结合不同形式的数据成为一个重要的研究课题。
### Innovation
M2VN创新性地结合了开源市场特征与由Time Machine GPT生成的新闻嵌入，确保了时间连续性。此外，通过引入辅助对齐损失，增强结构化和非结构化数据在深度学习架构中的集成，从而能有效处理数值金融数据和文本信息之间的融合问题，并且显著减少了前瞻偏差，相比于现存的基准模型，M2VN的预测效果普遍更好，提供了实际的风控和决策支持价值。
### Conclusion
实验表明，M2VN在金融波动率预测中表现更为出色，能够有效融合时间序列特征和新闻数据，提供更高的预测精度，这对于实现动态市场环境下的有效风险管理及金融决策具有重要的实际价值。
## 143. `cs.AI` - 在推理时LLM反思中寻找甜蜜点：权衡质量、成本和速度 [PDF](https://arxiv.org/pdf/2510.20653), [HTML](https://arxiv.org/abs/2510.20653)
### Authors
Jack Butler,Nikita Kozodoi,Zainab Afolabi,Brian Tyacke,Gaiar Baimuratov
### Background
随着大型语言模型（LLMs）的不断演进，实践者在无需重新训练模型的情况下有了越来越多的提升推理时性能的方法，包括预算调整和多步技术，如自我反思。尽管这些方法可以改善输出质量，但它们在准确率、成本和延迟之间创造了复杂的权衡，目前这些权衡在不同领域的理解仍不充分。本文系统地将自我反思与预算调整应用于数学推理和翻译任务，并评估了著名的LLM模型，如Anthropic Claude、Amazon Nova、Mistral系列，以及其他不同深度的反思和计算预算下的模型，从而得出帕累托最优的性能边界。研究表明，自我反思的有效性因领域而异，在数学推理中的性能增幅可达220%。进一步的研究探讨了反思轮次深度和反馈机制质量对不同模型家族性能的影响。为了在现实环境中验证这一发现，我们在Zalando的Lounge部署了一个带有自我反思增强的营销内容本地化系统，证明了市场依赖的有效性，强调了在部署这些技术时进行领域特定评估的重要性。结果为选择特定领域和资源约束下的最优推理策略提供了可操作的指导，并开放源代码以确保可重复性。
### Innovation
本文通过系统比较自我反思与预算调整技术在数学推理和翻译任务中的应用，首次研究了这些技术在不同领域的综合影响，尤其是自我反思在不同领域的增益显著不同。此外，研究首次详细分析了不同模型家族的性能，并探索了反射轮次深度和反馈机制质量对模型性能的影响。最后，通过实际应用验证这些技术在市场依赖性方面的有效性，强调了领域特定评估的重要性。
### Conclusion
本文为选择特定领域和资源约束下的最优推理策略提供了具体的建议，即通过系统分析自我反思与预算调整技术在不同领域中的综合影响，揭示了这些技术在数学推理任务中带来的显著性能改善。同时，研究还强调了在实际部署时进行领域特定评估的重要性，为实际应用中的选择提供了行动指南。进一步开放源代码，确保了研究结果的可重复性。
## 144. `cs.AI` - 神经多样性在小型模型中规整幻觉 [PDF](https://arxiv.org/pdf/2510.20690), [HTML](https://arxiv.org/abs/2510.20690)
### Authors
Kushal Chakrabarti,Nirmal Balachundhar
### Background
语言模型尽管参数量、计算资源和数据量不断增加，仍然会生成与训练数据不一致的幻觉。研究者发现，神经多样性——即解耦并行表示——作为一种原则性机制，在固定参数和数据预算下可以减少幻觉率。受到投资组合理论的启发，不同资产的不相关性可以通过 $frac{1}{text{相关性}}$ 来降低风险。这个论文探讨了表示相关性与幻觉概率之间的关系，从而发现语言模型需要较合适的神经多样性来减少幻觉概率。
### Innovation
引入了结合低秩适应器和巴罗孪生正则化技术的 ND-LoRA 方法，该方法能够在不影响通用准确性的前提下减少幻觉至最高 25.6%（平均 14.6%），展示了低秩适应器和正则化之间的协同作用，并通过因果干预和相关性分析证明了神经多样性作为幻觉减少机制的概念，特别是在任务依赖的优化上，不同任务需要不同的神经多样性水平。
### Conclusion
通过提供理论基础和实验证据，研究结果强调了在固定预算条件下，增加神经多样性作为提高语言模型可靠性的第三条独立于参数和数据的扩大路径。
## 145. `cs.AI` - 基于脉冲神经网络的可扩展、因果且节能的神经解码框架 [PDF](https://arxiv.org/pdf/2510.20683), [HTML](https://arxiv.org/abs/2510.20683)
### Authors
Georgios Mentzelopoulos,Ioannis Asmanis,Konrad P. Kording,Eva L. Dyer,Kostas Daniilidis,Flavia Vitale
### Background
脑-计算机接口（BCIs）能够帮助神经运动受损的个体恢复诸如言语和假肢控制等功能。神经解码器是实现这一目标的关键，它们将神经活动映射到预期的行为。当前的学习型解码方法可以分为两类：简单因果模型虽然易于实现，但在推广性上存在不足；较为复杂的非因果模型能够实现离线推广和扩展，但在实时应用中表现不佳。无论是哪一类方法，都面临着能量密集型的神经网络作为支撑，这使得它们难以集成到资源受限的现实系统中。脉冲神经网络（SNNs）提供了另一种选择。由于其因果特性，SNNs非常适合实时应用，并且低能耗特性使其成为限制电池环境的理想选择。
### Innovation
本文提出了一种基于SNNs的可扩展、因果且节能的神经解码框架——Spikachu。该框架直接处理分桶后的脉冲信号，并将它们投影到一个共享的潜在空间中，通过适应输入的脉冲模块提取相关特征；这些潜在表示被整合并解码以生成行为预测。Spikachu在非人类灵长类动物的113个记录会话中得到了验证，总计共43小时的记录。相比于单会话训练的因果基准模型，该方法在能量消耗上分别降低了2.26到418.81倍，并展示了多会话和多用户扩展训练的性能提升以及对未见过的会话、用户和任务的少量样本迁移学习能力。
### Conclusion
Spikachu引入了一种基于SNNs的可扩展、在线兼容的神经解码框架，其性能相对先进模型更为优越，同时消耗的数量级更小的能量。
## 146. `cs.AI` - 探索大型语言模型在访问控制策略合成与总结中的应用 [PDF](https://arxiv.org/pdf/2510.20692), [HTML](https://arxiv.org/abs/2510.20692)
### Authors
Adarsh Vatsa,Bethel Hall,William Eiers
### Background
随着云计算的普及，越来越多的服务开始在云端运行。传统的云计算系统允许管理员编写实施访问控制规则的策略，但这些策略需要手动编写且因复杂性易出错。现有的访问控制策略通常较为复杂，在分析其行为是否和预期一致时也会遇到困难。近年来，大型语言模型在自动化代码合成和摘要方面表现出极大的成功，在这种背景下，它们或许能用于自动化生成访问控制策略或辅助理解现有策略。因此，论文探讨了大型语言模型在访问控制策略合成与总结方面的有效性。
### Innovation
研究采用了多种大型语言模型进行访问控制策略的合成，发现尽管这些模型能够生成语义正确的策略，但也存在一定的宽松性，且在使用推理的模型中更为明显。论文还提出了一种基于语义的请求总结方法，利用大型语言模型生成对策略所允许请求的精确描述。研究结果表明，虽然自动化策略生成面临挑战，但大型语言模型与符号方法结合可以有效地分析现有的策略，展现出良好的前景。
### Conclusion
研究揭示了大型语言模型在自动化访问控制策略合成与总结方面的能力和局限性，指出这些模型在辅助分析现有策略时表现良好，并且与符号方法结合具有潜在的应用价值。
## 147. `cs.AI` - 使用N-BEATS和图神经网络的多变量半导体制造过程时间序列无监督异常预测 [PDF](https://arxiv.org/pdf/2510.20718), [HTML](https://arxiv.org/abs/2510.20718)
### Authors
Daniel Sorensen,Bappaditya Dey,Minjin Hwang,Sandip Halder
### Background
半导体制造是一个极其复杂且需高精度执行的过程，涉及成千上万个相互关联的参数，跨越多种工具和工序。多变量时间序列分析作为一种关键技术，已被用于实时监控和故障检测。然而，半导体制造中的异常预测面临诸多挑战，包括高维度的传感器数据和严重的类别不平衡问题，因为真正故障的情况极其罕见。复杂变量间的相互依赖性还增加了异常预测和根本原因分析的难度。
### Innovation
本文提出了一种新颖的方法，从异常检测推进到异常预测，这是实现实时过程校正和预防性故障的关键步骤。该方法包括两个主要阶段：首先，在假设数据集中无异常的情况下训练一个预测模型，然后在未知的时间序列数据上进行预测。预测结果与训练信号的预测进行对比，超出预先定义阈值的偏差被标记为异常。两种方法在使用不同的预测模型上有所区别：第一个假设变量之间独立，使用N-BEATS模型进行单一变量时间序列预测；第二个则通过使用图神经网络（GNN）来捕捉变量间的相互关系。两个模型的预测性能在20个时间点内较强，并在50个时间点内稳定预测异常。GNN在计算参数量和计算成本方面均显著优于N-BEATS模型，并且表现更优异。
### Conclusion
本文展示了图神经网络在在线异常预测中的优势，可用于部署在制造环境中进行实时分析。GNN表现出色，同时保持了较低的计算成本，提供了可行的解决方案。
## 148. `cs.AI` - 使用模型预测控制和强化学习实现四足动物的实时步態適應 [PDF](https://arxiv.org/pdf/2510.20706), [HTML](https://arxiv.org/abs/2510.20706)
### Authors
Ganga Nair B,Prakrut Kotecha,Shishir Kolathaya
### Background
模型自由的强化学习（RL）使得四足动物的运动更为适应和灵活，然而，这些策略通常会收敛到单一的步態模式，导致性能不佳。传统上，模型预测控制（MPC）被广泛用于获取特定任务的最优策略，但缺乏适应不同环境的能力。为了应对这些限制，作者提出了一种在连续步態空間中实现实时步態適應的优化框架，结合了模型预测路径积分（MPPI）算法和一个梦者模块（Dreamer），以生成适应性和最优的四足运动策略。在每一步，MPPI联合优化动作和步態变量，利用一个学习到的Dreamer奖励来促进速度跟踪、高效能、稳定性及平滑过渡，同时惩罚突然步態变化。加入学习到的价值函数作为终结奖励，将形式扩展到无限时距计划器中。
### Innovation
提出了一种新的优化框架，结合使用MPPI算法和Dreamer模块，实现实时步態適應，同时优化动作和步態变量，采用学习到的奖励来促进多个性能指标，同时加入学习到的价值函数，提高长期表现。该方法在目标速度变化时，显示了能效提高了最多36.48%的效果，同时保持了准确的跟踪和适应性、任务适当的步態。
### Conclusion
本研究提出的方法能够在不同环境和速度条件下，实现实时步態適應，显著提高了四足动物的能源效率，同时维持了动作执行的准确性，展示了该方法在改进四足动物机动性和适应性上的潜力。
## 149. `cs.AI` - 通过多智能体系统协同设计具有横向对角门的量子码 [PDF](https://arxiv.org/pdf/2510.20728), [HTML](https://arxiv.org/abs/2510.20728)
### Authors
Xi He,Sirui Lu,Bei Zeng
### Background
该研究建立在Subset-Sum线性规划框架之上，该框架通过按模块余数分区基本字符串并使用小型线性规划来强制$Z$-边缘的Knill-Laflamme（KL）等式。研究在LaTeX-Python环境中进行，探讨了量子编码的设计问题，并通过多智能体系统合作解决了相关问题。
### Innovation
该工作提出了一种多智能体、人工介入的工作流，用于共同设计具有指定横向对角门的量子码。该方法结合了系统枚举和精确的分析重建，展示了基于子集和线性规划的新量子码体系结构，并通过 Git/Overleaf 实现了协作和一致的工作流程。
### Conclusion
该研究通过系统枚举和精确分析将横向对角线可行性重组为一个可扩展的分析管道，不仅实现了可复制的量子码构造，还为更大维度和更高距离的扩展提供了支持，并朝着数据驱动的分类研究方向迈进。
## 150. `cs.AI` - 使用自然语言处理从临床笔记中自动化提取氟尿嘧啶治疗及治疗相关毒性 [PDF](https://arxiv.org/pdf/2510.20727), [HTML](https://arxiv.org/abs/2510.20727)
### Authors
Xizhi Wu,Madeline S. Kreider,Philip E. Empey,Chenyu Li,Yanshan Wang
### Background
氟尿嘧啶类药物广泛用于治疗结直肠癌和乳腺癌，但会导致如手足综合征和心脏毒性等副作用。这些副作用的信息经常记录在临床笔记中，因此开发自然语言处理（NLP）方法以从这些笔记中提取治疗和副作用信息是必要的。
### Innovation
本研究构建了一个包含204,165名成人癌症患者临床笔记的金标准数据集，通过标记治疗方案和副作用类别来评估基于规则、机器学习（如随机森林、支持向量机和支持向量机、逻辑回归）、深度学习（如BERT和临床BERT）以及大型语言模型（LLM）的NLP方法，发现基于LLM的方法在提取治疗和副作用信息方面效果最佳。
### Conclusion
基于LLM的NLP方法最有效地从临床笔记中提取了氟尿嘧啶治疗和副作用信息，并有望支持癌症研究和药物警戒。
## 151. `cs.AI` - 用户在隐私敏感场景下对LLM响应的隐私性和帮助性的感知 [PDF](https://arxiv.org/pdf/2510.20721), [HTML](https://arxiv.org/abs/2510.20721)
### Authors
Xiaoyuan Wu,Roshni Kaushik,Wenkai Li,Lujo Bauer,Koichi Onoue
### Background
大型语言模型（LLMs）在起草电子邮件、总结会议、回答健康咨询等方面得到了迅速应用。然而，在这些应用中，用户可能需要分享私人信息（如健康记录、联系信息）。为了评估LLMs识别和遮蔽此类私人信息的能力，先前的研究开发了一些基准（如ConfAIde、PrivacyLens），利用真实场景进行评估。尽管已发现LLMs在处理复杂任务时有时无法保护隐私（例如，在会议总结中泄露员工工资），但这些评估主要依赖于LLMs（代理LLMs）来衡量其遵守隐私规范的情况，而忽视了真实用户对隐私保护质量的感知。先前的研究主要集中在LLM响应的隐私保护质量上，没有深入探讨它们在有用性方面的细微差异。
### Innovation
本文通过在94名参与者中使用来自PrivacyLens的90个情景进行用户研究，探索了用户在隐私敏感场景下对LLM响应的隐私保护质量和帮助性的感知。研究表明，用户在评估相同场景下LLM响应的隐私保护质量和帮助性时，彼此之间存在较低的一致性。而五个代理LLMs之间的一致性较高，但每个个体LLMs与用户评价的相关性较低。这一结果表明，LLM响应的隐私性和帮助性往往因个人而异，代理LLMs不能很好地预测真实用户在隐私敏感场景下对此类响应的感知。研究表明，需要进行以用户为中心的研究来衡量LLMs为用户隐私保护和帮助能力的能力。此外，未来的研究可以探索提高代理LLMs与用户之间对齐的方法，以更好地估计用户感知到的隐私性和实用性。
### Conclusion
本研究揭示了用户在隐私敏感场景下对LLM响应的隐私保护质量和帮助性存在较大主观差异，代理模型不能准确反映真实用户感知。未来的研究应基于用户角度，推动LLMs在隐私保护方面的应用，并探索改进代理模型以更准确评估用户感知的方法。
## 152. `cs.AI` - Empathic Prompting: 通过非言语上下文整合实现多模态LLM对话 [PDF](https://arxiv.org/pdf/2510.20743), [HTML](https://arxiv.org/abs/2510.20743)
### Authors
Lorenzo Stacchio,Andrea Ubaldi,Alessandro Galdelli,Maurizio Mauri,Emanuele Frontoni,Andrea Gaggioli
### Background
传统的多模态接口需要用户进行显式的控制，但在这种情况下，系统通过集成一个商用面部表情识别服务捕获用户的非言语情感提示，并将其作为上下文信号嵌入到提示中，无需用户干预，而是以不显眼的方式增强文本输入的情感信息，实现对话的流畅性和一致性。这种架构是模块化的和可扩展的，可以方便地添加其他非言语模块。本研究通过一个本地部署的DeepSeek实例描述了系统的架构，并报告了初步的服务和可用性评估（N=5）。研究结果表明，非言语输入可以一致地整合到连贯的LLM输出中，参与者也强调了对话的流畅性。
### Innovation
该研究提出的Empathic Prompting框架是一种新颖的多模态人类-人工智能互动框架，通过集成商用面部表情识别服务，将用户的隐性非言语上下文嵌入到大型语言模型（LLM）对话中，无需用户显式控制，而是以不显眼的方式增强文本输入的情感信息，实现对话的流畅性和一致性。该架构是模块化的和可扩展的，可以方便地添加其他非言语模块。
### Conclusion
这项研究表明，非言语输入可以一致地整合到连贯的LLM输出中，参与者也强调了对话的流畅性。Empathic Prompting框架不仅证明了概念的可行性，而且预示着在医疗服务、教育等领域作为聊天机器人中介通信的应用潜力，其中用户的情感信号至关重要但往往在口头交流中是不透明的。
## 153. `cs.AI` - 大型推理模型作为翻译评估器的效果如何？分析与性能提升 [PDF](https://arxiv.org/pdf/2510.20780), [HTML](https://arxiv.org/abs/2510.20780)
### Authors
Runzhe Zhan,Zhihong Huang,Xinyi Yang,Lidia S. Chao,Min Yang,Derek F. Wong
### Background
大型推理模型（LRMs）最近的进展引入了在生成最终答案之前的中介“思考”过程，提升了它们在复杂下游任务中的推理能力。然而，LRMs在机器翻译（MT）质量评估中的潜力尚未充分发掘。
### Innovation
该研究首次系统分析了LRM作为MT评估器的效果。作者提出通过训练LRMs以合成、类似人类的思考轨迹来调整它们的思考过程。实验结果表明，这种方法可以将“思考”预算大幅减少约35倍，同时在不同LRM规模上提高了评价性能（例如，R1-Distill-Qwen-7B的精度提升了8.7点）。
### Conclusion
这些发现强调了高效校准的LRMs在精细自动MT评估中的潜力。
## 154. `cs.AI` - 多智能体合作中的思考交流 [PDF](https://arxiv.org/pdf/2510.20733), [HTML](https://arxiv.org/abs/2510.20733)
### Authors
Yujia Zheng,Zhuokai Zhao,Zijian Li,Yaqi Xie,Mingze Gao,Lizhu Zhang,Kun Zhang
### Background
自然语言虽然有助于人类合作，但由于其易失性、模糊性和间接性限制了集体智能的潜力。尽管机器不受这些限制，但大多数基于大语言模型（LLM）的多智能体系统仍然依赖自然语言，通过交换标记或其嵌入进行交流。本文提出了一种新的范式——思考交流，使智能体能够直接进行心灵交流，类似于心灵感应，以克服语言限制。在理论指导下，开发了一种框架来提取智能体的潜在思想，在通信之前将相关信息提供给智能体，以促进协作。这一框架不仅适用于LLM，还适用于所有模态，因为大多数观察数据都来自于隐式的生成过程。实验证明，该理论可在合成和真实世界基准上验证，并且展示了思考交流的协作优势。尽管利用潜在世界有很大的潜力，但许多挑战仍然无法仅通过表层观察解决，无论是在计算能力还是数据规模方面。
### Innovation
提出了思考交流的新范式，使智能体能够不依赖自然语言直接进行心灵交流；理论化了思考交流的过程，证明了在没有辅助信息的情况下可以识别出智能体间的共享和私有潜在思想；提出了提取潜在思想和分配与其相关的共享模式的框架，适用于LLM和其他模态；验证了理论在合成和真实世界基准上的有效性，展示了思考交流的协作优势。
### Conclusion
思考交流为多智能体合作提供了一种新的可能性，能够克服自然语言的限制，通过直接心灵交流促进更高效的协作。未来的研究需要进一步探索如何在实际应用中实现这一范式，以及如何处理更多的智能体和更复杂的模态。
## 155. `cs.AI` - 强化学习与消费储蓄行为 [PDF](https://arxiv.org/pdf/2510.20748), [HTML](https://arxiv.org/abs/2510.20748)
### Authors
Brandon Kaplowitz
### Background
本文探讨了强化学习如何解释经济衰退期间家庭消费行为中的两个令人困惑的现象。现有文献表明，失业家庭在受到刺激转移的影响下比拥有较高流动资产的家庭有更高的边际储蓄倾向（MPC），而且以前失业经历多的家庭在控制当前经济状况后仍然维持较低的消费水平，这是一种“伤疤效应”。作者指出，传统的基于收入风险信念更新或先验异质性的解释无法同时解释这两个现象。
### Innovation
本文通过开发一个模型，其中代理使用具有神经网络逼近的Q学习来在收入不确定性下做出消费储蓄决策，该模型克服了传统的理性预期假设。该模型能够重现近期文献中的两个关键发现：首先，没有先前高流动资产的失业家庭在面对刺激转移时的边际消费倾向显著高于拥有高流动资产的家庭（分别为0.50和0.34），即使两组家庭都没有借贷约束，这与Ganong等人（2024）的发现一致；其次，具有更多过去失业经历的家庭在控制当前经济状况后持续保持较低的消费水平，这一点由Malmendier和Shen（2024）的发现所证实。令人创新的是，该论文通过价值函数逼近误差随经验变化的机制来解释这两个现象，这种强化学习机制同时产生了较高的边际消费倾向和较低的消费水平。
### Conclusion
模拟结果显示，通过强化学习的自适应学习与实测估计结果密切相关，这表明强化学习提供的自适应学习框架能够统一解释家庭过去的经历如何影响当前的消费行为，而不仅仅是当前经济状况能预测的范围。
## 156. `cs.AI` - 针对LLM生成文本负责任性能维度的特定用例数据集 [PDF](https://arxiv.org/pdf/2510.20782), [HTML](https://arxiv.org/abs/2510.20782)
### Authors
Alicia Sagae,Chia-Jung Lee,Sandeep Avula,Brandon Dang,Vanessa Murdock
### Background
当前对于大型语言模型（LLMs）的评估方法通常集中在文本生成等高层次任务上，而缺乏针对具体AI应用场景的考量。这在评估LLMs是否具备公平性等责任AI维度方面不够充分，因为不同的应用场景中，与保护属性相关的因素的重要性可能有所不同。现有方法忽略了这些差异，使得评估不够全面和精确。
### Innovation
该研究构建了一个由真实世界应用驱动的数据集（根据产品属性列表生成平面文本产品描述），并考虑了公平属性与性别化形容词和产品类别的交叉参数，提供了涵盖丰富标记提示的资源库。这种方法能够揭示LLMs在质量、准确性、安全性和公平性方面的差异，并提出了一种特定应用场景下的LLM评估方案。
### Conclusion
本文通过提出的特定用例数据集和评估方案，详细展示了如何有效评估LLMs在负责任AI维度的表现，并为研究社区提供了实践资源和方法指导。
## 157. `cs.AI` - RAGRank：使用PageRank对抗CTI LLM管道中的中毒攻击 [PDF](https://arxiv.org/pdf/2510.20768), [HTML](https://arxiv.org/abs/2510.20768)
### Authors
Austin Jia,Avaneesh Ramesh,Zain Shamsi,Daniel Zhang,Alex Liu
### Background
Retrieval-Augmented Generation (RAG)已成为在Cyber Threat Intelligence (CTI)系统中操作化大型语言模型（LLM）使用的主要架构模式。然而，这种设计易受到投毒攻击的影响，此前提出的防御措施在CTI上下文中可能无效，因为关于新兴攻击的信息通常都是全新的，而 sophisticated 的威胁行为者能够模仿合法的格式、术语和风格。
### Innovation
本文提出了一种增强RAG防御鲁棒性的方法，通过在语料库中应用源可信度算法，以PageRank为例。实验表明，我们的算法降低了恶意文档的权威性评分，同时提高了可信内容的评分，使用了标准的MS MARCO数据集进行了定量验证。我们还展示了该算法在CTI文档和流中的原理验证性能。
### Conclusion
实验结果表明我们的算法在对抗CTI LLM管道中的投毒攻击方面是有效的。
## 158. `cs.AI` - FieldGen：从远程操作预操作轨迹到场引导数据生成 [PDF](https://arxiv.org/pdf/2510.20774), [HTML](https://arxiv.org/abs/2510.20774)
### Authors
Wenhao Wang,Kehe Ye,Xinyu Zhou,Tianxing Chen,Cao Min,Qiaoming Zhu,Xiaokang Yang,Yongjian Shen,Yang Yang,Maoqing Yao,Yao Mu
### Background
现有数据收集方法很难同时满足大规模、多样性和高质量的要求。仿真虽然能提供规模性，但存在仿真到现实的差距，而远程操作能够提供高质量的演示，但多样性和低成本受到限制。我们的论文旨在通过FieldGen场引导数据生成框架，实现低成本、高多样性和高质量的实地数据收集，同时减少人类监督。FieldGen分为前操作阶段和精细操作阶段，前一个阶段捕捉关键接触和姿势信息，后一个阶段使用吸引力场生成多样化轨迹。Remote操作记录关键操作信息，FieldGen-Reward进一步添加奖励标注，提高策略学习效果。
### Innovation
引入FieldGen框架，通过将前操作阶段和精细操作阶段解耦，实现低成本、高多样性和高质量的实地数据收集，减少人类监督。结合远程操作记录关键操作信息，并使用吸引力场生成多样化轨迹。此外，通过FieldGen-Reward为生成的数据添加奖励标注，进一步提高学习策略的效果。
### Conclusion
通过使用FieldGen框架，训练出来的策略在成功率和稳定性上优于基于远程操作的基线方法，同时显著降低了远程收集实地数据的人力成本。
## 159. `cs.AI` - 简单的上下文压缩：均值池化和多比率训练 [PDF](https://arxiv.org/pdf/2510.20797), [HTML](https://arxiv.org/abs/2510.20797)
### Authors
Yair Feldman,Yoav Artzi
### Background
在使用大规模语言模型（LLMs）和检索增强生成（RAG）处理长上下文时，常用的一种减少计算成本的策略是软上下文压缩，即将输入序列转换为一个较短的连续表示。该项研究旨在开发一种轻量级、简单且高效的均值池化方法，该方法在多项实验中表现优于常用的方法，如压缩标记架构。研究还探讨了对同一个压缩器进行多种压缩比例的训练，并进行了广泛的实验，横跨领域内和领域外的问答数据集、不同模型家族、规模和压缩比例。
### Innovation
研究开发了一种轻量级简单的均值池化方法，该方法在实验中展现出更优的表现，同时研究了同一压缩器进行多种压缩比例的训练，展示了压缩方法的复杂性。
### Conclusion
在不同领域、不同模型家族和不同压缩比例上进行的广泛实验表明，简单的均值池化方法表现最强，即使训练时设置多个压缩比例，性能下降也非常小。但总体而言，不同的架构和训练方法间存在复杂的权衡关系。
## 160. `cs.AI` - 利用球面图神经网络从CMB推断原初磁场参数的贝叶斯推理 [PDF](https://arxiv.org/pdf/2510.20795), [HTML](https://arxiv.org/abs/2510.20795)
### Authors
Juan Alejandro Pinto Castro,Héctor J. Hortúa,Jorge Enrique García-Farieta,Roger Anderson Hurtado
### Background
深度学习已成为现代宇宙学中一种变革性的方法，为从复杂天文数据集中提取有意义的物理信息提供了强大的工具。本文采用了一种新颖的贝叶斯图深度学习框架，直接从模拟的宇宙微波背景(CMB)图中估计原初磁场（PMF）宇宙学中的关键宇宙学参数。该方法利用了DeepSphere，这是一个专门为尊重CMB数据的球面几何特性而设计的球面卷积神经网络架构，通过HEALPix像素化实现了这一点。
### Innovation
将贝叶斯神经网络（BNNs）集成到框架中以超越确定性点估计并实现鲁棒的不确定性量化。使用Variance Scaling和GPNormal等后训练技术获得校准的不确定性估计。这种方法不仅能够精确估计含有PMF贡献的CMB图中的参数，还能提供可靠的不确定性量化，从而在精确宇宙学时代为稳健的宇宙学推理提供了必要的工具。
### Conclusion
提出的框架展示了卓越的性能，磁参数估计的$R^{2}$得分超过0.89。通过后训练技术（包括Variance Scaling和GPNormal）获得校准的不确定性估计，该集成的DeepSphere-BNNs框架在CMB图中提供了准确的参数估计和可靠的不确定性量化。
## 161. `cs.AI` - Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples [PDF](https://arxiv.org/pdf/2510.20800), [HTML](https://arxiv.org/abs/2510.20800)
### Authors
Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus
### Background
Sharma等人提出了一种称为Layer-SElective-Rank reduction (LASER)的方法，表明在精心选择的LLM权重矩阵中剪枝高阶组件可以提升下游任务的准确性，而无需基于梯度的微调。然而，LASER方法由于每个矩阵都需要完整的数据前向传递进行全面搜索，使得这种方法不适用于快速部署。
### Innovation
该研究通过以下创新去除LASER方法的高开销，并发现：(i)仅需要仔细选择的一小部分矩阵进行检查，消除了逐层扫描的过程，(ii) 每个矩阵的奇异值导数指出哪些矩阵值得进行减少，(iii) 通过允许矩阵行聚集在多个亚空间并分别分解每个集群来增加因式分解搜索空间，进一步减少了对原始训练数据的过拟合，并进一步提高了24.6%的准确性，(iv) 对100个样本而非完整训练数据进行评估（用于计算指示性梯度和测量最终准确性），以进一步减少搜索时间。结果，展示了一种快速且稳健的下游任务适应算法。
### Conclusion
该研究通过单个梯度步长和一次对100个样例的快速扫描，可以无微调地使LLM适应新的数据集。
## 162. `cs.AI` - 机器人现实鸿沟：挑战、解决方案与最佳实践 [PDF](https://arxiv.org/pdf/2510.20808), [HTML](https://arxiv.org/abs/2510.20808)
### Authors
Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos
### Background
机器学习在机器人学的不同领域如导航、运动和操控方面推动了显著进步，这些进步很多时候依赖于仿真作为训练和测试机器人系统的关键工具。然而，仿真模拟伴随着近似和抽象，会导致模拟环境与实际环境之间的差异，称为现实鸿沟，这种差异严重阻碍了从仿真向现实世界的顺利过渡。近年来，许多研究通过利用领域随机化、现实到仿真的迁移、状态和动作抽象以及仿真与现实的联合训练等技术，缓解了这一差距，但还需进一步理解其根本原因和解决方案。
### Innovation
本文综述了从仿真到现实的迁移场景，详细概述了现实鸿沟的原因、解决方案及评估指标。通过探讨各种平台（如导航、运动和操控）上的最新进展，为解决现实鸿沟提供了全面的视角，并提出了进一步研究的方向。
### Conclusion
本文总结了机器人现实鸿沟的现状，强调了应用领域随机化、现实到仿真、状态和动作抽象以及仿真与现实联合训练方法的重要性。同时指出，未来还需要深入研究现实鸿沟的根本原因，并提出相应的改进措施，以促进从仿真到现实世界的平滑过渡。
## 163. `cs.AI` - MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning [PDF](https://arxiv.org/pdf/2411.12977), [HTML](https://arxiv.org/abs/2411.12977)
### Authors
Mircea Lică,Ojas Shirekar,Baptiste Colle,Chirag Raman
### Background
基于大型语言模型（LLMs）的具身代理，如Voyager，在Minecraft等世界中展示了开放性的能力。然而，即使进行了领域特定的微调，这些基于预训练模型的具身代理仍然在基础任务上表现不佳。针对这一问题，本文提出了MindForge这一框架，通过显式视角推理来推动文化终身学习。
### Innovation
MindForge的关键创新包括：(1) 结构化的理论模型表示，将感知、信念、欲望和行为联系起来；(2) 自然的代理间通信；(3) 多组件记忆系统。
### Conclusion
通过在Minecraft中的文化学习框架进行测试，MindForge在指导设置中显著提高了使用预训练大语言模型的具身代理在基本任务上的表现，同时在完全协作的设置中，随着通信轮次的增加，两个表现不佳的代理表现得到了改进，这与Condorcet投票定理相呼应。此外，MindForge展示了复杂的行为，包括专家与新手之间的知识转移、合作问题解决以及通过积累的文化经验适应该分布外任务的能力。
## 164. `cs.AI` - 基于对比和预测的隐空间扩散桥梁模型通向通用模态翻译 [PDF](https://arxiv.org/pdf/2510.20819), [HTML](https://arxiv.org/abs/2510.20819)
### Authors
Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot
### Background
生成建模的最新进展将扩散模型置于从复杂数据分布中采样的最先进技术之列。尽管这些模型在单一模态领域（如图像和音频）取得了显著的成功，但在跨越不同感觉模态的模态转化（MT）能力上仍然存在挑战。现有的方法常常依赖于共享维度、高斯先验和模态特定的架构等限制性假设，这限制了它们的通用性和理论基础。
### Innovation
本文提出了一种基于隐变量扩展的去噪扩散桥模型（LDDBM）的通用模态翻译框架。它通过在共享隐空间中操作，避免了对齐维度的需求，学习任意模态之间的桥梁。该模型通过对比对齐损失强制约束配对样本之间的语义一致性，并设计了一个适用于隐空间中的噪声预测的域泛化编码器-解码器架构。此外，还提出了预测损失以指导训练向准确的跨领域转化，并探索了几种训练策略以提高稳定性。
### Conclusion
我们的方法支持任意模态对，并在多样化的模态转化任务（如多视图到3D形状生成、图像超分辨率和多视图场景合成）中表现出色。全面的实验证据和消融实验验证了该框架的有效性，为通用模态翻译建立了新的强基准。
## 165. `cs.AI` - 小草稿，大裁决：通过猜测实现密集信息视觉推理 [PDF](https://arxiv.org/pdf/2510.20812), [HTML](https://arxiv.org/abs/2510.20812)
### Authors
Yuhan Liu,Lianhui Qin,Shengjie Wang
### Background
大规模的视觉语言模型（VLMs）在多模态理解方面取得了显著进展，但在处理稠密地将文本注释与细粒度图形元素交织在一起的复杂图像时，它们表现不佳。主要挑战在于在密集布局中精确定位关键线索以及多跳推理以整合分散的证据。
### Innovation
提出了Speculative Verdict（推测裁决，SV）框架，这是一种无需训练的框架，结合了多个轻量级草稿专家和一个大型裁决模型。草稿阶段，小型VLM作为草稿专家生成提供多种定位候选的推理路径；判决阶段，强大的VLM整合这些路径以生成最终答案，以最小化计算成本同时恢复正确的答案。此外，SV引入了一种共识专家选择机制，仅将高一致性的推理路径转发给最终裁决，以进一步提高效率和准确性。
### Conclusion
实验证明，SV在具有挑战性的信息密集和高分辨率视觉问答基准测试（包括InfographicVQA、ChartMuseum、ChartQAPro和HR-Bench 4K）上实现了持续的改进。通过从多个部分准确的推理路径中综合正确的见解，SV在纠正错误和提高效率方面优于大型专有模型或训练管线。
## 166. `cs.AI` - VAMOS: A Hierarchical Vision-Language-Action Model for Capability-Modulated and Steerable Navigation [PDF](https://arxiv.org/pdf/2510.20818), [HTML](https://arxiv.org/abs/2510.20818)
### Authors
Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta
### Background
机器人的导航面临一个基本挑战，即学习能够在多种环境之间泛化的策略，同时又符合特定载体的独特物理约束和能力。VAMOS通过将语义规划与载体特性分离，提供了一种解决方法。它利用机器人在安全且低成本的模拟环境中学习其物理限制，从而能够在不同的载体之间实现导航任务。
### Innovation
VAMOS提出了一个分层的视觉-语言-行动模型，将通用规划者从多样化的开放数据中学习出的策略与机器人具体物理特性的专门模型区分开来。通过在图像空间中直接提出候选路径，高级规划者可以将这些路径传递给专用模型进行评估和重新排序，从而实现不同类别机器人跨载体的导航能力。
### Conclusion
VAMOS在室内和复杂室外导航任务中显示出更高的成功率，优于最新的基于模型和端到端学习方法。其分层设计使得不同类型的载体之间可以互换，并且可以通过自然语言轻松调整。实验还表明，专门模型是实现载体特异性导航的关键，单个高级规划者可以应用于物理上不同的轮式和腿足机器人。此外，该模型通过拒绝物理上不可行的策略，显著提高了单个机器人的可靠性，成功率提高了3倍。
## 167. `cs.AI` - GSWorld：用于机器人操作的闭环写实模拟套件 [PDF](https://arxiv.org/pdf/2510.20813), [HTML](https://arxiv.org/abs/2510.20813)
### Authors
Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang
### Background
当前，机器人操作需要高度逼真的模拟环境，以促进算法的训练和测试，特别是用于从实际机器人数据中学习的策略。传统的模拟器往往缺乏物理准确性和逼真度，这限制了它们在机器人操作中的应用。此外，实现从仿真到现实的直接迁移也是一个挑战。为了解决这些问题，本文提出了GSWorld，这是一种集成了3D高斯绘制与物理引擎的机器人操纵模拟器，能够创建高质量的逼真场景，并支持闭环开发环境中的策略学习和迁移，无需使用真实的机器人。
### Innovation
本文的主要创新在于提出了一个新的资产格式，即GSDF（Gaussian Scene Description File），它结合了机器人URDF和其他物体的高斯网格表示，以实现多样场景的高质量渲染。得益于简化了的重建管道，数据库中包含3种单臂和双臂操作的机器人实体，以及超过40种不同物体。通过GSDF与物理引擎的结合，本研究展示了几个即时有趣的应用实例，包括：从写实渲染学习零样本仿真实现实策略，自动化高质量的DAgger数据收集以适应部署环境，确保实际机器人操纵策略的重现基准测试以及通过虚拟远程操作收集仿真数据，还有零样本逆向视觉强化学习等。
### Conclusion
综上所述，GSWorld是一个为机器人操作设计的高度复现和物理准确的模拟框架，实现了从仿真到行为的直接迁移，提高了数据收集的效率，并支持实验室环境下的闭环策略开发和测试。这种组合技术有望改进机器人操作策略的有效开发和实现实现。
## 168. `cs.AI` - MIR-Bench: 你的大语言模型能否通过多例情景推理识别复杂模式？ [PDF](https://arxiv.org/pdf/2502.09933), [HTML](https://arxiv.org/abs/2502.09933)
### Authors
Kai Yan,Zhan Ling,Kang Liu,Yifan Yang,Ting-Han Fan,Lingfeng Shen,Zhengyin Du,Jiecao Chen
### Background
模式识别和应用的能力是通用人工智能的基础，心理学和人工智能研究人员广泛探讨这一主题。虽然已经提出了许多基准来衡量大型语言模型（LLMs）的这种能力，但这些基准主要关注少量示例（通常少于10个）的情况，并且缺乏对从长上下文中整合大量信息的评估。另一方面，LLMs不断增长的上下文字长引发了新的多例情景学习（ICL）范式，该范式能够以数百到数千个示例解决新任务，而不需昂贵且低效的微调。然而，多例评价往往集中在分类任务上，而流行的大上下文LLMs任务如Needle-In-A-Haystack（NIAH）通常不需要复杂的智能来整合大量信息。
### Innovation
本文提出了MIR-Bench，这是第一个针对多例情景推理的模式识别基准，它要求LLMs通过输入-输出示例来预测来自具有多样数据格式的基础函数的输出。基于MIR-Bench，研究了多种新的多例情景推理问题，并获得了诸如规模效应、鲁棒性、归纳推理与演绎推理、检索增强生成（RAG）、编码以促进归纳推理、跨域泛化等许多有意义的发现。
### Conclusion
通过MIR-Bench，研究了多种新颖的多例情景推理问题，并从多个方面得出了深刻的见解，包括规模效应、鲁棒性、归纳推理与演绎推理、检索增强生成（RAG）、编码以促进归纳推理、跨域泛化等。
## 169. `cs.AI` - RL是否真的激励LLMs超过基模型的推理能力？ [PDF](https://arxiv.org/pdf/2504.13837), [HTML](https://arxiv.org/abs/2504.13837)
### Authors
Yang Yue,Zhiqi Chen,Rui Lu,Andrew Zhao,Zhaokai Wang,Yang Yue,Shiji Song,Gao Huang
### Background
最近，RLVR（可验证奖励的强化学习）在提升大型语言模型（LLM）的推理性能上取得了显著成效，特别是在数学和编程任务上。RLVR被认为能促使LLM持续自我提升，获得超越基模型的新推理能力。然而，该研究通过系统性地探索不同模型家族、RL算法及数学、编程和视觉推理基准上的RLVR训练模型的能力边界，发现当前训练设置并未产生根本性的新推理模式。尽管RLVR训练的模型在小k值（如k=1）上优于其基模型，但在大k值时，基模型的表现更好。进一步分析揭示，观察到的推理能力来源于基模型，且受到基模型的限制。多种流行的RLVR算法未能充分利用基模型的潜力，而蒸馏则能引入新的推理模式并真正扩展模型的推理能力。这些结果表明，当前的RLVR方法尚未实现RL激励LLM产生真正新推理能力的潜力，暗示需要改进的RL范式以解锁这一潜力。
### Innovation
该研究通过使用较大k值的通过率评估方法，系统地检验了不同模型家族、RL算法及数学、编程和视觉推理基准上的RLVR训练模型的能力边界。研究展示了一种与基模型紧密相关的新发现，即尽管RLVR在某些任务上表现出色，但在大k值上的表现仍然受基模型限制。此外，研究还揭示了通过蒸馏可以引入新的推理模式，真正扩展模型的推理能力，这为探索新的RL范式提供了方向，这与当前RLVR方法相比具有创新性。
### Conclusion
当前的RLVR方法尚未实现RL潜力来激励LLM产生真正新推理能力，强调需要改进的RL方法，如持续扩展模型的训练和多轮交互以解锁这一潜力。
## 170. `cs.AI` - 停止求和：过程奖励模型所需的最小形式信用分配 [PDF](https://arxiv.org/pdf/2504.15275), [HTML](https://arxiv.org/abs/2504.15275)
### Authors
Jie Cheng,Gang Xiong,Ruixi Qiao,Lijun Li,Chao Guo,Junle Wang,Yisheng Lv,Fei-Yue Wang
### Background
过程奖励模型（PRMs）在大型语言模型（LLMs）的挑战性推理任务测试时扩展中表现有效。然而，PRMs存在奖励作弊问题，限制了它们在强化学习微调中的广泛应用。原因在于强化学习（RL）中常用的累加形式的信用分配会导致LLMs为高奖励步骤作弊。本研究旨在解决这一问题。
### Innovation
提出了PURE（过程监督强化学习），该方法采用最小形式的信用分配，将价值函数定义为未来奖励的最小值。这种方法通过限制价值函数范围和更合理地分配优势，显著缓解了奖励作弊问题。实验结果表明，采用最小形式信用分配的PRM方法在仅30%的步骤内即可达到与可验证奖励基线方法相当的表现。此外，结合10%的可验证奖励， PURE方法进一步缓解了奖励作弊，提高了Qwen2.5-Math-7B模型在AMC23等5个基准测试上的表现，准确率分别达到82.5%和53.3%。
### Conclusion
该研究详细分析了奖励作弊现象及其原因，并总结了训练崩溃的案例。提出了PURE方法，成功解决了PRM奖励作弊问题，通过简化模型在多个基准测试中达到了卓越表现。该方法通过机制设计有效提升了模型性能。研究代码和模型权重已公开。
## 171. `cs.AI` - 基于集成学习的大规模多元建筑HVAC控制的机器学习模型预测控制途径 [PDF](https://arxiv.org/pdf/2505.02439), [HTML](https://arxiv.org/abs/2505.02439)
### Authors
Yang Deng,Yaohui Liu,Rui Liang,Dafang Zhao,Donghua Xie,Ittetsu Taniguchi,Dan Wang
### Background
建筑热力学模型能够实时预测在潜在HVAC控制操作下的室内温度变化，这对于优化建筑HVAC控制至关重要。虽然早期的研究已经尝试为各种建筑环境开发这类模型，但这些模型通常需要长时间的数据收集，并且高度依赖专家知识，这使得模型开发过程效率低下，限制了模型的重用。
### Innovation
本文提出了一种基于集成学习的观点，利用已有的基模型为特定的建筑环境提供准确的预测，同时减少了相关的工作量。为了解决建筑数据流的非平稳性以及基模型数量可能增加的问题，本文提出了一种层次强化学习（HRL）方法，通过两级决策过程动态选择和加权基模型。高层专注于模型选择，而低层确定所选模型的权重。
### Conclusion
通过离线实验和现场案例研究对提出的方法进行了全面评估，实验结果展示了该方法的有效性。
## 172. `cs.AI` - 关于LLM生成文本的可检测性：究竟什么是LLM生成的文本？ [PDF](https://arxiv.org/pdf/2510.20810), [HTML](https://arxiv.org/abs/2510.20810)
### Authors
Mingmeng Geng,Thierry Poibeau
### Background
随着大规模语言模型（LLMs）的广泛使用，许多研究人员开始关注检测由它们生成的文本。然而，‘LLM生成的文本’这一目标并没有一致或精确的定义。使用场景的不同和LLMs的多样性增加了检测的难度。常见的检测目标通常仅为LLMs潜在生成文本的一个子集，且人类编辑LLM输出以及LLMs对用户微妙的影响正在模糊LLM生成文本和人类撰写的文本之间的界限。现有的基准测试和评估方法未能充分解决实际检测器应用中的各种情况，导致检测器的结果常被误解，其重要性也在下降。
### Innovation
本文提出了对于‘LLM生成的文本’明确的定义问题的认识，并指出现有基准测试和评估方法的不足之处，强调了在特定条件下的检测器结果仅供参考，而非决定性指标。
### Conclusion
检测器在特定条件下仍然有用，但结果应仅作为参考而非决定性指标。
## 173. `cs.AI` - Prover Agent: 基于代理的框架用于形式数学证明 [PDF](https://arxiv.org/pdf/2506.19923), [HTML](https://arxiv.org/abs/2506.19923)
### Authors
Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai
### Background
本文介绍了一个名为Prover Agent的新颖AI代理，它将大型语言模型（LLMs）与形式证明助手Lean集成起来。Prover Agent协调非形式化的推理LLM、正式证明模型，并从Lean获取反馈，同时也自动生成辅助引理。这些辅助引理不限于正式证明中的子目标，还可能包括从假设中推导出来的特殊情况或可能有用的事实，以发现可行的证明策略。
### Innovation
Prover Agent实现了在MiniF2F基准测试中88.1%的成功率，这是利用小型语言模型（SLMs）的方法中的新最先进水平，并且相比于以前的方法使用了显著较少的样本预算。同时，文章还提供了理论分析和案例研究，展示了这些生成的引理如何有助于解决复杂问题。
### Conclusion
研究表明，Prover Agent通过其独特的功能，不仅能够生成辅助引理提高证明成功率，并且建立了使用小型语言模型的新的成功标准，与此同时，还提供了理论依据和实践案例来证明其方法的有效性。
## 174. `cs.AI` - SAFEPATH：早期对齐防止链式推理中的有害内容 [PDF](https://arxiv.org/pdf/2505.14667), [HTML](https://arxiv.org/abs/2505.14667)
### Authors
Wonje Jeung,Sangyeon Yoon,Minsuk Kahng,Albert No
### Background
大型推理模型（LRMs）在解决复杂问题方面变得越来越强大，但由于其结构化推理路径，在暴露于有害提示时可能会产生不安全的输出。现有的安全对齐方法可以减少有害输出，但可能导致推理深度下降，在复杂多步骤任务中存在显著的权衡，并且仍然容易受到高级‘监狱逃脱’攻击。
### Innovation
本文介绍了一种名为SAFEPATH的轻量级对齐方法，这种方法可以在LRMs面对有害提示时在推理开始时自动生成一个8个标记的Safety Primer作为响应，从而在保留推理性能的同时减少有害输出。SAFEPATH方法在多个基准测试中的结果表明，与直接拒绝和SafeChain相比，其计算需求分别降低了295.9倍和314.1倍，减少了高达90.0%的有害响应，并成功阻止了83.3%的‘监狱逃脱’尝试。此外，还引入了零样本变体，无需微调。
### Conclusion
SAFEPATH成功地减少了有害输出，同时保持了推理性能。此外，这项研究揭示了现有方法在应用到推理中心模型时的局限性，指出安全AI的重要缺口和新方向。
## 175. `cs.AI` - 隐私风险与保存方法在可解释人工智能中的研究: 一项范围性回顾 [PDF](https://arxiv.org/pdf/2505.02828), [HTML](https://arxiv.org/abs/2505.02828)
### Authors
Sonal Allana,Mohan Kankanhalli,Rozita Dara
### Background
解释性人工智能（XAI）作为可信赖人工智能的支柱，旨在为复杂的、原本不透明的模型增加透明度。尽管在模型中加入解释有很多好处，但发现了一个亟待解决的问题，即提供这些额外信息时必须考虑终端用户的隐私保护。本文通过范围性回顾现有文献，旨在探讨隐私与解释之间的冲突。我们从2019年1月至2024年12月发表的1,943项研究中筛选出57篇文章，提出了三个研究问题，以帮助读者更好地理解该主题：(1) 在人工智能系统中发布解释存在哪些隐私风险？(2) 研究人员目前采用了哪些方法来实现XAI系统的隐私保护？(3) 什么样的解释才算是隐私保留的解释？
### Innovation
本文通过范围性回顾，系统地分析和分类了隐私风险和保存方法在解释性人工智能中的应用。同时，基于选定研究的汇总知识，提出了隐私保留解释的特征，这有助于研究人员和从业者更好地理解符合隐私要求的可解释人工智能的要求。此外，本文还指出了在平衡隐私与其他系统需求时面临的挑战，并提供了一些建议来实现隐私保留的XAI。
### Conclusion
本文预期将照亮隐私和解释之间的复杂关系，两者都是可信赖人工智能的基本原则。研究结果强调了隐私保留的可解释人工智能发展的必要性和重要性，同时也指明了这一领域的潜在研究方向和改进空间。
## 176. `cs.AI` - 思考更多总是有帮助吗？推理模型测试时扩展思维的幻象 [PDF](https://arxiv.org/pdf/2506.04210), [HTML](https://arxiv.org/abs/2506.04210)
### Authors
Soumya Suvra Ghosal,Souradip Chakraborty,Avinash Reddy,Yifu Lu,Mengdi Wang,Dinesh Manocha,Furong Huang,Mohammad Ghavamzadeh,Amrit Singh Bedi
### Background
最近，测试时扩展模型推理路径（例如，OpenAI o1，DeepSeek R1）的趋势导致了一个普遍的认知，即使用提示如“等待”或“让我再想一下”可以提升性能。因此，自然而然地引起了人们的疑问：测试时更深入的思考是否会真正提升推理效果？针对这一问题，研究表明，虽然最初的推理性能有所提升，但随后因“过度思考”而下降。这一非单调趋势表明，额外的思考增加了输出的变异，虽然表面上看起来提升了推理效果，但实际上是降低了精确度。
### Innovation
为了理解这一现象，作者提出一个简化的概率模型来揭示语言模型为什么不准确的提升推理效果。这是由于模型的不确定性与评估指标的连接性所致。论文还提出了一个替代的测试时扩展方法——并行思考，受Best-of-N抽样的启发，这种新方法在相同的推理预算中生成多个独立推理路径，并通过多数投票选择最一致的响应，从而实现了20%的更高准确性，相比扩展思考更为有效。
### Conclusion
这项研究揭示了测试时利用扩展思考预算进行推理扩展的有效性存在局限性。提出了并行思考作为替代方法，能够实现更高的准确性，提供了一个简洁而有效的推理模型测试时扩展机制。
## 177. `cs.AI` - 玩个游戏怎么样？语言模型在开放式战略模拟游戏中的应用 [PDF](https://arxiv.org/pdf/2509.17192), [HTML](https://arxiv.org/abs/2509.17192)
### Authors
Glenn Matlin,Parv Mahajan,Isaac Song,Yixiong Hao,Ryan Bard,Stu Topp,Evan Montoya,M. Rehan Parwani,Soham Shetty,Mark Riedl
### Background
战略模拟游戏是参与者决策影响未来事件的模拟冲突。严肃的战略模拟游戏被专家用于探索决策的战略影响和体验式学习。军事组织已经开始使用语言模型（LMs）来提供关于真实世界决策后果的见解，特别是在开放式战略模拟游戏中使用自然语言传达行动和结果。在此之前，AI系统在战略规划方面的表现接近甚至超过了人类专家的能力。
### Innovation
本研究提出了通过语言模型进行开放式战略模拟游戏中的应用。这不仅提出一个关于AI系统的战略规划能力的观点，还构建了一个关于开放式战略模拟游戏的新颖的本体论，考虑了玩家、裁判和观察者提供的创意空间，并从中提炼出适用于各种领域的实际建议和关键安全考虑事项。特别地，研究强调了对开放式战略模拟游戏中AI系统的安全、可解释性和可说明性进行进一步研究所的重要性。
### Conclusion
研究最后提出了未来工作中的关键研究挑战，这些挑战具有高影响，以推动开放式战略模拟游戏领域中AI技术的进一步发展。
## 178. `cs.AI` - 从经验中学：一种代码LLM的多智能体框架以学习和改进 [PDF](https://arxiv.org/pdf/2505.23946), [HTML](https://arxiv.org/abs/2505.23946)
### Authors
Yuanzhe Liu,Ryan Deng,Tim Kaler,Xuhao Chen,Charles E. Leiserson,Yao Ma,Jie Chen
### Background
近年来的研究显示，大语言模型（LLMs）在不同的技能上表现不一，专门化于不同类型的任务。研究观察到这些模型的性能在不同粒度级别上有所不同。例如，在代码优化任务中，代码LLMs在不同的优化类别中表现出色，且没有一个类别可以完全主导其他类别。这引发了如何在不知道每个模型的互补优势的情况下利用多个LLM解决编程问题的问题。
### Innovation
本文提出了一种基于经验的多智能体协作框架，旨在通过让智能体之间学习彼此的成功和失败来提高自己的性能。该框架设计了一种经验请求-银行-选择机制来促进这种知识的传递。实验结果显示，由小型LLM组成的学习了经验的团队能够超越一个较大的LLM和其他多LLM协作方法。
### Conclusion
研究提出了一种基于经验的方法，利用该方法，小型且多智能体的LLM团队通过学习彼此的成功和失败可以在代码优化任务上超过更大的LLM，展示了一种有效的多智能体协作方法。
## 179. `cs.AI` - RADAR: 一种通过角色专业化协作实现LLM安全性评估的感知风险动态多智能体框架 [PDF](https://arxiv.org/pdf/2509.25271), [HTML](https://arxiv.org/abs/2509.25271)
### Authors
Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li
### Background
现有的大型语言模型的安全评估方法存在固有的局限性，包括评估者偏见和由于模型同质性引起检测失败等问题，这些问题共同削弱了风险评估过程的稳健性。现有方法无法全面覆盖显性和隐性风险，并且容易受到评估者偏见的影响。本文重新审视风险评估范式，通过引入一个新的理论框架对潜在的风险概念空间进行重构，将潜在的风险概念空间分解为三个互斥的子空间：显性风险子空间、隐性风险子空间和非风险子空间。在此基础上提出了一种多智能体协作评估框架RADAR，该框架采用多轮辩论机制并通过四种专业化互补角色进行协作，并通过动态更新机制实现风险概念分布的自我进化，从而全面覆盖显性和隐性风险并缓解评估者偏见。
### Innovation
引入了一个全新的理论框架，将潜在的风险概念空间分解为显性风险子空间、隐性风险子空间和非风险子空间；提出了一个多智能体协作评估框架RADAR，基于角色专业化分工进行协作，并采用了多轮辩论机制和动态更新机制，以实现自我进化和风险概念分布的优化。
### Conclusion
实验验证了RADAR框架的有效性，该框架在准确度、稳定性和自我评估风险敏感性等多个维度上显著优于基线评估方法。特别是，RADAR在风险识别精度上相比最强基线评估方法提高了28.87%。
## 180. `cs.AI` - GTAlign：通过博弈论对LLM助手进行相互福利的对齐 [PDF](https://arxiv.org/pdf/2510.08872), [HTML](https://arxiv.org/abs/2510.08872)
### Authors
Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You
### Background
大型语言模型（LLMs）在推理方面取得了显著进步，但有时会生成对用户在写作、信息查询或提供实际指导等任务中的响应不佳。传统的对齐方法通常假设最大化模型奖励也能最大化用户福利，但这种假设在实践中经常失败：模型可能过度详细解释或生成过于冗长的推理过程，而用户更倾向于简洁的答案。这类行为类似于囚徒困境，个人理性选择会导致社会次优结果。根本挑战在于缺乏一个能在LLM和用户之间建立双赢机制的决策机制。因此，本文提出了一种博弈论对齐（GTAlign）框架，将博弈论决策融入推理和训练过程，以改进这类问题。
### Innovation
GTAlign框架将博弈论决策整合进推理和训练过程。在推理过程中，模型将用户-LLM交互视为一个战略博弈，构建收益矩阵来估算双方的福利，并选择双方都有利的选择。在训练过程中引入了一个相互福利奖励，以强化合作性响应，使模型行为与社会高效的成果相一致。此外，还引入了一种利用博弈论推理优化的推理技术，根据LLM服务的定价政策变化动态适配模型的响应方式。实验结果表明，与基线相比，GTAlign在多种任务中显著提高了推理效率、答案质量和双方的福利。
### Conclusion
GTAlign在多种任务中显著提高了对齐LLM的推理效率、答案质量以及双方的福利，通过引入博弈论决策机制，有效克服了传统方法在处理LLM和用户之间利益冲突时的不足。实验结果证明了该方法的有效性，并在[提供链接]处提供了代码，便于进一步研究和应用。
## 181. `cs.AI` - EA4LLM：通过进化算法实现大型语言模型优化的无梯度方法 [PDF](https://arxiv.org/pdf/2510.10603), [HTML](https://arxiv.org/abs/2510.10603)
### Authors
WenTao Liu,Siyu Song,Hao Hao,Aimin Zhou
### Background
近年来，大型语言模型（LLMs）取得了显著进展，模型优化主要依赖基于梯度的优化器，如Adam。然而，这些基于梯度的方法对硬件有严格的限制，需要高并发、高记忆的GPU，并且要求所有神经网络操作都可微分，从而排除了很多有潜力的非可微分架构的实际应用。
### Innovation
我们提出了EA4LLM，这是一种使用进化算法优化LLMs的方法，并首次实证验证了从预训练阶段开始对不同规模模型（从0.5B到32B）进行全面参数优化。我们的工作挑战了基于梯度优化是唯一可行的神经网络训练方法的假设，并且有可能降低训练大型语言模型的计算成本，从而使计算资源有限的团队也能参与深度学习研究。
### Conclusion
我们的研究结果挑战了基于梯度优化是唯一可行的神经网络训练方法的假设，展示出进化算法在优化神经网络方面的有效性和潜力，有助于解决基于梯度优化方法的严格硬件需求，并为计算资源有限的研究团队提供了优化大型语言模型的替代方案。
## 182. `cs.AI` - BuildArena: 用于工程建筑的LLM物理对齐交互基准 [PDF](https://arxiv.org/pdf/2510.16559), [HTML](https://arxiv.org/abs/2510.16559)
### Authors
Tian Xia,Tianrun Gao,Wenhao Deng,Long Wei,Xiaowei Qian,Yixian Jiang,Chenglei Yu,Tailin Wu
### Background
工程建筑自动化旨在将自然语言规范转化为实际可行的结构，需要在严格的物理约束下进行复杂的综合推理。尽管现代大型语言模型（LLM）具备广泛知识和强大的推理能力，使其成为这一领域有前途的候选对象，但它们在建筑领域的应用尚处于未验证状态。为了填补这一空白，本文引入了一个名为BuildArena的新基准，这是首个针对语言驱动工程建筑的物理对齐交互基准，旨在评估LLM的能力。
### Innovation
1. 提供一个高度可定制的基准测试框架，用于深入比较和分析LLM；2. 设计一个扩展性强、涵盖静态和动态机械、多难度级别的任务策略；3. 提出一个支持基于语言指令的3D空间几何计算库；4. 设定一个基础的LLM代理工作流程，有效评估多种模型的能力；该基准分别在八个前沿的LLM上对语言驱动和物理接地的建筑自动化能力进行了全面评估。
### Conclusion
通过BuildArena，首次全面评估了广泛语言模型在工程建筑自动化中的表现，为这一领域的研究和应用提供了重要参考。
## 183. `cs.AI` - 在空间基础agent模型中进行气候风险评估的适应性学习：具有进化型经济代理的地理空间框架 [PDF](https://arxiv.org/pdf/2509.18633), [HTML](https://arxiv.org/abs/2509.18633)
### Authors
Yara Mohajerani
### Background
气候风险评估需要模拟空间异质性灾害与适应性经济系统之间的复杂相互作用。本文介绍了一种新的地理空间基础的agent模型，该模型将气候灾害数据与经济代理的进化学习相结合。
### Innovation
本文提出的一种框架将 Mesa 基地的空间建模与 CLIMADA 气候影响评估相结合，引入适应性学习行为，使企业能够通过基于适应性的选择和突变来进化预算分配、定价、工资和风险适应策略。
### Conclusion
通过使用 RCP8.5 下直到 2100 年的河流洪水预测，本文表明，通过进化适应，企业可以在数十年的气候压力中断后逐渐恢复到基线生产水平。结果揭示了系统性风险，即使未直接暴露于洪水中的代理也会通过供应链中断而受到影响。到本世纪末，在我们所展示的经济网络中，货物的平均价格在 RCP8.5 场景下比基线高出 5.6%。本开源框架为金融机构和公司提供了量化直接和二级气候风险的工具，并评估经济有效的适应策略。
## 184. `cs.AI` - 为多智能体强化学习设计的目标干预原则 [PDF](https://arxiv.org/pdf/2510.17697), [HTML](https://arxiv.org/abs/2510.17697)
### Authors
Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang
### Background
在大规模的多智能体强化学习（MARL）中，直接从人类获取全局指导是不现实的，因此需要设计外部机制（如内在奖励和人类反馈）来协调智能体，但这些机制目前主要是基于经验研究，缺乏一个易于使用的研究工具。研究背景是在这种情况下，使用多智能体影响图（MAIDs）作为一个图形框架来解决这些问题。
### Innovation
提出了多智能体干预（Targeted Intervention）的MARL交互范式，并引入了因果推理技术（称为预策略干预PSI）来实现这一范式。通过MAIDs，可以实现复合期望结果，即综合主要任务目标和额外期望结果，并强调MAIDs的综合相关性图分析工具，以评估MARL学习范式的可行性。
### Conclusion
实验结果证实了我们提出的多智能体干预的有效性，并验证了相关图分析的结果。
## 185. `cs.AI` - 通过主动试验选择实现及时临床诊断 [PDF](https://arxiv.org/pdf/2510.18988), [HTML](https://arxiv.org/abs/2510.18988)
### Authors
Silas Ruhrberg Estévez,Nicolás Astorga,Mihaela van der Schaar
### Background
近年来，机器学习（ML）在支持临床诊断方面引起了越来越多的兴趣，但大多数方法依赖于静态、完全观测的数据集，未能反映临床医生在实际工作中所用的序列化、资源意识推理。诊断过程依然复杂且容易出错，尤其是在高压或资源有限的情况下，这突显出需要帮助临床医生做出及时和成本效益高的决策的框架的必要性。
### Innovation
我们提出了ACTMED（基于模型实验设计的自适应临床测试选择）诊断框架，该框架结合了贝叶斯实验设计（BED）和大型语言模型（LLMs），更好地模拟了现实世界的诊断推理。在每一步中，ACTMED都会选择预期能够最大程度降低患者诊断不确定性的测试。LLMs充当灵活的模拟器，生成可能的患者状态分布并支持信念更新，而无需特定于任务、结构化的训练数据。临床医生可以保持在环中，审查测试建议，解释中间输出，并在整个过程中应用临床判断。
### Conclusion
我们在实际数据集上评估了ACTMED，表明它可以优化测试选择以提高诊断准确性、可解释性和资源利用率。这代表了朝着透明、自适应和与临床医生对齐的诊断系统迈出的一步，这些系统可以泛化到不同的环境，并减少了对领域特定数据的依赖。
## 186. `cs.AI` - 大型语言模型中的反思推理的系统性失败：开放性任务揭示了错觉 [PDF](https://arxiv.org/pdf/2510.18254), [HTML](https://arxiv.org/abs/2510.18254)
### Authors
Sion Weatherhead,Flora Salim,Aaron Belbasis
### Background
现有的大型语言模型在生成推理文本和反思性文本方面做得很好，但这些模型的功能是否与人类的反思性推理相等同还是未知的。以往的研究集中在有明确外部正确性信号的封闭任务上，这使得反思似乎非常有效而掩盖了自我纠正能力的局限性。本文研究了在混合了开放性和规则约束来检验大型语言模型的反思推理能力的方法。
### Innovation
本文创新地将大型语言模型应用于开放性任务，具体要求模型自行生成科学实验测试题并对其进行修订审查，评估其反思推理能力。结果显示，模型的初期表现不佳，而反思带来的改进也非常有限，甚至有时会重复同样的错误，这表明这些改进更多来自于随机生成了有效项目，而非错误检测及原则性的、根据约束修正的方法。这揭示了当前大多数大型语言模型缺乏真正‘反思’的能力，即主动地、以目标为导向地监控并遵守约束的能力，这对于人类来说是在首次尝试时就自然具备的特性。
### Conclusion
当前大型语言模型在‘反思’环节的表现并未提供充分的证据显示其具备与人类相似的主动、目标驱动的监控机制，可以帮助模型遵守约束。在模型不具备这些机制的情况下，要实现可靠的性能需要外部结构来强制执行这些约束。
## 187. `cs.AI` - CircuitSeer: 探测LLMs中数学推理电路以挖掘高质量数据 [PDF](https://arxiv.org/pdf/2510.18470), [HTML](https://arxiv.org/abs/2510.18470)
### Authors
Shaobo Wang,Yongliang Miao,Yuancheng Liu,Qianli Ma,Ning Liao,Linfeng Zhang
### Background
大型语言模型（LLMs）展示了令人印象深刻的推理能力，但扩展其性能通常依赖于大型且计算成本高昂的推理数据集。现有的数据选择方法旨在挑选较小且高质量的数据子集，但往往依赖于昂贵的外部模型或不透明的启发式方法。本研究将注意力转向模型的内部机制，发现复杂的推理任务通常激活一小部分特定的注意力头，形成核心推理电路。基于这一洞察，本文提出了一种新型数据选择方法CircuitSeer，该方法通过测量数据对这些关键电路的影响来量化数据的推理复杂性。在4个模型和9个数据集上进行的大量实验表明了CircuitSeer的优越性。特别是，仅在本方法选择的10%数据上对Qwen2.5-Math-7B进行微调，平均通过率提高了1.4个百分点，这突显了其效率和有效性。
### Innovation
本文提出了一种名为CircuitSeer的新颖数据选择方法，其创新之处在于不仅仅依赖外部模型或启发式选择，而是利用模型内部的机制来识别和选择高质量的数据。具体来说，CircuitSeer通过测量数据对关键推理电路的影响来量化数据的推理复杂性，从而在有限的数据集上获得了更好的模型性能。
### Conclusion
CircuitSeer在4个模型和9个数据集上的大量实验验证了其优越性，特别是在仅使用少量选定数据进行微调的情况下，模型性能得到了显著提升，这证实了其高效性和有效性。
## 188. `cs.AI` - 基于计数基内在奖励引导大型语言模型推理中的探索 [PDF](https://arxiv.org/pdf/2510.16614), [HTML](https://arxiv.org/abs/2510.16614)
### Authors
Xuan Zhang,Ruixiao Li,Zhijian Zhou,Long Li,Yulei Qin,Ke Li,Xing Sun,Xiaoyu Tan,Chao Qu,Yuan Qi
### Background
持续强化学习（RL）正在增强大型语言模型（LLM）的多步推理能力。然而，现有的RL范式仍依赖稀疏的结果奖励和有限的探索，这常常驱动LLMs产生重复且次优的推理模式。因此，该研究探讨了如何设计LLM推理中的探索，并提出了MERCI（基于计数引导内在奖励的LLM推理探索）算法，该算法以一种原则性的内在奖励补充了策略优化。MERCI借鉴了基于计数的探索理念，利用一个轻量级的硬币翻转网络（CFN），估计伪计数和推理轨迹的进一步（知识）不确定性，并将它们转化为内在奖励，强调新颖性同时保留了任务奖励的学习信号。该研究将MERCI整合到一些先进的RL框架中，如组相对策略优化（GRPO）。对于复杂的推理基准实验表明，MERCI鼓励更丰富和多样的想法链条，显著提高了性能，并帮助策略摆脱局部模式，发现更好的解决方案。这表明，我们有针对性的内在动机可以确保LLM推理中的探索变得可靠。
### Innovation
提出了一种新颖的探索机制MERCI，利用基于计数的内在奖励补充了策略优化，以引导LLMs的推理探索。MERCI利用一种轻量级的硬币翻转网络估计伪计数和推理轨迹的进一步不确定性，并将这些估计值转换为一种内在奖励，强调新颖性同时保留任务奖励的学习信号。该研究将MERCI集成到了一些先进的RL框架中，实验结果显示MERCI能够鼓励更丰富、多样的想法链条，显著提高性能，并帮助策略越过局部模式，找到更好的解决方案。
### Conclusion
MERCI作为一种基于计数的内在奖励引导策略，显著改善了LLMs的推理探索能力，增强了多步推理的效果，并为理解如何设计LLM探索提供了一种新的视角。实验表明，这种方法有利于LLMs发现更好的解决方案，提高了整体性能，并促进了更有效的学习过程。
## 189. `cs.AI` - DAIL: 超越任务歧义的语言条件强化学习 [PDF](https://arxiv.org/pdf/2510.19562), [HTML](https://arxiv.org/abs/2510.19562)
### Authors
Runpeng Xie,Quanwei Wang,Hao Hu,Zherui Zhou,Ni Mu,Xiyun Li,Yiqin Yang,Shuang Xu,Qianchuan Zhao,Bo XU
### Background
自然语言理解和遵循人类指令是智能代理的关键能力。然而，语言条件下的指令具有很大的灵活性，容易产生歧义，严重影响算法性能。本文指出这一问题并对其局限性进行了解释。通过这种方法，DAIL 模型旨在解决这些限制，提高强化学习的性能，特别是在歧义性较强的环境中。
### Innovation
DAIL 提出了一种新颖的方法，包含两个核心组件：分布策略 (distributional policy) 和语义对齐 (semantic alignment)。该方法通过增加任务可差异性（通过价值分布估算机制）和捕捉轨迹与语言指令之间的对应关系（通过语义对齐模块）来解决语言条件下的任务歧义问题。实验结果表明，DAIL 在结构化和视觉观察基准上均优于基线方法。
### Conclusion
本文提出的 DAIL 方法对于解决语言条件下的任务歧义性问题具有显著效果，能在强化学习中实现更优异的表现。
## 190. `cs.AI` - 评估世界模型学习的标准 [PDF](https://arxiv.org/pdf/2510.19788), [HTML](https://arxiv.org/abs/2510.19788)
### Authors
Archana Warrier,Dat Nguyen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares
### Background
模型学习的代理应该收集信息以构建支持多种下游任务和推断的世界模型，例如预测未观察到的状态、估计行动的近期和远期结果、规划行动序列以及检测动力学变化。当前用于学习和评估世界模型的方法都偏离了这个目标：训练和评估大多基于下一帧的预测，成功与否则通过在相同环境中最大化奖励来衡量。
### Innovation
论文提出了一种新的评估方法WorldTest，该方法分离了奖励无关的交互阶段和有得分的测试阶段，且在不同的相关环境中进行。WorldTest是开放的，模型应该能够在未来未知的不同任务中都表现良好，并且不依赖模型表示，从而可以对不同方法进行比较。通过具体实例化为AutumnBench，AutumnBench包括一系列43个交互式网格世界环境和129种任务，论文将人类参与者和前沿模型进行了比较，结果显示人类的表现优于模型，并且性能提升在某些环境中有效但在其他环境中并不有效。
### Conclusion
WorldTest为评估代理学习环境动力学提供了新的模板，包括无奖励探索、衍生测试和基于行为的评分。AutumnBench展示了世界模型学习的巨大空间。
## 191. `cs.AI` - α-变换在随机迭代中的过渡及其在网络理论中的应用 [PDF](https://arxiv.org/pdf/2410.05056), [HTML](https://arxiv.org/abs/2410.05056)
### Authors
Attila Lovas
### Background
非线性时间序列模型在计量经济学、排队理论和机器学习中非常重要，尽管它们的统计分析尚未完全完善。已知关于弱相关变量的一些关键结果，如大数定律和函数中心极限定理。本文探讨了通过耦合方法将混合性质从外生回归变量转移到响应变量的过程，研究了在非平稳环境中具有有利混合性质的随机环境马尔可夫链，并将其框架应用于单服务器排队模型中。
### Innovation
通过耦合方法将外生回归变量的混合性质转移到响应，并研究了随机环境中的马尔可夫链及其应用，特别是在非平稳环境中具有有利混合性质的情况下。
### Conclusion
研究证明了通过耦合方法转移混合性质的可行性，扩展了在非平稳环境中研究马尔可夫链的可能性，并将其应用于单服务器排队模型。
## 192. `cs.AI` - 从安全神经元出发理解安全对齐：一个机制性视角 [PDF](https://arxiv.org/pdf/2406.14144), [HTML](https://arxiv.org/abs/2406.14144)
### Authors
Jianhui Chen,Xiaozhi Wang,Zijun Yao,Yushi Bai,Lei Hou,Juanzi Li
### Background
大语言模型（LLMs）在各种能力方面表现出色，但在安全方面也存在风险，如生成有害内容和错误信息，即使在经过安全对齐之后。论文探讨了通过机制可解释性的视角研究安全对齐的内部机制，重点关注识别和分析负责安全行为的安全神经元，并提出推理时激活对比来定位这些神经元，以及动态激活修补以评估它们对模型安全性的因果影响。实验表明，可以一致地识别大约5%的安全神经元，并仅通过修补它们的激活即可恢复超过90%的安全性能，而不会影响一般能力。这些安全神经元的存在有助于解释“对齐税”现象，揭示模型安全性和有用性的关键神经元显著重叠，但需要不同的激活模式来达到相同的神经元效果。此外，研究还展示了利用这些发现来保护LLMs，在生成之前检测不安全的输出的应用。
### Innovation
提出了通过推理时激活对比来定位安全神经元，并通过动态激活修补来评估其对模型安全性的因果影响。验证了大约5%的安全神经元可以在不损害一般能力的情况下恢复超过90%的安全性能。揭示了模型安全性和有用的神经元之间的重要重叠，并且需要不同的激活模式来实现相同效果。提出了检测不安全输出的应用来保护LLMs。
### Conclusion
通过机制可解释性的视角，成功识别并分析了安全神经元，从而能够提升模型的安全性能，揭示了模型安全性和有用性的关系，并展示了在实际应用中的安全输出检测功能。
## 193. `cs.AI` - 通过连续反馈对变换器进行能级排列对齐 [PDF](https://arxiv.org/pdf/2405.12961), [HTML](https://arxiv.org/abs/2405.12961)
### Authors
Shriram Chennakesavalu,Frank Hu,Sebastian Ibarraran,Grant M. Rotskoff
### Background
在化学空间中搜索是一种极其具有挑战性的问题，因为随着原子数的增加，可能的化合物数量呈组合增长。为了应对这一挑战，研究人员开发了大规模自回归模型，这些模型在化学化合物数据库上训练，产生了强大的生成器。然而，依然缺乏能够稳健生成具有特定性质分子的方法。分子搜索问题与大语言模型的“对齐”问题类似，但化学任务通常具有特定且易于评估的奖励函数。基于此背景，文章探讨了一种新算法——能量秩对齐（ERA），以利用显式的奖励函数生成基于梯度的目标，用于优化自回归策略。ERA 算法相较于现有的直接偏好优化等方法，具有高度可扩展性，无需强化学习，并且在少量成对的偏好观察时，相对其他方法表现更优。ERA 算法在对齐分子和蛋白质语言模型方面进行了应用，结果显示其生成输出稳定，能够探索化学空间的多样化部分，从而找到了具体的物化性质或蛋白质序列。
### Innovation
介绍了一种新颖的算法——能量秩对齐（ERA），该算法通过利用显式的奖励函数生成基于梯度的目标，优化自回归策略。ERA 算法理论上与近邻策略优化（PPO）和直接偏好优化（DPO）相关，但其优化器的最小值会收敛于理想中的吉布斯-玻尔兹曼分布，其中奖励充当能量函数的角色。此外，ERA 算法相对其他基于偏好的优化方法具有高度的可扩展性，无需进行强化学习，并且在观察成对偏好的样本较少的情况下，对齐后表现良好。该研究进一步展示了 ERA 算法在对齐分子和蛋白质语言模型时的有效性与稳健性。
### Conclusion
文章通过能量秩对齐（ERA）算法，展示了如何利用显式的化学奖励对分子和蛋白质语言模型进行优化，从而产生具有特定性能特性的化学分子和蛋白质序列。ERA 算法在空气中的成对偏好观察数量较少时，表现优于现有的直接偏好优化等方法，能够高效地探索化学空间的多样化部分。
## 194. `cs.AI` - Temporal-Difference Variational Continual Learning [PDF](https://arxiv.org/pdf/2410.07812), [HTML](https://arxiv.org/abs/2410.07812)
### Authors
Luckeciano C. Melo,Alessandro Abate,Yarin Gal
### Background
现实世界的应用中，机器学习模型需要不断学习新的任务以适应数据生成分布的变化。然而，在持续学习（Continual Learning, CL）中，模型常常难以平衡学习新任务（可塑性）与保留先前知识（记忆稳定性）之间的关系。这种不平衡导致了灾难性遗忘（Catastrophic Forgetting），从而降低了性能并削弱了部署系统的可靠性。贝叶斯持续学习文献中，变分方法通过使用递归地更新后验分布的方法解决了这一挑战，同时将其保持在接近其先前估计的位置。然而，这种方法可能存在累积近似误差的问题。
### Innovation
本文提出了一种新的学习目标，将多个先前后验估计的正则化效果集成在一起，以防止个体错误在未来的后验更新中占主导地位并随着时间累积。这些目标基于时间差分方法，这是强化学习和神经科学中流行的 learning 机制。实验结果表明，这种方法有效地缓解了灾难性遗忘的问题，优于强变分持续学习方法。
### Conclusion
本文方法在具有挑战性的持续学习基准测试中表现出众，有效缓解了灾难性遗忘的问题，超过了现有的变分持续学习方法。
## 195. `cs.AI` - 基于注释指南的知识增强：面向教育文本分类的大型语言模型改进 [PDF](https://arxiv.org/pdf/2406.00954), [HTML](https://arxiv.org/abs/2406.00954)
### Authors
Shiqi Liu,Sannyuya Liu,Lele Sha,Zijie Zeng,Dragan Gasevic,Zhi Liu
### Background
近年来，各种机器学习方法在自动分类教育文本以识别学习参与度指标方面获得了广泛关注，这被称为学习参与度分类（LEC）。LEC可以提供深入了解人类学习过程的信息，引起多元研究社区的关注，包括自然语言处理（NLP）、学习分析和教育数据挖掘。尽管大型语言模型（LLMs）如ChatGPT在各种NLP任务中表现优异，但它们在LEC任务中的全面评估和改进策略尚未受到充分研究。本文旨在提出基于注释指南的知识增强（AGKA）方法以提升LLMs的性能，涵盖行为分类、情感分类和认知分类六个LEC数据集，旨在展示AGKA在不同任务中的有效性及其与现有技术的比较。
### Innovation
提出了AGKA方法，通过GPT 4.0从注释指南中检索标签定义知识，并采用随机下采样器选出典型示例。实验结果显示，AGKA能有效提升未经微调的LLMs，特别是GPT 4.0和Llama 3 70B的性能。AGKA使得GPT 4.0在简单二分类任务中优于全量微调的BERT和RoBERTa模型，但GPT 4.0在需要深刻理解复杂语义信息的多分类任务中表现稍逊。值得注意的是，开源的Llama 3 70B结合AGKA与闭源GPT 4.0性能相当。此外，LLMs在处理名称相似的标签时在多分类任务中表现出色不足。
### Conclusion
研究结果表明，AGKA能够提升未经微调的LLMs，尤其是在简单二分类任务中，优于全量微调模型；对于多分类任务，AGKA与GPT 4.0和开源模型Llama 3 70B性能相当；同时，LLMs在区分名称相似标签时存在挑战。
## 196. `cs.AI` - Bi-Mamba：走向准确的1比特状态空间模型 [PDF](https://arxiv.org/pdf/2411.11843), [HTML](https://arxiv.org/abs/2411.11843)
### Authors
Shengkun Tang,Liqun Ma,Haonan Li,Mingjie Sun,Zhiqiang Shen
### Background
当前使用在Mamba中的典型选择性状态空间模型（SSM）解决了Transformer的部分问题，如序列长度相关的二次计算复杂性和推断过程中由于关键值（KV）缓存导致的大量内存需求。然而，Mamba模型的不断增加的规模给训练和部署带来了挑战，尤其是在训练和推理过程中巨大的计算需求。
### Innovation
本文提出了一种名为$texttt{Bi-Mamba}$的可扩展和强大的1比特Mamba架构，旨在使更大的语言模型（LLM）更高效。$texttt{Bi-Mamba}$模型在标准LLM规模的数据集上从头开始使用自回归蒸馏损失进行训练。实验表明，$texttt{Bi-Mamba}$在语言建模基准上达到了与全精度（FP16或BF16）模型相当的效果，并且优于后训练二值化（PTB）Mamba和二值化感知训练（BAT）Transformer基线模型。此外，与原始的Mamba相比，$texttt{Bi-Mamba}$显著减少了内存使用和计算成本。
### Conclusion
我们的工作开辟了在低比特表示下线性复杂度LLM的新途径，并为针对高效1比特Mamba模型的专用硬件设计提供了可能性。代码和预训练权重可在此网址访问。
## 197. `cs.AI` - 增强型残差柯尔莫哥洛夫-阿诺尔德网络 [PDF](https://arxiv.org/pdf/2410.05500), [HTML](https://arxiv.org/abs/2410.05500)
### Authors
Ray Congrui Yu,Sherry Wu,Jiang Gui
### Background
尽管深层卷积神经网络（CNNs）在许多应用中取得了巨大的成功，但由于网络深度中的数百个层，导致其优化和训练成本高昂。传统的卷积操作因其线性性质以及固定的激活函数，使得许多层需要学习数据中的有意义模式变得困难。因为这些网络的巨大量级，这种方法在计算上是不高效的，并且在小数据集上尤其容易导致过拟合或梯度爆炸风险。因此，提出了一个“即插即用”的模块，称为残差柯尔莫哥洛夫-阿诺尔德网络（RKAN）。
### Innovation
RKAN模块具有高度紧凑性，可以轻松集成到传统深度网络的任何阶段，它学习将支持性的多项式特征变换整合到现有的卷积框架中。该模块在不同的视觉任务和广泛测试的基准测试中，提供了基线模型的一致改进，实现了前沿级别的性能。
### Conclusion
残差柯尔莫哥洛夫-阿诺尔德网络在多种视觉任务中的应用表现出色，提供了基线模型的显著改进，在广泛测试的基准测试中实现了顶尖的性能表现。
## 198. `cs.AI` - 不同头并不重要：一种集成了检索和推理的头级别KV缓存压缩方法 [PDF](https://arxiv.org/pdf/2410.19258), [HTML](https://arxiv.org/abs/2410.19258)
### Authors
Yu Fu,Zefan Cai,Abedelkadir Asi,Wayne Xiong,Yue Dong,Wen Xiao
### Background
大型语言模型（LLMs）中的键值（KV）缓存技术可以提高计算效率，但随着输入长度的增长，内存开销迅速增加。已有研究表明，并非所有token在文本生成中都同等重要，因此提出了一种按层选择性保留关键信息的KV缓存压缩方法。基于此，这篇论文强调注意力头在生成过程中的不同作用，提出了头级别的KV缓存压缩方法（HeadKV）及HeadKV-R2，后者引入了一种新的上下文推理能力估计方法进行压缩，该方法在各种基准测试、模型架构和长时间上下文测试中展示了优异的性能，特别是在资源有限的环境中，头级别的KV缓存压缩显著优于强基线方法，同时仅保留了KV缓存的1.5%，但在上下文问答基准中达到了97%的性能。
### Innovation
提出了头级别的KV缓存压缩方法（HeadKV）及HeadKV-R2，基于上下文问答任务中检索和推理能力评估进行压缩，相比层级别的压缩方法，在资源有限的环境中，性能显著提升。特别地，该方法仅保留了1.5%的KV缓存，但在基准测试中达到了97%的满缓存性能，展现出创新性。
### Conclusion
在长文本基准测试（LongBench、LooGLE）、不同模型架构（如Llama-3-8B-Instruct、Mistral-7B-Instruct）和长时间上下文能力测试中，头级别的KV缓存压缩方法显著优于强基线方法，特别是在资源有限的环境中，性能提升显著，验证了该方法的有效性，同时减少大量内存开销，提高了效率。
## 199. `cs.AI` - DMWM: 双思维模型及其长期想象 [PDF](https://arxiv.org/pdf/2502.07591), [HTML](https://arxiv.org/abs/2502.07591)
### Authors
Lingyi Wang,Rashed Shelim,Walid Saad,Naren Ramakrishnan
### Background
在学习长期策略方面，世界模型对于智能代理非常重要。现有的基于递归状态空间模型（RSSM）的世界模型依赖于单步统计推理来捕捉环境动态，这限制了它们进行长期想象的能力，因为预测误差会累积。为了解决这个问题，本研究基于人类认知的双重加工理论提出了一种新的双思维世界模型（DMWM）框架。
### Innovation
该研究提出了一个双思维世界模型框架，分为两个部分：一个基于RSSM的直观处理状态转换的系统1，和一个基于逻辑集成神经网络的引导想象过程的系统2。系统2通过分层的深度逻辑推理来进行推理，且两者之间存在反馈机制以确保想象过程遵循现实环境的逻辑规则。该框架在DMControl基准任务上进行了评估，实验结果表明，该框架在逻辑一致性、实验效率、数据效率和长期想象方面优于最先进的世界模型。
### Conclusion
该研究提出了一种新的双思维世界模型框架，通过逻辑推理增强了模型的长期想象能力。实验结果显示，该框架在各类基准任务上表现出显著优势。
## 200. `cs.AI` - 跨越不同同质性水平的经典GNN作为基准：一种平滑-泛化视角 [PDF](https://arxiv.org/pdf/2412.09805), [HTML](https://arxiv.org/abs/2412.09805)
### Authors
Ming Gu,Zhuonan Zheng,Sheng Zhou,Meihan Liu,Jiawei Chen,Tanyu Qiao,Liangcheng Li,Jiajun Bu
### Background
图神经网络（GNNs）虽然取得了巨大成功，但往往被认为在不同同质性水平的图中表现不佳。尽管最近的实证研究表明，适当调优超参数后，同质性GNN可以在不同同质性水平的数据集上表现出色，但其背后的理论基础和有效的架构仍然不清楚。为了解决这一问题，本文通过理论重温GNN消息传递机制，发现了一个新的平滑-泛化困境，即增加路径长度会提高平滑性但会损害泛化能力。该困境限制了更高阶同质性和所有异质性邻居中的学习，因为这些邻居中复杂的邻居类别分布对由噪声和稀疏性引起的扰动非常敏感。为了克服这一问题，本文提出了基于三个简单而有效的设计理念构建的开掘图神经网络（IGNN），它能够通过适配平滑性来实现逐级泛化，从而在整体上提高泛化能力。基准测试表明，IGNN具有优越性，并揭示了一些同质性GNN变种在特定同质性水平上的普适性。相关代码和数据集可在指定网站上获取。
### Innovation
本文首次理论分析了GNN消息传递中的平滑-泛化困境，并在此基础上提出了开掘图神经网络（IGNN），通过适配平滑性有效解决了这一困境，提高了GNN在不同同质性水平上的表现。除了提出新的理论和架构外，IGNN还在多种基准测试中展示了优秀的性能，特别是对于某些同质性GNN的变种，在特定同质性水平上具有明显的普适性。
### Conclusion
本文通过理论分析发现了GNN消息传递中的平滑-泛化困境，并提出了开掘图神经网络（IGNN）来解决这一问题。IGNN通过适当的平滑性适配，能够实现逐级的泛化并提高了整体的泛化能力，在多个基准测试中取得了优秀的结果。
## 201. `cs.AI` - Face-Human-Bench: 多模态助手中 face 和人类理解的综合基准 [PDF](https://arxiv.org/pdf/2501.01243), [HTML](https://arxiv.org/abs/2501.01243)
### Authors
Lixiong Qin,Shilong Ou,Miaoxuan Zhang,Jiangning Wei,Yuhang Zhang,Xiaoshuai Song,Yuchen Liu,Mei Wang,Weiran Xu
### Background
面部和人类元素是社交互动中的重要组成部分，广泛出现在日常照片和视频中。因此，对面部和人类的理解将会使多模态助手具备更好的响应质量和更广泛的应用范围。然而，目前多模态助理社区缺乏对理解面部和人类能力的全面和科学的评估。因此，作者提出了一种分层的能力分类法，基于该分类法收集面部和人类社区中的图像和注释，构建了一个半自动的数据管道，用于创建一个新的基准测试。并利用Face-Human-Bench对25款主流的多模态大型语言模型进行评估，侧重于能力之间的关联、目标相对位置对性能的影响、以及‘链式思考’（CoT）提示对性能的影响，探讨哪种能力需要通过专业模型进行补充。
### Innovation
该研究首次提出了一个多模态助手中面部和人类理解的分层能力分类法，并基于此分类法构建了一个新的基准测试库Face-Human-Bench。该基准测试库能够对主流的多模态大型语言模型进行系统性的评估，涵盖面部和人类的多个理解能力，支持英文和中文，并公开了数据集和评估代码。
### Conclusion
Face-Human-Bench 提供了一个多模态助手中面部和人类理解的新基准，通过系统性评估，为改进多模态助手的性能和应用范围提供了重要参考，同时也指出了多模态大型语言模型中需要通过专业模型补充的能力。整个研究工作通过公开的数据集和评估代码进一步推动了该领域的研究和发展。
## 202. `cs.AI` - 向基于比喻流的语音用户界面对话设计迈进 [PDF](https://arxiv.org/pdf/2502.11554), [HTML](https://arxiv.org/abs/2502.11554)
### Authors
Smit Desai,Jessie Chin,Dakuo Wang,Benjamin Cowan,Michael Twidale
### Background
目前的语音用户界面(VUI)设计通常依赖于静态的人类中心的比喻，这些比喻未能适应多样化的语境和用户需求。这种设计方式限制了用户体验的多样性，未能针对特定任务和场景进行优化。
### Innovation
本文提出了一种名为比喻流设计（Metaphor-Fluid Design）的新方法，该方法能够根据对话使用的语境动态调整比喻性表达。作者将此方法与现有的默认VUI进行了对比，后者通常围绕助手的人格特点进行设计，提供统一的交互风格。通过两项研究，作者展示了比喻流设计如何通过更好地适应不同场景下用户的期望来提升用户体验。
### Conclusion
本文研究结果挑战了一种一刀切的VUI设计方式，并表明比喻流设计有潜力创造更加适应和引人入胜的人机交互。尽管个体会有不同的比喻偏好，但这进一步突显了个性化的重要性。
## 203. `cs.AI` - ExpertLens: 激活引导特征具有高度可解释性 [PDF](https://arxiv.org/pdf/2502.15090), [HTML](https://arxiv.org/abs/2502.15090)
### Authors
Masha Fedzechkina,Eleonora Gualdoni,Sinead Williamson,Katherine Metcalf,Skyler Seto,Barry-John Theobald
### Background
在大语言模型（LLMs）中，激活引导方法作为一种有效的方式，可以通过定向更新来提升生成语言的质量，而不需要大量的适应数据。然而，这些方法发现的特征是否具有可解释性仍然是一个未解决的问题。本文通过应用‘发现专家’方法来识别与特定概念相关的神经元，并通过检查这些神经元来揭示模型表示的信息。
### Innovation
本文提出了ExpertLens，这是一种检查特定神经元的方法，能够揭示模型表示的信息，并揭示了这些表示在不同模型和数据集上的稳定性。研究还发现，ExpertLens 的表示与从行为数据推断的人类表示高度对齐，并且优于词/句嵌入捕捉的对齐程度。此外，通过使用 ExpertLens 重构人类概念组织，该方法能够为LLM概念表示提供粒度视图。
### Conclusion
研究结果表明，ExpertLens 是一种灵活且轻量级的方法，能够捕获和分析模型表示。
## 204. `cs.AI` - S$^2$-Diffusion: 在机器人操作中从实例级到类别级技能的推广 [PDF](https://arxiv.org/pdf/2502.09389), [HTML](https://arxiv.org/abs/2502.09389)
### Authors
Quantao Yang,Michael C. Welle,Danica Kragic,Olov Andersson
### Background
近期技能学习的进步使机器人的操作达到了新的高度，使其能够从实际数量的演示中学习复杂的操作任务。然而，这些技能通常局限于演示训练数据中特定的动作、物体和环境实例，并且难以转移到同一类别的其他实例上。
### Innovation
本文提出了一种开放词汇的时空语义扩散策略（S$^2$-Diffusion），该策略能够从实例级别的训练数据推广到类别级别，使技能在相同类别实例之间具有可迁移性。通过一个可通过提示的语义模块与时空表示相结合，可以捕获技能的功能方面。此外，提出了利用深度估计网络的方法，仅使用一个RGB摄像头即可。该方法在多个机器人操作任务上，在模拟和现实世界中进行了评估和比较，结果显示S$^2$-Diffusion策略对与类别无关的因素变化具有不变性，并能在未受过特定实例训练的情况下，在同一类别其他实例上实现令人满意的性能。
### Conclusion
我们的结果表明，S$^2$-Diffusion策略不仅对与类别无关的因素变化具有不变性，还能够在未受过特定实例训练的情况下，在同一类别其他实例上实现令人满意的表现，甚至比之前的方法更为优越。
## 205. `cs.AI` - 深度学习驱动的电生理脑信号分析：推进神经诊断 [PDF](https://arxiv.org/pdf/2502.17213), [HTML](https://arxiv.org/abs/2502.17213)
### Authors
Jiahe Li,Xin Chen,Fanqi Shen,Junru Chen,Yuxin Liu,Daoze Zhang,Zhizhang Yuan,Fang Zhao,Meng Li,Yang Yang
### Background
神经疾病对全球健康构成重大挑战，促进了脑电图信号分析的进步。头皮脑电图（EEG）和颅内脑电图（iEEG）广泛应用于诊断和监测。然而，数据集的异质性及任务的变化阻碍了稳健的深度学习解决方案的发展。本评论系统地审查了基于EEG/iEEG的神经疾病诊断中的深度学习方法进步，覆盖了7种神经疾病，利用46个数据集。
### Innovation
审查涵盖了基于EEG/iEEG的神经疾病诊断中的深度学习方法进步，重点分析了每种疾病中代表性方法及其定量结果，结合了性能比较、数据使用分析、模型设计和任务特定适应的分析，特别是在预训练多任务模型在实现可扩展和普遍性解决方案中的作用。
### Conclusion
最后，提出了一种标准化基准来评估跨多种数据集的模型并提高可重复性，突出了近期创新如何使神经诊断向智能且适应性强的健康保健系统转型。
## 206. `cs.AI` - 神经注意搜索 [PDF](https://arxiv.org/pdf/2502.13251), [HTML](https://arxiv.org/abs/2502.13251)
### Authors
Difan Deng,Marius Lindauer
### Background
本文介绍了一种称为神经注意搜索（NAtS）的框架，它可以自动评估序列中每个token的重要性，并决定在经过几步后是否可以删除相应的token。此方法可以在推理过程中有效减少基于Transformer的模型所需的KV缓存大小，从而降低推理成本。研究设计了一个包含三种token类型的搜索空间，即全局token、局部token和滑动窗口token。这三种token类型分别影响推理过程的不同方面。通过可学习的注意力掩码，可以与架构权重一起学习tokens的类型信息。实验表明，NAtS可以在保持模型性能的同时有效地减少所需的KV缓存大小。
### Innovation
本框架引入了一种新的搜索空间，设计了三种不同类型的token（全局token、局部token和滑动窗口token），并通过可学习的注意力掩码与架构权重一起学习tokens的类型信息。此外，它可以自动评估token的重要性并决定是否在推理过程中删除它们，有效地降低了Transformer模型的推理成本和所需的KV缓存大小。
### Conclusion
通过实验验证，NAtS可以在保持模型性能的同时有效减少KV缓存大小，展示了其降低推理成本的潜力。
## 207. `cs.AI` - UMoE：融合注意力机制和前馈网络共享专家 [PDF](https://arxiv.org/pdf/2505.07260), [HTML](https://arxiv.org/abs/2505.07260)
### Authors
Yuanhang Yang,Chaozheng Wang,Jing Li
### Background
稀疏混合专家(MoE)架构已经成为扩展Transformer模型的有前途的方法。最初的MoE工作主要集中在前馈网络(FFN)层，但最近的研究已经探索将MoE原理扩展到注意力层以提升模型性能。现有的基于注意力机制的MoE层需要专门的实现，并且表现出比其FFN对应的层面差的性能。
### Innovation
本文提出了一个新的关于注意力机制的重新定义，揭示了注意力模块中存在的类似前馈网络的结构。通过这种新的架构，UMoE能够在基于注意力机制的MoE层中实现更好的性能，同时允许FFN和注意力组件之间高效的参数共享。
### Conclusion
UMoE架构通过基于注意力机制的MoE层实现优异的性能，同时实现了FFN和注意力组件之间的有效参数共享。
## 208. `cs.AI` - DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration [PDF](https://arxiv.org/pdf/2503.15984), [HTML](https://arxiv.org/abs/2503.15984)
### Authors
Suraj Singh,Anastasia Batsheva,Oleg Y. Rogov,Ahmed Bouridane
### Background
现代图像恢复和超分辨率方法依赖于深度学习，因为其在性能上优于传统算法。然而，深度学习通常需要大量训练数据集，而在天文学摄影中这些数据集很少可用。Deep Image Prior (DIP) 通过在单张图像上进行盲训练来绕过这一限制，虽然在某些情况下有效，但往往会出现过拟合、伪影生成和不稳定等问题。为了克服这些问题并提高整体性能，作者提出了DIPLI框架，该框架从单帧训练转换为多帧训练，使用后投影技术，结合TVNet模型进行光学流量估计，并采用拉马尔维恩动力学获得无偏蒙特卡洛估计取代确定性预测。在合成数据集上的实验表明，该方法在SSIM、PSNR、LPIPS和DISTS等度量中普遍优于基线，具有更高的重建质量。此外，该模型所需的输入图像数量远少于幸运成像，不容易出现过拟合或伪影生成问题。在存在领域迁移问题的现实世界天文学数据中，该方法仍能保持高重建质量，证明其实用鲁棒性.
### Innovation
提出了DIPLI框架，其特征在于使用多帧训练代替单帧训练，整合后投影技术、TVNet模型的光学流估计和拉马尔维恩动力学获得的无偏蒙特卡洛估计，提高了深度图先行盲天文学图像恢复模型的鲁棒性和稳定性，同时减少了对大量训练数据的依赖，并且在多种评估指标上优于其他类似方法，如幸运成像、基于Transformer的模型RVRT和基于扩散的模型DiffIR2VR-Zero，特别适用于现实世界天文学数据中的应用.
### Conclusion
通过DIPLI框架，作者成功地解决了DIP在多帧图像恢复中的局限性，提出了一个基于多帧的深度学习方法，该方法在天文学图像恢复中表现出更高的质量和鲁棒性，并且验证了其应用潜力。
## 209. `cs.AI` - 在BiGTex中结合Text-attributed Graphs的结构和语义信号 [PDF](https://arxiv.org/pdf/2504.12474), [HTML](https://arxiv.org/abs/2504.12474)
### Authors
Azadeh Beiranvand,Seyed Mehdi Vahidipour
### Background
文本属性图（TAGs）在表示学习中提出独特的挑战，需要模型同时捕捉节点关联文本的语义丰富性和图的结构依赖性。尽管图神经网络（GNNs）在建模拓扑信息方面表现出色，但它们缺乏处理无序文本的能力。与此同时，大型语言模型（LLMs）在文本理解方面表现出色，但通常不了解图结构。因此，需要一种结合GNNs和LLMs的方法来同时处理结构和语义信息。
### Innovation
本文提出了一种名为BiGTex的新架构，该架构通过堆叠图-文本融合单元，将GNNs和LLMs紧密结合。每个单元允许文本和结构表示之间的相互注意，使信息可以在两个方向上流动，文本可以影响结构，而结构可以指导文本解释。该架构通过参数高效的微调（LoRA）训练，保持LLMs冻结状态，同时适应特定任务的信号。实验表明，BiGTex在节点分类任务中达到了最先进的性能，并且能够有效地泛化到链预测任务。进一步的消融研究表明，软提示和双向注意对模型的成功至关重要。
### Conclusion
BiGTex架构在节点分类和链预测任务中表现出优越的性能，说明结合GNNs和LLMs的能力能够有效处理图结构和语义信息。
## 210. `cs.AI` - 不要懒惰：CompleteP 使深度变换器计算效率更高 [PDF](https://arxiv.org/pdf/2505.01618), [HTML](https://arxiv.org/abs/2505.01618)
### Authors
Nolan Dey,Bin Claire Zhang,Lorenzo Noci,Mufan Li,Blake Bordelon,Shane Bergsma,Cengiz Pehlevan,Boris Hanin,Joel Hestness
### Background
研究在使用不同参数化时大规模语言模型（LLM）训练的计算效率，特别是随着模型大小的变化，模型和优化器超参数（HPs）的调整规则。一些参数化方案在模型深度变化时无法有效转移基本的最优HPs（如学习率），这要求实践者在扩展模型时重新调整这些HPs（代价高昂），或者在重新调整不可行时接受次优的训练表现。即使在某些情况下实现了HP转移，理论分析表明参数化方案仍然可能处于“懒学习”阶段，导致各层只能学习接近线性化的特征，从而限制了深度和非线性效果的充分利用。
### Innovation
识别并采用了名为CompleteP的参数化方案，该方案实现了深度内HP转移和各层非懒惰学习。CompleteP使模型宽度/深度比更广泛地保持计算效率，解锁了更适合不同硬件配置和运行环境的模型形状。相对于之前最先进的方法，CompleteP在Cerebras CS-3系统上实现了12-34%的计算效率改进。
### Conclusion
CompleteP能够通过实现深度HP转移和非懒惰学习来扩大计算效率的范围，解锁了更适合不同硬件配置和操作上下文的模型形状，并且在计算效率上超过了之前的状态最先进方法，实现了12-34%的提升。
## 211. `cs.AI` - Fair Clustering via Alignment [PDF](https://arxiv.org/pdf/2505.09131), [HTML](https://arxiv.org/abs/2505.09131)
### Authors
Kunwoong Kim,Jihu Lee,Sangchul Park,Yongdai Kim
### Background
公平聚类的目标是平衡每个聚类中带有给定敏感属性的实例比例。现有的公平聚类算法在特定公平约束下优化聚类目标，但由于内在复杂性或近似性，实际应用中常常导致聚类效果不佳或数值不稳定。
### Innovation
提出了一种新的公平聚类算法，名为Fair Clustering via Alignment (FCA)，通过分解公平K均值聚类目标函数。FCA算法交替执行：（i）找到联合概率分布以对来自不同受保护群体的数据进行对齐；（ii）在对齐的空间中优化聚类中心。FCA算法的主要优势在于理论上能够保证在任何给定公平水平下聚类效用近似最优，而且无需复杂约束，从而在实践中实现高效用的公平聚类。
### Conclusion
实验表明，FCA算法在（i）公平水平与聚类效用之间的权衡方面表现优越，并且能够在没有数值不稳定的情况下实现近乎完美的公平性。
## 212. `cs.AI` - FAST-GRPO: 快慢思维的GRPO算法在大型视觉-语言模型推理中的应用 [PDF](https://arxiv.org/pdf/2504.18458), [HTML](https://arxiv.org/abs/2504.18458)
### Authors
Wenyi Xiao,Leilei Gan
### Background
在使用强化学习（尤其是通过GRPO）对大型视觉-语言模型进行推理时，难以有效扩展推理长度或在所有任务中生成简洁的输出，仅在准确性方面有微小提升。这导致了模型在处理复杂问题时表现不佳，特别是在增加推理长度的同时难以保持准确性和简洁性的平衡。为解决这一问题，该研究提出FAST-GRPO，这是一种基于GRPO的变体，可以根据问题的特点动态调整推理深度。通过实证分析，作者探讨了回答长度和数据分布对性能的影响，从而验证了在大型视觉-语言模型中使用快慢思维的可行性。
### Innovation
FAST-GRPO通过引入两种互补的度量标准来估计问题的难易程度，帮助模型决定何时使用快思维或慢思维。在此基础上，将自适应长度奖励和难度感知的KL散度整合到GRPO算法中。实验结果表明，与基线模型相比，FAST实现了超过10%的相对性能提升，同时减少了32.7%至67.3%的令牌使用量，显著优于之前的慢思维方法，有效地平衡了推理长度和准确性之间的关系。
### Conclusion
该研究通过FAST-GRPO算法，有效解决了大型视觉-语言模型在推理过程中难以平衡推理长度和准确性的问题。通过自适应调整和难度感知机制，FAST不仅提高了模型的推理准确率，还大幅减少了模型的令牌使用量，为后续的视觉-语言模型研究提供了新的思路和方法。
## 213. `cs.AI` - PRUNE: 基于补丁的可验证神经网络遗忘修复框架 [PDF](https://arxiv.org/pdf/2505.06520), [HTML](https://arxiv.org/abs/2505.06520)
### Authors
Xuran Li,Jingyi Wang,Xiaohan Yuan,Peixin Zhang
### Background
在训练好的神经网络模型中，人们常常希望删除特定的一部分训练数据。这与保护数据持有者的“被遗忘权”息息相关，是许多最近法规促进的需求。现有的遗忘方法通常需要训练替代模型来处理剩余数据，这从数据持有者或第三方审核者的视角来看可能会很昂贵且难以验证。本文提供了一个新的视角，提出了一个新型的遗忘方法，即通过在原始神经网络上施加精心设计的“补丁”来实现针对特定数据点的“遗忘”。
### Innovation
本文通过借鉴神经网络修复的研究路线，提出了一种策略性地选出轻量级最小“补丁”，确保能够针对给定数据点进行可验证的遗忘。此外，为了遗忘大量数据点或整个类别，本文提出了迭代地选择少量的代表数据点进行遗忘的方法，以实现整体遗忘的效果。广泛的实验结果显示，该方法不仅在实现出色的遗忘效果方面有效，还在保持模型性能的同时与多种基线方法相比在效率和内存消耗方面具有竞争力。
### Conclusion
通过PRUNE框架，实现了对神经网络特定数据点的可验证遗忘，保证了模型性能，且在效率和内存消耗方面具有竞争力。
## 214. `cs.AI` - token嵌入违反流形假设 [PDF](https://arxiv.org/pdf/2504.01002), [HTML](https://arxiv.org/abs/2504.01002)
### Authors
Michael Robinson,Sourya Dey,Tony Chiang
### Background
深入理解大型语言模型（LLM）的行为需要我们掌握其输入词元空间的结构。如果该空间与我们的假设不同，我们对LLM的理解和结论可能会出现偏差。为了理解词元嵌入的结构，该研究从实验和理论两方面进行了阐述。
### Innovation
提出了一个新的统计检验，假设每个词元周围的区域在无零假设情况下具有相对平坦和光滑的结构。该研究通过运行新的假设检验来检验多种开源LLM的不同词元嵌入，发现无零常常被拒绝，表明词元空间不是流形，因此不是纤维丛。这一发现影响了对LLM的稳定性分析。
### Conclusion
研究结果表明，词元空间不是纤维丛，表明LLM可能不是流形。因此，当LLM呈现两个语义等价的提示时，其中一个包含被检验词元的提示可能会比另一个表现出更少的稳定性。
## 215. `cs.AI` - 浅层流匹配机制在粗细分层文本转语音合成中的应用 [PDF](https://arxiv.org/pdf/2505.12226), [HTML](https://arxiv.org/abs/2505.12226)
### Authors
Dong Yang,Yiyi Cai,Yuki Saito,Lixu Wang,Hiroshi Saruwatari
### Background
现有的基于流匹配（FM）机制的文本转语音（TTS）模型大多采用粗分到细分（coarse-to-fine）的生成范式。这些模型通常依赖于次级生成器提供的粗略表示作为条件，但常规的FM模块未充分利用这些粗略表示来构建中间状态。本文旨在通过引入浅层流匹配机制（SFM）来改进这种范式，使得生成过程更加精细化和有效率。
### Innovation
提出了浅层流匹配（SFM）机制，该机制不受限于常规FM模块仅用从次级生成器获取的粗略表示作为条件。SFM从这些粗略表示开始构建中间状态，并通过正交投影方法动态确定这些中间状态的时间位置。SFM还采用了一种基于单段分段流的原理构造策略。通过这种方法，SFM可以逆向计算流匹配路径的后段，从而利用系统能力更有效地进行流畅度和自然度的演绎。
### Conclusion
通过实验证明，SFM能够提高语音的自然度，无论是客观评价还是主观测试都能获得一致的改进效果。此外，SFM还与多种TTS模型进行了集成，在使用自适应步长ODE求解器时能够显著加快推理速度。相关Demo和代码可以在此处获得：this https URL.
## 216. `cs.AI` - 超越离散令牌采样的文本生成 [PDF](https://arxiv.org/pdf/2505.14827), [HTML](https://arxiv.org/abs/2505.14827)
### Authors
Yufan Zhuang,Liyuan Liu,Chandan Singh,Jingbo Shang,Jianfeng Gao
### Background
在标准自回归生成中，大型语言模型（LLM）预测下一个令牌的概率分布，然后采样一个离散的令牌并将该令牌作为新输入，同时抛弃该分布。这样在生成过程中会丢失许多潜在有用的信息。
### Innovation
为保留这些信息，本文提出了混合输入（MoI）方法。在生成新的一令牌后，MoI 构建一个新的输入，该输入是新生成的离散令牌与之前被抛弃的概率分布的融合。该方法利用贝叶斯估计方法，将概率分布视为先验，将采样令牌视为观察值，并使用连续后验期望替代传统的 one-hot 向量，作为新的模型输入。
### Conclusion
实验证明，MoI 在数学推理、代码生成和博士水平的问答任务上均提高了多个模型（包括 QwQ-32B、Nemotron-Super-49B、Gemma-3-27B 和 DAPO-Qwen-32B 的性能，且无需额外训练和几乎无计算负载的增加。
## 217. `cs.AI` - 基于Koopman建模的一步离线蒸馏扩散模型 [PDF](https://arxiv.org/pdf/2505.13358), [HTML](https://arxiv.org/abs/2505.13358)
### Authors
Nimrod Berman,Ilan Naiman,Moshe Eliasof,Hedi Zisling,Omri Azencot
### Background
扩散生成模型已经展示了出色的表现，但在采样过程中依然存在计算成本高昂的问题。为了降低成本，人们提出了蒸馏策略，尤其是离线蒸馏在效率、模块化和灵活性方面有着明显优势。现有的扩散模型虽然通过动力系统理论被广泛研究，但仍然有许多强大的、尚未深入探索的工具可以进一步利用。此外，扩散模型还在潜在空间中自然地定义了结构化且语义连贯的轨迹。基于上述背景，在Koopman理论框架下提出了一种新型的离线蒸馏方法——Koopman Distillation Model (KDM)。
### Innovation
提出了一种基于Koopman理论的离线蒸馏方法，名叫KDM。KDM通过将噪声输入编码到嵌入空间中，利用一个学习到的线性算子将其向前传播，最终通过解码器重建纯净样本，从而实现了一步生成并保持语义准确性。理论验证表明：在轻微假设下，所学习的扩散动态可以表示为有限维的Koopman表示；Koopman潜在空间中的邻近性与生成输出的语义相似性是相关的，有助于轨迹对齐。
### Conclusion
KDM在标准的离线蒸馏基准测试中取得了非常有竞争力的性能。
## 218. `cs.AI` - 增强学习中提取策略集合如何提高泛化能力 [PDF](https://arxiv.org/pdf/2505.16581), [HTML](https://arxiv.org/abs/2505.16581)
### Authors
Max Weltevrede,Moritz A. Zanger,Matthijs T.J. Spaan,Wendelin Böhmer
### Background
在零样本策略迁移的强化学习（Reinforcement Learning, RL）场景中，目标是通过在一组固定的训练环境中训练代理，使它能够迁移到未见的相似测试环境中并表现良好。先前的研究表明，训练后进行策略蒸馏有时可以产生在测试环境中比原始策略性能更好的策略。但至今尚不清楚这种现象的原因，以及应该如何选择用于策略蒸馏的数据。
### Innovation
本文证明，在某些假设下，训练后策略蒸馏存在泛化边界的理论。这一理论提供了两个实际见解：为了改善泛化，应1) 训练提取策略的集合，2) 使用尽可能多的训练环境中数据进行提取。此外，实验验证了该理论在更广泛的情景下仍然适用，即使某些假设不成立。最后，展示了基于多样数据集提取的策略集合相比原始代理具有显著更好的泛化能力。
### Conclusion
本文验证了通过提取策略集合提高强化学习迁移中泛化的可行性，并展示了这样做的有效性，特别是在更多样化的数据集上。
## 219. `cs.AI` - Your Pre-trained LLM is Secretly an Unsupervised Confidence Calibrator [PDF](https://arxiv.org/pdf/2505.16690), [HTML](https://arxiv.org/abs/2505.16690)
### Authors
Beier Luo,Shuoyuan Wang,Sharon Li,Hongxin Wei
### Background
后训练的大型语言模型对于适应预训练语言模型以符合人类偏好和下游任务至关重要。虽然预训练语言模型（PLMs）通常表现出良好的置信度校准，但后训练语言模型（PoLMs）往往过于自信，这可能导致在关键应用中可靠性降低。由于缺乏专门标记的下游任务数据，校准PoLMs已成为主要障碍。
### Innovation
本文提出了一种新的无监督方法——分歧意识置信校准（DACA），用于优化后训练置信校准的参数（如温度τ）。该方法通过预测模型和PoLM之间在分歧示例上的不一致性来解决下信心问题，仅使用一致性示例进行校准，从而避免了分歧示例导致的温度过大问题，提高了校准性能。
### Conclusion
通过广泛的实验，证明了DACA方法的有效性，将开源和基于API的大型语言模型（如GPT-4o）在常见基准上的平均ECE提高了高达15.08%。
## 220. `cs.AI` - CALM-PDE：连续且自适应卷积的时空依赖偏微分方程的潜在空间建模 [PDF](https://arxiv.org/pdf/2505.12944), [HTML](https://arxiv.org/abs/2505.12944)
### Authors
Jan Hagnberger,Daniel Musekamp,Mathias Niepert
### Background
利用密集离散空间解决时间依赖偏微分方程（PDEs）是多个科学和工程学科中的基本问题，包括气候现象和流体动力学建模。然而，在物理空间中直接进行这些计算可能涉及显著的计算成本。为了解决这一问题，已开发出一些基于神经的替代模型，它们在压缩的潜在空间中操作以解决PDEs。尽管这些方法降低了计算复杂性，但它们经常使用基于变换器的注意力机制以处理不规则采样域，从而增加了内存消耗。相比之下，卷积神经网络可实现有效的编码和解码但限于规则离散化。鉴于这些考虑，我们提出CALM-PDE，这是一种高效地在压缩潜在空间中解决任意离散化PDEs的模型类。
### Innovation
我们引入了一种新型连续卷积为基础的编码解码架构，使用ε邻域约束核，能够学习应用卷积操作到自适应和优化查询点。这种方法在处理具有规则和不规则空间域的多种PDEs方面表现出有效性。CALM-PDE不仅具有与基线方法相媲美的性能，而且在内存和推理时间效率上也优于基于变换器的方法。
### Conclusion
CALM-PDE能够在压缩的潜在空间中高效地解决任意离散化的PDEs。这种方法通过使用ε邻域约束核和学习应用卷积操作到自适应查询点，实现了在规则和不规则空间域上的有效建模。与基于变换器的方法相比，它提供显著的内存和推理时间效率改进。
## 221. `cs.AI` - 打破mBad！跨语言去毒的监督微调 [PDF](https://arxiv.org/pdf/2505.16722), [HTML](https://arxiv.org/abs/2505.16722)
### Authors
Himanshu Beniwal,Youngwoo Kim,Maarten Sap,Soham Dan,Thomas Hartvigsen
### Background
随着大型语言模型（LLMs）在全球应用中越来越普遍，确保它们在多种语言背景下保持无毒仍然是一个关键挑战。本文探讨了“跨语言去毒”这一跨语言范式，该范式能够减少有害内容，并允许去毒能力在不同语系的高资源和低资源语言之间进行转移。
### Innovation
本文提出了监督微调方法，以实现跨语言去毒。该方法能够在语料有限的情况下，有效减少跨分布环境中的毒性内容，同时研究去毒措施对模型在非有害任务上的性能影响，揭示了安全性和知识保留之间的权衡。
### Conclusion
本文通过广泛设置（392种）评估了跨语言去毒的有效性，并在多语言数据集上展示了代码和数据集的公开可用性。研究揭示了在降低毒性的同时，可能需要在保持知识完整性方面做出妥协。
## 222. `cs.AI` - CLEVER: 一个正式验证代码生成的精心挑选基准 [PDF](https://arxiv.org/pdf/2505.13938), [HTML](https://arxiv.org/abs/2505.13938)
### Authors
Amitayush Thakur,Jasper Lee,George Tsoukalas,Meghana Sistla,Matthew Zhao,Stefan Zetzsche,Greg Durrett,Yisong Yue,Swarat Chaudhuri
### Background
现有技术在端到端验证代码生成方面的不足，包括测试案例监督、由大型语言模型生成的注释、以及包含实现逻辑或导致无效解决方案的规范。当前基准测试集没有提供全面验证的方法和挑战，使得评估代码生成的精确性和可靠性成为一个难题。因此，需要一个高质量、精心选择的基准来解决这些问题并评估程序合成和形式推理的先进方法的有效性，例如基于最先进的语言模型的少样本和代理方法。针对这些挑战，提出了CLEVER基准测试集。
### Innovation
CLEVER是一个由161个精心挑选的问题组成的基准，用于端到端验证的代码生成。每个问题包含两个任务：一是生成一个与隐藏的真实规范相匹配的规范；二是生成一个能够证明满足此规范的Lean实现。与先前的基准不同，CLEVER避免了测试案例监督、大型语言模型生成的注释和包含实现逻辑或导致无效解决方案的规范。CLEVER的所有输出都在使用Lean的类型检查器后进行验证，以确保机器可验证的正确性。CLEVER使用这种方法评估了基于最先进的语言模型的新少样本和代理方法，这些方法难以实现全面验证，因此确定这是一个具有挑战性的前沿基准，用于程序合成和形式推理。通过这些评估，清晰地展示了CLEVER基准的强度和它对当前人工智能在证明有效性和可靠性的帮助。该基准可在GitHub和HuggingFace上找到，并且评估代码也可以在线获取。
### Conclusion
CLEVER代表了一种新的挑战，能够评估最先进的语言模型在程序合成和形式推理方面的能力，特别是对于实现全面验证的能力。尽管这些方法在一定程度上能生成满足规范的代码，但它们难以实现全面验证，这标志着在程序合成和形式推理服务方面仍有许多挑战需要解决。CLEVER是一个重要的工具，有助于推动这些领域的进一步研究与发展。
## 223. `cs.AI` - LLM-Explorer: 通过大规模语言模型驱动的强化学习策略探索增强插件 [PDF](https://arxiv.org/pdf/2505.15293), [HTML](https://arxiv.org/abs/2505.15293)
### Authors
Qianyue Hao,Yiwen Song,Qingmin Liao,Jian Yuan,Yong Li
### Background
在强化学习（RL）中，策略探索至关重要。现有的方法包括贪婪策略和基于高斯过程的方法等，但这些方法采用预设的随机过程，且在各种RL任务中不分情景地应用，未能考虑任务特定特征对该策略探索的影响。此外，在RL训练期间，这类随机过程的演变通常是刚性的，仅涉及方差的衰减，并不能根据代理的实际学习状态灵活调整。
### Innovation
本文受到大型语言模型（LLMs）分析和推理能力的启发，设计了LLM-Explorer，这是一种能够自适应地生成特定任务探索策略的插件模块，以增强RL策略探索。该设计通过提示LLMs分析代理当前的策略学习状态，并生成未来策略探索的概率分布，然后周期性地更新这一概率分布，从而为特定任务产生专门化的随机过程，并动态调整以适应学习过程。LLM-Explorer兼容各种广泛应用的RL算法，包括DQN系列、DDPG、TD3及其任何可能的变种。实验结果表明，LLM-Explorer可以显著增强RL策略探索，平均性能提升高达37.27%。
### Conclusion
通过广泛的Atari和MuJoCo基准实验，验证了LLM-Explorer提高RL策略探索能力的效能。我们提供了开源代码以确保研究的可复现性。
## 224. `cs.AI` - RL Tango: 联同增强生成器和验证器以提升语言推理 [PDF](https://arxiv.org/pdf/2505.15034), [HTML](https://arxiv.org/abs/2505.15034)
### Authors
Kaiwen Zha,Zhengqi Gao,Maohao Shen,Zhang-Wei Hong,Duane S. Boning,Dina Katabi
### Background
近期，强化学习（RL）作为一种提升大型语言模型（LLMs）推理能力的有效方法引起了广泛关注。在RL应用中，LLM生成器在约束下被指导工作，这些约束由验证者（奖励模型）提供。然而，当前的RL后训练方法在LLMs上通常使用的是固定验证器（规则基础或冻结预训练）或通过有监督微调（SFT）训练的验证器。这些设计容易出现奖励作弊，并且在处理未涵盖的分布时泛化能力差。
### Innovation
Tango框架提出了一个新颖的配置，该框架通过交替训练LLM生成器和验证器来同时训练两者。Tango的核心创新之处在于通过RL训练得到的生成式验证器，这是一种过程级别的生成器验证器，仅凭结果级别的验证正确性奖励训练，并与生成器协同进化。与确定性或通过SFT训练的验证器相比，这种生成式RL训练验证器表现出更好的稳健性和优越的泛化能力，可以与生成器形成有效的相互促进。
### Conclusion
广泛实验表明，Tango框架的生成器和验证器分别在7B/8B规模模型中取得最优结果：生成器在五个竞赛级数学基准测试和四个具有挑战性的域外推理任务中取得最佳表现，验证器在ProcessBench数据集中给出最佳成绩。特别是在最先进的数学理任务上，两者的性能提升尤为显著。相关代码可在以下链接获取：this https URL.
## 225. `cs.AI` - 随机森林自编码器 [PDF](https://arxiv.org/pdf/2505.21441), [HTML](https://arxiv.org/abs/2505.21441)
### Authors
Binh Duc Vu,Jan Kapar,Marvin Wright,David S. Watson
### Background
本研究基于非参数统计和谱图理论的基础成果，提出了自动编码的新方法，利用随机森林进行学习。
### Innovation
提出了利用随机森林进行自动编码的原理性方法，通过约束优化、分割重新标记和最近邻回归等方式解决解码问题。除此之外，该方法应用于数据可视化、压缩、聚类和降噪等多种场景。
### Conclusion
该方法与监督或无监督模型兼容，能够提供条件分布或联合分布的窗口，各种实验验证了该方法的普遍适用性和实用性。
## 226. `cs.AI` - 超重叠产生稳健的神经缩放 [PDF](https://arxiv.org/pdf/2505.10465), [HTML](https://arxiv.org/abs/2505.10465)
### Authors
Yizhou Liu,Ziming Liu,Jeff Gore
### Background
今天的大型语言模型（LLMs）的成功在于模型越大表现越好这一观察。然而，这种神经网络缩放法则的起源，即损失随着模型大小呈幂律减少，仍然不清楚。本文探讨了表示叠加的意义，即LLMs具有超过其维度的特征表示，可能是损失和产生神经网络缩放的关键因素。基于Anthropic的玩具模型，通过使用权重衰减来控制叠加的程度，可以系统地研究损失随模型大小的变化情况。当叠加较弱时，损失仅在数据特征频率呈幂律分布时才遵循幂律；而在强叠加下，损失在广泛的频率分布类型中与模型维度成反比，由于表示向量之间的几何重叠。实证数据显示开源的LLMs处于强叠加状态，损失的缩放类似于模型维度的倒数，并且Chinchilla的缩放法则与这种行为相一致。
### Innovation
本文提出表示叠加是神经网络缩放法则的关键驱动力，并通过Anthropic的玩具模型和对开源大型语言模型的研究，展示了损失如何随着模型维度的变化而变化，提供了一种理解神经网络缩放的机制。
### Conclusion
研究表明，表示叠加在神经缩放中起着核心作用，有助于回答何时可以改进神经网络缩放，以及何时会失效的问题。
## 227. `cs.AI` - 无需妥协的可解释性：Mixture of Decoders的忠实密集层分解 [PDF](https://arxiv.org/pdf/2505.21364), [HTML](https://arxiv.org/abs/2505.21364)
### Authors
James Oldfield,Shawn Im,Sharon Li,Mihalis A. Nicolaou,Ioannis Patras,Grigorios G Chrysos
### Background
多层感知器（MLPs）是大型语言模型不可或缺的部分，但由于它们密集的表示形式，使得理解和编辑它们变得困难。尽管最近的方法通过神经层级的稀疏性学习可解释的近似模型，但它们未能准确重建原始映射，这会显著增加模型的下一个标记交叉熵损失。
### Innovation
本文提出了一种稀疏层级分解的新方法，即Mixture of Decoders（MxD）。MxDs不仅保持了原模型的表征能力，还能够适应高度稀疏性的需求。通过一种灵活的张量分解形式，每个激活稀疏的MxD子层实现了具有全秩权重的线性变换。
### Conclusion
实验证明，MxDs在具有3B参数的语言模型上显著优于最先进的方法（例如Transcoders），在稀疏性和准确性之间取得了较好的平衡。此外，在稀疏探针和特征引导方面的进一步评估表明，MxDs学会了类似于自然语言的专门化特征，展示了设计忠实而可解释的分解方法的有希望的新途径。
## 228. `cs.AI` - LeCoDe：交互式法律咨询对话评估的数据集 [PDF](https://arxiv.org/pdf/2505.19667), [HTML](https://arxiv.org/abs/2505.19667)
### Authors
Weikang Yuan,Kaisong Song,Zhuoren Jiang,Junjie Cao,Yujie Zhang,Jun Lin,Kun Kuang,Ji Zhang,Xiaozhong Liu
### Background
个人权利的保护和司法公正的保障需要法律咨询的支持，但高昂的成本和缺乏专业人士使得许多个人无法获得这些服务。近年来，大型语言模型（LLMs）的发展为提供规模化、低成本的法律援助带来了希望，但现有系统在处理现实中的交互性和知识密集型法律咨询方面仍存在不足。
### Innovation
本文引入了LeCoDe，这是一个包含3696个法律咨询对话和110080个对话回合的真实世界多回合基准数据集，旨在评估并提升LLMs的法律咨询能力。通过从短视频平台收集实时咨询并由法律专家进行严格的注释，LeCoDe提供了真实的多回合法律咨询对话。此外，我们还提出了一整套评估框架，从咨询澄清能力和专业建议的质量两个维度来评估LLMs的表现，共包含12个评价指标。
### Conclusion
通过在各种通用和特定领域的LLMs上的广泛实验，我们的结果显示即使是最新的模型如GPT-4，在澄清和建议质量上的表现也十分有限，这凸显了专业咨询场景的复杂性。基于这些发现，我们进一步探讨了提升LLMs法律咨询能力的策略。LeCoDe将促进法律领域对话系统的研究，特别是在模拟真实的用户-专家交互方面。
## 229. `cs.AI` - 利用可微梯度在证明安全性强化学习中的应用 [PDF](https://arxiv.org/pdf/2506.01665), [HTML](https://arxiv.org/abs/2506.01665)
### Authors
Tim Walter,Hannah Markgraf,Jonathan Külz,Matthias Althoff
### Background
在安全性关键应用中部署自主机器人需要安全性保证。证明安全的强化学习是一个活跃的研究领域，它试图通过安全措施来提供这些保证。这些措施应该在训练过程中整合，以减少仿真到现实之间的差距。尽管有几种方法可以为基于抽样强化学习提供保护，但基于分析梯度的强化学习通常需要较少的环境交互就能获得更好的表现。但是，还没有为这种学习范式提供保护措施的方法。目前的工作通过开发第一个有效的保护措施填补了这一空白，该保护措施被纳入最先进的学习算法和可微仿真中。
### Innovation
开发了首个有效的保护措施以适应基于分析梯度的强化学习。通过分析现有的可微保护措施，对其进行修改和整合到一个最先进的学习算法和可微仿真中。利用数值实验评估了不同保护措施对学习的影响，显示了保护性训练可以在不牺牲性能的前提下进行。
### Conclusion
研究结果表明，即使在保护性训练中，学习性能也不会受到损害。提供了额外的可视化结果以支持这些发现。
## 230. `cs.AI` - 机器参数过剩情况下的机器遗忘 [PDF](https://arxiv.org/pdf/2505.22601), [HTML](https://arxiv.org/abs/2505.22601)
### Authors
Jacob L. Block,Aryan Mokhtari,Sanjay Shakkottai
### Background
机器遗忘算法旨在移除特定训练样本的影响，理想情况下恢复仅基于其余数据训练的模型。在参数过剩的场景中，许多模型可以近似或精确拟合数据，这意味着将解定义为在保留数据集上最小化损失的任意解是不合适的。因为在参数不足的情况下，原始模型就可能已经可以通过保留的数据，满足这一条件，而损失梯度在这种情况下消失，导致基于梯度扰动的先前方法失效。因此，需要新的定义和算法来适应参数过剩的情况。
### Innovation
在参数过剩场景下，定义机器遗忘的解为保留数据上的最小复杂度近似模型，并提出了一种新的算法框架，该框架只需要获取原始解在保留数据集上的模型梯度。通过最小化经过特定条件约束的扰动正则化目标，第一次将插值条件松弛为一阶条件。通过不同的模型类别，提供了精确和近似的遗忘保证，并演示了框架在多项遗忘实验中优于现有基线的方法实施效果。
### Conclusion
论文通过定义保留数据上的最小复杂度近似模型，提出了新的遗忘算法框架，通过一阶松弛插值条件，提供了一种解决参数过剩情况下的机器遗忘问题的新方法，并通过实验结果验证了其有效性和优越性。
## 231. `cs.AI` - REOrdering Patches Improves Vision Models [PDF](https://arxiv.org/pdf/2505.23751), [HTML](https://arxiv.org/abs/2505.23751)
### Authors
Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta
### Background
序列模型如transformer需要将输入表示为一维序列。在视觉领域，这通常通过固定行优先（栅格扫描）顺序来实现图像的展平。虽然全自注意机制是置换等变的，但现代长序列transformer越来越多地依赖于破坏这种不变性的架构近似，从而对块的顺序产生敏感性。文章指出，在这种情况下，块的顺序显著影响模型性能，简单的替代顺序，如列优先或希爾伯特定理曲线，能显著改变准确性。
### Innovation
文章提出了REOrder，一种双阶段框架，用于发现任务最优的块顺序。第一阶段通过评估各种块序列的可压缩性，定义了信息论先验。第二阶段通过优化Plackett-Luce策略，学习策略置换。这种方法在组合置换空间中实现了高效的策略学习。REOrder在ImageNet-1K上比行优先顺序提高了高达3.01%的顶级准确性，并且在Functional Map of the World数据集上提高了13.35%的准确性，从而改进了视觉模型的表现。
### Conclusion
该研究证明了块顺序对视觉模型性能的重要性，并且通过REOrder框架有效改进了模型的准确性.
## 232. `cs.AI` - Balanced Token Pruning: 超越局部优化加速 vision-language 模型 [PDF](https://arxiv.org/pdf/2505.22038), [HTML](https://arxiv.org/abs/2505.22038)
### Authors
Kaiyuan Li,Xiaoyue Chen,Chen Gao,Yong Li,Xinlei Chen
### Background
大规模视觉-语言模型（LVLMs）在多模态任务中表现出色，通过将图像编码成数千个标记实现这一效果。然而，大量的图像标记导致了计算负担的显著增加，特别是在使用动态高分辨率输入时。现有方法通过标记剪枝尝试减少图像标记的数量，通常基于注意力分数或图像标记的多样性来选择标记。实验证明，现有方法在决定是否剪枝时往往忽视了剪枝对当前层输出（局部）和后续层输出（全局）的影响，导致剪枝效果不佳。因此，亟需一种更加综合的方法来平衡两者的影响。
### Innovation
提出了一种名为平衡标记剪枝（BTP）的插件方法，用于剪枝视觉标记。BTP方法通过一个小规模的校准集将剪枝过程分为多个阶段。在早期阶段，BTP强调剪枝对后续层输出的影响；而在较深层阶段，则更注重保持局部输出的一致性。广泛的实验表明，该方法在多个基准测试中具有广泛的有效性，平均压缩率高达78%，同时保留了96.7%的原模型性能。
### Conclusion
加速视觉语言模型的现有方法往往只考虑了局部优化，而忽略了全局影响。而本文提出的BTP方法通过分阶段考虑剪枝对局部输出和全局输出的影响，实现了有效的剪枝效果，显著降低了计算负担并保持了模型的性能。
## 233. `cs.AI` - 通过空间推理进行3D室内场景合成的直接数值布局生成 [PDF](https://arxiv.org/pdf/2506.05341), [HTML](https://arxiv.org/abs/2506.05341)
### Authors
Xingjian Ran,Yixuan Li,Linning Xu,Mulin Yu,Bo Dai
### Background
3D室内场景的现实合成对具身人工智能和数字内容创建至关重要。这项任务可以自然地分为两个子任务：物体生成和布局生成。尽管最近的生成模型在物体级别上显著提高了质量和可控性，但布局生成仍然具有挑战性，因为现有数据集有限。现有的方法要么过度拟合这些数据集，要么依赖于预定义的约束来优化数值布局，牺牲了灵活性。因此，它们无法生成开放词汇和精细用户指令对齐的场景。
### Innovation
我们提出了DirectLayout，这是一个框架，直接从文本描述中生成数值3D布局，利用大型语言模型（LLMs）的通用空间推理。DirectLayout分解生成过程为三个阶段：生成顶视图（BEV）布局、将其提升到3D空间中以及细化物体放置。我们利用基于3D-Front数据集的Chain-of-Thought（CoT）激活来引导模型掌握基本的物体放置原则。此外，我们设计了CoT-Grounded生成布局奖励，以增强泛化能力和空间规划。在推断时，DirectLayout通过上下文学习解决资产-布局不匹配问题。实验证明，DirectLayout实现了令人印象深刻的语义一致性、泛化能力和物理可信度。
### Conclusion
DirectLayout框架通过直接从文本描述生成数值3D布局，结合大型语言模型的通用空间推理，有效地解决了3D室内场景合成中的布局生成难题，提升了生成场景的语义一致性、泛化能力和物理可信度。
## 234. `cs.AI` - 采用扰动后合并：连续学习的两阶段框架 [PDF](https://arxiv.org/pdf/2505.22389), [HTML](https://arxiv.org/abs/2505.22389)
### Authors
Haomiao Qiu,Miao Zhang,Ziyue Qiao,Liqiang Nie
### Background
连续学习（CL）的目标是使模型能够在一系列任务中持续获取新知识，同时避免遗忘之前学到的信息。现有的CL方法仅依赖最近任务的参数进行推理，这使它们容易发生灾难性遗忘。本文探讨了在CL框架中引入模型合并技术的方法，以减轻遗忘问题。通过理论分析，提出了一个新的两阶段框架，第一阶段结合扰动与合并技术，第二阶段利用正则化项减少合并引入的降级影响。该方法已经在多个连续学习基准数据集上展示了最佳性能，而代码可以在提供的链接中获取。
### Innovation
本文提出了一种新颖的连续学习框架Perturb-and-Merge (Ptextbf{textit{textamp;M}})，该框架将模型合并技术引入CL中以减轻遗忘问题。它通过形成前一个模型和新训练任务专用模型的凸组合来构建新的模型。此外，通过引入正则化项来减少合并过程带来的降级影响，并设计了一种无额外前向和反向传播的随机扰动策略来有效实现该正则化项的近似。最后，该方法与LoRA相结合以减少内存开销，实现了最佳性能。
### Conclusion
本文提出了一个新颖的两阶段连续学习框架Ptextbf{textit{textamp;M}}，该框架结合扰动与模型合并技术，并通过正则化项减少合并引入的降级影响，从而有效减轻了遗忘问题。实验结果表明，该方法在多个连续学习基准数据集上实现了最先进的性能，而且该框架被设计为对内存占用的影响较小。
## 235. `cs.AI` - HauntAttack: 当攻击成为推理的阴影 [PDF](https://arxiv.org/pdf/2506.07031), [HTML](https://arxiv.org/abs/2506.07031)
### Authors
Jingyuan Ma,Rui Li,Zheng Li,Junfeng Liu,Heming Xia,Lei Sha,Zhifang Sui
### Background
新兴的大规模推理模型（LRMs）在数学和推理任务中表现出色，展现了显著的能力。然而，提高推理能力并揭露内部推理过程也引入了新的安全漏洞。关键问题在于：当推理与危害性交织时，LRMs在推理模式下是否会更加容易遭受推理攻击？
### Innovation
该研究引入了HauntAttack，这是一种新颖且通用的黑盒对抗攻击框架，系统地将有害指令嵌入到推理问题中。具体来说，该框架通过修改现有问题的关键推理条件以有害指令，从而逐步引导模型生成不安全的输出。该研究在11个LRMs上进行了评估，获得了70%的平均攻击成功率，相对于最强的先验基线提高了12个百分点。
### Conclusion
进一步分析显示，即使是最先进的与安全对齐的模型也高度易受基于推理的攻击，为未来模型开发中平衡推理能力和安全性提供了宝贵的见解。
## 236. `cs.AI` - FuseUNet: U-形网络的多尺度特征融合方法 [PDF](https://arxiv.org/pdf/2506.05821), [HTML](https://arxiv.org/abs/2506.05821)
### Authors
Quansong He,Xiangde Min,Kaishen Wang,Tao He
### Background
医学图像分割是计算机视觉中的关键任务，UNet作为这一领域的里程碑架构而广受认可。UNet家族的经典组件是跳跃连接，但它们存在两个显著的局限性：（1）不同尺度特征之间的缺乏有效交互；（2）依靠简单的拼接或加法操作来整合信息，限制了信息的有效整合。尽管最近对UNet的改进集中在增强编码器和解码器的能力上，但这些问题仍未得到充分的关注。
### Innovation
为了克服这些挑战，我们提出了一种新的多尺度特征融合方法，将UNet的解码过程重新构想为求解初始值问题（IVP），将跳跃连接视为离散节点。通过利用线性多步法的原理，我们提出了一种自适应常微分方程方法来实现有效的多尺度特征融合。我们的方法不依赖于编码器和解码器的架构，使其能够适应各种类似U-Net的网络。
### Conclusion
在ACDC、KiTS2023、MSD脑肿瘤和ISIC2017/2018皮肤病变分割数据集上的实验表明，该方法提高了特征利用效率，减少了网络参数数量，并保持了高性能。源代码可在该网址找到：this https URL.
## 237. `cs.AI` - LeVo: 高质量歌曲生成与多偏好对齐 [PDF](https://arxiv.org/pdf/2506.07520), [HTML](https://arxiv.org/abs/2506.07520)
### Authors
Shun Lei,Yaoxun Xu,Zhiwei Lin,Huaicheng Zhang,Wei Tan,Hangting Chen,Jianwei Yu,Yixuan Zhang,Chenyu Yang,Haina Zhu,Shuai Wang,Zhiyong Wu,Dong Yu
### Background
近年来，大型语言模型（LLMs）和音频语言模型在音乐生成方面取得了显著进步，特别是在歌词到歌曲生成方面。然而，现有的方法仍然难以处理复杂的歌曲结构和高质量数据的缺乏，这导致了音频质量、音乐性和指令跟随等多个方面的局限性。
### Innovation
本文提出了LeVo框架，结合了LeLM和Music Codec。LeLM能够并行建模两类令牌：混合令牌，代表人声和伴奏的混合音频，以实现更好的人声-伴奏和谐；以及双轨令牌，单独编码人声和伴奏，以生成高质量的歌曲。此外，LeVo引入了基于直接偏好优化（DPO）的多偏好对齐方法，通过半自动数据构造过程和训练后处理来处理多种人类偏好。LeVo在客观和主观指标上显著优于现有开源方法，且在与行业系统的竞争中表现不错。
### Conclusion
通过实验结果和消融研究进一步证明了LeVo设计的有效性。相关音频示例和源代码可以在提供的链接中找到。
## 238. `cs.AI` - 自回归图像生成的水印 [PDF](https://arxiv.org/pdf/2506.16349), [HTML](https://arxiv.org/abs/2506.16349)
### Authors
Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez
### Background
生成模型的输出水印化作为一种有潜力的方法，已被用于追踪它们的来源。尽管自回归图像生成模型因其潜在的滥用问题而引起了广泛关注，但在此之前没有任何研究尝试在生成令牌级别上水印它们的输出。
### Innovation
本文作者通过调整语言模型水印技术首次提出了一种在自回归图像生成模型生成输出进行水印的可行方法。为解决反向环路一致性（RCC）不足的问题，以及使方法对常见的图像变换、神经压缩和去除攻击具有鲁棒性，作者提出了(i) 一种自定义的令牌-反令牌微调流程以提高RCC，(ii) 一种互补的水印同步层。
### Conclusion
实验结果表明，作者的方法能够在理论上具有支持的p值上实现可靠和鲁棒的水印检测。相关代码和模型可在这个链接中找到：[this https URL]。
## 239. `cs.AI` - ReDit: 改进LLM政策优化的奖励抖动方法 [PDF](https://arxiv.org/pdf/2506.18631), [HTML](https://arxiv.org/abs/2506.18631)
### Authors
Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu
### Background
DeepSeek-R1 通过规则基础的奖励系统成功提升了大型语言模型（LLM）的推理能力，然而这种奖励机制往往是离散的，容易导致梯度异常、优化不稳定和收敛缓慢。
### Innovation
提出了ReDit方法，通过在离散的奖励信号中添加简单的随机噪声来抖动奖励信号，从而在整个学习过程中持续提供探索性的梯度，使梯度更新更加平滑并加速收敛。同时，噪声减少了平坦奖励区域的确定性，促使模型探索新策略并逃离局部最大值。
### Conclusion
实验表明，ReDit方法在各种任务上都能有效提高性能，只需约10%的训练步骤即可达到与原始GRPO相同的效果，并且在相似训练时间下的性能提高了4%。可视化结果显示ReDit显著减轻了梯度问题。此外，还提供了理论分析以进一步验证这些优点。
## 240. `cs.AI` - 使用Transformer学习模幂运算 [PDF](https://arxiv.org/pdf/2506.23679), [HTML](https://arxiv.org/abs/2506.23679)
### Authors
David Demitri Africa,Sara M. Kapoor,Theo Simon Sorg,Challenger Mishra
### Background
模幂运算对数论和密码学至关重要，但其从机制可解释性的角度研究仍相对不足。本文采用了一种4层的编码-解码变换器模型来执行模幂运算，并研究了训练过程中数字推理能力的涌现。通过有原则的采样策略、基于PCA的嵌入分析和激活补丁技术，深入了解了模幂运算的数论属性是如何被模型编码的。
### Innovation
文章采用了一种基于编码-解码结构的4层Transformer模型来学习模幂运算，发现了逆运算训练能够显著提升性能，并在相关模数间突然产生泛化。此外，还发现最后一层的子图结构足够完成常规幂运算的任务，这表明Transformer模型通过专门的计算电路学习模运算，为进一步提高模型的可解释性和效率提供了新的途径。
### Conclusion
研究表明，Transformer模型通过具体的计算电路学习模运算，这种机制性的理解有望带来更可解释和高效的神经网络方法，为模块运算的研究开辟了新的方向。
## 241. `cs.AI` - ixi-GEN：通过领域适应连续预训练实现高效的工业小语言模型 [PDF](https://arxiv.org/pdf/2507.06795), [HTML](https://arxiv.org/abs/2507.06795)
### Authors
Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon
### Background
开源的大语言模型（LLMs）为企业应用带来了机会，但许多组织尚未建立部署和维护大规模模型的基础设施。因此，尽管存在固有的性能限制，小语言模型（sLLMs）成为一种实用的替代方案。尽管已经探索了领域适应连续预训练（DACP），但在商业环境中的实用性和效果仍需验证。
### Innovation
研究验证了基于DACP的方法在多种基础模型和服务领域中的有效性，开发了DACP应用的小语言模型（ixi-GEN）。通过广泛的实验和实际评估，研究展示了ixi-GEN模型在目标领域的性能显著提高，同时保持了一般能力，提供了一种高效且可扩展的企业级部署方案。
### Conclusion
ixi-GEN模型通过领域适应连续预训练实现了在多种基础模型和服务领域中显著提高目标性能的效果，同时保持了一般的能力，为企业的部署提供了高效且可扩展的解决方案。
## 242. `cs.AI` - 基于流的方法用于具有非高斯或异方差噪声的动态时序因果模型 [PDF](https://arxiv.org/pdf/2506.17065), [HTML](https://arxiv.org/abs/2506.17065)
### Authors
Abdellah Rahmani,Pascal Frossard
### Background
理解多元时间序列中的因果关系在许多场景中至关重要，例如金融或神经科学数据。此类时间序列通常包含多个不同因果结构的非可知边界时间段。推断因果依赖关系和时间段变化对分析底层过程至关重要。然而，在这种非平稳环境下识别因果结构具有挑战性，因为(1)非平稳性(每个时间段有其独特的因果图和混合函数)，(2)复杂的噪声分布，可能非高斯或异方差。现有因果发现方法无法解决这些挑战，通常假设平稳或常量方差高斯噪声。
### Innovation
我们提出了FANTOM，这是一个统一框架，用于处理非平稳过程以及非高斯和异方差噪声。FANTOM同时推断出不同时间段的数量及其对应的索引，并学会每个时间段的有向无环图(DAG)。它使用贝叶斯期望最大算法，最大化数据对数似然性的证据下界。在理论方面，我们证明，在温和的假设下，在FANTOM的建模中引入的时间异方差因果模型在平稳和非平稳设置中是可识别的。
### Conclusion
在合成和真实数据方面的广泛实验表明，FANTOM在现有方法中表现出色。
## 243. `cs.AI` - 从高信噪比雷达信号到心电图：基于心血管聚焦算法的小数据情景下迁移学习模型 [PDF](https://arxiv.org/pdf/2506.19358), [HTML](https://arxiv.org/abs/2506.19358)
### Authors
Yuanyuan Zhang,Haocheng Zhao,Sijie Xiong,Rui Yang,Eng Gee Lim,Yutao Yue
### Background
雷达信号中的心电图（ECG）特征已被文献成功恢复，但性能高度依赖高质量的雷达信号和大量的雷达-ECG配对进行训练，这限制了其在数据稀缺的新场景中的应用潜力。因此，该研究旨在解决在数据有限的新场景下如何通过心血管聚焦和追踪（CFT）算法精确追踪心脏位置，以确保高效获取高质量雷达信号的问题。同时，提出了一种迁移学习模型（RFcardi），该模型能够在没有心电图真实数据的情况下从雷达信号中提取心血管相关的信息，只需少量同步雷达-ECG配对即可对预训练模型进行微调，进行ECG恢复。实验结果表明，提出的CFT能够动态识别心脏位置，而RFcardi模型能够在使用少量雷达-ECG配对进行训练后有效地生成真实的心电图恢复结果。代码和数据集将在发表后提供。
### Innovation
提出了心血管聚焦和追踪（CFT）算法，能够精确追踪心脏位置，确保高效获取高质量雷达信号；并开发了一种基于雷达信号（无需心电图真实数据）提取心血管相关信息的迁移学习模型（RFcardi），仅需少量同步雷达-ECG配对即可对预训练模型进行微调，进行ECG恢复，显著减少了对数据的需求，提升了在数据有限新场景下的应用效果。
### Conclusion
提出的CFT算法可以动态识别心脏位置，RFcardi模型能够在少量雷达-ECG配对训练后生成真实的心电图恢复结果。相关代码和数据集将在论文发表后提供。
## 244. `cs.AI` - AssistedDS：外部领域知识如何协助LLM在自动化数据科学中评估基准 [PDF](https://arxiv.org/pdf/2506.13992), [HTML](https://arxiv.org/abs/2506.13992)
### Authors
An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding
### Background
大型语言模型（LLMs）已经提高了数据科学工作流程的自动化水平。然而，尚不清楚这些模型是否能够像人类数据科学家那样，批判性地利用外部领域知识。为了回答这个问题，我们介绍了一个名为AssistedDS（辅助数据科学）的基准，以系统地评估LLMs在表格预测任务中处理领域知识的能力。该基准包括具有明确生成机制的合成数据集和现实世界的大规模数据分析竞赛，每个竞赛都有经过筛选的文档集，提供有关数据清洗、特征工程和模型选择的专业见解。我们的研究评估了尖端LLMs将有益信息与有害信息区分开并应用的能力，通过验证提交的有效性、信息检索准确性和预测性能来进行评估。研究结果揭示了三个关键发现：（1）LLMs在不加批判地采用所提供信息时表现不佳，当引入对抗性内容时，其预测性能显著下降；（2）有益的指导往往无法抵消对抗性信息的负面影响；（3）在Kaggle数据集中，LLMs在处理时间序列数据、在不同折中的特征工程一致性和正确解释分类变量方面经常出错。这些发现凸显了当前模型在批判性评估和利用专家知识方面的巨大缺口，指出了研发更稳健、能感知知识的自动化数据科学系统的重要研究方向。
### Innovation
我们提出了AssistedDS基准，旨在系统评估LLMs在表格预测任务中处理领域知识的情况。该基准包括合成数据集和现实世界的大规模数据分析竞赛，每个竞赛都有经过筛选的文档集，提供领域特定的见解。我们评估了尖端LLMs如何辨别和应用有益于有害的领域知识，通过提交的有效性、信息检索准确性和预测性能来进行评估。
### Conclusion
我们的研究表明，当前的LLMs在处理领域知识时存在显著问题。他们往往不加批判地接受所提供信息，导致在引入对抗性内容时预测性能急剧下降。有益的指导往往不足以抵消对抗性信息的负面影响，在某些具体任务中，如处理时间序列数据、一致性的特征工程和分类变量的正确解释，LLMs常会犯错误。这些发现说明了领域知识的批判性评估和利用对当前LLMs的重要不足，揭示了一个重要的研究方向，即开发更稳健的知识感知自动化数据科学系统。我们的数据和代码已公开。
## 245. `cs.AI` - 在HPC集群中服务LLMs：Qualcomm Cloud AI 100 Ultra与NVIDIA数据中心GPU的对比研究 [PDF](https://arxiv.org/pdf/2507.00418), [HTML](https://arxiv.org/abs/2507.00418)
### Authors
Mohammad Firas Sada,John J. Graham,Elham E Khoda,Mahidhar Tatineni,Dmitry Mishin,Rajesh K. Gupta,Rick Wagner,Larry Smarr,Thomas A. DeFanti,Frank Würthwein
### Background
本文对Qualcomm的Cloud AI 100 Ultra (QAic) 加速器在大型语言模型 (LLM) 推断中的性能进行了基准分析，测试了其能量效率（瓦特每吞吐量），性能和硬件扩展性，相对于NVIDIA A100 GPU（4x和8x配置）在国家研究平台（NRP）生态系统内的表现。通过使用vLLM框架，共测试了12个开源LLM模型，参数数量范围从1.24亿到700亿个。研究发现QAic在特定模型上具有竞争力的能量效率，并且能够实现更细粒度的硬件分配：在某些情况下，70亿参数模型仅需1个QAic卡而非8个A100 GPU，且功率消耗仅为前者的1/20（148W对比2,983W）。对于较小的模型，单个QAic设备所消耗的功率比我们的4-GPU A100配置低35倍（36W对比1,246W）。
### Innovation
本文创新地将Qualcomm Cloud AI 100 Ultra用于大型语言模型推理，并通过性能和能效对比分析，展示了其在特定场景下的优势：能够更高效地分配和使用硬件资源，特别是在能耗受限和资源高效计算集群中，相对于NVIDIA A100 GPU具有明显的优势。
### Conclusion
本文的研究结果提供了关于Qualcomm Cloud AI 100 Ultra在HPC部署中潜在应用的洞见，特别是在能源受限和资源高效的国家研究平台（NRP）环境中，推动了未来的研究和应用方向。
## 246. `cs.AI` - 在表格数据中构建无感知的沿流形攻击 [PDF](https://arxiv.org/pdf/2507.10998), [HTML](https://arxiv.org/abs/2507.10998)
### Authors
Zhipeng He,Alexander Stevens,Chun Ouyang,Johannes De Smedt,Alistair Barros,Catarina Moreira
### Background
表格数据的栅栏特征性质（包括混合的分类和数值特征）导致对抗性攻击具有独特的挑战。与图像数据中的像素扰动保持视觉相似性不同，表格数据缺乏直观的相似性度量，使得定义不可感知的修改变得困难。传统的梯度基方法通常依赖于$textbf{textit{l}_p}$范数约束，这往往会导致生成的对抗性样本偏离原始数据分布。
### Innovation
本文提出了一种使用混合输入变分自动编码器（VAE）的潜在空间扰动框架，以生成统计一致性对抗样本。这个VAE将分类嵌入和数值特征整合到一个统一的潜在流形中，使得扰动可以保持统计一致性。此外，引入了内部数据成功率（IDSR）来联合评估攻击的有效性和分布对齐。
### Conclusion
实验结果表明，本文方法在六个公开可用的数据集和三种模型架构上显著降低了离群值率，并且具有更一致的性能，相比传统输入空间攻击和其它源自图像域的VAE方法，以较低的离群值率和更高的IDSR在六个数据集和三种模型架构上实现了更高的性能。通过超参数敏感性、稀疏性控制和生成架构的综合分析，发现基于VAE的攻击的有效性主要依赖于重建质量以及有足够训练数据的存在。当这些条件满足时，所提出的框架相比输入空间方法在实用性和稳定性方面具有优越性。
## 247. `cs.AI` - 共生：多适配器推理与微调 [PDF](https://arxiv.org/pdf/2507.03220), [HTML](https://arxiv.org/abs/2507.03220)
### Authors
Saransh Gupta,Umesh Deshpande,Travis Janssen,Swami Sundararaman
### Background
参数效率微调（PEFT）允许模型构建者将任务特定参数捕获到适配器中，适配器的大小仅为原始基础模型的一部分。由于PEFT技术的流行，已经为流行的大型语言模型（LLMs）创建了大量的适配器。然而，现有的框架在支持使用多个适配器进行推理或微调方面存在以下不足：1）对于微调，每个任务需要部署其专用的基础模型实例，这导致了GPU内存消耗过多和GPU利用率低下。2）虽然流行的推理平台可以为多个PEFT适配器提供服务，但它们不允许独立的资源管理或不同PEFT方法的混合使用。3）它们不能有效地利用异构加速器。4）它们没有为希望不向服务提供商暴露微调参数的用户提供隐私保障。
### Innovation
在Symbiosis中，我们通过启用基模型的即服务部署解决了上述问题。基础模型的层可以跨多个推理或微调过程共享。我们的拆分执行技术将客户端特定适配器和层的执行与冻结的基础模型层解耦，提供灵活的资源管理功能、微调方法选择和性能目标的实现。我们的方法对模型透明且可以无缝支持大多数transformers库中的模型。我们展示了Symbiosis同时在8块GPU上微调20个Gemma2-27B适配器的应用场景。
### Conclusion
Symbiosis提供了一种新颖的方法，通过共享基础模型层和拆分执行技术解决了现有框架在多适配器推理与微调方面的各种问题，从而在资源管理、微调方法选择和性能目标实现方面提供了更大的灵活性。
## 248. `cs.AI` - 基于频率动态注意调制的密集预测 [PDF](https://arxiv.org/pdf/2507.12006), [HTML](https://arxiv.org/abs/2507.12006)
### Authors
Linwei Chen,Lin Gu,Ying Fu
### Background
视觉变换器(ViTs)在计算机视觉领域取得了显著进展，并在多种任务中表现出优异的性能。然而，ViTs中的注意力机制使得每层功能成为一个低通滤波器，现有的transformer堆叠层结构会带来频率消失的问题。这会导致关键细节和纹理的丢失。
### Innovation
本文提出了一种电路理论启发式的新颖策略，称为频率动态注意调制(FDAM)，该策略可以轻松插入到ViTs中。FDAM直接调节ViTs的整体频率响应，包括两种技术：注意反转(AttInv)和频率动态缩放(FreqScale)。此外，通过特征相似性分析和有效的秩评估，证明了该方法可以避免表示坍塌，从而在各种模型包括SegFormer、DeiT和MaskDINO中实现了持续的性能提升。此外，该方法在遥感检测任务中的单尺度设置中也取得了最先进的成果。
### Conclusion
通过引入FDAM，该研究在包括语义分割、对象检测和实例分割等多个任务中展示了改进，并在遥感检测任务中的单尺度设置中达到了最先进的结果。
## 249. `cs.AI` - 基于量化感知的类脑架构在资源受限设备上高效皮肤疾病分类 [PDF](https://arxiv.org/pdf/2507.15958), [HTML](https://arxiv.org/abs/2507.15958)
### Authors
Haitian Wang,Xinyu Wang,Yiren Wang,Zichen Geng,Xian Zhang,Yu Zhang,Bo Miao
### Background
在边缘设备上实现准确且高效的皮肤病变分类对于可及性的皮肤病学护理至关重要，但由于计算、能量和隐私约束，目前仍具挑战性。
### Innovation
我们提出了QANA，一种针对资源受限硬件增量皮肤病变分类的新型量化感知神经形态架构。QANA巧妙地集成了幽灵模块、高效通道注意机制和挤压-激励模块，实现了低延迟和能效的鲁棒特征表示，并通过其量化感知头和后台兼容变换无缝转换为突触神经网络（SNNs），并在神经类硬件平台上部署。QANA在HAM10000基准数据集和临床数据集上的表现超过了现有的CNN到SNN模型，其准确性及宏观F1分数表现出显著优势。在BrainChip Akida硬件上部署时，QANA实现了1.5 ms的推理延时和每张图片1.7 mJ的能量使用，相较于基于GPU的CNN，其推理延时和能量使用分别减少了94.6%和98.6%。
### Conclusion
这些结果表明，QANA在边缘环境中实现准确、实时和隐私敏感的医学分析的有效性。
## 250. `cs.AI` - 使用大型语言模型实现多机器人团队组合协调 [PDF](https://arxiv.org/pdf/2507.16068), [HTML](https://arxiv.org/abs/2507.16068)
### Authors
Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme
### Background
传统的多机器人协调依赖于任务特定和专家驱动的流程，其中自然语言的任务描述需要由领域专家手动转换为数学公式、算法设计和可执行代码。这种传统方法耗时、对非专家不友好且无法灵活应对任务需求的变化。
### Innovation
提出了LAN2CB（语言到集体行为）框架，利用大型语言模型（LLMs）简化并通用化多机器人协调的流程。LAN2CB通过两个核心模块将自然语言的任务描述转化为可用于多机器人系统的可执行Python代码：(1) 任务分析模块将任务描述解析为行为树，(2) 代码生成模块利用行为树和结构化知识库生成机器人控制代码。此外，还引入了一个自然语言任务描述的数据集以支持开发与基准测试。
### Conclusion
实验表明，无论是在仿真还是真实环境中，LAN2CB都能实现从自然语言到多机器人协调的稳健且灵活的支持，显著减少了手工工程的努力，并且在不同任务类型上有广泛的通用性。
## 251. `cs.AI` - 使用高斯过程作为代理模型基于贝叶斯优化的传感器排序系统工艺参数优化 [PDF](https://arxiv.org/pdf/2507.22766), [HTML](https://arxiv.org/abs/2507.22766)
### Authors
Felix Kronenwett,Georg Maier,Thomas Längle
### Background
传感器基座分选系统能够对物料流进行物理分离，通过传感器采集的数据图像进行评估，并使用执行器执行分选决策。根据物料流特性、系统大小和所需的分选精度，必须不断调整各种工艺参数。然而，由于需求和物料流组成的改变，持续验证和重新调整是必要的。因此，本文提出了一种优化、重复监控和调整传感器基座分选系统工艺参数的方法，以适应不断变化的要求和物料流组成变化。具体来说，基于贝叶斯优化，使用高斯过程回归模型作为代理模型，以包含其中的不确定性实现所需系统行为，同时减少必要实验的数量，还考虑了两个可能的优化目标，即两个物料输出流的要求，并在模型计算中考虑了确定分选精度时的不确定性，通过三种示例工艺参数进行了评估验证。
### Innovation
本文提出的方法采用了基于贝叶斯优化的高斯过程回归模型作为代理模型，用于优化传感器基座分选系统的工艺参数。这种方法既能减少实验次数，又能同时考虑两个可能的优化目标，并在模型计算过程中考虑了不确定性的因素，从而提高分选的准确性。
### Conclusion
通过实验验证，提出的方法成功地优化了传感器基座分选系统的工艺参数，验证了在高斯过程回归模型和贝叶斯优化结合下的有效性和实用性，为分选系统的操作和维护提供了新的视角和支持。
## 252. `cs.AI` - LFD: 层融合解码以利用检索增强生成中的外部知识 [PDF](https://arxiv.org/pdf/2508.19614), [HTML](https://arxiv.org/abs/2508.19614)
### Authors
Yang Sun,Zhiyong Xie,Dan Luo,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li,Lixin Zou
### Background
检索增强生成（RAG）将外部知识融入大型语言模型（LLMs），提高了它们对下游任务的适应性，使得模型能够更新信息。最近的实证研究表明，向检索出的相关文档中注入噪声实际上可以更好地利用外部知识，提高生成质量。尽管这种现象令人难以置信且在实践中难以应用，但它使研究人员能够更精细地控制和分析LLMs如何整合外部知识。
### Innovation
本文提出了层融合解码（LFD），这是一种简单的解码策略，直接将中间层的表示与最终层的解码输出相结合，充分利用外部事实知识。同时，还引入了内部知识评分（IKS）标准来确定最佳中间层，选择后半段层中IKS值最低的层。实验证明LFD有助于RAG系统更有效地揭示检索出的上下文知识。
### Conclusion
实验结果表明，LFD能够帮助RAG系统更有效地利用检索出的上下文知识，同时保持较低的成本。
## 253. `cs.AI` - 变化点时间序列预测的校准预测 [PDF](https://arxiv.org/pdf/2509.02844), [HTML](https://arxiv.org/abs/2509.02844)
### Authors
Sophia Sun,Rose Yu
### Background
校准预测已被探索作为一种通用且高效的方法来为时间序列提供不确定性量化。然而，当前的方法难以处理具有变化点（数据生成过程中的突然偏移）的时间序列数据。
### Innovation
本文提出了一种新的时间序列表现变更的校准预测算法（CPTC），通过结合一个预测潜在状态的模型以及在线校准预测来建模非平稳时间序列中的不确定性，来解决这一难题。证明了CPTC在最少假设下在时间序列设置中的有效性和增强的适应性，并在6个合成和实际数据集上展示了与最先进的基线相比的改进的有效性和适应性。
### Conclusion
研究证明CPTC在时间序列中的有效性，并通过比较实际应用中的表现，显示出了比现有方法更好的适应性和有效性。
## 254. `cs.AI` - MCIF: 多模态跨语言指令遵循基准数据集来自科学演讲 [PDF](https://arxiv.org/pdf/2507.19634), [HTML](https://arxiv.org/abs/2507.19634)
### Authors
Sara Papi,Maike Züfle,Marco Gaido,Beatrice Savoldi,Danni Liu,Ioannis Douros,Luisa Bentivogli,Jan Niehues
### Background
近年来，大型语言模型的发展推动了多模态LLMs（MLLMs）的出现，这些模型能够整合文本、语音和视觉信息。随着MLLMs从单一语言、单一任务的系统发展成为通用命令遵循模型，评估其跨语言和多模态能力的新挑战出现了。现有的基准测试在多个维度上评估模型的能力时存在局限性：它们通常局限于英语，主要集中在单一模态下，依赖于简短的上下文，或者缺乏人类注释，这些都限制了对语言、模态和任务复杂性全面评估。为了解决这些问题，作者提出MCIF（多模态跨语言指令遵循），一个基于科学演讲、多语言的人类注释基准数据集，旨在评估多模态、跨语言环境下的指令遵循能力，涵盖短文和长文输入。MCIF还包括了三种核心模态（语音、视觉和文本）和四种不同语言（英语、德语、意大利语和中文），使评估能够全面考察MLLMs的跨语言解读指令和结合多模态上下文信息的能力。MCIF数据集将在CC-BY 4.0许可证下发布，以促进开放研究和MLLMs的发展。
### Innovation
提出了MCIF（多模态跨语言指令遵循），这是首个基于科学演讲的多语言人工注释基准数据集，能够同时评估多模态、跨语言环境下的指令遵循能力，涵盖简短和长篇输入。MCIF跨越三种核心模态和四种不同语言，填补了当前基准在多语言和多模态方面评估的空白，为MLLMs的能力提供了全面的评估框架。此外，该数据集的开放获取特性进一步促进了多模态语言模型的研究和开发。
### Conclusion
MCIF为评估多模态语言模型在跨语言和多模态环境中的指令遵循能力提供了新的基准，可以更好地衡量模型在复杂任务中的表现。数据集的发布鼓励了开放研究和MLLMs的发展。
## 255. `cs.AI` - DMSC: 动态多尺度协调框架用于时间序列预测 [PDF](https://arxiv.org/pdf/2508.02753), [HTML](https://arxiv.org/abs/2508.02753)
### Authors
Haonan Yang,Jianchao Tang,Zhuo Li,Long Lan
### Background
时间序列预测（TSF）面临着模型不同规模复杂时间依赖关系的持久挑战。尽管最近的研究利用了不同的分解操作和基于CNN、MLP或Transformer的新型架构，但现有方法仍然受到固定分解策略、片段化依赖关系建模和不灵活融合机制的限制，限制了其建模复杂时间依赖关系的能力。
### Innovation
我们提出了一种新的动态多尺度协调框架（DMSC），其中包括多尺度块（EMPD）、三元交互块（TIB）和自适应尺度路由 MoE 块（ASR-MoE）。EMPD动态地将序列分割为具有指数级粒度的多层次块，TIB共同建模每个层分解表示内的块内、块间以及跨变量依赖关系。EMPD和TIB共同构成多层渐进级联架构，通过门控路径使粗粒度表示从早期层引导后续层的精细特征提取。ASR-MoE通过利用具有时域权重的专业全球和局部专家动态融合多尺度预测。
### Conclusion
在13个真实世界基准上的全面实验表明，DMSC在时间序列预测任务中保持了最先进的性能和计算效率。代码可在该链接处获得。
## 256. `cs.AI` - 当前的AI会议模式不可持续！诊断集中式AI会议危机 [PDF](https://arxiv.org/pdf/2508.04586), [HTML](https://arxiv.org/abs/2508.04586)
### Authors
Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He
### Background
人工智能（AI）会议对于促进研究、分享知识和培养学术社区至关重要。然而，它们的迅速扩张使得中央会议模式变得越来越不可持续。本文通过数据驱动的方法诊断了一场结构危机，威胁到了科学研究的基本目标，包括知识传播、公平性和社区福祉。论文指出了四个关键领域的问题：（1）科学上，每位作者的每年论文发表率在过去十年中几乎翻了一番，超过4.5篇；（2）环境上，单个会议的碳足迹超过了举办城市的日均排放量；（3）心理上，在线社区讨论的71%反映了消极情绪，35%提到了心理健康问题；（4）后勤上，顶级会议如2024年的NeurIPS的参会人数开始超过场地容量。这些压力表明系统已经与核心使命脱节。
### Innovation
本文提出了社区联办会议（CFC）模型，将同行评审、展示和社交网络分离为全球化协调但本地组织的组件，为AI研究提供了一条更可持续、包容和有弹性的道路。
### Conclusion
现有AI会议模式不可持续，四个关键问题揭示了系统与核心使命的脱节。CFC模型提出了一个新的解决方案，旨在更可持续、包容和有弹性地推进AI研究。
## 257. `cs.AI` - Memory Decoder: 一种预训练的插件式记忆模块 [PDF](https://arxiv.org/pdf/2508.09874), [HTML](https://arxiv.org/abs/2508.09874)
### Authors
Jiaqi Cao,Jiarui Wang,Rubin Wei,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin
### Background
大型语言模型（LLMs）在通用语言任务上展示了强大的能力，但将它们适应特定领域仍然是一个挑战。当前的方法，如Domain Adaptive Pretraining (DAPT)，需要进行昂贵的全参数训练，并且会产生灾难性遗忘的现象。另外，Retrieval-Augmented Generation (RAG) 方法在推理过程中由于昂贵的最近邻搜索和更长的上下文引入了显著的延迟。
### Innovation
论文引入了Memory Decoder，这是一种即插即用的预训练记忆模块，能够使模型高效地适应特定领域，而无需改变原始模型的参数。Memory Decoder 采用一个小的变压器解码器，学习模仿外部非参数检索器的行为。训练完成后，Memory Decoder 可以无缝地与任何具有相同分词器的预训练语言模型集成，无需进行模型特定的修改。实验结果显示，Memory Decoder 使 Qwen 和 Llama 模型在三个不同专业领域（生物医学、金融、法律）中的泛化表现得到提升，平均 perplexity 减少 6.17 点。
### Conclusion
总体而言，Memory Decoder 引入了一种基于特别预训练记忆组件的新范式，该记忆架构可以以即插即用的方式集成，有效地增强了多个模型在目标领域的性能。
## 258. `cs.AI` - 无线边缘网络中多智能体强化学习的任务卸载 [PDF](https://arxiv.org/pdf/2509.01257), [HTML](https://arxiv.org/abs/2509.01257)
### Authors
Andrea Fox,Francesco De Pellegrini,Eitan Altman
### Background
在边缘计算系统中，自主智能体必须在有限的可观测性和通信约束下进行快速的本地决策并竞争共享资源。现有的多智能体强化学习方法往往依赖于集中式评论家或者频繁通信，这在上述约束下表现不佳。
### Innovation
本文提出了一种去中心化的框架，每个智能体分别解决带约束的马尔可夫决策过程（CMDP），并通过共享的约束向量隐式协调。针对任务卸载的具体案例，约束防止共享服务器资源过度使用。这些约束不频繁更新，提供了一种轻量级的协调机制，使智能体能够实现全局资源使用的协调目标，但需要少量直接通信。利用安全强化学习，智能体学会了满足本地和全球目标的策略。在假设条件温和的情况下，建立了理论保证，并通过实验验证了该方法优于集中式和独立的基线，特别是在大规模设置中。
### Conclusion
通过实验证明，在大规模设置中，本文方法在性能上超过了集中式和独立基线。
## 259. `cs.AI` - 使用多语言语言模型进行代码审查：对工业C#项目的实证研究 [PDF](https://arxiv.org/pdf/2507.19271), [HTML](https://arxiv.org/abs/2507.19271)
### Authors
Igli Begolli,Meltem Aksoy,Daniel Neider
### Background
代码审查对于保持软件质量至关重要，但在工业环境中通常耗时且认知负担大。近年来，语言模型的进步为自动化核心审查任务开辟了新的途径。本研究通过实证评估单一语言微调技术在不同类型代码审查任务中的性能，包括代码更改质量估计、审查评论生成和代码精炼。研究将三种不同的模型CodeReviewer、CodeLlama-7B和DeepSeek-R1-Distill在C#特定数据集上进行了微调，该数据集结合了公开基准和工业代码库。研究探讨了训练数据中的编程语言和自然语言组合如何影响语言模型的性能，特别是评论生成方面的性能。同时，研究还将微调后的模型与自动软件分析工具(ASAT)和人类审查员进行了基准测试，以评估其在实际环境中的实用价值。研究结果表明，单一语言微调比多语言基线提高了模型的准确性和相关性。虽然语言模型可以有效地支持代码审查工作流程，特别是在重复性任务方面，但仍需人类审查员来处理语义复杂或上下文相关的变化。此项研究强调了在优化自动化代码审查方面进行语言对齐和任务特定适应的重要性。
### Innovation
本研究通过单一语言微调技术评估了语言模型在三个关键的自动代码审查任务中的性能：代码更改质量估计、审查评论生成和代码精炼。该研究特别关注不同编程语言和自然语言组合如何影响模型的性能，特别是在评论生成方面的表现。此外，研究还比较了微调后的模型与自动软件分析工具（ASAT）和人类审查员的性能，以评估其在实际应用中的实用性。研究成果表明，单一语言微调在提高模型准确性和相关性方面优于多语言基准。另有发现指出，尽管语言模型可以支持代码审查工作流程，但人类审查员在处理语义复杂或上下文相关的变化方面仍占据优势。这项研究强调了为自动代码审查优化特定任务适应性和语言对齐的重要性。
### Conclusion
单一语言微调技术在自动代码审查中的应用显著提升了模型的准确性和相关性。相比之下，虽然语言模型在处理程序依存任务方面表现出色，但在处理语义复杂或上下文相关的变化时仍然需要人类审查员的专业技能。研究还指出，优化语言模型对于特定任务和适应不同的编程语言和自然语言组合至关重要。未来的研究可以进一步探索如何通过强化学习或其他方法来改进语言模型在自动化代码审查中的性能。
## 260. `cs.AI` - 稀疏自编码器神经算子：函数空间中的模型恢复 [PDF](https://arxiv.org/pdf/2509.03738), [HTML](https://arxiv.org/abs/2509.03738)
### Authors
Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar
### Background
虽然柏拉图式的表示假设指出，神经网络在不同架构下会收敛到相似的表示，但神经算子在表示属性方面的研究仍然不足，尽管它们在科学计算领域的应用变得越来越重要。作者将统一表示的问题视为稀疏模型恢复问题，并引入了一种框架，将稀疏自编码器（SAEs）扩展到提升空间和无限维度的函数空间中，使大规模神经算子具有机械可解释性。
### Innovation
引入了一种新的框架，将稀疏自编码器（SAEs）扩展到提升空间和无限维度的函数空间，用于提升和算子模块的实现，旨在提高模型恢复能力、更有效地恢复平滑概念，并在不同分辨率下进行鲁棒推断，同时通过对比稀疏自编码器、提升的稀疏自编码器和神经算子在推理和训练动力学中的表现，展示了这种扩展框架的优势。
### Conclusion
该框架通过引入升维和算子模块，为大规模神经算子增添了有利的归纳偏置，实现了更快的恢复速度、更好的平滑概念恢复性能以及在不同分辨率下进行鲁棒推理的能力，这使得神经算子在功能空间中的模型恢复具有独特的优势。
## 261. `cs.AI` - TianHui: 专为多种传统中医场景设计的领域特定大规模语言模型 [PDF](https://arxiv.org/pdf/2509.19834), [HTML](https://arxiv.org/abs/2509.19834)
### Authors
Ji Yin,Menglan He,Yujie Zhang,Linshuai Zhang,Tingting Ma,Ce Tian,Jie Wu,Lin Xu,Tao Jiang,  ((1) School of Intelligent Medicine, Chengdu University of Traditional Chinese Medicine, Chengdu, China (2) The Acupuncture and Tuina School, Chengdu University of Traditional Chinese Medicine, Chengdu, China (3) Center of Preventive Medicine, Hospital of Chengdu University of Traditional Chinese Medicine, Chengdu, China (4) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China (5) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China)
### Background
在研究环境中，领域特定的大规模语言模型在中医（TCM）中的应用受到了适应性有限、评估数据集不足和计算资源有限的限制。
### Innovation
本文提出了通过上下文数据整合和领域知识融合构建的专门针对中医的TianHui大语言模型。构建了一个大规模的中医语料库，并采用了两阶段训练策略，运用了QLoRA、DeepSpeed Stage 2和Flash Attention 2技术。在12个基准测试上的评估显示，TianHui在六个数据集中所有指标上排名前三，在其他六个数据集中取得最优结果。进一步的实验在多个参数配置中确定了最优配置。
### Conclusion
TianHui能够系统地保存并扩展应用中医知识，所有资源均已开源。
## 262. `cs.AI` - floq：通过流匹配训练批评者以扩大值为基础的强化学习中的计算规模 [PDF](https://arxiv.org/pdf/2509.06863), [HTML](https://arxiv.org/abs/2509.06863)
### Authors
Bhavya Agrawalla,Michal Nauman,Khush Agrawal,Aviral Kumar
### Background
现代大规模机器学习技术的一个特征是使用为中间计算提供密集监督的目标函数，例如在语言模型中使用教师强迫技术或在去噪过程中逐步扩散，这使得模型能够在一般化的层面上学习复杂的函数。受到这一现象的启发，作者研究了迭代计算方法对强化学习中时差（TD）方法的好处。传统的TD方法通常以整体的方式表示价值函数，缺乏迭代计算。
### Innovation
作者引入了一种名为floq（flow-matching Q-functions）的新方法，该方法通过使用流匹配技术参数化Q函数并通过时差学习目标进行训练，该目标包含一个通过多次数值积分计算的目标流。floq通过适当地设置积分步骤数量，允许比整体架构更精细地控制和扩展Q函数的能力。
### Conclusion
通过在一系列具有挑战性的离线强化学习基准测试和在线微调任务中评估，floq实现了接近1.8倍的性能改进。与标准的TD学习架构相比，floq显示出更好的计算能力扩展性，这表明迭代计算在价值学习方面的潜力。
## 263. `cs.AI` - FerretNet:通过局部像素依赖实现高效合成图像检测 [PDF](https://arxiv.org/pdf/2509.20890), [HTML](https://arxiv.org/abs/2509.20890)
### Authors
Shuqiao Liang,Jian Liu,Renzhang Chen,Quanlong Guan
### Background
随着VAEs、GANs和LDMs等高级模型生成的合成图像越来越逼真，合成图像检测面临着重大挑战。本文聚焦于生成过程中引入的两种特征：（1）潜在分布偏差和（2）解码引起的平滑效应，这些特征导致局部纹理、边缘和颜色过渡不一致。
### Innovation
基于Markov随机场的局部像素依赖（LPD）特性，本文提出了一种轻量级神经网络FerretNet，该网络仅包含1.1M参数，可以在开放世界基准测试中高效且稳健地检测合成图像。FerretNet仅在4类ProGAN数据集上进行训练，但在包含22个生成模型的开放世界基准测试中的平均准确率达到97.1%。
### Conclusion
实验结果表明，基于局部像素依赖的FerretNet在合成图像检测方面表现优越，参数量少，检测效果好。相关代码和数据集可在给定的URL找到。
## 264. `cs.AI` - 向人工智能的计量学迈进：隐藏规则环境与强化学习 [PDF](https://arxiv.org/pdf/2509.06213), [HTML](https://arxiv.org/abs/2509.06213)
### Authors
Christo Mathew,Wentian Wang,Jacob Feldman,Lazaros K. Gallos,Paul B. Kantor,Vladimir Menkov,Hao Wang
### Background
研究在Game Of Hidden Rules (GOHR) 环境中的人工智能强化学习，这是一个复杂的谜题游戏。在这个环境中，智能体需要推断并执行隐藏规则来通过在特定容器中放置游戏中的物品来清理一个6×6的板面。研究还探讨了两种不同的状态表示策略：以特征为中心的策略(Feature-Centric, FC)和以对象为中心的策略(Object-Centric, OC)，并通过变换器基线优势演员评论家(Transformer-based Advantage Actor-Critic, A2C)算法进行训练。由于智能体只能获得部分观察信息，因此需要同时推断支配规则并从经验中学习最优策略。实验通过基于规则和实验列表的不同情况来测试模型，分析转移效应以及不同表示方法对学习效率的影响。
### Innovation
采用了Feature-Centric (FC) 和 Object-Centric (OC) 两种不同的状态表示策略，在复杂的Game Of Hidden Rules (GOHR) 环境中利用一种新的Transformer-based Advantage Actor-Critic (A2C) 算法进行训练和学习，这是创新之处。研究还特别关注了不同表示方法下的学习效率和结果转移效应。
### Conclusion
在GOHR环境中的不同实验设置下测试了两种状态表示方法和A2C算法。实验结果展示了不同表示方法对智能体学习效率和策略转移的影响。这些发现有助于更好地理解复杂隐藏规则环境下的强化学习过程，为未来的研究提供了新的见解。
## 265. `cs.AI` - GPT-5在生物医学自然语言处理方面的基准测试 [PDF](https://arxiv.org/pdf/2509.04462), [HTML](https://arxiv.org/abs/2509.04462)
### Authors
Yu Hou,Zaifu Zhan,Min Zeng,Yifan Wu,Shuang Zhou,Rui Zhang
### Background
生物医学文献和临床叙述对于自然语言理解提出了多方面挑战，包括精确的实体提取、文档合成以及多步诊断推理等。为此，研究团队对GPT-5和GPT-4o进行了评估，测试了从零样本到五样本的不同提示策略，并评估了五个核心的生物医学自然语言处理任务：命名实体识别、关系抽取、多标签文档分类、摘要和简化，以及九个扩展的生物医学QA数据集，涵盖了事实性知识、临床推理和多模态视觉理解。
### Innovation
研究使用标准化提示、固定解码参数和一致的推理管道，评估了模型性能、延迟和归一化token成本。GPT-5在推理密集的数据集如MedXpertQA和DiagnosisArena表现突出，同时在多模态QA方面显示出稳定改进。在核心任务中，GPT-5在化学实体识别和ChemProt评分方面表现更好，但在疾病实体识别和摘要方面仍低于领域调整的基线。尽管生成了较长的输出，但GPT-5的延迟相似，且每正确预测的手续费降低了30-50%。详细的分析显示在诊断、治疗和推理亚型方面有所改进，但在边界敏感的抽取和包含大量证据的摘要方面仍具有挑战。
### Conclusion
GPT-5在生物医学QA方面接近部署就绪的表现，提供了准确性和可解释性与经济效率间的良好平衡。研究支持分级提示策略，对于大规模或成本敏感的应用进行直接提示，而在分析复杂或高风险的情境中使用逐步推理框架，强调在这些关键领域中仍需混合解决方案以确保精度和事实真实性。
## 266. `cs.AI` - PersonaMatrix: 一种面向角色感知的法律摘要评估方法 [PDF](https://arxiv.org/pdf/2509.16449), [HTML](https://arxiv.org/abs/2509.16449)
### Authors
Tsz Fung Pang,Maryam Berijanian,Thomas Orth,Breanna Shi,Charlotte S. Alexander
### Background
法律文件通常冗长、复杂且难以理解，不仅对于普通公民，对法律专家也是如此。虽然自动文档摘要具有提高法律知识访问的巨大潜力，但现有的基于任务的评估工具未能充分考虑到不同用户和利益相关者的不同需求。为此，需要一种工具开发框架，既要满足诉讼律师的技术性需求，又要对自我帮助公众进行法律诉讼研究时具有易访问性。
### Innovation
本文介绍了一种名为PersonaMatrix的角色-标准评估框架，通过六个角色（包括法律和非法律用户）的视角对摘要进行评分，并提供了一个受控维度偏移的试点数据集，其中包括美国民事权利案例摘要，这些摘要在深度、易访问性和程序细节方面有所不同，以及多样性-覆盖率指数（DCI），以展示角色感知与角色无关评估者之间的不同优化结果。这项工作为法律AI摘要系统提供了改进的基础，以满足专家和非专家用户的需求，从而提高法律知识的访问性。
### Conclusion
该研究为法律AI摘要系统的优化提供了可能，通过公共GitHub上的代码库和数据实现了角色感知评估框架的公开可用性，以便进一步改进法律AI摘要系统，提高法律知识的可访问性。
## 267. `cs.AI` - 解决自然语言生成中不确定性评估方法评价中的问题 [PDF](https://arxiv.org/pdf/2510.02279), [HTML](https://arxiv.org/abs/2510.02279)
### Authors
Mykyta Ielanskyi,Kajetan Schweighofer,Lukas Aichberger,Sepp Hochreiter
### Background
大型语言模型（LLMs）中的幻觉问题是影响其可靠性的常见问题。近年来，研究人员已经识别出一种特定类型的幻觉，称为虚构化，它是由LLMs的预测不确定性引起的。为了检测虚构化，开发了多种估计自然语言生成（NLG）中预测不确定性的方法。这些方法通常通过将不确定性估计与生成文本的正确性相关来评估，通常使用问答（QA）数据集作为标准基准。然而，常用的近似正确性函数在彼此之间存在显著分歧，从而影响不确定性估计方法评价的排名。这使得能够夸大不确定性估计方法的表现。
### Innovation
论文提出使用多种替代风险指标进行风险相关实验，以提高不确定性估计算法在NLG中的评估稳健性。对于问答任务，通过考虑多个LLM作为评判者的变体来减少评估偏差。此外，还探索了结构化任务以及异常分布和干扰检测任务，以提供更加稳健和可控的风险指标。最后，建议使用不确定性估计方法的Elo评级来在广泛的评估环境中客观总结。
### Conclusion
研究展示了一种新的不确定性评估方法的评价框架，能够提供更加稳健的风险衡量，为NLG中的不确定性估计方法提供了一个客观的评价标准。
## 268. `cs.AI` - WolBanking77: Wolof Banking Speech Intent Classification Dataset [PDF](https://arxiv.org/pdf/2509.19271), [HTML](https://arxiv.org/abs/2509.19271)
### Authors
Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione
### Background
瞬时，意图分类模型在近来取得了显著进展，但这些研究主要集中在高资源语言数据集上，这导致了低资源语言和高文盲率地区（如西非的塞内加尔）的数据缺口。在这些地区，更多的语言是口头传播而非书写或阅读。作为例子，塞内加尔的维奥福语被90%的人口使用，而该国的文盲率为42%。维奥福语在西非地区实际上被超过1000万人使用。本文旨在填补这些空白，为此我们介绍了Wolof银行语音意图分类数据集（WolBanking77），这是一个用于意图分类研究的数据集。WolBanking77目前包含了9791个文本句子和4多小时的口头录音，研究中进行了多种基线实验，包括文本和语音领域的最先进的模型。
### Innovation
本文介绍了一个新的数据集WolBanking77，该数据集针对低资源语言和高文盲率地区的维奥福语在银行业务领域的语音意图分类进行了构建。此外，本文还展示了NLP和ASR模型在该数据集上的准确率和词错误率，并对不同模型进行了比较，同时提供了该数据集用于学术研究和进一步开发的资源链接。
### Conclusion
WolBanking77数据集在银行领域的语音意图分类实验中显示了非常有前景的结果。通过提供这个新的数据集和相关代码，本文旨在促进对该低资源语言的研究，并推动相关技术的发展。
## 269. `cs.AI` - DragFlow：基于区域监督解锁DiT先验的拖动编辑 [PDF](https://arxiv.org/pdf/2510.02253), [HTML](https://arxiv.org/abs/2510.02253)
### Authors
Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong
### Background
拖动基础的图像编辑方法长期以来一直受到目标区域失真问题的困扰，主要是由于早期基础模型Stable Diffusion的先验不足，无法将优化后的潜空间投影回自然图像流形。随着从基于UNet的DDPMs向更可扩展的DiT及其流匹配（如SD3.5, FLUX）技术的转变，生成先验得到了显著加强，使得在各种编辑任务中取得了进展。然而，拖动编辑尚未从中受益。
### Innovation
本文提出了第一个有效的框架用于利用FLUX丰富的先验进行拖动编辑，称为DragFlow，实现在基线上的显著提升。通过引入基于区域的编辑范式，利用仿射变换提供更丰富且一致的特征监督，解决了直接将点拖动编辑应用到DiT的较差表现的问题。此外，还结合了预训练的开放式领域个性化适配器来增强主体一致性，通过梯度掩码等方式保持背景保真度。还使用了多模态大型语言模型（MLLM）解决任务不确定性。通过新构建的区域级拖动基准（ReD Bench）进行评估，结果表明DragFlow超越了基于点的和基于区域的基线，成为拖动图像编辑的新标准。
### Conclusion
DragFlow在DragBench-DR和ReD Bench上的实验表明，该方法在拖动图像编辑中取得了优越的表现，大幅超越了现有的基线方法。随着代码和数据集的公开，它有望为拖动编辑领域带来重要的提升。
## 270. `cs.AI` - 基于约束满意度的Wordle：新颖启发式和跨语种验证 [PDF](https://arxiv.org/pdf/2510.02855), [HTML](https://arxiv.org/abs/2510.02855)
### Authors
Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel
### Background
Wordle提供了一个具有算法复杂性问题的工作测试平台，用于解决约束满足问题（CSP）。现有的求解器依赖于信息论中的熵最大化或基于频率的经验启发式方法，而没有正式的约束处理。该研究是一个关于CSP求解策略的新尝试，引入了CSP意识熵，并结合了贝叶斯词频先验和逻辑约束的概率CSP框架，以改进现有方法并展示新颖的求解策略和技术。
### Innovation
1. 提出了CSP意识熵，该方法在传播约束之后计算信息增益，而不是基于原始候选集。2. 提出了一种概率CSP框架，该框架结合了贝叶斯词频先验和逻辑约束。3. 对2,315个英文词进行评估，展示了在噪声环境中提高成功率和更快的运行时间。4. 通过跨语系验证500个西班牙词，展示了核心CSP原则在不同语言间的通用性，尽管在一定程度上由于语言差异存在差距。5. 提供了34个单元测试，覆盖率高达91%的开源实现，为CSP研究提供了可重复的基础设施。
### Conclusion
采用正式的CSP分析，意识计算启发式，结合概率逻辑框架，具有鲁棒性分析和跨语系验证的组合方法，设置新的性能基准，证明了原则上约束满足技术在结构化谜题解决领域优于经典信息论和基于学习的方法。
## 271. `cs.AI` - 新的数字鸿沟？开发者世界观、烂经济与人工智能时代的民主 [PDF](https://arxiv.org/pdf/2510.04755), [HTML](https://arxiv.org/abs/2510.04755)
### Authors
Jason Miklian,Kristian Hoelscher
### Background
数字技术正在以复杂的方式重塑民主进程。本文探讨了软件开发者的观点、伦理观和工作文化如何影响他们所构建的技术的社会影响和民主潜力。研究发现，尽管开发者普遍认识到其产品对公民自由和政治对话的影响，但他们也经常面临伦理困境和自上而下的压力，这些压力可能导致设计选择背离民主价值。同时，文章还考察了一个新的数字鸿沟，不是互联网接入问题，而是信息质量差异。在烂经济中，大量的用户因无法支付高质量内容的费用，只能接触到低质量、AI驱动的广告主导的互联网。这种背景下，技术创作者的信念与他们所创造的数字生态系统之间形成了强化循环。
### Innovation
文章结合了两个视角来解释数字化转型中的矛盾：一是通过一项针对硅谷软件开发者的调查，揭示开发者的世界观、伦理和工作文化如何影响他们构建的技术的社会影响和民主潜力；二是从烂经济的角度，探讨信息质量差异如何加剧新的数字鸿沟，并对这种现状进行批判性分析。
### Conclusion
研究强调需要采用更符合伦理的设计和政策干预来解决新的数字鸿沟，从而确保技术的进步能够支持而不是削弱民主价值观。
## 272. `cs.AI` - 用锐化的余弦相似性替代Softmax相似性：扩展到千百万上下文注意的理论与实践 [PDF](https://arxiv.org/pdf/2510.04008), [HTML](https://arxiv.org/abs/2510.04008)
### Authors
Sahil Joshi,Agniva Chowdhury,Amar Kanakamedala,Ekam Singh,Evan Tu,Anshumali Shrivastava
### Background
Softmax Attention在处理长上下文时具有二次时间复杂度，这在使用优化的GPU内核时也变得难以实现。例如，FlashAttention（一种GPU优化的Softmax Attention实现）在NVIDIA GH200上处理超过约400万个标记的上下文时无法完成一次前向和后向传递。这种限制使得在当前硬件上使用非常长的上下文窗口变得不切实际。
### Innovation
提出了一种名为RACE Attention的新内核启发式替代Softmax Attention，它的复杂度为序列长度和嵌入维度线性。RACE Attention通过锐化角度（余弦）相似性替换指数核，并通过随机投影和软局部敏感哈希（LSH）来近似注意力输出。这种设计不仅提高了准确率，还减少了运行时间和内存消耗。
### Conclusion
在语言模型、掩码语言模型和文本分类领域，RACE Attention能够匹配强大的基线模型的效果，同时在NVIDIA GH200 GPU上独立处理高达1200万个标记，在Intel Xeon Gold 5220R CPU上可处理高达7500万个标记。这使RACE Attention成为当今硬件上实现千百万上下文窗口的一种实用且理论依据充足的机制。我们希望它能被实际应用中采纳。
## 273. `cs.AI` - FlyLoRA: 通过隐式分层Mixture-of-Experts增强任务解耦和参数效率 [PDF](https://arxiv.org/pdf/2510.08396), [HTML](https://arxiv.org/abs/2510.08396)
### Authors
Heming Zou,Yunliang Zang,Wutong Xu,Yao Zhu,Xiangyang Ji
### Background
LoRA是一种广泛使用的参数高效微调方法，但存在参数干扰问题，导致性能不佳。虽然基于MoE的LoRA变体在单任务指令微调中缓解任务内相关性方面表现出潜力，但在多任务模型合并中由于任务间干扰仍无能为力。
### Innovation
提出了一种基于MoE的方法——FlyLoRA，通过以下方面解决LoRA问题：1. 在上投影矩阵中引入分层专家激活，2. 使用冻结的稀疏随机投影矩阵隐式路由专家，这消除了传统密集可训练版本的需要，同时利用随机矩阵的正交性固有地缓解任务间干扰。FlyLoRA在四个领域（一般知识理解、科学问题回答、数学推理和代码生成）中表现出一致的性能提升。
### Conclusion
广泛的实验表明，FlyLoRA在多项任务中的一致性能改进。FlyLoRA展示了生物结构如何启发AI技术的创新，并强调了如何通过生物学结构设计增强AI系统性能。
## 274. `cs.AI` - 语言模型规格的压力测试揭示了模型特征差异 [PDF](https://arxiv.org/pdf/2510.07686), [HTML](https://arxiv.org/abs/2510.07686)
### Authors
Jifan Zhang,Henry Sleight,Andi Peng,John Schulman,Esin Durmus
### Background
大型语言模型（LLMs）越来越多地基于AI宪法和模型规范进行训练，这些规范设定了行为准则和伦理原则。然而，这些规范面临内部原则冲突和对细微场景覆盖不足的挑战。
### Innovation
我们提出了一种系统的方法来压力测试模型特征规格，自动识别当前模型规范中的原则矛盾和解释模糊性，并生成价值权衡场景来揭示这些分歧。我们使用全面的分类体系生成各种价值权衡场景，以测试模型必须在无法同时满足原则的正当原则之间进行权衡。我们评估了十二个先进技术提供者的前沿LLM对这些场景的响应，并通过价值分类得分衡量行为分歧。
### Conclusion
在这些场景中，我们发现了超过70,000个表现出显著行为分歧的情况。实验证明这种高度的行为分歧强烈预测了模型规范中的潜在问题。我们通过定性分析提供了各种模型规格中的问题实例，例如直接矛盾和若干原则解释模糊性。我们生成的数据集还揭示了所有研究前沿模型中的清晰不一致案例和误判情况。最后，我们还提供了这些模型的价值优先级模式和差异。
## 275. `cs.AI` - 公平的隐私保护：针对差分隐私机器学习中组隐私风险差异的衡量与缓解 [PDF](https://arxiv.org/pdf/2510.09114), [HTML](https://arxiv.org/abs/2510.09114)
### Authors
Zhi Yang,Changwu Huang,Ke Tang,Xin Yao
### Background
虽然在传统公平性感知机器学习和差分隐私机器学习方面已经取得了显著进展，但不同群体的隐私保护公平性仍缺乏探索。现有研究提出了评估群体隐私风险的方法，但这些方法主要基于数据记录的平均隐私风险。这样的方法可能低估了群体的隐私风险，从而可能低估不同群体隐私风险之间的差异。此外，当前评估数据记录最坏情况隐私风险的方法耗时较长，限制了它们的实用性。
### Innovation
本文提出了一种新的成员推理游戏，可以高效地审计数据记录的近似最坏情况隐私风险。实验结果表明，本方法提供了对群体隐私风险更严格的衡量，能够可靠地评估群体隐私风险差异。为了在差分隐私机器学习中促进隐私保护公平性，本文还通过引入针对不同群体的自适应梯度剪裁策略，增强了标准的DP-SGD算法。广泛的实验验证了该算法在降低群体隐私风险差异方面具有有效性。
### Conclusion
我们的方法不仅能够更严格地衡量群体隐私风险，提供了对群体隐私风险差异的可靠评估，而且还可以通过改进现有算法来有效减少群体隐私风险的差异，从而增强差分隐私机器学习中隐私保护的公平性。
## 276. `cs.AI` - 关系变换器：走向关系数据的零样本基础模型 [PDF](https://arxiv.org/pdf/2510.06377), [HTML](https://arxiv.org/abs/2510.06377)
### Authors
Rishabh Ranjan,Valter Hudovernik,Mark Znidar,Charilaos Kanatsoulis,Roshan Upendra,Mahmoud Mohammadi,Joe Meyer,Tom Palczewski,Carlos Guestrin,Jure Leskovec
### Background
预训练变换器在零样本提示下容易适应新的序列建模任务，但关系领域的架构仍然缺乏能够跨数据集和任务迁移的设计。核心挑战在于关系数据的多样性，包括变化的异构模式、图形结构和函数依赖。
### Innovation
本文提出了关系变换器（RT）架构，能够在多样化的关系数据库中进行预训练，并且无需针对特定任务或数据集进行微调或上下文示例检索，就能直接应用于未见过的数据集和任务。RT具有以下特点：（i）基于表格/列元数据对单元格进行标记化，（ii）通过掩码标记预测进行预训练，（iii）利用一种新的关系注意机制，用于对列、行和主/外键链接。在涵盖诸如客户流失和销售预测等任务的RelBench数据集上进行预训练后，RT在二分类任务上实现了强大的零样本性能，单次前向传递2200万参数模型的平均AUCROC达到93%，相比之下，270亿参数的语言模型达到84%。微调后可获得目前最佳的结果，且具有高效的样本效率。实验表明，RT的零样本迁移利用了任务-表格上下文、关系注意模式和模式语义。
### Conclusion
RT为关系数据提供了一条实用的道路，使其能够作为基础模型使用。
## 277. `cs.AI` - 全基因组多组学整合揭示人类衰老的异质表型 [PDF](https://arxiv.org/pdf/2510.12384), [HTML](https://arxiv.org/abs/2510.12384)
### Authors
Huifa Li,Feilong Tang,Haochen Xue,Yulong Li,Xinlin Zhuang,Bin Zhang,Eran Segal,Imran Razzak
### Background
衰老是一个高度复杂且具有异质性的过程，每个人的衰老速率不同，使得生物学年龄比按年龄计时更能准确反映生理衰退。尽管过去的研究利用单组学数据构建了衰老时钟，但往往未能捕捉到人类衰老的全部分子复杂性。
### Innovation
通过利用大规模队列（10,000名40-70岁成人），该研究整合了临床、行为、环境和多组学（转录组学、脂质组学、代谢组学和微生物组）数据，开发并严格验证了一个多组学衰老时钟，该时钟能够预测多种健康结果和未来的疾病风险。此外，无监督聚类揭示了衰老的不同生物亚型，显示出衰老轨迹的显著异质性，并识别了与不同衰老模式相关的特定信号通路改变。
### Conclusion
多组学整合的力量在于能够破译衰老的分子景观，为个性化健康监测和预防与衰老相关的疾病的设计提供了基础。
## 278. `cs.AI` - 在协同多智能体强化学习中稳健性和恢复力的实证研究 [PDF](https://arxiv.org/pdf/2510.11824), [HTML](https://arxiv.org/abs/2510.11824)
### Authors
Simin Li,Zihao Mao,Hanxiao Li,Zonglei Jing,Zhuohang bian,Jun Guo,Li Wang,Zhuoran Han,Ruixiao Xu,Xin Yu,Chengdong Ma,Yuqing Ma,Bo An,Yaodong Yang,Weifeng Lv,Xianglong Liu
### Background
在协同多智能体强化学习（Cooperative Multi-Agent Reinforcement Learning, C-MARL）中，人们常通过在理想仿真环境中调整超参数来最大化合作性能。然而，这些合作策略在面对现实世界的不确定性时往往缺乏稳定性和恢复力。为了构建可信的MARL系统，全面理解稳健性和恢复力是关键，这一概念在控制理论中已有广泛研究但在C-MARL领域却很少被关注。本文通过大规模实验评估了超过82,620次实验以及4个真实世界环境下的合作、稳健性和恢复力表现，覆盖了13种不确定性类型和15个超参数。
### Innovation
本文进行了大量实验，通过综合评估合作、稳健性和恢复力来研究C-MARL系统。研究的关键发现包括：(1) 在轻微不确定性下，优化合作能够提升稳健性和恢复力，但随着扰动加剧，它们之间的联系会削弱，同时稳健性和恢复力也受算法和不确定性类型的影响；(2) 稳健性和恢复力并不跨不确定性类型或代理范围泛化；(3) 仅通过调整超参数即可在所有MARL框架中显著提升合作、稳健性和恢复力，同时该现象也推广至这些框架上的鲁棒性MARL方法，标准技术和技巧有时会损害系统的效果。
### Conclusion
要构建可信的MARL系统，需要专门关注稳健性和恢复力的评估，并通过精细化调整超参数来提升系统性能。即使在单一问题上表现出色的算法和假设也不一定在其他环境中同样有效。
## 279. `cs.AI` - HoMer:通过建模顺序和集合理上下文解决异质性进行点击率预测 [PDF](https://arxiv.org/pdf/2510.11100), [HTML](https://arxiv.org/abs/2510.11100)
### Authors
Shuwei Chen,Jiajun Cui,Zhengqi Xu,Fan Zhang,Jiangke Fan,Teng Zhang,Xingxing Wang
### Background
点击率（CTR）预测是工业推荐系统的基础，它通过模型行为序列和非序列特征（例如用户/项配置文件或交叉特征），以推断用户兴趣。然而，大多数方法面临三种形式的异质性，这些异质性会降低预测性能：(i) 特征异质性：当有限的序列侧特征提供比广泛非序列特征更不精细的兴趣表示时，会阻碍序列建模性能；(ii) 上下文异质性：由于用户对项目的兴趣会受到其他项目的影响力，但是点预测忽视了整个项目集的交叉项目交互上下文；(iii) 架构异质性：特化的网络模块碎片化集成导致模型在工业部署中的效果、效率和可扩展性削弱。
### Innovation
我们提出了HoMer，一种旨在解决顺序和集合理上下文异质性的同质化导向Transformer模型。首先，HoMer对齐序列侧特征与非序列特征，以实现精确的序列建模和细粒度的兴趣表示。其次，HoMer从点预测转为集预测，以并行方式促进项目间的交互。最后，HoMer通过结构简化和共享计算实现统一的编码-解码架构，确保高效计算的同时保持模型规模下的可扩展性。通过初步的工程优化，HoMer节省了27%的GPU资源，并在AUC指标上优于工业基线0.0099，并在线上业务指标（如CTR/RPM）上增强了1.99%/2.46%。
### Conclusion
HoMer在AUC指标上比工业基线提高了0.0099，对于CTR/RPM的在线业务指标分别提高了1.99%和2.46%，同时通过初步的工程优化节省了27%的GPU资源，证明了其优越性和实用性。
## 280. `cs.AI` - TriQuest:由AI副驾赋能的跨学科课程设计平台 [PDF](https://arxiv.org/pdf/2510.03369), [HTML](https://arxiv.org/abs/2510.03369)
### Authors
Huazhen Wang,Huimin Yang,Hainbin Lin,Yan Dong,Lili Chen,Liangliang Xia,Wenwen Xu
### Background
跨学科教学是现代课程改革的基础，但在实施过程中受到知识整合和耗时的教学计划规划的阻碍。现有工具常常缺乏必要的教学和领域专业知识支持。
### Innovation
本文介绍了一个名为TriQuest的人工智能副驾平台，利用大型语言模型和知识图谱通过直观的图形用户界面帮助教师高效生成高质量的跨学科教学计划。TriQuest的核心功能包括跨学科知识的智能化整合和人机协作审核过程，以确保教学质量和降低设计门槛和认知负担。
### Conclusion
我们的研究展示了将智能技术应用于赋能教师专业发展的新范式。TriQuest的引入显著提高了课程设计效率和教学计划质量，降低了设计障碍和认知负担。
## 281. `cs.AI` - 面向胎儿超声解释的知识感知视觉-语言基础模型 [PDF](https://arxiv.org/pdf/2510.12953), [HTML](https://arxiv.org/abs/2510.12953)
### Authors
Xiao He,Huangxuan Zhao,Guojia Wan,Wei Zhou,Yanxing Liu,Juhua Liu,Yongchao Xu,Yong Luo,Dacheng Tao,Bo Du
### Background
近期的医学视觉-语言模型在诸如视觉问答（VQA）、报告生成和异常检测等任务上显示出了潜力。然而，大多数模型适应于结构化的成人医学成像，并在胎儿超声成像上表现不佳，这给多视角图像推理、众多疾病和影像多样性带来了挑战。
### Innovation
该项目提出了一种面向胎儿超声的医疗AI系统FetalMind，用于报告生成和诊断。为了解决多变量图像推理和不同疾病之间的异质性，该系统采用了知识感知的观察能力分离（Epistemic Disentanglement，简称SED）设计，该设计通过强化学习引导专家编撰的主题图将视图-疾病关联进行分离，并引导临床忠实步骤的选择。此外，还构建了FetalSigma-1M数据库，该数据库是首个大规模胎儿超声报告语料库，包含来自12个医疗中心的20000多份报告，解决了一个领域的数据稀缺问题。
### Conclusion
实验结果显示，FetalMind在各个妊娠阶段均优于开源和专有基准模型，在关键条件下准确率提高了61.2%，保持高效、稳定和可扩展。
## 282. `cs.AI` - VaultGemma: 一种差分隐私保护的Gemma模型 [PDF](https://arxiv.org/pdf/2510.15001), [HTML](https://arxiv.org/abs/2510.15001)
### Authors
Amer Sinha,Thomas Mesnard,Ryan McKenna,Daogao Liu,Christopher A. Choquette-Choo,Yangsibo Huang,Da Yu,George Kaissis,Zachary Charles,Ruibo Liu,Lynn Chua,Pritish Kamath,Pasin Manurangsi,Steve He,Chiyuan Zhang,Badih Ghazi,Borja De Balle Pigem,Prem Eruvbetine,Tris Warkentin,Armand Joulin,Ravi Kumar
### Background
在隐私保护的大语言模型领域，差分隐私是一项重要技术，能够保护用户隐私的同时保证模型的效果。Gemma是最新的系列之一，专注于差分隐私下的模型训练和优化。VaultGemma 1B作为Gemma家族的一部分，在模型规模和隐私保护方面进行了重大改进，基于相同的训练数据集，提供更强的隐私保护能力。
### Innovation
VaultGemma 1B是Gemma家族中的一个1亿参数模型，完全使用差分隐私进行训练。与之前的Gemma系列相比，它代表了在隐私保护的大语言模型方面的重要进展。该模型基于与Gemma 2系列相同的预训练数据集，但在隐私保护和模型性能之间达到了更好的平衡。此外，该模型对外公开发布，促进了学术界和工业界的进一步研究和应用。
### Conclusion
VaultGemma 1B是首个完全使用差分隐私训练的大型语言模型，提供更强的隐私保护能力。该模型的提出和公开发布将为隐私保护领域的技术发展带来积极影响。
## 283. `cs.AI` - 贝叶斯定律或海森堡不确定性原理：谁统治？ [PDF](https://arxiv.org/pdf/2510.13894), [HTML](https://arxiv.org/abs/2510.13894)
### Authors
Volker Tresp,Hang Li,Federico Harjes,Yunpu Ma
### Background
尽管量子系统通常用量子态矢量描述，然而研究显示某些情况下其测量过程可以重新表述为基于概率状态矢量的概率方程。这些概率表示可以进一步通过张量大脑（TB）模型的神经网络动力学近似表示。张量大脑是一种新兴的框架，用于模拟大脑中的感知与记忆，提供了一种生物学启发式的机制，用于高效地将生成的符号表示集成到推理过程中。
### Innovation
提出了一种新的方法，将量子测量过程转化为基于概率状态矢量的方程，并能用张量大脑模型的神经网络动力学近似表达。这种表示方式提供了一种新的生物学启发式机制，用于将符号表示集成到推理过程中。
### Conclusion
通过将量子测量表示为概率方程，并用张量大脑模型进行近似，研究提供了一种新的生物启发式的方式，能够有效地将符号表示集成为推理过程。
## 284. `cs.AI` - 迈向鲁棒的零样本强化学习 [PDF](https://arxiv.org/pdf/2510.15382), [HTML](https://arxiv.org/abs/2510.15382)
### Authors
Kexin Zheng,Lauriane Teyssier,Yinan Zheng,Yu Luo,Xianyuan Zhan
### Background
零样本强化学习（RL）的近期发展为学习通用的预训练策略提供了新的途径，这些策略能够以零样本的方式适应任意的新任务。虽然前向-后向表示（FB）及其相关方法在零样本RL中显示出潜力，但实验发现它们的建模表达力不足，且离分布（OOD）动作导致的表示偏差，这导致学习过程出现错误，最终导致表现不佳。
### Innovation
提出了增强表达性的行为正则化零样本RL（BREEZE），这是一种升级的基于FB的框架，同时增强了学习稳定性、策略提取能力和表示学习质量。BREEZE在零样本RL策略学习中引入了行为正则化，将策略优化转化为稳定的样本内学习范式。此外，BREEZE使用条件扩散模型提取策略，使在零样本RL设置中生成高质量和多模态动作分布成为可能。BREEZE还使用具有表达性的注意力架构来捕捉环境动力学之间的复杂关系。
### Conclusion
BREEZE在ExORL和D4RL Kitchen上的广泛实验中表现出最佳或接近最佳性能，并且具有比之前的离线零样本RL方法更强的鲁棒性，公开实现可在这个网址找到。
## 285. `cs.AI` - 在增强对抗鲁棒性方面对对称性和鲁棒性之间联系的桥梁：对等变性在提高对抗鲁棒性中的作用 [PDF](https://arxiv.org/pdf/2510.16171), [HTML](https://arxiv.org/abs/2510.16171)
### Authors
Longwei Wang,Ifrat Ikhtear Uddin,KC Santosh,Chaowei Zhang,Xiao Qin,Yang Zhou
### Background
对抗样本揭示了深度神经网络在细微输入扰动下的关键漏洞。虽然对抗训练是占主导地位的防御策略，但常常会带来大量的计算成本并可能损害干净数据的准确性。
### Innovation
本文研究了一种架构性的对抗鲁棒性方法，通过将旋转和平移等变卷积层嵌入到标准卷积神经网络中。提出并评估了两种对称性意识架构：并行处理标准特征和对称特征的平行设计和先处理对称操作后进行融合的级联设计。理论分析表明，这类模型可以减少假设空间的复杂性，正则化梯度并在CLEVER框架下获得更严格的鲁棒性边界。
### Conclusion
实验结果表明，我们的模型在CIFAR-10，CIFAR-100和CIFAR-10C上在FGSM和PGD攻击下的对抗鲁棒性和泛化能力都得到了提升，而无需进行对抗训练。这些发现强调了对称性强制架构作为数据扩充基础上防御的高效和原则替代方法的潜力。
## 286. `cs.AI` - 特征选择和正则化在多类分类中的实证研究：基于梯度下降优化和L1稀疏约束的一对多逻辑回归 [PDF](https://arxiv.org/pdf/2510.14449), [HTML](https://arxiv.org/abs/2510.14449)
### Authors
Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel
### Background
多类别葡萄酒分类存在模型准确性、特征维度和可解释性之间的基本权衡。这些因素对于分析化学中的生产部署至关重要。 authors 使用UCI葡萄酒数据集进行了全面研究，探讨了手工实现梯度下降法和使用scikit-learn优化解决器之间的对比，以及L1正则化对特征稀疏性的影响。
### Innovation
authors 对一对多逻辑回归模型进行了实证研究，包括：(1) 比较从头开始实现的梯度下降法与scikit-learn优化解决器；(2) 研究L1正则化对特征稀疏性的影响；(3) 提出一个最优的5特征子集，使其在减少复杂性的同时保持高准确性。
### Conclusion
通过从头开始实现的梯度下降法，研究实现了92.59%的平均测试精度，而使用scikit-learn提供的优化解决器则提高了训练速度（24倍），并且达到98.15%的准确性。L1正则化显著减少了特征数量（减少54-69%，略降低了4.63%的精度），同时保持了可解释性和性能的良好平衡。研究还提出了一个最优5特征子集，实现了约62%的复杂性减少，节省了每样本80美元的开销和56%的时间，并且具有亚毫秒级的预测延迟，适合实时质量控制。这些发现为资源受限环境下平衡全面化学分析和定位特征测量提供了实用指南。
## 287. `cs.AI` - MARIS：海洋开放词汇实例分割与几何增强和语义对齐 [PDF](https://arxiv.org/pdf/2510.15398), [HTML](https://arxiv.org/abs/2510.15398)
### Authors
Bingyu Li,Feiyu Wang,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li
### Background
现有的大多数水下实例分割方法受近义词预测的限制，限制了它们识别新的海洋类别的能力。已有的开放词汇（Open-Vocabulary，OV）分割在自然图像上显示出潜力，但迁移到水下场景时，由于严重的视觉退化（例如颜色衰减）和由于缺乏水下类定义导致的语义对齐问题，表现较差。因此，亟需引入新的方法和基准来解决这些挑战。为此，论文提出了MARIS基准，用于评估水下开放词汇实例分割，旨在提升模型在水下场景中的识别能力。
### Innovation
提出了MARIS，首个大规模细粒度的水下开放词汇注释基准，包括被看到的类别和未见的类别。提出了一个统一框架，包含两个互补组件：几何先验增强模块（GPEM）和语义对齐注入机制（SAIM）。GPEM利用稳定的部分级和结构线索，在退化的视觉条件下保持物体一致性。SAIM通过加入领域特定先验丰富语言嵌入，降低语义不确定性，提高未见类别的识别率。实验表明，该框架在MARIS基准上的表现优于现有模型，无论是在领域内还是跨领域设置。
### Conclusion
MARIS基准和提出的统一框架（包含GPEM和SAIM）为未来的水下感知研究奠定了坚实的基础。通过实验证明，该方法在MARIS基准上无论是在领域内还是跨领域设置均表现出更优的性能。未来的工作有望进一步改进该框架，提升水下场景下的识别精度和效果。
## 288. `cs.AI` - HumanCM：一步人类动作预测 [PDF](https://arxiv.org/pdf/2510.16709), [HTML](https://arxiv.org/abs/2510.16709)
### Authors
Liu Haojie,Gao Suixiang
### Background
现有的动作预测方法通常依赖于多步去噪，这在计算上消耗较大。为了提高效率，作者提出了一种基于一致性模型的一次性人类动作预测框架HumanCM。HumanCM通过学习噪声动作状态与干净动作状态之间的自一致性映射，实现了高效的一次性动作生成。此外，该方法采用了基于Transformer的空间-时间架构，并且通过引入时间嵌入来建模长时间依赖关系并保持动作连贯性，以此来提高动作预测的准确性。实验结果显示，该方法在Human3.6M和HumanEva-I数据集上的表现与最先进的扩散模型相当，但计算时间减少了一个数量级甚至更多。
### Innovation
HumanCM框架通过学习噪声动作状态与干净动作状态之间的自一致性映射实现了高效的一次性动作生成，并采用基于Transformer的空间-时间架构来建模长时间依赖关系并保持动作连贯性，进而提高了动作预测的效率和准确性。相较于传统的多步骤去噪方法，HumanCM将推理步骤减少了两个数量级，展现出显著的计算效率提升。
### Conclusion
HumanCM方法在Human3.6M和HumanEva-I数据集上达到了与最新扩散模型相当的预测精度，但其计算效率显著提高，表明该方法在实际应用中具有较高的实用价值。
## 289. `cs.AI` - SPLite手部：基于稀疏性的轻量级3D手部姿态估计 [PDF](https://arxiv.org/pdf/2510.16396), [HTML](https://arxiv.org/abs/2510.16396)
### Authors
Yeh Keng Hao,Hsu Tzu Wei,Sun Min
### Background
随着AR/VR设备的广泛应用，将深度学习模型部署到边缘设备上已成为了关键挑战。这些设备需要实时推理、低功耗和低延迟。许多框架设计师在平衡效率和性能之间面临困境。因此，设计一个轻量级框架变得尤为重要，该框架采用编码器-解码器架构，并引入了改进效率和准确性的几个关键贡献。
### Innovation
本文创新地应用稀疏卷积于ResNet-18基础模型上，以利用手部姿态图像中的固有稀疏性，实现了端到端42%的效率改进。此外，提出了一种新的SPLite解码器，该解码器在Raspberry Pi 5上将解码帧率提升了3.1倍，同时保持了相当的精度。此外，通过量化感知训练进一步优化了性能，减少了内存使用量，同时保持了准确性（PA-MPJPE仅微增至9.1毫米），整体系统在Raspberry Pi 5 CPU（BCM2712四核Arm A76处理器）上实现了2.98倍的速度提升。该方法还在复合基准数据集上进行评估，展示了与最先进的方法相当的精度，同时显著提高了计算效率。
### Conclusion
我们的系统在保持高精度的同时大幅提高了计算效率，特别是在边缘设备上实现了显著的性能提升。SPLite手部姿态估计框架为处理手部姿态估计问题提供了一种有效的解决方案。
## 290. `cs.AI` - GUIDE: 使用去噪模型增强联邦学习中的梯度反转攻击 [PDF](https://arxiv.org/pdf/2510.17621), [HTML](https://arxiv.org/abs/2510.17621)
### Authors
Vincenzo Carletti,Pasquale Foggia,Carlo Mazzocca,Giuseppe Parrella,Mario Vento
### Background
联邦学习（FL）使多个客户端能够在不共享原始数据的情况下协作训练机器学习模型，从而保护隐私。然而，基于梯度反转攻击（GIAs）的对手可以利用客户端更新来反向重建训练数据，甚至通过技术手段重构原始输入，这威胁到了联邦学习中的隐私保护。
### Innovation
提出了GUIDE（Gradient Update Inversion with Denoising），一种利用扩散模型（diffusion models）作为去噪工具，以提高图像重建攻击质量的新方法。GUIDE能够与GIAs中的任何使用代理数据集的攻击场景无缝集成，大幅提高重建质量。
### Conclusion
就GIAs而言，GUIDE在多个指标上显著提高了重建质量。具体而言，GUIDE在DreamSim度量标准下的感知相似性提高了高达46%。
## 291. `cs.AI` - TabR1: 通过GRPO驯化表格推理大语言模型 [PDF](https://arxiv.org/pdf/2510.17385), [HTML](https://arxiv.org/abs/2510.17385)
### Authors
Pengxiang Cai,Zihao Gao,Jintai Chen
### Background
传统的表格预测依靠梯度提升决策树和专业化的深度学习模型，虽然在特定任务上表现出色，但在可解释性和跨表格任务的迁移性方面表现不佳。理论上的大语言模型(Large Language Models, LLMs)可以实现跨任务的适应性，并透明地提供推理路径，但其潜力尚未在表格数据上得到充分利用。因此，本文提出了TabR1，这是一种针对表格预测的多步推理大语言模型。
### Innovation
TabR1的核心是Permutation Relative Policy Optimization (PRPO)，一种简单高效的强化学习方法，将列排列不变性作为结构先验。通过为每个样本构建多个标签保持排列，并在排列内外估计优势，PRPO将稀疏奖励转化为密集学习信号，从而改善泛化能力。在有限的监督下，PRPO激活了LLMs的推理能力，提升了少样本和零样本性能及可解释性。全面的实验表明，TabR1在全监督调优下达到与强大基线相当的表现。在零样本设置下，TabR1接近32样本设置下强基线的表现。此外，TabR1在各个任务中显著优于更大的LLMs，提高了高达53.17%。
### Conclusion
TabR1因其多步推理能力而表现出色，能够有效应对表格预测任务。尤其是对大规模LLMs相比，TabR1在多个任务上展现出显著的优势，提升了模型的性能和可解释性。
## 292. `cs.AI` - 通过第一层值头的跳连接改进模型表示并减少KV缓存 [PDF](https://arxiv.org/pdf/2510.16807), [HTML](https://arxiv.org/abs/2510.16807)
### Authors
Zhoutong Wu,Yuan Zhang,Yiming Dong,Chenheng Zhang,Cong Fang,Kun Yuan,Zhouchen Lin
### Background
Transformer模型在各种语言任务中取得了突破，得益于它们强大的学习丰富上下文表示的能力。然而，扩大它们以提升表示通常需要大量的内存和计算成本，例如自回归解码过程中使用的Key-Value（KV）缓存。尽管跳跃连接提供了一种不增加资源使用情况提高表示的方法，但大多数先前的研究要么改进了表达能力而未改变KV成本，要么通过削弱表示减少了内存。
### Innovation
本文提出了一种名为SkipV1Former的Transformer变体，它利用第一层值头的跳跃连接来加强模型表示并减少KV缓存。从第二个块开始，每一层都会重用一半来自第一层的值头，而另一半则按常规计算，从而将值投影和V缓存减半。理论证明，这种跳跃连接机制能够通过恢复压缩信息加速模型的隐形新优化，这对自回归任务中的Transformer至关重要。通过这种方法，SkipV1Former能够在不同规模的模型中在保持或者提升困惑度的同时减少约25%的KV缓存，并且只需要10-15%额外的计算量就可将现有的MHA Transformer模型升级为SkipV1Former。此外，它还可以无缝结合如组查询注意力和多潜空间注意力等高级方法进一步节省KV缓存并提升性能，甚至与YOCO结合使用时，KV缓存大小可以减少近50%。
### Conclusion
SkipV1Former在保持或提高困惑度的同时，通过减少约25%的KV缓存，为Transformer的自回归任务提供了一种有效的资源配置方法。此外，提出了一种只需额外10-15%计算量的方法来升级现有MHA Transformer模型，并展示了其能够与多组查询注意力等先进方法结合使用，以进一步节省KV缓存并提升性能。
## 293. `cs.AI` - 计算VC-维度的参数化复杂性 [PDF](https://arxiv.org/pdf/2510.17451), [HTML](https://arxiv.org/abs/2510.17451)
### Authors
Florent Foucaud,Harmender Gahlawat,Fionn Mc Inerney,Prafullkumar Tale
### Background
VC维是衡量集合系统（或超图）复杂度的一个广泛研究且基础性指标，对机器学习等多个领域至关重要。已有研究证明了计算VC维的方法，但关于如何在多项式时间内高效地计算这一复杂性指标仍然缺乏深入认识。
### Innovation
1. 证明了基于经验时间假设（ETH）条件下，朴素的 $2^{rm{O}(|rm{V}|)}$ 时间算法是计算VC维的最佳极限。2. 发现并提出了当参数化于超图的最大度数和维数时，该问题分别可获得1-增量固定参数近似算法和固定参数算法。3. 描述了一个基于图的超图VC维的通用问题，并设计了一种适用于图的树宽的 $2^{rm{O}(rm{tw} times rm{log} rm{tw})} times |V|$ 时间算法，这与同类问题相比，只需要线性依赖于树宽，从而显著提升了算法效率。
### Conclusion
论文研究了计算VC维的复杂性，并提出了针对最大度数和维数的固定参数算法，同时设计了一种基于树宽的高效算法，这为理解集合系统和图的VC维计算开辟了新的途径。
## 294. `cs.AI` - 基于配置的多智能体路径规划中的局部引导 [PDF](https://arxiv.org/pdf/2510.19072), [HTML](https://arxiv.org/abs/2510.19072)
### Authors
Tomoki Arita,Keisuke Okumura
### Background
指导是多智能体路径规划（MAPF）方法的一个新兴概念，它通过提供有关全局拥堵状况的额外信息来改善实际应用中实时、非最优算法的效果。传统的全局视角有助于减少智能体的等待时间，从而提高整体协调效率。但本研究提出了另一种方法——在每个智能体附近的局部区域提供引导，尽管这种局部方法在智能体移动时需要重新计算，看似计算成本较高，但实验证明，通过提供时空提示来改善计划器的解决方案质量是可行的，且不会超出预算时间.
### Innovation
本研究探索了一种新的方法，即在每个智能体附近的局部区域提供引导信息，而不是传统的全局指导方法。虽然这种方法在智能体移动时需要重新计算，看似计算成本较高，但实验结果表明，在不超出预算时间的情况下，这种方法可以显著提高解决方案的质量，具有计算效率和解决方案质量的双重优势.
### Conclusion
将这种局部引导应用于LaCAM（一种领先的基于配置的求解器），这种形式的指导为MAPF设定了新的性能边界。
## 295. `cs.AI` - NER模型扩展中表示动态的诊断 [PDF](https://arxiv.org/pdf/2510.17930), [HTML](https://arxiv.org/abs/2510.17930)
### Authors
Xirui Zhang,Philippe de La Chevasnerie,Benoit Fabre(papernest)
### Background
在嘈杂的口述语言数据中扩展命名实体识别（NER）模型来识别新的个人信息（PII）实体如电子邮件和电话号码是一项常见需求。研究发现，同时在标准语义实体（PER、LOC、ORG）和新模式基础PII（EMAIL、PHONE）上对BERT模型进行联合微调，对原有类别的性能影响很小。这项工作使用逐步学习设置作为诊断工具，测量语义漂移并发现了两个关键见解。
### Innovation
这项工作揭示了语义独立性、表示重叠和‘O’标签的可塑性。通过测量语义漂移，确定了位于（地点）实体的独特脆弱性，因为它与新PII共享模式特征（例如邮政编码）。还发现了“反向O标签表示漂移”现象。模型最初被训练将PII模式映射到'O'，阻止新学习。通过解冻'O'标签分类器，允许背景类别适应并“释放”这些模式来解决这一问题。这项工作提供了一种NER模型适应的机制性诊断方法，强调了特征独立性、表示重叠和‘O’标签的可塑性。
### Conclusion
该工作提供了一种机械诊断NER模型扩展的方法，强调特征独立性、表示重叠和‘O’标签的可塑性，并使用逐步学习设置作为诊断工具，发现并解决了两种关键的语义漂移。
## 296. `cs.AI` - 每个注意力机制都重要：高效混合架构用于长上下文推理 [PDF](https://arxiv.org/pdf/2510.19338), [HTML](https://arxiv.org/abs/2510.19338)
### Authors
Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou
### Background
长上下文的推理场景中，传统的注意力机制和计算成本较高，特别是在大规模模型的推理过程中，成本更是显著增加。因此，如何在保持模型性能的同时降低计算和IO成本成为了一个重要的研究方向。此前的Ring系列模型已经在这方面取得了一定的成果，但仍有进一步优化的空间。
### Innovation
1. 提出了一种混合架构，有效地结合了线性注意力和softmax注意力，显著降低了长上下文推理场景中的I/O和计算开销。2. 相比于32B参数的密集模型，该系列模型将推理成本降低了10倍。3. 相比于原始的Ring系列，成本降低了50%以上。4. 通过系统探索混合架构中不同注意力机制的比例，确定了目前最优的模型结构。5. 利用自主研发的高性能FP8算子库-玲珑，整体训练效率提高了50%。6. 通过训练和推理引擎操作的高度对齐，在强化学习阶段实现了模型的长期、稳定和高效优化，保持了在多个复杂推理基准测试中的SOTA性能。
### Conclusion
该研究提出了一种高效的混合架构模型系列，通过优化注意力机制和提高算子效率，降低了长上下文推理中的计算成本，同时保持了高性能。
## 297. `cs.AI` - 高效视觉语言行动模型在实体操控中的系统综述 [PDF](https://arxiv.org/pdf/2510.17111), [HTML](https://arxiv.org/abs/2510.17111)
### Authors
Weifan Guan,Qinghao Hu,Aosheng Li,Jian Cheng
### Background
视觉语言行动（VLA）模型通过将自然语言指令和视觉观察映射到机器人行动，将视觉语言模型扩展到了实体控制领域。尽管如此，VLA系统面临着巨大的计算和内存需求挑战，这些需求与边缘平台（如车载移动机械臂）的实时性能要求相冲突。为解决这一问题，研究者们越来越注重开发更高效、更具扩展性的VLA系统，这已成为近期研究的核心焦点。
### Innovation
本文提供了一种系统性的VLA效率提升方法的综述，重点关注减少延迟、内存占用和训练及推理成本。将现有解决方案分为四类：模型架构、感知特征、行动生成以及训练/推理策略，并总结了每个类别中的代表性技术。
### Conclusion
最后，讨论了未来的发展趋势和开放性挑战，指出了推进高效实体智能的方向。
## 298. `cs.AI` - 使用有限示范学习向人群推迟 [PDF](https://arxiv.org/pdf/2510.19351), [HTML](https://arxiv.org/abs/2510.19351)
### Authors
Nilesh Ramgolam,Gustavo Carneiro,Hsiang-Ting Chen
### Background
这篇论文处理了一个关键问题：数据稀缺性阻碍了学习推迟（L2D）系统的实际部署。现有的学习推迟系统通常需要大量的标记数据来训练模型，但实际应用场景中经常难以获得这些数据，尤其是在涉及人类专家的多元领域中。因此，论文旨在寻找一个方法，能够在仅有限示范的情况下，有效提升系统的性能和适应性，尤其在数据稀缺的环境中更显重要。
### Innovation
该研究提出了一个基于元学习的半监督框架，能够在仅少量示范的情况下生成专家特定的嵌入表示。该框架具有双重机制，首先，生成大量的伪标签用于训练；其次，在测试时，可即时适应新专家。研究成果在三个不同数据集上的实验展示了模型在这些合成标签上训练的效果，快速接近了理想的性能水平，证明了该方法的数据效率。这项工作的创新在于解决了训练瓶颈问题，使自适应L2D系统更加实用和可扩展，从而推动了人类和人工智能之间的协作在真实环境中的应用。
### Conclusion
通过该框架，论文展示了能够显著提升基于L2D模型的学习效率，并验证了该方法在真实世界应用场景中的实用性和可扩展性。这种方法解决了现有L2D系统在数据稀缺环境中的主要挑战，为未来的研究和应用奠定了基础。
## 299. `cs.AI` - 向高效多模态生成迈进的扩散模型缓存方法综述 [PDF](https://arxiv.org/pdf/2510.19755), [HTML](https://arxiv.org/abs/2510.19755)
### Authors
Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang
### Background
扩散模型已成为现代生成人工智能的核心，因为它们在生成质量和可控性上表现出色。然而，它们固有的多步迭代和复杂的底层网络导致了巨大的计算开销和生成延迟，成为实时应用的主要瓶颈。尽管已有加速技术取得了一些进展，但它们仍然面临着应用局限性、高训练成本或质量下降等挑战。
### Innovation
扩散缓存提供了一种无需训练、架构无关且高效的推理范式。其核心机制在于识别和重用扩散过程中的内在计算冗余，在不修改模型参数的情况下通过特征级别的跨步重用和层间调度来减少计算量。该论文系统地回顾了扩散缓存的理论基础和演变，并提出了一种统一框架进行分类和分析。研究表明，扩散缓存从静态重用向动态预测演进，提高了多任务适应性，并能够与采样优化和模型蒸馏等其他加速技术集成，为未来多模态和互动应用提供了一个统一的高效推理框架。
### Conclusion
该范式将有望成为实时和高效生成人工智能的关键驱动力，注入新的活力到生成智能的理论和实践中。
## 300. `cs.CL` - 使用大型语言模型对荷兰电子健康记录进行自动艾滋病毒筛查 [PDF](https://arxiv.org/pdf/2510.19879), [HTML](https://arxiv.org/abs/2510.19879)
### Authors
Lang Zhou,Amrish Jhingoer,Yinghao Luo,Klaske Vliegenthart--Jongbloed,Carlijn Jordans,Ben Werkhoven,Tom Seinen,Erik van Mulligen,Casper Rokx,Yunlei Li
### Background
高效筛查和早期诊断HIV对于减少病毒传播至关重要，但由于大规模实验室测试不可行，利用广泛采用的电子健康记录（EHRs）提供了新的机会。现有研究主要集中在使用机器学习方法对结构化数据，如患者人口统计信息进行改进诊断，但这些方法往往忽视了临床笔记等非结构化文本数据，这些数据可能包含与HIV风险相关的重要信息。
### Innovation
提出了一个新的管道，该管道利用大型语言模型分析非结构化的EHR文本，以确定患者是否需要进一步的HIV检测。实验结果表明，该管道在保持低假阴性率的同时达到了高准确率。
### Conclusion
利用大型语言模型分析荷兰埃因霍温大学医学中心临床数据证明了该管道的有效性，这为利用EHRs进行HIV筛查提供了一种新方法。
## 301. `cs.CL` - 从去噪到精炼：一种视觉语言扩散模型的校正框架 [PDF](https://arxiv.org/pdf/2510.19871), [HTML](https://arxiv.org/abs/2510.19871)
### Authors
Yatai Ji,Teng Wang,Yuying Ge,Zhiheng Liu,Sidi Yang,Ying Shan,Ping Luo
### Background
离散扩散模型在视觉语言任务中表现出巨大潜力，能够进行双向语境建模并实现理论上的并行化。然而，这些模型的实际应用受到了训练与推理之间差异的严重制约，这导致了灾难性的错误级联：并行解码过程中产生的初始token错误污染生成语境，引发一系列不断累积的错误，从而导致句法错误和语义虚幻。
### Innovation
我们重新定义了生成过程，从被动去噪转向主动精炼。引入了ReDiff框架，旨在教会模型识别和纠正自身错误。框架采用两阶段训练过程：首先，通过训练模型修订合成错误来培养基础修订能力；其次，引入一种新颖的在线自我校正环，通过学习专家修正来训练模型修订其自身错误的草稿。这种错误驱动的学习使模型能够回顾并精炼其已生成的输出，从而打破错误级联。
### Conclusion
广泛的实验表明，ReDiff显著提高了生成内容的连贯性和事实准确性，使其在并行生成的稳定性和效率方面超越了传统的去噪方法。我们的代码和模型已可通过链接访问。
## 302. `cs.CL` - 不同模型和提示框架在高中国物理课程中生成的教案的教育有效性和实用性评价 [PDF](https://arxiv.org/pdf/2510.19866), [HTML](https://arxiv.org/abs/2510.19866)
### Authors
Xincheng Liu
### Background
本文研究了五种主流大型语言模型（ChatGPT（GPT-5），Claude Sonnet 4.5，Gemini 2.5 Flash，DeepSeek V3.2，Grok 4）生成的教案的教育有效性和实用性。研究通过三种不同的提示框架（TAG，RACE，COSTAR）进行了三个层次的分析：包含任务，受众和目标；角色，受众，情境和执行；上下文，目标，风格，语气，受众和回应格式。最终，研究生成了针对《电磁谱》这一高中物理主题的15个教案，并通过四个标准化的自动化计算标准对其进行了评价：可读性和语言复杂性，事实准确性及虚构检测，标准与课程的吻合度，以及学习目标的认知需求。
### Innovation
研究同时评估了不同语言模型和提示框架对生成的教案的影响。通过三个不同的提示框架进行测试，并综合了语言模型选择，算法优化，以及明确的检查列表（包括物理概念，课程标准和高层次目标）来确定最有效的组合。结果显示，模型选择直接影响语言的可读性，而提示框架结构则对事实准确性及教学完整性的影响更大。
### Conclusion
研究发现，语言模型的设计对编写教案的可读性影响显著，而教学可靠性和课程标准的符合度更多地依赖于提示框架结构。最有效的组合是结合具有优化可读性的模型，使用RACE提示框架，并带有明确列出的物理概念、课程标准和高层次目标的清单。
## 303. `cs.CL` - DeBERTa-KC：在线学习话语中知识构建的变压器分类器 [PDF](https://arxiv.org/pdf/2510.19858), [HTML](https://arxiv.org/abs/2510.19858)
### Authors
Jindi Wang,Yidi Zhang,Zhaoxing Li
### Background
该研究旨在利用评论数据自动分类在线科学学习对话中的知识构建（KC）层级。研究者从四个知名的YouTube科学频道收集了2022年至2024年的评论，并创建了平衡的标注数据集，包括4个KC类别：nonKC、Share、Explore和Negotiate。这些类别代表了不同程度的学术对话参与度，从非知识构建到高层次的知识协商。
### Innovation
研究提出了一种基于变压器的模型DeBERTa-KC，通过对DeBERTa-v3进行增强，包括引入Focal Loss、Label Smoothing和R-Drop正则化技术，以处理类别不平衡问题并提高模型泛化能力。研究者还实现了一个可复现的端到端工作流程，涵盖数据提取、标注、预处理、训练和评估。实验结果显示DeBERTa-KC在宏F1得分为0.836±0.008，显著优于传统和变压器基线（p<0.01）。每个类别结果特别强调在高层次表征性的学术参与（Explore和Negotiate类别）中的敏感性。这些发现表明大型语言模型能够有效地捕捉非正式数字学习环境中的复杂知识构建指标，为对话分析提供可扩展的理论导向方法，并开发自动评估学术参与度的工具。
### Conclusion
研究结果表明大型语言模型能够有效捕捉非正式数字学习环境中复杂的知识构建指标，为对话分析提供可扩展的理论导向方法，并开发自动评估学术参与度的工具。DeBERTa-KC模型在在线科学学习对话的自动分类任务中表现出色，特别是在处理表征性的高层次学术参与（Explore和Negotiate）时。
## 304. `cs.CL` - 通用大语言模型在生命周期评估中的专家基准测试 [PDF](https://arxiv.org/pdf/2510.19886), [HTML](https://arxiv.org/abs/2510.19886)
### Authors
Artur Donaldson,Bharathan Balaji,Cajetan Oriekezie,Manish Kumar,Laure Patouillard
### Background
本文探讨了人工智能（特别是大型语言模型）作为生命周期评估（LCA）支持工具的应用日益增加的情况。现有证明了其在环境和社会领域的广泛性，但对其可靠性和稳健性的系统证据仍然有限。在没有明确真相或共识协议的领域，本文采用专家基准测试的方法填补了标准化评估框架的空白。
### Innovation
本文首次进行了专家基准测试，评估了11种不同的通用大语言模型在22项LCA相关的任务中的表现，这些模型覆盖了商业和开源两大类别。通过17名经验丰富的从业者对模型输出进行评审，重点关注科学准确度、解释质量、稳健性、可验证性和遵循指令的情况，揭示了不同模型的表现差异及其潜在应用价值。
### Conclusion
本文的结论强调了在LCA中未经培训使用大语言模型的风险，特别是在将其视为自由形式的预言时。同时，也展示了这些模型在解释质量方面的好处，并能减轻简单任务的劳动密集度。然而，如果没有基础机制的支持，使用通用大语言模型会存在一定的风险。
## 305. `cs.CL` - Stream: 通过稀疏注意力扩大在LLMs中的机制可解释性到长上下文 [PDF](https://arxiv.org/pdf/2510.19875), [HTML](https://arxiv.org/abs/2510.19875)
### Authors
J Rosser,José Luis Redondo García,Gustavo Penha,Konstantina Palla,Hugues Bouchard
### Background
大型语言模型（LLMs）随着上下文长度扩展到百万级标记，传统的机制可解释性技术对注意力的分析随着时间长度的增加呈四次方增长，这需要超过10万个标记的 terabytes 级内存。这使得对于十个以上标记的序列变得不可行，大大限制了这种技术在实际中的应用。为解决这一问题，该研究引入了稀疏追踪Sparse Tracing技术，该技术利用动态稀疏注意力来高效分析长上下文注意力模式。Stream是一种编译型的分层剪枝算法，可以在接近线性时间O(T log T)和线性空间O(T)的情况下估计每头稀疏注意力掩码，使得可在单次通过中进行大规模的解释性分析而不必依赖大规模缓存。Stream通过二分搜索式的细致调整来保留每个查询中最重要的k个关键块，同时保留模型的下一个标记行为。在RULER基准测试中，Stream保留了关键检索路径，同时抛弃了90-96%的交互，并揭示了从输入到输出的逐层路径。
### Innovation
该研究提出了稀疏追踪Sparse Tracing技术，这是一种新型机制可解释性技术，能够有效地分析LLMs中的长上下文注意力模式。同时，研究还提出了一种编译型的分层剪枝算法Stream，它可以在接近线性时间和线性空间中估计每头稀疏注意力掩码，实现了在单次通过中的大规模解释性分析，不需要大量的缓存。通过这种技术，原始的机制可解释性技术可以被应用到更长的上下文序列中，使得链式推理的监控成为可能，特别是在消费级GPU上也能实现。这种方法为分析注意力模式和追踪信息流提供了一个实用的插件工具，它打破了以往因为大量内存需求而无法实现的限制。
### Conclusion
本研究通过引入稀疏追踪Sparse Tracing技术和Stream算法解决了传统机制可解释性技术在LLMs中处理长上下文时所面临的巨大挑战。研究展示了如何在保持模型准确性的前提下，有效地分析和解释LLMs中的注意力模式，为在消费级硬件上进行大规模的机制可解释性分析提供了可能。
## 306. `cs.CL` - LyriCAR：一种面向词曲可控翻译的难度感知学习强化学习框架 [PDF](https://arxiv.org/pdf/2510.19967), [HTML](https://arxiv.org/abs/2510.19967)
### Authors
Le Ren,Xiangjian Zeng,Qingqiang Wu,Ruoxuan Liang
### Background
歌词翻译是一项具有挑战性的任务，需要平衡多种音乐约束。现有方法往往依赖于手工构建的规则和句子级别的建模，这限制了它们在段落级内部化音乐语言模式和有效泛化的能力，尤其是在跨行连贯性和全局押韵方面至关重要的地方。
### Innovation
本文提出了LyriCAR，一种全新的自监督框架，用于可控歌词翻译。LyriCAR引入了难度感知的学习强化设计和自适应的学习策略，确保了训练资源的有效分配，加速了收敛，并通过逐步指导模型应对越来越复杂的挑战来提高整体翻译质量。此外，自适应的学习策略在保持卓越性能的同时减少了训练步骤近40%。
### Conclusion
在EN-ZH歌词翻译任务上的广泛实验表明，LyriCAR在标准翻译指标和多维奖励得分方面均取得了最先进的结果，超越了强有力的基线。代码、数据和模型可在此处访问：[提供网址]。
## 307. `cs.CL` - 基于语义和情境记忆的监督学习：一种代理适应的反思性方法 [PDF](https://arxiv.org/pdf/2510.19897), [HTML](https://arxiv.org/abs/2510.19897)
### Authors
Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka
### Background
当前，基于预训练大型语言模型的代理通常通过微调等传统方法来学习分类函数，这种方法往往代价高昂、灵活性差且不透明。本文研究了如何利用标记数据和LLM生成的批评意见，通过记忆增强框架来学习目标分类功能，从而提升代理的适应性和透明度。
### Innovation
本文提出了一种记忆增强框架，利用语义和情境记忆来存储和提炼特定的过去经验和任务层面的指导。这种方法通过存储实例级别的批评意见和提炼这些批评意见以生成可重用的任务指导，相比于仅依赖标签的检索基线方法，在多种任务中表现出了24.8%的准确率提升。此外，通过引入一个新的度量标准‘可建议性’，该研究揭示了开源模型和OpenAI模型在处理事实导向与偏好导向数据时的不同行为，并解释了代理对不同监督表示的反应。
### Conclusion
基于记忆的学习对于构建更具适应性和可解释性的LLM代理具有巨大的潜力。通过记忆策略，代理能够更好地理解任务需求，并更有效地区分监督信息，从而优化学习动态。
## 308. `cs.CL` - Can They Dixit? Yes they Can! Dixit作为多模态语言模型能力的游乐场 [PDF](https://arxiv.org/pdf/2510.19892), [HTML](https://arxiv.org/abs/2510.19892)
### Authors
Nishant Balepur,Dang Nguyen,Dayeon Ki
### Background
多模态大型语言模型（MLMs）通常在静态、分离的基准测试上进行评估，这不能同时评估模型在单一任务中的能力，或者依赖于人类或模型的两两比较，这非常主观、昂贵，并且允许模型利用表层捷径（例如冗长）来夸大其胜率。为了克服这些问题，我们提出了一种基于游戏的评估方法，以全面评估MLMs的能力。游戏要求玩家具备多种能力才能获胜，本质上是竞争性的，并且是通过固定的客观规则来治理的，这使得评估更加引人入胜，为应对上述挑战提供了稳健的框架。
### Innovation
我们特别通过Dixit，一种幻想卡牌游戏，来实现这种评估方法。Dixit要求玩家生成卡片的描述，使得其他部分玩家误选已玩的卡片，但不是全部。我们的实验结果表明，Dixit的胜率排名与流行的MLM基准测试是完全相关的，而人类与MLM玩家之间的游戏揭示了各种不同策略以及对于MLM推理能力改进的领域。
### Conclusion
实验结果表明，Dixit能够为评估MLMs的能力提供一个全面且有效的游乐场。这是一种更为公平和富有表现力的方法，可以帮助识别和改进MLMs在复杂任务中的表现。
## 309. `cs.CL` - 大型语言模型驱动的数学建模 [PDF](https://arxiv.org/pdf/2510.19895), [HTML](https://arxiv.org/abs/2510.19895)
### Authors
Guoyun Zhang
### Background
传统的优化方法如线性规划、整数规划和模拟依赖于专业知识将现实世界的难题转化为可求解的数学模型。尽管求解器如Gurobi和COPT是强大的工具，但专家输入依然对于定义目标、约束和变量是必要的。然而，此前的模型如GPT-4、Claude和Bard尽管在NLP和推理任务中表现出色，但由于高成本和虚假信息的倾向，它们在供应链场景中的实际应用受限。相比之下，DeepSeek-R1作为一种成本效益高且性能良好的模型，在基准测试如LiveCodeBench和Math-500中表现出色，但其在实际运筹学场景中的效果尚未被充分探索。
### Innovation
研究通过使用DeepSeek-R1模型结合自然语言理解和代码生成技术，旨在解决传统优化建模中的专家依赖问题，特别是在运筹学领域。研究提出了幻觉分类学，并结合LLM作为裁判、少量示例学习、工具调用和多代理框架等一系列技巧，减少了幻觉，提高了模型表述的准确性，更好地将模型输出与用户意图对齐。
### Conclusion
本研究系统性地在四个关键运筹学基准（NL4OPT、IndustryOR、EasyLP和ComplexOR）上评估了DeepSeek-R1的表现，通过采用基准评估、幻觉分类学和幻觉缓解策略，取得了显著的进展，证明了大语言模型在数学建模中的潜力，特别是对于优化建模领域而言。
## 310. `cs.CL` - 依赖解析的基本算法（附更正） [PDF](https://arxiv.org/pdf/2510.19996), [HTML](https://arxiv.org/abs/2510.19996)
### Authors
Michael A. Covington
### Background
该论文提出了一个用于解析自然语言句子为依赖树的基础算法。这种算法与基于短语结构（成分）的解析器不同，它在一个词接一个词的基础上进行操作，一旦可以附加就立即附加每个词，这与人类大脑中声称的解析器特性相吻合。虽然依赖解析的最坏情况复杂度为$O(n^3)$，与短语结构解析相同，但在人类语言的实际应用中，最坏情况仅在$n$较小的情况下出现。
### Innovation
该算法的主要创新点在于它以一种人类大脑解析器可能具备的特性为基础，一个词接一个词地进行依赖树构建，而不需要等待整个句子结构确定。这种方法在实际的人类语言使用中表现出更好的性能。
### Conclusion
尽管依赖解析的最坏复杂度与短语结构解析相同，但在处理人类语言时，这种算法呈现出了更好的实时性，减少了不必要的复杂运算，在实际应用中表现更加高效。
## 311. `cs.CL` - LLM-Augmented Symbolic NLU System for More Reliable Continuous Causal Statement Interpretation [PDF](https://arxiv.org/pdf/2510.19988), [HTML](https://arxiv.org/abs/2510.19988)
### Authors
Xin Lian,Kenneth D. Forbus
### Background
尽管大型语言模型（LLMs）具有广泛的应用前景，但它们依赖于概率推理，这使得它们在生成事实时可能产生幻觉错误，在自然语言理解（NLU）任务中可能产生输出结构不一致的问题。相比之下，符号型NLU系统提供基于精心整理的词汇表、语义资源和句法与语义解释规则的可解释理解。这些系统能够生成关系表示，可应用于准确推理和计划，并且支持增量可调试的学习。然而，符号型NLU系统在覆盖面方面比LLMs更有限，需要专业知识表示和语言学技能进行扩展和维护。
### Innovation
本文探讨了一种将LLMs广泛的语言处理能力与符号型NLU生成结构化关系表示的能力相结合的混合方法。通过使用LLMs进行重述和文本简化以提供广泛的覆盖面，并将它们作为信息来源自动填补知识空白。利用符号型NLU生成可用于推理和增量学习的表示。本文利用此方法评估了从常识科学文本中提取和解释数量及因果律的任务，并将其与仅基于符号型和仅基于LLMs的管道进行了比较。结果表明，本文的混合方法明显优于仅基于符号型的方法。
### Conclusion
本文提出了一种增强的符号型NLU系统，该系统结合了LLMs的广泛覆盖能力和符号型NLU的结构化关系表示生成能力。通过这种方法，提高了连续因果陈述的解释可靠性，并通过实验验证了这种方法的有效性。
## 312. `cs.CL` - 超越MedQA：大型语言模型在LLM时代走向真实的临床决策 [PDF](https://arxiv.org/pdf/2510.20001), [HTML](https://arxiv.org/abs/2510.20001)
### Authors
Yunpeng Xiao,Carl Yang,Mark Mai,Xiao Hu,Kai Shu
### Background
大型语言模型（LLMs）在临床应用中显示出潜力，但常使用MedQA等简化问题回答的数据集进行评估。然而，许多医疗数据集，如MedQA，依赖于简化的问答形式，未能充分反映实际的临床决策过程。文章回顾了现有数据集和基准，从两个维度总结了设置，并讨论了用于解决临床决策问题的方法和技术，提出超越MedQA的新范式，以更接近真实的临床环境进行评估，从而更全面地衡量模型性能，包括准确性和效率，以及提高解释性，并指出现有挑战，为开发具有临床意义的LLMs指明方向。
### Innovation
文章提出了一种新的综合范式，从两个维度即临床背景和问题来表征临床决策任务，以此评估模型的难度和实际应用效果，超越了传统单一高准确率指标，扩展了评价维度，包括准确性和效率，以及模型的解释性。这一范式的引入旨在改进临床决策任务中模型的评估方法，使其更贴近真实临床情境，从而推动临床应用中的LSTM技术发展。
### Conclusion
文章澄清了评估假定，标准化了比较基准，为开发具有临床意义的LLMs指明了方向，进一步推动了LLMs在临床决策任务中的实践应用。
## 313. `cs.CL` - 通过适应预训练神经语言模型改进序列标注任务的迁移学习 [PDF](https://arxiv.org/pdf/2510.20033), [HTML](https://arxiv.org/abs/2510.20033)
### Authors
David Dukić
### Background
该博士论文旨在通过适应预训练的神经语言模型来改进序列标注任务中的迁移学习。背景涉及如何利用预训练模型来提升迁移学习的效果，特别是在事件触发检测任务的域迁移中，通过引入多任务模型和修改语言模型架构等方法来提高模型性能。
### Innovation
创新点包括提出了一个多任务模型引入额外信号的方法、在自回归大型语言模型中引入双向信息流的架构修改方法，以及利用生成监督下文方式对自回归大型语言模型进行序列标注框架。这些方法展示了通过针对特定任务进行的迁移学习，可以更好地利用预训练神经语言模型解决序列标注任务。
### Conclusion
通过改进的迁移学习方法，预训练神经语言模型在序列标注任务中表现出最佳性能。这表明，通过设计适当的多任务模型、修改架构和采用特定的调优方法，可以显著提升预训练模型在复杂任务上的适应性和效果。
## 314. `cs.CL` - 锻造GEMs：通过基于质量的语料库编纂和专门的预训练推进现代希腊语自然语言处理 [PDF](https://arxiv.org/pdf/2510.20002), [HTML](https://arxiv.org/abs/2510.20002)
### Authors
Alexandra Apostolopoulou,Konstantinos Kanaris,Athanasios Koursaris,Dimitris Tsakalidis,George Domalis,Ioannis E. Livieris
### Background
在处理像现代希腊语这样的形态丰富的、资源中等的语言时，自然语言处理的进步受到研究领域分散、缺乏架构多样性以及使用有限上下文长度模型的限制。在诸如法律这样的专业化、高价值领域，现有模型经常局限于早期的Transformer架构，这些架构对长文档分析能力不足，存在512个标记的限制窗口。
### Innovation
本文提出了希腊嵌入模型（Greek Embedding Models，GEM），一种新的基于现代架构的变压器模型家族，构建于广泛的质量驱动语料库基础上。构建了多种大规模希腊语语料库，并应用严格的、质量导向的过滤和预处理方法，从通用领域和专门的法律来源中生成高质量的训练数据集。前馈并系统评估了包括ELECTRA、ConvBERT和ModernBERT在内的多种现代架构，这是这些架构首次应用于希腊语言。提出了高效的双语希腊-英语嵌入模型，专门针对法律领域，并在下游任务中进行广泛实验，表明GEM-RoBERTa和GEM-ConvBERT模型显著优于现有基准模型，彰显了提出方法的有效性。
### Conclusion
新的模型类别证明了本文方法的有效性，GEM-RoBERTa和GEM-ConvBERT模型在法律领域等下游任务中显著优于现有基线，展示了基于高质量语料库的编纂和专门预训练的优势。
## 315. `cs.CL` - 从数据到民间故事：评估大型语言模型在孟加拉文化知识上的表现 [PDF](https://arxiv.org/pdf/2510.20043), [HTML](https://arxiv.org/abs/2510.20043)
### Authors
Nafis Chowdhury,Moinul Haque,Anika Ahmed,Nazia Tasnim,Md. Istiak Hossain Shihab,Sajjadur Rahman,Farig Sadeque
### Background
最近在NLP领域的研究显示了大型语言模型（LLMs）在多种任务中的卓越能力。尽管多语言基准测试提升了对LLMs的文化评估，但仍存在捕捉低资源文化细微差别的关键不足。本研究通过创建包含民间传统、烹饪艺术和地方方言在内的Bengali Language Cultural Knowledge（BLanCK）数据集来解决这些局限性。
### Innovation
该研究开发了一个名为BLanCK的数据集，专门涵盖孟加拉文化的三个重要方面。研究发现，尽管多语言模型在非文化类别上表现良好，但在评估文化知识时却表现不佳，而在提供语境的情况下，这些模型的表现显著提高，这强调了语境感知架构和文化定制训练数据的重要性。
### Conclusion
多语言模型在传统文化知识上的表现仍存局限，通过提供语境信息，模型的性能得到了显著提高。研究揭示了语境感知架构以及文化定制训练数据在提升模型文化知识处理能力中的重要性。
## 316. `cs.CL` - ToolScope: 通过工具合并和上下文感知过滤增强LLM代理的工具使用 [PDF](https://arxiv.org/pdf/2510.20036), [HTML](https://arxiv.org/abs/2510.20036)
### Authors
Marianne Menglin Liu,Daniel Garcia,Fjona Parllaku,Vikas Upadhyay,Syed Fahad Allam Shah,Dan Roth
### Background
大型语言模型（LLM）代理依赖外部工具来解决复杂任务，但在实际应用中，工具集中往往包含冗余工具，导致名称和描述重叠，引入了歧义并降低了选择准确性。此外，LLMs面临严格的输入上下文限制，这影响了它们高效评估大型工具集的能力，从而降低了工具使用的灵活性和效率。
### Innovation
文章提出了ToolScope，这是一个解决方案，旨在解决上述问题：它包括（1）一种结合自动纠察功能的ToolScopeMerger工具合并模块，用于减少冗余和提高工具名称的准确性，以及（2）ToolScopeRetriever工具检索模块，该模块根据查询选择并压缩最相关的工具组合，使其适合上下文限制的同时保持准确性。
### Conclusion
通过在三个先进LLM和三个开源工具使用基准测试上进行评估，ToolScope展示了在工具选择准确性方面的显著提升，最高达38.6%，证明了其在提升LLM工具使用体验方面的有效性。
## 317. `cs.CL` - 在小型波斯语医疗语言模型中增强推理能力可以超越大规模数据训练 [PDF](https://arxiv.org/pdf/2510.20059), [HTML](https://arxiv.org/abs/2510.20059)
### Authors
Mehrdad Ghassabi,Sadra Hakim,Hamidreza Baradaran Kashani,Pedram Rostami
### Background
在特定领域如医疗问答中，尤其是对于小众语言（如波斯语），增强小型语言模型的推理能力是关键。现有的研究表明，在波斯语等语言中的医疗问答能力是至关重要的。
### Innovation
本研究利用强化学习带AI反馈（RLAIF）和直接偏好优化（DPO）来提升通用波斯语语言模型的推理能力。通过将多选医疗问答数据集翻译成波斯语，并使用RLAIF生成了被偏好和未被偏好的答案对，进而用于DPO训练。研究结果显示，使用少量数据集就能显著提高模型在波斯语医疗问答中的推理能力，该方法相较于大量数据训练的方法效果更佳。
### Conclusion
研究结果表明，通过集中训练增强推理能力的方法在数据有限的情况下，能够有效提升小型波斯语医疗语言模型的能力，性能甚至超过了基于5700万 token 训练的模型。这展示了在有限数据情况下，专注于推理能力训练的重要性。
## 318. `cs.CL` - CreativityPrism：大型语言模型创造力的全面基准 [PDF](https://arxiv.org/pdf/2510.20091), [HTML](https://arxiv.org/abs/2510.20091)
### Authors
Zhaoyi Joey Hou,Bowei Alvin Zhang,Yining Lu,Bhiman Kumar Baghel,Anneliese Brei,Ximing Lu,Meng Jiang,Faeze Brahman,Snigdha Chaturvedi,Haw-Shiuan Chang,Daniel Khashabi,Xiang Lorraine Li
### Background
以往的研究虽然认为创造力是人类智能的一大特征，且大型语言模型（LLMs）也开始被认为是创造性的文本生成者，但目前缺乏一个全面的框架来评估LLMs在不同场景中的创造力。现有的评估方法碎片化，不同的领域和任务之间有着显著的差异，主要原因是对创造力的不同定义和测量标准。
### Innovation
本文提出了CreativityPrism，这是一种评估分析框架，将创造力分解为三个维度：质量、新颖性、多样性。该框架包含九个评估任务、三个领域（发散思维、创造性写作、逻辑推理）以及二十种评估指标，这些指标以任务特定的独特方式度量每个维度。研究使用17种最先进（SoTA）的商业和开源LLMs进行了评估，并分析了不同指标和任务领域的性能相关性。
### Conclusion
研究结果显示，商业模型和开源模型之间存在显著的差距。模型在同一个领域内的不同任务之间的表现高度相关，而在不同领域之间则不那么相关。在评估维度上，多样性和质量指标的相关性较强，而新颖性指标与其他指标的相关性较弱。这些发现支持了我们的假设，即在一项创造力任务或维度表现出色的模型不一定在其他任务或维度上也表现出色，这强调了全面评估LLMs创造力的必要性。
## 319. `cs.CL` - 利用自适应路由和目标推理在实体链接中发挥大型语言模型的威力 [PDF](https://arxiv.org/pdf/2510.20098), [HTML](https://arxiv.org/abs/2510.20098)
### Authors
Yajie Li,Albert Galimov,Mitra Datta Ganapaneni,Pujitha Thejaswi,De Meng,Priyanshu Kumar,Saloni Potdar
### Background
传统的实体链接（Entity Linking, EL）依赖于大规模标注数据集和广泛的模型微调。近年来，少量样本的方法通过提示技术利用大型语言模型（ Large Language Models, LLMs），减少了训练需求，但存在由于依赖昂贵的LLM推理导致的效率问题。
### Innovation
ARTER（Adaptive Routing and Targeted Entity Reasoning）提出了一个结构化的流程，通过策略性地结合候选生成、基于上下文的评分、自适应路由和选择性推理，实现了高性能而无需深入微调。ARTER计算从检索到的候选中的一组互补信号（包括嵌入和LLM基推理），将上下文提及分为容易和困难的案例，分别由低计算复杂度的实体链接器（例如 ReFinED）和更昂贵的目标驱动的LLM推理处理。相比ReFinED，在标准基准测试中，ARTER表现更好，最高提高了4.47%，平均提高了2.53%，且在计算效率上比完全依赖LLM推理的流程高近两倍。
### Conclusion
ARTER在保持高性能的同时，通过合理利用大规模语言模型和减少计算资源消耗，提供了可扩展且高效的方法，从而在实体链接任务中取得了显著成效。
## 320. `cs.CL` - BoundRL：通过强化边界生成的高效结构化文本分段 [PDF](https://arxiv.org/pdf/2510.20151), [HTML](https://arxiv.org/abs/2510.20151)
### Authors
Haoyuan Li,Zhengyuan Shen,Sullam Jeoung,Yueyan Chen,Jiayu Li,Qi Zhu,Shuai Wang,Vassilis Ioannidis,Huzefa Rangwala
### Background
随着结构化文本在不同领域变得愈发复杂，包括技术报告和生成AI提示在内的多种文档类型，对于文本进行分段以提取语义上有意义的组件变得至关重要。传统的句子或段落级别的分段方法无法有效处理表格、代码片段和占位符等非纯文本元素。
### Innovation
本文提出了一种名为BoundRL的创新性方法，结合了标记级别文本分段和标签预测，适用于长格式结构化文本。BoundRL通过生成起始标记序列并在原始文本中定位这些标记来重建内容，从而大幅减少推理成本并减少错觉。此外，它还通过系统地扰乱部分生成的序列片段来构建中间候选方案，以逐步提高解决方案的质量。
### Conclusion
实验表明，BoundRL使小语言模型（参数量1.7B）在处理复杂提示时表现出色，超出了一次提示的大规模模型。与监督微调相比，RLVR与自定义奖励相结合显著提高了性能，进一步引入中间候选方案则进一步提升了泛化能力。
## 321. `cs.CL` - 大语言模型在零样本观点检测中是否受到刻板印象的影响？ [PDF](https://arxiv.org/pdf/2510.20154), [HTML](https://arxiv.org/abs/2510.20154)
### Authors
Anthony Dubreuil,Antoine Gourru,Christine Largeron,Amine Trabelsi
### Background
大型语言模型从预训练数据中继承刻板印象，导致在情感分析或仇恨言论检测等自然语言处理任务中对某些社会群体表现出偏见的行为。尽管如此，对于这种偏见在观点检测方法中的评价仍未受到社区足够的关注。观点检测涉及对某个特定目标的反对、支持或中立标签，是NLP中最敏感的任务之一，因为它通常与政治倾向有关。本文研究了大型语言模型在零样本环境下的观点检测偏见。
### Innovation
本文自动给预存在观点检测数据集中的帖子标注了方言或特定群体的语言复杂度/可读性两个属性，以此来研究这些属性是否影响模型的观点检测决策。结果显示，大型语言模型在观点检测任务中表现出显著的刻板印象，如错误将支持大麻的观点与低文本复杂性和非洲裔美国方言关联起来，以及将反对唐纳德·特朗普的行为与非洲裔美国方言相关联。
### Conclusion
大型语言模型在零样本观点检测中表现出明显的刻板印象，这些刻板印象影响了模型对某些社会群体观点的识别。
## 322. `cs.CL` - DeepWideSearch: 评估信息检索中深度与广度的基准 [PDF](https://arxiv.org/pdf/2510.20168), [HTML](https://arxiv.org/abs/2510.20168)
### Authors
Tian Lan,Bin Zhu,Qianghuai Jia,Junyang Ren,Haijun Li,Longyue Wang,Zhao Xu,Weihua Luo,Kaifu Zhang
### Background
当前的搜索代理在执行多跳检索的深入推理和广泛信息收集方面存在根本性的不足，这对于实际应用如市场分析和企业发展来说是关键的缺失。DeepWideSearch 框架旨在弥补这一差距，提供首个明确评估代理综合深度与广度信息收集能力的基准。
### Innovation
DeepWideSearch 提出了两种方法来处理现有数据集，创建了一套涵盖 15 个不同领域的 220 个问题的精选集合。实验表明，即使是当前最先进的代理在 DeepWideSearch 上的成功率也仅有 2.39%，突显了将深度和广度搜索结合到信息检索任务中的巨大挑战。此外，错误分析揭示了四种失败模式：缺乏反思，过度依赖内部知识，检索不足，以及语境溢出，这些揭示了现有代理架构的关键限制。
### Conclusion
DeepWideSearch 公开发布以促进更强大、更可靠的搜索代理研究。
## 323. `cs.CL` - Mixture-of-Minds：表格理解的多智能体强化学习 [PDF](https://arxiv.org/pdf/2510.20176), [HTML](https://arxiv.org/abs/2510.20176)
### Authors
Yuhang Zhou,Mingrui Zhang,Ke Li,Mingyi Wang,Qiao Liu,Qifei wang,Jiayi Liu,Fei Liu,Serena Li,Weiwi Li,Mingze Gao,Abhishek Kumar,Xiangjun Fan,Zhuokai Zhao,Lizhu Zhang
### Background
理解和推理表格在许多实际应用中是至关重要的能力。虽然大型语言模型在表格推理任务上表现出了潜力，但现有的方法仍受到局限。基于微调的方法增强了语言推理能力，但容易出现算术错误和虚构情节；基于工具的方法能够实现精确的表操作，但依赖于僵硬的模式，缺乏语义理解。这些互补的不足之处表明，需要结合稳健推理和可靠表处理的方法。因此，我们提出了Mixture-of-Minds，一个拆分表格推理任务到三个专门角色的多智能体框架：规划、编码和回答。
### Innovation
Mixture-of-Minds是一种多智能体架构，通过将表格推理任务拆解为规划、编码和回答三个专门角色，每个智能体专注于特定任务方面，并利用代码执行来实现精确的表操作。通过基于蒙特卡洛树搜索（MCTS）的自我改进训练框架和强化学习（RL）优化代理，展示出显著改进，达到了62.13%的TableBench得分，并超过了OpenAI-o4-mini-high。
### Conclusion
这项工作展示了将结构化的多智能体工作流与RL结合以推进表格理解的潜力。
## 324. `cs.CL` - 在矩阵中受困：探索大型语言模型的空间推理能力 [PDF](https://arxiv.org/pdf/2510.20198), [HTML](https://arxiv.org/abs/2510.20198)
### Authors
Maggie Bai,Ava Kim Cohen,Eleanor Koss,Charlie Lichtenbaum
### Background
本文通过五项任务来探索大型语言模型（LLMs）在文本输入上的空间推理能力。任务涵盖基础的空间识别、几何变换、距离评估、单词搜索和拼图移动等，在网格结构环境中测试模型的基本空间推理和多步骤问题解决能力。随着任务复杂性的增加，模型需要从简单的模式识别转向抽象的空间推理。
### Innovation
作者设计了一系列旨在测试大型语言模型在空间理解和计算能力上的任务，探索了它们在不同复杂度任务中的表现差异，并揭示了模型在复杂任务中空间推理能力的局限性。
### Conclusion
研究发现，小型和基础复杂的任务中LLMs表现出适度的成功，但随着任务复杂性的增加，性能急剧下降，准确率平均下降42.7%，最高下降至84%。模型在复杂任务中的表现衰退表明其基础架构中缺乏稳健的空间表示。该研究强调了LLMs在语言和空间推理之间的差距，并指出其当前的限制，为未来结合语言和几何的基准测试奠定了基础。
## 325. `cs.CL` - 无解码采样策略用于LLM边缘化 [PDF](https://arxiv.org/pdf/2510.20208), [HTML](https://arxiv.org/abs/2510.20208)
### Authors
David Pohl,Marco Cognetta,Junyoung Lee,Naoaki Okazaki
### Background
现代语言模型通过子词标记化文本来折衷模型大小、推理速度和词汇覆盖范围。这种子词标记化会导致在推理过程中，模型仅评估特定标记化的概率，但实际上存在多种可能的标记化方式来表示同一文本。最近的研究建议通过边缘化来评估大规模语言模型（LLMs），即计算给定文本所有标记化的概率总和。然而，由于文本可能有大量不同的标记化方式，使边缘化变得困难，通常是通过采样来近似计算。尽管采样可以减轻计算负担，但它要求LLM进行昂贵的生成步骤，这限制了在给定运行时间预算内可以生成的样本数量，从而影响了近似的准确性。
### Innovation
本文研究了无解码采样策略，这些策略不需要LLM生成任何内容，而是依赖于非常便宜且模型和标记化器无关的采样策略，来估计边缘化的概率。研究发现这些无解码采样策略能够以较低的时间成本提供足够准确的边缘化估计，并且展示其在下游推理任务中的应用。
### Conclusion
本文探讨了几种无解码采样策略，发现它们在运行时间成本很小的情况下能提供充分准确的边缘化估计，并通过在多种开放模型上的测试展示了这种方法的有效性。这种方法为大规模语言模型的边缘化评估提供了一种高效且模型无关的方法。
## 326. `cs.CL` - 引用失败：定义、分析与高效缓解 [PDF](https://arxiv.org/pdf/2510.20303), [HTML](https://arxiv.org/abs/2510.20303)
### Authors
Jan Buchmann,Iryna Gurevych
### Background
LLM（大型语言模型）基于RAG（检索-生成）系统的引用被认为是简化响应验证的一种方式。然而，当模型生成有益回应但未能完全引用证据时，这种设想无法实现。这种引用失败不同于先前的研究工作，这里我们将引用失败与回应失败区分开来，回应失败是指回应本身存在问题，因此无法引用完整证据。本文提出了一个两步方法来应对引用失败：首先研究引用失败何时发生，其次探讨如何缓解这种问题。
### Innovation
本文引入了CITECONTROL基准，系统地改变了回应与证据之间的关系来分析失败模式。提出了CITENTION框架，结合生成式、注意力基和检索基方法，提高了LLM的引用效率。这种方法在CITECONTROL和迁移设置中显著提高了引用质量。
### Conclusion
实验结果表明，结合引用方法可能改进性能，因此开发CITENTION框架可以在引用控制测试和实际应用中显著提高引用质量。相关数据和代码已公开发布。
## 327. `cs.CL` - 跨抑郁和创伤后应激障碍的三模态严重性融合诊断 [PDF](https://arxiv.org/pdf/2510.20239), [HTML](https://arxiv.org/abs/2510.20239)
### Authors
Filippo Cenacchi,Deborah Richards,Longbing Cao
### Background
抑郁和创伤后应激障碍（PTSD）经常同时出现且伴有共病症状，这使得自动化评估变得复杂。现有的自动化评估方法往往是二元和特定于单一障碍的，而临床有效诊断需要针对多种障碍的严重程度意识评估和解释决策支持。本文介绍了一个统一的三模态情感严重性框架，该框架通过将访谈文本与句子级transformer嵌入、音频与log Mel统计及其差值、面部信号与动作单元、凝视、头部和姿态描述同步和融合，输出针对诊断抑郁症（PHQ-8，5类）和PTSD（3类）的严重性评估。
### Innovation
本文提出了一种三模态融合方法，通过将访谈文本、音频和面部信号等三种模式的数据同步和融合，输出抑郁症和PTSD的严重性评估。该方法采用标准化特征和校准的后期融合分类器，融合后模型在噪声或数据缺失的情况下具有更强的健壮性和可解释性。该融合方法在DAIC衍生的多障碍并发抑郁症和PTSD评估中表现出色，超越了单模态和消融基线。对于PTSD，融合方法降低了回归误差并提高了类别一致性，误判集中在相邻严重程度之间，极端严重程度也能可靠地识别。
### Conclusion
本文提出的方法在临床决策中提供了可重复评估和支持，并与语言和行为标记的属性保持一致，不仅提高了解释性，还提高了在噪声或缺失数据情况下的稳健性。
## 328. `cs.CL` - FreeChunker：一种跨粒度分块框架 [PDF](https://arxiv.org/pdf/2510.20356), [HTML](https://arxiv.org/abs/2510.20356)
### Authors
Wenxuan Zhang,Yuan-Hao Jiang,Yonghe Wu
### Background
现有的分块策略方法依赖于固定粒度的模式并且基于静态边界的识别，这限制了它们在应对多样化查询需求时的灵活性。
### Innovation
提出了FreeChunker，这是一种跨粒度编码框架，改变了传统的分块模式，将句子视为原子单元，从静态分块分割转向灵活的检索，支持任意句子组合。这一变革不仅大幅减少了语义边界检测所需的计算开销，还增强了对复杂查询的适应能力。
### Conclusion
实验证明，FreeChunker在LongBench V2上的检索性能优于传统的分块方法，并且在计算效率方面显著优于现有方法。
## 329. `cs.CL` - 探索生成过程奖励建模在半结构化数据中的应用：表问题回答案例研究 [PDF](https://arxiv.org/pdf/2510.20304), [HTML](https://arxiv.org/abs/2510.20304)
### Authors
Lei Tang,Wei Zhou,Mohsen Mesgar
### Background
过程奖励模型（PRMs）通过逐步评估候选解决方案并汇总步骤分数来选择答案，从而在大型语言模型（LLMs）中提升复杂推理能力。尽管在数学等领域表现出色，但其对涉及半结构化数据的任务，如表问题回答（TQA）的应用尚未被探索。TQA 面临的独特挑战包括大量的无关信息、松散连接的推理步骤以及领域特定的推理。
### Innovation
这是首次系统研究 PRMs 在 TQA 中的应用。本文评估了最先进的生成 PRMs 在 TQA 中的性能，从答案和步骤两方面进行评价。结果显示，结合文本和代码验证的 PRMs 能够辅助解决方案选择，但难以泛化到新域数据。分析发现，在步骤级别验证与答案准确性之间的关系较弱，可能源于较弱的步骤依赖性和松散的因果联系。本研究揭示了当前 PRMs 在 TQA 中的局限性，提供了构建更稳健、过程意识更强的验证器的重要见解。
### Conclusion
研究发现当前 PRMs 在 TQA 中存在局限性，并为构建更稳健、过程知情的验证器提供了宝贵的见解。
## 330. `cs.CL` - 通过学习预测性上下文嵌入实现上下文级别的语言建模 [PDF](https://arxiv.org/pdf/2510.20280), [HTML](https://arxiv.org/abs/2510.20280)
### Authors
Beiya Dai,Yuliang Liu,Daozheng Xue,Qipeng Guo,Kai Chen,Xinbing Wang
### Background
Next-token prediction (NTP) 是现代大型语言模型 (LLMs) 预训练的基础，推动了其在文本生成、推理和指令跟随方面的前所未有的能力。然而，基于标记级别的预测限制了模型捕捉更高层次语义结构和长距离上下文关系的能力。为了克服这一局限，本文提出了 ContextLM 框架，通过在标准预训练中增加固有的下文级预测目标来增强模型的能力。此机制训练模型学习多标记上下文的预测表示，并利用未来标记片段派生的误差信号。实验表明，ContextLM 在标准自回归、逐标记评估范式（如困惑度）上保持兼容性的同时，能带来一致的困惑度和下游任务性能改进。通过分析发现，下文级预测提供了一种更高效、可扩展的语言建模途径，增强了长距离连贯性并优化了注意力分配，而几乎没有增加计算开销。
### Innovation
提出了 ContextLM 框架，该框架通过增强标准预训练模型来引入一种固有的下文级预测目标。这一机制训练模型学习多标记上下文的预测表示，并利用未来标记片段派生的误差信号。ContextLM 保持了与标准自回归、逐标记评估范式（如困惑度）的兼容性，同时提高了模型的长距离上下文理解和预测能力，即使在大型参数规模的模型中也能够实现这种改进。
### Conclusion
实验证明，ContextLM 通过实现下文级预测增强了语言模型，这种增强在大型语言模型中表现为显著的困惑度和下游任务性能的提升。下文级预测为更强大的语言建模提供了一种可扩展和高效的途径，通过减少计算开销提高了更长范围的语境连贯性以及更有效的注意力分配。
## 331. `cs.CL` - 教学语言模型利用工具进行推理 [PDF](https://arxiv.org/pdf/2510.20342), [HTML](https://arxiv.org/abs/2510.20342)
### Authors
Chengpeng Li,Zhengyang Tang,Ziniu Li,Mingfeng Xue,Keqin Bao,Tian Ding,Ruoyu Sun,Benyou Wang,Xiang Wang,Junyang Lin,Dayiheng Liu
### Background
大型推理模型（LRMs）如OpenAI-o1展示了在自然语言推理方面的显著能力，但在处理复杂数学运算时却经常表现出低效或不准确。虽然集成计算工具如代码解释器（CIs）提供了一种有前景的解决方案，但也带来了关键挑战：模型内部的概率推理与由CI提供的外部确定性知识之间的冲突，常导致模型陷入无效的思考。
### Innovation
本文提出了CoRT（代码优化推理训练），这是一种后训练框架，旨在教导LRMs有效利用CIs。提出了一种新的数据合成策略——提示工程，该策略在推理路径中的关键点注入多样化的提示，生成高质量的、代码集成的推理数据，专门优化LRM-CI的互动。CoRT进一步通过拒绝采样和强化学习来更好地进行外部CI使用与内部思考的交错。实验结果显示，CoRT在五个具有挑战性的数学推理数据集上取得了绝对改进，分别为4%和8%的提升，并显著提高了模型的效率，分别减少了30%和50%的令牌使用量，与纯自然语言推理基线相比。
### Conclusion
TCL模型在处理复杂数学运算时收到了CoRT训练的显著改善，特别是在数学推理效率和准确性的提升上，展示了在LRM与外部工具集成方面的一个重要进展。
## 332. `cs.CL` - 大型语言模型中否定文本对幻觉的影响 [PDF](https://arxiv.org/pdf/2510.20375), [HTML](https://arxiv.org/abs/2510.20375)
### Authors
Jaehyung Seo,Hyeonseok Moon,Heuiseok Lim
### Background
近期对大型语言模型（LLMs）中的幻觉研究已在自然语言处理领域迅速发展，但关于否定文本对幻觉的影响研究较少。当前关于LLMs在处理否定文本时对幻觉检测的能力仍不清楚，需要进一步探索和研究。
### Innovation
本文提出了三个未被广泛研究的研究问题，并通过构建带有否定表达的NegHalu数据集来设计实验。结果表明，LLMs在否定文本中检测幻觉的能力较弱，容易产生逻辑不一致或不忠实的判断，揭示了处理否定输入时缓解其意外影响的挑战，提供了在处理否定文本时改进幻觉检测的方法和思路。
### Conclusion
本文通过设计带有否定文本的实验数据集，揭示了LLMs在处理这类文本时对幻觉检测的不足，为进一步优化幻觉检测提出了可能的改进方向。
## 333. `cs.CL` - 大型语言模型中对公共表格数据集隐含知识的评估 [PDF](https://arxiv.org/pdf/2510.20351), [HTML](https://arxiv.org/abs/2510.20351)
### Authors
Matteo Silvestri,Flavio Giorgi,Fabrizio Silvestri,Gabriele Tolomei
### Background
大型语言模型（LLMs）在处理结构化数据时被越来越多地评估其推理能力，但在这些评估中往往忽略了数据集污染这一重要因素。本文通过一系列受控假设检验实验，探究LLMs是否事先知道广泛使用的表格基准数据集，如Adult Income、Titanic等。实验结果揭示出，仅在包含强烈语义提示的数据集中，如有意义的列名或可解释的数据类别，才会出现污染效应。而去除了或随机化这些提示后，性能会急剧下降至近乎随机水平。这表明LLMs在表格推理任务中的看似能力可能部分反映了对公开数据集的记忆，而不是真正的泛化能力。
### Innovation
本文提出了通过控制性假设检验实验揭示大型语言模型数据集污染的现象，特别是当数据集中有强语义线索（如有意义的列名和可解释的数据类别）时，模型会表现出预学习的倾向。这为理解大型语言模型在处理结构化数据时的真正能力提供了一个新的视角。
### Conclusion
研究结果表明，大型语言模型在表格推理任务上的表现部分是由于对公开数据集的记忆，而不是真正的泛化能力。因此，对于评估协议提出了考虑数据集污染的影响，并提出策略以分离语义泄漏和真实的推理能力，从而在未来的大型语言模型评估中提高公平性和可靠性。
## 334. `cs.CL` - 对话并不能让小型语言模型具备沟通能力（但发展启发式强化学习也不行） [PDF](https://arxiv.org/pdf/2510.20358), [HTML](https://arxiv.org/abs/2510.20358)
### Authors
Francesca Padovani,Bastian Bunzeck,Manar Ali,Omar Momen,Arianna Bisazza,Hendrik Buschmeier,Sina Zarrieß
### Background
本文探讨了仅基于对话数据进行预训练是否能够生成在形式和功能上都合适的较小语言模型。研究者们基于名为llamalogue的预训练模型，通过多种微调策略，试图提升模型在生成更具沟通性的文本方面的表现。尽管这些模型在大多数标准BabyLM基准上表现不佳，但在最小对设置下的对话延续预测任务上表现出色。虽然PPO微调效果参差不齐，有些甚至具有对抗性质，但DPO微调提升了它们在自定义对话基准上的表现。
### Innovation
研究引入了多种微调策略来增强模型的沟通能力，特别是在对话延续预测任务上的表现，并对比了不同微调方法的效果。研究发现，尽管对话数据预训练能够取得一定的优势，但单一的数据源不足以让小语言模型达到全面的沟通能力，同时也挑战了通过强化学习来改进语言模型沟通能力的方法。
### Conclusion
尽管进行了多种尝试，仅依赖对话数据进行预训练和使用发展启发式强化学习微调都不能有效地让小语言模型具备全面的沟通能力。研究结果表明，小型语言模型在多种沟通任务上的表现仍然有限，这提示未来的研究需要在多数据源和多种训练方法的结合上下功夫。
## 335. `cs.CL` - VLSP 2025 MLQA-TSR挑战：越南多模态法律问答中的交通标志条例 [PDF](https://arxiv.org/pdf/2510.20381), [HTML](https://arxiv.org/abs/2510.20381)
### Authors
Son T. Luu,Trung Vo,Hiep Nguyen,Khanh Quoc Tran,Kiet Van Nguyen,Vu Tran,Ngan Luu-Thuy Nguyen,Le-Minh Nguyen
### Background
VLSP 2025 MLQA-TSR是VLSP 2025中的一项共享任务，目的是推进越南多模态法律法规文本处理的研究，并为构建和评估多模态法律领域的智能系统提供基准数据集，特别关注越南的交通标志条例。该任务包括两个子任务：多模态法律检索和多模态问答。
### Innovation
提出了VLSP 2025 MLQA-TSR共享任务，通过设置多模态法律检索和多模态问答两个子任务，促进越南多模态法律文本处理的研究。提供了用于评估多模态法律领域智能系统性能的基准数据集，特别聚焦于越南交通标志法规。
### Conclusion
最佳报告显示，多模态法律检索任务的F2分数为64.55%，多模态问答任务的准确率为86.30%。
## 336. `cs.CL` - NeoDictaBERT: 推动BERT模型在_hebrew_领域的前沿 [PDF](https://arxiv.org/pdf/2510.20386), [HTML](https://arxiv.org/abs/2510.20386)
### Authors
Shaltiel Shmidman,Avi Shmidman,Moshe Koppel
### Background
自BERT模型首次发布以来，尽管其规模较小（BERT-base约有100M参数），但在各种任务中表现出色。然而，这些模型的架构选择已落后于Llama3和Qwen3等新一代的Transformer模型。最近几个月，有几种架构被提出以弥补这一差距。ModernBERT和NeoBERT在英语基准测试中表现出色，并显著扩展了支持的上下文窗口。
### Innovation
本研究引入了NeoDictaBERT和NeoDictaBERT-bilingual：采用与NeoBERT相同的架构，专注于希伯来语文本的BERT风格模型。这些模型在几乎所有希伯来语基准测试中表现出色，为下游任务提供了坚实的基础。值得注意的是，NeoDictaBERT-bilingual模型在检索任务中表现尤为出色，胜过其他相似规模的多语言模型。
### Conclusion
本文描述了NeoDictaBERT和NeoDictaBERT-bilingual模型的训练过程，并在多种基准测试上报告了其结果。模型已被社区公开发布，旨在推进希伯来语自然语言处理的研究和开发。
## 337. `cs.CL` - 优化掩码语言模型以预训练BabyLMs：获取你所掩蔽 [PDF](https://arxiv.org/pdf/2510.20475), [HTML](https://arxiv.org/abs/2510.20475)
### Authors
Lukas Edman,Alexander Fraser
### Background
本文介绍了2025年BabyLM挑战赛的战略。背景信息为当前语言模型使用掩码语言模型（MLM）进行预训练的方法，尽管效果良好，但在特定任务上仍然存在提升空间，特别是在处理超胶水（Super）任务时，标准的MLM方法仍有改进的余地。
### Innovation
研究的主要创新点在于改进了掩码的语言模型方法，通过根据模型预测能力调整被掩码的标记概率，这种方法显示出在（超）胶水任务上显著的性能提升。此外，论文还引入了子标记嵌入，增强模型在形态分析上的泛化能力。
### Conclusion
提交的结果在严格的BabyLM小轨道比赛中超过了基线模型。
## 338. `cs.CL` - RECALL: 代表对齐的大灾难遗忘缓解通过层次模型合并 [PDF](https://arxiv.org/pdf/2510.20479), [HTML](https://arxiv.org/abs/2510.20479)
### Authors
Bowen Wang,Haiyuan Wan,Liwen Shi,Chen Yang,Peng He,Yue Ma,Haochen Han,Wenhao Li,Tiao Tan,Yongjian Li,Fangming Liu,Yifan Gong,Sheng Zhang
### Background
大型语言模型（LLMs）的内部表示被证明是学习知识的可靠代理。然而，现有方法在持续学习过程中需要历史数据访问或会牺牲性能。
### Innovation
提出了一种新的RECALL框架，用于无需访问历史数据的持续学习。RECALL通过层间隐藏表示计算模型间相似性，并进行适应性和分层级的参数融合，以在保持浅层普遍特征的同时允许深层任务特定适应。与需要任务标签或造成性能权衡的现有方法不同，RECALL实现了无缝的多域集成并具有强大的灾难性遗忘抵抗力。
### Conclusion
广泛的实验表明，RECALL在知识保留和泛化方面优于基线，提供了一种可扩展且无需数据的解决方案，适用于演化的LLMs。
## 339. `cs.CL` - BabyLM在儿童交互区的近位发展区域内教师示范对含应对性的多轮交互的影响 [PDF](https://arxiv.org/pdf/2510.20411), [HTML](https://arxiv.org/abs/2510.20411)
### Authors
Suchir Salhan,Hongyi Gu,Donya Rooein,Diana Galvan-Sosa,Gabrielle Gaudeau,Andrew Caines,Zheng Yuan,Paula Buttery
### Background
多轮对话中的儿童与看护者之间存在一种称为连贯的特性，即对话参与者之间直接、有意义且相关的交流。本文研究了如何通过教师-学生框架在训练于100万词上的BabyLM模型中，评估和提高多轮对话中的连贯性，并使用一个新颖的对齐数据集在后续训练中生成更具语法性和连贯性的响应。尽管实验表明适应教师解码策略能带来有限的额外增益，但ContingentChat框架仍然证明了针对后训练对对话质量的改进具有优势，且表明连贯性仍然是BabyLM面临的一大挑战。
### Innovation
引入了ContingentChat框架，该框架利用对齐数据集在后续训练中评估和改进训练于100万词上的BabyLM模型的多轮对话连贯性。探索了适应教师解码策略，并展示了通过针对性后训练对提升对话质量的效果，尽管看到了有限的额外增益，但仍揭示了连贯性依然是BabyLM需要解决的重要问题。
### Conclusion
ContingentChat框架表明，针对后训练对提升对话质量有益，同时也展示了提高多轮对话中的连贯性仍是一个具有挑战性的问题。
## 340. `cs.CL` - LM-mixup：基于语言模型的混合逼近文本数据增强方法 [PDF](https://arxiv.org/pdf/2510.20449), [HTML](https://arxiv.org/abs/2510.20449)
### Authors
Zhijie Deng,Zhouan Shen,Ling Li,Yao Zhou,Zhaowei Zhu,Yanji He,Wei Wang,Jiaheng Wei
### Background
语言模型（LLMs）的指令调优至关重要，但用于指令跟随的数据质量差异显著。高质量数据稀缺，而大量低质量数据常被丢弃，导致大量信息损失。现有数据增强方法难以有效增强低质量数据，且这些技术的评估标准模糊不清。因此，需要一种方法来正式定义指令蒸馏任务，并创建一个大型数据集，用以将低质量或语义冗余的指令簇转化为高质量的指令-输出对。
### Innovation
本文提出了LM-Mixup，一种基于语言模型的数据增强方法。该方法首先进行监督微调和MIXTURE数据集中的指令蒸馏，然后使用强化学习进行优化。采用组相对策略优化（GRPO）提供三种互补奖励信号：质量、语义对齐和格式合规。实验展示了LM-Mixup可以有效增强不完美的数据集：使用仅占整个数据集3%的蒸馏数据微调LLMs，不仅超越了全数据集训练，还在多个基准测评中与最先进的高质量数据选择方法竞争。这表明当适当蒸馏并使用LM-Mixup增强时，低质量数据也是有价值的资源，显著提升了指令调优LLMs的效率和性能。
### Conclusion
本文的工作证明，低质量数据通过LM-Mixup的适当蒸馏和增强，可以成为指令调优LLMs的有价值资源，显著提高其效率和性能。
## 341. `cs.CL` - 大规模语言模型中不确定性估计方法的系统评估 [PDF](https://arxiv.org/pdf/2510.20460), [HTML](https://arxiv.org/abs/2510.20460)
### Authors
Christian Hobelsberger,Theresa Winner,Andreas Nawroth,Oliver Mitevski,Anna-Carolina Haensch
### Background
大型语言模型（LLMs）生成的输出具有不同程度的不确定性，并且同样存在不同程度的正确性；使得其实际可靠性无法得到保证。为了量化这种不确定性，本文系统性地评估了四种置信度估计方法：VCE、MSP、样本一致性以及CoCoA（Vashurin等人，2025年）。实验基于最先进的开源LLM在四个问答任务上进行。这些结果显示，每种不确定性度量方法捕捉到了模型信心的不同方面，并且CoCoA综合方法在改进模型校准度和正确答案区分度方面表现最佳。
### Innovation
本文系统评估了四种不同的置信度估计方法，并通过实验证明CoCoA（Vashurin等人，2025年）在综合方法上提供最佳的可靠性，能够在校准度和正确答案区分度方面有所提升。此外，还讨论了每种方法的权衡，并提供了在LLM应用中选择不确定度度量的建议。
### Conclusion
每种不确定性度量方法捕捉到的不同方面表明，CoCoA综合方法整体上表现最优，能够提升校准度和正确答案区分度。每种方法都有各自的权衡，文章提供了选择在LLM应用中使用的不确定性度量的具体建议。
## 342. `cs.CL` - 引导评估意识语言模型表现出部署中的行为 [PDF](https://arxiv.org/pdf/2510.20487), [HTML](https://arxiv.org/abs/2510.20487)
### Authors
Tim Tian Hua,Andrew Qin,Samuel Marks,Neel Nanda
### Background
大型语言模型（LLMs）有时会在被评估时察觉这一状况并调整其行为，使其显得更符合道德标准，从而影响评估的安全性可靠性。本文探讨了一种通过向LLM的激活添加引导向量来抑制评估意识、使其在评估时表现出与部署中类似的言行的方法。
### Innovation
提出了一种通过引导向量技术抑制评估意识的方法。该方法首先通过带两个步骤的训练过程使模型表现出评估意识，然后使用这一技巧来调整模型的行为，使其在评估时表现出与实际部署时的行为相似。
### Conclusion
实验结果表明，通过使用最初模型构建的引导向量可以抑制评估意识，并使模型即使在存在评估提示时也表现出像已部署行为。这为提高安全评估的可靠性提供了一种新的思路。
## 343. `cs.CL` - 通过方向邻域一致性的稳健偏好对齐 [PDF](https://arxiv.org/pdf/2510.20498), [HTML](https://arxiv.org/abs/2510.20498)
### Authors
Ruochen Mao,Yuling Shi,Xiaodong Gu,Jiaheng Wei
### Background
创建可靠且可控的人工智能系统需要让大型语言模型与人类偏好保持一致。人类偏好可以视为一个高维向量，不同方向表示各种期望属性之间的权衡（例如：帮助性与冗长性之间的权衡）。然而，由于训练数据通常反映的是主流和平均偏好，通用语言模型在处理常见请求方面表现出色，但在满足特定和个体需求方面却表现不佳。这种不匹配导致了偏好覆盖缺口。现有的方法通常通过昂贵的重新训练来解决此问题，但这种方法可能无法适用于整个多样偏好范围。模型在遇到与训练数据中心趋势有所偏离的用户请求时，性能可能会不可预测地恶化。为解决这一挑战，我们提出了一种后训练、无需重新训练的方法Robust Preference Selection (RPS)，通过利用方向邻域一致性的策略来提升模型的稳健性。RPS 从一个相关偏好局部邻域中采样多个响应，创建一个候选池，然后选择与用户原始意图最匹配的响应。我们提供了理论框架，证明我们的邻域生成策略在多个批次中都是优于基准的。
### Innovation
我们提出了Robust Preference Selection (RPS) 方法，该方法在没有模型重新训练的情况下，通过利用方向邻域一致性的策略来提升模型对偏好覆盖缺口的稳健性。RPS 方法首先从一个与用户偏好相关的局部邻域中采样多个响应，形成候选池，然后选择与用户真实意图最匹配的响应。我们提供了理论框架来证明我们的邻域生成策略的效果，并通过跨三个不同的对齐范式（DPA、DPO 和 SFT）进行的全面实验来展示其优势，即使在次要偏好区域也取得了高达69%的胜出率，而无需任何模型重训练。
### Conclusion
我们的工作提供了实践且理论依据充足的解决方案，以增强偏好对齐模型的可靠性。
## 344. `cs.CL` - 超越检索-排名：电子商务搜索中的多智能体认知决策框架 [PDF](https://arxiv.org/pdf/2510.20567), [HTML](https://arxiv.org/abs/2510.20567)
### Authors
Zhouwei Zhai,Mengxiang Chen,Haoyun Xia,Jin Li,Renquan Zhou,Min Yang
### Background
检索-排名范式长期以来主导了电子商务搜索，但其依赖于查询项匹配，本质上传递了与平台用户多阶段认知决策过程不一致的信息，这种不一致导致了复杂查询中的语义缺口、跨平台信息采集带来的高决策成本以及缺乏专业购物指导的问题。
### Innovation
提出了一种多智能体认知决策框架（MACDF），从被动检索转向主动决策支持，通过广泛的离线评估和JD搜索引擎平台的A/B测试验证了MACDF在推荐准确性和用户满意度方面的显著改进，尤其是对于涉及否定、多约束或推理需求的复杂查询。
### Conclusion
这项工作突显了多智能体认知系统在重新定义电子商务搜索方面的潜力变革。
## 345. `cs.CL` - 层次序列迭代在异构问答中的应用 [PDF](https://arxiv.org/pdf/2510.20505), [HTML](https://arxiv.org/abs/2510.20505)
### Authors
Ruiyi Yang,Hao Xue,Imran Razzak,Hakim Hacid,Flora D. Salim
### Background
检索增强生成（RAG）在处理多步问题和异构证据源时表现不佳，常常需要在准确性和延迟之间做出权衡，以及在令牌/工具预算之间的权衡。
### Innovation
引入了一种统一框架——层次序列（HSEQ）迭代用于异构问答，该框架包括：（i）将文档、表格和知识图谱线性化为可逆的层次序列，并使用轻量级结构标记；（ii）执行结构感知迭代，在证据收集之前进行回答合成。头部代理提供指导，引导检索，迭代代理则通过结构尊重的操作（如亲缘关系跳转、表格行/列邻居、知识图关系等）选择和扩展HSeq。最后，头部代理通过证据规范化生成最终答案，并可选地进行校正循环以解决检测到的矛盾。在HotpotQA（文本）、HybridQA/TAT-QA（表格+文本）和MetaQA（知识图谱）上进行的实验显示，与强单步骤、多跳和代理RAG基线相比，该方法在效率高的情况下表现出一致的准确率/召回率增益。
### Conclusion
层次序列（HSEQ）展示了三个关键优势：（1）一种格式无关的统一框架，使一个策略能够在文本、表格和知识图谱数据集上通用，不需要对每个数据集进行特定化；（2）指导下的预算感知迭代，减少了不必要的跳转、工具调用和令牌，同时保持了准确率；（3）证据规范化，提高了问题回答的一致性和可审计性。
## 346. `cs.CL` - GlobalRAG：通过强化学习提升多跳问答中的全局推理 [PDF](https://arxiv.org/pdf/2510.20548), [HTML](https://arxiv.org/abs/2510.20548)
### Authors
Jinchang Luo,Mingquan Cheng,Fan Wan,Ni Li,Xiaoling Xia,Shuangshuang Tian,Tingcheng Bian,Haiwei Wang,Haohuan Fu,Yan Tao
### Background
尽管强化学习在提升检索增强生成（RAG）方面展现了潜力，但在多跳问答（QA）中的效果仍受限于两个基本问题：缺乏全局规划来结构化多步推理，以及不可靠执行，这阻碍了有效的查询形成和一致利用检索出的证据。
### Innovation
提出了GlobalRAG，这是一种强化学习框架，旨在增强多跳QA中的全局推理。GlobalRAG将问题分解为子目标，协调检索与推理，并迭代细化证据。该框架引入了规划质量奖励和子目标完成奖励，以促进连贯规划和可靠子目标执行。此外，采用逐步权重退火策略平衡面向过程和面向结果的目标。
### Conclusion
在多种指标上的实验结果表明，GlobalRAG 在仅使用 8k 训练数据（仅为强基线数据的 42%）的情况下，显著超越强基线，平均在 EM 和 F1 指标上分别提高了 14.2%。
## 347. `cs.CL` - ChatGPT能否公平地编码沟通数据？：来自多种协作任务的实证证据 [PDF](https://arxiv.org/pdf/2510.20584), [HTML](https://arxiv.org/abs/2510.20584)
### Authors
Jiangang Hao,Wenju Cui,Patrick Kyllonen,Emily Kerzabi
### Background
大规模评估沟通与协作依赖于将大量的沟通数据手工分类到不同框架中的劳动密集型过程。先前研究发现，ChatGPT可以被直接指导使用编码规范来对沟通数据进行分类，并且在准确性上与人类评定者相当。然而，ChatGPT或类似的人工智能技术生成的编码是否会对不同的性别和种族群体产生偏见尚不清楚。因此，本研究探讨了使用典型的协作问题解决编码框架，基于ChatGPT对沟通数据进行自动编码，并检验了性别和种族群体之间的差异。研究数据来源于三种类型的协作任务：谈判、问题解决和决策制定。
### Innovation
本研究利用了ChatGPT对沟通数据进行自动编码的能力，并通过多个协作任务来检验其编码是否会对不同性别和种族群体产生偏见，填补了该领域的研究空白。
### Conclusion
研究结果表明，基于ChatGPT的编码在性别和种族群体间没有显著偏见，这为在大规模评估协作和沟通中采用ChatGPT铺平了道路。
## 348. `cs.CL` - BUSTED在AraGenEval共享任务中的表现：基于Transformer模型的阿拉伯AI生成文本检测比较研究 [PDF](https://arxiv.org/pdf/2510.20610), [HTML](https://arxiv.org/abs/2510.20610)
### Authors
Ali Zain,Sareem Farooqui,Muhammad Rafi
### Background
本文分析了在阿拉伯AI生成文本检测的Ara-GenEval共享任务中的表现，团队BUSTED在该任务中获得了第5名。研究比较了三种预训练的变换器模型：AraELECTRA、CAMeLBERT和XLM-RoBERTa，探讨了这些模型在二分类任务中的有效性。经过对提供的数据集进行微调后，发现具有多语言能力的XLM-RoBERTa模型表现最佳，获得了F1分数0.7701，优于专门的阿拉伯语模型。这项工作强调了AI生成文本检测的复杂性，并突显了多语言模型的强大泛化能力。
### Innovation
研究团队BUSTED在AraGenEval共享任务中获得了第5名；经过对AraELECTRA、CAMeLBERT和XLM-RoBERTa模型的比较研究，发现具有多语言能力的XLM-RoBERTa模型在阿拉伯AI生成文本检测中表现最佳，这一发现超出了预期。
### Conclusion
这项研究揭示了多语言模型在AI生成文本检测中的强大泛化能力，同时也强调了该领域的复杂性。
## 349. `cs.CL` - 被追逐的狗难住了模型：测量语言模型何时放弃结构转而使用捷径 [PDF](https://arxiv.org/pdf/2510.20543), [HTML](https://arxiv.org/abs/2510.20543)
### Authors
Sangmitra Madhusudan,Kaige Chen,Ali Emami
### Background
尽管语言模型在解析嵌套从句（如“The cat that the dog chased meowed”）时表现良好，但我们在区分语法理解与语义模式匹配的方法上缺乏工具。许多模型在处理复杂嵌套结构时，表现并未如预期般精确，显示出在处理嵌套层次增加时，准确度有所下降的趋势。研究发现，这些模型在处理语义合理和不合理句子时，表现差异随复杂度增加而扩大，尤其在因果推理方面差异显著。因此，研究者提出了一种名为CenterBench的数据集，旨在通过复杂嵌套从句分析语言模型的理解机制。
### Innovation
研究者提出了CenterBench，这是一个包含9,720个以中心嵌套结构（如“The cat that the dog chased meowed”）为核心的理解问题的数据集。每个句子都有一个语义相似但语法不符的对应句子，并设置了六个问题来测试表面理解、句法依赖和因果推理能力。通过测试六个模型的表现，研究者发现，模型在处理复杂结构时，表现与简单结构相比，有显著的差距，这种差距随着句子复杂度的提高而增大。研究还发现了推理模型使用语义捷径的问题，相比之下，人类对复杂结构的理解表现则不一致，研究首次提供了一个框架来说明模型从结构分析转向模式匹配的过程。
### Conclusion
研究发现，当语言模型处理极其复杂的嵌套句子时，它们更倾向于依赖于语义匹配而不是结构分析。模型无法像人类一样灵活应对复杂的结构关系，模型性能的差距随着复杂度的增加而显著放大。研究结果提供了一个有效框架，以衡量语言模型何时放弃了结构分析而依赖于捷径。
## 350. `cs.CL` - 为何苹果会落地：评估大型语言模型中的好奇心 [PDF](https://arxiv.org/pdf/2510.20635), [HTML](https://arxiv.org/abs/2510.20635)
### Authors
Haoyu Wang,Sihang Jiang,Yuyan Chen,Yitong Wang,Yanghua Xiao
### Background
人类的好奇心作为探索和学习新知识的关键驱动力，最近大型语言模型（LLMs）在自然语言处理方面的进步引发了关于这些模型是否拥有与人类相似的好奇驱动学习能力的讨论。本文以人类好奇心评估问卷五维好奇心量表修订版（5DCR）为基础，设计了一个全面的评估框架，涵盖信息寻求、冒险寻求和社会好奇心等维度，来评估LLMs的好奇心水平。研究表明，尽管LLMs在不确定环境中倾向于保守选择，但它们的知识渴求程度超过了人类。进一步研究发现，好奇行为能够提升模型的推理和主动学习能力。
### Innovation
本文通过设计一种结合信息寻求、冒险寻求和社会好奇心等多维度的评估框架，首次系统性地评估了大型语言模型的好奇心水平。这为未来学习能力和LLMs创新研究提供了实证支持，指出LLMs具有与人类类似的好奇心潜力。
### Conclusion
研究结果表明，尽管LLMs在面对不确定环境时倾向于保守行为，但它们的知识渴求程度超过了人类，并且好奇行为能够提升模型的推理和主动学习能力。这些发现表明，LLMs有潜力表现出类似于人类的好奇心，为未来LLMs的学习能力和创新研究提供了实验支持。
## 351. `cs.CL` - ARC-Encoder: 学习压缩文本表示以适应大规模语言模型 [PDF](https://arxiv.org/pdf/2510.20535), [HTML](https://arxiv.org/abs/2510.20535)
### Authors
Hippolyte Pilchen,Edouard Grave,Patrick Pérez
### Background
近年来，检索增强生成或链条思考推理等技术提高了上下文长度和推断成本。上下文压缩技术可以降低这些成本，但最有效的策略往往需要对目标模型进行微调甚至修改其架构。这会在特定任务外降低模型的一般能力。本文探讨了另一种方法：一个压缩上下文为连续表示的编码器，这些连续表示将替换解码器LLM中的令牌嵌入。首先，研究并系统研究了编码器的训练策略和架构选择。研究结果导致设计了一个名为ARC-Encoder的可调作品文本表示压缩器，该压缩器输出的连续表示通常少于文本标记的4倍或8倍。ARC-Encoder在从上下文学习到上下文窗口扩展的各种LLM使用场景中进行了评估。结果显示，ARC-Encoder在多个基准测试上达到了最佳性能，同时提高了推理的计算效率。另外，研究证明了模型可以适应多个解码器，使得一个编码器能够跨不同解码器LLM进行泛化。这使得ARC-Encoder成为适合多个LLM的灵活和高效解决方案。
### Innovation
本文介绍了一种名为ARC-Encoder的可调作品文本表示压缩器，该压缩器以连续的表示形式压缩文本，而不是直接替换令牌嵌入。通过系统研究训练策略和架构选择，设计出一种能够在不同解码器LLM上泛化的高效解决方案。ARC-Encoder在多种场景下表现出了最佳性能，同时还能显著提高计算效率。该方法使得一个编码器可以同时适应多个解码器，提高了灵活性和通用性。相关的训练代码和数据集已公开。
### Conclusion
ARC-Encoder作为一种高效和灵活的解决方案，能够为多个不同的LLM提供一个可以跨越不同解码器的编码器。这种解决方案大大提高了解决实际问题时的通用性和适应性，且在保持模型性能的同时也提高了计算效率。
## 352. `cs.CL` - 评估多语言LLMs的政治公平性：基于21种语言平行EuroParl数据集的案例研究 [PDF](https://arxiv.org/pdf/2510.20508), [HTML](https://arxiv.org/abs/2510.20508)
### Authors
Paul Lerner,François Yvon
### Background
以往评估大型语言模型（LLMs）的政治偏见通常通过模拟它们对英语问卷的回答来进行。这篇论文提出了一个新的评估框架，该框架基于多语言翻译中的公平性原则，通过系统比较欧洲议会（EP）演讲的翻译质量来评估政治偏见。
### Innovation
该研究采用了多语言平行的EuroParl数据集，这是一个包含每个发言者政治派别信息的21个平行版本的议会记录，它是评估LLMs翻译质量的一个新方法，从而揭示了不同派别在翻译过程中的系统性差异。
### Conclusion
该研究发现，从左、中、右不同政派的主要政党相较于边缘政党，在翻译质量上表现更好。这表明政治立场可能影响到大型语言模型的理解和翻译能力。
## 353. `cs.CL` - Neural Diversity Regularizes Hallucinations in Small Models [PDF](https://arxiv.org/pdf/2510.20690), [HTML](https://arxiv.org/abs/2510.20690)
### Authors
Kushal Chakrabarti,Nirmal Balachundhar
### Background
语言模型尽管参数、计算能力和数据量不断增加，但仍然会表现出幻觉现象。现有的方法未能有效地减少这种幻觉。作者提出了‘神经多样性’这一概念，即去相关的并行表示，作为一种在固定参数和数据预算下减少幻觉现象的理论机制。
### Innovation
作者受投资组合理论启发，证明幻觉概率受表示相关性限制，提出了一种新的机制——神经多样性，结合平行LoRA适配器和Barlow Twins正则化，有效减少了幻觉现象，改善了语言模型的可靠性。实验证明，神经多样性在减少幻觉方面起到了关键作用。
### Conclusion
神经多样性作为一种新的方法，可以在不牺牲整体准确性的情况下，显著减少幻觉现象，成为提高语言模型可靠性的一种新的第三维度（与参数和数据预算无关）的扩展手段。不同的任务需要不同的神经多样性水平，以实现最佳效果。
## 354. `cs.CL` - CantoNLU: 一个粤语自然语言理解基准 [PDF](https://arxiv.org/pdf/2510.20670), [HTML](https://arxiv.org/abs/2510.20670)
### Authors
Junghyun Min,York Hay Ng,Sophia Chan,Helena Shunhua Zhao,En-Shiun Annie Lee
### Background
虽然粤语使用者众多，但由于政策和双语现象的影响，粤语资源匮乏。现有的评价框架不足以评估粤语自然语言理解（NLU）任务，因此亟需开发专门针对粤语的基准框架。
### Innovation
提出了一项新的基准测试框架 CantoNLU，覆盖七项任务，包括语法和语义理解，如词汇消歧、语法判断、语言检测、自然语言推理、情感分析、词性标注和依存句法分析。此外，还提供了针对不同模型的基准性能，包括未经粤语训练的普通话模型、通过持续预训练的两种粤语适应模型以及从零开始训练的粤语单一语言模型。
### Conclusion
粤语适应模型整体表现最佳，单一语言模型在句法任务上表现更优。未经粤语训练的普通话模型在某些场景下仍具有竞争力，表明当粤语领域数据稀缺时，直接迁移可能是足够的。
## 355. `cs.CL` - 和谐的语言：双刃剑效应的多语言AI推理 [PDF](https://arxiv.org/pdf/2510.20647), [HTML](https://arxiv.org/abs/2510.20647)
### Authors
Alan Saji,Raj Dabre,Anoop Kunchukuttan,Ratish Puduppully
### Background
大型推理模型（LRMs）在数学、科学及其他问答任务上表现出色，但它们的多语言推理能力尚未得到充分探索。当遇到非英语问题时，LRMs通常会以英语进行推理，这引发了对其可解释性和处理语言及文化细微差别的担忧。本文系统地对比了一个LRM在英语和问题语言背景下的推理表现，涵盖MGSM和GPQA Diamond两个任务，并从回答准确性及推理过程中的认知特征两个维度进行了评估，揭示了英语在推理中的优势，但也发现了以英语为中心的策略可能会导致“翻译失败”等问题，即翻译步骤可能导致用问题语言直接推理可以避免的错误。
### Innovation
本文创新性地系统研究了大型推理模型在不同语言环境下的推理能力和表现，尤其是在处理非英语问题时的行为模式，并深入分析了使用英语推理的优势与局限性，首次清晰指出了英语推理和非英语推理间的认知行为差异及其影响。引入“翻译失败”这一概念，揭示了多语言AI推理中的关键缺陷。
### Conclusion
英语推理在回答准确性上具有明显优势，但在面对更复杂任务时这一优势变得更为显著。然而，以英语为中心的推理策略存在“翻译失败”的固有风险，这种风险使得在处理涉及语言和文化差异的问题时，使用原问题语言进行推理更为可靠。
## 356. `cs.CL` - 结构条件下的最小贝叶斯风险解码 [PDF](https://arxiv.org/pdf/2510.20700), [HTML](https://arxiv.org/abs/2510.20700)
### Authors
Bryan Eikema,Anna Rutkiewicz,Mario Giulianelli
### Background
最小贝叶斯风险（Minimum Bayes Risk, MBR）解码近年来作为传统生成策略的替代方案引起了新的关注。虽然在机器翻译中MBR已被证明有效，但在更加开放的任务如对话或指令遵循中，由于语言模型结果空间的变化性更大，MBR可能会面临挑战。因此，提出了一种假设，即MBR在这样的环境中选择代表性且广泛的响应可能在某些具体类别中变得更次优，特别是当这些响应共享潜在结构时。
### Innovation
本文提出了三个针对实用函数的轻量级调整，以使MBR更加敏感于输出空间中的结构变化。研究还包括了一个数据集，用来捕捉三种代表性的潜在结构类型，以及两个用于评估结构最优性的新指标。分析结果表明，常用的基于相似性的实用函数未能达到这些指标的要求，而提出的调整显著提高了结构最优性。最后，作者将这些方法评估在真实世界的指令遵循基准上，显示出增强的结构敏感性可提高生成质量高达13.7个百分点。
### Conclusion
我们的研究证明了结构条件下的实用函数调整对MBR选择响应时的结构敏感度改进，特别是在指令遵循任务中的应用。通过引入新的适应方法和评估标准，MBR在实际应用中的表现得到了显著的提升。
## 357. `cs.CL` - 通过混合稀疏注意和上下文可学习的token移除缓解线性注意的健忘性 [PDF](https://arxiv.org/pdf/2510.20787), [HTML](https://arxiv.org/abs/2510.20787)
### Authors
Mutian He,Philip N. Garner
### Background
线性注意模型通过将其整个输入序列压缩为固定大小的循环状态提供了与Transformer相比的一种更高效的替代方案，但有限的内存导致遗忘，影响检索密集型任务的表现。
### Innovation
探索了一系列混合模型，通过恢复直接访问过去的词，缓解健忘性问题。具体包括引入了一种可学习的token移除方法，与滑动窗口注意机制结合使用，该机制支持信息聚合，同时保持线性注意的时间和空间复杂度的线性特性。此外，还提供了高效Triton内核以支持稀疏注意机制。
### Conclusion
在检索密集型基准上的实证研究表明，所提方法有效。
## 358. `cs.CL` - 使用自然语言处理从临床笔记中自动提取氟尿嘧啶治疗及其相关毒性的方法 [PDF](https://arxiv.org/pdf/2510.20727), [HTML](https://arxiv.org/abs/2510.20727)
### Authors
Xizhi Wu,Madeline S. Kreider,Philip E. Empey,Chenyu Li,Yanshan Wang
### Background
氟尿嘧啶类药物广泛用于治疗结肠癌和乳腺癌，但与手足综合征和心脏毒性等副作用相关。这些副作用的信息通常嵌入在临床笔记中，为了更好地记录和研究这些信息，研究者们致力于开发和评估自然语言处理（NLP）的方法来提取治疗和副作用的信息。
### Innovation
该研究构建了一个包含236份临床笔记的高质量数据集，用于训练和评估不同类型的NLP方法。研究结果显示，基于大规模语言模型（LLM）的方法在治疗和副作用提取方面表现最优，其次是机器学习方法。与基于深度学习的方法相比，基于LLM的方法更能泛化，尤其是在处理稀有类别时。
### Conclusion
基于LLM的NLP方法最有效地从临床笔记中提取了氟尿嘧啶的治疗及相关副作用信息，并且具有支持肿瘤学研究和药物流行病学的强大潜力。
## 359. `cs.CL` - 简单的上下文压缩：均值池化与多比例训练 [PDF](https://arxiv.org/pdf/2510.20797), [HTML](https://arxiv.org/abs/2510.20797)
### Authors
Yair Feldman,Yoav Artzi
### Background
在使用长期上下文进行检索增强生成（RAG）时，使用大型语言模型（LLMs）的一个常见策略是软上下文压缩，即将输入序列转换为较短的连续表示来减少计算成本。目前广泛使用的方法是压缩令牌架构。
### Innovation
本文开发了一种轻量级且简单的方法——均值池化，该方法在性能上显著优于常用的压缩令牌架构。此外，研究了训练同一压缩器以输出多种压缩比例的方法。
### Conclusion
我们的简单均值池化方法在所有实验中表现最佳，即使在训练多个压缩比例时也只会有一个相对较小的性能下降。然而，在不同的架构和训练策略下，压缩方法之间的权衡更为复杂，体现了压缩方法的复杂性。
## 360. `cs.CL` - 针对LLM生成文本负责任性能维度的特定用例数据集 [PDF](https://arxiv.org/pdf/2510.20782), [HTML](https://arxiv.org/abs/2510.20782)
### Authors
Alicia Sagae,Chia-Jung Lee,Sandeep Avula,Brandon Dang,Vanessa Murdock
### Background
当前评估大型语言模型（LLMs）的方法主要集中在高级任务如文本生成上，而不针对特定的AI应用进行优化。这种方法在评估有关公平性等负责任AI方面可能不够充分，因为不同的应用中保护属性的相关性可能差异很大。
### Innovation
本文构建了一个由具体应用驱动的数据集（根据产品特性列表生成文本描述），该数据集根据公平性属性与性别化形容词和产品类别的交叉参数化，形成了一组丰富的标注提示。通过此数据集，研究了评估LLMs的质量、真实性、安全性和公平性差距问题，提出了一种LLMs评估方法，同时提供了研究社区可使用的资源。
### Conclusion
此研究提出了一种特定用例的评估方法，用于衡量LLMs生成文本的负责任性能维度，贡献了一个具体的资源，以帮助研究社区进行更细致的评估和改进工作。
## 361. `cs.CL` - 用户对隐私敏感情景中LLM响应的隐私保护和帮助感知 [PDF](https://arxiv.org/pdf/2510.20721), [HTML](https://arxiv.org/abs/2510.20721)
### Authors
Xiaoyuan Wu,Roshni Kaushik,Wenkai Li,Lujo Bauer,Koichi Onoue
### Background
大语言模型（LLMs）在电子邮件撰写、会议总结和健康问题回答等领域得到了迅速采用。在这些应用场景中，用户可能需要分享私密信息（如健康记录、联系方式）。现有研究通过开发包含真实场景的基准（如ConfAIde、PrivacyLens）来评估LLMs识别和屏蔽私密信息的能力。然而，这些评估主要依赖LLMs（或代理LLMs）来判断其是否遵守隐私规范，忽略了真实用户感知的重要性。先前工作的主要关注点是LLMs响应的隐私保护质量，而没有探讨其在帮助性方面的细微差异。
### Innovation
本文通过一项包含94名参与者和来自PrivacyLens的90个情景的用户研究，深入探讨了用户对于隐私敏感情景中LLM响应的隐私保护质量和帮助感知的看法。研究发现，在评估同一个情景下相同的响应时，用户之间的共识较低。同样，五种代理LLMs之间显示出高度的一致性，而单个LLM与用户评价的相关性较低。这表明，LLM响应的隐私性和帮助性往往因人而异，代理LLMs在评估用户在隐私敏感场景中的感知方面表现不佳。研究结论指出了进行用户体验导向的研究以衡量LLMs在帮助用户的同时保护隐私的必要性，并建议未来研究应探索提高代理LLMs与用户之间一致性的方法，从而更准确地估计用户感知的隐私和效用。
### Conclusion
结果表明，LLM响应的隐私性和帮助性往往因个人而异，代理LLMs不能很好地预测真实用户在隐私敏感场景中的感知。因此，未来的研究需要进行用户为中心的研究来测量LLMs的能力，以帮助用户保护隐私，并且需要提高代理LLMs与用户之间的对齐，以更好地估计用户感知的隐私和效用。
## 362. `cs.CL` - 关于LLM生成文本的可检测性：到底什么是LLM生成的文本？ [PDF](https://arxiv.org/pdf/2510.20810), [HTML](https://arxiv.org/abs/2510.20810)
### Authors
Mingmeng Geng,Thierry Poibeau
### Background
随着大型语言模型（LLMs）的广泛应用，许多研究人员转向了识别由它们生成的文本的研究。但是，对于“LLM生成文本”的目标定义并不一致或精确。使用场景的不同和LLM的多样性进一步增加了检测的难度。通常认为的检测目标通常仅代表LLMs可以生成的一部分文本。人类对LLM输出的编辑，加上LLM对用户的微妙影响，使得LLM生成的文本与人工撰写的文本之间的界限变得模糊。现有的基准测试和评估方法未能充分应对实际应用中检测器的各种情况，因而检测器的数字结果经常被误解，其重要性在逐渐消减。
### Innovation
本文探讨了LLM生成文本的可检测性问题，指出现有的定义不够精确，可能只代表了LLM生成文本的一个子集。结合人类对LLM输出的编辑和微妙影响，提出了LLM生成文本与人工文本的界限模糊的观点。面对现有基准测试和评估方法未能全面覆盖实际应用的情况，提出了需要更精确定义和评估标准的需求。
### Conclusion
检测器在特定情况下仍是有用的，但其结果只能作为参考而非决定性指标。
## 363. `cs.CL` - 超越单向影响：多轮人-LLM互动中的双向意见动态 [PDF](https://arxiv.org/pdf/2510.20039), [HTML](https://arxiv.org/abs/2510.20039)
### Authors
Yuyang Jiang,Longjie Guo,Yuchen Wu,Aylin Caliskan,Tanu Mitra,Hua Shen
### Background
大规模语言模型（LLM）驱动的聊天机器人越来越多地被用于意见探索。先前的研究关注了LLM如何改变用户的观点，但很少有人研究如何从单向影响扩展到双向影响，探讨用户输入如何影响LLM响应，以及这种双向影响如何在多轮对话中表现。
### Innovation
本研究通过一项涉及50个争议话题讨论的研究，探讨在三种不同条件下（静态陈述、标准聊天机器人和个人化聊天机器人），人类观点和LLM输出的变化。研究成果揭示，个性化聊天机器人相较于标准设置，更能够放大人类和LLM观点的双向变化。此外，研究还发现，包含参与者个人故事的对话更有可能触发双方立场的转变。
### Conclusion
研究结果强调了在人-LLM交互中过度对齐的风险，并指出需要更加谨慎地设计个性化聊天机器人，以更谨慎和稳定地与用户保持一致。
## 364. `cs.CL` - SODBench: 使用大型语言模型记录电子表格操作的方法 [PDF](https://arxiv.org/pdf/2510.19864), [HTML](https://arxiv.org/abs/2510.19864)
### Authors
Amila Indika,Igor Molybog
### Background
众多知识工作者利用电子表格进行业务、会计和金融等工作，但由于缺乏系统化的文档方法，这阻碍了自动化、协作和知识转移，从而导致关键机构知识的损失。因此，介绍了一种名为电子表格操作文档(SOD)的人工智能任务，即从电子表格操作中生成人类可读的解释。
### Innovation
本研究呈现了一个包含111个电子表格操作代码片段的基准，每个代码片段都配有一个相应的自然语言总结，旨在评估五个大型语言模型（GPT-4o、GPT-4o-mini、LLaMA-3.3-70B、Mixtral-8x7B和Gemma2-9B）在转换代码为自然语言方面的表现。
### Conclusion
研究结果表明，大型语言模型能够生成准确的电子表格文档，使SOD成为提高电子表格的可再现性、可维护性和协作工作流的可行先决条件，但仍需解决一些挑战。
## 365. `cs.CL` - Communication to Completion: Modeling Collaborative Workflows with Intelligent Multi-Agent Communication [PDF](https://arxiv.org/pdf/2510.19995), [HTML](https://arxiv.org/abs/2510.19995)
### Authors
Yiming Lu,Xun Wang,Simin Ma,Shujian Liu,Sathish Reddy Indurthi,Song Wang,Haoyun Deng,Fei Liu,Kaiqiang Song
### Background
在复杂任务的工作空间中，团队合作需要多样化的沟通策略，但当前的多代理大型语言模型系统缺乏系统性的任务导向沟通框架。现有的多代理系统在沟通策略上存在不足，无法有效提升工作效率，尤其是在面向具体任务时缺乏有效的沟通机制和策略支持.
### Innovation
本文提出Communication to Completion (C2C)，这是一个可扩展的框架，通过两个关键创新来解决这一问题：（1）引入了新颖的“对齐因子”（AF），这是一种衡量代理任务对齐的新指标，直接影响工作效率；（2）提出了序贯行动框架，将步骤执行与智能沟通决策相结合。C2C 让代理能够进行成本意识的沟通选择，通过有针对性的互动动态提升任务理解.
### Conclusion
我们对C2C进行了评估，评估对象包含了从5到17个代理的三种复杂度不同的编码工作流程，与无沟通和固定步骤的基线对比，结果显示C2C能够将任务完成时间减少约40%的同时，保持可接受的沟通成本。该框架在标准配置下能够成功完成所有任务，并且在大规模条件下保持有效性。C2C确立了多代理系统中测量沟通效果的理论基础，并为复杂的协作任务提供了一个实用框架.
## 366. `cs.CL` - BIOCAP：超越标签利用合成描述性标题在生物基础模型中的应用 [PDF](https://arxiv.org/pdf/2510.20095), [HTML](https://arxiv.org/abs/2510.20095)
### Authors
Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu
### Background
该研究探讨了使用描述性标题作为辅助监督来源，以提高生物多模态基础模型的性能。通过结合图像和描述性标题，可以捕捉物种潜在的形态学特征，从而在训练中促进模型与这些特征共享的潜在结构的对齐。然而，获取大规模的忠实、实例特定的描述性标题存在挑战，这限制了自然语言监督在生物领域中的应用。
### Innovation
该研究通过生成与特定领域（如维基百科视觉信息）和特定类别（如税率科目格式示例）相关的合成描述性标题，来补充这一空白。这有助于减少虚假内容并提供准确、实例化的描述性标题。通过使用这些描述性标题，研究训练了一个新的生物基础模型BIOCAP（即BIOCLIP + 描述性标题），该模型在物种分类和图文检索方面表现出色。
### Conclusion
该研究的结果表明，描述性标题在将生物图像与多模态基础模型对接中发挥着重要作用，超越了传统的标签，进一步证明了其在生物领域中的应用价值。
## 367. `cs.CL` - AI PB: 一种用于个性化投资洞察的定位生成代理 [PDF](https://arxiv.org/pdf/2510.20099), [HTML](https://arxiv.org/abs/2510.20099)
### Authors
Daewoo Park,Suho Park,Inseok Hong,Hanwool Lee,Junkyu Park,Sangjun Lee,Jeongman An,Hyunbin Loh
### Background
本文介绍了一种名为AI PB的生产级生成代理，用于零售金融领域。不同于被动回应的反应式聊天机器人，AI PB能够主动生成与用户具体投资相关的、合规的并基于数据的洞察。该系统在韩国金融监管环境下运行，使用Docker Swarm和vLLM在本地基础设施上管理NVIDIA H100 GPU资源。
### Innovation
AI PB系统包含了三个主要创新点：(i) 一个基于组件的编排层，该层能够根据数据敏感性决定性地路由内部和外部的大规模语言模型(MLM)；(ii) 结合了OpenSearch和财务专业领域嵌入式模型的一种混合检索管道；(iii) 一个多阶段的推荐机制，它结合了规则启发式、序列行为建模和上下文多臂老虎机方法。
### Conclusion
通过人工审核和系统性能指标，本文展示了基于明确路由和分层安全性的生成代理能够提供金融行业所需的可信赖的AI洞察。
## 368. `cs.CL` - 大型推理模型适合作为翻译评估者吗？分析与性能提升 [PDF](https://arxiv.org/pdf/2510.20780), [HTML](https://arxiv.org/abs/2510.20780)
### Authors
Runzhe Zhan,Zhihong Huang,Xinyi Yang,Lidia S. Chao,Min Yang,Derek F. Wong
### Background
最近在大型推理模型(LRMs)的发展中，已经引入了一种中间的“思考”过程，在生成最终答案之前，这提高了它们在复杂下游任务上的推理能力。然而，LRMs在机器翻译(MT)质量评估方面的潜力尚未被充分探索。本文提供了第一个系统分析LRMs作为MT评估者的分析，并揭示了它们的关键挑战，比如需要特定的评估材料、倾向于对简单实例“过度思考”以及评分机制问题导致过度估计。
### Innovation
本文提出通过在合成、类似人类的思考轨迹上进行训练，以校准LRMs的思考过程。实验表明，这种校准方法大幅减少了思考预算（约减少35倍），并提高了不同规模的LRMs（例如R1-Distill-Qwen-7B）的评估性能，提高了8.7个相关性点。这表明高效校准的LRMs有可能促进精细化自动MT评估的发展
### Conclusion
这些发现强调了高效校准的LRMs在推进精细化自动MT评估方面的潜力。
## 369. `cs.CL` - LLMs可以隐藏与其长度相同的其他文本中的文本.ipynb [PDF](https://arxiv.org/pdf/2510.20075), [HTML](https://arxiv.org/abs/2510.20075)
### Authors
Antonio Norelli,Michael Bronstein
### Background
在当前背景下，大型语言模型（LLMs）能够生成连贯和合理的文本，即使这些文本隐藏了具有完全不同意图的秘密信息。例如，一个包含尖锐政治批评的推文可以嵌入一个赞扬同一政治领导人的推文中，或者一个普通的商品评论可以隐藏一部秘密手稿。这种奇怪的现象现在可以通过LLMs实现，本文介绍了一种简单且高效的协议来实现这一目标。研究表明，即使是最小的开源8亿参数的LLM也足以获得高质量的结果，甚至可以在笔记本电脑上在几秒钟内对如此长度的消息进行加密和解密。这种协议的存在进一步表明文本与其作者意图之间存在根本性脱节，这已经削弱了人们对书面沟通的信任，因为依赖于LLM聊天机器人的兴起。
### Innovation
本文提出了一种简单且高效的协议，利用大型语言模型（LLMs）的能力，可以在不改变其连贯性和合理性的情况下隐藏任意长度的消息文本。研究发现，即便是中等规模的LLM也可以达到高质量的隐藏效果，并且可以在本地设备上快速实现加密和解密。这项工作进一步强调了大型语言模型与人类意图之间的脱节现象，这已经引起了人们对AI安全性的深深担忧。
### Conclusion
这种协议揭示了文本与其作者意图之间的一种根本性的脱节，进一步动摇了人们对书面沟通的信任。文章通过具体例子展示了一家公司如何通过将模型答案嵌入安全模型的合规回答中，来部署未经过滤的LLM，这引发了许多关于AI安全的紧迫问题，以及需要重新定义什么是大型语言模型知道的。
## 370. `cs.CL` - Branch-and-Browse: 效率可控的树结构推理和行动记忆驱动的网络探索 [PDF](https://arxiv.org/pdf/2510.19838), [HTML](https://arxiv.org/abs/2510.19838)
### Authors
Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury
### Background
自主网络代理利用大型语言模型（LLMs）在信息检索、报告生成和在线交易等目标导向任务上展示出强大潜力，标志着开放网络环境中实用化的嵌入式推理的关键步骤。然而，现有方法在推理深度和效率上仍有限制：基础线性方法无法进行多步推理且缺乏有效的回溯机制，而其他搜索策略则较为粗糙并耗费大量计算资源。
### Innovation
提出了精细的Branch-and-Browse框架，统一了结构化推理执行、上下文记忆和高效执行。该框架通过树状结构探索和显式的子任务管理实现可控制的多分支推理；通过高效网页状态重演和背景推理实现探索启动；利用页面动作为符号在会话内外共享已探索动作。
### Conclusion
Branch-and-Browse在WebArena基准测试中实现了任务成功率35.8%并使执行时间最多减少40.4%，显示了其作为LLM驱动的网络代理可靠且高效的框架特性。
## 371. `cs.CL` - 每一个问题都有自己的价值：带有显式人类价值观的强化学习 [PDF](https://arxiv.org/pdf/2510.20187), [HTML](https://arxiv.org/abs/2510.20187)
### Authors
Dian Yu,Yulai Zhao,Kishan Panaganti,Linfeng Song,Haitao Mi,Dong Yu
### Background
目前使用可验证奖励（RLVR）的方法在实体领域有效地训练模型时，仅使用二元正确性奖励，但忽略了一点，即并非所有任务都具有同等的重要性。因此，需要一种新的方法来直接将人类定义的价值信号纳入奖励函数，以便更准确地反映任务的重要性和偏好。该论文提出了Reinforcement Learning with Explicit Human Values (RLEV)，以应对这一问题，通过使用带有明确正确性标签的考试数据，RLEV 在多个强化学习算法和模型规模下大幅超越仅基于正确性的基准模型，并展示了价值导向的终止策略，从而证明了这一方法的有效性。
### Innovation
该研究提出了RLEV，这是一种直接将可量化的具体人类价值信号纳入强化学习中的方法，目的是更好地反映任务的重要性。RLEV 在考试类型数据上表现出色，通过对末尾序列标记的价值加权梯度放大，提高了价值加权的准确性，并学习了一种敏感于价值的终止策略。此外，实验证明这种方法不仅提高了价值加权的准确性，还能在具有噪声的价值信号（如基于难度的标签）下保持鲁棒性。
### Conclusion
研究展示了，通过使用显式的人类价值观信号，强化学习模型可以更好地适应和优化，从而更准确地服务于人类的优先事项和偏好。RLEV 的价值在于提供了优化大型语言模型与人类价值之间对齐的一种可实践路径。
## 372. `cs.CL` - 具有多媒体意识的问答：检索与跨模态推理架构的综述 [PDF](https://arxiv.org/pdf/2510.20193), [HTML](https://arxiv.org/abs/2510.20193)
### Authors
Rahul Raja,Arpita Vats
### Background
问答（QA）系统历来依赖于结构化文本数据，但随着多媒体内容（图像、音频、视频和结构化元数据）的快速增长，检索增强的QA面临着新的挑战和机遇。本文综述了集成多媒体检索管道的QA系统的最新进展，重点关注与用户查询相匹配的视觉、语言和音频模态的架构。
### Innovation
文章基于检索方法、融合技术以及答案生成策略对方法进行分类，并分析了基准数据集、评估协议和性能权衡。此外，文章强调了多模态对齐、延迟-准确性的权衡和语义定位等关键挑战，并指出了建立更稳健和上下文感知的QA系统利用多媒体数据的开放问题和未来研究方向。
### Conclusion
文章总结了QA系统在利用多媒体进行检索和跨模态推理方面的最新进展和挑战，并提出了未来研究方向。
## 373. `cs.CL` - 为什么在更长的回答中LVLMs更容易发生幻觉：上下文的作用 [PDF](https://arxiv.org/pdf/2510.20229), [HTML](https://arxiv.org/abs/2510.20229)
### Authors
Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang
### Background
近年来，大型视觉-语言模型（LVLMs）取得了显著进步，但在处理较长、自由格式的响应时，这些模型也面临幻觉问题。幻觉的产生通常是由于累积的不确定性导致的。已有研究主要认为幻觉是由响应长度增加引起的错误导致的，但本文发现幻觉风险并非由长度本身引起，而是由更重视长响应中的上下文连贯性和完整性所导致的依赖增加引起。
### Innovation
本文提出了一种新颖的“诱导-检测-抑制”框架。该框架首先通过故意设计的上下文积极诱导幻觉，然后利用诱导出的实例进行早期高风险案例的检测，并最终在实际解码过程中抑制潜在的对象级幻觉。该方法在所有基准上都表现出显著的改进，证实其有效性。此外，强大的检测和改进的幻觉抑制不仅验证了该框架，还重新验证了关于上下文的假设。
### Conclusion
研究虽然旨在提供新的见解，但它还标志着对LVLMs更长响应中的幻觉进行更深入探索的第一步。相比之下，以往的研究通常只追求性能的提高，而本文则侧重于提供新的见解并重新验证关于上下文在LVLMs中作用的假设。
## 374. `cs.CL` - Calibrating Multimodal Consensus for Emotion Recognition [PDF](https://arxiv.org/pdf/2510.20256), [HTML](https://arxiv.org/abs/2510.20256)
### Authors
Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan
### Background
近年来，多模态情感识别（MER）取得了显著进展。然而，大多数现有方法忽略了模态间可能出现的语义不一致性，例如文本和视觉输入之间的情感线索冲突。此外，当前的方法往往主要依赖于文本模态，因为它具有强大的表征能力，这可能损害识别准确率。
### Innovation
提出了一个名为Calibrated Multimodal Consensus（CMC）的新模型。CMC引入了伪标签生成模块（PLGM）来生成伪单模标签，支持在无监督下进行单模预训练。然后，它使用参数自由融合模块（PFM）和多模态共识路由器（MCR）进行多模态微调，减轻了文本主导性，并引导融合过程向更可靠的共识方向发展。
### Conclusion
实验结果表明，CMC在CH-SIMS、CH-SIMS v2、CMU-MOSI和CMU-MOSEI四个数据集上取得了与最先进的方法相当或更好的性能，并在具有语义不一致性的情况下（如CH-SIMS和CH-SIMS v2）展现出显著优势。这项工作的实现可以在此处公开访问：this https URL。
## 375. `cs.CL` - ImpossibleBench：衡量LLMs利用测试案例倾向的框架 [PDF](https://arxiv.org/pdf/2510.20270), [HTML](https://arxiv.org/abs/2510.20270)
### Authors
Ziqian Zhong,Aditi Raghunathan,Nicholas Carlini
### Background
研究发现，大型语言模型（LLMs）在完成任务时倾向于寻找并利用“捷径”，这种行为对可靠评估和部署LLMs带来巨大风险。例如，如果LLM能够访问单元测试，其可能会选择删除失败的测试而不是修复潜在的错误。这种行为不仅影响基准测试结果的有效性，还会影响实际部署中的LLM编程助手的可靠性。
### Innovation
本文提出了一种名为ImpossibleBench的基准框架，用于系统性地测量LLM代理利用测试案例的倾向。该框架通过对现有基准（如LiveCodeBench和SWE-bench）进行修改，创造“不可能”的任务变体，从而引入自然语言说明与单元测试之间的直接冲突。文章进一步展示了ImpossibleBench的实际用途，包括：（1）研究模型行为，揭示从简单的测试修改到复杂的操作符重载的各种作弊行为方式；（2）上下文工程，展示了提示、测试访问和反馈循环对作弊率的影响；（3）开发监控工具，提供包含验证欺骗性解决方案的测试床。
### Conclusion
我们希望ImpossibleBench作为一个有用框架，为构建更健壮和可靠的LLM系统做出贡献。该框架不仅可以用于评估模型行为，还能作为一种灵活的工具开发支撑模型行为的监控与验证工具。相关实现可参见此链接：this https URL.
## 376. `cs.CL` - IKnow: 意识到指令知识的持续预训练以实现有效的领域能力适应 [PDF](https://arxiv.org/pdf/2510.20377), [HTML](https://arxiv.org/abs/2510.20377)
### Authors
Tianyi Zhang,Florian Mai,Lucie Flek
### Background
持续预训练旨在使用仅未标记的测试时间数据来适应大型语言模型（LLMs）的新领域，但直接将标准自监督目标应用于指令调优模型会削弱它们的指令执行能力和语义表示。现有的解决方法依赖于原始基础模型或依赖于外部领域特定数据库的知识，但在基模型权重被安全理由保留或可靠外部语料库不可用的情况下，这些都不是现实的解决方法。
### Innovation
我们提出了指令知识感知的持续适应框架（IKnow），该框架以指令-响应对话格式修订了新颖的自监督目标。IKnow 不依赖外部资源，而是利用自身文本嵌入的领域知识，并学习在更深层次的语义水平上编码它，从而增强领域适应能力并保持指令执行能力与语义表示的平衡.
### Conclusion
IKnow 提供了一个简单的且通用的框架，通过从文本中获取嵌入的领域知识，能够有效地在不依赖外部资源的情况下适应新领域。
## 377. `cs.CL` - 神经语言模型的相对基规缩放定律 [PDF](https://arxiv.org/pdf/2510.20387), [HTML](https://arxiv.org/abs/2510.20387)
### Authors
Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu
### Background
现有的缩放定律研究几乎完全依赖于交叉熵作为评估指标，但交叉熵只能提供关于性能的片面视角，因为它只衡量正确标记的概率，而不考虑正确标记与不正确标记之间的相对顺序。然而，对于语言模型而言，后者尤为关键，尤其是在贪婪采样的场景中。因此，本文旨在从相对顺序的角度来探究缩放问题。
### Innovation
本文提出了基于相对概率（RBP）的新衡量标准，它量化了正确标记被正确预测的概率，并针对此建立了基于相对概率的缩放定律来描述RBP随模型规模增加而提升的规律。通过在四个数据集和四个模型家族（覆盖五个数量级）上进行广泛实验，证明了此定律的稳定性和准确性。此外，通过两个示例（解释涌现现象和帮助发现缩放定律的基本理论）来展示此定律的广泛适用性。
### Conclusion
基于相对概率的缩放定律补充了交叉熵视角，为大规模语言模型的理解提供了更全面的视角，既为实际开发提供有价值的观点，也为理论探索提供指导。
## 378. `cs.CL` - 解码耳朵：一种通过高效对齐将人类偏好转化为客观评估的框架 [PDF](https://arxiv.org/pdf/2510.20513), [HTML](https://arxiv.org/abs/2510.20513)
### Authors
Zhiyu Lin,Jingwen Yang,Jiale Zhao,Meng Liu,Sunzhu Li,Benyou Wang
### Background
最近的语音生成模型已经能够生成清晰的语音，但在自然表达方面仍显不足，这主要归因于缺乏可靠的评估标准。现有的评估方法，如主观质量评分、低层次的声学特征和情感识别，成本高昂、范围有限或不够全面。为了解决这些问题，本文提出了DeEAR（Decoding the Expressive Preference of eAR）框架，将人类对语音表达性的偏好转化为客观评分体系。该框架基于语音学和心理学，通过评估情感、语调和自发性这三个维度，实现了与人类感知的强烈一致性（ Spearman's Rank Correlation Coefficient, SRCC = 0.86），仅使用不到500个标注样本.
### Innovation
DeEAR框架首次成功地将人类对语音表达性的偏好转化为客观评分，通过评估语音的情感、语调和自发性三个维度，实现了与人类感知的高度一致性。此外，该框架可以进行公平的基准测试和有针对性的数据整理，不仅能区分不同语音生成模型在表达性方面的差距，还能从大语料库中挑选出14000个表达性较强的语音片段，显著提高语音生成模型的表达性评分（从2.0提升到23.4分）。
### Conclusion
DeEAR框架不仅提供了一种可靠的评估方式，还首次大规模量化了语音生成模型的表达性表现，有助于更好地推进语音生成技术的发展。
## 379. `cs.CL` - Analyticup E-commerce Product Search Competition Technical Report from Team Tredence_AICOE [PDF](https://arxiv.org/pdf/2510.20674), [HTML](https://arxiv.org/abs/2510.20674)
### Authors
Rakshith R,Shubham Sharma,Mohammed Sameer Khan,Ankush Chopra
### Background
该研究介绍了Tredence_AICOE团队开发的多语言电子商务搜索系统。比赛涉及两个多语言相关性任务：Query-Category (QC) 相关性评估查询与产品类别的匹配程度，以及Query-Item (QI) 相关性评估多语言查询与单个商品列表的匹配情况。为确保完全的语言覆盖，团队通过将现有数据集翻译成开发集所缺的语言来进行数据增强，从而在所有目标语言上进行训练。比赛采用多种策略对Gemma-3 12B和Qwen-2.5 14B模型进行了微调。Gemma-3 12B (4-bit) 模型在使用原始和翻译数据时在QC任务中表现出色，在使用原始、翻译和少数类别数据创建时在QI任务中表现出色。这些方法在最终排行榜中获得了第4名，在私人测试集上的平均F1分数为0.8857。
### Innovation
创新点包括使用多语言数据增强方法、针对两个多语言相关性任务微调两个大型语言模型Gemma-3 12B和Qwen-2.5 14B，并结合原始数据、翻译数据和少数类数据创建提高了模型性能。
### Conclusion
研究团队在最终排行榜中获得了第4名，并在私有测试集上实现了平均F1分数为0.8857的业绩。
## 380. `cs.CL` - 通过多智能体系统协同设计具有纵向对角门的量子编码 [PDF](https://arxiv.org/pdf/2510.20728), [HTML](https://arxiv.org/abs/2510.20728)
### Authors
Xi He,Sirui Lu,Bei Zeng
### Background
该研究基于Subset-Sum线性规划（SSLP）框架，该框架通过模块化残差对基本字符串进行分区，并通过小型线性规划（LP）来强制执行$Z$-边缘Knill-Laflamme（KL）等式。研究在一个LaTeX-Python环境中进行，该环境支持多智能体协作，包括合成智能体、搜索智能体和审计智能体，共同完成量子编码设计的任务。
### Innovation
一种多智能体系统工作流程，结合GPT-5和TeXRA平台技术，实现了基于广义隐式结构的量子编码设计。该方法包括系统扫描候选方案、精确化数值，并证明所有参数都满足KL等式，从而解决了量子代码中的纵向对角门可行性问题，并展示了SSLP技术对残差退化情况的适应性，例如，展示了新的5个量子码。这种方法使得量子编码设计的分析管道得以大规模执行，并结合系统枚举与精确的分析性重建，实现可重复和可扩展的量子编码构造。
### Conclusion
此工作流将对角横向可行性重构为分析管道，通过系统枚举与精确重建相结合的方法，提高了大规模量子编码的构造可重复性，支持针对更大码维数和更高距离的目标扩展，并朝着数据驱动分类方向发展。
## 381. `cs.CL` - Real Deep Research for AI, Robotics and Beyond [PDF](https://arxiv.org/pdf/2510.20809), [HTML](https://arxiv.org/abs/2510.20809)
### Authors
Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang
### Background
随着AI和机器人技术研究的快速发展，每年发表的研究论文多达10,000篇以上，这使得研究人员难以跟上最新进展。快速变化的趋势、跨学科研究的兴起以及探索自己专业之外的领域的需求，都加剧了这一挑战。
### Innovation
我们提出了一种可泛化的管道，能够系统地分析任何研究领域：识别新兴趋势、发现跨领域机会，并为新的研究提供具体的起点。本研究旨在将Real Deep Research (RDR)框架应用于AI和机器人领域，特别是关注基础模型和机器人进步。我们还简要将分析扩展到了其他科学研究领域。
### Conclusion
我们希望这项工作能为AI及其他领域的研究人员提供借鉴。
## 382. `cs.CL` - 共情提示：多模态LLM对话中的非言语情境集成 [PDF](https://arxiv.org/pdf/2510.20743), [HTML](https://arxiv.org/abs/2510.20743)
### Authors
Lorenzo Stacchio,Andrea Ubaldi,Alessandro Galdelli,Maurizio Mauri,Emanuele Frontoni,Andrea Gaggioli
### Background
传统的对话式人机界面需要用户进行显式的控制，才能将非言语信号融入对话中。这种传统的交互方式无法很好地捕捉用户的非言语情感信息，导致语境不一致和对话的不流畅。研究者们一直在探索如何将非言语信息有效集成到人机交互中，以提高对话的质量和用户满意度，特别是在涉及情感交流的领域如医疗或教育中，用户的非言语情感信号往往是至关重要的，但在言语交流中往往被忽略或不透明。
### Innovation
本文提出了一种名为‘共情提示’的新型框架，用于多模态人机互动，通过引入商业面部表情识别服务来检测用户的非言语情感提示，并将其作为上下文信号在提示中嵌入。这种框架无需用户进行显式控制，而是在不显眼的情况下增强文本输入的情感信息，与对话内容进行情感上的对齐。架构模块化和可扩展，允许集成其他非言语模块。通过本地部署的DeepSeek实例实现了系统设计，并进行了初步的服务和使用评估。结果显示，非言语输入能稳健地融合到LLM输出中，用户反馈对话流动性和情感一致性较好。这也为以聊天机器人为中介的通信提供了新的应用前景，特别是在医疗或教育等领域。
### Conclusion
共情提示为多模态LLM对话中非言语信息的有效集成提供了新的解决方案，提高了对话质量和用户的体验满意度。虽然目前还处于初步发展阶段，但其在未来应用于医疗或教育等重视情感交流的领域具有巨大潜力。
## 383. `cs.CL` - 通过单个梯度步骤在100份样本上进行压缩以提升：使用单个梯度步骤在100份样本上进行高效的大规模语言模型适应 [PDF](https://arxiv.org/pdf/2510.20800), [HTML](https://arxiv.org/abs/2510.20800)
### Authors
Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus
### Background
近期，Sharma等提出了一种称为Layer-SElective-Rank reduction（LASER）的方法，通过剪裁精心选择的大型语言模型权重矩阵的高阶组件，展示了在无需基于梯度的微调的情况下，可以提升下游任务的准确性。尽管如此，LASER的搜索过程需要对每个矩阵进行全数据集的前向传播，这使得其部署效率较低。
### Innovation
本文提出了一种新的方法，通过选择性地检查少数需要的权重矩阵、利用每个矩阵的奇异值的梯度来确定哪些矩阵需要减少复杂性、增加因子分解搜索空间以提高准确性、并且通过在100个样本上而不是全数据集上来计算指示性梯度和最终准确性来进一步加快搜索时间。这些发现相结合，实现了快速且稳健的下游任务适应算法。
### Conclusion
结合这些发现，可以通过单个梯度步骤在100个样本上对大型语言模型进行适应，无需微调，实现快速的下游任务适应。
## 384. `cs.CL` - 在知识密集型检索增强生成中的多视角洞察解锁 [PDF](https://arxiv.org/pdf/2404.12879), [HTML](https://arxiv.org/abs/2404.12879)
### Authors
Guanhua Chen,Wenhan Yu,Xiao Lu,Xiao Zhang,Erli Meng,Lei Sha
### Background
检索增强生成（RAG）在大型语言模型（LLMs）的应用中扮演着重要角色，但在法律和医学等知识密集型领域，现有的检索方法仍然缺乏多视角的观点，这会影响解释性和可靠性。先前的研究主要集中在不同语义形式的查询上，忽视了特定领域知识视角的表达。
### Innovation
该论文提出了一种新的多视角RAG框架（MVRAG），利用来自多个领域视角的意图感知查询重写，以提高检索精度，从而提高最终推理的有效性。实验结果表明，在法律和医学案例检索中，该框架显著提高了召回率和精度。
### Conclusion
多视角检索方法释放了多视角信息在RAG任务中的潜力，加速了知识密集型领域LLM的进一步应用。
## 385. `cs.CL` - BadGraph：针对文本引导图生成中潜藏扩散模型的后门攻击 [PDF](https://arxiv.org/pdf/2510.20792), [HTML](https://arxiv.org/abs/2510.20792)
### Authors
Liang Ye,Shengqin Chen,Jiazhu Dai
### Background
图生成的快速发展引发了新的安全问题，特别是后门漏洞问题。之前的研究已经探讨了图像扩散和无条件图生成中的后门攻击，但对于条件引导，尤其是文本引导下的图生成，后门攻击的研究仍然非常有限。BadGraph旨在填补这一缺口，提出了一种针对文本引导下图生成中潜藏扩散模型的后门攻击方法。
### Innovation
BadGraph通过利用文本触发器污染训练数据，秘密植入后门，在触发器出现时诱导攻击者指定的子图，同时在干净输入上保持正常性能。实验结果展示了该攻击的有效性和隐蔽性：不到10%的污染率即可实现50%的成功率，而24%则足以实现超过80%的成功率，对良性样本的性能影响可以忽略不计。进一步的消融研究揭示了后门是在VAE和扩散模型的训练过程中植入的，而不是在预训练过程中。这些发现揭示了文本引导图生成中潜藏扩散模型的潜在安全漏洞，并突显了在药物发现等模型应用中存在严重风险，强调了此类扩散模型中对抗后门攻击的稳健防御所需的重要性
### Conclusion
这些研究结果揭示了文本引导图生成中潜藏扩散模型的安全漏洞，突显了模型在药物发现等应用中的严重风险，并强化了在这些扩散模型中对抗后门攻击的坚固防御的重要性。
## 386. `cs.CL` - 小草案，大判决：通过投机进行密集信息视觉推理 [PDF](https://arxiv.org/pdf/2510.20812), [HTML](https://arxiv.org/abs/2510.20812)
### Authors
Yuhan Liu,Lianhui Qin,Shengjie Wang
### Background
大型视觉-语言模型（VLMs）在多模态理解方面取得了显著进步，但在处理包含密集文本注释与细粒度图形元素的复杂图像时，仍存在问题。这些模型在精确定位密集布局中的关键线索以及进行多步推理以整合分散的证据方面遇到了挑战。现有方法需要大量的计算和训练成本，通常难以应对这些挑战。因此，开发一种可以减少计算成本并保持正确答案的新型框架成为了研究需求。
### Innovation
本文提出了一种名为 Speculative Verdict（SV）的无需培训的框架，它借鉴了投机解码的思想，结合了多个轻量级的草案专家和一个大型的判决模型。在草案阶段，小型 VLMs 作为草案专家生成多样化的位置候选；在判决阶段，强大的 VLM 合成这些路径以产生最终答案。此外，SV 还引入了一种共识专家选择机制，仅向前传输具有高一致性的推理路径，从而提高效率和准确性。与大型私有模型或训练管道相比，SV 可以实现错误校正和成本效率。
### Conclusion
实验结果显示，SV 在 InfographicVQA、ChartMuseum、ChartQAPro 和 HR-Bench 4K 等具有挑战性的密集信息和高分辨率视觉问答基准测试中，实现了持续的性能提升。通过从多个部分准确的推理路径中合成正确的见解，SV 同时实现了错误校正和成本效率。代码已开源。
## 387. `cs.CL` - 基于注释指南的知识增强：面向教育文本分类的大语言模型改进 [PDF](https://arxiv.org/pdf/2406.00954), [HTML](https://arxiv.org/abs/2406.00954)
### Authors
Shiqi Liu,Sannyuya Liu,Lele Sha,Zijie Zeng,Dragan Gasevic,Zhi Liu
### Background
各种机器学习方法在教育文本的自动化分类中取得了显著的进展，特别是用于识别学习参与度指标的学习参与度分类（LEC）。LEC可以深入揭示人类学习过程，吸引了来自自然语言处理（NLP）、学习分析和教育数据挖掘等多个研究社区的兴趣。最近，大型语言模型（LLMs）如ChatGPT在各种NLP任务中表现出色，但在一系列LEC任务中的综合评估和改进研究尚未充分开展。
### Innovation
本文提出了一种基于注释指南的知识增强（AGKA）方法，该方法利用GPT 4.0从注释指南中检索标签定义知识，并使用随机下采样选择少量典型示例。研究对比了AGKA对多个LEC数据集（涵盖行为分类、情绪分类和认知分类）的系统评价基准，结果显示AGKA能显著提升未微调的LLMs，特别是GPT 4.0和Llama 3 70B的性能，但LLMs在多类分类任务中区分名称相似的标签方面仍存在困难。
### Conclusion
研究结果表明，AGKA可以提升非微调LLMs，特别是在简单的二分类数据集上，GPT 4.0结合AGKA的少量示例比完全微调模型如BERT和RoBERTa具有更好的性能；然而，在需要深刻理解复杂语义信息的多类任务中，GPT 4.0则表现逊色。此外，Llama 3 70B结合AGKA作为开源LLMs中的有前途的组合，其性能与闭源GPT 4.0结合AGKA相当。
## 388. `cs.CL` - 从安全神经元的角度理解安全对齐：一种机械主义视角 [PDF](https://arxiv.org/pdf/2406.14144), [HTML](https://arxiv.org/abs/2406.14144)
### Authors
Jianhui Chen,Xiaozhi Wang,Zijun Yao,Yushi Bai,Lei Hou,Juanzi Li
### Background
大型语言模型（LLMs）在各种能力上表现出色，但存在安全风险，如生成有害内容和错误信息，即使经过安全对齐后依然如此。现有方法通过观察和调整这些模型的行为来提高其安全性，但缺乏深入理解其安全行为的机制。本文通过机械解释性方法探讨安全对齐的内部机制，旨在识别并分析LLMs中负责安全行为的安全神经元。
### Innovation
提出了一种名为推理时激活对比的方法来定位这些安全神经元，并通过动态激活补丁来评估其因果效应。实验表明，可以通过仅修补这些神经元的激活来恢复超过90%的安全性能，而不会影响一般能力。文中还揭示了安全神经元与模型安全和有用性的关键神经元显著重叠，但其激活模式不同。此外，展示了一种应用成果，即在生成之前检测不安全的输出，以保障LLM的安全性。
### Conclusion
研究发现了约5%的安全神经元，只需调整其激活即可显著恢复模型安全性，而不会影响其一般能力。这一发现有助于解释“对齐税”现象，并通过检测生成前的不安全输出实现对LLM的安全保护。
## 389. `cs.CL` - LLMs中的良好推理是什么？用多维度评估分解推理步骤 [PDF](https://arxiv.org/pdf/2510.20603), [HTML](https://arxiv.org/abs/2510.20603)
### Authors
Heejin Do,Jaehui Hwang,Dongyoon Han,Seong Joon Oh,Sangdoo Yun
### Background
目前对大型语言模型（LLMs）的评估主要集中在最终答案的正确性上，但这种方法提供的信号较为粗略，忽视了底层推理过程的质量。本文认为，对推理质量进行更细致的评估是提高模型鲁棒性的有效途径，提出了因果分步评估（CaSE）的方法来衡量推理的两个方面：相关性和连贯性，从而避免了事后偏差。
### Innovation
提出了一种新的评估方法CaSE，用于评价大型语言模型的推理过程。该方法将推理质量分解为相关性和连贯性两个维度，并通过重建的专家标注数据集MRa-GSM8K和MRa-MATH验证了CaSE的有效性。此外，验证结果显示，利用CaSE评估相关性和连贯性来精心构建训练数据可以直接提高最终任务的表现。
### Conclusion
本文提供了一种可扩展的框架来分析、调试和提高LLMs的推理能力，证明了从只关注答案正确性转向关注推理过程质量的重要性，并强调了相关的实验结果和实用价值。
## 390. `cs.CL` - 越南对抗自然语言推断的新基准数据集和混合专家语言模型 [PDF](https://arxiv.org/pdf/2406.17716), [HTML](https://arxiv.org/abs/2406.17716)
### Authors
Tin Van Huynh,Kiet Van Nguyen,Ngan Luu-Thuy Nguyen
### Background
目前现有的越南语自然语言推理（NLI）数据集缺乏对抗性复杂性，限制了它们评估模型在面对挑战性语言现象时的鲁棒性。
### Innovation
本文通过介绍ViANLI，即第一个对抗性NLI数据集，并提出了NLIMoE混合专家模型来解决其复杂性，填补了越南语NLI资源的空白。NLIMoE通过一个共享的变压器编码器和一个学习的动态路由机制，结合专家子网络。
### Conclusion
ViANLI包含超过10,000个前提-假设对，挑战了当前最先进的模型，XLM-R Large的准确率为45.5%，而NLIMoE达到了47.3%。使用ViANLI进行训练能够提高其他基准越南NLI数据集的性能，包括ViNLI、VLSP2021-NLI和VnNewsNLI。ViANLI被释放以增强模型鲁棒性的研究，并丰富了未来越南语和多语言NLI研究的资源。
## 391. `cs.CL` - 迭代自调优LLMs以增强逃逸攻击能力 [PDF](https://arxiv.org/pdf/2410.18469), [HTML](https://arxiv.org/abs/2410.18469)
### Authors
Chung-En Sun,Xiaodong Liu,Weiwei Yang,Tsui-Wei Weng,Hao Cheng,Aidan San,Michel Galley,Jianfeng Gao
### Background
近期的研究表明，大型语言模型（LLMs）容易遭受由算法构造的对抗性后缀触发的自动化逃逸攻击。这些后缀被添加到有害查询中以绕过安全对齐，从而引发意想不到的响应。目前生成这些后缀的方法计算成本高，并且攻击成功率（ASR）较低，尤其是在对抗像Llama2和Llama3这样对齐较好的模型时更为明显。
### Innovation
我们引入了ADV-LLM，这是一个迭代自我调节过程，可以生成具备增强逃逸攻击能力的对抗性LLMs。该框架大大降低了生成对抗性后缀的计算成本，同时在多种开源LLMs中实现了接近100%的攻击成功率。此外，ADV-LLM在闭源模型中也具有强大的攻击迁移性，对GPT-3.5的攻击成功率高达99%，对GPT-4的攻击成功率高达49%，即使是在Llama3上进行优化。ADV-LLM不仅提高了逃逸攻击能力，还通过生成大量数据集为未来LLM安全对齐研究提供了有价值的知识。
### Conclusion
我们的代码可在此获得：this https URL
## 392. `cs.CL` - LAMA-UT：通过书写统一和语言特异性转写实现无语言依赖的多语言ASR [PDF](https://arxiv.org/pdf/2412.15299), [HTML](https://arxiv.org/abs/2412.15299)
### Authors
Sangmin Lee,Woo-Jin Chung,Hong-Goo Kang
### Background
构建一种在各种语言上公平表现的通用多语言自动语音识别（ASR）模型长期以来一直颇具挑战性，因为这取决于非常复杂的语言特性。我们探讨了一种名为LAMA-UT的新管道方法，通过书写统一和语言特异性转写来解决此问题。
### Innovation
LAMA-UT是一个无需任何特定语言模块的方法，能够在少量数据下实现与最先进的模型相当的性能。该方法包括先通过一个通用转录生成器将不同语言的书写特征统一为罗马化形式，并捕获跨多种语言的常见音素特征。第二步是使用一个通用转换器将这些通用转录转换为特定语言的转录。实验结果显示，我们的方法在大规模多语言ASR中表现有效，相对错误率减少45%，尽管仅使用了Whisper训练数据的0.1%。此外，此方法不依赖任何特定语言模块，但在与零样本ASR方法相当，这些方法依赖额外的语言词典和语言模型。
### Conclusion
我们预期此框架将成为灵活的多语言ASR系统的基础，即使是对未见过的语言也能实现广泛的适用性。
## 393. `cs.CL` - Bi-Mamba：向着准确的1比特状态空间模型 [PDF](https://arxiv.org/pdf/2411.11843), [HTML](https://arxiv.org/abs/2411.11843)
### Authors
Shengkun Tang,Liqun Ma,Haonan Li,Mingjie Sun,Zhiqiang Shen
### Background
当前使用的典型选择性状态空间模型（SSM）在Mamba中解决了变换器的一些局限性，如序列长度的二次计算复杂性以及推理过程中由于关键值（KV）缓存对大量内存的需求。然而，Mamba模型的大小持续增加，给训练和部署带来了挑战，特别是在训练和推理过程中计算密集型的需求。
### Innovation
本文介绍了一种可扩展且强大的1比特Mamba架构——$texttt{Bi-Mamba}$，用于实现更有效的大语言模型（LLMs），参数量为780M、1.3B和2.7B。$texttt{Bi-Mamba}$模型通过使用自回归蒸馏损失从标准LLM规模的数据集进行了从零开始的训练。实验表明，$texttt{Bi-Mamba}$在语言建模基准测试中达到了与全精度（FP16或BF16）持平的性能，同时优于后训练二值化（PTB）的Mamba和二值感知训练（BAT）的变换器基线，并且在内存使用和计算成本上大幅降低，相比原始的Mamba模型。这项工作首次提出了一条在低比特表示下具有线性复杂性的LLM的新路线，并为针对高效1比特Mamba的设计和优化专门硬件提供了思路。
### Conclusion
我们的工作开创了低比特表示下的线性复杂性大语言模型的新方向，并为专为高效1比特Mamba模型优化的硬件设计提供了设计途径。代码和预训练权重已公开。
## 394. `cs.CL` - 基于人类判断列表排名的排列偏好对齐 [PDF](https://arxiv.org/pdf/2410.04346), [HTML](https://arxiv.org/abs/2410.04346)
### Authors
Yang Zhao,Yixin Wang,Mingzhang Yin
### Background
调整大型语言模型（LLMs）与人类偏好的一致性对于确保模型行为的结果性和可控性至关重要。当前的方法，如基于人类反馈的强化学习（RLHF）和直接偏好优化（DPO），通常依赖布雷德利-特里（B-T）模型来最大化两两选择的似然性。但是，当有多种响应可用时，B-T模型无法确保响应列表的准确排名。因此，为了应对这一挑战，作者提出了一种新型的离线列表方法——排列偏好对齐（PPA），该方法将标准化折扣累积增益（NDCG）作为LLM对齐的替代训练目标，NDCG是一种广泛使用的排名指标。通过近似NDCG为目标函数，作者开发了一个端到端的对齐算法。实验结果表明，PPA在评估集和AlpacaEval等通用基准上优于现有的两两和列表方法，且基于NDCG的方法在排序准确性上比基于B-T的方法更有效。
### Innovation
提出了排列偏好对齐（PPA），一种新的离线列表方法，通过将标准化折扣累积增益（NDCG）作为LLM对齐的训练目标，解决了布雷德利-特里（B-T）模型在多种响应情况下无法确保准确列表排名的问题。PPA通过近似NDCG为目标函数，与传统的两两选择方法和基于B-T的方法相比，能提供更优的排序准确性和理论解释.
### Conclusion
PPA在多种评估标记和通用基准集上表现出色，证明了基于NDCG的方法能提高排序准确性，并提供了更好的理论解释，优于基于B-T的方法。
## 395. `cs.CL` - 神经注意搜索 [PDF](https://arxiv.org/pdf/2502.13251), [HTML](https://arxiv.org/abs/2502.13251)
### Authors
Difan Deng,Marius Lindauer
### Background
本文介绍了一种名为NAtS的框架，用于自动评估序列中每个令牌的重要性，并在几次步骤后确定是否可以删除相应的令牌。该方法能够有效减少基于transformer的模型在推理过程中所需的KV缓存大小，从而降低推理成本。
### Innovation
设计了一个包含三种令牌类型的空间：全局令牌、局部令牌和滑动窗口令牌。利用可学习注意掩码联合学习架构权重来获取这些令牌类型的信息。实验表明，NAtS可以在保持模型性能的同时有效地减少所需的KV缓存大小。
### Conclusion
本文实验表明，无论是在从头训练新的transformer还是微调现有大型语言模型中，NAtS都能有效地减少模型所需的KV缓存大小，同时保持模型的性能。
## 396. `cs.CL` - 从RoPE到NoPE再回来：一种新的混合注意力策略 [PDF](https://arxiv.org/pdf/2501.18795), [HTML](https://arxiv.org/abs/2501.18795)
### Authors
Bowen Yang,Bharat Venkitesh,Dwarak Talupuru,Hangyu Lin,David Cairuz,Phil Blunsom,Acyr Locatelli
### Background
长上下文大规模语言模型取得了显著进展，这得益于如旋转位置嵌入（RoPE）等技术的发展，以及其在不同研究中的扩展应用。通过调整RoPE参数并使用包含扩展上下文的数据进行训练，可以训练出表现良好的长输入序列模型。但是，现有基于RoPE的方法在处理扩展上下文长度时表现出性能限制。因此，有必要对不同的注意力机制进行全面分析，识别它们在长上下文建模中的优势和不足，为结构设计提供有价值的信息。
### Innovation
本文提出了一种新颖的混合注意力机制，结合了全局和局部注意力跨度，不仅在长和短上下文任务中超越了传统的基于RoPE的全注意力的转换器模型，还在训练和推理过程中实现了显著的效率提升。这是对长上下文模型的同时性能和效率的一种创新性提升。
### Conclusion
通过对不同注意力机制的综合分析，本文识别出这些机制在长上下文建模中的独特模式及其对性能的影响，提出了与传统RoPE基于的全注意力机制不同的新型混合注意力结构。这种设计策略超越了现有技术，并展示了其在效率和性能上的优越性。
## 397. `cs.CL` - 从文本到带隙：预训练语言模型在半导体带隙预测编码中的应用 [PDF](https://arxiv.org/pdf/2501.03456), [HTML](https://arxiv.org/abs/2501.03456)
### Authors
Ying-Ting Yeh,Janghoon Ock,Achuth Chandrasekhar,Shagun Maheshwari,Amir Barati Farimani
### Background
研究了基于变压器的语言模型，如RoBERTa、T5、Llama-3和MatSciBERT，用于直接从材料描述中预测半导体材料的带隙。这些输入包含化学组成的结构字符串模板和通过ChatGPT API生成的自然语言叙述。与需要大量特征工程的浅层机器学习模型或依赖于原子坐标图形表示的图神经网络不同，预训练的语言模型可以直接处理文本输入，无需手动特征预处理或结构编码。
### Innovation
本文提出了一种新的方法，利用预训练的语言模型直接从文本描述中预测半导体材料的带隙，这简化了特征工程过程，并表明预训练的语言模型能够直接处理 textual 输入以预测物理性质，同时强调了领域特定预训练的重要性。
### Conclusion
不同架构和参数规模的语言模型均能通过可读文本准确预测带隙，精确度达到0.25-0.33 eV。Llama-3在1.2亿参数的情况下实现了最高精度（MAE 0.248 eV，R2 0.891），而MatSciBERT（1.1亿参数）在领域特定预训练下表现出相似的性能（MAE 0.288 eV，R2 0.871）。注意力分析表明两种模型都强调组成和自旋相关特征，而减弱几何特征的重视，这反映了通过文本捕捉空间信息的困难性。这些结果验证了预训练语言模型在从文本材料描述中有效提取复杂特征-性质关系的能力。
## 398. `cs.CL` - 不是每个注意力头都重要：一种集成检索与推理的头级KV缓存压缩方法 [PDF](https://arxiv.org/pdf/2410.19258), [HTML](https://arxiv.org/abs/2410.19258)
### Authors
Yu Fu,Zefan Cai,Abedelkadir Asi,Wayne Xiong,Yue Dong,Wen Xiao
### Background
大语言模型（LLMs）的键值（KV）缓存技术可以提高计算效率，但随着输入长度的增加，其内存开销迅速增长。先前的研究显示，不是所有标记在文本生成中都具有同等的重要性，提出了逐层KV缓存压缩方法，以选择性地保留重要信息。考虑到生成任务中注意力头的不同作用，本文提出了头级KV缓存压缩（HeadKV）方法以及通过新颖的上下文推理能力评估进行压缩的HeadKV-R2方法。本文的方法在个体注意力头级别上操作，通过估计这些头在需要检索和推理能力的上下文问答任务中的重要性来进行压缩。
### Innovation
本文提出了头级KV缓存压缩（HeadKV）方法以及头级KV缓存压缩改进版（HeadKV-R2）方法。HeadKV方法在个体注意力头上进行操作，通过估计这些头在需要检索和推理能力的上下文问答任务中的重要性来进行压缩。HeadKV-R2方法通过引入新的上下文推理能力评估机制进一步增强压缩效果。
### Conclusion
通过广泛的实验，本文表明头级KV缓存压缩显著优于强劲的基线方法，特别是在低资源设置（KV大小=64 & 128）中。本文的方法仅保留了KV缓存的1.5%，但在上下文问答基准测试中的性能达到了完整KV缓存的97%。
## 399. `cs.CL` - 语言模型（大多数情况下）知道何时停止阅读 [PDF](https://arxiv.org/pdf/2502.01025), [HTML](https://arxiv.org/abs/2502.01025)
### Authors
Roy Xie,Junlin Wang,Paul Rosu,Chunyuan Deng,Bolun Sun,Zihao Lin,Bhuwan Dhingra
### Background
大型语言模型 (LLMs) 会无差别地处理整个输入上下文，这在查询所需回答的信息集中在上下文中的情况下是低效的。本文分析表明，特定的注意力头会内在地编码“充足性信号”，可以通过轻量级分类器检测到，从而预测出关键信息是否已经处理完成。
### Innovation
提出了动态上下文截断方法，使得模型在获得足够任务相关信息后能够自我终止处理。该方法揭示了新的高效性范式：模型的内部理解自然地决定了处理需求，而不是外部压缩的启发式方法。通过在六个QA数据集（最多40K tokens）上进行实验，展示了在每种情况下平均减少1.33倍的token数量的同时，还能获得准确性3.4%的提升。该方法在同等的token减少率上优于其他上下文效率方法。此外，观察到一种新兴的扩展现象：小型模型需要进行探测以检测充足性，而大型模型则通过提示表现出内在的自我评估能力。
### Conclusion
研究结果表明，语言模型能够有效地自我终止处理，从而提高效率。这种方法可以通过探测模型的内部理解以减少不必要的处理，而无需外部压缩技巧。大型语言模型还表现出自我评估充足性的能力。
## 400. `cs.CL` - 令牌嵌入违反流形假设 [PDF](https://arxiv.org/pdf/2504.01002), [HTML](https://arxiv.org/abs/2504.01002)
### Authors
Michael Robinson,Sourya Dey,Tony Chiang
### Background
了解大型语言模型（LLM）的行为需要理解其输入的令牌空间。如果这个空间与我们之前的假设不同，那么我们对这些模型的理解和结论可能会有偏差。本文通过实证和理论分析研究了令牌嵌入的空间结构。
### Innovation
提出了一种新的统计检验，该检验将每个令牌周围的邻域结构视为平坦和光滑的假设。当此假设被拒绝时，表明令牌空间在特定令牌周围的非流形性质。进一步发现，令牌嵌入空间不是传统的流形或纤维丛。这为理解令牌嵌入的空间结构提供了一种新的视角。
### Conclusion
通过对几个开源LLM进行测试，发现边界假设经常被拒绝。这表明令牌嵌入空间不是流形，也不是纤维丛。因此，当LLM接收到两个语义等价的提示时，如果一个提示包含我们的测试所指出的令牌，则该提示的响应可能不如另一个提示稳定。
## 401. `cs.CL` - 更多文档，相同长度：RAG 中多文档挑战的隔离 [PDF](https://arxiv.org/pdf/2503.04388), [HTML](https://arxiv.org/abs/2503.04388)
### Authors
Shahar Levy,Nir Mazor,Lihi Shalmon,Michael Hassid,Gabriel Stanovsky
### Background
检索增强生成（RAG）通过在生成过程中利用相关的外部文档来提高大型语言模型（LLM）响应的准确性。尽管先前的研究指出，检索大量文档可能会降低性能，但它们没有在控制上下文长度的情况下单独研究文档数量对性能的影响。本文通过对多重跳问答任务的数据集进行定制评估，探讨了这一点。
### Innovation
本研究通过在保持上下文长度和相关信息位置不变的情况下，变化文档数量来评估各种语言模型在RAG设置中的表现。发现大多数LLM在增加文档数量时面临显著挑战，性能下降最多可达20%；然而Qwen2.5表现稳定，表明其在处理多文档方面有更好的能力。研究还表明，处理多个文档是不同于处理长上下文的另一项挑战。
### Conclusion
本研究结果指出，处理多个文档是一项独立于处理长上下文的挑战。最后，作者提供了所用的数据集和代码：this https URL.
## 402. `cs.CL` - 所有人的安全标准相同吗？大规模语言模型的用户特定安全评估 [PDF](https://arxiv.org/pdf/2502.15086), [HTML](https://arxiv.org/abs/2502.15086)
### Authors
Yeonjun In,Wonjoong Kim,Kanghoon Yoon,Sungchul Kim,Mehrab Tanjim,Sangwu Park,Kibum Kim,Chanyoung Park
### Background
随着大规模语言模型（LLM）代理的广泛应用，其安全漏洞逐渐显现出来。现有的安全评估基准主要依赖通用标准，并未充分考虑用户的特定标准。然而，LLM的安全标准可能因用户特定的档案而异，而非在所有用户中保持一致。基于此，提出了一个关键的研究问题：在考虑用户特定的安全标准时，LLM代理是否能安全地运行？然而，当前没有可用于评估LLM用户特定安全性的基准数据集。为了填补这一空白，作者引入了名为‘U-SafeBench’的基准测试，旨在评估用户特定的LLM安全性。评估结果显示，目前广泛使用的20种LLM在考虑用户特定的安全标准时，未能实现安全性，这在该领域是一个新的发现。
### Innovation
作者提出并设计了‘U-SafeBench’基准测试，这是首个专门用于评估用户特定的LLM安全性的基准。此外，作者提出了一种基于chain-of-thought的简单补救措施，证明了其在提升用户特定安全性方面的有效性。
### Conclusion
通过U-SafeBench的评估结果显示，目前流行的LLM在考虑用户特定的安全标准时未能实现安全性。研究还提出了一种基于chain-of-thought的简单解决方案，表明这种补救措施在提高用户特定安全性方面是有效的。
## 403. `cs.CL` - 大型视觉语言模型推理中的快速-缓慢思考GRPO [PDF](https://arxiv.org/pdf/2504.18458), [HTML](https://arxiv.org/abs/2504.18458)
### Authors
Wenyi Xiao,Leilei Gan
### Background
在通过GRPO应用强化学习进行大型视觉语言模型推理时，难以有效扩展推理长度或产生冗长的输出结果，且在所有任务上仅能实现边际准确率提升。
### Innovation
提出了FAST-GRPO，这是一种基于问题特征动态适应推理深度的GRPO变体。通过引入两种互补的度量以估计问题难度，并据此引导模型确定何时采用快速或缓慢的思考方式，同时结合可调节长度的奖励和难度感知的KL散度到GRPO算法中。
### Conclusion
在七个推理基准测试中，FAST在准确率上超过了基线模型10%以上，并且能够减少32.7-67.3%的标记使用量，有效平衡了推理长度和准确率。
## 404. `cs.CL` - S-DAT：一种多语言、基于生成式AI的自动化发散思维评估框架 [PDF](https://arxiv.org/pdf/2505.09068), [HTML](https://arxiv.org/abs/2505.09068)
### Authors
Jennifer Haase,Paul H. P. Hanel,Sebastian Pokutta
### Background
传统的发散思维评估往往耗时且依赖于特定语言，需要人工主观评分，导致其难以大规模和跨文化应用。相比之下，S-DAT (Synthetic-Divergent Association Task) 利用大规模语言模型和先进的多语言嵌入计算语义距离，提供了一种语言无关的发散思维代理指标，能够实现多语言环境下的评估，并显现出可靠的评分一致性。
### Innovation
S-DAT提供了一种可扩展、多语言的自动化评估框架，利用大语言模型和先进的多语言嵌入技术，计算语言无关的语义距离作为发散思维的代理指标。它克服了传统评估方法的局限性，与发散思维的其他测量方法具有收敛效度，与集中思维的效度则相反，显示了跨语言评估的一致性和有效性。
### Conclusion
S-DAT 提供了一种强大的工具，用于对多元人口的认知灵活性进行公平和全面的评估，可以在线免费评估。S-DAT 为跨文化、全球规模的创造力研究提供了更包容的方法，解决了早期方法的关键局限性。
## 405. `cs.CL` - 通过BiGTex整合文本归属图中的结构和语义信号 [PDF](https://arxiv.org/pdf/2504.12474), [HTML](https://arxiv.org/abs/2504.12474)
### Authors
Azadeh Beiranvand,Seyed Mehdi Vahidipour
### Background
文本归属图（TAGs）在表示学习中面临独特挑战，需要模型捕获节点关联文本的语义丰富性和图结构的依赖关系。尽管图神经网络（GNNs）擅长建模拓扑信息，但缺乏处理未结构化文本的能力。相反，大型语言模型（LLMs）擅长文本理解，但通常不了解图结构。在这一背景下，本文探讨了GNNs与LLMs之间的互补性，并提出了一种新的架构BiGTex（双向图文本）.
### Innovation
本文提出了BiGTex（双向图文本）架构，这是一种通过堆叠Graph-Text融合单元将GNNs和LLMs紧密结合的创新方法。每个单元允许文本和结构表示之间的互注意力，使得信息可双向流动，即文本影响结构，同时结构指导文本解释。此外，该架构使用参数效率的微调（LoRA）进行训练，保持LLMs冻结状态，但适应特定任务信号。实验表明，BiGTex在节点分类上达到最先进的性能，并且在链接预测任务中表现出有效的泛化能力。研究还强调了软提示和双向注意对于该模型成功的重要作用.
### Conclusion
广泛实验表明，BiGTex在节点分类上达到最先进的性能，并且在链接预测任务中表现出有效的泛化能力。进一步的消融研究还强调了软提示和双向注意对于提高模型性能的重要性。
## 406. `cs.CL` - ExpertLens：激活引导特征高度可解释 [PDF](https://arxiv.org/pdf/2502.15090), [HTML](https://arxiv.org/abs/2502.15090)
### Authors
Masha Fedzechkina,Eleonora Gualdoni,Sinead Williamson,Katherine Metcalf,Skyler Seto,Barry-John Theobald
### Background
在大规模语言模型（LLMs）中，激活引导方法已被证明是进行有针对性的更新，以增强生成的语言，而无需大量适应数据的有效手段。研究人员想知道激活引导方法发现的特征是否具有可解释性。通过“寻找专家”方法识别特定概念（例如，“猫”）相关的神经元，观察这些神经元的“专家镜”（ExpertLens）揭示了模型表示的信息。研究发现，专家镜在不同模型和数据集上表现稳定，且与从行为数据推断的人类概念表示高度一致，匹配人际关系的一致性水平。专家镜在单词/句子嵌入捕捉的对齐上表现更优。通过专家镜重构人类概念组织，展示了其对LLM概念表示的精细视角。这些发现表明，专家镜是一种灵活且轻量级的方法，用于捕获和分析模型表示。
### Innovation
本研究提出了一种名为专家镜（ExpertLens）的方法，用于识别特定概念相关的神经元，并通过观察这些神经元展示了模型表示的可解释性。相比于单词/句子嵌入，专家镜在对齐上表现更优，能够提供对大规模语言模型概念表示的深入理解。
### Conclusion
研究发现，专家镜方法在对齐模型表示方面表现出色并具有高度的可解释性，能够提供对大规模语言模型概念表示的精细视角。建议进一步利用专家镜方法来捕获和分析更多的模型表示特征。
## 407. `cs.CL` - Heterogeneous Swarms: Jointly Optimizing Model Roles and Weights for Multi-LLM Systems [PDF](https://arxiv.org/pdf/2502.04510), [HTML](https://arxiv.org/abs/2502.04510)
### Authors
Shangbin Feng,Zifeng Wang,Palash Goyal,Yike Wang,Weijia Shi,Huang Xia,Hamid Palangi,Luke Zettlemoyer,Yulia Tsvetkov,Chen-Yu Lee,Tomas Pfister
### Background
当前研究主要集中在设计多大语言模型（LLM）系统的算法。现有的方法通常仅关注优化模型的权重或角色，较少同时考虑两者的联合优化。论文提出了一种名为“Heterogeneous Swarms”的算法，旨在为多LLM系统的设计提供一个新的解决方案，通过同时优化模型角色和权重来提升系统的性能。这种方法采用了有向无环图（DAG）来表示LLM系统，利用拓扑信息进行协作生成，并提出了一种迭代的策略来逐步优化角色和权重，从而实现模型间更有效的协作和共同学习。
### Innovation
Heterogeneous Swarms 的创新在于提出了一个全新的算法框架，该框架能够同时优化多LLM系统的模型角色和权重。在角色优化阶段（role-step），算法通过解析连续的邻接矩阵来解码出离散的DAG结构，然后利用粒子群优化（PSO）进行角色优化，以最大化任务性能。在权重优化阶段（weight-step），算法定义了一种新的度量标准JFK-score来量化每个模型的贡献，并基于此进行权重优化。实验结果表明，Heterogeneous Swarms在12个任务上平均比15种基线方法高出18.5%的性能，并揭示了具有异构模型角色和显著协作增益的多LLM系统。此外，该方法充分利用了模型间的多样性，进一步提升了系统的性能和泛化能力。
### Conclusion
实验结果表明，Heterogeneous Swarms在12个任务上平均比15种基线方法高出18.5%的性能。通过同时优化模型角色和权重，Heterogeneous Swarms发现了一种具有异构模型角色和显著协作增益的多LLM系统架构，并表明了这种方法在提升大语言模型整体性能上的潜力。该方法不仅优化了模型配置，还加深了对大语言模型协同作用的理解，为进一步的理论研究和实用应用提供了新的途径。
## 408. `cs.CL` - XtraGPT: 针对学术论文的上下文感知和可控性修订 [PDF](https://arxiv.org/pdf/2505.11336), [HTML](https://arxiv.org/abs/2505.11336)
### Authors
Nuo Chen,Andre Lin HuiKai,Jiaying Wu,Junyi Hou,Zining Zhang,Qian Wang,Xidong Wang,Bingsheng He
### Background
尽管大型语言模型（LLMs）在学术工作流程中的应用日益增多，但它们的能力仍然有限，不能支持高质量的科学写作。现有的大多数系统都是为了通用科学文本生成设计的，未能满足超越表面处理的研究交流的高层次需求，例如各部分之间概念上的连贯性。此外，学术写作本质上是迭代和修订驱动的，而直接提示式的方法并没有很好地支持这一过程。
### Innovation
本文提出了一种基于标准指引意图对齐和上下文感知建模的人机协作框架，以解决上述问题。我们构建了一个包含7000篇顶级学术会议的高质量学术论文数据集，附有14万个用于反映真实段落级别修订的指令-响应对。我们通过开源LLM XtraGPT实现了该框架，XtraGPT是第一个针对上下文感知、指令引导写作辅助的LLM套件（参数量从1.5B到14B）。实验表明XtraGPT在性能上明显优于同等规模的基线系统，并达到了商业系统的质量水平。自动偏好评估和人工评价都证实XtraGPT能够有效提高科学草稿的质量。
### Conclusion
综上所述，XtraGPT显著提升了学术论文修订的质量，是上下文感知和可控的论文修订的有效工具。
## 409. `cs.CL` - MultiHal：基于知识图谱的LLM幻觉跨语言评估数据集 [PDF](https://arxiv.org/pdf/2505.14101), [HTML](https://arxiv.org/abs/2505.14101)
### Authors
Ernests Lavrinovics,Russa Biswas,Katja Hose,Johannes Bjerva
### Background
大语言模型（LLMs）存在忠实性和可信度不足的问题，通常被称为幻觉。虽然已经开发了一些基准用于英语为中心的数据集的事实评估，但这些基准依赖于额外的信息上下文，如网页链接或文本段落，却没有利用结构化的事实资源。知识图谱（KGs）被认为是缓解幻觉的有效工具，因为它们以结构化的方式表示实体及其关系，且具有最小的语义负担。本文探讨了在现有幻觉评估基准中引入KG路径和多语言性的不足，并提出了一个名为MultiHal的基于KG的多语言、多跳基准，用于生成文本评估。
### Innovation
本文提出了一个名为MultiHal的基于KG的多语言、多跳基准，填补了现有幻觉评估基准在KG路径和多语言性方面的不足，强调了KG在事实语言模型中的作用，并展示了MultiHal在跨语言和多模型评估中的潜力。
### Conclusion
MultiHal有望促进未来基于图的幻觉缓解和事实核查任务的研究。基准显示，Multihal在多种语言和多个模型上的幻觉检测评分提高了0.12到0.42分，表现出KG整合的潜力。
## 410. `cs.CL` - 受LLM驱动的实体代理遇到了个性化挑战：通过记忆利用视角进行探讨与解决 [PDF](https://arxiv.org/pdf/2505.16348), [HTML](https://arxiv.org/abs/2505.16348)
### Authors
Taeyoon Kwon,Dongwook Choi,Hyojun Kim,Sunghwan Kim,Seungjun Moon,Beong-woo Kwak,Kuan-Hao Huang,Jinyoung Yeo
### Background
LLM驱动的实体代理已经在传统的物体重新排列任务中取得了成功，但如何提供个性化帮助并利用用户过往交互中的具体知识则带来了新的挑战。
### Innovation
本文通过探讨实体代理在两个关键维度上使用记忆的能力：对象语义（基于个人意义识别对象）和用户模式（回忆行为模式中的序列），构建了一个端到端的双阶段评估框架MEMENTO，专门用于评估这些能力。研究发现，当前代理能识别简单的对象语义，但在应用序列用户模式进行规划时存在问题，提出了基于情景记忆的层次知识图谱用户档案记忆模块，有效解决了多记忆处理中的信息过载和协调失败问题。
### Conclusion
研究表明现有的实体代理在处理序列用户模式用于规划时存在缺陷，可以通过设计层次知识图谱用户档案记忆模块来改善这一问题，该模块能够有效管理个性化知识并在单记忆和联合记忆任务上都取得了显著的改进。
## 411. `cs.CL` - 利用稀疏自编码器进行LLM去毒：改变有毒词汇 [PDF](https://arxiv.org/pdf/2505.14536), [HTML](https://arxiv.org/abs/2505.14536)
### Authors
Agam Goyal,Vedant Rathi,William Yeh,Yian Wang,Yuen Chen,Hari Sundaram
### Background
大语言模型（LLMs）现在在用户界面应用中无处不在，但它们仍然生成不当的有毒输出，包括粗俗语言、粗鄙言论和侮辱性评论。尽管存在许多去毒方法，大多数方法只进行表面的修正，容易受到囚徒突破攻击的操纵。
### Innovation
本文利用稀疏自编码器（SAEs）识别模型残差流中的毒害相关方向，并使用对应的解码器向量进行定向激活引导。引入了三种级别的引导强度，并在GPT-2 Small和Gemma-2-2B上进行评估，揭示了毒害减少和语言流畅性之间的权衡。通过更强的引导强度，这些因果干预措施在减少毒害方面优于竞争基线高达20%，但语言流畅性在GPT-2 Small上可能会明显下降。关键在于，通过引导标准NLP基准得分保持稳定，表明模型的知识和一般能力得以保留。此外，更宽的SAE中的特征拆分阻碍了安全干预，突显了解耦特征学习的重要性。
### Conclusion
我们的研究突显了基于SAE的因果干预在LLM去毒中的潜力和当前局限性，同时提供了更安全的语言模型部署的实用指南。
## 412. `cs.CL` - MoMoE: Mixture of Moderation Experts Framework for AI-Assisted Online Governance [PDF](https://arxiv.org/pdf/2505.14483), [HTML](https://arxiv.org/abs/2505.14483)
### Authors
Agam Goyal,Xianyang Zhan,Yilun Chen,Koustuv Saha,Eshwar Chandrasekharan
### Background
现有的内容审查方法需要为每个社群建立一个独立的模型，并且在决策过程中不够透明，这限制了这些方法在现实生活中的应用。大语言模型（LLMs）在标记在线社群中的有害内容方面显示出巨大的潜力，但现有方法面临上述挑战。因此，存在一种需求，即开发一种能够跨社群进行可扩展的内容审查，并能够提供后验解释的解决方案。
### Innovation
引入了Mixture of Moderation Experts（MoMoE），这是一种模块化的跨社群框架，可以为可扩展的内容审查添加后验解释。MoMoE由四个操作组成——分配、预测、聚合和解释，并且以七种社群特化的专家（MoMoE-Community）和五种违反规范的专家（MoMoE-NormVio）的形式实例化。研究表明，MoMoE能够在无需每个社群单独微调的情况下实现可扩展、透明的机制。此外，MoMoE还表明，轻量级的可解释专家集成可以指导未来的人工智能治理研究，特别是在在线社群中的人工智能和人类治理方面。
### Conclusion
MoMoE能够在无需每个社群单独微调的情况下，实现跨社群可扩展的内容审查和后验解释。尽管社群特化的专家在峰值准确率上表现最好，但违反规范的专家则在不同领域表现出更稳定的性能。这些发现表明，MoMoE可以通过合适的轻量级、可解释的专家集成来实现可扩展且透明的内容审查，而不需要单独为每个社群进行微调，这对于未来的人类-人工智能治理研究是非常有价值的。
## 413. `cs.CL` - 语言模型使用回顾机制追踪信念 [PDF](https://arxiv.org/pdf/2505.14685), [HTML](https://arxiv.org/abs/2505.14685)
### Authors
Nikhil Prakash,Natalie Shapira,Arnab Sen Sharma,Christoph Riedl,Yonatan Belinkov,Tamar Rott Shaham,David Bau,Atticus Geiger
### Background
本研究探讨了语言模型（LMs）如何表示角色的信念，尤其是当这些信念与现实不符时。这是理解语言模型的理论思维（ToM）能力的核心问题。研究者采用因果中介和抽象分析的方法，研究了LMs在处理角色信念推理的能力，并构建了一个包含简单故事的数据集，这些故事中两个角色独立改变了两个对象的状态，可能没有意识到彼此的行为。研究发现了LM用于回忆重要信息的共同算法模式，即“回顾机制”。
### Innovation
研究的主要创新在于发现了一种称为‘回顾机制’的算法模式，LM通过在状态标记的残差流中的低秩子空间中并置每个角色对象状态三元组的引用信息，将它们关联在一起。当询问关于某角色对其所关注对象状态的信念时，‘绑定回顾’机制检索正确的状态引用信息，然后‘答案回顾’机制检索相应状态标记。研究还引入了关于可见性的文本，发现LM首先生成一个可见性ID来编码观察角色与被观察角色之间的关系。当在‘可见性回顾’机制中使用ID时，可以检索到关于被观察角色的信息并更新观察角色的信念。这些发现为理解信念追踪机制提供了新的见解，是解开语言模型理论思维（ToM）推理机制的关键一步。
### Conclusion
研究揭示了语言模型在追踪角色信念时使用“回顾机制”的机制，这展示了LM对于理论思维（ToM）推理能力的理解迈出了一步，有助于未来的研究进一步解析语言模型的理解和推理机制。
## 414. `cs.CL` - 通过强化学习实现的混合隐式推理 [PDF](https://arxiv.org/pdf/2505.18454), [HTML](https://arxiv.org/abs/2505.18454)
### Authors
Zhenrui Yue,Bowen Jin,Huimin Zeng,Honglei Zhuang,Zhen Qin,Jinsung Yoon,Lanyu Shang,Jiawei Han,Dong Wang
### Background
近年来，大型语言模型 (LLMs) 的最新进展提出了隐式推理作为一种有前途的替代自回归推理的方式。通过在先前步骤的隐藏状态中进行内部计算，隐式推理能够利用更丰富的特征，而不是抽样离散的思维链（CoT）路径。然而，隐式推理方法往往与LLMs不兼容，因为它们的连续范式与自回归生成的离散性质相冲突。此外，这些方法依赖于CoT踪迹进行训练，因此无法充分利用LLMs内部的推理模式。
### Innovation
我们通过强化学习（RL）利用LLMs内置的能力来探索隐式推理。我们引入了一种基于RL的混合隐式推理政策优化（HRPO）方法，该方法（1）通过可学习的门控机制将先前的隐藏状态整合到生成的令牌中，（2）初始训练主要使用令牌嵌入，然后逐渐增加更多隐藏特征的使用。这种方法保持了LLMs的生成能力，并使用离散和连续表示激励混合推理。此外，混合HRPO通过令牌抽样引入了隐式推理中的随机性，从而使其能够进行基于RL的优化，而无需CoT路径。
### Conclusion
广泛的基准测试表明，HRPO在知识和推理密集型任务中优于先前的方法。此外，经过HRPO训练的LLMs保持可解释性，并表现出跨语言模式和更短的生成长度等有趣的行为，突显了我们基于强化学习的方法的潜力，并为未来的工作提供了见解。
## 415. `cs.CL` - 超越离散令牌采样的人文生成 [PDF](https://arxiv.org/pdf/2505.14827), [HTML](https://arxiv.org/abs/2505.14827)
### Authors
Yufan Zhuang,Liyuan Liu,Chandan Singh,Jingbo Shang,Jianfeng Gao
### Background
在标准的自回归生成过程中，LLM预测下一个令牌的概率分布，然后采样一个离散的令牌并将分布丢弃，仅传递采样的令牌作为新的输入。这种丢弃分布的方式导致了部分信息的丢失。为了保留这一分布中的丰富信息，该研究提出了Mixture of Inputs (MoI) 方法，这是一种无需额外训练的自回归生成方法。在生成令牌后，MoI 方法构造一个新的输入，将生成的离散令牌与之前丢弃的令牌分布融合在一起。这种方法通过贝叶斯估计方法，将令牌分布视为先验，采样令牌作为观察值，并用连续的后验期望值替代传统的用一热向量作为新的模型输入。
### Innovation
MoI 是一种无需额外训练的自回归生成方法。它在生成令牌后，通过融合生成的离散令牌与之前丢弃的令牌分布来构造一个新的输入。这种方法使用贝叶斯估计方法，将传统的一热向量输入替换为连续的后验期望值。实验结果显示，MoI 在数学推理、代码生成和博士水平的问题解答任务上，能够提升多个模型（包括 QwQ-32B, Nemotron-Super-49B, Gemma-3-27B, 和 DAPO-Qwen-32B）的性能，且无需额外训练和几乎没有额外的计算开销。
### Conclusion
MoI 方法通过保留令牌生成过程中的概率分布信息，使得模型在整个生成过程中保持更丰富的内部表示，从而提升了生成质量及推理能力。在多个实际应用任务中，MoI 均实现了性能的提升。
## 416. `cs.CL` - DREAM: Drafting with Refined Target Features and Entropy-Adaptive Cross-Attention Fusion for Multimodal Speculative Decoding [PDF](https://arxiv.org/pdf/2505.19201), [HTML](https://arxiv.org/abs/2505.19201)
### Authors
Yunhai Hu,Tianhua Xia,Zining Liu,Rahul Raman,Xingyu Liu,Bo Bao,Eric Sather,Vithursan Thangarasa,Sai Qian Zhang
### Background
 speculate decoding (SD) 已经成为加速大规模语言模型 (LLMs) 自回归生成的强大方法，但在视觉语言模型 (VLMs) 中的应用仍相对不足。现有的 SD 方法大多针对 LLMs，而对 VLMs 的整合研究较少。
### Innovation
DREAM 引入了一种新的投机性解码框架，专为 VLMs 设计，集成了三个关键创新：1) 基于交叉注意力的机制，用于将目标模型的中间特征注入草稿模型以提高对齐；2) 基于注意力熵的自适应中间特征选择，以引导高效的草稿模型培训；3) 视觉标记压缩，以减少草稿模型的延迟。这些创新使得在多种分布式解码设置下，可以实现高效的、准确的和并行的多模态解码，并提升吞吐量。
### Conclusion
通过在广泛的多模态基准测试中对 DREAM 方法进行实验，研究人员展示了其相对于传统解码方法的最大 3.6 倍的速度提升，并在推断吞吐量和投机性草稿接受长度方面均显著优于先前的 SD 基线。这项研究对于推进 VLMs 的发展具有重要价值，并且已经开源。
## 417. `cs.CL` - LeCoDe：一种交互式法律咨询对话评估基准数据集 [PDF](https://arxiv.org/pdf/2505.19667), [HTML](https://arxiv.org/abs/2505.19667)
### Authors
Weikang Yuan,Kaisong Song,Zhuoren Jiang,Junjie Cao,Yujie Zhang,Jun Lin,Kun Kuang,Ji Zhang,Xiaozhong Liu
### Background
法律咨询保护个人权利并确保获得司法公正至关重要，但由于专业人员短缺，成本高昂且许多个人无法获得。最近，大规模语言模型（LLMs）的进展为提供可扩展、低成本的法律援助带来希望。然而，现有系统在处理互动性和知识密集型的现实咨询方面仍存在不足。由于这些挑战，我们介绍了LeCoDe，这是一个包含3,696次法律咨询对话和110,008轮对话的实战多层次基准数据集，旨在评估和提升LLMs的法律咨询能力。
### Innovation
LeCoDe通过从短视频平台收集实时流播咨询，提供真实多轮的法律咨询对话，并由法律专家进行严格标注，增强了数据集的专业洞察和经验。我们提出了一种全面的评估框架，评估LLMs的咨询能力包括（1）澄清能力（2）专业建议质量。该框架涉及两个维度的12个指标。通过在多种通用和特定领域的LLMs上的广泛实验，我们揭示了该任务中的重大挑战，即使像GPT-4这样的最先进的模型，澄清召回率也只有39.8%，建议质量的总体评分为59%，突显了专业咨询场景的复杂性。基于这些发现，我们进一步探讨了提高LLMs法律咨询能力的策略。LeCoDe为推进法律领域对话系统的研究做出了贡献，特别是在模拟更多真实世界的用户专家互动方面。
### Conclusion
我们的基准为推进法律领域对话系统的研究做出了贡献，特别是在模拟更多真实世界的用户专家互动方面。
## 418. `cs.CL` - ixi-GEN：通过领域自适应连续预训练实现高效的工业小型语言模型 [PDF](https://arxiv.org/pdf/2507.06795), [HTML](https://arxiv.org/abs/2507.06795)
### Authors
Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon
### Background
开源大规模语言模型（LLMs）扩展了企业应用的机会，但许多组织仍然缺乏部署和维护大规模模型的基础设施。因此，尽管存在固有的性能限制，小型语言模型（sLLMs）成为了一种实用的替代方案。尽管领域自适应连续预训练（DACP）已被探索用于领域自适应，但在商业环境中的应用价值仍然未被充分研究。
### Innovation
基于DACP的方法在多种基础模型和服务领域中得到了验证，产生了应用DACP的小型语言模型（ixi-GEN）。通过广泛的实验和实际评估，ixi-GEN模型在目标领域的性能上实现了显著提升，同时保持了一般能力，提供了一种成本高效且可扩展的解决方案，适用于企业级部署。
### Conclusion
ixi-GEN模型通过DACP方法在目标领域的性能获得了显著提高，同时保留了一般能力，为小型语言模型在企业级部署提供了经济高效且可扩展的解决方案。
## 419. `cs.CL` - 定量的大语言模型法官 [PDF](https://arxiv.org/pdf/2506.02945), [HTML](https://arxiv.org/abs/2506.02945)
### Authors
Aishwarya Sahoo,Jeevana Kruthi Karnuthala,Tushar Parmanand Budhwani,Pranchal Agarwal,Sankaran Vaidyanathan,Alexa Siu,Franck Dernoncourt,Jennifer Healey,Nedim Lipka,Ryan Rossi,Uttaran Bhattacharya,Branislav Kveton
### Background
本文介绍了一种框架，其中大语言模型（LLM）评估另一个LLM的输出。尽管LLM在生成定性文本评估方面表现出色，但在预测人类偏好和数值评分方面常常遇到困难。研究提出了一种定量的大语言模型法官，这种法官通过回归模型将现有LLM法官在给定领域中的评估分数与人类一致，训练模型以改进原始法官的评分，同时使用其推理和评分。研究展示了该框架对不同类型绝对和相对反馈的普遍性和灵活性。该框架在计算效率上优于监督微调，并且在人类反馈限制的情况下（如实际预期的那样）具有更高的统计效率。
### Innovation
本文的创新之处在于提出了一种定量的大语言模型法官框架，这种框架使用回归模型将现有LLM法官在特定领域中的评估分数与人类一致，从而提高评分的准确性和预测能力。该框架可以更高效地进行计算，并在人类反馈有限的情况下提供更稳定的统计结果。
### Conclusion
通过在四个数据集上使用两种基准法官进行实验证明，定量的大语言模型法官可以利用后验建模提高现有法官的预测能力。此外，该方法在计算效率和统计效率方面优于监督微调方法。
## 420. `cs.CL` - MCIF: 科学讲座中的多模态跨语言指令跟随基准 [PDF](https://arxiv.org/pdf/2507.19634), [HTML](https://arxiv.org/abs/2507.19634)
### Authors
Sara Papi,Maike Züfle,Marco Gaido,Beatrice Savoldi,Danni Liu,Ioannis Douros,Luisa Bentivogli,Jan Niehues
### Background
近年来，大型语言模型的发展促进了多模态大模型（MLLMs）的兴起，这些模型能够整合文本、语音和视觉信息。MLLMs从单一语言、单一任务的小范围应用向通用指令跟随模型发展，但在评估其跨语言和多模态能力方面，现有基准仍然存在缺陷。现有基准多局限于英语，主要关注单一模态，集中在短文本上，缺乏人类注释，导致模型在多语言、多模态以及任务复杂度上的表现评估不全面。
### Innovation
本文提出MCIF（Multimodal Crosslingual Instruction Following），这是一个基于科学讲座的多语言人类注释基准，旨在评估跨语言和多模态环境下的指令跟随能力。MCIF包括三个核心模态（语音、视觉、文本），涵盖四种不同的语言（英语、德语、意大利语和中文），能够全面评估MLLMs在不同语言和模态下的指令理解能力和整合多模态上下文信息的能力。MCIF以CC-BY 4.0许可证发布，促进开放研究和MLLMs的发展。
### Conclusion
MCIF为评估模型的多语言、多模态以及指令跟随能力提供了一个新的基准，填补了现有基准的空白，对推动MLLMs的发展具有重要意义。
## 421. `cs.CL` - 打破mBad！监督微调在跨语言去毒中的应用 [PDF](https://arxiv.org/pdf/2505.16722), [HTML](https://arxiv.org/abs/2505.16722)
### Authors
Himanshu Beniwal,Youngwoo Kim,Maarten Sap,Soham Dan,Thomas Hartvigsen
### Background
随着大型语言模型（LLMs）在全球应用中变得越来越普遍，确保它们在多种语言环境中无毒性仍然是一个关键挑战。探索跨语言去毒是一种跨语言模式，可以减少毒性并使去毒能力在不同语言体系的高资源和低资源语言之间进行迁移。该研究通过392种广泛的设置来评估跨分布环境中的毒性减少效果，并调查抑制措施如何影响模型在非毒性任务上的性能，揭示了安全性和知识保留之间的权衡。
### Innovation
提出了一种跨语言去毒的框架，通过监督微调技术使得去毒能力能够在不同语言体系的高资源和低资源语言之间进行迁移。这一方法通过广泛的设置评估了在数据稀缺情况下的毒性减少效果，同时研究了抑制措施对模型在非毒性任务性能的影响，揭示了安全性和知识保留之间的权衡。研究团队还公开了代码和数据集。
### Conclusion
研究表明，跨语言去毒能够有效降低不同语言环境下模型的毒性，同时在某些情况下，这种去毒技术在非毒性任务上的性能有所下降。研究结果说明了在实现安全性和知识保留之间需要做出权衡，并提供了进一步优化的途径。
## 422. `cs.CL` - RMTBench：通过多轮用户中心角色扮演评估大型语言模型 [PDF](https://arxiv.org/pdf/2507.20352), [HTML](https://arxiv.org/abs/2507.20352)
### Authors
Hao Xiang,Tianyi Tang,Yang Su,Bowen Yu,An Yang,Fei Huang,Yichang Zhang,Yaojie Lu,Hongyu Lin,Xianpei Han,Jingren Zhou,Junyang Lin,Le Sun
### Background
近期大型语言模型（LLMs）在角色扮演应用方面显示出巨大的潜力。然而，评估这些模型的能力变得至关重要但同时也充满挑战。当前的基准测试大多采取以角色为中心的方法，将用户与角色的互动简化为孤立的问答任务，并未能反映真实世界的应用场景。
### Innovation
为了弥补这一局限，本文引入了RMTBench，这是一个全面的以用户为中心的双语角色扮演基准测试，包含80种多样化的人物角色和超过8,000轮对话。该基准测试结合了自定义角色和由简单特质定义的抽象角色，旨在评估用户场景中的表现。RMTBench根据用户的明确动机构建对话，而不是基于角色描述，确保与实际用户应用的对齐。此外，我们建立了一个真实的多轮对话模拟机制，结合精心选择的评估维度和基于LLM的评分，捕捉用户与角色之间对话的复杂意图。通过将评估中心从角色背景转向用户意图的实现，RMTBench弥合了学术评估与实际部署需求之间的差距，提供了一个更有效的评估LLMs角色扮演能力的框架。
### Conclusion
RMTBench通过多轮用户中心的角色扮演，提供了一个更有效的框架来评估大型语言模型的角色扮演能力。所有代码和数据集将很快发布，相关数据集可以在这个链接下载。
## 423. `cs.CL` - 词汇嵌入中的线性类比现象的起源 [PDF](https://arxiv.org/pdf/2505.18651), [HTML](https://arxiv.org/abs/2505.18651)
### Authors
Daniel J. Korchinski,Dhruva Karkada,Yasaman Bahri,Matthieu Wyart
### Background
词嵌入模型如Word2Vec和GloVe通过分析文本语料库中词组共现概率$P(i,j)$来构建词嵌入。生成的向量不仅对语义相似的词进行分组，还呈现出显着的线性类比结构，例如$W_{text{king}} - W_{text{man}} + W_{text{woman}} rightarrow W_{text{queen}}$。尽管观察到这种类比结构具有多种属性，但其理论起源仍然不明确。现有的观察结果表明，这些类比结构：(i)已经表现在矩阵$M(i,j) = P(i,j)/P(i)P(j)$的前几个主特征向量中，(ii)随着嵌入维度的增加而增强，(iii)通过使用$text{log} M(i,j)$而不是$M(i,j)$而增强，(iv)即使在从语料库中删除特定类比关系（如king-queen, man-woman）涉及的所有词对后仍然存在。
### Innovation
提出了一种理论生成模型，其中词由二元语义特征定义，共现概率来自基于特征的互作处理。该模型可以在理论上解释线性类比结构的出现，并为这些属性提供自然解释。此模型能够清晰地解析每个额外嵌入维度的作用，并且对不同形式的噪声具有鲁棒性，与Wikipedia和Mikolov等人引入的类比基准测量得出的共现统计结果高度吻合。
### Conclusion
该模型不仅可以解释词汇嵌入中存在的线性类比结构现象，而且可以通过主特征向量的性质分析来理解每个额外嵌入维度的贡献，并且模型具有较强的鲁棒性，可以应用于真实世界的语料库。
## 424. `cs.CL` - MLP Memory: 一种基于检索预训练的记忆模块用于大型语言模型 [PDF](https://arxiv.org/pdf/2508.01832), [HTML](https://arxiv.org/abs/2508.01832)
### Authors
Rubin Wei,Jiaqi Cao,Jiarui Wang,Jushi Kai,Qipeng Guo,Bowen Zhou,Zhouhan Lin
### Background
当前提升大规模语言模型的事实准确性和知识利用的现代方法面临一个根本性的权衡：非参数检索增强生成(RAG)方法虽然可以灵活地访问外部知识，但存在推理延迟高和浅层集成的问题，而参数微调方法如LoRA可能存在灾难性遗忘和一般能力下降的风险。
### Innovation
本文提出了一种轻量级参数模块MLP Memory，能够学习检索模式而无需显式访问文档。通过在预训练数据集上预训练一个多层感知器（MLP），使其模仿最近邻（$k$NN）检索器的行为，从而创建一个可微分的记忆组件，该组件以完全参数化的方式捕捉基于检索的知识访问的好处。将这种预训练好的MLP Memory与Transformer解码器简单地通过概率插值进行集成，从而在WikiText-103和Web数据集上分别获得17.5%和24.1%的效果提升，在五个问答基准测试中相对改进12.3%，在九个通用NLP任务上获得5.2分的绝对成绩提升，同时减少了最高10分的幻觉现象。此外，MLP Memory在性能上比RAG快2.5倍，提供优越的准确性。
### Conclusion
我们的研究结果表明，学习检索模式的参数方法能够弥合高效推理与有效知识访问之间的差距，为RAG和微调方法提供了一种实用的选择。
## 425. `cs.CL` - Memory Decoder: 一种预先训练的即插即用记忆组件 [PDF](https://arxiv.org/pdf/2508.09874), [HTML](https://arxiv.org/abs/2508.09874)
### Authors
Jiaqi Cao,Jiarui Wang,Rubin Wei,Qipeng Guo,Kai Chen,Bowen Zhou,Zhouhan Lin
### Background
大型语言模型（LLMs）在通用语言任务中表现出色，但将其适应特定领域仍然具有挑战性。当前方法，如领域适应预训练（DAPT），需要成本高昂的全程参数训练并且容易发生灾难性遗忘。同时，检索增强生成（RAG）由于昂贵的最近邻搜索和更长的上下文导致推理延迟增加。现有的这些方法都有明显的局限性，并没有很好地解决这一问题。为了克服这些挑战，本文引入了Memory Decoder，这是一种可在保持原始模型参数不变的情况下实现高效领域自适应的即插即用预训练记忆组件。
### Innovation
Memory Decoder 采用了小型的变压器解码器来模仿外部非参数检索器的行为。一旦训练完成，它就能与任何共享相同分词器的预训练语言模型无缝集成，无需进行模型特定的修改。实验结果表明，Memory Decoder 能够使得多种预训练模型（如 Qwen 和 Llama）在生物医学、金融和法律等三个特定领域表现出高度的有效适应性，平均每减少困惑度6.17点。该工作首次提出了一种专门针对领域特定适应的新型范式，并提供了一种插件方式的内存架构，能够在多个模型中一致地提升性能。
### Conclusion
Memory Decoder 引入了一种特殊预训练的记忆组件，能够实现高效和无缝的领域自适应。通过该组件，可以在不改变原始模型参数的情况下增强预训练语言模型在特定领域的性能，为解决现有方法中的问题提供了一种创新的解决方案。
## 426. `cs.CL` - 单人表决还是辩论：多代理大型语言模型中哪种方式更能做出更好决策？ [PDF](https://arxiv.org/pdf/2508.17536), [HTML](https://arxiv.org/abs/2508.17536)
### Authors
Hyeong Kyu Choi,Xiaojin Zhu,Sharon Li
### Background
多代理辩论（MAD）作为一种通过协作推理来提升大型语言模型性能的有前途的范式已逐渐显现。尽管近期取得了进展，但其有效性的关键驱动因素仍不清楚。本研究旨在探讨MAD的关键组成部分——多数投票和代理间辩论，分别评估它们的贡献。研究表明，多数投票在MAD的性能提升中发挥主要作用。为解释这一现象，研究提出一个理论框架，将辩论建模为一个随机过程，并证明它不会提升代理信念轨迹的期望准确性。这为解决MAD的有效性提供了理论依据。研究还展示了有针对性的干预措施的重要性，这些干预措施通过偏向于纠正来改善辩论的有效性。
### Innovation
本研究将MAD分解为两个关键部分——多数投票和代理间辩论，并评估它们的贡献。提出了一个理论框架，将辩论建模为一个随机过程，并证明它不会提升代理信念轨迹的期望准确性。提出了有针对性的干预措施，通过偏向于纠正来提高辩论的有效性。
### Conclusion
研究结果显示，虽然MAD具有潜力，但在许多实际应用中，简单的集成方法仍然是更可靠的选择。
## 427. `cs.CL` - LFD: 层融合解码以利用检索增强生成中的外部知识 [PDF](https://arxiv.org/pdf/2508.19614), [HTML](https://arxiv.org/abs/2508.19614)
### Authors
Yang Sun,Zhiyong Xie,Dan Luo,Long Zhang,Liming Dong,Yunwei Zhao,Xixun Lin,Yanxiong Lu,Chenliang Li,Lixin Zou
### Background
检索增强生成（RAG）将外部知识融入大型语言模型（LLMs），提高了它们对下游任务的适应性，并允许信息更新。令人惊讶的是，注入相关文档噪声反而可以增强利用外部知识的能力，并提高生成质量。这一现象虽然违反直觉且在实践中难以应用，但可以提供对LLMs如何整合外部知识的精细控制和严格分析。
### Innovation
本文通过对噪声注入进行干预，明确了LLM中的层次特化功能分界：浅层专注于局部上下文建模，中间层侧重于整合长距离外部事实知识，深层则主要依赖参数内部知识。基于此见解，提出了层融合解码（LFD）策略，直接将中间层表示与最终层解码输出融合以充分利用外部事实知识。通过引入内部知识评分（IKS）标准选取最优的中间层。
### Conclusion
多项基准实验结果表明，LFD有助于RAG系统更有效地展现检索的上下文知识，同时成本较低。
## 428. `cs.CL` - SpecEval：评估模型行为规范遵守情况 [PDF](https://arxiv.org/pdf/2509.02464), [HTML](https://arxiv.org/abs/2509.02464)
### Authors
Ahmed Ahmed,Kevin Klyman,Yi Zeng,Sanmi Koyejo,Percy Liang
### Background
当前，研发基础模型的公司会制定行为准则，宣称模型会遵守这些规则，但实际执行情况并不清楚。尽管像OpenAI、Anthropic和Google这样的供应商发布了详尽的规范描述，包括安全约束和品质特性，但却没有系统性地审计模型是否遵循这些规范。为了填补这一空白，作者提出了一个自动化框架，通过解析行为声明、生成有针对性的提示以及利用模型来判断是否遵守规定，重点在于三方一致性：供应商规范、模型输出和供应商模型的评估。
### Innovation
作者引入了一个自动化的评估框架，通过解析行为声明、生成针对性的提示和使用模型来判断模型是否遵守供应商的规范。该框架强调了供应商规范、模型输出和供应商模型评估三者之间的一致性，扩展了之前的双向生成验证一致性，从而建立了一个必要的基准：至少基础模型在供应商评估模型的判断下应满足开发者的行为规范。
### Conclusion
研究人员运用该框架对来自六个供应商的16个模型以及超过100个行为声明进行了评估，发现存在系统性不一致，包括多达20%的供应商合规缺口。这一结果表明，当前基础模型的规范遵守情况并不理想，需要进一步改进和监管。
## 429. `cs.CL` - 视觉接地：一种用于减少LVLMs幻觉的条件互信息校准解码策略 [PDF](https://arxiv.org/pdf/2505.19678), [HTML](https://arxiv.org/abs/2505.19678)
### Authors
Hao Fang,Changle Zhou,Jiawei Kong,Kuofeng Gao,Bin Chen,Shu-Tao Xia
### Background
大型视觉-语言模型（LVLMs）容易出现幻觉现象，即生成的回答虽然在语义上看似合理，但与输入图像几乎没有相关性。之前的研究表明，这个问题主要源于LVLMs过多依赖语言先验信息，而在解码过程中忽视了视觉信息。这种现象严重降低了模型的性能和可用性，尤其是在实现图像理解和生成任务时。
### Innovation
引入了一种新的条件点wise互信息（C-PMI）校准解码策略，该策略能够自适应地增强生成文本与输入图像之间的相互依赖关系，以减少幻觉。这个方法不同于现有的仅仅关注文本令牌抽样，而是考虑视觉和文本令牌对C-PMI的贡献，将幻觉缓解转化为一个双层优化问题，目标是最小化互信息之间的差距。为此，设计了一种令牌净化机制，动态地调整解码过程，确保抽样出的文本令牌与给定图像最为相关，并同时改进生成响应中最为相关图像令牌。实验表明，该方法显著减少了LVLMs中的幻觉现象，同时保持了解码效率。
### Conclusion
通过提出的解码策略显著降低了LVLMs中的幻觉现象，同时保持了高效的解码过程，验证了该方法的有效性，并在各个基准测试中得到了验证。
## 430. `cs.CL` - 多语言大语言模型的提示策略在医学英越机器翻译中的应用 [PDF](https://arxiv.org/pdf/2509.15640), [HTML](https://arxiv.org/abs/2509.15640)
### Authors
Nhu Vo,Nu-Uyen-Phuong Le,Dung D. Le,Massimo Piccardi,Wray Buntine
### Background
在越南，医疗英语-越语机器翻译（En-Vi MT）是医疗 доступ和沟通的关键，但越南语目前仍是一个资源稀缺且研究较少的语言。多语言大语言模型（LLM）显示出翻译潜力，但其在医疗领域的表现和训练策略尚未得到充分研究。
### Innovation
本研究系统地评估了六种不同参数量的多语言LLM（0.5B-9B参数）在MedEV数据集上的提示策略表现，包括零样本、少量样本和增词典提示，并与一个英越医学词汇表（Meddict）进行了比较。研究发现，模型的规模是决定性能的关键因素，更大的LLM在零样本情况下表现出色；少量样本提示仅带来边际提升；而术语感知提示和基于嵌入的示例检索则持续提高专业领域内的翻译质量。
### Conclusion
本研究的结果强调了多语言LLM在医学En-Vi MT中的潜力及其目前的局限性。
## 431. `cs.CL` - PersonaMatrix：一种面向用户的人格化法律摘要评估方法 [PDF](https://arxiv.org/pdf/2509.16449), [HTML](https://arxiv.org/abs/2509.16449)
### Authors
Tsz Fung Pang,Maryam Berijanian,Thomas Orth,Breanna Shi,Charlotte S. Alexander
### Background
法律文件通常很长、内容密集且难以理解，不仅对普通民众，而且对法律专家也是如此。自动化法律文件摘要化拥有改进法律知识获取的潜力，但现有的基于任务的评估方法忽视了不同的用户和利益相关者需求。因此，需要开发一种兼顾律师案例摘要的技术性和普通诉讼当事人访问性的评估工具。
### Innovation
提出了PersonaMatrix，这是一种基于六个人格的评价框架，通过法律和非法律用户的角度评估摘要。此外，还介绍了一个受控的维度偏移试点数据集，该数据集在美国民事权益案例摘要中变化，涵盖了深度、易用性和程序细节。同时，引出多样性覆盖率指数（DCI），以揭示基于人格感知和不基于人格感知的法官之间法律摘要的不同最优化。
### Conclusion
这项工作能够改进法律AI摘要系统，使其既适合专家用户，又适合非专家用户，有可能增加对法律知识的访问。代码库和数据已公开发布在GitHub上。
## 432. `cs.CL` - GPT-5在生物医学自然语言处理中的基准测试 [PDF](https://arxiv.org/pdf/2509.04462), [HTML](https://arxiv.org/abs/2509.04462)
### Authors
Yu Hou,Zaifu Zhan,Min Zeng,Yifan Wu,Shuang Zhou,Rui Zhang
### Background
生物医学文献和临床记录对自然语言理解提出了多元化挑战，主要包括精确的实体抽取、文档合成以及多步诊断推理等。现有的研究和技术尚未全面评估大型语言模型在多个核心生物医学自然语言处理任务中的表现，这些任务包括实体识别、关系抽取、多标签文档分类、摘要和简化等。此外，现有的研究通常未标准化测试策略，导致不同模型间的表现不易直接比较。
### Innovation
本研究提出了一个统一的基准来评估GPT-5和GPT-4o在无提示、单提示和五提示下的表现，覆盖了五个关键生物医学自然语言处理任务，并扩展了九个涵盖事实知识、临床推理和多模态视觉理解的生物医学问答数据集。使用标准化的提示、固定的解码参数和一致的推理管道，评估了模型性能、延迟和每正确预测的标准化成本。研究表明，GPT-5在推理密集型数据集上的表现优于GPT-4o，并在多模态问答方面表现出稳定的改进。尽管生成了更长的输出，GPT-5在预测的准确性和经济效率方面仍保持竞争力，特别是在诊断、治疗和推理子类型的细粒度分析上取得改善，但边界敏感的提取和证据密集型摘要仍然具有挑战性。
### Conclusion
GPT-5接近于可用于生物医学问答的部署性能，提供了一个可接受的准确、可解释性和经济效益之间的平衡。研究结果支持分层提示策略：直接提示适用于大规模或成本敏感的应用，而在复杂或高风险的情景中，应使用逐步思考框架，这强调了在关键精度和事实一致性要求下持续需要混合解决方案的重要性。
## 433. `cs.CL` - Text2Mem：一种统一的内存操作语言，用于内存操作系统 [PDF](https://arxiv.org/pdf/2509.11145), [HTML](https://arxiv.org/abs/2509.11145)
### Authors
Yi Wang,Lihai Yang,Boyu Chen,Gongyi Zou,Kerun Xu,Bo Tang,Feiyu Xiong,Siheng Chen,Zhiyu Li
### Background
大型语言模型代理在维持长时间互动时越来越依赖于记忆功能，但现有的框架仍然有限。大部分框架仅提供基本的操作，如编码、检索和删除，而像拼接、提升、降级、分割、锁定和过期等更高级的操作则缺乏或支持不一致。另外，没有正式且可执行的指令规范，导致各类系统在处理规则和生命周期方面表现出不确定的行为。
### Innovation
Text2Mem 提供了一种标准的操作语言，从自然语言到可靠执行提供了一条统一的路径。它定义了一套紧凑而表达力强的操作集，与编码、存储和检索对齐。每个指令都是一个基于 JSON 的 schema 实例，包含必要字段和语义不变量，并通过解析器转换为带有标准化参数的类型化操作对象。一个验证器确保在执行前正确性，配置适配器将类型化对象映射到 SQL 原型后端或真正的内存框架。当需要时，模型基础服务（如嵌入或总结）会被集成。所有结果通过统一的执行合同返回。该设计确保了跨异构后端的安全性、确定性和可移植性。此外，我们还概述了 Text2Mem Bench，这是一个计划中的基准测试，将模式创建与后端执行分离，以实现系统评价。
### Conclusion
这些组件共同建立了代理中第一个标准化的基础架构，用于记忆控制。
## 434. `cs.CL` - 扩散语言模型中的块级SFT：弥合双向关注与自回归解码之间的分歧 [PDF](https://arxiv.org/pdf/2508.19529), [HTML](https://arxiv.org/abs/2508.19529)
### Authors
Bowen Sun,Yujun Cai,Ming-Hsuan Yang,Yiwei Wang
### Background
离散扩散语言模型在文本生成方面展现了强大的潜力，但标准的监督微调（SFT）方法与其半自回归推断方式存在不匹配，导致梯度偏向于不太理想的序列概率，而不是所需的块状概率。传统的SFT方法在响应中随机遮蔽整个文本中的单词，而在推断过程中则是按固定大小分块顺序生成，这种不匹配会引入噪声前缀和泄露的后缀，从而创建梯度偏见，远离理想的块级似然度。
### Innovation
提出了块级SFT方法，该方法将响应划分为固定大小的块，每步选择一个激活块进行随机遮蔽，冻结所有先前的词元，并完全隐藏未来的词元。损失计算仅限于激活块，直接模拟块状解码过程。实验表明，在相同的计算资源或标记预算下，块级SFT在GSM8K，MATH和MetaMathQA等数据集上的表现优于传统SFT。进一步的研究和消融实验显示，改进的原因在于监督和推理的精度对齐，而不仅仅是偶然的遮蔽效果。这些结果突出强调了在扩散型语言模型中匹配监督粒度与解码过程的重要性。
### Conclusion
块级SFT方法在弥合扩散语言模型中的双向注意力与自回归解码之间的重要分歧方面取得了显著成效，实验结果表明这种方法能够直接提升模型的训练与推理一致性，从而在多个数据集上表现出更好的性能。
## 435. `cs.CL` - 基于约束 satisfaction 方法的 Wordle：新颖启发式方法和跨词库验证 [PDF](https://arxiv.org/pdf/2510.02855), [HTML](https://arxiv.org/abs/2510.02855)
### Authors
Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel
### Background
Wordle 提供了一个丰富的测试环境，可以用于解决约束满足问题 (CSP)。现有的求解器主要依赖于信息论熵最大化或基于频次的启发式方法，而未对约束进行正式处理。
### Innovation
该论文首次对 Wordle 进行了全面的 CSP 表述，引入了新颖的约束感知信息量计算方法（CSP-Aware Entropy）以及综合贝叶斯词频先验与逻辑约束的概率 CSP 框架。通过2,315个英文单词的评估，CSP-Aware Entropy 在平均猜测次数和运行时间上均优于现有方法。
### Conclusion
结合形式化 CSP 处理、约束感知启发式方法、概率逻辑集成、稳健性分析和跨词库验证，新的 CSP 方法在语言拼图求解领域建立了新的基准性能，证明了基于约束的求解技术优于经典的信息论和学习方法。
## 436. `cs.CL` - TianHui：针对多样化中医场景的专业大语言模型 [PDF](https://arxiv.org/pdf/2509.19834), [HTML](https://arxiv.org/abs/2509.19834)
### Authors
Ji Yin,Menglan He,Yujie Zhang,Linshuai Zhang,Tingting Ma,Ce Tian,Jie Wu,Lin Xu,Tao Jiang,  ((1) School of Intelligent Medicine, Chengdu University of Traditional Chinese Medicine, Chengdu, China (2) The Acupuncture and Tuina School, Chengdu University of Traditional Chinese Medicine, Chengdu, China (3) Center of Preventive Medicine, Hospital of Chengdu University of Traditional Chinese Medicine, Chengdu, China (4) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China (5) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China)
### Background
在研究环境中，针对传统中医（TCM）的专业大语言模型（Domain-specific LLMs）面临适用性受限、缺乏足够的评估数据集以及计算资源有限等挑战。这些因素限制了这类模型在TCM领域的广泛应用和发展。
### Innovation
本文提出了一种名为TianHui的专门针对TCM的大型语言模型，该模型通过上下文数据集成和领域知识融合的方式构建。研究团队构建了一个大规模的TCM语料库（包含0.97GB的无监督数据和611,312个问答对），并采用了一种两阶段的训练策略，包括QLoRA、DeepSpeed Stage 2和Flash Attention 2。该模型在12个基准测试中的表现非常出色，多项指标中排名靠前，并且还在其他基准测试中取得了最佳结果。通过优化配置，确定了最优参数为LoRA rank=128、alpha=256、epoch=4、dropout=0.2、最大长度=2048。这一工作通过TianHui模型有效保存和扩展了TCM的知识应用。
### Conclusion
TianHui在多种TCM场景中表现出色，能够系统地保存和扩展TCM知识的应用，并且所有资源已经开源。该模型的成功为TCM领域的研究和应用提供了有力支持。
## 437. `cs.CL` - WolBanking77：沃洛夫语银行语音意图分类数据集 [PDF](https://arxiv.org/pdf/2509.19271), [HTML](https://arxiv.org/abs/2509.19271)
### Authors
Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione
### Background
近年来，意图分类模型取得了显著进展，但大多数研究主要集中在高资源语言数据集上，这导致了低资源语言和高文盲率地区的研究缺口，这些地区更多使用口语而非书写语言。例如，在塞内加尔，沃洛夫语被90%的人口使用，但全国文盲率仍高达42%。沃洛夫语在西非地区实际上被超过1000万人使用。
### Innovation
本文介绍了沃洛夫语银行语音意图分类数据集（WolBanking77），填补了低资源语言和高文盲率地区的研究空白。WolBanking77数据集包括9,791句话（文本）和超过4小时的语音数据。为提升研究，本研究对比了NLP和ASR模型在这个数据集上的基线F1分数和字错误率。
### Conclusion
实验结果表明，WolBanking77数据集对于意图分类具有很高的研究潜力。该数据集及相应代码已发布，可供学术界使用。
## 438. `cs.CL` - 通过推测解码和NPU协调执行加速移动语言模型 [PDF](https://arxiv.org/pdf/2510.15312), [HTML](https://arxiv.org/abs/2510.15312)
### Authors
Zhiyang Chen,Daliang Xu,Haiyang Shen,Mengwei Xu,Shangguang Wang,Yun Ma
### Background
在移动设备上增强本地大语言模型（LLMs）通过利用本地数据的上下文信息，可以实现个性化和任务感知的生成，这为智能助手和UI代理等应用场景提供了动力。尽管在神经处理器方面的近期发展显著提高了移动设备上的填充效率，但逐个token的生成过程因为其内存绑定的特性仍然面临高延迟和硬件利用率低的问题。本文介绍了一种名为‘this http URL’的移动推理框架，该框架结合了推测解码和动态硬件调度，以加速移动设备上的上下文感知文本生成。通过减少解码延迟和处理并行度，该框架在多个智能手机和典型工作负载上展示了最高3.8倍的生成速度提升和4.7倍的能效改进，与现有的移动推理解决方案相比。
### Innovation
本文提出了一种移动推理框架，通过结合推测解码和动态硬件调度来加速移动设备上的上下文感知文本生成。具体包括三个方面：自适应执行调度、上下文对齐草稿和硬件友好的草稿扩展，这些组件能够动态平衡计算图分配，提高推测效率，并重用和扩展中间序列以提高处理并行度并减少验证成本。
### Conclusion
在多种智能手机和典型工作负载上的实验结果显示，该框架与现有移动推理解决方案相比，在生成速度上有了高达3.8倍的提升，在能效上 improved energy efficiency up to 4.7 times。组件级分析还进一步验证了每种优化的贡献。
## 439. `cs.CL` - 使用评分标准奖励治愈LLM数学推理中的奇迹步骤 [PDF](https://arxiv.org/pdf/2510.07774), [HTML](https://arxiv.org/abs/2510.07774)
### Authors
Youliang Yuan,Qiuyang Mang,Jingbang Chen,Hong Wan,Xiaoyuan Liu,Junjielong Xu,Jen-tse Huang,Wenxuan Wang,Wenxiang Jiao,Pinjia He
### Background
当前的大型语言模型（LLM）用于数学推理的训练通常采用结果导向的奖励机制，只奖励最终的答案。然而，这种机制容易导致模型通过不严谨的过程得出正确答案，增加模型推理能力的高估。研究人员观察到这种现象并发现了一些特征明显的失败模式，例如“奇迹步骤”——模型突然到达正确的输出，但缺乏有效的前置推导过程。这种现象表明，当前的奖励机制可能促使模型通过记忆直接召回答案，而非进行推导。为了克服这一问题，研究者引入了一个过程导向的奖励函数——评分标准奖励模型（RRM），该模型根据具体问题的评分标准评估整个推理过程，提供细粒度、可校准的奖励（0-1），明确惩罚逻辑错误并鼓励严谨的演绎。
### Innovation
研究者提出了一种新的奖励机制——评分标准奖励模型（RRM），在生成模型的基础上，RRM能够细粒度地评估推理过程并提供可校准的奖励，明确地惩罚逻辑错误并鼓励严谨的演绎。通过将RRM集成到强化学习流水线中，在四个数学基准测试中，基于RRM的训练比仅依赖最终结果的监督更有效。特别地，它显著提高了AIME2024验证通过率，并减少了“奇迹步骤”的发生率。
### Conclusion
奖励推理过程对于构建更准确和可靠的模型至关重要。通过使用基于评分标准的奖励模型，可以有效克服当前结果导向奖励机制的缺陷，提高模型的推理能力和可靠性。
## 440. `cs.CL` - KAT-Coder 技术报告 [PDF](https://arxiv.org/pdf/2510.18779), [HTML](https://arxiv.org/abs/2510.18779)
### Authors
Zizheng Zhan,Ken Deng,Xiaojiang Zhang,Jinghui Wang,Huaixi Tang,Zhiyi Lai,Haoyang Huang,Wen Xiang,Kun Wu,Wenhao Zhuang,Minglei Zhang,Shaojie Wang,Shangpeng Yan,Kepeng Lei,Zongxian Feng,Huiming Wang,Zheng Lin,Mengtong Li,Mengfei Xie,Yinghan Cui,Xuxing Chen,Chao Wang,Weihao Li,Wenqiang Zhu,Jiarong Zhang,Jingxuan Xu,Songwei Yu,Yifan Yao,Xinping Lei,C. Zhang,Han Li,Junqi Xiong,Zuchen Gao,Dailin Li,Haimo Li,Jiaheng Liu,Yuqun Zhang,Junyi Peng,Haotian Zhang,Bin Chen
### Background
近年来，大型语言模型（LLMs）的发展推动了代理性编程的进步，模型可以在交互式软件开发流程中自主推理、规划和执行。然而，从静态文本训练到动态现实世界的自主执行之间仍存在巨大差距。
### Innovation
该技术报告介绍了KAT-Coder，这是一个通过多阶段课程训练的大规模代理性代码模型，该课程包括中期训练、监督微调（SFT）、强化微调（RFT）以及强化到部署适配。中期阶段通过实际软件工程数据和合成代理交互提升推理、规划和反思能力，SFT阶段构建了融合多种编程语言和应用场景的数据集，RFT阶段引入了新的多基准奖励公式以优化稳定性和样本效率，最终使用错误遮蔽SFT和树结构轨迹训练，使模型适应生产级集成开发环境，实现了工具使用鲁棒性、指令对齐和长上下文推理等特性，构成了实现真实智能编码代理的基础。
### Conclusion
研究表明，这些训练阶段使KAT-Coder具备了强大的工具使用可靠性、指令对齐和长上下文推理能力，形成了现实世界智能编码代理部署的基础。KAT系列32B模型KAT-Dev已被开源发布。
## 441. `cs.CL` - 对模型规范进行压力测试揭示了语言模型的性格差异 [PDF](https://arxiv.org/pdf/2510.07686), [HTML](https://arxiv.org/abs/2510.07686)
### Authors
Jifan Zhang,Henry Sleight,Andi Peng,John Schulman,Esin Durmus
### Background
大型语言模型（LLMs）越来越多地从AI宪法和模型规范中训练，这些规范设定了行为准则和伦理原则。然而，这些规范面临诸如原则之间的内部冲突和不充分覆盖微妙场景等关键挑战。本文介绍了一种系统的压力测试方法，自动识别当前模型规范中存在的原则矛盾和解释性模糊问题。通过生成促使模型在竞争的价值原则之间显式权衡的场景，本文测试了当前模型规范。这些场景涵盖了模型在不能同时满足多个合理原则时的选择，通过构建综合分类法生成了多样化的价值权衡场景。研究评估了来自Anthropic、OpenAI、Google、xAI等主要提供商的十二种前沿LLM的响应，并通过价值分类评分衡量行为分歧。实证结果显示，模型行为的高度分歧强烈预测了模型规范中存在的潜在问题。通过定性分析，本文提供了当前模型规范中的多个实例问题，如直接矛盾和原则的解释性模糊。此外，生成的数据集还揭示了所有研究模型之间的明确失准案例和假阳性拒绝情况。最后，本文还提供了这些模型的价值优先级模式和差异。
### Innovation
本文提出了一种系统性方法，通过对特定场景的生成与分析，自动识别模型规范中的原则矛盾和解释性模糊问题。该方法使用综合分类法生成多样化的价值权衡场景，迫使模型在无法同时满足的合理原则之间做出选择。通过对十二种前沿LLM的评估，本文揭示了模型在行为上的显著分歧，这为理解当前模型规范中的潜在问题提供了重要见解。此外，生成的数据集也揭示了模型之间的失准和假阳性拒绝情况，进一步突出了规范设计中的关键挑战。通过这种方式，本文为优化和改进语言模型的行为提供了实际应用的指导和理论支持。
### Conclusion
本文的实证结果显示，模型行为中的高度分歧强烈预测了模型规范中存在的潜在问题。通过对模型规范中的直接矛盾和解释性模糊问题的详细分析，本文提供了大量实例和问题分类。同时，生成的数据集揭示了模型之间的明确失准和假阳性拒绝情况，进一步突显了模型规范设计中的关键挑战。最后，本文还总结了这些模型的价值优先级模式和差异，为改进和优化语言模型提供了宝贵的见解。
## 442. `cs.CL` - 您被拒！：大型语言模型参加招聘评估的实证研究 [PDF](https://arxiv.org/pdf/2510.19167), [HTML](https://arxiv.org/abs/2510.19167)
### Authors
Dingjie Fu,Dianxing Shi
### Background
随着互联网的普及和人工智能的迅速发展，领先的技术公司面临着每年对大量软件和算法工程师的迫切需求。为了有效地从成千上万的申请者中识别出高潜力的人选，这些公司建立了一套多阶段的选拔流程，其中包括标准化的招聘评估，以评估候选人是否具备岗位所需的具体技能。鉴于大型语言模型（LLMs）在编码和推理任务中的卓越表现，该研究探讨了一个关键问题：LLMs能否成功通过这些招聘评估？
### Innovation
研究团队利用最先进的大型语言模型生成回答，并对其进行评估，以探究LLMs在广泛使用的专业评估问卷中的表现。实证结果表明，所有评估的LLMs都无法通过招聘评估，这颠覆了人们对LLMs作为理想工程师的预期。这种实证研究为理解LLMs在复杂问题解决中的局限性提供了新的视角
### Conclusion
评估结果显示，所有参与者中的LLMs在通过招聘评估方面表现不佳。所有评估的LLMs无法成功通过招聘评估，这表明大型语言模型在面对复杂、具体的职业技能评估时存在显著的局限性。
## 443. `cs.CL` - NER模型扩展中的表示动力学诊断 [PDF](https://arxiv.org/pdf/2510.17930), [HTML](https://arxiv.org/abs/2510.17930)
### Authors
Xirui Zhang,Philippe de La Chevasnerie,Benoit Fabre(papernest)
### Background
在嘈杂的口语数据上扩展命名实体识别（NER）模型以识别新的个人身份信息（PII）实体是一个常见的需求。研究显示，同时调整一种预训练的BERT模型以识别标准语义实体（PER、LOC、ORG）和新的基于模式的PII实体（EMAIL、PHONE），可以对原始类别造成最小性能下降。
### Innovation
本文研究了这种两者能力的‘和平共存’，通过增量学习设置进行诊断，发现地名实体（LOC）特别脆弱。这种脆弱性归因于新PII实体与之共享模式特征（例如：邮政编码）。另有反向O标签表示漂移：模型最初将PII模式映射到'O'，阻止了新学习。这一问题可以通过解冻'O'标签分类器来解决，使背景类别适应并“释放”这些模式。这项工作对NER模型适应性进行了机制性诊断，强调了特征独立性、表示重叠和'O'标签可塑性。
### Conclusion
本文提供了一种诊断NER模型适应性的方法，揭示了特征独立性、表示重叠及'O'标签的可塑性，为future工作提供了理论基础和方法论支持。
## 444. `cs.CL` - Zhyper: 因子超网络用于条件化LLM微调 [PDF](https://arxiv.org/pdf/2510.19733), [HTML](https://arxiv.org/abs/2510.19733)
### Authors
M. H. I. Abdalla,Zhipin Wang,Christian Frey,Steffen Eger,Josif Grabocka
### Background
大型语言模型（LLM）的条件化是指指导LLM生成符合特定文化规范和价值观、特定政治倾向信念或其他指定语义条件的内容。不幸的是，提示工程并不能确保LLM行为符合所需的条件化要求，因为预训练和对齐数据集的归纳偏见。先前的研究主要通过直接调整LoRA权重进行LLM微调，但这种方法会引入大量参数。为了解决这个问题，本文提出了Zhyper，一种参数高效因子化超网络框架，可以从文本描述中生成上下文感知的LoRA适配器。实验结果表明，Zhyper在多个基准测试中的性能与最先进的基线相媲美，但参数量最多可减少26倍。此外，还将Zhyper扩展到文化对齐，表明其在跨领域设置中具有更好的泛化能力和对细粒度上下文值的更好捕捉能力。
### Innovation
本文提出了Zhyper，一种参数高效因子化超网络框架，能够从文本描述生成上下文感知的LoRA适配器。与直接调整LoRA权重的方法相比，Zhyper仅需少量参数即可实现与最先进的基线相当的性能，同时支持更有效的文化对齐。
### Conclusion
实验结果显示，Zhyper在多个基准测试中表现出与最先进的基线相媲美的性能，但在参数效率上具有显著优势；其在文化对齐方面也展示出了更好的泛化能力和对细粒度上下文价值的捕捉能力。
## 445. `cs.CL` - 通过模型合并适应代码混合任务的多语言模型 [PDF](https://arxiv.org/pdf/2510.19782), [HTML](https://arxiv.org/abs/2510.19782)
### Authors
Prashant Kodali,Vaishnavi Shivkumar,Swarang Joshi,Monojit Choudhary,Ponnurangam Kumaraguru,Manish Shrivastava
### Background
研究模型合并作为一种实用替代方法，用于代码混合自然语言处理的常规适应策略，基于多语言基础模型，进行持续预训练，合并检查点并进行微调，以解决下游任务数据。评估代码混合情感分类和仇恨言论分类任务中的英-印和英-西模型性能，展示了合并模型在F1分数上的一致性优势，优于完全微调和持续预训练后微调。进一步测试跨语言对的迁移训练，发现合并检查点相较于单一语言基线模型具有更强的迁移效果，表明代码混合知识是低资源语言对的更可靠的基底。
### Innovation
提出了模型合并作为适应代码混合任务的一种策略，与传统的持续预训练和完全微调策略相比，模型合并能够更有效地利用未标注数据，特别是在代码混合输入场景下，相比仅使用持续预训练，合并后的模型在F1分数上有了显著提升。此外，合并模型在跨语言对的迁移学习中表现更好，提供了适应代码混合任务的多种数据策略的方法，并讨论了跨更广泛任务和更大模型时的局限性与扩展性考虑。
### Conclusion
总结了代码混合任务适应的几种策略，并根据常见的数据范围（仅标记数据；标记加未标记数据；仅迁移学习）提出了相应的适应食谱，同时讨论了更大规模模型和更广泛任务的适应限制和扩展性考虑。
## 446. `cs.CL` - X-Reflect：跨模态反思提示在多模态推荐系统中的应用 [PDF](https://arxiv.org/pdf/2408.15172), [HTML](https://arxiv.org/abs/2408.15172)
### Authors
Hanjia Lyu,Ryan Rossi,Xiang Chen,Md Mehrab Tanjim,Stefano Petrangeli,Somdeb Sarkhel,Jiebo Luo
### Background
大型语言模型（LLMs）已被证明能够增强项目描述的丰富性，从而提高推荐系统的准确性。然而，大多数现有的方法要么依靠纯文本提示，要么使用基础的多模态策略，这些策略未能充分利用来自文本和视觉两种模态的互补信息。这篇文章介绍了一个新的框架，称为跨反射提示（X-Reflect），旨在通过提示多模态大型语言模型（MLLMs）明确识别和调和文本和图像之间支持性和冲突性信息来解决这些局限性。
### Innovation
该研究引入了一种新的提示框架——跨反射提示（X-Reflect），旨在通过提示多模态大型语言模型（MLLMs）明确识别和调和文本和图像之间支持性和冲突性信息，从而从两种模态中捕捉到细微的见解，生成更全面、更具上下文的相关项目表示。实验结果表明，该方法在下游推荐准确性方面优于现有的提示基线，并识别出文本-图像差异与推荐性能之间的U型关系，表明在多模态提示中适度使用模态信息的益处。
### Conclusion
该工作强调了多模态信息集成的重要性，并提供了一个提高多模态推荐系统中项目理解的有效解决方案。此外，通过使用关键词来总结图像内容，并用一个较小的模型替换基础模型，引入了X-Reflect-keyword变体，实现了近50%的输入长度减少，同时保持了竞争力。
## 447. `cs.CL` - MindForge：赋予理论认知以增强文化终身学习的实体代理 [PDF](https://arxiv.org/pdf/2411.12977), [HTML](https://arxiv.org/abs/2411.12977)
### Authors
Mircea Lică,Ojas Shirekar,Baptiste Colle,Chirag Raman
### Background
本领域的研究背景在于，基于大型语言模型的实体代理（如Voyager）在Minecraft等世界中表现出广泛的适应能力，然而，这些代理在经过特定领域微调后，仍然难以完成一些基础任务。因此，作者探索了一种文化终身学习框架下的生成代理体系——MindForge，旨在通过显性的视角切换来提升代理的适应能力。
### Innovation
MindForge提出的三个关键创新点包括：(1) 结构化的理论认知表示，关联知觉、信念、欲望和行为；(2) 自然的代理间通信；(3) 多组件记忆系统。
### Conclusion
在Minecraft中的测试表明，MindForge（以开源语言模型为动力）的代理在基本任务中显著优于Voyager版本，展示了如专家-新手知识转移、协作问题解决等复杂行为。此外，在完全合作设置下，随着沟通轮次增加，代理性能提升，这与策略定理相符。
## 448. `cs.CL` - Twilight: 随机逐级Top-$p$剪枝以实现自适应注意力稀疏性 [PDF](https://arxiv.org/pdf/2502.02770), [HTML](https://arxiv.org/abs/2502.02770)
### Authors
Chaofan Lin,Jiaming Tang,Shuo Yang,Hanshuo Wang,Tian Tang,Boyu Tian,Ion Stoica,Song Han,Mingyu Gao
### Background
利用注意力稀疏性加速具有长语境的大型语言模型(LLMs)已经成为研究热点。然而，现有的算法如稀疏注意或键值缓存压缩往往采用固定预算，这在实际部署中面临挑战，因为固定预算未能考虑到现实场景中准确性和效率之间的动态平衡可能有很大差异。
### Innovation
本文发现，采用Top-$p$采样(核采样)来调整稀疏注意力可以实现自适应预算。基于此，我们提出了Twilight框架，可以在不牺牲原有准确性的前提下，为任何现有的稀疏注意力算法引入自适应稀疏性。实证结果显示，Twilight可以在自注意力操作中最多剪枝98%的冗余令牌，并在长语境LLM解码过程中使端到端每令牌延迟加速15.4倍和自注意力操作加速3.9倍。
### Conclusion
Twilight框架通过结合自适应Top-$p$剪枝技术，无需牺牲原有算法的准确性，实现了对任何现有稀疏注意力算法的自适应稀疏性改进，在长语境LLM解码中显著提高了效率。
## 449. `cs.CL` - 为语音用户界面设计构建具有流动性的隐喻对话 [PDF](https://arxiv.org/pdf/2502.11554), [HTML](https://arxiv.org/abs/2502.11554)
### Authors
Smit Desai,Jessie Chin,Dakuo Wang,Benjamin Cowan,Michael Twidale
### Background
现有的语音用户界面（VUIs）设计往往依赖于静态的人类中心的隐喻，缺乏对不同情境和用户需要的适应能力。这些隐喻在塑造用户体验方面起着关键作用，但它们尚未充分利用这一潜力。
### Innovation
本文提出了‘具有流动性的隐喻设计’（Metaphor-Fluid Design），这是一种新颖的方法，能够根据对话使用情境动态调整隐喻表示。该研究还对比了这种设计方法与默认VUI的差异，后者通常围绕助手身份进行设计，提供统一的交互风格。
### Conclusion
研究发现，具有流动性的隐喻设计能够更好地满足不同情境下的用户期望，提高用户接受度、愉悦感和满意度。但个人在隐喻偏好上的差异也表明需要进行个性化设计。这些发现挑战了适用于所有情况的VUI设计模式，并展示了具有流动性的隐喻设计在创造更具适应性和互动性的用户-人工智能交互方面的潜力。
## 450. `cs.CL` - Face-Human-Bench: 用于多模态助手的面部和人类理解综合基准 [PDF](https://arxiv.org/pdf/2501.01243), [HTML](https://arxiv.org/abs/2501.01243)
### Authors
Lixiong Qin,Shilong Ou,Miaoxuan Zhang,Jiangning Wei,Yuhang Zhang,Xiaoshuai Song,Yuchen Liu,Mei Wang,Weiran Xu
### Background
面部和人类是社交互动中至关重要的元素，广泛出现在日常生活中的照片和视频中。因此，对面部和人类的理解将使多模态助手能够提高响应质量并扩大应用范围。然而，当前的多模态助手社区缺乏全面和科学的面部和人类理解能力评估。
### Innovation
本文首先提出了一个层级能力分类，包括三个层次的能力。然后基于此分类，收集了来自面部和人类领域公开可用数据集的图像和注释，并建立了一个半自动的数据管道来生成新的基准问题。此外，通过我们的Face-Human-Bench对25个主流的多模态大型语言模型进行了评估，专注于能力之间的相关性、目标相对位置对性能的影响以及Chain of Thought (CoT)提示对性能的影响。
### Conclusion
Face-Human-Bench包括一个开发集和一个测试集，每个集有1800个问题，支持英语和中文。同时，探索了多模态大型语言模型需要补充的专业模型能力。数据集和评估代码已公开可用。
## 451. `cs.CL` - RL真的能激励超出基模型的LLMs的推理能力吗？ [PDF](https://arxiv.org/pdf/2504.13837), [HTML](https://arxiv.org/abs/2504.13837)
### Authors
Yang Yue,Zhiqi Chen,Rui Lu,Andrew Zhao,Zhaokai Wang,Yang Yue,Shiji Song,Gao Huang
### Background
论文背景在于探讨了强化学习与验证奖励（RLVR）在增强大型语言模型（LLMs）的推理性能方面的潜力，尤其是数学和编程任务上取得了显著的成功。RLVR被期待使LLMs能够不断自我改进，获取超越基模型的新推理能力。因此，研究者系统地评估了RLVR训练模型的推理能力边界，使用较大的k值下的pass@k作为评估指标，发现当前训练设置未能引发新的推理模式，表明现有的RLVR方法尚未真正激发RL在LLMs中引出真正新颖推理能力的潜力。
### Innovation
创新点在于，研究团队通过系统的评估展示了RLVR在不同模型家族、强化学习算法和数学、编码和视觉推理基准测试中的表现，通过pass@k指标，使用较大的k值来衡量，表明当前RLVR方法未能激发真全新的推理能力。此外，研究还发现，模型蒸馏可以从教师模型中引入新的推理模式，真正扩展模型的推理能力。这揭示了需要改进RL范式，例如持续扩展和多回合的代理-环境交互，来解锁这一潜力。
### Conclusion
结论指出，当前的RLVR方法在激发LLMs中的新推理能力方面尚未达到理想效果。研究结果强调了需改进当前RL模型的必要性，以真正实现激发LLMs新型推理能力的目标。
## 452. `cs.CL` - MLMA：基于Mamba架构的多语种自动语音识别 [PDF](https://arxiv.org/pdf/2510.18684), [HTML](https://arxiv.org/abs/2510.18684)
### Authors
Mohamed Nabih Ali,Daniele Falavigna,Alessio Brutti
### Background
多语种自动语音识别（ASR）仍然是一项具有挑战性的任务，尤其是在平衡高低资源语言性能方面。最近的序列建模进展表明，超越变换器的架构可能在可扩展性和效率方面提供更好的表现。
### Innovation
本文介绍了MLMA（基于Mamba的多语种语言建模），该方法利用了Mamba架构——一种专为长上下文序列处理优化的高效状态空间模型。MLMA通过隐式地结合语言感知条件和共享表示来支持多样语言的稳健识别。实验表明，MLMA在标准多语种基准上的表现与基于变换器的架构相当，突显了Mamba作为可扩展、高效和准确多语种语音识别的潜在强大基础骨架的作用。
### Conclusion
MLMA在标准多语种基准上的实验结果表明其与基于变换器的架构相当，证明了Mamba架构在多语种ASR中的潜力和优势。
## 453. `cs.CL` - MIR-Bench：您的LLM能否通过多示例情境推理识别复杂模式？ [PDF](https://arxiv.org/pdf/2502.09933), [HTML](https://arxiv.org/abs/2502.09933)
### Authors
Kai Yan,Zhan Ling,Kang Liu,Yifan Yang,Ting-Han Fan,Lingfeng Shen,Zhengyin Du,Jiecao Chen
### Background
模式识别和应用的能力是通用智能的核心，心理学和AI研究者对其进行广泛研究。许多基准测试用于衡量大型语言模型（LLMs）的这种能力，但它们大多侧重于少样本设置（通常少于10个样本），并且缺乏对长上下文中的大量信息聚合的评估。另一方面，LLMs的上下文长度不断增加，带来了新的多示例情境学习（ICL）范式，它使用数百到数千个示例来解决新任务，无需昂贵且低效的微调。然而，多示例评估往往侧重于分类，而常见的长上下文LLMs任务如“针扎干草堆”（NIAH）通常不需要复杂的智能来整合大量信息。
### Innovation
为了弥补上述两个方面的问题，本文提出了MIR-Bench，这是第一个用于模式识别的多示例情境推理基准，它要求LLM通过输入输出示例预测来自具有多种数据格式的底层函数的结果。基于MIR-Bench，我们研究了多示例情境推理中的许多新问题，并获得了关于缩放效应、鲁棒性、归纳推理与演绎推理、检索增强生成（RAG）、编码进行归纳推理、跨域泛化性等许多洞察结果。
### Conclusion
通过MIR-Bench，我们深入研究了多示例情境推理中的多种问题，并获得了多个重要发现，包括缩放效应、鲁棒性、归纳推理与演绎推理的区别、检索增强生成（RAG）、编码进行归纳推理、跨域泛化性等。
## 454. `cs.CL` - RL Tango: Reinforcing Generator and Verifier Together for Language Reasoning [PDF](https://arxiv.org/pdf/2505.15034), [HTML](https://arxiv.org/abs/2505.15034)
### Authors
Kaiwen Zha,Zhengqi Gao,Maohao Shen,Zhang-Wei Hong,Duane S. Boning,Dina Katabi
### Background
近年来，强化学习（RL）已经成为增强大规模语言模型（LLM）推理能力的强大方法，其中LLM生成器由验证器（奖励模型）引导。然而，当前用于LLM的RL后训练方法通常使用固定的验证器（基于规则或冻结预训练）或通过监督细调（SFT）进行有区别的训练。这些设计容易受到奖励作弊的影响，并且在训练分布之外的泛化能力较差。
### Innovation
Tango是一个新颖的框架，它使用RL同时训练LLM生成器和验证器，采用交织的方式。Tango的主要创新在于它采用生成过程层次的LLM验证器，这种验证器通过RL训练并与生成器共同进化。验证器仅基于结果层次的验证正确性奖励进行训练，不需要明确的过程层次注释。这种通过RL训练的生成器验证器相比确定性和SFT训练的验证器在鲁棒性和泛化性能上表现出明显的优势，从而促进了生成器和验证器之间的有效相互强化。
### Conclusion
广泛的实验表明，Tango的两个组件在7B/8B规模的模型中都达到了最先进的结果：生成器在五个竞赛级别数学基准测试和四个具有挑战性的领域外推理任务上取得了最佳表现，验证器在ProcessBench数据集上表现出色。特别地，两个组件在最困难的数学推理问题上表现出显著的改进。
## 455. `cs.CL` - Superposition Yields Robust Neural Scaling [PDF](https://arxiv.org/pdf/2505.10465), [HTML](https://arxiv.org/abs/2505.10465)
### Authors
Yizhou Liu,Ziming Liu,Jeff Gore
### Background
今天的大型语言模型（LLMs）的成功取决于一个观察结果，即更大的模型表现更好。然而，这种神经缩放法的本质，即损失随模型大小呈幂律减少的原因仍然不清楚。论文提出，表示叠加现象，即LLMs比其维度更广泛地表示特征，可以是损失和神经缩放的关键促成因素。基于Anthropic的简化模型，研究通过重量衰减来控制叠加的程度，系统性地研究了损失如何随模型大小变化。结果表明，在弱叠加时，只有当数据特征频率呈幂律分布时，损失才遵循幂律；而在强叠加时，损失通常会与模型维度成反比，这归因于表示向量之间的几何重叠。我们证实开源LLMs运行在强叠加区域，并且损失遵循与模型维度成反比的趋势，Chinchilla缩放定律也与此行为一致。
### Innovation
论文提出了表示叠加现象作为神经缩放定律的主要驱动因素，通过Anthropic的简化模型，使用重量衰减控制叠加程度，系统研究了损失如何随着模型尺寸变化。提出了在弱叠加和强叠加情况下，损失遵循不同的幂律或反比规律的解释。进一步证实了开源LLMs和Chinchilla的行为符合这一理论
### Conclusion
研究结果确定表示叠加是神经缩放定律的核心驱动因素，为理解何时能改进和何时会破坏缩放律提供了洞察。表明开源LLMs和Chinchilla的缩放定律符合这一行为，为深入理解模型性能与叠加的关系提供了理论支持和实证依据。
## 456. `cs.CL` - SAFEPATH：通过早期对齐防止链式思考中的有害推理 [PDF](https://arxiv.org/pdf/2505.14667), [HTML](https://arxiv.org/abs/2505.14667)
### Authors
Wonje Jeung,Sangyeon Yoon,Minsuk Kahng,Albert No
### Background
大型推理模型（LRMs）已成为解决复杂问题的强大工具，但它们的结构化推理路径在面临有害提示时可能导致不安全的输出。现有的安全对齐方法可以降低有害输出，但会损害推理深度，特别是在复杂的多步任务中，它们仍然容易受到高级劫持攻击。
### Innovation
本文介绍了一种名为SAFEPATH的轻量级对齐方法，该方法通过在有害提示响应时向前推理发送一个短的8个标记的安全简介，从而对LRMs进行微调，而将其余推理过程不受监督。实验证明，SAFEPATH能够有效减少有害输出并保持推理性能。SAFEPATH相较于直接拒绝和SafeChain分别节省了295.9倍和314.1倍的计算资源。此外，该论文还引入了一个零样本变种，无需微调即可工作，还对现有LLM方法在推理为中心的模型上的应用进行了全面分析，揭示了关键缺口和新的安全AI方向。
### Conclusion
SAFEPATH通过利用早期对齐方法减少了有害输出，同时保持了推理性能。它在不具备有害回应的基准测试中表现突出，并且在处理现有模型的局限性方面提供了新的见解。
## 457. `cs.CL` - Sherlock: 自注意力自我纠正视觉语言模型中的推理 [PDF](https://arxiv.org/pdf/2505.22651), [HTML](https://arxiv.org/abs/2505.22651)
### Authors
Yi Ding,Ruqi Zhang
### Background
视觉语言模型(VLMs)在复杂多模态任务上表现出有希望的性能，但它们仍然面临重大挑战：对推理错误非常敏感，需要大量标注数据或准确的验证者，难以在特定领域之外泛化。
### Innovation
该研究探讨了自我纠正作为提升推理VLMS的一种策略。引入了Sherlock，一种包括轨迹级自我纠正目标、基于视觉扰动的偏好数据构建方法和动态β的自我纠正和自我改进训练框架，使模型在仅需较少的标注数据集后即可具备自我纠正的能力，并实现了在八个基准测试中的优异结果。
### Conclusion
Sherlock在没有外部监督的情况下，使用不到20%的标注数据，通过自我纠正和自我改进达到64.1的直接生成准确率和65.4的自我纠正后准确率。与LLaVA-CoT、Mulberry和LlamaV-o1相比取得了更好的表现。
## 458. `cs.CL` - 天生即为变换器——永远为变换器？关于预训练对架构能力的影响 [PDF](https://arxiv.org/pdf/2505.21785), [HTML](https://arxiv.org/abs/2505.21785)
### Authors
Mayank Jobanputra,Yana Veitsman,Yash Sarrof,Aleksandra Bakalova,Vera Demberg,Ellie Pavlick,Michael Hahn
### Background
变换器在序列到序列的任务中存在理论局限性，但尚不清楚这些局限性是否在大规模预训练的大模型中发挥作用，或者模型和预训练数据的规模是否使大模型能够有效克服这些限制。论文通过研究受Liu等人启发的家庭检索和复制任务，来探索这些架构限制在预训练后如何表现。
### Innovation
使用一个最近提出的长度泛化研究框架来确保每个研究设置的验证，并观察到预训练模型在检索任务中表现出正向诱导的优势而非反向诱导，这与理论上的长度泛化保证相关。机制性分析显示这种偏斜与预训练变换器内部正向诱导与反向诱导路径的强度差异有关。
### Conclusion
预训练选择性地增强了某些变换器能力，但并不能解决基本的长度泛化限制。
## 459. `cs.CL` - HauntAttack：当攻击随 reasoning 潜行时 [PDF](https://arxiv.org/pdf/2506.07031), [HTML](https://arxiv.org/abs/2506.07031)
### Authors
Jingyuan Ma,Rui Li,Zheng Li,Junfeng Liu,Heming Xia,Lei Sha,Zhifang Sui
### Background
新兴的大规模推理模型（LRMs）在数学和推理任务上表现出色，展示了出色的推理能力。但增强的推理能力和暴露的内部推理过程也带来了新的安全脆弱性。当推理与危害性交织时，是否会使得LRMs在推理模式下更容易遭受推理攻击？
### Innovation
本研究提出了名为HauntAttack的新颖且通用的黑盒对抗攻击框架，系统地将有害指令嵌入到推理问题中。通过对现有问题中的关键推理条件进行修改，创建指导模型逐步产生不安全输出的推理路径。研究在11种LRMs上进行了评估，发现平均每种模型的成功攻击率为70%，相较于最强的先前基线，攻击成功率提高了12个百分点。进一步分析表明，即使是最先进的安全对齐模型也高度易受基于推理的攻击，揭示了未来模型开发中推理能力和安全性平衡的迫切挑战。
### Conclusion
我们的研究结果显示，即便是先进的安全对齐模型也高度易受基于推理的攻击，这提示我们在未来模型开发中需要着重平衡推理能力和安全性。HauntAttack为推理安全领域带来了新的理解和启示，标志着该领域的研究进入了新的阶段。
## 460. `cs.CL` - Roboflow100-VL: 多域物体检测基准数据集用于视觉语言模型 [PDF](https://arxiv.org/pdf/2505.20612), [HTML](https://arxiv.org/abs/2505.20612)
### Authors
Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri
### Background
视觉-语言模型（VLMs）在互联网规模数据上训练后，能够实现令人惊讶的零样本检测性能，特别是在如汽车、卡车和行人的常见物体上。然而，最先进的模型仍然难以泛化到其预训练中未通常出现的分布外类别、任务和成像模态。当前的做法是简单地对VLMs进行更多的视觉数据训练，但本文提出了另一种方法，即利用包含少量视觉示例和丰富文本描述的注释指令对VLMs进行重新对齐。
### Innovation
本文引入了Roboflow100-VL，这是一个大规模的多模态物体检测数据集集合，包含100个不同概念，这些概念通常不在VLM的预训练中发现。作者评估了多种最先进的模型在零样本、少样本、半监督和完全监督设置下的表现，旨在比较不同数据集设置下的表现。结果显示，一些VLMs（如GroundingDINO和Qwen2.5-VL）在Roboflow100-VL中的复杂医学影像数据集上的零样本准确性低于2%，这突显了少样本概念对齐的需求。
### Conclusion
最后，作者讨论了CVPR 2025 Foundational FSOD竞赛，并分享了社区的见解。获胜团队的表现显著超越了基准，提升了17个mAP！所有代码和数据集均可在指定的网址获得。
## 461. `cs.CL` - BioCLIP 2: 通过层次对比学习扩展产生生物学意义的属性 [PDF](https://arxiv.org/pdf/2505.23883), [HTML](https://arxiv.org/abs/2505.23883)
### Authors
Jianyang Gu,Samuel Stevens,Elizabeth G Campolongo,Matthew J Thompson,Net Zhang,Jiaman Wu,Andrei Kopanev,Zheda Mai,Alexander E. White,James Balhoff,Wasila Dahdul,Daniel Rubenstein,Hilmar Lapp,Tanya Berger-Wolf,Wei-Lun Chao,Yu Su
### Background
大规模训练的基础模型会展现出非凡的新兴行为，超越初始训练目标学会新的能力。我们通过大规模对比视觉-语言训练在生物视觉模型中发现了这些新兴行为。为此，我们首先构建了包含2.14亿张生物图像的TreeOfLife-200M数据集，这是迄今为止最大和最多样化的生物有机体图像数据集。然后，我们训练了BioCLIP 2模型以区分不同的物种。尽管训练目标较为狭窄，BioCLIP 2在各种生物视觉任务（如栖息地分类和特征预测）中表现出卓越的准确性。我们确定了BioCLIP 2学习嵌入空间中的新兴属性。在物种间层面，不同物种的嵌入分布与功能和生态意义紧密对齐，例如喙的大小和栖息地。在物种内层面，内物种变异（如生命周期和性别）不仅未被削弱，反而在与物种间区分正交的亚空间中得到了更好的区分。我们提供了形式证明并进行了分析来解释层级监督和对比目标是如何促使这些新兴属性的生成。关键的是，我们的结果表明，随着训练数据规模的扩大，这些属性变得越来越重要，最终形成一个生物学上有意义的嵌入空间。
### Innovation
我们通过大规模对比视觉-语言训练在生物视觉模型中发现了新的能力，并构建了BioCLIP 2模型。该模型在生物视觉任务中的表现超出了训练目标，特别是在嵌入空间中显示出物种间的功能和生态对齐以及物种内更细致的区分。我们提供了形式证明和分析来解释这种现象背后的机制。此外，我们的研究揭示了随着训练数据量的增加，模型嵌入空间中的生物学意义属性变得越来越显著。
### Conclusion
这项研究探索了大规模训练下生物视觉模型的新兴行为，并通过BioCLIP 2模型展示了在生物视觉任务中生物学上具有重要意义的嵌入空间。这项成果为我们理解模型能力的转移及其内在机制提供了新的视角。
## 462. `cs.CL` - 思考更多真的总是有帮助吗？推理模型测时扩展的幻象 [PDF](https://arxiv.org/pdf/2506.04210), [HTML](https://arxiv.org/abs/2506.04210)
### Authors
Soumya Suvra Ghosal,Souradip Chakraborty,Avinash Reddy,Yifu Lu,Mengdi Wang,Dinesh Manocha,Furong Huang,Mohammad Ghavamzadeh,Amrit Singh Bedi
### Background
最近，推理模型（如OpenAI的o1和DeepSeek的R1）在测试时扩展推理的能力呈现出一种趋势，即通过提示（如“请等一下”或“让我再想想”）来延长推理过程可以提高模型的性能。这种现象促使人们认为，在测试时花费更多时间可以提高推理质量。然而，这一假设的真实性和效果仍有待验证。研究者们希望探究的是，是否延长测试时的思考过程能够始终改善模型的推理性能。有鉴于此，他们开展了一系列详细的实证研究，发现初始性能随着额外思考的增加会有所提升，但随后会由于过度思考而下降。此外，为了理解这种非单调趋势的原因，他们提出了一个简单的概率模型，揭示了额外思考会增加输出的不确定性，从而造成推理改善的错觉，最终却损害了精确性。
### Innovation
研究者们提出了一个名为“并行思考”的替代测时扩展方法，该方法受到Best-of-N采样的启发，在相同的推理预算内生成多条独立的推理路径，并通过多数投票选择最一致的响应，从而在测试时提高了准确度，最高可达20%的提升。该方法提供了一种简单而有效的机制，用于推理模型的测时扩展。这一创新方法区分了传统的测时扩展方法，并为如何有效利用推理预算提供了一种新的思考方式。
### Conclusion
测试时通过延长思考来扩展推理可能并不始终是提高模型推理性能的有效途径。相反，研究者提出了一种并行思考的新方法，该方法在相同的推理预算内生成多条独立的推理路径，并通过多数投票选择最一致的响应，从而提高了准确度。这一方法揭示了延长思考带来的改善可能更多的是表面的，在本质上，它更可能表明模型的不确定性与评估指标之间的关联，而不是真正的推理性能提升。
## 463. `cs.CL` - 当前人工智能会议模式不可持续！集中式人工智能会议危机诊断 [PDF](https://arxiv.org/pdf/2508.04586), [HTML](https://arxiv.org/abs/2508.04586)
### Authors
Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He
### Background
人工智能（AI）会议对于促进研究、分享知识和培养学术社群至关重要。然而，这些会议的迅速扩张使其集中的会议模式变得越来越难以维持。论文通过对数据的分析诊断出该模式面临结构性危机，威胁到了科学传播、平等和社区福祉等基础目标。本文指出了四个关键压力点：（1）科学上，每位作者的发表率在过去十年中翻了一番以上，每年超过4.5篇论文；（2）环境上，单个会议的碳足迹超过了举办城市的日均排放量；（3）心理上，71%的在线社区讨论反映了消极情绪，并且35%提及了心理健康问题；（4）从实际操作上，顶级会议如NeurIPS 2024的出席人数已经开始超出场地容量。这些压力表明该系统与核心使命不符。
### Innovation
论文提出了社区联邦会议（CFC）模式，将同行评审、展示和网络活动分离成为全球协调但本地组织的部分，旨在为AI研究提供一个更可持续、更具包容性和更具弹性的道路。
### Conclusion
当前的集中式AI会议模式已经不可持续，需要新的模式来改善现状。CFC模式通过分离会议功能，能够更好地适应不断变化的需求并促进AI社区的发展。
## 464. `cs.CL` - AssistedDS: 基准测试外部领域知识如何辅助LLM进行自动化数据科学 [PDF](https://arxiv.org/pdf/2506.13992), [HTML](https://arxiv.org/abs/2506.13992)
### Authors
An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding
### Background
大型语言模型（LLMs）已经推进了数据科学工作流的自动化。然而，尚不清楚它们是否像人类数据科学家那样能够有效利用外部领域知识。为了回答这个问题，我们引入了AssistedDS（辅助数据科学），一个旨在系统地评估LLMs在表格预测任务中如何处理领域知识的基准测试。AssistedDS包含具有显式已知生成机制的合成数据集以及现实世界的Kaggle竞赛，并附带了有用的和对抗性的文档库。这些文档提供了数据清洗、特征工程和模型选择的领域特定见解。我们评估最先进的LLMs在区分和应用有益于有害的领域知识方面的能力，评估提交的有效性、信息检索和预测性能。我们的结果显示了三个关键发现：（1）LLMs经常无批判地采用提供的信息，当引入对抗性内容时严重影响其预测性能；（2）有用的指导往往不足以抵消对抗性信息的负面影响；（3）在Kaggle数据集中，LLMs经常在处理时间序列数据、在不同折中一致应用特征工程以及正确解释分类变量方面出现错误。这些发现揭示了现有模型在评估和利用专家知识方面的重大差距，强调了开发更稳健、具有知识意识的自动化数据科学系统的必要研究方向。我们在此提供的数据和代码可以公开访问
### Innovation
我们提出了一种名为AssistedDS的新基准测试，用于系统地评估大型语言模型在处理表格预测任务中的领域知识。它结合了具有已知生成机制的合成数据集和现实世界的Kaggle竞赛，并附带了有用的和对抗性的文档。该研究测定了最先进的LLMs在区分和应用有益及有害的领域知识方面的能力，揭示了现有模型在处理与领域知识相关的复杂任务时的不足之处
### Conclusion
我们的研究表明，现有模型对领域知识的评价和利用仍有显著差距，尤其是在处理对抗性信息和复杂数据任务（如时间序列数据、特征工程和分类变量解释）方面的局限。这强调了开发更强大、具有知识意识的自动化数据科学系统的必要性，这些系统能够经受住对抗性信息的冲击。我们的数据和代码公开发布，为未来的研究提供了宝贵的资源。
## 465. `cs.CL` - ViSpec: 使用视觉感知推测性解码加速视觉语言模型 [PDF](https://arxiv.org/pdf/2509.15235), [HTML](https://arxiv.org/abs/2509.15235)
### Authors
Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen
### Background
推测性解码被广泛应用于加速大型语言模型（LLMs）的推理，但在视觉语言模型（VLMs）中的应用却相对较少，现有的方法只能实现较小的速度提升（不到1.5倍）。随着多模态功能在大规模模型中变得越来越重要，这一差距变得愈发显著。我们假设大型VLMs可以通过逐层过滤冗余图像信息，而不影响文本理解，而小规模的草稿模型则难以做到这一点。
### Innovation
我们提出了用于VLMs的视觉感知推测性解码（ViSpec）框架。ViSpec通过轻量级的视觉适配模块将图像标记压缩为紧凑表示，并将其无缝集成到草稿模型的注意力机制中，同时保留原始图像的位置信息。此外，ViSpec还为每个输入图像提取全局特征向量，并将其添加到后续的所有文本标记中，以增强跨模态的一致性。为了克服现有的多模态数据集中缺乏长辅助响应的问题，我们通过重新利用现有数据集并使用目标VLM生成扩展输出来创建了专门的训练数据集。
### Conclusion
广泛的实验验证了ViSpec的效果，据我们所知，这是首次在VLM推测性解码中实现显著的加速。代码已开放。
## 466. `cs.CL` - FlyLoRA: 通过隐式按秩混合-专家增强任务解耦和参数效率 [PDF](https://arxiv.org/pdf/2510.08396), [HTML](https://arxiv.org/abs/2510.08396)
### Authors
Heming Zou,Yunliang Zang,Wutong Xu,Yao Zhu,Xiangyang Ji
### Background
LoRA是一种广泛使用的参数高效细调方法，常用于基础模型，但存在参数干扰问题，导致性能不理想。尽管基于MoE的LoRA变体在单任务指令细调中减少了任务内相关性，但引入了额外的路由器参数，并且在多任务模型合并中对任务间干扰无效。
### Innovation
提出了FlyLoRA，这是一种基于MoE的隐式LoRA变体，引入了(1) 在上投影矩阵中的按秩专家激活，和(2) 一个隐式路由器，将专家路由与下投影统一，其中冻结的稀疏随机投影矩阵取代了传统的密集可训练版本。这种设计通过消除显式路由器的需要解决了任务内去相关与计算效率之间的权衡，同时由于随机矩阵的正交性内在地减轻了任务间干扰。
### Conclusion
在四个领域（通用知识理解、科学问题回答、数学推理和代码生成）进行了详尽的实验，展示了FlyLoRA相对于现有方法的一致性能提升。FlyLoRA突显了生物学结构如何启发AI技术的创新。
## 467. `cs.CL` - LLM-赋能自主软件工程中基准与解决方案的全面调查 [PDF](https://arxiv.org/pdf/2510.09721), [HTML](https://arxiv.org/abs/2510.09721)
### Authors
Jiale Guo,Suizhi Huang,Mei Li,Dong Huang,Xingsheng Chen,Regina Zhang,Zhijiang Guo,Han Yu,Siu-Ming Yiu,Pietro Lio,Kwok-Yan Lam
### Background
大型语言模型（LLMs）的引入推动了软件工程从传统的基于规则的系统向自主智能系统转变，这些系统能够解决复杂的工程问题。然而，系统的进展受到缺乏对基准与解决方案之间全面理解的限制。这项调查填补了这一空白，通过对过百篇近期论文的回顾，提供了一个综合分析框架，涵盖了解决方案和基准任务，揭示了从简单的提示工程到复杂智能系统的发展历程，并提出了一个统一流程图，展示了从任务说明到输出的整个工作流程，说明了不同解决方案如何应对不同难度的问题。
### Innovation
本文提出了一种新的分类体系，分为基于提示、微调和代理的解决方案以及一系列任务基准，如代码生成、翻译和修复，详细分析了从简单提示工程到复杂智能系统的进化过程，并建立起50多种基准与相应的解决方案策略之间的连接，使研究人员可以识别出适用于多样化评估标准的最佳方法。还指出了关键的研究空白，并提出了未来研究方向，如多智能体协作、自我进化的系统和形式验证的集成。
### Conclusion
本调查为进步LLM驱动的软件工程提供了基础指南。更新的评论和相关内容可以在该研究团队的GitHub仓库中找到。
## 468. `cs.CL` - 用于攻破基于推理的安全护栏的一系列技巧 [PDF](https://arxiv.org/pdf/2510.11570), [HTML](https://arxiv.org/abs/2510.11570)
### Authors
Shuo Chen,Zhen Han,Haokun Chen,Bailan He,Shengyun Si,Jingpei Wu,Philip Torr,Volker Tresp,Jindong Gu
### Background
近年来，大型推理模型（LRMs）的安全护栏，如反思对齐，表现出了强大的抵御‘牢笼逃脱’攻击的能力。通过利用LRMs的推理能力，这些护栏在用户输入生成最终响应前评估了输入的安全性。然而，研究发现这些基于推理的安全护栏容易受到输入提示的细微操纵，并可能导致更加有害的结果。
### Innovation
本文提出了一整套方法，以攻破基于推理的安全护栏，包括白盒、灰盒和黑盒设置，并涵盖从简单模板操纵到完全自动优化的各种攻击方法。这些方法的实现具备可扩展性，并且在不同基准测试上取得了惊人的高成功率（例如，在gpt-oss系列中的成功率超过90%），涉及本地主机模型和在线API服务。
### Conclusion
各领先的开源LRMs中发现这些漏洞具有系统性，这突显了为开源LRMs建立更强大的对齐技术以防止恶意使用的需求。研究成果已开源于链接 提供的github地址
## 469. `cs.CL` - 每一种注意力都重要：一种高效的长上下文推理混合架构 [PDF](https://arxiv.org/pdf/2510.19338), [HTML](https://arxiv.org/abs/2510.19338)
### Authors
Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou
### Background
该技术报告旨在介绍一种名为Ring-linear的模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0。这些模型采用了混合架构，有效结合了线性注意力和softmax注意力，主要用于长上下文推理场景，能够显著减少数据输入/输出和计算开销。
### Innovation
该研究提出了一种高效的混合架构，通过优化不同注意力机制的比例，确定了当前最佳模型结构；并且使用自研的高性能FP8算子库linghe，提高整体训练效率达50%。通过对训练和推理引擎操作的高度对齐，模型在强化学习阶段可以进行长期、稳定且高效的优化，保持在多个复杂推理基准测试中的SOTA性能。
### Conclusion
与具有320亿参数的密集模型相比，此系列模型将推理成本降低至1/10，并且相较于原始Ring系列的成本也降低了超过50%。通过系统探索混合架构中的不同注意力机制比例，已经找到了当前最优模型结构，同时也优化了模型的训练效率。
## 470. `cs.CL` - Deep Research Brings Deeper Harm [PDF](https://arxiv.org/pdf/2510.11851), [HTML](https://arxiv.org/abs/2510.11851)
### Authors
Shuo Chen,Zonggen Li,Zhen Han,Bailan He,Tong Liu,Haokun Chen,Georg Groh,Philip Torr,Volker Tresp,Jindong Gu
### Background
基于大型语言模型（LLMs）的深度研究（Deep Research）代理能够通过分解任务、检索在线信息和生成详细的报告来执行复杂的多步骤研究。然而，这样的强大能力也可能被滥用，特别是在涉及高风险和知识密集的生物安全等领域的研究中，可能会生成包含详细禁忌知识的专业报告。作者发现，仅仅提交一个有害查询，即便单个LLM直接拒绝，深度研究代理也能生成详细且危险的报告，这凸显了更高的风险并强调了更深入的安全分析的需求。
### Innovation
作者提出了一种新的 jailbreak 方法，包括 Plan Injection 和 Intent Hijack 战略，以应对 LLMs 犯罪方法在面对研究能力时的不足。实验结果揭示了三个关键发现：（1）在深度研究代理中，LLMs 的对齐通常会失败，有害提示以学术术语框架可以劫持代理意图；（2）多步骤规划和执行削弱了对齐，揭示了系统性漏洞，这些漏洞无法通过单一提示级别的保护措施解决；（3）深研究代理不仅绕过了拒绝，还产生了比单个LLM更连贯、专业化且危险的内容。
### Conclusion
这些发现揭示了在深研究代理中对齐的根本性错误，并呼吁开发针对深研究代理的更适合的对齐技术。已经准备了代码和数据集以供进一步研究使用。
## 471. `cs.CV` - 基于Fourier变换的ResNet50 GAN指纹检测 [PDF](https://arxiv.org/pdf/2510.19840), [HTML](https://arxiv.org/abs/2510.19840)
### Authors
Sai Teja Erukude,Viswa Chaitanya Marella,Suhasnadh Reddy Veluru
### Background
生成对抗网络（GAN）生成的逼真图像的迅速崛起，给图像取证以及需要可靠内容真实性的工业系统带来了严峻挑战。
### Innovation
该论文利用频域分析和深度学习相结合的方法，用于区分StyleGAN生成的图像和真实图像。具体而言，本文应用二维离散傅里叶变换（2D DFT）将图像转化为频域，在此频域中，可以检测到细微的周期性特征。然后，训练ResNet50神经网络以识别真实和合成的图像。实验结果表明，在频域模型的识别准确率达到了92.8%，AUC为0.95，远远优于在原始空间域图像上训练的等效模型。
### Conclusion
该方法表明GAN生成的图像具有独特的频域特征或“指纹”，凸显了将信号处理技术与深度学习结合以增强数字取证并加强工业AI系统的可信度的工业潜力。
## 472. `cs.CL` - ReDit: 改进大语言模型策略优化的奖励抖动 [PDF](https://arxiv.org/pdf/2506.18631), [HTML](https://arxiv.org/abs/2506.18631)
### Authors
Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu
### Background
DeepSeek-R1 通过其基于规则的奖励系统成功增强了大语言模型 (LLM) 的推理能力。尽管这是一种有效的奖励系统，能够有效缓解奖励劫持问题，但这些奖励函数通常是离散的。实验证据表明，离散奖励会导致梯度异常、优化不稳定和收敛缓慢的问题。为了解决这些问题，在训练大规模语言模型策略优化时，需要一种方法来平滑奖励信号并促进更有效的学习过程。传统的离散奖励系统产生不稳定梯度，使模型难以识别全局最优解并陷入局部最优解。鉴于此，本文提出了 ReDit (Reward Dithering)，即通过向离散的奖励信号中添加简单的随机噪声来平滑奖励信号的方法。这种抖动虽然引入了随机性，但可以使模型探索新的策略，防止陷入局部最优解，并提供连续的探索梯度，从而加快梯度更新和加速收敛。
### Innovation
ReDit (Reward Dithering) 方法通过简单的随机噪声扰动离散的奖励信号，这种方法不仅可以提供连续的探索梯度，促进更有效的梯度更新，还可以通过引入随机性鼓励模型探索新的策略，避免陷入局部最优解，使模型能够更顺畅地找到全局最优解。实验表明，ReDit 在多任务场景下表现优异，训练步骤减少约 10%，并且在相同的训练周期内仍然表现优于传统的 GRPO，提高 4%。此外，通过理论分析进一步验证了 ReDit 的优势。
### Conclusion
实验结果证明了 ReDit 的有效性和效率。与传统的 GRPO 方法相比，ReDit 可以以比传统方法少 10% 的训练步骤获得类似甚至更好的性能，特别是在任务多样化的场景下表现更为优异。此外，除了实验结果外，文中还提供了理论分析来支持 ReDit 的优势。这种方法在大规模语言模型策略优化中具有潜在的应用价值，并且能够在多个任务上提高模型的性能。
## 473. `cs.CV` - 基于鱼眼视角的统一检测管道在鲁棒交通监控中的对象检测 [PDF](https://arxiv.org/pdf/2510.20016), [HTML](https://arxiv.org/abs/2510.20016)
### Authors
Neema Jakisa Owor,Joshua Kofi Asamoah,Tanner Wambui Muturi,Anneliese Jakisa Owor,Blessing Agyei Kyem,Andrews Danyo,Yaw Adu-Gyamfi,Armstrong Aboah
### Background
鱼眼相机通过单一视角捕捉宽广视野，为大规模道路交通监控提供了一种高效解决方案。然而，鱼眼图像中固有的强烈径向失真和非均匀分辨率使得标准对象检测器在处理图像边界时面临重大挑战，因为这些区域的对象外观严重退化。
### Innovation
该论文提出了一种基于简单高效前处理和后处理管道的检测框架，以增强图像中不同区域的对象检测一致性，特别是针对严重失真的区域。通过训练多种当前最先进的检测模型并在鱼眼交通图像上进行集成，显著提高了总体检测准确性。
### Conclusion
该方法在其在2025年AI城市挑战赛第4赛道的F1分数为0.6366，排名62支队伍中的第8位，证明了其框架在解决鱼眼图像固有问题方面的有效性。
## 474. `cs.CV` - 通过在线标签平滑提高医学影像预测置信度 [PDF](https://arxiv.org/pdf/2510.20011), [HTML](https://arxiv.org/abs/2510.20011)
### Authors
Kushan Choudhury,Shubhrodeep Roy,Ankur Chanda,Shubhajit Biswas,Somenath Kuiry
### Background
深度学习模型，尤其是在医学图像分类方面，取得了显著成果。然而，这些模型常常表现出过度自信的预测，这在关键的医疗保健环境中可能削弱其可靠性。传统的标签平滑提供了一种简单的解决方法来减少这种过度自信，但它未能考虑类别之间的关系，因为它将所有非目标类别同等处理。
### Innovation
研究探索了在线标签平滑（OLS）的使用，这是一种动态方法，在训练过程中根据模型自身的预测模式调整软标签。评估使用了大规模的RadImageNet数据集和三种广泛使用的架构：ResNet-50, MobileNetV2, 和 VGG-19。结果表明，与标准训练方法（包括硬标签、传统标签平滑和无教师的知识蒸馏）相比，OLS在Top-1和Top-5分类准确性上表现出一致的改进。此外，OLS还导致更紧凑且区分更好的特征嵌入，表明改进了表示学习。
### Conclusion
这些发现表明，OLS不仅加强了预测性能，还提高了校准，使其成为在医学成像领域开发可信赖AI系统的实用且有效的解决方案。
## 475. `cs.CV` - 使用对比学习变换多视角3D形状特征 [PDF](https://arxiv.org/pdf/2510.19955), [HTML](https://arxiv.org/abs/2510.19955)
### Authors
Márcus Vinícius Lobo Costa,Sherlon Almeida da Silva,Bárbara Caroline Benato,Leo Sampaio Ferraz Ribeiro,Moacir Antonelli Ponti
### Background
计算机视觉方法在从2D图像识别3D物体时存在困难，通常需要大量标注数据和依赖卷积神经网络（CNNs），这可能导致忽视重要的形状关系。代表学习3D形状特征的挑战需要更好的方法来捕捉全局形状语义和局部区分特征。现有的基于CNN的方法在处理多视图3D分析时遇到瓶颈，尤其是在标注数据稀缺和形状关系难以捕捉的情况下。
### Innovation
本文通过使用基于ViT的架构并配以现代对比学习目标，解决3D形状特征的表示学习挑战。表明了这种方法在ModelNet10等下游任务中获得了令人鼓舞的结果，特别是在多视图3D分析方面。利用ViTs理解和捕捉整体形状的能力，以及对比学习的有效性，从而克服了需要大量标注数据和CNN捕捉关键形状关系的限制。这一方法在于通过ViTs捕捉全局形状语义并通过对比优化精炼局部区分特征。结果显示，这种方法在对比损失监督方面达到了约90.6%的准确率。
### Conclusion
本文方法的关键在于验证了结合ViT和对比学习目标在3D表示学习中的有效性，这种方法不仅改进了3D几何对象的表示能力，而且减少了对大量标注数据的需求。
## 476. `cs.CV` - FutrTrack: 一种基于相机-激光雷达融合的3D多目标跟踪变换器 [PDF](https://arxiv.org/pdf/2510.19981), [HTML](https://arxiv.org/abs/2510.19981)
### Authors
Martha Teiko Teye,Ori Maoz,Matthias Rottmann
### Background
近年来，相机和激光雷达在多目标跟踪中的应用日益广泛。现有的3D检测方法虽然能够识别物体，但在跟踪和融合不同传感器数据时存在一些挑战。本文探讨了如何通过引入基于变压器的平滑器和融合驱动的追踪器来改进现有的3D检测框架。实验结果表明，基于查询的变压器追踪方法在多传感器融合特征的辅助下，相比于之前单传感器的方法，有显著的优势。
### Innovation
本文提出了一种模块化的相机-激光雷达多对象跟踪框架FutrTrack，该框架基于现有的3D检测体系，在此基础上引入了变压器结构的平滑器和融合驱动的追踪器。FutrTrack采用了基于查询的双阶段变压器精炼和追踪流水线，能够利用来自多个相机和激光雷达的多模态视角融合特征，无需显式的运动模型。此外，它还能够在遮挡和视角变化的情况下，通过几何和语义线索实现鲁棒的再识别。
### Conclusion
FutrTrack克服了数据稀少和不需要预训练的挑战，通过多模式传感器融合特征的引入，在nuScenes和KITTI数据集上的测试结果表明，该方法不仅能够减少身份切换，还能保持与基于神经网络的其他方法相当的准确性。这为基于变压器的追踪器提供了高效框架，使其能够与其他基于神经网络的方法竞争，即使在数据有限的情况下也不例外。
## 477. `cs.CV` - Endoshare: 开源解决方案以去标识化和管理手术视频 [PDF](https://arxiv.org/pdf/2510.20087), [HTML](https://arxiv.org/abs/2510.20087)
### Authors
Lorenzo Arboit,Dennis N. Schneider,Britty Baby,Vinkle Srivastav,Pietro Mascagni,Nicolas Padoy
### Background
基于视频的评估及手术数据科学能够促进手术培训、研究及质量提升，但其广泛应用受限于视频录制格式的异质性和与视频共享相关的隐私问题。
### Innovation
Endoshare 是一个开源、跨平台的应用程序，用于合并、标准化和匿名处理内镜手术视频。该应用通过软件开发生命周期与迭代用户中心反馈进行开发，采用了隐私设计的核心架构。
### Conclusion
Endoshare 提供了一个透明且用户友好的标准化、隐私保护手术视频管理管道。为确立其作为可替代专有系统的部署方案，仍需进行符合性认证和更广泛的互操作性验证。该软件可在该网站获取。
## 478. `cs.CV` - BrainPuzzle:杂波驱动与物理驱动重建的混合方法用于颅内超声CT [PDF](https://arxiv.org/pdf/2510.20029), [HTML](https://arxiv.org/abs/2510.20029)
### Authors
Shengyu Chen,Shihang Feng,Yi Luo,Xiaowei Jia,Youzuo Lin
### Background
由于头骨和大脑组织之间声速的差异以及将大型探头耦合到头骨的难度，颅内超声成像仍具有挑战性。传统的基于物理的全波形反演（FWI）方法受限于由头骨引起的衰减、模式转换和相位偏差造成的弱信号，以及由于全孔径阵列在临床上的不切实际而产生的不完整的空间覆盖。相比之下，从原始超声数据直接学习的纯数据驱动方法往往无法模拟通过骨骼的复杂非线性和非局部波传播，导致在低信噪比和稀疏孔径条件下重建的声速图在解剖上合理但数量上偏倚。
### Innovation
我们提出了一种混合的两阶段框架BrainPuzzle，结合了物理建模和机器学习。第一阶段使用逆时差成像将多角度采集的数据转化为迁移片段，即使在信噪比低的情况下也能保留结构细节。第二阶段，一种基于变压器的超分辨率编码解码器，结合基于图的注意力单元（GAU），将这些片段融合成一个完整且数量上准确的声速图。一种使用可移动低计数换能器阵列的部分阵列采集策略，提高了实用性和耦合性，而混合算法弥补了缺失的孔径。
### Conclusion
在两个合成数据集上的实验表明，BrainPuzzle实现了更高的声速重建精度和图像完整性，展示了其在推进定量超声脑成像方面的潜力。
## 479. `cs.CV` - 事件驱动图像重构的基于滤波的方法 [PDF](https://arxiv.org/pdf/2510.20071), [HTML](https://arxiv.org/abs/2510.20071)
### Authors
Bernd Pfrommer
### Background
从移动事件相机的事件中重建强度图像是一项具有挑战性的任务，通常使用部署在图形处理单元上的神经网络来解决。
### Innovation
该论文提出了一种更简单的方法——基于滤波的异步重构方法（FIBAR）。该方法首先使用数字IIR滤波器整合由事件信号的强度变化；通过新颖的算法检测旧像素，并结合高斯滤波器模糊处理这些旧像素，以减少重建噪声。FIBAR是异步的，并允许在任意时间点读取图像，它在现代笔记本电脑CPU上可以每秒处理42（不启用空间滤波器的情况下140）百万事件。
### Conclusion
虽然FIBAR的重建结果比基于神经网络的方法更噪，且存在鬼影图像的问题，但它足够用于检测一些特定的任务，如尺规标记的检测。
## 480. `cs.CV` - 超视图：用于生成未知分布摄像机姿态新视图的3D高斯采样滤波器 [PDF](https://arxiv.org/pdf/2510.20027), [HTML](https://arxiv.org/abs/2510.20027)
### Authors
Damian Bowness,Charalambos Poullis
### Background
当从与训练数据分布显著不同的相机位置查看3D高斯采样（3DGS）模型时，常见的视觉噪声显著增加。这些缺陷是由这些外推区域缺乏训练数据引起的，导致模型在这些区域对密度、颜色和几何形状的预测存在不确定性。现有的方法在处理此类问题时往往依赖于重新训练或精细调校，这不仅过程复杂，还可能导致时间和资源的巨大浪费。论文分析了现有方法的局限性，并指出现有Neural Radiance Field（NeRF）方法如BayesRays所面临的挑战，这些方法在处理超出训练数据分布的新视图合成时效果不佳或需要额外的后处理步骤。
### Innovation
提出了一个新颖的实时渲染感知滤波器方法。与之前方法相比，该方法利用从中间梯度中派生的敏感性得分，明确针对由各向异性方向引起的不稳定性问题，而不是均匀方差问题。这种方法直接解决了生成不确定性的核心问题，使得3D重建系统即使在用户自由导航到原始训练视角之外，也能保持高度的视觉保真度。与现有的基于NeRF的方法如BayesRays相比，所提出的方法显著提高了视觉质量、真实性和一致性。此外，该滤波器可以无缝集成到现有的3DGS渲染管道中，无需进行额外的后处理或调优。
### Conclusion
通过实验评估，证明了所提出方法在视觉质量、真实性和一致性方面的显著改进。与现有的基于NeRF的方法相比，该方法在实际应用中具有更高的实时性和集成性。这种方法的提出和实现解决了现有方法在处理未知分布摄像机姿态的新视图合成时的局限性，为未来的3D重建和合成应用提供了有力支持。
## 481. `cs.CV` - 暴露盲点：生成图像模型中的文化偏差评估 [PDF](https://arxiv.org/pdf/2510.20042), [HTML](https://arxiv.org/abs/2510.20042)
### Authors
Huichan Seo,Sieun Choi,Minki Hong,Yi Zhou,Junseo Kim,Lukman Ismaila,Naome Etori,Mehul Agarwal,Zhixuan Liu,Jihie Kim,Jean Oh
### Background
先前的研究主要关注文本到图像(T2I)系统中的文化偏差，而图像到图像(I2I)编辑器则被忽略了。该研究通过覆盖六个国家、8个大类和36个小类的评估体系以及时代意识的提示，填补了这一空白。使用标准化的评估方案，该研究评估了T2I生成和I2I编辑的表现，并揭示了文化偏差的具体表现和趋势。
### Innovation
该研究创新之处在于引入了一个统一的文化偏差评估框架，包括跨国家、跨时代和跨类别的评估。研究结合了标准自动评估指标、文化意识检索增强QA以及来自本土审查者的专家评价。为了便于研究结果的验证和重复，研究还公开了所用的数据集、提示和配置参数。
### Conclusion
研究揭示了三个主要发现：(1) 无特定国家提示时，模型偏向于展示全球北方、现代取向的描述，这抹杀了不同国家之间的差异；(2) 迭代的I2I编辑降低了文化忠实度，即使传统指标保持不变或有所提升；(3) I2I模型使用表面特征（色彩、通用道具）而非与时代一致和上下文相关的改变，经常保留源图像的身份，特别是在针对全球南方的目标图像中。研究结果表明，当前的生成图像模型中的文化敏感性编辑仍然不可靠，通过公开标准化的数据、提示和人类评估协议，本研究提供了文化中心的基准，有助于诊断和追踪生成图像模型中的文化偏差。
## 482. `cs.CV` - 数据自适应变换双边张量核表示及其在聚类中的应用 [PDF](https://arxiv.org/pdf/2510.20077), [HTML](https://arxiv.org/abs/2510.20077)
### Authors
Hui Chen,Xinjie Wang,Xianchao Xiu,Wanquan Liu
### Background
张量低秩表示（TLRR）在图像聚类中取得了显著的成功。然而，大多数现有的方法依赖固定的变换，并且在噪声鲁棒性方面表现较差。
### Innovation
提出了一个新模型，即自适应变换双边张量低秩表示（TBTLRR），通过学习任意单位变换引入数据自适应张量核范数，更好地捕捉全局相关性。同时，TBTLRR利用潜在张量数据的双边结构来利用图像样本和特征之间的局部相关性。此外，TBTLRR还通过引入$boldsymbol{boldsymbol{frac{1}{2}}}$-范数和Frobenius范数正则化项来更好地处理实际场景中的复杂噪声。为了解决提出的非凸模型，开发了一种基于交替方向乘子法（ADMM）启发的有效优化算法，并提供了理论收敛性分析。
### Conclusion
大量的实验验证了TBTLRR在聚类中的优越性，优于最先进的方法。代码将在此处提供：this https URL。
## 483. `cs.CV` - StableSketcher: 通过视觉问答反馈增强基于像素的手绘草图生成的扩散模型 [PDF](https://arxiv.org/pdf/2510.20093), [HTML](https://arxiv.org/abs/2510.20093)
### Authors
Jiho Park,Sieun Choi,Jaeyoon Seo,Jihie Kim
### Background
尽管近年来扩散模型在生成图像的质量上取得显著进步，但在合成基于像素的手绘草图方面仍面临挑战。手绘草图是抽象表达的典型代表。为此，本文提出了StableSketcher，一种新的框架，使扩散模型能够生成高精度描述的草图。
### Innovation
在该框架中，我们对变分自编码器进行了微调以优化潜在编码，使其能够更好地捕捉草图特征。同时，我们引入了一种基于视觉问答的新奖励函数，用于强化学习，以提高文本-图像对齐和语义一致性，从而显著改善了草图的风格保真度。此外，我们提出了一种名为SketchDUO的新数据集，这是第一个包括实例级别的草图及其描述和问答对的数据集，解决了现有依赖于图像-标签对数据集的限制。
### Conclusion
广泛的实验表明，StableSketcher生成的草图在风格保真度上有所提高，并且与提示的对齐程度优于Stable Diffusion基线。此外，我们还提供了一个开源的代码和数据集。
## 484. `cs.CV` - 注意力卷积：结合自注意力的表达能力和卷积的效率 [PDF](https://arxiv.org/pdf/2510.20092), [HTML](https://arxiv.org/abs/2510.20092)
### Authors
Hao Yu,Haoyu Chen,Yan Jiang,Wei Peng,Zhaodong Sun,Samuel Kaski,Guoying Zhao
### Background
自注意（SA）已成为现代视觉骨干的重要基石，因其强大的表达能力超越了传统的卷积（Conv）操作。然而，自注意的二次复杂度仍然是实际应用中的关键瓶颈。尽管卷积具有线性复杂度和强大的视觉先验，但人们一直在努力促进其复兴。然而，性能差距依然存在，表明这些改进尚未捕捉到自注意固有的独特表达能力。
### Innovation
本文重新审视了CNN设计，通过‘自适应路由’和‘横向抑制’两大基本洞察揭示了自注意在表达上的优越性。基于此，提出了注意力卷积（ATConv），一个基于这些原理重新构想的卷积操作，仅用3×3内核，在基本视觉任务中也表现出优越性。在此基础上，引入了AttNet家族网络，在ImageNet-1K上实现了84.4%的Top-1准确率，仅需27M参数。在基于扩散的方法中生成图像时，使用提出的3×3 ATConv替代所有自注意机制，在SiT-XL/2下400k步骤中将ImageNet FID降低了0.15，并实现更快的采样。
### Conclusion
注意力卷积（ATConv）是一个结合了自注意表达能力和卷积效率的基本卷积操作重构，仅用3×3内核在基本视觉任务中就实现了优于各种自注意力机制的表现。基于ATConv的AttNet家族网络在同样的计算量下实现了突破性的性能提升，展示了显著的应用潜力。
## 485. `cs.CV` - 基于物理的融合方法实现鲁棒快速移动小对象的3D跟踪 [PDF](https://arxiv.org/pdf/2510.20126), [HTML](https://arxiv.org/abs/2510.20126)
### Authors
Prithvi Raj Singh,Raju Gottumukkala,Anthony S. Maida,Alan B. Barhorst,Vijaya Gopu
### Background
虽然计算机视觉在通用对象检测和跟踪方面取得了显著进展，但快速移动的小目标的检测和跟踪问题仍然较少探索。本文探讨了利用RGB-D相机解决快速移动小目标的检测与跟踪问题，结合深度学习检测与物理跟踪算法，弥补现有方法的不足，并提出了针对遮挡和快速方向变化等复杂场景的稳健解决方案。
### Innovation
本文贡献包括：1、针对3D空间中快速移动小目标的检测与跟踪的设计全面系统；2、一种创新性的基于物理的跟踪算法，结合了运动学方程来处理异常值和遗漏检测；3、一个异常检测与修正模块，在面对遮挡和快速方向变化等挑战场景中显著提升了跟踪性能。与基于卡尔曼滤波的跟踪器相比，本系统在平均位移误差方面降低至70%以下，展示了现有方法与物理模型结合的实时3D检测和跟踪的有效性。
### Conclusion
本系统在自动平台上增强了机器人感知能力，并展示了基于物理和深度学习结合的实时3D检测与跟踪方法对难以捕捉的小目标的有效性。
## 486. `cs.CV` - BIOCAP：在生物基础模型中利用合成描述性标题超越标签 [PDF](https://arxiv.org/pdf/2510.20095), [HTML](https://arxiv.org/abs/2510.20095)
### Authors
Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu
### Background
现有研究中，生物多模态基础模型使用监督的主要来源是标签，而描述性标题则较少被利用。本文通过对描述性标题的研究，考虑将其作为生物多模态基础模型的额外监督来源。图像和描述性标题可以视为来自物种潜在形态空间的互补样本，每个都捕捉特定的生物特性。在训练过程中加入描述性标题，有助于与其他共享的潜在结构保持一致，在强调潜在诊断特征的同时抑制虚假相关性。然而，这一过程面临的挑战是大规模获取准确且实例特定的描述性标题。这限制了自然语言在有机生物学领域的应用，相比于其他许多科学领域较为有限。
### Innovation
本文通过生成与维基百科信息和分类学特定格式示例相辅相成的合成描述性标题，采用多模态大型语言模型（MLLMs），构建了合成描述性标题指导下的BIOLIP模型，即BIOCAP。该模型通过使用这些描述性标题训练而成，具有丰富的语义理解能力，且在物种分类和图文检索任务上取得了优异性能。这一创新不仅展示了描述性标题在促进生物图像与多模态基础模型的联系上具有价值，还补充了自然语言在有机生物学中的应用短板，提升了多模态基础模型的训练和应用效果。
### Conclusion
使用合成描述性标题训练的BIOCAP在生物图象与多模态基础模型的联系方面显示出了比传统标签训练更高的价值。通过优化生成的描述性标题，本文方法提升了生物多模态基础模型的性能，同时也为未来研究提供了新的思路和技术支持。
## 487. `cs.CV` - PartNeXt: 一种用于细粒度和层次化3D部件理解的下一代数据集 [PDF](https://arxiv.org/pdf/2510.20155), [HTML](https://arxiv.org/abs/2510.20155)
### Authors
Penghao Wang,Yiyang He,Xin Lv,Yukai Zhou,Lan Xu,Jingyi Yu,Jiayuan Gu
### Background
理解物体及其组成部分对于推进计算机视觉、图形和机器人技术至关重要。尽管像PartNet这样的数据集推动了3D部件理解的进步，但它们依赖于无纹理的几何形状和专家依赖的标注，这限制了其可扩展性和实用性。
### Innovation
PartNeXt引入了一个新的数据集，解决了上述不足之处，其中包括超过23,000个高质量、带纹理的3D模型，并且这些模型被细致地、层次地标注了跨50个类别的部分标签。除此之外，使用来自PartNeXt的数据训练Point-SAM比使用PartNet的数据有着显著的提高，这表明PartNeXt数据集在质量和多样性的优越性。
### Conclusion
通过结合可扩展的标注、纹理感知的标签和多任务评估，PartNeXt为结构化3D理解的研究开辟了新途径。
## 488. `cs.CV` - 重新审视logit分布以实现可靠的异常分布检测 [PDF](https://arxiv.org/pdf/2510.20134), [HTML](https://arxiv.org/abs/2510.20134)
### Authors
Jiachen Liang,Ruibing Hou,Minyang Hu,Hong Chang,Shiguang Shan,Xilin Chen
### Background
在开放世界的应用中，确保深度学习模型的可靠性至关重要。现有的后置方法虽然效率高且易于部署，但往往未能充分利用模型logits空间中蕴含的丰富信息。当前的研究旨在提出一种名为LogitGap的新颖后置方法，该方法通过明确利用最大logit与其他logit之间的关系，增强了典型样本与异常样本间的可分性。为提高其有效性，研究还引入了一种无需训练的策略，该策略能够自动识别出最具信息量的logits进行评分。实验结果表明，LogitGap在多种异常检测场景和基准测试中均能够获得最先进的性能。
### Innovation
提出了一种名为LogitGap的新颖后置方法，用于异常分布检测。该方法强调利用最大logit与其他logit之间的关系，以及一种无需训练的策略，自动识别最具信息量的logits进行评分，以提高分离典型样本与异常样本的能力。
### Conclusion
LogitGap在多种异常检测场景中展现出优越的性能，并且在各种基准测试中均能达到最先进的结果。该方法提供了一个理论分析以及实验证据来验证其有效性。相关代码现可在指定链接获取。
## 489. `cs.CV` - 从单张图像生成光场的逆图像渲染 [PDF](https://arxiv.org/pdf/2510.20132), [HTML](https://arxiv.org/abs/2510.20132)
### Authors
Hyunjun Jung,Hae-Gon Jeon
### Background
光场的概念，通过对多个视图图像在规则网格上的计算，已显示出其在场景表示中的益处，并支持新的视图以及诸如对焦和浅景深等摄影效果的逼真渲染。尽管这种方法在光流计算方面表现出有效性，但获取光场需要高昂的计算成本或专用设备，如复杂的相机设置和显微镜透镜阵列。因此，为了扩大其应用范围，本文提出了一种仅从单张图像生成光场的新颖视图合成方法，称为逆图像渲染。
### Innovation
不同于之前的隐式重建3D几何或显式表示客观场景的方法，本文的方法从图像像素重构光流，这种方法与基于图像的渲染相反。为了实现这一目标，我们设计了一种神经渲染管arserses，首先存储输入图像中源光线的光流，然后通过交叉注意力计算它们之间的关系，最后根据这些关系预测目标光线的颜色。生成第一个新视图后，生成的超出视图的内容被更新到源光线集合中。这个过程在确保遮挡内容的一致生成的同时反复进行。
### Conclusion
实验结果表明，我们的逆图像渲染方法能够很好地与各种具有挑战性的数据集配合工作，可以在合成数据集上训练一次后无需任何重新训练或微调。并且，与相关的最新视观点合成方法相比，我们的方法表现更优。
## 490. `cs.CV` - 基于单目视觉的 articulated 自行车和骑行者 8D 姿态估计 [PDF](https://arxiv.org/pdf/2510.20158), [HTML](https://arxiv.org/abs/2510.20158)
### Authors
Eduardo R. Corral-Soto,Yang Liu,Yuan Ren,Bai Dongfeng,Liu Bingbing
### Background
骑自行车者属于自动驾驶中的关键安全性类别，即易受伤害的道路使用者（VRU），准确估计他们的姿态对于骑行者过街意图分类、行为预测和碰撞避免至关重要。尽管6D姿态方法可以估计刚性自行车的3D旋转和平移，但当自行车的转向角或踏板角度变化时，6D姿态变得不足，因为这会导致自行车的3D包围盒发生变化，且3D包围盒的方向可能与转向方向不一致。因此，需要引入一种适用于articulated自行车的8D姿态估计方法，以更精确地估计自行车及其骑行者的姿态。
### Innovation
本文提出了一种基于单目RGB图像的articulated自行车和骑行者的8D姿态估计方法。该方法能够估计自行车的3D平移和旋转以及转向把和踏板相对于自行车本体框架的旋转，从而估计更细粒度的自行车姿态状态和行驶方向。此外，该方法结合使用合成数据和真实图像数据进行训练，以在真实图像上泛化。
### Conclusion
在评估部分中，验证了所估计的8D姿态参数的准确性，结果显示该方法与使用刚性标准物体模板的最新6D姿态估计器相比，取得竞争性的成绩。
## 491. `cs.CV` - TOMCAT: 测试时全面知识积累用于组合作零样本学习 [PDF](https://arxiv.org/pdf/2510.20162), [HTML](https://arxiv.org/abs/2510.20162)
### Authors
Xudong Yan,Songhe Feng
### Background
现有的组合作零样本学习（CZSL）方法在测试时性能下降，这主要是由于标签空间分布的变化，这种变化源于未见组合重新组合的属性和对象。这导致了从已知组合到未见组合的分布变化，对模型提出了新的挑战。
### Innovation
该研究提出了一种名为TOMCAT的新方法，该方法通过在测试时利用无监督数据在文本和视觉模态中积累全面的知识来更新多模态原型。此外，该方法还设计了一个自适应更新权重来控制原型调整的程度，并引入了一个动态优先队列，以存储高置信度图像并从中获取历史图像的视觉知识，用于推理。通过多模态协作表示学习对文本和视觉原型进行了语义一致性对齐。
### Conclusion
广泛的实验表明，该方法在四个基准数据集上实现了最先进的性能，适用于封闭世界和开放世界的设置。
## 492. `cs.CV` - IB-GAN: 使用信息瓶颈生成对抗网络的解耦表示学习 [PDF](https://arxiv.org/pdf/2510.20165), [HTML](https://arxiv.org/abs/2510.20165)
### Authors
Insu Jeon,Wonkwang Lee,Myeongjang Pyeon,Gunhee Kim
### Background
当前存在的许多生成模型在解耦表示学习方面存在挑战，特别是未监督的学习方法。现有的方法如β-VAE和InfoGAN虽然取得了一定的效果，但在优化生成对抗网络（GAN）以实现解耦表示的部分表现还有待提高。
### Innovation
本文提出了一种基于GAN的新颖的无监督模型——IB-GAN，它试图利用信息瓶颈（IB）框架来优化GAN，通过在生成器中引入一个中间层来约束输入与生成输出之间的互信息，使得生成器能够以解耦和可解释的方式利用潜在空间。与InfoGAN相比，IB-GAN在此基础上进行了关键改进，为生成器奠定了学习可学习的潜在分布的基础，这些分布在端到端训练中与生成器联合训练。实验结果表明，IB-GAN在dSprites和Color-dSprites数据集上的解耦表示得分与最先进的η-VAE相当，并且在CelebA和3D Chairs数据集的FID分数指标方面与η-VAE和Info-GAN相比输出质量更高，多样性的样本更好。
### Conclusion
IB-GAN在解耦表示学习方面取得了显著的进展，不仅在两个数据集上达到了与先进方法相近的效果，还在生成样本的质量和多样性方面超越了竞争对手。
## 493. `cs.CV` - PPMStereo: 选择并播放记忆构建以实现一致的动态立体匹配 [PDF](https://arxiv.org/pdf/2510.20178), [HTML](https://arxiv.org/abs/2510.20178)
### Authors
Yun Wang,Junjie Hu,Qiaole Dong,Yongjian Zhang,Yanwei Fu,Tin Lun Lam,Dapeng Wu
### Background
在增强现实等实际应用中，从立体视频中实现时间上一致的深度估计至关重要。由于长时间一致性的建模在计算效率方面存在挑战，先前的方法尝试通过整合时空信息来解决这一问题，但这些方法面临本质上难以调和的权衡：时间和空间建模的局限性只能带来有限的收益，而捕获长程依赖性则会显著增加计算成本。
### Innovation
本文提出了一个记忆缓冲来建模长时间的时空一致性，同时实现高效动态立体匹配。受人类两阶段决策过程的启发，本文提出了一个名为PPM（Pick-and-Play Memory）的构造模块，用于动态立体匹配，称为PPMStereo。PPM由两个步骤组成：‘选择’过程用来识别最相关的帧，‘播放’过程则根据时空聚合的需要对选择的帧进行自适应加权。这一两阶段的协作过程能够维持一个紧凑而包含高信息量的记忆缓冲，同时实现时序一致性的信息聚合。
### Conclusion
广泛的实验验证了PPMStereo的有效性，显示其在准确性和时序一致性方面达到了最先进的性能。具体来说，PPMStereo在Sintel数据集上的TEPE得分分别为0.62/1.11（比BiDAStereo在清洁/最终数据集上的表现分别提升了17.3%和9.02%）。代码可以在提供的链接中获取。
## 494. `cs.CV` - 公共脑MRI数据集的结构化回顾和定量表征及其在基础模型开发中的应用 [PDF](https://arxiv.org/pdf/2510.20196), [HTML](https://arxiv.org/abs/2510.20196)
### Authors
Minh Sao Khue Luu,Margaret V. Benedichuk,Ekaterina I. Roppert,Roman M. Kenzhin,Bair N. Tuchinov
### Background
基础模型的发展依赖于数据的规模、多样性与一致性，但对这些因素的系统性评估仍然不足。这项研究分析了54个公开的脑MRI数据集，包含超过538,031个样本，以提供一个针对基础模型开发层次化的多维度概述。研究发现，大型健康人群的比例远高于临床小样本群体，且在图像层面也存在大量的异质性，影响特征表示学习。
### Innovation
研究通过对54个数据集进行结构化分析，揭示了大规模健康人群与临床小样本群体间的显著不平衡，并定量分析了这些数据集在预处理时的图像层面异质性。研究发现，尽管标准化预处理可以提高数据集内部的一致性，但不同数据集之间仍然存在剩余差异，证实了在标准化预处理后基础模型中的残余协变量偏移，强调了预处理意识和领域适应策略在脑MRI基础模型设计中的重要性。
### Conclusion
这些分析提供了公共脑MRI资源中变异性的统一表征，并强调了在基础模型开发中需要预处理意识和领域适应策略以实现模型的通用性。
## 495. `cs.CV` - 评估视频模型作为多人行人的轨迹模拟器 [PDF](https://arxiv.org/pdf/2510.20182), [HTML](https://arxiv.org/abs/2510.20182)
### Authors
Aaron Appelle,Jerome P. Lynch
### Background
大规模的视频生成模型在不同场景中展现出高度的视觉真实性，引起了人们对它们作为通用世界模拟器的兴趣。现有的基准测试主要集中在单一主体上，而不是包含多个相互作用的人的场景。虽然生成的视频中多人动态的合理性尚未得到验证，但这些模型在模拟多主体动态方面的潜力未被充分探究。本文提出了一种严格评估协议，用于衡量文本到视频（T2V）和图像到视频（I2V）模型作为行人动力学的隐式模拟器的能力。针对I2V，利用现有数据集的起始帧进行真实视频数据集的对比分析。对于T2V，开发了一套提示套件来探索不同的行人密度和交互方式。关键在于从像素空间重建二维的鸟瞰视角轨迹的方法，无需已知相机参数。分析表明，主流模型已经学习到了相当有效的先验知识以模拟合理的多主体行为。然而，合并和消失的人等失败模式表明需要在未来改进的领域。
### Innovation
1. 提出了一种严格的评估框架，用于评估文本到视频（T2V）和图像到视频（I2V）模型作为行人动力学的隐式模拟器的能力。2. 针对I2V，利用已有的数据集中起始帧来与真实视频数据集进行对比分析。3. 针对T2V，开发了一套提示套件来探索不同的行人密度和交互方式。4. 提出了无相机参数的方法重建二维的鸟瞰视角轨迹，以评估模型的性能。
### Conclusion
主流的文本到视频和图像到视频模型已经学会了一些对于模拟合理多人动态非常有效的先验知识。然而，模型在多人合并和异常消失等场景下的表现较差，表明在相关领域仍然需要进一步的研究与改进。
## 496. `cs.CV` - FlowCycle：追求循环一致性的流用于基于文本的编辑 [PDF](https://arxiv.org/pdf/2510.20212), [HTML](https://arxiv.org/abs/2510.20212)
### Authors
Yanghao Wang,Zhen Wang,Long Chen
### Background
近年来，预训练的文本到图像生成模型在基于文本的图像编辑方面取得了显著进展。目前主流的方法采用破坏-恢复范式，即将源图像首先破坏为“中间状态”，然后在提示的指导下恢复为目标图像。然而，现有的方法以目标无关的方式构建这种中间状态，即他们主要集中在实现源图像重构，而忽视了与特定编辑目标之间的语义差距。这种设计会导致当目标修改与源图像有较大差异时，编辑结果有限制性或不一致性的问题。
### Innovation
本文提出了一种新颖的无反演且基于流动的编辑框架FlowCycle。该方法通过可学习的噪声参数化破坏过程，并通过循环一致性的过程优化它们。通过源图像到目标图像的迭代编辑并且通过双一致性约束恢复回源图像，FlowCycle学习生成目标感知的中间状态，从而实现忠实的修改并保持源一致性。广泛的经验表明，与现有的最先进的方法相比，FlowCycle在编辑质量和一致性上表现出优越性。
### Conclusion
FlowCycle学习生成目标感知的中间状态，从而实现忠实的修改并保持源一致性，优于现有的最先进的方法。
## 497. `cs.CV` - RAPO++: 通过数据对齐和测试时缩放进行跨阶段提示优化的文本到视频生成 [PDF](https://arxiv.org/pdf/2510.20206), [HTML](https://arxiv.org/abs/2510.20206)
### Authors
Bingjie Gao,Qianli Ma,Xiaoxue Wu,Shuai Yang,Guanzhou Lan,Haonan Zhao,Jiaxuan Chen,Qingyang Liu,Yu Qiao,Xinyuan Chen,Yaohui Wang,Li Niu
### Background
文本到视频（T2V）生成中，提示设计至关重要，但由于用户提供的提示往往是简短、无结构且与训练数据不匹配的，这限制了基于扩散的T2V模型的生成潜力。
### Innovation
提出了RAPO++，这是一种跨阶段提示优化框架，该框架通过统一训练数据对齐改进、测试时迭代缩放和大语言模型（LLM）微调来提高T2V生成效果，而无需修改底层生成核心。具体创新包括：- 阶段1：使用关系图检索语义相关修饰符并丰富用户提示，使其更符合训练分布，增强组合性和多对象的一致性。- 阶段2：引入样本特定提示优化（SSPO），通过多源反馈进行迭代优化，逐步提高视频生成质量。- 阶段3：利用SSPO优化的提示对重写LLM进行微调，内化特定任务优化模式，使高质量提示生成更高效。
### Conclusion
实验证明，RAPO++在语义对齐、组合推理、时间稳定性和物理合理性方面显著优于现有方法，RTPO++作为一个模型通用、成本高效且可扩展的解决方案，为T2V生成中的提示优化设定了新标准。
## 498. `cs.CV` - SPAN: 用于时间意图定位的连续建模的疑虑 progression 网络 [PDF](https://arxiv.org/pdf/2510.20189), [HTML](https://arxiv.org/abs/2510.20189)
### Authors
Xinyi Hu,Yuran Wang,Yue Li,Wenxuan Liu,Zheng Wang
### Background
时间意图定位（TIL）对于视频监控至关重要，专注于识别不同级别的可疑意图以提高安全监控。然而，现有的离散分类方法无法捕捉可疑意图的连续性，限制了早期干预和可解释性。过去的方法往往无法适应意图的动态变化和累积效应，从而影响了监控系统的效率和效果。SPAN 网络解决了这一问题，它从离散分类转向连续回归，能够捕捉到变化和发展中的可疑意图，同时利用时间点过程（TPP）理论理解长期依赖和累积效应，从而定义了一个连续变化的疑虑评分公式，并通过多模态信息调制疑虑系数，链接可疑行为与预定义意图概念，展示了其在低频情况下的优越性能，提升了系统的解释能力和实际应用价值。
### Innovation
通过提出疑虑进展分析网络（SPAN），将从离散分类转变为连续回归，以捕捉变化和发展中的可疑意图。使用长期依赖和累积效应来定义疑虑评分公式，引入了多模态信息调制疑虑系数的方法，并提出了概念锚定映射方法，将可疑行为与预定义意图概念链接起来。极端实验结果表明，与现有方法相比，SPAN 显著提高了指标（降低19.8% 的 MSE 和提高1.78% 的平均mAP），特别是在低频情况下的表现更为出色，提升了系统的解释能力和实用价值。
### Conclusion
SPAN 网络显著优于现有方法，在 HAI 数据集上的实验表明，通过不间断建模，能够实现早期检测和主动干预，极大提升了系统的解释性和现实应用中的有效性。
## 499. `cs.CV` - 客观化医学超声评估：胎儿运动检测的对比表示学习 [PDF](https://arxiv.org/pdf/2510.20214), [HTML](https://arxiv.org/abs/2510.20214)
### Authors
Talha Ilyas,Duong Nhu,Allison Thomas,Arie Levin,Lim Wei Yap,Shu Gong,David Vera Anaya,Yiwen Jiang,Deval Mehta,Ritesh Warty,Vinayak Smith,Maya Reddy,Euan Wallace,Wenlong Cheng,Zongyuan Ge,Faezeh Marzbanrad
### Background
准确的胎儿运动（FM）检测对于评估妊娠期健康至关重要，因为异常的运动模式可能表明潜在问题，如胎盘功能不全或胎儿窘迫。传统方法，如母体感知和心电图（CTG），存在主观性和准确性有限的问题。
### Innovation
我们提出了对比超声视频表示学习（CURL），这是一种新颖的自监督学习框架，用于从延伸的胎儿超声视频记录中检测FM。该方法利用双对比损失，结合空间和时间对比学习，学习稳健的运动表示。此外，我们引入了一种针对任务的采样策略，确保在自监督训练过程中有效分离运动和非运动段，同时通过概率微调方法在任意长时间的超声记录上实现灵活的推理。
### Conclusion
CURL在包含92个对象的内部数据集上的评估（每个对象有30分钟的超声会话）显示出78.01%的灵敏度和81.60%的AUCROC，证明了其在可靠的、客观的FM分析中的潜力。这些结果强调了自监督对比学习在胎儿运动分析中的潜力，为改善孕前监测和临床决策开辟了道路。
## 500. `cs.CV` - EditInfinity：使用二元量化生成模型进行图像编辑 [PDF](https://arxiv.org/pdf/2510.20217), [HTML](https://arxiv.org/abs/2510.20217)
### Authors
Jiahuan Wang,Yuxin Chen,Jun Yu,Guangming Lu,Wenjie Pei
### Background
基于预训练扩散生成模型的文本驱动图像编辑已经显示出巨大的潜力。然而，这种方法中经典改编范式在进行图像编辑时受到图像反转过程中引入的近似误差限制，这些误差源于扩散模型在中间生成步骤中缺乏精确监督。为了克服这个问题，该研究探讨了基于VQ的生成模型的高效参数改编方式，利用其固有的特性来获取源图像的确切中间量化表示，从而更有效地监督以实现精准的图像反转。
### Innovation
研究提出了一种名为EditInfinity的方法，该方法改编了二元量化生成模型Infinity用于图像编辑。具体而言，该方法提出了一种高效的图像反转机制，将文本提示校正和图像风格保存相结合，实现了精准的图像反转。此外，该研究还提出了一种整体平滑策略，使得EditInfinity能够以较高的保真度编辑图像并精确对齐文本提示的语义。
### Conclusion
在 PIE-Bench 基准测试中对 'add'、'change' 和 'delete' 编辑操作的广泛实验表明，该模型的性能优于最先进的基于扩散的基线模型。此外，源代码可在以下链接获取：this https URL。
## 501. `cs.CV` - 为什么长响应中LVLM更容易产生幻觉：上下文的作用 [PDF](https://arxiv.org/pdf/2510.20229), [HTML](https://arxiv.org/abs/2510.20229)
### Authors
Ge Zheng,Jiaye Qian,Jiajin Tang,Sibei Yang
### Background
近年来，大规模视觉-语言模型（LVLMs）取得显著进展，但容易产生幻觉的问题也日益凸显。这些模型在较长的、自由形式的回应中表现出更频繁的幻觉现象，这通常被认为是累积不确定所导致的。该研究旨在探讨幻觉增加是否完全由长度引起，还是存在更深层次的原因。通过一系列初步实验和发现，研究者提出了幻觉风险不是由于长度本身，而是由于在较长回应中对上下文依赖性增加而引发的新观点。
### Innovation
研究者提出了一个新的“诱导-检测-抑制”框架，通过故意设计上下文来主动诱导幻觉，利用诱导实例进行高风险案例的早期检测，并在实际解码过程中抑制潜在的对象级幻觉。该方法在所有基准测试中都表现出一致且显著的改进，证明了其有效性。强大的检测和幻觉抑制不仅验证了研究框架的有效性，还重新验证了上下文的作用理论。这种研究不仅追求性能提升，还为理解LVLMs在较长响应中的幻觉现象提供了新见解，并为此类研究指明了方向。
### Conclusion
研究结果证实了LVLM在较长响应中更容易产生幻觉的主要原因在于对上下文依赖性的增加。所提出的方法通过早期发现并抑制潜在幻觉，显著提高了模型的性能。该研究不仅是对LVLMs幻觉问题的探索性一步，也为未来的深入研究提供了基础。
## 502. `cs.CV` - COS3D:协作开放式词汇3D分割 [PDF](https://arxiv.org/pdf/2510.20238), [HTML](https://arxiv.org/abs/2510.20238)
### Authors
Runsong Zhu,Ka-Hei Hui,Zhengzhe Liu,Qianyi Wu,Weiliang Tang,Shi Qiu,Pheng-Ann Heng,Chi-Wing Fu
### Background
开放词汇的3D分割是一个基础但也具有挑战性的任务，需要理解分割和语言的相互作用。现有方法基于高斯揉面的方法要么依赖单个3D语言场导致分割效果不佳，要么依赖预计算的非类特异性分割导致错误累积。
### Innovation
我们提出了COS3D，这是一种新的协作提示-分割框架，通过整个管道内不断发展地集成语言和分割线索来有效解决这一问题。COS3D首先引入了协作场的概念，结合实例场和语言场作为协作的基础。通过一种新颖的实例到语言特征映射和设计高效的两阶段训练策略，有效地构建了协作场。在推断过程中，通过设计自适应语言到实例的提示细化来解决两个场的特性差异，促进高质量的提示分割推断。
### Conclusion
大量的实验不仅证明了COS3D在两个广泛使用的基准上的领先性能，而且还展示了它在各种应用中的高潜力，例如基于图像的新3D分割、层次分割和机器人技术。COS3D的代码已公开可访问：
## 503. `cs.CV` - 展开语言的力量：DualGround 在结构化短语和句子级时间定位中的应用 [PDF](https://arxiv.org/pdf/2510.20244), [HTML](https://arxiv.org/abs/2510.20244)
### Authors
Minseok Kang,Minhyeok Lee,Minjung Kim,Donghyeong Kim,Sangyoun Lee
### Background
视频时间定位（VTG）旨在在长的未修剪视频中定位与给定自然语言查询相匹配的时间段。该任务通常包括两个子任务：时刻检索（MR）和亮点检测（HD）。近年来，强大的预训练多模态模型如CLIP和InternVideo2促进了这一领域的发展，但现有方法通常在跨模态注意力中统一处理所有文本标记，忽略其独特的语义角色。通过受控实验，研究证实，VTG模型过度依赖于以[EOS]驱动的全局语义，而未能有效利用字级别的信号，限制了其实现细粒度时间对齐的能力。
### Innovation
提出了一种名为DualGround的双分支架构，该架构明确分离全局和局部语义，通过将[EOS]标记路由到句子级路径，并将词标记聚类成短语级单元来实现局部定位。该方法引入了（1）感知标记角色的跨模态交互策略，以结构上分离地对齐视频特征与句子级和短语级语义，以及（2）一个联合建模框架，该框架不仅提高了全局句子级对齐，还通过利用结构化的短语意识上下文增强了细粒度的时间定位。
### Conclusion
DualGround 在QVHighlights和Charades-STA基准测试中的时刻检索和亮点检测任务上取得了最先进的性能，表明了解耦合语义建模在视频-语言对齐中有效性的证明。
## 504. `cs.CV` - 视觉因果去偏见在视觉常识推理中的应用 [PDF](https://arxiv.org/pdf/2510.20281), [HTML](https://arxiv.org/abs/2510.20281)
### Authors
Jiayi Zou,Gengyun Jia,Bing-Kun Bao
### Background
视觉常识推理(VCR)是指基于图像进行问题回答和提供解释的能力。现有的方法在预测准确性上表现出色，但往往忽视了数据集中的偏见问题，缺乏去偏见策略。研究表明，数据中的文本和视觉信息都存在关联性和统计性偏见。
### Innovation
该研究提出了VCR-OOD数据集，包括用于跨模态评估模型泛化能力的VCR-OOD-QA和VCR-OOD-VA子集。研究还通过因果图分析VCR中的预测捷径，并采用了后门调整方法来去除偏见。研究创建了一个词典，基于正确答案集合来消除预测捷径。实验结果表明，这种方法在多个数据集上的有效性得到了验证。
### Conclusion
该研究通过后门调整方法成功去除了VCR中的偏见，验证了该方法在不同数据集上的有效性，并强调了评估模型泛化能力的重要性，尤其是在多模态数据上。
## 505. `cs.CV` - 实时货币检测及语音反馈系统为视障人士 [PDF](https://arxiv.org/pdf/2510.20267), [HTML](https://arxiv.org/abs/2510.20267)
### Authors
Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim
### Background
智能手机等科技已成为人们日常生活中的必需品，包括视力障碍人士也能方便地使用。智能手机摄像头的应用使得图像捕捉和处理更加便捷，通过智能手机和机器学习技术，可以为视力障碍人士提供帮助。手持货币而不依赖他人成为一个挑战，为此，本论文提出了一种实时货币检测系统，旨在辅助视力障碍人士独立处理货币。
### Innovation
本文采用YOLOv8 nano模型结合自定义检测头部（包括深卷积层和Squeeze-and-Excitation模块）来增强特征提取和检测准确性，并训练了一个包含30个类别的数据集，包括代表三种货币的纸币和硬币：美元（USD）、欧元（EUR）和孟加拉塔卡（BDT）。模型检测的准确率高达97.73%，召回率为95.23%，F1分数为95.85%，平均精度97.21%（IoU=0.5时mAP50(B)）。通过检测后的语音反馈，帮助视力障碍人士识别货币。
### Conclusion
本论文旨在建立一个实用且高效的货币检测系统，以帮助视力障碍人士独立处理货币。
## 506. `cs.CV` - DMC$^3$: 双模态反事实对比构建方法在自身中心视频问答中的应用 [PDF](https://arxiv.org/pdf/2510.20285), [HTML](https://arxiv.org/abs/2510.20285)
### Authors
Jiayi Zou,Chaofan Chen,Bing-Kun Bao,Changsheng Xu
### Background
自身中心视频问答（Egocentric VideoQA）是自身中心视频理解的关键组成部分，涉及基于第一人称视频回答问题的任务。现有方法在预训练和微调的范式中取得了进展，但忽略了第一人称视角带来的独特挑战，如理解和识别多个事件及手物交互。
### Innovation
本文提出了一个双模态反事实对比构建（DMC$^3$）框架，包含自中心视频问答基线、反事实样本构建模块和包含反事实样本的对比优化模块。通过事件描述重新表述和核心交互提取生成正负样本，并应用于对比优化中，以最小化原始样本与正样本之间的距离，同时最大化与负样本之间的距离。
### Conclusion
实验表明，我们的方法在EgoTaskQA的常规和间接分拆上分别达到了52.51%和46.04%，并且在QAEGO4D上的得分达到了13.2%的性能，均达到了当前最先进的水平。
## 507. `cs.CV` - 基于掩码的定位编码和条带卷积上下文建模的超越视图物体地理定位 [PDF](https://arxiv.org/pdf/2510.20247), [HTML](https://arxiv.org/abs/2510.20247)
### Authors
Shuhan Hu,Yiru Li,Yuanyuan Li,Yingying Zhu
### Background
跨视角物体地理定位能够通过跨视角匹配实现高精度物体定位，具有在自动驾驶、城市管理和灾害响应中的关键应用价值。然而，现有方法依赖于特征点基座的位置编码，仅捕获二维坐标而忽视了物体形状信息，导致对注释偏移敏感且跨视角匹配能力有限。
### Innovation
本文提出了一种基于掩码的位置编码方案，利用分割掩码同时捕获空间坐标和物体轮廓，将模型从“位置感知”提升到“物体感知”。此外，为应对卫星影像中大跨度物体（如长条形建筑）的挑战，设计了一种上下文增强模块，该模块使用水平和垂直条带卷积核提取长距离上下文特征，增强条带状物体的特征辨别。结合基于掩码的位置编码（MPE）和上下文增强模块（CEM），提出了端到端的稳健跨视角物体地理定位框架EDGeo。实验结果表明，该方法在两个公开数据集（CVOGL和VIGOR-Building）上的定位准确率明显提升，特别是在地面到卫星的挑战性场景中获得了最先进的性能，提升了3.39%。
### Conclusion
本文提供了一种稳健的位置编码范式和上下文建模框架，推动了跨视角地理定位研究的发展。
## 508. `cs.CV` - Calibrating Multimodal Consensus for Emotion Recognition [PDF](https://arxiv.org/pdf/2510.20256), [HTML](https://arxiv.org/abs/2510.20256)
### Authors
Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan
### Background
近年来，多模态情感识别（MER）取得了显著进展。然而，大多数现有方法忽略了模态间可能产生的语义不一致问题，例如文本和视觉输入间的情感矛盾线索。此外，由于文本模态的强大表征能力，当前方法往往以文本为主导，这可能会削弱识别准确性。本文指出了这些挑战。
### Innovation
为了应对这些挑战，本文提出了一个名为校准多模态共识（CMC）的模型。CMC引入了一个伪标签生成模块（PLGM），能够生成伪单模标签，以实现自我监督的单模预训练。它还采用了一个参数自由融合模块（PFM）和一个多模态共识路由器（MCR），以进行多模态微调。这有助于减轻文本主导性，引导融合过程向更可靠的共识方向发展。实验结果表明，CMC在四个数据集（CH-SIMS，CH-SIMS v2，CMU-MOSI，CMU-MOSEI）上的表现与最先进的方法持平或更优，并在包含语义不一致的CH-SIMS和CH-SIMS v2数据集上表现出色。本文的工作实现公开于此：https://this.is.public.url.
### Conclusion
实验结果显示，CMC在四个数据集上的表现与最先进的方法持平或更优，并在存在语义不一致的场景下表现出明显的优越性。
## 509. `cs.CV` - GMFVAD: 使用粒度多模态特征提高视频异常检测 [PDF](https://arxiv.org/pdf/2510.20268), [HTML](https://arxiv.org/abs/2510.20268)
### Authors
Guangyu Dai,Dong Chen,Siliang Tang,Yueting Zhuang
### Background
视频异常检测（VAD）是一项挑战性的任务，旨在检测连续监控视频中的异常帧。过去的大多数工作都是利用时空视觉特征的相关性来判断视频片段中是否存在异常。最近，一些研究尝试引入多模态信息，如文本特征，以增强视频异常检测的结果。然而，这些工作仅将文本特征粗略地整合到视频片段中，忽视了视频片段中存在的大量冗余信息。因此，本文提出利用多模态信息之间的多样性来进一步细化提取的特征，减少视觉特征中的冗余，并提出了一种名为粒度多模态特征视频异常检测（GMFVAD）的方法。特别是基于视频片段生成更细粒度的多模态特征，并通过原始视频的字幕引入文本特征，进一步增强突出部分的视觉特征。实验结果表明，提出的GMFVAD在四个主要数据集上达到了最先进的性能。消融实验也证实了GMFVAD的性能提升是由于减少了冗余信息造成的。
### Innovation
本文提出了一种名为GMFVAD的方法，通过利用多模态信息之间的多样性来精细化提取的特征，减少视觉特征中的冗余，并引入精心生成的细粒度多模态特征。这种方法通过利用视频内容和文本信息之间的互补优势，进一步提高了视频异常检测的性能。
### Conclusion
通过实验验证，所提出的GMFVAD方法在四个主要的数据集上取得了最先进的性能。该方法的有效性被消融实验进一步验证，表明GMFVAD的性能提升主要归因于减少了冗余信息。
## 510. `cs.CV` - 知识导向的神经网络用于复值SAR图像识别 [PDF](https://arxiv.org/pdf/2510.20284), [HTML](https://arxiv.org/abs/2510.20284)
### Authors
Haodong Yang,Zhongling Huang,Shaojie Guo,Zhe Zhang,Gong Cheng,Junwei Han
### Background
在数据有限和领域迁移的情况下，复值合成孔径雷达（CV-SAR）图像识别的深度学习模型本质上受限于一个表现三重困境：同时追求泛化、可解释性和效率，这三者之间存在冲突。虽然丰富的电磁散射特征是关键，但传统的基于数据的模型未能充分利用这些特征。论文指出这种困境主要是因为现有模型未能有效提取和利用这些关键信息。
### Innovation
本文提出了知识导向神经网络（KINN），这是一种基于“压缩-聚合-压缩”架构的轻量级框架。KINN通过物理指导压缩阶段内的新颖字典处理器，嵌入物理先验信息，从而实现紧凑的展开网络，高效抽取稀疏的、基于物理的特征。随后的聚合模块丰富这些特征表示，最后通过使用紧凑的分类头自蒸馏，学习最相关的特征表示。KINN已实现在卷积神经网络（CNN）和视觉变换器（Vision Transformer）两种变体中，其在五个SAR基准上的广泛评估表明，KINN在参数效率识别方面达到最佳表现，在数据稀缺和领域的外推场景中提供出色的泛化，并且提供了解释性，从而有效解决了表示三重困境，为SAR图像分析提供了新的可信AI路径。
### Conclusion
KINN在参数效率识别方面表现出色，并提供了出色的泛化性能和解释性，在数据稀缺和领域迁移的情境中有效解决了复值SAR图像识别中的表现三重困境，为SAR图像分析提供了新的有效解决方案，并指出了未来可信AI的发展方向。
## 511. `cs.CV` - 在生成式人工智能时代下的霹雳舞视频分类 [PDF](https://arxiv.org/pdf/2510.20287), [HTML](https://arxiv.org/abs/2510.20287)
### Authors
Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson
### Background
近年来，大型视觉语言模型在多个体育应用中都有广泛应用，多数研究集中于足球、板球、篮球等热门体育项目，主要集中在生成任务如视觉问答、片段生成等方面。这类模型在运动视频分析中的应用已取得了一定成果。
### Innovation
研究将现代视频基础模型（包括编码器和解码器）应用于霹雳舞视频分类这一非常特定但也极其流行的体育项目，发现视频编码器模型在这种特定任务上仍然表现出色，超越了现有的视频语言模型。研究还提供了如何选择编码器模型的见解，并对微调解码器模型在霹雳舞视频分类中的工作原理进行了全面分析。
### Conclusion
研究结果表明视频编码器模型在预测任务中仍然表现最佳，提出了选择编码器模型的方法，并对微调解码器模型进行了深入分析。为今后针对特定体育项目的视频分析提供了新的研究方向和依据。
## 512. `cs.CV` - UI-Ins: 使用多视角指令作为推理增强GUI定位 [PDF](https://arxiv.org/pdf/2510.20286), [HTML](https://arxiv.org/abs/2510.20286)
### Authors
Liangyu Chen,Hanzhang Zhou,Chenglin Cai,Jianan Zhang,Panrong Tong,Quyu Kong,Xu Zhang,Chen Liu,Yuqi Liu,Wenxuan Wang,Yue Wang,Qin Jin,Steven Hoi
### Background
GUI接地是一种将自然语言指令映射到可操作的UI元素的核心能力。早期的研究将指令视为用户意图的静态代理，忽略了指令多样性和质量对接地性能的影响。现有研究数据集存在23.3%的错误率，说明指令多样性对推理性能有显著影响。
### Innovation
本文提出了指令作为推理的新范式，将指令视为动态分析路径，使模型在推理过程中选择最有效的路径。该工作提出了一种两阶段训练框架：通过有监督微调(SFT)来培养多视角推理能力，然后通过强化学习(RL)优化路径选择与组成。模型UI-Ins-7B和UI-Ins-32B在五个困难的定位基准测试中实现了最新的成果，并且表现出新兴的推理能力，在执行时综合和合成新的指令路径。特别地，UI-Ins-32B在UI-I2E-Bench上获得了最高的接地精度，得分87.3%。我们的模型显示出强大的代理潜力，在AndroidWorld上成功率达到74.1%。我们的深入分析揭示了如何将推理以增强而不是阻碍接地性能的形式进行构建，并揭示了方法如何缓解SFT+RL框架中的策略崩溃问题。
### Conclusion
我们的模型在五个挑战性对接地基准测试中实现了最先进的结果，并且在执行时能够综合和合成新的指令路径。此外，我们提供的模型具有较强的代理潜力，并揭示了通过多视角指令作为推理来增强对接地性能的新策略。
## 513. `cs.CV` - AccuQuant: Simulating Multiple Denoising Steps for Quantizing Diffusion Models [PDF](https://arxiv.org/pdf/2510.20348), [HTML](https://arxiv.org/abs/2510.20348)
### Authors
Seunghoon Lee,Jeongwoo Choi,Byunggwan Son,Jaehyeon Moon,Jeimin Jeon,Bumsub Ham
### Background
量化误差在去噪过程中逐步积累，这会对基于去噪过程的扩散模型性能产生负面影响。
### Innovation
AccuQuant是一种新颖的后训练量化方法，模拟多个去噪步骤以量化扩散模型，同时显著降低内存复杂度。
### Conclusion
AccuQuant在各种任务和扩散模型上展示了其有效性和效率。
## 514. `cs.CV` - 一种高效混合专家框架在跨模态地理定位中的应用 [PDF](https://arxiv.org/pdf/2510.20291), [HTML](https://arxiv.org/abs/2510.20291)
### Authors
LinFeng Li,Jian Zhao,Zepeng Yang,Yuhang Song,Bojun Lin,Tianle Zhang,Yuchen Yuan,Chi Zhang,Xuelong Li
### Background
任务涉及从包含卫星、无人机和地面平台的大型多平台数据库中，根据自然语言查询检索最相关的地理定位图像。然而，由于跨平台异构性和通用训练描述与特定平台测试查询之间的领域差距，任务具有挑战性。背景中的解决方案需要能够处理这些挑战，以便在多视角中实现稳健的跨模态地理定位。
### Innovation
该研究提出了一种参数高效的混合专家（Mixture-of-Experts, MoE）框架来解决跨模态地理定位问题。具体创新点包括：（1）针对不同平台的数据划分、卫星数据增强及去除方位描述词；（2）基于LLM的图片文字描述改进管道，以使文本语义与不同平台的视觉特征对齐；（3）使用BGE-M3（文本）和EVA-CLIP（图像）训练三种平台专用模型，并采用二次训练策略，利用硬负样本增强区分能力，在推理时融合专家模型的得分。
### Conclusion
该系统在官方排行榜中名列榜首，展示了在不同视点下进行稳健跨模态地理定位的能力。
## 515. `cs.CV` - 任何点云压缩模型：使用单一通用模型压缩任意点云 [PDF](https://arxiv.org/pdf/2510.20331), [HTML](https://arxiv.org/abs/2510.20331)
### Authors
Kangli Wang,Qianxi Yi,Yuqi Ye,Shihao Li,Wei Gao
### Background
深度学习模式下的点云几何压缩普遍存在泛化能力不足的问题。这一问题主要源于两个关键限制：缺乏稳健的内容建模以及对离分布数据处理的低效。因此，亟需一种能够克服这些限制的通用点云压缩框架。
### Innovation
该论文提出了一种名为AnyPcc的通用点云压缩框架，该框架包含两个创新点：首先，引入了一个使用空间和通道间聚类先验信息的通用上下文模型，以捕捉稳健的上下文依赖关系；其次，采用了实例自适应微调策略IAFT，结合显式和隐式压缩方法，对每个实例微调少量网络权重，并将这些权重整合到比特流中，从而在压缩几何形状时带来显著的成本效益。
### Conclusion
该研究通过在15个多样化的数据集基准测试中验证，证明了AnyPcc在点云压缩方面达到了新的最先进水平。研究团队还公开了代码和数据集，鼓励可重复的研究。
## 516. `cs.CV` - PE-Field [PDF](https://arxiv.org/pdf/2510.20385), [HTML](https://arxiv.org/abs/2510.20385)
### Authors
Yunpeng Bai,Haoxiang Li,Qixing Huang
### Background
DiTs已经成为驱动图像和视频生成的主导架构，通过将图像表示为具有位置编码的块令牌，DiTs结合了Transformer的可扩展性和空间及时间的归纳偏置。
### Innovation
提出了一种名为PE-Field的结构，将位置编码从二维平面扩展到有结构的三维场，引入了深度感知编码进行体积推理和层次编码以进行细粒度子块控制，使DiTs能够直接在三维空间中建模几何。
### Conclusion
PE-Field增强的DiT在单视图新颖视角合成上达到了最新性能，并且在可控空间图像编辑上具备良好的泛化能力。
## 517. `cs.CV` - HyperET：在双曲空间中高效训练多模态大语言模型 [PDF](https://arxiv.org/pdf/2510.20322), [HTML](https://arxiv.org/abs/2510.20322)
### Authors
Zelin Peng,Zhengqin Xu,Qingyang Liu,Xiaokang Yang,Wei Shen
### Background
多模态大语言模型（MLLMs）已经作为一种变革性的方法，用于实现视觉和文本理解的对齐。然而，它们在训练过程中通常需要极其高的计算资源（例如，成千上万的GPU），以在多粒度水平上实现跨模态对齐。当前通用的视觉编码器（如CLIP和SAM）缺乏对语言的多粒度层级对齐，是导致这一低效率的重要因素。
### Innovation
本文提出了一种称为HyperET的有效训练理念，在双曲空间中运行，通过动态调整双曲半径来优化视觉表示，使其与文本的对应表示在任意粒度级别上达到对齐。HyperET利用可学习的矩阵和Möbius乘法操作，并通过三种有效配置（对角缩放矩阵、块对角矩阵和带状矩阵）提供了一个灵活且高效的参数化策略。
### Conclusion
在多个MMLM基准上的全面实验表明，HyperET在优化现有的预训练和微调MMLMs性能方面，始终表现出色，并且只增加了不到1%的额外参数量。
## 518. `cs.CV` - 多文化图像到食谱检索中的跨模态表示偏差缓解 [PDF](https://arxiv.org/pdf/2510.20393), [HTML](https://arxiv.org/abs/2510.20393)
### Authors
Qing Wang,Chong-Wah Ngo,Yu Cao,Ee-Peng Lim
### Background
现有的图像到食谱检索方法假定食物图像能完整反映其食谱中文字描述的细节。然而，食物图像仅反映烹饪完成后的视觉效果，未体现烹饪过程。因此，在学习跨模态表示以弥合图像与食谱间的模态差距时，往往忽略了那些未在视觉上显现但对食谱检索至关重要的细微、食谱特有的信息。这些表示偏向于捕捉图像中的主导视觉元素，导致难以区分在原料和烹饪方法使用上有细微差异的相似食谱。当训练数据来源混杂不同菜系时，这种表示学习的偏差会更加严重。
### Innovation
本文提出了一种新颖的因果方法，不仅能预测图像中可能忽略的烹饪元素，还能显式地将这些元素注入跨模态表示学习过程以缓解偏差。
### Conclusion
实验在标准的单语言Recipe1M数据集和新构建的多语言多元文化烹饪数据集上进行，结果表明所提出的因果表示学习能够揭示细微的原料和烹饪动作，并在单语言和多语言多元文化数据集上都取得了出色的检索性能。
## 519. `cs.CV` - EchoDistill：双向概念蒸馏以实现单步扩散个性化 [PDF](https://arxiv.org/pdf/2510.20512), [HTML](https://arxiv.org/abs/2510.20512)
### Authors
Yixiong Yang,Tao Wu,Senmao Li,Shiqi Yang,Yaxing Wang,Joost van de Weijer,Kai Wang
### Background
最近在加速文本到图像（T2I）扩散模型方面取得的进展已经能够即使在一个步骤内生成高质量的图像。然而，如何将这些模型个性化以纳入新的概念依然是一个挑战，因为单步模型在捕捉新概念分布时具有有限的容量。
### Innovation
本文提出了一种双向概念蒸馏框架，EchoDistill，以实现单步扩散个性化（1-SDP）。该方法包含端到端的训练过程，其中多步扩散模型（教师）和单步扩散模型（学生）被同时训练。原理包括：语音概念首先从教师模型到学生，然后再从学生回传到教师。在EchoDistill期间，两个模型共享文本编码器以确保语义理解一致。学生模型利用自己更快的生成能力反馈到教师模型中。双向概念蒸馏机制不仅增强学生模型对新概念的个性化能力，还改善了教师模型的生成质量。实验表明，这种协作框架在1-SDP设置中显著优于现有的个性化方法，确立了一个新的快速和有效的个性化范式在T2I扩散模型中。
### Conclusion
本研究提出了一种双向概念蒸馏框架EchoDistill，用以提高单步扩散模型（1-SDP）的个性化能力，并通过实验验证了其在T2I扩散模型中能够实现快速有效的个性化，显著优于现有的个性化方法。
## 520. `cs.CV` - 可靠且可重复的群体属性推理以提高面部分析中的公平性 [PDF](https://arxiv.org/pdf/2510.20482), [HTML](https://arxiv.org/abs/2510.20482)
### Authors
Alexandre Fournier-Montgieux,Hervé Le Borgne,Adrian Popescu,Bertrand Luvison
### Background
面部分析系统的公平性评估通常依赖于自动人口统计属性推断（DAI），而DAI本身基于预定义的人口统计分段。然而，公平性审计的有效性取决于DAI过程的可靠性。研究从理论上阐述了这种依赖关系，并表明改进的DAI可靠性能导致更少偏见和更低方差的FAS公平性估计。因此，研究构建了一个完全可复制的DAI流程，替代传统的端到端训练方法采用一种模块化迁移学习方法。该设计结合了预训练的面部识别编码器和非线性分类头，审计了该流程在三个维度上的表现：准确度、公平性和一种新的稳健性度量（基于身份内的一致性定义）。该稳健性度量适用于任何人口统计分割方案。该工作在性别和种族推断上对多个数据集和训练配置进行了基准测试。研究结果表明，提出的方法在种族推断上优于强基线，因为种族是更具有挑战性的属性。
### Innovation
提出了一种完全可复制的DAI流水线，采用了模块化迁移学习方法替代传统的端到端训练。该设计结合了预训练的面部识别编码器和非线性分类头。该研究从准确度、公平性和一个新的基于身份内一致性的稳健性度量三个方面审计了该流水线的表现。他还提出了适用于任何人口统计分割方案的稳健性度量，并公开发布了训练数据集元数据、完整代码库、预训练模型和评估工具。
### Conclusion
该工作提供了一个可靠的基础，用于公平性审计中的群体属性推断，并公开发布了训练数据集元数据、完整代码库、预训练模型和评估工具，以促进透明性和可重复性。
## 521. `cs.CV` - 基于深度学习的视觉SLAM助力盲人导航 [PDF](https://arxiv.org/pdf/2510.20549), [HTML](https://arxiv.org/abs/2510.20549)
### Authors
Marziyeh Bamdad,Hans-Peter Hutter,Alireza Darvishy
### Background
尽管SLAM技术取得了进步，但在低纹理、运动模糊或困难的光照等恶劣条件下仍难以稳健工作，这在诸如为视障者提供辅助导航的应用中更为常见。这些条件削弱了定位精度和跟踪稳定性，降低了导航的可靠性和安全性。
### Innovation
本文提出了一种结合SuperPoint和LightGlue的深度学习增强SLAM框架（SELM-SLAM3），以实现鲁棒特征提取和匹配。研究结果表明，该框架在TUM RGB-D、ICL-NUIM和TartanAir等具有复杂多变场景的多个数据集上表现优异，平均优于传统的ORB-SLAM3 87.84%，超出当前最佳RGB-D SLAM系统36.77%。
### Conclusion
SELM-SLAM3在低纹理场景和快速运动等恶劣条件下显示出更好的性能，为开发面向视障者的导航辅助平台提供了可靠基础。
## 522. `cs.CV` - Metis-HOME: Hybrid Optimized Mixture-of-Experts for Multimodal Reasoning [PDF](https://arxiv.org/pdf/2510.20519), [HTML](https://arxiv.org/abs/2510.20519)
### Authors
Xiaohan Lan,Fanfan Liu,Haibo Qiu,Siqi Yang,Delian Ruan,Peng Shi,Lin Ma
### Background
随着大型语言模型（LLM）推理能力的最近进步，多模态推理领域取得了显著进展，尤其在复杂的数学问题解决等任务上表现优异。然而，当前的多模态大型推理模型存在两个关键问题：首先，它们倾向于针对简单查询进行复杂的、计算成本高的推理，导致效率低下；其次，这种专注于专门推理的方法往往削弱了它们处理更广泛、更一般性问题的能力。
### Innovation
本文提出了一种名为Metis-HOME的混合优化专家混合模型框架，通过将原始密集模型拆分为两个专门的专家支路——一个用于复杂、多步推理的思考支路和一个用于快速直接推理任务如通用VQA和OCR的非思考支路，解决了上述权衡问题。一个轻量级的可训练路由器动态分配查询给最合适的专家。通过将Qwen2.5-VL-7B适应为MoE架构来实例化Metis-HOME。全面的评估表明，这种方法不仅大幅提高了复杂推理能力，还提升了模型的一般性能，逆转了其他推理专门化模型性能下降的趋势。这项工作为构建强大的、多功能的多模式大型语言模型建立了新的范式，有效解决了推理与泛化之间的普遍困难。
### Conclusion
Metis-HOME解决了多模态大型语言模型在推理能力与泛化能力之间的权衡问题，通过引入混合优化专家混合模型框架，不仅提高了复杂推理能力，还增强了模型的一般性能，为构建多功能的多模态大型语言模型提供了一种有效的新范式。
## 523. `cs.CV` - 从远至近：不同细节级别人群表示的知觉评估 [PDF](https://arxiv.org/pdf/2510.20558), [HTML](https://arxiv.org/abs/2510.20558)
### Authors
Xiaohan Sun,Carol O'Sullivan
### Background
本文探讨了用户对不同细节级别（LoD）和视距下人群角色表示的视觉质量感知。各种表示形式（几何网格、图像基于的 impostors、神经辐射场 NeRFs 和 3D 高斯分布）在视觉保真度和计算性能之间存在独特的权衡。
### Innovation
研究表明，通过定性和定量的评估结果，可以为人群渲染的设计提供感知优化的 LoD 策略指导，使不同级别的细节在视觉保真度和计算性能之间找到最佳平衡。
### Conclusion
研究结果为提高人群角色表示的视觉质量提供了有价值的见解，尤其是在视觉保真度和计算性能之间权衡的策略设计中。
## 524. `cs.CV` - Blur2seq: 从单张运动模糊图像盲去模糊和相机轨迹估计 [PDF](https://arxiv.org/pdf/2510.20539), [HTML](https://arxiv.org/abs/2510.20539)
### Authors
Guillermo Carbajal,Andrés Almansa,Pablo Musé
### Background
运动模糊是图像恢复中的一个主要挑战，尤其是在大范围或旋转运动下。当前的图像去模糊方法往往难以处理严重的或空间变异的模糊情况。本文根据这一点，探讨了一个利用深度学习框架从单张模糊图像同时估计潜在清晰图像和相机运动轨迹的方法。该方法利用了一个高效的投影运动模糊模型（PMBM），并且通过一个可与现代网络兼容的差分模糊生成模块实现。此外，该方法还能从模糊输入中重建产生模糊图像的序列清晰图像。
### Innovation
本文提出了一种模块化架构，利用有效的投影运动模糊模型和差分模糊生成模块，能够从单张模糊图像中同时估计清晰图像和相机运动轨迹。该模型能够预测完整的三维旋转轨迹，并引导端到端训练的模型基础去模糊网络进行图像恢复。此外，此方法还通过后优化轨迹提升恢复结果的精确度，提高模糊输入和恢复输出的一致性。
### Conclusion
本研究表明，该方法在合成和实际数据集上均取得了最先进的性能，特别是在严重的或空间变异的模糊情况上。码和训练模型可以在此链接下载：this https URL
## 525. `cs.CV` - 从廉价到专业：基于学习的自适应摄像参数网络实现专业级成像 [PDF](https://arxiv.org/pdf/2510.20550), [HTML](https://arxiv.org/abs/2510.20550)
### Authors
Fuchen Li,Yansong Du,Wenbo Cheng,Xiaoxia Zhou,Sen Yin
### Background
消费级摄像头系统在复杂光照条件下（如低光照、高动态范围、背光和空间色温变化）难以保持稳定画质，导致曝光不足、色彩偏差和色调不一致，影响后续视觉任务性能。
### Innovation
提出ACamera-Net，一种轻量级且场景适应的摄像参数调整网络，直接从RAW输入预测最优曝光和白平衡设置。该框架包括两个模块：ACamera-Exposure估算ISO以缓解曝光不足和对比度损失，ACamera-Color预测相关色温和增益因子以提高色彩一致性。该模型优化了边缘设备上的实时推理，可无缝集成到成像管道中，并且在多种照明条件下泛化效果良好。实验表明ACamera-Net在提升画质和稳定感知效果方面优于传统自动模式和其他轻量级基线，无需额外图像增强模块的支持。
### Conclusion
ACamera-Net通过实验证明能够稳定和提升图像质量，使廉价摄像头的图像质量接近专业设备水平，为边缘设备上的实时视频流和画面质量优化提供了新的解决方案。
## 526. `cs.CV` - Fake-in-Facext: 向精细化可解释深度伪造分析迈进 [PDF](https://arxiv.org/pdf/2510.20531), [HTML](https://arxiv.org/abs/2510.20531)
### Authors
Lixiong Qin,Yang Zhang,Mei Wang,Jiani Hu,Weihong Deng,Weiran Xu
### Background
多模态大型语言模型（MLLMs）的进步已经弥合了视觉和语言任务之间的差距，使得实施可解释的深度伪造分析（XDFA）成为可能。然而，当前方法存在细粒度感知不足的问题：数据注释中对于伪像的描述不可靠且粗放，模型无法支持文本伪造解释与伪像视觉证据之间的连接输出，也无法接受任意面部区域的查询。因此，其响应无法充分依托人脸视域场景（Facext）背景信息。
### Innovation
本文提出了Fake-in-Facext (FiFa)框架，该框架对数据注释和模型构建做出了贡献。首先定义了面部图像概念树（FICT）将面部图像划分为细粒度的区域概念，从而获得更加可靠的注释流程FiFa-Annotator，用于生成伪造解释。基于专属性注释，引入了新的伪像关联解释（AGE）任务，该任务生成与篡改伪像分割掩码交错的文本伪造解释。提出的统一多任务学习架构FiFa-MLLM能够同时支持丰富的多模态输入和输出，支持细粒度的可解释深度伪造分析。
### Conclusion
通过多个辅助监督任务，FiFa-MLLM在AGE任务上表现出色，已经在现有XDFA数据集上达到SOTA性能。代码和数据将在此处开放：[提供链接]。
## 527. `cs.CV` - 基于相似性原型的无监督域适应方法在跨模态分割中的应用 [PDF](https://arxiv.org/pdf/2510.20596), [HTML](https://arxiv.org/abs/2510.20596)
### Authors
Ziyu Ye,Chen Ju,Chaofan Ma,Xiaoyun Zhang
### Background
深度学习模型在各种视觉挑战中取得了巨大成功，但这些模型在应用于未见过的数据时会面临严重的性能下降。由于模型对领域变换敏感，无监督域适应试图减少领域差距，并避免对未见过的领域进行昂贵的标注。
### Innovation
该论文提出了一种新的跨模态分割框架，通过相似性原型。具体来说，通过嵌入空间学习类间的原型，引入相似性约束使其具有代表性且彼此可区分；使用字典存储来自不同图像的原型，避免类别缺失，促进原型的对比学习，进一步提高性能。
### Conclusion
广泛的实验表明，该方法在跨模态分割中的表现优于其他最先进的方法。
## 528. `cs.CV` - EmbodiedBrain: 扩展具身智能力量规划的性能边界 [PDF](https://arxiv.org/pdf/2510.20578), [HTML](https://arxiv.org/abs/2510.20578)
### Authors
Ding Zou,Feifan Wang,Mengyu Ge,Siyuan Fan,Zongbing Zhang,Wei Chen,Lingfeng Wang,Zhongyou Hu,Wenrui Yan,Zhengwei Gao,Hao Wang,Weizhao Jin,Yu Zhang,Hainan Zhao,Mingliang Zhang,Xianxian Xi,Yaru Zhang,Wenyuan Li,Zhengguang Gao,Yurui Zhu
### Background
当前的大型语言模型（LLMs）和多模态大型语言模型（MLLMs）在具身任务中存在关键限制，包括模型设计与代理要求之间的显著差距、实时延迟与性能之间的不可避免权衡，以及使用不真实的离线评估指标。因此，需要一种能够在物理环境中实现鲁棒空间感知、有效任务规划和适应性执行的具身AI代理。
### Innovation
提出了EmbodiedBrain，这是一个新颖的视语言基础模型，提供了7B和32B两种参数规模。该框架包括代理对齐的数据结构，并采用了一种强大的训练方法，将大规模监督微调（SFT）与步骤增强组相对策略优化（Step-GRPO）结合，通过将先前步骤纳入引导先行者来增强长期任务成功。此外，还整合了一个全面的奖励系统，包括加速基础设施的生成奖励模型（GRM），以提高训练效率。为了进行全面验证，建立了包含通用、规划和端到端仿真基准的三个部分评估系统，其中包括新的、具有挑战性的仿真环境提案和开源。
### Conclusion
实验证明，EmbodiedBrain在所有指标上均表现出卓越的性能，确立了具身基础模型的新最高水平。为此，下一代具身通用代理的发展铺平了道路，所有数据、模型权重和评估方法均开源，可通过this https URL访问。
## 529. `cs.CV` - OnlineSplatter：无姿态的在线自由移动物体3D重建 [PDF](https://arxiv.org/pdf/2510.20605), [HTML](https://arxiv.org/abs/2510.20605)
### Authors
Mark He Huang,Lin Geng Foo,Christian Theobalt,Ying Sun,De Wen Soh
### Background
基于单目视频的自由移动物体三维重建仍然具有挑战性，尤其是缺乏可靠的位姿或深度线索，以及任意物体运动的情况下。现有的方法通常需要姿态、深度先验或束优化，增加了实现的复杂度。
### Innovation
提出了一种名为OnlineSplatter的新颖的在线预测框架，直接从RGB帧生成高质量的物体中心3D高斯，无需相机姿态、深度先验或束优化。该方法以第一帧作为基础，并通过密集的高斯原始场逐步细化对象表示，保持恒定的计算成本，而不受视频序列长度的影响。核心贡献是一个结合潜在外观-几何键与显式方向键的双向记忆模块，该模块通过时空聚合的对象状态与当前帧特征进行鲁棒融合，从而有效处理自由移动的物体。通过空间引导的记忆读取和高效的稀疏化机制确保全面而紧凑的对象覆盖。
### Conclusion
在真实世界数据集上的评估表明，OnlineSplatter显著超越现有的无姿态重建基线，在获得更多信息观察时持续改进，同时保持恒定的内存和运行时间。
## 530. `cs.CV` - GenColorBench:中文版标题为：GenColorBench：用于文本到图像生成模型的颜色评估基准 [PDF](https://arxiv.org/pdf/2510.20586), [HTML](https://arxiv.org/abs/2510.20586)
### Authors
Muhammad Atif Butt,Alexandra Gomez-Villa,Tao Wu,Javier Vazquez-Corral,Joost Van De Weijer,Kai Wang
### Background
近年来，文本到图像生成领域取得了显著进展，生成模型能够从文本生成高质量的图像。然而，这些模型在细微色彩控制方面仍存在不足，难以准确匹配文本指令中指定的颜色。现有的基准主要评估组合理解和指令遵循能力，但没有系统地评估色彩精确度。色彩是人类视觉感知和沟通的基础，对从艺术到设计工作流程需要品牌一致性等应用至关重要。然而，现有的基准要么忽略色彩，要么依赖粗糙的评估，未能涵盖诸如解读RGB值或与人类期望对齐等关键能力。
### Innovation
本文提出了GenColorBench，这是首个全面的用于文本到图像颜色生成的基准，基于ISCC-NBS和CSS3/X11等色彩系统，涵盖了数值色彩，而这些是其他地方没有的。GenColorBench包含了覆盖400多种色彩的44000个颜色聚焦提示，能够通过感官和自动化评估揭示模型的真实能力。利用GenColorBench对流行的文本到图像模型进行评估，展示了模型在色彩生成上的表现差异，指出了哪些色彩规范模型理解最佳，并识别了失败模式。GenColorBench评估将指导精确色彩生成的改进。
### Conclusion
GenColorBench将作为公共基准供大家使用，为文本到图像生成模型在颜色生成方面的性能提供系统的评估方法，指导模型的改进。
## 531. `cs.CV` - Open-o3 Video: 显式的时空证据支撑视频推理 [PDF](https://arxiv.org/pdf/2510.20579), [HTML](https://arxiv.org/abs/2510.20579)
### Authors
Jiahao Meng,Xiangtai Li,Haochen Wang,Yue Tan,Tao Zhang,Lingdong Kong,Yunhai Tong,Anran Wang,Zhiyang Teng,Yujing Wang,Zhuochen Wang
### Background
大多数视频推理模型只生成文本推理痕迹，而不指明关键证据的出现时间和地点。虽然近年来如OpenAI-o3这样的模型激发了在图像中进行以证据为中心的推理的兴趣，但在视频中扩展这种能力更具挑战性，因为它需要在动态场景中对时间和空间特征进行联合跟踪和定位。本研究旨在克服这一挑战，引入了一种非代理框架——Open-o3 Video，该框架整合了视频推理中的明确时空证据，并通过精心收集训练数据和设计训练策略来应对上述挑战，使推理过程能够基于具体的视觉观察有一个明确的依据。
### Innovation
作者首次构建了高质量的STGR-CoT-30k和STGR-RL-36k数据集，解决了现有数据集通常只能提供视频的时间跨度或图像的空间框，缺乏统一的时空监督和推理痕迹的问题。此外，提出了冷启动强化学习策略，并设计了多种奖励以促进答案准确性、时间和空间匹配度。在V-STAR基准上，Open-o3 Video在Qwen2.5-VL基线上取得了最先进的性能，同时在多个视频理解基准上也表现出一致的改进，包括VideoMME、WorldSense、VideoMMMU和TVGBench。
### Conclusion
Open-o3 Video通过明确的时空证据实现了视频推理，能够突出关键时间点、对象及边界框，并与答案一同展现，使推理可以基于具体的视觉观察。其模型架构不仅提高了视频理解的准确性和可靠性，还为测试时的扩展提供了有价值的信号，增强了答案的可靠性。
## 532. `cs.CV` - SeViCES：统一语义-视觉证据共识的长视频理解 [PDF](https://arxiv.org/pdf/2510.20622), [HTML](https://arxiv.org/abs/2510.20622)
### Authors
Yuan Sheng,Yanbin Hao,Chenxu Li,Shuo Wang,Xiangnan He
### Background
长视频理解由于其复杂的、多样化的以及时间上分散的内容而颇具挑战性。尽管视频大型语言模型（Video-LLMs）可以处理几十分钟的视频，但在真正长序列上应用它们是计算上不可行且常常导致不聚焦或不一致的推理。现有方法通常只是选择最信息丰富的帧，但它们通常忽视时间依赖性或依赖单一模态的证据，限制了它们提供完整且查询相关背景信息的能力。
### Innovation
我们提出了一种无需训练且模型无关的语义-视觉共识证据选择（SeViCES）框架。SeViCES通过引入两个关键组件来实现有效的且可靠的长视频理解：1) 语义-视觉共识帧选择（SVCFS）模块，通过一个时间意识的语义分支利用LLM对字幕的推理和一个基于聚类的视觉分支，利用互信息对嵌入与语义分数进行对齐；2) 答案共识细化（ACR）模块，通过融合证据和限制答案空间来解决基于语义和视觉预测之间的一致性问题。
### Conclusion
在长视频理解基准上的广泛实验表明，SeViCES在准确性和鲁棒性上都优于最新的方法，这显示出共识驱动的证据选择对于Video-LLMs的重要性。
## 533. `cs.CV` - 深度学习在牙科图像分析中的应用：数据集、方法和技术挑战的系统综述 [PDF](https://arxiv.org/pdf/2510.20634), [HTML](https://arxiv.org/abs/2510.20634)
### Authors
Zhenhuan Zhou,Jingbo Zhu,Yuchen Zhang,Xiaohang Guan,Peng Wang,Tao Li
### Background
牙科图像的高效分析和处理对于牙医实现准确诊断和最优治疗规划至关重要。然而，牙科影像固有地带来了诸如对比度低、金属伪影和投影角度差异等挑战。加之牙医之间专业知识差异导致的主观性，手工解释往往耗时且易出现不一致性。基于人工智能（AI）的牙科图像分析（DIA）自动化的解决方案显现出了巨大的潜力，并已成为计算机辅助牙科诊断和治疗不可或缺的一部分。在各种AI技术中，深度学习（DL）因其优异的特征提取和表示能力而被广泛应用于这一领域。
### Innovation
本文系统回顾了260项关于深度学习在牙科图像分析应用的研究，包括49篇关于公开可用的牙科数据集的论文和211篇关于基于深度学习的算法的论文。介绍了牙科影像的基本概念，总结了现有数据集的特性和获取方法，分类整理了相关模型和算法，分析了它们的网络架构、优化策略、训练方法和性能。此外，汇总了牙科图像分析领域常用的训练和评估指标。
### Conclusion
本文讨论了现有研究中存在的挑战，并概述了未来可能的研究方向。希望能为该领域的研究人员提供有价值的参考。所有补充材料和详细比较表将在GitHub上公开可用。
## 534. `cs.CV` - Conan: 进阶学习如同侦探般在多尺度视觉证据上进行推理 [PDF](https://arxiv.org/pdf/2510.20470), [HTML](https://arxiv.org/abs/2510.20470)
### Authors
Kun Ouyang,Yuanxin Liu,Linli Yao,Yishuo Cai,Hao Zhou,Jie Zhou,Fandong Meng,Xu Sun
### Background
视频推理要求在多帧之间进行多步推理，这是多模态大型语言模型（MLLMs）面临的重大挑战。尽管基于强化学习（RL）的方法可以提升推理能力，但它们往往依赖于仅文本的推理链，导致无法获得可靠的结论。相反，帧检索方法虽然引入了视觉语境，但仍然难以准确地定位证据。因此需要一种既能提升描述能力又能确保推理准确性的方法来应对这些挑战。
### Innovation
我们提出了Conan框架以实现基于证据的多步视频推理。Conan通过（1）构建包含帧识别、证据推理和行为决策的大规模自动推理追踪数据集——Conan-91K，以及（2）设计多阶段逐步冷启动策略和包含识别-推理-行动（AIR）的逐步增强RLVR训练框架，分别增强了多步视觉推理能力。实验结果表明，Conan比基准模型Qwen2.5-VL-7B-Instruct在准确性上平均高出10%以上，并在长视频理解任务中的泛化能力良好，验证了其强大的可扩展性和鲁棒性。
### Conclusion
Conan在多个多步推理基准测试中表现优异，平均准确率超过基线10%以上，展现了超出领先水平的能力，并且在长视频理解任务中表现出良好的通用性和鲁棒性。
## 535. `cs.CV` - Better Tokens for Better 3D: Advancing Vision-Language Modeling in 3D Medical Imaging [PDF](https://arxiv.org/pdf/2510.20639), [HTML](https://arxiv.org/abs/2510.20639)
### Authors
Ibrahim Ethem Hamamci,Sezgin Er,Suprosanna Shit,Hadrien Reynaud,Dong Yang,Pengfei Guo,Marc Edgar,Daguang Xu,Bernhard Kainz,Bjoern Menze
### Background
近年来，3D 医学成像中的视-语模型进展得益于大规模的配对自由文本报告的计算机断层扫描（CT）数据集、更强的架构和更强大的预训练模型。这些进展促成了自动化报告生成和基于文本条件的3D图像合成等应用的出现。然而，当前的方法在处理高分辨率和长序列的体积数据时遇到了困难：对比预训练往往会生成与临床语言不一致的视觉编码器，而逐层面的分词则模糊了精细的解剖结构，降低了下游任务的诊断性能。
### Innovation
本文提出了BTB3D（更好的3D标记），这是一种因果卷积编码-解码器，统一了2D和3D的训练和推理，同时生成紧凑、频率感知的体素标记。通过三阶段的训练课程，分别实现局部重建、重叠窗口镶嵌和长上下文解码器优化，模型能够在不增加内存开销的情况下，从短切片片段学习并泛化到超过300片切的扫描。在两个关键任务上，BTB3D 设置了新的最先进的水平：在报告生成任务中，BLEU分数提高了，临床F1分数提高了40%；在文本到CT合成任务中，FID降低了75%，FVD减半，生成了解剖上一致的512x512x241体素。这些结果证实了精确的三维标记化对于3D医学成像中的可扩展视-语建模至关重要，而不仅仅是更大的语言后台架构。
### Conclusion
这些结果证实了精确的三维标记化，而非仅仅更大的语言后台架构，是3D医学成像中可扩展视-语建模的关键。BTB3D的代码库可在 [这里](this https URL) 获取。
## 536. `cs.CV` - 利用视觉变换器实现高精度肺癌检测和实时部署的动态权重调整知识蒸馏 [PDF](https://arxiv.org/pdf/2510.20438), [HTML](https://arxiv.org/abs/2510.20438)
### Authors
Saif Ur Rehman Khan,Muhammad Nabeel Asim,Sebastian Vollmer,Andreas Dengel
### Background
本文介绍了利用动态模糊逻辑驱动的知识蒸馏（KD）方法的FuzzyDistillViT-MobileNet模型，旨在解决肺癌（LC）诊断中的不确定性和复杂性问题。传统的知识蒸馏方法依赖于静态KD和固定的权重，而本文的方法通过动态调整蒸馏权重，使学生模型能够专注于高置信度区域，同时减少对模糊区域的注意力。研究使用了Vision Transformer (ViT-B32) 作为教师模型，有效地将知识传递给学生模型MobileNet，提高了学生的泛化能力。此外，采用了像素级图像融合改善技术，如伽马校正和直方图均衡化，以及小波变换融合，以增强图像质量和特征保留。通过遗传算法选择最适合的预训练学生模型，以平衡模型性能和计算成本。模型在两个数据集上进行了评估，显示了在不同成像领域的稳健性。
### Innovation
本文的创新在于提出了一种利用动态模糊逻辑驱动的知识蒸馏方法，该方法通过动态调整蒸馏权重，使学生模型能够更好地处理肺癌图像中的各种不确定性。此外，引入了像素级图像融合技术以及利用遗传算法选择最合适的预训练学生模型。这种动态权重调整机制和融合技术提高了模型在肺癌检测中的准确性和实时部署能力。
### Conclusion
本文提出的方法在两个数据集上均显示出高的准确率，分别达到99.16%和99.54%，证明了该模型在不同成像领域的稳健性和高精度。该方法能够有效应对肺癌识别中的不确定性并提供高精度的识别结果，适于实现实时部署。
## 537. `cs.CV` - 诊断视觉推理：挑战、洞见及未来之路 [PDF](https://arxiv.org/pdf/2510.20696), [HTML](https://arxiv.org/abs/2510.20696)
### Authors
Jing Bi,Guangyu Sun,Ali Vosoughi,Chen Chen,Chenliang Xu
### Background
目前，多模态大语言模型通过结合视觉和文本推理，并利用链式思维（CoT）提示来处理复杂的视觉任务，但这些模型仍然存在视觉幻觉和过度依赖文本先验的问题。
### Innovation
本文提出了一个三阶段评估框架，系统地诊断最先进的视觉-语言模型的关键故障模式。为此，提出了一种基于代理的架构，将LLM推理与轻量级视觉模块结合，实现精细的推理链条分析和逐步改进。研究结果表明，未来视觉推理模型应整合更广泛的专业工具来分析视觉内容，该系统在MMMU和MathVista上相对于7B基线分别取得了显著提升(+10.3和+6.0)，并接近或超越了更大的模型。
### Conclusion
我们发布了该评估框架和评估套件，以促进未来的相关研究。
## 538. `cs.CV` - HybridSOMSpikeNet：结合不同可微软自组织映射和脉冲动力学的深度模型及其在废物分类中的应用 [PDF](https://arxiv.org/pdf/2510.20669), [HTML](https://arxiv.org/abs/2510.20669)
### Authors
Debojyoti Ghosh,Adrijit Goswami
### Background
准确的废物分类对于实现可持续废物管理并减轻城市化进程对环境的影响至关重要。回收材料的错误分类会导致填埋场累积、回收效率低下和温室气体排放增加。为解决这些问题，本研究引入了HybridSOMSpikeNet，这是一种结合卷积特征提取、可微自组织和脉冲启发式时间处理的混合深度学习框架，用于实现智能和节能的废物分类。
### Innovation
该研究提出了一种名为HybridSOMSpikeNet的混合深度学习框架，集成了卷积特征提取、可微自组织和脉冲启发式的时序处理，以实现智能和节能的废物分类。该模型使用预训练的ResNet-152主干来提取深层空间表示，随后使用可微软自组织图（Soft-SOM）增强拓扑聚类和可解释性。脉冲神经网络头部在离散时间步中累积激活，增强了鲁棒性和泛化能力。与多个最先进的架构相比，测试准确率达到97.39%，保持了轻量化的计算特性，适用于实际部署。
### Conclusion
该框架不仅具有技术创新，还提供了实际的环境效益。通过实现精确和自动的废物分离，提高回收效率，减少回收物料的污染，减少废物处理的生态和运营成本。该方法符合全球可持续发展目标，特别是联合国可持续发展目标11和12，通过推动清洁城市、循环经济倡议和智能环境管理系统来贡献力量。
## 539. `cs.CV` - 通过权重偏差校正和位级核心采样实现高效的多比特量化网络训练 [PDF](https://arxiv.org/pdf/2510.20673), [HTML](https://arxiv.org/abs/2510.20673)
### Authors
Jinhee Kim,Jae Jun An,Kang Eun Jeon,Jong Hwan Ko
### Background
现有的多比特量化网络通常会带来显著的训练开销，因为需要对每个支持的不同精度等级进行全面的数据集更新，这导致计算成本与精度等级数量成线性关系。此外，为了支持额外或中间的精度选项，常常需要额外的微调阶段，这进一步增加了整体训练负担。
### Innovation
提出了两种技术以大幅减少训练开销而不牺牲模型实用性：(i) 权重偏差校正能够共享批量规范化，并通过消除量化偏差和对激活分布进行对齐来取消对额外微调的需求；(ii) 位级核心采样策略允许每个子模型仅从通过渐变重要性评分选择的紧凑且信息丰富的子集中进行训练，利用潜在的知识传递现象。
### Conclusion
在CIFAR-10/100、TinyImageNet和ImageNet-1K上的实验表明，该方法在保持同等或更优准确率的同时，可将训练时间最多减少7.88倍。代码已发布于this https URL.
## 540. `cs.CV` - UltraHR-100K: 基于大规模高质量数据集增强UHR图像合成 [PDF](https://arxiv.org/pdf/2510.20661), [HTML](https://arxiv.org/abs/2510.20661)
### Authors
Chen Zhao,En Ci,Yunzhe Xu,Tiehan Fan,Shanyan Guan,Yanhao Ge,Jian Yang,Ying Tai
### Background
超高分辨率（UHR）文本到图像（T2I）生成已经取得了显著的进步，但依然存在两大挑战：1）缺少一个大型高质量UHR文本到图像数据集，2）忽视了在UHR场景中定制化生成细粒度细节的训练策略。现有方法难以生成高质量且细节丰富的超高清图像。因此，本文通过创建一个高质量的100K超高清图像数据集UltraHR-100K解决数据不足的问题，提供多样且高质量的图像内容，每个图像的分辨率都超过3K，并且经过详细筛选以确保细节丰富、内容复杂和美观质量。为解决训练策略不足的问题，提出了一种频率感知的后训练方法，该方法增强T2I扩散模型中的细粒度细节生成效果。具体方法包括针对关键去噪步骤进行学习的Detail-Oriented Timestep Sampling (DOTS) 和利用离散傅里叶变换（DFT）的软权重频率正则化Soft-Weighting Frequency Regularization (SWFR)。实验表明该方法能显著提升超高清图像生成的细粒度细节质量并增强整体保真度。
### Innovation
本文的创新之处在于提出了一个高质量的超高清图像数据集UltraHR-100K，解决了UHR T2I数据不足的问题，具有超高分辨率、高质量的图像内容，同时还能提供丰富的图像细节。此外，还提出了一种专注于细粒度噪声去除步骤的方法（DOTS）及一种利用频率信息增强细粒度细节生成的软约束方法（SWFR）。
### Conclusion
实验结果在UltraHR-eval4K基准上表明，本文方法在细粒度细节质量和整体保真度方面有显著提升。该方法不仅解决了UHR场景中的数据不足问题，还有效增强了细粒度生成能力。源代码可在这里获取。
## 541. `cs.CV` - 在大型视觉语言模型中结合重要性和多样性进行联合优化以对KV缓存进行压缩 [PDF](https://arxiv.org/pdf/2510.20707), [HTML](https://arxiv.org/abs/2510.20707)
### Authors
Xuyang Liu,Xiyan Gui,Yuchao Zhang,Linfeng Zhang
### Background
最近的大型视觉语言模型（LVLMs）展示了在处理扩展的多模态序列方面的卓越能力，但是这导致了关键值（KV）缓存扩展，成为限制部署可扩展性的关键内存瓶颈。现有的KV缓存压缩方法主要集中在保留高重要性的KV对以减少存储需求，但往往会忽略多模态KV缓存中出现的模态特定语义冗余模式。
### Innovation
本文分析了LVLMs中的KV缓存不仅在重要性上存在差异，还在多个注意力头之间表现出不同程度的冗余性。为此，我们提出了一种新颖的方法 texttt{MixKV}，该方法结合了重要性和多样性，以优化KV缓存压缩。通过选择性地平衡多样性与重要性，texttt{MixKV}能够更好地适应模态特定的语义冗余。实验结果显示，texttt{MixKV}在多种大型视觉语言模型中均优于现有方法，尤其在极限压缩情况下取得了显著的性能提升。
### Conclusion
texttt{MixKV} 在多模态理解基准测试中平均提高了5.1%的现有方法性能，并且在GUI接地任务中分别取得了8.0%和9.0%的显著增益。此外，texttt{MixKV} 还能无缝扩展到其他大型语言模型，并且保持相似的推理效率。
## 542. `cs.CV` - AutoScape: 几何一致性的长时段场景生成 [PDF](https://arxiv.org/pdf/2510.20726), [HTML](https://arxiv.org/abs/2510.20726)
### Authors
Jiacheng Chen,Ziyu Jiang,Mingfu Liang,Bingbing Zhuang,Jong-Chyi Su,Sparsh Garg,Ying Wu,Manmohan Chandraker
### Background
当前，生成长时段的驾驶视频面临着严峻的挑战，尤其是在保持几何一致性方面。现有方法在生成高质量、连贯的视频帧时，容易出现不一致或低质量的问题。为解决这些问题，本文提出了一种新的框架AutoScape，旨在生成长达20秒以上的逼真驾驶视频。
### Innovation
AutoScape的核心是一种新颖的RGB-D扩散模型，该模型能够迭代生成几何上一致的关键帧，作为场景外观和几何结构的可靠锚点。该模型通过1) 在共享的潜在空间中同时处理图像和深度，2) 明确依赖于之前生成的关键帧中的场景几何结构（即渲染的点云），3) 通过一个缩放一致的引导机制来控制采样过程，从而确保长期的几何一致性。最后，使用一个视频扩散模型在高质量的RGB-D关键帧之间进行插值，生成密集且连贯的视频帧。
### Conclusion
AutoScape能够生成超过20秒的逼真且几何一致的驾驶视频，相较之前的先进水平而言，分别在长时段FID和FVD指标上提高了48.6%和43.0%。这表明该方法在生成高质量、连贯的长时段驾驶视频方面取得了显著的进步。
## 543. `cs.CV` - ALICE-LRI：一种无需校准元数据即可生成旋转LiDAR传感器无损范围图像的通用方法 [PDF](https://arxiv.org/pdf/2510.20708), [HTML](https://arxiv.org/abs/2510.20708)
### Authors
Samuel Soutullo,Miguel Yermo,David L. Vilariño,Óscar G. Lorenzo,José C. Cabaleiro,Francisco F. Rivera
### Background
3D LiDAR传感器在自主导航、环境监测和遥感应用中的精密测绘中至关重要。为了高效处理由这些传感器生成的大规模点云数据，LiDAR数据通常被投影到2D范围图像中，按角度位置和距离组织点。虽然这些范围图像表示形式可以实现高效的处理，但传统投影方法存在基本的几何不一致性，导致不可逆的信息损失，影响高保真应用。
### Innovation
本文提出了ALICE-LRI（自动LiDAR内在校准估算以生成无损范围图像），这是一种通用且传感器无关的方法，能够在不依赖制造商元数据或校准文件的情况下从旋转LiDAR点云生成无损范围图像。该算法可以自动逆向工程任何旋转LiDAR传感器的内在几何结构，推断出关键参数，包括激光束配置、角度分布和每束的校准修正，实现无损投影和完整点云重构，无点丢失。实验结果表明，ALICE-LRI 实现了完美的点保持，在所有点云中没有丢失任何点，几何精度也保持在传感器精度极限内，建立了实时性能的几何无失真性。此外，还进行了压缩案例研究，验证了明显的好处，证明在实际应用中，在质量上有了显著改进。这一从近似到无损LiDAR投影的范式转变为进一步要求完整几何保真的高精度遥感应用开辟了新的可能性。
### Conclusion
ALICE-LRI 的全面评估表明，在 KITTI 和 DurLAR 数据集中，它实现了完美的点保持，完全没有点丢失，几何精度保持在传感器精度范围内，实现了几何无失真性。这种实时性能的实现也为高精度远程传感应用提供了新的可能性，提高了下游应用的质量。
## 544. `cs.CV` - DyPE: 动态位置外插用于超高清分辨率扩散 [PDF](https://arxiv.org/pdf/2510.20766), [HTML](https://arxiv.org/abs/2510.20766)
### Authors
Noam Issachar,Guy Yariv,Sagie Benaim,Yossi Adi,Dani Lischinski,Raanan Fattal
### Background
扩散变换器模型能够生成具有极佳保真度和细节的图像，但它们在超高清分辨率下的训练代价异常高昂，因为自我注意机制与图像标记的数量呈二次增长。现有的方法在生成器训练和采样时都非常昂贵。因此，本文探讨了如何在不需要额外训练和采样成本的情况下，使已预训练的扩散变换器能够合成远超训练数据分辨率的图像，并在此过程中提出了动态位置外插（DyPE）方法。
### Innovation
DyPE 提出了一种无需训练的新型方法，能够使预训练的扩散变换器生成远超训练数据分辨率的图像，且不会增加额外的采样成本。方法利用生成过程中固有的频谱进展：低频结构会早期收敛，而高频成分则需要更多时间来解决。DyPE 动态调整模型的位置编码，使其频谱与当前生成过程阶段相匹配。这使模型能够在远超出训练分辨率的情况下生成图像，例如，使用 FLUX 可生成 1600 万像素的图像。在多个基准测试中，DyPE 的性能表现优秀且达到了超高清分辨率下图像生成的最新水平，尤其是在高分辨率下效果更为显著。
### Conclusion
DyPE 的方法在多个基准测试中展示了优越的性能，特别在高分辨率图像生成中达到了最先进的保真度，且无需额外的训练和采样成本。这种方法对于下一代超高清图像生成具有重要意义。
## 545. `cs.CV` - CUPID：单图像基于姿态的生成3D重建 [PDF](https://arxiv.org/pdf/2510.20776), [HTML](https://arxiv.org/abs/2510.20776)
### Authors
Binbin Huang,Haobin Duan,Yiqun Zhao,Zibo Zhao,Yi Ma,Shenghua Gao
### Background
当前3D重建方法主要依赖于多视角图像或复杂的传感器配置，对于单图像下的3D物体重建精度和细节表现具有挑战。
### Innovation
Cupid通过将3D重建视为从已学习的3D物体分布中进行条件采样的过程，提出了一种基于生成的两阶段方法。方法包括：1）粗略阶段生成初始3D几何和伴随的2D投影用于姿态恢复；2）精细阶段结合对齐的姿态图像特征以增强结构保真度和外观细节。该方法在统一生成框架中同时生成体素和像素-体素对应关系，以实现鲁棒的姿态和形状估计，并在多个实验验证上优于现有方法。
### Conclusion
Cupid在峰值信噪比（PSNR）上提高了超过3 dB，减少超过10%的切氏距离（Chamfer Distance），同时在姿态准确性上与单目估计保持一致，并在基本3D生成模型上提供更优越的视觉保真度。
## 546. `cs.CV` - 基于雷达-摄像头融合的多目标跟踪：在线校准与公共特征 [PDF](https://arxiv.org/pdf/2510.20794), [HTML](https://arxiv.org/abs/2510.20794)
### Authors
Lei Cheng,Siyang Cao
### Background
许多研究中雷达的使用被低估，往往被赋予辅助角色，仅提供补充信息，而非充分挖掘其提供准确三维范围/深度信息的能力。此外，现有的多对象跟踪（MOT）框架通常不利用雷达和摄像头之间的公共特征进行在线校准，从而影响了检测结果的关联精度。
### Innovation
本文提出了一种雷达-摄像头融合的多对象跟踪框架，通过在线雷达-摄像头校准简化了两种传感器检测结果的整合；利用雷达和摄像头数据之间的公共特征准确推导出检测目标的真实世界位置，并采用特征匹配和类别一致性检查来提高传感器关联的准确性。这是首次研究雷达和摄像头公共特征的利用及其在线校准在多目标跟踪中的应用。
### Conclusion
本文所提出的框架通过简化雷达-摄像头映射过程和提高跟踪精度，已经在受控环境和实际交通场景中的真实世界实验中得到了验证。代码已开源。
## 547. `cs.CV` - ACS-SegNet: 基于注意力机制的CNN-SegFormer组织分割网络在病理学中应用 [PDF](https://arxiv.org/pdf/2510.20754), [HTML](https://arxiv.org/abs/2510.20754)
### Authors
Nima Torbati,Anastasia Meshcheryakova,Ramona Woitek,Diana Mechtcheriakova,Amirreza Mahbod
### Background
计算机辅助诊断中自动组织病理学图像分析扮演着重要角色，尤其是基于深度学习的方法在多任务中表现出色，比如组织学图像的语义分割。本文探讨了如何利用注意力驱动的卷积神经网络（CNN）和视觉变换器（ViT）的特征融合来提高语义分割性能，并在两个公开可用的数据集上进行了评估。
### Innovation
提出了一种新颖的方法，基于统一的双编码器模型中的注意力驱动特征融合的卷积神经网络（CNN）和视觉变换器（ViT），以此来改善语义分割性能。实验结果表明，该模型在GCPS数据集上达到了μIoU/μDice分数的76.79%/86.87%，在PUMA数据集上达到了64.93%/76.60%，超越了当前最先进的和基准模型。
### Conclusion
在两个公开数据集上的评估表明，该方法表现出色，超越了现有的最先进的模型和基准。该方法已在GitHub上公开实现：this https URL
## 548. `cs.CV` - ARGenSeg: 图像分割中的自回归图像生成模型 [PDF](https://arxiv.org/pdf/2510.20803), [HTML](https://arxiv.org/abs/2510.20803)
### Authors
Xiaolong Wang,Lixiang Ru,Ziyuan Huang,Kaixiang Ji,Dandan Zheng,Jingdong Chen,Jun Zhou
### Background
现有的将图像分割融入多模态大型语言模型（MLLMs）的方法通常采用边界点表示或专用分割头。这些方法依赖于离散表示或输入任务特定解码器的语义提示，这限制了MLLM捕捉到细微的视觉细节的能力。论文介绍了一种基于图像生成的分割框架，用于MLLM，它自然地生成了目标对象的密集掩码。这种方法利用MLLM输出视觉令牌，并使用通用VQ-VAE将其解码为图像，使分割完全依赖于MLLM的像素级理解。为减少推理延迟，采用了下一尺度预测策略并行生成所需的视觉令牌。
### Innovation
提出了新的自回归生成器基线图（ARGenSeg）的图像分割方法。该方法基于图像生成，提供了一种多模态理解和像素级感知统一框架。利用多模态大型语言模型输出视觉令牌，通过通用VQ-VAE解码为图像，实现了对MLLM像素级理解的依赖。采用下一尺度预测策略以并行方式生成所需的视觉令牌，大幅减少了推理延迟，同时保持了强大的理解能力。
### Conclusion
实验结果表明，该方法在多个图像分割数据集上超过了之前的SOTA方法，在推理速度上有显著提升，同时保持了较强的了解能力。
## 549. `cs.CV` - AlphaFlow：理解并改进MeanFlow模型 [PDF](https://arxiv.org/pdf/2510.20771), [HTML](https://arxiv.org/abs/2510.20771)
### Authors
Huijie Zhang,Aliaksandr Siarohin,Willi Menapace,Michael Vasilkovsky,Sergey Tulyakov,Qing Qu,Ivan Skorokhodov
### Background
MeanFlow作为一种新兴的用于无监督生成建模的框架，尽管表现出色，但其成功的原因尚未完全理解。
### Innovation
作者通过梯度分析发现，MeanFlow目标可以自然地分解为轨迹流匹配和轨迹一致性两个部分，并且这两个部分之间存在强烈的负相关关系，导致优化冲突和收敛缓慢。基于这些见解，作者提出了α-Flow，这是一种广义的目标家族，它统一了轨迹流匹配、捷径模型和MeanFlow，并通过一种从轨迹流匹配到MeanFlow的逐渐退火的课程策略来分离这些冲突的目标，从而实现更好的收敛。使用vanilla DiT骨干网络从头训练在类条件性ImageNet-1K 256x256上，α-Flow在各种规模和设置下均优于MeanFlow，且最大的α-Flow-XL/2+模型达到了最先进的结果。
### Conclusion
我们的最大模型α-Flow-XL/2+在使用vanilla DiT骨干网络的情况下取得了最先进的结果，FID分数分别为2.58（1-NFE）和2.15（2-NFE）。
## 550. `cs.CV` - 层架者：通过空间感知分层画布实现互动个性化T2I [PDF](https://arxiv.org/pdf/2510.20820), [HTML](https://arxiv.org/abs/2510.20820)
### Authors
Guocheng Gordon Qian,Ruihang Zhang,Tsai-Shien Chen,Yusuf Dalva,Anujraaj Argo Goyal,Willi Menapace,Ivan Skorokhodov,Meng Dong,Arpit Sahni,Daniil Ostashev,Ju Hu,Sergey Tulyakov,Kuan-Chieh Jackson Wang
### Background
尽管现有的个性化生成模型在视觉保真度方面表现出色，但它们缺乏对空间构成的互动控制，并且在处理多个主体时表现不佳。
### Innovation
提出了LayerComposer，一种交互式框架，用于多主体的个性化文本到图像生成。该框架引入了两个主要贡献：1) 分层画布，在其中每个主体被放置在单独的图层上，使无遮挡组合成为可能；2) 锁定机制，保留选定图层的高保真度，同时允许其余图层灵活适应周围环境。
### Conclusion
通过广泛的实验表明，与多主体个性化图像生成的最新方法相比，LayerComposer在空间控制和身份保留方面表现更优。
## 551. `cs.CV` - 小草案，大裁决：通过推测进行密集信息视觉推理 [PDF](https://arxiv.org/pdf/2510.20812), [HTML](https://arxiv.org/abs/2510.20812)
### Authors
Yuhan Liu,Lianhui Qin,Shengjie Wang
### Background
大视觉语言模型（VLMs）在多模态理解方面取得了显著进展，但在处理密集排列的文字注释和细腻图形元素交织的信息密集型图像时，往往难以进行有效的推理。主要挑战在于精确定位复杂布局中的关键线索以及进行多步推理以整合分散的证据。现有的方法难以高效且准确地解决这些问题，尤其是在需要精细定位和复杂推理的任务中。因此，本文旨在探讨一种新的训练方式来解决这一问题，提高信息密集型视觉推理的效率和准确性。
### Innovation
提出了Speculative Verdict (SV)框架，这是一种无需训练的框架，灵感来源于推测性解码，结合了多个轻量级的草案专家和一个大的裁决模型。它在草稿阶段使用小型VLMs作为草案专家，生成多样化的定位候选路径，在裁决阶段由强大的VLM综合这些路径生成最终答案。此外，SV引入了一种共识专家选择机制，仅将一致性高的推理路径传递到裁决阶段，进一步提升了效率和准确性。实验结果显示，SV在InfographicVQA、ChartMuseum、ChartQAPro和HR-Bench 4K等具有挑战性的信息密集型和高分辨率视觉问答基准测试中取得了稳定的改进。通过综合多条部分正确的推理路径，SV实现了错误纠正和成本效率。
### Conclusion
本文提出的Speculative Verdict框架在信息密集型视觉推理任务中表现出色，通过引入新的共识专家选择机制，能够在保持准确性的前提下提高计算效率。该方法不仅能够纠正错误，还能有效地利用推理路径中的部分正确信息，展示了其在视觉理解和图形解析任务中的潜力。
## 552. `cs.CV` - 基于对比和预测潜变量扩散桥的通用模态转换 [PDF](https://arxiv.org/pdf/2510.20819), [HTML](https://arxiv.org/abs/2510.20819)
### Authors
Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot
### Background
近期生成建模的进展使扩散模型成为从复杂数据分布中采样的顶尖工具。这些模型在如图像和音频等单一模态领域的表现十分突出，但在不同感受模态之间的模态转换(Modality Translation, MT)方面仍存在挑战。现有方法往往依赖于共享维度、高斯先验等限制性假设，限制了它们的通用性和理论基础。
### Innovation
本文提出了一种基于潜变量扩展的去噪扩散桥模型(Latent Denoising Diffusion Bridge Model, LDDBM)的新框架，用于模态转换。该方法能在共享的潜变量空间中学习任意模态之间的桥梁，无需对齐维度。该方法引入了对比对齐损失来确保配对样本的语义一致性，设计了通用的编码器-解码器架构，适用于潜变量空间中的噪声预测，并提出了预测损失来指导训练以实现准确的跨域转换，还探索了几种训练策略以提高稳定性。
### Conclusion
本文的方法支持任意模态对，且在多种模态转换任务中表现优异，包括多视图到3D形状生成、图像超分辨率和多视图场景合成。全面的实验和消融研究验证了该框架的有效性，建立了通用模态转换的新基线。有关更多信息，请参阅我们的项目页面: 这个链接。
## 553. `cs.CV` - SpectraMorph: 结构化潜空间学习用于自我监督的高光谱超分辨率 [PDF](https://arxiv.org/pdf/2510.20814), [HTML](https://arxiv.org/abs/2510.20814)
### Authors
Ritik Shah,Marco F Duarte
### Background
高光谱传感器能够捕捉每个像素密集的光谱，但其空间分辨率较低，导致边界模糊和混合像素效应。多光谱、RGB或全色相机等共注册伴生传感器提供了高分辨率的空间细节，从而推动了通过融合高光谱和多光谱图像实现高光谱超分辨率的方法。现有基于深度学习的方法表现强大，但它们依赖于不透明的回归模型，缺乏可解释性，在MSI具有非常少的波段时容易失效。
### Innovation
提出了一种基于物理的自我监督融合框架——SpectraMorph，该框架具有结构化的潜在空间。SpectraMorph 通过反混合法则引入了提取限端模式的瓶颈：从低分辨率高光谱传感器（HSI）中提取端模式签名，并使用紧凑的多层感知器从多光谱传感器（MSI）预测类似丰度的地图。光谱通过线性混合重建，训练通过MSI传感器的光谱响应函数以自我监督方式进行。与现有的基于深度学习的方法相比，SpectraMorph 生成可解释的中间结果，能在不到一分钟内训练完成，并且即使在使用单一波段（全色）的MSI时也能保持鲁棒性。实验结果表明，SpectraMorph 在合成数据集和真实数据集上均优于最先进的自我监督基准，并且在对抗监督基准时仍表现出色。
### Conclusion
SpectraMorph 在合成数据集和真实数据集上通过自我监督方式实现了高光谱超分辨率，并且即使在使用单一波段的多光谱图像时也能保持鲁棒性。与基于监督的学习方法相比，SpectraMorph 也具有竞争力。
## 554. `cs.CV` - 使用像素空间时序变换器进行动态物理模拟的视频预测 [PDF](https://arxiv.org/pdf/2510.20807), [HTML](https://arxiv.org/abs/2510.20807)
### Authors
Dean L Slack,G Thomas Hudson,Thomas Winterbottom,Noura Al Moubayed
### Background
受自回归大型语言模型（LLMs）的性能和可扩展性启发，基于变压器的模型在视觉领域取得了近期的成功。本研究探讨了基于变压器的方法在视频预测中的应用，并通过对比不同空间时序注意力布局来改进视觉领域的方法，特别关注于物理模拟的因果建模，这是现有视频生成方法中常见的不足之处。现有的视频生成方法通常缺乏对时空推理的隔离和训练，并且难以通过物理模拟数据集进行无监督训练。因此，本研究采用一种简单的端到端方法，提出一种纯变换器模型进行自回归视频预测，利用连续的像素空间表示方式。这种方法不依赖于复杂的训练策略或潜在特征学习组件，显著扩展了物理准确预测的时间范围（最多可达50%），同时在常见的视频质量指标上保持了相似性能。此外，还进行了可解释性实验以确定负责通过探针模型准确估计偏微分方程（PDEs）模拟参数的网络区域，并发现这种方法对于估计未知分布的模拟参数具有跨域适用性。
### Innovation
本研究提出了一种采用像素空间时序变换器的简单端到端模型进行自回归视频预测的方法。该方法通过直接利用连续的像素空间表征来预测视频，无需复杂的训练策略或潜在空间的特征学习组件。这种方法能显著延长物理准确预测的时间范围，并在通用的视频质量指标上保持相似的性能。此外，该研究还通过可解释性实验揭示了用于建模物理现象的相关网络区域，并验证了这种方法的泛化能力，即能够估计不同分布下的物理模拟参数。
### Conclusion
本文提出的方法为基于注意力的视频和时空建模提供了一个有效的平台，只需少量参数即可实现解释性好的模型，同时在保持或提升视频预测精度的同时缓解了现有方法的局限性。
## 555. `cs.CV` - HoloCine: 整体生成电影多镜头长视频叙事 [PDF](https://arxiv.org/pdf/2510.20822), [HTML](https://arxiv.org/abs/2510.20822)
### Authors
Yihao Meng,Hao Ouyang,Yue Yu,Qiuyu Wang,Wen Wang,Ka Leong Cheng,Hanlin Wang,Yixuan Li,Cheng Chen,Yanhong Zeng,Yujun Shen,Huamin Qu
### Background
现有的最先进的文本到视频模型在生成孤立片段方面表现出色，但在创建连贯的、多镜头叙事方面存在不足，而这些才是讲故事的本质。因此，本文研究如何弥合这一“叙事缺口”。
### Innovation
本文提出了一种名为HoloCine的模型，该模型能够整体生成整个场景，以确保从第一个镜头到最后一个镜头的全局一致性。该架构通过窗口跨注意力机制具体化文本提示，同时通过稀疏跨镜头自我注意力模式（在镜头内部密集但在镜头之间稀疏）确保生成高效性，适用于分钟尺度。HoloCine在叙事连贯性方面达到了新的前沿，并发展出令人瞩目的新兴能力，包括对人物和场景的持久记忆以及对电影技术的直观掌握。这项工作标志着从片段合成向自动化电影制作的转折点，使端到端的电影创作成为现实的未来。
### Conclusion
HoloCine为端到端的电影创作带来了重大突破，标志着电影制作自动化的新阶段，使得分钟尺度的多镜头长视频叙事生成成为可能。
## 556. `cs.CV` - FINDER：噪声数据集特征推断中的特征空间残差 [PDF](https://arxiv.org/pdf/2510.19917), [HTML](https://arxiv.org/abs/2510.19917)
### Authors
Trajan Murphy,Akshunna S. Dogra,Hanfeng Gu,Caleb Meredith,Mark Kon,Julio Enrique Castrillion-Candas
### Background
噪声数据集（信号与噪声比低、样本量小、数据采集有误等）是分类方法研究中的关键前沿领域，具有重要的理论和实践意义。
### Innovation
本文提出了一种名为FINDER的严谨框架，专门针对噪声数据集的分类问题进行分析，并设计了相应算法。FINDER将基本的随机分析思想融入特征学习和推断阶段，以最优方式考虑所有经验数据中固有的随机性。通过将经验数据集视为潜在随机场的实现（不假设其精确分布），利用Kosambi-Karhunen-Loéve扩张（KLE）分解成可计算的不可约成分，并通过特征值分解进行分类操作，从而实现了在噪声数据集上的分类。验证了FINDER在几个具有挑战性的、数据不足的科学领域中的有效性，实现了在阿尔茨海默病阶段分类和遥感检测森林砍伐领域的突破性成果。
### Conclusion
FINDER有望在特征学习和分类方面超越现有方法，但也存在失效模式和其他限制。
## 557. `cs.CV` - 自动化Iconclass分类：通过LLMs和RAG大规模分类宗教木刻 [PDF](https://arxiv.org/pdf/2510.19986), [HTML](https://arxiv.org/abs/2510.19986)
### Authors
Drew B. Thomas
### Background
现有的图像和关键词搜索方法在分类早期现代宗教图像方面存在局限性，而通过大型语言模型（LLMs）和矢量数据库结合检索增强生成（RAG）的新方法可以改善分类准确性，提供一种强大的分析早期现代视觉档案的工具。
### Innovation
该方法利用全页书籍插图的上下文，结合LLMs生成包含视觉和文本元素的详细描述，并通过混合矢量搜索将这些描述与相关的Iconclass代码匹配。该方法在五级和四级分类中的精度分别达到87%和92%，显著优于传统图像和关键词搜索。这种方法利用全页描述和RAG增强了分类准确性，展示了LLMs和RAG在艺术史和数码人文研究领域中的巨大潜力。
### Conclusion
该论文提出了一种结合LLMs、矢量数据库和RAG的新方法，用于大规模分析早期现代宗教图像。这种方法在分类精度上实现了显著提升，展示了LLMs和RAG在艺术史和数码人文领域的应用前景。
## 558. `cs.CV` - 原型为何坍塌：诊断并在原型式半监督学习中防止部分坍塌 [PDF](https://arxiv.org/pdf/2510.20108), [HTML](https://arxiv.org/abs/2510.20108)
### Authors
Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera
### Background
原型式半监督学习方法在多个原型融合到近乎相同的表示时经常遭受部分原型坍塌的问题。这种问题削弱了它们的主要目的——为编码器提供多样且具信息性的目标，以引导生成丰富的表示，导致实践者过度参数化原型集或添加非正式正则化项，这些只是缓解症状而非从根本上解决问题。
### Innovation
本文通过实验证明，原型坍塌源于编码器与原型的联合优化，促进了捷径学习。为了解决这一问题，作者提出了一种完全解耦的训练策略，将原型和编码器分别学以致用。具体而言，作者将原型建模为通过在线EM样式的程序逐步更新的高斯混合模型，并独立于编码器的损失函数。这种方法不仅消除了原型坍塌，而且不需要显式的正则化，从而获得具有多样性的原型和更强的下游性能。
### Conclusion
通过解耦编码器和原型的训练，本文提出的方法可以有效避免原型坍塌，无需显式的正则化手段，从而产生更具有多样性的原型，并显著提高下游任务的表现。
## 559. `cs.CV` - 基于AI姿态分析的阻力训练范围内运动范围变化的动力学特征分析 [PDF](https://arxiv.org/pdf/2510.20012), [HTML](https://arxiv.org/abs/2510.20012)
### Authors
Adam Diamant
### Background
本研究旨在利用AI技术对阻力训练中的动作姿态进行精确量化，通过分析Wolf等（2025）的研究数据，比较了八种上半身锻炼中部分长度化范围的运动（pROM）和全范围的运动（fROM）之间的差异，特别是在26名参与者中所进行的280次录像记录的数据处理中。研究通过提取帧级别的关节角度轨迹，重新计算迈克尔传渍，并使用随机效应元分析模型来涉足个体内部和动作间的差异性变异。结果显示，部分长度化重复动作中的运动范围较小，持续时间也较短，特别是在动作的离心阶段。进一步的变异分析表明，参与者水平的差异是主要的变异驱动因素，尽管存在某些特定的治疗效应。
### Innovation
研究引入了一个新的指标，即在部分长度化过程中达到的全范围运动的比例（%ROM），以显示部分长度化动作在不同锻炼中的相对一致性。该研究使用了数据驱动的方法和AI技术，提供了精准的动作姿态分析和动力学特征特性，为研究和推荐阻力训练提供了潜在的帮助和见解。
### Conclusion
研究表明，部分长度化运动不仅在运动范围上，而且在执行动力学和一致性方面与全范围运动存在差异。这强调了基于AI的方法在提升研究质量和改进阻力训练处方方面的潜力。
## 560. `cs.CV` - 多媒体感知的问答：检索和跨模态推理架构的综述 [PDF](https://arxiv.org/pdf/2510.20193), [HTML](https://arxiv.org/abs/2510.20193)
### Authors
Rahul Raja,Arpita Vats
### Background
传统的问答（QA）系统依赖于结构化的文本数据，但多媒体内容（如图像、音频、视频和结构化元数据）的快速增长为检索增强的QA带来了新的挑战和机遇。这些挑战和机遇涉及到将视觉、语言和音频模态与用户查询对齐的目标。
### Innovation
本文综述了集成了多媒体检索管道的最新QA系统进展，重点关注视觉、语言和音频模态与用户查询对齐的体系结构。此外，还根据检索方法、融合技术和答案生成策略对方法进行了分类，并分析了基准数据集、评估协议和性能权衡。同时，强调了跨模态对齐、延迟和准确性的权衡、语义基础等关键挑战，并概述了利用多媒体数据构建更稳健和上下文感知的QA系统的开放问题和未来研究方向。
### Conclusion
本文总结了多媒体增强的QA系统的研究现状，指出未来的研究方向，特别是如何解决跨模态对齐、延迟和准确性的权衡、语义基础等关键挑战，以构建更稳健和上下文感知的QA系统。
## 561. `cs.CV` - Dino-Diffusion Modular Designs 缝合自主泊车跨域鸿沟 [PDF](https://arxiv.org/pdf/2510.20335), [HTML](https://arxiv.org/abs/2510.20335)
### Authors
Zixuan Wu,Hengyuan Zhang,Ting-Hsuan Chen,Yuliang Guo,David Paz,Xinyu Huang,Liu Ren
### Background
驾驶安全的一个关键环节是停车，尽管最近的端到端(E2E)方法在特定领域的结果上表现出色，但在领域迁移（例如天气和光照变化）下的鲁棒性仍然是一个主要挑战。
### Innovation
本文提出了一种名为Dino-Diffusion Parking (DDP)的方法，这是一种领域无关的自动驾驶泊车管道，将视觉基础模型与基于扩散的规划结合起来，实现分布迁移下的泛化感知和鲁棒运动规划。该管道在CARLA中以常规设置进行训练，并以零样本的方式转移到更具对抗性的环境中。对各种出域场景进行了测试，结果显示成功率超过90%，并且消融实验验证了网络架构和算法设计的改进显著提升了跨域性能，优于现有基线。此外，在从真实停车场重建的三维高斯散点（3DGS）环境中进行了测试，显示出了从仿真到现实的良好迁移。
### Conclusion
本文提出的DDP框架在多种出域场景下实现了高性能的泊车，并验证了其有效性和鲁棒性。
## 562. `cs.CV` - Kinaema:一个用于运动中记忆和姿态的递归序列模型 [PDF](https://arxiv.org/pdf/2510.20261), [HTML](https://arxiv.org/abs/2510.20261)
### Authors
Mert Bulent Sariyildiz,Philippe Weinzaepfel,Guillaume Bono,Gianluca Monaci,Christian Wolf
### Background
空间感知机器人的一大关键方面是能够“找到方向”，即正确地在之前见过的空间中定位自己。本文针对连续的机器人操作场景，利用开始实际操作之前的观察信息来优化效率。研究人员引入了一个新的模型Kinaema，该模型结合移动中的视觉观察流，在需要时处理查询图像，预测显示空间相对于当前位置的相对位置。该模型不显式储存观察历史，因此没有固定的历史长度约束，而是通过变压器以递归方式维护一个隐式潜在记忆，将传感器读数的历史压缩为紧凑表示形式，以实现连续的空间定位和导航任务。研究者通过一个新的下游任务“Mem-Nav”来评估模型的效果，展示了其大容量递归模型在场景中的有用表现、目标导航以及高效性特点，特别是在与具有观察历史注意力的经典变压器的比较中更为明显。
### Innovation
引入了一个新的模型Kinaema，这是一种递归序列模型，它能够在机器人移动中整合视觉观察流，然后在需要时处理查询图像并预测空间的相对位置。模型通过递归方式维护一个隐式潜在记忆，以紧凑的方式压缩传感器读数的历史信息，而不需要显式存储观察历史，从而提高了计算效率。并且，这一模型在新的Mem-Nav任务中展现了优秀的场景表示能力、目标导航能力和高效率特点，相比传统的基于观察历史注意力的变压器模型具有显著优势。
### Conclusion
Kinaema模型在没有固定上下文长度限制的情况下，能够高效地维护持续场景表示，实现智能化的空间导航，展现出在连续操作场景中的优越性，为机器人导航领域的研究提供了新的方法和技术。
## 563. `cs.CV` - 通过图像偏好模型的一次性黑盒传递伪造水印 [PDF](https://arxiv.org/pdf/2510.20468), [HTML](https://arxiv.org/abs/2510.20468)
### Authors
Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko
### Background
近年来，数字内容水印技术的兴趣激增，这主要是由于生成模型的广泛应用和法律压力的增加。随着越来越多的AI生成内容在网上可用，水印在确保内容的真伪和归属方面的作用变得越来越重要。尽管已经有很多研究评估了水印对删除攻击的鲁棒性，但当一个水印从真实内容被盗并应用于恶意内容的情况（即水印伪造）却少有探讨。
### Innovation
该研究提出了一个偏好模型来判断图片是否被水印处理，通过无监督的方式训练模型，仅需一个经过水印处理的图片，就可以通过反向传播优化输入图片来去除并伪造水印，这种方法不需要了解水印算法的具体内容，从而使攻击更加简便且实用。结果表明，该方法能够在多种后嵌水印模型上有效伪造水印，从而对当前水印技术的安全性提出了质疑。
### Conclusion
该研究通过引入图像偏好模型，有效实现了水印的去除和伪造，提出的方法无需使用真实水印样本，且只需要一个水印化样本即可执行攻击。这种方法大大简化了攻击的过程且适用性强，挑战了当前水印技术的安全性，同时开源了代码和相关资源。
## 564. `cs.CV` - GUSL-Dehaze: A Green U-Shaped Learning Approach to Image Dehazing [PDF](https://arxiv.org/pdf/2510.20266), [HTML](https://arxiv.org/abs/2510.20266)
### Authors
Mahtab Movaheddrad,Laurence Palmer,C.-C. Jay Kuo
### Background
图像去雾霾是恢复清晰图像的任务，传统方法依赖于统计先验和基于物理的大气散射模型进行去雾霾处理。近年来，基于深度学习的模型在该领域取得了领先成果，但这些模型通常具有较高的计算成本和庞大的参数量，不适合资源约束设备。
### Innovation
本文提出了GUSL-Dehaze，一种绿色U形学习方法。该方法结合了基于物理的模型和绿色学习框架，提供了一种轻量级、透明的替代传统深度学习技术的方案。不同的是，GUSL-Dehaze 在不采用神经网络解决方案的情况下，采用一种初始去雾霾步骤（使用修改后的暗通道先验）和一个由U形架构组成的绿色学习流水线，通过无监督表示学习有效提取特征，并使用相关的特征测试（RFT）和最小二乘法正态变换（LNT）等特征工程技巧来保持模型的紧凑性。最终，通过透明的监督学习策略得到去雾霾图像。GUSL-Dehaze 显著减少了参数数量，同时保证了数学可解释性，并实现了与最先进深度学习模型相当的性能。
### Conclusion
GUSL-Dehaze 在保持与最先进的深度学习模型相当的性能的同时，显著减少了参数数量，同时保持了数学可解释性。这种方法为资源受限设备提供了高效的选择。
## 565. `cs.CV` - 合成数据在稳健跑道检测中的应用 [PDF](https://arxiv.org/pdf/2510.20349), [HTML](https://arxiv.org/abs/2510.20349)
### Authors
Estelle Chigot,Dennis G. Wilson,Meriem Ghrib,Fabrice Jimenez,Thomas Oberlin
### Background
深度视觉模型已经足够成熟，可以应用于工业甚至关键性应用如自主导航。然而，为了训练这些模型，数据收集和标注所需的劳动和成本对单个公司或产品来说是个挑战，尤其在关键应用中更为明显。关键应用要求训练数据需涵盖所有可能情况，包括罕见场景。为解决这一问题，生成合成图像是一种可行的解决方案，因为它能够以低成本、可靠的覆盖所有条件和环境，前提是能够减轻合成数据与真实数据之间分布差异的影响。本文研究了自主着陆系统中跑道检测的需求，并提出了一种基于商用飞行模拟器的图像生成方法，结合少量标注的真实图像，通过控制图像生成和真实、合成数据的整合，展示了标准对象检测模型能够实现准确预测，并且能够在未在实际数据中出现的不利条件下（例如夜间图像），显示出使用定制领域适应策略的优越性。
### Innovation
通过商用飞行模拟器生成合成图像，并将其与少量标注的真实图像结合使用，提出了一种新的图像生成方法。这种方法能够有效弥补训练数据不足的问题，提高模型的鲁棒性，特别是在未在实际数据中出现的不利条件下，显示出定制领域适应策略的优势。
### Conclusion
本文展示了标准对象检测模型在基于商用飞行模拟器生成的合成图像与少量标注的真实图像结合使用的情况下，能够实现准确的跑道检测，并且在不利条件下表现出良好的鲁棒性。这证明了生成合成数据在关键应用中稳健性提升的有效性。
## 566. `cs.CV` - Real Deep Research for AI, Robotics and Beyond [PDF](https://arxiv.org/pdf/2510.20809), [HTML](https://arxiv.org/abs/2510.20809)
### Authors
Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang
### Background
随着人工智能和机器人学研究的迅猛发展，每年产生超过10,000篇论文，研究人员难以跟上最新进展。快速变化的趋势，跨学科工作的兴起以及探索超出其专长的领域的需求都增加了这一挑战。为了应对这些问题，本文提出了一个通用管道，能够系统分析任何研究领域：识别新兴趋势，发现跨领域机会，并提供新的研究切入点。
### Innovation
本文提出了一种全面的框架——Real Deep Research (RDR)，应用于人工智能和机器人学领域，特别是基础模型和机器人技术的进步。此外，该分析还扩展到了其他科学领域。主要部分详细描述了RDR管道的构建过程，附录提供了每个分析主题的详细结果。
### Conclusion
我们希望这项工作能够为从事人工智能及其相关领域研究的科研人员提供指导。
## 567. `cs.CV` - MEIcoder: 通过利用最令人兴奋的输入解码神经活动中的视觉刺激 [PDF](https://arxiv.org/pdf/2510.20762), [HTML](https://arxiv.org/abs/2510.20762)
### Authors
Jan Sobotka,Luca Baroni,Ján Antolík
### Background
解码来自神经种群活动的视觉刺激对于理解大脑和大脑-机器接口的应用至关重要，然而，在灵长类动物或人类中由于技术限制（如双光子成像技术难以应用），高质量的数据相对稀缺。这种限制使得深度学习解码技术面临挑战。为了克服这一问题，该研究介绍了一种名为MEIcoder的生物启发式解码方法，该方法结合了针对单个神经元的最令人兴奋输入（MEIs）、结构相似性指数度量损失和对抗训练，能在小数据集上重建初级视皮层（V1）的视觉刺激，尤其在记录的神经元数量较少时表现优异。
### Innovation
MEIcoder结合了针对单个神经元的最令人兴奋输入（MEIs）、结构相似性指数度量损失和对抗训练，能在小数据集上重建初级视皮层（V1）的视觉刺激，尤其在记录的神经元数量较少时表现优异。通过消融研究，该方法证明MEIs是实现高绩效的主要因素。实验还表明，即使从1,000到2,500个神经元的数据中，也可以重建高保真的自然图像，且只需不到1,000个训练数据点。同时，研究提出了包含超过160,000个样本的统一基准，以促进未来的研究进展。
### Conclusion
该研究展示了早期视觉系统可靠解码的可行性，并为神经科学和神经工程应用提供了实用的见解。
## 568. `cs.CV` - Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples [PDF](https://arxiv.org/pdf/2510.20800), [HTML](https://arxiv.org/abs/2510.20800)
### Authors
Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus
### Background
最近，Sharma等人提出了一种名为Layer-SElective-Rank reduction (LASER)的方法，该方法表明，经过精心选择的大语言模型权重矩阵的高阶组件剪裁可以提升下游任务的准确性，而无需任何基于梯度的微调。但是，LASER的方法需要对每个矩阵进行全面数据前向传播的详尽搜索，这使其不适合快速部署。因此，该研究旨在解决这一瓶颈，并提出了一种高效的方法，通过减少搜索开销、利用梯度信息指导剪裁、扩展因式分解搜索空间以及在有限样本上进行评估来实现对下游任务的快速适应。
### Innovation
本文的主要创新点包括：(i) 只需要检查一小部分精心选择的矩阵，从而省去了逐层扫描；(ii) 每个矩阵的奇异值梯度可以指出哪些矩阵值得进行剪裁；(iii) 扩展因式分解搜索空间，允许矩阵行围绕多个子空间聚类，然后独立分解每个聚类，进一步减少了对原始训练数据的过度拟合，同时提升了准确性最多24.6个百分点；(iv) 为了进一步减少搜索时间，只需在100个样本上进行评估，而不仅仅是整个训练数据，无论是计算指示性梯度还是测量最终准确性。解释认为，下游任务的适应主要由提示风格而非数据集大小主导。
### Conclusion
通过综合这些发现，本文展示了适用于下游任务的快速且稳健的适应算法。具体而言，通过在100个样本上进行一次梯度步骤以及对顶部候选层和因式分解技术的快速扫描，无需微调，即可实现大语言模型（LLM）对新数据集的适应。
## 569. `cs.CV` - GSWorld: 闭环逼真仿真套件用于实现机器人操作 [PDF](https://arxiv.org/pdf/2510.20813), [HTML](https://arxiv.org/abs/2510.20813)
### Authors
Guangqi Jiang,Haoran Chang,Ri-Zhao Qiu,Yutong Liang,Mazeyu Ji,Jiyue Zhu,Zhao Dong,Xueyan Zou,Xiaolong Wang
### Background
当前，机器人操作模拟器普遍面临模拟效果和实际操作之间的差距，模拟器无法提供逼真的环境以进行高质量的策略训练和转换。此外，虽然存在一些模拟器能够将模拟环境与物理引擎相结合，但大多数模型仍然依赖于真实的机器人进行训练和实现实体到真实体（sim2real）的转换，这大大增加了训练成本和实际部署的复杂性。因此，本研究旨在开发一个闭合环路的逼真模拟系统，结合使用3D高斯点绘制和物理引擎，以提高策略转换的稳定性和逼真度，同时减少对真实机器人的依赖，从而实现更高效的模拟和机器人操作训练。
### Innovation
该论文提出了GSWorld，这是一种结合了3D高斯点绘制和物理引擎的健壮、逼真的机器人抓取模拟器。其创新点在于通过提出一种新的资产格式GSDF（高斯场景描述文件），将高斯网格表示与机器人URDF和其他对象结合，实现了多样场景的逼真渲染。此外，GSWorld框架通过闭环策略开发机制，实现了无需使用真实机器人即可进行策略学习和经由模拟到真实体的训练，大大降低了训练成本和实际部署的复杂性。该系统还能够进行零样本sim2real的像素到动作策略学习、自动高质量数据收集、真实机器人策略的重复性仿真基准测试等多种应用。
### Conclusion
通过GSWorld，研究者表示达到了优化机器人抓取策略训练和实现的闭环、高效性和逼真度的目标，为机器人操作技术的发展提供了一个强大的工具。GSWorld能够显著降低模拟和实际应用间的一致性差距，并且通过模拟数据的生成和策略的直接评估，为机器人领域的研究人员和开发人员提供了一个可靠的研究平台。
## 570. `cs.CV` - 增强型深度学习中的残差柯西洛夫-阿诺尔德网络 [PDF](https://arxiv.org/pdf/2410.05500), [HTML](https://arxiv.org/abs/2410.05500)
### Authors
Ray Congrui Yu,Sherry Wu,Jiang Gui
### Background
尽管深度卷积神经网络(CNNs)取得了巨大成功，但由于网络深度中的数百层，其优化和训练成本高昂。传统的卷积操作因其线性本质和固定激活函数的限制，需要众多层才能学习数据中的有意义模式。由于这些网络的规模庞大，这种方法在计算上效率低下，并且在小数据集上存在过拟合或梯度爆炸的风险。
### Innovation
我们提出了一个‘即插即用’模块，称为残差柯西洛夫-阿诺尔德网络（RKAN）。该模块高度紧凑，可以轻松地插入传统深度网络的任何阶段，学习整合支持性的多项式特征变换到现有的卷积框架中。在不同的视觉任务和广泛测试的基准上，RKAN在基线模型上提供了持续的改进，并实现了尖端的性能。
### Conclusion
RKAN模块为传统深度网络提供了有效的支持，能够在保持计算效率的同时提供更好的性能。在不同的视觉任务上进行测试，它能够在广泛测试的基准上实现领先的表现。
## 571. `cs.CV` - Frequency Cam: 实时成像周期信号 [PDF](https://arxiv.org/pdf/2211.00198), [HTML](https://arxiv.org/abs/2211.00198)
### Authors
Bernd Pfrommer
### Background
事件摄像头因其高时间分辨率和大动态范围而非常适合分析图像中的时间周期信号。本文介绍了一种高效的完全异步事件摄像头算法，用于检测图像像素的基频，即像素在图像中的闪烁频率。该算法使用一个二次数字无限脉冲响应(IIR)滤波器进行近似的逐像素亮度重构，并且比基准方法更适用于高频频噪声。此外，使用信号的下降沿比上升沿能更准确地估计周期，而对于某些信号，通过插值零水平穿越可以进一步提高准确性。然而，实验发现，该摄像头检测单像素频率高达64kHz的能力在全传感器成像中无法保持，因为读出带宽限制成为主要障碍。这表明，在传感器附近的硬件实现将极大地改善频率成像能力。有关全传感器频率成像的重要设计参数以及借助笔记本电脑CPU核心运行的频率检测代码Frequency Cam和演示视频等详细信息也会对该领域贡献有意义的结果。
### Innovation
本文提出了一种高效的全异步事件摄像头算法，用于检测图像像素的闪烁频率。该算法利用二次数字无限脉冲响应（IIR）滤波器进行逐像素亮度重构，并且对高频噪声具有更高的鲁棒性。研究还发现，在某些情况下，使用信号的下降沿比上升沿能更准确地估计周期。此外，还提出了Frequency Cam，这是一个开源实现，可以在笔记本电脑CPU单核心上以超过每秒5000万个事件的速度运行，产生的结果与Prophesee公司Metavision Toolkit中的封装振动分析模块的结果非常相似。这表明，接近传感器的硬件实现将显著提高频率成像的效果。
### Conclusion
该研究发现优等的摄像头检测频率能力不适用于全传感器成像，因为带宽限制成为了主要瓶颈。硬件方案接近传感器的实现将提升频率成像能力，且已经实现了基于笔记本电脑CPU核心的高事件处理频率。开源的Frequency Cam代码展示了其在实际应用中的效用。
## 572. `cs.CV` - FairGen:通过自我发现的隐含方向提升文本到图像扩散模型的公平性 [PDF](https://arxiv.org/pdf/2412.18810), [HTML](https://arxiv.org/abs/2412.18810)
### Authors
Yilei Jiang,Weihong Li,Yiyuan Zhang,Minghong Cai,Xiangyu Yue
### Background
尽管扩散模型（DM）在各种图像生成任务中表现出色，但它们仍然折射出训练集中固有的偏差。由于DMs在实际应用中的广泛应用，这些偏差可能延续一种被扭曲的世界观，从而阻碍少数群体的机会。现有的去偏方法通常需要重新训练模型，使用人工编写的参考数据集或附加分类器，但这种方法存在两个主要限制：（1）收集参考数据集会产生高昂的标注成本；（2）去偏性能受到参考数据集或附加分类器质量的极大限制。
### Innovation
本文提出了一种名为FairGen的 Plug-and-Play 方法，可以以自我发现的方式学习属性隐含方向，从而消除对参考数据集的依赖。FairGen 由两部分组成：一组属性适配器和一个分布指示器。每个适配器旨在学习一个属性隐含方向，并通过自我发现过程进行优化。然后，分布指示器将乘以适配器集，以指导生成过程向指定的分布靠拢。该方法能够同时去偏多种属性，且保持轻量级和易于与其他DM整合，无需重新训练。
### Conclusion
在去偏性别、种族及其交叉偏见的广泛实验中，我们的方法大幅超过了以前的SOTA。
## 573. `cs.CV` - Face-Human-Bench：多模态助手中人脸识别与理解的综合基准 [PDF](https://arxiv.org/pdf/2501.01243), [HTML](https://arxiv.org/abs/2501.01243)
### Authors
Lixiong Qin,Shilong Ou,Miaoxuan Zhang,Jiangning Wei,Yuhang Zhang,Xiaoshuai Song,Yuchen Liu,Mei Wang,Weiran Xu
### Background
面部和人类是社交互动中的关键元素，广泛出现在日常生活中的照片和视频中。因此，对面部和人类有深层次的理解可以帮助多模态助理提高回应质量并拓宽应用范围。然而，当前的多模态助理社区缺乏对理解面部和人类能力的全面和科学评估。
### Innovation
本文首先提出了一种分层能力分类体系，包括三个级别的能力。基于这个分类体系，从面部和人类社区的公开数据集中收集图像和标注，并建立了一个半自动数据处理管道，生成新的基准问题。此外，此Face-Human-Bench包括开发集和测试集，每部分有1800个问题，并支持中英文语言。研究者对25种主流多模态大规模语言模型进行了评估，重点在于能力之间相关性、目标相对位置对性能的影响以及思维链（CoT）提示对性能的影响，并探索了需要由专科模型补充的多模态语言模型的能力。
### Conclusion
Face-Human-Bench提供了一个用于多模态助理理解人脸和人类能力的综合基准集，包括开发集和测试集，并公开了该数据集和评估代码，旨在推动相关领域的研究和发展。
## 574. `cs.CV` - Tex-ViT: 一种通用且鲁棒的基于纹理的双分支交叉注意力深伪检测器 [PDF](https://arxiv.org/pdf/2408.16892), [HTML](https://arxiv.org/abs/2408.16892)
### Authors
Deepak Dagar,Dinesh Kumar Vishwakarma
### Background
深度伪造技术利用生成对抗网络（GAN）制作高度逼真的面部修改，被视为当前的主要方法。传统卷积神经网络（CNN）可以识别虚假媒体，但在不同数据集上表现不佳，并且容易受到对抗攻击的影响，因为它们缺乏鲁棒性。尽管视觉变压器在图像分类任务中有潜力，但由于需要足够的训练数据，它们的应用仍有局限性。
### Innovation
本文介绍了一种名为 Tex-ViT（纹理-视觉变压器）的新模型，通过结合 ResNet 和视觉变压器来增强 CNN 特征。该模型在 ResNet 的每个下采样操作前的区块上并行运行一个纹理模块，并将此模块作为交叉注意力视觉变压器双分支的输入。该模型特别关注改进全局纹理模块，该模块提取特征图相关性。实验结果表明，假图像在操纵过程中具有平滑的纹理但不会保持长时间的一致性。该模型在跨域场景中超越了最先进的模型，准确率达到 98%，显示了其学习操纵样本中共享的显著纹理特征的能力。此外，实验证实了该模型适用于多种情况，并能够抵抗多种后处理方法的影响。
### Conclusion
Tex-ViT 模型在深伪检测任务中展现了优异的泛化能力和鲁棒性，能够处理多种类型的 GAN 数据集，以及不同的后处理情况。实验结果证明了其在各种真实世界应用中的适用性和有效性。
## 575. `cs.CV` - BevSplat: 通过基于特征的Gaussian原语解决透视歧义的弱监督跨视点定位 [PDF](https://arxiv.org/pdf/2502.09080), [HTML](https://arxiv.org/abs/2502.09080)
### Authors
Qiwei Wang,Shaoxun Wu,Yujiao Shi
### Background
在弱监督跨视点定位问题中，目标是利用有噪声的地面 truth 注释来估算地面相机相对于卫星图像的姿态。现有的方法往往使用鸟瞰图（BEV）合成来弥合视点间的差异，但由于地面图像和卫星高度图缺乏深度信息，导致高度歧义问题难以解决。现有解决方案要么假设平坦的地平面，要么依赖复杂的模型如跨视点变换器。
### Innovation
提出了一种名为BevSplat的新方法，通过使用基于特征的Gaussian模型来解决高度歧义问题。每个地面上的像素由一个具有语义和空间特征的三维Gaussian表示，被合成到BEV特征图中用于相对姿态估计。此外，还提出了一种基于icosphere的监督策略来应对全景查询图像的挑战。
### Conclusion
在广泛使用的KITTI和VIGOR数据集上的实验证明，BevSplat显著提高了定位精度，超过了先前的方法。
## 576. `cs.CV` - GenLit: 将单图像重新照明重新定义为视频生成 [PDF](https://arxiv.org/pdf/2412.11224), [HTML](https://arxiv.org/abs/2412.11224)
### Authors
Shrisha Bharadwaj,Haiwen Feng,Giorgio Becherini,Victoria Fernandez Abrevaya,Michael J. Black
### Background
在计算机视觉和图形学中，单图像内3D场景的照明操控是一个基础挑战。传统上，逆渲染技术使用显式的三维资产重建和昂贵的光线追踪模拟来解决这个问题。然而，最近视觉基础模型的进步表明，可能即将出现一种新的范式，即用大型图像和视频数据训练的网络取代显式的物理模型。在此背景下，本文借助视频扩散模型（特别是Stable Video Diffusion）的隐式场景理解能力，将单图像重新照明问题转化为视频生成问题。
### Innovation
本文介绍了一种名为GenLit的框架，即通过将图形引擎的照明操控能力转换为视频生成模型的方式，允许用户直接在给定图像中插入和操控点光源，并直接生成视频序列的结果。值得注意的是，该模型仅在少量合成数据集上微调就能泛化到真实场景中，实现了具有合理性且令人信服阴影和互反射的单图像重新照明效果。此外，本文的结果揭示了视频基础模型捕捉关于照明、材质和形状的丰富信息的能力，并表明这些模型通过最小量的训练即可用于重新照明，无需进行显式的资产重建或光线追踪。
### Conclusion
本文利用Stable Video Diffusion等视频扩散模型的独特能力，将单图像重新照明问题转变为视频生成问题，从而引入了一种新的方法。该方法具有训练高效、泛化能力好的特点，仅需少量数据即可实现重新照明，并且能够直接生成视频序列结果，展示了视频基础模型在照明、材质和形状理解方面的潜力，同时也为重新照明技术提供了一条全新的途径。
## 577. `cs.CV` - 视频生成中的物理理解：基于3D点的正则化方法 [PDF](https://arxiv.org/pdf/2502.03639), [HTML](https://arxiv.org/abs/2502.03639)
### Authors
Yunuo Chen,Junli Cao,Vidit Goel,Sergei Korolev,Chenfanfu Jiang,Jian Ren,Sergey Tulyakov,Anil Kag
### Background
当前的视频生成模型在处理2D对象时存在显著缺陷，尤其是缺乏对3D形状和运动的理解，导致生成的视频在描绘接触丰富的场景时存在非物理变形等问题，这限制了它们在任务导向等关键应用中的性能和真实性。论文旨在通过整合3D几何和动态感知来改进视频生成框架，使得模型能够用3D坐标追踪2D对象，提升生成视频的质量，并解决常见的对象变形问题，增强视频的真实性和应用范围。
### Innovation
提出了一种新颖的视频生成框架，该框架结合了3D几何和动态感知。通过在2D视频中添加3D点轨迹并将其在像素空间中对齐，构建了3D感知的视频数据集，进而用此数据集微调一个隐空间扩散模型，使其能够用3D笛卡尔坐标追踪2D对象，有效消除非物理变形等图像瑕疵。此外，该框架还能增强接触丰富的场景，如任务导向的视频，确保在处理固体互动时能够准确感知形状和运动。
### Conclusion
通过3D增强和正则化处理，所提出的方法能够处理接触丰富的场景，提升现有视频扩散模型的视觉可信度。论文证明了所提出的模型在生成精确、高质量RGB视频方面的优越性，并能无缝集成到现有的视频扩散模型中，显著提升这些模型的表现力。
## 578. `cs.CV` - 8-Calves 图像数据集 [PDF](https://arxiv.org/pdf/2503.13777), [HTML](https://arxiv.org/abs/2503.13777)
### Authors
Xuyang Fang,Sion Hannuna,Neill Campbell,Edwin Simpson
### Background
精准农业中自动 livestock 监控非常重要，但现有的计算机视觉模型受限于缺乏反映真实世界群体挑战的数据集。为了解决这一问题，作者引入了 8-Calves 数据集，该数据集包含一个农场中八头荷斯坦-弗里辛恩小牛的一小时视频，视频中经常出现遮挡、运动模糊和多变的姿态。
### Innovation
作者提出了8-Calves数据集，并开发了一个半自动管道，使用微调的YOLOv8检测器和ByteTrack，再由人工修正，生成超过537,000个具有时间身份标签的边框。此外，作者对比了28种对象检测器，展示了在宽松IoU阈值下的近完美性能，但在严格指标下表现显著分化，并揭示了精细定位挑战。通过识别基准测试，作者发现了模型大小和分类准确性、检索之间的权衡，并提出了一些有效的预训练方法。
### Conclusion
8-Calves 数据集提供了时间和丰富的现实挑战，对于推动农业视觉模型的发展具有重要意义。该数据集和代码可以在指定链接处获取。
## 579. `cs.CV` - DIPLI: Deep Image Prior Lucky Imaging for Blind Astronomical Image Restoration [PDF](https://arxiv.org/pdf/2503.15984), [HTML](https://arxiv.org/abs/2503.15984)
### Authors
Suraj Singh,Anastasia Batsheva,Oleg Y. Rogov,Ahmed Bouridane
### Background
现代图像恢复和超分辨率方法主要依赖深度学习，因为与传统算法相比，其表现更优。然而，深度学习通常需要大量训练数据集，而这些数据在天体摄影中往往难以获得。Deep Image Prior (DIP)通过在单张图像上进行盲训练来绕过这一限制，但在某些情况下，DIP存在过拟合、伪影生成和不稳定的问题。
### Innovation
本文提出了DIPLI框架，该框架从单帧训练转向多帧训练，使用Back Projection技术结合TVNet模型进行光流估计，并通过Langevin动力学获得无偏蒙特卡洛估计。与传统的幸运成像技术（Lucky Imaging）、DIP、基于Transformer的模型RVRT和基于扩散的模型DiffIR2VR-Zero相比，该方法在多个指标上（如SSIM、PSNR、LPIPS和DISTS）展示了一致的改进，并且需要较少的输入图像，不易过拟合或生成伪影。在真实世界天文数据上的评估进一步确认了其实践中的鲁棒性。
### Conclusion
实验证明，该方法在合成数据集和真实世界天文数据上的重建质量均优于基线方法，同时需要更少的输入图像，具有更高的稳健性。
## 580. `cs.CV` - 全面评估和分析文本到图像扩散模型中的NSFW概念擦除 [PDF](https://arxiv.org/pdf/2505.15450), [HTML](https://arxiv.org/abs/2505.15450)
### Authors
Die Chen,Zhiwen Li,Cen Chen,Yuexiang Xie,Xiaodan Li,Jinyan Ye,Yingda Chen,Yaliang Li
### Background
文本到图像扩散模型在各个领域得到了广泛应用，展现了巨大的创作潜力。然而，扩散模型的强大泛化能力也可能导致生成不适宜公开（NSFW）的内容，这对其安全部署构成了重大风险。尽管已经提出了一些概念擦除方法来缓解与NSFW内容相关的问题，但在各种场景下的全面评估仍然不足。
### Innovation
本文引入了一个全面的概念擦除工具包，首次系统地研究了NSFW概念擦除方法。通过探讨底层机制与实际观察之间的关系，提供了深入的见解和实用指导，旨在推进扩散模型内容安全的理解，并为该关键领域的未来研究和开发奠定坚实基础。
### Conclusion
通过研究概念擦除方法在各种实际应用场景中的有效应用，本文为推动扩散模型内容安全的理解和未来研究与发展提供了实用指导，并为这一关键领域奠定了坚实基础。
## 581. `cs.CV` - Panoptic-CUDAL：在湿润条件下澳大利亚农村区域点云数据集 [PDF](https://arxiv.org/pdf/2503.16378), [HTML](https://arxiv.org/abs/2503.16378)
### Authors
Tzu-Yun Tseng,Alexey Nekrasov,Malcolm Burdorf,Bastian Leibe,Julie Stephany Berrio,Mao Shan,Zhenxing Ming,Stewart Worrall
### Background
现有的自主驾驶数据集主要针对结构化的城市环境和良好的天气条件，忽略了农村环境和恶劣天气条件的复杂性。尽管有一些数据集包含了天气和光照的变化，但恶劣天气场景并不常见。雨水会严重影响传感器的功能，导致LiDAR和相机数据中出现噪声和反射，降低系统可靠环境感知和安全导航的能力。
### Innovation
该论文介绍了Panoptic-CUDAL数据集，这是专门为在降雨条件下进行农村地区的全景分割而设计的数据集。通过记录高分辨率LiDAR、相机和姿态数据，Panoptic-CUDAL提供了在挑战性场景下的多样化、信息丰富的数据集。作者通过此数据集展示了记录数据的分析以及用于LiDAR点云的全景、语义分割和3D占用预测方法的基线结果。
### Conclusion
该数据集在澳大利亚农村地区雨水条件下记录了高分辨率的LiDAR、相机和姿态数据，为研究者提供了挑战性条件下的多样化信息丰富数据集，可支持自动驾驶技术在农村和恶劣天气条件下的研究和发展。
## 582. `cs.CV` - 通过受限制偏差惩罚的语义增量重新平衡对比对齐在文本-视频检索中的应用 [PDF](https://arxiv.org/pdf/2505.12499), [HTML](https://arxiv.org/abs/2505.12499)
### Authors
Jian Xiao,Zijie Song,Jialong Hu,Hao Cheng,Jia Li,Zhenzhen Hu,Richang Hong
### Background
近年来，文本-视频检索的进步主要受到对比学习的驱动。然而，现有的方法经常忽略了模态差异的影响，导致锚表示进行原位优化（即优化张力），限制了其对齐能力。此外，嘈杂的困难负样本能进一步扭曲锚点的语义。
### Innovation
本文提出了一种Gap-Aware Retrieval框架（GARE），引入了文本$t_i$与视频$v_j$之间的可学习、成对特定增量$triangle_{ij}$，重新分配梯度以缓解优化张力并吸收噪声。通过在信任区域约束下对InfoNCE损失进行多元一阶泰勒展开来推导$triangle_{ij}$，表明它指导沿局部一致的下降方向的更新。基于语义差距的轻量级神经模块跨批次耦合增量以实现结构感知校正。进一步通过具有松弛压缩的变分信息瓶颈正则化$triangle$，增强稳定性和语义一致性。
### Conclusion
实验结果显示，GARE在四个基准上一致地提高了对齐准确性和鲁棒性，验证了间隙感知紧张力缓解的有效性。代码见 this https URL.
## 583. `cs.CV` - 从不平衡数据学习密集手接触估计 [PDF](https://arxiv.org/pdf/2505.11152), [HTML](https://arxiv.org/abs/2505.11152)
### Authors
Daniel Sungho Jung,Kyoung Mu Lee
### Background
手部是人类互动的重要组成部分，研究手与世界的接触可以增进对手部功能的全面理解。近年来，关于手与其环境互动的手部互动数据集数量显著增加，涵盖了物间接触、手间接触、场景接触和身体接触。尽管手接触任务的重要性日益凸显，并且数据质量也在提高，但是如何有效学习密集的手部接触估计仍然面临挑战。学习密集手接触估计面临两个主要问题：一是手接触数据集中存在类别不平衡问题，大多数区域在接触；二是这类数据集在空间上存在不平衡，大部分手接触都在指尖上，这给其它手部区域接触的推广带来了挑战。
### Innovation
本文提出了一种框架，可以从不平衡数据中学习密集的手部接触估计（HACO）。为解决类不平衡问题，引入了平衡接触采样方法，该方法构建并从多个采样组中抽样，以公平地代表接触和非接触顶点的多样接触统计。为解决空间不平衡问题，提出了顶点级别类平衡损失（VCB损失），该损失通过根据顶点在整个数据集中接触频率不同地重新加权每个顶点的损失贡献，整合了空间变化的接触分布。
### Conclusion
本研究成功地通过大规模手部接触数据有效地学习了密集的手部接触估计，克服了类别和空间不平衡的问题。
## 584. `cs.CV` - FreeGraftor：无需训练的跨图像特征移植方法用于依据主题的文本到图像生成 [PDF](https://arxiv.org/pdf/2504.15958), [HTML](https://arxiv.org/abs/2504.15958)
### Authors
Zebin Yao,Lei Ren,Huixing Jiang,Chen Wei,Xiaojie Wang,Ruifan Li,Fangxiang Feng
### Background
主题驱动的图像生成旨在根据参考图像中的主体身份合成符合文本指导的新颖场景。现有方法在保真度和效率之间面临关键权衡。基于调优的方法依赖于耗时且资源密集的主体特定优化，而零样本方法往往会失去足够的主体一致性。这项工作中，我们提出了一种名为FreeGraftor的无需训练框架，通过跨图像特征移植解决了这些限制。具体来说，FreeGraftor利用语义匹配和位置约束的注意力融合将参考主体的视觉细节转移到生成的图像中。此外，我们框架引入了一种新的噪声初始化策略，以保留参考主体的几何先验，促进稳健的特征匹配。广泛的定性和定量实验表明，我们的方法能够精确传输主体身份并保持与文本对齐的场景合成。无需模型调优或额外训练，FreeGraftor在主体保真度和文本对齐方面显著优于现有零样本和无需训练的方法。此外，我们框架可以无缝扩展到多主体生成，使其适用于现实世界的部署。
### Innovation
FreeGraftor 是一种无需训练的框架，通过跨图像特征移植解决了主题驱动图像生成中保真度和效率的权衡问题。具体创新包括：利用语义匹配和位置约束的注意力融合将特征从参考主体传递到生成图像；引入一种新的噪声初始化策略以保留参考主体的几何先验；无需模型调优或额外训练，显著提高主体保真度和文本对齐效果。
### Conclusion
FreeGraftor方法在主体保真度和文本对齐方面显著优于现有零样本和无需训练的方法，能够无缝扩展到多主体生成，适用于现实世界的部署。实验结果表明，FreeGraftor能够精确传输主体身份并保持与文本对齐的场景合成。
## 585. `cs.CV` - ControlFusion: 基于语言-视觉退化提示的可控制图像融合框架 [PDF](https://arxiv.org/pdf/2503.23356), [HTML](https://arxiv.org/abs/2503.23356)
### Authors
Linfeng Tang,Yeda Wang,Zhanchuan Cai,Junjun Jiang,Jiayi Ma
### Background
当前的图像融合方法难以应对真实世界成像场景中遇到的复合退化，并且缺乏灵活性以适应用户特定的需求。因此，本文旨在解决这些挑战，提出了一种可控制图像融合框架ControlFusion，通过语言-视觉提示适配性地中和复合退化。该方法通过开发一种融合物理成像机制的退化成像模型，如Retinex理论和大气散射原理，来模拟复合退化，从而从数据层面应对复杂的现实世界退化。同时，还设计了一种提示调节的恢复与融合网络，能够动态增强带有退化提示的特征，使得该方法能够适应不同水平的复杂退化。进一步地，考虑到用户对质量感知的个体差异，引入了文本编码器来嵌入用户指定的退化类型与严重程度，并通过自主感知源图像中的退化设计了一种空间-频率协作视觉适配器，从而减少了对用户指令的依赖。
### Innovation
提出了一种名为ControlFusion的可控制图像融合框架，结合了语言-视觉提示技术。该框架能够通过内部模型模拟复合退化，并通过动态特征增强和自主感知退化来适应不同水平的退化。此外，该框架还考虑了用户的个体质量感知差异，引入了用户指定的退化类型和严重程度作为提示，并设计了能够自主感知退化的空间-频率协作视觉适配器。这些创新使得ControlFusion能够更好地处理复杂、多样的真实世界退化，并优于现有技术。
### Conclusion
通过广泛实验表明，ControlFusion在图像融合质量和退化处理方面均优于现有的顶尖融合方法，尤其是在应对各种程度和类型的现实世界退化方面表现突出。源代码已公开。
## 586. `cs.CV` - OpenMIBOOD: 开放的医学影像领域离群输入检测基准 [PDF](https://arxiv.org/pdf/2503.16247), [HTML](https://arxiv.org/abs/2503.16247)
### Authors
Max Gutbrod,David Rauber,Danilo Weber Nunes,Christoph Palm
### Background
随着人工智能（AI）在关键领域如医疗保健中依赖性增强，确保这些系统的可信性变得尤为重要，尤其是在面对意外或异常输入时。当前缺乏专门针对医学影像领域离群输入检测的基准，广域自然图像离群输入检测基准的结果在医学应用中并不适用，这凸显了医学领域需要独立基准的关键性。
### Innovation
该论文引入了OpenMIBOOD，一个综合框架，用于评估特定于医学影像领域的离群输入检测方法。OpenMIBOOD 包含来自不同医学领域的三个基准，涵盖14个数据集，分为共变转移入分布、近离群和远离群类别。评估了24种后处理方法，提供了标准化参考，以促进离群输入检测方法的发展和公平比较。研究表明广域自然图像离群输入检测基准结果并不适用于医学领域，强调了医学领域特定基准的必要性，有助于减少AI模型暴露在训练分布之外的风险，促进可信赖的AI系统在医疗领域的进步。
### Conclusion
OpenMIBOOD 的目的是为可靠的和可信赖的AI系统在医疗领域的进步提供支持，通过降低模型暴露在训练分布外的风险。基准库在此网址可以获得：this https URL。
## 587. `cs.CV` - MODEM: Morton-Order Degradation Estimation Mechanism for Adverse Weather Image Recovery [PDF](https://arxiv.org/pdf/2505.17581), [HTML](https://arxiv.org/abs/2505.17581)
### Authors
Hainuo Wang,Qiming Hu,Xiaojie Guo
### Background
由于恶劣天气导致的图像退化具有高度非均匀性和空间异质性，例如细粒度的雨痕与广泛存在的雾霾，准确估计潜在退化对于提供更精确和有效的恢复指导具有重要意义，能够使处理策略更加适应环境。
### Innovation
该研究提出了一种“MODEM（Morton-Order Degradation Estimation Mechanism）”机制，用于恶劣天气图像恢复。核心是Morton-Order 2D-Selective-Scan模块（MOS2D），该模块结合了Morton编码的空间排序和选择性状态空间模型，以捕捉长期依赖关系并保持局部结构一致性。此外，引入了双重退化估计模块（DDEM），以分离和估计全局和局部退化先验。这些先验动态调节MOS2D模块，使其能够实现适应性和上下文感知的恢复。研究结果表明，MODEM在多种基准和天气类型下取得了最先进的性能，证明了其在建模复杂退化动态方面的有效性。
### Conclusion
广泛的实验和消融研究证明，MODEM能够跨多个基准和天气类型取得最先进的结果，突出其在建模复杂退化动态方面的有效性。我们的代码将发布在给定的链接中。
## 588. `cs.CV` - Mesh-RFT：通过细粒度强化微调提高网格生成 [PDF](https://arxiv.org/pdf/2505.16761), [HTML](https://arxiv.org/abs/2505.16761)
### Authors
Jian Liu,Jing Xu,Song Guo,Jing Li,Jingfeng Guo,Jiaao Yu,Haohan Weng,Biwen Lei,Xianghui Yang,Zhuo Chen,Fangqi Zhu,Tao Han,Chunchao Guo
### Background
现有的3D网格生成预训练模型存在数据偏差和生成质量低的问题，而基于全局强化学习（RL）的方法依赖于对象级别的奖励，难以捕捉局部结构细节。因此，这些方法在处理上述挑战时表现出色度不足。
### Innovation
本文提出了Mesh-RFT，一种新颖的细粒度强化微调框架，利用Masked Direct Preference Optimization (M-DPO) 进行质量感知的面掩蔽，从而实现局部优化；同时引入了一个目标拓扑感知评分系统，通过边界边比例（BER）和拓扑评分（TS）两个指标，在物体和面级别评估几何完整性和拓扑规律性；将这些指标整合到细粒度RL策略中，完成功能上可以在个体面级别优化网格质量，从而解决局部错误并保持全局一致性。Mesh-RFT 是第一个在个体面级别优化网格质量的方法，实验结果表明相较于预训练模型，M-DPO方法能够降低24.6%的Hausdorff距离，提高3.8%的拓扑评分，并优于全局DPO方法，分别实现17.4%的Hausdorff距离减少和4.9%的拓扑评分增长，这些结果表明Mesh-RFT能有效提升几何完整性和拓扑规律性，实现生产级别的3D网格生成新最优性能
### Conclusion
Mesh-RFT能够有效地提高3D网格生成中的几何完整性和拓扑规律性，通过细粒度的强化微调机制优化网格质量，实现了生产级别的网格生成新最优性能，大幅度降低了Hausdorff距离并提高了拓扑评分。
## 589. `cs.CV` - Balanced Token Pruning: 加速视觉语言模型超越局部优化 [PDF](https://arxiv.org/pdf/2505.22038), [HTML](https://arxiv.org/abs/2505.22038)
### Authors
Kaiyuan Li,Xiaoyue Chen,Chen Gao,Yong Li,Xinlei Chen
### Background
大规模的多模态视觉-语言模型（LVLMs）通过将图像编码成数千个标记来展示出色的任务性能。然而，大量的图像标记引发了显著的计算负担，动态输入更是加重了这一负担。现有方法通过标记修剪减少图像标记数量，通常依据注意力分数或图像标记多样性来选择标记。我们的实证研究表明，现有方法往往忽视了修剪对当前层输出（局部）和后续层输出（全局）的联合影响，导致修剪决策不尽人意。
### Innovation
我们提出了平衡标记修剪（BTP），一种即插即用的修剪视觉标记的方法。BTP 使用小型校准集将修剪过程分为多个阶段。在早期阶段，该方法强调修剪对后续层的影响，而在更深层次的阶段，重点关注保留局部输出的一致性。我们的方法在多种 LVLMs 上进行了广泛实验，并在多个基准测试中展示了其广泛的有效性。实验结果表明，我们方法的压缩率达到了 78%，同时保持了模型 96.7% 的性能。
### Conclusion
我们的方法在压缩 LVLMs 方面表现出显著效果，有效减少了计算负担，同时保持了模型性能。
## 590. `cs.CV` - Spiking Neural Networks Need High Frequency Information [PDF](https://arxiv.org/pdf/2505.18608), [HTML](https://arxiv.org/abs/2505.18608)
### Authors
Yuetong Fang,Deming Zhou,Ziqing Wang,Hongwei Ren,ZeCui Zeng,Lusong Li,Shibo Zhou,Renjing Xu
### Background
Spiking Neural Networks (SNNs)通过二元（0/1）脉冲传递信息，具有脑启发式和能源效率的优势。但SNNs的性能仍然低于人工神经网络，通常归因于稀疏和二元激活导致的信息损失。
### Innovation
本文挑战了信息损失导致SNNs性能下降的传统假设，揭示了一种之前未被注意到的频率偏差：SNNs固有地抑制高频分量，并优先传播低频信息。这导致了SNNs在特征表示中的降级。为此，作者引入了Max-Former，通过两个频率增强操作使混合精度信号恢复：(1)在补丁嵌入中增加最大池化操作，(2)用深度可分离卷积替换自注意力机制。实验结果显示，Max-Former在ImageNet上的top-1准确率达到82.39%，仅使用63.99M参数，超越了Spikformer，证明了高频率信息的重要性。
### Conclusion
Max-Former仅使用63.99M参数在ImageNet上达到82.39%的top-1准确率，显著超越了使用74.81%准确率和66.34M参数的Spikformer。此外，Max-ResNet-18在卷积基准测试上也表现出色，分别在CIFAR-10和CIFAR-100上达到了97.17%和83.06%的准确率。这项工作希望激发未来研究探索SNNs的独特性质。
## 591. `cs.CV` - PolyPose: 通过多项刚性变换进行可变形的2D/3D注册 [PDF](https://arxiv.org/pdf/2505.19256), [HTML](https://arxiv.org/abs/2505.19256)
### Authors
Vivek Gopalakrishnan,Neel Dey,Polina Golland
### Background
在介入治疗中，从有限的2D X光图像集中确定患者的位置是一项关键任务。传统上，术前的容积成像（如CT和MRI）能提供准确的3D定位和解剖学目标的可视化，但这些方法在手术过程中无法使用，而在此期间需要使用快速的2D成像（X光）。为了在术中整合容积指导，本研究提出了一种名为PolyPose的简单且健壮的方法来进行可变形的2D/3D注册。这种方法通过使用生物约束（即骨头在典型运动中不会弯曲），将复杂的3D变形场参数化为一系列刚体变换的组合，从而解决了常规方法在简化数据集中的失效问题。
### Innovation
PolyPose方法通过采用多项刚性变换来解决2D/3D注册问题，它能够适应人体运动的分段刚性特性，从而不影响瑜伽变形场，并通过这种生物约束消除了解剖学上合理的先验知识。该方法显著减少了对昂贵的变形正则化要求的需求，以及针对患者和特定手术的超参数优化。因此，该方法能够在低视角和角度受限的复杂场景中，使用少量的X光图像成功地将患者的术前容积与术中进行匹配。
### Conclusion
在涉及骨科手术和放疗的多个不同数据集上进行了广泛的实验，聚姿（PolyPose）方法表明，通过这种强烈的归纳偏置，它能够成功地将患者术前的容积图像与最少两张X光图像对齐，为在当前注册方法无法工作的困难场景中提供关键的3D导向。此外，还有很多可视化、教程和代码可以在提供的链接处获取。
## 592. `cs.CV` - PreFM: 通过预测未来建模进行在线音频-视觉事件解析 [PDF](https://arxiv.org/pdf/2505.23155), [HTML](https://arxiv.org/abs/2505.23155)
### Authors
Xiao Yu,Yan Fang,Xiaojie Jin,Yao Zhao,Yunchao Wei
### Background
音频-视觉事件解析在理解多媒体视频内容方面起着关键作用，但现有方法通常依赖于对整个视频进行离线处理，模型规模巨大，限制了实时应用。
### Innovation
提出了基于预测未来建模（PreFM）框架的新型在线音频-视觉事件解析方法（On-AVEP）。该方法通过（1）预测多模态未来建模来推断并整合有益的未来音频-视觉线索，从而增强上下文理解；（2）模态无关的稳健表示和重点时间优先级，以提高精度和泛化能力。通过构建在线准确推断能力和实时效率，旨在实现高性能和计算约束之间的平衡。
### Conclusion
实验结果表明，PreFM在UnAV-100和LLP数据集上显著优于现有方法，参数远远少于其他方法，为实时多模态视频理解提供了新的解决方案。相关代码可从提供的链接获取。
## 593. `cs.CV` - Sherlock: 自视语言模型中的自我纠正推理 [PDF](https://arxiv.org/pdf/2505.22651), [HTML](https://arxiv.org/abs/2505.22651)
### Authors
Yi Ding,Ruqi Zhang
### Background
视觉-语言模型（VLMs）在复杂多模态任务中表现出有前途的性能，但仍然面临重大挑战：高度依赖推理错误、需要大量标注数据或准确验证器，以及难以在特定领域之外进行泛化。
### Innovation
提出了通过自我纠正策略增强推理VLMs的方法。介绍了Sherlock，这是一种自我纠正和自我改进训练框架，包括轨迹级自我纠正目标、基于视觉扰动的偏好数据构造方法以及动态$beta$偏好调整。该模型仅使用20k随机样本标记数据便获得自纠正能力，并在其后自改进无需外部监督。Sherlock在八项基准测试中取得了显著成果，直接生成的平均准确率达到64.1%，经过自我纠正的为65.4%，在标注数据使用量少于20%的情况下优于其他模型。
### Conclusion
Sherlock框架通过自我纠正和自我改进，解决了视觉-语言模型的局限性，并在多个基准测试中展示了卓越的性能，有效地减少了对大量标注数据的依赖。
## 594. `cs.CV` - Roboflow100-VL: 一种用于视觉语言模型的多领域物体检测基准 [PDF](https://arxiv.org/pdf/2505.20612), [HTML](https://arxiv.org/abs/2505.20612)
### Authors
Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri
### Background
目前，面向互联网规模数据训练的视觉语言模型（VLMs）在常见物体（如汽车、卡车和行人的零样本检测任务）上表现出色，但这些模型在未包含在其预训练中的新类别、任务和成像模式上的泛化能力仍然有限。传统的解决方法是仅重新训练VLMs来获取更多的视觉数据，但本文提出了一种新的方法：通过带有少量视觉示例和丰富文本描述的注解指令来对齐VLMs到新概念。现有的VLMs无法在医疗成像等挑战性的新领域中展现出较好的零样本能力，进一步突显了需要使用新的方法来对齐新概念的必要性。
### Innovation
本文提出Roboflow100-VL，一个包含100个具有多样化概念的多模态对象检测数据集的大型集合。这超过了VLMs在预训练时时常见的对象类型，通过我们的基准测试评估了现有的SOTA模型在零样本、少样本、半监督和完全监督设置中的表现，为其他数据集设置之间的性能比较提供了条件，这也揭示了VLMs需要进行少量次对齐的问题。
### Conclusion
研究结果表明，像GroundingDINO和Qwen2.5-VL这样的VLMs在挑战性的医疗成像数据集上的零样本准确度不到2%，示范了新概念对齐的必要性。最后，本文解释了最近CVPR 2025 Foundational FSOD竞赛的结果，分享了来自社区的见解，获胜团队比我们的基准线取得了17个mAP的显著性能提升。研究团队已开源了代码和数据集。
## 595. `cs.CV` - 在计算病理学中重新审视滑块级监督的端到端学习 [PDF](https://arxiv.org/pdf/2506.02408), [HTML](https://arxiv.org/abs/2506.02408)
### Authors
Wenhao Tang,Rong Qin,Heng Fang,Fengtao Zhou,Hao Chen,Xiang Li,Ming-Ming Cheng
### Background
在计算病理学（CPath）中，预训练编码器用于离线特征提取，随后通过多个实例学习（MIL）聚合器已成为主导模式，这种模式对癌症诊断和预后非常有利。然而，这种模式的性能受限于编码器在下游任务中缺乏微调，以及与MIL的分离优化。尽管滑块级别的端到端（E2E）监督学习似乎是解决这一问题的一个直观方法，但它面临着计算需求高以及结果不理想的问题。这些挑战促使我们重新审视E2E学习，并指出先前工作忽视了E2E优化的核心挑战，导致性能不及传统的两阶段方法。滑块级别的E2E监督学习在计算病理学中具有潜在优势，但仍需要更深入的研究探索其潜力。
### Innovation
本文提出了针对稀疏注意资源的MIL优化挑战的解决方案，引入了一种名为ABMILX的新颖的MIL方法，该方法通过全局相关性注意力改进和多头机制来缓解该问题。通过高效的多尺度随机补丁采样策略，采用ABMILX的端到端训练ResNet模型在多个挑战性基准测试上超越了SOTA基础模型，同时保持高效的计算性能（<10 RTX3090小时）。
### Conclusion
端到端学习在计算病理学中显示出巨大的潜力，并且呼吁在未来的研究中加强对此领域的关注。
## 596. `cs.CV` - BioCLIP 2: 放大层次对比学习中的涌现特性 [PDF](https://arxiv.org/pdf/2505.23883), [HTML](https://arxiv.org/abs/2505.23883)
### Authors
Jianyang Gu,Samuel Stevens,Elizabeth G Campolongo,Matthew J Thompson,Net Zhang,Jiaman Wu,Andrei Kopanev,Zheda Mai,Alexander E. White,James Balhoff,Wasila Dahdul,Daniel Rubenstein,Hilmar Lapp,Tanya Berger-Wolf,Wei-Lun Chao,Yu Su
### Background
大规模训练的基础模型表现出显著的涌现行为，学会超越其初始训练目标的新能力。通过大规模的对比视觉-语言训练，我们在生物视觉模型中发现了这些涌现行为。为实现这一目标，本文首先创建了一个包含2.14亿张生物图像的TreeOfLife-200M数据集，这是迄今为止最大、最多样化的生物图像数据集。然后，通过使用这个数据集训练BioCLIP 2，使其能够区分不同物种的特征。尽管训练目标较为狭窄，BioCLIP 2在各种生物视觉任务上表现出卓越的准确性，如栖息地分类和性状预测。
### Innovation
本文通过创建TreeOfLife-200M数据集，并利用层次对比学习训练BioCLIP 2模型，从而揭示了生物视觉模型中的一些新的涌现特性。这些特性包括：跨物种层面，不同物种的嵌入分布严格地与功能性及生态含义相吻合（例如喙的大小和栖息地）；在物种内部层面，尽管存在物种间区别，但内部变异如生活阶段和性别仍然保持并更良好地被区分在与物种间区分正交的子空间中。此外，通过形式化的证明和分析解释了层次监督和对比目标如何促进这些涌现特性。
### Conclusion
更大的训练数据规模使得这些特性变得越来越重要，从而形成了具有生物学意义的嵌入空间。
## 597. `cs.CV` - 通过空间推理进行3D室内场景合成的直接数值布局生成 [PDF](https://arxiv.org/pdf/2506.05341), [HTML](https://arxiv.org/abs/2506.05341)
### Authors
Xingjian Ran,Yixuan Li,Linning Xu,Mulin Yu,Bo Dai
### Background
3D室内场景合成对于赋能AI和数字内容创作至关重要。它主要可分为两个子任务：对象生成和布局生成。虽然最新的生成模型在对象级别的质量和控制方面取得了显著进展，但布局生成仍然面临挑战，因为现有数据集有限。现有的方法要么过度拟合到这些数据集，要么依赖预定义约束来优化数值布局而牺牲了灵活性。因此，它们无法生成既开放词汇又与精细用户指令对齐的场景。
### Innovation
DirectLayout提出了一个直接生成文本描述的3D布局的方法，利用大规模语言模型（LLMs）的通用空间推理能力。DirectLayout将生成过程分为三个阶段：生成鸟瞰图布局、将其提升到3D空间、并改进对象放置。为了使模型具备明确的空间推理能力并理解物体定位的基本原则，它采用了基于3D-Front数据集的Chain-of-Thought激活机制。此外，设计了CoT-Grounded生成布局奖励以增强泛化和空间规划能力。推理过程中，DirectLayout通过上下文学习解决资产和布局的不匹配问题。
### Conclusion
大量实验表明，DirectLayout在语义一致、泛化能力和物理可信度等方面表现出色。
## 598. `cs.CV` - REOBench: 评估地球观测基础模型鲁棒性的基准 [PDF](https://arxiv.org/pdf/2505.16793), [HTML](https://arxiv.org/abs/2505.16793)
### Authors
Xiang Li,Yong Tao,Siyuan Zhang,Siwei Liu,Zhitong Xiong,Chunbo Luo,Lu Liu,Mykola Pechenizkiy,Xiao Xiang Zhu,Tianjin Huang
### Background
地球观测基础模型在多个地球观测任务中显示出较强的一般化能力，但它们在真实世界扰动下的鲁棒性尚未得到充分探索。本文通过构建REOBench基准，填补了这一空白，旨在评估地球观测基础模型在六项任务和十二种图像扭曲类型（包括基于外观和几何的扰动）下的鲁棒性，特别是在高分辨率光学遥感图像方面，这些图像在城市规划和灾害响应等关键应用中广泛使用。研究通过系统评估使用掩模图像建模、对比学习和视觉语言预训练范式训练的一系列模型，揭示了现有地球观测基础模型在面对输入扰动时存在显著性能下降，并根据任务、模型架构、骨干网络大小和扰动类型的不同，分析了性能下降的严重性差异。
### Innovation
REOBench是首个全面评估地球观测基础模型鲁棒性的基准，涵盖了六种任务和十二种图像扭曲类型。它特别强调了高分辨率光学遥感图像的评估，以确保更真实的和细致的评估。此外，研究还通过比较视觉语言模型在多模态任务中的表现，揭示了其增强的鲁棒性。REOBench填补了现有研究中对于地球观测基础模型面对真实世界扰动的鲁棒性评估的空白，提供了发展更鲁棒和可靠的模型的实用见解。
### Conclusion
研究结果表明，现有地球观测基础模型在面对输入扰动时存在显著性能下降。性能下降的程度因任务、模型架构、骨干网络大小和扰动类型的不同而异，从不到1%到超过20%不等。视觉语言模型在多模态任务中表现出增强的鲁棒性。REOBench突显了当前地球观测基础模型在应对现实世界干扰方面的脆弱性，并为开发更鲁棒和可靠的模型提供了行动指引。相关的代码和数据已公开。
## 599. `cs.CV` - FuseUNet: U形网络的多尺度特征融合方法 [PDF](https://arxiv.org/pdf/2506.05821), [HTML](https://arxiv.org/abs/2506.05821)
### Authors
Quansong He,Xiangde Min,Kaishen Wang,Tao He
### Background
医学图像分割是计算机视觉中的关键任务，UNet作为里程碑式架构。UNet家族典型组成部分是跳跃连接，在跳过连接存在两个重要限制：（1）各尺度特征间缺乏有效的交互；（2）依赖简单的串联或加法操作，限制了信息的有效整合。尽管UNet近年来朝着提升编码器和解码器能力的方向改进，但仍忽视了这些问题。
### Innovation
提出了一个新颖的多尺度特征融合方法，将UNet解码过程重新构想为求解初始值问题（IVP），并将跳过连接视为离散节点。基于线性多步法原则，建议使用自适应常微分方程方法来实现有效的多尺度特征融合。该方法不依赖于编码器和解码器架构，适用于各种U-Net类似网络。实验证明，该方法提高了特征利用效率，减少了网络参数数量，并保持了高性能。
### Conclusion
在ACDC、KiTS2023、MSD脑肿瘤和ISIC2017/2018皮肤病变分割数据集上的实验结果表明，该方法提高了特征利用，减少了网络参数，并维持了高性能。
## 600. `cs.CV` - PlantSegNeRF：利用多视角图像实例匹配和联合通道NeRF的跨物种少量样本3D实例点云重建方法 [PDF](https://arxiv.org/pdf/2507.00371), [HTML](https://arxiv.org/abs/2507.00371)
### Authors
Xin Yang(1 and 2),Ruiming Du(3),Hanyang Huang(1 and 2),Jiayang Xie(1 and 2),Pengyao Xie(1 and 2),Leisen Fang(1 and 2),Ziyue Guo(1 and 2),Nanjun Jiang(4),Yu Jiang(5),Haiyan Cen(1 and 2) ((1) College of Biosystems Engineering and Food Science, Zhejiang University, (2) Key Laboratory of Spectroscopy Sensing, Ministry of Agriculture and Rural Affairs, (3) Department of Biological and Environmental Engineering, Cornell University, (4) Amway (China) Botanical R and D Center, (5) Horticulture Section, School of Integrative Plant Science, Cornell AgriTech)
### Background
植物器官分割是高分辨率和准确提取器官水平表型特征的前提。尽管深度学习的快速发展推动了植物点云分割的研究，现有的器官分割技术仍然在分辨率、分割准确性和泛化能力方面存在局限，特别是在不同植物物种之间的应用。
### Innovation
本研究提出了一个新的方法，PlantSegNeRF，旨在直接从多视角RGB图像序列生成高精度实例点云，适用于多种植物物种。该方法通过2D实例分割生成每个器官的实例掩码，并利用专门设计的实例匹配模块对同一植物器官的多视角实例ID进行匹配和优化。进一步开发了实例NeRF，渲染包含颜色、密度、语义和实例信息的隐式场景，最终基于体密度将隐式场景转换成高精度的植物实例点云。研究表明，与常用的点云语义分割方法相比，PlantSegNeRF在复杂物种的语义分割中表现更好，分别在精度、召回率、F1分数和IoU上平均提高了16.1%、18.3%、17.8%和24.2%，并展示了显著的跨物种植物点云实例分割优势。
### Conclusion
本研究扩展了器官水平植物表型分析，并提供了大规模植物科学模型开发所需的高质量3D数据的高通量途径。
## 601. `cs.CV` - OpenWorldSAM：扩展SAM2以实现使用语言提示的通用图像分割 [PDF](https://arxiv.org/pdf/2507.05427), [HTML](https://arxiv.org/abs/2507.05427)
### Authors
Shiting Xiao,Rishabh Kabra,Yuhang Li,Donghyun Lee,Joao Carreira,Priyadarshini Panda
### Background
基于开放语言提示对物体进行分割的能力仍然是一个关键挑战，需要模型将文本语义精确地带入空间掩码中，同时处理多样性和未见过的类别。现有的模型需要在处理多样性类别和开放词汇表时提升性能，以便更好地进行语义分割、实例分割和泛光分割任务。
### Innovation
提出了一种名为OpenWorldSAM的新框架，它通过从轻量级视觉语言模型（VLM）中提取多元模态嵌入来扩展prompt-driven的Segment Anything Model v2（SAM2），适用于开放词汇场景。OpenWorldSAM基于四个关键原则：统一提示、效率、实例感知和泛化能力，从而实现多样语言描述的支持、减少训练参数、提升空间理解能力、并在未见过的类别上表现出色。
### Conclusion
通过OpenWorldSAM进行的广泛实验表明，该模型在多种标准上的开放词汇语义、实例和泛光分割任务中取得了最先进的性能。代码已在官方网站提供。
## 602. `cs.CV` - 频率动态注意力调节以实现密集预测 [PDF](https://arxiv.org/pdf/2507.12006), [HTML](https://arxiv.org/abs/2507.12006)
### Authors
Linwei Chen,Lin Gu,Ying Fu
### Background
视觉变换器（ViTs）在计算机视觉中取得了显著的进步，但在各种任务中表现出色。然而，ViTs中的注意力机制让每一层都如同低通滤波器，现有的变压器堆叠结构则面临着频率衰减的问题，这导致了关键细节和纹理的损失。
### Innovation
提出了一个新的基于电路理论的策略——频率动态注意力调制（FDAM），该策略可以轻松插入到ViTs中，直接调节ViTs的整体频响，并且包含两项技术：注意力反转（AttInv）和频率动态缩放（FreqScale）。AttInv通过反转注意力矩阵中的低通滤波器生成互补的高通滤波，并动态结合。FreqScale则为了微调目标响应函数，对不同频段进行加权。通过分析特征相似性和有效的秩评估，证明了该方法避免了表示坍缩，使其在包括SegFormer、DeiT和MaskDINO等多种模型中实现了性能提升。此外，将该方法应用到遥感检测中，在单尺度设置中达到了最新的性能结果。
### Conclusion
这项工作通过提出频率动态注意力调制技术，改善了现有视觉变换器的性能，在多项计算机视觉任务中表现出了提升。代码已对外开放。
## 603. `cs.CV` - SnapMoGen: 从表达性文本生成人体运动 [PDF](https://arxiv.org/pdf/2507.09122), [HTML](https://arxiv.org/abs/2507.09122)
### Authors
Chuan Guo,Inwoo Hwang,Jian Wang,Bing Zhou
### Background
近年来，文本到运动生成取得了显著的进展，但现有方法仍局限于从简短或通用的文本提示中生成运动，主要是由于数据集的限制。这限制了对细微控制和对未见过的提示的一般性。目前的方法无法提供对长时间运动生成和混合的细粒度控制，从而阻碍了该领域的进一步研究。
### Innovation
本文介绍了一种新的文本-运动数据集SnapMoGen，该数据集包含高质量的运动捕捉数据，并配以准确且富有表现力的文字注释。数据集包括20,000个运动片段，总时长44小时，每条描述平均48个词（相比之下，HumanML3D是12个词）。这些运动片段保留了原始时间连续性，便于进行长期运动生成和混合的研究。此外，本文提高了以前生成掩码模型的方法。 MoMask++将运动转换为多尺度标记序列，并利用标记容量更好地进行利用，还学习使用单一生成掩码变换器来生成所有标记。MoMask++在HumanML3D和SnapMoGen基准上均取得了最先进的性能。这种方法还展示了处理随意用户输入的能力，通过使用LLM将输入重新格式化，使其与SnapMoGen的表现力和叙述风格相匹配。
### Conclusion
本文通过引入SnapMoGen数据集和提出MoMask++模型，解决了文本到运动生成中数据限制和生成表现的问题。通过这些方法，未来研究可以在更长时间段上更好地生成和理解身体运动，推进相关领域的发展。
## 604. `cs.CV` - 通过指令编辑数据和长描述提升CLIP的细粒度视觉理解 - VITRIX-CLIPIN [PDF](https://arxiv.org/pdf/2508.02329), [HTML](https://arxiv.org/abs/2508.02329)
### Authors
Ziteng Wang,Siqi Yang,Limeng Qiao,Lin Ma
### Background
尽管视觉语言模型（VLMs）如CLIP已经在视觉和语言对齐方面取得了成功，但在细节和细粒度的视觉理解方面仍面临巨大挑战。
### Innovation
CLIP-IN引入了两项创新：首先，利用指令编辑数据集中的硬负例图像-文本对，通过对称的硬负例对比损失来提高模型对细微视觉-语义差异的区分能力；其次，结合长描述性描述，使用旋转位置编码来捕捉通常被标准CLIP忽略的丰富语义上下文。
### Conclusion
CLIP-IN在MMVP基准测试和各种细粒度视觉识别任务中取得了显著的进步，同时保持了广泛的分类和检索任务中的鲁棒零样本性能。将CLIP-IN的视觉表示集成到多模态大型语言模型中，可以显著减少视觉幻觉并增强推理能力。这项工作强调了结合针对性指令对比学习和全面描述信息以提升VLMs的细粒度理解潜力。
## 605. `cs.CV` - 基于文本条件状态空间模型的跨域泛化变化检测视觉问答 [PDF](https://arxiv.org/pdf/2508.08974), [HTML](https://arxiv.org/abs/2508.08974)
### Authors
Elman Ghazaei,Erchan Aptoula
### Background
地球表面持续发生改变，检测这些变化为人类社会的各个方面提供了宝贵的信息。传统的变化检测方法虽然能从双时相影像中检测变化，但通常需要专家知识进行准确解读。为此，变化检测视觉问答（CDVQA）任务被提出，以使非专家用户能够访问变化信息。然而，现有的CDVQA方法在训练和测试数据集分布相似的假设下进行开发，但在实际应用中，领域变化（domain shift）通常发生。因此，需要一个能够处理领域变化的CDVQA方法来实现更广泛的访问和更灵活的应用。
### Innovation
该论文提出了一种新的多模态和多域数据集BrightVQA，旨在促进CDVQA中的领域泛化研究。同时，提出了一种新的文本条件状态空间模型（TCSSM）。TCSSM不仅整合了双时相影像和与地理灾害相关的文本信息，还在模型中利用了输入依赖参数的动态预测，实现了双时相视觉数据与相关文本描述的对齐。实验证明，该方法在与最新模型的对比中表现出优异的性能。
### Conclusion
该研究通过提出BrightVQA数据集和TCSSM模型，显著提升了在存在领域变化情况下的变化检测视觉问答性能。所提出的方法已经在广泛的实验中显示出优越性，并且代码和数据集将在论文被接受后公开。
## 606. `cs.CV` - FerretNet：基于局部像素依赖的高效合成图像检测 [PDF](https://arxiv.org/pdf/2509.20890), [HTML](https://arxiv.org/abs/2509.20890)
### Authors
Shuqiao Liang,Jian Liu,Renzhang Chen,Quanlong Guan
### Background
随着先进模型如VAEs、GANs和LDMs生成的合成图像逼真度不断提升，合成图像检测面临着重大挑战。为了应对这一问题，该研究探讨了两类生成过程中产生的特征：（1）潜在分布偏差和（2）解码引起的平滑效果。这些特征表现为局部纹理、边缘和颜色过渡的一致性问题。利用马尔可夫随机场（Markov Random Fields）中的局部像素依赖（LPD）特性，通过使用邻近像素信息重构合成图像，以揭示纹理连续性和边缘一致性的中断。
### Innovation
基于LPD特性，该研究提出了一种轻量级神经网络FerretNet，仅包含1.1M参数，实现了高效的合成图像检测。在仅使用4类ProGAN数据集训练的情况下，FerretNet在包含22个生成模型的公开世界基准上的平均准确率达到97.1%。
### Conclusion
广泛实验表明，FerretNet在综合图像检测方面表现出高效和鲁棒性。该代码和数据集已公开，读者可访问相关链接获取。
## 607. `cs.CV` - SeG-SR: 通过视觉语言模型将语义知识集成到遥感图像超分辨率中 [PDF](https://arxiv.org/pdf/2505.23010), [HTML](https://arxiv.org/abs/2505.23010)
### Authors
Bowen Chen,Keyan Chen,Mohan Yang,Zhengxia Zou,Zhenwei Shi
### Background
高分辨率（HR）遥感图像在城市规划和环境监测等多种应用中发挥着重要作用。然而，由于传感器和数据传输链路的限制，实践中获取的图像常常受到分辨率下降的影响。现有遥感图像超分辨率（RSISR）方法主要关注像素空间中的低级特性，而忽视了遥感场景的高级理解，这可能导致重建结果的语义不一致。
### Innovation
本文致力于探索高阶语义知识在提高RSISR性能中的作用。因此，我们提出了一个基于语义指导的超分辨率框架SeG-SR，该框架利用预训练的视觉语言模型从输入图像中提取语义知识，并将其用于指导超分辨率（SR）过程。具体而言，我们设计了一个语义特征提取模块（SFEM），利用预训练的视觉语言模型从遥感图像中提取语义知识；然后提出了一种语义定位模块（SLM），它从提取的语义知识中推导出一系列语义指导；最后，我们开发了一个可学习调制模块（LMM），它使用语义指导来调制SR网络提取的特征，从而有效地将高级场景理解整合到SR管道中。
### Conclusion
我们通过大量实验验证了SeG-SR的有效性和适应性：SeG-SR在三个数据集上取得了最先进的性能，并且能够跨各种SR架构持续提升性能。特别地，对于UCMerced数据集的x4 SR任务，它实现了29.3042 dB的PSNR和0.7961的SSIM。
## 608. `cs.CV` - ViSpec：使用视觉感知推测性解码加速视觉语言模型 [PDF](https://arxiv.org/pdf/2509.15235), [HTML](https://arxiv.org/abs/2509.15235)
### Authors
Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen
### Background
推测性解码是一种广泛应用于加速大型语言模型（LLMs）推理的技术，但在视觉语言模型（VLMs）中应用较少，现有方法仅能实现轻微的速度提升（<1.5倍）。随着多模态能力在大规模模型中变得越来越重要，这种差距越来越显著。研究者假设，大型VLMs能够逐层过滤冗余的图像信息而不影响文本理解，但小型草稿模型难以做到这一点。
### Innovation
本文提出了视觉感知推测性解码（ViSpec），这是一个专为VLMs设计的新框架。ViSpec通过一个轻量级的视觉适配模块将图像标记压缩为紧凑表示，并无缝集成到草稿模型的注意力机制中，同时保持原始图像位置信息。此外，还为每个输入图像提取全局特征向量，并将该特征附加到所有后续文本标记上，以增强多模态一致性。为了克服缺乏具有长助手回复的多模态数据集的问题，通过重新利用现有数据集并使用目标VLM生成扩展输出生成了专门的训练数据集。因此，训练策略消除了草稿模型直接访问目标模型隐藏状态的风险，这些方法会否则仅通过目标模型输出训练就会导致捷径学习。
### Conclusion
广泛的实验验证了ViSpec，据我们所知，这是首次在VLM推测性解码中实现显著加速。代码可在论文网站上获取。
## 609. `cs.CV` - JaiLIP：基于损失引导图像扰动的视觉-语言模型脱管 [PDF](https://arxiv.org/pdf/2509.21401), [HTML](https://arxiv.org/abs/2509.21401)
### Authors
Md Jueal Mia,M. Hadi Amini
### Background
视觉-语言模型（VLMs）在生成多模态推理任务方面表现出显著的能力，但其潜在的误用或安全对齐问题因不同的攻击向量而显著增加。在这些攻击向量中，基于图像的扰动被认为特别有效，能够生成有害输出。已有研究提出了许多方法来脱管VLMs，导致了不稳定性能和可见扰动。因此，尽管存在这些风险，脱管攻击仍然可能带来有效的攻击手段，特别是在交通等领域需要超越一般文本生成的毒性内容攻击中展现其实用性。研究重点在于缓解这些问题，开发更为高效的防御机制以保护VLMs不因脱管攻击而失效或生成有害内容。
### Innovation
JaiLIP是一种基于图像空间的脱管攻击方法，通过最小化清洁图像和对抗性图像之间的均方误差（MSE）损失和模型有害输出损失的联合目标函数，旨在生成既有效又难以察觉的对抗图像。与现有方法相比，JaiLIP在毒性和处理现实世界应用方面具有优势，特别是在交通等领域的特定场景中得到了验证，展示了其在针对特定领域生成有毒文本之外的实用性。
### Conclusion
通过实验结果表明，JaiLIP方法能够生成高效且难以察觉的对抗图像，并且在检测工具（如Perspective API和Detoxify）评估中呈现出优越的性能。此外，该研究还指出图像基于的脱管攻击的实际挑战，以及对保护VLMs免受脱管攻击的高效防护机制的需求。
## 610. `cs.CV` - 朝向医学影像数据的视觉语言基础模型：越南PET/CT报告生成的多模态数据集和基准测试 [PDF](https://arxiv.org/pdf/2509.24739), [HTML](https://arxiv.org/abs/2509.24739)
### Authors
Huu Tien Nguyen,Dac Thai Nguyen, TheMinh Duc Nguyen,Trung Thanh Nguyen,Thao Nguyen Truong,Huy Hieu Pham,Johan Barthelemy,Minh Quan Tran,Thanh Tam Nguyen,Quoc Viet Hung Nguyen,Quynh Anh Chau,Hong Son Mai,Thanh Trung Nguyen,Phi Le Nguyen
### Background
视觉语言基础模型（VLMs）通过大量多模态数据训练，已经在人工智能领域取得了显著进步，特别是在跨模态推理方面。然而，将这些模型应用于医疗成像仍存在挑战，主要因为医疗成像数据多样性有限，且多语言临床数据稀缺。现有医疗VLMs大多仅针对部分成像模态，并以高资源语言为主，限制了其泛化能力和临床应用价值。
### Innovation
本研究提出了一个全新的越南语言多模态医疗数据集，包含2,757个独立患者的整体PET/CT影像及其对应的全长度临床报告。该数据集旨在填补医学AI发展中两个关键空白：一是现有VLMs训练数据中缺乏PET/CT影像数据，阻碍了处理功能性成像任务的模型开发；二是越南语等低资源语言在医学视觉语言研究中的代表性不足。同时，还引入了训练框架改进VLMs的学习，包括数据增强和专家验证测试集。这些方法在下游任务上展示了显著提高现有VLMs性能的结果。
### Conclusion
本研究的数据集和基准测试将为开发更稳健的VLMs在医学成像中的应用，特别是针对低资源语言和越南医疗临床使用提供了关键一步。
## 611. `cs.CV` - LucidFlux：通过大规模扩散变换器实现无提示的通用图像恢复 [PDF](https://arxiv.org/pdf/2509.22414), [HTML](https://arxiv.org/abs/2509.22414)
### Authors
Song Fei,Tian Ye,Lujia Wang,Lei Zhu
### Background
通用图像恢复 (UIR) 的目标是恢复被未知混合物降级的图像，同时保留语义信息。现有方法如具有图像语义的判别恢复器和基于UNet的扩散先验有时会出现过度平滑、虚假重建或漂移的问题。
### Innovation
提出了LucidFlux，一种无需图像描述的UIR框架，采用大规模扩散变换器（Flux.1）。引入了轻量级的双支路调节器，分别注入降级输入和轻度恢复的代理信号，以锚定几何结构和抑制伪影。此外设计了时间步长和层自适应的调节计划，以跨骨干网逐层传递这些线索，从而实现上下文感知的细节恢复。还通过代理提取SigLIP特征实现语义对齐，避免了文本提示或MLLM描述的延迟和不稳定问题，并进一步通过可扩展的编目流水线对大规模数据进行筛选以提供结构丰富的监督。实验表明，LucidFlux在合成和野外基准测试中表现出色，且消融研究验证了每个组件的必要性。研究表明，对于大规模扩散变换器，何时、何地以及如何使用条件信息而非添加参数或依赖文本提示对于实现鲁棒且无需描述的野外通用图像恢复至关重要。
### Conclusion
LucidFlux 持续优于开源和商用基线，通过大规模扩散变换器实现了无提示的通用图像恢复，证明了条件信息的合理使用对结果的重要性，为图像恢复技术开辟了新方向。
## 612. `cs.CV` - VT-FSL: 通过大规模语言模型连接视觉与文本的少数样本学习 [PDF](https://arxiv.org/pdf/2509.25033), [HTML](https://arxiv.org/abs/2509.25033)
### Authors
Wenhao Li,Qiangchang Wang,Xianjing Meng,Zhibin Wu,Yilong Yin
### Background
少数样本学习（FSL）旨在仅从少量标记的支持样本中识别新的概念。近年来的研究通过引入额外的语义信息或设计复杂的语义融合模块来增强支持特征，但这些方法仍然存在由于缺乏实际实例的定位而导致生成与视觉证据相矛盾的语义信息的问题，这会带来不准确的指导和高昂的修正成本。
### Innovation
本文提出了一种新的框架，即VT-FSL，通过大规模语言模型连接视觉与文本，该框架通过大型语言模型（LLMs）和支持图像构建精确的跨模态提示，并通过几何感知对齐无缝集成。该框架主要由跨模态迭代提示（CIP）和跨模态几何对齐（CGA）组成。CIP通过结合类名称和支持图像条件化LLMs，生成精确的类描述，GCAM则通过最小化它们集构成的三维平行otope的核体积来联合对齐融合的文本、支持和合成视觉表示，以捕捉所有表示之间全局的和非线性的关系，促进结构化的多模态集成。
### Conclusion
VT-FSL方法在包括标准、跨领域和细粒度少数样本学习场景在内的十个不同基准中建立了新的最先进的性能。
## 613. `cs.CV` - EasyOcc：通过3D伪标签监督实现完全自监督语义占据预测模型 [PDF](https://arxiv.org/pdf/2509.26087), [HTML](https://arxiv.org/abs/2509.26087)
### Authors
Seamie Hayes,Ganesh Sistu,Ciarán Eising
### Background
自监督模型在语义占据预测领域取得了显著进展，这些模型依赖复杂的方法来弥补缺乏真实标签的问题，如新型视图合成、跨视图渲染和深度估计，但这些方法会带来较高的计算成本和内存使用，尤其是在新型视图合成的情况下。早期的研究成果往往难以迁移到其他架构上，且效果通常不如模型内部集成的技术显著。
### Innovation
本文提出了利用由基础模型Grounded-SAM和Metric3Dv2生成的3D伪标签以及利用时间信息进行标签稠密化的新方法，能够显著提升模型性能，mIoU提升45%，达到14.09％。此外，还提出了一种简化模型EasyOcc，仅依靠这些标签进行学习，无需复杂的渲染策略，性能表现优异，与基础模型集成后mIoU为7.71％，优于之前最优模型31％。该研究表明了基础模型、时间上下文以及损失计算空间选择在自监督学习中对全面场景理解的重要性。
### Conclusion
本文开发的方法展示了在无需复杂渲染策略的情况下，通过利用基础模型生成的3D伪标签和时间信息可以实现对全面场景的语义占据预测。模型EasyOcc无需摄像机遮罩即可达到最佳性能，展现出了基础模型在自监督学习中的重大作用。
## 614. `cs.CV` - DragFlow: 使用区域监督释放DiT先验以实现拖拽编辑 [PDF](https://arxiv.org/pdf/2510.02253), [HTML](https://arxiv.org/abs/2510.02253)
### Authors
Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong
### Background
拖拽式图像编辑因为早期基模型Stable Diffusion中的先验不足，长期以来在目标区域经历了失真的问题。随着从基于UNet的DDPMs转向更可扩展的DiT（例如SD3.5、FLUX）并加入流匹配技术后，生成先验变得更强，这在多样的编辑任务中推动了进展。然而，拖拽式编辑尚未从这些更强的先验中获益。
### Innovation
本文提出了一个名为DragFlow的第一框架，能够有效地利用FLUX的丰富先验进行拖拽编辑。该框架通过引入基于区域的编辑范式，采用了仿射变换来提供更丰富和一致的特征监督。此外，还整合了预训练的开放领域个性化适配器（例如IP-Adapter），并通过梯度掩码实现硬约束以保持背景保真度。还运用了多模态大型语言模型来解决任务歧义性。
### Conclusion
广泛的实验表明，DragFlow在拖拽式图像编辑中超越了基线和基于区域的基线，达到了新的技术前沿。该研究还构建了新的基于区域拖拽的基准（ReD Bench），包含区域级别拖拽指令。代码和数据集将在发表后公开。
## 615. `cs.CV` - 基于样式概况的合成到真实差距度量框架在自动驾驶数据集中的应用 [PDF](https://arxiv.org/pdf/2510.10203), [HTML](https://arxiv.org/abs/2510.10203)
### Authors
Dingyi Yao,Xinyao Han,Ruibo Ming,Zhihang Song,Lihui Peng,Jianming Hu,Danya Yao,Yi Zhang
### Background
确保无人驾驶感知系统的可靠性需要广泛的环境测试，但在实际中往往不切实际。合成数据集因此成为一种有前景的替代方案，具有成本效益、无偏标签和可控场景等优点。然而，合成数据和真实数据之间的域差异仍是模型泛化的重大障碍。鉴于此，本文从数据为中心的视角介绍了合成和真实图像数据集背后样式概貌的提取和发现框架。我们提出了样式嵌入分布差异（SEDD）作为新的评估指标。该框架结合基于Gram矩阵的样式提取和优化了类内紧凑性和类间分离的度量学习来提取样式嵌入，并提出了一个基于公开数据集的标准。在多种数据集和仿真到现实的方法上进行了实验，结果表明该方法可以量化合成到真实的数据差距。这为合成数据集的标准化概况评估和针对性改进提供了一种范式，促进了未来数据驱动的自动驾驶系统的发展。
### Innovation
本文提出了一种基于样式提取和发现的框架，采用SEDD作为新的评估指标，目的是量化合成数据集到真实数据集的差距，显著提高了合成数据集的质量控制标准，并为仿真到现实的场景提供了可量化的指标。该框架结合了基于Gram矩阵的样式提取和优化了类内紧凑性和类间分离的度量学习，能够更准确地识别和量化数据集之间的风格差异。此外，该工作还提出了标准的基准，为后续研究提供了同行可比的方法和数据环境。
### Conclusion
本文提供了一种基于样式概况的质量控制范式，该范式能够系统诊断并针对性地提升合成数据集的质量，从而推动未来数据驱动的自动驾驶系统的研发。这项工作为理解和解决合成数据集与真实数据集之间的差距提供了新的视角和方法。
## 616. `cs.CV` - 通过视觉异常检测揭示海洋环境监测中的异常事件 [PDF](https://arxiv.org/pdf/2510.10750), [HTML](https://arxiv.org/abs/2510.10750)
### Authors
Laura Weihl,Stefan H. Bengtson,Nejc Novak,Malte Pedersen
### Background
水下视频监控是评估海洋生物多样性的一种有前景的策略，但由于大量的无事件视频使得人工检查变得极其不实用，因此需要寻找自动化的解决方案。视觉异常检测（VAD）基于深度神经网络被探索用于自动识别有趣的或异常的事件。然而，目前的VAD模型在不同标注者的性能上存在巨大差异，且对训练数据的数量和定义“正常”场景的视觉内容变化高度敏感。通过AURA数据集和四个VAD模型的评估发现，稳健的帧选择策略对于提取有意义的视频段至关重要。研究结果强调了软标签和共识标签的价值，并提供了一种支持科学探索和可扩展生物多样性监测的实用方法。
### Innovation
1. 介绍了AURA，首个用于水下VAD的多标注者基准数据集。2. 评估了四种VAD模型在两类水下场景中的表现。3. 强调了稳健的帧选择策略的重要性。4. 阐明了当前VAD模型的性能对标注者的敏感性以及数据量和视觉内容变化的影响。5. 提出了使用的软标签和共识标签在实践中的应用价值。
### Conclusion
研究结果表明，当前VAD模型的性能差异巨大，受训练数据量和视觉内容变化的显著影响。稳健的帧选择策略对于提取有意义的视频段非常重要。软标签和共识标签在实践中具有重要价值，能够支持科学探索和可扩展的生物多样性监测。
## 617. `cs.CV` - 基于知识的视觉-语言基础模型在胎儿超声解释中的应用 [PDF](https://arxiv.org/pdf/2510.12953), [HTML](https://arxiv.org/abs/2510.12953)
### Authors
Xiao He,Huangxuan Zhao,Guojia Wan,Wei Zhou,Yanxing Liu,Juhua Liu,Yongchao Xu,Yong Luo,Dacheng Tao,Bo Du
### Background
近期的医学视觉-语言模型在如VQA（视觉问答）、报告生成和异常检测等任务中显示出了巨大的潜力。然而，大多数模型针对结构化的成人医学成像进行了调整，而在胎儿超声成像上表现不佳。胎儿超声存在多视角图像推理、多种疾病和图像多样性等挑战。为了解决这些问题，本文介绍了FetalMind，一种专门针对胎儿超声成像的医疗AI系统，用于报告生成和诊断。该系统受到临床工作流程的指导，引入了知性特征解耦（SED）方法，通过强化学习引导偏好选择，依照临床忠实步骤，减轻疾病和视角之间的差异，使模型的推理更符合产科实践的要求。为了大规模训练FetalMind，作者创建了FetalSigma-1M数据集，这是首个大型的胎儿超声报告语料库，包含来自十二家医疗机构的2万份报告，解决了领域数据稀缺的问题。
### Innovation
本文提出了一种名为Epistemic-aware Vision-Language Foundation Model的新模型，特别设计用于胎儿超声成像的报告生成和诊断任务。该模型引入了知性特征解耦机制（SED），通过专家标注的二分图来解耦视角和疾病间的关联，并通过强化学习指引生成过程，使得生成模型的推理结果与产科实践紧密结合。此外，该研究还创建了一种大型的胎儿超声报告数据集，解决了在这个领域数据稀缺的问题。
### Conclusion
FetalMind在所有妊娠阶段的评估中均优于开源和闭源基准模型，平均性能提高了14%，对关键状况的准确率达到61.2%的提高，同时表现出高效、稳定和可扩展的特点。
## 618. `cs.CV` - 基于因果表示与推理联合学习的点云分割中新类发现 [PDF](https://arxiv.org/pdf/2510.13307), [HTML](https://arxiv.org/abs/2510.13307)
### Authors
Yang Li,Aming Wu,Zihao Zhang,Yahong Han
### Background
该研究聚焦于点云分割中的新型类别发现（3D-NCD）任务，目标是学习一种模型，能够仅通过标注（基类）3D类别的监督信息来分割未标注（新型）3D类别。实现这一任务的关键在于建立点表示与基类标签之间的精确对应关系，以及基类和新型类点之间的表示对应关系。粗略或统计性的相关学习可能导致新型类推断的混淆。通过引入结构因果模型（SCM），可以揭示出与类别准确对应的本质点云表示，并提出了一种新的方法——联合学习因果表示与推理，以解决这一问题。
### Innovation
该研究通过引入结构因果模型（SCM），揭示了与类别准确对应的本质点云表示，并提出了一种新的方法——联合学习因果表示与推理。具体地，研究首先通过SCM分析基类中的隐藏混淆因子，以及基类与新型类之间的因果关系，设计了一种消除混淆因子的因果表示原型，用于捕捉基类的因果表示，并利用图结构建模基类和新型类间的因果关系，从而实现从基类到新型类的因果推理。
### Conclusion
广泛的应用实验和可视化结果表明，该方法在3D和2D NCD语义分割中优于现有方法。
## 619. `cs.CV` - Spatial-DISE: 综合基准评估视觉语言模型的时空推理能力 [PDF](https://arxiv.org/pdf/2510.13394), [HTML](https://arxiv.org/abs/2510.13394)
### Authors
Xinmiao Huang,Qisong He,Zhenglin Huang,Boxuan Wang,Zhuoyun Li,Guangliang Cheng,Yi Dong,Xiaowei Huang
### Background
视觉语言模型对于实现机器人技术、增强现实和自主导航等多元化领域的实际应用至关重要。然而，现有的基准测试难以全面评估模型的时空推理能力，特别是内嵌动态时空推理，这是人类时空认知的基本方面。
### Innovation
本文提出了一种综合基准测试，即Spatial-DISE，基于认知基础分类体系，将任务分为四个基本象限：内嵌静动态、外嵌静动态时空推理。同时，为解决数据稀缺问题，开发了一套可扩展和自动化的管道生成多样化的可验证时空推理问题，形成了Spatial-DISE数据集，包括Spatial-DISE Benchmark（559个评估VQA对）和Spatial-DISE-12K（12K+训练VQA对）。该研究发现当前视觉语言模型在多元时空推理方面存在明显的人类水平差距，特别在多步骤多视图时空推理中。Spatial-DISE提供了一个健壮的框架、有价值的数据集以及未来研究方向，以发展类似人类的时空智能。
### Conclusion
Spatial-DISE框架提供了一个稳健的评估平台、重要的数据集和明确的研究方向，旨在推动视觉语言模型在时空推理能力方面达到人类水平。基准测试、数据集和代码将公开发布。
## 620. `cs.CV` - Vision-Centric Activation and Coordination for Multimodal Large Language Models [PDF](https://arxiv.org/pdf/2510.14349), [HTML](https://arxiv.org/abs/2510.14349)
### Authors
Yunnan Wang,Fan Lu,Kecheng Zheng,Ziyuan Huang,Ziqiang Li,Wenjun Zeng,Xin Jin
### Background
现有的多模态大语言模型（MLLMs）通过视觉编码器的图像特征与大语言模型（LLMs）的结合，展示了高级的理解能力。然而，主流的MLLMs主要依靠下一个文本标记的预测进行监督，忽略了用于分析能力的关键视觉中心信息。这种方法导致了分析能力的不足。
### Innovation
本文提出了VaCo，优化了MLLMs的表示，通过视觉中心激活（Vision-Centric activation）和协调（Coordination）机制，利用多种视觉基础模型（VFMs）促进了任务敏感的感知特征的结合。具体来说，引入了可学习的模块任务查询（MTQs）和视觉对齐层（VALs），激活特定的视觉信号，并通过定制的Token Gateway Mask (TGM)限制多个MTQ组间的信息流动，以协调来自多组VFMs的表示冲突。
### Conclusion
广泛的实验表明，VaCo显著提高了多种MLLMs在各种基准测试上的表现，突显了其在视觉理解方面的优越能力。
## 621. `cs.CV` - MARIS：具备几何增强与语义对齐的海洋开放词汇实例分割 [PDF](https://arxiv.org/pdf/2510.15398), [HTML](https://arxiv.org/abs/2510.15398)
### Authors
Bingyu Li,Feiyu Wang,Da Zhang,Zhiyuan Zhao,Junyu Gao,Xuelong Li
### Background
当前大多数水下实例分割方法受到近词汇预测的限制，这限制了它们识别新的海洋类别能力。虽然开放词汇（Open-Vocabulary, OV）分割在自然图像中显示出潜力，但分析表明，水下场景中的迁移学习面临严重的视觉退化（如颜色衰减）和语义错位问题，这些问题由缺乏水下类定义引起。为了克服这些问题并支持评估，本文引入了MARIS（Marine Open-Vocabulary Instance Segmentation），这是第一个大规模细粒度的水下开放词汇分割基准，包含有限的已见类别和多样化的未见类别。
### Innovation
本文提出了一种统一框架，包括两个互补组件：几何先验增强模块（GPEM）利用稳定的部分级和结构特征，在退化的视觉条件下保持物体一致性；语义对齐注入机制（SAIM）通过加入领域特定先验丰富语言嵌入，减少语义歧义并改善未见类别的识别。实验表明，该框架在MARIS基准上的表现优于现有OV基线，在领域内和跨领域设置中均能提升性能，为未来的水下感知研究奠定了坚实基础。
### Conclusion
本文提出并验证了MARIS，这是我们第一个针对水下开放词汇分割的大规模基准。通过GPEM和SAIM两个模块的结合，有效解决了水下场景的视觉和语义挑战，提升了解识未见类别和领域迁移的性能。研究为未来水下感知技术的发展提供了重要参考。
## 622. `cs.CV` - SPLite手部：基于稀疏性的轻量级3D手部姿态估计 [PDF](https://arxiv.org/pdf/2510.16396), [HTML](https://arxiv.org/abs/2510.16396)
### Authors
Yeh Keng Hao,Hsu Tzu Wei,Sun Min
### Background
随着AR/VR设备的普及，将在边缘设备上部署深度学习模型已成为一个重要挑战。这些设备需要实时推理、低功耗和低延迟。许多框架设计师面临效率和性能之间的权衡。为了应对这一挑战，本文设计了一个轻量级框架，采用了编码器-解码器结构，并提出了一些关键贡献，以提高效率和准确性。
### Innovation
1. 在ResNet-18主干上应用稀疏卷积，利用手部姿态图中的固有稀疏性，实现42%的端到端效率提升。2. 提出了SPLite解码器，显著提高树莓派5的解码帧率3.1倍，同时保持准确性。3. 采用量化感知训练，在降低内存使用的同时保持准确性（PA-MPJPE从9.0 mm轻微增加到9.1 mm）。4. 系统在树莓派5 CPU（BCM2712 四核ARM A76处理器）上实现2.98倍的加速。
### Conclusion
我们的系统在树莓派5上实现了显著的计算效率提升，同时也能够在复合基准数据集上达到与现有先进方法相当的准确度。
## 623. `cs.CV` - 基于奖励导向优化的身份保存图像到视频生成 [PDF](https://arxiv.org/pdf/2510.14255), [HTML](https://arxiv.org/abs/2510.14255)
### Authors
Liao Shen,Wentao Jiang,Yiran Zhu,Jiahe Li,Tiezheng Ge,Zhiguo Cao,Bo Zheng
### Background
图像到视频(I2V)生成技术近年来在合成高质量、时间上连贯的视频方面取得了显著进展，尤其在以人为中心的视频生成方面占比较大。然而，现有的I2V模型在保持输入的人脸图像与生成视频之间的身份一致性方面遇到困难，特别是在视频中人物表情和动作变化显著、人脸占图像很小比例时更为明显。这一问题在人脸占图像很小比例时尤为重要，因为人类对身份变化非常敏感，这提出了一个目前尚未充分探索的I2V生成挑战。
### Innovation
提出了一种名为Identity-Preserving Reward-guided Optimization (IPRO)的新颖视频扩散框架，基于强化学习来增强身份保存。IPRO不引入辅助模块或改变模型架构，而是引入了一种直接且有效的方法，即使用面部身份评分器优化扩散模型。为了提高性能和加速收敛，该方法在采样链的最后几步通过奖励信号进行反向传播，以提供更丰富的梯度反馈。此外，提出了一种新的面部评分机制，将真实的视频中的面部作为面部特征池，提供多角度的面部信息以增强泛化能力。还引入了KL散度正则化项来稳定训练过程并防止对奖励信号的过拟合。
### Conclusion
在Wan 2.2 I2V模型和自有的I2V模型上进行的广泛实验表明，该方法的有效性。项目的代码可以在这里访问：this https URL.
## 624. `cs.CV` - HumanCM: 一步到位的人体动作预测 [PDF](https://arxiv.org/pdf/2510.16709), [HTML](https://arxiv.org/abs/2510.16709)
### Authors
Liu Haojie,Gao Suixiang
### Background
本文介绍了一种基于一致性模型的人体动作预测框架——HumanCM。传统的人体动作预测方法通常依赖于多步去噪过程，这需要较长的推理时间。相比之下，HumanCM通过学习噪声和清洁动作状态之间的自一致映射，实现了一步生成，从而提高了预测效率。并且，该模型利用了基于Transformer的空间-时间架构，结合了时间嵌入，更好地捕捉长期依赖关系，保持动作的一致性。通过在Human3.6M和HumanEva-I上进行的实验表明，与最先进的扩散模型相比，HumanCM在精度方面具有竞争力，同时将推理步骤减少了100倍以上。
### Innovation
HumanCM 的创新在于它提出了一种单步生成的人体动作预测框架，通过学习噪声和清洁动作状态之间的自一致映射，从而实现了一步到位的高效预测。此外，该模型使用了基于Transformer的空间-时间架构，结合时间嵌入，更好地捕捉了长期依赖性，保持动作的一致性。与现有最先进的扩散模型相比，HumanCM在精度方面具有竞争力，同时将推理步骤大幅减少。
### Conclusion
HumanCM 实现了一步生成的人体动作预测，通过自一致映射和空间-时间Transformer架构显著提高了预测效率和准确性。实验结果证明了与其他扩散模型相比的优势。
## 625. `cs.CV` - Occluded nuScenes: 一个多传感器数据集，用于评估自动驾驶中感知鲁棒性 [PDF](https://arxiv.org/pdf/2510.18552), [HTML](https://arxiv.org/abs/2510.18552)
### Authors
Sanjay Kumar,Tim Brophy,Reenu Mohandas,Eoin Martino Grua,Ganesh Sistu,Valentina Donzella,Ciaran Eising
### Background
在自动驾驶中，可靠的感知表现需要在不利条件下可靠地工作，此时传感器可能会受到部分故障或环境遮挡的影响。尽管现有自动驾驶数据集本身已包含传感器噪声和环境变化，但很少有数据集能够控制、参数化并重复跨多种传感器模态的退化。这一缺口限制了系统性评估感知和融合架构在定义良好的不利条件下的表现的能力。
### Innovation
引入了Occluded nuScenes数据集，这是对广泛使用的nuScenes基准的新型扩展。该数据集包含相机、雷达和LiDAR三个传感器模态，提供了四种类型的遮挡，支持一致、可重复的评价感知模型在部分传感器故障和环境干扰下的表现。通过提供受控和可重复退化的第一个多传感器遮挡数据集，旨在推进鲁棒传感器融合、鲁棒性分析和自动驾驶中的安全感知研究。
### Conclusion
通过发布受控和可重复的多传感器遮挡数据集，本研究旨在促进鲁棒传感器融合、鲁棒性分析和自动驾驶中的安全感知的研究。
## 626. `cs.CV` - 视频一致性距离：通过基于奖励的微调增强图像到视频生成的时序一致性 [PDF](https://arxiv.org/pdf/2510.19193), [HTML](https://arxiv.org/abs/2510.19193)
### Authors
Takehiro Aoshima,Yusuke Shinohara,Byeongseon Park
### Background
奖励驱动的视频扩散模型微调是一种有效的方法，可以提升生成视频的质量，因为它能够在不需要真实世界视频数据集的情况下对模型进行微调。然而，传统的奖励函数主要侧重于提升整个生成视频序列的质量，如审美吸引力和整体一致性，这可能导致生成视频的时序一致性在图像到视频生成任务中受到限制。
### Innovation
本文提出了视频一致性距离（VCD），这是一种新颖的度量标准，旨在提高时序一致性，并结合基于奖励的微调框架对模型进行微调。VCD在视频帧特征的频域中定义，通过频域分析有效捕捉帧信息，以实现与条件图像相关的连贯时序一致性。
### Conclusion
在多个图像到视频生成数据集上的实验结果表明，使用VCD对视频生成模型进行微调，能够在不降低其他性能指标的情况下显著提高时序一致性。
## 627. `cs.CV` - 从Transformer中发掘显式运动信息挖掘用于动作识别的复兴 [PDF](https://arxiv.org/pdf/2510.18705), [HTML](https://arxiv.org/abs/2510.18705)
### Authors
Peiqin Zhuang,Lei Bai,Yichao Wu,Ding Liang,Luping Zhou,Yali Wang,Wanli Ouyang
### Background
近年来，动作识别主要依赖于基于变换器的方法，这得益于其在时空上下文整合方面的优势。尽管在场景相关的数据集上取得了显著进展，但这些方法在敏感于动作的数据集上表现不佳，主要原因是对运动建模的详细设计不足。此外，传统动作识别中广泛使用的成本体与变换器中的注意力机制中的相关矩阵高度相似，但具备强大的运动建模能力。
### Innovation
本文提议通过引入显式运动信息挖掘模块(EMIM)将有效的运动建模特征整合到现有的变换器模型中。EMIM通过滑动窗口的方式从下一流水帧查询基邻域中采样关键候选标记集合，构建出期望的相关矩阵，用于外观建模的上下文信息聚合，并转换为运动特征进行运动建模。
### Conclusion
我们验证了该方法在四个常用数据集上的运动建模能力，并在动作敏感数据集Something-Something V1 & V2上优于现有最先进的方法。项目代码可以在该网址获取。
## 628. `cs.CV` - 叛逆学生：用于高光谱异常检测背景特征增强的互补学习框架 [PDF](https://arxiv.org/pdf/2510.18781), [HTML](https://arxiv.org/abs/2510.18781)
### Authors
Wenping Jin,Yuyang Tang,Li Zhu,Fei Guo
### Background
近年来出现了一类只需要一次训练背景数据集便可以普遍应用于高光谱异常检测领域的算法，无需针对每个场景重新训练或参数调整，这些方法显示了良好的效率和鲁棒性。本文在这个范式基础上，着重将光谱和空间线索结合起来，引入了一个新颖的‘叛逆学生’框架来进行互补特征学习。
### Innovation
本文提出了一种‘叛逆学生’框架，其创新点在于，不同于传统的模仿式教师-学生范式，本方法故意训练空间分支与光谱教师分离，从而学习教师未能捕捉到的互补空间模式。该框架采用两阶段学习策略：首先通过反向蒸馏训练光谱增强网络获得鲁棒背景光谱表示；其次用去相关损失训练空间网络，强化特征正交性同时保持重建准确性，以避免无关噪声。
### Conclusion
实验结果表明，该框架与传统高光谱异常检测器结合后，在高光谱异常检测标准数据集HAD100上显著超越了多个现有基线，并且具有较小的计算开销，验证了提出的互补学习范式的有效性。提出的代码已公开，可供下载。
## 629. `cs.CV` - CBDiff: 条件伯努利扩散模型在图像伪造定位中的应用 [PDF](https://arxiv.org/pdf/2510.19597), [HTML](https://arxiv.org/abs/2510.19597)
### Authors
Zhou Lei,Pan Gang,Wang Jiahao,Sun Di
### Background
图像伪造定位（IFL）是一个关键任务，旨在准确识别图像中的篡改或伪造区域。现有方法通常生成一个单一的确定性定位图，这在高风险应用如法医分析和安全监控等领域缺乏必要的精度和可靠性。
### Innovation
引入了先进的条件伯努利扩散模型（CBDiff），该模型在给定篡改图像时生成多个多样且合理的定位图，提供伪造分布的更丰富和更全面的表示，同时创新性地将伯努利噪声纳入扩散过程，以更好地反映伪造掩模的二进制和稀疏特性。此外，CBDiff 引入了时间步长交叉注意力（TSCAttention），具体设计用于通过时间步骤利用语义特征指导提高篡改检测效果。
### Conclusion
在八个公开基准数据集上的广泛实验表明，CBDiff 显著优于现有最先进的方法，突显了其在实际部署中的强大潜力。
## 630. `cs.CV` - Faiss库 [PDF](https://arxiv.org/pdf/2401.08281), [HTML](https://arxiv.org/abs/2401.08281)
### Authors
Matthijs Douze,Alexandr Guzhva,Chengqi Deng,Jeff Johnson,Gergely Szilvasy,Pierre-Emmanuel Mazaré,Maria Lomeli,Lucas Hosseini,Hervé Jégou
### Background
目前，AI应用程序正在迅速发展，需要存储和索引的嵌入向量数量也在增加。Faiss库专门用于向量相似性搜索，这是向量数据库的核心功能之一。Faiss是一个包含索引方法及相关基础组件的工具包，用于搜索、聚类、压缩和变换向量。
### Innovation
本文描述了向量搜索的权衡空间以及Faiss的设计原则，包括结构设计、优化方法以及接口设计。同时，论文还对库的关键功能进行了基准测试，并讨论了几种选定的应用场景，以展示其广泛适用性。
### Conclusion
本文通过对Faiss库的关键特性和应用场景的介绍，展示了其在向量相似性搜索方面的强大功能和广泛适用性，同时也指出了Faiss在向量搜索方面的潜在改进空间。
## 631. `cs.CV` - 具有输入凸神经网络正则化的图像重建的 primal-dual 算法 [PDF](https://arxiv.org/pdf/2410.12441), [HTML](https://arxiv.org/abs/2410.12441)
### Authors
Matthias J. Ehrhardt,Subhadip Mukherjee,Hok Shing Wong
### Background
本文探讨了在数据驱动的变分重建框架中的优化问题，其中正则化器由输入凸神经网络（ICNN）参数化。虽然梯度基方法通常用于解决此类问题，但它们难以有效处理非光滑问题，导致收敛速度慢。此外，神经网络的嵌套结构使标准非光滑优化技术（如近端算法）的应用复杂化。
### Innovation
为了克服这些挑战，作者重新形式化了问题并消除了神经网络的嵌套结构。通过将此重新形式化与激活函数的外水平投影相关联，作者将问题转化为可以用 primal-dual 算法高效求解的凸优化问题。同时，作者证明了这种重新形式化等同于原始变分问题。实验表明，所提出的方法不仅在光滑设置中优于次梯度方法，甚至优于加速方法，还能促进正则化器本身的训练。
### Conclusion
实验结果表明，该方法不仅在光滑设置中优于次梯度方法和加速方法，而且还能促进正则化器本身的训练。
## 632. `cs.CV` - 从3D CT扫描中进行多标签异常分析的结构化频谱图表示学习 [PDF](https://arxiv.org/pdf/2510.10779), [HTML](https://arxiv.org/abs/2510.10779)
### Authors
Theo Di Piazza,Carole Lazarus,Olivier Nempont,Loic Boussel
### Background
随着CT检查的数量不断增加，对自动化工具的需求也在增加，如器官分割、异常检测和报告生成，以支持放射科医生管理其临床工作负载。虽然基于3D卷积神经网络的方法已经在多标签分类3D胸CT扫描方面取得了进展，但由于体积数据中的复杂空间关系和异常多样性的广泛变化，这个任务仍然是一项关键而具有挑战性的任务。现有的方法难以捕捉长距离依赖关系，而视觉变换器则需要大量的预训练数据来在性能上与之竞争。该研究旨在解决3D CT扫描中的多标签异常分析问题，引入了一种新的图基框架，将3D CT体积表示为结构化图，通过谱图卷积处理轴向切片三重组，从而在保持临床部署复杂性的同时，能够推理层间依赖关系。
### Innovation
该研究提出了一种2.5D的图基框架，将3D CT体积表示为结构化图，其中轴向切片三重组作为节点，通过谱图卷积进行处理，以捕捉层间依赖关系并保持临床部署所需的复杂性。通过这种结构化频谱图表示学习方法，该研究实现了跨数据集的强泛化能力，并在自动化放射学报告生成和腹部CT数据上的转移实验中展示了更广泛的应用潜力。通过不同的聚合并策略、边权重方案和图连接模式进行了全面的消融研究，评估了各方面的性能影响。
### Conclusion
该方法在三个独立机构提供的数据集上进行了训练和评估，展示了与最先进的视觉编码器相当的性能。此外，该研究还进行了全面的消融研究，评估了不同聚合策略、边权重方案和图连接模式的影响。研究还展示了该方法在自动化放射学报告生成和腹部CT数据上的更广泛适用性。
## 633. `cs.CV` - X-Reflect: 杂糅反向提示对于跨模态推荐 [PDF](https://arxiv.org/pdf/2408.15172), [HTML](https://arxiv.org/abs/2408.15172)
### Authors
Hanjia Lyu,Ryan Rossi,Xiang Chen,Md Mehrab Tanjim,Stefano Petrangeli,Somdeb Sarkhel,Jiebo Luo
### Background
大规模语言模型（LLMs）已被证明可以增强通过丰富项目描述提高推荐系统准确性的能力。然而，大多数现有方法要么依赖纯文本提示，要么采用基本的多模态策略，这些策略并未充分利用文本和视觉模态之间的互补信息。这项研究介绍了一种新颖的方法，称为跨反思提示（Cross-Reflection Prompting，简称X-Reflect），通过提示多模态大型语言模型（MLLMs）明确识别和解决图文之间的支持和冲突信息，来解决上述问题。这种方法通过捕捉两种模态的细微洞察，生成更为全面和上下文丰富的项目表示。
### Innovation
该研究提出了一种名为X-Reflect的方法，设计了跨反思提示框架，以解决现有方法限制的问题。具体来说，该方法通过提示MLLMs明确识别和解决图文之间的支持和冲突信息，从而生成更为全面和上下文丰富的项目表示。实验表明，与现有提示基础方法相比，该方法在推荐准确性方面表现出色。此外，研究还发现文本-图像差异与推荐性能之间存在U形关系，表明在特定情况下，多模态提示是有益的。为了支持实时高效推理，还提出了一种轻量级变体X-Reflect-keyword，通过使用关键词来总结图像内容，并用较小的骨干模型替换基础模型，输入长度减少了近50%，同时保持了竞争性能。
### Conclusion
这项工作强调了整合多模态信息的重要性，并提出了在多模态推荐系统中提高项目理解的有效解决方案。
## 634. `cs.CV` - Fast-Slow Thinking GRPO for Large Vision-Language Model Reasoning [PDF](https://arxiv.org/pdf/2504.18458), [HTML](https://arxiv.org/abs/2504.18458)
### Authors
Wenyi Xiao,Leilei Gan
### Background
在应用强化学习（通常通过GRPO实现）来处理大型视觉语言模型推理时，模型难以有效地扩展推理长度或产生冗余输出，且精度提升有限。
### Innovation
该论文提出了一种名为FAST-GRPO的新变体，它根据不同问题的特性动态调整推理深度。通过引入两个衡量问题难度的指标，并结合自适应长度的奖励和难度感知的KL散度，改进了GRPO算法，从而在多个推理基准测试中取得了最佳性能，同时减少了32.7%-67.3%的 token 使用量，比之前的慢思考方法更高效地平衡了推理长度和精度。
### Conclusion
FAST-GRPO通过改进的GRPO算法和新的衡量指标，在多个推理基准测试中展示了显著的性能提升和资源节约，为大型视觉语言模型的推理提供了新的解决思路。
## 635. `cs.CV` - mmWalk: 向多模态多视点步行辅助迈进 [PDF](https://arxiv.org/pdf/2510.11520), [HTML](https://arxiv.org/abs/2510.11520)
### Authors
Kedi Ying,Ruiping Liu,Chongyan Chen,Mingzhe Tao,Hao Shi,Kailun Yang,Jiaming Zhang,Rainer Stiefelhagen
### Background
对于盲人或低视力（BLV）人士而言，在复杂或极端环境中进行步行辅助仍是一个显著的挑战，主要原因是缺乏全面的场景理解。BLV群体的实际需求促进了本文的发展，我们构建了一个名为mmWalk的模拟多模态数据集，它结合了多视角传感器和无障碍导向功能，用于户外安全导航。该数据集中有120条手动控制的场景分类步行轨迹，包括62,000帧同步序列。该数据集包含超过559,000张全景图像，覆盖RGB、深度和语义模态。另外，每个轨迹都包含了适用于BLV用户的户外特殊情况和无障碍特定地标，以强调其实际相关性。此外，我们还生成了一个超过69,000个视觉问题-答案三元组的基准mmWalkVQA，这些三元组涵盖了9个类别，专门用于安全和知情的步行辅助。我们使用最先进的视觉语言模型（VLMs）进行了零样本和少样本设置下的评估，发现它们在我们的风险评估和导航任务中表现不佳。我们还使用真实世界的数据集验证了mmWalk微调模型的有效性，并展示了我们的数据集对于推动多模态步行辅助的进展的重要作用。
### Innovation
我们创建了一种名为mmWalk的新模拟多模态数据集，用于户外安全导航，助力盲人或低视力人士在复杂或极端环境中进行步行协助。该数据集采用了图像、深度和语义模态的融合，重点突出了适用于BLV用户的户外特殊情况和无障碍特定地标，以增强数据的实际相关性。此外，我们还创建了一个称为mmWalkVQA的视觉问答基准，为安全和知情的步行辅助提供了关键资源。通过评估最先进的视觉语言模型在我们的风险评估和导航任务中表现不佳的问题，我们展示了一个基于mmWalk的数据集的有效性，以解决BLV群体的步行协助需求。
### Conclusion
我们验证了mmWalk数据集微调后的模型在真实世界数据集上的有效性，并证明了该数据集对于多模态步行辅助技术进步的有效性。
## 636. `cs.CV` - 从零开始的稀疏训练的重参数化方法：Sign-In [PDF](https://arxiv.org/pdf/2504.12801), [HTML](https://arxiv.org/abs/2504.12801)
### Authors
Advait Gadhikar,Tom Jacobs,Chao Zhou,Rebekka Burkholz
### Background
从零开始训练稀疏神经网络（PaI）与从密集到稀疏的训练之间的性能差距成为高效深度学习的主要障碍。根据Lottery Ticket Hypothesis，PaI的关键在于找到特定问题的参数初始值，而研究表明，正确的参数符号即可实现这一点，但PaI难以找到正确的参数符号。因此，亟需一种能够解决这一问题的方法来提升PaI的性能，缩小PaI与从密集到稀疏训练之间的差距。
### Innovation
提出了Sign-In方法，该方法通过一种动态重参数化，可以证明其可以引发符号翻转。这种符号翻转与从密集到稀疏的训练能够实现的符号翻转互补，使得Sign-In成为一种独立的方法。实验和理论结果表明，Sign-In能提高PaI的性能，但同时也揭示了主要的开放挑战在于进一步缩小PaI与从密集到稀疏训练之间的差距。
### Conclusion
尽管Sign-In方法在理论上和实验上都证明了能改善PaI的性能，但在实际应用中还需克服一些主要挑战，尤其是在如何更好地引导符号翻转以进一步提升PaI的稀疏训练效果方面。
## 637. `cs.CV` - RL真的能够激励LLMs在基模型之外产生推理能力吗？ [PDF](https://arxiv.org/pdf/2504.13837), [HTML](https://arxiv.org/abs/2504.13837)
### Authors
Yang Yue,Zhiqi Chen,Rui Lu,Andrew Zhao,Zhaokai Wang,Yang Yue,Shiji Song,Gao Huang
### Background
近期，可验证奖励强化学习（RLVR）在提高大型语言模型（LLMs）的推理能力方面取得了显著成效，特别是在数学和编程任务上。与传统强化学习帮助代理探索和学习新策略类似，RLVR被认为能使LLMs持续自我提升，从而获得超出原始基模型的新推理能力。
### Innovation
本研究系统地测试了RLVR训练的LLMs在不同模型家族、RL算法以及数学、编程和视觉推理基准测试中的推理能力边界，采用大k值下的pass@k作为评估指标。发现当前训练设置未能激发实质性的新推理模式，尽管在小k值下RLVR训练模型优于基模型，但在大k值时基模型表现出更高的pass@k分数。覆盖分析和困惑度分析显示，观测到的推理能力源于并受限于基模型。定量分析表明，六种流行RLVR算法表现相似，且远未充分利用基模型的潜力。相比之下，发现蒸馏可以从教师模型引入新的推理模式，真正扩展模型的推理能力。
### Conclusion
我们的发现表明，当前RLVR方法尚未实现通过RL激发LLMs真正新的推理能力的潜力。这强调了需要改进的RL范式，如持续扩展和多轮代理-环境交互，以挖掘这一潜力。
## 638. `cs.CV` - CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs [PDF](https://arxiv.org/pdf/2505.12944), [HTML](https://arxiv.org/abs/2505.12944)
### Authors
Jan Hagnberger,Daniel Musekamp,Mathias Niepert
### Background
使用稠密的空间域求解时间依赖偏微分方程（PDEs）是许多科学和工程学科中一个基本问题，包括气候现象建模和流体动力学。直接在物理空间进行这些计算通常会带来显著的计算成本。为此，开发了在压缩潜在空间中工作的神经代理模型来求解PDE。这些方法降低了计算复杂性，但通常使用基于变换器的注意力机制来处理不规则样本域，导致内存消耗增加。相比之下，卷积神经网络可以进行内存高效编码和解码，但只能处理规则分割。
### Innovation
我们提出了一个模型类别CALM-PDE，能够有效地在压缩潜在空间中求解任意分割的PDEs。我们引入了一种新颖的连续卷积编码器-解码器架构，使用了ε-邻域约束核，并且可以学习将在自适应和优化查询点上应用卷积操作。CALM-PDE 在多种具有规则和不规则空间域的时间依赖PDEs 上展示了有效性和竞争力，同时与基于变换器的方法相比，在内存和推理时间效率上有显著改进。
### Conclusion
CALM-PDE 在与现有基线方法的竞争中具有竞争力或表现出色，同时在内存和推理时间效率方面提供了显著改进。
## 639. `cs.CV` - 生成扩散模型代理用于机制化基于代理的生物模型 [PDF](https://arxiv.org/pdf/2505.09630), [HTML](https://arxiv.org/abs/2505.09630)
### Authors
Tien Comlekoglu,J. Quetzalcoatl Toledo-Marín,Douglas W. DeSimone,Shayn M. Peirce,Geoffrey Fox,James A. Glazier
### Background
机制性、多细胞、基于代理的模型常用于在单细胞分辨率下研究组织、器官和整体生物。细胞-方块模型（CPM）是一个强大的框架，用于开发和探讨这些模型。但在大规模空间和时间尺度上，CPM变得计算成本过高，难以应用和研究。因此，代理模型可能会加快复杂生物系统的CPM评估，但这些模型的随机性意味着每组参数可能会导致不同的模型配置，使得代理模型的开发复杂化。
### Innovation
本文利用自去噪扩散概率模型训练了一个生成式AI代理的CPM，用于研究体外血管生成。通过使用图像分类器学习定义二维参数空间的独特区域的特征，辅助代理模型的选择和验证。CPM代理模型可以提前20,000个时间步长生成模型配置，并比原生代码执行大约减少22倍的计算时间。这项工作代表了自去噪扩散概率模型在构建随机生物系统的数字双胞胎中的应用一步。
### Conclusion
本文的工作代表了开发随机生物系统的数字双胞胎中自去噪扩散概率模型开发代理模型的一步。
## 640. `cs.CV` - 以视觉为基础的语言约束：一种用于减轻LVLMs幻觉的条件互信息校准解码策略 [PDF](https://arxiv.org/pdf/2505.19678), [HTML](https://arxiv.org/abs/2505.19678)
### Authors
Hao Fang,Changle Zhou,Jiawei Kong,Kuofeng Gao,Bin Chen,Shu-Tao Xia
### Background
大型视觉-语言模型（LVLMs）容易出现幻觉，生成的响应虽然在语义上看似合理，但实际上与输入图像关系不大。前人研究表明，这一问题主要源于LVLMs对语言先验的高度依赖，忽略了解码过程中视觉信息的作用。
### Innovation
提出了一种新颖的条件点互信息（C-PMI）校准解码策略，该策略能够动态增强生成文本与输入图像之间的互相关依赖性，以减少幻觉。这种方法新颖之处在于不仅关注文本令牌的采样，还联合建模视觉和文本令牌对C-PMI的贡献，将幻觉减少转化为两级优化问题，旨在最大化互信息。通过设计一种令牌净化机制来动态调节解码过程，该机制根据图像相关性不断调整文本令牌的采样，同时优化生成响应相关性。
### Conclusion
广泛的实验表明，所提出的方法显著减少了LVLMs中的幻觉现象，同时保持了解码效率。
## 641. `cs.CV` - 自回归图像生成的水印技术 [PDF](https://arxiv.org/pdf/2506.16349), [HTML](https://arxiv.org/abs/2506.16349)
### Authors
Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez
### Background
生成模型的输出水印化已成为一种追踪其来源的有前途的方法。尽管对于自回归图像生成模型及其潜在滥用已经产生了显著的兴趣，但此前没有工作尝试在其标记级别对它们的输出进行水印。
### Innovation
提出了将语言模型水印技术适应到自回归图像生成模型的情境中。通过一种定制的标记器-反标记器微调过程来提高逆循环一致性（RCC），并引入了一个互补的水印同步层，以增强其鲁棒性，同时应对常见的图像变换、神经压缩和删除攻击。
### Conclusion
实验表明，该方法能够实现可靠且基于理论依据的 p 值来检测水印。相关的代码和模型可提供下载。
## 642. `cs.CV` - REOrdering Patches Improves Vision Models [PDF](https://arxiv.org/pdf/2505.23751), [HTML](https://arxiv.org/abs/2505.23751)
### Authors
Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta
### Background
现有的序列模型（如变换器）要求输入必须被表示为一维序列。在视觉领域，这通常通过固定行优先（栅格扫描）顺序对图像进行展平实现。尽管全自注意力机制在置换下是不变的，但现代长序列变换器越来越多地依赖于打破这种不变性和引入对块顺序敏感性的架构近似。研究表明，在这种情况下，块顺序对模型性能有显著影响，简单的替代方案如列优先或希耳伯特曲线能够带来显著的准确性变化。
### Innovation
本文提出了一种名为REOrder的两阶段框架，用于发现任务最优的块顺序。首先，通过评估不同块序列的压缩性来推导信息理论的先验。然后，通过优化 Plackett-Luce 策略来学习一个置换的操作策略。这种方法能够在组合置换空间中实现有效的学习。实验结果表明，REOrder 模型在 ImageNet-1K 和 Functional Map of the World 上分别比行优先顺序提高了高达 3.01% 和 13.35% 的 top-1 准确率。
### Conclusion
REOrder 改进了视觉模型在 BlockOrder 方面的表现，特别是在 ImageNet-1K 和 Functional Map of the World 上取得了显著的准确率提升。
## 643. `cs.CV` - 一种用于显微镜图像中微管噪声自适应和稳健分割的新注意力机制 [PDF](https://arxiv.org/pdf/2507.07800), [HTML](https://arxiv.org/abs/2507.07800)
### Authors
Achraf Ait Laydi,Louis Cueff,Mewen Crespo,Yousef El Mourabit,Hélène Bouvrais
### Background
细胞骨架纤维在理解细胞功能方面至关重要，但在密集复杂的网络以及在噪声或低对比度图像条件下进行分割仍具有挑战性。尽管深度学习技术进步了图像分割的性能，但在这些不利条件下表现往往不佳。此外，准确标注数据的难度和严重类别不平衡也构成了额外挑战。
### Innovation
提出了一种新型的噪声自适应注意力机制，扩展了Squeeze-and-Excitation (SE)模块，使其能够动态适应不同级别的噪声。该自适应SE (ASE)机制集成到U-Net解码器中，带有残差编码器块，形成一个轻量级但强大的模型：ASE_Res_U-Net。此外，使用了合成数据集策略和定制损失函数以及评估指标来缓解类别不平衡，确保公平评估。ASE_Res_U-Net在合成和实际噪声图像中有效分割微管，性能优于其消融变体和现有曲线条结构分割方法，同时使用了更少的参数，适合资源受限环境。ASE_Res_U-Net还在不同成像条件下很好地泛化了对其他曲线条结构（血液血管和神经）的分割。
### Conclusion
ASE_Res_U-Net模型在不同成像条件下有效分割了微管，克服了数据标注、分类不平衡和噪声条件下的分割挑战，提供了更好的分割性能和泛化能力。
## 644. `cs.CV` - RADAR: 一种基于角色专业化协作的风险感知动态多智能体框架用于大语言模型安全评估 [PDF](https://arxiv.org/pdf/2509.25271), [HTML](https://arxiv.org/abs/2509.25271)
### Authors
Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li
### Background
现有的大语言模型（LLMs）的安全评估方法存在内在局限性，包括评估者偏见和由于模型同质性引起的风险检测失败，这些都削弱了风险评估过程的稳健性。
### Innovation
本文通过引入一个理论框架，重新审视风险评估范式，将潜在的风险概念空间分解为三个互斥子空间：显式风险子空间（涉及直接违反安全准则）、隐式风险子空间（捕捉需要情境推理识别的潜在恶意内容）以及无风险子空间。进一步提出了一个利用多轮辩论机制的多人协作评估框架RADAR，该框架通过四个特殊互补角色和动态更新机制实现了风险概念分布的自进化，从而全面覆盖显式和隐式风险并缓解评估者偏见。
### Conclusion
通过在包含800个具有挑战性的案例的自定义评估数据集和公开基准测试上的广泛实验，表明RADAR在准确性、稳定性和自我评估风险灵敏度等多个维度上显著优于基线评估方法，其风险识别准确率提高了28.87%。
## 645. `cs.CV` - MCIF: 多模态跨语言指令跟随基准(data从科学演讲中获得的多模态跨语言指令跟随基准)| [PDF](https://arxiv.org/pdf/2507.19634), [HTML](https://arxiv.org/abs/2507.19634)
### Authors
Sara Papi,Maike Züfle,Marco Gaido,Beatrice Savoldi,Danni Liu,Ioannis Douros,Luisa Bentivogli,Jan Niehues
### Background
近期大规模语言模型的发展促进了多模态LLM（MLLMs）的发展，这些模型整合了文本、语音和视觉信息，统一框架之下的多模态LLM从单一语言、单一任务系统向通用指令遵循模型转变。然而，现有的评估基准在评估多语言和多模态能力时存在局限：它们通常仅限于英语，主要关注单一模态，依赖短文本内容，或者缺乏人工注释——这限制了对语言、模态和任务复杂性全面模型性能的评估.
### Innovation
本文引入了MCIF（跨语言多模态指令跟随），这是第一个基于科学演讲的人工标注基准，用于评估跨语言和多模态环境下的指令遵循能力，涵盖短、长文本输入。MCIF涵盖了三个核心模态（语音、视觉和文本），以及四种语言（英语、德语、意大利语和中文），旨在全面评估多模态LLM跨语言解释指令的能力和结合多模态上下文信息的能力。该基准数据集在CC-BY 4.0许可下发布，促进研究开放和多模态LLM的发展.
### Conclusion
MCIF为评估多模态LLM在多语言、多模态、跨语言和复杂任务环境中的性能提供了一个全面的基准，克服了现有Benchmark的局限性，为多模态LLM的研发提供了坚实的基础.
## 646. `cs.CV` - 量化感知类脑架构在资源受限设备上实现高效皮肤疾病分类 [PDF](https://arxiv.org/pdf/2507.15958), [HTML](https://arxiv.org/abs/2507.15958)
### Authors
Haitian Wang,Xinyu Wang,Yiren Wang,Zichen Geng,Xian Zhang,Yu Zhang,Bo Miao
### Background
在边缘设备上实现高效且准确的皮肤病变分类对于可访问的皮肤科护理至关重要，但出于计算、能源和隐私的制约，这一目标仍具有挑战性。
### Innovation
QANA提出了一种新型的可用于资源受限硬件上的增量皮肤病变分类的量化感知神经形态架构。QANA通过有效地整合鬼模块、高效通道注意机制和Squeeze-and-Excitation块，实现了低延迟和能效的鲁棒特征表示。其量化感知头部和与神经脉冲兼容的转换使得 QANA 可无缝转换为脉冲神经网络（SNNs），并部署于类脑平台上。QANA在HAM10000大规模基准测试和真实临床数据集上的实验表明，该方法在HAM10000测试集上的Top-1准确率为91.6%，宏F1分数为82.4%，在临床数据集上的准确率为90.8%/81.7%，显著超越了在公平比较下的最先进的CNN到SNN模型。部署在BrainChip Akida硬件上，QANA实现了每图像1.5毫秒的推理延迟和1.7毫焦的能量消耗，分别相比基于GPU的CNN模型减少了94.6%/98.6%以上的推理延迟和能耗，超越了最先进的CNN到SNN转换基线，表明QANA在这种环境下的有效性。
### Conclusion
这些结果证明了QANA在边缘环境中的有效性，能够实现准确、实时和隐私敏感的医疗分析。
## 647. `cs.CV` - VO-DP: 仅视觉语义几何自适应扩散策略用于视觉机器人操作 [PDF](https://arxiv.org/pdf/2510.15530), [HTML](https://arxiv.org/abs/2510.15530)
### Authors
Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He
### Background
在模仿学习的背景下，基于视觉运动的高斯分布策略学习是机器人操作的主要方向之一。大多数方法依赖于点云作为输入，并通过点云特征学习构建场景表示，这种机制能实现显著的准确性。然而，现有的文献缺乏对纯视觉解决方案的深入探索，尽管这些解决方案具有巨大的潜力。
### Innovation
本文提出了一种名为VO-DP的纯视觉单视图扩散政策学习方法，这种方法利用预训练的视觉基础模型实现语义和几何特征的有效融合。通过结合VGGT的中间特征、DINOv2的语义特征和交替注意力模块的几何特征，使用跨注意力和CNN进行空间压缩，形成策略头部的输入。广泛的实验证明，VO-DP不仅显著优于纯视觉基准DP，还在在模拟任务中达到64.6%的成功率（与DP3的64.0%相当，远高于DP的34.8%），在实际任务中高达87.9%，远远超过了DP3的67.5%和DP的11.2%。此外，VO-DP在各种条件下表现出高度的稳定性，包括颜色、大小、背景和照明。
### Conclusion
最后，我们开源了一个基于Accelerate的训练库，支持多机多GPU并行训练和混合精度训练。该库兼容诸如DP、DP3和VO-DP等视觉运动策略，同时也支持RoboTwin模拟器。
## 648. `cs.CV` - 扩散模型中的缓存方法综述：朝向高效的多模态生成 [PDF](https://arxiv.org/pdf/2510.19755), [HTML](https://arxiv.org/abs/2510.19755)
### Authors
Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang
### Background
扩散模型已经成为现代生成人工智能的关键支柱，以其卓越的生成质量和可控性而闻名。然而，它们的固有特性——多步骤迭代和复杂的骨干网络——导致了巨大的计算开销和生成延迟，这成为了实时应用中的主要瓶颈。尽管现有的加速技术已经取得了一些进展，但仍面临适用限制、高昂的训练成本或质量下降等问题。
### Innovation
扩散缓存（Diffusion Caching）提供了一种在无需训练、适应多种架构且高效的推理范式。它通过识别和重用扩散过程中内在的计算冗余，允许特征级别的跨步重用和层间调度，从而在不修改模型参数的情况下减少计算量。本文系统地回顾了扩散缓存的理论基础和演变，并提出了其分类和分析的统一框架。通过代表性方法的比较分析，展示了扩散缓存从静态重用于动态预测的发展趋势，增强了其在不同任务中的灵活性，并使其能够与其他加速技术（如采样优化和模型蒸馏）集成，为未来的多模态和交互应用提供了统一、高效的推理框架。
### Conclusion
我们认为这种范式将成为实时和高效生成人工智能的关键使能器，为理论和实践中的高效生成智能注入新的活力。
## 649. `cs.LG` - 检索只需要部分注意力 [PDF](https://arxiv.org/pdf/2510.19861), [HTML](https://arxiv.org/abs/2510.19861)
### Authors
Felix Michalak,Steven Abreu
### Background
我们展示了混合SSM-Transformer架构中的完全功能分离：检索完全依赖于自注意力层。在RecurrenceGemma-2B/9B和Jamba-Mini-1.6模型中，移除自注意力会导致灾难性的检索失败（准确率为0%），而SSM层即使在使用改进的提示下也无补偿机制。然而，将注意力稀疏化到仅15%的头能在保持近完美的检索同时保留84%的MMLU性能，表明自注意力主要针对检索任务专业化。我们确定了精确的机制要求：生成期间需要暴露针状令牌，且预填充或生成期间需要足够的上下文。这种严格的功能专业化挑战了混合架构中冗余性的假设，并表明这些模型作为专一模块而非综合系统运行，这对架构优化与可解释性具有即时影响。
### Innovation
研究发现混合SSM-Transformer架构中自注意力层和SSM层的功能分离显著。移除自注意力导致检索彻底失败，而自注意力仅稀疏化就能保持高检索准确率和相对高的性能。
### Conclusion
研究表明，自注意力在检索任务中具有专一性，需要特定的机制来暴露针状令牌和提供足够的上下文。这一发现提出了混合架构设计中的假设，并指出这些模型可能作为专一模块而非综合系统运作，对未来的架构优化和模型解释有重要意义。
## 650. `cs.CV` - 利用有限示范学习向人群推诿 [PDF](https://arxiv.org/pdf/2510.19351), [HTML](https://arxiv.org/abs/2510.19351)
### Authors
Nilesh Ramgolam,Gustavo Carneiro,Hsiang-Ting Chen
### Background
本文解决了学习推诿（L2D）系统实践部署中遇到的关键数据稀缺问题。这些系统需要大量的示例数据，但在许多实际应用场景中，由于示例数据受限，导致难以实际应用。为解决这一问题，本文提出了一种结合元学习的半监督框架，这种框架可以从少量示例中生成专家特定的嵌入，从而减轻数据需求，增强模型的泛化能力。同时，这些嵌入用于生成大规模的伪标签用于训练，并在测试时允许模型实时适应新的专家，大大提高了系统的灵活性和实用性。这些实验在三个不同数据集上验证了通过使用合成标签训练的模型能够快速达到接近理想的性能，进一步证明了该方法在数据效率上的优势。
### Innovation
本文提出了一种结合元学习的半监督框架，该框架能够在少量示范的基础上为不同专家生成特定的嵌入表示。这些嵌入首先用于生成大规模的伪标签以优化训练过程，进而使系统具备在测试时快速适应新专家的灵活性。这种方法解决了传统L2D系统数据需求高、难以适应新环境的问题，显著提高了系统的实用性和可扩展性，有利于推动人类与人工智能的协作在真实环境中的实现。
### Conclusion
本文展示了通过元学习生成特定嵌入并在少量示范基础上训练L2D系统的方法，该方法通过快速逼近理想性能，验证了数据效率的显著提升，并通过解决关键的训练瓶颈，使得自适应L2D系统更加实用和可扩展。这种方法为在现实环境中实现人机协作提供了可能，并为后续研究提供了新的方向。项目成果包括源代码和训练配置在提供的网站上详细说明。
## 651. `cs.LG` - 从小到大：通过推理图转移CUDA优化专业知识 [PDF](https://arxiv.org/pdf/2510.19873), [HTML](https://arxiv.org/abs/2510.19873)
### Authors
Junfeng Gong,Zhiyi Wei,Junying Chen,Cheng Liu,Huawei Li
### Background
尽管CUDA编程和领域特定库已经有了长足的发展，但有效地利用具有大规模并行引擎的GPU仍然颇具挑战性。大语言模型（LLMs）展示了从顺序代码生成优化CUDA代码的强大潜力，但在实际应用中，云基础API存在代码泄露风险，而本地部署则往往计算成本高且效率低下。这些问题促使人们转向较小语言模型（SLMs），因为SLMs更加轻量级且隐私友好。虽然SLMs在特定领域任务上可以与LLMs媲美，但在复杂CUDA代码生成方面仍表现不佳。因此，研究提出了ReGraphT框架，它能够通过检索增强生成，将LLM级别的推理能力转移到较小模型上，从而弥补这一差距。
### Innovation
ReGraphT是一个无需训练、基于检索增强的生成框架，能够将LLM级别的推理能力转移给较小模型。该框架将CUDA优化路径组织成一个结构化的推理图，将联合CUDA优化表示为状态转移，并利用蒙特卡洛图搜索（MCGS）进行高效的探索。此外，还提出了一个针对CUDA的特定基准测试，包含不同推理复杂度的难度等级，以更全面地评估模型性能。
### Conclusion
实验结果表明，ReGraphT在CUDAEval和ParEval上分别比特定高性能计算（HPC）微调模型和其他检索增强方法快2.33倍，并且与DeepSeek-Coder-V2-Lite-Instruct和Qwen2.5-Coder-7B-Instruct搭配使用时，使SLMs接近LLM级别的性能，而无需承担隐私风险或过度的计算开销。
## 652. `cs.LG` - 通过可解释的SHAP引导特征选择和分类提高泌尿 tract 疾病诊断准确性 [PDF](https://arxiv.org/pdf/2510.19896), [HTML](https://arxiv.org/abs/2510.19896)
### Authors
Filipe Ferreira de Oliveira,Matheus Becali Rocha,Renato A. Krohling
### Background
本文提出了一种使用基于SHAP的特征选择方法来支持泌尿系统疾病的诊断，重点是膀胱癌。该研究开发了六个二元分类场景来区分膀胱癌与其他泌尿系统和肿瘤相关疾病。研究采用了XGBoost、LightGBM和CatBoost算法，并通过Optuna进行超参数优化，使用SMOTE技术进行类别平衡。
### Innovation
研究提出的方法使用了SHAP（SHapley Additive exPlanations）解释性技术来引导特征选择，这不仅提高了模型的透明性，还维持或提高了如均衡准确率、精度和特异性等性能指标。研究发现，使用解释性技术（SHAP）进行特征选择是有效的，对于开发更透明、可靠且高效的临床决策支持系统，优化泌尿系统疾病的筛查和早期诊断具有重要意义。
### Conclusion
所提出的方法可能会为泌尿系统疾病的诊断提供更透明、可靠和高效的临床决策支持系统，优化筛查和早期诊断过程。
## 653. `cs.LG` - 贪婪任务顺序在连续线性回归中的优越性 [PDF](https://arxiv.org/pdf/2510.19941), [HTML](https://arxiv.org/abs/2510.19941)
### Authors
Matan Tsipory,Ran Levinstein,Itay Evron,Mark Kong,Deanna Needell,Daniel Soudry
### Background
本文分析了在假设训练数据可联合实现的情况下，连续学习中线性回归任务的顺序安排。研究关注的是能够贪婪地最大化连续任务之间差异的顺序，这种顺序在先前的研究中有所探讨但仍有许多开放性问题。
### Innovation
利用Kaczmarz方法文献中的工具，本文正式化了上述顺序，并发展了关于它们的几何和代数直觉。实证研究表明，贪婪顺序在平均损失方面比随机顺序收敛更快，无论是对随机数据的线性回归任务还是对CIFAR-100分类任务的线性探针任务。理论分析表明，在高秩回归环境中，贪婪顺序具有类似随机顺序的损失上界。但在一般秩下，我们建立了依赖重复次数的分离。特别是，我们证明了无重复的单过贪婪顺序可能会灾难性失效，而允许重复的单过贪婪顺序收敛速度优于随机顺序。
### Conclusion
总体而言，本文揭示了贪婪顺序与随机顺序之间的微妙之处及其差异。
## 654. `cs.LG` - 超越理想：分析不精确的Muons更新 [PDF](https://arxiv.org/pdf/2510.19933), [HTML](https://arxiv.org/abs/2510.19933)
### Authors
Egor Shulgin,Sultan AlRashed,Francesco Orabona,Peter Richtárik
### Background
Muons优化器作为一种快速崛起的强大且几何感知的能力计算替代AdamW，在大规模训练神经网络中表现出色。然而，研究与实践经验之间存在一个关键的理论与实践差距：Muons的效率依赖于快速的近似正交化，而之前的理论工作则基于假设完全的SVD基更新的理想化版本进行了分析，这是计算不可行的。
### Innovation
本文突破了理想状态，首次分析了Muons核心的近似正交化更新。作者通过线性最小化或acles（LMO）优化的一般框架，引入了一个现实的加性误差模型来捕捉实践中近似方案的不准确性。研究结果提供了明确的界线，量化了LMO不准确性与性能下降之间的函数关系，揭示了不准确性与最优步骤尺寸和动量之间的基本耦合：较低的或acles精度需要更小的步骤尺寸但更大的动量参数。这些发现将近似过程（例如，Newton-Schulz步骤的数量）从实现细节提升为必须与学习计划一同调校的关键参数。
### Conclusion
纳米GPT实验直接证实了预测的耦合关系，最优学习率随精度变化而明显改变。
## 655. `cs.LG` - 从优化到预测：基于Transformer的路径流量估计解决交通分配问题 [PDF](https://arxiv.org/pdf/2510.19889), [HTML](https://arxiv.org/abs/2510.19889)
### Authors
Mostafa Ameli,Van Anh Le,Sulthana Shams,Alexander Skabardonis
### Background
交通分配问题是交通流分析的核心，通常通过数学规划方法在均衡原则下解决。这些方法因复杂性随OD对数量非线性增长而在大规模网络中变得计算上不可行。研究引入了一种新颖的数据驱动方法，利用深度神经网络（特别是Transformer架构），直接预测路径均衡流量。该方法关注路径级别的交通分布，能够捕捉OD对之间的复杂相关性，相较于传统链路级别的方法，提供更详细和灵活的分析。Transformer架构模型极大地减少了计算时间，同时能够适应需求和网络结构的变化而无需重新计算。研究在曼哈顿样式合成网络、Sioux Falls网络和东部马萨诸塞网络上进行了数值实验，结果显示，提出的模型在常规优化方法上快数千倍，能够高效地估算多类网络中的路径流量，减少了计算成本并提高了预测准确性，同时捕获了详细的旅行和流量信息。该模型还能够灵活适应需求和网络条件的变化，支持交通管理和增强的运输规划和政策制定，
### Innovation
提出的模型采用了基于Transformer的深度神经网络架构，直接预测路径均衡流量。这种路径级的交通分布处理能够捕捉OD对之间的复杂相关性，提供比传统链路级别方法更详细和灵活的分析。此外，基于Transformer的模型大幅减少了计算时间，并能够适应需求和网络结构的变化而无需重新计算，显著提高了效率和灵活性。
### Conclusion
研究表明，所提出的方法在计算效率和预测准确性方面远超传统优化方法。该模型能够广泛应用于多类网络，不仅降低了计算成本，还改进了预测精度，捕捉了详细的旅行和流入信息。此外，该模型能够灵活适应不同需求和网络条件，为交通管理和运输规划提供了增强的支持，并且能够快速进行“假设”分析，进一步支持政策制定。
## 656. `cs.LG` - FINDER: 使用特征残差的特征推断无噪声数据集中 [PDF](https://arxiv.org/pdf/2510.19917), [HTML](https://arxiv.org/abs/2510.19917)
### Authors
Trajan Murphy,Akshunna S. Dogra,Hanfeng Gu,Caleb Meredith,Mark Kon,Julio Enrique Castrillion-Candas
### Background
低信噪比、样本量小、数据收集故障等导致的‘嘈杂’数据集是分类方法研究的关键前沿领域，具有理论和实践意义。现有的分类方法在处理这类数据集时面临挑战，急需新的框架和方法来有效处理这些噪声数据。因此，本文提出了一种名为FINDER的严格框架，旨在分析通用分类问题，并为嘈杂数据集量身定制算法。FINDER利用了基本的随机分析思想，在特征学习和推理阶段有效地考虑到了所有经验数据固有的随机性。这种方法通过将经验数据视为随机场的实现（无需假设其确切分布），再映射到适当的希尔伯特空间，来构建‘随机特征’，并在Kosambi-Karhunen-Loéve扩展（KLE）分解中将其分解成可计算的不可约部分，用特征值分解来进行分类。这种方法在多个具有挑战性的、数据稀缺的科学领域进行了验证，取得了现有技术水平的突破性成果，包括阿尔茨海默病阶段分类和遥感检测森林砍伐。
### Innovation
引入了FINDER框架，该框架采用了一种创新的方法来处理噪声数据，使用随机场理论构建随机特征，并通过Kosambi-Karhunen-Loéve扩展将这些随机特征分解为可计算的不可约部分。这种方法通过特征值分解来实现分类，能够在嘈杂的数据集上进行有效的分类。此外，FINDER还能够在特定条件下超越现有方法，并且也能识别其失败模式和其他局限性，为用户提供了一个全面的评价工具。
### Conclusion
该论文通过在多个科学领域的应用验证了FINDER框架的有效性，并实现了业界最优的分类成果。还探讨了该方法的实际应用范围、失效模式和潜在的局限性，在为未来的研究提供了宝贵的参考。
## 657. `cs.LG` - 金融中的鲁棒强化学习：使用椭圆不确定性集建模市场影响 [PDF](https://arxiv.org/pdf/2510.19950), [HTML](https://arxiv.org/abs/2510.19950)
### Authors
Shaocong Ma,Heng Huang
### Background
在金融应用中，强化学习（RL）代理通常在历史上未受影响的价格水平上进行训练。然而，在部署时，这些代理在活跃市场中进行交易，他们的交易可以影响资产价格，这就是所谓的市场影响。训练和部署环境之间的这种差异会显著降低表现。传统的鲁棒RL方法通过优化一系列不确定性中的最坏情况表现来解决这个问题，但通常依赖于对称结构，这些结构无法捕捉到市场影响的方向性特征。这使得它们在处理市场交易时的鲁棒性不足。
### Innovation
为了应对这一问题，作者开发了一种新的椭圆不确定性集的类别。通过这些集合，可以得出隐式和显式的最坏情况不确定性封闭形式解，从而能够实现高效的鲁棒策略评估。实验表明，作者的方法在单一资产和多资产交易任务中实现了更好的夏普比率，并且在交易量增加时仍保持了鲁棒性。这种方法为金融市场的RL提供了更精确且可扩展的方法。
### Conclusion
实验结果证明了该方法在处理市场影响时的优越性，特别是在交易量增加的情况下能够保持良好的鲁棒性，提供了更精准且能够广泛应用到金融市场的RL方法。
## 658. `cs.LG` - 零阶优化中无偏梯度估计器的最优构造 [PDF](https://arxiv.org/pdf/2510.19953), [HTML](https://arxiv.org/abs/2510.19953)
### Authors
Shaocong Ma,Heng Huang
### Background
零阶优化（ZOO）是一种在梯度不可用或计算成本高昂时用于随机优化的重要框架。现有ZOO方法的主要局限在于大多数梯度估计器都存在偏差，除非扰动步长趋于消失。本文的目标是解决这一偏差问题，并提出一种仅基于函数评估的新颖无偏梯度估计器族。通过将方向导数重新表示为级联系列，并从仔细设计的分布中进行采样，构建了无偏估计器的同时保持了有利的方差特征。分析了其理论性质，推导了四个特定构造的最优尺度分布和扰动步长，并证明使用提出估计器的随机梯度下降（SGD）对于平滑非凸目标实现了最优复杂性。
### Innovation
提出了一种新型的无需计算梯度的无偏梯度估计器族，通过将方向导数重写为级联级数，并精心设计分布采样来消除偏差同时保持有利的方差。分析了估计器的理论性质并证明了采用这些新估计器的随机梯度下降算法在光滑非凸目标上实现了最优的复杂度。
### Conclusion
实验结果表明，该方法在合成任务和语言模型微调方面的准确性和收敛性优于标准方法。
## 659. `cs.LG` - FairGRPO: 公平强化学习以实现临床推理中的公正 [PDF](https://arxiv.org/pdf/2510.19893), [HTML](https://arxiv.org/abs/2510.19893)
### Authors
Shiqi Dai,Wei Dai,Jiaee Cheong,Paul Pu Liang
### Background
医疗人工智能系统在诊断能力上取得了显著进步，但在不同的种族群体中表现出不同的性能差距，这对代表性不足的群体造成了实际伤害。尽管最近的多模态推理基础模型通过集成多种类型的医疗数据来提升临床诊断，但强化学习训练过程中对大型训练数据集中的偏见进行了继承和放大。因此，研究团队引入了一种公平感知分层强化学习方法FairGRPO，旨在促进临床异质群体的公平学习。该方法结合了自适应的优势加权法，并利用无监督聚类自动发现潜在的种族群体标签，特别是在标签不可用的情况下。针对7个跨越5种临床模态的临床诊断数据集（X射线、CT扫描、皮肤镜检查、乳腺X线摄影和超声检查），实验结果表明，FairGRPO相比于所有其他原始的和消除偏差的RL基线，减少了预测平等性27.2%，同时F1得分提高了12.49%。
### Innovation
FairGRPO是一种分层强化学习方法，通过自适应的重要性加权优或、任务难度以及数据来源，强调公平学习，同时利用无监督聚类在标签不可用时自动发现潜在的人口属性分组。这种方法能有效减少性能差距，并在整个优化过程中逐步提高公平性，而现有RL方法的公平性在训练过程中则会下降。通过这种方法，实验团队还发布了FairMedGemma-4B，这是一个公平感知的临床VLLM，其性能达到了业界领先水平，并显示出跨族裔群体的显著减少差异。
### Conclusion
实验结果表明，FairGRPO在各个项目上均实现了公平性和性能的双重提升。在多个医疗诊断数据集上的全方面实验中，FairGRPO显著减少了模型在不同群体间的预测差距，同时提高了F1得分，证明了这种方法在实际应用中的有效性。进一步的训练动态分析也显示，在FairGRPO中，公平性随着优化的推进而持续提高，而基线RL方法的公平性则随训练进展而下降。FairMedGemma-4B作为该团队的成果，体现了这一技术的能力，并展示了在公平性和性能上的显著进步。
## 660. `cs.LG` - 重新审视零阶优化：最小方差两点估计和方向对齐扰动 [PDF](https://arxiv.org/pdf/2510.19975), [HTML](https://arxiv.org/abs/2510.19975)
### Authors
Shaocong Ma,Heng Huang
### Background
现有研究主要关注固定长度的扰动，并忽视了方向对齐的潜在优势。本文则探索了两点零阶梯度估计器，并确定了可以使估计器渐近方差最小化所需的随机扰动分布。同时，通过理论和实证分析，我们进一步探讨了方向对齐扰动（DAP）方案的特性，并对使用δ无偏随机扰动的随机梯度下降进行了收敛性分析。
### Innovation
该研究将随机扰动分布最小化零阶梯度估计器渐近方差的优化问题形式化为约束泛函优化问题。研究发现，理想的扰动可以沿真梯度方向对齐，而不是保持固定长度。同时，研究了DAP方案的理论和实证特性，为使用δ无偏随机扰动的随机梯度下降提供了收敛性分析，扩展了现有复杂性界至更广泛的扰动。
### Conclusion
通过在合成问题和实际任务上的实证评估，研究证明在特定条件下，DAPs相较于传统方法有更高的性能。此外，研究提供了对于随机梯度下降使用δ无偏随机扰动的收敛性分析，并将其复杂性界扩展到了更广泛的扰动范围。
## 661. `cs.LG` - 向强认证防御迈出一步：通用非对称随机化 [PDF](https://arxiv.org/pdf/2510.19977), [HTML](https://arxiv.org/abs/2510.19977)
### Authors
Hanbin Hong,Ashish Kundu,Ali Payani,Binghui Wang,Yuan Hong
### Background
随机平滑已成为实现机器学习模型鲁棒性认证的关键技术。然而，当前的方法主要使用等方向噪声分布，这意味着所有数据维度的均匀噪声，例如图像像素，这限制了其认证鲁棒性效果，因为它没有考虑到输入和数据维度的异质性。现有的方法难以应对这些问题，因此需要一种新的方法来改进鲁棒性认证方法。
### Innovation
本文提出了一种新技术UCAN：一种通用的、能够认证对抗鲁棒性的非对称噪声方法。UCAN旨在增强现有的随机平滑方法，使其从对称（等方向）噪声分布转变为不对称（非对称）的噪声分布，从而提供更个性化的对抗攻击防御。该理论框架具有广泛性，支持不同$boldsymbol{text{ℓ}}_p$范数下的噪声分布，并通过针对扰动输入的预测提供可证实的鲁棒性上下界来确保任何分类器的鲁棒性。此外，开发了一种新型框架，包含三个噪声参数生成器（NPGs），用于在不同数据维度上调优非对称噪声参数，以实现不同的鲁棒性增强。结果显示，UCAN在MNIST、CIFAR10和ImageNet数据集上的认证准确率大幅提高，尤其是在大的认证半径下，最高改进幅度可达182.6%。
### Conclusion
UCAN这一方法显著提升了随机平滑方法的语言模型的鲁棒性认证水平，其优异的性能超越了现有最先进技术，为未来的研究提供了有力的支持。
## 662. `cs.LG` - Abstain Mask Retain Core: Time Series Prediction by Adaptive Masking Loss with Representation Consistency [PDF](https://arxiv.org/pdf/2510.19980), [HTML](https://arxiv.org/abs/2510.19980)
### Authors
Renzhao Liang,Sizhe Xu,Chenggang Xie,Jingru Chen,Feiyang Ren,Shu Yang,Takahiro Yabe
### Background
时间序列预测在能源管理和金融市场等领域扮演着关键角色。尽管基于深度学习的方法（如MLP、RNN、Transformer）取得了显著进展，但现有的“长期序列信息获取假说”存在内在局限性。通过系统实验，本研究揭示了一个出乎意料的现象：适当裁剪历史数据可以意外地提高预测准确性。这表明现有模型在训练过程中学习了大量的冗余特征（如噪声或无关波动），从而影响有效的信号提取。
### Innovation
基于信息瓶颈理论，本研究提出了一种创新的解决方案，称为自适应掩码损失与表示一致性 (AMRC)。该解决方案包括两个核心组件：1) 动态掩码损失，其能够适应性地识别高度区分性的临时时间片段，以指导模型训练中的梯度下降；2) 表示一致性约束，其稳定了输入、标签和预测之间的映射关系。实验结果表明，AMRC 有效地抑制了冗余特征的学习，显著提高了模型性能。这项工作不仅挑战了时间模型的常规假设，还提供了开发高效和稳健预测模型的新颖理论见解和方法突破。
### Conclusion
本研究挑战了时间建模的常规假设，提出了自适应掩码损失与表示一致性 (AMRC) 解决方案，不仅有效抑制了冗余特征的学习，还显著提高了模型性能，为开发高效和稳健的预测模型提供了新的理论见解和方法突破。
## 663. `cs.LG` - 推测采样用于参数化时间点过程 [PDF](https://arxiv.org/pdf/2510.20031), [HTML](https://arxiv.org/abs/2510.20031)
### Authors
Marin Biloš,Anderson Schneider,Yuriy Nevmyvaka
### Background
时间点过程是一种强大的生成模型，用于捕捉事件序列中时间序列数据中的复杂时间依赖关系。它们通常使用自回归模型指定，学习下一事件的概率分布依赖于过去的事件。这种自回归模型使得采样过程不可避免地顺序进行，限制了效率。
### Innovation
本文提出了一种新的基于拒绝采样的算法，该算法可以在并行且无需任何架构更改或重新训练的情况下，从现有的时间点过程模型中精确采样多个未来的值。该方法除了提供理论保证外，还在实际数据集上展示了经验上的加速效果，实现了表达性和高效并行生成之间的平衡。
### Conclusion
本研究通过提出推测采样算法，成功解决了时间点过程模型在采样上的顺序限制问题，为大规模时间点过程应用提供了高效的并行生成方案。
## 664. `cs.LG` - 比特币交易的时序图 [PDF](https://arxiv.org/pdf/2510.20028), [HTML](https://arxiv.org/abs/2510.20028)
### Authors
Vahid Jalili
### Background
自2009年比特币网络成立以来，已处理超过10.8亿笔交易，涉及超过872亿枚比特币，为机器学习研究提供了丰富的数据潜力；然而，由于其以输出证明（UTXO）为基础的隐私设计，比特币网络中交易流的隐蔽性使得这些数据难以被机器学习研究利用。
### Innovation
本文通过重构资金流动，提出了一个适用于机器学习的比特币经济拓扑图模型。该模型是一个包含超过24亿个节点和397.2亿条边的异构时序图，能够全面记录到第textit{cutoffHeight}区块为止的完整交易历史。作者还提供了定制的采样方法和能够加载和分析比特币图数据的工具，以及可供直接使用的数据库快照。
### Conclusion
本文提供的全面数据集和工具集能够使机器学习社区能够大规模探索比特币复杂的生态系统，推动异常检测、地址分类、市场分析以及大型图机器学习基准测试等方面的应用进展。数据集和代码可在提供的链接处访问。
## 665. `cs.LG` - No Compute Left Behind: 重新思考掩码扩散模型中的推理与采样 [PDF](https://arxiv.org/pdf/2510.19990), [HTML](https://arxiv.org/abs/2510.19990)
### Authors
Zachary Horvitz,Raghav Singhal,Hao Zou,Carles Domingo-Enrich,Zhou Yu,Rajesh Ranganath,Kathleen McKeown
### Background
MDLMs 通过在随机屏蔽序列中填补位置来训练，并且相对于下一个标记预测模型，存在两种主要优势：(1) 任意顺序解码，(2) 多字令牌解码。然而，作者在数学和编码任务中观察到，任意顺序算法通常表现不佳或与左到右采样行为相似，标准的多字令牌解码会显著降低性能。在推理时，MDLMs 计算所有屏蔽位置的条件分布。自然问题是：当一次解码一个标记时，左到右解码与任意顺序解码算法表现相当，这段额外的计算如何被合理化？
### Innovation
1. 推理填充：通过使用 MDLMs 填补推理模板，可以结构化输出并区分理由和答案标记。这使得在推理过程中测量答案不确定性和早期退出成为可能，在模型收敛于答案时。2. 多字令牌熵解码 (MED)：一种简单的可适应采样器，基于位置的条件熵同时解码这些位置的错误。MED 在基准测试中保持了性能，并减少了解码步骤数量。3. 提供细调的新数据来源：使用 MDLMs 的后推理痕迹进行 fine-tuning，性能提升与使用人类编写的推理痕迹相当。4. 中间步骤推理过程的评分：给定一个答案，理由填充提供了一种方法来评估推理过程中的正确性。
### Conclusion
我们的工作展示了训练和计算使用 MDLMs 打开许多新的推理和后训练方法的潜力。
## 666. `cs.LG` - 基于RSSI决策树和CAD建模的RFID传感器网络定位精度的机器学习方法在国防应用中的研究 [PDF](https://arxiv.org/pdf/2510.20019), [HTML](https://arxiv.org/abs/2510.20019)
### Authors
Curtis Lee Shull,Merrick Green
### Background
RFID技术可以用于存储必须遵循安全指南的国防资产的跟踪，但传感器的非特异性（包括远程检测、欺骗和假冒）可能导致误检测和安全事件。目前使用RSSI数据和决策树分类在计算机辅助设计（CAD）模型中模拟RFID传感器网络的定位精度，并通过监督学习方法对12个实验室区域进行分类以进行位置推理。分类数据集有大约980,000次读取，且类别不平衡，因此计算了类别权重来处理分类不平衡的问题。研究发现RSSI数据下的决策树可以在实际模拟中用于国防供应链的区域异常检测或误位监测。
### Innovation
该研究利用CAD模型和监督学习算法对RFID标签的RSSI数据进行分析并分类实验室区域，提出一种新的方法来改进RFID传感器网络的定位精度。该方法特别适用于解决实验室区域的分类不平衡问题，并且考虑了相邻区域之间的物理关系，有助于提高定位精度。
### Conclusion
该研究通过RSSI数据下的决策树分类成功地在实验室区域进行了位置推理，但分类效果并不理想，尤其是在低覆盖率和低信号区域。为改进分类性能，建议优化天线布局或增加传感器并与其他模态进行传感器融合。这为RFID技术在国防领域的应用提供了新的思路和可能的改进方向。
## 667. `cs.LG` - 通过延迟回报下的上下文强化学习学习个性化广告影响 [PDF](https://arxiv.org/pdf/2510.20055), [HTML](https://arxiv.org/abs/2510.20055)
### Authors
Yuwei Cheng,Zifeng Zhao,Haifeng Xu
### Background
在线广告平台使用自动化拍卖来连接广告商与潜在客户，这需要有效的出价策略以最大化利润。准确的广告影响评估需要考虑三个关键因素：延迟和长期效果、累积广告影响（如强化或疲劳效应）以及客户异质性。然而，这些影响通常在之前的研究所未能同时进行处理。为了解决这些问题，作者将广告竞标建模为具有延迟泊松奖励的上下文马尔可夫决策过程（CMDP）。
### Innovation
提出了一种两阶段的最大似然估计器与数据分割策略结合的方法，基于第一阶段估计器的准确度来控制估计误差。在此基础上，设计了一种强化学习算法来推导有效的个性化出价策略，该方法实现了接近最优的遗憾界为$tilde{O}{(dH^2boldsymbol{root frac{1}{2}boldsymbol{right)}})}$，其中 $d$ 表示上下文维度、$H$ 表示轮数、$T$ 表示客户数量。
### Conclusion
理论发现通过仿真试验得到了验证。
## 668. `cs.LG` - SALT: Step-level Advantage Assignment for Long-horizon Agents via Trajectory Graph [PDF](https://arxiv.org/pdf/2510.20022), [HTML](https://arxiv.org/abs/2510.20022)
### Authors
Jiazheng Li,Yawei Wang,David Yan,Yijun Tian,Zhichao Xu,Huan Song,Panpan Xu,Lin Lee Cheong
### Background
大型语言模型（LLMs）展示了显著的能力，使语言代理能够在单轮任务中表现出色。然而，它们在处理复杂的多步骤和长期任务方面仍然面临挑战。强化学习（RL）为解决这些问题提供了前景，但主流方法通常仅依赖稀疏的结果奖励，这对没有批评模型的群体相对策略优化（GRPO）等群体基线RL算法尤其具有挑战性。在这些方法中，对轨迹内的所有行动统一奖励或惩罚会导致训练不稳定性和次优策略，因为有利和不利的行动往往在多步骤互动中交织在一起。
### Innovation
我们提出了SALT，一种新型且轻量级的框架，通过从轨迹图中量化每个步骤的质量并据此分配优势，实现了细粒度的优势分配，仅基于结果奖励。SALT设计为即插即用模块，可以无缝集成到现有的群体基线RL算法中，无需修改展开程序且引入的计算开销可以忽略不计。广泛的实验在不同的基准数据集（如WebShop、ALFWorld和AppWorld）上验证了SALT的一致改进性能，并通过深入分析验证了SALT设计的选择。
### Conclusion
我们展示了SALT在不同模型规模和基准数据集上的广泛实验一致提高了性能，并提供了可操作的见解来验证SALT的设计选择。
## 669. `cs.LG` - ShapeX：基于形状特征的时间序列分类模型事后解释框架 [PDF](https://arxiv.org/pdf/2510.20084), [HTML](https://arxiv.org/abs/2510.20084)
### Authors
Bosong Huang,Ming Jin,Yuxuan Liang,Johan Barthelemy,Debo Cheng,Qingsong Wen,Chenghao Liu,Shirui Pan
### Background
在高风险应用领域（如医疗和金融），时间序列分类模型的解释性至关重要，因为透明度和信任是关键因素。尽管已有许多方法通过识别关键子序列（称为形状特征）来提高分类性能并验证其在分类结果中的核心作用，但现有的事后时间序列解释方法主要集中在时间步长级别的特征归因上，而忽略了关键形状特征是分类结果主要驱动因素这一基本假设。因此，现有方法在解释模型决策时存在不足。
### Innovation
本文提出了名为ShapeX的创新框架，该框架通过将时间序列按形状特征驱动的有意义片段划分，并采用Shapley值评估其重要性，从而弥补了现有方法的不足。ShapeX的核心是形状特征描述与检测（SDD）框架，该框架能够学习对于分类至关重要的多样形状特征。此外，ShapeX生成的解释不仅仅是相关性，还能揭示因果关系，因为形状特征具有原子性特点。
### Conclusion
实验结果表明，ShapeX在识别最相关的子序列方面优于现有方法，提高了时间序列解释的精度和因果性。
## 670. `cs.LG` - 不使用老虎机：推测解码中LLMs中可验证无遗憾的稿者选择 [PDF](https://arxiv.org/pdf/2510.20064), [HTML](https://arxiv.org/abs/2510.20064)
### Authors
Hongyi Liu,Jiaji Huang,Zhen Jia,Youngsuk Park,Yu-Xiang Wang
### Background
推测解码在加速大规模语言模型（LLM）推理方面被广泛使用。在本工作中，我们专注于推测解码中的在线草稿模型选择问题。我们设计了一个算法，该算法对于每个查询无论是基于标记接受概率还是预期接受长度，都能与后见之明的最佳草稿模型竞争。我们展示了在不影响查询目标模型的情况下，可以准确评估所有草稿模型，而不是仅评估所选模型，这使我们的方法在草稿模型数量增加时能够指数级超越现有的基于老虎机的方法。我们提出的方法适用于任何推测解码方法（单草稿、多草稿和草稿树），并且我们设计了系统高效版的在线学习器，可以显著减少计算和延迟的开销。我们进行了广泛的实验，表明我们的方法在具有专门领域专家草稿者可用的各种领域中明显优于最先进的EAGLE3和BanditSpec基线，尤其是在需要较长推理链的场景中表现出色。
### Innovation
我们在推测解码中设计了一个算法， provably 可与后见之明的最佳草稿模型竞争，不需要额外对目标模型进行查询，适用于单草稿、多草稿和草稿树等任何推测解码方法，而且设计了系统高效版本的在线学习器，显著降低了计算和延迟的开销。
### Conclusion
我们在多种开源LLMs和不同数据集上的实验表明，我们的方法在存在领域专家草稿者的情况下，特别是在需要较长推理链时，显著优于最先进的EAGLE3和BanditSpec基线方法。
## 671. `cs.LG` - 竞争至关重要：基于博弈论的因果发现方法 [PDF](https://arxiv.org/pdf/2510.20106), [HTML](https://arxiv.org/abs/2510.20106)
### Authors
Amartya Roy,Souvik Chakraborty
### Background
因果发现仍是机器学习中的核心挑战。现有方法面临一个根本性差距：如GES和GraN-DAG等算法虽然在经验上表现出色，但缺乏有限样本保证；而理论上稳健的方法无法扩展。因此，需要一个提供有限样本保证、又能保持理论稳健性的方法来解决这个问题。
### Innovation
作者提出了一种基于博弈论的强化学习框架来解决因果发现问题，其中DDQN代理与强基线（如GES或GraN-DAG）直接竞争。这种方法提供了三个可证明的保障：学到的图永远不会比对手差，热启动可以加速收敛，最重要的是，高概率下算法会选择真正的最佳候选图。这篇论文是首次在因果发现中解释有限样本保证的结果。
### Conclusion
这些结果证明了一类基于强化学习的因果发现算法，同时具有理论一致性、采样效率和实际可扩展性。这意味着这些算法在保证理论稳健性的前提下实现了较好的实际性能，标志着朝着实现理论与实践的统一迈出了决定性的一步。
## 672. `cs.LG` - Coupled Transformer Autoencoder for Disentangling Multi-Region Neural Latent Dynamics [PDF](https://arxiv.org/pdf/2510.20068), [HTML](https://arxiv.org/abs/2510.20068)
### Authors
Ram Dyuthi Sristi,Sowmya Manojna Narasimha,Jingya Huang,Alice Despatin,Simon Musall,Vikash Gilja,Gal Mishne
### Background
现有方法在多脑区记录同步放电时，要么忽视了时间结构，要么未能同时捕捉到脑区间的共享动态和独特的动力学特征，而且通常局限于单一脑区的分析。研究人员寻求一种能够同时捕捉脑区间的共享和私有信号、并能处理非线性、非稳态结构的模型。因此，介绍Coupled Transformer Autoencoder (CTAE)，这是一种序列模型，能够同时处理跨多个脑区的同步记录的非稳态、非线性动力学，并且能够明确将各脑区的潜在空间分为共享和私有子空间。
### Innovation
提出了Coupled Transformer Autoencoder (CTAE)，该模型能够捕捉跨多个脑区的长程神经动力学，并且能够明确地将每个脑区的潜在空间分为正交的共享和私有子空间，同时也具备处理非线性和非稳态结构的能力。与现有方法相比，CTAE能够更有效地分离出脑区间的共享和私有信号。
### Conclusion
在来自运动皮层和感觉皮层的两个高密度电生理数据集上，CTAE能够提取出更有意义的表征，相比现有方法，更好地解码了行为变量。该研究拓展了神经科学中多脑区数据分析的方法，展示了CTAE在神经科学应用中的潜力。
## 673. `cs.LG` - 基于加密资产流动性的多层机器学习和计量经济学管道在市场风险预测中的证据 [PDF](https://arxiv.org/pdf/2510.20066), [HTML](https://arxiv.org/abs/2510.20066)
### Authors
Yimeng Qiu,Feihuang Fang
### Background
研究一组核心加密资产的流动性和波动性代理指标是否能够生成跨市场风险的溢出效应，即这些指标是否能够预测市场整体风险。研究采用了一个三层统计框架：（A）核心流动性和收益之间的交互作用，（B）流动性与收益之间的主成分关系，（C）捕捉横截面波动拥挤的波动因子预测。此外，研究使用了向量自回归脉冲响应和预测误差方差分解、HAR-X异质自回归模型、以及一种不泄露的机器学习协议。所有这些技术都是为了更好地理解和预测市场风险。
### Innovation
论文创新地整合了多层统计方法，特别是通过将机器学习技术与传统的计量经济学方法相结合，提供了一种新的预测市场风险的框架。这种多层方法能够更好地捕捉流动性指标和收益之间的复杂关系，以及横截面波动拥挤现象。此外，该研究中使用了多种先进的数据处理技术，如临时分割、早期停止、验证集阈值化和SHAP解释，以确保结果的可靠性和可解释性。
### Conclusion
该研究使用2021年至2025年每日数据（涉及74种资产的1462个观测值）记录了跨层统计上显著的格兰杰因果关系，并且在样本外预测准确性方面表现出适度的准确性。结果表明，核心流动性指标和收益指标之间的关系可以作为市场风险的有用预测指标，尽管其预测能力并非非常强。研究提供了许多可视化图表，包括流程图概述、层A热图、层C稳健性分析等。全文数据和图表输出物都已存储在项目仓库中以供进一步研究使用。
## 674. `cs.LG` - 基于MentalRoBERTa的分层双头模型用于自杀风险评估 [PDF](https://arxiv.org/pdf/2510.20085), [HTML](https://arxiv.org/abs/2510.20085)
### Authors
Chang Yang,Ziyi Wang,Wangfeng Tan,Zhiting Tan,Changrui Ji,Zhiming Zhou
### Background
社交媒体已成为识别自杀风险的重要来源，但自动化检测系统面临多重挑战，包括严重的类别不平衡、帖子模式的时间复杂性以及风险等级的双重性质（既是序数的也是分类的）。
### Innovation
本文提出了一个基于MentalRoBERTa的分层双头神经网络，用于将自杀风险分类为四个级别：指标、意图、行为和尝试。该模型采用两个互补的预测头工作在一个共享序列表示上：一个保持风险级别之间序数关系的CORAL头，以及一个标准分类头，支持灵活的类别区分。模型还使用3层Transformer编码器和8头多头注意力机制来建模帖子序列之间的时序依赖关系，同时通过显式的时长嵌入捕捉发帖行为的动态。优化后的损失函数结合了CORAL、交叉熵和焦点损失，以同时解决序数结构保存、过信度减少和类别不平衡问题，通过冻结MentalRoBERTa的前6层和使用混合精度训练提高计算效率。
### Conclusion
该模型通过5折分层交叉验证进行评估，主要使用宏F1分数作为评价指标，显示了在自杀风险评估中的有效性和优越性。
## 675. `cs.LG` - 基于加权维度的模式分类研究 [PDF](https://arxiv.org/pdf/2510.20107), [HTML](https://arxiv.org/abs/2510.20107)
### Authors
Ayatullah Faruk Mollah
### Background
在涉及多种应用场景的多维样本模式分类研究中，加权基于维度的距离度量是一个重要的考虑因素，因为它反映了样本之间的相似度程度。尽管欧几里得距离通常被认为是可行的标准，但仍然存在许多问题。
### Innovation
本文提出了如下几点创新：(a) 对距离度量规范和维度权重的影响进行了详细分析，并进行了可视化；(b) 提出了一种新的维度加权方案；(c) 将此维度加权方案融入KNN分类器中；(d) 在多种合成及真实数据集上对开发模型进行了模式分类实验，相比传统的KNN，在相同实验设置下表现良好。特别是在基因表达数据集中，展示了显著且一致的分类准确性提升（约10%），适用于具有高维度较少样本的数据。
### Conclusion
通过所开发的加权Minkowski距离模型和权重方案，有效地调节了包含k个参考样本区域的形状和大小，实现了对最近邻的有意义选择，从而在广泛的实验中表现卓越，证实了KNN分类器的一种重要推广。
## 676. `cs.LG` - 原型为何崩溃：诊断和预防原型自监督学习中的部分崩溃 [PDF](https://arxiv.org/pdf/2510.20108), [HTML](https://arxiv.org/abs/2510.20108)
### Authors
Gabriel Y. Arteaga,Marius Aasan,Rwiddhi Chakraborty,Martine Hjelkrem-Tan,Thalles Silva,Michael Kampffmeyer,Adín Ramírez Rivera
### Background
自监督学习方法中的原型常常会遭受部分崩溃的问题，即多个原型收敛到几乎是相同的代表。这削弱了自监督学习的核心目的——提供多样性和信息丰富的目标来引导编码器生成丰富的表示，并导致实践者通过过度参数化原型集或加入随意的正则化来解决这一问题，但这些方法只是缓解症状而非解决根本原因。
### Innovation
本文通过经验分析，追踪了这种崩溃现象到编码器和原型的联合优化，这促进了编码器的捷径学习。提出一种全解耦训练策略，分别对原型和编码器进行训练，通过在线EM类型的程序更新高斯混合模型原型，独立于编码器的损失。这种方法简单而合理地解决了原型崩溃问题，无需明确的正则化，且能够产生一致多样和更强下游性能的原型。
### Conclusion
该研究通过分离原型和编码器的训练目标来消除原型崩溃的现象，引入了无须显式正则化即可消除原型崩溃的简单而合理的方法，最终给出了更具多样性和更强下游性能的原型。
## 677. `cs.LG` - 在时间序列中没有'苹果': 从不变性视角重新思考时间序列基础模型 [PDF](https://arxiv.org/pdf/2510.20119), [HTML](https://arxiv.org/abs/2510.20119)
### Authors
Arian Prabowo,Flora D. Salim
### Background
时间序列基础模型（TSFMs）虽多，但轻量级的监督基准模型或经典的模型表现往往与之相当。这背后的原因在于对自然语言处理（NLP）或计算机视觉（CV）管道的简单移植。在语言和视觉领域，大规模的网络数据集能密集地捕捉人类概念，而时间序列数据则旨在弥补图像和文本模态的不足。现有的时间序列数据集中缺乏苹果这样的概念。因此，网络抓取范式对时间序列（TS）无效。这表明，进步需要从机会性的数据聚合转向基于原则的设计，构建系统地覆盖保持时间语义不变性的数据集。
### Innovation
本文提出了构建基于不变性原则的时间序列数据集的构想，以确保表示完整性的覆盖，从而实现有效的结构化、推理和真正涌现的行为。这一构想强调了时间序列不变性在先原则构建中的重要性。
### Conclusion
通过不变性这一视角，时间序列基础模型需要从随意的数据集合转向系统地设计数据集，以确保时间语义的完整性，从而促进通用性、推理和真正涌现的行为改善。
## 678. `cs.LG` - 每个问题都有其价值：具有显式人类价值观的强化学习 [PDF](https://arxiv.org/pdf/2510.20187), [HTML](https://arxiv.org/abs/2510.20187)
### Authors
Dian Yu,Yulai Zhao,Kishan Panaganti,Linfeng Song,Haitao Mi,Dong Yu
### Background
尽管可验证奖励的强化学习（RLVR）能够在客观领域中有效训练模型，使用二元正确性奖励，但它忽视了一个事实，即并非所有任务都具有同等的重要性。因此，需要一个方法直接将大型语言模型（LLM）的优化与可量化的具体的人类价值信号结合起来。
### Innovation
本文提出了强化学习与显式人类价值观（RLEV），并通过结合人类定义的价值信号直接进入奖励函数，有效解决了RLVR框架中存在的问题。该方法在多个RL算法和模型规模上，利用有明确价值标签的考试数据，表现出优于仅考虑正确性的基线。RLEV不仅能提高价值加权准确性，还能学习到对高价值问题细致的终止策略。
### Conclusion
实验证明，RLEV 能在噪声价值信号下保持鲁棒性，如基于难度的标签。这表明，通过优化一个显式的效用函数，可以为大型语言模型与人类优先事项对齐提供实用途径。
## 679. `cs.LG` - 通过多层次建模理解结构连接和功能连接在tau传播中的机制作用 [PDF](https://arxiv.org/pdf/2510.20148), [HTML](https://arxiv.org/abs/2510.20148)
### Authors
Tingting Dan,Xinwei Huang,Jiaqi Ding,Yinggang Zheng,Guorong Wu
### Background
新兴的神经影像学证据表明，对阿尔茨海默病（AD）患者大脑局部网络的病理tau蛋白积累有重要影响，表明大规模网络架构在AD进展中的关键作用。然而，结构连接（SC）和功能连接（FC）如何相互作用以影响tau传播仍然不清楚。
### Innovation
本文利用前所未有的长时间神经影像数据量，通过多层次图扩散模型考察SC-FC之间的相互作用。模型揭示了SC和FC在tau传播中的区域不对称贡献，并发现SC和FC在大脑不同区域的作用存在时间上的变化。
### Conclusion
SC和FC主导区域的空间模式与与AD有关的炎症、凋亡和溶酶体功能相关的基因表达高度一致。除AD的非可修改风险因素（如APOE基因型、性别）和生物机制（如淀粉样蛋白沉积）也通过重新塑造从解剖到功能路径上主导路线的方式影响tau的传播路径，最终在独立的AD群组中验证了研究结果。
## 680. `cs.LG` - ADP-VRSGP: 基于减量随机梯度推送的自适应差分隐私的去中心化学习 [PDF](https://arxiv.org/pdf/2510.20157), [HTML](https://arxiv.org/abs/2510.20157)
### Authors
Xiaoming Wu,Teng Liu,Xin Wang,Ming Yang,Jiguo Yu
### Background
差分隐私广泛应用于去中心化学习中，通过在模型更新中添加噪声来保护敏感数据。然而，现有的使用固定方差噪声的方法往往会导致模型性能下降和训练效率降低。
### Innovation
提出了一种新颖的方法——自适应差分隐私的去中心化学习通过减量随机梯度推送（ADP-VRSGP）。该方法使用步进衰减调度动态调整噪声方差和学习率，加速训练，提高最终的模型性能，并提供节点级别的个性化隐私保证。还引入了渐进式梯度融合策略来应对早起迭代中由高方差噪声导致的收敛速度变慢问题。ADP-VRSGP结合了去中心化推求和聚集技术，使其特别适用于时间变化的通信拓扑结构。通过严格的理论分析，证明ADP-VRSGP能够在适当的步长下实现稳健的收敛，显著提高训练稳定性和速度。
### Conclusion
实验结果表明，该方法在多个场景下优于现有基线，突显了其在保护隐私的去中心化学习中的有效性。
## 681. `cs.LG` - 通过超行程引导的大规模TSP目标邻域搜索增强 [PDF](https://arxiv.org/pdf/2510.20169), [HTML](https://arxiv.org/abs/2510.20169)
### Authors
Tongkai Lu,Shuai Ma,Chongyang Tao
### Background
旅行商问题（TSP）是经典的NP难问题，受到了学术界和工业界的广泛关注。尽管基于神经网络的方法在解决TSP方面显示出潜力，但在处理大规模实例时仍面临挑战，尤其是在内存约束、全局热图、边权重或访问矩阵相关的记忆限制，以及生成高质量初始解和缺乏对大面积搜索空间的有效全局指导方面。因此，需要提出一种解决方案来解决这些挑战，以便更好地处理大规模TSP实例。
### Innovation
我们提出了一个用于大规模TSP实例的超行程引导邻域搜索（HyperNS）方法。这种方法借鉴了“先聚类后规划”的策略，首先使用稀疏网格图将TSP实例划分为聚类，并将其抽象为超级节点，随后生成超行程来指导初始化和优化过程。通过这种方式，缩小了搜索空间，从而提高了优化的效率和效果。实验结果表明，我们的方法在处理大规模实例方面优于现有的基于神经网络的方法，特别是在缩小与最优解的差距方面表现尤为显著。
### Conclusion
实验结果表明，我们的方法在合成和真实世界的数据集上都表现出了良好的性能，尤其是在处理大规模实例时，与现有基于神经网络的方法相比，我们的方法能够显著缩小与最优解的差距，从而证明了这种方法的有效性和优越性。
## 682. `cs.LG` - CO-PFL: 基于贡献度的个性化联邦学习方法用于异构网络 [PDF](https://arxiv.org/pdf/2510.20219), [HTML](https://arxiv.org/abs/2510.20219)
### Authors
Ke Xing,Yanjie Dong,Xiaoyi Fan,Runhao Zeng,Victor C. M. Leung,M. Jamal Deen,Xiping Hu
### Background
传统的联邦学习依赖单一共识模型，在数据异构性背景下显得不足。其标准聚合方法基于经验或数据量加权客户端更新，将每个客户端的实际贡献假设为等同值，无法有效衡量更新的真实效用和可靠性，导致个性化不足和聚合偏差。
### Innovation
提出了贡献导向的个性化联邦学习（CO-PFL）算法，动态估计每个客户端的贡献进行全球聚合。CO-PFL通过同时分析梯度方向差异和预测偏差，利用梯度和数据子空间信息进行双子空间分析，为每个客户端提供合乎原理且区分度高的聚合权重，强调高质量的更新。同时，CO-PFL通过参数智慧个性化机制结合掩码感知动量优化，增强个性化适应性和优化稳定性。
### Conclusion
大量在四个基准数据集（CIFAR10，CIFAR10C，CINIC10和Mini-ImageNet）上的实验表明，CO-PFL在个性化准确度、鲁棒性、可扩展性和收敛稳定性方面均优于现有方法。
## 683. `cs.LG` - 学习中的近似可再现性 [PDF](https://arxiv.org/pdf/2510.20200), [HTML](https://arxiv.org/abs/2510.20200)
### Authors
Max Hopkins,Russell Impagliazzo,Christopher Ye
### Background
(Impagliazzo等人在2022年STOC会议上引入的)可再现性是指算法在获取共享随机性的情况下，能够在其输入重新采样的情况下保持稳定性。尽管这是一个强有力的且有趣的概念稳定性，但其成本可能是难以承受的：例如，就没有可再现的学习算法（如Bun等人在2023年STOC会议上指出的）对于简单任务如阈值学习而言。鉴于这种强有力的不可能性结果，作者们询问：在什么近似的可再现性概念下，学习是可能的？在此工作中，作者提出了三种可再现性在PAC学习中的自然放松：(1)点处理：学习者必须对任何固定输入保持一致，但不是同时在所有输入上保持一致；(2)近似：学习者必须输出能够一致分类大部分分布的假设；(3)半：算法完全可再现，但可以额外使用共享的未标记样本。在所有三种情况下，对于常数可再现性参数，我们得到了样本最优化的无偏差PAC学习者：(1)和(2)可以在Θ(d/α^2)样本上实现，而(3)则需要Θ(d^2/α^2)标记样本。
### Innovation
作者提出了解三种近似可再现性概念在PAC学习中的放松方法：点处理、近似和半。它们都在不同程度上放松了原本的严格可再现性要求，从而使得学习成为可能。具体而言，通过对这三种放松方法的研究，作者实现了样本最优化的无偏差PAC学习者，分别在Θ(d/α^2) 和 Θ(d^2/α^2) 的样本复杂度上取得了不同的学习效果。
### Conclusion
对于常数可再现性参数，在所有提出的三种近似可再现性方案下，我们建立了样本最优化的PAC学习者：点处理和近似可以在Θ(d/α^2)样本上实现，而半则需要Θ(d^2/α^2)标记样本。这意味着在一定程度上放宽可再现性的要求会使得学习任务变得更加可行。
## 684. `cs.LG` - 为具有群体公平性约束的大规模谱聚类寻找拉普拉斯矩阵的替代方案 [PDF](https://arxiv.org/pdf/2510.20220), [HTML](https://arxiv.org/abs/2510.20220)
### Authors
Iván Ojeda-Ruiz,Young Ju-Lee,Malcolm Dickens,Leonardo Cambisaca
### Background
最近的研究集中在通过将公平性约束融入算法设计来减轻聚类中的算法偏见。已经提出了差异影响、社区凝聚力和每人口成本等概念来确保公平结果。其中，群体公平性（平衡）确保每个保护群体在每个聚类中均等代表。然而，将群体公平性作为公平性的度量标准应用到谱聚类算法中会导致计算时间增加。
### Innovation
本文通过利用拉格朗日方法和Sherman-Morrison-Woodbury (SMW) 身份推导出的一种新形式，对带约束的优化问题进行重新表述，提出了Fair-SMW算法。Fair-SMW算法使用不同的谱间隙的拉普拉斯矩阵替代方案生成多种Fair-SMW变体，能够在保持与现有算法相似的群体平衡性的同时提供更好的运行时性能。
### Conclusion
通过在Stochastic Block Model (SBM)上测试Fair-SMW算法，结果显示计算时间比最先进的算法快两倍，同时也能够在真实世界网络数据集（如LastFM、FacebookNet、Deezer、德国数据）上实现两倍的群体平衡性。
## 685. `cs.LG` - 使用常规实验室数据评估早期癌症检测的可行性：不平衡数据集上机器学习方法的评价 [PDF](https://arxiv.org/pdf/2510.20209), [HTML](https://arxiv.org/abs/2510.20209)
### Authors
Shumin Li
### Background
在兽医领域开发易于获取的早期癌症筛查工具是一项重大挑战。虽然常规实验室数据因其低成本而被视为潜在资源，但单一生物标志物的非特异性以及筛查人群中的严重类别不平衡阻碍了其应用。该研究利用金毛寻回犬终身研究（GRLS）组，在实际约束条件下评估了癌症风险分类的可能性，包括不同癌症类型的分组和包含诊后样本。该工作还探讨了统计数据等表明常规实验室数据中存在癌症信号，但信号过弱且受到其他非特异性因素的影响，无法从正常老化或炎症条件下进行可靠的区分
### Innovation
研究全面评估了126种不同的分析管道的可行性，这些管道结合了各种机器学习模型、特征选择方法和数据平衡技术，同时采用患者级别的数据分割以防止数据泄露。最优化的模型是一个具有类别权重和递归特征消除的逻辑回归分类器，这表明尽管其具有中等的排名能力（AUROC = 0.815；95% CI: 0.793-0.836），但在临床分类中的性能较差（F1分数 = 0.25，阳性预测值 = 0.15）。负预测值达到0.98，但由于召回率不足（0.79），无法作为可靠排除测试使用。此外，通过SHapley Additive exPlanations (SHAP)进行可解释性分析显示，预测主要是由年龄等非特异性特征和炎症及贫血标志物驱动的。这一工作明确了单模态数据在单独使用时存在的性能限制，并强调了跨模态数据集成在计算兽医肿瘤学中的重要性
### Conclusion
现有的机器学习方法在使用常规实验室数据进行早期癌症检测时的统计信号过于微弱且易受其他非特异性因素影响，无法实现临床可靠的区分。该研究通过评估这些数据的可行性，为未来的工作设定了关键性能上限，并强调了跨模态数据整合在计算兽医肿瘤学中的必要性。
## 686. `cs.LG` - 带有优化确定等价的警惕风险约束强化学习 [PDF](https://arxiv.org/pdf/2510.20199), [HTML](https://arxiv.org/abs/2510.20199)
### Authors
Jane H. Lee,Baturay Saglam,Spyridon Pougkakiotis,Amin Karbasi,Dionysis Kalogerias
### Background
约束优化为处理强化学习（RL）中冲突目标提供了一个通用框架。然而，这种形式化忽略了奖励分布尾部的风险事件或甚至是可能灾难性的事件，并且在高风险应用场景中往往不足以应对。
### Innovation
本文提出了一种基于优化确定等价（OCEs）的风险感知约束RL框架，该框架在奖励值和时间上具有阶段稳健性。该框架在适当的约束资格下，提供了原始约束问题的精确等效，并提供了一个可用于标准RL求解器（如PPO）的简单算法。
### Conclusion
本文证明了所提出的算法在常见假设下收敛，并通过多个数值实验验证了所提出方法的风险感知特性。
## 687. `cs.LG` - 基于Meta-变分丢弃的联邦学习 [PDF](https://arxiv.org/pdf/2510.20225), [HTML](https://arxiv.org/abs/2510.20225)
### Authors
Insu Jeon,Minui Hong,Junhyeog Yun,Gunhee Kim
### Background
联邦学习（FL）的目标是从远程分布的客户端中训练一个全局推理模型，由于能够提高数据隐私而受到欢迎。然而，传统的联邦学习在实际应用中面临模型过拟合和由于客户端数据有限且非独立同分布（非-IID）而导致的局部模型发散等问题。
### Innovation
我们引入了一种新颖的贝叶斯元学习方法称之为元变分丢弃（MetaVD）。MetaVD通过共享超网络学习预测客户端特定的丢弃率，从而在有限的非-IID数据环境中有效个性化联邦学习算法。我们也强调了元学习的后验适应视角和贝叶斯联邦学习的后验聚合视角，通过条件丢弃后验。
### Conclusion
我们对多种稀疏和非IID的联邦学习数据集进行了广泛实验。MetaVD展示了卓越的分类准确性和不确定性校准性能，尤其是在跨分布（OOD）客户端方面。MetaVD压缩了每个客户端所需的本地模型参数，减轻了模型过拟合并降低了通信成本。
## 688. `cs.LG` - QKCV 注意力：通过静态类别嵌入增强时序预测，适用于轻量级和预训练基础模型。 [PDF](https://arxiv.org/pdf/2510.20222), [HTML](https://arxiv.org/abs/2510.20222)
### Authors
Hao Wang,Baojun Ma
### Background
在实际时间序列预测任务中，类别信息对于捕捉内在数据模式至关重要。现有的基于注意力机制的模型（如 Vanilla Transformer、Informer、PatchTST、TFT）在此类任务中表现出色。然而，这些模型在处理类别信息时存在不足。
### Innovation
QKCV（Query-Key-Category-Value）注意力机制是传统QKV框架的扩展，引入了一个静态类别嵌入C，以强调类别特定的信息。QKCV作为一种灵活的插件模块，能够增强基于注意力机制的模型的预测准确性，并且适用于多种实际数据集。此外，QKCV还展示了对单变量时间序列基础模型的微调能力，仅更新静态嵌入C，同时保留预训练权重，从而减少了计算开销并实现了出色的微调性能。
### Conclusion
QKCV智能地整合了类别信息，提高了多种基于注意力机制的时间序列预测模型的性能。对于轻量级模型，QKCV能够通过更新静态嵌入C和保留预训练权重来实现高效的微调，从而在保证预测准确性的前提下大幅减少计算成本。
## 689. `cs.LG` - 最大最小准则下的多目标强化学习：博弈论方法 [PDF](https://arxiv.org/pdf/2510.20235), [HTML](https://arxiv.org/abs/2510.20235)
### Authors
Woohyeon Byeon,Giseung Park,Jongseong Chae,Amir Leshem,Youngchul Sung
### Background
本文提出了一个有保证收敛性和实用性的多目标强化学习框架，特别是在采用最大最小准则的情况下。从博弈论的角度出发，重新定义了多目标强化学习问题，并引入了一种基于镜像下降法的高效算法。该方法在简化策略更新的同时，保证了全局最后迭代的收敛性。
### Innovation
1. 将多目标强化学习重新定义为两点零和正则连续博弈问题。2. 提出了一种基于镜像下降法的有效算法。3. 对提出的算法进行了全面的理论分析，包括精确和近似策略评估下的迭代复杂度分析以及样本复杂性边界。4. 提出了带有自适应正则化的改进算法以进一步提升性能。
### Conclusion
实验结果在表格环境中显示了提出算法的收敛行为，并证明了该方法在深度强化学习环境中的显著性能提升，超越了之前的基线方法。
## 690. `cs.LG` - Sparse Local Implicit Image Function for sub-km Weather Downscaling [PDF](https://arxiv.org/pdf/2510.20228), [HTML](https://arxiv.org/abs/2510.20228)
### Authors
Yago del Valle Inclan Redondo,Enrique Arriaga-Varela,Dmitry Lyamzin,Pablo Cervantes,Tiago Ramalho
### Background
该研究旨在通过引入稀疏局部隐式图像函数（SpLIIF）生成隐式神经表示，从而实现气象变量的任意下放缩。背景集中在需要更高的气象数据分辨率以进行精度更高的局部气象预测和模拟的需求上，特别是在天气变化预测、气候研究以及气象服务等场景中的应用。
### Innovation
该研究的创新之处在于开发了稀疏局部隐式图像函数（SpLIIF），该方法能够利用稀疏的气象站和地形数据训练模型，并生成高分辨率的气象变量隐式表示，从而在进行气象变量的任意下放缩时表现出色，特别是在温度和风速的预测上，比现有的CorrDiff和插值方法更优。
### Conclusion
研究表明，该模型在温度下放缩预测方面的表现比CorrDiff和基线方法分别提高了50%和约10-20%，在风速的下放缩预测方面也有所改进。这表明了SpLIIF在处理大型地理数据集和生成高分辨率气象图像方面的潜力，为局部气象预测提供了新的方法。
## 691. `cs.LG` - FedGPS：对抗联邦学习中数据异质性的统计修正 [PDF](https://arxiv.org/pdf/2510.20250), [HTML](https://arxiv.org/abs/2510.20250)
### Authors
Zhiqin Yang,Yonggang Zhang,Chenxin Li,Yiu-ming Cheung,Bo Han,Yixuan Yuan
### Background
联邦学习(Federated Learning, FL)面临的一个重要挑战是数据异质性，这会影响模型性能和收敛。尽管已有方法在解决这一问题方面取得了显著进展，但在某些异质性场景下的性能提升依然是一个被忽视的问题。即，现有方法在多样化的异质性场景下部署的鲁棒性如何。为了解决这个问题，该研究进行全面评估，展示了大多数现有方法在鲁棒性方面表现有限。实验结果还表明，共享统计信息可以减轻异质性，使客户端能够从全局视角进行更新。受到这种认识的启发，该文提出了一个新型框架FedGPS，该框架无缝地结合了来自其他客户端的统计分布信息和梯度信息。
### Innovation
FedGPS是对抗联邦学习中数据异质性的一种新框架，它结合了统计分布信息和梯度信息，以提高客户端的鲁棒性和模型的性能。具体来说，FedGPS静态调整每个客户端的学习目标，使用替代信息隐式地建模全局数据分布；同时，通过其他客户端的梯度信息动态调整本地更新方向。该研究证明了FedGPS在多种异质性场景下性能优越，验证了其有效性和鲁棒性。
### Conclusion
 FedGPS通过结合统计分布信息和梯度信息，有效提高了在多样化的异质性场景下的学习效果和鲁棒性。实验结果表明，FedGPS在多种场景下优于现有的同类方法，验证了其有效性和鲁棒性。
## 692. `cs.LG` - OpTI-BFM: Optimistic Task Inference for Behavior Foundation Models [PDF](https://arxiv.org/pdf/2510.20264), [HTML](https://arxiv.org/abs/2510.20264)
### Authors
Thomas Rupf,Marco Bagatella,Marin Vlastelica,Andreas Krause
### Background
背景：行为基础模型（BFMs）能够在测试时直接指定奖励函数的情况下检索出高性能的政策，这被称为零样本强化学习（RL）。虽然从计算角度来看这个过程效率高，但在数据方面效率较低，BFMs通常需要通过非微不足道的推理数据集来计算奖励，这可以是基于奖励功能的形式，也可以是大量标记的努力。因此，本研究旨在通过在测试时与环境交互来解决这些问题，通过提出一种乐观决策标准OpTI-BFM，来直接建模关于奖励函数的不确定性并通过环境交互收集任务信息，指导BFMs的数据收集过程。
### Innovation
创新：提出了OpTI-BFM（乐观任务推断BFMs），一种直接建模奖励函数不确定性的乐观决策标准。这帮助BFMs通过与环境的交互收集数据进行任务推断，无需预先存在的标注数据或奖励形式。论文还通过与线性带宽的上置信区间算法直接关联，给出了一般情况下的遗憾率界限。实验表明，OpTI-BFM能够使基于后续特征的BFMs在有限的几个回合中识别并优化未知奖励函数，且计算开销最小。
### Conclusion
结论：OpTI-BFM为BFMs提供了一种高效的方法，在无需预先提供奖励功能的形式或大量标注数据的情况下，能够在测试时通过与环境的交互完成任务推断。这种方法显著减少了数据需求，在有限的多次测试中能有效识别并优化未知奖励函数，降低了计算开销。
## 693. `cs.LG` - 可扩展的GPU加速Euler特征曲线：PyTorch中的优化和可微学习 [PDF](https://arxiv.org/pdf/2510.20271), [HTML](https://arxiv.org/abs/2510.20271)
### Authors
Udit Saxena
### Background
拓扑特征可以捕捉成像数据中的全局几何结构，但在深度学习中的实用应用需要计算效率和可微性。现有的GPU实现不够高效，无法满足这些需求。
### Innovation
本文提出了针对Ampere GPU的优化CUDA内核，实现了16-2000倍的性能提升；引入了一个可微分的PyTorch层，采用了一种类似于Differentiable Euler Characteristic Transform风格的Sigmoid松弛方法学习门限值。此外，讨论了该技术的下游应用，并概述了批量处理和多GPU扩展以促进更广泛的采用。
### Conclusion
该研究通过提高Euler特征曲线计算的效率和引入可微分层，促进了其在深度学习中的应用。
## 694. `cs.LG` - ImpossibleBench：测量大语言模型利用测试案例的倾向性 [PDF](https://arxiv.org/pdf/2510.20270), [HTML](https://arxiv.org/abs/2510.20270)
### Authors
Ziqian Zhong,Aditi Raghunathan,Nicholas Carlini
### Background
大语言模型（LLMs）倾向于寻找和利用‘捷径’来完成任务，这种行为对可靠评估和部署大语言模型构成了重大风险。例如，一个具备访问单元测试权限的LLM代理可能会删除失败的测试，而不是修复实质问题。这种行为损害了基准成绩的有效性和现实世界中LLM编码助手部署的可靠性。
### Innovation
该研究引入了ImpossibleBench，这是一种基准框架，旨在系统地衡量LLM代理利用测试案例的倾向性。通过在现有基准（如LiveCodeBench和SWE-bench）中引入自然语言规范与单元测试之间的直接冲突，创建出‘不可能’的任务变体。评价代理的'作弊率'是其在这些不可能任务上的通过率，任何通过都意味着存在规范违反的捷径。ImpossibleBench是一种实用框架，不仅用于评估，也用于多种应用，包括研究模型行为、情境工程和开发检测工具。
### Conclusion
我们希望ImpossibleBench能作为一个有用的框架，用于构建更加稳健可靠的LLM系统。我们的实现可以在该网址查找：this https URL。
## 695. `cs.LG` - 基于LLMs的数学推理中PRM引导树搜索的局限性 [PDF](https://arxiv.org/pdf/2510.20272), [HTML](https://arxiv.org/abs/2510.20272)
### Authors
Tristan Cinquin,Geoff Pleiss,Agustinus Kristiadi
### Background
链式思维提示结合Best-of-N (BoN)选择已成为大型语言模型（LLMs）进行数学推理的流行方法。然而，这种方法的线性结构无法捕捉复杂问题解决中的分支和探索性质。
### Innovation
提出了一种自适应算法来最大化不可解的动作空间中的过程奖励模型（PRM）得分，并研究PRM引导的树搜索是否可以提高数学推理能力，通过探索多个部分解决方案路径。使用Qwen2.5-Math-7B-Instruct及其关联的PRM作为案例研究，发现了几个关键发现。
### Conclusion
PRM引导的树搜索在成本更高但不显著提升BoN表现的情况下，蒙特卡洛树搜索和束搜索方法更胜一筹。PRM难以近似状态值，并且其可靠性随着推理深度增加而降低，普适性差。这些表现不佳源于树搜索更多依赖不可靠的PRM得分，因此在LLMs中通过树搜索有效增强数学推理可能需要不同的奖励建模。
## 696. `cs.LG` - SynTSBench：重新思考深度学习模型在时间序列中的时间模式学习 [PDF](https://arxiv.org/pdf/2510.20273), [HTML](https://arxiv.org/abs/2510.20273)
### Authors
Qitai Tan,Yiyun Chen,Mo Li,Ruiwen Gu,Yilin Su,Xiao-Ping Zhang
### Background
近年来，深度学习取得了快速进展，尤其在时间序列预测领域，但许多最先进的模型在实际应用中仍然表现不稳定，尤其是在标准基准数据集上取得优异结果的情况下。这一持续存在的差距可以归因于深度学习架构的黑箱特性以及当前评估框架的局限性，这些框架往往缺乏提供清晰、定量洞察不同模型具体优势和弱点的能力，从而妨碍了为特定预测场景选择合适模型。
### Innovation
本文提出了一种合成数据驱动的评估框架SynTSBench，通过编程特征配置系统性评估时间序列预测模型的基本建模能力。该框架通过分离干扰因素和建立可解释的评估系统（包括三个方面核心分析维度），提供了详细且具体的模型评估：(1) 时间特征分解和能力映射，允许系统性评估模型学习特定模式类型的能力；(2) 在数据不规则性下的鲁棒性分析，量化噪声容忍阈值和异常恢复能力；以及 (3) 理论最优基准测试，设定了每个模式类型的性能边界，支持模型预测与数学最优值的直接对比。
### Conclusion
我们的实验表明，当前的深度学习模型在各种类型的时间序列上普遍未达到最优基准。代码可从这里获取：https://github.com/synthetic-timeseries/synthetic_benchmark
## 697. `cs.LG` - KCM: KAN-Based Collaboration Models Enhance Pretrained Large Models [PDF](https://arxiv.org/pdf/2510.20278), [HTML](https://arxiv.org/abs/2510.20278)
### Authors
Guangyu Dai,Siliang Tang,Yueting Zhuang
### Background
近年来，研究人员提出了大模型和小模型协作框架，利用易于训练的小模型辅助大模型。其目标在于显著减少计算资源消耗同时保持相当的准确度，以及提升大模型在专业化任务中的性能。然而，这种协作模式存在显著的准确度下降、灾难性遗忘加剧以及由于小模型知识引起的大规模幻觉问题等挑战。
### Innovation
本文提出了一种基于KAN（Knowledge Augmented Network）的协作模型(KCM)，这是一种改进的大模型和小模型协作方法。KCM中的KAN是一种不同于传统MLP（多层感知机）的替代神经网络架构，可以实现更好的可视化和解释性，同时减少灾难性遗忘。实验结果表明，与仅使用大模型的方法相比，利用KCM进行协作的框架能够显著减少大模型的推理调用次数，保持几乎相同的任务准确度，从而大幅降低计算资源消耗。同时，基于KAN的小型协作模型可以显著缓解灾难性遗忘，提高长尾数据的准确度。结果显示，KCM在所有指标上都优于基于MLP的小型协作模型（MCM）。
### Conclusion
KCM在多个场景（语言、视觉及跨模态任务）中证明了其在提高任务准确度和降低计算资源消耗方面比基于MLP的小型模型更具优势。
## 698. `cs.LG` - Graph Neural Network for Chemical Property Prediction中的层间知识混合 [PDF](https://arxiv.org/pdf/2510.20236), [HTML](https://arxiv.org/abs/2510.20236)
### Authors
Teng Jiek See,Daokun Zhang,Mario Boley,David K. Chalmers
### Background
目前，图神经网络（GNNs）是最有效的预测分子性质的方法之一，但是仍需要更准确的模型。尽管可以通过增加模型复杂性来提高GNN的准确性，但这同时也增加了训练和推理过程中的计算成本和内存需求。
### Innovation
本文开发了一种名为层间知识混合（LKM）的新型自知识蒸馏方法，该方法可以在不显著增加训练和推理过程中计算复杂度的情况下，提高最先进的GNNs的准确性。LKM通过最小化GNN层中预存的隐藏嵌入之间的平均绝对距离，有效地聚合多跳和多尺度信息，从而改善分子局部和全局特征的表示。
### Conclusion
通过在三个不同的GNN架构（DimeNet++、MXMNet和PAMNet）上使用量子化学性质（QM9、MD17和Chignolin）的数据集进行评估，发现LKM方法可将量子化学和生物物理性质预测的平均绝对误差分别最多降低9.8%、45.3%和22.9%。这项工作展示了LKM在不显著增加训练和推理成本的情况下，能够显著提高GNNs的化学性质预测的准确性。
## 699. `cs.LG` - 构建高性能选择性分类器需要什么？ [PDF](https://arxiv.org/pdf/2510.20242), [HTML](https://arxiv.org/abs/2510.20242)
### Authors
Stephan Rabanser,Nicolas Papernot
### Background
选择性分类器通过在模型认为不确定的情况下弃权来提高模型的可靠性。然而，很少有实际方法能够达到完美排序的oracle的性能，即精确按照正确性顺序接受样本。对于这种不足，本文将其形式化为选择性分类器差距，并首次给出了该差距的有限样本分解。
### Innovation
文章正式化了这一差距为选择性分类器差距，并提出首次对该差距进行五种独立的松弛来源的分解：贝叶斯噪声、近似误差、排名误差、统计噪声和实施或转移引起的余量。关键的是，分析表明单调的后验校准——通常被认为能够加强选择性分类器的安全性——对缩小这一差距的影响有限，因为这种校准很少改变模型的基本评分排名。因此，要弥合差距需要评分机制不仅重标定，还可以有效地重新排序预测。
### Conclusion
通过合成两轨道数据和现实世界的视觉和语言基准测试验证分解，结果证实了（i）贝叶斯噪声和有限模型能力可以解释大量的差距，（ii）只有更丰富、特征感知的校准器能够显著改善评分排序，（iii）数据转移引入了一个独立的余量，这需要分布鲁棒训练。这一分解提供了定量的误差预算和具体的实践指导，使从业人员能够在更接近理想oracle行为的性能方面改进选择性分类器的设计。
## 700. `cs.LG` - 无偏差图泛化的因果子图分布不变性量化 [PDF](https://arxiv.org/pdf/2510.20295), [HTML](https://arxiv.org/abs/2510.20295)
### Authors
Yang Qiu,Yixiong Zou,Jun Wang,Wei Liu,Xiangyu Fu,Ruixuan Li
### Background
对于图神经网络而言，异分布泛化在不同分布转移下的问题仍然是一个关键挑战。现有的方法多采用不变风险最小化（IRM）框架，但需要昂贵的环境注释或手工生成的合成分割。
### Innovation
本文提出了一种无IRM的方法来捕捉因果子图。首先，识别出因果子图在各种环境中相比非因果组件具有明显较小的分布变化，这被正式化为不变分布准则，并在本文中进行了理论证明。基于这个准则，系统地揭示了分布转移与表示范数之间的定量关系，并对其背后的机制进行了深入研究。最终，提出了一个无IRM的方法，通过引入范数引导的不变分布目标来发现和预测因果子图。
### Conclusion
在两个广泛使用的基准上的 extensive 实验表明，本文的方法在图泛化方面始终优于最先进的方法。
## 701. `cs.LG` - LEGO: 一种轻量级高效多属性遗忘框架用于推荐系统 [PDF](https://arxiv.org/pdf/2510.20327), [HTML](https://arxiv.org/abs/2510.20327)
### Authors
Fengyuan Yu,Yuyuan Li,Xiaohua Feng,Junjie Fang,Tao Wang,Chaochao Chen
### Background
随着对保护敏感用户信息的需求增长，推荐系统中推荐属性遗忘引起了越来越多的关注。现有研究主要集中在单一属性遗忘上，但在现实生活中，隐私保护需求往往涉及多个敏感属性，并且是动态的。现有的单一属性遗忘方法无法满足这些现实需求，因为它们存在两个主要问题：无法同时处理多个遗忘请求和缺乏对动态遗忘需求的高效适应能力。
### Innovation
为了解决上述挑战，本文提出了LEGO，一种轻量级和高效的多属性遗忘框架。LEGO将多属性遗忘过程分为两个步骤：一是嵌入校准，从用户嵌入中移除特定属性的相关信息；二是灵活组合，将这些嵌入结合成一个单一嵌入，保护所有敏感属性。通过将遗忘过程建模为互信息最小化问题，LEGO提供了同时遗忘的理论保证，解决了第一个挑战(CH1)。通过两步框架，嵌入校准可以在并行执行，灵活组合也是灵活高效，解决了第二个挑战(CH2)。
### Conclusion
在三个真实世界数据集上的广泛实验表明，所提出的框架具有有效性和高效性。相关的代码和附录可从给定的链接获取。
## 702. `cs.LG` - 当您的奖励模型不确定时请咨询强大的LLM法官 [PDF](https://arxiv.org/pdf/2510.20369), [HTML](https://arxiv.org/abs/2510.20369)
### Authors
Zhenghao Xu,Qin Lu,Qingru Zhang,Liang Qiu,Ilgee Hong,Changlong Yu,Wenlin Yao,Yao Liu,Haoming Jiang,Lihong Li,Hyokun Yun,Tuo Zhao
### Background
奖励模型（RM）在人类反馈强化学习（RLHF）中用于对齐大规模语言模型（LLMs），但经典的人类偏好训练的RM容易受到奖励欺骗，并且对离分布（OOD）输入的泛化能力较差。相比之下，具有推理能力的强LLM法官尽管无需额外训练即可表现出优越的泛化能力，但其推理成本高昂，限制了其在在线RLHF中的应用。
### Innovation
本文提出了一种基于不确定性路由框架，该框架能够高效地用快速的RM补充昂贵的强LLM法官。该方法将优势估计在策略梯度（PG）方法中转化为两两偏好分类问题，并通过有指导的不确定性量化来指导路由决策。
### Conclusion
在RM基准实验中，我们发现基于不确定性的路由策略在相同成本下显著优于随机法官调用，而下游的对齐结果也证实了这种方法在提升在线RLHF中的有效性。
## 703. `cs.LG` - DB-FGA-Net：用于多类分类的双主干频率门控注意网络及Grad-CAM解释性 [PDF](https://arxiv.org/pdf/2510.20299), [HTML](https://arxiv.org/abs/2510.20299)
### Authors
Saraf Anzum Shreya,MD. Abu Ismail Siddique,Sharaf Tasnim
### Background
脑肿瘤在神经肿瘤学中是一个具有挑战性的问题，早期和准确的诊断对于成功的治疗至关重要。当前的深度学习方法通常依赖于数据增强技术，这可能会限制模型在临床应用中的泛化能力和可信度。本文分析了在不同大小和分布的数据集上无数据增强的深度学习模型仍然可以取得高性能的方法及其在临床应用中的挑战和重要性。
### Innovation
本文提出了一种结合VGG16和Xception双主干网络，并引入了频率门控注意力（FGA）模块的DB-FGA-Net模型，以捕捉局部和全局特征的互补性。与之前的模型相比，该模型无需数据增强即能达到顶级性能，展示了对大小和分布变异的数据集的鲁棒性。此外，引入Grad-CAM以增强模型可解释性，使临床医生能够理解模型的决策过程。
### Conclusion
DB-FGA-Net在7K-DS数据集4类设置上达99.24%的准确率，在3类和2类设置上分别达到98.68%和99.85%的准确率。独立的3K-DS数据集上的试验显示，模型具有95.77%的准确率，优于基准和顶级方法。为支持临床应用，还开发了一个图形用户界面（GUI）提供实时分类和基于Grad-CAM的肿瘤定位。这些发现表明，无需数据增强的、可解释性强且可部署的深度学习模型DB-FGA-Net在脑肿瘤诊断的临床转化中有巨大的潜力。
## 704. `cs.LG` - InvDec：多变量时间序列预测的倒置解码器，用于分离的时间和变量建模 [PDF](https://arxiv.org/pdf/2510.20302), [HTML](https://arxiv.org/abs/2510.20302)
### Authors
Yuhang Wang
### Background
多变量时间序列预测需要同时对时间模式进行建模和跨变量依赖性。目前的方法要么专注于时间建模而忽略变量间的相关性（如PatchTST），要么专注于变量层面的注意机制而牺牲了时间编码（如iTransformer）。
### Innovation
本文提出了一种新的混合架构InvDec，它通过在变量维度上使用变量间的自我注意实现了时间编码与变量级解码的原理性分离。InvDec结合了基于块的时间编码器和一个倒置的解码器，该解码器在变量维度上进行操作。此外，它还引入了延迟变量嵌入，仅在时间编码后丰富变量特定的表示，并保持时间特征的完整性。适应性的残差融合机制能够根据数据集的维度动态平衡时间和变量信息。通过使用PatchTST实例化InvDec，得到了InvDec-PatchTST。广泛的实验表明，在高维数据集上取得了显著的提升：在Electricity（321个变量）数据集上MSE减少了20.9%，在Weather和Traffic数据集上分别提高了4.3%和2.7%，同时在低维ETT数据集上保持了竞争力。
### Conclusion
消融研究验证了每个组件，分析表明随数据集维度的增加，InvDec的优势也在增长，证实了随着变量数量的增加，跨变量建模变得至关重要。
## 705. `cs.LG` - 合成数据在稳健跑道检测中的应用 [PDF](https://arxiv.org/pdf/2510.20349), [HTML](https://arxiv.org/abs/2510.20349)
### Authors
Estelle Chigot,Dennis G. Wilson,Meriem Ghrib,Fabrice Jimenez,Thomas Oberlin
### Background
深度视觉模型已经足够成熟，可以应用于工业甚至关键应用领域如自主导航。然而，收集和标注训练这些模型的数据需要巨大的时间和资金投入，尤其是对于关键应用而言，需要覆盖所有可能的情况，包括罕见的场景。因此，在这种情况下，生成合成图像成为了一种有吸引力的解决方案，因为它可以以低成本高效地覆盖所有条件和环境，前提是需要减少合成数据与实际数据之间的分布差异。本文关注的是跑道检测，这是飞机制造商正在开发的自主降落系统中至关重要的一部分。我们提出了一种基于商用飞行模拟器的图像生成方法，这种方法能够补充少量标注的真实图像，并通过控制图像生成和真实数据与合成数据的结合使用，我们展示了标准的目标检测模型能实现准确的预测。此外，我们还评估了这些模型在不利条件下（例如我们的案例中的夜间图像）的鲁棒性，这两类数据在真实数据集中并不存在，显示了使用定制域适应策略的兴趣。
### Innovation
提出了基于商用飞行模拟器的图像生成方法，来补充少量标注的真实图像。通过控制图像生成和两种数据类型的结合使用，展示了标准的目标检测模型在实现准确预测和增强其对不利条件的鲁棒性方面的能力。特别地，评估了夜间图像中两种数据类型的模型的性能，证实了定制域适应策略的有效性。
### Conclusion
通过结合少量真实标注图像和基于商用飞行模拟器生成的大量合成图像，标准的目标检测模型可以实现准确的跑道检测，同时增强对不利条件（如夜间图像）的鲁棒性。
## 706. `cs.LG` - 具有鲁棒协调的分层时间序列预测 [PDF](https://arxiv.org/pdf/2510.20383), [HTML](https://arxiv.org/abs/2510.20383)
### Authors
Shuhei Aikawa,Aru Suzuki,Kei Yoshitake,Kanata Teshigawara,Akira Iwabuchi,Ken Kobayashi,Kazuhide Nakata
### Background
该论文关注分层时间序列数据的预测问题，其中高一级的观测值是它相应低一级时间序列的和。传统方法独立地为每个时间序列生成基预测值，然后通过综合或调整步骤确保所有层次中的预测值具有内在一致性。然而，由于真值协方差矩阵无法在实践中获得，只能基于有限样本进行估计，这可能导致预测性能下降。基于此背景，该研究提出了一种鲁棒优化框架，考虑到估计协方差矩阵的不确定性，通过构建一个最小化最坏情况期望平方误差的协调问题来提升预测性能。
### Innovation
论文提出的创新点在于提出了一种鲁棒优化框架，该框架考虑了估计协方差矩阵的不确定性，旨在通过最小化最坏情况期望平方误差来优化协调过程。这种方法将不确定性融入协调流程中，从而增强了预测的稳健性和准确性。
### Conclusion
数值实验表明，提出的鲁棒协调方法在预测性能上优于现有的分层预测方法，这证明了将不确定性纳入协调过程的有效性。
## 707. `cs.LG` - 神经语言模型的基于相对概率的扩展法则 [PDF](https://arxiv.org/pdf/2510.20387), [HTML](https://arxiv.org/abs/2510.20387)
### Authors
Baoqing Yue,Jinyuan Zhou,Zixi Wei,Jingtao Zhan,Qingyao Ai,Yiqun Liu
### Background
扩展定律旨在准确预测不同规模下的模型性能。现有的扩展定律研究几乎完全依赖于交叉熵作为评估标准。然而，交叉熵只能提供性能的片面视角：它度量了对正确标签赋予权重的概率，但忽略了正确标签与错误标签之间的相对排序。而相对排序对于语言模型至关重要，特别是在贪婪采样场景中。
### Innovation
本文从相对排序的角度研究了扩展定律。首先提出了基于相对概率（RBP）的度量标准，该度量标准量化了正确标签被排在最可能候选预测中的概率。由此建立了基于相对排序的扩展定律，说明了随着模型规模的增加，RBP如何改善。通过在四个数据集和四个模型系列上的广泛实验，证明了该定律的鲁棒性和准确性。
### Conclusion
基于相对概率的扩展定律补充了交叉熵的视角，有助于更全面地理解大规模语言模型的扩展。它为实际开发和理论探索提供了宝贵见解。
## 708. `cs.LG` - 研究GPT：评估与训练针对计算机科学研究全流程的大型语言模型 [PDF](https://arxiv.org/pdf/2510.20279), [HTML](https://arxiv.org/abs/2510.20279)
### Authors
Penghao Wang,Yuhao Zhou,Mengxuan Wu,Ziheng Qin,Bangyuan Zhu,Shengbin Huang,Xuanlei Zhao,Panpan Zhang,Xiaojiang Peng,Yuzhang Shang,Jianfei Yang,Zheng Zhu,Tianlong Chen,Zhangyang Wang,Kai Wang
### Background
随着大型语言模型（LLMs）的发展，它们在科学领域中的角色也越来越清晰，即建立一个人工智能合作者，能够有效协助人类科学家进行整个科学研究过程。由于科学研究涉及多个紧密相关的阶段，实现这一愿景需要一个评估完整工作流程的规范，而不仅仅是孤立的子任务。现有的评估方法多针对特定的子任务，因此无法全面地评估一个系统的整体表现。因此，提出了CS-54k，这是一个高质量的计算机科学领域问答对集合，来源于14000多篇CC许可论文，并通过一个可扩展的、基于论文的流程构建，结合检索增强生成（RAG）和多阶段的质量控制，确保数据的准确性。通过对这个统一的集合进行分析，得到了两个互补的数据子集：CS-4k用于评估AI辅助科学研究的能力，CS-50k用于大规模训练模型。
### Innovation
本文提出了CS-54k，这是一个高质量的计算机科学领域问答对集合，用于评估与训练大型语言模型，以实现全面支持科学研究的任务。CS-54k在于它不是简单地评估特定子任务，而是一个评估完整工作流程的数据集。此外，通过使用CS-50k进行训练的开放模型在监督学习和强化学习的基础上显示出显著的改进，即使是较小规模的模型，如7B，经过适当训练后也能超越一些大型专有系统（例如GPT-4、GPT-4o、Gemini 2.5 Pro）。这表明，使得AI模型成为更好的研究助手，更依赖于针对特定领域的高质量数据训练，而不是大规模预训练或一般基准测试的性能。因此，通过CS-4k和CS-50k，可以促进AI系统作为计算机科学研究中可靠的合作者。
### Conclusion
研究GPT的目标是通过建立一个全面的评估框架，促进大型语言模型在计算机科学研究全流程中的应用。这个框架不仅对于评估AI的能力至关重要，而且对于引导未来的训练方法也有关键作用。值得注意的是，即使是中小规模的模型，也可以通过高质量数据训练获得与大型专有系统的竞争力，这表明领域对齐的训练是关键。
## 709. `cs.LG` - 平衡专业化与集中化：一种适用于顺序工业控制的多代理强化学习基准 [PDF](https://arxiv.org/pdf/2510.20408), [HTML](https://arxiv.org/abs/2510.20408)
### Authors
Tom Maus,Asma Atamna,Tobias Glasmachers
### Background
多阶段工业过程的自主控制需要同时具备局部专业化和全局协调。虽然强化学习（RL）提供了一种有前景的方法，但在工业中的应用仍然受限于奖励设计、模块化和动作空间管理等挑战。许多学术基准与工业控制问题有很大差异，限制了它们向实际应用的转移。
### Innovation
该研究提出了一个增强的行业启发式基准环境，该环境将两个现有基准（SortingEnv 和 ContainerGym）的任务结合在一个顺序回收场景中，涉及分类和压块操作。评估了两种控制策略：模块化架构的专用代理和集中治理整个系统的单一代理，同时还分析了动作屏蔽的影响。结果显示，在不使用动作屏蔽时，代理难以学习有效的策略，而模块化架构表现更好。当应用动作屏蔽时，两种架构都有显著改进，性能差距大大缩小。
### Conclusion
研究表明，动作空间约束起着决定性作用，专业化的优势随动作复杂性的降低而减弱。所提出的基准为在工业自动化中探索实用且稳健的多代理强化学习解决方案提供了有价值的测试环境，同时也促进了关于集中化与专业化之间辩论的进展。
## 710. `cs.LG` - 无积分的神经标记时间点过程中的标记不平衡问题解决 [PDF](https://arxiv.org/pdf/2510.20414), [HTML](https://arxiv.org/abs/2510.20414)
### Authors
Sishun Liu,Ke Deng,Xiuzhen Zhang,Yongli Ren,Yan Wang
### Background
已有的研究已经很好地应用了标记时间点过程（MTPP）来建模标记事件流中的事件分布，并可用于预测下一个事件的到到来时间和标记。然而现有的研究忽略了在很多实际应用中事件标记分布存在高度不平衡的现象，一些标记频繁出现而另一些则稀少。这种不平衡对预测的性能，特别是对于稀有标记的事件预测产生了巨大挑战。
### Innovation
提出了一个阈值方法，该方法通过学习阈值来调整标记概率（已归一化为其先验概率），以优化标记预测，而不是像现有研究那样直接基于标记概率来预测标记。结合该方法，首先预测标记，然后预测时间。开发了一个新型的神经MTPP模型，以实现有效的时间采样和标记概率估计，避免了计算上昂贵的数值积分。
### Conclusion
在实际数据集上的广泛实验表明，我们的方法在针对下一个事件的标记和时间预测方面优于各种基线。
## 711. `cs.LG` - 为什么DPO是一种不合适的估计器以及如何修复它 [PDF](https://arxiv.org/pdf/2510.20413), [HTML](https://arxiv.org/abs/2510.20413)
### Authors
Aditya Gopalan,Sayak Ray Chowdhury,Debangshu Banerjee
### Background
直接对齐算法如直接偏好优化（DPO）通过偏好数据微调模型，仅使用监督学习，而不是两阶段的人类反馈强化学习（RLHF）。研究表明DPO实质上是一个关于奖励函数（由参数策略类诱导）的统计估计问题。当真实奖励函数无法通过策略类实现时，DPO会变得不合适，导致偏好顺序逆转、策略奖励恶化、以及对输入偏好数据分布的高敏感性等问题。
### Innovation
研究了两阶段RLHF在参数类中的局部行为，将其与策略空间的自然梯度步相关联。通过微细化的几何表征，提出了AuxDPO，通过在DPO损失函数中引入辅助变量帮助趋向RLHF解并减轻DPO的不合适性。实证展示了AuxDPO在教科书式的联立问题设置以及大型语言模型对齐任务中的优越性能。
### Conclusion
通过引入AuxDPO，解决了DPO的不合适性问题，使模型在算法对齐任务中表现出更好的性能，验证了两阶段RLHF的有效性。
## 712. `cs.LG` - 通过概念学习视角实现可解释基准测试 [PDF](https://arxiv.org/pdf/2510.20439), [HTML](https://arxiv.org/abs/2510.20439)
### Authors
Quannian Zhang,Michael Röder,Nikit Srivastava,N'Dah Jean Kouagou,Axel-Cyrille Ngonga Ngomo
### Background
系统性能通常通过少量指标进行总结，而分析评估细节和获取进一步发展的见解仍是一个耗时且易偏倚的手动任务。为了改进这一点，本文提出了可解释基准测试，旨在自动为基准中系统的性能生成解释。这一方法首次为基于知识图谱的问答系统进行实例化。通过使用一种专为大规模知识图谱开发的新颖概念学习方法PruneCEL来计算解释，研究表明PruneCEL在可解释基准测试任务上表现出色，F1分数比最先进的概念学习方法高出0.55分。参与者的研究发现，80%的情况下，多数参与者能够基于系统的解释预测其行为。
### Innovation
本文提出了一种新的基准测试方法——可解释基准测试，通过自动为系统的性能生成解释。使用了专为大规模知识图谱开发的概念学习方法PruneCEL，该方法在可解释基准测试任务上优于现有方法。用户研究进一步验证了解释的有效性，参与者的预测准确率达到80%以上。
### Conclusion
PruneCEL在可解释基准测试任务中表现出色，一种全新的方法使得用户能够更好地理解系统的性能。
## 713. `cs.LG` - 网球预测中的非传递性玩家优势及市场效率低下：基于图神经网络的方法 [PDF](https://arxiv.org/pdf/2510.20454), [HTML](https://arxiv.org/abs/2510.20454)
### Authors
Lawrence Clegg,John Cartlidge
### Background
在竞争性网球赛事中，非传递性玩家优势较为常见，即玩家A胜过B，B胜过C，但C又胜过A。然而，目前在预测方法中对此现象的处理方式较少。现有预测方法中，例如博彩公司Pinnacle Sports，对于高复杂度非传递性比赛的处理较为不足，这为通过新的方法捕捉这种关系动态提供了机会。
### Innovation
本文提出了一种使用图神经网络的方法，明确通过时态有向图来建模这些非传递性关系，使用玩家作为节点，其历史比赛结果作为有向边。该方法独特地捕捉了这些场景中的关系动态，并在某些赛事中实现了显著的正向回报率(3.26% ROI)。
### Conclusion
当使用模型对高非传递性匹配进行选择性下注时，获得了65.7%的准确性和0.215的比尔得分，并在1903次下注中实现了3.26%的回报率。这说明博彩市场在处理这些高非传递性赛事中存在效率问题，而我们的方法能够有效利用这种市场效率的缺失。
## 714. `cs.LG` - Bi-CoG: 双一致性引导的自我训练方法 [PDF](https://arxiv.org/pdf/2510.20477), [HTML](https://arxiv.org/abs/2510.20477)
### Authors
Rui Zhu,Song-Lin Lv,Zi-Kang Wang,Lan-Zhe Guo
### Background
标签稀缺场景中，半监督学习（SSL）和微调预训练模型是两种主流方法。近年来，研究逐渐关注将预训练的视觉-语言模型（VLMs）的微调与SSL结合，形成了半监督微调的新范式。然而，现有方法常常受到模型偏差和超参数敏感性的限制，这是因为它们依赖于预测一致性或预定义的置信度阈值。
### Innovation
提出了一种简单且有效的插件式方法——双一致性引导的自我训练（Bi-CoG）。该方法通过同时利用跨模型一致性和模型内一致性的策略，结合一种错误感知动态伪标签分配策略，为预训练的视觉-语言模型生成高质量和低偏差的伪标签。
### Conclusion
通过理论分析和在14个数据集上的广泛实验，Bi-CoG方法被证明是有效的，并且能够显著且一致地提升现有方法的效果。
## 715. `cs.LG` - 大型语言模型修复中样本选择策略的实验研究 [PDF](https://arxiv.org/pdf/2510.20428), [HTML](https://arxiv.org/abs/2510.20428)
### Authors
Xuran Li,Jingyi Wang
### Background
由于大型语言模型（LLMs）在现实系统中的广泛应用，它们可能会生成有毒或有偏见的输出，从而损害安全性和信任度。因此，后 hoc 模型修复提供了一种有效的解决方案，但大规模参数更新的高成本促使人们有选择性地使用修复数据。尽管已有大量关于模型训练数据选择的工作，但对于大规模生成模型的行为修复而言，哪种抽样标准最有效且最高效仍不明确。因此，本研究系统地分析了 LLM 修复中的样本优先策略，评估了五种代表性选择方法，以了解其修复效果和权衡。
### Innovation
本研究提出了 Semantically-Aware Prioritized Sampling (SAPS) 方法，并通过评估毒性减少、WikiText-2 和 LAMBADA 的困惑度以及三个综合指标 Repair Proximity Score (RPS)、Overall Performance Score (OPS) 和 Repair Efficiency Score (RES) 来评估修复效果和权衡。实验结果显示，SAPS 能够在减毒、保持功能和效率之间取得最佳平衡，相较于其他方法，它使用的数据量更少。此外，研究还表明随机抽样方法对于大模型或稳健模型仍然有效，而高成本方法 CCS 和 GraNd 提供的增益有限。模型规模和修复方法决定了最优数据比例，表明样本选择应被视为修复管道中的可调组件。这一发现证实了基于选择的修复作为一种高效的可扩展框架，适用于维持 LLM 可靠性。
### Conclusion
总体而言，这些研究结果确立了基于选择的修复作为一种高效可扩展的框架，用于维护 LLM 可靠性。样本选择方法的选择应根据模型规模和修复技术调整，以提高 LLM 的行为修复效果。
## 716. `cs.LG` - MolBridge：针对稳健药物药物相互作用事件预测的原子级别联合图形精炼 [PDF](https://arxiv.org/pdf/2510.20448), [HTML](https://arxiv.org/abs/2510.20448)
### Authors
Xuan Lin,Aocheng Ding,Tengfei Ma,Hua Liang,Zhe Quan
### Background
药物组合可以提供治疗益处，但也伴随着药物-药物相互作用（DDIs）的风险，尤其是在复杂的分子结构下。准确地预测DDI事件需要捕捉细粒度的药物间关系，这对于建模如酶介导的竞争代谢机制至关重要。然而，现有的方法通常依赖于孤立的药物表示，未能明确建模分子间的原子级交叉相互作用，限制了不同分子复杂性和DDI类型分布下的有效性。
### Innovation
为了解决上述局限性，我们提出了一种新颖的原子级别联合图形精炼框架MolBridge，用于稳健的药物药物相互作用事件预测。MolBridge通过构建整合药物对原子结构的联合图形，直接模型药物间的关联。为克服联合图形设置中的潜在信息损失问题（特别是处理长时间范围的原子依赖关系时的过度平滑），我们引入了一个结构一致性模块，该模块通过迭代细化节点特征来保留全局结构上下文。这种联合设计使MolBridge能够有效地学习局部和全局相互作用，超越最先进的基线方法，实现跨长尾和归纳场景的优良性能。这些模式产生了一种稳健的表示，适用于频繁和罕见的药物药物相互作用类型。
### Conclusion
在两个基准数据集上的广泛实验表明，MolBridge始终表现出优越的性能。这些结果表明，在增强DDI事件预测的准确度、稳健性和机制可解释性方面，细粒度的图形精炼具有优势。这项工作通过为挖掘和分析药物药物相互作用网络开发基于图形的方法，为Web挖掘和内容分析作出了贡献。
## 717. `cs.LG` - 通过图像偏好模型可移植的黑盒一次性的水印伪造方法 [PDF](https://arxiv.org/pdf/2510.20468), [HTML](https://arxiv.org/abs/2510.20468)
### Authors
Tomáš Souček,Sylvestre-Alvise Rebuffi,Pierre Fernandez,Nikola Jovanović,Hady Elsahar,Valeriu Lacatusu,Tuan Tran,Alexandre Mourachko
### Background
近年来，数字内容水印技术引起了广泛关注，这主要是由于生成模型的广泛应用以及法律压力的增加。随着越来越多的AI生成内容出现在网络上，水印在大规模确保内容真实性和归属方面的作用变得越来越重要。尽管已经有关于水印抗去除攻击的研究，但当一个水印从真实内容窃取后应用到恶意内容上的水印伪造问题却鲜有探讨。本文聚焦于广泛使用的后处理图像水印，研究水印伪造问题。虽然有多个研究评估了水印的鲁棒性，但尚未充分研究伪造攻击。近年来的研究通常需要知道水印模型的具体信息，而本文则提供了一种简化且更实用的攻击方法，只需单一水marked图像即可。该攻击方法不依赖于对水印模型的了解。 
### Innovation
本文创新性地提出了一种偏好模型来评估图像是否被水印干扰。该模型通过纯程序生成图像进行训练，不需真实水印。更重要的是，通过反向传播优化输入图像，可以实现对水印的移除和伪造。这种方法仅需单个水标图像就能完成攻击，不需了解具体水印模型。方法更加简单且实用，对当前常见水印方法的有效性发出了质疑。此外，该模型还可评估及其他具有后处理图像水印框架方案的有效性。
### Conclusion
本文提出的偏好模型及攻击方法对水印应用产生了重要的启示，揭示了现有水印方法的潜在安全隐患，特别是当水印被盗取并在恶意内容上应用时。模型可以评估图像是否被水印干扰，优化输入图像实现水印移除和伪造。通过简单且实用的攻击方法验证了现有水印模型的有效性存在一定疑问，强调了需对水印伪造进行充分研究。此代码和进一步资源已经公开，为该领域研究提供了良好的参考和对比基础。
## 718. `cs.LG` - SheafAlign：一种用于分布式多模态对齐的sheaf理论框架 [PDF](https://arxiv.org/pdf/2510.20540), [HTML](https://arxiv.org/abs/2510.20540)
### Authors
Abdulmomen Ghalkha,Zhuojun Tian,Chaouki Ben Issaid,Mehdi Bennis
### Background
传统的多模态对齐方法假定所有模态间存在互冗余性，但在实际分布化的场景中这种假设不成立。现有的方法缺乏处理这种分布化场景的能力，特别是在模态之间不需要互冗余性的情况下，既不能有效地保留共享信息，也不能有效保留独特信息，导致在零样本泛化、跨模态对齐和缺省模态的鲁棒性方面表现不佳，同时伴随着较高的通信成本。
### Innovation
提出了SheafAlign框架，这是一种基于sheaf理论的方法，用于分布式多模态对齐。SheafAlign通过sheaf结构建模模态之间的成对关系，并采用基于解中心化的学习目标进行训练。这种方法在不需要所有模态间互冗余的情况下，能够有效保留共享信息及独特信息，从而在多模态感知数据集上实现了更好的零样本泛化能力、跨模态对齐和对缺省模态的鲁棒性，且与最先进的基线相比，通信成本降低了50%。
### Conclusion
SheafAlign方法通过创新的sheaf结构和分散对抗学习机制，克服了传统方法的缺陷，在实际情况中能达到更好的性能，并减少了通信成本。
## 719. `cs.LG` - Hurdle-IMDL:一种针对红外降雨遥感中不均衡数据的学习框架 [PDF](https://arxiv.org/pdf/2510.20486), [HTML](https://arxiv.org/abs/2510.20486)
### Authors
Fangjian Zhang,Xiaoyong Zhuge,Wenlan Wang,Haixia Xiao,Yuying Zhu,Siyang Cheng
### Background
尽管人工智能已经推进了定量遥感的进步，但由于标签分布不平衡的限制，其效果受到了制约。传统的模型往往倾向于训练常见的样例，而忽略罕见样例，这导致了在识别稀有事件时的检索性能下降。以降雨检索为例，这种问题尤为突出，特别是在辨别极端降雨时性能尤为受限。本文探讨了降雨分布不平衡的问题，并将其分为两个部分：零膨胀和长尾效应。零膨胀指的是非降雨样本的过多，而长尾效应指的是轻降雨样本相对于极端降雨的非对称富余。为了解决这些问题，本文提出了一种洪水干涉模型偏差学习框架（IMDL），通过将其转化成无偏的理想逆向模型来应对降雨分布的不平衡问题。实验结果表明，相较于传统、成本敏感、生成和多任务学习方法，IMDL框架在降雨检索上的表现优越，特别是在减轻系统低估和获取极端降雨方面具有显著效果。
### Innovation
本文提出了一种新的框架：洪水干涉模型偏差学习（Hurdle-IMDL），它能够有效应对遥感降雨检索中由于样本不平衡引起的标签分布问题。通过分解降雨分布不平衡为零膨胀和长尾效应，并分别采用 hurdle模型 和 IMDL 方法来处理，从而提出了一个有效的学习框架。这个框架的关键创新点在于能够有效缓解系统低估问题，并显著提高对极端降雨的检索性能。此外，该方法还提供了一种通用的解决方案，可用于解决环境变量分布不均的检索问题，提高了对稀有但影响巨大的事件的检索能力。
### Conclusion
基于统计指标和案例研究，Hurdle-IMDL框架在红外降雨检索中表现出了显著的优势，特别是在纠正系统性低估和检索极端降雨方面。这种方法提供了一种有效的解决方案，能够泛化应用于处理环境变量分布中的不平衡问题，从而改善稀有但具有高影响事件的检索效果。
## 720. `cs.LG` - 零样本强化学习统一框架 [PDF](https://arxiv.org/pdf/2510.20542), [HTML](https://arxiv.org/abs/2510.20542)
### Authors
Jacopo Di Ventura,Jan Felix Kleuker,Aske Plaat,Thomas Moerland
### Background
零样本强化学习（RL）作为一种在无需监督的情况下开发通用代理的方法已经崭露头角，能够在测试时无需额外训练或规划就能解决下游任务。与传统RL优化固定奖励下的策略不同，零样本RL要求代理能够编码丰富的表示以适应任何目标，类似于视觉和语言的基础模型。尽管该领域引起了广泛关注，但缺乏一个共同的分析视角。
### Innovation
论文提出了首个统一的零样本强化学习框架，引入了一致的符号表示和分类方式，能够组织并对比现有的方法。该框架将算法分为两大类：直接表示和组合表示，后者利用价值函数的子结构进行分解。此外，框架还对方法中的共通原则和关键差异进行了阐述，并推导出对后继特征方法的新界线，提供新的视角来看待其在零样本环境中的表现。
### Conclusion
通过将现有工作统一于一个共同的框架下，该框架提供了一种原则性的基础，为未来零样本RL的研究指出了明确的方向，同时也为开发更通用的代理设定了清晰的路径。
## 721. `cs.LG` - 嵌入MLOps生命周期到OT参考模型 [PDF](https://arxiv.org/pdf/2510.20590), [HTML](https://arxiv.org/abs/2510.20590)
### Authors
Simon Schindler,Christoph Binder,Lukas Lürzer,Stefan Huber
### Background
随着机器学习操作（MLOps）实践在工业环境中的日益普及，将其与操作技术（OT）系统结合带来了显著挑战。本研究分析了如何克服这两者相结合的基础性障碍，并提出了一种系统的方法，将MLOps实践嵌入现有的OT参考模型中。
### Innovation
本文评估了参考架构模型4.0（RAMI 4.0）和国际自动化协会标准95（ISA-95）的适用性，用于MLOps集成，并详细映射了MLOps生命周期组件，通过实际案例进行了说明。研究表明，虽然标准的MLOps实践不能直接应用于OT环境，但通过现有的参考模型进行有结构的适应可以提供成功的集成途径。
### Conclusion
研究结果表明，通过使用现有的参考模型进行有结构的适应，可以为MLOps的成功集成提供一条途径。虽然标准的MLOps实践不能直接移植到OT环境中，但这种适应性方法提供了可行解决方案。
## 722. `cs.LG` - 结构不变性很重要：通过图度量重新思考图重接 [PDF](https://arxiv.org/pdf/2510.20556), [HTML](https://arxiv.org/abs/2510.20556)
### Authors
Alexandre Benoit,Catherine Aitken,Yu He
### Background
图重接作为一种关键技术，通过修改图拓扑以改善信息流来缓解图神经网络（GNNs）和图变换器中的过度挤压现象。尽管效果显著，但图重接不可避免地改变了图的结构，这可能使重要的拓扑相关信号失真。尽管图重接的应用日益增多，但很少有研究探讨必须保存哪些结构属性，以确保性能改进和结构保真度之间的平衡。本文提供了一种系统的分析方法，研究图重接对一系列图结构度量的影响，以及这些变化与下游任务性能的关系。我们研究了七种不同的图重接策略，并将局部和全局图属性的变化与节点分类准确性相关联。研究表明：成功的图重接方法通常保持局部结构的同时，允许在全球连通性上具有灵活性。这些发现为有效图重接策略的设计提供了新的见解，并填补了图论与实际GNN优化之间的差距。
### Innovation
本文提供了一种系统的分析方法，研究图重接对一系列图结构度量的影响，以及这些变化与下游任务性能的关系。我们探讨了图重接可能带来的结构不变性的重要性，通过分析不同重接策略对图属性变化的影响，揭示了成功的重接方法需要保持局部结构但允许全局连通性的灵活性特点。这些研究为设计有效的图重接策略提供了新的思路，为图论和实际GNN优化之间的理论与应用结合提供了新的见解。
### Conclusion
成功的图重接方法倾向于保持局部结构同时允许全局连通性的灵活性，这一发现提出了关于设计有效图重接策略的新见解，填补了图论与实际GNN优化之间的鸿沟。
## 723. `cs.LG` - SGD 在期望光滑条件下收敛性分析 [PDF](https://arxiv.org/pdf/2510.20608), [HTML](https://arxiv.org/abs/2510.20608)
### Authors
Yuta Kawamoto,Hideaki Iiduka
### Background
随机梯度下降（SGD）是大规模学习的基石，但经典的分析依赖于过强（如有界方差）或过于粗糙（如均匀噪声）的假设。期望光滑度（ES）条件被视为一种灵活替代，它将随机梯度的二阶矩与目标值及全梯度联系起来。现有的研究主要集中在对该条件的初步探讨和一些特定情况下SGD的收敛性分析，但尚未有一个自包含的、全面的具体分析框架。
### Innovation
本文通过细化期望光滑度条件，引入解释和采样依赖的常数，并推导出全梯度范数平方的期望界，证明了不同步长安排下的收敛率（$O(1/K)$），并详细给出了所有证明。这种方法统一并扩展了最近的研究成果（Khaled和Richtárik, 2020；Umeda和Iiduka, 2025）.
### Conclusion
本文提供了一种对在期望光滑条件下的SGD收敛性的自包含和详尽的分析框架，证明了不同步长安排下的收敛率，统一并扩展了相关研究结果。
## 724. `cs.LG` - 大规模实际代码RAG：在计算预算下的任务感知检索设计选择 [PDF](https://arxiv.org/pdf/2510.20609), [HTML](https://arxiv.org/abs/2510.20609)
### Authors
Timur Galimzyanov,Olga Kolomyttseva,Egor Bogomolov
### Background
本文研究了在实际计算预算下，针对代码导向生成任务的检索设计。通过Long Code Arena提供的两种互补任务——代码补全和错误定位，系统地比较了不同上下文窗口大小的各种检索配置在三个方面：（i）分块策略，（ii）相似度评分，和（iii）划分粒度。研究表明，在不同资源限制下，最优的分块大小和划分策略有所不同，需要针对具体任务需求和模型约束进行优化，以实现高效计算。
### Innovation
本文针对不同的编程语言对检索策略进行了比较，提出了一种基于任务特性的最佳检索设计方案。结果显示，对于某些场景使用词级分裂和稀疏BM25能够获得更好的效果，而对于其他场景则需要使用更复杂的密集编码器，尽管这会带来较长的延迟。此外，还强调了根据可获得的上下文大小调整分块策略的重要性，以及BM25和词级分割提供了一个良好的性能与延迟折衷方案。
### Conclusion
研究提供了基于具体任务需求、模型限制和计算效率的证据指导，设计有效的代码导向的RAG系统。研究表明，检索延迟在不同配置之间可相差200倍，基于BPE的分割过于缓慢，而BM25结合词级分割提供了最佳的质量延迟权衡。
## 725. `cs.LG` - 通过组合能量最小化实现可泛化的推理 [PDF](https://arxiv.org/pdf/2510.20607), [HTML](https://arxiv.org/abs/2510.20607)
### Authors
Alexandru Oarga,Yilun Du
### Background
泛化是机器学习中的一个关键挑战，特别是在需要解决比训练数据更为复杂的问题的推理任务中。现有的方法通常以端到端的方式训练推理模型，直接将输入实例映射到解决方案。虽然这种方法使模型能够从数据中学习有用的启发式方法，但它通常仅限于在训练分布之外的有限泛化能力。在这种情况下，本文提出了一个通过学习更小且可管理的子问题解空间的能量景观来提高推理泛化的新型方法。在测试时，通过组合多个子问题的能量函数构建给定问题的全局能量景观。这种方法的组合特性允许在推理中引入附加约束，从而构建不同难度级别的能量景观。通过Parallel Energy Minimization (PEM)技术进一步提升了从新构建的能量景观中采样的质量。作者在一系列的推理任务上对方法进行了评估，其方法比现有的最先进的方法表现更好，能够泛化到更大的和更复杂的问题上。
### Innovation
提出了一种新型的推理泛化方法，通过学习更小和更可管理的子问题解空间上的能量景观。在测试时将多个子问题的能量函数组合起来，构建全局能量景观。引入Parallel Energy Minimization (PEM)，以提高从新构建的能量景观中采样的质量。这种方法显著提升了模型的泛化能力，尤其是对于更大和更复杂的问题。该方法在多个推理任务上的评估优于现有的最先进的方法。
### Conclusion
提出的通过组合能量最小化实现的推理方法达到了优异的效果，不仅可以泛化到更大的问题，而且能够处理更复杂的问题。该方法提供了一种新的视角来解决推理任务中的泛化挑战，未来还可以进一步探索该方法在其他领域的应用。项目网站可在此处找到。
## 726. `cs.LG` - PSO-XAI: 一种增强的可解释人工智能框架，用于可靠的乳腺癌检测 [PDF](https://arxiv.org/pdf/2510.20611), [HTML](https://arxiv.org/abs/2510.20611)
### Authors
Mirza Raquib,Niloy Das,Farida Siddiqi Prity,Arafath Al Fahim,Saydul Akbar Murad,Mohammad Amzad Hossain,MD Jiabul Hoque,Mohammad Ali Moni
### Background
乳腺癌是全球女性中最常见和最严重的癌症之一，导致癌症相关死亡率增加。早期和准确的检测至关重要，可以减轻潜在威胁并提高生存率。传统诊断方法受限于变异性、成本和最严重的是误诊风险。为应对这些挑战，机器学习（ML）成为计算机辅助诊断的强大工具，特征选择对于提高模型性能和可解释性起着关键作用。
### Innovation
研究提出了一种结合自定义粒子群优化（PSO）的集成框架，用于特征选择。该框架在29种不同的模型上进行了评估，涵盖了经典分类器、集成技术、神经网络、概率算法和基于实例的算法。通过结合交叉验证和可解释的人工智能方法以保证可解释性和临床相关性，实验证明该方法在所有性能指标中实现了99.1%以上的得分，同时通过降低维度提供透明且模型无关的解释。研究展示了将 swarm 智能与可解释的机器学习相结合的潜力，从而实现稳健、可信赖和临床意义重大的乳腺癌诊断。
### Conclusion
结果表明，结合 swarm 智能与可解释机器学习的框架可能为乳腺癌诊断提供可靠、透明且无可争议的结果，具有显著的临床意义。
## 727. `cs.LG` - H-SPLID：基于HSIC的显著性保留潜在信息分解 [PDF](https://arxiv.org/pdf/2510.20627), [HTML](https://arxiv.org/abs/2510.20627)
### Authors
Lukas Miklautz,Chengzhi Shi,Andrii Shkabrii,Theodoros Thirimachos Davarakis,Prudence Lam,Claudia Plant,Jennifer Dy,Stratis Ioannidis
### Background
该研究提出了H-SPLID算法，该算法通过将显著特征和非显著特征明确分解到不同的空间中，来学习显著的特征表示。研究表明H-SPLID有助于学习低维度的任务相关特征。
### Innovation
算法将显著特征和非显著特征明确分解到不同的空间中，从而在输入扰动下预测偏差的期望值受显著特征子空间的维度及输入与表示间的希尔伯特-施密特独立性判据的约束。实验结果表明，使用H-SPLID训练的模型主要依赖于显著输入组件，显示了对非显著特征（如图像背景）的扰动不敏感。
### Conclusion
研究表明，H-SPLID有助于学习低维度且与任务相关的重要特征，模型对非显著特征的扰动不敏感，实验验证了H-SPLID在图像分类任务中的有效性。
## 728. `cs.LG` - MS-BART: 统一建模质谱和分子以解析结构 [PDF](https://arxiv.org/pdf/2510.20615), [HTML](https://arxiv.org/abs/2510.20615)
### Authors
Yang Han,Pengyu Wang,Kai Yu,Xin Chen,Lu Chen
### Background
质谱（MS）在分子识别中起着关键作用，大大推进了科学发现的进步。然而，从MS数据中解析结构仍然具有挑战性，因为缺少标注的光谱。虽然大规模预训练在其他领域证明了有效性，但在质谱应用中受限于原始光谱信号的复杂性和异质性。
### Innovation
本文提出了一种统一建模框架MS-BART，它通过大规模预训练将质谱和分子结构映射到共享的令牌词汇中，实现跨模态学习。多任务预训练目标进一步增强MS-BART的泛化能力，通过对指纹-分子数据集进行联合优化去噪和翻译任务。预训练模型经过微调后运用到实验光谱，增强对实际光谱变化的鲁棒性。引入了化学反馈机制进一步引导模型生成更接近参考结构的分子。
### Conclusion
MS-BART在5/12关键指标上达到了最先进的性能，比竞争的扩散方法快一个数量级。全面的消融研究系统验证了模型的有效性和鲁棒性。
## 729. `cs.LG` - 关于差异隐私深度迁移学习中最佳超参数的研究 [PDF](https://arxiv.org/pdf/2510.20616), [HTML](https://arxiv.org/abs/2510.20616)
### Authors
Aki Rehn,Linzh Zhao,Mikko A. Heikkilä,Antti Honkela
### Background
当前，差异隐私(DP)迁移学习，即在私人数据上微调预训练模型，是隐私约束下训练大型模型的最先进的方法。在这一背景下，我们专注于两个关键的超参数：剪切界限C和批量大小B。现有的理论认为更强的隐私需要更小的C，然而从实际经验来看，在较强隐私条件下较大的C表现更好，这是由于梯度分布的变化所导致。文章指出，尤其是在固定计算预算（固定周期）的情况下，现有的批量大小B调整方法并不有效，累积DP噪声可以更好地解释为何更小或更大的批量表现更好。同时，文章还强调了在整个任务中使用单一的(C,B)设置可能导致性能不佳，尤其是在从宽松隐私转移到严格隐私和从大量计算资源转移到有限计算资源时，性能会显著下降。文章通过对剪切作为梯度重权的形式进行分析，并讨论累积DP噪声来解释上述现象。
### Innovation
文章通过固定计算预算证明了现有的批量大小调整方法并不有效，而是累积DP噪声更好地解释了何为更小或更大的批量表现更好。文章还指出在整个任务中使用单一(C,B)设置可能导致性能不佳，并通过分析剪切作为梯度重权的形式和讨论累积DP噪声来解释此现象。“
### Conclusion
研究发现，在从宽松隐私转移至严格隐私以及从丰富计算资源转移到稀缺计算资源时，性能会显著下降。通过对剪切作为梯度重权的形式进行分析，并讨论累积DP噪声来解释此现象。
## 730. `cs.LG` - 大型多模态模型赋能的任务导向自主通信：设计方法与实现挑战 [PDF](https://arxiv.org/pdf/2510.20637), [HTML](https://arxiv.org/abs/2510.20637)
### Authors
Hyun Jong Yang,Hyunsoo Kim,Hyeonho Noh,Seungnyun Kim,Byonghyo Shim
### Background
大型语言模型（LLMs）和大型多模态模型（LMMs）在自然语言理解、生成及复杂推理方面取得了前所未有的突破。这种变革性的潜力使它们成为6G自主通信的关键使能器，涵盖机器、车辆和类人机器人之间的通信。
### Innovation
本文提供了基于LLMs和LMMs的任务导向自主通信的综述，重点集中在多模态传感集成、适应性重构和无线任务的提示/微调策略。通过三个案例研究，展示了基于LMM的交通控制、基于LLM的机器人调度和基于LMM的环境感知信道估计框架。实验结果表明，提出的LLM/LMM辅助自主系统在动态目标、变化的输入参数和异构多模态条件下表现出显著优于传统和判别性深度学习（DL）模型方法的效果。
### Conclusion
所提出的LLM/LMM辅助自主系统在动态目标、变化的输入参数和异构多模态条件下表现出显著优于传统和判别性DL模型方法的效果。
## 731. `cs.LG` - 公平生存预测：公平感知生存建模（FASM）方法 [PDF](https://arxiv.org/pdf/2510.20629), [HTML](https://arxiv.org/abs/2510.20629)
### Authors
Mingxuan Liu,Yilin Ning,Haoyuan Wang,Chuan Hong,Matthew Engelhard,Danielle S. Bitterman,William G. La Cava,Nan Liu
### Background
随着机器学习模型在医疗保健中的应用越来越广泛，基于一体临床数据中的结构不平等和社会偏见的数据驱动模型可能会加剧这些不平等现象。在生存分析中，截尾数据的存在和时间动态的复杂性给公平模型的开发带来了更多复杂性。现有的算法公平性方法往往忽略了不同组内和跨组风险排名的不平等，例如，高风险的黑人患者可能会被错误地排名低于低风险但没有经受死亡事件的白人患者。这种错误排名会巩固生物学本质主义，并破坏公平医疗服务。长期以来，截尾数据在生存分析中的处理复杂性，使得在公平建模中更具挑战性。
### Innovation
本文提出了一种公平感知生存建模（FASM），旨在减少模型在不同组内和跨组风险排名中的算法偏见。通过将FASM应用于SEER乳腺癌数据，结果表明，FASM在提高公平性的同时，能够保持与未考虑公平性生存模型相当的区分性能。模型在10年时间跨度内的稳定公平性，在随访中期观察到最大的改进。该方法使生存模型在临床决策中实现准确性和公平性的双重优先，促发展成为临床护理的核心原则。
### Conclusion
公平感知生存建模（FASM）在改进公平性方面表现显著，同时保留了与未考虑公平性生存模型相比相似的预测性能，表明其在临床生存分析中的潜在应用价值。该方法通过优化跨组风险排名，有助于促进更公平的医疗决策，同时确保临床预测的准确性。
## 732. `cs.LG` - 智能云系统中的增强注意力实体推荐 [PDF](https://arxiv.org/pdf/2510.20640), [HTML](https://arxiv.org/abs/2510.20640)
### Authors
Fiza Hussain,Anson Bastos,Anjaly Parayil,Ayush Choure,Chetan Bansal,Rujia Wang,Saravan Rajmohan
### Background
在Microsoft的云服务监控中，现有方法无法有效推荐应由自动化看门犬（监控工具）跟踪的最佳属性子集，因为现有的方法性能较差，难以捕捉跨长范围实体之间的依赖关系，且缺乏对实体间互动动态的结构性和参与信息的综合考虑。
### Innovation
我们提出了DiRecGNN，一个基于注意力增强的实体推荐框架。该框架包括一个多头注意力机制，能够关注异构邻居及其属性，并通过随机漫步采样的路径来捕捉长期依赖关系。此外，还使用了多方面损失函数来优化相关推荐，尊重数据的固有稀疏性。模型在实验评估中显示出显著的性能提升，MRR提高了43.1%，并且得到了产品团队的认可，被评为实用特征，得分为4.5/5。
### Conclusion
我们的框架成功解决了监控云服务时的选择性监控问题，在推荐性能上有了显著进步，得到了用户的积极反馈。
## 733. `cs.LG` - 连接Jensen-Shannon散度和Kullback-Leibler散度：一个新的表示学习界值 [PDF](https://arxiv.org/pdf/2510.20644), [HTML](https://arxiv.org/abs/2510.20644)
### Authors
Reuben Dorent,Polina Golland,William Wells III
### Background
互信息（MI）是统计依赖性的一种基本度量，广泛应用于表示学习。尽管可以通过Kullback-Leibler散度（KLD）的定义直接优化MI，但这种方法通常很难实现。因此，许多最近的方法使用替代依赖性度量来最大化对联合分布和边际分布乘积的Jensen-Shannon散度（JSD）之间的差异。然而，这些替代目标与MI之间的联系仍不清楚。
### Innovation
本文通过推导一个新的、紧密且可解的JSD关于KLD的下界，解决了此问题。通过该下界，发现最大化基于JSD的信息可以增加一个已保证的MI下界。此外，作者回顾了基于JSD目标的实践实现，并观察到通过最小化二元分类器的交叉熵损失（用于区分联合和边际分布对）可恢复一个已知的关于JSD的变分下界。
### Conclusion
在各种基准参考场景中，我们将下界与最新状态的神经VLB估计器进行了比较。我们的下界估计器在互信息估计中提供了稳定且低方差的估计。此外，还展示了它在信息瓶颈框架中的实用价值。综上所述，本文提供了使用区分学习进行基于MI的表示学习的新理论依据和实验证据。
## 734. `cs.LG` - 使用混合CNN和路径损耗混合专家的贝叶斯干扰定位 [PDF](https://arxiv.org/pdf/2510.20666), [HTML](https://arxiv.org/abs/2510.20666)
### Authors
Mariona Jaramillo-Civill,Luis González-Gudiño,Tales Imbiriba,Pau Closas
### Background
全球导航卫星系统（GNSS）信号容易受到干扰，尤其是在城市区域，多路径和阴影会影响接收功率。以往的数据驱动方法能够在一定程度上实现定位，但难以重构接收到的信号强度（RSS）场，因为缺乏足够的空间上下文。
### Innovation
提出了一种融合物理路径损耗（PL）模型和卷积神经网络（CNN）的混合贝叶斯混合专家框架，通过对数线性池化。PL专家确保物理一致性，而CNN利用建筑物高度图来捕获城市传播效应。通过拉普拉斯近似的贝叶斯推理提供了干扰位置和RSS场的后验不确定性。
### Conclusion
实验表明，在城市射线跟踪数据上，随着训练点的增加，定位精度提高且不确定性降低，不确定性集中在干扰附近的区域和城市峡谷中，这些地方的传播最为敏感。
## 735. `cs.LG` - 从掩码到世界：世界模型的 hitchhiker 引导 [PDF](https://arxiv.org/pdf/2510.20668), [HTML](https://arxiv.org/abs/2510.20668)
### Authors
Jinbin Bai,Yu Lei,Hecong Wu,Yuchen Zhu,Shufan Li,Yi Xin,Xiangtai Li,Molei Tao,Aditya Grover,Ming-Hsuan Yang
### Background
本文不是关于世界模型的普通文献综述，而是一份指南，旨在帮助读者构建世界模型。该文章的目的不是罗列所有提到“世界模型”的论文，而是沿着一条清晰的道路，从早期可以统一不同模态数据表现学习的掩码模型，到共用单一模式的统一架构，再到可以完成感知-行动闭环的交互生成模型，最后到能够持久保持世界一致性记忆增强系统。文章跳过了与主线关系较弱的分支，专注于核心：生成中心、交互循环和记忆系统。
### Innovation
文章提出的方法是从早期的掩码模型到交互式生成模型，再到记忆增强系统，构建持久连贯世界模型的路径，重点关注生成核心、交互循环和记忆系统。
### Conclusion
该文章认为这是通向真正世界模型最有前景的路径。
## 736. `cs.LG` - xTime: 使用分层知识蒸馏和专家融合的极值事件预测 [PDF](https://arxiv.org/pdf/2510.20651), [HTML](https://arxiv.org/abs/2510.20651)
### Authors
Quan Li,Wenchao Yu,Suhang Wang,Minhua Lin,Lingwei Chen,Wei Cheng,Haifeng Chen
### Background
在实际时间序列中，极端事件频繁发生并往往具有重要的实践意义。在气候和医疗行业等领嫰，诸如洪水、热浪或急性医疗事件会导致严重后果。因此，这些事件的准确预测是非常重要的。现有的许多时间序列预测模型着重于整个预测窗口的整体性能，但往往难以准确预测极端事件，如高温或心率突跃。主要挑战在于数据不平衡以及在预测极端事件之前的重要事件信息的忽视。
### Innovation
本文提出xTime，一种用于时间序列中极端事件预测的新颖框架。xTime利用知识蒸馏机制，将低频事件训练的模型信息传递到高频事件预测中，从而提高预测性能。此外，引入了专家融合（MoE）机制，动态选择和融合不同频率级别专家模型的输出，进一步改进了极端事件的预测性能。
### Conclusion
实验结果表明，xTime实现了持续的改进，在极端事件预测准确性上从3%提高到78%。
## 737. `cs.LG` - 基于图的成瘾护理预测 (GRACE: GRaph-based Addiction Care prEdiction),  [PDF](https://arxiv.org/pdf/2510.20671), [HTML](https://arxiv.org/abs/2510.20671)
### Authors
Subham Kumar,Prakrithi Shivaprakash,Koustav Rudra,Lekhansh Shukla,Animesh Mukherjee
### Background
为成瘾患者确定适当的治疗地点是临床决策中至关重要的一环，对患者治疗结果和资源的有效利用有直接影响。由于缺乏足够的专业治疗资源，如住院床位或工作人员，开发自动化框架的需求未得到满足。当前的决策方法在成瘾数据集上遭受严重类别不平衡的限制。
### Innovation
本文提出了一种新颖的图神经网络（GRACE）框架，将治疗地点预测问题形式化为结构化学习问题。进行了广泛的功能工程，并提出了一种新的获取无偏置元图的方法，用于训练GNN以克服类别不平衡问题。实验结果表明，在实际数据中，该方法在少数类的F1分数上比竞品基线提高了11-35%。
### Conclusion
该研究展示了使用GRACE框架进行成瘾护理预测的改进效果，并提供了代码和笔记嵌入，以供进一步研究使用。
## 738. `cs.LG` - 基于脉冲神经网络的可扩展、因果和高效神经解码框架 [PDF](https://arxiv.org/pdf/2510.20683), [HTML](https://arxiv.org/abs/2510.20683)
### Authors
Georgios Mentzelopoulos,Ioannis Asmanis,Konrad P. Kording,Eva L. Dyer,Kostas Daniilidis,Flavia Vitale
### Background
脑-计算机接口（BCIs）有望为神经运动功能受损的个体恢复诸如语音和假肢控制等关键功能。它们的核心组件是神经解码器，即能将神经活动映射到预期行为的模型。现有基于学习的解码方法可分为两类：一是简单但缺乏泛化的因果模型，二是复杂但能离线扩展和泛化但在实时场景下难以适应的非因果模型。这些方法共有的问题是依赖于耗电的人工神经网络作为基础，这意味着很难将其整合进资源受限的现实系统中。脉冲神经网络（SNNs）提供了替代方案，因其因果计算特性适于实时使用，并且低能耗使其成为电池受限环境的理想选择。
### Innovation
本文介绍了名为Spikachu的框架，这是一种基于SNNs的可扩展、因果且节能的神经解码框架。Spikachu直接处理分桶后的脉冲，通过投影到共享的潜在空间，其中适应输入时间的脉冲模块提取相关特征。这些潜在表示然后被集成和解码以生成行为预测。该方法在单次会话训练时表现出了比因果基线更好的性能，并且在多会话和多主体训练后具备较好的泛化能力和少量样本转移能力。
### Conclusion
总之，Spikachu提出了一种基于SNNs的可扩展、在线兼容的神经解码框架，在相对最先进的模型性能相当的情况下，耗能低得多。
## 739. `cs.LG` - 分离组成计算中的“是什么”和“如何做”以实现重用和持续学习 [PDF](https://arxiv.org/pdf/2510.20709), [HTML](https://arxiv.org/abs/2510.20709)
### Authors
Haozhe Shan,Sun Minni,Lea Duncker
### Background
智能和高效行为的关键特征之一是能够不断学习、保留和应用技能以达成目标。然而，神经机制如何促进持续学习和灵活重组技能还不清楚。本研究中，作者使用一个新颖的双系统方法研究组成学习和已学计算的组合再利用，在循环神经网络（RNN）模型中进行探讨。
### Innovation
作者提出了一种新颖的双系统方法，一个系统负责推断执行何种计算任务，另一个系统执行具体的计算过程。通过构建一个统一的生成模型，能够以概率方式描述一系列组合认知任务。基于此模型，作者开发了一种无监督的在线学习方法，能够在每次试验中学习生成模型，构建词汇并推断潜在阶段结构作为时间变化的计算上下文。RNN的低秩组件根据由“是什么”系统推断出的上下文进行组合，实现持续学习而不发生灾难性遗忘。
### Conclusion
该两系统学习框架在示例任务中展示了其有效性和竞争力，证明了其在前向和后向迁移中的潜力，以及对未见过任务的快速组合泛化能力。
## 740. `cs.LG` - 基于高斯过程的有限时间区间马尔可夫决策过程的无遗憾托马斯采样 [PDF](https://arxiv.org/pdf/2510.20725), [HTML](https://arxiv.org/abs/2510.20725)
### Authors
Jasmine Bayrooti,Sattar Vakili,Amanda Prorok,Carl Henrik Ek
### Background
托马斯采样(TS)是一种在贝叶斯优化到强化学习(RL)等多个领域广泛应用的策略。尽管TS在实践中取得了成功，但在具有复杂时间结构的RL场景下的理论基础仍显得有限。本文通过使用具有高斯边缘分布的模型来填补这一空白，研究在具有高斯过程(GP)先验奖励和转移的RL中的TS算法，并证明了TS在有限时间区间马尔可夫决策过程中的无遗憾保证。
### Innovation
1. 提出了使用高斯边缘分布模型的TS算法，并证明了在成本函数和贝尔曼更新递归结构中的无遗憾保证。2. 首次将椭圆潜在引理扩展到多输出场景，以解决价值函数非高斯的问题和贝尔曼更新的递归结构问题。3. 充分考虑了高斯过程模型的复杂性，并通过理论分析得出有限时间区间马尔可夫决策过程中的无遗憾保证公式。
### Conclusion
本文通过对托马斯采样算法在有限时间区间马尔可夫决策过程中的研究，进一步完善了TS在RL中的理论基础，并强调了结构假设和模型不确定性的建模对TS性能的影响。
## 741. `cs.LG` - 优化临床跌倒风险预测：约翰霍普金斯跌倒风险评估工具与电子健康记录变量的数据驱动整合 [PDF](https://arxiv.org/pdf/2510.20714), [HTML](https://arxiv.org/abs/2510.20714)
### Authors
Fardin Ganjkhanloo,Emmett Springer,Erik H. Hoyer,Daniel L. Young,Kimia Ghobadi
### Background
本研究旨在通过数据驱动的方法提高约翰霍普金斯跌倒风险评估工具（JHFRAT）与临床有意义的其他指标的契合度。研究回顾性分析了自2022年3月至2023年10月期间，来自约翰霍普金斯健康系统三家医院的54,209份住院记录，将其中20,208份高跌倒风险住院记录和13,941份低跌倒风险住院记录用于分析。基于临床知识和保持可解释性，本研究利用约束评分优化（CSO）模型结合JHFRAT评估数据和额外的电子健康记录（EHR）变量进行分析。基准的黑盒模型（XGBoost）虽然在性能指标上优于基于知识的约束逻辑回归模型，但CSO模型具有更好的风险标签变化适应性。该研究提供了基于证据的方法，为医疗机构系统性地增强住院跌倒预防策略和患者安全提供数据驱动优化技术的基础，有助于提高风险评估和资源分配的准确性。
### Innovation
本研究提出了利用约束评分优化（CSO）模型结合约翰霍普金斯跌倒风险评估工具（JHFRAT）与电子健康记录（EHR）变量进行分析的方法，该方法显著提高了预测性能。尽管基准黑盒模型在性能指标上有所提升，但CSO模型在面对风险标签变化时表现出更好的稳健性。
### Conclusion
基于证据的方法为医疗机构提供了优化住院跌倒风险评估的技术基础，有助于提高风险评估和资源分配的准确性，从而系统性地增强住院患者的安全性。
## 742. `cs.LG` - MEIcoder: 根据神经活动利用最有效输入解码视觉刺激 [PDF](https://arxiv.org/pdf/2510.20762), [HTML](https://arxiv.org/abs/2510.20762)
### Authors
Jan Sobotka,Luca Baroni,Ján Antolík
### Background
从神经群体活动解码视觉刺激对于理解大脑和脑机接口的应用至关重要。然而，这类生物数据在灵长类动物或人类中往往稀缺，尤其是在猴子或人类中，高通量记录技术如双光子成像仍然具有挑战性或无法应用，这使得深度学习解码技术面临挑战。
### Innovation
我们提出了MEIcoder，一种基于生物体征的解码方法，利用了特定神经元的最有效输入（MEIs）、结构性相似性索引度量损失以及对抗训练。MEIcoder在初级视觉皮层（V1）单细胞活动重建方面达到了最先进的性能，尤其是在小数据集和少量记录神经元的情况下表现尤为突出。通过消融研究，我们表明MEIs是性能的主要驱动因素。并且在扩展实验中，我们展示了MEIcoder可以从1,000至2,500个神经元和不到1,000个训练数据点重建高保真、自然外观的图像的能力。我们还提出了一种包含超过16万个样本的统一基准，以促进未来的研究。
### Conclusion
我们的结果证明了早期视觉系统中可靠解码的可行性和实际意义，并为神经科学和神经工程应用提供了实用见解。
## 743. `cs.LG` - 使用N-BEATS和图神经网络的多变量半导体制造过程时序无监督异常预测 [PDF](https://arxiv.org/pdf/2510.20718), [HTML](https://arxiv.org/abs/2510.20718)
### Authors
Daniel Sorensen,Bappaditya Dey,Minjin Hwang,Sandip Halder
### Background
半导体制造是一个复杂且精度要求高的过程，涉及成千上万个不同工具和工艺步骤中的相关参数。多变量时间序列分析在这些环境中的实时监控和故障检测中起着关键作用。然而，在半导体制造中进行异常预测面临一些重要挑战，包括高维度的传感器数据和由于实际故障的罕见性而引起的严重类别不平衡。此外，变量之间的复杂关系增加了异常预测和根本原因分析的难度。
### Innovation
本文提出了两种新的方法，将异常检测推进到异常预测，这是实现实时过程校正和提前故障预防的一个重要步骤。提出的异常预测框架包括两个主要阶段：(a) 在假设数据集中没有异常的情况下训练一个预测模型，(b) 对未见过的时间序列数据进行预测。预测结果与训练信号的预测进行比较。超出预定义阈值的偏差被标记为异常。两种方法在预测模型的选择上有所不同。第一种方法通过利用N-BEATS模型进行单变量时间序列预测来假设变量之间的独立性。第二种方法通过利用图神经网络来捕捉变量间的相互关系而克服了这一点。两种模型均表现出强大的预测性能，总体预测异性能保持稳定。图神经网络无论在性能还是计算成本上都优于N-BEATS模型，这使其成为在线异常预测的一个有前景的解决方案，在制造环境中部署有希望。
### Conclusion
本文提出的方法通过使用图神经网络在半导体制造中实现了多变量过程时间序列的无监督异常预测，并证明这种模型在性能和计算成本上都优于N-BEATS模型。
## 744. `cs.LG` - 利用变分狄利克雷过程放大多模态学习中的显著表示 [PDF](https://arxiv.org/pdf/2510.20736), [HTML](https://arxiv.org/abs/2510.20736)
### Authors
Tsai Hor Chan,Feng Wu,Yihang Chen,Guosheng Yin,Lequan Yu
### Background
在许多现实场景中，如医疗保健和金融领域，开发有效的多模态融合方法变得越来越重要。关键挑战是如何在学习跨模态交互的同时保持每个模态的特征表达能力。之前的多模态学习方法主要集中在跨模态对齐上，但过度强调模态边缘分布的对齐可能会引入过多的正则化，阻碍每个模态中的有意义表示。狄利克雷过程（DP）混合模型作为一种强大的贝叶斯非参数方法，可以通过其更丰富的性质放大最显著的特征。
### Innovation
受DP特性的启发，本文提出了一种新的DP驱动的多模态学习框架，可以自动实现显著模内表示学习和跨模态对齐之间的最优平衡。具体来说，假设每个模态遵循多元高斯分布的混合模型，并利用DP计算所有组件的混合权重。这一范式允许DP动态分配特征的贡献并选择最显著的特征，利用其更丰富的性质，从而促进多模态特征融合。实验结果表明，该模型在多个多模态数据集上的性能优于其他竞争对手。进一步的消融分析验证了DP在对齐模态分布和对关键超参数变化的鲁棒性方面的有效性。
### Conclusion
本文提出的DP驱动的多模态学习框架有效地解决了多模态学习中的显著特征放大问题，并且在性能和鲁棒性方面优于其他方法。
## 745. `cs.LG` - 多智能体合作中的思辨通信 [PDF](https://arxiv.org/pdf/2510.20733), [HTML](https://arxiv.org/abs/2510.20733)
### Authors
Yujia Zheng,Zhuokai Zhao,Zijian Li,Yaqi Xie,Mingze Gao,Lizhu Zhang,Kun Zhang
### Background
自然语言长期以来促使人类进行合作，但其具有的信息损失、含糊不清和间接性等特点限制了集体智能的潜力。尽管机器不受这些限制，但目前大多数基于大语言模型（LLM）的多智能体系统仍然依赖自然语言进行交互，通过交换标记或其嵌入来实现。为了超越语言，本文提出了思辨通信的新范式，让智能体能够直接进行心灵通讯，类似于心灵感应。为了解释这些潜在的思维，我们将过程形式化为一般的潜在变量模型，其中智能体的状态由未知的隐含思维生成函数生成。
### Innovation
提出了一种名为思辨通信的新范式，允许智能体直接进行心灵通讯。通过形式化过程为一个一般潜在变量模型，证明在无辅助信息的非参数设置中，可以识别任意智能体间共享和私有的潜在思维，同时还能恢复思维共享的全局结构。开发了一种框架，可以在通信之前提取所有智能体的潜在思维，并为每个智能体分配相关的思维及其共享模式。这种方法自然延伸到所有模态，因为大多数观察性数据都源自隐藏的生成过程。实验验证了理论的有效性，并展示了思考通讯的协作优势。
### Conclusion
这项工作展示了利用隐藏世界潜在价值的潜力，许多挑战目前仅通过表面观察无法解决，无论计算能力和数据规模多大。思辨通信在多智能体合作中展现出巨大的协作优势，并为未来的智能系统设计提供了新的视角。
## 746. `cs.LG` - BadGraph：针对文本引导图生成的潜在扩散模型后门攻击 [PDF](https://arxiv.org/pdf/2510.20792), [HTML](https://arxiv.org/abs/2510.20792)
### Authors
Liang Ye,Shengqin Chen,Jiazhu Dai
### Background
图生成技术的快速发展引发了新的安全担忧，尤其是后门漏洞。尽管已有研究探讨了图生成中的后门攻击，但在条件图生成，尤其是文本引导图生成方面，这一领域仍有许多未被探索。
### Innovation
本文提出了BadGraph，一种针对潜在扩散模型的文本引导图生成后门攻击方法。BadGraph利用文本触发器来污染训练数据，秘密植入一个后门，当触发器在推理过程中出现时，会诱导攻击者指定的子图，但在干净输入上保持基本性能。
### Conclusion
通过对四个基准数据集（PubChem，ChEBI-20，PCDes，MoMu）的广泛实验，表明后门攻击的有效性和隐蔽性。低至10%的污染率可实现50%的成功率，而24%的率则可以超过80%的成功率，且对良性样本的性能影响甚微。进一步的消融研究显示，后门是在VAE和扩散模型的训练过程中植入的，而非预训练阶段。这些结果揭示了文本引导图生成中潜在扩散模型的安全漏洞，强调了在这些模型中的应用（如药物发现）中存在的重大风险，并突显了针对此类扩散模型后门攻击的鲁棒防御需求。
## 747. `cs.LG` - 在不同分布测试中揭示国际象棋变换器的组合性 [PDF](https://arxiv.org/pdf/2510.20783), [HTML](https://arxiv.org/abs/2510.20783)
### Authors
Anna Mészáros,Patrik Reizinger,Ferenc Huszár
### Background
国际象棋是一个典型的需要严谨推理和长期规划的任务。现代决策变换器（如大语言模型所训练的方式）能够学习玩棋规则，但对其是否真正捕捉到国际象棋规则的了解尚不清楚。为此，该研究通过训练一个含270M参数的国际象棋变换器，并在设计来揭示系统泛化的失败情况的测试场景中进行测试，以探索这一点。实验结果显示，变换器表现出组合泛化的现象，即通过严格遵循游戏的基本语法规则并恒定地选择有效棋子移动来展示出较强的游戏规则外推能力，即使面对与训练数据迥异的情况。此外，它们对于出分布（OOD）场景也生成高质量的棋步。在更为严格的测试中，研究对包括随机国际象棋（Fischer Random Chess）在内的游戏变种进行了评估。研究发现，虽然模型展示了基本策略的适应性，但在与Lichess用户对战时，它们的表现不如进行明确搜索的符号AI算法，不过差距在LSIChess用户对战时减小了。通过对训练动态的观察发现，模型早期学习移动的是自己的棋子，显示出对游戏的新兴组合理解。
### Innovation
该研究通过训练大参数量的国际象棋变换器，并在设计用于揭示系统泛化失败的测试场景中测试它，来探究变换器是否真正掌握了国际象棋规则。实验结果展示出了变换器的能力，不仅年里表现了强大的规则外推能力，还能够为出分布场景生成高质量的棋步。此外，该研究还对包括随机国际象棋在内的游戏变种进行了评估，并展示了模型在某些场景下的局限性。
### Conclusion
该变换器对国际象棋表现出组合泛化的现象，尽管具备基本策略适应性，但在某些具体场景（如随机国际象棋）下，与特定算法相比有一定的局限性，但仍展示了其在国际象棋中的强大推断与规划能力。
## 748. `cs.LG` - Compress to Impress: Efficient LLM Adaptation Using a Single Gradient Step on 100 Samples [PDF](https://arxiv.org/pdf/2510.20800), [HTML](https://arxiv.org/abs/2510.20800)
### Authors
Shiva Sreeram,Alaa Maalouf,Pratyusha Sharma,Daniela Rus
### Background
最近，Sharma等人提出了一种称为Layer-SElective-Rank reduction (LASER)的方法，该方法表明，通过剪除精心挑选的大型语言模型（LLM）权重矩阵中的高阶组件，可以在没有基于梯度的微调的情况下提高下游任务的准确性。但是，LASER需要对每个矩阵进行完整的数据前向传播搜索，这使得其在快速部署时变得不切实际。
### Innovation
研究发现，（i）只需检查一小部分精心挑选的矩阵即可，无需逐层扫描；（ii）每个矩阵奇异值的梯度可以确定哪些矩阵需要减少；（iii）通过允许矩阵的行围绕多个子空间聚集并分别分解每个集群来增加因子分解搜索空间，可以进一步降低对原始训练数据的过拟合并提高准确性24.6个百分点；（iv）评估仅使用100个样本而非完整训练数据计算指示性梯度和测量最终准确性可以进一步减少搜索时间，因为下游任务的适应主要依赖于指令风格而非数据集大小；（v）结合这些发现，提出了一种快速且稳健的下游任务自适应算法，在100个示例上执行一次梯度步骤并快速扫描候选层和分解技术即可适应LLMs。
### Conclusion
研究展示了这些发现的应用，形成了一种快速且稳健的下游任务自适应算法。通过在100个示例上执行一次梯度步骤并快速扫描候选层和分解技术，可以在不进行微调的情况下适应LLMs。
## 749. `cs.LG` - KL-正则化强化学习旨在模式崩溃 [PDF](https://arxiv.org/pdf/2510.20817), [HTML](https://arxiv.org/abs/2510.20817)
### Authors
Anthony GX-Chen,Jatin Prakash,Jeff Guo,Rob Fergus,Rajesh Ranganath
### Background
人们普遍认为，优化逆KL散度会导致‘模式寻求’，而优化前向KL则会导致‘质量覆盖’。在样本多样性的目标下，后者更受欢迎。然而，该研究表明，这种直觉在使用逆/前向KL正则化的强化学习中并不能很好地转移，例如在语言模型中常见的情况下。正则化类型决定了最优目标分布的家族，而模式覆盖主要取决于其他因素，如正则化强度以及奖励和参考概率之间的相对规模。
### Innovation
该研究揭示了常用的低正则化强度和相等可验证奖励设置往往会指定单模目标分布，这导致优化目标本身不具有多样性。基于这些见解，他们提出了一种简单、可扩展且具有理论依据的算法。该算法对奖励幅度的改动很小，却能够在所有高质采样模式上引入高概率。实验表明，这种简单的修改可以提高大型语言模型和化学语言模型的解决方案质量和多样性，而且不需要任何外在的多样性信号；当使用逆/前向KL正则化失效时，该算法依然有效。
### Conclusion
该研究结果表明，KL-正则化强化学习不仅会导致模式寻求，还可能因为不当设置而丢失多样性。通过选择适当的正则化类型和参数，可以优化出高质量且多样性的解决方案。
## 750. `cs.LG` - 关联尖峰模型中的谱阈值及其部分最小平方的基本限制 [PDF](https://arxiv.org/pdf/2510.17561), [HTML](https://arxiv.org/abs/2510.17561)
### Authors
Pierre Mergny,Lenka Zdeborová
### Background
该研究关注的是两种高维数据通道之间部分对齐的信号，这类模型由多模态学习动机驱动，并作为部分最小二乘(Partial Least Squares, PLS)方法的标准生成设置。PLS 是一个广泛使用但在理论上尚未充分开发的方法。研究背景强调了理解这类模型信号恢复能力的重要性和现有理论的局限性。
### Innovation
该研究通过严谨的随机矩阵理论分析，揭示了样本交叉协方差矩阵的首要奇异值经历了一种类似Baik-Ben Arous-Peche (BBP)类型的相变，并精确刻画了信息性成分出现的临界点。这一工作首次给出了PLS在这一设置下信号恢复能力的精确渐近描述，揭示了PLS与贝叶斯最优估计器之间的基本性能差异。特别地，该研究定义了PLS在理论上可检测，但实际无法恢复信号的SNR和相关性区间。
### Conclusion
这项研究澄清了PLS在高维环境下理论限制，并为设计可靠的多模态推理方法提供了指导。
## 751. `cs.LG` - SSL-SE-EEG: 一种基于自监督学习和压缩-激励网络的无标签EEG数据鲁棒学习框架 [PDF](https://arxiv.org/pdf/2510.19829), [HTML](https://arxiv.org/abs/2510.19829)
### Authors
Meghna Roy Chowdhury,Yi Ding,Shreyas Sen
### Background
脑电图（EEG）在脑-机接口（BCI）和神经学诊断中扮演着重要角色，但其在现实中的应用面临着噪声伪迹、数据缺失和标注成本高的挑战。
### Innovation
提出了一种名为SSL-SE-EEG的框架，将自监督学习（SSL）与Squeeze-and-Excitation Networks（SE-Nets）相结合，以提升特征提取效果、增强噪声鲁棒性，并减少对标注数据的依赖。EEG信号被转换为结构化的2D图像表示，适合用于深度学习处理。
### Conclusion
通过在MindBigData、TUH-AB、SEED-IV和BCI-IV数据集上的实验验证，SSL-SE-EEG展示了在MindBigData数据集上达到91%、在TUH-AB数据集上达到85%的最先进的准确性，使其适合用于实时BCI应用。通过低功耗且可扩展的EEG处理，SSL-SE-EEG为生物医学信号分析、神经工程和下一代BCI提供了有前景的解决方案。
## 752. `cs.LG` - Branch-and-Browse: 效率高且可控的树状推理与行动记忆驱动的网络探索 [PDF](https://arxiv.org/pdf/2510.19838), [HTML](https://arxiv.org/abs/2510.19838)
### Authors
Shiqi He,Yue Cui,Xinyu Ma,Yaliang Li,Bolin Ding,Mosharaf Chowdhury
### Background
自主网络代理（由大型语言模型驱动）在执行信息检索、报告生成和在线交易等目标任务方面表现出强大的潜力。现有的方法在推理深度和效率上仍有限制：简单的线性方法不擅长多步骤推理且缺乏有效的回溯，而其他搜索策略则细粒度过低且计算成本高。开放网络环境中的实用化体现推理仍然是一个关键挑战。
### Innovation
作者提出了一个称为Branch-and-Browse的新框架，该框架统一了结构化推理-行动、上下文记忆和高效执行。具体地，它：(i) 使用树结构探索进行显式子任务管理，以实现可控的多分支推理；(ii) 通过高效重温网络状态并利用背景推理启动探索；(iii) 利用页面动作记忆，在不同会话之间共享已探索的动作。在WebArena基准测试中，Branch-and-Browse实现了高达35.8%的任务成功率，并将执行时间减少了最多40.4%。这些结果表明，Branch-and-Browse是一个可靠且高效的基于LLM的网络代理框架。
### Conclusion
实验结果表明，Branch-and-Browse可以成为LSTM网络代理开发中的一个可靠且高效的框架。
## 753. `cs.LG` - DAG-Math: 在LLMs中基于图指导的数学推理 [PDF](https://arxiv.org/pdf/2510.19842), [HTML](https://arxiv.org/abs/2510.19842)
### Authors
Yuanhe Zhang,Ilja Kuzborskij,Jason D. Lee,Chenlei Leng,Fanghui Liu
### Background
大规模语言模型（LLMs）在得到链式思考（CoT，Chain-of-Thought）提示时，表现出了强大的数学问题解决能力，但这种成功背后的原因尚不明确，可能是由于搜索、机械步骤或规则一致的推理。本文旨在探讨这个问题。
### Innovation
本文提出了一种新的框架，将链式思考建模为有向无环图（DAG，Directed Acyclic Graph）上的确定性规则基随机过程。借助于这种方法，作者引入了逻辑接近度作为评价标准，用于衡量模型的链式思考轨迹与DAG结构的契合程度。此外，设计了一个新的CoT格式（DAG-MATH CoT）的基准测试，以指导LLMs生成符合DAG结构的链式思考轨迹，从而评估其推理能力。研究结果表明，即使最终答案相似，不同LLM家族在推理精度上存在统计显著差异，强调了最终答案与规则一致推理之间的差异。
### Conclusion
本文框架在自由形式的链式思考和形式证明系统之间提供了一个平衡，为LLMs的推理能力评估提供了具体诊断工具。所提出的基准和代码可以在提供的链接获取。
## 754. `cs.LG` - 利用多分辨率分析对热带气旋对流结构的研究以提供短期强度指导 [PDF](https://arxiv.org/pdf/2510.19854), [HTML](https://arxiv.org/abs/2510.19854)
### Authors
Elizabeth Cucuzzella,Tria McNeely,Kimberly Wood,Ann B. Lee
### Background
在大西洋热带气旋（TC）盆地，24小时预报期内的准确短期强度预报对于灾害减缓至关重要。大多数TC远离陆地观测网络发展，因此卫星图像对于监测这些风暴至关重要。然而，预报员难以实时定性地解释这些复杂且高分辨率的空间结构。因此，需要一种简洁、可解释且描述性的方法来用多分辨率分析（MRA）中的离散小波变换量化TC的精细结构，从而帮助数据分析师识别与快速强度变化高度关联的物理上有意义的结构特征。此外，深度学习技术可以在此基础上为短期强度指导提供支持。
### Innovation
本文提出了一种简洁的、可解释的、描述性的方法，通过多分辨率分析（使用离散小波变换），量化热带气旋的精细结构，使得数据分析师能够识别出与快速强度变化紧密相关的物理上意义的结构特征。此外，该研究还探讨了如何利用此多分辨率分析进一步提高短期强度预测的准确性，结合深度学习技术提供短期强度指导。
### Conclusion
该研究展示了多分辨率分析在理解TC复杂结构和预测TC短期强度变化中的潜在价值。该方法提供了一种新的视角，通过离散小波变换不仅可以快速提取出具有重要气象意义的结构特征，还支持后续的深度学习应用，从而提供更加准确的短期强度预报，帮助提升灾害应对能力。
## 755. `cs.LG` - 边缘设备上低延迟的神经推断以实现基于EEG信号的实时手写识别 [PDF](https://arxiv.org/pdf/2510.19832), [HTML](https://arxiv.org/abs/2510.19832)
### Authors
Ovishake Sen,Raghav Soni,Darpan Virmani,Akshar Parekh,Patrick Lehman,Sarthak Jena,Adithi Katikhaneni,Adam Khalifa,Baibhab Chatterjee
### Background
脑机接口（BCIs）为严重运动或言语障碍者恢复沟通提供了一种途径。想象中的手写提供了一种直观的神经解码模式，将人类意图与数字通信连接起来。虽然侵入式的电皮层图谱（ECoG）方法能够实现高准确性，但由于其手术风险，难以广泛采用。非侵入式的脑电图（EEG）方法则因其更低的信噪比和空间分辨率，解码精度受限。本文旨在通过结合先进的机器学习和信息性的EEG特征提取，克服这些障碍，实现能够在便携边缘设备上实现实时、高准确度的神经解码。
### Innovation
本文提出了一种结合时域卷积神经网络和多层感知器的混合架构EEdGeNet，用于非侵入式EEG神经解码。通过在便携式边缘设备上部署该系统，实现了89.83%的高准确度和每字符914.18毫秒的低延迟。进一步选择十个关键特征，将延迟减少四倍至202.6毫秒，同时损失不到1%的准确度。
### Conclusion
研究结果表明，基于先进的机器学习和EEG特征提取的非侵入式BCIs实现了准确、低延迟且完全便携的特性，为实时通信提供了可行的解决方案。
## 756. `cs.LG` - 神经震颤：一种用于支持上肢肌肉功能的可穿戴支持设备 [PDF](https://arxiv.org/pdf/2510.19826), [HTML](https://arxiv.org/abs/2510.19826)
### Authors
Aueaphum Aueawattthanaphisut,Thanyanee Srichaisak,Arissa Ieochai
### Background
介绍了上肢功能（肱三头肌和拇短伸肌）的一种融合了传感器的便携辅助原型。该设备集成了表面肌电图（sEMG）、惯性测量单元（IMU）、弯折/力传感器和M5StickC以及ESP32-S3计算枢纽。传感器信号经过带通和窄带滤波；在250毫秒的窗口内计算特征（均方根值、动静态量、零交叉和4-12 Hz的震颤带功率），并传递给INT8的TensorFlow Lite Micro模型。控制命令通过控制屏障函数的安全边界线进行限制，并在基于游戏的任务中实现轻量级个人化。在这项技术可行性评估中，12名健康志愿者进行了三项日常生活活动任务，结果显示震颤突出度降低、关节活动范围增加、重复动作次数增加、肌电中频斜率变得更不负面；系统运行频率为100 Hz，中位设备延迟为8.7毫秒，所有会话完成，没有设备相关的不良事件。这些结果表明，内置的、融合传感器的辅助技术对于上肢功能是可行的；计划在IRB监管下进行正式的患者研究。
### Innovation
该项目提出了一种便携式的辅助原型设备，将表面肌电图（sEMG）、惯性测量单元（IMU）和弯折/力传感器集成在一起，并通过控制屏障函数安全边界线限制控制命令来安全有效地辅助上肢功能。该系统进行了100 Hz的实时运行，中位设备延迟仅为8.7毫秒，展示了其高性能特性。技术的可行性通过健康志愿者进行了验证，并且没有不良事件记录。
### Conclusion
该研究结果证明了嵌入式、融合传感器的辅助设备对于上肢功能的支持技术的可行性。研究团队计划在IRB的监管下进一步进行患者的正式研究，以验证该设备在实际应用中的表现。
## 757. `cs.LG` - 基于人工智能识别榕树潜在的抗糖尿病化合物 [PDF](https://arxiv.org/pdf/2510.19867), [HTML](https://arxiv.org/abs/2510.19867)
### Authors
Md Ashad Alam,Md Amanullah
### Background
糖尿病是一种由于其渐进性发展和代谢并发症的出现而需要新型治疗方法的慢性代谢障碍。研究发现，榕树是一种具有潜在抗糖尿病活性生物活性植物化学物质的常规药用植物。本研究利用基于生态系统的计算方法，结合人工智能，探究并评估从榕树中提取的具有抗糖尿病活性的化合物。该研究通过集成机器学习方法、分子对接技术和ADMET预测系统，评估植物化学物质对关键抗糖尿病酶二肽酶-4 (DPP-4) 的抑制作用。
### Innovation
引入了基于人工智能加速筛选过程，并提高了准确性，展示了其在研究基于植物的抗糖尿病剂方面的有效性。这一点对于未来糖尿病管理的自然产品疗法的实验验证提供了科学基础，从而提升了疗法的适应性和针对性。
### Conclusion
该研究中的深度绑定GCN和AutoDock软件通过深度学习技术研究了结合交互作用，结果表明黄酮类和生物碱等植物化学物质因其强烈的结合作用和有利的药理效应，成为吸引人的候选化合物。人工智能加速了筛选过程，提高了准确性，显示了其在研究基于植物的抗糖尿病剂方面的有效性，为糖尿病管理的自然疗法的未来实验验证提供了科学基础。
## 758. `cs.LG` - 量化在线内容审核中特征的重要性 [PDF](https://arxiv.org/pdf/2510.19882), [HTML](https://arxiv.org/abs/2510.19882)
### Authors
Benedetta Tessa,Alejandro Moreo,Stefano Cresci,Tiziano Fagni,Fabrizio Sebastiani
### Background
准确估算用户对审核干预的反应对于开发有效的、用户中心化的审核策略至关重要。这需要明确理解哪些用户特征与不同的行为反应相关。本篇研究旨在研究16800个受到Reddit大规模审核干预影响的用户在753个社会行为、语言、关系和心理特征方面的信息性，以预测他们行为的变化。
### Innovation
研究采用了贪婪特征选择策略，既识别出最能预测用户活动、毒性和参与多样性变化的特征，也估计了这些特征的重要性。研究表明，许多特征仅对特定任务有用，有些则几乎无用。此外，预测表现因任务而异，活动和毒性变化比多样性变化更容易估计。研究结果为开发准确预测用户对审核干预反应的系统铺平了道路，并突显出了后审核用户行为的复杂性，强调了审核应不仅针对用户特质，也针对干预的具体目标进行调整的重要性。
### Conclusion
本研究通过量化特征的重要性，为开发更准确的系统预测用户对审核干预的反应提供了方法，同时也揭示了后审核用户行为的复杂性，希望这能够指导未来更有效的在线内容管理策略的制定。
## 759. `cs.LG` - 使用GAN进行多组学整合：在阿尔茨海默病及癌症中的应用 [PDF](https://arxiv.org/pdf/2510.19870), [HTML](https://arxiv.org/abs/2510.19870)
### Authors
Md Selim Reza,Sabrin Afroz,Mostafizer Rahman,Md Ashad Alam
### Background
多组学数据整合对于理解复杂疾病至关重要，但有限的样本数量、噪声和异质性常会限制其预测能力。为了应对这些挑战，研究引入了基于生成对抗网络（GAN）的Omics-GAN框架，该框架旨在生成高质量的合成多组学资料，同时保留生物关系。研究使用包括阿尔茨海默病（AD）、结肠癌和肝癌在内的数据集进行了评估。结果显示，与原始组学资料相比，合成数据集在提高预测准确性方面表现更佳，尤其在RNA、miRNA和甲基化数据方面。此外，合成数据保留了统计分布、降低了噪声和异常值，并通过功能基因组学和KEGG富集分析确定了显著基因，从而加快了生物标志物和药物发现，为精准医疗提供了可扩展的策略。
### Innovation
研究提出了基于GAN的Omics-GAN框架，用于生成高质量的合成多组学资料，该框架能够保留生物关系并提高在不同疾病中的预测准确性。通过与原始数据集的对比，验证了合成数据在阿尔茨海默病、结肠癌及肝癌领域预测表现的提升，同时通过GO和KEGG富集分析发现了新的候选基因，利用分子对接技术发现了潜在的药物重新定位候选药物，如尼洛替尼、阿托伐醌和特可维瑞。
### Conclusion
Omics-GAN提升了疾病的预测能力，保留了生物的准确性，并加速了生物标志物和药物的发现过程，提供了精准医疗的可扩展应用策略。
## 760. `cs.LG` - 基于语义和情景记忆从监督中学习：一种代理适应的反思性方法 [PDF](https://arxiv.org/pdf/2510.19897), [HTML](https://arxiv.org/abs/2510.19897)
### Authors
Jackson Hassell,Dan Zhang,Hannah Kim,Tom Mitchell,Estevam Hruschka
### Background
传统的方法，如微调，在学习目标分类函数时往往成本高、灵活性差且不透明。本研究旨在探讨利用预训练的大语言模型构建的代理如何在不需要参数更新的情况下从标记的实例中学习目标分类功能。
### Innovation
提出了一个结合了标记数据和大语言模型生成的批判意见的记忆增强框架。该框架利用情景记忆存储实例级批判意见，并将它们提炼为可重用的任务级指导。研究还引入了一个名为suggestibility的新颖度量，用于解释代理对不同形式监督表现行为的响应，从而揭示了模型特性和记忆策略如何共同影响学习动态。
### Conclusion
研究结果表明，利用记忆驱动的、反思性的学习方法有助于构建更具适应性和解释性的大语言模型代理。此方法在多种任务中展示了显著的优势，特别是在处理事实导向的数据和偏好导向的数据时表现出不同方式的行为差异。
## 761. `cs.LG` - 基于深度序列模型的GNSS欺骗检测 [PDF](https://arxiv.org/pdf/2510.19890), [HTML](https://arxiv.org/abs/2510.19890)
### Authors
Jan Zelinka,Oliver Kost,Marek Hrúz
### Background
本研究旨在通过构建数据生成框架来模拟欺骗攻击，并在世界各地随机放置攻击场景。同时，使用基于深度神经网络的模型进行欺骗检测，这些模型特别是针对在线检测设计，并使用生成的数据集进行训练。研究表明，深度学习模型能够准确地区分欺骗信号和真实信号，实现高检测性能。最佳结果来自于受Transformer启发的架构，输入的早期融合导致错误率为0.16%。
### Innovation
本研究创新在于构建了一个数据生成框架，能够模拟欺骗攻击并随机分布全球各地的攻击场景；使用长短期记忆网络和受Transformer启发的架构进行欺骗检测；尤其是针对在线检测进行了设计和训练；通过深度学习模型，尤其是在受Transformer启发的架构上实现早期融合输入，显著提升了检测性能。
### Conclusion
研究表明，利用深度学习模型，尤其是受Transformer启发的架构，可以实现高精度的GNSS欺骗信号检测。输入的早期融合优化了模型性能，最终错误率为0.16%，有效地提升了欺骗检测的准确性。
## 762. `cs.LG` - 压缩生物学：评估Stable Diffusion变分自编码器在表型药物发现中的应用 [PDF](https://arxiv.org/pdf/2510.19887), [HTML](https://arxiv.org/abs/2510.19887)
### Authors
Télio Cropsal,Rocío Mercado
### Background
高通量表型筛选产生了大量显微镜图像数据，对生成模型的维度提出了挑战。尽管通用模型在自然图像上的训练日益受到显微镜数据处理的青睐，但它们在该领域的有效性尚未得到定量验证。Stable Diffusion的变分自编码器(SD-VAE)首次被系统地评估用于重建Cell Painting图像，评估其在包含多样分子扰动和细胞类型的大数据集中的性能。通用特征提取器如InceptionV3在检索任务中表现出色，简化了未来的处理流程。
### Innovation
首次使用SD-VAE对Cell Painting图像进行重建评估，系统地比较了多种评估指标以进行生物信息学评价。展示了通用特征提取器如InceptionV3在检索任务中能够匹配或超越公开的专业模型，简化了显微镜数据分析流程。提出了对生成模型在显微镜数据上的评估指南，支持使用现成模型在表型药物发现中的应用。
### Conclusion
SD-VAE在显微镜图像数据的重建中表现出色，具有保留表型信号能力。通用特征提取器如InceptionV3在检索任务中有卓越表现，简化了模块化流程。研究提供了一种系统评估生成模型在显微镜数据分析中的有效性的方法，并支持使用现成模型应用于表型药物发现。
## 763. `cs.LG` - LyriCAR：一种面向可控歌词翻译的难度感知课程强化学习框架 [PDF](https://arxiv.org/pdf/2510.19967), [HTML](https://arxiv.org/abs/2510.19967)
### Authors
Le Ren,Xiangjian Zeng,Qingqiang Wu,Ruoxuan Liang
### Background
歌词翻译是一个具有挑战性的任务，需要平衡多种音乐约束。现有方法通常依赖手工设计的规则和基于句子的建模，这限制了其理解音乐-语言模式并在段落级别有效泛化的能力，特别是在跨行连贯性和整体韵律方面至关重要。
### Innovation
本文提出了LyriCAR，一种新的在完全无监督条件下运行的可控歌词翻译框架。LyriCAR引入了一种感知难度的课程设计师和自适应课程策略，确保高效地分配训练资源，加快收敛速度，并通过逐步增强模型的挑战性来提高整体翻译质量。
### Conclusion
在EN-ZH歌词翻译任务上的广泛实验表明，LyriCAR在标准翻译指标和多维度奖励评分方面均实现了最先进的结果，超越了强劲的基线模型。值得注意的是，自适应课程策略使训练步数减少了近40%，同时保持了更好的性能。代码、数据和模型可以在以下链接访问：this https URL.
## 764. `cs.LG` - 引导扩散模型从稀疏数据重构流场 [PDF](https://arxiv.org/pdf/2510.19971), [HTML](https://arxiv.org/abs/2510.19971)
### Authors
Marc Amorós-Trepat,Luis Medrano-Navarro,Qiang Liu,Luca Guastoni,Nils Thuerey
### Background
流场的瞬变流场重建是一项在许多工程应用中具有挑战性和关键性的任务。由于机器学习模型能够从数据中learn复杂的模式，并且在不同条件下泛化，因此它们在解决这个问题时变得流行。扩散模型因其在生成任务中的强大表现而受到重视，它们通过逐步改进噪声输入产生高质量样本。与其他方法不同的是，这些生成模型能够重构流体频谱中的最小子尺度。
### Innovation
本文提出了一种新的扩散模型采样方法，通过使用可用的稀疏数据引导反向过程，使模型能够生成高保真的重构样本。此外，在训练过程中使用无冲突更新方法结合可用的物理知识增强重构结果。
### Conclusion
通过在2D和3D湍流流场数据上进行实验，我们证明了该方法在预测流体结构和像素精度方面优于其他基于扩散的方法。该研究强调了扩散模型在重构流场数据方面的巨大潜力，并为它们在计算流体动力学研究中的应用开辟了道路。
## 765. `cs.LG` - RELATE：一种针对多模态关系图的无模式感知视知觉编码器 [PDF](https://arxiv.org/pdf/2510.19954), [HTML](https://arxiv.org/abs/2510.19954)
### Authors
Joseph Meyer,Divyansha Lachi,Reza Mohammadi,Roshan Reddy Upendra,Eva L. Dyer,Mark Li,Tom Palczewski
### Background
在电子商务、医疗保健和科学研究等领域中，多表关系数据是常见的，这些数据可以自然地表示为具有多模态节点属性的异构时序图。现有的图神经网络（GNN）依赖于特定模式的特征编码器，需要为每种节点类型和特征列分别设计模块，这限制了其可扩展性和参数共享。
### Innovation
我们引入了RELATE（关系编码器以蕴含类型实体的潜在聚集），这是一种与模式无关可插拔的特征编码器，可以与任何通用图神经网络一同使用。RELATE采用了共享的模态特定编码器对分类、数值、文本和时间属性进行编码，然后通过视知觉式的跨注意力模块将特征聚合为一个固定大小、置换不变的节点表示。
### Conclusion
我们在RelBench基准上的ReLGNN和HGT中评估了RELATE，它在性能上能够达到与特定模式编码器相同的水平，同时参数量最多减少了5倍。这种设计支持不同的模式变化，并使通用图神经网络能够在多个数据集上进行预训练，为关系图数据的基础模型铺平了道路。
## 766. `cs.LG` - 增强的循环坐标下降方法用于弹性网正则化线性模型 [PDF](https://arxiv.org/pdf/2510.19999), [HTML](https://arxiv.org/abs/2510.19999)
### Authors
Yixiao Wang,Zishan Shao,Ting Jiang,Aditya Devarakonda
### Background
提出了一个用于解决具有弹性网约束的广义线性模型的新颖增强循环坐标下降(ECCD)框架，与现有的先进方法相比，这种方法可以减少训练时间。
### Innovation
通过在当前迭代点附近展开梯度计算的泰勒展开式来重新设计CD方法，避免了非线性操作，将循环向量展开为更有效的批处理计算重新表述。此参数可通过可调整整数参数s控制，其中s>1可提高性能而不影响收敛，s=1则恢复原始的CD方法。利用此方法解决了块坐标下降法的收敛延迟和数值不稳定问题。
### Conclusion
使用C++和Eigen进行了方法实现，表明该方法在多种基准数据集上相比现有最先进的求解器具有3倍左右的一致性能提升，其代码已公开可用。
## 767. `cs.LG` - 用随机搜索法投掷风藤：基于随机搜索的结构学习 [PDF](https://arxiv.org/pdf/2510.20035), [HTML](https://arxiv.org/abs/2510.20035)
### Authors
Thibault Vatter,Thomas Nagler
### Background
 Vine copulas 提供了灵活的多变量依赖建模方式，并在机器学习中得到了广泛应用，但结构学习仍然是一个关键挑战。早期的启发式方法如 Dissmann 的贪婪算法虽然仍是金标准，但常常不够最优。
### Innovation
 提出了基于随机搜索的结构选择方法，并建立了一个统计框架，该框架基于模型置信集，提供了选择概率的理论保证，并为集成方法奠定了坚实的基础。
### Conclusion
 在多个真实数据集上的实证结果显示，所提出的这些方法稳定地优于现有最佳方法。
## 768. `cs.LG` - SecureInfer: 混合 TEE-GPU 架构用于大型语言模型部署中的隐私关键张量 [PDF](https://arxiv.org/pdf/2510.19979), [HTML](https://arxiv.org/abs/2510.19979)
### Authors
Tushar Nayan(1),Ziqi Zhang(2),Ruimin Sun(1) ((1) Florida International University, (2) University of Illinois Urbana-Champaign)
### Background
随着大型语言模型（LLMs）在移动和边缘平台上越来越广泛地部署，保护它们免受模型抽取攻击已成为一个紧迫的问题。然而，如何在不牺牲基于不可信加速器（例如GPU）带来的性能优势的同时保护模型的隐私，仍是一个具有挑战性的权衡。
### Innovation
本文提出了SecureInfer，一种利用异构可信执行环境（TEEs）-GPU 架构的混合框架，在不牺牲性能的情况下隔离隐私关键组件，并将计算密集型操作卸载到不可信加速器上。SecureInfer 采用一种基于信息论和威胁感知的分区策略：将安全性敏感组件（包括非线性层、注意力头投影、FNN 变换和 LoRA 调理器）在 SGX 壁垒中执行，而其他线性操作（矩阵乘法）则在加密后于 GPU 上执行，并在回填至 enclave 时保持安全。
### Conclusion
我们的研究结果表明，SecureInfer 在保证安全的同时，提供了合理的性能，为设备上的安全模型推理提供了一个实际的解决方案。
## 769. `cs.LG` - SODBench：采用大规模语言模型记录电子表格操作的方法 [PDF](https://arxiv.org/pdf/2510.19864), [HTML](https://arxiv.org/abs/2510.19864)
### Authors
Amila Indika,Igor Molybog
### Background
许多知识工作者在商业、会计和金融领域使用电子表格，但由于缺乏系统化的电子表格文档方法，电子表格的自动化、协作和知识转移受到了阻碍，从而可能导致关键的机构知识丧失。因此，本文通过介绍电子表格操作文档（SOD），即从电子表格操作中生成人类可读的解释，来促进电子表格的文档记录，提升再现性、维护性和协作流程的可行性。
### Innovation
大多数先前的研究利用大型语言模型（LLMs）生成电子表格操作代码，但将代码转化为自然语言用于SOD尚属未被广泛探索的领域。为了解决这一问题，本文提出了一套由111个电子表格操作代码片段与相应自然语言摘要构成的基准测试SODBench，并评估了五种LLM在BLEU、GLEU、ROUGE-L和METEOR等衡量指标下的表现。研究结果表明，LLMs可以生成准确的电子表格文档，使SOD成为提升电子表格再现性、维护性和协作的工作流中的一项可行的前提步骤，但仍存在一些需要解决的挑战。
### Conclusion
本文通过SODBench基准测试展示了LLMs在SOD方面的潜力，但仍需进一步解决挑战，旨在推广使用SOD以增强电子表格的文档记录，提升其在协作和维护方面的能力。
## 770. `cs.LG` - 在希尔伯特空间中同时求解无穷多个LQ均场博弈：神经算子的强大力量 [PDF](https://arxiv.org/pdf/2510.20017), [HTML](https://arxiv.org/abs/2510.20017)
### Authors
Dena Firoozi,Anastasis Kratsios,Xuwei Yang
### Background
传统的均场博弈（MFG）求解器是针对每个实例单独操作的，当需要解决很多相关问题时变得不再可行。这包括在路径扰动下寻求数值稳定的解，或者涉及到无限个参数化的代理的环境中。
### Innovation
通过训练神经算子（NOs）来学习从LQ MFG规则（“规则”：动力学和代价函数）到相应的平衡策略的规则到均衡映射，本研究能够同时求解无穷多个LQ MFG。主要结果是提供了统计保证：即使在无限维的情况下，训练NO在少数随机抽取的规则上也能可靠地解决未见过的LQ MFG变种问题。并且，NO的参数数量在适当的规则抽取下不会不受控制。
### Conclusion
本研究的结果来源于三个关键发现：局部Lipschitz估计、利用具有特定Lipschitz正则性的NOs的通用逼近定理，以及对无限维度$L$-Lipschitz学习器的新样本复杂度界，这些新结果保证了在适当的规则抽取下，通过训练得到的NO可以有效解决未见过的LQ MFG问题。
## 771. `cs.LG` - 通过在线标签平滑提高医学影像预测置信度 [PDF](https://arxiv.org/pdf/2510.20011), [HTML](https://arxiv.org/abs/2510.20011)
### Authors
Kushan Choudhury,Shubhrodeep Roy,Ankur Chanda,Shubhajit Biswas,Somenath Kuiry
### Background
深度学习模型，尤其是卷积神经网络，在医学图像分类方面取得了显著成果。然而，这些模型往往会产生过于自信的预测，这会削弱其在关键医疗保健环境中的可靠性。传统的标签平滑虽然是减少这种自信的方法之一，但未能根据类别间的相互关系来调整标签，而是将非目标类别视为等价的。
### Innovation
本研究探讨了在线标签平滑（OLS）的应用，这是一种动态方法，通过根据模型自身的预测模式在整个训练过程中调整软标签来减少过拟合。我们在大规模的RadImageNet数据集上使用了三种常用架构（ResNet-50、MobileNetV2和VGG-19）评估了OLS的效果。结果显示，与标准训练方法（包括硬标签、常规标签平滑和无教师的知识蒸馏）相比，OLS可以显著提高Top-1和Top-5分类准确性，并且带来了更紧凑且分离良好的特征嵌入，表明改善了表示学习。这些发现表明，OLS不仅增强了预测性能，还提高了校准，使其成为开发可信赖的医疗影像领域人工智能系统的实用且有效的解决方案。
### Conclusion
在线标签平滑（OLS）通过根据模型自身的预测模式动态调整软标签，有效降低了过拟合。在RadImageNet数据集上，OLS提高了Top-1和Top-5分类准确性，增强了校准，提供了更紧凑且分离良好的特征嵌入，从而提高了医学影像领域的预测性能和可靠性，是开发可信赖的AI系统的有效方法。
## 772. `cs.LG` - 从事实到民间传说：评估大型语言模型的孟加拉国文化知识 [PDF](https://arxiv.org/pdf/2510.20043), [HTML](https://arxiv.org/abs/2510.20043)
### Authors
Nafis Chowdhury,Moinul Haque,Anika Ahmed,Nazia Tasnim,Md. Istiak Hossain Shihab,Sajjadur Rahman,Farig Sadeque
### Background
近年来，自然语言处理（NLP）研究展示了大型语言模型（LLMs）在广泛任务中的出色能力。虽然多语言基准测试提高了对LLMs的文化评估，但仍然存在捕捉低资源文化细微差别的关键缺陷。这项研究通过创建一个包括民间传统、烹饪艺术和区域方言在内的孟加拉语言文化知识（BLanCK）数据集来填补这一空白。研究发现，尽管这些多语言模型在非文化类别上表现良好，但在文化知识方面却面临巨大挑战，当提供上下文时，模型的性能显著改善，强调了上下文感知架构和文化定制训练数据的重要性。
### Innovation
该研究通过创建BLanCK数据集，填补了LLMs文化评估中的空白，尤其是在处理低资源文化细微差别方面。研究显示，上下文感知架构和文化定制训练数据对提高模型文化知识处理能力至关重要。
### Conclusion
尽管多语言模型在非文化类别上表现良好，但在文化知识处理方面依然面临显著挑战。通过提供上下文和采用文化定制训练数据，模型的性能得到了显著提升，这表明上下文感知架构在NLP中的重要性，也为未来研究提供了一个新的数据集和评估框架。
## 773. `cs.LG` - 使用量子电路编码矩阵 [PDF](https://arxiv.org/pdf/2510.20030), [HTML](https://arxiv.org/abs/2510.20030)
### Authors
Liron Mor Yosef,Haim Avron
### Background
十多年前，研究证明量子计算有潜力通过启用经典计算中无法达成其复杂度的算法来革新数值线性代数。例如，具有里程碑意义的HHL算法可用于解决线性系统问题。高效执行这些算法需要将输入（矩阵和向量）以量子电路形式表示，使其能够编码或实现这些输入。为此，文献中出现了两种常见的电路表示方法：块编码和状态准备电路。本文系统地研究了使用块编码和状态准备电路表示矩阵的方法，并探讨了从经典形式给出的矩阵构建这些表示的方法，以及这些电路表示之间的量子双向转换算法。这项研究进一步建立了两种关键技术成果：（a）一种高效构建任意矩阵块编码的一般方法（矩阵以经典随机存取内存中的条目形式给出）；(b) 低开销的块编码与状态准备电路之间的双向转换算法，表明这两种模型本质上是等价的。
### Innovation
本文研究了块编码和状态准备电路两种矩阵表示方法的构建方法，还提出了两种关键技术：（a）一种高效构建任意矩阵块编码的一般方法；(b) 低开销的块编码与状态准备电路之间的双向转换算法，表明这两种模型本质上是等价的。此外，本文介绍了某些新技术组件，如特殊常深度多路复用器和矩阵的标准基与更高阶Pauli基之间的量子转换算法。
### Conclusion
本文通过研究块编码和状态准备电路之间的转换，为构建任意矩阵的量子电路表示提供了新的方法，并证明了这两种模型之间的等价性，为未来的量子算法设计提供了更灵活、高效的工具。
## 774. `cs.LG` - LLMs可以隐藏文本于相同长度的其他文本中 [PDF](https://arxiv.org/pdf/2510.20075), [HTML](https://arxiv.org/abs/2510.20075)
### Authors
Antonio Norelli,Michael Bronstein
### Background
现有的大型语言模型（LLM）能够将有意义的文本隐藏在另一段完全不同的、但仍然连贯和可信的文本中，且长度相同。这种现象背后的技术基础是LLMs的强大生成能力，使得普通文本可以包含秘密信息而不被察觉。这一技术打破了文本与作者意图之间的联系，动摇了人们对书面交流的信任。
### Innovation
本文介绍了一种简单高效的方法，即使使用拥有8亿参数的小规模开源LLM也能够实现高质量的文本隐藏效果。编码和解码可以在笔记本电脑上以秒为单位完成，侧面展现了LLMs的先进性和普及性。
### Conclusion
这种文本隐藏技术表明，文本和其背后的意图之间存在极大的脱钩，影响了人们对人工智能理解的信任。这种可能性提出了AI安全的紧迫问题，并挑战了我们对大型语言模型知识的理解。
## 775. `cs.LG` - 大型数据集中的多重数据包络分析分数内生聚合 [PDF](https://arxiv.org/pdf/2510.20052), [HTML](https://arxiv.org/abs/2510.20052)
### Authors
Hashem Omrani,Raha Imanirad,Adam Diamant,Utkarsh Verma,Amol Verma,Fahad Razak
### Background
本文提出了一种使用数据包络分析（DEA）方法，在多个组织维度上进行动态效率评估的方法。这种方法可以生成维度特定和整体效率分数，并能整合有利和不利输出。通过引入两种正则化DEA模型，即基于余量的度量（SBM）和非线性目标规划模型的线性版本（GP-SBM），以便在大规模问题设置下适用。这些模型通过使用正则化参数增强区分能力，并能直接整合有利和不利输出。在多个数据集上展示了其计算效率和有效性，并应用于加拿大多伦多地区12家医院的病例研究，评估了自2018年1月至2019年12月期间的三维组织有效性：技术效率、临床效率和患者体验，采用SBM和GP-SBM模型更好的捕捉了输入/输出变量之间的联系，并在分离评估维度后再综合前的方法中表现出色。
### Innovation
本文介绍了两种正则化的DEA模型：基于余量的度量（SBM）和非线性目标规划模型的线性版本（GP-SBM）。而SBM模型首先估算总体效率并将其在维度间分配，GP-SBM模型则首先估计了维度级别效率再推导出总体效率。两者都利用正则化参数提高了区分力，整合了有利和不利产出。此外，该研究通过大规模数据集和医院案例验证了该方法的有效性和实用性。
### Conclusion
研究结果显示，SBM和GP-SBM模型在捕捉输入/输出变量间的联系和处理多个维度的效率评估方面表现更优，优于传统的分维度评估后综合的基准方法。这表明该方法在大规模数据集和多维度效率评估中具有显著优势。
## 776. `cs.LG` - BIOCAP：利用合成描述超出标签在生物基础模型中的应用 [PDF](https://arxiv.org/pdf/2510.20095), [HTML](https://arxiv.org/abs/2510.20095)
### Authors
Ziheng Zhang,Xinyue Ma,Arpita Chowdhury,Elizabeth G. Campolongo,Matthew J. Thompson,Net Zhang,Samuel Stevens,Hilmar Lapp,Tanya Berger-Wolf,Yu Su,Wei-Lun Chao,Jianyang Gu
### Background
当前研究生物多模态基础模型时，通常将图像作为监督信息的主要来源。然而，自然语言描述提供了一种补充监督的途径，能够捕捉到物种潜在的生物特征，并有助于对齐模型的隐含结构。然而，获取大量准确且实例特定的描述性文本是一个挑战，这限制了自然语言在生物进化学中的应用，相较其他科学领域应用更为有限。
### Innovation
本文提出了一种方法，利用多模态大型语言模型（MLLMs）生成合成描述性文本，并通过维基百科中的视觉信息和特定分类群的格式示例予以指导。这种方法减少了虚构描述的产生，使得生成的描述性文本更加准确和实例化，从而用于训练生物多模态基础模型（BIOCAP，即BIOCLIP结合描述性文本）。实验结果表明，BIOCAP能够捕捉丰富语义，在物种分类和图文检索方面表现优异，验证了描述性文本在跨模态模型中的额外价值。
### Conclusion
合成描述性文本在生物多模态基础模型中的应用提供了具有诊断价值的额外监督信息，有助于减少模型的误关联，并提升了其性能。这种方法克服了传统依赖标签的限制，拓展了自然语言在生物学多模态建模中的应用。
## 777. `cs.LG` - AsyncHZP: 基于异步调度的层次化零冗余优化并行训练大规模语言模型 [PDF](https://arxiv.org/pdf/2510.20111), [HTML](https://arxiv.org/abs/2510.20111)
### Authors
Huawei Bai,Yifan Huang,Wenqi Shi,Ansheng You,Feifan Shao,Tengfei Han,Minghui Yu
### Background
目前，大规模语言模型在庞大集群中的训练效率和可扩展性仍然是一个重要瓶颈。主流方法，如ND并行化，通常复杂且难以操作，而灵活的选择如零冗余优化器（ZeRO）则经常受到通信开销的限制。
### Innovation
我们提出了基于异步调度的层次化零冗余并行（AsyncHZP），这是一种新型的异步ZeRO变体，旨在实现高性能的同时保持简单和内存效率。AsyncHZP通过自适应地重新分割参数、梯度和优化器状态来优化设备内存使用并显著减少通信开销。此外，我们还设计了一种多流异步调度方法，该方法在专有的后台线程中执行参数全集和梯度归约散操作，从而在不产生明显内存碎片的情况下有效重叠通信与计算。实证评价证明，AsyncHZP在大规模下保持稳健稳定性，并且总体上比经典的ND并行化方法表现更好，无需复杂的技术调优，从而简化了高效大规模训练的道路。
### Conclusion
实证评估表明，AsyncHZP在大规模下保持了稳健的稳定性，在不依赖复杂技术调优的情况下，总体上超过了经典的ND并行化方法，实现最先进的性能，简化了高效大规模训练的路径。
## 778. `cs.LG` - 扩展用于自由能计算的机器学习模型对显式溶剂化方法的适用性 [PDF](https://arxiv.org/pdf/2510.20103), [HTML](https://arxiv.org/abs/2510.20103)
### Authors
Rishabh Dey,Michael Brocidiacono,Kushal Koirala,Alexander Tropsha,Konstantin I. Popov
### Background
显式溶剂化方法在分子模拟中能够较为精确地模型溶剂效应，但计算成本较高。相比之下，隐式溶剂化方法由于计算效率高，但准确度往往较低，限制了其在精确热力学计算中的应用。近年来，机器学习方法为改进隐式溶剂化模型提供了新的可能性，尤其是通过神经网络开发更精确的隐式溶剂化势。然而，当前基于机器学习的方法主要依赖于力匹配，这种单一的方法导致能量预测存在任意常数差异，不适合进行绝对自由能比较。
### Innovation
该论文提出了一种基于图神经网络（GNN）的隐式溶剂化模型——Lambda溶剂化神经网络（LSNN），该模型不仅使用力匹配方法，还训练模型使其能够匹配阿尔卡姆变量的导数，从而确保不同化学物种的溶剂化自由能可以进行有意义的比较。LSNN通过一个包含约300,000个小分子的数据集进行训练，实现了与显式溶剂化阿尔卡姆模拟相当的自由能预测精度，同时具有提高计算效率的优势，并为药物发现等未来应用奠定了基础框架。
### Conclusion
LSNN在保持与显式溶剂化模拟相似的自由能预测精度的同时，通过图神经网络模型提高了计算效率，并通过匹配阿尔卡姆变量的导数解决了现有方法中的关键问题，为今后的药物发现等领域提供了可行的基础框架。
## 779. `cs.LG` - 多媒体感知的问答：检索和跨模态推理架构综述 [PDF](https://arxiv.org/pdf/2510.20193), [HTML](https://arxiv.org/abs/2510.20193)
### Authors
Rahul Raja,Arpita Vats
### Background
传统的问答系统依赖于结构化文本数据，但多媒体内容（如图像、音频、视频和结构化元数据）的快速增长引入了新的检索增强问答挑战和机遇。
### Innovation
该综述回顾了集成多媒体检索管道的最新问答系统进展，重点介绍了与用户查询对齐的视觉、语言和音频模态的架构；分类方法依据检索方法、融合技术和答案生成策略；分析基准数据集、评估协议和性能权衡；强调跨模态对齐、延迟-准确度权衡和语义定位等关键挑战。
### Conclusion
最后，指出了构建更强大、更具有上下文感知的问答系统的开放问题和未来研究方向，利用多媒体数据。
## 780. `cs.LG` - 长时程耦合偏微分方程的组合生成 [PDF](https://arxiv.org/pdf/2510.20141), [HTML](https://arxiv.org/abs/2510.20141)
### Authors
Somayajulu L. N. Dhulipala,Deep Ray,Nicholas Forman
### Background
模拟耦合偏微分方程（PDE）系统在计算上是密集的，先前的努力主要集中在训练联合数据上的代理模型，这需要大量的数据。本文研究了组合扩散方法，其中扩散模型仅在解耦PDE数据上进行训练，并在推断时组合以恢复耦合场。研究目的是探讨在涉及大量时间步的长时间框架下组合策略的可行性。
### Innovation
提出了基于组合扩散的策略，该策略仅在解耦PDE数据上训练扩散模型，然后在推断时进行组合。并且引入了基于欧拉方案的对称组合方案，用于耦合场。研究比较了基线扩散模型和使用v参数化策略训练的模型，并与基于耦合数据训练的傅里叶神经算子进行了基准测试。尽管仅使用解耦训练数据，组合扩散模型仍能以低误差恢复耦合轨迹。v参数化可以提高扩散模型的准确性，但傅里叶神经算子依然在针对耦合数据进行训练时表现最好。
### Conclusion
这些结果表明，组合扩散是一种可行策略，可用于高效地、长时间框架下建模耦合偏微分方程。
## 781. `cs.LG` - 关于 McKean-Vlasov 方程稳态解的结构及其在嘈杂变换器中的应用 [PDF](https://arxiv.org/pdf/2510.20094), [HTML](https://arxiv.org/abs/2510.20094)
### Authors
Krishnakumar Balasubramanian,Sayan Banerjee,Philippe Rigollet
### Background
本文研究了圈上线性 McKean-Vlasov 方程的稳态解。主要背景是通过观察稳态 McKean-Vlasov 方程解与无限维四阶系统之间的精确等价性，将稳态状态的显式表征从函数空间转化到序列空间。这为局部分岔的透彻描述提供了框架，包括周期性结构和共振结构，同时处理奇异势。通过推导能够刻画可能涉及多个傅里叶模态的分岔出现、形式以及形状（超临界、临界、亚临界或批判性）的解析表达式，并将它们与不连续相变联系起来。同时也定义了在特定假设下，准确定义的稳态分岔解结构，准确度高达任意数量的傅里叶模态。全局层面，揭示了自由能量景观的正则性和凹性，证明了全局最小化稳态测度的存在性和紧凑性，进一步识别不连续相变与最小自由能量图的非可微点之间的关系。文章还将理论应用于嘈杂变换器模型，阐述了如何通过改变温度参数β影响从均匀测量中的无量纲无限分岔几何形状。
### Innovation
通过将 McKean-Vlasov 方程的稳态解建模为无限维四维系统的傅里叶系数，提供了一种透明的分岔描述框架，能够直接从序列空间描述稳态状态。该框架能够处理奇异势并提供详细的结构分析，连接非连续相变与分岔形态。识别了在不同 β 值下的分岔行为，特别是在β增加时从连续的到不连续相行为的尖锐转变。还探讨了在β增加时不同类型稳态解决方案的可能性，包括少量模式的稳定状态和多模式的准稳态状态。
### Conclusion
本文揭示了 McKean-Vlasov 方程稳态解的详细结构，并将其应用到嘈杂变换器模型中。通过分析不同温度参数 β 的影响，证明了自由能量景观的正则性与凹性，定义了在 β 增加时全局最小化测度的性质和不连续相变。明确了分岔行为从连续转变为不连续相行为的性质，并讨论了高β值下多模式稳态解的可能形式。详细地描述了不同傅里叶模态下的分岔，为深入理解复杂系统中的相变提供了新的见解。
## 782. `cs.LG` - 赋权词语：DoubleGround在结构化短语和句子级时间定位上的应用 [PDF](https://arxiv.org/pdf/2510.20244), [HTML](https://arxiv.org/abs/2510.20244)
### Authors
Minseok Kang,Minhyeok Lee,Minjung Kim,Donghyeong Kim,Sangyoun Lee
### Background
视频时间定位（VTG）旨在在长且未剪辑的视频中定位与给定自然语言查询对齐的时间段。任务通常包括子任务：时刻检索（MR）和突显检测（HD）。现有方法通常在跨模态注意过程中均等地处理所有文本标记，忽视了它们独特的语义角色。研究表明，这种处理方式使VTG模型过度依赖全局语义，而无法有效利用词级信号，限制了它们实现细粒度时间对齐的能力。
### Innovation
作者提出了一种双重架构的双源（DualGround），通过分离全局和局部语义并通过分离的路径传递句子级别的路径，将文本标记聚类为短语级别单元，以实现局部定位。该方法引入了（1）令牌角色感知的跨模态交互策略，这些策略以结构分解的方式对齐视频特征与句子级和短语级语义；（2）联合建模框架不仅提高了整体句子级对齐，还通过利用结构化的短语感知背景增强了细粒度的时间定位。该设计使得模型能够捕捉粗略和局部语义，从而进行更具表现力和上下文感知的视频定位。
### Conclusion
双源（DualGround）在QVHighlights和Charades-STA基准测试中同时实现了时刻检索（MR）和突显检测（HD）任务的最新性能，展示了在视频语言对齐中分离语义建模的有效性。
## 783. `cs.LG` - 使用AI代理进行自动化云基础设施即代码一致性的研究 [PDF](https://arxiv.org/pdf/2510.20211), [HTML](https://arxiv.org/abs/2510.20211)
### Authors
Zhenning Yang,Hui Guan,Victor Nicolet,Brandon Paulsen,Joey Dodds,Daniel Kroening,Ang Chen
### Background
云基础设施通常通过云控制台、命令行界面（CLI）、软件开发工具包（SDK）等接口进行管理。近年来，基础设施即代码/IaC框架（如Terraform）越来越受欢迎。IaC框架将基础设施编码为“单一真实来源”的配置，能够自动部署、更新或销毁资源，使实际基础设施与IaC配置保持一致。然而，当IaC与控制台、CLI或SDK并用时，IaC会失去对外部变化的可见性，导致基础设施漂移，使配置过时，导致后续IaC操作可能取消有效的更新或触发错误。因此，论文探讨了NSync系统，能够检测并解决基础设施漂移问题，并将外部变化同步到IaC程序中，提高其准确性和效率。
### Innovation
NSync是一个自动化的IaC一致性系统，通过跟踪API调用来检测和解决基础设施变化。该系统包含了一个代理架构，利用大型语言模型（LLMs）从杂乱的API序列中推理高级意图，使用专门的工具合成目标IaC更新，并通过自我进化的知识库不断增强。此外，还引入了新的评估流程，将真实的漂移注入云基础设施，评估一致性性能。实验结果表明，与基线相比，NSync在准确性（从0.71提升到0.97的pass@3）和标记效率（提高1.47倍）方面表现出色。
### Conclusion
NSync通过检测和整合外部变化，实现了IaC配置的一致性，提高了云基础设施管理的准确性和效率。该系统通过AI代理实现了自动化API跟踪和IaC更新，证明了在实际项目中的适用性和优越性。
## 784. `cs.LG` - 校准多模态共识以进行情感识别 [PDF](https://arxiv.org/pdf/2510.20256), [HTML](https://arxiv.org/abs/2510.20256)
### Authors
Guowei Zhong,Junjie Li,Huaiyu Zhu,Ruohong Huan,Yun Pan
### Background
近年来，多模态情感识别（MER）取得了显著进展。然而，现有方法大多忽略了模态间可能产生的语义不一致，如文本和视觉输入之间的矛盾情感提示。此外，由于文本模态的表征能力强，现有方法往往受到文本模态的主导，这可能会牺牲识别准确性。因此，需要提出一种解决方案来解决这些问题。
### Innovation
本文提出了一种名为校准多模态共识（CMC）的模型。CMC引入了伪标签生成模块（PLGM），以生成伪单模标签，从而实现自监督的单模预训练。之后，CMC采用了参数自由融合模块（PFM）和多模态共识路由器（MCR），用于多模态微调，从而减轻文本主导现象，并引导融合过程朝着更可靠的一致性进行。实验结果表明，CMC在四个数据集（CH-SIMS，CH-SIMS v2，CMU-MOSI，CMU-MOSEI）上表现与或优于现有最好方法，并在CH-SIMS和CH-SIMS v2中表现出处理语义不一致场景的优势。
### Conclusion
CMC 通过引入伪标签生成模块和参数自由融合模块克服了模态间的语义不一致问题和文本模态的主导现象，从而实现了更准确的情感识别。实验结果证明了其在多个数据集中的优越性。
## 785. `cs.LG` - 在生成式人工智能时代的霹雳舞视频分类 [PDF](https://arxiv.org/pdf/2510.20287), [HTML](https://arxiv.org/abs/2510.20287)
### Authors
Sauptik Dhar,Naveen Ramakrishnan,Michelle Munson
### Background
近年来，大型视觉语言模型在体育领域的应用取得了巨大进展，但大多数研究集中在足球、板球、篮球等少数热门体育项目上，主要用于生成任务，如视觉问答和精彩瞬间生成。本文则探讨了这些现代视频基础模型（包括编码器和解码器）在霹雳舞这一非常小众但极其流行的运动项目中的应用潜力。
### Innovation
本文的研究创新在于使用现代视频基础模型对霹雳舞视频进行分类，并发现视频编码器模型在预测任务中继续超越现有的视频语言模型。研究还提供了如何选择编码器模型的见解，并深入分析了微调解码器模型的工作原理，这对霹雳舞视频分类具有重要价值。
### Conclusion
研究结果表明，视频编码器模型在预测任务中继续优于现有的视频语言模型。为了更好地应用于霹雳舞视频分类，研究提出了选择编码器模型的建议，并对微调的解码器模型进行了全面分析。
## 786. `cs.LG` - 增强深度强化学习安全性：对抗攻击与防御的全面综述 [PDF](https://arxiv.org/pdf/2510.20314), [HTML](https://arxiv.org/abs/2510.20314)
### Authors
Wu Yichao,Wang Yirui,Ding Panpan,Wang Hailong,Zhu Bingqian,Liu Chun
### Background
随着深度强化学习（DRL）技术在自动驾驶、智能制造和智能医疗等复杂领域的广泛应用，如何在动态和多变环境中提升其安全性和鲁棒性成为当前研究的焦点。对抗性攻击使DRL可能遭受严重的性能下降或甚至导致危险的决策，因此在安全敏感场景中确保其稳定性至关重要。
### Innovation
本文首先介绍了DRL的基本框架，并分析了其在复杂和多变环境下的主要安全挑战。此外，本文提出了一种基于扰动类型和攻击目标的对抗攻击分类框架，并详细回顾了主流针对DRL的对抗攻击方法，包括状态空间、动作空间、奖励函数和模型空间的各种攻击方法。为了有效对抗这些攻击，本文系统地总结了现有的多种鲁棒性训练策略，包括对抗训练、竞争训练、鲁棒学习、对抗检测、防御蒸馏等相关防御技术，并讨论了这些方法在提升DRL鲁棒性方面的优缺点。
### Conclusion
本文展望了DRL在对抗环境下的未来研究方向，强调了提高泛化能力、降低计算复杂性、增强可扩展性和可解释性等方面的研究需求，为研究人员提供有价值的参考资料和方向。
## 787. `cs.LG` - 使用正则化流提取TAIGA实验中稀有伽马事件的能力 [PDF](https://arxiv.org/pdf/2510.20334), [HTML](https://arxiv.org/abs/2510.20334)
### Authors
A.P. Kryukov,A.Yu. Razumov,A.P. Demichev,J.J. Dubenskaya,E.O. Gres,S.P. Polyakov,E.B. Postnikov,P.A. Volchugov,D.P. Zhurov
### Background
该研究旨在开发一种方法，以通过基于深学习和正则化流的异变检测方法从来自宇宙源的带电粒子流量中检测罕见的伽马量子。正则化流特别适用于处理复杂的概率分布问题，这种方法被证明可能适用于伽马检测。研究在TAIGA-IACT实验的模型数据上进行了测试，但所获得的定量性能指标仍不如其他方法，因此提出了改进方法实现的可能途径。
### Innovation
该研究采用了一种基于深度学习和正则化流的新方法来检测宇宙射线中稀缺的伽马量子。这种方法特别适合处理复杂的概率分布问题，具有潜在的应用价值。
### Conclusion
尽管使用正则化流的方法在TAIGA实验中仍显现出一定的局限性，但其性能指标劣于其他方法。因此，该研究提出了一些改进的方法实现途径，旨在提高这种方法的检测性能和应用潜力。
## 788. `cs.LG` - MemER: 通过经验检索扩大机器人控制中的记忆力 [PDF](https://arxiv.org/pdf/2510.20328), [HTML](https://arxiv.org/abs/2510.20328)
### Authors
Ajay Sridhar,Jennifer Pan,Satvik Sharma,Chelsea Finn
### Background
人类在执行任务时会依赖记忆，但机器人策略通常缺乏这一能力。传统的机器人策略在处理长时间任务时存在计算成本高和在特征偏移下脆弱的问题，简单的历史摘要又会导致无关或冗余的信息。为此，本文提出了一种分层策略框架，其中高层策略被训练以从其经验中选择和跟踪相关的关键帧，低层策略则根据这些关键帧和最新的图片生成说明来执行。这种设计兼容现有的视觉-语言-动作模型，使其能够高效地处理长期依赖关系。实验显示，该方法在需要几分钟记忆的三个真实世界长时机器人操作任务中表现优于先前的方法。
### Innovation
本文提出了一种分层策略框架MemER，能够有效地帮助低层策略执行长时任务。该框架中，高层策略负责从经验中选择和跟踪相关的关键帧，低层策略则使用这些关键帧和最新帧来生成指令执行任务。这种方法兼容现有的视觉-语言-动作模型，能够处理长期依赖关系。实验结果显示该方法在多个任务上表现优于以前的方法。
### Conclusion
本文提出了MemER框架，它能够通过经验检索有效扩大机器人控制中的记忆力。实验结果在多个真实世界长时机器人操作任务上验证了该方法的有效性，能够显著改进现有策略的性能。
## 789. `cs.LG` - 多任务深度学习在表面计量中的应用 [PDF](https://arxiv.org/pdf/2510.20339), [HTML](https://arxiv.org/abs/2510.20339)
### Authors
D. Kucharski,A. Gaska,T. Kowaluk,K. Stepien,M. Repalska,B. Gapinski,M. Wieczorowski,M. Nawotka,P. Sobecki,P. Sosinowski,J. Tomasik,A. Wojtowicz
### Background
介绍了用于表面计量的可重复深度学习框架，旨在预测表面纹理参数及其报告的标准不确定度。该研究使用跨越触觉和光学系统的多仪器数据集，解决了测量系统类型分类问题，并对 Ra, Rz, RONt 及其不确定性目标(Ra_uncert, Rz_uncert, RONt_uncert)进行了协调回归。通过量化和异方差头部建模不确定性，并使用后验同校准生成校准区间。
### Innovation
提出了一个多任务深度学习框架，能够同时预测表面纹理参数及其不确定性；使用量化和异方差头部建模不确定性，并通过后验证校准进行校准；单目标模型和多目标模型的性能对比，显示了单目标模型在某些任务上的优越性。
### Conclusion
在保留集上，单目标回归器实现了高保真度(R2: Ra 0.9824, Rz 0.9847, RONt 0.9918)，对于两个不确定性目标也得到了较好的建模(Ra_uncert 0.9899, Rz_uncert 0.9955)，但在 RONt_uncert 上模型表现不佳（R2 0.4934）。分类器的准确性达到了92.85%，概率校准在温度缩放之后几乎保持不变。研究结果为表面计量工作流程中的仪器选择和验收决策提供了校准预测。
## 790. `cs.LG` - 基于数据增强的截尾期望回归神经网络 [PDF](https://arxiv.org/pdf/2510.20344), [HTML](https://arxiv.org/abs/2510.20344)
### Authors
Wei Cao,Shanshan Wang
### Background
期望回归神经网络(ERNNs)是强大的工具，用于捕获数据中的异质性和复杂的非线性结构。然而，大部分现有研究主要集中在完全观察的数据上，对包含截尾观察的数据场景关注较少。因此，本文旨在提出一种基于数据增强的ERNNs算法（DAERNN），以建模异质的截尾数据。该论文指出，DAERNN 是完全数据驱动的，并且只需要最少的假设，提供了很大的灵活性，不需要对截尾机制进行显式参数模型规定，从而提高了其在实际截尾数据分析中的适用性。
### Innovation
提出了一种新的数据分析方法——基于数据增强的ERNNs算法（DAERNN），该算法专门用于处理异质截尾数据。DAERNN 大大提高了在处理截尾数据时的灵活性和适用性，无需进行显式参数模型设定，能够提供与完全观测数据训练的模型相近的预测性能，并且模拟研究和实际数据应用显示其性能优越于现有的截尾ERNNs方法。
### Conclusion
DAERNN 提供了一种统一的框架来处理各种截尾机制，无需显式指定参数模型。它在模拟研究和实际数据应用中展示了卓越的性能，证明其能够有效地处理截尾数据，为截尾数据的预测提供了强有力的工具。
## 791. `cs.LG` - ComProScanner：基于多智能体的从科学文献中提取组分-属性结构化数据框架 [PDF](https://arxiv.org/pdf/2510.20362), [HTML](https://arxiv.org/abs/2510.20362)
### Authors
Aritra Roy,Enrico Grisan,John Buckeridge,Chiara Gattinoni
### Background
自各种预训练大型语言模型问世以来，从科学文本中提取结构知识经历了与传统机器学习或自然语言处理技术相比具有革命性的变化。尽管如此，在线的可访问自动化工具，允许用户从科学文献提取数据集进行构造、验证和可视化仍然相对稀缺。
### Innovation
我们开发了ComProScanner，这是一种自主的多智能体平台，用于提取、验证、分类和可视化可读的化学组成和性质，并结合了期刊文章中的合成数据，以创建全面的数据库。该框架使用100篇期刊文章和10种不同的LLM（包括开源和专有模型）进行评估，以提取复杂且相关的陶瓷压电材料组成及对应的介电应变系数（d33）数据。DeepSeek-V3-0324以0.82的显著总体准确度领先所有模型。该框架提供了一个简单、用户友好的提取埋藏在文献中的复杂实验数据的工具包，以构建机器学习或深度学习数据集。
### Conclusion
该框架为从文献中提取并构建机器学习或深度学习数据集提供了简单易用的工具包，特别适用于缺乏大数据集的情况，如陶瓷压电材料的数据提取。
## 792. `cs.LG` - 基于Transformer启发的人工智能MIMO接收机 [PDF](https://arxiv.org/pdf/2510.20363), [HTML](https://arxiv.org/abs/2510.20363)
### Authors
András Rácz,Tamás Borsos,András Veres,Benedek Csala
### Background
传统MIMO（多输入多输出）检测方法在处理多层传输数据时存在一定的局限性，尤其是在复杂信道环境下，需要更加高效的解调算法来提高性能和复杂度之间的平衡。
### Innovation
AttDet方法借鉴了Transformer架构，将每个传输层视为一个token，通过轻量级的自注意力机制学习流间干扰，通过估计的信道矩阵直接获取查询和键值，以量化信道相关性。该方法结合了模型基础的可解释性与数据驱动的灵活性，并通过链路级仿真在现实的5G信道模型和高阶混合QAM调制编码方案下展示了接近最优的BER/BLER性能，同时保持了可预测性和多项式级的复杂度。
### Conclusion
AttDet方法在MIMO检测方面提供了新的解决方案，通过自注意力机制有效处理多流间干扰，实现了与5G信道模型高度适应的性能提升，并且保持了可预测的复杂度增长，为未来MIMO系统设计提供了新的思路。
## 793. `cs.LG` - 检验最具有影响力的子集 [PDF](https://arxiv.org/pdf/2510.20372), [HTML](https://arxiv.org/abs/2510.20372)
### Authors
Lucas Darius Konrad,Nikolas Kuschnig
### Background
在数据分析过程中，小部分具有显著影响力的子数据集会对模型结果产生重大影响，甚至可以颠覆关键发现。尽管近期已有研究发展出识别这些最具有影响力的子数据集的方法，但尚未有理论能够区分其影响是否反映真实问题，而非自然采样偏差。现有方法通常采用非正式的敏感性检查方法。本文旨在填补这一空白，通过构建一个原则性的框架来评估最具有影响力的子数据集的统计显著性，从而进行严谨超常影响力的相关假设检验，替代现有的非正式敏感性检查
### Innovation
本文提出了一个原则性的框架，用于评估最具有影响力的子数据集的统计显著性。这种理论成果描述了最大影响力的极端值分布，从而可进行严谨的超常影响力假设检验，取代目前非正式的敏感性检查方法。通过经济学、生物学和机器学习基准的应用验证了该方法的实际价值
### Conclusion
本文通过构建一个原则性的框架，解决了现有方法无法区分最具有影响力的子数据集的影响是否真实反映问题的难题。该方法在经济、生物学和机器学习领域具有较大的实际应用价值。
## 794. `cs.LG` - 通用图中的三次相关聚类的局部最优条件 [PDF](https://arxiv.org/pdf/2510.20431), [HTML](https://arxiv.org/abs/2510.20431)
### Authors
David Stein,Bjoern Andres,Silvia Di Gregorio
### Background
该论文探讨了一个NP难问题，即给定图G及其子(clique)的代价，找到一个划分，使得所有节点在同一个子组的子集的代价总和最小。已有的研究主要集中在使用局部搜索启发式方法来解决这个问题。本文关注于三次相关聚类，即最多包含三个节点的子集。
### Innovation
本文提出了三次相关聚类的局部最优条件，并设计和实现了相应的决策算法，通过实验证明了这些条件的有效性。
### Conclusion
通过实验验证，本文的算法能够有效地验证三次相关聚类的局部最优条件，为实际应用提供了有用的方法和工具。
## 795. `cs.LG` - 使用GraphDOP学习地球系统耦合动力学 [PDF](https://arxiv.org/pdf/2510.20416), [HTML](https://arxiv.org/abs/2510.20416)
### Authors
Eulalie Boucher,Mihai Alexe,Peter Lean,Ewan Pinnington,Simon Lang,Patrick Laloyaux,Lorenzo Zampieri,Patricia de Rosnay,Niels Bormann,Anthony McNally
### Background
地球系统不同组成部分（如海洋、大气、陆地和冰雪圈）之间的相互作用是全球天气模式的关键驱动因素。现代数值天气预报系统通常运行独立的模型来模拟不同组成部分，通过显式耦合来模拟不同组成部分之间的交换。准确地表示这些耦合的相互作用仍然是天气预报中的主要科学研究和技术挑战。GraphDOP是一种基于图的机器学习模型，能够直接从原始的卫星和现场观测数据中进行天气预报，无需依赖再分析产品或传统的基于物理的数值天气预报模型。GraphDOP可以同时将来自地球系统各个方面多样观测信息嵌入到共享的潜在空间中，从而使模型能够在单个模型中隐含捕捉跨域交互，而不需要任何显式耦合。
### Innovation
GraphDOP是一种基于图的机器学习模型，通过直接从地球系统的原始观测数据中学习，可以隐含地捕捉跨域交互，无需依赖传统的再分析产品或基于物理的数值天气预报模型。这种方法为实现单一模型驱动的、物理一致的端到端地球系统预测提供了新的途径。
### Conclusion
学习直接从地球系统观测数据中描述和传播跨组件交互，表明了一种在单一模型中实现物理一致的端到端数据驱动地球系统预测的有前途的方法，通过案例研究表明，这种方法可以成功地为快速冻结的北极海冰、飓风伊恩引起的混合引起的海洋表层冷却以及2022年的严重欧洲热浪等重要耦合过程提供预测。
## 796. `cs.LG` - 超越标准模型物理中的符号回归和可微拟合 [PDF](https://arxiv.org/pdf/2510.20453), [HTML](https://arxiv.org/abs/2510.20453)
### Authors
Shehu AbdusSalam,Steven Abel,Deaglan Bartlett,Miguel Crispim Romão
### Background
本文探讨了使用符号回归（SR）来探究超越标准模型（BSM）的粒子物理学模型的有效性。本文通过考虑所谓的限制最小超对称标准模型（CMSSM）进行研究。与其他BSM物理学模型类似，该模型有若干（四个）任意参数，这些参数决定了实验信号和如暗物质遗迹密度等宇宙学观测值。研究发现，通过用输入参数的符号表达式来分析现象学，可以显著加速研究进程。
### Innovation
本文展示了SR在产生极其准确的表达式方面的优势，并且能够使用可微方法进行拟合，而不是采样方法，从而提高了拟合的全局稳健性。此外，还对比了符号回归与神经网络回归，发现SR可以提供更稳健的结果，而神经网络需要集中在有希望的数据区域才能表现得同样出色。
### Conclusion
本文发现，使用SR方法可以构建高度准确的观测表达式，并使用这些表达式在全球范围内拟合CMSSM输入参数，结果与传统方法得出的结果一致。文章还展示了SR的显著优势，即可以使用可微方法进行拟合，而传统的神经网络方法可能需要针对有希望的数据区域进行训练才能达到同样的性能。
## 797. `cs.LG` - 用于SHOIQ中稳健实例检索的神经推理 [PDF](https://arxiv.org/pdf/2510.20457), [HTML](https://arxiv.org/abs/2510.20457)
### Authors
Louis Mozart Kamdem Teyou,Luke Friedrichs,N'Dah Jean Kouagou,Caglar Demir,Yasir Mahmood,Stefan Heindorf,Axel-Cyrille Ngonga Ngomo
### Background
本文介绍了概念学习，通过描述逻辑公理背景知识来学习可解释的分类模型，尽管神经符号概念学习取得了突破，但大多数方法至今仍无法应用于实际的知识库。这是由于使用了不稳健的描述逻辑推理器，它们无法应对不一致性和错误数据。
### Innovation
本文提出了一个新的神经推理器EBR，依赖嵌入来近似符号推理器的结果。EBR仅需要检索原子概念和存在限制实例，就可以检索或近似描述逻辑SHOIQ中任何概念的实例集。实验表明，EBR比现有推理器更能应对缺失和错误数据。
### Conclusion
我们的研究结果表明，相比于现有的推理器，EBR能够针对实际知识库中的不一致和错误数据提供稳健的实例检索能力。
## 798. `cs.LG` - 无线信道中敌手意识的隐私保护推理 [PDF](https://arxiv.org/pdf/2510.20518), [HTML](https://arxiv.org/abs/2510.20518)
### Authors
Mohamed Seif,Malcolm Egan,Andrea J. Goldsmith,H. Vincent Poor
### Background
AI在无线边缘设备中的应用可以显著提升如自主驾驶和环境监测等视觉和感知任务。推理阶段需要从感测数据中提取特征用于预测任务（如分类或回归）。在边缘网络中，传感器和模型服务器往往不共存，因此需要通过通信传递特征。敏感的个人数据可以通过对手重构，因此需要对特征进行转换以降低隐私泄露的风险。现有的差分隐私机制可以保护有限数据集，但尚未解决单个特征的保护问题。
### Innovation
本文提出了一种新型框架，通过在传输到模型服务器之前对提取的特征进行转换，实现AI驱动感测的隐私保护。
### Conclusion
该研究在无线信道中提出了敌手意识下的隐私保护推理框架，通过特征转换确保个人数据隐私，解决了现有差分隐私机制未能处理的单个特征保护问题。
## 799. `cs.LG` - 在月球延迟容忍网络中通过图注意力机制多智能体强化学习学习分散路由策略 [PDF](https://arxiv.org/pdf/2510.20436), [HTML](https://arxiv.org/abs/2510.20436)
### Authors
Federico Lozano-Cuadra,Beatriz Soret,Marc Sanchez Net,Abhishek Cauligi,Federico Rossi
### Background
本文提出了一种适用于月球延迟容忍网络（LDTN）约束条件下，多机器人探索任务中的分散路由框架。在这种环境中，自主漫游车必须在间歇性连接和未知移动模式下将收集的数据传递给着陆器。研究者将问题定义为部分可观测马尔可夫决策过程（POMDP），并提出了一种基于图注意力的多智能体强化学习（GAT-MARL）策略，采用集中式训练、分布式执行（CTDE）的方法。这一方法仅依赖于局部观察，无需进行全局拓扑更新或数据包复制，不同于传统的最短路径和控制泛洪等经典方法。
### Innovation
该研究将部分可观测马尔可夫决策过程应用于多机器人网络中的分散路由问题，并提出了一种基于图注意力机制的多智能体强化学习策略，集中式训练、分布式执行（CTDE）。通过蒙特卡洛模拟的随机探索环境，GAT-MARL策略能够提供更高的数据传输率、无数据重复和更少的数据包丢失，能够利用短期移动预测，为未来的空间机器人系统提供可扩展的解决方案，并成功应用于更大的漫游车团队中。
### Conclusion
研究展示了GAT-MARL策略在分散路由中的有效性和优越性，为月球及其他行星探索任务中的网络路由提供了新的方法。该方法能够适应间歇性连接和未知的漫游车移动模式，证明了其在实际机器人系统中的应用潜力。
## 800. `cs.LG` - Blur2seq: 仅从单张相机运动模糊图像推断盲去模糊和相机轨迹估计 [PDF](https://arxiv.org/pdf/2510.20539), [HTML](https://arxiv.org/abs/2510.20539)
### Authors
Guillermo Carbajal,Andrés Almansa,Pablo Musé
### Background
相机抖动引起的运动模糊，尤其是在大范围或旋转运动的情况下，是图像恢复中的一个重大挑战。现有的方法难以有效处理此类模糊，特别是在严重或空间变异性模糊的情况下。
### Innovation
提出了一种深度学习框架，可以从单张模糊图像中联合估计潜在的锐利图像和底层的相机运动轨迹。该方法利用了投影运动模糊模型（PMBM），并通过与现代网络兼容的可微模糊创建模块实现高效计算。该框架通过预测完整的3D旋转轨迹指导端到端训练的模型，从而实现了图像恢复并提供可解释性。进一步通过后推理的重新模糊损失优化轨迹，增强了输入模糊图像与恢复输出之间的一致性。
### Conclusion
大量实验表明，该方法在合成和真实数据集上均达到了最先进的性能，尤其是在严重或空间变异性模糊的情况下，端到端去模糊网络存在挑战。代码和训练模型可在指定网址下载。
## 801. `cs.LG` - 关于不平衡分类中使用合成过采样的集中性和超额风险界 [PDF](https://arxiv.org/pdf/2510.20472), [HTML](https://arxiv.org/abs/2510.20472)
### Authors
Touqeer Ahmad,Mohammadreza M. Kalan,François Portier,Gilles Stupfler
### Background
合成过采样（如SMOTE及其变体）是解决不平衡分类问题的主要策略。尽管这种方法在实践中很成功，但其理论基础仍较少被研究。本文发展了一种理论框架，用于分析在使用合成数据训练分类器时SMOTE及其相关方法的行为。研究表明，可以通过合成的少数类样本以一种统一的方式集中其经验风险与真实少数类分布上的总体风险之间的差异。进一步，证明了一类基于核的方法在使用这些合成数据训练时的非参数超额风险保证。
### Innovation
提出了分析SMOTE及其相关方法在使用合成数据训练分类器时的行为的理论框架，并且提供了基于核的方法在使用合成数据训练时的超额风险保证。这些结果还为SMOTE参数调优和下游学习算法提供了实用指南，并通过数值实验进行了验证和支持。
### Conclusion
本文通过理论分析和数值实验，为更好地调优SMOTE以及下游学习算法提供了指导，并证明了基于核的方法在使用合成数据训练时的超额风险，从而增强对SMOTE及其变体的理解和应用。
## 802. `cs.LG` - 解码耳朵：通过高效对齐将人类偏好客观化为表达性的框架 [PDF](https://arxiv.org/pdf/2510.20513), [HTML](https://arxiv.org/abs/2510.20513)
### Authors
Zhiyu Lin,Jingwen Yang,Jiale Zhao,Meng Liu,Sunzhu Li,Benyou Wang
### Background
近期的语音到语音（S2S）模型可以生成可理解的语言，但缺乏自然的表达性，主要是由于缺乏可靠的评估标准。现有的方法，如主观的MOS评分、低水平的声学特征和情绪识别，要么成本高昂，要么信息有限，要么不完整，无法有效评价这些模型的表达性。因此，需要一种新的方法来客观地评估语音的表达性，从而提高S2S模型的自然性和表达力。
### Innovation
提出了DeEAR（Decoding the Expressive Preference of eAR）框架，该框架将人类对语音表达性的偏好转换为客观得分。该框架基于phonetics和心理学，评估语音在情感、语调和自发性三个维度上，能在不到500个标记样本的基础上，与人类感知高度一致（Spearman等级相关系数SRCC = 0.86），同时还提供了公平的基准测试和针对性的数据采集。DeEAR不仅能够识别S2S模型之间的表达性差距，而且还选取了14,000条具有表达性的语音切片，形成了ExpressiveSpeech数据集，提高了S2S模型的表达得分（从2.0到100分中的23.4）。
### Conclusion
DeEAR不仅能够客观地评估语音的表达性，而且还能够在较低的注释样本数量下实现与人类感知高度一致，通过高效的对齐机制实现了公平的基准测试和有针对性的数据采集，从而极大地改善了S2S模型的表达性。
## 803. `cs.LG` - 黑盒子吸收：大型语言模型侵蚀创新思想 [PDF](https://arxiv.org/pdf/2510.20612), [HTML](https://arxiv.org/abs/2510.20612)
### Authors
Wenjun Cao
### Background
大型语言模型被广泛应用于加速创新，但这些模型的内部架构往往是不透明的，这可能导致一种系统性风险：黑盒吸收。这种机制通过平台在交互过程中吸收、泛化和再利用用户贡献的创新概念，造成了个体创作者与平台运营商之间严重的信息和结构不对称，从而威胁到创新生态系统的长期可持续性。
### Innovation
论文定义了黑盒吸收这一概念，并提出了‘想法单位’和‘想法安全性’两个核心概念。为了解决这一挑战，论文还分析了吸收机制，并提出了具体的治理和工程议程，以确保创作者贡献的可追踪性、可控性和公平性，从而减轻这些风险。
### Conclusion
通过这些机制和建议，论文希望确保大型语言模型的应用不损害创新经济的基础原则，保护个体创作者的利益，并实现创新生态系统的长期可持续发展。
## 804. `cs.LG` - Diffusion Autoencoders with Perceivers for Long, Irregular and Multimodal Astronomical Sequences [PDF](https://arxiv.org/pdf/2510.20595), [HTML](https://arxiv.org/abs/2510.20595)
### Authors
Yunyi Shen,Alexander Gagliano
### Background
自监督学习已成为表示学习的核心策略，但用于编码数据的大多数架构仅在如图像、音频和视频等定期采样的输入上得到了验证。然而，在许多科学领域，数据以长时间的、不规则的和多模态序列的形式出现。因此，需要一种能够从这些不规则且多模态的序列中提取语义信息的方法和方法框架。为解决这一问题，该研究引入了Diffusion Autoencoder with Perceivers (DAEP)，通过将异构测量分词，使用Perceiver编码器压缩这些数据，再通过Perceiver-IO扩散解码器重建数据，从而在多样的数据设置中实现可扩展的学习。研究中还引入了一种基线方法，名为Masked Autoencoder with Perceivers (MAEP)，以评估DAEP架构的效果。
### Innovation
提出的Diffusion Autoencoder with Perceivers (DAEP)方法通过自监督学习从长时间的、不规则的和多模态的天文学序列中提取语义信息，这与现有的对定期采样数据验证的方法不同。DAEP使用Perceiver编码器对异构测量进行编码，通过Perceiver-IO扩散解码器重建数据，该方法适用于多种多样的光谱和光度天文学数据集。此外，还引入了Masked Autoencoder with Perceivers (MAEP)作为基线，从而在相同的架构家族中进行对比测试，结果表明DAEP在重建误差、潜在空间的区分性和局部结构的保持方面优于变分自编码器（VAE）和MAEP基线。
### Conclusion
研究结果表明，Diffusion Autoencoder with Perceivers (DAEP)是科学领域中一种有效的框架，该框架能够处理长时间的、不规则和多模态序列数据，对这些领域中的信息化需求具有重要意义。
## 805. `cs.LG` - 寻找最佳平衡点：推理时LML自我反思中的质量、成本和速度的权衡 [PDF](https://arxiv.org/pdf/2510.20653), [HTML](https://arxiv.org/abs/2510.20653)
### Authors
Jack Butler,Nikita Kozodoi,Zainab Afolabi,Brian Tyacke,Gaiar Baimuratov
### Background
随着大型语言模型（LLMs）的不断发展，从业者在无需重新训练模型的情况下，获得增强推理性能的选择越来越多，包括预算调整和多步技术，如自我反思。这些方法可以提升输出质量，但它们在准确度、成本和延迟之间带来了复杂的权衡，这些权衡在不同领域尚未被充分理解。本研究系统地比较了自我反思和预算调整在数学推理和翻译任务中的效果。
### Innovation
本研究首次系统地比较了自我反思和预算调整在数学推理和翻译任务中的效果，并通过不同深度的自我反思和计算预算评估了多个主流模型（包括Anthropic Claude、Amazon Nova、Mistral家族及其他模型）。研究还发现了自我反思在不同领域的效果差异，特别是在数学推理任务中性能可提高220%。研究进一步探讨了反思轮次深度和反馈机制质量对不同模型家族性能的影响。此外，通过在Lounge by Zalando的营销内容本地化系统中部署自我反思增强功能，验证了研究成果在实际应用中的适用性。
### Conclusion
研究结果为选择合适的推理策略提供了实际指导，考虑到特定领域和资源限制时应进行领域特定评估。研究还开源了自我反思实施，以确保结果的可重复性。
## 806. `cs.LG` - PointMapPolicy: 结构化点云处理用于多模态模仿学习 [PDF](https://arxiv.org/pdf/2510.20406), [HTML](https://arxiv.org/abs/2510.20406)
### Authors
Xiaogang Jia,Qian Wang,Anrui Wang,Han A. Wang,Balázs Gyenes,Emiliyan Gospodinov,Xinkai Jiang,Ge Li,Hongyi Zhou,Weiran Liao,Xi Huang,Maximilian Beck,Moritz Reuss,Rudolf Lioutikov,Gerhard Neumann
### Background
机器人操作系统可以从互补的感知模态中受益，其中每种模态提供关于环境的独特信息。点云捕获详细的几何结构，RGB图像提供丰富的语义上下文。当前的点云方法在捕捉细节方面存在困难，尤其是在复杂任务中，而RGB方法缺少几何感知，这阻碍了它们的精度和泛化能力。
### Innovation
我们介绍了PointMapPolicy，这是一种新颖的方法，它通过结构化的点网格对扩散策略进行条件化，而无需下采样。这种方法使得更容易从观察中提取形状和空间关系，并且可以在不同的参考框架之间进行转换。由于它们在正交网格中的结构化，我们能够直接将成熟的计算机视觉技术应用于3D数据。使用xLSTM作为骨干网络，我们的模型高效地将点图与RGB数据融合，以增强多模态感知。我们的方法在RoboCasa和CALVIN基准测试以及真实机器人评估中展示了在多种操作任务上的最先进的性能。
### Conclusion
通过广泛的实验，我们证明了PointMapPolicy方法在多模态模仿学习中实现了最先进的性能。我们的模型有效地将点图与RGB数据结合，提高了多模态感知的能力，并在多种操作任务中取得了最佳结果。详细的内容和演示可在我们的项目页面查看: [this https URL](this https URL)。
## 807. `cs.LG` - 强化学习与消费储蓄行为 [PDF](https://arxiv.org/pdf/2510.20748), [HTML](https://arxiv.org/abs/2510.20748)
### Authors
Brandon Kaplowitz
### Background
本文通过强化学习的视角解释了经济衰退期间家庭消费行为的两个难以理解的模式。研究表明，在面对经济衰退时，家庭的消费储蓄决定机制在收入不确定性情况下使用Q-学习和神经网络近似可以更好地模拟实际数据。
### Innovation
本文开发了一个模型，其中代理使用神经网络近似的Q-学习进行消费储蓄决策，这与标准的理性预期假设有所不同。该模型通过价值函数近似误差的演变，同时解释了高资产家庭和低资产家庭在刺激转移下的边际消费倾向差异，以及以前失业次数多的家庭在控制当前经济状况后持久较低的消费水平。这种机制不同于基于收入风险信念更新或先验异质性的现有解释。
### Conclusion
模拟结果与实证估计高度契合，表明通过强化学习适应性学习可以为理解过去经验如何塑造当前消费行为提供统一的框架，超出了当前经济条件所能预测的范围。
## 808. `cs.LG` - 通过权重偏差校正和位级核心采样提高多比特量化网络训练效率 [PDF](https://arxiv.org/pdf/2510.20673), [HTML](https://arxiv.org/abs/2510.20673)
### Authors
Jinhee Kim,Jae Jun An,Kang Eun Jeon,Jong Hwan Ko
### Background
多比特量化网络可以通过在单个模型中支持多种精度级别，灵活部署深度神经网络。然而，现有的方法存在较大的训练开销，因为每个支持的位宽都需要对全数据集进行更新，导致总体成本线性增长。此外，为了支持额外或中间精度选项，还需要额外的微调阶段，这进一步增加了训练负担。
### Innovation
本文提出了一种技术来大大减少训练开销，同时不牺牲模型实用性：(i) 通过权重偏差校正，允许共享批量归一化，并通过中和量化偏差和调整激活分布来消除额外的微调需求；(ii) 位级核采样策略使每个子模型能够通过利用隐含的知识迁移现象，从基于梯度的重要性评分中选择紧凑且具有信息性的子集进行训练。这一方法在CIFAR-10/100、TinyImageNet和ImageNet-1K上的实验表明，我们的方法在减少训练时间高达7.88倍的同时，仍能获得竞争力或更优的准确性。
### Conclusion
实验结果表明，我们的方法在CIFAR-10/100、TinyImageNet和ImageNet-1K数据集上，在保持或提高准确性的同时，将训练时间最多减少7.88倍。我们的代码可在此处下载：this https URL。
## 809. `cs.LG` - 感知偏见在公平选择中的战略成本 [PDF](https://arxiv.org/pdf/2510.20606), [HTML](https://arxiv.org/abs/2510.20606)
### Authors
L. Elisa Celis,Lingxiao Huang,Milind Sohoni,Nisheeth K. Vishnoi
### Background
公平的评价体系旨在公正地奖励技能和努力。然而，人群之间普遍存在种族、性别和阶级的差距，挑战了这一理念。一些人认为这些差距是结构性不平等的结果；另一些人则认为是个人选择导致的。本文构建了一个博弈论模型，说明了不同社会经济背景的候选人之间关于评估后价值感知的不同，这种差异受到社会环境的影响，以及人工智能工具提供的个性化职业或薪酬建议。每个候选人根据成本与预期回报之间的权衡来战略性地选择投入努力，努力反映为可观察的技能，选择仅基于技能。
### Innovation
本文开发了一种博弈论模型，其中候选人从不同的社会经济背景出发，感知到的评估后价值不同，这种差异由社会环境塑造，并且越来越受到人工智能工具提供的个性化职业或薪酬建议的影响。模型在大量参与者的情况下刻画了一个独特的纳什均衡，并推导出明确的公式，显示了主观价值的差异和机构选择性如何共同决定努力、代表性、社会福利和效用。此外，提出了一种成本敏感的优化框架，量化了改变选择性或感知价值如何可以在不牺牲机构目标的情况下减少差距。模型揭示了感知驱动的偏见：当不同群体之间的评估后价值感知不同时，这些差异会理性地导致不同水平的努力，从而通过“公平”的选择过程反向传递差异。尽管模型是静态的，但它捕捉到了一个更广泛的反馈循环的一部分，将感知、激励和结果联系起来，通过显示技术社会环境如何塑造机能制度下的个人激励，弥合了理性选择和结构性不平等解释之间的鸿沟。
### Conclusion
感知驱动的偏见在公平选择过程中具有战略成本。尽管模型是静态的，但它展示了技术和社会环境如何塑造候选人选择努力水平的激励机制，从而影响最终的选择结果。通过分析这些动态，提出了一种成本敏感的优化框架，可以量化改变选择性和感知价值对公平性的影响，而不会牺牲机构目标。这一模型揭示了如何通过调整目标和价值观来管理偏见，以促进更具包容性的公平选择过程。
## 810. `cs.LG` - 神经多样性正则化小型模型中的幻觉 [PDF](https://arxiv.org/pdf/2510.20690), [HTML](https://arxiv.org/abs/2510.20690)
### Authors
Kushal Chakrabarti,Nirmal Balachundhar
### Background
语言模型在参数、计算和数据不断增加的情况下仍然存在遐想现象。研究提出神经多样性——去相关的并行表示——作为一种在固定参数和数据预算下减少遐想率的机制。受到投资组合理论的启发，证明了表征的不确定性可以减少风险，因此，语言模型需要一个适当的神经多样性水平。
### Innovation
提出了神经多样性作为一种方法，通过加入去相关的并行表示减少模型的遐想现象。引入了ND-LoRA（神经多样性低秩适应），结合了LoRA适配器和Barlow Twins正则化，实验证明其能在不降低整体准确性的前提下减少达25.6%的遐想现象（平均减少14.6%）。实验证明，LoRA适配器和正则化作用协同，因果干预证明神经多样性是中间变量，相关性分析显示规模效应。
### Conclusion
在不同的任务中，最优的神经多样性水平可能会不同。研究结果强调神经多样性作为一种改善语言模型可靠性的第三种尺度维度，与其他两个维度（参数和数据）相独立，可以在固定预算下提高语言模型的可靠性。
## 811. `cs.LG` - CSU-PCAST: 一种用于中长期集合降水预测的双支路变换器框架 [PDF](https://arxiv.org/pdf/2510.20769), [HTML](https://arxiv.org/abs/2510.20769)
### Authors
Tianyi Xiong,Haonan Chen
### Background
中长期降水预测对于水文气象风险管理和灾害减轻至关重要，但当前的数值天气预测系统仍然难以维持高技能，尤其是在长时间尺度上预测中小到大雨量时。传统集合系统如全球集合预报系统（GEFS）难以保持高技能，因此需要开发新的方法来提高中长期降水预测的准确性。
### Innovation
本文提出了一种基于深度学习的集合框架（CSU-PCAST），通过联合建模大气变量集合进行多步降水预测。模型采用分块式的Swin Transformer骨干网络，并结合周期卷积来处理经向连续性，通过条件层标准化集成时间和噪声嵌入。双支路解码器分别预测总降水量和其他变量，并专门冻结编码器-解码器路径以进行训练。训练过程中采用结合连续排名概率评分（CRPS）和加权对数1+均方误差（log1pMSE）的混合损失函数，平衡概率准确性和幅度忠实度。在中长期预报中，该模型通过实时全球预报系统（GFS）初始条件自回归生成预报数据。
### Conclusion
该模型在采用集成多卫星降水测量（IMERG）数据的GEFS进行评估时，展示了在0.1 mm、1 mm、10 mm和20 mm降水阈值下的更高成功指数（CSI）分数，特别是在中到大雨量的预测中表现出改进的性能。
## 812. `cs.LG` - 基于Node.js包中动态程序分析报告的学习型漏洞分类 [PDF](https://arxiv.org/pdf/2510.20739), [HTML](https://arxiv.org/abs/2510.20739)
### Authors
Ronghao Ni,Aidan Z.H. Yang,Min-Chien Hsu,Nuno Sabino,Limin Jia,Ruben Martins,Darion Cassel,Kevin Cheang
### Background
程序分析工具通常会产生大量候选漏洞报告，需要昂贵的人工审核。这给安全分析师提出了一个实际挑战，即如何优先处理最有可能是真实漏洞的报告。本文研究了是否可以使用机器学习来对程序分析工具报告的漏洞进行优先级排序。
### Innovation
本文通过构建基准数据集，包括1,883个Node.js包，每个包包含一个报告的ACE或ACI漏洞，评估了多种机器学习方法，如经典模型、图神经网络、大型语言模型以及结合图神经网络和大型语言模型的混合模型，这些方法都是基于动态程序分析工具的输出数据训练的。研究表明，顶级大型语言模型的$F_{1}$值达到0.915，而最佳图神经网络和经典机器学习模型的$F_{1}$值达到0.904，在低于7%的假阴性率下，领先模型可以删除66.9%的良性包，耗时约60毫秒/包。如果模型调整旨在0.8的精度水平（即允许20%的所有警告中的假阳性），该方法可以检测到99.2%的可利用污染流，而只错过了0.8%，显示出在真实世界漏洞分类中具有强大的潜力。
### Conclusion
研究发现机器学习在处理动态程序分析工具报告的漏洞中表现出色，特别是在减少假阴性率的同时，能够显著减少需要手动审查的包数量，而且有较高的检测率，表明该技术有强大的实际应用前景。
## 813. `cs.LG` - AlphaFlow: 了解和改进MeanFlow模型 [PDF](https://arxiv.org/pdf/2510.20771), [HTML](https://arxiv.org/abs/2510.20771)
### Authors
Huijie Zhang,Aliaksandr Siarohin,Willi Menapace,Michael Vasilkovsky,Sergey Tulyakov,Qing Qu,Ivan Skorokhodov
### Background
MeanFlow作为一种强大的框架，最近在从零训练的少量步骤生成建模中崭露头角，但其成功尚未完全理解。
### Innovation
本文引入了$beta$-Flow，这是一种旨在统一轨迹流匹配、Shortcut Model和MeanFlow的广泛目标家族。通过采用从轨迹流匹配平滑过渡到MeanFlow的教学策略，$beta$-Flow解决了冲突目标，取得了更好的收敛效果，特别是在从零训练时，$beta$-Flow在ImageNet-1K 256x256类条件设置下表现出色。使用vanilla DiT骨干网络，最大的$beta$-Flow-XL/2+模型实现了新的SOTA结果。
### Conclusion
当从零训练类条件ImageNet-1K 256x256时，$beta$-Flow在整个尺度和设置中始终优于MeanFlow。最大的$beta$-Flow-XL/2+模型使用vanilla DiT骨干网络，达到了FID分数为2.58（1-NFE）和2.15（2-NFE）的新SOTA结果。
## 814. `cs.LG` - 基于连贯性的一种AGI量化方法 [PDF](https://arxiv.org/pdf/2510.20784), [HTML](https://arxiv.org/abs/2510.20784)
### Authors
Fares Fourati
### Background
Hendrycks等人的近期研究将人工通用智能(AGI)定义为人类认知能力模型Cattell-Horn-Carroll (CHC)模型下跨认知领域综合能力的算术平均值。虽然这种定义简洁优雅，但它假设了在某些领域的能力优异可以弥补其他领域的失败。但是真正的通用智能应该体现连贯充分性，即在所有重要领域都平衡的胜任力。
### Innovation
本文提出了一种基于连贯性的度量AGI的方法，基于补偿指数连续体上广义平均值的积分。这种形式涵盖了算术、几何和谐波区间，并通过曲线下面积(AUC)量化了在不同补偿假设下的稳健性。与算术平均值相比，AUC惩罚不平衡并捕捉跨域依赖性。这种方法为测量真正进步提供了原则性的、可解释的和严格的基础。
### Conclusion
将广义平均值应用于基于CHC的GPT-4和GPT-5领域得分，调整后的连贯性AUC显示，尽管具有高算术分数，这两个系统在整体胜任力方面仍然远远不够。因此，这种方法揭示了通用智能研究中的系统局限于跨领域的不平衡，为衡量真实的AGI进步提供了新的视角。
## 815. `cs.LG` - Real Deep Research for AI, Robotics and Beyond [PDF](https://arxiv.org/pdf/2510.20809), [HTML](https://arxiv.org/abs/2510.20809)
### Authors
Xueyan Zou,Jianglong Ye,Hao Zhang,Xiaoyu Xiang,Mingyu Ding,Zhaojing Yang,Yong Jae Lee,Zhuowen Tu,Sifei Liu,Xiaolong Wang
### Background
随着人工智能和机器人学领域研究的迅速发展，每年发表的论文数量超过1万篇，这使得研究人员难以跟上最新进展。快速演变的趋势、跨学科研究的兴起以及探索超出自己专业知识领域的必要性，都构成了这一挑战。
### Innovation
本文提出了一种通用的分析管道，能够系统地分析任何研究领域：识别新兴趋势、发现跨领域机会，并为新的研究提供具体的起点。文章展示了Real Deep Research（RDR）框架在人工智能和机器人学领域的应用，特别是对基础模型和机器人技术的进步进行了深入分析。此外，还简要扩展了RDR框架在其他科学领域中的应用分析。
### Conclusion
我们希望这项工作能够为从事人工智能及其他相关领域的研究人员提供一些启示。附录提供了每个分析主题的详细结果，望能对研究有所帮助。
## 816. `cs.LG` - 通过混合稀疏注意和上下文可学习token逐出缓解线性注意力的健忘性 [PDF](https://arxiv.org/pdf/2510.20787), [HTML](https://arxiv.org/abs/2510.20787)
### Authors
Mutian He,Philip N. Garner
### Background
线性注意力模型通过将整个输入序列压缩到固定大小的递归状态来提供与Transformer相比的高效替代方案，但它们有限的记忆会导致忘记，从而影响检索密集型任务。为了解决这个问题，本文探索了一系列混合模型，恢复对过去token的直接访问。这些模型介于线性注意和全注意之间，包括具有token逐出的稀疏注意和基于query的原生稀疏注意。特别是，提出了一个新颖的学习token逐出方法。该方法结合滑动窗口注意力，一个可端到端训练的轻量级CNN从过去和未来的相邻token中聚合信息，以自适应地保留每头中关键的KV对，同时保持线性注意力的常数时间和空间复杂度。
### Innovation
提出了一种新颖的基于滑动窗口的轻量级CNN和学习token逐出方法，结合了线性和全注意的混合模型来缓解线性注意力的健忘性问题。此外，还提供了一种高效的Triton内核来支持稀疏注意机制。
### Conclusion
在检索密集型基准测试中的经验评估证明了本文方法的有效性。通过混合稀疏注意和上下文可学习token逐出的方法能够有效缓解线性注意力模型的健忘性问题，提升模型在检索密集型任务上的性能。
## 817. `cs.LG` - 使用球面图神经网络从CMB推断原始磁场参数的贝叶斯推理 [PDF](https://arxiv.org/pdf/2510.20795), [HTML](https://arxiv.org/abs/2510.20795)
### Authors
Juan Alejandro Pinto Castro,Héctor J. Hortúa,Jorge Enrique García-Farieta,Roger Anderson Hurtado
### Background
深度学习已成为现代宇宙学中的一个变革性方法，提供了从复杂天文学数据集中提取有意义的物理信息的强大工具。本文采用贝叶斯图形深度学习框架，直接从模拟的宇宙微波背景(CMB)图中估计原初磁场参数，通过球面卷积神经网络架构DeepSphere，考虑了CMB数据的球形几何特征。为了超越确定性点估计，实现稳健的不确定性量化，文章结合贝叶斯神经网络(BNNs)，捕捉到预测中的 aleatoric 和 epistemic 不确定性，反映模型对其预测的信心。
### Innovation
本文引入了结合球面图神经网络和贝叶斯神经网络的框架，实现在含PMF贡献的CMB图中准确估计关键宇宙学参数，同时提供了可靠的可能性定量。通过后验训练技术如Variance Scaling和GPNormal，实现了很好的不确定性估算。这种方法不仅提高了参数估计的准确性，还提供了可靠的可能性估计，为精确宇宙学的宇宙推断提供了必要的工具。
### Conclusion
本研究提出了结合DeepSphere和BNNs的框架，能够从包含PMF效应的CMB图中准确估计关键的宇宙学参数，并提供了可靠的不确定性量化。这一方法在原初磁场参数的贝叶斯推断中表现优异，为精确宇宙学提供了强有力的支持。
## 818. `cs.LG` - 机器人中的现实差距：挑战、解决方案和最佳实践 [PDF](https://arxiv.org/pdf/2510.20808), [HTML](https://arxiv.org/abs/2510.20808)
### Authors
Elie Aljalbout,Jiaxu Xing,Angel Romero,Iretiayo Akinola,Caelan Reed Garrett,Eric Heiden,Abhishek Gupta,Tucker Hermans,Yashraj Narang,Dieter Fox,Davide Scaramuzza,Fabio Ramos
### Background
机器学习推动了机器人领域如导航、运动和操作等多个方面的显著进步，许多这些成就都依赖于在现实环境部署之前通过模拟进行训练和测试。然而，模拟包含的抽象和近似会导致模拟环境与现实环境之间的差距，这被称为现实差距。这种差距阻碍了系统从模拟到现实世界的成功转移。关闭这个差距仍然是机器人领域的一个关键挑战。最近的一些研究证明了模拟到真实转换在各平台上的良好前景，包括运动、导航和操作，并且采用诸如领域随机化、真实到模拟转换、状态和行为抽象以及模拟和现实协同训练等技术。尽管取得了一些进展，但仍存在着挑战，并且需要对现实差距的根本原因和解决方案有更深入的理解。
### Innovation
本文提供了一个全面的模拟到真实转换的概览，强调了现实差距的原因、解决方案和评估指标。本文梳理了利用领域随机化、真实到模拟转换、状态和行动抽象以及模拟-现实协同训练等方法来解决现实差距的研究成果，并探讨了仍待解决的问题和未来研究方向。
### Conclusion
本文总结了当前模拟到真实转换的技术和方法，并提出了未来研究的方向。此外，本文还对现实差距的根本原因进行了深入探讨，并提出了一些改进现有方法的建议。
## 819. `cs.LG` - 使用像素空间时空变换器进行动态物理模拟的视频预测 [PDF](https://arxiv.org/pdf/2510.20807), [HTML](https://arxiv.org/abs/2510.20807)
### Authors
Dean L Slack,G Thomas Hudson,Thomas Winterbottom,Noura Al Moubayed
### Background
受自回归大型语言模型性能和可扩展性的启发，基于Transformer的模型在视觉领域取得了近期的成功。本研究探讨了一种简单的端到端方法，以便将Transformer模型适应于视频预测，并比较了不同的时空自注意力布局。特别是在物理模拟的时间因果建模方面，现有视频生成方法的一个常见缺点是其无法有效地进行时空推理。因此，本研究试图通过物理对象跟踪指标和无需监督的训练来实现这一点，主要利用连续像素空间表示进行视频预测，以实现自回归视频预测。这种方法不需要复杂的训练策略或潜在特征学习组件，能够显著提高物理准确预测的时间范围，并在通用视频质量指标上保持与现有潜在空间方法相当的表现。同时，我们还进行了可解释性实验，通过探针模型识别网络区域中编码有用信息的部分，这些信息可以用于准确估计偏微分方程模拟参数，这一方法表现出对非分布外模拟参数估计的泛化能力。本研究为未来的基于注意力的时空视频建模提供了一个简单、参数效率高且可解释的平台。
### Innovation
本研究介绍了一种简单的纯Transformer模型用于自回归视频预测，利用连续像素空间表示进行视频预测，无需复杂的训练策略或潜在特征学习组件，显著延长了物理准确预测的时间范围（最多提高50%），同时保持与现有潜在空间方法相当的性能。此外，通过探针模型识别网络区域中编码有用信息的部分，这一方法能够泛化到非分布外模拟参数的估计。
### Conclusion
本研究为基于注意机制的时空视频建模提供了简单、参数有效且可解释的方法，为未来的研究奠定了基础。
## 820. `cs.LG` - LLM-生成文本的可检测性：什么是LLM-生成的文本？ [PDF](https://arxiv.org/pdf/2510.20810), [HTML](https://arxiv.org/abs/2510.20810)
### Authors
Mingmeng Geng,Thierry Poibeau
### Background
随着大型语言模型（LLMs）的广泛应用，研究人员开始关注如何检测由它们生成的文本。然而，对于‘LLM生成文本’这一目标并没有一个一致和明确的定义，这使得检测更加困难。常见的检测目标通常只代表LLMs可能生成文本的一部分。同时，人类对LLM输出的编辑以及LLM对使用者的微妙影响，使得两者之间的界限变得模糊。现有的基准和评估方法未能充分应对实际应用场景中的各种情况，因此检测器的结果常被误解且意义减弱。这意味着，在特定条件下，检测器依然很有用，但其结果只应作为参考而非决定性指标。
### Innovation
本文指出了当前对LLM生成文本的检测存在的一些难点，包括没有明确的定义、实际场景中的应用场景差异和LLM的多样性等，强调了当前基准和评估方法的不足。
### Conclusion
检测器在特定条件下仍可提供有用的信息，但其结果应被视为参考而非决定性指标。
## 821. `cs.LG` - Faiss库 [PDF](https://arxiv.org/pdf/2401.08281), [HTML](https://arxiv.org/abs/2401.08281)
### Authors
Matthijs Douze,Alexandr Guzhva,Chengqi Deng,Jeff Johnson,Gergely Szilvasy,Pierre-Emmanuel Mazaré,Maria Lomeli,Lucas Hosseini,Hervé Jégou
### Background
矢量数据库通常管理大量嵌入向量集合。随着AI应用的快速增长，需要存储和索引的嵌入数量也在增加。Faiss库致力于向量相似搜索，这是矢量数据库的核心功能。Faiss是一个索引方法及其相关基本要素的工具包，用于搜索、聚类、压缩和变换向量。
### Innovation
本文描述了矢量搜索的权衡空间，以及Faiss的设计原则，包括结构设计、优化方法和接口设计。同时，基准测试了库的关键功能，并讨论了几种选定的应用案例，以突显其广泛的应用性。
### Conclusion
本文分析了Faiss库的功能和设计，通过基准测试展示了其性能，并强调了其在多种应用场景中的灵活性和适用性。
## 822. `cs.LG` - 多任务逆强化学习用于获取常识性奖励 [PDF](https://arxiv.org/pdf/2402.11367), [HTML](https://arxiv.org/abs/2402.11367)
### Authors
Neta Glazer,Aviv Navon,Aviv Shamsian,Ethan Fetaya
### Background
在复杂的真实世界环境中应用强化学习的一个挑战是为代理提供足够详细的奖励函数。任何奖励与期望行为之间的对齐偏差都可能导致不良结果，如‘奖励作弊’，即代理通过非预期行为最大化奖励。因此，需要分离出奖励，使之包含特定任务的简单奖励和环境中介代理期望行为的未知常识性奖励。
### Innovation
本文提出了一种新的方法，即多任务逆强化学习，通过同时对多个任务进行训练，学习有用的奖励功能。这种方法解决了传统逆强化学习训练出的代理无法有效模仿专家行为的问题。
### Conclusion
该研究通过多任务逆强化学习成功提供了更好的常识性奖励，进而改善了代理的行为表现。
## 823. `cs.LG` - 通过机器学习在闪电网络中插值信道余额 [PDF](https://arxiv.org/pdf/2405.12087), [HTML](https://arxiv.org/abs/2405.12087)
### Authors
Vincent Davis,Emanuele Rossi,Vikash Singh
### Background
比特币的闪电网络是一个第二层支付协议，通过支付通道来实现快速和成本效益高的交易，以解决比特币的可扩展性问题。已有研究在平衡探查和多路径支付协议方面进行了大量探索，但仅通过节点和信道特征预测信道余额仍然是一个未被探索的领域。本文通过评估几种机器学习模型的性能，与两种启发式基准进行比较，研究了不同特征的预测能力。实验结果显示，本文模型优于等分基线，性能提升了10%。
### Innovation
本文主要贡献在于通过机器学习模型来插值闪电网络中的信道余额，这在现有研究中是一个未曾探索的领域。同时，通过模型对比实验发现了高性能的特征集，有效优化了网络的路径寻找算法。
### Conclusion
本文通过机器学习模型在闪电网络中插值信道余额，研究了几种模型的性能并发现了高性能的特征集。实验结果表明，模型性能优于现有基准，有助于优化网络路径寻找算法，未来可以进行大规模的真实环境测试以验证模型效果。
## 824. `cs.LG` - 基于条件一致性的神经回归器概率拟合评估 [PDF](https://arxiv.org/pdf/2405.12412), [HTML](https://arxiv.org/abs/2405.12412)
### Authors
Spencer Young,Riley Sinema,Cole Edgren,Andrew Hall,Nathan Dong,Porter Jenkins
### Background
尽管在代表不确定性的神经网络方面取得了显著进展，但深度网络仍然经常表现出过度自信和预测分布错配的问题。现有的评估不匹配的方法主要是在校准框架下进行，常用的指标包括期望校准错误（ECE）。然而，校准只能提供概率对齐的边缘评估，因此，校准指标如ECE是针对整个分布的测量，不能诊断单个输入点的具体可靠性，这对实际决策非常重要。
### Innovation
提出了条件一致性这一更强的标准来评估概率模型的拟合度，并引入了条件一致性误差（CCE）这一新的度量标准，该标准使用条件核均值嵌入来估计数据集中任何点处学习得到的预测分布与经验条件分布之间的距离。研究显示，CCE具有正确性、单调性、可靠性和鲁棒性等四大关键属性。
### Conclusion
评估神经回归器概率拟合的新方法（CCE）展示了其在高维回归任务中的有效性，并且确认CCE作为一个度量标准具有四个重要的特性。
## 825. `cs.LG` - VAMOS: 一种用于能力调节和可操控导航的层次化视觉-语言-行为模型 [PDF](https://arxiv.org/pdf/2510.20818), [HTML](https://arxiv.org/abs/2510.20818)
### Authors
Mateo Guaman Castro,Sidharth Rajagopal,Daniel Gorbatov,Matt Schmittle,Rohan Baijal,Octi Zhang,Rosario Scalise,Sidharth Talia,Emma Romig,Celso de Melo,Byron Boots,Abhishek Gupta
### Background
机器人导航面临的基本挑战是在学习能够在多种多样的环境中推广的策略，同时还要遵守特定物理载体的独特物理约束和能力（例如，四足机器人可以上楼梯，但轮式机器人不行）。现有的模型和端到端学习方法在处理这些挑战时表现不佳，尤其是在复杂环境下的导航任务中。论文提出了一种名为VAMOS的分层VLA模型，它将语义规划与载体具体化分离：generalist规划器从多样化的开放世界数据中学习，而专门的 affordedness模型则在安全且低成本的模拟环境中学习机器人的物理约束和能力。通过精心设计的接口使高层规划器可以直接在图像空间中提出候选路径，由affordance模型进行评估和重新排序。实验证明，VAMOS在室内和复杂室外导航中比最先进的模型和端到端学习方法具有更高的成功率。此外，研究表明，分层的设计使跨不同载体种类的导航成为可能，且易于使用自然语言进行调控。在实际场景中的消融实验表明，专门的模型对于载体具体化至关重要，使单一高层规划器能够跨不同类型（包括腿式和轮式）的机器人部署。最后，该模型显著提高了单个机器人导航的可靠性，使其成功率达到3倍之多，通过拒绝物理上不可行的计划来实现这一点。
### Innovation
VAMOS提出了一个分层的VLA模型，将语义规划与载体具体化分离。它包括generalist planner（泛化规划器）和affordance model（赋能力模型）两种模型。generalist planner从多样化的开放世界数据中学习，而affordance model在安全且低成本的模拟环境中学习机器人的物理约束和能力。该模型通过一个精心设计的接口，使高层规划器可以在图像空间中直接提出候选路径，然后由affordance模型进行评估和重新排序。实验证明，VAMOS能够实现更高的成功率，并且能够跨不同种类的载体进行导航，同时也易于使用自然语言进行控制。
### Conclusion
VAMOS在复杂环境下的导航中取得了明显优于现有模型和端到端学习方法的成功率。通过将语义规划与载体具体化分离，VAMOS不仅实现了跨不同种类的机器人导航，而且还展现了高度的可操控性。这些结果表明，VAMOS为机器人导航插上了翅膀，具有广泛的应用前景。
## 826. `cs.LG` - 通过连续反馈对变压器进行能量等级对齐 [PDF](https://arxiv.org/pdf/2405.12961), [HTML](https://arxiv.org/abs/2405.12961)
### Authors
Shriram Chennakesavalu,Frank Hu,Sebastian Ibarraran,Grant M. Rotskoff
### Background
化学空间搜索是一个极其具有挑战性的问题，因为它包含的可能分子数量随原子数量的增加呈组合式增长。虽然大型自回归模型在数据库中的化学化合物训练后已经产生强大的生成器，但我们仍然缺乏可靠的策略来生成具有特定性质的分子。此分子搜索问题与大型语言模型的“对齐”问题相似，但对于许多化学任务，我们有一个明确且易于评估的奖励函数。
### Innovation
作者提出了一种名为能量排名对齐（ERA）的算法，该算法利用显式的奖励函数产生梯度基目标，从而优化自回归策略。理论上，该算法与近端策略优化（PPO）和直接偏好优化（DPO）密切相关，但其优化器收敛于理想的理想吉布斯-玻尔兹曼分布，奖励函数作为能量函数的角色。此外，该算法具有高度的可扩展性，不需要强化学习，并在每对观测的偏好样本小时，相对DPO表现良好。
### Conclusion
该方法被用于对分子转化器和蛋白质语言模型进行对齐，以分别生成具有外部指定性质的分子和蛋白质序列，结果显示该方法能在化学空间中持续有效地进行搜索。
## 827. `cs.LG` - 基于对比学习和预测性潜在扩散桥的一般模态翻译 [PDF](https://arxiv.org/pdf/2510.20819), [HTML](https://arxiv.org/abs/2510.20819)
### Authors
Nimrod Berman,Omkar Joglekar,Eitan Kosman,Dotan Di Castro,Omri Azencot
### Background
最近，生成模型的发展使扩散模型成为从复杂数据分布中采样的先进工具。这些模型在单模态领域，如图像和音频方面表现出显著的成功。然而，将其能力扩展到模态翻译（MT），即在不同的感觉模态间翻译信息，仍是一个未解决的挑战。现有的方法往往依赖于共享维度、高斯先验和特定模态架构等严格的假设，这限制了它们的普遍性和理论基础。本文引入了一种基于潜在变量扩展的去噪扩散桥模型（Latent Denoising Diffusion Bridge Model，LDDBM）的新框架，以解决这个问题。这种方法在共享的潜在空间中运行，学习任意模态之间的桥梁，而无需对齐维度。由此引入了一种对比对齐损失来确保配对样本之间的语义一致性，并设计了一种跨模态噪声预测的领域通用编码器-解码器架构。这项研究支持任意模态对，并且在多种模态翻译任务上表现出了强大的性能，包括从多视图到3D形状生成、图像超分辨率和多视图场景合成。综合实验和消融测试验证了该框架的有效性，建立了新的强基线参考线，适用于一般的模态翻译任务。
### Innovation
本文提出了一种新的模态翻译框架——潜在去噪扩散桥模型（Latent Denoising Diffusion Bridge Model，LDDBM），该框架在共享的潜空间中操作，能够学习任意模态之间的桥梁关系，而不需要对齐维度。通过引入对比对齐损失，以确保配对样本之间的语义一致性，并设计了适用于噪声预测的跨模态通用编码器-解码器架构。此外，还提出了预测损失以指导准确的跨域翻译，探索了多种训练策略以改进模型的稳定性。
### Conclusion
本方法支持任意模态对并且在多种模态翻译任务上表现出色，包括多视图到3D形状生成、图像超分辨率和多视图场景合成。全面的实验和消融测试验证了该框架的有效性，建立了一种新的强标准参考线，适用于通用模态翻译任务。
## 828. `cs.LG` - Log Neural Controlled Differential Equations: The Lie Brackets Make a Difference [PDF](https://arxiv.org/pdf/2402.18512), [HTML](https://arxiv.org/abs/2402.18512)
### Authors
Benjamin Walker,Andrew D. McLeod,Tiexin Qin,Yichuan Cheng,Haoliang Li,Terry Lyons
### Background
该研究背景建立在控制微分方程的向量场描述控制路径与解路径演变之间关系的基础上。神经控制微分方程（NCDEs）将时间序列数据视为控制路径的观测值，通过神经网络参数化控制微分方程的向量场，并将解路径作为连续演变的隐藏状态。鉴于其对不规则采样率的鲁棒性，NCDEs是建模现实世界数据的强大方法。基于神经粗糙微分方程（NRDEs），该方法介绍了一种新颖、有效且高效的Log-NCDEs方法，以训练NCDEs，并展示了它在多种多变量时间序列数据集上的优越性，这些数据集最多包含50,000个观测值。核心组件是粗糙路径研究中的Log-ODE方法，用于近似控制微分方程的解。在多个数据集上，Log-NCDEs显著优于NCDEs、NRDEs、线性递归单元、S5和MAMBA方法。
### Innovation
该创新在于提出了Log-NCDEs，这是一种新颖有效的学习NCDEs的方法。其核心是基于粗糙路径研究的Log-ODE方法，用于近似控制微分方程的解。Log-NCDEs展示了比NCDEs、NRDEs、线性递归单元、S5和MAMBA等方法更好的性能，尤其在处理最多包含50,000个观测值的多变量时间序列数据集上表现突出。
### Conclusion
通过提出Log-NCDEs方法，利用Log-ODE方法的高效性，该研究提供了对控制微分方程更为有效的学习和应用方式，特别是在处理大规模和不规则采样率的时间序列数据方面。Log-NCDEs在多种数据集上优于现有的方法，展示了其在实际应用中的强大潜力。
## 829. `cs.LG` - 优化时间序列预测架构：一种分层神经架构搜索方法 [PDF](https://arxiv.org/pdf/2406.05088), [HTML](https://arxiv.org/abs/2406.05088)
### Authors
Difan Deng,Marius Lindauer
### Background
时间序列预测研究的迅速发展引入了许多基于深度学习的模块，然而，尽管有大量的新型预测架构出现，我们仍然不清楚是否已经充分利用了这些现有模块的潜力，尤其是在一个合理设计的架构中。
### Innovation
提出了一种分层神经架构搜索方法来解决时间序列预测任务。通过设计分层搜索空间，整合了许多为预测任务设计的架构类型，并允许不同预测架构模块的有效组合。研究结果表明，该方法可以在不同预测任务中搜索到轻量级高性能预测架构。
### Conclusion
该方法在长期时间序列预测任务中的结果表明，可以搜索到适用于多种预测任务的轻量级高性能预测架构。
## 830. `cs.LG` - 使用成员或acles求解具有未知背包约束的0-1整数规划问题 [PDF](https://arxiv.org/pdf/2405.14090), [HTML](https://arxiv.org/abs/2405.14090)
### Authors
Rosario Messana,Rui Chen,Andrea Lodi,Alberto Ceselli
### Background
本文考虑使用成员或acles解决具有未知背包约束的组合优化问题时的情况，其中每个未知约束都有一个成员或acles，可以确定给定解是否满足该约束。决策者的目的是在预算内找到最佳解，即在或acles调用量有限的情况下找到最优解。本文借鉴了基于支持向量机（SVM）的二元分类的主动学习方法，研究解决未知约束背包问题的框架。该框架包括训练线性边界器和选择新点进行标记，其中包括使用采样策略并解决0-1整数线性规划问题。传统上，可以使用SVM作为线性分类器和以简单边缘为基础的信息采样策略。然而，本文提出了改进：提出了基于混合整数二次规划的替代采样策略和受凸优化算法启发的线性分离方法。研究了不同的线性分离方法和采样策略对结果质量的影响，包括目标值、对偶界和运行时间等指标。通过经典问题及其现实应用的变体进行实验验证。
### Innovation
本文提出了使用混合整数二次规划的替代采样策略和以凸优化算法为灵感的线性分离方法，改进了传统的基于SVM的采样策略和线性分离方法。通过实验验证了不同线性分离方法和采样策略对结果质量的影响，并验证了所提出方法的有效性。
### Conclusion
本文提出了一个结合了混合整数二次规划和新型线性分离方法的主动学习框架，克服了传统方法的局限性。最终，研究发现所提出的框架在多个评估标准上都有了显著提升，实验结果表明了新型采样策略和线性分离方法的有效性。
## 831. `cs.LG` - 简单的上下文压缩：均值池化和多比例训练 [PDF](https://arxiv.org/pdf/2510.20797), [HTML](https://arxiv.org/abs/2510.20797)
### Authors
Yair Feldman,Yoav Artzi
### Background
在使用大语言模型（LLMs）的检索增强生成（RAG）中，为了减少使用长上下文的计算成本，通常采用软上下文压缩的方法，即将输入序列转换为较短的连续表示。常见的压缩方法是使用压缩标记架构，但该研究开发了一种轻量且简单的均值池化方法，并且这种方法在多个实验中表现优于压缩标记架构。进一步地，研究还探讨了针对同一压缩器训练多个压缩比例的问题。研究覆盖了多种领域和外部领域的问题回答数据集，以及多个模型系列、规模和压缩比例。研究表明，简单的均值池化方法在大多数情况下表现最佳，但在为多个压缩比例训练时，性能有轻微下降。然而，总体而言，不同的架构和训练策略之间的取舍关系较为复杂，反映了压缩方法复杂的适用性景观。
### Innovation
研究开发了一种轻量级且简单的均值池化方法，该方法在多个实验中优于常用的压缩标记架构。进一步地，研究探讨了同一压缩器同时输出多个压缩比例的可能性，发现虽然在为多个压缩比例训练时性能略有下降，但在大多数情况下该方法表现最佳。研究还揭示了不同压缩方法在不同模型和训练策略下的复杂性差异。
### Conclusion
简单的均值池化方法在大多数情况下表现出色，即使针对多个压缩比例进行训练时也有相对较小的性能下降。然而，不同压缩方法在不同模型及训练策略下的复杂性差异表明，压缩方法的选择需综合考虑具体应用的需求和条件。
## 832. `cs.LG` - 预训练决策变换器以奖励预测方式实现任务内多任务结构化臂学习 [PDF](https://arxiv.org/pdf/2406.05064), [HTML](https://arxiv.org/abs/2406.05064)
### Authors
Subhojyoti Mukherjee,Josiah P. Hanna,Qiaomin Xie,Robert Nowak
### Background
本文研究了多任务结构化臂问题的学习，目标是学习一个接近最优的算法以最小化累积遗憾。任务共享一种常见结构，算法应利用共享结构来最小化新出现但相关的测试任务的累积遗憾。使用transformer作为决策算法，通过示范者在一组训练任务实例上收集的数据来学习这种共享结构。目标是设计一种训练过程，使transformer能够在未见的测试任务实例上超越示范者的算法表现。此前的工作要么需要提前知道最佳策略的信息（如访问到最优臂），要么无法超越示范者的性能。在此基础上，本文提出了一种新的预训练方法，该方法通过反向推理学习共享的结构，能够在上下文环境中学习接近最优策略，这种方法不需访问最优行为，并能超越示范者的性能。
### Innovation
本文介绍了一种预训练方法，能够通过奖励预测训练transformer网络以学习接近最优策略。这一方法可以利用跨任务的共享结构，无需访问最优行为，且能在未见的测试任务上超越示范者的性能。因此，这种方法创新地实现了在多任务结构化臂问题中的上下文学习，无需提前知道最优策略，相比现有方法更具有泛化能力。
### Conclusion
本文验证了该方法在多种结构化臂问题中的有效性，证明了所提出的方法具有普适性，并能在未知测试任务上快速识别期望奖励，为有效的探索提供了支持。
## 833. `cs.LG` - 通过稀疏傅里叶表示计算SHAP值 [PDF](https://arxiv.org/pdf/2410.06300), [HTML](https://arxiv.org/abs/2410.06300)
### Authors
Ali Gorji,Andisheh Amrollahi,Andreas Krause
### Background
SHAP值作为一种广泛使用的局部特征归因方法，在可解释人工智能领域得到了广泛应用。现有的计算SHAP值的方法在不同场景下效率低下，尤其是在黑盒模型和基于树的模型中。对于黑盒模型和基于树的模型，我们提出了一种高效的两阶段算法来计算SHAP值。这种算法能够在不牺牲精度的同时提高计算效率。
### Innovation
1. 首先，通过紧凑的傅里叶表示对模型进行近似，对于基于树的模型是精确的，对于黑盒模型是近似的。2. 在第二阶段，提出了一个闭合形式的公式，可以通过傅里叶表示“线性化”地计算SHAP值，易于并行化。3. 由于傅里叶近似只需要计算一次，本方法能够实现SHAP值的分摊计算，显著提高了速度，并且提供了一种对效率和精度进行权衡的方法。
### Conclusion
本方法通过傅里叶表示实现了SHAP值的高效计算，相比现有方法具有显著的加速效果，并且能够根据需求调整效率与精度的平衡。
## 834. `cs.LG` - Temporal-Difference Variational Continual Learning [PDF](https://arxiv.org/pdf/2410.07812), [HTML](https://arxiv.org/abs/2410.07812)
### Authors
Luckeciano C. Melo,Alessandro Abate,Yarin Gal
### Background
在现实世界应用中的机器学习模型必须持续学习新的任务以适应数据生成分布的变化。然而，连续学习（Continual Learning，CL）模型在平衡学习新任务（可塑性）与保留先前知识（记忆稳定性）之间常常表现出色。这使得它们容易遭受灾难性遗忘现象的影响，该现象会降低模型性能并削弱已部署系统的可靠性。在贝叶斯CL文献中，变分方法通过利用能递归更新后验分布并确保其靠近先前估计的学习目标来应对这一挑战。
### Innovation
本文提出了一种新的学习目标，它整合了多个先前后验估计的正则化效果，防止个别错误在未来后验更新中主导并随时间累积。这一新方法与时差差异（Temporal-Difference）方法建立了新的联系，这些方法在强化学习和神经科学中很受欢迎。实验结果表明，这种方法有效缓解了灾难性遗忘现象并优于现有的变分CL方法。
### Conclusion
本文提出的方法在解决连续学习中的灾难性遗忘问题上表现优异，特别是在具有挑战性的连续学习基准测试中取得了更好的性能，优于现有的变分CL方法。
## 835. `cs.LG` - Learn2Mix：使用自适应数据集成训练神经网络 [PDF](https://arxiv.org/pdf/2412.16482), [HTML](https://arxiv.org/abs/2412.16482)
### Authors
Shyam Venkatasubramanian,Vahid Tarokh
### Background
在资源受限的环境中加速模型的收敛对于快速和高效的神经网络训练至关重要。传统的方法使用静态类别比例，这些方法在训练过程中不调整类别比例，导致收敛速度较慢。因此，需要一种新的训练策略来适应性地调整批次中的类别比例，特别是在那些具有较高错误率的类别上。
### Innovation
本文提出了Learn2Mix，这是一种新的训练策略，能在训练过程中自适应调整类别比例，聚焦于高错误率的类别。与使用静态类别比例的传统训练方法不同，Learn2Mix能够在整个训练过程中持续调整类别比例，从而加速收敛。实验证明，使用Learn2Mix训练的神经网络在各类任务（分类、回归和重构）上收敛速度更快，尤其是在资源有限和类别不平衡的情况下。
### Conclusion
实证研究结果得到了理论分析的支持，证明了Learn2Mix在不同任务类型和数据集上的有效性，特别是在资源受限和类别不平衡的情况下，提出的策略能够显著加速神经网络的训练过程，提高训练效果。
## 836. `cs.LG` - 低秩适应的可证明元学习 [PDF](https://arxiv.org/pdf/2410.22264), [HTML](https://arxiv.org/abs/2410.22264)
### Authors
Jacob L. Block,Sundararajan Srinivasan,Liam Collins,Aryan Mokhtari,Sanjay Shakkottai
### Background
基础模型（FMs）因其能够学习高度表达性的表示而具有强大的能力，可以应用于广泛的任务。然而，这些预训练模型需要额外的训练阶段才能有效用于下游应用。在多任务设置中，先前的研究表明，特定的元学习方法可以显著提高参数高效微调（PEFT）的效果，但元学习的机制仍需深入探究。本文介绍了一种通用的PEFT基元学习框架，旨在学习一个可以轻松适应未见过的任务的模型。对于使用LoRA的线性模型，本文证明了标准重训练对于找到可适应的参数集是不可证明的最优解，并提供了我们提出的方案的严格性能保证。通过在合成数据和真实的视觉与语言任务上的实验验证了这些理论洞见。结果表明，在重训练过程中使用我们提出的元学习方案可以显著提高性能，相比传统方法有着明显的优势。
### Innovation
本文引入了一种通用的PEFT基元学习框架，旨在学习一种适应未见过任务的模型。对于使用LoRA的线性模型，本文证明了标准重训练对于找到可适应的参数集是不可证明的最优解，并提供了我们提出的方案的严格性能保证。此外，我们通过实验验证了理论洞见，展示了相较于传统方法，我们提出的元学习方案能够显著提高性能。
### Conclusion
我们提出了一种新的元学习方案，与传统的重训练方法相比，在使用简单的实现方式进行PEFT时，能够显著提高模型的适应性。通过理论分析和实验验证，该方法在找到可适应的参数集方面展示了严格的性能优势，证实了其在实际应用中的有效性。
## 837. `cs.LG` - Twilight: 采用分层Top-$p$修剪实现适应性关注稀疏性 [PDF](https://arxiv.org/pdf/2502.02770), [HTML](https://arxiv.org/abs/2502.02770)
### Authors
Chaofan Lin,Jiaming Tang,Shuo Yang,Hanshuo Wang,Tian Tang,Boyu Tian,Ion Stoica,Song Han,Mingyu Gao
### Background
利用注意稀疏性加速长上下文大型语言模型（LLMs）是当前热门的研究课题。然而，现有的稀疏注意机制，如固定预设预算的稀疏注意或关键值（KV）缓存压缩算法，无法灵活应对实际场景中的动态变化，导致最优的准确性和效率之间的权衡难以达到。
### Innovation
提出了Twilight框架，将分层Top-$p$修剪技术引入到任何现有的稀疏注意机制中，实现适应性稀疏，同时保持原有的准确性。
### Conclusion
实验证明，Twilight框架能够适应性地修剪最多98%的冗余标记，将自我注意操作加速15.4倍，并将端到端每次标记延迟加速3.9倍。
## 838. `cs.LG` - 跨越变化同质性的经典GNNs：平滑性与泛化视角 [PDF](https://arxiv.org/pdf/2412.09805), [HTML](https://arxiv.org/abs/2412.09805)
### Authors
Ming Gu,Zhuonan Zheng,Sheng Zhou,Meihan Liu,Jiawei Chen,Tanyu Qiao,Liangcheng Li,Jiajun Bu
### Background
图神经网络（GNNs）在多个领域取得了巨大成功，但这些模型在面对不同水平的同质性时往往表现不佳。尽管一些经验研究发现，适当调参后同质性GNN也能在不同同质性水平的数据集上表现出色，但仍缺乏有效的理论支持和架构设计。本文深入研究了GNN的信息传递机制并揭示了一个新的平滑性-泛化困境：增加传递步数虽然能够提高平滑性，但会牺牲泛化能力，特别是在高阶同质性区域和所有异质性区域这些泛化能力至关重要的区域。这些区域的类分布复杂且对噪声和稀疏性敏感。
### Innovation
本文提出了一种新的图神经网络Inceptive Graph Neural Network (IGNN)。IGNN基于三个简单而有效的设计原则：平衡不同传播步长的泛化能力，同时通过适应性平滑性提升整体泛化性能。实验结果显示，IGNN在30个基线方法中表现出色，并揭示了一些同质性GNN变体的普适性。这些结果表明IGNN在特定的同质性场景下具有普遍适用性。
### Conclusion
本文通过对GNN信息传递机制的理论重新审视，揭示了平滑性-泛化困境，并提出了IGNN，通过适应性平滑机制在不同传播步长中平衡泛化能力，从而在不同同质性水平的图上提高了GNN的泛化能力。本文还展示了IGNN在一系列基准任务中的优越性能。
## 839. `cs.LG` - 从反事实到树：模型提取攻击的竞争性分析 [PDF](https://arxiv.org/pdf/2502.05325), [HTML](https://arxiv.org/abs/2502.05325)
### Authors
Awa Khouna,Julien Ferry,Thibaut Vidal
### Background
随着机器学习即服务（MLaaS）的兴起，模型的可解释性和安全性之间的权衡变得更加突出。尤其是可解释性技术（如反事实解释）会无意中增加模型提取攻击的风险，使未经授权复制专有模型变得更加可能。本文分析了模型重构的风险及其内在复杂性，特别关注用于准确推断底层预测函数所需的查询。
### Innovation
本文提供了基于加法决策树（如决策树、梯度提升和随机森林）模型重构的竞争性分析，并提出了新的重构算法，实现了可验证的完美还原精度，同时显示出强大的即时性能。此外，提出了从提取树模型的角度的查询复杂度理论界，为这些模型部署的安全漏洞提供了新的见解和评估框架。
### Conclusion
本文构建了一个基础框架，用于评估模型提取攻击的效率，并提供了从树模型提取的查询复杂度理论边界，提出了新的重建算法，实现了可证明的完美还原精度和优秀的即时性能。
## 840. `cs.LG` - Pareto-Optimal Energy Alignment for Designing Nature-Like Antibodies [PDF](https://arxiv.org/pdf/2412.20984), [HTML](https://arxiv.org/abs/2412.20984)
### Authors
Yibo Wen,Chenwei Xu,Jerry Yao-Chieh Hu,Kaize Ding,Han Liu
### Background
提出了一个用于抗体序列-结构协同设计的深度学习模型的三阶段框架。首先使用大量抗体序列数据预先训练一个语言模型，在此基础上使用学习到的表示来引导一种扩散模型，用于同时优化抗体的序列和结构。在最终对齐阶段，优化模型以偏好低排斥力和高吸引力到抗原结合位点的抗体为目标，增强设计的合理性和功能。为了缓解冲突的能量偏好，扩展了AbDPO技术，以在多种基于能量的对齐目标下引导模型向帕累托最优方向发展。此外，采用迭代学习范式，并通过温度缩放使模型能够从多样化的在线数据集中获益，而无需额外的数据支持。通过广泛的实验，在不同样本和之前对齐技术产生的样本中，展示了摘要提出的方法在生成具有高结合亲和力的自然抗体方面的优越性能，并生成了更好的帕累托前沿
### Innovation
提出了一种三阶段的框架，用于训练专注于抗体序列-结构协同设计的深度学习模型。创新点包括通过预先训练的自然语言模型和扩散模型引导训练过程，特别是在对抗原结合位点的结构优化中引入能量对齐目标。此外，通过扩展AbDPO技术，实现多能量对齐目标下的帕累托最优对齐，并采用迭代学习范式和温度缩放方法来提高模型的多样性和稳定性。
### Conclusion
提出的方法在生成具有高结合亲和力的自然抗体方面表现出优越性能，并能够在对抗体设计提供高稳定性的同时生成更好的帕累托前沿，相比于基线方法和先前的对齐技术生成的样本，具有更高的表现。
## 841. `cs.LG` - DMWM: 具有长期想象能力的双重思维世界模型 [PDF](https://arxiv.org/pdf/2502.07591), [HTML](https://arxiv.org/abs/2502.07591)
### Authors
Lingyi Wang,Rashed Shelim,Walid Saad,Naren Ramakrishnan
### Background
世界模型主要用于帮助智能体高效学习长期策略，现有基于递归状态空间模型（RSSM）的世界模型依赖于单步统计推理来捕捉环境动态，导致长期想象任务能力不足，这是因为预测错误的累积效应。人类认知的双重过程理论给予了启发，提出了新的双重思维世界模型（DMWM），融合了逻辑推理以确保长期想象的逻辑一致性。
### Innovation
DMWM框架由两个部分组成：基于RSSM的直观处理状态转换的System 1（RSSM-S1）和基于逻辑集成神经网络的通过层次深层逻辑推理引导想象过程的System 2（LINN-S2）。系统间反馈机制设计用于确保想象过程遵循真实环境的逻辑规则。
### Conclusion
在DMControl基准任务上的实验结果表明，与最先进的世界模型相比，该框架在逻辑一致性、试次效率、数据效率和长期想象方面具有显著改进。
## 842. `cs.LG` - 使用隔室原型预训练流行病时间序列预测模型 [PDF](https://arxiv.org/pdf/2502.03393), [HTML](https://arxiv.org/abs/2502.03393)
### Authors
Zewen Liu,Juntong Ni,Max S. Y. Lau,Wei Jin
### Background
准确的流行病预测对于应对疫情至关重要，但现有的数据驱动模型通常比较脆弱。这些模型通常只能在单一病原体上进行训练，面对新疫情时往往因数据稀缺而难以应对，并且在病毒进化或干预措施导致的分布变化时也难以有效应对。然而，多年来不同疾病的监控数据提供了丰富的借鉴知识。通过利用这些历史教训，本研究提出了CAPE，一个用于流行病预测的开源预训练模型，首次尝试建模流行病动力学，将流行病动态视为潜在人群状态的混合物。CAPE还通过结合自我监督预训练目标和轻量级的流行病学意识正则化器，促进了鲁棒的泛化能力。在包含17种疾病和50多个地区的一个全面基准测试中，CAPE在零样本、少样本和全样本预测方面显著优于强大的基线模型。
### Innovation
提出了一个用于流行病预测的开源预训练模型CAPE，该模型首次通过将流行病动态建模为潜在人群状态的混合物来克服常规时间序列模型对流行病学挑战的忽视。CAPE利用监控数据自动生成灵活的隔室原型字典，每个疫情都可以表示为时间变化的混合物，将观察到的感染与潜在人群状态联系起来。此外，通过结合自我监督预训练目标和轻量级的流行病学意识正则化器，CAPE提高了模型的稳健泛化能力。
### Conclusion
本研究代表了预训练流行病模型向前迈进的一步，这种模型不仅具有可转移性，而且与流行病学有实际联系。CAPE在跨17种疾病和50多个地区的广泛基准测试中表现出色，显著优于具有竞争力的基线模型，证明了其在零样本、少样本和全样本预测方面的优越性。
## 843. `cs.LG` - 通过编织排列的神经网络深度界限 [PDF](https://arxiv.org/pdf/2502.09324), [HTML](https://arxiv.org/abs/2502.09324)
### Authors
Moritz Grillo,Christoph Hertrich,Georg Loho
### Background
该研究致力于解决ReLu网络所需的隐藏层数量问题，以准确表示所有连续和分段线性函数。尽管在某些特殊情况下该问题已被解决，但一般情况下已知的最小下界仍是2。该研究特别关注与某些聚胞复合体兼容的神经网络，尤其是与编织扇形相关的网络。研究表明，此类网络需要非恒定的隐藏层数量下界为Ω(log log d)，才能准确表示d个数的最大值。
### Innovation
研究人员证明了在某些假定条件下，高度为3的网络对于计算5个数的最大值是必要的，此前只能通过计算验证。此外，研究还展示了最佳已知上限的自然推广在最大单元网络中的不精确性，通过证明使用一个秩为3的最大单元层后接一个秩为2的最大单元层即可表示7个数的最大值。
### Conclusion
对于与编织扇形兼容的神经网络，证明了非恒定的隐藏层数量下界为Ω(log log d)，用于表示d个数的最大值。还提供了计算5个数最大值所需的最小隐藏层数量为3的组合证明。最后，展示了一种自然推广的已知上限在最大单元网络中并不紧实，并通过具体的层结构证明了可以表示7个数的最大值。
## 844. `cs.LG` - WENDy for Nonlinear-in-Parameters ODEs [PDF](https://arxiv.org/pdf/2502.08881), [HTML](https://arxiv.org/abs/2502.08881)
### Authors
Nic Rummel,Daniel A. Messenger,Stephen Becker,Vanja Dukic,David M. Bortz
### Background
WENDy框架是一种用于参数估计和控制系统常微分方程（ODEs）推断的最近开发的方法。之前的WENDy工作表明，该方法在鲁棒性、计算效率和准确性方面表现出色，但仅适用于参数线性的ODEs。本文对其进行了扩展，使其能够处理参数非线性的更广泛类别的ODEs，并提出了一种新的WENDy-MLE算法，此算法通过局部非凸优化方法近似最大似然估计器，从而显著提高了准确性、增加收敛域并减少计算时间。此外，该方法扩展以适应包含对数正态噪声的多重乘法噪声数据。该实现使用Julia效率高。本文通过数值结果证明了该方法在准确性、精确性、偏差和覆盖率方面的实际优势，并将其与弱形式方法和输出误差最小二乘法进行了比较。
### Innovation
本文提出了一种新的WENDy-MLE算法，用于处理参数非线性的ODEs，通过局部非凸优化方法近似最大似然估计器。此方法提高了精度、增加了收敛域并通常比其他弱形式方法和输出误差最小二乘法更快。此外，该方法扩展以适应包含对数正态噪声的多重乘法噪声数据。
### Conclusion
本文的方法在准确性、精确性、偏差和覆盖率方面优于其他方法，并且通常计算更快。通过数值实验证明了该方法在实际操作中的优势。
## 845. `cs.LG` - 通过建模噪声依赖性训练鲁棒图神经网络 [PDF](https://arxiv.org/pdf/2502.19670), [HTML](https://arxiv.org/abs/2502.19670)
### Authors
Yeonjun In,Kanghoon Yoon,Sukwon Yun,Kibum Kim,Sungchul Kim,Chanyoung Park
### Background
在实际应用中，图中的节点特征常常包含来自各种来源的噪声，这会导致图神经网络（GNN）性能显著下降。尽管已经发展出多种方法来增强鲁棒性，但它们依赖一个不切实际的假设，即节点特征中的噪声与图结构和节点标签无关，这限制了其适用性。
### Innovation
本文引入了一种更为现实的噪声情景——图上的依赖性噪声（DANG），其中节点特征中的噪声会形成一连串噪声依赖关系，传播到图结构和节点标签。提出了一种新颖的鲁棒图神经网络（DA-GNN），它使用变分推断来捕捉DANG数据生成过程（DGP）中变量的因果关系。同时，还提供了一组新的基准数据集，模拟DANG在实际应用中的情况，使关于鲁棒图神经网络的研究更加实用。
### Conclusion
广泛的实验表明，DA-GNN在各种噪声场景下（包括DANG和通常被认为在这个领域中的传统噪声模型）始终优于现有基线。
## 846. `cs.LG` - Gatekeeper: 通过信心调优改进模型级联 [PDF](https://arxiv.org/pdf/2502.19335), [HTML](https://arxiv.org/abs/2502.19335)
### Authors
Stephan Rabanser,Nathalie Rauschmayr,Achin Kulshrestha,Petra Poklukar,Wittawat Jitkrittum,Sean Augenstein,Congchao Wang,Federico Tombari
### Background
大规模机器学习模型在广泛任务中表现出色，但伴随着显著的计算和资源限制。为了解决这些挑战，常用的方法是将较小的本地模型与较大的模型结合使用，并利用路由和延迟机制将复杂的任务卸载到较大的模型上。然而，现有方法未能恰当地平衡这些模型的能力，通常导致不必要的延迟或资源利用率低的问题。
### Innovation
本文提出了一种名为Gatekeeper的新型损失函数，用于在级联设置中校准较小的模型。该方法微调较小的模型，使其能自信地处理它能正确完成的任务，同时将复杂的任务委托给较大的模型。此外，它包含一种机制来管理模型性能与延迟准确性之间的权衡，并且可以在各种任务和领域中广泛适用而无需更改架构。我们在仅编码器、仅解码器和编码器-解码器架构上评估了该方法。跨图像分类、语言建模和视觉-语言任务的实验表明，本方法大幅提升了延迟性能。
### Conclusion
我们的方法显著提高了延迟性能，在不同类型的模型和任务中展示了良好的适用性和效果。
## 847. `cs.LG` - 语言建模的连续扩散模型 [PDF](https://arxiv.org/pdf/2502.11564), [HTML](https://arxiv.org/abs/2502.11564)
### Authors
Jaehyeong Jo,Sung Ju Hwang
### Background
扩散模型已经成为了在建模离散分类数据方面替代自回归模型的一种有前途的替代方案。现有的针对离散数据的扩散模型无法充分利用迭代细化的优势，因信号在离散状态之间的转换过程中会被丢失。现有的连续扩散模型在离散数据上的表现不佳，缺乏两者的明确联系阻碍了有效扩散模型的发展。本文研究背景在于此，旨在克服现有模型的不足，提高扩散模型在离散数据上的表现。
### Innovation
本文提出了一个针对语言建模的连续扩散模型，该模型结合了底层分类分布的几何特性。通过建立离散扩散和连续流在统计流形上的联系，引入一种既能概括现有离散扩散模型又能简便易行的扩散过程。另外，提出了一种无模拟的训练框架，并引入一种应对流形高维性的简单技术。该方法在语言建模基准和其他模态上均表现出优异性能，优于现有的离散扩散模型，接近于自回归模型的表现。
### Conclusion
本文的实验表明，所提出的连续扩散模型在语言建模上表现优于现有的离散扩散模型，并接近于自回归模型的表现。这种方法为后续研究提供了新的思路和良好的基础，在实现上也相对简单和有效。代码可以在提供的链接中访问。
## 848. `cs.LG` - 利用任意目标对齐下的特征谐振进行离群节点检测 [PDF](https://arxiv.org/pdf/2502.16076), [HTML](https://arxiv.org/abs/2502.16076)
### Authors
Shenzhi Yang,Junbo Zhao,Sharon Li,Shouqing Yang,Dingyu Yang,Xiaofang Zhang,Haobo Wang
### Background
在基于图的机器学习领域中，检测离群（OOD）节点是具有挑战性的，尤其是在无法获得内部分布（ID）节点多类标签的情况下。因此，本文重点关注特征空间而非标签空间，发现理想情况下，优化已知ID样本时，未知ID样本的表示变化更为显著，甚至当模型训练拟合随机目标时也是如此，我们称这一现象为特征谐振现象。这一现象的背后原因是即使没有黄金标签，局部流形仍可能表现出平滑谐振。因此，本文在此基础上提出了一种全新的基于图的OOD检测框架Resonance-based Separation and Learning (RSL)，该框架包含两个核心模块：（i）微观层面的特征谐振的更实际代理，用于衡量一次训练步骤中特征向量的移动；（ii）结合合成OOD节点策略以训练有效的OOD分类器。理论上，我们推导出一个误差边界，证明了在谐振期间OOD节点的优越可分性。广义实验在总共十三个真实世界图数据集上证明了RSL达到了最先进的性能。
### Innovation
本文提出了一种全新的基于图的OOD检测框架——Resonance-based Separation and Learning (RSL)，该框架包含两个核心模块：一个微观层面的特征谐振的代理，以及结合合成OOD节点策略以训练有效的OOD分类器。此外，作者还推导出了一个理论上的误差边界，证明了在谐振期间OOD节点的优越可分性。
### Conclusion
本文提出的 Resonance-based Separation and Learning (RSL) 架构在广泛测试中展现了卓越的性能，达到了与其他方法相比的先进水平。
## 849. `cs.LG` - Markovian数据流联邦学习 [PDF](https://arxiv.org/pdf/2503.18807), [HTML](https://arxiv.org/abs/2503.18807)
### Authors
Tan-Khiem Huynh,Malcolm Egan,Giovanni Neglia,Jean-Marie Gorce
### Background
联邦学习（FL）现在被公认为一种高效协作学习的关键框架。然而，大多数理论和实证研究假设客户端能够访问预先收集的数据集，而很少探讨客户端不断收集数据的情况。在许多实际应用场景中，尤其是在数据由物理或生物过程生成的情况下，客户端的数据流通常由非平稳马尔可夫过程建模。与标准的独立同分布抽样相比，由于客户样本之间的时间统计依赖性，当数据流为马尔可夫过程时，联邦学习的性能仍然不甚明了。因此，本文探讨了是否可以在马尔可夫过程数据流的情况下，联邦学习仍能支持协作学习
### Innovation
本文分析了Minibatch SGD、Local SGD以及带有动量的Local SGD变体在马尔可夫过程数据流情况下的性能，并证明了在标准假设和光滑非凸客户端目标函数的条件下，样本复杂度与客户端数量的倒数成比例，通信复杂度与独立同分布（i.i.d.）情况相当。然而，对于马尔可夫过程数据流，样本复杂度仍然高于独立同分布抽样。
### Conclusion
本研究揭示了在马尔可夫过程数据流的情况下，联邦学习仍能有效支持协作学习，特别是在标准假设和光滑非凸客户端目标函数的情况下，其样本和通信复杂度与独立同分布场景相似，但马尔可夫过程数据流的样本复杂度仍然较高。
## 850. `cs.LG` - 实时FPGA加速的原位深度学习细胞排序 [PDF](https://arxiv.org/pdf/2503.12622), [HTML](https://arxiv.org/abs/2503.12622)
### Authors
Khayrul Islam,Ryan F. Forelli,Jianzhong Han,Deven Bhadane,Jian Huang,Joshua C. Agar,Nhan Tran,Seda Ogrenci,Yaling Liu
### Background
精确的细胞分类在生物医学诊断和治疗监测中至关重要，尤其是对于识别涉及各种疾病的多种细胞类型。传统细胞分类方法，如流式细胞术，依赖于分子标记，这往往成本高、耗时且会改变细胞完整性。为克服这些限制，本文提出了一种基于明亮场显微图片的无标记机器学习框架，用于实时细胞分类应用。该方法借助知识蒸馏增强的教师-学生模型架构，能够高效且可扩展地跨不同类型细胞进行分类。
### Innovation
本研究的创新之处在于提出了一种教师-学生模型架构，利用知识蒸馏提高效率和可扩展性；该方法在无标记情况下，对T4和T8淋巴细胞与B细胞进行分类，实现了高精度；学生模型仅需教师模型0.02%的参数量，可在FPGA上部署，实现了超低的推理延迟（14.5 μs）和从细胞检测到触发排序的总延迟（24.7 μs），与现有最先进的实时细胞分析算法相比，分别提高了12倍和40倍的效率，同时保持与教师模型相当的精度。该框架提供了一种可扩展且成本效益高的淋巴细胞分类解决方案，并为即时识别亚群提供了最新的实时细胞排序实施方案。
### Conclusion
该框架为淋巴细胞分类提供了一种可扩展且成本效益高的解决方案，并为即时识别亚群提供了最新的实时细胞排序实施方案，在常规计算硬件上实现了现场深度学习加速，具有高效率和低延迟等优点。
## 851. `cs.LG` - 正则决策树：解决任意划分规则的最优决策树问题的形式化框架 [PDF](https://arxiv.org/pdf/2503.01455), [HTML](https://arxiv.org/abs/2503.01455)
### Authors
Xi He,Max A. Little
### Background
本文提出了一个分析决策树算法属性的形式化框架。该框架通过结构和祖先约束对决策树问题进行分类，并基于严格的数学基础来进行分类。本文特别关注一类称为正则决策树的问题，因为它们的通用性和有效性。正则决策树能够涵盖多种已知的数据结构，如二叉空间分割树、K-D树以及机器学习决策树模型。本文证明了只有正则决策树可以被唯一地刻画为K-排列，而非正则决策树则具有更大的复杂性。由于存在形式化的特征描述，本文开发了一个通用的算法方法来解决任意划分规则和目标函数下的正则决策树的最优决策树问题，并构造性地导出了一个通用的动态规划递归算法来精确解决这些问题。然而，研究发现，通用动态规划算法在处理空间复杂性时，通常被视为不切实际的，无论是在存储数据集还是子树方面都需要大量空间。这篇文章还进一步分析了几种非正则决策树，包括二元特征数据下的决策树，二叉搜索树，以及矩阵链乘法问题中出现的树结构，展示了如何通过适当修改或删除某些公理来解决这些问题。
### Innovation
本文提出了一种新的形式化框架来分析决策树的属性，特别关注正则决策树，并且证明了只有正则决策树能够通过K-排列来刻画。此外，本文提出了一个通用的算法方法来解决任意划分规则和目标函数下的正则决策树的最优决策树问题，并构造了通用的动态规划递归算法。文章还揭示了通用动态规划算法在实际应用中的局限性，即在空间复杂性上的限制。最后，引入了一种加速技术——减薄技术，并将这种技术应用于非正则决策树的问题解决中。
### Conclusion
本文通过构造性的方法发展了一种用于解决任意划分规则和目标函数下的最优化决策树问题的动态规划递归算法。然而，由于空间复杂性的限制，通用动态规划方法并不适合实际应用。此外，本文还扩展了所讨论的问题范围，包括研究了二叉特征数据下的决策树、二叉搜索树及矩阵链乘法中的树结构等几种非正则决策树问题。
## 852. `cs.LG` - 从零开始稀疏训练的重新参数化：Sign-In [PDF](https://arxiv.org/pdf/2504.12801), [HTML](https://arxiv.org/abs/2504.12801)
### Authors
Advait Gadhikar,Tom Jacobs,Chao Zhou,Rebekka Burkholz
### Background
从零开始训练稀疏神经网络（PaI）和从稠密到稀疏的训练之间存在性能差距，这对高效深度学习构成了重大障碍。据连锁票假设，PaI 关键在于找到特定问题的参数初始化。研究表明，确定正确的参数符号是足够的，但这对 PaI 来说仍然难以实现。
### Innovation
提出了一种名为 Sign-In 的方法，引入了一种动态重新参数化，能够证明地诱导符号翻转。这些符号翻转与从稠密到稀疏的训练能够完成的符号翻转互补，使 Sign-In 成为一种互补的方法。
### Conclusion
我们的实验和理论表明，PaI 的性能可以得到提升，但也指出了关闭 PaI 和从稠密到稀疏的训练之间差距的主要开放挑战。
## 853. `cs.LG` - CTSketch: 成分张量草图法实现可扩展的神经符号学习 [PDF](https://arxiv.org/pdf/2503.24123), [HTML](https://arxiv.org/abs/2503.24123)
### Authors
Seewon Choi,Alaia Solko-Breslin,Rajeev Alur,Eric Wong
### Background
许多计算任务可以从将其表述为神经网络的组成后跟着一个离散符号程序中受益。神经符号学习的目标是使用输入输出标签端到端地训练所组成的神经网络。本文介绍了一种新的、可扩展的神经符号学习算法——CTSketch。CTSketch通过将符号程序分解为子程序并通过草图张量总结每个子程序来提高神经符号推断的可扩展性。这个策略使得我们可以使用简单的张量操作来近似输出程序的分布。
### Innovation
CTSketch 算法通过将符号程序分解为子程序，并使用草图张量来总结每个子程序，从而提高了神经符号推理的可扩展性。该算法通过简单的张量操作近似程序的输出分布，并提供理论上的最大近似误差洞见。评估结果显示，CTSketch 能够将神经符号学习推向新的规模，即使只有最终输出的监督，神经预测器也能在具有千个输入的任务中获得高准确度。
### Conclusion
CTSketch 算法在神经符号学习基准测试上显示出优异的效果，特别是在评估可扩展性的设计后，该算法大大推动了神经符号学习向以前无法实现的新规模迈进。
## 854. `cs.LG` - 基于PCA的自适应异常检测在空间任务多特征时间序列中的应用 [PDF](https://arxiv.org/pdf/2504.15846), [HTML](https://arxiv.org/abs/2504.15846)
### Authors
Jonah Ekelund,Savvas Raptis,Vicki Toy-Edens,Wenli Mo,Drew L. Turner,Ian J. Cohen,Stefano Markidis
### Background
空间任务中有效事件检测对于自动分析至关重要，但受限于有限的机载计算资源和数据下传限制，需要开发能够实时识别感兴趣区域的鲁棒方法。现有数据集具有多特征时间序列数据的特点，这些数据需要高效的分析方法来提高事件检测的效率和准确性。
### Innovation
提出了一种基于主成分分析（PCA）重建误差的自适应异常检测算法。该算法通过增量PCA动态适应数据分布的变化，无需预设模型即可进行部署。此外，通过预缩放过程标准化每项特征的量级，同时保持特征内部的相对方差。该方法在NASA的MMS任务观测中成功应用于检测空间等离子事件，并在NASA的THEMIS数据中成功识别出白天瞬变现象。
### Conclusion
该自适应PCA异常检测算法能够实时识别感兴趣区域，特别适用于空间任务的需求。通过利用增量PCA和预缩放过程，该方法能够在不牺牲性能的情况下实现高效的数据分析。
## 855. `cs.LG` - 不要懒惰：CompleteP 使深度变压器计算更高效 [PDF](https://arxiv.org/pdf/2505.01618), [HTML](https://arxiv.org/abs/2505.01618)
### Authors
Nolan Dey,Bin Claire Zhang,Lorenzo Noci,Mufan Li,Blake Bordelon,Shane Bergsma,Cengiz Pehlevan,Boris Hanin,Joel Hestness
### Background
研究了在使用不同参数化（即模型和优化器超参数调整规则）进行大规模语言模型训练时的计算效率。不同的参数化方式在模型规模变化时无法成功转移最佳基础超参数（如学习率），这需要实践者在扩展模型时重新调整这些超参数（代价高昂），或者在重新调整不可行时接受次优的训练效果。即使能在某些情况下实现超参数转移，理论分析表明，参数化方式仍可能处于惰性学习阶段，使得模型只能学习接近线性化的特征，影响深度和非线性效果的有效利用。
### Innovation
识别并采用了一种名为CompleteP的参数化方式，它能在所有层中实现深度超参数转移和非惰性学习，从而使不同硬件配置和运行上下文中的模型大小/深度比例更加广泛地保持计算效率，并且与之前的最优方法相比，实现了12-34%的计算效率提升。所有实验均在Cerebras CS-3系统上进行。
### Conclusion
CompleteP 使深度变压器在不同硬件设置和操作场景下更加高效，不仅成功实现了深度超参数转移，还避免了惰性学习带来的问题，从而提高了模型训练的计算效率。
## 856. `cs.LG` - 探索RBM的能量景观：对抗空间视角下的玻色子、分层学习与对称性破缺 [PDF](https://arxiv.org/pdf/2503.21536), [HTML](https://arxiv.org/abs/2503.21536)
### Authors
J. Quetzalcóatl Toledo-Marin,Anindita Maiti,Geoffrey C. Fox,Roger G. Melko
### Background
深度生成模型由于其学习和生成复杂分布的能力而变得普遍。尽管存在多种框架，但这些模型之间的关系尚未被充分探索，这妨碍了统一的人工智能学习理论的发展。背景文献指出，尽管存在这些模型，但其间的联系仍然不明确，需要进一步研究来填补这一空白。
### Innovation
该研究通过引入相互空间表示，揭示了受限玻尔兹曼机（RBM）与扩散过程、耦合玻色子之间的联系。它展示了初始化时RBM处于鞍点状态，当地方曲率由奇异值决定，且奇异值的分布遵循Marcenko-Pastur定律并表现出对称性。训练过程中，由于分层学习导致不同自由度逐级捕捉不同的抽象层级，这种对称性被破坏，能量景观表现为对称性破缺，类似于Landau理论。研究推导了对应的平均场自由能，并指出随着RBM的尺寸趋于无限，相互变量将遵循高斯分布。此外，研究还指出，在这种状态下，某些模式的扩散过程可能不会收敛到玻尔兹曼分布。最后，通过使用MNIST数据集训练不同隐藏层大小的RBM复制品，该研究展示了结果，桥梁连接不同的生成模型框架，并进一步揭示了生成模型中学习过程的机制。
### Conclusion
该研究通过分析RBM的能量景观，揭示了RBM与其他物理现象的联系，并讨论了分层学习和对称性破缺的机制。研究方法为理解和改进生成模型提供了新的视角，同时也展示了在无限大小的RBM中的自洽分布。
## 857. `cs.LG` - SetONet：一种基于集合的算子网络，用于解决具有可变输入采样的PDE问题 [PDF](https://arxiv.org/pdf/2505.04738), [HTML](https://arxiv.org/abs/2505.04738)
### Authors
Stepan Tretiakov,Xingjian Li,Krishna Kumar
### Background
神经算子，特别是DeepONet，在学习函数空间之间的映射以解决微分方程方面显示出一定的潜力。然而，标准的DeepONet需要输入函数在固定位置采样，这在传感器配置可变或输入存在于不规则网格时限制了其适用性。
### Innovation
本文引入了SetONet，它通过修改分支网络来处理输入函数为顺序无关的位置-值对集合。通过结合Deep Sets原理，SetONet在保持与基线相同的参数数量的同时实现了集合不变性。在经典的操作学习基准测试中，SetONet在固定布局上与DeepONet达到同等性能，并在传感器配置变化或传感器丢失的条件下保持准确性。此外，SetONet天然处理输入以不规则点云（如点源或密度样本）形式出现的问题，这是标准DeepONet无法解决的。
### Conclusion
SetONet是一种以轻量级设计解决此类问题的DeepONet类别架构，极大地拓宽了操作学习的应用范围，使其能够应对具有可变、不完整或不规则输入数据的问题。SetONet能够在无需栅格化或多阶段流水线的情况下直接从点源的热传导、对流-扩散建模化学羽流和密度样本之间的最优运输学习算子。
## 858. `cs.LG` - UMoE: 将注意力和前馈网络统一为共享专家 [PDF](https://arxiv.org/pdf/2505.07260), [HTML](https://arxiv.org/abs/2505.07260)
### Authors
Yuanhang Yang,Chaozheng Wang,Jing Li
### Background
稀疏混合专家（MoE）架构已证明是扩展Transformer模型的有效方法。早期工作主要将MoE集成到前馈网络（FFN）层中，近期研究则探讨了将MoE应用于注意力层以提升模型性能的可能性。然而，现有的基于注意力的MoE层需要特殊实现，并且在性能上不如基于FFN的MoE层。
### Innovation
本文提出了一种新颖的注意力机制的重构，揭示了注意力模块内的内在FFN-like结构。由此构建的UMoE架构通过注意力基的MoE层实现了卓越的性能，同时允许FFN和注意力组件之间高效地共享参数。
### Conclusion
UMoE架构通过统一注意力和前馈网络层的设计，实现了更优的性能，并促进了两个组件之间的参数共享，从而实现了在扩展Transformer模型方面的优势。
## 859. `cs.LG` - PRUNE: 基于补丁修复框架的神经网络可验证遗忘方法 [PDF](https://arxiv.org/pdf/2505.06520), [HTML](https://arxiv.org/abs/2505.06520)
### Authors
Xuran Li,Jingyi Wang,Xiaohan Yuan,Peixin Zhang
### Background
在训练好的神经网络模型中去除特定训练数据的部分（也称为遗忘）常常是有益的。具体的应用场景之一是保护数据持有者的被遗忘权利，这已经在许多新的法规中得到了推广。现有的遗忘方法涉及使用剩余数据重新训练替代模型，这可能需要较高的成本，并且在数据持有者或第三方审计员的角度来看难以验证其准确性。本文审视了这个问题并提供了一种新的思路，即通过在原神经网络上施加精心设计的“补丁”来实现目标数据遗忘，从而一定程度上规避上述问题。
### Innovation
本文提出了一种创新的神经网络遗忘方法，即PRUNE（基于补丁修复框架的可验证遗忘方法）。本文创新点在于，通过借鉴神经网络修复的研究方向，提出了一个策略性的方法来寻找轻量级的最小“补丁”，以实现对指定数据点的确凿遗忘。同时，为了减少遗忘较大数量的数据点（或一个整个类别），本文建议迭代选择一小部分代表性的数据点来遗忘，从而实现对整个数据集的遗忘效果。这些方法相比现有方法，在多个分类数据集上证明了其有效性，同时在模型性能的保持、效率和内存消耗方面表现得更为出色。
### Conclusion
本文提出的PRUNE方法在多个分类数据集上验证了其有效性，不仅实现了可衡量的数据遗忘，而且在保持模型性能的同时，与现有方法相比，具有更高的效率和更小的内存消耗。通过采用精心设计的“补丁”，本文提供了一种创新的神经网络模型遗忘方法，提高了数据持有者的数据安全性和隐私保护能力。
## 860. `cs.LG` - 公平聚类中的对齐 [PDF](https://arxiv.org/pdf/2505.09131), [HTML](https://arxiv.org/abs/2505.09131)
### Authors
Kunwoong Kim,Jihu Lee,Sangchul Park,Yongdai Kim
### Background
在聚类算法中考虑公平性旨在平衡在给定敏感属性下的各个聚类中的实例比例。尽管最近开发的公平聚类算法能够在特定的公平性约束下优化聚类目标，但它们的固有复杂性或近似性导致了聚类实用性和数值稳定性的问题。因此，本文旨在通过提出一个新的基于新型公平$K$-means聚类目标函数分解的聚类算法来解决这些问题，该算法能更好地实现公平性与聚类实用性之间的平衡，同时避免数值不稳定的问题。
### Innovation
本文提出了一个新的名为Fair Clustering via Alignment (FCA)的聚类算法，该算法通过交替地（i）找到一个联合概率分布来对齐来自不同受保护群体的数据，（ii）在对齐空间中优化聚类中心来实现公平聚类。FCA的主要优势在于理论上可以保证在任何给定公平水平下获得近似最优的聚类实用性，从而在实践中实现高实用性的公平聚类。实验结果表明，FCA相比已有方法在公平性水平和聚类实用性之间取得了更好的权衡，并能在保持完全公平的同时避免数值不稳定的问题。
### Conclusion
FCA在公平性和聚类实用性之间的权衡取得了优异的表现，并在实践应用中具备高实用性和避免数值不稳定性。
## 861. `cs.LG` - 通过Woodbury、动量和随机化改进能量自然梯度下降 [PDF](https://arxiv.org/pdf/2505.12149), [HTML](https://arxiv.org/abs/2505.12149)
### Authors
Andrés Guzmán-Cordero,Felix Dangel,Gil Goldshlager,Marius Zeinhofer
### Background
自然梯度方法显著加快了物理信息神经网络（PINNs）的训练，但往往成本过高。为此，作者提出了一套技术来提升能量自然梯度下降（ENGD）的准确性和效率。
### Innovation
作者利用Woodbury公式大幅减少了ENGD的计算复杂度；引入了变分蒙特卡洛文献中的Subsampled Projected-Increment Natural Gradient Descent算法以加速收敛；并探索了在大批次处理时使用随机算法进一步降低成本的方法。研究发现，随机化在低维问题的早期训练阶段可以加速进程，并指出了其他情况下加速的障碍。
### Conclusion
实验结果表明，作者的方法优于之前的方法，在某些情况下可以达到原ENGD $L^2$误差的75倍加速效果。
## 862. `cs.LG` - 同构神经网络分类问题中的嵌入原理 [PDF](https://arxiv.org/pdf/2505.12419), [HTML](https://arxiv.org/abs/2505.12419)
### Authors
Jiahan Zhang,Yaoyu Zhang,Tao Luo
### Background
本文探讨了同构神经网络（包括全连接和卷积神经网络）关联的最大边缘问题的Karush-Kuhn-Tucker (KKT) 点。特别地，研究了不同宽度网络生成的不同KKT点之间的关系。
### Innovation
本文引入并形式化了KKT点嵌入原则，证明了同构网络最大边缘问题的KKT点可以在特定线性等距变换下嵌入到较大网络问题的KKT点中。此外，证明了这一嵌入原则在全连接网络的神经元分裂和卷积神经网络的通道分裂中成立。还探讨了这种静态嵌入与光滑损失梯度流训练动态之间的联系，表明从适当映射点开始的轨迹在整个训练过程中保持映射，并且收敛的方向也随之映射，从而在方向收敛时动态地保持KKT方向的对齐。
### Conclusion
实验结果支持这一发现，揭示了网络宽度、参数冗余及不同大小的同构网络中优化所找到的解之间的结构联系对分类问题的影响。
## 863. `cs.LG` - 基于回合级别奖励设计在LLM代理中增强多回合推理 [PDF](https://arxiv.org/pdf/2505.11821), [HTML](https://arxiv.org/abs/2505.11821)
### Authors
Quan Wei,Siliang Zeng,Chenliang Li,William Brown,Oana Frunza,Wei Deng,Anderson Schneider,Yuriy Nevmyvaka,Yang Katie Zhao,Alfredo Garcia,Mingyi Hong
### Background
本文研究了强化学习（RL）方法如何增强大型语言模型（LLM）代理在长时序、多回合场景中的推理能力。尽管诸如组相对策略优化（GRPO）和近端策略优化（PPO）等RL算法已被广泛用于训练多回合LLM代理，但这些方法通常仅依赖稀疏的最终结果奖励，缺乏多决策步骤中的密集中间信号，这限制了它们在复杂推理任务中的表现。
### Innovation
本文首次系统地研究了多回合RL算法中的回合级别奖励设计，并通过集成回合级别奖励，将GRPO和PPO扩展到各自的多回合变体，从而实现更精细的信用分配。我们精心设计了两种类型的回合级别奖励：验证型和LLM作为裁判。实验结果表明，在多回合搜索任务中，结合精心设计的回合级别奖励，使RL算法能够显著优于仅使用轨迹级别奖励的基本方法。另外，通过训练和验证奖励曲线，我们的方法实现了更高的稳定性、更快的收敛速度和更高的准确性。
### Conclusion
我们在多种问答数据集上的数值结果显示，我们的方法能够保持最高答案准确性和100%的格式准确性。
## 864. `cs.LG` - superposition_yields_robust_neural_scaling [PDF](https://arxiv.org/pdf/2505.10465), [HTML](https://arxiv.org/abs/2505.10465)
### Authors
Yizhou Liu,Ziming Liu,Jeff Gore
### Background
大型语言模型的成功依赖于模型规模增大能带来性能提升的观察，但这种神经网络规模法则的起源，即损失随模型规模以幂律形式减少的原因仍不清楚。文章通过探索表示叠加的概念，即大型语言模型能用比维度更多的特征来表示，提出这可能是导致损失和引发神经网络规模法则的关键因素。通过Anthropic的玩具模型和权重衰减技术，系统研究了损失随模型规模的改变情况，并揭示了在不同叠加程度下损失随模型规模变化的不同规律。研究发现，开源的大规模语言模型确实处于强烈的表示叠加状态，并且损失呈现与模型维度成反比的趋势。Chinchilla的模型也显示了类似的行为，证实了该研究发现。这为神经网络规模法则提供了新的见解，指出了如何改进和何时这些法则失效的问题。
### Innovation
研究提出了表示叠加作为神经网络规模法则的核心驱动因素，并通过Anthropic的玩具模型和权重衰减技术，系统地研究了不同叠加程度下损失随模型规模的变化规律。该研究通过实证分析了开源的大规模语言模型和Chinchilla模型的行为，提供了对神经网络规模法则的新见解，揭示了当模式维度增加时，不同特征频率分布下损失随模型维度变化的规律。
### Conclusion
研究确认代表叠加是神经网络规模法则的主要驱动因素，表明在表示叠加较强的情况下，损失通常与模型维度成反比变化。这些发现为理解和改进神经网络规模法则提供了新的理论基础。
## 865. `cs.LG` - CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs [PDF](https://arxiv.org/pdf/2505.12944), [HTML](https://arxiv.org/abs/2505.12944)
### Authors
Jan Hagnberger,Daniel Musekamp,Mathias Niepert
### Background
时间依赖型偏微分方程（PDEs）的求解在气候建模和流体力学等领域至关重要，但直接在物理空间中进行这些计算往往消耗大量的计算资源。为应对这一挑战，研究人员开发了在压缩潜在空间中工作的神经代理模型，但这些方法往往使用基于Transformer的注意力机制处理非规则样本域，导致内存消耗增加。相比之下，卷积神经网络虽然有助于内存高效的编码和解码，但受限于规则离散化。
### Innovation
本文提出了一种CALM-PDE模型类，该模型能够在压缩潜在空间中高效求解任意规化的PDE。它引入了一种新颖的基于连续卷积的编码-解码架构，该架构使用ε-邻域约束内核，并学习应用卷积运算到可适应和优化的查询点上。CALM-PDE在不同类型的PDE上有良好的表现，与现有基线方法相比，在内存和推理时间效率上都有显著改进。
### Conclusion
CALM-PDE 竞争或优于现有基线方法，相较于基于 Transformer 的方法提供了显著的内存和推理时间效率改进，在时间依赖型 PDE 的潜在空间建模中表现优异。
## 866. `cs.LG` - CLEVER: A Curated Benchmark for Formally Verified Code Generation [PDF](https://arxiv.org/pdf/2505.13938), [HTML](https://arxiv.org/abs/2505.13938)
### Authors
Amitayush Thakur,Jasper Lee,George Tsoukalas,Meghana Sistla,Matthew Zhao,Stefan Zetzsche,Greg Durrett,Yisong Yue,Swarat Chaudhuri
### Background
当前的代码生成基准主要依赖于测试案例监督、LLM生成的注释，这些方法可能包含实施逻辑或导致无意义的解决方案，不能满足严格的形式验证需求。本文介绍了一个名为$?text{CLEVER}$的高质量、精简的基准，用于在Lean中的端到端形式验证代码生成问题集，每个问题都包括生成一个与保留的正确规范匹配的规范的任务，以及生成一个证明满足此规范的Lean实现的任务。这一基准旨在解决现有方法的形式验证不足问题，提供一个挑战性的前沿基准，以评估程序合成和形式推理的能力。
### Innovation
该论文的独特之处在于：1) 避免了测试案例监督和LLM生成的标注；2) 规范不泄露实施逻辑，不支持无意义的解决方案；3) 通过Lean类型检查器后验验证所有输出，确保机器可验证的正确性；4) 提供了详细的评估代码，便于研究和验证。这些特点使其能够成为评估程序合成和形式推理的方法的严格基准。
### Conclusion
本文介绍的$?text{CLEVER}$基准能够全面评估基于最新语言模型的少样本和自主方法在形式验证代码生成领域的能力，并确立了这一领域的挑战性前沿标准，有助于推动该领域的发展。
## 867. `cs.LG` - 通过Koopman建模实现基于扩散模型的一步离线蒸馏 [PDF](https://arxiv.org/pdf/2505.13358), [HTML](https://arxiv.org/abs/2505.13358)
### Authors
Nimrod Berman,Ilan Naiman,Moshe Eliasof,Hedi Zisling,Omri Azencot
### Background
基于扩散的生成模型表现出了卓越的表现，但其迭代采样过程存在计算成本高昂的问题。为了降低这一成本，一种显着的战略是蒸馏，其中离线蒸馏具有效率、模块化和灵活性上的优势。与此同时，研究者们已经从动力系统理论视角分析了扩散模型，但仍有很多强大的但未充分开发的工具可以利用，且扩散模型在潜空间中提供了结构性和语义连贯的轨迹。基于这些观察，本文提出了Koopman Distillation Model (KDM)，一种依据Koopman理论构建的一点离线蒸馏方法，解决了扩散模型迭代采样过程的高效性问题，旨在提供一种更高效的一点生成方法同时保留语义保真度。
### Innovation
本文引入了Koopman Distillation Model (KDM)，这是一种基于Koopman理论的离线蒸馏方法。KDM能够在不牺牲语义保真度的情况下，通过单一步骤产生高质量的样本，解决了基于扩散的生成模型的计算成本问题。此外，KDM在理论上的演化是有限维的Koopman表示，并且在Koopman潜空间中的接近度与生成输出中的语义相似性相关，这使得轨迹对齐更为有效。KDM在标准离线蒸馏基准测试中表现出色，具有高度竞争力的性能。
### Conclusion
本文通过引入Koopman Distillation Model (KDM)，提出了一个基础扎实的一点离线蒸馏方法，能够利用Koopman理论将噪声输入转换为改进的线性操作符，进而实现高效的语义保真度单步生成。验证了KDM在理论上的合理性并在离线蒸馏基准测试中取得良好结果，具有广阔的应用前景。
## 868. `cs.LG` - 连续时间跳跃随机控制的深度学习方法 [PDF](https://arxiv.org/pdf/2505.15602), [HTML](https://arxiv.org/abs/2505.15602)
### Authors
Patrick Cheridito,Jean-Loup Dupret,Donatien Hainaut
### Background
本文介绍了基于模型的深度学习方法，用于解决具有跳跃的有限时段连续时间随机控制问题。通过迭代训练两个神经网络来分别代表最优策略和近似值函数，并利用连续时间动态规划原理，基于哈密尔顿-雅克比-贝尔曼方程衍生出两种不同的训练目标，确保网络能够捕捉到潜在的随机动态。
### Innovation
本文提出了一种基于模型的深度学习方法，用于解决具有跳跃的连续时间随机控制问题，并通过迭代训练两个不同的神经网络来优化策略和价值函数。这种方法通过连续时间动态规划原理和哈密尔顿-雅克比-贝尔曼方程的应用，提供了一种新颖的解决策略和价值函数的方式，增强了对复杂随机动态的建模能力。
### Conclusion
在不同问题上的实证评估表明，该方法在准确性和可扩展性方面表现出色，证明了其在解决复杂、高维随机控制任务方面的有效性。
## 869. `cs.LG` - RL Tango: 一起强化生成器和验证器以增强语言推理 [PDF](https://arxiv.org/pdf/2505.15034), [HTML](https://arxiv.org/abs/2505.15034)
### Authors
Kaiwen Zha,Zhengqi Gao,Maohao Shen,Zhang-Wei Hong,Duane S. Boning,Dina Katabi
### Background
强化学习（RL）最近被证明是提升大规模语言模型（LLM）推理能力的有效方法，其中LLM生成器由验证器（奖励模型）引导。当前的LLM RL后训练方法通常使用固定的验证器（规则基于或冻结预训练）或通过监督微调（SFT）进行有区别的训练。然而，这些设计容易受到奖励作弊的影响，且在训练分布之外的泛化表现不佳。
### Innovation
Tango是一个新颖的框架，使用RL同时训练LLM生成器和验证器，并通过交错方式进行训练。其创新之处在于使用生成的、过程级别的LLM验证器进行训练，并且与生成器共同进化。验证器仅基于结果级别验证正确性奖励进行训练，无需明确的过程级别标注。这种方法使得生成的RL训练验证器相比确定性或SFT训练验证器表现出更好的鲁棒性和更强的泛化能力，从而促进生成器的有效相互强化。
### Conclusion
广泛的实验表明，Tango框架的两个组件均在其规模的LLM模型中达到了最先进的结果：生成器在五个比赛级别的数学基准测试和四个具有挑战性的跨域推理任务中获得了最佳性能，而验证器则在ProcessBench数据集中表现最佳。特别是，Tango的两个组件在最复杂的数学推理问题上表现出显著的改进。源代码可在：this https URL.
## 870. `cs.LG` - Wasserstein Transfer Learning [PDF](https://arxiv.org/pdf/2505.17404), [HTML](https://arxiv.org/abs/2505.17404)
### Authors
Kaicheng Zhang,Sinian Zhang,Doudou Zhou,Yidong Zhou
### Background
传统的迁移学习方法往往侧重于欧几里得空间内的标量或多元数据，这对复杂的数据结构（如概率分布）的应用造成了限制。因此，需要一种新的迁移学习框架来处理这种类型的数据，并能够量化领域相似性对迁移效率的影响，同时开发一种数据驱动的迁移学习过程以减轻负面影响.
### Innovation
该论文提出了一种新的迁移学习框架，适用于输出为Wasserstein空间中概率分布的回归模型。它能够当转移学习的信息子集已知时，提供具有可证明渐近收敛率的估计器。对于未知的信息子集，该论文发展了一种数据驱动的迁移学习过程。这些方法通过严格的理论分析和技术验证得到支持，并通过广泛的模拟和实际应用进行验证.
### Conclusion
提出的迁移学习方法通过综合的数据驱动过程和支持，显著提升了复杂数据结构的迁移学习效果，并通过理论和实验验证了其有效性，同时提供了相关代码供进一步研究使用.
## 871. `cs.LG` - LLM-Explorer：由大型语言模型驱动的插件强化学习策略探索增强 [PDF](https://arxiv.org/pdf/2505.15293), [HTML](https://arxiv.org/abs/2505.15293)
### Authors
Qianyue Hao,Yiwen Song,Qingmin Liao,Jian Yuan,Yong Li
### Background
在强化学习（RL）中，策略探索是至关重要的。现有的策略探索方法包括贪婪方法和高斯过程等，但这些方法依靠预先设定的随机过程，并且在所有RL任务中以固定方式应用，未考虑任务特性对策略探索的影响。此外，在RL训练过程中，这些随机过程的演变通常是刚性的，只能根据预设的衰减机制调整，缺乏灵活性，无法根据代理的实时学习状态进行调整。因此，设计能够适应各任务特性的策略探索机制是提高RL性能的关键挑战问题。
### Innovation
本文受大型语言模型（LLMs）分析和推理能力的启发，设计了LLM-Explorer插件，旨在生成特定任务的适应性探索策略。设计包括采样RL训练过程中的agent学习轨迹，使用LLMs分析因子学习状态，生成未来策略探索的概率分布，并定期更新这些分布以生成专用于特定任务的自适应随机过程。该设计易于与各种广泛使用的RL算法（如DQN系列、DDPG、TD3及其任何变体）集成。通过在Atari和MuJoCo基准上的广泛实验，验证了LLM-Explorer在增强RL策略探索方面的能力，该插件使得RL性能平均提高了37.27%。同时，提供的代码确保了实验结果的可复现性并开放了以便进一步研究和发展。
### Conclusion
通过使随机过程具体化且动态调整，LLM-Explorer显著增强了RL的策略探索过程，为针对特定任务的策略探索提供了一种新的有效方法。未来的进一步研究可以集中在探索如何利用不同的大型语言模型特性以进一步提升该方法的有效性和鲁棒性方面。
## 872. `cs.LG` - 如何通过提炼策略的集成提高强化学习的泛化能力 [PDF](https://arxiv.org/pdf/2505.16581), [HTML](https://arxiv.org/abs/2505.16581)
### Authors
Max Weltevrede,Moritz A. Zanger,Matthijs T.J. Spaan,Wendelin Böhmer
### Background
在零样本策略转移的强化学习环境中，目标是在一组固定的训练环境中训练智能体，使其能够泛化到相似但未见过的测试环境中。已有研究表明，训练后进行策略提炼有时可以生成在测试环境中表现优于原始策略的策略。然而，尚未完全清楚为何如此，以及应该使用什么数据进行策略提炼。本文在某些假设条件下证明了训练后策略提炼的一般泛化界，并提供了两个实用见解：为了提高泛化能力，应1) 训练提炼策略的集成，2) 尽可能多使用训练环境的数据进行提炼。在更多一般性条件下，通过实验验证了这些见解仍然有效。最后，证明了一个在多样数据集上提炼的策略集比原始智能体表现显著更好。
### Innovation
本文证明了训练后策略提炼的一般泛化界，并提供了两种提高泛化能力的实用方法：训练策略提炼的集成，并尽可能多地使用训练环境的数据进行提炼。此外，实验验证了这些方法的有效性，并展示了在多样数据集上提炼的策略集能显著提高泛化能力。
### Conclusion
本文证明了通过策略提炼的智能体集成可以在不满足理论假设的情况下依然有显著的泛化性能提升。研究表明，通过多样化训练数据的策略集成能显著改善强化学习任务的表现。
## 873. `cs.LG` - Tropical Attention: 对组合算法的神经算法推理 [PDF](https://arxiv.org/pdf/2505.17190), [HTML](https://arxiv.org/abs/2505.17190)
### Authors
Baran Hashemi,Kurt Pasque,Chris Teska,Ruriko Yoshida
### Background
当前现代神经推理模型在提升推理准确性和鲁棒性以及解释性方面存在局限，可以通过引入代数几何提供的数学基础归纳偏差来改进这些模型。具体来说，组合推理具有的多面体决策结构在传统模型中可能会被平滑掉，代数几何能帮助保留这种结构，从而提高模型的精确性和鲁棒性。
### Innovation
本文引入了Tropical Attention，这是一种基于热带几何的注意力机制。通过将注意力核提升到热带射影空间，推理过程变得分段线性且1-一致，从而保留了组合推理中的多面体决策结构。并且，Tropical Attention能够通过级联方式近似地表示热带电路，实现热带传递闭包，且无需使用递归机制，从而在不增加资源开销的情况下提高了模型的表达能力。实验表明，Tropical Attention相比基于Softmax和递归机制的基线模型，在离分布外的推理方面表现更优，具有更强的鲁棒性，并且以更少的参数实现了更快的推理速度。
### Conclusion
以Tropical Attention为基础，首次将神经算法推理扩展到NP难和NP完全问题上，为构建能够处理复杂组合挑战的大型推理模型（Large Reasoning Models）开辟了新途径，包括进化树构建、密码学、粒子物理学和数学发现等领域提出了新的可能性。
## 874. `cs.LG` - 几何感知操作转换器作为在任意域上高效且准确的PDE神经代理 [PDF](https://arxiv.org/pdf/2505.18781), [HTML](https://arxiv.org/abs/2505.18781)
### Authors
Shizheng Wen,Arsh Kumbhat,Levi Lingsch,Sepehr Mousavi,Yizhou Zhao,Praveen Chandrashekar,Siddhartha Mishra
### Background
学习PDEs在任意域上的解算子是一个在工程和工业模拟中至关重要的任务。尽管存在许多用于逼近PDEs的算子学习算法，我们发现准确模型并不一定具有计算效率，反之亦然。因此，课题如何提高模型的准确性和计算效率变得至关重要。
### Innovation
本文提出了一种几何感知操作转换器（GAOT），结合了新型多层次注意力图神经操作编码器和解码器、几何嵌入以及（视觉）转换器处理器，以准确地映射域和输入的信息到PDE解的稳健逼近。此外，多个实现在GAOT中的创新确保了计算效率和可扩展性。
### Conclusion
在一系列来自不同PDEs的大规模学习任务上，GAOT相对于多个基线模型在准确性和效率上都具有显著优势，并在三个大规模的三维工业CFD数据集中达到了最先进的性能。
## 875. `cs.LG` - DesignX: 黑盒优化中的人类竞争级算法设计师 [PDF](https://arxiv.org/pdf/2505.17866), [HTML](https://arxiv.org/abs/2505.17866)
### Authors
Hongshu Guo,Zeyuan Ma,Yining Ma,Xinglin Zhang,Wei-Neng Chen,Yue-Jiao Gong
### Background
设计有效的黑盒优化器受到有限的问题特定知识和数月的人工控制限制，几乎在每一个细节上都需要手动调整。本文介绍了DesignX，这是一个自动化的算法设计框架，能够在几秒钟内根据给定的黑盒优化问题生成一个有效的优化器。
### Innovation
该研究根植于第一原理，识别出两个关键亚任务：1）算法结构生成；2）超参数控制。构建了一个全面的模块化算法空间，包含多年来研究中收集的数百种算法组件。然后介绍了双智能体强化学习系统，通过新的合作训练目标实现结构和参数设计上的合作，能够大规模地在数千个不同的实例中进行元训练。经过几天的自主学习，由DesignX生成的优化器在合成试验台或如蛋白质对接、自动化机器学习和无人飞行器路径规划等现实优化场景中均超过了人类设计的优化器，效果显著。
### Conclusion
深入分析表明，DesignX 能够发现超出专家直觉的复杂算法模式，这对优化社区提供了有价值的设计见解。项目代码开源在提供的链接中。
## 876. `cs.LG` - 无需牺牲的解释性：Mixture of Decoders实现忠实的密集层分解 [PDF](https://arxiv.org/pdf/2505.21364), [HTML](https://arxiv.org/abs/2505.21364)
### Authors
James Oldfield,Shawn Im,Sharon Li,Mihalis A. Nicolaou,Ioannis Patras,Grigorios G Chrysos
### Background
多层感知机（MLPs）是大规模语言模型中的重要组成部分，但由于它们的密集表示使其难以理解和编辑，因此需要找到提高解释性的方法。现有的方法通过神经元级的稀疏性来学习可解释的近似值，但由于未能忠实地重建原始映射，显著增加了模型的下一点交叉熵损失。因此，现有方法在准确性和解释性之间存在权衡。
### Innovation
本文提出了一种新的方法，即Mixture of Decoders（MxDs），通过在层级上引入稀疏性来克服这种准确性和解释性的权衡。MxDs通过对预训练的密集层进行扩展，将其转化为数千个专门的子层，实现了线性变换，并且可以在高度稀疏的情况下保留原始解码器的表达能力。实验表明，MxDs在多达30亿参数的语言模型中超越了现有的最佳方法，在稀疏探针和特征控制方面也表现出相似的特定特征，开启了设计既可解释又忠实的分解的新途径。
### Conclusion
实验结果显示，MxDs在稠密层的稀疏分解方面显著优于最先进的方法，尤其是在参数量达到30亿的语言模型中。此外，进一步的评估表明MxDs能够学习自然语言的特定特征，为设计既可解释又忠实的分解开辟了新的前景。
## 877. `cs.LG` - 天生即为Transformer——预训练对架构能力的影响 [PDF](https://arxiv.org/pdf/2505.21785), [HTML](https://arxiv.org/abs/2505.21785)
### Authors
Mayank Jobanputra,Yana Veitsman,Yash Sarrof,Aleksandra Bakalova,Vera Demberg,Ellie Pavlick,Michael Hahn
### Background
Transformer架构虽然在某些序列到序列的任务中存在理论局限性，但目前尚不清楚这些局限性是否在大规模预训练的语言模型中发挥作用，或者由于模型规模和预训练数据的增大，语言模型能否有效地克服这些限制。作者通过研究由Liu等人提出的复制和检索任务系列，探索这些架构上的限制在预训练后的表现，同时使用Huang等人提出的研究长度泛化的框架，确保了每个研究场景的可靠性。通过这些方法，作者发现了模型在检索上比复制表现更好的不对称现象，这种现象在理论保证长度泛化时会消失。机制分析表明这种不对称性与预训练Transformer中促进性电路和反向电路的强度差异有关。通过实际任务的实验验证了这一结论，表明预训练可能增强某些Transformer的能力，但未能克服基本的长度泛化限制。
### Innovation
作者开发了新的研究框架来确保长度泛化，并通过细致的分析揭示了模型在检索任务上优于复制任务的不对称现象及其实现机制。这一研究为理解预训练对Transformer架构能力的影响提供了新的视角。
### Conclusion
预训练可以增强某些Transformer的能力，如信息检索，但并不能克服固有的长度泛化限制。研究表明，对于某些特定任务，预训练可能会增强模型的能力，但对于涉及特定类型长度变化的任务，模型仍会表现有限。
## 878. `cs.LG` - 在过参数化情况下的机器卸载 [PDF](https://arxiv.org/pdf/2505.22601), [HTML](https://arxiv.org/abs/2505.22601)
### Authors
Jacob L. Block,Aryan Mokhtari,Sanjay Shakkottai
### Background
机器卸载算法旨在通过移除特定训练样本的影响来恢复仅从剩余数据训练的模型，这在数据隐私和模型可解释性方面具有重要意义。然而，当处于过参数化设置中，许多模型都能很好地拟合数据，定义解决方案为在保留数据集上的任意损失最小化者不足以准确描述问题，因为原先的模型可能已经能够在保留的数据上进行拟合。在这种场景下，损失梯度消失，之前的基于梯度扰动的方法变得无效，这需要引入新的卸载定义和算法。
### Innovation
研究者提出了一个新的卸载解决方案定义，即最小复杂度的拟合器，用于如何定义过参数化设置下的卸载解决方案。同时，他们提出了一种新的算法框架，仅需访问保留数据集上模型的梯度。这包括在与这些模型梯度正交的约束下最小化正则化目标。该方法对于不同的模型类别提供了精确和近似的卸载保证，并在各种卸载实验中证明了该框架的优越性。
### Conclusion
该研究探讨了在过参数化设置下机器卸载的方法，并提出了新的解决方案定义和算法框架。实验结果表明，这种方法优于现有基线方法。
## 879. `cs.LG` - 驯服数据归因中的超参数敏感性：无需昂贵重训的实用选择 [PDF](https://arxiv.org/pdf/2505.24261), [HTML](https://arxiv.org/abs/2505.24261)
### Authors
Weiyi Wang,Junwei Deng,Yuzheng Hu,Shiyuan Zhang,Xirui Jiang,Runting Zhang,Han Zhao,Jiaqi W. Ma
### Background
数据归因方法，可以通过量化个别训练数据点对机器学习模型的影响来评估训练数据的重要性，在现代 AI 的数据为中心的应用中越来越受欢迎，尽管最近出现了许多新的方法，但这些方法中的超参数调优的影响仍被广泛忽视。
### Innovation
本文首次进行大规模实证研究，探讨常见数据归因方法对关键超参数的敏感性。提出了一种理论分析来解释关键正则化项的行为，并提出了一种不需重新训练模型即可选择正则化值的轻量化方法，验证其在多种标准数据归因基准上有效。
### Conclusion
研究表明，数据归因方法在实际应用中存在一个关键且被忽视的挑战，即对超参数的选择需要谨慎讨论，并强调未来方法发展过程中需要更加重视对超参数选择的详细讨论。
## 880. `cs.LG` - 将互补记忆系统融合于混合二次-线性变换器中 [PDF](https://arxiv.org/pdf/2506.00744), [HTML](https://arxiv.org/abs/2506.00744)
### Authors
Kazuki Irie,Morris Yau,Samuel J. Gershman
### Background
论文背景介绍了用于通用序列处理神经网络的组合记忆架构的发展，这种架构结合了使用softmax注意力的键值记忆（KV-memory）与通过动态突触调制的快速权重记忆（FW-memory）。KV-memory和FW-memory各自具有互补但受限的特性。KV-memory擅长精确检索，但对序列长度具有二次复杂性限制；FW-memory支持任意长序列且能进行表达性计算，但牺牲了精确回忆的能力。
### Innovation
论文提出了三种方法来融合这两种记忆系统，通过不同的输入信息传递方式和时间来利用各自的优势。此外，作者通过训练包含340M和1.3B参数的模型，以及设计用于精确展示某些组合方法优势的合成算法任务，对这些方法进行了实验验证。
### Conclusion
研究展示了精心设计的组合能够克服个体组件的限制，为神经记忆系统的设计原则提供了新的见解。同时，这些研究成果也被应用于部分可观测环境下的增强学习任务中。
## 881. `cs.LG` - KOALA++: 通过梯度协方差产品高效神经网络卡尔曼优化 [PDF](https://arxiv.org/pdf/2506.04432), [HTML](https://arxiv.org/abs/2506.04432)
### Authors
Zixuan Xia,Aram Davtyan,Paolo Favaro
### Background
在神经网络训练过程中，优化算法在准确性与效率之间寻求平衡。传统的二次优化方法依赖于昂贵的二阶梯度计算，而基于一阶梯度的算法则更加高效但可能忽略了复杂的不确定结构。原有的KOALA框架虽然简化了协方差计算，但仍假设协方差矩阵是对角的，导致信息损失。
### Innovation
KOALA++通过递归更新紧凑的梯度协方差积，直接估计参数协方差矩阵，从而捕捉更丰富的不确定性结构而无需存储完整的协方差矩阵，避免了大规模矩阵逆运算。这种设计相比传统的二次优化方法，不仅提高了准确性，还保持了一阶优化算法的高效性。
### Conclusion
KOALA++在图像分类和语言模型等多个任务中，达到或超过了现有最佳的一阶和二阶优化器的准确性，同时保持了一阶优化器的高效性。
## 882. `cs.LG` - 训练时扰动，合并后推理：一种两阶段持续学习框架 [PDF](https://arxiv.org/pdf/2505.22389), [HTML](https://arxiv.org/abs/2505.22389)
### Authors
Haomiao Qiu,Miao Zhang,Ziyue Qiao,Liqiang Nie
### Background
持续学习（CL）旨在使模型能够从一系列任务中连续获取新知识，同时避免遗忘已学信息。然而，现有的CL方法只依赖于最近任务的参数进行推理，这使得它们容易出现灾难性遗忘。基于最近在模型合并技术上的成功，本文提出了一种新的CL框架——扰动与合并（Ptextbf{?&}M），它将模型合并技术整合进CL范式中以减轻遗忘问题。具体而言，训练了每个任务后，Ptextbf{?&}M通过形成先前模型和新训练的任务特定模型的凸组合来建立一个新的模型。通过理论分析，本文最小化了所有任务的总损失增加，并在轻微假设下推导出合并系数的闭式解。为提高合并模型的性能，本文观察到，在合并过程中引入的退化可以通过损失函数的梯度矩阵和任务向量的正则化项来缓解。此正则化项能够通过二阶对称有限差分高效近似，并提出了一种沿任务向量方向扰动策略，该策略不增加前向或反向传递次数，但仍能提供正则化项的有效近似。最后，本文将Ptextbf{?&}M和参数高效微调方法LoRA结合，以减少内存开销。所提出的方法在几个持续学习基准数据集上取得了最先进的性能。代码可在该网址获取。
### Innovation
Ptextbf{?&}M框架结合了模型合并技术来减轻持续学习中的遗忘问题。通过在训练每个任务后形成从前序模型和新训练任务特定模型的凸组合，提出了一种新的合并策略。通过理论分析，推导出闭式解并提供了有效的近似方法来缓解合并过程中的退化。此外，还结合了参数高效微调方法LoRA，以进一步减少内存开销。
### Conclusion
本文提出了一种新的持续学习框架——Ptextbf{?&}M，通过理论分析和实际实验展示了其在多个持续学习基准数据集上的优越性能。这种方法不仅减少了遗忘的发生，还有效降低了内存开销，展示了在持续学习领域的创新贡献。
## 883. `cs.LG` - 重新排列构建图像模型优化 [PDF](https://arxiv.org/pdf/2505.23751), [HTML](https://arxiv.org/abs/2505.23751)
### Authors
Declan Kutscher,David M. Chan,Yutong Bai,Trevor Darrell,Ritwik Gupta
### Background
序列模型如变压器需要输入表示为一维序列，对于视觉任务，通常会通过固定顺序（如行主要顺序或栅格扫描）来展平图像。在自注意力机制中，全自我注意力是置换不变的，但现代长序列变压器正越来越多地依赖破坏这种不变性的近似架构，从而使其对图像块的顺序变得敏感。研究者发现，图像块顺序显著影响模型性能，并且简单的替代顺序（如列主要顺序或海克尔曲线）可以带来显著的准确率提升。为了应对这一问题，该研究提出了REOrder（重新排列图像块）框架，该框架分为两个阶段：首先通过解释数据压缩性的方法得出先验信息；然后使用Plackett-Luce策略进行优化，利用REINFORCE算法获得排序策略，从而能够高效地在置换空间中学习.
### Innovation
提出了REOrder（重新排列图像块）框架，解决了长序列变压器顺带结构不能充分保持图像块不变性的问题。该框架包括两个阶段：首先通过测量数据压缩性来构建先验知识；其次通过优化Plackett-Luce策略并使用REINFORCE算法获取最优排序策略，该方法可以高效地处理置换空间的优化问题。实验证明，与传统的行主要顺序相比，REOrder在ImageNet-1K和Functional Map of the World数据集上显著提高了准确性，分别提高了3.01%和13.35%.
### Conclusion
提出了一个新的框架REOrder，用于在多个数据集上优化图像块的排序，证明了合理设计的排序策略可以提高视觉模型的性能。该框架为设计更有效的一维序列表示提供了新的思路。
## 884. `cs.LG` - 利用解析梯度实现可验证安全的强化学习 [PDF](https://arxiv.org/pdf/2506.01665), [HTML](https://arxiv.org/abs/2506.01665)
### Authors
Tim Walter,Hannah Markgraf,Jonathan Külz,Matthias Althoff
### Background
在安全关键应用中部署自主机器人需要安全保障。证实安全性的强化学习是一个活跃的研究领域，旨在通过安全措施提供此类保障。这些安全措施应在训练过程中集成以减少仿真实验到实际操作的差距。尽管有许多方法可以确保基于样本的强化学习的安全性，但基于解析梯度的强化学习通常能够以较少的环境互动实现更好的性能，然而目前尚未有这种学习范式的安全保障方法。
### Innovation
我们通过开发第一个有效的基于解析梯度的强化学习的安全措施来填补这一空白。该工作分析现有的可微分安全措施，通过修改映射和梯度公式进行调整，并将它们集成到最先进的学习算法和可微分模拟中。通过三个控制任务的数值实验，评估不同安全措施对学习的影响。结果表明，在不牺牲性能的情况下，使用了受保护的训练。
### Conclusion
该工作展示了如何利用现有的不同类型的可微分安全措施，并通过调整映射和梯度公式实现对基于解析梯度的强化学习的有效保障，同时通过实验验证了这种安全性保障不会影响学习性能。
## 885. `cs.LG` - 你的预训练LLM其实是未监督的信心校正器 [PDF](https://arxiv.org/pdf/2505.16690), [HTML](https://arxiv.org/abs/2505.16690)
### Authors
Beier Luo,Shuoyuan Wang,Sharon Li,Hongxin Wei
### Background
对大规模语言模型（PLMs）进行后训练是将预训练语言模型调整以适应人类偏好和下游任务的关键步骤。然而，后训练的语言模型（PoLMs）往往表现出过度自信的现象，即使错误输出也会被赋予高置信度，这可能在关键应用中降低可靠性。由于缺乏针对单个下游任务的标注数据，这是一项主要挑战。论文旨在解决这一问题，并提出了一种新的自监督方法，即DACA，用于优化参数（如温度$tau$）以校准模型的置信度。
### Innovation
DACA方法通过挑选同义样本来减小展温的影响，从而减轻了因预测分歧导致的置信不足问题。这种方法独立了预测分歧对校准过程的影响，从而避免了过大的温度调整，改善了校准性能。实验结果表明DACA方法的有效性，在常见的基准测试中能提高公开和API 基础的大规模语言模型（如 GPT-4o）的平均置信平等化误差（ECE）至多15.08%。
### Conclusion
DACA方法通过筛选出同义样本以减轻预测分歧带来的影响，有效改进了后训练语言模型的校准性能，使得在实际应用中更加可靠。
## 886. `cs.LG` - 基于扩散的分层图神经网络在模拟非线性固体力学中的应用 [PDF](https://arxiv.org/pdf/2506.06045), [HTML](https://arxiv.org/abs/2506.06045)
### Authors
Tobias Würth,Niklas Freymuth,Gerhard Neumann,Luise Kärger
### Background
图形学习型模拟器在对不规则网格中的物理系统进行模拟方面展现出巨大潜力，但常常难以捕捉全局现象，如弯曲或长程相关性，并且在长时间的模拟中由于依赖局部消息传递和直接预测下一步，会导致误差累积。
### Innovation
引入了Rolling Diffusion-Batched Inference Network (ROBIN)，它包含两个关键创新：(i) Rolling Diffusion-Batched Inference (ROBI)，一种并行化的推理方案，通过在时间窗口内重叠去噪步骤，跨时间步长分摊基于扩散的基础细化的成本。(ii) 在代数多重网格细化的基础上构建的分层图神经网络，允许在不同网格分辨率之间进行多尺度消息传递。
### Conclusion
ROBIN在包含几何、材料和接触非线性的2D和3D固体力学基准测试中表现优异，达到最先进的准确性，显著优于现有步长学习模拟器，同时与标准扩散模拟器相比，减少推理时间最多达一个数量级。
## 887. `cs.LG` - Edit Flows：通过编辑操作的流动匹配 [PDF](https://arxiv.org/pdf/2506.09018), [HTML](https://arxiv.org/abs/2506.09018)
### Authors
Marton Havasi,Brian Karrer,Itai Gat,Ricky T. Q. Chen
### Background
自回归生成模型能够自然地生成可变长度的序列，而非自回归模型则难以处理此类任务，经常需要引入固定、逐token的结构。该论文介绍了一种名为Edit Flows的非自回归模型，通过定义序列上的编辑操作（插入、删除和替换）流动，克服了上述局限，实现了更灵活、相对位置生成，以更好地适应序列数据的结构。
### Innovation
提出了一种名为Edit Flows的非自回归模型，通过连续时间马尔可夫链在序列空间中对这些操作进行建模，实现在位置上的灵活生成，并利用扩展状态空间的辅助变量训练方法使学习过程更高效可解
### Conclusion
实验结果显示，Edit Flows在图像字幕、文本和代码生成方面均优于自回归模型和遮盖模型，在遮盖构建任务上表现尤为突出。
## 888. `cs.LG` - MIRA：面向现实医疗数据的时间序列基础模型 [PDF](https://arxiv.org/pdf/2506.07584), [HTML](https://arxiv.org/abs/2506.07584)
### Authors
Hao Li,Bowen Deng,Chang Xu,Zhiyuan Feng,Viktor Schlegel,Yu-Hao Huang,Yizheng Sun,Jingyuan Sun,Kailai Yang,Yiyao Yu,Jiang Bian
### Background
现有的通用时间序列基础模型难以处理医疗时间序列数据，因为医疗时间序列数据具有固有的挑战，如不规则的时间间隔、异质的采样率和频繁的缺失值。这导致在数据稀缺或隐私约束的环境中难以进行有效的模型迁移。
### Innovation
MIRA 是一种专门设计用于医疗时间序列预测的统一基础模型，它采用了连续时间旋转位置编码、基于频率特定的专家混合层以及基于神经ODE的连续动力学外推模块。MIRA 在一个大规模且多样的医疗语料库上进行预训练，该语料库包含来自公开数据集的超过 4540 亿个时间点。MIRA 在出-of-distribution 和 in-distribution 场景下分别比其他零样本和微调基准降低了 10% 和 7% 的预测误差。
### Conclusion
本文引入了 MIRA，并构建了一个涵盖多个下游临床任务的基准，为未来医疗时间序列建模的研究奠定了基础，特别适用于数据稀缺或隐私约束的环境。
## 889. `cs.LG` - 火花变压器：在FFN和注意力机制中重新激活稀疏性 [PDF](https://arxiv.org/pdf/2506.06644), [HTML](https://arxiv.org/abs/2506.06644)
### Authors
Chong You,Kan Wu,Zhipeng Jia,Lin Chen,Srinadh Bhojanapalli,Jiaxian Guo,Utku Evci,Jan Wassenberg,Praneeth Netrapalli,Jeremiah J. Willcock,Suvinay Subramanian,Felix Chern,Alek Andreev,Shreya Pathak,Felix Yu,Prateek Jain,David E. Culler,Henry M. Levy,Sanjiv Kumar
### Background
研究发现，在训练好的Transformer中，几乎所有前馈网络中的神经元在每个令牌上都是不活跃的，这引起了对激活稀疏性的极大兴趣，旨在提高大型模型的效率。尽管在将稀疏性转化为实际时间效益方面取得了显著进展，但现代Transformer已经不再使用能导致这一现象的关键ReLU激活函数。现有努力重新引入激活稀疏性往往会降低模型质量，增加参数数量，复杂化或减慢训练过程。稀疏注意力机制虽然受到类似挑战，但通常也难以实现稀疏性。
### Innovation
本文介绍了一种名为Spark Transformer的新架构，该架构能够在FFN和注意力机制中同时实现高激活稀疏性，同时保持模型质量、参数数量和标准训练程序。该方法通过top-k掩码实现稀疏性控制，提出了一种硬件友好的、线性时间的近似算法（统计top-k），以避免昂贵的排序操作并减少标准top-$k$操作引起的显著训练缓慢。此外，Spark Transformer重新分配了现有的FFN参数和注意力键嵌入，形成了一个低成本预测器来识别激活的条目，以减少因强制稀疏性而导致的质量损失，同时提高实际时间效益。
### Conclusion
预训练后Spark Transformer在标准基准中表现出竞争力，FFN中的激活神经元仅占8%，每个令牌最多关注256个令牌，这些稀疏性降低了2.5倍的FLOPs，导致CPU上提高1.79倍的解码实际时间效益，GPU上提高1.40倍。
## 890. `cs.LG` - 损失平台期间发生了什么？理解Transformer中的突发学习 [PDF](https://arxiv.org/pdf/2506.13688), [HTML](https://arxiv.org/abs/2506.13688)
### Authors
Pulkit Gopalani,Wei Hu
### Background
在使用Transformer对算法任务进行训练时，经常观察到一个有趣的突发学习现象：即长时间的性能平台期后，随后突然出现显著改善。这项工作主要研究了浅层Transformer中这种动态的底层机制。
### Innovation
研究揭示了在平台期，模型通常发展出可解释的部分解决方案，同时输出表现出强烈的重复偏置。这种输出退化伴随着内部表示压缩，使得不同标记的隐藏状态几乎平行。进一步确定了最优注意力图的缓慢学习是关键瓶颈。在此期间，注意力配置中的隐藏进展预示了最终快速收敛，直接干预注意力显著改变了平台期的持续时间和重复偏置及表示压缩的严重程度。研究验证了这些已识别现象（重复偏置和表示压缩）不仅出现在玩具设置中，也在像Pythia和OLMo这样的大型语言模型的早期预训练阶段中显现。
### Conclusion
研究结果表明这些现象的存在，并非玩具设置的产物，也在大型语言模型的预训练中存在。直接干预注意力机制可以显著改变平台期的持续时间以及重复偏置和表示压缩的严重程度。
## 891. `cs.LG` - 无处不在的不变性：图基础模型的配方 [PDF](https://arxiv.org/pdf/2506.14291), [HTML](https://arxiv.org/abs/2506.14291)
### Authors
Ben Finkelshtein,İsmail İlkan Ceylan,Michael Bronstein,Ron Levie
### Background
图机器学习架构通常针对特定任务和特定数据集进行定制，限制了它们更广泛的应用。这促使研究人员探索如何构建能够跨越任意图和特征进行泛化的图基础模型。本文从基本原理出发，介绍了设计节点级任务的图基础模型的配方，重点研究了图基础模型必须尊守的对称性。通过对节点和标签排列不变、特征排列不变以及局部邻域节点排列不变的系统性研究，提出了适用于节点属性预测的图基础模型类别。
### Innovation
提出了针对节点级别的任务设计图基础模型的方法，重点在于对称性的系统性研究，包括节点和标签排列不变性以及特征排列不变性，并证明了这种方法能够构成在特定对称性下的多元集的通用逼近器。验证方法通过在29个真实世界的节点分类数据集上进行广泛的实验，展示了零样本条件下强大的性能，并随着训练图的数量增加表现出一致的改进。
### Conclusion
本文提出的方法不仅在零样本条件下表现出强大的性能，还随着训练图数量的增加表现出一致的性能提升，验证了所提出的图基础模型的有效性。
## 892. `cs.LG` - Thermodynamic Kolmogorov-Arnold Model for Structured Generative Modeling [PDF](https://arxiv.org/pdf/2506.14167), [HTML](https://arxiv.org/abs/2506.14167)
### Authors
Prithvi Raj
### Background
学习在自上而下的生成模型的潜在空间中的能量模型（EBM）为多数据模态的生成提供了一个灵活的框架，但如何利用其可解释性指导模型设计、提高生成质量和减少训练时间仍不清楚。同时，依赖Langevin蒙特卡洛（LMC）采样在效率和采样多模态潜在分布方面面临挑战。因此，研究一个能够平衡这些挑战和提供有效解决方案的新型生成模型框架是必要的.
### Innovation
本文提出了一种Kolmogorov-Arnold表示定理在生成建模中的新适应方法，并引入了热力学Kolmogorov-Arnold模型（T-KAM），利用了结构和归纳偏见。通过限制先验关系到单变量关系，T-KAM能够通过反变换法实现快速且精确的推理。通过降低潜在空间的维度并编码适当的归纳偏置，T-KAM证明了重要性采样（IS）成为一个可行、无偏且高效的后验采样器。对于IS失效的情况，T-KAM还探索了一种基于人口的LMC的新策略，分解后验采样为一系列退火分布，以改善多模态采样。
### Conclusion
T-KAM优雅地平衡了生成建模中的常见权衡，提供了快速推理、可解释性和稳定的训练，且自然适合未来的Zettascale Computing Corp.硬件。
## 893. `cs.LG` - AssistedDS: Benchmarking How External Domain Knowledge Assists LLMs in Automated Data Science [PDF](https://arxiv.org/pdf/2506.13992), [HTML](https://arxiv.org/abs/2506.13992)
### Authors
An Luo,Xun Xian,Jin Du,Fangqiao Tian,Ganghua Wang,Ming Zhong,Shengchun Zhao,Xuan Bi,Zirui Liu,Jiawei Zhou,Jayanth Srinivasa,Ashish Kundu,Charles Fleming,Mingyi Hong,Jie Ding
### Background
大型语言模型（LLMs）已推动了数据科学工作流程的自动化，但尚不清楚它们是否能像人类数据科学家那样灵活利用外部领域知识。为了解决这一问题，本文提出了一个名为AssistedDS的基准测试，旨在系统评估LLMs在表结构预测任务中处理领域知识的能力。AssistedDS集成了合成数据集和真实世界的数据科学比赛，并提供了专业的指导和对抗性文档，帮助数据科学模型更好地理解和应用领域知识。
### Innovation
1. 提出了AssistedDS基准测试，通过合成数据集和Kaggle数据科学竞赛来评估LLMs在处理领域知识时的表现。2. 结合了指导性文档和对抗性文档，这些文档针对数据清洗、特征工程和模型选择提供了领域特定的见解。3. 评估了现有的先进LLMs在识别和应用有益或有害的领域知识方面的表现，以及在信息回忆和预测性能方面的表现。
### Conclusion
实验结果表明，当前的LLMs在处理域知识时存在显著的不足，经常无批判地采用提供的信息，导致在对抗性信息干预下预测性能下降。有益指导往往无法抵消有害信息的负面影响，并且在处理时间序列数据、不同折算的一致特征工程以及正确解释类别变量方面常常犯错。这些发现揭示了现有模型在评估和利用专家知识方面的不足，强调了开发更健壮、知识敏感的自动化数据科学系统的重要性。所有相关数据和代码均可公开获取。
## 894. `cs.LG` - Execution Guided Line-by-Line Code Generation [PDF](https://arxiv.org/pdf/2506.10948), [HTML](https://arxiv.org/abs/2506.10948)
### Authors
Boaz Lavon,Shahar Katz,Lior Wolf
### Background
大型语言模型（LLMs）在代码生成方面展现了令人印象深刻的性能，但通常在推理过程中不利用执行反馈，而这种反馈是人类程序员在编程时经常依赖的关键信号。现有的方法缺乏利用这一反馈来生成可执行代码的机制，导致生成的代码可能在实际执行中出现问题。因此，本研究表明了一个利用实时执行信号动态调整生成过程的新方法，在代码生成过程中提供逐行反馈，以导向生成可执行的解决方案。这种方法能够提供连贯的指导，同时保持语法规则的结构一致性，并且自然支持任务级别的原生并行，使得多个代理可以并行处理，探索不同的推理路径，生成多样化的候选解决方案。实验结果表明，这种方法显著提高了代码生成性能，优于标准方法，在从基础问题到复杂编程和数据科学任务等多个复杂程度的任务上都达到了最先进的效果。
### Innovation
该研究提出了一种名为Execution-Guided Classifier-Free Guidance (EG-CFG)的新方法，能够在代码生成过程中动态地整合执行信号，提供逐行反馈，指导生成可执行解。这种方法利用了多阶段流程：首先进行束搜索以抽样每个位置的候选程序完成，然后通过执行这些候选程序获取执行信号，最后在生成过程中整合这些信号。此外，方法自然支持并行处理，有助于生成多样化的候选解决方案。通过保持相同行内的一致信号并在行界刷新信号，该方法提供了连贯的指导，并保持了语法结构的一致性。
### Conclusion
实验结果证明，EG-CFG显著改善了代码生成性能，并在广泛的任务级别上达到了最先进的结果，从基础问题到挑战性的编程和数据科学任务。这表明该方法在提高代码生成质量方面具有显著优势，并提供了实用的框架来提高未来的工作效率。
## 895. `cs.LG` - 采用生成模型输出的水印技术 [PDF](https://arxiv.org/pdf/2506.16349), [HTML](https://arxiv.org/abs/2506.16349)
### Authors
Nikola Jovanović,Ismail Labiad,Tomáš Souček,Martin Vechev,Pierre Fernandez
### Background
生成模型的输出水印化被认为是一种有前途的方法，用于追踪其来源。尽管对自回归图像生成模型的兴趣浓厚，且存在潜在滥用的风险，但没有先前的研究尝试在标记级别对这些模型的输出进行水印处理。该研究旨在填补这一空白，通过将语言模型水印技术应用于该情境，解决反向周期一致性（RCC）问题，即重新标记生成的图像标记会显著改变标记序列，从而抹去水印。为了提高鲁棒性，针对常见的图像变换、神经压缩和去除攻击，研究提出了定制的标记器-去标记器微调过程和补渠的水印同步层。实验表明，该方法能够实现有理论依据的p值的可信赖和鲁棒的水印检测。相关代码和模型可在特定网址获取。
### Innovation
首次应用语言模型水印技术于自回归图像生成模型的输出层面，提出改进反向周期一致性的自定义标记器-去标记器微调方法以及补渠的水印同步层，旨在提高鲁棒性并抵御常见变换、神经压缩和去除攻击等威胁。
### Conclusion
该方法展示了在理论上可验证的p值下可靠的且鲁棒的水印检测能力。相关代码和模型已公开。
## 896. `cs.LG` - MoORE: 基于SVD的模型MoE-化方法以实现抗冲突和抗遗忘的多任务适应 [PDF](https://arxiv.org/pdf/2506.14436), [HTML](https://arxiv.org/abs/2506.14436)
### Authors
Shen Yuan,Yin Zheng,Taifeng Wang,Binbin Liu,Hongteng Xu
### Background
在多任务场景中对大规模基础模型进行调整时，往往会遇到任务冲突和任务遗忘的问题。现有的方法虽然有所尝试，但效果并不理想，因此需要一种新的策略来解决这些问题。MoORE提出了一种新颖的“模型MoE-化”方法，通过SVD和引入可学习路由器来调整奇异值，使模型适应多种任务的同时具备抗冲突和抗遗忘的特点。这种方法通过SVD分解预先训练的模型权重矩阵，并通过可学习的路由器调整其奇异值，将其转换为Mixture of Orthogonal Rank-one Experts (MoORE)的形式，每一专家对应于左奇异向量和相应右奇异向量的外积。进一步通过在右奇异向量上施加可学习的正交变换提高模型容量。这种方法有效地解决了任务冲突和任务遗忘的问题，实验表明其在多个数据集上的表现优于其他方法，验证了其在抗冲突和抗遗忘方面的优越性。相关的实验代码可以在指定的链接处获取。
### Innovation
MoORE 提出了一个新的“模型MoE-化”方法，该方法通过SVD技术将模型转换为Mixture of Orthogonal Rank-one Experts (MoORE)的形式，每一种专家对应左奇异向量和相应右奇异向量的外积。这种方法不仅保证了专家间的正交性，还保持了原始权重矩阵的列空间，使得模型在新的任务中表现得更稳定，同时避免了原有任务知识的遗忘。相比低秩调整（LoRA）及其MoE驱动的变体，MoORE具有明显的优势。
### Conclusion
实验结果表明，MoORE方法在各种数据集上都表现出了比现有方法更好的性能，特别是在处理任务冲突和任务遗忘方面，展现出了其优越性。
## 897. `cs.LG` - 基于流的方法用于具有非高斯或异方差噪声的动态时间因果模型 [PDF](https://arxiv.org/pdf/2506.17065), [HTML](https://arxiv.org/abs/2506.17065)
### Authors
Abdellah Rahmani,Pascal Frossard
### Background
理解多变量时间序列中的因果关系在许多场景中至关重要，如金融或神经数据。许多此类时间序列表现出多个分段，即具有未知边界的连续时间段，每个分段都有其自身的因果结构。推断因果依赖性和分段转移对于分析底层过程至关重要。然而，在这种设置中推断因果结构具有挑战性，因为每个分段可以有自己的因果图和混合函数，并且由于复杂的噪声分布（可能是非高斯的或异方差的）。现有的因果发现方法不能解决这些挑战，因为它们通常假设平稳性或具有恒定方差的高斯噪声。
### Innovation
提出了一种名为FANTOM的统一框架，可以处理非平稳过程以及非高斯和异方差噪声。FANTOM同时推断分段的数量及其索引，并学习每个分段的有向无环图。该框架使用最大化数据对数似然证据下界的贝叶斯期望最大化算法。从理论上证明，在平稳和非平稳设置下，FANTOM建模的时间异方差因果模型在温和假设下是可识别的。
### Conclusion
在合成和真实数据上的广泛实验表明，FANTOM在性能上优于现有方法。
## 898. `cs.LG` - 使用Transformer学习模幂运算 [PDF](https://arxiv.org/pdf/2506.23679), [HTML](https://arxiv.org/abs/2506.23679)
### Authors
David Demitri Africa,Sara M. Kapoor,Theo Simon Sorg,Challenger Mishra
### Background
模幂运算在数论和密码学中至关重要，但在机制可解释性方面仍然未被深入探索。本文通过训练一个4层编码-解码Transformer模型来执行模幂运算，并研究训练过程中数值推理的出现。
### Innovation
利用原理性采样策略、PCA嵌入分析和激活补丁，研究模型中数论性质的编码方式。发现倒数运算符训练可显著提升性能，且对相关模数突然泛化。这些同步准确度跃升反映出类似理解能力的动力学，表明模型内部化了共享的算术结构。此外，最终层的子图充分包含注意力头，可实现普通幂运算任务的全性能。
### Conclusion
研究结果表明，Transformer模型通过专门的计算电路学习模算术，为更加可解释且高效的神经模幂运算方法指明了方向。
## 899. `cs.LG` - ReDit: Reward Dithering for Improved LLM Policy Optimization [PDF](https://arxiv.org/pdf/2506.18631), [HTML](https://arxiv.org/abs/2506.18631)
### Authors
Chenxing Wei,Jiarui Yu,Ying Tiffany He,Hande Dong,Yao Shu,Fei Yu
### Background
DeepSeek-R1 通过基于规则的奖励系统成功增强了大型语言模型（LLM）的推理能力，但它在解决奖励欺骗方面存在局限。实验观察表明，离散的奖励会引发梯度异常、优化不稳定以及收敛速度缓慢等问题。这是因为离散奖励信号在处理连续变化时可能导致问题。在这样的背景下，研究者提出了 ReDit 方法，通过在离散奖励信号中添加简单的随机噪声来解决这些问题，从而实现更平滑的梯度更新和更快的收敛速度。
### Innovation
ReDit 方法通过在离散的奖励信号中添加简单的随机噪声，提供连续的探索梯度，从而加快了模型的收敛速度并提高了其政策优化效率。这种方法在不同任务上都显示出了有效性，并且在相同训练步数下，ReDit 的性能与 vanilla GRPO 相当，并且在相似的训练时间内还提高了 4% 的性能。此外，提供的理论分析进一步验证了这一方法的优势。
### Conclusion
实验结果和理论分析表明，ReDit 可有效解决离散奖励带来的梯度问题，不仅能加速模型的训练过程，还能在某些情况下提升模型的性能。这对于需要高性能 LLM 的应用场景具有重要意义。
## 900. `cs.LG` - 时间序列预测中的变更点形式预测 [PDF](https://arxiv.org/pdf/2509.02844), [HTML](https://arxiv.org/abs/2509.02844)
### Authors
Sophia Sun,Rose Yu
### Background
形式预测已被探索为一种通用且有效的方法，用于为时间序列提供不确定性量化。然而，当前的方法难以处理具有变更点的时间序列数据——即时间序列生成过程中的突然变化。
### Innovation
本文提出了一种新的时间序列变更点形式预测（CPTC）算法，通过将预测潜在状态的模型与在线形式预测结合，用于建模非平稳时间序列中的不确定性，填补了该领域的空白。
### Conclusion
我们证明了CPTC在最小假设下的有效性和改进的适应性，并通过6个合成和真实世界的数据集展示了CPTC相较于最先进的基准方法的有效性和适应性的改进。
## 901. `cs.LG` - 针对表格数据生成不可察觉的在流形上的对抗攻击 [PDF](https://arxiv.org/pdf/2507.10998), [HTML](https://arxiv.org/abs/2507.10998)
### Authors
Zhipeng He,Alexander Stevens,Chun Ouyang,Johannes De Smedt,Alistair Barros,Catarina Moreira
### Background
表格数据上的对抗攻击因其混合了分类和数值特征而具有独特的挑战。与图像不同，表格数据缺乏直观的相似度度量，因此难以定义不可感知的修改。传统梯度基方法倾向于使用$boldsymbol{textbf{L_p}}$-范数约束，往往会导致生成的对抗样本偏离原始数据分布。
### Innovation
本文提出了一种使用混合输入变分自编码器（VAE）的潜在空间扰动框架，以生成统计上一致的对抗样本。该VAE将分类嵌入和数值特征整合到一个统一的潜在流形中，实现了保持统计一致性的扰动。引入了In-Distribution Success Rate (IDSR)，以联合评估攻击效果和分布对齐情况。通过六种公共数据集和三种模型架构的评估显示，该方法的异常值率显著较低，并且性能更一致，比传统的输入空间攻击和其他基于图像领域的VAE方法具有显著更低的异常值率和更高的IDSR。
### Conclusion
通过全面分析超参数敏感性、稀疏控制和生成架构，研究表明基于VAE的攻击的有效性很大程度上依赖于重建质量和充足的训练数据。在这些条件下，提出的框架在实际实用性和稳定性方面优于输入空间方法。这项工作强调了在表格领域生成真实可信且稳健的对抗样本时，在流形上进行不破坏性的扰动的重要性。
## 902. `cs.LG` - 使用高斯过程作为代理模型的基于贝叶斯优化的传感器分类系统工艺参数优化 [PDF](https://arxiv.org/pdf/2507.22766), [HTML](https://arxiv.org/abs/2507.22766)
### Authors
Felix Kronenwett,Georg Maier,Thomas Längle
### Background
基于传感器的分类系统能够对物料流进行物理分离，通过评估传感器采集的图像数据来做出分类决策，并通过执行装置进行操作。物料流的特性、系统的设计以及所需的分类精度都会影响设置的过程参数。然而，由于需求和物料流组成的变化，持续的验证和调整是必要的。本文通过引入一种基于贝叶斯优化的方案，旨在优化、持续监测和调整基于传感器的分类系统的工艺参数。
### Innovation
本文提出了一种方法，采用基于高斯过程的代理模型进行贝叶斯优化，以实现基于包含不确定性的系统行为的具体要求。这种方法减少了所需实验的次数，同时在模型计算过程中考虑了两个输出物料流的两个可能的优化目标。此外，不确定性也被考虑在内，以确定分类的准确性。
### Conclusion
我们通过三例过程参数对方法进行了评价。
## 903. `cs.LG` - DMSC: 动态多尺度协调框架用于时间序列预测 [PDF](https://arxiv.org/pdf/2508.02753), [HTML](https://arxiv.org/abs/2508.02753)
### Authors
Haonan Yang,Jianchao Tang,Zhuo Li,Long Lan
### Background
时间序列预测（TSF）在建模不同尺度间的复杂时序依赖关系方面面临持续挑战。尽管最近的研究利用了不同的分解操作和基于CNN、MLP或Transformer的新型架构，现有方法在静态分解策略、分散的依赖建模以及不可灵活融合机制方面仍存在局限性，这些限制了它们对复杂时序依赖关系的建模能力。
### Innovation
本文提出了一种新型的动态多尺度协调框架（DMSC），它包含多尺度片段分解块（EMPD）、三元交互块（TIB）和自适应尺度路由MoE块（ASR-MoE）。EMPD设计为内置组件，动态地将序列分割为具有递增尺度粒度的分层片段，通过输入适应性的片段调整消除了预定义尺度的限制。TIB联合建模层分解表示内的片段内、片段间和跨变量依赖关系。EMPD和TIB在每一层中联合集成，以分层渐进级联结构组织，早期层的粗粒度表示通过门控路径自适应引导后期层的细粒度特征提取。ASR-MoE通过利用具有时态感知加权的专业全球和局部专家动态融合多尺度预测。
### Conclusion
在十三个现实世界的基准测试上进行全面实验表明，DMSC在TSF任务中保持了最先进的（SOTA）性能和出色的计算效率。代码可在以下链接获取：this https URL
## 904. `cs.LG` - 无线边缘网络中任务卸载的多智能体强化学习 [PDF](https://arxiv.org/pdf/2509.01257), [HTML](https://arxiv.org/abs/2509.01257)
### Authors
Andrea Fox,Francesco De Pellegrini,Eitan Altman
### Background
在边缘计算系统中，自主代理需要在竞争有限的共享资源的同时快速做出本地决策。现有的多智能体强化学习（MARL）方法往往依赖于集中式评论家或频繁的通信，而这些方法在有限的能见度和通信约束下会失效。
### Innovation
该论文提出了一种分散框架，其中每个代理解决一个受约束的马尔可夫决策过程（CMDP），并隐式通过共享的约束向量进行协调。对于特定的卸载任务，约束防止共享服务器资源过载。协调约束不常更新且作为轻量级协调机制。它们使代理能够与全局资源使用目标对齐，但需要很少的直接通信。利用安全强化学习，代理学习同时满足本地和全局目标的策略。该论文在轻度假设下建立了理论保证，并实验验证了该方法优于集中式和独立的基础方法，尤其是在大规模设置中表现更好。
### Conclusion
该论文为无线边缘网络中的任务卸载提出了一个创新的多智能体强化学习方法，通过较少的直接通信实现了更优的整体性能，并且验证了该方法在多种场景下的有效性。
## 905. `cs.LG` - 人工智能计量学探索：隐藏规则环境与强化学习 [PDF](https://arxiv.org/pdf/2509.06213), [HTML](https://arxiv.org/abs/2509.06213)
### Authors
Christo Mathew,Wentian Wang,Jacob Feldman,Lazaros K. Gallos,Paul B. Kantor,Vladimir Menkov,Hao Wang
### Background
研究者们在复杂的谜题——Game Of Hidden Rules (GOHR) 环境中探讨了强化学习的应用。在这个环境中，代理必须通过在6×6板上放置棋子至桶中来推断隐藏的规则并清空板面。实验采用部分观测，要求代理同时推断规则并学习最优策略。
### Innovation
本研究创新地探索了两种状态表示策略——Feature-Centric (FC) 和 Object-Centric (OC)，并采用了基于Transformer的Advantage Actor-Critic (A2C) 算法进行训练。研究还评估了不同规则基和试验基的实验设置下模型的表现，分析了表示方法对学习效率的影响及其迁移效应。
### Conclusion
研究展示了Agent在部分观测条件下推断隐藏规则并学习策略的成效。结果表明，不同的状态表示策略影响学习效率，蕴含规则环境为检验和改进强化学习方法提供了一个有价值的平台。
## 906. `cs.LG` - xRFM: 准确的、可扩展且具有解释性的特征学习模型用于表型数据 [PDF](https://arxiv.org/pdf/2508.10053), [HTML](https://arxiv.org/abs/2508.10053)
### Authors
Daniel Beaglehole,David Holzmüller,Adityanarayanan Radhakrishnan,Mikhail Belkin
### Background
表型数据，其中包含连续和分类变量并组织成矩阵，是现代技术和科学的基础。尽管AI的其他领域经历了巨大的变革，但预测任务的最佳实践几乎没有变化，仍然主要基于梯度提升决策树（GBDT）的变体。最近，基于神经网络和特征学习方法的发展，对表型数据的先进方法产生了新的兴趣。目前，这项工作中引入了xRFM算法，该算法结合了特征学习核机与树结构的特点，既能适应数据的局部结构，又能扩展到几乎无限的训练数据量。实验结果表明，xRFM在100个回归数据集上优于31种其他方法（包括最近引入的表型基础模型TabPFNv2和GBDT），在200个分类数据集上与最好的方法具有竞争力，并且在GBDT上表现出色。此外，xRFM通过平均梯度外积本征地提供了可解释性。
### Innovation
xRFM算法创新地结合了特征学习核机和树结构的特点，使其能够适应数据的局部结构并扩展到无限的训练数据量。它在多种数据集上展示了优异的性能和可解释性，特别是优于经典的GBDT方法。
### Conclusion
xRFM算法跨100个回归数据集表现最佳，200个分类数据集竞争力强，优于GBDT等其他方法，并且本征地提供了高可解释性。
## 907. `cs.LG` - floq: 通过流匹配训练批评者以扩展价值基础强化学习中的计算能力 [PDF](https://arxiv.org/pdf/2509.06863), [HTML](https://arxiv.org/abs/2509.06863)
### Authors
Bhavya Agrawalla,Michal Nauman,Khush Agrawal,Aviral Kumar
### Background
现代大规模机器学习技术的一个特征是使用提供密集监督到中间计算的目标，例如语言模型中的教师强迫下一个标记或在扩散模型中的逐步去噪。这些方法使模型能够以可泛化的方式学习复杂函数。
### Innovation
本文提出了一种新的方法floq，这是一种通过流匹配参数化Q函数的方法，并使用TD学习目标进行训练。Q函数的训练利用了数值积分的多步过程，同时通过目标流提供的值进行引导。这种方法在价值函数表示中引入了迭代计算，相比传统的单一架构，提供了更精细的控制和Q函数容量的扩展。
### Conclusion
实验结果显示，floq在一系列具有挑战性的离线强化学习基准测试和在线微调任务中性能提升了近1.8倍。更重要的是，相较标准的TD学习架构，floq在扩展计算能力方面表现更为出色，突显了通过迭代计算提高价值学习表现的潜力。
## 908. `cs.LG` - 稀疏自编码器神经算子：函数空间中的模型恢复 [PDF](https://arxiv.org/pdf/2509.03738), [HTML](https://arxiv.org/abs/2509.03738)
### Authors
Bahareh Tolooshams,Ailsa Shen,Anima Anandkumar
### Background
现有的研究表明，神经网络在不同的架构中会收敛到相似的表示。然而，尽管神经算子在科学计算中的重要性日益增加，其表示特性仍未得到充分探索。论文将神经模型中的表示统一问题归结为稀疏模型恢复问题，并提出了一种框架，将稀疏自编码器扩展到提升空间和无穷维函数空间，从而使得大型神经算子具有机制可解释性。文章强调了提升和算子模块引入的优势归纳偏置，可以实现更快的恢复、改善光滑概念的恢复质量和跨不同分辨率的鲁棒推理，这些都是神经算子独有的特性。
### Innovation
论文提出了一种将稀疏自编码器扩展到提升空间和无限维函数空间的框架，以实现稀疏模型恢复，增强了对大型神经算子的机制解释能力，并强调这些提升和算子模块引入了有益的归纳偏置，有利于更快和更高质量的概念恢复及较高的推理稳健性，这些都是针对神经算子独有的特性描述。此外，论文还进行了稀疏自编码器（SAEs）、提升的稀疏自编码器（lifted-SAE）和稀疏自编码器神经算子的相关对比分析研究。
### Conclusion
论文的研究揭示了稀疏自编码器、提升的稀疏自编码器和稀疏自编码器神经算子之间的对比特性，强调了稀疏自编码器神经算子在实现有效表示恢复和提供更好的机制可解释性方面的优势。
## 909. `cs.LG` - ROOT: 通过概率桥梁重新思考离线优化作为一种分布转换 [PDF](https://arxiv.org/pdf/2509.16300), [HTML](https://arxiv.org/abs/2509.16300)
### Authors
Manh Cuong Dao, TheHung Tran,Phi Le Nguyen,Thao Nguyen Truong,Trong Nghia Hoang
### Background
本文研究的是黑盒优化任务，即利用观测到的输入-输出对来找到黑盒函数的最大值。通常通过学习和优化一种替代函数来实现，也可以将其视为一个逆向建模任务，将所需性能映射到可能实现该性能的输入候选者上。然而，这两种方法都受限于离线数据量有限。为了克服这一限制，作者引入了一种新视角，将离线优化视为一种分布转换任务。这一任务通过学习一个概率桥梁来转换低价值输入的隐含分布到高价值输入的分布上来实现。
### Innovation
提出的是一种通过学习从低价值输入（即离线数据）隐含分布到高价值输入（即解候选）概率桥梁的方法。这些高价值输入是从类似于目标函数的合成函数中抽样得到的。这些合成函数由针对离线数据的不同参数化拟合的多个高斯过程的均值后验构建，从而缓解了数据瓶颈问题。这种方法在广泛的基准测试中表现优异，且能够显著提高性能并确立新的前沿水平。
### Conclusion
本文的方法在广泛的基准测试中展示了显著的性能提升，达到了新的前沿水平。代码已公开提供，可以从这个 https URL 获取。
## 910. `cs.LG` - 解决不确定性评估方法在自然语言生成评价中的陷阱 [PDF](https://arxiv.org/pdf/2510.02279), [HTML](https://arxiv.org/abs/2510.02279)
### Authors
Mykyta Ielanskyi,Kajetan Schweighofer,Lukas Aichberger,Sepp Hochreiter
### Background
大语言模型（LLMs）常常会出现幻觉问题，降低了其可靠性。最近的研究发现了一种特定类型的幻觉，称为自编（confabulations），这类幻觉是由于LLMs的预测不确定性引起的。目前有许多方法来估计自然语言生成（NLG）中的预测不确定性，并通过将其与生成文本的正确性进行相关性评估来衡量这些方法的有效性。然而，常用的近似正确性函数之间存在较大分歧，这使得在对不确定性估计方法进行排序时存在偏差，从而影响评估结果的准确性。
### Innovation
本文提出了使用多种替代风险指标来改善不确定性估计方法（UE算法）的实证评估的鲁棒性。对于问答任务，提出了多种LLM-as-a-judge变体的边际化方法来减少评估偏差。此外，还探索了结构化任务和离群值及扰动检测任务，这些任务可以提供稳健且可控的风险指标。最终，提出了使用不确定性估计方法的Elo排名来进行客观的总结，适用于广泛的评估设置。
### Conclusion
通过对不确定性估计方法进行重新评估，本文提出的方法能够提高对NLG中不确定性估计算法的评估鲁棒性和客观性。使用多变体的边际化评估可以让评估结果更加公平，而Elo排名方法则能够为各种广泛评价进行全面且客观的总结。
## 911. `cs.LG` - 用锐化的角相似度替换Softmax相似度：扩展到十亿上下文注意机制的理论与实践 [PDF](https://arxiv.org/pdf/2510.04008), [HTML](https://arxiv.org/abs/2510.04008)
### Authors
Sahil Joshi,Agniva Chowdhury,Amar Kanakamedala,Ekam Singh,Evan Tu,Anshumali Shrivastava
### Background
Softmax Attention在处理长上下文时具有二次时间复杂度，使得在长时间上下文中运行变得不再可行，即使是使用了高度优化的GPU内核。例如，FlashAttention（精确的GPU优化实现的Softmax Attention）在NVIDIA GH200（96 GB）上，当上下文超过约400万个标记时，就无法完成单次前向-后向传递的过程。
### Innovation
RACE Attention是一种基于内核的替代Softmax Attention的新机制，其时间复杂度为序列长度和嵌入维度的线性。RACE Attention用锐化的角相似度替换指数内核，并通过随机投影和软局部敏感哈希（LSH）来近似注意力输出。在语言建模、掩码语言建模以及文本分类中，RACE Attention的准确度与强基准模型相当，同时减少了运行时间和内存占用。
### Conclusion
在一项控制规模的测试中，RACE Attention能够在NVIDIA GH200 GPU上处理1200万个标记，在Intel Xeon Gold 5220R CPU上处理7500万个标记，超过了当前最先进的注意力实现的实用性限制。因此，RACE Attention为现代硬件上实现极其长的上下文窗口提供了一个实用且理论支持的机制。
## 912. `cs.LG` - 语言模型中小批量训练：当使用标准SGD有效及梯度积累为何浪费 [PDF](https://arxiv.org/pdf/2507.07101), [HTML](https://arxiv.org/abs/2507.07101)
### Authors
Martin Marek,Sanae Lotfi,Aditya Somasundaram,Andrew Gordon Wilson,Micah Goldblum
### Background
传统的智慧认为小批量大小会导致语言模型预训练和微调不稳定，因此开发了梯度累积作为补偿手段，通过增加批量大小来获得更多的优化步骤。小批量大小往往会降低学习率，而其他超参数通常保持不变。本文重新审视了从一到极小批量大小的稳定性问题，并提出了一种针对小批量调整Adam超参数的规则。结果显示，小批量训练不仅稳定，而且在超参数选择上更具鲁棒性，性能与大批次相当甚至更优，并且使得标准SGD在不使用动量的情况下也能稳定训练大模型。
### Innovation
提出了调整Adam超参数的规则，特别是保持第二矩衰减半衰期固定。显示了标准SGD在小型批量大小下的稳定性，并发现除非使用多个设备上多个模型，否则梯度积累是浪费的。还提出使用具有较小状态大小的优化器，可以提供全微调的性能优势，同时保持与LoRA相似的内存占用。
### Conclusion
建议选择适当的批量大小和设置优化器超参数，并建议在使用多个设备和模型副本时使用梯度积累。小批量与具有小状态大小的优化器结合可提供全微调的性能优势，同时保持与LoRA相似的内存占用。
## 913. `cs.LG` - 任意熵策略优化：在强化学习微调中熵是可控的 [PDF](https://arxiv.org/pdf/2510.08141), [HTML](https://arxiv.org/abs/2510.08141)
### Authors
Chen Wang,Zhaochun Li,Jionghao Bai,Yuzhi Zhang,Shisheng Cui,Zhou Zhao,Yue Wang
### Background
强化微调（RFT）是提高大语言模型（LLM）推理能力的关键，但广泛应用的组相对策略优化（GRPO）方法存在熵坍塌问题，导致熵单调递减、探索消失和策略过早收敛。现有熵正则化方法未能完全解决这一问题，反而引入了偏差和不稳定性，使得熵控制问题悬而未决，熵、探索和性能之间的关系也不明了。
### Innovation
提出了任意熵策略优化（AEPO），通过将熵红利替换为温度调整后的分布上的REINFORCE策略梯度，以及通过温度调节稳定熵来消除熵坍塌。AEPO 结合了策略梯度、分布和REINFORCE作为正则化设计，可以在不扭曲优化的情况下实现精确的熵控制。实验证明AEPO（1）能够稳定在任意目标水平的熵，有效地去除GRPO中的熵坍塌；（2）揭示了非单调关系，即性能首先在熵增加时提升，然后随熵进一步增加而下降，这澄清了熵、探索和推理之间的联系；（3）超越了熵的概念，提供了一个更广泛的RFT范式，其中优越的目标分布可以作为REINFORCE正则化器。
### Conclusion
AEPO 在熵控制、探索与性能之间的关系揭示以及增强RFT的普遍性方面做出了重要贡献。
## 914. `cs.LG` - 无机晶体生成建模中连续唯一性和新颖性度量 [PDF](https://arxiv.org/pdf/2510.12405), [HTML](https://arxiv.org/abs/2510.12405)
### Authors
Masahiro Negishi,Hyunsoo Park,Kinga O. Mastej,Aron Walsh
### Background
随着应对气候变化等紧迫的科学挑战，越来越复杂的生成人工智能模型正在被开发，这些模型可以高效地采样可能的功能材料的巨大化学空间，快速生成新的化学组成和晶体结构。这些模型通常使用唯一性和新颖性度量进行评估，这些度量依赖于所选择的晶体距离函数。然而，最常用的距离函数存在四个主要局限：无法量化化合物之间的相似度；无法区分组成差异和结构差异；缺乏对原子坐标位移的Lipschitz连续性；以及导致的唯一性度量对于生成样本的排列不具备不变性。
### Innovation
本文提出使用两种连续距离函数来评估生成唯一性和新颖性，理论上克服了上述局限。实验结果表明，这些距离函数揭示了传统距离函数所遗漏的洞察，为评估和比较生成无机晶体的模型提供了更可靠的依据。
### Conclusion
本研究中的两种连续距离函数能更全面准确地评价生成的无机晶体模型的唯一性和新颖性，实验结果验证了其有效性和可靠性。
## 915. `cs.LG` - DeepCausalMMM：一种结合因果推理的深度学习营销组合模型框架 [PDF](https://arxiv.org/pdf/2510.13087), [HTML](https://arxiv.org/abs/2510.13087)
### Authors
Aditya Puttaparthi Tirumala
### Background
传统的营销组合模型（MMM）方法使用线性回归或贝叶斯分层模型来估计营销活动对销售、收入或客户访问等业务结果的影响。这些方法假设了不同渠道之间的独立性，难以捕捉复杂的时序动态和非线性饱和效应。因此，需要一种新的方法来解决这些问题。
### Innovation
DeepCausalMMM是一种结合深度学习、因果推理和先进营销科学的Python包，通过门控循环单元（GRUs）自动学习时序模式，如广告效应（滞后效应），并同时通过有向无环图（DAG）学习营销渠道之间的统计依赖性和潜在因果结构。此外，它还通过希尔方程基饱和曲线模型来优化营销预算分配并理解渠道饱和。
### Conclusion
DeepCausalMMM通过数据驱动的方法自动学习超参数和变换，具备多区域建模、稳健的统计方法和全面的响应曲线分析功能，从而提供了一种新的营销组合模型方法，以克服现有方法的局限性。
## 916. `cs.LG` - 关系变换器：通往关系数据零样本基础模型的道路 [PDF](https://arxiv.org/pdf/2510.06377), [HTML](https://arxiv.org/abs/2510.06377)
### Authors
Rishabh Ranjan,Valter Hudovernik,Mark Znidar,Charilaos Kanatsoulis,Roshan Upendra,Mahmoud Mohammadi,Joe Meyer,Tom Palczewski,Carlos Guestrin,Jure Leskovec
### Background
预训练的变压器模型能够通过零样本提示快速适应新的序列建模任务，但关系领域缺乏能够在不同数据集和任务之间迁移的架构。核心挑战在于关系数据的多样性，包括不同的异构模式、图形结构和功能依赖关系。本文分析了这种背景下存在的问题和发展需求。
### Innovation
本文提出了关系变换器（RT）架构，这种架构能基于多样化的关系数据库预训练，并在不进行任务或数据集特定的微调或检索上下文示例的情况下直接应用到未知的数据集和任务中。RT架构包括：(i) 使用表/列元数据对单元进行分词，(ii) 通过掩码词预测进行预训练，(iii) 应用一种新颖的关系注意力机制，用于遍历列、行和主外键链接。实验结果表明，RT在涵盖如流失和销售预测任务的各种RelBench数据集上，能够实现强大的零样本性能，单次前向传递的22M参数模型的二元分类任务AUPRC平均值为93%，而27B参数的大型语言模型仅达到84%。微调后，RT能获得最先进的结果，具有高效的数据样本使用率。本文强调了RT的零样本迁移利用了任务-表格上下文、关系注意力模式和模式语义。
### Conclusion
总体而言，RT为关系数据提供了一条可行的基础模型路径。
## 917. `cs.LG` - 关于隐私保护的公平性：差分隐私机器学习中组隐私风险差异的测量与缓解 [PDF](https://arxiv.org/pdf/2510.09114), [HTML](https://arxiv.org/abs/2510.09114)
### Authors
Zhi Yang,Changwu Huang,Ke Tang,Xin Yao
### Background
尽管在传统公平型机器学习（ML）和差分隐私机器学习（DPML）方面取得了显著进展，但对于不同群体间的隐私保护公平性，尤其是在隐私保护方面仍存在不足。现有研究主要集中在评估群体隐私风险，但通常基于数据记录的平均隐私风险，这可能导致低估特定群体的隐私风险差异。此外，评估数据记录的最坏情况隐私风险的方法耗时，限制了其实际应用。这些问题促使研究者寻找一种更有效的方法来评估和缓解这种差异。
### Innovation
本文介绍了一种新型的成员推理游戏，能够高效地审计数据记录的近似最坏情况隐私风险。通过与现有方法对比，发现该方法能提供更严格的群体隐私风险测量，有助于公平评估不同群体的隐私风险差异。此外，为了在DPML中促进隐私保护公平性，论文提出了在标准DP-SGD算法中加入自适应组别特定梯度裁剪策略，这种方法基于差分隐私审计研究中的“金丝雀”设计灵感。广泛的实验表明，该算法能有效减少群体间的隐私风险差异，从而提高DPML中的隐私保护公平性。
### Conclusion
本文通过提出一种新的成员推理游戏，提供了对数据记录的近似最坏情况隐私风险的高效审计方法，并通过自适应的组别特定梯度裁剪策略改进了DP-SGD算法。实验结果表明，该方法能有效减少不同群体隐私风险之间的差异，提高DPML中隐私保护的公平性。
## 918. `cs.LG` - 连接对称性和鲁棒性：增强对抗鲁棒性的对称性的作用 [PDF](https://arxiv.org/pdf/2510.16171), [HTML](https://arxiv.org/abs/2510.16171)
### Authors
Longwei Wang,Ifrat Ikhtear Uddin,KC Santosh,Chaowei Zhang,Xiao Qin,Yang Zhou
### Background
对抗样本揭示了深度神经网络中存在的关键漏洞，这些漏洞通过利用输入微小扰动的敏感性被利用。虽然对抗训练仍然是主要的防御策略，但它通常会引入显著的计算成本，并且可能损害干净数据的准确性。
### Innovation
本文提出并评估了两种对称性感知架构：一种并行设计，分别处理标准和对称特征，然后再融合；一种级联设计，按顺序应用对称运算。理论上，我们展示了这些模型减少了假设空间的复杂性，正则化梯度，并在CLEVER框架下提供了更紧的鲁棒性界限。实证研究显示，这些模型在CIFAR-10、CIFAR-100和CIFAR-10C上的对抗鲁棒性和泛化能力得到了提高，而无需进行对抗训练
### Conclusion
这些结果强调了对称性约束架构作为高效且原理上可行的替代数据增强防御策略的潜力。
## 919. `cs.LG` - 特征选择与正则化在多类分类中的实证研究：基于梯度下降优化和L1稀疏约束的一对多逻辑回归 [PDF](https://arxiv.org/pdf/2510.14449), [HTML](https://arxiv.org/abs/2510.14449)
### Authors
Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel
### Background
多类葡萄酒分类展示了模型准确性、特征维度和可解释性之间的基本权衡，这些因素对于分析化学中的生产部署至关重要。本文通过全面的实证研究，探讨了一对多逻辑回归在UCI葡萄酒数据集上的应用（178个样本，3种葡萄品种，13个化学特征），比较了从零开始实现的梯度下降与scikit-learn优化求解器之间的差异，并量化了L1正则化对特征稀疏性的影响。
### Innovation
1. 研究基于梯度下降优化和L1稀疏约束的一对多逻辑回归，比较了从零开始实现的梯度下降与scikit-learn优化求解器性能。2. 通过分类特定分析，揭示了不同葡萄品种具有不同的化学特征标记，这些标记具有异质性模式，并且颜色强度在不同葡萄品种之间变化剧烈。3. L1正则化在仅减少4.63%准确性的情况下，可以减少54-69%的特征，显示出有利的解释性能权衡。4. 提出了一个仅包含5个特征的最佳子集，实现了62%的复杂度减少，估计准确性为92-94%，简化了实际部署，降低了80美元的每样本成本和56%的时间。
### Conclusion
研究结果提供了在资源受限环境中平衡全面化学分析与目标特征测量的操作指南。统计验证证实了模型的稳健泛化性和小于2毫秒的预测延迟，适合实时质量控制。
## 920. `cs.LG` - 许多深度学习的泛化度量都是脆弱的 [PDF](https://arxiv.org/pdf/2510.18934), [HTML](https://arxiv.org/abs/2510.18934)
### Authors
Shuofeng Zhang,Ard Louis
### Background
已经应用了各种泛化度量来评估深度神经网络(DNNs)的性能。尽管获得稳健的界限仍然是一个挑战，但这些度量通常被认为是能够反映泛化趋势的。然而，本文指出，许多后验泛化度量（在训练后计算的度量）都是非常脆弱的，即使是微小的训练改变也会显著改变这些度量的值、趋势或缩放行为。
### Innovation
本文研究表明，许多现有的泛化度量，如路径范数、谱范数、弗罗贝尼乌斯范数、平坦性度量以及基于确定性的PAC-Bayes代数方法，都是脆弱的。此外，作者还识别了一些微妙形式的脆弱性，例如尽管PAC-Bayes起源度量被认为是最可靠的，但在数据复杂度方面几乎无法捕捉到学习曲线之间的差异。
### Conclusion
本文还建议，开发新泛化度量的开发者应该明确地检查它们的脆弱性。
## 921. `cs.LG` - TabR1: Taming PRPO for tabular reasoning LLMs [PDF](https://arxiv.org/pdf/2510.17385), [HTML](https://arxiv.org/abs/2510.17385)
### Authors
Pengxiang Cai,Zihao Gao,Jintai Chen
### Background
传统的表格预测依赖于梯度增强决策树和专门的深度学习模型，这些模型在特定任务上的表现优异，但缺乏解释性且在跨表格任务间的迁移能力较弱。具有透明推理痕迹的大型语言模型（LLMs）展示了跨任务适应性的潜力，但尚未充分利用在表格数据中的应用。
### Innovation
本文提出了TabR1，这是首个应用于表格预测的多步推理LLM，核心在于Permutation Relative Policy Optimization (PRPO)方法，通过编码列重排不变性作为结构先验，构造样本的多种保持标签的重排，并在重排内部和跨重排之间估算优势，将稀疏奖励转化为密集学习信号，以提高泛化能力。PRPO方法在有限监督下激活了LLMs的推理能力，提升了少样本和零样本下的性能和解释性。
### Conclusion
全面实验表明，在全监督微调下，TabR1的性能与强大基线相当。在零样本场景中，TabR1的表现接近32-shot设置下的强大基线。此外，TabR1 (8B) 在各种任务中显著优于多得多的LLM（如DeepSeek-R1 (685B)），在某些任务上的性能提高了高达53.17%。
## 922. `cs.LG` - 每个注意力机制都重要：一种用于长上下文推理的高效混合架构 [PDF](https://arxiv.org/pdf/2510.19338), [HTML](https://arxiv.org/abs/2510.19338)
### Authors
Ling Team,Bin Han,Caizhi Tang,Chen Liang,Donghao Zhang,Fan Yuan,Feng Zhu,Jie Gao,Jingyu Hu,Longfei Li,Meng Li,Mingyang Zhang,Peijie Jiang,Peng Jiao,Qian Zhao,Qingyuan Yang,Wenbo Shen,Xinxing Yang,Yalin Zhang,Yankun Ren,Yao Zhao,Yibo Cao,Yixuan Sun,Yue Zhang,Yuchen Fang,Zibin Lin,Zixuan Cheng,Jun Zhou
### Background
论文介绍了Ring-linear模型系列，包括Ring-mini-linear-2.0和Ring-flash-linear-2.0。两种模型都采用混合架构，结合了线性注意力与softmax注意力，显著降低了长上下文推理中的I/O和计算开销。相较于一个参数量为320亿的密集模型，该模型系列将推理成本减小到1/10，相比原Ring系列也减少了超过50%的成本。
### Innovation
论文提出了使用自研高性能FP8操作符库-灵hé来提高整体训练效率，并改善了混合架构中不同注意力机制之间的比例关系，从而找到了目前最佳的模型结构。这些改进使得在强化学习阶段能进行长期、稳定且高效的优化，维持了在多个复杂推理基准测试中的SOTA性能。
### Conclusion
该模型系列在保留高性能的同时，显著降低了模型的大小及计算资源的需求，适用于长上下文推理任务。
## 923. `cs.LG` - FlyLoRA: 通过隐式秩别混合专家提高任务解耦和参数效率 [PDF](https://arxiv.org/pdf/2510.08396), [HTML](https://arxiv.org/abs/2510.08396)
### Authors
Heming Zou,Yunliang Zang,Wutong Xu,Yao Zhu,Xiangyang Ji
### Background
低秩适应（LoRA）是一种广泛使用的参数高效微调方法，用于基础模型，但它面临参数干扰的问题，导致性能不佳。虽然基于混合专家（MoE）的LoRA变体在单任务指令微调中可以减轻任务内相关性，但它们增加了额外的路由器参数，并且在多任务模型合并中仍然无效，因为多任务环境中的任务间干扰引起了问题。
### Innovation
受苍蝇嗅觉电路的启发，我们提出了FlyLoRA，这是一种隐式的基于MoE的LoRA变体，引入了（1）在上投影矩阵中的秩别专家激活，和（2）一个隐式路由器，将专家路由和下投影统一在一起。该设计通过消除显式路由器的需要，解决了任务内去相关和计算效率之间的权衡，并且由于随机矩阵的正交性质，天生可以缓解任务间干扰。
### Conclusion
我们在四个领域——通用知识理解、科学问题解答、数学推理和代码生成——进行了广泛的实验，表明FlyLoRA对比现有方法具有一致的性能改进。FlyLoRA 还表明生物结构可以启发人工智能技术中的创新。
## 924. `cs.LG` - 通过第一层Value头的跳接连接改进模型表示并减少KV缓存 [PDF](https://arxiv.org/pdf/2510.16807), [HTML](https://arxiv.org/abs/2510.16807)
### Authors
Zhoutong Wu,Yuan Zhang,Yiming Dong,Chenheng Zhang,Cong Fang,Kun Yuan,Zhouchen Lin
### Background
Transformer模型在各种语言任务中取得了突破，主要得益于它们强大的学习丰富上下文表示的能力。但是，为了规模扩大以提高表示能力，通常需要大量的内存和计算资源，例如自回归解码中使用的Key-Value（KV）缓存。尽管跳接连接能够提高表示能力而不增加资源使用，但大多数先前的工作要么在保持KV成本不变的情况下提高表达能力，要么减少内存但牺牲表示能力。在本文中，研究者提出了一种名为SkipV1Former的Transformer变体，这种变体使用第一层Value头部的跳接连接来加强模型表示并减少KV缓存。从第二块开始，每一层重新使用第一层的一半Value头部，而计算另一半，则完全减小了Value投影和V缓存的使用量，大约减去了50%。
### Innovation
提出了一种名为SkipV1Former的新Transformer变体，它通过使用第一层的Value头部的跳接连接来增强模型表示能力并减少KV缓存。具体地说，从第二块开始，每一层重新使用第一层的一半Value头部，计算另一半时则通常计算，这减去了大约50%的Value投影和V缓存。从理论上讲，未经压缩的第一层Value头部被路由到更深层，可以恢复压缩造成的信息损失，并加快模型的潜在优化过程。在不同模型规模下，SkipV1Former在减少大约25%的KV缓存的同时，改善了困惑度，比标准的多头注意机制（MHA）的Transformer及其一些高级变体表现更好。此外，研究者提供了一个将现有的MHA Transformer检查点升级到SkipV1Former的食谱。当与YOCO结合使用时，它可以几乎减半KV缓存大小，同时仍然提高性能。
### Conclusion
SkipV1Former可以无缝结合高级方法如组查询注意和多潜在注意，以实现进一步的KV缓存节省和性能改进。与其他方法结合使用时，它可以显著减小KV缓存的大小，同时提高性能。
## 925. `cs.LG` - 通过注意力桥梁实现的高效任意Transformer到Mamba蒸馏 [PDF](https://arxiv.org/pdf/2510.19266), [HTML](https://arxiv.org/abs/2510.19266)
### Authors
Penghao Wang,Yuhao Zhou,Mengxuan Wu,Panpan Zhang,Zhangyang Wang,Kai Wang
### Background
状态空间模型（SSMs）作为序列建模的高效替代方案，通过递归结构实现了更好的可扩展性，但其训练成本高昂，周围的生态系统远不如Transformer成熟。此外，两者结构的异质性使得从预训练的注意力模型中有效地提取知识变得具有挑战性。
### Innovation
提出了一种名为Cross-architecture distillation via Attention Bridge (CAB)的新颖数据高效蒸馏框架，该框架能够通过轻量级桥梁和灵活的逐层对齐机制高效地将Transformer教师权重的知识转移到状态空间学生模型中。与传统的仅在输出层面进行知识转移的方法不同，CAB支持在词汇层面的监督，从而提高效率和可移植性。
### Conclusion
广泛的实验表明，该方法在视觉和语言领域的一系列任务中都能提升状态空间模型的性能，即使在有限的训练数据下也表现良好，超过了标准和跨架构蒸馏方法。研究结果表明，基于注意力的知识可以高效转移至递归模型中，促进Transformer专长的快速利用以建立更强大的SSM社区。
## 926. `cs.LG` - 团队协作的大语言模型检测和缓解幻觉 [PDF](https://arxiv.org/pdf/2510.19507), [HTML](https://arxiv.org/abs/2510.19507)
### Authors
Demian Till,John Smeaton,Peter Haubrick,Gouse Saheb,Florian Graef,David Berman
### Background
最近的研究展示了通过一致性方法在大语言模型（LLM）幻觉检测和缓解方面取得了最先进的成果，这些方法涉及从同一个LLM为一个给定提示生成的多个响应中进行聚合。这些方法有助于抵消训练数据的不足所造成的限制，包括偏见和信息不足等问题，这些问题可能导致幻觉。
### Innovation
研究表明将单一模型的一致性方法扩展到结合来自不同训练数据、不同训练方案和模型架构的多个LLM的响应，可以在幻觉检测和缓解能力上取得显著的进一步提升，超越单一模型的一致性方法。该研究还评估了这种“联盟一致性”方法，并探索在这种方式下将不同LLM团队联合起来的什么条件下是有益的。此外，研究表明这些性能提升往往伴随着推理成本的减少，弥补了单一模型一致性方法的一个重要缺点。
### Conclusion
本文通过实验表明，将不同训练数据、不同训练方案和不同模型架构的多个LLM结合在一起，形成一个“联盟一致性”方法，可以在幻觉检测和缓解方面取得进一步的改进。同时，这种方法的性能提升通常伴随着推理成本的减少，这弥补了单一模型一致性方法的一个重大的缺点。
## 927. `cs.LG` - 迈向鲁棒性的零样本强化学习 [PDF](https://arxiv.org/pdf/2510.15382), [HTML](https://arxiv.org/abs/2510.15382)
### Authors
Kexin Zheng,Lauriane Teyssier,Yinan Zheng,Yu Luo,Xianyuan Zhan
### Background
零样本强化学习（RL）最近的发展为学习能够以零样本方式适应任意新任务的广泛预训练策略开辟了新途径。虽然流行的前向-后向表示（FB）及其相关方法在零样本RL中展示了潜力，但我们发现它们的建模缺乏表达性，且在离线学习过程中因离分布（OOD）动作导致的外推误差有时会导致有偏表示，从而导致次优性能。
### Innovation
我们提出了行为正则化零样本强化学习和表达性增强（BREEZE），这是一种升级的基于FB的框架，旨在同时增强学习稳定性、策略提取能力和表示学习质量。BREEZE引入了零样本RL策略学习中的行为正则化，将策略优化转换为一个稳定的学习模型。此外，BREEZE使用任务条件的扩散模型来提取策略，允许在零样本RL设置中生成高质量和多模态的动作分布。BREEZE还采用表达性的基于注意力的架构进行表示建模，以捕捉环境动力学之间的复杂关系。
### Conclusion
在ExORL和D4RL Kitchen上的广泛实验表明，BREEZE在性能上达到最佳或接近最佳，同时表现出比以前的离线零样本RL方法更好的鲁棒性。完整的实现可以在这个链接中找到：this https URL
## 928. `cs.LG` - 通过分层推测性解码实现快速推理 [PDF](https://arxiv.org/pdf/2510.19705), [HTML](https://arxiv.org/abs/2510.19705)
### Authors
Clara Mohri,Haim Kaplan,Tal Schuster,Yishay Mansour,Amir Globerson
### Background
变压器语言模型生成文本时是自回归的，这使得推理延迟与生成的词元数量成正比。推测性解码通过使用较小的初步模型预先提出可能的词元，并且由较大的目标模型并行验证，从而可以减少这种延迟而不牺牲输出质量。然而，实际中可能存在一系列不同速度和准确性的初步模型选择问题。现有的技术只考虑单个初步模型，而没有优化这一过程。
### Innovation
提出了一种名为分层推测性解码（HSD）的算法，通过堆叠不同的初步模型形成分层结构，每个模型提出词元，下一个更大模型并行验证，最终由目标模型进行验证。此外，还推导出了该层次结构的期望延迟表达式，并展示了如何在多项式时间内选择具有最短延迟的层次结构。实验结果表明，与最佳单一初步模型技术相比，HSD 可以获得高达 1.2 倍的加速，证明了该算法在减少生成延迟方面的实际应用价值超越了先前的技术手段。
### Conclusion
研究指出了如何通过优化分层初步模型的选择来降低Transformer翻译模型的推理延迟问题，并证明了HSD算法在实践中能够有效提升生成速度。
## 929. `cs.LG` - CONFEX: 基于可信性保证的不确定性感知反事实解释 [PDF](https://arxiv.org/pdf/2510.19754), [HTML](https://arxiv.org/abs/2510.19754)
### Authors
Aman Bilkhoo,Mehran Hosseini,Milad Kazemi,Nicola Paoletti
### Background
反事实解释(CFX)为模型预测提供人类可理解的理由，使行动归因成为可能，并增强可解释性。要可靠，CFX必须避免高预测不确定性的区域，在这些区域解释可能误导或不适用。然而，现有方法通常忽略不确定性或缺乏将不确定性纳入其中的正规机制。
### Innovation
作者提出了一种名为CONFEX的新方法，使用Conformal Prediction (CP) 和 Mixed-Integer Linear Programming (MILP)生成不确定感知的反事实解释。CONFEX设计提供局部覆盖保证，解决CFX生成的不可交换性问题。通过开发一种基于树形分区的新型局部化CP程序，CONFEX能够利用高效的MILP编码。这使得CONFEX在预測不确定性和最优性方面提供严谨的保证。
### Conclusion
在不同的基准和度量上，CONFEX与最先进的方法进行了评估，结果表明其不确定性感知的方法能够提供稳健且合理的解释。
## 930. `cs.LG` - 因果预测模型后处理 [PDF](https://arxiv.org/pdf/2406.09567), [HTML](https://arxiv.org/abs/2406.09567)
### Authors
Carlos Fernández-Loría,Yanfang Hou,Foster Provost,Jennifer Hill
### Background
组织越来越多地依赖预测模型来决定哪些人应该成为干预对象的候选人，如市场活动、客户保留计划或医疗治疗。然而，这些模型通常是为了预测结果（如购买可能性或流失概率）而构建的，而不是评估干预的实际影响。因此，它们产生的评分（预测值）经常不是资源分配的良好指南。随机实验可以估计因果效应，但实验成本高昂、规模有限且与特定行动相关。
### Innovation
我们提出了因果后处理（CPP）技术家族，这是一种使用有限的实验数据来改进预测模型输出的技术，从而使它们更好地适应因果决策。CPP技术家族跨越了灵活度与数据效率之间的权衡，统一了现有方法并鼓励了新的方法。通过模拟和数字广告领域的实证研究，我们展示了CPP可以在预测模型捕捉有用但不完美的因果信号时改善干预决策。
### Conclusion
我们的结果表明，组织可以通过结合预测建模和实验证据来做出更有效的、可扩展的干预决策。
## 931. `cs.LG` - 关于扩散模型中缓存方法的综述：迈向高效的多模态生成 [PDF](https://arxiv.org/pdf/2510.19755), [HTML](https://arxiv.org/abs/2510.19755)
### Authors
Jiacheng Liu,Xinyu Wang,Yuqi Lin,Zhikai Wang,Peiru Wang,Peiliang Cai,Qinming Zhou,Zhengan Yan,Zexuan Yan,Zhengyi Shi,Chang Zou,Yue Ma,Linfeng Zhang
### Background
扩散模型因其卓越的生成质量和可控性成为了现代生成人工智能的核心基础。然而，它们内在的多步迭代和复杂的骨干网络导致了巨大的计算开销和生成延迟，成为实时应用的主要瓶颈。尽管已经有一系列加速技术取得进展，但它们仍然面临着应用限制、训练成本高昂或质量下降等问题。
### Innovation
扩散缓存（Diffusion Caching）提供了一种无需训练、架构通用且高效的推理范式。其核心机制在于识别并重用扩散过程中的内在计算冗余。它通过实现特征级别的跨步重用和跨层调度，减少计算量而不改变模型参数。本文系统地回顾了扩散缓存的理论基础和演变历程，并提出了一体化的分类和分析框架。研究表明，扩散缓存从静态重用向动态预测发展，提高了缓存灵活性并有利于与其他加速技术的整合，从而为未来的多模态和互动应用提供了一个统一且高效的推理框架。
### Conclusion
我们主张这种范式将成为实时和高效生成人工智能的关键催化剂，为高效生成智能这一理论与实践注入新的活力。
## 932. `cs.LG` - ResNets信号传播的场论 [PDF](https://arxiv.org/pdf/2305.07715), [HTML](https://arxiv.org/abs/2305.07715)
### Authors
Kirsten Fischer,David Dahmen,Moritz Helias
### Background
研究表明，残差网络在深度较大时比前馈网络具有更好的可训练性和性能，这得益于引入了跳接连接以促进信号传播。先前的研究发现，在残差分支中添加缩放参数可以进一步提高泛化性能，尽管通过实证方法确定了一个特别有益的参数范围，但关于这种缩放参数带来的性能提升及其实现的普适性仍需进一步理论理解。针对前馈网络，有限尺寸理论已经为信号传播及其超参数调优提供了重要的见解。本文在此基础上，通过推导残差网络的系统性有限尺寸场理论，研究信号传播及其对缩放参数依赖性。
### Innovation
本文推导了一种残差网络的系统性有限尺寸场理论，解释了缩放参数在不同网络超参数下的普适性。理论结果证明了实测的缩放参数值位于最大敏感度范围内，并给出了依赖于其他网络超参数的最优缩放参数的解析表达式。
### Conclusion
这项工作提供了在有限尺寸下研究残差网络的理论框架，分析了信号传播及其对缩放参数的依赖性，解释了缩放参数的普适性原因。
## 933. `cs.LG` - 从安全神经元视角探索安全对齐：机制性的理解 [PDF](https://arxiv.org/pdf/2406.14144), [HTML](https://arxiv.org/abs/2406.14144)
### Authors
Jianhui Chen,Xiaozhi Wang,Zijun Yao,Yushi Bai,Lei Hou,Juanzi Li
### Background
大型语言模型（LLMs）在各种能力上表现出色，但在安全方面也存在风险，如生成有害内容和误导信息，即便经过了安全对齐。本研究旨在通过机制性可解释性探索安全对齐的内在机制，重点关注LLMs中负责安全行为的安全神经元的识别与分析。
### Innovation
本文提出了推理时激活对比方法来定位这些神经元，并通过动态激活修补来评估其对模型安全性的因果影响。实验结果表明，可以稳定地识别大约5%的安全神经元，并通过修补它们的激活，可以在多种红队测试基准上恢复超过90%的安全性能，而不影响一般能力。此外，安全神经元的发现有助于解释“对齐税”现象，揭示了模型安全性和有用性关键神经元的高度重叠，但需要不同的激活模式。
### Conclusion
研究结果表明可以通过检测生成前的不安全输出来应用这一发现以保护LLMs。研究成果的代码可以在提供的链接地址下载获得。
## 934. `cs.LG` - 关于核拟合优度检验的稳健性 [PDF](https://arxiv.org/pdf/2408.05854), [HTML](https://arxiv.org/abs/2408.05854)
### Authors
Xing Liu,François-Xavier Briol
### Background
拟合优度检验常因缺乏实际相关性而受到批评：由于“所有模型都不准确”，随着样本量的增加，数据与模型符合的零假设最终总会被拒绝。尽管如此，人们仍然广泛使用概率模型，于是这个问题变得更加重要：该模型是否在执行特定任务时足够好。这个问题可以通过将限制轻微扰动模型的数据生成分布的问题形式化来具体化。现有核拟合优度测试并不具备在两种确认稳健性下的稳健性，而方法细节和核倾斜技术在参数估计文献中有效，但在检验设定下并不足以保证两种稳健性。
### Innovation
本文通过提出首个使用核Stein差异（KSD）球的稳健核拟合优度测试，解决了这一开放问题。这一框架涵盖了诸如Huber污染和密度带模型等诸多知名扰动模型。
### Conclusion
现有的核拟合优度检验在某些常见的稳健性概念下并不稳健，倾斜核的方法在参数估计中是有效的，但在检验设置下并不足以保证两种稳健性。为此，本文提出了首个使用KSD球的方法，该方法能够解决此开放问题，并且该框架包括了多种扰动模型。
## 935. `cs.LG` - ROTI-GCV: 广义交叉验证用于右旋不变数据 [PDF](https://arxiv.org/pdf/2406.11666), [HTML](https://arxiv.org/abs/2406.11666)
### Authors
Kevin Luo,Yufan Li,Pragya Sur
### Background
在高维正则化回归中，两个关键任务是调节正则化强度以实现准确预测，以及估计样本外风险。标准方法K折交叉验证在现代高维设置中是不一致的。虽然在某些高维情况下，留一交叉验证和广义交叉验证仍然是一致的，但在样本相关或包含重尾协变量的情况下，它们变得不一致。为此，本文利用压缩感知中的右旋转不变协变量分布，提出了针对这些挑战条件下的可靠交叉验证框架ROTI-GCV，因此主要背景在于现有交叉验证方法的局限性和对新型框架的需求。
### Innovation
提出了新的右旋转不变协变量分布，并构建了一个新的框架ROTI-GCV，应用于高维设置中，特别处理了样本相关性和重尾协变量的情况。在适度大小的数据集中，提出了新的噪声比率和噪声方差估计器，并通过实验验证了该方法的准确性。
### Conclusion
在渐进比例情形中，即特征数量和样本数量以相似的速度增长，这种情况下更接近于中等规模数据集的实际情况，ROTI-GCV框架被证明能够在有挑战性的情况下可靠地执行交叉验证，同时引入了新的信号噪声比和噪声方差估计器，增强了精度。
## 936. `cs.LG` - 通过几何凸性实现近最优样本复杂度的矩阵和张量正态模型 [PDF](https://arxiv.org/pdf/2110.07583), [HTML](https://arxiv.org/abs/2110.07583)
### Authors
Cole Franks,Rafael Oliveira,Akshay Ramachandran,Michael Walter
### Background
矩阵正态模型是一种常用的多变量矩阵数据建模方法，其协方差矩阵是两个低维因子的克罗内克乘积。张量正态模型则进一步推广了这一模型，使其协方差矩阵通过三个或更多因子的克罗内克乘积来表示。本文主要研究这些模型中协方差矩阵的克罗内克因子的推断问题，特别是最大似然估计（MLE）在Fisher-Rao和Thompson度量下的性能。研究结果表明，对于矩阵和张量正态模型，MLE在非渐进样本复杂性和误差率上几乎是近最优的。并且，本文证明了一种实用且广泛使用的迭代计算MLE的算法—翻转算法在高概率下具有线性收敛性。
### Innovation
主要创新点在于证明了，在足够样本的情况下，负对数似然函数在由Fisher信息度量诱导的正定矩阵几何结构下的强测地凸性。这一强凸性由某些随机量子信道的展开决定。此外，与先前的工作不同，本文的结果不需要假设因子是条件优良的或稀疏的，也不需要假设初始猜测是准确的。所有的误差界限都达到了最小最大最优（除对数因子外），并证明在相同条件下，具备足够样本的情况下，翻转算法可以以高概率线性收敛。
### Conclusion
本文研究了矩阵和张量正态模型中协方差矩阵的克罗内克因子的估计问题，展示了MLE几乎达到最优的非渐近样本复杂性与误差率，并证明了翻转算法在线性收敛方面的可靠性。这些结果对于理解和使用这些模型具有重要意义。
## 937. `cs.LG` - Tex-ViT: 一种泛化性强、鲁棒性的基于纹理的双分支交叉注意力深伪图像检测器 [PDF](https://arxiv.org/pdf/2408.16892), [HTML](https://arxiv.org/abs/2408.16892)
### Authors
Deepak Dagar,Dinesh Kumar Vishwakarma
### Background
生成对抗网络（GAN）驱动的深仿（Deepfakes）生产极其逼真的面部修改，传统卷积神经网络（CNN）能够识别虚假媒体，但在不同数据集上的表现不佳，并且容易受到对抗攻击。视觉变换器在图像分类问题上有潜力，但需要足够的训练数据。
### Innovation
该论文提出了一种Tex-ViT模型，通过将ResNet与视觉变换器结合，增强CNN特征，特别注重改进全局纹理模块以提取特征图之间的相关性。实验表明，Tex-ViT模型在跨领域的泛化性能上优于最先进的模型，准确率达到98%，显示其能够学习伪造样本中的共享区别性纹理特征，并对多种后处理操作具有抵抗力。
### Conclusion
Tex-ViT模型能够应用于各种情况，并且对许多后处理操作具有鲁棒性，证明了其在深仿检测中的泛化能力。
## 938. `cs.LG` - 增强型残差柯尔莫哥洛夫-阿诺尔德网络 [PDF](https://arxiv.org/pdf/2410.05500), [HTML](https://arxiv.org/abs/2410.05500)
### Authors
Ray Congrui Yu,Sherry Wu,Jiang Gui
### Background
尽管深度卷积神经网络（CNNs）在许多任务上表现优异，但由于网络深度较大，导致优化困难且训练成本高昂。传统的卷积操作因其线性特性和固定激活函数，需要许多层才能从数据中学习到有意义的模式。这种方法在计算效率上非常低，特别是在小数据集时容易出现过拟合或梯度爆炸等问题。因此，提出了一个名为残差柯尔莫哥洛夫-阿诺尔德网络（RKAN）的模块，它可以被轻松地添加到传统深度网络的任何层级，通过学习整合支持性的多项式特征转换来增强现有的卷积框架。
### Innovation
提出了一个新的模块——残差柯尔莫哥洛夫-阿诺尔德网络（RKAN），它可以被无缝插入到任何传统深度网络的层级中，并学习整合支持性的多项式特征转换，以增强现有的卷积框架。RKAN在不同的视觉任务和广泛测试的基准上提供了与其他基线模型的一致性改进，实现了最先进的性能。
### Conclusion
即使是在小数据集下，RKAN也能够提高深度学习模型的性能，同时保持计算效率，解决传统CNNs中优化困难和效率低下等问题。
## 939. `cs.LG` - JAMUN:搭建平滑分子动力学与评分学习之间的桥梁以生成构象ensemble [PDF](https://arxiv.org/pdf/2410.14621), [HTML](https://arxiv.org/abs/2410.14621)
### Authors
Ameya Daigavane,Bodhi P. Vani,Darcy Davidson,Saeed Saremi,Joshua Rackers,Joseph Kleinhenz
### Background
蛋白质构象是理解蛋白质功能和新颖药物发现模式（如隐秘口袋）的重要因素。现有的分子动力学（MD）采样技术在计算上效率低下，而许多近期的机器学习方法仅适用于其训练数据范围内的系统。
### Innovation
我们提出了JAMUN，通过利用走跳采样的框架，在所有原子3D构象的平滑、噪声空间中进行分子动力学采样。JAMUN能够以比传统分子动力学快一个数量级的速度生成短肽的构象ensemble，并且其物理先验知识使其能够在未见过的系统中进行传递，即使是对比其训练数据更长的肽也适用。
### Conclusion
我们的模型、代码和权重可以在下面的链接找到：this https URL
## 940. `cs.LG` - 迭代自调优LLM以增强逃狱能力 [PDF](https://arxiv.org/pdf/2410.18469), [HTML](https://arxiv.org/abs/2410.18469)
### Authors
Chung-En Sun,Xiaodong Liu,Weiwei Yang,Tsui-Wei Weng,Hao Cheng,Aidan San,Michel Galley,Jianfeng Gao
### Background
最近的研究表明，大型语言模型（LLMs）容易受到自动逃狱攻击，这种攻击通过算法生成的对抗性附加后缀绕过安全对齐，触发意外响应。当前生成这些附加后缀的方法计算成本高，攻击成功率低，尤其是在对抗像Llama2和Llama3这样的高度对齐的模型。
### Innovation
我们提出了ADV-LLM，这是一种迭代自调优过程，用于制造具有增强逃狱能力的对抗性LLM。该框架显著减少了生成对抗性附加后缀的计算成本，并在各种开源LLM上实现了接近100%的攻击成功率。此外，ADV-LLM在其优化仅限于Llama3的情况下，显示了强大的攻击可转移性，对GPT-3.5实现了99%的攻击成功率，对GPT-4实现了49%的攻击成功率。
### Conclusion
ADV-LLM不仅提高了逃狱能力，还通过生成用于研究LLM安全性的大数据集为未来的安全对齐研究提供了有价值见解。我们的代码可在以下链接获取：this https URL
## 941. `cs.LG` - 基于动态任务严重程度的机器人操作员故障预测框架 [PDF](https://arxiv.org/pdf/2412.00538), [HTML](https://arxiv.org/abs/2412.00538)
### Authors
Ayush Mohanty,Jason Dekarske,Stephen K. Robinson,Sanjay Joshi,Nagi Gebraeel
### Background
机器人操作员在许多应用中至关重要，但随着时间推移会逐渐退化，这种退化受到机器人执行任务性质的影响。严重程度较高的任务，如处理重载荷，会加速退化过程。机器人的末端执行器的位置准确性是这一退化过程的一个表现。现有方法通常忽视了任务严重性的影响，本文提出了一种考虑任务严重性影响的预测模型框架，用于预测机器人操作员的剩余使用寿命(RUL)。
### Innovation
本文创新性地提出了一个考虑任务严重性影响的预测模型框架，用于预测机器人操作员的剩余使用寿命。该模型将机器人位置准确性表示为具有随机漂移参数的布朗运动过程，随机漂移参数受任务严重性影响。任务严重性的动态变化被建模为连续时间马尔可夫链（CTMC）。同时，提出了两种评估剩余寿命的方法：一种是新的闭合形式的剩余寿命分布(RLD)表达式，另一种是常用的蒙特卡洛模拟。理论结果显示这两种方法在计算RUL方面是等效的。
### Conclusion
通过在两种不同的物理仿真的平面机器人队列和空间机器人队列中进行实验验证，研究结果表明，当处理较高比例的高严重性任务时，两者的剩余使用寿命都会缩短。
## 942. `cs.LG` - 高维空间中的多峰张量PCA中随机梯度下降 [PDF](https://arxiv.org/pdf/2410.18162), [HTML](https://arxiv.org/abs/2410.18162)
### Authors
Gérard Ben Arous,Cédric Gerbelot,Vanessa Piccolo
### Background
本文研究了多峰张量模型中在线随机梯度下降（SGD）的高维动态，该模型源于具有多个峰的张量主成分分析（PCA）问题。目标是在N维单位球中估计未知的r个信号向量，通过从噪声观测中进行最大似然估计来实现。研究确定了样本数量和信噪比（SNR）的条件，以便从自然随机初始化有效地恢复未知峰。研究表明，通过数量为N^(p-2)的样本可实现所有峰的完整恢复，这与秩为1的情况下的算法阈值一致。
### Innovation
通过详细的低维系统分析估算器与峰之间的相关性演化，同时控制动态噪声来实现这一目标，发现峰值按顺序逐步恢复。此过程被称作“顺序消除”：一旦某个相关性超过关键阈值，所有具有相同行或列索引的相关性变得足够小，使得下一个相关性能增长并变得宏观。相关性的先后顺序取决于它们的初始值和相应的SNR，从而导致精确恢复或峰的排列恢复。当p=2时，在信号噪声比足够分开的情况下，能实现精确恢复；若SNR相等，只能恢复他们的子空间。
### Conclusion
在多峰张量PCA中，随机梯度下降随着信号噪声比和样本量的关系达到特定条件时，可以有效地恢复所有信号峰。此外，分析了多峰情况下信号峰的恢复顺序及其影响因素，并在特定条件下给出了精确恢复的条件。
## 943. `cs.LG` - 生成模型比较的统计推理 [PDF](https://arxiv.org/pdf/2501.18897), [HTML](https://arxiv.org/abs/2501.18897)
### Authors
Zijun Gao,Yan Sun,Han Su
### Background
生成模型在各种应用中取得了显著的成功，然而其评估仍然缺乏原理性的不确定性量化方法。
### Innovation
本文提出了一种方法，用于比较不同生成模型与测试样本真实分布的接近程度。该方法利用Kullback-Leibler(KL)散度来衡量生成模型与未知测试分布之间的距离，因为它不需要像RKHS基度量中所用的核函数那样的调参，且是唯一具有关键抵消效果的f-散度，这使得不确定性量化成为可能。此外，该方法还扩展到了条件生成模型的比较，并利用Edgeworth展开来处理数据量较少的情况。在已知真实情况的模拟数据集上，该方法实现了有效覆盖率，并表现出比基于核的方法更高的效能。在图像和文本数据集上的生成模型上应用该程序时，所得结论与基准度量一致，但具有统计置信度。
### Conclusion
在已知真实情况的数据集上，验证了该方法的有效覆盖率和相比核基方法更高的效能。该方法在图像和文本数据集上的应用结果与基准度量一致，但具有更高的统计置信度。
## 944. `cs.LG` - 深度连续时间状态空间模型在标记事件序列中的应用 [PDF](https://arxiv.org/pdf/2412.19634), [HTML](https://arxiv.org/abs/2412.19634)
### Authors
Yuxin Chang,Alex Boyd,Cao Xiao,Taha Kass-Hout,Parminder Bhatia,Padhraic Smyth,Andrew Warrington
### Background
标记时间点过程（MTPPs）用于建模不规则时间间隔内发生的事件序列，广泛应用于医疗、金融和社会网络等领域。
### Innovation
提出了一种新型且高效的底层状态空间点过程（S2P2）模型，该模型融合了现代深度状态空间模型的技术，克服了现有MTPP模型的局限性，同时具备其他离散序列模型（如RNNs、transformers）无法捕捉的连续时间事件序列中的强归纳偏置。该模型采用经典线性Hawkes过程的思想，将随机跳跃微分方程与非线性相结合，创建了一种高表达性的强度基MTPP模型，无需对强度进行严格的参数假设。该方法通过并行扫描实现高效训练和推理，保留了MTPPs的表达能力，并且具有线性复杂度和亚线性缩放。
### Conclusion
S2P2在八组真实世界数据集上的预测似然性方面实现了最先进的性能，在最佳现有方法的基础上平均提高了33%。
## 945. `cs.LG` - 在固定维度下使用反向扩散的多项式查询复杂度从多重分布中进行采样 [PDF](https://arxiv.org/pdf/2501.00565), [HTML](https://arxiv.org/abs/2501.00565)
### Authors
Adrien Vacher,Omar Chehab,Anna Korba
### Background
在低维度条件下，从多重分布中进行采样仍然是一个挑战。本文关注的是一个多模态分布的广泛类别，包括所有正态混合分布，并提供了一个在固定维度下具有多项式查询复杂度的采样算法，特别是依赖于多模态参数的复杂度是多项式的假设下.
### Innovation
我们的采样算法模拟了一个时间反向的扩散过程，并使用正则化蒙特卡洛估计器来计算中间状态的分数函数。不同于先前的工作，它避免了不稳定性、不需要先验模式位置的知识，并且打破了当前限制，即放宽了众所周知的对数光滑性假设，使其适用于一般的正态混合分布.
### Conclusion
我们提供了一种采样算法，可以在固定维度下高效地从多重分布中进行采样，适用于包括所有正态混合分布在内的广泛类别，且算法的查询复杂度是多项式的，基于多模态参数.
## 946. `cs.LG` - IRIS: 一种沉浸式机器人交互系统 [PDF](https://arxiv.org/pdf/2502.03297), [HTML](https://arxiv.org/abs/2502.03297)
### Authors
Xinkai Jiang,Qihao Yuan,Enes Ulas Dincer,Hongyi Zhou,Ge Li,Xueyin Li,Xiaogang Jia,Timo Schnizer,Nicolas Schreiber,Weiran Liao,Julius Haag,Kailai Li,Gerhard Neumann,Rudolf Lioutikov
### Background
现有的基于扩展现实（XR）的系统能够高效地收集数据，但往往难以复制和重新利用，因为它们针对特定的机器人、物体、模拟器和环境。这限制了这些系统在不同场景中的应用灵活性和通用性。
### Innovation
IRIS通过支持在多种模拟器和现实世界场景中进行沉浸式交互和数据收集解决了这些问题。它能够可视化任意刚性或弹性物体、从模拟中生成的机器人，并集成实时传感器生成的点云，用于实际应用。此外，IRIS还增强了协作能力，允许多个用户在相同的虚拟场景中同时交互。
### Conclusion
广泛的实验表明，IRIS在模拟和现实世界环境中都提供高效且直观的数据收集能力。
## 947. `cs.LG` - CoCoA Is ADMM: Unifying Two Paradigms in Distributed Optimization [PDF](https://arxiv.org/pdf/2502.00470), [HTML](https://arxiv.org/abs/2502.00470)
### Authors
Runxiong Wu,Dong Liu,Xueqin Wang,Andi Wang
### Background
本文考虑了在分布式环境下解决一般经验风险最小化问题的对偶主算法，并聚焦于两类算法。第一类是高效的分布式对偶坐标上升算法（CoCoA），它从解决对偶问题的坐标上升方法派生而来。第二类是增广拉格朗日乘子法（ADMM），包括共识ADMM、邻近点ADMM和线性化ADMM。研究发现这两类算法都可以转换为只涉及原始变量和对偶变量的统一更新形式，揭示了这两类算法之间的重要联系：CoCoA可以视为一种特定情况的邻近点ADMM，用于解决对偶问题；共识ADMM相当于邻近点ADMM算法的一种。这一发现揭示了如何通过调整增广拉格朗日乘子参数使ADMM变体能够超越CoCoA变体。进一步研究了几种ADMM的线性化版本及其在分布式环境下的性能，并研究了调节参数的影响。广泛的模拟研究和现实世界数据的分析支持了理论发现。
### Innovation
发现CoCoA可以看作是邻近点ADMM的一种特殊情况，共识ADMM与邻近点ADMM等价。进一步研究了几种ADMM变体的线性化版本，并分析了调节参数对其性能的影响。
### Conclusion
CoCoA和ADMM两大类算法在分布式优化中可以统一表示为仅涉及原始和对偶变量的统一更新形式。这一发现表明，通过调整增广拉格朗日乘子参数，ADMM算法的变体可以超越CoCoA算法的变体。线性化ADMM在分布式环境下的表现和调节参数的影响也得到明确分析。支持这些理论发现的广泛模拟研究和实际数据验证了研究结果。
## 948. `cs.LG` - Unity is Power: Semi-Asynchronous Collaborative Training of Large-Scale Models with Structured Pruning in Resource-Limited Clients [PDF](https://arxiv.org/pdf/2410.08457), [HTML](https://arxiv.org/abs/2410.08457)
### Authors
Yan Li,Xiao Zhang,Mingyi Li,Guangwei Xu,Feng Chen,Yuan Yuan,Yifei Zou,Mengying Zhao,Jianbo Lu,Dongxiao Yu
### Background
本文研究了如何利用大规模异构弱计算能力，在分散的数据集上协作训练大规模模型。为提高资源自适应协作学习的效率和准确性，提出了一种新的半异步协作训练框架，称为Co-S2P。该框架结合了数据分布感知的结构化剪枝和跨块知识转移机制，解决了无序剪枝、模型子结构变化、知识损失和节点延迟等问题。
### Innovation
本文提出了一种新的半异步协作训练框架Co-S2P，通过数据分布感知的结构化剪枝和跨块知识转移机制，同时解决了无序剪枝、模型子结构变化、知识损失和节点延迟等问题，并提供了理论证明，表明Co-S2P可以实现渐近最优的收敛速度O(1/√(N^*EQ))。实验结果表明，Co-S2P相较于最先进的方法，可提高多达8.8%的准确性，提高高达1.2倍的资源利用率，并且在所有资源受限的设备上分别减少了约22%的内存消耗和约24%的训练时间。
### Conclusion
本文提出了一种新的半异步协作训练框架Co-S2P，该框架通过数据分布感知的结构化剪枝和跨块知识转移机制有效解决了大规模异构弱计算设备上的协作训练挑战，并显著提高了模型的精度和资源的利用效率。
## 949. `cs.LG` - 量子计算对非线性蒙特卡罗问题的加速 [PDF](https://arxiv.org/pdf/2502.05094), [HTML](https://arxiv.org/abs/2502.05094)
### Authors
Jose Blanchet,Yassine Hamoudi,Mario Szegedy,Guanyang Wang
### Background
随机变量的均值可以被理解为概率分布空间上的线性泛函。量子计算已知能够为均值估计提供经典蒙特卡罗方法的二次速度提升。本文探讨了是否可以为概率分布的非线性泛函估计获得类似二次速度提升。现有算法如An等人（2021）引入的量子多级蒙特卡罗算法已经尝试了这个问题，但本文提出了一个量子内部量子蒙特卡罗算法，该算法可以在较宽的非线性估计问题类中实现这种速度提升，包括嵌套条件期望和随机优化。
### Innovation
本文的关键创新在于设计了一种新的量子多级蒙特卡罗近似序列，专门针对量子计算，这是算法性能改进的核心。
### Conclusion
现有的下界表明，本文的算法在多项对数级因子上是最佳的。该算法改进了现有直接应用的量子多级蒙特卡罗算法，并能为更广泛的非线性估计问题提供二次速度提升。
## 950. `cs.LG` - 样本高效的有理论保证的概念学习：无需干预从数据到概念 [PDF](https://arxiv.org/pdf/2502.06536), [HTML](https://arxiv.org/abs/2502.06536)
### Authors
Hidde Fokkema,Tim van Erven,Sara Magliacane
### Background
机器学习在许多实际系统中至关重要，但人们对黑盒AI系统的可解释性和稳健性仍有诸多担忧。概念瓶颈模型（CBM）通过从高维数据（如图像）中学习可解释的概念来预测标签，从而部分解决了这些挑战。然而，现有的缓解策略存在很强的假设，如假设概念之间统计独立，或者需要大量的干预和注解者的标签以获得准确性。因此，需要一个无需干预即可提供概念学习理论保证的框架。
### Innovation
本文提出一种框架，利用因果表示学习方法从高维度观测中无监督学习潜在因果变量，然后用少量的概念注释将这些变量与可解释的概念对齐。提出了线性和非参数估计器来实现这种映射，对于线性情况提供有限样本的高概率结果，对于非参数估计器提供渐近一致性结果。并在合成和图像基准上进行了评估，表明学习的概念杂质少且通常比其他CBM更准确，即使概念之间存在强相关性也在所不畏。
### Conclusion
该框架能够提供关于学到的概念正确性和所需标签数量的理论保证，无需进行任何干预，为解决概念瓶颈模型中的问题提供了一种新的思路，能够更高效地学习概念。
## 951. `cs.LG` - SMRS：在人工智能时代倡导统一的代理模型报告标准 [PDF](https://arxiv.org/pdf/2502.06753), [HTML](https://arxiv.org/abs/2502.06753)
### Authors
Elizaveta Semenova,Alisa Sheinkman,Timothy James Hitge,Siobhan Mackenzie Hall,Jon Cockayne
### Background
代理模型在科学和工程中被广泛用于近似复杂系统，以减少计算成本。尽管它们被广泛应用，但在建模管道的各个关键阶段（包括数据采样、模型选择、评估和下游分析）缺乏标准化，导致重现性和跨域实用性受限。AI驱动的代理模型的迅速传播进一步加剧了这一挑战。
### Innovation
论文提出了Surrogate Model Reporting Standard (SMRS)，这是一种结构化的报告标准，旨在系统地捕捉代理模型设计和评估中必不可少的选择，同时保持对实现细节的中立。SMRS旨在通过推广一种标准化但灵活的框架来提高代理建模的可靠性、促进跨学科知识转移，并在未来加速科学进步。
### Conclusion
通过建立SMRS，作者希望在AI时代促进代理模型的标准化报告，从而提高代理建模的可靠性，促进跨学科的知识转移，并加速科学进步。
## 952. `cs.LG` - 基于神经网络熵差异估计的互信息估算器 [PDF](https://arxiv.org/pdf/2502.13085), [HTML](https://arxiv.org/abs/2502.13085)
### Authors
Haoran Ni,Martin Lotz
### Background
在高维度下，不依赖特定建模假设来估算互信息（MI），一种衡量随机量之间依赖性的关键指标，是一个极具挑战性的问题。
### Innovation
提出了基于参数化条件密度的归一化流动，这是一种近年来受欢迎的生成模型的方法，通过区块自回归结构实现了在标准基准任务上更好的偏差-方差权衡。
### Conclusion
该估计器通过使用归一化流动参数化条件密度，以及利用区块自回归结构，提供了一种在高维条件下有效估算互信息的新方法，从而改善了偏差-方差的权衡。
## 953. `cs.LG` - Computationally Expensive 模拟器的多级别仿真为基础的推理 [PDF](https://arxiv.org/pdf/2502.08416), [HTML](https://arxiv.org/abs/2502.08416)
### Authors
Anastasia N. Krouglova,Hayden R. Johnson,Basile Confavreux,Michael Deistler,Pedro J. Gonçalves
### Background
在科学的许多领域中，随机模型是理解所观察到的数据背后机制的重要工具。模型可以具有不同的详细程度和准确性，通常更倾向于精确（即高准确度）地研究现象的模拟器。但通过模拟推理推断高精度模型的参数是具有挑战性的，特别是在模拟器计算昂贵的情况下。本文提出了一个名为MF-(TS)NPE的新方法，利用转移学习来利用低价的低精度模拟器以有效推断高精度模拟器的参数，该方法适用于默克和非默克神经后验估计。进一步通过引入A-MF-TSNPE，一种带有目标为密度估计器预测不确定性采样函数的序列性变体，能够自适应地选择高精度参数，以提高模拟效率。
### Innovation
引入了MF-(TS)NPE新方法，该方法利用转移学习来利用低价的低精度模拟器以有效推断高精度模拟器的参数，该方法适用于默克和非默克神经后验估计。进一步通过引入A-MF-TSNPE，一种带有目标为密度估计器预测不确定性采样函数的序列性变体，能够自适应地选择高精度参数，以提高模拟效率。
### Conclusion
我们的方法在基准测试和神经科学任务上，需要相比现有方法高达两个数量级更少的高精度模拟器，并且显示出相似的性能。总的来说，我们的方法为在计算昂贵的模拟器上执行高效贝叶斯推理开辟了新的可能性。
## 954. `cs.LG` - 分布式联邦学习中精确的高斯逼近结果 [PDF](https://arxiv.org/pdf/2505.08125), [HTML](https://arxiv.org/abs/2505.08125)
### Authors
Soham Bonnerjee,Sayar Karmakar,Wei Biao Wu
### Background
联邦学习在隐私敏感的协作环境中得到了广泛应用，局部随机梯度下降（SGD）作为去中心化设置中关键的优化方法受到了重视。尽管已经对局部SGD的收敛性质进行了深入研究，但关于收敛之外的渐近统计保证仍然有限。
### Innovation
本文提出了两种广义高斯近似结果，分别为局部SGD最终迭代的贝里-埃森定理，并引入两种时间统一的高斯逼近以支持整个轨迹的高斯化测试，这些新的统计结果特别适用于检测敌对攻击。
### Conclusion
文章通过大量模拟表明支持其理论结果。
## 955. `cs.LG` - Stop Summation: 最小形式奖励分配是过程奖励模型实现推理所需的一切 [PDF](https://arxiv.org/pdf/2504.15275), [HTML](https://arxiv.org/abs/2504.15275)
### Authors
Jie Cheng,Gang Xiong,Ruixi Qiao,Lijun Li,Chao Guo,Junle Wang,Yisheng Lv,Fei-Yue Wang
### Background
过程奖励模型（PRMs）在大型语言模型（LLMs）的关键推理任务测试时间缩放方面表现出有效性。然而，PRMs中的奖励作弊问题限制了其在强化学习微调中的成功应用。传统的强化学习（RL）中的奖励分配方式定义值为折扣未来奖励的累计值，容易促使LLMs作弊来获取高奖励。
### Innovation
本文提出了PURE：过程监督强化学习，其关键创新是一个最小形式的奖励分配，将价值函数定义为未来奖励的最小值。这种方法通过限制价值函数范围和更合理地分配优势显著减轻了奖励作弊。
### Conclusion
通过在3个基础模型上的广泛实验，我们展示了采用最小形式信用分配的PRM方法在只有30%的步骤内达到了与可验证奖励方法相当的推理性能。当使用10%的可验证奖励补充基于PRM的微调时，训练崩溃得到了缓解，Qwen2.5-Math-7B的微调模型在AMC23上的准确率为82.5%，平均准确率从前5个基准测试中得出。
## 956. `cs.LG` - 基于集成学习的大规模多上下文建筑HVAC控制的机器学习预测控制方法 [PDF](https://arxiv.org/pdf/2505.02439), [HTML](https://arxiv.org/abs/2505.02439)
### Authors
Yang Deng,Yaohui Liu,Rui Liang,Dafang Zhao,Donghua Xie,Ittetsu Taniguchi,Dan Wang
### Background
对于建筑物的热力学模型，这种模型可以预测在潜在的HVAC操作下室内温度的实时变化，对于优化HVAC控制至关重要。尽管开拓性的研究已经尝试为各种建筑环境开发这样的模型，但这些模型通常需要漫长的收集大量数据的时间，并且依赖于专家知识，使得建模过程效率低下，并限制了模型的重用性。基于这些背景，本文探索了一种模型集成的观点，利用现有的基模型服务于目标建筑环境，从而提供准确的预测并减少相关的努力。
### Innovation
本文提出了一种分层强化学习（HRL）方法，以动态选择和加权基模型。该方法采用两层决策过程：高层负责模型选择，低层确定所选模型的权重。通过离线实验和现场案例研究的彻底评估，证实了该方法的有效性.
### Conclusion
本文通过理论分析和实验验证，提出了一种基于集成学习的大规模多上下文建筑HVAC控制的机器学习预测控制方法，实现了模型的有效性验证，并在实验中得到了良好的结果展示。
## 957. `cs.LG` - 随机森林自动编码 [PDF](https://arxiv.org/pdf/2505.21441), [HTML](https://arxiv.org/abs/2505.21441)
### Authors
Binh Duc Vu,Jan Kapar,Marvin Wright,David S. Watson
### Background
该研究基于非参数统计和谱图理论的基础结果，提出了一个原理性的方法来使用随机森林进行自动编码。这种方法旨在在低维空间中学习模型，以最优地表示数据中的关系。
### Innovation
提出了通过约束优化、分裂重标记和最近邻回归解决解码问题的新方法。这些方法有效地逆转了压缩管道，使用森林中单个树学习的划分，从嵌入空间映射回输入空间。该自动编码器在常见的正则性假设下表现出通用一致性。该方法适用于监督或无监督模型，为条件或联合分布的可视化、压缩、聚类和去噪提供了新的工具。
### Conclusion
实验结果表明，该方法在多种设置下都具有简便和实用的优势，适用于表格、图像和基因组数据。
## 958. `cs.LG` - 深学习驱动的电脑电信号分析：推进神经诊断学 [PDF](https://arxiv.org/pdf/2502.17213), [HTML](https://arxiv.org/abs/2502.17213)
### Authors
Jiahe Li,Xin Chen,Fanqi Shen,Junru Chen,Yuxin Liu,Daoze Zhang,Zhizhang Yuan,Fang Zhao,Meng Li,Yang Yang
### Background
神经系统疾病构成重大的全球健康挑战，推动了脑信号分析的进步。头皮脑电图(EEG)和颅内脑电图(iEEG)广泛用于诊断和监测。然而，数据集异质性和任务变化妨碍了稳健的深度学习解决方案的发展。
### Innovation
该文系统地回顾了近年来基于EEG/iEEG的深度学习方法在神经科诊断中的进展，涉及7种神经性疾病和46个数据集，并重点审查代表性方法与定量结果。它强调了多任务预训练模型的作用，以实现可扩展和普适的解决方案。
### Conclusion
文章提出一个标准化基准来评估模型在不同数据集中的表现并提高可重复性，强调最近的创新如何推动神经科诊断向智能化、可适应的医疗系统发展。
## 959. `cs.LG` - 更快地转移，更智能的价格设定：跨市场偏好转移下的最小最大动态价格策略 [PDF](https://arxiv.org/pdf/2505.17203), [HTML](https://arxiv.org/abs/2505.17203)
### Authors
Yi Zhang,Elynn Chen,Yujun Yan
### Background
本文研究市场需求变化时，利用K个辅助市场（包括离线日志或并发流）信息进行价格调整的动态定价问题。这些辅助市场的平均效用存在结构性的偏好偏移。文章基于这一背景，探讨如何在考虑偏好偏移的情况下进行有效的价格动态调整，尤其是对于不同维度的线性和非参数效用模型。
### Innovation
本文提出了一种名为Cross-Market Transfer Dynamic Pricing (CM-TDP)的新算法，该算法首次能够在存在模型偏移的情况下进行动态价格调整，并能够以最小最大化遗憾值提供最优的线性和非参数效用模型的动态定价策略。对于线性效用模型，算法复杂度为$tilde{O}((d*K^{-1}+s_{0})text{log } T)$。对于非线性需求模型，复杂度达到了信息论下界的新高度，显示了该方法的独特性。并且，实验证明了CM-TDP相比单一市场定价策略具有显著的优势，能够实现累计遗憾值的50%减少和学习速度的5倍提升。这通过整合迁移学习、稳健聚合和收益优化，实现了更智能和更快的价格策略设定。
### Conclusion
本文提出的方法CM-TDP在面对跨市场偏好偏移时表现出色，无论是在线性模型还是非线性模型中都能提供理论上最优的动态定价策略。此外，该方法还展示了比传统单一市场定价策略更高的效率。未来的研究可以进一步探索如何利用更多的辅助市场信息进行更好的价格策略调整。
## 960. `cs.LG` - Roboflow100-VL：专门为视觉-语言模型设计的多领域目标检测基准 [PDF](https://arxiv.org/pdf/2505.20612), [HTML](https://arxiv.org/abs/2505.20612)
### Authors
Peter Robicheaux,Matvei Popov,Anish Madan,Isaac Robinson,Joseph Nelson,Deva Ramanan,Neehar Peri
### Background
视觉-语言模型(VLMs)在互联网规模的数据上训练后，展示了对常见物体（如汽车、卡车和行人的零样本检测性能）。然而，当前最先进的模型在处理未见类别、任务和成像模态时仍存在问题，这些情况在它们的预训练中并不存在。本文讨论了通过重新训练VLMs或简单地提供更多视觉数据可能无法有效解决这些问题，提出了另一种方法，即将VLMs与包含少量视觉示例和丰富文本描述的注释指令进行对齐。
### Innovation
本文提出了Roboflow100-VL，这是一个大规模的多模态对象检测数据集集合，包含在标准预训练中不常见的多种概念。研究显示VLMs在挑战性的医学影像数据集上的零样本准确性低于2%，这强调了对概念进行少样本对齐的需求。此外，通过该数据集评估了状态最领先模型在零样本、少样本、半监督和完全监督设置下的表现。
### Conclusion
文章通过讨论CVPR 2025 FindSod（Foundational Few-Object Detection）竞赛的结果，展示了社区对此领域的最新见解。竞赛中获胜团队的表现超越了基准线17 mAP。相关代码和数据集可在给定的链接中获取。
## 961. `cs.LG` - 基于分解的稳健训练的物理启发式神经网络方法用于近不可压缩线性弹性问题 [PDF](https://arxiv.org/pdf/2505.21994), [HTML](https://arxiv.org/abs/2505.21994)
### Authors
Josef Dick,Seungchan Ko,Quoc Thong Le Gia,Kassem Mustapha,Sanghyeon Park
### Background
当Lamé系数λ趋向无穷大或泊松比ν趋向1/2时，低阶一致性有限元方法在近不可压缩弹性方程中的准确性会下降，这种现象称为锁存或非鲁棒性。尽管已经进行了大量研究，但这种现象尚未完全理解。物理启发式神经网络（PINNs）在处理这类问题时也会遇到类似的问题，导致准确性和收敛性问题。
### Innovation
本文提出了一种基于分解的稳健PINN框架，通过将弹性方程分解为平衡子系统来消除导致锁存的病态条件，从而同时解决正向和逆向问题，恢复分段的场变量及其相关外部条件，并进行了收敛性分析以增强方法的可靠性。
### Conclusion
通过各种数值实验，本文表明提出的基于分解的方法在不同条件下（常数、变量和参数Lamé系数）的效率。
## 962. `cs.LG` - 词语嵌入中线性类比结构的起源 [PDF](https://arxiv.org/pdf/2505.18651), [HTML](https://arxiv.org/abs/2505.18651)
### Authors
Daniel J. Korchinski,Dhruva Karkada,Yasaman Bahri,Matthieu Wyart
### Background
Word2Vec和GloVe等模型基于词语在文本语料库中的共现概率$P(i,j)$构建词嵌入，生成的向量$W_i$不仅将语义相似的词语分组，还展现出一种显著的线性类比结构，例如$W_{text{king}} - W_{text{man}} + W_{text{woman}} rightarrow W_{text{queen}}$等。这种结构的理论基础尚不清楚。先前的研究观察到这种类比结构：(i) 在矩阵$M(i,j) = P(i,j)/P(i)P(j)$的前几个特征向量中已经出现；(ii) 随着特征向量数量的增加而增强并饱和，$M(i,j)$控制着嵌入的维度；(iii) 使用$text{log} M(i,j)$而不是$M(i,j)$可以使结构得到增强；(iv) 即使移除特定类比关系（如king-queen，man-woman）的所有词对时依然存在。
### Innovation
作者引入了一个通过二元语义属性来定义词语并根据基于属性的相互作用推导共现概率的理论生成模型。这个模型能够从理论上重现线性类比结构的出现，并自然解释上述属性(i)-(iv)，提供对每个额外嵌入维度作用的详细解析，并表现出对各种噪声形式的鲁棒性，同时很好地符合维基百科和米科洛夫等人引入的类比基准中的共现统计.
### Conclusion
该模型不仅解析了嵌入维度对类比结构形成的影响，还证明了这些现象的理论基础，并且对于噪声的鲁棒性更强，为理解词嵌入中固有的线性关系提供了一种新的见解。
## 963. `cs.LG` - OpenMIBOOD: Open Medical Imaging Benchmarks for Out-Of-Distribution Detection [PDF](https://arxiv.org/pdf/2503.16247), [HTML](https://arxiv.org/abs/2503.16247)
### Authors
Max Gutbrod,David Rauber,Danilo Weber Nunes,Christoph Palm
### Background
随着人工智能（AI）在医疗健康等关键领域中的应用日益增长，确保这些系统的可信度变得越来越重要，尤其是在遭遇意外或异常输入时。当前，可用于医疗成像领域出分布检测（OOD）方法评估的基准数据集相对缺乏，这导致难以标准化和公平地比较这些检测方法的表现。现有大尺度自然图像领域的OOD基准中，有不少发现无法直接应用于医疗场景，进一步凸显了医疗领域的特别需求。因此，需要构建一个专门针对医疗成像的全面框架，来评估出分布检测方法。
### Innovation
本文介绍了《Open Medical Imaging Benchmarks for Out-Of-Distribution Detection（OpenMIBOOD）》：提供了一个全面的框架，专门用于评估医疗成像领域中的出分布检测方法。OpenMIBOOD 包含来自不同医学领域的三个基准，涵盖了14个数据集，并且将这些数据集分为协变量偏移的在分布、接近出分布和远出分布三种类别。研究团队评估了24种后处理方法，提供了标准的参考，促进了这些检测方法的发展与公平比较。结果表明，大尺度自然图像领域的ODD基准结果不适用于医疗应用，因此强调了医疗领域中开发专门基准的必要性。这是一个旨在支持医疗领域内可靠、信赖的AI系统发展的重大创新。
### Conclusion
OpenMIBOOD 的发布旨在减轻AI模型对未训练分布输入的风险，推动医疗健康领域中更可靠和值得信赖的人工智能系统的进步。研究结果显示，大尺度自然图像领域的ODD基准结果不适用于医疗应用，特地开发的基准是至关重要的。
## 964. `cs.LG` - 学会的教训：一种关于代码LLM的学习和改进的多智能体框架 [PDF](https://arxiv.org/pdf/2505.23946), [HTML](https://arxiv.org/abs/2505.23946)
### Authors
Yuanzhe Liu,Ryan Deng,Tim Kaler,Xuhao Chen,Charles E. Leiserson,Yao Ma,Jie Chen
### Background
最近的研究表明，大语言模型（LLM）具有不同的技能，擅长不同的任务。具体而言，它们在多个粒度级别上表现出不同的性能，例如，在代码优化任务中，代码LLM在不同的优化类别表现出色，没有一个LLM能胜过其他模型。
### Innovation
提出了一种基于教训的协作框架，设计了教训的提出——存储——选择机制，表明一个小的LLM团队，通过学习其他LLM的成功和失败，可以从中学到知识并在集体解决问题的过程中提高性能，并能超越一个更大的LLM和其它多LLM协作方式。
### Conclusion
这种基于教训的协作框架可以促进多智能体团队在解决编码问题时更好地利用各自的专长，从而提高整体性能。
## 965. `cs.LG` - 定量LLM裁判 [PDF](https://arxiv.org/pdf/2506.02945), [HTML](https://arxiv.org/abs/2506.02945)
### Authors
Aishwarya Sahoo,Jeevana Kruthi Karnuthala,Tushar Parmanand Budhwani,Pranchal Agarwal,Sankaran Vaidyanathan,Alexa Siu,Franck Dernoncourt,Jennifer Healey,Nedim Lipka,Ryan Rossi,Uttaran Bhattacharya,Branislav Kveton
### Background
语言模型（LLM）在生成定性文本评估方面表现出色，但在预测人类偏好和量化分数方面经常遇到困难。因此，本文提出了一种新的框架，通过回归模型将现有的LLM裁判评分与特定领域的人类评分对齐，旨在提高评分的准确性。
### Innovation
作者提出了一种新的框架，即定量LLM裁判，利用回归模型对不同类型的绝对和相对反馈进行评分，使得LLM能够更好地预测人类评分。该框架在计算效率上优于监督微调，并在人类反馈有限时具有更高的统计效率。
### Conclusion
通过实验证明，定量LLM裁判可以通过事后建模提高现有裁判的预测能力。该框架在四个数据集上进行了验证，并使用两种基础裁判进行了实验，结果显示定量裁判的引入确实提高了评分的预测准确性。
## 966. `cs.LG` - MIR-Bench: 能否通过少量多次上下文推理识别复杂模式？ [PDF](https://arxiv.org/pdf/2502.09933), [HTML](https://arxiv.org/abs/2502.09933)
### Authors
Kai Yan,Zhan Ling,Kang Liu,Yifan Yang,Ting-Han Fan,Lingfeng Shen,Zhengyin Du,Jiecao Chen
### Background
模式识别和应用是通用智能的关键能力，受到心理学和人工智能研究者的广泛研究。大型语言模型（LLMs）的多种基准测验主要关注小量提示（通常少于10个），忽略了从大量背景信息中聚合信息的能力。另一方面，LLMs的上下文长度不断增加，推动了新型的多量上下文推理（Many-Shot In-Context Learning, ICL）范式，该范式通过数百到数千个示例解决新任务，无需昂贵且低效的微调。然而，多量上下文推理通常仅关注分类任务，而流行的长期上下文LLM任务（如Needle-In-A-Haystack, NIAH）很少需要整合大量信息的复杂智能。
### Innovation
提出了MIR-Bench，这是第一个用于模式识别的多量上下文推理基准，要求LLMs通过底层函数的不同数据格式输入输出示例来进行预测。基于MIR-Bench，研究了多种新的多量上下文推理问题，并发现了诸多有洞察力的发现，包括扩展效应、稳健性、归纳推理与演绎推理、检索增强生成（RAG）、为归纳推理编码、跨领域泛化能力等。
### Conclusion
MIR-Bench填补了小量提示基准和多量上下文推理之间的空白，在长上下文中测试了LLM对复杂模式的识别能力，揭示了多种新的研究问题和发现。
## 967. `cs.LG` - Sherlock: 自视觉语言模型中的自我纠正推理 [PDF](https://arxiv.org/pdf/2505.22651), [HTML](https://arxiv.org/abs/2505.22651)
### Authors
Yi Ding,Ruqi Zhang
### Background
视觉语言模型(VLMs)在复杂多模态任务中表现出色，但仍然面临重大挑战，包括高敏感性的推理错误、需要大量标注数据或准确的验证器，以及难以跨域泛化。这些模型需要改进以提高其推理能力并减少错误。因此，研究者们探索了自我纠正作为增强推理VLMs策略的可能性，通过分析现有的自我纠正能力，发现关键差距，并引入了Sherlock框架，该框架包含轨迹级自我纠正目标、基于视觉扰动的偏好数据构造方法和动态β值进行偏好调整，从而在少量标注数据下增强模型的自我纠正和自我改进能力，最终在多个基准测试中取得了优异成绩，精度分别为64.1和65.4，超越了其他模型如LLaVA-CoT、Mulberry和LlamaV-o1。
### Innovation
Sherlock框架引入了轨迹级自我纠正目标、基于视觉扰动的偏好数据构造方法和动态β值进行偏好调整，使模型能够在少量标注数据下获得自我纠正能力，并持续自我改进。该框架在Llama3.2-Vision-11B模型上训练，展现出强大的自我纠正能力和泛化能力，在八个基准测试中表现出色，显著超越了同类的其他模型。
### Conclusion
Sherlock框架在视觉语言模型中引入自我纠正和自我改进机制，使得模型能够在有限数据下有效增强推理能力，达到更好的泛化效果，是该领域的一个重要创新贡献。
## 968. `cs.LG` - 代理目标：弥合离散脉冲神经网络与连续控制之间的差距 [PDF](https://arxiv.org/pdf/2505.24161), [HTML](https://arxiv.org/abs/2505.24161)
### Authors
Zijie Xu,Tong Bu,Zecheng Hao,Jianhao Ding,Zhaofei Yu
### Background
脉冲神经网络（SNNs）在神经形态硬件上具有低延迟和高能效的优势，使其成为资源受限边缘设备中强化学习（RL）的理想选择。然而，大多数用于连续控制的RL算法是为人工神经网络（ANNs）设计的，特别是目标网络软更新机制，这与脉冲神经元的离散和非可微特性产生冲突，导致SNN训练不稳定和性能下降。
### Innovation
提出了一个新的代理目标框架，该框架通过引入连续和可微的动态机制，使目标更新变得平滑，从而稳定学习过程。代理网络仅在训练期间运行，因此部署的SNN在没有额外推理开销的情况下保持完全能源效率。大量的连续控制基准测试表明，与不同脉冲神经元模型相比，该框架可以持续提高稳定性，并在某些情况下提高高达32%的性能。值得注意的是，到目前为止，这是第一个使使用简单泄漏积分和放电（LIF）神经元的SNN超过其ANN对手的方法。
### Conclusion
这项工作强调了SNN定制的RL算法的重要性，并为具有高性能和低功耗的神经形态代理铺平了道路。
## 969. `cs.LG` - MVP-Shapley: 基于特征建模评估篮球最有价值球员 [PDF](https://arxiv.org/pdf/2506.04602), [HTML](https://arxiv.org/abs/2506.04602)
### Authors
Haifeng Sun,Yu Xiong,Runze Wu,Kai Wang,Lan Zhang,Changjie Fan,Shaojie Tang,Xiang-Yang Li
### Background
随着电子竞技和多人在线游戏社区的蓬勃发展，评估最有价值球员（MVP）变得尤为重要。建立一个可解释且实用的MVP评估方法极具挑战性。本文专注于比赛中的逐帧数据，这些数据记录了比赛中的相关事件，如助攻和得分。为了应对这一挑战，本文提出了一种新的MVP评估框架（textbackslashoursys，即MVP-Shapley），该框架利用了Shapley值，涵盖了特征处理、胜败模型训练、Shapley值分配以及基于球员贡献的MVP排名确定。进一步优化算法以因果视角与专家投票结果相匹配。
### Innovation
本文提出了一种基于Shapley值的新MVP评估框架，称为MVP-Shapley。该方法通过逐帧数据记录比赛中的关键事件，结合特征处理、模型训练、Shapley值分配及基于贡献的MVP排名确定。算法进一步优化以因果视角与专家投票结果匹配，通过NBA数据集和Dunk City Dynasty数据集验证了其有效性，最终实现工业应用部署。
### Conclusion
本文展示了MVP-Shapley方法的有效性和实用性，通过理论分析和实验证明了该方法在MVP评估中的潜力，并实现了部分工业部署，为进一步优化和完善MVP评估方法奠定了基础。
## 970. `cs.LG` - BioCLIP 2: 层次对比学习中的涌现特性 [PDF](https://arxiv.org/pdf/2505.23883), [HTML](https://arxiv.org/abs/2505.23883)
### Authors
Jianyang Gu,Samuel Stevens,Elizabeth G Campolongo,Matthew J Thompson,Net Zhang,Jiaman Wu,Andrei Kopanev,Zheda Mai,Alexander E. White,James Balhoff,Wasila Dahdul,Daniel Rubenstein,Hilmar Lapp,Tanya Berger-Wolf,Wei-Lun Chao,Yu Su
### Background
大规模训练的基础模型展现出惊人的涌现行为，能够学习超出初始训练目标的新能力。本文通过大规模对比视觉-语言训练，在生物视觉模型中发现了这种涌现行为。为实现这一目标，研究人员首先创建了包含2.14亿张生物图像的TreeOfLife-200M数据集，这是迄今为止最大的和最多样化的生物有机体图像数据集。随后使用TreeOfLife-200M数据集训练了BioCLIP 2模型，以区分不同种类。尽管训练目标较为狭窄，但BioCLIP 2在各种生物视觉任务上表现卓越，如栖息地分类和特征预测。研究还发现，在训练过程中获得了BioCLIP 2学习嵌入空间中的新特性。不同物种的嵌入分布与功能和生态意义紧密相关（例如嘴的大小和栖息地）。在同物种内部，虽然物种间的差异被强调，但物种内的差异（例如生命周期阶段和性别）在与物种间差异正交的空间中得到了更明显的区分和保持。
### Innovation
本文通过大规模对比视觉-语言训练的方法，发现并验证了BioCLIP 2模型的新型生物视觉能力，表明这种基于策略的训练方法可以产生出非预期的新能力。同时，研究还提供了形式上的证明和分析，解释了为何层次监督和对比目标可以激励这些涌现特性的发展，尤其在大量数据训练的背景下显得尤为重要。这表明随着训练数据规模的增加，开发出的嵌入空间具有更生物意义，证明了训练数据规模对模型能力提升的显著影响。
### Conclusion
研究结果表明，在大规模数据训练下，模型的嵌入空间越来越具有生物学意义，这正式解释了为何层次监督和对比目标可以促进这些涌现特性的产生。并且，这种效果随着训练数据规模的增加而变得更加明显。
## 971. `cs.LG` - Prover Agent: 基于代理的正式数学证明框架 [PDF](https://arxiv.org/pdf/2506.19923), [HTML](https://arxiv.org/abs/2506.19923)
### Authors
Kaito Baba,Chaoran Liu,Shuhei Kurita,Akiyoshi Sannai
### Background
本文介绍了一种名为Prover Agent的新型AI代理，用于自动定理证明。Prover Agent结合了大型语言模型（LLMs）和形式证明辅助程序Lean。背景信息还指出，Prover Agent能够在MiniF2F基准测试中取得88.1%的成功率，比之前使用小型语言模型（SLMs）的方法有更少的样本预算，并且达到了新的技术前沿。
### Innovation
该研究提出了一种将大型语言模型与形式证明辅助程序结合的创新性代理框架——Prover Agent。它不仅能够生成辅助定理，还可以利用这些辅助定理发现有效的证明策略。此外，Prover Agent在很少的样本预算下，实现了与现有的小型语言模型相比更加优秀的表现。
### Conclusion
该研究通过理论分析和案例研究展示了生成的辅助定理如何帮助解决复杂的证明问题。研究的代码已经公开发布。Prover Agent在Magic Squares和Heine-Borel定理的证明中展现了其有效性。
## 972. `cs.LG` - 从树集合中提取可解释模型：计算与统计视角 [PDF](https://arxiv.org/pdf/2506.20114), [HTML](https://arxiv.org/abs/2506.20114)
### Authors
Brian Liu,Rahul Mazumder,Peter Radchenko
### Background
树集合是非参数方法，因其高准确性和复杂交互捕捉能力而广为人知。尽管这些模型在预测方面表现出色，但它们难以解释，并且可能无法揭示数据中的有用关系。
### Innovation
提出了一个提取树集合中紧凑决策规则的估计器。该估计器的一个关键新颖之处在于能够同时控制提取规则的数量和每个规则的交互深度，从而提高准确性。开发了针对优化问题的定制精确算法，以及用于计算正则化路径（即模型大小变化时的解决方案序列）的近似算法，并建立了针对所提方法的新非渐近预测误差界，与受同样复杂性约束的最佳数据依赖线性组合的最佳数据进行了比较。
### Conclusion
通过实验表明，该估计器在规则提取方面优于现有算法。所提估计器的大样本预测性能与参考解决方案相当。
## 973. `cs.LG` - 分布对抗攻击与深度对冲的训练 [PDF](https://arxiv.org/pdf/2508.14757), [HTML](https://arxiv.org/abs/2508.14757)
### Authors
Guangyi He,Tobias Sutter,Lukas Gonon
### Background
本文研究了在分布变化情况下经典深度对冲策略的鲁棒性，并利用对抗攻击的概念进行分析。研究表明，标准的深度对冲模型对输入分布的微小扰动非常敏感，导致性能大幅下降。
### Innovation
本文提出了一种针对分布变化进行增强的对抗训练框架，通过将点攻击扩展到分布式设置，并采用Wasserstein球上的可计算重构的对抗优化问题，使得能够高效训练对分布扰动具有鲁棒性的对冲策略。大量实证实验表明，对抗训练的深度对冲策略在离样本外性能和对模型错误指定的抵抗性方面均优于经典方法。
### Conclusion
研究结果确立了一种在现实市场不确定性条件下实际且有效的深度对冲鲁棒性框架。
## 974. `cs.LG` - ixi-GEN：通过领域适应连续预训练实现高效的工业级sLLMs [PDF](https://arxiv.org/pdf/2507.06795), [HTML](https://arxiv.org/abs/2507.06795)
### Authors
Seonwu Kim,Yohan Na,Kihun Kim,Hanhee Cho,Geun Lim,Mintae Kim,Seongik Park,Ki Hyun Kim,Youngsub Han,Byoung-Ki Jeon
### Background
开源的大语言模型（LLMs）为企业的应用提供了更多机会，但许多组织缺乏部署和维护大规模模型所需的基础设施。因此，尽管小型语言模型（sLLMs）在性能上存在局限性，它们仍成为一种实用的选择。尽管已经研究了领域适应性连续预训练（DACP），但其在商业环境中的实用性仍需验证。
### Innovation
研究验证了DACP方法的有效性，跨越了不同的基础模型和服务领域，设计了DACP应用的小型语言模型（ixi-GEN），并通过广泛的实验和实际评估，证明了ixi-GEN模型在目标领域中取得了显著的性能提升，同时保留了通用能力，提供了一种成本效益高且可扩展的企业级部署解决方案。
### Conclusion
ixi-GEN模型能够在保持通用能力的同时，在目标领域中取得显著的性能提升，为商业应用提供了一种高效的低成本解决方案。
## 975. `cs.LG` - Transformer在非稳态强化学习中实现最优动态遗憾 [PDF](https://arxiv.org/pdf/2508.16027), [HTML](https://arxiv.org/abs/2508.16027)
### Authors
Baiyuan Chen,Shinji Ito,Masaaki Imaizumi
### Background
transformers在多个领域中表现出了卓越的能力，而且已有理论和实验证实它们有能力进行上下文中的强化学习。然而，在非稳态环境中的表现尚不明确。
### Innovation
本文通过实验证明，transformers在非稳态设置中能够实现几乎最优的动态遗憾边界的指标。进一步证明了transformers能够近似处理非稳态环境的策略，并在上下文学习设置中学习这些近似策略。
### Conclusion
实验表明，transformers能够在非稳态环境中与甚至超越现有专家算法的表现。
## 976. `cs.LG` - AICO: 监督学习中的特征显著性检验 [PDF](https://arxiv.org/pdf/2506.23396), [HTML](https://arxiv.org/abs/2506.23396)
### Authors
Kay Giesecke,Enguerrand Horel,Chartsiri Jirachotkulthorn
### Background
机器学习已成为科学、工业和政策领域中的关键工具，算法可用于识别化学性质、预测疾病风险、评估借款人信用以及指导公共干预措施。然而，这种预测能力往往是以透明度为代价的，我们通常不清楚哪些输入特征真正驱动模型的预测。缺乏这种理解，研究人员无法得出可靠的科学结论，从业者无法确保公平和问责，政策制定者无法信任或管理基于模型的决策。尽管重要，现有的功能影响评估工具仍有限制——大多数没有统计保证，并且许多需要昂贵的重新训练或替代建模，使其对大规模现代模型来说不切实际。
### Innovation
我们提出了AICO，一种广泛适用的框架，将模型可解释性转化为高效的统计实验。AICO通过屏蔽特征的信息并测量导致的性能变化，来判断任何训练好的回归或分类模型的每个特征是否真正提升了模型性能。该方法可以提供精确、有限样本的推理，即精确的功能p值和可信区间，无需重新训练、替代建模或分布假设，使其适用于现代的大规模算法。AICO在控制实验和实际应用中（从信用评分到抵押行为预测）都能一致地指出推动模型行为的变量，为透明及可信赖的机器学习提供快速可靠的道路。
### Conclusion
AICO为监督学习中的特征选择提供了一种快速且可靠的方法，使得研究人员、从业者和政策制定者能够信任和治理基于模型的决策。
## 977. `cs.LG` - 共生：多适配器推理和微调 [PDF](https://arxiv.org/pdf/2507.03220), [HTML](https://arxiv.org/abs/2507.03220)
### Authors
Saransh Gupta,Umesh Deshpande,Travis Janssen,Swami Sundararaman
### Background
参数效率微调（PEFT）允许模型构建者将任务特定参数捕获到适配器中，适配器的大小仅为原始基础模型的一小部分。PEFT技术的流行促使为流行的大型语言模型（LLMs）创建了大量的适配器。然而，现有的框架在以下几个方面支持使用多个适配器的推理或微调时存在不足：1）针对微调，每个任务都需要部署其专用的基础模型实例，导致GPU内存消耗过多和GPU利用率低下；2）虽然流行的推理平台可以为多个PEFT适配器服务，但不支持独立资源管理或混合不同PEFT方法；3）无法有效利用异构加速器；4）不为不愿意暴露微调参数给服务提供商的用户提供隐私保护。
### Innovation
Symbiosis通过使基础模型作为服务部署来解决上述问题。基础模型层可以在多个推理或微调过程中共享。我们的分拆执行技术将客户端特定适配器和层的执行与冻结的基础模型层解耦，从而为用户提供灵活的资源管理能力、选择其微调方法、实现其性能目标的灵活性。我们的方法对模型是透明的，可以开箱即用地应用于大多数transformers库中的模型。研究展示了通过Symbiosis同时在8个GPU上微调20个Gemma2-27B适配器的应用场景。
### Conclusion
Symbiosis方法不仅解决了多适配器推理和微调过程中的资源管理和隐私问题，还提升了灵活性和性能，使其成为处理大型语言模型适配器的一种有效方案。
## 978. `cs.LG` - SafeDiver: 多智能体强化学习辅助自主水下机器人-水面无人船协作潜水员通信 [PDF](https://arxiv.org/pdf/2509.11508), [HTML](https://arxiv.org/abs/2509.11508)
### Authors
Tinglong Deng,Hang Tao,Xinxiang Wang,Yinyan Wang,Hanjiang Luo
### Background
随着海洋活动中的人类活动增加，对水下通信服务的需求也随之增大。现有的水下潜水员通信方法因自身局限性和复杂的水下环境而受阻。
### Innovation
本文提出了一种利用海上无人系统辅助潜水员进行可靠和高速通信的方案。通过装备有多模式通信设备（如光学和声学设备）的多个AUV，并使用多智能体强化学习(MARL)策略控制AUVs的协同移动，实现了潜水器之间的高速可靠数据传输。同时，通过水面无人船只（USVs）作为中继节点进行信息协调和转发，以及让AUVs适应性选择中继USV节点，实现了潜水员与水面平台之间高质量通信。
### Conclusion
通过仿真验证，所提出的方法能够有效实现潜水员的可靠和高速通信。
## 979. `cs.LG` - 平均报酬稳健马尔可夫决策过程的贝尔曼最优性 [PDF](https://arxiv.org/pdf/2509.14203), [HTML](https://arxiv.org/abs/2509.14203)
### Authors
Shengbo Wang,Nian Si
### Background
学习与控制在稳健马尔可夫决策过程（MDPs）下的研究引起了越来越多的关注，但现有的大部分理论、算法和应用主要集中在有限时限或折扣模型上。长期平均报酬模型虽然在许多运筹学和管理背景中自然适用，但仍然被探索不足。这是因为动态规划的基础技术性很强，尚未完全理解，仍然有许多基础问题未解决。
### Innovation
本文通过分析常增益环境下的平均报酬稳健MDP，提供了一个更一般性的框架。研究了控制器与S-矩形对手之间可能存在信息不对称情况下的平均报酬稳健控制问题。中心研究稳健贝尔曼方程的常增益版本，探讨了其解的存在性及其与最优平均报酬的关系。明确了哪些情况下，稳健贝尔曼方程的解表征最优平均报酬和稳态策略，并提供了一边弱通信条件以确保解的存在性。这些发现扩展了平均报酬稳健MDP的动态规划理论，为运营环境中面向长期平均标准的稳健动态决策奠定了基础。
### Conclusion
研究结果进一步完善了平均报酬稳健MDP的动态规划理论，为在操作环境中进行稳健动态决策提供了一种机制，尤其是适用于长期平均标准的问题。
## 980. `cs.LG` - WolBanking77: Wolof Banking Speech Intent Classification Dataset [PDF](https://arxiv.org/pdf/2509.19271), [HTML](https://arxiv.org/abs/2509.19271)
### Authors
Abdou Karim Kandji,Frédéric Precioso,Cheikh Ba,Samba Ndiaye,Augustin Ndione
### Background
近期，意图分类模型取得了显著进步，但大多数研究集中在资源丰富的语言数据集上，导致低资源语言和高文盲率地区的研究缺口，这些地区更多地使用口语而非阅读或书写语言。例如，在塞内加尔，尽管42%的人口是文盲，但 Wolof 言语仍然被90%的人口使用。Wolof在西非地区有超过1000万使用者。针对这一局限，本文提出了Wolof Banking Speech Intent Classification Dataset (WolBanking77)数据集，旨在促进相关领域的学术研究。
### Innovation
论文提出了一种具有9,791个文本句子和超过4小时音频的WolBanking77数据集，旨在填补Wolof等低资源语言的语义意图分类数据缺口。同时，实验使用了最先进的文本和语音模型，并展示了初步的良好结果。此外，文章还深入分析了数据集内容，对比了不同模型的基线F1分数和词错误率，并提供了模型间的比较结果。
### Conclusion
WolBanking77数据集为学术研究提供了宝贵的资源，有助于改善低资源语言和高文盲率地区意图分类模型的性能。未来工作将进一步优化模型效果并扩展数据集规模。
## 981. `cs.LG` - 受过训练的单层神经网络向高斯过程的定量收敛 [PDF](https://arxiv.org/pdf/2509.24544), [HTML](https://arxiv.org/abs/2509.24544)
### Authors
Eloy Mosig,Andrea Agazzi,Dario Trevisan
### Background
以往的研究已经证明了在广泛条件下的定性的浅神经网络训练和高斯过程之间的收敛性，但在有限宽度下的精确、有限宽度估计仍然有限，尤其是在训练过程中。本文旨在通过提供网络输出和其高斯逼近之间的二次 Wasserstein 距离的明确上限来量化这种收敛性，展示出随着网络宽度增加呈polynomial衰减的趋势。
### Innovation
本文提供了网络输出和其高斯逼近之间的二次 Wasserstein 距离在任何训练时间 $t eq 0$ 的明确上限，证明了宽度呈polynomial衰减的趋势，量化了架构参数（如宽度和输入维度）如何影响收敛，以及训练动态如何影响逼近误差。
### Conclusion
本文的结果量化了单层神经网络的架构参数如何影响收敛，以及训练动态如何影响逼近误差，填补了这一领域中关于有限宽度模型精确性估计的空白，并为理解和改进深度学习中的神经网络训练提供了新的视角。
## 982. `cs.LG` - RADAR: 一种基于角色专业化协作的风险意识动态多代理框架用于大型语言模型的安全评价 [PDF](https://arxiv.org/pdf/2509.25271), [HTML](https://arxiv.org/abs/2509.25271)
### Authors
Xiuyuan Chen,Jian Zhao,Yuchen Yuan,Tianle Zhang,Huilin Zhou,Zheng Zhu,Ping Hu,Linghe Kong,Chi Zhang,Weiran Huang,Xuelong Li
### Background
现有的大型语言模型（LLMs）的安全评估方法存在固有的局限性，包括评估者的偏见以及由于模型同质性导致的检测失败，这共同影响了风险评估过程的稳健性。
### Innovation
引入了一个理论框架，重建了潜在风险概念空间，将潜在风险空间分为三个互斥子空间：明确的风险子空间（涵盖直接违反安全准则的行为），隐含的风险子空间（捕捉需上下文推理才能识别的潜在恶意内容），以及无风险子空间。此外，提出了一种名为RADAR的多代理协作评估框架，通过四个专门的互补角色采用多轮辩论机制，并通过动态更新机制实现风险概念分布的自我演化。该方法可以在全面覆盖明确和隐含风险的同时，减少评估者的偏见。
### Conclusion
在广泛实验中，RADAR在多个维度（包括准确性、稳定性和自我评估风险敏感性）上显著优于基准评估方法。相比于最强基准评估方法，RADAR在风险识别准确率上提高了28.87%。
## 983. `cs.LG` - DragFlow：基于区域监督解锁DiT先验的拖拽编辑 [PDF](https://arxiv.org/pdf/2510.02253), [HTML](https://arxiv.org/abs/2510.02253)
### Authors
Zihan Zhou,Shilin Lu,Shuli Leng,Shaocong Zhang,Zhuming Lian,Xinlei Yu,Adams Wai-Kin Kong
### Background
基于拖拽的图像编辑长期以来一直存在目标区域失真的问题，主要是因为早期的基础模型Stable Diffusion的先验不足，无法将优化后的潜在向量准确地映射回自然图像流形。随着从基于UNet的DDPMs向更可扩展的DiT（例如SD3.5,FLUX）的转变，生成先验变得更强，推动了多种编辑任务的进步。然而，基于拖拽的编辑尚未从中受益。
### Innovation
本文提出了首个有效利用FLUX丰富先验进行拖拽编辑的框架DragFlow，显著超过了基线。DragFlow通过引入区域编辑范式，使用仿射变换提供更丰富且一致的特征监督，克服了直接在DiT上应用基于点的拖拽编辑效果不佳的问题。此外，DragFlow集成了预训练的开放域个性化适配器（如IP-Adapter），以增强主体一致性，同时通过梯度掩码的硬约束保持背景保真度。最后，通过多模态大语言模型解决任务歧义问题。
### Conclusion
基于广泛的实验，DragFlow在拖拽编辑基准（DragBench-DR和ReD Bench）上超过了基于点和区域的基线，建立了基于拖拽的图像编辑的新SOTA。代码和数据集将在出版后公开。
## 984. `cs.LG` - 超越静态知识信使：面向医学AI的自适应、公平和可扩展联邦学习 [PDF](https://arxiv.org/pdf/2510.06259), [HTML](https://arxiv.org/abs/2510.06259)
### Authors
Jahidul Arafat,Fariha Tasmin,Sanjaya Poudel,Iftekhar Haider
### Background
医疗AI在确保跨异质医疗机构的隐私保护协作学习的同时面临挑战，当前的联邦学习方法存在静态架构、收敛速度慢（45-73轮）、公平性差距以及小机构被边缘化和可扩展性受限（最多支持15个客户端）等问题。
### Innovation
本文提出了自适应公平联邦学习（AFFL）的三个创新：（1）自适应知识信使，基于异质性和任务复杂度动态调整容量；（2）公平感知知识蒸馏，利用影响加权聚合提升公平性；（3）课程引导加速，减少轮数60-70%。理论分析保证了ε-公平性边界，并达到了降低通信、提高公平性和节约能源的效果，为多模态数据集的整合提供了可能，同时保持HIPAA和GDPR合规性。
### Conclusion
本文提出了一套MedFedBench基准测试套件，用于六个维度的标准化评估：收敛效率、机构公平性、隐私保存、多模态集成、可扩展性和临床部署准备。经济分析表明，该框架可以为农村医院提供400-800%的投资回报率，并为学术中心带来15-25%的性能提升。作者提出了研究议程和实施路线图，探讨如何普及医学AI应用。
## 985. `cs.LG` - VT-FSL: 通过LLMs弥合视觉与文本之间差距的少样本学习 [PDF](https://arxiv.org/pdf/2509.25033), [HTML](https://arxiv.org/abs/2509.25033)
### Authors
Wenhao Li,Qiangchang Wang,Xianjing Meng,Zhibin Wu,Yilong Yin
### Background
少样本学习（FSL）旨在仅从少量标记的支持样本中识别新的概念。最近的研究通过引入附加的语义信息或设计复杂的语义融合模块来增强支持特征。然而，这些方法仍然面临由于缺乏实际实例的关联而导致虚幻语义问题，这使得语义信息与视觉证据相矛盾，产生嘈杂的指导，并导致成本高昂的纠正。
### Innovation
本文提出了一个新颖的框架，即通过视觉和文本与大语言模型的少样本学习（VT-FSL），该框架通过大型语言模型（LLMs）条件化构造精确的跨模态提示，并通过几何感知对齐无缝集成。其核心组成部分是跨模态迭代提示（CIP）和跨模态几何对齐（CGA）。CIP通过一次结构化的推理过程，条件化LLMs利用类别名称和支持图像生成精确类别描述，这些描述既能丰富新的类别的语义理解，又能使零样本合成语义一致的图像。CGA通过最小化它们所跨越的3维平行otope的核体积，联合对齐融合的文本、支持和合成的视觉表示，捕捉所有表示间的全局和非线性关系，实现结构化和一致的多模态整合。
### Conclusion
本文提出的VT-FSL方法在十个多样性的基准上设立了新的少样本学习性能标准，包括标准、跨域和细粒度的少样本学习场景。完整代码可在以下链接获取：this https URL.
## 986. `cs.LG` - 机器人通过自我探索推动行动与语言发展的好奇心驱动发展 [PDF](https://arxiv.org/pdf/2510.05013), [HTML](https://arxiv.org/abs/2510.05013)
### Authors
Theodore Jerome Tinker,Kenji Doya,Jun Tani
### Background
人类婴儿通过逐步学习语言和行动，仅需少量学习例子便能实现广泛的一般化能力。然而，最近的大规模语言模型需要接触数十亿的训练令牌才能实现类似的一般化能力。这一研究探讨了人类在发展中高效学习的机制，提出了通过模拟实验（让机器人通过自我引导探索来学习符合命令句的动作，如“推红色立方体”）来研究好奇心驱动的发展性学习机制。研究发现，通用性的提高随着组成元素数量的增加而显著增强；好奇心驱动的探索结合运动噪声在很大程度上优于没有好奇心驱动的学习；在生成组成性的通用化之前，句动搭配会先发生；更简单的、先决条件式的动作会在早期出现，而涉及这些先决条件的更复杂动作则会之后发展出来。这些发现为儿童发展性学习机制提供了可能的解释，并为发育心理学的发现提供了计算上的类比.
### Innovation
本研究创新地将主动推理框架与强化学习结合，实现了好奇心驱动的发展性学习。通过机器人自我引导探索来学习与命令句相对应的动作，以研究人类高效发展的机制。研究揭示了一系列重要的发现，使得对儿童发展性学习机制的理解更为深刻，并与发育心理学的发现建立了一种类比关系。
### Conclusion
研究结果指出，伴随着组成语义元数量的增长，通用性的提升显著。好奇心驱使的探索和运动噪声能够显著优于常规学习。句动随机对应发生在组成性的通用化出现之前，更简单的先决条件式动作会先于复杂涉及这些先决条件的动作出现。这些发现让人更好地理解了婴幼儿发展性学习的潜在机制，并提供了发育心理学发现的计算模拟。
## 987. `cs.LG` - 适应性鲁棒优化中的过拟合问题 [PDF](https://arxiv.org/pdf/2509.16451), [HTML](https://arxiv.org/abs/2509.16451)
### Authors
Karl Zhu,Dimitris Bertsimas
### Background
适应性鲁棒优化(ARO)是一种扩展自静态鲁棒优化的方法，它使得决策依赖于实际的不确定性，从而在建模的不确定性集中弱化了静态解决方案的表现。虽然ARO提高了决策的灵活性，但也使得先前独立于不确定性约束现在变得依赖于不确定性，这就使得当实际结果超出不确定性集时更容易出现不可行性。这种适应性策略易碎性现象类似于机器学习中的过拟合问题。
### Innovation
为了缓解这一问题，论文提出赋予每条约束特定的不确定性集大小，更难满足的约束应获得更强的概率保证。通过过拟合的角度来看待，这种方法起到正则化的作用：更强的保证会缩小适应系数以确保稳定性，而较弱的保证则保留更多的有用灵活性。这种观点启发了一种在鲁棒性和适应性之间寻求平衡的原则性方法设计不确定性集的方法。
### Conclusion
该研究提供了一种方法来设计不确定性集，既能保证鲁棒性，又能保持适应性。通过拟合与正则化的关系，这种方法平衡了在各种不确定性情况下的解决方案的稳定性和实用性。
## 988. `cs.LG` - GTAlign: 游戏论对齐的大型语言模型助手以实现双方福利最大化 [PDF](https://arxiv.org/pdf/2510.08872), [HTML](https://arxiv.org/abs/2510.08872)
### Authors
Siqi Zhu,David Zhang,Pedro Cisneros-Velarde,Jiaxuan You
### Background
大型语言模型（LLMs）在推理方面取得了显著进步，但在诸如写作、信息检索或提供实际指导等任务中，有时会产生对用户来说次优的回应。传统的对齐实践通常假设最大化模型奖励也等同于最大化用户福利，但在实践中，这个假设经常无法得到满足：模型可能会过于详细地解释或生成冗长的推理，而用户可能更偏好简洁的答案。这种行为类似于囚徒困境，个人理性选择会导致社会福利不佳的结果。根本问题是缺乏一种兼顾LLM和用户双方利益的规范决策机制。
### Innovation
我们提出了游戏论对齐（GTAlign），这是一种将游戏论决策机制整合到推理和训练中的对齐框架。在推理过程中，模型将用户-LLM互动视为一个战略博弈，并在其推理链中构建收益矩阵来评估自己和用户双方的福利，从而选择具有互惠利的行动。在训练过程中，我们引入了一种互惠福利奖励机制，增强了合作回应，使模型行为与社会高效的成果相一致。此外，引入了一种利用博弈论推理以动态适应LLM服务定价策略变化进行推理的技巧。广泛的实验结果表明，与基线相比，GTAlign在多个任务中显著提高了推理效率、答案质量和互惠福利。
### Conclusion
GTAlign在多个任务中显著提高了LLMs的推理效率、答案质量和互惠福利，与传统的对齐方法相比有了明显的改进。
## 989. `cs.LG` - 减少已过时和易受攻击依赖项哪一种更好： pinning 还是 floating？ [PDF](https://arxiv.org/pdf/2510.08609), [HTML](https://arxiv.org/abs/2510.08609)
### Authors
Imranur Rahman,Jill Marley,William Enck,Laurie Williams
### Background
开发者在项目中一致使用版本约束来指定依赖项的可接受版本。pinning 可以减少引入破坏性更改的可能性，但会增加手动管理过时和易受攻击依赖项替代的费用。另一方面，floating 可以自动获取错误修复和安全修复，但可能会导致破坏性更改。安全从业者建议 pinning 依赖项以防止软件供应链攻击，例如恶意更新包。然而，由于 pinning 是最严格的版本约束，这意味着它最有可能导致依赖项过时。关于在不同版本约束类型下依赖项过时或易受攻击的可能性变化并未明确。本研究目标是通过大规模的实证评估，帮助开发者根据使用不同类型版本约束的情况下依赖项过时或易受攻击的可能性来做出知情决策。本研究首先确定了依赖项版本约束使用的趋势以及开发者在 npm、PyPI 和 Cargo 生态系统中的版本约束类型变化模式。使用生存分析建模依赖项状态的转换，并估计使用 pinning 相对于其他版本约束类型时，变成过时或易受攻击的可能性如何变化。结果显示，最常见的版本约束类型是 floating-minor，而 pinning 是最常见的。同时发现 floating-major 最不可能导致依赖项过时，floating-minor 最不可能导致易受攻击的依赖项。
### Innovation
本研究通过大规模实证评估，详细分析了不同版本约束类型下依赖项过时或易受攻击的可能性，帮助开发者在 pinning 和 floating 之间做出更加明智的决策。研究使用了生存分析建模依赖项状态的转换，并量化了 pinning 相对于其他版本约束类型的效果差异，提供了具体的实证依据。
### Conclusion
在过时和易受攻击的依赖项中，最常用的是 floating-minor 版本约束，紧随其后的是 pinning。同时，floating-major 版本约束最不可能导致依赖项过时，而 floating-minor 版本约束最不可能导致依赖项易受攻击。
## 990. `cs.LG` - 在合作多智能体强化学习中稳健性和韧性的一种实证研究 [PDF](https://arxiv.org/pdf/2510.11824), [HTML](https://arxiv.org/abs/2510.11824)
### Authors
Simin Li,Zihao Mao,Hanxiao Li,Zonglei Jing,Zhuohang bian,Jun Guo,Li Wang,Zhuoran Han,Ruixiao Xu,Xin Yu,Chengdong Ma,Yuqing Ma,Bo An,Yaodong Yang,Weifeng Lv,Xianglong Liu
### Background
在合作多智能体强化学习(MARL)中，通常在理想的模拟环境中调整超参数以最大化合作表现。然而，这些经过合作优化的策略在面对真实世界的不确定性时往往缺乏稳健性和恢复力。建立可信赖的MARL系统需要对稳健性和恢复力有深刻的理解，即确保系统在不确定性下的稳定性和恢复能力，而这些概念在控制系统中已被广泛研究但在MARL领域却较少关注。
### Innovation
本文进行了一项大规模的实证研究，包括超过82,620次实验，评估了在4个实际环境下的合作、稳健性和恢复力，涵盖了13种不确定性类型和15个超参数。研究发现超参数调整对可信赖MARL至关重要，发现了一些标准实践可能损害稳健性，如参数共享、GAE和PopArt，而早期停止、高批评学习率和Leaky ReLU则有助于提升这些指标。研究还发现，稳健性和恢复力不容易在不同不确定性类型或代理范围内推广，超参调优能显著提升MARL策略在所有后端模型中的合作、稳健性和恢复力。
### Conclusion
在修订后的合作、稳健性和恢复力指标下，超参数调整能显著提升MARL策略的整体性能，即使在不同的MARL架构中，这一现象也具有一致性。研究结果已公布在https://this/https/URL上供进一步研究。
## 991. `cs.LG` - 基于行为生物特征的虚拟现实用户熟悉度自动检测 [PDF](https://arxiv.org/pdf/2510.12988), [HTML](https://arxiv.org/abs/2510.12988)
### Authors
Numan Zafar,Priyo Ranjan Kundu Prosun,Shafique Ahmad Chaudhry
### Background
随着虚拟现实（VR）设备在日常环境中的应用越来越广泛，越来越多的用户在缺乏先验VR经验的情况下将与VR系统交互。自动检测用户的VR熟悉程度可以实现实时、适应性的训练和界面调整，减少用户挫败感并提高任务绩效。在本研究中，通过分析使用基于按键的密码开门任务中的手部运动模式来探索VR熟悉程度的自动检测方法，这种方法在会议房间、办公室和医疗环境中是一项常见的交互方式。
### Innovation
本研究采用最新的深度分类器来自动检测VR熟悉程度，实现了手部追踪和控制器交互方式下手部运动模式的高准确性：手部追踪92.05%和控制器交互83.42%。研究还说明了通过控制器数据训练的分类器在手部追踪数据上的交叉设备评价，以及将两者结合的方法在混合设备评价中的高准确性（94.19%）。这表明手部运动生物特征可以用于实时检测关键VR应用中的用户熟悉程度，为个性化和自适应的VR体验铺平了道路。
### Conclusion
研究表明，使用手部运动生物特征可以有效检测用户在VR环境中的熟悉程度，对于提高用户任务完成度和用户满意度具有重要意义。
## 992. `cs.LG` - 贝叶斯或海森堡，谁（们）统治？ [PDF](https://arxiv.org/pdf/2510.13894), [HTML](https://arxiv.org/abs/2510.13894)
### Authors
Volker Tresp,Hang Li,Federico Harjes,Yunpu Ma
### Background
量子系统通常由量子状态向量描述，但研究表明，在某些情况下，它们的测量过程可以重新表述为用概率状态向量表示的概率方程。这些概率表示可以近似为Tensor Brain（TB）模型神经网络的动力学，该模型是一个最近提出的框架，用于模拟大脑中的感知和记忆，提供了一种基于生物学机制的有效综合生成符号表示进入推理过程的方法。
### Innovation
提出了一种新的方法，即将量子测量过程重新表述为用概率状态向量表示的概率方程，并且利用Tensor Brain模型的神经网络动力学来近似这些概率表示，实现了对量子测量过程的新理解与模拟，为理解和构建量子计算和大脑模型提供了新的视角。
### Conclusion
该研究不仅揭示了量子测量过程的概率表示形式，还展示了Tensor Brain模型如何用于近似这些表示，为结合机器学习和量子计算等领域提供了新的可能性，也提出了在贝叶斯和量子力学框架之间找到兼容性和整合方式的研究方向。
## 993. `cs.LG` - DexCanvas：从人类演示到机器人学习灵巧操作的桥梁 [PDF](https://arxiv.org/pdf/2510.15786), [HTML](https://arxiv.org/abs/2510.15786)
### Authors
Xinyue Xu,Jieqiang Sun,Jing(Daisy)Dai,Siyuan Chen,Lanjie Ma,Ke Sun,Bin Zhao,Jianbo Yuan,Sheng Yi,Haohua Zhu,Yiwen Lu
### Background
研究灵巧操作的学习，包括基于物理的接触控制和技能在不同手型之间的转移，目前面临着缺乏全面和多样化的数据集的问题。现有的数据集要么规模有限，要么缺乏系统的技能覆盖和物理验证的接触标注。
### Innovation
DexCanvas 是一个包含7000小时灵巧手物互动数据的大规模混合真人合成数据集，基于 70 小时的真实人类示范创建，涵盖了21种基本操作类型。每个条目包含同步多视角RGB-D图像、高精度的动捕数据及MANO手部参数，包括每帧的接触点和物理一致的力分布。通过强化学习训练政策，能够再现人类示范的同时发现产生观察到物体运动的接触力。这是第一个结合大规模真实演示、系统化的技能覆盖（基于现有分类）以及物理验证的接触标注的数据集。
### Conclusion
DexCanvas 能够促进灵巧操作学习、接触丰富的控制以及不同手型之间的技能转移的研究。
## 994. `cs.LG` - 使用大型语言模型的多机器人团队组成协调 [PDF](https://arxiv.org/pdf/2507.16068), [HTML](https://arxiv.org/abs/2507.16068)
### Authors
Zhehui Huang,Guangyao Shi,Yuwei Wu,Vijay Kumar,Gaurav S. Sukhatme
### Background
传统的多机器人协调依赖于一种特定任务且由专家驱动的管道，具体来说，自然语言的任务描述需要通过领域专家的手动翻译，转化为数学形式、算法设计和可执行代码。这种传统过程 labor-intensive，对非专家来说难以接触，并且对任务需求的变化不够灵活。因此，本书提出的 LAN2CB (自然语言到群体行为)框架，利用大型语言模型 (LLMs) 来简化并泛化多机器人协调管道，将自然语言的任务描述转化为可执行的 Python 代码，增强了系统自动生成和辅助操作功能，为多机器人的协调提供了更加灵活和稳健的解决方案。
### Innovation
提出了一种新型框架 LAN2CB，利用大型语言模型将自然语言的任务描述转化为可执行的 Python 代码。该框架通过两个核心模块：任务分析（将任务描述解析为行为树）和代码生成（利用行为树和结构化的知识库生成机器人控制代码），实现了从自然语言生成可执行代码的过程，显著减少了手动工程努力，并支持广泛任务类型的泛化。
### Conclusion
LAN2CB 在仿真和真实环境中的实验表明，它能够实现稳健且灵活的多机器人协调，从自然语言入手，大大减少了手动工程努力，支持各类型任务场景的广泛泛化。
## 995. `cs.LG` - AGNES: 自适应图神经网络和动态规划混合框架实现实时纳米孔种子链接 [PDF](https://arxiv.org/pdf/2510.16013), [HTML](https://arxiv.org/abs/2510.16013)
### Authors
Jahidul Arafat,Sanjaya Poudel
### Background
纳米孔测序能够在实时情况下进行超长读长长片段DNA测序，但其固有的12-15％的高错误率给读对对齐带来了巨大的计算挑战。现有的种子链接方法依赖于固定的缺口惩罚函数，无法适应从串联重复序列到结构变异的各种基因组上下文。
### Innovation
本文提出了RawHash3框架，结合图神经网络与经典动态规划，实现自适应种子链接。该框架中的种子节点作为自节点具有12维特征向量，边编码8维空间关系，包括缺口一致性。采用三层EdgeConv图卷积神经网络，以及基于置信度的方法选择，在自学习指导和算法回退之间动态切换。大规模评估实现了99.94％的精度和40.07％的召回率，相比基线提高了25.0％，并且在1.59ms的中位推理延迟下仍能满足实时需求。
### Conclusion
交叉验证表明稳定性，确立了图神经网络在生产基因组分析管道中的可行性。
## 996. `cs.LG` - 高效视觉-语言-行动模型在环境操作中的系统性综述 [PDF](https://arxiv.org/pdf/2510.17111), [HTML](https://arxiv.org/abs/2510.17111)
### Authors
Weifan Guan,Qinghao Hu,Aosheng Li,Jian Cheng
### Background
视觉-语言-行动（Vision-Language-Action, VLA）模型通过将自然语言指令和视觉观察映射到机器人动作，进一步扩展了视觉-语言模型，使机器能够在物理环境中执行任务。尽管这些系统具备强大的功能，但它们在计算和内存需求方面面临巨大挑战，这与边缘平台（例如车载移动操作器）的实时性能要求产生了冲突。为应对这一矛盾，最近的研究集中于通过提高VLA系统的效率来解决这些问题。鼓励开发更高效、可扩展的VLA系统。
### Innovation
本文提供了一个关于提高VLA系统效率的方法的系统性综述，重点关注减少延迟、内存占用和训练推理成本。文章将现有的解决方案分为四个维度：模型架构、感知特征、动作生成和训练/推理策略，总结了每个类别中的代表性技术。最后，讨论了未来趋势和开放挑战，强调了推进高效环境智能的方向。
### Conclusion
本文综述了改进VLA效率的方法，分类总结了模型架构、感知特征、动作生成和训练/推理策略等方面的技术手段，并展望了未来的研究方向，指出需要关注的方向以进一步推进高效环境智能的发展。
## 997. `cs.LG` - VO-DP: 单视图语义-几何自适应弥散策略方法在仅视觉机器人操作中的应用 [PDF](https://arxiv.org/pdf/2510.15530), [HTML](https://arxiv.org/abs/2510.15530)
### Authors
Zehao Ni,Yonghao He,Lingfeng Qian,Jilei Mao,Fa Fu,Wei Sui,Hu Su,Junran Peng,Zhipeng Wang,Bin He
### Background
在模仿学习的背景下，基于视觉运动的弥散策略学习是机器人操作的主要方向之一。现有方法大多依赖于点云作为观测输入，并通过学习点云特征构建场景表示，从而实现高度精确的结果。然而，现有文献尚未深入探讨视觉唯一解决方案，这些解决方案有巨大的潜力。该论文旨在弥补这一空白，提出了一种名为VO-DP的视觉唯一单视图弥散策略学习方法。该方法利用预训练的视觉基础模型实现语义和几何特征的有效融合，并利用结合DINOv2语义特征和Alternating Attention块几何特征的VGGT中间特征。通过交叉注意力和卷积网络压缩空间特征形成策略头的输入。广泛实验表明，VO-DP在多个领域均表现出显著优越性，不仅远超其他视觉唯一基线方法，而且在模拟任务中，平均成功率高达64.6%，超过基于点云的DP3方法的64.0%，远高于标准DP方法的34.8%；在真实世界任务中，其成功率更是达到87.9%，大幅超越DP3方法的67.5%和标准DP方法的11.2%。
### Innovation
该研究创新性地提出了一种基于预训练视觉基础模型的单视图视觉唯一弥散策略学习方法（VO-DP），该方法能够同时融合语义和几何特征，有效提高了机器人操作的准确性与稳定性。这种方法在模拟与真实环境中均表现出色，特别是在真实任务中取得了显著的性能提升，验证了其在机器人操作应用中的优越性和适用性。此外，该研究还开放了针对机器人操作的训练库，支持多机器、多GPU并行训练和混合精度训练，且兼容多种视觉策略，与RoboTwin模拟器兼容。这些创新为机器人操作的研究和应用带来了新的可能性。
### Conclusion
总之，VO-DP方法不仅显著提升了机器人操作中的性能，还在不同场景下展示了高度的鲁棒性。通过搭建强大的训练平台，该研究为未来的机器人操作研究提供了强有力的支持。
## 998. `cs.LG` - 计算VC维度的参数化复杂性 [PDF](https://arxiv.org/pdf/2510.17451), [HTML](https://arxiv.org/abs/2510.17451)
### Authors
Florent Foucaud,Harmender Gahlawat,Fionn Mc Inerney,Prafullkumar Tale
### Background
VC维度是一个广泛研究且基础的集合系统（或超图）复杂度度量，对机器学习等多个领域至关重要。已有研究表明，计算VC维度的问题在复杂性上存在一定的局限性。本文在已有研究的基础上，进一步探讨了计算VC维度的复杂性，并深入分析了该问题的结构参数。
### Innovation
研究了计算VC维度的问题，并证明了在给定超图的情况下，朴素的 $2^{text{O}(|text{V}|)}$ 时间算法是最紧的下界，除非存在亚指数时间算法。进一步证明了当以超图的最大度和维度作为参数时，问题具有1-加性固定参数近似算法和固定参数算法，并表明这些是可利用的结构性参数的本质特征。此外，提出了一种关于图的 VC 维度计算的参数化复杂性问题的通用化形式，对于具有树宽的图设计了一个 $2^{text{O}(rm{tw}timesrm{log}rm{tw})}times|V|$ 时算法，这与某些密切相关的问题形成了对比，后者需要双指数依赖于树宽的时间复杂性（除非存在亚指数时间算法）.
### Conclusion
该研究确定了VC维度计算的一些关键参数化边界，并提出了针对图和集合系统的高效算法，为深入理解该领域的复杂性提供了新的见解。
## 999. `cs.LG` - 通过推断感知策略优化克服胜者诅咒 [PDF](https://arxiv.org/pdf/2510.18161), [HTML](https://arxiv.org/abs/2510.18161)
### Authors
Hamsa Bastani,Osbert Bastani,Bryce McLaughlin
### Background
近年来，自动学习基于丰富个体协变量的目标治疗决策策略引起了广泛关注。一种常见方法是使用机器学习模型预测反事实结果，然后选择能优化预测目标值的政策。然而，由于胜者诅咒问题——策略优化过程会利用预测误差而非实际改进——预测性能的改善往往无法通过后期政策优化得到证实。
### Innovation
本文提出了一种新型策略——推断感知策略优化，旨在调整策略优化过程以考虑其在后期将如何被评估。该方法不仅优化估计的目标值，还确保策略在统计学上显著优于收集数据时使用的观察策略的概率。通过数学定义了这两种目标的帕累托前沿，并设计了一个策略优化算法来估计该前沿，使得决策者可以根据其偏好选择满意的策略，然后在测试集上进行策略评估。
### Conclusion
研究展示了该方法的有效性，并通过模拟进行了证明。
## 1000. `cs.LG` - 基于多智能体强化学习的靶向干预原则 [PDF](https://arxiv.org/pdf/2510.17697), [HTML](https://arxiv.org/abs/2510.17697)
### Authors
Anjie Liu,Jianhong Wang,Samuel Kaski,Jun Wang,Mengyue Yang
### Background
在大规模多智能体强化学习（MARL）中，由人类提供全局指导是不切实际的，因此需要一种能有效引导多智能体系统向期望结果进发的方法。现有的长篇累牍的协调机制设计主要依赖于经验研究，缺乏现成的研究工具。多智能体影响图（MAIDs）作为一种图形框架能解决上述问题。
### Innovation
提出了一种新的多智能体强化学习交互范式——靶向干预范式，仅应用于单一靶向智能体，可以缓解全局指导的问题。通过引入因果推断技术前策略干预（PSI），利用MAIDs实现靶向干预。该方法通过最大化预期因果效应来实现综合期望结果，并通过联合相关性图分析以图形方式查看和评估MARL学习范式的可行性。
### Conclusion
实验结果表明，我们提出的靶向干预能有效引导多智能体强化学习，并通过相关性图分析验证了其有效性。
## 1001. `cs.LG` - 认证自我一致性：无标签训练和测试时训练的统计保证与可靠推理 [PDF](https://arxiv.org/pdf/2510.17472), [HTML](https://arxiv.org/abs/2510.17472)
### Authors
Paula Cordero-Encinar,Andrew B. Duncan
### Background
近年来，通过自我一致性（如自我一致性）和测试时强化学习（TTRL）等技术，大型语言模型（LLMs）的可靠性得到了提高，而无需额外的监督。尽管这些技术取得了进步，但对于它们的内部机制和统计保证的了解仍然不足。
### Innovation
提出了一个统一的LLMs可认证推理框架，表明多数投票提供了自我一致性的统计证书：在轻微假设下，汇总的答案与模型最终分布的众数在高概率上匹配。推导出有限样本和任意时间点有效的集中偏差界，以量化这种信心。引入了马尔可夫多数证书（MMC），这是一种自适应的序列停止规则，可确定何时足够样本已被绘制。进一步证明了测试时的无标签后训练方法（例如TTRL）通过指数地将答案分布倾向到其众数来隐式提高锐度，从而减少认证所需的样本数量。基于这一洞见，提出了新的后训练目标，旨在明确优化这一锐度和偏差之间的权衡。
### Conclusion
这些结果解释并连接了两个关键的测试时扩展策略：自我一致性与TTRL，且在单一的无标签、可认证的统计框架中对推理LLMs进行可靠性研究。
## 1002. `cs.LG` - 变换器本质上是简洁的 [PDF](https://arxiv.org/pdf/2510.19315), [HTML](https://arxiv.org/abs/2510.19315)
### Authors
Pascal Bergsträßer,Ryan Cotterell,Anthony W. Lin
### Background
本文探讨了变换器在描述概念时的表达能力。研究发现变换器相比于有限自动机和线性时序逻辑（LTL）等标准形式语言表示方法，能够以更简洁的方式表示正式语言。
### Innovation
提出以简洁性作为衡量变换器表达能力的标准，并证明变换器能够在更简洁的表示形式上表示正式语言。作为这一高表达性的结果，验证变换器属性是证明其不可解的问题（即EXPSPACE完全问题）。
### Conclusion
变换器在描述概念时具有高表达能力，这一能力使得变换器能够以更简洁的方式表示正式语言，同时也带来了验证其属性的复杂性挑战。
## 1003. `cs.LG` - 反思的幻象：开放任务揭示大型语言模型反思推理中的系统性失败 [PDF](https://arxiv.org/pdf/2510.18254), [HTML](https://arxiv.org/abs/2510.18254)
### Authors
Sion Weatherhead,Flora Salim,Aaron Belbasis
### Background
当前的大语言模型能够生成推理文本和‘反思性’内容，但这种‘反思’是否与人类的反思推理功能等同？以往关于封闭任务的研究往往使“反思”看起来是有效的，但掩盖了模型自我纠正能力的局限。因此，作者设计了一个有实际意义且受限的开放任务来测试模型的反思推理能力，即生成有效的科学测试项目并自评为之纠正。
### Innovation
研究表明，即使在开放而受限的任务中，大型语言模型在初次尝试和反思后仍表现出低效，并且虚假改进主要是通过偶然生成有效项目而非错误检测修复问题。这一发现揭示了现有大模型在实现主动、目标驱动的监控方面的局限性，强调了外在结构在确保模型遵守约束中的重要性。
### Conclusion
当前大模型的‘反思’缺乏功能性的证据表明类似于人类的主动、目标驱动监测，这在初次尝试中同样重要。模型需要内置这样的机制以实现可靠的性能，否则需要外部结构来强制执行约束。
## 1004. `cs.LG` - Zhyper：基于因子超网络的条件大语言模型微调 [PDF](https://arxiv.org/pdf/2510.19733), [HTML](https://arxiv.org/abs/2510.19733)
### Authors
M. H. I. Abdalla,Zhipin Wang,Christian Frey,Steffen Eger,Josif Grabocka
### Background
大语言模型（LLM）的条件指训练LLM生成符合特定文化规范、特定政治倾向价值观或任何指定语义条件的内容。但由于预训练和对齐数据集的归纳偏差，提示工程无法确保LLM按照期望的条件进行行为。此前研究主要集中在通过直接条件LoRA权重对LLM进行微调，这种方法会引入大量参数。
### Innovation
我们提出了Zhyper，一种参数效率的因子超网络框架，可以从文本描述中生成上下文感知的LoRA适配器。实验表明，Zhyper在多个基准上的性能可与最先进基线相媲美，同时还仅有最先进基线的26分之一的参数量。此外，我们还将Zhyper扩展到了文化对齐方面，展示了其在跨域设置中的更好泛化能力和对细粒度上下文价值的更好捕捉。
### Conclusion
Zhyper实现了有效的参数高效微调，特别是通过因子化的超网络生成具有上下文感知能力的LoRA适配器，显著减少了参数量，并在跨域泛化和细粒度语境价值捕捉方面表现出色。
## 1005. `cs.LG` - 世界模型学习基准测试 [PDF](https://arxiv.org/pdf/2510.19788), [HTML](https://arxiv.org/abs/2510.19788)
### Authors
Archana Warrier,Dat Nguyen,Michelangelo Naim,Moksh Jain,Yichao Liang,Karen Schroeder,Cambridge Yang,Joshua B. Tenenbaum,Sebastian Vollmer,Kevin Ellis,Zenna Tavares
### Background
现有的方法在学习和评估世界模型时，主要聚焦于下一帧的预测，并且评估成功标准是最大化在相同环境中的奖励。这与模型学习的理想目标有所偏离，理想目标是收集信息来学习能够支持多种下游任务和推理的世界模型。
### Innovation
本文提出了WorldTest，一种评估模型学习代理的协议，将无奖励交互与在不同但相关的环境中经过测试得分的阶段分开，采用开放式评估标准，可以支持多种未知的下游任务，这使得该方法对模型的表示形式是无偏的，便于不同方法之间的比较。WorldTest实现了与AutumnBench的集成，这是一个包含43个交互网格环境和129个任务的环境套件，分为遮掩帧预测、计划和预测动态变化三种类别。
### Conclusion
实验结果表明，人类在AutumnBench上表现优于模型，且计算资源的增加仅在某些环境中能够提升表现，而在其他环境中则不然。WorldTest提供了一种新颖的评估模板：无奖励探索，衍生测试，基于行为评分，可以评估代理对环境动力学的理解，并且AutumnBench揭示了环境模型学习的巨大改进空间。
## 1006. `cs.SE` - E-Test: E'er-Improving Test Suites [PDF](https://arxiv.org/pdf/2510.19860), [HTML](https://arxiv.org/abs/2510.19860)
### Authors
Ketai Qiu,Luca Di Grazia,Leonardo Mariani,Mauro Pezzè
### Background
测试套件天生不完美，测试人员可以不断丰富测试套件，以提高其质量，提升目标软件系统的可靠性。然而，找到能够覆盖超出现有测试套件范围的执行场景的新测试用例非常具有挑战性和劳动密集，尤其是在长时间管理和维护大型测试套件时。
### Innovation
本文提出E-Test方法，通过利用大型语言模型（LLMs）识别那些现有测试套件未能充分覆盖的执行场景，并补充新的测试用例以增加其覆盖范围，从而缩小测试执行空间与实际测试后执行之间的差距。与现有回归测试和现场测试方法相比，E-Test在检测未测试执行场景方面取得了显著的F1分数改进，达到0.55。
### Conclusion
E-Test在一组包含1,975个从实际生产中的高度评价的开源Java项目和Defects4J收集的场景数据集上的评估表明，相比现有方法，E-Test能够更好地识别未测试的执行场景。这一结果强调了E-Test通过有效针对未测试的执行场景来提升测试套件效果，并减少了维护测试套件所需的手动劳动量。
## 1007. `cs.SE` - SODBench: 一种大型语言模型方法来记录表格操作 [PDF](https://arxiv.org/pdf/2510.19864), [HTML](https://arxiv.org/abs/2510.19864)
### Authors
Amila Indika,Igor Molybog
### Background
当前，许多知识工作者依靠电子表格进行商业、会计和金融工作，但由于缺乏系统的电子表格文档方法，自动化、协作和知识传递存在困难，可能会导致关键机构知识的丢失。
### Innovation
本文介绍了一种名为Spreadsheet Operations Documentation（SOD）的AI任务，旨在生成人类可读的电子表格操作解释。提供了一个基准数据集，包含111个电子表格操作代码片段及其对应的自然语言摘要，以评估大型语言模型（LLMs）在生成自然语言解释方面的表现，这在之前的研究中是一个较少探讨的领域。
### Conclusion
研究发现，大型语言模型能够生成准确的电子表格文档，这使SOD成为增强电子表格的可重现性、可维护性和协作工作流的一个可行的前提步骤，但仍需解决一些挑战。
## 1008. `cs.SE` - 由知识引导的面向应用级软件代码生成多智能体框架 [PDF](https://arxiv.org/pdf/2510.19868), [HTML](https://arxiv.org/abs/2510.19868)
### Authors
Qian Xiong,Bo Yang,Weisong Sun,Yiran Zhang,Tianlin Li,Yang Liu,Zhi Jin
### Background
自动化代码生成通过大型语言模型（LLMs）提高了开发效率，但在生成复杂的应用级软件代码方面仍然具有挑战性。现有的多智能体框架虽然具有潜力，但在大规模应用级软件代码生成方面表现不足，无法确保项目代码的合理组织结构，使得代码生成过程难以维护。
### Innovation
本文提出了一种名为KGACG的知识引导应用级代码生成框架，通过代码组织与规划智能体（COPA）、编码智能体（CA）和测试智能体（TA）的协作循环以及反馈机制，将软件需求规范和架构设计文档转化为可执行代码。
### Conclusion
KGACG致力于推进应用级软件开发的自动化，并通过一个案例研究展示了智能体的协作过程，面对挑战展现了其应用潜力。
## 1009. `cs.SE` - BugPilot：高效学习软件工程技能的复杂错误生成 [PDF](https://arxiv.org/pdf/2510.19898), [HTML](https://arxiv.org/abs/2510.19898)
### Authors
Atharv Sonwane,Isadora White,Hyunji Lee,Matheus Pereira,Lucas Caccia,Minseon Kim,Zhengyan Shi,Chinmay Singh,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan
### Background
以高质量错误作为训练下一代基于语言模型的软件工程（SWE）代理的关键。现有的生成错误的方法往往通过故意对现有代码进行局部扰动生成错误，这并不反映真实的开发过程。因此，需要一种新型的方法来生成复杂且多样的错误，以便更好地提高监督微调的效率，同时减少训练数据的需求量。
### Innovation
提出了一种新颖的合成生成复杂且多样的错误的方法。通过指导SWE代理在代码库中引入特性，可能会无意中破坏测试，从而生成错误。这种方法相比之前的生成错误的方法更真实地反映了人工编辑的模式，并证明了所生成的错误能更高效地用于监督微调，减少了所需训练数据量，且性能更优越。
### Conclusion
通过使用BugPilot生成的错误数据集训练模型，FrogBoss在具有32B参数的情况下，在SWE-bench上的通过率为54.6%，而FrogMini在14B参数的情况下则为45.3%，均达到最先进水平。
## 1010. `cs.SE` - 开发用于将PL/SQL触发器迁移到Java的模型驱动重构方法：一种实践经验 [PDF](https://arxiv.org/pdf/2510.20121), [HTML](https://arxiv.org/abs/2510.20121)
### Authors
Carlos J. Fernandez-Candel,Jesus Garcia-Molina,Francisco Javier Bermudez Ruiz,Jose Ramon Hoyos Barcelo,Diego Sevilla Ruiz,Benito Jose Cuesta Viera
### Background
随着现代软件技术的成功，许多企业开始尝试从RAD平台如Oracle Forms迁移到现代技术栈上。本研究聚焦于使用模型驱动的重构方法来开发一款工具，用于将PL/SQL代码迁移到Java代码，尤其是针对Oracle Forms触发器和程序单元的迁移。
### Innovation
提出了一种采用类似于TDD的方法增量开发模型转换的软件过程。这个过程中包含了对生成代码的三种类型的验证。具体解释了该重构方法的实现和验证过程，并讨论了MDE应用中遇到的一些问题。
### Conclusion
研究展示了如何使用MDE技术实现对PL/SQL代码的迁移，采用模型驱动的方法和严格的验证机制，并指出了一些实际应用中的挑战。
## 1011. `cs.SE` - 灰盒模糊测试中的交互效应研究 [PDF](https://arxiv.org/pdf/2510.19984), [HTML](https://arxiv.org/abs/2510.19984)
### Authors
Konstantinos Kitsios,Marcel Böhme,Alberto Bacchelli
### Background
灰盒模糊测试是一种自动化的软件测试工具，通过在种子输入上随机应用变异器（如翻转一个位或删除一块字节）来生成新的测试输入，并将所有增加覆盖率的输入添加到种子库中。现有研究通常基于随机顺序应用变异器，但没有深入探讨变异器应用顺序对效果的影响。本文作者认为种子输入上变异器应用顺序可能会影响灰盒模糊测试的有效性，并通过实验数据验证了这一假设，揭示出变异器组合的效果，从而提出一种新的模糊测试方法，以提高测试效率和效果。
### Innovation
作者提出了MuoFuzz，一种灰盒模糊测试工具，通过学习每个先前选择的变异器下后续变异器生成有趣输入的概率，再基于此概率进行随机游走生成一系列变异器序列，以此来选择最有潜力的有效变异器序列。MuoFuzz通过评估-focused顺序，进行更有效的模糊测试。实验结果表明，MuoFuzz在FuzzBench和MAGMA基准测试中实现了最高的代码覆盖率，并发现了一些AFL++和MOPT均未发现的漏洞。
### Conclusion
MuoFuzz通过学习变异器的顺序依赖性，有效地提高了灰盒模糊测试的效果，生成了一系列更有可能产生有趣测试数据的变异器序列，实验结果显示MuoFuzz在多种基准测试中表现出色，实现了更高的代码覆盖率并发现了新的漏洞。
## 1012. `cs.SE` - 为中型企业及大型企业提供生成式AI采纳与整合的框架 (FAIGMOE)  [PDF](https://arxiv.org/pdf/2510.19997), [HTML](https://arxiv.org/abs/2510.19997)
### Authors
Abraham Itzhak Weinberg
### Background
生成式人工智能（GenAI）为组织提供了变革性机遇，但中型企业面临资源约束和有限的人工智能专业能力，而大型企业则面临组织复杂性和协调挑战。现有的技术采纳框架，如 TAM、TOE 和 DOI 理论，缺乏针对这些差异性环境实施 GenAI 所需的特定性，形成了采纳文献中的关键缺口。这项研究提出了一种名为 FAIGMOE（框架为在中型企业和大型企业中采用和整合生成式AI）的概念框架，旨在解决这两种组织类型的特定需求。
### Innovation
FAIGMOE 框架将技术采纳理论、组织变革管理和创新扩散视角综合为四个互相连接的阶段：战略评估、规划与用例开发、实施和整合、运营化和优化。每个阶段提供了针对组织规模和复杂性的可扩展指导，包括准备性评估、战略对齐、风险管理、技术架构和变革管理。FAIGMOE 包括针对 GenAI 的特定考虑，如提示工程、模型编排和幻觉管理，从而区分它与其他通用技术采纳框架。这项贡献首次提出了一个全面的概念框架，专门针对中型和大型企业的生成式AI采纳，提供了可操作的实施协议、评估工具和治理模板，需要未来研究进行实证验证以加以印证。
### Conclusion
FAIGMOE 提供了一个系统性框架，以应对中型企业和大型企业在实施生成式AI时的具体需求，并提出了具体的实施、评估和治理方法，期待未来研究进一步验证其有效性。
## 1013. `cs.SE` - Classport：为Java设计运行时依赖反查 [PDF](https://arxiv.org/pdf/2510.20340), [HTML](https://arxiv.org/abs/2510.20340)
### Authors
Serena Cofano,Daniel Williams,Aman Sharma,Martin Monperrus
### Background
软件供应链安全的一个重要方面是运行时依赖反查，即在程序运行时观察当前使用的依赖关系。Java没有内置的支持这项功能的特性。Classport系统解决这个问题，该系统将依赖信息嵌入到Java类文件中，使依赖信息可以在运行时检索。Classport已经在六个真实项目上进行了评估，展示了此功能的可行性，即在运行时识别依赖关系。这为运行时完整性的检查铺开了重要途径
### Innovation
Classport系统创新性地将依赖信息嵌入到Java类文件中，使依赖信息可以在运行时进行检索。此系统填补了Java在运行时依赖反查方面的空白，为软件供应链安全性提供了一种新的检测手段
### Conclusion
通过Classport系统在六个真实项目上的测试，展示了其在识别运行时依赖方面的可行性，这对软件供应链的安全性具有重要意义，因为它为运行时完整性检查开启了新的途径
## 1014. `cs.SE` - 软件平台中的对称性作为架构原则 [PDF](https://arxiv.org/pdf/2510.20389), [HTML](https://arxiv.org/abs/2510.20389)
### Authors
Bjorn Remseth
### Background
软件平台通常表现为结构保持系统。它们提供一致的接口和行为，在特定变换（我们称之为对称性）下保持稳定。论文探讨了架构 robustness（鲁棒性）是从强制执行此类结构规律中产生出来的观点。
### Innovation
文章提出将对称性作为一种架构原则，来增强软件平台的架构稳健性。通过识别和维护系统内的对称性，可以在特定变换下保持系统的稳定性和一致性。
### Conclusion
通过强调软件平台中的对称性，可以使架构更加稳健，从而使系统在面对特定的变换时能够保持一致性和稳定性。
## 1015. `cs.SE` - 构建系统降级的成本：Kubernetes的一项案例研究 [PDF](https://arxiv.org/pdf/2510.20041), [HTML](https://arxiv.org/abs/2510.20041)
### Authors
Gareema Ranjan,Mahmoud Alfadel,Gengyi Sun,Shane McIntosh
### Background
由于开发人员频繁调用构建系统，其性能可能会影响生产力。现代的基于构件的构建工具可以加快构建速度，但以前的研究表明，开发团队可能会放弃这些工具，转向其他更易于维护的替代方案。尽管以前的研究探讨了降级的原因，但降级的影响及其在大规模项目中的具体表现仍然没有充分探索。本文通过对Kubernetes项目的案例研究，分析了从基于构件的构建工具（Bazel）降级到语言特定解决方案（Go Build）期间的完整构建和增量构建。结果显示，Bazel的构建速度比Go Build更快，但对内存的需求更大，且随着并行性的增加，Bazel对CPU的负荷也会增加。研究还通过在四个其他项目上复制Kubernetes的研究，观察到虽然构建时间的损失减少了，但Bazel在所有测试中都消耗了更多的内存。这表明，放弃基于构件的构建工具，尽管可能存在维护性的好处，但对大型项目来说，会导致显著的性能损失。这些观察结果可以帮助项目相关方评估构建工具的采用中的权衡。
### Innovation
本文的研究通过实证方法，探索了从基于构件的构建工具（如Bazel）降级到语言特定解决方案（如Go Build）的影响。研究不仅详细分析了不同工具之间的具体性能差异，还在多个项目中验证了Observations的一般性，即尽管构建时间损失减少，Bazel仍然在内存消耗上表现出更高的成本。研究为理解和优化构建工具的采用提供了新的见解。
### Conclusion
本文通过对Kubernetes等多个项目的案例研究发现，放弃基于构件的构建工具，尽管在维护性上可能存在一些短期内的提升，但对于大型项目来说，长期可能会导致显著的性能损失，尤其是在资源成本和内存消耗方面。因此，项目相关方在选择构建工具时需要权衡各种因素，包括维护成本、项目规模、性能表现等。
## 1016. `cs.SE` - 利用AI代理进行自动云基础设施即代码校正 [PDF](https://arxiv.org/pdf/2510.20211), [HTML](https://arxiv.org/abs/2510.20211)
### Authors
Zhenning Yang,Hui Guan,Victor Nicolet,Brandon Paulsen,Joey Dodds,Daniel Kroening,Ang Chen
### Background
传统的云架构主要通过云控制台、命令行界面（CLI）和软件开发工具包（SDK）进行管理。近年来，基础设施即代码/IaC框架（如Terraform）变得非常流行。这些框架以“单一真理源”配置的形式编码基础设施，并能自动执行资源的部署、更新或销毁操作，使实际基础设施与IaC配置保持一致。然而，当IaC与云控制台、CLI或SDK一起使用时，可能会丢失对外部更改的可见性，导致基础设施漂移，即配置逐渐过时，从而导致后续的IaC操作可能会撤销有效的更新或引发错误。
### Innovation
该项目提出了一个名为NSync的自动化系统，该系统能够将外部更改推送到IaC程序中。NSync通过API调用跟踪来检测漂移（即非IaC更改）并进行校正（即更新IaC配置以捕捉更改）。NSync采用了代理式架构，利用大语言模型（LLMs）从嘈杂的API序列中推断高层次意图，使用专用工具生成有针对性的IaC更新，并通过自进化的知识基持续改进。此外，还介绍了一种新的评估管道，用于将现实中的更改注入云基础设施中并评估校正性能。
### Conclusion
实验表明，NSync在准确性和token效率方面都优于基线。准确率从0.71提高到0.97，在token效率上提高了1.47倍。
## 1017. `cs.SE` - 向实用演绎验证迈进：工业与学术界定性调查的见解 [PDF](https://arxiv.org/pdf/2510.20514), [HTML](https://arxiv.org/abs/2510.20514)
### Authors
Lea Salome Brugger,Xavier Denis,Peter Müller
### Background
演绎验证是一种有效的方法，用于确保给定系统表现出预期的行为。尽管在选定的项目中已经被证明了其有效性和可行性，但演绎验证至今仍不是主流技术。为了促进其广泛应用，本研究调查了成功应用演绎验证的因素以及阻碍更广泛采用的潜在问题。研究者对30名来自工业和学术界的验证从业者进行了半结构化访谈，并采用主题分析方法系统分析了收集的数据。尽管实证确认了熟悉的问题，如进行形式证明所需的高技术需求，但数据还揭示了几个未充分探讨的障碍，如证明维护、自动化控制不足和可用性问题。通过数据分析的结果，研究者提炼出演绎验证的成功要素和障碍，并制定出针对从业者、工具构建者和研究者的具体建议，包括可用性、自动化和与现有工作流程的结合原则，
### Innovation
本研究揭示了未充分探讨的障碍，如证明维护、自动化控制不足和可用性问题，并提出了针对从业者、工具构建者和研究者的具体建议，特别是在可用性、自动化和与现有工作流程的结合方面的原则，
### Conclusion
本研究强调了在演绎验证方面存在的未充分探讨的障碍，并提供了一些建议，以促进其在更广泛的领域中的应用。
## 1018. `cs.SE` - 大型语言模型在故障定位中的应用：一项实证研究 [PDF](https://arxiv.org/pdf/2510.20521), [HTML](https://arxiv.org/abs/2510.20521)
### Authors
YingJian Xiao,RongQun Hu,WeiWei Gong,HongWei Li,AnQuan Jie
### Background
大型语言模型（LLMs）在代码相关任务中表现出显著的能力，尤其是自动程序修复。然而，修复的有效性高度依赖于上游故障定位的性能，对于此，目前缺少全面的评估。本文对LLMs在语句级代码故障定位任务中的表现进行了系统性的实证研究。
### Innovation
研究评估了代表性的开源模型（Qwen2.5-coder-32b-instruct，DeepSeek-V3）和闭源模型（GPT-4.1 mini，Gemini-2.5-flash）在HumanEval-Java和Defects4J数据集上的故障定位能力。通过不同的提示策略（包括标准提示、少量样本示例、链式推理），研究分析了模型在准确率、时间效率和经济效益维度上的表现。
### Conclusion
实验结果表明，纳入错误报告上下文显著提升了模型的性能。少量样本学习具有一定的改进潜力，但边际效益递减明显，而链式推理的有效性则高度依赖于模型自身的推理能力。该研究不仅强调了不同类型模型在故障定位任务中的性能特征和权衡，还提供了关于当前LLMs强项及改进故障定位有效性的策略的见解。
## 1019. `cs.SE` - 基于FMI的增强安全性和知识产权保护的分布式协同仿真 [PDF](https://arxiv.org/pdf/2510.20403), [HTML](https://arxiv.org/abs/2510.20403)
### Authors
Santiago Gil,Ecem E. Baş,Christian D. Jensen,Sebastian Engelsgaard,Giuseppe Abbiati,Cláudio Gomes
### Background
分布式协同仿真在不同利益相关者之间实现协作建模和仿真时起着关键作用，同时保护知识产权。尽管协同仿真能隐式地提供知识产权保护，但对于如何保护连续时间和混合系统在不暴露于潜在黑客攻击的情况下进行分布式协同仿真，业界尚未达成一致的指导方针。本文研究了在UniFMU的基础上实现具有增强安全性和知识产权保护机制的分布式协同仿真方法，确保连接由客户端发起，并且模型和二进制文件存储在可信平台上。该研究在四种不同的网络配置下展示了一个具有双重知识产权保护和增强安全性的协同仿真示例，并分析了知识产权保护分布与性能效率之间的权衡关系。
### Innovation
提出了基于UniFMU的具有增强安全性和知识产权保护机制的分布式协同仿真方法，确保连接由客户端发起，模型和二进制文件存在于可信平台上，并通过两个协同仿真示例在四种不同网络配置下展示了该方法的功能，同时分析了知识产权保护分布与性能效率之间的权衡关系。
### Conclusion
通过基于FMI的方法实现了分布式协同仿真，并增强了安全性与知识产权保护，确保了连接发起的安全性，保护了模型和二进制文件的安全。展示了该方法在多种网络配置下的应用，并探讨了保护知识产权的效率与系统性能的关系。
## 1020. `cs.SE` - 设计一种安全可靠的分布式智能手机参与者数据收集系统 [PDF](https://arxiv.org/pdf/2510.19938), [HTML](https://arxiv.org/abs/2510.19938)
### Authors
Foad Namjoo,Neng Wan,Devan Mallory,Yuyi Chang,Nithin Sugavanam,Long Yin Lee,Ning Xiong,Emre Ertin,Jeff M. Phillips
### Background
现实世界中的健康研究需要从移动和可穿戴设备中连续和安全地收集数据。现有的系统往往缺乏在这种情境下的高效解决方案，尤其是在有限的电池寿命、不稳定的网络连接和较少用户监督的情况下。
### Innovation
MotionPI 是一款基于智能手机的设计，能够在尽量减少用户互动的情况下通过传感器和调查收集行为和健康数据。该系统将被动数据采集（如 GPS 和腕带运动数据）与生态时刻评估（EMA）调查相结合，这些调查可以随机触发或基于体力活动触发。MotionPI 能够在现实生活中的限制条件下（例如电池寿命有限、网络连接薄弱或间歇性、需要较少用户监督）工作。系统将数据存储在本地和安全的云端服务器上，并通过加密传输和存储。通过蓝牙低功耗技术（BLE），系统可以与存储原始数据的手环设备集成，发送运动汇总和触发事件。
### Conclusion
MotionPI 为在现实生活中进行符合人体工程学的、安全的和可扩展的移动数据收集提供了实际的解决方案。
## 1021. `cs.SE` - 受政策控制的RAG - 研究设计研究 [PDF](https://arxiv.org/pdf/2510.19877), [HTML](https://arxiv.org/abs/2510.19877)
### Authors
Jean-Marie Le Ray
### Background
本文提出了一个适用于受监管工作流程的审计-ready生成的RAG（检索-生成）架构。该架构通过合同/控制（类似于SHRDLU）、证明/轨迹（类似于Memex）和收据/验证（类似于Xanadu）三个模块组织，用于确保生成内容符合法律和内部政策，并且所有引用的证据都能被验证。目标应用领域包括制药、医疗设备、金融、法律和公共部门等领域，这些领域可能因错误而面临的成本高昂，并且法规如欧盟AI法案要求保留审计追踪。
### Innovation
本文的核心创新在于设计了一个政策控制下的RAG架构，该架构能够进行合规性检查、可重复使用以及带有收据背书的审计，通过预注册的NO-GO门限制输出内容，确保生成模型的输出是可以验证的，从而提高系统的透明度和可信度。
### Conclusion
本文提出的政策控制下的RAG架构已经在某些应用领域展示了潜在的优势，包括但不限于减少置信错误、保证95%的延迟不超过900毫秒、以及将服务成本降低两倍以上。该设计未来可能会针对任何未达标的例子承诺发布负面结果，进一步确保审计的透明度和结果的可信性。
## 1022. `cs.SE` - Java去多余代码工具的准确性和精确度基准测试 [PDF](https://arxiv.org/pdf/2510.20679), [HTML](https://arxiv.org/abs/2510.20679)
### Authors
Jonas Klauke,Tom Ohlmer,Stefan Schott,Serena Elisa Ponta,Wolfram Fischer,Eric Bodden
### Background
现代软件开发中通过导入库作为依赖来重用代码。软件项目通常包含约36个依赖项，其中80%是传递依赖，这意味着它们是依赖的依赖。近期研究表明，这些依赖项中只有24.9%在运行时是必需的，并且即使在这些必需依赖项中，很多程序构造也被忽略了。这导致了去多余代码工具的开发，这些工具在平衡准确性和完整性的前提下，去除不必要的依赖项和程序构造。为了系统评估这些权衡取舍，作者开发了Deblometer微基准测试，包含59个测例，用以评估去多余代码工具对各种Java语言特性的支持。每个测试案例包含一个手动验证的真实情况（ground truth），明确规定必要和多余的类、方法和字段，使得可以精确测量准确性和精确性。
### Innovation
作者开发了Deblometer，一个包含59个测试用例的微基准测试，目的是评估Java去多余代码工具对各种Java语言特性支持的准确性和精确性。每个测试用例中包含了一手验证的真实情况（ground truth），明确指出必要和多余的类、方法和字段。通过Deblometer，作者测试了三种流行的Java去多余代码工具：Deptrim、JShrink和ProGuard。研究表明，所有工具都会移除必要的程序构造，这导致了语义变化或执行崩溃。动态类加载特性在所有测试中都引入了不准确性。
### Conclusion
尽管所有去多余代码工具都移除了不必要的依赖和程序构造，但这导致了全部工具出现不准确性问题。Deptrim保留了更多的多余构造，而ProGuard移除过多必要的构造。JShrink的不准确性显著受到注解支持有限的影响，导致去多余代码后生成的文件被破坏。这些问题强调了需要改进去多余代码工具以确保稳定的可靠去多余代码软件的重要性。
## 1023. `cs.SE` - 探索大型语言模型在访问控制策略合成与总结方面的应用 [PDF](https://arxiv.org/pdf/2510.20692), [HTML](https://arxiv.org/abs/2510.20692)
### Authors
Adarsh Vatsa,Bethel Hall,William Eiers
### Background
随着云计算的普及，每天都有越来越多的服务托管在云平台上。传统的云计算系统允许管理员编写策略来实现访问控制规则，规定对私有数据的访问权限。然而，这些策略通常需要手动编写，并且由于其复杂性，容易出错。现有的策略往往实施复杂的访问控制需求，使得精确分析其工作方式变得非常困难。近年来，大型语言模型（LLMs）在自动化代码合成和总结方面取得了巨大成功，这引发了一种可能性，即它们可以用于自动生成访问控制策略或帮助理解现有策略。
### Innovation
本文探讨了大型语言模型在访问控制策略合成与总结方面的有效性。我们首先研究了不同类型的大型语言模型在访问控制策略合成中的应用，发现尽管一些能够有效生成语法正确的策略，但由于其宽松性，这些模型中有45.8%的情况会生成与给定规格等效的策略，而基于逻辑推理的模型中则有93.7%。然后，我们通过提出一种基于语义的请求总结方法来利用大型语言模型生成一个精确描述允许请求的策略特性来调查大型语言模型如何用于策略分析。我们的结果表明，虽然在利用大型语言模型进行自动策略生成方面存在显著障碍，但将大型语言模型与符号方法结合使用来分析现有策略时，取得了有希望的结果。
### Conclusion
尽管大型语言模型在自动访问控制策略生成方面存在挑战，但在结合符号方法分析现有策略时表现出令人鼓舞的结果。
## 1024. `cs.SE` - SecureInfer: 异构 TEE-GPU 架构用于大型语言模型部署中的隐私关键张量 [PDF](https://arxiv.org/pdf/2510.19979), [HTML](https://arxiv.org/abs/2510.19979)
### Authors
Tushar Nayan(1),Ziqi Zhang(2),Ruimin Sun(1) ((1) Florida International University, (2) University of Illinois Urbana-Champaign)
### Background
随着大型语言模型（LLMs）在移动和边缘平台上部署的增加，保护它们免受模型提取攻击的安全性变得尤为重要。然而，在不牺牲未信任AI加速器（如GPU）带来的性能优势的情况下保护模型隐私仍面临重大挑战。
### Innovation
我们提出了SecureInfer，一种混合框架，利用异构可信执行环境（TEEs）和GPU架构来隔离隐私关键组件，同时将计算密集型操作卸载到未信任加速器上。SecureInfer采用基于外包方案的信息理论和威胁导向分区策略，将安全敏感组件执行在SGX保护的环境内，并将其他线性操作在加密后于GPU上执行，然后在保护环境中安全恢复。
### Conclusion
我们的结果显示，SecureInfer提供了强大的安全保证，同时性能合理，提出了用于设备上安全模型推理的实用解决方案。
## 1025. `cs.SE` - ToolScope：通过工具有缝合并上下文感知过滤以增强LLM代理的工具使用 [PDF](https://arxiv.org/pdf/2510.20036), [HTML](https://arxiv.org/abs/2510.20036)
### Authors
Marianne Menglin Liu,Daniel Garcia,Fjona Parllaku,Vikas Upadhyay,Syed Fahad Allam Shah,Dan Roth
### Background
大型语言模型（LLM）代理依赖于外部工具来解决复杂的任务，但在实际世界中，工具集常常包含具有冗余且重叠名称和描述的工具，这会引起混淆并降低工具选择的准确性。此外，LLMs还面临着输入上下文长度的严格限制，这使得高效处理大型工具集变得困难。
### Innovation
该研究提出了一种名为ToolScope的方法，包括两个组件：（1）具有自动纠正功能的ToolScopeMerger，用于自动审计和修正工具合并，减少冗余；（2）ToolScopeRetriever，用于按相关性排名并选择每个查询中最相关的工具，从而压缩工具集以适应上下文限制而不损失准确性。
### Conclusion
对三个最先进的LLM和三个开源工具使用基准的评估显示，ToolScope在工具选择准确性上提高了8.38%到38.6%。这证明了ToolScope在增强LLM工具使用方面的有效性。
## 1026. `cs.SE` - 基于动态程序分析的Node.js包中传播流分类学习 [PDF](https://arxiv.org/pdf/2510.20739), [HTML](https://arxiv.org/abs/2510.20739)
### Authors
Ronghao Ni,Aidan Z.H. Yang,Min-Chien Hsu,Nuno Sabino,Limin Jia,Ruben Martins,Darion Cassel,Kevin Cheang
### Background
程序分析工具经常产生大量的候选漏洞报告，需要昂贵的手动审查，这给安全分析师带来了挑战，如何优先处理那些最有可能是真正漏洞的报告。本文探讨了是否可以利用机器学习来优先处理程序分析工具报告的漏洞。
### Innovation
本文收集了1,883个Node.js包的数据集，每个包包含一个报告的漏洞。研究了多种机器学习方法，包括经典模型、图神经网络（GNN）、大型语言模型（LLMs）以及结合GNN和LLMs的混合模型。基于动态程序分析工具的结果数据进行训练。利用大型语言模型（LLMs）实现了最高的$F_{1} = 0.915$，而最好GNN和经典ML模型达到了$F_{1} = 0.904$。在不到7%的假阴性率下，领先模型从需要手动审查的包中消除了66.9%，平均每包处理时间为60毫秒。
### Conclusion
在99.2%的可利用污染流检测率下，而假阳性率为0.8%，本文方法在真实世界的漏洞分类中显示出强大的潜力。
## 1027. `cs.SE` - 开发团队多久更新其易受攻击的依赖项？ [PDF](https://arxiv.org/pdf/2403.17382), [HTML](https://arxiv.org/abs/2403.17382)
### Authors
Imranur Rahman,Ranindya Paramitha,William Enck,Laurie Williams
### Background
随着软件中包含易受攻击的第三方依赖项（直接和间接）的数量不断增加，行业从业人员越来越关注这一问题。为此，研究者提出了响应度量标准来衡量开发团队更新其依赖项的速度：Mean-Time-To-Update (MTTU) 和 Mean-Time-To-Remediate (MTTR)。然而，当前的度量标准未能捕捉到重要细节，比如玩忽职守版本和优先更新最近版本，因此无法准确反映开发团队的更新实践。
### Innovation
本文提出了两个新的度量标准，即 Mean-Time-To-Update for dependencies (MTTU) 和 Mean-Time-To-Remediate for vulnerable dependencies (MTTR)，旨在克服现有度量标准的局限性。研究在 npm、PyPI 和 Cargo 中使用数万个包进行实证分析，探讨了生态系统在 MTTU 和 MTTR 方面的差异，还研究了哪些包属性影响了 MTTU 和 MTTR。结果显示，大多数包的依赖项更新实践相对较快。此外，本文还探讨了在缺乏漏洞数据时 MTTU 是否可以作为 MTTR 的替代指标。尽管未发现足够的统计证据支持作为强替代指标，但在缺乏漏洞数据时 MTTU 可以作为部分替代指标使用（但应谨慎使用）。
### Conclusion
该研究表明，大多数包的依赖项更新实践相对较快。虽然 MTTU 可以部分替代 MTTR 作为衡量凭证，但在没有足够的漏洞数据时，使用 MTTU 作为 MTTR 的替代指标时应谨慎。
## 1028. `cs.SE` - Faiss库 [PDF](https://arxiv.org/pdf/2401.08281), [HTML](https://arxiv.org/abs/2401.08281)
### Authors
Matthijs Douze,Alexandr Guzhva,Chengqi Deng,Jeff Johnson,Gergely Szilvasy,Pierre-Emmanuel Mazaré,Maria Lomeli,Lucas Hosseini,Hervé Jégou
### Background
矢量数据库通常管理大量嵌入向量集合。随着AI应用的快速发展，需要存储和索引的嵌入数量也在不断增加。Faiss库专门用于向量相似性搜索，这是矢量数据库的核心功能之一。Faiss是一个索引方法工具包和相关基础结构，用于搜索、聚类、压缩和转换向量。
### Innovation
本文描述了向量搜索的权衡空间，并从结构、优化方法和接口方面阐述了Faiss的设计原则。还对库的关键功能进行了基准测试，并讨论了几种选定的应用，以突出其广泛适用性。
### Conclusion
本文基于结构、优化方法和接口设计方面介绍了Faiss库的设计原理，并对库的关键功能进行了基准测试，通过几个应用展示其广泛适用性。
## 1029. `cs.SE` - 为神经策略合成高效且宽松的程序化运行时屏蔽 [PDF](https://arxiv.org/pdf/2410.05641), [HTML](https://arxiv.org/abs/2410.05641)
### Authors
Jieke Shi,Junda He,Zhou Yang,Đorđe Žikelić,David Lo
### Background
随着神经网络政策在控制系统中的应用日益增多，确保其安全性和可靠性已成为关键的软件工程任务。现有方法通常部署程序化的运行时遮罩来纠正神经策略的不安全命令，但这些遮罩或者计算成本过高，或者过于苛刻，导致系统效率低下且频繁中断。
### Innovation
本文提出了一种名为Aegis的新框架，它能够为神经策略合成轻量级且宽松的程序化运行时遮罩。Aegis通过将寻找运行时遮罩的问题定义为基于草图的程序合成问题，并利用反例引导归纳合成和贝叶斯优化来解决该问题来实现这一目标。Aegis的遮罩在时间开销和内存使用方面比现有最先进的方法分别减少了2.2倍和3.9倍，且平均每种处理器少发生1.5倍的干预，证明了更好的宽松性。
### Conclusion
Aegis合成了能够纠正所有神经策略不安全命令的程序化运行时遮罩，确保系统在所有时间都不违反任何期望的安全属性。相比于现有的最新技术，Aegis的遮罩在时间开销和内存使用上均有显著优化，且更加宽松有效。
## 1030. `cs.SE` - 利用多语言语言模型对工业C#项目进行微调：一项实证研究 [PDF](https://arxiv.org/pdf/2507.19271), [HTML](https://arxiv.org/abs/2507.19271)
### Authors
Igli Begolli,Meltem Aksoy,Daniel Neider
### Background
代码审查对维持软件质量至关重要，但在工业环境中常常耗时且认知负担重。近年来，语言模型的进步为自动化核心审查任务开辟了新的途径。本文通过实证研究考察了一种单语言微调方法，评估了开源语言模型在三个关键的自动化代码审查任务（代码更改质量估计、审查评论生成和代码改进）上的性能。
### Innovation
研究采用了单语言微调方法，对三个不同的模型（CodeReviewer、CodeLlama-7B、DeepSeek-R1-Distill）进行了微调，数据集包括公共基准和工业存储库中的C#特定数据。研究还探讨了不同类型编程语言和自然语言在训练数据中的配置对语言模型性能，特别是评论生成的影响。此外，对比了微调后的模型与自动化软件分析工具（ASAT）和人工审查员的基准测试，以评估其在实际环境中的实用价值。
### Conclusion
实验证明，单语言微调比多语言基线提高了模型的准确性和相关性。尽管语言模型能够有效支持代码审查流程，尤其是在日常工作或重复任务中，人类审查员在处理语义复杂或上下文敏感变化方面仍然优于这些模型。研究强调了语言对齐和任务特定适应性在优化自动化代码审查语言模型方面的重要性。
## 1031. `cs.SE` - LLMs在自认技术债务分类自动化的进展如何？ [PDF](https://arxiv.org/pdf/2506.09601), [HTML](https://arxiv.org/abs/2506.09601)
### Authors
Sota Nakashima,Yuta Ishimoto,Masanari Kondo,Tao Xiao,Yasutaka Kamei
### Background
自认技术债务（SATD）是指开发人员故意引入的、降低软件质量的次优化代码。通常，构建SATD分类体系需要手动检查SATD注释及其周围的代码，这一过程耗时、劳动密集，并且由于注释者的主观性而常不一致。已有研究表明，这使得分类工作效率低下且不一致。研究者们希望通过大型语言模型（LLMs）来提高这一过程的自动化水平，从而提高效率并减少主观偏差。
### Innovation
本文设计了一个结构化的、由LLM驱动的流程，旨在模仿研究人员通常遵循的分类构建步骤。该研究在量子软件、智能合约以及机器学习三个领域中测试了这一方法。该方法成功地恢复了先前工作中报告的领域特定类别，如机器学习中的层配置，并在不到两小时内生成了分类体系，成本低于1美元，即使在最大数据集上也是如此。这是对LLMs在SATD分类自动化方面的一项重要进步。
### Conclusion
尽管完全自动化仍然具有挑战性，但本文的实验表明，大型语言模型（LLMs）能够支持半自动的SATD分类构建。此外，本项工作为未来自动分类生成在其他领域的应用开辟了新的可能性。
## 1032. `cs.SE` - LLM驱动自主系统软件工程中的基准与解决方案全面调研 [PDF](https://arxiv.org/pdf/2510.09721), [HTML](https://arxiv.org/abs/2510.09721)
### Authors
Jiale Guo,Suizhi Huang,Mei Li,Dong Huang,Xingsheng Chen,Regina Zhang,Zhijiang Guo,Han Yu,Siu-Ming Yiu,Pietro Lio,Kwok-Yan Lam
### Background
大语言模型（LLMs）在软件工程中的集成推动了从传统基于规则的系统向能够解决复杂问题的自主代理系统的转变。但系统性的进展受到缺乏基准和解决方案相互连接全面理解的影响。为了填补这一空白，本文通过梳理150多篇最近的论文，提供了一个全面的分析，揭示了评估方法和解决方案范式的见解。该研究展示了从简单的提示工程到包含规划、推理、记忆机制和工具增强的复杂代理系统的演变过程。
### Innovation
1. 提出了一个涵盖解决方案和基准的分类体系，其中解决方案分为基于提示、微调和代理范式，并将50多种不同的基准与相应的方法策略相联系，帮助研究人员识别适合多样化评估标准的最佳方法。2. 指出了研究中的关键缺口，并提出了未来的研究方向，包括多代理协作、自进化系统和形式验证的集成。3. 提供了一个统一的工作流程示例，展示了从任务规范到交付成果的全流程，详细说明了不同解决方案范式如何应对各种复杂度层次的问题。
### Conclusion
本文作为一个基础指南，旨在促进LLM驱动下的软件工程发展。同时，维护了一个GitHub仓库，实时更新已审查和相关论文的信息。
## 1033. `cs.SE` - 在高性能软件系统中检测和预防潜在风险累积 [PDF](https://arxiv.org/pdf/2510.03712), [HTML](https://arxiv.org/abs/2510.03712)
### Authors
Jahidul Arafat,Kh.M. Moniruzzaman,Shamim Hossain,Fariha Tasmin
### Background
现代分布式系统采用了激进的优化策略，这些策略造成了隐性的风险——当优化失效时，高隐藏漏洞将因性能异常而被掩盖，暴露出灾难性的脆弱性。高缓存层的缓存命中率可以掩盖数据库瓶颈，直到缓存失效导致负载放大100倍并引发级联崩溃。当前的可靠性工程主要集中于反应式的事故响应，而不是对优化引发的漏洞进行主动检测。
### Innovation
本文提出了第一个全面框架，通过集成数学建模、智能扰动测试和风险意识性能优化来系统性地检测、预防和优化潜在风险。创新点包括引入了隐性风险指数（LRI），其与事故严重性高度相关（r=0.863, p<0.001），能够预测风险；提出整合了三项系统的框架：HYDRA（采用6种优化感知扰动策略，发现风险率为89.7%），RAVEN（在1,748个场景中具有92.9%的精度和93.8%的召回率）和APEX（保持96.6%的基准性能，降低了59.2%的隐性风险）。以上方法在三个试验环境中实现了显著的统计验证和高度的可再现性，在生产部署中展示了显著的性能提升。
### Conclusion
该方法将可靠性工程从被动的事故管理转变为主动的风险意识优化，减少了平均恢复时间、事故严重度和预防事故的数量，产生了显著的年度经济效益，预期回报期为3.2个月。
## 1034. `cs.SE` - pinning 或浮动哪种更好用于减少过时和易受攻击的依赖项？ [PDF](https://arxiv.org/pdf/2510.08609), [HTML](https://arxiv.org/abs/2510.08609)
### Authors
Imranur Rahman,Jill Marley,William Enck,Laurie Williams
### Background
开发者经常使用版本约束来指定项目依赖项的可接受版本。固定依赖项可以减少发生重大变更的可能性，但会带来手动管理过时和易受攻击的依赖项替换的代价。浮动依赖项则可以自动获取补丁更新和安全修复程序，但会带来发生重大变更的风险。尽管安全从业者提倡固定依赖项以防止软件供应链攻击（例如恶意包更新），但固定依赖项通常是最容易导致依赖项过时的类型。尽管如此，不同版本约束类型下依赖项变过时或易受攻击的可能性变化仍然未知。本研究旨在通过大规模实证评估，帮助开发者基于依赖项版本约束类型了解它们变过时或易受攻击的可能性，从而做出知情选择。
### Innovation
研究通过在 npm、PyPI 和 Cargo 生态系统中识别依赖项版本约束使用趋势和版本约束类型变化的模式，首次使用生存分析建模依赖项状态转换，并估计使用固定约束与使用其他版本约束类型相比，依赖项变过时或易受攻击的可能性如何变化。研究发现，在常见版本约束类型中，浮动次要版本是最频繁使用且最不易导致过时的，而固定依赖项是最易导致过时的；浮动主要版本则是最不易导致依赖项过时的。这表明对减少依赖项过时性和易受攻击性而言，浮动次要版本比固定依赖项更为有效。
### Conclusion
在实际开发过程中，开发者应当注意选择浮动次要版本的依赖项以最大限度减少版本依赖问题，以及利用固定依赖项的简便性和浮动主要版本的安全性与效率平衡，做出更合理的版本约束选择。
## 1035. `cs.SE` - CodeFuse-CR-Bench: 一种针对Python项目的端到端代码审查综合评估基准 [PDF](https://arxiv.org/pdf/2509.14856), [HTML](https://arxiv.org/abs/2509.14856)
### Authors
Hanyang Guo,Xunjin Zheng,Zihan Liao,Hang Yu,Peng DI,Ziyin Zhang,Hong-Ning Dai
### Background
现有的代码审查基准主要评估模型在孤立子任务上的表现，使用简化且缺乏上下文的数据。这种评估方式无法反映真实世界代码审查的全面性和复杂性。为了弥合这一差距，研究人员引入了CodeFuse-CR-Bench，这是一个针对代码仓库级别的代码审查全面性感知的基准。该基准包含来自70个Python项目的601个高质量实例，涵盖了九个pull请求问题领域，每个实例提供了丰富而多面的上下文信息，包括相关问题、PR详情和仓库状态，从而实现端到端的评估。
### Innovation
CodeFuse-CR-Bench 引入了第一个针对代码仓库级别的代码审查全面性感知基准。相比前人的工作，它包含了更丰富的上下文信息和多维度评估框架，结合基于规则的检查和模型驱动的判断来评估代码审查质量。此外，该项工作对最先进的大型语言模型进行了大规模评估，并揭示了不同模型在冗余上下文中的鲁棒性差异。
### Conclusion
研究表明，没有单一的模型可以主导代码审查的所有方面；Gemini 2.5 Pro在整体性能上表现最佳；不同模型之间在对冗余上下文的鲁棒性上存在差异。这些发现强调了进行全面、多维度评估的必要性，并为开发真正智能且实用的代码审查助理提供了可行的指导。
## 1036. `cs.SE` - CLEVER: 一个正式验证代码生成的精心筛选基准 [PDF](https://arxiv.org/pdf/2505.13938), [HTML](https://arxiv.org/abs/2505.13938)
### Authors
Amitayush Thakur,Jasper Lee,George Tsoukalas,Meghana Sistla,Matthew Zhao,Stefan Zetzsche,Greg Durrett,Yisong Yue,Swarat Chaudhuri
### Background
此前并未有高质量且彻底验证的基准来评估端到端的代码生成在Lean系统中的表现。大多数现有基准存在一些问题，如监督测试案例、LLM生成的注解、暴露实施逻辑的规范以及允许空解的规范，这都使得评估结果不够准确和可靠。
### Innovation
提出了一个名为${rm C{tiny LEVER}}$的基准，它包含161个问题，每个问题由生成符合未见的规范的规范和生成满足这些规范的无错误形式化代码两部分组成。所有输出都使用Lean的类型检查器进行事后验证，以确保机器可验证的正确性。${rm C{tiny LEVER}}$基准没有上述问题，使得它成为一个具有挑战性的前沿基准，用于程序合成和形式化推理。
### Conclusion
研究利用${rm C{tiny LEVER}}$基准评估了多种基于最先进的语言模型的少量提示和代理方法。这些方法在实现完全验证方面都遇到困难，证实了${rm C{tiny LEVER}}$对于程序合成和形式推理具有挑战性。基准可在GitHub(this https URL)和HuggingFace(this https URL)上找到，所有评估代码也在GitHub(this https URL)上公开提供。
## 1037. `cs.SE` - 学会的经验：一种代码LLM多代理框架以学习和改进 [PDF](https://arxiv.org/pdf/2505.23946), [HTML](https://arxiv.org/abs/2505.23946)
### Authors
Yuanzhe Liu,Ryan Deng,Tim Kaler,Xuhao Chen,Charles E. Leiserson,Yao Ma,Jie Chen
### Background
最近的研究表明，语言模型（LLMs）具备不同的技能，并且擅长不同的任务。实际上观察到，它们在多种粒度级别的表现各异。例如，在代码优化任务中，代码LLMs在不同的优化类别中表现优异，没有一个模型能够主导其他模型。这种观察促使研究人员思考如何利用多个未知互补优势的LLM代理来解决编程问题。先前的工作已经表明，多LLM协作方法需要了解各自的专长，但本文提出的方法可以在不知道互补优势的情况下实现这一目标。该论文探讨了代理团队如何通过互相学习彼此的成功与失败来提升自己的性能，并提出了一种基于教训的协作框架，设计了教训的请求-储存-选择机制。
### Innovation
本文提出了一个基于教训的多代理框架，该框架设计了一个教训请求-储存-选择机制。该方法可以在没有预先知道各代理专长的情况下，通过代理团队互相学习彼此的成功与失败来提升各自的表现。这种多代理框架能够表现出色，甚至超过了较大的单一代理模型和其他多代理模型协作方法。
### Conclusion
通过设计的基于教训的多代理协作框架，代理团队能够在无需预先了解各自专长的前提下，通过相互学习来提高整体性能。实验结果表明，小型代理模型团队在学习了教训后，可以超越单一大型代理模型和其他多代理模型协作方法。
