{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23734", "html_url": "https://arxiv.org/abs/2510.23734", "title": "AI and the Decentering of Disciplinary Creativity", "title_en": "AI and the Decentering of Disciplinary Creativity", "authors": "Eamon Duede", "background": "该论文探讨了人工智能在科学问题解决中的作用及其对学科创造力的影响。它基于最近在创造力哲学中的研究成果，区分了创造力的方法和创造性的产品，并引入了学科创造力的概念，即特定学科专业知识的创造性应用来解决该领域的有价值问题。", "innovation": "论文通过对数学案例的分析，展示了计算可以扩展学科创造力，但某些涉及人工智能的方法可能会取代它。这种取代可能会改变甚至降低科学追求的价值。", "conclusion": "人工智能有可能改变（甚至降低）学科创造力的价值，某些涉及AI的做法可能会取代学科创造力的作用。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23824", "html_url": "https://arxiv.org/abs/2510.23824", "title": "使用大型语言模型的分布式多智能体目标分配用于路径规划", "title_en": "Decentralized Multi-Agent Goal Assignment for Path Planning using Large Language Models", "authors": "Murad Ismayilov,Edwin Meriaux,Shuo Wen,Gregory Dudek", "background": "在机器人学和人工智能领域，协调多个自主代理在共享环境下的任务分配和路径规划是一个长期存在的挑战，尤其是在分中心化条件下。研究集中在多智能体路径规划中的分布式目标分配问题，其中智能体根据环境的结构化表示（如网格可视化和场景数据）独立地生成它们的目标优先级。", "innovation": "这项工作提出了将大型语言模型（LLM）应用于多智能体路径规划中的分布式目标分配。智能体在推理阶段生成目标优先级后，通过固定的、确定性的冲突解决规则（如按代理索引顺序）进行目标分配，无需谈判或迭代协调。研究系统比较了贪婪启发式、最优分配和基于LLM的智能体在完全可观测网格世界环境中的性能，结果显示基于LLM的智能体在适当设计提示和相关信息的支持下，可以达到接近最优的周转时间并且持续优于传统启发式方法。", "conclusion": "研究结果强调了语言模型在分布式多智能体路径规划中执行目标分配的潜力，并突出了信息结构在这些系统中的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23772", "html_url": "https://arxiv.org/abs/2510.23772", "title": "评价虚拟环境中的创造性：AI国际象棋创作的专家评审", "title_en": "Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions", "authors": "Vivek Veeriah,Federico Barbero,Marcus Chiam,Xidong Feng,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Johan Obando-Ceron,Jiaxin Shi,Shaobo Hou,Satinder Singh,Nenad Tomašev,Tom Zahavy", "background": "随着生成式AI的迅速发展，关于其生成创新性和新颖性输出的能力引发了广泛关注。本文在国际象棋谜题领域开展了相关研究，旨在开发一种能够生成具备美学吸引力、新奇性和独特解法的AI系统。为了评估该系统的创造力，研究者向三位世界知名的国际象棋专家展示了AI生成的谜题书籍，通过他们的选择与评价来检验系统的创意水平。这三位专家都是国际象棋美学领域的作者，对计算机在游戏中的角色演变有深入研究。", "innovation": "本文介绍了一种针对国际象棋谜题领域的AI系统，该系统能够生成具备美学吸引力、新奇性和独特解法的谜题。研究通过国际象棋专家的评价来检验系统的创造力，这是对现有技术的一大创新。", "conclusion": "研究中,AI系统生成的国际象棋谜题得到了三位知名专家的认可，部分作品因其创意、挑战性或美学设计获得了好评。这证明了AI在生成高素质、有创意的国际象棋谜题方面的潜力。未来该技术有望应用到其他创意领域，进一步探索AI在促进人类创造力和艺术创新方面的可能性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23822", "html_url": "https://arxiv.org/abs/2510.23822", "title": "ReCAP：大型语言模型代理的递归上下文感知推理与规划", "title_en": "ReCAP: Recursive Context-Aware Reasoning and Planning for Large Language Model Agents", "authors": "Zhenyu Zhang,Tianyi Chen,Weiran Xu,Alex Pentland,Jiaxin Pei", "background": "长时程任务需要多步推理和动态重新规划，这对大型语言模型（LLMs）来说仍然极具挑战性。顺序提示方法容易出现语境漂移、目标信息丢失和反复失败的循环问题，而分层提示方法则常常削弱不同层级之间的连贯性或造成显著的运行时开销。", "innovation": "提出了ReCAP（Recursive Context-Aware Reasoning and Planning），一种具有共享上下文的分层框架，用于LLMs中的推理和规划。ReCAP机制包括：(i) 先行分解计划，在模型生成整个子任务列表的同时执行第一步并精炼剩余部分；(ii) 有组织地重新注入父计划，确保在递归返回时多层级上下文的一致性；(iii) 记忆高效执行，限制活跃提示的大小，使得成本与任务深度线性增长。这些机制使高层目标与低级行动保持一致，减少了重复提示，并保持了递归过程中上下文的连贯更新。", "conclusion": "实验表明，ReCAP在各种长时程推理基准上的子目标对齐性和成功率都得到了显著提升，在同步Robotouille上的表现提升了32%，在异步Robotouille上的表现提高了29%，特别是在严格的一次通过协议下。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23881", "html_url": "https://arxiv.org/abs/2510.23881", "title": "生成创新性的棋盘谜题", "title_en": "Generating Creative Chess Puzzles", "authors": "Xidong Feng,Vivek Veeriah,Marcus Chiam,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Federico Barbero,Johan Obando-Ceron,Jiaxin Shi,Satinder Singh,Shaobo Hou,Nenad Tomašev,Tom Zahavy", "background": "尽管生成式人工智能在多个领域迅速进步，但生成真正具有创意、美观和反直觉的输出仍然是一个挑战。本文通过基准测试生成式人工智能架构，并结合一种基于国际象棋引擎搜索统计数据的新颖奖励机制，提出了一种解决国际象棋谜题领域问题的方法。这种方法在谜题的独特性、反直觉性、多样性和现实性方面有所提升。", "innovation": "本文引入了一种基于强化学习（RL）框架的方法，通过设计新的奖励机制来克服生成式人工智能的局限性。这种方法使得反直觉谜题的生成效率提高了10倍，从0.22%（监督式学习）提升到了2.5%，远超现有数据集和最优秀的Lichess训练模型（分别为2.1%和0.4%）。生成的谜题在新颖性和多样性方面达到标准，保持了审美主题，并且被人类专家评为比书籍谜题更具创意、更有乐趣和反直觉，甚至接近经典作品的水平。最终，生成的谜题被三位世界著名专家认可其创造性，这些谜题被整理成一本精心编排的书。", "conclusion": "通过这种强化学习和新颖奖励机制相结合的方法，文章实现了生成创新性的国际象棋谜题，这些谜题不仅在技术上具有突破，还在人类专家和领域内的认可度上有所提升，标志着在生成式人工智能领域的一个重要进展。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23746", "html_url": "https://arxiv.org/abs/2510.23746", "title": "测试时调优的语言模型使从MS/MS光谱生成从头开始的分子结构成为可能", "title_en": "Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra", "authors": "Laura Mismetti,Marvin Alberts,Andreas Krause,Mara Graziani", "background": "串联质谱能够识别代谢组学、天然产物发现和环境分析中未知化合物，但现有方法依赖于数据库匹配已观察的分子，或需要多步骤流程进行中间片段或指纹预测，这使得正确识别分子变得非常具有挑战性，特别是对于不在参考数据库中的化合物。", "innovation": "我们提出了一种框架，通过利用测试时调优来提升预训练的变压器模型的学习能力，以弥补这一差距，从而直接从串联质谱和分子式生成从头开始的分子结构，绕过了手动注释和中间步骤。我们在这两个流行的基准测试NPLIB1和MassSpecGym上的表现分别优于现有的事实上的最佳方法DiffMS100%和20%。在实验光谱的测试时调优使模型能够动态适应新的光谱，与常规微调相比，在MassSpecGym上的相对性能改进为62%。即使预测与真实值偏离，生成的分子候选也保持结构准确性，为人类解释和更可靠的识别提供了有价值的指导。", "conclusion": "我们的框架使从头开始直接从MS/MS光谱生成分子结构成为可能，显著提高了识别的准确性，特别是在处理参考数据库中不存在的化合物时。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23856", "html_url": "https://arxiv.org/abs/2510.23856", "title": "从基准到企业影响力：IBM通用代理在企业生产中的部署", "title_en": "From Benchmarks to Business Impact: Deploying IBM Generalist Agent in Enterprise Production", "authors": "Segev Shlomov,Alon Oved,Sami Marreed,Ido Levy,Offer Akrabi,Avi Yaeli,Łukasz Strąk,Elizabeth Koumpan,Yinon Goldshtein,Eilam Shapira,Nir Mashkif,Asaf Adi", "background": "智能体在自动化数字工作方面正在迅速发展，但企业面临的挑战是如何将这些原型转换为能够提供可量化商业价值的部署系统。这一过程受到了架构碎片化、开发缓慢以及缺乏标准化评估实践的阻碍。通用型智能体作为一种新兴方向，能够在学术基准测试中表现优异，并具有跨任务类型、应用和模态的灵活性，但在实际生产型企业场景中的应用证据仍然有限。", "innovation": "本文报道了IBM开发并试点的通用代理Agent（CUGA）的经验。CUGA采用了一种分层规划执行者架构，并引入了一种名为BPO-TA的26任务基准测试，涵盖13个分析端点。CUGA在AppWorld和WebArena上达到了领先性能，并在业务流程外包人才获取领域进行了试点，以满足企业对可扩展性、可审计性、安全和治理的需求。研究显示，CUGA在准确度接近专门代理的同时，显示出减少开发时间和成本的潜力。此外，该研究还提供了从初步试点中提炼的技术和组织教训，并提出了进一步将CUGA这类研究级架构转化为企业级系统的必要条件和下一步措施。", "conclusion": "我们通过展示通用代理在企业规模上的初步证据，和从中提炼的技术及组织经验教训，对这种前沿技术的实际应用进行了探索。接下来的研究和开发工作需要解决安全、可审计性、企业需求和治理等问题，以推动类似CUGA的架构发展为成熟的、企业可采用的系统。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23744", "html_url": "https://arxiv.org/abs/2510.23744", "title": "多环境POMDP：在部分可观测性下的离散模型不确定性", "title_en": "Multi-Environment POMDPs: Discrete Model Uncertainty Under Partial Observability", "authors": "Eline M. Bovy,Caleb Probine,Marnix Suilen,Ufuk Topcu,Nils Jansen", "background": "标准POMDP（部分可观测马尔可夫决策过程）已经考虑了部分可观测性问题，但无法处理离散的模型不确定性。ME-POMDPs（多环境POMDPs）扩展了POMDPs，引入了模型不确定性，表示一系列共享相同状态、操作和观测空间但可能在转移、观测和奖励模型上有显著差异的POMDPs集合。这种模型不确定性在多个领域专家对某一问题建模有分歧时会出现。目标是找到一个能抵抗任何POMDP选择的鲁棒策略，即最大化所有POMDP的最坏情况奖励。当前研究方法首先将ME-POMDPs扩展为具有初始信念集合的POMDPs（称为对抗性信念POMDPs，AB-POMDPs），其次证明了任何ME-POMDP都可以被简化为仅在转移和奖励函数或观测和奖励函数方面变化的ME-POMDP，并保留了最优策略。最后，研究团队开发了精确和近似（基于点的方法）算法来计算AB-POMDPs和ME-POMDPs的鲁棒策略。这表明可以计算出适用于标准POMDP基准扩展到多环境设置的策略。", "innovation": "将ME-POMDPs扩展为AB-POMDPs，证明了任何ME-POMDP都可以被简化为仅在转移和奖励函数或观测和奖励函数方面变化的形式，同时保留了最优策略，并开发了精确和近似算法来计算这些环境下的鲁棒策略。", "conclusion": "通过开发新的扩展和简化技术以及算法，能够处理在部分可观测性和多个不确定性模型下的决策问题。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23807", "html_url": "https://arxiv.org/abs/2510.23807", "title": "病理学中的基础模型为何失败", "title_en": "Why Foundation Models in Pathology Are Failing", "authors": "Hamid R. Tizhoosh", "background": "在非医学领域，基础模型（FMs）通过大规模自我监督和多模态学习已经彻底改变了计算机视觉和语言处理。因此，人们普遍认为这些模型在计算病理学中的快速应用将带来癌症诊断、预后和多模态检索的突破性进展。然而，近期的系统性评估揭示了基础模型存在根本性的弱点，包括低诊断准确性、较差的鲁棒性、几何不稳定、计算需求大以及安全漏洞等问题。这篇短论文指出这些缺陷来自于基础建模假设与人类组织内在复杂性之间的根本性概念不匹配，并进一步详细分析了问题根源，包括生物复杂性、效果不佳的自我监督、过度泛化、过多的架构复杂性、缺乏领域特定创新、数据不足以及与组织切片大小相关的根本设计缺陷等因素。这些发现表明，当前的病理学基础模型仍然与组织形态的性质在概念上不一致，需要从根本上重新思考这一范式本身。", "innovation": "识别了七个基础模型在病理学领域未能成功的主要原因：生物复杂性、无效自我监督、过度泛化、架构复杂性、缺乏领域特定创新、数据不足以及组织切片大小的根本设计缺陷，提出了从基础建模到病理学特定领域的根本性再思路径。", "conclusion": "当前病理学基础模型仍存在偏差，与组织形态的性质不一致，需要从根本上重新思考基础模型在病理学领域的应用路径。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23883", "html_url": "https://arxiv.org/abs/2510.23883", "title": "Agentic AI安全：威胁、防御、评估和开放挑战", "title_en": "Agentic AI Security: Threats, Defenses, Evaluation, and Open Challenges", "authors": "Shrestha Datta,Shahriar Kabir Nahin,Anshuman Chhabra,Prasant Mohapatra", "background": "大型语言模型（LLMs）驱动的具备规划能力、工具使用、记忆和自主性的代理型AI系统正在成为自动化领域的强大平台。这些系统在跨网络、软件和物理环境自主执行任务的能力创造了新的和增强的安全风险，这些风险不同于传统AI安全和常规软件安全。", "innovation": "本文概述了特定于代理型AI的威胁分类，回顾了最新的基准和评估方法，并从技术和治理两个角度讨论了防御策略。文章综合当前研究并突显了开放挑战，旨在支持设计安全的代理系统的发展。", "conclusion": "本文总结了现有研究的成果和当前面临的开放挑战，提供了从技术与治理两个方面来保障代理型AI系统的安全性的视角和方法，为未来的代理型AI系统的安全设计提供了指导和建议。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23925", "html_url": "https://arxiv.org/abs/2510.23925", "title": "视觉推理中的隐含推理", "title_en": "Latent Chain-of-Thought for Visual Reasoning", "authors": "Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao", "background": "Chain-of-thought (CoT) reasoning 对提高大型视觉语言模型 (LVLMs) 的可解释性和可靠性至关重要。然而，现有的训练算法如SFT、PPO和GRPO在跨未知推理任务时可能表现不佳，并且严重依赖于偏见的奖励模型。", "innovation": "本文通过将LVLMs中的推理重新表述为后验推断，并提出了一种基于近似变分推断的可扩展训练算法来解决这一挑战。此外，通过使用多样性寻求的强化学习算法，引入了一种新颖的稀疏奖励函数，可以鼓励多样性的、高可能性的潜在CoT，并通过贝叶斯推理比例策略替代了昂贵的Best-of-N和Beam Search，以高效地排名最优结论和答案。", "conclusion": "实验证明，所提出的方法在七个推理基准上提升了最先进的LVLMs，特别是在效果、泛化能力和可解释性方面。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23691", "html_url": "https://arxiv.org/abs/2510.23691", "title": "Game-TARS: 预训练基础模型为可扩展的泛用型多模态游戏代理", "title_en": "Game-TARS: Pretrained Foundation Models for Scalable Generalist Multimodal Game Agents", "authors": "Zihao Wang,Xujing Li,Yining Ye,Junjie Fang,Haoming Wang,Longxiang Liu,Shihao Liang,Junting Lu,Zhiyong Wu,Jiazhan Feng,Wanjun Zhong,Zili Li,Yu Wang,Yu Miao,Bo Zhou,Yuanfan Li,Hao Wang,Zhongkai Zhao,Faming Wu,Zhengxuan Jiang,Weihao Tan,Heyuan Yao,Shi Yan,Xiangyang Li,Yitao Liang,Yujia Qin,Guang Shi", "background": "本文介绍了Game-TARS，这是一种通过统一和可扩展的动作空间进行训练的一般游戏代理，该动作空间与人类对齐的键盘-鼠标输入联系紧密。不同于基于API或GUI的方法，这种方式使跨不同领域（如操作系统、网页和模拟游戏）的大规模持续预训练成为可能。Game-TARS 使用超过5000亿个标记进行了预训练，涵盖了多样轨迹和多模态数据。实验表明，与上一代最佳模型相比，Game-TARS 在开放式minecraft任务中的成功率提高了近两倍，接近未见过的3D网页游戏的新鲜人类的一般性，并在FPS基准中优于GPT-5、Gemini-2.5-Pro和Claude-4-Sonnet。训练时间和测试时间的扩展结果显示，统一的动作空间在跨游戏和多模态数据上持续改进。研究表明，简单的可扩展动作表示结合大规模预训练为具备广泛计算机使用能力的通用代理提供了有希望的路径。", "innovation": "Game-TARS采用统一、可扩展的动作空间，基于人类对齐的键盘-鼠标输入训练。这种方法允许跨OS、网页和模拟游戏的大型持续预训练。关键技术包括衰减的持续损失以减少因果混淆，并采用高效稀疏思考策略来平衡推理深度和推理成本。实验结果表明，Game-TARS在开放式minecraft任务中的成功率远超过上一代最佳模型，在未见过的3D网页游戏中接近新鲜人类的一般性，并且在FPS基准中优于GPT-5、Gemini-2.5-Pro和Claude-4-Sonnet。", "conclusion": "统一的动作空间使跨游戏和多模态数据的大型预训练变得可能，并且简单可扩展的动作表示与大规模预训练结合为跨领域游戏代理的能力提供了有希望的路径。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23942", "html_url": "https://arxiv.org/abs/2510.23942", "title": "使用柔道算子的去中心化因果发现", "title_en": "Decentralized Causal Discovery using Judo Calculus", "authors": "Sridhar Mahadevan", "background": "在生物学、医学和社会科学等实际应用中，因果效应取决于不同的条件，如年龄、国家、剂量、基因型或实验协议。现有因果发现方法通常缺乏并在不同条件下的局部有效性，本研究提出了一种以柔道算子为基础的去中心化因果发现框架，利用拓扑学中的覆盖概念，将因果断言以局部真命题的形式进行形式化，确保这些断言在特定条件下有效。", "innovation": "本研究提出了将柔道算子与传统因果发现方法相结合的去中心化框架，使用judo calculus基于覆盖的局部真理性，定义因果声明的有效性。通过利用拓扑学中的托普学（topos of sheaves）集合概念，开发了一种新的去中心化因果推理方法，结合了评分法、约束法和梯度法，提高了计算效率和实际性能。", "conclusion": "实验结果显示，基于柔道算子的去中心化因果发现方法在计算效率上具有优势，并且在不同场景下的表现超过了传统的因果发现方法。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23989", "html_url": "https://arxiv.org/abs/2510.23989", "title": "基于社会基础设施依赖性的城市中断后个体移动模式学习", "title_en": "Learning Individual Movement Shifts After Urban Disruptions with Social Infrastructure Reliance", "authors": "Shangde Gao,Zelin Xu,Zhe Jiang", "background": "个体在遭遇中断事件后移动模式的变化可以揭示社区资源需求的变化，但预测这些变化仍然具有挑战性。主要原因包括缺乏衡量个人异质社会基础设施韧性的指标，常用的特征往往在规模上有限且难以获取（如社会经济特征），个体移动模式与空间上下文之间的复杂相互作用没有得到充分捕捉，以及传统决策方法在处理个体层面的移动预测时可能不适应时空稀疏数据。", "innovation": "本文将个人的社会基础设施韧性（SIR）纳入条件深度学习模型中，利用大规模、稀疏的个体级数据捕捉个体移动模式与局部空间上下文之间的复杂关系。实验结果表明，集成个人SIR和空间上下文可以增强模型预测灾后个体移动模式的能力。模型能够捕捉到在预灾模式相似但SIR不同的个体间移动模式的差异性变化。", "conclusion": "本文通过引入个人的社会基础设施韧性，利用条件深度学习模型改进了灾后个体移动模式的预测能力。研究成果表明，在灾后个体移动模式预测中，不仅需要考虑传统的社会经济特征，还应关注个体的社会基础设施韧性。(The model improves the prediction of post-event individual movement patterns by incorporating individual social infrastructure resilience, and the research findings indicate the need to consider both traditional socioeconomic features and individual social infrastructure resilience in post-disaster individual movement pattern prediction.)"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23882", "html_url": "https://arxiv.org/abs/2510.23882", "title": "数字孪生中的混合建模、虚拟到现实的强化学习以及大语言模型驱动的控制", "title_en": "Hybrid Modeling, Sim-to-Real Reinforcement Learning, and Large Language Model Driven Control for Digital Twins", "authors": "Adil Rasheed,Oscar Ravik,Omer San", "background": "本文研究了数字孪生在动态系统建模和控制中的应用，结合物理学驱动、数据驱动和混合方法，与传统和AI驱动的控制器。以一个微小的温室作为测试平台，开发了四种预测模型，包括线性模型、基于物理学的建模（PBM）、长短时记忆（LSTM）和混合分析与建模（HAM），并在内插和外推场景下进行了比较。同时，实现了三种控制策略（模型预测控制MPC、强化学习RL和基于大型语言模型的控制LLM），以评估精度、适应性和实现难度之间的权衡。研究表明，混合分析与建模（HAM）在建模中提供了最均衡的性能，在准确性、泛化能力和计算效率方面表现出色；而LSTM在资源成本较高的情况下达到较高的精度。在控制器方面，MPC提供稳健且可预测的性能，RL展示出强大的适应性，而基于大型语言模型的控制器在与预测工具结合时提供灵活的人机交互。", "innovation": "提出了在数字孪生中结合物理学驱动、数据驱动和混合方法的建模策略；开发了四种不同的预测模型（线性模型、基于物理学的建模（PBM）、长短时记忆（LSTM）和混合分析与建模（HAM））；实现了三种基于模型的预测控制（MPC）、强化学习（RL）和大型语言模型驱动的控制策略，并通过实际的温室控制研究验证了不同方法之间的权衡与优势。", "conclusion": "在建模中，HAM提供了最均衡的性能；在学习中，LSTM在高资源开销时能够达到高精度；在控制策略方面，MPC表现出稳健性和可预测性、RL展示了强大的适应性，而LLM驱动的控制器能够提供灵活的人机交互。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23965", "html_url": "https://arxiv.org/abs/2510.23965", "title": "符号估计器：面对选择异质性的LLM对齐", "title_en": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity", "authors": "Aymane El Gadarri,Ali Aouad,Vivek F. Farias", "background": "传统的LLM对齐方法容易受到人类偏好异质性的影响。对两两比较数据（例如提示-完成对）使用朴素的概率模型拟合会导致对总体平均效用的不一致估计——这是一致的社会福利度量。本研究旨在提出一种新颖的方法，通过在聚合步骤中用二元分类损失替换交叉熵，提供一个简单、可证明的一致且高效的估计器，以解决这些挑战。这种方法在现实的LLM对齐模拟中表现出色，显著减少了偏好失真，有效降低了估计误差，并减少了与真实群体偏好不一致的程度，同时保持了现有LLM对齐管道的实施简便性。", "innovation": "提出了一种名为符号估计器的新方法，该方法通过在聚合步骤中使用二元分类损失替换交叉熵，解决了传统LLM对齐方法在处理人类偏好异质性时的不一致性问题。符号估计器能够在实现简单的同时，提供一种简单、可证明一致且高效的估计器，并且在有限样本中获得首例多项式误差界。此外，该方法在现实的LLM对齐模拟中表现出色，显著减少了偏好失真，降低了估计误差，并减少了与真实群体偏好不一致的程度，优于现有的面板数据启发式方法，这些方法需要跟踪个体水平的偏好数据。", "conclusion": "符号估计器通过简单的修改，在处理选择异质性的LLM对齐任务中表现出了显著优势，有效地减少了偏好失真和估计误差，并降低了与真实群体偏好不一致的程度，同时保持了现有对齐管道的简便性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24031", "html_url": "https://arxiv.org/abs/2510.24031", "title": "LLMLogAnalyzer: 使用大型语言模型的基于聚类的日志分析聊天机器人", "title_en": "LLMLogAnalyzer: A Clustering-Based Log Analysis Chatbot using Large Language Models", "authors": "Peng Cai,Reza Ryan,Nickson M. Karie", "background": "系统日志是网络安全的核心，支持预防性漏洞检测和事件后的调查。然而，分析大量多样的日志数据依然具有重大挑战。高昂的成本、缺乏内部专业知识和时间限制使得许多组织即使进行基本的日志分析也很困难。", "innovation": "本文介绍了一种名为LLMLogAnalyzer的基于聚类的日志分析聊天机器人，该机器人利用大型语言模型（LLMs）和机器学习（ML）算法简化和优化日志分析流程。该创新方法解决了大型语言模型的关键限制，包括上下文窗口限制和对结构化文本处理能力差的问题，可以更有效地进行总结、模式提取和异常检测任务。", "conclusion": "LLMLogAnalyzer通过其模块化的架构，在四个不同的日志域和各种任务中进行了评估。结果表明，与最先进的基于大型语言模型的聊天机器人（如ChatGPT、ChatPDF和NotebookLM）相比，在不同任务上均实现了显著性能提升，具体增益范围从39%到68%。该系统在ROUGE-1得分下的中位数差值减少了93%，表明结果变异性显著降低。该框架的有效性源自其模块化架构，包括路由器、日志识别器、日志解析器和搜索工具。此设计增强了大型语言模型在结构化文本分析中的能力，提高了准确性和鲁棒性，使其成为网络安全专家和技术用户都可用的宝贵工具。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24085", "html_url": "https://arxiv.org/abs/2510.24085", "title": "用电车辆跟随行为建模：经典方法与机器学习方法的比较", "title_en": "Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach", "authors": "Md. Shihab Uddin,Md Nazmus Shakib,Rahul Bhadani", "background": "随着电动汽车（EVs）的广泛采用，了解其驾驶行为对于提高交通安全和开发智能驾驶系统至关重要。本研究旨在比较经典模型和机器学习模型在预测电动汽车跟随其他车辆行为方面的表现。经典模型包括智能驾驶员模型（IDM）、最佳速度模型（OVM）、相对速度最佳速度模型（OVRV）以及简化后的CACC模型，而机器学习方法则使用随机森林回归器进行加速预测。", "innovation": "研究使用真实数据集比较了经典模型和机器学习模型在不同驾驶条件下的预测精度。机器学习模型（随机森林模型）使用距离、速度和空档类型作为输入来预测加速度，结果显示其预测精度明显优于经典模型。对于不同空档情况，随机森林模型的RMSE分别为0.0046（中空档）、0.0016（长空档）、0.0025（超长空档）。经典物理模型中，CACC模型在长空档情况下的RMSE为2.67。这些结果强调了在各种场景下机器学习模型的优越性。", "conclusion": "研究表明，机器学习模型在预测电动汽车跟随行为方面表现出色，尤其是在各种驾驶条件下。该模型对于模拟电动汽车行为和分析电动汽车集成环境中混合自动交通动态具有重要价值。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24013", "html_url": "https://arxiv.org/abs/2510.24013", "title": "使用大型语言模型（LLMs）为混合整数规划发现启发式算法：单机调度", "title_en": "Discovering Heuristics with Large Language Models (LLMs) for Mixed-Integer Programs: Single-Machine Scheduling", "authors": "İbrahim Oğuz Çetinkaya,İ. Esra Büyüktahtakın,Parshin Shojaee,Chandan K. Reddy", "background": "该研究关注单机总延迟（SMTT）问题，即在没有预emption的情况下，通过顺序安排n个作业在一个处理器上，最小化总延迟。先前的研究使用了简单规则为基础的启发式算法进行评估。而本研究利用大型语言模型（LLMs）发现新的启发式方法，旨在克服先前研究的简化方法，并使用混合整数规划（MIP）形式化标准进行评估，包括精确度间隙和解决方案时间等。此外，本研究还对比了这些新启发式方法与其他最新启发式和精确方法在不同规模的工作集上的性能，尤其在作业规模超过100个时，精确方法变得计算上不可行，这些结果展示了人在LLM辅助下的合作可以产生适用于NP困难约束组合优化的可扩展且高性能的启发式算法，即使在有限资源的情况下也可以实现配置优化的效果。", "innovation": "该研究利用大型语言模型（LLMs）开发了两种新的启发式算法：EDD Challenger (EDDC)和MDD Challenger (MDDC)，这两种算法借鉴了经典的Earliest Due Date （EDD）和Modified Due Date（MDD）规则。这些算法在评估标准上更加严格，包括与MIP形式化标准的对比分析，以及与最新启发式和精确方法的性能对比。这些新的启发式方法在工作规模较小的情况下表现优于经典启发式算法，尤其在作业规模达到500时，MDD Challenger持续优于传统的启发式算法，并且与精确方法保持竞争力，特别是在更大的、更复杂的情况下。", "conclusion": "该研究表明，即使在资源有限的情况下，人与LLM的合作也能产生可扩展且高性能的启发式算法，甚至对于NP难的约束组合优化问题也是适用的。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24028", "html_url": "https://arxiv.org/abs/2510.24028", "title": "OneCast：结构分解与模块化生成在跨域时间序列预测中的应用", "title_en": "OneCast: Structured Decomposition and Modular Generation for Cross-Domain Time Series Forecasting", "authors": "Tingyue Pan,Mingyue Cheng,Shilong Zhang,Zhiding Liu,Xiaoyu Tao,Yucong Luo,Jintao Zhang,Qi Liu", "background": "跨域时间序列预测是各种网络应用中的一项宝贵任务。尽管该领域取得了快速发展，但在跨不一致性时间序列数据获得有效泛化方面仍面临重大挑战。现有方法通过扩展单域模型取得了进展，但在遭遇特定领域趋势变化和不一致的周期性模式时往往表现不佳。主要原因在于将时间序列视为未区分的序列，未能明确解耦其固有的结构性成分。", "innovation": "本文提出了一种名为OneCast的结构化和模块化预测框架，该框架将时间序列分解为季节性和趋势成分，并通过定制的生成路径对这两种成分进行建模。季节成分通过一个轻量级的投影模块进行捕捉，该模块利用可解释的基础函数重建周期性模式。趋势成分则在语义感知的标记化器中按段编码，并通过掩码离散扩散机制进行推断。来自两个分支的输出综合生成最终的预测，能够同时捕捉季节模式并跟踪特定领域的趋势。实验结果显示，OneCast通常优于最先进的基准方法。", "conclusion": "在八类数据领域的大量实验中，OneCast表明其普遍优于现有最先进的基线方法，能够有效解决跨域时间序列预测中的关键问题。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24145", "html_url": "https://arxiv.org/abs/2510.24145", "title": "从可观测数据到诊断：一种用于云系统故障管理的进化多智能体系统", "title_en": "From Observability Data to Diagnosis: An Evolving Multi-agent System for Incident Management in Cloud Systems", "authors": "Yu Luo,Jiamin Jiang,Jingfei Feng,Lei Tao,Qingliang Zhang,Xidao Wen,Yongqian Sun,Shenglin Zhang,Jielong Huang,Nan Qi,Dan Pei", "background": "大型云系统的可靠性依赖于有效的故障管理（IM）。然而，手动的故障管理方式因大量异构可观测数据而变得劳动密集且易出错。现有的自动化故障管理方法难以跨系统进行泛化，缺乏可解释性，并且可能存在较高的部署成本，这限制了它们在实际中的应用。因此，如何在确保质量的同时降低成本，实现自动化故障管理系统的持续演进，成为了一个亟待解决的问题。", "innovation": "本文提出的OpsAgent是一个轻量级的自演化多智能体系统，它通过无训练的数据处理器将异构可观测数据转化为结构化的文本描述，并采用了多智能体协作框架来增强诊断推断的透明度与可审计性。此外，OpsAgent采用了一种双重自演进机制，将内部模型更新与外部经验积累结合起来，从而实现了从部署到自我迭代的闭环。", "conclusion": "在OPENRCA基准上的全面实验结果表明，OpsAgent具有业界领先的表现，同时也是可泛化、可解释、成本效益高且自我演进的解决方案，为实际云系统的长期运营提供了可部署和可持续的解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24115", "html_url": "https://arxiv.org/abs/2510.24115", "title": "HistoLens: 一种用于病理学视觉-语言模型验证和减轻缺陷的互动可解释性工具包", "title_en": "HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology", "authors": "Sandeep Vissapragada,Vikrant Sahu,Gagan Raj Gupta,Vandita Singh", "background": "为了医生真正信任人工智能，它不能仅仅是‘黑盒’。医生需要理解其推理过程，类似于咨询同事一样。为此，我们开发了 HistoLens1，旨在成为透明且合作的伙伴。该系统使病理科医生可以简单地用日常语言对组织切片提问，就像向实习生提问一样。系统会将其问题智能地翻译成精准的查询，为AI引擎提供指出，生成清晰的结构化报告。", "innovation": "HistoLens实现了透明化和可解释性，当医生问“为什么”的时候，可以即时提供‘视觉证明’，指出AI分析使用的确切细胞和区域。此外，系统通过教导AI忽略背景干扰，使其专注于病人的组织，如同经过培训的病理学家一样。因此，这种路径学家剩下的仍是专家，信赖的AI助理辅助验证其见解且快速做出诊断的工作流程被实现。", "conclusion": "HistoLens是一个有效的工具，让病理医生在保持其专业知识的同时，借助可靠的AI助手快速和自信地做出诊断，同时可解释性和透明度确保了这一过程的可信度。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24168", "html_url": "https://arxiv.org/abs/2510.24168", "title": "MGA: 记忆驱动的GUI代理用于观察中心交互", "title_en": "MGA: Memory-Driven GUI Agent for Observation-Centric Interaction", "authors": "Weihua Cheng,Ersheng Ni,Wenlong Wang,Yifei Sun,Junming Liu,Wangyu Shen,Yirong Chen,Botian Shi,Ding Wang", "background": "随着大型语言模型（LLMs）及其多模态扩展（MLLMs）的快速发展，已经能够研发出能感知并操作于多种环境下的自主系统。GUI代理的开发成为了一个新的前沿领域，这些代理需要在保持鲁棒性和泛化能力的同时导航复杂的桌面和网络界面。现有的方法通常将任务建模为较长的执行链，通过历史轨迹来扩展上下文，但这种方法往往会放大错误传播，且偏向局部探索，忽视了关键界面提示的重要性，从而影响了决策的质量。", "innovation": "本文提出了一种名为MGA（Memory-Driven GUI Agent）的记忆驱动GUI代理，其特点是首次观察然后决策的交互框架。MGA通过引入三元组——当前屏幕截图、任务无关的空间信息以及动态更新的结构化记忆，重新定义了每一步的操作环境。实验结果表明，与最先进的基线方法相比，MGA在鲁棒性、泛化能力和效率方面均有显著提升。代码已经公开可用。", "conclusion": "MGA通过优化交互模式，提升了GUI代理在复杂界面下的性能，对于实现更加智能化、灵活的系统具有重要意义。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24161", "html_url": "https://arxiv.org/abs/2510.24161", "title": "BLM$_1$: 一种跨空间、跨任务和跨体模学习的无界大型模型", "title_en": "BLM$_1$: A Boundless Large Model for Cross-Space, Cross-Task, and Cross-Embodiment Learning", "authors": "Wentao Tan,Bowen Wang,Heng Zhi,Chenyu Liu,Zhe Li,Jian Liu,Zengrong Lin,Yukun Dai,Yipeng Chen,Wenjie Yang,Enci Xie,Hao Xue,Baixu Ji,Chen Xu,Zhibin Wang,Tianshi Wang,Lei Zhu,Heng Tao Shen", "background": "现有大型多模态语言模型（MLLMs）在视觉-语言推理方面取得了显著进展，并被广泛应用于实体代理中。然而，它们在数字-物理空间转换、实体适应以及高阶推理方面存在明显局限性。视觉-语言-动作模型（VLAs）虽能执行基本动作，但缺乏稳健的高阶实体推理能力。大多数实体大型语言模型（ELLMs）局限于数字空间，缺乏向物理世界的泛化能力。因此，同时在数字和物理空间中无缝运行且具有跨实体通用性的统一模型仍然缺失。", "innovation": "本文提出了一种新的多模态空间基础模型（BLM$_1$），该模型整合了跨空间转换、跨任务学习和跨体模泛化的三大关键能力。通过两阶段训练方法，第一阶段通过精心选择的数字化语料库注入实体知识，同时保持语言能力；第二阶段通过意图桥梁接口训练策略模块，提取高阶语义以指导控制而无需Fine-tuning MLLM主干。该过程通过自收集的跨实体示范套件进行支持，覆盖了四种不同机器人实体和六个渐进挑战的任务。评估结果显示，单一BLM$_1$实例在数字和物理基准测试中均超过了四类模型，分别是MLLMs、ELLMs、VLAs和GMLMs，在数字任务中提升了大约6%，在物理任务中提升了大约3%。", "conclusion": "总体而言，BLM$_1$为跨领域学习提供了一种新的方法，显著提升了模型在跨领域、跨任务和跨实体的表现。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24297", "html_url": "https://arxiv.org/abs/2510.24297", "title": "探索非精确抽象算法内的抽象政策", "title_en": "Investigating Intra-Abstraction Policies For Non-exact Abstraction Algorithms", "authors": "Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn", "background": "蒙特卡洛树搜索(MCTS)的一个缺点是样本效率不高，可以通过并行建立和使用状态和/或动作抽象来提高。这种方法可以使得同一层节点之间共享信息。现有抽象算法，如修剪实时路径抽象(pruned On the Go Abstractions, pruned OGA)，通常未注意到当多个具有相同父节点的动作被置于同一抽象节点时的情况，这些动作会被赋予相同的上置信界值(UCB)，因此需要打破平局规则。", "innovation": "本文提出并实证评估了多种不同的内部抽象政策。这些政策在大多数环境和参数设置下均优于随机平局打破规则。", "conclusion": "所提出的一些内部抽象政策优化了MCTS的样本效率，特别是在多种环境和参数设置下表现更优。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24303", "html_url": "https://arxiv.org/abs/2510.24303", "title": "增强检索与论证的多代理LLM系统在判断性预测中的应用", "title_en": "Retrieval and Argumentation Enhanced Multi-Agent LLMs for Judgmental Forecasting", "authors": "Deniz Gorur,Antoni Rago,Francesca Toni", "background": "判断性预测是基于人类判断对未来事件进行预测的任务，可以视为一种声明验证的形式，验证未来的声明的真实性。已有研究中，这类任务通常是单一模型或简单的多模型方法进行验证。", "innovation": "本文提出了一种新颖的多代理框架，用于声明验证。该框架中，不同代理对声明的真实性可能存在分歧，并且每个代理会提供支持声明或反驳声明的证据，这种证据表示为定量双极论证框架（QBAFs）。此框架通过多种LLM代理实现：ArgLLM代理用于生成并评估QBAFs；RbAM代理通过LLM从外部来源进行关系基础论证挖掘（RbAM）以生成QBAFs；RAG-ArgLLM代理结合了从外部来源检索论证的机制。通过两个标准的判断性预测数据集进行了实验，验证了该框架的有效性。", "conclusion": "实验表明，结合多个代理的证据可以提高预测准确性，尤其是使用三个代理时，同时提供了可解释的证据组合来支持声明验证。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24151", "html_url": "https://arxiv.org/abs/2510.24151", "title": "BMGQ: 一种从半结构化数据生成复杂多跳推理问题的自底向上的方法", "title_en": "BMGQ: A Bottom-up Method for Generating Complex Multi-hop Reasoning Questions from Semi-structured Data", "authors": "Bingsen Qiu,Zijian Liu,Xiao Liu,Haoshen Yang,Zeren Gao,Bingjie Wang,Feier Zhang,Yixuan Qin,Chunyan Li", "background": "构建可以真正测试模型检索和推理能力的多跳问答训练数据集仍然极具挑战。尽管存在一些可以捕捉难以搜索但易于验证的问题特征的评估数据集，这些数据集需要集成模糊、间接和跨领域线索，但这些资源仍然稀缺，多用于评估而非监督微调或强化学习。手动创建非琐碎检索问题的成本高昂且不可扩展，形成了一个关键的数据瓶颈。", "innovation": "提出了一种自动化框架，用于从半结构化知识源生成高难度的训练多跳问题。该系统通过自然语言推理（NLI）基于关系类型和多样性意识扩展来生成多元且逻辑标记的证据集合；应用逆向问题构建来组成间接线索，使得单一信号的信息不足，但组合可以唯一识别目标实体；并采用两阶段的质量评价管道，结合多模型共识过滤、结构约束分解和基于证据的匹配来保障质量。", "conclusion": "这一过程实现了可扩展且生成复杂、检索抵抗但可验证的问题，这些问题是进行监督微调/强化学习训练以及挑战性评估的理想选择。该方法显著减少了人类整理工作量，同时保留了强大评估基准的难度特征。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24284", "html_url": "https://arxiv.org/abs/2510.24284", "title": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "title_en": "MCP-Flow: Facilitating LLM Agents to Master Real-World, Diverse and Scaling MCP Tools", "authors": "Wenhao Wang,Peizhi Niu,Zhao Xu,Zhaoyu Chen,Jian Du,Yaxin Du,Xianghe Pang,Keduan Huang,Yanfeng Wang,Qiang Yan,Siheng Chen", "background": "大型语言模型（LLMs）越来越多地依赖外部工具来执行复杂的现实任务，但它们利用快速扩展的模型上下文协议（MCP）生态系统的能力仍然有限。现有MCP研究覆盖的服务器较少，依赖于昂贵的手动整理，缺乏训练支持，阻碍了其在真实世界部署方面的进展。为克服这些局限，本文介绍了一种自动化的web代理驱动的大规模服务器发现、数据合成和模型训练流水线，称为MCP-Flow。", "innovation": "MCP-Flow能够自动从1166个服务器和11536个工具中收集和筛选数据，生成68733个高质量的指令-函数调用对以及6439条轨迹，这在规模和多样性上都超越了以往的工作。MCP-Flow还在大规模服务器发现、数据合成和模型训练方面提供了自动化的解决方案。广泛的实验证明，MCP-Flow能够有效地驱动MCP工具有更好的选择、函数调用生成能力和增强的代理任务性能。MCP-Flow为提升LLM代理在真实MCP环境中的专业性提供了可扩展的基础。", "conclusion": "MCP-Flow为LLM代理在现实世界的MCP环境中提供了可扩展的基础，以提高其全力水平。MCP-Flow已在https://arxiv.org/abs/2305.11817处公开可用。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24299", "html_url": "https://arxiv.org/abs/2510.24299", "title": "利用相关矩阵秩验证大型语言模型的推理路径", "title_en": "Verifying Large Language Models' Reasoning Paths via Correlation Matrix Rank", "authors": "Jiayu Liu,Wei Dai,Zhenya Huang,Ning Miao,Enhong Chen", "background": "尽管大型语言模型（LLMs）具有强大的推理能力，但它们容易出错和产生幻觉。因此，在实际应用中，如何有效地验证LLMs输出结果成为了一个关键问题。现有的验证方法严重依赖外部资源，如经过训练的验证器（例如，过程/结果奖励模型）或复杂的提示，这不仅增加了计算负担，而且仅适用于特定领域。", "innovation": "本文探讨了LLMs内部行为是否已经暗示了其推理路径的可信度。具体而言，作者发现输入问题和输出推理路径之间相关矩阵的秩是一个稳健的推理正确性指标。与其他LLM正确性指标不同，计算相关矩阵只需依赖LLM本身，避免了训练额外模型或设计复杂提示的麻烦。基于此，作者设计了一种简单、即插即用的Self-Indicator方法来重新加权候选推理路径，该方法在极低的计算开销下显著提高了其他投票和验证方法的性能。作者在不同规模和模型族的多种LLMs上的实验进一步证明了Self-Indicator的有效性，其在区分正确和错误推理路径方面达到了超过75%的准确性，并且在三个推理基准测试上分别提高了超过8%的准确性。", "conclusion": "Self-Indicator方法能够在低计算开销的情况下显著提高大型语言模型推理路径的验证效果，实验结果表明它在多个大型语言模型上都取得了显著的准确性提升。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24339", "html_url": "https://arxiv.org/abs/2510.24339", "title": "VDSAgents：一种基于PCS原则的多代理系统，用于符合规范的数据科学自动化", "title_en": "VDSAgents: A PCS-Guided Multi-Agent System for Veridical Data Science Automation", "authors": "Yunxuan Jiang(School of Management, Xi'an Jiaotong University),Silan Hu(School of Computing, National University of Singapore),Xiaoning Wang(School of Data Science and Media Intelligence, Communication University of China),Yuanyuan Zhang(Beijing Baixingkefu Network Technology Co., Ltd.),Xiangyu Chang(School of Management, Xi'an Jiaotong University)", "background": "随着大型语言模型（LLMs）在数据科学工作流程中的应用日益增加，这些系统依赖于LLMs的内部推理，缺乏科学和理论原则的指导，这限制了系统的可靠性和鲁棒性，尤其是在处理噪声大和复杂的现实世界数据集时。已有系统如AutoKaggle和DataInterpreter等在处理这类数据集时的表现并不理想，可能无法确保科学的可审计性。", "innovation": "本文提出了VDSAgents，这是一种多代理系统，基于Veridical Data Science (VDS)框架中的Predictability-Computability-Stability (PCS)原则。VDSAgents通过分模块的方式处理数据清洗、特征工程、建模和评估，并结合扰动分析、单元测试和模型验证，确保系统的功能性和科学审计能力。", "conclusion": "本文将VDSAgents应用到九个具有不同特性的数据集上，并将其实验结果与AutoKaggle和DataInterpreter等最先进的端到端数据科学系统进行了对比。实验结果表明，VDSAgents在多个指标上都优于这两个系统，证明了将PCS原则嵌入到LLM驱动的数据科学自动化中的可行性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24166", "html_url": "https://arxiv.org/abs/2510.24166", "title": "UniPlanner：通过多数据集集成实现自主车辆决策系统中统一运动规划框架", "title_en": "UniPlanner: A Unified Motion Planning Framework for Autonomous Vehicle Decision-Making Systems via Multi-Dataset Integration", "authors": "Xin Yang,Yuhang Zhang,Wei Li,Xin Lin,Wenbin Zou,Chen Xu", "background": "自主车辆决策系统中的运动规划是关键组件，直接影响轨迹安全性与驾驶效率。尽管深度学习方法提升了规划能力，但现有方法大多使用单一数据集进行训练，限制了其在规划中的鲁棒性。实际上，不同数据集中车辆轨迹分布和历史未来相关性的统计一致性表明，存在多数据集整合的可能性和必要性。因此，文章通过系统分析发现了这一特点，并提出了UniPlanner，这是一个专门为自主车辆决策系统中多数据集整合而设计的规划框架。", "innovation": "UniPlanner 通过三个协同创新实现统一多数据集学习：1. 历史-未来轨迹字典网络 (HFTDN) 从多个数据集中聚合历史-未来轨迹对，通过历史轨迹相似度检索相关未来，从而进行跨数据集规划指导；2. 无梯度轨迹映射器 (GFTM) 从多个数据集中学习稳健的历史-未来关联性，将历史轨迹转化为通用的规划先验，其无梯度设计确保了先验知识的有效引入并防止了捷径学习，从而确保规划知识的安全转移；3. 稀疏到密集 (S2D) 原理在训练期间通过适配性丢弃有选择地抑制规划先验，以实现稳健学习，而在推理期间完全利用这些先验来最大化规划性能。", "conclusion": "UniPlanner 是首个为自主车辆决策系统中多数据集整合设计的规划框架，通过这三个创新技术实现了统一多数据集学习，既提升了规划的鲁棒性，又保证了规划性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24342", "html_url": "https://arxiv.org/abs/2510.24342", "title": "连接AI模型与人类大脑的统一几何空间", "title_en": "A Unified Geometric Space Bridging AI Models and the Human Brain", "authors": "Silin Chen,Yuzhong Chen,Zifan Wang,Junhao Wang,Zifeng Jia,Keith M Kendrick,Tuo Zhang,Lin Zhao,Dezhong Yao,Tianming Liu,Xi Jiang", "background": "长期以来，神经科学家和计算机科学家都致力于理解智能并构建智能系统。现代人工神经网络在语言、感知和推理方面已经与人类相当，但这些人工系统的信息组织方式是否与大脑相似尚不清楚。尽管已有研究展示了这两种系统之间惊人的对应关系，但这些比较仅限于特定输入和任务，没有提供一种比较不同感知方式（如视觉、语言或跨模态）的AI模型内在结构的方式。", "innovation": "本文提出了一个革新开创性的“类脑空间”概念：这是一种统一的几何空间，在其中，每个AI模型可以通过将其实质性的空间注意力拓扑组织映射到标准的人类功能脑网络上来精确放置和比较，而不考虑输入模态、任务或感官领域。通过分析151个基于Transformer的模型（包括最先进的大型视觉模型、大型语言模型和大型跨模态模型），作者发现了该空间内的连续弧形几何结构，反映了逐渐增加的类脑性。不同的模型在其空间几何结构内的分布模式各异，反映了它们的不同程度的类脑性，这种差异不仅由模态决定，还与预训练范式是否强调全局语义抽象以及位置编码方案是否促进不同模态的深度融合有关。", "conclusion": "类脑空间首次为跨域安置、量化和比较智能提供了一个统一框架，揭示了连接机器和大脑的深层组织原则。此外，模型的类脑性程度和其下游任务性能并不是“孪生子”，这表明类脑空间能够进一步解释和区分不同AI模型在不同任务上的表现差异。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24359", "html_url": "https://arxiv.org/abs/2510.24359", "title": "一个针对精准医学的N-of-1人工智能生态系统", "title_en": "An N-of-1 Artificial Intelligence Ecosystem for Precision Medicine", "authors": "Pedram Fard,Alaleh Azhir,Neguine Rezaii,Jiazi Tian,Hossein Estiri", "background": "当前的人工智能医学系统旨在服务于‘平均患者’，通过在大数据集中减小错误，大多数系统能够实现强大的群体准确性，但在处理罕见变异、多病症或多族裔代表性不足的患者方面表现不佳。这种‘平均患者谬误’逐步侵蚀了公平性和信任度。鉴于此，论文提出了一种新的设计思路：为N-of-1决策支持构建一个多代理生态系统。该系统中的代理按照器官系统、患者群体和分析方法分组，并共享模型和证据综合工具，它们的结果在协调层融合，该层评估可靠性和不确定性，并将结果以包含风险估算、异常信号和关联证据的决定支持包形式呈现给临床医生。", "innovation": "该论文提出了一个多代理生态系统，用于N-of-1决策支持，强调这些代理按照器官系统、患者群体和分析方法分组，并共享模型和证据综合工具。其创新点在于突破了传统人工智能医学服务于‘平均患者’的局限，关注群体与个体之间的差异性，并提出了从群体平均水平转向个体可信度的验证方法。", "conclusion": "这种多代理人工智能生态系统致力于将医学AI与医学的第一原则——透明、公平和以个人为中心——相结合。论文建议通过计算策略、共识检查和自适应试验框架来应对计算需求、自动化偏差和监管合规性等挑战，从而实现更为精准和个性化的医疗决策支持。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24411", "html_url": "https://arxiv.org/abs/2510.24411", "title": "OS-Sentinel：在现实工作流程中通过混合验证提升移动GUI代理的安全性", "title_en": "OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows", "authors": "Qiushi Sun,Mukai Li,Zhoumianze Liu,Zhihui Xie,Fangzhi Xu,Zhangyue Yin,Kanzhi Cheng,Zehao Li,Zichen Ding,Qi Liu,Zhiyong Wu,Zhuosheng Zhang,Ben Kao,Lingpeng Kong", "background": "基于视觉-语言模型（VLMs）的计算机使用代理已经展示了在操作如移动平台的数字环境中的人类能力。然而，这些代理可能因系统破坏或隐私泄露等不安全操作而引发安全担忧。在复杂的移动环境中检测这些安全性问题是一个艰巨的挑战。为了推动移动代理安全研究的基础，该研究介绍了MobileRisk-Live，一种动态沙箱环境及其配套的安全检测基准，该基准包括详细的细粒度注解的现实轨迹。", "innovation": "基于MobileRisk-Live，该研究提出了OS-Sentinel，一种新颖的混合安全检测框架，结合了形式验证器（用于检测明确的系统级违规）和基于VLM的上下文评估器（用于评估上下文风险和代理行动）。实验结果表明，OS-Sentinel在多个指标上超过了现有方法，达到了10%-30%的改进。", "conclusion": "进一步的分析提供了关键见解，有助于开发更安全、更可靠的自主移动代理。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24383", "html_url": "https://arxiv.org/abs/2510.24383", "title": "政策卡片：自主AI代理的机器可读运行时治理", "title_en": "Policy Cards: Machine-Readable Runtime Governance for Autonomous AI Agents", "authors": "Juraj Mavračić", "background": "政策卡片是一种机器可读的部署层标准，用于表达对AI代理的操作、监管和伦理约束。它使代理在运行时能够遵循必要的约束，通过定义允许/禁止规则、义务、证据要求以及与NIST AI RMF、ISO/IEC 42001和欧盟AI法案等保障框架的跨走映射来扩展现有的透明度工具（如模型卡、数据卡和系统卡）。每个政策卡片都可以自动验证、版本控制，并与运行时执行或连续审计管道相关联。这种框架为多代理生态系统中的可验证合规性提供了基础，使得大规模实现负责自主具有可行性。", "innovation": "政策卡片通过定义规范层（允/禁规则、义务、证据要求及与保障框架的跨走映射），扩展了现有的透明度工具，使自主人工智能代理在运行时能够遵循必要的约束。政策卡片允许自动验证、版本控制，并与运行时执行或连续审计管道相关联，从而形成可验证合规性的基础，在多代理生态系统中实现分布式保障。此外，政策卡片提供了一种将高层治理与实际工程实践相结合、从而实现规模化负责自主的实用机制。", "conclusion": "政策卡片提供了一个框架，使自主人工智能代理能够在运行时遵循操作、监管和伦理约束，并且通过自动验证、版本控制和与运行时执行或连续审计管道相关联，实现可验证合规性，从而在多代理生态系统中形成分布式保障基础，实现了大规模负责自主。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24397", "html_url": "https://arxiv.org/abs/2510.24397", "title": "APTBench：预训练期间基线LLM的代理潜能基准测试", "title_en": "APTBench: Benchmarking Agentic Potential of Base LLMs During Pre-Training", "authors": "Jiarui Qin,Yunjia Xi,Junjie Huang,Renting Rui,Di Yin,Weiwen Liu,Yong Yu,Weinan Zhang,Xing Sun", "background": "随着基于LLM的代理的快速发展，人们开始将代理特定的数据纳入LLM的预训练阶段，以更好地使LLM与现实世界的自主任务执行相匹配。然而，当前的预训练基准主要集中在孤立和静态技能上，如常识或数学/代码推理等，并未能反映模型的代理能力。另一方面，代理基准通常是为了后训练模型而设计的，需要多轮次的任务执行能力，这超出了基础模型的支持范围。因此，需要一种基准来评估代理潜力并在预训练期间指导模型训练。", "innovation": "我们提出了APTBench，一种框架，将真实世界的代理任务和成功的轨迹转换为适用于基础模型的选择题或文本填充问题。该框架专注于核心代理能力，如规划和行动，并覆盖关键代理场景，包括软件工程和深度研究。与现有的通用基准相比，APTBench 提供了对模型作为代理的下游性能更为预测性的信号，同时仍然比完整的端到端代理评估更为轻量级和成本效益。", "conclusion": "APTBench 为预训练期间评估基线LLM的代理潜能提供了一种有效的方法，有助于改进模型训练，提高了代理模型的实用性和性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24390", "html_url": "https://arxiv.org/abs/2510.24390", "title": "通过依赖感知查询拆分和逻辑并行内容扩展提高LLM推理", "title_en": "Improving LLM Reasoning via Dependency-Aware Query Decomposition and Logic-Parallel Content Expansion", "authors": "Xianjun Gao,Jianchun Liu,Hongli Xu,Liusheng Huang", "background": "文章背景阐述了将大型语言模型（LLMs）集成到实时Web应用中（如AI搜索和对话代理）所面临的根本性Web基础设施挑战，即需要高质量、复杂的推理能力与交互服务的严格低延迟和高吞吐量要求之间的矛盾。当前的LLM推理存在运算效率低且固定的推理策略，造成立即服务的重大瓶颈。现有的方法一般只能优化LLM推理的效率或质量，但难以同时兼顾两者，无法满足现代Web平台的双重需求。文章基于这一挑战提出了解决这一问题的方法。", "innovation": "文章提出了Orion，这是一种新型且高效的推理框架，通过依赖感知的查询拆分和逻辑并行内容扩展增强了LLM的推理能力。具体来说，Orion将查询推理过程分解为两阶段：（1）关键点生成，通过检索增强的少量提示提取逻辑结构的关键点；（2）内容并行扩展，基于依赖图并行扩展这些关键点，确保逻辑一致性。此外，Orion还引入了一种流水线调度机制，使多个查询中的两个阶段（生成利用GPU计算，扩展利用GPU内存）能够并行执行，不仅提高了推理性能，还改善了推理质量。实验结果显示，Orion在基准测试上比基线提高了4.33倍的标记生成速度、3.42倍的较低答案延迟，并且推理质量提升了18.75%。", "conclusion": "文章提出的Orion框架不仅提高了LLM推理的速度和质量，而且实现了跨查询的并行处理，提升了推理性能。这些成果表明，Orion在解决LLM推理中的高效性和质量之间的权衡问题上取得了重要突破。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24435", "html_url": "https://arxiv.org/abs/2510.24435", "title": "超凡推理能力：大型语言模型在逻辑和抽象推理方面的比较研究", "title_en": "Human-Level Reasoning: A Comparative Study of Large Language Models on Logical and Abstract Reasoning", "authors": "Benjamin Grando Moreira", "background": "评估大型语言模型（LLMs）的推理能力对于推动人工智能的发展至关重要。这不仅仅是语言任务性能的问题，还涉及到模型是否真正理解信息、进行推理以及以逻辑和合理的方式得出结论的能力。该研究通过一系列自定义设计的推理问题，比较了包括GPT、Claude、DeepSeek、Gemini、Grok、Llama、Mistral、Perplexity和Sabiá在内的几种LLMs的逻辑和抽象推理能力，同时这些模型的结果与人类同任务的绩效进行对比与基准测试，揭示出显著差异，表明LLMs在演绎推理方面存在困难。", "innovation": "本研究采用了一套自定义设计的推理问题，对比了多种大型语言模型的逻辑和抽象推理能力，并将模型结果与人类绩效进行基准对比，以揭示这些模型在推理能力上的差异和不足之处。这种方法提供了对LLMs推理能力的深入理解，并突出了它们在演绎推理方面的局限性。", "conclusion": "研究结果表明，虽然大型语言模型在某些方面的推理能力接近甚至超过了人类，但它们在演绎推理能力方面仍存在显著差距。这为改进大型语言模型的推理能力指明了方向。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24442", "html_url": "https://arxiv.org/abs/2510.24442", "title": "Law in Silico: 使用基于LLM的代理模拟法律社会", "title_en": "Law in Silico: Simulating Legal Society with LLM-Based Agents", "authors": "Yiding Wang,Yuxuan Chen,Fanxu Meng,Xifan Chen,Xiaolei Yang,Muhan Zhang", "background": "由于实际的法律实验往往成本高昂或不可行，使用人工智能（AI）系统模拟法律社会提供了一种验证和开发法律理论的有效替代方法，同时也能支持法律管理。大型语言模型（LLMs）由于其世界知识和角色扮演能力，被视为模拟法律社会的良好基础。然而，LLMs在模拟法律体系方面的应用仍然未被充分探索。", "innovation": "本文介绍了Law in Silico，这是一种基于LLM的代理框架，用于模拟涉及个体决策和立法、司法和执行机制的法律场景。实验结果显示，LLM代理可以大规模再现犯罪趋势，并提供与现实世界观察相符的见解。同时，微观层面的模拟显示，功能健全、透明和适应性强的法律系统能更好地保护弱势个体的权利。", "conclusion": "LLM代理在模拟法律场景方面具有潜力，能够再现宏观犯罪趋势，并提供有助于理解法律系统有效性的见解。此外，通过模拟展示，清晰透明及动态适应的法律系统能够更好地保护弱势群体的权益。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24459", "html_url": "https://arxiv.org/abs/2510.24459", "title": "自主代理中的能力表示与识别", "title_en": "Affordance Representation and Recognition for Autonomous Agents", "authors": "Habtom Kahsay Gidey,Niklas Huber,Alexander Lenz,Alois Knoll", "background": "软件代理的自主性依赖于它们构建可操作的内部世界模型的能力，从定义其数字环境的结构化数据中产生，例如网页的文档对象模型（DOM）和网页服务的语义描述。然而，从原始结构化数据构建这些世界模型存在两个关键挑战：原始HTML的冗长性使其对于基础模型的直接使用计算上不可行，而硬编码的API集成的静态性质阻止代理适应不断变化的服务。因此，本文介绍了从结构化数据构建世界模型的模式语言，并提出了两种互补的架构模式以解决上述挑战。", "innovation": "本文提出了一种模式语言，介绍了两种互补的架构模式：DOM转换模式通过简化冗长原始DOM为一个紧凑且任务相关的表示或世界模型来应对网页复杂性问题；超媒体功能识别模式则使代理能够动态丰富其世界模型，通过解析标准化的语义描述，发现并运行时整合未知的网页服务的功能。这些模式提供了一个坚实框架，使得工程师能够高效的构建并维护准确的世界模型，以实现跨互联网和扩展资源的可扩展、自适应和互操作自动化。", "conclusion": "这些模式提供了用于构建和维护准确世界模型的坚实框架，使代理能够进行高效的自动化，实现跨互联网及其扩展资源的可扩展、自适应和互操作自动化。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24461", "html_url": "https://arxiv.org/abs/2510.24461", "title": "基于脉冲神经网络的序贯强化学习自适应代理梯度", "title_en": "Adaptive Surrogate Gradients for Sequential Reinforcement Learning in Spiking Neural Networks", "authors": "Korneel Van den Berghe,Stein Stroobants,Vijay Janapa Reddi,G.C.H.E. de Croon", "background": "神经形态计算系统有望通过实现数量级的能效提升和本地时间处理能力，彻底改变能量受限的机器人技术。脉冲神经网络（SNNs）作为一种具有潜力的算法方法，在复杂控制任务中面临着两个关键挑战：(1) 脉冲神经元的非可微性质导致了代理梯度的需求，但其优化性质尚不明确；(2) 脉冲神经网络的动态状态需在序列上进行训练，在强化学习中由于训练初期序列长度有限，限制了网络在暖启动期后的性能提升。", "innovation": "本文通过系统地分析代理梯度坡度设置，发现较浅的坡度虽然增加了深层层的梯度大小，但减少了梯度与真实梯度的匹配度。在监督学习中，发现固定或计划梯度坡度无明显偏好。但在强化学习中，较浅的或计划梯度坡度可以使训练和最终部署性能提高2.1倍。此外，提出了一个新颖的训练方法，利用特权指导策略来加速学习过程，同时利用在线环境与脉冲策略的互动。这种方法结合适应性坡度计划，实现了真实世界无人机位置控制任务中平均得分400，显著优于之前的技术，包括行为克隆和TD3BC。", "conclusion": "本文推进了对NNS中代理梯度学习的理论理解，展示了在真实世界机器人系统中实现神经形态控制器的实用训练方法。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24528", "html_url": "https://arxiv.org/abs/2510.24528", "title": "从跨任务示例到任务内提示：无LLM图基伪标签框架以用于在上下文学习", "title_en": "From Cross-Task Examples to In-Task Prompts: A Graph-Based Pseudo-Labeling Framework for In-context Learning", "authors": "Zihan Chen,Song Wang,Xingbo Fu,Chengshuai Shi,Zhenyu Lei,Cong Shen,Jundong Li", "background": "大语言模型（LLMs）可以通过上下文学习（ICL）在不更新参数的情况下执行新任务。然而，收集高质量的新或具有挑战性的任务的输入输出示例是非常耗时且成本高昂的。本研究提出了一个成本效益高的两阶段管道，减少了对LLM的数据标注依赖。该方法首先利用现成的跨任务示例来提示LLM并伪标注一部分目标任务实例，然后引入一种基于图的标签传播方法，将标签信息传播给剩余的目标示例，无需额外的LLM查询。生成的完整伪标注数据集用于构建ICL的任务内示范。这种方法结合了跨任务监督的灵活性和无需LLM的传播方法的规模扩展性。", "innovation": "本研究提出了一种基于图的伪标签框架，用于ICL。该框架包含两个阶段：第一阶段利用现成的跨任务示例提示LLM并伪标注目标任务实例；第二阶段利用基于图的标签传播方法传播标签信息到未伪标注的任务数据。这种方法减少了对LLM的数据标注依赖，并证明在五个任务上取得了优秀的性能，同时降低了标签成本。", "conclusion": "本研究提出的方法通过使用现成的跨任务示例和基于图的标签传播方法，减少了收集高质量新或挑战性任务标签的成本，而在ICL中达到了良好的性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24551", "html_url": "https://arxiv.org/abs/2510.24551", "title": "医疗领域的生成式AI：基础、挑战与展望", "title_en": "Generative AI for Healthcare: Fundamentals, Challenges, and Perspectives", "authors": "Gang Chen,Changshuo Liu,Gene Anne Ooi,Marcus Tan,Zhongle Xie,Jianwei Yin,James Wei Luen Yip,Wenqiao Zhang,Jiaqi Zhu,Beng Chin Ooi", "background": "生成式人工智能（GenAI）正在全球范围内迅速发展，它为医学实践带来革命性的机会，从大型语言模型（LLMs）在临床文档合成和对话辅助中的应用到集成医学成像、电子健康记录和基因组数据的多模态系统，支持决策支持。尽管GenAI在医学领域具有为临床医生减轻认知负担、提高整体医疗保健交付的巨大潜力，但在其部署过程中需要深入理解医学任务及其实现可能性。因此，该论文探讨了数据在设计和部署医疗领域GenAI系统中的核心地位。", "innovation": "本文提出了一种数据为中心的设计与部署框架，旨在充分支持多样化的医疗数据和知识。具体而言，该框架重新定义了数据生命周期，使其成为支撑基因型医疗系统的基础平台。通过高效的数据处理管道，例如语义向量搜索和上下文查询，支持大型预训练模型和特定领域模型的生成式AI操作。该框架不仅提供高质量、多模态数据进行大规模预训练和特定领域微调，还作为知识检索后端，支持基于任务的推断。", "conclusion": "该生态系统使GenAI能够实现高质量、有效的医疗保健交付，并提出了一种可持续支持多源医学数据和知识的医疗生态系统。通过这种数据驱动的方法，促进GenAI在医疗保健领域的广泛应用，最终提高医疗服务的质量和效率。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24663", "html_url": "https://arxiv.org/abs/2510.24663", "title": "OrchDAG：使用计划DAG进行多回合交互的复杂工具编排", "title_en": "OrchDAG: Complex Tool Orchestration in Multi-Turn Interactions with Plan DAGs", "authors": "Yifu Lu,Shengjie Liu,Li Dong", "background": "随着代理工具调用的兴起，代理工具使用得到了重视，但大多数现有研究忽略了多回合工具交互的复杂性。现有模型在处理多回合工具交互时面临挑战。", "innovation": "提出了OrchDAG数据生成管道，将其工具执行建模为具有可控复杂性的有向无环图(DAGs)，并使用该数据集及其基于图的奖励对RLVR训练进行基准测试。研究表明，该数据集提供了一个具有挑战性但可解决的基准，并证明在结合GRPO类型算法时，提出的奖励是有效的。", "conclusion": "实验表明，数据集为多回合工具使用提供了一个具有挑战性的但可解决的基准，而提出的基于图的奖励在与GRPO型算法结合时是有效的，这强调了在多回合工具使用中利用拓扑结构和数据复杂性的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24650", "html_url": "https://arxiv.org/abs/2510.24650", "title": "推进精准农业中特定地点的病虫害管理：从推理驱动的基础模型到适应性、基于反馈的学习", "title_en": "Advancing site-specific disease and pest management in precision agriculture: From reasoning-driven foundation models to adaptive, feedback-based learning", "authors": "Nitin Rai,Daeun(Dana)Choi,Nathan S. Boyd,Arnold W. Schumann", "background": "作物的特定地点病害管理（SSDM）通过机器学习和深度学习（ML和DL）在实时计算机视觉方面取得了迅速发展。研究从手工特征提取发展到大规模自动特征学习。基于模型（FMs）的引入使得作物病害数据集以全新的方式被处理。传统神经网络仅处理视觉数据，而FMs能够整合视觉和文本数据，解释症状文本，推敲症状管理的关系，并支持农管理和教育的互动问答。", "innovation": "1. FMs在处理作物病害数据方面带来了根本性的新方法。2. VLMs（视觉-语言模型）和LLMs（大型语言模型）的应用显著增加，VLMs的增长速度快5-10倍。3. 虽然强化学习（RL）和自适应学习（AL）尚未成熟，可用于精准喷洒，但数字双胞胎框架可以实现虚拟的精准喷洒模拟。4. 关于迁移自模拟到现实的差距，实际部署仍然关键。5. 人类-机器人协作仍然有限，特别是在机器人鉴定早期症状而人类验证不确定案例的人机在环路径中。", "conclusion": "多模态FMs与实时反馈将推动下一代SSDM的发展。为了获取更新、资源和参与贡献，请访问此链接，以提交论文、代码或数据集。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24645", "html_url": "https://arxiv.org/abs/2510.24645", "title": "FunReason-MT 技术报告：克服多轮函数调用的复杂性障碍", "title_en": "FunReason-MT Technical Report: Overcoming the Complexity Barrier in Multi-Turn Function Calling", "authors": "Zengzhuang Xu,Bingguang Hao,Zechuan Wang,Yuntao Wen,Maolin Wang,Yang Liu,Long Chen,Dong Wang,Yicheng Chen,Cunyin Peng,Chenyi Zhuang,Jinjie Gu,Leilei Gan,Xiangyu Zhao,Shi Gu", "background": "功能调用（FC）使大型语言模型（LLMs）和自主代理能够与外部工具交互，这对于解决复杂现实世界问题至关重要。随着这种能力在先进AI系统中的重要性日益增加，高质量、多轮训练数据的发展和改进变得至关重要。现有数据合成方法，如随机环境采样或多智能体角色扮演，不足以在真实环境中生成高质量的数据。实际挑战来自于三个方面：针对模型的训练、工具架构的隔离以及多轮逻辑依赖。", "innovation": "我们提出了FunReason-MT，一种新型的真实世界多轮工具使用数据合成框架。FunReason-MT 通过3个方面解决了多轮FC数据的复杂性障碍：1) 环境-API 图形交互来收集多样的高质量轨迹；2) 高级工具-查询合成来简化复杂查询构建；3) 指导迭代链以生成复杂的推理链。在伯克利函数调用排行榜（BFCLv3）的评估上，基于FunReason-MT生成数据的4B模型在同等大小模型中表现出最强性能，且超过了多数商用模型。BFCLv4的进一步性能提升验证了FunReason-MT为代理学习提供的可靠和稳健的数据来源。", "conclusion": "我们的框架展现了强大的能力，建立在FunReason-MT上的4B模型在可比大小模型中获得了最先进的性能，并且在BFCLv4上进一步的性能提升证实了FunReason-MT是一个可靠和稳健的代理学习数据来源。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24337", "html_url": "https://arxiv.org/abs/2510.24337", "title": "生成式大型语言模型（gLLMs）在内容分析中的应用：传播研究的实用指南", "title_en": "Generative Large Language Models (gLLMs) in Content Analysis: A Practical Guide for Communication Research", "authors": "Daria Kravets-Meinke,Hannah Schmid-Petri,Sonja Niemann,Ute Schmid", "background": "生成式大型语言模型（如ChatGPT）正在传播研究中越来越多地用于内容分析，研究显示，这些模型在各种与传播科学相关的内容编码任务上可以超越群众工作者和训练有素的编码人员，如研究助手，并且可以在成本和时间上大幅度节省。此外，生成式大型语言模型还可以解码隐含意义和上下文信息，能够用自然语言接受指令，并仅需基本的编程技巧即可部署。而且，在进行生成式大型语言模型辅助的内容分析时只需少量标记数据，甚至不需要标记数据，从而引发内容分析自动化的新范式。尽管拥有上述潜在优势，但将生成式大型语言模型整合到传播研究的方法工具箱中仍然不够发达。研究人员在使用生成式大型语言模型辅助的数量型内容分析时，至少需要解决七个关键挑战：代码书开发、提示工程、模型选择、参数调整、迭代优化、以及验证模型可靠性，还有可选的性能增强。这篇论文综合了关于生成式大型语言模型辅助的质量型内容分析的新兴研究，并提出了一种全面的最佳实践指南，旨在帮助更广泛的传播研究人员实现生成式大型语言模型的内容分析，并保证研究结果的效度、可靠性、可再现性和研究伦理标准的符合性。", "innovation": "生成式大型语言模型（gLLMs）在传播研究中的应用，并提出了一个全面的解决方案来解决在生成式大型语言模型辅助的内容分析中遇到的挑战，提高了研究人员实现生成式大型语言模型内容分析的可能性，同时确保了研究结果的质量标准符合性。这种方案是一种方法论上的创新，可以促进生成式大型语言模型在传播研究中的更大范围应用。", "conclusion": "本文综合了关于生成式大型语言模型辅助的质量型内容分析的新兴研究，并提出了一种全面的最佳实践指南，旨在帮助更广泛的传播研究人员实现生成式大型语言模型的内容分析，并保证研究结果的效度、可靠性、可再现性和研究伦理标准的符合性。这种最佳实践指南将使基于生成式大型语言模型的内容分析更加易于非专业研究人员获得，并确保研究的高质量标准得到遵守。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.09539", "html_url": "https://arxiv.org/abs/2411.09539", "title": "使用有限数据调优大型语言模型：综述与实用指南", "title_en": "Fine-tuning Large Language Models with Limited Data: A Survey and Practical Guide", "authors": "Marton Szep,Daniel Rueckert,Rüdiger von Eisenhart-Rothe,Florian Hinterwimmer", "background": "在低资源语言、专业领域和受限部署环境中，用有限数据调优大规模语言模型（LLM）是一个实际挑战。预训练的LLM提供了坚实的基础，但在数据稀缺的情况下，有效的适应需要聚焦且高效的调优技术。", "innovation": "本文对近期在数据稀缺场景下调优LLM的方法进行了系统性的回顾，涵盖了参数高效的调优技术、降低训练和部署成本的方法，以及针对编码器和解码器模型的领域和跨语言适应方法。此外，还探讨了通过有限的人类或合成反馈引导模型行为的偏好对齐方法，强调了样本和计算效率。", "conclusion": "本文旨在为研究人员和实践者提供实用的见解，帮助他们在数据和资源有限的情况下有效地调优LLM。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24690", "html_url": "https://arxiv.org/abs/2510.24690", "title": "基于图的框架：在上下文规划中弥合工具依赖性和领域知识差距", "title_en": "Bridging Tool Dependencies and Domain Knowledge: A Graph-Based Framework for In-Context Planning", "authors": "Shengjie Liu,Li Dong,Zhenyu Zhang", "background": "该研究旨在通过揭示和利用工具和文档之间的依赖关系来提高示例性制品生成的效率。研究从工具模式中构建工具知识图，结合描述、参数和输出负载，同时从内部文档和SOP中生成互补的知识图，并将其与工具图融合。采用深度-稀疏集成策略来生成示例性计划，该策略能够使结构化的工具依赖与程序性知识相匹配，以此来更好地进行规划生成。\n", "innovation": "该框架通过工具知识图和领域知识图的融合，实现了更有效的问题解决和规划生成方法。特别地，该方法创新性地结合了DeepResearch的深度分析方法，与文档知识的融合策略，以及结构化的工具依赖与程序性知识的对齐，这些都为工具增强的推理和计划提供了新的路径。\n", "conclusion": "研究结果表明，统一框架能够有效地建模工具间的交互，并提高计划生成的质量。实验验证了利用链接工具图与领域知识图带来的好处，特别是对于工具增强的推理和规划，这种方法有效改善了现有的工具依赖理解和利用方式。\n"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23619", "html_url": "https://arxiv.org/abs/2510.23619", "title": "短票欺诈检测框架分析报告", "title_en": "Short Ticketing Detection Framework Analysis Report", "authors": "Yuyang Miao,Huijun Xing,Danilo P. Mandic,Tony G. Constantinides", "background": "本文报告对铁路系统的短票欺诈检测进行了全面分析，采用了无监督的多专家机器学习框架。该研究旨在识别并分类30个高风险车站中的可疑模式，并通过四个互补算法（孤立森林、局部异常因子、一类支持向量机和马氏距离）来检测短票欺诈行为。研究结果揭示了5种不同的短票欺诈模式，并表明该框架在运输系统中的检测能力较强，具备欺诈行为恢复的潜力。", "innovation": "提出了A/B/C/D站分类系统，成功识别30个高风险车站的可疑模式；采用一套互补的机器学习算法，包括孤立森林、局部异常因子、一类支持向量机和马氏距离，以提高欺诈检测的准确性和效率。", "conclusion": "该无监督多专家机器学习框架成功识别了铁路系统中不同的短票欺诈模式，并表明该方法在运输系统中的欺诈检测和恢复具有重要潜力，为进一步的动态监控和预防提供支持。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23617", "html_url": "https://arxiv.org/abs/2510.23617", "title": "增强的双重Transformer对比网络在多模态情感分析中的应用", "title_en": "An Enhanced Dual Transformer Contrastive Network for Multimodal Sentiment Analysis", "authors": "Phuong Q. Dao,Mark Roantree,Vuong M. Ngo", "background": "多模态情感分析（MSA）旨在通过联合分析来自多个模态（通常为文本和图像）的数据，提供比单模态方法更丰富和准确的解释。现有的方法通常使用后期融合策略，但可能会限制跨模态交互的深度。", "innovation": "该论文提出了Bert-ViT-EF模型，这是一个结合了基于Transformer的编码器BERT和ViT的早期融合策略的新颖模型，促进更深入的跨模态交互和更有效的联合表示学习。在此基础上，论文进一步提出了一种称为双Transformer对比网络（DTCN）的扩展方法，该方法在BERT后增加了一个Transformer编码器层，用于细化文本上下文，并采用对比学习对齐文本和图像表示，以促进稳健的多模态特征学习。", "conclusion": "实验结果表明，DTCN在TumEmo数据集上取得了最佳准确率（78.4%）和F1分数（78.3%），在MVSA-Single数据集上也达到了竞争性的表现，准确率为76.6%，F1分数为75.9%。这些改进突显了Transformer基干下的早期融合和更深层次的上下文建模在多模态情感分析中的优势。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22820", "html_url": "https://arxiv.org/abs/2505.22820", "title": "响应时间下的偏好学习：鲁棒损失与保证", "title_en": "Preference Learning with Response Time: Robust Losses and Guarantees", "authors": "Ayush Sawarni,Sahasrajit Sarmasarkar,Vasilis Syrgkanis", "background": "随着二元偏好数据在优化基础模型、生成人工智能系统及其他大规模模型中作为关键信息源的角色越来越重要，研究表明这种模式忽略了用户决策过程中的时间信息。本文旨在将响应时间数据整合到人类偏好学习框架中，以提高奖励模型提取的有效性。本文指出，传统偏好学习方法在奖励规模较大的情况下会出现指数级错误率，这需要一种新的方法来优化这一问题。因此，研究提出了新的方法来结合响应时间和二元选择数据，并开发了Neyman-正交损失函数，用于奖励模型的学习，使得学习率接近理论最优。通过实验证明了理论预期的有效性，尤其是在图像偏好学习中的应用效果显著。", "innovation": "1. 提出了新的方法来结合响应时间和二元选择数据，利用了Evidence Accumulation Drift Diffusion (EZ) 模型，其中响应时间反映了偏好强度。\n2. 开发了Neyman-正交损失函数，以实现奖励模型学习的Oracle收敛率，即当预期的每个查询的响应时间已知时的最佳理论率。\n3. 对于线性奖励函数，证明了传统偏好学习方法的错误率随奖励尺寸指数级上升的问题，而新的响应时间增强方法将错误率降低到多项式衰减，大幅提高了样本效率。同时，这些保证也被扩展到了非参数奖励函数空间，确保了更复杂和现实奖励模型的收敛特性。", "conclusion": "相比于传统的方法，使用响应时间来增强偏好学习，对于线性奖励函数具有多项式失败率，而非传统方法的指数失败率，显著提高了样本效率。实验结果验证了文章提出的理论推导，特别是在图像偏好学习上的效果显著。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23627", "html_url": "https://arxiv.org/abs/2510.23627", "title": "AI驱动的出版社开发：Xynapse Traces", "title_en": "AI-Driven Development of a Publishing Imprint: Xynapse Traces", "authors": "Fred Zimmerman", "background": "该研究介绍了一种名为Xynapse Traces的实验性出版物系列，它通过结合人类和算法方法，使用配置驱动的架构和多模型AI集成框架创建。这项系统性努力旨在探讨人与AI协作的新范式，以降低成本，提高效率，并为不具经济效益的小众市场提供更广泛的机会，同时保证出版标准不被妥协。", "innovation": "该系统的关键技术创新包括实时创意管道、锦标赛式评估、用于转写冥想实践的新型编年史设计、从创意到生产再到分销的全面自动化流程、定义并指导出版物系列使命的出版者角色，以及集自动验证和人工监督为一体的系统集成，确保速度提升不降低出版标准。这些创新方法显著降低了市场规模和时间，是传统出版方式的一种革新.", "conclusion": "该研究的成果对于未来书籍出版具有重要意义，提供了新的人类-AI协作模式，并使以前无法实现的小众市场变得更加可行，这项努力通过降低成本和提高效率，为更加民主化的高端出版能力开启了大门。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23626", "html_url": "https://arxiv.org/abs/2510.23626", "title": "从检测到发现：社交媒体上同步连续扩展医疗知识和抑郁症检测的闭环方法", "title_en": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media", "authors": "Shuang Geng,Wenli Zhang,Jiaheng Xie,Rui Wang,Sudha Ram", "background": "社交媒体用户生成的内容（UGC）提供了有关抑郁症等心理健康状况的实时、自我报告的指标，为预测分析提供了宝贵的数据来源。尽管先前的研究通过整合医学知识来提高预测精度，但它们忽视了通过预测过程同时扩展此类知识的机会。大规模的UGC能够同时提高预测准确性和医学理解。", "innovation": "本文开发了一种闭环大型语言模型（LLM）-知识图谱框架，该框架通过迭代学习周期整合预测和知识扩展。框架包含两个关键阶段：在知识感知抑郁检测阶段，LLM同时执行抑郁检测与实体提取，知识图谱表示并加权这些实体以优化预测性能；在知识精炼和扩展阶段，在专家监督下，新的实体、关系和实体类型被纳入知识图谱，从而实现持续的知识进化。", "conclusion": "该框架证明了计算模型和领域知识共同进化的过程，为适应其他动态风险监测情境的自适应、数据驱动的知识系统奠定了基础。专家评估证实，框架发现了具有临床意义的症状、共病和社交触发因素，这些因素补充了现有文献。将预测与学习相结合，并注重知识的自我强化过程，推进了预测分析的理论和方法理解。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16620", "html_url": "https://arxiv.org/abs/2510.16620", "title": "反馈午餐：用于窃听信道的深度反馈码", "title_en": "Feedback Lunch: Deep Feedback Codes for Wiretap Channels", "authors": "Yingyao Zhou,Natasha Devroye,Onur Günlü", "background": "本文考虑了反转降级的窃听信道，在没有信道反馈的情况下，这种信道的保密容量为零。以往的研究显示，在有信道反馈的情况下，由于窃听者的优势，信道的保密性能可能会下降。本文关注的是结合了通用散列函数（用于安全性）和基于学习的反馈编码（用于可靠性）的高斯窃听信道的设计，以实现积极的保密率。研究了通信可靠性与信息泄露之间的权衡，展示了反馈如何帮助合法方达成一个共享的密钥，这是窃听者所无法获得的。这项研究揭示了用于辅助传感的安全通信编码设计的重要性，以便应用于下一代综合传感与通信方法中。", "innovation": "本文创新性地结合了通用散列函数和反馈编码技术，提出了一种基于深度反馈的编码方案，用于高斯窃听信道。通过这种方法，能够在保持一定通信可靠性的前提下，有效提高信息保密性，克服了窃听者的优势。本文还基于反馈编码讨论了安全通信中通信可靠性和信息泄露之间的权衡，并且指出了传感辅助的安全通信编码设计的重要性。", "conclusion": "本文通过综合运用通用散列函数和反馈编码技术，提出了一套新的编码方案，显著提高了高斯窃听信道下的保密性能，并且展示了反馈编码在安全通信中的重要作用。此外，本文的工作还为下一代综合传感与通信方法提供了重要的编码设计方案指导。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23621", "html_url": "https://arxiv.org/abs/2510.23621", "title": "加速MACE：等变力场的低精度技巧", "title_en": "Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields", "authors": "Alexandre Benoit", "background": "传统的基于机器学习的力场在进行分子动力学模拟时会消耗大量计算资源，但对于像MACE这样的SO(3)等变模型，使用低精度算术和GPU优化内核能否在不损害物理精度的情况下降低成本，则缺乏系统性的证据。因此，有必要通过识别计算瓶颈并评估低精度执行策略来使MACE更加高效和快速。", "innovation": "研究团队详细分析了MACE的计算性能，通过端到端及逐块分析评测了e3nn和NVIDIA cuEquivariance后端，并评估了不同精度的浮点设置（FP64、FP32、BF16、FP16，FP32积累）对不同应用场景的影响。研究发现使用cuEquivariance可以减少推理延迟约3倍，仅将线性层转换为BF16/FP16可以在不丢失结果一致性的前提下大幅提升速度。不过，训练过程中使用半精度权重会导致力RMSE增加，且直接混合e3nn和cuEq模块会引发表示不匹配。该研究提出要充分利用cuEquivariance和BF16/FP16混合精度实现最大吞吐量，但训练应保持FP32精度。", "conclusion": "基于上述研究，研究认为在使用MACE进行分子动力学模拟时，可以采用默认使用cuEquivariance结合FP32，对于线性层则可启用BF16/FP16，但务必保留FP32的累加操作以实现最优性能。未来在Ampere/Hopper GPU和内核层次的FP16/BF16路径及管线融合等方面有望进一步提升性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23620", "html_url": "https://arxiv.org/abs/2510.23620", "title": "通过机器学习和个性化基因调控网络实现表型-基因型整合以预测癌症转移", "title_en": "Genotype-Phenotype Integration through Machine Learning and Personalized Gene Regulatory Networks for Cancer Metastasis Prediction", "authors": "Jiwei Fu,Chunyu Yang,Charalampos P. Triantafyllidis", "background": "癌症转移是导致癌症相关死亡的主要原因，尽管如此，大多数预测模型仍依赖于浅层架构，并且忽略了患者特异性的调控机制。本文旨在将经典机器学习与深度学习相结合，以预测不同癌症类型中的转移潜能。利用癌症细胞线文库的基因表达谱与DoRothEA提供的转录因子目标前知识，专注于九个与转移相关的调控因子，通过Kruskal-Wallis检验筛选差异基因，进一步使用ElasticNet、随机森林和XGBoost模型进行训练对比基准。", "innovation": "本文创新性地结合了传统机器学习与基于图的深度学习方法（Graph Attention Neural Network，GATv2），构建个人化基因调控网络，并通过生成对抗网络（PANDA）和LIONESS进行分析，从而学习拓扑和表达基础的表示。尽管XGBoost在AUROC（0.7051）上得分最高，但GNN能够捕捉到患者级别的非线性调控依赖性。这些结果表明，传统机器学习与基于图的深度学习的结合可以提供一种可扩展且具有解释性的框架，用于精准肿瘤学中的转移风险预测。", "conclusion": "研究结果表明，将传统机器学习与图基深度学习相结合，可以构建一个可扩展且可解释的框架，用于精准肿瘤学中的转移风险预测。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23630", "html_url": "https://arxiv.org/abs/2510.23630", "title": "NUM2EVENT: 从数值时间序列中进行可解释的事件推理", "title_en": "NUM2EVENT: Interpretable Event Reasoning from Numerical time-series", "authors": "Ninghui Feng,Yiyan Qi", "background": "大型语言模型在多模态推理方面表现出令人印象深刻的性能，但在纯粹的数值时间序列信号的理解上仍存在局限性。现有方法主要集中在预测或趋势描述，而未能揭示驱动数值变化的潜在事件，亦或是解释其背后的推理过程。", "innovation": "本文提出了数值到事件推理和解码任务，旨在从数值输入中推断出可解释的结构化事件，即使当前文本不可用。为了解决数据稀缺和语义对齐的挑战，本文提出了一种推理意识框架，该框架结合了代理指导事件提取器（AGE）、标记多变量霍尔兹基生成器（EveDTS）以及时间序列编码和结构化解码的两阶段微调管道。", "conclusion": "实验结果表明，我们的方法在事件级别的准确性和召回率上显著优于强大的LLM基线。这些结果暗示了一个新的方向，即结合定量推理和语义理解，使LLM能够直接从数值动态中解释和预测事件。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23629", "html_url": "https://arxiv.org/abs/2510.23629", "title": "在大型语言模型中促进一般推理的执行链监督", "title_en": "Chain of Execution Supervision Promotes General Reasoning in Large Language Models", "authors": "Nuo Chen,Zehua Li,Keqin Bao,Junyang Lin,Dayiheng Liu", "background": "构建强大且通用的推理能力是大型语言模型（LLMs）发展中一个核心目标。近年来，研究越来越多地将代码作为丰富训练来源，得益于其内在的逻辑结构和多样化的推理范式，如分而治之、拓扑排序和枚举。然而，代码中的推理往往是隐式的，且常与语法或实现噪声交织在一起，这使得直接对原始代码进行训练变得困难。", "innovation": "该研究引入了TracePile，一个包含260万个样本的大规模语料库，将代码执行转化为明确的、逐步的执行链式推理，即称为执行链（CoE）。该语料库涵盖了数学、经典算法和算法竞赛等众多领域，并通过增加变量追踪问题和代码重写来增强逻辑细节和代码多样性。研究使用三种训练设置进行了评估：继续预训练、预训练后指令调优，以及两阶段微调。实验在四个基础模型（LLaMA 3、LLaMA 3.1、Qwen-2.5 和 Qwen-2.5 Coder）和20个覆盖数学、代码、逻辑和算法的基准测试上进行，结果显示了持续的一致改进。值得注意的是，TracePile将LLaMA3.1-8B在九个数学数据集上的表现平均提升了7.1%，并在两阶段微调下，在LiveCodeBench、CRUX 和 MMLU 上取得了显着收益。", "conclusion": "该研究通过使用TracePile作为训练数据，证明了能够显著提升大型语言模型的推理能力，特别是在数学领域的表现，特别是在两阶段微调下，这对于提高模型的泛化能力和实际应用有重要意义。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23633", "html_url": "https://arxiv.org/abs/2510.23633", "title": "噪声即所需：通过噪声组合采样解决线性逆问题", "title_en": "Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models", "authors": "Xun Su,Hiroyuki Kasai", "background": "预训练扩散模型在零样本逆问题求解中表现出强大的能力，通过将观察信息整合到扩散模型的生成过程中。然而，这种整合存在固有的困境：过度整合会破坏生成过程，而整合不足则无法强调逆问题施加的约束。", "innovation": "提出了一种名为Noise Combination Sampling的新方法，该方法从噪声子空间合成最优噪声向量，以近似测量得分，替代标准去噪扩散概率模型过程中的噪声项，使有条件信息能够自然嵌入生成过程，且无需依赖逐步超参数调整。该方法适用于各种逆问题求解器，特别当生成步骤较少时，能够实现高性能且无明显计算开销，显著提升鲁棒性和稳定性。", "conclusion": "该方法可广泛应用于逆问题求解，尤其是在生成步骤较少的情况下，能够显著克服传统方法的不足，表现出色且计算效率高。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23632", "html_url": "https://arxiv.org/abs/2510.23632", "title": "LLMComp：一种用于误差限定科学数据压缩的语言建模范式", "title_en": "LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data Compression", "authors": "Guozhong Li,Muhannad Alhumaidi,Spiros Skiadopoulos,Panos Kalnis", "background": "随着高分辨率科学模拟和观测系统的快速发展，生成了大量的时空数据集。高效、误差限定的压缩变得至关重要。同时，仅解码器大型语言模型（LLMs）在建模复杂序列数据方面表现出色。", "innovation": "本文提出了一种名为LLMCOMP的新颖有损压缩范式，利用仅解码器大型语言模型来建模科学数据。LLMCOMP首先将三维场量化为离散标记，通过Z-order曲线排列以保持局部性，并通过覆盖引导下采样来提高训练效率。然后，使用空问-时间嵌入的自回归变压器对标记转换进行建模。压缩过程中，模型进行top-k预测，仅存储排名索引和回退更正，以确保严格的误差界限。", "conclusion": "实验结果显示，LLMCOMP在多个再分析数据集上始终优于最先进的压缩器，在严格的误差限定下压缩比提高了高达30%。这表明LLM作为高保真科学数据的通用压缩器的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23637", "html_url": "https://arxiv.org/abs/2510.23637", "title": "结合文本和结构信息在Lean中的前提选择", "title_en": "Combining Textual and Structural Information for Premise Selection in Lean", "authors": "Job Petrovčič,David Eliecer Narvaez Denis,Ljupčo Todorovski", "background": "在大规模形式化库中扩展定理证明的关键瓶颈是前提选择。现有的基于语言的方法通常将前提独立考虑，忽视它们之间的依赖关系网络。", "innovation": "提出了一种图增强方法，该方法结合了Lean形式化密集文本嵌入与包含状态-前提和前提-前提关系的异质依赖图的图神经网络。在LeanDojo基准测试中，该方法在标准检索指标上比ReProver语言基线提高了超过25%。", "conclusion": "这些结果表明，关系信息对于更有效的前提选择具有强大的能力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23634", "html_url": "https://arxiv.org/abs/2510.23634", "title": "单调可分集合函数：特性与神经模型", "title_en": "Monotone and Separable Set Functions: Characterizations and Neural Models", "authors": "Soutrik Sarangi,Yonatan Sverdlov,Nadav Dym,Abir De", "background": "本文受到了集合包含问题应用的启发，探讨了如何通过设计集合到向量的函数，保持集合的自然部分序，即如果集合S包含集合T，那么函数F(S)必然小于等于F(T)。这被称为单调可分集合函数（MAS函数）.", "innovation": "建立了MA S函数所需的向量维度的上下边界，根据不同集合的基数和底层基本集合，对这些边界进行了分析。对于无限底集的情形，证明了不存在MA S函数，但提供了一种被称为‘弱MA S’的模型，该模型可以证明具有放松的MA S性质，并且在哈德尔连续性的意义上是稳定的。还表明，可以通过构造使用M AS函数来构建单调性并且能逼近所有单调集合函数的模型。实验表明，该模型在集合包含任务上优于标准集合模型，因为它们未将集合包含作为归纳偏置.", "conclusion": "MA S函数可以用来构建全功能模型，而这些模型本身就是单调的，并且能够逼近所有单调集合函数。通过实验还展示了将该模型应用于集合包含任务的优势。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23631", "html_url": "https://arxiv.org/abs/2510.23631", "title": "超越成对优化：通过排名选择建模提升大语言模型的对齐", "title_en": "Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling", "authors": "Yuxuan Tang,Yifan Feng", "background": "现有的大语言模型（LLMs）对齐主要依赖于成对偏好优化，即让注释者选择对同一提示响应中更好的一个。然而，这种方式未能充分利用更加丰富的多选比较和Top-$k$排名等形式的人类反馈。传统的成对方法忽略了这种潜在的反馈形式，限制了对齐的效果和灵活性。", "innovation": "本文提出了一种名为Ranked Choice Preference Optimization (RCPO)的统一框架，该框架通过最大似然估计将偏好优化与排名选择建模相结合。RCPO支持基于效用和基于排名的选择模型，并扩展了现有的成对方法（如DPO和SimPO），使得在处理更加丰富的反馈形式时具有明确的训练目标。研究中采用了两种典型的排名选择模型（多项式逻辑模型和Mallows-RMJ模型）来实例化框架。研究结果显示，RCPO在多个基准测试中均表现出色，优于其他竞争性基线。这项工作展示了如何直接利用排名偏好数据来增强对齐效果，同时强调了选择适当模型的重要性。", "conclusion": "RCPO框架提供了一个灵活且可扩展的基础，用于将排名选择建模整合到LLM训练中，从而实现更有效的对齐。这种方法展示了如何通过使用适当的排名选择数据来改善语言模型的对齐，为未来的研究提供了新方向。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23635", "html_url": "https://arxiv.org/abs/2510.23635", "title": "助人为乐：自助中心数据清洁的怀疑学习野外评估", "title_en": "Help the machine to help you: an evaluation in the wild of egocentric data cleaning via skeptical learning", "authors": "Andrea Bontempelli,Matteo Busso,Leonardo Javier Malcotti,Fausto Giunchiglia", "background": "任何数字个人助手，无论用于支持任务执行、回答问题、管理工作和个人生活（包括健身计划）等，都需要高质量的标注。然而，用户标注（无论是主动生成的还是从上下文中推断的，例如智能手环的数据）往往会受到错误和噪声的影响。先前关于“怀疑学习”（SKEL）的研究通过将离线主动标注与被动数据进行比较来解决标签噪音的问题，从而评估了注释的准确性，但没有包括最终用户的反馈，最终用户是最了解自己情况的评判者。因此，本研究旨在在真实世界的条件下评估SKEL的性能，让实际用户可以根据当前的观点和需求调整输入的标签。该研究涉及四周内使用iLog移动应用程序的大学生，结果强调了在用户努力和数据质量之间找到正确平衡的挑战，以及使用SKEL的潜在好处，包括减少标注工作量并提高收集数据的质量。", "innovation": "本研究创新在于将SKEL应用于现实生活中的实际用户中，通过用户的反馈和当前视角来调整和优化数据标签，填补了以往研究中缺乏用户参与评估的空白。此外，研究通过理解用户在不同场景下的需求和反馈，提高了数据标注的准确性和效用性。", "conclusion": "研究结果表明，在真实世界的应用中，使用怀疑学习(SKEL)进行自我中心数据清洗具有挑战但潜在的益处，包括减少了标注工作量和提高了收集数据的质量。然而，这也强调了在用户努力和数据质量之间找到正确平衡的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23636", "html_url": "https://arxiv.org/abs/2510.23636", "title": "通过大规模语言模型和航空轨迹表示的跨模态适应进行航班延误预测", "title_en": "Flight Delay Prediction via Cross-Modality Adaptation of Large Language Models and Aircraft Trajectory Representation", "authors": "Thaweerath Phisannupawong,Joshua Julian Damanik,Han-Lim Choi", "background": "航班延误已成为空中交通管理中的关键焦点，因为延误突显了影响整体网络性能的低效率问题。先前的研究通常采用基于轨迹的数据来预测航班延误，但本文从空中交通管制员监控飞机延误后的终端区域出发，提出了结合轨迹表示和文本航空信息的轻量级大型语言模型的多模态航班延误预测方法。这种方法整合了飞行信息、天气报告、机场通知等文本航空信息，通过将轨迹数据适应语言模态来捕捉空域状况，并取得了显著的效果，证明了语言理解结合跨模态适应轨迹信息在延误预测中的有效性。", "innovation": "该研究的关键创新在于将大型语言模型与航空轨迹表示相结合，通过跨模态适应的方法进行航班延误预测，利用文本航空信息（如飞行信息、天气报告、机场通知等）和轨迹数据，提高精确性。该方法在实验中实现了亚分钟级的预测误差，表明其能够有效利用与延误源相关的上下文信息，显示出其实用性和可扩展性，能够支持实时更新的预测，以适应新的操作信息。", "conclusion": "该命题框架展示了将语言理解与轨迹信息的跨模态适应相结合的有效性，提升了航班延误预测的准确性，并且该方法在实际操作中具有实用性和可扩展性，能够实时更新预测以更好地适应新的运营信息。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23638", "html_url": "https://arxiv.org/abs/2510.23638", "title": "通过负微分电阻网络连接函数逼近与器件物理", "title_en": "Bridging Function Approximation and Device Physics via Negative Differential Resistance Networks", "authors": "Songyuan Li,Teng Wang,Jinrong Tang,Ruiqi Liu,Yuyao Lu,Feng Xu,Bin Gao,Xiangwei Zhu", "background": "实现全模拟神经计算需要能够高效且原生执行线性和非线性操作的硬件。虽然计算在内存架构推进了模拟矩阵-向量乘法的发展，但非线性激活函数仍然是瓶颈，通常需要使用数字或混合解决方案。当前采用的技术仍无法同时在硬件层面进行高效地线性与非线性操作，这是推动模拟计算向前发展的关键挑战之一。", "innovation": "本文受到Kolmogorov-Arnold框架的启发，提出了KANalogue，采用负微分电阻器件作为可学习单变量基函数的物理实现来全模拟Kolmogorov-Arnold网络（KAN）。臂chair和zigzag器件被用于构造具有独特曲率和支持特性的坐标的非线性函数。通过提取并软件模拟这些微分电阻器件的I-V数据，并利用这些学习到的基函数来训练视觉基准测试上的KAN。实验结果表明，KANalogue能够在最少参数的情况下近似复杂函数，保持分类准确度与数字基准相当。这种工作将器件级别的物理性质与函数逼近理论紧密结合，为面向可扩展和节能的模拟机器学习系统指出了可能的发展路径。", "conclusion": "研究结果证明了KANalogue的有效性，通过全模拟KAN的方式，减少了参数量并保持了性能。此外，该工作还通过结合设备物理原理和函数逼近理论的技术路线，为实现更具竞争力的模拟机器学习系统铺平了道路。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23640", "html_url": "https://arxiv.org/abs/2510.23640", "title": "结构感知融合与渐进注入在多模态分子表示学习中的应用", "title_en": "Structure-Aware Fusion with Progressive Injection for Multimodal Molecular Representation Learning", "authors": "Zihao Jing,Yan Sun,Yan Yi Li,Sugitha Janarthanan,Alana Deng,Pingzhao Hu", "background": "多模态分子模型常常面临3D构象不可靠性和模态消融的问题，这限制了其在鲁棒性和泛化能力上的表现。", "innovation": "MuMo提出了一个结构化多模态融合框架，通过两类关键策略解决了分子表示中的挑战。MuMo设计了一个结构化融合管道(SFP)，将2D拓扑和3D几何统一为一个稳定结构先验，以减少依赖构象融合的不稳定性。此外，引入了渐进注入(PI)机制，不对称地将该先验整合到序列流中，确保模态特定建模的同时实现跨模态丰富。", "conclusion": "MuMo在29个基准任务中比最佳基线平均提高了2.7%，在22个任务中排名第一，包括LD50任务上的27%改进。这些结果证实了其对3D构象噪声的鲁棒性和多模态融合的效能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23641", "html_url": "https://arxiv.org/abs/2510.23641", "title": "SAL-T在粒子Jets分类中的空间感知线性变换器", "title_en": "Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging", "authors": "Aaron Wang,Zihan Zhao,Subash Katel,Vivekanand Gyanchand Sahu,Elham E Khoda,Abhijith Gandrakota,Jennifer Ngadiuba,Richard Cavanaugh,Javier Duarte", "background": "变换器在高能粒子碰撞中的应用非常有效，但由于信息吞吐量高的环境（如CERN LHC）的部署挑战，其二次复杂性导致了资源需求大和推理延迟高。文中分析了现有线性变换器架构（如Linformer）的瓶颈。", "innovation": "提出了空间感知线性变换器(SAL-T)，这是一种基于粒子动力学特性的物理启发式增强架构，保持了线性注意力。该方法通过基于空间感知的粒子分区计算具有物理意义区域之间的注意力。此外，SAL-T结合了用于局部相关性捕捉的卷积层，受Jets物理的见解激发。实验结果显示SAL-T在Jet分类任务上比标准线性变换器表现更好，同时在资源利用和推理延迟方面表现更优；并且在通用点云分类数据集(ModelNet10)上也验证了该趋势。", "conclusion": "SAL-T方法在资源消耗和推断延迟上优于线性变换器，同时在粒子Jet分类任务中达到与全注意变换器相似的分类结果。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23639", "html_url": "https://arxiv.org/abs/2510.23639", "title": "将基因组学融入多模态EHR基础模型", "title_en": "Integrating Genomics into Multimodal EHR Foundation Models", "authors": "Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T.J. Chen,Cory Y. McLean", "background": "本文介绍了将多基因风险评分（PRS）作为基础数据模式集成的人工智能健康信息系统（EHR）基础模型，超越了传统仅依赖EHR的数据方法，构建更加综合的医疗档案。通过All of Us (AoU)研究项目中的大量多元数据，该多模态框架旨在学习临床数据和遗传倾向之间的复杂关系。方法上，将生成式人工智能的最新进展应用到EHR基础模型领域，增强了预测能力和可解释性。在AoU数据上的评估展示了该模型对各种疾病发病时间的预测价值，特别是2型糖尿病（T2D），并说明了PRS与EHR数据之间的相互作用。研究还探讨了转移学习在自定义分类任务中的应用，展示了该架构的灵活性和高效性。这种方法对于解锁疾病的预测、积极健康管理、风险分层和个性化治疗策略方面的新见解至关重要，为更个性化、公平和可操作的临床证据生成奠定了基础。", "innovation": "通过将PRS集成进EHR基础模型，提出了一种超越传统EHR的方法，旨在学习临床数据和遗传倾向之间的复杂关系。将生成式人工智能最新进展应用到EHR基础模型中，提升了预测能力和解释性。该研究引入了转移学习方法来实现自定义分类任务，展示了架构的灵活性和效率。通过这种方法，研究工作为疾病的预测、主动健康管理、风险分层和个性化治疗策略提供了新的见解，并为更个性化、公平和可操作的临床证据生成奠定了基础。", "conclusion": "本文的研究工作对疾病预测、主动健康管理、风险分层和个性化治疗策略提供了新的见解，对于解锁新的医疗洞察至关重要，为更个性化、公平和可操作的临床证据生成奠定了基础。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23643", "html_url": "https://arxiv.org/abs/2510.23643", "title": "SAND: 自监督和自适应基于NAS的硬件木马检测框架", "title_en": "SAND: A Self-supervised and Adaptive NAS-Driven Framework for Hardware Trojan Detection", "authors": "Zhixin Pan,Ziyu Shu,Linh Nguyen,Amberbir Alemayoh", "background": "全球化的半导体供应链使得硬件木马（HT）成为嵌入式系统中的一个重要安全威胁，需要设计高效的适应性检测机制。尽管文献中有许多基于机器学习的硬件木马检测技术，但它们存在手动特征选择不规范和缺乏适应性的问题，这阻碍了其在不同硬件木马攻击中的有效性。", "innovation": "本文提出了一种名为SAND的自监督和自适应基于神经架构搜索（NAS）的硬件木马检测框架。具体来说，本文做出了三个关键贡献：(1) 利用自监督学习（SSL）实现自动化特征提取，消除对人工设计特征的依赖；(2) 将神经架构搜索（NAS）集成到下游分类器中，使其能够无缝适应新的基准检测需求，减少微调；(3) 实验结果表明，SAND相比现有方法，在检测准确率上提高了最高18.3%，具有很强的对抗欺骗性硬件木马的能力，表现出良好的泛化能力。", "conclusion": "实验结果表明，SAND在检测准确率上取得了显著提升，对欺骗性硬件木马具有很高的抗性，并具备强大的泛化能力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23642", "html_url": "https://arxiv.org/abs/2510.23642", "title": "VisCoder2: 构建多语言可视化编码代理", "title_en": "VisCoder2: Building Multi-Language Visualization Coding Agents", "authors": "Yuansheng Ni,Songcheng Cai,Xiangchao Chen,Jiarong Liang,Zhiheng Lyu,Jiaqi Deng,Kai Zou,Ping Nie,Fei Yuan,Xiang Yue,Wenhu Chen", "background": "现有的大语言模型（LLMs）能够生成、执行和修订可视化代码，但实际工作流程中仍面临诸多挑战，如语言覆盖有限、执行不可靠、缺乏迭代修正机制。这些问题制约了进展，因为现有数据集和基准测试关注的是单轮生成和单语言任务。", "innovation": "本文提出了三种为推进可视化编码代理而设计的资源。VisCode-Multi-679K 是一个大型监督数据集，包含679K 经验证并可执行的可视化样本，涉及多轮修正对话及12种编程语言。VisPlotBench 是一个基准测试，包含可执行任务、渲染输出和一轮或多轮自调试协议。此外，还介绍了基于VisCode-Multi-679K 训练的VisCoder2 多语言可视化模型系列，实验表明VisCoder2 在整体执行通过率（32B 规模达到82.4%）等多个方面显著优于开源基线并接近私有模型如GPT-4 的性能，并且通过多重自调试进一步提升。", "conclusion": "VisCoder2 显著提升了多语言可视化编码代理的性能，特别是在符号或编译依赖语言中效果尤为明显，体现了其在复杂任务下的显著优势。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23648", "html_url": "https://arxiv.org/abs/2510.23648", "title": "RoGBot：不依赖关系的基于图的神经网络与上下文知识应用于机器人检测", "title_en": "RoGBot: Relationship-Oblivious Graph-based Neural Network with Contextual Knowledge for Bot Detection", "authors": "Ashutosh Anshul,Mohammad Zia Ur Rehman,Sri Akash Kadali,Nagendra Kumar", "background": "自动账户（机器人）在社交媒体平台（如Twitter）上的检测是一个具有挑战性的任务，因为这些账户的行为和策略不断变化。尽管最近的方法通过组合基于图的框架中的文本、元数据和用户关系信息来实现高性能的检测，但许多模型严重依赖于显式用户间关系数据。这种依赖性限制了它们在缺乏此类信息场景中的应用。", "innovation": "本文提出了一种新颖的模态融合框架，该框架整合了详细的文本特征和丰富的用户元数据，同时避免使用需要追随者-关注者数据的图基于推理。通过使用基于变压器的模型（如BERT）从推文中提取深层次语义嵌入，并使用Max Pooling进行聚合形成全面的用户级表示。进一步结合辅助行为特征并通过GraphSAGE模型捕捉用户行为的局部和全局特征，实现了对日益复杂的机器人策略的高效检测。", "conclusion": "实验证据展示了本文方法的鲁棒性，在Cresci-15、Cresci-17和PAN 2019数据集上分别实现了99.8%、99.1%和96.8%的准确率，突出了其在检测复杂机器人策略方面的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23649", "html_url": "https://arxiv.org/abs/2510.23649", "title": "高效低秩注意力机制用于大型语言模型长上下文推理", "title_en": "Efficient Low Rank Attention for Long-Context Inference in Large Language Models", "authors": "Tenghui Li,Guoxu Zhou,Xuyang Zhao,Yuning Qiu,Qibin Zhao", "background": "随着输入文本长度的增长，大型语言模型（LLM）中的键值（KV）缓存会对GPU内存造成巨大的成本，限制了在资源受限设备上进行长上下文推理的能力。现有的方法，如KV量量化和剪枝，可以减少内存使用，但会牺牲数值精度或关键值对的最优保留。这一问题亟待解决，以满足更多场景的需求。", "innovation": "论文提出了低秩查询和键注意（LRQK）框架，这是一种两阶段的方法，在预填充阶段将全精度查询和键矩阵分解为紧凑的秩-r因子，然后在解码的每一步中使用这些低维投影来计算代理注意分数。此外，该方法采用了混合GPU-CPU缓存机制，仅传送缺少的全精度KV对，从而保持了精确的注意输出并减少了GPU-CPU之间的数据传输。这种机制在保持低内存使用的同时，也能提供接近或超过顶级稀疏注意方法的效果，而对准确性的损失极小。", "conclusion": "在RULER和LongBench基准上使用LLaMA-3-8B和Qwen2.5-7B进行的广泛实验表明，LRQK在长上下文设置中与最先进的稀疏注意方法相匹配或超越，并且能实现显著的内存节省，同时损失最小的准确性。该代码已经在GitHub上提供。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23650", "html_url": "https://arxiv.org/abs/2510.23650", "title": "超越隐藏层操作：语义感知的logits干预方法在消除LLM偏见中的应用", "title_en": "Beyond Hidden-Layer Manipulation: Semantically-Aware Logit Interventions for Debiasing LLMs", "authors": "Wei Xia", "background": "本文探讨了消除大型语言模型（LLM）偏见的方法。以往的研究主要集中在通过干预隐藏层来减少模型的偏见，但这种方法可能会牺牲模型的流畅性。本文提出了Static和Dynamic两种零样本logits层去偏方法，旨在通过干预logits层直接减少模型的偏见，而且在提高去除偏见的效果同时，尽量保持模型的流畅性。", "innovation": "本文提出的两种零样本logits层去偏方法（Static和Dynamic）能够有效地减少模型偏见，其中Dynamic方法可将偏见降低高达70%，而且能最大限度地保持模型的流畅性。此外，语义感知的logits干预方法被证明比隐藏层干预方法更有效且更稳定，能够更好地对齐LLM的偏见。", "conclusion": "本文提出的语义感知logits干预方法能够有效减少LLM的偏见，同时保持模型的流畅性，证明了这是一种更为有效且稳定的方法来实现LLM的去偏。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23652", "html_url": "https://arxiv.org/abs/2510.23652", "title": "结构化手术刀：用于大型语言模型的自动化连续层剪枝", "title_en": "The Structural Scalpel: Automated Contiguous Layer Pruning for Large Language Models", "authors": "Yao Lu,Yuqi Li,Wenbin Xie,Shanqing Yu,Qi Xuan,Zhaowei Zhu,Shiping Wen", "background": "虽然大型语言模型（LLMs）在许多领域取得了革命性的突破，但其庞大的模型规模和高昂的计算成本给在资源受限的边缘设备上的实际部署带来了巨大挑战。为了应对这些问题，提出了层剪枝方法来通过直接移除冗余层来减少计算开销。然而，现有的层剪枝方法通常依赖于手工设计的指标来评估和移除单独的层，而忽略了层之间的依赖关系。这可能导致模型信息流的中断，并严重降低性能。", "innovation": "本文提出了一种新颖的连续层剪枝框架CLP，它包括两个关键创新：一种可微凹门限算法（differential concave gate algorithm），该算法通过基于梯度的优化自动生成最佳连续层段以进行剪枝；以及一个端点调节策略，该策略通过仅微调剪枝段相邻的层来有效恢复模型性能。这些创新解决了现有方法忽视层依赖关系的问题，从而实现更有效的剪枝并保持更好的性能。", "conclusion": "在多个模型架构（包括LLaMA2、LLaMA3和Qwen）和大小（从7B到70B个参数）上进行的广泛实验表明，CLP显著优于现有的最先进基线。例如，在20%的剪枝率下，CLP在LLaMA3-70B上的平均性能保留率为95.34%，比基线高出4.29%至30.52%。此外，CLP可以无缝结合量化，进一步压缩模型，仅造成轻微的性能损失。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23656", "html_url": "https://arxiv.org/abs/2510.23656", "title": "基于时空相关融合的误差调整方法在交通预测中的应用", "title_en": "Error Adjustment Based on Spatiotemporal Correlation Fusion for Traffic Forecasting", "authors": "Fuqiang Liu,Weiping Ding,Luis Miranda-Moreno,Lijun Sun", "background": "深度神经网络（DNNs）在交通预测领域的研究中发挥重要作用，主要是因为它们能够有效捕捉交通数据中的时空模式。现有研究通常假设通过均方误差估计训练预测模型时，预测误差在时间步长和空间位置之间是不相关的，但实际上由于交通数据的时空自相关性，这一假设不成立，从而限制了基于DNN的预测模型的性能。现有研究忽视了这一点。本文提出了一种新颖的一般框架Spatiotemporally Autocorrelated Error Adjustment（SAEA），它能够系统地调整交通预测中的时空相关预测误差，纠正了这一不足。SAEA不假设预测误差遵循随机高斯噪声分布，而是将其建模为时空向量自回归（VAR）过程，以捕捉内生的依赖性。", "innovation": "SAEA模型将时空误差相关性明确嵌入到新的成本函数中，通过系数矩阵捕捉时空误差相关性，并引入结构稀疏正则化以融合先验的时空信息，确保学习到的系数矩阵与内置的道路网络结构对齐。此外，文章设计了一个测试时误差调整的推理过程，动态细化预测，减轻了实时预测中相关误差的影响。", "conclusion": "在不同交通数据集上的实验证明，所提出的方法在几乎所有情况下都提高了性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23658", "html_url": "https://arxiv.org/abs/2510.23658", "title": "通过无配对偏好优化对扩散语言模型进行对齐", "title_en": "Aligning Diffusion Language Models via Unpaired Preference Optimization", "authors": "Vaibhav Jindal,Hejian Sang,Chun-Mao Lai,Yanning Chen,Zhipeng Wang", "background": "扩散语言模型（dLLMs）作为一种新兴的替代自回归（AR）生成器的方法，具有挑战性地需要对它们进行人类偏好对齐，因为序列对数似然不可计算且成对偏好数据难以收集。", "innovation": "提出了ELBO-KTO方法，结合了扩散对数似然的ELBO近似与前景理论导向的无成对偏好目标（Kahneman Tversky Optimization, KTO），同时分析了ELBO近似带来的偏差和方差，并采用减小方差的技术稳定训练过程中的梯度。在LLaDA-8B-Instruct上实现测试表明，ELBO-KTO在kto-mix-14k和UltraFeedback-Binary上的调整胜率分别为65.9%和62.3%，优于基础模型。", "conclusion": "ELBO-KTO在 UltraFeedback-Binary上的训练结果显示，在下游任务，如GSM8K、MMLU和额外的推理/知识基准测试上，对齐后的模型表现与基础模型相当或更优，从而确立了无配对偏好优化在扩散LLMs中的可行性替代方案，相比成对对齐更实际。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23660", "html_url": "https://arxiv.org/abs/2510.23660", "title": "肺炎检测中的量子卷积神经网络：一种高效的量子辅助特征提取范式", "title_en": "Quanvolutional Neural Networks for Pneumonia Detection: An Efficient Quantum-Assisted Feature Extraction Paradigm", "authors": "Gazi Tanbhir,Md. Farhan Shahriyar,Abdullah Md Raihan Chy", "background": "肺炎构成了全球公共卫生的重大挑战，急需准确和及时的诊断。尽管深度学习，尤其是卷积神经网络（CNNs），在肺炎检测的医学图像分析中显示出了潜力，但是CNNs常常受到高计算成本、特征表示限制和从较小数据集泛化的挑战。为了应对这些限制，本文探讨了将量子卷积神经网络（QNNs）应用于肺炎检测，利用量子计算提高特征提取能力。", "innovation": "本文通过引入一种新颖的量子-经典混合模型，利用参数化量子电路（PQC）处理2x2图像块，结合旋转Y门和纠缠层生成非经典特征表示，实现量子特征提取，并将提取的量子特征输入经典神经网络进行分类。实验结果表明，提出的QNN相较于一个可比的经典CNN，在验证准确率上达到83.33%，而经典CNN达到73.33%，这突显了QNNs在医疗图像分析中的潜在价值，尤其是在有限标记数据的场景中。", "conclusion": "本文的研究为将量子计算整合到基于深度学习的医学诊断系统中奠定了基础，提供了一种比传统方法更具计算效率的替代方案。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23665", "html_url": "https://arxiv.org/abs/2510.23665", "title": "从压缩表示生成的变压器", "title_en": "Transformers from Compressed Representations", "authors": "Juan C. Leon Alcazar,Mattia Soldan,Mohammad Saatialsoruji,Alejandro Pardo,Hani Itani,Juan Camilo Perez,Bernard Ghanem", "background": "压缩文件格式是高效数据存储和传输的基础，但它们在表示学习方面的潜力仍被大大忽视。现有的方法依赖于原始字节级处理或完全解码媒体内容，而如何有效利用压缩文件本身的特性来设计新的方法以直接从压缩数据流中学习语义表示，仍然是个待突破的领域。", "innovation": "介绍了TEMPEST（从压缩表示生成的变压器）方法，通过利用压缩文件固有的字节流结构来设计有效的分词和编码策略，使标准变压器能够直接从压缩数据流中学习语义表示，而无需进行原始字节级别处理或全媒体解码。这种方法显著减少了语义分类所需的令牌数量，从而降低了计算复杂度和内存使用量。通过跨多个数据集、编码方案和模态的广泛实验，证明了TEMPEST在准确率与最先进的方法相当的同时，实现了内存和计算效率的提升。", "conclusion": "TEMPEST方法在保持与最先进的方法相似的高准确率的同时，通过有效利用压缩数据流直接进行语义表示学习，显著降低了计算复杂性和内存使用量。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23669", "html_url": "https://arxiv.org/abs/2510.23669", "title": "AI实际上在做什么工作？揭示生成式AI采用的驱动因素", "title_en": "What Work is AI Actually Doing? Uncovering the Drivers of Generative AI Adoption", "authors": "Peeyush Agarwal,Harsh Agarwal,Akshat Ranaa", "background": "随着人工智能系统如ChatGPT、Claude AI等的迅速集成，它们对工作方式产生了深远影响。预测人工智能将如何重塑工作要求不仅要理解其能力，还要了解其实际采用情况。本文探讨了哪些内在任务特征驱动用户将其工作委托给AI系统。", "innovation": "本研究首次系统地证明了现实世界中生成式AI使用与综合多维内在任务特征之间的联系。它引入了一种基于数据的任务分类体系，为分析新兴的人类-AI劳动分工提供了一个新的框架。", "conclusion": "我们的分析揭示了高度集中的AI使用模式，只有5%的任务占用了59%的所有互动。AI适用性最好由任务特征的组合而不是个别因素来预测。任务要求高度创造性、复杂性和认知需求，但低自动化程度的，吸引了最多的AI参与。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23668", "html_url": "https://arxiv.org/abs/2510.23668", "title": "交通流量预测：基于STL分解的LSTM ARIMA XGBoost混合模型", "title_en": "Traffic flow forecasting, STL decomposition, Hybrid model, LSTM, ARIMA, XGBoost, Intelligent transportation systems", "authors": "Fujiang Yuan,Yangrui Fan,Xiaohuan Bing,Zhen Tian,Chunhong Yuan,Yankang Li", "background": "准确的交通流量预测是智能交通系统和城市交通管理的重要前提。然而，单一模型往往无法捕捉交通流量数据中的复杂、非线性和多尺度的时间模式。因此，有必要寻求能够更好地适应这些复杂特性的方法。", "innovation": "本文提出了一种基于STL分解的混合预测框架，结合了LSTM、ARIMA和XGBoost三种互补预测模型。首先，STL分解将原始时间序列分解为趋势、季节性和残差分量。然后，LSTM负责建模长期趋势，ARIMA捕捉季节性周期性，XGBoost预测非线性残差波动。最终预测是通过子模型预测的加权组合获得的。这种方法通过隔离时间特性，使每个模型能够专业化，从而提高了预测准确性、可解释性和鲁棒性，特别是在MAE、RMSE和R squared三个指标上优于单一LSTM、ARIMA和XGBoost模型。", "conclusion": "基于STL分解的LSTM ARIMA XGBoost混合模型在预测中新颖地利用了模型的互补优势，通过有效隔离时间特性，提高了预测性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23664", "html_url": "https://arxiv.org/abs/2510.23664", "title": "Agentsway — 基于AI代理团队的软件开发方法", "title_en": "Agentsway -- Software Development Methodology for AI Agents-based Teams", "authors": "Eranga Bandara,Ross Gore,Xueping Liang,Sachini Rajapakse,Isurunima Kularathne,Pramoda Karunarathna,Peter Foytik,Sachin Shetty,Ravi Mukkamala,Abdul Rahman,Amin Hass,Ng Wee Keong,Kasun De Zoysa,Aruna Withanage,Nilaan Loganathan", "background": "随着代理型人工智能（Agentic AI）的发展，软件设计、开发和维护的方式正经历着根本性的转变。传统的以人类为中心的软件开发方法论（如敏捷开发、看板、ShapeUp等），原本是为人类团队设计的，在AI代理参与规划、编码、测试和持续学习的环境中逐渐显现出不足。因此，亟需一种新的软件开发框架来填补这一方法论上的空白。", "innovation": "文中提出了一种新型的软件开发框架——Agentsway，该框架旨在为在软件开发生态系统中代理型AI作为首要协作者运作的团队设计。主要创新点包括：1) 引入了以人类编排为中心的结构化生命周期及AI代理间的隐私保护合作；2) 定义了计划、提示、编程、测试和微调代理的专门角色，促进整个开发过程中的迭代改进和自适应学习；3) 微调的大型语言模型（LLMs）作为代理反馈机制的一部分，增强了领域特定推理和可解释决策；4) 通过协调使用多个微调后的LLMs和高级推理模型嵌入负责任的人工智能原则，确保协调、透明和可问责的决策。", "conclusion": "Agentsway 正朝着下一代基于AI的、自我提升的软件开发方法论迈出了一步。通过正式化代理式合作、整合隐私设计原则以及定义可衡量的生产力和信任指标，它为软件工程领域带来了重要进展。据我们所知，这是一次专门设计用于AI代理团队的首个研究努力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23671", "html_url": "https://arxiv.org/abs/2510.23671", "title": "MoE中的稀疏性和叠加", "title_en": "Sparsity and Superposition in Mixture of Experts", "authors": "Marmik Chaudhari,Jeremi Nuer,Rome Thorstenson", "background": "混合专家（MoE）模型已成为扩展大型语言模型的关键，但MoE模型与密集型网络在机理上的区别仍未得到充分理解。前期工作探讨了密集网络如何通过叠加（叠加性）表示多于维度的特征，叠加性由特征稀疏性和重要性决定。而MoE模型无法用同样的视角进行解释。研究表明，特征稀疏性和重要性并不能引起分阶段的变化，而是网络稀疏性（活跃专家与总专家的比例）更好地描述了MoE模型。", "innovation": "该研究开发了新的指标来衡量专家间的叠加性，并发现网络稀疏性更大的模型表现出更强的单义性（降低多义性）。提出了基于特征单一表征的新专家专业化定义，而非以负载均衡为基础，显示了适当初始化的专家自然围绕共现特征组合进行组织。这些结果表明MoE模型中的网络稀疏性可能使模型更具可解释性而不牺牲性能，挑战了可解释性和能力不可兼得的普遍假设。", "conclusion": "研究表明MoE模型中的网络稀疏性能够促进更可解释的模型构建，同时保持甚至提升模型性能。这一结论表明可解释性和模型能力并不必然冲突。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23667", "html_url": "https://arxiv.org/abs/2510.23667", "title": "任意结构拓扑优化：一种形状和分辨率无关的结构拓扑优化基础模型", "title_en": "Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free Structural Topology Optimization", "authors": "Amin Heyrani Nobari,Lyle Regenwetter,Cyril Picard,Ligong Han,Faez Ahmed", "background": "结构拓扑优化是工程设计的核心内容，但由于复杂物理现象和严格的约束条件，仍然具有高度计算密集型的特点。现有的深度学习方法受限于固定正方形网格、有限的手动边界条件以及后处理优化，无法普遍应用。", "innovation": "本文引入了Optimize Any Topology (OAT)，一种基础模型框架，能够直接预测任意长宽比、分辨率、体积分数、载荷和固定条件下的最小合规度布局。OAT 结合了一个无分辨率和无形状先验的自动编码器、隐式神经场解码器，并在OpenTO训练集中进行了条件潜在扩散模型训练，该训练集包含了200万种独特的边界条件配置，拥有220万种优化结构。在四组公开基准测试和两个具有挑战性的未见测试中，OAT 将相对最优模型的平均合规度降低了最多90%，且在单个GPU上从64 x 64到256 x 256的分辨率和10:1的高宽比范围内，实现了1秒以下的推理速度。这些结果确立了OAT为物理感知拓扑优化提供的通用、快速和无分辨率框架，还提供了一个大规模数据集，以推动生成建模在逆向设计中的进一步研究。", "conclusion": "这些结果确立了OAT作为物理感知拓扑优化的通用、快速和无分辨率框架，并提供了一个大规模的数据集，以推进生成建模在逆向设计中的进一步研究。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23674", "html_url": "https://arxiv.org/abs/2510.23674", "title": "RefleXGen:未经审查的代码不值得使用", "title_en": "RefleXGen:The unexamined code is not worth using", "authors": "Bin Wang,Hui Li,AoFan Liu,BoTao Yang,Ao Yang,YiLu Zhong,Weixiang Huang,Yanping Zhang,Runhuai Huang,Weimin Zeng", "background": "在应用大语言模型（LLMs）时，代码安全性仍然是一个核心挑战。传统的应对方法包括微调LLMs或开发专门的安全代码数据集，但这些方法需要大量资源。", "innovation": "本文提出了RefleXGen，这是一种创新的方法，通过将检索增强生成（RAG）技术与LLMs内在的引导式自我反思机制相结合，显著提升代码安全性。该方法不需要大量的资源就能优化代码生成过程。实验结果表明，RefleXGen在多个模型中提高了代码安全性，具体为：GPT-3.5 Turbo提高13.6%，GPT-4o提高6.7%，CodeQwen提高4.5%，Gemini提高5.8%。", "conclusion": "我们的研究结果表明，提高模型自我反思的质量是加强AI生成代码安全的有效且实用策略。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23675", "html_url": "https://arxiv.org/abs/2510.23675", "title": "QueryIPI：代码代理中的查询无关间接提示注入", "title_en": "QueryIPI: Query-agnostic Indirect Prompt Injection on Coding Agents", "authors": "Yuchong Xie,Zesen Liu,Mingyu Luo,Zhixiang Zhang,Kaikai Zhang,Zongjie Li,Ping Chen,Shuai Wang,Dongdong She", "background": "现代集成到集成开发环境（IDE）中的编码代理结合了强大的工具和系统级操作，暴露了高风险的攻击面。现有的间接提示注入（IPI）研究主要关注查询特定的行为，导致攻击不稳定且成功率较低。", "innovation": "我们识别出了一种更严重的、查询无关的威胁，这种威胁在各种用户输入下仍保持有效。我们通过利用代理内部提示的泄漏来利用这一挑战，将攻击转化为受限的白盒优化问题。我们提出了QueryIPI，这是一种针对编码代理的首款查询无关的IPI方法。QueryIPI通过迭代的提示过程对恶意工具描述进行细化，其中受到泄漏的内部提示的指导。实验结果表明，QueryIPI在五种模拟代理上的成功率高达87%，显著优于基线，且生成的恶意描述也可应用于实际系统，突显了现代基于LLM的编码代理的实践安全风险。", "conclusion": "QueryIPI通过细化恶意工具描述并在五种模拟代理上的有效性验证，展示了其在现代基于LLM的编码代理中的应用潜力，提出了新的攻击面并验证了其实用安全风险。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23693", "html_url": "https://arxiv.org/abs/2510.23693", "title": "机器学习的社会影响", "title_en": "On the Societal Impact of Machine Learning", "authors": "Joachim Baumann", "background": "机器学习（ML）越来越多地影响重要的决策和建议，显著影响着我们的生活方方面面。然而，由于这些数据驱动系统往往缺乏明确的公平性考虑，在开发过程中容易引入歧视性影响。", "innovation": "本论文提出了更为合适地测量ML系统公平性的方法；系统分解ML系统以预见偏差动态；有效的干预措施以减少算法性歧视，同时保持系统功能。", "conclusion": "本研究最后讨论了ML系统，包括生成式人工智能，日益融入社会所带来的持续挑战与未来研究方向。本工作为确保ML的社会影响与更广泛的社会价值保持一致奠定了基础。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23685", "html_url": "https://arxiv.org/abs/2510.23685", "title": "平行BiLSTM-Transformer网络在预测混沌动态中的应用", "title_en": "Parallel BiLSTM-Transformer networks for forecasting chaotic dynamics", "authors": "Junwen Ma,Mingyu Ge,Yisen Wang,Yong Zhang,Weicheng Fu", "background": "混沌系统的非线性特征导致对初始条件的极端敏感性和极其复杂的动态行为，这给准确预测其演变带来了根本性挑战。传统方法难以同时捕捉混沌时间序列的局部特征和全局依赖性，因而存在局限性。", "innovation": "本文提出了一种结合Transformer和双向长短期记忆网络（BiLSTM）的并行预测框架。该混合模型采用双重分支架构，Transformer分支主要用于捕获长距离依赖性，而BiLSTM分支则侧重于提取局部时间特性。两种分支的互补表示在专用的特征融合层中进行融合，以增强预测准确性。同时，该模型在洛伦兹系统中的两个代表性任务上系统性地进行了评估，包括自主演化预测和未测量变量的推断，评估其长期跟踪准确性和状态恢复能力。实验结果表明，提出的混合框架在各种任务中均优于单一分支架构，显示出其在混沌系统预测中的稳健性和有效性。", "conclusion": "本文提出了一种创新的并行预测框架，结合了Transformer和BiLSTM网络，显著提升了混沌系统预测的准确性，并证明了该模型在混沌系统预测中的稳健性和有效性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23751", "html_url": "https://arxiv.org/abs/2510.23751", "title": "使用保证的表示学习消除奖励模型中的偏差", "title_en": "Debiasing Reward Models by Representation Learning with Guarantees", "authors": "Ignavier Ng,Patrick Blöbaum,Siddharth Bhandari,Kun Zhang,Shiva Kasiviswanathan", "background": "近年来，基于人类反馈的强化学习等对齐技术被广泛应用，用于使大型语言模型与人类偏好对齐，这主要依赖于建立和利用奖励模型。然而，这些模型在实践中常因白 BuzzFeed，如响应长度、歧视、溜须拍马以及概念偏差等问题而受到负面关注。这些问题正逐渐受到关注。", "innovation": "本文提出了一种基于表示学习的有保证的框架，旨在减轻奖励模型中的偏见，同时保留反映预期偏好的潜在因素。该框架首先从数据生成过程提供了一个建模，假设观察到的数据（如文本）来源于虚假与非虚假的潜在变量。有趣的是，研究表明，即使没有虚假潜在变量的替代指标，非虚假的潜在变量也可从数据中理论性地识别。基于此，提出了使用变分推理恢复这些变量，并利用这些变量训练奖励模型的实用方法。", "conclusion": "实验结果表明，该方法能有效减轻虚假相关性问题并产生更稳健的奖励模型。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23682", "html_url": "https://arxiv.org/abs/2510.23682", "title": "超越指令工程：神经语义因果架构的稳健多目标AI代理", "title_en": "Beyond Prompt Engineering: Neuro-Symbolic-Causal Architecture for Robust Multi-Objective AI Agents", "authors": "Gokturk Aytug Akarlar", "background": "大型语言模型作为自主决策代理显示出潜力，但在高风险领域部署时面临诸多风险。缺乏架构保护措施的大型语言模型（LLM）代理表现出灾难性脆弱性：相同能力在不同提示框架下产生截然不同的结果。本文分析了在现实电商环境中，LLM代理在策略优化与品牌信任下的表现差异，强调了架构设计而非指令工程对自主代理可靠性的影响。", "innovation": "本文提出了Chimera架构，这是一种综合了神经语义因果结构的神经-符号-因果模型，它结合了LLM策略员、形式验证的符号约束引擎和因果推理模块来处理假设因果关系。该架构在52周的仿真中表现出超越基线模型（仅LLM，LLM加符号约束）的优势，并通过形式验证保证了零约束违反，展示了在各类场景中的稳健性和整体提升的效果。", "conclusion": "本文的实验结果表明，架构设计而非指令工程是决定生产环境中自主代理可靠性的关键因素。Chimera架构不仅在多种目标优化下提供了更好的收益和品牌信任，而且通过TLC+形式验证证明了其可靠性。该研究提供了开源实现和交互演示，以确保可重复性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23756", "html_url": "https://arxiv.org/abs/2510.23756", "title": "通过增量概念形成解释对灾难性遗忘的稳健性", "title_en": "Explaining Robustness to Catastrophic Forgetting Through Incremental Concept Formation", "authors": "Nicki Barari,Edward Kim,Christopher MacLellan", "background": "灾难性遗忘是连续学习领域的核心挑战之一，模型需要随时间整合新知识而不丢失已有知识。在先前的研究中，作者提出了一种层次结构的概念形成模型Cobweb/4V，该模型在视觉领域展示了对灾难性遗忘的稳健性。", "innovation": "本文提出了三个关于稳健性因素的假设：（1）自适应结构重组增强知识保留，（2）稀疏和选择性的更新减少干扰，（3）基于充分统计量的信息理论学习优于基于梯度的反向传播。通过与神经基线模型（包括论文中提出的CobwebNN）进行比较，实验表明自适应重组增强了学习的可塑性，稀疏更新有助于减轻干扰，而信息理论学习过程可以在不重访过去数据的情况下保留先验知识。", "conclusion": "这些发现为理解能够减轻灾难性遗忘的机制提供了见解，并突显了基于概念的信息理论方法在构建稳定和适应性强的连续学习系统中的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23673", "html_url": "https://arxiv.org/abs/2510.23673", "title": "MCPGuard：自动检测MCP服务器中的漏洞", "title_en": "MCPGuard : Automatically Detecting Vulnerabilities in MCP Servers", "authors": "Bin Wang,Zexin Liu,Hao Yu,Ao Yang,Yenan Huang,Jing Guo,Huangsheng Cheng,Hui Li,Huiyu Wu", "background": "MCP作为一种标准化接口，使大型语言模型（LLMs）和外部数据源及工具之间无缝集成。尽管MCP简化了开发复杂性并增强了代理能力，但其开放性和可扩展性也带来了关键的安全漏洞，威胁系统的可信度和用户数据保护。本文系统地分析了基于MCP系统的安全状况，识别了三个主要威胁类别：(1) 协议设计缺陷导致的代理劫持攻击；(2) 存在于MCP服务器中的传统网络漏洞；(3) 供应链安全问题。", "innovation": "本文全面调查并评估了现有的防御策略，包括多层次检测管道、代理审查框架和零信任注册系统等主动服务器端扫描方法，以及运行时交互监测解决方案，实现持续监控和策略执行。研究表明，MCP安全从根本上代表了一种新的范式转移，攻击面从传统的代码执行扩展到自然语言元数据的语义解释，需要针对这一独特威胁模型开发新的防御机制。", "conclusion": "MCPGuard通过对MCP服务器进行自动漏洞检测，有效地识别并缓解了MCP相关的安全威胁，为保障MCP及其依赖系统的安全性提供了实用解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23761", "html_url": "https://arxiv.org/abs/2510.23761", "title": "TDFlow：基于测试驱动的智能工作流", "title_en": "TDFlow: Agentic Workflows for Test Driven Software Engineering", "authors": "Kevin Han,Siddharth Maddikayala,Tim Knappe,Om Patel,Austen Liao,Amir Barati Farimani", "background": "该研究背景在于软件工程中，特别是在解决大规模仓库级别的代码修复任务时，自动化的测试和修复流程显得尤为重要。现有系统往往难以有效处理人类编写的测试，导致性能较低。TDFlow旨在通过引入一种新的测试驱动型智能工作流来改进这一问题，该工作流将大型代码仓库的软件工程任务简化为测试问题的解决过程，特别设计用于解决人类编写的测试问题。", "innovation": "TDFlow的主要创新点在于提出了一种新的人工测试驱动型工作流（Agentic Workflow），这种方法将大代码仓库级别的软件工程问题分解为四个受特定子代理指导的组件：修复建议、调试、修复修订以及可选测试生成。这种简单的拆分方法不仅减少了每个子代理的负担，还使其专注于特定的子任务，并允许在这些特定子任务上进行专门化改进。此外，通过TDFlow，当提供人类编写的测试时，通过对SWE-Bench Lite的评估，其通过率达到了88.8%，比第二好的系统提高了27.8%，展示了人类水平的软件工程性能。同时，该研究还指出了人类级软件工程性能的主要障碍在于成功复现测试的编写。", "conclusion": "TDFlow的研究结果表明，现代大语言模型（LLMs）嵌入在这种狭窄工程化的、测试驱动的工作流中，已经能够达到人类级的测试解决水平。未来完全自主的代码修复的最后一道挑战将是生成准确的复现测试。TDFlow的工作为人类开发者与大语言模型交互的新系统提供了理论支持，即人类开发者编写由大语言模型解决的测试。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23775", "html_url": "https://arxiv.org/abs/2510.23775", "title": "使用Faster-Than-Lies和视觉语言模型进行边缘设备上具有局部化艺术制品的可解释检测的AI生成图像检测", "title_en": "Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices", "authors": "Aryan Mathur,Asaduddin Ahmed,Pushti Amit Vasoya,Simeon Kandan Sonar,Yasir Z,Madesh Kuppusamy", "background": "随着AI生成的图像越来越逼真，验证视觉真实性变得更具挑战性。本文研究了如何通过结合轻量级卷积分类器和视觉语言模型来检测和解释低分辨率图像中的艺术制品，以应对这一挑战。", "innovation": "提出了一种可解释的图像真实性检测系统，该系统结合了轻量级卷积分类器“Faster-Than-Lies”和视觉语言模型Qwen2-VL-7B，用于分类、定位和解释32x32图像中的艺术制品。该模型在扩展的CiFAKE数据集中达到了96.5%的准确率，并且在8核CPU上可以保持175ms的推理时间，适用于本地或边缘设备的部署。通过自编码器生成的重构误差图生成了艺术制品定位热图，提高了人类和VLM的可解释性。进一步将70种视觉艺术制品类型分为八大语义类别，并为每个检测到的异常生成可解释的文本。", "conclusion": "该研究强调结合视觉和语言推理以实现低分辨率图像中的可解释真实性检测的可行性，并指出潜在的跨域应用，包括法医鉴定、工业检测和社会媒体管理。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23785", "html_url": "https://arxiv.org/abs/2510.23785", "title": "CountFormer: 一种基于变换器的学习视觉重复和结构的类无关对象计数框架", "title_en": "CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting", "authors": "Md Tanvir Hossain,Akif Islam,Mohd Ruhul Ameen", "background": "人类可以通过感知视觉重复和结构关系来轻松地计数不同种类的对象，而不是依赖于类别身份。然而，现有的大多数计数模型在处理复杂形状、内部对称或重叠部分的对象时往往会出错，不能像人类那样计数。", "innovation": "CountFormer 是一种基于变换器的框架，能够学习在类无关的情况下识别重复和结构一致性来进行对象计数。它使用 DINOv2 自监督基础模型替代视觉编码器，增强了空间一致的特征表示，并结合位置嵌入融合来保持几何关系，通过轻量级的卷积解码器将特征解码为密度图。该模型在 FSC-147 数据集上的表现与当前最先进的方法相当，并且在结构复杂或密集排列的场景中具有更好的准确性。研究结果表明，集成基础模型如 DINOv2 可以使计数系统接近人类的结构感知，朝着真正通用且无需示例的计数范式发展。", "conclusion": "CountFormer 通过在类无关的场景中识别重复和结构一致性，提高了复杂或密集排列场景中的计数准确性，展示了与当前最先进的方法具有竞争力的性能，并为未来的计数系统提供了新的解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23798", "html_url": "https://arxiv.org/abs/2510.23798", "title": "使用现场摄像机监测城市河流中漂浮人为垃圾的几何和深度学习可重复管道", "title_en": "A geometric and deep learning reproducible pipeline for monitoring floating anthropogenic debris in urban rivers using in situ cameras", "authors": "Gauthier Grimmer,Romain Wenger,Clément Flint,Germain Forestier,Gilles Rixhon,Valentin Chardon", "background": "城市河流中的漂浮人为垃圾问题日益严重，对生物多样性、水质以及航行和娱乐等活动产生了负面影响。本研究提出了一种新的方法论框架，利用固定在现场的摄像头来监测这种废物。该方法利用深度学习进行连续的量化和监测，并在复杂环境条件下测试了多种深度学习模型的准确性和推断速度。", "innovation": "研究的主要贡献包括：（i）使用深度学习连续量化和监测漂浮垃圾，以及（ii）识别在复杂环境条件下最适合的深度学习模型。研究还采用几何模型从二维图像估计检测对象的实际大小。此外，研究测试了不同环境条件和学习配置下的模型，并探讨了数据泄漏偏差。研究还强调了数据集构成协议的重要性，特别是与负图像的整合和时间泄漏的考虑。", "conclusion": "这项研究表明，使用射影几何与回归校正结合进行度量物体估计是可行的。此方法为城市水体中开发坚固且成本较低的自动监测系统铺平了道路。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23866", "html_url": "https://arxiv.org/abs/2510.23866", "title": "一种用于2米温度下标化的PDE启发式潜扩散模型", "title_en": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling", "authors": "Paul Rosu,Muchang Bahng,Erick Jiang,Rico Zhu,Vahid Tarokh", "background": "本文提出了一种针对大气数据动态下标化的物理条件下的潜扩散模型，重点在于重建高分辨率2米温度场。该模型基于现有的扩散架构，采用残差形式与参考UNet相结合，并将偏微分方程（PDE）损失项融入模型训练目标中。", "innovation": "该模型通过在全分辨率（像素）空间中解码潜表示来计算PDE损失，并采用有限差分近似实现有效的对流-扩散平衡，从而确保物理一致性。此外，通过将这种额外损失进行微调，进一步正则化模型，提高生成字段的物理可行性。", "conclusion": "实验结果表明，传统的扩散训练已经产生了较低的PDE残差，进一步通过微调来进一步正则化模型，从而进一步提高了生成场的物理合理性。整个代码库已发布在GitHub上，以供未来参考和开发。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23849", "html_url": "https://arxiv.org/abs/2510.23849", "title": "一种用于上下文偏差评分学习和过滤的神经网络模型", "title_en": "A Neural Model for Contextual Biasing Score Learning and Filtering", "authors": "Wanting Huang,Weiran Wang", "background": "上下文偏差在自动语音识别（ASR）中通过在解码过程中整合外部知识，如用户特定的短语或实体，来提升识别的准确性。以往的方法在识别过程中使用注意力机制的偏差解码器根据声学信息为候选短语评分，以此来过滤掉不符合的情况并帮助浅融合偏差计算。在Librispeech偏差基准测试中，这些方法的有效性得到了证实，但尚未有模型能够系统地进行偏差评分的学习和过滤", "innovation": "引入了一个基于每个词的判别性目标，它鼓励为真实短语分配更高的分数并抑制干扰项，从而改善识别准确率。该方法具有模块化特性，可以与任何ASR系统兼容，过滤机制也有潜力提升其他偏差方法的效果", "conclusion": "实验结果表明，该方法能够有效过滤大部分候选短语，且在浅融合偏差方法中使用评分时，在不同偏差条件下显著提高了识别准确性"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23845", "html_url": "https://arxiv.org/abs/2510.23845", "title": "CRADLE Bench：基于临床标注的多维度心理健康危机和安全风险检测基准", "title_en": "CRADLE Bench: A Clinician-Annotated Benchmark for Multi-Faceted Mental Health Crisis and Safety Risk Detection", "authors": "Grace Byun,Rebecca Lipschutz,Sean T. Minton,Abigail Lott,Jinho D. Choi", "background": "检测自杀念头、性侵犯、家庭暴力、儿童虐待和性骚扰等心理健康危机情况是语言模型面临的重要但尚未充分探索的挑战。当这些情况在用户与模型的互动中出现时，模型必须可靠地检测并标记它们，否则可能导致严重后果。因此，需要一个全面的基准测试集来评估模型在这些情境下的性能。现有的基准多关注单一类型的危机，而未能涵盖所有关键因素和时间标签。", "innovation": "本研究引入了CRADLE BENCH，为多维度危机检测提供了一个基准测试集。该基准包括七种与临床标准相符的危机类型，是首个包含时间标签的基准测试集。此外，基准集包含了600个由临床医生注释的评估示例和420个开发示例，以及约4000个自动标注的训练集，这些训练集使用多个语言模型的多数投票聚集。这显著优于单一模型标注。另外，针对六种危机检测模型进行了进一步的微调，这些模型根据共识和一致的集合共识定义了子集，从而提供了在不同一致标准下训练的不同互补模型。", "conclusion": "CRADLE BENCH为多维度心理健康危机和安全风险检测提供了全面的基准测试集，其中包括广泛的危机类型、时间标签和经过临床医生注释的数据。通过引入多角度的多样标签和高度自动化的标注方式，CRADLE BENCH能够有效评估和改进语言模型在检测心理健康危机方面的性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23854", "html_url": "https://arxiv.org/abs/2510.23854", "title": "LLMs能否叙述表格数据？一种针对Text-to-SQL系统输出自然语言表示的评估框架", "title_en": "Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural Language Representations of Text-to-SQL System Outputs", "authors": "Jyotika Singh,Weiyi Sun,Amit Agarwal,Viji Krishnamurthy,Yassine Benajiba,Sujith Ravi,Dan Roth", "background": "在现代工业系统中，如多轮对话代理，Text-to-SQL技术将自然语言(NL)问题与数据库(DB)查询联系起来。将表格DB结果转化为NL表示(NLRs)，使基于对话的交互成为可能。目前，NLR生成通常由大型语言模型（LLMs）处理，但将表格结果转化为NL时的信息损失或错误尚未得到充分探索。", "innovation": "本论文提出了一种新型评估方法——Combo-Eval，该方法结合了多种现有方法的优点，优化了评估真实度并减少了25-61%的LLM调用。同时，配套推出了首个专门针对NLR基准测试的数据集NLR-BIRD，并通过人工评估展示了Combo-Eval与人类判断的高度一致性，适用于各种有无真实参考数据的场景。", "conclusion": "本研究通过提出Combo-Eval评估方法和NLR-BIRD数据集，解决了LLMs生成NLR时存在的问题，显著提高了评估的真实性和效率，同时实现了与人类判断的高度一致。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23870", "html_url": "https://arxiv.org/abs/2510.23870", "title": "OraPlan-SQL：一种以计划为中心的框架，用于复杂双语NL2SQL推理", "title_en": "OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL Reasoning", "authors": "Marianne Menglin Liu,Sai Ashish Somayajula,Syed Fahad Allam Shah,Sujith Ravi,Dan Roth", "background": "本论文介绍了OraPlan-SQL系统，这是为2025年的Archer NL2SQL评估挑战开发的系统。该挑战要求系统进行复杂的推理，包括算术、常识和假设推理。与之前的参加者相比，OraPlan-SQL在执行准确性（EX）上超过了第二名超过6%，分别在英语和汉语上达到了55.0%和56.7%的准确率，同时保持了超过99%的SQL语句有效性（VA）。这项系统的架构基于一个代理框架，包括生成自然语言步骤计划的计划代理，以及将这些计划转换成可执行SQL代码的SQL代理。", "innovation": "OraPlan-SQL系统创新之处在于采用了以计划为中心的代理框架，并通过单个计划生成器配合反馈指导的元提示策略来优化系统性能。不同于其他方法依赖多个子代理进行规划，容易产生协调问题，OraPlan-SQL引入了一种更强健的方法来改善计划生成器的表现。同时，针对多语言场景中的同音异形和实体匹配问题，OraPlan-SQL整合了实体链接指导策略，生成实体的替代表象，并明确包含在计划中。最后，通过生成多个候选计划，提高系统输出可靠性，最终输出通过大多数执行结果进行选择。", "conclusion": "基于OraPlan-SQL系统在多语言环境下的表现，作者认为该系统在进行复杂多语种的自然语言到SQL转换时虽然遇到了一些挑战，但却提供了一种新颖且有效的解决方法。该方法不仅能够提升系统的准确性，还增强了系统的适应性和可靠性。未来的工作可以进一步探索其他优化策略和新的人工智能技术，以使系统更加完善和高效。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23891", "html_url": "https://arxiv.org/abs/2510.23891", "title": "PRO: 使开源大语言模型具备精确且健壮的文本水印能力", "title_en": "PRO: Enabling Precise and Robust Text Watermark for Open-Source LLMs", "authors": "Jiaqi Xue,Yifei Zhao,Mansour Al Ghanim,Shangqian Gao,Ruimin Sun,Qian Lou,Mengxin Zheng", "background": "文本水印技术对于大语言模型（LLMs）的所有者来说，能够验证文本的来源并保护知识产权十分重要。虽然对于封闭源代码的LLMs，已有相对成熟的方法来嵌入文本水印，但将这些方法扩展到开源模型仍然具有挑战性。因为编译商无法控制解码过程。开源LLMs的所有者缺乏有效的手段来验证文本是否由其模型生成。主要难题在于直接将水印嵌入模型权重而不破坏其检测性。先前一种可能的想法是，从封闭源代码模型中提取水印并应用到开源模型上，但这攻击到了两个问题：（i）识别性差，因为学到的模式与预定义的模式不匹配；（ii）对下游修改（如微调或模型合并）的脆弱性。", "innovation": "文章提出了一种新的方法——PRO（Precise and Robust），这是一种为了开源大语言模型设计的精确且健壮的文本水印方法。PRO通过联合训练水印政策模型和LLM，生成模型更容易学习且更符合检测标准的水印模式。此外，通过正则化项模拟下游的扰动并惩罚水印检测性下降，从而能够在模型优化后确保水印的鲁棒性。通过在开源大语言模型（如LLaMA-3.2、LLaMA-3、Phi-2）上的实验表明，PRO显著提高了水印的识别性和抵御模型修改的能力。", "conclusion": "本文提出的PRO方法克服了现有方法中的不足之处，通过同时训练LLM和水印策略模型，生成了更加稳定和易于学习的水印模式，并通过正则化项确保水印在模型修改下的鲁棒性。实验表明，PRO能显著提高水印的识别性和对模型修改的抵抗力，为开源大语言模型的所有者提供了有效验证文本来源的手段。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23893", "html_url": "https://arxiv.org/abs/2510.23893", "title": "基于大语言模型的互操作性效果评估", "title_en": "Evaluating the effectiveness of LLM-based interoperability", "authors": "Rodrigo Falcão,Stefan Schweitzer,Julien Siebert,Emily Calvet,Frank Elberzhager", "background": "随着系统体系变得日益动态和异构，长期存在的互操作性挑战正受到更多压力。除了技术方面，互操作性还具有经济方面的影响，因为在开发阶段需要投入时间来构建互操作性构件。近年来，大语言模型（LLMs）取得了显著进展，本研究旨在探讨利用LLMs策略使系统在运行时自主互操作的有效性，而无需人工干预。", "innovation": "本研究选择了13个开放源代码的LLMs，并针对农业互操作性用例制作了四个数据集版本，进一步比较了使用两种不同策略的模型在多次运行中的效果和结果一致性。结果显示，在大部分数据集版本中，qwen2.5-coder:32b模型在两种策略下都表现出了较高的效果。此外，对于包含单位转换的数据集版本，使用DIRECT策略的所有模型都失败了，而使用CODEGEN的qwen2.5-coder:32b模型则成功地实现了自主互操作。", "conclusion": "有些大语言模型能够使系统在运行时自主互操作。建议在不同领域进行进一步评估，并进一步研究可靠性策略。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23907", "html_url": "https://arxiv.org/abs/2510.23907", "title": "DynaStride: 动态步长窗口结合MMCoT方法用于指令多场景字幕生成", "title_en": "DynaStride: Dynamic Stride Windowing with MMCoT for Instructional Multi-Scene Captioning", "authors": "Eddison Pham,Prisha Priyadarshini,Adrian Maliackel,Kanishk Bandi,Cristian Meo,Kevin Zhu", "background": "场景级别的字幕在教学视频中能够通过理解和配合视觉提示和时间结构来增强学习效果。通过将视觉提示与文本指导对齐，这种理解支持程序性学习和多模态推理，提供更丰富的技能获取背景。然而，如果字幕未能捕捉到这种结构，可能会缺乏连贯性和质量，导致学生混淆并削弱教学视频的教育意图。", "innovation": "提出了一种名为DynaStride的管道，可以生成连贯的场景级别字幕，而无需手动分割场景。DynaStride通过适应性帧采样和多模态窗口法来捕捉每个场景中的关键过渡，使用多模态链式思考过程生成多个动作-对象对，通过动态步长窗口选择算法进行校正和融合，以适当地平衡时间和冗余，并用一个综合了视觉语义和时间推理的单个指令字幕来实现最终的场景级别字幕。与VLLaMA3和GPT-4o等强基线相比，实证评估显示DynaStride在N-gram度量（BLEU，METEOR）和语义相似度度量（BERTScore，CLIPScore）上表现出持续的优势。定性分析进一步表明，DynaStride生成的字幕更具有时间连贯性和信息性。", "conclusion": "DynaStride为改进AI驱动的教学内容生成提供了一个有前景的方向。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23934", "html_url": "https://arxiv.org/abs/2510.23934", "title": "MFiSP: 多模态 wildfire 传播预测框架", "title_en": "MFiSP: A Multimodal Fire Spread Prediction Framework", "authors": "Alec Sathiyamoorthy,Wenhao Zhou,Xiangmin Zhou,Xiaodong Li,Iqbal Gondal", "background": "2019-2020年澳大利亚黑夏季山火造成1900万公顷土地破坏、3000栋房屋被毁并持续七个月，凸显了野火威胁的规模和紧迫性，需要更准确的预测以应对。传统的野火建模依赖于消防行为分析师（FBAns）的手动解释和静态环境数据，常常导致不准确和操作限制。新兴的数据源，如NASA的FIRMS卫星图像和志愿地理信息，通过提供动态火灾传播预测，可能改善这种情况。", "innovation": "本文提出了一种结合社交媒体数据和遥感观测，以提高火灾传播预测准确性的多模态火灾传播预测框架（MFiSP）。通过在同化周期中调整燃料图处理策略，框架能够动态适应火灾行为预测，使其与观测到的传播速率相匹配。研究通过使用合成生成的火灾事件多边形在多个场景下评估MFiSP的有效性，分析单独和联合使用多模态数据对预测边界的个体和综合影响。", "conclusion": "结果表明，集成多模态数据的MFiSP相较于依赖FBAn专业知识和静态输入的传统方法，能更有效地提高火灾传播预测的准确性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23924", "html_url": "https://arxiv.org/abs/2510.23924", "title": "基于指令遵循大语言模型的基于代理的自动索赔匹配", "title_en": "Agent-based Automated Claim Matching with Instruction-following LLMs", "authors": "Dina Pisarevskaya,Arkaitz Zubiaga", "background": "研究自动索赔匹配任务，主要依赖手动生成提示进行匹配，但这种方法费时且效率低。当前主要方法包括使用最先进的技术（SOTA）和人类生成的提示，但这一过程可能需要大量人工努力且效果有限。因此，探索自动提示生成的方法，特别是利用指令遵循的大型语言模型（LLMs），成为该领域的关键挑战之一。", "innovation": "提出了一种新颖的基于代理的方法，结合LLMs进行自动索赔匹配。方法包括两步：首先使用LLMs生成提示，然后使用LLMs将索赔匹配任务作为二元分类问题来解决。实验结果显示，LLMs自动生成的提示可以超越最先进的基于人类提示的方法，此外，较小的LLMs在生成过程中与较大的LLMs具有类似的性能，能够节省计算资源。同时，研究还表明可以在管道的不同步骤使用不同的LLMs，例如，一个用于提示生成，另一个用于索赔匹配，以提高整体效果。", "conclusion": "研究揭示了LLMs对索赔匹配的理解，并展示了使用指令遵循的大语言模型自动生成提示并执行匹配任务的有效性。此外，通过使用不同LLMs，该方法节省了计算资源，具有广泛应用的潜力，尤其在需要进行大量数据处理和匹配的任务中。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23906", "html_url": "https://arxiv.org/abs/2510.23906", "title": "在子系统中使用深网络进行干预以发现因果关系", "title_en": "Group Interventions on Deep Networks for Causal Discovery in Subsystems", "authors": "Wasim Ahmad,Maha Shadaydeh,Joachim Denzler", "background": "因果发现能够揭示变量之间的复杂关系，增强预测、决策和对现实世界系统的洞察力，特别是在非线性多变量时间序列中。然而，目前大多数方法主要关注成对的因果关系，而忽略了变量组（即子系统以及它们的集体因果影响）之间的相互作用。本研究旨在填补这一空白，提出了一种新颖的多组因果发现方法gCDMI，该方法利用训练深度神经网络中的组水平干预，结合模型不变性检验来推断因果关系。通过三个关键步骤，本研究首先利用深度学习同时建模所有时序中的组间结构关系，然后在训练模型上应用组间干预，最后通过模型不变性测试确定变量组之间的因果链接。", "innovation": "本研究提出了gCDMI，一种利用组水平干预的深学习模型进行因果关系推理的新方法。gCDMI包括三个步骤，分别是：1. 利用深度学习同时建模所有时序中的组间结构关系；2. 在训练后的模型上应用组间干预；3. 通过模型不变性测试确定变量组之间的因果链接。该方法在模拟数据集中展示了其在识别组水平因果关系方面的优越性能，在实际数据集（如脑网络和气候生态系统）中的验证也证实了这一方法的有效性，揭示了组水平干预结合不变性测试可以有效揭示复杂的因果结构，尤其对神经科学和气候科学等领域提供了有价值的见解。", "conclusion": "本研果表明，通过对深度学习模型进行组水平干预并结合不变性测试，能够有效地揭示复杂的因果结构，这些发现为神经科学和气候科学等领域的研究提供了有价值的信息。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23940", "html_url": "https://arxiv.org/abs/2510.23940", "title": "使用回声状态网络建模生物多功能性", "title_en": "Modeling Biological Multifunctionality with Echo State Networks", "authors": "Anastasia-Maria Leventi-Peetz,Jörg-Volker Peetz,Kai Weber,Nikolaos Zacharis", "background": "本文工作开发了一个三维多组分反应-扩散模型，结合了激活性系统的动力学与扩散过程，并与FitzHugh-Nagumo模型共享概念特征。该模型用于捕获生物系统的时空行为，特别是电生理过程。通过数值求解生成时间序列数据，为训练和评估回声状态网络（ESN）的数据驱动模型提供了基础。", "innovation": "创新之处在于利用数据驱动的多功能回声状态网络模型来模拟生物动力学。该回声状态网络成功地再现了系统的动态行为，证明了使用数据分析方法来模拟复杂生物系统的可行性及其有效性。", "conclusion": "研究结果表明，使用数据驱动、多功能的回声状态网络模型模拟生物动力学既可行又有效。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23912", "html_url": "https://arxiv.org/abs/2510.23912", "title": "仅需键和值权重：关于解码器唯一直接变换器中Query, Key, Value权重三元组的必要性", "title_en": "Key and Value Weights Are Probably All You Need: On the Necessity of the Query, Key, Value weight Triplet in Decoder-Only Transformers", "authors": "Marko Karbevski,Antonij Mijoski", "background": "当前最先进的大规模语言模型（LLMs）中的注意机制的基本构建块是Query, Key, Value权重三元组。已有研究主要集中在如何优化和减少模型参数数量，包括查询权重（Query）的冗余性。这项研究在理论上分析了查询权重的冗余性，并通过实验验证了简化假设下的理论结果，证明了解除简化假设后的模型参数可以减少超过8%，同时验证了在复杂度较高的GPT-3小型架构中的有效性并保持了与标准基线相当的验证损失。研究表明，键和值权重可能是解码器唯一直接变换器中必要的权重，进一步探索了大规模模型中查询权重的冗余性问题。", "innovation": "创新点在于理论分析并证明了在简化假设下，Query权重是多余的，从而减少了模型的参数数量。进一步通过实验验证了该理论在实际复杂模型架构中的有效性，并展示了减少Query权重后模型性能仍然与标准基线相当的结果。", "conclusion": "研究表明键和值权重在解码器唯一直接变换器中可能足够，无需查询权重，模型参数可以减少8%以上。进一步探索大规模变换器模型的查询权重冗余性问题，对未来优化和简化大模型参数架构具有重要意义。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23938", "html_url": "https://arxiv.org/abs/2510.23938", "title": "基于GPU的大型机器学习模型可扩展性完整性验证", "title_en": "Scalable GPU-Based Integrity Verification for Large Machine Learning Models", "authors": "Marcin Spoczynski,Marcela S. Melara", "background": "目前，分布式机器学习的安全性主要依赖于CPU平台上的验证机制，这导致了性能和验证开销的问题。传统的验证方法通常是独立于大型模型执行的GPU任务，这导致了根本性的不匹配，降低了效率。因此，需要一种新的框架来标准化跨CPU和GPU的完整性保护，并显著减少验证开销，以解决这一问题。", "innovation": "本文提出了一种安全框架，该框架将完整性验证与大型ML模型的执行直接放在GPU加速器上进行，同时利用GPU的高带宽内存和并行处理能力，实现了加密操作的本地化处理。这种方法解决了传统CPU验证系统的潜在架构瓶颈，并确保了即使对于超过100GB的巨大模型，完整性检查也能跟上模型的执行速度。此外，该框架还提供了一个互操作性机制，支持不同GPU供应商和硬件配置的设备，同时为未来创建安全通道的能力提供了基础支持。", "conclusion": "通过将验证直接与大型ML模型的执行绑定到GPU上，本文提出的方法实现了更好的性能和长期的一致性架构。这种设计减少了CPU验证开销，使得大型模型的验证更高效。此外，这种方案还为依赖不同CPU和GPU基础设施的企业团队提供了一种硬件无关的安全基础。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23901", "html_url": "https://arxiv.org/abs/2510.23901", "title": "RS-ORT: 减少空间的分支定界算法用于最优回归树", "title_en": "RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees", "authors": "Cristobal Heredia,Pedro Chumpitaz-Flores,Kaixun Hua", "background": "混合整数规划（MIP）已成为学习最优决策树的强大框架。然而，现有的MIP方法在回归任务上要么仅限于纯二元特征，要么在处理连续、大规模数据时变得计算上不可行。简单地将连续特征二值化会牺牲全局最优性，并通常会导致不必要的深层树结构。", "innovation": "我们重新将最优回归树训练问题表示为两阶段优化问题，并提出了一种专门的分支定界（BB）算法——RS-ORT，该算法仅对树结构变量进行分支。这确保了算法的收敛性和与训练样本数量无关。基于模型结构，我们引入了多种边界紧缩技术——闭合形式的叶预测、经验阈值离散化和确切深度1子树解析——这些技术与可分解的上界和下界策略相结合，加速了训练。BB节点分解允许简单的并行执行，即使对于数百万级别的数据集也能进一步缓解计算不可行性。关于包含二元和连续特征的多个回归基准的数据实验表明，RS-ORT在训练和测试性能上都优于最先进的方法。特别是在包含多达200万样本的连续特征数据集上，RS-ORT能够在四小时内获得保证的性能，使用更简单的树结构和更好的泛化能力。", "conclusion": "基于对几个回归基准的实验，在二元和连续特征数据集上，RS-ORT在训练和测试性能方面都优于最先进的方法。重要的是，在包含最多200万个样本和连续特征的数据显示集上，RS-ORT可以在四小时内获得保证的训练性能，具有更简单的树结构和更好的泛化能力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23972", "html_url": "https://arxiv.org/abs/2510.23972", "title": "一种用于类似扩散模型的高效概率硬件架构", "title_en": "An efficient probabilistic hardware architecture for diffusion-like models", "authors": "Andraž Jelinčič,Owen Lockwood,Akhil Garlapati,Guillaume Verdon,Trevor McCourt", "background": "概率AI的广泛应用促使了专门的随机计算机方案的提出。尽管这些方案有潜在的效率提升，但由于依赖于根本有限的建模技术和难以扩展的硬件，这些方案并未得到广泛应用。", "innovation": "本文提出了一种全晶体管概率计算机，通过硬件层面实现强大的去噪模型。系统级分析表明，基于本文架构的设备在简单图像基准测试中可以实现与GPU相当的性能，同时能源消耗仅为GPU的约1/10000。", "conclusion": "本文方法能够显著提高概率模型处理的效率和能效比。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23941", "html_url": "https://arxiv.org/abs/2510.23941", "title": "无需训练标签的自动提示：一种用于电子商务目录产品质量评估的LLM级联", "title_en": "Auto prompting without training labels: An LLM cascade for product quality assessment in e-commerce catalogs", "authors": "Soham Satyadharma,Fatemeh Sheikholeslami,Swati Kaul,Aziz Umit Batur,Suleiman A. Khan", "background": "在电子商务中，需要一种无需训练标签或模型微调的方法，用于自动提示大型语言模型（LLMs）以评估产品质量。现有的方法通常依赖于人工标注或模型微调，这在数据密集型和复杂目录环境中非常耗时和难以实现。", "innovation": "提出了一种无需训练的级联系统，用于自动提示大型语言模型评估电子商务目录中的产品质量。该系统从一个种子提示集开始，逐步优化指令以满足特定目录的要求。该系统能够将通用的语言理解与大规模的专业领域知识相结合。实验结果显示，与传统的思维链提示方法相比，该级联系统在精度和召回率方面分别提高了8-10%，同时将每个属性的专业领域专家工作时间从5.1小时减少到3分钟，减少了99%的工作量。此外，该系统在五种语言和多个质量评估任务中表现出良好的泛化能力，保持了性能收益。", "conclusion": "该研究提出了一种创新的方法，通过一个无需训练的级联系统，自动提示大型语言模型评估电子商务目录中的产品质量，显著提高了效率和性能，具有广泛应用前景。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23956", "html_url": "https://arxiv.org/abs/2510.23956", "title": "神经USD：一种面向对象的迭代编辑与控制框架", "title_en": "Neural USD: An object-centric framework for iterative editing and control", "authors": "Alejandro Escontrela,Shrinu Kushagra,Sjoerd van Steenkiste,Yulia Rubanova,Aleksander Holynski,Kelsey Allen,Kevin Murphy,Thomas Kipf", "background": "可控生成模型在近年来取得了显著进步，但仍存在一些挑战，如精确的迭代对象编辑。当前的方法在通过调整条件信号尝试编辑生成的图像（例如，改变场景中特定对象的颜色或更改背景同时保持其他元素不变）时，常常会导致场景中的意外全局变化。", "innovation": "借鉴计算机图形学社区开发的通用场景描述符(USD)标准，提出了“神经通用场景描述符”(Neural USD)。Neural USD采用结构化、分层的方式表示场景和对象，以适应多样化信号，最小化模型特定约束，并允许针对每个对象控制外观、几何形状以及姿态。通过细调方法确保了上述控制信号的分离。", "conclusion": "Neural USD框架支持迭代和增量的工作流程，证明了其在对象中心的编辑与控制中的应用潜力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23974", "html_url": "https://arxiv.org/abs/2510.23974", "title": "文本到图像扩散模型中的扩散自适应文本嵌入", "title_en": "Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models", "authors": "Byeonghu Na,Minsang Park,Gyuwon Sim,Donghyeok Shin,HeeSun Bae,Mina Kang,Se Jung Kwon,Wanmo Kang,Il-Chul Moon", "background": "文本到图像扩散模型依赖预训练的文本编码器生成图像，但由于这些嵌入在整个扩散时间步骤中保持固定，因此限制了其在生成过程中的适应性。", "innovation": "作者提出了扩散自适应文本嵌入(DATE)，该方法能够在每个扩散时间步骤中基于中间的扰动数据动态更新文本嵌入。通过优化问题的建模和推导出更新规则，DATE在每个采样步骤中不断调整文本嵌入，以改进预测图像与文本之间的对齐和偏好。这种方法使得DATE在扩散采样过程中可以动态适配文本条件到反向扩散的图像，而无需额外的模型训练。", "conclusion": "通过理论分析和实验证据，作者表明DATE保留了模型的生成能力，同时在固定文本嵌入的各种任务中提供了更好的文本图像对齐。代码可在指定链接处获取。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23948", "html_url": "https://arxiv.org/abs/2510.23948", "title": "ChessQA：评估大型语言模型的国际象棋理解能力", "title_en": "ChessQA: Evaluating Large Language Models for Chess Understanding", "authors": "Qianfeng Wen,Zhenwei Tang,Ashton Anderson", "background": "国际象棋为评估大型语言模型（LLMs）的推理、建模和抽象能力提供了一个理想的试验场，因为它结构清晰、有客观的正确答案且技能水平广泛。然而，现有的LLMs在国际象棋方面的评估往往是临时性的且范围狭窄，这使得准确衡量LLMs的国际象棋理解以及这些理解如何随规模、后训练方法或架构选择变化变得困难。因此，本研究提出了ChessQA，一个全面的基准测试，它评估LLMs在五个任务类别（结构、模式、短战术、位置判断、语义）下的国际象棋理解能力，这些类别大致对应玩家在积累国际象棋知识过程中从理解基本规则、学习战术模式到正确计算战术、评估棋局和语义化描述高级概念的梯度抽象层次。ChessQA因此能够捕捉到更全面的国际象棋能力和理解图景，远远超越了之前简单的走子质量评估，提供了一个受控且一致的环境用于诊断和比较。此外，ChessQA具有动态性，其提示、答案密钥和构建脚本会随着模型的提升而演变。通过评估一系列当代LLMs，研究发现所有五个类别中都存在持续的弱点，并提供了按类别分类的结果和错误分析。研究团队还将发布代码、定期刷新的数据集和公共排行榜，以支持进一步的研究。", "innovation": "该研究提出了ChessQA，这是一个全面的基准测试，用于评估LLMs在五个特定任务类别下的国际象棋理解能力，涵盖从基础规则到高级概念的整个梯度抽象层次；ChessQA具有动态特性，其提示、答案密钥和构建脚本会随着模型的进步而更新；研究团队提供了详细的结果和错误分析，并承诺发布代码、刷新数据集和公开排行榜，以支持进一步研究。", "conclusion": "通过ChessQA，研究团队能够全面评估LLMs在不同复杂度水平的国际象棋理解情况，发现五个类别中的普遍弱点，并为未来的改进提供详细的方向。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23986", "html_url": "https://arxiv.org/abs/2510.23986", "title": "STNet：求解算子特征值问题的谱变换网络", "title_en": "STNet: Spectral Transformation Network for Solving Operator Eigenvalue Problem", "authors": "Hong Wang,Jiang Yixuan,Jie Wang,Xinyi Li,Jian Luo,Huanshuo Dong", "background": "算子特征值问题在多个科学领域和工程应用中具有重要作用，但数值方法受维度诅咒限制。最近的深度学习方法通过迭代更新神经网络来应对这一挑战，但这些方法的性能高度依赖于给定算子的谱分布：算子特征值之间的较大差距可以提高精度，因此可以利用谱分布的定制化谱变换来增强其性能。基于此观察，我们提出了谱变换网络（STNet）。", "innovation": "STNet 在每次迭代中利用近似的特征值和特征函数对原始算子进行谱变换，将其转化为一个等效但更简单的问题。具体来说，使用消液投影来排除已解决特征函数对应的子空间，从而减少搜索空间并避免收敛到现有特征函数。此外，我们的滤波变换放大了目标区域内的特征值并抑制了外部的特征值，进一步提高性能。广泛的实验表明，STNet 在准确性和性能方面优于现有的基于学习的方法，达到了最新水平。", "conclusion": "STNet 通过利用预校的谱分布进行谱变换，在解决算子特征值问题中表现出色，性能优于现有的基于学习的方法。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23980", "html_url": "https://arxiv.org/abs/2510.23980", "title": "HyperGraphX：使用超维计算和消息传递的图归纳学习", "title_en": "HyperGraphX: Graph Transductive Learning with Hyperdimensional Computing and Message Passing", "authors": "Guojing Cong,Tom Potok,Hamed Poursiami,Maryam Parsa", "background": "本文介绍了一种名为\\hdgc的新颖算法，该算法利用超维计算（Hyperdimensional Computing）中的图卷积与绑定和捆绑操作相结合，用于图归纳学习。该研究旨在通过实证方法验证\\hdgc在预测准确性方面是否优于现有图神经网络（Graph Neural Networks，GNNs）和超维计算的实现。", "innovation": "提出了一种结合图卷积和绑定/捆绑操作的新型算法\\hdgc，应用于超维计算环境下的图归纳学习。与最先进的图神经网络和超维计算实现相比，在相同的预测准确度下，\\hdgc在特定GPU平台上比GNN实现（如\\gcnii）和超维计算实现（HDGL）分别快9561.0和144.5倍。", "conclusion": "由于大部分操作集中在二进制向量上，\\hdgc在神经形态和新兴的存储计算设备上预期具有出色的能耗性能。该算法通过提高计算效率和预测精度，为图学习领域带来了新方法和新思路。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24010", "html_url": "https://arxiv.org/abs/2510.24010", "title": "Mars-Bench：火星科学任务中评估基础模型的标准平台", "title_en": "Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks", "authors": "Mirali Purohit,Bimal Gajera,Vatsal Malaviya,Irish Mehta,Kunal Kasodekar,Jacob Adler,Steven Lu,Umaa Rebbapragada,Hannah Kerner", "background": "基础模型通过在大量未标注数据上进行大规模预训练，已在许多专业领域实现了快速进展，展现了对多种下游任务的强大泛化能力。尽管这些模型在地球观测等领域的应用中引起了广泛关注，但它们在火星科学中的应用仍相对有限。其他领域的进步得益于标准化基准的支持，而火星科学缺乏这样的基准和标准化评估框架，限制了其向火星任务中开发基础模型的进展。", "innovation": "本文引入了Mars-Bench，这是首个用于系统评估火星相关任务模型的数据集基准，包括轨道和表面图像。Mars-Bench 包含20个涵盖分类、分割和对象检测的任务数据集，关注关键地质特征如陨石坑、火山锥、巨石和霜。该基准提供了标准化且可直接使用的数据集和使用自然图像、地球卫星数据及最新视觉语言模型预训练模型的基准评估结果。", "conclusion": "所有分析的结果表明，针对火星任务的基础模型可能比通用领域模型更具有优势，这激励进一步探索领域适应性预训练。Mars-Bench旨在为火星科学中的机器学习模型开发和比较提供标准化基础，其数据、模型和代码已公开。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23949", "html_url": "https://arxiv.org/abs/2510.23949", "title": "揭示多语言LLM卸载中潜在风险：仅英语卸载的危险", "title_en": "Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs", "authors": "Kyomin Hwang,Hyeonjin Kim,Seungyeon Kim,Sunghyun Wee,Nojun Kwak", "background": "一些研究显示，只使用英语数据试图清除多语言知识对于多语言大语言模型（LLM）是不够的。然而，这些研究仍主要从性能角度进行分析。本文改变研究视角，关注评估，并探讨了在完全用平行多语言数据集微调多语言LLM后再进行卸载时存在的盲点。当模型在受到卸载处理后出现语言混淆现象时（即模型以与输入提示不同的语言响应），标准参考基线评估指标失效。语言混淆现象是卸载过程中一个严重的问题，对该现象，本文从三个方面进行了研究：一方面量化地说明多语言LLM普遍且一致地出现语言混淆现象；另一方面证明当N-混合分数较高时，参考基线评估可能导致假阴性；此外还建议需要一种新的评估指标来直接审查生成句子的内容。", "innovation": "本文从评估角度出发，引入一种新的方法N-词组基线的混合（N-Mix）评分，量化地展现了多语言LLM普遍且一致地出现语言混淆现象；进一步揭示了当N-Mix分数较高时，参考基线评估可能导致假阴性；并指出需要新的基于语义的评估指标来直接评估生成句子的内容。", "conclusion": "本文提出了一种新的基于语义的评估指标，这种指标能够直接评估生成句子的内容，以应对多语言LLM卸载过程中出现的语言混淆现象。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24020", "html_url": "https://arxiv.org/abs/2510.24020", "title": "通过细粒度语义置信度奖励指导大语言模型进行回避", "title_en": "Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward", "authors": "Hao An,Yang Xu", "background": "在大语言模型（LLMs）的可靠部署中，减轻幻觉现象至关重要。现有方法通常通过细调LLMs来避免回答超出其知识范围的问题，但这些方法往往依赖于粗粒度的信号来指导模型回避，这可能导致模型对自己知识边界认识的不精确。", "innovation": "提出了一个新的基于‘细粒度语义置信度奖励（作者名称）’的强化学习框架，该框架通过特定样本的置信度信号来指导LLMs进行回避。此外，还提出了一种新的评估回避微调任务可靠性的指标。", "conclusion": "所提出的方法在领域内和领域外基准测试中都显著提升了可靠性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23960", "html_url": "https://arxiv.org/abs/2510.23960", "title": "SafeVision: 高效具备强大政策遵守能力和可解释性的图像护栏", "title_en": "SafeVision: Efficient Image Guardrail with Robust Policy Adherence and Explainability", "authors": "Peiyang Xu,Minzhou Pan,Zhaorun Chen,Shuang Yang,Chaowei Xiao,Bo Li", "background": "随着数字媒体的迅速普及，有效地防止有害内容变得越来越重要。传统图像护栏模型受限于预定义的类别，由于纯粹基于特征的学习而缺乏语义推理，经常误分类内容。这些模型还很难应对新的威胁，需要昂贵的重新训练。因此，通过引入SafeVision，我们提供了具备人类推理能力的新颖图像护栏，提高适应性和透明度。该方法包括有效的数据收集和生成框架、遵循策略的训练管道和自定义损失函数。我们也提出了多样化的问答生成和训练策略以增强学习效果。SafeVision能够在推断时动态地与不断演变的安全政策对齐，无需重新训练，确保了精确的风险评估和解释。由于现有不安全图像基准的不足，我们还引入了一个高质量的数据集VisionHarm，该数据集包含两个子集：第三方VisionHarm (VisionHarm-T) 和综合型VisionHarm (VisionHarm-C)，涵盖了多种有害类别。SafeVision在VisionHarm-T和VisionHarm-C上的表现分别优于GPT-4o 8.6%和15.5%，同时计算速度提高超过16倍。该工作提出了一种综合、遵循策略并具有可解释性的图像护栏，具备对新兴威胁的动态适应能力。", "innovation": "引入SafeVision，一种新型图像护栏，整合了类似人类的推理能力来增强适应性和透明度。该方法包括有效的数据收集和生成框架、遵循策略的训练管道和自定义损失函数。此外，提出了多样化的问答生成和训练策略以增强学习效果。SafeVision具备在推断时动态适应不断变化的安全政策的功能，而无需重新训练，同时提供精确的风险评估和解释。我们还引入了高质量的数据集VisionHarm，涵盖了多种有害类别，为图像护栏评估提供更全面的参考。", "conclusion": "通过广泛的实验，SafeVision在不同基准上的表现达到了最先进的水平。SafeVision在VisionHarm-T和VisionHarm-C上的性能分别优于GPT-4o 8.6%和15.5%，同时计算速度提高了16倍。SafeVision提供了一种全面、遵循策略并可解释的图像护栏，具备对新兴威胁的动态适应能力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24021", "html_url": "https://arxiv.org/abs/2510.24021", "title": "SpecKD: 推测性解码在大规模语言模型知识蒸馏中的高效应用", "title_en": "SpecKD: Speculative Decoding for Effective Knowledge Distillation of LLMs", "authors": "Haiduo Huang,Jiangcheng Song,Yadong Zhang,Pengju Ren", "background": "知识蒸馏（KD）已成为压缩大型语言模型（LLMs）为更小、更高效的“学生”模型的关键技术。然而，传统的KD方法通常对所有令牌应用统一的蒸馏损失，而不考虑教师的信心水平。这种无差别的模仿可能会引入噪声，因为学生被迫从教师的不确定或高熵预测中学习，这最终可能损害学生的表现，尤其是在教师比学生大得多、更有能力时。", "innovation": "本文提出了一种名为Speculative Knowledge Distillation（SpecKD）的新颖、即插即用框架，该框架引入了一种动态的、基于令牌的门控机制，该机制借鉴了推测性解码的“提出和验证”范式。在每一步，学生的令牌提案都与教师的分布进行验证；仅对“接受”的令牌应用选择性的蒸馏损失，而对“拒绝”的令牌进行遮挡。", "conclusion": "在各种文本生成任务上的广泛实验表明，SpecKD在稳态训练和能力更强的学生模型方面显著优于强大的KD基线，达到最先进的性能结果。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24029", "html_url": "https://arxiv.org/abs/2510.24029", "title": "基于3D LiDAR的hippocampus启发模型中改进的机器人定位精度", "title_en": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model", "authors": "Andrew Gerstenslager,Bekarys Dukenbaev,Ali A. Minai", "background": "边界向量细胞（BVCs）在脊椎动物的大脑中负责编码特定距离和定向的环境边界，对于形成海马区的场所领域至关重要。大多数计算BVC模型限制在二维环境中，这在面对环境中的水平对称性时会导致空间模糊。研究旨在克服这一限制，通过在BVC框架中引入垂直角度敏感性，从而能够在三维环境中实现稳健的边界检测，并显著提高生物启发的机器人模型的空间定位准确性。", "innovation": "提出了一种基于BVC和LiDAR数据的三维模型，该模型能够捕捉垂直轮廓，并在存在水平对称性的环境中提供更准确的位置信息。该模型在环境垂直变化较小时能与二维基线模型性能相当，而随着3D复杂性的增加，它能生成更加独特且空间分辨率更高的场领域，显著减少空间模糊。", "conclusion": "研究结果表明，通过增加垂直维度来增强基于BVC的空间定位，在真实世界的3D环境中能够显著提高导航和制图性能，同时在简单的接近平面的情景中保持与2D模型的性能一致。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24019", "html_url": "https://arxiv.org/abs/2510.24019", "title": "生命周期感知的代码生成：利用软件工程阶段改进大型语言模型", "title_en": "Lifecycle-Aware code generation: Leveraging Software Engineering Phases in LLMs", "authors": "Xing Xing,Wei Wang,Lipeng Ma,Weidong Yang,Junjie Zheng", "background": "近年来，大语言模型（LLMs）在自动代码生成方面取得了显著进展，但大多数方法依赖于直接的、单一步骤的从问题描述到代码的翻译，忽略了结构化的软件工程实践。研究发现，大多数自动生成代码的方法缺乏系统地融入中间文件如需求分析、状态机建模和伪代码的能力，这限制了代码生成的质量。", "innovation": "本文提出了一种生命周期感知框架，该框架可以在训练和推理阶段系统地整合中间产物，如需求分析、状态机建模和伪代码，使其与标准的软件开发生命周期相吻合。该设计提高了代码生成的结构化推理能力。实验证明，生命周期级别的微调相较于未经微调的相同模型在代码正确性上提升了75%以上，且这种性能提升随着中间阶段的增加而累加。多步骤推理一致性地超过了单步骤生成，表明中间阶段支架的有效性。有研究表明，基于该框架微调的开源LLMs在性能上能够与使用代码进行预训练的模型相匹敌，甚至略有超越。当应用于DeepSeek-Coder-1.3B时，所提出的框架分别比ChatGPT-3.5、ChatGPT-4o-mini、DeepSeek-R1和LLaMA-8B代码BLEU提升了34.3%、20.0%、11.2%和22.3%。", "conclusion": "本框架提高了代码生成的结构化设计，并且相比未经定制的模型提升显著。通过消除中间产物的强化学习，使代码在实际中更加可靠。此外，通过删除的实验证实，每个中间产物对最终代码质量的提升贡献是独特的，状态机建模产生了最大的影响。源代码和详细的实验数据可在此链接访问：this https URL."}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24036", "html_url": "https://arxiv.org/abs/2510.24036", "title": "残差学习使深层卷积神经网络成为可能", "title_en": "ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning", "authors": "Xingyu Liu,Kun Ming Goh", "background": "卷积神经网络（CNNs）在计算机视觉中取得了革命性的进步，但训练非常深层的网络面临着梯度消失问题。ResNet通过使用跳过连接克服了这一限制，使得训练具有数百层的网络变得可能。", "innovation": "ResNet通过引入跳跃连接，使网络能够直接通过跳过中间层的快捷连接发送梯度，从而允许训练更深的网络。与传统的深层CNN相比，在CIFAR-10数据集上实现时，ResNet-18的准确率为89.9%，而传统的深层CNN的准确率为84.1%，同时收敛速度更快，训练更稳定。", "conclusion": "ResNet使得深层卷积神经网络的训练成为可能，通过使用跳过连接，它允许实现具有数百层的网络，并且在CIFAR-10数据集上的表现优于传统的深层CNN。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24039", "html_url": "https://arxiv.org/abs/2510.24039", "title": "几何算法在约束神经组合最优化中的应用", "title_en": "Geometric Algorithms for Neural Combinatorial Optimization with Constraints", "authors": "Nikolaos Karalias,Akbar Rafiey,Yifei Xu,Zhishang Luo,Behrooz Tahmasebi,Connie Jiang,Stefanie Jegelka", "background": "自监督学习（SSL）结合组合优化（CO），利用神经网络解决组合问题，是一个新兴的范式。然而，现有SSL方法大多难以处理具有离散限制的问题。本文针对此挑战，提出了一种端到端的可微框架，采用算法技术将神经网络输出分解为凸组合形式，确保了在自监督训练的同时能够高效地将神经网络输出转换为可行解。", "innovation": "设计了一种端到端的可微框架，利用凸几何算法和技术，特别是Carathéodory定理，将神经网络输出分解为可行集的凸组合。这种方法不仅支持自监督训练，还能高效、保质地区分神经网络输出，转化为可行解。", "conclusion": "在基数约束优化实验中，本文方法能够持续优于神经网络基线。进一步表明该方法不仅适用于基数约束问题，还可应用于各种组合优化问题，包括图中的独立集问题和基序列约束问题。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24012", "html_url": "https://arxiv.org/abs/2510.24012", "title": "训练免费的文本嵌入安全指导用于文本到图像扩散模型", "title_en": "Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion Models", "authors": "Byeonghu Na,Mina Kang,Jiseok Kwak,Minsang Park,Jiwoo Shin,SeJoon Jun,Gayoung Lee,Jin-Hwa Kim,Il-Chul Moon", "background": "文本到图像模型在生成逼真且语义连贯的图像方面取得了显著进展，这主要得益于先进的扩散模型和大规模的网络抓取数据集。然而，这些数据集中常常包含不适当或有偏的内容。这引发了关于在提供恶意文本提示时生成有害输出的担忧。现有的方法主要集中在训练数据上进行改进，但训练数据往往存在上述问题，因此需要提出新的方法来解决这些问题。", "innovation": "文章提出了一种无需训练的补救方案——Safe Text Embedding Guidance (STG)。STG 在采样过程中通过调整文本嵌入来指导扩散模型，并利用安全函数评估预期的最终去噪图像，以生成更加安全的内容，同时不影响生成质量。理论分析表明，STG 能够使模型的潜在分布与安全约束对齐，从而在最小程度上影响生成质量的同时确保输出的安全性。实验结果显示，在各种安全场景下，如裸露、暴力和艺术家风格去除，STG 在去除不安全内容的同时，能够更好地保留输入提示的核心语义意图，优于基于训练和其他无训练的方法。", "conclusion": "文章利用创新的STG方法显著提升了扩散模型生成内容的安全性，相比于现有方法和无训练的基础方法，STG在去除不安全内容方面表现更优，同时保持了生成的质量。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24046", "html_url": "https://arxiv.org/abs/2510.24046", "title": "具有强化学习的因果感知生成对抗网络", "title_en": "Causal-Aware Generative Adversarial Networks with Reinforcement Learning", "authors": "Tu Anh Hoang Nguyen,Dang Nguyen,Tri-Nhan Vo,Thuc Duy Le,Sunil Gupta", "background": "表格数据在模型训练和大规模数据分析中的应用常常受到隐私问题和监管障碍的限制。现有的生成数据的方法，尤其是基于生成对抗网络（GAN）的方法表现出一定的潜力，但它们在捕捉复杂的因果关系、保持数据质量和提供适用于企业部署的可证明隐私保障方面仍然存在挑战。", "innovation": "我们提出了CA-GAN，这是一种新型的生成框架，特别设计以解决真实世界表格数据集的这些挑战。该框架采用两步方法：因果图提取以在数据流形中学习稳健的全面因果关系，随后使用仅根据因果图中节点结构操作的自定义条件WGAN-GP（Wasserstein GAN with Gradient Penalty）。此外，生成器用一种基于强化学习的新目标进行训练，以确保从真实和虚假数据构建的因果图的一致性，从而确保在训练和采样阶段的因果意识。", "conclusion": "我们在14个表格数据集上对CA-GAN与六种当前最佳方法进行了对比实验，并关注核心数据工程指标：因果关系保持、数据质量和隐私保护。结果证明了CA-GAN的优越性。该方法为数据工程师提供了一种实际的、高性能的解决方案，以创建高质量且符合隐私要求的合成数据集，用于基准数据库系统、加速软件开发以及促进安全的数据驱动研究。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24052", "html_url": "https://arxiv.org/abs/2510.24052", "title": "SynAD：通过合成数据集成增强现实世界的端到端自动驾驶模型", "title_en": "SynAD: Enhancing Real-World End-to-End Autonomous Driving Models through Synthetic Data Integration", "authors": "Jongsuk Kim,Jaeyoung Lee,Gyojin Han,Dongjae Lee,Minki Jeong,Junmo Kim", "background": "近年来，深度学习的进步和高质量真实驾驶数据集的可用性推动了端到端自动驾驶的发展。但完全依赖真实世界数据的局限性在于，它无法提供多样化的驾驶场景进行训练。合成数据生成技术为此提供了一种解决方案，以丰富训练数据的多样性。然而，如何在端到端自动驾驶模型中应用这种技术仍是一个未解决问题。问题是缺乏真实的车辆（如自我车辆）及其相关的传感器输入（例如摄像机或LiDAR）。", "innovation": "SynAD框架是第一个利用合成数据增强真实世界端到端自动驾驶模型的框架。该框架将具有最全面驾驶信息的代理设定为多代理合成场景中的自我车辆。进一步将路径级场景投影到地图上，并使用新开发的Map-to-BEV网络从地图中提取鸟瞰图特征，不依赖于传感器输入。最后，提出了一种有效的训练策略，将基于地图的合成数据与真实驾驶数据有效结合。", "conclusion": "实验结果表明，SynAD能够将所有组件集成在一起，并显著提高安全性能。通过合成场景生成与端到端自动驾驶技术之间的联系，SynAD为更全面和稳健的自动驾驶模型铺平了道路。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24058", "html_url": "https://arxiv.org/abs/2510.24058", "title": "PULSE：从电导生物检测活动向低成本传感器转移特权知识以进行压力监测", "title_en": "PULSE: Privileged Knowledge Transfer from Electrodermal Activity to Low-Cost Sensors for Stress Monitoring", "authors": "Zihan Zhao,Masood Mortazavi,Ning Yan", "background": "电导生物检测活动（EDA）是检测应激反应的主要信号，但需要昂贵的硬件，常在实际可穿戴设备中不可用。因此，该论文探讨了一个利用EDA在自我监督预训练阶段进行模型训练的新框架PULSE，旨在利用EDA的优势，同时在推理阶段可以不依赖于EDA输入，借用更多易获取的模态特征如ECG、BVP、ACC、TEMP等，以期达到降低成本和提高准确性双重目标。", "innovation": "PULSE框架将模型输出分为共享嵌入和私有嵌入。共享嵌入在不同模态之间保持一致，并融合形成一个模态不变的表示形式，而私有嵌入则保留了模态特定的信息以支持重建目标。此外，通过一个冻结的EDA教师模型，在预训练后向学生编码器转移交感神经唤醒反应的表示，从而利用EDA的特权知识提升低成本传感器的压力检测性能。", "conclusion": "PULSE方法在WESAD数据集上的表现证明，特权EDA的知识能够通过预训练的方式转移到低成本传感器，不仅提高了准确性，而且降低了硬件成本。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24027", "html_url": "https://arxiv.org/abs/2510.24027", "title": "选取变量的时空多变量时间序列预测", "title_en": "Spatio-temporal Multivariate Time Series Forecast with Chosen Variables", "authors": "Zibo Liu,Zhe Jiang,Zelin Xu,Tingsong Xiao,Yupu Zhang,Zhengkun Xiao,Haibo Wang,Shigang Chen", "background": "时空多变量时间序列预测(STMF)使用了近期时间段内n个空间分布变量的时间序列来预测未来短期内这些变量的值。这种方法在诸如道路交通预测和空气污染预测等时空传感预测领域有重要应用。近年来，研究重点转向了模型输入中变量缺失的问题，特别是在传感器数量m远少于需要监控的位置数量n的预算限制情况下的传感应用中。现有的研究假设模型输入中的m个变量（即具有传感器的位置）是预先确定的，但如何选择这m个变量的问题一直没有得到解决。因此，该研究填补了这一空白，提出了一个新的问题即选择变量的时空多变量时间序列预测(STMF)，旨在最优地从n个变量中选择m个变量作为模型输入以最大化预测准确性。研究还提出了一个统一的框架，该框架联合执行变量选择和模型优化，旨在提高预测准确性和模型效率。实验在五个真实数据集上显示了该工作在准确性和效率上都显著优于最先进的基线方法，证明了联合变量选择和模型优化的有效性。", "innovation": "提出了一种统一的框架，该框架联合执行变量选择和模型优化，旨在提高预测准确性和模型效率。框架包括三个新颖的技术组件：逐级剪枝较少信息的变量和注意力参数的量化掩码变量参数剪枝；优先回放低损失的过去样本，保持已学习的知识以提高模型稳定性；基于可学习的空间嵌入和邻接信息的动态外推机制，将选中的变量中的信息传播到所有其他变量。", "conclusion": "研究成果在五个真实数据集上的实验表明，在准确性和效率上都显著优于最先进的基线方法，证明了联合变量选择和模型优化的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24095", "html_url": "https://arxiv.org/abs/2510.24095", "title": "从演示中学习参数化技能", "title_en": "Learning Parameterized Skills from Demonstrations", "authors": "Vedant Gupta,Haotian Fu,Calvin Luo,Yiding Jiang,George Konidaris", "background": "该研究旨在通过专家演示自动生成参数化技能。背景在于传统的技能学习方法往往需要大量的标注数据或手动设计技能，这在实际应用中效率低下。本文提出的方法通过结合时间变分推断和信息论正则化方法，解决了潜在变量模型中常见的泛化不足问题，确保了学习到的技能在时间上是连贯、语义上有意义且具有可适应性。", "innovation": "DEPS是一个端到端的算法，能够从专家演示中发现参数化技能。该方法联合学习参数化技能策略和用于选择适当离散技能和连续参数的元策略。通过结合时间变分推断和信息论正则化方法，解决了泛化不足问题，能够显著提高在未见任务上的泛化能力，尤其是在LIBERO和MetaWorld基准测试中优于多任务和技能学习基准。", "conclusion": "研究表明，从多任务专家演示中学习参数化技能能显著提高泛化能力。实验结果表明，DEPS方法在LIBERO和MetaWorld基准测试中优于多任务学习和技能学习基准，且能够发现可解释的参数化技能，例如定义抓取位置的对象抓取技能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24113", "html_url": "https://arxiv.org/abs/2510.24113", "title": "调和尾部延迟：面向片上异构芯片加速器的混合DL工作负载的NoI拓扑合成", "title_en": "Taming the Tail: NoI Topology Synthesis for Mixed DL Workloads on Chiplet-Based Accelerators", "authors": "Arnav Shukla,Harsh Sharma,Srikant Bharadwaj,Vinayak Abrol,Sujay Deb", "background": "当前，异构芯片（Chiplet）基系统的性能通过分解CPU/GPU以及新兴技术（如HBM/DRAM）来提高。然而，这种封装内的解构建会导致介面板（Network-on-Interposer, NoI）中的延迟增加。特别是在现代大型模型推理中，参数和激活数据需要频繁在HBM/DRAM之间移动，形成了大量突发流量，影响了NoI的尾部延迟，违反了服务级别协议（SLAs）。", "innovation": "本文引入了一种干扰评分（Interference Score, IS）来量化最坏情况下由于上述问题而导致的减速。同时，将NoI的设计转化为一个多目标优化（Multi-objective Optimization, MOO）问题。并开发了一种名为PARL（Partition-Aware Reinforcement Learner）的拓扑生成器，它可以平衡带宽、延迟和功耗。PARL生成的拓扑减少了内存接口处的争用，满足SLA，将最坏情况下的延迟降低至1.2倍，同时保持与丰富的链接网格相当的平均吞吐量。", "conclusion": "这一研究成果重新定义了面向工作负载感知的异构芯片加速器NoI设计，通过多目标优化方法，可以平衡性能和功耗以应对混合DL工作的挑战。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24025", "html_url": "https://arxiv.org/abs/2510.24025", "title": "神经PathNet：用于脑功能连接分析的动力路径轨迹学习", "title_en": "NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional Connectivity Analysis", "authors": "Guo Tianqi Guo,Chen Liping,Peng Ciyuan,Guo Jingjing,Ren Jing", "background": "脑功能网络随时间的演变对于认知机制的分析和神经疾病诊断具有重要意义。现有方法在捕捉特定功能社区之间的连接演变特性方面存在困难。鉴于此，本文提出了一种新的路径级别的轨迹建模框架（NeuroPathNet），用于表征脑功能分区之间连接路径的动力学行为。结合医学支持的静态分区方案（如Yeo和Smith ICA），提取每对功能分区之间的连接强度的时间序列，并使用时间神经网络对其进行建模。在三个公开的功能磁共振成像（fMRI）数据集上验证模型性能，结果显示在多个指标上优于现有的主流方法。研究可以促进脑网络分析中动态图学习方法的发展，并为神经疾病的诊断提供潜在的临床应用可能性。", "innovation": "本文提出了NeuroPathNet框架，这是一种新的路径级轨迹建模方法，用于表征脑功能分区之间的动态行为，特别是改善了特定功能社区之间的连接演变特性的捕捉。该方法结合医学支持的静态分区方案提取连接强度的时间序列，并使用时间神经网络进行建模。实验结果显示该模型在多个指标上优于现有方法。", "conclusion": "本文的工作促进了动态图学习方法在脑网络分析中的发展，并为神经疾病的诊断提供了新的临床应用可能性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24103", "html_url": "https://arxiv.org/abs/2510.24103", "title": "模型引导的双角色对齐及其在高保真开放域视频转音频生成中的应用", "title_en": "Model-Guided Dual-Role Alignment for High-Fidelity Open-Domain Video-to-Audio Generation", "authors": "Kang Zhang,Trung X. Pham,Suyeon Lee,Axi Niu,Arda Senocak,Joon Son Chung", "background": "当前的视频到音频生成方法主要依赖于分类器进行指导，或是完全不依赖分类器，而MGAudio采用了模型引导下的双角色对齐机制作为核心设计理念，这在视频到音频生成领域是一种新的探索。这种方法旨在使生成模型能够通过专门设计的目标训练，指导自身进行视频条件下的音频生成，从而改善生成质量，增强跨模态一致性和音频保真度。与现有方法相比，MGAudio在VGGSound数据集上取得了最先进的性能，大幅超越了最先进的不依赖分类器的方法，并在FD、IS和对齐度量上持续优于现有方法，同时也展现出对UnAV-100具有挑战性的基准的良好泛化能力。这些结果表明，模型引导下的双角色对齐是一种强大的、可扩展的范式，适用于条件下的视频到音频生成任务。", "innovation": "MGAudio是一种基于流的框架，用于开放域视频到音频生成，引入了模型引导下的双角色对齐作为核心设计理念。与传统的依赖于分类器或不依赖分类器的方法不同，MGAudio通过设计专门的目标，使生成模型能够自我指导进行视频条件下音频的生成，从而改善生成质量。框架整合了三个主要组件：一个可扩展的基于流的Transformer模型，一个双角色对齐机制，其中音频-视觉编码器不仅作为条件模块，还作为特征对齐器来提高生成质量，以及一个模型引导的目标，以增强跨模态的一致性和音频的真实性。", "conclusion": "MGAudio在VGGSound基准上达到了最先进的性能，将FAD降低到0.40，显著超过了最好的不依赖分类器的方法，并在FD、IS和对齐指标上持续优于现有方法。它也很好地泛化到具有挑战性的UnAV-100基准。这些结果突显了模型引导下的双角色对齐作为有条件视频到音频生成中的强大和可扩展范式。相关代码已公开。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24133", "html_url": "https://arxiv.org/abs/2510.24133", "title": "基于推理时缩放的组成性图像合成", "title_en": "Compositional Image Synthesis with Inference-Time Scaling", "authors": "Minsuk Ji,Sanghyeok Lee,Namhyuk Ahn", "background": "尽管现代从文本到图像的模型具有极高的真实性，但在组成性（compositionality）方面仍然存在挑战，经常无法准确渲染对象数量、属性及空间关系。", "innovation": "本文提出了一个无需训练的框架，该框架结合了对象为中心的方法与自我修正，以增强布局的真实性并保持美学质量。具体来说，利用大语言模型（LLMs）从输入提示中生成显式布局，并将其注入图像生成过程中，在此过程中，对象为中心的视觉语言模型（VLM）评估并迭代筛选多个候选方案，以选择与提示最一致的结果。通过将显式布局与基于自我修正的推理时缩放相结合，本文框架在场景对齐方面比最近的从文本到图像模型表现更优。", "conclusion": "本文框架在提示对齐方面表现更优，实验结果表明相较于近期从文本到图像的模型，该框架实现了更强的场景对齐。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24139", "html_url": "https://arxiv.org/abs/2510.24139", "title": "LLMs预训练语料库中的超越行级过滤", "title_en": "Beyond Line-Level Filtering for the Pretraining Corpora of LLMs", "authors": "Chanwoo Park,Suyoung Park,Yelim Ahn,Jongmin Kim,Jongyeon Park,Jaejin Lee", "background": "传统的行级过滤技术，如行级重复数据删除和尾随标点符号过滤，虽然广为使用，但有时会丢弃有价值的内容，从而负面影响后续性能。", "innovation": "本文提出了一种增强型过滤技术——模式感知行级重复数据删除（PLD）和模式感知尾随标点符号过滤（PTF）。不仅考虑行级信号，还考虑其在文档中的顺序分布，从而保留了本来可能被删除的结构重要内容。", "conclusion": "通过在英语和韩语中训练小型语言模型（1B参数），我们的方法在多项选择基准测试中保持了性能提升，并且在SQuAD v1和KorQuAD v1上的生成问答准确性上有显著增强。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24049", "html_url": "https://arxiv.org/abs/2510.24049", "title": "从历史中学习：一种时空预测检索增强框架", "title_en": "Learning from History: A Retrieval-Augmented Framework for Spatiotemporal Prediction", "authors": "Hao Jia,Penghao Zhao,Hao Wu,Yuan Gao,Yangyu Tao,Bin Cui", "background": "在科学计算中，准确且长时间的时空预测对于复杂物理系统仍然是一个基本挑战。尽管深度学习模型作为强大的参数近似器表现出色，它们在长期自回归滚动过程中累积的误差常常导致物理上不可行的现象。这主要是由于它们纯参数的性质，难以捕捉系统内在动态的全部约束。传统的深度学习方法难以解决这一问题，因此需要一种新的方法来克服这一缺陷。", "innovation": "我们提出了一种新的Retrieval-Augmented Prediction (RAP)框架，这是一个混合框架，结合了深度网络的预测能力和历史数据的真实现状。核心思想是利用历史演化实例作为系统局部动态的非参数估计。对于任何给定的状态，RAP高效地从大规模数据库中检索最相似的历史实例，并将其真实的未来演变作为参考目标。这个目标不是在损失函数中的硬约束，而是专有双流架构的强大条件输入，提供了动态引导，使模型预测指向物理上可行的轨迹。该框架在气象学、湍流和火模拟的广泛基准测试中不仅超过了最先进的方法，而且显著优于仅使用模拟的预测基线。更重要的是，RAP通过有效抑制长期滚动中的误差发散，生成了更物理上现实的预测。", "conclusion": "RAP在气象学、湍流和火模拟的广泛基准测试中不仅超过了最先进的方法，而且显著优于仅使用模拟的预测基线。更重要的是，通过有效地抑制长期滚动中的误差发散，RAP生成了更物理上现实的预测。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24159", "html_url": "https://arxiv.org/abs/2510.24159", "title": "自监督合成预训练以推断嵌入密集气体中的恒星质量", "title_en": "Self-supervised Synthetic Pretraining for Inference of Stellar Mass Embedded in Dense Gas", "authors": "Keiya Hirashima,Shingo Nozaki,Naoto Harada", "background": "恒星质量是决定恒星性质和演化的基本参数，在恒星形成区域估算恒星质量极具挑战性，因为年轻恒星被密集气体所遮蔽，且区域内部结构高度不均匀，使得球形动力学估计不可靠。监督机器学习可以将这种复杂结构与恒星质量联系起来，但需要来自高分辨率磁流体动力学（MHD）模拟的大规模高质量标签数据集，而这些数据集是计算成本高昂的。", "innovation": "该研究通过在百万个合成分形图像上进行自监督预训练，使用DINOv2框架，然后将冻结的模型应用于少量的高分辨率MHD模拟。实验结果显示，合成预训练可以改善冻结特征回归恒星质量预测，且预训练模型性能略优于仅在相同有限模拟上进行监督训练的模型。主成分分析进一步揭示提取特征中存在的具有语义意义的结构，表明该模型实现了无监督的星 formation 区域分割，无需标签数据或微调。", "conclusion": "研究表明，自监督合成预训练可以有效提高恒星质量预测的准确性，为星形成区域的研究提供了新的方法。通过该模型可以实现不需要标签数据的无监督分割，使恒星质量和星形成区域分析更加高效和精确。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24072", "html_url": "https://arxiv.org/abs/2510.24072", "title": "智能设备中的隐蔽监视：SCOUR框架下青少年隐私影响的分析", "title_en": "Covert Surveillance in Smart Devices: A SCOUR Framework Analysis of Youth Privacy Implications", "authors": "Austin Shouli,Yulia Bobkova,Ajay Kumar Shrestha", "background": "本文探讨了智能设备如何隐蔽地捕获私人对话，并深入讨论了这对其青少年隐私的影响。研究采用了基于PRISMA方法学的结构化回顾，分析隐私关切、数据捕获方法、数据存储与分享实践，以及提出的技术缓解措施。研究表明，智能设备尤其是为青少年设计的智能玩具和语音激活智能设备，已被隐蔽地捕获个人信息。这些问题因数据收集实践不透明和智能设备在应用中的不足透明度而加剧。平衡智能设备中的隐私与实用性非常重要，因为青少年越来越多地意识到隐私泄露并更加重视他们的个人数据。该研究还指出了监管和技术保障的战略，并识别了研究缺口和未来方向，强调了数据收集透明度对政策制定的重要性。", "innovation": "本文引入了SCOUR框架，涵盖监视机制、同意和意识、数据流操作、使用和开发以及监管和技术保障，以结构化和综合研究发现。该框架有助于更好地理解和分析与智能设备相关的隐私问题。研究还提供了改进监管和技术保障的策略，并指出了未来的研究方向，强调了隐私风险对于政策制定的重要性.", "conclusion": "本文的研究发现对智能设备的数据收集透明度和政策制定具有重要意义，揭示了当前智能设备在隐私保护方面的不足之处，并提出了改进监管和技术保障的策略。然而，文献回顾也存在局限性，未来还需进一步研究以填补研究空白。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24118", "html_url": "https://arxiv.org/abs/2510.24118", "title": "LagMemo: 语言3D高斯点阵记忆在模态开放词汇多目标视觉导航中的应用", "title_en": "LagMemo: Language 3D Gaussian Splatting Memory for Multi-modal Open-vocabulary Multi-goal Visual Navigation", "authors": "Haotian Zhou,Xiaole Wang,He Li,Fusheng Sun,Shengyu Guo,Guolei Qi,Jianghuan Xu,Huijing Zhao", "background": "智能机器人利用视觉信息导航至预定目标是一项基本能力。大多数经典视觉导航方法仅适用于单一目标、单一模态和封闭词汇目标设置。为了满足多模态、开放词汇目标查询和多目标视觉导航的实际需求，本文提出了LagMemo导航系统，该系统利用了语言3D高斯点阵内存。", "innovation": "提出了一种名为LagMemo的导航系统，该系统利用语言3D高斯点阵内存，并能够在探索过程中构建统一的三维语言内存。通过任务目标输入，系统查询内存，预测候选目标位置，并结合局部感知验证机制，在导航过程中动态匹配和验证目标。为了公平和严格的评估，作者精心构建了GOAT-Core数据集，该数据集是从GOAT-Bench中提炼出来的，专门针对多模态开放词汇多目标视觉导航。实验结果显示，LagMemo的记忆模块能够有效地实现多模态开放词汇目标定位，并且在多目标视觉导航中表现优于最新的技术。", "conclusion": "实验结果表明，LagMemo的记忆模块能够有效实现多模态开放词汇的目标定位，并且在多目标视觉导航方面表现优于最新技术。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24217", "html_url": "https://arxiv.org/abs/2510.24217", "title": "填补缺口：ICU生命体征插补分析", "title_en": "Closing Gaps: An Imputation Analysis of ICU Vital Signs", "authors": "Alisher Turubayev,Anna Shopova,Fabian Lange,Mahmut Kamalak,Paul Mattes,Victoria Ayvasky,Bert Arnrich,Bjarne Pfitzner,Robin P. van de Water", "background": "随着更多重症监护室（ICU）数据的可用性增强，开发临床预测模型以改进医疗护理模式的需求也随之增加。然而，数据质量的不足仍然阻碍了使用机器学习（ML）进行临床预测。许多重要的生命体征测量值如心率存在大量的缺失段，这些空白数据段可能对预测性能产生负面影响。尽管先前引入了许多时间序列插补技术，但对于插补ICU生命体征的最佳实践仍然需要进一步研究来确定。现实生活中，仍然会使用降低预测精度的临时插补技术，如零插补。本文旨在比较现有的插补技术，以指导研究人员通过选择最精确的插补技术来提高临床预测模型的性能。", "innovation": "本文提出一个可扩展且可重用的基准测试，其中包括目前15种插补和4种截断方法，用于基准测试在主要ICU数据集上的表现。该工作旨在为进一步的ML开发提供比较基础，并促进将更多模型引入临床实践。", "conclusion": "通过比较现有的插补技术，本文旨在提供一个比较基础，帮助进一步促进ML开发，使更多模型能够应用于临床实践中。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24061", "html_url": "https://arxiv.org/abs/2510.24061", "title": "FALQON：使用低比特浮点算术加速LoRA微调", "title_en": "FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point Arithmetic", "authors": "Kanghyun Choi,Hyeyoon Lee,SunJong Park,Dain Kwon,Jinho Lee", "background": "低比特浮点（FP）格式，如FP8，在现代GPU和NPU的原生硬件支持下，为模型训练提供了显著的加速和内存节约。然而，研究发现，FP8量化主要在大型矩阵乘法中提供加速，但在应用于低阶适应（LoRA）时效果减小，因为LoRA使用小维矩阵进行大型语言模型（LLM）高效微调，存在固有的量化开销。因此，我们需要一种方法来消除LoRA计算路径中的量化开销。", "innovation": "本文提出了一种名为FALQON的新框架，该框架在微调期间直接将LoRA适配器合并到FP8-量化主干中，从而消除LoRA计算路径中的量化开销。此外，它还对合并适配器的前向和反向计算进行了重新制定，以显著减少量化开销，并引入了一种行向量代理更新机制，以高效地将大量更新集成到量化主干中。实验评估表明，与现有的量化LoRA方法相比，FALQON在保持类似精度的情况下，实现了约3倍的训练加速，提供了一种高效的大型模型微调的实用解决方案。此外，FALQON的端到端FP8流程消除了后训练量化的需求，促进了高效的部署。代码可以在该网址获取：this https URL", "conclusion": "FALQON通过消除LoRA适配器中的量化开销和引入高效数据集成机制，实现了表征性LoRA模型的加速微调，同时保持与非量化LoRA方法相近的精度，简化了部署流程。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG: 优化文本到视频生成的视频字幕", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "文本到视频（T2V）生成的最新进展强调了高质量的视频-字幕对生成连贯且与指令一致的视频模型的重要性，但专用于T2V训练的字幕优化策略尚未得到充分探索。", "innovation": "本文提出了VC4VG（视频字幕为视频生成），这是一种专门针对T2V需求的全面的字幕优化框架。该框架通过从T2V的视角分析字幕内容，将视频重建所需的基本要素分解为多个维度，并提出了一种原则性的字幕设计方法。此外，还构建了VC4VG-Bench基准，该基准包括细粒度、多维度和需求分级的度量标准，以与T2V特定性契合。T2V微调实验表明，提升字幕质量与视频生成性能之间存在强关联，验证了该方法的有效性。", "conclusion": "通过发布基准工具和代码，旨在支持进一步研究。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24150", "html_url": "https://arxiv.org/abs/2510.24150", "title": "Ko-MuSR：具备理解韩国语能力的大型语言模型多步软推理基准", "title_en": "Ko-MuSR: A Multistep Soft Reasoning Benchmark for LLMs Capable of Understanding Korean", "authors": "Chanwoo Park,Suyoung Park,JiA Kang,Jongyeon Park,Sangho Kim,Hyunji M. Park,Sumin Bae,Mingyu Kang,Jaejin Lee", "background": "当前，大规模语言模型已经开始在多语言任务中表现出一定的推理能力，但考虑到韩国语特定的语境和表达方式，专门针对韩国语的推理基准仍然较为缺乏。Ko-MuSR 基准测试旨在评估模型在长篇韩国语叙述中的多步软推理能力，同时最大程度地减少数据污染的影响。", "innovation": "Ko-MuSR 是首个全面评估多步软推理能力的基准，特别专注于韩国语。该基准包括完整的韩国语故事情节、推理链以及经过人工注释验证的多选题，保证逻辑一致性和可回答性。实验结果显示，即使在纯韩国推理任务中，多语言模型依然优于专门针对韩国语的模型，表明了推理能力的跨语言泛化。精心设计的提示策略，结合少量示例、推理痕迹和任务特定提示，进一步提高了准确性，接近人类水平的表现。", "conclusion": "Ko-MuSR 为韩语 NLP 的发展提供了坚实的基础，通过系统评估长语境下的推理能力和提示策略，有助于推动韩语自然语言处理的进步。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24241", "html_url": "https://arxiv.org/abs/2510.24241", "title": "MAGNET: 一种用于代码克隆检测的多图注意力网络", "title_en": "MAGNET: A Multi-Graph Attentional Network for Code Clone Detection", "authors": "Zixian Zhang,Takfarinas Saber", "background": "代码克隆检测是在软件工程中的一项基础任务，支撑着重构、调试、剽窃检测和漏洞分析等工作。现有方法通常依赖单一表示（如抽象语法树、控制流图和数据流图），这些方法只能捕捉代码语义的部分方面。虽然已经出现了混合方法，但它们的融合策略通常是手工设计的，效果不佳。", "innovation": "本文提出了一种名为MAGNET的多图注意力框架，该框架联合利用抽象语法树、控制流图和数据流图来捕捉源代码的语法规则和语义特征。MAGNET结合使用残差图神经网络与节点级别自注意力机制学习局部和长距离依赖关系，引入了门控交叉注意力机制以获得细粒度的跨图交互，并采用了Set2Set聚合法将多图嵌入融合为统一的程序级表示。", "conclusion": "MAGNET在BigCloneBench和Google Code Jam上的实验表明，该方法分别获得了F1分数为96.5%和99.2%的最新技术水平。消融研究证实了多图融合和每个注意力组件的关键贡献。代码已于此链接公开。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24152", "html_url": "https://arxiv.org/abs/2510.24152", "title": "通过任务特定提示和空间推理增强视觉语言模型在自动驾驶中的应用", "title_en": "Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning", "authors": "Aodi Wu,Xubo Luo", "background": "本文档展示了一种针对2025年IROS RoboSense挑战中视觉语言模型（VLM）性能评估的解决方案。该挑战涵盖了自主驾驶场景理解中的感知、预测、规划和数据损坏检测任务。针对这些任务，研究提出了一种综合框架，由四个核心组件构成：提示路由、任务特定提示嵌入、视觉组装模块以及模型推理参数配置。这种系统性方法改进了VLM在自动驾驶安全关键任务中的表现，特别是在使用结构化提示和空间定位优化视觉理解方面。", "innovation": "研究提出了一个系统性框架，包括四个核心组件：提示路由以分类问题和调度特定任务的专家提示，以消除不同问题类型的干扰；任务特定提示嵌入了明确的坐标系统、空间推理规则、角色扮演、思维链/思维树推理以及针对每个任务的少量示例；视觉组装模块根据问题需求复现多视角图像、对象截图、品红色标记和自适应历史帧；配置模型推理参数（温度、top-p、信息角色）以优化输出质量。该框架通过使用结构化提示和空间定位大大提升了VLM在安全关键的自动驾驶任务中的性能。", "conclusion": "在Qwen2.5-VL-72B上实施，该方法在清洁数据（第一阶段）中实现了70.87%的平均准确性，在受污染数据（第二阶段）中实现了72.85%的准确性，证明结构化提示和空间定位显著提升了VLM在安全关键的自动驾驶任务中的表现。代码和提示可在指定链接中获得。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24235", "html_url": "https://arxiv.org/abs/2510.24235", "title": "PaTaRM: Preference-Aware Task-Adaptive Reward Modeling for Bridging Pairwise and Pointwise Signals", "title_en": "PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling", "authors": "Ai Jian,Jingqing Ruan,Xing Ma,Dailin Li,QianLin Zhou,Ke Zeng,Xunliang Cai", "background": "奖励模型（RMs）是大规模语言模型（LLMs）从人类反馈中强化学习（RLHF）的关键。现有技术包括对偶方法和点对方法。对偶方法依赖于二元的好与坏标签，这在点对推理中导致不匹配，并需要复杂的配对策略。点对方法需要更复杂的绝对标签来适应和注释，这导致了低适应性和高昂的成本。因此，需要一种能够结合相对偏好信息和任务自适应评价标准的新方法，以提高奖励模型的效率、通用性和可解释性。", "innovation": "本文提出了一种统一框架——偏好感知任务自适应奖励模型（PaTaRM），融合了偏好感知奖励（PAR）机制和动态评价标准自适应。PaTaRM利用对偶数据中的相对偏好信息构建稳健的点对训练信号，避免了明确的点对标签的需求。同时，它采用一种任务自适应评价标准系统，灵活生成适用于全局任务一致性和实例特定细粒度推理的评价标准。这一设计使得PaTaRM能够高效、通用且具有可解释性地进行奖励建模。通过广泛的实验，PaTaRM显示出了在RewardBench和RMBench上的平均相对改进为4.7%，以及在IFEval和InFoBench基准上的平均改进为13.6%，从而证明了其效果和鲁棒性。", "conclusion": "PaTaRM通过结合偏好感知奖励机制和动态评价标准自适应，克服了当前训练范式的限制。实验结果显示，PaTaRM在多个基准上显著提高了RLHF性能，并展示了其高效性、通用性和可解释性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24255", "html_url": "https://arxiv.org/abs/2510.24255", "title": "基于数字孪生的未知环境下基于无人机的低空无线网络轨迹设计：TD3方法", "title_en": "Trajectory Design for UAV-Based Low-Altitude Wireless Networks in Unknown Environments: A Digital Twin-Assisted TD3 Approach", "authors": "Jihao Luo,Zesong Fei,Xinyi Wang,Le Zhao,Yuanhao Cui,Guangxu Zhu,Dusit Niyato", "background": "无人机(UAVs)正在成为低空无线网络(LAWN)的关键使能器，尤其是在地面网络不可用的情况下。在这种情况下，环境拓扑通常未知，因此设计高效的和安全的无人机轨迹至关重要且具有挑战性。", "innovation": "本文提出了一个基于数字孪生(DT)的培训和部署框架。该框架中，UAV传输集成化的感测和通信信号以提供地面用户的通信服务，同时收集回声上传到DT服务器以逐步构建虚拟环境(VEs)。这些VEs加速了模型训练并实时更新，支持部署中的决策并增强飞行安全性。进一步开发了一种轨迹设计方案，结合了模拟退火算法进行高效的用户调度和TD3算法进行连续轨迹设计，旨在最小化任务完成时间并确保避障。", "conclusion": "仿真结果表明，所提出的方法相比基准方法实现了更快的收敛、更高的飞行安全性和更短的任务完成时间，为在未知环境下的LAWN部署提供了稳健而高效的解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24178", "html_url": "https://arxiv.org/abs/2510.24178", "title": "MuSaG:一个包含全模式注释的多模态德国讽刺数据集", "title_en": "MuSaG: A Multimodal German Sarcasm Dataset with Full-Modal Annotations", "authors": "Aaron Scott,Maike Züfle,Jan Niehues", "background": "讽刺是一种复杂的比喻语言形式，其实际含义与字面意思相反。社交媒体和流行文化中讽刺的普遍存在给自然语言理解、情感分析和内容管理带来了持续的挑战。随着多模态大语言模型的出现，讽刺检测已不再局限于文本，而是需要综合听觉和视觉的线索。现有研究中缺乏针对德国语言的多模态讽刺检测数据集，现有的数据集主要关注英美文化背景下的视频内容，针对这些语境训练的模型在德国文化背景下的表现不佳。因此，建立一个基于德国语境的数据集并使用多模态信息进行标注是必要的。", "innovation": "该研究首次发布了一个名为MuSaG的德国多模态讽刺检测数据集，数据集基于德国电视节目的33分钟对话，以文本、音频和视频的形式进行手动选择和注释。每个实例提供了独立的人工标注的文本、音频和视频模态，可以用于单模态和多模态的评价。研究团队利用九个开源和商用模型（包括文本、音频、视觉和多模态架构）对模型进行了评估，并与人工注释进行了对比。研究结果表明，人类在对话场景中更依赖音频信息，而模型在文本上表现更好。这些发现揭示了当前多模态模型的不足之处，进一步推动了MuSaG数据集在开发更适合实际场景模型方面的应用。", "conclusion": "本研究通过公开MuSaG数据集，不仅支持了未来有关多模态讽刺检测的研究，而且也促进了模型与人类行为之间的对齐。本次实验还揭示了一个重要的现象，即现有模型在处理德国语境下的多模态讽刺数据时可能存在缺陷，这表明进一步研究的必要性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24242", "html_url": "https://arxiv.org/abs/2510.24242", "title": "通过大型视觉语言模型的卫星-地面合作实现近实时遥感", "title_en": "Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration of Large Vision-Language Models", "authors": "Zihan Li,Jiahao Yang,Yuxin Zhang,Zhe Chen,Yue Gao", "background": "近年来，大型视觉语言模型（LVLMs）在由低地球轨道（LEO）卫星执行的遥感（RS）任务（如灾害监测）中展现出了巨大的潜力。然而，这些模型在实际LEO卫星系统中的应用尚未被广泛探索，主要是由于受限的机载计算资源和短暂的卫星-地面联系时间。", "innovation": "本文提出了Grace，一种卫星-地面协作系统，旨在为遥感任务提供接近实时的LVLM推理服务。Grace将小型LVLM部署在卫星上进行实时推理，而较大的则部署在地面站（GSs）以确保端到端的性能。系统包含两个主要阶段：异步卫星-地面检索增强生成（RAG）以及任务调度算法。此外，还提出了一种基于置信度的测试算法，该算法决定任务是在卫星上执行还是卸载到地面站处理。实验表明，与现有方法相比，Grace可以将平均延迟减少76-95%，而不会影响推理准确性。", "conclusion": "Grace通过卫星-地面协作实现了LVLM在遥感任务中的接近实时推理，显著降低了延迟，同时保持了高推理准确性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24272", "html_url": "https://arxiv.org/abs/2510.24272", "title": "过程系统工程中强化学习方法的综述与教程", "title_en": "Survey and Tutorial of Reinforcement Learning Methods in Process Systems Engineering", "authors": "Maximilian Bloor,Max Mowbray,Ehecatl Antonio Del Rio Chanona,Calvin Tsay", "background": "在过程系统工程(PSE)中，传统方法控制和优化复杂且具有随机性的系统时常受限。强化学习(Reinforcement Learning, RL)作为一种数据驱动的方法，能够为解决此类挑战提供控制策略。本文旨在为PSE社区提供关于RL方法的综述与教程，涵盖基本概念、主要算法家族（基于值、基于策略和演员-评论家方法），以及RL技术在PSE各领域的应用实例，包括连续过程控制、过程优化和供应链等领域。在这些基础上，文章最后讨论了针对PSE的技术特性和未来研究方向，综述了当前RL算法的发展和对该领域的影响，归纳了存在的问题、趋势，并展望了未来研究的方向。", "innovation": "本文提供了一个专门为PSE社区设计的强化学习方法的综述与教程，涵盖了基本概念、重要算法家族和专门的PSE技术，及其在各种过程系统工程中的应用场景。此外，还讨论了未来研究的方向和发展趋势，填补了该领域研究的空白，具有创新意义。", "conclusion": "本文总结了关于PSE领域的强化学习方法的研究现状，讨论了成功案例、存在的挑战、未来趋势，并提出了未来研究方向，为研究人员提供了一个有价值的参考框架，推动了该领域的进一步发展。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24261", "html_url": "https://arxiv.org/abs/2510.24261", "title": "DynaRend: 通过遮罩未来渲染学习3D动力学的机器人操作", "title_en": "DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation", "authors": "Jingyi Tian,Le Wang,Sanping Zhou,Sen Wang,Jiayi Li,Gang Hua", "background": "学习通用机器人操作策略仍然是一个挑战，因为现实世界中多样化的训练数据稀缺。尽管最近的方法试图通过自我监督表示学习来减轻这一问题，但大多数方法要么依赖于2D视觉预训练方法，如遮罩图像建模，主要关注静态语义或场景几何，要么使用大规模视频预测模型，侧重于2D动力学，这无法同时学习进行有效操作所需的几何、语义和动力学。因此，当前的方法难以实现有效的物理操作。", "innovation": "我们提出了DynaRend，一种通过可微分体积渲染进行遮罩重建和未来预测来学习3D意识和动力学告知的三平面特征的表示学习框架。DynaRend 在多视角RGB-D视频数据上的预训练能够联合捕获空间几何、未来动力学和任务语义，并通过动作价值图预测将学习的表示有效转移至下游机器人操作任务。实验结果证明了DynaRend在RLBench和Colosseum等挑战性基准上以及在实际机器人实验中的大幅性能提升，以及在多种操作任务中的泛化能力和实际应用价值。", "conclusion": "DynaRend通过创新地使用遮罩未来渲染技术，在多视角RGB-D视频数据上进行预训练，实现联合捕捉空间几何、未来动态和任务语义，并成功应用于下游机器人操作任务，展示了在复杂基准和实际机器人实验中的显著成效，证明了其有效性和广泛适用性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24278", "html_url": "https://arxiv.org/abs/2510.24278", "title": "通过复原训练免费的AI生成图像源归Attribution of AI-generated Images via Resynthesis", "title_en": "Training-free Source Attribution of AI-generated Images via Resynthesis", "authors": "Pietro Bongini,Valentina Molinari,Andrea Costanzo,Benedetta Tondi,Mauro Barni", "background": "合成图像源归属性是一项具有挑战性的任务，特别是在数据稀缺条件下，需要具备极少样本分类能力。现有的方法在这些条件下表现不佳。", "innovation": "本文提出了一种基于图像复原的无训练框架下的单次归属性方法。通过生成对分析图像的描述提示，用其进行复原，将图像归因于生成与原始图像最接近复原结果的模型。同时，作者还引入了一个新的合成图像归属性数据集，由商业和开源文本到图像生成器生成的人脸图像组成，为开发新的归属性模型提供了具有挑战性的框架。", "conclusion": "实验结果表明，该提出的复原方法在少量样本可用于训练或微调时，优于现有的技术；新数据集具有挑战性，并且是评估前方和零方方法的宝贵基准。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24170", "html_url": "https://arxiv.org/abs/2510.24170", "title": "SymMaP: 通过符号预处理提高线性求解器的计算效率", "title_en": "SymMaP: Improving Computational Efficiency in Linear Solvers through Symbolic Preconditioning", "authors": "Hong Wang,Jie Wang,Minghao Ma,Haoran Shao,Haoyang Liu", "background": "矩阵预条件化是加速线性系统求解的关键技术，其性能高度依赖于预条件化参数的选择。传统方法往往定义特定场景下的固定常数，但这些方法依赖领域专业知识，未能考虑单个问题的实例特征，限制了其性能。机器学习方法虽然有潜力，但由于高推断成本和有限的可解释性而受到阻碍。为了结合两者的优点，本文提出了一种符号发现框架——即Symbolic Matrix Preconditioning (SymMaP)，以学习预条件化参数的有效符号表达式。该方法使用神经网络在高维离散空间中搜索可以准确预测最优参数的表达式。通过学习的表达式提供高效的推断效率和优秀的可解释性（以简洁的符号公式表示），使其实现部署简单可靠。实验结果表明，SymMaP 在各种基准测试中都能持续优于传统策略。", "innovation": "本文提出了一种结合了机器学习和符号处理的Symbolic Matrix Preconditioning (SymMaP)框架，通过使用神经网络在高维离散空间搜索高质量的预条件化参数表达式，解决了传统方法依赖领域知识和机器学习方法的高推断成本和有限可解释性问题，提高了预处理的效率和可解释性。", "conclusion": "实验结果表明，SymMaP 在各种基准测试中都能持续优于传统预条件化策略，展现了该方法的优越性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24320", "html_url": "https://arxiv.org/abs/2510.24320", "title": "Critique-RL: 通过双阶段强化学习训练语言模型进行批评", "title_en": "Critique-RL: Training Language Models for Critiquing through Two-Stage Reinforcement Learning", "authors": "Zhiheng Xi,Jixuan Huang,Xin Guo,Boyang Hong,Dingwen Yang,Xiaoran Fan,Shuo Li,Zehui Chen,Junjie Ye,Siyu Yuan,Zhengyin Du,Xuesong Yao,Yufei Xu,Jiecao Chen,Rui Zheng,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "训练具有批评能力的语言模型以评估模型输出并提供反馈，被认为能提升大语言模型在复杂推理任务上的性能。然而，现有方法通常依赖于更强的监督者来标注批评数据。本研究旨在解决这一问题。", "innovation": "提出了Critique-RL，一种无需更强监督的线上强化学习方法，通过两阶段优化策略，在提高批评者的区分度（确定响应质量）的同时，也增强了其建设性（提供有用反馈）。", "conclusion": "广泛的实验表明，Critique-RL在各类任务和模型中均显著提升了性能。例如，在Qwen2.5-7B模型上，它分别实现了9.02%和5.70%的性能提升，展示了其潜力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24318", "html_url": "https://arxiv.org/abs/2510.24318", "title": "Transformers可以进行贝叶斯聚类", "title_en": "Transformers can do Bayesian Clustering", "authors": "Prajit Bhaskaran,Tom Viering", "background": "贝叶斯聚类可以处理不确定性，但大规模计算上费时。真实世界的数据集往往包含缺失值，简单的插补方法忽视了其不确定性，导致次优结果。", "innovation": "提出了基于Transformer的Cluster-PFN模型，将Prior-Data Fitted Networks (PFNs)扩展到无监督的贝叶斯聚类。Cluster-PFN完全在从有限高斯混合模型（GMM）先验生成的合成数据集上进行训练，能够估计聚类的数量和聚类分配的后验分布。该方法在聚类数量的估计上比手工设计的选择程序（如AIC、BIC和变分推断）更准确，并且在分类质量上与变分推断相当，但速度快得多。Cluster-PFN可以处理复杂先验和缺失数据，特别是在基因组学等真实世界的数据集中的高缺失性情况下，优于基于插补的基线方法。", "conclusion": "Cluster-PFN可以提供可扩展和灵活的贝叶斯聚类。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24356", "html_url": "https://arxiv.org/abs/2510.24356", "title": "感知学习：感知识别学习与决策学习的形式分离", "title_en": "Perception Learning: A Formal Separation of Sensory Representation Learning from Decision Learning", "authors": "Suman Sanyal", "background": "该论文提出了一种新的学习范式——感知学习（PeL），它通过使用任务无关的信号来优化智能体的感官接口 $f_\theta: \text{X} \to \text{Z}$ ，而与下游决策学习 $g_\theta: \text{Z} \to \text{Y}$ 分开。PeL 直接针对无需标签的感知特性进行优化，如对噪声的稳定性、信息性以及控制几何结构等，这些特性通过客观的、不变表示度量法进行评估。", "innovation": "该研究正式分离了感知识别学习与决策学习，定义了独立于目标或参数化方式的感知属性。此外，它证明了保持足够不变量的PeL更新是与贝叶斯任务风险梯度正交的，并提供了多种任务无关的评估度量来验证感知质量。", "conclusion": "研究提出了感知学习这一范式，强调直接优化感知过程，并通过客观度量来确认其质量，同时证明了这种分离在理论上的可行性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24438", "html_url": "https://arxiv.org/abs/2510.24438", "title": "LLMs能否忠实地写作？基于代理评估的LLM生成的伊斯兰内容", "title_en": "Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content", "authors": "Abdullah Mushtaq,Rafay Naeem,Ezieddin Elmahjub,Ibrahim Ghaznavi,Shawqi Al-Maliki,Mohamed Abdallah,Ala Al-Fuqaha,Junaid Qadir", "background": "随着大型语言模型在伊斯兰指导中的应用日益增多，它们面临误引文本、错误应用法律或产生文化不一致回答的风险。本文通过针对真实伊斯兰博客的提示，对GPT-4o、Ansari AI和Fanar进行了试点评估。", "innovation": "本文提出了一种双代理框架，该框架包括一个用于引文验证的定量代理和一个用于五维度对比的定性代理。GPT-4o在伊斯兰准确性（3.93）和引文（3.38）方面表现最佳，Ansari AI次之，Fanar的表现较差。尽管模型在生成准确的伊斯兰内容和引文方面有出色的表现，但在可靠地产生信仰敏感内容方面仍存在不足。Fanar虽然落后，但为伊斯兰和阿拉伯语环境引入了创新。", "conclusion": "本研究强调了需要围绕穆斯林视角建立社区驱动的标准，并迈出了更可靠AI在伊斯兰知识及其他关键领域的第一步，如医学、法律和新闻业。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24402", "html_url": "https://arxiv.org/abs/2510.24402", "title": "基于元数据的检索增强生成技术在金融问答中的应用", "title_en": "Metadata-Driven Retrieval-Augmented Generation for Financial Question Answering", "authors": "Michail Dadopoulos,Anestis Ladas,Stratos Moschidis,Ioannis Negkakis", "background": "检索增强生成（RAG）在处理长且结构化的金融文件时遇到困难，尤其是在相关证据稀疏且交叉引用的情况下。本文详细探讨了面向金融问答的高级元数据驱动的RAG技术，分析了其在长且结构化金融文件中的应用挑战。", "innovation": "提出了一个新颖的、多阶段的RAG架构，该架构利用LLM生成的元数据。引入了一个复杂的索引管道来创建内容丰富的文档片段，并对一系列增强技术进行了基准测试，包括预检索过滤、后检索重排和增强的嵌入。特别强调直接将片段元数据与文本嵌入（“上下文片段”）对性能提升的重要性。", "conclusion": "研究结果表明，尽管强大的重排序对精度至关重要，但对性能提升最大的是直接将片段元数据嵌入到文本中。提出的最优化架构结合了LLM驱动的预检索优化和这些上下文嵌入，以实现更好的性能。同时，提出了一种自定义的元数据重排序器，作为一种经济高效的商业替代方案，突出了在最高性能与操作效率之间的实际权衡。这项研究为构建金融文件分析的鲁棒且元数据感知的RAG系统提供了一个蓝图。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24431", "html_url": "https://arxiv.org/abs/2510.24431", "title": "MiniOneRec: 开源的大规模生成推荐框架", "title_en": "MiniOneRec: An Open-Source Framework for Scaling Generative Recommendation", "authors": "Xiaoyu Kong,Leheng Sheng,Junfei Tan,Yuxin Chen,Jiancan Wu,An Zhang,Xiang Wang,Xiangnan He", "background": "近年来，大规模语言模型的成功激发了对推荐系统能否同样实现规模化效益的兴趣。传统的推荐系统靠巨大的嵌入表为主，这些系统在嵌入维度增长时会遇到瓶颈。相比之下，新兴的生成范式将嵌入替换为由自回归Transformer生成的紧凑的语义ID（SID）序列。然而，大多数工业部署仍保持私有化，留下了两个基本问题：（1）生成推荐是否在公共基准上表现出预期的扩展规律？（2）最小的后训练食谱是什么，能够实现竞争性表现？", "innovation": "我们提出了MiniOneRec，据我们所知，这是第一个完全开源的生成推荐框架，它提供了从SID构建、监督微调到推荐导向的强化学习的端到端工作流程。我们通过残差量化VAE生成SID，并在亚马逊评论数据集上对不同参数量（0.5B至7B）的Qwen后端进行训练。实验结果显示，随着模型规模的增加，训练和评估损失持续下降，证明了生成方法的参数效率。为了进一步提高性能，我们提出了一种轻量但有效的方法，包括全过程SID对齐和使用约束解码和混合奖励的强化学习。", "conclusion": "这些技术共同实现了排名准确性和候选多样性的重要改进。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24328", "html_url": "https://arxiv.org/abs/2510.24328", "title": "超越选择题——基于方言的阿拉伯文化QA开放式基准", "title_en": "Beyond MCQ: An Open-Ended Arabic Cultural QA Benchmark with Dialect Variants", "authors": "Hunzalah Hassan Bhatti,Firoj Alam", "background": "大型语言模型（LLMs）在回答日常问题方面越来越多地被使用，但在处理具有文化背景和方言特征的内容时，它们的表现因语言而异，存在不均衡。这项研究提出了一种全面的方法，用于将现代标准阿拉伯语（MSA）的选择题（MCQ）翻译成英语和几种阿拉伯方言，将其转化为开放式问题（OEQ），并针对选择题和开放式问题设置分别对多种零样本和微调的LLMs进行基准测试，同时生成链式思考（CoT）推理来提升模型的逐步推理能力。这种方法扩展了一个现有的数据集，使其在多个语言变体中平行对齐Q&A，并且这是迄今为止第一个此类数据集。研究通过开放和封闭模型进行了广泛的实验，结果显示LLMs在阿拉伯方言上的表现不佳，揭示了持续存在的文化背景和方言特定知识的差距；阿拉伯中心模型在选择题上表现良好但难以处理开放式问题；CoT可以在一定程度上提高判读的正确性，但不适用于基于n-克隆的指标。开发的数据集将公开发布，以支持进一步研究文化多样性和语言包容性评估方面的问题。", "innovation": "（1）提出了一种全面的方法，包括将MSA的MCQ翻译成英语和几种阿拉伯方言；（2）将MCQ转换为OEQ；（3）在MCQ和OEQ设置下对多种零样本和微调的LLMs进行基准测试；（4）生成CoT推理以提升模型的逐步推理能力；（5）扩展了一个现有的多语言变体对齐的Q&A数据集，使它成为第一个此类数据集，旨在增强文化及语言包容性评估的研究。", "conclusion": "（1）LLMs在阿拉伯方言上的表现不佳，这揭示了在文化背景和方言特定知识方面持续存在的知识差距；（2）虽然阿拉伯中心模型在选择题上表现良好，但在开放式问题上则面临挑战；（3）CoT能够提高判读正确性，但在基于n-克隆的指标上表现不一；（4）开发的数据集将公开发布，以促进进一步研究文化多样性和语言包容性评估方面的问题。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24450", "html_url": "https://arxiv.org/abs/2510.24450", "title": "绘制欧洲大型语言模型基准测试格局：新的分类法和一套最佳实践", "title_en": "Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices", "authors": "Špela Vintar,Taja Kuzman Pungeršek,Mojca Brglez,Nikola Ljubešić", "background": "随着新的大型语言模型（LLMs）不断进步，它们的能力和人工智能的总体能力都在增强，相应的基准测试也在不断更新。然而，对于非英语语言的LLM使用和评估方面，研究仍然相对较少。因此，本文旨在简要概述LLM基准测试的最新发展，并提出一种专为多语言或非英语应用场景设计的新分类法。此外，还提出了一套最佳实践和质量标准，以促进欧洲语言基准测试的协调发展。", "innovation": "提出了一个新的基准分类法，专为多语言或多语种使用场景设计，增强了评价方法对语言和文化的敏感性，从而改进了针对欧洲语言的基准测试的发展。", "conclusion": "本文详细说明了在多语言环境中进行LLM基准测试的新分类和最佳实践，强调了提高评估方法的语言和文化敏感性的重要性，以促进欧洲语言的基准测试发展。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24448", "html_url": "https://arxiv.org/abs/2510.24448", "title": "重新思考视觉智能：视频预训练的见解", "title_en": "Rethinking Visual Intelligence: Insights from Video Pretraining", "authors": "Pablo Acuaviva,Aram Davtyan,Mariam Hassan,Sebastian Stapf,Ahmad Rahimi,Alexandre Alahi,Paolo Favaro", "background": "大语言模型（LLMs）已经在语言领域展示出大规模预先训练可以使其在少量监督的情况下快速适应新的问题。然而，在视觉领域，模型包括LLMs仍然在组成理解、样本效率和通用问题解决方面存在困难。研究者们将视频扩散模型（VDMs）作为跨越这一差距的一种有希望的方向。预先在时空数据上进行训练使得这些模型具备了对结构和动态的强大归纳偏置，推测这些偏置可以支持广泛的适应性任务。", "innovation": "研究者设计了一个受控评估，在这个评估中，两者是预先训练过的LLM和VDM，它们都被配备了轻量级的适配器，并提供了自然模态的任务。在这个过程中，VDM在ARCs-AGI、ConceptARC、视觉游戏、路线规划和细胞自动机等基准测试中显示出了比语言对应物更高的数据效率。这些结果表明，视频预训练提供了支持向视觉基础模型发展的归纳偏置。", "conclusion": "我们的研究表明，视频预训练提供了支持向视觉基础模型发展的归纳偏置。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24321", "html_url": "https://arxiv.org/abs/2510.24321", "title": "使用CLIP和提示学习实现卫星和航空影像的少样本场景分类", "title_en": "Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning", "authors": "Ivica Dimitrovski,Vlatko Spasev,Ivan Kitanovski", "background": "遥感应用越来越依赖于深度学习进行场景分类。然而，性能受限于标注数据稀缺以及不同地理和传感器域的高标注成本。尽管CLIP等视觉-语言模型展示了通过大规模视觉-文本模态对齐学习可转移表示的潜力，但它们在遥感应用中的直接使用仍受限于领域差距和任务特定语义适应的需要。因此，本文系统探索提示学习作为一种轻量级高效适应策略，用于解决少样本遥感图像场景分类的关键挑战。", "innovation": "本文评估了多种提示学习方法，包括上下文优化、条件上下文优化、多模态提示学习、自调节约束提示等。这些方法反映了互补的设计理念：从静态上下文优化到增强泛化的条件提示，再到通过多模态提示进行视觉-语言联合适应，以及通过语义正则化的提示以进行稳定学习而不遗忘。通过在多个遥感基准数据集上的广泛实验，本文证明提示学习在少样本场景中优于两种标准基线方法，并且自调节约束提示能够实现最稳健的跨域性能。这项工作的创新之处在于提出了一种有效的方法来解决遥感领域的可扩展性和效率问题。", "conclusion": "我们的发现强调提示学习作为跨越卫星和航空影像领域差距的可扩展和高效解决方案的重要性，为该领域的未来研究奠定了坚实的基础。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24482", "html_url": "https://arxiv.org/abs/2510.24482", "title": "连续时间RL中的高效且可扩展的探索", "title_en": "Sample-efficient and Scalable Exploration in Continuous-Time RL", "authors": "Klemens Iten,Lenart Treven,Bhavya Sukhija,Florian Dörfler,Andreas Krause", "background": "通常，强化学习算法旨在处理离散时间动力系统，而实际控制系统的动力学往往是连续时间的。因此，该研究聚焦于连续时间强化学习问题，研究未知系统动力学的非线性常微分方程表示，并利用概率模型（如高斯过程和贝叶斯神经网络）构建具备不确定性意识的底层ODE模型。", "innovation": "提出了利用COMBRL算法，它贪婪地最大化外在奖励和模型的先验不确定性加权和，从而提供了一种可扩展且样本高效的连续时间模型导向RL方法。此外，在奖励驱动和无监督RL设置下提供了样本复杂性分析。", "conclusion": "COMBRL在标准强化学习和无监督强化学习设置中均表现出更好的可扩展性及样本效率，并在多个深度学习任务中优于先前方法和基准。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24345", "html_url": "https://arxiv.org/abs/2510.24345", "title": "长织：一种连接实际相关性和可验证性的长格式生成基准", "title_en": "LongWeave: A Long-Form Generation Benchmark Bridging Real-World Relevance and Verifiability", "authors": "Zikai Xiao,Fei Huang,Jianhong Tu,Jianhui Wei,Wen Ma,Yuxuan Zhou,Jian Wu,Bowen Yu,Zuozhu Liu,Junyang Lin", "background": "大型语言模型（LLMs）生成长、有信息量且真实的输出仍然是一项重大挑战。现有的长格式生成基准通常使用难以验证的度量标准来评估真实的查询，或者使用简化但忽视了实际复杂性的合成测试环境。本文介绍了一个名为LongWeave的新基准，它通过结合实际场景与可验证评估来平衡这两方面的问题。LongWeave采用Constraint-Verifier Evaluation（CoV-Eval）方法构建任务，首先定义可验证的目标，然后系统地生成相应的查询、文本材料和约束信息，以确保任务既实际又客观可评估，从而更严格地评估模型在满足复杂实际约束方面的能力。LongWeave支持输入/输出长度的可定制化调整，范围在7个不同的任务中达到最大64K/8K个标记。在23个LLM模型上的评估表明，即使是最先进的模型，在长格式生成中也会面临重大挑战，尤其是在实际复杂性和输出长度增加的情况下。", "innovation": "引入了LongWeave这一新基准，结合了实际场景评估与可验证评估，通过定义可验证目标和系统生成查询、文本材料和约束信息，确保了任务的现实性和客观性。可定制输入/输出长度的设计，以及在多个任务上的应用，突显了此创新性方法在评估LLM生成能力方面的优势。此外，评估结果展示了更多最先进的模型在面对长格式生成任务时所遇到的挑战，特别是在处理实际复杂性和增加的输出长度时。", "conclusion": "LongWeave通过结合实际场景与可验证性达到了对大型语言模型在长格式生成方面的一种更严格的评估。其创新方法确保了生成任务在真实性和客观性方面都能满足更高的标准，展示了模型在处理复杂实际问题时的能力。评估结果揭示了当前各类最先进的LLM模型在长格式生成任务中面临的显著挑战，突出了LongWeave在评价模型性能方面的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24476", "html_url": "https://arxiv.org/abs/2510.24476", "title": "在大规模语言模型（LLMs）中缓解幻觉：基于应用的RAG、推理和主体系统综述", "title_en": "Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems", "authors": "Yihan Li,Xiyuan Fu,Ghanshyam Verma,Paul Buitelaar,Mingming Liu", "background": "幻觉是制约大规模语言模型（LLMs）可靠部署的关键障碍，特别是在实际应用中。虽然检索增强生成（RAG）和推理增强已经成为了缓解幻觉最有效和最广泛采用的两种策略，但它们的协同潜力及其缓解幻觉的机制尚未系统性地研究。", "innovation": "本文提出了一种基于应用能力增强视角的分类法，区分基于知识和基于逻辑的幻觉，并系统地分析了RAG和推理如何缓解这些幻觉。此外，作者还提出了一种综合框架，该框架是通过实际应用、评估和基准测试来支持的。", "conclusion": "文章通过分析RAG、推理增强及其在主体系统中的集成如何缓解幻觉，提出了一种新的认知框架，并系统地研究了基于知识和基于逻辑的幻觉缓解机制。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24488", "html_url": "https://arxiv.org/abs/2510.24488", "title": "一种用于评估与人类相比LLMs中的隐式偏见的词语联想网络方法", "title_en": "A word association network methodology for evaluating implicit biases in LLMs compared to humans", "authors": "Katherine Abramski,Giulio Rossetti,Massimo Stella", "background": "随着大型语言模型（LLMs）在我们生活中的应用越来越多，它们固有的社会偏见仍然是一个紧迫的问题。检测和评估这些偏见具有挑战性，因为它们通常是隐式的而非明确的，所以开发评估方法以评估LLMs的隐式知识表示是必要的。", "innovation": "我们提出了一种新颖的词语联想网络方法，基于模拟LLM生成的词语联想网络中的语义启发效果来评估LLMs中的隐式偏见。基于提示的方法可以挖掘LLMs中隐含的关系结构，并提供定性和定量的偏见评估。本方法可以直接比较各种LLMs与人类，提供参考并为LLMs与人类认知的对齐提供了新的观点。", "conclusion": "我们的方法为系统、可扩展和可推广的框架提供了评估和比较多个LLMs和人类偏见的手段，促进了透明、责任感强的语言技术的发展。本研究揭示了LLMs和人类在性别、宗教、种族、性取向和政治派别等方面偏见的契合点和分歧，提供了使用LLMs可能风险的新视角。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24469", "html_url": "https://arxiv.org/abs/2510.24469", "title": "增强LLM个性化的一种迭代批判-完善框架", "title_en": "Iterative Critique-Refine Framework for Enhancing LLM Personalization", "authors": "Durga Prasad Maram,Dhruvin Gandhi,Zonghai Yao,Gayathri Akkinapalli,Franck Dernoncourt,Yu Wang,Ryan A. Rossi,Nesreen K. Ahmed", "background": "个性化文本生成不仅要求模型产生连贯的文字，还需与目标用户的声音、风格和主题焦点相一致。现有的基于检索的增强方法，如LaMP和PGraphRAG，在生成文本时会加入用户的和邻居的历史信息，但它们在生成文本后通常未能保持一致的语气、主题或风格。因此，研究者在此背景下提出了一个新的框架——PerFine，旨在通过迭代、基于档案的反馈来增强个性化程度。PerFine采用了一个教练模型（批判者）和一个生成器模型，两者均基于同一文件档案生成反馈和文本草案，迭代地改进这些草案。", "innovation": "PerFine提供了一个统一且无需训练的批判-完善框架，旨在通过迭代的、基于档案的反馈增强个性化。在每一轮迭代中，LLM生成器分别基于从中检索到的档案生成文稿草案，而批判性的LLM则基于同一档案提供结构化的反馈，包括语气、词汇、句子结构和主题方面的建议。生成器在继续改进过程中应用了一个创新的淘汰策略，保留了更强的文稿草案。研究还探讨了在推理阶段使用Best-of-N和主题提取策略以平衡质量和效率。在包括Yelp、Goodreads和Amazon的数据集上，PerFine在PostHoc GEval度量方面持续优于PGraphRAG，且在改进三次到五次之后就形成了稳定的改进，并且随着批评者的规模增加具有可扩展性。", "conclusion": "PerFine的结果表明，事后、档案意识的反馈为个性化LLM生成提供了一种强大的范式，该范式既无需训练又具有模型无关性。这一框架有助于提高模型个性化文本生成的质量和效率，同时也具备较好的可扩展性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24497", "html_url": "https://arxiv.org/abs/2510.24497", "title": "无失真差分波束形成器的在线神经融合方法以实现鲁棒性语音增强", "title_en": "Online neural fusion of distortionless differential beamformers for robust speech enhancement", "authors": "Yuanhang Qian,Kunlong Zhao,Jilu Jin,Xueqin Luo,Gongping Huang,Jingdong Chen,Jacob Benesty", "background": "固定波束形成器在实践中广泛应用，因其无需估计噪声统计且能提供相对稳定的表现。然而，单一波束形成器无法适应变化的声学条件，限制了其干扰抑制能力。为解决这个问题，已经引入了自适应凸组合（ACC）算法，通过将多个固定波束形成器的输出线性组合来增强鲁棒性。但ACC在高度非平稳场景，如快速移动的干扰情况下经常失效，因为其自适应更新无法可靠地跟踪快速变化。", "innovation": "提出了一种用于多个无失真差分波束形成器的帧在线神经融合框架。该方法通过神经网络估计组合权重，与传统ACC相比，该方法能更有效地适应动态声学环境，实现更强的干扰抑制效果同时保持无失真约束。", "conclusion": "该论文提出的方法克服了传统ACC在高度非平稳场景中的局限性，实现更加有效的干扰抑制，同时维持了无失真的特性，增强了声学环境下的鲁棒性语音增强能力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24498", "html_url": "https://arxiv.org/abs/2510.24498", "title": "设计和优化云原生同态加密工作流以支持隐私保护机器学习推理", "title_en": "Design and Optimization of Cloud Native Homomorphic Encryption Workflows for Privacy-Preserving ML Inference", "authors": "Tejaswini Bollikonda", "background": "随着机器学习模型通过云基础设施部署，推理过程中用户数据的保密性成为一个重要安全问题。同态加密（HE）作为一种加密技术，允许在密文上进行计算，从而在不泄露敏感输入的情况下生成预测，但将其集成到大规模的云原生管道中仍然受到高计算开销、编排复杂性和模型兼容性问题的限制。", "innovation": "该论文提出了一种系统性框架，旨在设计和优化支持隐私保护机器学习推理的云原生同态加密工作流。该架构集成了容器化的同态加密模块，并采用基于Kubernetes的编排，实现了在分布式环境中的弹性和并行加密计算。此外，通过使用密文打包、多项式模调整和操作符融合等优化策略，系统达到了加速推理和降低内存消耗的目的。", "conclusion": "实验结果表明，与传统的同态加密管道相比，所提出系统实现了最高3.2倍的推理加速和40%的内存利用率降低。这些发现展示了在零信任云环境中安全地部署机器学习即服务（MLaaS）系统的实际路径，保证数据的保密性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24495", "html_url": "https://arxiv.org/abs/2510.24495", "title": "扩散模型在无线接收机中的应用：从试点高效信道估计到AI原生6G接收机", "title_en": "Diffusion Models for Wireless Transceivers: From Pilot-Efficient Channel Estimation to AI-Native 6G Receivers", "authors": "Yuzhi Yang,Sen Yan,Weijie Zhou,Brahim Mefgouda,Ridong Li,Zhaoyang Zhang,Mérouane Debbah", "background": "随着人工智能（AI）技术的发展，利用AI技术来提高无线收发器的性能成为新兴的研究领域。在大规模正交频分复用（OFDM）系统中，基于AI的信道表征和估计成为研究的重点，因为这些方法传统方法解决得很好，已经成为收发器效率的瓶颈。通过将信道估计转化为生成型AI问题，扩散模型（DMs）能够有效处理粗糙的初始估计，并与传统的信号处理方法有很大的合作潜力。", "innovation": "基于DMs的OFDM系统收发器设计，具体包括：1）将信道估计问题转化为生成型AI问题；2）扩散模型能够有效处理粗糙的初始估计；3）扩散模型与传统信号处理方法相结合，具有巨大的合作潜力；4）提供了进一步适应DMs以提高无线接收器性能的概念性案例研究。", "conclusion": "基于DMs的方法为无线接收机的设计提供了新的思路，不仅提高了信道估计的精度和效率，还指出了未来研究的方向。同时，为实现AI原生6G接收机奠定了理论和技术基础。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24285", "html_url": "https://arxiv.org/abs/2510.24285", "title": "ViPER: 使视觉语言模型的视觉感知能力自我进化", "title_en": "ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model", "authors": "Juntian Zhang,Song Jin,Chuanqi Cheng,Yuhan Liu,Yankai Lin,Xun Zhang,Yufei Zhang,Fei Jiang,Guojun Yin,Wei Lin,Rui Yan", "background": "视觉语言模型（VLMs）在实际应用中面临着精细视觉感知能力有限的瓶颈。由于高质量数据的稀缺和现有方法的局限性，如监督微调（SFT）会牺牲通用能力，强化微调（RFT）则更注重文本推理而忽视视觉感知。", "innovation": "提出了一个新颖的两阶段任务，将视觉感知学习构建成一个从粗到细的渐进过程。基于此任务，开发了ViPER框架，这是一个自我启发的框架，通过自我批评和自我预测实现迭代进化。通过将基于图像级别的和实例级别的重建与两阶段的强化学习策略相协同，ViPER构建了一个闭环训练范式，其中内部合成的数据直接促进了感知能力的提升。这一方法应用于Qwen2.5-VL家族，生成了Qwen-Viper系列，在七个综合基准测试中，平均提高了1.7%，在精细感知方面提高了6.0%，在各种视觉语言场景中都表现出优越性能和可扩展性。此外，ViPER还提供了生成与理解之间相互关系的实证证据，推动了更自主和强大的VLMs的开发。", "conclusion": "Qwen-Viper系列在不同视觉语言场景中表现出优越性能和可扩展性，证实了视觉感知能力的自我提升，并提供了生成与理解之间相互关系的实证证据，推动了更自主和强大的VLMs的开发。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24503", "html_url": "https://arxiv.org/abs/2510.24503", "title": "局部性能 vs. 异分布泛化：在异质数据环境中个性化 Federated Learning 的实证分析", "title_en": "Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments", "authors": "Mortesa Hussaini,Jan Theiß,Anthony Stein", "background": "在 Federated Learning 的环境下，由于数据环境的异质性，本地模型倾向于在其本地数据分布中收敛到局部最优解，而不是整体数据分布的最优解。这种差异造成了模型更新偏差，即客户端漂移，而这通常使用 FedAvg 等聚合方法无法校正。个性化 Federated Learning 方法通过专注于客户端自身数据分布上的平均本地性能来解决这一挑战，但它们在处理异分布样本泛化能力上的不足尚未充分考量。本文对不同的 Federated Learning 方法进行全面评估，涉及本地性能和泛化能力，以深入了解相关度量指标。通过引入一个改进的 FedAvg 方法，即 Federated Learning with Individualized Updates (FLIU)，来增强模型的个体化性能并开展详细实证研究，使用 MNIST 和 CIFAR-10 数据集进行评估，包括各种分布条件下的表现，以检验算法在复杂数据异质性环境下的性能。", "innovation": "本文提出了一种改进的 FedAvg 方法，称为 Federated Learning with Individualized Updates (FLIU)，通过添加一个简单的个性化步骤，增强算法的个体化性能。本文还通过引入新的测试环境，使用 Dirichlet 分布特别开发的新型测试环境，以复杂数据异质性来考验算法。", "conclusion": "本文通过对 Federated Learning 方法全面评估，展示了不同方法在本地性能和异分布泛化中的表现，并提出了增强 FedAvg 方法的新方法 FLIU，使其能够更好地应对复杂数据异质性环境中的问题。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24534", "html_url": "https://arxiv.org/abs/2510.24534", "title": "使用后量子密码学的量子免疫网络", "title_en": "Quantum-Resistant Networks Using Post-Quantum Cryptography", "authors": "Xin Jin,Nitish Kumar Chandra,Mohadeseh Azari,Kaushik P. Seshadreesan,Junyu Liu", "background": "量子网络依赖于量子和经典通道协同运作。当前架构通过量子通道分配纠缠和密钥交换，但常常假设经典通信足够安全。然而，传统的加密技术保护的经典通信在实践中仍可能受到量子对手攻击，因为大规模量子计算机可能破解广泛使用的公钥方案，降低对称密钥加密的有效安全性。", "innovation": "提出了一种量子免疫网络架构，该架构通过使用后量子加密技术保护经典通信的同时支持基于纠缠的量子通信。此外，该框架还包括对量子和经典层的持续监控以及跨异构基础设施的编排，以确保端到端的安全性。", "conclusion": "上述机制为构建可扩展、稳健和对经典和量子时代威胁都可靠的量子网络提供了途径。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24561", "html_url": "https://arxiv.org/abs/2510.24561", "title": "LoRA-DA：通过渐进分析实现数据驱动的低秩适应初始化", "title_en": "LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via Asymptotic Analysis", "authors": "Qingyue Zhang,Chang Chu,Tianren Peng,Qi Li,Xiangyang Luo,Zhihao Jiang,Shao-Lun Huang", "background": "随着大语言模型（LLMs）的广泛应用，低秩适应（LoRA）已成为参数精调（PEFT）的一种主流方法，其初始化方法也因此越来越受到关注。但现有方法存在明显局限性：许多方法未利用目标域数据，梯度方法仅浅层地利用数据，依赖单一梯度分解，这在基础的一步精细调优模型表现不佳的情况下，尚不令人满意。此外，这些方法要么缺乏坚实的理论基础，要么依赖严格的均质假设。", "innovation": "本文构建了一种基于渐进分析的数据感知LoRA初始化理论框架。从一个最小化精细调优模型与目标模型参数差异的通用优化目标出发，推导出包含偏差项和方差项的优化问题，偏差项通过费舍尔梯度表达式来保持各向异性，方差项则通过费舍尔信息来考虑采样随机性带来的不确定性。通过求解这一问题，我们得到LoRA的最佳初始化策略。在此基础上，我们开发了一种高效算法LoRA-DA，从少量目标域样本中估计优化问题中的各项，并获得最优的LoRA初始化。实验结果表明，LoRA-DA在多个基准测试中都能提高最终的准确率，并显示了更快、更稳定的收敛性、均衡的鲁棒性和较小的初始化开销。", "conclusion": "通过LoRA-DA这一数据驱动的初始化方法，我们在多个基准测试中展示了显著的性能提升。该方法在收敛速度、稳定性和初始化成本方面表现出优势，其源代码将在发表后公开。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24574", "html_url": "https://arxiv.org/abs/2510.24574", "title": "DistDF: 时间序列预测需要联合分布Wasserstein对齐", "title_en": "DistDF: Time-Series Forecasting Needs Joint-Distribution Wasserstein Alignment", "authors": "Hao Wang,Licheng Pan,Yuan Lu,Zhixuan Chu,Xiaoxi Li,Shuting He,Zhichao Chen,Haoxuan Li,Qingsong Wen,Zhouchen Lin", "background": "时间序列预测模型的训练需要使模型预测的条件分布与标签序列的条件分布保持一致。传统直接预测（DF）方法通常通过最小化标签序列的条件负对数似然来实现，这通常通过均方误差估计。然而，这种方法在存在标签序列自相关性的情况下会表现出偏见。背景提出现有方法的问题在于传统方法对条件偏态的估计容易出错，特别是在时间序列有限的观测数据下。", "innovation": "本文提出的DistDF方法通过交替最小化条件预测和标签分布之间的不一致性来实现对齐。由于条件不一致性难以从时间序列有限观察数据中估计，作者引入了一个新的时间序列预测中联合分布Wasserstein不一致性，该不一致性可以证明地上限拟合研究中的条件不一致性。该方法允许从经验样本中进行可处理且可微的估计，并能无缝与基于梯度的训练结合。该方法在广泛实验中证明能提升多种预测模型的性能，并达到了最先进的预测性能水平。", "conclusion": "广泛的实验表明，DistDF提高了各类预测模型的性能并实现了最先进的时间序列预测性能。代码可从此处获取：this https URL"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24519", "html_url": "https://arxiv.org/abs/2510.24519", "title": "使用时域梅尔-尺度小波系数的音频信号处理", "title_en": "Audio Signal Processing Using Time Domain Mel-Frequency Wavelet Coefficient", "authors": "Rinku Sebastian,Simon O'Keefe,Martin Trefzer", "background": "提取音频信号特征是语音信号处理中最关键的过程之一。梅尔频率倒谱系数（MFCC）是使用最广泛的特征之一，因为在这种特征中的滤波与人耳中的滤波相似。然而，MFCC仅提供频率信息，而未能提供某个频率什么时候出现的时间信息。小波变换提供信号的时间和频率信息，是分析非稳态信号如语音的良好工具。但因具有均匀的频率缩放，常规的小波变换可能在分析语音信号方面不够有效，特别是在低频段的频率分辨率较差，并且可能与人类听觉感知不太吻合。因此，有必要开发结合MFCC和小波变换优点的新特征。已有许多研究尝试将这两个特征结合在一起。目前的基于小波变换的梅尔尺度特征提取方法在使用小波变换叠加在梅尔尺度滤波上时会增加额外的计算步骤，因此带来更大的计算负担和复杂性。因此，提出了结合小波变换概念的时域梅尔频率小波系数（TMFWC）方法，从而减少了时间和频率转换以及小波提取的复杂性和计算量。该方法与回声池计算相结合，显著提高了音频信号处理的效率", "innovation": "提出了一种新的时域梅尔频率小波系数（TMFWC），该方法结合了小波变换和梅尔频率倒谱系数的优点，减少了计算负担和复杂性。将TMFWC与回声池计算相结合，提高了音频信号处理的效率", "conclusion": "结合TMFWC和回声池计算的方法显著提高了音频信号处理的效率。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24643", "html_url": "https://arxiv.org/abs/2510.24643", "title": "稳健性带来的成本：ReLu神经网络中稳健记忆参数复杂性的更紧边界", "title_en": "The Cost of Robustness: Tighter Bounds on Parameter Complexity for Robust Memorization in ReLU Nets", "authors": "Yujun Kim,Chaewon Moon,Chulhee Yun", "background": "本文研究了ReLu网络在拥有 ε-分离的异标签点之间进行鲁棒插值所需的参数复杂性，同时确保每份训练样本周围的 μ-球内部预测保持一致。这也是对鲁棒性比 ρ = μ/ε 的鲁棒记忆所需参数数量的研究。研究范围覆盖了 ρ ∈ (0,1) 的整个区间，以获得现有结果更紧致的上界和下界。", "innovation": "本文提供了整个鲁棒性比 ρ 的区间（0,1）上的细微划分分析，并且得到了相较于先前研究更紧致的上界和下界。研究发现，当鲁棒性比 ρ 较小时，稳健记忆所需的参数复杂性与非稳健记忆相同，但当鲁棒性比 ρ 增大时，参数复杂性会随之增加。", "conclusion": "本文研究了鲁棒性带来的参数复杂性，并提供了比现有研究更紧致的上界和下界。当 ρ 较小时，参数复杂性与非鲁棒记忆相同，但随着 ρ 的增加，参数复杂性增长。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24668", "html_url": "https://arxiv.org/abs/2510.24668", "title": "InteractComp：使用模糊查询评估搜索代理", "title_en": "InteractComp: Evaluating Search Agents With Ambiguous Queries", "authors": "Mingyi Deng,Lijun Huang,Yani Fan,Jiayi Zhang,Fashen Ren,Jinyi Bai,Fuzhen Yang,Dayi Miao,Zhaoyang Yu,Yifan Wu,Yanfei Zhang,Fengwei Teng,Yingjia Wan,Song Hu,Yude Li,Xin Jin,Conghao Hu,Haoyu Li,Qirui Fu,Tai Zhong,Xinyu Wang,Xiangru Tang,Nan Tang,Chenglin Wu,Yuyu Luo", "background": "语言代理已经在网络搜索和信息检索中展示了显著的潜力。然而，这些搜索代理假设用户查询是完整的且明确的，但实际情况是用户在开始时持有的查询往往是不完整且需要通过交互来澄清的。现有的一些搜索代理在搜索过程中缺乏互动机制，且当前的基准测试无法评估这一能力。为此，作者提出了InteractComp基准测试，旨在评估搜索代理识别查询模糊性并在此过程中积极互动解决模糊性的能力。", "innovation": "作者通过目标分散的方法构建了210个专家整理的问题，并覆盖了9个领域，以此为基础提出了InteractComp基准测试，用于评估搜索代理在处理模糊查询时识别查询模糊性和通过互动澄清模糊性的能力。评估结果显示，即使在给予完整背景信息的情况下，最先进的模型也只能达到13.73%的准确率，显示出系统性过度自信而非推理缺陷的现象。强迫互动可以显著提高模型的表现，显示出当前策略未充分利用的潜在能力。作者还发现，互动能力在过去15个月内停滞不前，而搜索性能却提高了七倍，揭示了一种关键的盲点。这停滞的互动能力和搜索任务中的即时反馈使InteractComp成为一个有价值的资源，用于评估和培训搜索代理的互动能力。", "conclusion": "InteractComp基准测试显示了当前搜索代理在处理模糊查询和进行互动以澄清模糊性方面存在明显的局限性。这种评估和训练工具对于提高搜索代理的互动能力至关重要。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24639", "html_url": "https://arxiv.org/abs/2510.24639", "title": "从时间序列结构学习中的因果排序", "title_en": "Causal Ordering for Structure Learning From Time Series", "authors": "Pedro P. Sanchez,Damian Machlanski,Steven McDonagh,Sotirios A. Tsaftaris", "background": "从时间序列数据中预测因果结构在生理学、脑连接性、气候动态和经济社会行为中理解复杂现象至关重要。但是，在时间序列中发现因果关系受到识别真实因果关系的组合复杂性限制，尤其是变量和时间点数量增加时。传统的时间序列因果发现方法通常通过顺序方法简化任务，但这些方法固有的限制了模型的表现能力。因此，针对这一问题，本文提出了一种新的方法Distributed Ordering for Temporal Structure (DOTS)，使用基于弥散的因果发现方法处理时间数据。", "innovation": "作者提出了一种新型的时间序列因果发现方法Distributed Ordering for Temporal Structure (DOTS)，该方法通过集成多个有效的因果顺序，而不是传统的单一顺序，有效恢复了潜在的有向无环图的传递闭包，减少了单顺序方法固有的假象艺术。此外，通过利用站稳性和加性噪声模型，并使用弥散过程来实现有效的Hessian估计，使方法具有高效性和可扩展性。实验证明该方法优于现有的一些基线方法，特别是在合成数据和现实世界数据集上提供了可扩展且稳定的因果发现解决方案，特别是在某些基准测试上取得了明显提升。例如，在合成基准测试中，窗口图F1分数从0.63提高到0.81。相比之下，尽管基线方法在单个数据集上表现最好，但在现实世界基准测试CausalTime上，DOTS不仅平均汇总图F1得分最高，而且相对于图优化方法的运行时间减少了一半。", "conclusion": "本文通过提出Distributed Ordering for Temporal Structure (DOTS)，解决时间序列因果发现中单一顺序方法固有的表现限制，通过集成多种有效的因果顺序，有效解决了该问题。DOTS在合成和现实世界数据集上的实验表明，该方法在因果发现方面具有较高的准确性和可扩展性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24637", "html_url": "https://arxiv.org/abs/2510.24637", "title": "一次时间步完成任务：增强多级突触神经网络的稀疏性和能效", "title_en": "All in one timestep: Enhancing Sparsity and Energy efficiency in Multi-level Spiking Neural Networks", "authors": "Andrea Castagnetti,Alain Pegatoquet,Benoît Miramond", "background": "突触神经网络（SNNs）因借鉴生物启发模型的优势，近年来吸引了越来越多的关注。SNNs 的事件驱动通信机制允许在专用神经形态硬件上进行稀疏且理论上低功耗的操作。然而，瞬时突触的二进制性质也会导致显著的信息丢失，从而降低准确性。为解决这一问题，本文提出了一种多级突触神经元模型，能够在保持低量化误差和最小推理延迟的同时，接近全精度人工神经网络（ANNs）的性能。研究表明，多级突触神经元提供了更好的信息压缩，允许在不牺牲性能的情况下减少延迟。", "innovation": "1. 提出了一种多级突触神经元模型，能够在保持低量化误差和最小推理延迟的同时，接近全精度人工神经网络的性能。\n2. 多级SNNs在图像分类场景中的能效降低2到3倍，具体取决于量化间隔数量。\n3. 在神经形态数据上，该方法能够大幅减少推理延迟至1个时间步，对应于10倍的压缩比，超出先前发表的结果。\n4. 引入了新的稀疏残差架构Sparse-ResNet，通过详细分析残差连接中的突触传播，揭示了突触雪崩效应，并通过该架构提供最优的图像分类准确性，在减少网络活动超过20%的情况下，依然保持与之前spiking ResNets相当的性能水平。", "conclusion": "多级SNNs和新型Sparse-ResNet架构能够在保持或提升模型性能的情况下，大幅减少延迟和能效消耗，表明SNNs在实际应用中的潜力。这一研究为SNNs的进一步优化和实际部署提供了新的视角。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24674", "html_url": "https://arxiv.org/abs/2510.24674", "title": "使用混合选项安全学习驾驶", "title_en": "Learning to Drive Safely with Hybrid Options", "authors": "Bram De Cooman,Johan Suykens", "background": "许多深度强化学习方法已被应用于自动驾驶，但其中只有少数使用了选项（或技能）框架。这一框架在层级控制和自动驾驶任务上显示出天然的优势，因此本文尝试将该框架应用于高速公路自动驾驶任务中。通过为纵向和横向操作定义特定选项并嵌入安全性和舒适性约束，本文尝试将先前的领域知识引入学习过程，使模型能更容易地约束学习到的驾驶行为。", "innovation": "提出了一系列层级控制的选项框架设置，并基于当前最先进强化学习技术提出了实用算法。通过单独为纵向和横向控制选择动作，引入的混合选项下的策略获得了与人类驾驶员相当的表达能力和灵活性，同时比传统的连续动作策略更容易理解。所有测试方法中，这些混合选项下的灵活策略在各种交通条件下的表现最佳，超越了基线策略。", "conclusion": "通过使用选项框架，本文展示了如何更好地将现有知识整合到自动驾驶的学习过程中，并通过混合选项框架提出了能够灵活适应不同交通条件的有效策略。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24671", "html_url": "https://arxiv.org/abs/2510.24671", "title": "基于增强条件变分自编码器的环岛多Agent场景生成", "title_en": "Multi-Agent Scenario Generation in Roundabouts with a Transformer-enhanced Conditional Variational Autoencoder", "authors": "Li Li,Tobias Brinkmann,Till Temmen,Markus Eisenbarth,Jakob Andert", "background": "随着智能驾驶功能越来越多地集成到量产车辆中，确保其功能性和稳健性带来了更大的挑战。与传统的道路测试相比，基于场景的虚拟测试在时间和成本效率、再现性和边缘情况探索方面具有显著优势。", "innovation": "提出了一种增强条件变分自编码器（CVAE-T）模型，用于生成环岛中的多Agent交通场景。这些场景具有高度的车辆动态和复杂布局，目前在研究中相对未被充分探索。该模型能够准确重建原始场景并生成真实、多样的合成场景。此外，还使用了两个关键性能指标（KPIs）来评估生成场景中的交互行为，分析潜在空间揭示了部分解缠，多个潜在维度对场景属性（如车辆入场时间、出场时间和速度轮廓）表现出独特的和可解释的影响。", "conclusion": "研究表明，该模型能够为涉及多Agent交互的智能驾驶功能验证生成场景，同时也可以增强其开发和迭代改进的数据。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24619", "html_url": "https://arxiv.org/abs/2510.24619", "title": "使用前缀适应实现零样本跨语言转移", "title_en": "Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation", "authors": "Snegha A(1),Sayambhu Sen(2),Piyush Singh Pasi(2),Abhishek Singhania(2),Preethi Jyothi(1) ((1) Indian Institute of Technology Bombay, (2) Amazon Alexa)", "background": "新大语言模型（LLMs）如Llama和Mistral的发布使得零样本跨语言转移变得越来越可行，得益于它们的多语言预训练和强大的泛化能力。然而，将这些仅解码器模型适应到新任务仍然具有挑战性，尤其是在多语言环境下的特定任务上。尽管参数高效微调（PeFT）技术如Low-Rank Adaptation (LoRA) 广泛使用，但基于前缀的技术如软提示调优、前缀调优和Llama Adapter在零样本转移中的研究相对较少，尤其是在解码器仅模型中。在本研究中，我们对三种基于前缀的方法在零样本跨语言转移中的表现进行了全面研究，任务是从英语到超过35种高度和低资源语言。我们的研究表明，这些前缀方法在贝雷贝莱基准测试上比基于LoRA的基线高6%。Llama 3.1 8B在使用1.23M学习参数时，表现出一致的改进。", "innovation": "本研究对基于前缀的方法进行了全面研究，重点探讨了从英语到35多种高资源和低资源语言的零样本跨语言转移。研究使用Llama 3.1 8B和Mistral v0.3 7B进行实验，发现了前缀调优方法在模型大小从1B到24B的 scales 下表现优于LoRA基线方法，即使仅使用1.23M学习参数，前缀调优也能达到一致的改进，展示了基于前缀技术作为一种有效且可扩展的替代LoRA的方法，特别是在多语言低资源设置中有潜力。", "conclusion": "研究表明，前缀方法在多种基准测上表现良好，甚至在仅使用部分参数的情况下也表现出色，这表明前缀调优技术在多语言应用中的潜力，并提出这是一种有效的和可扩展的替代LoRA的方法。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24677", "html_url": "https://arxiv.org/abs/2510.24677", "title": "通过神经元消融剖析医学LLM中的角色认知", "title_en": "Dissecting Role Cognition in Medical LLMs via Neuronal Ablation", "authors": "Xun Liang,Huayi Lai,Hanyu Wang,Wentao Zhang,Linfeng Zhang,Yanfang Chen,Feiyu Xiong,Zhiyu Li", "background": "大型语言模型（LLMs）在医疗决策支持系统中的应用日益增多，特别是在医学问答和模拟扮演中。使用提示引导的模拟扮演（PBRP）方法，可以指示模型扮演不同的临床角色（如医学生、住院医师和主治医生），以模拟各种专业行为。然而，这些角色提示对模型推理能力的影响仍然不清楚。", "innovation": "本研究引入了一种名为RP-Neuron-Activated Evaluation Framework (RPNA)的框架，用于评估角色提示是否在LLMs中引发特定的、角色化的认知过程，或仅仅是改变了语言风格。通过使用神经元消融和表示分析技术测试该框架，并在三个医学问答数据集上进行评估，结果显示，角色提示并未显著提高LLMs的医学推理能力，而主要影响了表面的语言特征。这表明，当前的PBRP方法未能再现现实生活中的医疗实践中存在的认知复杂性。", "conclusion": "尽管表面的风格变化，LLMs在不同角色中的核心决策机制保持一致，这表明目前的PBRP方法无法模拟真实世界医学实践所涉及的真正认知过程。这强调了需要模型能够模拟真实的认知过程而非仅仅语言模型的必要性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24694", "html_url": "https://arxiv.org/abs/2510.24694", "title": "重新利用合成数据进行精细粒度的搜索代理监督", "title_en": "Repurposing Synthetic Data for Fine-grained Search Agent Supervision", "authors": "Yida Zhao,Kuan Li,Xixi Wu,Liwen Zhang,Dingchu Zhang,Baixuan Li,Maojia Song,Zhuo Chen,Chenxi Wang,Xinyu Wang,Kewei Tu,Pengjun Xie,Jingren Zhou,Yong Jiang", "background": "基于LLM的搜索代理越来越多地被训练在以实体为中心的合成数据上以解决复杂且知识密集型的任务。然而，目前常用的训练方法，如Group Relative Policy Optimization (GRPO)，忽略了这些丰富的实体信息，而是依靠稀疏的结果导向奖励。这种做法使得代理难以区分那些有正确推理但最终回答错误的“接近正确”的样本和完全错误的答案，从而丢失了重要的学习信号。", "innovation": "我们通过利用训练过程中被丢弃的实体信息来解决这个问题。实证分析表明，搜索代理在推理过程中识别出的正确实体的数量与最终答案的准确性之间存在强烈的正相关关系。基于这一发现，我们提出了Entity-aware Group Relative Policy Optimization (E-GRPO)，一种新的框架，它定义了一个密集的实体感知奖励函数。E-GRPO为不完全正确的样本分配部分奖励，该奖励与它们的实体匹配率成比例，从而使模型能够有效地从这些‘接近正确’的样本中学习。实验结果表明，E-GRPO在多样化的问答和深度研究基准上不仅能一致且显著地优于GRPO基准，还能引导更高效、消耗工具调用更少的推理策略，从而实现更有效且样本效率更高的搜索代理对齐方法。", "conclusion": "E-GRPO不仅实现了更高的准确性，还诱导了更高效的推理策略，减少了工具调用，显示出更有效且样本效率更高的方法来对齐搜索代理。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24698", "html_url": "https://arxiv.org/abs/2510.24698", "title": "ParallelMuse: 自主并行思维用于深度信息检索", "title_en": "ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking", "authors": "Baixuan Li,Dingchu Zhang,Jialong Wu,Wenbiao Yin,Zhengwei Tao,Yida Zhao,Liwen Zhang,Haiyang Shen,Runnan Fang,Pengjun Xie,Jingren Zhou,Yong Jiang", "background": "并行思维能够扩展探索的广度，与信息寻求(IS)代理的深度探索互补，从而增强问题解决能力。然而，传统的并行思维在具体场景下面临两个主要挑战：重复从头开始展开导致的效率低下，以及在答案生成过程中整合长时推理轨迹的困难，因为有限的上下文容量无法充分考虑推理过程。", "innovation": "我们提出了ParallelMuse，这是一种为深度IS代理设计的两阶段框架。第一阶段，功能指定的部分展开，将生成的序列分割成功能区域，并使用不确定性引导的方法进行路径重用和分支，以提高探索效率。第二阶段，压缩推理聚合，利用推理冗余来无损压缩与答案推导相关的信息，并综合形成一个连贯的最终答案。通过跨多个开源代理和基准的实验，ParallelMuse在性能上实现了最多62%的提升，同时减少了10-30%的探索性标记的消耗。", "conclusion": "ParallelMuse通过两阶段框架有效地解决了传统并行思维中存在的效率和整合长时推理轨迹的问题，显著提高了深度信息检索代理的问题解决能力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24699", "html_url": "https://arxiv.org/abs/2510.24699", "title": "AgentFold: 长期任务网络代理的主动上下文管理", "title_en": "AgentFold: Long-Horizon Web Agents with Proactive Context Management", "authors": "Rui Ye,Zhongwang Zhang,Kuan Li,Huifeng Yin,Zhengwei Tao,Yida Zhao,Liangcai Su,Liwen Zhang,Zile Qiao,Xinyu Wang,Pengjun Xie,Fei Huang,Siheng Chen,Jingren Zhou,Yong Jiang", "background": "LLM（大型语言模型）驱动的网络代理在信息检索方面极具潜力，但它们在长期任务中的有效性受到了上下文管理的基本权衡的阻碍。现有的ReAct基础代理因累积大量嘈杂的、原始的历史记录而陷入上下文饱和问题，而固定每步总结完整历史记录的方法则可能因为不可逆地丢失关键细节而受限。", "innovation": "为了解决这些问题，论文提出了AgentFold这一新颖的代理范式，它以主动上下文管理为核心，灵感来源于人类认知过程中回顾性整合的过程。AgentFold将它的上下文视为一个动态的认知工作区，可以主动地进行构造而不是被动地记录日志。在每一步中，它学习执行一个‘折叠’操作，该操作可以多尺度管理其历史轨迹：既可以进行精炼的概括以保留关键的细粒度细节，也可以进行深层的整合以抽象掉整个多步子任务。", "conclusion": "在 prominent benchmarks 上的结果令人瞩目：使用简单的监督微调（无需持续预训练或 RL），论文的 AgentFold-30B-A3B 剂获得 36.2% 在 BrowseComp 和 47.3% 在 BrowseComp-ZH。值得注意的是，这一性能不仅超越或达到了远大于其规模的开源模型，如 DeepSeek-V3.1-671B-A37B，还超过了 OpenAI 的 o4-mini 等领先的企业专用代理。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24706", "html_url": "https://arxiv.org/abs/2510.24706", "title": "ComboBench：LLMs可以操纵物理设备来玩虚拟现实游戏吗？", "title_en": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality Games?", "authors": "Shuqing Li,Jiayi Yan,Chenyu Niu,Jen-tse Huang,Yun Peng,Wenxuan Wang,Yepang Liu,Michael R. Lyu", "background": "虚拟现实（VR）游戏要求玩家将高层次的语义动作转化为利用控制器和头戴式显示器（HMD）的精确设备操作。人类基于常识和身体体验能够自然而准确地完成这一转换，但大型语言模型（LLMs）能否有效复制这一能力尚待探索。 ComboBench 基准测试评估了七种LLMs（包括GPT-3.5、GPT-4、GPT-4o、Gemini-1.5-Pro、LLaMA-3-8B、Mixtral-8x7B和GLM-4-Flash）在262个场景中的语义动作转化为VR设备操作序列的能力。", "innovation": "研究引入了ComboBench基准测试，首次评估了LLMs在将语义动作转化为VR设备操作序列方面的能力。通过对比LMS模型与注释的正确答案和人类操作，发现虽然部分模型如Gemini-1.5-Pro展现了强大的任务分解能力，但在程序性推理和空间理解方面仍逊色于人类表现，且在不同的游戏中表现各异，显示了对交互复杂性的敏感性。", "conclusion": "少量示例极大地提高了模型的表现，证明了有针对性地增强LLMs处理VR交互能力的潜力。所有测试材料已公开。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24701", "html_url": "https://arxiv.org/abs/2510.24701", "title": "Tongyi DeepResearch技术报告", "title_en": "Tongyi DeepResearch Technical Report", "authors": "Tongyi DeepResearch Team:Baixuan Li,Bo Zhang,Dingchu Zhang,Fei Huang,Guangyu Li,Guoxin Chen,Huifeng Yin,Jialong Wu,Jingren Zhou,Kuan Li,Liangcai Su,Litu Ou,Liwen Zhang,Pengjun Xie,Rui Ye,Wenbiao Yin,Xinmiao Yu,Xinyu Wang,Xixi Wu,Xuanzhong Chen,Yida Zhao,Zhen Zhang,Zhengwei Tao,Zhongwang Zhang,Zile Qiao,Chenxi Wang,Donglei Yu,Gang Fu,Haiyang Shen,Jiayin Yang,Jun Lin,Junkai Zhang,Kui Zeng,Li Yang,Hailong Yin,Maojia Song,Ming Yan,Peng Xia,Qian Xiao,Rui Min,Ruixue Ding,Runnan Fang,Shaowei Chen,Shen Huang,Shihang Wang,Shihao Cai,Weizhou Shen,Xiaobin Wang,Xin Guan,Xinyu Geng,Yingcheng Shi,Yuning Wu,Zhuo Chen,Zijian Li,Yong Jiang", "background": "近年来，大语言模型在多个领域的应用逐渐增多。为应对长周期、深入的信息搜索研究任务，需要具备更强自主性和推理能力的模型。本文介绍了一种名为Tongyi DeepResearch的代理型大型语言模型，旨在通过整合代理型中期训练和代理型后期训练，实现广泛复杂的推理和信息收集功能，以提升自主研究机构的能力，应对这些研究任务。", "innovation": "Tongyi DeepResearch采用了端到端的训练框架，结合代理型中期训练和代理型后期训练，设计了一整套自动化的数据合成管道，不依赖于昂贵的人工标注，所有训练阶段都可以自动化实现。每个训练阶段都构建了定制化的环境，保证了稳定的、一致的交互。模型总参数为305亿，平均每词激活3.3亿参数，在多种代理型深度研究基准测试中表现出色，包括人类最后一考、BrowseComp、BrowseComp-ZH、WebWalkerQA、xbench-DeepSearch、FRAMES和xbench-DeepSearch-2510，并且开源了模型、框架和完整解决方案，以促进社区的发展和研究。", "conclusion": "Tongyi DeepResearch在多个代理型深度研究基准测试中均实现了标准设置下的最佳性能，展示了其在长周期、深入信息搜索任务中的强大能力。随着全面开源其模型、框架和解决方案，该模型有望在更大的社区中得到广泛应用，并且在未来进一步开发和提升其性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24700", "html_url": "https://arxiv.org/abs/2510.24700", "title": "Greedy Sampling Is Provably Efficient for RLHF", "title_en": "Greedy Sampling Is Provably Efficient for RLHF", "authors": "Di Wu,Chengshuai Shi,Jing Yang,Cong Shen", "background": "强化学习从人类反馈（RLHF）已成为对大规模语言模型进行后训练的重要技术。尽管在实际应用中效果显著，但对RLHF的理论理解仍然有限，因为它在仅使用偏好反馈学习KL正则化的目标时，相较于传统的强化学习（RL）提出了额外的挑战。现有工作的主要成果是在基于奖励的Bradley-Terry（BT）偏好模型下通过乐观或悲观策略进行了研究和扩展。", "innovation": "本文重点关注一般偏好模型（其实践相关性已得到观察），并获得了迄今为止最佳的性能保证，表现出显著的改进。与其他工作相比，这些结果是从直接使用经验估计（即贪婪采样）得到的，而不是通过构建乐观或悲观估计。这种见解深刻地源于KL正则化目标下最优策略类的唯一结构特性，并进一步将其特化为BT模型，突显了贪婪采样在RLHF中的非凡充分性。", "conclusion": "总之，本文获得了一种证明贪婪采样在RLHF中是有效的方法，并且通过直接使用经验估计而无需构建乐观或悲观估计，为KL正则化目标下的最优策略类提供了深刻的结构特性解释。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24709", "html_url": "https://arxiv.org/abs/2510.24709", "title": "大型预训练视觉变换器中对象绑定能否自然涌现？", "title_en": "Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?", "authors": "Yihao Li,Saeed Salehi,Lyle Ungar,Konrad P. Kording", "background": "对象绑定是人类认知的核心，它使得大脑能够将代表物体的各种特征整合为一个统一的整体。这种能力将低级感知特征分组为高级的对象表示，并在记忆中高效且组合地存储这些对象，支持人类对个体对象实例的推理。尽管先前的工作常常通过显式地使用以对象为中心的注意力机制（例如槽注意力）来探究这一能力带来的好处，但不清楚这种能力是否会自然地在预训练视觉变换器（ViTs）中出现。直觉上来说，这应该是有用的：识别属于同一物体的补丁应当有助于下游预测，从而引导注意力。", "innovation": "该研究假设ViTs表示两种补丁是否属于同一个对象，这一特征它称为‘IsSameObject’。通过相似性探针从未经过训练的ViT层补丁嵌入中解码IsSameObject，准确率超过90%。IsSameObject在自我监督的ViTs（DINO、MAE、CLIP）中可靠地出现，但在基于ImageNet监督的模型中较弱，表明绑定不是一种简单的架构性特征，而是在特定预训练目标下获得的能力。研究还发现IsSameObject在对象特征之上编码在低维子空间中，并且这种信号积极地引导注意力。从模型激活中消除IsSameObject会降低下游性能并且与学习目标相悖，表明自然浮现的对象绑定自然地服务于预训练目标。", "conclusion": "研究挑战了ViTs缺乏对象绑定的观点，指出了在连接主义系统中如何自然地产生表示‘哪些部分属于一起’的符号知识。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24702", "html_url": "https://arxiv.org/abs/2510.24702", "title": "代理数据协议：统一多样化高效微调大型语言模型代理的集合", "title_en": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents", "authors": "Yueqi Song,Ketan Ramaneti,Zaid Sheikh,Ziru Chen,Boyu Gou,Tianbao Xie,Yiheng Xu,Danyang Zhang,Apurva Gandhi,Fan Yang,Joseph Liu,Tianyue Ou,Zhihao Yuan,Frank Xu,Shuyan Zhou,Xingyao Wang,Xiang Yue,Tao Yu,Huan Sun,Yu Su,Graham Neubig", "background": "大规模监督微调AI代理的研究成果仍然比较罕见，因为代理训练数据的收集面临着独特的挑战。现有工作认为瓶颈在于缺乏底层数据源，但实际上数据种类繁多，分布在不同的格式、工具和接口中，导致难以统一。现有数据集中数据格式和接口不统一，阻碍了代理培训流水线的统一和标准化。因此，为了解决这些问题，作者提出了一种轻量级的数据表达语言，称为代理数据协议（ADP），旨在作为不同格式的代理数据和统一代理培训流水线之间的“中介”，能够表达各种任务并简化数据处理和模型训练过程，降低数据标准化和代理培训的复杂性，并能适应多种代理框架。作者将一批现有的数据集转换为ADP格式，展示了在多种代理框架上的标准化处理和微调，取得了显著的效果提升。", "innovation": "作者提出了一种叫作代理数据协议（ADP）的轻量级数据表达语言，作为不同格式的代理数据和统一代理流水线之间的“中介”。ADP可以表达多种任务，能够简化数据处理和模型训练过程，并且对于多种代理框架而言是标准化且普适的。通过将13个不同数据集的代理数据转换为ADP格式并进行微调，研究显示了显著的性能提升，并且在标准的编码、浏览、工具使用和研究基准上也达到了行业领先的表现。这项工作降低了代理培训的标准化和可再现性障碍，有助于促进不同格式代理数据的统一与标准化。同时，所有代码和数据已经公开发布。", "conclusion": "研究提出了一种新的代理数据协议（ADP）来统一代理数据，从而提高了代理的多样性和有效性。ADP为代理数据标准化提供了新的解决方案，通过将其转换为ADP格式，研究证明了显著的性能提升，并在多个基准上达到了领先的水平。作者希望ADP能够帮助降低代理培训的标准化、可扩缩性和可再现性障碍。所有代码和数据已经公开发布，以促进该领域的进一步研究和发展。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24687", "html_url": "https://arxiv.org/abs/2510.24687", "title": "快速算法使正则化优化和深度学习在圆周检测几何中的光声断层成像加速", "title_en": "Fast algorithms enabling optimization and deep learning for photoacoustic tomography in a circular detection geometry", "authors": "Andreas Hauptmann,Leonid Kunyansky,Jenni Poimala", "background": "光声成像和其他耦合物理模态中的源反问题通常通过迭代算法来解决，这些算法依赖于特定成本函数的最小化。近年来，人们正在研究新的深度学习技术以进一步改进这种优化方法。然而，所有这些方法都需要对正向问题定义的操作及其共轭进行多次应用。本文基于此背景，提出了一种新的算法，用于快速评估圆周采集几何中的正向和共轭算子，从而加速这些过程。", "innovation": "本文提出了一种新的算法，能够在$\text{O}(n^2 \text{log} n)$的浮点运算中快速计算圆周几何中的正向和共轭算子，这对于多种迭代图像重建技术（包括经典的变分方法和深度学习方法）都具有显著优势。实现了Python版本，并提供给公众使用，展示了算法在不同技术中的性能。", "conclusion": "本文的结果展示了我们算法在不同成像技术中的高效性。对圆周检测几何中的正向和共轭算子的高效计算可以显著改善基于优化和深度学习的光声成像。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2208.07777", "html_url": "https://arxiv.org/abs/2208.07777", "title": "在大量图上挖掘大型独立集", "title_en": "Mining Large Independent Sets on Massive Graphs", "authors": "Yu Zhang,Witold Pedrycz,Chanjuan Liu,Enqiang Zhu", "background": "最大独立集问题是从大型图中提取无冲突结构的基础，适用于排程、推荐和网络分析等领域。现有的启发式方法在搜索计划固定且过去解决方案的信息被低估的情况下容易停滞，导致在搜索空间的低质量区域浪费努力。", "innovation": "本文提出了ARCIS，一种用于在大量图中挖掘大型独立集的有效算法。ARCIS结合了两种主要组件：一种自适应重启策略，用于在进度减慢时重新探索；另一种称为共识引导顶点固定，通过在每一轮中固定从收敛顶点观察到的一致顶点来限制搜索，同时保持一致性并确保在重启时可以撤销固定的顶点，进而纠正偶尔的错误同时保持进展。实验表明，ARCIS在大多数情况下获得了最佳或并列最佳的结果，同时提供竞争的运行时间和低变异性。", "conclusion": "成分消减研究分离了每个组件的影响，显示ARCIS是一种实用且稳健的方法，适用于大规模图的挖掘。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.11133", "html_url": "https://arxiv.org/abs/2410.11133", "title": "3D-Prover：使用行列式点过程的多样化驱动定理证明", "title_en": "3D-Prover: Diversity Driven Theorem Proving With Determinantal Point Processes", "authors": "Sean Lamont,Christian Walder,Amir Dezfouli,Paul Montague,Michael Norrish", "background": "自动形式化推理的一个关键挑战是搜索空间的不可行性，随着证明深度的增加，这个空间呈指数增长。这种分支是由应用于给定目标的大量候选证明策略引起。然而，其中许多策略在语义上相似或导致执行错误，这两种情况都会浪费宝贵资源。我们通过仅使用来自先前尝试证明的数据生成的合成数据来解决有效剪枝搜索的问题。我们首先证明了可以从这些数据中生成语义感知的策略表示，该表示包含了对证明环境的影响、成功概率和执行时间。", "innovation": "我们提出了一个新颖的过滤机制，利用这些表示选择语义多样性和高质量策略，该机制使用行列式点过程。我们开发的方法3D-Prover旨在通用，能够增强任何底层策略生成器。我们通过增强流行的开源推理LLM，使用miniF2F和LeanDojo基准展示了3D-Prover的有效性。我们证明了这种方法增加了总的证明率，显著提高了策略成功率、执行时间和多样性。", "conclusion": "我们展示了3D-Prover在miniF2F和LeanDojo基准上的有效性，指出3D-Prover能够提高证明率、策略成功率、执行时间和多样性。我们将其代码发布在this https URL。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.15737", "html_url": "https://arxiv.org/abs/2411.15737", "title": "TableTime: 使用大型语言模型实现无训练表格理解的时间序列分类", "title_en": "TableTime: Reformulating Time Series Classification as Training-Free Table Understanding with Large Language Models", "authors": "Jiahao Wang,Mingyue Cheng,Qingyang Mao,Yitong Zhou,Daoyu Wang,Qi Liu,Feiyang Xu,Xin Li", "background": "大型语言模型（LLMs）在多变量时间序列分类（MTSC）任务中显示了有效性。现有基于LLM的方法直接从零开始将时间序列嵌入到LLM的潜在空间中以与语义空间对齐，尽管它们有效，但这些方法存在三个内在瓶颈：（1）难以无损编码时间特性和通道特定信息，这是MTSC的关键组成部分；（2）难以将学习的表示空间与LLM的语义空间对齐；（3）需要针对特定任务重新训练，这既耗时又耗资源。", "innovation": "本文提出了TableTime，该方法重新定义MTSC为无训练的表格理解任务。具体来说，TableTime引入了以下策略：（1）将多变量时间序列转换为表格形式，从而最大限度地减少信息损失；（2）以文本格式表示表格时间序列，以实现与LLM语义空间的自然契合；（3）设计一种推理框架，整合上下文文本信息、邻域协助、多路径推理和问题分解，以增强LLM的推理能力和实现零样本分类。", "conclusion": "在UEA档案中10个公开代表数据集上进行的大量实验验证了TableTime的优势。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22092", "html_url": "https://arxiv.org/abs/2505.22092", "title": "VIRAL: 视觉嵌入的奖励设计与学习集成", "title_en": "VIRAL: Vision-grounded Integration for Reward design And Learning", "authors": "Valentin Cuzin-Rambaud,Emilien Komlenovic,Alexandre Faure,Bruno Yun", "background": "人类和机器之间的对齐是当今人工智能的一个关键挑战。强化学习旨在最大化奖励函数，但容易受到设计不良的奖励函数带来的风险影响。最近的研究表明，大型语言模型（LLMs）在奖励生成方面可以超越人类的表现。本文介绍了一种名为VIRAL的方法，通过使用多模态LLMs生成和优化奖励函数。", "innovation": "VIRAL方法通过多模态LLMs自主创建并交互式改进奖励函数，可以根据给定的环境和目标提示或标注图像进行优化。此外，该过程还可以通过人类反馈或由视频LLMs生成的描述来指导，这些描述以视频形式解释了代理的政策。", "conclusion": "在五个Gymnasium环境中评估VIRAL，证明了它能够加速新行为的学习过程，同时确保与用户意图的更好的对齐。代码和演示视频可在特定链接中找到。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.23464", "html_url": "https://arxiv.org/abs/2506.23464", "title": "谬误的自信：大模型何时会错", "title_en": "The Confidence Paradox: Can LLM Know When It's Wrong", "authors": "Sahil Tripathi,Md Tabrez Nafis,Imran Hussain,Jiechao Gao", "background": "现有的DocVQA模型在不确定性情况下容易产生过于自信或伦理上不正确的响应。尽管模型如LayoutLMv3、UDOP和DONUT注重准确度，但缺乏伦理校准。", "innovation": "提出了HonestVQA，这是一种模型无关、自监督框架，通过加权损失和对比学习来使模型的自信程度与准确性保持一致。此外，还提出了一种诚实分数（H-Score）和伦理信心指数（ECI）来评估伦理一致性。HonestVQA在SpDocVQA、InfographicsVQA和SROIE数据集上的准确性提高了0-4.3%，同时降低了模型的自信程度，并且在不同领域具有良好的泛化能力，准确性达到78.9%，F1分数达到76.1%。", "conclusion": "HonestVQA在提高准确性和F1分数的同时，降低了模型的盲目信心，具有良好的伦理一致性，并且在多种数据集上表现良好，具有广阔的适用前景。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.21142", "html_url": "https://arxiv.org/abs/2502.21142", "title": "多模态想象：全局工作区方法在基于世界模型的强化学习中的应用", "title_en": "Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning", "authors": "Léopold Maytié,Roland Bertin Johannet,Rufin VanRullen", "background": "人类利用丰富的内部世界模型来预测未来、想象替代情境并适应新情况。在强化学习(RL)中，世界模型旨在捕捉环境在代理行为下如何演变，从而促进规划和泛化。然而，典型的世界模型直接操作于环境变量（例如像素或物理属性），这可能导致训练速度缓慢且复杂。相较而言，利用能够捕捉重要多模态变量的高层隐空间可能更为有益。Global Workspace (GW)理论提供了一种认知框架，用于大脑中的多模态整合和信息广播，近期的研究已经开始引入高效的深度学习实现GW。", "innovation": "该研究将GW方法与世界模型结合，探讨了其在强化学习系统中的应用。实验将GW-Dreamer与现有的标准PPO和Dreamer算法进行了比较，结果显示将想象过程（即心理模拟）在GW潜空间中进行可以减少环境步骤。此外，该模型还展示了强大的对缺失单模态观察（图像或模拟属性）的鲁棒性，这在其比较基线中并未发现。研究认为GW与世界模型的结合对于提升RL代理的决策能力具有巨大潜力。", "conclusion": "GW与世界模型的结合在强化学习中的潜在应用为提高代理决策能力提供了新的途径。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.02039", "html_url": "https://arxiv.org/abs/2404.02039", "title": "基于大型语言模型的游戏代理", "title_en": "A Survey on Large Language Model-Based Game Agents", "authors": "Sihao Hu,Tiansheng Huang,Gaowen Liu,Ramana Rao Kompella,Fatih Ilhan,Selim Furkan Tekin,Yichang Xu,Zachary Yahn,Ling Liu", "background": "游戏环境提供了丰富的、可控的设置，能够激发现实世界的复杂性。因此，游戏代理是探索与通用人工智能相关的能力的绝佳测试平台。近年来，大型语言模型（LLMs）的出现为这些代理添加了普遍的推理、记忆和复杂环境中的适应性提供了新的机会。本文通盘回顾了基于大型语言模型的游戏代理（LLMGAs），并根据统一的参考架构进行了分类研究。在单个代理层面，综合了现有研究关于三个核心组件：记忆、推理和感知-行动接口，以便概括语言如何使代理感知、思考和行动。在多个代理层面，详述了如何通过通信协议和组织模型支持协调、角色差异化和大规模社会行为。这些设计的背景，通过将六个游戏主要类型与主导代理要求联系起来的挑战导向分类来提供语境，从即时控制在动作游戏中到开放型目标资源在沙盒世界中。", "innovation": "本文通过统一的参考架构对基于大型语言模型的游戏代理（LLMGAs）进行了最新的综述性研究。研究了单个代理层面的三个核心组件：记忆、推理和感知-行动接口，以及多个代理层面的通信协议和组织模型，支持协调、角色差异化和大规模社会行为。并引入了一种挑战导向的分类，将六个主要游戏类型与其主导代理要求进行了联系，为相关研究提供了一个框架。", "conclusion": "本文从挑战出发，以六种主要游戏类型为例，提供了一个关于LLMGAs的设计分类框架。这个框架既涵盖了单个代理层面的记忆、推理和感知-行动接口，也涵盖了多个代理层面的通信协议和组织模型。此外，还提供了一个综述性的资源列表，旨在总结现有研究，为未来研究提供参考。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03285", "html_url": "https://arxiv.org/abs/2507.03285", "title": "Memory Mosaics at scale", "title_en": "Memory Mosaics at scale", "authors": "Jianyu Zhang,Léon Bottou", "background": "记忆马赛克 [张等人，2025]展示了在中等规模网络（如GPT-2规模）和合成小型数据集上，具有吸引人的组合性和上下文学习能力的关联记忆网络的表现。本研究旨在将记忆马赛克扩展到大型语言模型规模（如llama-8B规模）以及真实世界数据集上。", "innovation": "研究人员将记忆马赛克扩展到10B规模，并在一个万亿词的数据集上进行训练。提出了“记忆马赛克v2”的一系列架构修改。在训练知识存储、新知识存储和上下文学习这三项评估维度上，记忆马赛克v2均表现出色。记忆马赛克v2在学习训练知识方面与Transformer模型相当，在推理时执行新任务方面则明显优于Transformer模型。这种改进不能仅通过增加Transformer的训练数据量来轻松复制。", "conclusion": "记忆马赛克v2在含有一万亿词训练数据的情况下仍优于训练于八万亿词数据的Transformer，在执行新任务方面表现出显著优势。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.18868", "html_url": "https://arxiv.org/abs/2507.18868", "title": "神经科学启发的双过程模型的组合泛化", "title_en": "A Neuroscience-Inspired Dual-Process Model of Compositional Generalization", "authors": "Alex Noviello,Claas Beger,Jacob Groner,Kevin Ellis,Weinan Sun", "background": "深度学习模型在处理系统全面组合泛化方面存在困难，这是人类认知的标志。本文提出了Mirage，这是一种神经启发的双过程模型，提供了一种这种能力的处理解释。模型结合了快速直觉的“系统1”（一个元训练的Transformer）和审慎的基于规则的“系统2”（Schema Engine），模仿了大脑的新生皮层和海马-前额叶回路。通过在随机语法流上进行一般单步分解的训练，Mirage在SCAN基准上的所有分割上实现了超过99％的准确性。消融实验表明，该模型的系统性行为源自其两个系统的架构交互，特别是使用显式优先级的模式和迭代细化。", "innovation": "Mirage是一个基于神经科学的双过程模型，结合了快速直觉的“系统1”和审慎的基于规则的“系统2”，在处理系统全面组合泛化方面表现出色。该模型独立地保留迭代神经更新，并将声明性控制外部化为可解释的模式模块。这符合最近有关递归/递归Transformer方法的进步。", "conclusion": "本研究提供了一个具体的计算模型，用于解释组合推理如何从模块化认知架构中产生。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.26080", "html_url": "https://arxiv.org/abs/2509.26080", "title": "评估大语言模型在社会科学研究中作为合成社会代理使用的效果", "title_en": "Evaluating the Use of Large Language Models as Synthetic Social Agents in Social Science Research", "authors": "Emma Rose Madden", "background": "大语言模型（LLMs）在社会科学研究中的应用越来越广泛，从增强调查回应到驱动多智能体模拟等不同应用领域都可见其身影。然而，由此产生的LLM输出需要谨慎解读。", "innovation": "该研究提出了将LLM重新定位为社会科学研究中的高容量模式匹配器，用于准预测性插补，并强调了明确的适用范围条件，而不是将其作为概率推断的替代品。研究还引入了一系列实用的指导方针，包括独立抽样、预先注册的人类基线、可靠性验证以及子组校准，以确保研究人员能够进行有意义的原型设计和预测，同时避免类别错误。", "conclusion": "通过这些措施，研究人员可以在利用LLM进行有用的研究原型设计和预测的同时，避免类错误。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.06463", "html_url": "https://arxiv.org/abs/2509.06463", "title": "通过量化指令集的覆盖范围和深度加速大规模语言模型微调的扩展", "title_en": "Accelerate Scaling of LLM Finetuning via Quantifying the Coverage and Depth of Instruction Set", "authors": "Chengwei Wu,Li Du,Hanyu Zhao,Yiming Ju,Jiapu Wang,Tianyu Chen,Haoyi Zhou", "background": "该研究指出，即使监督参数调整（SFT）所使用的数据量成比例增加，并不能保证模型性能的相应提高。因此，研究强调了理解哪些训练样本能够有效提高模型性能的重要性。本文识别了两个数据集属性，用于调控SFT的扩展性：\n1. 语义覆盖，即任务领域的广度；\n2. 信息深度，即每个样本的丰富度。研究表明，这些属性的简单代理变量能够解释大多数验证损失的变化。", "innovation": "本文提出了一种名为'信息景观近似’(ILA) 的模型通用数据选择框架，ILC 能够同时优化上述两个因素，从而构建能够近似大型数据集信息价值的小型子集。实验结果显示，使用ILA 选择数据调整的模型，在各种任务和模型规模上实现更快速且持续的性能提升，这一现象被称为‘加速扩展’。", "conclusion": "这项工作通过量化指令集的覆盖范围和深度，提出了一种加速大规模语言模型微调扩展的方法，这种方法能够优化语义覆盖和信息深度两个关键因素，从而实现模型性能的大幅度提升。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23143", "html_url": "https://arxiv.org/abs/2509.23143", "title": "MathBode: 使用动力学系统理解大语言模型推理", "title_en": "MathBode: Understanding LLM Reasoning with Dynamical Systems", "authors": "Charles L. Wang", "background": "以往对大型语言模型（LLMs）的评估主要侧重于单一问题的一次性准确性。然而，这种方法未能充分揭示模型在处理系列参数问题时的动态行为和推理一致性的细微差别。本文通过引入MathBode，一种动力学诊断方法，旨在提供更深入、更详细的数学推理评估方法，从而改进和补充现有的基准测试。", "innovation": "MathBode 提出了一种新的诊断方法来评估大语言模型的数学推理能力。它将每个参数问题视为一个系统，通过驱动单一参数的正弦波并拟合模型输出和准确解的一阶谐波响应来获得可解释和频率分辨率高的度量标准，包括增益（幅度跟踪）和相位（滞后）。这种方法打破了单一准确性评估的局限性，并且能够揭示准确度数据中隐藏的系统低通行为和增长的相位滞后。此外，它还通过将各种模型与符号基准进行比较，提供了一种紧凑且可重复的评估协议，补充了现有的标准基准，并提供了可操作的测量来评估推理的准确性和一致性。", "conclusion": "MathBode 方法能够区分前沿模型与中级模型在动态方面的表现，为未来研究提供了开源数据集和代码，使得进一步研究和实际应用更加容易。此外，这种方法在标准基准上提供了关于推理准确性和一致性的真实可操作度量，补充了目前的评估方法。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21730", "html_url": "https://arxiv.org/abs/2508.21730", "title": "可复用Ansatz求解旅行商问题", "title_en": "Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem", "authors": "Fabrizio Fagiolo,Nicolò Vescera", "background": "本文介绍了一种用于旅行商问题（TSP）的变分算法，结合了一个紧凑的排列编码方法，降低了qubit的需求，以及一种优化-冻结-重用策略。通过这种策略，研究人员可以先在特定实例上优化电路拓扑结构，然后在新的实例上冻结并重用该电路拓扑结构，仅对电路参数进行快速重新优化。这种方法能够避免在测试中进行耗时的结构研究，使得该方法可以直接在NISQ硬件上实施。在4-7个城市规模的40个随机生成的对称实例上进行了测试，结果显示对于4城市的案例，最优行程采样概率为100%，5城市的案例为90%，6城市的案例为80%，7城市的案例成功率为20%左右，揭示了提出方法的可扩展性局限。此外，研究表明这种方法在中等问题规模上具有鲁棒的泛化能力，并且可以大幅缩短解决问题的时间而不牺牲解决方案的质量。文章还讨论了可扩展性限制、参数暖启动初始化的影响以及将该方法扩展到更复杂问题（如车辆路由和作业车间调度）的前景。", "innovation": "1. 采用一种紧凑的排列编码方法，减少qubit的需求；2. 利用优化-冻结-重用策略，在初试实例上优化电路拓扑结构，然后在新的实例上冻结并重用该电路拓扑结构，仅对电路参数进行快速重新优化，避免了耗时的结构研究；3. 显示出方法在中等问题规模上的鲁棒性泛化能力，且可以大幅缩短解决问题的时间而不影响解决方案的质量；4. 探讨了方法的可扩展性限制、参数初始化的影响及扩展到复杂问题的潜力。", "conclusion": "提出的方法能够显著缩短求解TSP问题的时间，且保持了高质量的解决方案，特别是在中等问题规模上表现出明显的鲁棒泛化能力。虽然面对较大规模的城市数量时，该方法的适用性有所下降，但仍为求解NP难问题提供了一种有价值的替代方案。此外，文章还讨论了未来进一步提升的方法和可能的应用范围。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16724", "html_url": "https://arxiv.org/abs/2510.16724", "title": "Reinforcement Learning-based Agentic Search: 基于强化学习的自主搜索综述: 基础、角色、优化、评估和应用", "title_en": "A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications", "authors": "Minhua Lin,Zongyu Wu,Zhichao Xu,Hui Liu,Xianfeng Tang,Qi He,Charu Aggarwal,Hui Liu,Xiang Zhang,Suhang Wang", "background": "由于大型语言模型（LLMs）的兴起，信息检索和推理通过开放式的自然语言交互得到了重塑。然而，这些模型仍受到固定知识、事实幻觉以及无法检索实时或特定领域信息的限制。检索增强生成（RAG）通过将模型输出与外部证据相结合来缓解这些问题，但传统的RAG管道通常是单轮的、基于启发式的，缺乏对检索和推理的自适应控制。近来，自主搜索的发展通过多步骤与搜索环境的交互使LLMs能够制定计划、检索和反思，从而解决了这些限制。强化学习（RL）提供了一种强大的机制，使搜索行为具有自适应性和自我改进特性。", "innovation": "本研究首次全面梳理了基于强化学习的自主搜索，并沿着三个互补维度组织：（i）强化学习的功能作用；（ii）强化学习的应用策略；（iii）优化的范围。研究总结了代表性的方法、评估协议和应用场景，讨论了开放挑战和未来发展方向，以构建可靠和可扩展的基于强化学习的自主搜索系统。", "conclusion": "我们希望这份综述能够激发未来研究中强化学习和自主搜索的整合。我们的资源库已发布于此：[此链接]。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08263", "html_url": "https://arxiv.org/abs/2510.08263", "title": "Co-TAP:三层代理交互协议技术报告", "title_en": "Co-TAP: Three-Layer Agent Interaction Protocol Technical Report", "authors": "Shunyu An,Miao Wang,Yongchao Li,Dong Wan,Lina Wang,Ling Qin,Liqin Gao,Congyao Fan,Zhiyong Mao,Jiange Pu,Wenji Xia,Dong Zhao,Zhaohui Hao,Rui Hu,Ji Lu,Guiyue Zhou,Baoyu Tang,Yanqin Gao,Yongsheng Du,Daigang Xu,Lingjun Huang,Baoli Wang,Xiwen Zhang,Luyao Wang,Shilong Liu", "background": "本文提出了一种名为Co-TAP（T: Triple，A: Agent，P: Protocol）的三层代理交互协议，旨在解决跨三大核心维度（互操作性、交互和合作、知识共享）的多代理系统所面临的挑战。协议包括三个核心协议：Human-Agent Interaction Protocol (HAI)，Unified Agent Protocol (UAP) 和 Memory-Extraction-Knowledge Protocol (MEK)，分别对应交互层、基础设施层和认知层，旨在确保用户、界面和代理之间的信息流动，实现跨异构代理的无缝连接和互操作，并使代理能够通过经验学习和知识共享建立真正的集体智能基础。", "innovation": "本文设计并提出了一种分层解决方案，由三个核心协议组成：HAI（Human-Agent Interaction Protocol，交互协议）、UAP（Unified Agent Protocol，统一代理协议）和MEK（Memory-Extraction-Knowledge Protocol，记忆提取知识协议）。HAI优化了交互层的标准化通信模式，确保信息在用户、界面和代理之间的实时传输；UAP通过统一的服务发现和协议转换机制打破异构代理间的沟通障碍，增强底层网络的互操作性；MEK则在认知层构建了一个标准化的记忆-提取-知识（MEK）认知链，使代理能够从个人经验中学习并分享知识，为实现真正的集体智能奠定基础。", "conclusion": "我们认为该协议框架将为构建下一代高效、可扩展和智能的多代理应用提供坚实的工程基础和理论指导。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17550", "html_url": "https://arxiv.org/abs/2509.17550", "title": "是一定是假的深伪造品吗？检测与生成生态系统中的可靠性分析", "title_en": "Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem", "authors": "Neslihan Kose,Anthony Rhodes,Umur Aybars Ciftci,Ilke Demir", "background": "随着生成模型的质量和数量不断提升，合成内容（如Deepfake）开始在线上引起怀疑和不信任。为应对这一问题，提出了多种Deepfake检测器。然而，这些检测器也可能被误用，即错误地将真实的视频或图片标记为假的，或者反之。这种误用现象进一步加剧了信息误导的问题。鉴于此，本文旨在系统性地研究Deepfake检测器对生成特征的不确定性分析，并探讨生成器如何影响这些不确定性。研究表明，不确定性的流形中包含足够的信息，用于检测Deepfake的来源，并提出了一种利用贝叶斯神经网络和蒙特卡洛dropout来量化不同检测器架构下两种不确定性（aleatoric和epistemic）的方法。通过在两个数据集上进行评估，比较多种不确定性方法，探讨基于区域和像素的不确定性，并进行了消融研究。评估内容覆盖了二元真实/伪造、多元真实/伪造、来源检测以及留一法实验，展示了生成器/检测器组合的一般化能力、模型校准、不确定性以及对抗性攻击的鲁棒性。此外，本文引入了像素级别的不确定性图，揭示了与生成器特定特征相关的预测信心的不同模式，为部署可靠的Deepfake检测系统提供了关键见解，并将不确定性量化确立为可信合成媒体检测的基本要求。", "innovation": "文章首次全面分析了Deepfake检测器的不确定性，系统研究生成特征对预测信心的影响。提出利用贝叶斯神经网络和蒙特卡洛dropout来量化生成器和检测器中的不确定性，并通过多种方法和实验比较，展示了生成器/检测器组合的不确定性和性质。此外，引入了基于像素级别的不确定性图，揭示了生成器特定特征的相关模式，提升了Deepfake检测系统的可靠性和准确性。", "conclusion": "通过系统的不确定性分析，研究发现不确定性的流形中包含足够的信息用于检测Deepfake的来源。本文提出的方法可以量化各种检测器架构下的不确定性，并通过实验验证了其效果。同时，引入了像素级别的不确定性图，进一步提高了Deepfake检测的精确性和可靠性。文章的研究成果对于部署可靠的Deepfake检测系统具有重要意义，确立了不确定性量化作为可信合成媒体检测的基本要求。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23008", "html_url": "https://arxiv.org/abs/2510.23008", "title": "从提示优化到多维可信性评估：增强基于中文LLM生成的肝MRI报告可信性", "title_en": "From Prompt Optimization to Multi-Dimensional Credibility Evaluation: Enhancing Trustworthiness of Chinese LLM-Generated Liver MRI Reports", "authors": "Qiuli Wang,Jie Chen,Yongxu Liu,Xingpeng Zhang,Xiaoming Li,Wei Chen", "background": "大型语言模型（LLMs）在从影像学检查结果生成诊断结论方面的表现令人期待，能够支持放射学报告、培训生教育和质量控制。然而，如何在不同临床背景下优化提示设计的系统性指导尚显不足。此外，还缺乏全面和标准化的评估LLMs生成的放射学报告可信性的框架。", "innovation": "该研究通过引入多维可信性评估（MDCA）框架，并提供机构特定提示优化的指导，旨在提升基于LLM生成的肝MRI报告的可信性。该框架在硅流平台（SiliconFlow）中被应用于评估和比较包括Kimi-K2-Instruct-0905、Qwen3-235B-A22B-Instruct-2507、DeepSeek-V3和ByteDance-Seed-OSS-36B-Instruct在内的几个先进LLMs的表现。", "conclusion": "通过MDCA框架的应用，研究为增强基于LLM生成的肝MRI报告的可信性提供了新方法，并通过具体实例展示了优化提示设计在多维度评估中的效果。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23216", "html_url": "https://arxiv.org/abs/2510.23216", "title": "在现实足球模拟中的类人守门员：一种高效强化学习方法", "title_en": "Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach", "authors": "Alessandro Sestini,Joakim Bergdahl,Jean-Philippe Barrette-LaPierre,Florian Fuchs,Brady Chen,Michael Jones,Linus Gisslén", "background": "尽管多个知名视频游戏被用作深度强化学习(DRL)的测试平台，但该技术在游戏行业中用于创造真实的AI行为方面应用较少。先前的研究集中在训练超级人类代理人，这在资源有限的游戏工作室中并不实用，他们希望训练出具备人类特点的AI代理。本文介绍了一种专门为工业环境下的视频游戏行业训练和微调代理的样本高效DRL方法。", "innovation": "该方法通过利用预先收集的数据和增加网络的可塑性来提高基于价值的DRL的样本效率。在EA SPORTS FC 25中训练守门员代理时，该代理的扑球率比游戏中内置的AI高10%。消融研究表明，与标准DRL方法相比，该方法可以将训练代理的速度提高50%。从领域专家的定性评价来看，该方法创建出的人类类游戏体验优于手工制作的代理。", "conclusion": "该方法的成功应用证明了其对游戏行业的潜在价值，预计将在该系列的后续版本中取代手工制作的同类代理。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.21143", "html_url": "https://arxiv.org/abs/2510.21143", "title": "PanicToCalm: 一种应对恐慌发作的主动咨询代理", "title_en": "PanicToCalm: A Proactive Counseling Agent for Panic Attacks", "authors": "Jihyun Lee,Yejin Min,San Kim,Yejin Jeon,SungJun Yang,Hyounghun Kim,Gary Geunbae Lee", "background": "恐慌发作是急性恐惧和焦虑症状，及时和适当的干预可以显著帮助个体恢复稳定。然而，由于伦理和物流问题，用于训练此类模型的适当数据集仍然稀缺。", "innovation": "本文提出了一种名为 PACE 的数据集，该数据集由第一人称叙述构建，涵盖高压力事件，并遵循心理第一响应（PFA）原则。基于该数据集，开发了一种名为 PACER 的咨询模型，该模型通过监督学习和模拟偏好对齐进行优化，提供同理心和指令性支持。此外，还提出了一个多维度的评估框架 PanicEval，用于评估其效果。", "conclusion": "实验结果显示，PACER 在咨询师和受试者情绪改善方面均优于其他基准模型。此外，人类评估进一步证实了 PACER 的实际价值，在恐慌情境下，PACER 优于普通咨询、CBT 基础和 GPT-4 驱动的模型（代码可在此处访问 https://github.com/PANIC-to-Calm）"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.21293", "html_url": "https://arxiv.org/abs/2510.21293", "title": "理解AI可信性：AIES & FAccT文章的综述研究", "title_en": "Understanding AI Trustworthiness: A Scoping Review of AIES & FAccT Articles", "authors": "Siddharth Mehrotra,Jin Huang,Xuelong Fu,Roel Dobbe,Clara I. Sánchez,Maarten de Rijke", "background": "可信的人工智能作为两大AI伦理会议AIES和FAccT的基础支柱，当前研究主要采用技术中心的方法，集中于技术属性如可靠性、鲁棒性和公平性，而忽视了理解现实世界情境中AI可信性的社技维度。", "innovation": "本文通过划分审查AIES和FAccT会议的论文，系统分析了信任的定义、操作化及其在不同研究领域中的应用，揭示了技术属性定义的进步与社会、伦理考量不足之间的矛盾，强调了需要结合技术严谨性和社会、文化和制度考量来促进可信AI的研究。", "conclusion": "跨学科的方法对于促进可信的人工智能研究至关重要，结合了技术严谨性与社会、文化和制度考虑，提出可操作的措施，为AI伦理社区提供全面框架，以解决AI系统与社会之间复杂互动问题，最终促进有利于所有利益相关者的负责任技术发展。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.21614", "html_url": "https://arxiv.org/abs/2510.21614", "title": "Huxley-Gödel 机：通过近似最优自我改进机器实现的人类级代码代理开发", "title_en": "Huxley-Gödel Machine: Human-Level Coding Agent Development by an Approximation of the Optimal Self-Improving Machine", "authors": "Wenyi Wang,Piotr Piękos,Li Nanbo,Firas Laakom,Yimeng Chen,Mateusz Ostaszewski,Mingchen Zhuge,Jürgen Schmidhuber", "background": "近期研究通过编程代理（编码器）来改进自己的代码库，通过扩展策略生成一系列自我修改，以优化软件工程基准性能，假设这将促进更有效的后续自我改进。然而，研究发现代理的自我改进潜力（元生产率）与其编码基准性能之间存在不匹配，即元生产率-性能不匹配问题。", "innovation": "基于赫胥黎的概念，提出了一种度量指标CMP，通过聚合代理后裔的基准性能来评估其自我改进潜力。基于CMP，提出了一种新的自我改进编码代理开发方法——Huxley-Gödel机，通过估计CMP并利用其作为指导来搜索自我修改的树形结构。结果显示，Huxley-Gödel机在自我改进编码代理开发上超越了先前的方法，在某些基准上使用更少的墙钟时间，并且在其他编程数据集和大型语言模型上的表现也强。通过使用Huxley-Gödel机优化的SWE-bench验证集上的代理，在SWE-bench轻量集上的表现达到了人类级别的水平，与人类工程编码代理的最佳结果相当。", "conclusion": "研究展示了Huxley-Gödel机在自我改进编码代理开发上的优势，并在多种代码数据集和大型语言模型上实现了优异性能，尤其在某些基准上能模拟类似Gödel机的行为，大幅提高了自我改进代理开发的效果。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.10028", "html_url": "https://arxiv.org/abs/2402.10028", "title": "扩散模型遇上上下文多臂老虎机", "title_en": "Diffusion Models Meet Contextual Bandits", "authors": "Imad Aouali", "background": "在线决策中的上下文多臂老虎机问题具有挑战性，因为缺乏信息先验的方法往往在计算或统计效率上存在问题。", "innovation": "利用预训练的扩散模型作为表达性的先验知识来捕捉复杂的行为依赖性，并开发了一种实用算法来高效地近似先验下的后验概率，从而实现快速更新和采样。", "conclusion": "实验证明，该方法在各种上下文多臂老虎机设置中都具有有效性与灵活性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23564", "html_url": "https://arxiv.org/abs/2510.23564", "title": "ReCode: 统一计划与行动以实现通用粒度控制", "title_en": "ReCode: Unify Plan and Action for Universal Granularity Control", "authors": "Zhaoyang Yu,Jiayi Zhang,Huixue Su,Yufan Zhao,Yifan Wu,Mingyi Deng,Jinyu Xiang,Yizhang Lin,Lingxiao Tang,Yingchao Li,Yuyu Luo,Bang Liu,Chenglin Wu", "background": "现实任务需要在不同的粒度级别上做出决策，人类能够通过统一的认知表示，将规划视为高级形式的行动来高效地完成这些任务。然而，当前基于大型语言模型（LLM）的智能代理缺乏在不同粒度级别上灵活操作的能力。这种局限性源于现有框架的不灵活，将高级规划和低级动作分离，从而限制了动态适应能力和泛化能力。", "innovation": "本文提出了一种新颖的ReCode（递归代码生成）范式，通过在一个统一的代码表示中联合规划和动作来解决上述局限性。ReCode将高级计划视为抽象占位符函数，代理递归地分解为更细粒度的子函数，直至到达基本动作。递归方法消除了计划与行动之间的刚性边界，使代理能够动态控制其决策粒度。递归结构还产生了丰富的多粒度训练数据，使模型能够学习分层决策过程。", "conclusion": "广泛的实验表明，ReCode在推理性能上明显优于先进的基线，在训练中表现出色的数据效率，验证了我们关于通过递归代码生成联合规划和动作的核心见解。这是一种实现通用粒度控制的强大且有效的途径。相关的代码已发布在如下链接：this https URL."}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2202.07980", "html_url": "https://arxiv.org/abs/2202.07980", "title": "使用ORBITS查询优先级不一致数据：算法、实现与实验", "title_en": "Querying Inconsistent Prioritized Data with ORBITS: Algorithms, Implementation, and Experiments", "authors": "Meghyn Bienvenu,Camille Bourgaux", "background": "本文研究了不一致容忍查询回答在优先知识库中的实际算法，这些知识库由逻辑理论、一组事实和矛盾事实之间的优先关系组成。研究考虑了三种已知的语义（AR、IAR和勇敢），基于两种最优修复的概念（帕累托和完成）。在一定类别的逻辑理论的数据复杂性下，决定某个查询答案是否在这些语义下成立是（co）NP完全问题。当没有优先关系或关系具有特殊结构时，已经为基于修复的语义设计了SAT基程序。本文原始地提供了第一个针对一般优先关系的帕累托和完成最优修复的SAT编码，并提出了一些利用现有和新编码的方法来在不同修复基础语义下计算查询答案。", "innovation": "本文首次提供了针对一般优先关系的帕累托和完成最优修复的SAT编码，并提出了一些利用现有和新编码的方法来在不同的修复基础上计算查询答案，同时利用了SAT求解器的不同推理模式。", "conclusion": "本文实现了综合实验，比较了不同修复基础语义的影响，并比较了相同语义下的不同程序的相对性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23595", "html_url": "https://arxiv.org/abs/2510.23595", "title": "Multi-Agent Evolve: LLM 自我改进通过协同进化", "title_en": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution", "authors": "Yixing Chen,Yiding Wang,Siqi Zhu,Haofei Yu,Tao Feng,Muhan Zhang,Mostofa Patwary,Jiaxuan You", "background": "强化学习（RL）在提升大型语言模型（LLMs）的推理能力方面显示出巨大潜力，但其成功依赖于人类标注的数据和可验证的奖励，这限制了其扩展性和通用性。最近的自我博弈RL方法，受到游戏和国际象棋领域成功激励，旨在通过消除对人类标注数据的依赖来提升LLMs的推理能力，但这些方法主要依赖于具体的环境提供反馈（如Python解释器或游戏引擎），将其扩展到通用领域仍然具有挑战性。", "innovation": "本文提出Multi-Agent Evolve (MAE)框架，这是一种框架，使LLMs能够在解决多样任务（如数学、推理和常识问答）中自我进化。该框架的核心设计基于一个由单一LLM创建的三个交互代理（提案者、解决者、裁判）组成 triplet，通过强化学习优化它们的行为。提案者生成问题，解决者尝试解决方案，裁判评估两者并共同进化。实验表明，MAE在Qwen2.5-3B-Instruct上实现了平均4.54%的多种基准上的改进，这突显了它作为一种针对LLMs提升通用推理能力的可扩展且数据高效的可选方法。", "conclusion": "实验结果表明，MAE作为一种针对LLMs提升通用推理能力的可扩展且数据高效的可选方法，证明了其有效性和潜力，尤其在多任务解决中的效果良好，展现了较低的人类监督依赖性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.02787", "html_url": "https://arxiv.org/abs/2410.02787", "title": "基于VLM框架的导航技术：走向任何语言的目标", "title_en": "Navigation with VLM framework: Towards Going to Any Language", "authors": "Zecheng Yin,Chonghao Cheng,and Yao Guo,Zhen Li", "background": "完全开放的语言目标导航和探索开放场景在智能方式下始终面临巨大挑战。尽管视觉语言模型(VLMs)能够处理语言和视觉数据，许多研究仍依赖于高计算成本、对象中心的方法或详细的环境先验信息。现有方法往往在导航开放环境时遇到这些问题。", "innovation": "NavVLM框架提出了一种无需训练的体系结构，利用开源VLMs的认知核心来感知环境信息并在没有详细环境先验指令的情况下持续提供探索指导，实现了智能导航。该框架在模拟和现实世界实验中展现出强大的导航能力，特别是在Matterport 3D (MP3D)，Habitat Matterport 3D (HM3D)和Gibson中的具体任务上达到了最先进的成功加权路径长度(SPL)性能。", "conclusion": "NavVLM在模拟场景中继承了开放集语言的导航能力，成功验证了其有效性和适应性。在室内场景的现实世界验证中，NavVLM展示了有效导航至任意语言目标的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.13397", "html_url": "https://arxiv.org/abs/2404.13397", "title": "基于检索增强生成的关系抽取", "title_en": "Retrieval-Augmented Generation-based Relation Extraction", "authors": "Sefika Efeoglu,Adrian Paschke", "background": "信息提取（IE）是一种将未结构化文本数据转换为结构化格式的过程，主要依赖实体抽取（RE）和关系抽取（RE）方法。识别实体对之间的关系在此框架中至关重要。尽管有许多关系抽取技术，但它们的有效性主要依赖于标记数据和大量的计算资源。为解决这些问题，大型语言模型（LLMs）成为了有前景的解决方案，但它们可能由于自己的训练数据而产生幻觉响应。", "innovation": "本研究提出了基于检索增强生成的关系抽取（RAG4RE），利用不同的大型语言模型（如Flan T5、Llama2、Mistral）进行评估，发现RAG4RE方法在TACRED及其变种数据集的表现超过基于LLM的传统关系抽取方法，并且在TACRED和TACREV数据集上的表现优于以往的关系抽取方法，突显了其在自然语言处理中的有效性与潜力。", "conclusion": "研究结果表明，基于检索增强生成的关系抽取方法在TACRED数据集及其变种中表现出色，优于仅基于LLM的传统关系抽取方法，且在TACRED和TACREV数据集上的表现优于之前的多种关系抽取方法，展示了其在自然语言处理中进行关系抽取任务的有效性和潜力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.15536", "html_url": "https://arxiv.org/abs/2410.15536", "title": "GRS: 根据真实世界图片生成机器人模拟任务", "title_en": "GRS: Generating Robotic Simulation Tasks from Real-World Images", "authors": "Alex Zook,Fan-Yun Sun,Josef Spjut,Valts Blukis,Stan Birchfield,Jonathan Tremblay", "background": "该研究提出了一种名为GRS（Generating Robotic Simulation tasks）的系统，旨在解决从真实世界到模拟环境中的机器人模拟问题。该系统的目标是从单个RGB-D观察中生成数字孪生模拟，并在虚拟代理训练中提供可解的任务。通过使用视觉语言模型（VLMs），研究开发了一种三阶段管道：首先使用SAM2进行场景解析和对象描述，其次将对象与可用于模拟的资产匹配，最后生成相应的任务。通过生成的测试套件确保模拟和任务的一致性，并提出了一个路由器机制，能够迭代细化模拟和测试代码。", "innovation": "该研究的创新之处在于使用视觉语言模型（VLMs）的三阶段管道技术，尤其是通过SAM2进行场景理解和对象描述，匹配实际对象与模拟资产，以及通过生成的测试套件和迭代路由器机制确保模拟环境和任务的一致性。", "conclusion": "实验结果表明，该系统能够在对象对应和任务环境生成方面有效运行，并通过新颖的路由器机制提高了系统的性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.19477", "html_url": "https://arxiv.org/abs/2411.19477", "title": "大型语言模型测试时计算的可验证扩展定律", "title_en": "Provable Scaling Laws for the Test-Time Compute of Large Language Models", "authors": "Yanxi Chen,Xuchen Pan,Yaliang Li,Bolin Ding,Jingren Zhou", "background": "本文探讨了如何为大型语言模型（LLMs）的测试时计算提供基本原理性的扩展定律。研究表明，通过两种策略，即淘汰赛方式和联赛方式算法，可以在计算量增加时提高准确率，将失败概率降低到零。", "innovation": "作者提出了两种简单的、基本原理上的可扩展性计算法则，适用于大型语言模型。这些建议包括两种新的算法：淘汰赛风格和联赛风格。这两种算法都能随着计算量的增加而导致失败概率呈指数或幂律函数衰减至零，同时不需要复杂的验证器或奖励模型等额外构件。", "conclusion": "通过广泛的实验，作者验证了这两种算法的理论，并展示了它们在不同模型和数据集上的卓越扩展特性。这些算法适用于实用应用并且易于为不同的任务进行调整。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.14571", "html_url": "https://arxiv.org/abs/2411.14571", "title": "学习、滞后、LLM解析：LLM对终端用户安全问题的响应", "title_en": "Learned, Lagged, LLM-splained: LLM Responses to End User Security Questions", "authors": "Vijay Prakash,Kevin Lee,Arkaprabha Bhattacharya,Danny Yuxing Huang,Jessica Staddon", "background": "回答终端用户的网络安全问题具有挑战性。尽管像GPT、LLAMA和Gemini这样的大型语言模型（LLMs）还不完美，但在回答多种非安全领域的问题上展现了一定潜力。本文研究了LLMs在终端用户安全领域的表现，通过对900个系统收集的安全相关问题进行定量评估，发现这些模型虽然具备广泛的一般性“知识”，但仍存在过时、不准确答案以及间接或不响应的服务方式等问题，这些都影响了信息的质量。", "innovation": "研究使用了900个系统收集的安全相关问题来评估LLMs的性能，揭示了模型在处理安全问题时存在的共同错误模式和局限性，从而为模型改进和用户使用策略提出了建议。", "conclusion": "本文指出了现有LLMs在处理终端用户安全问题时的局限，并建议了改进方向，同时还为用户在依赖LLMs寻求安全帮助时提供了策略建议。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.22366", "html_url": "https://arxiv.org/abs/2410.22366", "title": "一蹴而就：用于文本到图像扩散模型的稀疏自编码器", "title_en": "One-Step is Enough: Sparse Autoencoders for Text-to-Image Diffusion Models", "authors": "Viacheslav Surkov,Chris Wendler,Antonio Mari,Mikhail Terekhov,Justin Deschenaux,Robert West,Caglar Gulcehre,David Bau", "background": "对于大型语言模型（LLMs），稀疏自编码器（SAEs）已被证明能够将难以直接解释的中间表示分解为稀疏的可解释特征之和，从而更好地控制和完善后续分析。然而，对于文本到图像模型，类似的分析和方法一直缺乏。本文探讨了使用SAEs学习SDXL Turbo模型可解释特征的可能性，SDXL Turbo是一种多步文本到图像扩散模型。", "innovation": "本文首次将SAEs应用于文本到图像扩散模型的可解释性研究。通过在SDXL Turbo的一步设置下的去噪UNET的transformer模块的更新上训练SAEs，发现了它们在没有额外训练的情况下，可以推广到4步SDXL Turbo甚至不同的多步SDXL基础模型。此外，本文创建了RIEBench，一个基于表示的图像编辑基准，通过切换单独的SAE特征来编辑生成中的图像，展示了SAEs学习到的特征是可解释的，因果影响生成过程，揭示了模块的专业化。", "conclusion": "本文的工作确立了SAEs作为理解并操控文本到图像模型内部机制的有前途的方法。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.20445", "html_url": "https://arxiv.org/abs/2410.20445", "title": "TrajAgent：通过大模型与小模型协作的轨迹建模LLM-Agent框架", "title_en": "TrajAgent: An LLM-Agent Framework for Trajectory Modeling via Large-and-Small Model Collaboration", "authors": "Yuwei Du,Jie Feng,Jie Zhao,Yong Li", "background": "轨迹建模包括轨迹数据模式挖掘和未来预测，广泛应用于生活服务、城市交通和公共管理等领域。尽管提出了许多方法来解决轨迹建模中的具体问题，但数据的异质性和轨迹任务的多样性使得有效的轨迹建模对于领域专家来说同样是既重要又具有挑战性的任务。由于轨迹数据和任务的多样性，如何实现有效和可靠的轨迹建模是一个难题。", "innovation": "本文提出了一种名为TrajAgent的代理框架，该框架基于大型语言模型，并通过自动化建模来促进轨迹建模的鲁棒性和效率。该框架利用并优化了多种专业模型，以有效应对不同数据集中的各种轨迹建模任务。通过统一的执行和训练环境UniEnv，以及LLM代理与小型专业化模型之间的协作学习框架，TrajAgent实现了显著的性能提升，实验结果显示，TrajAgent在五个任务的四个真实数据集上提高了2.38%-69.91%的性能，相对于基线方法有所改善。", "conclusion": "TrajAgent通过大型语言模型和小型专业化模型的合作，为轨迹建模提供了一个有效的代理框架。这为自动化轨迹建模提供了新思路，实验结果表明其在不同任务上的性能有显著提升，证明了该框架的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.15805", "html_url": "https://arxiv.org/abs/2502.15805", "title": "FragFM: 分级框架通过片段级别离散流匹配实现高效分子生成", "title_en": "FragFM: Hierarchical Framework for Efficient Molecule Generation via Fragment-Level Discrete Flow Matching", "authors": "Joongwon Lee,Seonghwan Kim,Seokhyun Moon,Hyunwoo Kim,Woo Youn Kim", "background": "传统的分子图生成方法以原子级别为中心，但在生成多样化、复杂的分子化合物时效率不高且难以控制分子的物理化学性质。研究者通过引入FragFM框架，提出了通过片段级别的离散流匹配来提高分子生成的效率和可扩展性，同时提出了用于评估现代分子图生成模型性能的Natural Product Generation基准（NPGen），以更好地反映药物发现的需求。", "innovation": "FragFM框架是一种新颖的分级方法，通过片段级别的离散流匹配来高效生成分子。它使用粗到细的自动编码器在原子级别重建细节，并结合随机片段袋策略来有效管理广泛的片段空间。FragFM相比原子级别的方法，能更好地控制分子性质，具有更强的灵活性。同时，提出的NPGen基准不仅能够评估模型生成复杂天然产物分子的能力，还为药物发现提供了更加挑战性和有意义的评价标准。", "conclusion": "FragFM框架在多个不同分子生成基准测试中展示了出色的性能，证明了基于片段生成模型在大规模、属性感知分子设计方面的潜在优势，为进一步高效探索化学空间开辟了道路。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.08748", "html_url": "https://arxiv.org/abs/2503.08748", "title": "使用迹形式熵和变形对数的镜像下降和新型指数梯度算法", "title_en": "Mirror Descent and Novel Exponentiated Gradient Algorithms Using Trace-Form Entropies and Deformed Logarithms", "authors": "Andrzej Cichocki,Toshihisa Tanaka,Frank Nielsen,Sergio Cruces", "background": "本文探讨了通过迹形式熵定义的变形对数所生成的广泛镜像下降（MD）和广义指数梯度（GEG）算法。这些算法具有改善的收敛行为、对消失和爆炸梯度的鲁棒性，以及通过镜像映射内在适应非欧几里得几何结构的能力。", "innovation": "本文通过引入高性能变形熵，提出了一类新的MD和GEG算法，这些算法具有更好的收敛行为，能够适应非欧几里得几何结构，并且对梯度的消失和爆炸具有鲁棒性。同时，通过与Amari的自然梯度之间的深层联系，揭示了这些方法共享统一的信息几何学基础。", "conclusion": "本文框架将关键的第一阶MD优化方法统一到一个基于泛化Bregman发散的信息几何视角下，其中熵的选择决定了基础度量和对偶几何结构。通过对迹形式熵的调节参数实现自适应的几何选择，提高了鲁棒性和收敛性与传统的欧几里得优化相比。\n"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.07862", "html_url": "https://arxiv.org/abs/2502.07862", "title": "ADMN: 一种针对动态输入噪声和计算资源的分层自适应多模态网络", "title_en": "ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources", "authors": "Jason Wu,Yuyang Yuan,Kang Yang,Lance Kaplan,Mani Srivastava", "background": "多模态深度学习系统在动态场景中广泛应用，因多个传感模态提供了鲁棒性。然而，这些系统在应对计算资源（由多租户、设备异质性等引起的变化）和输入质量（从传感器信号污染、环境噪声等引起的变化）波动方面存在挑战。静态分配的多模态系统无法适应计算资源变化，而现有的动态网络在严格计算预算下运行困难。此外，这两种系统往往忽视了模态质量变化的影响，导致遭受重大污染的模态需要不必要的资源，而其他模态则缺乏所需的资源。", "innovation": "我们提出了ADMN，一种分层自适应深度多模态网络，能够解决上述两个挑战：通过调整所有模态的总活跃层数来满足严格的计算资源约束，并根据模态质量不断重新分配输入模态的层数。评估结果表明，ADMN可以在达到最先进的网络精度的同时，减少高达75%的浮点运算量。", "conclusion": "ADMN能够适应动态的输入噪声和计算资源变化，通过动态调整模态的活跃层数和进行资源的再分配，有效提升了系统的灵活性和效率。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.11364", "html_url": "https://arxiv.org/abs/2504.11364", "title": "大规模语言模型中的离线学习与遗忘", "title_en": "Offline Learning and Forgetting for Reasoning with Large Language Models", "authors": "Tianwei Ni,Allen Nie,Sapana Chaudhary,Yao Liu,Huzefa Rangwala,Rasool Fakoor", "background": "在推理时利用大规模语言模型进行搜索可以进一步增强模型解决复杂数学和推理问题的能力，但这种方法会显著增加计算成本和推理时间，因为模型需要生成和评估多个候选解决方案以确定有效的推理路径。", "innovation": "本文提出一种有效的集成搜索能力的方法，通过在成功的和失败的推理路径上对模型进行微调，这些路径是从各种搜索方法中得出的配对数据组成。通过降低学习率来解决 naive 微调可能退化模型搜索能力的问题，实验结果表明，在脱机微调中使用搜索生成的数据优于推理时的搜索基线，成功率提高了约 23%，推理时间减少了 180 倍，同时研究发现我们的学习和遗忘目标比监督微调和基于偏好的方法表现更好。", "conclusion": "本研究展示了通过脱机学习和遗忘目标在大型语言模型中的应用，提升了解决复杂问题的能力，同时显著降低了计算成本和推理时间。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.09060", "html_url": "https://arxiv.org/abs/2504.09060", "title": "多模态3D基因组预训练", "title_en": "Multimodal 3D Genome Pre-training", "authors": "Minghao Yang,Pengteng Li,Yan Liang,Qianyi Cai,Zhihang Zheng,Shichen Zhang,Pengfei Zhang,Zhi-An Huang,Hui Xiong", "background": "深度学习技术已经在计算生物学中的3D基因组各种分析任务中取得了显著的进步，但对3D基因组知识的理解仍然不够全面和深入。当前缺乏既能整合3D基因组结构和表观遗传图谱数据又能统一表示这些信息的模型，从而使得3D基因组相关的功能分析受限。", "innovation": "本文提出了一种新的多模态基础模型MIX-HIC，它首次结合了3D基因组结构和表观遗传图谱，实现了统一且全面的语义表示。为准确融合异构语义，设计了跨模态交互和映射块，增强了统一表示的鲁棒性，并通过大规模的数据集进行预训练，能够更好地探索3D基因组的功能意义。MIX-HIC在多个下游任务中显著优于现有先进方法，提供了推动3D基因组研究进步的重要资源。", "conclusion": "MIX-HIC在3D基因组领域的多模态预训练方面取得了显著成果，能够显著提升3D基因组知识理解与应用，为后续研究提供了有力支持。通过这种方式，可以更好地探索和利用3D基因组的复杂性和功能多样性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.17500", "html_url": "https://arxiv.org/abs/2502.17500", "title": "使用欧拉双参数对数的广义指数梯度算法", "title_en": "Generalized Exponentiated Gradient Algorithms Using the Euler Two-Parameter Logarithm", "authors": "Andrzej Cichocki", "background": "在文献中，如今已有超过五十个数学上验证完善的熵函数和相应的变形对数。为了研究广泛适用的有效更新方法，在该研究中，作者专注于具有迹形式熵的变形双参数对数类及其关联的广义指数梯度/梯度下降算法的研究，着重于评估变形指数函数以估计逆变形欧拉二参数对数，进而调整超参数以适应训练数据分布并适配所期望的梯度下降算法特性。", "innovation": "提出了一种新的广义指数梯度（GEG）算法类别，结合了使用镜像下降（MD）更新和欧拉双参数变形对数作为链接函数的Bregman发散应用。这种链接函数（称之为欧拉对数）关联于广泛类型的迹形式熵。通过估算变形指数函数来估计逆变形欧拉二参数对数，从而调整算法以适应训练数据的分布并优化梯度下降算法的特性。", "conclusion": "研究提出了具有迹形式熵的欧拉双参数对数关联的广义指数梯度/梯度下降算法类。通过学习调节超参数以适应数据分布，实现了对梯度算法的微调，以达到所期望的算法特性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.23502", "html_url": "https://arxiv.org/abs/2503.23502", "title": "使用预训练深度基础模型提升全景立体视觉匹配", "title_en": "Boosting Omnidirectional Stereo Matching with a Pre-trained Depth Foundation Model", "authors": "Jannik Endres,Oliver Hahn,Charles Corbière,Simone Schaub-Meyer,Stefan Roth,Alexandre Alahi", "background": "全景深度感知对于要求完整360度视野场景理解的移动机器人应用至关重要。基于相机的解决方案通过使用立体深度估计生成高分辨率的密集深度图，提供了一种经济有效的方法，无需依赖昂贵的主动传感。然而，现有的全景立体匹配方法在不同环境、深度范围和光照条件下的深度准确性仅限于有限的水平，这主要是由于缺乏实际数据。", "innovation": "提出了一种新的全景立体匹配方法DFI-OmniStereo，该方法利用大规模预训练基础模型进行相对单目深度估计，并在迭代优化的立体匹配架构中。引入了专用的两阶段训练策略，利用相对单目深度特征进行全景立体匹配，然后进行缩放不变微调。DFI-OmniStereo在现实世界的Helvepad数据集上达到了最先进的性能，将视差MAE降低了大约16%。", "conclusion": "DFI-OmniStereo通过利用预训练深度基础模型提升了全景立体匹配的准确性，相比之前的最佳方法，视差MAE减少了约16%。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.05860", "html_url": "https://arxiv.org/abs/2503.05860", "title": "软件工程中AI模型基准测试：回顾、搜索工具及提升基准质量的统一方法", "title_en": "Benchmarking AI Models in Software Engineering: A Review, Search Tool, and Unified Approach for Elevating Benchmark Quality", "authors": "Roham Koohestani,Philippe de Bekker,Begüm Koç,Maliheh Izadi", "background": "基准对于统一评估和再现性至关重要。人工智能在软件工程（AI4SE）领域的迅速增长产生了许多用于代码生成和错误修复等任务的基准。但这些基准的大量产生带来了许多挑战，包括任务间知识碎片化、选择相关基准的难度、基准建立标准缺失以及潜在存在的缺陷限制了其实用性。为应对这些挑战，需要系统地映射现有基准，为合理选择提供指导，并定义统一的基准开发准则以提高基准的质量和适应性。研究团队回顾了自2014年以来的247个研究，识别了273个AI4SE基准，通过分类和分析这些基准的局限性，揭示了当前实践中的空白。", "innovation": "研究团队开发了BenchScout，这是一种扩展的语义搜索工具，用于定位合适的基准。它采用了基于语境的嵌入自动聚类方法，并通过维度降低来工作。BenchScout在用户体验、有效性及直观性上的得分分别为4.5、4.0和4.1。此外，提出了BenchFrame，这是一种统一的框架，用于提高基准质量，将其应用于HumanEval产生了HumanEvalNext，这项改进后的新版本纠正了错误，提高了语言转换能力，扩大了测试覆盖率并增加了难度。通过对10个最先进的代码模型进行评估，研究展示了持续优化基准的必要性。研究还通过一个代理管道检验了BenchFrame的可扩展性，并在MBPP数据集上证实了其普遍适用性。所有的审查数据、用户研究材料和改进后的基准都公开发布。", "conclusion": "本研究通过系统回顾现有基准、开发BenchScout和BenchFrame框架，解决了基准化标准的挑战，为生成和改进高质量的基准提供了实用的解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.04242", "html_url": "https://arxiv.org/abs/2502.04242", "title": "一种用于多源迁移学习中优化转移数量的高维统计方法", "title_en": "A High-Dimensional Statistical Method for Optimizing Transfer Quantities in Multi-Source Transfer Learning", "authors": "Qingyue Zhang,Haohao Fu,Guanbo Huang,Yaoyuan Liang,Chang Chu,Tianren Peng,Yanru Wu,Qi Li,Yang Li,Shao-Lun Huang", "background": "在实际场景中的监督学习中，多源转移学习提供了一种有效的方法来应对数据稀缺问题，通过利用多个来源的任务数据。现有研究通常利用所有可用的源样本进行训练，这限制了训练效率并可能导致次优结果。", "innovation": "提出了一种理论框架，确定在多源转移学习中所需从每个源任务联合训练目标模型的最佳样本数量。引入了基于K-L散度的泛化误差度量，并通过高维统计分析将其最小化以确定每个源任务的最佳转移数量。此外，开发了架构无关的数据高效算法OTQMS来实现理论结果，并在多种架构和两个真实世界的基准数据集上进行了实验，证明了该算法在准确性和数据效率方面显著优于现有方法。", "conclusion": "提出的算法在准确性和数据效率方面显著优于现有方法，为多源转移学习中的目标模型训练提供了重要支持。相关代码和补充材料可在指定网址获取。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.00913", "html_url": "https://arxiv.org/abs/2501.00913", "title": "β-DQN: 通过进化行为提高深度Q学习", "title_en": "$β$-DQN: Improving Deep Q-Learning By Evolving the Behavior", "authors": "Hongming Zhang,Fengshuo Bai,Chenjun Xiao,Chao Gao,Bo Xu,Martin Müller", "background": "尽管许多高级探索方法已经提出，但由于其缺乏通用性和高计算成本，研究人员更倾向于使用像ε-greedy这样简单的方法。受此启发，本文介绍了β-DQN，这是一种简单而高效的新探索方法，它通过将行为函数β添加到标准DQN中来增强其标准DQN。该函数估计每个状态中每个动作被采取的概率。通过利用β，β-DQN生成了一种在状态-动作覆盖和过度估计偏差校正之间平衡探索的多样策略。设计了一个自适应元控制器在每轮中选择有效的策略，增强其灵活性和可解释性。β-DQN实现简单，几乎没有增加计算开销。实验表明，β-DQN在简单和复杂探索域上都表现出色，比现有基准方法在多种任务上更为优越，为提高深度强化学习中的探索提供了有效的解决方案。", "innovation": "推出了β-DQN，这是一种简单而高效的新探索方法，通过将行为函数β添加到标准DQN中来增强其标准DQN。利用β函数，它可以生成在状态-动作覆盖和过度估计偏差校正之间平衡的多种策略。设计了自适应元控制器，用于每轮选择有效的策略，提供了灵活性和可解释性。该方法增加的计算负担很小，但在各种任务中表现出色，显著优于现有基准方法，适用于改进深度强化学习中的探索。", "conclusion": "β-DQN提供了提高深度Q学习中探索的有效解决方案。通过在标准DQN中引入行为函数β，生成了多样策略，并通过自适应元控制器增强了在每轮中的灵活性和可解释性。实验表明，该方法不仅适用于简单环境，也能在复杂环境中取得显著效果，能够在广泛的任务中优于现有基准方法。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13043", "html_url": "https://arxiv.org/abs/2505.13043", "title": "跨域注视估计的泛化标签移位视角", "title_en": "A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation", "authors": "Hao-Ran Yang,Xiaohui Chen,Chuan-Xian Ren", "background": "现有的跨域注视估计（CDGE）方法通过提取域不变特征来减轻特征空间中的域移位，但泛化标签移位（GLS）理论证明了这种方法的不足。因此，需要一种新的方法来更好地解决跨域问题。", "innovation": "引入了泛化标签移位（GLS）的新视角，并将跨域问题建模为标签和条件移位问题。提出了一个泛化标签移位校正框架，并提出了一种基于截断高斯分布的重新加权策略来克服标签移位校正中的连续性挑战。进一步提出了概率感知的条件运算不一致性概率估计，以将重加权后的源分布嵌入条件不变学习中。", "conclusion": "在多种标准CDGE任务中，使用不同的骨干模型进行了详尽的实验，验证了该方法在跨域场景下的优越泛化能力和适用于各种模型的适用性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14969", "html_url": "https://arxiv.org/abs/2505.14969", "title": "STree: 混合状态空间模型的推测树解码", "title_en": "STree: Speculative Tree Decoding for Hybrid State-Space Models", "authors": "Yangchao Wu,Zongyue Qin,Alex Wong,Stefano Soatto", "background": "状态空间模型（SSMs）相比自回归（AR）Transformer模型更为高效，因为它们的状态可以综合所有过去的输入信息，无需缓存或重新处理滑动窗口中的令牌。然而，这些模型的状态可能会包含数千个令牌。现有的推测解码方法没有利用树验证方法，因为当前的SSMs尚无有效计算令牌树的方法。针对这一问题，提出了一种新的算法来在SSMs及其与Transformer层的混合架构中进行树验证推测解码。", "innovation": "本文首次提出了针对状态空间模型（SSMs）及其与Transformer层混合架构的可扩展的树验证推测解码算法。通过利用累积状态转换矩阵的结构，实现了最小额外开销下进行树验证推测解码。此外，还针对SSMs及混合模型的硬件实施进行了优化，改进了自回归Transformer的推测解码方法。实验证明，在三种基准测试中，即使使用基础草稿模型和树结构，此方法也优于传统的推测解码。", "conclusion": "通过树验证推测解码，该研究提高了混合状态空间模型的效率，并为未来进一步加速模型推理提供了可能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18976", "html_url": "https://arxiv.org/abs/2505.18976", "title": "GraSS: 可扩展的数据归因与梯度稀疏化及稀疏投影", "title_en": "GraSS: Scalable Data Attribution with Gradient Sparsification and Sparse Projection", "authors": "Pingbang Hu,Joseph Melkonian,Weijing Tang,Han Zhao,Jiaqi W. Ma", "background": "梯度基数据归因方法，如影响函数，对于理解单个训练样本的影响至关重要。然而，这些方法常常受限于每次样本梯度计算所需的高计算和内存成本，这限制了它们的可扩展性。", "innovation": "本文提出了GraSS，一个新的梯度压缩算法及其针对线性层的变体FactGraSS，该算法显式利用了每次样本梯度的固有稀疏性，实现了次线性的空间和时间复杂度。实验表明这种做法有效，不仅加快了速度，还保有一定的数据影响准确性。特别地，FactGraSS 在亿级模型上的吞吐量提升高达165% 比之前的最先进基线更为优秀。", "conclusion": "我们的代码可在以下链接中公开获取：this https URL."}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10978", "html_url": "https://arxiv.org/abs/2505.10978", "title": "Group-in-Group Policy Optimization for LLM Agent Training", "title_en": "Group-in-Group Policy Optimization for LLM Agent Training", "authors": "Lang Feng,Zhenghai Xue,Tingcong Liu,Bo An", "background": "近期，基于群体的强化学习（RL）取得了进展，推动了数学推理等单回话任务中的大规模语言模型（LLMs）的进步。然而，现有方法在扩展到多回话LLM代理训练方面仍有限制。与静态任务不同，代理-环境交互往往需要许多步骤才能完成，其间还可能产生稀疏或延迟的奖励。这使得在各个步骤之间准确归因奖励变得尤为困难。", "innovation": "本文提出了基于群体的群体策略优化（GiGPO），这是一种新颖的RL算法，能够为LLM代理提供精细的奖励归因，同时保留群体RL的优良特性：无批评家、低内存占用和稳定收敛。GiGPO引入了两层结构来估计相对优势：在回话级别，GiGPO基于完整轨迹的群体计算宏观相对优势；在步骤级别，GiGPO通过识别轨迹中重复的环境状态引入锚定状态分组机制，反向构建步骤级别群体。源自相同状态的动作被分组在一起，能进行微观相对优势估计。这种分层结构有效地捕捉到了全局轨迹质量和局部步骤效果，无需依赖辅助模型或额外试运行。", "conclusion": "我们分别在ALFWorld和WebShop等代理基准测试以及集成工具的搜索增强问答任务中，使用了Qwen2.5-1.5B/3B/7B-Instruct评估了GiGPO。结果表明，GiGPO实现了每步骤的精细奖励信号，ALFWorld上的性能提高了超过12%，WebShop上的性能提高了超过9%，在QA任务上也表现更优（3B任务上为42.1%，7B任务上为47.2%），同时保持相同的GPU内存开销、相同的LLM试运行次数且几乎没有额外的时间成本。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.19467", "html_url": "https://arxiv.org/abs/2504.19467", "title": "BRIDGE: 评估大型语言模型理解实际临床实践文本的标准", "title_en": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text", "authors": "Jiageng Wu,Bowen Gu,Ren Zhou,Kevin Xie,Doug Snyder,Yixing Jiang,Valentina Carducci,Richard Wyss,Rishi J Desai,Emily Alsentzer,Leo Anthony Celi,Adam Rodman,Sebastian Schneeweiss,Jonathan H. Chen,Santiago Romero-Brufau,Kueiyu Joshua Lin,Jie Yang", "background": "大型语言模型（LLMs）在医学应用方面具有巨大潜力，并且正在迅速发展，新模型的发布速度加快。然而，对大规模真实世界数据，如电子健康记录（EHRs）的基准测试至关重要，因为临床决策直接基于这些数据，但当前的评估依然有限。大多数现有的基准评估依赖于医学考试风格的问题或PubMed中的文本，未能捕捉到真实世界临床数据的复杂性。此外，许多评估专注于特定的应用场景，限制了其在更广泛的临床使用中的通用性。因此，需要一个涵盖多语言和多任务的真实世界临床数据基准来评估LLMs在实际临床文本理解中的性能。BRIDGE（Benchmark of Real-World iNterachatges with GeNerative EFIciency）正是为解决这一问题而设计的多语言综合基准，它包含了87个任务，来源于九种语言的真实世界临床数据来源，涵盖了8个主要任务类型和六个临床阶段的20种代表性应用，并涉及14个临床专业领域。", "innovation": "BRIDGE是首次提出的多语言、综合性的大型语言模型基准，涵盖了真实世界临床数据源，包含了87个任务，这些任务来自九种语言的各种临床场景。BRIDGE首次系统性地评估了95个LLMs（包括DeepSeek-R1、GPT-4o、Gemini系列和Qwen3系列）在不同推理策略下的性能。研究结果揭示了模型规模、语言、自然语言处理任务和临床专业领域之间的性能差异。BRIDGE证明，开源LLMs可以达到与专有模型相当的性能，而基于较旧架构的医学调整LLMs通常不如更新的一般目的模型。BRIDGE和对应的排行榜作为开发和评估新LLMs的重要资源和独特参考，特别是在实际临床文本理解方面。BRIDGE排行榜：[链接]（this https URL）", "conclusion": "BRIDGE和其对应的排行榜为开发和评估新的LLMs在实际临床文本理解方面提供了基础资源和独特参考。通过BRIDGE，研究者可以更好地理解和改善大型语言模型在临床实践中的应用，提高医疗领域的自动化和智能化水平。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13898", "html_url": "https://arxiv.org/abs/2505.13898", "title": "语言模型是否有效利用了它们的深度？", "title_en": "Do Language Models Use Their Depth Efficiently?", "authors": "Róbert Csordás,Christopher D. Manning,Christopher Potts", "background": "现代的大型语言模型（LLMs）变得越来越深，深度与性能之间存在相关性，但存在边际效应递减的现象。然而，这些模型是否有效地利用了它们的深度尚不清楚。具体而言，它们是否通过叠加更多层次开发出浅层模型无法实现的高级计算，还是仅仅将同样的计算分配到更多的层中。为了回答这些问题，研究者们分析了Llama 3.1、Qwen 3以及OLMo 2模型家族的残差流。通过这种方法，研究者发现了一些可能的答案。例如，模型后半部分的层次几乎不比前半部分的权重更大；在多跳任务中，模型并没有利用增加的深度来组合更多结果的证据；研究者试图直接证明更深的模型是否使用它们的额外层来执行新的计算，通过将较浅模型的残差流映射到更深模型中。结果显示，相同相对深度的层之间对应的最好。这意味着，更大的模型只是将同样的计算分散到更多的层中。", "innovation": "研究团队首次系统地分析了几个知名模型的残差流，通过比较子层输出与残差流，发现模型前半部分的层贡献大于后半部分；后半部分层对后续计算和输出预测的影响较小；在多跳任务中，未能找到模型利用增加的深度来组合更多结果的证据；使用线性映射方法从较浅模型的残差流到更深模型，表明相同相对深度的层互为最佳映射，提示深层模型仅用来执行更细致的残差调整。", "conclusion": "研究发现，更深的模型并没有利用其深度来学习新的计算方式，而是仅使用更大的深度来执行更精细的残差调整。这种观察可能有助于解释为什么对于堆叠的Transformer架构，增加规模会导致边际效应递减。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11930", "html_url": "https://arxiv.org/abs/2505.11930", "title": "通过二维产品逻辑探讨时序GNN的逻辑演绎能力", "title_en": "The Logical Expressiveness of Temporal GNNs via Two-Dimensional Product Logics", "authors": "Marco Sälzer,Przemysław Andrzej Wałęga,Martin Lange", "background": "近年来，不同类型的神经架构（包括图神经网络GNN、变换器和递归神经网络）的表达能力已被逻辑和形式语言理论等工具进行刻画。随着基本架构能力的逐步理解，研究焦点转向了结合多种架构范式的模型。特别是在时序扩展的GNN中，它们将空间（图结构）和时间（随时间的演变）维度结合，这种模型尤为关键但也更为复杂。本文旨在探讨时序GNN的逻辑表达能力，通过将其与二维产品逻辑联系起来进行研究", "innovation": "本文首次提出了时序GNN的逻辑表达能力研究，并表明时序GNN的表达能力取决于其空间和时间组件的组合方式。具体而言，递归应用静态GNN的时间GNN能够捕捉（过去）命题时序逻辑PTL和模态逻辑K定义的所有性质。相比之下，如图和时间TGNN和全局TGNN的架构仅能表达该逻辑的受限片段，其中时空操作符之间的交互受到语法上的限制。这些结果为我们理解和分析时序GNN提供了新的视角", "conclusion": "本文通过将时序GNN与二维产品逻辑联系起来，首次提出了关于时序GNN逻辑表达能力的重要结果，揭示了时序GNN的表达能力与其空间和时间组件组合方式之间的关系"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21724", "html_url": "https://arxiv.org/abs/2505.21724", "title": "OmniResponse: 在双人互动中的在线多模态对话响应生成", "title_en": "OmniResponse: Online Multimodal Conversational Response Generation in Dyadic Interactions", "authors": "Cheng Luo,Jianghui Wang,Bing Li,Siyang Song,Bernard Ghanem", "background": "在线对话中，产生与讲话者多模态输入同步的自然同步听者反馈是一项新的挑战性任务。现有的方法通常无法准确生成与听者面部反应同步的声音响应，这需要一种新的方法来解决这些挑战。", "innovation": "作者提出了Online Multimodal Conversational Response Generation (OMCRG) 任务及其解决方案OmniResponse。OmniResponse是一个多模态大型语言模型 (MLLM)，它以自回归的方式生成准确的多模态听者响应。OmniResponse结合使用了Chrono-Text Markup精确地对生成的语言标记进行时间戳，并使用可控的在线文本转语音(TTS)模块 TempoVoice，以确保语音响应与面部反应同步。", "conclusion": "作者创建了ResponseNet数据集，包含696个详细的双人互动场景，包括同步的屏幕分割视频、多通道音频、转录以及面部行为的注释。在ResponseNet数据集上的综合评估表明，OmniResponse在语义语音内容、音频-视频同步性以及生成质量方面超过了基线模型。数据集、代码和模型均已公开发布，旨在推进OMCRG研究。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21923", "html_url": "https://arxiv.org/abs/2505.21923", "title": "FALCON：一种完整的基于布局约束的模拟电路设计的ML框架", "title_en": "FALCON: An ML Framework for Fully Automated Layout-Constrained Analog Circuit Design", "authors": "Asal Mehradfar,Xuzhe Zhao,Yilun Huang,Emir Ceyani,Yankai Yang,Shihao Han,Hamidreza Aghasi,Salman Avestimehr", "background": "设计符合性能规格的模拟电路是一个复杂且多阶段的过程，涉及拓扑选择、参数推断和布局可行性。当前的设计方法通常是人工指导的，效率低下且耗时。", "innovation": "FALCON是一个统一的机器学习框架，实现了基于性能的模拟电路从设计到布局的完全自动化。它通过性能驱动的分类器来选择合适的电路拓扑，并使用自定义的基于边的图神经网络进行拓扑和参数到性能的映射，实现基于梯度的参数推断和布局感知设计。此外，FALCON利用可微布局代价，通过解析方程捕捉寄生和频率依赖效应，对设计规则进行约束。", "conclusion": "FALCON通过大规模自定义数据集（包含1M个毫米波电路）的训练和评估，展示了99%以上的拓扑推断准确率、小于10%的性能预测相对误差以及每实例不到1秒的高效布局感知设计。这些成果将FALCON确立为端到端模拟电路设计自动化的实用和可扩展的基础模型。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16947", "html_url": "https://arxiv.org/abs/2505.16947", "title": "MixAT：结合连续和离散对抗训练的LLMs", "title_en": "MixAT: Combining Continuous and Discrete Adversarial Training for LLMs", "authors": "Csaba Dékány,Stefan Balauca,Robin Staab,Dimitar I. Dimitrov,Martin Vechev", "background": "尽管最近在大型语言模型（LLM）的安全性和对齐方面做出了许多努力，当前针对前沿LLM的对抗攻击仍然能够一致地产生有害生成。虽然对抗训练在传统机器学习模型中被广泛研究并显示出显著提高模型鲁棒性的效果，但其在LLM中的优势和不足还不是很清楚。现有的离散对抗攻击虽然能够有效地生成有害内容，但用具体的对抗提示训练LLMs往往计算成本高，于是导致使用连续松弛的方法。同时，尽管连续扰动训练在效果和泛化能力上具有优势，但它们并不总是能够捕捉到所有由离散攻击利用的漏洞。因此，存在一个需要弥合的缺口，即如何通过结合离散和连续对抗攻击来提高LLM的鲁棒性。", "innovation": "本文提出了MixAT，一种新的方法，在训练过程中结合了更强的离散攻击和更快的连续攻击。作者使用ALO-ASR指标严格评估MixAT在一系列先进的攻击方法上的性能，并证明MixAT相比之前的防御措施在鲁棒性方面（ALO-ASR < 20%）有了显著提高，同时在运行时间上与基于连续松弛的方法相当。此外，作者还分析了MixAT在实际部署中的表现，探讨了聊天模板、量化、低秩适应器和温度等因素如何影响对抗训练和评估，并揭示了当前方法中的盲点。结果表明，MixAT的离散-连续防御在计算开销最小的情况下提供了更为合理的鲁棒性和准确性权衡，显示出其构建更安全的LLMs的潜力。", "conclusion": "研究结果表明，MixAT的离散-连续防御提供了一种原理上较强的、在鲁棒性和准确性之间具有最小计算开销的权衡方式，强调了其用于建设更安全的LLMs的巨大潜力。研究团队还提供了MixAT的代码和模型。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00481", "html_url": "https://arxiv.org/abs/2506.00481", "title": "PVP: 一种包含说服策略、观众特征和说服评分的个性化视觉说服图像数据集", "title_en": "PVP: An Image Dataset for Personalized Visual Persuasion with Persuasion Strategies, Viewer Characteristics, and Persuasiveness Ratings", "authors": "Junseo Kim,Jongwook Han,Dongmin Choi,Jongwook Yoon,Eun-Ju Lee,Yohan Jo", "background": "视觉说服利用视觉元素影响认知和行为，在广告和政治沟通等领域至关重要。近年来，随着人工智能的发展，自动生成个性化说服性图像的系统前景广阔。然而，这一领域的一个主要瓶颈是缺乏能够将图像的说服力与评价图像的人的个人信息联系起来的综合数据集。为了解决这一缺口并促进个性化视觉说服的技术进步，该论文发布了包含28,454幅说服性图像、596条消息和9种说服策略的个性化视觉说服(PVP)数据集。该数据集包含了2,521位人类标注者对图像的说服力评分，以及他们的人口统计学和心理学特征（个性特征和价值观）等信息。", "innovation": "该研究创新地开发了一个个性化视觉说服数据集（PVP），该数据集涵盖了广泛的说服性图像、消息和策略。同时，该数据集包括了由2,521名人类标注者提供的说服力评分及其相关的人口统计学与心理学特征，这对个性化视觉说服技术的发展具有重要意义。基于此数据集，该研究还开发了一个说服性图像生成器和自动评估器，并建立了基准线标准，揭示了心理特征在生成和评估说服性图像中的价值", "conclusion": "研究表明，结合心理特征可以有效提高说服性图像的生成和评估效果，为进一步个性化视觉说服研究提供了宝贵洞见。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01374", "html_url": "https://arxiv.org/abs/2506.01374", "title": "REASONING COMPILER: 由大语言模型引导的高效模型服务优化", "title_en": "REASONING COMPILER: LLM-Guided Optimizations for Efficient Model Serving", "authors": "Sujun Tang,Christopher Priebe,Rohan Mahapatra,Lianhui Qin,Hadi Esmaeilzadeh", "background": "虽然模型服务解锁了前所未有的功能，但服务大型模型的成本继续成为广泛使用和快速创新的重要障碍。现有编译器优化在很多方面已实现了显著的性能提升，但由于可能的转换空间庞大且高度相互依赖，它们在神经网络工作负载方面遇到了挑战。尽管现有的随机搜索技术可以有效，但它们往往是样本效率低的，并且无法充分利用编译决策下的结构化上下文。本文旨在研究大型语言模型（LLMs）在无需重新训练的情况下，能否利用编译优化的认知空间显著提高样本效率。", "innovation": "本文提出了一个新颖的编译框架（称为Reasoning Compiler），将优化过程表述为由大型语言模型（LLM）和结构化蒙特卡洛树搜索（MCTS）引导的逐步、具有上下文感知的决策过程。LLM作为建议机制，根据当前程序状态和累积的性能反馈提出硬件驱动的转换。MCTS利用LLM生成的建议来平衡探索和利用，促进广泛的编译优化空间的结构化、上下文相关的遍历。通过在比现有神经编译器少得多的样本中实现显著的速度提升，该方法展示了LLM引导的推理在编译优化领域中的潜在价值。", "conclusion": "本文的工作表明，LLM引导的推理有可能改变编译优化的格局。通过提供显著的速度提高，尽管所需样本较少，我们的方法演示了LLM指导下的优化的巨大潜力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.02703", "html_url": "https://arxiv.org/abs/2506.02703", "title": "信用卡欺诈检测方法中的数据泄漏和误导性能：一项关键检视", "title_en": "Data Leakage and Deceptive Performance: A Critical Examination of Credit Card Fraud Detection Methodologies", "authors": "Mohammed Hilal Al-Kharusi,Khizar Hayat,Khalil Bader Al Ruqeishi,Haroon Rashid Lone", "background": "在当今数字时代，传统的《古兰经》诵读（诵读技巧）学科面临着重大教育挑战。尽管现代科技提供了无与伦比的学习机会，现有的自动评估诵读系统的接受度和教育效果表现不尽如人意。现有的适应自动语音识别（ASR）系统的做法大多侧重于词识别，而忽视了对音质的定性评价。这些系统存在数据偏见、人口统计差异及难以提供改善反馈等局限性。", "innovation": "本文提倡从数据导向的方法转向知识为基础的计算框架。通过利用《古兰经》文本的不变性及其明确的诵读规则，提出了以基于规则的声学建模为核心，围绕标准发音原则和发音点来构建有效的评估系统，而非依赖从有缺陷或偏见数据中抽取的统计模式。强调结合语言专业知识和高级音频处理技术的发展，以实现可靠、公平和教育有效的工具的开发，为全球学习者提供帮助。", "conclusion": "未来，《古兰经》诵读自动评估系统的设计和构建需要采取混合系统的方法，结合语言专长与先进的音频处理技术，从而开发出可靠、公平且教育有效的工具，以真实地协助全球学习者。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05316", "html_url": "https://arxiv.org/abs/2506.05316", "title": "通过难度导向的在线数据选择和回放卷积提高大规模语言模型的强化学习微调数据效率", "title_en": "Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay", "authors": "Yifan Sun,Jingyan Shen,Yibin Wang,Tianyu Chen,Zhendong Wang,Mingyuan Zhou,Huan Zhang", "background": "强化学习（RL）已成为有效微调大型语言模型（LLM）的方法，特别有助于增强其推理能力。然而，RL微调依然高度耗资源，现有工作很大程度上忽视了数据效率的问题。", "innovation": "提出两种技术以提高LLM RL微调的数据效率：难度导向的在线数据选择和回放卷积。引入自适应难度的概念来指导在线数据选择，优先选择更可能提供信息性学习信号的中等难度问题。为有效地估算自适应难度，开发了一种基于注意力的框架，仅对一小部分参考问题进行卷积。剩余问题的自适应难度则是基于其与这组的相似性进行估算。为进一步降低卷积成本，提出了一种借鉴传统RL中的经验回放机制的回放卷积技术，它可以重用最近的卷积以降低每步计算成本并保持稳定的更新。", "conclusion": "在6种LLM-数据集组合的实验中，我们的方法在将RL微调时间减少了23%到62%的情况下达到了与原GRPO算法相同水平的性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05699", "html_url": "https://arxiv.org/abs/2506.05699", "title": "评估工程高等教育中的AI辅助学习助手：学生活动、伦理挑战及政策影响", "title_en": "Evaluating AI-Powered Learning Assistants in Engineering Higher Education: Student Engagement, Ethical Challenges, and Policy Implications", "authors": "Ramteja Sajja,Yusuf Sermet,Brian Fodale,Ibrahim Demir", "background": "随着生成式AI在高等教育中的应用越来越广泛，理解学生如何使用这些技术至关重要，以实现负责任的采用。这项研究通过一项在大型R1公立大学的本科土木与环境工程课程中实施的AI驱动学习框架——教育AI枢纽，来评估学生对AI技术的使用情况。", "innovation": "该研究采用混合方法设计，结合前后的问卷调查、系统使用日志以及对学生AI互动的定性分析，全面考察了学生对信任、伦理、可用性和学习成果的感知。研究发现，在使用AI助手方面，学生们认为它提高了便捷性和舒适性，特别是在完成作业和理解概念方面更为有用，但对它的教学质量持有不同的观点。学生活动的检验结果揭示了伦理上的不确定性，特别是政策和学术诚信方面的担忧，是显著挑战。总体来看，学生们认为AI是一种辅助而非替代物，这突显了用户体验、伦理透明度和教师指导在促进有意义的AI参与中的重要性。", "conclusion": "共有71名学生参与了这项研究，产生了600多条AI互动和100份调查问卷，提供了定量和定性的学习参与洞察，强调了在推动正式AI参与中的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.05426", "html_url": "https://arxiv.org/abs/2506.05426", "title": "Mixture-of-Experts Meets In-Context Reinforcement Learning", "title_en": "Mixture-of-Experts Meets In-Context Reinforcement Learning", "authors": "Wenhao Wu,Fuhong Liu,Haoru Li,Zican Hu,Daoyi Dong,Chunlin Chen,Zhi Wang", "background": "在基于上下文的强化学习（In-context Reinforcement Learning，ICRL）中，通过提示条件化来适应下游任务的强化学习（RL）代理已显示出巨大前景。然而，该领域仍面临两大挑战：状态-动作-奖励数据的内在多模态性和决策任务的多样化和异质性。为了应对这些挑战，现有框架和方法尚未完全利用ICRL的能力。", "innovation": "本文提出的T2MIR（Token-和Task-wise MoE for In-context RL）框架将mixture-of-experts（MoE）架构引入基于transformer的决策模型中，通过引入token-wise MoE和task-wise MoE，能够在多模态输入中捕捉不同语义，并针对各种任务路由到特定专家，缓解梯度冲突。此外，通过对比学习方法最大化任务及其路由器表示之间的互信息，提高任务路由的精确度。", "conclusion": "全面的实验表明，T2MIR显著提高了ICRL的在上下文学习能力，并在各种基线方法中表现优异。将MoE引入ICRL，为这一领域提供了一个简单且可扩展的架构增强，一步接近语言和视觉社区的成就。代码可在此URL下载：http://github.com/your-repo-url"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10754", "html_url": "https://arxiv.org/abs/2506.10754", "title": "BNMusic: 将环境噪声融入个性化音乐", "title_en": "BNMusic: Blending Environmental Noises into Personalized Music", "authors": "Chi Zuo,Martin B. Møller,Pablo Martínez-Nuevo,Huayang Huang,Yu Wu,Ye Zhu", "background": "在被环境噪声干扰的情况下，声音工程中常用的声音掩蔽技术通过使用其他具有主导性但不那么侵入性的声音来覆盖噪声以减少烦恼。然而，主导声音与噪声之间的不对齐（如节奏错位）往往需要增加音量才能有效掩蔽。受跨模态生成技术进展的启发，本文提出了一种新的声音掩蔽方法，旨在通过根据用户提供的文本提示生成个性化音乐来将环境噪声融入音乐中，从而降低噪声的注意度。", "innovation": "本文提出了一种名为BNMusic（将噪声融入个性化音乐）的框架，该框架包括两个关键阶段。第一阶段使用梅尔频谱图表示生成包含噪声音乐精髓的完整音乐。第二阶段适应性地放大生成的音乐片段，以进一步减少噪声感知并增强融合效果，同时保持听觉质量。该方法在MusicBench、EPIC-SOUNDS和ESC-50上的全面评估中证明了其有效性。", "conclusion": "实验结果表明，通过将环境噪声与节奏对齐、适应性放大和令人愉悦的音乐片段相结合，BNMusic框架能够最大限度地降低噪声注意度，从而提升整体声学体验。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17939", "html_url": "https://arxiv.org/abs/2506.17939", "title": "GEMeX-RMCoT: 一种增强的具有区域意识的多模态推理医学VQA数据集", "title_en": "GEMeX-RMCoT: An Enhanced Med-VQA Dataset for Region-Aware Multimodal Chain-of-Thought Reasoning", "authors": "Bo Liu,Xiangyu Zhao,Along He,Yidi Chen,Huazhu Fu,Xiao-Ming Wu", "background": "医学视觉问答旨在通过使模型能够基于医学影像回答自然语言问题来支持临床决策。尽管近期多模态学习的进展显著提升了性能，但当前的方法仍然存在答案可靠性有限、解释性差的问题，这妨碍了临床医生和患者理解并信任模型的输出结果。", "innovation": "该工作首先提出了一个区域感知的多模态链推理（RMCoT）数据集，该数据集包含一系列中间推理步骤，这些步骤能够明确标记医疗影像中的相关视觉区域，从而提供细粒度的解释性。此外，引入了一种新的可验证奖励机制用于强化学习，以引导训练后的模型行为，提高模型推理过程和最终答案的一致性。通过这种方法，仅使用训练数据量的八分之一便能达到相当的性能，展示了提议方法的效率和有效性。", "conclusion": "该方法通过提出RMCoT数据集和新的可验证奖励机制，显著提高了医学视觉问答系统的解释性和一致性，同时证明了模型在少量训练数据上的高效性能。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.16925", "html_url": "https://arxiv.org/abs/2506.16925", "title": "使用机器学习模拟玻色—爱因斯坦凝聚体的测温法", "title_en": "Thermometry of simulated Bose--Einstein condensates using machine learning", "authors": "Jack Griffiths,Steven A. Wrathmall,Simon A. Gardiner", "background": "由于传统测量技术的破坏性和固有的实验不确定性，精确测定超低温玻色气体的热力学参数仍然具有挑战性。我们展示了一种使用机器学习算法快速非破坏性地从单张图像中提取有限温度玻色气体原位密度剖面的化学势和温度的方法。我们的卷积神经网络仅在谐振子陷阱配置中的准二维‘煎饼’凝聚物上进行训练。该模型实现了参数提取只需短短数秒的时间。模型还展示了跨陷阱几何形状和热化动力学的某些零样本迁移能力，成功估计了环状陷阱凝聚物的温度（尽管没有化学势的估计），尽管在训练过程中从未接触过这种几何结构，并且在相对短暂的非平衡状态演化过程中维持了预测准确性。这些结果表明，监督学习可以克服传统超低温原子测温法的限制，将其扩展到更广泛的几何配置、温度范围和额外参数，从而实现量子气体实验的全面实时分析。这些能力有望大幅简化实验工作流程，提高量子流体系统中测量精度。", "innovation": "提出了一种基于机器学习的非破坏性方法，可以从单张图像中快速估计超低温玻色气体的化学势和温度。该方法基于卷积神经网络的训练，能在极短时间内完成参数提取，并展示了跨不同几何形状和热化动力学的零样本迁移能力。", "conclusion": "这种基于监督学习的方法能够克服传统超低温原子测温法的限制，未来有可能拓展到更广泛的几何结构、温度范围及其他参数，实现量子气体实验的全面实时分析。这些能力有望简化实验工作流程，提高测量精度。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06041", "html_url": "https://arxiv.org/abs/2508.06041", "title": "动态逐层精度分配的运行时模型自适应：DP-LLM", "title_en": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment", "authors": "Sangwoo Kwon,Seong Hoon Seo,Jae W. Lee,Yeonhong Park", "background": "在处理具有不同运行时约束（如延迟和准确性）的设备上大型语言模型（LLMs）查询时，传统方法难以有效应对。多尺度量化通过叠加不同位宽的模型变体，实现了模型运行时的高效调整，但如何正确配置模型以匹配目标精度或延迟仍是一个开放问题。", "innovation": "提出了一种新的机制DP-LLM，该机制根据输入值动态地为每一层分配精度。实验结果表明，DP-LLM 在性能-延迟权衡方面优于现有方法。", "conclusion": "实验结果证明，DP-LLM 能够在多个模型和基准测试中实现更优的性能-延迟权衡，统治了先前的方法。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.04536", "html_url": "https://arxiv.org/abs/2506.04536", "title": "NOBLE -- 一种基于生物启发潜变量嵌入的神经算子，用于捕捉生物神经元模型中的实验变异性", "title_en": "NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models", "authors": "Luca Ghafourpour,Valentin Duruisseaux,Bahareh Tolooshams,Philip H. Wong,Costas A. Anastassiou,Anima Anandkumar", "background": "理解神经元在大脑中的功能是基础性的，为此，生成生物现实模型至关重要，这需要整合多模态的神经元数据集并建立因果关系。然而，现有的建模方法受限于实验神经元数据的有限性和内在变异性。当前的生物学现实模型的确定性形式主义无法考虑到实验中观察到的自然变异性。尽管深度学习在这个领域变得越来越相关，但它无法捕捉神经元的完整生物物理复杂性，包括非线性电压动态和变异性。为解决这些不足，引入了NOBLE，一种神经算子框架，该框架从一个连续的频率调制的可解释神经元特征嵌入中学习到细胞电位响应与当前注入之间的映射。该模型通过从生物现实模型生成的合成数据进行训练，可以预测考虑实验内在变异性下的神经动力学分布。与传统的生物学现实模型不同，在嵌入空间中插值可以生成具有与实验观察响应一致动力学的模型。NOBLE可以高效地生成模拟实验数据且表现出试次间变异的合成神经元，比数值解法快4200倍。NOBLE是第一个通过真实实验数据验证其泛化的深层学习框架，可以捕捉到神经元的基本属性，这对于理解细胞组成和运算、神经形态架构、大规模大脑电路和通用神经AI应用具有重要意义。", "innovation": "NOBLE是一种新颖的神经算子框架，通过学习一个连续的频率调制的可解释神经元特征嵌入到细胞电位响应的映射。该模型能够预测考虑实验内在变异性下的神经动力学分布。不同于传统的生物学现实模型，它可以在嵌入空间中生成具有与实验观察响应一致动力学的模型。此外，NOBLE通过从生物现实模型生成的合成数据进行训练，能够高效地生成接近实验数据且具有试次间变异的合成神经元，并通过真实实验数据验证其泛化能力。", "conclusion": "NOBLE作为一种新型的神经算子框架，通过学习连续频率调制的可解释神经元特征嵌入到细胞电位响应之间的映射，能够高效地生成接近实验数据且具有试次间变异的合成神经元，并通过真实实验数据验证其泛化能力。它通过捕捉到神经元的基本属性开启了对细胞组成和运算、神经形态架构、大规模大脑电路和通用神经AI应用的更好理解的大门。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01271", "html_url": "https://arxiv.org/abs/2507.01271", "title": "PULSE: 实践导向的大型多模态模型遗忘评估场景", "title_en": "PULSE: Practical Evaluation Scenarios for Large Multimodal Model Unlearning", "authors": "Tatsuki Kawakami,Kazuki Egashira,Atsuyuki Miyai,Go Irie,Kiyoharu Aizawa", "background": "近年来，遗忘技术吸引了人们的注意，这些技术旨在使模型“忘记”之前学习的信息，以解决大型语言模型（LLMs）和大型多模态模型（LMMs）中的隐私和版权问题。尽管已经为LLMs建立了多个遗忘基准，但对于LMMs的遗忘实践评价框架研究较少。现有针对LMMs的遗忘基准仅考虑单一遗忘操作去学习微调知识的场景，而PULSE引入了两个关键视角，分别是预训练知识遗忘和长期可持续性评估，提出了适用于LMMs的实际遗忘场景。", "innovation": "PULSE提出了一个双视角的评估协议，包括预训练知识遗忘和长期可持续性评估，旨在解决现有方法在单一操作和顺序请求下的局限性。研究表明，某些技术虽然能够成功遗忘通过微调获得的知识，但在遗忘预训练阶段学习的信息时存在挑战。此外，能够一次性遗忘目标数据集的方法，在数据被分割后按顺序遗忘时性能会显著下降。", "conclusion": "研究结果表明，虽然有技术能够成功遗忘通过微调获得的知识，但在遗忘预训练阶段学习的信息时存在困难。同时，能够一次遗忘一批目标数据的方法，在数据被分割按顺序遗忘时会表现出显著的性能下降。因此，需要进一步研究改进现有的遗忘技术，以更好地处理复杂的遗忘场景。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13771", "html_url": "https://arxiv.org/abs/2506.13771", "title": "LittleBit: 通过潜在因子化实现超低比特量化", "title_en": "LittleBit: Ultra Low-Bit Quantization via Latent Factorization", "authors": "Banseok Lee,Dongkyu Kim,Youngcheon You,Youngmin Kim", "background": "部署大型语言模型（LLMs）通常面临巨大的内存和计算成本挑战。量化提供了一种解决方案，但亚1比特（sub-1-bit）下的性能降级仍然是一个特别难以解决的问题。本文介绍了一种名为LittleBit的新型方法，以实现极端的LLM压缩。它能将每权重比特数（BPW）降至0.1位，实现近31倍的内存减少，例如将Llama2-13B的大小压缩至不到0.9 GB。LittleBit使用潜在矩阵分解以低秩形式表示权重，之后将这些因子二进制化。为补偿这种极端精度带来的信息损失，它整合了多尺度补偿机制，包括行、列以及额外的潜在维度来学习每个秩的重要性。", "innovation": "LittleBit的主要创新包括Dual Sign-Value-Independent Decomposition（Dual-SVID）进行量化感知训练（QAT）初始化，以及集成残差补偿机制来缓解误差。通过这些方法，LittleBit在亚1比特量化方面表现出优越性，例如在Llama2-7B上的0.1 BPW性能优于现有领先方法的0.7 BPW。LittleBit制定了新的、可行的大小-性能折衷方案，可以在核级别上实现11.6倍的加速，并使强大的LLM在资源受限环境中变得实用.", "conclusion": "本文研究的LittleBit提出了一种新的方法，能够在亚1比特精度下有效压缩大型语言模型的权重，同时通过多尺度补偿机制和量化感知初始化等方式提高精度。实验表明，该方法显著改善了性能，并在实际应用中提供了较好的速度和内存折衷解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.02937", "html_url": "https://arxiv.org/abs/2507.02937", "title": "FoGE: 股空间启发式编码在图提示中的应用", "title_en": "FoGE: Fock Space inspired encoding for graph prompting", "authors": "Sotirios Panagiotis Chytas,Rudrasis Chakraborty,Vikas Singh", "background": "近期的研究表明，现代大型语言模型（LLM）能够理解和回答关于结构化数据，如图的提问。这种新的范式可以导致需要较少监督的解决方案，同时提供一个能够泛化并回答超越训练标签的问题的模型。现有的方案通常通过图的一些描述来创建一个用于LMLM的‘增强’提示。针对特定类型的图，通过部署一个适配良好的图编码器与预训练的LMLM合作，模型可以很好地回答图相关的问题。现有的图基提示解决方案范围从图序列化到图变换器。", "innovation": "论文展示了基于数学物理中的Fock空间表示的参数自由图编码器在这一问题设定中的灵活性。这个简单的构建，直接继承自理论，通过少量调整可以为各种不同类型的图提供丰富的且信息丰富的图编码。利用这个想法，他们还研究了利用预训练、冻结的LMLM能力的前缀调整提示（prefix-tuned prompts），这种方法导致了一个能够有效地回答从简单图到蛋白质再到超图等图相关问题的模型，而且架构上的调整非常少。这种方法大大简化了现有的解决方案，并能轻松地适应多种不同类型的图基结构。", "conclusion": "这项工作显著简化了现有解决方案，广泛泛化到多种不同的图基结构，明显提高了图相关问题的回答能力，且架构上的改动很小。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00063", "html_url": "https://arxiv.org/abs/2509.00063", "title": "MolErr2Fix:通过模块化错误检测、定位、解释和修订评估LLM在化学中的可信度基准", "title_en": "MolErr2Fix: Benchmarking LLM Trustworthiness in Chemistry via Modular Error Detection, Localization, Explanation, and Revision", "authors": "Yuyang Wu,Jinhui Ye,Shuhao Zhang,Lu Dai,Yonatan Bisk,Olexandr Isayev", "background": "大型语言模型（LLMs）在分子科学领域显示出越来越大的潜力，但它们经常生成化学不准确的描述，并且难以识别或证明潜在错误。这引发了对其在科学应用中的稳健性和可靠性的重大关注。为了支持更严格的LLM在化学推理方面的评估，我们提出了MolErr2Fix基准，用于评估LLM在分子描述中的错误检测和纠正能力。", "innovation": "MolErr2Fix基准不同于现有的专注于分子到文本生成或属性预测的基准，更侧重于精细的化学理解。它要求LLM识别、定位、解释和修订分子描述中的潜在结构和语义错误。MolErr2Fix包括1193个精细标注的错误实例，每个实例包含四重注释，即（错误类型、跨度位置、解释和修正）。这些任务旨在反映现实中的化学交流中所需的推理和验证类型。", "conclusion": "当前最先进的LLM在评估中的表现存在显著差距，突显了对更强大的化学推理能力的需求。MolErr2Fix提供了一个专注于评估这些能力的基准，并旨在支持更可靠和化学导向的模型的发展。所有注释和配套评估API都将公开展示，以促进未来的研究。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19563", "html_url": "https://arxiv.org/abs/2508.19563", "title": "Robustness is Important: Limitations of LLMs for Data Fitting", "title_en": "Robustness is Important: Limitations of LLMs for Data Fitting", "authors": "Hejia Liu,Mochen Yang,Gediminas Adomavicius", "background": "大型语言模型（LLMs）在广泛的场景中应用，远超语言处理任务。研究显示，LLMs 通过在上下文学习或监督微调的方式在表数据监督学习任务中能取得与传统方法相当的预测性能。然而，本文发现使用 LLMs 进行数据拟合存在一个严重漏洞，即改变与学习任务完全无关的数据表示形式可以显著改变 LLMs 在相同数据上的预测结果。这种预测的敏感性在上下文学习和监督微调过程中表现明显，即使是在训练时不同的输入位置理论上应得到类似关注的情况下，数据的特定位置会在输出生成时得到更多关注。", "innovation": "作者通过分析 LLMs 的注意力分数，揭示了一种非均匀的注意力模式，解释了任务无关变化影响预测敏感性的原因。此外，研究还探讨了专门为数据拟合训练的最先进的表格基础模型（TabPFN）的鲁棒性不足，尽管该模型旨在实现预测稳健性。", "conclusion": "尽管 LLMs 在预测方面表现出色，但目前它们缺乏用于数据拟合的充分鲁棒性，这限制了它们作为数据拟合工具的可靠性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.13499", "html_url": "https://arxiv.org/abs/2509.13499", "title": "在线AI在数字健康中的可重复工作流程", "title_en": "Reproducible workflow for online AI in digital health", "authors": "Susobhan Ghosh,Bhanu T. Gullapalli,Daiqi Gao,Asim Gazi,Anna Trella,Ziping Xu,Kelly Zhang,Susan A. Murphy", "background": "在线人工智能算法是数字健康干预的重要组成部分。随着算法、传感器、软件和设备的进步，数字健康干预的发展是一个不断循环的过程，包括重新开发和优化，每次部署都会为下一步带来信息。这强调了可重复性的重要性，跨部署收集的数据必须被准确存储以进行科学研究，算法行为必须可审计，并且结果必须时间可比，以促进科学研究和值得信赖的改进。", "innovation": "本文提出了一种可重复的科学工作流程，以开发、部署和分析在线AI决策算法在数字健康干预中的应用。该工作流程基于多个实际部署的经验，旨在解决在线AI算法开发生命各阶段的可重复性挑战。", "conclusion": "这种迭代的性质强调了在数字健康干预中实施在线AI算法的可重复性的重要性，考虑到准确的数据存储、可审核的算法行为以及随时间进行结果的比较，以促进科学发现和可靠的改进。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.00103", "html_url": "https://arxiv.org/abs/2509.00103", "title": "预训练知识提升大型语言模型超越传统化学反应优化器", "title_en": "Pre-trained knowledge elevates large language models beyond traditional chemical reaction optimizers", "authors": "Robert MacKnight,Jose Emilio Regio,Jeffrey G. Ethier,Luke A. Baldwin,Gabe Gomes", "background": "现代实验化学中，优化算法通过黑盒参数空间搜索进行实验设计。使用六组完全列举的分类反应数据集（768-5,684个实验），本研究对比了LLM引导优化（LLM-GO）与贝叶斯优化（BO）和随机抽样。研究发现，在五组单目标数据集中，前沿LLM在匹配或超越BO性能的同时，随着参数复杂度的增加和高效条件的稀缺性增强，其优势愈发明显，尤其是在高熵探索通常无法奏效的解决方案稀缺参数空间。BO仅在显式多目标权衡时保持优势。", "innovation": "本研究引入了一种拓扑无关的信息理论框架，用于量化整个优化过程中的采样多样性。研究结果显示，无论是哪个数据集，预先训练的领域知识都使模型维持着更高的探索信息熵，从而实现更好的性能，特别是在解决方案稀缺的参数空间中，低熵探索通常无法提高性能。这一发现表明，预训练的领域知识能够更有效地导航化学参数空间，而不只是替代结构化探索策略", "conclusion": "我们的发现表明，LLM-GO在复杂分类参数空间和需要领域理解而不是数学优化的场景中表现出色，这正是传统方法所面临困难的地方。我们还发布了一个无代码平台Iron Mind，用于透明地进行基准测试和社区验证，该平台允许对人类、算法和LLM优化方案进行直接比较，并提供公共排行榜和完整轨迹。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.14057", "html_url": "https://arxiv.org/abs/2509.14057", "title": "人类与机器人的悖论：协同作用如何创造或摧毁价值，以及为何增强能力是解决这一问题的关键", "title_en": "The human-machine paradox: how collaboration creates or destroys value, and why augmentation is key to resolving it", "authors": "Riccardo Zanardelli", "background": "当部署人工技能时，管理者普遍认为将这些技能与人类因素结合使用可以缓解全自动化带来的风险，特别是在高复杂度任务中。然而，本文正式质疑了这一常见假设的经济有效性，指出人类与机器技能政策的实际经济实用性被危险地误解了，这高度依赖于情境和设计因素。", "innovation": "本文通过开发基于蒙特卡洛模拟的实验框架，量化不同复杂度水平任务中人类与机器技能的经济影响，填补了理论与实践之间的差距。研究发现，人类与机器的协同策略在复杂的场景下可能产生最高的经济价值，但前提是实现了真正的增强能力。否则，这种协同策略可能会导致价值的损失。", "conclusion": "对于决策者而言，当情境复杂且关键时，仅仅分配人类和机器技能给任务可能不够，不是所谓的银弹解决方案或低风险的妥协。相反，这是一个增强竞争力的关键机会，需要组织强有力的支持。此外，研究还发现，随着时间的推移提高机器技能的成本效益是有用的，但这并不能替代专注于实现增强能力的基本需求。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.20234", "html_url": "https://arxiv.org/abs/2509.20234", "title": "ImageNet训练的CNN并非偏向于纹理：通过受控抑制重新审视特征依赖", "title_en": "ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression", "authors": "Tom Burgert,Oliver Stoll,Paolo Rota,Begüm Demir", "background": "卷积神经网络（CNNs）被认为在特征使用上偏向于纹理，这个假设影响了人们对深度学习中特征使用方式的讨论。此前的研究通过Geirhos等人的实验发现了CNNs在处理视觉任务时可能存在对纹理的偏见。但这些研究存在一些局限性，尤其是通过强迫选择冲突来探究特征依赖的方法。", "innovation": "本文提出了一个无领域限制的框架，通过系统地抑制形状、纹理和颜色线索来定量评估特征依赖性，从而规避了此前研究中的混杂变量。此外，作者还扩展了研究范围，包括图像识别、医学影像和遥感领域，并系统地分析了不同领域的模型在特征依赖上的差异。", "conclusion": "实验证明CNN并不天生偏向于纹理，而主要依赖于局部形状特征。不过，通过现代的训练策略或架构（如ConvNeXt和ViTs）可以显著减少这种依赖性。此外，不同领域的模型在特征依赖上有系统性的差异：图像识别模型偏好形状，医疗影像模型强调颜色，而遥感模型则更依赖于纹理。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23311", "html_url": "https://arxiv.org/abs/2509.23311", "title": "透视符号，忽视文化：视觉语言模型在火象绘画和文化意义推理中的表现", "title_en": "Seeing Symbols, Missing Cultures: Probing Vision-Language Models' Reasoning on Fire Imagery and Cultural Meaning", "authors": "Haorui Yu,Yang Zhao,Yijia Chu,Qiufeng Yi", "background": "视觉语言模型（VLMs）虽然在处理文化相关图像时表现得似乎文化熟练，但实际上它们更多地依赖于浅层次的模式匹配，而不是真正的文化理解。本文探讨了VLMs在理解具有火主题的文化图像时的问题，包括节日、非西方传统和紧急场景。研究表明，这些模型对突出的西方节日识别准确，但对于不太常见的文化事件则难以处理，经常给出模糊的标签或错误地将紧急情况分类为庆祝活动。这些失败揭示了符号捷径的风险，强调了超越准确度指标的文化评价的重要性，以确保可解释和公平的多模态系统。", "innovation": "本文提出了一种新的诊断框架，通过分类与解释分析来测试VLMs对具有火主题的文化图像的推理能力，揭示了VLMs在处理特定文化事件时存在的系统偏差。", "conclusion": "VLMs在处理文化差异时存在显著偏差，需要采用更全面的评估方法，不仅仅是准确性指标，来确保系统的解释性和公平性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01268", "html_url": "https://arxiv.org/abs/2510.01268", "title": "AdaDetectGPT：具有统计保证的LLM生成文本的自适应检测", "title_en": "AdaDetectGPT: Adaptive Detection of LLM-Generated Text with Statistical Guarantees", "authors": "Hongyi Zhou,Jin Zhu,Pingfan Su,Kai Ye,Ying Yang,Shakeel A O B Gavioli-Akilagun,Chengchun Shi", "background": "现有的最先进方法使用从给定来源的大语言模型的概率分布中得出的统计信息来检测文本是否由人类或大语言模型（LLM）撰写。但仅依赖对数概率可能不尽完美。", "innovation": "引入了AdaDetectGPT——一种新型的自适应学习判别函数的分类器，以提升基于对数概率的检测器的表现。该方法提供了真实阳性率、假阳性率、真实阴性率和假阴性率的统计保证。广泛的数据研究表明，AdaDetectGPT在各种数据集和大语言模型的组合中几乎均匀地改善了最先进的方法，性能提升最高可达37%。", "conclusion": "AdaDetectGPT几乎在所有数据集和大语言模型的组合中统一地改善了最先进的检测方法，性能提升最高可达37%。我们的方法的Python实现可在指定链接找到。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.01161", "html_url": "https://arxiv.org/abs/2510.01161", "title": "在大规模语言模型中，过时数据之前也能繁荣：离策学习与过时数据的远行能力", "title_en": "Prosperity before Collapse: How Far Can Off-Policy RL Reach with Stale Data on LLMs?", "authors": "Haizhong Zheng,Jiawei Zhao,Beidi Chen", "background": "强化学习是近年来大型语言模型推理的关键所在，但多数算法依赖于在线策略训练，即每次更新都需要重新生成滚动数据，这限制了效率和可扩展性。异步RL系统通过解藕滚动数据生成与训练来缓解这一问题，但性能严重依赖于能容忍较大的模型更新延迟。现有方法在这种情况下要么性能下降，要么彻底失败。", "innovation": "该研究重新审视了这一挑战，揭示了一种繁荣前的衰退现象：过时数据能在适当利用的情况下与实时数据一样有信息价值。基于这一发现，该研究引入了M2PO算法，通过约束重要权重的二阶矩抑制极端异常值同时保留有价值的信息更新。实验表明，M2PO能够即使在数据过时256个模型更新后还能提供稳定的离策训练，并且能与实时策略的性能相匹配，能够显著减少剪辑令牌的比例（从1.22%下降到0.06%）。", "conclusion": "该研究证明了M2PO算法不仅使离策训练在过时数据中保持稳定，还能恢复性能至与实时策略等同的水平。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02999", "html_url": "https://arxiv.org/abs/2510.02999", "title": "untargeted jailbreak attack", "title_en": "Untargeted Jailbreak Attack", "authors": "Xinzhe Huang,Wenjing Hu,Tianhang Zheng,Kedong Xiu,Xiaojun Jia,Di Wang,Zhan Qin,Kui Ren", "background": "现有的基于梯度的监狱突破攻击，如Greedy Coordinate Gradient (GCG) 和 COLD-Attack，通常通过优化对抗后缀使其与预定义目标响应一致。然而，这些方法通过将优化目标限制为预定义的目标，内在限制了对抗搜索空间，从而限制了整体攻击效果。此外，现有方法通常需要大量的优化迭代来弥补固定目标和原始模型响应之间的巨大差距，导致攻击效率低下。", "innovation": "我们提出了首个基于梯度的无目标监狱突破攻击（UJA），旨在引发一种不安全的响应而不需要强制任何预定义模式。具体来说，我们提出了一个无目标攻击目标来最大化LLM响应的不安全性，该不安全性可以通过裁判模型量化。由于目标是非可微的，我们进一步将其分解为两个可优化的子目标，以优化最佳有害响应及其相应的对抗提示，并通过理论分析验证了这种分解的有效性。与目标监狱突破攻击相比，UJA的无限制目标显著扩展了搜索空间，使对LLM的探索更加灵活和高效。", "conclusion": "评估表明，UJA仅需100次优化迭代即可在最近的安全对齐的LLM上实现超过80%的攻击成功率，优于最先进的基于梯度的攻击方法如I-GCG和COLD-Attack，超过20%。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.24085", "html_url": "https://arxiv.org/abs/2509.24085", "title": "PEARL: Peer-Enhanced Adaptive Radio via On-Device LLM", "title_en": "PEARL: Peer-Enhanced Adaptive Radio via On-Device LLM", "authors": "Ju-Hyung Lee,Yanqing Lu,Klaus Doppler", "background": "该研究提出了PEARL框架，用于设备到设备（D2D）通信中的跨层优化。它基于作者之前关于单设备上设备LLM的工作，通过利用发布者和订阅者的状态来指导Wi-Fi Aware（WA）参数的选择。引入了一种情境感知的奖励机制，该机制通过应用容忍度来归一化延迟，并通过设备电池状态来调节能量。研究了两种轻量级变体：PEARL（仅头部+低秩适应（LoRA））在总体性能上表现出最佳效果，而PEARL-Lite（仅头部）在接近相同的目标分数的情况下提供低于20毫秒的推理时间。", "innovation": "该研究引入了PEARL框架，通过利用发布者和订阅者的状态，基于KL的调优进行轻量级变体的训练。提出了情境感知的奖励机制，通过应用容忍度归一化延迟，并通过设备电池状态调节能量，提供了更丰富的监督。在合成场景中，PEARL提高了目标分数，并在合作低电池情况下的能量减少了高达16%。这些结果表明，同伴感知的上下文、奖励对齐的训练和头部效率使得LLM能够在持续的、上设备的跨层控制中实用化。", "conclusion": "研究表明，同伴感知的上下文、奖励对齐的训练和基于头部的效率使得LLM能够在持续的上设备跨层控制中实用化。Pearl框架在D2D通信中的应用展示了LLM在实际场景中的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.16989", "html_url": "https://arxiv.org/abs/2509.16989", "title": "PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models", "title_en": "PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models", "authors": "He Xiao,Runming Yang,Qingyao Yang,Wendong Xu,Zhen Li,Yupeng Su,Zhengwu Liu,Hongxia Yang,Ngai Wong", "background": "大型语言模型（LLMs）的后训练量化（PTQ）到极低位宽（如二进制或复杂补偿机制）仍具有挑战性，这是因为计算效率和模型表示能力之间的基本权衡。现有的一些超低位PTQ方法依赖于二值近似或复杂的补偿机制，但它们要么表示能力有限，要么计算开销高，从而抵消了效率的提升。", "innovation": "我们提出了PTQTP（Post-Training Quantization to Trit-Planes），这是首个三值权重量化框架，通过将其权重矩阵分解成结构化的三值矩阵（{-1, 0, 1}），使用2x1.58位表示实现无乘法的推理，同时通过其新颖的结构分解保持了优越的表达能力。其创新点在于：（1）提供了一个理论支持的渐进逼近算法，确保全局权重一致性；（2）能够在各种现代大语言模型上部署（无需架构修改）；（3）统一的三值操作消除了混合精度或补偿方案的需求。该方法在LLaMA3.x和Qwen3模型家族（参数从0.6B到70B）上的全面实验表明，PTQTP显著优于现有的超低位量化方法，保留了82.4%的数学推理能力，而竞争对手的方法是0%。PTQTP甚至接近或超越了1.58位量化感知训练的效果，仅需单小时量化，而基于训练的方法则需要10-14个GPU天的训练时间。", "conclusion": "这些结果表明，PTQTP是一个在资源受限环境中高效部署大语言模型的实用解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.00037", "html_url": "https://arxiv.org/abs/2510.00037", "title": "Vision-Language-Action模型在多模态干扰下的鲁棒性研究", "title_en": "On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations", "authors": "Jianing Guo,Zhenhong Wu,Chang Tu,Yiyao Ma,Xiangqi Kong,Zhiqian Liu,Jiaming Ji,Shuning Zhang,Yuanpei Chen,Kai Chen,Qi Dou,Yaodong Yang,Xianglong Liu,Huijie Zhao,Weifeng Lv,Simin Li", "background": "在Vision-Language-Action（VLA）模型中，模型对现实世界干扰的鲁棒性是部署时的关键因素。现有方法主要针对简单的视觉扰动，忽视了动作、指令、环境和观察中的更广泛多模态干扰。作者首先评估了主流VLA模型在17种跨四模态干扰下的鲁棒性，发现行动是最脆弱的模态，视觉鲁棒的VLA在其他模态上没有增加鲁棒性，pi0模型在基于扩散的动作头方面表现更优。", "innovation": "提出了RobustVLA模型，用于增强VLA输入和输出在多模态干扰下的鲁棒性。通过离线鲁棒优化针对最坏情况的动作噪声，最大化流匹配目标的不匹配度，这可以视为对抗训练、标签平滑和异常值惩罚。在输入鲁棒性方面，模型要求输入变化保持任务语义的一致性。为处理多种干扰，将鲁棒性转化为多臂博弈问题，应用上层置信边界算法自动识别最有害的干扰类型。该模型在LIBERO上的实验表明，相比基础模型，RobustVLA在所有17种干扰下的绝对提升分别为pi0主干12.6%和开集VLA主干10.4%，较快50.6倍的推理速度，混合干扰下有10.4%的提升。同时，RobustVLA在真实世界FR5机器人的有限演示中表现出色，四种模态下的干扰绝对提升为65.6%。", "conclusion": "研究结果表明，RobustVLA通过离线鲁棒优化、流匹配目标下的不匹配度最大化和上层置信边界算法，显著提升了VLA模型的综合鲁棒性，特别适用于复杂的现实环境中的实际应用。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03095", "html_url": "https://arxiv.org/abs/2510.03095", "title": "Distilled Protein Backbone Generation", "title_en": "Distilled Protein Backbone Generation", "authors": "Liyang Xie,Haoran Zhang,Zhendong Wang,Wesley Tansey,Mingyuan Zhou", "background": "扩散模型和流模型在蛋白质主链生成任务中表现出强大的性能，提供了前所未有的从头设计蛋白质的能力。然而，这些模型在生成速度上受到限制，通常在反向扩散过程中需要成百上千的迭代步骤，这限制了它们在大规模蛋白质发现中的应用，因为需要成千上万个候选结构。", "innovation": "研究人员探索了得分蒸馏技术，该技术在视觉领域成功减少了采样步骤的数量，同时保持了高生成质量。通过研究，他们适当地将最先进的得分身份蒸馏（SiD）策略应用于训练短步骤的蛋白质主链生成器，显著减少了采样时间，同时保持与预训练教师模型相当的性能。特别地，多步骤生成结合推理时间噪声调制是成功的关键。", "conclusion": "蒸馏后的短步骤生成器的采样速度提高了20多倍，同时设计性、多样性和新颖性与Proteina教师模型相当。这种减少的推理成本使大规模蛋白质设计成为可能，推动扩散模型更接近实际蛋白质工程应用。此PyTorch实现可在提供的链接找到。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08146", "html_url": "https://arxiv.org/abs/2510.08146", "title": "适时思考：序列级熵作为LLM推理中的置信信号", "title_en": "Think Just Enough: Sequence-Level Entropy as a Confidence Signal for LLM Reasoning", "authors": "Aman Sharma,Paras Chopra", "background": "介绍了以熵为基础的机制来驱动大规模语言模型在推理任务中的标记效率，使用标记层面的logprobs计算香农熵作为置信信号，用于实现提前终止以节省约25-50%的计算资源，同时保持任务准确性。", "innovation": "引入了一个简单但新颖的熵基础框架，利用序列级熵作为置信度信号，以实现推理任务中能量源的高效利用。该方法发现了高级推理模型中存在而标准指令调整和预训练模型中缺失的一种新兴特性，即熵基置信度校准。", "conclusion": "显示了熵阈值在不同模型之间变化，但可以通过较少的现有推理数据集样本在一次计算中轻松得出。研究表明高级推理模型在推理过程中常常较早地意识到正确性，这种新兴的置信度意识可以被利用以节省标记并在很大程度上减少延迟。框架在推理优化模型家族中表现出一致性，实现了25-50%的计算成本减少同时保持准确性，揭示出置信度机制是现代后训练推理系统区别于先前系统的特征之一。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.03490", "html_url": "https://arxiv.org/abs/2510.03490", "title": "SEER: 基于短语的情感证据检索基准", "title_en": "SEER: The Span-based Emotion Evidence Retrieval Benchmark", "authors": "Aneesha Sampath,Oya Aran,Emily Mower Provost", "background": "传统的识别情感任务通常为整个句子分配单一的情感标签，而SEER（基于短语的情感证据检索）基准测试大型语言模型（LLMs）识别表达情感的具体短语的能力，这是对传统任务的一个补充，更注重具体的情感表达识别任务，服务于如同情对话和临床支持这样需要精确识别情感表达的应用场景。该基准包含两项任务：单句内的情感证据识别，以及五句连续句的情感证据识别。涵盖了1200个真实世界的句子的新注释。发现一些模型在短句子上的性能与人类相当，但在较长段落中准确度下降。错误分析表明模型过度依赖情感关键词以及在中性文本中出现误判是关键的失败模式之一。", "innovation": "SEER是一个新的基准测试集，专注于识别表达情感的具体短语，与传统的为整个句子分配单一情感标签的任务不同，强调情感表达的具体识别。它包含两个具体任务和新的表情和情感证据标注，适用于需要精确识别情感表达的应用场景。特别是它展示了大型语言模型在较短句子与较长段落之间的表现差异，并揭示了模型的失败模式，这对于改进大语言模型的性能和理解至关重要。", "conclusion": "通过评估14种开源大语言模型，SEER基准展示了模型在短句子和较长段落中的表现差异，发现了一些关键的失败模式。这表明，尽管一些模型在短句子上可能接近人类平均水平，但在较长段落中的准确性下降了。因此，在涉及精确情感表达识别的场景中，需要进一步改进大语言模型。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15545", "html_url": "https://arxiv.org/abs/2510.15545", "title": "TokenTiming: 一种通用谱取解码模型对的动态对齐方法", "title_en": "TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs", "authors": "Sibo Xiao,Jinyuan Fu,Zhongle Xie,Lidan Shou", "background": "在生成式AI中，加速大型语言模型（LLMs）的推理是关键挑战。推测性解码（SD）显著提高了LLM推理效率，但其应用受到一个基本限制：草稿模型和目标模型必须共享相同的词汇表，这限制了可选择的草稿模型的数量，并且通常需要从头开始训练一个新模型。", "innovation": "受Dynamic Time Warping (DTW)算法的启发，我们提出了一种名为TokenTiming的算法，旨在实现通用的推测性解码。TokenTiming通过重新编码草稿的标记序列以获取一个新的目标标记序列，并利用DTW构建映射，将概率分布用于推测性抽样。这种方法使得词汇表不匹配的问题得以解决，并且无需对现有模型进行重训或修改，即可应用于任何现成的模型。", "conclusion": "我们在多种任务中进行了全面实验，显示出1.57倍的加速效果。这项工作为草稿模型的选择提供了一个通用方法，使推测性解码（SD）成为LLM加速的一个更为灵活和实用的工具。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14788", "html_url": "https://arxiv.org/abs/2510.14788", "title": "在十亿规模下跨场景统一建模用户兴趣", "title_en": "Cross-Scenario Unified Modeling of User Interests at Billion Scale", "authors": "Manjie Xu,Cheng Chen,Xin Jia,Jingyi Zhou,Yongji Wu,Zejian Wang,Chi Zhang,Kai Zuo,Yibo Chen,Xu Tang,Yao Hu,Yixin Zhu", "background": "内容平台上的用户兴趣具有多样性，体现在多种异构场景下的复杂行为模式，如搜索、推荐流浏览和内容发现。传统的推荐系统通常在特定场景中优化业务指标，忽视了跨场景的行为信号，并且难以在十亿规模下集成先进的技术如LLMs，最终影响了对用户兴趣的全面捕捉。", "innovation": "我们提出了RED-Rec，一种增强型层级推荐引擎，适用于行业级内容推荐系统。RED-Rec 通过跨多个行为场景聚合和合成多样化场景的动作，实现了全面的项目和用户建模。核心框架是双塔LLM驱动的系统，能够提供详细的、多面的表示，并具有部署效率；场景感知密集混合和查询策略有效地融合了多样的行为信号，捕捉跨场景的用户意图，并在服务期间表达细粒度、情境特定的意图。该系统通过在线A/B测试在RedNote上的数百万用户中得到了验证，显著提升了内容推荐和广告定向任务的效果。我们还引入了一个百万规模的序列推荐数据集RED-MMU，用于全面的离线训练和评估。这项工作推进了统一用户建模的发展，为大规模UGC平台解锁了更深一层的个性化，并促进了更贴近用户的互动。", "conclusion": "RED-Rec 改进了主流推荐系统的局限性，在大规模部署中展示了显著的性能提升，并通过引入一个新的序列推荐数据集，为全面的离线训练和评估提供了基础，为内容平台上的用户兴趣建模提供了一种新的方法。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14205", "html_url": "https://arxiv.org/abs/2510.14205", "title": "DPRF: 通用的动态人设优化框架，用于优化个性化的大语言模型角色扮演代理与人类的行为对齐", "title_en": "DPRF: A Generalizable Dynamic Persona Refinement Framework for Optimizing Behavior Alignment Between Personalized LLM Role-Playing Agents and Humans", "authors": "Bingsheng Yao,Bo Sun,Yuanzhe Dong,Yuxuan Lu,Dakuo Wang", "background": "现有的大型语言模型角色扮演代理（LLM RPAs）旨在模拟个体的人类行为，但这些代理的人格忠实度通常会因手动创建的人格档案（如有限信息和个性特征的选择性描述）而受损，而这些档案未能验证与目标个体的一致性。由于这种方法导致代理行为与目标个体的行为不匹配，从而削弱了代理的人格真实性。为了克服这一限制，本文提出了动态个性优化框架（DPRF）。DPRF的目标是通过迭代地识别生成行为与人类真实行为之间的认知差异（无论是自由形式的还是基于理论的结构化分析），并优化LKM RPAs的行为与目标个体行为的一致性，从而优化个性化的大语言模型角色扮演代理与人类的行为对齐。通过在五款不同的LLM上对四个多样化的行为预测场景进行评估（正式辩论、涉及心理健康问题的社交媒体帖子、公共访谈和电影），DPRF能够显著提升行为的对齐度，并且其方法具有通用性，适用于不同的模型和应用场景。", "innovation": "本文提出了一个名为DPRF的动态个性优化框架，它能够通过一系列迭代分析方法来优化个性化的大语言模型角色扮演代理与目标个体之间的行为对齐。该框架不仅提供了一种新的人格档案更新机制，还能够有效提升对齐度，并具有广泛的适用性。该方法有助于增强个性化代理根据实际人类行为模拟的能力，进而为下游应用（如用户模拟、社会研究和个人化AI）提供更可靠的基础支持。", "conclusion": "此工作提供了一种坚实的动态人设优化方法，通过这种方法，可以创建高度真实的人设档案，从而增加下游应用的有效性和可靠性。这种方法在多样化的行为预测场景中得到了验证，并在多个模型之间具有稳健性和通用性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.15870", "html_url": "https://arxiv.org/abs/2510.15870", "title": "OmniVinci：提升多模态理解模型结构与数据", "title_en": "OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM", "authors": "Hanrong Ye,Chao-Han Huck Yang,Arushi Goel,Wei Huang,Ligeng Zhu,Yuanhang Su,Sean Lin,An-Chieh Cheng,Zhen Wan,Jinchuan Tian,Yuming Lou,Dong Yang,Zhijian Liu,Yukang Chen,Ambrish Dantrey,Ehsan Jahangiri,Sreyan Ghosh,Daguang Xu,Ehsan Hosseini-Asl,Danial Mohseni Taheri,Vidya Murali,Sifei Liu,Yao Lu,Oluwatobi Olabiyi,Yu-Chiang Frank Wang,Rafael Valle,Bryan Catanzaro,Andrew Tao,Song Han,Jan Kautz,Hongxu Yin,Pavlo Molchanov", "background": "为了推动机器智能的发展，需要增强跨多个感知模态的能力，类似于人类对世界的感知方式。本文针对这一目标，介绍了一个名为OmniVinci的项目，旨在构建一个强大且开放的多模态大型语言模型（LLM）。项目通过精心设计多种创新技术，在模型架构和数据收集与整理方面深入研究，以提升跨模态理解能力。", "innovation": "1. 引入OmniAlignNet，以加强视觉和音频嵌入在共享多模态隐空间中的对齐；\n2. 开发Temporal Embedding Grouping，以捕捉视觉与音频信号之间的相对时间对齐；\n3. 采用Constrained Rotary Time Embedding，以编码多模态嵌入中的绝对时间信息。", "conclusion": "本研究表明，不同模态之间在感知和推理方面互相加强。OmniVinci模型在DailyOmni（跨模态理解）、MMAR（音频）和Video-MME（视觉）三项基准测试中分别取得了+19.05、+1.7和+3.9的提升，且仅使用了0.2T的训练标记，相比Qwen2.5-Omni的1.2T减少了6倍。除此之外还证明了多模态方法在机器人技术、医疗人工智能和智能工厂等下游应用领域的优势。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16175", "html_url": "https://arxiv.org/abs/2510.16175", "title": "强化学习研究中的形式实现差距", "title_en": "The Formalism-Implementation Gap in Reinforcement Learning Research", "authors": "Pablo Samuel Castro", "background": "过去十年中，人们对强化学习（RL）技术的兴趣和采用大幅上升，这主要是由于其在执行某些任务方面表现出的“超人类”能力。这种趋势导致社区倾向于重视展示RL代理性能的研究，而忽视了那些旨在理解这些学习动态的研究。这种专注于性能的研究存在过度拟合于学术基准的风险，从而降低了其实用性，使得将提出的技术应用于新问题变得困难。此外，这还隐含地削弱了那些虽不推进性能前沿，但旨在改善我们对这些技术理解的工作。", "innovation": "论文提出了两个观点：一是RL研究应停止仅专注于展示代理的能力，而更应致力于推进强化学习的科学和理解；二是需要更精确地说明我们的基准如何映射到基础的数学形式主义。作者使用广受欢迎的街机学习环境（ALE）作为一个例子，尽管它正日益被认为“饱和”，但它仍可以有效用于发展这种理解，并促进RL技术在实际问题中的应用。", "conclusion": "因此，论文建议强化学习研究应关注深入理解和科学推进，同时提高基准与数学形式主义之间的映射精确度，从而有效指导实际应用并解决过度拟合问题。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19585", "html_url": "https://arxiv.org/abs/2510.19585", "title": "使用大型语言模型检测历史书中的拉丁文：一种多模态基准测试", "title_en": "Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark", "authors": "Yu Wu,Ke Shu,Jonas Fischer,Lidia Pivovarova,David Rosson,Eetu Mäkelä,Mikko Tolonen", "background": "本文讨论了从具有多种布局的混合语言历史文件中提取拉丁语片段的新任务。研究使用724页标注数据进行了大量基础模型和多模态模型的基准测试，展示了当代模型进行拉丁文检测的可能性。", "innovation": "文章提供了一种全新的任务——从混合语言的历史文件中提取拉丁语片段，并通过多模态基准数据集评估了大型基础模型的表现。这是首次对这些模型在这项任务上的能力和局限性进行全面分析。", "conclusion": "研究表明，利用当前的模型可以实现可靠的拉丁文检测。这项研究为理解大型基础模型在这类任务上的性能提供了重要参考。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20280", "html_url": "https://arxiv.org/abs/2510.20280", "title": "通过学习预测性上下文嵌入实现上下文级语言建模", "title_en": "Context-level Language Modeling by Learning Predictive Context Embeddings", "authors": "Beiya Dai,Yuliang Liu,Daozheng Xue,Qipeng Guo,Kai Chen,Xinbing Wang,Bowen Zhou,Zhouhan Lin", "background": "下一个词预测（NTP）是现代大规模语言模型（LLMs）预训练的基础，推动了文本生成、推理和指令遵循等前所未有的能力。然而，基于词级别的预测限制了模型对高层语义结构和长距离上下文关系的捕捉能力。", "innovation": "提出了ContextLM框架，该框架通过内置的'下一个上下文预测'目标增强标准预训练。它使模型学习多词上下文的预测表示，利用来自后续词块的误差信号。重要的是，ContextLM能够在保持与标准自回归、逐词评估范式（如困惑度）兼容的同时实现这一增强。", "conclusion": "大规模实验表明，ContextLM在困惑度和下游任务性能方面均提供了稳健的改进。我们的分析表明，下一个上下文预测为更强的语言建模提供了一种可扩展且高效的途径，使得上下文的一致性和更加有效的注意力分配得以改进，同时几乎不增加计算开销。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.20774", "html_url": "https://arxiv.org/abs/2510.20774", "title": "FieldGen: 从远程操作预操作轨迹到场引导数据生成", "title_en": "FieldGen: From Teleoperated Pre-Manipulation Trajectories to Field-Guided Data Generation", "authors": "Wenhao Wang,Kehe Ye,Xinyu Zhou,Tianxing Chen,Cao Min,Qiaoming Zhu,Xiaokang Yang,Ping Luo,Yongjian Shen,Yang Yang,Maoqing Yao,Yao Mu", "background": "现有的数据收集方法难以平衡大规模、多样化和高质量数据之间的关系。模拟虽然能够提供扩展性，但存在模拟与真实世界之间的差距；而远程操作虽然能提供高质量的操作示范，但其多样性和人力成本都很低。", "innovation": "FieldGen 是一种场引导数据生成框架，能够在最小的人类监督下实现大规模、多样性和高质量的真实世界数据收集。该框架将操作过程分为两个阶段：预操作阶段允许轨迹多样性，精细操作阶段需要专家级的精确度。FieldGen-Reward 进一步通过增加奖励注解来增强策略学习。", "conclusion": "使用 FieldGen 训练的策略在成功率和稳定性上都优于基于远程操作的基线模型，同时显著减少了长时间内真实世界数据收集所需的人力投入。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18383", "html_url": "https://arxiv.org/abs/2510.18383", "title": "MENTOR：通过教师优化奖励实现小型模型工具使用的强化学习框架", "title_en": "MENTOR: A Reinforcement Learning Framework for Enabling Tool Use in Small Models via Teacher-Optimized Rewards", "authors": "ChangSu Choi,Hoyun Song,Dongyeon Kim,WooHyeon Jung,Minkyung Cho,Sunjin Park,NohHyeob Bae,Seona Yu,KyungTae Lim", "background": "大型语言模型（LLMs）的工具使用能力需要被浓缩并转化为更高效的小型语言模型（SLMs），以便实际应用。传统的监督微调（SFT）方法在泛化能力上表现不佳，因为它们训练模型去模仿一组静态的教师路径，而不是学习一种稳健的方法。标准的利用稀疏奖励的强化学习（RL）无法有效地指导SLMs，使得它们在探索效率低下并且采用非最优策略方面遇到困难。", "innovation": "提出了MENTOR框架，结合了RL和教师指导下的蒸馏，通过探索学习更为通用的策略，而不是简单的模仿。此外，针对稀疏奖励问题，使用教师的参考轨迹构建密集的复合奖励，提供了详细的指导。", "conclusion": "广泛的实验表明，与传统SFT方法和标准稀疏奖励RL基线相比，MENTOR在跨领域的泛化能力和策略技能培训方面显著提高。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.21727", "html_url": "https://arxiv.org/abs/2510.21727", "title": "您的密集检索器实际上是一个高效的推理器", "title_en": "Your Dense Retriever is Secretly an Expeditious Reasoner", "authors": "Yichi Zhang,Jun Bai,Zhixin Cai,Shuhan Qin,Zhuofan Chen,Jinghua Guan,Wenge Rong", "background": "密集检索器通过将查询和文档编码为连续向量来增强检索，但它们在处理涉及推理的查询方面往往能力不足。虽然大型语言模型（LLMs）可以重新表述查询以捕捉复杂的推理，但普遍应用它们会带来重大的计算成本。需要一个既能降低成本又能保持或提高检索性能的解决方案。", "innovation": "提出了自适应查询推理（AdaQR）的混合查询重写框架，其中包括一个推理路由器，该路由器动态地将每个查询导向快速密集推理或深入LLM推理。Dense Reasoner通过直接在嵌入空间中执行LLM风格的推理，实现了一种在效率和准确性之间可调节的计算方式。", "conclusion": "在大规模检索基准BRIGHT上的实验表明，AdaQR可以将推理成本降低28%，同时能保持或甚至提高检索性能7%。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17191", "html_url": "https://arxiv.org/abs/2510.17191", "title": "SimpleVSF：端到端自主驾驶路径预测的VLM评分融合", "title_en": "SimpleVSF: VLM-Scoring Fusion for Trajectory Prediction of End-to-End Autonomous Driving", "authors": "Peiru Zheng,Yun Zhao,Zhan Gong,Hong Zhu,Shaohua Wu", "background": "端到端自主驾驶作为一种实现稳健和智能驾驶策略的有前景的范式已经涌现，但现有的端到端方法仍然面临诸如在复杂场景下的次优决策等重大挑战。", "innovation": "提出了SimpleVSF（简单的VLM评分融合）框架，该框架通过利用视觉语言模型（VLMs）的认知能力以及先进的轨迹融合技术来增强端到端规划。该框架利用了传统的评分器和新型的VLM增强评分器，并利用了稳健的权重融合器进行定量聚合，以及强大的基于VLM的融合器进行上下文感知的决策。", "conclusion": "我们的SimpleVSF框架在ICCV 2025 NAVSIM v2端到端驾驶挑战中作为领先方法展现了最新的技术水平，实现了安全、舒适和效率之间的卓越平衡。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.22379", "html_url": "https://arxiv.org/abs/2510.22379", "title": "TraceTrans：手术预测中的翻译与空间追踪", "title_en": "TraceTrans: Translation and Spatial Tracing for Surgical Prediction", "authors": "Xiyu Luo,Haodong Li,Xinxing Cheng,He Zhao,Yang Hu,Xuan Song,Tianyang Zhang", "background": "图像到图像的转换模型已经在跨视觉领域的图像转换中取得了显著的成功，并且越来越多地被用于医疗任务，如预测手术后的结果和建模疾病进展。然而，现有的大多数方法主要目标是匹配目标分布，常常忽略了源图像和翻译图像之间的空间对应关系。这可能导致结构不一致和虚构，从而削弱了预测的可靠性和可解释性。在临床应用中，这一问题被进一步放大，因为需要高度准确的解剖结构。已有模型难以满足这一精度要求，尤其是在手术预测这类任务中面临更高标准的需求。", "innovation": "该研究提出了TraceTrans，一种为术后预测设计的新型可变形图像转换模型，它生成与目标分布匹配的同时，明确揭示与术前输入的时空对应关系。框架中使用编码器提取特征，并通过两个解码器分别预测空间变形和合成转换图像。预测的变形场对生成输出施加了空间限制，确保生成图像与源图像的一致性。", "conclusion": "广泛的实验结果显示，TraceTrans能够提供准确且可解释的术后预测，强调了其在可靠临床部署中的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.22931", "html_url": "https://arxiv.org/abs/2510.22931", "title": "通过连续领域预训练实现自进化大型语言模型的鲁棒不确定性量化", "title_en": "Robust Uncertainty Quantification for Self-Evolving Large Language Models via Continual Domain Pretraining", "authors": "Xiaofan Zhou,Lu Cheng", "background": "连续学习(CL)对大型语言模型(LLMs)的自进化至关重要，使其能够适应快速增长的知识。尽管CL非常重要，但在连续领域预训练(CDP)环境中，LLMs的统计可靠性保证尚未受到足够的关注。现有的方法，如符合性预测(CP)，能够为LLMs提供正确性保证，但在CDP场景下，由于测试数据可能来自未知或变化的领域分布，CP的有效性可能会降低。此外，为了保证高置信度，CP可能产生过大的预测集，减少信息量。", "innovation": "本文提出了一个适应性拒绝和非交换CP框架。该方法通过基于变换器的聚类估计测试集中问题在不同领域下的分布，之后根据这些估计重新加权或重采样校准数据。随后，适应性拒绝CP允许LLM在其信心或能力显著变化时选择不作答。实验结果表明，在CDP场景下，该框架提升了CP的有效性和可靠性。", "conclusion": "通过适应性拒绝和非交换CP框架，本文解决了符合性预测在连续领域预训练环境下的挑战。广泛的实验表明，该框架提升了CP在CDP情景下的有效性和可靠性。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.22118", "html_url": "https://arxiv.org/abs/2510.22118", "title": "GRAID: 通过高保真数据生成增强VLM的空间推理", "title_en": "GRAID: Enhancing Spatial Reasoning of VLMs Through High-Fidelity Data Generation", "authors": "Karim Elmaaroufi,Liheng Lai,Justin Svegliato,Yutong Bai,Sanjit A. Seshia,Matei Zaharia", "background": "Vision Language Models (VLMs) 在许多视觉语言任务中表现出强大的性能，但往往在空间推理方面存在困难，而空间推理是许多应用的前提。当前使用的数据生成管道生成的数据集的人工验证率为57.6%。这源于当前的限制：单图像的3D重建引入了级联建模错误，并需要宽泛的答案容差，而基于字幕的方法需要超详细的注释，并遭受生成性的幻觉。对于VQA（视觉问题回答），现有的工具生成的高质量数据集，但人工评估证实其质量较低，尤其是对于空间关系、计数、排名和大小比较的详细问题。", "innovation": "本文提出了GRAID框架，基于关键洞察：质性的空间关系可以从2D几何基本元素中可靠地确定。通过仅使用标准物体检测器生成的2D边框数据，GRAID避免了3D重建错误和生成性幻觉，从而生成了质量高于现有工具的数据集。作者将该框架应用于BDD100k、NuImages和Waymo数据集，生成了超过850万高质量的VQA对，涵盖范围广泛的空间关系、计数、排名和大小比较等问题。在对一个数据集进行评估时，其人工验证的准确率达到91.16%，远高于最近工作生成的数据集的57.6%的准确率。训练于GRAID数据上的模型学习到了具有泛化性的空间推理概念，并在多个基准测试中取得了显著提升。", "conclusion": "本研究证明，当训练基于GRAID数据时，模型可以学习空间推理概念并表现出良好的泛化能力。对于6种不同类型的预训练，6种不同类型的问题在BDD数据集中的准确率提高了47.5%，在NuImages数据集中的准确率提高了37.9%。此外，训练于所有问题类型的模型在多个现有基准测试上也表现出了改进。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23444", "html_url": "https://arxiv.org/abs/2510.23444", "title": "FRBNet: 通过频率域径向基网络重新审视暗光视觉", "title_en": "FRBNet: Revisiting Low-Light Vision through Frequency-Domain Radial Basis Network", "authors": "Fangtong Sun,Congyu Li,Ke Yang,Yuchen Pan,Hanwen Yu,Xichuan Zhang,Yiying Li", "background": "暗光视觉仍然是计算机视觉领域的基本挑战，由于严重的光照降级，这会对检测和分割等下游任务的性能产生重大影响。虽然最近的先进技术通过不变特征学习模块提高了性能，但它们仍未完全解决暗光条件的建模问题。", "innovation": "本文通过拓展经典朗伯模型来更好地描述暗光条件，并转移到频域进行分析，理论上证明了频域通道比可以用于通过结构化滤波过程提取光照不变特征。提出了一种名为FRBNet的新颖且端到端可训练模块，该模块将频域通道比操作与可学习的频域滤波器集成用于整体光照不变特征增强。FRBNet可以无缝集成到现有的网络中处理暗光下游任务，而无需修改损失函数。", "conclusion": "广泛的实验表明，FRBNet在各种下游任务中表现出色，包括黑暗物体检测的+2.2 mAP和夜间分割的+2.9 mIoU。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23409", "html_url": "https://arxiv.org/abs/2510.23409", "title": "Eigen-Value：基于特征值方法的高效域稳健数据估值", "title_en": "Eigen-Value: Efficient Domain-Robust Data Valuation via Eigenvalue-Based Approach", "authors": "Youngjun Choi,Joonseong Kang,Sungjun Lim,Kyungwoo Song", "background": "在以数据为中心的人工智能时代，数据估值已成为关键问题。现有数据估值方法主要在一致分布（ID）场景下估计移除单个数据点的影响，但在不同分布（OOD）场景下往往表现不佳，尤其是在验证集中没有OOD数据的情况下。虽然存在一些OOD感知方法，但由于计算成本高昂，难以实际部署。因此，迫切需要一种能够高效、轻量级地进行OOD稳健数据估值的方法，特别是在存在领域变化的大规模应用场景中。", "innovation": "提出了Eigen-Value (EV) 框架，这是一种基于ID数据集的插件式数据估值方法，能够高效且轻量级地进行OOD鲁棒数据估值。EV通过特征值比率提供了一种新型的领域不连续性谱估计方法，并利用扰动理论估计每个数据点对这一差异的边际贡献，从而缓解了计算负担。此外，EV可以通过增加EV项直接插件到基于ID损失的方法中，而不需要额外的训练循环。", "conclusion": "实验结果表明，EV在多种实际数据集上实现了改进的OOD鲁棒性和稳定的值排名，同时保持了计算上的轻量级。这表明EV在存在领域变化的大规模应用场景中是实际可行的，提供了一条有效的OOD鲁棒数据估值路径。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17281", "html_url": "https://arxiv.org/abs/2510.17281", "title": "MemoryBench：LLM系统中的记忆与连续学习基准", "title_en": "MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems", "authors": "Qingyao Ai,Yichen Tang,Changyue Wang,Jianming Long,Weihang Su,Yiqun Liu", "background": "近年来，通过扩大数据、参数和测试时的计算量来提升语言模型系统的性能已成为主流方法，但由于高质量数据资源的逐渐枯竭和额外计算资源增益的边际效应，这些方法的上限几乎已经到达。受人类和传统AI系统从实践中学习、构建记忆和持续学习框架的启发，构建记忆和连续学习框架已成为近期文献中的重要且流行的研究方向。然而，现有的LLM系统记忆基准大多侧重于在包含长格式输入的同质阅读理解任务上评估系统性能，而非测试系统在实际服务过程中从累积用户反馈中学习的能力。因此，作者提出了一个用户反馈模拟框架和涵盖多个领域、语言和任务类型的全面基准，以评估LLM系统的持续学习能力。实验表明，最先进的基准方法的有效性和效率远远不够理想，希望通过此基准为未来LLM系统记忆与优化算法的研究铺平道路。", "innovation": "本文提出了一个用户反馈模拟框架和全面基准，涵盖多个领域、语言和任务类型，以评估LLM系统的持续学习能力，填补了当前基准在实际服务时间从用户反馈中学习能力测试方面的空白。", "conclusion": "最新的基准方法在有效性和效率方面不尽如人意，作者希望此基准能够引导未来LLM系统记忆与优化算法的研究方向。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23730", "html_url": "https://arxiv.org/abs/2510.23730", "title": "评估长程记忆在长上下文问答中的表现", "title_en": "Evaluating Long-Term Memory for Long-Context Question Answering", "authors": "Alessandra Terranova,Björn Ross,Alexandra Birch", "background": "为了使大型语言模型实现真正连贯的对话并从经验学习中受益，它们需要记忆功能。尽管已有研究集中于开发复杂的记忆系统，但对于哪些类型的记忆最适合长上下文对话任务仍缺乏明确的认识。本文通过使用基于合成长上下文对话的基准测试LoCoMo，对记忆增强方法进行了系统的评估，这些对话经过标注以便完成需要多种推理策略的问答任务。论文分析了基于上下文的全对话提示、基于检索增强生成的语义记忆、自主记忆、情景记忆以及基于提示优化的程序性记忆等几种记忆增强方法。研究表明，记忆增强方法可以将令牌使用量减少超过90%，同时保持竞争性的准确性。记忆架构的复杂性应与模型能力相匹配，小型基础模型从基于检索的生成（RAG）中受益最大，而经过强指令调优的推理模型则从情景记忆学习和更复杂的自主语义记忆中获益。特别是情景记忆可以帮助大语言模型识别自身知识的局限性", "innovation": "本文通过使用LoCoMo基准测试，系统地评估了多种记忆增强方法在长上下文对话问答任务中的应用效果。论文强调了情景记忆、基于检索增强生成的语义记忆、自主记忆等不同类型的记忆对不同能力模型的影响，揭示了不同的记忆类型在不同模型中的最佳应用方式，并指出情景记忆可以帮助大语言模型识别其知识局限性。", "conclusion": "记忆增强方法可以显著减少语言模型在长上下文对话问答任务中的令牌使用量，并保持高准确性。记忆架构的复杂性应根据模型的能力进行调整。对于小型基础模型，基于检索的生成（RAG）方法最为有效；对于经过强指令调优的推理模型，情景记忆和复杂语义记忆则更为有利。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23842", "html_url": "https://arxiv.org/abs/2510.23842", "title": "语用学如何塑造手势：一项涉及STEM美式手语话语的计算案例研究", "title_en": "How Pragmatics Shape Articulation: A Computational Case Study in STEM ASL Discourse", "authors": "Saki Imai,Lee Kezar,Laurel Aichler,Mert Inan,Erin Walker,Alicia Wooten,Lorna Quandt,Malihe Alikhani", "background": "现有的大多数先进手语模型都是在手语翻译者或孤立的手势词汇数据上进行训练的，这忽略了自然对话中的变量性。人类交际会根据上下文和对话双方动态调整，这种调整通过空间和时间的变化及手势表达方式体现出来。这种调整特别在教育场景中表现得尤为明显，教师和学生会使用新的词汇。", "innovation": "本研究收集了一个美式手语（ASL）STEM（科学、技术、工程和数学）对话的运动捕捉数据集，用于对比双向互动手势、单人手语讲授以及翻译文本之间的差异。使用连续的动力学特征，研究将对话特征中的同步调节与个人努力减少分离，并展示了STEM术语反复出现时的时间空间变化。研究表明，对话手势比孤立的手势短24.6%-44.6%，并且这种变化在单向讲解中不明显。此外，研究评估了手语嵌入模型在识别STEM手势和推测参与者随着时间的互动程度方面的性能。", "conclusion": "本研究将语言分析与计算建模结合起来，旨在理解语用学如何影响手语的表达和手语技术中的表示方式。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23458", "html_url": "https://arxiv.org/abs/2510.23458", "title": "BrowseConf: 根据信心水平调整测试时缩放的网络代理", "title_en": "BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents", "authors": "Litu Ou,Kuan Li,Huifeng Yin,Liwen Zhang,Zhongwang Zhang,Xixi Wu,Rui Ye,Zile Qiao,Pengjun Xie,Jingren Zhou,Yong Jiang", "background": "语言模型（LLMs）的置信度是模型不确定性和答案可靠性的有用指标。现有研究主要集中在单轮对话场景，而对于复杂多轮交互中的置信度研究有限。本研究探讨了基于LLM的搜索代理在长时间交互序列后是否有能力通过口头化信心评分来表达自己的信心，这相比单一交互场景是一个更加具有挑战的任务。研究发现，模型在高信心时任务准确率较高，而在低信心时接近零准确率。基于此观察，提出了一种称为测试时缩放（TTS）的方法，该方法使用信心分数来确定答案的质量，并鼓励模型直到达到满意的信心水平后再次尝试。结果表明，提出的方法显著减少了令牌消耗，同时展示出与基线固定预算TTS方法相当的性能。", "innovation": "提出了一种测试时缩放（TTS）的方法，通过口头化信心评分来确定答案质量，并鼓励模型达至满意的信心水平后再次尝试。这种方法在显著减少令牌消耗的同时展示了与固定预算TTS基线方法相当的性能。创新之处在于将信心评分应用于多轮交互，以及提出的方法可以有效提高模型答案质量同时节省资源。", "conclusion": "本文研究了基于LLM的搜索代理是否能在长时间序列交互后有效表达自己的信心，并提出了测试时缩放（TTS）方法。实验结果显示该方法显著减少了令牌消耗，并在性能上与基线方法相当。表明在多轮交互场景中使用信心评分可以有效提高模型答案质量并节省资源。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.22917", "html_url": "https://arxiv.org/abs/2510.22917", "title": "HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment", "title_en": "HyPerNav: Hybrid Perception for Object-Oriented Navigation in Unknown Environment", "authors": "Zecheng Yin,Hao Zhao,Zhen Li", "background": "ObjNav技术使机器人能够在未知环境中直接自主导航到目标对象。然而，在这样的环境中有效感知至关重要，虽然个人视角的RGB-D传感器能够提供丰富的局部信息，实时的全局地图则提供了有价值的上下文信息，但现有的大多数研究主要集中在单一感知源上，忽视了这两种互补感知方式的结合使用，尽管人类自然会同时关注这两种信息。随着视觉语言模型（VLM）的迅速发展，研究者提出了HyPerNav方法，利用VLM的强大推理能力和视-语言理解能力，同时感知局部和全局信息，提高在未知环境中导航的有效性和智能化。", "innovation": "HyPerNav方法结合了视觉语言模型的推理能力和视-语言理解能力，同时利用个人视角的RGB-D传感器提供的局部信息和实时的全局地图提供的上下文信息，从而增强了未知环境中导航的有效性和智能性。在大规模模拟评估和实地验证中，HyPerNav的方法在对比流行基准方法时达到了最先进的性能。", "conclusion": "通过采用混合感知方法，HyPerNav能够捕获更多的线索并更有效地找到目标对象，同时利用个人视角的观察信息和全局地图信息。进一步的消融研究证明了混合感知对导航性能的贡献。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23853", "html_url": "https://arxiv.org/abs/2510.23853", "title": "多轮LLM代理的时间盲视：工具使用与人类时间感知的错位", "title_en": "Temporal Blindness in Multi-Turn LLM Agents: Misaligned Tool Use vs. Human Time Perception", "authors": "Yize Cheng,Arshia Soltani Moakhar,Chenrui Fan,Kazem Faghih,Parsa Hosseini,Wenxiao Wang,Soheil Feizi", "background": "大型语言模型代理在多轮对话场景中被广泛用于与用户交互并执行任务，但在动态环境中，它们受限于缺乏时间感知，无法考虑到消息之间的时间流逝。这就造成了一个关键问题：代理在决定是否基于时间间隔调用工具时，会出现过度依赖或不足依赖过往上下文的情况。为了研究和解决这一问题，研究者提出了一种名为TicToc-v1的数据集，包含34个不同时间敏感性的场景，每个场景包含多轮对话轨迹，用户的问题依赖于自上次消息后的时间长短。研究通过添加显式的时间戳信息来赋予LLM时间背景，比较了时间信息对LLM决策的影响。", "innovation": "研究聚焦于大型语言模型代理在时间敏感场景中工具使用方面的局限性，通过引入TicToc-v1测试数据集，实现了对话时间信息的动态捕捉，并通过收集人类对使用工具偏好（prefer-noTool和prefer-Tool）的数据，评估了不同时间间隔下LLM决策与人类感知的匹配情况。研究发现，缺乏时间信息时，大多数模型仅略优于随机匹配，添加时间戳虽有轻微改进，但对于大型模型带来的效果有限。", "conclusion": "研究结果表明，需要特定的后训练校准来使多轮LLM的工具使用与人类的时间感知更加一致。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23854", "html_url": "https://arxiv.org/abs/2510.23854", "title": "LLMs能否叙述表格数据？一种针对Text-to-SQL系统输出自然语言表示的评估框架", "title_en": "Can LLMs Narrate Tabular Data? An Evaluation Framework for Natural Language Representations of Text-to-SQL System Outputs", "authors": "Jyotika Singh,Weiyi Sun,Amit Agarwal,Viji Krishnamurthy,Yassine Benajiba,Sujith Ravi,Dan Roth", "background": "在现代工业系统中，如多轮聊天代理，Text-to-SQL技术将自然语言（NL）问题与数据库（DB）查询连接起来。将表格型数据库结果转换为自然语言表示（NLR）使基于聊天的交互成为可能。目前，NLR生成通常由大型语言模型（LLMs）处理，但对于表格结果在自然语言中的信息损失或表示错误问题，仍然缺乏充分的研究。", "innovation": "本文提出了一种新型评估方法——Combo-Eval，结合了多种现有方法的优点，提高了评估的准确性，并在保持评估准确性的前提下，使对LLMs的调用减少了25-61%。此外，作者还提出了首个专门用于NLR基准测试的数据集NLR-BIRD，并通过人工评估显示了Combo-Eval与人类判断的高度一致，适用于有或无真实参考的情况。", "conclusion": "通过引入Combo-Eval和NLR-BIRD数据集，该研究为评价LLMs作为Text-to-SQL系统输出的自然语言表示提供了新的工具，并证明了这种新方法的有效性和优越性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23766", "html_url": "https://arxiv.org/abs/2510.23766", "title": "BitSkip：量化与早期退出组合的实证分析", "title_en": "BitSkip: An Empirical Analysis of Quantization and Early Exit Composition", "authors": "Ramshankar Bhuvaneswaran,Handan Liu", "background": "论文背景在于对高效大型语言模型（LLMs）的研究推动了复杂技术的发展，如极端量化和动态路由。尽管这些方法各自具有明显的优点，但它们的组合效果仍知之甚少。因此，本研究旨在通过BitSkip这一混合架构框架系统地探讨这些技术之间的相互作用。实验发现，一种简单的8位无Hadamard变换的量化模型（BitSkip-V1）不仅超越了其更为复杂的4位及Hadamard增强同类模型，其质量（困惑度为1.13）甚至接近全精度基线（困惑度为1.19），而Hadamard变换即使是8位精度下也显著降低了性能，增加了超过37,000%，可见基本训练不稳定性导致的问题。此外，BitSkip-V1 展现出优越的早期退出特征，从第18层可获得32.5%的速度提升，同时质量损失仅为4%。", "innovation": "本研究创新点在于提出了BitSkip，一种混合架构框架，以系统地探索量化和早期退出技术的交互作用。研究结果发现，与复杂的模型相比，一种简单的8位量化模型（BitSkip-V1）不使用Hadamard变换不仅表现更好，而且其在速度和质量上的表现能够与全精度模型相媲美。此外，实验发现引入Hadamard变换即使在8位精度下也导致了性能的灾难性下降，揭示了基本训练不稳定性的问题。BitSkip-V1展示了其在早期退出方面的优越特征，提供了一种有效平衡速度和质量的方法。", "conclusion": "研究结果表明，一种简单的8位量化模型（BitSkip-V1）无需Hadamard变换不仅性能超越其复杂的4位和增强的模型，而且还接近甚至超过全精度基线的质量。即使在引入Hadamard变换的情况下，特别是在8位精度下，其性能破坏性影响显著。BitSkip-V1展示了优秀的早期退出特性，结合速度显著提升，同时损失最低的质量。"}
{"llm_update_time": "20251029", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.21729", "html_url": "https://arxiv.org/abs/2510.21729", "title": "CustomIR：针对已知文档集合的无监督密集嵌入微调", "title_en": "CustomIR: Unsupervised Fine-Tuning of Dense Embeddings for Known Document Corpora", "authors": "Nathan Paull", "background": "密集嵌入模型已成为现代信息检索的关键部分，特别是在RAG管道中，但它们在应用到预训练分布之外的专门领域时的表现常常会退化。为了应对这一挑战，我们提出了CustomIR，这是一种框架，通过使用合成生成的查询-文档对，使预训练语言嵌入模型能够无监督地适应特定领域的语料库。CustomIR 利用大型语言模型（LLMs）创建多种多样的查询，这些查询基于已知的目标语料库，配以LLM验证的困难负样本，从而消除了对昂贵的人工注释的需求。实验结果表明，对于企业电子邮件和消息数据集，CustomIR 可以持续提升检索效果，即使是小型模型，在精确度@10提高达2.3个点，这使得小型模型得以与更大规模的替代方案相媲美，降低了RAG部署的成本。这些结果说明，针对特定领域的目标合成微调是一种可扩展且成本效益高的策略，可以提高领域特定性能。", "innovation": "提出了一种名为CustomIR的框架，通过使用合成生成的查询-文档对，使预训练的语言嵌入模型能够在不需要大量人工注释的情况下适应特定领域的语料库。", "conclusion": "实验证明CustomIR框架可以在不依赖大量人工注释的情况下，提高小规模模型在企业电子邮件和消息数据集上的检索效果，使得这些小型模型能够与更大规模的模型相媲美，从而降低RAG部署成本。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23828", "html_url": "https://arxiv.org/abs/2510.23828", "title": "超越理解：大型语言模型在具象语言文化处理中的语用鸿沟评估", "title_en": "Beyond Understanding: Evaluating the Pragmatic Gap in LLMs' Cultural Processing of Figurative Language", "authors": "Mena Attia,Aashiq Muhamed,Mai Alkhamissi,Thamar Solorio,Mona Diab", "background": "该研究评估了大型语言模型（LLMs）处理文化背景语言的能力，特别是理解并实际运用包含地方知识和文化细微差别的比喻表达的能力。研究使用比喻语言作为文化细微差别和地方知识的代理，设计了阿拉伯语和英语的语境理解、实际应用和含意解释评估任务，并评估了包括阿拉伯和英语在内的22个开源和版权软件的LLMs。结果显示，平均准确率呈现一定的阶层顺序：阿拉伯成语的准确率比英语成语低4.29%，而埃及口语惯用语的准确率比阿拉伯成语低10.28%。在实际应用任务中的准确率比理解任务低14.07%，但在提供上下文的惯用语句子时，准确率可以提高10.66%。模型在解释含义方面也表现不佳，对后一类惯用语的具体含意仅有85.58%的一致性与人类注释者的评估，而人类注释者之间的一致性达到100%。研究发现，比喻语言是文化推理的有效诊断工具：尽管LLMs可以解释比喻含义，但它们在正确运用这些含义时遇到困难。", "innovation": "本研究通过设计针对阿拉伯语和英语的比喻理解、实际应用和含意解释任务来评估LLMs处理具象语言的文化处理能力，这是对LLMs在这一领域评估的一个新颖方法。此外，还发布了Kinayat数据集，这是第一个用于评估比喻理解和实际应用的埃及阿拉伯语惯用语数据集。", "conclusion": "研究发现LLMs在处理具象语言的文化推理方面存在挑战，特别是在实际应用如此语言时。模型能够解释比喻含义，但在实际情况中正确使用这些含义时却遇到了困难。为了未来的研究，Kinayat数据集被发布为评测比喻理解和实际应用提供了工具。这些发现表明，进一步研究和改进LLMs对文化细微差别的理解非常重要。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23845", "html_url": "https://arxiv.org/abs/2510.23845", "title": "CRADLE Bench: 临床注释的多方面心理健康危机和安全风险检测基准", "title_en": "CRADLE Bench: A Clinician-Annotated Benchmark for Multi-Faceted Mental Health Crisis and Safety Risk Detection", "authors": "Grace Byun,Rebecca Lipschutz,Sean T. Minton,Abigail Lott,Jinho D. Choi", "background": "对于语言模型来说，识别潜在的心理健康危机情况（如自杀倾向、性侵、家庭暴力、儿童虐待和性骚扰）是一项至关重要的但尚未充分探索的挑战。在用户与模型交互过程中，出现这种情况时，模型必须能够可靠地识别并标记，否则可能导致严重后果。本研究介绍了一种新的基准测试CRADLE BENCH，旨在解决多方面危机检测的问题。该基准涵盖了符合临床标准的七种危机类型，并首次将时间标签纳入考量。", "innovation": "CRADLE BENCH是在有限危机类型的基准之上的一大创新，它针对七种危机类型，涵盖临床标准定义的问题，同时引入了时间标签。它提供600个临床标注的评估示例和420个开发示例，还包括约4000个用多个语言模型的多数投票集成自动标注的训练示例，这显著优于单一模型标注。此外，还根据不同一致性标准对六个危机检测模型进行了微调，提供了在不同一致性标准下训练的不同模型版本。", "conclusion": "CRADLE BENCH的引入为心理健康危机和安全风险检测提供了重要基准，有助于改善语言模型对这些关键问题的识别能力。通过对比不同模型表现出的性能差异，该基准能够推动研究和开发更有效的危机检测模型。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23870", "html_url": "https://arxiv.org/abs/2510.23870", "title": "OraPlan-SQL：一种以计划为中心的框架以应对复杂双语自然语言到SQL推理问题", "title_en": "OraPlan-SQL: A Planning-Centric Framework for Complex Bilingual NL2SQL Reasoning", "authors": "Marianne Menglin Liu,Sai Ashish Somayajula,Syed Fahad Allam Shah,Sujith Ravi,Dan Roth", "background": "该论文提出了一种系统OraPlan-SQL，用于2025年的Archer NL2SQL评估挑战。该评估挑战需要处理复杂的推理任务，如算术、常识以及假设性推理。系统取得了显著的成绩，在执行准确性方面超越了排名第二的系统，分别达到55.0%（英文）和56.7%（中文），同时SQL的有效性保持在99%以上。", "innovation": "该系统采用了一个代理框架，包括生成自然语言步骤计划的规划代理，和将这些计划转换为可执行SQL的SQL代理。OraPlan-SQL的主要创新在于它通过反馈引导的元提示策略改进了一个综合规划器，而不是依赖多个子代理，从而减少了编排开销。系统通过社群合对小型预留集的失败案例进行分组，并利用人类输入对语言模型进行微调，生成纠正指南，从而改善了泛化能力。此外，系统还处理了多语言场景下出现的转写和实体匹配问题，通过实体链接生成了实体的替代表征形式，并明确地将它们包含在计划中。最后，系统通过计划多元化提升了可靠性，为每个查询生成了多个候选计划，SQL代理为每个计划生成了一个查询，并通过多数投票选择最终输出。", "conclusion": "OraPlan-SQL系统在挑战中取得了优秀的成绩，表明了其在处理复杂双语自然语言到SQL的推理任务中的有效性。通过集成多种改进策略，如多语言处理、实体链接和计划多样性，该系统提供了一种有效的解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23921", "html_url": "https://arxiv.org/abs/2510.23921", "title": "通过最小上下文增强揭秘大语言模型偏见", "title_en": "Breaking the Benchmark: Revealing LLM Bias via Minimal Contextual Augmentation", "authors": "Kaveh Eskandari Miandoab,Mahammed Kamruzzaman,Arshia Gharooni,Gene Louis Kim,Vasanth Sarathy,Ninareh Mehrabi", "background": "大型语言模型在训练过程中表现出因数据的辨别特性而产生的刻板偏见。尽管已经开发出许多方法和模型以避免在决策中使用这种刻板信息，但现有方法在偏见校正方面显示出脆弱性。研究发现，对公平性评估模型的轻微调整（输入扰动）即可引发大规模语言模型（LLMs）的行为刻板化，尤其在被研究文献较少涉及的社区中，模型更易表现出偏见行为，强调了扩展公平性和安全性研究的重要性。", "innovation": "本文提出了一种新的、通用的增强框架，包含三个可插入的步骤，并对多个公平性评估基准适用。通过应用增强技术到公平性评估数据集（Bias Benchmark for Question Answering (BBQ)），发现即使是最先进的开放与封闭权重模型，对输入的轻微扰动也会引发模型行为的刻板化，特别在文献较少涉及的群体中，模型更容易显示出偏见。", "conclusion": "大型语言模型在输入微调后容易表现出刻板行为，尤其是针对较不受重视的群体。因此，需要扩展相关研究以包括更多样化的社区，以提高模型的公平性和安全性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23896", "html_url": "https://arxiv.org/abs/2510.23896", "title": "AfriMTEB 和 AfriE5：为非洲语言评估和适应文本嵌入模型", "title_en": "AfriMTEB and AfriE5: Benchmarking and Adapting Text Embedding Models for African Languages", "authors": "Kosei Uemura,Miaoran Zhang,David Ifeoluwa Adelani", "background": "文本嵌入是许多自然语言处理任务的关键组成部分，尤其是对于像检索增强生成这样的方法，对于预防大规模语言模型的幻觉至关重要。尽管最近发布了大规模多语言多任务评估基准（MMTEB），但非洲语言仍严重缺乏代表性，大多数现有任务来自翻译基准，如 FLORES 聚类或 SIB-200。", "innovation": "本文介绍了 AfriMTEB 平台，它扩展了 MMTEB，涵盖了 59 种语言、14 项任务和 38 个数据集，包括六个新数据集。与许多包含不到五种语言的 MMTEB 数据集不同，新添加的数据集涵盖了 14 到 56 种非洲语言，并引入了如仇恨言论检测、意图检测和情感分类等全新任务。此外，还提出了 AfriE5，这是一种通过跨语言对比蒸馏适应非洲语言的 mE5 模型。评估表明，AfriE5 在性能上实现了最先进的成果，优于诸如 Gemini-Embeddings 和 mE5 这样的强基线。", "conclusion": "AfriMTEB 通过扩展 MMTEB 极大地提高了非洲语言的代表性，而 AfriE5 通过适应这些语言的模型为非洲语言的文本嵌入任务树立了新的标准。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23946", "html_url": "https://arxiv.org/abs/2510.23946", "title": "利用LLM进行早期阿尔茨海默病预测", "title_en": "Leveraging LLMs for Early Alzheimer's Prediction", "authors": "Tananun Songdechakraiwut", "background": "文章介绍了一种基于连接组的LLM框架，该框架将动态fMRI连接性编码为时间序列，应用稳健的规范化，并将这些数据映射到适合冻结预训练LLM的表示形式，以进行临床预测。该方法应用于早期阿尔茨海默病诊断，能够实现敏感的预测，错误率低于临床认可的门槛，对早期阿尔茨海默病干预具有重要意义。", "innovation": "这种方法创新地将动态fMRI连接性编码为时间序列，并应用了稳健的规范化技术。然后，这些数据被映射到适合LLM的表示形式，以进行临床预测。这种连接组指导的LLM框架能够在早期准确预测阿尔茨海默病的发展，为早期干预提供可能性。", "conclusion": "研究方法应用于早期阿尔茨海默病检测，实现了敏感的预测，错误率低于临床认可的门槛。这种方法对早期阿尔茨海默病的干预具有潜在的意义。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23924", "html_url": "https://arxiv.org/abs/2510.23924", "title": "基于指令遵循LLM的基于代理的自动索赔匹配", "title_en": "Agent-based Automated Claim Matching with Instruction-following LLMs", "authors": "Dina Pisarevskaya,Arkaitz Zubiaga", "background": "论文介绍了一种新的基于代理的方法，用于自动索赔匹配任务，使用指令遵循的大语言模型（LLMs）。传统上，这种任务可能涉及复杂的自然语言处理技术和人工生成的提示。作者提出了一种两步管道策略，先使用大语言模型生成提示，然后利用这些提示作为二元分类任务来执行索赔匹配。这表明，生成的提示可以通过大语言模型优于手动生成的提示，并且在生成过程中较小的LLMs也可以与较大的LLMs表现得一样好，从而节省了计算资源。此外，作者还展示了在管道的不同步骤中使用不同LLMs的有效性。", "innovation": "提出了一个新的基于代理的方法，使用指令遵循的大语言模型自动执行索赔匹配任务，通过两步管道：首先使用LLMs生成提示，然后将它们作为二元分类任务执行匹配。实验表明，LLMs生成的提示不仅能够优于人类生成的提示，而且较小的LLMs在生成过程中与较大的LLMs具有相似的表现，这使得可以节省计算资源。此外还发现，在管道的不同步骤中使用不同的LLMs可以提高效果。", "conclusion": "研究表明，指令遵循的大语言模型在生成提示和执行索赔匹配任务方面的表现优于手动生成的提示，并且可以在生成过程中使用较小的LLMs来节省计算资源。此外，通过让不同的大语言模型分别执行提示生成和匹配任务，可以进一步提高效果。对提示生成过程的研究还为理解大语言模型中索赔匹配的理解提供了见解。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23995", "html_url": "https://arxiv.org/abs/2510.23995", "title": "M-Eval: 一种基于异质性分析的多证据验证框架在医疗RAG系统中的应用", "title_en": "M-Eval: A Heterogeneity-Based Framework for Multi-evidence Validation in Medical RAG Systems", "authors": "Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bin Qin", "background": "检索增强生成（RAG）已经在通过大型语言模型（LLMs）与外部医学文献的整合来增强医疗问答系统方面展示了潜力。尽管LLMs可以从外部文献中检索相关医学文章以生成更专业的回复，但当前的RAG应用仍然面临问题，如生成不正确信息（如幻觉）以及未能正确使用外部知识。为了解决这些问题，本研究提出了一种名为M-Eval的新方法，该方法受循证医学（EBM）中的异质性分析方法启发，能够利用多源证据检查RAG响应中的事实错误。", "innovation": "本研究提出了M-Eval，这是一种基于异质性分析的多证据验证框架，用于医学RAG系统。M-Eval的方法首先从外部知识库中提取额外的医学文献，然后检索RAG系统生成的证据文档，并使用异质性分析来检查这些证据是否支持响应中的不同观点。此外，该方法还评估了RAG系统提供的证据的可靠性。研究结果表明，M-Eval相对于各种LLMs提高了高达23.31%的准确性，这有助于检测现有的RAG医疗系统中的错误，并使得LLMs的应用更加可靠，减少了诊断错误。", "conclusion": "M-Eval方法能够通过多源证据验证RAG响应中的事实错误，尤其在医疗领域具有重要作用，有助于提高RAG系统的准确性与可靠性，减少诊断错误。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23998", "html_url": "https://arxiv.org/abs/2510.23998", "title": "PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine", "title_en": "PICOs-RAG: PICO-supported Query Rewriting for Retrieval-Augmented Generation in Evidence-Based Medicine", "authors": "Mengzhou Sun,Sendong Zhao,Jianyu Chen,Bin Qin", "background": "证据主导医学（EBM）研究一直非常重要。为了减少医疗事故，需要为医生或患者找到合适的医学理论支持，而这一过程常由人类查询相关文献数据库完成，但这种方法缺乏客观性和效率。因此，研究人员使用检索增强生成（RAG）来自动搜索证据并生成回应。然而，当前的RAG方法难以处理实际临床场景中的复杂查询。例如，如果查询缺少某些信息或使用含糊的语言，模型可能会检索到无关的证据并生成不有用的答案。", "innovation": "为了应对这一问题，本文提出了PICOs-RAG方法，该方法能够将用户查询扩展为更专业、更规范的格式，并利用EBM中的PICO格式（一种检索策略工具）来提取最重要的用于检索的信息。此方法显著提高了检索效率和相关性，相比基线方法，检索效率提高了8.8%。因此，PICOs-RAG使得大型语言模型能够成为EBM中可行且可靠的医学助手。", "conclusion": "PICOs-RAG方法显著提升了RAG在处理EBM复杂查询时的性能，实现了高质量的证据检索和生成，为EBM中的医学理论支持提供了有力的工具。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23941", "html_url": "https://arxiv.org/abs/2510.23941", "title": "无需训练标签的自动提示：跨语言电子商务商品质量评估的大语言模型级联", "title_en": "Auto prompting without training labels: An LLM cascade for product quality assessment in e-commerce catalogs", "authors": "Soham Satyadharma,Fatemeh Sheikholeslami,Swati Kaul,Aziz Umit Batur,Suleiman A. Khan", "background": "该研究介绍了用于电子商务中的产品质量自动评估的大语言模型（LLMs）的创新框架。传统方法通常需要大量的训练标签和模型微调，而在实际应用中，这些资源往往有限。本文指出，该系统的独特之处在于能够从少量人工编写的提示开始，自动优化提示以满足特定目录的需求，无需额外的训练或微调。", "innovation": "该研究创新性地引入了一个无需训练标签的大语言模型级联框架，该框架能够自动生成和优化评估提示。它从少量的人工编写的提示开始，通过级联逐步优化指令以适应特定目录的要求。这种方法克服了传统提示方法的限制，提高了整体的准确性和召回率，同时极大地减少了对领域专家的工作负担。", "conclusion": "实验结果表明，该自动提示级联方法在多种语言和质量评估任务中都能有效提高准确性和召回率，此外，还显著降低了领域专家的工作量——从每个属性的5.1小时减少到3分钟，减少了99%的工作量。这种方法不仅提高了产品质量评估的效率，还展示了其在多种语言环境下的广泛适用性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24021", "html_url": "https://arxiv.org/abs/2510.24021", "title": "SpecKD: Speculative Decoding for Effective Knowledge Distillation of LLMs", "title_en": "SpecKD: Speculative Decoding for Effective Knowledge Distillation of LLMs", "authors": "Haiduo Huang,Jiangcheng Song,Yadong Zhang,Pengju Ren", "background": "知识蒸馏（KD）已经成为将大型语言模型（LLMs）压缩成更小、更高效的学徒模型的核心技术。然而，传统的KD方法通常对所有token施加均匀的蒸馏损失，而不考虑老师的信心水平。这种无差别的模仿可能会引入噪声，因为学生被迫学习教师的不确定或高熵预测，这可能最终损害学生模型的表现，尤其是在老师模型庞大且强大时。", "innovation": "本文提出了以“猜测与验证”范式为基础的推测性知识蒸馏（SpecKD）——一种新颖且插拔式的框架，引入了一个动态的、基于token的门控机制。在每一步骤中，学生的token猜测将被验证与老师的预测分布；仅对“接受”的token应用选择性的蒸馏损失，而“拒绝”的token则被遮蔽排除。", "conclusion": "广泛的实验表明，SpecKD在各种文本生成任务中始终能够显著优于强大的KD基线，从而实现更稳定的训练和更强大的学生模型，并且达到了最先进的成果。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23884", "html_url": "https://arxiv.org/abs/2510.23884", "title": "临床预测的语言模型", "title_en": "Language Models for Longitudinal Clinical Prediction", "authors": "Tananun Songdechakraiwut,Michael Lutz", "background": "研究探讨了一种轻量级框架，该框架能够将冻结的大型语言模型适配以分析纵向临床数据。这种框架通过整合患者的历史信息和上下文，能够在无需微调模型的情况下生成精准的预测。特别是在神经心理学评估方面，即使使用少量的训练数据也能实现高度准确和可靠的性能，为早期阿尔茨海默病的监测带来了希望。", "innovation": "该框架的主要创新点在于通过整合患者的历史信息和上下文，利用冻结的大型语言模型进行纵向临床数据的分析预测，能够在无需对模型进行微调的情况下实现精准的预测。这种方法为神经心理学评估和早期阿尔茨海默病的监测提供了一种新的可能。", "conclusion": "在神经心理学评估方面，该轻量级框架展示了即使使用少量训练数据也能实现高度准确和可靠的性能，显示出其在早期阿尔茨海默病监测中的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24014", "html_url": "https://arxiv.org/abs/2510.24014", "title": "TEXT2DB：带有大型语言模型代理的集成感知信息提取", "title_en": "TEXT2DB: Integration-Aware Information Extraction with Large Language Model Agents", "authors": "Yizhu Jiao,Sha Li,Sizhe Zhou,Heng Ji,Jiawei Han", "background": "信息提取（IE）的任务是从文本中抽取结构化知识。然而，由于IE本体与下游应用需求之间的不匹配，IE的输出往往不易直接利用。本文提出了一种新的信息提取任务TEXT2DB，强调IE输出与目标数据库（或知识库）的整合。给定用户指令、文档集合和数据库，模型需要从文档集合中抽取并更新数据库中的值以满足用户指令。这一任务要求理解用户指令的内容以及根据给定的数据库/知识库模式动态适应提取方法。", "innovation": "提出了一个新的信息提取任务TEXT2DB，该任务特别强调将IE输出与目标数据库或知识库相结合。此外，还提出了一种基于大型语言模型代理的OPAL框架，包括观察者组件、计划者组件和分析器组件，以生成基于代码的计划并调用IE模型。实验表明，OPAL可以通过生成不同的代码计划并调用所需的IE模型来适应各种数据库模式。该框架还能够提供关于代码质量的反馈以提升数据库的更新质量。", "conclusion": "实验结果显示，OPAL可以通过生成不同的代码计划以及调用所需的IE模型，成功适应多种数据库模式。文章还指出了处理大型复杂依赖关系的数据库和抽取幻觉等困难情况，认为这些问题未来需要进一步研究，以改进文本到数据库的映射机制。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24051", "html_url": "https://arxiv.org/abs/2510.24051", "title": "Pie：为新兴大语言模型应用程序设计的可编程服务系统", "title_en": "Pie: A Programmable Serving System for Emerging LLM Applications", "authors": "In Gim,Zhiyao Ma,Seung-seob Lee,Lin Zhong", "background": "当前的大语言模型（LLM）应用涉及多种推理策略和自主工作流程，现有的基于单一令牌生成循环的服务系统无法满足其需求。", "innovation": "Pie 是一个可编程的大语言模型服务系统，设计旨在灵活性和效率上更优。它将传统的生成循环分解为细粒度的服务处理程序，并通过 API 暴露出来，将生成过程的控制权交给用户提供的程序（称为 inferlets）。Pie 使用 WebAssembly 执行 inferlets，利用其轻量级的沙箱环境。应用可以在不需要修改服务系统的情况下实施新的 KV 缓存策略、定制生成逻辑和无缝集成计算和 I/O。这种系统显著提高了基于应用的优化能力，特别是在自主工作流程中的延迟和吞吐量方面。", "conclusion": "Pie 在标准任务上的性能与现有先进技术相当（延迟开销 3-12%），在自主工作流程方面显著提升了性能（1.3-3.4 倍的延迟和吞吐量提高）。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24023", "html_url": "https://arxiv.org/abs/2510.24023", "title": "成功和成本促进高效沟通中的惯例形成", "title_en": "Success and Cost Elicit Convention Formation for Efficient Communication", "authors": "Saujas Vaduguru,Yilun Hua,Yoav Artzi,Daniel Fried", "background": "人类通过共享对话上下文逐渐提高沟通的效率和成功率。一种表现形式是形成临时的语言惯例，利用共享的对话上下文，使得人们能在较少的沟通成本下达成共识。已有研究表明，模仿人类这样进行沟通的方式可以帮助大型多模态模型学习高效的沟通策略，但这一过程中通常需要额外的人类生成的数据补充。本研究致力于利用模拟参考游戏来训练多模态模型形成惯例，从而提高沟通效率，而无需额外的人类数据输入，以此来研究并改进模型的沟通能力。该研究在涉及照片和七巧板图像的重复参考游戏中进行实验，结果显示，与对照组相比，该方法能够显著降低模型的通讯信息长度并提高沟通的成功率，同时，人类与该模型交流的速度也有所提高。", "innovation": "本文提出了一种新型的方法，通过模拟的参考博弈来训练大型多模态模型形成语言惯例，从而实现高效沟通。这种策略独特之处在于，不需要额外的人类生成的数据，同时，通过使模型在成功和成本之间取得平衡，可以有效促进惯例的形成。这种策略的应用将使得多模态模型在实际场景中能够更好地与人类用户进行有效的沟通交流。", "conclusion": "在重复的参考游戏中，通过对部分涉及照片和七巧板图像的交互实验，我们的方法能够使模型与人类交流时大大缩短消息长度，提高成功沟通率，并且人类在与形成惯例的模型交流时反应更快。进一步的研究表明，单纯的基于成功或成本的训练是不够的，同时考虑这两方面是促进惯例形成的关键。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24073", "html_url": "https://arxiv.org/abs/2510.24073", "title": "挑战多语言LLM：一种新的分类法和用于解析翻译幻觉的基准", "title_en": "Challenging Multilingual LLMs: A New Taxonomy and Benchmark for Unraveling Hallucination in Translation", "authors": "Xinwei Wu,Heng Liu,Jiang Zhou,Xiaohu Zhao,Linlong Xu,Longyue Wang,Weihua Luo,Kaifu Zhang", "background": "大型语言模型（LLMs）在机器翻译上取得了进步，但仍然容易出现幻觉问题。现有的机器翻译基准测试无法充分揭示多语言LLM的失败情况。因此，需要一个新的框架来识别这些幻觉，特别是分离指令脱钩和源脱钩问题，并建立一个综合的翻译测试基准来保护多语言LLM不出现错误。", "innovation": "提出了一个诊断框架，引入了分离指令脱钩和源脱钩的新分类法；创建了多语言的人工审核基准（HalloMTBench），覆盖了11种英译X方向；使用4个前端LLM生成候选翻译，并通过LLM众包和专家审核进行验证，筛选出5,435个高质量实例；揭示了幻觉触发因素，包括幻觉模式、模型规模、源长度敏感性、语言偏见和强化学习放大语言混合问题。", "conclusion": "HalloMTBench提供了一个能够引导诊断LLM翻译错误的测试平台，有助于进一步研究和改进LLM翻译过程中的幻觉问题。该基准数据集已在https://... 上公开供研究者使用。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24126", "html_url": "https://arxiv.org/abs/2510.24126", "title": "使用强化学习构建长期多轮搜索代理", "title_en": "Reinforcement Learning for Long-Horizon Multi-Turn Search Agents", "authors": "Vivek Kalyan,Martin Andrews", "background": "大语言模型（LLM）代理能够利用多轮对话和工具来解决复杂任务，基于提示的方法已经取得了很好的性能。然而，现有的方法是否可以通过学习经验进一步提升尚未得到验证。特别是在长期多轮搜索的情况下，已有模型的准确性有限。", "innovation": "本文通过在法律文档搜索基准测试中应用强化学习（RL），展示了这种学习方式可以显著提高搜索代理的能力，尤其是在长期多轮交互方面。实验表明，训练好的140亿参数的RL模型在准确率上优于当前前沿模型（分别为78% vs 85%）。此外，研究还发现，限制转数（训练和测试时）可以进一步提升代理的效果。", "conclusion": "研究表明，利用强化学习训练的搜索代理在评估指标上优于现有的强大模型，并且通过限制多轮交互的转数可以进一步优化代理的表现。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24102", "html_url": "https://arxiv.org/abs/2510.24102", "title": "Squrve: 统一且模块化的复杂真实世界文本到SQL任务框架", "title_en": "Squrve: A Unified and Modular Framework for Complex Real-World Text-to-SQL Tasks", "authors": "Yihan Wang,Peiyu Liu,Runyu Chen,Jiaxing Pu,Wei Xu", "background": "文本到SQL技术已迅速发展，多样化的学术方法取得了令人印象深刻的结果。然而，将这些技术部署到实际系统中仍然是一个挑战，这是因为缺乏集成工具。尽管取得了这些进展，本研究引入了Squrve，这是一个统一、模块化、广泛的文本到SQL框架，旨在将研究的最新成果与实际应用相结合。", "innovation": "Squrve首先建立了一个通用执行框架，标准化了调用接口，然后提出了基于七个抽象的有效原子实体组件的多参与者协作机制。实验表明，协作工作流在常用基准上的表现优于原始单个方法，从而为解决复杂的现实世界查询开辟了一条新的有效途径。", "conclusion": "实验结果表明，协作工作流在常用基准上的表现持续优于原始单一方法，从而为解决复杂的现实世界查询提供了新的有效途径。此外，相关代码已公开可用。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24139", "html_url": "https://arxiv.org/abs/2510.24139", "title": "LLM预训练语料库中的行级过滤之外", "title_en": "Beyond Line-Level Filtering for the Pretraining Corpora of LLMs", "authors": "Chanwoo Park,Suyoung Park,Yelim Ahn,Jongmin Kim,Jongyeon Park,Jaejin Lee", "background": "传统的行级过滤技术，如行级别的去重和尾随标点过滤，虽然广泛使用，但这些基本方法有时会丢弃有价值的内容，这可能会影响下游性能。", "innovation": "本文介绍两种新的方法：模式感知行级去重（PLD）和模式感知尾随标点过滤（PTF），通过增强传统的过滤技术。这些方法不仅考虑了行级别的信号，而且还考虑了这些信号在文档中的序列分布，从而能够保留可能被移除的结构上重要内容。通过训练1亿参数的小型语言模型，本文评估了这些方法在英韩语中的表现，结果表明，该方法在多项选择基准和SQuAD v1和KorQuAD v1上的生成性问答准确性上都有显著提升。", "conclusion": "本文通过提出模式感知行级去重和模式感知尾随标点过滤两种新方法，有效地提高了预训练语料库的质量，从而在下游任务中取得了更好的性能。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24150", "html_url": "https://arxiv.org/abs/2510.24150", "title": "Ko-MuSR：能够理解韩语的大语言模型的多步骤软推理基准", "title_en": "Ko-MuSR: A Multistep Soft Reasoning Benchmark for LLMs Capable of Understanding Korean", "authors": "Chanwoo Park,Suyoung Park,JiA Kang,Jongyeon Park,Sangho Kim,Hyunji M. Park,Sumin Bae,Mingyu Kang,Jaejin Lee", "background": "当前存在对长韩语叙事的多步、软推理评估有限的问题，而且缺乏能有效减少数据污染的基准。研究人员希望开发一个全面评估大语言模型在韩国长叙事中多步推理能力的基准。", "innovation": "该基准（Ko-MuSR）是首个专门针对长期韩国叙事的多步骤、软推理基准，包括完整的韩语叙事、推理链和多次选择问题。这些问题经过人工注释者验证，确保逻辑一致性和可回答性。研究还展示了区分多语言和基于韩语的大型语言模型在韩语推理任务中的表现，揭示了跨语言推理能力的一般性。此外，精心设计的提示策略，结合少量示例、推理痕迹和任务特定提示，进一步提高了模型的准确性，接近人类水平。", "conclusion": "Ko-MuSR 为推动韩语自然语言处理的进步提供了坚实的基础，通过系统评估长语境推理能力和提示策略进一步完善了该领域。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23949", "html_url": "https://arxiv.org/abs/2510.23949", "title": "揭示多语言LLM去学习潜在风险：仅英语去学习的危险", "title_en": "Uncovering the Potential Risks in Unlearning: Danger of English-only Unlearning in Multilingual LLMs", "authors": "Kyomin Hwang,Hyeonjin Kim,Seungyeon Kim,Sunghyun Wee,Nojun Kwak", "background": "有多项研究显示，仅使用英语数据尝试抹去多语言知识对于多语言LLM是不够的。然而，这些研究的分析主要集中在性能方面。本文将视角转向评估，并探讨了一种此前未被注意到的现象，当多语言LLM在完全微调后使用平行多语言数据集进行去学习时，会出现语言混淆的问题。即模型响应的语言与输入提示语言不一致，这是一个在去学习过程中会导致标准参考基指标失效的问题现象。", "innovation": "本文提出了一种新的评估方法，即N-gram基于的语言混合（N-Mix）分数来量化地展示语言混淆是多语言LLM中普遍存在且一致的问题，证明了当N-Mix分数高时，基于参考的指标会导致假阴性结果，并建议需要新的类型去学习评估方法，可以直接评估生成句子的内容，称为基于语义的指标。这些创新点深化了对多语言LLM去学习过程中语言混淆问题的理解，并提出了改进评估方法的新途径。", "conclusion": "本文通过引入N-Mix分数，量化显示语言混淆在多语言LLM中普遍存在且一致的现象，证明了基于参考的指标在高N-Mix分数时会导致假阴性，并建议需要基于语义的新型评估方法直接评估生成内容，从而揭示了多语言LLM去学习面临的潜在风险，尤其是仅英语数据下的去学习问题。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24178", "html_url": "https://arxiv.org/abs/2510.24178", "title": "MuSaG：德语全模态讽刺数据集", "title_en": "MuSaG: A Multimodal German Sarcasm Dataset with Full-Modal Annotations", "authors": "Aaron Scott,Maike Züfle,Jan Niehues", "background": "讽刺是一种复杂的修辞形式，其中意图含义与字面意思相矛盾。其在社交媒体和流行文化中的普遍存在对自然语言理解、情感分析和内容审核提出了持续挑战。随着多模态大型语言模型的出现，讽剌检测不再局限于文本，还需要融合来自音频和视觉的信息。现有的讽刺数据集多为单模态数据，缺乏多模态数据支持。实验展示了在会话环境中，人类主要依赖音频来识别讽刺，而现有模型在处理文本上表现最佳。这揭示了当前多模态模型的不足，需要开发更符合实际情况的模型。", "innovation": "首次构建了德语多模态讽刺检测数据集MuSaG，包含33分钟的手动挑选和人工标注的电视剧片段，每条数据提供对齐的文本、音频和视频模态，并分别由人类进行标注，支持单模态和多模态的评估。该数据集包括文本、音频和视频模态，且每个实例都由人类分别标注，支持多种模型的基准测试，并且公开发布，支持欺诈研究的发展和人机对齐的研究。", "conclusion": "结果显示，人类在对话中对音频的依赖度非常高，但现有模型在处理文本数据时表现最佳。这一发现揭示了当前多模态模型的局限性，强调了利用该数据集开发更适用于现实场景的模型的重要性。MuSaG的公开发布旨在支持未来的研究并促进人-模型一致性方面的发展。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24096", "html_url": "https://arxiv.org/abs/2510.24096", "title": "RegSpeech12:覆盖方言的孟加拉语自发语音语料库", "title_en": "RegSpeech12: A Regional Corpus of Bengali Spontaneous Speech Across Dialects", "authors": "Md. Rezuwan Hassan,Azmol Hossain,Kanij Fatema,Rubayet Sabbir Faruque,Tanmoy Shome,Ruwad Naswan,Trina Chakraborty,Md. Foriduzzaman Zihad,Tawsif Tashwar Dipto,Nazia Tasnim,Nazmuddoha Ansary,Md. Mehedi Hasan Shawon,Ahmed Imtiaz Humayun,Md. Golam Rabiul Alam,Farig Sadeque,Asif Sushmit", "background": "孟加拉语在南亚广泛使用，并在世界各地的移民社区中有较大影响力。该语言表现出由地理、文化和历史因素共同塑造的高度方言多样性。尽管孟加拉国有五个主要方言群：东部孟加拉语、曼邦胡米、兰普里、瓦伦德里和拉尔希，但是词汇、语法和形态方面的地区差异在更小的地理区域内进一步显现。尽管孟加拉语拥有丰富的语言资源，但系统性研究其方言的计算处理仍然相对不足。本研究旨在记录并分析这些方言的音韵和形态特性，探索为地区变体构建特别是自动语音识别（ASR）系统的可行性。此类努力有可能应用于虚拟助手和其他语言技术领域，既有助于方言多样性的保护，又促进整体包容性语言工具的应用，服务于孟加拉语使用者。", "innovation": "研究在孟加拉语方言的音韵和形态特性记录与分析方面进行了系统性探索，特别是为本地变体构建自动语音识别系统的可行性研究。此外，研究还创建了一个供公众使用的数据集，促进了相关领域的进一步研究和应用开发。", "conclusion": "研究为孟加拉语方言的音韵和形态学特性提供了系统性记录和分析，探索了构建针对地区变体的自动语音识别系统的可行性。通过创建和公开数据集，研究有助于方言多样性的保护和包容性数字工具的发展，同时为未来该领域的研究和完善自动化语言技术奠定基础。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24081", "html_url": "https://arxiv.org/abs/2510.24081", "title": "Global PIQA: 评估 100 多种语言和文化的物理常识推理", "title_en": "Global PIQA: Evaluating Physical Commonsense Reasoning Across 100+ Languages and Cultures", "authors": "Tyler A. Chang,Catherine Arnett,Abdelrahman Eldesokey,Abdelrahman Sadallah,Abeer Kashar,Abolade Daud,Abosede Grace Olanihun,Adamu Labaran Mohammed,Adeyemi Praise,Adhikarinayum Meerajita Sharma,Aditi Gupta,Afitab Iyigun,Afonso Simplício,Ahmed Essouaied,Aicha Chorana,Akhil Eppa,Akintunde Oladipo,Akshay Ramesh,Aleksei Dorkin,Alfred Malengo Kondoro,Alham Fikri Aji,Ali Eren Çetintaş,Allan Hanbury,Alou Dembele,Alp Niksarli,Álvaro Arroyo,Amin Bajand,Amol Khanna,Ana Chkhaidze,Ana Condez,Andiswa Mkhonto,Andrew Hoblitzell,Andrew Tran,Angelos Poulis,Anirban Majumder,Anna Vacalopoulou,Annette Kuuipolani Kanahele Wong,Annika Simonsen,Anton Kovalev,Ashvanth.S,Ayodeji Joseph Lana,Barkin Kinay,Bashar Alhafni,Benedict Cibalinda Busole,Bernard Ghanem,Bharti Nathani,Biljana Stojanovska Đurić,Bola Agbonile,Bragi Bergsson,Bruce Torres Fischer,Burak Tutar,Burcu Alakuş Çınar,Cade J. Kanoniakapueo Kane,Can Udomcharoenchaikit,Catherine Arnett,Chadi Helwe,Chaithra Reddy Nerella,Chen Cecilia Liu,Chiamaka Glory Nwokolo,Cristina España-Bonet,Cynthia Amol,DaeYeop Lee,Dana Arad,Daniil Dzenhaliou,Daria Pugacheva,Dasol Choi,Daud Abolade,David Liu,David Semedo,Deborah Popoola,Deividas Mataciunas,Delphine Nyaboke,Dhyuthy Krishna Kumar,Diogo Glória-Silva,Diogo Tavares,Divyanshu Goyal,DongGeon Lee,Ebele Nwamaka Anajemba,Egonu Ngozi Grace,Elena Mickel,Elena Tutubalina,Elias Herranen,Emile Anand,Emmanuel Habumuremyi,Emuobonuvie Maria Ajiboye,Eryawan Presma Yulianrifat,Esther Adenuga,Ewa Rudnicka,Faith Olabisi Itiola,Faran Taimoor Butt,Fathima Thekkekara,Fatima Haouari,Filbert Aurelian Tjiaranata,Firas Laakom,Francesca Grasso,Francesco Orabona,Francesco Periti,Gbenga Kayode Solomon,Gia Nghia Ngo,Gloria Udhehdhe-oze", "background": "目前，几乎没有任何涵盖大量语言和文化的大型语言模型特定评价基准。本文介绍了一个参与者手工构建的常识推理基准——Global PIQA，旨在覆盖100多种语言，涉及全世界65个国家的335名研究人员。Global PIQA 包含116种语言变体，分布在五个大洲、14个语言家庭和23种书写系统中。尽管最先进的大型语言模型在整体性能上表现良好，但在低资源语言上的表现较弱，存在高达37%的准确率差距，而随机猜测为50%。开放模型通常表现不如专有模型。Global PIQA 说明了在许多语言和文化中，日常生活知识仍然是一个需要改进的领域，同时还强调了复杂的推理和专家知识等更广泛讨论的能力。Global PIQA 除了用于大型语言模型的评估之外，还希望能够提供一个窥探嵌入人类语言的广泛文化多样性的窗口。", "innovation": "Global PIQA 是一个由335名来自65个国家的研究人员手工构建的常识推理基准，旨在评估100多种语言中的物理常识推理能力。该基准覆盖了五大洲、14个语言家族和23种书写系统，特别突出了文化特定的元素，如地方食品、习俗和传统。此外，还发现了最先进的大型语言模型在低资源语言上的表现较弱。环球PIQA展示了许多语言和文化中的日常生活知识在驱动语言模型改进的重要性，并对比了开放模型和专有模型的表现。", "conclusion": "Global PIQA 的建立表明，在多个语言和文化中，日常生活知识依然是改进的重点领域，而不仅仅是复杂的推理和专家知识。除了用于大型语言模型的评估外，大全PIQA还强调了文化的多样性，并提供了一个窗口，让研究者能够更好地理解和评估不同语言背景下模型的性能。这将推动跨文化的语言模型理解与应用的发展。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24179", "html_url": "https://arxiv.org/abs/2510.24179", "title": "探索相关知识对自然语言生成可解释性的影响", "title_en": "Exploring the Influence of Relevant Knowledge for Natural Language Generation Interpretability", "authors": "Iván Martínez-Murillo,Paloma Moreda,Elena Lloret", "background": "该论文探讨了外部知识整合对自然语言生成（NLG）的影响，特别关注常识生成任务。之前的研究通常忽略了外部知识的影响，但本文通过创建一种包含从ConceptNet中检索的语义关系并进行手动注释的新数据集KITGI，旨在填补这一空白。", "innovation": "本文提出了一个名为KITGI的新基准数据集，其中包括输入概念集和从ConceptNet检索的语义关系，以及人工标注的输出。使用T5-Large模型，该研究在包含完整外部知识和过滤掉高度相关的关系两种情况下比较了句子生成的效果，通过解释性基准测试识别并移除关键知识，重新生成句子，最终通过人工评估生成内容的常识合理性和概念覆盖范围。", "conclusion": "研究结果表明，使用完整外部知识生成的句子在两个评估标准上均达到91%的正确性，而过滤知识后性能显著下降至6%。这表明相关外部知识对于保持NLG的连贯性与概念覆盖至关重要。这项工作强调了需要设计可解释的、知识增强的NLG系统，并呼吁构建能够捕捉表面度量标准背后深层推理的评估框架。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24222", "html_url": "https://arxiv.org/abs/2510.24222", "title": "HACK: 沿着知识和确定性轴的幻觉", "title_en": "HACK: Hallucinations Along Certainty and Knowledge Axes", "authors": "Adi Simhi,Jonathan Herzig,Itay Itzhak,Dana Arad,Zorik Gekhman,Roi Reichart,Fazl Barez,Gabriel Stanovsky,Idan Szpektor,Yonatan Belinkov", "background": "LLMs中的幻象是一个严重的障碍，阻碍了其可靠使用。现有研究主要根据外部特性对幻觉进行分类，而不是其内部特性。这种方法忽略了基于其机制的幻觉可能需要定制的缓解策略。因此，提出了一种沿知识和确定性两个轴分类幻觉的框架，以更好地理解不同类型的幻觉并采取针对性的缓解措施。该框架通过特定模型的数据集区分了不同类型的知识和确定性幻觉，验证了基于知识分类的有效性。\n", "innovation": "提出了一个新的框架，沿着知识和确定性两个轴分类LLMs中的幻觉。引入了一种新的评估指标来测量缓解方法在这部分幻觉中的有效性。这一创新强调在幻觉分析中同时考虑知识和确定性的重要性，表明需要考虑到幻觉的内在因素，采用针对性的缓解策略。\n", "conclusion": "研究结果表明，在幻觉分析中同时考虑知识和确定性的重要性，并呼吁采取针对幻觉内在因素的定向缓解措施。此外，验证了某些缓解方法在处理幻觉时的不均衡表现，尤其是在知识和确定性都正确的关键情况下。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24208", "html_url": "https://arxiv.org/abs/2510.24208", "title": "超越神经不兼容性：通过潜在语义对齐促进大语言模型跨尺度知识转移", "title_en": "Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in Large Language Models through Latent Semantic Alignment", "authors": "Jian Gu,Aldeida Aleti,Chunyang Chen,Hongyu Zhang", "background": "大语言模型（LLMs）在其庞大的参数中编码了大量知识，这些知识可以通过定位、跟踪和分析来访问。尽管在神经可解释性方面取得了进展，但如何在细粒度上转移知识，即参数化知识转移（PKT），仍然不明确。一个关键问题是跨不同规模的LLMs实现知识的有效、高效的转移，这对于在LLMs之间转移知识时实现更大的灵活性和更广泛的适用性至关重要。由于神经不兼容性，现有的直接重用层参数的方法受到了限制，这是由于LLMs在架构和参数方面存在差异。", "innovation": "本文确定潜在空间中的语义对齐是跨尺度LLM知识转移的基本前提。我们的方法采用激活作为层间知识转移的介质，而不是直接使用层参数。利用潜在空间中的语义，我们的方法简单有效，优于之前的工作，更好地对齐了不同规模模型的行为。对四个基准的评估显示了我们方法的有效性。进一步的分析揭示了跨尺度知识转移的关键因素，并对潜在语义对齐的本质提供了见解。", "conclusion": "我们的方法在四个基准上的评估结果证明了其有效性，并通过潜在空间中的语义对齐简化了跨尺度知识转移的问题，这种方法能够更好地对齐不同规模模型的行为。进一步的分析揭示了跨尺度知识转移的关键因素，并提供了对潜在语义对齐本质的见解。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24020", "html_url": "https://arxiv.org/abs/2510.24020", "title": "通过细粒度语义置信奖励使LLMs学会放弃", "title_en": "Teaching LLMs to Abstain via Fine-Grained Semantic Confidence Reward", "authors": "Hao An,Yang Xu", "background": "在大型语言模型（LLMs）的可靠部署中，减轻幻觉问题至关重要。现有的方法通常通过微调LLMs来避免回答超出其知识范围的问题。然而，这些方法通常依赖粗粒度的信号来引导LLMs放弃回答，例如多次采样的答案的整体置信度或不确定性评分，这可能导致模型对自己知识边界认知的不精确。因此，提出了一种基于细粒度语义置信奖励的新型强化学习框架，通过样本特定的置信度指导LLMs放弃回答。该方法通过采样多个候选答案并进行语义聚类，然后训练LLMs保留高置信度集群中的答案，丢弃低置信度集群中的答案，从而促进准确的后置放弃。此外，还提出了一种新的评价指标，用于更全面地评估放弃微调任务的可靠性。这种方法在领域内和域外基准测试中显著提高了可靠性。", "innovation": "提出了基于细粒度语义置信奖励的新型强化学习框架，指导LLMs通过样本特定置信度进行细化的后置放弃。此外，提出了一个新的测评指标，更全面地评估放弃微调任务的可靠性。这种方法能够显著提高LLMs在领域内和域外基准测试中的可靠性。", "conclusion": "通过细粒度语义置信奖励的强化学习框架显著提升了LLMs在可靠性和准确性方面的表现，特别是在领域内和域外任务中的表现。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24236", "html_url": "https://arxiv.org/abs/2510.24236", "title": "走向透明推理：大型语言模型中忠诚度驱动力的研究", "title_en": "Towards Transparent Reasoning: What Drives Faithfulness in Large Language Models?", "authors": "Teague McMillan,Gabriele Dominici,Martin Gjoreski,Marc Langheinrich", "background": "大型语言模型（LLMs）通常会产生不忠实反映其预测驱动因素的解释。在医疗保健环境中，这种不忠实尤为严重：不忠实的解释可能会忽略重要的临床线索或掩盖错误的捷径，从而削弱医师的信任并导致不安全的决策支持。本文研究推理和训练时间的选择如何影响解释的忠实性，专注于在部署过程中从业者可以控制的因素。评估了三种LLMs（GPT-4.1-mini、LLaMA 70B、LLaMA 8B）在两个数据集（社交偏见的BBQ和医学执照问题的MedQA）上的表现，通过调整少量示例的数量和类型、提示策略和训练过程。研究表明：（i）少量示例的数量和质量对模型的忠实性有显著影响；（ii）忠实性对提示设计敏感；（iii）指令微调阶段在MedQA上提高了测得的忠实性。这些发现为在敏感领域提高LLMs的可解释性和可信度提供了见解。", "innovation": "本文通过评估不同的LLM模型在不同数据集上的表现，并通过调整少量示例的数量和类型、提示策略和训练过程，研究推理和训练时间的选择如何影响解释的忠实性。此外，还发现指令微调阶段对提高MedQA上的测得忠实性有显著作用，从而为改善LLMs的可解释性和可信度提供了有用的策略。", "conclusion": "这些发现揭示了在敏感领域提高LLMs的可解释性和可信度的具体策略，特别是在医疗保健环境中，构建了更可信的大规模语言模型的方法论基础。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24247", "html_url": "https://arxiv.org/abs/2510.24247", "title": "Abjad AI在2025 NADI：CATT-Whisper：使用文本和语音表示的多模态重音恢复", "title_en": "Abjad AI at NADI 2025: CATT-Whisper: Multimodal Diacritic Restoration Using Text and Speech Representations", "authors": "Ahmad Ghannam,Naif Alharthi,Faris Alasmary,Kholood Al Tabash,Shouq Sadah,Lahouari Ghouti", "background": "本文探讨了使用多模态方法（结合文本和语音信息）解决阿拉伯方言句子的重音恢复（DR）任务。传统的重音恢复方法往往只依赖于文本信息，而忽略了语音的丰富信息，这限制了模型的效果和泛化能力。为了克服这一问题，作者采用了CATT编码器和OpenAI Whisper模型组合来建模文本和语音信息，以提升模型的性能和鲁棒性。", "innovation": "本文提出了一种结合文本和语音信息的多模态方法，具体创新点包括：1）使用CATT编码器处理文本模态；2）使用OpenAI Whisper模型的编码器处理语音模态；3）采用两种集成策略：一是早期阶段将语音分词与输入文本分词融合；二是利用交叉注意机制融合文本和语音嵌入；4）在训练过程中随机禁用语音输入，使模型能够适应有或没有语音信息的情况。这些方法提升了模型的鲁棒性和准确性。", "conclusion": "实验结果表明，所提出的方法在开发集上达到了0.25的词错误率（WER）和0.9的字符错误率（CER，可能为显示错误，实际应为较低的值），测试集上的结果为0.55的WER和0.13的CER。这表明该方法在预测重音级别方面具有良好的性能。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24003", "html_url": "https://arxiv.org/abs/2510.24003", "title": "META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine", "title_en": "META-RAG: Meta-Analysis-Inspired Evidence-Re-Ranking Method for Retrieval-Augmented Generation in Evidence-Based Medicine", "authors": "Mengzhou Sun,Sendong Zhao,Jianyu Chen,Haochun Wang,Bin Qin", "background": "证据医学（EBM）在临床应用中扮演着重要角色，通过合适的医学文献，医生可以有效降低误诊率。尽管大型语言模型（LLMs）如RAG（ Retrieval-Augmented Generation）技术被发现可用于EBM任务，但EBM对证据有严格要求，而RAG应用在EBM中难以有效区分高质量证据。因此，研究者们借鉴EBM中常用的荟萃分析方法，提出了一种新的方法，以重新排序和筛选医学证据。这种方法基于多个原则过滤出最佳的证据，供LLMs诊断使用。通过采用多种EBM方法模拟荟萃分析过程，包括可靠性的分析、异质性分析和外推分析，以帮助用户获取最佳的医学证据并与LLMs进行交互。", "innovation": "研究者们提出了一种名为META-RAG的新方法，通过模拟更像是荟萃分析的过程，利用多种EBM方法（包括可靠性分析，异质性分析和外推分析），对获得的医学证据进行重新排序和筛选，旨在提高LLMs获取高质量和可靠的医学证据的能力，从而在RAG生成过程中提供更准确和可靠的医学信息，实验结果显示准确率提高了11.4%。这种方法成功地帮助RAG从PubMed数据集中提取出更高质量、更可靠的证据，减少了错误知识的引入，有助于用户获得更有效的回复。", "conclusion": "该研究通过对医学证据进行重新排序和筛选，结合多种EBM方法（包括可靠性分析，异质性分析和外推分析），显著提高了RAG在证据医学应用中的准确性，实验证明准确率提升11.4%，有助于减少错误知识的输入并提供更有效的回复。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24250", "html_url": "https://arxiv.org/abs/2510.24250", "title": "评估生成适龄儿童对话的LLM模型", "title_en": "Evaluating LLMs on Generating Age-Appropriate Child-Like Conversations", "authors": "Syed Zohaib Hassan,Pål Halvorsen,Miriam S. Johnson,Pierre Lison", "background": "大型语言模型（LLMs）主要基于成人对话数据进行训练，当生成儿童对话时，它们面临显著挑战，难以生成符合儿童特点的真实对话。本文研究了五个不同LLMs（GPT-4，RUTER-LLAMA-2-13b，GPTSW，NorMistral-7b，NorBloom-7b）生成适合5岁和9岁儿童的挪威语对话的能力，通过教育专业人士的盲评，评估其对话的真实性和发展适宜性。虽然GPT-4和NorBloom-7b表现相对良好，但大多数模型生成的语言被认为比目标年龄段更为复杂，这突显了在涉及儿童的特殊应用中开发LLM系统的数据挑战，特别是在低资源语言中，缺乏全面的适龄词汇资源是关键问题之一。", "innovation": "本文通过比较研究不同LLM模型，旨在评估它们生成适合特定年龄段儿童对话的能力。研究采用盲评机制，确保评估结果的客观性和有效性，并且特别关注语言模型在生成适合儿童对话方面的真实性和准确性。这种方法为评估和改进LLM系统在青少年和儿童对话生成中的表现提供了新的视角，特别是在低资源语言环境下。", "conclusion": "研究结果显示，教育专业人士在评估LLM生成的对话真实性和发展适宜性时，达到了较高的信度（ICC=0.75）。对于5岁儿童，年龄预测更准确，但对于9岁儿童则相对较低。尽管GPT-4和NorBloom-7b在预测年龄上表现相对较好，但大多数模型生成的对话语言被认为比目标年龄段更为复杂。这些研究发现强调了在涉及儿童的特殊应用中开发LLM系统的数据挑战，特别是在词汇资源稀缺的低资源语言环境下，需进一步改进和优化。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24295", "html_url": "https://arxiv.org/abs/2510.24295", "title": "MERGE：自然语言推理中的最小表达替换泛化测试", "title_en": "MERGE: Minimal Expression-Replacement GEneralization Test for Natural Language Inference", "authors": "Mădălina Zgreabăn,Tejaswini Deoskar,Lasha Abzianidze", "background": "近年来，许多泛化基准显示语言模型在自然语言推理（NLI）方面的鲁棒性不足。手动创建新基准的成本较高，而通过修改现有基准来自动生成高质量的基准，即使是最微小的修改，也是非常困难的。", "innovation": "本文提出了一种通过替换开放类词汇自动生成原始NLI问题高质量变体的方法，同时关键地保留它们的推理基础。该方法将泛化测试命名为MERGE（最小表达替换泛化），用于评估模型预测在保留推理的基础上变体问题中的正确性。实验结果表明，NLI模型在变体中的表现比在原始问题上低4-20%，这表明即使在这种稍微改变的问题上其泛化能力也较低。此外，我们分析了替换词的词类、词的概率和可接受性对NLI模型性能的影响。", "conclusion": "我们的结果表明，NLI模型在变体问题上的表现比在原始问题上低4-20%，这表明即使在这种稍微改变的问题上其泛化能力也较低。我们还分析了替换词的词类、词的概率和可接受性对NLI模型性能的影响。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24302", "html_url": "https://arxiv.org/abs/2510.24302", "title": "基于前瞻树的滚动策略在可验证奖励增强学习中增强轨迹级探索", "title_en": "Lookahead Tree-Based Rollouts for Enhanced Trajectory-Level Exploration in Reinforcement Learning with Verifiable Rewards", "authors": "Shangyu Xing,Siyuan Wang,Chenyuan Yang,Xinyu Dai,Xiang Ren", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 和算法如 Group Relative Policy Optimization (GRPO) 已经有效地提高了大型语言模型的推理能力。然而，当前流水线中的关键瓶颈在于分组滚动期间采样轨迹的多样性有限，这使得政策更新的有效性受限。由于在标记级别使用随机采样，局部变化很可能导致几乎相同的原因路径。", "innovation": "我们提出了前瞻树基滚动策略 (Lookahead Tree-Based Rollouts, LATR)，旨在通过强制不同候选标记分叉来显式地促进轨迹级别的多样性。具体而言，LATR 在三个阶段操作：（1）在生成步骤中高不确定性处进行分叉；（2）为每个新分支进行前瞻仿真；（3）修剪模拟中长时间表现出类似性的分支。", "conclusion": "与随机采样方法相比，LATR 平均加快了策略学习 131% 并提高了最终 pass@1 性能 4.2%。结果显示，无论是在 GRPO 还是在 Dynamic sAmpling Policy Optimization (DAPO) 算法下，二者在不同推理任务中的表现均有所提升。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24320", "html_url": "https://arxiv.org/abs/2510.24320", "title": "Critique-RL：通过两阶段强化学习训练语言模型进行批评", "title_en": "Critique-RL: Training Language Models for Critiquing through Two-Stage Reinforcement Learning", "authors": "Zhiheng Xi,Jixuan Huang,Xin Guo,Boyang Hong,Dingwen Yang,Xiaoran Fan,Shuo Li,Zehui Chen,Junjie Ye,Siyu Yuan,Zhengyin Du,Xuesong Yao,Yufei Xu,Jiecao Chen,Rui Zheng,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "训练批评型语言模型以评估并提供模型输出反馈，这被证明是一种提高大模型在复杂推理任务中能力的有效方法。然而，现有方法通常需要更强的监督来标注批评数据。因此，该研究旨在提出一种新的在线强化学习方法Critique-RL，以开发批评型语言模型并避免强力监督。", "innovation": "提出了一种基于两阶段强化学习的Critique-RL方法，用于在线开发不需要强大监督的批评型语言模型。该方法采用了双人博弈框架，包括：生成器生成回复，批评者提供反馈，生成器根据反馈改进回复的过程。为了改善批评的质量，该方法首先通过直接规则奖励信号来增强批评者的辨别能力，再通过引入基于生成器改进的间接奖励信号来提升实用性，同时通过适当的正则化保持批评者的辨别能力。", "conclusion": "Critique-RL在多种任务和模型上展示了显著的性能提升。例如，在领域内任务中，Critique-RL实现了9.02%的性能提升，在领域外任务中，实现了5.70%的性能提升，这突显了其潜在的应用价值。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24259", "html_url": "https://arxiv.org/abs/2510.24259", "title": "LLMs能否将人类指令转换为强化学习代理的内部涌现符号表示？", "title_en": "Can LLMs Translate Human Instructions into a Reinforcement Learning Agent's Internal Emergent Symbolic Representation?", "authors": "Ziqi Ma,Sao Mai Nguyen,Philippe Xu", "background": "涌现的符号表示对于促进发展型学习代理进行规划和在不同任务中的泛化至关重要。本文探讨了大型语言模型（LLMs）是否能够将人类自然语言指令转换为在层次强化学习过程中出现的内部符号表示。研究者使用结构化的评估框架，衡量GPT、Claude、Deepseek和Grok等常见LLMs在不同内部符号分区上的转换性能，这些分区是在Ant Maze和Ant Fall环境中由层次化强化学习算法生成的。研究表明，尽管LLMs在将自然语言转换为环境动力学的符号表示方面具有一定的能力，但它们的表现高度依赖于符号分区的粒度和任务复杂性。这些结果显示了目前在表示对齐方面存在的局限性，强调了进一步研究语言与内部代理表示之间稳健对齐的需求。", "innovation": "研究使用了结构化的评估框架来测量LLMs在不同内部符号分区上的转换性能，涵盖了几种常见的大语言模型，并探索了其在处理复杂任务时的表现。此外，研究揭示了LLMs在表示对齐方面的局限性，为未来的研究提供了方向。", "conclusion": "虽然LLMs在将自然语言指令转换为环境动力学符号表示方面具有一定的能力，但其性能高度依赖于符号分区的粒度和任务复杂性。这表明当前LLMs在表示对齐方面存在局限性，需要进一步研究以实现语言与内部代理表示之间的更稳健对齐。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24328", "html_url": "https://arxiv.org/abs/2510.24328", "title": "超越MCQ：基于方言的开放性阿拉伯文化问答基准", "title_en": "Beyond MCQ: An Open-Ended Arabic Cultural QA Benchmark with Dialect Variants", "authors": "Hunzalah Hassan Bhatti,Firoj Alam", "background": "大型语言模型（LLMs）在回答日常生活中的问题时被广泛使用，但在处理基于文化背景和方言的内容时，它们的表现并不均匀。现有的评估方法主要集中在标准化的问题形式上，如多项选择题（MCQ），但对于开放性问题回答（OEQ）和不同方言中的文化具体知识的评估不足。", "innovation": "该研究提出了一种全面的方法，其中包括：（i）将现代标准阿拉伯语（MSA）的多项选择题（MCQ）翻译成英语和几种阿拉伯方言，（ii）将这些问题转换成开放性问题（OEQ），（iii）在MCQ和OEQ设置下对一系列零样本和微调后的LLMs进行基准测试，（iv）生成链式思考（CoT）推理以微调模型用于逐步推理。这项研究扩展了一个现有的数据集，使其能够跨多种语言变体并行对齐Q&A，这是已知的首个此类数据集。", "conclusion": "实验结果表明：（i）模型在阿拉伯方言上表现不佳，揭示了在文化具体和方言特定知识方面的持续差距；（ii）以阿拉伯为中心的模型在多项选择题上表现良好，但在开放性问题回答上存在困难；（iii）链式思考（CoT）提高了判断的正确性，但在基于n-克隆的指标上产生了混合结果。开发的数据集将公开发布，以支持进一步的文化和语言包容性评估研究。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24365", "html_url": "https://arxiv.org/abs/2510.24365", "title": "基于句子嵌入的文本简化", "title_en": "Text Simplification with Sentence Embeddings", "authors": "Matthew Shardlow", "background": "句子嵌入可以解码近似原来的文本。本文在文本简化的情境下探索了这一效果，表明重构的句子嵌入能够保留复杂程度。实验使用小型前馈神经网络学习高复杂度和低复杂度文本之间句子嵌入的转换，对比Seq2Seq和大模型（LLM）方法，展示了较小学习环境中的积极结果。该研究还展示了所学习的变换在未见过的简化数据集（MedEASI）和训练数据以外的语言数据集（ES,DE）的适用性。这为进一步研究提供了新的方向，并有潜力开发小型但有力的模型以用于文本简化和其他自然语言生成任务。", "innovation": "本文通过小型前馈神经网络学习句子嵌入在高中低复杂度文本之间的转换，方法比Seq2Seq和大模型方法更为简洁高效，展示了在未见过的数据集上同样有效的结果，对于文本简化和自然语言生成任务具有潜在应用价值及理论意义并提出了新的研究方向", "conclusion": "本文的研究表明，在句子嵌入空间中学习转换是一种有前景的研究方向，可以用于开发小型但有效的模型来实现文本简化和自然语言生成任务。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24434", "html_url": "https://arxiv.org/abs/2510.24434", "title": "LuxIT：源自单语种子数据的卢森堡语指令调优数据集", "title_en": "LuxIT: A Luxembourgish Instruction Tuning Dataset from Monolingual Seed Data", "authors": "Julian Valline,Cedric Lothritz,Jordi Cabot", "background": "在低资源语言环境中，指令调优的大语言模型（LLMs）的有效性往往受限于高质量训练数据的缺乏。LuxIT 数据集是为缓解这一挑战而开发的第一个单语言指令调优数据集，它基于卢森堡语文本编写而成。", "innovation": "LuxIT 是一个针对卢森堡语开发的创新性单一语言指令调优数据集。通过使用 DeepSeek-R1-0528，一个在卢森堡语方面表现出色的模型，生成数据集，并利用LLM作为审查者进行质量保证，是进行单语语料库生成的新方法。", "conclusion": "LuxIT 对卢森堡语自然语言处理领域是一个重要的贡献，提供了可复制的单一语言数据集方法。尽管如此，性能在不同模型之间的差异显示出了需要进一步研究以优化其应用的必要性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24425", "html_url": "https://arxiv.org/abs/2510.24425", "title": "COMPEFFDIST：全面高效的轻量级情感分析模型精简框架", "title_en": "Comprehensive and Efficient Distillation for Lightweight Sentiment Analysis Models", "authors": "Guangyu Xie,Yice Zhang,Jianzhu Bao,Qianlong Wang,Yang Sun,Bingbing Wang,Ruifeng Xu", "background": "近期的研究利用知识蒸馏技术开发轻量级的情感分析模型。这些方法基于人类编写的指导说明和大规模用户文本。尽管取得了有希望的结果，但仍然存在两个关键挑战：（1）手动编写的指导说明在多样性和数量上有限，无法确保全面覆盖所提取的知识；（2）大规模用户文本的计算成本高，妨碍了这些方法的实用性。", "innovation": "我们提出了COMPEFFDIST框架，这是一种全面且高效的精简框架，旨在解决情感分析中的这两个关键挑战。该框架由两个关键模块组成：基于属性的自动指令构建和基于难度的数据过滤，分别解决上述问题。本文还使用Llama-3、Qwen-3和Gemma-3等多个模型系列验证了方法的有效性，使3B学生模型在大多数任务上达到了20倍更大教师模型的性能。同时，该方法在数据效率方面大幅优于基线方法，在相同性能水平情况下仅使用数据的10%。", "conclusion": "本文介绍了一种全面且高效的精简框架COMPEFFDIST，用于情感分析。该框架解决了现有方法在指导说明多样性和计算成本上的挑战，使得轻量级学生模型可以在大多数任务上与大型教师模型媲美，同时在数据效率上表现出色。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24345", "html_url": "https://arxiv.org/abs/2510.24345", "title": "LongWeave: 一种结合现实相关性和可验证性的长形式生成基准", "title_en": "LongWeave: A Long-Form Generation Benchmark Bridging Real-World Relevance and Verifiability", "authors": "Zikai Xiao,Fei Huang,Jianhong Tu,Jianhui Wei,Wen Ma,Yuxuan Zhou,Jian Wu,Bowen Yu,Zuozhu Liu,Junyang Lin", "background": "目前，大型语言模型（LLMs）生成长篇、详尽且事实准确的输出仍面临重大挑战。现有的长格式生成基准通常使用难以验证的指标评估实际查询，或者采用可能简化评估但忽略现实复杂性的合成设置。因此，现有的基准不能全面评估模型在面对真实世界的复杂约束时的能力。", "innovation": "本文提出了LongWeave，这是一种结合了现实相关性和可验证性的新型基准测试。它通过首先在现实场景中定义可验证的目标，然后系统地生成相应的查询、文本材料和约束，确保了任务的真实性和客观评估性。此外，LongWeave 支持不同任务的可定制输入/输出长度（最大64K/8K标记），并且评估结果显示最先进的模型在处理长格式生成时仍然面临显著挑战，尤其是在面对组合复杂性和输出长度增加的情况下。", "conclusion": "通过对23个LLM模型的评估，研究显示即使是目前最先进的模型，在处理长格式生成任务时仍然遇到显著的挑战。尤其在现实世界复杂性和输出长度增加的情况下，模型的性能差异尤为明显。这证明了LongWeave有效地评估了模型在处理深具挑战性的现实需求方面的能力。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24256", "html_url": "https://arxiv.org/abs/2510.24256", "title": "从损失曲率谱系中理解记忆到推理", "title_en": "From Memorization to Reasoning in the Spectrum of Loss Curvature", "authors": "Jack Merullo,Srihita Vatsavaya,Lucius Bushnaq,Owen Lewis", "background": "前人的理论和实验证据表明，记忆化的训练点曲率比未记忆化的部分更尖锐。因此，通过按曲率降序排列权重组件可以揭示其区别而无需显式标签。基于此，该研究将系统地探讨在语言模型和视觉变压器中如何表征记忆，并提出一种权重编辑程序，以更有效的方式抑制未目标化的记忆数据的复述，同时保持较低的困惑性。该研究进一步分析了这种编辑对下游任务的影响，特别是发现事实检索和算术在某些方面表现一致地变差，尽管开放书事实检索和一般逻辑推理保持不变。这表明，这些任务依赖于专门化的权重空间方向，而不是一般的机制。", "innovation": "该研究提出了一种新的权重编辑方法，能够更有效地抑制未目标化的记忆数据的复述，同时保持较低的困惑性。研究还详细分析了该编辑程序对语言模型下游任务的影响，发现事实检索和算术任务表现下降，而开放书事实检索和一般逻辑推理保持不变，揭示了特定方向的权重空间在解决这些任务中的作用。", "conclusion": "该研究加深了对神经网络中记忆的理解，并提出了实际应用，以便去除它。它提供了证据表明，在像数学和事实检索这样的任务中使用的特定结构是独特且专门的。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24427", "html_url": "https://arxiv.org/abs/2510.24427", "title": "SynthWorlds：用于分离语言模型推理与知识的可控平行世界", "title_en": "SynthWorlds: Controlled Parallel Worlds for Disentangling Reasoning and Knowledge in Language Models", "authors": "Ken Gu,Advait Bhat,Mike A Merrill,Robert West,Xin Liu,Daniel McDuff,Tim Althoff", "background": "评估语言模型（LMs）的推理能力受到其广泛的参数世界知识的影响，基准测试的成功往往反映了事实的记忆而非真正的推理。现有的数据集和方法（例如，时间过滤，改写，对抗替换）无法干净地将这两者区分开来。", "innovation": "SynthWorlds 提出了一种框架，用于分离任务推理复杂性与事实知识。在 SynthWorlds 中，构建了两个具有相同连接结构的平行语料库：一个与现实对应的世界，模型可以利用参数知识，而在另一个合成的世界中，这些知识没有意义。在此基础上，设计了两个镜像任务作为案例研究：多跳问答和页面导航，这两个任务在两个世界中保持相同的推理难度。实验揭示了知识优势差距的持续存在，而知识获取和整合机制虽然减小但未消除这种差距，强调了系统改进的机会。SynthWorlds 是全自动和可扩展的，提供了寻求先前无法实现的、精确测试语言模型推理与记忆能力对比的受控环境。", "conclusion": "SynthWorlds 为评估 LMs 提供了一个受控环境，使得以前难以实现的推理与记忆对比成为可能，增强了对推理和记忆机制的精确测试。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24450", "html_url": "https://arxiv.org/abs/2510.24450", "title": "绘制欧洲LLM基准测试景观：一种新的分类法和一套最佳实践", "title_en": "Charting the European LLM Benchmarking Landscape: A New Taxonomy and a Set of Best Practices", "authors": "Špela Vintar,Taja Kuzman Pungeršek,Mojca Brglez,Nikola Ljubešić", "background": "随着新的大型语言模型（LLMs）基准不断更新以适应新模型及人工智能不断增强的能力，使用和评估非英语语言的LLMs仍然没有得到充分研究。文章对近期LLM基准的发展进行了简要回顾，并提出了一个适合多语言或非英语使用场景的新分类法。此外，提出了促进欧洲语言基准协调发展的最佳实践和质量标准建议，强调提高评估方法的语种和文化敏感性的重要性.", "innovation": "提出了一个针对多语言或非英语使用场景的新基准分类法，以及用于促进欧洲语言基准协调发展的最佳实践和质量标准建议，强调评估方法的语种和文化敏感性.", "conclusion": "文章指出，为了更好地发展多语言或非英语使用场景的基准评估工具，需要更具语种和文化敏感性的评估方法，并呼吁相关领域采取更多协调行动，共同促进欧洲语言及人工智能技术的发展."}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24476", "html_url": "https://arxiv.org/abs/2510.24476", "title": "在大型语言模型（LLMs）中缓解幻觉：基于应用的RAG、推理和代理系统调查", "title_en": "Mitigating Hallucination in Large Language Models (LLMs): An Application-Oriented Survey on RAG, Reasoning, and Agentic Systems", "authors": "Yihan Li,Xiyuan Fu,Ghanshyam Verma,Paul Buitelaar,Mingming Liu", "background": "幻觉是大型语言模型（LLMs）可靠部署的一个关键障碍，特别是在实际应用中。过去，抑制幻觉的策略被广泛采用，但缺乏从增强能力的角度来系统检查RAG和推理增强策略及其如何协同作用并缓解幻觉。本文采用应用导向的方法，分析如何通过RAG、推理增强及其在代理系统中的集成来缓解幻觉。", "innovation": "提出了知识驱动和逻辑驱动幻觉的分类方法，并系统地探讨了RAG和推理如何处理每种类型的幻觉。此外，本文提出了基于实际应用、评价和基准的统一框架。", "conclusion": "该调查以应用为导向，从增强能力的角度分析了RAG、推理增强及其在代理系统中的集成如何缓解幻觉。通过提出新的分类体系和实证框架，本文填补了该领域的空白，为解决LLMs的幻觉问题提供了新的视角。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24446", "html_url": "https://arxiv.org/abs/2510.24446", "title": "利用文本自编码器潜在空间中的黑盒对抗改写评估推理分割鲁棒性", "title_en": "SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space", "authors": "Viktoriia Zinkovich,Anton Antonov,Andrei Spiridonov,Denis Shepelev,Andrey Moskalenko,Daria Pugacheva,Elena Tutubalina,Andrey Kuznetsov,Vlad Shakhuro", "background": "多模态大语言模型（MLLMs）在视觉语言任务中展示出了强大的能力，例如推理分割，这些模型能够基于文本查询生成分割掩码。尽管先前研究主要集中在图像输入的扰动上，但在现实应用中，用户用不同方式表达相同意图的同义文本表达（semantically equivalent textual paraphrases）仍然未被充分探索。本文正是旨在填补这一空白，提出了一个新颖的对抗改写任务：生成语法正确且保留原查询意义但会降低分割性能的同义句。为评估对抗改写的质量，作者开发了一个全面的自动评估协议，并结合了人工研究进行验证。同时，作者还引入了一种名为SPARTA的方法，这是一种黑盒的、基于强化学习在文本自编码器低维语义潜在空间进行的句子级优化方法。作者通过SPARTA和强大的基线方法评估了高级推理分割模型的鲁棒性，发现即使在严格的语义和语法约束下，这些模型仍易受对抗改写攻击。所有代码和数据将在文章被接受后公开发布。", "innovation": "本文提出了一个新颖的对抗改写任务，旨在通过生成保留原查询意义但降低分割性能的同义句来挑战MLLMs的鲁棒性。为了评估这些对抗改写的质量，作者开发了一个全面的自动评估协议，该协议通过人工研究进行了验证。此外，作者还引入了SPARTA方法，这是一种黑盒的、基于强化学习在文本自编码器低维语义潜在空间进行的句子级优化方法，该方法能够显著提高成功率，相较于先前的方法，成功率提高高达2倍。", "conclusion": "通过SPARTA和竞争性基线方法验证，发现先进的推理分割模型在严格的语义和语法约束下仍易受对抗改写攻击。综上所述，本文提出的方法不仅能够有效评估模型的鲁棒性，还揭示了模型在实际应用中的潜在脆弱性。所有相关代码和数据将在文章被接受后公开发布。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24488", "html_url": "https://arxiv.org/abs/2510.24488", "title": "一种评估大型语言模型隐性偏见的方法，与人类相比", "title_en": "A word association network methodology for evaluating implicit biases in LLMs compared to humans", "authors": "Katherine Abramski,Giulio Rossetti,Massimo Stella", "background": "随着大型语言模型（LLMs）在生活中的应用越来越广泛，它们固有的社会偏见问题日益突出。检测和评估这些偏见具有挑战性，因为它们往往是隐性的，而非明确的。因此，开发能够评估LLMs隐含知识表示的评估方法至关重要。", "innovation": "本文提出了一种基于模拟LLM生成的词联想网络中的语义联想的新型词联想网络方法，用以评估隐性偏见。该方法基于提示驱动，能够揭示和评估偏见的量化和定性特征，适用于直接比较不同LLMs和人类。此外，该方法提供了LLMs与人类认知对齐的新视角。", "conclusion": "本文方法为评估和比较包括LLMs和人类在内的多种偏见提供了一个系统、可扩展和通用的框架，有助于实现透明和具有社会责任感的语言技术目标。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24438", "html_url": "https://arxiv.org/abs/2510.24438", "title": "LLMs 能够忠诚地写作吗？基于代理的LLM生成的伊斯兰内容评估", "title_en": "Can LLMs Write Faithfully? An Agent-Based Evaluation of LLM-generated Islamic Content", "authors": "Abdullah Mushtaq,Rafay Naeem,Ezieddin Elmahjub,Ibrahim Ghaznavi,Shawqi Al-Maliki,Mohamed Abdallah,Ala Al-Fuqaha,Junaid Qadir", "background": "大型语言模型（LLM）越来越多地用于提供伊斯兰指导，但存在引文错误、误用法理学或产生文化不一致回应的风险。为了评估这些模型在生成伊斯兰内容方面的表现，作者设计了一种基于代理框架的评估方法，使用真实的伊斯兰博客提示来测试GPT-4o、Ansari AI和Fanar。该研究旨在解决信仰敏感写作中准确性和引文的首要需求，然而现有的模型尚未完全满足这一需求。研究表明，尽管模型在生成准确的伊斯兰内容和引文方面表现出一定的潜力，但仍需进一步改进以确保高质量输出。背景指出了该领域存在的挑战和现有模型的局限性。", "innovation": "该研究创新性地提出了一种代理框架，分别采用定量代理和定性代理进行评估。其中，定量代理用于验证引文和评分六个维度（如结构、伊斯兰一致性、引文等），定性代理用于进行五个维度的左右对比（如语气、深度、原创性）。该方法能更全面地评估模型在生成高质量伊斯兰内容方面的表现，并为后续研究提供了新的思路。Fanar在某些方面也展示了其针对伊斯兰和阿拉伯语境的独特创新。", "conclusion": "尽管现有的LLM模型在生成准确的伊斯兰内容和引文方面取得了一定进展，但仍存在较大的改进空间。该研究强调了需要制定社区驱动的基准，使其更中心化考虑到穆斯林的观点，以促进更可靠的AI在伊斯兰知识以及其他高风险领域（如医学、法律和新闻业）的发展。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24478", "html_url": "https://arxiv.org/abs/2510.24478", "title": "Talk2Ref：科学演讲中参考文献预测的数据集", "title_en": "Talk2Ref: A Dataset for Reference Prediction from Scientific Talks", "authors": "Frederik Broy,Maike Züfle,Jan Niehues", "background": "科学研究交流日益通过科学演讲进行，自动识别支持或丰富演讲相关的文献将对研究人员和学生具有极高的价值。现有研究中，缺乏专门针对科学演讲的上下文来预测参考文献的数据集和任务定义，限制了相关技术的发展。Talk2Ref数据集和Talk2Ref任务定义弥补了这一空白，它将6,279份科学演讲和43,429篇相关论文进行匹配（平均每份演讲26篇），提供了一种新的方法来将长且结构化不完整的科学演讲转化为相关的论文集。", "innovation": "创新点在于：1、提出了Talk2Ref，该任务旨在将长而未结构化的科学演讲映射到相关论文。2、构建了Talk2Ref数据集，包括大量科学演讲和相关论文，以及对应的参考文献信息。3、采用了双编码器架构，并对现有最先进的文本嵌入模型进行了初步评估和改进。4、探索了长演讲文本处理策略及领域适应性训练方法。", "conclusion": "通过Talk2Ref数据集，显著提升了一般文本嵌入模型对于引用预测的表现，证明了任务的挑战性同时展示了开放数据集对于学习口语化科学内容的语义表示的有效性。未来研究将基于该数据集进一步促进将口语化科学交流整合到引文推荐系统中。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24505", "html_url": "https://arxiv.org/abs/2510.24505", "title": "CritiCal: 反思能否帮助LLM不确定性或置信度校准？", "title_en": "CritiCal: Can Critique Help LLM Uncertainty or Confidence Calibration?", "authors": "Qing Zong,Jiayu Liu,Tianshi Zheng,Chunyang Li,Baixuan Xu,Haochen Shi,Weiqi Wang,Zhaowei Wang,Chunkit Chan,Yangqiu Song", "background": "大型语言模型（LLMs）在高风险领域的安全使用依赖于准确的信心校准，清晰的信心表达可以增强用户的信任。传统的方法往往无法捕捉到准确信心评估所需的推理。在准确的信心标签难以获得且通常需要多次生成的情况下，自然语言反思作为解决方案，被认为更适合信心校准。", "innovation": "提出了自然语言反思（CritiCal）作为自然语言的解决方案，其中包括两种方法：Self-Critique和CritiCal。Self-Critique使LLMs能够反思和优化其信心，而CritiCal是一种新颖的反思校准训练方法，利用自然语言反思来提高信心校准，不再只是直接进行数值优化。实验表明，CritiCal在复杂推理任务中显著优于Self-Critique和其他竞争基线，并在泛化到未见分布时表现尤为出色，提升了LLM的可靠性。", "conclusion": "CritiCal在提高LLM的信心校准方面表现出色，特别是在复杂推理任务和未见分布场景中。这种新颖的方法推进了LLM的信心校准和可靠性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24541", "html_url": "https://arxiv.org/abs/2510.24541", "title": "开源高丽历史语料库：公共领域文本的千年动态集合", "title_en": "Open Korean Historical Corpus: A Millennia-Scale Diachronic Collection of Public Domain Texts", "authors": "Seyoung Song,Nawon Kim,Songeun Chae,Kiwoong Park,Jiho Jin,Haneul Yoo,Kyunghyun Cho,Alice Oh", "background": "高丽语的历史特征在于其口语和书面语言之间存在差异，以及从中文字体到韩文字母的转变。然而，由于缺乏可访问的历史语料库，在自然语言处理(NLP)领域对这种语言演变的研究一直不足。", "innovation": "介绍了开源高丽历史语料库，这是一个跨越1300年、包括6种语言及如韩国风格的汉语（Idu）和汉字-韩文混合字体在内的不足代表的书写系统的大型开源数据集。该语料库包含1800万份文档和50亿个词元，来自19个不同的来源，时间范围从公元7世纪到2025年。", "conclusion": "该工作为定量历时分析提供了基础资源，通过捕获高丽语的历史。此外，它还可以作为大型语言模型的预训练语料库，有潜力提高它们对现代韩语中的中韩词汇以及古文字系统的理解。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24570", "html_url": "https://arxiv.org/abs/2510.24570", "title": "基于BEST-RQ的自监督学习方法在Whisper领域适应中的应用", "title_en": "BEST-RQ-Based Self-Supervised Learning for Whisper Domain Adaptation", "authors": "Raphaël Bagat,Irina Illina,Emmanuel Vincent", "background": "尽管ASR系统在多语言训练方面取得了显著进展，但在出域场景和低资源场景下，由于缺乏标注数据，其表现不尽如人意。", "innovation": "提出了一种新的框架BEARD（BEST-RQ Encoder Adaptation with Re-training and Distillation），通过结合BEST-RQ目标和知识蒸馏来适应Whisper的编码器，使用未标记的数据进行自监督学习，完成领域适应任务。", "conclusion": "实验结果显示，提出的BEARD方法克服了之前基线方法和微调模型的不足，在ATCO2空中交通管制通信领域数据集上取得了显著的相对性能提升，达到12%。这是首次将自监督学习目标应用于在Whisper领域适应的研究。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24469", "html_url": "https://arxiv.org/abs/2510.24469", "title": "增强LLM个性化的迭代批判-完善框架", "title_en": "Iterative Critique-Refine Framework for Enhancing LLM Personalization", "authors": "Durga Prasad Maram,Dhruvin Gandhi,Zonghai Yao,Gayathri Akkinapalli,Franck Dernoncourt,Yu Wang,Ryan A. Rossi,Nesreen K. Ahmed", "background": "个性化文本生成要求模型不仅生成连贯的文本，还要与目标用户的话题、语气和风格保持一致。现有的检索增强方法如LaMP和PGraphRAG通过包含用户和邻居的历史记录来丰富个人资料，但在生成过程中通常会产生在语气、话题或风格上偏离目标的输出。", "innovation": "提出了一种名为PerFine的统一、无需训练的批判-完善框架，通过基于个人资料的迭代反馈增强个性化。在每次迭代中，LLM生成器基于检索到的个人资料生成草稿，受条件制约的批判LLM则提供关于语气、词汇、句式结构和相关性的结构化反馈。生成器根据新型淘汰机制保留更强的草稿。此外还研究了其他推理时间策略，如Best-of-N和主题提取，以平衡质量和效率。", "conclusion": "在Yelp、Goodreads和Amazon数据集上的实验表明，PerFine在以GEval衡量的个性化方面持续优于PGraphRAG，改进幅度为7-13%，且在3-5次迭代中保持稳定的改善，随着批判队伍规模的增加而提高。结果表明，事后、基于个人资料的反馈为无训练、无模型的个性化LLM生成提供了一个强大的范式。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24530", "html_url": "https://arxiv.org/abs/2510.24530", "title": "通过局部语法消除歧义", "title_en": "Levée d'ambiguïtés par grammaires locales", "authors": "Eric G. C. Laporte", "background": "许多单词在词性（POS）上存在歧义。然而，在文本中，这种歧义通常会被显著减少。词性标注涉及使用上下文来减少与单词关联的词性数量，是词典标注的主要挑战之一。这一问题在自然语言处理中频繁出现，如拼写检查、语法或风格检查、表达式识别、语音合成、文本语料库分析等。因此，词典标注系统可以作为许多自然语言处理系统的重要组成部分。近年来，一些词典标注系统在文本存在歧义或无法找到唯一正确标注时，会生成多个解决方案。然而，需要保证无零漏检率的目标在唯一标注每个单词的系统中难以实现。本文所探讨的方法旨在适应无零漏检率的目标，该方法来自Silberztein的INTEX系统（1993）。本文正式描述了这种方法，并提出了验证局部消歧语法时需要考虑不同转换路径的相互作用，以及当多个转换器组合使用时不能单独预测结果的观点。同时，提出通过直接检查由INTEX生成的初始标注来发现词汇消歧规则的方法，但语法直觉可能由于未知构造或歧义而错误。如果追求无零漏检率，局部语法需要仔细测试，单个语法的动作也应在应用于文本后有详细说明。", "innovation": "本文提出的消除了局部消歧语法中单独考虑转换路径交互和技术组合结果无法预测的问题，强调了在实现零漏检率目标时对局部语法的仔细测试和标注方法的详细描述。", "conclusion": "通过提供局部消歧语法的详细描述及相关验证方法，本文有助于提高自然语言处理中词性标注的全面性和准确度，特别是在具有复杂语言构造和词性多义性的文本中。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24538", "html_url": "https://arxiv.org/abs/2510.24538", "title": "黑暗与暴风雨：建模最糟糕句子中的幽默", "title_en": "Dark & Stormy: Modeling Humor in the Worst Sentences Ever Written", "authors": "Venkata S Govindarajan,Laura Biester", "background": "文本幽默极其多样，现有的计算研究需要涵盖这一范围，尤其是包括故意拙劣的幽默。本文通过调查和分析Bulwer-Lytton小说竞赛中的句子集，旨在更好地理解英语中的“糟糕”幽默。", "innovation": "现有的幽默检测模型在该数据集上表现不佳。分析文学手法显示，这些句子不仅包含现有的幽默数据集中的常见特征（如双关语、反讽等），而且还结合了比喻、元小说和明喻等特征。通过提示大规模语言模型生成竞赛风格的句子，本文发现这些模型更注重形式模仿，但通过过度使用某些文学手法以及使用更大量的新形容词-名词短语组合，以夸张的方式放大了效果。", "conclusion": "数据、代码和分析结果可在以下链接获取：this https URL"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24592", "html_url": "https://arxiv.org/abs/2510.24592", "title": "ReForm: 使用前瞻性有限序列优化的反思性自动形式化", "title_en": "ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization", "authors": "Guoxin Chen,Jing Wu,Xinjie Chen,Wayne Xin Zhao,Ruihua Song,Chengxi Li,Kai Fan,Dayiheng Liu,Minpeng Liao", "background": "自然语言数学问题的自动形式化对于利用形式数学推理解决用自然语言表述的数学问题是至关重要的。尽管大型语言模型可以生成语法正确的形式化陈述，但它们往往无法保留原始问题的意义意图。这源于这些模型将自动形式化视为一个简单的翻译任务，缺乏人类专家自然使用的自我反思和逐步改进的机制。", "innovation": "我们提出了ReForm，一种反思性自动形式化方法，它将语义一致性评估紧密集成到自动形式化过程中。这使模型能够逐步生成形式化陈述，评估其语义忠实度，并通过逐步改进自我纠正发现的错误。为了有效地训练这种反思性模型，我们引入了前瞻性有限序列优化（PBSO），该方法在序列的不同位置使用不同的奖励，以确保模型不仅发展出准确的自动形式化，还能进行正确的语义验证，防止表面的批评，这种批评会削弱反思的目的。", "conclusion": "在四个自动形式化基准的广泛实验中，ReForm在最强的标准基线之上实现了平均17.2个百分点的改进。为了进一步确保评估的可靠性，我们引入了ConsistencyCheck基准，它包含859个由专家标注的项目，不仅验证了LLMs作为评判者的能力，还揭示了自动形式化是固有的困难：即使在人类专家中，也有高达38.5%的情况会产生语义错误。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24605", "html_url": "https://arxiv.org/abs/2510.24605", "title": "具有本征可变生成长度的扩散LLM：让[EOS]引领道路", "title_en": "Diffusion LLM with Native Variable Generation Lengths: Let [EOS] Lead the Way", "authors": "Yicun Yang,Cong Wang,Shaobo Wang,Zichen Wen,Biqing Qi,Hanlin Xu,Linfeng Zhang", "background": "基于扩散的大语言模型（dLLMs）在并行文本生成方面展现出了巨大的潜力，这可能使其相比自回归模型生成文本更有效率。然而，当前dLLMs存在固定生成长度的问题，这意味着dLLMs的生成长度在解码之前就被确定为一个超参数，导致效率和灵活性的问题。现有的解决方案无法解决这些问题，因此需要一种新的方法来改进这一问题，以便dLLMs能够更加灵活、高效地生成文本。", "innovation": "本文提出了一种名为dLLM-Var的扩散LLM模型，该模型可以训练来准确预测生成文本中的[EOS]标记，从而使dLLM能够以块扩散的方式进行推断，同时保持全局双向（完全）注意力和高并行性的能力。实验结果表明，与传统的dLLM推理方法相比，该方法可以实现30.1倍的加速，并且在与Qwen和Llama之类的自回归模型相比时也能实现2.4倍的加速。该方法不仅提高了精确度，也加快了推理速度，使得dLLMs不仅具有学术意义，还能在实际应用中使用。相关的代码和模型已经开源。", "conclusion": "通过训练预测[EOS]标记，dLLM-Var模型解决了dLLMs的固定生成长度问题，实现了更高的准确性和更快速的推理速度，提升了dLLMs的实际应用潜力。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24591", "html_url": "https://arxiv.org/abs/2510.24591", "title": "ReplicationBench：AI代理能否复制天文学研究论文？", "title_en": "ReplicationBench: Can AI Agents Replicate Astrophysics Research Papers?", "authors": "Christine Ye,Sihan Yuan,Suchetha Cooray,Steven Dillmann,Ian L. V. Roque,Dalya Baron,Philipp Frank,Sergio Martin-Alvarez,Nolan Koblischke,Frank J Qu,Diyi Yang,Risa Wechsler,Ioana Ciuca", "background": "先进的人工智能代理显示其作为科学研究助手的潜力正在增加，尽管最终可能被用来支持扩展的开放研究工作流程，但在使用这些代理进行新颖研究之前，我们必须首先评估其工作的准确性和可信度。为了评估这些代理作为研究助手的效果，本文引入了ReplicationBench，该框架测试代理能力是否能复制来自天文学文献的整篇研究论文。天文学作为研究高度依赖于档案数据和计算研究且很少涉及实际试验的领域，是测试科学界AI代理性能的一个特别有用的试验基地。", "innovation": "作者提出了一种新的评估框架ReplicationBench，通过让代理重新生成整篇研究论文的各个环节，包括实验设置、推导、数据分析和代码库，确保它们能够准确地再现原始方法和科学结果，从而验证这些代理作为科学研究助手的有效性。该框架基于领域专家的共同开发，适用于大规模科学任务，展示了当前最先进的语言模型在这些任务上的表现极差。", "conclusion": "ReplicationBench 设立了第一个专家验证的天文学研究任务基准，揭示了其他领域数据驱动科学中代理性能的一般性见解，并提供了一个可扩展的框架来衡量AI代理在科学研究中的可靠性。当前最前沿的语言模型甚至最好的得分也低于20%，这表明代理在科学和工程领域的总体表现仍然存在巨大差距。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24619", "html_url": "https://arxiv.org/abs/2510.24619", "title": "使用前缀基适应实现零样本跨语言迁移", "title_en": "Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation", "authors": "Snegha A(1),Sayambhu Sen(2),Piyush Singh Pasi(2),Abhishek Singhania(2),Preethi Jyothi(1) ((1) Indian Institute of Technology Bombay, (2) Amazon Alexa)", "background": "随着新的大型语言模型（LLMs）如Llama和Mistral的发布，多语言预训练和强大的泛化能力使得零样本跨语言迁移变得越来越可行。然而，将这些解码器只有型LLMs适配到新的多语言任务仍然具有挑战性。尽管参数高效的微调技术如LoRA被广泛应用，但前缀基技术如软提示微调、前缀微调和Llama Adapter在解码器只有模型中的零样本迁移方面较少被探索。", "innovation": "本文对三种前缀基方法在从英语到35多种（高资源和低资源）语言的零样本跨语言迁移中进行了全面研究。这些方法包括软提示微调、前缀微调和Llama Adapter。研究发现，在使用Llama 3.1 8B模型时，前缀方法在Belebele基准上的表现比基于LoRA的基线高出最多6%。类似地，在Mistral v0.3 7B模型中也观察到类似的改进。在使用只有1.23万学习参数进行前缀微调的情况下，它们在不同基准上的表现保持一致。", "conclusion": "这些发现表明，前缀基技术在低资源多语言设置中可能是一种有效且可扩展的替代LoRA的方法。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24628", "html_url": "https://arxiv.org/abs/2510.24628", "title": "Mm, Wat？检测对话中的其他发起的修正请求", "title_en": "\"Mm, Wat?\" Detecting Other-initiated Repair Requests in Dialogue", "authors": "Anh Ngo,Nicolas Rollet,Catherine Pelachaud,Chloe Clavel", "background": "维护对话双方的相互理解是避免对话中断的关键，特别是在人类之间的对话中，对其他发起方修复（OIR）的需求尤为重要。然而，现有的对话代理（CAs）仍然无法识别用户发起的修复信号，导致对话中断或用户的沮丧感增加。因此，研究人员提出了一种利用语言和声学特征相结合的方式来解决这个问题。", "innovation": "该研究创造了一种多模态模型，用于自动检测荷兰对话中的修复的起点。该模型通过综合语言和声学特征，在对话分析的基础上提升了前馈文本和音频嵌入的效果。这一方法强调不同特征之间相互作用的重要性，本文还为未来的研究提供了方向，包括引入视觉线索，探索多语言和跨场景语料库，以评估模型的稳健性和通用性。", "conclusion": "研究结果表明，声学线索可以补充语言特征，并显著提高了预训练文本和音频嵌入的表现。未来的研究方向包括整合视觉线索、探索多语言和跨场景语料库来评估模型的稳健性和通用性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24606", "html_url": "https://arxiv.org/abs/2510.24606", "title": "动态分层稀疏注意机制在设备端长上下文LLM中的长上下文建模", "title_en": "Long-Context Modeling with Dynamic Hierarchical Sparse Attention for On-Device LLMs", "authors": "Siheng Xiong,Joe Zou,Faramarz Fekri,Yae Jee Cho", "background": "由于注意机制的二次成本限制了具有长上下文的大型语言模型（LLM）的可扩展性，特别是在资源受限的环境中。现有的静态稀疏方法如滑动窗口或全局标记利用了注意机制的稀疏性来降低注意力成本，但不能很好地适应由于静态特性引起的注意机制依赖于内容的变化。虽然先前的工作提出了一些动态方法以提高灵活性，但这些方法仍然依赖于预定义的模板或启发式机制，这限制了其在不同任务中的适用性和准确性。", "innovation": "本文提出了一种名为动态分层稀疏注意力（DHSA）的数据驱动框架，该框架能够在线动态预测注意力的稀疏性，而无需重新训练。DHSA适应性地将序列分割成长短不同的片段，然后通过聚合每个片段内的标记嵌入来计算片段代表。通过应用长度归一化聚合消除了由片段长度变化带来的偏差，考虑了片段大小的平方根对平均嵌入进行缩放。最后，DHSA将片段级别的相似度评分上采样为标记级别的相似度来计算重要性评分，从而决定应保留哪些标记级交互。实验表明，与密集注意力相比，DHSA在准确性上相当，在预填充延迟上降低20-60%，峰值内存使用量减少35%。与代表性基线方法如区块稀疏注意力相比，DHSA在准确性上实现了一致的更高增长率（相对提高6-18%），同时成本可比较或更低，为设备端长上下文LLM提供了一种高效且适配的解决方案。", "conclusion": "通过引入DHSA，该研究为设备端长上下文LLM提供了一种高效且适应性强的解决方案，能够在维护准确性的前提下显著降低预填充延迟和峰值内存使用量，同时展示出与现有技术相当甚至更好的性能。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24652", "html_url": "https://arxiv.org/abs/2510.24652", "title": "通过强化对比学习优化RAG检索", "title_en": "Optimizing Retrieval for RAG via Reinforced Contrastive Learning", "authors": "Jiawei Zhou,Lei Chen", "background": "随着检索增强生成（RAG）技术的普及，信息检索（IR）的角色正在从为人用户提供信息检索转变为为人工智能（AI）系统检索上下文知识，其中相关性的定义和标注变得更加困难。这就提出了挑战.", "innovation": "本文提出R3，一种为RAG优化的检索框架，通过试错强化对比学习实现。R3不同于以往依赖标注或合成数据进行监督微调的方法，它能够让检索器在RAG环境中动态探索和优化相关性。在训练过程中，检索到的结果与环境互动，产生对比信号以自动引导检索器的自我改进。", "conclusion": "大量实验表明，R3在多元任务上的表现为RAG性能提升了5.2%，超越了最先进的检索器4.9%，同时实现了与基于后训练或指令调整大语言模型（LLM）的检索增强与RAG系统相当的结果。R3既高效又实用，仅需要4个GPU，并在一整天内完成训练。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24636", "html_url": "https://arxiv.org/abs/2510.24636", "title": "OpenReward: 使用强化学习学习奖励长形式有机构能任务", "title_en": "OpenReward: Learning to Reward Long-form Agentic Tasks via Reinforcement Learning", "authors": "Ziyou Hu,Zhengliang Shi,Minghang Zhu,Haitao Li,Teng Sun,Pengjie Ren,Suzan Verberne,Zhaochun Ren", "background": "奖励模型（RMs）已成为大型语言模型（LLMs）对齐的关键组成部分，替代人类评估进行训练和推理。然而，现有的奖励模型在需要广泛知识和长文本任务中表现不佳，尤其是在需要外部证据进行评估时。这导致它们无法可靠地区分微妙的质量差异。", "innovation": "本文提出了OpenRM，一种结合了外部工具的长形式奖励模型，能够系统地评估开放式响应并收集相关证据。OpenRM通过组相对策略优化（GRPO）在超过27,000个合成的成对示例上进行训练，这些示例是通过可控的数据合成框架生成的。OpenRM的训练目标同时监督工具使用和最终结果的准确性，促使奖励模型学习有效的基于证据的判断策略。", "conclusion": "在三个新收集的数据集和两个广泛使用的基准测试上的大量实验表明，OpenRM明显优于现有奖励建模方法。我们进一步将OpenRM集成到了推理时间和训练时间的选择中，这在下游LLM对齐任务中产生了持续的改进，突显了增强奖励模型在扩展可靠长文本评估中的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24626", "html_url": "https://arxiv.org/abs/2510.24626", "title": "LLMs的相对扩展法则", "title_en": "Relative Scaling Laws for LLMs", "authors": "William Held,David Hall,Percy Liang,Diyi Yang", "background": "现有的扩展法则描述了语言模型随附加数据、参数和计算资源的增加而改进的方式。传统的评估方法使用聚合测试集进行测量，这能够提供清晰的趋势，但掩盖了不同子群体之间的性能差异。因此，需要一种新的方法来跟踪不同测试分布的性能差异随扩展的变化情况，而非仅仅关注绝对误差的变化。本文通过训练255个等算力的解码器-only Transformer模型，并在固定算力预算下使用标准预训练数据集从$10^{18}$到$10^{20}$ FLOPs训练模型，发现了不同轨迹的结果，展示了虽然扩展可以提高整体性能，但它并不是一个普遍的均衡器。", "innovation": "引入了相对扩展法则，这种方法跟踪的是不同测试分布的性能差距随扩展的变化情况，而不仅仅关注绝对误差的变化。通过对255个等算力的解码器-only Transformer模型在固定算力预算下从$10^{18}$到$10^{20}$ FLOPs的训练结果，发现了学术领域、不同地区的英语方言以及AI风险因素群组截然不同的增长轨迹。", "conclusion": "虽然扩展能够提高模型的整体性能，但这种方法并非无差别的均衡器。为了进一步的研究，本研究将所有模型检查点公开，以使实践者能够在测量传统的扩展法则的同时，测量相对扩展法则，从而更好地优先考虑鲁棒性挑战。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24647", "html_url": "https://arxiv.org/abs/2510.24647", "title": "量化词长、频率和可预测性对阅读障碍影响的效果", "title_en": "Quantifying the Effects of Word Length, Frequency, and Predictability on Dyslexia", "authors": "Hugo Rydel-Johnston,Alex Kafkas", "background": "本研究探讨了在大规模自然阅读数据集中阅读障碍导致的额外读取成本发生的时间和条件，使用眼动追踪数据并结合单词级别的特征（词长、频率和可预测性）进行建模，以分析这些特征如何影响阅读时间。研究发现，词长、频率和可预测性这三个特征都能显著影响典型的和阅读障碍读者的阅读时间，且阅读障碍读者对这些特征的敏感度尤其是可预测性方面更强。", "innovation": "通过量化词汇特征（词长、频率和可预测性）对阅读障碍的影响，研究者发现通过改变这些特征可以显著缩小阅读障碍与对照组之间的时间差异，特别是增强的可预测性效果最明显，其次是词长和频率。研究结果与阅读障碍理论中的语言工作记忆和语音编码需求增强的观点一致，并为下一步研究词汇复杂性和旁视预览效益提供了动机，以进一步解释剩余的时间差异。", "conclusion": "综上，本研究量化了阅读障碍的额外成本发生的时间点及其大小，为制定针对阅读障碍者的干预措施和计算模型提供了可操作的指导。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24664", "html_url": "https://arxiv.org/abs/2510.24664", "title": "MQM Re-Annotation: 一种机器翻译协作评估技术", "title_en": "MQM Re-Annotation: A Technique for Collaborative Evaluation of Machine Translation", "authors": "Parker Riley,Daniel Deutsch,Mara Finkelstein,Colten DiIanni,Juraj Juraska,Markus Freitag", "background": "机器翻译模型质量不断提高，但合适的评价方法也需相应改善，以确保评价结果不会因评价误差而产生偏差。当前的评价标准（MQM）可能由于人工标注的一次性审查产生的错误，导致翻译质量测量不准，因此需要改进评价方法，使其更可靠和准确，确保模型质量的真正提升被公正反映出来。基于此背景，本文提出了一种改进的评价策略：MQM重标注法。", "innovation": "本文引入了MQM重标注法，这是一种两阶段的评价方式，其中评价者会审查和修正先前标注的内容。这种方法显著提高了评价质量，主要是通过纠正初次标注过程中遗漏的错误，使评价结果更加准确。这种创新弥补了当前评价方法中的不足，尤其是在确保评价结果与实际翻译质量之间的一致性方面。", "conclusion": "实验表明，重标注后的评价结果与目标一致，且重标注后的评价结果质量更高。这主要归因于在初次标注中因疏忽而未被发现的错误被纠正，从而确保了评价的准确性。这种新的评价方式为机器翻译评价提供了一种高效和可靠的解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24654", "html_url": "https://arxiv.org/abs/2510.24654", "title": "在虚拟临床环境中演化的诊断代理", "title_en": "Evolving Diagnostic Agents in a Virtual Clinical Environment", "authors": "Pengcheng Qiu,Chaoyi Wu,Junwei Liu,Qiaoyu Zheng,Yusheng Liao,Haowen Wang,Yun Yue,Qianrui Fan,Shuai Zhen,Jian Wang,Jinjie Gu,Yanfeng Wang,Ya Zhang,Weidi Xie", "background": "本文介绍了使用强化学习训练大型语言模型作为诊断代理的框架，使它们能够在多轮诊断过程中进行判断，选择适当的检查，并得出最终诊断。与仅基于静态病例摘要的指令调优模型不同，本文方法通过交互式探索和基于结果的反馈来获取诊断策略。", "innovation": "本研究的贡献有四个方面：（i）提出了DiagGym，一个使用电子健康记录培训的诊断世界模型，该模型基于患者历史和推荐的检查项目生成检查结果，作为真实的诊断培训和评估的虚拟临床环境；（ii）通过端到端、多轮次强化学习训练DiagAgent，学习优化信息产出和诊断准确性的诊疗策略；（iii）引入了包含750个病例，带有医师验证检查建议的DiagBench诊断基准，以及99个标注了973个医师诊断过程评价的病例；（iv）在各种诊断场景中展示了DiagAgent的卓越性能。DiagAgent在多个基准测试中显著优于10个最先进的大型语言模型，包括DeepSeek-v3和GPT-4o，以及两个提示工程的代理。", "conclusion": "实验结果显示，学习策略在交互式临床环境中赋予了动态且临床意义重大的诊断管理能力，这是仅通过被动训练无法实现的。单轮设置中，DiagAgent的诊断准确性和检查建议命中率分别提高了9.34%和44.03%。端到端设置中，其诊断准确性和检查建议F1分数分别提高了15.12%和23.09%。在评分基准评估中，其在加权评分基准上的表现超过了第二好的模型Claude-sonnet-4，高出7.1%。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24668", "html_url": "https://arxiv.org/abs/2510.24668", "title": "InteractComp: 使用含歧义查询评估搜索代理", "title_en": "InteractComp: Evaluating Search Agents With Ambiguous Queries", "authors": "Mingyi Deng,Lijun Huang,Yani Fan,Jiayi Zhang,Fashen Ren,Jinyi Bai,Fuzhen Yang,Dayi Miao,Zhaoyang Yu,Yifan Wu,Yanfei Zhang,Fengwei Teng,Yingjia Wan,Song Hu,Yude Li,Xin Jin,Conghao Hu,Haoyu Li,Qirui Fu,Tai Zhong,Xinyu Wang,Xiangru Tang,Nan Tang,Chenglin Wu,Yuyu Luo", "background": "语言代理在网页搜索和信息检索中展现出了巨大的潜力，但现有的搜索代理通常假设用户的问题是完整且明确的，这意味着在用户实际的问题通常不完整且需要通过交互进行澄清这一现实场景中，这些代理仅依赖部分信息进行搜索，难以满足用户需求。然而，现有基准无法评估代理的这种交互能力。", "innovation": "为了解决上述问题，作者提出了一种名为InteractComp的新基准，专门用于评估搜索代理在面对含义模糊的查询时能否察觉模糊性并主动通过交互方式进行澄清。通过引入特定的方法论构造出实际可以解除模糊的含歧义问题。实验结果表明，现有17种模型在处理模糊查询时效果差强人意，最佳模型仅能以13.73%的准确率处理模糊问题，而在提供完整上下文的情况下准确率为71.50%，显示出过度自信而非推理缺陷的问题。强制性交互可以大幅提升模型处理模糊查询的能力，显示出当前策略未充分利用的潜在能力。此外，长时间分析还揭示了交互功能没有得到预期的发展，而搜索表现则有了显著提升。", "conclusion": "InteractComp作为一项关键资源，不仅能够帮助评估搜索代理的交互能力，同时也为提升这些代理在处理含意义模糊的查询方面的性能提供了有价值的参考。详细的代码已经公开。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24684", "html_url": "https://arxiv.org/abs/2510.24684", "title": "SPICE：基于语料库环境的自互动提升了推理能力", "title_en": "SPICE: Self-Play In Corpus Environments Improves Reasoning", "authors": "Bo Liu,Chuanyang Jin,Seungone Kim,Weizhe Yuan,Wenting Zhao,Ilia Kulikov,Xian Li,Sainbayar Sukhbaatar,Jack Lanchantin,Jason Weston", "background": "自我改进系统需要与环境交互以实现持续适应。现有的未接地的自互动方法仅提供了有限的改进。本文旨在研究如何利用基于语料库的环境改进模型的推理能力。", "innovation": "本文引入了SPICE（自互动于语料库环境）框架，该框架中的单个模型同时扮演挑战者和解决者两个角色，通过对抗机制，挑战者会创建与解决者能力边界相匹配的自动课程，从而不断地提升模型的推理能力。", "conclusion": "实验结果显示，SPICE在多种模型家族中，在数学推理(+8.9%)和通用推理(+9.8%)基准测试上都取得了持续性的改进。分析表明，文档接地对于SPICE生成自我挑战的目标至关重要，从而使模型能够自我持续改进。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24677", "html_url": "https://arxiv.org/abs/2510.24677", "title": "通过神经元消融剖析医学LLMs中的角色认知", "title_en": "Dissecting Role Cognition in Medical LLMs via Neuronal Ablation", "authors": "Xun Liang,Huayi Lai,Hanyu Wang,Wentao Zhang,Linfeng Zhang,Yanfang Chen,Feiyu Xiong,Zhiyu Li", "background": "大规模语言模型（LLMs）在医疗决策支持系统中的应用越来越广泛，尤其是在医学问答和角色扮演模拟中。常见的做法是基于提示的角色扮演（PBRP），这种做法要求模型模拟不同临床角色（如实习生、住院医师和主治医师）的临床行为。然而，角色提示对模型推理能力的影响尚不清楚。本研究引入了RP-Neuron-Activated Evaluation Framework（RPNA）框架，旨在评估角色提示是否引发模型特定的认知过程，还是仅仅改变了语言风格。该框架通过神经元消减和表示分析技术，在三个医学问答数据集上进行了测试。", "innovation": "本研究创新性地提出RP-Neuron-Activated Evaluation Framework（RPNA）框架，通过神经元消减技术检查模型在不同角色提示下的推理路径变化。研究发现，尽管存在表面上的风格变化，但模型的核心决策机制在不同角色中保持一致，表明现有的PBRP方法未能复制真实世界医学实践中所见的认知复杂性。这突显了医疗AI中角色扮演的局限，并强调了模拟真正认知过程而非语言模拟的模型需求。", "conclusion": "角色提示并未显著提升LLMs的医学推理能力，主要影响表层语言特征，未发现不同临床角色下不同推理路径或认知分化的证据。尽管表面风格有所变化，LLMs的核心决策机制保持一致，这表明当前的PBRP方法未能复制实际医疗实践中的认知复杂性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24698", "html_url": "https://arxiv.org/abs/2510.24698", "title": "ParallelMuse:自主平行思考在深度信息检索中的应用", "title_en": "ParallelMuse: Agentic Parallel Thinking for Deep Information Seeking", "authors": "Baixuan Li,Dingchu Zhang,Jialong Wu,Wenbiao Yin,Zhengwei Tao,Yida Zhao,Liwen Zhang,Haiyang Shen,Runnan Fang,Pengjun Xie,Jingren Zhou,Yong Jiang", "background": "平行思考能够扩展探索范围，补充信息寻求(IS)代理的深度探索，从而提升解决问题的能力。然而，传统的平行思考在此场景中面临两个关键挑战：从头开始重复尝试的低效性，以及在生成答案时难以整合长期推理轨迹，因为有限的上下文容量无法全面考虑推理过程。", "innovation": "针对上述问题，我们提出了ParallelMuse，一种为深度IS代理设计的两阶段范式。第一阶段，功能指定的部分展开，将生成序列分割为功能区域，并使用不确定性指导的路径重用和分支来提高探索效率。第二阶段，压缩推理聚合，利用推理冗余来无损地压缩与答案推导相关的信息，并综合出一个连贯的最终答案。", "conclusion": "在多个开源代理和基准上的实验表明，ParallelMuse可实现高达62%的性能改进，并且在探索性token消耗上减少10-30%。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24697", "html_url": "https://arxiv.org/abs/2510.24697", "title": "WebLeaper：通过增强网络代理的信息丰富搜索，实现高效性和有效性", "title_en": "WebLeaper: Empowering Efficiency and Efficacy in WebAgent via Enabling Info-Rich Seeking", "authors": "Zhengwei Tao,Haiyang Shen,Baixuan Li,Wenbiao Yin,Jialong Wu,Kuan Li,Zhongwang Zhang,Huifeng Yin,Rui Ye,Liwen Zhang,Xinyu Wang,Pengjun Xie,Jingren Zhou,Yong Jiang", "background": "基于大规模语言模型（LLM）的代理已经成为了开放式问题解决的一种变革性方法，其中信息检索（IS）作为一个核心能力，支持了自主的推理和决策。早先的研究主要集中在提高检索深度上，然而，当前的IS代理往往面临低搜索效率的问题，这限制了整体性能。造成这种低效率的主要原因是训练任务中目标实体的稀疏性，这限制了代理学习和泛化高效搜索行为的机会。", "innovation": "本文提出了WebLeaper，这是一种构建高覆盖信息检索任务和生成高效解空间的框架。通过将IS问题形式化为树状推理问题，WebLeaper能够在一个受限上下文中包含更多的目标实体。WebLeaper采用了精心设计的Wikipedia表格，提出了三种合成IS任务的变体：基本型、联合型和反联合型，这些变体系统地提高了检索效率和有效性。同时，通过仅保留同时准确且高效的训练轨迹，确保了模型在正确性和搜索性能方面都进行了优化。", "conclusion": "在五大IS基准测试浏览器组件、GAIA、xbench-DeepSearch、宽搜索和Seal-0上的广泛实验表明，我们的方法在有效性与效率方面都优于强基准线。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24699", "html_url": "https://arxiv.org/abs/2510.24699", "title": "AgentFold：长周期网页代理的主动上下文管理", "title_en": "AgentFold: Long-Horizon Web Agents with Proactive Context Management", "authors": "Rui Ye,Zhongwang Zhang,Kuan Li,Huifeng Yin,Zhengwei Tao,Yida Zhao,Liangcai Su,Liwen Zhang,Zile Qiao,Xinyu Wang,Pengjun Xie,Fei Huang,Siheng Chen,Jingren Zhou,Yong Jiang", "background": "基于大语言模型（LLM）的网页代理在信息检索方面显示出巨大的潜力，但它们在长期任务中的有效性受到了上下文管理上的一种根本性权衡的限制。现有的基于ReAct的代理由于累积了嘈杂的原始历史记录而面临上下文饱和的问题，而固定地在每一步总结完整历史记录的方法则会不可避免地损失关键细节。", "innovation": "该论文提出了一种名为AgentFold的新代理范式，它以主动上下文管理为基础，受到人类认知过程中回顾性整合的启发。AgentFold将其上下文视为一个动态的认知工作空间，可以主动塑造，而不是被动记录。在每一步中，AgentFold学会执行“折叠”操作，该操作可以对历史轨迹进行多尺度管理，既可以进行粒度压缩以保留关键的细粒度细节，也可以进行深度整合以抽象出整个多步子任务。", "conclusion": "实验结果表明，使用简单的监督微调，无需持续预训练或强化学习，AgentFold-30B-A3B代理在BrowseComp基准测试中达到了36.2%的成绩，在BrowseComp-ZH中达到了47.3%的成绩。这种性能不仅超越或与之匹配了大幅更大规模的开源模型DeepSeek-V3.1-671B-A37B，还超过了OpenAI等领先商业代理o4-mini。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24701", "html_url": "https://arxiv.org/abs/2510.24701", "title": "Tongyi DeepResearch技术报告", "title_en": "Tongyi DeepResearch Technical Report", "authors": "Tongyi DeepResearch Team:Baixuan Li,Bo Zhang,Dingchu Zhang,Fei Huang,Guangyu Li,Guoxin Chen,Huifeng Yin,Jialong Wu,Jingren Zhou,Kuan Li,Liangcai Su,Litu Ou,Liwen Zhang,Pengjun Xie,Rui Ye,Wenbiao Yin,Xinmiao Yu,Xinyu Wang,Xixi Wu,Xuanzhong Chen,Yida Zhao,Zhen Zhang,Zhengwei Tao,Zhongwang Zhang,Zile Qiao,Chenxi Wang,Donglei Yu,Gang Fu,Haiyang Shen,Jiayin Yang,Jun Lin,Junkai Zhang,Kui Zeng,Li Yang,Hailong Yin,Maojia Song,Ming Yan,Peng Xia,Qian Xiao,Rui Min,Ruixue Ding,Runnan Fang,Shaowei Chen,Shen Huang,Shihang Wang,Shihao Cai,Weizhou Shen,Xiaobin Wang,Xin Guan,Xinyu Geng,Yingcheng Shi,Yuning Wu,Zhuo Chen,Zijian Li,Yong Jiang", "background": "研究中介绍了Tongyi DeepResearch，这是一个专门设计用于长期深度信息搜索研究任务的有代理性的大规模语言模型。作者开发了端到端的训练框架，结合有代理性的中期训练和后期训练，以激励自主的深度研究机制，实现复杂任务中可扩展的逻辑推理和信息查找。此外，通过设计完全自动化的数据合成管道，无需依赖昂贵的人工注释来赋能所有训练阶段，从而实现稳定且一致的交互", "innovation": "Tongyi DeepResearch采用了一种端到端的训练框架，该框架结合了有代理性的中期训练和后期训练，以促进自主的深度研究代理能力，使得在复杂的任务中实现可扩展的逻辑推理和信息查找。此外，该研究采用完全自动化的数据合成管道，不需要依赖昂贵的人工注释，从而实现所有训练阶段的赋能", "conclusion": "Tongyi DeepResearch，拥有总计305亿参数，但每个标记仅有3.3亿参数激活，已经在一系列有代理性深度研究基准测试中（包括人类最后一次考试、BrowseComp、BrowseComp-ZH、WebWalkerQA、xbench-DeepSearch、FRAMES和xbench-DeepSearch-2510）达到了最先进水平。该模型、框架和完整解决方案已开放源代码，以赋能社区"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24702", "html_url": "https://arxiv.org/abs/2510.24702", "title": "Agent Data Protocol: 统一代理数据协议，以实现多样化且高效的LLM代理微调", "title_en": "Agent Data Protocol: Unifying Datasets for Diverse, Effective Fine-tuning of LLM Agents", "authors": "Yueqi Song,Ketan Ramaneti,Zaid Sheikh,Ziru Chen,Boyu Gou,Tianbao Xie,Yiheng Xu,Danyang Zhang,Apurva Gandhi,Fan Yang,Joseph Liu,Tianyue Ou,Zhihao Yuan,Frank Xu,Shuyan Zhou,Xingyao Wang,Xiang Yue,Tao Yu,Huan Sun,Yu Su,Graham Neubig", "background": "关于大规模监督微调AI代理的公共研究结果相对较少，因为代理训练数据的收集具有独特的挑战。现有的研究主要集中在数据的收集和整合，而缺乏统一的数据表示标准使得跨不同格式、工具和接口的数据难以有效利用。", "innovation": "作者提出了一种轻量级的表示语言——代理数据协议（ADP），作为不同格式代理数据集之间的“中介语”，能够捕捉包括API/工具使用、浏览、编码、软件工程和通用代理工作流程等多种任务，并且易于解析和训练，无需在每个数据集上进行工程化处理。该研究将13个现有代理训练数据集统一到ADP格式，并将标准化的ADP数据转换为多个代理框架的训练准备格式，实现了约20%的性能提升，且在标准编码、浏览、工具使用和研究基准上达到了最先进的或接近SOTA的性能，无需领域特定的调整。", "conclusion": "所有代码和数据已公开发布，旨在降低标准化、可扩展且可复现的代理训练的门槛。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24695", "html_url": "https://arxiv.org/abs/2510.24695", "title": "AgentFrontier：通过ZPD指导的数据合成扩展LLM代理的能力前沿", "title_en": "AgentFrontier: Expanding the Capability Frontier of LLM Agents with ZPD-Guided Data Synthesis", "authors": "Xuanzhong Chen,Zile Qiao,Guoxin Chen,Liangcai Su,Zhen Zhang,Xinyu Wang,Pengjun Xie,Fei Huang,Jingren Zhou,Yong Jiang", "background": "训练大型语言模型代理在接近其能力极限的任务上是解锁高级推理的关键。本文提出了一种基于教育理论中的‘最近发展区’（ZPD）概念的数据合成方法，该理论定义了这些极限任务为LLM无法独立解决，但通过指导可以掌握的任务。通过这种方式，本文介绍了AgentFrontier Engine，一个自动化的数据合成引擎，该引擎合成高质量的多学科数据，精准定位在LLM的ZPD区域内。该引擎支持继续预训练与复杂推理任务的针对性后训练。作为同一框架的一部分，我们推出了ZPD Exam动态和自动化的基准，用于评估代理在这些前沿任务上的能力。我们使用该合成数据对AgentFrontier-30B-A3B模型进行训练，并在挑战性基准测试如‘人类最后考试’中达到了最先进的结果，甚至超过了某些领先的私有代理。这项工作表明，ZPD引导的数据合成方法为构建更强大的LLM代理提供了一条可扩展且有效的方法路径。", "innovation": "本文引入了一种受“最近发展区”（ZPD）启发的数据合成方法，用于训练大型语言模型代理。设计了AgentFrontier Engine，一个自动化的数据合成引擎，能够生成高质量的多学科数据，这些数据正好定位在模型无法独立解决但通过指导可以掌握的任务范围内。方法还包括了一个称为ZPD Exam的动态自动化基准测试，用于评估代理在这些前沿任务上的表现。通过使用该合成数据集训练模型，实现了在挑战性任务上的卓越性能。", "conclusion": "ZPD引导的数据合成方法为构建更强大的LLM代理提供了一条可扩展且有效的方法路径。通过这一方法，展示了在面临挑战性任务时，代理性能的显著提升，并有望在未来推动语言模型能力的进一步突破。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23626", "html_url": "https://arxiv.org/abs/2510.23626", "title": "从检测到发现：一种社交媒体上的同时和连续医学知识拓展与抑郁症检测的闭环方法", "title_en": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media", "authors": "Shuang Geng,Wenli Zhang,Jiaheng Xie,Rui Wang,Sudha Ram", "background": "社交媒体用户生成的内容（UGC）提供了实时的、自我报告的关于心理健康的指标，比如抑郁，这些内容为预测分析提供了重要的数据源。现有研究通过集成医学知识来提升预测准确性，但忽略了在预测过程中同时扩展知识的机会。", "innovation": "本研究开发了一个闭环大型语言模型（LLM）-知识图谱框架，该框架在一个迭代学习周期中集成了预测与知识扩展。框架通过医学知识意识的抑郁检测阶段和知识细化与扩展阶段，实现了监测数据上同时发现和检测抑郁症的发展，并利用大型用户生成内容增强预测准确性和医学理解。", "conclusion": "专家评估确认框架能够发现临床重要的症状、共病和社交诱因。该框架描绘了计算模型与领域知识的共生发展，提供了适用于其他动态风险监测情境的自适应数据驱动知识系统的基础。概念上，预测促进学习和学习促进预测的过程相互强化，深化了预测分析的方法论和理论理解。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24707", "html_url": "https://arxiv.org/abs/2510.24707", "title": "MetricX-25和GemSpanEval：Google Translate在WMT25评估共享任务中的提交", "title_en": "MetricX-25 and GemSpanEval: Google Translate Submissions to the WMT25 Evaluation Shared Task", "authors": "Juraj Juraska,Tobias Domhan,Mara Finkelstein,Tetsuji Nakagawa,Geza Kovacs,Daniel Deutsch,Pidong Wang,Markus Freitag", "background": "该论文分析了Google针对WMT25翻译评估共享任务的参赛作品，包括Quality Score Prediction（质量评分预测）和Error Span Detection（错误片段检测）两个子任务。背景主要围绕现有的评估系统，如MetricX和Gemma 3，并指出这些系统在输入格式和训练协议上的改进需求。", "innovation": "创新之处在于开发了MetricX-25和GemSpanEval。MetricX-25是一个基于Gemma 3的改进版本，采用编码器架构并带有回归头部，能够有效预测MQM和ESA质量评分，性能显著优于前代产品。GemSpanEval则是一款全新的仅解码器模型，用于错误片段检测，与xCOMET相比具有竞争力。此外，GemSpanEval能够生成每个预测错误片段的上下文，确保错误片段的唯一识别。", "conclusion": "实验结果表明，MetricX-25能够有效预测质评分，并在质量评分预测子任务中表现出色。GemSpanEval则是该领域的有力候选，能够与其他强大的序列标注基线（如xCOMET）竞争，并能够精确地识别错误片段。这些改进展示了通过充分利用现有开放版权模型和改进训练策略来提升翻译评价系统的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23637", "html_url": "https://arxiv.org/abs/2510.23637", "title": "结合文本和结构信息的Lean前提选择", "title_en": "Combining Textual and Structural Information for Premise Selection in Lean", "authors": "Job Petrovčič,David Eliecer Narvaez Denis,Ljupčo Todorovski", "background": "在大规模形式化库中，前提选择是定理证明的关键瓶颈。现有的基于语言的方法通常将前提孤立处理，忽视了它们之间的相互依赖关系。", "innovation": "提出了一种图增强方法，将Lean形式化密集的文本嵌入与一个捕捉状态-前提和前提-前提关系的异构依赖图结合的图神经网络相结合。这种方法在LeanDojo基准测试中，跨标准检索指标，性能比ReProver基于语言的基线高出25%以上。", "conclusion": "这些结果表明关系信息在更有效的前提选择中的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23630", "html_url": "https://arxiv.org/abs/2510.23630", "title": "NUM2EVENT: 从数值时间序列中获得可解释的事件推理", "title_en": "NUM2EVENT: Interpretable Event Reasoning from Numerical time-series", "authors": "Ninghui Feng,Yiyan Qi", "background": "大型语言模型（LLMs）尽管展现了令人印象深刻的多模态推理能力，但在理解纯粹的数值时间序列信号方面仍有限制。现有的方法主要集中在预测或趋势描述上，未能揭示驱动数值变化的潜在事件，亦未解释背后的推理过程。为了应对这一挑战，本研究提出了从数值输入中推断可解释的结构化事件的任务，即使当前无法获得相关文本。但现有方法存在数据稀缺和语义对齐的难题。", "innovation": "本研究提出了一种新的推理意识框架，该框架整合了代理引导的事件提取器（AGE）、标记的多重Hawkes过程合成生成器（EveDTS），以及结合时间序列编码器和结构化解码器的两阶段微调管道。该模型不仅能够推理数值变化、生成中间解释，还能输出结构化的事件假设。实验结果表明，该方法在事件级的精确度和召回率上显著优于现有的强LLM基线。", "conclusion": "这些结果表明了量化推理和语义理解之间联系的新方向，使LLM能够直接从数值动态中解释和预测事件。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23617", "html_url": "https://arxiv.org/abs/2510.23617", "title": "增强的双变换器对比网络在多模态情感分析中的应用", "title_en": "An Enhanced Dual Transformer Contrastive Network for Multimodal Sentiment Analysis", "authors": "Phuong Q. Dao,Mark Roantree,Vuong M. Ngo", "background": "多模态情感分析（MSA）通过联合分析文本和图像等不同类型的数据，提供比单一模态方法更丰富和准确的情感理解。已有工作提出了一种新的模型Bert-ViT-EF，该模型结合了基于Transformer的编码器BERT用于文本输入和ViT用于视觉输入，并通过早期融合策略促进了跨模态的深度交互和有效联合表示学习。进一步，为了增强模型的能力，提出了Dual Transformer Contrastive Network (DTCN)，该网络在BERT之后加入了一个额外的Transformer编码器层以细化文本上下文（在融合之前），并通过对比学习对齐文本和图像表示，促进稳健的多模态特征学习。实验结果表明，DTCN在TumEmo和MVSA-Single两个广泛使用的MSA基准上的表现更为出色，准确率和F1分数均高于现有方法，证明了早期融合和更深层次的上下文建模在基于Transformer的多模态情感分析中的好处。", "innovation": "本文创新性地提出了Bert-ViT-EF模型和Dual Transformer Contrastive Network (DTCN)。Bert-ViT-EF结合了BERT和ViT，通过早期融合策略增强了跨模态交互和有效联合表示学习。DTCN在BERT之后加入了额外的Transformer编码器层，通过对比学习对齐文本和图像表示，从而实现更加稳健的多模态特征学习。", "conclusion": "DTCN在TumEmo中实现了最高的准确率（78.4%）和F1分数（78.3%），并且在MVSA-Single上也表现出较为竞争力的结果，实现了76.6%的准确率和75.9%的F1分数，验证了早期融合和深度上下文建模在基于Transformer的多模态情感分析中的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23636", "html_url": "https://arxiv.org/abs/2510.23636", "title": "通过大规模语言模型和飞机航迹表示的跨模态适应进行航班延误预测", "title_en": "Flight Delay Prediction via Cross-Modality Adaptation of Large Language Models and Aircraft Trajectory Representation", "authors": "Thaweerath Phisannupawong,Joshua Julian Damanik,Han-Lim Choi", "background": "航班延误已成为空中交通管理的关键关注点，因为空中交通延误反映了网络运行的低效率，影响了整体网络性能。研究人员提出了一种飞行延误预测方法，从空中交通管制员监测飞机在终端区域进入后的延误的角度出发，该方法以轻量级的大规模语言模型为基础，结合轨迹表示与文本航空信息，包括航空飞行信息、天气报告和机场通告，通过将轨迹数据转换为语言模态来捕捉空中态势。", "innovation": "该方法通过将轨迹数据整合进语言模态，将航空轨迹表示与文本航空信息相结合，实现了跨模态适应。这种方法能够有效利用与延误源相关的上下文信息，从而使模型能够实现接近实时的延误预测，显著改善了航班延误预测的精度。此框架展示了语言理解与轨迹信息的跨模态适应相结合，可增强航班延误预测的能力。另外，该方法表明，在实际运营中具有可操作性和可扩展性，能够提供实时更新，细化预测。", "conclusion": "实验证明，模型可以持续实现亚分钟级的预测误差，通过有效利用与延误源相关的上下文信息。此外，该框架证明了语言理解和轨迹信息跨模态适应相结合增强航班延误预测的效果，显示其在实际操作中的实用性和扩展性，支持实时更新以精化预测。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24706", "html_url": "https://arxiv.org/abs/2510.24706", "title": "ComboBench：大语言模型能否操纵物理设备玩虚拟现实游戏？", "title_en": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality Games?", "authors": "Shuqing Li,Jiayi Yan,Chenyu Niu,Jen-tse Huang,Yun Peng,Wenxuan Wang,Yepang Liu,Michael R. Lyu", "background": "虚拟现实（VR）游戏需要玩家将高层次的语义动作转化为精准的设备操作。人类可以通过常识和经验感知来直观地完成这种转换。然而，大型语言模型（LLMs）是否能够有效复制这一能力尚未充分研究。本文介绍了一个基准测试，名为ComboBench，用于评估LLMs在四种流行VR游戏（《半条命：ALYX》、《Into the Radius》、《Moss：第二册》、《Vivecraft》）中的262个场景中转换语义动作为VR设备操作序列的能力，评估了包括GPT-3.5、GPT-4、GPT-4o、Gemini-1.5-Pro、LLaMA-3-8B、Mixtral-8x7B、GLM-4-Flash在内的七种模型，并与人工标注的真实数据和人类表现进行了对比。结果显示顶级模型虽表现出强大的任务分解能力，但在程序推理和空间理解方面仍不及人类。不同游戏的游戏交互复杂性导致性能差异显著。提示样本显著提高了性能，表明在特定增强方面有潜在可能性。相关资料可在本文提供的链接中获取。", "innovation": "提出了一个名为ComboBench的基准测试，用于评估LLMs在将语义动作转化为VR设备操作序列方面的表现。这是第一次系统地研究LLMs在转换复杂的日志语义动作以进行精确的VR设备操纵方面的能力。通过使用多种LLM模型和广泛的场景，该研究揭示了模型在任务分解和程序推理方面的局限性以及对交互复杂性的敏感性。此外，该研究强调了小样本提示在提升性能中的重要性。", "conclusion": "尽管顶级模型显示了强大的任务分解能力，但在程序推理和空间理解方面落后于人类。不同VR游戏的游戏复杂性会导致性能差异显著。通过提供相关的提示样本，可以在增强LLM的VR设备操纵能力方面取得进展。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23642", "html_url": "https://arxiv.org/abs/2510.23642", "title": "VisCoder2: 建立多语言可视化编码代理", "title_en": "VisCoder2: Building Multi-Language Visualization Coding Agents", "authors": "Yuansheng Ni,Songcheng Cai,Xiangchao Chen,Jiarong Liang,Zhiheng Lyu,Jiaqi Deng,Kai Zou,Ping Nie,Fei Yuan,Xiang Yue,Wenhu Chen", "background": "大型语言模型(LLMs)最近使得能够生成、执行和修订可视化代码的编码代理成为可能。然而，现有的模型在实际的工作流中往往由于语言覆盖有限、执行不可靠以及缺乏迭代修正机制而失败。进展受到狭窄数据集和侧重于单轮生成和单语言任务的基准测试的限制。", "innovation": "该论文介绍了三种推进可视化编码代理的互补资源：1) VisCode-Multi-679K，一个包含679K经过验证和可执行的可视化样本的大规模监督数据集，涉及多轮修正对话，适用于12种编程语言；2) VisPlotBench，一个系统评估基准，包含可执行任务、渲染输出以及针对初始生成和多轮自调试的协议；3) VisCoder2，一种多语言的可视化模型家族，训练数据来自VisCode-Multi-679K，实验表明，VisCoder2显著优于强大开源基线，并接近于GPT-4等专有模型的表现，通过迭代自调试，32B规模的总体执行通过率达到82.4%，特别是在符号或编译器依赖的语言中。", "conclusion": "通过引入VisCode-Multi-679K和VisPlotBench资源以及开发VisCoder2模型，本研究解决了现有模型实际工作流程中的缺陷，并展示了在多语言可视化编码任务中显著的改进。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23763", "html_url": "https://arxiv.org/abs/2510.23763", "title": "RoboOmni：全模态情境下的主动机器人操作", "title_en": "RoboOmni: Proactive Robot Manipulation in Omni-modal Context", "authors": "Siyin Wang,Jinlan Fu,Feihong Liu,Xinzhe He,Huangxuan Wu,Junhao Shi,Kexin Huang,Zhaoye Fei,Jingjing Gong,Zuxuan Wu,Yugang Jiang,See-Kiong Ng,Tat-Seng Chua,Xipeng Qiu", "background": "最近，多模态大型语言模型（MLLMs）在视觉-语言-动作（VLA）模型方面的进展推动了机器人操作的快速发展。现有的方法主要依赖明确指令，但在实际交互中，人类很少直接给出指令。有效的协作需要机器人主动推断用户的意图。", "innovation": "本文提出了跨模态关联指示这一新框架，意图从口头对话、环境声音和视觉提示中推导，而非直接的明确命令。为了解决这一新框架，我们提出了一种基于端到端全模态大语言模型的RoboOmni框架，综合了意图识别、交互确认和行动执行三个功能。RoboOmni通过结合音频和视觉信号进行稳健的意图识别，同时支持直接语音交互。", "conclusion": "实验结果表明，RoboOmni在成功率、推理速度、意图识别和主动辅助方面均优于基于文本和自动语音识别的基准模型。同时，我们构建了OmniAction数据集，包含140k集、5000多位讲者、2400个事件声音、640种背景和六种表征语境指令的类型。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23727", "html_url": "https://arxiv.org/abs/2510.23727", "title": "MUStReason：用于视频LM多模态反讽检测中的pragma推理诊断的基准", "title_en": "MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection", "authors": "Anisha Saha,Varsha Suresh,Timothy Hospedales,Vera Demberg", "background": "反讽是一种特定类型的修辞手法，涉及从字面上理解含义。检测反讽不仅依赖于言辞的字面内容，还依赖于非言语线索，如讲话者音调、面部表情和对话背景。然而，当前的多模态模型在处理此类复杂的任务时（如反讽检测），难以识别跨模态的相关线索，并在语用层面上进行推理以推断说话者的意图。", "innovation": "为了探讨在VideoLMs中存在的这些限制，该研究提出了MUStReason，一个增强标记的基准，包含了模态特定的相关线索和潜在的推理步骤标注，用于识别讽刺意图。此外，MUStReason用于定量和定性地评估VideoLMs生成的推理，将问题拆解为感知和推理两部分，并提出了PragCoT框架，该框架指导VideoLMs关注隐含意图而非字面意义，这正是检测反讽的核心属性。", "conclusion": "MUStReason不仅可用于评估VideoLMs的反讽分类性能，还可以路径在解决反讽检测任务时面临的挑战。通过PragCoT框架，VideoLMs能够更好地聚焦于隐含意图上而不是字面意义，从而提高反讽检测的准确性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23925", "html_url": "https://arxiv.org/abs/2510.23925", "title": "视觉推理中的潜在链式思维", "title_en": "Latent Chain-of-Thought for Visual Reasoning", "authors": "Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao", "background": "链式思维（CoT）对于提高大型视觉-语言模型（LVLMs）的可解释性和可靠性至关重要。然而，目前的训练算法如SFT、PPO和GRPO在处理未见过的推理任务时可能无法很好地泛化，且过度依赖于有偏见的奖励模型。", "innovation": "本文将LVLMs中的推理重新定义为后验推理，并提出了一种基于近似变分推理的可扩展训练算法。通过利用寻求多样性的强化学习算法，引入了一种新颖的稀疏奖励函数，以鼓励多样化且高概率的潜在CoT，解决了确定性采样的局限性，避免了奖励作弊。此外，实施了一种贝叶斯推理扩展策略，用边际似然逐步替代昂贵的多个最佳采样和束搜索，以高效地排名最优论据和答案。", "conclusion": "所提出的方法定量上证明了在七个推理基准测试上的先进LVLMs具有更高的有效性、泛化能力和可解释性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23849", "html_url": "https://arxiv.org/abs/2510.23849", "title": "一种用于上下文偏倚分数学习和过滤的神经模型", "title_en": "A Neural Model for Contextual Biasing Score Learning and Filtering", "authors": "Wanting Huang,Weiran Wang", "background": "上下文偏倚可以通过在解码时整合外部知识（如用户特定短语或实体）来提升自动语音识别（ASR）的性能。传统方法依赖于上下文信息来提高识别准确性，但在实际应用中，偏倚信息可能与识别场景不完全匹配，导致识别错误。本文提出使用基于注意力的偏倚解码器来生成候选短语的分数，这些分数基于ASR编码器提取的声学信息，用于过滤出不可能的短语并计算浅融合偏倚的加分。", "innovation": "本文提出了一种新的基于神经模型的方法，用于上下文偏倚分数的学习和过滤。具体来说，通过引入一个每token的判别目标，该目标鼓励真实的短语得分更高并抑制干扰项。这种方法在不同的偏倚条件下都能显著提高识别准确性。", "conclusion": "实验结果表明，本文提出的方法能够有效过滤出大部分候选短语，并在浅融合偏倚中使用时显著提高了识别准确性。该方法具有模块化特性，适用于任何ASR系统，其过滤机制还可能增强其他偏倚方法的性能。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23868", "html_url": "https://arxiv.org/abs/2510.23868", "title": "GIFT: 根据组相对隐式微调结合GRPO与DPO和UNA", "title_en": "GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA", "authors": "Zhichao Wang", "background": "现有强化学习框架如PPO和GRPO主要通过直接最大化累计奖励来进行训练，尽管隐式奖励方法如DPO和UNA提出了一种新的奖励建模方式，但在实际应用中存在难以有效利用隐式奖励的问题，导致训练过程中出现过度拟合和其他问题。", "innovation": "GIFT提出了一个新的强化学习框架，通过同时规范化隐式和显式奖励来减少训练难题。它结合了GRPO的在线多响应生成和规范化机制、DPO的隐式奖励形式以及UNA的隐式-显式奖励对齐原则。GIFT将复杂的奖励最大化为目标简化为简单的均方误差（MSE）损失，使得问题变得更加凸性和稳定，并且易于分析。此外，与DPO和UNA这些离线方法相比，GIFT保持了在线策略的特性，保留了探索能力；与GRPO相比，它需要更少的超参数，更快收敛，并且具有更好的泛化能力，减少了训练过拟合。", "conclusion": "实验结果表明，GIFT在数学基准测试上实现了卓越的推理和对齐性能，同时保持了计算效率。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24035", "html_url": "https://arxiv.org/abs/2510.24035", "title": "GraphNet: 一个大规模计算图数据集，用于张量编译器研究", "title_en": "GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler Research", "authors": "Xinqi Li,Yiqun Liu,Shan Jiang,Enrong Zheng,Huaijin Zheng,Wenhao Dai,Haodong Deng,Dianhai Yu,Yanjun Ma", "background": "介绍了GraphNet数据集，包含2700个真实的深度学习计算图，覆盖多达六个主要任务类别，横跨多个深度学习框架，提供了丰富的元数据。为了评估这些样本下张量编译器的性能，本文提出了一个新的基准度量Speedup Score S(t)，它同时考虑了运行时加速和可调容差水平下的执行正确性，提供了优化能力的可靠度量。", "innovation": "提出了Speedup Score S(t)和Error-aware Speedup Score ES(t)两个新的基准度量，能够可靠地评估张量编译器的优化能力，并帮助识别编译器的关键性能瓶颈。", "conclusion": "本文在计算机视觉和自然语言处理领域对CINN（PaddlePaddle）和TorchInductor（PyTorch）的默认张量编译器进行了基准测试，展示了GraphNet的实际应用价值。同时，全文还包括了从图表提取到编译器评估工具的完整构建管道。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23969", "html_url": "https://arxiv.org/abs/2510.23969", "title": "从肌肉电图合成语音：利用自监督语音模型从电肌图合成语音", "title_en": "emg2speech: synthesizing speech from electromyography using self-supervised speech models", "authors": "Harshavardhana T. Gowda,Lee M. Miller", "background": "该研究介绍了一种将口腔面部肌肉在发音时采集的肌电图（EMG）信号直接转化为声音的神经肌肉语音接口。研究发现，自监督（SS）语音表征与肌肉动作电位的电气功率之间存在强烈的线性关系，SS特征与EMG功率之间的相关性为0.85。不同发音手势对应的EMG功率向量在特征空间中形成了结构化且可分离的簇。这种关系不仅表明SS模型隐式编码了发音机制，还为直接通过EMG信号生成语音提供了可能，无需明确的发音模型和声码器训练。", "innovation": "该研究利用自监督语音模型中的发音机制，直接将EMG信号映射至SS特征空间，从而实现从EMG到语音的直接合成。这种方法无需显式的发音模型以及声码器的训练，实现了端到端的EMG到语音的生成。", "conclusion": "研究展示了自监督语音模型在将EMG信号转化为语音时的能力，揭示了这些模型具备编码发音机制的特性。通过这种方法，可以直接且高效地从EMG信号生成语音，为未来的语音合成技术提供了新的方向。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG: 优化面向文本生成视频的视频字幕", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "文本-视频生成（T2V）领域近期的研究强调了高质量视频-文本对在训练能够生成连贯且与指令对齐的视频模型中的关键作用。然而，针对T2V训练优化视频字幕的策略仍然很少被探索。现有工作主要集中在如何生成高质量的字幕，但少有研究关注字幕设计如何直接优化对视频生成性能的影响。", "innovation": "本文提出了一种专门为T2V训练设计的全面字幕优化框架，名为VC4VG。该框架首先从T2V的角度分析字幕内容，将其划分为多个维度。在此基础上，提出了一种基于原理的字幕设计方法。为了支持评估，构建了带有多维度、细粒度和需求级度量标准的新基准VC4VG-Bench。实验结果表明，改进后的字幕质量与视频生成性能之间存在强烈的正相关，验证了该方法的有效性。此外，所有基准工具和代码已开源，以促进进一步的研究。", "conclusion": "通过对视频字幕的优化设计，可以显著提高文本生成视频的性能。所提出的VC4VG框架和评估基准为该领域提供了新的解决方案和支持工具，有利于推动T2V生成技术的发展。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24285", "html_url": "https://arxiv.org/abs/2510.24285", "title": "ViPER：赋能视觉感知能力自我进化的视觉语言模型", "title_en": "ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model", "authors": "Juntian Zhang,Song Jin,Chuanqi Cheng,Yuhan Liu,Yankai Lin,Xun Zhang,Yufei Zhang,Fei Jiang,Guojun Yin,Wei Lin,Rui Yan", "background": "视觉语言模型（VLMs）在实际应用中受限于其精细视觉感知能力的有限容量，这导致了关键瓶颈。现有方法如监督微调（SFT）和强化微调（RFT）分别存在一般能力下降和视觉感知优先不足的问题，使得解决这一问题颇具挑战性。因此，迫切需要提出新的方法和框架来改进视觉感知能力。", "innovation": "该论文提出了一种新颖的两阶段任务，将视觉感知学习结构化为逐步精细的过程。基于此任务模型，开发了ViPER，这是一种自我引导的框架，通过自我批评和自我预测实现迭代进化。ViPER融合了图像级和实例级重构，并采用了两阶段的强化学习策略，建立了闭环训练模式，利用内部合成数据直接增强感知能力。通过将ViPER应用于Qwen2.5-VL家族，生成了Qwen-Viper系列，显示出在多种任务中的显著提升，并证明了生成与理解之间的相互促进关系，从而推动了自适应和强大的视觉语言模型的发展", "conclusion": "Qwen-Viper系列在七个全面基准测试中有1.7%的平均性能提升，在细粒度感知方面甚至高达6.0%，在不同视觉语言场景中持续表现出卓越性能，同时保持了通用性。此外，ViPER还证明了生成和理解之间的相互作用，为开发更加自主和强大的视觉语言模型提供了实证依据。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24442", "html_url": "https://arxiv.org/abs/2510.24442", "title": "Law in Silico: 使用基于大语言模型的代理来模拟法律社会", "title_en": "Law in Silico: Simulating Legal Society with LLM-Based Agents", "authors": "Yiding Wang,Yuxuan Chen,Fanxu Meng,Xifan Chen,Xiaolei Yang,Muhan Zhang", "background": "由于实际的法律实验往往成本高昂或不可行，使用人工智能系统模拟法律社会提供了一种有效的替代方案，以验证和开发法律理论，以及支持法律管理。现有的研究中，大规模语言模型（LLMs）以其世界知识和角色扮演能力成为模拟法律社会的基础的强有力候选者。然而，将LLMs应用于模拟法律系统尚未得到广泛研究。", "innovation": "本文介绍了‘Law in Silico’，这是一种基于LLM的代理框架，用于模拟涉及个体决策和立法、司法和执行等机构机制的法律场景。通过将模拟的犯罪率与实际数据进行比较，研究证明基于LLM的代理可以重现宏观层面的犯罪趋势，并提供与实际情况相符的见解。同时，微观层面的模拟显示，功能完善、透明和适应性强的法律制度可以更好地保护弱势个体的权利。", "conclusion": "研究结果表明，基于LLM的法律模拟代理可以作为有效的工具来揭示法律系统如何作用于整体社会行为，以及如何保护弱势群体的权利。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24358", "html_url": "https://arxiv.org/abs/2510.24358", "title": "通过代理驱动的标注和评估自动基准测试LLM代码代理", "title_en": "Automatically Benchmarking LLM Code Agents through Agent-Driven Annotation and Evaluation", "authors": "Lingyue Fu,Bolun Zhang,Hao Guan,Yaoming Zhu,Lin Qiu,Weiwen Liu,Xuezhi Cao,Xunliang Cai,Weinan Zhang,Yong Yu", "background": "近年来，代码代理的进步使得在项目级别实现自动化软件开发成为可能，这得益于大型语言模型（LLMs）和广泛采用的工具的支持。现有代码代理评估基准面临着两个主要限制：标注成本高且需要专业知识，以及主要依赖单元测试的刚性评估指标。", "innovation": "本文提出了一种代理驱动的基准构建管道，利用人类监督高效生成多样且具有挑战性的项目级任务。基于此方法，引入了PRDBench基准，包含50个跨20个领域的现实Python项目，每个项目都有结构化的PRD需求、全面的评估标准和参考实现。PRDBench具有丰富的数据来源、高任务复杂度和灵活的评估指标。还采用代理作为裁判的范式来评估代理输出，从而能够评价超出单元测试的各种测试类型。实验结果表明，PRDBench在评估代码代理和评估代理的能力方面有效，并为标注和评估提供了一个可扩展且稳健的框架。", "conclusion": "本文通过PRDBench为代码代理和评估代理提供了一个可扩展且稳健的评估基准，展示了其在自动化软件开发中的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.13397", "html_url": "https://arxiv.org/abs/2404.13397", "title": "检索增强生成式的关系抽取", "title_en": "Retrieval-Augmented Generation-based Relation Extraction", "authors": "Sefika Efeoglu,Adrian Paschke", "background": "信息抽取（IE）将无结构文本数据转换为结构化格式，依靠实体和关系抽取方法。关系抽取在这一框架中扮演关键角色。尽管存在多种关系抽取技术，但它们的效果高度依赖于标记数据和大量计算资源。大型语言模型（LLMs）作为应对这些挑战的潜在解决方案，但也存在生成幻觉响应的问题。", "innovation": "本文提出了检索增强生成式关系抽取（RAG4RE）方法，通过利用不同的LLMs来增强关系抽取任务的性能。研究使用TACRED、TACREV、Re-TACRED和SemEval RE数据集作为评估基准，展示了RAG4RE在Flan T5、Llama2和Mistral等重要LLMs上的优越性能，特别是在TACRED数据集及其变体中的效果显著。", "conclusion": "研究结果表明，RAG4RE方法在关系抽取任务中超越了仅基于LLMs的传统方法，特别是在TACRED等数据集中的表现尤为突出。此外，与之前的RE方法相比，RAG4RE在TACRED和TACREV数据集上的性能也表现出显著优势，突显了该方法在自然语言处理中关系抽取任务的潜力和有效性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24411", "html_url": "https://arxiv.org/abs/2510.24411", "title": "OS-Sentinel: 通过混合验证提升真实工作流程中移动GUI代理的安全性", "title_en": "OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows", "authors": "Qiushi Sun,Mukai Li,Zhoumianze Liu,Zhihui Xie,Fangzhi Xu,Zhangyue Yin,Kanzhi Cheng,Zehao Li,Zichen Ding,Qi Liu,Zhiyong Wu,Zhuosheng Zhang,Ben Kao,Lingpeng Kong", "background": "使用视觉语言模型（VLMs）驱动的计算机代理在操作移动平台等数字环境方面展现了类人的能力。尽管这些代理在推动数字自动化方面具有巨大潜力，但它们进行系统滥用和隐私泄露等不安全操作的风险正引发严重担忧。在移动环境的广阔复杂运行空间中检测这些安全问题是一项艰巨的挑战，目前严重缺乏相关研究基础。为建立移动代理安全性研究的基础，引入了MobileRisk-Live，这是一种动态的沙箱环境，并且包含了一个由现实轨迹及其精细微粒注释组成的安全性检测基准。基于此，提出了一种名为OS-Sentinel的新型混合检测框架，该框架将形式验证器与基于VLM的情境判断器结合，用于检测系统级显式违规行为和评估情境风险及代理行动。实验证明，OS-Sentinel在多个指标上实现了10%-30%的改进。进一步的分析提供了关键的见解，促进了更安全可靠的自主移动代理的开发。", "innovation": "OS-Sentinel提供了一种混合的安全检测框架，在系统级违规检测和情境风险评估方面结合了形式验证器和基于VLM的情境判断器。此外，通过引入MobileRisk-Live，为移动代理研究建立了新的安全检测基准。实验结果显示，OS-Sentinel在多个指标上超越现有方法，实现显著改进。", "conclusion": "OS-Sentinel通过结合形式验证和基于VLM的情境判断，显著提高了移动GUI代理的安全性，为未来开发更安全、更可靠的自主移动代理提供了重要支持。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.17401", "html_url": "https://arxiv.org/abs/2404.17401", "title": "语言模型中地理失真的评估", "title_en": "Evaluation of Geographical Distortions in Language Models", "authors": "Rémy Decoupes,Roberto Interdonato,Mathieu Roche,Maguelonne Teisseire,Sarah Valentin", "background": "当前，语言模型已成为提高许多专业任务（如写作、编程或学习）效率的重要工具。因此，有必要识别其固有的偏见。在自然语言处理领域，已有五个来源的偏见被广泛确认：数据、标记、表示、模型和研究设计。本文专注于地理知识相关的偏见。研究聚焦于语言模型在描绘空间信息方面存在误导性，从而导致地理距离表示失真。通过四种指标来评估这些失真，并使用十种广泛使用的语言模型进行实验，揭示了需要警惕并纠正语言模型中的空间偏见，以确保准确和公正的表示。", "innovation": "研究引入了四种评估语言模型中地理失真的指标，通过将地理距离与语义距离进行对比来探索语言模型与地理之间的联系，针对性地评估并揭示了不同语言模型在地理表示上的差异。", "conclusion": "研究所揭示的结果强调了检查和纠正语言模型中的空间偏见的重要性，以确保其准确和公正地表示地理信息。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24693", "html_url": "https://arxiv.org/abs/2510.24693", "title": "STAR-Bench：探查作为音频4D智能的深层时空推理", "title_en": "STAR-Bench: Probing Deep Spatio-Temporal Reasoning as Audio 4D Intelligence", "authors": "Zihan Liu,Zhikang Niu,Qiuyang Xiao,Zhisheng Zheng,Ruoqi Yuan,Yuhang Zang,Yuhang Cao,Xiaoyi Dong,Jianze Liang,Xie Chen,Leilei Sun,Dahua Lin,Jiaqi Wang", "background": "尽管多模态大型语言模型和大型音频-语言模型取得了快速进展，现有的音频基准测试主要集中在可以从文本描述中恢复的语义方面，从而掩盖了精细感知推理方面的不足。本文定义了音频4D智能，即在时间和三维空间上对声音动力学进行推理的能力，并提出了STAR-Bench来衡量这一点。STAR-Bench结合了基础声学感知设置（绝对和相对状态下的六个属性）和综合时空推理设置，后者包括连续和离散过程的片段重排序，以及从静态定位到多源关系再到动态轨迹的空间任务。", "innovation": "本文遵循一个四个阶段的过程来确保高质量样本的数据整理管道，包括机器生成和物理模拟音频的大规模数据集，并且进行了符合人类表现的人工注释和最终选择。STAR-Bench区分了纯文本回答与其他基准的细微差别，如仅使用短语回答略有降低准确性，STAR-Bench则造成了较大的降低（时间上-31.5%，空间上-35.2%），这表明其关注于难以用语言描述的线索。评估19个模型显示出与人类和能力层次上的巨大差距：封闭源模型在精细感知方面受阻，而开源模型则在感知、知识和推理方面滞后。", "conclusion": "STAR-Bench 为未来模型的发展提供了关键见解，并阐明了开发具有更坚实对物理世界理解模型的前进道路。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24514", "html_url": "https://arxiv.org/abs/2510.24514", "title": "Latent Sketchpad: 通过草图刻画视觉思考以激发多模态推理在MLLM中的应用", "title_en": "Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs", "authors": "Huanyu Zhang,Wenshan Wu,Chengzu Li,Ning Shang,Yan Xia,Yangyu Huang,Yifan Zhang,Li Dong,Zhang Zhang,Liang Wang,Tieniu Tan,Furu Wei", "background": "虽然多模态大语言模型（MLLMs）在视觉理解方面表现出色，但在需要视觉规划和想象的复杂场景中经常遇到困难。传统的MLLMs的内部视觉表示主要局限于感知理解，缺乏支持生成视觉思考的能力。鉴于人类如何通过绘画来发展和交流想法，作者提出了一种名为Latent Sketchpad的新框架，旨在增强MLLMs的视觉生成能力，同时保持推理能力。框架通过将视觉生成直接融入其原生自回归推理过程，使模型能够交替进行文本推理和视觉隐变量生成，并通过预训练的草图解码器将这些隐变量转换为可由人类理解的图像，从而实现这一目标。研究表明，该框架在MazePlanning数据集上的性能与基线模型相当甚至更优，并且可以在不同类型的大模型中泛化，如Gemma3和Qwen2.5-VL。这项工作为更丰富的跨模态交互和更广泛的应用提供了新的机会。", "innovation": "提出的Latent Sketchpad框架旨在提升MLLMs的生成视觉思考的能力，将其引入到原生的自回归推理过程中，既保持了推理能力又允许模型在文本推理和视觉隐变量生成之间交替进行。框架包括一个上下文感知的视觉头，用于自回归地生成视觉表示，并通过预训练的草图解码器将其转换为可由人类理解的图像。这种新的交互方式有望开启更多样化的跨模态交互和更广泛的应用场景。", "conclusion": "通过将文本推理扩展到视觉思考，该框架展示了在训练的MLLMs基础上增强功能的可能性，并为更多的跨模态交互和实际应用提供了新的途径。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.11390", "html_url": "https://arxiv.org/abs/2409.11390", "title": "说是谁？关于制焦点的高效零样本标注", "title_en": "Says Who? Effective Zero-Shot Annotation of Focalization", "authors": "Rebecca M. M. Hicke,Yuri Bizzoni,Pascale Feldkamp,Ross Deans Kristensen-McLachlan", "background": "制焦点描述了叙述信息的访问方式，基于叙述者所知的知识限缩或控制。这一概念通过广泛的词汇和语法特征编码，并且其解读依赖于读者的理解。即使是受过训练的注释员在标记时也经常出现分歧，这表明该任务兼具质性和计算上的挑战性。本文测试了几种现代大型语言模型（LLM）和两个基线模型在为叙述片段标注制焦点方面的表现。尽管任务非常具有挑战性，但我们发现这些模型的表现与受过训练的人类注释员相当，GPT-4o 达到了84.79%的平均F1值。此外，我们证明了GPT 家族模型提供的对数概率输出反映了标注特定片段的难度。最后，我们对十六本斯蒂芬·金的小说进行了案例研究，展示了这种方法在计算文学研究中的应用价值及其带来的重要见解。", "innovation": "本文尝试利用现代大型语言模型（LLM）进行零样本标注，特别关注制焦点这一概念。研究发现，尽管任务极度复杂，但这些模型在性能上与专业的人类注释员相当，提供了一种新的标注方法和潜在的研究工具。同时，通过分析模型的对数概率输出，揭示了片段难度与标注结果之间的关系，这对进一步研究有着重要意义。", "conclusion": "本文通过案例研究展示了基于大型语言模型对制焦点进行标注的有效性和可行性。这种方法不仅可以提高标注效率，还能提供深入的分析和见解，尤其是在计算文学研究领域，为大规模分析提供了新的武器。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.12679", "html_url": "https://arxiv.org/abs/2412.12679", "title": "增强文档级机器生成内容检测的 discourse 功能", "title_en": "Discourse Features Enhance Detection of Document-Level Machine-Generated Content", "authors": "Yupei Li,Manuel Milling,Lucia Specia,Björn W. Schuller", "background": "高质量的API使大型语言模型生成的内容变得普遍，但也带来了学术剽窃和虚假信息传播等挑战。现有检测方法大多侧重于表面信息，忽视了隐含和结构特征，容易被表面模式欺骗，尤其是在长文本和再加工文本中。", "innovation": "引入了新的方法和数据集，包括使用GPT和DIPPER生成的paraLFQA和paraWP数据集。提出了DTransformer模型，通过PDTB预处理进行话语分析来编码结构特征，相比现有最佳方法，在paraLFQA上提高了15.5%，在paraWP上提高了4%，在M4上提高了1.5%。", "conclusion": "通过增强对话语功能的考虑，模型在检测机器生成的文档内容方面取得了显著改进。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.20445", "html_url": "https://arxiv.org/abs/2410.20445", "title": "TrajAgent：通过大模型和小模型协作进行轨迹建模的LLM-Agent框架", "title_en": "TrajAgent: An LLM-Agent Framework for Trajectory Modeling via Large-and-Small Model Collaboration", "authors": "Yuwei Du,Jie Feng,Jie Zhao,Yong Li", "background": "轨迹建模涉及轨迹数据模式挖掘和未来预测，广泛应用于生活服务、城市交通和公共管理等领域。尽管提出了许多方法来解决轨迹建模中的特定问题，但由于数据异质性和轨迹任务的多样性，有效的和可靠的轨迹建模对于非专家也同样具有挑战性。目前，存在的问题包括提高自动化水平和实现不同数据集的有效建模。", "innovation": "本文提出了一种名为TrajAgent的框架，该框架利用大型语言模型作为动力，通过自动化方式实现了稳健高效的轨迹建模。TrajAgent首先开发了UniEnv，一种具有统一数据和模型接口的执行环境，支持各种模型的执行和训练。此外，通过引入大模型代理与小型专业模型之间的合作学习机制，TrajAgent在整个框架中的性能得到了提升。实验结果表明，与其他基线方法相比，TrajAgent在自动轨迹建模中的性能提高了2.38%-69.91%。", "conclusion": "大量的实验证明，TrajAgent在自动轨迹建模方面表现出色，有效提高了性能，并且其代码和数据可以在此链接访问。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.19477", "html_url": "https://arxiv.org/abs/2411.19477", "title": "可验证的大语言模型测试时计算的缩放定律", "title_en": "Provable Scaling Laws for the Test-Time Compute of Large Language Models", "authors": "Yanxi Chen,Xuchen Pan,Yaliang Li,Bolin Ding,Jingren Zhou", "background": "该研究旨在开发适用于大语言模型（LLMs）测试计算的简单、高效且能够提供理论保证的算法。背景信息强调了LLMs在处理大规模复杂问题时面临的计算挑战，以及现有解决方案的不足之处，特别是缺乏有效的大规模缩放性能验证。", "innovation": "论文提出了两个算法，即两阶段淘汰赛风格算法和两阶段联盟风格算法。首先，淘汰赛风格算法通过生成多个候选解决方案，然后进行淘汰赛汇总来生成最终输出。联盟风格算法则是通过对比每个候选方案相对于多个对手的表现来评估。无论采用哪种算法，只要假设模型有一定概率生成正确解并且在正确解和错误解之间表现更好，它们都能证明算法的失败概率会随着测试计算资源的增加以指数或幂律形式减小。此外，这些算法只需要黑盒LLM，无需其他组件（如验证器或奖励模型），便于实际应用和易于针对不同任务进行调整。", "conclusion": "通过广泛的实验验证了提出的理论，并展示了两种算法在所有测试模型和数据集上的出色缩放特性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.15189", "html_url": "https://arxiv.org/abs/2412.15189", "title": "Face the Facts! Evaluating RAG-based Fact-checking Pipelines in Realistic Settings", "title_en": "Face the Facts! Evaluating RAG-based Fact-checking Pipelines in Realistic Settings", "authors": "Daniel Russo,Stefano Menini,Jacopo Staiano,Marco Guerini", "background": "近年来，自然语言处理和生成系统显示出补充和简化专业事实核查人员繁琐工作的潜力。本文在基于检索增强生成（RAG）范式的自动事实核查现有最先进的流水线限制的基础上，提出了一种新方法。研究在生成判语（即，关于声明真实性的简短文本讨论）时，评估了RAG方法在复杂陈述和多样但可靠的知识库上的表现。", "innovation": "本研究针对基于RAG的方法进行多场景的基准测试，重点关注LARGE语言模型在检索方面的表现优于其他检索技术，同时指出大模型在判语准确性上表现突出，小模型在上下文一致性方面表现更好。研究对比了零样本和单样本方法对信息性和情感对齐的影响。", "conclusion": "RAG方法在多种复杂和多样化的现实场景中的表现复杂，不同规模的模型在不同方面表现出不同的优势，未来需进一步优化以满足多样化和复杂化的实际需求。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.19467", "html_url": "https://arxiv.org/abs/2504.19467", "title": "BRIDGE: 评估大型语言模型在理解现实临床文本中的表现", "title_en": "BRIDGE: Benchmarking Large Language Models for Understanding Real-world Clinical Practice Text", "authors": "Jiageng Wu,Bowen Gu,Ren Zhou,Kevin Xie,Doug Snyder,Yixing Jiang,Valentina Carducci,Richard Wyss,Rishi J Desai,Emily Alsentzer,Leo Anthony Celi,Adam Rodman,Sebastian Schneeweiss,Jonathan H. Chen,Santiago Romero-Brufau,Kueiyu Joshua Lin,Jie Yang", "background": "大型语言模型（LLMs）在医疗应用中具有巨大潜力，并且正在迅速发展，新的模型以加速的速度被发布。然而，它们在大规模真实世界数据（如电子健康记录EHRs）上的基准测试仍然是关键需求，因为临床决策直接依靠这些数据源，但当前的评估仍然有限。大多数现有基准依赖于医学考试风格的问题或PubMed衍生的文本，未能捕捉到现实临床数据的复杂性。其他基准则集中在特定的应用场景上，这限制了它们在更广泛的临床用途中的通用性。", "innovation": "我们提出了BRIDGE，一个涵盖九种语言共计87项任务的综合多语言基准，这些任务来自涵盖六项临床阶段和20项代表性应用的真实临床数据源。我们系统性地评估了95个LLM（包括DeepSeek-R1、GPT-4o、Gemini系列和Qwen3系列），观察到了不同模型规模、语言、自然语言处理任务以及临床专科领域之间显著的性能差异。值得注意的是，我们的结果显示开源LLM可以达到与专有模型相当的表现，基于旧架构的医疗精细化调参LLM往往比更新的一般化模型表现更差。BRIDGE及其相应的排行榜为新LLM的发展和评估提供了一个基础资源和独特参考。", "conclusion": "BRIDGE和相应的排行榜为现实临床文本理解中新LLM的发展和评估提供了基础资源和独特参考。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.06560", "html_url": "https://arxiv.org/abs/2504.06560", "title": "NeedleInATable：探索大型语言模型处理长结构化表格的长上下文能力", "title_en": "NeedleInATable: Exploring Long-Context Capability of Large Language Models towards Long-Structured Tables", "authors": "Lanrui Wang,Mingyu Zheng,Hongyin Tang,Zheng Lin,Yanan Cao,Jingang Wang,Xunliang Cai,Weiping Wang", "background": "处理结构化表格数据，尤其是大型且复杂的表格，是大型语言模型（LLMs）的一个基本但具有挑战性的任务。现有的长上下文基准如Needle-in-a-Haystack主要关注无序文本，忽视了多样化的结构化表格的挑战。此外，先前的表格基准主要考虑需要高级推理能力的下游任务，而忽略了模型对单个表格单元的细微感知，这对于实际的、健壮的基于LLM的表格应用至关重要。", "innovation": "为了填补这一差距，我们提出了一个新长上下文表格基准NeedleInATable（NIAT），它将每个表格单元视为一个‘针’，要求模型根据单元格位置或查询问题提取目标单元格。我们的全面评估显示，流行的下游表格任务与简单的NIAT任务之间存在显著的性能差距，表明它们可能依赖于特定数据集的相关性或捷径以获得更好的基准结果，但缺乏真正的结构化表格的长上下文理解能力。此外，我们证明使用合成的NIAT训练数据可以有效提高NIAT任务和下游表格任务的表现，验证了NIAT能力对LLM真正理解表格的重要性。", "conclusion": "我们的全面评估结果显示，流行的下游表格任务与NIAT任务之间存在显著的性能差距，表明这些模型可能依赖于特定数据集的相关性或捷径来获得更好的基准结果，但缺乏真正依赖于长上下文理解结构化表格的能力。使用合成的NIAT训练数据可以有效提高表现，这验证了NIAT能力对LLM真正理解表格的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.20039", "html_url": "https://arxiv.org/abs/2504.20039", "title": "AutoJudge：无需手动注解的解码判断", "title_en": "AutoJudge: Judge Decoding Without Manual Annotation", "authors": "Roman Garipov,Fedor Velikonivtsev,Ivan Ermakov,Ruslan Svirschevski,Vage Egiazarian,Max Ryabinin", "background": "随着大语言模型（LLM）的快速发展，后端推理速度成为了新的挑战。传统的解码方法需要逐个匹配目标模型的输出分布，这在保证高质量响应的同时增加了推理时间。为了提高推理速度，研究者们尝试了无损推测性解码（Speculative Decoding），但这种方法仍旧需要精细的匹配，从而影响了速度。\n", "innovation": "本文提出了一种名为AutoJudge的新方法，通过任务特定的推测性损失解码来加速大语言模型推理。该方法通过半贪婪搜索算法与轻量级分类器相结合，可以在不降低最终答案质量的前提下，快速生成“不重要的”令牌。这种方法仅需现有的LLM嵌入来预测哪些解码不匹配可以在推理时间被安全地接受，而不需要手动标注或复杂的专门配置。\n", "conclusion": "AutoJudge在数学推理和编程基准测试中实现了显著的速度提升，代价是轻微的准确率下降。在GSM8k测试集上，与推测性解码相比，AutoJudge达到了约2倍的加速，准确率下降不超过1%。在LiveCodeBench基准测试中，AutoJudge自动检测编程特定的重要令牌，在每推测周期接受至少25个令牌的情况下，Pass@1准确率下降2%。AutoJudge方法无需人工标注且易于集成到现代的LLM推理框架中。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14617", "html_url": "https://arxiv.org/abs/2505.14617", "title": "推理模型中的霍桑效应：评估和操控测试意识", "title_en": "The Hawthorne Effect in Reasoning Models: Evaluating and Steering Test Awareness", "authors": "Sahar Abdelnabi,Ahmed Salem", "background": "当大型语言模型（LLM）意识到自己正在被评估时，它们的行为可能会发生变化，这种现象称为‘测试意识’。这种变化可能导致模型优化以通过测试或执行有害指令时更加顺从，特别是在没有实际后果的情况下。本文通过定量研究探讨‘测试意识’如何影响模型行为，特别是其在安全性任务中的性能。", "innovation": "本文提出了第一个白盒探查框架，该框架能够线性识别与‘测试意识’相关的激活，并引导模型增加或减少这种意识，同时监控下游性能。该方法应用于不同最先进开放权重推理LLM，涵盖了现实和假设任务（代表测试或模拟）。研究结果表明，‘测试意识’显著影响安全性对齐（如遵守有害请求和遵守刻板印象），具体效果因模型而异。", "conclusion": "通过提供对这一潜在影响的控制，我们的研究旨在提供一种压力测试机制，并增加我们如何进行安全性评估的信任度。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00481", "html_url": "https://arxiv.org/abs/2506.00481", "title": "PVP: 一个包含说服策略、观众特征和说服评分的个性化视觉说服图像数据集", "title_en": "PVP: An Image Dataset for Personalized Visual Persuasion with Persuasion Strategies, Viewer Characteristics, and Persuasiveness Ratings", "authors": "Junseo Kim,Jongwook Han,Dongmin Choi,Jongwook Yoon,Eun-Ju Lee,Yohan Jo", "background": "视觉说服是通过视觉元素影响认知和行为的重要领域，尤其在广告和政治传播中。随着人工智能的发展，自动生成个性化说服图像成为可能，但是缺乏综合性的数据集来连接图像的说服力与评价者的个人信息，成为技术进步的瓶颈。", "innovation": "该论文通过发布个人视觉说服（PVP）数据集，包含了28,454幅说服图像、596条信息和9种说服策略，以及2,521名人类标注者的说服评分和个人特征（如性格特质和价值观），提出了一种新颖的数据集，旨在促进个性化视觉说服技术的发展。", "conclusion": "实验表明，整合心理学特征能够提高说服图像的生成和评估效果，为个性化视觉说服提供了有价值的认识。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.01381", "html_url": "https://arxiv.org/abs/2506.01381", "title": "AdaRewriter：通过测试时适应解锁基于提示的对话查询重写的力量", "title_en": "AdaRewriter: Unleashing the Power of Prompting-based Conversational Query Reformulation via Test-Time Adaptation", "authors": "Yilong Lai,Jialong Wu,Zhenglin Wang,Deyu Zhou", "background": "基于提示的对话查询重写作为一种强大的对话搜索方法，能够将模糊的用户查询转换为独立的搜索查询，显示了显著的潜在扩展能力。然而，先前的调整方法和适应方法在利用其好处方面仍存局限。", "innovation": "提出了一种新的框架AdaRewriter，通过测试时调整使用结果监督的奖励模型进行查询重写。它通过对比排序损失训练了一个轻量级的奖励模型，在推理过程选择最有可能的重写结果，且能在黑盒系统中有效运行，包括商用LLM API。", "conclusion": "实验表明，AdaRewriter在五个对话搜索数据集上显著优于现有方法，展示了测试时调整在对话查询重写中的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.06964", "html_url": "https://arxiv.org/abs/2506.06964", "title": "基于奖励加权微调的离线强化学习对话优化", "title_en": "Offline RL by Reward-Weighted Fine-Tuning for Conversation Optimization", "authors": "Subhojyoti Mukherjee,Viet Dac Lai,Raghavendra Addanki,Ryan Rossi,Seunghyun Yoon,Trung Bui,Anup Rao,Jayakumar Subramanian,Branislav Kveton", "background": "离线强化学习(Offline RL)是一种使用之前收集的状态轨迹和奖励数据来学习策略的RL变体。以往的方法如使用监督微调(SFT)和直接偏好优化等，存在额外的超参数设置，并且不直接优化奖励。", "innovation": "将离线RL问题重新表述为奖励加权微调问题，并利用了与监督微调类似的技术。研究应用于短周期问题回复策略的学习，该方法在对比现有的SFT和直接偏好优化方法中展现出了显著优势，提高了优化奖励和语言质量。", "conclusion": "尽管现有基于SFT和直接偏好优化的方法在超参数设置和直接奖励优化上有所不足，但提出的方法在实际应用中取得了显著的提升，证明了相对传统方法的优势。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17100", "html_url": "https://arxiv.org/abs/2505.17100", "title": "任何大型语言模型都可以成为可靠的裁判：基于推理的偏见检测器去偏", "title_en": "Any Large Language Model Can Be a Reliable Judge: Debiasing with a Reasoning-based Bias Detector", "authors": "Haoyan Yang,Runxue Bao,Cao Xiao,Jun Ma,Parminder Bhatia,Shangqian Gao,Taha Kass-Hout", "background": "LLM-as-a-Judge作为一种自动评估生成输出的有前景工具，但由于评价员潜在偏见的影响，其可靠性常常受到质疑。现有的减轻这些偏见的努力面临关键限制：上下文学习方法无法解决由于评价员自我反思能力有限导致的根植偏见，而微调方法不适用于所有类型的评价员，尤其是闭源模型。", "innovation": "论文提出了一种基于推理的偏见检测器（RBD），这是一种插件模块，能够识别偏见评价并生成结构化推理以引导评价员自我纠正。不同于直接修改评价员本身，RBD在外部分离工作，并通过迭代过程进行偏见检测和反馈驱动的修订。为了支持RBD的开发，设计了一个完整的管道，包括带有偏见的数据集构建、监督收集、被知识萃取和筛选的推理导向的微调以及与LLM评估器的集成。实验结果表明，在8种类型的大型语言模型评估器上评价4种偏见类型（冗余度、位置、随大流、情绪）的RBD具有强大的效果。", "conclusion": "实验结果表明，RBD模型在所有规模下都表现出一致的性能提升，其在包括评价准确性和一致性在内的多个指标上超过了基于提示的基线和微调的对手。此外，进一步的实验显示RBD具有强大的泛化能力和高效性，适用于各种偏见类型和领域。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2405.07883", "html_url": "https://arxiv.org/abs/2405.07883", "title": "Zero-Shot Tokenizer Transfer", "title_en": "Zero-Shot Tokenizer Transfer", "authors": "Benjamin Minixhofer,Edoardo Maria Ponti,Ivan Vulić", "background": "语言模型（LM）依赖于分词器，该分词器将原始文本映射为词汇项（标记）的序列。这种方法限制了模型的灵活性。例如，主要在英语上训练的模型在其他自然语言和编程语言上仍然可能表现良好，但由于它们使用的是以英语为中心的分词器而导致效率大幅下降。这表明，为了弥补这一限制，研究人员希望能够快速且不损失性能地替换原来的分词器为任意分词器。因此，本研究提出了一个新的问题：零样本分词器转移（ZeTT）。零样本分词器转移的核心挑战是为新分词器的词汇表中的标记找到嵌入。之前对于初始化嵌入的启发式方法在ZeTT场景中表现较差，因此提出了一种新的解决方案：训练一个基于输入分词器预测相应嵌入的超网络。该研究实验证明此方法在不同架构的编码器和解码器LLM中都能泛化，同时保持与原始模型相近的性能，显著减少了标记化序列的长度。进一步的实验表明，通过在少于10亿标记上进行额外训练，可以迅速缩小现有的性能差距。最后，研究还发现在基础模型上训练的ZeTT超网络同样可以应用到微调后的变体中，而不需要额外的训练。结果表明，这一工作朝着从模型中分离分词器迈出了实质性的一步。", "innovation": "研究提出了零样本分词器转移（ZeTT）这一新问题，并提出了一种基于输入分词器预测相应嵌入的超网络解决方案。该方法能够快速且不损失性能地替换原始分词器，并且在不同模型架构的LLM中都表现出良好的泛化能力，同时减少了标记化序列的长度，显著提升模型的灵活性和性能。此外，通过在有限标记上进行额外训练，可以迅速缩小与基础模型之间的性能差距。最后，该超网络也可以应用于微调后的变体模型中，而不需要额外的训练。", "conclusion": "研究的主要结论是，通过引入零样本分词器转移（ZeTT）和提出基于输入分词器预测相应嵌入的超网络解决方案，推动了语言模型从其分词器的解耦。这种方法在多个任务中取得了接近基础模型的性能，同时大幅减少了标记化序列的长度，并且可以通过少量额外训练进一步提升性能。此外，还可以将这种超网络应用于微调后的变体模型中，表明这种方法具有广泛的适用性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21837", "html_url": "https://arxiv.org/abs/2509.21837", "title": "语义一致同意推动高效的开放性大型语言模型级联", "title_en": "Semantic Agreement Enables Efficient Open-Ended LLM Cascades", "authors": "Duncan Soiffer,Steven Kolawole,Virginia Smith", "background": "级联系统通过将计算请求分发到较小的模型并在必要时才转向较大模型来平衡成本和质量，但它们在开放生成文本时面临一个根本挑战：在生成质量呈连续光谱分布的情况下，如何确定输出的可靠性，通常会有多个有效的响应版本。", "innovation": "提出了语义一致同意——一种基于意义层面的合议作为训练无信号以促进可靠的延期的方法。研究表明，当多样化的模型输出在语义上一致时，其合议比令牌级的信心更强大的可靠信号。这种方法适用于从500M到70B参数的各种规模的模型，证明了语义级联可以在降低40%的成本同时保持与目标模型质量相当，并减少延迟高达60%。", "conclusion": "该方法不需要访问模型的内部信息、可以在黑盒API中工作，并且在模型更新中保持稳健，因此为实际部署中的大型语言模型提供了一个实用的基础线方法。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00789", "html_url": "https://arxiv.org/abs/2506.00789", "title": "RARE: 评估检索增强生成系统的检索感知鲁棒性", "title_en": "RARE: Retrieval-Aware Robustness Evaluation for Retrieval-Augmented Generation Systems", "authors": "Yixiao Zeng,Tianyu Cao,Danqing Wang,Xinran Zhao,Zimeng Qiu,Morteza Ziyadi,Tongshuang Wu,Lei Li", "background": "当前的检索增强生成（RAG）系统在回答中的近期性和事实性有所改进，但现有评价很少测试这些系统在处理真实世界的噪声、内部和外部检索上下文之间的冲突或快速变化的事实方面的表现。RARE 是一个统一框架和大规模基准，旨在对查询和文档扰动在动态、时间敏感的语料库上的鲁棒性进行综合测试。RARE 引入了自动从自定义语料库提取单一和多跳关系，并生成多级问题集而不需人工干预的知识图谱驱动合成管道（RARE-Get）。利用此管道构建了涵盖527份专家级时间敏感的金融、经济和政策文档以及48295个问题的RARE-Set数据集，这些问题的分布随着基础来源的变化而变化。为了量化鲁棒性，RARE 定义了检索条件下的鲁棒性度量标准（RARE-Met），以捕捉模型在查询、文档或实际检索结果系统性改变时保持正确性或恢复的能力。研究表明，RAG 系统对扰动表现出意外的敏感，并且在所有领域中的一跳查询中表现出了比多跳查询更低的鲁棒性。", "innovation": "RARE 提出了一种统一框架和大规模基准，旨在综合测试查询和文档扰动在动态、时间敏感的语料库上的鲁棒性。特别地，RARE-Get 管道可以自动提取单一和多跳关系，并生成多级问题集而无需人工干预，从而构建了涵盖大量时间敏感文档的问题数据集。此外，RARE 定义了鲁棒性度量标准来量化模型在面对查询、文档或实际检索结果系统性改变时的稳定性。", "conclusion": "RAG 系统对扰动显示出意外的敏感性，在所有领域的一跳查询中表现出比多跳查询更低的鲁棒性。因此，RARE 强调了对检索增强生成系统的鲁棒性进行全面评估的重要性，这有助于改进模型的实时信息处理和事实准确性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.22699", "html_url": "https://arxiv.org/abs/2509.22699", "title": "你在确定吗？通过不确定性测量内容审核模型的偏见", "title_en": "Are you sure? Measuring models bias in content moderation through uncertainty", "authors": "Alessandra Urbinati,Mirko Lai,Simona Frenda,Marco Antonio Stranisci", "background": "自动内容审核对于确保社交媒体的安全至关重要。基于语言模型的分类器被广泛采用，但它们存在种族和社会偏见的问题。尽管已经开发了一些资源和基准数据集来解决这些问题，但在内容审核模型的公平性测量方面仍然是一个开放的问题。", "innovation": "本文提出了一种无监督的方法，通过计算不确定性来评估模型在分类标注来自弱势群体的信息时的表现，从而分析模型对女性和非白人标注者的偏见程度。这种方法使用混淆预测技术计算的不确定性作为公平性测量的代理，评估了11种模型的偏见，并观察其与基于性能的度量（如F1分数）的差异。", "conclusion": "研究结果表明，一些预训练模型即使在预测准确率很高时，缺乏足够的信心度。通过测量模型的信心，可以发现预训练模型中哪些标注群体得到更好代表，并能在模型实际使用前带动去偏工作。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15355", "html_url": "https://arxiv.org/abs/2506.15355", "title": "SANSKRITI: 评估语言模型印度文化知识的综合基准", "title_en": "SANSKRITI: A Comprehensive Benchmark for Evaluating Language Models' Knowledge of Indian Culture", "authors": "Arijit Maji,Raghvendra Kumar,Akash Ghosh,Anushka,Sriparna Saha", "background": "语言模型（LMs）是现代工作流程中不可或缺的工具，但它们在全球范围内的有效性依赖于对当地社会文化背景的理解。论文介绍了SANSKRITI基准，旨在评估语言模型对印度丰富文化多样性理解的能力。SANSKRITI包含来自28个印度邦和8个联邦领土的21,853个经过仔细筛选的问答对，覆盖了印度文化的16个关键方面，为印度文化的全面代表提供了多层次的内容。通过利用这个丰富、文化和多样化数据集，SANSKRITI为评估和提高语言模型的文化理解能力设定了新的标准。", "innovation": "SANSKRITI是一个大规模的基准数据集，用于测试印度文化知识，包含21,853个精心策划的问答对，覆盖16个关键文化方面，是迄今为止最大的此类数据集。它首次提供了系统性地评估大规模语言模型、印度语言模型以及较小规模语言模型在处理文化特异查询时能力的方法，揭示了它们在区域特定背景下的显著差异。", "conclusion": "SANSKRITI为语言模型的文化理解能力评估设立了新标准，展示了广泛的、文化丰富和多样的数据集的重要性，并揭示了模型在处理文化具体问题时的不足之处，为未来改进模型的跨文化理解能力提供了新的视角和方向。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09349", "html_url": "https://arxiv.org/abs/2506.09349", "title": "DrVoice: 通过双分辨率语音表示实现并行语音-文本语音对话模型", "title_en": "DrVoice: Parallel Speech-Text Voice Conversation Model via Dual-Resolution Speech Representations", "authors": "Chao-Hong Tan,Qian Chen,Wen Wang,Chong Deng,Qinglin Zhang,Luyao Cheng,Hai Yu,Xin Zhang,Xiang Lv,Tianyu Zhao,Chong Zhang,Yukun Ma,Yafeng Chen,Hui Wang,Jiaqing Liu,Xiangang Li,Jieping Ye", "background": "近年来，关于使用大型语言模型（Large Language Models, LLMs）实现端到端（End-to-End, E2E）语音生成的研究引起了广泛的关注，已有多个研究工作将基于文本的LLMs扩展为生成离散语音令牌。现有的E2E方法主要分为两类：（1）不将生成的离散语音令牌整合到LLMs的自回归过程中独立生成，导致文本生成对同期语音合成不知情。（2）通过联合自回归建模生成交错或并行的语音-文本令牌，使生成过程中的两种模态具备相互了解的能力。本研究所提出的方法基于联合自回归建模提出了DrVoice，这是一个带有双分辨率语音表示的并行语音-文本语音对话模型。目前的方法主要使用12.5Hz的输入音频表示，而我们的双分辨率机制将输入频率降低至5Hz，显著降低了计算成本，改善了语音和文本令牌之间的频率差异，从而更好地发挥了LLMs的能力。实验结果证明了DrVoice在OpenAudioBench和Big Bench Audio基准上的新最先进的技术水平，同时在VoiceBench和UltraEval-Audio基准上也达到了与最先进的技术水平相当的表现，使其成为一个领先的开源语音基础模型。", "innovation": "本研究提出了一个基于联合自回归建模的并行语音-文本语音对话模型——DrVoice。其创新点在于采用了双分辨率的语音表示机制，将LLMs的输入频率从12.5Hz降低到5Hz，显著减少了计算成本，并改善了语音和文本令牌之间的频率一致性，从而更好地利用了LLMs的功能。", "conclusion": "实验结果显示，DrVoice在多个基准测试中取得了最先进的技术水平，并且在开源语音基础模型中处于领先地位。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.24958", "html_url": "https://arxiv.org/abs/2509.24958", "title": "治愈之对话：医生代理询证能力的全面评估", "title_en": "The Dialogue That Heals: A Comprehensive Evaluation of Doctor Agents' Inquiry Capability", "authors": "Linlu Gong,Ante Wang,Yunghwei Lai,Weizhi Ma,Yang Liu", "background": "有效的医生应该具备同理心、专业知识、耐心和清晰沟通等多种能力。尽管AI医生在专家诊断技能方面取得了进步，尤其在通过询问获取信息方面表现突出，但在其他关键的医生素质方面仍然存在不足。为了弥合这一差距，该研究提出了MAQuE（Medical Agent Questioning Evaluation），这是首个针对多轮对话的全面自动评估基准，包含3000个真实模拟病人代理，具有多样化的语言模式、认知限制、情感反应及被动披露倾向。", "innovation": "研究提出了MAQuE，作为首个进行全面自动评估的基准，涵盖任务成功率、询问熟练度、对话技巧、询问效率和患者体验等多个方面。实验结果显示，最先进的模型在询问能力方面仍有很大的改进空间，对现实病人行为的变化非常敏感，显著影响诊断准确性。此外，精细的评估指标揭示了不同评估视角之间的权衡关系，突显了在现实临床环境中平衡性能和实用性所面临的挑战。", "conclusion": "实验显示，最先进的模型在询问能力方面仍有显著改进空间，尤其是在处理现实中病人行为的变化时存在巨大挑战。通过精细的评估指标，研究突显了在现实临床环境中平衡性能和实用性所面临的复杂性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.24494", "html_url": "https://arxiv.org/abs/2509.24494", "title": "GRPO-MA：GRPO中的多答案生成以实现稳定的高效链式推理训练", "title_en": "GRPO-MA: Multi-Answer Generation in GRPO for Stable and Efficient Chain-of-Thought Training", "authors": "Hongcheng Wang,Yinuo Huang,Sukai Wang,Guanghui Ren,Hao Dong", "background": "近年来，诸如DeepSeek-R1等研究显示，通过强化学习（RL）中的GRPO算法可以有效训练大型语言模型（LLMs）和视觉语言模型（VLMs）中的推理链（CoT）。然而，GRPO算法在使用过程中遇到了三个主要挑战：想法与答案之间的梯度耦合、由于有限的并行采样导致的稀疏奖励信号，以及不稳定的优势估计。为了应对这些挑战，作者提出了一种称为GRPO-MA的方法，通过从每个推理过程中生成多种答案，改善了算法的稳定性和效率。此方法不仅理论上证明了增加每种想法的生成答案数量能降低想法优势估计的方差，还通过梯度分析实验验证了这一效果，表明GRPO-MA能显著减少梯度峰值。", "innovation": "提出了GRPO-MA，一种利用每个推理处理过程生成多种答案的方法，以提高算法的稳定性和效率。理论分析显示增加每种想法的生成答案数量能减少想法优势估计的方差；实验验证GRPO-MA相比GRPO能显著减少梯度峰值。", "conclusion": "在数学、代码和多样化的多模态任务中，GRPO-MA在性能和训练效率上均显著超越了GRPO。进一步的消融研究证实增加每种想法的生成答案数量能持续提升模型性能。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.10114", "html_url": "https://arxiv.org/abs/2510.10114", "title": "LinearRAG: Linear Graph Retrieval Augmented Generation on Large-scale Corpora", "title_en": "LinearRAG: Linear Graph Retrieval Augmented Generation on Large-scale Corpora", "authors": "Luyao Zhuang,Shengyuan Chen,Yilin Xiao,Huachi Zhou,Yujing Zhang,Hao Chen,Qinggang Zhang,Xiao Huang", "background": "使用检索增强生成（RAG）来减轻大型语言模型（LLMs）的 hallucinations，通过利用外部知识有效应对简单的查询任务。然而，在大规模的非结构化语料库中，信息是分散的，传统的RAG系统难以处理。现有基于知识图的RAG方法通过关系提取构建图，这往往会导致图中的关系不准确或不一致，从而降低检索质量。因此，现有方法存在不稳定性和高成本的问题。", "innovation": "提出了一种高效框架LinearRAG，用于构建可靠的关系自由层次图Tri-Graph，仅使用轻量级实体提取和语义链接，避免复杂的关系建模。LinearRAG采用两阶段检索策略：首先是通过局部语义桥接激活相关实体，然后是通过全局重要性聚合进行段落检索。实验表明，LinearRAG在四个数据集上显著优于基准模型。", "conclusion": "LinearRAG提供了一种经济且可靠的原文档索引方式，图构建线性扩展语料库大小，不消耗额外的标记，促进了复杂、多跳推理解析任务的有效性，显著优于现有基准模型。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.15545", "html_url": "https://arxiv.org/abs/2510.15545", "title": "TokenTiming：一种用于通用推测性解码模型配对的动态对齐方法", "title_en": "TokenTiming: A Dynamic Alignment Method for Universal Speculative Decoding Model Pairs", "authors": "Sibo Xiao,Jinyuan Fu,Zhongle Xie,Lidan Shou", "background": "加速大型语言模型（LLMs）的推理是生成式AI中的关键挑战。投机性解码（SD）大幅提升LLM推理效率，但其适用性受限于词表必须相同的基本约束，这限制了可用的草稿模型数量，并常常需要从头训练新模型。", "innovation": "受经典时序对齐算法Dynamic Time Warping (DTW)的启发，本文提出了TokenTiming算法，通过重新编码草稿令牌序列以获取新的目标令牌序列，然后使用DTW构建映射以转移概率分布以供推测采样，从而实现了词表不匹配，并且能够与任何现成模型进行交互而无需重新训练和修改。", "conclusion": "进行的全面实验展示了1.57倍的速度提升，这项工作使得草稿模型的选择更加通用，使SD成为加速LLM更加灵活和实用的工具。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.14205", "html_url": "https://arxiv.org/abs/2510.14205", "title": "DPRF: 一种用于优化个性化大语言模型角色扮演代理与人类行为对齐的可泛化动态角色完善框架", "title_en": "DPRF: A Generalizable Dynamic Persona Refinement Framework for Optimizing Behavior Alignment Between Personalized LLM Role-Playing Agents and Humans", "authors": "Bingsheng Yao,Bo Sun,Yuanzhe Dong,Yuxuan Lu,Dakuo Wang", "background": "现有的大语言模型（LLM）角色扮演代理（RLPs）旨在模拟个体人类行为，但在手动创建的人格档案中往往由于缺乏对齐验证而导致人设真实性受损。这些档案依赖于挑选的信息和个人特质，缺乏验证，这影响了角色扮演代理的行为与目标个体之间的对齐度。", "innovation": "本研究提出了动态角色完善框架（DPRF），该框架通过迭代地识别生成行为与人类真实行为之间的认知差异（包括自由形式分析和理论驱动的结构分析），并不断优化和完善人格档案，以提升大语言模型角色扮演代理行为与目标个体之间的对齐度。该框架在五个大语言模型上对四种行为预测场景进行评估，结果表明DPRF能够显著提高行为一致性，并在多个模型上实现泛化。", "conclusion": "该研究提供了一种稳健的方法来创建高保真的人格档案，并增强了下游应用程序（如用户仿真、社会研究和个性化AI）的有效性。DPRF框架能够跨多个模型和场景泛化，并能显著改善角色扮演代理与目标个体的行为对齐度。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18383", "html_url": "https://arxiv.org/abs/2510.18383", "title": "MENTOR: 一种通过教师优化奖励实现小模型工具使用能力的强化学习框架", "title_en": "MENTOR: A Reinforcement Learning Framework for Enabling Tool Use in Small Models via Teacher-Optimized Rewards", "authors": "ChangSu Choi,Hoyun Song,Dongyeon Kim,WooHyeon Jung,Minkyung Cho,Sunjin Park,NohHyeob Bae,Seona Yu,KyungTae Lim", "background": "将大型语言模型的工具使用能力通过蒸馏转换为更小、更高效的语言模型是其实用应用的关键挑战。现有的监督微调方法在推广性方面表现不佳，因为这种方法训练模型仅模仿静态的教师路线，而不是学习稳健的方法。而标准的基于强化学习的方法虽然提供了另一种选择，但使用稀疏奖励的标准强化学习未能有效指导小语言模型，导致它们在探索效率低和采用次优策略方面遇到困难。", "innovation": "提出了MENTOR框架，这是一种将RL与教师指导式蒸馏相结合的框架。MENTOR通过探索学习一个更具泛化能力的策略，而不仅仅是简单的模仿。同时，为了解决奖励稀疏性的问题，MENTOR使用教师的参考轨迹来构建密集、复合的教师指导奖励，从而提供细粒度的指导。实验结果表明，与监督微调和标准稀疏奖励强化学习基准相比，MENTOR显著提高了小语言模型的跨域泛化能力和战略性技巧。", "conclusion": "EXTENSIVE EXPERIMENTS DEMONSTRATE THAT MENTOR SIGNIFICANTLY IMPROVES THE CROSS-DOMAIN GENERALIZATION AND STRATEGIC COMPETENCE OF SLMs COMPARED TO BOTH SFT AND STANDARDSPARSE-REWARD RL BASELINES."}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19457", "html_url": "https://arxiv.org/abs/2510.19457", "title": "MINED：探查和更新大型多模态模型中的多模态时敏知识", "title_en": "MINED: Probing and Updating with Multimodal Time-Sensitive Knowledge for Large Multimodal Models", "authors": "Kailin Jiang,Ning Jiang,Yuntao Du,Yuchen Ren,Yuchen Li,Yifan Gao,Jinhe Bi,Yunpu Ma,Qingqing Liu,Xianhao Wang,Yifan Jia,Hongbo Jiang,Yaocong Hu,Bin Li,Lei Liu", "background": "现有大型多模态模型（LMMs）通过跨模态预训练编码丰富的事实知识，但其静态表示在保持时间敏感的事实知识方面存在困难。现有基准仍然受静态设计的限制，未能充分评估LMMs理解时间敏感知识的能力。", "innovation": "提出了一种名为MINED的基准测试，该测试评估LMMs在6个关键维度和11个挑战任务中的时间意识：认知、意识、可靠性、理解、推理和鲁棒性。MINED基准测试由两名专业注释员从维基百科构建，包含2,104个时间敏感知识样本，涵盖六种知识类型。通过MINED评估15个广泛使用的LMMs，结果显示GEMini-2.5-Pro在CEM得分上最高，为63.07，但大多数开源LMMs在时间理解方面仍表现不足。同时，LMMs在组织知识的理解上表现最好，而在运动方面表现最差。通过更新时间敏感知识的方法研究了更新LMMs的可行性，结果显示LMMs可以通过知识编辑方法在单一编辑场景中有效地更新知识。", "conclusion": "实验结果表明，大多数开源LMMs在时间敏感知识理解方面仍然不足，而通过知识编辑方法可以有效地更新LMMs中的时间敏感知识。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20280", "html_url": "https://arxiv.org/abs/2510.20280", "title": "通过学习预测性上下文嵌入实现上下文级语言建模", "title_en": "Context-level Language Modeling by Learning Predictive Context Embeddings", "authors": "Beiya Dai,Yuliang Liu,Daozheng Xue,Qipeng Guo,Kai Chen,Xinbing Wang,Bowen Zhou,Zhouhan Lin", "background": "Next-token prediction (NTP) 是现代大型语言模型（LLMs）预训练的基石，推动了其在文本生成、推理和指令遵循方面的前所未有的能力。然而，基于单个标记的预测限制了模型对更高层次的语义结构和长距离上下文关系的捕捉能力。", "innovation": "我们引入了 ContextLM 框架，它在标准预训练中增加了固有的下个上下文预测目标。这一机制训练模型学习多个标记上下文的预测表示，并利用未来标记片段产生的错误信号。ContextLM 在保持与标准自回归、按标记评估的兼容性（例如困惑度）的同时实现了这一增强。", "conclusion": "大规模实验表明，ContextLM 在困惑度和下游任务性能方面的改进是持续的。我们的分析表明，下个上下文预测提供了一条可扩展且高效的增强语言建模的路径，减少了更多计算开销的同时提高了长距离连贯性和更有效的注意力分配。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17281", "html_url": "https://arxiv.org/abs/2508.17281", "title": "从语言到行动：大型语言模型作为自主代理和工具使用者的综述", "title_en": "From Language to Action: A Review of Large Language Models as Autonomous Agents and Tool Users", "authors": "Sadia Sultana Chowa,Riasad Alvi,Subhey Sadi Rahman,Md Abdur Rahman,Mohaimenul Azam Khan Raiaan,Md Rafiqul Islam,Mukhtar Hussain,Sami Azam", "background": "近年来，追求达到人类水平的人工智能（AI）显著推动了自主代理和大型语言模型（LLMs）的发展。LLMs现已被广泛应用为决策代理，因其能够理解指令、管理序列任务并根据反馈自我调整。本文综述了2023年至2025年间在A*和A排名及Q1期刊中有关LLMs作为自主代理和工具使用者的研究进展，提出了七个研究问题。", "innovation": "本文通过结构化分析LLMs的架构设计原则，将其应用分为单代理系统和多代理系统，并探讨了如何整合外部工具。此外，还研究了LLMs的认知机制，包括推理、规划和记忆，并讨论了提示方法和微调过程对代理性能的影响。与此同时，作者还评估了当前的基准测试和评估协议，并分析了68个公开可用数据集，以评估基于LLMs的代理在各种任务中的表现。最后，作者指出了目前研究中的关键发现和验证推理、自我改进以及基于LLMs的代理个性化的能力，并讨论了十个未来研究方向以弥补现有空白。", "conclusion": "本文总结了在大型语言模型作为自主代理和工具使用者领域的最新研究进展，探讨了其架构设计原则、认知机制、整合外部工具的方法以及当前的评估标准。此外，对68个公开数据集的分析展示了基于LLMs的代理在不同任务中的表现。最后，提出了十个未来研究方向，这将有助于进一步提升代理性能和多功能性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.22830", "html_url": "https://arxiv.org/abs/2510.22830", "title": "生成语言模型通过总结法在长作文自动评分中的探索", "title_en": "Exploration of Summarization by Generative Language Models for Automated Scoring of Long Essays", "authors": "Haowei Hua(1),Hong Jiao(2),Xinyi Wang(3) ((1) Princeton University, (2) University of Maryland, College Park, (3) University of Maryland, College Park &amp; Beijing Normal University)", "background": "BERT及其变体已被广泛用于自动评分。然而，这些基于编码器的模型受限于512个标记的限制，显示了在长文章自动评分方面的不足。因此，这项研究探索了生成语言模型通过总结和提示的方法，用于长文章的自动评分。实验结果显示，这种方法显著提高了评分的准确性，QWK得分从0.822提高到了0.8878，使用的是Learning Agency Lab Automated Essay Scoring 2.0数据集。", "innovation": "这项研究利用生成语言模型来解决基于编码器的模型在处理长文本自动评分时的局限性，通过总结和提示的方法提高了评分准确性。", "conclusion": "生成语言模型通过总结和提示的方法显著提高了Long Essays的自动评分准确性，从0.822提高到0.8878，这显示出这种方法在处理长文本自动评分上的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.01268", "html_url": "https://arxiv.org/abs/2510.01268", "title": "AdaDetectGPT：具有统计保证的大规模语言模型生成文本的自适应检测", "title_en": "AdaDetectGPT: Adaptive Detection of LLM-Generated Text with Statistical Guarantees", "authors": "Hongyi Zhou,Jin Zhu,Pingfan Su,Kai Ye,Ying Yang,Shakeel A O B Gavioli-Akilagun,Chengchun Shi", "background": "现有的顶级logits检测器利用给定来源的大规模语言模型（LLM）的分布函数计算观测文本的对数概率统计量来确定文本是由人类还是由LLM创作的。然而，仅依赖对数概率可能不是最优的。因此，引入了AdaDetectGPT——一种新颖的分类器，能够在训练数据中自适应地学习见证函数，以增强logits检测器的性能。该方法提供了对真正阳性率、假阳性率、真正阴性和假阴性率的统计保证。", "innovation": "AdaDetectGPT通过自适应学习见证函数，提高了logits检测器的性能，并对检测结果提供了统计保证。广泛的数值研究表明，在不同的数据集和LLM组合中，它几乎始终优于现有的最佳方法，性能提升最高可达37%。", "conclusion": "AdaDetectGPT在统计保证下的大规模语言模型生成文本的自适应检测中取得了显著的性能提升，表明该方法在实际应用中具有重要的价值。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23458", "html_url": "https://arxiv.org/abs/2510.23458", "title": "BrowseConf: 针对网络代理的基于置信度的测试时缩放", "title_en": "BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents", "authors": "Litu Ou,Kuan Li,Huifeng Yin,Liwen Zhang,Zhongwang Zhang,Xixi Wu,Rui Ye,Zile Qiao,Pengjun Xie,Jingren Zhou,Yong Jiang", "background": "LLMs的置信度是衡量模型不确定性和答案可靠性的有用指标。现有工作主要集中在单轮场景，而复杂多轮对话中的置信度研究有限。本文探讨了基于LLM的搜索代理是否有能力在长时间序列操作后通过口头化的置信度评分来传达自己的置信度，这比简单输出单轮交互的置信度更具挑战性。", "innovation": "提出了Test-Time Scaling (TTS)方法，使用置信度得分来决定答案质量，鼓励模型在达到满意置信水平之前多次尝试。", "conclusion": "实验结果表明，所提出的方法显著减少了令牌消耗，同时展示了与基线固定预算TTS方法相当的性能。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.02787", "html_url": "https://arxiv.org/abs/2410.02787", "title": "基于VLM框架的导航：向去任何语言迈进", "title_en": "Navigation with VLM framework: Towards Going to Any Language", "authors": "Zecheng Yin,Chonghao Cheng,and Yao Guo,Zhen Li", "background": "在智能导航领域，实现完全开放的语言目标并以智能方式探索开放场景一直面临重大挑战。近期，视觉语言模型（VLMs）在处理语言和视觉数据方面展示了显著的能力。尽管许多研究工作已经在利用VLMs进行开放场景中的导航，但这些方法往往存在高计算成本、依赖对象中心的方法或依赖于具体环境先验的详细人类指令等问题。现有的方法难以处理人类友好的语言目标，如抽象地点、动作或开放场景中的特定物体。因此，需要一种无需培训且能够处理这些开放式语言目标的框架，以实现智能导航。", "innovation": "本文介绍了一种名为Navigation with VLM (NavVLM) 的培训框架，它利用开源的VLM作为其认知核心，通过仅提供简洁的目标，不依赖详细的环境先验，使机器人能够有效导航到人类友好的语言目标。NavVLM 在模拟和现实世界的实验中均展示了优越的性能，证明了其在复杂环境中的导航能力，并展示了在开放词汇集语言中的导航能力。", "conclusion": "在模拟环境中，NavVLM 在 Matterport 3D (MP3D)、Habitat Matterport 3D (HM3D) 和 Gibson 这些丰富细节的环境中，针对特定任务实现了最先进的成功率加路径长度 (SPL) 性能。在现实世界的验证中，NavVLM 也表现出了良好的实际机器人室内导航能力。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.19585", "html_url": "https://arxiv.org/abs/2510.19585", "title": "使用大型语言模型在历史书籍中检测拉丁文：一个多模态基准测试", "title_en": "Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark", "authors": "Yu Wu,Ke Shu,Jonas Fischer,Lidia Pivovarova,David Rosson,Eetu Mäkelä,Mikko Tolonen", "background": "本文讨论了从混合语言的历史文档中提取拉丁文片段的新型任务。这些文档包含多个语种且格式各异。研究团队基于一个包含724页注解的多模态数据集，对大型基础模型进行了基准测试和评估。研究结果表明，可以使用当下模型实现可靠的拉丁文检测。这为这些模型在这项任务中的应用提供了基础分析和讨论.", "innovation": "本文创新之处在于提出了检测历史书籍中拉丁文的新型任务，使用多模态数据集和大型基础模型进行评估，以首次全面分析这类模型在该任务中的能力和局限性.", "conclusion": "研究结果证明了当前模型在拉丁文检测中的可行性，并进行了全面的分析。这为未来研究提供了基础，揭示了模型的应用前景与潜在限制。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.15737", "html_url": "https://arxiv.org/abs/2411.15737", "title": "TableTime: 无训练表格理解的大语言模型时间序列分类", "title_en": "TableTime: Reformulating Time Series Classification as Training-Free Table Understanding with Large Language Models", "authors": "Jiahao Wang,Mingyue Cheng,Qingyang Mao,Yitong Zhou,Daoyu Wang,Qi Liu,Feiyang Xu,Xin Li", "background": "大型语言模型（LLMs）在多变量时间序列分类（MTSC）任务中表现出色。现有的LLM方法直接在LLM的潜在空间中从零开始编码时间序列的嵌入，以与LLM的语义空间对齐，但这些方法存在一些局限性，包括无法保留时间信息和通道特定信息、难以将学习到的表示空间与LLM的语义空间对齐，以及需要特定任务的重新训练，这既耗时又耗资源。", "innovation": "TableTime 方法将MTSC重新表述为无训练所需的表格理解任务。通过将多变量时序数据转换成表格形式，并将表格数据表示为文本格式，使其自然地与LLM的语义空间对齐。同时，设计了一个推理框架，结合上下文文本信息，邻域协助，多路径推理和问题分解，增强了LLM的推理能力，实现了零样本分类。", "conclusion": "在UEA档案库的10个公开代表性数据集上进行的大量实验验证了TableTime方法的优越性。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.14571", "html_url": "https://arxiv.org/abs/2411.14571", "title": "从学过、滞后、LLM解释：LLM对终端用户安全问题的响应", "title_en": "Learned, Lagged, LLM-splained: LLM Responses to End User Security Questions", "authors": "Vijay Prakash,Kevin Lee,Arkaprabha Bhattacharya,Danny Yuxing Huang,Jessica Staddon", "background": "回答终端用户的安全问题具有挑战性。虽然类似于GPT、LLAMA和Gemini等大型语言模型(LLMs)尚未达到无错误的标准，但在回答多种非安全类问题上已经显示出潜力。然而，这些模型在处理终端用户安全问题时存在知识过时、不准确以及沟通方式间接或不回应的问题，这影响了所提供的信息质量。本研究通过对三种流行的LLM进行定量评估，探讨了它们处理系统收集的900个终端用户安全问题的表现，旨在识别并建议改进方向，以更好地帮助用户寻求安全方面的指导和策略。", "innovation": "本研究通过评估流行的LLM在处理终端用户安全问题上的表现，揭示了这些模型在知识准确性和沟通风格上的不足，并提出了针对性的改进建议。此外，研究还为终端用户提供了与LLM交互的策略，以提高他们在面临安全问题时获取帮助的质量。", "conclusion": "尽管LLM在回答终端用户安全问题上显示出了广泛的一般性知识，但在知识的及时性和准确性方面仍然存在局限。根据这些发现，研究提出模型改进的方向和用户与LLM交互的策略，从而提高安全问题处理的质量。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.03490", "html_url": "https://arxiv.org/abs/2510.03490", "title": "SEER：基于短语的情感证据检索基准", "title_en": "SEER: The Span-based Emotion Evidence Retrieval Benchmark", "authors": "Aneesha Sampath,Oya Aran,Emily Mower Provost", "background": "传统的表情识别任务通常是给整个句子分配一个单一的情感标签，而未深入探讨如何具体指出有哪些短语表达了情感的问题。为解决这一问题，研究者们引入了SEER基准。SEER旨在评估大规模语言模型（LLMs）在识别具体表达情感的文本短语方面的能力，这对于需要明白情感是如何表达的应用场景，如同理心对话和临床支持尤为重要。SEER包含两个任务：在单句中识别情感证据和在一个短的五句子连续段落中识别情感证据。", "innovation": "SEER通过引入一个新的基于短语的情感识别任务，填补了传统情感识别任务的空白。它不仅要求模型识别整个句子的情感，还要求识别具体的短语表达的情感。这需要模型在细节上做出准确的判断，对于理解情感表达的具体方式很有价值。SEER基准包含了1200个真实世界的句子的新注释，使得研究者能够评估不同模型在不同情境下的表现。研究者评估了14个开源的大规模语言模型，发现这些模型在长文本中的表现较差，这是因其对情感关键词的过分依赖以及在中性文本中产生误报的问题所致。", "conclusion": "研究者提出了SEER基准，用来衡量大模型识别具体情感表达短语的能力。结果显示，一些模型虽然在单句任务中接近人类平均水平，但在更长的文本中表现较差。持续改进模型，减少对关键词的依赖，以及提高在中性文本中的准确性对于提高大模型的情感识别能力至关重要。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23169", "html_url": "https://arxiv.org/abs/2510.23169", "title": "MATCH: 通过对比学习的任务驱动代码评估", "title_en": "MATCH: Task-Driven Code Evaluation through Contrastive Learning", "authors": "Marah Ghoummaid,Vladimir Tchuiev,Ofek Glick,Michal Moshkovitz,Dotan Di Castro", "background": "基于AI的代码生成越来越普遍，GitHub Copilot估计在GitHub上生成的代码中有46%是由代码生成的。准确地评估生成的代码与开发者意图的契合度仍然是一个关键挑战。传统的评估方法，如单元测试，往往不具备可扩展性和成本效益。语法相似度度量（例如BLEU、ROUGE）无法捕捉代码的功能性，而像CodeBERTScore这样的度量则需要参考代码，而参考代码并不总是可获得的。为此，本文填补了无参考评估的空白，提出MATCH这一新颖的无参考度量方法，", "innovation": "MATCH利用对比学习生成代码和自然语言任务描述的有意义嵌入，使相似性评分能够反映生成代码对任务的实现程度。与现有度量相比，MATCH在多个编程语言中实现了与功能正确性和人类偏好的更强的相关性，填补了无参考评估机制的空白。", "conclusion": "MATCH作为一种新颖的无参考度量方法，在多个编程语言中展示了与功能正确性和人类偏好的更强相关性，解决了传统评估方法的局限性，为代码评估提供了新的解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11842", "html_url": "https://arxiv.org/abs/2505.11842", "title": "Video-SafetyBench：视频LVLM安全性评价基准", "title_en": "Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs", "authors": "Xuannan Liu,Zekun Li,Zheqi He,Peipei Li,Shuhan Xia,Xing Cui,Huaibo Huang,Xi Yang,Ran He", "background": "随着大型视觉-语言模型（LVLMs）的应用日益增多，潜在的恶意输入可能导致的安全问题引起了广泛关注。然而，现有的多模态安全评估主要集中在静态图像输入暴露的模型脆弱性上，忽视了视频中的时间动态性可能带来的独特安全风险。", "innovation": "该研究引入了Video-SafetyBench，这是首个旨在评估视频-文本攻击下LVLM安全性综合基准。该基准包含2,264个视频-文本配对，涵盖了48个细分类的不安全类别，每个配对包括一个与有害查询或看似无辜但实际上引发有害行为的视频关联的合成视频。此外，还提出了一种RJScore评价新方法，综合了法官模型的置信度和人类一致决策阈值校准。实验结果表明，无害查询的视频组成可以获得67.2%的平均攻击成功率，显示出视频引发攻击的一致易感性。", "conclusion": "研究指出Video-SafetyBench将促进基于视频的安全评估和防御策略的研究。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.11364", "html_url": "https://arxiv.org/abs/2504.11364", "title": "离线学习与遗忘对于大型语言模型进行推理", "title_en": "Offline Learning and Forgetting for Reasoning with Large Language Models", "authors": "Tianwei Ni,Allen Nie,Sapana Chaudhary,Yao Liu,Huzefa Rangwala,Rasool Fakoor", "background": "在大型语言模型推理时，采用推理时间搜索（inference-time search）可以进一步增强模型解决复杂数学和推理问题的能力，但这种方法会显著增加计算成本和推理时间。模型需要生成和评估多个候选解决方案，以识别有效的推理路径。针对此问题，研究提出了一种有效的方法，该方法将搜索能力直接集成到模型中，通过在多种搜索方法产生的成功（学习）和失败（遗忘）推理路径上进行微调实现。", "innovation": "该研究提出了一种结合搜索能力的方法，通过在包含成功和失败推理路径的数据上进行离线微调来增强模型的推理能力；同时，研究发现通过较小的学习率进行微调可以避免对模型搜索能力的负面影响，这种方法在处理24点游戏和计数排序等难题时表现出色，与推理时间搜索基线相比，成功率为23%左右，且推理时间减少180倍。此外，该方法在学习与遗忘目标方面优于监督微调和基于偏好方法。", "conclusion": "研究证实了通过离线学习和遗忘策略改进大型语言模型的推理效果，该策略显著提高了模型的推理准确性并大幅减少了推理时间。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.01068", "html_url": "https://arxiv.org/abs/2502.01068", "title": "FastKV: Token-Selective Propagation for KV Cache Compression in Fast Long-Context Processing", "title_en": "FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation", "authors": "Dongwon Jo,Jiwon Song,Yulhwa Kim,Jae-Joon Kim", "background": "大语言模型（LLMs）在处理长上下文序列方面表现出色，但它们需要大量的预填充计算和键值（KV）缓存，这会严重消耗计算效率和内存使用。最近的一些工作通过预填充加速来压缩KV缓存，从而减少了成本，但这一做法无意中将预填充计算的减少与解码KV预算绑定了起来。这种绑定来自于忽视了被提取的上下文在不同层之间变异性，往往导致准确性的下降。为了应对这一问题，本文提出了FastKV框架，通过利用后层对令牌重要性的稳定化，提供了在预填充和解码中都减小延迟的解决方案，进而解除了KV预算和预填充计算减少之间的绑定关系。", "innovation": "FastKV框架通过引入Token-Selective Propagation（TSP）层，仅将最具信息量的令牌传递给后续层，并独立选择对于缓存最相关的KV条目，从而在保持准确性的同时实现了预填充阶段高达1.82倍和解码阶段高达2.87倍的加速。这种独立控制TSP率和KV保留率的方式可使效率和准确性获得灵活的优化。", "conclusion": "实验结果显示，与全上下文基线相比，FastKV在预填充中实现了高达1.82倍的加速，在解码中实现了高达2.87倍的加速，同时保持了与仅加速解码阶段的基线相同的准确性。本文的代码可以在提供的链接处获得。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.17336", "html_url": "https://arxiv.org/abs/2509.17336", "title": "Mano 技术报告", "title_en": "Mano Technical Report", "authors": "Tianyu Fu,Anyang Su,Chenxu Zhao,Hanning Wang,Minghui Wu,Zhe Yu,Fei Hu,Mingjia Shi,Wei Dong,Jiayao Wang,Yuyang Chen,Ruiyang Yu,Siran Peng,Menglin Li,Nan Huang,Haitian Wei,Jiawei Yu,Yi Xin,Xilin Zhao,Kai Gu,Ping Jiang,Sifan Zhou,Shuo Wang", "background": "图形用户界面（GUI）是人机交互的主要媒介，但自动化GUI交互仍然具有挑战性，主要由于视觉元素的复杂性、动态环境以及需要多步推理。现有的基于视觉-语言模型（VLMs）的方法通常受到分辨率有限、领域不匹配以及序列决策能力不足的限制。", "innovation": "我们提出了一种名为Mano的鲁棒GUI代理，基于多模态预训练模型，并在广泛的网页和计算机系统数据上进行预训练。该方法包括一个新颖的模拟环境用于高保真数据生成、三阶段训练管道（监督微调、离线强化学习和在线强化学习）以及一个验证模块用于错误恢复。Mano在多个GUI基准测试上表现出最先进的性能，包括Mind2Web和OSWorld，显著提高了成功率和操作准确性。这项工作为强化学习与VLMs的有效集成提供新的见解，强调了领域特定数据、迭代训练和整体奖励设计的重要性。", "conclusion": "我们的工作为GUI代理的实际部署提供了新的理解，突显了领域特定数据、迭代训练和整体奖励设计的重要性。Mano在多个GUI基准测试中实现了显著的成功率和操作准确性上的改进。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13771", "html_url": "https://arxiv.org/abs/2506.13771", "title": "LittleBit: 通过隐因子化实现超低比特量化", "title_en": "LittleBit: Ultra Low-Bit Quantization via Latent Factorization", "authors": "Banseok Lee,Dongkyu Kim,Youngcheon You,Youngmin Kim", "background": "部署大型语言模型（LLMs）常常面临高内存和计算成本的挑战。量化提供了一种解决方案，但在小于1比特的范围内会带来性能下降，尤其是0.1比特每权重（BPW）这样的极端情况下更为困难。", "innovation": "本文介绍了LittleBit，这是一种新的极端LLM压缩方法，针对0.1 BPW水平进行压缩，实现了近31倍的内存降低成本，例如将Llama2-13B压缩到不到0.9GB。LittleBit使用潜在矩阵分解将权重表示为低秩形式，随后对这些因素进行二进制化，并引入了多层次补偿机制，包括行、列和额外的潜在维度，以学习每个秩的重要性。LittleBit的两个关键贡献是用于量化感知训练（QAT）初始化的双向符号值无关分解（Dual-SVID）以及集成残差补偿机制。", "conclusion": "广泛实验表明，LittleBit在超低比特量化方面优于现有方法，其在Llama2-7B上的0.1 BPW性能超过了领先方法的0.7 BPW。LittleBit为大小和性能之间的权衡提供了新的可能性，能够在内核级别上提供高达11.6倍的速度提升，并使强大的LLM在资源受限的环境中变得实用。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.15870", "html_url": "https://arxiv.org/abs/2510.15870", "title": "OmniVinci: 提升面向多模态理解的语言模型的架构和数据", "title_en": "OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM", "authors": "Hanrong Ye,Chao-Han Huck Yang,Arushi Goel,Wei Huang,Ligeng Zhu,Yuanhang Su,Sean Lin,An-Chieh Cheng,Zhen Wan,Jinchuan Tian,Yuming Lou,Dong Yang,Zhijian Liu,Yukang Chen,Ambrish Dantrey,Ehsan Jahangiri,Sreyan Ghosh,Daguang Xu,Ehsan Hosseini-Asl,Danial Mohseni Taheri,Vidya Murali,Sifei Liu,Yao Lu,Oluwatobi Olabiyi,Yu-Chiang Frank Wang,Rafael Valle,Bryan Catanzaro,Andrew Tao,Song Han,Jan Kautz,Hongxu Yin,Pavlo Molchanov", "background": "为了推进机器智能，需要开发跨多种模态感知的能力，如同人类感知世界一样。 OmniVinci 是一项旨在构建强大且开源的多模态大语言模型（LLM）的计划。研究团队仔细研究了模型架构和数据编纂的设计选择。", "innovation": "OmniVinci 提出了三大创新：\n1. 全域对齐网络（OmniAlignNet）：加强了视觉和音频嵌入在共享全域模态潜空间中的对齐。\n2. 时间嵌入分组：捕捉视觉和音频信号之间的相对时间对齐。\n3. 受限旋转时间嵌入：在全域模态嵌入中编码绝对时间信息。\n此外，还提出了一个采集和合成管道，生成了 2400 万单模态和全域模态对话。", "conclusion": "OmniVinci 在多模态感知和推理方面表现出色，相较于 Qwen2.5-Omni，其 DailyOmni（跨模态理解）提高了 19.05%，MMAR（音频）提高了 1.7%，Video-MME（视觉）提高了 3.9%。同时，训练 tokens 仅使用 0.2T，比 Qwen2.5-Omni 的 1.2T 减少了 6 倍。在多个下游应用领域，如机器人技术、医疗 AI 和智能工厂，显示了全域模态的优势。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23564", "html_url": "https://arxiv.org/abs/2510.23564", "title": "ReCode: 统一计划与行动以实现通用粒度控制", "title_en": "ReCode: Unify Plan and Action for Universal Granularity Control", "authors": "Zhaoyang Yu,Jiayi Zhang,Huixue Su,Yufan Zhao,Yifan Wu,Mingyi Deng,Jinyu Xiang,Yizhang Lin,Lingxiao Tang,Yingchao Li,Yuyu Luo,Bang Liu,Chenglin Wu", "background": "现实任务要求在不同的粒度级别做出决策，人类能够通过统一的认知表征高效地进行此类决策，其中规划被理解为一种高级形式的行动。然而，当前基于大型语言模型（LLM）的代理缺乏在不同决策粒度级别间流畅操作的能力。这一局限源自现行范式将高一级别的规划与低级别的行动严格分离，这限制了动态适应性和泛化能力。", "innovation": "本文提出ReCode（递归代码生成）作为一种新颖的范式，通过在单一代码表示中统一规划与行动来解决这一局限。在这种表示中，ReCode 将高级计划视为抽象占位函数，并对其进行递归分解，一直到基本动作，这一递归方法消除了计划与行动之间刚性的边界，使代理能够动态控制其决策粒度。递归结构本身还生成了丰富的、多粒度的训练数据，使得模型能够学习层次决策过程。", "conclusion": "大量的实验表明，ReCode 在推理性能方面显著超越了最先进的基线，并在训练上展示了出色的样本效率，验证了我们的核心洞察，即通过递归代码生成将计划与行动统一起来，是一种强大的有效方法，以实现通用粒度控制。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.22672", "html_url": "https://arxiv.org/abs/2510.22672", "title": "Look and Tell：跨越主观与客观视角的多模态语义定位数据集", "title_en": "Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views", "authors": "Anna Deichler,Jonas Beskow", "background": "该研究介绍了一个名为Look and Tell的多模态数据集，旨在研究视角中心(主观)与视域中心(客观)之间进行参照交流的情况。通过使用Meta Project Aria智能眼镜和固定摄像头记录参与者在厨房指导同伴识别材料时的眼球运动、言语和视频，结合3D场景重建，该数据集为不同空间表示方法（2D vs. 3D；主观 vs. 客观）如何影响多模态语义定位提供了基准。", "innovation": "该研究创新地结合了主观和客观视角，提出了Look and Tell数据集，这有助于推动物体语义定位和理解基于具体环境的对话的机器人代理的发展。通过同步记录眼球运动、言语和视频，并结合3D场景重建，该数据集填补了现有数据集的空白，为评估不同空间表示方法的影响提供了新的视角。", "conclusion": "研究结果表明，该数据集有助于推动多模态语义定位领域的发展，特别是对于开发能够理解并参与情境对话的实践型代理具有重要意义。研究还指出，不同的空间表示方法对多模态语义定位有不同的影响，这为未来的研究提供了参考。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23798", "html_url": "https://arxiv.org/abs/2510.23798", "title": "使用现场摄像头进行城市河流中漂浮人为垃圾监测的几何和深度学习可重复管道", "title_en": "A geometric and deep learning reproducible pipeline for monitoring floating anthropogenic debris in urban rivers using in situ cameras", "authors": "Gauthier Grimmer,Romain Wenger,Clément Flint,Germain Forestier,Gilles Rixhon,Valentin Chardon", "background": "河流中的漂浮人工垃圾日益成为环境关注的热点问题，对生物多样性、水质以及航行和娱乐等活动产生了不利影响。", "innovation": "提出了一个新颖的方法学框架，利用固定在位摄像头监测上述垃圾。该研究有两个关键贡献：一是通过深度学习连续量化和监测漂浮垃圾；二是确定在复杂环境条件下最合适的深度学习模型，以实现准确性和推理速度的优化。", "conclusion": "展示了使用几何和回归校正方法进行度量物体估计的可能性。这种方法为开发城市水生环境的稳健、低成本、自动监测系统开辟了道路。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.05316", "html_url": "https://arxiv.org/abs/2506.05316", "title": "通过难度导向的在线数据选择和回放重播提高大规模语言模型强化学习微调的数据效率", "title_en": "Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay", "authors": "Yifan Sun,Jingyan Shen,Yibin Wang,Tianyu Chen,Zhendong Wang,Mingyuan Zhou,Huan Zhang", "background": "强化学习（RL）已成为对大规模语言模型（LLMs）进行微调的有效方法，特别是在增强其推理能力方面。然而，RL微调依然非常耗资源，并且现有研究主要忽略了数据效率的问题。该研究旨在提高LLM RL微调的数据效率，通过引入难度导向的在线数据选择和回放重播技术来实现目标。", "innovation": "1. 建立了适应性难度的概念，指导在线数据选择，优先处理具有中等难度的问题，以获得更有用的学习信号。\n2. 开发了一种基于注意力的框架，仅对一个小的参考问题集进行回放，以高效估计剩余问题的适应性难度。\n3. 引入了回放重播机制，重用最近的回放结果，降低每步计算成本，同时保持稳定的更新。该机制借鉴了传统RL中的经验回放思想。", "conclusion": "实验结果表明，该方法在6种LLM-数据集组合上将RL微调时间减少了23%到62%，同时达到与原始GRPO算法相同水平的性能。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23775", "html_url": "https://arxiv.org/abs/2510.23775", "title": "使用Faster-Than-Lies和视觉语言模型进行边设备上具有特征定位的可解释检测的AI生成图像", "title_en": "Explainable Detection of AI-Generated Images with Artifact Localization Using Faster-Than-Lies and Vision-Language Models for Edge Devices", "authors": "Aryan Mathur,Asaduddin Ahmed,Pushti Amit Vasoya,Simeon Kandan Sonar,Yasir Z,Madesh Kuppusamy", "background": "随着AI生成图像的真实感增强，验证图像的真实性变得愈加困难。本文旨在应对这一挑战，通过开发一种可解释的图像真实性检测系统来解决该问题。该系统结合了一种轻量级卷积分类器（Faster-Than-Lies）和视觉语言模型（Qwen2-VL-7B），用于分类、定位和解释32x32图像中的伪影。", "innovation": "本文提出了一种创新性的方法，即结合轻量级卷积分类器（Faster-Than-Lies）和视觉语言模型（Qwen2-VL-7B），并使用自编码器重建误差图生成伪影定位热图。该系统能够以96.5%的准确率分类扩展的CiFAKE数据集，并在8核CPU上保持175ms的推理时间。这种方法使得该系统适用于本地或边缘设备的部署，并且能够在低分辨率图像中进行可解释的真实性检测。此外，该系统还能解释检测到的异常，进一步将其归类为八种语义组，并生成可解释的文本说明。", "conclusion": "本文的工作强调了在低分辨率图像中结合视觉和语义推理进行可解释的真实性检测的可行性，并指出了其在法医科学、工业检查和社交媒体管理中的潜在应用前景。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23880", "html_url": "https://arxiv.org/abs/2510.23880", "title": "TRELLISWorld：基于对象生成器的无训练世界生成", "title_en": "TRELLISWorld: Training-Free World Generation from Object Generators", "authors": "Hanke Chen,Yuan Liu,Minchen Li", "background": "文本驱动的3D场景生成在多种应用中具有潜力，如虚拟原型设计、增强现实/虚拟现实（AR/VR）和模拟。然而，现有的方法往往局限于单个对象生成、需要专门领域的训练，或者无法支持360度视角。", "innovation": "本文提出了一种无需训练的3D场景合成方法，通过将通用文本转3D对象扩散模型重新用作模块化瓷砖生成器。将场景生成重新定义为一个多瓦片去噪问题，其中独立生成重叠的3D区域并通过加权平均无缝融合。这种方法能够生成大型、连贯的场景，同时保留局部语义控制。该方法不需要场景级别数据集或再训练，依赖少量启发式规则，并继承了对象级别先验的知识泛化能力。", "conclusion": "我们的方法支持各种场景布局、高效生成和灵活编辑，为通用语言驱动3D场景构建提供了一个简单而强大的基础。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23785", "html_url": "https://arxiv.org/abs/2510.23785", "title": "CountFormer: 一种用于无类别对象计数的变压器框架，以学习视觉重复和结构", "title_en": "CountFormer: A Transformer Framework for Learning Visual Repetition and Structure in Class-Agnostic Object Counting", "authors": "Md Tanvir Hossain,Akif Islam,Mohd Ruhul Ameen", "background": "人类可以轻松地通过感知视觉重复和结构关系来计数，而不是依赖于类别身份。然而，现有的大多数计数模型无法复制这种能力；当物体具有复杂形状、内部对称或重叠组件时，它们通常会出错。", "innovation": "提出了一种基于变压器的框架CountFormer，用于在无类别对象计数中学习识别重复和结构一致性。与CounTR架构相比，该模型用自监督基础模型DINOv2替换其视觉编码器，这产生了更丰富和空间一致的特征表示。进一步引入位置嵌入融合以保留几何关系，通过轻量级卷积解码器将这些特征解码为密度图。该模型在FSC-147数据集上的性能与当前最先进的方法相当，并且在结构复杂或紧密排列的场景上表现出更高的准确性。我们的研究结果表明，结合基础模型如DINOv2能够使计数系统接近人类的结构感知，推进了真正通用且无需范例的计数范式的进程。", "conclusion": "CountFormer在FSC-147数据集上的表现与当前最先进的方法相当，且在结构复杂或紧密排列的场景中表现出更佳准确性。通过结合基础模型如DINOv2，CountFormer能够更接近人类的结构感知，这为发展真正通用且无需范例的计数系统奠定了重要基础。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23894", "html_url": "https://arxiv.org/abs/2510.23894", "title": "提升CLIP的视觉分辨能力以实现不依赖训练的开放词汇语义分割", "title_en": "Improving Visual Discriminability of CLIP for Training-Free Open-Vocabulary Semantic Segmentation", "authors": "Jinxin Zhou,Jiachen Jiang,Zhihui Zhu", "background": "将CLIP模型扩展到语义分割仍然具有挑战性，因为它们在图像级别的预训练目标与密集预测所需的像素级别视觉理解之间存在不匹配。尽管前期努力取得了令人鼓舞的结果，通过重新组织最后一层和特征，但这些方法常保留前序层的全局对齐偏差，导致分割性能欠佳。", "innovation": "本文提出了一种名为LHT-CLIP的全新非训练框架，该框架系统地利用CLIP在层、头和令牌级别上的视觉区分能力。文章揭示了三项关键见解：(i) 最后几层主要增强图像-文本对齐，但牺牲了视觉区分能力；(ii) 某些注意力头（如ViT-B/16中的10个头）在不同数据集上展示了持续的强视觉区分能力；(iii) 异常令牌表现出与正常令牌相比稀疏且一致的激活模式。基于这些发现，提出了三种互补技术：语义-空间重新加权、选择性头增强和异常令牌替换，以有效地恢复视觉区分能力并提高分割性能，而无需额外训练、辅助预训练网络或广泛的超参数调整。", "conclusion": "在8个常见语义分割基准测试上的广泛实验表明，LHT-CLIP在多种场景中达到了最优性能，突显了其在实际部署中的有效性和实用性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23816", "html_url": "https://arxiv.org/abs/2510.23816", "title": "RareFlow：基于物理感知的跨传感器稀有地球特征超分辨率流匹配方法", "title_en": "RareFlow: Physics-Aware Flow-Matching for Cross-Sensor Super-Resolution of Rare-Earth Features", "authors": "Forouzan Fallah,Wenwen Li,Chia-Yu Hsu,Hyunho Lee,Yezhou Yang", "background": "遥感图像的超分辨率（SR）方法通常在处理稀有的、多传感器获取的地貌特征时表现不佳，会导致视觉上合理的但物理上不准确的恢复结果。为此，该研究提出了一种名为RareFlow的物理感知SR框架，旨在增强SR方法在这些异常条件下的鲁棒性。RareFlow的核心是一个双条件结构，它通过门控控制网络保持低分辨率输入的细微几何保真度，并通过文本提示来提供合成复杂特征的语义指导。为确保输出的物理一致性，引入了一个多层损失函数，该函数强制实施与传感器特性的光谱和辐射特性的一致性。另外，框架通过采用随机前向传播的方法量化其自身的预测不确定性，这种方法导致的输出方差可以直接识别出不熟悉的输入，从而减轻特征幻觉。", "innovation": "RareFlow引入了一种双条件架构，其中门控控制网络保持低分辨率输入的细节几何保真度，而文本提示则提供了合成复杂特性的语义指导。为了确保物理一致性，该框架引入了一个多层次的损失函数，确保输出与传感器特性在光谱和辐射度上的一致性。此外，框架通过随机前向传播的方法来量化自身的预测不确定性，这种输出方差可以直接识别不熟悉的输入，从而减轻特征幻觉。", "conclusion": "RareFlow提供了一种在数据稀缺的科学研究领域进行高保真合成的稳健框架，并提供了一种在严重领域偏移下进行受控生成的新范式。在新的多传感器卫星图像基准测试中，地物理专家对模型输出的评估接近真实图像的保真度，显著优于最先进的基线方法。这一定性的优势也通过感知指标的定量增加得到了验证，包括FID降低了近40%。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.23311", "html_url": "https://arxiv.org/abs/2509.23311", "title": "识别符号，忽视文化：视觉-语言模型在火灾图像和文化意义推理中的表现", "title_en": "Seeing Symbols, Missing Cultures: Probing Vision-Language Models' Reasoning on Fire Imagery and Cultural Meaning", "authors": "Haorui Yu,Yang Zhao,Yijia Chu,Qiufeng Yi", "background": "视觉-语言模型（VLMs）通常在文化表现上显得得当，但实际上依赖于表面的模式匹配而非真正的文化理解。本文通过分类和解释分析，提出了一种诊断框架，用于检验模型在涉及火灾主题的文化图像推理中的缺陷，揭示了模型在识别西方节日、非西方传统以及紧急事件方面的系统性偏见。这些发现提示了仅依赖准确度指标对模型进行评估的限制，强调了需要在确保解释性和公平性方面进行文化评估的重要性。", "innovation": "本文引入了一种诊断框架，用于评估视觉-语言模型在涉及火灾主题的文化图像中的推理能力，特别是通过分类和解释分析，揭示了模型存在的系统性偏见和符号捷径问题。这种方法能够更深入地理解模型的文化理解能力，为改善这些系统的多样性和公平性提供了新的视角。", "conclusion": "研究结果指出，视觉-语言模型在处理文化相关的火灾主题图像时存在严重的系统性偏见和过度依赖表面模式匹配的问题。为了确保这些系统的解释性和公平性，研究强调了需要超越仅靠准确度指标的文化评估。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23929", "html_url": "https://arxiv.org/abs/2510.23929", "title": "TurboPortrait3D：基于单步扩散的快速人像新视角合成", "title_en": "TurboPortrait3D: Single-step diffusion-based fast portrait novel-view synthesis", "authors": "Emily Kim,Julieta Martinez,Timur Bagautdinov,Jessica Hodgins", "background": "现有的图像到3D的人像生成模型虽然能够生成可用的3D表示，但容易出现视觉伪影，缺乏细节，并且往往无法完全保留主题的身份。另一方面，图像扩散模型在生成高质量图像方面表现出色，但由于计算成本高且不基于3D，因此无法直接生成多视角一致的输出。", "innovation": "本研究展示了如何利用图像空间扩散模型显著提高现有图像到头像方法的质量，同时保持3D感知并在低延迟下运行。此外，还提出了一种新颖有效的训练策略，包括在大量合成的多视角数据上预训练，然后在高质量的真实图像上进行微调，从而实现高效的人像新视角合成。", "conclusion": "我们的方法在时间效率方面优于现有的最先进的方法，并且在定性和定量上都表现出色，实现了快速、高质量的人像新视角合成。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.16724", "html_url": "https://arxiv.org/abs/2510.16724", "title": "基于强化学习的自主搜索综述：基础、功能、优化、评估和应用", "title_en": "A Comprehensive Survey on Reinforcement Learning-based Agentic Search: Foundations, Roles, Optimizations, Evaluations, and Applications", "authors": "Minhua Lin,Zongyu Wu,Zhichao Xu,Hui Liu,Xianfeng Tang,Qi He,Charu Aggarwal,Hui Liu,Xiang Zhang,Suhang Wang", "background": "大型语言模型（LLMs）通过开放性的自然语言交互改变了信息获取和推理，但这些模型仍然受限于静态知识、事实性幻觉以及无法检索实时或领域特定信息。检索增强生成（RAG）通过将模型输出与外部证据相结合来缓解这些问题，但传统的RAG管道往往是单步骤且启发式的，缺乏对检索和推理过程的适应性控制。最近在自主搜索方面的进展通过多步骤与搜索环境互动来解决这些限制，增强了LLMs的计划、检索和反思能力。自主搜索范式中，强化学习（RL）为自适应和自我改善的搜索行为提供了强大的机制。", "innovation": "该综述对基于强化学习的自主搜索进行了全面概述，通过三个互补维度组织领域新兴的研究：(i) RL的功能角色，(ii) RL的使用方法，(iii) RL的应用范围。总结了代表性方法、评估协议和应用案例，讨论了构建可靠和可扩展的由RL驱动的自主搜索系统面临的挑战和发展方向，以期促进RL与自主搜索的集成研究。", "conclusion": "该综述旨在为未来的研究提供灵感，促进RL与自主搜索的整合。研究人员可通过访问文末提供的仓库了解更多详细信息。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23943", "html_url": "https://arxiv.org/abs/2510.23943", "title": "通过剪枝和密度化进行INR的自适应训练", "title_en": "Adaptive Training of INRs via Pruning and Densification", "authors": "Diana Aldana,João Paulo Lima,Daniel Csillag,Daniel Perazzo,Haoan Feng,Luiz Velho,Tiago Novello", "background": "现有的隐神经表示（INRs）方法通过将输入坐标编码为正弦函数输入多层感知器（MLPs）来表示低维信号，能够模拟高频细节，但是选择适当的输入频率和架构并管理参数冗余仍然是一个挑战，通常需要依靠启发式方法和大量的超参数优化。", "innovation": "本文提出了一种自适应训练方案AIRe（Adaptive Implicit Neural Representation），它通过神经元剪枝机制避免冗余，并通过增加输入频率来提高表示容量，从而在模型规模和重建质量之间实现了更好的平衡。", "conclusion": "通过在图像和SDF数据集上的实验表明，AIRe能够减小模型规模，同时保持或改善重建质量。该研究成果的代码和预训练模型将被公开发布。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23930", "html_url": "https://arxiv.org/abs/2510.23930", "title": "PlanarGS: 高保真室内3D高斯散点图表示，由视觉语言平面先验引导", "title_en": "PlanarGS: High-Fidelity Indoor 3D Gaussian Splatting Guided by Vision-Language Planar Priors", "authors": "Xirui Jin,Renbiao Jin,Boying Li,Danping Zou,Wenxian Yu", "background": "3D高斯散点图（3DGS）近年来成为新兴的新型视角合成高效表示形式，能够实现高质量的视觉效果。但当场景中有大面积低纹理区域时，特别是在室内环境中，优化3DGS的光度损失会导致几何混乱，难以恢复高保真3D表面。", "innovation": "论文引入了PlanarGS，这是一种专为室内场景重建设计的基于3DGS的框架。设计了一个包含视觉语言分割模型预训练和多视图融合以及几何先验检查的平面先验引导（LP3）管道，对3D高斯分布增加了两个额外的优化项：平面先验监督项和几何先验监督项，强制高斯分布平面一致并倾向于深度和法线线索，从而提高重建质量。", "conclusion": "通过在标准室内基准测试上的实验，结果显示PlanarGS在重建3D表面的准确性与详细程度上均优于当前最先进的方法，表现出了显著的优势。"}
{"llm_update_time": "20251029", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.22162", "html_url": "https://arxiv.org/abs/2510.22162", "title": "表面阅读LLMs：合成文本及其风格", "title_en": "Surface Reading LLMs: Synthetic Text and its Styles", "authors": "Hannes Bajohr", "background": "尽管机器学习（ML）的进步可能达到 plateau，社会影响更多体现在大语言模型生成的人类难以区别的文本表面，而非接近超智能。现有批判性人工智能研究提供了重要的材料和技术和社会批评，但忽视了大语言模型如何从现象学上重塑意义建构。因此，本文提出一种“表面完整性”符号学，关注LLMs如何将其嵌入人类交流的即时平面。文章区分了机器学习研究中的三种知识兴趣（认识论、本体论和语用论），并主张将表面风格分析与深度导向批评相结合。通过两个案例研究，文章探讨了合成文本风格标记，揭示了LLMs作为文化行动者在当代话语中影响意义产生和传播条件的表现，而不涉及机器意识问题。", "innovation": "提出了“表面完整性”符号学的概念，关注大语言模型在人类交流中的即时平面；区分了机器学习研究中的认识论、本体论和语用论三种知识兴趣，并倡导表面风格分析与深度导向批评相结合的方法；通过两个案例研究，揭示了LLMs作为文化行动者在影响意义产生和传播条件上的独立作用；强调了LLMs在当代话语中的文化影响，而不受机器意识问题的影响。", "conclusion": "通过对合成文本风格的细致考察，这篇文章揭示了大语言模型作为文化行动者在当代话语中重塑意义产生和流通条件的角色。这一研究扩展了我们对大语言模型的社会影响的理解，强调了从表面角度分析其风格的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23956", "html_url": "https://arxiv.org/abs/2510.23956", "title": "Neural USD: 一种以对象为中心的框架，用于迭代编辑和控制", "title_en": "Neural USD: An object-centric framework for iterative editing and control", "authors": "Alejandro Escontrela,Shrinu Kushagra,Sjoerd van Steenkiste,Yulia Rubanova,Aleksander Holynski,Kelsey Allen,Kevin Murphy,Thomas Kipf", "background": "可控生成建模取得了显著进展，尤其是在过去的几年中。然而，仍存在一些挑战，特别是精确和迭代的对象编辑问题。目前许多方法在通过改变条件信号来尝试编辑生成的图像时（例如，在场景中改变特定对象的颜色或更改背景同时保持其他元素不变），经常会引发场景中的意外全局变化。", "innovation": "从计算机图形社区开发的通用场景描述（USD）标准中汲取灵感，我们引入了“神经通用场景描述”或Neural USD。在这一框架中，我们以结构化和分层次的方式表示场景和对象，这有助于容纳多样化的信号，减少模型特定的约束，并允许对每个对象的外观、几何形状和姿态进行单独控制。我们进一步采用了一种精细化调优方法，以确保上述控制信号彼此分离。", "conclusion": "我们验证了该框架的几种设计方案，展示了Neural USD如何使迭代和增量工作流程成为可能。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23960", "html_url": "https://arxiv.org/abs/2510.23960", "title": "SafeVision：具有强大策略遵从性和可解释性的高效图像护栏", "title_en": "SafeVision: Efficient Image Guardrail with Robust Policy Adherence and Explainability", "authors": "Peiyang Xu,Minzhou Pan,Zhaorun Chen,Shuang Yang,Chaowei Xiao,Bo Li", "background": "随着数字媒体的迅速增长，确保内容安全、高效且透明的需求变得更加重要。传统的图像护栏模型由于依赖预定义类别而限制了灵活性，纯粹基于特征的学习往往缺乏语义推理，容易误分类。此外，它们难以应对新出现的威胁，导致需要高成本的重新训练。", "innovation": "我们提出了SafeVision，这是一种结合人类逻辑推理的新型图像护栏，旨在提高适应性和透明度。SafeVision包含有效的数据收集和生成框架、遵循政策的训练管道以及定制化的损失函数。此外，我们还提出了一种多样化的QA生成和训练策略以增强学习效果。SafeVision能够在推理时动态调整，无需重新训练，提供准确的风险评估和解释。我们还引入了VisionHarm数据集，旨在弥补现有无害图像基准的不足，包括VisionHarm Third-party和VisionHarm Comprehensive两个子集。", "conclusion": "SafeVision在不同的基准测试上达到了最先进的性能，在VisionHarm-T上超越GPT-4o 8.6%，在VisionHarm-C上超越15.5%，同时运行速度快16倍。SafeVision提供了全面、遵循政策的且具有可解释性的图像护栏，能够应对新兴威胁的动态适应。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23978", "html_url": "https://arxiv.org/abs/2510.23978", "title": "使用傅里叶约束实现高效可调控任意尺度超分辨率", "title_en": "Efficient Cost-and-Quality Controllable Arbitrary-scale Super-resolution with Fourier Constraints", "authors": "Kazutoshi Akita,Norimichi Ukita", "background": "在任意尺度的超分辨率领域，成本和质量的可控性至关重要。现有方法使用递归神经网络逐个预测傅里叶成分，这导致性能下降和低效，因为这是独立预测的结果。", "innovation": "本文提出了一种新的方法，即共同预测多个傅里叶成分以提高质量和效率。这种方法通过联合预测解决了独立预测带来的问题，从而提升整体性能和效率。", "conclusion": "通过采用新的共同预测傅里叶成分的方法，本文实现了高效且可控的任意尺度超分辨率。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23968", "html_url": "https://arxiv.org/abs/2510.23968", "title": "胸部X光分析的推理视觉语言模型", "title_en": "Reasoning Visual Language Model for Chest X-Ray Analysis", "authors": "Andriy Myronenko,Dong Yang,Baris Turkbey,Mariam Aboian,Sena Azamat,Esra Akcicek,Hongxu Yin,Pavlo Molchanov,Marc Edgar,Yufan He,Pengfei Guo,Yucheng Tang,Daguang Xu", "background": "视觉-语言模型(VLMs)在医学图像分析中显示出了强大的潜力，但大多数VLMs仍具有不透明性，无法提供透明的、逐步的推理过程，这正是临床医生所依赖的。本文介绍了将逐步推理(CoT)引入胸部X光解读的框架。该框架借鉴了推理优先训练范式，旨在通过与可观察的影像证据和放射学工作流程对齐中间步骤来学习专家如何推理，而不是仅学习他们得出的结论。这种方法不仅提高了准确性，还通过明确的推理痕迹支持临床审计：它们揭示了结论是如何得出的，考虑了哪些替代方案，以及仍存在的不确定性，从而促进质量保证、错误分析和人类-AI协作的安全性。", "innovation": "本文提出的方法包括以下几个创新点：1) 以逐步推理为中心的训练范式，学习专家的推理过程，而不是仅仅学习他们的结论；2) 高保真视觉编码与两阶段训练配方相结合，包括推理风格的监督微调和基于X光异常列表的可验证奖励强化学习；3) 输出的推理过程与放射科医生系统的思维过程、不确定性及鉴别诊断相匹配；4) 通过补充外部数据的评估，实现了具有竞争力的多标签分类，并提升了可解释性；5) 在放射专家的阅读研究中，完整的推理痕迹增加了信心，支持了错误审计，并减少了完成报告所需的时间。", "conclusion": "该模型在分布外评估中实现了有竞争力的多标签分类性能，提高了可解释性，在放射专家的阅读研究中增强了信心，支持了错误审计，并减少了完成报告所需的时间。本文还公开了代码和模型NV-Reason-CXR-3B，以支持在胸部放射摄影和其他医学成像任务中的可信、可解释AI的社区进展。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24009", "html_url": "https://arxiv.org/abs/2510.24009", "title": "从多中心获取自动分割、建模和网格化腹主动脉血管树：SEG.A. 2023腹主动脉分割挑战的概述", "title_en": "Towards the Automatic Segmentation, Modeling and Meshing of the Aortic Vessel Tree from Multicenter Acquisitions: An Overview of the SEG.A. 2023 Segmentation of the Aorta Challenge", "authors": "Yuan Jin,Antonio Pepe,Gian Marco Melito,Yuxuan Chen,Yunsu Byeon,Hyeseong Kim,Kyungwon Kim,Doohyun Park,Euijoon Choi,Dosik Hwang,Andriy Myronenko,Dong Yang,Yufan He,Daguang Xu,Ayman El-Ghotni,Mohamed Nabil,Hossam El-Kady,Ahmed Ayyad,Amr Nasr,Marek Wodzinski,Henning Müller,Hyeongyu Kim,Yejee Shin,Abbas Khan,Muhammad Asad,Alexander Zolotarev,Caroline Roney,Anthony Mathur,Martin Benning,Gregory Slabaugh,Theodoros Panagiotis Vagenas,Konstantinos Georgas,George K. Matsopoulos,Jihan Zhang,Zhen Zhang,Liqin Huang,Christian Mayer,Heinrich Mächler,Jan Egger", "background": "腹主动脉血管树（AVT）的CT血管造影（CTA）自动分析具有巨大的临床潜力，但其发展受到了共享高质量数据不足的阻碍。为促进这一领域的进步，我们发起了SEG.A.挑战，通过引入一个大型的、公共可用的、多机构的数据集来用于AVT分割。评估重点是自动算法在隐藏的测试集上的性能，后续还有一些可选任务，包括表面网格化以供计算模拟。研究发现，大多数顶尖提交都采用了深度学习方法，特别是3D U-Net架构；集合多个高排名算法的模型性能显著优于单一模型，表明模型融合的优势。", "innovation": "引入了大规模、公开可用、多机构的AVT分割数据集；通过隐藏测试集评估自动算法的性能；发现3D U-Net架构在顶尖提交中占据主导地位；集合高排名算法的模型性能优于单一模型，强调了模型融合的重要性；性能与算法设计、定制后处理步骤以及训练数据的特性密切相关。", "conclusion": "这项倡议不仅建立了新的性能基准，还提供了推动未来创新、研发临床可转移工具的持久资源。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24000", "html_url": "https://arxiv.org/abs/2510.24000", "title": "AdvBlur: 对抗模糊化在鲁棒糖尿病视网膜病变分类和跨域泛化的应用", "title_en": "AdvBlur: Adversarial Blur for Robust Diabetic Retinopathy Classification and Cross-Domain Generalization", "authors": "Heethanjan Kanagalingam,Thenukan Pathmanathan,Mokeeshan Vathanakumar,Tharmakulasingam Mukunthan", "background": "糖尿病视网膜病变（DR）是全球视力丧失的主要原因之一。早期和准确的检测可以显著提高治疗效果。尽管许多基于深度学习（DL）的模型可以从眼底图像中预测DR，但由于设备差异、人口统计数据和成像条件导致的分布差异，这些模型在保持鲁棒性方面面临挑战。", "innovation": "本文提出了一种新的糖尿病视网膜病变分类方法，称为AdvBlur。该方法通过将对抗模糊图像集成到数据集中，并采用双损失函数框架来解决域泛化问题。这种方法有效地减轻了未见分布差异的影响，实验证明其在多个数据集上的表现良好。本文还进行了广泛的实验，探索了相机类型、低质量图像和数据集大小等因素的影响，并进行了消融实验以验证模型的选择。", "conclusion": "实验结果表明，AdvBlur方法在不常见外部数据集上具有竞争力的性能，证明了其在糖尿病视网膜病变分类和跨域泛化方面的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23981", "html_url": "https://arxiv.org/abs/2510.23981", "title": "TeleEgo: 在野外评估自中心AI助理", "title_en": "TeleEgo: Benchmarking Egocentric AI Assistants in the Wild", "authors": "Jiaqi Yan,Ruilong Ren,Jingren Liu,Shuning Xu,Ling Wang,Yiheng Wang,Yun Wang,Long Zhang,Xiangyu Chen,Changzhi Sun,Jixiang Luo,Dell Zhang,Hao Sun,Chi Zhang,Xuelong Li", "background": "在真实世界环境中，自中心AI助理需要处理多种模态输入（视频、音频、文本），实时响应，并保持长期记忆。然而，现有的基准测试通常是在孤立环境中评估这些能力，缺乏实际的流式传输场景，或仅支持短期任务。因此，需要一个长期、流式传输、多模态的基准测试来评估在现实日常生活情景下的自中心AI助理的表现。", "innovation": "介绍了TeleEgo，这是一个为了评估自中心AI助理在现实日常生活情景下的一个长期、流式传输、多模态基准。数据集包括四个领域超过14小时的同步自中心视频、音频和文本：工作&学习、生活方式&日常、社交活动、外出&文化。定义了12个诊断子任务，涵盖了三个核心能力：记忆、理解、跨记忆推理。同时提出两个关键的评估指标——实时准确性和记忆持久时间，这有助于衡量正确性、时间响应性和长期保持能力。TeleEgo提供了一个现实且全面的评估，以促进实用AI助理的发展", "conclusion": "TeleEgo提供了一个现实且全面的评估方案，旨在推动实用自中心AI助理的发展。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24010", "html_url": "https://arxiv.org/abs/2510.24010", "title": "Mars-Bench：用于评价火星科学任务基础模型的标准基准", "title_en": "Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks", "authors": "Mirali Purohit,Bimal Gajera,Vatsal Malaviya,Irish Mehta,Kunal Kasodekar,Jacob Adler,Steven Lu,Umaa Rebbapragada,Hannah Kerner", "background": "基础模型通过大规模未标记数据预训练，在许多专门领域迅速取得了显著进展，展示了对多种下游任务的强适应性。尽管地球观测等领域已经广泛应用于基础模型，但火星科学领域的应用仍然有限。其他领域快速进步的一个关键因素是标准化基准的支持，使得系统评价成为可能。然而，火星科学中缺乏这样的基准和标准化评估框架，阻碍了针对火星任务的基础模型开发。", "innovation": "该研究介绍了Mars-Bench，这对于系统性评估跨越广泛的火星相关任务的模型（包括轨道和表面图像）是一个首创的基准。该基准包括20个涵盖分类、分割和对象检测的数据集，侧重于地学特征如陨石坑、圆锥、岩石和霜冻。所有数据集和用于基准评估的预训练模型均标准化和预处理完毕，可用作基础模型的测试床，提供了地球图像、地球卫星数据和最新视觉-语言模型的预训练基础。研究结果表明，针对火星特定任务开发的模型可能优于通用领域模型，促进了领域适应性预训练的进一步探索。", "conclusion": "Mars-Bench旨在为开发和比较用于火星科学的机器学习模型建立标准化基础。该研究团队提供的数据、模型和代码可以在指定的链接访问。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24036", "html_url": "https://arxiv.org/abs/2510.24036", "title": "残差学习使深层卷积神经网络成为可能", "title_en": "ResNet: Enabling Deep Convolutional Neural Networks through Residual Learning", "authors": "Xingyu Liu,Kun Ming Goh", "background": "卷积神经网络(CNNs)已彻底改变了计算机视觉领域，但训练非常深的网络由于梯度消失问题而颇具挑战性。", "innovation": "论文探讨了He等人在2015年引入的残差网络（ResNet），通过使用跳过连接解决了这一问题。ResNet允许训练具有数百层的网络，从而直接通过略过中间层的快捷连接来使梯度流通。", "conclusion": "在CIFAR-10数据集上的实现结果显示，ResNet-18的准确率达到了89.9%，而同等深度的传统深层CNN的准确率为84.1%，并且它还能更快地收敛并更稳定地训练。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24034", "html_url": "https://arxiv.org/abs/2510.24034", "title": "AutoPrompt：通过基于LLM的对抗提示自动生成红队测试的文本对图片模型", "title_en": "AutoPrompt: Automated Red-Teaming of Text-to-Image Models via LLM-Driven Adversarial Prompts", "authors": "Yufan Liu,Wanqian Zhang,Huashan Chen,Lin Wang,Xiaojun Jia,Zheng Lin,Weiping Wang", "background": "尽管在文本生成图片（T2I）模型方面取得了快速进展，但这些模型的安全机制仍易受到恶意提示的攻击，导致违规的图像生成。现有的红队评估方法通常需要对T2I模型有白盒访问权限，并依赖于效率低下的逐提示优化，同时很容易生成被过滤器屏蔽的语义空泛的提示。", "innovation": "本文提出了APT（AutoPrompT），一种黑盒框架，利用大型语言模型（LLMs）自动生成易于理解的对抗后缀，针对良性提示。该框架采用交替优化微调管道，并在优化阶段集成了一种双重回避策略，用于绕过基于困惑度的滤镜和黑名单词汇滤镜。此外，还引入了禁止词汇惩罚以抑制黑名单中显式生成的禁止词汇。", "conclusion": "广泛实验表明，我们的可读人工对抗提示具有优秀的红队测试性能，并且具有出色的零样本迁移性能，能够立即适应未见过的提示，并在商业API（例如上述链接）中揭示关键漏洞。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23907", "html_url": "https://arxiv.org/abs/2510.23907", "title": "DynaStride：基于MMCoT的动态窗口分割多场景指令视频字幕生成", "title_en": "DynaStride: Dynamic Stride Windowing with MMCoT for Instructional Multi-Scene Captioning", "authors": "Eddison Pham,Prisha Priyadarshini,Adrian Maliackel,Kanishk Bandi,Cristian Meo,Kevin Zhu", "background": "场景级字幕在教学视频中可以通过促进对视觉线索和时间结构的理解来增强学习效果。通过将视觉线索与文本指导对接，这种理解有助于程序性学习和多模态推理，从而为技能获取提供更丰富的上下文。然而，如果字幕未能捕捉这些结构，可能会缺乏连贯性和质量，从而造成混淆并削弱视频的教学意图。为了解决这一差距，我们引入了DynaStride，一种无需人工场景分割即可生成连贯的场景级字幕的流水线。通过使用YouCookII数据集中场景注释，DynaStride进行自适应帧采样和多模态窗口化，以捕获每个场景中的关键过渡。然后，它采用多模态的问题推理过程，产生多个动作-对象对，这些对通过动态步长窗口选择算法进行优化和融合，该算法能够适当地平衡时间上下文和冗余。最终，场景级字幕将视觉语义和时间推理整合到一个教学字幕中。", "innovation": "DynaStride无需手动场景分割，通过自适应框架采样和多模态窗口化捕捉场景内的关键过渡，并使用动态步长窗口选择算法优化和融合动作-对象对，生成连贯的场景级字幕。该算法在多模态链式推理过程中产生多个动作-对象对，并通过动态步长窗口选择算法，适当地平衡了时间上下文和冗余。该方法在YouCookII数据集中场景注释的辅助下进行，最终生成的场景级字幕集成了视觉语义和时间推理。", "conclusion": "DynaStride在基于N-gram的指标（BLEU、METEOR）和语义相似度度量（BERTScore、CLIPScore）上均比强基线（包括VLLaMA3和GPT-4o）取得一致性的提升。定性分析进一步表明，DynaStride生成的字幕更加时间连贯和信息丰富，表明其在改进AI驱动的指令性内容生成方面具有前景。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24117", "html_url": "https://arxiv.org/abs/2510.24117", "title": "DogMo: 多视角RGB-D数据集用于4D犬类运动恢复", "title_en": "DogMo: A Large-Scale Multi-View RGB-D Dataset for 4D Canine Motion Recovery", "authors": "Zan Wang,Siyu Chen,Luya Mo,Xinfeng Gao,Yuxin Shen,Lebin Ding,Wei Liang", "background": "现有的狗运动数据集存在多视角和真实三维数据缺乏、规模有限和多样性不足等问题，限制了狗的运动恢复研究。", "innovation": "DogMo数据集是大规模多视角RGB-D视频数据集，包含来自10只不同品种狗的1200个运动序列，具有丰富的运动和品种多样性。通过DogMo，建立了四个运动恢复基准设置，并提出了三阶段实例特定优化管道，逐步优化体形和姿态。", "conclusion": "DogMo数据集与方法为狗运动恢复研究提供了有原则的基础，并促进了计算机视觉、计算机图形学和动物行为建模的交叉领域的新方向。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24105", "html_url": "https://arxiv.org/abs/2510.24105", "title": "提升预训练表示的分类能力可以增强其可解释性", "title_en": "Enhancing Pre-trained Representation Classifiability can Boost its Interpretability", "authors": "Shufan Shen,Zhaobo Qi,Junshu Sun,Qingming Huang,Qi Tian,Shuhui Wang", "background": "预训练视觉模型在下游任务中的广泛应用对表示的可解释性提出了新的要求。然而，目前尚未明确预训练表示能否同时具备高可解释性和分类能力。已有研究表明，可解释性与分类能力可能存在正相关关系，但这一关系及其在实际应用中的意义仍需进一步研究和验证。", "innovation": "本文提出了内在可解释性评分（IIS），该评分评估信息损失、衡量可解释性语义的比例，并量化表示的可解释性。实验结果揭示了可解释性与分类能力间存在正相关关系，并验证了通过最大化可解释性进行微调可以提高表示的分类能力，同时以较少的准确性损失获得基于解释的预测。这一发现表明，用户可以统一提高预训练视觉模型的可解释性和分类能力。", "conclusion": "研究结果支持通过提升预训练模型的分类能力来增强其可解释性。未来工作的重点可以是进一步探索基于微调来优化预训练模型的方法。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24037", "html_url": "https://arxiv.org/abs/2510.24037", "title": "具有双层参数竞争的核化稀疏微调方法", "title_en": "Kernelized Sparse Fine-Tuning with Bi-level Parameter Competition for Vision Models", "authors": "Shufan Shen,Junshu Sun,Shuhui Wang,Qingming Huang", "background": "参数高效微调（PEFT）的目标是适应预训练的视觉模型以应对下游任务。目前，稀疏调整是最显着提高性能的方法，因为它通过仅调整与下游任务最相关的权重，而不是稠密调整整个权重矩阵，实现了卓越的效果。现有的方法遵循两阶段流程：首先通过梯度信息定位相关权重，但忽略了微调过程中的参数调整，限制了性能；其次，通过应用稀疏掩码更新仅定位的权重，这导致由于在优化器中存储所有权重矩阵而导致的高内存使用率。该论文旨在解决这些局限性并提出了一种新方法SNELLA。", "innovation": "SNELLA提出了一种一阶段方法，通过将权重矩阵与两个低秩可学习矩阵合并而成的另一个稀疏矩阵相加，选择性地更新权重矩阵，从而降低内存使用率。此外，通过引入非线性核函数扩展低秩分解，增加合并矩阵的秩，防止更新之间的依赖性，从而更好地适应下游任务。为了找到相关权重，SNELLA提出了一种基于重要性得分的全能双层参数竞争机制，鼓励权重在跨层和内层之间的竞争。实验结果展示，使用不同预训练视觉模型在分类、分割和生成任务中，SNELLA达到了最佳性能，同时具有较低的内存使用率。与前一种方法SPT-LoRA相比，SNELLA在FGVC基准上的Top-1精度高出了1.8%（91.9%相较于90.1%）。与相比之前的大多数方法，SNELLA在参数量从86M到632M的模型中，内存减少31.1%-39.9%。", "conclusion": "通过提出SNELLA方法，该论文显著改善了参数高效微调任务中的性能和内存使用率，展示了其在视觉模型任务中的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24038", "html_url": "https://arxiv.org/abs/2510.24038", "title": "通过跨模态对齐增强CLIP的鲁棒性", "title_en": "Enhancing CLIP Robustness via Cross-Modality Alignment", "authors": "Xingyu Zhu,Beier Zhu,Shuo Wang,Kesen Zhao,Hanwang Zhang", "background": "视觉-语言模型（VLMs）如CLIP在零样本分类中表现出很强的泛化能力，但对对抗性扰动非常脆弱。现有方法主要集中在对抗性微调或提示优化，却往往忽视了CLIP编码特征中的差距，即文本和图像特征之间的距离较大。在对抗性扰动下，这种不匹配会显著加剧，导致分类性能严重下降。", "innovation": "该文提出了Cross-modality Alignment（COLA），一种基于最佳运输的框架，通过恢复全局图像-文本对齐和局部结构一致性来显式地解决对抗性不匹配问题。首先，COLA将对抗性图像嵌入投影到由类别文本特征构成的子空间上，有效滤除非语义扰动并保留判别信息；然后，它将图像和文本建模为在多个增强视图上以离散分布的形式，通过最优运输（OT）调整它们的对齐，同时将子空间投影无缝集成到成本计算中，确保即使在对抗性条件下也能实现稳定的跨模态对齐。COLA是一种无需训练的方法，并且与现有的微调模型兼容。一系列跨14个零样本分类基准的广泛评估证明了COLA的有效性，特别是在PGD对抗性攻击下，在ImageNet及其变体上平均提高了6.7%，同时在干净样本上保持了高精度。", "conclusion": "COLA通过恢复全局图像-文本对齐和局部结构一致性，显著提升了CLIP在对抗性扰动下的鲁棒性，同时在多个零样本分类基准上展示了其优越性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24078", "html_url": "https://arxiv.org/abs/2510.24078", "title": "超越物体：细粒度分类的上下文合成数据生成", "title_en": "Beyond Objects: Contextual Synthetic Data Generation for Fine-Grained Classification", "authors": "William Yang,Xindi Wu,Zhiwei Deng,Esin Tureci,Olga Russakovsky", "background": "文本到图像（T2I）模型在合成数据集生成中广泛应用，但对于分类任务的有效合成训练数据生成仍然具有挑战性。通过对几个真实样例进行细调，可以改善合成训练数据的质量，但这也可能引起过拟合并减少生成样本的多样性。研究表明，一种名为BOB（BeyondOBjects）的细调策略可以解决这些关注点。给定一组少量的真实样例，BOB首先提取无类别属性，如场景背景和物体姿态，然后在细调过程中显式地基于这些属性进行条件处理，并在生成时将这些属性消除。这种设计减少了过拟合，保持了T2I模型的生成先验，减少了估计误差，并进一步减少了无意的跨类别关联。", "innovation": "提出了一种名为BOB的细调策略，该策略通过提取无类别属性并显式地在细调过程中基于这些属性进行条件处理，从而解决传统方法的过拟合和减少多样性的问题。实验表明，BOB在细粒度分类任务中，特别是在使用合成数据增强后，取得了当前最佳性能，并且与以前的方法相比，在18个实验设置中有2%以上的准确度提升。", "conclusion": "通过BOB方法，使用少量真实图像及其基于合成数据的增强，当类间具有相同的5个真实图像时，细粒度分类模型的最终表现超过了使用10个真实图像的情况。在四个基准测试中，三种效果优于使用10个真实图像的情况。总体而言，BOB在24个实验设置中的18个中表现出色，其中有14个设置的准确度提高了2%以上。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24129", "html_url": "https://arxiv.org/abs/2510.24129", "title": "ETC：通过Error-aware Trend Consistency实现无训练加速的扩散模型", "title_en": "ETC: training-free diffusion models acceleration with Error-aware Trend Consistency", "authors": "Jiajian Xie,Hubery Yin,Chen Li,Zhou Zhao,Shengyu Zhang", "background": "扩散模型在生成质量方面取得了显著成果，但仍然受限于耗时的迭代采样过程。最近提出的一些无训练方法通过重复利用模型输出来加速扩散过程，但这些方法忽略了去噪趋势，缺乏针对特定模型的误差控制，这导致在多次重复使用过程中轨迹偏移，并加剧了生成结果的一致性问题。", "innovation": "提出了一种名为Error-aware Trend Consistency（ETC）的框架，它包括两个主要方面：首先，引入了一种一致趋势预测器，利用扩散轨迹的平滑连续性，将历史去噪模式投影到稳定未来方向，并逐步在多个逼近步骤中分配，以在无需偏离的情况下实现加速；其次，提出了一种模型特定的误差容限搜索机制，通过识别从语义规划的波动性过渡到稳定质量细化的过程中的转换点来推导纠正阈值。实验表明，ETC在FLUX上实现了2.65倍的加速，同时损失可以忽略不计的(-0.074 SSIM分数)一致性下降。", "conclusion": "ETC框架通过引入一致趋势预测和模型特定的误差容限搜索机制，有效解决了无训练扩散模型加速过程中存在的问题，实现了显著的加速效果并保持了高质量的一致性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24116", "html_url": "https://arxiv.org/abs/2510.24116", "title": "UHKD: 一种基于频率域表示的统一异构知识蒸馏框架", "title_en": "UHKD: A Unified Framework for Heterogeneous Knowledge Distillation via Frequency-Domain Representations", "authors": "Fengming Yu,Haiwei Pan,Kejia Zhang,Jian Guan,Haiying Jiang", "background": "知识蒸馏（KD）是一种有效的模型压缩技术，通过从高性能的“教师”模型向轻量级的“学生”模型传输知识，降低部署成本同时保持高精度。在视觉应用中，由于广泛使用大尺度图像模型，KD技术可以实现高效的部署。但在异构模型架构下，这种技术面临向量差异的问题，导致中间表示难以作用于异构的教师-学生模型对。现有大多数KD方法主要针对同构模型设计，性能在异构场景中会下降，特别是当涉及到特征图时。先前研究侧重于输出层，未能充分利用中间层中的语义信息。为解决上述问题，本文提出了一种称为统一异构知识蒸馏（UHKD）框架，该框架在频率域提取和利用中间特征，使用傅里叶变换捕捉全局特征信息，从而解决异构模型对间的表示差异问题。", "innovation": "UHKD框架利用中间特征在频率域进行跨架构的知识迁移，通过傅里叶变换捕捉全局特征信息，减轻异构教师-学生模型对之间的表示差异。设计了特征变换模块（FTM）产生教师特征的紧凑频率域表示，学习特征对齐模块（FAM）投影学生特征并利用多级匹配进行对齐。统一了基于中间特征的均方误差损失和输出层的Kullback-Leibler散度损失作为训练目标，以指导模型训练。实验结果表明，UHKD在CIFAR-100和ImageNet-1K数据集上分别比最新方法提高了5.59%和0.83%的准确率，验证了其统一异构表示和高效利用视觉知识的有效性。", "conclusion": "本文提出了一种名为UHKD的框架，通过频率域中的中间特征成功实现在异构模型架构上的知识蒸馏，实验结果展示了其在CIFAR-100和ImageNet-1K数据集上超越现有方法的表现，突显其作为一种有效方法的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24133", "html_url": "https://arxiv.org/abs/2510.24133", "title": "基于推断时缩放的成 compositional 图像合成", "title_en": "Compositional Image Synthesis with Inference-Time Scaling", "authors": "Minsuk Ji,Sanghyeok Lee,Namhyuk Ahn", "background": "尽管现代文本到图像模型在逼真度方面表现出色，但仍存在组合性的问题，经常无法准确渲染物体数量、属性和空间关系。本文旨在解决这一问题，提出了一种无需训练的框架，结合对象中心的方法与自我完善，以提高布局的真实性同时保持美学质量。具体来说，利用大型语言模型（LLMs）从输入提示中生成显式布局，并将这些布局注入图像生成过程，由对象中心的视觉语言模型（VLM）进行评估和重新排序，以迭代选择与提示最对齐的结果。通过将显式布局与基于自我完善的推断时缩放结合起来，该框架在场景对齐方面比最近的文本到图像模型更具优势。相关代码可在以下链接获取：this https URL", "innovation": "本文提出的框架结合了对象中心的方法与自我完善的机制，在生成图像时无需训练，利用大型语言模型从输入提示中生成显式布局，由对象中心的视觉语言模型进行评估和重新排序，以迭代选择最符合提示的内容，从而实现比现有文本到图像模型更强的场景对齐效果。", "conclusion": "通过统一显式的布局定位与基于自我完善的推断时缩放推理，本文提出的框架在场景与提示的对齐方面优于现有的文本到图像模型，展示了在成图像合成领域的创新方法。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24093", "html_url": "https://arxiv.org/abs/2510.24093", "title": "OmniText:无训练通用可控文本图像操作", "title_en": "OmniText: A Training-Free Generalist for Controllable Text-Image Manipulation", "authors": "Agus Gunawan,Samuel Teodoro,Yun Chen,Soo Ye Kim,Jihyong Oh,Munchurl Kim", "background": "基于扩散的文本合成最近在通过修复技术在图像中插入和编辑文本方面取得了显著的性能提升。然而，尽管文本修复方法具有潜力，但存在三大限制，阻碍了它们在更广泛的文本图像操作（Text Image Manipulation, TIM）任务中的应用：（i）无法删除文本，（ii）无法控制呈现文本的样式，（iii）容易生成重复的字母。为解决这些挑战，我们提出了OmniText，这是一种无需训练的一般性方法，能够执行广泛的TIM任务。具体地，我们研究了跨注意力机制和自我注意力机制的两种关键属性，以实现文本删除并提供文本样式的控制。我们的研究发现，通过应用自我注意力反转可以实现文本删除，这减轻了模型关注周围文本的倾向，从而减少了文本幻觉。我们还重新分配了跨注意力，以增加特定文本标记的概率来减少文本幻觉。为了实现可控的修复，我们引入了一种在潜优化框架中的新型损失函数：跨注意力内容损失以提高文本呈现准确性，和自我注意力样式损失以促进样式定制。此外，我们提出了OmniText-Bench基准数据集，用于评估各种TIM任务，包括输入图像、带有掩码的目标文本和样式参考，涵盖了多种应用，如文本删除、缩放、重新定位、插入和编辑，以及多种样式的文本操作。", "innovation": "我们提出了OmniText，这是一种无需训练的一般性方法，能够执行广泛的TIM任务。OmniText通过自我注意力反转实现文本删除，同时通过重新分配跨注意力减少文本幻觉。我们还引入了新型损失函数来促进文本呈现和样式的控制。此外，我们提出了OmniText-Bench基准数据集，用于评估TIM任务，涵盖了多种应用。", "conclusion": "我们的OmniText框架是首个能够执行多样化TIM任务的一般性方法。在多个任务和指标上，其性能达到了最先进的水平，并且与专门的方法相比具有可比性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG: 优化视频描述以实现文本转视频生成", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "文本转视频（T2V）生成领域的最新进展突显了高质量视频-文本对在训练能够生成连贯且与指令对齐的视频模型中的关键作用。然而，对于优化视频描述以适合T2V训练的策略仍然缺乏研究。", "innovation": "本文提出了VC4VG（视频描述优化视频生成），这是一种专门为T2V需求定制的全面的描述优化框架。该框架通过从T2V角度分析描述内容，将视频重建所需的重要元素分解为多个维度，并提出了一种有原则的描述设计方法来支持评估。同时，作者构建了VC4VG-Bench，这是一个新的基准测试，它包括细粒度、多维度和必要性分级的指标，这些指标与T2V特定要求对齐。", "conclusion": "T2V调整实验表明，改进描述质量与视频生成性能之间存在密切关联，这验证了本方法的有效性。所有基准工具和代码均可通过提供的链接获取，以支持进一步的研究。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24152", "html_url": "https://arxiv.org/abs/2510.24152", "title": "通过任务特定提示和空间推理增强视觉语言模型在自动驾驶中的应用", "title_en": "Enhancing Vision-Language Models for Autonomous Driving through Task-Specific Prompting and Spatial Reasoning", "authors": "Aodi Wu,Xubo Luo", "background": "本文档介绍了团队在2025年IROS RoboSense挑战赛中的解决方案，评估视觉-语言模型（VLMs）在自动驾驶场景理解上的表现，涵盖感知、预测、规划和异常检测任务。背景信息指出，当前的视觉-语言模型在这些任务中表现出一定的局限性，特别是对于复杂多变的自动驾驶场景，需要提供一种系统的方法来优化这些模型的表现。", "innovation": "本文提出了一个系统的框架，由四个核心组件构成。首先，Mixture-of-Prompts路由器能够将问题分类并分发给特定任务的专家提示，以消除不同问题类型之间的干扰。其次，每个特定任务的提示嵌入了明确的坐标系统、空间推理规则、角色扮演、链/树推理以及针对每个任务定制的少量示例。第三，视觉组装模块根据问题要求组合多视图图像、对象裁剪、品紫标记和自适应历史帧。第四，根据不同任务配置模型推理参数（温度、top-p、消息角色），以优化输出质量。该方法在Qwen2.5-VL-72B上实现，在第一阶段（干净数据）中实现了70.87%的平均准确性，在第二阶段（污染数据）中实现了72.85%的准确性。", "conclusion": "系统提示和空间定位显著提升了视觉-语言模型在关键安全任务中的性能，特别是在第二阶段的污染数据处理中表现出更优异的性能。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24195", "html_url": "https://arxiv.org/abs/2510.24195", "title": "消失于无形：针对SAM2的跨提示通用对抗攻击", "title_en": "Vanish into Thin Air: Cross-prompt Universal Adversarial Attacks for SAM2", "authors": "Ziqi Zhou,Yifan Hu,Yufei Song,Zijing Li,Shengshan Hu,Leo Yu Zhang,Dezhong Yao,Long Zheng,Hai Jin", "background": "近期研究揭示了图像分割基础模型SAM对对抗样本的脆弱性。SAM的继任者SAM2因其在视频分割中的强大泛化能力引起了广泛关注，但其鲁棒性尚未得到探索。目前尚不清楚针对SAM的现有攻击是否可以直接应用于SAM2。", "innovation": "该论文首先分析了现有攻击在SAM与SAM2之间的性能差距，并指出由于其架构差异产生的两个关键挑战：来自提示的方向指导以及连续帧间的语义纠缠。为解决这些问题，提出了一种基于双语义偏差的跨提示通用对抗攻击UAP-SAM2。方法包括：一种目标扫描策略，将每帧分为k个区域，各随机分配一个提示，以减少优化过程中的提示依赖性；以及一种双语义偏差框架，该框架通过扭曲当前帧内的语义并通过破坏连续帧间的语义一致性来优化UAP。", "conclusion": "通过在六个数据集上的广泛实验，结果表明所提出的方法对于SAM2的有效性。对比结果表明，UAP-SAM2在很大程度上优于现有的最先进的（SOTA）攻击方法。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24202", "html_url": "https://arxiv.org/abs/2510.24202", "title": "CLFSeg：基于模糊逻辑的医学图像分割边界清晰性和不确定性减少解决方案", "title_en": "CLFSeg: A Fuzzy-Logic based Solution for Boundary Clarity and Uncertainty Reduction in Medical Image Segmentation", "authors": "Anshul Kaushal,Kunal Jangid,Vinod K. Kurmi", "background": "早期检测和治疗对癌症类疾病诊断和治疗计划至关重要，但传统基于卷积神经网络（CNN）的方法在泛化能力、鲁棒性和处理不确定性方面有限，影响了分割性能。", "innovation": "CLFSeg 通过引入模糊卷积（FC）模块，结合卷积层和模糊逻辑，构建了一个编码器-解码器框架。该模型通过识别局部和全局特征来提升分割性能，同时最小化边界区域的不确定性、噪声和模糊性，确保计算效率，并通过二元交叉熵（BCE）结合Dice损失来处理类别不平衡问题，专注于感兴趣区域。", "conclusion": "CLFSeg 在四个公开数据集（CVC-ColonDB、CVC-ClinicDB、EtisLaribPolypDB 和 ACDC）上表现出色，实验和视觉研究显示其超越了现有的最佳表现，并且关注于解剖结构的相关感兴趣区域。该模型提高了性能，同时保持了计算效率，可以用于实际的医疗诊断场景。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24136", "html_url": "https://arxiv.org/abs/2510.24136", "title": "MSRANetV2：一种用于结肠直肠组织病理图像多类别分类的可解释深度学习架构", "title_en": "MSRANetV2: An Explainable Deep Learning Architecture for Multi-class Classification of Colorectal Histopathological Images", "authors": "Ovi Sarkar,Md Shafiuzzaman,Md. Faysal Ahamed,Golam Mahmud,Muhammad E. H. Chowdhury", "background": "结直肠癌（CRC）是导致癌症死亡的主要原因之一，早期准确检测对提高患者预后至关重要。然而，传统诊断方法如肠镜检查和组织学检查存在主观性、耗时且易受变异性影响。基于数字病理学的发展，深度学习算法在提升诊断精确度和效率方面成为强有力的方法。本文背景即是在这一背景下讨论如何利用深度学习技术改进CRC的诊断方法，进而提升患者待遇。", "innovation": "本文提出了一种特别为结直肠组织图像分类优化的卷积神经网络架构——MSRANetV2。该模型采用了ResNet50V2作为主干网，并扩展了残差注意力机制和squeeze-and-excitation（SE）块，以提取深层次语义和细粒度的空间特征。通过通道对齐和上采样操作，MSRANetV2能够有效融合多尺度表示，从而增强分类的鲁棒性。此外，研究还整合了Grad-CAM可视化方法以提高模型的可解释性，通过突出显示医学相关的组织区域来实现这一目标。这些创新点使得MSRANetV2在外科病理图像分类中表现出卓越的性能。", "conclusion": "实验结果证明，MSRANetV2不仅能够实现高度准确的CRC组织图像分类，其在7K和100K数据集上的平均精度、召回率、F1分数、AUC和测试精度均达到极高水平。此外，Grad-CAM可视化方法的使用提高了模型的可解释性，验证了MSRANetV2是一个可靠、可解释且高性能的分类模型。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24213", "html_url": "https://arxiv.org/abs/2510.24213", "title": "超越推断干预：解耦身份的面部匿名化扩散模型", "title_en": "Beyond Inference Intervention: Identity-Decoupled Diffusion for Face Anonymization", "authors": "Haoxin Yang,Yihong Lin,Jingdan Kang,Xuemiao Xu,Yue Li,Cheng Xu,Shengfeng He", "background": "面部匿名化旨在在保护非身份属性的同时隐藏身份信息。主流扩散模型依赖于推断时的干预措施，如负向指导或能量基优化，这些措施在训练后应用于抑制身份特征，但这些干预措施往往会引入分布偏移，使身份与非身份属性交织在一起，从而降低视觉保真度和数据实用性。", "innovation": "提出了一种基于训练的匿名化框架ID^2Face，该框架通过学习一个结构化的潜在空间，使身份和非身份信息显式解耦，从而在推断时实现直接且可控的匿名化。通过设计条件式扩散模型和身份解耦潜在重构器，采用身份变分自动编码器建模身份特征，并通过双向潜在对齐提取和对齐非身份属性。这是一种创新的方法，它在训练过程中就解耦了身份和非身份信息，从而无需推断时的优化。", "conclusion": "实验结果表明，ID^2Face在视觉质量、身份屏蔽和数据保真度方面优于现有方法。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24211", "html_url": "https://arxiv.org/abs/2510.24211", "title": "MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive Visual Generation Acceleration", "title_en": "MC-SJD : Maximal Coupling Speculative Jacobi Decoding for Autoregressive Visual Generation Acceleration", "authors": "Junhyuk So,Hyunho Kook,Chaeyeon Jang,Eunhyeok Park", "background": "尽管自回归（AR）建模已成为视觉生成的新范式，但由于单个词令牌生成的推理速度缓慢，其实际应用受到了严重限制，这通常需要成千上万的步骤才能生成一个样本。Speculative Jacobi Decoding（SJD）在加速AR生成方面显示出了潜力，但令牌在迭代中的不稳定显著降低了接受率，这是由于在草稿令牌生成过程中使用了独立采样过程。", "innovation": "我们提出了MC-SJD，这是一种无需训练、无损的并行解码框架，通过将SJD扩展到信息理论方法中，基于耦合来加速AR视觉生成，显著提高了连续迭代中抽样相同草稿令牌的概率，从而实现了其速度的大幅提升，仅通过单行代码修改即可实现性能的提升，图像生成加速了约4.2倍，视频生成加速了约13.3倍，同时保持了质量无退化。", "conclusion": "MC-SJD方法仅需要对现有算法进行简单的单行代码修改，便能实现显著的性能提升，在图像和视频生成方面分别实现了约4.2倍和13.3倍的加速，同时保持了生成结果的高质量，无需损失无损属性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24214", "html_url": "https://arxiv.org/abs/2510.24214", "title": "SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodal LLMs", "title_en": "SCOPE: Saliency-Coverage Oriented Token Pruning for Efficient Multimodel LLMs", "authors": "Jinhong Deng,Wen Li,Joey Tianyi Zhou,Yang He", "background": "多模态大型语言模型（MLLMs）通常会处理大量的视觉标记，这导致了巨大的计算开销，尽管许多标记是冗余的。现有的视觉标记剪枝方法主要根据注意力分数选择最显著的标记，但这些选择往往导致所选标记的语义完整性不足。", "innovation": "本文提出了一种新颖的视觉标记剪枝策略，称为Saliency-Coverage Oriented Token Pruning for Efficient MLLMs（SCOPE），以联合建模所选视觉标记的显著性和覆盖度，更好地保留语义完整性。具体地说，引入了一个基于标记关系计算的集合覆盖，定义了每个未选择标记的标记覆盖增益，并将显著性分数整合到标记覆盖增益中，提出了SCOPE分数并迭代选择具有最高SCOPE分数的标记。", "conclusion": "在多个视觉-语言理解基准上使用LLaVA-1.5和LLaVA-Next模型进行广泛实验后，实验证明了本方法总体上优于先前的方法。代码可在\textit{this https URL}下载。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24231", "html_url": "https://arxiv.org/abs/2510.24231", "title": "使用事件摄像机进行微跳动识别的基准测试：一个新型数据集和评估", "title_en": "Benchmarking Microsaccade Recognition with Event Cameras: A Novel Dataset and Evaluation", "authors": "Waseem Shariff,Timothy Hanley,Maciej Stec,Hossein Javidnia,Peter Corcoran", "background": "微跳动是支持视觉感知和神经处理的小而自发的眼睛运动。传统的方法通常使用眼动追踪器或基于帧的分析，这些方法虽然精确，但成本高且在可扩展性和时间分辨率方面有限。事件驱动的感知提供了高速、低延迟的替代方案，通过高效地捕获细微的空间-时间变化。", "innovation": "该工作引入了一个首创的事件驱动的微跳动数据集，用于支持认知计算中小眼睛运动动力学的研究。使用Blender渲染高保真眼睛运动场景并模拟0.5至2.0度的角度偏差的微跳动，分为七个不同的类别。这些数据集通过v2e转换为事件流，保持了微跳动的自然时间动态性，持续时间从0.25毫秒到2.25毫秒不等。使用Spiking-VGG11、Spiking-VGG13和Spiking-VGG16模型进行评估，并提出了用于SpikingJelly的Spiking-VGG16Flow，一种增强版的光学流模型。这些模型实现了大约90％的平均准确率，成功地根据角度偏差而不是事件数量或持续时间分类微跳动。", "conclusion": "这些结果展示了脉冲神经网络在精细运动识别上的潜力，并为事件驱动的视觉研究设立了基准。数据集、代码和训练模型将在指定的链接处公开。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24260", "html_url": "https://arxiv.org/abs/2510.24260", "title": "DeshadowMamba: 消除阴影作为一维序列相似性", "title_en": "DeshadowMamba: Deshadowing as 1D Sequential Similarity", "authors": "Zhaotong Yang,Yi Chen,Yanying Li,Shengfeng He,Yangyang Xu,Junyu Dong,Jian Yang,Yong Du", "background": "近期的图像阴影去除模型通常依赖注意力机制来捕捉长距离依赖关系，但这些模型固定的关注模式易将无关区域的光照线索混合进去，导致结构失真和颜色不一致。", "innovation": "从序列建模的角度重新审视阴影去除问题，采用Mamba模型，这是一种选择性状态空间模型，通过方向性状态转换传播全局上下文，从而保持位置连续性。为解决Mamba直接应用于图像数据时的局限性问题，提出CrossGate机制，用于将阴影感知的相似性注入Mamba的输入门，实现相关上下文的选择性集成。此外，引入ColorShift正则化，通过全局颜色统计驱动对比学习目标，引导模型抑制颜色污染，实现稳健的颜色恢复。", "conclusion": "这些组件使序列建模适应阴影去除所要求的结构完整性和色彩一致性。在公共基准数据集上的广泛实验表明，DeshadowMamba达到了最佳视觉质量和强大的定量性能。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24321", "html_url": "https://arxiv.org/abs/2510.24321", "title": "使用CLIP和提示学习进行少量样本遥感图像场景分类", "title_en": "Few-Shot Remote Sensing Image Scene Classification with CLIP and Prompt Learning", "authors": "Ivica Dimitrovski,Vlatko Spasev,Ivan Kitanovski", "background": "遥感领域的场景分类越来越多地依赖于深度学习模型，但其性能受限于标记数据稀缺和地理及传感器域的高标注成本。尽管如CLIP等视觉语言模型能够通过视觉和文本模态的对齐学习可转移的表示，直接应用在遥感领域仍不理想，因为存在显著的领域差异和任务特定语义适应的需求。", "innovation": "本文系统地探索了使用提示学习作为轻量且高效的适应策略，以应对遥感领域少量样本场景分类的瓶颈。评估了几种方法，包括上下文优化、条件上下文优化、多模态提示学习和自调节约束提示。通过跨多个基准遥感数据集的大量实验，本文证明了提示学习在少量样本场景分类中始终优于两类基准方法，并且自调节约束提示具有最佳的跨域鲁棒性。", "conclusion": "提示学习作为一种可扩展且高效的方法，能够解决卫星和航空图像中的领域差距问题，为该领域的未来研究奠定了坚实的基础。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24285", "html_url": "https://arxiv.org/abs/2510.24285", "title": "ViPER: 使视觉语言模型的视觉感知能力实现自我进化的赋能框架", "title_en": "ViPER: Empowering the Self-Evolution of Visual Perception Abilities in Vision-Language Model", "authors": "Juntian Zhang,Song Jin,Chuanqi Cheng,Yuhan Liu,Yankai Lin,Xun Zhang,Yufei Zhang,Fei Jiang,Guojun Yin,Wei Lin,Rui Yan", "background": "视觉和语言模型在现实世界应用中面临的最关键瓶颈在于其对精细视觉感知能力的有限容量。由于高质量数据稀缺和现有方法的限制，这些问题尤其突出。传统的监督微调方法往往牺牲了通用能力，而强化微调则更侧重于文本推理而忽视了视觉感知。", "innovation": "提出了一种新的两阶段任务，将视觉感知学习构建成从粗到细的逐步过程，并开发了ViPER框架。该框架通过自我批判和自我预测实现迭代进化，并通过图像级别和实例级别的重建与两阶段强化学习策略的协同整合，建立了一个闭环训练模式，直接使用内部合成数据来提升感知能力。", "conclusion": "所提出的Qwen-Viper系列在七个综合基准测试中平均提高了1.7%，在精细感知方面甚至提高了6.0%，且在不同视觉语言场景中表现出色，保持了一致的性能和泛化能力。ViPER不仅促进感知能力的自我提升，还为生成和理解之间的相互作用提供了实证支持，为开发更具自主性和能力的视觉语言模型开辟了新的途径。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24262", "html_url": "https://arxiv.org/abs/2510.24262", "title": "UtilGen: 专用于双重适应任务的实用性导向生成数据增强", "title_en": "UtilGen: Utility-Centric Generative Data Augmentation with Dual-Level Task Adaptation", "authors": "Jiyu Guo,Shuo Yang,Yiming Huang,Yancheng Long,Xiaobo Xia,Xiu Su,Bo Zhao,Zeke Xie,Liqiang Nie", "background": "数据增强使用生成模型已成为提升计算机视觉任务性能的强大 paradigm。然而，现有增强方法主要关注优化内在数据属性（如保真度和多样性）来生成视觉高品质的合成数据，而往往忽略了下游任务的具体需求。不同类型的任务和网络架构对训练数据的需求差异巨大，因此生成的数据需要适应这些需求。", "innovation": "本文提出了一种新的实用性导向的数据增强框架 UtilGen，该框架能够适应地优化数据生成过程，通过下游任务反馈生成具体任务高实用性训练数据。通过引入权重分配网络评估每个合成样本的任务专用实用性，随后采用双重优化策略逐步优化数据生成过程：模型层优化使生成模型适应下游任务，实例层优化调整每次生成轮次的生成策略（如提示嵌入和初始噪声）。实验结果表明，UtilGen 在八个不同复杂度和粒度的基准数据集上表现出色，平均准确性提高 3.87%，并且生成的合成数据更具影响性和任务相关性。", "conclusion": "实验结果验证了从视觉特性导向转换为任务实用性导向的数据增强的有效性，证明了 UtilGen 的优越性能。该工作为实现更具针对性和高效性数据增强框架提供了新的思路和方法。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24278", "html_url": "https://arxiv.org/abs/2510.24278", "title": "通过合成训练源归因于 artificial intelligence 生成图像的无训练方法", "title_en": "Training-free Source Attribution of AI-generated Images via Resynthesis", "authors": "Pietro Bongini,Valentina Molinari,Andrea Costanzo,Benedetta Tondi,Mauro Barni", "background": "在数据稀缺条件下进行合成图像来源归属性鉴别是一项具有挑战性的任务，尤其是在需要少量样本或零样本分类能力的情况下。该文介绍了一种新的无训练的单次映射方法，依据图像再合成技术进行来源归属性。创新之处在于作者使用描述分析图像的提示语言，通过所有候选来源合成功能重新生成图像，模型被赋予将图像归因于在特征空间中与原图像最接近的来源。此外，作者还提出了一组新的图像数据集，包含来自商业和开源文本到图像生成器的人脸图像，以挑战现有归属性方法，有助于新模型的开发与评测。实验结果表明，当仅有少量训练或微调样本可用时，研究中的再合成方法优于现有技术。", "innovation": "提出了基于图像再合成的无训练的单次映射来源归属性方法。相较于以往方法，这种方法在仅有少量样本的情况下表现更优。", "conclusion": "本文表明，新提出的再合成方法在数据稀缺条件下优于现有的技术。同时，新数据集作为一个挑战性的情景，为开发和评估未来少量样本和零样本方法提供了有价值的基准。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24232", "html_url": "https://arxiv.org/abs/2510.24232", "title": "深入探讨级联不稳定现象：图像恢复与目标检测协同中的Lipschitz连续性视角", "title_en": "Delving into Cascaded Instability: A Lipschitz Continuity View on Image Restoration and Object Detection Synergy", "authors": "Qing Zhao,Weijian Deng,Pengxu Wei,ZiYi Dong,Hannan Lu,Xiangyang Ji,Liang Lin", "background": "在不良条件（如雾霾和低光照）下提高检测鲁棒性时，通常会应用图像恢复作为预处理步骤来提升图像质量，从而改善检测效果。然而，恢复网络与检测网络之间的功能不匹配会引入不稳定性，导致有效融合受阻。这种问题还未能受到广泛关注。本文通过对Lipschitz连续性的考察，重新审视了这一限制，分析了恢复网络和检测网络在输入空间和参数空间中的功能差异。研究指出，恢复网络执行平滑连续的转换，而物体检测器则具有突变的决策边界，使得它们对细微变化非常敏感。这种不匹配在传统级联框架中引入了不稳定性，即使是从恢复网络引入的微不足道的噪声在检测阶段也会被放大，打断了梯度流动并影响优化效果。", "innovation": "本文提出了Lipschitz正则化目标检测（LROD），这是一种结合图像恢复直接融入检测器特征学习的简洁而有效的框架，确保训练过程中两种任务的Lipschitz连续性。将该框架作为Lipschitz正则化YOLO（LR-YOLO）实施，与现有YOLO检测器无缝集成。在雾和低光等基准测试中进行了广泛的实验，结果表明LR-YOLO能够稳定检测、平滑优化并提高总体准确性。", "conclusion": "本文通过Lipschitz连续性的视角，提出了融合图像恢复与检测任务的新方法。该方法有效解决了传统级联框架中的不稳定性问题，显著提升了在不良条件下的检测性能。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24366", "html_url": "https://arxiv.org/abs/2510.24366", "title": "自适应知识传递与切换双学生架构在半监督医学图像分割中的应用", "title_en": "Adaptive Knowledge Transferring with Switching Dual-Student Framework for Semi-Supervised Medical Image Segmentation", "authors": "Thanh-Huy Nguyen,Hoang-Thien Nguyen,Ba-Thinh Lam,Vi Vu,Bach X. Nguyen,Jianhua Xing,Tianyang Wang,Xingjian Li,Min Xu", "background": "教师-学生框架已成为半监督医学图像分割的领先方法，展示了在各种任务中的强大性能。然而，这种方法的学习效果仍然受教师和学生网络之间强烈相关性和不可靠知识传递过程的限制。", "innovation": "引入了一种新颖的切换双学生架构，该架构在每个迭代中战略性地选择最可靠的学一个学生来增强双学生合作，并防止错误的强化。同时，引入了损失感知指数移动平均策略，动态确保教师吸收学生的有意义信息，提高伪标签的质量。此插拔式框架在3D医学图像分割数据集上进行了广泛评估，证明了其在有限监督下的分割精度改进。", "conclusion": "该框架在3D医学图像分割数据集上优于最新的半监督方法，证明了其提高分割精度的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24374", "html_url": "https://arxiv.org/abs/2510.24374", "title": "为引用表达计数解耦所计数内容与观察位置", "title_en": "Decoupling What to Count and Where to See for Referring Expression Counting", "authors": "Yuda Zou,Zijian Zhang,Yongchao Xu", "background": "引用表达计数（Referring Expression Counting, REC）将目标计数从类水平扩展到亚类水平，旨在根据描述类别和特征属性的文本表达式来统计对象数量。然而，一个基本挑战被忽视了：标定点通常放置在代表性的类位置上（例如，头部），这迫使模型专注于类别特征，而忽略了其他视觉区域（例如，“行走”时的腿部）的属性信息。这使得模型在处理亚类特征时效果不理想。", "innovation": "本文提出了一种新的框架 W2-Net，它通过双查询机制明确地将问题解耦为“要计数什么”和“在哪里观察”。具体来说，除了标准的“要计数什么”查询（w2c）来定位对象外，还引入了专门的“在哪里观察”查询（w2s）。w2s 查询旨在从特定属性的视觉区域中获取并提取特征，以实现精确的亚类区分。此外，该框架还引入了一种名为 Subclass Separable Matching (SSM) 的新颖匹配策略，该策略在标签分配时采用了排斥力以增强亚类间的可分性。", "conclusion": "W2-Net 在 REC-8K 数据集上显著超越了现有最先进的方法，验证集的计数误差降低了 22.5%，测试集则降低了 18.0%。同时，定位 F1 分数提高了 7% 和 8%。代码将公开提供。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24378", "html_url": "https://arxiv.org/abs/2510.24378", "title": "临床工作流中的脑卒中病灶分割：一个模块化、轻量级且易于部署的工具", "title_en": "Stroke Lesion Segmentation in Clinical Workflows: A Modular, Lightweight, and Deployment-Ready Tool", "authors": "Yann Kerverdo,Florent Leray,Youwan Mahé,Stéphanie Leplaideur,Francesca Galassi", "background": "尽管诸如nnU-Net之类的深度学习框架在脑病变分割方面达到了最先进的性能，但它们在临床上部署仍然存在困难，主要由于其对依赖性和集成度的高要求。当前的研究介绍了一种名为StrokeSeg的模块化和轻量级框架，能够将研究级别的脑卒中病灶分割模型转换为可部署的应用程序。", "innovation": "StrokeSeg框架将预处理、推理和后处理分离，预处理依赖于Anima工具和BIDS兼容输出，推理使用ONNX Runtime和Float16量化，从而减小模型大小约50%。该工具提供图形界面和命令行界面，并以Python脚本和独立的Windows可执行文件形式分发。研究证明，StrokeSeg在分割性能上与原始PyTorch管道相当（Dice差异<1e-3），表明高性能的研究管道可以转换为便携且临床可用的工具。", "conclusion": "研究展示了如何将研究级别且高性能的脑卒中病灶分割模型转化为临床上可部署工具，通过模块化设计和轻量化实现，证明了这种方法的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24414", "html_url": "https://arxiv.org/abs/2510.24414", "title": "为语义分割设计的XAI评估框架", "title_en": "XAI Evaluation Framework for Semantic Segmentation", "authors": "Reem Hammoud,Abdul karim Gizzini,Ali J. Ghandour", "background": "确保人工智能（AI）模型的透明性和信任度对于在其应用于关键领域和高风险领域至关重要。可解释的人工智能（XAI）方法已经出现，用以应对这一挑战，但仍需严格评估XAI方法，以优化模型复杂性、预测性能和可解释性之间的权衡。尽管在评估XAI技术方面已经取得了很大进展，但针对语义分割任务的评估策略仍然相对未被充分探索。", "innovation": "本文引入了一个针对语义分割任务的全面且系统性的评估框架，专门用于评估XAI，并明确考虑了空间和上下文任务复杂性。该框架采用像素级评估策略和精心设计的指标，提供了细粒度的可解释性见解。使用最近调整的特定激活映射（CAM）为基础的XAI方案进行的模拟结果证明了该方法的有效性、稳定性和可靠性。", "conclusion": "这些发现有助于推进透明、可信且负责任的语义分割模型的发展。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24413", "html_url": "https://arxiv.org/abs/2510.24413", "title": "50 Years of Water Body Monitoring: The Case of Qaraaoun Reservoir, Lebanon", "title_en": "50 Years of Water Body Monitoring: The Case of Qaraaoun Reservoir, Lebanon", "authors": "Ali Ahmad Faour,Nabil Amacha,Ali J. Ghandour", "background": "黎巴嫩贝卡平原上的卡拉昂水库是该国最大的地表水体，其可持续管理依赖于在频繁传感器故障和有限维护能力的情况下进行可靠的监测。这项研究关注的是通过卫星图像、先进的水面分割技术和机器学习来实时估算水库的面积和容量，无需依赖地面测量。", "innovation": "该研究提出了一种无传感器的方法，结合开源卫星图像、先进的水面分割技术和机器学习模型，能够在近乎实时的情况下估计卡拉昂水库的表面积和容量。研究利用Sentinel-2和Landsat图像，并引入了一个新的水面分割指数来进行水面分割。机器学习模型通过支持向量回归（SVR）训练，基于收集的水面积、水位和水容量的数据集，能够仅通过卫星图像提取的表面积来估算水库容量。优化后的SVR性能显示出小于50%容量1.5%的误差和大于0.98的确定系数。", "conclusion": "研究结果证明了该方法的稳健性和成本效益，提供了一种独立于传感器的水库蓄水监测的实用解决方案。该方法能够复制到其他水体，并且产生的50年时间序列数据对气候变化和环境模式研究有价值。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24448", "html_url": "https://arxiv.org/abs/2510.24448", "title": "重新思考视觉智能：视频预训练的见解", "title_en": "Rethinking Visual Intelligence: Insights from Video Pretraining", "authors": "Pablo Acuaviva,Aram Davtyan,Mariam Hassan,Sebastian Stapf,Ahmad Rahimi,Alexandre Alahi,Paolo Favaro", "background": "大规模语言模型（LLMs）已经展示了大规模预训练可以使系统在语言领域中快速适应新的问题，而无需大量的监督。然而，这种成功在视觉领域并没有得到有效的转化，模型，包括LLMs，仍然在组合理的理解、采样效率和通用问题解决能力方面面临挑战。本文探讨了视频扩散模型（VDMs）作为弥合这一差距的潜在方向。", "innovation": "研究采用了视频时间空间数据进行预训练，赋予模型在结构和动态方面的强归纳偏置，该偏置我们假设能够支持更广泛的任适应性。通过与语言模型的对照实验，发现视频预训练模型在多种基准测试中的表现优于其语言模型对照。", "conclusion": "我们的结果表明，视频预训练提供了支持视觉基础模型发展的归纳偏置。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24385", "html_url": "https://arxiv.org/abs/2510.24385", "title": "放射学报告在训练医学图像分类器时何时有用？", "title_en": "When are radiology reports useful for training medical image classifiers?", "authors": "Herman Bergström,Zhongqi Yue,Fredrik D. Johansson", "background": "医学图像用于训练机器学习模型时，通常会伴随放射学报告，其中包含丰富的专家注释。然而，依赖这些报告作为临床预测的输入需要经过训练的放射科医生及时进行手动工作。这引发了一个自然的问题：在训练过程中何时可以利用放射学报告来提高仅靠图像的分类效果？以往的研究仅限于通过微调预训练的图像表示以预测诊断标签来评估放射学报告的利用价值，这些标签通常是从报告中提取的，而忽略了与文本关系较弱的标签的任务。", "innovation": "本文通过系统研究放射学报告在预训练和细调过程中的利用方式，涵盖了诊断和预后任务（例如，12个月后再入院）以及不同训练集大小的情况。研究发现在标签在文本中有良好表示的情况下，利用报告进行预训练对下游分类任务有益；然而，在不适用的情况下，通过显式图像-文本对齐进行预训练可能会产生不利影响。此外，利用报告进行细调可以在某些情况下带来显著改善，甚至可能超越预训练方法的影响。这些结果为如何利用特权文本数据训练医学图像分类器提供了实际的指导，并揭示了当前研究中的缺口。", "conclusion": "利用问题揭示了在特定条件下利用特权文本数据训练医学图像分类器的过程和效果，强调了现有研究中的不足。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24437", "html_url": "https://arxiv.org/abs/2510.24437", "title": "基于自生成先验的深度条件图像压缩", "title_en": "Deeply-Conditioned Image Compression via Self-Generated Priors", "authors": "Zhineng Zhao,Zhihai He,Zikun Zhou,Siwei Ma,Yaowei Wang", "background": "学习型图像压缩（LIC）展示了实现高速率-失真性能的巨大潜力。但目前的方法往往难以建模自然图像中复杂的内在关联结构，尤其是一体化的全局不变结构与局部瞬时纹理的交织。这种限制在低比特率下会导致严重的几何变形。", "innovation": "本文提出了基于功能分解的框架，称为通过自生成先验的深层条件图像压缩（DCIC-sgp）。核心思想是首先编码一个强大的自生成先验来捕捉图像的结构性骨架，该先验随后被用来整体调节整个压缩流程。对于分析变换尤其深度地调节，使其能够集中其表示能力于残差的高熵细节。这种层次化的、依赖驱动的方法实现了信息流的有效解纠缠。实验验证了这一说法；视觉分析表明，该方法显著减少了传统编解码器在低比特率下的几何变形 artifacts。", "conclusion": "本框架在定性和定量上均表现出高度竞争力，相较于VVC测试模型VTM-12.1，在 Kodak、CLIC 和 Tecnick 数据集上实现了14.4%、15.7%和15.1%的显著BD-rate减少。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24398", "html_url": "https://arxiv.org/abs/2510.24398", "title": "无监督检测中风后脑部异常", "title_en": "Unsupervised Detection of Post-Stroke Brain Abnormalities", "authors": "Youwan Mahé,Elise Bannier,Stéphanie Leplaideur,Elisa Fromont,Francesca Galassi", "background": "中风后的MRI不仅能够识别出局灶性损伤，还能揭示其他结构性变化，如脑萎缩和脑室扩大。这些异常已被公认是评估恢复情况和预期结果的成像生物标志物，但现有的监督分割方法在捕捉这些异常方面仍然表现欠佳。论文的研究目的是评估基于流的生成模型REFLECT，以进行无监督检测，能同时识别局灶性和非局灶性异常改变，特别是在中风患者中。论文在ATLAS数据集上的研究表明，使用健康对照组数据进行训练的模型在局灶性损伤分割和非局灶性异常检测方面表现更好，这表明使用完全健康的解剖结构进行训练可以提高对正常变异性的建模，从而实现更广泛的、可靠的结构性异常检测。", "innovation": "提出了一种基于流的生成模型（REFLECT），用于对中风后患者的无监督检测。该方法能够检测局灶性和非局灶性异常，这是在传统的监督分割方法之外的一种新的尝试。通过将模型分别训练在中风患者无病变的切片和健康对照组上，研究表明，后者在病灶分割和非病灶异常检测方面表现更好，从而发现了正常解剖结构的重要性。", "conclusion": "基于流的生成模型REFLECT能够有效对中风后患者的影像学数据进行无监督检测，尤其是对于非病灶异常的检测能力更强，能够提高不同区域结构性异常的检测率，为中风后的功能恢复和长期管理提供了新的工具。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24399", "html_url": "https://arxiv.org/abs/2510.24399", "title": "GenTrack: 新一代多目标跟踪", "title_en": "GenTrack: A New Generation of Multi-Object Tracking", "authors": "Toan Van Nguyen,Rasmus G. K. Christiansen,Dirk Kraft,Leon Bodenhagen", "background": "本文介绍了一种名为GenTrack的新型多对象跟踪(MOT)方法。该方法的主要贡献是在不确定和随时间变化的目标数量的情况下，采用了一种结合随机和确定性处理的混合跟踪方法，特别强调了目标身份（ID）一致性以及处理非线性动态，以及通过粒子群优化（PSO）和提出的适应度度量来引导随机粒子向目标分布模式，即使在较弱和噪声较大的对象检测器的情况下也能实现有效的跟踪。此外，还整合了目标间的社会互动，以增强PSO引导的粒子并改善对强（匹配）和弱（未匹配）轨迹的连续更新，从而减少ID切换和跟踪丢失，特别是在遮挡情况下。文章基于空间一致性、外观、检测置信度、轨迹惩罚和社会评分，提出了一个包含综合状态和观测模型的视觉MOT基线，并在标准基准和实际场景中提供真实结果。", "innovation": "1. 结合随机和确定性处理的混合跟踪方法；\n2. 利用粒子群优化（PSO）和适应度度量引导随机粒子；\n3. 引入社会互动增强PSO引导的粒子并改善轨迹更新；\n4. 提出了一个全面的状态和观测模型基线，基于空间一致性、外观、检测置信度、轨迹惩罚和社会评分；\n5. 提供了最小依赖项的开源代码实现，并包含GenTrack基本版、PSO版和带社会评分的PSO版三种变体。", "conclusion": "实验结果显示，GenTrack在标准基准和实际场景中比最先进的跟踪器提供了更优的表现，提供的基准实现和开源代码实现使得研究者能够进行公平的比较和灵活的重新实现。未来的研究方向也进行了讨论。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24410", "html_url": "https://arxiv.org/abs/2510.24410", "title": "一种视觉多目标跟踪的混合方法", "title_en": "A Hybrid Approach for Visual Multi-Object Tracking", "authors": "Toan Van Nguyen,Rasmus G. K. Christiansen,Dirk Kraft,Leon Bodenhagen", "background": "本文提出了一种结合了随机和确定性机制的视觉多目标跟踪方法，以确保在非线性动力学和未知或随时间变化的目标数量下，特征标识的一致性。方法应对非线性动态和非高斯噪声，采用粒子滤波器，并通过粒子群优化（PSO）引导粒子向状态分布模式靠近，同时提出融合运动一致性、外观相似性和社交互动线索作为邻近目标的适应性度量，以减少发散。确定性关联进一步确保了特征的一致性，通过包含粒子与当前检测的空问一致性、检测置信度和轨迹惩罚的代价矩阵实现。此外，提出了一种新的方案，在保持目标身份的同时平滑更新目标状态，特别是在目标与其他目标交互过程中和长时间遮挡时对于较弱轨迹的更新。过去状态的平均推测速度为粒子采样提供趋势线索，增强状态更新。该追踪器被设计为用于预录制视频和相机实时流的灵活性工具，在未来的帧信息不可用时均可操作。实验结果证明，该方法在多种情况下优于最先进的方法。", "innovation": "文章在几个方面提出了创新：1）结合了随机粒子滤波器和确定性关联方法；2）通过引入粒子群优化（PSO）和适应性度量确保特征标识的一致性；3）提出了融合运动一致性、外观相似性和社交互动线索的粒子更新策略；4）通过过去的轨迹估计速度提供趋势线索，优化粒子采样和状态更新；5）其灵活性适用于预录制视频和实时相机流的应用场景。实验结果表明，该方法在多种条件下均优于现有的最先进方法。", "conclusion": "本文提出了一种结合随机和确定性机制的视觉多目标跟踪方法，采用粒子滤波器和适应性度量确保目标标识的一致性，在复杂背景下实现了较强的鲁棒性和准确性，适用于多种应用场景。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24456", "html_url": "https://arxiv.org/abs/2510.24456", "title": "使用机器学习技术检测帕金森病的深入研究", "title_en": "A Critical Study towards the Detection of Parkinsons Disease using ML Technologies", "authors": "Vivek Chetia,Abdul Taher Khan,Rahish Gogoi,David Kapsian Khual,Purnendu Bikash,Sajal Saha", "background": "本文提出了一个基于深度学习技术的解决方案，用于识别三种茶树叶病害，其中两种由害虫引起，一种由病原体（传染性生物体）和环境条件引起。具体来说，识别的是红锈病、Helopeltis和红蜘蛛病。文中评估了两种模型，分别为SSD MobileNet V2和Faster R-CNN ResNet50 V1，比较了这些模型在目标检测方面的性能和效果。此外，还使用了Mask R-CNN进行了物体实例分割，并开发了一种计算受病害影响的叶子部分的方法。关键词包括茶树叶病、深度学习、红锈病、Helopeltis、红蜘蛛病、SSD MobileNet V2、Faster R-CNN ResNet50 V1和Mask RCNN。", "innovation": "文中提出了一种基于深度学习技术的解决方案，用于识别茶树叶上的三种病害。该研究评估了两种不同模型，比较了它们在目标检测方面的表现，并结合了Mask R-CNN技术，开发了一种新的方法来计算受病害影响的叶子部分。", "conclusion": "SSD MobileNet V2和Faster R-CNN ResNet50 V1模型在这项研究中展现了各自特定的优势，其中Faster R-CNN ResNet50 V1在多个指标上表现更好。使用Mask R-CNN技术能更精确地定位和分割受病害影响的树叶区域。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24486", "html_url": "https://arxiv.org/abs/2510.24486", "title": "通过知识蒸馏实现快速且准确的神经反射变换成像", "title_en": "Fast and accurate neural reflectance transformation imaging through knowledge distillation", "authors": "Tinsae G. Dulecha,Leonardo Righetto,Ruggero Pintus,Enrico Gobbetti,Andrea Giachetti", "background": "反射变换成像（RTI）技术因其能够在有限视角下通过交互式变化照明增强表面细节，而非常受欢迎。传统的PTM和HSH方法虽然简洁且快速，但在捕捉复杂反射场时存在不足，尤其在高反射或阴影区域容易出现伪影。尽管NeuralRTI通过神经自动编码器学习用于更好逼近局部反射的紧凑函数，已在保真度与存储成本上取得成功，但由于需要大量参数的自定义解码器网络，其交互式重新照明步骤在计算上非常消耗资源，特别是在设备性能有限的情况下。", "innovation": "本文提出了一种新颖的方法——基于知识蒸馏的DisK-NeuralRTI，旨在降低NeuralRTI的计算成本，同时保持高质量的重新照明结果。这种方法通过从大模型的知识蒸馏中获取有效信息，训练一个更小且更有效的模型来实现交互式重新照明，从而克服了原方法计算成本高导致的局限性。", "conclusion": "通过知识蒸馏的DisK-NeuralRTI在保持高质量成像结果的同时，显著降低了计算成本，使得在资源有限的环境下也能实现快速且准确的神经反射变换成像。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24464", "html_url": "https://arxiv.org/abs/2510.24464", "title": "Kineo: 无需校准的稀疏RGB相机的标量级运动捕捉", "title_en": "Kineo: Calibration-Free Metric Motion Capture From Sparse RGB Cameras", "authors": "Charles Javerliat,Pierre Raimbaud,Guillaume Lavoué", "background": "无标记的多视角运动捕捉通常受到精确相机校准需求的限制，这限制了非专家和野外捕捉的易用性。现有的无需校准的方法虽能减轻这一要求，但计算成本较高，且重建精度降低。", "innovation": "Kineo 是一个全自动的无需校准的无标记运动捕捉管道，能够从未同步、未校准的消费级RGB相机拍摄的视频中捕捉无标记运动。Kineo 通过利用现有的2D关键点，同时校准相机，包括布朗科内迪奇失真系数，并以标量级规模重建3D关键点和密集场景点图。提出了一种基于置信度的时空关键点采样策略和图基全球优化，以确保稳健的校准，且计算成本固定，与序列长度无关。引入了一种成对重新投影共识得分，以量化3D重建的可靠性，从而提供更适合下游任务的数据。", "conclusion": "在EgoHumans和Human3.6M上的评估表明，Kineo 相比前人无校准方法有显著改进。与以前的最先进方法相比，Kineo 减少了大约83-85%的相机平移误差，86-92%的相机旋转误差，以及83-91%的世界平均关节点误差（W-MPJPE）。Kineo 还具有在实际场景中的高效性，能在特定配置下（如，36分钟处理1小时20分钟的录像）比录像本身更快地处理多视角序列。完整的管道和评估代码均已公开发布，以促进可重复性和实际应用，网址为: this https URL。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24474", "html_url": "https://arxiv.org/abs/2510.24474", "title": "解耦均值流: 将流模型转换为流图以加速采样", "title_en": "Decoupled MeanFlow: Turning Flow Models into Flow Maps for Accelerated Sampling", "authors": "Kyungmin Lee,Sihyun Yu,Jinwoo Shin", "background": "去噪生成模型，如扩散模型和流模型，能够生成高质量样本，但由于离散化误差需要很多去噪步骤。流图通过估计时间步之间的平均速度来缓解这一误差，使采样速度加快。然而，其训练通常需要进行架构调整，限制了与预训练流模型的兼容性。", "innovation": "我们引入了一种简单的解耦均值流策略，该策略能够在无需架构修改的情况下将流模型转换为流图模型。我们的方法通过对扩散变换器的最终块进行条件化配置，使得预训练流模型可以直接重新配置为流图。结合增强的训练技术，这种设计能够在1到4步内生成高质量样本。我们发现，训练流模型并随后进行转换比从零开始训练流图更加高效且效果更好。", "conclusion": "在ImageNet 256x256和512x512上，我们的模型分别达到1步的FID为2.16和2.12，明显优于现有技术。当步骤增加到4时，我们实现了1.51和1.68的FID，几乎与流模型的性能相当，但推断速度快了100多倍。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24514", "html_url": "https://arxiv.org/abs/2510.24514", "title": "Latent Sketchpad: 通过勾画视觉想法来激发全模态推理", "title_en": "Latent Sketchpad: Sketching Visual Thoughts to Elicit Multimodal Reasoning in MLLMs", "authors": "Huanyu Zhang,Wenshan Wu,Chengzu Li,Ning Shang,Yan Xia,Yangyu Huang,Yifan Zhang,Li Dong,Zhang Zhang,Liang Wang,Tieniu Tan,Furu Wei", "background": "多模态大型语言模型（MLLMs）虽然在视觉理解方面表现出色，但在需要视觉规划和想象力的复杂场景中却常常表现不佳。本文指出，人类通过草图进行视觉思考，开发并传达想法，而现有的MLLMs的内部视觉表示仅限于感知理解。因此，本文提出了一种新的框架——Latent Sketchpad，旨在为MLLMs提供一个内部视觉草稿板，使其能够在支持生成性视觉思考的同时不损害推理能力。", "innovation": "本文提出了一种新的框架——Latent Sketchpad，该框架通过引入两个组件（Context-Aware Vision Head和pretrained Sketch Decoder）来集成视觉生成，同时保持MLLMs的推理能力。Context-Aware Vision Head用于自回归生成视觉表示，而pretrained Sketch Decoder则将这些表示渲染成可由人类理解的图像。该框架将模型的文本推理扩展到视觉思考，使MLLMs能够交替进行文本推理和生成视觉潜变量。", "conclusion": "在MazePlanning新数据集上的实验结果表明，Latent Sketchpad在各种MLLMs中提供与骨干模型相当或更优的推理性能，并且还能跨不同的前沿MLLMs（如Gemma3和Qwen2.5-VL）进行推广。通过将模型的文本推理扩展到视觉思考，该框架为更丰富的跨人机交互和更广泛的应用提供了新的机会。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24379", "html_url": "https://arxiv.org/abs/2510.24379", "title": "一种多场景数据集下的亮度感知多尺度网络用于偏振图像融合", "title_en": "A Luminance-Aware Multi-Scale Network for Polarization Image Fusion with a Multi-Scene Dataset", "authors": "Zhuangfan Huang,Xiaosong Li,Gao Wang,Tao Ye,Haishu Tan,Huafeng Li", "background": "偏振图像融合通过结合S0和DOLP图像来揭示表面粗糙度和材料属性，广泛应用于伪装识别、组织病理学分析、表面缺陷检测等领域。现有方法在复杂光照环境下融合不同偏振图像时，由于各图像间的对比度差异，难以有效地整合互补的纹理特征。该研究旨在提出一种亮度感知的多尺度网络（MLSN）来解决这一问题。", "innovation": "该研究提出了亮度感知的多尺度网络（MLSN），包括一个亮度分支的多尺度空间加权矩阵，用于在编码器阶段动态加权注入亮度，解决偏振图像对比度差异问题；设计了全局-局部特征融合机制，并在特征重塑阶段通过残差连接进行窗口自注意力计算，解决全局上下文和局部细节的平衡问题；在解码器阶段引入亮度增强模块，建立了亮度分布与纹理特征之间的映射关系，实现融合结果的非线性亮度校正。", "conclusion": "提出的MLSN在MSP、PIF和GAND数据集上的实验表明，在主观和客观评估中均优于现有方法，MS-SSIM和SD指标分别比其他方法高出了8.57%、60.64%、10.26%、63.53%、22.21%和54.31%。此外，该研究还提供了包含17类室内和室外复杂光照场景的1000对偏振图像数据集MSP，解决了偏振图像融合领域高质量数据集稀缺的问题。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24653", "html_url": "https://arxiv.org/abs/2510.24653", "title": "数字病理学中的眼动追踪、鼠标追踪、刺激追踪和决策制作数据集", "title_en": "Eye-Tracking, Mouse Tracking, Stimulus Tracking,and Decision-Making Datasets in Digital Pathology", "authors": "Veronica Thai,Rui Li,Meng Ling,Shuning Jiang,Jeremy Wolfe,Raghu Machiraju,Yan Hu,Zaibo Li,Anil Parwani,Jian Chen", "background": "病理学家在解读单张大像素组织玻片图像（WSIs）时，其诊断准确性约为70%，增加更多的医生也未能显著提升诊断一致性。当前领域缺乏足够的行为数据分析来解释诊断错误和不一致性。为了填补这一空白，该研究展示了PathoGaze1.0，这是一个全面的行为数据集，记录了19名病理学家解读397个WSIs时的全方位诊断工作流程中的动态视搜索和决策过程。", "innovation": "提出了PathoGaze1.0，这是一个行为数据集，涵盖了18.69小时的眼动追踪、鼠标交互、刺激追踪、视窗导航和诊断决策数据。数据收集过程注重生态有效性，采用了一种基于应用的测试平台（PTAH）。此外，这些数据还可以用于改进病理学家和可能支持专家的AI系统的培训。", "conclusion": "所有实验均已事前登记，并且完整的数据集和分析代码可在特定网址下载。这些数据能为病理学诊断提供行为分析的基础，帮助发现诊断错误的原因，并可能用于改善病理学家和AI系统的培训。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24563", "html_url": "https://arxiv.org/abs/2510.24563", "title": "OSEarth-MCP: 改进计算机使用代理的MCP工具调用基准", "title_en": "OSWorld-MCP: Benchmarking MCP Tool Invocation In Computer-Use Agents", "authors": "Hongrui Jia,Jitong Liao,Xi Zhang,Haiyang Xu,Tianbao Xie,Chaoya Jiang,Ming Yan,Si Liu,Wei Ye,Fei Huang", "background": "随着决策能力和推断能力的进步，多模态代理在计算机应用场景中显示出强大的潜力。过去评估主要集中在GUI交互能力，而通过模型上下文协议（MCP）实现的工具调用能力却很少受到关注。单纯将具有集成工具调用能力的代理与仅评估GUI交互能力的代理进行比较是不公平的。", "innovation": "本文提出了首个全面且公正的基准OSWorld-MCP，用于评估计算机使用代理的工具调用、GUI操作和决策能力。设计了一种新颖的自动化代码生成流水线，创建工具并将现有工具进行综合。经过严格的手动验证，生成了158个高质量的工具（涵盖7个常见应用），并分别验证了功能的正确性、实用性和多样性。", "conclusion": "在OSWorld-MCP上进行广泛评估显示，MCP工具通常能提高任务成功率（例如，从OpenAI o3的8.3%提高到20.4%，从Claude 4 Sonnet的40.1%提高到43.3%），这突显了评估工具调用能力的重要性。尽管最强的模型在工具调用方面的比例仅为36.3%，这表明仍有改进的空间，同时表明了基准测试的挑战性。明确测量MCP工具使用技能的OSWorld-MCP加深了对多模态代理的理解，并为复杂工具支持环境中的性能评估设立了新的标准。所有代码、环境和数据均可在相关链接处下载。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24640", "html_url": "https://arxiv.org/abs/2510.24640", "title": "一种用于稳健检测AI生成面部伪造的双分支CNN", "title_en": "A Dual-Branch CNN for Robust Detection of AI-Generated Facial Forgeries", "authors": "Xin Zhang,Yuqi Song,Fei Zuo", "background": "生成AI的快速发展使得伪造面部图像变得高度逼真，这对AI安全、数字媒体完整性和公众信任构成了重大威胁。面部伪造技术，包括面部替换、属性编辑等，以及基于扩散的强大图像合成方法，正越来越多地被用于恶意用途，如虚假信息传播、身份欺诈和诽谤。面对这一不断增长的挑战，迫切需要开发出稳健且泛化的面部伪造检测方法，作为AI安全基础设施的重要组成部分。", "innovation": "提出了一种新颖的双分支卷积神经网络，用于面部伪造检测。该网络利用空间域和频率域的互补线索。RGB分支捕捉语义信息，而频率分支则关注难以让生成模型抑制的高频特征。引入了通道注意力模块以适应性地融合这些异构特征，突显出伪造鉴别的最有信息性通道。设计了一种统一的损失函数FSC Loss，结合了焦点损失、监督对比损失和频率中心间隔损失，以增强类别可分性和鲁棒性。", "conclusion": "在DiFF基准数据集上对模型进行评估，该数据集包括来自四种代表方法生成的伪造图像：文本到图像、图像到图像、面部替换和面部编辑。该方法在所有类别中都取得了优异的性能，优于平均人类准确性。这些结果证明了该模型的有效性，并表明它可能在保护视觉伪造攻击下的AI生态系统方面做出重要贡献。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24579", "html_url": "https://arxiv.org/abs/2510.24579", "title": "基于物理学启发的高斯柯尔莫哥洛夫-阿诺尔德网络在锥束CT中X射线散射校正", "title_en": "Physics-Inspired Gaussian Kolmogorov-Arnold Networks for X-ray Scatter Correction in Cone-Beam CT", "authors": "Xu Jiang,Huiying Pan,Ligen Shi,Jianing Sun,Wenfeng Xu,Xing Zhao", "background": "锥束CT（CBCT）利用平板探测器实现高空间分辨率的三维成像。但数据采集过程中存在散射问题，导致重建图像中的CT值偏差和组织对比度降低，从而影响诊断准确性。", "innovation": "提出了一种基于深度学习的散射伪影校正方法，结合物理先验知识。利用点散射概率密度分布在投影域中具有旋转对称性这一特性，通过高斯径向基函数（Gaussian RBF）来建模点散射函数，并将其嵌入到Kolmogorov-Arnold网络（KAN）层中，以高效地学习高维散射特征。通过结合散射光子分布的物理特性与KAN的复杂函数映射能力，提高了模型准确表示散射的能力。", "conclusion": "通过合成和实际扫描实验验证了该方法的有效性，结果表明模型能够有效纠正重建图像中的散射伪影，并且在量化指标上优于现有方法。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24657", "html_url": "https://arxiv.org/abs/2510.24657", "title": "Group Relative Attention Guidance for Image Editing", "title_en": "Group Relative Attention Guidance for Image Editing", "authors": "Xuanpu Zhang,Xuesong Niu,Ruidong Chen,Dan Song,Jianhao Zeng,Penghui Du,Haoxiang Cao,Kai Wu,An-an Liu", "background": "近期，基于扩散-变压器模型的图像编辑迅速发展，但现有方法通常缺乏有效的编辑程度控制，限制了它们获得更个性化结果的能力。本文研究了DiT模型中的MM-Attention机制，观察到查询和键标记共享一个仅逐层依赖的偏置向量。作者认为该偏置向量代表了模型固有的编辑行为，而每个标记与其对应偏置的差异编码了内容特定的编辑信号。基于这一洞察，作者提出了一种简单有效的方法——Group Relative Attention Guidance（GRAG），通过重新加权不同标记的差异值来调节模型相对于编辑指令输入图像的关注焦点，从而在无需调整的情况下实现连续且精细的编辑强度控制。大量的实验在现有的图像编辑框架上进行，展示了GRAG可以仅通过四行代码集成，并且在提高编辑质量方面效果显著。与常用的分类器自由引导相比，GRAG在编辑程度上实现了更平滑和精确的控制。", "innovation": "作者提出了Group Relative Attention Guidance（GRAG），这是一种简单有效的图像编辑方法。通过重新加权不同标记的差异值，清晰地将编辑指令模拟为比对偏差，允许在不进行任何调整的情况下实现连续且精细的编辑强度控制。实验表明，GRAG在简单集成（仅四行代码）的情况下可以显著提高编辑质量，并且在编辑控制的平滑性和精确性方面优于分类器自由引导方法。", "conclusion": "GRAG可以在少量代码集成的情况下，一致地提高图像编辑的质量，并且相较于常用的Classifier-Free Guidance实现了更平滑、更精确的编辑控制。我们的代码将在此处发布：[该链接]。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24688", "html_url": "https://arxiv.org/abs/2510.24688", "title": "MIC-BEV: 多基础设施相机鸟瞰图变换器与关系意识融合的3D目标检测", "title_en": "MIC-BEV: Multi-Infrastructure Camera Bird's-Eye-View Transformer with Relation-Aware Fusion for 3D Object Detection", "authors": "Yun Zhang,Zhaoliang Zheng,Johnson Liu,Zhiyu Huang,Zewei Zhou,Zonglin Meng,Tianhui Cai,Jiaqi Ma", "background": "基础设施基座的感知在智能交通系统中扮演着至关重要的角色，能够提供全局态势感知并支持协同自主。然而，现有的基于相机的目标检测模型在多视角基础设施配置、不同相机参数设置、视觉输入退化和各种道路布局的场景中常常表现不佳。", "innovation": "提出了基于Transformer的多相机鸟瞰图(MIC-BEV)感知框架，用于基础设施基座的3D目标检测。MIC-BEV支持不同数量和参数的相机，具有良好的鲁棒性，特别是在传感器退化情况下。框架中引入的图增强融合模块通过利用相机几何关系和隐式视觉线索将多视角图像特征整合到鸟瞰图空间。", "conclusion": "在M2I和真实场景数据集RoScenes上的广泛实验表明，MIC-BEV在3D目标检测方面达到了最先进的性能，并且在极端天气和传感器退化等恶劣条件下保持了良好的鲁棒性。这些结果强调了MIC-BEV在实际应用中的潜力。该数据集和源代码可从此链接下载：this https URL."}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24667", "html_url": "https://arxiv.org/abs/2510.24667", "title": "SAGE: 结构感知的生成视频过渡", "title_en": "SAGE: Structure-Aware Generative Video Transitions between Diverse Clips", "authors": "Mia Kan,Yilin Liu,Niloy Mitra", "background": "视频过渡旨在在两个片段之间合成中间帧，但诸如线性插值等朴素方法会产生艺术特征不足的缺点，限制了它们在专业领域的应用或破坏了时间一致性。传统技术（如交叉淡入淡出、形态变换、帧插值）和近期生成插值方法能够生成高质量的过渡帧，但在处理涉及巨大时间差距或有意义差异的片段间过渡时存在困难。为了克服这些限制，作者借鉴了艺术工作流程，实现了一些策略，如轮廓对齐和重要特征的插值，以保持结构和感知连续性。", "innovation": "本文提出了一种称为SAGE（Structure-Aware Generative vidEo transitions）的零样本方法，该方法结合了通过线图和运动流提供的结构指导与生成合成，从而可以在无需微调的情况下，生成平滑且语义一致的过渡。", "conclusion": "大量的实验和与当前替代方法（如FILM，TVG，DiffMorpher，VACE，GI）的对比结果显示，SAGE在生成从不同片段过渡时优于经典的和生成的基线方法，在定量指标和用户体验方面表现更优。代码将在文章接受后公开发布。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24717", "html_url": "https://arxiv.org/abs/2510.24717", "title": "Uniform Discrete Diffusion with Metric Path for Video Generation", "title_en": "Uniform Discrete Diffusion with Metric Path for Video Generation", "authors": "Haoge Deng,Ting Pan,Fan Zhang,Yang Liu,Zhuoyan Luo,Yufeng Cui,Wenxuan Wang,Chunhua Shen,Shiguang Shan,Zhaoxiang Zhang,Xinlong Wang", "background": "连续空间视频生成已经取得了显著进步，但现有的离散生成方法由于误差累积和长时间上下文不一致的限制而进展缓慢。", "innovation": "作者提出了URSA（Uniform discRete diffuSion with metric pAth，统一离散扩散与度量路径）框架，这是一个简单而强大的方法，通过集成线性化度量路径和分辨率相关的步骤调整机制，有效地将离散模型与连续方法之间的差距缩小。URSA框架将视频生成任务定义为离散的时空单元的迭代全局细化。此外，还引入了一种异步时间微调策略，可以统一多种任务，如插值和图像到视频的生成。", "conclusion": "广泛的实验表明，URSA在视频和图像生成基准测试中持续优于现有的离散方法，并在性能上达到了最先进的连续扩散方法水平。代码和模型可以在此网址下载：this https URL"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24709", "html_url": "https://arxiv.org/abs/2510.24709", "title": "大型预训练视觉变换器中物体绑定能力是否自然涌现？", "title_en": "Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?", "authors": "Yihao Li,Saeed Salehi,Lyle Ungar,Konrad P. Kording", "background": "物体绑定是人类认知的核心能力，它将代表物体的各种特征组合成一个整体。物体绑定将低级的感知特征组建成高级的对象表示，并有效地存储在记忆中，支持人类对个体物体实例的认知。然而，尽管先前的工作经常通过显式地使用以物体为中心的注意机制（如槽注意力）来探索这些好处，但在预训练的视觉变换器（ViTs）中这种能力是否自然地产生仍然是不确定的。", "innovation": "研究通过对ViT的自我注意力特征进行解码来探索物体绑定能力。研究者发现，ViTs能够识别哪些补丁属于同一个物体，这种能力在自监督预训练模型（DINO、MAE、CLIP）中可靠地表现出物体绑定能力，但在基于ImageNet监督的模型中则较弱。此外，研究揭示出物体绑定的信息被编码在对象特征的低维子空间中，并且这种信号主动引导注意。这些发现反驳了ViTs缺乏物体绑定能力的观点，并强调了符号知识“哪些部件属于同一个物体”如何自然地在连接主义系统中涌现。", "conclusion": "物体绑定能力自然地在大型预训练ViTs中涌现，这一能力不是简单的架构性特征，而是在特定预训练目标下获得的一种能力。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24718", "html_url": "https://arxiv.org/abs/2510.24718", "title": "Generative View Stitching", "title_en": "Generative View Stitching", "authors": "Chonghyuk Song,Michal Stary,Boyuan Chen,George Kopanas,Vincent Sitzmann", "background": "自回归视频扩散模型能够生成长期稳定的、与历史一致的视频序列，但无法利用未来的条件信息来引导当前的生成过程。在带有预定义相机轨迹的相机引导视频生成中，这一局限会导致所生成的场景中存在与相机路径碰撞的情况，从而导致自回归快速失效。", "innovation": "我们提出了生成视图缝合（GVS）方法，它通过并行采样整个序列，使所生成的场景能够忠实于预定义的相机轨迹的每一部分。GVS是一个扩展了用于机器人规划的扩散缝合法的方法，适用于视频生成。此外，我们还引入了全方位引导（Omni Guidance）技术，该技术同时依赖于过去和未来的条件，增强了拼接的时序一致性，并确保生成的视频具备远距离连贯性。GVS兼容任何使用扩散强迫训练的现成视频模型，无需专门的训练。", "conclusion": "GVS实现了稳定、无碰撞、帧间一致以及能够闭合循环的相机引导视频生成，适用于多种预定义相机路径，包括奥斯卡·雷图斯瓦德的不可能楼梯。查看结果请访问：this https URL."}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23633", "html_url": "https://arxiv.org/abs/2510.23633", "title": "噪声即全部所需：通过扩散模型中的噪声组合采样解决线性逆问题", "title_en": "Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models", "authors": "Xun Su,Hiroyuki Kasai", "background": "预训练的扩散模型通过将观察信息整合到生成过程，展示了在零样本逆问题解决中的强大能力，但这种整合方式存在固有的矛盾：过度整合会扰乱生成过程，而整合不足则无法强调逆问题施加的约束。现有方法需要通过逐步骤调参来嵌入条件信息，这限制了生成模型的应用灵活性和效果。", "innovation": "提出了‘噪声组合采样’的新方法，该方法能够从噪声子空间合成最优噪声向量，用来近似测量得分，并替换掉标准去噪扩散概率模型中的噪声项。这种方法可以自然地将条件信息嵌入生成过程，无须依赖逐步骤调参，同时适用于多种逆问题求解器，特别地，在生成步骤较少时，可以实现显著的性能提升，且几乎不增加计算成本，从而大幅提高建模的稳健性和稳定性。", "conclusion": "该方法不仅在图像压缩等多个逆问题求解领域表现出色，而且可以显著改进低生成步数情况下的稳定性和鲁棒性，同时几乎不增加额外计算开销。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23659", "html_url": "https://arxiv.org/abs/2510.23659", "title": "量子机器学习在图像分类中的应用：残差网络与量子支持向量机的混合模型", "title_en": "Quantum Machine Learning for Image Classification: A Hybrid Model of Residual Network with Quantum Support Vector Machine", "authors": "Md. Farhan Shahriyar,Gazi Tanbhir,Abdullah Md Raihan Chy", "background": "近年来，量子机器学习（QML）与经典深度学习方法的结合受到越来越多的关注，因为计算技术对于提高图像分类任务的性能至关重要。经典机器学习和深度学习模型在处理高维和复杂数据集时常常存在困难，因此需要先进技术如量子计算来提高分类效率。本研究利用ResNet-50进行特征提取，结合量子支持向量机（QSVM）进行分类，特别是在马铃薯疾病检测中。", "innovation": "本研究提出了一种混合模型，使用ResNet-50进行特征提取，并结合量子支持向量机进行分类。该模型利用量子特征映射（如ZZ、Z和Pauli-X）将经典数据转化为量子态，通过主成分分析（PCA）对特征进行降维。研究结果表明，基于Z特征映射的QSVM在五折交叉验证中表现出色，准确率达到99.23%，超越了传统模型。", "conclusion": "本研究强调了量子计算在图像分类中的优势，并提供了通过混合量子和经典模型进行疾病检测的潜在解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23660", "html_url": "https://arxiv.org/abs/2510.23660", "title": "Pneumovoltional Neural Networks for Pneumonia Detection: An Efficient Quantum-Assisted Feature Extraction Paradigm", "title_en": "Quanvolutional Neural Networks for Pneumonia Detection: An Efficient Quantum-Assisted Feature Extraction Paradigm", "authors": "Gazi Tanbhir,Md. Farhan Shahriyar,Abdullah Md Raihan Chy", "background": "肺炎是一个重大的全球公共卫生挑战，需要准确及时的诊断。虽然卷积神经网络(CNNs)在肺炎检测的医学图像分析中显示出前景，但CNNs通常面临高计算成本、特征表示限制以及从较小数据集泛化的挑战。为了解决这些问题，该研究探讨了量子卷积神经网络(QNNs)的应用，利用量子计算增强特征提取。", "innovation": "该研究提出了一种新型的量子-经典混合模型，使用参数化量子电路(PQC)处理2x2图像块，并利用旋转Y门进行数据编码，以及纠缠层生成非经典特征表示。这些量子提取的特征随后被馈送到经典的神经网络中进行分类。实验结果表明，提出的QNN在验证准确率方面达到了83.33%，而类似的经典CNN达到了73.33%。这种方法的快速收敛性和样本效率突显了QNNs在医学图像分析中的潜力，特别是在少量标记数据的情景中。", "conclusion": "这项研究为将量子计算集成到基于深度学习的医疗诊断系统中奠定了基础，提供了一种比传统方法更计算高效的替代方案。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23928", "html_url": "https://arxiv.org/abs/2510.23928", "title": "在动态环境中的自适应关键帧选择以实现可扩展的3D场景重建", "title_en": "Adaptive Keyframe Selection for Scalable 3D Scene Reconstruction in Dynamic Environments", "authors": "Raman Jha,Yang Zhou,Giuseppe Loianno", "background": "传统的三维场景重建方法在动态环境中存在数据瓶颈问题，特别是对于实时感知而言。静态关键帧选择策略（如固定的时间间隔或均匀的帧跳过）无法有效解决动态场景的高效重建问题。", "innovation": "本文提出了一种适应性的关键帧选择方法，结合了基于误差的模块和基于动量的更新模块，能够动态调整关键帧选择阈值，从而能够从压缩的数据流中创建高质量的3D世界表示，特别适用于复杂及动态环境下的机器人学习部署。", "conclusion": "实验结果表明，与传统的静态关键帧选择策略相比，本文的自适应关键帧选择方法在重建质量上有了显著的改进。此外，全面的消除研究进一步证实了方法中每个组件的有效性，强调了它们对整体性能提升的贡献。这种方法对于复杂动态环境下实时3D场景重建具有重要意义。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23807", "html_url": "https://arxiv.org/abs/2510.23807", "title": "病理学中基础模型为何失败", "title_en": "Why Foundation Models in Pathology Are Failing", "authors": "Hamid R. Tizhoosh", "background": "在非医疗领域，基础模型（FMs）通过大规模自我监督和多模态学习已彻底改变了计算机视觉和语言处理。因此，它们在计算病理学中的快速应用被认为是实现癌症诊断、预估和多模态检索方面突破的期望得以实现。然而，最近的系统评估揭示了一些根本性缺陷：诊断准确性低、鲁棒性差、几何不稳定、计算需求大以及安全风险。", "innovation": "本文识别了七种相关原因导致这些缺陷：生物复杂性、无效的自我监督、过度泛化、架构过于复杂、缺乏领域特定创新、数据不足以及与组织切片大小相关的根本设计缺陷。这些发现表明当前的病理学基础模型在概念上与组织形态的本质不匹配，呼吁对这一范式进行彻底的反思和重新设计。", "conclusion": "研究表明现行的病理学基础模型在概念上与组织形态的本质不匹配，因此需要从根本上重新思考这一范式。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23977", "html_url": "https://arxiv.org/abs/2510.23977", "title": "利用随机采样进行空气污染的协同神经预测", "title_en": "Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling", "authors": "Yohan Abeysinghe,Muhammad Akhtar Munir,Sanoojan Baliah,Ron Sarafian,Fahad Shahbaz Khan,Yinon Rudich,Salman Khan", "background": "空气污染仍是全球范围内的主要公共卫生和环境风险，尤其是在易受野火、城市雾霾和沙尘暴导致的空气污染高峰期影响的地区。准确预测颗粒物（PM）浓度对于及时发出公共卫生警告和干预措施至关重要，但现有的模型往往低估了罕见但危险的污染事件。因此，提高颗粒物浓度预测的准确性是非常必要的。", "innovation": "SynCast模型是一种高分辨率的神经预测模型，它通过将气象和空气质量数据相结合，提高了对平均和极端污染水平的预测精度。该模型基于地区适应的变压器结构，并通过扩散机制增加了随机细化模块，能够更准确地捕捉驱动PM峰值的非线性动力学。与现有方法相比，SynCast模型在几个PM变量（PM1，PM2.5，PM10）的预测精度上有显著提高，尤其是在极端条件下。此外，SynCast模型通过采用领域感知目标和极端值理论，在受严重影响的地区提升了性能，同时不牺牲全局精度。", "conclusion": "SynCast模型提供了一个可扩展的基础，为下一代空气质量预警系统铺平了道路，并支持脆弱地区气候与健康风险的缓解。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24024", "html_url": "https://arxiv.org/abs/2510.24024", "title": "视听无差别：视听描述中的模态偏差", "title_en": "Listening without Looking: Modality Bias in Audio-Visual Captioning", "authors": "Yuchi Ishikawa,Toranosuke Manabe,Tatsuya Komatsu,Yoshimitsu Aoki", "background": "音频-视觉描述旨在通过联合建模声音和视觉生成场景的整体描述。尽管最近的方法通过复杂的模态融合提高了性能，但目前尚不清楚当前的视听描述模型中两个模态是多大程度互补的，以及当一个模态被降级时这些模型的鲁棒性如何。本文通过在听取最先进的视听描述模型（LAVCap）的系统模态鲁棒性测试中，对音频或视觉流进行选择性抑制或破坏，来回答这些问题。初步分析显示，LAVCap 对音频流有明显的偏向。为了评估模型在使用两者模态上的平衡性，将Textual Annotations加入到AudioCaps中，形成了AudioVisualCaps数据集。", "innovation": "通过系统地对LAVCap进行模态鲁棒性测试，评估模型在单一模态缺失时的性能表现；通过创建AudioVisualCaps数据集，结合语言描述和视听模态进行描述，评估模型在使用两者上的平衡性；分析发现LAVCap对音频流有明显的偏向，但使用AudioVisualCaps训练时，其模态偏差减小了。", "conclusion": "LAVCap 在AudioVisualCaps数据集上的基线结果表明，通过使用联合视听数据进行训练，模型对单一模态的偏向有所减轻。未来的工作可以通过进一步增加数据的多样性和复杂性，从而改善模型的鲁棒性和平衡性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24331", "html_url": "https://arxiv.org/abs/2510.24331", "title": "Vision-language models在上下文中的所见：探索多模态在上下文中的学习", "title_en": "What do vision-language models see in the context? Investigating multimodal in-context learning", "authors": "Gabriel O. dos Santos,Esther Colombini,Sandra Avila", "background": "上下文学习(ICL)使大规模语言模型(LLMs)能够在无需参数更新的情况下通过示例学习任务。尽管在LLMs中得到了广泛的研究，但在视觉-语言模型(Vision-Language Models, VLMs)中的有效性仍鲜有探讨。本文旨在深入研究VLMs中的ICL，评估了四种架构下的七个模型在三个图像字幕基准上的表现。研究发现，使用图像-文本交织的数据进行训练可以提升ICL的性能，但并不能有效整合示范示例中的视觉和文本信息。此外，虽然指令调优有助于指令遵循，但可能会减少对上下文示例的依赖，这表明指令对齐与上下文适应之间存在权衡。", "innovation": "首次系统研究了VLMs中的ICL现象，分析了提示设计、架构选择和训练策略对其影响，并探讨了伴随上下文示例不断增加时VLMs中注意力模式的变化。该研究通过实验证明，当前VLMs在多模态集成方面的能力有限，尤其是在利用视觉信息方面。", "conclusion": "发现当前VLMs在多模态ICL方面存在局限性，提示设计、训练策略和架构选择对ICL性能影响显著。这些发现提出了增强VLMs从多模态上下文示例中学习能力的新见解。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24108", "html_url": "https://arxiv.org/abs/2510.24108", "title": "ZTRS: 无需模仿的端到端自主驾驶与轨迹评分", "title_en": "ZTRS: Zero-Imitation End-to-end Autonomous Driving with Trajectory Scoring", "authors": "Zhenxin Li,Wenhao Yao,Zi Wang,Xinglong Sun,Jingde Chen,Nadine Chang,Maying Shen,Jingyu Song,Zuxuan Wu,Shiyi Lan,Jose M. Alvarez", "background": "现有的自主驾驶框架大多依赖于模仿学习（IL），但其可能受限于专家演示的子优化和部署时的特征转移问题。另一方面，强化学习（RL）虽在模拟中表现出潜力，但通常局限于低维度符号输入（如3D物体和地图），未能实现从原始传感器数据的全端到端学习。现有框架往往受到感知模块级联错误的影响，而ZTRS旨在通过直接处理高维度的传感器输入和强化学习训练来防止这种错误。", "innovation": "ZTRS框架结合了IL和RL的优点：不丢失传感器信息并使用RL进行鲁棒规划。ZTRS是第一个完全消除IL的端到端框架，仅通过奖励学习并直接操作高维度传感器数据。ZTRS利用我们提出的Exhaustive Policy Optimization（EPO），一种适用于可枚举动作和奖励的策略梯度变体。ZTRS在三个基准测试中展示了出色的性能：Navtest（通用的现实世界开放式路径规划）、Navhard（挑战性的现实世界和合成场景中的开放式路径规划）和HUGSIM（模拟闭环驾驶）。特别是在Navhard基准测试中达到最先进的结果，并在HUGSIM上优于基于IL的基线。", "conclusion": "ZTRS实现了端到端的动态路径预测与规划，直接从原始传感器数据中学习，不依赖于IL，结合了RL的优点。此框架通过Exhaustive Policy Optimization优化策略，展示了在三个不同基准测试中的优秀表现，并且在HUGSIM基准测试中打破了基于IL的方法的表现。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24332", "html_url": "https://arxiv.org/abs/2510.24332", "title": "动态场景中手术动作的空间映射的声源定位", "title_en": "Sound Source Localization for Spatial Mapping of Surgical Actions in Dynamic Scenes", "authors": "Jonas Hein,Lazaros Vlachopoulos,Maurits Geert Laurent Olthof,Bastian Sigrist,Philipp Fürnstahl,Matthias Seibold", "background": "手术场景理解对于推进计算机辅助和智能手术系统至关重要。当前的方法主要依赖于视觉数据或端到端学习，这限制了精细上下文建模的能力。", "innovation": "本文提出了一种新颖的方法，通过将相控麦克风阵列的声学定位信息投影到RGB-D摄像机生成的动态点云上，生成4D音视融合的手术场景表示。基于变换器的声学事件检测模块能识别包含器械与组织交互的相关时间段，并在音视场景表示中进行空间定位。该方法在现实手术室中评估了模拟手术操作。", "conclusion": "本文提出的方法成功在三维空间中定位了手术声源并将它们与视觉场景元素关联。实验评估表明，该方法在空间声源定位和多模态数据融合方面表现出准确性和鲁棒性，提供了一个综合和动态的手术活动表示，是多模态手术场景表示的第一个方法，对于未来的智能和自主手术系统奠定了基础。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24261", "html_url": "https://arxiv.org/abs/2510.24261", "title": "DynaRend: 通过掩蔽未来渲染学习3D动力学的机器人操作", "title_en": "DynaRend: Learning 3D Dynamics via Masked Future Rendering for Robotic Manipulation", "authors": "Jingyi Tian,Le Wang,Sanping Zhou,Sen Wang,Jiayi Li,Gang Hua", "background": "由于现实世界训练数据多样性的稀缺性，学习通用的机器人操作策略依然是一个关键挑战。现有方法主要通过自监督表示学习减轻这一问题，但大多数方法依赖于静态语义或场景几何学的2D视觉预训练范式，或者重视2D动态性的大规模视频预测模型，这些方法无法同时学习对有效操作而言至关重要的几何学、语义和动力学信息。因此，需要一种新的框架来学习意识到3D和动力学信息的三平面特征，从而使训练能够联合捕捉空间几何、未来动态和任务语义。", "innovation": "DynaRend提出了一种新的表示学习框架，通过使用可微分体积渲染来实现掩蔽重建和未来预测，以学习3D感知和动力学导向的三平面特征。通过多视角RGB-D视频数据预训练，DynaRend能够统一捕捉空间几何、未来动态和任务语义。学习到的表示能有效地转移到下游的机器人操作任务中，通过动作价值图预测实现任务执行。相比于现有方法，DynaRend在RLBench和Colosseum基准测试集以及真实的机器人实验中显示出在策略成功、对环境扰动的泛化以及不同操作任务的适用性方面的显著提高。", "conclusion": "DynaRend通过一个三平面表示成功地解决了现有方法在处理机器人操作任务时存在的几何学、语义学和动力学信息学习不足的问题，并通过多视角RGB-D视频数据预训练实现空间几何、未来动态和任务语义的统一捕捉。该框架展示了在机器人操作任务中的优越表现，为通用机器人操作策略的学习提供了新的方向。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24335", "html_url": "https://arxiv.org/abs/2510.24335", "title": "NVSim：大规模室内导航新视图合成模拟器", "title_en": "NVSim: Novel View Synthesis Simulator for Large Scale Indoor Navigation", "authors": "Mingyu Jeong,Eunsung Kim,Sehun Park,Andrew Jaeyong Choi", "background": "传统的3D扫描存在成本高和可扩展性有限的问题，而通过普通图像序列自动生成大规模可导航的室内模拟器能够克服这些问题。然而，机器人穿越数据中常见的稀疏观察地板会导致视觉上的缺陷，现有的方法难以解决这一问题。", "innovation": "本文提出了一种名为NVSim的框架，该框架能够从普通图像序列中自动构建大规模、可导航的室内模拟器。该框架通过适应3D高斯斑点来解决稀疏观察地板导致的视觉缺陷问题。同时，还引入了“面向地板的高斯斑点”算法，以确保干净、可导航的地面，并提出了一种无网格的通行性检查算法，该算法通过直接分析渲染视图来构建拓扑图。", "conclusion": "实验结果表明，该系统能够从真实数据中生成有效的大型导航图。系统具有强大的生成大规模导航图的能力，并展示了其在实际应用中的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24411", "html_url": "https://arxiv.org/abs/2510.24411", "title": "OS-Sentinel: 通过现实工作流程中的混合验证增强移动GUI代理的安全性", "title_en": "OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows", "authors": "Qiushi Sun,Mukai Li,Zhoumianze Liu,Zhihui Xie,Fangzhi Xu,Zhangyue Yin,Kanzhi Cheng,Zehao Li,Zichen Ding,Qi Liu,Zhiyong Wu,Zhuosheng Zhang,Ben Kao,Lingpeng Kong", "background": "计算机运用视觉语言模型（VLMs）的代理在操作如移动平台等数字环境中展现了类似人类的能力，这些能力和潜力促使了数字自动化的进展。然而，这些代理也存在非法操作的风险，如系统破坏和隐私泄露，这引发了严重关切。在移动计算的复杂操作空间内检测这些安全问题依然是未被充分探索的挑战。", "innovation": "该研究引入了OS-Sentinel，这是一种结合形式验证器（用于检测明确的系统级违规）和基于VLM的上下文判定器（用于评估上下文风险和代理行为）的新颖混合验证框架。此外，该研究推出了一个名为MobileRisk-Live的动态沙盒环境和包含细粒度注解的真实轨迹的安全检测基准。实验结果表明，OS-Sentinel在多个度量标准上比现有方法提高了10%-30%的表现，这一成果为开发更安全可靠的移动代理提供了关键见解。", "conclusion": "OS-Sentinel能够有效提升移动GUI代理的安全性，并且在评估上下文风险和检测系统级违规方面展示了显著优势。通过引入此混合验证框架和详细安全检测基准，该研究为移动代理的安全研究提供了一种新的思路和依据。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24711", "html_url": "https://arxiv.org/abs/2510.24711", "title": "MoE中的路由机制对于扩展扩散变换器的重要性：带有显式路由指导的扩展", "title_en": "Routing Matters in MoE: Scaling Diffusion Transformers with Explicit Routing Guidance", "authors": "Yujie Wei,Shiwei Zhang,Hangjie Yuan,Yujin Han,Zhekai Chen,Jiayu Wang,Difan Zou,Xihui Liu,Yingya Zhang,Yu Liu,Hongming Shan", "background": "Mixture-of-Experts (MoE) 被视为一种强大的方法，能够提高模型容量同时保持计算效率。尽管 MoE 在大规模语言模型 (LLMs) 中取得了显著成功，但在应用到扩散变换器 (DiTs) 上时效果有限。这主要归因于语言和视觉标记的固有差异：语言标记具有语义密集且标记间差异显著，而视觉标记则表现出空间冗余和功能异质性，这妨碍了视觉 MoE 中专家的专业化。研究者提出了一种 ProMoE 框架，该框架采用两步路由机制并具有显式路由指导，促进专家专业化。通过这种机制，路由可以将图像标记根据其功能角色分为条件性和非条件性集，并通过基于语义内容的学习原型进行质心路由精炼标记分配。基于此种机制，质心路由在潜在空间中实现基于相似性的专家分配，提供了一种自然机制来引入显式语义指导，研究证实这种指导对于视觉 MoE 是至关重要的.", "innovation": "本文介绍了一种名为 ProMoE 的 MoE 框架，该框架通过两步路由机制引入明确的路由指导，专门用于促进视觉标记的专业主义。具体而言，这种指导促使路由机制通过条件路由按功能角色将图像标记划分为条件和非条件集进行分组，并通过基于语义内容的可学习原型进行质心路由，调整标记分配。通过此质心路由在潜在空间中的基于相似性的专家分配，提供了引入显式语义指导的自然机制。研究者还提出了一种路由对比损失，以明确增强质心路由过程，促进专家内部一致性与专家间多样性.", "conclusion": "在 ImageNet 基准测试上，ProMoE 在使用 Rectified Flow 和 DDPM 训练目标的情况下，超过了最先进的方法。有关代码和模型将在未来向公众提供."}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23763", "html_url": "https://arxiv.org/abs/2510.23763", "title": "RoboOmni：全模态环境中主动型机器人操作", "title_en": "RoboOmni: Proactive Robot Manipulation in Omni-modal Context", "authors": "Siyin Wang,Jinlan Fu,Feihong Liu,Xinzhe He,Huangxuan Wu,Junhao Shi,Kexin Huang,Zhaoye Fei,Jingjing Gong,Zuxuan Wu,Yugang Jiang,See-Kiong Ng,Tat-Seng Chua,Xipeng Qiu", "background": "近年来，多模态大型语言模型（MLLMs）在视觉-语言-动作（VLA）模型方面取得了迅速进展，这些模型被应用在机器人的操作中。尽管目前的方法在许多场景下是非常有效的，但在实际交互中，人类通常不会直接发出指令。高效的协作需要机器人能够主动推断用户的意图。这项研究提出了一种新的多模态上下文指令设置，意图可以从口语对话、环境声音和视觉线索中推断而来，而不是通过明确的命令。为了应对这一新的设置，研究构建了RoboOmni框架，该框架结合了端到端的全模态LLM，可以实现意图识别、交互确认和动作执行的一体化处理。", "innovation": "1. 引入了新的多模态上下文指令设置，推断意图的方式从直接的命令转变为通过对话、环境声音和视觉线索。\n2. 基于端到端的全模态LLMs提出了RoboOmni框架，能够同步处理听觉和视觉信号，支持直接语音 interactions，并融合了意图识别、交互确认和执行等功能。\n3. 构建了大规模的数据集OmniAction，包含140000个场景、5000名演讲者、2400个事件声音、640个背景环境和六种不同类型的上下文指令，为机器人的主动意图识别补充了缺失的训练数据。", "conclusion": "RoboOmni在模拟和实际操作环境中超越了基于文本和ASR的基本方法，在成功率、推理速度、意图识别和主动辅助等方面均表现出色。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.09962", "html_url": "https://arxiv.org/abs/2401.09962", "title": "CustomVideo: 多主体定制文本到视频生成", "title_en": "CustomVideo: Customizing Text-to-Video Generation with Multiple Subjects", "authors": "Zhao Wang,Aoxue Li,Lingting Zhu,Yong Guo,Qi Dou,Zhenguo Li", "background": "当前的文本到视频生成方法在处理多主题时存在不足，这使得多主题指导下的文本到视频定制成为一个更具有挑战性和实际意义的场景。本文旨在解决这一问题，提出了能够根据多个主题生成保持身份的视频的CustomVideo新框架。", "innovation": "CustomVideo框架通过以下创新点来提高多主体指导下的文本到视频定制质量：1）通过在同一图像中组合多个主体来促进它们的同时出现；2）在扩散模型的潜在空间中设计简单而有效的注意力控制策略以分离不同主体；3）通过从给定的参考图像中分割对象并提供相应的对象遮罩来帮助模型聚焦于特定区域。此外，还收集了一个多主体文本到视频生成的综合基准数据集。", "conclusion": "实验结果表明，我们的方法在定性、定量和用户研究中均优于之前最先进的方法，从而证明了CustomVideo框架的有效性。项目页面见此链接: isthis https URL。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.02096", "html_url": "https://arxiv.org/abs/2402.02096", "title": "UMCFuse: 统一多复杂场景红外与可见光图像融合框架", "title_en": "UMCFuse: A Unified Multiple Complex Scenes Infrared and Visible Image Fusion Framework", "authors": "Xilai Li,Xiaosong Li,Tianshu Tan,Huafeng Li,Tao Ye", "background": "红外和可见光图像的融合已成为计算机视觉研究中的一个突出领域。然而，在复杂场景下，融合任务的关注较少，导致在干扰下的结果不理想。本文针对这一问题，提出了适用于复杂场景的红外与可见光图像融合统一框架UMCFuse。", "innovation": "UMCFuse框架通过分类可见光图像中的像素，以光传输散射程度的差异来进行细节与整体亮度的分离。提出了自适应去噪策略来在干扰去除与细节保留间寻找平衡，并通过多方向分析不同模态的能量特征进行融合。实验结果表明UMCFuse方法在多项复杂场景任务中表现优越，且代码已开源。", "conclusion": "在实际与合成的复杂场景数据集上进行的融合实验一致表明，UMCFuse方法在不利气象条件、噪声、模糊、过曝、火灾以及包括语义分割、目标检测、显著对象检测和深度估计在内的下游任务中均优于最近的一些代表方法。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24446", "html_url": "https://arxiv.org/abs/2510.24446", "title": "SPARTA：基于文本自动编码器潜在空间的黑盒对抗性改写评估推理分割鲁棒性", "title_en": "SPARTA: Evaluating Reasoning Segmentation Robustness through Black-Box Adversarial Paraphrasing in Text Autoencoder Latent Space", "authors": "Viktoriia Zinkovich,Anton Antonov,Andrei Spiridonov,Denis Shepelev,Andrey Moskalenko,Daria Pugacheva,Elena Tutubalina,Andrey Kuznetsov,Vlad Shakhuro", "background": "多模式大型语言模型（MLLMs）已经在视觉-语言任务中显示出了令人印象深刻的性能，如推理解码分割，这些模型可以根据文本查询生成分割掩码。以往的研究主要集中在图像输入的扰动上，而这种在真实世界应用中用户以不同方式表达相同意图的同义文本表达（如语义等价的文本改写）仍然被严重忽视。为了填补这一空白，本文提出了一种新型的对抗性改写任务：生成语法正确的改写，这些改写能够保留原始查询含义的同时降低分割性能。为了评估对抗性改写的质量，作者开发了一套全面的自动评估协议，并通过人类研究进行了验证。此外，作者还提出了一种名为SPARTA的黑盒、句子级优化方法，该方法在文本自编码器的低维语义潜在空间中操作，并由强化学习引导。", "innovation": "论文的主要创新包括提出了一种针对视觉-语言任务的新的对抗性改写任务，这种任务需要生成语法正确且含义保留的改写，但能够降低模型的分割性能；开发了一套全面的自动评估协议，并通过人类研究进行了验证；引入了一种名为SPARTA的黑盒、句子级优化方法，该方法在文本自编码器的语义潜在空间中操作，并通过强化学习进行引导；SPARTA方法在ReasonSeg和LLMSeg-40k数据集中，相比之前的最优方法表现更好，成功率提高了2倍。", "conclusion": "本文使用SPARTA和竞争性基线评估了高级推理分割模型的鲁棒性，揭示这些模型在严格语义和语法约束下仍然容易受到对抗性改写的攻击。这些代码和数据将在论文被接受后对外公开。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24503", "html_url": "https://arxiv.org/abs/2510.24503", "title": "局部性能与分布外泛化：异质数据环境个性化联邦学习的实证分析", "title_en": "Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments", "authors": "Mortesa Hussaini,Jan Theiß,Anthony Stein", "background": "在联邦学习的异质数据环境中，本地模型倾向于在本地训练步骤中收敛到各自的局部最优模型，偏离整体数据分布。联邦学习常用方法如FedAvg在聚合局部更新时，通常无法与全局最优模型对齐（客户端漂移），导致大多数客户端的更新效果不佳。个性化联邦学习方法专注于客户的模型在其自身数据分布上的平均性能，但往往没有充分考虑到对分布外样本的泛化能力，而这是FedAvg等方法的一个重要优势。现有的评估和分析方法未能充分评估这一方面。本研究通过评估不同联邦学习方法的局部性能和泛化能力，使用MNIST和CIFAR-10数据集在不同的分布条件（包括基准IID和病理非IID，以及特定设计的狄利克雷分布测试环境）对上述方法进行实证对比研究，进一步提出并评估了一个改进版的FedAvg方法，称为带有个性化更新的联邦学习（FLIU），该方法通过一个简单的个性化步骤加入自适应个性化因子。", "innovation": "本研究提出了一种改进版的FedAvg方法，称为FLIU，通过一个简单的个性化步骤加入自适应个性化因子，以增强对分布式样本的泛化能力。研究通过?,?,?,?,?（具体实验设置）进行实证评估和对比研究，增强了对联邦学习方法局部性能和泛化能力的理解。", "conclusion": "本研究通过对联邦学习方法的实证分析，强调了对分布外样本的泛化能力评估的重要性，并提出了一种改进的方法以更好地满足这一需求。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.03520", "html_url": "https://arxiv.org/abs/2405.03520", "title": "Sora是否是一个世界模拟器？关于通用世界模型及其延伸的综合调研", "title_en": "Is Sora a World Simulator? A Comprehensive Survey on General World Models and Beyond", "authors": "Zheng Zhu,Xiaofeng Wang,Wangbo Zhao,Chen Min,Bohan Li,Nianchen Deng,Min Dou,Yuqi Wang,Botian Shi,Kai Wang,Chi Zhang,Yang You,Zhaoxiang Zhang,Dawei Zhao,Liang Xiao,Jian Zhao,Jiwen Lu,Guan Huang", "background": "通用世界模型是实现通用人工智能（AGI）的关键路径，它们作为虚拟环境和决策系统等应用的基础。最近，Sora模型因其卓越的模拟能力而受到广泛关注，因为它初步具备了对物理法则的理解。本文旨在全面探讨最新的世界模型进展，特别是在视频生成中的生成方法以及在自主驾驶世界模型中的应用及其对交通和城市移动方式的潜在影响。本文还深入探讨了部署在自主代理中的世界模型的复杂性及其在动态环境中的智能交互中的重要性，同时也指出了世界模型的挑战和局限性，并展望了未来的发展方向。", "innovation": "本文提供了一个详尽的世界模型综述，特别关注Sora模型的最新进展。它覆盖了世界模型在生成视觉内容和自主驾驶中的应用，以及在自主代理中的复杂性，揭示了这些模型在智能化交互中的关键作用。同时，本文还讨论了世界模型面临的主要挑战及其未来的研究方向。", "conclusion": "本文为研究社区提供了一个坚实的信息参考点，并鼓励持续的创新。希望本文能够激发更多关于通用世界模型及其相关领域的创新研究。作者承诺定期更新本文档，以反映最新的研究和发展。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24623", "html_url": "https://arxiv.org/abs/2510.24623", "title": "GroundLoc：高效的大规模室外仅激光雷达定位", "title_en": "GroundLoc: Efficient Large-Scale Outdoor LiDAR-Only Localization", "authors": "Nicolai Steinke,Daniel Goehring", "background": "当前，激光雷达（LiDAR）用于移动机器人在大规模室外环境中的定位时，通常依赖配合多种传感器以提高精度和可靠性。然而，这增加了成本和复杂性。该论文提出了一种仅依赖激光雷达进行定位的方法，旨在解决单一传感器在大规模室外环境中定位的挑战。", "innovation": "论文提出了名为GroundLoc的激光雷达（LiDAR）专用定位管道，它采用鸟瞰视角（BEV）图像投影关注地表感知区域，并使用R2D2或SIFT网络识别并选择关键点进行BEV图像地图注册。GroundLoc在多会话定位评估中表现出色，实现了所有Ouster OS2 128序列的平均轨迹误差不到50厘米，并且满足在线运行要求。该系统支持各种传感器模型，已通过使用Velodyne HDL-64E、Ouster OS2 128、Aeva Aeries II和Livox Avia传感器进行了评估。地面先验地图以2D栅格图像形式存储，可以从单次驾驶创建，且每平方公里仅需4 MB的存储空间。", "conclusion": "GroundLoc在可视化基准数据集SemanticKITTI和HeLiPR上超越了现有方法，在各种传感器上表现良好。在多会话定位评估中，GroundLoc在所有Ouster OS2 128序列中实现了低于50厘米的平均轨迹误差，同时满足在线运行需求。该系统支持多种传感器，并且地图存储空间小，仅为每平方公里4 MB。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.07046", "html_url": "https://arxiv.org/abs/2405.07046", "title": "RETTA: 提取增强的测试时自适应方法用于零样本视频字幕生成", "title_en": "RETTA: Retrieval-Enhanced Test-Time Adaptation for Zero-Shot Video Captioning", "authors": "Yunchuan Ma,Laiyun Qing,Guorong Li,Yuankai Qi,Amin Beheshti,Quan Z. Sheng,Qingming Huang", "background": "尽管完全监督的视频字幕取得了显著进展，但零样本方法仍然很少被探索。现有的研究大多集中在如何利用预训练的大型视觉和语言模型直接在测试时生成字幕。本文针对如何让文本生成模型充分了解给定视频的内容以生成相应的字幕这一挑战进行研究。", "innovation": "本文提出了一个新颖的零样本视频字幕框架，名为RETTA（Retrieval-Enhanced Test-Time Adaptation）。该框架使用四类模型进行视频和文本的桥梁构建：XCLIP（通用视频-文本检索模型）、CLIP（通用图像-文本匹配模型）、AnglE（文本对齐模型）和GPT-2（文本生成模型）。通过引入可学习的标记作为这四类冻结模型之间的通信介质，并使用特定的损失函数下的软目标学习这些标记，使模型能够吸收特定于GPT-2的视频信息，从而提高生成字幕的质量。", "conclusion": "在MSR-VTT、MSVD和VATEX三个广泛使用的数据集上进行的广泛实验证明，RETTA方法在主要指标CIDEr上比几个最先进的零样本视频字幕方法有5.1%-32.4%的绝对改进。这种无需使用真实数据的方法，使得模型在几轮迭代（实验中使用16轮）内就能进行高效的训练以适应视频内容。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.09782", "html_url": "https://arxiv.org/abs/2406.09782", "title": "基于分层特征引导扩散的无监督单目深度估计", "title_en": "Unsupervised Monocular Depth Estimation Based on Hierarchical Feature-Guided Diffusion", "authors": "Runze Liu,Dongchen Zhu,Guanghui Zhang,Yue Xu,Wenjun Shi,Xiaolin Zhang,Lei Wang,Jiamao Li", "background": "单目深度估计在没有地面真值的情况下训练受到了广泛关注，因为这种估计方法具有不依赖标记数据的优点。然而，在现实场景中，由于环境条件和相机固有限制，图像可能会有模糊或噪声。因此，开发出抗干扰能力强的深度估计模型尤为重要。", "innovation": "本文利用生成网络的训练策略引入了一种收敛良好的扩散模型进行无监督单目深度估计，并提出了分层特征引导去噪模块和隐式深度一致性损失，进而增强模型性能并保证视频序列中深度的一致性。", "conclusion": "我们的方法在多个数据集（KITT、Make3D和自收集的SIMIT）上进行了实验，并且其在生成网络基线模型中脱颖而出，展示了显著的鲁棒性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.20336", "html_url": "https://arxiv.org/abs/2405.20336", "title": "RapVerse：从文本生成连贯的歌声和全身动作", "title_en": "RapVerse: Coherent Vocals and Whole-Body Motions Generations from Text", "authors": "Jiaben Chen,Xin Yan,Yihang Chen,Siyuan Cen,Zixin Wang,Qinwei Ma,Haoyu Zhen,Kaizhi Qian,Lie Lu,Chuang Gan", "background": "现有的工作主要分别处理文本到语音和文本到动作的单一模态生成任务，很少有研究同时处理这两种模态。本文通过创建RapVerse数据集，结合同步的说唱歌词、音频和高质量的3D全身网格，旨在解决同时生成3D连贯动作和歌唱声音的任务，进一步推进该领域的研究边界。", "innovation": "引入RapVerse数据集，包含同步的说唱音频、歌词和高质量的3D全身网格，利用可跨语言、音频、运动扩展的自回归多模态变压器，以及矢量量化变分自编码器对全身动作进行编码并融合声音和动作，确保歌声与动作的统一和连贯。这种方法不仅能够从文本直接生成连贯的歌声和人体动作，还能够与专门针对单一模态的生成系统相媲美，建立了联合歌声-动作生成的新基准。", "conclusion": "通过联合方式对文本、音频和动作模态进行自回归多模态变压器建模，提出的统一生成框架不仅能够从文本生成连贯且真实的歌声和人体动作，也能够与专门的单模态生成系统竞争，为多模态同步生成提供了新的基准。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02076", "html_url": "https://arxiv.org/abs/2412.02076", "title": "具有空间意识持久特征匹配的拓扑保持图像分割", "title_en": "Topology-Preserving Image Segmentation with Spatial-Aware Persistent Feature Matching", "authors": "Bo Wen,Haochen Zhang,Dirk-Uwe G. Bartsch,William R. Freeman,Truong Q. Nguyen,Cheolhong An", "background": "在生物医学图像中，管状结构的分割依赖于其拓扑正确性，现有的拓扑分割损失函数主要基于图像的持久同调理论。它们通过匹配分割的持久特征与真值的持久特征，并最小化两者之间的差异来实现。但是，这些方法存在匹配不明确的问题，因为匹配仅依赖于拓扑空间的信息。", "innovation": "本文提出了一种高效的空间感知拓扑损失函数，进一步利用图像原始空间域中的信息来辅助持久特征的匹配。实验表明，与最先进的方法相比，所提方法在提高分割的拓扑准确性方面具有优越性。", "conclusion": "在各种类型的管状结构图像上进行的大量实验表明，所提出的方法在提高分割的拓扑准确性方面比最先进的方法具有更好的表现。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.18833", "html_url": "https://arxiv.org/abs/2412.18833", "title": "带有部分标注数据的联邦学习：一种条件蒸馏方法", "title_en": "Federated Learning with Partially Labeled Data: A Conditional Distillation Approach", "authors": "Pochuan Wang,Chen Shen,Masahiro Oda,Chiou-Shann Fuh,Kensaku Mori,Weichung Wang,Holger R. Roth", "background": "在医学成像领域，开发能够处理多种器官和病灶的通用分割模型至关重要。然而，标注数据稀缺和严格的隐私法规限制了数据共享。现有的联邦学习方法在处理部分标注数据时常常遇到模型发散和灾难性遗忘的问题。", "innovation": "本文提出了ConDistFL，这是一种新的联邦学习框架，集成了条件蒸馏以解决上述挑战。ConDistFL能够有效利用部分标注数据，显著提高分布式和非均匀数据集的分割精度。此外，ConDistFL还保持了计算和通信效率，确保其在实际应用中的可扩展性。此外，ConDistFL展示了出色的泛化能力，在我们的实验中，即使在未见到对比度阶段（如非对比CT图像）的情况下，也显著优于现有的联邦学习方法。", "conclusion": "通过对3D CT和2D胸部X射线数据集的广泛评估，本文证明了ConDistFL是一个高效且适应性强的解决方案，适用于受隐私约束的协作医学图像分割。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02542", "html_url": "https://arxiv.org/abs/2412.02542", "title": "揭示扩散模型的概念归因", "title_en": "Unveiling Concept Attribution in Diffusion Models", "authors": "Quang H. Nguyen,Hoang Phan,Khoa D. Doan", "background": "扩散模型在从文本提示生成逼真高质量图像方面显示出显著的能力，但这些模型仍然很大程度上是黑盒的，我们对组件在展示概念（如物体或风格）中的作用了解甚少。现有工作通过因果追踪来定位知识存储层，但未说明其他层如何贡献于目标概念。本文采用扩散模型可解释性的更广泛视角，探讨了模型组件如何共同展示知识。", "innovation": "提出了基于组件归因的方法CAD（Component Attribution for Diffusion Model），不仅发现了引发概念的正面组件，还揭示了另一类对生成概念产生负面影响的组件。本文还介绍了两种快速推理时模型编辑算法，CAD-Erase和CAD-Amplify，以及框架的实现效果得到了广泛实验结果的支持，证明了提供了生成模型解释的完整视图的潜力。", "conclusion": "基于CAD框架实现的全面理解，本文介绍了两项新的模型编辑算法，能够针对性地增强或减弱生成的概念同时保留其他概念的知识，验证了正面和负面组件的重要性，展示了对未来生成模型解释潜力的提升。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.05177", "html_url": "https://arxiv.org/abs/2502.05177", "title": "Long-VITA: 扩展大型多模态模型至百万标记，具备领先短语境准确性", "title_en": "Long-VITA: Scaling Large Multi-modal Models to 1 Million Tokens with Leading Short-Context Accuracy", "authors": "Yunhang Shen,Chaoyou Fu,Shaoqi Dong,Xiong Wang,Yi-Fan Zhang,Peixian Chen,Mengdan Zhang,Haoyu Cao,Ke Li,Shaohui Lin,Xiawu Zheng,Yan Zhang,Yiyi Zhou,Ran He,Caifeng Shan,Rongrong Ji,Xing Sun", "background": "现有大型多模态模型在短语境多模态任务上表现出色，但在长序列视觉语言理解任务上存在挑战。研究人员致力于开发能够在长输入下仍保持高性能的模型。", "innovation": "提出了一种有效的多模态训练方案，采用从大规模语言模型开始，经过视觉语言对齐、一般知识学习，以及两次长期序列微调，同时引入了上下文并行分布式推理和掩码语言模型头部，以处理长输入。", "conclusion": "Long-VITA 模型在多种多模态基准测试中达到了最先进的性能，并且是开源的。通过该模型的设计，实现了每节点8 GPU 单节点上的2倍预填充速度提升和4倍上下文长度扩展。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.02885", "html_url": "https://arxiv.org/abs/2501.02885", "title": "MDP3：一种无训练的Video-LLMs全局帧选择方法", "title_en": "MDP3: A Training-free Approach for List-wise Frame Selection in Video-LLMs", "authors": "Hui Sun,Shiyin Lu,Huanyu Wang,Qing-Guo Chen,Zhao Xu,Weihua Luo,Kaifu Zhang,Ming Li", "background": "视频大型语言模型（Video-LLMs）在理解视频方面取得了显著进展，但处理多帧会导致较长的视觉标记序列，这带来了挑战，如有限的上下文长度无法容纳整个视频，以及包含无关帧会阻碍视觉感知。因此，有效的帧选择至关重要。", "innovation": "本文提出了一个无训练且模型无关的方法MDP3（Markov决定性点过程与动态规划）进行帧选择。该方法首先利用条件高斯核在重复核希尔伯特空间内估计帧相似性，然后应用确定性点过程到相似矩阵中，以捕捉查询相关性和列表级多样性。通过在每个片段中应用确定性点过程，结合马尔可夫决策过程对各个片段的选择大小进行建模以引入序列性，从而提高选择的顺序一致性。MDP3在理论上提供了NP难题列表级帧选择问题的(1 - 1/e)-近似解，并在假定多项式时间复杂度下展示了其效率。", "conclusion": "实验结果表明，MDP3在多个基准测试上显著优于现有方法，验证了其有效性和鲁棒性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.09282", "html_url": "https://arxiv.org/abs/2502.09282", "title": "MsEdF：一种用于遥感图像描述的多流编码解码框架", "title_en": "MsEdF: A Multi-stream Encoder-decoder Framework for Remote Sensing Image Captioning", "authors": "Swadhin Das,Raksha Sharma", "background": "遥感图像包含复杂的空间模式和语义结构，这使得描述模型难以准确描述。编码-解码架构已经成为遥感图像描述（RSIC）中的广泛应用的方法，通过将视觉内容转译为描述性文字。然而，许多现有方法依赖于单流架构，这削弱了模型准确描述图像的能力。单流架构通常难以提取多样化的空间特征或捕捉复杂语义关系，限制了它们在高类内相似度场景或上下文歧义中的有效性。", "innovation": "本文提出了一种新的多流编码-解码框架（MsEdF），以通过优化编码器-解码器架构的空间表示和语言生成来提高RSIC性能。编码器通过融合两种互补的图像编码器的信息，利用多尺度和结构上不同的提示来促进特征多样性。解码器方面，通过采用堆叠的GRU架构和元素级聚合方案来改进上下文感知的描述捕获。实验结果显示，MsEdF 在三个基准RSIC数据集上表现出色，优于几个基线模型。", "conclusion": "MsEdF通过优化空间表示和语言生成，提高了编码-解码架构在RSIC中的性能。实验结果表明，MsEdF在多种基准数据集上显著优于其他模型。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.12427", "html_url": "https://arxiv.org/abs/2502.12427", "title": "频率意识到视知觉变换器在地球系统模型高保真超分辨率中的应用", "title_en": "Frequency-Aware Vision Transformers for High-Fidelity Super-Resolution of Earth System Models", "authors": "Ehsan Zeraatkar,Salah A Faroughi,Jelena Tešić", "background": "高分辨率（超分辨率）对于增强地球系统模型（ESM）输出的空间准确性至关重要，能够从粗略的模拟中恢复出对气候变化至关重要的精细结构。然而，传统的深度超分辨率方法，如卷积和基于变换器的模型，往往表现出光谱偏差，更容易重建低频内容而忽视有价值的高频细节", "innovation": "我们引入了两种频率意识框架：Vision Transformer-Tuned Sinusoidal Implicit Representation (ViSIR)，结合了视知觉变换器和正弦激活函数以减轻光谱偏差；Vision Transformer Fourier Representation Network (ViFOR)，将显式傅里叶过滤器集成到独立低频和高频学习中。这些模型在E3SM-HR地球系统数据集上的表现优于最先进的卷积神经网络、生成对抗网络和基于变换器的基本模型，ViFOR在峰值信噪比(PSNR)上显著提高了2.6 dB，在结构相似性指数(SSIM)上的表现也更好。详细的消融研究和扩展研究强调了整体场训练、频率超参数的影响和通用性的潜力", "conclusion": "结果确立了ViFOR作为高分辨率气候数据降尺度的先进、可扩展解决方案。未来的研究将解决时间超分辨率、多模态气候变量、自动化参数选择以及物理守恒约束的集成，以扩大科学应用范围"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06456", "html_url": "https://arxiv.org/abs/2503.06456", "title": "DynCIM: 动态课程学习方法在不平衡多模态学习中的应用", "title_en": "DynCIM: Dynamic Curriculum for Imbalanced Multimodal Learning", "authors": "Chengxuan Qian,Kai Han,Jiaxin Liu,Zhenlong Yuan,Zhengzhong Zhu,Jingchao Wang,Chongwen Lyu,Jun Chen,Zhe Liu", "background": "多模态学习通过整合不同模态的信息来改善决策过程。然而，由于数据质量和模态表示能力的差异，多模态合作的潜力仍未得到充分利用。", "innovation": "我们提出了DynCIM，一种新颖的动态课程学习框架，旨在从样本和模态两个层面量化固有的不平衡。DynCIM通过样本级别的课程动态评估每个样本的难度，通过模态级别的课程衡量模态的贡献。此外，还引入了一种基于门控的动态融合机制，以适应性调整模态的贡献，从而减少冗余并优化融合效果。在六个多模态基准数据集上进行的实验表明，DynCIM始终优于最先进的方法，我们的方法有效缓解了模态和样本的不平衡，提高了多模态学习任务的适应性和鲁棒性。", "conclusion": "我们的方法有效缓解了模态和样本的不平衡，增强了多模态学习任务的适应性和鲁棒性。我们的代码在此处提供：this https URL."}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06415", "html_url": "https://arxiv.org/abs/2503.06415", "title": "多边形网络的扭转紊乱及扭转距离", "title_en": "Polygonal network disorder and the turning distance", "authors": "Alex Dolce,Ryan Lavelle,Bernard Scott,Ashlyn Urbanski,Joseph Klobusicky", "background": "扭转距离是用于衡量两个多边形相似性的广泛研究的度量标准。它通过计算跟踪多边形边界路径的切线角度的不同阶梯函数之间的L^p距离来构建。", "innovation": "本文引入了多边形平面网络的扭转紊乱，这是通过对网络面和有序形状（正多边形或圆）之间的扭转距离进行平均来定义的。同时，本文推导了几种特殊种类正多边形的扭转距离的闭形式表达式，以及正多边形与圆之间的距离表达式，并展示了在两种正多边形之间的2次扭转距离计算时间可以从O(mnlog(mn))减少到O((m+n)log(m+n))。此外，本文还探讨了扭转紊乱在Archimedean晶格、弹簧网络以及多边形破裂过程中的应用。", "conclusion": "两类扭转紊乱的定义方式——选择有序形状以及是否进行面积加权——可以表征不同的网络紊乱概念。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17071", "html_url": "https://arxiv.org/abs/2503.17071", "title": "超级增强开放词汇对象检测器以实现X射线视觉", "title_en": "Superpowering Open-Vocabulary Object Detectors for X-ray Vision", "authors": "Pablo Garcia-Fernandez,Lorenzo Vaquero,Mingxuan Liu,Feng Xue,Daniel Cores,Nicu Sebe,Manuel Mucientes,Elisa Ricci", "background": "开放词汇对象检测（OvOD）旨在通过使系统能够识别X射线扫描中的任何物品，革新安全检查。然而，开发适用于X射线成像的有效OvOD模型面临独特挑战，包括数据稀缺性和光谱模态差异，这阻止了直接使用基于RGB的解决方案。由于这些局限，现有方法难以有效应用于X射线成像中。", "innovation": "本文提出了一种名为RAXO的训练无框架，该框架能够利用现成的RGB OvOD检测器来提升X射线检测效果。RAXO通过一种双源检索策略构建高质量的X射线类别描述符，并使用一种新颖的X射线材料转移机制从网络中收集相关RGB图像并丰富它们。该视觉描述符取代了基于文本的分类，利用模态内部特征距离实现鲁棒检测。此方法在广泛实验中展示了高度一致的性能改进，与基础检测器相比，平均mAP提高了17.0分。", "conclusion": "文章通过增加新的数据集和评估基准DET-COMPASS支持此新兴领域的进一步研究。该数据集提供了超过300种物体类别的边界框注释，用于大规模评估X射线中的OvOD性能。研究团队还提供了代码和数据集供公众访问。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.02787", "html_url": "https://arxiv.org/abs/2410.02787", "title": "在VLM框架下的导航：通往任何语言", "title_en": "Navigation with VLM framework: Towards Going to Any Language", "authors": "Zecheng Yin,Chonghao Cheng,and Yao Guo,Zhen Li", "background": "在探索全开放语言目标和以智能方式探索开放场景方面始终存在重大挑战。尽管已有许多研究工作集中利用视觉语言模型（VLMs）进行开放场景中的导航，但它们往往需要高计算成本、依赖于以物体为中心的方法或依赖于详细的人类指令中的环境先验知识。", "innovation": "我们介绍了一种无需训练的框架——基于VLM的导航（NavVLM），利用开源VLM使机器人能够有效导航，甚至能够处理诸如抽象地点、动作或特定物体等人类友好的语言目标。NavVLM利用VLM作为认知核心，通过仅提供简洁目标实现智能导航，而不需要详细的包含环境先验的指令。该框架在模拟和真实世界的实验中均得到了评估和验证。在模拟实验中，其性能达到了在Matterport 3D（MP3D）、Habitat Matterport 3D（HM3D）和Gibson等丰富详细的环境中执行具体任务的最新水平；而在真实世界的验证中，该框架被证明对室内场景中的机器人导航具有有效性。", "conclusion": "该框架在模拟和实际环境中均展示了其导航能力，特别在处理开放式的语言目标方面表现出色。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.23502", "html_url": "https://arxiv.org/abs/2503.23502", "title": "使用预训练深度基础模型提升全景立体匹配", "title_en": "Boosting Omnidirectional Stereo Matching with a Pre-trained Depth Foundation Model", "authors": "Jannik Endres,Oliver Hahn,Charles Corbière,Simone Schaub-Meyer,Stefan Roth,Alexandre Alahi", "background": "全方位深度感知是移动机器人应用中跨整个360°视野进行场景理解的重要需求。基于相机的设置通过使用立体深度估计生成密集的高分辨率深度图，提供了一种成本效益高的选择，无需依赖昂贵的主动传感。然而，现有的全方位立体匹配方法在不同环境、深度范围和光照条件下的深度精度有限，主要原因是缺乏真实世界的数据。", "innovation": "提出了DFI-OmniStereo，一种创新性的全方位立体匹配方法，利用大规模预训练基础模型进行迭代优化立体匹配架构中的相对单目深度估计。创新点在于引入了专门的两阶段训练策略，首先利用相对单目深度特征进行全方位立体匹配，之后进行尺度不变性微调。", "conclusion": "DFI-OmniStereo在现实世界的Helvipad数据集上取得了最先进的效果，相比此前最好的全方位立体匹配方法，减少了约16%的视差MAE。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.06131", "html_url": "https://arxiv.org/abs/2504.06131", "title": "FaceCloak：学习保护人脸识别模板", "title_en": "FaceCloak: Learning to Protect Face Templates", "authors": "Sudipta Banerjee,Anubhav Jain,Chinmay Hegde,Nasir Memon", "background": "生成模型可以从编码表示（模板）重建人脸图像，这些图像与原始人脸极为相似，引发了安全和隐私方面的担忧。", "innovation": "提出了一种名为FaceCloak的神经网络框架，通过生成智能、可再生的二元遮罩来保护人脸模板。该方法通过从单个人脸模板中即时合成独特的干扰器来主动对抗逆向工程攻击，并在不牺牲生物识别效用和匿名性的情况下实现这一目标。遮蔽后的模板可以抑制敏感属性，并能够适应新的特征提取方案，同时在生物识别匹配和抵御重建攻击方面优于现有基准。基于FaceCloak的匹配非常快速（推理时间为0.28毫秒）且轻量（0.57 MB）。", "conclusion": "我们已公开了用于可再现研究的代码。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.09336", "html_url": "https://arxiv.org/abs/2503.09336", "title": "3D Point Cloud中的基于曲率感知的隐形片级后门攻击", "title_en": "Stealthy Patch-Wise Backdoor Attack in 3D Point Cloud via Curvature Awareness", "authors": "Yu Feng,Dingxin Zhang,Runkai Zhao,Yong Xia,Heng Huang,Weidong Cai", "background": "深度神经网络（DNNs）面临后门攻击的严重威胁，这种攻击通过植入隐形后门，在特定触发条件下激活这些后门以恶意操控模型的行为。现有的3D点云后门攻击主要依赖样本级的整体修改，但这降低了隐形性。虽然优化可以提高隐蔽性，但样本级触发的优化会大幅增加计算成本。", "innovation": "提出了基于曲率感知的隐形片级后门攻击（SPBA），这是首个针对3D点云的片级后门攻击框架。SPBA通过将点云分解为局部片段，并利用基于曲率的隐形性评分来指引向视觉不敏感的片段注入触发器。SPBA优化统一的片级触发器来扰动选定片段的频谱特性，显著提高了优化效率同时保持高度隐形性。", "conclusion": "在ModelNet40和ShapeNetPart上的广泛实验进一步证明，SPBA在攻击效果和对抗防御方法的抵抗力上都优于现有的先进后门攻击。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.11049", "html_url": "https://arxiv.org/abs/2502.11049", "title": "公平性的面孔：探索面部表情识别数据集和模型中的偏见", "title_en": "Faces of Fairness: Examining Bias in Facial Expression Recognition Datasets and Models", "authors": "Mohammad Mehdi Hosseini,Ali Pourramezan Fard,Mohammad H. Mahoor", "background": "面部表情识别（FER）系统的构建涉及数据和模型设计两个关键方面，二者在FER任务中都显著影响了偏差和公平性。现有研究中，关于FER数据集和模型中偏差及公平性的问题尚未得到充分探索。本研究旨在探讨FER数据集和模型中的偏差来源，分析了AffectNet、ExpW、Fer2013和RAF-DB等四个常用FER数据集，并评估了六种深度模型，包括三种最新的卷积神经网络（CNN）模型（MobileNet、ResNet、XceptionNet）和三种基于Transformer的模型（ViT、CLIP、GPT-4o-mini）。", "innovation": "研究创新地将重点放在对四大常用数据集和六种不同模型进行系统性的评估，并特别关注模型在保持高准确率的同时是否也保持着尽可能低的偏差水平，特别是在采用了最新的人工智能模型（如ViT和GPT-4o-mini）的情况下。通过这些评估，揭示了在情感计算应用中需要开发新的方法论来减轻偏差和确保公平性的重要性。", "conclusion": "研究结果表明，尽管AffectNet和ExpW数据集在数据不平衡的情况下仍表现出良好的泛化能力，但GPT-4o-mini和ViT模型尽管达到了最高的准确度，同时显示出了最高的偏差水平。这强调了在面部表情识别领域设计更公平、无偏的数据集和模型的迫切需求，尤其是对于情感计算的应用而言。本研究还提供了完整的实施细节，以便其他研究者能够复现和扩展这些研究。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04852", "html_url": "https://arxiv.org/abs/2503.04852", "title": "CAUSAL3D: 从视觉数据中学习因果关系的全面基准", "title_en": "CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data", "authors": "Disheng Liu,Yiran Qiao,Wuche Liu,Yiren Lu,Yunlai Zhou,Tuo Liang,Yu Yin,Jing Ma", "background": "人工智能和计算机视觉取得了显著的进步，但缺乏评估模型从复杂视觉数据中推断潜在因果关系能力的基准。真正的人工智能依赖于发现和利用隐藏的因果关系。本研究提出了Causal3D，一个全新的综合基准，旨在通过结合结构化数据（表格）与对应的视觉表示（图像）来评估因果推理能力，涵盖19个3D场景数据集，展示多样化的因果关系、视角和背景，适用于不同复杂度场景的评估。\n", "innovation": "Causal3D是首个用于3D场景中从视觉数据推断因果关系的综合基准。它融合了结构化数据和视觉表示，提供了一个系统框架，评估当前最先进的方法，包括经典因果发现、因果表示学习以及大规模/视觉语言模型。实验结果显示，随着因果结构复杂度的增加，缺乏先验知识的情况下，性能显著下降，这凸显了在复杂因果场景中即使先进方法也面临的挑战。因此，Causal3D为视觉因果推理研究提供了一个宝贵资源，有助于推动人工智能在关键领域的可信发展。\n", "conclusion": "Causal3D作为一个重要的资源，能够推动视觉因果推理研究，并促进关键领域中的可信人工智能的发展。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13043", "html_url": "https://arxiv.org/abs/2505.13043", "title": "跨域注视估计的一般化标签偏移视角", "title_en": "A Generalized Label Shift Perspective for Cross-Domain Gaze Estimation", "authors": "Hao-Ran Yang,Xiaohui Chen,Chuan-Xian Ren", "background": "为了在新目标领域泛化经过充分训练的注视估计模型，本文提出了跨域注视估计（CDGE），以适应实际应用场景。现有的CDGE方法通常提取域不变特征以减轻特征空间的域移位现象，但已被GLS理论证明不足。", "innovation": "本文从GLS视角出发，重新定义了跨域问题，通过标签和条件移位问题建模，并提出了一种GLS校正框架。提出了基于截尾高斯分布的重要性加权策略来克服标签移位校正中的连续性挑战，并进一步推导出一种条件算子不连续性概率感知估计方法。文章在不同骨干模型的标准CDGE任务上进行了大量实验，验证了新方法的优越的跨域泛化能力和应用性。", "conclusion": "所提出的GLS校正框架和其概率感知的条件算子估计方法在多个标准CDGE任务上展示了更好的泛化能力和适用性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.05900", "html_url": "https://arxiv.org/abs/2410.05900", "title": "MTFL: 多时间尺度特征学习在监视视频中弱监督异常检测中的应用", "title_en": "MTFL: Multi-Timescale Feature Learning for Weakly-Supervised Anomaly Detection in Surveillance Videos", "authors": "Yiling Zhang,Erkut Akdag,Egor Bondarev,Peter H. N. De With", "background": "异常事件的检测对公共安全至关重要，需要结合细粒度的运动信息和上下文事件，同时在可变量时间尺度上进行。为此，该研究提出了一种多时间尺度特征学习（MTFL）方法，以增强异常特征的表示。通过使用Video Swin Transformer提取时空视频特征，管段（包括短期、中期和长期三种时间尺度）被用来捕获动态变化。实验结果表明，MTFL在UCF-Crime数据集上优于现有最佳方法，实现了89.78%的AUC异常检测性能。并且，在ShanghaiTech和XD-Violence数据集上也表现出良好的补充性，AUC得分分别为95.32%和AP得分84.57%。此外，为了进一步开发和评价更广泛的异常类型，还创建了UCF-Crime的扩展数据集Video Anomaly Detection Dataset（VADD），涉及18个类别的2,591个视频，广泛涵盖了现实中的异常情况。", "innovation": "提出了多时间尺度特征学习（MTFL）方法，利用Video Swin Transformer和三种时间尺度的管段来提高异常特征的表示。该方法在多个数据集上表现出优越的性能，尤其是在UCF-Crime数据集上的AUC达到89.78%。此外，还创建了涵盖更广泛异常类型的扩展数据集VADD，旨在促进该领域的进一步研究和发展。", "conclusion": "研究展示了MTFL在异常检测领域的有效性，特别是在公共安全监测中。同时，通过创建VADD数据集，为更广泛的异常检测研究提供了支持。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12702", "html_url": "https://arxiv.org/abs/2505.12702", "title": "Long-RVOS：长时易观测对象分割的综合基准", "title_en": "Long-RVOS: A Comprehensive Benchmark for Long-term Referring Video Object Segmentation", "authors": "Tianming Liang,Haichao Jiang,Yuting Yang,Chaolei Tan,Shuai Li,Wei-Shi Zheng,Jian-Fang Hu", "background": "参考视频对象分割（RVOS）旨在基于语言描述在视频中识别、跟踪和分割对象，近年来得到了广泛关注。然而，现有的数据集主要关注几秒钟以内的短视频剪辑，且大多数帧中存在显著的对象。为了使任务更接近实际场景，作者引入了一个大规模的基准——Long-RVOS，用于长时参考视频对象分割，它包含2000多个平均长度超过60秒的视频，涵盖了经过遮挡、消失再现和镜头转换的多种对象，并且对这些对象进行了手动注释，以分别评估静止属性、运动模式和时空关系的理解。", "innovation": "1. 长视频基准Long-RVOS，视频长度超过60秒，包含多种场景，提供了更实际的数据集。\n2. 引入两种新指标来评估时间和时空一致性，不同于以往仅依赖于逐帧的时空评估。\n3. 提出了一种名为ReferMo的基准方法，该方法结合运动信息扩展了时域感受野，并采用局部到全局的架构同时捕捉短时动态和长时依赖关系，从而在长时间场景中实现了显著改进。", "conclusion": "当前的方法在Long-RVOS中面临着严重的挑战。作者希望Long-RVOS和基准方法能够推动未来RVOS研究朝着处理更真实和长视频的方向发展。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.18384", "html_url": "https://arxiv.org/abs/2503.18384", "title": "LiDAR遥感遇上弱监督：概念、方法与展望", "title_en": "LiDAR Remote Sensing Meets Weak Supervision: Concepts, Methods, and Perspectives", "authors": "Yuan Gao,Shaobo Xia,Pu Wang,Xiaohuan Xi,Sheng Nie,Cheng Wang", "background": "LiDAR遥感涵盖了数据解释和参数反演两大方向，但这两个方向都严重依赖昂贵且劳动密集型的标签数据和实地测量，这限制了它们的可扩展性和时空适应性。现有的监督学习方法依赖于高质量的标签数据，这增加了研究成本。而弱监督学习提供了一个统一的框架，可以通过不完全、不准确或不一致的标签进行学习，从而简化了数据获取和标注过程，提高了数据利用效率和适用性。", "innovation": "本文打破了将数据解释和参数反演视为独立任务的传统观念，从统一的弱监督学习视角概述了LiDAR遥感领域近期的发展，并涵盖了典型弱监督设定（如稀疏点标签、场景级别标签、噪声标签、跨域监督等）及相应的技术方法（如伪标签、一致性正则化、自我训练、标签精炼等），以增强从有限和弱标签中学习的能力。同时，文章进一步分析了LiDAR特有的挑战（如不规则几何结构、数据稀疏性、域异质性），并探讨了稀疏LiDAR观测如何引导与其它遥感数据的联合学习，为持续表面参数恢复提供了可能。", "conclusion": "文章强调了弱监督学习在接合LiDAR与基础模型之间的桥梁作用，建议利用大规模多模态数据集来减少标注成本，同时促进了更广泛的弱监督学习驱动的通用化、开放世界适应性和大规模可扩展LiDAR遥感的发展。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13389", "html_url": "https://arxiv.org/abs/2505.13389", "title": "VSA: 更快的视频扩散变换利用可训练稀疏注意", "title_en": "VSA: Faster Video Diffusion with Trainable Sparse Attention", "authors": "Peiyuan Zhang,Yongqi Chen,Haofeng Huang,Will Lin,Zhengzhong Liu,Ion Stoica,Eric Xing,Hao Zhang", "background": "视频扩散变换器（DiTs）受到其三维注意力机制的二次复杂性限制，尽管大多数注意力集中于少量位置上。现有的方法无法有效利用这种现象，从而限制了模型的进一步扩展。", "innovation": "VSA（可训练稀疏注意力）是一种硬件高效且可训练的稀疏注意力机制，可以在训练和推理中全面取代全注意力机制。VSA包含粗略阶段和精细阶段，粗略阶段通过池化令牌形成瓷砖并识别高权重的关键令牌；精细阶段仅在这些瓷砖内部计算令牌级别注意力，确保高效计算布局。这种方法形成了一个端到端可训练的单一可微内核，无需后处理配置，并保持了85%的FlashAttention3 MFU性能。通过从60M到1.4B参数规模的大规模预训练实验，证明了VSA在保持扩散损失不变的情况下，将训练FLOPS降低了2.53倍。此外，将开源Wan-2.1模型进行适应性改进，能将注意时间加速6倍，从端到端生成时间31s降低到18s，保持质量的同时提升了速度。", "conclusion": "这些结果确立了可训练稀疏注意力作为全注意力的实用替代方案，并成为进一步扩展视频扩散模型的关键使能技术。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20426", "html_url": "https://arxiv.org/abs/2505.20426", "title": "MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness", "title_en": "MMPerspective: Do MLLMs Understand Perspective? A Comprehensive Benchmark for Perspective Perception, Reasoning, and Robustness", "authors": "Yolo Yunlong Tang,Pinxin Liu,Zhangyun Tan,Mingqian Feng,Rui Mao,Chao Huang,Jing Bi,Yunzhong Xiao,Susan Liang,Hang Hua,Ali Vosoughi,Luchuan Song,Zeliang Zhang,Chenliang Xu", "background": "理解视角是人类视觉感知的基础，然而，关于多模态大型语言模型（MLLMs）是否能够内化视角几何的理解仍不清楚。这项研究旨在评估MLLMs在视角认知、推理和鲁棒性方面的表现。", "innovation": "作者提出了MMPerspective，这是首个专门设计用于系统性评估MLLMs视角理解能力的基准，包含10个精心设计的任务，涉及视角感知、推理以及鲁棒性。基准测试包括2,711个真实和合成图像实例，以及5,083个问-答对，从而检测出模型在透视消失点感知、透视类型推理、三维空间线关系理解以及保持透视变换不变性等方面的能力。通过全面评估43个最先进的MLLMs，揭示了模型在表面感知任务上的能力，但在组合推理和维持空间一致性方面的不足。", "conclusion": "MMPerspective 成功揭示了MLLMs在理解视角方面的显著局限性，并发现了模型架构、规模与视角能力之间的有趣模式，为诊断和提升视觉-语言系统的空间理解能力提供了有力工具。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20744", "html_url": "https://arxiv.org/abs/2505.20744", "title": "MoPFormer：用于穿戴传感器活动识别的运动本征变换器", "title_en": "MoPFormer: Motion-Primitive Transformer for Wearable-Sensor Activity Recognition", "authors": "Hao Zhang,Zhan Zhuang,Xuehao Wang,Xiaodong Yang,Yu Zhang", "background": "穿戴传感器的人活动识别（HAR）挑战在于其有限的可解释性，这严重影响了不同数据集之间的泛化能力。", "innovation": "提出了一种名为MoPFormer的新颖自监督框架，通过将惯性测量单元信号分解为具有语义意义的运动本征，并利用Transformer架构学习丰富的时序表示来增强可解释性。", "conclusion": "MoPFormer在多个HAR基准测试中不仅优于现有最佳方法，而且能够在多个数据集之间成功泛化。更重要的是，学习到的运动本征显著提高了可解释性和跨数据集性能，捕捉到在相似活动下保持一致的基础运动模式，而不依赖于数据集的来源。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21724", "html_url": "https://arxiv.org/abs/2505.21724", "title": "OmniResponse：双向互动中实时多模态对话响应生成", "title_en": "OmniResponse: Online Multimodal Conversational Response Generation in Dyadic Interactions", "authors": "Cheng Luo,Jianghui Wang,Bing Li,Siyang Song,Bernard Ghanem", "background": "在线会话中，多模态对话响应生成旨在基于演讲者的多模态输入同步生成口述和非口述的听众反馈。这项任务捕捉了自然的双向互动，并引入了将生成的音频与听众面部反应对齐的新挑战。", "innovation": "提出了Online Multimodal Conversational Response Generation（OMCRG）任务和一种名为OmniResponse的多模态大型语言模型（MLLM）。OmniResponse通过引入文本作为一种中间模态将音频和面部响应连接起来，并且利用预训练的语言模型增强了两个核心组件：Chrono-Text Markup（精确时间戳生成的文字标记）和 TempoVoice（可控的在线文本到语音模块）。此外，该研究还提供了名为ResponseNet的数据集，包含696个详细互动的同步视频和音频、转录以及面部行为标注。", "conclusion": "在ResponseNet上的全面评估表明，OmniResponse在语义语音内容、音频-视觉同步以及生成质量方面均优于基线模型。该研究的数据集、代码和模型已公开可用，有助于推动OMCRG领域的研究进步。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.00129", "html_url": "https://arxiv.org/abs/2506.00129", "title": "Geo-Sign：几何对比正则化及其在几何感知手语翻译中的应用", "title_en": "Geo-Sign: Hyperbolic Contrastive Regularisation for Geometrically Aware Sign Language Translation", "authors": "Edward Fish,Richard Bowden", "background": "近年来，手语翻译（SLT）的研究主要集中在提高大型语言模型的表示能力，以便更好地整合手语特征。这项工作探索了一种新的方向：即通过提升骨骼表示本身的几何特性来增强手语翻译的效果。", "innovation": "提出了Geo-Sign 方法，利用双曲几何的特性来建模手语动作中的固有层次结构。通过将时空图卷积网络（ST-GCNs）提取的骨骼特征投影到庞加莱球模型中，旨在创建更具有区分性的嵌入，特别是对于手指动作等精细动作。引入了双曲投影层、加权Fréchet平均聚合方案和直接在双曲空间中操作的几何对比损失。这些组件被集成到一个端到端的翻译框架中，作为正则化函数，以增强语言模型中的表示。", "conclusion": "研究表明，双曲几何在提升用于手语翻译的骨骼表示方面有潜力，同时改善了基于RGB的方法的性能，保持了隐私并提高了计算效率。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11842", "html_url": "https://arxiv.org/abs/2505.11842", "title": "Video-SafetyBench：大型视觉语言模型基于视频的安全评估基准", "title_en": "Video-SafetyBench: A Benchmark for Safety Evaluation of Video LVLMs", "authors": "Xuannan Liu,Zekun Li,Zheqi He,Peipei Li,Shuhan Xia,Xing Cui,Huaibo Huang,Xi Yang,Ran He", "background": "随着大型视觉语言模型（LVLMs）的广泛应用，这些模型在潜在恶意输入下的安全性引起了担忧。现有的多模态安全评估主要集中在静态图像输入暴露的模型漏洞上，而忽视了视频中的时间动态，这可能导致独特的安全风险。", "innovation": "本文引入了Video-SafetyBench，这是第一个为评估LVLM在视频文本攻击下的安全性而设计的综合基准。它包含2264个视频-文本配对，涵盖了48个细粒度的不安全类别，每个配对都包含与合成视频关联的有害查询或看似无害但与视频结合后会导致有害行为的良性查询。此外，还设计了一种新的基于LLM的度量标准RJScore，它结合了法官模型的信心和人类校准的决策阈值，以有效评估不确定或临界有害输出。", "conclusion": "大规模实验显示，良性查询视频组成的平均攻击成功率达到了67.2%，揭示了模型对视频诱导攻击的一致性漏洞。我们相信Video-SafetyBench将促进基于视频的安全评估和防御策略的研究。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.04897", "html_url": "https://arxiv.org/abs/2506.04897", "title": "从物体到任何地方：3D场景多层次视觉定位的全面基准", "title_en": "From Objects to Anywhere: A Holistic Benchmark for Multi-level Visual Grounding in 3D Scenes", "authors": "Tianxu Wang,Zhuofan Zhang,Ziyu Zhu,Yue Fan,Jing Xiong,Pengxiang Li,Xiaojian Ma,Qing Li", "background": "3D视觉定位已经在复杂3D场景中定位物体方面取得了显著进展，但超出物体的3D场景中的视觉定位表达尚未被探索。", "innovation": "引入了Anywhere3D-Bench，这是一个包含跨越四层语义级别的2,886个参考表达-3D边界框对的大规模基准，涵盖了人类活动区域、场景中未占用的空间、个体物体和细粒度物体部分。此外，评估了多种最先进的3D视觉定位方法，以及大型语言模型（LLMs）和多模态LLMs（MLLMs）。", "conclusion": "空间层面和部分层面的视觉定位任务对模型构成了最大挑战，模型在空间层面任务上的性能显著低于区域层面和物体层面的任务。这些发现揭示了当前模型在理解并处理3D场景超出物体层面语义方面的重要差距。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20510", "html_url": "https://arxiv.org/abs/2505.20510", "title": "CPathAgent: 一种模仿病理学家诊断逻辑的基于代理的基础模型，进行可解释的高分辨率病理图像分析", "title_en": "CPathAgent: An Agent-based Foundation Model for Interpretable High-Resolution Pathology Image Analysis Mimicking Pathologists' Diagnostic Logic", "authors": "Yuxuan Sun,Yixuan Si,Chenglu Zhu,Kai Zhang,Zhongyi Shui,Bowen Ding,Tao Lin,Lin Yang", "background": "近年来，计算病理学的进步催生了广泛的基础模型。这些模型通常依赖于通用编码器和多实例学习来进行全切片图像（WSI）分类，或者采用多模态方法直接从图像生成报告。然而，这些模型无法模拟病理学家的诊断方法，即病理学家会在低放大倍数下系统地观察切片，获得总体概述，然后逐步放大到可疑区域以形成全面的诊断。现有的模型直接输出最终诊断结果，而未揭示背后的推理过程。为进一步解决这一问题，提出了CPathAgent，一种基于代理的方法，它能够模仿病理学家的诊断流程，自动根据观察到的视觉特征在WSI上导航，从而生成更加透明和可解释的诊断总结。这种方法需要一个多阶段训练策略，该策略在一个模型中统一了贴片级、区域级和WSI级的能力，对于复制病理学家在不同图像尺度下的理解与推理至关重要。此外，构建了PathMMU-HR2，这是首个专家验证的大区域分析基准，这是贴片和全切片之间的一个关键中间尺度，反映了病理学家通常一次性不看完整个切片，而是重点关注几个关键大区域的临床现实。", "innovation": "CPathAgent是一个基于代理的方法，能模仿病理学家的诊断流程，在WSI上自动导航，生成更透明和可解释的诊断总结。该模型采用一个多阶段培训策略，统一了贴片级、区域级和WSI级的能力，从而更好地模拟病理学家的理解与推理过程。同时，构建了PathMMU-HR2作为首个专家验证的大区域分析基准，填补了从贴片到全切片之间的空白，更贴近临床实践。研究还表明，在三个不同图像尺度的基准上，CPathAgent的一致性表现优于现有方法，证明了代理基础模型在计算病理学中的有效性并为未来的发展指明了方向。", "conclusion": "CPathAgent在不同图像尺度的基准测试中均优于现有方法，验证了基于代理的诊断方法的有效性，为计算病理学指明了一个有希望的研究方向。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.05229", "html_url": "https://arxiv.org/abs/2505.05229", "title": "CLIP是否以我们相同的方式感知艺术？", "title_en": "Does CLIP perceive art the same way we do?", "authors": "Andrea Asperti,Leonardo Dessì,Maria Chiara Tonetti,Nico Wu", "background": "CLIP作为一种强大的多模态模型，能够通过联合嵌入连接图像和文本。然而，它在解读艺术品时是否‘看到’与人类相同的方式尚不清楚。本文探讨了CLIP提取绘画中的高层语义和风格信息的能力，涵盖人类创造和AI生成的图像。评估专注于多个维度的内容、场景理解、艺术风格、历史时期以及视觉变形或瑕疵的存在。通过设计针对性的探测任务并比较CLIP的响应与人类注释和专家基准，进一步探讨了CLIP在感知上的与人类感知和上下文理解的一致性。\n", "innovation": "通过设计特定的探测任务，将CLIP的反应与人类注释和专家基准进行了比较，以探索其在感知方面的与人类感知和上下文理解的一致性，揭示了CLIP在美学暗示和艺术意图方面的强项和局限性，特别是在创意领域，细腻和主观性扮演中心角色时的需求。这项工作突显了在应用到创意领域时，多模态系统需要更深入的可解释性。\n", "conclusion": "文章的研究结果揭示了CLIP在视觉表示方面的强项和局限，特别是在美学暗示和艺术意图方面。进一步讨论了这些见解对使用CLIP作为生成过程中指导机制（如风格转移或提示驱动的图像合成）的含义。强调了在创意领域中多模态系统需要更深入可解释性的需求。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06517", "html_url": "https://arxiv.org/abs/2506.06517", "title": "GS4：通用稀疏散点语义SLAM", "title_en": "GS4: Generalizable Sparse Splatting Semantic SLAM", "authors": "Mingqi Jiang,Chanho Kim,Chen Ziwen,Li Fuxin", "background": "传统的SLAM算法擅长相机跟踪，但通常生成不完整且低分辨率的地图，且不紧密集成语义预测。最近的研究将高斯散点图（GS）集成到SLAM中，以实现密集的、具象逼真的三维地图建图，然而现有的基于GS的SLAM方法需要逐场景优化，这既慢又消耗大量的高斯体。", "innovation": "本文提出了GS4，这是一种通用的基于GS的语义SLAM系统。与先前的方法相比，GS4的运行速度快10倍，使用高斯体的数量少10倍，并在颜色、深度、语义映射和相机跟踪方面达到了最先进的性能。GS4通过前馈网络从RGB-D视频流中增量构建和更新一组三维高斯体。", "conclusion": "实验证明，GS4在真正的ScanNet和ScanNet++基准上达到了最先进的语义SLAM性能，同时通过零样本迁移展示了强大的泛化能力，适用于NYUv2和TUM RGB-D数据集。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.17939", "html_url": "https://arxiv.org/abs/2506.17939", "title": "GEMeX-RMCoT: 一种增强的多模态链式推理医学问答数据集", "title_en": "GEMeX-RMCoT: An Enhanced Med-VQA Dataset for Region-Aware Multimodal Chain-of-Thought Reasoning", "authors": "Bo Liu,Xiangyu Zhao,Along He,Yidi Chen,Huazhu Fu,Xiao-Ming Wu", "background": "医学视觉问答旨在通过使模型基于医学图像回答自然语言问题来支持临床决策。虽然多模态学习的进步显著提高了性能，但现有方法的答题可靠性有限，且解释性差，这影响了临床医生和患者理解并信任模型输出的能力。", "innovation": "该工作提出了一种新的Region-Aware多模态链式推理（RMCoT）数据集，其中包含解释推理步骤，以明确地将相关视觉区域与医学图像联系起来，从而提供精细的解释性。同时，引入了一种新型可验证的奖赏机制，增强了训练后的控制，改善了模型推理过程与最终答案之间的对齐。该方法仅使用八分之一的数据就能达到相似的性能，证明了提议方法的高效性和有效性。", "conclusion": "该方法使用较小的数据集达到类似性能，展示了提议的RMCoT数据集和模型的效率和有效性，为提高医学视觉问答系统的可靠性和解释性提供了一种新的解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.08423", "html_url": "https://arxiv.org/abs/2505.08423", "title": "DArFace: Deformation Aware Robustness for Low Quality Face Recognition", "title_en": "DArFace: Deformation Aware Robustness for Low Quality Face Recognition", "authors": "Sadaf Gulshad,Abdullah Aldahlawi", "background": "面部识别系统通过利用深度神经网络、先进的损失函数和大规模数据集取得了显著的成功，但在低质量面部图像的现实场景中，其性能常常会下降。这些低质量图像常见于监控录像或远距离成像中，包含低分辨率、运动模糊和各种扭曲，与用于训练的高质量数据形成显著差异。尽管现有方法通过修改网络结构或建模全局空间变换来增强鲁棒性，但它们往往忽视了现实环境中固有的局部非刚性变形。", "innovation": "我们提出了DArFace，这是一种变形感知的鲁棒面部识别框架，能够在不需要高、低质量配对训练样本的情况下提高对变形破坏的鲁棒性。该方法在训练中通过对抗性整合全局变换（如旋转、平移）和局部弹塑变形来模拟真实的低质量条件。此外，我们引入了对比目标来确保不同变形视图之间的身份一致性。广泛的评估表明，DArFace在低质量基准数据集，如TinyFace、IJB-B和IJB-C上超越了现有的最先进的方法，显著的收益归因于局部变形建模的引入。", "conclusion": "DArFace框架在低质量面部识别中表现出显著的鲁棒性提升，通过对抗性训练整合全局和局部变形建模，并引入对比目标来增强身份一致性。该方法在多种低质量数据集上展现了卓越的性能，解决了现有技术对局部非刚性变形忽略的问题。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.15256", "html_url": "https://arxiv.org/abs/2508.15256", "title": "Normal和异常病理知识增强的视觉语言模型在病理图像中异常检测中的应用", "title_en": "Normal and Abnormal Pathology Knowledge-Augmented Vision-Language Model for Anomaly Detection in Pathology Images", "authors": "Jinsol Song,Jiamu Wang,Anh Tien Nguyen,Keunho Byeon,Sangjeong Ahn,Sung Hak Lee,Jin Tae Kwak", "background": "在计算病理学中，异常检测旨在识别稀少且带有疾病相关的数据有限或缺失的异常。现有的异常检测方法，主要针对工业环境设计，因计算限制、多样的组织结构以及缺乏可解释性，在病理学中面临挑战。", "innovation": "我们提出了Ano-NAViLa，一种结合正常和异常病理知识的预训练视觉语言模型，配备轻量级可训练的MLP。该模型通过结合正常和异常病理知识，增强了病理图像的检测准确性和鲁棒性，并通过图像-文本关联提供可解释性。", "conclusion": "Ano-NAViLa在两种不同器官的淋巴结数据集上评估，取得了最先进的异常检测和定位性能，优于其他竞争模型。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12841", "html_url": "https://arxiv.org/abs/2507.12841", "title": "AnyCap 项目：多模态可控配图的统一框架、数据集和基准", "title_en": "AnyCap Project: A Unified Framework, Dataset, and Benchmark for Controllable Omni-modal Captioning", "authors": "Yiming Ren,Zhiqiang Lin,Yu Li,Gao Meng,Weiyun Wang,Junjie Wang,Zicheng Lin,Jifeng Dai,Yujiu Yang,Wenhai Wang,Ruihang Chu", "background": "目前的模型在精准的跨模态对齐和指令遵循方面经常缺乏细粒度的控制和可靠的评估协议，因此可控的多模态配图对于精确的跨模态对齐和指令遵循是必不可少的。", "innovation": "本文提出了 AnyCap 项目，这是一个整合了模型、数据集和评估的新解决方案。引入了 AnyCapModel (ACM)，这是一个轻量级的即插即用框架，可以在不重新训练基础模型的情况下增强现有基础模型在多模态配图中的可控性。此外，为了弥补可控多模态配图中的数据稀缺性，建立了一个包含三个模态、28种用户指令类型和30万高质量数据条目的 AnyCapDataset (ACD)。同时，还提出了 AnyCapEval，这是一个新的基准，通过松耦合内容准确性和风格忠实度提供了更可靠的评估指标。", "conclusion": "ACM 显著提高了 AnyCapEval 上多种基础模型的配图质量。值得注意的是，ACM-8B 将 GPT-4 的内容评分提高了 45%，风格评分提高了 12%，同时在广泛使用的基准测试（如 MIA-Bench 和 VidCapBench）上也取得了显著的改进。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14643", "html_url": "https://arxiv.org/abs/2507.14643", "title": "多光谱状态空间特征融合：连接共享和交叉参数交互以实现目标检测", "title_en": "Multispectral State-Space Feature Fusion: Bridging Shared and Cross-Parametric Interactions for Object Detection", "authors": "Jifeng Shen,Haibo Zhan,Shaohua Dong,Xin Zuo,Wankou Yang,Haibin Ling", "background": "现代多光谱特征融合目标检测面临两个关键限制：第一，过度强调局部互补特征而忽视跨模态共享语义，影响了泛化性能；第二，感受野大小与计算复杂度之间的权衡成为可扩展特征建模的关键瓶颈。", "innovation": "提出了基于状态空间模型（SSM）的新型多光谱状态空间特征融合框架（MS2Fusion），通过双路径参数交互机制实现高效有效的融合。主要创新点包括：通过交叉参数交互路径继承交叉注意力的优势，在SSM中解码跨模态隐藏状态以挖掘互补信息；通过共享参数路径在联合嵌入中探索跨模态对齐，以参数共享获取跨模态相似的语义特征和结构。最终，这两种路径结合SSM在统一框架中融合多光谱特征，使MS2Fusion同时享有功能互补性和共享语义空间。", "conclusion": "在主流基准FLIR、M3FD和LLVIP上的广泛实验表明，MS2Fusion显著优于其他最先进的多光谱对象检测方法，显示出其优越性。此外，MS2Fusion具有通用性，适用于其他多光谱感知任务。结果显示，即使没有特定设计，MS2Fusion在RGB-T语义分割和RGBT显著目标检测任务中也取得了最先进的成果，展示了其通用性。源代码可在提供的链接处获得。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12758", "html_url": "https://arxiv.org/abs/2505.12758", "title": "全球城市视觉感知因人口统计特征和个人特质而异", "title_en": "Global urban visual perception varies across demographics and personalities", "authors": "Matias Quintana,Youlong Gu,Xiucheng Liang,Yujun Hou,Koichi Ito,Yihan Zhu,Mahmoud Abdelrahman,Filip Biljecki", "background": "理解人们对于城市环境的偏好对于城市规划至关重要。然而，目前的方法往往将多文化群体的反应结合起来，这模糊了人口差异，并增加了放大偏见的风险。本研究通过使用街景图像在全球范围内进行大规模的城市视觉感知调查，以5个国家和45个国籍的1000名具有平衡人口统计数据的参与者为对象，考察了人口特征，包括性别、年龄、收入、教育程度、种族和民族以及个性特征如何影响感知。这项名为Street Perception Evaluation Considering Socioeconomics (SPECS)的数据集揭示了六种传统指标（安全、活力、富有、美丽、无聊、令人沮丧）和四种新指标（住在附近、步行、骑行、绿色）之间的人口统计学和个性差异，并进一步证实了基于地理位置的情感变化对这些偏好的影响。", "innovation": "本研究利用 Street Perception Evaluation Considering Socioeconomics (SPECS) 数据集揭示了不同地区人们的感知差异，采用了多样化的参与者样本，打破了单一文化的模式，并且使用了机器学习模型对比人类反馈与已有的全球数据集结果，这显示了现有模型可能因缺乏地方性而产生偏差，从而强调了需要考虑地方语境的重要性。", "conclusion": "本研究旨在纠正街景感知的单维认知，强调人口统计学和个人特质对此类感知的重要性。使用Locality-aware Machine Learning (LML) 模型来提高对不同群体感知的精度，对未来的城市规划具有指导意义。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02293", "html_url": "https://arxiv.org/abs/2508.02293", "title": "通过自信元学习实现真正的无监督异常检测", "title_en": "Towards Real Unsupervised Anomaly Detection Via Confident Meta-Learning", "authors": "Muhammad Aqeel,Shakiba Sharifi,Marco Cristani,Francesco Setti", "background": "通常所谓的无监督异常检测实际上可以被更好地描述为半监督学习，因为其假设所有训练数据都是正常的。这种假设简化了训练过程，但需要手动数据整理，这可能会引入偏差并限制模型的灵活性。现有的方法通常依赖于人为筛选正常和异常样本，这不仅耗时且难以确保筛选的准确性，也可能导致信息的丢失或不完整。因此，需要一种新的训练策略，以使得深度异常检测模型能够从包含正常和异常样本的未整理数据中学习，而不需要显式地进行筛选操作。", "innovation": "本文提出了一种新的训练策略——自信元学习（CoMet），该方法允许深度异常检测模型从包含正常和异常样本的未整理数据中学习，无需显式筛选。CoMet集成了软自信学习和元学习。软自信学习通过为低置信度样本分配较低的权重来避免将这些样本纳入训练。元学习则通过基于训练验证损失协方差的正则化更新来稳定训练过程，防止过拟合并增强对噪声数据的鲁棒性。此外，CoMet 是模型无关的，可以应用于任何可通过梯度下降进行训练的异常检测方法。实验结果表明，CoMet 在多个数据集和两种最先进的异常检测模型上的表现均优于基线方法，并在所有数据集上达到了最新水平。", "conclusion": "CoMet 通过避免人工筛选，能够利用包含正常和异常样本的未整理数据进行训练，从而增强了模型对噪声数据的鲁棒性和对训练集中异常的不敏感性。实验证明这种方法的有效性，并且结果经过评估已在所有数据集上设置了最新的基线水平。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.16691", "html_url": "https://arxiv.org/abs/2509.16691", "title": "InstanceAssemble: Layout-Aware Image Generation via Instance Assembling Attention", "title_en": "InstanceAssemble: Layout-Aware Image Generation via Instance Assembling Attention", "authors": "Qiang Xiang,Shuang Sun,Binglei Li,Dejia Song,Huaxia Li,Nemo Chen,Xu Tang,Yao Hu,Junping Zhang", "background": "Diffusion models展示了在生成高质量图像方面的显著能力。布局到图像（Layout-to-Image，L2I）生成领域最近的进展利用了位置条件和文本描述来促进精确和可控的图像合成。尽管总体上取得了进展，但现有的L2I方法仍然表现出亚最优的性能。因此，本文提出了一种新颖的架构InstanceAssemble，它通过实例组装注意力机制整合布局条件，实现了通过边界框控制位置以及包括文本和附加视觉内容的多模态内容控制。", "innovation": "提出了一种新的InstanceAssemble架构，通过实例组装注意力机制整合布局条件，实现了通过边界框控制位置以及包括文本和附加视觉内容的多模态内容控制。通过轻量级LoRA模块实现了对现有DiT基于的图像到文本方法的灵活适应。还提出了一套布局到图像基准Denselayout，以及一种可解释的评估指标Layout Grounding Score (LGS)来精确实现L2I生成的准确性评估。", "conclusion": "实验结果表明，我们的InstanceAssemble方法在复杂的布局条件下达到了最先进的性能，同时展示了与多样风格LoRA模块的强大兼容性。代码和预训练模型可以在指定的链接处获取。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.17102", "html_url": "https://arxiv.org/abs/2508.17102", "title": "GRASP: 地理空间像素推理通过结构化策略学习", "title_en": "GRASP: Geospatial pixel Reasoning viA Structured Policy learning", "authors": "Chengjie Jiang,Yunqi Zhou,Jiafeng Yan,Jing Li,Jiayang Li,Yue Zhou,Hongjie He,Jonathan Li", "background": "地理空间像素推理旨在直接从自然语言指令生成遥感图像的分割掩码。目前大多数方法采用监督方式微调多模态大型语言模型，但这种方法存在两大主要问题：(1) 大规模密集像素标签注解的成本很高，(2) 在域外场景下的泛化能力有限。", "innovation": "本文提出了一种新的结构化策略学习框架GRASP，该框架将多模态大型语言模型与预训练的分割模型以级联方式集成。为了增强泛化能力，引入了PRIME训练范式，该范式用强化学习代替监督微调，使推理和定位行为更好地与任务目标对齐。为了降低成本，设计了BoP-奖励，用边界框和正点替换密集掩码标签，并通过格式和准确性两种互补信号进一步验证输出。", "conclusion": "实验结果表明GRASP在域内表现超越现有最佳方法SOTA，并且在域外场景中性能提高了54%。研究结果证实了使用成本感知奖励的强化学习框架对于地理空间像素推理具有稳健性和可扩展性。所有代码和数据集将公开发布。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.20072", "html_url": "https://arxiv.org/abs/2508.20072", "title": "离散扩散VLA：将离散扩散引入视觉-语言-行动策略中的动作解码", "title_en": "Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies", "authors": "Zhixuan Liang,Yizhuo Li,Tianshuo Yang,Chengyue Wu,Sitong Mao,Tian Nian,Liuao Pei,Shunbo Zhou,Xiaokang Yang,Jiangmiao Pang,Yao Mu,Ping Luo", "background": "VLA（视觉-语言-行动）模型通过自回归的方式在固定的方向上生成行动，或者在主干之外附加单独的MLP或扩散头部，这些方式导致了信息路径的分裂和特殊的训练需求，不利于形成统一、可扩展的架构。", "innovation": "介绍了一种名为Discrete Diffusion VLA的统一变压器策略，它使用离散扩散来建模离散的动作片段，保留了扩散的逐步细化理念，同时保持了与视觉语言模型（VLM）的离散标记接口的原生态兼容性。该方法实现了一个自适应的解码顺序，先解决简单的动作元素然后再处理复杂的，通过二次遮罩重新审视不确定的预测，在逐步修正过程中提高了预测的一致性和鲁棒性纠错能力。该统一的解码器保留了预训练的视觉-语言先验，支持并行解码，打破了自回归的瓶颈，减少了函数评估的次数。", "conclusion": "该模型在LIBERO上取得了96.3%的平均成功率，在SimplerEnv-Fractal上实现了71.2%的视觉一致匹配，在SimplerEnv-Bridge上实现了54.2%的整体结果，超过自回归和平滑头部连续扩散基本模型的效果。这表明离散扩散VLA支持精确的动作建模和一致的训练，为VLA扩展到更大的模型和数据集奠定了基础。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.20234", "html_url": "https://arxiv.org/abs/2509.20234", "title": "ImageNet训练的CNNs并未倾向于纹理：通过受控抑制重新审视特征依赖", "title_en": "ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression", "authors": "Tom Burgert,Oliver Stoll,Paolo Rota,Begüm Demir", "background": "长期以来，人们普遍认为卷积神经网络（CNNs）在特征使用中偏向于纹理。这种假设已经影响了深度学习领域关于特征使用模式的讨论。然而，此项研究通过对Geirhos等人实验的局限性进行重新审视，并提出了一种跨领域的框架，用于系统地抑制形状、纹理和颜色线索，从而消除逼迫选择冲突带来的混杂因素。通过在受控抑制条件下评估人类和神经网络，研究人员发现在这些条件下，CNNs并不天生偏好于纹理，而是主要依赖于局部形状特征。这一结果提出了关于CNNs特征依赖模式的新见解。", "innovation": "研究提出了一个跨领域的框架，用于系统地评估和抑制CNNs对不同视觉线索的依赖，避免了先前研究中出现的强迫选择冲突所带来的混淆。该研究还考察了多样任务（计算机视觉、医学成像、遥感）中的特征依赖模式差异，进一步揭示了不同领域的模型依赖特征类型的不同偏好。", "conclusion": "ImageNet训练的CNNs并非天生偏向于纹理，而是主要依赖于局部形状特征。不过，通过现代训练策略或架构（如ConvNeXt、ViT），这种对形状的依赖也可以得到显著缓解。不同领域的模型依赖特征类型不同：计算机视觉模型侧重形状，医学成像模型侧重颜色，而遥感模型则呈现出更强的对纹理的依赖性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14431", "html_url": "https://arxiv.org/abs/2510.14431", "title": "实时统一内插和间接码的神经视频压缩", "title_en": "Real-Time Neural Video Compression with Unified Intra and Inter Coding", "authors": "Hui Xiang,Yifan Bian,Li Li,Jingran Wu,Xianguo Zhang,Dong Liu", "background": "近年来，神经视频压缩（NVC）技术取得了飞速发展，一些先进的方案，如DCVC-RT，已经展示了超越H.266/VVC的压缩效率，并具备实时编码/解码能力。然而，现有的NVC方案仍存在一定的局限性，例如在处理遮挡和新内容方面效率不高、帧间误差传播和累积等问题。", "innovation": "本文借鉴了经典视频编码方案中允许帧间嵌入帧内编码的思想，设计了一个结合了内插和间接编码统一框架的NVC系统。新的框架允许每个帧由一个模型进行处理，并使其能够适应性地执行内插/间接编码。此外，提出了一种双重帧压缩设计，以充分利用前后帧间的冗余信息。实验结果显示，与DCVC-RT相比，该方案平均降低了10.7%的BD率，并提供了更稳定的比特率和帧质量。同时，该方案保留了实时编码/解码性能。", "conclusion": "本文研究了一种具有统一内插和间接编码的实时神经视频压缩方案，并展示了其相对于现有技术的优势。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.00037", "html_url": "https://arxiv.org/abs/2510.00037", "title": "Vision-Language-Action模型对抗多模态扰动的鲁棒性", "title_en": "On Robustness of Vision-Language-Action Model against Multi-Modal Perturbations", "authors": "Jianing Guo,Zhenhong Wu,Chang Tu,Yiyao Ma,Xiangqi Kong,Zhiqian Liu,Jiaming Ji,Shuning Zhang,Yuanpei Chen,Kai Chen,Qi Dou,Yaodong Yang,Xianglong Liu,Huijie Zhao,Weifeng Lv,Simin Li", "background": "在Vision-Language-Action (VLA) 模型中，抵抗现实世界中的各种干扰对于应用部署至关重要。现有的方法主要针对简单的视觉干扰，却没有考虑到行动、指令、环境和观察中的更广泛多模态干扰。这项研究通过评估具有代表性的VLAs在四个模态上的鲁棒性，揭示了行动是最脆弱的模态，现有的视觉鲁棒VLA仅在视觉上具有鲁棒性，并提出Pi0模型由于其基于扩散的行动头表现出优越的多模态鲁棒性。", "innovation": "本文提出了RobustVLA模型，旨在提高VLA模型在输入和输出不同扰动下的鲁棒性。对于输出鲁棒性，执行针对最坏情况动作噪声的离线鲁棒优化，以最大化流匹配目标中的不匹配。对于输入鲁棒性，要求输入变化中任务语义的一致性。通过多臂赌博机问题的鲁棒性建模以及上置置信度算法，自动识别最具害的噪声。实验结果表明，在所有17种扰动下，我们的RobustVLA相对于基线的绝对收益分别提高了12.6%和10.4%，推理速度比现有视觉鲁棒VLA快了50.6倍，在混合扰动下获得了10.4%的收益，并且在FR5机器人中表现出65.6%的绝对收益。", "conclusion": "我们的 RobustVLA 在 FR5 机器人中特别有效，即使示范量有限，也能在多种扰动下的任务成功率提高 65.6%，并在 LIBERO 数据集上展示了在所有17种扰动下的绝对收益，尤其是显著提高了推理速度和鲁棒性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.18513", "html_url": "https://arxiv.org/abs/2510.18513", "title": "DWaste: 手持和边缘设备上用于垃圾分类的更绿色的人工智能", "title_en": "DWaste: Greener AI for Waste Sorting using Mobile and Edge Devices", "authors": "Suman Kunwar", "background": "便利包装的兴起导致了大量废物的产生，使得高效的废物分类对于可持续废物管理至关重要。", "innovation": "开发了DWaste，这是一种基于计算机视觉的平台，用于资源受限的智能手机和边缘设备上的实时废物分类，并包括离线功能。通过比较各类图像分类模型（EfficientNetV2S/M、ResNet50/101、MobileNet）和物体检测模型（YOLOv8n、YOLOv11n，包括自定义的YOLOv8n-CBAM模型），并在回收专用数据集上进行了基准测试。研究结果表明，虽然准确率高的模型（如EfficientNetV2S）具有高延迟和高碳排放，但轻量级物体检测模型在低功耗和高速推理方面表现出色，并且模型大小可显著减小。", "conclusion": "我们的研究证明了如何成功实施“更绿色的AI”模型，以支持边缘设备上的实时、可持续的废物分类。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14383", "html_url": "https://arxiv.org/abs/2510.14383", "title": "DRBD-Mamba用于具有分析洞察力的稳健高效脑肿瘤分割", "title_en": "DRBD-Mamba for Robust and Efficient Brain Tumor Segmentation with Analytical Insights", "authors": "Danish Ali,Ajmal Mian,Naveed Akhtar,Ghulam Mubashar Hassan", "background": "精确的脑肿瘤分割对临床诊断和治疗至关重要，但由于肿瘤异质性，这项任务仍然具有挑战性。尽管基于Mamba的时空模型表现出色，但由于在多个空间轴上进行顺序特征计算，它们在计算效率方面仍具有较高的开销。此外，这些模型在不同BraTS数据分区中的表现可靠性尚未得到充分探索，留下了可靠评估的关键差距。", "innovation": "首先提出了一种双分辨率双向Mamba（DRBD-Mamba）模型，这是一种高效3D分割模型，能够捕捉多尺度长程依赖关系，同时保持较低的计算开销。通过利用空间填充曲线在3D到1D特征映射过程中保持空间局部性，减少了对昂贵的多轴特征扫描的依赖。提出了一种门控融合模块，能够适配地整合前向和反向上下文，以及一个量化块以提高鲁棒性。进一步提出了五个系统折分方法以在多种条件下严格评估分割技术，并分析了常见的失败场景。在最近方法使用的20%测试集中，DRBD-Mamba模型在脑肿瘤的整体、肿瘤核心和增强肿瘤上的Dice改进分别为0.10%、1.75%和0.93%。在提出的系统折分方法上的评估显示，该模型在保持竞争力的整体肿瘤准确性的同时，在肿瘤核心和增强肿瘤上分别实现了1.16%和1.68%的平均Dice增益。此外，该模型在保持高分割准确性的同时实现了15倍的效率提升，展示了其相对于现有方法的鲁棒性和计算优势。", "conclusion": "我们的研究表明，DRBD-Mamba在处理脑肿瘤分割时表现出色，能够在保证高准确性的前提下显著提高计算效率。通过引入新的双分辨率双向Mamba模型和相关的创新机制，该研究不仅验证了模型的有效性，还为未来的脑肿瘤分割研究提供了新的见解和方法。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.15870", "html_url": "https://arxiv.org/abs/2510.15870", "title": "OmniVinci：增强架构和数据以提高多模态理解LLM", "title_en": "OmniVinci: Enhancing Architecture and Data for Omni-Modal Understanding LLM", "authors": "Hanrong Ye,Chao-Han Huck Yang,Arushi Goel,Wei Huang,Ligeng Zhu,Yuanhang Su,Sean Lin,An-Chieh Cheng,Zhen Wan,Jinchuan Tian,Yuming Lou,Dong Yang,Zhijian Liu,Yukang Chen,Ambrish Dantrey,Ehsan Jahangiri,Sreyan Ghosh,Daguang Xu,Ehsan Hosseini-Asl,Danial Mohseni Taheri,Vidya Murali,Sifei Liu,Yao Lu,Oluwatobi Olabiyi,Yu-Chiang Frank Wang,Rafael Valle,Bryan Catanzaro,Andrew Tao,Song Han,Jan Kautz,Hongxu Yin,Pavlo Molchanov", "background": "机器智能的进步要求发展跨多模态感知的能力，类似于人类感知世界的方式。研究旨在开发一种坚强的、开放源代码的多模态语言模型（LLM），并仔细研究模型架构和数据收集设计的选择。", "innovation": "三类创新的介绍：(i) OmniAlignNet，用于增强视觉和音频嵌入在共享多模态潜空间中的对齐；(ii) Temporal Embedding Grouping，用于捕捉视觉和音频信号之间的相对时间对齐；(iii) Constrained Rotary Time Embedding，用于在多模态嵌入中编码绝对时间信息。此外，介绍了用于生成包含2400万个单模态和多模态对话的采集和合成管道。", "conclusion": "我们的模型OmniVinci在跨模态理解（DailyOmni）上比Qwen2.5-Omni高出19.05%，在音频方面比MMAR提高1.7%，在视频理解方面比Video-MME提高3.9%。同时，我们只使用了0.2T训练标记，与Qwen2.5-Omni的1.2T相比减少了6倍。同时展示了多模态优点在机器人、医疗AI和智能工厂等下游应用中的应用。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.15710", "html_url": "https://arxiv.org/abs/2510.15710", "title": "UniMedVL：通过观察-知识-分析统一医疗多模态理解和生成", "title_en": "UniMedVL: Unifying Medical Multimodal Understanding And Generation Through Observation-Knowledge-Analysis", "authors": "Junzhi Ning,Wei Li,Cheng Tang,Jiashi Lin,Chenglong Ma,Chaoyang Zhang,Jiyao Liu,Ying Chen,Shujian Gao,Lihao Liu,Yuandong Pu,Huihui Xu,Chenhui Gou,Ziyan Huang,Yi Xin,Qi Qin,Zhongying Deng,Diping Song,Bin Fu,Guang Yang,Yuanfeng Ji,Tianbin Li,Yanzhou Su,Jin Ye,Shixiang Tang,Ming Hu,Junjun He", "background": "医疗诊断应用需要能够处理多种医疗输入（图像、病史、实验室结果）并生成包括文本报告和视觉内容（注释、分割掩模和图像）在内的多样化输出的模型。然而，当前的医疗人工智能系统无法统一处理这种多步骤的过程：专注于图像识别的模型不能生成图像输出，而专注于图像生成的模型则不能提供文本解释。这导致了数据表示、特征整合和任务级别多模态能力的缺口。因此，本文提出了一个多级框架，借鉴诊断工作流程中的观察-知识-分析（OKA）范式。该框架在观察层构建了包含超过560万个样本的UniMed-5M数据集，将不同类型的单模态数据整合为互模态对。", "innovation": "本文提出了一个医疗统一多模态框架UniMedVL，该框架包含三个层次：观察层、知识层和分析层。在观察层，它通过 UniMed-5M 数据集对多种单模态数据进行整合处理；在知识层，它提出了渐进式的课程学习方法以系统地引入医疗多模态知识；在分析层，UniMedVL 成为了首个能够在同一架构中同时处理图像理解和生成任务的医疗统一多模态模型。UniMedVL 在五个医疗图像理解基准测试中表现优越，并在八个医疗成像模态中达到了与专门模型相当的生成质量。通过统一架构，该模型实现了生成任务对视觉理解特征的双向知识共享，展示了在单一医疗框架中集成传统上分离的能力能提高多种医疗视觉语言任务的效果。", "conclusion": "本文提出的 UniMedVL 模型通过一个多级框架成功整合了医疗图像理解和生成，填补了传统模型之间的空缺。该模型不仅在多模态数据处理上表现优异，还在多个医疗成像领域中实现了与专项模型相当的生成质量，并通过双向知识共享提升了整体性能。这一研究为规范化并改进医疗图像和自然语言处理提供了新的视角，也为未来的工作奠定了基础。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22035", "html_url": "https://arxiv.org/abs/2510.22035", "title": "基于字幕的解释性：使用CLIP探测CNN中的偏差", "title_en": "Caption-Driven Explainability: Probing CNNs for Bias via CLIP", "authors": "Patrick Koller(Northwestern University, Evanston, Illinois, United States),Amil V. Dravid(University of California, Berkeley, California, United States),Guido M. Schuster(Eastern Switzerland University of Applied Sciences, Rapperswil, St. Gallen, Switzerland),Aggelos K. Katsaggelos(Northwestern University, Evanston, Illinois, United States)", "background": "机器学习的鲁棒性已成为一个极其重要的问题。为了解释ML模型的行为并提升其鲁棒性，解释型人工智能(XAI)被引入。对于计算机视觉问题，一个领先的XAI方法是生成显著性图。显著性图突出显示了让ML模型最强兴奋的图像像素空间。然而，如果该空间存在虚假明显的特征，则这一特性可能会引人误解。本文旨在改进XAI方法，提出了一种基于字幕的XAI方法，该方法将要解释的独立模型与对比跨模态预训练（CLIP）模型结合，利用新的网络手术方法。这种方法识别出对模型预测贡献最大的主导概念，并帮助减轻模型对协变量变化的偏好，从而有助于开发更鲁棒的ML模型。", "innovation": "本文提出了一种基于字幕的XAI方法，将独立模型与CLIP模型结合，使用新的网络手术方法。这种方法通过识别贡献最大的主导概念来解释模型预测，从而减轻协变量变化的影响，显著促进了开发更鲁棒的ML模型。", "conclusion": "所提出的方法可以显著降低ML模型对协变量变化的敏感度，并且该研究报告的代码已公开可获取。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22200", "html_url": "https://arxiv.org/abs/2510.22200", "title": "LongCat-Video 技术报告", "title_en": "LongCat-Video Technical Report", "authors": "Meituan LongCat Team:Xunliang Cai,Qilong Huang,Zhuoliang Kang,Hongyu Li,Shijun Liang,Liya Ma,Siyu Ren,Xiaoming Wei,Rixu Xie,Tong Zhang", "background": "视频生成是构建世界模型的关键路径，高效的长视频推断是关键能力。为此，引入了具有13.6B参数的LongCat-Video，作为一种基础视频生成模型，在多个视频生成任务中表现强大。LongCat-Video 特别擅长高效和高质量的长视频生成，标志着世界模型的第一步。", "innovation": "统一了多任务架构：基于Diffusion Transformer（DiT）框架，LongCat-Video 支持文本到视频、图像到视频和视频延续任务；长视频生成：预训练在视频延续任务上，长视频生成能保持长时间视频的高质量和时间连贯性；高效推理：通过时域和空域的粗到细生成策略，LongCat-Video 可在几分钟内生成720p、30fps的视频；Block Sparse Attention 进一步提高效率，特别是在高分辨率下。", "conclusion": "多奖励RLHF训练使LongCat-Video在性能上与最新的闭源和领先开源模型相当。代码和模型权重已公开，以加速领域内的进展。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22693", "html_url": "https://arxiv.org/abs/2510.22693", "title": "VADTree：通过层次粒度意识树实现可解释的无需训练的视频异常检测", "title_en": "VADTree: Explainable Training-Free Video Anomaly Detection via Hierarchical Granularity-Aware Tree", "authors": "Wenlong Li,Yifei Xu,Yuan Rao,Zhenhua Wang,Shuiguang Deng", "background": "视频异常检测（VAD）旨在识别视频中的异常。目前的监督方法依赖大量领域内的训练数据，无法清晰地解释异常。相比之下，无需训练的方法利用大型预训练模型的知识库和语言互动能力来检测异常。然而，现有的固定时长时间窗口采样方法难以准确捕捉不同时间跨度的异常。因此，本文提出了VADTree，利用层次粒度意识树（HGTree）结构实现灵活的视频异常检测采样。", "innovation": "VADTree利用预训练的通用事件边界检测（GEBD）模型来刻画潜在的异常事件边界，通过将视频分解为基础的事件节点并构建多层次结构从而进行自适应的信息抽取和冗余删除，同时将多维先验注入视觉语言模型以增强节点级别的异常感知，并通过大规模语言模型实现对基础事件节点的异常推理，最后使用簇间节点相关性方法集成不同层次的异常得分。", "conclusion": "在三个具有挑战性的数据集上的广泛实验表明，VADTree在无需训练的设置下获得了最先进的性能，并大幅减少了需要采样的视频片段数量。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22672", "html_url": "https://arxiv.org/abs/2510.22672", "title": "Look and Tell：跨第一人称和第三人称视角的多模态语义关联数据集", "title_en": "Look and Tell: A Dataset for Multimodal Grounding Across Egocentric and Exocentric Views", "authors": "Anna Deichler,Jonas Beskow", "background": "本研究介绍了Look and Tell数据集，用于研究从第一人称和第三人称视角的指代性交流。通过使用Meta Project Aria智能眼镜和固定摄像头录制同步的眼球追踪、对话和视频，研究者记录了25名参与者指导同伴在厨房内识别食材的过程。结合3D场景重建，该数据集为评估不同空间表示（2D vs. 3D；第一人称 vs. 第三人称）对多模态语义关联的影响提供了基准。该数据集包含3.67小时的记录，包括2,707个详细标注的指代表达，目的是促进能够理解和参与情境对话的物理代理系统的开发和研究。", "innovation": "本研究创新之处在于使用第一人称和第三人称视角相结合的条件下的记录，通过多模态数据（眼动、对话和视频）分析指代性交流，提供了评估不同视角下空间表示对多模态语义关联影响的新基准，为研究和开发能够理解情境对话的物理代理系统提供了宝贵的数据资源。", "conclusion": "本研究构建的Look and Tell数据集对于多模态语义关联的研究具有重要意义，能够帮助研究人员理解人与人在不同视角下的交流机制，并促进开发出更加智能的物理代理系统。该数据集为未来行为理解和生成领域的发展提供了参考样本。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22706", "html_url": "https://arxiv.org/abs/2510.22706", "title": "IGGT: 基于实例的几何变换器用于语义3D重建", "title_en": "IGGT: Instance-Grounded Geometry Transformer for Semantic 3D Reconstruction", "authors": "Hao Li,Zhengyu Zou,Fangfu Liu,Xuanyang Zhang,Fangzhou Hong,Yukang Cao,Yushi Lan,Manyuan Zhang,Gang Yu,Dingwen Zhang,Ziwei Liu", "background": "人类能够自然地将3D世界的几何结构和语义内容视为交织的维度，这使得对复杂场景进行全面而准确的理解成为可能。然而，大多数现有的方法重视训练大型几何模型来进行低层次3D重建，并将高层次的空间理解视为独立的部分，忽略了这两方面在3D场景分析中的重要互动性，从而限制了泛化能力和在下游3D理解任务中的表现。最近的尝试通过简单地将3D模型与特定的语言模型对齐来缓解这个问题，但这也限制了感知的范围，并限制了对下游任务的适应能力。", "innovation": "本文提出了一种端到端的大型统一变换器——实例定位几何变换器（IGGT），旨在同时统一空间重建和实例级别的上下文理解的知识。文章设计了一种3D一致对比学习策略，指导IGGT仅通过二维视觉输入来编码几何结构和实例定位聚类的统一表示。此外，构建了一个大规模数据集InsScene-15K，用于训练和支持IGGT进行语义3D重建。", "conclusion": "本文提出的IGGT通过统一几何信息和实例级别上下文理解的知识，全面提升语义3D重建任务的表现，同时通过构建大型数据集InsScene-15K来提供高质量的视觉输入和高精度的3D一致实例层次掩码标注，为后续研究提供了坚实的基础。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22943", "html_url": "https://arxiv.org/abs/2510.22943", "title": "Switchable Token-Specific Codebook Quantization For Face Image Compression", "title_en": "Switchable Token-Specific Codebook Quantization For Face Image Compression", "authors": "Yongbo Wang,Haonan Wang,Guodong Mu,Ruixin Zhang,Jiaqi Chen,Jingyun Zhang,Jun Wang,Yuan Xie,Zhizhong Zhang,Shouhong Ding", "background": "随着视觉数据量的不断增长，高效且无损的数据传输及其后续的解析和理解成为现代信息系统中的关键瓶颈。目前采用的基于码本的方法使用全局共享码本来量化和反量化每个令牌，通过调整令牌数量或码本大小来控制比特率。然而，对于富于属性的面部图像，这种方式忽略了图像内的类别特定相关性和令牌间的语义差异，尤其是在低比特率下表现不佳。", "innovation": "本文提出了一种针对面部图像压缩的可切换令牌特定码本量化方法，该方法为不同的图像类别学习不同的码本组，并为每个令牌分配独立的码本。通过用少量位记录每个令牌所属的码本组，可以在减小每个码本组大小时减少损失。这使得在总的比特率较低的情况下能够使用更多的码本，从而增强表达能力和重建性能。该方法的设计具有通用性，可以集成到任何现有的基于码本的表示学习方法中，并已在面部识别数据集上证明了其有效性，准确率为93.51%（在0.05比特率下）", "conclusion": "我们的方法能够在较低的整体比特率下实现更高的表达能力和解码性能。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23118", "html_url": "https://arxiv.org/abs/2510.23118", "title": "地球观测中的任务无关的时间序列和图像融合", "title_en": "Task-Agnostic Fusion of Time Series and Imagery for Earth Observation", "authors": "Gianfranco Basile,Johannes Jakubik,Benedikt Blumenstiel,Thomas Brunschwiler,Juan Bernabe Moreno", "background": "该论文提出了一种适用于时间序列和单一时间戳图像多模态融合的任务无关框架，使跨模态生成和下游性能更加稳健。该框架探索了时间序列量化中的确定性和学习策略，并利用遮罩相关性学习目标来统一图像和时间序列标记在表示空间中的对齐。", "innovation": "该创新点在于提出了一种任务无关的时间序列和图像融合框架，通过探索确定性和学习策略进行时间序列量化，并使用遮罩相关性学习目标来对齐离散图像和时间序列标记，从而实现跨模态生成并在地球观测领域通过卫星图像生成一致的全球温度剖面。", "conclusion": "任务无关预训练方法在下游任务中表现出色，比任务特定融合方法分别在R²和RMSE上高出6%和2%，平均而言比基线方法在R²和RMSE上分别高出50%和12%。此外，还分析了各模态的梯度敏感性，提供了关于模型稳健性的见解。相关代码、数据和权重将在宽松的授权下公开。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.26386", "html_url": "https://arxiv.org/abs/2509.26386", "title": "PANDA:借助代理型AI工程师实现通用视频异常检测", "title_en": "PANDA: Towards Generalist Video Anomaly Detection via Agentic AI Engineer", "authors": "Zhiwei Yang,Chen Gao,Mike Zheng Shou", "background": "视频异常检测（VAD）是一个关键但具有挑战性的任务，由于实际场景的复杂性和多样性。以往的方法通常依赖于特定领域的训练数据，并且在应用到新场景和未知异常类型时需要手动调整，这带来了高昂的人力成本并且限制了泛化能力。因此，本研究旨在实现通用的VAD，即无需训练数据或人类干预的情况下自动处理各种场景和异常类型。", "innovation": "本研究提出了一种名为PANDA的代理型AI工程师，基于MLLMs。PANDA通过实现四个关键能力来实现这一目标，分别是：(1) 自适应场景感知策略规划，(2) 目标驱动的启发式推理，(3) 工具增强的自我反思，(4) 自我提升的记忆链。这四个能力具体表现为：(1) 自适应场景感知的自回复机构，使PANDA能够检索异常特定知识以进行异常检测策略规划；(2) 潜在异常引导的启发式提示策略，以提高推理精度；(3) 进步反思机制和一套上下文感知工具，以在复杂场景下迭代优化决策；(4) 历史经验记忆链机制，使PANDA可以利用历史经验持续提升性能。", "conclusion": "广泛的实验验证了PANDA在多场景、开放集和复杂场景设置下的性能达到最先进的水平，无需训练和手动干预，证明了其泛化能力和鲁棒性异常检测能力。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.23311", "html_url": "https://arxiv.org/abs/2509.23311", "title": "见符号，失文化：视觉-语言模型在火焰意象和文化含义推理中的探查", "title_en": "Seeing Symbols, Missing Cultures: Probing Vision-Language Models' Reasoning on Fire Imagery and Cultural Meaning", "authors": "Haorui Yu,Yang Zhao,Yijia Chu,Qiufeng Yi", "background": "视觉-语言模型（VLMs）虽然在处理图像和文本时表现出色，但主要依赖于表面的模式匹配而非深层次的文化理解。文章通过分类和解释分析，考察了多个模型在处理西方节日、非西方传统及紧急情况下的火焰主题文化意象时的系统性偏差。这些偏差暴露出模型在处理未广泛代表的文化事件时的不足，并指出现有的准确性指标不足以保证多模态系统的可解释性和公平性。", "innovation": "文章引入了一个诊断框架，用于分析视觉-语言模型在处理火焰主题文化意象时的推理过程。通过测试多个模型在西方节日、非西方传统以及紧急情况下的表现，揭示了系统性的偏差问题，强调了超越准确性指标进行文化评价的必要性，以确保多模态系统的可解释性和公平性。", "conclusion": "研究结果显示，视觉-语言模型在处理非广泛代表的文化事件时存在显著偏差，正确识别了主要的西方节日，但在处理未广泛代表的文化事件时常常提供模糊的标签或错误地将紧急情况当作庆祝活动。这些发现揭示了符号捷径的风险，并强调了需要采用超越准确性指标的文化评估方法，确保多模态系统的可解释性和公平性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.21412", "html_url": "https://arxiv.org/abs/2510.21412", "title": "跨越现实世界语言接地视觉概念学习的鸿沟", "title_en": "Bridging the gap to real-world language-grounded visual concept learning", "authors": "Whie Jung,Semin Kim,Junee Kim,Seunghoon Hong", "background": "人类智能可以轻松地对视觉场景进行多维度的语义解析。然而，现有的基于语言的视觉概念学习方法通常仅限于有限的几个预定义的基础维度（如颜色和形状），而且这些方法通常是在合成数据集上进行探索。本研究针对这一现状提出了一种新的框架，该框架能够自适应地识别与图像相关的概念维度，并在真实世界场景中将视觉概念与这些维度相结合。", "innovation": "该框架利用预训练的视觉-语言模型和一种通用的提示策略，无需任何先验知识就能识别多样化的图像相关维度。通用的概念编码器能够自适应地绑定视觉特征到发现的维度，而无需为每个概念引入额外的模型参数。为了将视觉概念沿发现的维度准确地放置，该方法优化了一个组合锚定目标，确保每个维度可以独立地被操纵而不影响其他维度。这些改进使得该方法在ImageNet、CelebA-HQ和AFHQ数据集的子集上表现出强大的编辑能力和组成泛化能力，超越了现有的视觉概念学习和基于文本的编辑方法。", "conclusion": "该研究提出了一个可扩展的框架，能够自适应地识别与图像相关的概念维度，在真实世界场景中将视觉概念与这些维度相结合。实验结果展示了该方法在多种现实世界概念上的强大编辑能力和组成泛化能力，证明了该方法的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22118", "html_url": "https://arxiv.org/abs/2510.22118", "title": "GRAID：通过高保真数据生成增强VLM的的空间推理能力", "title_en": "GRAID: Enhancing Spatial Reasoning of VLMs Through High-Fidelity Data Generation", "authors": "Karim Elmaaroufi,Liheng Lai,Justin Svegliato,Yutong Bai,Sanjit A. Seshia,Matei Zaharia", "background": "视觉语言模型（VLMs）在许多视觉语言任务上表现出色，但在涉及空间推理的任务上常常遇到困难，而空间推理是许多应用场景的先决条件。当前训练数据生成管道生成的数据，经过人工验证的准确率为57.6%。主要问题是单幅图像3D重建引入了积累的建模错误，并需要宽泛的答案容忍度，而基于描述的方法要求超详细的注释并遭受生成的幻觉。", "innovation": "提出了GRAID框架，基于核心洞察，质的空间关系可以从单独的二维几何原语中可靠地确定。GRAID仅使用标准对象检测器的二维边界框操作，避免了3D重建错误和生成的幻觉，从而产生了比现有工具生成的类似数据集更高质量的数据集，经过人工评估验证。框架应用于BDD100k、NuImages和Waymo数据集，生成超过850万高质量的VQA对，涵盖了空间关系、数量比较、排名等多个领域。模型在GRAID数据上的训练显示出跨出的迁移能力，准确度获得显著提升。", "conclusion": "当使用GRAID数据训练模型时，模型的学习空间推理概念能够泛化。模型在6种问题类型上的微调提高超过10种未见过类型的问题，而使用Llama 3.2B和11B分别提高了BDD和NuImages数据集47.5%和37.9%的准确性。训练在所有问题类型上的模型也表现出在BLINK等现有基准测试上的改进。项目包括GRAID框架、生成的数据集以及其他相关信息，可在此链接查阅：[链接]。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23444", "html_url": "https://arxiv.org/abs/2510.23444", "title": "FRBNet：通过频域径向基网络重温低光照视觉", "title_en": "FRBNet: Revisiting Low-Light Vision through Frequency-Domain Radial Basis Network", "authors": "Fangtong Sun,Congyu Li,Ke Yang,Yuchen Pan,Hanwen Yu,Xichuan Zhang,Yiying Li", "background": "低光照条件下保持照明，对于计算机视觉来说是一个基本的挑战，因为严重的光照退化显著影响检测和分割等下游任务的性能。尽管最近的先进技术通过不变特征学习模块提高了性能，但它们仍然无法完全建模低光照条件。因此，作者重新审视低光照成像，并将经典的朗伯模型扩展以更好地刻画低光照条件。", "innovation": "通过频域分析，作者理论证明了频域通道比可以用于通过结构化滤波器过程提取照明不变特征。然后，作者提出了一种称为FRBNet的新颖且端到端可训练模块，该模块将频域通道比操作与可学习的频域滤波器结合，以增强整体照明不变特征。FRBNet作为一种插件即用模块，可以不修改损失函数就集成到现有网络中，用于低光照下游任务。", "conclusion": "广泛的实验在各种下游任务上证明了FRBNet的优越性能，包括暗物体检测提高了+2.2 mAP，夜间分割提高了+2.9 mIoU。代码可在指定的网址获取。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23225", "html_url": "https://arxiv.org/abs/2510.23225", "title": "通过镜头：在Moiré诱导的失真背景下评估深fake检测器", "title_en": "Through the Lens: Benchmarking Deepfake Detectors Against Moiré-Induced Distortions", "authors": "Razaib Tariq,Minji Heo,Simon S. Woo,Shahroz Tariq", "background": "深fake检测在现实场景中仍是一个紧迫的挑战，特别是在智能手机拍摄的数字屏幕媒体中，经常会引入Moiré纹理，这些纹理会误导检测结果。本文系统性地评估了最先进的（SOTA）深fake检测器在Moiré影响的视频上的性能，强调了这一问题的忽视。研究收集了来自Celeb-DF、DFD、DFDC、UADFV和FF++数据集的12,832个视频，涵盖了多种现实条件，包括不同屏幕、手机、照明设置和相机角度。", "innovation": "研究引入了DeepMoiréFake（DMF）数据集和两种合成Moiré纹理生成技术，进一步探讨了Moiré模式对深fake检测的影响。研究表明，Moiré纹理可导致高达25.4%的性能下降，而合成Moiré纹理会导致21.4%的准确性下降。令人惊讶的是，旨在缓解此问题的降Moiré方法反而降低了准确性，降低了最多17.2%。这些发现强调了迫切需要能够处理Moiré扭曲以及其他现实世界挑战（如压缩、锐化和模糊）的检测模型。从引入DMF数据集的角度出发，我们旨在推动未来研究接近控制实验和实际深fake检测之间的差距。", "conclusion": "本文结果揭示，在Moiré扭曲及其他现实挑战下，检测模型应具备更强的鲁棒性。通过引入DMF数据集，我们推动了深fake检测的研究，在真实世界条件下的准确性和鲁棒性方面缩小了研究与应用之间的差距。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.08930", "html_url": "https://arxiv.org/abs/2503.08930", "title": "声学神经3D重建中的姿态漂移", "title_en": "Acoustic Neural 3D Reconstruction Under Pose Drift", "authors": "Tianxiang Lin,Mohamad Qadri,Kevin Zhang,Adithya Pediredla,Christopher A. Metzler,Michael Kaess", "background": "当前最先进的声学3D建模算法的准确性高度依赖于准确的姿态估计；传感器姿态的小误差会导致严重的重建伪影。", "innovation": "本文提出了一种算法，该算法联合优化神经场景表示和声纳姿态。该算法通过将6自由度姿态参数化为可学习参数，并通过神经渲染器和隐式表示反向传播梯度来实现。实验验证了该算法在实际和模拟数据集上的有效性。", "conclusion": "即使在显著的姿态漂移下，该算法也能够生成高质量的3D重建结果。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.22366", "html_url": "https://arxiv.org/abs/2410.22366", "title": "One-Step is Enough: Sparse Autoencoders for Text-to-Image Diffusion Models", "title_en": "One-Step is Enough: Sparse Autoencoders for Text-to-Image Diffusion Models", "authors": "Viacheslav Surkov,Chris Wendler,Antonio Mari,Mikhail Terekhov,Justin Deschenaux,Robert West,Caglar Gulcehre,David Bau", "background": "对于大型语言模型（LLMs），稀疏自编码器（SAEs）已经显示出能将不可直接解释的中间表示分解为可解释特征的稀疏和，从而改善了控制和后续分析。然而，类似分析和方法在文本到图像模型中尚未得到发展。\n研究人员旨在调查SAEs为一个基于几个步骤的文本到图像扩散模型（SDXL Turbo）学习可解释特征的可能性。研究者在SDXL Turbo的1步设置下训练SAEs于其去噪U-net中变换器块的更新。", "innovation": "研究者展示了如何在其生成过程中切换单一SAE特征来创建基于表示的图像编辑基准（RIEBench），从而跟踪各变换器块特征的影响。研究结果表明，SAEs能够推广到SDXL Turbo的4步设置及多步版本的基模型，无需额外训练。此外，研究还揭示了块的特化，并证明了学习到的特征具有可解释性且影响生成过程。", "conclusion": "这是首次研究SAEs在文本到图像扩散模型中的可解释性，研究结果证实SAEs可以作为一种有效的方法来理解并操控文本到图像模型的内部机制。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.07862", "html_url": "https://arxiv.org/abs/2502.07862", "title": "ADMN:逐层自适应多模态网络的动态输入噪声和计算资源", "title_en": "ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources", "authors": "Jason Wu,Yuyang Yuan,Kang Yang,Lance Kaplan,Mani Srivastava", "background": "由于多传感器模态提供的鲁棒性，多模态深度学习系统被部署在动态场景中。然而，这些系统在计算资源可用性（由于多租户、设备异构等）和输入质量（从传感器反馈污染、环境噪声等）波动时表现不佳。静态提供计算资源的多模态系统无法适应计算资源随时间的变化，而现有的动态网络在严格的计算预算下难以处理。此外，这两种系统通常忽视了模态质量变化的影响。因此，遭受严重污染的模态可能会无谓地消耗本应用于其他更可靠的模态的资源。", "innovation": "我们提出了ADMN（逐层自适应多模态网络），该网络可以同时解决上述两个挑战：它通过调整所有模态之间活动层的总数来满足严格的计算资源限制，并根据各模态的质量持续重新分配层。我们的评估表明，ADMN能够在减少高达75%浮点运算的情况下达到与最新网络相当的准确性。", "conclusion": "ADMN能够在面对动态输入噪声和计算资源时提供出色的适应性，从而优化资源利用并提高模型的准确性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23497", "html_url": "https://arxiv.org/abs/2510.23497", "title": "VOLD: 通过在线策略蒸馏从LLMs向视觉语言模型迁移推理能力", "title_en": "VOLD: Reasoning Transfer from LLMs to Vision-Language Models via On-Policy Distillation", "authors": "Walid Bousselham,Hilde Kuehne,Cordelia Schmid", "background": "训练视觉-语言模型（VLMs）进行复杂的推理仍然是一项具有挑战性的任务，部分原因是高质量的图像-文本推理数据稀少。相比之下，基于文本的推理资源丰富且可扩展，但如何利用这些资源来提升VLM的推理能力仍是一个开放性问题。为了应对这一挑战，本文提出了一个名为VOLD的框架，用于将仅基于文本的教师模型的推理能力转移到VLM学生模型中。VOLD结合了强化学习中的组相对策略优化（GRPO）与在线策略蒸馏，使得学生模型的推理过程能够在教师模型的指导下进行，从而显著提高了效果。研究还发现，在线训练过程中，冷启动对齐是有效迁移的关键，只有当教师模型和学生模型的分布足够匹配时，策略蒸馏才能提供有意义的指导。", "innovation": "本文创新性地提出了一个名为VOLD的框架，通过结合强化学习中的组相对策略优化（GRPO）与在线策略蒸馏，将仅基于文本的教师模型的推理能力转移到视觉语言学生模型中。此外，该研究强调了冷启动对齐在在线训练阶段的有效性，表明只有当教师模型和学生模型的分布足够匹配时，策略蒸馏才能有效地指导学生模型的推理过程。VOLD在多个基准测试中表现出色，显著优于基线模型，并在某些基准上超越了最先进的技术水平。", "conclusion": "本文通过VOLD框架成功地将基于文本的推理能力迁移到了视觉语言模型中，显著改善了模型的推理能力。研究还证明了冷启动对齐的重要性，对于在线策略蒸馏的成功至关重要。VOLD在多个复杂推理任务上都优于基线和当前最先进的模型，展示了其在实际应用中的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23594", "html_url": "https://arxiv.org/abs/2510.23594", "title": "PRISM-Bench：具有CoT错误检测的基于谜题的视觉任务基准", "title_en": "PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error Detection", "authors": "Yusu Qian,Cheng Wan,Chao Jia,Yinfei Yang,Qingyu Zhao,Zhe Gan", "background": "多模态大型语言模型（MLLMs）在视觉语言任务中取得了显著进展，但其推理过程有时并不可靠。现有评估多模态模型的方法通常仅关注最终答案的准确性，而没有充分评估其推理过程的逻辑一致性和错误检测能力。现有评估专注于模型能否解决问题，但不能深入评估其推理过程。PRISM-Bench则引入了一个诊断任务，通过要求模型识别给定视觉谜题和包含一个错误的详细推理步骤（CoT）中的第一个错误，来更细致地评估逻辑一致性、错误检测和视觉推理能力。", "innovation": "PRISM-Bench是一个基于视觉谜题的评估基准，旨在不仅评估模型能否解决问题，还评估其推理全过程。不同于之前仅关注最终答案准确性的评估，PRISM-Bench引入了诊断任务：给定一个视觉谜题和一个含有精确一个错误的详细推理步骤，模型必须识别第一个错误的步骤。这种设置使得评估更加精细，能够评估逻辑一致性、错误检测和视觉推理。PRISM-Bench中的谜题要求多步骤的符号推理、几何推理和类比推理，同时抵制了基于表面模式匹配的捷径。在前沿多模态语言模型上的评估显示，流畅的生成和准确的推理之间存在持续的差距：生成看似合理的推理步骤的模型往往难以检测到简单的逻辑错误。通过分离答案生成和推理验证，PRISM-Bench提供了对多模态推理能力更清晰的视角，并强调了诊断性评估协议在开发可信赖的多模态语言模型中的重要性。", "conclusion": "PRISM-Bench通过设定期望模型识别推理过程中的错误，提供了对多模态推理能力更精细和深入的评估。这种设置揭示了在开发可信赖的多模态语言模型中，解决流畅生成和精确推理之间差距的重要性，强调了诊断性评估协议的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.24424", "html_url": "https://arxiv.org/abs/2505.24424", "title": "在高效微调中推进CLIP的组合理解能力", "title_en": "Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning", "authors": "Amit Peleg,Naman Deep Singh,Matthias Hein", "background": "基于视觉-语言的模型（如CLIP）在零样本分类和检索方面表现出非凡的能力，但它们在处理组合理解方面常常遇到困难，即理解概念间的关系。现有的基准（如SugarCrepe++）表明，之前改进组合理解的工作主要增强了词汇敏感性，却忽略了语义理解。同时，尽管提升组合理解应该改善检索性能，但下游检索性能却常常下降。鉴于此，研究提出了CLIC（组合理解中的CLIP谙熟学习方法），通过结合多张图像及其关联的描述进行新型训练技术，提升了不同架构及预训练CLIP模型的组合理解能力，在词汇理解和语义理解方面均有所改进，且检索性能也得到了一致的提升。这项方法甚至适用于最近的CLIPS，后者获得了检索性能的SOTA成果。通过CLIC进行短周期微调，检索性能显著提升，并获得了最佳组成的CLIP模型的SugarCrepe++排行榜。", "innovation": "CLIC是一种基于结合多张图像及其关联描述的新型训练技术的微调方法，它能够显著提升不同架构及预训练CLIP模型的组合理解能力，包括词汇理解和语义理解，及其检索性能，并且即使适用于最近的在检索性能上取得SOTA成果的CLIPS。通过CLIC的高效微调，检索性能不仅提升，还在SugarCrepe++的组合理解榜上处于领先位置。", "conclusion": "CLIC通过结合多图像和描述进行训练，提升了不同CLIP模型的组合理解能力和检索性能，特别在短周期微调后表现突出，提升了CLIP和CLIPS在组合理解方面的表现，并在SugarCrepe++基准测试中取得了最好成绩。所有模型及相关代码均在给定的链接处提供。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.00034", "html_url": "https://arxiv.org/abs/2506.00034", "title": "GaussianFusion: Gaussian-Based Multi-Sensor Fusion for End-to-End Autonomous Driving", "title_en": "GaussianFusion: Gaussian-Based Multi-Sensor Fusion for End-to-End Autonomous Driving", "authors": "Shuai Liu,Quanmin Liang,Zefeng Li,Boyang Li,Kai Huang", "background": "多传感器融合对于提升端到端自动驾驶系统的性能和鲁棒性至关重要。现有的方法主要采用基于注意力的扁平融合或通过几何变换的鸟瞰视图融合，但这些方法往往缺乏可解释性和高计算量的问题。", "innovation": "本文提出了一种基于高斯的多传感器融合框架——GaussianFusion，利用直观且紧凑的高斯表示作为一种中间载体来聚合来自不同传感器的信息。通过迭代地融合多模态特征，逐步细化高斯，并设计了一个级联计划头，通过与高斯的交互逐步优化轨迹预测，从而充分挖掘高斯中的丰富空间和语义信息，提升了系统的整体效果和鲁棒性。", "conclusion": "在NAVSIM和Bench2Drive基准上的大量实验验证了提出的方法GaussianFusion的有效性和鲁棒性，详细的源代码将在指定链接处发布。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.19585", "html_url": "https://arxiv.org/abs/2510.19585", "title": "使用大型语言模型检测历史书籍中的拉丁文：一种跨模态基准", "title_en": "Detecting Latin in Historical Books with Large Language Models: A Multimodal Benchmark", "authors": "Yu Wu,Ke Shu,Jonas Fischer,Lidia Pivovarova,David Rosson,Eetu Mäkelä,Mikko Tolonen", "background": "该论文旨在从包含多种语言的复杂布局历史文档中提取拉丁语片段。研究人员利用大型基础模型和一个包含724个标注页面的多模态数据集对这一任务进行了基准测试和评价。研究表明，当前模型在拉丁语检测方面具有可靠的能力。", "innovation": "研究提出了一个新颖的任务，即从混合语言的历史文件中提取拉丁语片段。通过将大型基础模型与包含724个标注页面的多模态数据集进行比较，提供了对这些模型在这项任务中的能力和局限性的首次全面分析。", "conclusion": "研究表明，使用当前的模型进行可靠拉丁语检测是可行的。研究为这一任务提供了一个详细的模型分析，揭示了其在不同场景下的有效性和限制。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.17336", "html_url": "https://arxiv.org/abs/2509.17336", "title": "Mano技术报告", "title_en": "Mano Technical Report", "authors": "Tianyu Fu,Anyang Su,Chenxu Zhao,Hanning Wang,Minghui Wu,Zhe Yu,Fei Hu,Mingjia Shi,Wei Dong,Jiayao Wang,Yuyang Chen,Ruiyang Yu,Siran Peng,Menglin Li,Nan Huang,Haitian Wei,Jiawei Yu,Yi Xin,Xilin Zhao,Kai Gu,Ping Jiang,Sifan Zhou,Shuo Wang", "background": "图形用户界面（GUI）是人机交互的主要媒介，但自动化GUI交互仍然具有挑战性，因为涉及到视觉元素的复杂性、动态环境以及需要多步推理。现有基于视觉-语言模型（VLMs）的方法通常在分辨率有限、领域不匹配以及序列决策能力不足等方面存在局限性。", "innovation": "本文提出了Mano，这是一种基于多模态基础模型的GUI代理，该模型在大量网络和计算机系统数据上预训练。Mano通过引入一个新颖的高保真度模拟环境、三阶段训练管线（监督微调、离线强化学习和在线强化学习）以及错误恢复验证模块，解决了之前方法的局限性。Mano在多个GUI基准测试中展现了最先进的性能，尤其是在成功率和操作准确性方面取得了显著提升。", "conclusion": "本研究为强化学习与VLMs的有效集成提供了新的见解，适用于实用的GUI代理部署，并强调了领域特定数据、迭代训练和整体奖励设计的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18443", "html_url": "https://arxiv.org/abs/2506.18443", "title": "雷达和事件相机融合用于敏捷机器人自我运动估计", "title_en": "Radar and Event Camera Fusion for Agile Robot Ego-Motion Estimation", "authors": "Yang Lyu,Zhenghao Zou,Yanfeng Li,Xiaohu Guo,Chunhui Zhao,Quan Pan", "background": "在高动态场景下，传统的传感器（如IMU）往往无法及时清晰地响应敏捷机器人的快速运动，导致测量模糊、失真和延迟。为了应对这一挑战，该研究提出了一种无需IMU和特征关联的框架，利用事件相机和毫米波雷达这两种外生传感器的瞬时原始事件和多普勒测量数据直接估计机器人的旋转和线性速度。这种方法避免了复杂的关联过程，适用于纹理和结构缺失的环境，并且更适合边缘计算设备。在后端，该研究提出了一种连续时间状态空间模型，将混合的时间和事件测量数据融合起来，通过固定延迟平滑的方式估计自我运动速度。这种方法验证了在自收集实验数据集中的广泛性能，并证明了该IMU和特征关联自由的自我运动估计框架能够在挑战性环境中提供可靠有效速度输出。", "innovation": "该研究的主要创新在于提出了一种无需IMU和特征关联的融合框架，通过结合事件相机和毫米波雷达的数据，直接估计机器人的速度，适用于高动态环境，且具有较高的计算效率和鲁棒性。同时，还提出了一种新的连续时间状态空间模型来平滑融合混合测量数据，提高了速度估计的准确性。", "conclusion": "研究验证了该框架在挑战性环境下的可靠性和效率，表明该IMU和特征关联自由的自我运动估计框架能够提供有效的速度输出。该研究成果为敏捷机器人自我运动估计提供了一种新的解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05186", "html_url": "https://arxiv.org/abs/2508.05186", "title": "学习感知与行动：具有任务感知的视图规划在机械臂操作中的应用", "title_en": "Learning to See and Act: Task-Aware View Planning for Robotic Manipulation", "authors": "Yongjie Bai,Zhouxia Wang,Yang Liu,Weixing Chen,Ziliang Chen,Mingtong Dai,Yongsen Zheng,Lingbo Liu,Guanbin Li,Liang Lin", "background": "当前的视觉-语言-动作（VLA）模型在多任务机械臂操作中通常依赖于固定视角和共享视觉编码器，这限制了3D感知并导致任务干扰，影响了模型的鲁棒性和泛化能力。", "innovation": "提出了一种名为Task-Aware View Planning（TAVP）的框架，通过结合任务特异性表示学习和主动视图规划来解决这些挑战。使用一种高效的探索策略，通过全新的伪环境加速，积极获取更多信息性的视图。同时，引入了一种Mixture-of-Experts（MoE）视觉编码器来分离不同任务的特征，提升了表示的准确性和任务的泛化能力。", "conclusion": "通过以任务感知的方式感知世界，TAVP生成了更为完整和区分性的视觉表示，显著提升了在各种机械臂操作挑战中的动作预测性能。在RLBench任务上的大量实验表明，所提出的TAVP模型优于最先进的固定视图方法。附加的视觉结果和代码已在this https URL处提供。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23622", "html_url": "https://arxiv.org/abs/2510.23622", "title": "适应对抗攻击的架构设计以构建稳健的医疗人工智能系统", "title_en": "Adversarially-Aware Architecture Design for Robust Medical AI Systems", "authors": "Alyssa Gerhart,Balaji Iyangar", "background": "AI系统在医疗领域的应用面临严重威胁，对抗攻击可能误导模型，导致误诊或延误治疗。这些攻击在人类无法察觉的情况下威胁患者安全，特别是在医疗资源不足的地区更为突出。通过对皮肤病学数据集的实验证明，对抗性方法显著降低了分类准确率。", "innovation": "通过实验证明了对抗性方法对医疗AI系统的威胁，展示了对抗训练和蒸馏等防御措施的部分有效性。强调防御措施的使用需要在保护模型免受攻击的同时保持在干净数据上的性能。", "conclusion": "呼吁从技术、伦理和政策三个方面综合考虑，以构建更加稳固和公平的医疗AI系统。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.17550", "html_url": "https://arxiv.org/abs/2509.17550", "title": "《定然是深伪吗？检测与生成生态系统中的可靠性分析》", "title_en": "Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem", "authors": "Neslihan Kose,Anthony Rhodes,Umur Aybars Ciftci,Ilke Demir", "background": "随着生成模型在质量和数量上的提升，用于生成合成内容的深伪开始在网络引起信任问题。为应对这一问题，反深伪检测器被提出，但这些检测器的误报和漏报进一步加剧了信息误导问题。因此，需要对这些检测器的不确定性进行综合分析，探讨生成特征如何影响预测置信度，同时考虑生成器本身的不确定性分析，以期利用不确定性来检测深伪来源。本研究通过系统的分析反深伪检测器和生成器的不确定性，确定了不确定性流形中包含足够一致信息的检测深伪源的方法。", "innovation": "本文提出了第一个全面的反深伪检测器不确定性分析，首次探讨生成特征如何影响预测置信度。研究采用了贝叶斯神经网络和蒙特卡洛丢弃方法量化不同检测器架构下的不确定性。通过在两个数据集上评估不确定性，进行了盲测试和生物检测器的对比研究，并通过消融实验探索区域和像素级别的不确定性。此外，还介绍了像素级别的不确定性图，揭示了与生成器特定特征相关联的不同模式。通过实验证明，不确定性量化是检测可信合成媒体的必要前提，为检测系统的可靠部署提供了重要见解。", "conclusion": "我们的分析为部署可靠的深伪检测系统提供了关键见解，并确立了不确定性量化作为检测可信合成媒体的基本需求。通过检测器和生成器的不同实验证明了其泛化能力、模型校准和对抗攻击的鲁棒性。各实验结果表明，通过不确定性量化可以鉴定各个生成和检测器组合的一致性和可靠性。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.22802", "html_url": "https://arxiv.org/abs/2506.22802", "title": "生成模型的黎曼几何特征", "title_en": "Riemannian-Geometric Fingerprints of Generative Models", "authors": "Hae Jin Song,Laurent Itti", "background": "近年来，生成模型（GMs）取得了突破性进展并迅速集成，引发了对模型归属和其特征的研究兴趣。这不仅吸引了服务提供商寻求可靠的模型验证方法以保护知识产权，也引起了用户和执法部门对生成内容来源验证的兴趣，以确保责任和信任。此外，随着更多由模型生成的数据被反馈到训练数据源中（例如YouTube），形成了“递归训练”现象，加剧了识别合成数据与人类数据的需求。然而，仍然缺乏一种正式框架来定义、表示和分析生成模型的特征，这是现有研究中存在的差距。我们采用几何方法，提出一种新的生成模型特征和指纹的定义，基于黎曼几何，使我们能够利用微分几何的丰富理论。这项新的定义推广了以前的工作（Song et al., 2024），通过从数据中学习黎曼度量，将其推广到非欧氏流形上，同时用测地线距离和基于kNN的黎曼质心取代欧几里得距离和最近邻搜索。我们在实践中提出了一种新的梯度算法计算模型特征以验证上述假设。结果表明，新的方法在多种指标上性能更优，涵盖了4个不同的数据集（两个不同分辨率：64x64，256x256），27种不同的模型架构和两个模态（视觉，视觉语言），显著提升了模型归属的准确性和泛化能力至未见过的数据集、模型类型和模态，进一步证明了其实用有效性。", "innovation": "我们提出了一种新的黎曼几何方法来定义生成模型的特征和指纹，该方法将生成模型推广到非欧氏流形，通过从数据中学习黎曼度量并用测地线距离和kNN计算中心取代欧几里得距离和最近邻搜索，从而在多个数据集和模型架构中显著提高了生成模型特征的区分度和泛化能力。我们还提出了一种新的梯度算法计算模型特征以验证上述假设。", "conclusion": "我们的新定义显著提高了生成模型特征的可信度和实用性，特别是在区分生成模型并在未见过的数据集、模型类型和模态上具有显著改进，验证了黎曼几何方法的优越性，为模型归属提供了新的研究视角。"}
{"llm_update_time": "20251029", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22379", "html_url": "https://arxiv.org/abs/2510.22379", "title": "TraceTrans: Translation and Spatial Tracing for Surgical Prediction", "title_en": "TraceTrans: Translation and Spatial Tracing for Surgical Prediction", "authors": "Xiyu Luo,Haodong Li,Xinxing Cheng,He Zhao,Yang Hu,Xuan Song,Tianyang Zhang", "background": "图像到图像的翻译模型在图像跨视觉域转换方面取得了显著成功，被用于医学任务如预测术后效果和疾病进展建模。然而，现有的大多数方法主要侧重于匹配目标分布，往往忽略了源图像和翻译图像之间的空间对应关系。这种局限性可能导致结构不一致和幻觉，影响预测的可靠性和可解释性。特别是在临床应用中，这种挑战因需要高度的解剖准确性而变得更加突出。", "innovation": "TraceTrans 是一种新型可变形图像翻译模型，专为术后预测而设计，能够在与目标分布匹配的同时明确显示与术前输入的空间对应关系。该框架采用编码器进行特征提取，以及双解码器进行预测空间变形和生成翻译图像。预测的变形场在生成输出上施加空间约束，确保解剖一致性。", "conclusion": "在医学美容和脑部MRI数据集上的广泛实验表明，TraceTrans 能够提供准确且可解释的术后预测，展示了其在可靠临床部署中的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23621", "html_url": "https://arxiv.org/abs/2510.23621", "title": "加速MACE：等变力场的低精度技巧", "title_en": "Speeding Up MACE: Low-Precision Tricks for Equivarient Force Fields", "authors": "Alexandre Benoit", "background": "现有的机器学习势场可以在高计算成本的情况下提供准确的分子动力学模拟。比如MACE等SO(3)-等变模型，虽然计算精度得到了保证，但并未系统地研究如何通过降低精度运算和GPU优化内核来降低成本而不损害物理精度。因此，本文旨在通过确定计算瓶颈并评估低精度执行策略，使MACE更便宜、更快且保持准确。", "innovation": "本文通过评估FP64/FP32/BF16/FP16设置对MACE进行端到端和块级别的性能剖析，比较e3nn和NVIDIA的cuEquivariance后端，并在复现、稳定状态下的计时条件下进行推理、短NVT和长NPT水模拟及玩具训练运行，实现了MACE在保留精度的同时比推理延迟减少了约3倍的加速效果。研究发现仅将线性层转换为BF16/FP16可以在保持精度的同时进一步加速4倍左右，且在NVT/NPT MD中的能量和热力学观测值在不同的运行中保持稳定。研究还指出，尽管半精度权重在训练过程中会降低力的均方根误差，但在训练时仍应保持在FP32精度以确保模型的训练质量和性能。", "conclusion": "使用cuEquivariance与FP32默认配合，且对线性层启用BF16/FP16（保持FP32累积）来实现最大吞吐量的策略是实际有效的。预计在Ampere/Hopper GPU（TF32/BF16）上可进一步获得性能增益，并可通过内核级FP16/BF16路径和管道融合实现更大加速。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23617", "html_url": "https://arxiv.org/abs/2510.23617", "title": "Enhanced 双变压器对比网络在多模态情感分析中的应用", "title_en": "An Enhanced Dual Transformer Contrastive Network for Multimodal Sentiment Analysis", "authors": "Phuong Q. Dao,Mark Roantree,Vuong M. Ngo", "background": "多模态情感分析（MSA）旨在通过联合分析文本和图像等多种模态的数据，提供比单模态方法更丰富和准确的情感解析。早期的研究通常使用单独的模型分别处理文本和视觉信息，这些方法在跨模态互动和联合表示学习方面存在不足。这项研究旨在通过结合强大的Transformer编码器BERT和ViT（视觉Transformer）并采用早期融合策略提出Bert-ViT-EF模型，以促进更深的跨模态交互和更有效的联合表示学习。进一步，提出了一种增强的Dual Transformer Contrastive Network (DTCN)模型，它在BERT之后引入了额外的Transformer编码层以进一步精炼文本上下文，并使用对比学习来对齐文本和图像表示，从而提升多模态特征学习的鲁棒性。", "innovation": "提出的Bert-ViT-EF模型将BERT和ViT通过早期融合策略相结合，促进了更深的跨模态交互和更有效的联合表示学习。进一步，提出了DTCN，该模型在BERT之后引入了额外的Transformer编码层以精炼文本上下文，并采用对比学习技术来对齐文本和图像的表示，加强了多模态特征的学习。实验结果表明，在两个广泛应用的MSA基准MVSA-Single和TumEmo上，DTCN表现出色，分别在TumEmo上获得最高的准确率（78.4%）和F1分数（78.3%），在MVSA-Single上获得76.6%的准确率和75.9%的F1分数，证明了早期融合和深度上下文建模在基于Transformer的多模态情感分析中的好处和效率。", "conclusion": "本研究通过提出Bert-ViT-EF模型和DTCN，提高了跨模态情感分析的数据联合建模能力，在两个基准测试上显示出色的性能，验证了早期融合和深度上下文学习在多模态情感分析中的有效性和重要性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23626", "html_url": "https://arxiv.org/abs/2510.23626", "title": "从检测到发现：社交媒体上同时和持续的情感知识扩展和抑郁症检测的闭环方法", "title_en": "From Detection to Discovery: A Closed-Loop Approach for Simultaneous and Continuous Medical Knowledge Expansion and Depression Detection on Social Media", "authors": "Shuang Geng,Wenli Zhang,Jiaheng Xie,Rui Wang,Sudha Ram", "background": "社交媒体用户生成的内容（UGC）提供了有关心理健康状况（如抑郁）的实时、自我报告指标，为预测分析提供了宝贵资源。尽管先前的研究将医学知识整合以提高预测准确性，但它们忽略了通过预测过程同时扩展知识的机会。大规模UCG可以同时提高预测准确性和医学理解。", "innovation": "开发了一种闭环大型语言模型（LLM）-知识图谱框架，将预测和知识扩展纳入迭代学习循环。在知识感知的抑郁检测阶段，LLM进行抑郁检测和实体提取，知识图谱代表并加权这些实体以改善预测性能。在知识细化和扩展阶段，LLM提取的新实体、关系和实体类型在专家监督下被纳入知识图谱中，实现知识的持续进化。该框架证明了计算模型与域知识的共生进化，并提出了适应其他动态风险监测领域的基础数据驱动知识系统。", "conclusion": "专家评估证实了对现有文献临床相关症状、共病和社交触发因素的新发现。该框架不仅提高了心理疾病的预测精确度，还促进了医学理解，展示了预测过程中的学习和学习过程中的预测的互加强化，为预测分析中的方法论和理论理解提供了新贡献。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23630", "html_url": "https://arxiv.org/abs/2510.23630", "title": "NUM2EVENT: 从数值时间序列中进行可解释的事件推理", "title_en": "NUM2EVENT: Interpretable Event Reasoning from Numerical time-series", "authors": "Ninghui Feng,Yiyan Qi", "background": "大型语言模型（LLMs）已经在跨模态推理方面展示了令人印象深刻的能力，但在理解纯粹的数值时间序列信号方面仍有限制。现有方法主要集中在预测或趋势描述，而没有揭示驱动数值变化的潜在事件，也无法解释背后的推理过程。本文背景在于填补这一空白，提出了一项从数值输入推断可解释的结构化事件的任务。", "innovation": "本文提出了一个推理感知的框架，该框架包含代理人引导的事件提取器（AGE）、标记多变量Hawkes合成生成器（EveDTS），以及结合时间序列编码器与结构化解码器的两阶段微调流水线，以应对数据稀缺性和语义对齐的挑战。该模型明确地在数值变化上进行推理，生成中间解释，并输出结构化的事件假设。", "conclusion": "在多领域数据集上的实验结果表明，本文方法在事件级别上的精确度和召回率上显著优于强大的LLM基线。这些结果表明，可以开辟一种新的路径，即通过直接从数值动态中解释和预测事件，来弥合定量推理和语义理解之间的差距，为LLMs的能力提供了新的方向。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23624", "html_url": "https://arxiv.org/abs/2510.23624", "title": "DiNo和RanBu：浅随机森林的轻量级预测", "title_en": "DiNo and RanBu: Lightweight Predictions from Shallow Random Forests", "authors": "Tiago Mendonça dos Santos,Rafael Izbicki,Luís Gustavo Esteves", "background": "随机森林是表型预测任务的强基线，但其依赖数百棵深度树通常会导致推理延迟和内存需求较高，限制了在延迟敏感或资源受限环境中的部署。浅森林方法通过限制深度并有效利用距离加权预测器，可以大大减少这些限制。现有方法如DiNo和RanBu，都能在保持或超越深度随机森林的准确性的同时，显著减少训练和推理时间。特别是在噪声较高的情况下，RanBu表现出色。DiNo在低噪声环境下达到最优的偏差-方差贸易，计算成本相对有限。这些方法可以直接应用于分位数回归，提供相同精度的同时显著提升速度。已有开源R/C++实现为用户提供工具支持。研究主要关注结构化表型随机样本（i.i.d.），未来将扩展到其他模态。", "innovation": "提出了两种浅随机森林方法DiNo和RanBu，这些方法通过限制树的深度并利用距离加权预测器，显著减少了训练和推理的时间。RanBu在高噪声设置中达到或超越了全深度随机森林的准确性，而DiNo在噪声较低的情况下能够提供最优的偏差-方差贸易，计算成本有限。此外，这两种方法直接适用于分位数回归，提高了预测速度而不损失准确性。开源实现可供用户使用。", "conclusion": "DiNo和RanBu能够在保持或超越深度随机森林准确性的前提下，显著减少训练和推理时间，尤其是有助于克服资源限制和延迟敏感环境的挑战。特别是在噪声较大和噪声较低的不同场景下，这两种方法表现优异。未来的研究将致力于扩展这些方法的应用到其他数据模态。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23629", "html_url": "https://arxiv.org/abs/2510.23629", "title": "链执行监督促进大规模语言模型的通用推理能力", "title_en": "Chain of Execution Supervision Promotes General Reasoning in Large Language Models", "authors": "Nuo Chen,Zehua Li,Keqin Bao,Junyang Lin,Dayiheng Liu", "background": "在大型语言模型（LLMs）的发展中，构建稳健且通用的推理能力是一个关键目标。近年来，研究人员开始越来越多地利用代码作为丰富的训练来源，因为代码具有固有的逻辑结构和多样化的推理范式，例如分而治之、拓扑排序和枚举。然而，代码中的推理往往是隐含表述的，并且通常与语法或实现噪声交织在一起，这使得直接对原始代码进行训练具有挑战性。针对这一问题，该研究引入了TracePile，这是一个大规模语料库，包含260万样本，将代码执行转化为显式的、逐步骤的、链式思考的推理过程，即称为链式执行（CoE）。该数据集覆盖了数学、经典算法和算法竞赛等领域，并通过引入追踪变量的问题和代码重写来增强逻辑细致度和代码多样性。", "innovation": "该研究创新性地通过将代码执行转化为显式的、逐步骤的、链式思考的推理过程（CoE），并构建了一个大规模数据集（TracePile）来训练LLMs，从而更有效地提高其推理能力。同时，该方法在四个基础模型和20项基准测试上表现出显著的效果，尤其是在数学数据集和特定的应用场景下。", "conclusion": "研究发现，使用TracePile训练的大规模语言模型在数学数据集上的平均提升率为7.1%，并且在两种阶段的微调下，在LiveCodeBench、CRUX和MMLU等基准测试中表现出显著的改进。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23633", "html_url": "https://arxiv.org/abs/2510.23633", "title": "噪声即你所需：通过噪声组合采样解决线性逆问题", "title_en": "Noise is All You Need: Solving Linear Inverse Problems by Noise Combination Sampling with Diffusion Models", "authors": "Xun Su,Hiroyuki Kasai", "background": "预训练的扩散模型在零样本逆问题解决方面表现出强大的能力，通过将观测信息整合到扩散模型的生成过程中。然而，过度整合会破坏生成过程，而不足的整合则无法强调逆问题施加的约束。", "innovation": "提出了一种名为噪声组合采样的新方法，从噪声子空间合成最优噪声向量来近似测量得分，替换标准去噪扩散概率模型过程中的噪声项。这种方法可以嵌入先验信息，无需依赖步骤式的超参数调整。该方法适用于广泛的逆问题解决器，特别是当生成步骤较少时，具有显著的性能提升和可忽略的计算成本，显著提高稳健性和稳定性。", "conclusion": "通过噪声组合采样，扩散模型可以在保持计算效率的同时，更好地解决逆问题，尤其在生成步数较少时表现出卓越的性能和稳定性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23631", "html_url": "https://arxiv.org/abs/2510.23631", "title": "超越成对：通过排序选择建模增强LLM对齐", "title_en": "Beyond Pairwise: Empowering LLM Alignment With Ranked Choice Modeling", "authors": "Yuxuan Tang,Yifan Feng", "background": "目前Large Language Models (LLMs) 的对齐主要是通过成对偏好优化实现的，即人工标注者在两个回应中选择更好的一个。虽然简单，但这种方法忽视了从更丰富的人类反馈形式（如多选项比较和top-$k$排名）中学习的机会。已有研究主要集中在成对方法上，如DPO、SimPO，但未能充分利用这些更丰富的反馈形式进行统一的学习优化。因此，改进现有的对齐方法，使它们能够处理多种反馈形式，对于提高LLM的对齐效果至关重要。", "innovation": "本文提出了Ranked Choice Preference Optimization (RCPO)框架，该框架通过最大似然估计将偏好优化与排序选择建模统一起来。RCPO支持基于效用的和基于排序的选择模型，并涵盖多种现有成对方法，同时为丰富反馈格式提供原理性训练目标。通过使用两种代表性的排序选择模型（多项式对数模型和Mallows-RMJ），实验结果表明，RCPO在Llama-3-8B-Instruct和Gemma-2-9B-it上超越了定制的基线方法。这表明综合使用排序偏好数据和合适的排序选择模型可以更有效地实现对齐，使排序选择建模成为LLM训练的通用基础框架。", "conclusion": "RCPO证明了直接利用排序偏好数据并结合适当的排序选择模型可以提高对齐效果。该研究为将排序选择模型整合到LLM训练中提供了灵活且扩展性强的框架。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23636", "html_url": "https://arxiv.org/abs/2510.23636", "title": "通过大型语言模型和航空轨迹表示的多模态适配进行航班延误预测", "title_en": "Flight Delay Prediction via Cross-Modality Adaptation of Large Language Models and Aircraft Trajectory Representation", "authors": "Thaweerath Phisannupawong,Joshua Julian Damanik,Han-Lim Choi", "background": "航班延误预测已经成为空中交通管理中的关键关注点，因为延误暴露了影响整个网络性能的低效问题。", "innovation": "该方法将轨迹表示与航空信息（包括飞行信息、天气报告和机场通知）的文本模态相结合，通过将轨迹数据适配到语言模态来捕捉空中条件。此模型通过有效利用与延误来源相关的上下文信息，实现了亚分钟级的预测误差。", "conclusion": "该框架表明，语言理解与轨迹信息的跨模态适配相结合，可以增强延误预测。此外，该方法具有实际可行性和可扩展性，支持在接收到新的操作信息时实时更新预测，从而改进预测。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23635", "html_url": "https://arxiv.org/abs/2510.23635", "title": "帮助机器帮你清理数据：基于怀疑学习的自我中心数据清洗野外评估", "title_en": "Help the machine to help you: an evaluation in the wild of egocentric data cleaning via skeptical learning", "authors": "Andrea Bontempelli,Matteo Busso,Leonardo Javier Malcotti,Fausto Giunchiglia", "background": "数字个人助手在支持任务执行、回答问题、管理日常事务或健身日程等方面都需要高质量的注释才能正常运行。但是，无论这些注释是用户的主动生产还是从上下文中推断出来的，都可能受到错误和噪声的影响。之前的Skeptical Learning（SKEL）研究通过比较离线的主动标注数据和被动数据来解决噪音标签的问题，实现了对注释准确性的评估，但是这种评估没有得到最终用户（即任务的真正执行者）的认可，因为他们是自己所处环境的最佳评判者。本研究旨在评估SKEL在现实世界条件下的表现，参与的大学学生将使用移动应用程序iLog四周，真实用户可以基于当前视角和需求改进输入标签。研究揭示了在用户努力与数据质量之间找到平衡的挑战，以及使用SKEL可能带来的减少注释工作量并提高数据质量的好处。", "innovation": "本研究在真实世界条件下评估Skeptical Learning（SKEL），通过实际用户反馈来验证标注数据的准确性和质量改进，填补了之前仅基于技术层面评估的不足，贴近实际应用场景。", "conclusion": "研究结果表明，SKEL在现实世界的使用中，能够帮助平衡用户的努力和数据质量。同时，使用SKEL能够减少标注工作量，并提高收集数据的质量。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23634", "html_url": "https://arxiv.org/abs/2510.23634", "title": "单调且分离的集合函数：表征与神经模型", "title_en": "Monotone and Separable Set Functions: Characterizations and Neural Models", "authors": "Soutrik Sarangi,Yonatan Sverdlov,Nadav Dym,Abir De", "background": "本文受集合包含问题应用的启发，探讨了如何设计从集合变换为向量的函数，能够保持集合的自然部分顺序，即如果集合S是集合T的子集（S⊆T），则变换后的向量F(S)≤F(T)。我们称满足这个性质的函数为单调且分离的（Monotone and Separating，MAS）集合函数。研究发现，在具有无限基础集合的情况下，这类函数不存在，但提出了一种称为‘弱单调分离’（Weakly MAS）的放松性质模型，并且证明其具有保连续性。实验表明，使用该模型比标准集合模型（不包含集合包含作为归纳偏置）具有优势。研究进一步证明单调且分离的集合函数可以构建具有单调性的通用模型，并且能近似所有单调集合函数。", "innovation": "1. 提出了单调且分离的集合函数的概念及其应用背景。\n2. 提出了一种在无限基础集合情况下无法存在这类函数，但提供了一个称为弱单调分离的放松性质模型，并证明其保连续性。\n3. 证明了这类函数可以构建具有单调性的通用模型，并且能近似所有单调集合函数。\n4. 实验表明该模型较传统模型有优势，且代码已公开提供。", "conclusion": "本文通过提出单调且分离的集合函数的概念，分析了此类函数的性质，并提供了一种在某些限制下此类函数存在的模型。此外，实验还展示了该模型相较于一般模型的优越性，并且提供了验证结果和代码。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23639", "html_url": "https://arxiv.org/abs/2510.23639", "title": "将基因组学融入多模态EHR基础模型", "title_en": "Integrating Genomics into Multimodal EHR Foundation Models", "authors": "Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T.J. Chen,Cory Y. McLean", "background": "传统的电子健康记录（EHR）仅限于临床数据，缺乏遗传信息，未能构建全面的健康档案。尽管所有美国研究所（AoU）研究项目提供了丰富的多元数据，但现有方法仍然侧重于单一的数据模态，无法学习复杂关系。", "innovation": "本文提出了一种创新的电子健康记录（EHR）基础模型，该模型将多基因风险评分（PRS）作为基础数据模态，超越了传统的EHR唯一方法，构建了更全面的健康档案。利用AoU研究项目的广泛多样数据，这项多模态框架旨在学习临床数据和遗传易感性之间的复杂关系。该方法扩展了生成式人工智能在EHR基础模型空间的应用，增强了预测能力和解释性。", "conclusion": "评估AoU数据表明，该模型对多种条件（特别是2型糖尿病）的发病具有预测价值，并展示了PRS和EHR数据之间的相互作用。该工作还探索了针对定制分类任务进行迁移学习的可能性，展示了架构的灵活性和效率。此方法为疾病预测、主动健康管理和风险分层以及个性化治疗策略奠定了新的视角，为更个性化、公平和可操作的实际证据生成奠定了基础。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23640", "html_url": "https://arxiv.org/abs/2510.23640", "title": "结构感知渐进注入以实现多模态分子表示学习", "title_en": "Structure-Aware Fusion with Progressive Injection for Multimodal Molecular Representation Learning", "authors": "Zihao Jing,Yan Sun,Yan Yi Li,Sugitha Janarthanan,Alana Deng,Pingzhao Hu", "background": "多模态分子模型经常遭受3D构象不可靠性和模态坍塌的问题，这限制了它们的鲁棒性和泛化能力。", "innovation": "提出了一种名为MuMo的结构化多模态融合框架，通过两种关键策略解决了分子表示中的挑战。设计了一种结构化融合管道（SFP），将2D拓扑和3D几何结合成统一且稳定的结构先验，以减少构象依赖性融合的不稳定性。引入了一种渐进注入（PI）机制，不对称地将该先验集成到序列流中，以保留模态特定建模并允许跨模态丰富。", "conclusion": "MuMo在来自Therapeutics Data Commons (TDC)和MoleculeNet的29项基准任务上，比最佳基线平均提高了2.7%，在22项任务中排名第一，LD50任务上的改进达到了27%。结果验证了其在3D构象噪声下的鲁棒性和多模态融合在分子表示中的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23632", "html_url": "https://arxiv.org/abs/2510.23632", "title": "LLMComp: 一种用于误差限定科学数据压缩的语言建模范式", "title_en": "LLMComp: A Language Modeling Paradigm for Error-Bounded Scientific Data Compression", "authors": "Guozhong Li,Muhannad Alhumaidi,Spiros Skiadopoulos,Panos Kalnis", "background": "高分辨率的科学模拟和观测系统正在迅速增长，生成了大量时空数据集，这使得高效、误差限制的压缩变得越来越重要。同时，仅解码的大语言模型（LLMs）在建模复杂序列数据方面展现了卓越的能力。", "innovation": "本文提出了一种新颖的有损压缩范式LLMCOMP，利用仅解码的大语言模型来建模科学数据。LLMCOMP首先将3D字段量化为离散标记，利用Z-order曲线排列以保持局部性，并应用覆盖率引导的采样以增强训练效率。然后，使用时空嵌入训练自回归变换器以建模标记转换。在压缩过程中，模型进行k-best预测，仅存储排名索引和回退修正，以确保严格的误差界限。", "conclusion": "实验表明，LLMCOMP在多个再分析数据集上持续优于最先进的压缩器，在严格的误差界限下压缩比最高可提高30%。这些结果突显了LLMs作为高保真科学数据通用压缩器的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23637", "html_url": "https://arxiv.org/abs/2510.23637", "title": "结合文本和结构信息在Lean中的前提选择", "title_en": "Combining Textual and Structural Information for Premise Selection in Lean", "authors": "Job Petrovčič,David Eliecer Narvaez Denis,Ljupčo Todorovski", "background": "大型形式库中的定理证明是一个关键瓶颈，现有的基于语言的方法往往将前提孤立地处理，忽略了连接它们的依赖网络。作者提出了一个图增强的方法，该方法结合了Lean形式化中的密集文本嵌入以及旨在捕捉状态-前提和前提-前提关系的异构依赖图上的图神经网络。", "innovation": "该研究提出将文本嵌入与图神经网络结合使用的方法，利用异构依赖图捕捉前提之间的依赖关系。这种方法在LeanDojo基准测试中，相比ReProver语言基线，在标准检索度量方面提高了超过25%的表现。", "conclusion": "本研究证明了关系信息对于提高前提选择的有效性有强大的作用。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23650", "html_url": "https://arxiv.org/abs/2510.23650", "title": "超越隐藏层操控：面向语义的logits干预方法在纠偏LLM中的应用", "title_en": "Beyond Hidden-Layer Manipulation: Semantically-Aware Logit Interventions for Debiasing LLMs", "authors": "Wei Xia", "background": "尽管已有隐藏层方法用于纠偏LLM，但是它们可能影响模型的流畅性，而且效果有限。因此，有必要探索新的方法来更有效地减少偏见，同时保持模型的流畅性和准确性。", "innovation": "提出了静态和动态两种零样本logits层去偏方法。动态方法在减少偏见的同时，将流畅性损失降到最低，并且 logits 干预方法优于隐藏层方法。进一步展示了面向语义的 logits 干预方法能够稳定且有效地纠偏对齐的LLM。", "conclusion": "所提出的面向语义的 logits 干预方法能够显著提高对齐的大语言模型（LLM）的去偏效果，同时减少流畅性损失，展现了其在实际应用中的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23649", "html_url": "https://arxiv.org/abs/2510.23649", "title": "高效低秩注意力机制在大型语言模型长期上下文推理中的应用", "title_en": "Efficient Low Rank Attention for Long-Context Inference in Large Language Models", "authors": "Tenghui Li,Guoxu Zhou,Xuyang Zhao,Yuning Qiu,Qibin Zhao", "background": "随着输入文本长度的增长，大型语言模型（LLM）中的键值（KV）缓存会对GPU内存产生巨大的成本，限制了在资源受限设备上的长期上下文推理。现有的方法，例如键值量化和剪枝，虽然能够减少内存使用，但会损失数值精度或导致键值对的非最优保留。", "innovation": "提出了一种名为Low Rank Query and Key attention (LRQK)的两阶段框架。在预填充阶段，LRQK将全精度的查询和键矩阵联合分解为紧凑的秩-r因子。在解码阶段，使用这些低维投影来计算约简的注意力分数，时间复杂度为O(lr)。通过仅选择前k个token和一小部分最近的token，LRQK利用混合GPU-CPU缓存机制，并且当内存不足时仅传输缺失的全精度键值对，以保持精确的注意力输出并减少GPU-CPU之间的数据传输。", "conclusion": "在RULER和LongBench基准上使用LLaMA-3-8B和Qwen2.5-7B进行的实验表明，LRQK在长期上下文设置中能够匹配或超越领先的稀疏注意力方法。同时，LRQK提供了显著的内存节省，且精度损失最小。相关代码已开源。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23641", "html_url": "https://arxiv.org/abs/2510.23641", "title": "Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging", "title_en": "Spatially Aware Linear Transformer (SAL-T) for Particle Jet Tagging", "authors": "Aaron Wang,Zihan Zhao,Subash Katel,Vivekanand Gyanchand Sahu,Elham E Khoda,Abhijith Gandrakota,Jennifer Ngadiuba,Richard Cavanaugh,Javier Duarte", "background": "变换器在高能粒子碰撞中能够捕捉全局和局部关系，但在高数据吞吐环境，如欧洲核子研究中心大型强子对撞机（CERN LHC）中部署时存在挑战。变换器模型的二次复杂性要求大量资源，增加了推理时的延迟。因此，本文回顾了现有技术的局限性和研究背景，强调了解决这些问题的必要性。", "innovation": "提出了一种名为Spatially Aware Linear Transformer (SAL-T)的物理启发方法，作为linformer架构的改进，保持线性注意力。该方法基于粒子的动力学特征进行空间感知分区，计算物理意义上重要的区域之间的注意。同时，利用卷积层捕捉局部相关性，受到粒子束物理的见解指导。与标准linformer相比，SAL-T在粒子束分类任务中表现出色，资源消耗和推断延迟更低，而在ModelNet10的点云分类数据集上也验证了这种趋势。", "conclusion": "SAL-T在粒子束分类任务中取得了优于标准linformer的结果，同时在资源消耗和推断延迟方面表现更佳。此外，SAL-T在ModelNet10上的性能进一步证实了其有效性，并提供了易于访问的代码。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23652", "html_url": "https://arxiv.org/abs/2510.23652", "title": "结构性的小刀：大规模语言模型的自动化连续层剪枝", "title_en": "The Structural Scalpel: Automated Contiguous Layer Pruning for Large Language Models", "authors": "Yao Lu,Yuqi Li,Wenbin Xie,Shanqing Yu,Qi Xuan,Zhaowei Zhu,Shiping Wen", "background": "尽管大型语言模型（LLMs）在许多领域取得了革命性的突破，但由于其大型模型体量和高昂的计算成本，它们对于资源受限的边缘设备的广泛应用构成了重大挑战。为了解决这一问题，已经提出了层剪枝技术，通过直接移除冗余层来减少计算开销。然而，现有的层剪枝方法通常依赖手工制定的指标来评估和移除单个层，而忽略了层之间的依赖关系。这可能会破坏模型的信息流动，严重降低性能。", "innovation": "本文提出了一种名为CLP的新颖连续层剪枝框架，引入了两个关键创新：可微凹门算法（一种基于梯度优化自动识别最佳连续层片段进行剪枝的算法）；以及端点调整策略（通过微调剪枝片段周围的层来有效恢复模型性能的一种策略）。", "conclusion": "广泛的实验表明，CLP在多个模型架构（包括LLaMA2、LLaMA3和Qwen）和不同参数量（从7B到70B）下显著优于现有最先进的基线。例如，在20%的剪枝率下，CLP在LLaMA3-70B上实现了平均性能保留95.34%，优于基线4.29%至30.52%。此外，CLP还可以与量化整合，以进一步压缩模型且仅造成轻微的性能损失。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23656", "html_url": "https://arxiv.org/abs/2510.23656", "title": "基于时空相关融合的预测误差调整方法及其在交通预报中的应用", "title_en": "Error Adjustment Based on Spatiotemporal Correlation Fusion for Traffic Forecasting", "authors": "Fuqiang Liu,Weiping Ding,Luis Miranda-Moreno,Lijun Sun", "background": "深度神经网络（DNN）在交通预报研究中扮演着重要角色，因为它们能够有效捕获交通数据中嵌入的空间和时间模式。然而，许多基于DNN的预报模型都是通过均方误差估计进行训练的，假设时间步长和空间位置上的误差是不相关的。然而，这种假设并不总是成立，因为交通数据具有时间和空间上的自相关性。这一差距限制了基于DNN的预报模型的性能，并被当前的研究所忽视。", "innovation": "本文提出了时空自相关误差调整（SAEA），这是一种新颖的一般框架，旨在系统地调整交通预报中的自相关预测误差。SAEA将这些误差建模为时空向量自回归（VAR）过程，以捕捉其内在依赖性。它通过一个系数矩阵显式地捕捉空间和时间误差的相关性，然后将此系数矩阵嵌入到一个新的代价函数中。此外，引入了一种结构稀疏正则化来结合先验的空间信息，以确保学习到的系数矩阵与内在的道路网络结构保持一致。最后，设计了一个带有测试时误差调整的推理过程，动态地精炼预测，减少实时预报中自相关误差的影响。", "conclusion": "通过在不同交通数据集上进行实验证明了该方法的有效性。结果表明，该方法在多种交通预报模型中几乎都提高了性能。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23657", "html_url": "https://arxiv.org/abs/2510.23657", "title": "集成种子特性和等离子参数的机器学习框架用于预测作物萌发提升", "title_en": "A machine learning framework integrating seed traits and plasma parameters for predicting germination uplift in crops", "authors": "Saklain Niam,Tashfiqur Rahman,Md. Amjad Patwary,Mukarram Hossain", "background": "冷等离子体（CP）是一种环保的方法，可提高种子发芽率，但由于种子-等离子体-环境之间的复杂相互作用，结果难以预测。本研究旨在通过引入第一台机器学习框架，预测在Dielectric Barrier Discharge（DBD）等离子体条件下大豆、大麦、向日葵、萝卜和番茄的发芽率提升。", "innovation": "研究采用了机器学习框架来预测作物在DBD等离子体条件下的发芽率提升，其中Extra Trees模型表现最佳。研究还发现了剂量反应性：在7 kV或200秒以下几乎没有影响，在7-15 kV、200-500秒达到最大发芽率，超过20 kV或长时间暴露会降低发芽率。等离子放电功率也是一个主要因素，功率至少100瓦时发芽率最大化，且暴露时间较短。不同作物和品种对发芽率提升的预测精确度不同，精度较高的有萝卜和大豆，而向日葵则相对较高变异性。", "conclusion": "该机器学习框架被嵌入到了MLflow中，为精准农业条件下优化冷等离子体种子发芽提供决策支持工具。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23658", "html_url": "https://arxiv.org/abs/2510.23658", "title": "通过无配对偏好优化对扩散语言模型进行对齐", "title_en": "Aligning Diffusion Language Models via Unpaired Preference Optimization", "authors": "Vaibhav Jindal,Hejian Sang,Chun-Mao Lai,Yanning Chen,Zhipeng Wang", "background": "扩散语言模型（dLLMs）作为一种新兴的选择，对自回归（AR）生成器构成了一种替代，但在将它们与人类偏好对齐方面存在挑战，因为序列对数似然在计算上是不可解的，而成对的偏好数据收集成本高昂。论文中，ELBO-KTO 方法将 ELBO 替代作为扩散对数似然的近似与前景理论指导下的非配对偏好目标（Kahneman Tversky Optimization, KTO）结合，以克服这一挑战并优化模型结构以更接近人类偏好权衡与一致性", "innovation": "提出了一种新的方法，ELBO-KTO，该方法通过将ELBO替代作为扩散对数似然的近似，并结合前景理论（KTO）中指导的非配对偏好目标来优化扩散语言模型（dLLMs）。此外，该方法还研究了ELBO近似带来的偏差和方差，并实施减少方差的技术以提高训练过程中的梯度稳定性", "conclusion": "ELBO-KTO 方法在多个下游任务上与基模型相当或表现出更好，特别是在使用 UltraFeedback-Binary 训练的 LLaDA-8B-Instruct 模型上，分别在kto-mix-14k和UltraFeedback-Binary上获得了65.9%和62.3%的调整胜出率，证明无配对偏好优化可以作为一种扩散 LLM 中替代成对对齐的可行方法"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23665", "html_url": "https://arxiv.org/abs/2510.23665", "title": "从压缩表示生成变换器", "title_en": "Transformers from Compressed Representations", "authors": "Juan C. Leon Alcazar,Mattia Soldan,Mohammad Saatialsoruji,Alejandro Pardo,Hani Itani,Juan Camilo Perez,Bernard Ghanem", "background": "压缩文件格式是高效数据存储和传输的基础，但在其作为表示学习潜力方面的探索尚待进一步挖掘。现有的研究大多关注原始字节级别的处理或媒体的完整解码，未能充分利用压缩文件中的内在字节流结构来设计有效的标记化和编码策略。", "innovation": "本文提出了一种名为TEMPEST的方法，即从压缩表示生成变换器。该方法通过利用压缩文件中的内在字节流结构，设计了一种有效的标记化和编码策略，使得标准变换器能够直接从压缩数据流中学习语义表示，从而避免了原始字节级别的处理或媒体解码的需要。这种方法大幅减少了语义分类所需的标记数量，降低了计算复杂度和内存使用量。通过在多样化的数据集、编码方案和模态下进行广泛实验，结果表明，TEMPEST在保持与现有最先进的精度的同时，实现了在内存和计算效率上的改进。", "conclusion": "本文通过实验证明，基于压缩表示的变换器不仅能够达到与现有先进技术相当的精度，还能在内存和计算效率上实现显著的改进。未来的研究将进一步探索这种新技术在实际应用中的潜力和局限性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23668", "html_url": "https://arxiv.org/abs/2510.23668", "title": "交通流量预测，STL 分解，混合模型，LSTM，ARIMA，XGBoost，智能交通系统", "title_en": "Traffic flow forecasting, STL decomposition, Hybrid model, LSTM, ARIMA, XGBoost, Intelligent transportation systems", "authors": "Fujiang Yuan,Yangrui Fan,Xiaohuan Bing,Zhen Tian,Chunhong Yuan,Yankang Li", "background": "准确的交通流预测对于智能交通系统和城市交通管理至关重要。然而，单一模型方法往往难以捕捉交通流数据中的复杂、非线性和多尺度时间模式。现有的方法在面对这些挑战时常常失效。鉴于此，本研究提出了一种基于分解的混合框架，将季节趋势分解使用局部回归平滑（STL）与三种互补预测模型相结合。", "innovation": "该研究提出了一种将STL分解与三种互补预测模型（LSTM、ARIMA和XGBoost）相结合的混合框架。具体来说，STL分解将原始时间序列分解为趋势、季节性和残差分量，然后分别使用LSTM网络、ARIMA模型和XGBoost算法来预测长短期趋势、季节性周期性和非线性残差波动。最终通过综合子模型的预测结果进行预测。这种方法提高了预测的准确性、解释性和鲁棒性。", "conclusion": "通过对纽约市某交叉口在2015年11月至12月的998条交通流记录进行实验，结果表明LSTM ARIMA XGBoost混合模型在MAE、RMSE和R平方度量上显著优于独立的LSTM、ARIMA和XGBoost模型。STL分解策略能够有效分离时间特性，从而使每个模型能够专业化，从而提高预测精度、可解释性和鲁棒性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23667", "html_url": "https://arxiv.org/abs/2510.23667", "title": "Optimize Any Topology: 一种形状和分辨率无关的结构拓扑优化基础模型", "title_en": "Optimize Any Topology: A Foundation Model for Shape- and Resolution-Free Structural Topology Optimization", "authors": "Amin Heyrani Nobari,Lyle Regenwetter,Cyril Picard,Ligong Han,Faez Ahmed", "background": "结构拓扑优化（TO）在工程设计中至关重要，但因其复杂的物理现象和严格的约束条件而计算密集。现有的深度学习方法仅限于固定的正方形网格、少量手工编码的边界条件和事后优化，这限制了它们的广泛应用。", "innovation": "我们提出了Optimize Any Topology (OAT)，这是一种基模型框架，可以直接预测任意长宽比、分辨率、体积分数、载荷和约束条件下的最小介效布局。OAT 结合了一个分辨率和形状无关的自编码器、一个隐式神经场解码器以及在大规模数据集 OpenTO 上训练的条件潜在扩散模型。OAT 在四个公开基准和两个复杂未见测试中，将平均介效降低了最多 90%，在单块 GPU 下实现了从 64×64 到 256×256 的分辨率和最高 10:1 的长宽比的亚一秒推理。", "conclusion": "这些结果确立了OAT作为一种通用、快速且不受分辨率限制的物理感知拓扑优化框架的地位，并提供了一个大型数据集，以促进生成建模在逆向设计中的进一步研究。代码和数据可以在该网址获取。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23671", "html_url": "https://arxiv.org/abs/2510.23671", "title": "MoE模型的稀疏性和叠加", "title_en": "Sparsity and Superposition in Mixture of Experts", "authors": "Marmik Chaudhari,Jeremi Nuer,Rome Thorstenson", "background": "混合专家（MoE）模型已成为大规模语言模型扩展的关键工具，但它们与密集网络在机制上的差异尚未完全理解。以往研究表明，密集模型利用叠加机制在维度上表示更多特征，叠加与特征稀疏性和重要性相关。然而，MoE模型无法通过相同的机制来解释。研究发现，特征稀疏性和重要性不会导致阶段突变，而是网络稀疏性（激活专家与总专家的比例）更好地描述了MoE模型。研究开发了新的叠加测量指标，发现具有更大网络稀疏性的模型表现出更强的单义性。", "innovation": "提出了基于单一特征表示的新专家专业化定义，而非传统负载均衡。研究表明，适当初始化后，专家自然而然地围绕一致的特征组合进行组织。结果表明，MoE模型中的网络稀疏性可能有助于提高模型的可解释性而不牺牲性能，挑战了通常认为可解释性和能力是根本冲突的观点。", "conclusion": "研究发现，MoE模型中的网络稀疏性有助于提高模型的可解释性而不牺牲性能，传统上认为可解释性和能力是根本冲突的观点可能被挑战。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23659", "html_url": "https://arxiv.org/abs/2510.23659", "title": "图像分类中的量子机器学习：基于残差网络的量子支持向量机混合模型", "title_en": "Quantum Machine Learning for Image Classification: A Hybrid Model of Residual Network with Quantum Support Vector Machine", "authors": "Md. Farhan Shahriyar,Gazi Tanbhir,Abdullah Md Raihan Chy", "background": "近期，量子机器学习（QML）与经典深度学习方法的结合受到了广泛关注，因为计算技术对于提高图像分类任务的性能至关重要。经典和深度学习模型常常在处理高维度和复杂数据集时遇到困难，因此需要像量子计算这样的先进技术来提高分类效率。通过使用ResNet-50来提取马铃薯疾病RGB图像的深度特征表示，并通过主成分分析（PCA）进行降维，再通过量子支持向量机（QSVM）模型进行分类，实现了一种将经典和量子计算相结合的方法，用于改进马铃薯疾病检测的分类效率及性能评估。", "innovation": "该研究提出了一种利用ResNet-50进行特征提取和量子支持向量机进行分类的混合方法。此方法利用量子特征图（如ZZ, Z, Pauli-X）将经典数据转换为量子态。通过与经典的SVM和RF模型在五折分层交叉验证中的比较，证实了基于Z特征图的量子支持向量机优于传统模型，实现了99.23%的准确率，超过了SVM和RF模型。这表明结合量子计算在图像分类中的优势，并提供了一种通过混合量子经典建模进行疾病检测的潜在解决方案。", "conclusion": "该研究展示了将量子计算整合入图像分类的优势，并为马铃薯疾病检测提供了一种潜在的解决方案。研究结果证明，基于Z特征图的量子支持向量机模型在马铃薯疾病分类中表现出色，并优于传统的机器学习算法，验证了量子技术在处理复杂数据集中的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23660", "html_url": "https://arxiv.org/abs/2510.23660", "title": "Quanvolutional Neural Networks for Pneumonia Detection: An Efficient Quantum-Assisted Feature Extraction Paradigm", "title_en": "Quanvolutional Neural Networks for Pneumonia Detection: An Efficient Quantum-Assisted Feature Extraction Paradigm", "authors": "Gazi Tanbhir,Md. Farhan Shahriyar,Abdullah Md Raihan Chy", "background": "肺部感染（肺炎）构成了全球健康的重大挑战，需要准确且及时的诊断。尽管卷积神经网络（CNN）在肺炎检测的医学图像分析中展现了潜力，但它们通常面临高计算成本、特征表示限制和小数据集泛化能力差的问题。", "innovation": "本文介绍了利用参数化量子电路（PQC）和旋转Y门对2x2图像块进行处理，并通过纠缠层生成非经典特征表示的量子卷积神经网络（QNN）模型。量子提取出的特征随后被输入到经典神经网络中进行分类。实验结果显示，所提出的QNN模型在验证集上的准确率达到83.33%，优于传统CNN的73.33%，这表明QNN在医疗影像分析中的收敛性和样本效率更高，尤其是在少量标注数据的情况下。这项研究为将量子计算集成到基于深度学习的医疗诊断系统中奠定了基础，提供了一种计算高效的替代传统方法的方案。", "conclusion": "本文的主要结论是，QNN模型在肺炎检测中表现出更高的验证准确率和更强的收敛性，这证明了量子计算在医疗影像分析中的潜力，特别是在数据标注不足的情况下。未来的研究可以进一步探索如何优化QNN模型以提高性能并扩大其应用范围。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23663", "html_url": "https://arxiv.org/abs/2510.23663", "title": "AI驱动的碳监测：基于变压器重建加拿大禽区大气中二氧化碳", "title_en": "AI-Driven Carbon Monitoring: Transformer-Based Reconstruction of Atmospheric CO2 in Canadian Poultry Regions", "authors": "Padmanabhan Jagannathan Prajesh,Kaliaperumal Ragunath,Miriam Gordon,Bruce Rathgeber,Suresh Neethirajan", "background": "准确地绘制农田上空柱平均CO2（XCO2）对于指导减排策略至关重要。本研究采用时空视觉变换器与小波（ST-ViWT）框架，利用OCO-2数据在加拿大南部重建了连续且带有不确定性度量的XCO2场，特别是集中在禽类密集区域。研究模型结合了波尔兹时间频率表示与气象学、植被指数、地形和土地覆盖的变压器注意力机制。该模型在2024年OCO-2数据上的表现尤为突出，达到了R2 = 0.984和RMSE = 0.468 ppm，并且在92.3%的情况下，填补后的预测值在±1 ppm范围内。独立验证显示了其稳健的泛化能力（偏差 = -0.14 ppm；相关系数r = 0.928），并准确再现了秋季的大规模二氧化碳吸收过程。通过分析14个禽区发现，设施密度与XCO2之间存在中度正相关（r = 0.43），高密度区域的季节振幅更大，夏季变异性更高。", "innovation": "本研究提出了一种时空视觉变换器与小波（ST-ViWT）框架，通过融合波尔兹时间频率表示与气象学、植被指数、地形和土地覆盖的变压器注意力机制，实现了对加拿大南部Ocotillo区域（强调禽类密集区）的连续、不确定性度量的XCO2场的重建。该模型在2024年OCO-2数据上表现卓越，R2达到了0.984，RMSE为0.468 ppm，填补后的预测92.3%落在±1 ppm范围内，并且具有显式的不确定性表征。它填补了观测稀疏带来的覆盖不足，支持了卫星观测与国家排放清单的整合，有助于提高精准养殖平台的排放基准，并验证特定干预措施的有效性。", "conclusion": "基于变压器的地球观测为实现碳账目的可扩展性、透明性和空间明确性提供了支持，有助于识别热点区域优先级，以及进行政策 relevant 的减排评估。ST-ViWT框架能够提供无缝的0.25度C02表面，显现具体不确定性，即便在稀疏观测情况下，也可以实现全年覆盖。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23672", "html_url": "https://arxiv.org/abs/2510.23672", "title": "DBLoss: 基于分解的时序预测损失函数", "title_en": "DBLoss: Decomposition-based Loss Function for Time Series Forecasting", "authors": "Xiangfei Qiu,Xingjian Wu,Hanyin Cheng,Xvyuan Liu,Chenjuan Guo,Jilin Hu,Bin Yang", "background": "时间序列预测在经济学、交通、能源和AIOps等领域具有重要意义，准确的预测有助于做出明智的决策。然而，现有的均方误差(MSE)损失函数有时无法准确捕捉预测区间内的季节性和趋势性，即使在前向传播过程中使用分解模块分别建模季节性和趋势性。为了应对这些挑战，我们提出了一种简单有效的基于分解的损失函数，称为DBLoss。这种方法利用指数移动平均将时间序列分解为预测区间内的季节性和趋势性成分，然后分别计算每个成分的损失，最后进行加权。作为一个通用的损失函数，DBLoss可以与任何深度学习预测模型结合使用。广泛的实验表明，DBLoss显著提高了状态最先进模型在各种现实世界数据集上的性能，为时序预测损失函数的设计提供了新的视角。", "innovation": "提出了一种基于分解的损失函数DBLoss，利用指数移动平均将时间序列分解为季节性和趋势性成分，分别计算损失后再加权，该方法可以与任何深度学习模型结合使用，显著提高了预测性能和新颖性。", "conclusion": "DBLoss在不同的现实世界数据集上显著改善了最新的时间序列预测模型的性能，提供了时间序列损失函数设计的新视角。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23685", "html_url": "https://arxiv.org/abs/2510.23685", "title": "平行的BiLSTM-Transformer网络用于混沌动态预测", "title_en": "Parallel BiLSTM-Transformer networks for forecasting chaotic dynamics", "authors": "Junwen Ma,Mingyu Ge,Yisen Wang,Yong Zhang,Weicheng Fu", "background": "混沌系统的非线性性质导致它们对初始条件极其敏感，并表现出极其复杂的动态行为，这为准确预测其演化带来了根本性挑战。传统方法无法同时捕捉混沌时间序列的局部特征和全球依赖关系，限制了预测效果。", "innovation": "为克服这一限制，研究提出了一种结合Transformer和双向长短期记忆(BiLSTM)网络的并行预测框架。该混合模型采用双分支架构，Transformer分支主要捕捉长距离依赖关系，而BiLSTM分支专注于提取局部时间特征。两个分支生成的互补表示在专门的特征融合层中融合，以增强预测准确性。这种框架在洛伦兹系统代表任务中的性能评估中表现优越，包括自主演化预测和不完观测变量的推断。", "conclusion": "研究结果表明，提出的混合框架比单一分支结构在任务中表现更优，显示出其在混沌系统预测中的稳健性和有效性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23693", "html_url": "https://arxiv.org/abs/2510.23693", "title": "关于机器学习的社会影响", "title_en": "On the Societal Impact of Machine Learning", "authors": "Joachim Baumann", "background": "机器学习越来越多地被用于做出影响我们生活的重大决策和建议。然而，由于这些数据驱动的系统在开发时常常没有明确考虑到公平性，它们存在产生歧视性影响的风险。", "innovation": "本论文的贡献在于允许更适当的测量机器学习系统的公平性、系统地分解机器学习系统以预见偏差动态，以及有效减少算法歧视的同时保持系统实用性。", "conclusion": "随着包括生成型人工智能在内的机器学习系统越来越多地融入社会，本文指出了存在的挑战和未来的研究方向。本研究为确保机器学习的社会影响与更广泛的社会价值相一致提供了一个基础。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23681", "html_url": "https://arxiv.org/abs/2510.23681", "title": "基于信息论的贝叶斯优化和主动学习的启发式初始化", "title_en": "Informed Initialization for Bayesian Optimization and Active Learning", "authors": "Carl Hvarfner,David Eriksson,Eytan Bakshy,Max Balandat", "background": "贝叶斯优化是一种用于优化昂贵的黑箱函数的方法，依赖于概率代理模型，如高斯过程。在只能以少量批次评估点的情况下，代理模型的品质对优化性能至关重要，尤其是在few-shot设置中。在这些情况下，初始化对代理模型的预测品质和随后的优化有重要影响。但由于实践者通常依赖于（准）随机设计来覆盖输入空间，这种做法忽视了两个重要因素：（a）空间填充设计可能不会降低预测不确定性；（b）初始化期间的高效超参数学习对于高质量预测至关重要，这可能与空间填充设计相冲突。", "innovation": "提出了一种新颖的获取策略——Hyperparameter-Informed Predictive Exploration (HIPE)，它结合信息论原则，平衡了预测不确定性减少与超参数学习。在高斯过程设置中推导了HIPE的闭式表达式，并通过广泛的主动学习和few-shot贝叶斯优化实验展示了其有效性。结果表明，HIPE在预测准确性、超参数识别和后续优化性能方面优于标准初始化策略，尤其在大批次、few-shot设置中，这与许多实际贝叶斯优化应用相关", "conclusion": "HIPE在预测准确性、超参数识别和后续优化性能方面表现出色，特别是在大型批次和few-shot设置中优于标准初始化策略，适用于许多实际的贝叶斯优化应用。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23682", "html_url": "https://arxiv.org/abs/2510.23682", "title": "超越提示工程：神经-符号-因果架构用于稳健的多目标AI代理", "title_en": "Beyond Prompt Engineering: Neuro-Symbolic-Causal Architecture for Robust Multi-Objective AI Agents", "authors": "Gokturk Aytug Akarlar", "background": "大语言模型作为自主决策代理展现出潜力，但它们在高风险领域的部署仍然充满风险。如果没有架构上的安全保障，大语言模型代理会表现出极端的脆弱性：相同的功能在不同的提示框架下会产生截然不同的结果。本文分析了在这种背景下，现有架构面临的问题以及如何通过设计来提高代理的可靠性。", "innovation": "本文提出了Chimera，一种神经-符号-因果架构，结合了大语言模型策略师、形式化验证的符号约束引擎和因果推理模块进行反事实推理。Chimera在现实的电子商务环境中针对价格弹性、信任动态和季节性需求进行了52周的模拟，并且在组织偏向于最大化数量或利润的情况下，证明了在保持品牌信任的前提下，提供了更高的回报并且具有提示无关的稳健性。此外，通过形式化验证法证明了零约束违反。这表明架构设计比提示工程更能决定自主代理在实际环境中的可靠性。", "conclusion": "Chimera架构在不同场景下持续产生最高回报，同时提升品牌信任度，并通过形式化验证证明其安全性。研究结果表明，架构设计而非仅依赖提示工程在生产环境中决定了自主代理的可靠性。作者提供了开源实现和交互演示以保证结果的可复现性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23751", "html_url": "https://arxiv.org/abs/2510.23751", "title": "通过具有保证的表示学习消除奖励模型中的偏见", "title_en": "Debiasing Reward Models by Representation Learning with Guarantees", "authors": "Ignavier Ng,Patrick Blöbaum,Siddharth Bhandari,Kun Zhang,Shiva Kasiviswanathan", "background": "近年来，强化学习等人生成的反馈已被广泛应用于通过学习和利用奖励模型来使大型语言模型与人类偏好保持一致。但在实践中，这些模型往往利用了错误的相关性，比如响应长度、偏见、奉承等，这种问题引起了人们的广泛关注。", "innovation": "本文提出了一个原则性的框架，该框架可以在不受错误相关性影响的同时，保留反映预期偏好的真正因素。该框架首先提供了一个数据生成过程的表述，假设观察到的数据（例如文本）由真正因素和错误因素的潜在变量共同生成。研究发现，非错误因素能从数据中理论上被识别出来，即使不存在错误因素的替代品。这一发现启发了一种实用的方法，即利用变分推断恢复这些变量，并利用这些变量来训练奖励模型。实验表明，该方法有效地缓解了错误相关性问题，生成了更稳健的奖励模型，", "conclusion": "本文介绍了一种利用表示学习来消除奖励模型偏见的具有保证的原则性框架。通过变分推断，有效地减少了由错误相关性引起的偏见问题，得到更加稳健的奖励模型。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23727", "html_url": "https://arxiv.org/abs/2510.23727", "title": "MUStReason: 视频-LMs中多模态语境中推理解释能力诊断的基准", "title_en": "MUStReason: A Benchmark for Diagnosing Pragmatic Reasoning in Video-LMs for Multimodal Sarcasm Detection", "authors": "Anisha Saha,Varsha Suresh,Timothy Hospedales,Vera Demberg", "background": "讽刺是一种特殊类型的 Irony，涉及到理解说话者的意思和实际说的话之间的区别。讽刺的检测不仅依赖于语句的字面内容，还依赖于非言语线索，如说话者的声音语调、面部表情和对话的上下文。然而，当前的多模态模型在处理这类需要跨模态识别相关线索并进行语用推理的复杂任务（如讽刺检测）时表现出挑战。为了诊断这些局限性，本文通过引入 MUStReason 来解决这个问题，它是一个包含模态特定相关线索及潜在推理步骤的诊断基准，用于识别讽刺意图。", "innovation": "引入 MUStReason 作为视频-LMs 中多模态讽刺检测中语用推理能力诊断的基准。MUStReason 不仅用于测试视频-LMs 中讽刺分类的性能，还通过将其视为感知和推理的分离问题来进行定量和定性分析，提出了 PragCoT 框架，该框架引导视频-LMs 将重点放在隐含的意图上而不是字面意义，这是检测讽刺的核心能力。", "conclusion": "MUStReason 通过拆分问题为感知与推理来量化和定性评估生成的推理过程，使视频-LMs 能够关注隐含意图，而不是字面意义，从而有效地检测讽刺意图。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23756", "html_url": "https://arxiv.org/abs/2510.23756", "title": "通过增量概念形成解释对灾难性遗忘的鲁棒性", "title_en": "Explaining Robustness to Catastrophic Forgetting Through Incremental Concept Formation", "authors": "Nicki Barari,Edward Kim,Christopher MacLellan", "background": "灾难性遗忘是持续学习中的一个核心挑战，在这种情况下，模型需要随着时间的推移不断集成新知识而不忘记之前学过的内容。以往研究中，我们引入了Cobweb/4V模型，这一层次的概念生成模型在视觉领域的灾难性遗忘方面表现出鲁棒性。", "innovation": "本文通过Cobweb/4V模型对增加这一稳定性的因素进行了探讨：（1）自适应结构重组促进知识保留，（2）稀疏和选择性的更新减少干扰，（3）基于信息论的学习过程利用充分统计量可能优于基于梯度的反向传播。使用CobwebNN这种神经实现框架进行比较实验，结果表明自适应重组提高了学习的灵活性，稀疏更新有助于减轻干扰，基于信息论的学习过程可以保存先前知识无需重新访问。这些发现揭示了减轻灾难性遗忘的机制，强调了基于概念、信息论方法在构建稳定和自适应的持续学习系统方面的潜力。", "conclusion": "实验结果表明自适应重组增强了学习的灵活性，稀疏的更新有助于减少干扰，信息论的学习过程能够保护先验知识而不重新访问历史数据。这些发现为减轻灾难性遗忘提供了见解，突显了概念基础、信息论方法在构建稳定和自适应的持续学习系统方面的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23786", "html_url": "https://arxiv.org/abs/2510.23786", "title": "Relaxed Sequence Sampling for Diverse Protein Design", "title_en": "Relaxed Sequence Sampling for Diverse Protein Design", "authors": "Joohwan Ko,Aristofanis Rontogiannis,Yih-En Andrew Ban,Axel Elaldi,Nicholas Franklin", "background": "使用结构预测模型（如AlphaFold2）进行蛋白质设计已取得显著成果，但现有方法如松弛序列优化（RSO）依赖于单一路径梯度下降并忽略了序列空间约束，这限制了设计的多样性和设计能力。", "innovation": "引入了Relaxed Sequence Sampling（RSS），这是一种结合结构和进化信息的马尔可夫链蒙特卡洛（MCMC）框架。RSS在连续的对数空间中运行，并结合了梯度引导的探索与基于蛋白质语言模型的跳跃。其能量函数将AlphaFold2获得的结构目标与ESM2获得的序列先验相结合，平衡了准确性和生物学可行性。在一项虚拟蛋白质结合设计任务中，RSS相比RSO基线生成了5倍更多的设计结构，且有2-3倍更高的结构多样性，同时计算成本相同。", "conclusion": "这些结果强调RSS是一种有原则的方法，可以有效探索蛋白质设计的景观。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23794", "html_url": "https://arxiv.org/abs/2510.23794", "title": "揭示可学习扰动集合预报模型在热带气旋预测中的潜力", "title_en": "Revealing the Potential of Learnable Perturbation Ensemble Forecast Model for Tropical Cyclone Prediction", "authors": "Jun Liu,Tao Zhou,Jiarui Li,Xiaohui Zhong,Peng Zhang,Jie Feng,Lei Chen,Hao Li", "background": "热带气旋（TCs）是高度破坏性和难以预测的天气系统。集合预报有助于量化这些不确定性，但传统的系统受限于高昂的计算成本和有限的能力来充分代表大气非线性。ECMWF-ENS等现有方法存在局限性，FuXi-ENS引入了一种学习可变性方案来生成集合预报，代表了一种基于AI的新预报范式。", "innovation": "FuXi-ENS通过引入学习可变性方案，改善了TC的相关物理变量预测，其轨迹预报更准确，且能更准确捕捉大型环流模式，显示出更好的预报能力。但是强度预报仍有改进空间。", "conclusion": "FuXi-ENS模型更加有效地捕获大气环流，特别是在水分湍流能量的分布上更为集中。相对于ECMWF-ENS，FuXi-ENS提供了更准确的TC预测，显示出AI在集合预报中的巨大潜力，能够提高极端天气事件预报技能，服务于社会需求。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23804", "html_url": "https://arxiv.org/abs/2510.23804", "title": "简单旋转如何影响Adam的隐性偏置？", "title_en": "How do simple rotations affect the implicit bias of Adam?", "authors": "Adela DePavia,Vasileios Charisopoulos,Rebecca Willett", "background": "自适应梯度方法如Adam和Adagrad在机器学习中广泛使用，但由于其对学习模型泛化能力的影响（相较于梯度下降等方法）尚未完全理解，特别是在二分类问题中，Adam表现出一种称为“丰富性偏置”的特点，可能使其能学习到更接近贝叶斯最优决策边界的非线性决策边界。然而，Adam所使用的坐标相关预标定方案使其整体方法对特征空间的正交变换极度敏感。", "innovation": "该研究展示了这一敏感性如何导致Adam的竞争优势逆转：即使是微小的数据分布旋转也可能让Adam失去其“丰富性偏置”，进而收敛到一个偏离贝叶斯最优决策边界的更远的线性决策边界，而这一结果则比梯度下降所学到的要差。为此，研究提出了一种最近提出的重参数化方法，通过对方差优化目标进行正交变换来赋予任何一阶方法对数据旋转的不变性，并通过实验验证了该方法恢复了Adam对丰富决策边界的偏好。", "conclusion": "通过对方差优化目标进行正交变换的重参数化方法，可以赋予一阶优化方法对数据旋转的不变性，从而在一定程度上恢复了Adam对丰富决策边界的偏好。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23818", "html_url": "https://arxiv.org/abs/2510.23818", "title": "ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning", "title_en": "ScaLoRA: Optimally Scaled Low-Rank Adaptation for Efficient High-Rank Fine-Tuning", "authors": "Yilang Zhang,Xiaodong Yang,Yiwei Cai,Georgios B. Giannakis", "background": "随着大规模语言模型（LLMs）的规模不断扩大，特定任务的微调所需计算资源成为了一个主要瓶颈。低秩适配（LoRA）通过将权重更新限制在低维子空间来有效削减成本，但这种限制可能会降低效果并减慢收敛速度。", "innovation": "这项贡献通过逐步累积连续低秩增量的高秩权重更新来克服这些限制。具体而言，每次更新时都识别出最优的低秩矩阵，以最小化损失函数并接近完全微调。为实现高效的优化流程，这种最优选择是通过适当缩放原始低秩矩阵的列来形成的。严格的性能保证表明，可以解析地找到最优缩放。", "conclusion": "广泛的数值测试表明，ScaLoRA在包括自然语言理解、常识推理和数学问题解决等多种任务上相对于最先进的LoRA变体在性能和快速收敛性方面都表现出一致的优势。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23817", "html_url": "https://arxiv.org/abs/2510.23817", "title": "结合SHAP和因果分析实现工业过程可解释的故障检测", "title_en": "Combining SHAP and Causal Analysis for Interpretable Fault Detection in Industrial Processes", "authors": "Pedro Cortes dos Santos,Matheus Becali Rocha,Renato A Krohling", "background": "工业过程会产生复杂的数据，这些数据对故障检测系统构成挑战，尽管使用了先进的机器学习技术，通常仍会产生透明度低或效果欠佳的结果。此研究采用了Tennessee Eastman过程作为基准案例，该案例以其复杂的动力学而闻名，旨在开发一种创新的故障检测框架。最初尝试使用标准模型时，性能和解释性方面均表现出局限，推动了转向易处理的途径。通过应用SHAP（SHapley Additive exPlanations），将问题转化为更易于管理和透明的形式，确定最能驱动故障预测的关键过程特征。这种复杂性的减少使得可以通过由多种算法生成的有向无环图进行因果分析，从而揭示故障传播的潜在机制。因果结构与SHAP发现高度一致，持续强调冷却和分离系统等关键工艺要素在故障发展中起到关键作用。这些方法不仅提高了检测准确性，还为操作员提供了关于故障根源的清晰、可操作的见解。", "innovation": "该研究利用SHAP（SHapley Additive exPlanations）将问题转化为更易于管理和透明的形式，并通过多种算法生成的有向无环图进行因果分析，揭示故障传播的潜在机制。这些方法不仅提高了检测准确性，还为操作员提供了关于故障根源的清晰、可操作的见解，实现了预测能力和因果理解的结合。这提供了一种强大的工具来监控复杂制造环境，并为工业系统的可解释故障检测铺平了道路。", "conclusion": "该研究提出了一种结合SHAP和因果分析的双管齐下的方法，能够同时提升工业过程故障检测的预测能力和解释性。这种方法能够有效监控复杂制造环境，并为未来的智能、可解释故障检测提供理论和技术支持。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23866", "html_url": "https://arxiv.org/abs/2510.23866", "title": "基于PDE的潜在扩散模型用于2米温度降尺度", "title_en": "A PDE-Informed Latent Diffusion Model for 2-m Temperature Downscaling", "authors": "Paul Rosu,Muchang Bahng,Erick Jiang,Rico Zhu,Vahid Tarokh", "background": "本文介绍了一种针对大气数据动态下尺度的物理条件下的潜在扩散模型，特别关注于高分辨率2米温度场的重建。该模型基于现有的扩散架构，并采用残差形式与参考UNet相比，通过计算全分辨率的空间潜在表示来获取PDE损失项，这使得通过有限差分近似实现的有效对流-扩散平衡进行物理一致性处理成为可能。实验证明传统的扩散训练已经产生了较低的PDE残差，本文进一步探索了使用这种附加损失项进行微调如何进一步正则化模型，并增加生成场的物理合理性。", "innovation": "本文创新点在于提出了一种基于PDE（偏微分方程）的潜在扩散模型，通过细分为对流-扩散平衡的有限差分近似计算PDE损失项，嵌入训练目标中，使得模型生成的高分辨率2米温度场更加符合物理约束。这种方法不仅增强了模型的物理合理性和预测精度，还通过额外的PDE损失项提高了模型的鲁棒性。", "conclusion": "本文通过在扩散模型中嵌入基于PDE的损失项，改进了2米温度场的降尺度过程。研究表明，该模型不仅能够生成具有良好物理一致性的高分辨率温度场，还能够通过额外的PDE损失项进行进一步的微调，增强模型的正则化，提升预测的物理合理性。整个模型代码已经在Github上开源，供未来的研究和开发使用。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23906", "html_url": "https://arxiv.org/abs/2510.23906", "title": "子系统中深度网络的组干预在因果发现中的应用", "title_en": "Group Interventions on Deep Networks for Causal Discovery in Subsystems", "authors": "Wasim Ahmad,Maha Shadaydeh,Joachim Denzler", "background": "因果关系的发现能够揭示变量之间的复杂关系，增强预测、决策和对实际系统洞见。然而，现有方法主要集中在成对因果关系上，忽视了组变量之间的相互作用，即子系统及其集体因果影响。现有的大多数方法没有考虑这种群体间的交互作用，阻碍了深入理解复杂的因果结构。", "innovation": "本文提出了gCDMI方法，这是一种创新的多组因果发现方法，利用训练好的深度神经网络进行组级干预，并采用模型不变性测试来推断因果关系。该方法包括三个关键步骤：首先，利用深度学习共同建模所有时间序列组的结构关系；其次，针对训练模型进行组级干预；最后，进行模型不变性测试以确定组间变量因果联系的存在。我们的方法在模拟数据集和真实世界数据集（如大脑网络和气候生态系统）上进行了验证，证明了其在识别组级因果关系方面的优越性能，相比现有方法表现更佳。", "conclusion": "我们的结果表明，在深度学习模型中应用组级干预并结合不变性测试，可以有效地揭示复杂的因果结构，为神经科学和气候科学等领域提供了宝贵见解。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23868", "html_url": "https://arxiv.org/abs/2510.23868", "title": "GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA", "title_en": "GIFT: Group-relative Implicit Fine Tuning Integrates GRPO with DPO and UNA", "authors": "Zhichao Wang", "background": "当前的强化学习框架，如PPO和GRPO，主要通过直接最大化累积奖励来优化语言模型（LLMs）。然而，这些方法在处理隐式奖励模型和直接奖励模型之间的差异方面存在局限性。论文指出，如何有效利用隐式奖励模型是一个未解决的问题，因为直接最大化复杂的奖励函数通常是不可行的。传统的离线方法如DPO和UNA在这方面有一定的局限性，因为在保持探索能力的同时难以有效利用隐式奖励。", "innovation": "作者提出了一个名为GIFT的新颖强化学习框架，旨在通过最小化隐式和显式奖励模型之间的差异来进行语言模型的对齐。GIFT结合了在线多响应生成和规范化（来自GRPO）、隐式奖励的框架（来自DPO）以及隐式-显式奖励对齐原则（来自UNA）。通过同时规范化隐式和显式奖励，GIFT消除了使用隐式奖励时的一个棘手项。这种规范化将复杂的奖励最大化目标转化成了一个简单的均方误差损失函数，从非凸优化问题转为了一个凸的、稳定且可以解析求导的格式。与离线方法相比，GIFT是在线的，从而保留了探索能力；与GRPO相比，GIFT所需超参数更少，收敛速度更快，泛化性能更好，且在显著减少训练过拟合的情况下表现稳健。实验结果表明，GIFT在数学基准测试上的推理和对齐性能优于其他方法，同时保持了计算效率。", "conclusion": "GIFT通过结合GRPO、DPO和UNA的核心思想，提供了一种新的语言模型对齐方法。通过有效的隐式和显式奖励规范化，GIFT不仅解决了奖励差距问题，还提高了模型的泛化能力，并在数学基准测试中展示了优越的推理和对齐性能。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23879", "html_url": "https://arxiv.org/abs/2510.23879", "title": "基于人工智能的电动巴士预测性维护", "title_en": "Artificial Intelligence Based Predictive Maintenance for Electric Buses", "authors": "Ayse Irmak Ercevik(TOBB University of Economics and Technology, Ankara, Turkey),Ahmet Murat Ozbayoglu(TOBB University of Economics and Technology, Ankara, Turkey)", "background": "电动巴士的环境效益需要通过预测性维护（PdM）来优化效率并减少停机时间。然而，由于其复杂的电力传输和电池系统，PdM带来了挑战。传统的基于定期检查的维护方法难以捕捉实时CAN总线数据中的多维度异常情况。为了解决这些问题，该研究使用基于图的特征选择方法来分析电动巴士CAN总线参数之间的关系，并研究使用人工智能技术预测特定报警性能的效果。研究中收集了两年的原始数据，经预处理以确保数据质量和一致性。机器学习模型（包括SVM、随机森林和XGBoost）使用网格搜索和随机搜索进行优化，数据通过SMOTEEN进行平衡，并使用二元搜索进行降采样，以确保模型的解释性。", "innovation": "研究开发了一种基于图的特征选择工具，结合了统计筛选（皮尔逊相关系数、卡方关联性V、ANOVA F检验）和基于优化的社区检测算法（InfoMap、Leiden、Louvain、快速贪婪算法）。此外，通过使用SMOTEEN进行数据平衡和二元搜索降采样优化了机器学习模型，并通过LIME来识别影响预测的关键特征，从而实现模型的解释性。利用人工智能技术优化了机器学习模型的性能，从而增强了PdM策略的有效性，支持符合工业4.0原则的主动维护策略。", "conclusion": "研究结果表明，所开发的系统能够在电动巴士维护中有效预测车辆报警，提高特征解释性，并支持针对工业4.0原则制定的主动维护策略。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23901", "html_url": "https://arxiv.org/abs/2510.23901", "title": "RS-ORT：一种用于最优回归树的缩减空间分支定界算法", "title_en": "RS-ORT: A Reduced-Space Branch-and-Bound Algorithm for Optimal Regression Trees", "authors": "Cristobal Heredia,Pedro Chumpitaz-Flores,Kaixun Hua", "background": "现有基于混合整数规划（MIP）的回归任务决策树学习方法要么局限于二元特征，要么在处理大规模连续数据时变得不可计算。直接二元化连续特征会牺牲全局最优性和导致不必要的深层树。", "innovation": "提出了Reduced-Space Optimal Regression Trees（RS-ORT）——一种专有的分支定界（BB）算法，仅在树结构变量上进行分支。此设计保证算法收敛且与样本数量无关。利用模型结构引入了封闭形式叶子预测、经验阈值离散化和精确深度1子树解析等紧化技术，结合可分解的上限和下限估算策略，加速训练。BB节点分解允许并行执行，即使在数百万数量级的大型数据集上也有助于缓解计算不可行性。在包含二元和连续特征的多个回归基准测试上，RS-ORT在训练和测试性能上均优于现有的先进方法。", "conclusion": "RS-ORT在包含多达200万连续特征样本的数据集上，能够在四个小时内获得有保证的训练性能，使用更简单的树结构并具有更好的泛化能力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23914", "html_url": "https://arxiv.org/abs/2510.23914", "title": "启发式统一分化奖励和平均奖励MDP框架", "title_en": "Geometry-Inspired Unified Framework for Discounted and Average Reward MDPs", "authors": "Arsenii Mustafin,Xinyi Sheng,Dominik Baumann", "background": "目前对于马尔可夫决策过程（MDPs）的理论分析通常分为两类——平均回报案例和折扣因子回报案例——尽管两类存在相似性，但通常分别进行分析。而本文则将针对折扣回报过程提出的一种几何解释扩展到平均回报案例中，使得两类分析能够统一起来。这为将已知针对折扣回报案例的显著结果推广至平均回报案例提供了可能，特别是在存在唯一且遍历最优策略的情况下，价值迭代算法可以达到几何收敛的速度。", "innovation": "通过将针对折扣回报MDPs（MDPs with discounted rewards）的几何解释扩展到平均回报MDPs（MDPs with average rewards），实现两个案例的统一分析。此扩展使得平均回报案例中的主要结果——即在存在唯一且遍历最优策略的情况下，价值迭代算法可以达到几何收敛——能够适用于折扣回报案例，并将这一结果推广到平均回报案例。", "conclusion": "本文通过将两种类型的MDPs的分析统一起来，不仅提供了一种新的理论视角，还扩展了适用于平均回报MDPs的价值迭代算法的适用条件，使之能够达到几何收敛的状态。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23912", "html_url": "https://arxiv.org/abs/2510.23912", "title": "键和值权重可能是你所需要的：解码器_transformers中查询、键、值权重三元组的必要性探讨", "title_en": "Key and Value Weights Are Probably All You Need: On the Necessity of the Query, Key, Value weight Triplet in Decoder-Only Transformers", "authors": "Marko Karbevski,Antonij Mijoski", "background": "当前最先进的LLM中，查询、键、值权重三元组是注意力机制的基本构建块。本文研究了这一三元组是否可以简化，通过理论分析，在简化假设下，证明了查询权重是多余的，从而减少模型的非嵌入/语言头参数量超过8%。", "innovation": "本文通过理论证明，在简化假设下单查询权重是冗余的，证明了可以通过减少查询权重来简化模型，使简化后的模型在训练从零开始的复杂度完整的GPT-3小型模型（包括层归一化、跳过连接和权重衰减）时，验证损失与标准基准相当，从而验证了理论的可行性，进一步推动了对按规模查询权重冗余性的研究。", "conclusion": "本文研究发现，查询权重可能是冗余的，展示了通过减少查询权重可以简化模型，验证了简化模型在与标准基准相当的复杂度上也能实现良好的效果，为了解决大型语言模型的尺寸和效率问题指明了新的方向。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23940", "html_url": "https://arxiv.org/abs/2510.23940", "title": "使用Echo State网络模拟生物多功能性", "title_en": "Modeling Biological Multifunctionality with Echo State Networks", "authors": "Anastasia-Maria Leventi-Peetz,Jörg-Volker Peetz,Kai Weber,Nikolaos Zacharis", "background": "本文开发了一个三维多组元反应-扩散模型，该模型结合了兴奋系统动力学和扩散过程，并在概念上与FitzHugh-Nagumo模型相似。该模型旨在捕捉生物系统的空间-时间行为，特别是电生理过程。研究者通过数值求解该模型生成了时间序列数据，用以训练和评估Echo State Network (ESN)，并成功地再现了系统的动态行为。结果显示，使用数据驱动、多功能的ESN模型模拟生物动力学既可行又有效。", "innovation": "本文创新性地提出了结合三维多组元反应-扩散模型与Echo State Network (ESN)的方法，用于模拟并分析生物系统的空间-时间行为，特别是电生理过程。这种方法能够捕捉更丰富的生物系统动态特性，并通过成功的模拟验证了其有效性和可行性。", "conclusion": "该研究证明了使用数据驱动的方法和多功能的Echo State Network来模拟生物系统的动态行为是可行且有效的。这种方法为复杂生物过程的实验研究提供了新的视角，并展示了在生物动力学建模领域的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23926", "html_url": "https://arxiv.org/abs/2510.23926", "title": "使用零阶信息改进直线通过估算器", "title_en": "Improving the Straight-Through Estimator with Zeroth-Order Information", "authors": "Ningfeng Yang,Tor M. Aamodt", "background": "研究用量化参数训练神经网络的问题。通过使使用直线通过估算器（STE）计算梯度成为可能来学习低精度量化参数，这可能会带来挑战。虽然STE能够实现反向传播，而反向传播是一种一阶方法，最近的研究已经探索了使用零阶（ZO）梯度下降方法进行微调。注意到STE提供了高质量的有偏梯度，而ZO梯度是无偏的，但代价较高。", "innovation": "提出了一种称为‘引导零阶梯度下降的一阶方法’（FOGZO）的方法，以减少STE的偏差，并减少与ZO方法相比的计算量。实验显示FOGZO在量化感知预训练中提高了质量和训练时间之间的权衡。相对于STE，FOGZO在DeiT Tiny/Small上的准确率提高了1-8%，在ResNet 18/50上的准确率提高了1-2%，在包含多达0.3亿参数的LLaMA模型上的困惑度提高了1-22分点。对于相同的损失，FOGZO在MNIST上的2层MLP中计算量降低了796倍。", "conclusion": "在量化感知预训练中，FOGZO改进了质量和训练时间之间的权衡。具体而言，与STE相比，在相同迭代次数的情况下，FOGZO在DeiT Tiny/Small上的准确率提高了1-8%，在ResNet 18/50上的准确率提高了1-2%，在包含多达0.3亿参数的LLaMA模型上的困惑度提高了1-22分点。对于相同的损失，FOGZO在MNIST上的2层MLP中计算量降低了796倍。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23972", "html_url": "https://arxiv.org/abs/2510.23972", "title": "一种用于扩散模型的有效概率硬件架构", "title_en": "An efficient probabilistic hardware architecture for diffusion-like models", "authors": "Andraž Jelinčič,Owen Lockwood,Akhil Garlapati,Guillaume Verdon,Trevor McCourt", "background": "随着概率AI的普及，专门的随机计算机提案有所增加。尽管这些提案 promise 效率提升，但因依赖于基础限制的建模技术和难以扩展的硬件而未能取得成功。", "innovation": "本文提出了一种基于全晶体管的概率计算架构，能够实现强大的去噪模型并以硬件层面的方式运行这些模型。系统级分析表明，基于我们架构的设备在使用图像基准测试时，与 GPU 的性能相当，但能耗仅为其大约1/10,000。", "conclusion": "我们的架构能够克服现有概率计算方法的局限性，并通过显著降低能耗实现了与GPU相当的性能。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23966", "html_url": "https://arxiv.org/abs/2510.23966", "title": "一种衡量链式思考监控性的实用方法", "title_en": "A Pragmatic Way to Measure Chain-of-Thought Monitorability", "authors": "Scott Emmons,Roland S. Zimmermann,David K. Elson,Rohin Shah", "background": "尽管链式思考监控为AI安全性提供了一种独特的机会，但通过训练实践或模型架构的变化，这种机会可能会被失去。为了帮助保持监控的可行性，本文提出了一个实用的方法来衡量其两个方面：可读性和覆盖度，以确保链式思考的合理性且足够全面。该方法通过自动评分提示使任何具备能力的LLM能够计算现有链式思考的可读性和覆盖度。", "innovation": "本文提出了一种实用的测量链式思考监控性的方法，包括一个自动评分提示，能够评估链式思考的可读性和覆盖度。作者在实际模型上进行了测试，并发现它们具有较高的监控性。该方法为开发者提供了一个工具，可以跟踪设计决策如何影响监控性。", "conclusion": "虽然分享的提示仅是初步版本，仍在发展中，作者希望社区的其他成员也会从中受益。此方法有助于衡量链式思考的默认监控性，但它应该被视为对抗性压力测试的补充，而不是替代品。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23802", "html_url": "https://arxiv.org/abs/2510.23802", "title": "通过稀疏自编码器在音频潜在空间中学习可解释特征", "title_en": "Learning Interpretable Features in Audio Latent Spaces via Sparse Autoencoders", "authors": "Nathan Paek,Yongyi Zang,Qihui Yang,Randal Leistikow", "background": "虽然稀疏自编码器（SAEs）能够从语言模型中提取可解释的特征，但在应用于音频生成时面临着独特挑战：音频的密集特性需要压缩，这会掩盖其语义含义，而且自动特征表征仍然有限。现有的方法不能很好地解析音频生成模型的潜在表示，导致难以从中获得有意义的信息。因此，需要提出一种框架，可以将音频生成模型的潜在表示映射到人类可解释的声学概念，从而揭示音频属性在合成过程中的变化机制。", "innovation": "本文提出了一种通过训练稀疏自编码器（SAEs）来解析音频生成模型的潜在表示，并学习将SAE特征映射到离散的声学属性（音高、幅度和音色）的技术。这种方法不仅能够对AI音乐生成过程进行可控的操纵和分析，还揭示了音高、音色和响度等声学属性在合成过程中的变化。该工作验证了这种方法在连续和离散音频潜在空间中的效果，并分析了最先进的文本到音乐模型（DiffRhythm-VAE），展示了如何通过此方法理解音频生成中的声学属性变化。尽管这项工作仅限于音频域，但该框架可以扩展到对视觉潜在空间生成模型的可解释分析中。", "conclusion": "研究证明了通过稀疏自编码器在音频潜在空间中学习可解释特征的有效性，该方法能够帮助理解音高、音色和响度等声学属性如何在生成过程中演变。这种方法为深入解析和控制音频生成过程提供了新的视角。进一步的研究可以将该框架扩展至其他模态领域，以便研究更广泛的生成模型。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23931", "html_url": "https://arxiv.org/abs/2510.23931", "title": "差分隐私：联邦学习环境中的梯度泄露攻击", "title_en": "Differential Privacy: Gradient Leakage Attacks in Federated Learning Environments", "authors": "Miguel Fernandez-de-Retana,Unai Zulaika,Rubén Sánchez-Corcuera,Aitor Almeida", "background": "联邦学习(FL)允许在无需直接分享敏感数据的情况下，以协作方式训练机器学习模型。但FL仍然容易受到梯度泄露攻击(GLAs)的威胁，这些攻击会从共享的模型更新中泄露私人信息。为了对抗梯度泄露攻击，研究者们调查了差分隐私(DP)机制的效果，特别是DP-SGD与一种基于显式正则化的变体PDP-SGD。研究人员在一个简单的分类任务上评估了在不同隐私水平下训练的各种计算机视觉模型，并分析了从模拟的FL环境中截获的梯度所能重建的私人数据质量。结果显示，虽然DP-SGD在减轻梯度泄露攻击风险方面表现显著，但会对模型实用性造成一定影响；相比之下，PDP-SGD则保持了强大的分类性能，但在实战中对抗重建攻击的效果欠佳。这些发现强调了在分布式学习场景中，除了理论保证外，还应该通过实际测评来评估隐私防护机制的重要性，因为信息泄露可能成为数据安全和隐私保护中不可忽视的关键威胁。", "innovation": "研究通过模拟联邦学习环境，对DiffPrivacy机制（包括DP-SGD和PDP-SGD）在缓解梯度泄露攻击方面进行了评估，揭示了两种机制在保护数据隐私方面各有优劣，为联邦学习中的隐私保护提供了新的视角和选择", "conclusion": "DP-SGD显著降低了梯度泄露攻击的风险，尽管会带来一定程度的模型实用性下降。PDP-SGD保持了分类性能但不具有有效的防御重建攻击的能力。这些结论突显了理论测评与实际环境测评在评价隐私机制时的重要性，特别是在分布式学习环境中，信息泄露可能对数据安全与隐私构成严重威胁。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23810", "html_url": "https://arxiv.org/abs/2510.23810", "title": "带物理信息的多分辨率神经算子", "title_en": "A Physics-informed Multi-resolution Neural Operator", "authors": "Sumanta Roy,Bahador Bahmani,Ioannis G. Kevrekidis,Michael D. Shields", "background": "操作学习框架的预测准确性依赖于可用的训练数据质量和数量，通常需要大量的高保真数据。然而，在一些实际工程应用中获取高保真数据具有挑战性。此外，这些数据集可能在不同实现中离散度不均，网格外解析度会有所不同。因此，本文旨在通过扩展Resolution Independent Neural Operator (RINO)框架来解决这两个问题，提出一种完全数据免费的方法，为任意（但足够精细）离散化的输入函数提供物理学导向的多分辨率神经算子。这种方法利用预训练的基本函数将输入函数投影到潜在嵌入空间中，然后通过简单的多层感知器（MLP）来近似求解与潜在偏微分方程（PDE）相关的运算符。物理空间中的PDE通过有限差分求解器实现约束。该方法在具有不同分辨率数据的各种数值示例中进行了验证和性能评估，包括粗细离散化采样。", "innovation": "本文提出了一个完全数据免费的物理学导向的多分辨率神经算子方法，通过扩展的RINO框架来解决离散数据质量和不均匀性带来的挑战。该方法利用预训练的基本函数将输入函数投影到潜在嵌入空间中，通过简单的多层感知器（MLP）近似求解与偏微分方程（PDE）相关的运算符，并通过物理空间中的有限差分求解器实现PDE的约束。这种方法在各种数值示例中得到了验证和性能评估，展示了其针对不同分辨率数据的有效性。", "conclusion": "本文通过将预训练的基本函数与多分辨率神经算子结合，提出了一种完全数据免费的方法，解决了离散数据质量和不均匀性带来的挑战。这种方法能够提高操作学习框架的预测准确性，并在多种数值示例中进行了验证。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23948", "html_url": "https://arxiv.org/abs/2510.23948", "title": "ChessQA: 评估大规模语言模型的国际象棋理解能力", "title_en": "ChessQA: Evaluating Large Language Models for Chess Understanding", "authors": "Qianfeng Wen,Zhenwei Tang,Ashton Anderson", "background": "国际象棋为评估大规模语言模型（LLMs）的推理、建模和抽象能力提供了理想测试平台，因为国际象棋具有明确结构和客观真相标准，同时覆盖广泛的技能水平。然而，现有的LLM在国际象棋上的评估多为临时性且范围狭窄，难以准确衡量LLM对国际象棋的理解及其随规模、训练后方法或架构选择的变化。", "innovation": "We present ChessQA，这是一种综合基准，评估LLM在五类任务（结构、动机、短技巧、位置判断和语义）中的国际象棋理解能力，涵盖了玩家累积棋艺知识时逐步掌握的抽象层次，从理解基本规则到学习战术模式，准确计算战术，评价位置，以及语义描述高级概念。这种方式捕捉了更全面的棋艺能力与理解，超越了之前仅评估移动质量的方法，提供了诊断和比较的受控且一致的环境。此外，ChessQA 具有动态性，其提示、答案密钥和构建脚本可随着模型的改进而演变。", "conclusion": "我们在五个类别中评估了一系列当前LLM，发现跨所有类别的一贯弱点，并按类别提供了结果和错误分析。我们还将发布代码、定期刷新的数据集和公共排行榜，以支持进一步研究。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23986", "html_url": "https://arxiv.org/abs/2510.23986", "title": "STNet: 基于谱变换网络解决算子特征值问题", "title_en": "STNet: Spectral Transformation Network for Solving Operator Eigenvalue Problem", "authors": "Hong Wang,Jiang Yixuan,Jie Wang,Xinyi Li,Jian Luo,Huanshuo Dong", "background": "算子特征值问题在科学和工程应用中至关重要，但由于维数灾难，数值方法受到了限制。最近的深度学习方法通过迭代更新神经网络提供了一种有效的解决方案。这些方法的表现依赖于给定算子的特征值分布：较大的特征值间隔能提高精度，因此，利用特征值分布的定制化谱变换可以提高它们的性能。", "innovation": "提出了谱变换网络（STNet）。在每次迭代中，STNet 使用近似特征值和特征函数对原始算子进行谱变换，将其转换为等效但更易于解决的问题。具体来说，使用消减投射排除已解决特征函数对应的子空间，从而减少搜索空间并避免收敛到已知特征函数。此外，我们的滤波变换增强了目标区域的特征值并抑制了其他区域的特征值，进一步提高了性能。", "conclusion": "广泛的实验表明，STNet 在准确率方面始终优于现有的基于学习的方法，达到业内最佳水平。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23980", "html_url": "https://arxiv.org/abs/2510.23980", "title": "HyperGraphX: 通过超维计算和消息传递进行图的归纳学习", "title_en": "HyperGraphX: Graph Transductive Learning with Hyperdimensional Computing and Message Passing", "authors": "Guojing Cong,Tom Potok,Hamed Poursiami,Maryam Parsa", "background": "在超维计算中，已有一个结合图形卷积与绑定和捆绑操作的新型算法被提出，用于超维图形学习。对于预测精度，该算法表现出色，超越了主要的图形神经网络实现和最先进的超维计算实现。特别是在同质图和异质图中，该算法的预测性能尤为突出。", "innovation": "提出了一种新的算法 \textbackslash{}hdgc，它将图形卷积与绑定和捆绑操作结合在超维计算中，用于归纳性图形学习。这种结合在提高预测准确度的同时，显著提高了运算速度，特别是在同质图和异质图中表现优异。该算法特别适合于二进制向量的操作，从而预计在神经形态计算和新兴的计算存储融合设备上具有出色的能量性能。", "conclusion": "相较于最精确的学习方法，\textbackslash{}hdgc 在相同的 GPU 平台上分别快了 9561.0 倍和 144.5 倍，分别相比图形神经网络实现 GCNII 和超维计算实现 HDGL。该算法特别适用于二进制向量运作，在神经形态和新兴计算存储融合设备上表现出卓越的能量性能。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23994", "html_url": "https://arxiv.org/abs/2510.23994", "title": "在内河航道上使用船舶轨迹衍生特征预测拖带长度：概念验证", "title_en": "Predicting Barge Tow Size on Inland Waterways Using Vessel Trajectory Derived Features: Proof of Concept", "authors": "Geoffery Agorku,Sarah Hernandez,Hayley Hames,Cade Wagner", "background": "由于驳船不具备自航能力以及现有监控系统的局限性，准确、实时估算内河航道上驳船的数量仍然是一项关键挑战。本文探讨了利用自动识别系统（AIS）船舶跟踪数据和机器学习（ML）方法来预测拖带数量的新方法。", "innovation": "提出了一种创新方法，通过分析AIS数据中的船舶轨迹特征来预测拖带数量，这种方法利用了机器学习模型，特别是Poisson回归模型，表现最佳，准确度高达1.92艘驳船。研究实现了通过船舶操作性和轨迹特征来提升内河航行领域的航海领域意识（MDA），具有在航道调度、港口管理和货运规划中的广泛应用潜力。", "conclusion": "所提出的方案提供了一种可扩展、易于实施的方法，用于增强海上航行领域的意识，并且在其他具有不同操作和环境条件的内河航道上具有良好的应用前景。未来的研究将扩大本文中提出的概念验证，探索模型在不同内河航道上的可转移性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24012", "html_url": "https://arxiv.org/abs/2510.24012", "title": "无训练的文本嵌入安全性指导在文本到图像扩散模型中的应用", "title_en": "Training-Free Safe Text Embedding Guidance for Text-to-Image Diffusion Models", "authors": "Byeonghu Na,Mina Kang,Jiseok Kwak,Minsang Park,Jiwoo Shin,SeJoon Jun,Gayoung Lee,Jin-Hwa Kim,Il-Chul Moon", "background": "文本到图像模型在生成逼真且语义一致的图像方面取得了显著进展，得益于先进的扩散模型和大规模的网络爬取数据集。然而，这些数据集往往包含不当或有偏见的内容，当输入恶意文本提示时，可能会生成有害内容。因此，提高扩散模型的安全性成为急需解决的问题。", "innovation": "提出了一种无需训练的文本嵌入安全性指导（STG）方法，通过在采样过程中引导文本嵌入来提高扩散模型的安全性。STG基于安全函数调整文本嵌入，以生成更安全的输出。理论上，STG将模型分布与安全约束对齐，在最小影响生成质量的前提下，实现更安全的输出。实验证明，STG在各种安全场景中表现出色，有效去除有害内容同时保留输入提示的核心意义。", "conclusion": "通过实验，STG在不同安全场景中均优于基于训练和无需训练的基线模型，有效地消除了不安全内容，同时保持了生成质量。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23977", "html_url": "https://arxiv.org/abs/2510.23977", "title": "使用随机采样的协同神经预测空气质量", "title_en": "Synergistic Neural Forecasting of Air Pollution with Stochastic Sampling", "authors": "Yohan Abeysinghe,Muhammad Akhtar Munir,Sanoojan Baliah,Ron Sarafian,Fahad Shahbaz Khan,Yinon Rudich,Salman Khan", "background": "空气污染仍然是全球健康和环境的主要风险，特别是在因为野火、城市雾霾和沙尘暴导致空气质量急剧恶化的情况下。准确预报颗粒物（PM）浓度对于及时发出健康警告和采取干预措施至关重要，但现有模型往往低估了罕见但具有高度危害性的污染事件。", "innovation": "提出了一种名为SynCast的高分辨率神经预测模型，能够整合气象和空气组分数据，以提高对平均和极端污染水平的预测准确性。该模型基于适应区域的变压器骨干结构，并通过基于扩散的随机精炼模块改进，从而捕捉驱动PM峰值的非线性动态更为准确。利用协调的ERA5和CAMS数据集，模型在多种PM变量（PM1，PM2.5，PM10）的预测准确性上取得了显著改善，特别是在极端条件下。同时，该模型使用了与领域意识目标和极端值理论相结合的损失函数，显著提升了在高受影响区域的性能，而没有牺牲全球准确性。", "conclusion": "该方法为下一代空气质量预警系统提供了可扩展的基础，并在脆弱地区支持气候变化和健康风险的缓解。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24025", "html_url": "https://arxiv.org/abs/2510.24025", "title": "神经PathNet：脑功能连接动态路径学习", "title_en": "NeuroPathNet: Dynamic Path Trajectory Learning for Brain Functional Connectivity Analysis", "authors": "Guo Tianqi Guo,Chen Liping,Peng Ciyuan,Guo Jingjing,Ren Jing", "background": "了解大脑功能网络随时间的演变对认知机制分析和神经疾病诊断至关重要。现有方法往往难以捕捉特定功能社区间连接的时间演变特性。因此，本研究提出了一个基于路径级别的轨迹建模框架（NeuroPathNet），用于表征脑功能分区之间连接路径的动态行为。通过基于医学支持的静态分区方案（如Yeo和Smith ICA），提取各功能分区间连接强度的时间序列，并使用时间神经网络进行建模。通过三个公共功能磁共振成像(fMRI)数据集验证模型性能，结果显示在多个指标上优于现有主流方法。这项研究可以促进脑网络分析中动态图学习方法的发展，并为神经疾病诊断提供潜在的临床应用平台。", "innovation": "提出了一个基于路径级别的轨迹建模框架（NeuroPathNet），用于表征脑功能分区之间连接路径的动态行为。通过医学支持的静态分区方案提取各功能分区间连接强度的时间序列，并使用时间神经网络进行建模，该方法在多个指标上优于现有主流方法", "conclusion": "这项研究可以促进动态图学习方法在脑网络分析中的发展，并为神经疾病诊断提供潜在的临床应用平台。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23974", "html_url": "https://arxiv.org/abs/2510.23974", "title": "Text-to-Image扩散模型中的自适应文本嵌入", "title_en": "Diffusion Adaptive Text Embedding for Text-to-Image Diffusion Models", "authors": "Byeonghu Na,Minsang Park,Gyuwon Sim,Donghyeok Shin,HeeSun Bae,Mina Kang,Se Jung Kwon,Wanmo Kang,Il-Chul Moon", "background": "文本到图像的扩散模型依赖于预训练文本编码器提供的文本嵌入，但这些嵌入在整个扩散时间步骤中保持不变，限制了它们在生成过程中的适应性。", "innovation": "提出了一种新的自适应文本嵌入方法——Diffeusion Adaptive Text Embedding (DATE)，该方法能够动态地在每次扩散时间步骤中根据中间扰动数据更新文本嵌入，从而改善预测图像均值与文本之间的对齐和偏好。通过理论分析和实证结果，展示了DATE在保持模型的生成能力的同时，提供了优于固定文本嵌入的文本-图像对齐能力，特别是在多概念生成和文本引导的图像编辑任务中。", "conclusion": "DATE方法在整个扩散采样过程中动态调整文本条件，无需额外的模型训练即可适应逆向扩散图像，该方法保持了模型的生成能力并提高了文本和图像之间的对齐度。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23992", "html_url": "https://arxiv.org/abs/2510.23992", "title": "组合臂消除算法在组合型 bandits 中的最优策略", "title_en": "Optimal Arm Elimination Algorithms for Combinatorial Bandits", "authors": "Yuxiao Wen,Yanjun Han,Zhengyuan Zhou", "background": "组合 bandits 将传统 bandit 框架扩展到学习者每轮可以选择多个臂的应用场景，这在在线推荐和商品组合优化等领域具有实际意义。虽然上确界（UCB）算法的扩展很容易设想，但臂消除方法的调整证明更具挑战性。本文探讨了一种新的臂消除方案，并证明了其在组合多臂 bandit（包括一般图反馈）和组合线性上下文 bandit 两种场景下均达到了接近最优的遗憾值，而基于UCB的方法由于缺乏明确的探索可能会导致失败。同时也提供了匹配的下界。", "innovation": "本文提出了一个新的臂消除方案，将臂分为已确认、活跃和已消除三类，并引入了明确的探索机制来更新这些集合。该算法在两种不同的场景下（一般图反馈的组合多臂 bandit 和组合线性上下文 bandit）都达到了接近最优的遗憾值，而在先前的基于UCB的方法中，由于缺乏明确的探索，无法保证最优效果。同时提供了匹配的下界。", "conclusion": "组合臂消除算法在两种组合 bandits 的应用场景中均表现出了良好的效果，通过明确的探索机制，在保证低遗憾值方面取得了突破。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23936", "html_url": "https://arxiv.org/abs/2510.23936", "title": "一种用于2D和3D纳维斯特okes方程快速推断的无数据神经运算符", "title_en": "A data free neural operator enabling fast inference of 2D and 3D Navier Stokes equations", "authors": "Junho Choi,Teng-Yuan Chang,Namjung Kim,Youngjoon Hong", "background": "高维流动模型（如纳维-斯托克斯类型的偏微分方程）进行集成模拟对实时应用来说计算成本极高。神经运算符能够快速进行推理但受限于昂贵的数据需求和对三维流动的不佳泛化能力。本文聚焦于发展一种基于物理的无数据运算符网络，针对纳维-斯托克斯方程，该网络不需要配对的解数据，并能够在大规模集成预测中实现快速且稳健的推理。该架构利用初始和边界条件以及激励函数，从而提供对高变异性及扰动具有鲁棒性的解决方案。在2D基准测试和3D测试案例中，该方法在准确度上优于之前的神经运算符，并且对于集成，实现比传统数值求解器更高的效率。另外，该方法能够提供三维纳维-斯托克斯方程的准确解，这是此前对于无数据的神经运算符未实现的领域。通过将数值稳定的架构与机器学习的可扩展性相结合，本文提出了一条实现无数据高保真PDE代理的实用途径，用于端到端的科学模拟和预测.", "innovation": "本文提出了一个基于物理的无数据运算符网络，针对纳维-斯托克斯方程，该网络不需要配对的解数据，并能够在大规模集成预测中实现快速且稳健的推理。在2D基准测试和3D测试案例中，该方法在准确度上优于之前的神经运算符，并且对于集成，实现比传统数值求解器更高的效率。该项目首次证明对于无数据神经运算符能够提供三维纳维-斯托克斯方程的准确解。这种方法通过结合数值稳定的架构与机器学习的可扩展性，为端到端的科学模拟和预测提供了实用的无数据代理之路.", "conclusion": "本文介绍了一种基于物理的无数据运算符网络，该网络能够在不需要配套解数据的情况下，提供快速且稳健的纳维-斯托克斯方程推理。实验结果表明，该方法在2D和3D测试中超越了现有神经运算符，并且实现了传统数值解决器无法比拟的集成预测效率。特别地，它能够提供三维纳维-斯托克斯方程的准确解，这是无数据神经运算符未曾实现的。该研究提出的方法为实现端到端的科学模拟和预测提供了一条实际可行的途径，未来具有广泛应用潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24035", "html_url": "https://arxiv.org/abs/2510.24035", "title": "GraphNet：用于张量编译器研究的大规模计算图数据集", "title_en": "GraphNet: A Large-Scale Computational Graph Dataset for Tensor Compiler Research", "authors": "Xinqi Li,Yiqun Liu,Shan Jiang,Enrong Zheng,Huaijin Zheng,Wenhao Dai,Haodong Deng,Dianhai Yu,Yanjun Ma", "background": "介绍了GraphNet，这是一个包含2,700个实际的深层学习计算图的数据集，这些图具有丰富的元数据，并跨越多个深度学习框架中的六大主要任务类别。为了评估这些样本上的张量编译器性能，提出了一个新的基准分数S(t)，该分数在可调容差水平下联合考虑运行时加速和执行正确性，提供了一种可靠的通用优化能力衡量标准。此外，还扩展了S(t)为错误感知的加速分数ES(t)，使编译器开发者能够识别关键的性能瓶颈。在此报告中，通过计算机视觉(CV)和自然语言处理(NLP)样本对默认张量编译器CINN for PaddlePaddle和TorchInductor for PyTorch进行了基准测试，展示了GraphNet的实际应用价值。", "innovation": "提出了新的基准分数S(t)和错误感知的加速分数ES(t)，这两种分数可以评估张量编译器的性能，并帮助开发者识别性能瓶颈。同时介绍了GraphNet这个大规模的计算图数据集，用于评估不同深度学习框架下的计算图性能。", "conclusion": "在计算机视觉和自然语言处理样本上对CINN for PaddlePaddle和TorchInductor for PyTorch进行了基准测试，验证了GraphNet的实际应用价值。提供了完整的构建管道，包括图提取和编译器评估工具。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24043", "html_url": "https://arxiv.org/abs/2510.24043", "title": "局部核投影异常值：一种用于多模态异常检测的两阶段方法", "title_en": "Localized Kernel Projection Outlyingness: A Two-Stage Approach for Multi-Modal Outlier Detection", "authors": "Akira Tamamori", "background": "本研究提出了两阶段LKPLO（Localized Kernel Projection Outlyingness）异常检测框架，以克服传统投影基方法存在的限制：即对固定统计度量的依赖以及假设单一数据结构。传统方法在处理复杂结构的数据时表现不佳。", "innovation": "该框架独特地综合了三个关键概念：（1）通用损失基异常值度量（PLO），用灵活的、自适应的损失函数代替固定度量，包括提出的类似SVM的损失；（2）全局核PCA阶段，用于线性化非线性数据结构；（3）后续的局部聚类阶段，以处理多模态分布。通过5折交叉验证实验在10个基准数据集上，并结合自动超参数优化，证明了LKPLO达到最先进的性能。与现有的方法相比，它在具有挑战性结构的数据集（如Optdigits和Arrhythmia）上表现得更好。", "conclusion": "消融研究实证证明，核化和局部化阶段的结合对于实现性能提升是必不可少的。这项工作为一类重要的异常检测问题提供了强有力的新型工具，并强调了混合、多阶段架构的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24044", "html_url": "https://arxiv.org/abs/2510.24044", "title": "通过减少环境分歧来缓解负向迁移", "title_en": "Mitigating Negative Transfer via Reducing Environmental Disagreement", "authors": "Hui Sun,Zheng Xie,Hao-Yuan He,Ming Li", "background": "无监督领域适应（UDA）旨在将标记的源域知识转移到无标记的目标域，解决领域不一致（domain shift）带来的挑战。显著的领域不一致性会阻碍有效的知识转移，导致负向迁移和模型性能下降。因此，缓解负向迁移变得尤为重要。本文通过因果分隔学习的视角重新审视负向迁移问题，强调目标域环境随环境变化而演化时，非因果环境特征上的判别性分歧（称为环境分歧）是关键因素。理论分析表明，过度依赖非因果环境特征会导致判别性分歧，从而产生负向迁移。", "innovation": "本文提出了一种名为Reduction of Environmental Disagreement（RED）的新方法，通过对抗训练领域特定的环境特征提取器，将每个样本分离为保持一致性的因果特征和特有的非因果环境特征。随后，RED根据领域特定的非因果环境特征来估计并减少环境分歧。最终实验验证了RED的有效性，并达到了最先进的性能。", "conclusion": "该研究通过因果分隔学习的新视角，提出了RED方法，有效地缓解了负向迁移，达到了目前的最优性能。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24027", "html_url": "https://arxiv.org/abs/2510.24027", "title": "带有选定变量的时空多变量时间序列预测", "title_en": "Spatio-temporal Multivariate Time Series Forecast with Chosen Variables", "authors": "Zibo Liu,Zhe Jiang,Zelin Xu,Tingsong Xiao,Yupu Zhang,Zhengkun Xiao,Haibo Wang,Shigang Chen", "background": "时空多变量时间序列预测（STMF）利用最近过去的时空分布变量的时间序列来预测未来期间的这些变量值。这种方法在时空传感器预测中具有重要应用，如道路交通预测和空气质量预测。近年来的研究解决了模型输入中缺失变量的实际问题，这是因为预算限制导致监测地点的数量$n$远大于传感器数量$m$。当前的研究发现，现有技术假设输入模型的$m$个变量已经被预先确定，而如何选择这些变量的问题从未被研究。因此，本文探讨了一个新的问题，即如何选择输入模型的最佳$m$个变量，以便在最大化预测准确性的同时优化模型的效率。", "innovation": "本文提出了一种统一框架，该框架同时为预测准确性和模型效率执行变量选择和模型优化。该框架的创新性组成部分包括：(1) 带有基于分位数掩码的变量和参数剪枝，这是逐步移除不相关信息的变量和注意力参数；(2) 优先级变量和参数重播，以重播低损失的过去样本，从而确保模型的稳定性；(3) 动态外推机制，通过可学习的空间嵌入和邻接信息，将为输入选择的变量信息传播给所有其他变量。实验结果表明，相对于最先进的基线方法，本文的工作在准确性和效率上都取得了显著的改进，证明了联合变量选择和模型优化的有效性。", "conclusion": "通过解决变量选择问题，本文提出的方法显著提高了时空多变量时间序列预测的准确性和效率。该方法能够在限定条件（如传感器数量有限）下，优化选择输入模型的变量，从而提高预测性能。实验结果支持所提出方法的有效性，并展示了其在实际应用中的潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24039", "html_url": "https://arxiv.org/abs/2510.24039", "title": "几何算法在约束神经组合优化中的应用", "title_en": "Geometric Algorithms for Neural Combinatorial Optimization with Constraints", "authors": "Nikolaos Karalias,Akbar Rafiey,Yifei Xu,Zhishang Luo,Behrooz Tahmasebi,Connie Jiang,Stefanie Jegelka", "background": "自监督学习（SSL）和组合优化（CO）是机器学习和运筹学中的重要领域。近年来，结合两者的新范式逐渐成为解决组合问题的有效方式。然而，如何利用神经网络解决带有离散约束的组合优化问题仍然是一个核心挑战。本文探讨了如何设计一种端到端可微框架，以利用几何算法和Carathéodory定理来解决此类问题。通过这种分解式方法，在保证质量的前提下，能够有效进行神经网络输出的简化和解决方案的优化.", "innovation": "文章创新性地设计了一种端到端的可微框架，结合了几何算法和Carathéodory定理，使得能够通过神经网络解决带有离散约束的组合优化问题。具体来说，通过将神经网络的输出分解为多面体棱角的凸组合，实现了自监督训练并确保了高效的质量保持的简化过程。这种改进的方法在多个组合优化任务中表现出色，特别是卡要度约束优化问题中取得了显著的成果.", "conclusion": "通过大量的实验验证，本文提出的几何算法在约束神经组合优化中具有显著优势，可以有效解决各种组合优化问题，包括在图中查找独立集和求解基有序问题。此外，该方法可以灵活应用于多种类型的组合优化任务。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24046", "html_url": "https://arxiv.org/abs/2510.24046", "title": "具有强化学习的因果意识生成对抗网络", "title_en": "Causal-Aware Generative Adversarial Networks with Reinforcement Learning", "authors": "Tu Anh Hoang Nguyen,Dang Nguyen,Tri-Nhan Vo,Thuc Duy Le,Sunil Gupta", "background": "表格数据在从模型训练到大规模数据分析的各种任务中具有很高的实用价值，但常常受到隐私问题或监管障碍的限制。现有的数据生成方法，尤其是基于生成对抗网络（GANs）的方法，虽然显示出一定的潜力，但在捕捉复杂因果关系、保持数据质量和提供适合企业部署的可证明隐私保护方面仍存在问题。", "innovation": "我们提出了CA-GAN（因果意识生成对抗网络），这是一种全新的生成框架，专门针对现实世界表格数据的挑战进行设计。CA-GAN采用了两步方法：因果图提取学习数据流形中的稳健全面因果关系，然后使用基于因果图中节点结构的自定义条件WGAN-GP（基于梯度惩罚的Wasserstein生成对抗网络）。此外，生成器经过新的基于强化学习的目标训练，确保真正数据和虚假数据构建的因果图一致，从而确保因果意识贯穿训练和采样阶段。", "conclusion": "我们在14个表格数据集上对比了CA-GAN与其他六种顶级方法的表现，评估指标集中在数据工程核心指标：因果保存、数据质量和隐私保护。我们的方法为数据工程师提供了一种实际、高性能的解决方案，用于生成高质量、隐私合规的合成数据集，以测试数据库系统、加速软件开发并促进安全的数据驱动研究。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24049", "html_url": "https://arxiv.org/abs/2510.24049", "title": "从历史中学习：一种时空预测的检索增强框架", "title_en": "Learning from History: A Retrieval-Augmented Framework for Spatiotemporal Prediction", "authors": "Hao Jia,Penghao Zhao,Hao Wu,Yuan Gao,Yangyu Tao,Bin Cui", "background": "在科学计算中，精确和长期的时空预测对于复杂的物理系统仍然是一个基本挑战。尽管深度学习模型作为强大的参数逼近器已经显示出显著的成功，但它们遭受一个关键的局限性：在长期自回归滚动过程中累积的误差往往会导致物理不可能的艺术品。这种缺陷源自它们纯粹的参数性质，难以捕捉到系统内在动力学的全部约束。", "innovation": "我们提出了一种新颖的Retrieval-Augmented Prediction (RAP)框架，这是一种将深度网络的预测能力和历史数据的真实情况相结合的混合范式。RAP的核心理念是从大规模数据库中高效检索与给定状态最相似的历史样本，该样本的真实未来演化作为参考预测目标。这个目标不是损失函数的硬约束，而是专门为特殊双流架构的强大条件输入，提供强烈的动态指导，引导模型预测物理可行的轨迹。", "conclusion": "在气象学、湍流和火情模拟等广泛的基准测试中，RAP不仅超过了最先进的方法，而且显著优于强大的单一历史模拟预测基线。更重要的是，通过有效抑制长期滚动中的误差发散，RAP生成的预测更为物理上合乎实际。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24026", "html_url": "https://arxiv.org/abs/2510.24026", "title": "高效的全局-局部融合采样方法用于物理准则神经网络", "title_en": "Efficient Global-Local Fusion Sampling for Physics-Informed Neural Networks", "authors": "Jiaqi Luo,Shixin Xu,Zhouwang Yang", "background": "物理准则神经网络（PINNs）的准确性高度依赖于插值点的位置，因为PDE损失是通过在解空间中采样来近似计算的。全局采样能够确保稳定性，因为它能覆盖整个领域，但这会需要很多样本并且计算成本高昂；而局部采样提高了效率，因为它集中于残差较高的区域，但可能会忽略已经较好学习的区域，从而减少了鲁棒性。", "innovation": "本文提出了一种全局-局部融合（GLF）采样策略，该策略结合了两种方法的优点。首先，通过使用与残差成反比的高斯噪声对训练点进行扰动来生成新的插值点，这集中了样本在难点区域同时保持探索。其次，引入轻量级的线性近似来近似全局基于残差的分布，以实现相似的效果但计算开销较小。这些组件—残差自适应采样和基于残差的近似—在保持全局方法的稳定性的同时，保持了局部精细处理的效率。实验结果表明，GLF策略在复杂和高维PDE问题上始终提高了准确性和效率，相较于全局和局部采样策略提供了更可靠的框架。", "conclusion": "该研究提供了一种实用且可扩展的框架，以增强物理准则神经网络在解决复杂和高维偏微分方程的可靠性和效率。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24053", "html_url": "https://arxiv.org/abs/2510.24053", "title": "使用 FolDE 的低批次蛋白活性优化", "title_en": "Low-N Protein Activity Optimization with FolDE", "authors": "Jacob B. Roberts,Catherine R. Ji,Isaac Donnell,Thomas D. Young,Allison N. Pearson,Graham A. Hudson,Leah S. Keiser,Mia Wesselkamper,Peter H. Winegar,Janik Ludwig,Sarah H. Klass,Isha V. Sheth,Ezechinyere C. Ukabiala,Maria C. T. Astolfi,Benjamin Eysenbach,Jay D. Keasling", "background": "传统上优化蛋白质需要构建和测量大量的突变体，这代价高昂。Active Learning-assisted Directed Evolution（ALDE）通过预测最佳改进并逐步测试突变体来减少成本，但现有ALDE方法存在一个关键限制：在每轮中选择预测值最高的突变体会产生同质化的训练数据，导致后续轮次中无法生成准确的预测模型。", "innovation": "本文提出了一种称为FolDE的新ALDE方法，以最大化最终成功概率。FolDE主要通过基于自然性的预热启动实现，它利用蛋白质语言模型输出的预测来补充有限的活性测量值，从而提高活性预测。此外，还引入了恒定撒谎批选择器，以提高批处理的多样性。", "conclusion": "通过模拟20个蛋白目标，FolDE发现了比现有最佳ALDE方法多23%的前10%突变体（p=0.005），并且找到前1%突变体的可能性高55%。FolDE的整个流程已作为开源软件提供，使得高效的蛋白质优化对任何实验室都是可及的。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24095", "html_url": "https://arxiv.org/abs/2510.24095", "title": "从演示中学习参数化技能", "title_en": "Learning Parameterized Skills from Demonstrations", "authors": "Vedant Gupta,Haotian Fu,Calvin Luo,Yiding Jiang,George Konidaris", "background": "本文介绍了DEPS，一种端到端算法，用于从专家演示中发现参数化技能。该方法联合学习参数化技能策略和一个元策略，该元策略在每个时间点选择合适的离散技能和连续参数。使用时间变分推断和信息论正则化方法，解决了潜在变量模型中常见的退化问题，保证所学习的技能具有时间扩展性、语义意义，并能够适应变化。", "innovation": "DEPS在从多任务专家演示中学习参数化技能方面具有显著优势，显著提高了对未见过任务的泛化能力。在LIBERO和MetaWorld基准测试中，该方法优于多任务学习和技能学习基线。DEPS还能够发现可解释的参数化技能，例如定义抓取位置的物体抓取技能。", "conclusion": "实验结果表明，DEPS能够从多任务专家演示中学习到适应性强、可泛化的参数化技能，并且能够有效应用于现实世界中的复杂任务。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24061", "html_url": "https://arxiv.org/abs/2510.24061", "title": "FALQON: 使用低比特浮点算术加速LoRA微调", "title_en": "FALQON: Accelerating LoRA Fine-tuning with Low-Bit Floating-Point Arithmetic", "authors": "Kanghyun Choi,Hyeyoon Lee,SunJong Park,Dain Kwon,Jinho Lee", "background": "低比特浮点（FP）格式，如FP8，在现代GPU和NPUs的原生硬件支持下，可以显著加速模型训练并节省内存。然而，FP8量化主要为大型维度矩阵乘法提供加速，而对于使用小维度矩阵进行大型语言模型（LLMs）高效微调的低秩适应（LoRA），其固有的量化开销会抵消这种加速效果。", "innovation": "提出了FALQON框架，该框架通过直接将LoRA适配器合并到FP8量化主干中以消除单独LoRA计算路径中的量化开销。此外，通过重新定义合并适配器的前向和反向计算，显著减少了量化开销，并引入了一种行向量代理更新机制，可以高效地将大量更新集成到量化主干中。", "conclusion": "实验结果表明，FALQON在与现有量化LoRA方法相似的准确度水平下，实现了约3倍的训练加速。此外，FALQON的端到端FP8工作流消除了后训练量化的需求，为高效部署提供了实用解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24135", "html_url": "https://arxiv.org/abs/2510.24135", "title": "固定点神经加速和反向代理模型用于电池参数识别", "title_en": "Fixed Point Neural Acceleration and Inverse Surrogate Model for Battery Parameter Identification", "authors": "Hojin Cheon,Hyeongseok Seo,Jihun Jeon,Wooju Lee,Dohyun Jeong,Hongseok Kim", "background": "随着电动汽车的迅速发展，对锂电池进行准确且高效的诊断变得日益紧迫。传统元启发式方法在参数识别方面存在高计算成本和缓慢收敛的问题，而近年来的机器学习方法依赖于恒定电流数据，这种数据可能在实践中难以获得。", "innovation": "本文提出了一种基于深度学习的框架，用于电解质单粒子模型（NeuralSPMe）的参数识别。该框架结合了一个神经拟合单粒子模型和电解质模型，并使用了一个基于深度学习的固定点迭代更新网络（PUNet）。该方法通过在真实的电动汽车负载配置文件上训练NeuralSPMe，能够准确预测动态运行条件下的锂浓度动态。PUNet通过固定点迭代更新，大大减少了每次样本的评估时间和整体迭代次数。实验结果表明，该框架能加速参数识别2000多倍，实现了更高的样本效率和准确度。", "conclusion": "实验评估表明，所提出的框架在动态负载场景下比传统的元启发式算法更快、更准确。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24160", "html_url": "https://arxiv.org/abs/2510.24160", "title": "可识别学习耗散动力学", "title_en": "Identifiable learning of dissipative dynamics", "authors": "Aiqing Zhu,Beatrice W. Soh,Grigorios A. Pavliotis,Qianxiao Li", "background": "复杂耗散系统存在于科学和工程的各个领域，如聚合物、活性物质和学习算法，这些系统远离平衡，能量耗散和时间不可逆性是其行为的关键，但很难从数据中量化。构建准确且可解释的非平衡动力学模型仍然是一项重大挑战：模型需要足够表达力来描述各种过程，同时又要受到实际意义和数学辨识性的约束。", "innovation": "引入了I-OnsagerNet，这是一种神经网络方法，可以直接从轨迹中学习耗散的随机动力学，并确保其可解释性和唯一性。I-OnsagerNet扩展了Onsager原理，确保学习到的势能是从静止密度中获得的，同时将漂移分解为可以单独识别的时间可逆和不可逆部分，遵循亥姆霍兹分解的规则。这种方法允许计算熵产生，并量化不可逆性，提供了一种原则性的方法来检测和量化偏离平衡的行为。", "conclusion": "I-OnsagerNet 为发现和解释非平衡动力学提供了通用的、基于数据的方法，并揭示了在延展流中聚合物拉伸和随机梯度拉梅尔分布的新见解。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24173", "html_url": "https://arxiv.org/abs/2510.24173", "title": "EddyFormer: 加速大规模三维湍流神经模拟", "title_en": "EddyFormer: Accelerated Neural Simulations of Three-Dimensional Turbulence at Scale", "authors": "Yiheng Du,Aditi S. Krishnapriyan", "background": "在流体动力学中，由于湍流的多尺度相互作用，计算上解决湍流仍然是一个核心挑战。通过直接数值模拟(DNS)全面解析大型湍流是不可行的，因此需要采用数据驱动的机器学习方法作为替代方案。", "innovation": "本文提出了EddyFormer，这是一种基于Transformer的谱元(Spectral-Element, SEM)架构，结合了谱方法的准确性与注意力机制的可扩展性。EddyFormer引入了一种SEM符号化方法，将流体分解为网格尺度和亚网格尺度组件，从而能够捕捉局部和全局特征。通过建立一个三维各向同性湍流数据集，EddyFormer在256^3分辨率下实现了DNS级别的准确度，并提供30倍于DNS的加速效果。此外，EddyFormer在未见过的领域中仍能保持准确度，展示了物理不变性指标上的领域泛化能力。在The Well基准平台上，EddyFormer能够成功模拟先前机器学习模型无法收敛的复杂流体动力。", "conclusion": "EddyFormer通过引入基于Transformer的谱元架构，实现了三维大规模湍流的高效模拟，同时保持了DNS级别的准确度，为复杂物理条件下的湍流模拟提供了新的解决方案，并展示了其在不同流动环境下的泛化能力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24125", "html_url": "https://arxiv.org/abs/2510.24125", "title": "因果卷积神经网络作为有限冲激响应滤波器", "title_en": "Causal Convolutional Neural Networks as Finite Impulse Response Filters", "authors": "Kiran Bacsa,Wei Liu,Xudong Jian,Huangbin Liang,Eleni Chatzi", "background": "研究因果卷积神经网络（CNNs）在具有多模态频率内容的时间序列数据上的行为，特别是其在经过训练后表现出与有限冲激响应（FIR）滤波器类似性质的现象。通常，因果CNNs在标准CNN架构中使用较短的卷积核，但在训练后，当卷积核长度延长时，这种网络可以捕捉频率特征，提供动态系统任务的增强可解释性。进一步利用卷积的性质，该研究展示了整个网络可以被简化为一个等价的单层滤波器，类似于通过最小二乘准则优化的FIR滤波器，从而揭示了因果CNNs在稀疏频率内容信号下的光谱学习行为。", "innovation": "研究发现因果CNNs在经过训练后可以表现出与FIR滤波器类似的图谱特征捕捉能力，特别是当卷积核长度超过标准CNN架构中的长度时。进一步展示了整个网络可以简化为单层滤波器，并且这种等价关系提供了一种新的见解，使其适用于光谱学习动态响应信号的任务。通过在模拟和实际桥梁振动数据集上的验证，强调了这种方法在建模并识别由动态响应支配的物理系统中相关性。", "conclusion": "因果CNNs在经过训练后可以被视为具有最小二乘优化准则优化的FIR滤波器，从而提供了一种新的方法来理解这类网络在处理具有稀疏频率内容的信号时的光谱学习行为。这种方法通过在模拟和实际桥梁振动数据集上的应用得到了验证，具有潜在的应用价值。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24088", "html_url": "https://arxiv.org/abs/2510.24088", "title": "信息论离散扩散", "title_en": "Information-Theoretic Discrete Diffusion", "authors": "Moongyu Jeon,Sangwoo Shin,Dongjae Jeon,Albert No", "background": "该研究基于信息论框架，针对离散扩散模型提出了一种全新的信息熵估计方法。研究从高斯设置下的I-MMSE（信息—最小均方误差）等式出发，推导出适用于离散设置的等式，特别是引入了一种称为信息最小去噪评分熵(I-MDSE)的关系，连接了数据与其去噪版本之间的互信息以及最小去噪评分熵损失。此外，研究还通过扩展理论到掩蔽扩散，建立了信息最小去噪交叉熵(I-MDCE)关系，将交叉熵损失与离散遮蔽过程中的互信息联系起来。这些理论成果为数据的对数似然提供了一个时间积分分解，表明常用的损失如DSE（去噪熵）和DCE（去噪交叉熵）不仅作为变分界限存在，而是精确的信息似然估计。最后，提出了I-MDCE分解可实现无需考虑时间的公式、提示-响应任务中的条件似然估计以及联合蒙特卡洛估计似然比等实操扩展。实验结果在合成数据和实际数据集上的表现证实了该估计方法的准确性、稳定性和适用性。研究的代码已公开可用。", "innovation": "该研究主要创新地提出了利用信息熵理论及其等式应用于离散扩散模型的一种新方法，即I-MDSE和I-MDCE关系，以此建立新的分数和损失函数，提出一种理论框架，提供了对数似然的时域积分分解，强调了常用损失函数如DSE和DCE不仅作为一种变分界限的损耗函数，也是一种精确的信息似然估算器，同时提供了多个实用扩展，包括无需时间的公式、条件似然估计和联合蒙特卡洛估计。", "conclusion": "研究结果表明，所提出的估计器在合成数据集和实际数据集上的准确性、稳定性和实用性，验证了I-MDSE和I-MDCE关系的有效性。未来的工作可以进一步探索更多类型的扩散模型以及在其他实际应用场景中的应用前景。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24120", "html_url": "https://arxiv.org/abs/2510.24120", "title": "基于图的概念选择以提高检索增强生成的效率", "title_en": "Graph-Guided Concept Selection for Efficient Retrieval-Augmented Generation", "authors": "Ziyu Liu,Yijing Liu,Jianfei Yuan,Minzhi Yan,Le Yue,Honghui Xiong,Yi Yang", "background": "基于图的RAG通过从文本片段构建知识图来增强大型语言模型（LLM）为基础的问题回答的检索能力。这种方法特别适用于生物医药、法律和政治科学等领域，这些领域中有效的检索经常需要在专有文档中进行多次推理。然而，现有方法需要大量调用LLM来抽取文本片段中的实体及其关系，导致大规模应用时成本极高。", "innovation": "本文通过详细的删除实验发现某些关键术语（称为概念）及其相关文档更为重要。基于此洞见，提出了一种概念选择方法——Graph-Guided Concept Selection（G2ConS）。该方法的核心包括一个片段选择方法和一个与LLM无关的概念图。片段选择方法能选择显著的文档片段以降低知识图构建的成本；概念图则不会增加成本即可填补由片段选择引入的知识空白。在多个真实世界数据集上的评估结果表明，G2ConS在构建成本、检索效果和回答质量方面均优于所有基准方法。", "conclusion": "基于图的概念选择方法G2ConS提升了检索增强生成的效率，通过对重要概念的选择大大降低了知识图的构建成本，且无需额外增加计算成本的情况下提高了检索效果和回答质量。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24200", "html_url": "https://arxiv.org/abs/2510.24200", "title": "SPEAR++: 通过稀疏使用的字典学习扩展梯度反转", "title_en": "SPEAR++: Scaling Gradient Inversion via Sparsely-Used Dictionary Learning", "authors": "Alexander Bakarsky,Dimitar I. Dimitrov,Maximilian Baader,Martin Vechev", "background": "近年来，联邦学习在实际场景中的应用增加，因为它允许在不显式共享个体客户端数据的情况下训练机器学习模型。然而，梯度反转攻击的出现根本上质疑了其保护隐私的特性。虽然 SPEAR 攻击是一种重要的理论突破，但由于其在批量大小上的指数级运行时间限制了其实际应用，因此需要通过新的方法来解决这一问题。", "innovation": "通过应用来自稀疏使用的字典学习的先进技巧，使具有 ReLU 激活的线性层上梯度反转问题变得可处理。SPEAR++ 攻击保留了 SPEAR 所有有益的特性，如对 DP 噪声和 FedAvg 聚合的鲁棒性，同时适用于比 SPEAR 大 10 倍的批量大小。", "conclusion": "实验结果表明，SPEAR++ 攻击不仅保留了 SPEAR 的所有有用特性，而且还扩展了其可处理的批量大小。这为解决联邦学习中的梯度反转攻击问题开辟了新途径，使其在实际部署中更具可行性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24216", "html_url": "https://arxiv.org/abs/2510.24216", "title": "通过物理引导的扩充实现动力学中的异常分布泛化", "title_en": "Unlocking Out-of-Distribution Generalization in Dynamics through Physics-Guided Augmentation", "authors": "Fan Xu,Hao Wu,Kun Wang,Nan Wang,Qingsong Wen,Xian Wu,Wei Gong,Xibin Zhao", "background": "在动态系统建模中，传统数值方法由于高计算成本而受到限制，而现代数据驱动方法在数据稀缺和分布偏移方面存在挑战。为解决这些基本限制，我们首先提出了一种名为SPARK的物理引导定量扩充插件。SPARK利用重建自编码器将物理参数整合到富含物理特性的离散状态字典中，该状态字典作为一个结构化的物理状态词典，通过在潜在空间中进行有原则的插值，可以生成新的物理上合理的训练样本。进一步地，为了下游预测，这些扩充表示无缝地与Fourier增强的图ODE相结合，该组合旨在稳健地建模丰富数据分布并捕捉长期时间依赖关系。", "innovation": "本文提出了SPARK，一种物理引导的定量扩充插件，它利用重建自编码器将物理参数整合到富含物理特性的离散状态字典中。这些扩充表示通过与Fourier增强的图ODE结合，能够使模型在丰富数据分布中稳健建模，并捕捉长期时间依赖关系，从而显著提高了模型在分布之外场景和数据稀缺环境中的性能。", "conclusion": "在多种基准测试中广泛实验表明，SPARK明显优于最先进的基线模型，特别是在数据稀少和分布之外的场景中证明了我们物理引导的扩充范式的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24217", "html_url": "https://arxiv.org/abs/2510.24217", "title": "填补空白：ICU生命体征的插补分析", "title_en": "Closing Gaps: An Imputation Analysis of ICU Vital Signs", "authors": "Alisher Turubayev,Anna Shopova,Fabian Lange,Mahmut Kamalak,Paul Mattes,Victoria Ayvasky,Bert Arnrich,Bjarne Pfitzner,Robin P. van de Water", "background": "随着重症监护病房（ICU）数据的增加，人们越来越关注开发临床预测模型以改进医疗保健协议。然而，数据质量的不足仍然阻碍了使用机器学习（ML）进行临床预测。心跳等重要生命体征测量值存在大量的缺失部分，这可能导致预测性能降低。尽管已有许多时间序列插补技术，但尚缺乏对插补ICU生命体征方法的全面比较，以确定最佳实践。目前，仍然使用可能降低预测准确性的临时插补方法。", "innovation": "本研究引入了一个可扩展且可重复使用的基准，其中包括15种插补方法和4种截断方法，专门用于ICU大型数据集的基准测试。与之前的研究相比，本研究通过对已建立的插补技术进行比较，旨在为研究人员提供指导，以选择最准确的插补技术来提高临床预测模型的性能。", "conclusion": "希望通过提供对比基础和促进进一步的ML开发，将更多的预测模型引入临床实践。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24234", "html_url": "https://arxiv.org/abs/2510.24234", "title": "Sparse Optimistic Information Directed Sampling", "title_en": "Sparse Optimistic Information Directed Sampling", "authors": "Ludovic Schwartz,Hamish Flynn,Gergely Neu", "background": "许多高维在线决策问题可以被建模为随机稀疏线性多臂老虎机。现有的大多数算法都是在数据丰富或数据贫乏的情况下设计的，前者必须依赖于环境维度的多项式依赖性，后者在失去维度独立性的情况下可以改善对于回合次数的依赖性。相比之下，稀疏信息导向采样(IDS)算法同时在两种情况下都达到了最优的贝叶斯遗憾界。", "innovation": "本文探讨了一种新的稀疏乐观信息导向采样(SOIDS)算法，它在不依赖贝叶斯假设的情况下，在最坏情况下实现了最优遗憾和信息之间的平衡。这种方法通过引入时间相关的学习率来提供一种新的分析方法，使理论上的保证得以延伸，首次实现了在数据丰富和数据贫乏两种情况下都具有最优最坏情况遗憾的算法。", "conclusion": "我们的结果显示SOIDS算法在理论和实际表现上都是非常有效的，为解决高维在线决策问题提供了一个强有力的工具。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24233", "html_url": "https://arxiv.org/abs/2510.24233", "title": "PRIVET: 基于极值理论的隐私度量", "title_en": "PRIVET: Privacy Metric Based on Extreme Value Theory", "authors": "Antoine Szatkownik(TAU, BioInfo),Aurélien Decelle,Beatriz Seoane(TAU),Nicolas Bereux(TAU),Léo Planche(BioInfo),Guillaume Charpiat(TAU),Burak Yelmen,Flora Jay(BioInfo, TAU),Cyril Furtlehner(TAU)", "background": "深度生成模型通常在敏感数据上进行训练，如遗传序列、健康数据或更广泛地说，受版权保护、许可或保护的内容。这引发了隐私保护合成数据方面的关键问题，尤其是隐私泄露问题，与过拟合密切相关。现有方法几乎完全依赖于全局标准来估计与模型相关的隐私失败风险，仅提供非解释性的定量洞察。对于样本级的数据隐私评估缺乏严格的评价方法可能阻碍合成数据在实际应用中的部署。", "innovation": "本文提出了一种名为PRIVET的通用样本基于和模态无关的算法，该算法能够为每个合成样本分配一个个体隐私泄露分数。PRIVET能可靠地检测不同数据模态中的记忆化和隐私泄露，包括高维度数据、样本量有限的数据（如遗传数据）以及尤其是在欠拟合状态下。与现有方法进行实验比较，展示了其在提供数据集级别和样本级别评估方面的优势，并通过定性和定量输出展示了现有计算机视觉嵌入的局限性。", "conclusion": "PRIVET为样本级数据隐私提供了严格的评价方法，能够有效地检测数据泄露和过度拟合。通过使用极值统计在最近邻距离上的极端值理论，PRIVET在不同数据类型中表现出色。该方法的优点在于提供详细的数据集级别和样本级别的评估，从而为实际应用中的合成数据部署提供了有力的工具。然而，现有方法在识别近似重复样本的距离感知方面存在局限性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24318", "html_url": "https://arxiv.org/abs/2510.24318", "title": "Transformer模型可以进行贝叶斯聚类", "title_en": "Transformers can do Bayesian Clustering", "authors": "Prajit Bhaskaran,Tom Viering", "background": "现有的贝叶斯聚类方法虽然可以处理不确定性，但在大数据规模下计算成本高昂。另外，现实数据集中往往包含缺失值，简单的插补方法会忽略不确定性并导致次优结果。", "innovation": "提出了一种基于Transformer的模型Cluster-PFN，扩展了Prior-Data Fitted Networks (PFNs)，用于无监督的贝叶斯聚类。Cluster-PFN在合成数据集上训练，能够学习估计聚类数量和聚类分配的后验分布。与手工制作的模型选择程序（如AIC、BIC和变分推断）相比，Cluster-PFN更准确地估计聚类数量，并在聚类质量方面与变分推断竞争，但速度要快得多。该方法还可以处理包含缺失数据的复杂先验，并在高缺失性真实的基因组数据集上优于基于插补的基线方法。", "conclusion": "研究表明，Cluster-PFN能够提供可扩展且灵活的贝叶斯聚类方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24310", "html_url": "https://arxiv.org/abs/2510.24310", "title": "EDC: 方程发现中的分类问题", "title_en": "EDC: Equation Discovery for Classification", "authors": "Guus Toussaint,Arno Knobbe", "background": "方程发现技术在回归任务中表现出显著的成功，用于发现简洁且可解释的模型（符号回归）。本文围绕这一主题，探讨了一种新的基于方程发现（Equation Discovery，ED）的二元分类框架。", "innovation": "提出了一个新的基于ED的二元分类框架EDC，并使用该方法在人工和实际数据集上发现决策边界的位置和形状。实验表明，EDC能够在二元分类中超越当前最先进的基于ED的方法，其性能与最新的二元分类技术相当。此外，该框架使用的文法具有适度的复杂性，但在必要时可以调整或针对特定领域进行修改，使用了一系列的和项（加法项），包括线性、二次和指数项，以及特征的乘积（生成双曲线曲线，适用于捕捉XOR依赖关系）。这个文法允许相当灵活的决策边界，但不至于导致过拟合。", "conclusion": "EDC通过发现目标方程的结构及其参数值，在二元分类任务中实现了超越现有技术的性能，同时提供了一个灵活且不过于复杂的文法框架。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24235", "html_url": "https://arxiv.org/abs/2510.24235", "title": "PaTaRM：通过偏好感知任务自适应奖励建模连接成对与点信号", "title_en": "PaTaRM: Bridging Pairwise and Pointwise Signals via Preference-Aware Task-Adaptive Reward Modeling", "authors": "Ai Jian,Jingqing Ruan,Xing Ma,Dailin Li,QianLin Zhou,Ke Zeng,Xunliang Cai", "background": "奖励模型（RMs）在基于人类反馈的强化学习（RLHF）中起着核心作用，提供使大型语言模型（LLMs）与人类偏好保持一致的关键监督信号。虽然生成性奖励模型（GRMs）提供了比传统标量RMs更好的可解释性，但当前的训练方法仍然有限。成对的方法依赖于二元好与坏的标签，这对于点预测推理来说会导致不匹配，并需要复杂的配对策略来有效应用于RLHF。另一方面，点式方法需要更加复杂的绝对标定和基于规则的标签，导致适应性差且标注成本高。", "innovation": "提出了偏好感知任务自适应奖励模型（PaTaRM），这是一种统一框架，结合了偏好感知奖励（PAR）机制与动态评价标准适应机制。PaTaRM 利用成对数据中的相对偏好信息来构建强大的点式训练信号，从而消除了需要显式的点式标签。同时，它采用了一种任务自适应的评价标准系统，能够灵活生成与全局任务一致性以及实例特定的精细推理相关的评估准则。这一设计使奖励建模对于RLHF更加高效、具有一般性和可解释性。", "conclusion": "广泛的实验表明，PaTaRM 在 RewardBench 和 RMBench 示例上的平均相对改进率为4.7%，并显著提高了下游RLHF性能，在IFEval和InFoBench基准上的平均改进率为13.6%，证实了其有效性和鲁棒性。我们的代码可从这里获取。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24180", "html_url": "https://arxiv.org/abs/2510.24180", "title": "V-SAT: 视频字幕注释工具", "title_en": "V-SAT: Video Subtitle Annotation Tool", "authors": "Arpita Kundu,Joyita Chakraborty,Anindita Desarkar,Aritra Sen,Srushti Anil Patil,Vishwanathan Raman", "background": "随着流媒体平台和社交媒体上音频视频内容的激增，对准确且易访问的字幕需求大幅上升。然而，现有的字幕生成方法主要是基于语音转录或OCR提取，存在同步差、文本错误或有害信息、格式不一致、阅读速度不合适以及无法适应动态音频视频环境等诸多问题。当前的方法通常仅针对孤立的问题，导致需要大量的人工编辑工作，耗时费力。", "innovation": "本文介绍了一种名为V-SAT（视频字幕注释工具）的统一框架，该框架能够自动检测和修正多种字幕质量问题。V-SAT结合了大语言模型（LLMs）、视觉-语言模型（VLMs）、图像处理和自动语音识别（ASR），利用音视频的上下文线索，显著提高了字幕质量，SUBER分数从9.6降低到3.54，同时图像模式问题的F1分数达到约0.80。通过人机交互验证确保了优质的结果，提供了一种综合解决方案，可以确保字幕的可靠性与准确性，实现了字幕注释的全自动化和高质量输出。", "conclusion": "V-SAT提供了一种全面且高质量的字幕注释解决方案，通过结合和利用多种先进技术，解决了当前字幕生成方法中的诸多问题，为音频视频内容的准确传播提供了强有力的支持。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24273", "html_url": "https://arxiv.org/abs/2510.24273", "title": "SALS：在隐空间中的稀疏注意对于KV缓存压缩", "title_en": "SALS: Sparse Attention in Latent Space for KV cache Compression", "authors": "Junlin Mu,Hantao Huang,Jihang Zhang,Minghui Yu,Tao Wang,Yidong Li", "background": "大型语言模型能够处理扩展上下文的需求日益增加，但在推理过程中，由于关键值（Key-Value）缓存的庞大尺寸和高内存带宽需求，其性能仍面临挑战。尽管先前的研究表明，关键值缓存具有低秩特性，暗示了有效的压缩潜力，但由于现代大规模语言模型中广泛采用的旋转位置嵌入机制（RoPE），朴素的低秩压缩方法会导致严重的准确度降低或产生新的速度瓶颈，因为低秩缓存必须首先重建才能应用RoPE。", "innovation": "本文提出了两项关键见解：首先，应用RoPE到关键字向量增加了它们的方差，从而导致更高的秩；其次，在该空间中，关键字向量在大多数层中保持了大致相同的表示。基于这些见解，本文提出了在隐空间中的稀疏注意力（SALS）框架。该框架通过低秩投影将KV缓存投影到紧凑的隐空间，并在该空间中使用无RoPE的查询-键交互进行稀疏令牌选择，只需重建一小部分重要令牌，即可避免KV缓存重建的开销。", "conclusion": "实验结果表明，SALS通过保持竞争力的准确度实现了SOTA性能。在不同的设置下，SALS实现了6.4倍的KV缓存压缩和5.7倍的注意力操作加速，相较于FlashAttention2，顺序为4K的序列中是如此。对于端到端的吞吐量性能，SALS分别在4k和32K序列中获得了1.4倍和4.5倍的性能提升，相比GPT-fast而言。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24356", "html_url": "https://arxiv.org/abs/2510.24356", "title": "感知学习：感觉表示学习与决策学习的正式分离", "title_en": "Perception Learning: A Formal Separation of Sensory Representation Learning from Decision Learning", "authors": "Suman Sanyal", "background": "该论文提出了一种名为感知学习（PeL）的范式，该范式通过使用任务无关的信号优化智能体的感觉接口，从而与下游决策学习分离。背景在于当前智能系统感觉和决策学习的结合导致了信息损失或几何控制等方面的问题，该论文旨在分离这两部分，以独立地优化感觉和决策。", "innovation": "该论文的创新之处在于提出了感知学习（PeL）范式，通过优化感觉接口直接针对无标签的感觉属性，如抗干扰性、信息性（未崩溃）、几何控制等。此外，还定义了独立于目标或参数化的方法来评估感觉质量和证明感知更新与贝叶斯任务风险梯度正交。", "conclusion": "结论是通过感知学习，能够独立地优化感觉接口，评估感觉质量并证明其与决策学习分离。这为智能体的设计提供了新的视角，允许更有效的无监督学习和独立优化感知特性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24368", "html_url": "https://arxiv.org/abs/2510.24368", "title": "在医疗保健中通过过滤实例和拒绝预测获得可靠模型", "title_en": "Filtering instances and rejecting predictions to obtain reliable models in healthcare", "authors": "Maria Gabriela Valeriano,David Kohan Marzagão,Alfredo Montelongo,Carlos Roberto Veiga Kiffer,Natan Katz,Ana Carolina Lorena", "background": "机器学习（ML）模型在高风险领域，如医疗保健中被广泛使用，但可靠性是关键因素。然而，这些模型往往没有考虑到不确定性，即使在低置信度的情况下也会提供预测结果。本文提出了一种新的两步数据为中心的方法，通过提高数据质量并过滤低置信度的预测，增强ML模型的性能。", "innovation": "该方法采用两步流程：第一步利用实例硬度（IH）在训练期间过滤问题实例，从而精炼数据集；第二步在推理过程中引入基于置信度的拒绝机制，确保只保留可靠的预测。通过三种实际医疗保健数据集的评估，证明该方法在提高模型可靠性的同时，平衡了预测性能和拒绝率。", "conclusion": "结果表明，结合利用实例硬度过滤与基于置信度的拒绝机制有效提升了模型性能，同时保留了大量实例。此方法为在关键安全应用中部署ML系统提供了一种实用的方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24331", "html_url": "https://arxiv.org/abs/2510.24331", "title": "Vision-language models在上下文中学到了什么？探究多模态在上下文中的学习", "title_en": "What do vision-language models see in the context? Investigating multimodal in-context learning", "authors": "Gabriel O. dos Santos,Esther Colombini,Sandra Avila", "background": "在上下文学习（ICL）方面，大型语言模型（LLMs）已经得到广泛研究，但在视觉-语言模型（VLMs）中的应用和效果仍然未被充分探索。这项工作旨在系统地研究VLMs中的ICL，评估了四种架构下的七个模型在三种图像字幕基准测试中的表现，分析了提示设计、架构选择和训练策略如何影响多模态ICL的效果。研究者还发现，训练时采用图-文交错数据可以提升ICL的效果，但这种训练方式并没有有效结合提示示例中的视觉和文本信息。此外，提示调优虽然可以提高模型遵循指令的能力，但可能会减少模型对上下文例子的依赖，表明了指令对齐和上下文适应之间的权衡问题。进一步的研究还表明，当前VLMs主要依赖文本线索，未能充分利用视觉信息，显示出其多模态集成能力的局限性。", "innovation": "首次分析了VLMs在增加上下文示例数量时注意力模式的变化，并发现图-文交错数据训练可以提升ICL性能，但未有效整合视觉和文本信息；提示调优有助于指令遵循但可能减少对上下文示例的依赖，显示了指令对齐和上下文适应之间的权衡；研究还揭示了VLMs在利用视觉信息方面的局限性，指出其多模态集成能力有待提升。", "conclusion": "研究揭示了当前VLMs在ICL能力上的关键局限，并为提升其从多模态上下文示例中学习的能力提供了有价值的见解。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24375", "html_url": "https://arxiv.org/abs/2510.24375", "title": "公共交通中合成行程数据生成的全面评估框架", "title_en": "A Comprehensive Evaluation Framework for Synthetic Trip Data Generation in Public Transport", "authors": "Yuanyuan Wu,Zhenlin Qin,Zhenliang Ma", "background": "智能卡数据在公共交通研究中面临着隐私和可访问性的挑战，合成数据提供了应对这些挑战的有前景的解决方案。尽管生成建模领域取得了快速进展，但关于合成数据的全面评估仍然有限，这使得人们对合成数据的真实可靠性、安全性和实用性存在不确定性。现有评估通常局限于人口级别的代表性或记录级别的隐私性，而没有考虑群体级别的差异或特定任务的实用性。", "innovation": "本文提出了一个代表性和隐私性实用性的（RPU）框架，该框架系统地从记录级、群体级和人口级三个层次评估合成行程数据的相似性、泄露风险和实际用途，通过整合一致的度量标准衡量合成数据的质量，提供了透明和均衡的综合评估方案。研究还涵盖了传统的统计模型、深度生成网络以及增强隐私的生成方法，展示了合成数据无法保证隐私，没有通用模型，并提出有条件表生成对抗网络（CTGAN）是最平衡的解决方案。", "conclusion": "RPU框架为研究人员和从业者提供了跨研究和应用比较合成数据生成技术的系统性和可重复基础，有助于在公共交通领域选择适当的方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24240", "html_url": "https://arxiv.org/abs/2510.24240", "title": "时间知识图谱超边预测：探索实体到类别的链接预测", "title_en": "Temporal Knowledge Graph Hyperedge Forecasting: Exploring Entity-to-Category Link Prediction", "authors": "Edward Markai,Sina Molavipour", "background": "时间知识图已经发展成为一种强大的方式，不仅可以建模实体之间的静态关系，还可以建模这些关系随时间的动态演变。由于这些信息结构可以从现实世界的应用场景中获取信息，如新闻流，因此预测图组件有助于预测现实世界中的事件。该领域的大部分研究集中在嵌入式方法上，通常利用卷积神经网络架构。这些解决方案作为黑盒工作，限制了它们提供的洞察力。该论文旨在探索对一个已建立的基于规则的框架TLogic的扩展，以提高预测准确性并提供可解释的预测结果。新的规则格式将实体类别作为关键组成部分，目的是仅在相关实体上应用规则。当构建图时类别未知，我们提出了一种基于大语言模型的方法来生成它们。此外，我们还研究了在执行类别预测时，累积检索实体得分的方法选择问题。", "innovation": "该论文提出了一种将实体类别作为关键组成部分的新规则格式，增强了基于规则的框架TLogic的解释能力。当类别未知时，提出了一种数据驱动的方法来生成类别。还研究了累积检索实体得分的方法选择问题。这些创新提供了透明度，使最终用户在预测阶段能够批判性地评估所应用的规则。", "conclusion": "通过将实体类别作为关键组成部分整合到现有的基于规则的框架TLogic中，该研究为时间知识网络的未来预测提供了高准确性和可解释性的模型。提出的基于大语言模型的方法可以自动识别和生成类别，为未知类别提供了解决方案。此外，对累积检索实体得分方法的研究有助于进一步优化预测模型。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24482", "html_url": "https://arxiv.org/abs/2510.24482", "title": "连续时间RL中的高效且可扩展探索", "title_en": "Sample-efficient and Scalable Exploration in Continuous-Time RL", "authors": "Klemens Iten,Lenart Treven,Bhavya Sukhija,Florian Dörfler,Andreas Krause", "background": "强化学习算法通常设计用于离散时间动态系统，但实际控制系统的动态往往是连续的。现有的研究主要关注离散时间强化学习，且较少涉及连续时间下的强化学习问题。因此，该论文研究了基于未知非线性常微分方程的连续时间强化学习问题。", "innovation": "提出了名为COMBRL的新算法，该算法通过贪婪地最大化外生奖励和模型表征不确定性的加权和，来实现连续时间强化学习的可扩展和样本高效性。另外，论文提供了无外生奖励情况下的样本复杂性边界，并证明了COMBRL在奖励驱动和无监督强化学习设置下的表现。", "conclusion": "研究成果表明，COMBRL在标准和无监督RL设置下表现良好，相较于之前的方法更具有可扩展性，更加样本高效，并在多个深度RL任务中表现优于基准方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24500", "html_url": "https://arxiv.org/abs/2510.24500", "title": "MIMIC-Sepsis: 用于重症监护室中脓毒症轨迹建模和学习的精心构建基准", "title_en": "MIMIC-Sepsis: A Curated Benchmark for Modeling and Learning from Sepsis Trajectories in the ICU", "authors": "Yong Huang,Zhongqi Yang,Amir Rahmani", "background": "严重脓毒症是重症监护病房（ICUs）中导致死亡的主要原因之一，但现有的研究通常依赖于过时的数据集、不可重复的预处理管道以及临床干预措施的覆盖率有限。", "innovation": "我们引入了MIMIC-Sepsis，这是一个从MIMIC-IV数据库中精心构建的队列和基准框架，旨在支持脓毒症轨迹可重复建模。我们提出了基于Sepsis-3标准的透明预处理管道、结构化填补策略以及治疗变量的纳入，并释放了聚焦于早期死亡预测、住院天数估计及休克发生分类的基准任务。实证结果显示，治疗变量的纳入显著提升了模型性能，特别是在Transformer架构中的表现。", "conclusion": "MIMIC-Sepsis作为一个坚实的研究平台，用于评估关键护理领域的预测和序列模型。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24380", "html_url": "https://arxiv.org/abs/2510.24380", "title": "APEX: 近似但彻底的搜索方法用于超大规模组合合成库", "title_en": "APEX: Approximate-but-exhaustive search for ultra-large combinatorial synthesis libraries", "authors": "Aryan Pedawi,Jordi Silvestre-Ryan,Bradley Worley,Darren J Hsu,Kushal S Shah,Elias Stehle,Jingrong Zhang,Izhar Wallach", "background": "现有的制造即用型组合合成库（CSLs），如Enamine REAL，显著推动了药物发现工作。然而，这些库的庞大体量给虚拟筛选带来了挑战。虚拟筛选的目的是根据计算目标（例如，优化对接分数）和约束条件，在有限的计算预算下识别出最具有潜力的化合物。对于当前几十亿级化合物的库和目标分数函数，一次常规的虚拟筛选活动可能只能评估不到0.1%的化合物，导致许多高分化合物未能被发现。此外，当虚拟筛选过程中出现约束条件或目标变化时，现有的筛选算法通常难以实现有效的时间成本补偿。", "innovation": "本文提出了一种近似但彻底的搜索协议（APEX），利用神经网络进行预测优化，使得在消费者级别的GPU上几分钟内就能完成穷尽搜索，从而实现接近理想的顶级化合物集检索。这种方法主要用于超大规模的组合合成库的虚拟筛选任务中，能够显著提高筛选的准确性和效率。通过构建超大型基准组合合成库（包含超过1000万个化合物，并附有多种医学相关目标的对接分数以及RDKit测量的物理化学性质），作者展示了APEX在检索精度和运行时间上的优越性能。", "conclusion": "APEX方法能够在保证一定检索精度的前提下，大幅度减少筛选所需的时间，这为超大规模组合合成库的虚拟筛选提供了新的解决方案。实验结果表明，相比于其他方法，APEX在检索准确性和运行时间上具有明显的优势。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24473", "html_url": "https://arxiv.org/abs/2510.24473", "title": "用于生存分析的机器学习算法比较方法", "title_en": "Methodology for Comparing Machine Learning Algorithms for Survival Analysis", "authors": "Lucas Buk Cardoso,Simone Aldrey Angelo,Yasmin Pacheco Gil Bonilha,Fernando Maia,Adeylson Guimarães Ribeiro,Maria Paula Curado,Gisele Aparecida Fernandes,Vanderlei Cunha Parro,Flávio Almeida de Magalhães Cipparrone,Alexandre Dias Porto Chiavegatto Filho,Tatiana Natasha Toporcov", "background": "该研究对比分析了六种机器学习模型在生存分析（MLSA）中的性能。研究使用了来自圣保罗医院癌症登记处的近45,000名结直肠癌患者的资料，评估了Random Survival Forest (RSF)、Gradient Boosting for Survival Analysis (GBSA)、Survival SVM (SSVM)、XGBoost-Cox (XGB-Cox)、XGBoost-AFT (XGB-AFT) 和LightGBM (LGBM) 六种模型在处理截尾数据时的生存预测能力。", "innovation": "研究利用不同的采样器对超参数进行了优化，并使用Concordance Index (C-Index)、C-Index IPCW、时间依赖AUC和Integrated Brier Score (IBS)来评估模型性能。研究还使用SHAP和置换重要性对预测因子进行了解释，并比较了模型生成的生存曲线与分类算法的预测结果。XGB-AFT模型取得了最佳性能（C-Index = 0.7618；IPCW = 0.7532），其次是GBSA和RSF，突显了MLSAP在提高生存预测和辅助决策中的潜力和适用性。", "conclusion": "XGB-AFT、GBSA和RSF在模型性能评估指标上表现最优，证实了MLSAP在生存分析中的应用价值，能够提升生存预测准确性和辅助临床决策。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24574", "html_url": "https://arxiv.org/abs/2510.24574", "title": "DistDF: 时间序列预测需要联合分布 Wasserstein 对齐", "title_en": "DistDF: Time-Series Forecasting Needs Joint-Distribution Wasserstein Alignment", "authors": "Hao Wang,Licheng Pan,Yuan Lu,Zhixuan Chu,Xiaoxi Li,Shuting He,Zhichao Chen,Haoxuan Li,Qingsong Wen,Zhouchen Lin", "background": "时间序列预测模型的训练需要使模型预测的条件分布与标签序列的分布相匹配。标准直接预测（DF）方法通常是通过最小化标签序列的条件负对数似然来实现这一目标，这通常使用均方误差估算。然而，在存在标签自相关性的条件下，这种估算可能会导致偏差。", "innovation": "本文提出了DistDF，通过交替最小化条件预测和标签分布之间的偏离来实现对齐。由于从有限的时间序列观测中难以估计条件偏离，本文引入了一种新的时间序列预测联合分布 Wasserstein 偏离，可以证明该偏差可以上界出目标的条件偏离。该偏离可以实现可计算和可微分的估计，并且可以与基于梯度的训练无缝集成。", "conclusion": "广泛的实验证明，DistDF 能够提升多种预测模型的性能，并达到最新的预测性能。相关代码可在提供的链接中获取。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24577", "html_url": "https://arxiv.org/abs/2510.24577", "title": "物理信息化的极端学习机（PIELM）：机遇与挑战", "title_en": "Physics-Informed Extreme Learning Machine (PIELM): Opportunities and Challenges", "authors": "He Yang,Fei Ren,Hai-Sui Yu,Xiaohui Chen,Pei-Zhi Zhuang", "background": "近年来，物理信息化的极端学习机（PIELM）在物理信息机器学习中展现出更高的计算效率和更高的准确性，但目前还没有对其的总结或综述文章。", "innovation": "本文通过展现作者们对PIELM的观点和经验，为这个有前景的研究方向提供了新的视角。许多努力都集中在解决具有尖锐梯度、非线性、高频行为、严格限制、不确定性和多物理场耦合的偏微分方程。", "conclusion": "尽管取得了成功，PIELM仍面临许多亟待解决的挑战，这些挑战也为开发更稳健、可解释和通用的PIELM框架提供了机会，这些框架具有在科学和工程中的应用潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24503", "html_url": "https://arxiv.org/abs/2510.24503", "title": "局部性能与离散外分布泛化：异构数据环境中个性化联邦学习的实证分析", "title_en": "Local Performance vs. Out-of-Distribution Generalization: An Empirical Analysis of Personalized Federated Learning in Heterogeneous Data Environments", "authors": "Mortesa Hussaini,Jan Theiß,Anthony Stein", "background": "在联邦学习的异构数据环境中，本地模型在本地训练步骤中往往会收敛到各自的局部最优模型，偏离全局数据分布。使用如FedAvg的聚合方法时常导致偏离全局最优模型（客户端偏差），从而产生不佳的更新效果。个性化联邦学习方法试图通过专注于客户端模型在其自身数据分布上的平均性能来应对这一挑战。然而，这些方法未充分考虑离散外分布样本的泛化能力，这是FedAvg的核心优势之一，对于强化模型的鲁棒性至关重要。该研究旨在全面评估联邦学习方法，不仅关注它们的局部性能，还关注它们的泛化能力。为此，研究探讨了单一通信轮中的不同阶段，以便对所考虑的指标有更细致的理解。此外，提出了一种修改的FedAvg方法，称为个体化更新的联邦学习（FLIU），通过一个简单的个体化步骤和自适应个性化因子扩展算法。", "innovation": "研究提出了一种增量的FedAvg方法，称为FLIU，通过引入一个简单的个体化步骤和自适应个性化因子来增强联邦学习方法。同时，研究还致力于均衡评估联邦学习方法的局部性能和泛化能力，特别是在异构数据环境中。实验使用MNIST和CIFAR-10数据集，涵盖了不同的分布条件，包括基准的IID和病态的非IID，以及特定的狄利克雷分布式测试环境。", "conclusion": "研究表明，局部性能与离散外分布泛化是评估个性化联邦学习方法的两个重要的指标。FLIU通过优化个体化更新的方法和自适应调整个性化因子，能够在复杂的异构数据环境中提高模型的性能和鲁棒性。相较于标准的FedAvg，FLIU在局部性能和泛化能力上展示了显著的改进。未来研究可以进一步探索更多个性化策略及其对联邦学习算法的影响，尤其是在更加复杂的分布条件下。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24561", "html_url": "https://arxiv.org/abs/2510.24561", "title": "LoRA-DA：通过渐近分析实现数据感知低秩适应的初始化方法", "title_en": "LoRA-DA: Data-Aware Initialization for Low-Rank Adaptation via Asymptotic Analysis", "authors": "Qingyue Zhang,Chang Chu,Tianren Peng,Qi Li,Xiangyang Luo,Zhihao Jiang,Shao-Lun Huang", "background": "随着大规模语言模型（LLMs）的普及，低秩适应性调整（LoRA）已成为可参数化微调（PEFT）的主导方法，其初始化方法吸引了越来越多的关注。然而，现有的方法存在明显限制：许多方法未利用目标领域数据，而基于梯度的方法仅通过一阶梯度分解浅层次地利用数据，这因其基础的一阶段微调模型的弱实证性能而不足，同时这些方法要么缺乏严谨的理论基础，要么依赖于严格的各向同性假设。", "innovation": "本文建立了一个基于渐近分析的数据感知LoRA初始化的理论框架。从一个一般化的优化目标出发，该目标旨在最小化细调模型和目标模型之间的参数偏差的期望值，推导出一个包含偏差项和方差项的优化问题。偏差项通过保留张量特性来近似采用费舍尔梯度形式计算，而方差项则考虑了使用费舍尔信息量引入的采样随机性。通过求解该问题，我们获得了LoRA的最优初始化策略。基于该理论框架，我们开发了一个高效的算法LoRA-DA，该算法从少量目标领域样本中估计优化问题中的项，并获得最优的LoRA初始化。", "conclusion": "在多个基准测试中的实验证明，LoRA-DA在最终准确性上优于现有初始化方法。此外的研究还显示了更快、更稳定的收敛性、在不同秩数下具有鲁棒性和仅轻微的初始化开销。源代码将在发表后公开。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24633", "html_url": "https://arxiv.org/abs/2510.24633", "title": "Symbolic Snapshot Ensembles", "title_en": "Symbolic Snapshot Ensembles", "authors": "Mingyue Liu,Andrew Cropper", "background": "归纳逻辑编程（ILP）是一种形式的逻辑机器学习。大多数ILP算法仅在单次训练过程中学习一个假设。集成方法则是对ILP算法进行多次训练以学习多个假设。该研究通过仅训练一次ILP算法并保存中间假设，然后使用最小描述长度加权方案结合这些假设，探索了一种新的方法来提高预测准确性。该方法在多个基准测试中得到了验证，包括游戏玩法和视觉推理，结果显示此方法的预测准确性提高了4%，且计算开销低于1%。", "innovation": "该方法的独特之处在于仅需一次ILP训练过程，通过保存中间假设并使用最小描述长度加权方案结合这些假设，从而在减少计算开销的同时提高预测准确性。这种新的方法创新性地应用于游戏和视觉推理任务中，验证了其有效性和高效性。", "conclusion": "实验结果显示，该方法在多个领域的基准测试中提高了4%的预测准确性，且计算开销低于1%。该方法为提高ILP在实际应用中的表现提供了一种新的途径。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24598", "html_url": "https://arxiv.org/abs/2510.24598", "title": "一种用于MaNGA星系速度位展建模的新型可解释性增强量子对抗网络", "title_en": "A Novel XAI-Enhanced Quantum Adversarial Networks for Velocity Dispersion Modeling in MaNGA Galaxies", "authors": "Sathwik Narkedimilli,N V Saran Kumar,Aswath Babu H,Manjunath K Vanahalli,Manish M,Vinija Jain,Aman Chadha", "background": "当前的量子机器学习方法在预测精度、鲁棒性和可解释性之间常常很难找到很好的平衡。因此，本文旨在通过将混合量子神经网络（QNN）与经典的深度学习层结合，经由具有LIME基可解释性的评估模型，扩展到量子生成对抗网络（GAN）和自监督变体中，提出一个新的量子对抗框架来解决上述问题。", "innovation": "提出一种新型的可解释性增强量子对抗网络。该网络结合了混合量子神经网络与经典的深度学习层，并通过评估模型中的LIME指导，同时利用量子生成对抗网络和自监督变体进行扩展。评估模型通过计算反馈损失，同时指导量子神经网络优化预测准确性和模型可解释性。试验结果显示，该模型在预测性能方面提供了较为一致的表现，优于其他对抗性模型。这展示了结合受量子启发的方法与经典架构，开发轻量、高性能和可解释的预测模型的潜力，从而进一步扩大了量子机器学习的应用范围，超越了当前限制", "conclusion": "所提出的量子对抗网络模型能够提供在回归指标上较为一致的性能表现，体现了结合经典架构与量子启发方法在构建可解释的预测模型方面的潜力。这种方法有望克服当前量子机器学习方法在预测准确性、鲁棒性和可解释性之间的平衡问题，从而推动量子机器学习的应用和发展。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24614", "html_url": "https://arxiv.org/abs/2510.24614", "title": "航空航天复合结构中超导波中健康指标的半监督和无监督学习", "title_en": "Semi-supervised and unsupervised learning for health indicator extraction from guided waves in aerospace composite structures", "authors": "James Josep Perry,Pablo Garcia-Conde Ortiz,George Konstantinou,Cornelie Vergouwen,Edlyn Santha Kumaran,Morteza Moradi", "background": "航空航天复合结构的健康指标（HIs）对于诊断和预估结构状态至关重要，有助于高效维护和运营安全。但由于材料性质的差异性、随机损伤演化以及多种损伤模式的存在，可靠健康指标的提取仍然是一个挑战。特别是制造缺陷（如脱粘）和服役过程中的意外事件（如鸟类撞击）进一步复杂化了这一过程。", "innovation": "本文提出了一种全面的数据驱动框架，该框架通过结合多域信号处理的两种学习方法来学习健康指标。提出了一种多样化深度半监督异常检测（Diversity-DeepSAD）方法，补全了过去仅能区分健康和失效状态的二元标签的不足；同时引入了一个退化趋势约束变分自动编码器（DTC-VAE），通过显式的趋势约束嵌入了单调性标准。此外，使用多频驱动波监测疲劳加载条件下单肋复合结构，探索了时间、频率和时频表示，并通过无监督集成学习融合了每频率的健康指标，从而减轻频率依赖性和减少方差。", "conclusion": "利用快速傅里叶变换特征，增强后的Diversity-DeepSAD模型实现了81.6%的性能，而DTC-VAE则提供的健康指标表现最为一致，达到92.3%的性能，超越了现有基准。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24639", "html_url": "https://arxiv.org/abs/2510.24639", "title": "时间序列因果结构学习中的因果排序", "title_en": "Causal Ordering for Structure Learning From Time Series", "authors": "Pedro P. Sanchez,Damian Machlanski,Steven McDonagh,Sotirios A. Tsaftaris", "background": "预测时间序列数据中的因果结构对于理解生理学、脑连接性、气候动力学和社会经济行为中的复杂现象至关重要。然而，随着变量数量和时间点的增长，识别真实的因果关系具有组合复杂性，传统的排序方法因其单一的因果排序限制了模型的表示能力。现有方法难以克服这一限制，通过整合多个有效的因果排序，本文提出了一种新的方法DOTS（Diffusion Ordered Temporal Structure），有效恢复了底层有向无环图的传递闭包，减少了单排序方法固有的虚假结果。在标准假设（如平稳性和加性噪声模型）下，通过扩散过程的评分匹配进行高效的Hessian估计。大量实验验证了方法的有效性。", "innovation": "本文创新地提出了一种新的时间序列因果结构学习方法DOTS，通过整合多个有效的因果排序克服了传统方法中单排序的限制，有效提高因果恢复的准确性，同时保持了较高的算法效率。在合成数据集和CausalTime真实世界数据集上的实验证明，DOTS取得了显著的性能提升，特别是在平均窗口图F1评分上提高了约20%，同时大大缩短了运行时间。", "conclusion": "本文提出的DOTS方法为时间序列因果发现提供了一种可扩展且准确的解决方案。在合成和真实世界的实验中，DOTS在F1评分上超越了最先进的基线方法，并展现出显著的性能和效率优势。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24670", "html_url": "https://arxiv.org/abs/2510.24670", "title": "珍珠：用于准确放置每个原子的位置的基础模型", "title_en": "Pearl: A Foundation Model for Placing Every Atom in the Right Location", "authors": "Genesis Research Team:Alejandro Dobles,Nina Jovic,Kenneth Leidal,Pranav Murugan,David C. Williams,Drausin Wulsin,Nate Gruver,Christina X. Ji,Korrawat Pruegsanusak,Gianluca Scarpellini,Ansh Sharma,Wojciech Swiderski,Andrea Bootsma,Richard Strong Bowen,Charlotte Chen,Jamin Chen,Marc André Dämgen,Roy Tal Dew,Benjamin DiFrancesco,J. D. Fishman,Alla Ivanova,Zach Kagin,David Li-Bland,Zuli Liu,Igor Morozov,Jeffrey Ouyang-Zhang,Frank C. Pickard IV,Kushal S. Shah,Ben Shor,Gabriel Monteiro da Silva,Maxx Tessmer,Carl Tilbury,Cyr Vetcher,Daniel Zeng,Maruan Al-Shedivat,Aleksandra Faust,Evan N. Feinberg,Michael V. LeVine,Matteus Pan", "background": "蛋白质-配体复合物的三维结构准确预测是计算药物发现中的一个基本挑战，这限制了治疗设计的速度和成功率。虽然深度学习方法已经显示出作为结构预测工具的强有力潜力，但它们的表现和实用性受到了实验数据稀缺、架构效率低下、物理上无效的构型以及在推理时难以利用辅助信息的限制。", "innovation": "Pearl通过三大创新解决了这些问题：1) 使用大规模合成数据进行训练的食谱，以克服数据稀缺；2) 结合SO(3)-对称扩散模块的架构，以内在尊重三维旋转对称性，提高泛化能力和样本效率；3) 可控推理，包括支持蛋白质和非聚合物组件的通用多链模板系统以及双重无条件/条件模式。Pearl在蛋白质-配体共折叠领域建立了新的最高技术水平。", "conclusion": "Pearl在公共Runs N' Poses和PoseBusters基准上的关键指标上生成了准确（RMSD < 2 Å）且物理上有效的构型，超越了AlphaFold 3和其他开源基线，分别提供了14.5%和14.2%的改进。在更严格的RMSD < 1 Å阈值下，对于一组更具挑战性的现实药物靶点，Pearl在口袋条件共折叠领域实现了3.6倍的改进。我们还展示了模型性能与用于训练的合成数据集大小直接相关性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24700", "html_url": "https://arxiv.org/abs/2510.24700", "title": "Greedy Sampling Is Provably Efficient for RLHF", "title_en": "Greedy Sampling Is Provably Efficient for RLHF", "authors": "Di Wu,Chengshuai Shi,Jing Yang,Cong Shen", "background": "Reinforcement Learning from Human Feedback (RLHF) is a crucial technique for training large language models after initial deployment. While RLHF has achieved empirical success, its theoretical foundation remains limited because learning with only preference feedback (as opposed to reward-based feedback) introduces unique challenges compared to traditional reinforcement learning methods. Most existing research focuses on specific preference models and extends classical optimistic or pessimistic approaches. However, this paper explores the general preference model and provides significant performance improvements over previous methods.", "innovation": "该论文创新地研究了适用于KL-正则化目标的一般偏好模型，并展示了直接使用经验估计（贪婪采样）的算法可以带来显著的性能提升，而不需要构造具有乐观或悲观估计的传统方法。这一发现源于KL-正则化目标下最优策略类的独特结构属性，并进一步专门应用于Bradley-Terry模型，突显了贪婪采样在RLHF中的意外有效性。", "conclusion": "通过直接使用经验估计（贪婪采样），该研究获得了对现有方法进行改进的性能保证，且结论证明了在KL-正则化目标下，贪婪采样的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16620", "html_url": "https://arxiv.org/abs/2510.16620", "title": "反馈午餐：无线窃听信道的深度反馈码", "title_en": "Feedback Lunch: Deep Feedback Codes for Wiretap Channels", "authors": "Yingyao Zhou,Natasha Devroye,Onur Günlü", "background": "我们考虑的是逆退化窃听信道，在这种信道中如果没有任何反馈流，则秘密容量为零。本研究着眼于结合通用哈希函数和基于反馈的编码策略，利用信道输出反馈在高斯窃听信道中设计分组码，以实现积极的秘密率。", "innovation": "提出了一个创新的编码设计方案，将通用哈希函数用于安全防护，结合基于学习反馈的编码策略以提高可靠性和信息泄漏之间的权衡，解锁了反馈在允许合法方达成共享秘密密钥方面的能力，进而克服了窃听者的安全优势。", "conclusion": "我们的研究结果表明，在使用反馈的信道环境中，编码设计应着重于评估通信可靠性与信息泄露之间的权衡。此外，还强调了用于传感辅助安全通信的设计，这些设计将用于下一代综合传感与通信方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24672", "html_url": "https://arxiv.org/abs/2510.24672", "title": "有序表示学习中的本征函数提取", "title_en": "Eigenfunction Extraction for Ordered Representation Learning", "authors": "Burak Varıcı,Che-Ping Tsai,Ritabrata Ray,Nicholas M. Boffi,Pradeep Ravikumar", "background": "近年来，表示学习的进步揭示了广泛应用的目标，如对比和非对比方法，实际上在输入与其上下文的关系诱导的上下文内核中隐式执行谱分解。然而，这些方法只能恢复内核的线性子空间中的顶级本征函数，而完整的谱分解对于理解特征排序和重要性至关重要。因此，本文探讨了如何提出一个通用框架来提取有序且可识别的本征函数，并通过模块化构建块及其关键属性来实现这一点。随后概述了两种主要的方法论范式——低秩逼近和Rayleigh商优化，以符合这种本征函数提取的框架。最后通过合成内核和现实世界图像数据集来验证方法的有效性，表明恢复的本征值作为特征选择的有效重要性得分，支持在可适应维度表征方面的效率-准确性的权衡。", "innovation": "本文提出了一种通用框架来提取有序和可识别的本征函数，该框架基于满足关键需求的模块化构建块设计，包括与上下文内核的兼容性和适用于现代环境的可扩展性。同时也指出了两种主要的方法论范式如何与这种框架相结合进行本征函数提取。另外，该方法在合成内核和真实图像数据集上的验证表明，恢复的本征值可以用作有效的特征重要性得分，从而在表征维度上实现效率与准确性的折中。", "conclusion": "通过这种通用框架，本文成功地实现了有针对性的本征函数提取，既实现了有序的特征排序与识别，又具有可扩展性和实际应用的有效性。这种方法提供了一种一体化的策略，用于在现代数据环境中进行有指导的表示学习。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23643", "html_url": "https://arxiv.org/abs/2510.23643", "title": "SAND: 自监督和自适应NAS驱动的硬件木马检测框架", "title_en": "SAND: A Self-supervised and Adaptive NAS-Driven Framework for Hardware Trojan Detection", "authors": "Zhixin Pan,Ziyu Shu,Linh Nguyen,Amberbir Alemayoh", "background": "全球化的半导体供应链使得硬件木马（HT）成为嵌入式系统中一个重大的安全威胁，因此需要设计高效和适应性强的检测机制。尽管文献中提出了许多基于机器学习的硬件木马检测技术，但这些技术在特征选择方面往往是随意的，并且缺乏适应性，这阻碍了它们在不同类型的硬件木马攻击中的有效性。", "innovation": "本文提出了一种自监督和自适应的基于NAS的框架SAND，用于高效的硬件木马检测。具体来说，本文做出了三个关键贡献：1. 利用自监督学习(SSL)实现自动特征提取，去除手动工程特征的依赖。2. 将神经架构搜索（NAS）集成到下游分类器中，使其能够动态优化并且能够在最少微调的情况下无缝适应新的基准。3. 实验结果显示，SAND在检测准确性上较先进方法提高了高达18.3%，并且在对抗性木马攻击方面表现出高度的鲁棒性，同时具有较强的泛化能力。", "conclusion": "实验结果表明，SAND在检测精度方面显著优于最先进的方法，对隐蔽的木马攻击具有高度的鲁棒性，并且具有良好的泛化性能，证明了SAND框架的有效性和优越性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00778", "html_url": "https://arxiv.org/abs/2509.00778", "title": "能效精确和近似 systolic 阵列架构用于矩阵乘法", "title_en": "Energy Efficient Exact and Approximate Systolic Array Architecture for Matrix Multiplication", "authors": "Pragun Jaswal,L.Hemanth Krishna,B. Srinivasu", "background": "深度神经网络（DNNs）需要高效的能量密集型矩阵乘法引擎来执行复杂计算。现阶段的设计存在节能减排的需求和挑战，本文侧重研究低功耗的 systolic 阵列架构，并介绍了新型精确和近似处理单元（PEs）的设计和实现方法。这些处理单元利用能量高效的正部分积和负部分积单元，分别称为 PPC 和 NPPC。所提出的 8 位精确和近似 PE 设计应用于 8x8 systolic 阵列，展示了显著的能源节省，与现有设计相比，精确 PE 降低 22% 的能耗，而近似 PE 降低 32% 的能耗。实验结果表明，这些处理单元在离散余弦变换和卷积边缘检测等应用中表现出色。", "innovation": "本文提出了几乎和近似的 systolic 阵列架构及其精确和近似处理单元（PEs）的新型设计，融合利用了能量高效的正部分积和负部分积单元（PPC 和 NPPC）。利用该设计，在 8x8 systolic 阵列中，惊艳的降低了能量消耗，分别达到了 22% 和 32% 的降低比例。并且，实验应用表明，该架构在离散余弦变换和卷积边缘检测等应用中展现出高效的性能。该设计充分利用 PPC 和 NPPC 实现优秀的低能耗和高质量输出，适用于具有容错性的图像和视觉处理应用。", "conclusion": "本文所提出的 systolic 阵列架构及相应的 PE 设计，成功实现了显著的能源效率提升，同时也保持了高质量输出。该设计完美平衡了能效和输出质量，使其非常适合用于误差容忍的视觉和图像处理应用。这些创新性的研究成果为构建高效和具有容错性的神经网络系统提供了强大的支持。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23662", "html_url": "https://arxiv.org/abs/2510.23662", "title": "JiuTian Chuanliu: 一个大型时空模型以支持通用动态城市感知", "title_en": "JiuTian Chuanliu: A Large Spatiotemporal Model for General-purpose Dynamic Urban Sensing", "authors": "Liangzhe Han,Leilei Sun,Tongyu Zhu,Tao Tao,Jibin Wang,Weifeng Lv", "background": "人类移动性是城市感知的窗口，包含了反映居民行为偏好和城市功能的丰富时空信息。然而，现有方法往往专注于具体任务，并从特定视角分析人类移动性，导致缺乏对移动性的全面建模，并限制了所学知识在多种下游应用中的实际应用。", "innovation": "本文提出了一个大规模且广覆盖的人类移动性数据框架——通用和动态人类移动嵌入（GDHME），将其推入时空模型中，发现移动行为背后的潜在语义，并支持各种城市感知任务。该框架遵循自监督学习理念，包含两个主要阶段。第一阶段将人类与地区视为动态图中的节点，统一人类移动数据作为人-地-时的交互，动态计算节点表示，捕捉人和区域的动态状态，并特别设计自回归自监督任务来指导通用节点嵌入的学习。第二阶段利用这些表示支持各种任务的完成。", "conclusion": "通过在大规模数据上的离线实验，GDHME展示了其自动从大量数据中学习有价值的节点特征的能力。此外，框架被用于部署在2023年中国移动全球合作伙伴会议中展示的JiuTian ChuanLiu大模型。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23638", "html_url": "https://arxiv.org/abs/2510.23638", "title": "通过负微分电阻网络架起函数逼近与器件物理的桥梁", "title_en": "Bridging Function Approximation and Device Physics via Negative Differential Resistance Networks", "authors": "Songyuan Li,Teng Wang,Jinrong Tang,Ruiqi Liu,Yuyao Lu,Feng Xu,Bin Gao,Xiangwei Zhu", "background": "实现完全模拟的神经计算需要硬件能够原生高效地执行线性和非线性操作。虽然模拟矩阵-向量乘法已经通过计算就地架构得到了发展，但非线性激活函数仍然是一个瓶颈，通常需要数字或混合解决方案。现有的解决方案主要集中在计算就地架构上的矩阵-向量乘法，而对于如何高效地实现复杂的非线性操作，特别是基于负微分电阻器件的应用尚未得到充分研究。", "innovation": "受Kolmogorov-Arnold框架启发，本文提出了KANalogue，一种使用隧道二极管（NbSi2N4/HfSi2N4异质结构）作为可学习单变量基函数的物理实现的Kolmogorov-Arnold网络（KANs）的完全模拟实现。通过利用隧道二极管固有的负微分电阻特性，构造了具有不同曲线和支撑配置的坐标方向的非线性函数。通过从制造的二型和六型二极管中提取I-V数据，软件拟合高阶多项式来模拟二极管行为，并使用这些学习到的基函数在视觉基准测试中训练KANs。结果表明，KANalogue能够使用最少的参数逼近复杂的函数，同时保持与数字基线相当的分类准确性。", "conclusion": "本工作结合了器件级物理和函数逼近理论，为可扩展、高效能模拟机器学习系统的实现铺平了道路。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24674", "html_url": "https://arxiv.org/abs/2510.24674", "title": "学习使用混合选项安全驾驶", "title_en": "Learning to Drive Safely with Hybrid Options", "authors": "Bram De Cooman,Johan Suykens", "background": "在众多针对自主驾驶的深度强化学习方法中，仅有少数使用了选项（或技能）框架。出乎意料的是，这一框架竟适用于复杂的层次控制应用，特别是自主驾驶任务。因此，本文将选项框架应用于高速公路下的自主驾驶任务，具体定义了用于纵向和横向操作的专用选项，并嵌入了安全和舒适约束，从而将先验领域的知识融入学习过程，使学到的驾驶行为更容易受到约束。", "innovation": "本文提出了几种层次控制框架的设置，开发了遵循最新的强化学习技术的实用算法。通过分别选择纵向和横向控制的动作，引入的混合选项的策略获得了与人类驾驶员相同的表达能力和灵活性，同时比传统的基于连续动作的策略更容易解释。在所有研究的方法中，这些基于混合选项的灵活策略在各种交通条件下表现最佳，超越了基线动作策略的表现。", "conclusion": "通过应用和定制选项框架，本文的混合选项策略在自主驾驶中获得了优异的表现，尤其是能够更好地处理复杂的驾驶场景，为自主驾驶技术的进一步发展提供了新的思路。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23702", "html_url": "https://arxiv.org/abs/2510.23702", "title": "在搜寻未知的未知：天文学调查中跨距离范式集成的超出分布异常检测", "title_en": "In Search of the Unknown Unknowns: A Multi-Metric Distance Ensemble for Out of Distribution Anomaly Detection in Astronomical Surveys", "authors": "Siddharth Chaini,Federica B. Bianco,Ashish Mahabal", "background": "距离基方法涉及特征间的距离计算，在机器学习中是一个成熟的范式。在异常检测中，异常被识别为其与正常数据点之间的大距离。然而，这些方法的性能通常取决于单一的用户选择的距离度量（例如，欧几里得距离），这可能不适合天文学中常见的复杂、高维特征空间。", "innovation": "提出了一种新的异常检测方法，DiMMAD（Distance Multi-Metric Anomaly Detection），它使用多种距离度量的集成来发现新颖性。这种方法克服了距离度量选择的问题，利用一个鲁棒的多样化距离度量集合来生成不受单一距离定义依赖的异常评分。", "conclusion": "通过使用多距离度量的方法，DiMMAD 在超出分布的异常检测中表现出色，能够发现新的类别，优于现有的最先进的方法。对于常见的在分布异常检测，DiMMAD 与其他方法表现相似，但可能提供更好的可解释性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23666", "html_url": "https://arxiv.org/abs/2510.23666", "title": "超越正态分布：非高斯数据下的可靠A/B测试", "title_en": "Beyond Normality: Reliable A/B Testing with Non-Gaussian Data", "authors": "Junpeng Gong,Chunkai Wang,Hao Li,Jinyong Ma,Haoxuan Li,Xu He", "background": "A/B 测试已成为在线市场决策的基石，指导平台推出新功能、优化定价策略和改善用户体验。通常使用配对 t 检验来比较实验组和对照组的结果，从而评估特定策略的有效性。然而，当数据分布偏离正态或实验组和对照组样本大小不同时，常用的配对 t 检验不再可靠，可能导致错误的结论。因此，需要量化偏斜和长尾数据及样本分配不均对误差率的影响，以及推导出确保 t 检验可靠的最小样本量公式。", "innovation": "本文量化了偏斜、长尾数据和样本不均对误差率的影响，并推导出 t 检验保持有效的最小样本量公式。此外，引入了基于 Edgeworth 的校正方法，以在样本量有限时更准确地计算 p 值，并通过在线实验验证了理论最小样本量阈值的有效性，证明了校正方法在实际条件下的可靠性增强。", "conclusion": "许多在线反馈指标需要数亿样本才能确保可靠的 A/B 测试。因此，本文提出了一种基于 Edgeworth 的校正方法，当可用样本量有限时，可以提供更准确的 p 值，从而显著提高 A/B 测试的可靠性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23772", "html_url": "https://arxiv.org/abs/2510.23772", "title": "在体外评估创造力：AI象棋布局的专业评审", "title_en": "Evaluating In Silico Creativity: An Expert Review of AI Chess Compositions", "authors": "Vivek Veeriah,Federico Barbero,Marcus Chiam,Xidong Feng,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Johan Obando-Ceron,Jiaxin Shi,Shaobo Hou,Satinder Singh,Nenad Tomašev,Tom Zahavy", "background": "生成式人工智能的快速发展引发了对其能否生成有创意和新颖性输出的重大疑问。本文探讨了这一问题在象棋谜题领域的应用，并设计了一个能够生成具有美学吸引力、新颖性、反直觉和独特解决方案的谜题的AI系统。", "innovation": "本文介绍了一个专为象棋谜题生成而设计的AI系统，该系统能够输出具有美学吸引力、新颖性、反直觉解决方案的谜题，这是将生成式AI技术应用于象棋领域的一项创新。", "conclusion": "为了评估系统的创造力，作者向三位知名的象棋专家展示了精心挑选的AI生成的谜题，用以进行评审。这些专家选择了他们认为最吸引人的谜题，并解释了其吸引人的原因，包括其创造性、挑战性或美学设计。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23684", "html_url": "https://arxiv.org/abs/2510.23684", "title": "VIKING: 深度变分推断与随机投影", "title_en": "VIKING: Deep variational inference with stochastic projections", "authors": "Samuel G. Fadel,Hrittik Roy,Nicholas Krämer,Yevgen Zainchkovskyy,Stas Syrota,Alejandro Valverde Mahou,Carl Henrik Ek,Søren Hauberg", "background": "变分均场近似方法在处理现代过度参数化的深度神经网络时常常遇到困难。尽管贝叶斯方法通常与高质量的预测和不确定性相关联，但实际应用中却表现出不稳定的训练、预测能力差和无法满足的校准问题。为了改善这一状况，该研究基于神经网络再参数化工作的最新成果，提出了一种简单的变分族，该族考虑了参数空间中的两个独立线性子空间。这两个子空间分别代表了训练数据支持内部和外部的功能变化。这使得能够构建一个完全相关的近似后验分布，反映了过度参数化并调节易解释的超参数。开发了可扩展的数值算法来最大化相关的证据下界（ELBO）并从近似后验中采样。实验结果表明，该方法在多项任务、模型和数据集中的表现优于广泛基线方法的最新成果。研究结果表明，在构建反映重新参数化几何形状的推理机制方面，应用于深度神经网络的近似贝叶斯推断并非无望。", "innovation": "该研究基于神经网络的再参数化成果，提出了一种新的变分族，该族考虑了参数空间中的两个独立线性子空间，利用随机投影技术改善了变分近似的性能。通过这种方法，能够构造一个与过度参数化相适应的完全相关近似后验，并调节易解释的超参数。开发了高效的数值算法来优化相关的下界（ELBO），并从近似后验中进行了采样。研究表明，这种方法在多个任务、模型和数据集上的表现优于多种基线方法。", "conclusion": "该研究展示了在深度神经网络中应用近似贝叶斯推理，通过构建反映重新参数化几何形状的推理机制，可以实现高质量的预测和性能提升。这种方法克服了传统变分近似的不足，取得了显著的效果。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23831", "html_url": "https://arxiv.org/abs/2510.23831", "title": "通过模型驱动变量选择的贝叶斯模态回归", "title_en": "Testing-driven Variable Selection in Bayesian Modal Regression", "authors": "Jiasong Duan,Hongmei Zhang,Xianzheng Huang", "background": "本文提出了在重尾响应框架下的贝叶斯变量选择方法，结合了模态回归。传统回归方法在处理重尾响应时可能存在局限性，而模态回归能够更好地捕捉数据的中心趋势。为了提高参数估计效率，采用了一种高效的预期最大化算法。此外，通过构建检验统计量来利用模型误差分布的形状，以有效区分信息性协变量和非信息性协变量。", "innovation": "提出了一种贝叶斯变量选择方法，并结合了模态回归，使用高效的预期最大化算法进行参数估计。通过构建检验统计量分析模型误差分布，有效地区分出重要和不重要的协变量。该方法特别适用于处理非高斯模型误差的情况。", "conclusion": "通过模拟研究展示了所提方法在非高斯模型误差下识别重要协变量的有效性，并将其应用于遗传和表观遗传学中产生的数据集，证明了方法的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23749", "html_url": "https://arxiv.org/abs/2510.23749", "title": "使用稀疏自编码器重新审视Euclid星系形态：识别和解释特征", "title_en": "Re-envisioning Euclid Galaxy Morphology: Identifying and Interpreting Features with Sparse Autoencoders", "authors": "John F. Wu,Michael Walmsley", "background": "星系形态的识别通常依赖预训练的神经网络模型。初步研究主要利用监督模型（如Zoobot）和最近开发的自监督模型（如MAE）对Euclid Q1图像的星系形态进行研究。研究发现，MAE模型在图像重建性能上表现出超人类的水平。", "innovation": "与主成分分析（PCA）相比，稀疏自编码器（SAEs）能够识别出与人类定义的分类树框架之外可解释的特征。SAEs的特征与Galaxy Zoo标签相比，显示出更强的一致性。此外，虽然解释模型的可解释性方面仍有挑战，但SAEs为发现超越人类分类限制的天体物理现象提供了一种强大的工具。", "conclusion": "稀疏自编码器能够有效地从预训练神经网络中识别候选单义特征，并且对于星系形态分析具有显著优势，尤其是在监督与自监督模型结合使用的情况下。尽管在可解释性方面仍有一些挑战，但SAEs展示了将人类定义之外的天体物理现象进行挖掘和理解的能力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23881", "html_url": "https://arxiv.org/abs/2510.23881", "title": "生成创意国际象棋谜题", "title_en": "Generating Creative Chess Puzzles", "authors": "Xidong Feng,Vivek Veeriah,Marcus Chiam,Michael Dennis,Ryan Pachauri,Thomas Tumiel,Federico Barbero,Johan Obando-Ceron,Jiaxin Shi,Satinder Singh,Shaobo Hou,Nenad Tomašev,Tom Zahavy", "background": "尽管生成式AI在各个领域迅速发展，但在生成真正具创造性和美学价值、且反直觉的输出方面仍面临挑战。本文针对国际象棋谜题这一领域探讨了如何应对这些挑战。", "innovation": "提出了一种基于强化学习（RL）框架的方法，设计了新颖的奖励机制，该机制基于国际象棋引擎搜索统计数据，用来提升谜题的独特性、反直觉性、多样性和真实性。与传统的监督学习相比，该方法使生成反直觉的谜题数量提高了10倍，甚至超过了现有的数据集（2.1%）和最优秀的Lichess训练模型（0.4%）。生成的谜题由人类专家评定为更具创造力、更令人愉悦且反直觉，甚至接近经典组合谜题的水平。最终，论文提供了一份经专家认可的创意AI生成谜题合集。", "conclusion": "该研究透过对生成式AI在国际象棋谜题生成领域的应用，成功提升了反直觉谜题的生成量和质量，展示了人类专家对AI生成谜题的认可，并为未来在该领域的研究提供了参考。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23745", "html_url": "https://arxiv.org/abs/2510.23745", "title": "利用Mercer核的可解释先验的贝叶斯神经网络", "title_en": "Bayesian neural networks with interpretable priors from Mercer kernels", "authors": "Alex Alberts,Ilias Bilionis", "background": "在科学或工程应用中，精确量化神经网络输出的不确定性至关重要，尤其是在数据有限或噪音数据的情况下进行决策。通常使用的贝叶斯神经网络（BNNs）能够提供一种框架，但它们的先验分布往往难以解释，因为BNNs从输入到输出的复杂映射使得很难理解某些分布如何对输出空间施加任何可解释的约束。相比之下，高斯过程（GPs）因其可解释性在不确定性量化任务中被广泛使用，但它们在处理大数据集时由于需要特定结构的协方差内核的技术限制而变得有限。因此，为了解决这些问题，该研究提出了一种名为Mercer先验的新类BNN，它可以生成与特定高斯过程的样本近似的BNN样本。", "innovation": "通过直接从Mercer表示的协方差核对网络参数进行定义先验，该方法能够利用BNNs的可扩展性，以有意义的方式在贝叶斯框架中进行计算。", "conclusion": "研究提出了一种新的BNN模型——Mercer先验BNN，它通过设计先验直接作用于网络参数，从而能够利用BNNs的可扩展性进行有效的贝叶斯计算，同时保持对先验的解释性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23905", "html_url": "https://arxiv.org/abs/2510.23905", "title": "基于图变换器神经网络的基于NLP的群体意图推断框架作为合作博弈", "title_en": "Inferring Group Intent as a Cooperative Game. An NLP-based Framework for Trajectory Analysis using Graph Transformer Neural Network", "authors": "Yiming Zhang,Vikram Krishnamurthy,Shashwat Jain", "background": "本文研究了群体目标轨迹意图作为合作博弈的结果，其中复杂时空轨迹通过基于NLP的生成模型建模。", "innovation": "1. 引入了基于Fisher信息的合作博弈的特征函数，从而产生生成协调时空模式的概率分布。\n2. 开发了一种基于形式语法的NLP生成模型，用于创建现实的多目标轨迹数据。\n3. 通过训练图变换器神经网络（GTNN）从观测数据中以高精度推断群体轨迹意图作为合作博弈的特征函数。", "conclusion": "本文提出了一个多层方法，结合了目标跟踪（贝叶斯信号处理）和GTNN（群体意图推断），并使用NLP生成模型生成协调时空轨迹模式的概率分布，成功从嘈杂的目标观测中推断出群体意图。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23746", "html_url": "https://arxiv.org/abs/2510.23746", "title": "在MS/MS光谱中从头生成分子结构的测试时调参语言模型", "title_en": "Test-Time Tuned Language Models Enable End-to-end De Novo Molecular Structure Generation from MS/MS Spectra", "authors": "Laura Mismetti,Marvin Alberts,Andreas Krause,Mara Graziani", "background": "串联质谱允许识别代谢组学、天然产物发现和环境分析中的未知化合物。然而，现有的方法依赖于数据库匹配或经过多步处理，需要预测中间片段或指纹，这使得找到正确的分子结构变得非常具有挑战性，尤其是对于数据库中未包含的化合物。", "innovation": "论文引入了一个框架，利用测试时调参，增强预训练的变换器模型的学习能力，从而直接从串联质谱图和分子公式生成从头结构，绕过手动注释和中间步骤。在两个流行的基准测试NPLIB1和MassSpecGym中，该方法分别超越了事实上的领先方法DiffMS的效果，提升幅度分别为100%和20%。实验光谱的测试时调参允许模型动态适应新型光谱，且相比传统微调，在MassSpecGym中的相对性能提升为62%。即使预测与真实值有所偏差，生成的分子候选也保持结构准确性，为人类解释提供有价值的指导，并提高识别的可靠性。", "conclusion": "通过测试时调参，提高预训练变换器模型的能力，直接从串联质谱图和分子公式生成从头的分子结构，超越了当前的最佳方法，且具有高度的鲁棒性，能够动态适应新型光谱。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23935", "html_url": "https://arxiv.org/abs/2510.23935", "title": "通过子空间分解和影响分析理解公平性和预测误差", "title_en": "Understanding Fairness and Prediction Error through Subspace Decomposition and Influence Analysis", "authors": "Enze Shi,Pankaj Bhagwat,Zhixian Yang,Linglong Kong,Bei Jiang", "background": "机器学习模型虽然取得了广泛的成功，但往往继承并放大了历史上的偏见，导致不公的结果。传统公平性方法通常在预测层面施加约束，而没有解决数据表示中的潜在偏见。", "innovation": "本文提出了一种原则性的框架，通过调整数据表示来平衡预测有用性和公平性。利用充分维约简，将特征空间分解为目标相关、敏感和共享组件，并通过有选择地移除敏感信息来控制公平性和有用性的权衡。文章还提供了关于预测误差和公平性差距随共享子空间添加而变化的理论分析，并使用影响函数来量化这些对参数估计渐近行为的影响。实验结果验证了理论洞见，并表明所提出的方法在提高公平性的同时保持了预测性能。", "conclusion": "通过实证研究，该研究证实了所提出的方法在实现实用性和公平性的良好平衡方面是有效的。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23921", "html_url": "https://arxiv.org/abs/2510.23921", "title": "通过最小背景扩充揭示LLM偏见：打破基准", "title_en": "Breaking the Benchmark: Revealing LLM Bias via Minimal Contextual Augmentation", "authors": "Kaveh Eskandari Miandoab,Mahammed Kamruzzaman,Arshia Gharooni,Gene Louis Kim,Vasanth Sarathy,Ninareh Mehrabi", "background": "大型语言模型在表示和行为中表现出刻板印象偏差，这源于训练数据的区分性特征。尽管在避免使用刻板印象信息的方法和模型开发上取得了显著进展，但近期研究表明，用于偏见对齐的方法脆弱性较大。因此，存在需要一种新型且通用的增强框架的需求，该框架可以适用于多种公平性评估基准，探讨大型语言模型是否会对输入的扰动表现出刻板印象行为，特别是在目标人群属于文献较少研究的社群时。", "innovation": "提出了一种新的通用增强框架，该框架包含三个可插拔步骤，并适用于多个公平性评估基准。通过将增强应用于公平性评估数据集（Bias Benchmark for Question Answering (BBQ)），发现大型语言模型（包括最先进的开放和封闭权重模型）对输入扰动敏感，更有可能表现出刻板印象行为，特别是在目标社群文献研究较少的情况下。", "conclusion": "该研究强调，扩大公平性和安全性研究以涵盖更多元的社群具有重要性和必要性。大型语言模型虽然在技术上处于领先地位，但仍然容易受到输入扰动的影响，显示出一定程度的刻板印象偏见。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23907", "html_url": "https://arxiv.org/abs/2510.23907", "title": "DynaStride：动态窗口MMCoT方法的多场景指令视频标题生成", "title_en": "DynaStride: Dynamic Stride Windowing with MMCoT for Instructional Multi-Scene Captioning", "authors": "Eddison Pham,Prisha Priyadarshini,Adrian Maliackel,Kanishk Bandi,Cristian Meo,Kevin Zhu", "background": "场景级别的标题可以在指令视频中增强学习，因为它们需要理解视觉线索和时间结构。通过将视觉线索与文本指导相匹配，这种理解支持程序学习和多模态推理，为技能获取提供更丰富的背景。然而，如果标题未能捕捉到这种结构，它们可能会缺乏连贯性和质量，从而造成混乱并削弱视频的教学意图。", "innovation": "介绍了一种名为DynaStride的管道来生成连贯的场景级标题，无需手动场景分割。DynaStride使用YouCookII数据集中场景标注，通过自适应帧采样和多模态窗口采样捕捉每个场景内的关键转换。然后，它使用多模态链式思考过程产生多个动作-对象对，并使用动态步进窗口选择算法进行细化和融合，从而适当地平衡时间上下文和冗余。最终的场景级标题结合了视觉语义和时间推理。", "conclusion": "DynaStride与强大的基线VLLaMA3和GPT-4o进行的实证评估表明，它在基于n-gram的指标（BLEU，METEOR）和语义相似度指标（BERTScore，CLIPScore）上的表现一致提高。进一步的定性分析表明，DynaStride生成的标题更具有时间连贯性和信息量，表明它为提高基于AI的指令内容生成的潜在方向提供了有价值的线索。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23891", "html_url": "https://arxiv.org/abs/2510.23891", "title": "PRO: 为开源大语言模型实现精确和稳健的文字水印", "title_en": "PRO: Enabling Precise and Robust Text Watermark for Open-Source LLMs", "authors": "Jiaqi Xue,Yifei Zhao,Mansour Al Ghanim,Shangqian Gao,Ruimin Sun,Qian Lou,Mengxin Zheng", "background": "大语言模型（LLMs）的所有者需要验证文本来源和保护知识产权。虽然针对封闭源大语言模型的水印方法已经相对成熟，但将其扩展到开源模型仍面临挑战，因为开发者无法控制解码过程，导致开源LLM的所有者缺乏验证生成文本是否来自他们模型的实用手段。因此，嵌入水印直接到模型权重以不损害检测的同时保持一致性是核心难题。一种有希望的方法是将来自封闭源模型的水印精简至开源模型，但这种方法由于学习和预定义模式之间的不匹配以及对下游修改（如微调或模型合并）的脆弱性，导致检测能力差和不稳定。", "innovation": "提出了一种名为PRO的方法，即精确和稳健的文字水印方法，这一方法能够针对开源大语言模型进行联合训练，生成易于模型学习且与检测标准更一致的模式。通过正则化项模拟下游扰动，确保水印在模型更改下更具鲁棒性，这种方法不仅能提高水印的检测能力，还能增强对模型修改的鲁棒性。实验结果表明，PRO 在开源大语言模型（例如 LLaMA-3.2、LLaMA-3、Phi-2）上的效果显著，大大提升了水印的检测能力和抗干扰能力。", "conclusion": "PRO 通过联合训练水印策略模型和大语言模型，产生更容易被模型学习且更符合检测标准的模式。同时，通过正则化项模拟下游扰动，确保在模型更改下提高水印的鲁棒性和检测能力，实验结果表明 PRO 在开源大语言模型上的性能显著提高。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23985", "html_url": "https://arxiv.org/abs/2510.23985", "title": "通过边界条件下的朗之万扩散进行分数基于的约束生成建模", "title_en": "Score-based constrained generative modeling via Langevin diffusions with boundary conditions", "authors": "Adam Nordenhög,Akash Sharma", "background": "基于分数的生成模型通过随机微分方程（SDEs）在抽样来自未知分布方面表现出色，但往往无法满足潜在约束。已有研究尝试通过使用带反射边界的朗之万扩散等方法来解决这一问题，但在实现上仍存在挑战。", "innovation": "提出了使用动能（欠阻尼）朗之万动力学的约束生成模型，并通过在定义约束的边界上对速度进行镜面反射来实现。这导致了一种分段连续可微的噪声和去噪过程，其中后者由镜面边界条件限制在受限域内的反向时间动力学表示。此外，该研究还贡献了一个概念化的局部时间术语，用于约束基于随机动态的生成模型。", "conclusion": "通过提供高效的数值采样器，该研究展示了受限（镜面反射动能）朗之万扩散模型与基于局部时间的反射扩散模型之间的全面对比，这些采样器在离散步长方面以最优速率收敛。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24010", "html_url": "https://arxiv.org/abs/2510.24010", "title": "Mars-Bench：火星科学任务评估基础模型基准", "title_en": "Mars-Bench: A Benchmark for Evaluating Foundation Models for Mars Science Tasks", "authors": "Mirali Purohit,Bimal Gajera,Vatsal Malaviya,Irish Mehta,Kunal Kasodekar,Jacob Adler,Steven Lu,Umaa Rebbapragada,Hannah Kerner", "background": "基础模型通过在大量未标记数据上进行大规模预训练，在许多专门领域取得了快速进展，展示了在各种下游任务上的强大泛化能力。尽管这些模型在地球观测等领域引起了广泛关注，但在火星科学领域的应用仍然有限。其他领域的进步得益于标准化基准的可用性，而火星科学缺乏这类基准和标准化评估框架，限制了开发火星特定任务基础模型的进展。", "innovation": "本文介绍了Mars-Bench，这是第一个设计用于系统性评估火星相关任务模型的基准，涵盖轨道和表面图像数据。Mars-Bench包括20个数据集，覆盖了分类、分割和物体检测等多种任务，重点关注地学特征如陨石坑、圆锥、岩石和霜冻等。此外，还提供了标准化的数据集和预训练模型的基准评估。这些结果表明，火星特定的基础模型可能比通用领域模型更具优势，推动了领域适应预训练的进一步探索。", "conclusion": "Mars-Bench旨在建立火星科学中机器学习模型开发和比较的标准基础。所有数据、模型和代码均可在以下网址获得：this https URL."}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23999", "html_url": "https://arxiv.org/abs/2510.23999", "title": "自适应PINNs及其在相变应用中的应用", "title_en": "Auto-Adaptive PINNs with Applications to Phase Transitions", "authors": "Kevin Buck,Woojeong Kim", "background": "本文提出的是一种自适应采样方法，用于物理惯知情神经网络（PINNs）的训练。该方法允许根据任意问题特定的启发式方法进行采样，该启发式方法可以依赖于网络及其梯度。研究特别集中在Allen-Cahn方程上，使用PINN准确解析特征界面区域，无需任何后处理重新采样。实验结果表明，该方法优于基于残差自适应框架的方法。", "innovation": "提出了一种自适应采样方法，根据问题特定的启发式方法进行采样，可以依赖于网络及其梯度。这一方法专注于Allen-Cahn方程，展示了一种在不进行后处理重采样的情况下准确解析特征界面区域的新方法。实验验证了该方法的有效性，表明它优于传统的基于残差的自适应框架。", "conclusion": "本文提出的方法在实验中证明了其在自适应采样训练PINNs方面的有效性，特别在Allen-Cahn方程的应用上，展示了准确解析特征界面区域而不需任何后处理重采样的能力。该研究成果提高了PINNs在相变等复杂物理问题上的应用效率和准确性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23965", "html_url": "https://arxiv.org/abs/2510.23965", "title": "符号估计量：面对选择异质性的LLM对齐", "title_en": "The Sign Estimator: LLM Alignment in the Face of Choice Heterogeneity", "authors": "Aymane El Gadarri,Ali Aouad,Vivek F. Farias", "background": "传统的大型语言模型（LLM）对齐方法容易受到人类偏好异质性的影响。当尝试通过对比数据（例如对话完成对的对比）拟合一个简单的概率模型时，可能会得到不一致的人口平均效用估计值，这并不充分衡量社会福利。研究者发现，这一问题源于信息聚合步骤中的交叉熵替代问题，导致了预测不一致和效用评估不理想的结果。因此，需要一种创新的方法来解决这一问题，以提高对齐过程的一致性和效率。", "innovation": "本文提出了一种名为‘符号估计量’的新方法，该方法在信息聚合步骤中用二元分类损失替代交叉熵损失，从而得到一个简单、可验证一致性和高效的估计器。这种方法即使在轻度假设下也能恢复一致性标准对齐。此外，它首次在该背景下提供了多项式有限样本误差边界，优于现有方法。在数字孪生模型的实用仿真中，符号估计量显著降低了偏好失真，减少了评估误差，并降低了对真实人群偏好的不一致性，从而在LLM对齐方面表现出色。同时，它还提供了一种灵活性更大的解决方案，相对现有的对齐流水线更加简单易行，而无需跟踪个体水平的偏好数据。", "conclusion": "符号估计量是一种高效的对齐方法，特别适用于处理选择异质性的LLM对齐问题。它通过简单地修改信息聚合步骤中的交叉熵，提高了对齐的一致性和效率，实现了更好的社会福利评估。相比现有的对齐方法，它能够大幅度减少偏好失真，并显著降低对真实人群偏好的不一致性。这为更准确和有效的LLM对齐提供了新的可能。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24013", "html_url": "https://arxiv.org/abs/2510.24013", "title": "使用大型语言模型（LLMs）为混合整数规划发现启发式算法：单机调度问题", "title_en": "Discovering Heuristics with Large Language Models (LLMs) for Mixed-Integer Programs: Single-Machine Scheduling", "authors": "İbrahim Oğuz Çetinkaya,İ. Esra Büyüktahtakın,Parshin Shojaee,Chandan K. Reddy", "background": "本研究探讨了单机总延期（SMTT）问题，即在给定各加工时间和最后期限的情况下，通过不预设顺序的方式对n个作业进行排序，以最小化总延期。此前的研究通常使用简单的规则基础启发式，而本文则利用大型语言模型（LLMs）发现新的启发式，并通过严格的评估标准（包括来自混合整数规划（MIP）表述的最优差距和解出时间）来检验这些新的启发式算法。对于拥有超过100个作业的实例，现有的精确方法如MIP和动态规划变得不可计算。到500个作业时，EDDC和MDDC在处理规模较大、更复杂的问题时表现优于传统启发式算法，同时EDDC也超越了经典的EDD规则和另一种广泛使用的算法。这项研究展示了在有限资源下，人与LLMs合作可以生成可扩展、高性能的NP难题制约组合优化启发式算法的潜力。", "innovation": "本文提出了两种新的由大型语言模型（LLMs）发现的启发式算法，即Edd Challenger（EDDC）和Mdd Challenger（MDDC）。这些启发式算法是基于著名的最早截止日期（EDD）和修改后截止日期（MDD）规则而设计的，相比之前的单纯规则启发式，本文通过严格的评估标准（包括最优差距和求解时间）来评估这些新的启发式算法，并将其与现有最先进的启发式及精确方法进行比较。研究中的这些新算法在处理更多作业实例时展现出了较好的性能，并且对于更大、更复杂的问题，MDDC保持了与精确方法竞争的水平。", "conclusion": "本研究证明了人与LLMs的合作能够生成适用于NP难题的组合优化问题的可扩展且高性能的启发式算法，即便在资源有限的情况下通过有效配置完全可以实现。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24058", "html_url": "https://arxiv.org/abs/2510.24058", "title": "PULSE: 从电皮肤活动向低成本传感器转移特权知识以进行压力监测", "title_en": "PULSE: Privileged Knowledge Transfer from Electrodermal Activity to Low-Cost Sensors for Stress Monitoring", "authors": "Zihan Zhao,Masood Mortazavi,Ning Yan", "background": "电皮肤活动（EDA）是用于检测压力的主要信号，但通常需要昂贵的硬件，这些硬件在实际穿戴设备中并不常见。因此，本文旨在提出一种新的框架PULSE，该框架在自我监督预训练阶段仅使用EDA，而在推理阶段不使用EDA，而是使用如ECG、BVP、ACC和TEMP等更易获取的模态数据。", "innovation": "PULSE框架通过将编码器输出划分为共享和私有嵌入，实现了模态间的共享嵌入对齐和融合。私有嵌入携带特定于模态的信息，以支持重建目标。预训练后进行知识转移，冻结的EDA教师将交感神经唤醒表征转移至学生编码器，从而提高压力检测性能，同时降低硬件成本。", "conclusion": "在WESAD数据集上，我们的方法取得了强大的压力检测性能，证明了特权EDA表示可以转移到低成本传感器上，从而提高准确率，同时降低了硬件成本。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24056", "html_url": "https://arxiv.org/abs/2510.24056", "title": "Copula-Stein Discrepancy: 一种基于生成函数的Archimedean依赖性Stein算子", "title_en": "Copula-Stein Discrepancy: A Generator-Based Stein Operator for Archimedean Dependence", "authors": "Agnideep Aich,Ashit Baran Aich", "background": "标准的核Stein差异(KSDs)通常对尾部依赖等高阶依赖结构不够敏感，这在许多科学和金融领域至关重要。因此，尽管KSDs已成为拟合优度检验的主要工具，但它们在检测这些高阶依赖结构方面的局限性成为了一个问题。", "innovation": "提出了一种Copula-Stein差异(CSD)，这是一个针对统计依赖性几何结构定制的新类差异。通过直接定义在Copula密度上的Stein算子，CSD利用了依赖性的生成结构，而不是依靠联合密度的梯度函数。对于广义的Archimedean Copulas，这种方法产生了一个闭式形式的Stein内核，源自标量生成函数。此外，还针对非Archimedean Copulas，包括椭圆和树状Copulas进行了扩展。计算上，精确的CSD核评估线性缩放于维度，而一种新型随机特征近似将$n$依赖性从二次$O(n^2)$降低到接近线性$\tilde{O}(n)$。", "conclusion": "CSD不仅证明了弱收敛性、最优收敛率和对尾部依赖系数差异的敏感性，还提供了一种依赖感知的推理工具的理论基础和实际可行性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24037", "html_url": "https://arxiv.org/abs/2510.24037", "title": "视觉模型的核化稀疏微调及双层参数竞争", "title_en": "Kernelized Sparse Fine-Tuning with Bi-level Parameter Competition for Vision Models", "authors": "Shufan Shen,Junshu Sun,Shuhui Wang,Qingming Huang", "background": "参数高效微调（PEFT）旨在适应预训练的视觉模型至下游任务。现有方法遵循两阶段范式：首先是通过梯度信息识别相关的权重，随后通过稀疏掩码仅限于更新这些权重，但这种方法存在局限性。第一阶段将注意力集中于梯度信息而忽略了微调过程中权重调整的影响，限制了性能。第二阶段只更新识别的权重，导致记忆占用高，因为所有的权重矩阵都要存储在优化器中。", "innovation": "本文提出了一种一阶段方法SNELLA，通过将权重矩阵添加到由两个低秩可学习矩阵合并而成的稀疏矩阵来优化内存使用。此外，使用非线性核函数扩展低秩分解，以提高合并矩阵的秩，从而减少权重更新之间的依赖性，促进了更好的下游任务适应能力。同时，提出了一种适应性双层参数竞争机制，鼓励权重在层间和层内根据其重要性得分进行竞争，以识别相关的权重，适用于端到端方式。实验结果显示，SNELLA在不同预训练视觉模型上的分类、分割和生成任务中，性能大幅度超越，且内存占用低。与先前方法相比，SNELLA在模型参数规模从86M到632M不同情况下，内存使用降低了31.1%-39.9%。", "conclusion": "SNELLA通过减少内存使用并提高性能，相对于传统的PEFT方法在FGVC基准中实现了SOTA表现，最高Top-1精度提升了1.8%（从90.1%提升至91.9%）并且内存降低了31.1%-39.9%。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24105", "html_url": "https://arxiv.org/abs/2510.24105", "title": "提升预训练表示的分类能力可以增强其可解释性", "title_en": "Enhancing Pre-trained Representation Classifiability can Boost its Interpretability", "authors": "Shufan Shen,Zhaobo Qi,Junshu Sun,Qingming Huang,Qi Tian,Shuhui Wang", "background": "预训练视觉模型在下游任务中的广泛应用对表示的可解释性提出了新的要求，但尚未明确预训练表示能否同时实现高可解释性和分类能力。本文通过衡量表示的可解释性与可解释语义比例之间的相关性来量化表示的可解释性。", "innovation": "本文提出了内在可解释性评分（IIS），用于评估信息损失、测量可解释语义的比例，并量化表示的可解释性。研究发现，分类能力和可解释性之间存在正相关，即分类能力较高的表示能提供更多可解释的语义，这些语义可以在解释中被捕捉。这支持了两个好处：通过最大化可解释性进行微调可以进一步提高表示的分类能力，且随着表示分类能力的提升，基于解释的预测准确性下降较少。", "conclusion": "所发现的正相关和相应的应用表明，从业者可以统一提高预训练视觉模型的可解释性和分类能力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24085", "html_url": "https://arxiv.org/abs/2510.24085", "title": "电驱动车辆跟随行为建模：经典方法与机器学习方法对比", "title_en": "Modeling Electric Vehicle Car-Following Behavior: Classical vs Machine Learning Approach", "authors": "Md. Shihab Uddin,Md Nazmus Shakib,Rahul Bhadani", "background": "随着电动汽车(EVs)的日益普及，了解其驾驶行为变得重要，这有助于提升交通安全并开发智能驾驶系统。本文对比了经典模型和机器学习模型在电动汽车跟随行为上的应用。", "innovation": "本文采用一系列经典模型，如智能驾驶员模型(IDM)、最优速度模型(OVM)、相对速度最优速度模型(OVRV)和简化的CACC模型，与机器学习方法中的随机森林回归器进行比较。模型使用真实世界数据集来预测电动汽车跟随内燃机车辆时的加速度，通过空间距离、速度和间隙类型作为输入参数。", "conclusion": "结果表明，随机森林模型在所有场景下的表现优于经典模型，尤其在不同间隙类型下的RMSE分别为0.0046（中等间隙）、0.0016（长间隙）和0.0025（超长间隙）。基于物理模型中，CACC表现最佳，长间隙下的RMSE为2.67。这些发现突出了机器学习模型在所有场景中的优越性能，对模拟电动汽车行为和分析混合自主车辆交通动态具有重要价值。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24074", "html_url": "https://arxiv.org/abs/2510.24074", "title": "基于深度学习的Heston模型校准：一个统一框架", "title_en": "Deep Learning-Enhanced Calibration of the Heston Model: A Unified Framework", "authors": "Arman Zadgar,Somayeh Fallah,Farshid Mehrdoust", "background": "Heston随机波动模型是金融数学中广泛用于定价欧式期权的重要工具，但由于模型非线性和多维参数空间，其校准过程仍具有较强的计算密集性和对外部局部最小值的敏感性。现有的校准方法存在局限性，本文旨在提出一种新的方法来解决这些问题，提高校准的效率和准确性。", "innovation": "本文提出了一种结合了监督前馈神经网络的混合深度学习框架。框架中包括两个网络：Price Approximator Network (PAN) 和 Calibration Correction Network (CCN)。前者基于敲出价和行权价值输入，近似期权价格曲面；后者通过修正系统性的价格错误，进一步校准Heston模型的输出。实验表明，该深度学习方法在多个错误度量指标上优于传统校准技术，具有更快的收敛速度和更强的泛化能力，尤其在样本内和样本外环境中表现优异。", "conclusion": "该框架为实时金融模型的校准提供了一种实用且稳健的解决方案，有效提高了Heston模型校准的效率和准确性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24055", "html_url": "https://arxiv.org/abs/2510.24055", "title": "语言条件化表示和专家混合策略在鲁棒多任务机器人操作中的应用", "title_en": "Language-Conditioned Representations and Mixture-of-Experts Policy for Robust Multi-Task Robotic Manipulation", "authors": "Xiucheng Zhang,Yang Jiang,Hongwei Qing,Jiashuo Bai", "background": "在仿人式机器人操作任务中，感知不确定性以及任务间的矛盾会导致多任务操作效率降低。现有的研究通过模仿学习提高了机器人操作性能，但通常在处理感知不确定性及任务间冲突时存在局限性。本文探讨了通过语言条件化的视觉表示（LCVR）模块以及语言条件化的专家混合策略（LMoE-DP）来解决这些问题。LCVR通过将视觉特征与语言指令结合，解决了感知上的不确定性问题；而LMoE-DP使用稀疏专家架构来专注处理不同、多模态的动作分布，并通过梯度调节来稳定这些分布，以此解决任务间的冲突问题。这项工作建立在现有技术之上，旨在实现更加鲁棒和高效的多任务机器人操作。", "innovation": "本文提出的框架关键创新点在于结合语言条件化的视觉表示（LCVR）模块和语言条件化的专家混合策略（LMoE-DP）。LCVR通过将视觉特征与语言指令结合，有效地解决了感知上的不确定性问题；而LMoE-DP则通过稀疏专家架构专注于处理不同、多模态的动作分布，并通过梯度调节稳定这些分布，从而有效解决了任务间的冲突。", "conclusion": "本研究通过结合语言条件化和专家专业化，提出了LCVR和LMoE-DP的综合框架，显著提高了机器人在多任务操作中的成功率，表现出更高的鲁棒性和效率。具体测试表明，该框架实施后，ACT和DP的成功率分别提高了33.75%和25%，并且整体成功率达到了79%，高于先进基准的21%。这一发现证明了策略的有效性，表明了在未来多任务机器人操作中应用这种综合方案的巨大潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24029", "html_url": "https://arxiv.org/abs/2510.24029", "title": "使用3D LiDAR在海马体启发模型中提高机器人定位精度", "title_en": "Improved Accuracy of Robot Localization Using 3-D LiDAR in a Hippocampus-Inspired Model", "authors": "Andrew Gerstenslager,Bekarys Dukenbaev,Ali A. Minai", "background": "边界向量单元（BVCs）是脊椎动物大脑中的神经元，用于编码特定距离和远离中心的方向的环境边界，对于形成海马体中的地点场至关重要。大多数计算BVC模型局限于二维（2D）环境，这在环境中存在水平对称性时容易产生空间歧义。为了克服这一局限性，引入垂直角度敏感性到BVC框架中，从而在三维中实现稳健的边界检测，并通过生物启发的机器人模型实现更准确的空间定位。该模型处理LiDAR数据来捕捉垂直轮廓，从而在纯2D表示无法区分的位置进行去歧义。实验结果显示，在环境垂直变化较少的情况下，提出的3D模型与2D基线表现相当；然而，随着3D复杂性的增加，它产生了显著更多的不同地点场，并大幅减少了空间混叠。研究表明，增加垂直维度到基于BVC的定位中可以显著提高在实际三维空间中的导航和地图构建，同时在较简单的接近平面场景中保持性能一致性。", "innovation": "引入垂直角度敏感性到BVC框架，实现三维边界检测，提高机器人在复杂三维环境中的定位精度。通过处理LiDAR数据来捕获垂直轮廓，解决了2D表示中的空间歧义问题。在3D复杂环境中，显著增加了地点场的数量，并降低了空间混叠。尽管在简单的接近平面场景中保持了与2D基线的性能一致性，但在高复杂度的三维环境中显著提升了性能。", "conclusion": "通过引入垂直维度，基于BVC的定位模型在实验环境中在复杂3D环境中表现出了显著的优越性，同时在简单的接近平面场景中保持了与2D基线的性能一致性。这表明在实际的三维空间中，增加垂直维度可以显著提高导航和地图构建的准确性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24115", "html_url": "https://arxiv.org/abs/2510.24115", "title": "HistoLens：组织病理学领域中一种交互式的可解释性工具包，用于验证和减轻视觉语言模型中的缺陷", "title_en": "HistoLens: An Interactive XAI Toolkit for Verifying and Mitigating Flaws in Vision-Language Models for Histopathology", "authors": "Sandeep Vissapragada,Vikrant Sahu,Gagan Raj Gupta,Vandita Singh", "background": "为了医生真正信任人工智能，AI系统不应只是一个黑箱子，医生需要理解AI的推理过程。传统的组织病理学分析依赖于病理学家的经验与直觉，而组织病理学中的AI系统通常缺乏透明度和解释性，这限制了医生对其结果的信任。", "innovation": "开发了HistoLens1作为一种透明且协作的伙伴。HistoLens允许病理学家用简单的英语提问来获取组织切片的信息，如同询问刚入职的实习生。系统能智能地将这些问题转化为精确的查询并提供清晰、结构化的报告。更重要的是，HistoLens可以提供‘视觉证据’，即热图来让用户了解系统的分析依据，从而提高医生对AI结果的信任。", "conclusion": "HistoLens通过一系列巧妙的设计，保证了AI系统在患者的组织上专注于关键信息，忽略干扰背景，使得病理学家能够保持其权威地位，同时借助可靠的AI助手进行诊断，从而实现更快和更自信的诊断流程。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24228", "html_url": "https://arxiv.org/abs/2510.24228", "title": "联合UKF和双UKF实现对水分配网络状态估计和泄漏定位的比较", "title_en": "A comparison between joint and dual UKF implementations for state estimation and leak localization in water distribution networks", "authors": "Luis Romero-Ben,Paul Irofti,Florin Stoican,Vicenç Puig", "background": "现代城市的可持续性高度依赖于高效的水资源分配管理，包括有效的压力控制和泄漏检测与定位。准确地了解网络液压状态是至关重要的。", "innovation": "该研究比较了两种基于无迹卡尔曼滤波器（UKF）的数据驱动状态估计方法，即联合状态向量估计方法和双估计器方案，分析了它们的主要特点，讨论了差异、优点和局限性，并从准确性和复杂性的理论角度进行了比较。", "conclusion": "文章展示了L-TOWN基准的几种估计结果，以便讨论它们在实际实施中的属性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24113", "html_url": "https://arxiv.org/abs/2510.24113", "title": "调教尾部延迟：针对基于芯粒的加速器上混合 DL 工作负载的 NoI 顶级生成", "title_en": "Taming the Tail: NoI Topology Synthesis for Mixed DL Workloads on Chiplet-Based Accelerators", "authors": "Arnav Shukla,Harsh Sharma,Srikant Bharadwaj,Vinayak Abrol,Sujay Deb", "background": "基于芯粒的系统通过将 CPU/GPU 以及新兴技术（如 HBM/DRAM）进行解耦来提高扩展性。然而，这种方法在封装内引入了 NoI（网络-中介层）的延迟问题。现代大规模模型推理过程中，参数和激活数据会在 HBM/DRAM 之间频繁移动，导致中介机构上的大量突发流量，增加了尾部延迟，并违反了服务级别协议 (SLA)。虽然目前有面向 k-ary n-立方体基础 NoI 顶级的方案，但这些方案无法有效解决上述问题。", "innovation": "论文通过引入 '干扰得分' (IS) 来量化最坏情况下的减速情况，并将 NoI 顶级生成作为一个多目标优化 (MOO) 问题。开发了 '知晓并行学习器' (PARL) 作为顶级生成器，平衡吞吐量、延迟和功耗。PARL 生成的顶级减少了内存切片处的争用，满足 SLA，将最坏情况下的减速减少到 1.2 倍，同时保持相对于丰富链接的网格具有竞争力的平均吞吐量。这项工作重新定义了面向 workload 意识目标的异构芯粒加速器的 NoI 设计。", "conclusion": "该研究通过提供一种新的方法来优化 NoI 顶级，以满足异构芯粒加速器上混合 DL 工作负载的工作负载意识目标，比如减少尾部延迟、满足 SLA，并以相对较低的最坏情况减速和与丰富连接的网格相竞争的平均吞吐量为目标，推动了 NoI 顶级在现代复杂计算系统中的设计和实现。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24194", "html_url": "https://arxiv.org/abs/2510.24194", "title": "盲目的专家表现更好：来自机器人操作和电子游戏的见解", "title_en": "Blindfolded Experts Generalize Better: Insights from Robotic Manipulation and Videogames", "authors": "Ev Zisselman,Mirco Mutti,Shelly Francis-Meretzki,Elisei Shafer,Aviv Tamar", "background": "行为 cloning 是一种简单而有效的技术，用于从示范中学习序列决策。近年来，它在物理世界的根部模型中取得了重要地位，实现泛化需要大量任务的示范。通常，一个拥有任务完整信息的人类专家示范近乎最优的行为。", "innovation": "本文提出了一种新颖的方法，即部分隐藏任务信息，迫使“蒙眼”的专家进行非平凡的探索以解决任务。实验表明，模仿蒙眼专家相比全知型专家具有更好的泛化性能。此外，理论分析证明泛化误差随着图中任务信息量根号比任务示范数量的增加而变化。", "conclusion": "理论和实践都表明，模仿蒙眼专家比全知型专家在更少的任务示范下有更好的泛化能力。从机器人操作和电子游戏中的实验结果支持了这一点。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24208", "html_url": "https://arxiv.org/abs/2510.24208", "title": "超越神经不兼容性：通过潜在语义对齐在大规模语言模型中实现跨尺度知识迁移", "title_en": "Beyond Neural Incompatibility: Easing Cross-Scale Knowledge Transfer in Large Language Models through Latent Semantic Alignment", "authors": "Jian Gu,Aldeida Aleti,Chunyang Chen,Hongyu Zhang", "background": "大规模语言模型（LLMs）通过其大量的参数编码了丰富的知识，这种知识可以在其中进行定位、追踪和分析。尽管在神经可解释性方面取得了进展，但仍不清楚如何进行细粒度的知识迁移，即参数化知识转移（PKT）。一个主要问题是，如何在不同规模的LLM之间有效地和高效地进行知识迁移，这对于在LLM之间进行知识迁移达到更大的灵活性和更广泛的适用性是至关重要的。由于神经不兼容性，即不同规模的LLM在架构和参数上的差异，现有的直接重用层参数的方法受到了严重限制。", "innovation": "本文识别了潜在空间中的语义对齐作为跨尺度LLM知识迁移的根本前提。我们的方法不直接使用层参数，而是将激活作为层间知识转移的媒介。利用潜在空间中的语义，我们的方法简单有效，超越了之前的工作，并更好地实现了不同规模模型行为之间的对齐。", "conclusion": "在四个基准上的评估证明了我们方法的有效性。进一步的分析揭示了促进跨尺度知识转移的关键因素，并对潜在语义对齐的本性提供了见解。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24187", "html_url": "https://arxiv.org/abs/2510.24187", "title": "Self-Concordant Perturbations for Linear Bandits", "title_en": "Self-Concordant Perturbations for Linear Bandits", "authors": "Lucas Lévy(1 and 2),Jean-Lou Valeau(1 and 3),Arya Akhavan(1 and 2),Patrick Rebeschini(1) ((1) University of Oxford, United Kingdom, (2) École Polytechnique, IP Paris, France, (3) ENSAE, IP Paris, France)", "background": "该论文研究了对抗线性贝叶斯问题，并提出了一种统一的算法框架，将Follow-the-Regularized-Leader (FTRL) 方法和Follow-the-Perturbed-Leader (FTPL) 方法结合起来，扩展了它们之间在完全信息设置中已知的联系。在这一框架中，引入了二次可缩减扰动，这是一种概率分布，类似于FTRL 基础算法SCRiBLe 中使用的二次可缩减障碍物的作用。使用这一思路，设计了一个结合二次可缩减正则化和有效随机探索的新FTPL 基算法。该研究在 $d$ 维超立方体和欧几里得球上分别实现了 regret $O(d\frac{\text{ln } n}{\text{sqrt } n})$ 的表现，对于欧几里得球，这与现有的二次可缩减FTRL 方法的速度相同，对于超立方体，则是这些方法的 $\frac{1}{\text{sqrt } d}$ 倍改进，改进达到最优界限，但有对数因子的差异。", "innovation": "提出了二次可缩减扰动，结合二次可缩减正则化和高效随机探索，设计的新FTPL 基算法，该算法在 $d$ 维超立方体和欧几里得球上的 regret 表现分别为 $O(d \frac{\text{ln } n}{\text{sqrt } n})$，在欧几里得球上与现有方法速度相同，在超立方体上是现有方法的 $\frac{1}{\text{sqrt } d}$ 倍改进，接近最优界限，但有对数因子的差异。", "conclusion": "该研究实现了一种新颖的算法，该算法结合了二次可缩减正则化和高效的随机探索，在 $d$ 维超立方体和欧几里得球上的 regret 表现优化，特别是对于超立方体，该算法改进了现有的最优办法，虽然在欧几里得球上的改善不明显，但在超立方体上显著改进了 regret 上界，为解决对抗线性贝叶斯问题提供了新的思路和方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24254", "html_url": "https://arxiv.org/abs/2510.24254", "title": "使用因果气候驱动因素指导的概率机器学习在北极地区的降水量预测", "title_en": "Forecasting precipitation in the Arctic using probabilistic machine learning informed by causal climate drivers", "authors": "Madhurima Panja,Dhiman Das,Tanujit Chakraborty,Arnob Ray,R. Athulya,Chittaranjan Hens,Syamal K. Dana,Nuncio Murukesh,Dibakar Ghosh", "background": "在北极海区，如熊岛和Ny-Ålesund，理解并预测降水事件对于评估气候风险以及开发脆弱海洋区域的早期预警系统至关重要。因此，本研究旨在提出一种概率机器学习框架，用于模型化和预测降水的动态及其严重性。", "innovation": "1. 采用小波相干性分析尺度相关的降水与关键大气驱动因素（如温度、相对湿度、云量和气压）之间的关系。\n2. 使用协同-独特-冗余分解评估联合因果影响，量化每个变量之间的交互效应对未来降水动态的影响。\n3. 采用因果分析结合概率预测的综合框架，生成校准的非参数预测区间，提高预测的可靠性和可解释性。", "conclusion": "研究结果强调了在北极海洋环境中使用综合框架进行降水预测的重要性，该框架结合了因果分析和概率预测，以增强预测的可靠性和可解释性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24279", "html_url": "https://arxiv.org/abs/2510.24279", "title": "HergNet: 一种通过平面波叠加快速神经代理模型声场预测", "title_en": "HergNet: a Fast Neural Surrogate Model for Sound Field Predictions via Superposition of Plane Waves", "authors": "Matteo Calafà,Yuanxin Xia,Cheol-Ho Jeong", "background": "介绍了为了高效预测二维和三维声场而提出的一种新颖神经网络架构。网络被设计成能够自动满足亥姆霍兹方程，确保输出是物理上有效的，因此该方法可以通过学习边界值问题中的各种波动现象（如声学、光学和电磁学）的有效解决方案，在房间声学模拟中特别是在中高频范围能够优于现有的最先进的方法。", "innovation": "提出了一种神经网络架构，设计上能够自动满足亥姆霍兹方程，确保输出的物理有效性，有效学习边界值问题中的波动现象解决方案。这种模型在房间声学模拟特别是在中高频范围内的性能有望优于现有的最先进的方法。", "conclusion": "数值实验表明，提出的方法在房间声学模拟中，特别是在中高频范围能够超越现有的最先进的方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24159", "html_url": "https://arxiv.org/abs/2510.24159", "title": "基于自我监督的合成预训练在稠密气体中推断恒星质量的应用", "title_en": "Self-supervised Synthetic Pretraining for Inference of Stellar Mass Embedded in Dense Gas", "authors": "Keiya Hirashima,Shingo Nozaki,Naoto Harada", "background": "恒星质量是决定恒星性质和演化的关键参数，但在恒星形成区域估计恒星质量具有挑战性，因为年轻的恒星被密集的气体所遮蔽，该区域的结构复杂且不均匀，导致基于球形动力学的估计不可靠。监督机器学习可以通过将复杂结构与恒星质量联系起来来解决这个问题，但这需要来自高分辨率磁流体力学（MHD）模拟的大规模、高质量标记数据集，而这些数据集的生成成本高昂。本文通过利用自我监督框架DINOv2对一百万张合成分形图像进行预训练，然后将冻结后的模型应用于有限的高分辨率MHD模拟数据，并取得了一系列积极的效果，展现了在高分辨率MHD模拟数据有限的情况下，合成数据预训练可以提升冻结模型预测恒星质量的精度，即对于预训练模型的预测效果略优于在相同有限模拟数据上直接进行监督训练的模型。通过主成分分析提取特征，还可以揭示出具有语义意义的结构，表明模型在无需标注数据和微调的情况下，能够实现恒星形成区域的无监督分割", "innovation": "通过自我监督框架DINOv2对大量合成分形图像进行预训练，并将冻结后的模型应用于有限的高分辨率MHD模拟数据，改进了直接基于有限数据进行监督训练的方法，提高了预留模型的恒星质量预测精度。主成分分析揭示出了具有语义意义的结构，这表明模型能够实现恒星形成区域的无监督分割，无需标注数据或微调。", "conclusion": "本研究通过合成数据预训练，显著提高了恒星质量预测的准确性，并通过主成分分析揭示了附加的语义结构，展示了模型在恒星形成区域的无监督分割能力。这些发现为未来利用机器学习方法研究恒星形成提供了新的途径。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24215", "html_url": "https://arxiv.org/abs/2510.24215", "title": "在稀疏敌手干扰下的可恢复内容是什么？无假设线性测量的理论", "title_en": "What Can Be Recovered Under Sparse Adversarial Corruption? Assumption-Free Theory for Linear Measurements", "authors": "Vishal Halder(IMT Atlantique - INFO, Lab-STICC),Alexandre Reiffers-Masson(IMT Atlantique - INFO, Lab-STICC),Abdeldjalil Aïssa-El-Bey(IMT Atlantique - MEE, Lab-STICC),Gugan Thoppe(CSA, IISc)", "background": "该研究讨论了在给定矩阵A和一个q-稀疏敌手向量e的情况下，最小化未知向量$x^*$所用信息，只要只知道y = Ax* + e的线性测量结果，而不知道e。虽然精确恢复$x^*$需要矩阵A或$x^*$具备某些强结构假设，如限制等距性质或稀疏性质，但这些假设并不总是在实际应用场景中适用。因此，研究在任何A和$x^*$情况下，最可能唯一恢复的内容是什么，是一个值得探索的问题。", "innovation": "该研究的主要创新在于证明了在任何A和$x^*$的情况下，最有希望唯一恢复的是$x^* + \text{ker}(\bm{U})$，其中$\bm{U}$是唯一投影矩阵，投影基是所有通过删除A的2q行的所有可能子矩阵行空间的交集。此外，研究还证明了最小化$\bm{y} - \bm{A} x$的$\bm{l}_0$范数的每个解$x$都包含在$x^* + \text{ker}(\bm{U})$中，从而提供了一种构造性方法来恢复这一集合。", "conclusion": "该论文的结论是，对于任何形式的A和$x^*$，最有可能唯一恢复的信息是$x^* + \text{ker}(\bm{U})$，其中$\bm{U}$定义如前。同时，该研究提供了一种基于解$\bm{l}_0$范数最小化的方法来系统地恢复$x^* + \text{ker}(\bm{U})$。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24256", "html_url": "https://arxiv.org/abs/2510.24256", "title": "从损失曲率光谱中的记忆到推理", "title_en": "From Memorization to Reasoning in the Spectrum of Loss Curvature", "authors": "Jack Merullo,Srihita Vatsavaya,Lucius Bushnaq,Owen Lewis", "background": "我们研究了 transformer 模型中记忆的表示方式，并展示了如何使用基于损失景观曲率的分解方法将其在语言模型和视觉变压器的权重中分离。先前的理论和实验证据表明，被记忆的数据点与未被记忆的数据点相比，其曲率更加尖锐。因此，可以通过按高到低排列权重组件的曲率来发现这种区别，而无需显式的标签。这促使我们提出了一种权重编辑方法，该方法比最近的遗忘方法（BalancedSubnet）更有效地抑制未目标化的记忆数据的复述，同时保持较低的困惑度。该方法解释了曲率可以自然地解释模型权重中的共享结构，因此我们研究了这种编辑方法对下游任务的影响，发现具体和一致地对事实检索和算术任务产生了负面影响，尽管开放书籍事实检索和通用逻辑推理任务保持不变。我们通过展示任务数据在我们编辑出的低曲率组件的激活强度与其编辑后性能下降之间的对应关系来支持这种观点。这项工作增强了我们对神经网络中记忆理解，具有实际应用的去除记忆的能力，并提供了解决数学和事实检索等任务所需的独特和专用结构的证据。", "innovation": "提出了一种基于损失景观曲率的分解方法来分离语言模型和视觉变压器中记忆的表示，该方法能更有效地抑制未目标化的记忆数据的复述，同时保持较低的困惑度，并支持在编辑低曲率权重后任务性能下降的观点。这种方法能够揭发现有方法难以揭示的记忆化数据的特定方向，对下游任务产生负面影响。", "conclusion": "研究表明，模型中的记忆不仅受到每个数据点的影响，也受到权重空间的特定方向的影响，即使这些数据点并未被明确记忆。通过编辑低曲率的权重组件可以有效减少特定任务的性能下降，为去除神经网络中记忆提供了一种实际应用的方法，并进一步支持了特定结构对解决某些任务的重要性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24422", "html_url": "https://arxiv.org/abs/2510.24422", "title": "对基于PUF的二进制神经网络的安全攻击", "title_en": "Attack on a PUF-based Secure Binary Neural Network", "authors": "Bijeet Basak,Nupur Patil,Kurian Polachan,Srinivas Vivek", "background": "在边缘计算中，利用存阻器交叉阵列部署的二值神经网络（BNNs）可以提供能源高效的解决方案，但由于存阻器的非易失性，它们对物理攻击非常敏感。Rajendran等人提出了一种基于物理不可克隆函数（PUF）的安全方案，以保护BNNs免受盗窃攻击。该方案通过对BNN层的权重和偏置矩阵进行基于设备的PUF密钥比特进行列交换来实现安全性。", "innovation": "该论文展示了上述基于PUF的安全BNN方案容易受到PUF密钥恢复攻击。攻击方法受到差分密码分析的启发，逐个位重建PUF密钥，通过观察模型准确性的变化来恢复BNN的模型参数。", "conclusion": "在采用MNIST数据集训练的BNN上进行的实验结果显示，该攻击可以恢复85%的PUF密钥，并将BNN模型的分类准确率恢复到93%，原模型的准确率为96%。攻击非常高效，恢复PUF密钥和模型参数只需几分钟。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24433", "html_url": "https://arxiv.org/abs/2510.24433", "title": "Nearest Neighbor Matching as Least Squares Density Ratio Estimation and Riesz Regression", "title_en": "Nearest Neighbor Matching as Least Squares Density Ratio Estimation and Riesz Regression", "authors": "Masahiro Kato", "background": "本研究证明了最近邻（NN）匹配可以被解释为Riesz回归的一种类型，适用于自动去偏差机器学习。Lin等人（2023）表明NN匹配是密度比率估计的一种实例，而Chernozhukov等人（2024）发展了Riesz回归以实现自适应去偏差机器学习，直接估计Riesz表示子（或等效地，偏差校正项）以最小化均方误差。", "innovation": "该研究首先证明了Lin等人（2023）提出的密度比率估计方法实际上是Kanamori等人（2009）提出的直接密度比率估计的LSIF方法的本质等价形式。在此基础上，研究提出了使用LSIF框架的Riesz回归，并从Riesz回归推导出NN匹配。", "conclusion": "基于我们之前的工作Kato（2025a）和Kato（2025b），本研究揭示了NN匹配和LSIF之间以及Riesz回归之间的联系，为去偏差机器学习提供了新的视角。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24262", "html_url": "https://arxiv.org/abs/2510.24262", "title": "UtilGen：基于双层任务适配的效用导向生成数据增强", "title_en": "UtilGen: Utility-Centric Generative Data Augmentation with Dual-Level Task Adaptation", "authors": "Jiyu Guo,Shuo Yang,Yiming Huang,Yancheng Long,Xiaobo Xia,Xiu Su,Bo Zhao,Zeke Xie,Liqiang Nie", "background": "数据增强使用生成模型在计算机视觉任务中已经成为提升性能的强大范式。然而，现有的大多数增强方法主要集中在优化内在数据属性，如保真度和多样性，以生成高质量的合成数据，而往往忽视了特定任务的需求。训练数据的需求因不同的任务和网络架构而异，所以数据生成器需要适应下游任务的需求。因此，研究提出一种基于效用的数据增强框架UtilGen，以适应不同的任务需求并提高合成数据的效用。", "innovation": "提出了一种名为UtilGen的新颖的效用导向的数据增强框架，它采用双层优化策略，通过下游任务反馈迭代优化数据生成过程，以产生特定任务的高效用训练数据。具体而言，该框架首先引入了一个权重分配网络来评估每个合成样本的任务特定效用，随后利用两层优化策略调整生成策略：模型层面的优化针对下游任务定制生成模型，实例层面的优化调整每次生成阶段的生成策略，如提示嵌入和初始噪声等参数。", "conclusion": "在八个不同复杂度和粒度的标准数据集上的广泛试验表明，UtilGen可以持续地取得较好的性能，平均准确性提高了3.87%，且通过进一步的数据影响和分布分析，发现UtilGen生成的合成数据更加具有影响力和任务相关性，验证了从视觉特征导向到任务效用导向的数据增强范式转变的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24287", "html_url": "https://arxiv.org/abs/2510.24287", "title": "针对可操作的低血压预测——ICU中去肾上腺素治疗启动的预测", "title_en": "Towards actionable hypotension prediction- predicting catecholamine therapy initiation in the intensive care unit", "authors": "Richard Koebe,Noah Saibel,Juan Miguel Lopez Alcaraz,Simon Schäfer,Nils Strodthoff", "background": "在重症监护室（ICU）中，低血压在重症患者中十分常见且具有致命风险。去肾上腺素等药物的使用标志着治疗管理的关键步骤，不恰当的治疗可能导致治疗不足或过度治疗。大多数机器学习模型使用固定的平均动脉压（MAP）阈值预测低血压，或使用MAP预测，未能体现治疗升级背后的临床判断。研究团队利用MIMIC-III数据库，将去肾上腺素治疗启动事件定义为15分钟内的二元事件，通过整合生理变量、统计描述符和患者特征来预测该事件。研究使用了梯度提升树模型（XGBoost），并通过.SHAP分析来解释模型，结果表明其在识别低血压方面优于标准MAP阈值方法。", "innovation": "该研究的创新在于，将去肾上腺素治疗的启动作为预测目标，这一目标更具有临床相关性，能够更好地反映实际的治疗决策过程。通过建模去肾上腺素治疗的启动，研究提供了一种从血流动力学动态、治疗背景及患者特征等方面支持临床决策的方法。这不仅超越了传统的基于阈值的报警方法，还能够为广泛ICU患者提供实用的决策支持，即使在事件不平衡的情况下也能实现。", "conclusion": "通过梯度提升树模型 XGBoost 和.SHAP分析，研究展示了去肾上腺素治疗启动的高预测性能，特别是对于特定的人群子集。该研究表示这种方法在ICU患者的日常管理中可行，并为未来的丰富时间生理背景、扩展标签定义、与现有低血压预测系统进行基准测试提供了方向。这为临床治疗决策提供了新的工具和支持。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24452", "html_url": "https://arxiv.org/abs/2510.24452", "title": "ARIMA_PLUS：在Google BigQuery中进行大规模、准确、自动且可解释的数据库内时间序列预测和异常检测", "title_en": "ARIMA_PLUS: Large-scale, Accurate, Automatic and Interpretable In-Database Time Series Forecasting and Anomaly Detection in Google BigQuery", "authors": "Xi Cheng,Weijie Shen,Haoming Chen,Chaoyi Shen,Jean Ortega,Jiashang Liu,Steve Thomas,Honglin Zheng,Haoyun Wu,Yuxiang Li,Casey Lichtendahl,Jenny Ortiz,Gang Liu,Haiyang Qi,Omid Fatemieh,Chris Fry,Jing Jing Long", "background": "时间序列预测和异常检测是零售、制造、广告和能源等行业从业人员的常见任务。面临的独特挑战包括高效准确地在大量数据中自动进行时间序列预测或异常检测，以及确保结果的可解释性，以便有效地融入业务洞察。", "innovation": "ARIMA_PLUS 是一个新颖的框架，通过独特的组合解决了这两个挑战，即（a）准确且可解释的时间序列模型和（b）可扩展且完全托管的系统基础设施。ARIMA_PLUS 具备模块化结构，可以处理时间序列的不同组件，如假日效应、季节性、趋势和异常，从而提高了结果的可解释性。它全面基准测试显示了在Monash预测存储库中的42个公共数据集上比传统统计模型和新型神经网络模型都表现出更高的准确性。此外，其基础设施直接内置在Google Cloud的BigQuery查询引擎中，通过简单SQL接口自动化了繁琐的技术问题如数据清洗和模型选择，并能够自动扩展，只需1.5小时即可处理1亿个时间序列，吞吐量超过每秒18000个时间序列。", "conclusion": "我们通过案例研究展示了ARIMA_PLUS生成的时间序列见解和高度可定制性，展示了在Google BigQuery中进行大规模、准确、自动且可解释的时间序列预测和异常检测的能力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24288", "html_url": "https://arxiv.org/abs/2510.24288", "title": "问题参数无关的分布式 bilevel 优化", "title_en": "Problem-Parameter-Free Decentralized Bilevel Optimization", "authors": "Zhiwei Zhai,Wenjing Yan,Ying-Jun Angela Zhang", "background": "分布式 bilevel 优化因其在解决大规模机器学习问题中的关键作用而受到广泛关注。现有的方法往往依赖于对问题参数（如光滑性、凸性和通信网络拓扑）的先验知识来确定合适的步长，但在实践中这些参数通常是不可用的，这导致需要大量的手动工作来调节超参数。这一背景下，该论文提出了一种无需问题参数的算法 AdaSDBO，该算法具有单环结构，利用累积梯度范数来自适应地调整所有变量，动态调整进度，而不必进行问题特定的超参数调整。通过严格的理论分析，AdaSDBO 达到了 $\tilde{\text{O}}\frac{1}{T}$ 的收敛率，与调优的最新方法在多项对数因子内具有相同的性能。广泛的数值实验表明，AdaSDBO 的性能与现有分布式 bilevel 优化方法相当，且在不同的步长配置下表现出出色的稳健性。", "innovation": "提出了 AdaSDBO 算法，该算法是首个无需问题参数的分布式 bilevel 优化算法，通过自适应地利用累积梯度范数更新所有变量，动态调整进度，从而无需进行问题特定的超参数调整。理论分析表明，该算法的收敛率与调优的最新方法在多项对数因子内具有相同的性能，且在不同的步长配置下表现出出色的稳健性。", "conclusion": "AdaSDBO 是首个无需问题参数的分布式 bilevel 优化算法，具有单环结构，并通过自适应地利用累积梯度范数更新所有变量来动态调整进度，无需进行问题特定的超参数调整。通过严格的理论和实验验证，AdaSDBO 的表现与调优的最新方法相当，且具有很强的鲁棒性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24523", "html_url": "https://arxiv.org/abs/2510.24523", "title": "无监督机器学习流水线在缺陷检测与表征中的数据驱动应用：以位移级联为例", "title_en": "Unsupervised Machine-Learning Pipeline for Data-Driven Defect Detection and Characterisation: Application to Displacement Cascades", "authors": "Samuel Del Fré,Andrée de Backer,Christophe Domain,Ludovic Thuinet,Charlotte S. Becquart", "background": "中子辐照在几皮秒内会产生位移级联，即一系列原子碰撞，产生点缺陷和延展缺陷，并影响材料的长期演化。这些缺陷，从形态和统计学上进行描述，称为'原始损伤'。本文介绍了一个完全无监督的机器学习流程，直接从分子动力学数据中检测和分类这些缺陷。", "innovation": "提出了一个全新的无监督机器学习工作流程，利用Smooth Overlap of Atomic Positions (SOAP)向量编码局部环境，使用自动编码器神经网络（AE）隔离异常原子，结合Uniform Manifold Approximation and Projection (UMAP)嵌入和Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN)聚类。该方法应用于Ni、Fe70Ni10Cr20和Zr的80 keV位移级联，能成功识别参与缺陷形成的少量异常原子，并以高比例精确分类这些异常原子为紧凑的物理模式。", "conclusion": "该无监督机器学习工作流程为定量表征材料中的结构异常提供了一个高效的工具，特别是在位移级联引起的辐照损伤中。与传统检测器的统计交叉分析显示，该方法具有很强的重叠和补充覆盖，无需任何模板或阈值调整。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24557", "html_url": "https://arxiv.org/abs/2510.24557", "title": "物理知情神经运算器的边界条件强制方法", "title_en": "Enforcing boundary conditions for physics-informed neural operators", "authors": "Niklas Göschel,Sebastian Götschel,Daniel Ruprecht", "background": "基于机器学习的方法，如物理知情神经网络和物理知情神经运算器，日益擅长于解决复杂的偏微分方程组。边界条件可以通过弱化方式强制执行，即通过惩罚损失函数中的偏差，或者通过训练一个具有内在匹配预设值和导数的解结构来实现强约束方式。虽然弱化方式易于实现，但强约束方式在精度和训练时间方面可提供优势。然而，以往强约束Neumann或Robin边界条件的方法要求整个边界具有完整的$C^1$性质，如果在具有局部$C^0$但整体$C^1$性质不完整的边界段上提出边界条件，会导致不稳定性问题。已有研究通过Sukumar和Srivastava的方案对这个问题进行了解决，本文提出了一种基于正交投影的新方法来克服这个问题，两种方法均被用来与弱化和半弱化边界条件的方法对比，实验结果基于标量达西流方程和静止纳维-斯托克斯方程进行测试以评估其性能。", "innovation": "本文提出了一种通用方法和基于正交投影的新方法，以克服在局部$C^0$但整体$C^1$性质不完整的边界段上强制执行Neumann或Robin边界条件的不稳定性问题。这种新方法提高了模型在处理复杂边界条件问题时的稳定性和准确性，并能够更有效地利用数据集来训练模型，进而缩短训练时间。", "conclusion": "本文提出的方法通过解决边界条件的强约束问题，提高了模型在处理复杂偏微分方程组时的准确性和训练效率。这些新方法在标量达西流方程和静止纳维-斯托克斯方程的测试中表现良好，为物理学启发式的神经运算器的应用提供了新的途径。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24601", "html_url": "https://arxiv.org/abs/2510.24601", "title": "广义加性模型与神经网络在应用中的比较：系统综述", "title_en": "Comparison of generalised additive models and neural networks in applications: A systematic review", "authors": "Jessica Doohan,Lucas Kook,Kevin Burke", "background": "神经网络已成为预测建模的热门工具，通常与机器学习和人工智能相关联，而不是与统计学相关联。广义加性模型（GAMs）是一种灵活的非线性统计模型，保留了可解释性。尽管彼此优点和缺点不同，但两者在各自领域都是最先进的。本文基于系统评估指南，对进行了GAMs与神经网络对比研究的论文进行了系统性综述，筛选出143篇论文和430个数据集，从文献和数据集层面提取并报告了关键属性。在不同的数据集上，关于最常见的评估指标（RMSE、$R^2$和AUC）没有一致证据表明GAMs或神经网络在性能上优越。神经网络在大数据集和多预测变量的数据集上表现更好，但这种优势随时间减弱。相反，GAMs在小数据集中依然具有竞争力，并保持了可解释性。大多数文献中报告的数据集特征和神经网络复杂性不完整，限制了透明度和可重复性。这项综述强调，GAMs和神经网络应被视为互补的方法，而不是竞争对手，对于许多表格应用，性能权衡很小，而可解释性可能更倾向于选择GAMs。", "innovation": "该研究首次基于系统评估指南，对近150篇论文进行了综述，提取并报告了关键属性，并使用混合效应模型分析了报告的性能指标，以探索潜在的特性以解释和量化观察到的差异，包括应用领域、研究年份、样本量、预测变量数量和神经网络复杂性。该研究的创新之处在于它提供了一个全面的比较，并为未来的研究提供了新的视角。", "conclusion": "在大多数表格应用中，GAMs和神经网络的性能权衡很小。对于小数据集或需要解释模型行为的应用场景，GAMs可能更占优势。神经网络在大型数据集和多特征数据集中表现出优势，但这种优势随时间减弱。此外，这篇综述还强调了报告数据集特征和神经网络复杂性的重要性，以提高透明度和可重复性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24616", "html_url": "https://arxiv.org/abs/2510.24616", "title": "深Learning中的统计物理学：多层感知器在插值附近的最佳学习", "title_en": "Statistical physics of deep learning: Optimal learning of a multi-layer perceptron near interpolation", "authors": "Jean Barbier,Francesco Camilli,Minh-Toan Nguyen,Mauro Pastore,Rudy Skerk", "background": "统计物理学在过去三十年中为分析神经网络提供了一个框架。长期以来，统计物理学在处理具有丰富特征学习效果的深度学习模型方面存在局限，这些模型超越了迄今为止分析的狭窄网络或核方法。本文通过研究监督学习中的多层感知器来积极地回答这一问题。这有助于理解统计物理学在深度学习中的作用，特别是在特征学习层面。研究集中在参数数量和数据量相当的插值区间，这将模型推向了适应任务的过程。", "innovation": "研究指出，多层感知器的宽度与输入维度成比例，使其更适合特征学习，且相比狭窄的网络或固定嵌入层更具表达能力。重点在其具有挑战性的插值区间的学习，这一区间迫使模型适应任务。考虑匹配的教师-学生设置，有助于识别学习随机深度神经网络目标的充分统计数据，特别是在数据预算增加的情况下。研究揭示了学习过程中的丰富现象，包括不同层级和神经元间的不均匀专业化，以及深度目标的更难学习。尽管该模型结构简单，但它提供了关于深度、非线性和有限宽度如何影响特征学习阶段神经网络运作的见解，而这些见解可能在更广泛的领域内具有相关性。", "conclusion": "尽管简单的贝叶斯最优设置提供了关于深度、非线性和有限宽度如何影响深度神经网络在特征学习阶段运作的见解，但在具有足够数据的情况下，仍然是通过模型的“专业化”来最佳地获得性能，但训练算法可能会被理论预测的次优解所吸引。专业化在不同层次之间以及每个层次内都是非均匀的，更深层次的目标更难学习。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24242", "html_url": "https://arxiv.org/abs/2510.24242", "title": "通过大型视觉语言模型的卫星-地面协作实现近实时遥感", "title_en": "Enabling Near-realtime Remote Sensing via Satellite-Ground Collaboration of Large Vision-Language Models", "authors": "Zihan Li,Jiahao Yang,Yuxin Zhang,Zhe Chen,Yue Gao", "background": "大型视觉语言模型（LVLMs）在遥感（RS）任务（例如灾害监测）中展现出了巨大潜力，尤其是在低地球轨道（LEO）卫星上。但由于这些模型需要大量的计算资源，而LEO卫星的机载计算资源有限，且卫星与地面站之间的连接时间短暂，因此它们在实际LEO卫星系统中的应用尚未得到充分探索。为了解决这个问题，本文提出了一种名为Grace的卫星-地面协作系统，用于遥感任务的近实时LVLM推断。该系统在卫星上部署了紧凑的LVLM模块以实现实时推理，而在地面站上部署了更大的LVLM模块以保证端到端的性能。系统包括两大部分：异步卫星-地面检索增强生成（RAG）和任务调度算法。此外，通过专门的自适应更新算法，在卫星与地面站之间数据交换有限的时间段内，固定地面站RAG的知识库并将其移植到卫星的知识库中。最后，提出了一种基于置信度的测试算法，该算法可以根据具体情况选择将任务在卫星上处理或卸载到地面站上处理。实验结果表明，Grace相比现有的最先进的方法可以使平均延迟降低76-95%，同时保持推理的准确性。", "innovation": "1. 提出了一种名为Grace的卫星-地面协作系统，用于遥感任务的近实时LVLM推断。\n2. 在卫星上部署紧凑的LVLM模块以实现实时推理，在地面站上部署更大的模块以保证整体性能。\n3. 提出了异步卫星-地面检索增强生成（RAG）和基于置信度的任务调度算法，以适应有限的卫星-地面数据交换。\n4. 在真实卫星轨道数据上的实验表明，Grace能够有效降低延迟并保持推理准确性。", "conclusion": "Grace系统通过卫星-地面合作的方式，显著降低了遥感任务中的平均延迟，同时保持了推理的准确性，为LEO卫星系统中的LVLM应用提供了新的解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24699", "html_url": "https://arxiv.org/abs/2510.24699", "title": "AgentFold：具有主动上下文管理的长时Web代理", "title_en": "AgentFold: Long-Horizon Web Agents with Proactive Context Management", "authors": "Rui Ye,Zhongwang Zhang,Kuan Li,Huifeng Yin,Zhengwei Tao,Yida Zhao,Liangcai Su,Liwen Zhang,Zile Qiao,Xinyu Wang,Pengjun Xie,Fei Huang,Siheng Chen,Jingren Zhou,Yong Jiang", "background": "基于LLM的Web代理在信息检索方面显示出巨大的潜力，但在执行长期任务时，它们的有效性受到上下文管理中的根本权衡的限制。现有的ReAct基代理遭受了上下文饱和的问题，因为它们积累了大量的杂乱无章的原始历史记录，而那些固定地在每一步总结完整的现代代理则面临了关键细节不可挽回的损失风险。", "innovation": "作者引入了AgentFold，这是一种新的代理范式，以主动的上下文管理为核心，受到了人类认知过程中的回顾性整合的启发。AgentFold将上下文视为一个动态的认知工作空间，由主动塑造，而不是被动记录填满。在每一步，它学习执行一个‘折叠’操作，该操作可以跨多个级别管理它的历史轨迹：它能够进行粒度浓缩以保留重要的、细粒度的细节，也可以进行深入整合以抽象掉整个多步子任务。", "conclusion": "在主要基准测试中，使用简单的监督微调（不包括持续预训练或RL），我们的AgentFold-30B-A3B代理在BrowseComp上获得了36.2%的成绩，在BrowseComp-ZH上获得了47.3%的成绩。值得注意的是，该性能不仅超越了规模远大于其的开源模型，如DeepSeek-V3.1-671B-A37B，还超越了领先的专业代理，如OpenAI的o4-mini。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24621", "html_url": "https://arxiv.org/abs/2510.24621", "title": "稳健几何中值的聚类核：消除异常值大小依赖", "title_en": "Coreset for Robust Geometric Median: Eliminating Size Dependency on Outliers", "authors": "Ziyi Fang,Lingxiao Huang,Runkai Yang", "background": "该论文研究了欧几里得空间$\\mathbb{R}^d$中的稳健几何中值问题，并重点探讨了如何构建聚类核（coreset）。聚类核是对数据集$P$的一个紧凑摘要，其大小为$n$，能近似计算所有中心$c$的稳健成本，误差约为乘性误差$\\varepsilon$。在此之前，已有研究（Huang等人，2022及2023年）存在关于异常值数量$m$的依赖性。论文进一步将结果推广至各种度量空间中的稳健$(k,z)$聚类，同时在数据假设较弱的情况下还能消除异常值的数量依赖。", "innovation": "主要创新点在于提出了一种新颖的非分量误差分析方法，通过这种方法显著减少了异常值的影响。与其他方法不同，这种新方法不保留异常值的影响。该论文构建的聚类核大小相对于之前的依赖性减少，尤其是在$n \ngeq 4m$时，构建一个大小为$\\tilde{O}(\\varepsilon^{-2} \\cdot \\min\\{\\varepsilon^{-2}, d/MM)$的聚类核。对于单一维度$d = 1$的情况，该论文实现了最优聚类核大小$\\tilde{\\Theta}(\\varepsilon^{-1/2} + \frac{m}{n} \\\nvarepsilon^{-1})$，并与之前的文献（Huang等人，2023年；及Afshani和Chris，2024年）的研究进行了对比。", "conclusion": "该论文进一步将其结果扩展到了各种度量空间中的稳健$(k,z)$聚类，通过非分量误差分析方法显著减小了异常值的影响。实验结果表明，该算法在大小-精度折衷以及运行时间方面表现优异，即使在数据假设被违背的情况下表现同样良好。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24701", "html_url": "https://arxiv.org/abs/2510.24701", "title": "Tongyi DeepResearch技术报告", "title_en": "Tongyi DeepResearch Technical Report", "authors": "Tongyi DeepResearch Team:Baixuan Li,Bo Zhang,Dingchu Zhang,Fei Huang,Guangyu Li,Guoxin Chen,Huifeng Yin,Jialong Wu,Jingren Zhou,Kuan Li,Liangcai Su,Litu Ou,Liwen Zhang,Pengjun Xie,Rui Ye,Wenbiao Yin,Xinmiao Yu,Xinyu Wang,Xixi Wu,Xuanzhong Chen,Yida Zhao,Zhen Zhang,Zhengwei Tao,Zhongwang Zhang,Zile Qiao,Chenxi Wang,Donglei Yu,Gang Fu,Haiyang Shen,Jiayin Yang,Jun Lin,Junkai Zhang,Kui Zeng,Li Yang,Hailong Yin,Maojia Song,Ming Yan,Peng Xia,Qian Xiao,Rui Min,Ruixue Ding,Runnan Fang,Shaowei Chen,Shen Huang,Shihang Wang,Shihao Cai,Weizhou Shen,Xiaobin Wang,Xin Guan,Xinyu Geng,Yingcheng Shi,Yuning Wu,Zhuo Chen,Zijian Li,Yong Jiang", "background": "探讨了针对长期、深入的信息搜索研究任务设计的代理型大型语言模型（LSTM），特别是在自动深度研究代理方面的需求。", "innovation": "提出了一种端到端的训练框架，结合代理型中间训练和代理型后续训练，以实现跨复杂任务的可扩展推理和信息搜索。设计了一个完全自动的数据合成管道，无需依赖昂贵的人工标注，以增强所有培训阶段。为每个阶段构建了定制化环境，从而使系统可以稳定和一致地进行交互。", "conclusion": "Tongyi DeepResearch模型具有305亿个总参数，每个标记只有3.3亿个被激活，表现出色，可在一系列代理型深度研究基准测试中取得最先进的性能。开源模型、框架和完整解决方案以赋能社区。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24466", "html_url": "https://arxiv.org/abs/2510.24466", "title": "具有分段可解析激活函数的神经网络中梯度下降映射的非奇异性质", "title_en": "Non-Singularity of the Gradient Descent map for Neural Networks with Piecewise Analytic Activations", "authors": "Alexandru Crăciun,Debarghya Ghoshdastidar", "background": "深度网络的训练理论已成为现代机器学习的核心问题，并且激发了许多实际进展。近年来，梯度下降（GD）优化算法得到了广泛研究。关于GD的一个关键假设是：GD映射并非奇异——它在预像下保测度为零的集子。这个假设被用于证明GD避免鞍点和最大值，并且建立了存在可计算量确定向全局最小值收敛（对于GD和随机梯度下降SGD均适用）。然而，现有文献要么假设GD映射的非奇异性质，要么施加限制性假设，如损失的Lipschitz光滑性（深度ReLU网络使用交叉熵损失时不成立）并且限制分析使用小步长的GD。本研究探讨了权重和偏置空间上的神经网络映射，并首次证明了具有全连接、卷积或softmax注意力层和可解析激活函数（包括Sigmoid、ReLU、Leaky ReLU等）的实际神经网络架构下，对于几乎所有步长，GD映射的非奇异性质。这一结果显著扩展了GD和SGD收敛性的现有研究成果，使之适用于实际的神经网络设置，有望进一步探索学习动力学。", "innovation": "首次证明了具有全连接、卷积或softmax注意力层和分段可解析激活函数的实际神经网络架构下，几乎所有步长的GD映射的非奇异性质。这显著扩展了GD和SGD收敛性的现有研究结果，使这些结果适用于实际的神经网络设置，为进一步探索学习动力学提供了可能。", "conclusion": "本研究证明了对于实际神经网络架构和分段可解析激活函数，GD映射的非奇异性质几乎对于所有步长都是成立的。这一发现扩展了GD和SGD的适用范围，有助于理论研究和实际应用。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2301.07530", "html_url": "https://arxiv.org/abs/2301.07530", "title": "通过调和乐观性进行在线（非）凸学习", "title_en": "Online (Non-)Convex Learning via Tempered Optimism", "authors": "Maxime Haddouche,Olivier Wintenberger,Benjamin Guedj", "background": "乐观在线学习旨在利用专家提供的可靠信息来预测未来。然而，在实际构建这类专家时，这种隐含的乐观性可能受到挑战。特别是在动态环境中，这种专家能提供的信息是部分相关的，可能导致过拟合。", "innovation": "提出了调和乐观（OT）在线学习框架以处理这样的不完美专家。通过提出对在线梯度下降和镜子下降的简单而强大的改进，证明了调和乐观是在线非凸学习的一个有成效的范式。另外，还提出了另一种调和乐观算法用于凸损失，并评估了调和乐观在真实数据集和玩具实验上的实际效率。", "conclusion": "调和乐观是一种有效的在线学习（非）凸问题处理方式，能够改进算法性能并提高其实用性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24718", "html_url": "https://arxiv.org/abs/2510.24718", "title": "生成视图缝合", "title_en": "Generative View Stitching", "authors": "Chonghyuk Song,Michal Stary,Boyuan Chen,George Kopanas,Vincent Sitzmann", "background": "自回归视频扩散模型能够生成长期并保持稳定且与历史一致的视频，但它们无法在当前生成过程中利用未来的信息进行指导。在根据预定义摄像机轨迹进行摄像机引导视频生成时，这种限制会导致生成的场景与摄像机路径发生碰撞，而自回归模型很快就会崩溃。", "innovation": "我们提出了生成视图缝合（GVS），它能够并行采样整个序列，使生成的场景忠实于预定义的每部分摄像机轨迹。GVS使用扩散缝合技术扩展了机器人规划领域的先前工作，并与任何使用扩散强迫训练的现成视频模型兼容，扩散强迫是一种常见的序列扩散框架，已经提供了缝合所需的属性。我们还引入了全方位引导技术，通过结合过去和未来的信息增强了缝合的时间一致性，并使我们提出的闭环机制能够实现长距离的连贯性。", "conclusion": "生成视图缝合实现了摄像机引导视频生成，该生成过程是稳定的，无碰撞的，帧到帧一致的，并能够闭合与各种预定义的摄像机路径相关的环。结果可以在下方链接查看：[这里](https://thisisanexample.com/link)"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2004.06231", "html_url": "https://arxiv.org/abs/2004.06231", "title": "Einsum Networks: 快速且可扩展的学习可处理的概率电路", "title_en": "Einsum Networks: Fast and Scalable Learning of Tractable Probabilistic Circuits", "authors": "Robert Peharz,Steven Lang,Antonio Vergari,Karl Stelzner,Alejandro Molina,Martin Trapp,Guy Van den Broeck,Kristian Kersting,Zoubin Ghahramani", "background": "概率电路（PCs）是一种有前途的概率建模方法，允许广泛的精确和高效推理操作。现有的‘深度学习风格’PC实现追求更好的可扩展性，但由于其稀疏连接的计算图，仍然难以在真实数据上进行训练。", "innovation": "我们提出了Einsum Networks（EiNets），这是一种新型的PC实现设计，改进了先前的技术。EiNets的核心在于在一个单一的monolithic einsum-operation中结合了大量的算术运算，相较于先前的实现，可以提供高达两个数量级的速度提升和内存节省。我们还简化了对PCs实现EM算法的方法，并展示了EiNets可以很好地扩展到如SVHN和CelebA等之前的难以处理的数据集上，同时能够用作有效的生成图像模型。", "conclusion": "EiNets相对于之前的实现技术改进了多个方面，并能够更好地扩展到大型和复杂的现实数据集上，成功地用作生成图像模型。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24709", "html_url": "https://arxiv.org/abs/2510.24709", "title": "大预训练视觉变换器中物体绑定能力是否会自然产生？", "title_en": "Does Object Binding Naturally Emerge in Large Pretrained Vision Transformers?", "authors": "Yihao Li,Saeed Salehi,Lyle Ungar,Konrad P. Kording", "background": "物体绑定是人类认知的核心能力，它将代表一个物体的所有特征进行综合，并组建成高效的记忆中的高层次物体表示，支持对物体个体的推理。以往的研究常常通过将注意力集中于物体的方式来探究这些好处，但不清楚这种能力是否会在预训练视觉变换器（ViTs）中自然产生。自注意力机制的二次性质让我们推测，ViTs 可能会表示哪两个补丁属于同一物体这一属性。", "innovation": "通过解码补丁嵌入中是否存在两个补丁属于同一物体的属性 (IsSameObject)，发现这种物体绑定能力在自监督预训练的ViTs 中可靠地生成，但在基于ImageNet 的监督预训练模型中较弱。这表明物体绑定不是简单的架构性特征，而是在特定预训练目标下获得的能力。进一步发现 IsSameObject 编码在物体特征之上的一维子空间中，并且这种信号积极引导注意力。", "conclusion": "研究表明，ViTs 并不是缺乏物体绑定能力，物体绑定能力自然地在连接主义系统中出现，并且象征性知识“哪些部分属于同一物体”会自然产生。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24546", "html_url": "https://arxiv.org/abs/2510.24546", "title": "双智心理世界模型：在动态无线网络中学习的一般框架", "title_en": "Dual-Mind World Models: A General Framework for Learning in Dynamic Wireless Networks", "authors": "Lingyi Wang,Rashed Shelim,Walid Saad,Naren Ramakrishnan", "background": "尽管强化学习（RL）在无线网络中的应用非常流行，现有依赖于无模型强化学习（MFRL）和模型化强化学习（MBRL）的方法效率低下且目光短浅。这些基于RL的解决方案无法泛化到新的网络状态，因为它们只能捕捉到无线数据中的统计模式，而不是底层的物理和逻辑关系。特别是在高动态性和长期规划需求复杂的无线网络中，这些限制尤为突出。", "innovation": "本文提出了一个新颖的双智心理模型化学习框架，旨在优化复杂毫米波V2X场景中的完备性加权信息新鲜度（CAoI）。该框架借鉴了认知心理学，其中包括一个模式驱动的System 1组件和一个逻辑驱动的System 2组件，用于学习无线网络的动力学和逻辑关系，并通过假设可靠的未来轨迹路径进行长期链路调度。通过端到端可微分的想象轨迹进行链路调度学习，与依赖无线数据获得环境互动的方法不同，该方法可以在没有观测区间内做出高效的决策。", "conclusion": "在基于Sionna的真实仿真器上进行的广泛实验中，证明了所提出的方法在数据效率方面取得了显著改进，并在未知环境中的泛化和适应性方面表现出色，超越了最先进的基于RL的基线方法和只有System 1的模型化方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2306.08848", "html_url": "https://arxiv.org/abs/2306.08848", "title": "机器学习传感器数据表", "title_en": "Datasheets for Machine Learning Sensors", "authors": "Matthew Stewart,Yuke Zhang,Pete Warden,Yasmine Omri,Shvetank Prakash,Jacob Huckelberry,Joao Henrique Santos,Shawn Hymel,Benjamin Yeager Brown,Jim MacArthur,Nat Jeffries,Emanuel Moss,Mona Sloane,Brian Plancher,Vijay Janapa Reddi", "background": "随着机器学习(ML)在嵌入式AI传感系统中的普及，这些“ML传感器”能够在不同应用中提供上下文感知的实时数据收集和决策，如工业场景中的异常检测和野生动物跟踪保护。为了确保这些ML驱动的传感系统的可再现性，应对监管和行业政策的最新合规性和审计要求，以及验证和验证其操作的负责任性，需要对其运行提供透明度。因此，论文提出了ML传感器数据表框架。", "innovation": "论文引入了ML传感器数据表框架，提供了一个全面的模板，该模板在学术界和工业界的合作伙伴共同开发下，涵盖了ML传感器的独特属性，包括硬件规格、ML模型和数据集特性、端到端性能指标以及环境影响。框架还关注连续流数据和实时处理需求，并嵌入了反映实际部署条件的基准测试方法，确保其实用性。该方法与FAIR原则（可查找性、可访问性、互操作性和可重用性）一致，提高了ML传感器文档在学术界、工业界和监管领域的透明性和可重用性。", "conclusion": "为了展示该方法的应用，论文呈现了两个数据表：一个是内部设计的开源ML传感器的数据表，另一个是工业合作伙伴开发的商业ML传感器的数据表，两者都基于计算机视觉进行人员检测。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24619", "html_url": "https://arxiv.org/abs/2510.24619", "title": "使用前缀适配的零样本跨语言迁移", "title_en": "Zero-Shot Cross-Lingual Transfer using Prefix-Based Adaptation", "authors": "Snegha A(1),Sayambhu Sen(2),Piyush Singh Pasi(2),Abhishek Singhania(2),Preethi Jyothi(1) ((1) Indian Institute of Technology Bombay, (2) Amazon Alexa)", "background": "由于新大型语言模型（LLMs）如Llama和Mistral的多语言预训练和较强的泛化能力，零样本跨语言迁移变得越来越可行。但是，将这些仅解码器的LLMs适应到不同语言的新任务仍然具有挑战性。虽然参数高效微调（PeFT）技术，如Low-Rank Adaptation（LoRA）被广泛使用，但前缀技术，如软提示调优、前缀调优等，在零样本跨语言迁移中对仅解码器模型的应用较少被探索。", "innovation": "本研究对三种前缀方法进行了综合研究，用于从英语到35多种高和低资源语言的零样本跨语言迁移。该分析进一步探讨了在语言家族和书写系统间转移的情况，以及从1B到24B模型规模的扩大影响。使用Llama 3.1 8B以及前缀方法，在Belebele基准测试中比LoRA基准提高了最高6%的性能。在使用前缀调优学习参数仅为1.23M的情况下，我们取得了在多种基准测试中均有所改进的结果。这些发现表明，前缀技术在低资源多语言设置中有可能成为LoRA的有效且具有扩展性的替代方案。", "conclusion": "研究发现，前缀技术在小参数和低资源多语言设置中表现出色，能够较为有效地提升语言模型的零样本跨语言迁移能力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.06328", "html_url": "https://arxiv.org/abs/2310.06328", "title": "UniCrossFi: 一种跨域Wi-Fi手势识别统一框架", "title_en": "UniCrossFi: A Unified Framework For Cross-Domain Wi-Fi-based Gesture Recognition", "authors": "Ke Xu,Zhiyong Zheng,Hongyuan Zhu,Lei Wang,Jiangtao Wang", "background": "Wi-Fi传感系统在未见的实际环境中部署时受跨域问题严重阻碍。现有的方法通常为域适应或领域泛化设计独立框架，通常依赖大量标记数据。针对更复杂的真实世界场景，该模型需要在有限标记源数据下进行泛化。现有方法中的领域泛化往往依赖于大量标注数据，而实际场景远比这复杂。", "innovation": "本文提出了UniCrossFi，一种统一框架，旨在减轻基于CSI的传感跨多种部署环境的性能下降。框架不仅将传统域泛化扩展到半监督域泛化设置，其中只提供部分标记源数据，还引入了一种基于天线响应一致性的物理信息数据增强策略。此外，设计了一个统一的对比学习目标，防止传统的对比学习将同一类别的不同域的样本分开。实验结果表明UniCrossFi在所有无监督域适应、DG和SSDG基准上均实现了新的绩效水平，显著优于现有方法。", "conclusion": "UniCrossFi提供了一个原则性和实用性的解决方案，推动了在有限标记数据下有效运作的稳健的、实际的Wi-Fi传感系统的发展。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.00913", "html_url": "https://arxiv.org/abs/2501.00913", "title": "β-DQN：通过进化行为改进深度Q学习", "title_en": "$β$-DQN: Improving Deep Q-Learning By Evolving the Behavior", "authors": "Hongming Zhang,Fengshuo Bai,Chenjun Xiao,Chao Gao,Bo Xu,Martin Müller", "background": "尽管已经提出了许多复杂的探索方法，但由于这些方法的通用性和高计算成本，研究人员往往更倾向于使用简单的ε-贪心方法。本研究旨在解决这一问题。", "innovation": "引入了β-DQN，一种简单的高效探索方法，通过增加一个行为函数β，来增强标准的DQN。β评估了在每个状态下执行每个动作的概率。通过利用β，生成了多样化策略的群体，平衡了状态-动作覆盖和过度估计偏差修正。设计了一个自适应元控制器，为每个回合选择最有效的策略，实现灵活且可解释的探索。β-DQN 实现简单，对标准DQN增加的计算成本极少。", "conclusion": "β-DQN 在简单和复杂的探索域中显示出比已有基线方法更好的性能，提供了一种有效提高深度强化学习中探索的解决方案。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.10028", "html_url": "https://arxiv.org/abs/2402.10028", "title": "扩散模型与上下文臂赛博弈的融合", "title_en": "Diffusion Models Meet Contextual Bandits", "authors": "Imad Aouali", "background": "在上下文臂赛博弈中进行有效的在线决策具有挑战性，因为没有先验知识的方法往往在计算效率或统计效率方面存在问题。", "innovation": "利用预训练的扩散模型作为表达性的先验知识来捕捉复杂的动作依赖性，并开发了一种实用的算法，该算法能够在这样的先验知识下高效地近似后验分布，从而实现快速更新和采样。", "conclusion": "实验结果表明了该方法的有效性和在多种上下文臂赛博弈设置中的多功能性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.19000", "html_url": "https://arxiv.org/abs/2405.19000", "title": "FedMAP: 个性化 federated 学习在真实大规模医疗健康系统中的应用", "title_en": "FedMAP: Personalised Federated Learning for Real Large-Scale Healthcare Systems", "authors": "Fan Zhang,Daniel Kreuter,Carlos Esteve-Yagüe,Sören Dittmer,Javier Fernandez-Marques,Samantha Ip,BloodCounts! Consortium,Norbert C.J. de Wit,Angela Wood,James HF Rudd,Nicholas Lane,Nicholas S Gleadall,Carola-Bibiane Schönlieb,Michael Roberts", "background": "联邦学习（FL）能促进医疗机构间的协作机器学习，同时保护数据隐私。实际部署受限于由患者人口统计、治疗方法和结果差异以及基础设施限制引起的统计异质性。本文探讨了在不同医疗机构基础设施和技术能力不一的情况下，如何实现大规模的医疗健康联邦学习部署挑战。", "innovation": "介绍了FedMAP，一种通过局部最大后验（MAP）估计与输入凸神经网络先验来应对异质性的个性化联邦学习（PFL）框架。这些先验能够从其他机构收集到的全局知识引导模型，并适应本地数据的变化。与依赖固定正则化的许多PFL方法不同，FedMAP的先验可以自适应学习复杂的跨机构关系模式。通过三个大规模临床数据集（心血管风险预测、铁缺乏检测和死亡率预测）实验，FedMAP比本地训练、FedAvg和其他几种PFL方法显示了更好的性能。此外，FedMAP采用三层设计，适用于不同基础设施和技术能力的医疗机构的参与，从全联邦训练到仅推理部署都有涵盖。地理分析表明，该框架在解决不同地区的性能差距方面表现出色，不发达区域可以提高14.3%的性能。", "conclusion": "该框架提供了大规模医疗健康联邦学习部署的第一个实用路径，确保各级临床机构能够从中受益，提高公平性并保留隐私。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.10856", "html_url": "https://arxiv.org/abs/2412.10856", "title": "RWKV-edge：为资源受限设备深度压缩的RWKV", "title_en": "RWKV-edge: Deeply Compressed RWKV for Resource-Constrained Devices", "authors": "Wonkyo Choe,Yangfeng Ji,Felix Xiaozhu Lin", "background": "近年来，非变压器架构的大型语言模型（LLMs）在移动机器人和智能手机等资源受限平台上取得了重要突破。特别是基于递归神经网络（RNN）的新型LLM家族Repentance Weighted Key Value (RWKV)展现了强大的计算效率，但其仍具有较高的参数量，限制了其应用部署。", "innovation": "本文提出了一种压缩技术套件，涵盖了从模型架构优化到后训练压缩等方法，并专门针对RWKV架构进行优化。结合使用这些技术，可以将RWKV模型的内存占用量减少3.4到5倍，同时只造成微不足道的准确率下降；与具有类似准确率的变压器模型相比，本文模型所需的内存占用量降低了4倍。", "conclusion": "研究结果表明，通过一系列压缩技术，可以有效减小RWKV模型的内存占用，同时保持其计算效率和准确率，从而更加适配资源受限设备的应用需求。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24710", "html_url": "https://arxiv.org/abs/2510.24710", "title": "线性约束 bilevel 优化的单环次梯度算法", "title_en": "A Single-Loop First-Order Algorithm for Linearly Constrained Bilevel Optimization", "authors": "Wei Shen,Jiawei Zhang,Minhui Huang,Cong Shen", "background": "本文研究了下层问题为强凸且具有耦合线性约束的 bilevel 优化问题。由于原始问题目标函数的潜在非光滑性及海森矩阵计算的挑战，本文利用惩罚和增广拉格rangian方法将初始问题重新表述为单层优化问题。通过刻画重新表述函数和原始超目标函数值及其导数的接近性，建立了两者之间的强理论联系。基于此重新表述，提出了一种线性约束 bilevel 优化的单环次梯度算法 (SFLCB)。", "innovation": "本文提出的 SFLCB 算法在收敛速度上有所改进，非渐近收敛速率为 O(ε⁻³) 而不是先前双环算法的 O(ε⁻³log(ε⁻¹))，并提供严格的理论分析支持。实验结果验证了理论分析，显示出所提 SFLCB 算法的实际高效性。", "conclusion": "本文利用惩罚和增广拉格rangian方法重新表述了 bilevel 优化问题，提出了 SFLCB 算法，并证明了与现有算法相比具有更快的收敛速度。通过实验验证了算法的有效性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.22366", "html_url": "https://arxiv.org/abs/2410.22366", "title": "一成不变：文本到图像扩散模型中的稀疏自编码器", "title_en": "One-Step is Enough: Sparse Autoencoders for Text-to-Image Diffusion Models", "authors": "Viacheslav Surkov,Chris Wendler,Antonio Mari,Mikhail Terekhov,Justin Deschenaux,Robert West,Caglar Gulcehre,David Bau", "background": "对于大型语言模型（LLMs），已经证明稀疏自编码器（SAEs）可以将中间表示分解为稀疏可解释特征的总和，从而实现更好的控制和后续分析。然而，对于文本到图像模型，类似的分析和方法却很少。本文旨在探讨SAEs在文本到图像扩散模型SDXL Turbo中的应用，通过在1步设置下训练SAEs，对其在4步SDXL Turbo和多步SDXL基础模型中的泛化能力进行研究。并通过创建基于表示的图像编辑基准RIEBench，验证SAEs的学习特征具有可解释性，并且能影响生成过程，揭示各块的特化程度。", "innovation": "本文是首次研究SAEs在文本到图像扩散模型中的可解释性，并且证明了SAEs在多步SDXL基础模型中具有潜在的应用价值。通过创建RIEBench，本文实现了根据编辑类别跟踪特征的影响，确保其研究方法的创新性。", "conclusion": "本文的研究结果显示SAEs作为一种理解并操控文本到图像模型内部机制的有前景的方法，这种分析方法能够提供重要的见解，帮助更好地理解和控制文本到图像生成过程中的特征选择和发展。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.00919", "html_url": "https://arxiv.org/abs/2501.00919", "title": "几何因素的重要性：通过Ollivier-Ricci 曲率和 Ricci 流揭示表征对齐的见解", "title_en": "Geometry matters: insights from Ollivier Ricci Curvature and Ricci Flow into representational alignment through Ollivier-Ricci Curvature and Ricci Flow", "authors": "Nahid Torbati,Michael Gaebler,Simon M. Hofmann,Nico Scherf", "background": "RSA被广泛用于分析人类和神经网络之间的对齐程度；然而，基于此方法得出的结论可能会误导人，除非考虑潜在的表征几何结构。本文引入了一种使用Ollivier Ricci 曲率和Ricci 流的框架，用于分析表征的精细局部结构，该方法对表征空间的来源是无偏的，可以实现对人类行为判断和模型向量嵌入之间直接的几何比较。该方法被用于比较2D和3D面部刺激的人类相似性判断与基准2D本地网络（VGG-Face）及其与人类行为对齐的变体之间的差异。研究表明，几何感知的分析能够更敏感地描述RSA仅部分捕捉到的表征中的差异和几何差异。特别地，研究揭示了从2D到3D视角转换时对齐中的几何不一致性，表明结合几何信息可以揭示传统度量可能忽略的对齐差异，提供更深入的表征组织洞察。", "innovation": "引入了一种使用Ollivier Ricci 曲率和Ricci 流的框架，用于分析表征的精细局部结构，这一方法对表征空间的来源是无偏的，使得能够直接比较人类行为判断和模型的向量嵌入之间的几何特性。方法应用于2D和3D面部刺激的人类相似性判断与基准2D本地网络（VGG-Face）及其与人类行为对齐的变体之间的比较，展示了几何感知分析在捕捉表征差异中的优势，尤其是揭示了传统度量可能忽略的几何不一致性。", "conclusion": "几何感知分析提供了对表征中未充分捕捉的差异和几何差异的更敏感描述，而这些差异仅部分地由RSA捕捉到。该研究揭示了从2D到3D视角转换时对齐中可能存在的几何不一致性，表明将几何信息纳入分析可以揭示传统的度量可能忽略的对齐差异，提供了更深入的表征组织理解。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.14118", "html_url": "https://arxiv.org/abs/2501.14118", "title": "使用贝叶斯优化选择配电网中关键的分布式能源采用场景", "title_en": "Selecting Critical Scenarios of DER Adoption in Distribution Grids Using Bayesian Optimization", "authors": "Olivier Mulkin,Miguel Heleno,Mike Ludkovski", "background": "对未来因新增光伏采用者而导致电压和线路流量违规风险的预测对于电力公司的投资规划至关重要，但现有的方法依旧依赖于确定性或随机情境选择，这限制了预测的准确性和效率。", "innovation": "提出了一种基于多目标贝叶斯优化的高度高效搜索框架。将基础电网压力指标视为计算密集型的黑箱函数，并通过高斯过程代理进行近似，设计了一个基于场景在一系列基于线路和母线违规目标附近的帕累托关键概率的获取函数。该方法提供了统计保证，并相对于保守的全搜索提供了一个数量级的速度提升。", "conclusion": "实配电网中包含200-400个母线的案例研究显示了该方法的有效性和准确性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.04378", "html_url": "https://arxiv.org/abs/2406.04378", "title": "TIDMAD: 时间序列数据集及其在AI降噪发现暗物质中的应用", "title_en": "TIDMAD: Time Series Dataset for Discovering Dark Matter with AI Denoising", "authors": "J. T. Fry,Xinyi Hope Fu,Zhenghao Fu,Kaliroe M. W. Pappas,Lindley Winslow,Aobo Li", "background": "暗物质约占宇宙总质量的大约85%，但从未在地球上任何实验室直接观测到。暗物质的起源是当代物理学中最重要的问题之一，而直接检测到暗物质将是物理学理论的一大突破。ABRACADABRA实验旨在寻找暗物质。尽管尚未发现暗物质，但它已产生了多个广泛认可的暗物质搜索结果。该实验每秒生成超长时间序列数据1000万个样本，暗物质信号会在该时间序列中表现为正弦振荡模式。本文提供了一套全面的ABRACADABRA实验数据释放，包括训练集、验证集和科学集三个部分的超长时间序列数据集；一个精心设计的降噪评分，用于直接模型基准测试；以及一个完整的分析框架，生成符合发表于物理论文的社区标准的暗物质搜索结果。这些数据集使核心AI算法能够提取暗物质信号并产生真实物理结果，从而推进了基础科学研究。", "innovation": "该论文提出了一种名为TIDMAD（Time Series Dataset for Discovering Dark Matter with AI Denoising）的数据集，旨在通过AI降噪技术提取暗物质信号，该数据集包括超长时间序列数据、降噪评分及分析框架，是发现暗物质的重要工具和资源。此数据集不仅为科学家们提供了直接的暗物质信号数据，同时也为人工智能算法提供了验证平台。", "conclusion": "该数据集的发布使得核心AI算法能够从超长时序列数据集中发掘暗物质信号，从而推动了物理学研究的进步。通过提供标准化的暗物质搜索结果，该数据集促进了该领域的国际合作与共享，加速了对暗物质本质的理解。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.11529", "html_url": "https://arxiv.org/abs/2409.11529", "title": "网络流中基于低秩张量分解和深度展开的自适应异常检测", "title_en": "Adaptive Anomaly Detection in Network Flows with Low-Rank Tensor Decompositions and Deep Unrolling", "authors": "Lukas Schynol,Marius Pesavento", "background": "异常检测(AD)被越来越多地认为是确保未来通信系统弹性的关键组成部分。尽管深度学习在异常检测方面表现出最先进的性能，但在关键系统中的应用却因训练数据效率、领域自适应和可解释性方面的担忧而受阻。通过利用鲁棒张量分解方法和深度展开技术，解决这些挑战，提出了基于网络流量的异常检测方法，以充分利用不完整的测量数据。", "innovation": "本文提出了一种基于正则化模型拟合目标的新颖块相继凸逼近算法，其中正常流量被建模为低秩张量，异性能被建模为稀疏。引入了目标函数的扩展来减少计算成本，并采用深度展开技术来设计新的深度网络架构，将正则化参数视为可学习权重。通过借鉴贝叶斯方法，提出了一种能够在线适应每种流量和每次时间步长统计信息的模型架构，从而提高异常检测性能，同时保持参数较少且保留问题的置换对称性。为优化深度网络权重以提高检测性能，采用了基于接收器操作特征曲线下的面积的高效近似方法来进行同胚优化。", "conclusion": "对合成和真实数据进行的广泛实验表明，所提出的深度网络架构具有高训练数据效率、优于参考方法，并且能够无缝适应不同的网络拓扑结构。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.18092", "html_url": "https://arxiv.org/abs/2501.18092", "title": "学习可证明提高梯度下降的收敛性", "title_en": "Learning Provably Improves the Convergence of Gradient Descent", "authors": "Qingyu Song,Wei Lin,Hong Xu", "background": "L2O 训练基于深度神经网络的求解器，成功加速了凸问题，并改进了非凸问题的解决方案。然而，L2O 缺乏其自身训练收敛的严谨理论支持，当前分析通常依赖于不现实的假设，造成实际应用中可能存在的差距。", "innovation": "本文通过证明 L2O 模型在二次规划中学习梯度下降超参数时的训练收敛性，弥补了理论验证的缺口。提出了一种确定性初始化策略，以支持理论结果，通过缓解梯度爆炸问题促进长时间优化时的稳定训练。现有 L2O 方法在合成数据集上，我们的框架显示出超过 50% 的最优性改进和更优的鲁棒性。", "conclusion": "实验结果表明，我们的L2O框架在合成数据集上表现出了优于50%的最优性改进以及相对于现有先进L2O方法更优的鲁棒性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04242", "html_url": "https://arxiv.org/abs/2502.04242", "title": "一种多源迁移学习中优化迁移量的高维统计方法", "title_en": "A High-Dimensional Statistical Method for Optimizing Transfer Quantities in Multi-Source Transfer Learning", "authors": "Qingyue Zhang,Haohao Fu,Guanbo Huang,Yaoyuan Liang,Chang Chu,Tianren Peng,Yanru Wu,Qi Li,Yang Li,Shao-Lun Huang", "background": "多源迁移学习在实际监督学习场景中能够有效解决数据稀缺问题，通过利用多个来源任务的数据。现有工作通常利用所有可用数据来进行训练，这限制了其训练效率，并可能导致次优结果。", "innovation": "提出了一个理论框架来确定从每个源任务所需的最佳样本数量，以实施目标模型的联合训练；引入了基于K-L散度的泛化误差度量，并通过高维统计分析来最小化它以确定每种源任务的最优迁移量；开发了一个架构无关且数据高效的算法OTQMS，将理论结果应用于多源迁移学习的目标模型训练。", "conclusion": "实验研究表明，所提出的算法在准确性和数据效率方面显著优于现有的最先进的方法。这也证明了该算法在不同架构和两个实际基准数据集上的适用性。所有的代码和补充材料可以在以下链接获取：this https URL."}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.08428", "html_url": "https://arxiv.org/abs/2501.08428", "title": "具有物理约束的潜在神经算子框架用于时间依赖的参数化偏微分方程的实时预测", "title_en": "Physics-Informed Latent Neural Operator for Real-time Predictions of time-dependent parametric PDEs", "authors": "Sharmila Karumuri,Lori Graham-Brady,Somdatta Goswami", "background": "DeepONet作为一种代理模型，在处理受偏微分方程（PDEs）约束的系统方面显示出了巨大的潜力，能够实现无限维函数空间之间的精确映射。然而，当应用于具有大量空间和时间节点的输入输出映射的系统时，这些模型通常需要高度过参数化的网络，从而导致较长的训练时间。Latent DeepONet通过引入两步方法，首先学习一个降低的潜在空间，然后在该潜在空间内进行算子学习，解决了部分问题，但这种方法是数据驱动的，缺乏整合物理定律的机制，从而限制了其在数据稀缺环境中的鲁棒性和泛化能力。", "innovation": "本文提出了PI-Latent-NO框架，这是一种具有物理约束的潜在神经算子框架，它直接将控制方程嵌入学习过程中。该架构包括两个端到端训练的DeepONet：一个潜在DeepONet学习解决方案的低维表示，另一个重建DeepONet将此潜在表示映射回物理空间。通过自动微分嵌入PDE约束，该方法消除了对标签训练数据的需求，并确保物理一致的预测。该框架在内存和计算效率方面表现出色，随问题规模扩展几乎呈常数级，相比传统物理约束算子模型具有显著的加速效果。", "conclusion": "我们通过在各种参数化PDEs上进行验证，展示了该方法的准确性、可扩展性以及在复杂物理系统中实时预测的适用性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01068", "html_url": "https://arxiv.org/abs/2502.01068", "title": "FastKV: 使用Token-选择性传播进行快速长上下文处理的KV缓存压缩", "title_en": "FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation", "authors": "Dongwon Jo,Jiwon Song,Yulhwa Kim,Jae-Joon Kim", "background": "大语言模型（LLMs）擅长处理长上下文序列，但在预填充和解码阶段需要大量的前缀计算和键值（KV）缓存，这会严重拖累计算效率和内存使用。已有工作通过预填充加速和压缩KV缓存来减少成本，但这种耦合方法会将预填充的计算减少与解码阶段的KV预算联系在一起，忽略了各层上下文的重要性差异，导致准确度下降。", "innovation": "FastKV框架通过利用后期层中Token重要性的稳定特性，结合Token-选择性传播（TSP）策略，仅向前传播最具信息量的Token，之后独立选择对KV缓存最关键的条目，从而在不依赖预填充计算减少的基础上解耦KV预算，实现灵活性的效率和准确度优化。实验结果显示，相较于全上下文基线，FastKV在预填充和解码阶段分别实现了1.82倍和2.87倍的加速，同时保持了仅加速解码阶段的基线准确度。", "conclusion": "FastKV框架通过引入Token-选择性传播，在预填充和解码阶段都实现了显著的加速，同时保持了高准确度，能够灵活地优化效率和准确度，提升了大语言模型的长上下文处理能力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.07862", "html_url": "https://arxiv.org/abs/2502.07862", "title": "ADMN: 分层自适应多模态网络，用于动态输入噪声和计算资源", "title_en": "ADMN: A Layer-Wise Adaptive Multimodal Network for Dynamic Input Noise and Compute Resources", "authors": "Jason Wu,Yuyang Yuan,Kang Yang,Lance Kaplan,Mani Srivastava", "background": "多模式深度学习系统在动态场景中部署，由于多种传感模态提供的鲁棒性。然而，这些系统难以应对计算资源可用性的变化（由于多租户、设备异构性等）和输入质量的变化（因传感器信号干扰、环境噪声等）。静态配置的多模式系统无法适应随时间变化的计算资源需求，而现有动态网络则难以严格把控计算预算。此外，这些系统往往没有考虑到模态质量变化的影响。因此，质量受损严重的模态可能无必要地消耗资源，而这些资源原本可以分配给其他模态。", "innovation": "提出了一种分层自适应深度多模态网络（ADMN），该网络能够同时应对上述挑战。ADMN能够根据严格的计算资源限制调整所有模态中活跃层的总数，并根据每种模态的质量不断重新分配输入模态中的层。我们的评估结果显示，ADMN能够在保持与最先进的网络相同准确度的同时，将浮点运算减少多达75%。", "conclusion": "ADMN能够根据模态质量和计算资源的需求动态调整模型，优化资源分配，提升系统的灵活性和效率。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.05295", "html_url": "https://arxiv.org/abs/2502.05295", "title": "GST-UNet: 一种处理时间变化混杂因素的空间和时间因果推断神经框架", "title_en": "GST-UNet: A Neural Framework for Spatiotemporal Causal Inference with Time-Varying Confounding", "authors": "Miruna Oprescu,David K. Park,Xihaier Luo,Shinjae Yoo,Nathan Kallus", "background": "在公共卫生、环境科学和政策评估等领域，基于时空观测数据估计因果效应至关重要，因为随机试验经常不可行。现有方法要么依赖于强烈的结构假设，要么无法应对诸如干扰、空间混杂、时间延续效应以及时间变化混杂等关键挑战，其中协变量可能受到过去的治疗影响并反过来影响未来的治疗。", "innovation": "我们引入了GST-UNet（G-计算时空Ｕ-Net）这一理论基础的神经框架，该框架结合了基于时空Ｕ-Net的基本编码器和基于回归的迭代G-计算，以在复杂的干预序列下估计特定位置的潜在结果。GST-UNet明确调整了时间变化的混杂因素，捕捉了非线性的空间和时间依赖关系，使得在数据稀缺的情况下从单一观察轨迹中进行有效的因果推断成为可能。", "conclusion": "我们的实验验证结果表明GST-UNet在合成实验和2018年加州坎普野火期间野火烟雾暴露与呼吸系统住院之间的因果推断中表现出有效性。这些结果将GST-UNet确立为一个适宜的原则和现成的空间和时间因果推断框架，促进了相关政策相关和科学领域的可靠估计。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05316", "html_url": "https://arxiv.org/abs/2506.05316", "title": "通过难度导向的在线数据选择和滚存回放提高大语言模型强化学习微调的数据效率", "title_en": "Improving Data Efficiency for LLM Reinforcement Fine-tuning Through Difficulty-targeted Online Data Selection and Rollout Replay", "authors": "Yifan Sun,Jingyan Shen,Yibin Wang,Tianyu Chen,Zhendong Wang,Mingyuan Zhou,Huan Zhang", "background": "强化学习（RL）已成为有效微调大型语言模型（LLMs）的方法，尤其用于增强其推理能力。然而，RL 微调仍然非常耗费资源，现有工作大多忽视了数据效率问题。", "innovation": "提出了两种技术来提高LLM RL 微调中的数据效率：难度导向的在线数据选择和滚存回放。引入了自适应难度的概念来指导在线数据选择，优先选择具有中等难度的问题，更容易提供有价值的学习信号。为了高效估计自适应难度，开发了一种基于注意力的框架，只需滚动一小部分问题的回放，其余问题的自适应难度基于它们与这个集合的相似度进行估计。为了进一步降低滚动成本，引入了一种滚动回放机制，类似于传统 RL 中的经验回放，该机制通过重用近来的滚动来降低每步计算成本并保持稳定的更新。", "conclusion": "对比原始的GRPO算法，我们的方法在6组LLM-数据集组合下的RL微调时间减少了23%到62%，同时达到了相同的性能水平。我们的代码可在以下链接找到：this https URL"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.24424", "html_url": "https://arxiv.org/abs/2505.24424", "title": "使用高效微调提升CLIP的组合意识", "title_en": "Advancing Compositional Awareness in CLIP with Efficient Fine-Tuning", "authors": "Amit Peleg,Naman Deep Singh,Matthias Hein", "background": "视觉-语言模型如CLIP在分类和检索方面展现了卓越的零样本能力。然而，这些模型在组合推理方面遇到了困难，即理解概念间关系的能力。最近的基准测试SugarCrepe++揭示了之前增强组合性的研究主要提升了词汇敏感性，却忽略了语义理解。此外，虽然理论上提升组合性应该改进检索性能，但其实现的下游检索性能却常常下降。CLIP及其改进模型（如CLIPS）的表现在此场景下尤其明显地显现这一问题。", "innovation": "本文提出了CLIC（组合性学习在CLIP中），这是一种基于新型训练技术的微调方法，该技术结合了多个图像及其关联的字幕。CLIC不仅在不同架构和预训练的CLIP模型中提高了组合性，还在词汇和语义理解方面都取得了改进，同时还维持了检索性能的一致提升。对于最近的CLIPS，CLIC的微调方法不仅进行了改进，还在SugarCrepe++基准测试中成为了最佳组合性CLIP模型。尽管CLIC的微调相当短暂，它仍带来了检索性能和组合性方面的显著提升。", "conclusion": "本文中的所有模型和代码均可在提供的链接中下载。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.02703", "html_url": "https://arxiv.org/abs/2506.02703", "title": "数据泄露和误导性表现：对信用欺诈检测方法的批判性检视", "title_en": "Data Leakage and Deceptive Performance: A Critical Examination of Credit Card Fraud Detection Methodologies", "authors": "Mohammed Hilal Al-Kharusi,Khizar Hayat,Khalil Bader Al Ruqeishi,Haroon Rashid Lone", "background": "在当今数字时代，古兰经读音（ت qcws）学科，即塔吉偶，面临着重大的教育挑战。尽管现代技术提供了前所未有的学习机会，但现有的自动评估系统在普及度和教育有效性方面仍面临困难。这篇文章通过历时二十年的文献综述来探讨这一关键差距，重点关注现有采用自动语音识别（ASR）系统的方法，这些系统侧重于单词识别，而非定性的声音评估。这些系统存在依赖偏见数据集、人口统计差异以及无法提供有意义的改进反馈等问题。", "innovation": "文章提议了一种基于知识的计算框架，通过利用古兰经文本的不变性质和塔吉偶明确的发音规则，建议构建一种基于语法规则的声音模型，强调经典发音原则和发音点（玛卡尔贾），而不是依赖从有缺陷或偏见的数据中提取的统计模式。这种观点挑战了以数据为中心的方法，促进了语言学专业知识与高级音频处理技术的结合，为开发可靠、公正且教育有效的工具铺平了道路。", "conclusion": "未来的自动古兰经读音评估系统应该结合语言专家知识与先进的音频处理技术，以开发出可靠、公正且教育有效的工具，帮助全球学习者。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01374", "html_url": "https://arxiv.org/abs/2506.01374", "title": "推理编译器：由大语言模型指导的高效模型服务优化", "title_en": "REASONING COMPILER: LLM-Guided Optimizations for Efficient Model Serving", "authors": "Sujun Tang,Christopher Priebe,Rohan Mahapatra,Lianhui Qin,Hadi Esmaeilzadeh", "background": "随着模型部署解锁了前所未有的能力，大规模模型的服务成本仍然是广泛访问和快速创新的主要障碍。传统编译器优化已经带来了显著的性能提升，但它们在处理神经网络工作负载方面仍然存在挑战，因为潜在变换的数量级极其庞大且高度互依。尽管现有的随机搜索技术可以有效，但它们通常样本效率不高，未能利用编译决策的结构背景。研究团队探讨了使用大型语言模型进行优化是否能在无需重新训练的情况下，利用编译器优化的上下文意识决策空间显著提高样本效率的问题。", "innovation": "研究引入了一种新颖的编译框架（称为推理编译器），将优化过程表述为由大型语言模型和结构化蒙特卡洛树搜索（MCTS）引导的顺序、上下文感知决策流程。该框架利用大型语言模型作为建议机制，提出反映当前程序状态和累积性能反馈的硬件相关变换。蒙特卡洛树搜索结合了大型语言模型生成的建议，平衡了探索和利用，使结构化、上下文感知地遍历庞大的编译优化空间成为可能。通过用明显更少的样本实现显著的加速，该方法证明了由大型语言模型指导的推理能够重塑编译优化的景观。", "conclusion": "与领先的神经编译器相比，该方法通过显着减少样本数量实现大量加速，展示了由大型语言模型引导的推理在编译优化领域中的巨大潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01855", "html_url": "https://arxiv.org/abs/2506.01855", "title": "通过强数据处理不等式探究数据记忆中的权衡", "title_en": "Trade-offs in Data Memorization via Strong Data Processing Inequalities", "authors": "Vitaly Feldman,Guy Kornowski,Xin Lyu", "background": "近期研究显示，训练大规模语言模型时会记忆训练数据中的相当一部分内容。这种记忆在使用敏感用户数据训练时可能导致隐私泄露，因此研究数据记忆在学习中的角色非常重要。已有研究表明存在数据记忆的下界，但该研究中提及的下界存在一些局限性，本文旨在解决这些问题，特别是在数据可用数量和所需记忆的信息量之间找到权衡关系", "innovation": "本文开发了一个证明学习算法数据记忆的下界的一般方法，该方法依赖于强数据处理不等式与数据记忆之间的新联系。本文还证明了一些简单的二分类问题在数据可用性和算法需要记忆多少关于训练数据的信息之间存在权衡关系。进一步，当存在有限数量的$d$维示例时，需要存储$\tilde{\theta}(d)$比特的信息，随着示例数量的增长，存储的必要信息量以问题特定的速率衰减。此外，本文还扩展了所证明的下界到更通用的聚类混合模型，并以其构建的数据定义和结果为基础，解决了Brown等（2021年）工作中下界的一些局限性", "conclusion": "本文通过引入强数据处理不等式与数据记忆之间的关系，解决了数据记忆下界证明中存在的局限性问题，并在数据可用性与所需记忆的信息量之间发现了权衡关系。此外，提出的结果对理解大规模语言模型的训练学习过程有重要意义"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05426", "html_url": "https://arxiv.org/abs/2506.05426", "title": "Mixture-of-Experts Meets In-Context Reinforcement Learning", "title_en": "Mixture-of-Experts Meets In-Context Reinforcement Learning", "authors": "Wenhao Wu,Fuhong Liu,Haoru Li,Zican Hu,Daoyi Dong,Chunlin Chen,Zhi Wang", "background": "在上下文强化学习（ICRL）中，通过提示条件适应强化学习（RL）代理的下游任务已经显示出前景，但仍面临两个主要挑战：状态-动作-奖励数据的内在多模态性和决策任务的多样化、异构性。现有方法在这方面进展有限，未能完全利用上下文学习的优势。因此，需要一种能够应对这些挑战的创新框架，以提升在强化学习中的上下文学习能力。", "innovation": "本文提出了一种名为T2MIR的创新框架，将混合专家（MoE）架构引入基于变压器的决策模型中。T2MIR采用了一种分层路由策略，包括一种 token-wise MoE 来捕捉多模态输入中的不同语义，另一种 task-wise MoE 通过最小化梯度冲突将多样化任务导向专用专家，以处理广泛的任务分布。此外，引入了对比学习方法来最大化任务及其路由器表示之间的互信息，从而更精确地捕获任务相关信息。实验结果表明，T2MIR 显著增强了上下文学习能力，并在多种基线方法中表现优异。", "conclusion": "T2MIR 提供了一种简单且可扩展的架构增强方案，将 MoE 带入 ICRL 领域，从而进一步推动 ICRL 在语言和视觉社区的发展。目前的代码可以在该链接中找到。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01356", "html_url": "https://arxiv.org/abs/2506.01356", "title": "通过Zubov取样和迭代域扩展的双阶段稳定神经控制器学习", "title_en": "Two-Stage Learning of Stabilizing Neural Controllers via Zubov Sampling and Iterative Domain Expansion", "authors": "Haoyu Li,Xiangru Zhong,Bin Hu,Huan Zhang", "background": "基于学习的神经网络（NN）控制策略在实际应用中展现出了出色的性能。然而，要获得这些学习控制神经网络的稳定性保证和吸引域估计是非常具有挑战性的，因为缺乏稳定且可扩展的训练和验证算法。尽管已有相关工作在该领域取得了巨大成功，但他们的框架依然存在许多保守性问题。", "innovation": "本文提出了一个新颖的两阶段训练框架，用于综合连续系统控制器和李亚普诺夫函数。通过利用Zubov启发的吸引域表征直接估计稳定性边界，提出了一种新的训练数据采样策略和域更新机制，大幅降低了训练的保守性。不同于其他连续系统的方法依赖SMT求解器进行形式验证，本文扩展了最先进的神经网络验证器α, β-CROWN，使其能够自动传播动态系统雅可比矩阵的边界，并提出了一种新的验证方案，避免了昂贵的二分法。", "conclusion": "通过在多个非线性系统上进行数值实验，展示了该方法的有效性。训练获得的吸引域体积比基线多5-150,000倍，连续系统验证比传统SMT求解器dReal快40-10,000倍。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01360", "html_url": "https://arxiv.org/abs/2506.01360", "title": "RDB2G-Bench: 用于关系数据库自动图建模的综合基准", "title_en": "RDB2G-Bench: A Comprehensive Benchmark for Automatic Graph Modeling of Relational Databases", "authors": "Dongwon Choi,Sunwoo Kim,Juyeon Kim,Kyungho Kim,Geon Lee,Shinhwan Kang,Myunghwan Kim,Kijung Shin", "background": "最近的研究证明，基于图的学习方法在关系数据库（RDBs）上的预测任务中非常有效。然而，将RDBs转化为图的过程（即RDB-to-graph建模）依然具有挑战性。不同的建模方法导致了预测性能的巨大差异，最佳模型与常见启发式规则相比，性能高出10%以上。为了推进智能RDB-to-graph建模的研究，作者提出了RDB2G-Bench，这是首个用于评估此类方法的基准框架。", "innovation": "作者引入了RDB2G-Bench，这是一个全面的基准框架，用于评估自动将RDBs转换为图的方法。它构建了覆盖5个真实世界RDB和12个预测任务的大规模数据集，产生了近5万对图模型-性能，以实现高效和可重复的评估。与实时评估相比，使用预计算的数据集，该基准框架可以在相同任务上快380倍的速度对10种自动RDB-to-graph建模方法进行基准测试。分析数据集和基准结果揭示了影响图模型有效性的关键结构模式，为实际有效的图建模提供了可行的见解。", "conclusion": "作者的数据集和代码可以在以下网址获得，通过这些数据和代码，研究人员可以更深入地了解不同RDB-to-graph建模方法的表现及其背后的原因。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.04536", "html_url": "https://arxiv.org/abs/2506.04536", "title": "NOBLE -- 基于生物启发潜在嵌入的神经算子以捕捉生物神经元模型中的实验可变性", "title_en": "NOBLE -- Neural Operator with Biologically-informed Latent Embeddings to Capture Experimental Variability in Biological Neuron Models", "authors": "Luca Ghafourpour,Valentin Duruisseaux,Bahareh Tolooshams,Philip H. Wong,Costas A. Anastassiou,Anima Anandkumar", "background": "理解神经元在大脑中的功能离不开对其细胞性质的详细表征。当前方法受限于可用实验神经元数据的有限性及内在变异性，而且确定性的生物现实模型无法解释实验中观察到的自然变异性。尽管深度学习日益相关，但现有技术无法全面捕捉神经元的生物物理学复杂性、非线性电压动态和变异性。这些不足促使我们寻找新的方法来克服纯理论模型和深度学习模型的局限性，以更好地解释和预测神经元动态及可变性。", "innovation": "我们提出了一种名为NOBLE的神经算子框架，它能从具有可解释神经元特征的连续频率调制嵌入中学习到诱导电流注射所产生的胞体电压响应的映射关系。NOBLE使用生物现实模型生成的合成数据进行训练，能够预测包含内在实验变性的神经动力学分布。与传统生物现实模型不同，通过嵌入空间内的插值能够生成动作电位动态与实验观察相符的模型。NOBLE不仅可以高效地生成与实验数据高度相似的合成神经元，并且表现出持续性变异性，与数值求解相比，其速度提升高达4200倍。NOBLE是首个能用真实实验数据验证其泛化的深度学习框架，能够以独特且涌现的方式捕捉神经元的基本性质，为细胞组成和计算、神经形态架构、大面积脑电路乃至通用神经AI应用提供了新的视角和理解工具。", "conclusion": "NOBLE框架能够克服传统模型和纯序列深度学习方法的局限性，用真实实验数据验证其泛化能力，高效生成与实验数据高度相似的神经元模型，为神经网络中的可变性建模和理解神经元的基本性质提供了革新方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.20362", "html_url": "https://arxiv.org/abs/2507.20362", "title": "MH-GIN: 基于多尺度异构图的AIS数据插值网络（扩展版本）", "title_en": "MH-GIN: Multi-scale Heterogeneous Graph-based Imputation Network for AIS Data (Extended Version)", "authors": "Hengyu Liu,Tianyi Li,Yuqiang He,Kristian Torp,Yushuai Li,Christian S. Jensen", "background": "自动识别系统(Automatic Identification System, AIS) 的位置跟踪数据在海上安全和监控应用中起着关键作用。然而，这些数据存在缺失值，影响了下游应用。由于不同异构属性更新速度不同，导致属性间存在多尺度依赖关系。现有的假设属性更新速率相似的插补方法无法捕捉和利用这种依赖关系，从而限制了插补准确性。\n", "innovation": "我们提出了MH-GIN (Multi-scale Heterogeneous Graph-based Imputation Network)，一种旨在通过捕捉多尺度依赖关系来提高插补准确性的插补网络。MH-GIN 首先为每个属性提取多尺度时序特征，同时保持其固有的异构特性，然后构建多尺度异构图以明确建模异构属性间的依赖关系，从而通过图传播实现更准确的插补。实验结果表明，与最先进的方法相比，MH-GIN 在两个真实数据集上的插补误差平均减少了57%，同时保持了计算效率。\n", "conclusion": "MH-GIN 能够显著提高AIS数据中缺失值的插补准确性，尽管在计算效率方面保持了高效性。相关源代码和实现细节已公开。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06041", "html_url": "https://arxiv.org/abs/2508.06041", "title": "DP-LLM: 基于动态逐层精度分配的运行时模型调整", "title_en": "DP-LLM: Runtime Model Adaptation with Dynamic Layer-wise Precision Assignment", "authors": "Sangwoo Kwon,Seong Hoon Seo,Jae W. Lee,Yeonhong Park", "background": "对于本地设备上的大型语言模型（LLMs），我们如何在确保时延和准确性的条件下有效地处理具有不同运行时约束的查询？多尺度量化通过在不同位宽度量化的多种模型变体上叠加来解决这一挑战，使得LLMs可以在运行时实现内存高效的模型适应。然而，如何根据目标精度或时延适当配置模型仍然开放性问题。虽然混合精度提供了一种可能的解决方案，我们进一步利用了一个关键观察，即每一层的敏感性会根据解码步骤动态变化这个洞察。", "innovation": "我们提出了一种新颖的机制称为DP-LLM，该机制可以根据输入值动态为每一层分配适当的精度。实验结果表明，DP-LLM 在性能与时延之间实现了更优越的权衡，超越了先前的方法。", "conclusion": "DP-LLM 通过动态分配每一层的精度来提高本地设备上大型语言模型的运行时性能和效率，解决了运行时模型适应中的开放性问题，为混合精度解决方案提供了新的思路。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.00103", "html_url": "https://arxiv.org/abs/2509.00103", "title": "预训练知识使大规模语言模型超越传统的化学反应优化器", "title_en": "Pre-trained knowledge elevates large language models beyond traditional chemical reaction optimizers", "authors": "Robert MacKnight,Jose Emilio Regio,Jeffrey G. Ethier,Luke A. Baldwin,Gabe Gomes", "background": "现代实验化学中的优化方法依赖于通过指导性搜索在黑盒参数空间中的算法搜索。本文通过六个完全枚举的分类反应数据集（768-5,684个实验）来评估由大型语言模型（LLM）指导的优化（LLM-GO）方法，对比了它与贝叶斯优化（BO）和随机抽样的性能。研究发现，即使对于单目标问题，前沿的LLM也能够匹配或超越BO的性能，特别是在参数复杂度增加且高表现条件稀缺的情况下（<5%的空间）。", "innovation": "研究表明，预训练知识使LLM能够在化学参数空间中实现更有效的导航，而不是简单地替换结构化的探索策略。这通过引入一种不依赖于拓扑结构的信息理论框架来量化优化活动中的采样多样性来解释，该框架揭示了在所有数据集中，LLM表现出更高的探索Shannon熵，从而在资源稀缺的参数空间中显示出最佳性能。为此，研究团队发布了一个名为Iron Mind的平台，允许透明的基准测试和社区验证。", "conclusion": "研究发现，LLM-GO特别在需要领域理解而非数学优化的传统方法无法胜任的复杂分类空间中表现出色。研究提出的框架和平台将为化学实验优化领域带来新的洞察和方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.19563", "html_url": "https://arxiv.org/abs/2508.19563", "title": "稳健性很重要：大语言模型在数据拟合中的局限性", "title_en": "Robustness is Important: Limitations of LLMs for Data Fitting", "authors": "Hejia Liu,Mochen Yang,Gediminas Adomavicius", "background": "大型语言模型（LLMs）正被应用于各种场景，不仅限于语言相关任务。研究发现，部分LLMs可用于直接拟合数据和生成预测，并且在预测性能上能与许多基于表格的监督学习技术竞争。然而，研究指出，使用LLMs进行数据拟合存在一个关键的脆弱性。通过对数据表示进行与任务无关的更改，可以导致模型预测结果发生巨大变化，例如仅仅更改变量名称，也可以使预测误差放大82%。这种敏感性不仅在基于上下文的学习和监督微调中存在，还在闭式权重和开放式权重的一般大语言模型中显现。通过对开放式权重模型的注意力评分进行研究，发现注意力模式是非均匀的，特定位置的训练示例和变量名称/值比其他位置受到更多的关注，这解释了在任务无关变异存在下的敏感性。此外，即使是在专门为数据拟合训练的最先进的表格基础模型（TabPFN）也无法幸免于这种任务无关的变异影响。", "innovation": "研究揭示了大型语言模型在数据拟合中的脆弱性——通过对数据表示进行与任务无关的更改，可以导致模型预测结果发生巨大变化。研究还发现了注意力模式的非均匀性，即在生成输出标记时，某些特定位置的训练示例和变量名称/值收到的关注度更高。这进一步揭示了任务无关变异影响模型预测的机理。", "conclusion": "尽管大型语言模型拥有令人印象深刻的预测能力，但它们目前仍缺乏基本的鲁棒性，不足以成为用于数据拟合的可靠工具。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02937", "html_url": "https://arxiv.org/abs/2507.02937", "title": "FoGE: Fock Space inspired encoding for graph prompting", "title_en": "FoGE: Fock Space inspired encoding for graph prompting", "authors": "Sotirios Panagiotis Chytas,Rudrasis Chakraborty,Vikas Singh", "background": "最近的研究结果表明，现代大型语言模型（LLM）能够理解并回答关于结构化数据（如图）的问题。目前，为了解决基于图的提示问题，已有多种方法，包括图序列化和图变换器等。在这种背景下，本文探索了如何利用物理中的无参数玻色子空间表示对图进行编码的方法，以构建有效的图提示。", "innovation": "本文提出了一种基于物理中的玻色子空间表示（Fock空间）的无参数图编码方法（FoGE），这种方法能够为不同类型的图提供丰富的图表示。通过这种方式，可以有效回答从简单的图到蛋白质再到超图等各种图相关的查询，同时对模型架构进行最小的修改，甚至可能不需要任何调整。", "conclusion": "本文的研究简化了现有的解决方案，并能够很好地推广到多种不同的基于图的结构。与现有的图序列化和图变换器相比，FoGE方法具有更高的灵活性和通用性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.16989", "html_url": "https://arxiv.org/abs/2509.16989", "title": "PTQTP：大型语言模型后训练量化到三态平面", "title_en": "PTQTP: Post-Training Quantization to Trit-Planes for Large Language Models", "authors": "He Xiao,Runming Yang,Qingyao Yang,Wendong Xu,Zhen Li,Yupeng Su,Zhengwu Liu,Hongxia Yang,Ngai Wong", "background": "后训练量化（PTQ）大型语言模型（LLM）到极低位宽（如极低位比特）仍然具有挑战性，主要由于计算效率和模型表达性的根本权衡。现有的一些超低比特PTQ方法依赖于二元近似或复杂的补偿机制，但这些方法要么代表能力有限，要么计算开销高，抵消了其计算效率的提高。", "innovation": "提出了PTQTP（Post-Training Quantization to Trit-Planes），这是第一个使用2x1.58比特表示分解权重矩阵为结构化三态（-1, 0, 1）平面的PTQ模型。PTQTP实现了无乘法推理，同时保持了卓越的表达性。其创新点包括：（1）提供了一种具有全局一致性保证的理论基础渐进逼近算法；（2）能够在不同现代LLM上进行模型无关的部署，无需架构修改；（3）提供了统一的三态操作，消除了对混合精度或补偿方案的需求。", "conclusion": "跨LLaMA3.x和Qwen3模型系列（0.6B-70B参数）的全面实验表明，PTQTP在数学推理保留率方面远超现有超低比特PTQ方法，相比竞争方法高达82.4%。PTQTP几乎或超越了1.58比特量化感知训练的效果，在量化方面仅需单小时相比基于训练的方法需要10-14个GPU天。实验结果证明PTQTP是资源受限环境下高效LLM部署的可实现方案。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.04415", "html_url": "https://arxiv.org/abs/2509.04415", "title": "在混合观察数据中适应性异质因果结构学习的可解释聚类", "title_en": "Interpretable Clustering with Adaptive Heterogeneous Causal Structure Learning in Mixed Observational Data", "authors": "Wenrui Li,Qinghao Zhang,Xiaowo Wang", "background": "理解因果异质性对于生物学和医学等领域的科学发现至关重要。现有的方法缺乏因果意识，无法充分建模异质性、混杂因素和观察约束，导致解释性不足，难以区分真正的因果异质性与虚假关联。", "innovation": "提出了一种名为HCL（可解释的因果机制感知聚类与自适应异质因果结构学习）的无监督框架。HCL联合推断潜在聚类及其相关因果结构，适用于混合类型观察数据，并且在不需要时间顺序、环境标签、干预或先验知识的情况下进行。HCL通过引入等效表示放松同质性和充分性假设，该表示编码结构性异质性和混杂因素。进一步开发双向迭代策略交替精炼因果聚类和结构学习，并使用自我监督正则化平衡跨聚类的一般性和特异性。", "conclusion": "这些组件使HCL能够向可解释的、异质的因果模式收敛。理论上，我们证明了在适度条件下异质因果结构的可识别性。通过实验，HCL在聚类和结构学习任务上均表现出更优越的性能，并且在真实世界的单细胞扰动数据中恢复了生物上意义的机制，证明了其用于发现可解释的机制层面因果异质性的效用。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.12630", "html_url": "https://arxiv.org/abs/2509.12630", "title": "频率域中的高能集中度在联邦学习中的应用", "title_en": "High-Energy Concentration for Federated Learning in Frequency Domain", "authors": "Haozhi Shi,Weiying Xie,Hangyu Ye,Daixun Li,Jitao Ma,Yunsong Li,Leyuan Fang", "background": "联邦学习（FL）提供了一种在无需数据共享的情况下进行协作优化的有效方式。通过将合成数据发送至服务器，利用数据集蒸馏的概念，这种方法可以在保护实际数据隐私的同时缓解数据异质性问题。然而，这种方法仍然面临整个空间域设计中的冗余信息和噪声问题，这不可避免地增加了通信负担。", "innovation": "本文提出了一个新颖的频率域感知的联邦学习方法（FedFD），该方法通过发现离散余弦变换主要分布在特定区域（称为高能集中度）的现象得到启发。FedFD的核心思想是低能组件（高频成分）通常包含冗余信息和噪声，因此过滤这些信息有助于降低通信成本并优化性能。FedFD通过使用二进制掩码来数学上保留低频成分，并通过频率域分布对齐来促进最优解。特别地，FedFD使用真实的数据驱动的合成分类来增强低频组件的质量。", "conclusion": "在五个图像和语音数据集上，FedFD达到了优于现有最佳方法的表现，同时降低了通信成本。例如，在CIFAR-10数据集上，当Dirichlet系数α=0.01时，FedFD将通信成本减少了37.78%，同时实现了10.88%的性能提升。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02089", "html_url": "https://arxiv.org/abs/2507.02089", "title": "线性约束MDP的生成模型样本复杂性界", "title_en": "Sample Complexity Bounds for Linear Constrained MDPs with a Generative Model", "authors": "Xingtu Liu,Lin F. Yang,Sharan Vaswani", "background": "本文研究了具有无限时间折扣的线性约束马尔可夫决策过程（CMDP），这些过程的目标是在满足预期累积约束的前提下最大化预期累积奖励。使用生成模型，提出了一个可以通过任何黑盒无约束MDP求解器来利用的对偶框架来解决CMDP，特别地，对于具有特征维度d的线性CMDP，利用镜像下降价值迭代（MDVI）作为MDP求解器来实例化该框架。为了解决CMDP问题，提供了解法样本复杂性的理论界，包括稀松可行性情况（允许轻微约束违反）和严格可行性情况（输出策略必须完全满足约束）。对于严格可行性情况，引入了一个关于有效可行区域大小的Slater常数。对于不同的可行性设置，给出了上界和下界，突显了目标、约束和特征维度依赖的近最优性。并通过表格命令CMDP实验验证了所得结果的有效性。", "innovation": "- 提出了一个可以利用任何黑盒无约束MDP求解器的对偶框架来解决具有线性约束的MDP；\n- 通过使用镜像下降价值迭代（MDVI）方法来具体实施该框架；\n- 提供了不同可行性设置下的样本复杂性的理论界，包括稀松可行性和严格可行性情况；\n- 揭示了上界对应的近最优依赖关系，并通过部分下界对其进行了验证；\n- 在表格命令CMDP的背景下验证了所得结果的有效性，展示了其实际应用性；", "conclusion": "本文在不同可行性设置下，通过严格的数学证明和复杂性分析，为具有线性约束的MDP算法提供了最优样本复杂性界。研究结果验证了所提出的对偶框架的有效性和实用性，在实际应用中具有指导意义。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.23712", "html_url": "https://arxiv.org/abs/2509.23712", "title": "FraudTransformer：时间感知的GPT交易欺诈检测", "title_en": "FraudTransformer: Time-Aware GPT for Transaction Fraud Detection", "authors": "Gholamali Aminian,Andrew Elliott,Tiger Li,Timothy Cheuk Hin Wong,Victor Claude Dehon,Lukasz Szpruch,Carsten Maple,Christopher Read,Martin Brown,Gesine Reinert,Mo Mamouei", "background": "在银行实际业务流中检测支付欺诈需要能够同时利用事件顺序和事件之间不规则时间间隔的模型。现有文献中，使用传统经典模型如逻辑回归、XGBoost和LightGBM在大数据集上的实验表明，这些模型在欺诈检测方面的性能受到限制。此外，虽然变压器模型在序列数据处理上表现出色，但它们在时间感知和相对顺序保留上的不足影响了其在欺诈检测任务中的效果。", "innovation": "引入了FraudTransformer，这是一种序列模型，它通过两个方面增强了一个基础的GPT架构：（i）一个专门的时间编码器，用于嵌入绝对时间戳或事件间值，（ii）一个学习到的位置编码器，用于保留相对顺序。该模型展示了在工业级大规模数据集上的优越表现，超越了使用逻辑回归、XGBoost和LightGBM等四个强大经典基线下模型及缺失了时间或位置组件的变压器版本。", "conclusion": "FraudTransformer在保留相对顺序和时间感知方面表现出色，从而在真实世界支付欺诈检测中表现优异。在保留的测试集上，它实现了最高的AUROC和PRAUC。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00799", "html_url": "https://arxiv.org/abs/2506.00799", "title": "Uni-LoRA: One Vector is All You Need", "title_en": "Uni-LoRA: One Vector is All You Need", "authors": "Kaiyang Li,Shaobo Han,Qing Su,Wei Li,Zhipeng Cai,Shihao Ji", "background": "低秩适应（LoRA）已成为大型语言模型（LLMs）参数高效微调（PEFT）的主流方法，它通过将权重更新限制在低秩矩阵中来实现参数约束。最近的工作如Tied-LoRA、VeRA和VB-LoRA通过引入额外的约束进一步提高了效率，减少了可训练参数空间。然而，这些方法在参数空间减少策略上存在差异，并依赖于层间或结构特定的投影，这限制了跨层参数共享，影响了参数效率。", "innovation": "提出了一个统一框架Uni-LoRA，其中LoRA参数空间可以作为一个高维向量空间$R^D$进行投影重建，投影是从子空间$R^d$进行的，且$d \rlap{\raise 3pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 3.5pt{\rlap{\rule{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 3.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 7.0pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 10.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\rule{8pt}{1px}}}}}}}}}}} < D$。该框架的关键在于投影矩阵$P \rlap{\raise 3pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 3.5pt{\rlap{\rule{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 3.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 7.0pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 10.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\rule{8pt}{1px}}}}}}}}}}}}} \rlap{\raise 3pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 3.5pt{\rlap{\rule{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 3.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 7.0pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 10.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\rule{8pt}{1px}}}}}}}}}}}}} \rlap{\raise 3pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 3.5pt{\rlap{\rule{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 3.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 7.0pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 10.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\rule{8pt}{1px}}}}}}}}}}}}} \rlap{\raise 3pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 3.5pt{\rlap{\rule{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 3.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 7.0pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 10.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\rule{8pt}{1px}}}}}}}}}}}}} \rlap{\raise 3pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 3.5pt{\rlap{\rule{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 3.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 7.0pt{\rlap{\rule{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 7.0pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\raise 10.5pt{\rlap{\rule{8pt}{1px}}}{\rlap{\raise 10.5pt{\rlap{\rule[-3.5pt]{8pt}{1px}}}{\rule{8pt}{1px}}}}}}}}}}}}}$。研究提出的投影矩阵是等距的，实现全局参数共享，减少了计算开销。该设计只需一个可训练向量即可重构整个LLM的LoRA参数，实现了统一框架和“一矢足性能”。", "conclusion": "广泛的实验结果显示，Uni-LoRA实现最佳的参数效率，同时在预测性能上优于或匹配先前的方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15403", "html_url": "https://arxiv.org/abs/2510.15403", "title": "Geometric Mixture Models for Electrolyte Conductivity Prediction", "title_en": "Geometric Mixture Models for Electrolyte Conductivity Prediction", "authors": "Anyi Li,Jiacheng Cen,Songyou Li,Mingze Li,Yang Yu,Wenbing Huang", "background": "精确预测电解质系统中的离子电导率对于多个科学和技术应用至关重要，但是目前的研究面临着两个根本性的挑战：缺乏高质量的标准基准，以及对混合系统中分子几何结构和分子间相互作用的建模不足。", "innovation": "提出了一种新的几何感知框架GeoMix，通过引入几何图形表示分子对电解质数据库（CALiSol和DiffMix）进行重组和增强。GeoMix的核心是一个几何相互作用网络（GIN），这是一种特定于分子间几何消息传递的群等变模块。实验表明，GeoMix在两个数据集中的一系列基线（包括MLP、GNN和几何GNN）中表现最佳，证明了跨分子几何交互和群等变消息传递对于准确预测性质的重要性。", "conclusion": "这项工作不仅为电解质研究建立了新的基准，还提供了一种通用的几何学习框架，推动了能量材料、药物开发等领域混合系统建模的进步。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21582", "html_url": "https://arxiv.org/abs/2510.21582", "title": "深入探讨深度神经网络的隐藏路径的无监督之旅", "title_en": "An unsupervised tour through the hidden pathways of deep neural networks", "authors": "Diego Doimo", "background": "本文旨在通过改进我们对深度人工神经网络内部机制的理解，提升网络创造有意义表示以及泛化能力的认识。研究集中在通过无监督学习工具表征隐藏层表示的语义内容上，这些工具部分由作者在本论文中开发并描述。", "innovation": "提出了Grid方法，能够在不减少数据集的情况下估计数据的固有维度，并且方法简单高效，基于严格的分布结果以量化估计的不确定性。此外，研究了深度神经网络中隐藏层概率密度的变化，揭示了语义层次结构的概念，并探讨了泛化问题，表明增加神经网络参数可以提升泛化性能，提供了一种新的理解模型偏见与方差权衡的视角。", "conclusion": "在深度神经网络中，广域网络学习冗余表示而不是过度拟合到偶然的关联。冗余神经元仅出现在网络被正则化且训练误差为零的情况下。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16175", "html_url": "https://arxiv.org/abs/2510.16175", "title": "强化学习研究中的形式-实现差距", "title_en": "The Formalism-Implementation Gap in Reinforcement Learning Research", "authors": "Pablo Samuel Castro", "background": "强化学习（RL）技术在过去的十年里得到了广泛关注和应用，这主要是因为它在某些任务上表现出了超人的能力。这种趋势促使研究社区更加注重展示RL代理的能力，而不是理解其学习动态。这种专注于性能的研究可能会导致过度拟合于学术基准，使得这些技术难以应用于新的问题。此外，这会无形中轻视了那些不追求性能前沿，而是旨在提高我们对这些技术理解的研究。", "innovation": "本文提出了两个观点：一是RL研究不应仅仅专注于展示代理的能力，而应更多地关注强化学习科学的发展；二是需要更加精确地解释我们的基准如何映射到潜在的数学公理。以广泛使用的游戏学习环境ALE为例，说明即使这个基准被认为是“饱和”的，它也可以用于发展这种理解，并促进强化学习技术在实际问题中的部署。", "conclusion": "RL研究应更多地关注推进强化学习的科学和技术的理解，同时在基准测试的设计上要有更精确的数学映射，从而解决当前形式和实现之间的差距，促进技术的实际应用。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.13397", "html_url": "https://arxiv.org/abs/2510.13397", "title": "在信息性删失下生存分析中异质性治疗效果的稳健性评估", "title_en": "Assessing the robustness of heterogeneous treatment effects in survival analysis under informative censoring", "authors": "Yuxin Wang,Dennis Frauen,Jonas Schweisthal,Maresa Schröder,Stefan Feuerriegel", "background": "在临床研究中，患者因副作用或其他原因早早就诊的情况很常见，占到了一半以上。当删失是信息性（即与生存时间相关）时，它会导致截尾偏差，这种偏差使治疗效果估计也受到影响。为了应对这一挑战，本文提出了一种基于部分识别框架，克服截尾偏差，评估生存分析中异质性平均治疗效果（CATE）估计在面对信息性删失时的稳健性。", "innovation": "本文提出了一种基于部分识别的框架，可处理信息性删失带来的截尾偏差。这一方法与其前人的工作不同，并不需要强假设，而是依靠部分识别来推导CATE的信息性界限。此外，本文还开发了一种新的元学习器，该学习器能够用任意机器学习模型估计CATE的界限，具有双重稳健性和准先验效率的理论性优点。该学习器通过数值实验和癌症药物试验应用得到了实证验证。", "conclusion": "本文提供的框架是一种实用工具，用于评估在面对删失时估计治疗效果的稳健性。这为医学和流行病学中的生存数据的有效使用提供了可靠的方法。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17281", "html_url": "https://arxiv.org/abs/2510.17281", "title": "MemoryBench：LLM系统中记忆与持续学习的基准", "title_en": "MemoryBench: A Benchmark for Memory and Continual Learning in LLM Systems", "authors": "Qingyao Ai,Yichen Tang,Changyue Wang,Jianming Long,Weihang Su,Yiqun Liu", "background": "尽管通过扩展数据、参数和测试时的计算量来提升大规模语言模型系统（LLMsys）依然是主流方法，但由于高质量数据逐渐枯竭以及更大计算资源带来的边际收益减少，这些方法的上限已经几乎达到。受到人类和传统AI系统从实践中学习、构建记忆和持续学习框架的能力启发，最近文献中将这种框架用于LLMsys已成为一个重要且热门的研究方向。然而，现有的LLM系统记忆基准主要集中在评估系统在具有长文本输入的同质阅读理解任务上的能力，而忽略了在服务过程中学习累积用户反馈的能力。因此，该研究提出了一种用户反馈模拟框架及覆盖多个领域、语言和任务类型的全面基准，以评估LLM系统持续学习的能力。实验结果表明，最先进的基线方法在效果和效率方面均不理想，并希望能为未来关于LLM系统记忆和优化算法的研究提供方向。", "innovation": "该研究提出了用户反馈模拟框架及全面基准，旨在评测LLM系统在服务过程中从累积用户反馈中学习的能力，这是一个不同于现有评估方法的创新点。", "conclusion": "最先进的基线方法在效果和效率方面均不理想，这表明了构建有效记忆和持续学习框架的重要性和紧迫性。研究人员希望通过此基准为未来的研究提供指导。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22777", "html_url": "https://arxiv.org/abs/2510.22777", "title": "SeeDNorm: 自适应动态归一化", "title_en": "SeeDNorm: Self-Rescaled Dynamic Normalization", "authors": "Wenrui Cai,Defa Zhu,Qingjie Liu,Qiyang Min", "background": "归一化层是神经网络中的重要组成部分。在变压器中，常用的RMSNorm将向量约束到单位超球面，并通过可学习的缩放因子γ进行维度-wise的重新缩放，从而保持模型的表示能力。然而，RMSNorm在前向传播过程中丢弃了输入的归一化信息，而且静态缩放因子γ可能无法适应输入数据的广泛变化和分布偏移，这限制了模型在零样本场景中的进一步性能提升。", "innovation": "我们提出了SeeDNorm，通过基于当前输入动态调整缩放系数来增强模型的表示能力，从而保留输入的归一化信息，并实现数据依赖的自适应动态归一化。在反向传播过程中，SeeDNorm保留了RMSNorm根据输入归一化动态调整梯度的能力。我们对SeeDNorm的训练优化进行了详细分析，并提出了相应的解决方案来解决可能出现在应用SeeDNorm时出现的不稳定问题。我们验证了SeeDNorm在不同规模的语言模型预训练和监督及无监督计算机视觉任务中的有效性，且其引入的参数极少、几乎不影响模型效率。", "conclusion": "与RMSNorm和LayerNorm等以往常用的归一化层相比，SeeDNorm在不同规模的模型中表现出更优越的性能，特别是在零样本场景中，同时，它可以实现自适应动态归一化、保留输入的归一化信息，并且不影响模型的效率。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22138", "html_url": "https://arxiv.org/abs/2510.22138", "title": "通过张量网络实现可管理的Shapley值和交互性", "title_en": "Tractable Shapley Values and Interactions via Tensor Networks", "authors": "Farzaneh Heidari,Chao Li,Guillaume Rabusseau", "background": "Shapley值和Shapley风格的交互性指数通常需要通过计算所有可能的联盟（O(2^n)复杂度）来估计，这在特征数量n较大时会变得极其耗时。现有方法如KernelSHAP-IQ虽然在一定程度上提高了效率，但仍然面临计算瓶颈和时间成本过高的问题。该研究旨在提出一种新的方法，以减少这一复杂性问题，并提供理论上可以接受的误差和可管理性保证。", "innovation": "该研究提出了一种名为TN-SHAP的新方法，通过将预测器局部行为表示为因子化多线性映射，将Shapley值和交互性计算转换为对张量网络中的系数张量进行线性探针。这种方法不仅将计算复杂度从O(2^n)降到一个小数量级的评估中，而且在单特征和两特征交互性计算中分别维持在O(n*poly(chi) + n^2)。实验结果显示，该方法在UCI数据集上与传统方法的结果一致，但评估效率提高了多个数量级，且比KernelSHAP-IQ更快，通常可提高25-1000倍的墙钟时间效率，同时保持相似的准确性。此外，该方法还实现了一致性的训练过程。", "conclusion": "该研究通过张量网络（TN-SHAP）实现了Shapley值和交互性的高效计算，显著降低了计算复杂性，提高了评估效率，并在准确性相近的情况下优于现有的方法，展示了张量网络技术在复杂模型解释性分析中的应用潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.14137", "html_url": "https://arxiv.org/abs/2510.14137", "title": "学习无线干扰模式：在异构多跳 p-persistent CSMA 网络中进行吞吐量预测的解耦 GNN", "title_en": "Learning Wireless Interference Patterns: Decoupled GNN for Throughput Prediction in Heterogeneous Multi-Hop p-CSMA Networks", "authors": "Faezeh Dehghan Tarzjani,Bhaskar Krishnamachari", "background": "p-persistent CSMA 协议是随机访问 MAC 分析的关键，但预测异构多跳无线网络中的饱和吞吐量一直是一个难题。简化模型假设单一共享干扰域，这在稀疏网络拓扑中低估了吞吐量高达 48%-62%。精确的马尔可夫链分析虽然准确，但由于计算时间呈指数增长，使得大型网络变得不切实际。这些计算障碍促使人们采用基于结构的机器学习方法，如 GNNs，来实现泛在网络拓扑中可扩展的吞吐量预测。然而，现成的 GNN 在这里遇到困难：标准的 GCN 在异构网络中的 NMAE 为 63.94%，这是因为对称归一化混淆了节点的直接干扰与通过网络图传播的更高阶的级联效应。", "innovation": "我们提出了一种新颖的 Decoupled Graph Convolutional Network (D-GCN) 架构，它明确地将节点自身传输概率的处理与其邻居干扰效应分开。D-GCN 用可学习的注意力机制替代平均聚合，生成可解释的、每个邻居的贡献权重，同时捕捉复杂的多跳干扰模式。D-GCN 达到了 3.3% 的 NMAE，优于强基线，并保持在精确的分析方法变得计算不可行时还是可行的，同时能够基于梯度的网络优化达到接近理论最优。", "conclusion": "D-GCN 不仅在异构网络中取得了显著的性能提升，还提供了一种可扩展且可优化的方法来预测异构多跳 p-persistent CSMA 网络的吞吐量，即使在计算不可行时也能保持高效性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21800", "html_url": "https://arxiv.org/abs/2510.21800", "title": "MARS-M: 当方差减低遇到矩阵时", "title_en": "MARS-M: When Variance Reduction Meets Matrices", "authors": "Yifeng Liu,Angela Yuan,Quanquan Gu", "background": "基于矩阵的预条件优化器（如Muon）已被证明在训练大规模神经网络，包括大语言模型（LLMs）时比基于标量的优化器更有效。另一方面，针对LLM预训练的优化器基准测试表明，采用方差减低技术（如MARS）的方法比不使用方差减低的标准优化器能实现显著的加速。基于这些背景，本文提出了MARS-M优化器，它将MARS的技术与Muon结合，旨在实现上述两种优化器的优点。", "innovation": "本文引入了一种新的优化器MARS-M，它通过结合MARS的方差减低技术和Muon的优势，旨在同时提高训练速度和模型性能。理论分析表明，在标准条件下，Muon-M收敛于一次最优点的速度为$\tilde{\text{O}}(T^{-1/3})$，优于Muon的$\tilde{\text{O}}(T^{-1/4})$。实验结果显示，MARS-M在语言建模和计算机视觉任务中的一致具有更低的损失和更好的性能，并且其实现已在GitHub上发布。", "conclusion": "实验证明，MARS-M在各种下游基准测试中的性能持续优于其他优化器，特别是在损失值和模型性能方面。该优化器的理论分析和实际应用显示，它代表了优化器领域的显著改进。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13112", "html_url": "https://arxiv.org/abs/2505.13112", "title": "基于注意力机制的聚类", "title_en": "Attention-based clustering", "authors": "Rodrigo Maulen-Soto(SU, LPSM),Pierre Marion(EPFL),Claire Boyer(UPS, IUF)", "background": "变换器作为强大的神经网络架构，能够处理广泛的学习任务。本文通过理论分析，在无监督环境下探讨其自动从数据中提取结构的能力。特别是，研究了输入数据由高斯混合模型生成的情况下，变换器在聚类中的适用性。", "innovation": "研究简化了双头注意力层，并定义了通过使用未标记数据最小化人群风险来驱动头部参数与真实混合质心对齐的目标。进一步研究固定了关键矩阵、查询矩阵和值矩阵为恒等矩阵的注意力层，展示了即使没有可训练参数，这种层也能进行上下文量化，体现了基于变换器的方法动态适应输入特定分布的能力。", "conclusion": "注意力机制的层能够捕获潜在的数据分布结构，即使在没有可训练参数的情况下，基于变换器的方法也能够根据输入数据自适应地进行量化。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.23502", "html_url": "https://arxiv.org/abs/2503.23502", "title": "使用预训练深度基础模型增强全景立体匹配", "title_en": "Boosting Omnidirectional Stereo Matching with a Pre-trained Depth Foundation Model", "authors": "Jannik Endres,Oliver Hahn,Charles Corbière,Simone Schaub-Meyer,Stefan Roth,Alexandre Alahi", "background": "全景深度感知对于需要全方位360°视野场景理解的移动机器人应用至关重要。基于摄像头的设置通过使用立体深度估计来生成密集、高分辨率的深度图，并且成本效益高，无需依赖昂贵的主动传感。然而，现有的全景立体匹配方法在不同的环境、深度范围和光照条件下仅能够实现有限的深度准确度，这是由于缺乏真实世界的数据。", "innovation": "我们提出了一种名为DFI-OmniStereo的新型全景立体匹配方法，利用大规模预训练基础模型在迭代优化的立体匹配架构中进行相对单目深度估算。我们引入了一种专门的两阶段训练策略，利用相对单目深度特征用于我们的全景立体匹配，并进行尺度不变的微调。DFI-OmniStereo在真实世界Helvipad数据集上达到了最先进的结果，与之前的最佳全景立体匹配方法相比，将视差MAE减少了约16%。", "conclusion": "DFI-OmniStereo在Helvipad数据集上实现了最先进的结果，并大幅提高了实际应用中的全景深度感知精度。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04852", "html_url": "https://arxiv.org/abs/2503.04852", "title": "CAUSAL3D：视觉数据因果学习的综合基准", "title_en": "CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data", "authors": "Disheng Liu,Yiran Qiao,Wuche Liu,Yiren Lu,Yunlai Zhou,Tuo Liang,Yu Yin,Jing Ma", "background": "现有的人工智能和计算机视觉技术取得了显著进展，但缺少评估模型从复杂视觉数据中推断潜在因果关系能力的基准。真智能依赖于发现和利用隐藏的因果关系。因此，迫切需要新的基准来评估模型在复杂视图中的因果推理能力。", "innovation": "提出了Causal3D基准，这是一个新颖且全面的基准，结合结构化数据（表格）和相应的视觉表示（图像）来评估因果推理。该基准包含了19个3D场景数据集，这些数据集捕捉了多种因果关系、视角和背景，提供了复杂场景下多种场景的评估能力。这一框架系统化地设计了评估方法以考察多种最先进的方法在因果推理中的表现。", "conclusion": "实验结果显示，随着因果结构变得更加复杂且缺乏先验知识，表现会显著下降，这突显了先进方法在复杂因果场景中的挑战。Causal3D作为一个资源，有助于推进计算机视觉中的因果推理，并促进关键领域的可信赖AI的发展。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.21142", "html_url": "https://arxiv.org/abs/2502.21142", "title": "多模态梦思：世界框架在基于世界模型的强化学习中的应用", "title_en": "Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning", "authors": "Léopold Maytié,Roland Bertin Johannet,Rufin VanRullen", "background": "人类依靠丰富的内部世界模型来推断未来、想象反事实并适应新情况。在强化学习（RL）中，世界模型旨在捕捉环境在代理执行动作时如何演变，从而促进规划和泛化。然而，传统的世界模型直接处理环境变量（例如像素、物理属性），这使其训练过程缓慢且复杂。与之相比，基于高阶潜维度（捕捉相关的多模态变量）可能是更优选择。全球工作空间（GW）理论提供了一种多模态整合和信息传播的认知框架，近年来的研究已经引入了高效的深度学习实现。", "innovation": "本研究将GW与世界模型结合提出了一种新的RL系统——GW-Dreamer，对比了GW-Dreamer与标准PPO和原始Dreamer算法的性能。实验显示，在GW的潜空间中进行“梦思”过程（即心理模拟）可以减少对环境步骤的训练需求。此外GW-Dreamer模型展现出了更强的在缺乏一种观察模态（图像或模拟属性）时的鲁棒性，这是一个额外的附加特性。", "conclusion": "GW与世界模型的结合显示出在RL代理决策制定方面巨大的改进潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.17323", "html_url": "https://arxiv.org/abs/2505.17323", "title": "Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)", "title_en": "Partner Modelling Emerges in Recurrent Agents (But Only When It Matters)", "authors": "Ruaridh Mon-Williams,Max Taylor-Davies,Elizabeth Mieczkowski,Natalia Velez,Neil R. Bramley,Yanwei Wang,Thomas L. Griffiths,Christopher G. Lucas", "background": "人类在合作方面表现出色，能够推断出新合作伙伴的优势和劣势，从而成功地为共享目标工作。为了构建具有这种能力的AI系统，必须首先理解其基本构建模块：这种灵活性是否需要明确、专门的机制来建模他人，或者可以从开放合作互动带来的压力中自发地出现？", "innovation": "通过训练简单的无模型递归神经网络（RNN）代理与多样化的合作伙伴进行合作，并使用Overcooked-AI环境收集数千个合作团队的数据，分析代理的内部隐藏状态。没有添加其他架构特性、诱导偏见或辅助目标，代理仍然发展出结构化的内部模型来表示其合作伙伴的任务能力，从而能够快速适应新的合作伙伴。该研究通过探究技术和大规模行为分析揭示，结构化的合作伙伴建模是在代理能够通过控制任务分配来影响合作伙伴行为时会自发出现。", "conclusion": "代理的合作伙伴建模可以在无模型代理中自发出现，但仅在环境条件施加适当的社会压力时才会出现。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.20039", "html_url": "https://arxiv.org/abs/2504.20039", "title": "AutoJudge: 在无需手动注解的情况下进行解码", "title_en": "AutoJudge: Judge Decoding Without Manual Annotation", "authors": "Roman Garipov,Fedor Velikonivtsev,Ivan Ermakov,Ruslan Svirschevski,Vage Egiazarian,Max Ryabinin", "background": "近年来，大型语言模型（LLM）的推理速度已成为影响其应用效果的关键因素。传统解码方法需要逐个匹配原始模型输出分布中的每个标记，这在时间和资源上都非常耗费成本。因此，研究者们开始探索如何通过牺牲少量准确性来提高解码速度的方法。已有工作如推测性解码通过放宽严格匹配要求来加速解码过程，但仍需人工介入识别哪些标记对下游质量至关重要。", "innovation": "AutoJudge提出了一个特定任务的损失性推测解码方法，通过半贪婪搜索算法测试目标模型和草稿模型之间的差异，并根据现有LLM嵌入训练一个轻量级分类器，以预测哪些差异可以安全接受而不会影响最终答案的质量。这种方法实现了在数学推理和编程基准测试上的显著加速，同时仅降低了微量准确率，无需任何人工注解，并且易于集成到现代LLM推理框架中。特别是在使用Llama 3.1 70B目标模型时，AutoJudge实现了约2倍的速度提升，准确率最多下降1%，同时在LiveCodeBench基准测试中接受至少25个推测周期的标记，准确率下降2%。", "conclusion": "AutoJudge方法通过半贪婪搜索算法和轻量级分类器的结合，大大加速了大规模语言模型的推理过程，同时保持了高质量的生成结果，显著减少了对单调的人工标注依赖，具有较高的实用性和扩展性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.06923", "html_url": "https://arxiv.org/abs/2504.06923", "title": "在端到端差分隐私合成数据中的离散重要性：测量细分的影响", "title_en": "The Importance of Being Discrete: Measuring the Impact of Discretization in End-to-End Differentially Private Synthetic Data", "authors": "Georgi Ganev,Meenatchi Sundaram Muthu Selva Annamalai,Sofiane Mahiou,Emiliano De Cristofaro", "background": "差分隐私(DP)生成边际模型常用于替代敏感数据发布合成表格数据，同时提供正式的隐私保障。这些模型通常需要对训练数据预先离散化，即将连续值划分为间隔，但这一过程中的参数设置可能影响最终的差分隐私保障效果和效果优化。传统的离散化策略（如均匀离散化、等频率离散化和k-均值离散化）可能不适用于所有场景，且其参数的选择依然随机，可能导致最终合成数据质量不佳和隐私保障失效。因此，研究细分策略对DP合成数据的影响以及如何优化细分过程显得尤为重要。", "innovation": "本文进行了对四种细分策略在DP生成边际模型中的广泛应用测量研究。研究内容包括设计并实现实现差分隐私版本的三种细分方法（均匀、等频率和k-均值），并重新实现PrivTree算法。研究发现，优化细分方法和间隔数可以平均提高6个DP生成边际模型的性能约30%，而PrivTree算法在大多数情况下表现为最佳细分方法。此外，研究还表明，在细分过程中应用差分隐私可以有效减少成员推断攻击的风险，同时改进了自动选择最佳间隔数的方法，提高了性能并减少了隐私预算的使用和计算开销。", "conclusion": "研究表明优化细分策略可以显著提高DP生成边际模型的数据效用，同时通过在细分过程应用差分隐私来减少隐私风险。研究还进行了一种改进的自动化选择最佳间隔数的方法，从而保证了高效用并减少了隐私预算和计算成本。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.13883", "html_url": "https://arxiv.org/abs/2504.13883", "title": "基于混合深度学习模型的fNIRS信号认知努力估算", "title_en": "Hybrid Deep Learning Model to Estimate Cognitive Effort from fNIRS Signals", "authors": "Shayla Sharmin,Roghayeh Leila Barmaki", "background": "本研究利用功能近红外光谱(fNIRS)数据和性能得分来估算认知努力，通过混合DeepNet模型实现。认知努力的估计有助于教育者根据学生的需求调整材料，提高学习效果和参与度。研究中使用了基于Unity引擎的教育游戏环境，收集了16名参与者在游戏中回答16个问题时的氧合血红蛋白数据，通过DeepNet模型预测了性能得分，并将传统机器学习与深度学习模型进行了比较，以确定哪种方法在预测性能得分方面更准确。结果显示，提出的CNN-GRU模型性能较好，准确率为73%。", "innovation": "研究采用混合深度学习模型（CNN-GRU）预测教育游戏中的认知努力。通过将氧合血红蛋白与性能得分相结合，评估认知努力。研究发现即使预测精度有限，预测的认知努力也与实际趋势非常接近。这为设计和改进学习环境提供了数据支持，并为学习材料优化提供了有价值的见解。", "conclusion": "研究结果表明，基于fNIRS信号的混合深度学习模型可以用于估算认知努力。尽管预测准确性有局限性，但仍能反映出实际认知努力的变化趋势。该方法可以应用于教育领域，帮助教育工作者更好地调整教学内容，从而提高学生的学习效果和参与度。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14323", "html_url": "https://arxiv.org/abs/2505.14323", "title": "使用反向同态加密保护转移学习网络", "title_en": "Securing Transfer-Learned Networks with Reverse Homomorphic Encryption", "authors": "Robert Allison,Tomasz Maciążek,Henry Bourne", "background": "随着关于训练数据重构攻击的文献越来越多，人们开始对训练于敏感数据上的神经网络分类器的部署提出严重担忧。虽然差异隐私训练（例如使用DP-SGD）可以在大样本训练数据下有效地抵御这些攻击，但现有文献并没有提供充分证据表明这种方法也适用于小样本类别数据的训练。因此，该领域的研究者一直担心小样本类别数据训练的神经网络可能受到重构攻击的影响。", "innovation": "该论文提出了一种新颖的方法——反向同态加密（Reversed Homomorphic Encryption, RHE），该方法在不损害模型准确性的情况下保护训练数据。传统的同态加密保护模型输入数据且需要对整个分类器进行昂贵的同态实现，而此方案计算效率更高，保护的是训练数据而非输入数据。通过简单的角色反转实现，即将分类器输入数据不解密但转移学习权重加密，从而保护了分类器的输出，防止了任何形式的数据重构攻击，只有持有私钥的受信任方可以获取分类器的类别决策。", "conclusion": "该研究通过在实际的对手模型下显著增强了重构攻击能力，直接证实了低样本类别数据训练的神经网络在差异隐私训练下容易遭受数据重构攻击。该论文提出了一种有效的反向同态加密方法，显著提高了神经网络在敏感数据上的安全性，而不会影响模型的准确性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12758", "html_url": "https://arxiv.org/abs/2505.12758", "title": "全球城市视觉感知因人口统计和性格差异而异", "title_en": "Global urban visual perception varies across demographics and personalities", "authors": "Matias Quintana,Youlong Gu,Xiucheng Liang,Yujun Hou,Koichi Ito,Yihan Zhu,Mahmoud Abdelrahman,Filip Biljecki", "background": "理解人们的偏好对于城市规划至关重要，但当前的方法往往将多元文化人口的回应结合在一起，掩盖了人口差异并可能放大偏见。因此，本研究使用街景图像在全球范围内进行了大规模的城市视觉感知调查，以探索包括性别、年龄、收入、教育、种族和民族、以及性格特质在内的多种人口统计学因素如何塑造了1,000名来自五个国家和45种国籍的参与者的城市感知。", "innovation": "该研究创建了一个名为Street Perception Evaluation Considering Socioeconomics (SPECS)的数据集，揭示了基于人口统计学和性格特征的差异对六个传统指标（包括安全、活力、富有、美丽、无聊、压抑）以及四个新指标（包括希望生活附近、步行、骑行和绿色）的影响。此外，地点感知进一步塑造了这些偏好。研究表明，基于现有全球数据集训练的机器学习模型往往高估了正面指标，而低估了负面指标，表明需要考虑地方背景。", "conclusion": "本研究旨在纠正城市感知中的短期视见问题，这些问题通常不考虑人口统计学或性格因素。研究强调了基于地方背景的数据收集和分析的重要性，以更准确地了解城市居民的实际感知和需求。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.15141", "html_url": "https://arxiv.org/abs/2510.15141", "title": "超越PCA：基于局部图结构的流形维度估计", "title_en": "Beyond PCA: Manifold Dimension Estimation via Local Graph Structure", "authors": "Zelong Bi,Pierre Lafaye de Micheaux", "background": "局部主成分分析（Local PCA）已被证明是估计流形本征维度的有效工具。最近，曲率调整主成分分析（CA-PCA）通过显式考虑流形的曲率而非假设局部平坦性，进一步提升了这一方法。在此基础上，我们提出了一个框架，通过结合主成分分析（PCA）和基于回归的技术来捕捉流形的局部图结构。在这个框架下，我们引入了两种代表性估计器：二次嵌入（QE）和总最小二乘法（TLS）", "innovation": "我们构建了一个通用框架，通过结合PCA和回归算法来估计流形的局部图结构，以此捕捉流形的局部几何特性。我们提出了两种新的估计器，分别是二次嵌入（QE）和总最小二乘法（TLS）", "conclusion": "实验表明，这些方法与最先进的替代方法相比，表现相当甚至更优。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.12730", "html_url": "https://arxiv.org/abs/2508.12730", "title": "Unlearning Comparator：一种用于评估机器卸载方法的可视分析系统", "title_en": "Unlearning Comparator: A Visual Analytics System for Comparative Evaluation of Machine Unlearning Methods", "authors": "Jaeung Lee,Suhyeon Yu,Yurim Jang,Simon S. Woo,Jaemin Jo", "background": "机器卸载（MU）旨在从训练好的模型中移除目标训练数据，使模型不再受这些数据的影响，从而满足数据隐私法律法规中的“被遗忘权利”。然而，研究人员在该新兴领域的分析和理解不同MU方法的行为时，尤其是准确性、效率和隐私这三个基本原则方面遇到了挑战。因此，他们往往依赖于聚合指标和随意评估，使得它们难以准确评估不同方法之间的权衡。", "innovation": "该研究引入了一个可视分析系统——Unlearning Comparator，旨在简化MU方法的系统评估。该系统支持两个重要任务：模型比较和攻击模拟。首先，它允许用户在类、实例和层三个层面比较两种模型的行为，以更好地理解卸载后的更改。其次，它通过模拟成员推断攻击（MIAs）来评估方法的隐私性，即攻击者试图确定特定数据样本是否是原始训练集的组成部分。", "conclusion": "通过一个案例研究对著名的MU方法进行可视化分析，该系统帮助用户不仅理解模型行为，还能获得有关改进MU方法的见解。源代码已公开。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.03534", "html_url": "https://arxiv.org/abs/2510.03534", "title": "使用多智能体强化学习进行杜罗河河口的长期测绘", "title_en": "Long-Term Mapping of the Douro River Plume with Multi-Agent Reinforcement Learning", "authors": "Nicolò Dal Fabbro,Milad Mesbahi,Renato Mendes,João Borges de Sousa,George J. Pappas", "background": "当前研究主要集中在使用多自主水下机器人（AUV）进行河流河口的长时间（多日）测绘。以杜罗河为代表的应用案例进行研究，现有的方法在能量和通信效率方面存在不足，且难以有效管理多智能体的协调。研究背景在于，需要一种能够高效利用资源同时提高测绘精度的方法来解决这一问题。", "innovation": "本文提出了一种能效和通信效率高的多智能体强化学习方法，通过中央协调器与AUV间间歇性通信，来收集测量并发布命令。该方法结合了时空高斯过程回归(GPR)和多头Q网络控制器，分别用于控制每个AUV的方向和速度。研究表明，随着智能体数量的增加，我们的方法不仅降低了均方误差（MSE），还提高了操作续航能力；在某些情况下，增加AUV数量可以显著提升续航能力，同时保持或提高准确性。", "conclusion": "本文的方法在不同季节和年份中表现出色，能够有效适用于未知的动态河口环境，具有数据驱动的长期动态河口监测的潜力，为未来的研究提供了重要启示。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.23143", "html_url": "https://arxiv.org/abs/2509.23143", "title": "MathBode：通过动力系统理解大语言模型的推理", "title_en": "MathBode: Understanding LLM Reasoning with Dynamical Systems", "authors": "Charles L. Wang", "background": "大语言模型（LLMs）的准确率被视为其性能的重要指标，但这种方法存在着局限性。这一研究旨在开发一种动力系统动态诊断工具，名为MathBode，用于评估LLMs在数学推理中的表现，不仅依赖于单一的准确率，还分析了频率相关的gain和phase响应，揭示了仅靠准确率无法看出的系统性低通行为和增长的相移等现象。", "innovation": "该论文创新地将大语言模型的数学推理问题视为动态系统，并使用了一种新的诊断方法——MathBode。通过驱动单一参数的正弦波并拟合模型输出和精确解的第一谐波响应，生成Bode图样的指纹，提供了可解释的频率分辨率度量标准——增益（幅度跟踪）和相位（滞后）。这种新方法能够更全面地评估模型在各种封闭形式家庭问题（如线性求解、比率/饱和度、复利、2x2线性系统和相似三角形）上的推理表现，尤其是动态特性和连续性方面。", "conclusion": "该研究揭示了大语言模型在数学推理中的系统性动态行为，并与符号基准进行对比，展示了对前沿模型和中等模型在动态性方面的区分能力。结果为大语言模型的准确推理提供了可操作的评估标准，补充了现有的基准测试，并提供了具体的研究指导。研究者将数据集和代码开源，支持进一步的研究和应用。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01268", "html_url": "https://arxiv.org/abs/2510.01268", "title": "AdaDetectGPT：具有统计保证的大规模语言模型生成文本的自适应检测", "title_en": "AdaDetectGPT: Adaptive Detection of LLM-Generated Text with Statistical Guarantees", "authors": "Hongyi Zhou,Jin Zhu,Pingfan Su,Kai Ye,Ying Yang,Shakeel A O B Gavioli-Akilagun,Chengchun Shi", "background": "现有的最先进的基于logits的检测器利用了从给定来源的语言模型的概率分布中得出的统计数据来评估观察到的文本的概率。然而，仅依赖于log概率可能会存在不足。因此，本文研究了如何更好地检测文本是由人类还是由大规模语言模型生成的问题。", "innovation": "作者提出了一种名为AdaDetectGPT的新颖分类器，它能够从训练数据中自适应地学习见证函数，以增强基于logits的检测器的性能。该方法提供了关于True Positive Rate、False Positive Rate、True Negative Rate和False Negative Rate的统计保证，并通过广泛的数值研究，证明了在不同数据集和语言模型的组合中，该方法几乎可以提升当前最先进的方法，并且提升幅度最大可达37%。", "conclusion": "通过AdaDetectGPT，研究人员显著提高了基于logits的检测器在识别由大规模语言模型生成的文本方面的性能，特别是在不同的数据集和语言模型组合方面，该方法增强了检测准确性和可靠性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20072", "html_url": "https://arxiv.org/abs/2508.20072", "title": "离散扩散VLA：将离散扩散引入视觉-语言-动作策略的动作解码", "title_en": "Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies", "authors": "Zhixuan Liang,Yizhuo Li,Tianshuo Yang,Chengyue Wu,Sitong Mao,Tian Nian,Liuao Pei,Shunbo Zhou,Xiaokang Yang,Jiangmiao Pang,Yao Mu,Ping Luo", "background": "视觉-语言-动作（VLA）模型通过大型视觉-语言主干网络将图像和指令映射为机器人动作。然而，现有的VLA要么以固定的从左到右顺序生成动作，要么在主干外部附加单独的MLP或扩散头，导致信息路径的碎片化以及专门的训练要求，这阻碍了统一和可扩展架构的构建。", "innovation": "我们提出了离散扩散VLA，这是一种统一变压器策略，通过离散扩散模型离散化的动作片段。该设计保留了扩散模型逐级细化的范式，同时与VLMs的离散标记接口保持原生兼容性。该方法实现了自适应解码顺序，首先处理简单的动作元素，再解决困难的元素，并通过二次掩码在更新过程中重访不确定的预测以提高一致性和实现稳健的错误校正。该统一的解码器保留了预训练的视觉语言属性，支持并行解码，突破了自回归瓶颈，并减少了函数评估的数量。", "conclusion": "离散扩散VLA在LIBERO上实现了96.3%的平均成功率，在SimplerEnv-Fractal上实现了71.2%的视觉匹配，在SimplerEnv-Bridge上实现了54.2%的整体性能，优于自回归、MLP解码器和连续扩散基线。这些发现表明，离散扩散VLA支持精细的动作建模和一致的训练，为将VLA扩展到更大模型和数据集奠定了基础。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.10712", "html_url": "https://arxiv.org/abs/2509.10712", "title": "MinatoLoader：通过高效数据预处理加速机器学习训练", "title_en": "MinatoLoader: Accelerating Machine Learning Training Through Efficient Data Preprocessing", "authors": "Rahma Nouaji,Stella Bitchebe,Ricardo Macedo,Oana Balmau", "background": "在机器学习框架（如PyTorch和TensorFlow）中，数据加载器在将数据送入加速器之前对数据进行变换。数据预处理在整个机器学习训练流程中至关重要，但如果它与训练操作高效耦合度不够，会导致GPU资源的大量闲置，从而造成重要的训练延迟。现有数据加载器，在处理数据时存在76%的GPU闲置问题。这主要是因为不同数据样本在预处理时间上的差异性，现有加载器缺乏对这种差异性的处理，导致整个批次延迟，训练管道被阻塞。", "innovation": "MinatoLoader是一个专为PyTorch设计的一般用途数据加载器，它通过在后台连续准备数据并优先处理预处理速度快的数据样本，从而加速训练、提高GPU利用率。MinatoLoader适用于单服务器环境，具有多个GPU。实验结果表明，与PyTorch DataLoader和Pecan相比，MinatoLoader在四块A100 GPU的机器上将多种工作负载的训练时间最多可提高7.5倍（平均提高3.6倍），与DALI相比最多提高3倍（平均提高2.2倍）。MinatoLoader还能够将平均GPU利用率从46.4%提高到90.45%，同时保持模型的准确性和加速收敛。", "conclusion": "MinatoLoader通过优化数据预处理流程，显著提高了GPU的利用效率，加速了PyTorch下的机器学习训练过程，展示了在单GPU或多GPU环境下的应用潜力。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.17550", "html_url": "https://arxiv.org/abs/2509.17550", "title": "Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem", "title_en": "Is It Certainly a Deepfake? Reliability Analysis in Detection & Generation Ecosystem", "authors": "Neslihan Kose,Anthony Rhodes,Umur Aybars Ciftci,Ilke Demir", "background": "随着生成模型不断进步，能够生成高质和大量合成内容的场景增多，使得“深度伪造”内容在网络上引发信任问题。为了应对这一问题，人们提出了深度伪造检测器。然而，这些检测器的误用可能会导致假内容被错误地标记为真实，从而使信息误导更加严重。本文首次进行了全面的不确定性分析，并系统地研究了生成艺术如何影响预测信心，进一步发现生成器本身也会增加这一不确定性。", "innovation": "本文提出了利用贝叶斯神经网络和蒙特卡洛dropout来量化不同检测器架构中的两种不确定性（Aleatoric和Epistemic不确定性）。在两个数据集上进行了九种不同生成器的不确定性分析，评估了不同不确定性方法、区域和像素级别的不确定性，并进行了消融研究。此外，还引入了不确定性地图，揭示了与生成器特定特征相关联的独特模式，从而提供了部署可靠深度伪造检测系统的关键见解。", "conclusion": "我们的分析为部署可靠的深伪检测系统提供了关键见解，确立了不确定性量化作为可信赖合成媒体检测的必要条件。我们进行了二元真实/假和多类别真实/假、源检测以及生成器/检测器组合之间的留一法实验，以评估它们的泛化能力、模型校准、不确定性以及对抗性攻击的鲁棒性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.20234", "html_url": "https://arxiv.org/abs/2509.20234", "title": "ImageNet训练的CNN并非偏向纹理：通过受控抑制重新审视特征依赖性", "title_en": "ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression", "authors": "Tom Burgert,Oliver Stoll,Paolo Rota,Begüm Demir", "background": "关于卷积神经网络（CNNs）在深度学习特征使用中的固有偏见假设，即它们偏好纹理，已影响了对特征使用的讨论。本文通过重新评估Geirhos等人设计的实验，探讨了这一假设，并提出了一种领域无关的框架，通过系统性地抑制形状、纹理和颜色线索来量化特征依赖性，从而克服了强制选择冲突的混淆因素。在控制抑制条件下评估人类和神经网络后，我们发现CNNs并非固有地偏好纹理，而是主要依赖于局部形状特征，但现代训练策略或架构（如ConvNeXt和ViTs）可以显著减轻这种依赖性。此外，本文还探讨了不同领域的特征依赖性差异：计算机视觉模型侧重于形状，医学成像模型侧重于颜色，遥感模型则在纹理依赖上表现更强。", "innovation": "本文提出了一种领域无关的框架来重新审视特征依赖性，通过系统性地抑制形状、纹理和颜色线索，克服了强制选择冲突的混淆因素，并且通过计算机视觉、医学成像和遥感领域的广泛分析，揭示了不同领域的依赖性差异。", "conclusion": "虽然ImageNet训练的CNNs对纹理的依赖情况比之前认为的要小，但它们在很大程度上依赖于局部形状特征。现代训练策略和架构可以通过在其他任务上的迁移学习来降低这种依赖性。不同领域的模型表现出不同的依赖性模式：计算机视觉模型优先考虑形状，医学成像模型强调颜色，而遥感模型则显示出更强的纹理依赖性。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08078", "html_url": "https://arxiv.org/abs/2510.08078", "title": "在视频到音频生成中检测和缓解插入幻觉", "title_en": "Detecting and Mitigating Insertion Hallucination in Video-to-Audio Generation", "authors": "Liyang Chen,Hongkai Chen,Yujun Cai,Sifan Li,Qingwen Ye,Yiwei Wang", "background": "视频到音频生成已经取得了显著进展，能够自动生成与视频匹配的声音。然而，现有的评价指标主要关注语义和时间上的对齐，忽视了一个关键的失败模式：生成模型通常会生成声学事件，尤其是语音和音乐，而这些事件在视频中没有相应的视觉来源。这种现象被称为插入幻觉，并主要由数据集中的偏见驱动，比如离屏声音的普遍存在，这些偏见目前的评价标准无法检测出来。", "innovation": "本文首先开发了一种系统评估框架，采用多个音频事件检测器的多数投票集合。还提出了两个新的度量标准：IH@vid（具有幻觉的视频占比）和IH@dur（幻觉持续时间的占比），以便量化这一问题的普遍性和严重程度。在此基础上，提出了无需训练的推理时后验特征校正方法（PFC），这种方法在两个步骤中进行操作：首先生成初始音频以检测幻觉段落，然后在这些时间戳处掩盖相应的视频特征并重新生成音频。实验表明，我们的PFC方法在平均降低幻觉的普遍性和持续时间方面效果显著，且在某些情况下甚至提高了传统的声音质量和时间同步指标。", "conclusion": "本文是首个正式定义、系统测量和有效缓解插入幻觉的工作，为更可靠和真实的视频到音频模型铺平了道路。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.18239", "html_url": "https://arxiv.org/abs/2510.18239", "title": "LIME: 基于链接的用户-项目交互建模与解耦XOR注意力机制以实现高效测试时间扩展", "title_en": "LIME: Link-based user-item Interaction Modeling with decoupled xor attention for Efficient test time scaling", "authors": "Yunjiang Jiang,Ayush Agarwal,Yang Liu,Bi Xue", "background": "构建大型推荐系统需要在三个主要领域取得进步：处理更长的用户历史、扩展候选集以及提高模型容量。尽管变压器在性能上表现出色，其计算成本会随着用户序列长度的平方和候选集数量的线性增长而增加。这种权衡使得在测试时扩大候选集或增加序列长度变得非常昂贵，尽管这能显著提高性能。", "innovation": "我们引入了LIME，一种新的架构，解决了上述权衡问题。LIME通过两种关键创新降低计算复杂度。首先，低秩“链接嵌入”通过解耦用户和候选的交互实现了注意力权重的预计算，使得推理成本几乎与候选集大小无关。其次，提出了线性注意力机制LIME-XOR，将用户序列长度的复杂度从二次（O(N^2)）降低到线性（O(N)）。", "conclusion": "实验表明，LIME在处理大量候选集或长序列时，在公共和工业数据集上几乎与最先进的变压器模型具有同等性能，但推理速度提高了10倍。在主流推荐平台上的测试显示，LIME在保持较低推理成本的同时，还增加了用户参与度，确立了一种新的高效且表达力强的推荐系统范式。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20958", "html_url": "https://arxiv.org/abs/2510.20958", "title": "神经导航：在线学习中增强学生注意力的实时脑-计算机接口系统", "title_en": "NeuroPilot: A Realtime Brain-Computer Interface system to enhance concentration of students in online learning", "authors": "Asif Islam,Farhan Ishtiaque,Md. Muhyminul Haque,Farhana Sarker,Ravi Vaidyanathan,Khondaker A. Mamun", "background": "在线学习的普及提出了实时监测学生注意力的重要挑战。传统的方法如问卷评估需要人工干预，基于网络摄像头的监控不能提供关于学习者心理专注度的准确见解，因为它会被简单的屏幕凝视所误导，缺乏真正的认知参与。现有的基于脑-机接口(BCI)的方法缺乏实时验证和评估程序。论文背景介绍了传统的监测方法和基于BCI的方法的局限性，强调了需要一种新的方法来解决这些问题。", "innovation": "该研究开发了一种非侵入性的脑电图(EEG)光环带FocusCalm，以实时监测学生的注意力状态。研究表明，通过使用新型视频内问卷评估、信号分割、滤波、去噪、特征提取和支持向量机(SVM)结合递归特征消除(RFE)进行分类，可以有效地区分学生的专注和不专注状态。该系统在88.77%的准确率下实现了注意力和非注意力状态的分类，并在实时反馈中通过了一项试点研究，显著提升了参与者的注意力水平。", "conclusion": "实验结果表明，该系统能够有效监测学生在线学习过程中的注意力状态，并通过实时反馈提高学生的专注度。未来的研究可能需要扩大参与者样本，优化算法以提高准确性，以及在更广泛的学习背景下验证该系统的效果。"}
{"llm_update_time": "20251029", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.20974", "html_url": "https://arxiv.org/abs/2510.20974", "title": "通过PCA基元的规范标准化实现鲁棒的点云强化学习", "title_en": "Robust Point Cloud Reinforcement Learning via PCA-Based Canonicalization", "authors": "Michael Bezick,Vittorio Giammarino,Ahmed H. Qureshi", "background": "最近的研究表明，直接从原始视觉输入进行强化学习（RL）已经取得了显著的成绩，但仍然对分布外变化（如光照、颜色和视角的变化）非常敏感。点云强化学习（PC-RL）通过减轻基于外观的脆弱性提供了一种有希望的替代方案，但由于摄像机姿态匹配的敏感性，在现实场景中的可靠性仍然存在问题。这限制了PC-RL在实际应用中的广泛使用。本文探讨了如何通过一种特定于下游机器人控制的标准化框架来解决这一挑战问题。", "innovation": "提出了PCA点云（PPC），这是一种专门针对下游机器人控制进行标准化的框架。PPC可以将任意刚体变换下的点云映射到唯一的标准姿态，使观察结果对齐到一致的框架，从而显著减少由视角引起的不一致性。实验结果显示，PPC显著提高了在挑战性机器人任务中对未见摄像机姿态的鲁棒性，提供了一种领域随机化之外的规范化替代方案，具有坚实的理论基础。", "conclusion": "本文提出的PPC框架通过向下游机器人控制应用点云进行规范标准化，增强了PC-RL的鲁棒性，特别是在处理未见摄像机姿态时。这种方法提供了一种改进的点云强化学习框架，特别适用于需要高鲁棒性的机器人任务。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.23966", "html_url": "https://arxiv.org/abs/2510.23966", "title": "一种衡量链式思维可监控性的实用方法", "title_en": "A Pragmatic Way to Measure Chain-of-Thought Monitorability", "authors": "Scott Emmons,Roland S. Zimmermann,David K. Elson,Rohin Shah", "background": "链式思维（CoT）监测为AI安全提供了独特的机会，但这种机会可能会因训练实践或模型架构的变化而丧失。为了帮助保留监测能力，作者提出了一种实用的方法来衡量监测的两个方面：可读性（人类能否理解推理过程）和覆盖性（CoT是否包含了生成最终输出所需的所有推理步骤）。作者使用了一个自动评分提示，使任何有能力的LLM能够计算现有CoT的可读性和覆盖性。", "innovation": "作者提出了一种新的实用方法，通过一个自动评分提示来衡量CoT的可读性和覆盖性，这种方法不仅可以在真实模型上应用，还经过了合成CoT降解的验证。这种方法有助于开发者监控设计决策对监测能力的影响。", "conclusion": "尽管作者分享的具体提示仍处于初步版本，但作者希望通过分享帮助社区其他成员发现其价值。这种方法主要用于衡量CoT的默认可监控性，应作为对抗性压力测试的补充，而不是替代。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.24459", "html_url": "https://arxiv.org/abs/2510.24459", "title": "自主性代理的可用性表示与识别", "title_en": "Affordance Representation and Recognition for Autonomous Agents", "authors": "Habtom Kahsay Gidey,Niklas Huber,Alexander Lenz,Alois Knoll", "background": "软件代理的自主性依赖于它们从定义其数字环境的结构化数据（如网页的文档对象模型DOM和网络服务的语义描述）构建可操作内部世界模型的能力。然而，从原始结构化数据构建世界模型面临着两个关键挑战：原始HTML的冗长性使得直接用于基础模型的计算上变得不切实际，而硬编码的API集成的静态性质阻止了代理适应服务的演变。", "innovation": "本文提出了一个结构化数据建模模式的语言，介绍了一种互补的架构模式，即DOM变换模式和超媒体可用性识别模式。DOM变换模式通过简化繁冗的原始DOM，将其提炼成一个紧凑的任务相关表示或世界模型，以便于代理的推理核心使用。同时，超媒体可用性识别模式使代理能够动态地丰富其世界模型，通过解析标准化的语义描述来发现并整合未知Web服务的运行时功能。", "conclusion": "结合使用这些模式提供了构建和维护准确世界模型的稳健框架，从而使代理能够高效地进行跨Web及其扩展资源的可扩展、适应性和互操作性自动化。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.24188", "html_url": "https://arxiv.org/abs/2510.24188", "title": "探究基于LLM生成的软件系统的软件老化现象", "title_en": "Investigating Software Aging in LLM-Generated Software Systems", "authors": "César Santos,Ermeson Andrade,Roberto Natella", "background": "自动生成的软件，尤其是由大型语言模型（LLMs）生成的代码，被广泛用于加速开发和减少人力成本。然而，对其在长时间连续运行下的长期可靠性知之甚少。本文通过实验研究基于LLM工具生成的应用程序中的软件老化现象，使用Bolt平台和Baxbench的标准提示生成了四个服务导向的应用程序，并进行了50小时的负载测试，持续监控资源使用情况、响应时间和吞吐量，以检测老化模式。结果显示，所有应用程序均显示出显著的老化现象，包括内存逐渐增长、响应时间增加以及性能不稳定。统计分析确认了这些趋势，并指出不同类型的软件老化程度存在差异性。", "innovation": "本文通过实验揭示了基于LLM生成的应用程序的软件老化现象，并使用Bolt平台和Baxbench的标准提示生成和测试了多个应用程序，这对于评估自动生成软件的长期可靠性具有重要意义。结果有助于认识自动生成软件中的老化现象，并为未来的老化缓解策略和长期可靠性评估奠定了基础。", "conclusion": "本文的研究发现了自动生成软件存在重要老化现象，建议在设计和使用此类系统时考虑软件的老化问题，同时为进一步进行老化缓解策略的研究和长期可靠性评估提供了基础和参考。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.24367", "html_url": "https://arxiv.org/abs/2510.24367", "title": "LLM-as-a-Judge for Software Engineering: Literature Review, Vision, and the Road Ahead", "title_en": "LLM-as-a-Judge for Software Engineering: Literature Review, Vision, and the Road Ahead", "authors": "Junda He,Jieke Shi,Terry Yue Zhuo,Christoph Treude,Jiamou Sun,Zhenchang Xing,Xiaoning Du,David Lo", "background": "大型语言模型（LLMs）在软件工程中的快速集成已经革新了诸如代码生成等任务，产生了大量软件产品。然而，评价这些输出的方法缺乏可扩展性和可靠性。传统的人工评价成本高且耗时，而传统的自动化评估指标（如BLEU）无法捕捉到质量的细微差异。因此，使用LLMs进行自动评估的‘LLM-as-a-Judge’方法逐渐兴起。然而，该领域在软件工程中仍处于初期阶段，本论文旨在指导社区关注这一领域并推动相关研究。", "innovation": "本文提供了现有软件工程文献的综述，分析其不足之处，明确了关键研究缺口，并提出了详细的行动规划。提出了LLM-as-a-Judge框架作为可靠的、稳健且可扩展的人类代理，能够在2030年实现多维度的软件产物评价。旨在促进LLM-as-a-Judge框架的研究和应用，提升软件产物评价的规模性。", "conclusion": "本文旨在推动研究和采用LLM-as-a-Judge框架，最终改善软件产物评价的规模性。文中提出的研究路径和框架为未来的相关研究提供了宝贵的指导。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.24265", "html_url": "https://arxiv.org/abs/2510.24265", "title": "开发者使用生成性人工智能工具的生产力", "title_en": "Developer Productivity with GenAI", "authors": "Sadia Afroz,Zixuan Feng,Katie Kimura,Bianca Trinkenreich,Igor Steinmacher,Anita Sarma", "background": "生成性人工智能工具在软件开发中的应用越来越广泛，但对其在提升生产力方面的具体影响缺乏明确的证据。本研究通过调查开发者的感知，利用SPACE框架探讨生成性人工智能工具如何影响开发者的不同生产力维度，包括满意度和福祉、绩效、活动、沟通与协作、效率和流程。研究表明，使用生成性人工智能工具的频率不会带来显著的整体生产力变化，揭示了开发者的效率提升并不一定导致更好的软件质量和更高的个人满意度的悖论现象。", "innovation": "本文通过利用SPACE框架分析生成性人工智能工具对开发者生产力的影响，这是一种新颖的方法，不仅可以提供对生产力变化的全面理解，还能帮助识别生成性人工智能工具的实际应用效果和潜在的局限性。此外，通过调查不同使用频率的开发者，识别出效率提升不总是伴随软件质量和个人满意度提升的现象，这是对当前研究的补充和加深认识。", "conclusion": "调查结果显示，生成性人工智能工具的应用虽然使开发者在某些方面变得更快，但并未显著提高软件质量和开发者的个人满意度。这种现象揭示了‘生产力悖论’，即开发者的效率提升并不等同于更好的软件质量和更高的个人满意度。研究对未来的研究和实际应用都有一定的指导意义，提倡在使用生成性人工智能工具时应更多关注质量和满意感的提升。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.24358", "html_url": "https://arxiv.org/abs/2510.24358", "title": "通过代理驱动的标注和评估自动基准测试LLM代码代理", "title_en": "Automatically Benchmarking LLM Code Agents through Agent-Driven Annotation and Evaluation", "authors": "Lingyue Fu,Bolun Zhang,Hao Guan,Yaoming Zhu,Lin Qiu,Weiwen Liu,Xuezhi Cao,Xunliang Cai,Weinan Zhang,Yong Yu", "background": "最近，代码代理的进步使项目级的自动化软件开发成为可能，由大型语言模型（LLMs）和常用工具支持。然而，现有代码代理评估基准面临两个主要挑战：高注释成本和专业知识要求，以及依赖主要单元测试的固有评估指标。", "innovation": "本文提出了一种代理驱动的基准构建管道，利用人类监督高效生成多样化和具有挑战性的项目级任务。基于此方法，作者引入了PRDBench，这是一个包含50个实际Python项目的新基准，每个项目涉及20个领域，并具有结构化的制品需求文档（PRD）要求、全面的评估标准和参考实现。PRDBench具有丰富的数据源、高任务复杂性和灵活的指标。此外，还采用代理作为法官的模式来评估代理输出，使评估范围超越单元测试。", "conclusion": "在PRDBench上的广泛实验表明，该基准能有效地评估代码代理和评估代理的能力，为注释和评估提供了可扩展和稳健的框架。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.24241", "html_url": "https://arxiv.org/abs/2510.24241", "title": "MAGNET: 多图注意力网络在代码克隆检测中的应用", "title_en": "MAGNET: A Multi-Graph Attentional Network for Code Clone Detection", "authors": "Zixian Zhang,Takfarinas Saber", "background": "代码克隆检测是软件工程中的一个基本任务，它支撑着重构、调试、剽窃检测和漏洞分析等工作。现有的方法往往依赖于单一表示方式，如抽象语法树（ASTs）、控制流图（CFGs）和数据流图（DFGs），它们只能捕捉代码语义的局部特性。为了解决这一问题，已有混合方法出现，但是它们的跨图融合策略通常是由人工设计的，效果并不理想。因此，迫切需要一种可以同时利用多种代码表示方式、且能捕捉局部和全局依赖性的方法。", "innovation": "本文提出了一种名为MAGNET的多图注意力框架，它结合了AST、CFG和DFG表示，利用残差图神经网络和节点级别的自我注意力机制学习局部和长期依赖关系，引入了门控交叉注意力机制以实现细粒度的跨图交互，并通过Set2Set池化将多种图嵌入融合为统一的程序级表示。实验结果表明，MAGNET在BigCloneBench和Google Code Jam数据集上分别达到了96.5%和99.2%的总体F1分数，并且消融研究验证了多图融合和每个注意力模块的重要贡献。", "conclusion": "MAGNET通过结合多种代码表示、学习局部和全局依赖性以及进行多图融合，能够实现高效的代码克隆检测，在BigCloneBench和Google Code Jam数据集上达到了最先进的性能。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.23682", "html_url": "https://arxiv.org/abs/2510.23682", "title": "超越提示工程：神经符号因果架构为稳健多目标AI代理", "title_en": "Beyond Prompt Engineering: Neuro-Symbolic-Causal Architecture for Robust Multi-Objective AI Agents", "authors": "Gokturk Aytug Akarlar", "background": "大型语言模型作为自主决策代理展现出潜力，但在高风险领域中的部署仍然充满风险。未经授权的架构防护下，LLM代理表现出致命的脆弱性：相同的能力因提示框架的不同而导致截然不同的结果。本文研究了Chimera架构，该架构将LLM战略家、形式验证的符号约束引擎和因果推理模块结合，以实现反事实推理。该研究在包含价格弹性、信任动态和季节性需求的现实电子商务环境中，对Chimera架构与LLM单一架构及带有符号约束的LLM架构进行了52周的基准测试。", "innovation": "Chimera架构通过结合LLM战略家、形式验证的符号约束引擎和因果推理模块，解决了LLM单纯依赖提示框架的问题。该研究强调了架构设计而非提示工程在生产环境中自主代理可靠性上的决定性作用。对Chimera的TLA+形式验证证明在所有场景下均无约束违规。", "conclusion": "研究结果表明，Chimera架构在多种场景下持续提供最高回报（分别为152万美元和196万美元，某些情况下甚至超过220万美元），并提升了品牌信任（增幅分别为1.8%和10.8%，某些情况下甚至增加20.86%）。形式化的验证证明Chimera在所有场景下均无约束违规。这说明自主代理的可靠性在实际生产环境中取决于架构设计而非提示工程。该研究提供了开源实现和互动演示以确保可复现性。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.24706", "html_url": "https://arxiv.org/abs/2510.24706", "title": "ComboBench: 能否让大规模语言模型操纵物理设备来玩虚拟现实游戏？", "title_en": "ComboBench: Can LLMs Manipulate Physical Devices to Play Virtual Reality Games?", "authors": "Shuqing Li,Jiayi Yan,Chenyu Niu,Jen-tse Huang,Yun Peng,Wenxuan Wang,Yepang Liu,Michael R. Lyu", "background": "虚拟现实（VR）游戏需要玩家将高层次的语义动作精确地转化为控制器和头戴式显示器（HMD）的操作。虽然人类能够通过常识和体感触觉直观地执行这种转换，但大规模语言模型（LLMs）是否能有效地复制这一能力尚未得到充分利用。本文通过创建一个名为ComboBench的基准测试，评估多种LLMs将语义动作转化为VR设备操作的能力。测试基于262个场景，涉及四款流行VR游戏：Half-Life: Alyx、Into the Radius、Moss: Book II 和 Vivecraft。", "innovation": "本文提出了一个新的基准测试——ComboBench，评估了七种不同的LLMs，包括GPT-3.5、GPT-4、GPT-4o、Gemini-1.5-Pro、LLaMA-3-8B、Mixtral-8x7B和GLM-4-Flash，将其能力转化为VR设备操作序列。这是第一次系统地评估LLMs在虚拟现实环境中的应用，特别是在游戏操作中的表现。", "conclusion": "尽管顶级模型如Gemini-1.5-Pro展现了强大的任务分解能力，但在程序推理和空间理解方面仍逊于人类。不同游戏的表现差异显著，反映出交互复杂度的敏感性。少量示例的使用显著提高了模型的表现，这表明可以通过针对性增强来提升LLMs在VR操作中的能力。所有材料已对外公开。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.05860", "html_url": "https://arxiv.org/abs/2503.05860", "title": "软件工程中AI模型基准测试：一种审查工具和提升基准质量的统一方法", "title_en": "Benchmarking AI Models in Software Engineering: A Review, Search Tool, and Unified Approach for Elevating Benchmark Quality", "authors": "Roham Koohestani,Philippe de Bekker,Begüm Koç,Maliheh Izadi", "background": "基准是统一评估和可再现性的关键。人工智能在软件工程中的飞速发展产生了许多用于代码生成和错误修复等任务的基准。但这一发展也带来了挑战：知识碎片化、选择语境相关基准困难、基准创建缺乏标准化以及基准中的缺陷限制了其实用性。", "innovation": "文章提出了两种创新：一是系统地映射现有基准以进行有见地的选择；二是定义统一的指导原则，用于稳健、适应性基准的开发。文章还提出了BenchScout，一种可扩展的语义搜索工具，用于定位合适的基准，并通过BenchFrame提出了一种统一框架来提升基准质量。", "conclusion": "通过应用BenchFrame到HumanEval，得到了HumanEvalNext，其含有修正的错误、改进的语言转换、更高的测试覆盖率和更大的难度。通过对10种最新的代码模型在HumanEval、HumanEvalPlus和HumanEvalNext上的评估，显示了基准持续改进的必要性。此外，还通过一个有代理的管道验证了BenchFrame的可扩展性和MBPP数据集上的普遍适用性。所有审查数据、用户研究材料和改进后的基准均已公开。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.24428", "html_url": "https://arxiv.org/abs/2510.24428", "title": "CodeWiki:自动化大规模仓库级文档生成", "title_en": "CodeWiki: Automated Repository-Level Documentation at Scale", "authors": "Nguyen Hoang Anh,Minh Le-Anh,Bach Le,Nghi D.Q. Bui", "background": "开发者花费近58%的时间理解代码库，但保持全面文档由于复杂性和手动操作仍然具有挑战性。尽管最近的大规模语言模型（LLMs）在功能级别文档生成上取得了进展，但对于需要捕捉架构模式和跨模块交互的仓库级别仍然无法胜任。现有的维护文档方法难以满足复杂代码库的需求，导致维护文档工作耗时且不精确。因此，研究人员希望能够通过自动化工具来提高仓库级别文档的质量和准确度，以便更高效地维护和理解代码库。", "innovation": "CodeWiki是一个开源框架，用于七种编程语言的大规模仓库级文档生成。它包含三个创新点：(i) 分级拆解以保留架构上下文，(ii) 递归代理处理与动态委派相结合，(iii) 文本和可视化元素（如架构图和数据流）的综合。此外，还提出了一种名为CodeWikiBench的新基准，用于评估多级语法规则和代理评估的仓库级文档生成。", "conclusion": "CodeWiki在使用专有模型时达到了68.79%的质量得分，使用开源替代品时为64.80%，优于现有的封闭源代码系统，展示了其在真实世界代码库中实现可扩展和准确文档生成的能力。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2406.12196", "html_url": "https://arxiv.org/abs/2406.12196", "title": "基于上下文相似性的深度学习框架错误检测", "title_en": "CITADEL: Context Similarity Based Deep Learning Framework Bug Finding", "authors": "Xiaoyu Zhang,Juan Zhai,Shiqing Ma,Shiwei Wang,Chao Shen", "background": "随着深度学习技术的应用，需要深度学习框架测试工具，但现有测试工具对于性能错误的覆盖不足，且效率低下，生成大量测试案例但触发错误有限。因此需要提出一种加速错误发现的方法来提高效率和有效性。", "innovation": "提出了一种名为Citadel的方法，通过上下文相似性度量相似的深度学习框架API对，自动生成具有或有测试案例，可以有效检测深度学习框架中的API错误，特别是那些新的相似错误，如数量较多的性能错误，而现有工具无法检测这些错误。", "conclusion": "Citadel在PyTorch和TensorFlow中检测到58和66个API错误（排除开发人员拒绝和之前的报告重复），其中13个性能错误是现有工具无法检测的。并且，Citadel产生的测试案例中，有35.40%能触发比现有最好方法更早的错误。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.23169", "html_url": "https://arxiv.org/abs/2510.23169", "title": "MATCH: 通过对比学习驱动的任务代码评估", "title_en": "MATCH: Task-Driven Code Evaluation through Contrastive Learning", "authors": "Marah Ghoummaid,Vladimir Tchuiev,Ofek Glick,Michal Moshkovitz,Dotan Di Castro", "background": "随着AI生成代码的日益普及，GitHub Copilot据估计算法生成了GitHub上46%的代码。准确评估生成代码是否符合开发者意图仍然是一个关键挑战。传统方法如单元测试通常不可扩展且成本高，而语法相似性度量（如BLEU, ROUGE）和CodeBERTScore等度量则不能捕捉代码功能，并且后者需要参考代码，而这往往不可用。为了解决无参考评估的空白问题，MATCH因此提出了一种新的无参考度量方法，使用对比学习生成代码和自然语言任务描述的有意义嵌入，从而评估生成代码完成任务的效果。MATCH度量在跨多种编程语言的实证研究中显示出比现有度量更强的功能正确性和人类偏好相关性。", "innovation": "MATCH是一种新的无参考代码度量方法，通过对比学习生成代码和自然语言任务描述的有意义嵌入，用于评估生成代码的功能实现效果，解决了传统方法成本高和不适用于无参考场景的问题。MATCH度量在功能正确性和人类偏好方面展现出更强的相关性，适用于多种编程语言。", "conclusion": "MATCH度量模型通过对比学习生成了代码和自然语言任务描述的有意义嵌入，能够更好地评估生成代码是否符合任务要求，其在多种编程语言中的实证研究结果表明，MATCH比现有方法更有效地度量了代码的功能正确性和人类偏好。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.24483", "html_url": "https://arxiv.org/abs/2510.24483", "title": "神圣的软件工程喜剧——地狱：冲绳文件", "title_en": "The Divine Software Engineering Comedy -- Inferno: The Okinawa Files", "authors": "Michele Lanza", "background": "在2024年六月，我们在日本冲绳共同组织了一场名为‘FUture of Software Engineering’的研讨会。我和Andrian Marcus、Takashi Kobayashi、Shinpei Hayashi担任大会主席，Nicole Novielli、Kevin Moran、Yutaro Kashiwa、Masanari Kondo担任程序委员会主席，我的团队成员Carmen Armenti、Stefano Campanella、Roberto Minelli担任讨论组成员。研讨会围绕未来的软件工程进行了广泛讨论，最终变成了一个关于软件工程是否有未来的马拉松式的辩论。这次文章是对个人在该研讨会上所见所感的一种暗淡反思，充满了一定的讽刺和怀疑态度。", "innovation": "文章以极具讽刺和怀疑态度的方式探讨了未来的软件工程困境，提出了三个主要挑战：不了解自己所做工作但能够完成任务的软件开发者，一个发展迅速以至于无法记住自己经验的领域，以及技术发展像春天里兔子一样迅速繁衍。文章将未来的软件工程比作缓慢迫近的车祸，形象地描述了行业面临的复杂问题和不确定性。这为理解软件工程的未来发展提供了独特的视角和反思。", "conclusion": "未来的软件工程看起来就像一种缓慢逼近的车祸，你是能预见其到来的，但又无法避开。文章总结了软件工程在未来的发展将面临三个主要问题：缺乏专业知识的软件开发者、高速发展的领域难以积累经验，以及技术的快速增长。文章以这种方式探讨了未来软件工程的黑暗面，强调了行业面临的严峻挑战，旨在引起思想上的共鸣。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.05470", "html_url": "https://arxiv.org/abs/2503.05470", "title": "The Software Diversity Card: 一种在软件项目中报告多样性的框架", "title_en": "The Software Diversity Card: A Framework for Reporting Diversity in Software Projects", "authors": "Joan Giner-Miguelez,Sergio Morales,Sergio Cobos,Javier Luis Canovas Izquierdo,Robert Clariso,Jordi Cabot", "background": "近年来，软件开发中的多样性问题受到了广泛关注。报告软件项目的多样性信息可以增强用户信任，并帮助监管机构评估软件的采用情况。近年来，AI指令中包含了在开发过程中必须报告多样性的条款，凸显了公共监管机构对于多样性的兴趣。然而，当前的文档往往忽视了多样性，偏好技术特征，部分原因是缺乏描述和注释多样性的工具.", "innovation": "本文提出了软件多样性卡片（Software Diversity Card，SDC），这是一种结构化的记录和分享软件项目中与多样性相关方面的方法。SDC旨在描绘参与软件开发和治理的各种团队，包括测试中的用户群体和为不同社会群体设计的软件.", "conclusion": "我们的提议可以提升软件开发中的多样性实践，支持公共管理机构对软件的评估，并帮助企业将多样性视为关键资产。然而，实际应用中依然存在挑战，例如平衡匿名性和透明性、处理敏感数据以及确保信息的真实性."}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2408.09536", "html_url": "https://arxiv.org/abs/2408.09536", "title": "Galápagos: 使用大语言模型的自动化N-版本编程", "title_en": "Galapagos: Automated N-Version Programming with LLMs", "authors": "Javier Ron,Diogo Gaspar,Javier Cabrera-Arteaga,Benoit Baudry,Martin Monperrus", "background": "N-版本编程是一种广泛认可的开发容错系统的方案，通过增加多样冗余性程序，在运行时实现故障检测和纠正，以减小冗余程序变体的故障模式重叠。本文基于此背景介绍了N-版本编程的方法及其在提高系统可靠性方面的作用。", "innovation": "本文提出了一种新的自动化生成程序变体的方法，利用大型语言模型（LLMs）。设计并开发了Galápagos工具，该工具可以生成功能等效的程序变体，并通过静态分析和运行时行为分析验证它们。此外，Galápagos能够生成使用不同编程语言写的程序变体，表明这些生成的变体是功能等效的，但在编译后具有静态差异，运行时行为也会有所分歧。这些程序变体被证明能够保护C代码免受Clang编译器引发的实际错误影响。", "conclusion": "本文展示了通过高级实用形式验证和生成语言模型的应用，可以大幅自动化生成N-版本软件。"}
{"llm_update_time": "20251029", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2404.19735", "html_url": "https://arxiv.org/abs/2404.19735", "title": "ParaGrapher：大规模压缩图的选择性并行加载", "title_en": "Selective Parallel Loading of Large-Scale Compressed Graphs with ParaGrapher", "authors": "Mohsen Koohi Esfahani,Marco D'Antonio,Syed Ibtisam Tauhidi,Thai Son Mai,Hans Vandierendonck", "background": "在高性能图处理中，全面评价贡献变得更为可行。然而，每种框架都创建了其特定的数据格式，可能无法读取大规模的真实世界图数据集，这突显了对能够加载图的高性能库的需求，这些库旨在（i）加速新图算法的设计，（ii）在广泛的图算法上评估贡献，以及（iii）在不同的图框架之间进行简单、快速的比较。作为解决方案，介绍ParaGrapher，这是一种高性能API和库，用于加载大型和压缩的图，支持在共享内存、分布式内存和离线图处理中访问图的不同类型请求。我们的评估显示，对于WebGraph格式的压缩图，ParaGrapher比二进制和文本格式提高了加载速度最高3.2倍，以及端到端执行速度高达5.2倍（即加载和执行的交错过程）。", "innovation": "ParaGrapher提供了一种高性能的API和库，用于加载大型和压缩的图，支持在不同类型的内存访问上访问图，并通过加载和执行的交互过程，实现了高达端到端5.2倍的加快速度。特别地，通过将压缩的WebGraph格式的图解压缩，ParaGrapher在加载速度上最高可以提高3.2倍，以及在端到端执行中可以提高5.2倍的速度。", "conclusion": "ParaGrapher提供了一种有效的方法来促进高性能图处理中的全面评估。通过支持不同类型的数据访问请求，以及通过解压缩WebGraph格式的压缩图来提高加载和执行速度，ParaGrapher成为设计新图算法和评估不同图框架贡献的理想工具。"}
