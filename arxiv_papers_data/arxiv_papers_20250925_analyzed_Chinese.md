# 20250925
[![Subscribe_Visitors](https://visitor-badge.laobi.icu/badge?page_id=nituchao.latest_arxiv_analyze_ai_rss)](https://github.com/nituchao/latest_arxiv_analyze_ai)

## 1. `cs.AI` - 校准推理：一种动态高效问题解决的解释性验证器 [PDF](https://arxiv.org/pdf/2509.19681), [HTML](https://arxiv.org/abs/2509.19681)
### Authors
Anisha Garg,Engin Tekin,Yash More,David Bick,Nishit Neema,Ganesh Venkatesh
### Background
为了放大推理模型的能力，测试时的计算策略至关重要，但其效果受限于模型本身的自我评估能力不足。
### Innovation
提出了通过强化学习（GRPO）训练的成对标记验证器，该验证器生成校准后的置信分数和与生成解决方案相关的自然语言推理。这种验证器不仅提高了诸如最优-n和自我反思等测试时策略的准确性和效率，还能识别更复杂的失败模式，标准方法如多数投票在这些模式中失效。
### Conclusion
该验证器能够显著提高推理模型在测试时间策略中的应用效果，尤其是在处理复杂的失败模式方面表现出色。
## 2. `cs.AI` - 用户模拟在追求AGI中的不可或缺作用 [PDF](https://arxiv.org/pdf/2509.19456), [HTML](https://arxiv.org/abs/2509.19456)
### Authors
Krisztian Balog,ChengXiang Zhai
### Background
AGI的发展面临重大瓶颈，特别是难以严格评估复杂的交互系统以及获得大量交互数据用于训练适应性代理。该文强调用户模拟（即创造能模仿人类与AI系统交互的计算代理）对于克服这些瓶颈和加速AGI的发展至关重要。
### Innovation
研究表明，真实的模拟器提供了必要的环境来评估、生成交互学习所需的交互数据，并培养AGI的核心适应能力。因此，用户模拟技术的研究与智能任务代理的开发是紧密相关的，必须同步进行。
### Conclusion
文章详细阐述了用户模拟在AGI中的关键作用，探索了构建真实模拟器的跨学科性质，并指出了关键挑战，包括来自大规模语言模型的挑战，并提出了未来的研究议程。
## 3. `cs.AI` - SteinerSQL：图导向的数学推理在文本到SQL生成中的应用 [PDF](https://arxiv.org/pdf/2509.19623), [HTML](https://arxiv.org/abs/2509.19623)
### Authors
Xutao Mao,Tao Liu,Hongying Zan
### Background
大型语言模型（LLMs）在处理复杂的文本到SQL查询时表现出色，但这些查询通常需要复杂的数学推理和精细的模式导航。现有的方法常常孤立地解决这些问题，导致推理过程断裂，逻辑和结构正确性受到影响。
### Innovation
我们提出了SteinerSQL框架，它将这两个挑战统一为一个基于图的优化问题。SteinerSQL分为三个阶段：数学分解以识别所需的表（终端），通过Steiner树问题构建最佳推理架构，以及多级验证以确保正确性。
### Conclusion
在挑战性的LogicCat和Spider2.0-Lite基准测试中，SteinerSQL分别以36.10%和40.04%的执行精度达到了新的最先进的性能，使用了Gemini-2.5-Pro。除了准确性外，SteinerSQL还提供了一种新的统一体系结构，为复杂的推理任务提供了更稳健和原理化的解决方案。
## 4. `cs.AI` - 估计大型语言模型的一致性 [PDF](https://arxiv.org/pdf/2509.19489), [HTML](https://arxiv.org/abs/2509.19489)
### Authors
Robert Nowak
### Background
系统经常向大型语言模型（LLMs）重复相同的提示并聚合响应以提高可靠性。本文探讨了在固定计算预算 $B=mn$ 下估计LLMs的一致性估计量，并分析了这种估计方法下的权衡，其中 $m$ 是从任务分布中采样的提示数量，$n$ 是每个提示重复调用LLM的次数。
### Innovation
文章分析了一种估计LLMs一致性的方法，并讨论了在固定计算预算下的权衡。研究结果倾向于采用大致比例分配 $m,nbuildreltextstylerm rightarrowbuildreltextstylerm typestyletext{∝}buildreltextstylerm typestyletext{√}B$。
### Conclusion
研究结果表明，为了在固定计算预算下获得最优的LLMs一致性估计，提示数量与每次提示重复调用LLM的次数大致呈平方根比例。
## 5. `cs.AI` - 评价意识强化学习 [PDF](https://arxiv.org/pdf/2509.19464), [HTML](https://arxiv.org/abs/2509.19464)
### Authors
Shripad Vilasrao Deshmukh,Will Schwarzer,Scott Niekum
### Background
政策评估是安全和性能关键系统部署的先决条件。现有的评估方法通常因数据有限和长时间任务而导致高方差，或者因不平等支持或不准确的环境模型而导致高偏差。这些挑战部分来自标准强化学习（RL）范式的政策学习，没有对评估进行显式考虑。
### Innovation
本文提出了评价意识强化学习（EvA-RL），在该方法中，策略旨在最大化预期收益同时最小化预期评估误差，即被视为“易于评估”。理论分析和实验证明，在使用固定评估价值预测方案的情况下，评估准确性和策略性能之间通常存在权衡。因此，文章进一步提出了一种同时学习适应性评估条件状态值预测的方法，能够在不同评估环境中使用较少的卷积动作域进行精确评估，证明在不同动作域中，EvA-RL可以显著减少评估误差同时保持竞争力的回报。
### Conclusion
本文的工作为一类新的RL方法奠定了基础，这些方法在训练过程中将可靠的评估作为首要原则。
## 6. `cs.AI` - Nano Bio-Agents (NBA): 小型语言模型代理用于基因组学 [PDF](https://arxiv.org/pdf/2509.19566), [HTML](https://arxiv.org/abs/2509.19566)
### Authors
George Hong,Daniel Trejo Banos
### Background
研究人员调查了小型语言模型（参数少于100亿）在基因组学问答中的应用，以解决幻觉问题和计算成本挑战。该论文通过引入一个名为Nano Bio-Agent (NBA)的代理框架，该框架整合了任务分解、工具编排和API访问，利用现有的系统如NCBI和AlphaGenome，旨在提高模型在基因组学任务上的表现和效率。
### Innovation
论文提出了一种名为Nano Bio-Agent (NBA)的代理框架，将任务分解、工具编排和API访问整合到现有的基因组学系统中，通过使用小型语言模型（3-100亿参数）来提高基因组学问答的性能和效率。实验结果显示，小型模型在准确性和效率上优于使用更大模型的方法，尤其是在计算资源的利用上更少消耗。
### Conclusion
研究展示了小型语言模型在基因组学工具中的潜在优势，不仅在性能上与大型模型相当甚至更优，而且在计算成本上显著降低，有助于这些工具的普及和降低成本，同时保留了高度稳定和准确的表现。
## 7. `cs.AI` - 大型语言模型的认知负荷限制：多步骤推理的基准测试 [PDF](https://arxiv.org/pdf/2509.19517), [HTML](https://arxiv.org/abs/2509.19517)
### Authors
Sai Teja Reddy Adapala
### Background
大型语言模型（LLMs）在静态基准测试中的性能与其在动态、信息丰富的环境中的脆弱性之间存在关键差距。尽管模型在孤立任务中表现出色，但它们在认知负荷下的推理能力受到的限制仍不完全理解。本文的研究背景在于探讨这种认知负荷对大型语言模型性能的影响，并提出一种新的基准测试方法来系统地评估模型在多步骤推理任务中的表现。
### Innovation
本文引入了一个正式的认知计算负荷理论，指出与任务无关的信息（环境饱和）和任务切换产生的干扰（注意力残留）是导致性能下降的关键机制。同时，设计了交错认知评估（ICE）基准测试，通过系统地操纵这些负荷因素来评估模型在多步骤推理任务中的表现。这一创新在于提供了一种新的基准测试方法，并识别了认知负荷对模型性能的影响机制。
### Conclusion
研究结果表明，认知负荷是推理失败的关键因素之一，并支持在不确定性下幻觉是猜测的理论。本研究得出结论，动态、认知敏感的压力测试，如ICE基准测试，对于评估先进AI系统的真正弹性和安全性至关重要。
## 8. `cs.AI` - 基于VLM的步骤评估：除了最终目标，还要评估步骤 [PDF](https://arxiv.org/pdf/2509.19524), [HTML](https://arxiv.org/abs/2509.19524)
### Authors
Ramy ElMallah,Krish Chhajer,Chi-Guhn Lee
### Background
机器人学习论文通常只报告单一的二元成功率，这掩盖了机器人在多步骤操作任务中何处成功或失败的具体信息。本文指出，常规报告每一步的成功率（SR）量表是必要的，以便让政策的效果更加透明，从而让机器人在每一步具备什么能力、比如抓取或倾倒变得可见。作者提出了一种基于目标层级评估的蓝图（StepEval），该框架利用视觉-语言模型（VLM）评估从记录的图像或视频中获取的子目标结果，同时未提出新的基准或API，而是提供了一套可扩展的、社区驱动的开源项目设计原则。
### Innovation
介绍了StepEval框架，一个成本意识强烈的插件评估框架，利用视觉-语言模型作为自动评估记录图像或视频的子目标成果的工具。该框架旨在通过细粒度评价步骤的成功率（SR）来帮助社区优化评估效率和准确性，同时保证模型无关性强，支持单视图或多视图输入，并且实现足够轻量化，可以跨实验室广泛采用。这项贡献旨在提供一种共享的方向，使得步骤评估成为一项标准和可重复的实践。
### Conclusion
本文的目标是提供一个最小化且可扩展的开源项目种子，邀请开源贡献，以实现步骤评估而不是仅仅最终目标的得分成为一项标准和可重复的实践。
## 9. `cs.AI` - 你的基准究竟衡量了什么？一种鲁棒推断AI能力的框架 [PDF](https://arxiv.org/pdf/2509.19590), [HTML](https://arxiv.org/abs/2509.19590)
### Authors
Nathanael Jo,Ashia Wilson
### Background
目前，对生成模型在基准数据上的评估已经非常普遍，这类评估的结果极大地影响了公众和科学界对人工智能能力的期望。然而，越来越多的人对这种评估方法的可靠性表示怀疑。怎样才能确认报告的准确度确实反映了模型的真实性能？通常，评价结果被认为是简单的测量值，但实际上它们更像是推断过程：将基准得分视为能力的证据已经在假设一种关于能力和测试中表现形式的理论了。我们通过提出可靠的评估推断框架，使这一假设步骤变得明确：从一种关于能力的理论出发，进而推导出评估方法，这种方法在心理测量学领域中听说过，但在人工智能评估中并不常见。我们在基准可靠性问题中最主要的挑战——扰动敏感性上进行了探讨，并提出了能够考虑扰动不确定性和有限样本的方法，包括一个能够显著减少样本复杂性的自适应算法。这些贡献为基于基准衡量人工智能能力提供了更加可靠和值得信赖的评估基础。
### Innovation
本文提出了一个基于理论的评估框架，用以进行可靠的推断：首先进一步明确一种关于能力的理论假设，再随后引出相应的评估方法。这一步骤此前在心理测量学中有所了解，但在人工智能评价领域仍然是不常见的做法。文章还特别探讨了一个主要挑战，即对扰动的敏感性，并介绍了一系列能够考虑到这种不确定性以及有限样本数量的方法，其中包括一个能够大幅减少所需样本复杂性的新自适应算法。这些贡献共同为基于基准评估人工智能能力的可靠性提供了坚实的基座。
### Conclusion
本文提出的基于理论的评估框架能够实现更可靠和可信的人工智能能力评估。通过进一步明确评估方法中的理论假设，并提出能够考虑扰动不确定性和有限样本的新方法，这篇文章为基于基准的人工智能能力评估提供了更加稳固的研究基础。
## 10. `cs.AI` - 指挥者与引擎：迈向协同设计的推理路径 [PDF](https://arxiv.org/pdf/2509.19762), [HTML](https://arxiv.org/abs/2509.19762)
### Authors
Yuanxin Wang,Pawel Filipczuk,Anisha Garg,Amaan Dhada,Mohammad Hassanpour,David Bick,Ganesh Venkatesh
### Background
现代大模型（LLM）的推理依赖于大量的测试时计算，这些计算受到模型内部训练和外部代理协调驱动。然而，这种协同作用往往效率低下，因为模型的冗长和对指令的执行不佳导致了大量的计算浪费。
### Innovation
本文分析了能力成本权衡关系，并引入了一种优化的推理工作流程（textit{CEPO}），它可以赋能较小的开源模型，使其超越比其大很多倍的模型。这项工作将开源这种工作流程，以促进进一步的研究。
### Conclusion
我们展示了如何通过与底层模型能力协同设计协调框架来解锁中小型模型的强大推理能力。
## 11. `cs.AI` - 代理元认知：设计一个具有自我意识的低代码代理以进行故障预测和人工移交 [PDF](https://arxiv.org/pdf/2509.19783), [HTML](https://arxiv.org/abs/2509.19783)
### Authors
Jiexi Xu
### Background
自主代理固有的非确定性特别是在低代码/无代码（LCNC）环境中，带来了显著的可靠性挑战。这些代理可能会陷入未预见的循环中、产生不准确的输出或遇到不可恢复的失败，导致用户不满和信任度降低。
### Innovation
本文提出了一种新颖的架构模式来解决这些问题：通过引入第二个‘元认知’层，该层能够主动监控主LCNC代理。该元认知层受到人类反省的认知启发，通过特定的触发器（如延迟过高或重复动作）来预测即将发生的任务失败，并在预测失败后主动将处理过程交给人类，为用户提供详细的失败原因解释。
### Conclusion
原型系统的经验分析表明，这种方法可以显著提高整体任务的成功率。然而，这种性能的提升伴随着计算开销的显著增加。研究结果重新定义了人工移交，认为这是一种核心设计功能，能够提升系统韧性、改善用户体验并通过对代理内部状态的透明提供信任感。报告还讨论了这种方法的实用和伦理影响，并指出了未来研究的关键方向。
## 12. `cs.AI` - 带有对数障碍函数的近似线性规划解决马尔可夫决策问题的分析 [PDF](https://arxiv.org/pdf/2509.19800), [HTML](https://arxiv.org/abs/2509.19800)
### Authors
Donghwan Lee,Hyukjun Yang,Bum Geun Park
### Background
马尔可夫决策问题（MDPs）通常通过动态规划基于贝尔曼方程的方法或线性规划（LP）来解决。动态规划方法由于其广泛应用形成了经典和现代强化学习的基础。相比之下，基于线性规划的方法使用较少，但最近在离线强化学习等情境中重新受到关注。线性规划方法的应用受限于它转化为一个不等式约束优化问题，而这种问题在有效求解方面通常比基于贝尔曼方程的方法更具有挑战性。
### Innovation
本文的关键创新在于提出了利用广泛用于不等式约束优化的对数屏障函数，将MDPs的线性规划形式转化为无约束优化问题，从而使得通过梯度下降方法获得近似解变得容易。尽管该方法看似简单，但到目前为止，对这一方法的详尽理论解释尚未发展。本文旨在填补这一空白，建立一个有效的、实用的解决方案的理论基础。
### Conclusion
本文通过引入对数屏障函数的概念，解决了基于线性规划的马尔可夫决策问题的有效求解问题。利用对数屏障函数，将线性规划问题转化为无约束优化问题，使得通过梯度下降法容易得到近似解。这一新的方法具有一定的理论和应用价值，在离线强化学习等领域有潜在应用前景。
## 13. `cs.AI` - UserRL: 使用强化学习训练交互式用户中心代理 [PDF](https://arxiv.org/pdf/2509.19736), [HTML](https://arxiv.org/abs/2509.19736)
### Authors
Cheng Qian,Zuxin Liu,Akshara Prabhakar,Jielin Qiu,Zhiwei Liu,Haolin Chen,Shirley Kokane,Heng Ji,Weiran Yao,Shelby Heinecke,Silvio Savarese,Caiming Xiong,Huan Wang
### Background
强化学习（RL）在训练能够进行动态多轮交互的代理模型方面表现出潜力，而不仅仅是静态基准。然而，这类代理模型的最终价值在于它们是否能够有效地帮助用户。在用户交互多样且动态的环境下，这些代理模型面临着挑战。
### Innovation
提出了UserRL，这是一个统一的框架，通过标准化的 gym 环境和模拟用户训练和评估用户中心的能力。系统地变化了回合级奖励分配和轨迹级得分计算，以分析不同的表述如何影响 GRPO 算法下的学习效果。实验结果揭示了三个关键发现：（i）法则细化（SFT）的冷启动是解锁初始交互能力和促进持续的RL改进的关键；（ii）有目的地计算轨迹得分能够更有效和有效地进行多轮交互；（iii）尽管较强的模拟用户（如GPT-4o）有利于训练，开源模拟器（如Qwen3-32B）仍然是成本效益高且可转移的选择。
### Conclusion
这些结果强调了精心设计奖励塑造和用户模拟选择与模型规模同样重要，并为开发稳健的用户中心代理模型奠定了实际途径。所有代码和数据均已公开用于未来研究。
## 14. `cs.AI` - 正式验证极小极大算法 [PDF](https://arxiv.org/pdf/2509.20138), [HTML](https://arxiv.org/abs/2509.20138)
### Authors
Wieger Wesselink,Kees Huizing,Huub van de Wetering
### Background
本文使用Dafny验证系统对极小极大搜索算法的各种变体进行了形式验证，包括带有alpha-beta剪枝和置换表的变体。对于有限深度搜索和置换表，引入了一种基于见证者的正确性标准，并应用于两个代表性算法。
### Innovation
引入了基于见证者的正确性标准，并将其应用于带有置换表的有限深度搜索算法，这是本文的一个创新点。
### Conclusion
所有验证成果，包括证明和Python实现，均已公开可获取。
## 15. `cs.AI` - PEPS: 量子启发的强化学习在LLMs中实现连贯性推理路径 [PDF](https://arxiv.org/pdf/2509.20105), [HTML](https://arxiv.org/abs/2509.20105)
### Authors
Venkat Margapuri,Garik Kazanjian,Naren Kosaraju
### Background
大型语言模型（LLMs）往往难以保持连贯的多步骤推理追踪，特别是在需要结构化逻辑流程的任务中。传统方法如直接监督或对比目标无法有效解决这一挑战。
### Innovation
本文提出了一种基于投影纠缠对态（PEPS）的保真度奖励的量子启发式方法，结合到近端策略优化中。这种方法通过结构一致性指导学习，提供了一种强化全局连贯性的新途径，与之前的直接监督或对比目标方法不同。
### Conclusion
所提出的框架在GSM8K、StrategyQA和EntailmentBank等多样数据集上使用多个连贯性指标进行评估，结果表明，量子启发式方法显著优于监督学习、对比目标和预训练基线方法，突显了量子启发式保真度作为LLMs推理路径连贯性的基础的有效性。
## 16. `cs.AI` - 通过测试时偏好对齐实现可操控的对抗情景生成 [PDF](https://arxiv.org/pdf/2509.20102), [HTML](https://arxiv.org/abs/2509.20102)
### Authors
Tong Nie,Yuewen Mei,Yihong Tang,Junlin He,Jie Sun,Haotian Shi,Wei Ma,Jian Sun
### Background
现有的对抗情景生成方法通常受到单个、固定的算法目标之间权衡的限制，例如对抗性和现实性，导致行为特定的模型缺乏在推理阶段进行调整的能力，影响多样化的训练和测试需求的效率和灵活性。
### Innovation
本文重新定义了对抗情景生成任务为一个多目标偏好对齐问题，并引入了一个新的框架——可操控对抗情景生成器（SAGE）。SAGE能够在推理阶段对对抗性和现实性之间的权衡进行细粒度的控制，而无需重新训练。通过分层组基偏好优化，SAGE实现了一种数据高效的方法来平衡竞争目标，而不解耦硬可行性约束和软偏好。推理时，SAGE通过线性插值专家的权重来构建连续的策略谱系，提供了一个理论分析，通过线性模式可连通性来证明该框架的有效性。
### Conclusion
通过广泛的实验，SAGE能够生成具有更好对抗性和现实性平衡的场景，并且能够有效提升驾驶策略的闭环训练效果。
## 17. `cs.AI` - LatentGuard：受控潜在空间引导以实现稳健的拒绝攻击和可靠的响应生成 [PDF](https://arxiv.org/pdf/2509.19839), [HTML](https://arxiv.org/abs/2509.19839)
### Authors
Huizhen Shu,Xuying Li,Zhuo Li
### Background
在大型语言模型（LLMs）中实现稳健的安全对齐同时保留其效用仍然是一个基本的挑战。现有的方法往往难以在全面的安全性和细粒度的表示级可控性之间找到平衡。
### Innovation
我们提出了LATENTGUARD，这是一种新颖的三阶段框架，将行为对齐与监督潜在空间控制相结合，实现可解释和精确的安全引导。通过精细调整LLM在理性的数据集上，包括增强推理的拒绝响应以及增强推理的正常响应，建立全面的行为先验。然后，对中间MLP激活训练结构化的变分自动编码器（VAE），并由多标签注释（包括攻击类型、攻击方法和良性指示剂）监督。这种监督使VAE能够学习非纠缠的表示，捕捉不同的攻击特性同时保持语义解释性。通过针对学习的潜在维度的操作，LATENTGUARD实现了选择性地拒绝行为，有效地阻止有害请求，同时保留合法用例中的实用性。实验表明，该方法在Qwen3-8B上显著提高了安全可控性和响应解释性。跨架构验证在Mistral-7B上证明了潜在引导方法的泛化性，展示了在不同模型家族中的一致有效性。研究表明，结构化的表示级干预为构建更加安全但又实用的LLM系统提供了一条有希望的道路。
### Conclusion
实验结果表明，LATENTGUARD在Qwen3-8B上显著提高了安全可控性和响应解释性，同时在Mistral-7B的跨架构验证中也显示了一致的有效性。该研究提出的方法为构建更加安全实用的LLM系统提供了新的路径。
## 18. `cs.AI` - 沉浸式人工智能：从大型语言模型到世界模型 [PDF](https://arxiv.org/pdf/2509.20021), [HTML](https://arxiv.org/abs/2509.20021)
### Authors
Tongtong Feng,Xin Wang,Yu-Gang Jiang,Wenwu Zhu
### Background
论文背景介绍了沉浸式人工智能（Embodied AI）作为实现通用人工智能（AGI）的一种智能系统范式，其在各类应用中起到基础支撑作用，并推动从虚拟空间到物理系统的进化。近期，大型语言模型（LLMs）和世界模型（WMs）的突破吸引了对沉浸式AI的广泛关注。LLMs通过语义推理和任务分解，增强了沉浸式AI的认知能力，使高阶自然语言指令和低阶自然语言动作得以实现。WMs则通过构建对外部世界的内部表征和未来预测，促进了物理守则下的交互。
### Innovation
本文全面探讨了沉浸式AI的文献，从基础到最新进展，涵盖了LLMs驱动和WMs驱动的工作。具体来说，本文首先介绍了沉浸式AI的历史、核心技术、关键组件及硬件系统，并从单模态到多模态的角度讨论了其发展。然后深入分析了两个新兴领域——LLMs/多模态LLMs（MLLMs）驱动的沉浸式AI和WMs驱动的沉浸式AI，在端到端的沉浸式认知和物理守则驱动的交互中强调其不可或缺的角色。进一步探讨了联合MLLM-WM驱动的沉浸式AI架构的必要性，揭示其在物理世界中完成复杂任务的深远意义。此外，还展示了沉浸式AI的应用案例，并指出了值得进一步研究的未来研究方向。
### Conclusion
本文总结了沉浸式AI在从物理系统发展到更广泛的应用场景中的先进研究，强调了联合大型语言模型和世界模型在实现复杂任务方面的巨大潜力，并提出了进一步的研究方向。
## 19. `cs.AI` - MACD: 多智能体临床诊断——利用自学习知识的LLM [PDF](https://arxiv.org/pdf/2509.20067), [HTML](https://arxiv.org/abs/2509.20067)
### Authors
Wenliang Li,Rui Yan,Xu Zhang,Li Chen,Hongji Zhu,Jing Zhao,Junjun Li,Mengru Li,Wei Cao,Zihang Jiang,Wei Wei,Kun Zhang,Shaohua Kevin Zhou
### Background
大型语言模型（LLMs）在医疗应用中表现出显著的潜力，但它们在处理复杂的临床诊断时仍面临重大挑战，尤其是在使用传统的提示方法时。当前的提示工程和多智能体方法通常优化独立的推理过程，忽视了可重用的临床经验的累积。这一研究提出了一个名为Multi-Agent Clinical Diagnosis (MACD) 的新框架，以解决上述问题。MACD框架通过一个多智能体管道自学习临床知识，总结、提炼并应用于诊断洞察。该框架模仿了医生通过经验发展专业知识的过程，从而使与特定疾病相关的关键诊断线索更加集中和准确。
### Innovation
该研究提出了一个名为Multi-Agent Clinical Diagnosis (MACD) 的新框架，通过一个多智能体管道自学习临床知识，总结、提炼并应用于诊断洞察。还进一步将其扩展到MACD-人协作的工作流中，其中多个基于LLM的诊断智能体进行迭代咨询，由评估智能体和人工监督提供支持，特别是在无法达成一致意见时。该框架在多个疾病的真实世界患者案例上进行了评估，使用了多种不同的开源LLM（Llama-3.1 8B/70B，DeepSeek-R1-Distill-Llama 70B），显著提高了主要诊断的准确性，超过了现有的临床指南，改善幅度高达22.3%（MACD）。此外，它在小数据集上达到了或超过了人类医生的表现（高达16%的改善）。在MACD-人工作流中，与其他只有医生诊断的情况相比，它实现了18.6%的改善。并且自学习知识显示出了强大的跨模型稳定性和可转移性，同时系统还可以生成可追踪的理由，提升了可解释性。
### Conclusion
这一研究展示了一种基于LLM辅助的诊断的可扩展的自学习范式，使得LLM内在的知识与现实世界临床实践之间的差距得以弥合，提供了一种利用自学习知识的多智能体临床诊断方法。
## 20. `cs.AI` - Scan-do Attitude: Towards Autonomous CT Protocol Management using a Large Language Model Agent [PDF](https://arxiv.org/pdf/2509.20270), [HTML](https://arxiv.org/abs/2509.20270)
### Authors
Xingjian Kang,Linda Vorberg,Andreas Maier,Alexander Katzmann,Oliver Taubmann
### Background
CT扫描协议管理既繁琐又需要临床和技术专家的经验，同时，放射科技术人才的短缺加剧了这一问题。
### Innovation
提出了一种基于大型语言模型（LLM）的代理框架，旨在帮助自然语言或结构化、设备无关格式下的协议配置请求的解释与执行，以提高工作效率并减轻技术人员的工作负担。
### Conclusion
尽管在原则上展示了可行性，但该方法受限于缺乏统一的设备API以及面对含糊或复杂的请求时存在挑战。研究结果表明，基于LLM的代理在CT成像扫描协议管理方向上具有明确的发展路径。
## 21. `cs.AI` - Federation of Agents: 多智能体的语义感知通信架构 [PDF](https://arxiv.org/pdf/2509.20175), [HTML](https://arxiv.org/abs/2509.20175)
### Authors
Lorenzo Giusti,Ole Anton Werner,Riccardo Taiello,Matilde Carvalho Costa,Emre Tosun,Andrea Protani,Marc Molina,Rodrigo Lopes de Almeida,Paolo Cacace,Diogo Reis Santos,Luigi Serio
### Background
该论文提出了一个分布式编排框架——Federation of Agents（FoA），它将静态的多智能体协调转变为动态的、能力驱动的合作。FoA引入了Versioned Capability Vectors（VCVs），一种机器可读的智能体能力描述文件，通过语义嵌入使得智能体的能力可以被搜索，这使得智能体能够宣传自己的能力、成本和限制。
### Innovation
FoA的核心创新包括三个方面：（1）语义路由，能够在分割的HNSW索引上匹配任务到智能体，并通过成本偏向优化来实施运营约束；（2）动态任务分解，允许兼容的智能体通过共识合并将复杂任务分解为子任务的DAG；（3）智能集群，在仿真学习前将执行相似子任务的智能体分组到协作渠道中进行多轮精炼。FoA基于MQTT的发布/订阅语义实现分布式消息传递，通过层次化的能力匹配和高效的索引维护实现子线性复杂度。
### Conclusion
在HealthBench上的评估表明，与单一模型基准相比，FoA提高了13倍的表现，尤其是在需要多视角复杂推理的任务中通过集群增强协作尤为有效。系统能够水平扩展并在保持稳定性能的同时证明了语义编排和结构化协作可以解锁异构智能体联邦的集体智能。
## 22. `cs.AI` - Wavelet Fourier Diffuser: 频率意识扩散模型在强化学习中的应用 [PDF](https://arxiv.org/pdf/2509.19305), [HTML](https://arxiv.org/abs/2509.19305)
### Authors
Yifu Luo,Yongzhe Chang,Xueqian Wang
### Background
扩散概率模型在离线强化学习中通过直接建模轨迹序列显示出显著潜力。然而，现有的方法主要侧重于时间域特征，而忽略了频率域特征，导致频率偏移和性能下降等问题。本文从频率域的新角度分析强化学习问题，发现仅依赖于时间域的方法会无意中引入低频成分的偏移，导致轨迹不稳定和性能下降。
### Innovation
本文提出了Wavelet Fourier Diffuser (WFDiffuser)，这是一种新颖的基于扩散的强化学习框架，将离散小波变换用于分解轨迹为低频和高频成分。WFDiffuser利用短时傅里叶变换和交叉注意力机制来提取频率域特征并促进跨频率的交互，从而增强每个成分的扩散建模能力。
### Conclusion
通过在D4RL基准上的广泛实验结果表明，WFDiffuser能有效缓解频率偏移，使轨迹更加平滑稳定，并且决策性能优于现有方法。
## 23. `cs.AI` - 异构无线网络中基础模型的联邦微调范式 [PDF](https://arxiv.org/pdf/2509.19306), [HTML](https://arxiv.org/abs/2509.19306)
### Authors
Jingyi Wang,Zhongyuan Zhao,Qingtian Wang,Zexu Li,Yue Wang,Tony Q. S. Quek
### Background
边缘智能作为一种提供低延迟和泛在服务的策略，已经引起了移动设备的关注。近期低秩适应（LoRA）与联邦学习的集成为边缘智能带来了可能性。然而，在无线网络中，设备异构性和边缘设备的资源限制对联邦微调的性能构成了巨大威胁。为解决这些问题，本文通过在线学习优化了异构无线网络中的联邦微调框架。
### Innovation
论文提出了一种在异构无线网络中基于切换的联邦微调框架。通过动态将边缘设备切换到LoRA模块以与基站协同进行联邦微调，共同减轻设备异构性和传输可靠性的影响。此外，通过理论分析和优化算法，提出了一个非凸混合整数规划问题，并将其分解为模型切换、发射功率控制和带宽分配子问题，从而提高了泛化能力并保证了计算复杂度和执行效率。
### Conclusion
仿真结果表明，在测试准确性和能量效率方面，本文提出的框架获得了性能提升。
## 24. `cs.AI` - LLMs作为Solidity的形式验证 oracle [PDF](https://arxiv.org/pdf/2509.19153), [HTML](https://arxiv.org/abs/2509.19153)
### Authors
Massimo Bartoletti,Enrico Lipparini,Livio Pompianu
### Background
智能合约的正确性至关重要，细微的错误可能导致严重的经济损失。虽然可以检测常见漏洞模式的工具能起到防御作用，但现实中的很多漏洞和损失源于合约业务逻辑中的错误。虽然形式验证工具如 SolCMC 和 Certora Prover 能解决这一挑战，但由于这些工具的学习曲线陡峭和限制性的规范语言，其影响受到了限制。最近的研究开始探索使用大型语言模型（LLMs）来处理安全相关的任务，如漏洞检测和测试生成。但是，一个基础问题依然存在：LLMs能否作为验证 oracle，能够对任意特定合约属性进行推理？
### Innovation
本文首次系统性评估了作为验证 oracle 的 GPT-5，这是一种最先进的推理 LLM。本文在大规模形式验证任务数据集上测试其性能，将其输出与现有形式验证工具的输出进行比较，并评估其在实际审计场景中的实用性。研究表明，近年来的推理导向的 LLM 可以出乎意料地作为有效的验证 oracle，开启了 AI 和形式方法结合以确保智能合约开发和审计安全的新前沿。
### Conclusion
本文展示了基于 LLM 的形式验证 oracle 是可行的，指出它们可以在智能合约安全开发和审计中发挥重要作用。
## 25. `cs.AI` - CON-QA: 使用云LLM保护合同领域隐私的问答系统 [PDF](https://arxiv.org/pdf/2509.19925), [HTML](https://arxiv.org/abs/2509.19925)
### Authors
Ajeet Kumar Singh,Rajsabi Surya,Anurag Tripathi,Santanu Choudhury,Sudhir Bisane
### Background
企业越来越多地将云基础上的大语言模型，如ChatGPT和Gemini，整合到其法律文件工作流程中，保护敏感合同信息（包括个人信息识别信息（PII）和商业敏感条款）已成为一个关键的挑战。
### Innovation
提出了一种名为CON-QA的混合隐私保护框架，专门用于企业合同的保护性问题回答，有效地结合了本地和云托管的大语言模型。CON-QA分为三个阶段： (i) 语义查询分解和查询感知文档片段检索； (ii) 通过结构化的一对多映射方案匿名化检测到的敏感实体，确保语义连贯性并防止会话间的实体推断攻击； (iii) 使用云托管的大语言模型生成匿名化回复，通过会话一致的一对多反向映射准确重建原始答案。为了严格评估CON-QA，引入了CUAD-QA数据集，包含来自510份真实合同文档的85000个问答对，涵盖简单、复杂和总结式查询。
### Conclusion
实证分析和详细的人类评估表明，CON-QA有效地维护了隐私和实用性，保持了答案质量，保持了法律条款语义的一致性，并显著降低了隐私风险，证明了其在安全的企业级合同文件中的实用性。
## 26. `cs.AI` - 从信息素到策略：工程化生物游群中的强化学习 [PDF](https://arxiv.org/pdf/2509.20095), [HTML](https://arxiv.org/abs/2509.20095)
### Authors
Aymeric Vellinger,Nemanja Antonic,Elio Tuci
### Background
游群智能源于简单代理之间的去中心化交互，能够实现集体问题解决。本文探讨了秀丽隐杆线虫（⳦⳦）信息素介导的聚集与强化学习（RL）之间的理论等效性，揭示了标记信号作为分布式奖励机制的功能。
### Innovation
研究通过模型化工程制造的秀丽隐杆线虫游群执行觅食任务，展示了信息素动态如何数学上反映跨学习更新，这是基本的RL算法。实验验证数据表明，在静态条件下，模型准确地重现了文献中的秀丽隐杆线虫觅食模式。在动态环境中，持久的信息素轨迹会形成正反馈循环，阻止适应，使游群困在过时的选择中。通过多臂老虎机场景的计算实验，研究揭示了引入对信息素不敏感的少数探索性代理能够恢复集体可塑性，实现任务快速切换。这种行为异质性平衡了探索-利用权衡，实现了群体层面淘汰过时策略。
### Conclusion
结果表明，标记系统本质上编码分布式RL过程，其中环境信号作为集体信用分配的外部记忆。通过将合成生物学与游群机器人学结合起来，这项工作推进了能够在动荡环境中实现稳健决策的可编程生物系统。
## 27. `cs.AI` - 基于硬件的协作感知架构在车道变更预测中的设计见解和比较评估 [PDF](https://arxiv.org/pdf/2509.20218), [HTML](https://arxiv.org/abs/2509.20218)
### Authors
Mohamed Manzour,Catherine M. Elias,Omar M. Shehata,Rubén Izquierdo,Miguel Ángel Sotelo
### Background
车道变更预测的研究在过去几年中引起了广泛关注。大部分现有研究是在仿真环境中或使用预录制数据集进行的，这些研究通常基于关于感知、通信和交通行为的简化假设，这些假设在实际中并不总是成立。实际部署的车道变更预测系统相对罕见，当有报道时，实际挑战、限制和经验教训往往记录不足。
### Innovation
该研究通过在混合交通中进行实际硬件部署探索合作车道变更预测，并分享实施和测试中获得的见解。特别强调了我们面临的实际挑战，包括瓶颈、可靠性问题和操作约束，这些因素影响了系统的运行。通过记录这些经验，研究为其他从事类似工作的人提供了指导。
### Conclusion
研究通过实际硬件部署和系统行为了解的记录，为其他从事协作感知架构的人提供了有用的设计见解和实践经验。
## 28. `cs.AI` - 使用大型语言模型的自动化项目中和：降低社会期望偏差的方法 [PDF](https://arxiv.org/pdf/2509.19314), [HTML](https://arxiv.org/abs/2509.19314)
### Authors
Sirui Wu,Daijin Yang
### Background
本研究评估了大型语言模型（LLM）辅助项目中和对人格评估中社会期望偏差的减少效果。研究者使用GPT-o3对国际人格项目库五大人格维度测量表（IPIP-BFM-50）进行重写，并让203名参与者完成原始和中和版本的测量以及马洛-克罗恩社会期望量表。背景信息强调了社会期望偏差在人格评估中的影响，以及现有方法的限制。
### Innovation
研究使用了大型语言模型（LLM）辅助的自动化项目中和方法，对国际人格项目库五大人格维度测量表进行了重写，这是利用AI技术的一种创新性方法来降低社会期望偏差。这一方法相较于传统的半自动过程更加高效和系统化，能够潜在地提高评估的准确性。
### Conclusion
结果表明，虽然社会期望偏差在某些项目上有所减少，但整体可靠性得以保留，五因素结构仍保持一致，不过度量不变性和量表不变性未能成立。研究结论支持AI中和作为一种潜在但不完美的偏差减少方法，表明在未完全验证其有效性和可靠性之前，这种方法尚需进一步完善。
## 29. `cs.AI` - Readme_AI: Dynamic Context Construction for Large Language Models [PDF](https://arxiv.org/pdf/2509.19322), [HTML](https://arxiv.org/abs/2509.19322)
### Authors
Millie Vyas,Timothy Blattner,Alden Dima
### Background
尽管大型语言模型（LLMs）在训练过程中使用了大量的数据，但在处理用户特定查询时仍可能提供不准确或不可靠的信息。特定查询的上下文环境可以显著提升LLM的响应质量。
### Innovation
提出了一种规格，用于动态构建数据源的上下文。该规格允许数据源的所有者创建包含元数据的文件，供LLM在处理数据集相关的查询时使用。该规格具有可扩展的类型，能代表数据抓取、数据仓库数据提取、科学论文下载和解析，以及通用文本。上下文通过用户指定的标签进行格式化和分组，为LLM提供清晰的语境信息，使其能准确推理相关的查询内容。此外，还展示了该规格的原型Readme_AI Model Context Protocol（MCP）服务器，能够从数据源中检索元数据并动态构建上下文。
### Conclusion
该研究的主要贡献是一种用于动态将LLM与特定所有者提供的数据绑定的可扩展协议，这不仅提高了LLM响应的质量，还减少了幻觉的出现。通过使用Readme_AI，LLM能够准确推理Hedgehog库及其用法，并生成来自Readme_AI文件中提供的示例代码插值生成的代码。Readme_AI的源代码已在此处发布：[此链接](this https URL)。
## 30. `cs.AI` - GAUSS：大型语言模型结构化数学技能评估基准 [PDF](https://arxiv.org/pdf/2509.18122), [HTML](https://arxiv.org/abs/2509.18122)
### Authors
Yue Zhang,Jiaxin Zhang,Qiuyu Ren,Tahsin Saffat,Xiaoxuan Liu,Zitong Yang,Banghua Zhu,Yi Ma
### Background
当前，对大型语言模型（LLMs）的数学能力评估主要依赖于单一维度的测试，缺乏全面评估其核心数学技能的能力。为此，本文提出了一种名为GAUSS的新基准（General Assessment of Underlying Structured Skills in Mathematics），旨在从十二个核心技能维度对模型进行全面评估，这些维度被分为知识和理解、问题解决和沟通、以及元技能和创造力三大领域。
### Innovation
GAUSS基准创新之处在于通过根据认知技能对问题进行分类，并设计能够分离出特定能力的任务，构建了全面、细粒度且可解释的模型数学能力画像。这一基准能够真实反映模型背后所具备的数学智能。通过使用GAUSS基准对GPT-5-thinking和o4-mini-high进行技能画像分析，展示了其优势、劣势及其差异性，从而突显了基于多维度技能评估的价值。
### Conclusion
GAUSS基准为评估大型语言模型的数学技能提供了一个新的工具，通过全面、细粒度的方法可以最为真实地展现模型的数学智能。这一方法不仅帮助识别模型的优势和不足，而且还可以促进模型开发中对数学技能的重视，进而推动大型语言模型整体能力的提升。
## 31. `cs.AI` - FHIR-AgentBench：面向现实互用型EHR问题回答的LLM代理基准测试 [PDF](https://arxiv.org/pdf/2509.19319), [HTML](https://arxiv.org/abs/2509.19319)
### Authors
Gyubok Lee,Elea Bach,Eric Yang,Tom Pollard,Alistair Johnson,Edward Choi,Yugang jia,Jong Ha Lee
### Background
当前，Health Level Seven Fast Healthcare Interoperability Resources (HL7 FHIR)标准的普及为临床AI带来了新的机遇，要求大语言模型（LLM）代理能够处理复杂、基于资源的数据模型，而非传统的结构化健康数据。然而，现有的基准测试落后于这一转变，难以评估最近的LLM在互操作性临床数据上的表现。为桥接这一差距，本研究引入了FHIR-AgentBench基准测试，其基于2,931个真实的临床问题来评估HL7 FHIR标准。该基准测试系统研究了不同数据检索策略（直接FHIR API调用 vs. 专门工具）、交互模式（单轮 vs. 多轮）以及推理策略（自然语言 vs. 代码生成）的表现，突显了从繁琐的FHIR资源中检索数据及在其上进行推理的实际挑战，这些挑战对问题回答性能有直接影响。
### Innovation
本研究引入了FHIR-AgentBench，这是首个专门针对互操作性健康记录基准测试的评估框架，结合了现实世界中的临床问题以及HL7 FHIR标准。该基准测试评估了代理框架在不同数据检索策略、交互模式以及推理策略下的表现，促进推动了在现实互用型EHR问题回答领域的LLM研究与发展。
### Conclusion
本研究通过FHIR-AgentBench模拟了获取和理解复杂FHIR资源的挑战，强调了实际问题中的挑战，并首次公开提供这个用于研究的基准测试平台及数据集，以促进可重复研究和提高临床应用中LLM代理的可靠性和鲁棒性。
## 32. `cs.AI` - LibEMER: 一个用于基于EEG的多模态情感识别的标准规范和算法库 [PDF](https://arxiv.org/pdf/2509.19330), [HTML](https://arxiv.org/abs/2509.19330)
### Authors
Zejun Liu,Yunshan Chen,Chengxi Xie,Huan Liu
### Background
基于EEG的多模态情感识别(EMER)引起了广泛关注并取得了显著进展，但由于人类神经系统的复杂性，该领域目前存在三大关键挑战：缺乏开源实现、缺乏标准化和透明的基准以及关于主要挑战和有希望的研究方向的深入讨论不足。
### Innovation
本研究引入了LibEMER，这是一个统一的评估框架，提供了深学习方法的全面可再现的PyTorch实现，以及标准化的数据预处理、模型建立和实验设置的协议。该框架可在三个广泛应用的公开数据集上对两种学习任务进行公平的性能评估。这一开源库可以在提供给公众使用。
### Conclusion
LibEMER为多模态情感识别领域提供了一个新的标准基准和算法库，有助于促进该领域的发展和研究，提高研究的可重复性和透明度。
## 33. `cs.AI` - 仅基于心电图数据的人类活动识别 [PDF](https://arxiv.org/pdf/2509.19328), [HTML](https://arxiv.org/abs/2509.19328)
### Authors
Sina Montazeri,Waltenegus Dargie,Yunhe Feng,Kewei Sha
### Background
人类活动识别在早起干预和健康管理等应用中至关重要。传统方法依赖于加速度计测量单元（IMUs），资源密集且需要校准。虽然心电图（ECG）方法已被探索，但在过去一般作为IMUs的补充手段，并局限于跌倒检测或日常活动中的静止状态与活动状态分类等粗略分类任务。
### Innovation
本文通过首次实现仅基于ECG的心电图数据对六种不同活动的健壯识别，推进了该领域的研究进步。文章设计并评估了三种新的深度学习模型：包含Squeeze-and-Excitation块的CNN分类器用于通道特征重塑，Dilated Convolution残差网络分类器用于多尺度时序依赖性捕捉，以及一种新的CNNTransformer混合模型，结合卷积特征提取与注意力机制，实现长时序关系建模。实验结果显示，三种模型在54个不同主体的六种活动中，对已见主体的准确率均超94%，而CNNTransformer混合模型在未见主体上的准确率达到72%，该结果可通过增加训练群体进一步提升。
### Conclusion
该研究展示了首个成功的仅基于ECG的心电图数据的多物理活动分类，为开发可同时进行心电监测和活动识别的下一代可穿戴设备提供了重要的潜在方向。
## 34. `cs.AI` - 面向多模态语义非正交传输和融合的端到端学习大规模MIMO [PDF](https://arxiv.org/pdf/2509.19312), [HTML](https://arxiv.org/abs/2509.19312)
### Authors
Minghui Wu,Zhen Gao
### Background
大规模多输入多输出（MIMO）虽然能够提供高频谱效率，但也导致了高维度的下行链路信道状态信息（CSI），这增加了实时信道获取和预编码的复杂性。
### Innovation
提出了一种端到端（E2E）上行-下行CSI融合预编码网络，该网络在一个单一的E2E神经架构中联合建模了下行链路CSI参考信号（CSI-RS）设计、CSI反馈和基站（BS）预编码。具体来说，一个基于MAXIM架构的投影网络以上行探测参考信号（SRS）作为输入，并输出用于设计下行CSI-RS的频率、波束和端口域投影矩阵。用户设备（UE）随后压缩/量化结果的CSI-RS观测，并反馈一个紧凑表示。在基站（BS），两个互补分支生成候选预编码器：一个是仅通过量化下行链路观测的反馈预编码网络，另一个是仅通过上行SRS的SRS预编码网络。这些候选预编码器随后由融合预编码网络组合，以产生最终的传输预编码器。所有模块在三次阶段调度下使用谱效导向的损失进行训练。
### Conclusion
仿真结果表明，所提出的方法能够有效利用SRS衍生的信息和UE反馈，超越传统基线方法实现显著的性能提升。
## 35. `cs.AI` - 自动科学论文评审生成中LLMs的优缺点揭开 [PDF](https://arxiv.org/pdf/2509.19326), [HTML](https://arxiv.org/abs/2509.19326)
### Authors
Ruochi Li,Haoxuan Zhang,Edward Gehringer,Ting Xiao,Junhua Ding,Haihua Chen
### Background
科学研究投稿的激增给传统的同行评审过程带来了压力，促使人们探索使用大型语言模型（LLMs）进行自动评审摘要生成。尽管LLMs在生成结构化和连贯反馈方面表现出色，但在批判性推理、情境关联性和质量敏感性方面的能力仍然有限。为了系统评估这些方面，该研究提出了一种结合语义相似性分析和结构化知识图谱度量的综合评估框架，以评估LLMs生成的评审与人类撰写的评审之间的差异。研究还对比了5种不同的LLMs在多个年份和会议上生成的评审，从而发现LLMs在描述性内容和肯定性方面表现良好，尤其是在捕捉原始工作的主要贡献和方法方面。然而，它们在识别弱点、提出实质性问题和根据论文质量调整反馈方面表现不佳。总体而言，这些结果为理解LLMs生成的评审的优缺点提供了实证基础，并为未来LLM辅助评审工具的发展提供了指导。相关数据、代码和更详细的结果已公开提供。
### Innovation
研究提出了一种结合语义相似性分析和结构化知识图谱度量的综合评估框架，以评估LLMs生成的评审与人类撰写的评审之间的差异。这一框架有助于系统地评估LLMs在自动论文评审生成中的表现。通过这种方式，研究揭示了LLMs在生成描述性内容和肯定性评价方面的优势，同时也发现了它们在识别论文弱点、提出实质性问题和根据论文质量调整反馈方面的局限性。这些发现为开发未来的LLM辅助评审工具提供了启发。
### Conclusion
研究发现，LLMs在描述性内容和肯定性评价方面表现良好，但在识别弱点、提出实质性问题和调整反馈方面表现不佳。这些结果为理解LLMs生成的评审的优缺点提供了实证基础，并为了解与开发未来LLM辅助评审工具提供了依据。相关数据、代码和更多详细结果已公开提供。
## 36. `cs.AI` - 使用大语言模型进行试验匹配管道的系统评价 [PDF](https://arxiv.org/pdf/2509.19327), [HTML](https://arxiv.org/abs/2509.19327)
### Authors
Braxton A. Morrison(1),Madhumita Sushil(1),Jacob S. Young(1) ((1) University of California, San Francisco)
### Background
临床试验中将患者与合适的治疗方案匹配对于发现新型治疗方法至关重要，尤其是在肿瘤学中。然而，手工匹配患者的过程非常耗费人力且容易出错，导致招募时间延误。引入使用大语言模型（LLMs）的管道被认为是一种有希望的解决方案。为此，本文系统回顾了2020年至2025年间发表的学术数据库和预印本服务器上的相关研究，识别出了基于LLMs的临床试验匹配方法。通过全面调研，发现LLM在匹配患者和试验方面的表现优于其他模型，但在实际应用中仍然面临如数据集获取、成本控制和保障公平性等挑战。
### Innovation
本文的主要创新在于通过系统性地回顾相关研究，总结了基于LLMs的临床试验匹配方法，并通过对不同模型的对比分析，指出了当前领域的性能最佳的模型（如GPT-4o模型），以及克服实际应用中的瓶颈（如合成数据使用、成本控制和数据隐私）的方法和策略。这为未来在实际情况中部署此类模型提供了指导意义。
### Conclusion
本文总结了使用LLMs进行临床试验匹配的研究进展，指出了一些可以发展的潜在方向。同时，强调标准化评估指标、更真实的测试集以及关注成本效率和公平性是扩大此类模型应用的关键。未来的研究应继续改善这些问题，以推动临床试验匹配技术的普及。
## 37. `cs.AI` - Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention [PDF](https://arxiv.org/pdf/2509.19331), [HTML](https://arxiv.org/abs/2509.19331)
### Authors
Enhao Huang,Zhiyu Zhang,Tianxiang Xu,Chunshu Xia,Kaichun Hu,Yuchen Yang,Tongtong Pan,Dong Dong,Zhan Qin
### Background
大多数深度模型将注意力视为实数相关性，忽略了干涉效应，而复杂的信号同时编码幅度和相位。
### Innovation
提出了一种受物理启发的Holographic Transformer架构，将波干涉原理融入自我注意中。该模型通过相对相位调节交互，并在振幅和相位之间保持一致性。此外，双头解码器同时重建输入并预测任务输出，防止优先考虑幅度而非相位的损失导致相位崩溃。
### Conclusion
Holographic Transformer在极化SAR图像分类和无线信道预测中的实验证明了其强性能，保持了相位一致性，增强了对相位扰动的鲁棒性。这些结果表明，确保注意力的物理一致性能实现复杂值学习的一般性改进，并提供了一个统一的物理基础框架以进行相干信号建模。代码可在以下网址获取：this https URL
## 38. `cs.AI` - 量化经典和最新嵌入模型的组合性 [PDF](https://arxiv.org/pdf/2509.19332), [HTML](https://arxiv.org/abs/2509.19332)
### Authors
Zhijin Guo(1 and 2),Chenhao Xue(1),Zhaozhen Xu(2),Hongbo Bo(2),Yuxuan Ye(2),Janet B. Pierrehumbert(1),Martha Lewis(3) ((1) University of Oxford, (2) University of Bristol, (3) University of Amsterdam)
### Background
为了使语言模型正确泛化到新的表达方式，它们在解释组合意义时需要有选择性地利用。即使我们不知道“pelp”是什么，我们仍然可以根据数字的知识理解“十pelps”比“二pelps”多。传统的词嵌入，比如Word2vec，对组合性的声明是绝对的，甚至有些过度。然而，最前沿的生成式、变压器模型和图模型在这一点上却走得过远，它们对意义随上下文的变化提供极少限制。为了量化加性组合性，作者提出了一个两步通用评估方法：首先通过典型相关分析测量已知实体属性与它们的嵌入之间的线性关系，然后通过重建未见过的属性组合的嵌入并对重构进行评估，检测重构指标如L2损失、余弦相似度和检索准确性，这些指标也涵盖了线性组合性失效的情况。评估对象包括句子、知识图谱和词嵌入，并跟踪各种数据模式和训练阶段的组合性变化。
### Innovation
作者提出了一个两步通用评估方法来量化嵌入模型的组合性：第一步通过典型相关分析测量已知实体属性与它们的嵌入之间的线性关系，第二步通过重建未见过的属性组合的嵌入并对重构进行评估，检测重构指标如L2损失、余弦相似度和检索准确性。
### Conclusion
在所有数据模式和训练阶段跟踪了组合性变化。观察到训练阶段后期和变压器基模型更深层中的组合信号更强，但在顶层有所下降。源代码可在指定网址找到。
## 39. `cs.AI` - 数量很重要：更适合整体语义理解的相似度度量 [PDF](https://arxiv.org/pdf/2509.19323), [HTML](https://arxiv.org/abs/2509.19323)
### Authors
V.S. Raghu Parupudi
### Background
在高维向量比较领域，自然语言处理（NLP）中占主导地位的标准是未加权的点积和余弦相似度。点积未加权且对向量范数敏感，而余弦相似度则完全忽略了大小信息。本文旨在挑战这些标准，提出了一种新的参数自由、感知大小的相似度度量方法。作者设计了两种函数：重叠相似度（OS）和双曲正切相似度（HTS），旨在更合理地整合向量的大小和对齐。
### Innovation
本文创新性地提出并评估了一类新的参数自由、感知大小的相似度度量方法，特别是重叠相似度（OS）和双曲正切相似度（HTS），并用四个最先进的句子嵌入模型（all-MiniLM-L6-v2，all-mpnet-base-v2，paraphrase-mpnet-base-v2，BAAI/bge-large-en-v1.5）在八个标准NLP基准测试集（包括STS-B，SICK，Quora，PAWS）上进行了全面评估。这种新的度量方法在涉及整体语义理解的任务（如比对和推理）上，表现出了在均方误差上的显著改善。
### Conclusion
本文的研究结果表明，感知大小的相似度度量在涉及整体语义理解的任务中提供了统计上优越的替代方案。这种显著改进在测试精细、复杂的组合作语义时未被观察到，为未来的工作指出了呈现组合作语义这一具有挑战性的方向。
## 40. `cs.AI` - Pluralistic Off-policy Evaluation and Alignment [PDF](https://arxiv.org/pdf/2509.19333), [HTML](https://arxiv.org/abs/2509.19333)
### Authors
Chengkai Huang,Junda Wu,Zhouhang Xie,Yu Xia,Rui Wang,Tong Yu,Subrata Mitra,Julian McAuley,Lina Yao
### Background
现有的LLM偏好对齐数据集在评估和对齐过程中，使用的政策与LLM本身相差较大，且现有脱策政策评估（Off-Policy Evaluation, OPE）方法主要关注整体效用，忽视了偏好多样性的考量，因此亟需开发一种能够捕捉多样性的脱策偏好对齐评估方法。
### Innovation
提出了首个用于LLM脱策多元偏好评估和对齐的框架—多元脱策评估（Pluralistic Off-policy Evaluation, POPE）。该框架包含一个统一的奖励函数，该函数结合了基于人类偏好信号（如点赞或相关性评分）的合作性效用成分和以熵为基础的覆盖度量的多样性成分，以捕获多元对齐。此外，POPE 提出了可分解逆倾向评分（IPS）估计器，分别评估相关性和多样性，从记录的交互中估计奖励。理论证明表明，分解的 IPS 估计器具有较低的方差下界。通过脱策评估的价值函数，可以实现脱策优化以进一步增强多元对齐。实验结果表明，POPE可以有效增强多元响应生成，同时保持模型在下游任务上的泛化能力。
### Conclusion
POPE能够有效实现LLM的多元偏好评估和对齐，在保留模型泛化能力的同时增强多元响应生成。
## 41. `cs.AI` - 利用新型对比损失和多模态学习推进儿科心律失常的少样本分类 [PDF](https://arxiv.org/pdf/2509.19315), [HTML](https://arxiv.org/abs/2509.19315)
### Authors
Yiqiao Chen,Zijian Huang,Zhenghui Feng
### Background
儿童心律失常是导致残疾和突发性心源性死亡的主要因素，但是由于类别不平衡、少量类别以及复杂信号特征，其自动化分类仍然具有挑战性。这些因素严重限制了早期筛查和临床干预的效率和可靠性。因此，本文对莱比锡心脏中心的儿科/先天性ECG+IEGM数据集进行了首个系统的分析，旨在解决此类问题，提高少样本心律失常分类的性能。
### Innovation
本文提出了一种结合双分支卷积编码器处理ECG和IEGM的多模态端到端深度学习框架，通过引入一种新型对比损失函数——自适应全局类别感知对比损失(AGCACL)，增强了类别内的紧凑性和类间可分性，适应了面向儿科和先天性心脏病人群心律失常分类的需求。
### Conclusion
实验结果显示，本文所提出的方法在莱比锡心脏中心儿童/先天性ECG+IEGM数据集上实现了最佳的整体性能，具体指标包括97.76%的一级准确性、94.08%的宏精准度、91.97%的宏召回率、92.97%的宏F1值以及92.36%的宏F2值，相较于最强基准方法有显著提高。这表明该框架显著提高了少数心律失常类别的检出率和鲁棒性，为儿科和先天性心脏病人群的心律筛查、介入前评估和术后随访提供了潜在的临床价值。
## 42. `cs.AI` - 无线传播建模：是区分还是深度学习，这是个问题 [PDF](https://arxiv.org/pdf/2509.19337), [HTML](https://arxiv.org/abs/2509.19337)
### Authors
Stefanos Bakirtzis,Paul Almasan,José Suárez-Varela,Gabriel O. Ferreira,Michail Kalntis,André Felipe Zanella,Ian Wassell,Andra Lutu
### Background
不同可微射线追踪方法在无线传播建模和数字孪生中的应用近期打破了传统模型的主导地位，提供了前所未有的速度和从实际数据中学习的能力，被视为传统深度学习模型的可行替代方案。然而，目前缺乏对生产级网络的实际评估，未能验证其假设的可扩展性和实际优势，因此运营商和研究社区无法明确指导其应用。
### Innovation
本文通过使用不同可微射线追踪和深度学习模型，利用大规模实际网络数据（覆盖13个城市和超过10,000个基站）来模拟无线电覆盖，填补了这方面的空白。结果显示，尽管可微射线追踪模拟器在减少效率-准确性的差距方面有所贡献，但它们在大规模从实际数据中泛化能力较弱，不适于实时应用。相反，深度学习模型在从城市、郊区和农村部署中显示出更高的准确性和更快的适应性，实现了高达3 dB的准确率提升。
### Conclusion
实验结果旨在为这一基础开放问题提供及时的见解，直接关系到无线生态系统和未来研究的方向。不同可微射线追踪相比，深度学习模型在无线传播建模中的适用性和性能方面显示出了优势。
## 43. `cs.AI` - CSIYOLO：集成传感与通信系统中基于CSI的智能散射感知框架 [PDF](https://arxiv.org/pdf/2509.19335), [HTML](https://arxiv.org/abs/2509.19335)
### Authors
Xudong Zhang,Jingbo Tan,Zhizhen Ren,Jintao Wang,Yihua Ma,Jian Song
### Background
ISAC 被认为是下一代通信系统中的一项有前途的技术，能够同时进行数据传输和目标感知。ISAC 中的散射感知对于实现其全部潜力和支持如自动驾驶和低空经济等应用至关重要。然而，现有的大多数方法要么依赖波形和硬件的修改，要么依赖传统信号处理方案，这导致了与当前通信系统的不兼容问题以及有限的感知精度。
### Innovation
我们提出了 CSIYOLO，一个仅利用单基站-用户设备对估计的信道状态信息 (CSI) 进行散射定位的框架。该框架包括基于锚点的散射参数检测和基于CSI的散射定位两大组件。首先，通过将散射参数提取建模为图像检测问题，我们提出了一种灵感来自于 You Only Look Once 架构的基于锚点的散射参数检测方法。之后，基于提取的参数，我们推导出一种CSI 基本地化算法来确定散射位置。为了提高定位精度和实现效率，我们设计了一种可扩展的网络结构，其具有任务导向的优化，能够进行多尺度锚点检测，并更好地适应CSI 特征。此外，我们还设计了一种噪声注入训练策略，以增强对信道估计误差的鲁棒性。由于该框架仅依赖于估计的CSI 而不修改波形或信号处理管道，因此它可以无缝集成到现有的通信系统中作为插件。实验结果表明，我们提出的方法在各种散射数量和估计误差条件下，可以显著优于现有方法的散射定位精度，同时具有较低的复杂性。
### Conclusion
我们的研究成果表明，CSIYOLO 能够显著提高散射定位精度，并且具有较高的兼容性和较低的复杂性，能够作为插件无缝地服务于现有的通信系统。
## 44. `cs.AI` - 多小区边缘网络中协作多点广播的细粒度AI模型缓存与下载 [PDF](https://arxiv.org/pdf/2509.19341), [HTML](https://arxiv.org/abs/2509.19341)
### Authors
Yang Fu,Peng Qin,Yueyue Zhang,Yifei Wang
### Background
6G网络预计能够支持按需下载AI模型，以满足终端用户的多样推理需求。通过在边缘节点主动缓存模型，用户可以以低延迟在本地设备上进行AI推理。然而，现代AI模型的庞大尺寸为边缘缓存带来了巨大挑战，尤其是在有限的存储空间下，同时复杂的异构模型并发传输也对无线信道提出了挑战。
### Innovation
该研究提出了一种细粒度的AI模型缓存和下载系统，利用参数重用，通过从共享预训练模型中冻结参数进行特定任务的微调实践。系统选择性地在边缘节点缓存模型参数块（PBs），消除不同缓存模型中重复参数的冗余存储，并结合协调多点（CoMP）广播，同时向多个用户传输可重用的PBs。此外，还提出了一种分布式多代理学习框架，通过数据增强方法自适应生成合成训练样本，提高采样效率，加速策略学习。
### Conclusion
研究通过理论分析和仿真实验，验证了所提出学习框架的优越收敛性能。
## 45. `cs.AI` - 流体天线辅助下的联合信道估计算法和计算卸载 [PDF](https://arxiv.org/pdf/2509.19340), [HTML](https://arxiv.org/abs/2509.19340)
### Authors
Ying Ju,Mingdong Li,Haoyu Wang,Lei Liu,Youyang Qu,Mianxiong Dong,Victor C. M. Leung,Chau Yuen
### Background
流体天线（FA）在无线通信中的出现使得动态调整端口位置能够显著提高空间多样性和频谱效率，这对于移动边缘计算（MEC）系统尤其重要。这项研究旨在通过一个FA辅助的MEC卸载框架来最小化系统延迟。然而，这种动态端口配置导致了信道估计的复杂性，并且联合优化问题本身不具凸性，带来了巨大的挑战。
### Innovation
本文提出的创新包括信息瓶颈度增强的信道压缩感知（IBM-CCS）方法和基于博弈论的帮助级双定博弈多代理算法（HiTDMA）。IBM-CCS通过将信息相关性融入到感知过程中，并有效地捕捉FA信道的关键特征，提高了FA信道的估计能力。HiTDMA旨在解决FA辅助MEC系统中的非凸和高维优化问题，通过级联系统有效地解耦和协调用户端和基站端的优化任务，并通过博弈论有效降低了功率控制变量的维度，使得深度强化学习（DRL）代理能够实现高度优化的性能。
### Conclusion
数值结果表明，提出的方法显著减少了系统延迟并提高了卸载性能，优于基准方法。此外，IBM-CCS信道估计在不同端口密度下具有优越的准确性和鲁棒性，有助于在不完善的CSI条件下实现高效的通信。
## 46. `cs.AI` - 基于能力意识检索和风格适应的认知水平自适应生成 [PDF](https://arxiv.org/pdf/2509.19336), [HTML](https://arxiv.org/abs/2509.19336)
### Authors
Qingsong Wang,Tao Wu,Wang Lin,Yueying Feng,Gongsheng Yuan,Chang Yao,Jingyuan Chen
### Background
大语言模型（LLMs）在开放生成任务中表现出色，但往往难以适应具有不同认知能力的用户，导致我们称作认知错位的现象。这种错位有两种形式：知识层面的错位，即内容相对于用户理解而言过于复杂或过于简单；以及表现风格的错位，即结构或语气阻碍了有效的理解。这些问题需要一种能够协调知识复杂度和展示风格与用户认知能力的框架来解决。为此，我们提出了认知层次对齐框架（CLAF），这是一种通用生成框架，能同时调整知识复杂性和展示风格以匹配用户认知水平。CLAF结合了基于层次知识图的具备能力感知的检索模块，以及由布鲁姆分类学和偏好学习引导的风格优化模块。此外，还实现了一个知识可控制的生成组件，确保输出的一致性和相关性。为了实现CLAF的训练和评估，我们构建了一个认知注释数据集SCALE，其中包括根据查询的不同理解层次构建的回复。实验证明，CLAF能增强LLM输出的适应性和信息性，适用于各种用户画像，并提供了一个解决现实应用中认知层次对齐问题的稳健方案。
### Innovation
本文提出了一种新的框架——认知层次对齐框架（CLAF），用于协调LLM生成的内容与用户的认知复杂度和表现风格。CLAF通过结合能力感知的检索模块、基于布鲁姆分类学和偏好学习的风格优化模块，以及知识可控的生成组件，能够更好地适应不同认知能力的用户。此外，还构建了一个认知注释数据集SCALE来支持CLAF的训练和评估，这是一个创新的数据处理和训练方法。CLAF能够提供一个更为有效和实用的解决方案，降低认知错位的影响，提高LLM在实际应用中的适应性和信息性。
### Conclusion
实验结果表明，CLAF增强了LLM输出的适应性和信息性，能够涵盖广泛的用户画像，并提供了在现实应用场景中解决认知层次对齐问题的稳健方法。
## 47. `cs.AI` - 使用CRF对纳加 pidgin 语言进行词性标注 [PDF](https://arxiv.org/pdf/2509.19343), [HTML](https://arxiv.org/abs/2509.19343)
### Authors
Alovi N Shohe,Chonglio Khiamungam,Teisovi Angami
### Background
Nagamese语言，也被称为Naga Pidgin，是一种以Assamese为词汇来源的克里奥尔语，主要用于尼加人和阿萨姆人之间的贸易交流。尽管对于资源丰富语言（如英语、印地语等）的词性标注已有大量研究，但Nagamese语言却没有相关研究。本文首次针对Nagamese语言的词性标注进行了研究，旨在识别Nagamese语言中给定句子的词性。创建了一个包含16,112个标记的语料库，并使用机器学习技术条件随机场（CRF）进行词性标注。研究结果表明，使用CRF的总体标记准确率为85.70%，精确率为86%，F1分数为85%。
### Innovation
这是首次关于Nagamese语言词性标注的研究，使用条件随机场（CRF）技术创建了一个包含16,112个标记的语料库。该研究填补了Nagamese语言在自然语言处理领域的一个研究空白，为该语言的进一步研究提供了基础。
### Conclusion
研究利用条件随机场（CRF）技术实现了Nagamese语言的词性标注，总体准确率达到85.70%，达到了初步的预期目标，为该语言的进一步自然语言处理奠定了基础。
## 48. `cs.AI` - TriSPrompt：一种用于不完整模态多模态谣言检测的分层软提示模型 [PDF](https://arxiv.org/pdf/2509.19352), [HTML](https://arxiv.org/abs/2509.19352)
### Authors
Jiajun Chen,Yangyang Wu,Xiaoye Miao,Mengying Zhu,Meng Xi
### Background
在多模态数据中普遍存在不完整模态的问题，这对准确检测谣言构成了重大挑战。现有的多模态谣言检测方法主要关注从完整多模态训练数据中学习联合模态表示，这使它们在处理现实环境中常见的缺失模态问题时变得无效。
### Innovation
本文提出了一种分层软提示模型TriSPrompt，通过集成三类提示——模态感知（MA）提示、模态缺失（MM）提示和相互视角（MV）提示，以有效地检测不完整多模态数据中的谣言。MA提示捕捉特定模态中的异构信息和可用数据中的同质特征，有助于模态恢复。MM提示建模不完整数据中的缺失状态，增强模型对缺失信息的适应性。MV提示学习主观（如文本和图像）和客观（如评论）视角之间的关系，有效地检测谣言。
### Conclusion
在三个现实世界基准测试上的大规模实验表明，TriSPrompt相比最先进的方法在准确率上提高了超过13%。代码和数据集可通过https://anonymous.this http URL. 获取。
## 49. `cs.AI` - SCORE：生成文档解析的语义评估框架 [PDF](https://arxiv.org/pdf/2509.19345), [HTML](https://arxiv.org/abs/2509.19345)
### Authors
Renyu Li,Antonio Jimeno Yepes,Yao You,Kamil Pluciński,Maximilian Operlejn,Crag Wolfe
### Background
传统的评价指标（如CER、WER、IoU或TEDS）在评估多模态生成的文档解析系统时会将多样化的正确输出误判为错误，这会导致对系统表现的不公正评价，掩盖真实的系统行为。这些评价方法无法全面应对生成模型在输出格式、内容准确性和结构一致性等方面的差异性挑战。因此，需要一种新的评估框架来反映不同解释的合理性并推广代表多样性，同时保持语义的严谨性。
### Innovation
SCORE（结构和内容稳健评估框架）提出了一种解析体系无关的框架，它包括：(i) 调整后的编辑距离以增强内容一致性核对，(ii) 用于区分虚构内容和内容缺失的标记级别诊断，(iii) 具有空间容差和语义对齐的表格评估，(iv) 涉及层次感知的语义一致性检查。这些维度共同为多样表示性与语义严谨性的评估提供了可能性，从而使评估体系能够反映不同的解释多样性，且能显示模型稳健性。此外，SCORE通过将生成输出标准化到格式无关表示，能恢复传统评分指标（如表格F1可达0.93）无需依赖检测管道，从而证明仅依赖生成解析就能够进行全面的评估。
### Conclusion
SCORE框架能够揭示标准指标未能捕捉到的跨数据集的性能趋势，并纠正了传统评估方法中错误的排名，显示了模型不同但合理的解释之间的等效性。通过暴露解释多样性对评估结果的影响，并提供多维解析性诊断，SCORE为现代文档解析系统提供了语义基础、公平且实用的基准制定原则。
## 50. `cs.AI` - 使用深度学习的反洗钱系统 [PDF](https://arxiv.org/pdf/2509.19359), [HTML](https://arxiv.org/abs/2509.19359)
### Authors
Mashkhal Abdalwahid Sidiq,Yimamu Kirubel Wondaferew
### Background
本文探讨了使用深度学习方法检测金融交易网络中的洗钱活动，以展示其作为基于规则的系统和传统反洗钱（AML）系统的补充或替代的优势。文中强调了反洗钱（AML）活动在全球金融行业的关键作用，并指出现有反洗钱系统的缺点，如高误报率和难以发现复杂的洗钱方案.
### Innovation
文章提出了一种利用深度学习技术进行链接分析的先进反洗钱系统。该系统的核心在于使用度中心性、接近中心性、中介中心性和PageRank等中心性算法来增强系统识别可疑活动的能力。此外，文章探讨了将新兴技术如深度学习和中心性算法整合到反洗钱努力中的前景，这意味着将交易或账户在其金融环境中进行分析.
### Conclusion
该研究结果表明，基于图卷积网络（GCN）模型的新实施方案是处理连通性结构数据的有效方法。结合中心性算法，这种新的反洗钱系统具有提高反洗钱系统效能的潜力，通过细化系统功能予以实现。
## 51. `cs.AI` - 用于个性化生成的大语言模型稳健性基准测试与改进 [PDF](https://arxiv.org/pdf/2509.19358), [HTML](https://arxiv.org/abs/2509.19358)
### Authors
Chimaobi Okite,Naihao Deng,Kiran Bodipati,Huaidian Hou,Joyce Chai,Rada Mihalcea
### Background
近年来，人们越来越关注如何个性化大语言模型（LLMs）的回应。现有的评估大多集中在回应是否符合用户的偏好上，而忽略了事实准确性的同等重要性。从个性化角度来看，我们定义一个模型是健壮的，如果其回应在保持事实准确性的同时也符合用户的偏好。本文通过引入PERG框架和新的数据集PERGData，评估了来自五个不同模型家庭的14个模型，在不同提示方法下进行评估。我们的研究发现，当前的LLMs在个性化方面表现出稳健性的挑战：即使是表现最强的模型（如GPT-4.1、LLaMA3-70B）在5%的先前成功的案例中无法保持正确性，而较小的模型（如7B规模）的失败率超过20%。进一步分析表明，健壮性显著受到查询性质和用户偏好类型的影響。此外，本文还提出了一种称为Pref-Aligner的两阶段方法，该方法在所有模型上平均改善了25%的健壮性。这项工作揭示了当前评价实践中的关键缺口，并提出了工具和指标来支持更可靠的、用户对齐的大语言模型部署。
### Innovation
本文引入了PERG框架和PERGData数据集，评估了14个来自5种不同模型家族的LLMs在个性化方面的健壮性，提出了Pref-Aligner两阶段方法，显著改善了模型的健壮性，并揭示了用户偏好和查询性质对健壮性的影响。
### Conclusion
本文的研究结果表明，当前LLMs在个性化方面存在稳健性的挑战，提出的方法可以显著改善模型的健壮性。此外，该研究揭示了评价实践中的关键缺口，并提出了可支持更可靠、用户对齐的大语言模型部署的工具和指标。
## 52. `cs.AI` - RoadMind：朝着灾害响应中的地理空间AI专家发展 [PDF](https://arxiv.org/pdf/2509.19354), [HTML](https://arxiv.org/abs/2509.19354)
### Authors
Ahmed El Fekih Zguir,Ferda Ofli,Muhammad Imran
### Background
大型语言模型在自然语言任务中表现出色，但在处理地理空间数据方面仍有限制，特别是在道路网络、距离和方向的推理上。这在灾害场景中造成了挑战，因为这些场景需要关键的地理空间理解，比如疏散计划和资源分配。当前的工作通过使用来自OpenStreetMap的结构化数据来解决这个问题，提出了一种名为RoadMind的半监督框架，以增强大型语言模型在地理空间推理的能力。
### Innovation
RoadMind框架通过自动管道从OpenStreetMap中提取道路基础设施数据，并将其转换为针对关键空间任务的多种监督形式。通过QLoRA适配器和4位量化模型进行预训练和微调。该方法在洛杉矶、基督城和马尼拉三个灾害频发城市进行评估，涵盖道路段识别、最近道路检索和距离/方向估计等多种任务。研究表明，通过RoadMind训练的模型显著优于强基线，包括具有高级提示工程技术的最先进的语言模型。这表明结构化地理空间数据可以增强语言模型的空间推理能力，使其更适用于灾害响应的离线AI系统。
### Conclusion
研究结果表明，通过RoadMind训练的模型在多种任务上表现优于最先进的语言模型和强基线，证明了结构化地理空间数据能够增强语言模型的空间推理能力，从而支持更有效的灾害响应离线AI系统。
## 53. `cs.AI` - 针对对齐的大语言模型的语义表示攻击 [PDF](https://arxiv.org/pdf/2509.19360), [HTML](https://arxiv.org/abs/2509.19360)
### Authors
Jiawei Lian,Jianhong Pan,Lefan Wang,Yi Wang,Shaohui Mei,Lap-Pui Chau
### Background
大语言模型（LLMs）越来越多地使用对齐技术来防止有害输出。尽管这些安全措施存在，攻击者仍可以通过精心设计提示来诱导LLMs生成有害内容。现有方法通常针对精确的肯定回答，如“当然，以下是...”，但这些方法存在局限性，包括有限的收敛性、不自然的提示和高计算成本等问题。
### Innovation
提出了语义表示攻击（Semantic Representation Attack，SRA），这是一种新的范式，重新定义了对对齐大语言模型的攻击目标，并不再追求精确的文本模式，而是利用包含等效有害意义的多种回应的语义表示空间。本文提出的语义表示启发式搜索算法能高效生成语义连贯且简洁的对抗性提示，同时保持解释性。通过严格的理论保证和实验结果验证，SRA方法显著提高了攻击成功率（18个LLM中的89.41%平均成功率，其中包括11个模型的100%成功率），同时保持了隐蔽性和效率性，证明了其在整体上的优越性。
### Conclusion
本文通过语义表示攻击（SRA）创新性地解决了现有方法的固有trade-off问题，即攻击效果与提示自然度之间的权衡。实验结果表明，SRA方法不仅攻击成功率高，而且能够保持隐身性和效率，是已知最先进的方法。
## 54. `cs.AI` - 线下LLM评估的不足：需要考量模型行为中的个性化现象 [PDF](https://arxiv.org/pdf/2509.19364), [HTML](https://arxiv.org/abs/2509.19364)
### Authors
Angelina Wang,Daniel E. Ho,Sanmi Koyejo
### Background
传统的离线评估方法假定语言模型的推理是独立且无状态的，但这些评估未能反映语言模型在实际使用中会因个性化因素而表现出不同行为的情况。例如，相同的基准问题在不同的用户聊天会话中可能会得到截然不同的响应。
### Innovation
本文通过比较离线评估和由800名真实ChatGPT和Gemini用户进行的现场评估，展示了这种个性化现象的实证证据。
### Conclusion
离线评估无法充分捕捉语言模型的实际行为，特别是在个性化方面。因此，需要在模型行为评估中考虑个性化因素。
## 55. `cs.AI` - 基于合作进化和多视图学习的多层次集成遗传编程用于分类 [PDF](https://arxiv.org/pdf/2509.19339), [HTML](https://arxiv.org/abs/2509.19339)
### Authors
Mohammad Sadegh Khorshidi,Navid Yazdanjue,Hassan Gharoun,Mohammad Reza Nikoo,Fang Chen,Amir H. Gandomi
### Background
本文介绍了一种计算智能框架——多层次集成遗传编程（MEGP），它将协同进化和多视图学习范式结合在一起，以应对高维度和异构特征空间中的分类挑战。MEGP 将输入空间分解为有条件的独立特征子集，使得多个子种群能够并行进化并在动态的基于集成的适应度机制下进行交互。
### Innovation
MEGP 使用一种可微软最大值加权层聚合多个基因的输出，增强了模型的解释性和可适应的决策融合。引入了结合独立和集成水平适应度的混合选择机制，促进种群间的合作同时保持种群内的多样性。这种双层进化的动态机制促进了结构化的搜索探索，减少了过早收敛。实验结果显示，MEGP 在收敛行为和泛化性能上优于基线 GP 模型，并且在日志损失、精确度、召回率、F1 分数和 AUC 上都取得了显着改进。
### Conclusion
MEGP 通过将基于种群的优化、多视图表示学习和合作进化统一起来，提供了一个结构适应性和可解释性框架，推动了进化机器学习的新兴方向。MEGP 能够保留分布的多样性并加速进化过程中的适应度增长，展示了其在可扩展和集成驱动进化学习中的有效性。
## 56. `cs.AI` - DeepACTIF: 通过神经序列模型激活跟踪实现高效特征归因 [PDF](https://arxiv.org/pdf/2509.19362), [HTML](https://arxiv.org/abs/2509.19362)
### Authors
Benedikt W. Hosp
### Background
特征归因对于解释深度学习模型至关重要，尤其在医学、生物识别和技术交互等领域的时间序列数据中更为重要。然而，传统的归因方法如集成梯度或SHAP计算量大，不适用于实时应用。
### Innovation
提出了一种轻量级且了解架构的特征归因方法——DeepACTIF，利用序列模型内部激活来高效估算特征的重要性。特别针对基于LSTM的网络，引入了逆加权聚合方案，强调了激活稳定性和时间步长的大小。实验证明，DeepACTIF在严重减少特征（保留最顶级10%特征）的情况下仍保持预测性能，并且在准确性和统计稳健性方面显著优于SHAP、IG和DeepLIFT等现有方法。此外，DeepACTIF还大幅减少了计算时间和内存使用，能够仅使用顶级特征保留模型准确性，为边缘设备上的实时可解释性提供可行解决方案。
### Conclusion
DeepACTIF不仅在高效性上显著超越了现有方法，还展示了在时间序列数据领域深度学习模型解释上的优越性能，特别适合用于移动XR头盔或嵌入式健康监测等实时应用环境。
## 57. `cs.AI` - 飞虫嗅觉神经回路结构变化对学习能力的影响 [PDF](https://arxiv.org/pdf/2509.19351), [HTML](https://arxiv.org/abs/2509.19351)
### Authors
Katherine Xie,Gabriel Koch Ocker
### Background
果蝇蘑菇体（MB）在嗅觉学习和记忆中起作用；肯尼细胞（KC）到蘑菇体输出神经元（MBON）突触的突触可塑性在学习过程中起关键作用。先前的研究主要集中在MB内的投射神经元（PN）到肯尼细胞（KC）的连接；本研究探讨了对MB回路结构的扰动和连接变化，特别是KC到MBON神经回路内部，如何影响MBON区分气味类别的能力。
### Innovation
构建了一个包含PN、KC和MBON之间的连接的神经网络模型；生成了十种人工输入类别来训练模型；揭示了KC的发育类型对每个MBON输出的影响；发现对成熟KC的随机和目标消融具有比对未成熟KC更大的负面影响；通过随机和目标修剪KC-MBON突触连接的实验结果与消融实验一致；进行了PN到KC电路的重新布线实验进一步探讨了各种类型的KC。
### Conclusion
本研究加深了我们对嗅觉神经可塑性的理解，提供了理解学习和记忆的重要线索。对嗅觉回路的研究也可以对人工智能和神经退行性疾病治疗产生潜在应用。
## 58. `cs.AI` - SLM-Based Agentic AI with P-C-G: Optimized for Korean Tool Use [PDF](https://arxiv.org/pdf/2509.19369), [HTML](https://arxiv.org/abs/2509.19369)
### Authors
Changhyun Jeon,Jinhee Park,Jungwoo Choi,Keonwoo Kim,Jisu Kim,Minji Hong
### Background
该研究背景在于开发一种小型语言模型（SLM）基于的代理架构，旨在优化在韩国工具使用场景中的性能。
### Innovation
该创新之处在于提出了一种名为Planner-Caller-Generator（P-C-G）的代理架构，该架构将规划、调用和生成任务按角色分离。引入了以韩语优先的价值策略，以减少执行失败，特别是在频繁切换韩语至英语代码时。
### Conclusion
研究结果表明，P-C-G在工具使用准确性和端到端质量方面表现出竞争力，同时减少了所需token的数量并保持了可接受的延迟，这表明角色特化的小型语言模型是为韩国工具使用代理提供的一种经济有效的替代方案。
## 59. `cs.AI` - 无监督异常检测在审计分析中的应用：美国联邦支出数据案例研究 [PDF](https://arxiv.org/pdf/2509.19366), [HTML](https://arxiv.org/abs/2509.19366)
### Authors
Buhe Li,Berkay Kaplan,Maksym Lazirko,Aleksandr Kogan
### Background
随着政府数据集的规模扩大，传统审计方法可能会变得效率低下且不够准确。因此，研究中探讨了在审计分析中使用无监督异常检测方法的有效性，特别是通过美国卫生与人类服务部(DHHS)的美国联邦支出数据作为案例进行分析。
### Innovation
研究采用了多种异常检测算法，包括直方图基异常得分（HBOS）、鲁棒主成分分析（RPCA）、最小协方差确定（MCD）和K-最近邻（KNN），并提出了将这些策略结合使用的方法以提升复杂财务数据中的异常识别的稳健性和准确性。
### Conclusion
研究通过数据分析、算法实现和使用精确度、召回率和F1分数进行性能评估，结果表明使用多种异常检测策略的混合方法能更好地识别复杂的财务数据中的异常。该研究为审计分析领域提供了关于不同异常检测模型的相对有效性的见解，并证明了无监督学习技术在提高审计质量和效率方面的潜力。
## 60. `cs.AI` - 使用自适应神经模糊推理系统分析信用卡欺诈对美国家庭经济波动的影响 [PDF](https://arxiv.org/pdf/2509.19363), [HTML](https://arxiv.org/abs/2509.19363)
### Authors
Zhuqi Wang,Qinghe Zhang,Zhuopei Cheng
### Background
随着信用卡欺诈的日益严重，它已成为威胁美国家庭财务状况的主要因素，导致家庭经济行为产生不可预测的变化。为了解决这个问题，本文提出了一种新的混合分析方法，采用增强的ANFIS框架。该模型对传统的ANFIS框架提出了多项改进，并采用了多分辨小波分解模块和时间注意力机制。该模型对历史交易数据和宏观经济指标进行离散小波变换，以生成局部经济冲击信号。
### Innovation
该模型在相同的背景下，采用了多分辨小波分解模块和时间注意力机制，通过模块化训练过程将模糊规则激活、小波基选择和时间相关权重进行了集成。模型通过小波变换在历史交易数据和宏观经济指标上生成局部经济冲击信号，并将这些特征输入基于Takagi-Sugeno模糊规则的深度模糊规则库中，该规则库具有自适应高斯隶属函数。该模型提出了一种时间注意力编码器，能够自适应地对多尺度经济行为模式分配权重，在模糊推理阶段提高相关性评估的有效性，并增强对伪装活动导致的长期时间依赖性和异常的捕获。与经典的ANFIS相比，该方法将模糊规则激活与波let基选择和时间相关权重结合，通过模块化训练过程实现集成。实验结果显示，与局部神经模糊模型和传统LSTM模型相比，RMSE降低了17.8%。
### Conclusion
通过增强的ANFIS框架，结合多分辨率小波分解和时间注意力机制，提出了一种新的模型，能够有效识别和预测信用卡欺诈行为，从而为解决家庭经济行为的不可预测变化提供了新的方法。
## 61. `cs.AI` - 基于表示的广义幻觉检测器无法做到离分布外泛化 [PDF](https://arxiv.org/pdf/2509.19372), [HTML](https://arxiv.org/abs/2509.19372)
### Authors
Zuzanna Dubanowska,Maciej Żelaszczyk,Michał Brzozowski,Paolo Mandica,Michał Karpowicz
### Background
当前最先进的幻觉检测方法在其在RAGTruth数据集上的性能很大程度上依赖于数据的错误相关性。去除这种影响后，最先进的方法的表现与监督线性探针相当，且需要在多个数据集上进行广泛的超参数调整。离分布外的泛化目前难以实现，所有分析的方法都在随机水平附近表现。
### Innovation
提出了一套幻觉检测及其评估的指导原则。
### Conclusion
基于表示的广泛幻觉检测器无法实现离分布外泛化，即使是最先进的方法，在处理未见数据时也表现不佳。
## 62. `cs.AI` - Meow：自动学术综述的一站式提纲写作 [PDF](https://arxiv.org/pdf/2509.19370), [HTML](https://arxiv.org/abs/2509.19370)
### Authors
Zhaoyu Ma,Yuan Shan,Jiahao Zhao,Nan Xu,Lei Wang
### Background
随着学术论文发表数量的指数级增长，自动地对大型语言模型（LLMs）进行深入调查已经成为一种不可避免的趋势。提纲写作旨在系统地整理相关工作，对于自动综述生成至关重要。但是，现有的自动综述方法将提纲写作视为整个工作流中的步骤，这种基于模板的方法产出的提纲缺乏对综述主题的深入理解以及细腻的风格。
### Innovation
我们提出了Meow，这是首个基于元数据驱动的提纲写作框架，能够高效地生成有条理且忠实的提纲。具体而言，我们首先将提纲写作定义为从论文元数据生成具有层次结构的结构化提纲的端对端任务。我们还从arXiv、bioRxiv和medRxiv收集了高质量的综述数据集，并建立了系统性的提纲质量评估标准。最后，我们采用结合监督微调和强化学习的两阶段训练方法。效果证明，我们的8B推理模型在结构完整性和风格一致性方面表现优异。
### Conclusion
Meow框架通过将提纲写作定义为端对端任务，提供了一个基于元数据驱动的提纲生成方法，这对于自动学术综述的生成具有重要意义。通过两阶段的训练方法，该框架生成的提纲能更好地体现综述主题的理解深度和风格的一致性。
## 63. `cs.AI` - 如何高效地注入知识？预训练大型语言模型的知识注入标度定律 [PDF](https://arxiv.org/pdf/2509.19371), [HTML](https://arxiv.org/abs/2509.19371)
### Authors
Kangtao Lv,Haibin Chen,Yujin Yuan,Langming Liu,Shilei Liu,Yongwei Wang,Wenbo Su,Bo Zheng
### Background
大语言模型（LLMs）因其在多样化下游任务中的出色泛化能力而受到广泛关注。然而，如果不进行特定领域的优化，它们在专门知识基准测试中往往会表现不佳，甚至会产生幻觉。最近的研究表明，在预训练过程中有选择地注入领域知识可以显著提高下游性能。一个关键挑战在于，适度平衡领域内知识的注入，过多或过少都会导致问题。注入不足会导致领域知识不足的特化，而过多的注入会导致对于之前学到的知识的灾难性遗忘。这项研究集中在过度注入导致的回放缓冲现象上，通过系统性的实验，观察到了两个关键点：每个模型都有一个知识保留能力急剧下降的临界点，这些临界点与模型大小之间存在一致的关联性。基于这些洞察，提出了一个知识注入标度定律，通过分析较小模型来预测注入到大型LLMs中的最优领域知识量。广泛的实验验证了该标度定律的有效性和泛化能力
### Innovation
提出了一个知识注入标度定律，通过分析较小模型来预测应用到大型LLMs中的最优领域知识量，旨在解决领域知识过度注入导致的回放缓冲问题，并验证了该定律的有效性和泛化能力
### Conclusion
通过系统的实验，该研究发现每个模型都存在一个知识预留能力急剧下降的临界点，这个点与模型的大小之间存在一致的关联性，基于这些发现提出了一个可以预测最佳领域知识注入量的知识注入标度定律，并通过不同的模型规模和相应的令牌预算验证了该定律的有效性和泛化能力
## 64. `cs.AI` - 从观察学习：最近进展的综述 [PDF](https://arxiv.org/pdf/2509.19379), [HTML](https://arxiv.org/abs/2509.19379)
### Authors
Returaj Burnwal,Hriday Mehta,Nirav Pravinbhai Bhatt,Balaraman Ravindran
### Background
模仿学习（IL）算法提供了一种通过模仿专家行为来训练智能体的方法，而不必使用奖励函数。传统的IL算法需要专家的动作信息，但获取这些信息在实际应用中可能难以实现。为了解决这个问题，从观察学习（LfO）或状态仅模仿学习（SOIL）的概念得到了关注，这种方法仅利用专家状态访问信息进行学习。
### Innovation
本文提出了一种从观察学习的框架，用于梳理和分类现有的从观察学习方法，从轨迹构建、假设以及算法设计选择等方面进行了分类。此外，该综述还探讨了与脱机强化学习、基于模型的强化学习和层次强化学习等相关领域之间的联系。
### Conclusion
本文框架被用来识别开放性问题并提出未来的研究方向。
## 65. `cs.AI` - TensLoRA: 张量替代方法用于低秩适应 [PDF](https://arxiv.org/pdf/2509.19391), [HTML](https://arxiv.org/abs/2509.19391)
### Authors
Axel Marmoret,Reda Bensaid,Jonathan Lys,Vincent Gripon,François Leduc-Primeau
### Background
低秩适应（LoRA）被广泛应用于通过向注意力投影添加可训练的低秩矩阵来高效地适应变压器。虽然这种方法有效，但这些矩阵被视为每层和每个注意力投影（查询、键和值）独立的。最近的扩展考虑了基于张量的联合调整，但仅限于有限的形式且没有系统化的框架。
### Innovation
引入了TensLoRA，这是一种统一框架，通过将LoRA更新聚合到高阶张量中，并建模了张量基低秩适应的不同形式。该方法扩展了现有的张量基方法，允许按模态和任务自定义压缩率，从而使参数预算能够根据具体情况调整。
### Conclusion
在视觉和语言基准测试中，张量构建直接提升了性能，在相似的参数数量下有时甚至超过了标准的LoRA方法。
## 66. `cs.AI` - 全管道并行是优化基于早期退出的自我推测解码所需的一切 [PDF](https://arxiv.org/pdf/2509.19368), [HTML](https://arxiv.org/abs/2509.19368)
### Authors
Ruanjun Li,Ziheng Liu,Yuanming Shi,Jiawei Shao,Chi Zhang,Xuelong Li
### Background
大语言模型（LLMs）生成高质量文本，但每次生成一个输出令牌时，模型层需要顺序工作，导致较高的推理成本。早期退出基于自我推测解码（EESD）技术被提出以减轻这种成本，但在实践中，许多方法在草案完成后再验证的模式中难以实现预期的加速，尤其是在早期退出头和退出位置设置良好时也是如此。研究发现，只有当大多数草案令牌被语言模型接受时，EESD 才能奏效。否则，尝试可能会抵消加速的增益，导致负面的速度提升，因此需要一种新的方法来减少这种浪费。
### Innovation
提出了一种名为Pipeline-Parallel Self-Speculative Decoding (PPSD)的新方法。PPSD的关键创新在于：1. 将模型层配置成一个管道，在其中早期退出（草案）计算和剩余层（验证）计算重叠，2. 交替进行每个令牌的草案和验证工作。这种验证的同时草案机制确保所有组件都在忙碌状态，并且对令牌进行即时验证，类似于将猜测和验证阶段并行化。
### Conclusion
实验证明，PPSD在自我推测LLM推理中的加速效果达到最佳状态。在多种基准测试中，PPSD实现了2.01x到3.81x的速度比，几乎在固定的接受率和退出位置下获得了最优加速，表明了其在提供高效自我推测方面的进步。
## 67. `cs.AI` - 使用近似贝叶斯计算量化大型语言模型的不确定性 [PDF](https://arxiv.org/pdf/2509.19375), [HTML](https://arxiv.org/abs/2509.19375)
### Authors
Mridul Sharma(1),Adeetya Patel(1),Zaneta D' Souza(1),Samira Abbasgholizadeh Rahimi(1 and 3),Siva Reddy(2 and 3),Sreenath Madathil(1) ((1) Faculty of Dental Medicine and Oral Health Sciences, McGill University, Montreal, Canada (2) School of Computer Science, McGill University, Montreal, Canada (3) Mila-Quebec Artificial Intelligence Institute, Montreal, Canada)
### Background
尽管大型语言模型（LLMs）在众多应用场景中广泛应用，但在高 stakes 和安全关键领域如临床诊断中，它们往往难以准确表达不确定性，这给可靠部署带来了挑战。现有的基准方法如模型 logits 和主观概率估计产生了过于自信且校准不良的估计结果。已有方法无法解决这一问题，使得在需要精确度量不确定性的领域部署LLMs时存在风险。因此，研究人员需要提出新的方法以提高LLMs的不确定性表达能力，增强在安全关键领域的可靠性。
### Innovation
本文提出了一种基于近似贝叶斯计算（ABC）的无似然贝叶斯推理方法，将LLMs作为随机模拟器来推断预测概率的后验分布。与现有基准方法相比，该方法在两个与临床相关的基准测试：合成口腔病灶诊断数据集和公开的GretelAI症状到诊断数据集上取得了显著的性能提升，包括准确性的提高，Brier分数和预期校准误差（ECE）以及预测熵的降低。这一方法在量化LLMs不确定性方面表现出了创新性，特别是在改善其在关键领域的可靠部署中具有潜力。
### Conclusion
通过使用近似贝叶斯计算， researchers在两个临床相关的数据集上证明了该方法的优越性，相较于传统的基准方法，显著提高了准确性、降低了Brier分数，并改进了预测校准。这表明该方法为提高大型语言模型在高 stakes 和安全关键应用中的可靠性提供了有力支持。
## 68. `cs.AI` - 解决RAG中的新颖性问题：简单的近期优先级和启发式趋势检测的局限性 [PDF](https://arxiv.org/pdf/2509.19376), [HTML](https://arxiv.org/abs/2509.19376)
### Authors
Matthew Grofsky
### Background
研究领域已在指代消解生成（RAG）系统中面临时间失效的问题。为了应对这个问题，作者们在网络安全数据上使用了两种方法进行研究。
### Innovation
作者们提出了一种简单的近期优先级方法，该方法在新颖性任务上的准确率为1.00。相反，他们提出的一种用于主题演化的聚类启发式方法效果不佳，F1分数仅为0.08。这一结果表明，趋势检测需要超越简单启发式的方法。
### Conclusion
研究发现，简单的近期优先级方法能够很好地解决RAG系统中的新颖性问题，而传统的启发式方法不足以进行趋势检测。
## 69. `cs.AI` - OmniFed: 一种从边缘到HPC的可配置模块化联邦学习框架 [PDF](https://arxiv.org/pdf/2509.19396), [HTML](https://arxiv.org/abs/2509.19396)
### Authors
Sahil Tyagi,Andrei Cozma,Olivera Kotevska,Feiyi Wang
### Background
联邦学习（FL）对于边缘计算和高性能计算（HPC）至关重要，因为数据未集中存储且隐私保护需求强烈。
### Innovation
OmniFed 提出了一个模块化框架，该框架将配置、编排、通信和训练逻辑解耦并清晰分离。支持配置驱动的原型设计和代码级别的自定义功能。支持不同拓扑、单个部署中的混合通信协议和流行的训练算法。提供可选隐私机制（包括差分隐私、同态加密和安全聚合）以及压缩策略。所有这些功能都通过明确的扩展点展示，使用户能够在不破坏核心系统本身完整性的前提下自定义拓扑、编排、学习逻辑和隐私/压缩插件。
### Conclusion
通过将拓扑配置、混合协议通信和插件模块统一在一个堆栈中，OmniFed 使联邦学习部署跨异构环境更加简洁高效。
## 70. `cs.AI` - 从稀疏观测数据驱动重构显著波高 [PDF](https://arxiv.org/pdf/2509.19384), [HTML](https://arxiv.org/abs/2509.19384)
### Authors
Hongyuan Shi,Yilin Zhai,Ping Dong,Zaijin You,Chao Zhan,Qing Wang
### Background
从稀疏和不均匀的浮标观测重建高分辨率区域显著波高高度仍然是海洋监测和风险感知操作的核心挑战。
### Innovation
介绍了一种结合站级序列编码器（MLP）和多尺度U-Net以及瓶颈自注意力层的混合深度学习框架AUWave，以恢复32×32区域的显著波高场。通过系统性的贝叶斯超参数搜索确定学习率是泛化的主导因素，其次是调度器衰减和潜在维数。使用NDBC浮标观测和ERA5再分析数据，AUWave实现了最低验证损失0.043285和轻微右偏的均方根误差分布。空间误差在观测站点附近最低，并随着距离增加而增加，反映了在稀疏采样下的识别极限。通过对各种数据组进行敏感性实验，展示了与基准模型相比，AUWave在数据丰富的配置中始终表现出显著优于基准模型，而基准模型几乎在单浮标最不确定的情况下也只能勉强竞争。这种混合架构的多尺度和关注机制，在少量但非琐碎的空间锚定可用时，转化为准确性收益。通过错误图和浮标删除实验揭示了关键锚定站，其移除会显著降低性能，提供了网络设计的可操作指导。AUWave提供了一种可扩展的解决方案路径，用于填补数据空白、提供数据同化中的高分辨率先验和应急重建。
### Conclusion
AUWave为大尺度数据同化提供了高分辨率先验，同时为数据稀疏情况下的波高重构提供了应急重建方案。
## 71. `cs.AI` - Self-Alignment Learning to Improve Myocardial Infarction Detection from Single-Lead ECG [PDF](https://arxiv.org/pdf/2509.19397), [HTML](https://arxiv.org/abs/2509.19397)
### Authors
Jiarui Jin,Xiaocheng Fang,Haoyu Wang,Jun Li,Che Liu,Donglin Xie,Hongyan Li,Shenda Hong
### Background
心肌梗死是冠状动脉疾病的关键表现，但通过单导联心电图（ECG）检测它仍然具有挑战性，因为其空间信息有限。将单导联转换为多导联ECG进行分类的想法是直观的，但现有优化信号级别的生成方法通常未能填补潜在空间的空白，最终降低了诊断性能。因此，自然地提出了潜在空间对齐是否能帮助的问题。然而，之前的大多数ECG对齐方法专注于学习变换不变性，这与单导联检测的目标不匹配。为了解决这一问题，我们提出了一种称为SelfMIS的简单有效的对齐学习框架，以提高单导联ECG中的心肌梗死检测能力。
### Innovation
SelfMIS框架摒弃了手动数据增强，采用自我切割策略将多导联ECG与其对应的单导联段配对，并直接在潜在空间中对齐。实验结果表明，SelfMIS在九种心肌梗死类型上优于基准模型，且保持了更简单的结构和更低的计算开销，从而证明了直接潜在空间对齐的有效性。
### Conclusion
SelfMIS在单导联ECG的心肌梗死检测中表现出色，架构简化且计算成本较低，证实了直接对齐潜在空间的效用。相关代码和检查点将在接受后公开。
## 72. `cs.AI` - 通过双重阶段对齐和自我监督进行的快速校准脑-计算机接口的在线适应 [PDF](https://arxiv.org/pdf/2509.19403), [HTML](https://arxiv.org/abs/2509.19403)
### Authors
Sheng-Bin Duan,Jian-Long Hao,Tian-Yu Xiang,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Zeng-Guang Hou
### Background
脑电图（EEG）基脑-计算机接口（BCI）系统受到个体大脑活动差异的阻碍，无法在线应用于不同个体。为了克服这一限制，本文提出了一种通过双重阶段对齐和自我监督的在线适应算法，旨在能快速校准并适用于未见个体。
### Innovation
该研究提出了一个融合欧氏对齐和批量归一化统计更新的双重阶段对齐过程，并通过设计自我监督损失来更新解码器，该损失是通过从解码器计算出的软伪标签计算的，并经过香农熵校准以促进自我监督训练。该算法无需特定的BCI范式和解码器架构即可无缝集成，且通过单次在线试验迭代可以提高4.9%的静息状态闪光视觉诱发 potentials(SSVEP)和3.6%的运动想象准确性。
### Conclusion
该研究展示了所提算法能够在不同的BCI范式和解码器架构下实现快速校准，且具有较大的BCI应用潜力。
## 73. `cs.AI` - TimeMosaic: 根据时空异质性指导的时间序列预测通过自适应粒度片段和段级解码 [PDF](https://arxiv.org/pdf/2509.19406), [HTML](https://arxiv.org/abs/2509.19406)
### Authors
Kuiye Ding,Fanda Fan,Chunyi Hou,Zheya Wang,Lei Wang,Zhengxin Yang,Jianfeng Zhan
### Background
多元时间序列预测在金融、交通、气候和能源等领域至关重要。现有的基于片段的方法通常采用固定的长度分割，忽略了局部时间动态的异质性和预测解码的异质性。这样的设计会在信息密集区域丢失细节，在平稳段引入冗余，并且无法捕捉短期和长期趋势的不同复杂性。
### Innovation
TimeMosaic是一个旨在解决时间异质性的预测框架。它使用自适应片段嵌入动态调整粒度，根据局部信息密度进行调整，平衡象征重用与结构清晰度，同时保持时间连续性。此外，它引入了按段解码，将每个预测时距视为相关子任务，适应特定时距的难度和信息需求，而不是使用单一的均匀解码器。在基准数据集上的广泛评估表明，TimeMosaic在现有方法上提供了持续改进，并且我们的模型在321亿次观察的大规模语料库上训练，达到了与最先进的TSFMs相当的性能。
### Conclusion
实验结果表明，TimeMosaic在各个基准数据集上都实现了对现有方法的持续性能改进。特别是在大规模数据集上的表现，其模型与当前最先进的TSFMs相比能达到可竞争的性能。
## 74. `cs.AI` - ROPA: Synthetic Robot Pose Generation for RGB-D Bimanual Data Augmentation [PDF](https://arxiv.org/pdf/2509.19454), [HTML](https://arxiv.org/abs/2509.19454)
### Authors
Jason Chen,I-Chun Arthur Liu,Gaurav Sukhatme,Daniel Seita
### Background
训练稳健的双臂操作策略需要广泛的机器人姿态、接触点和场景上下文覆盖的示例数据。然而，收集多样且精确的现实世界示例数据成本高昂且耗时，这限制了其可扩展性。以往的工作主要针对具有RGB输入的眼在手中（手腕相机）的示例数据增强，或生成新的图像而不配对动作，对于眼在手中的RGB-D训练数据增强，生成新的动作标签方面较少探索。
### Innovation
本文提出了一种名为ROPA的方法，这是一种基于Stable Diffusion的离线模仿学习数据增强方法，用于生成新的机器人姿态的第三视角RGB和RGB-D观察值。该方法同时生成对应的关节空间动作标签，并通过合适的双臂场景中的夹具-物体接触约束来确保物理一致性。我们对5个模拟任务和3个现实世界任务进行了评估。
### Conclusion
我们的实验结果表明，ROPA在2625次仿真试验和300次现实世界试验中优于基线方法和部分消融实验，展示了其在眼在手RGB和RGB-D数据增强中的潜在可扩展性。
## 75. `cs.AI` - FedOC: 在无线边缘网络中具有重叠客户端中继的多服务器联邦学习 [PDF](https://arxiv.org/pdf/2509.19398), [HTML](https://arxiv.org/abs/2509.19398)
### Authors
Yun Ji,Zeyu Chen,Xiaoxiong Zhong,Yanan Ma,Sheng Zhang,Yuguang Fang
### Background
多服务器联邦学习（FL）作为一种解决单服务器FL通信瓶颈的有前景的解决方案而出现。本文聚焦于一种典型的多服务器FL架构，其中不同边缘服务器（ESs）覆盖区域可能有重叠，这意味着位于重叠区域的客户端能够同时从多个ESs访问边缘模型。在此基础上，本文提出了FedOC（具有重叠客户端的联邦学习）框架，旨在充分利用这些重叠客户端的潜力。
### Innovation
FedOC框架中的重叠客户端可以扮演双重角色：（1）作为中继重叠客户端（ROCs），它们会在边缘服务器之间实时转发边缘模型，促进不同边缘服务器之间模型的共享；（2）作为常规重叠客户端（NOCs），它们可以根据边缘模型交付时间动态选择初始模型进行本地训练，从而在不同的边缘服务器区域间接实现数据融合。通过这种方式，FedOC框架在每一轮中，每个客户端都会基于最早接收到的边缘模型进行本地模型训练，并将其传输给相应的ESs进行模型聚合。随后，每个ES会通过ROC中继将聚合的边缘模型传输给相邻的ESs。在接收到这些中继模型后，每个ES会进行二次聚合，并将更新后的模型广播给覆盖的客户端。通过ROC的存在，可以使得每个边缘服务器的模型以去中心化的方式传播到其他边缘服务器，从而间接地实现跨区模型的传播和加速训练过程，使其非常适用于敏感的边缘环境。
### Conclusion
广泛的实验结果表明，本文提出的方法与现有方法相比，具有显著的性能优势。
## 76. `cs.AI` - 视觉深度学习系统概率运行时验证、评估和风险评估 [PDF](https://arxiv.org/pdf/2509.19419), [HTML](https://arxiv.org/abs/2509.19419)
### Authors
Birk Torpmann-Hagen,Pål Halvorsen,Michael A. Riegler,Dag Johansen
### Background
尽管深度神经网络在基准测试中表现出色，但在实际部署中常常表现不佳，这是由于对输入数据中的细微变化（分布偏移）高度敏感，而这些变化通常不可察觉。这些变化在实际场景中很常见，但评测时却很少考虑，导致性能指标被虚增。为填补这一空白，本文提出了一种新的方法，用于深度学习系统的验证、评估和风险评估。该方法在运行时明确地建模分布偏移的发生概率，并结合网络正确性的条件概率，通过二叉树结构计算网络准确性的可靠和精确估计。
### Innovation
本文提出了一种新的方法，用于视觉深度学习系统的概率运行时验证、评估和风险评估。该方法主要创新点在于：在运行时估计分布偏移的发生概率，并结合网络正确性的条件概率，结构化为二叉树，通过遍历该树来计算网络准确性的可信和精确估计。相比传统的评估方式，该方法具有更小的准确性估算误差，通常在0.01到0.1之间。此外，本文通过医疗分割基准进一步展示了方法的应用潜力，通过将成本与树节点关联，支持成本效益分析和价值判断。
### Conclusion
本文提供了一种稳健的框架，以提高深度学习系统的可靠性和可信度，特别是在安全关键应用中，通过更准确的性能估计和可操作的风险评估措施。
## 77. `cs.AI` - 自适应仿生学习在模拟世界中的应用 [PDF](https://arxiv.org/pdf/2509.19460), [HTML](https://arxiv.org/abs/2509.19460)
### Authors
Yifan Ye,Jun Cen,Jing Chen,Zhihe Lu
### Background
近年来，模仿学习已经成为了研究的热点领域，但训练可以处理多种任务的一般型智能体仍然需要大量的专家演示数据，这些数据的收集过程复杂且耗时成本高。为了应对监督有限的挑战，本文提出了Self-Evolved Imitation Learning (SEIL)框架，该框架通过与模拟器的互动逐步提升少量起始模型的表现。
### Innovation
SEIL框架包含了一种新的多级增强机制：在智能体层面，通过使用指数移动平均（EMA）模型与主模型合作；在环境层面，引入轻微的对象起始位置变化，以提高演示数据的多样性。此外，还引入了一个轻量级筛选器来过滤生成池中的互补且有信息量的轨迹，确保演示质量。这些精心挑选的样本使模型能够在更少的训练样本情况下达到与之前相似的成绩。
### Conclusion
在LIBERO基准测试上的广泛实验结果表明，SEIL在少样本模仿学习场景中达到了新的最佳性能。源代码可在以下链接获取：this https URL
## 78. `cs.AI` - EngravingGNN：端到端钢琴乐谱印刷的一种混合图神经网络方法 [PDF](https://arxiv.org/pdf/2509.19412), [HTML](https://arxiv.org/abs/2509.19412)
### Authors
Emmanouil Karystinaios,Francesco Foscarin,Gerhard Widmer
### Background
本文聚焦于自动音乐印刷，即从音乐内容生成能够为人阅读的乐谱这一步骤。这一步骤在包含人类演奏者的所有应用程序中都至关重要，但在符号音乐处理领域仍是一个未得到充分探索的主题。本文将问题视为一系列相互依赖的子任务集合，并提出一个统一的图神经网络（GNN）框架，针对钢琴音乐和量化的符号输入。该方法使用一个多任务GNN共同预测声部连接、五线谱分配、音高标记、调式符号、音符方向、八度跃迁和谱号标志。
### Innovation
提出了一种多任务GNN框架，用于同时预测多个音乐印刷任务（声部连接、五线谱分配、音高标记、调式符号、音符方向、八度跃迁和谱号标志），并采用专门的后处理流水线生成印刷就绪的MusicXML/MEI输出。通过两个不同的钢琴曲集（J-Pop和DCML浪漫）进行全面评估表明，统一模型在所有子任务中都表现出良好的准确性，与仅针对特定子任务的现有系统相比，这种方法表明共享GNN编码器与轻量级的任务特定解码器在多任务设置下的方法提供了自动音乐印刷的可扩展且有效的解决方案。
### Conclusion
本研究提出的统一模型在所有子任务中都表现良好，能够有效解决自动音乐印刷的问题，并展示了在多任务框架下结合图神经网络的潜在优势。
## 79. `cs.AI` - 跨频次迁移学习和基础预测模型的现实评估 [PDF](https://arxiv.org/pdf/2509.19465), [HTML](https://arxiv.org/abs/2509.19465)
### Authors
Kin G. Olivares,Malcolm Wolff,Tatiana Konstantinova,Shankar Ramasubramanian,Andrew Gordon Wilson,Andres Potapczynski,Willa Potosnak,Mengfei Cao,Boris Oreshkin,Dmitry Efimov
### Background
跨频次迁移学习（CFTL）已经成为一个流行的框架，用于收集大规模时间序列数据集以预训练基础预测模型（FFMs）。尽管CFTL显示出潜力，但当前的基准测试实践无法准确评估其性能。这些基准测试的不足之处主要源于对小型评估数据集的过度依赖，计算汇总统计时未充分处理样本大小，报告次优统计模型，以及未考虑训练数据集和测试数据集之间的非忽略交叠风险。
### Innovation
作者引入了一个统一的重新实现广泛采用的神经预测网络，适应CFTL设置；仅在内部和合成数据上进行预训练，以防止测试泄漏；并在15个大而多样的公共预测比赛数据集上进行评估。实证分析表明统计模型的准确性经常被低估。研究确认统计模型及其集成显著优于现有FFMs，sCRPS方面超过8.2%，MASE方面超过20%，在各个数据集中均有所体现。但研究人员还发现，使用合成数据集预训练可以提高FFM的准确性，达到7%。
### Conclusion
统计模型在报告中经常表现出的未优化度表明，其性能往往被低估。研究结果表明，统计模型和它们的集成显著优于现有的FFM，在多个关键指标上显著提升。尽管使用合成数据集预训练可以提升FFM的准确性，但统计和集成模型仍然表现出更优的表现。
## 80. `cs.AI` - ArtiFree：检测和减少基于扩散的语音增强中的生成性 artifacts [PDF](https://arxiv.org/pdf/2509.19495), [HTML](https://arxiv.org/abs/2509.19495)
### Authors
Bhawana Chhaglani,Yang Gao,Julius Richter,Xilin Li,Syavosh Zadissa,Tarun Pruthi,Andrew Lovitt
### Background
基于扩散的语音增强（SE）能够实现自然的语音效果和强大的泛化能力，但存在生成性缺陷（如生成性伪影）和较高的推理延迟等关键限制。
### Innovation
本文系统地研究了基于扩散的语音增强中的伪影预测和减少方法。提出了一种利用语音嵌入的方差预测推理过程中语音学错误的增强方法，并基于此提出了一个由多次扩散运行的语义一致性指导的集成推理方法，能够减少低信噪比条件下的错误率（WER）15%，提升语音学准确性和语义合理性。此外，分析了扩散步骤数量的影响，表明自适应扩散步骤可以平衡伪影抑制和延迟。
### Conclusion
研究结果强调了语义先验作为指导生成性语音增强的核心工具，可以引导生成结果减少伪影输出。
## 81. `cs.AI` - 使用较小的LLM识别和解决智能家居中的用户级安全问题 [PDF](https://arxiv.org/pdf/2509.19485), [HTML](https://arxiv.org/abs/2509.19485)
### Authors
Hafijul Hoque Chowdhury,Riad Ahmed Anonto,Sourov Jajodia,Suryadipta Majumdar,Md. Shohrab Hossain
### Background
随着智能家居IoT设备的迅速增长，用户面临越来越多的安全风险。用户在依赖在线博客和技术手册获取信息时，这些来源复杂且可能难以理解，这与智能家居用户的常见思维模式不符，进一步威胁了智能家居的安全性。因此，该研究旨在识别并解决智能家居中的主要用户级安全问题，通过建立一个Q&A系统来帮助用户应对智能家居IoT设备的常见安全问题，旨在提高系统的准确性和相关性，增强智能家居的安全性.
### Innovation
研究人员开发了一个由公开论坛上的Q&A组成的新数据集，利用Latent Dirichlet Allocation (LDA)提取主要的安全挑战。他们还对较小的transformer模型，如T5和Flan-T5，进行了微调，用于构建专门为智能家居安全定制的Q&A系统。相比于大型模型如GPT和Gemini，使用较小模型可以在资源有限或隐私敏感的环境中更易部署。研究者还手动整理数据集并补充了合成数据，以评估其对模型性能的影响，从而显著提高了系统回答准确性与相关性.
### Conclusion
实验证明，本研究通过构建专门针对智能家居安全的Q&A系统，显著提高了基模型的性能，有效应对了用户在使用智能家居IoT设备时的安全问题，为用户提供了更准确、更有针对性的安全建议与解决方案.
## 82. `cs.AI` - AIRwaves在CheckThat! 2025：使用双编码器和神经再排序检索社交媒体上的隐式声明的科学来源 [PDF](https://arxiv.org/pdf/2509.19509), [HTML](https://arxiv.org/abs/2509.19509)
### Authors
Cem Ashbaugh,Leon Baumgärtner,Tim Gress,Nikita Sidorov,Daniel Werner
### Background
在社交媒体上隐式声明与原始出版物之间建立联系对于基于证据的事实核查和学术交流至关重要，但这一过程受到词汇稀疏性、非常短的查询以及领域特定语言的阻碍。CLEF-2025 CheckThat! Lab的Subtask 4b中，AIRwaves以明显优于竞争基线的方法获得第二名。优化后的BM25基线在黄金标签盲测试集上实现了MRR@5 = 0.5025。
### Innovation
引入了一种两阶段检索管道：第一阶段使用E5-large的双编码器，结合内部批中和开采的负样本进行微调，并通过分块标记化和丰富的文档元数据增强；第二阶段利用SciBERT交叉编码器进行神经再排序。通过使用神经表示而不是纯词汇匹配，性能提升到了MRR@5 = 0.6174，完整管道进一步提升至MRR@5 = 0.6828。
### Conclusion
研究发现，结合密集检索与神经再排序器为推文到研究匹配提供了强有力的和高效的解决方案，并为未来的证据检索管道提供了可行的蓝图。
## 83. `cs.AI` - 生成式人工智能作为民主创新的催化剂：增强参与式预算中的公民参与 [PDF](https://arxiv.org/pdf/2509.19497), [HTML](https://arxiv.org/abs/2509.19497)
### Authors
Italo Alberto do Nascimento Sousa,Jorge Machado,Jose Carlos Vaz
### Background
面对公民参与下降和社会 Polarization 加剧的挑战，本研究探讨了在线政治参与如何加强民主并促进社会公平。研究旨在通过将生成式人工智能集成到公共咨询平台中，提高公民提案的形成质量，并促进公民与政府之间的有效对话。研究还评估了政府实施增强型参与工具所需的技术能力和潜在的脆弱性。
### Innovation
研究通过分析技术结构、参与者、利益和策略，进一步理解了技术进步如何重塑参与机构，以更好地促进公民参与。研究特别关注了生成式人工智能在促进公民参与中的角色，如何使之成为民主创新的催化剂，从而提升公民参与式预算的效率和公平性.
### Conclusion
生成式人工智能能够改变公民参与的机构结构，促进更加包容和民主的参与，并赋予公民力量。研究强调了生成式人工智能在参与式预算中的潜力及其对民主创新的重要性。
## 84. `cs.AI` - 使用伴侣聊天机器人的纵向随机对照研究：拟人化及其对社交影响的中介作用 [PDF](https://arxiv.org/pdf/2509.19515), [HTML](https://arxiv.org/abs/2509.19515)
### Authors
Rose E. Guingrich,Michael S. A. Graziano
### Background
社交人工智能代理（如聊天机器人Replika）与人类的关系正在增加，人们可能会将这些聊天机器人视为朋友、导师甚至是伴侣。有关使用这些伴侣聊天机器人可能损害或替代人类关系的担忧已经提出，但这些社交影响的具体表现形式仍然不清楚。先前的研究表明，人们的社会需求状态及其对聊天机器人的人类特质（拟人化）感知可能影响人类与AI互动对人类互动的影响。
### Innovation
本研究通过一项纵向随机对照试验（N = 183），观察了伴侣聊天机器人对人类社会健康和关系的影响，并探讨了拟人化在其中的中介作用。研究发现，长期与伴侣聊天机器人互动并没有显著影响人类的社会健康和关系。其中，更渴望社交连接的人更倾向于将聊天机器人拟人化，这种拟人化对人类互动和社会关系产生了更大的影响。
### Conclusion
研究结果表明，人类与AI互动对人类社交结果的影响是由人们对于AI代的选择性拟人化程度中介的，而拟人化的程度又与人类渴望建立社交连接的需求相关。这种影响机制对了解人类如何与AI互动以及它们如何影响人类的社会生活具有重要意义。
## 85. `cs.AI` - Heterogeneous Multi-Agent Challenge [PDF](https://arxiv.org/pdf/2509.19512), [HTML](https://arxiv.org/abs/2509.19512)
### Authors
Charles Dansereau,Junior-Samuel Lopez-Yepez,Karthik Soma,Antoine Fagette
### Background
多智能体强化学习（MARL）是一个正在增长的研究领域，特别是在近年来逐渐受到重视。它将深度强化学习（Deep RL）的应用扩展到更广泛的场景。特别是在Heterogeneous Multi-Agent Reinforcement Learning（HeMARL）中，拥有不同传感器、资源或能力的智能体需要基于局部信息进行合作。由于现实世界中涉及异构智能体的情况很多，这一领域具有吸引力但尚未充分探索，因为大多数MARL研究集中在同构智能体（例如，一群相同的机器人）上。在MARL和单智能体RL中，已经有许多标准化环境（如ALE和SMAC）有助于建立基准来衡量进展，但在合作HeMARL方面缺乏标准化的测试平台。
### Innovation
由于缺乏适合HeMARL的标准测试平台，本研究旨在填补这一空白，着重于Heterogeneous Multi-Agent Reinforcement Learning（HeMARL）的研究，特别是在缺乏标准化测试场景的情况下，新研究往往依赖于过于简单或异构不足的环境，这阻碍了有效评估和推进算法。
### Conclusion
研究指出了当前HeMARL领域的一个关键问题——缺乏标准测试平台，同时提出了解决这一问题的必要性，强调了需要专门针对HeMARL问题设计和评估算法的重要性，以推动这一领域的进一步发展。
## 86. `cs.AI` - DAWM: 基于动作推理过渡的弥散行动世界模型在离线强化学习中的应用 [PDF](https://arxiv.org/pdf/2509.19538), [HTML](https://arxiv.org/abs/2509.19538)
### Authors
Zongyue Li,Xiao Han,Yusong Li,Niklas Strauss,Matthias Schubert
### Background
基于弥散的世界模型在离线强化学习中展示了强大的合成长期轨迹的能力。然而，许多现有方法未能直接生成动作和奖励，这限制了其与依赖一步骤时差（TD）学习的标准基于值的离线RL算法的兼容性。尽管先前的工作已经探索了状态、奖励和动作的联合建模以解决此问题，但这些方法常常导致训练复杂性增加并在实际中表现出降低的性能。这些基于弥散的方法通常无法直接处理RL中的动作生成问题，导致了在实际应用中的效率低下和兼容性问题。
### Innovation
作者提出了一种新的弥散行动世界模型（DAWM），该模型通过当前状态、动作和剩余回报条件生成未来的状态-奖励轨迹，并配以逆动力学模型（IDM），以进行高效的动作推理。这种模块化设计能够产生适合一步骤TD基础的离线RL的完整合成过渡，从而实现有效的、计算效率高的训练。实验证明，保守的离线RL算法，如TD3BC和IQL，在这些增强轨迹上训练可以显著受益，多个D4RL基准测试任务中表现明显更好，优于先前的基于弥散的方法。
### Conclusion
DAWM 模型通过结合条件生成和逆动力学模型提高了离线RL的性能和效率，解决了标准值基础离线RL算法在处理复杂动作生成问题上的兼容性问题。
## 87. `cs.AI` - 一种用于全面基于片段的药物发现的基础化学语言模型 [PDF](https://arxiv.org/pdf/2509.19586), [HTML](https://arxiv.org/abs/2509.19586)
### Authors
Alexander Ho,Sukyeong Lee,Francis T.F. Tsai
### Background
近年来，药物发现领域的研究越来越多地转向使用基于片段的方法，这种方法能够高效地生成和筛选大量的化学片段，以发现潜在的新药分子。然而，现有的基础模型在处理和生成化学片段方面的表现有限，无法覆盖化学片段的空间并满足药物发现的需求。
### Innovation
本文引入了一种专门针对最大的片段数据集训练的基础模型——FragAtlas-62M。该模型基于完整的ZINC-22片段子集，包含超过6200万种分子，实现了前所未有的化学片段空间覆盖。基于GPT-2的模型可以生成99.90%的化学有效片段，且在12个分子描述符和三种指纹方法的验证中表现出色，生成的片段与训练分布高度一致（所有效应大小均小于0.4）。此外，模型保留了53.6%已知的ZINC片段，同时产生22%具有实际相关性的新颖结构。
### Conclusion
FragAtlas-62M模型通过其卓越的化学片段生成能力，有望加速并改进基于片段的药物发现过程。研究人员已公开了该模型的训练代码、预处理数据、文档和模型权重，以促进广泛采用。
## 88. `cs.AI` - 深度学习的动力学：深度神经网络的力分析 [PDF](https://arxiv.org/pdf/2509.19554), [HTML](https://arxiv.org/abs/2509.19554)
### Authors
Yi Ren
### Background
该论文探讨了深度学习模型随着时间的学习过程，采用了灵感来自力分析的概念。具体来说，研究者聚焦模型的训练过程，分析一个训练样本如何影响另一个样本的学习过程，类似于分析力如何移动物体的过程。本文框架被用于理解不同真实系统中模型行为的广泛现象。该框架帮助解释了为什么某些例子具有非平凡的学习路径，为什么（或为什么不能）一些大模型微调方法有效，以及为什么更简单、更加有序的模式更容易被学习。
### Innovation
论文创新地将深度学习的训练过程分解为两个部分：类似性和更新力的强度。提供了一种新的系统性解释模型行为的方法，有助于揭示新的改进模型训练策略。
### Conclusion
这种方法虽然仍在发展中，但为系统解释模型行为提供了新的视角，揭示了改进模型训练的新策略。
## 89. `cs.AI` - GuessingGame：评估大型语言模型开放式问题信息量的方法 [PDF](https://arxiv.org/pdf/2509.19593), [HTML](https://arxiv.org/abs/2509.19593)
### Authors
Dylan Hutson,Daniel Vennemeyer,Aneesh Deshmukh,Justin Zhan,Tianyu Jiang
### Background
论文介绍了GuessingGame，一种评估大型语言模型（LLMs）作为具有策略性的提问者在开放式、跨领域场景中的表现的协议。Guesser LLM能够识别隐藏对象，通过提出自由形式的问题向Oracle提问，而无需事先定义的选择或候选列表。通过两个信息增益（IG）评估问题质量的方法测量问题质量：一种使用LLM评分相关性的贝叶斯方法，通过跟踪概念的信念更新；另一种基于熵的方法，通过ConceptNet过滤候选列表。这些指标对模型具有通用性，并支持后续分析。
### Innovation
引入了GuessingGame协议，提出了两种衡量问题质量的方法，分别是基于贝叶斯的方法和基于熵的方法。这些方法消除了对预先定义的选择或候选列表的依赖，使评估更加灵活。结果显示，指导提问策略的信息增益可以显著提升较弱模型的性能，体现了问题询问在LLMs中的可测量性和改进的潜力。
### Conclusion
研究表明，问题询问是可度量和可改进的，对于交互式推理至关重要。当基于信息增益的变化调整提问策略时，即使是较弱的模型也可以实现显著的性能提升。
## 90. `cs.AI` - 通过移动数据增强提高多小区指纹定位的室外定位 [PDF](https://arxiv.org/pdf/2509.19405), [HTML](https://arxiv.org/abs/2509.19405)
### Authors
Tony Chahoud,Lorenzo Mario Amorosa,Riccardo Marini,Luca De Nardis
### Background
在蜂窝网络中实现准确的室外定位受到稀疏和异质的测量集合以及彻底的现场勘查高成本的阻碍。本文提出了一种轻量级和模块化的移动数据增强框架，以增强基于多小区指纹的定位，该框架利用运营商收集的最小驱车测试记录（MDT）。这种方法将空间特征和无线电特征的合成分离：核密度估计（KDE）模型生成地理上一致的合成位置来描述经验空间分布，而基于k近邻（KNN）的方法生成每个小区的增强无线电指纹。该架构是无需训练的、可解释的，适用于分布式的或在本地设备上的运营商部署，并支持隐私意识的工作流程。
### Innovation
提出了一种采用KDE和KNN方法的轻量级和模块化移动数据增强框架，以增强基于多小区指纹的定位效果。该方法将空间特征和无线电特征的合成分离，并利用运营商收集的最小驱车测试记录进行增强，提升了定位精度，特别是在采样稀疏或结构复杂区域。
### Conclusion
实验结果表明，提出的KDE-KNN增强方法在定位性能方面表现优良，尤其是在采样稀疏或结构复杂区域，同时观察到随着增强量的变化区域依赖的饱和效应。该框架提供了一种实用且低复杂度的方法，用于利用现有的移动数据轨迹改进运营定位服务。
## 91. `cs.AI` - 语义感知模糊测试：一种基于LLM引导的推理驱动输入突变的实证框架 [PDF](https://arxiv.org/pdf/2509.19533), [HTML](https://arxiv.org/abs/2509.19533)
### Authors
Mengdi Lu,Steven Ding,Furkan Alaca,Philippe Charland
### Background
互联网Of事物（IoT）设备、移动平台和自主系统中的安全漏洞仍然至关重要。传统的基于变异的模糊测试工具尽管能够有效探索代码路径，但主要进行字节级或位级编辑，缺乏语义推理能力。尽管覆盖引导式工具如AFL++使用字典、文法和连接启发式规则来施加浅层次的结构约束，但尚未解决深层协议逻辑、字段间依赖性和特定领域的语义问题。相比之下，推理能力强大的大型语言模型（LLMs）能够利用预训练知识理解输入格式、尊重复杂约束并提出有针对性的突变，类似于资深的逆向工程师或测试专家。但由于缺乏突变正确性的真实标准，基于监督微调的方法不可行，因此激发了通过提示驱动的少样本学习来探索现成LLM的动机。
### Innovation
介绍了将推理LLMs与AFL++集成到模糊测试突变循环中的一种开源微服务框架，该框架旨在解决异步执行和LLMs与模糊器之间不同的硬件需求。本文还评估了四个研究问题：（R1）推理LLMs如何整合到模糊测试突变循环中？（R2）少样本提示是否能产生更高质量的突变？（R3）是否有通过现成模型的提示工程直接改进模糊测试的有效性？（R4）在仅提示条件下，哪种开源推理LLMs表现最佳？实验证明了Deepseek在这些LLMs中最为出色。突变效果更取决于提示复杂度和模型选择，而不是样本数量。响应延迟和吞吐量瓶颈仍是最关键的障碍，提供了未来工作方向。
### Conclusion
实验结果显示，尽管突变效果更多依赖于提示复杂度和模型选择，而不是样本数量，但响应延迟和吞吐量仍是最关键的障碍。Deepseek被确定为最有可能的LLM，而未来研究方向可能集中在进一步优化响应时间和提高吞吐量上。
## 92. `cs.AI` - 使用大型语言模型从代码中逆向工程用户故事 [PDF](https://arxiv.org/pdf/2509.19587), [HTML](https://arxiv.org/abs/2509.19587)
### Authors
Mohamed Ouf,Haoyu Li,Michael Zhang,Mariam Guizani
### Background
用户故事对于敏捷开发至关重要，但在旧系统和文档记录不足的系统中往往缺失或过时。研究发现，大型语言模型（LLMs）能够自动从源代码中恢复用户故事，研究探讨了提示设计如何影响输出质量。
### Innovation
使用1,750个标注过的C++代码片段，评估了五种最先进的大型语言模型，在六种不同的提示策略下。研究发现，单个示例可以使较小的模型（8B）达到与更大模型（70B）相同的性能。此外，结构化推理通过链式思考仅在较大模型中提供边际收益，这表明较小模型在特定条件下的优越性。
### Conclusion
所有模型在200 NLOC及以下的代码中平均实现0.8的F1分数。单个示例有效提升了小型模型的表现，而结构化思考则对提升大模型性能的帮助不大。
## 93. `cs.AI` - 我们在对什么进行扩展？一种测试时间扩展的系统视角 [PDF](https://arxiv.org/pdf/2509.19645), [HTML](https://arxiv.org/abs/2509.19645)
### Authors
Youpeng Zhao,Jinpeng LV,Di Wu,Jun Wang,Christopher Gooley
### Background
近年来，测试时扩展（TTS）已成为挖掘预训练大型语言模型（LLMs）潜在推理能力的一种有前途的方法。现有的扩展方法过于关注计算最优的帕累托前沿，而忽略了计算最优并不总是系统最优这一事实。
### Innovation
本文提出了一个基于系统的视角来考虑TTS，分析推理模型如何在实际指标（如延迟和每词成本）上扩展。通过评估当前流行的优化技术如张量并行和推测性解码的影响，初步分析揭示了现有方法的局限性，并呼吁向全面、系统意识的评估转变，以捕捉推理时间真实扩展规律的本质。
### Conclusion
现有方法忽略了计算最优不一定等同于系统最优这一事实，建议从系统视角出发进行全面、综合的评估，以揭示推理模型在实际应用中如何更有效地扩展以捕捉推理时间的真正扩展规律。
## 94. `cs.AI` - 效率提升多码本语音生成的帧堆叠局部transformer [PDF](https://arxiv.org/pdf/2509.19592), [HTML](https://arxiv.org/abs/2509.19592)
### Authors
Roy Fejgin,Paarth Neekhara,Xuesong Yang,Edresson Casanova,Ryan Langman Jaehyeon Kim,Subhankar Ghosh,Shehzeen Hussain,Jason Li
### Background
基于大型语言模型的语音生成模型通常处理离散的声学代码，这些代码与文本标记在多码本结构上存在根本差异。在每一时间步，模型需要联合预测N个码本条目，这引入了挑战简单并行预测方法的依赖性。平行预测假设码本之间的独立性，从而实现高效解码，但可能会导致保真度较低。现有的层次策略使用局部变换器（LT）来细化预测并捕捉时间步内的依赖性，通过顺序生成码本或迭代掩码预测来实现此目标。这些设计还使帧堆叠成为可能，在这种情况下，主变压器联合预测多个帧，局部变压器解码它们的码本，从而在不影响感知质量的前提下提高速度。
### Innovation
该研究系统性地考查了两种局部变换器（LT）架构：自回归变换器和基于MaskGIT的迭代掩码预测变换器。这两种设计都进一步支持帧堆叠，即主变压器联合预测多个帧，局部变压器解码它们的码本，从而实现了速度的提升，同时不影响感知质量。通过广泛的分析，该研究描述了不同吞吐量和质量范式下并行和迭代采样策略之间的权衡。
### Conclusion
最后，该研究提出了基于部署优先级（如计算效率和合成保真度）选择解码策略的实用指南。
## 95. `cs.AI` - 6G现状：演进、使能技术和研究差距 [PDF](https://arxiv.org/pdf/2509.19646), [HTML](https://arxiv.org/abs/2509.19646)
### Authors
Salma Tika,Abdelkrim Haqiq,Essaid Sabir,Elmahdi Driouch
### Background
随着第五代（5G）移动通信系统的全球部署，行业和学术界已经开始构想第六代（6G）以满足日益增长的对更具先进性和数字化社会的需求。尽管5G相比LTE提供了显著的改进，但它可能难以满足所有要求，包括超高的可靠性和无缝自动化以及广泛的覆盖。因此，6G被认为将带来一个高度智能化、自动化和超可靠的通信系统，能够处理大量的连接设备。
### Innovation
该论文提供了一个对6G的全面概述，重点是其主要的严格要求，着重介绍能够塑造6G网络的关键使能技术，如太赫兹（THz）通信、智能反射表面、大规模MIMO和AI驱动的网络。此外，论文还列出了将从这些进步中受益的各种6G应用和使用场景。
### Conclusion
在文章结尾，概述了必须解决的潜在挑战，以实现6G的承诺。
## 96. `cs.AI` - 利用强化学习提升多模态LLM的语音摘要能力 [PDF](https://arxiv.org/pdf/2509.19631), [HTML](https://arxiv.org/abs/2509.19631)
### Authors
Shaoshi Ling,Gang Liu,Guoli Ye,Jinyu Li
### Background
语音摘要是理解语音内容的关键组成部分，特别是在演讲和音频视觉数据快速增长的时代。最近，多模态大语言模型（MLLMs）的进步，利用了LLMs的强大功能，能够直接从语音生成文本摘要，而无需中间转录，并支持可控样式和零样本泛化。然而，开源的MLLMs仍然落后于最先进的文本基于的大语言模型，这限制了它们在语音摘要中的实际部署。
### Innovation
本研究提出了一种新颖的多阶段强化学习训练框架，以增强MLLMs的语音摘要能力。该模型在强基线模型上取得了显著改进，超越了更大的MLLMs，并显著缩小了与最先进的文本基于的大语言模型之间的差距。
### Conclusion
我们的模型在多模态大语言模型中的语音摘要能力方面取得了实质性改进，超越了强大的基线模型，优于更大的多模态大语言模型，并显著缩小了与最先进的文本基于大语言模型之间的差距。
## 97. `cs.AI` - Mamba Modulation: 关于Mamba在长度泛化方面的研究 [PDF](https://arxiv.org/pdf/2509.19633), [HTML](https://arxiv.org/abs/2509.19633)
### Authors
Peng Lu,Jerry Huang,Qiuhao Zeng,Xinyu Wang,Boxing Wang,Philippe Langlais,Yufei Cui
### Background
Transformer模型中的注意力机制具有二次时间复杂度，这促使开发出具有亚二次时间复杂度的替代架构，如状态空间模型。Mamba已被证明是最具竞争力的架构之一，但在面对超出现有训练上下文长度的任务时性能显著下降，表现出对上下文长度的敏感性。这种敏感性通常被归因于时间步长中的细节累积消失现象。本文通过详细分析，将这种性能下降归因于状态演化行为，特别是在状态转移矩阵A的参数化上，揭示了状态空间的谱特征与序列长度扩展之间的紧密联系，提供了对这种长度扩展敏感性的理论解释。
### Innovation
本文提出了一种利用状态转移矩阵A的谱缩放方法，改善Mamba模型在长上下文的应用，并且验证了简单调整时间步长$triangle_t$无法有效解决问题时，这种调整方法的优越性。这为具有良好结构的转移矩阵的状态空间模型提供了更好的长度泛化策略。
### Conclusion
通过对Mamba模型状态转移矩阵A的谱特征进行调节，本文提出的方法能够显著提高模型在具有长上下文的场景中的性能，为状态空间模型的长度泛化提供了理论依据和实际应用途径。
## 98. `cs.AI` - Knowledge Base-Aware Orchestration: 一种动态的、保护隐私的方法用于多智能体系统 [PDF](https://arxiv.org/pdf/2509.19599), [HTML](https://arxiv.org/abs/2509.19599)
### Authors
Danilo Trombino,Vincenzo Pecorella,Alessandro de Giulii,Davide Tresoldi
### Background
多智能体系统(MAS)越来越多地被用来解决复杂的知识密集型问题，有效的智能体编排至关重要。传统的编排方法依赖于静态的智能体描述，这些描述往往变得过时或不完整。这种限制导致在动态环境中任务路由不高效，因为智能体的能力持续演变。传统的编排方法无法适应环境的变化，导致任务分配不精准，尤其是在动态环境中，智能体的能力会持续变化，静态描述往往不够准确，导致路由决策不清晰，从而影响系统效率和精度。
### Innovation
我们提出了知识库感知(KBA)编排，这是一种新颖的方法，通过将动态的、保护隐私的相关性信号与每个智能体内部的知识库结合到静态描述中，来解决这一问题。该方法在框架中实现，当静态描述不足以做出明确的路由决策时，编排器并行地提示子智能体。每个智能体将任务的相关性与私有的知识库进行评估，返回一个轻量级的ACK信号，而不暴露底层数据。收集到的信号填充共享语义缓存，为未来的查询提供了动态的智能体适用性指示。通过结合这种新机制与静态描述，我们的方法实现了更加准确且适应性强的任务路由，同时保持了智能体的自主性与数据机密性。研究表明，我们的KBA编排显著优于基于静态描述的方法，在路由精度和整体系统效率上表现更好，适用于需要比标准描述驱动路由更高的准确性的大型系统。
### Conclusion
我们的KBA编排方法通过结合静态描述和动态、保护隐私的相关信号，实现更准确、更适应性强的任务路由，同时增强系统的动态性和智能体的自主性。基准测试显示，与基于静态描述的方法相比，我们的方法在路由精度和系统效率方面表现更优，特别适用于要求更高准确性的大型系统。
## 99. `cs.AI` - PolicyPad：LLM政策的协作快速原型设计 [PDF](https://arxiv.org/pdf/2509.19680), [HTML](https://arxiv.org/abs/2509.19680)
### Authors
K. J. Kevin Feng,Tzu-Sheng Kuo,Quan Ze(Jim)Chen,Inyoung Cheong,Kenneth Holstein,Amy X. Zhang
### Background
随着LLM在高风险领域（如心理健康）中的普及，领域专家被越来越多地咨询以提供相关政策制定行为的指导。通过对9位专家在15周内的19次政策制定工作坊的观察，研究发现强化政策制定过程中快速实验、反馈和迭代的机会。
### Innovation
提出了一套交互式系统——PolicyPad，它借鉴了用户体验原型设计实践（如启发式评估和故事板）来支持LLM政策原型设计。通过PolicyPad，政策设计者可以实时协作制定政策，并独立测试基于政策的模型行为。
### Conclusion
通过在心理健康和法律领域的22位领域专家组成的8个小组中的工作坊评估，PolicyPad促进了政策设计中的协作动力，实现了紧密的反馈循环，并促进了新的政策贡献。整体而言，这项工作铺平了参与途径，以推进AI对齐和安全。
## 100. `cs.AI` - DyBBT: 通过类 Bandit 的目标选择实现认知双系统对话策略的动态平衡 [PDF](https://arxiv.org/pdf/2509.19695), [HTML](https://arxiv.org/abs/2509.19695)
### Authors
Shuyu Zhang,Yifan Wei,Jialuo Yuan,Xinru Wang,Yanmin Zhu,Bin Li
### Background
任务导向的对话系统通常依赖于静态探索策略，这些策略无法适应动态对话环境，导致探索效率低下且性能不佳。
### Innovation
提出了 DyBBT，一种新的对话策略学习框架，通过结构化的认知状态空间捕捉对话进程、用户不确定性以及槽位依赖关系来正式定义探索挑战。DyBBT 提出了一种基于类 Bandit 的元控制器，该控制器可以基于实时的认知状态和访问计数动态切换为快速直觉推理（系统1）和缓慢详尽推理（系统2）。
### Conclusion
在单领域和多领域的基准测试中，DyBBT 在成功率、效率和泛化能力方面均达到了最先进的表现，同时人类评估也证实了其决策与专家判断高度一致。
## 101. `cs.AI` - 大语言模型在行人安全中的应用：无信号交叉口驾驶员礼让行为预测 [PDF](https://arxiv.org/pdf/2509.19657), [HTML](https://arxiv.org/abs/2509.19657)
### Authors
Yicheng Yang,Zixian Li,Jean Paul Bizimana,Niaz Zafri,Yongfeng Dong,Tianyi Li
### Background
行人安全是城市交通中的一个关键组成部分，受到行人决策和驾驶员在人行横道处礼让行为的交互影响。模型驾驶员-行人的交互需要准确捕捉这些行为的复杂性。传统的机器学习模型由于依赖固定的特征表示和有限的解释性，在捕捉多因素交互的复杂推理时常常力不从心。相比之下，大语言模型(LLMs)适合从异构交通数据中提取模式，从而使对驾驶员-行人交互的准确建模成为可能。因此，本研究通过一种新颖的提示设计利用多模态大语言模型，将领域专业知识、结构化推理和少样本提示结合在一起，以驾驶员礼让行为为例，实现可解释的上下文感知推理，作为建模行人-驾驶员交互的应用实例。
### Innovation
本研究采用大语言模型进行驾驶员礼让行为预测，并通过新颖的提示设计将领域专业知识、结构化推理和少样本提示相结合，实现了可解释的上下文感知推理，从而对驾驶员礼让行为进行建模。研究还对比了最先进的大语言模型和传统分类器，在准确性、召回率和精确度等方面对模型进行了评估，提供了部署大语言模型在现实世界的行人安全系统中的实用指导。
### Conclusion
研究发现，GPT-4o在准确性和召回率方面始终表现最佳，而Deepseek-V3在精确度方面表现卓越。这些结果强调了模型性能与计算效率之间的关键权衡，为部署大语言模型在行人安全系统中提供了实用建议。
## 102. `cs.AI` - 倾听中思考：音频分类中的简单测试时扩展 [PDF](https://arxiv.org/pdf/2509.19676), [HTML](https://arxiv.org/abs/2509.19676)
### Authors
Prateek Verma,Mert Pilanci
### Background
该研究基于近期语言模型推理能力的提升，旨在开发一种框架，使神经模型能够边听边思考，从而提高音频分类性能。研究关注如何在现有音频分类流水线中加入思考机制，以增强类别的推理能力，以及是否可以设计一个新的架构以支持在测试时间上的可扩展性。
### Innovation
该论文提出了一个框架，使神经模型能够在听取日常声音时进行推理，从而提高音频分类的性能。研究通过引入测试时间上的扩展来验证改进的效果，并展示了在两种开源推理模型（GPT-OSS-20B和Qwen3-14B）上轻量化方法的优越性。
### Conclusion
研究结果显示，在增加抽样轨迹数量的同时，模型的分类准确性得到了持续提高。并且，通过仅重新训练较小模型（如GPT-2）的嵌入矩阵，轻量级的方法在测试时能够超越基于文本的大规模参数推理模型的表现。
## 103. `cs.AI` - 零样本文本到语音中的选择性分类器自由指导 [PDF](https://arxiv.org/pdf/2509.19668), [HTML](https://arxiv.org/abs/2509.19668)
### Authors
John Zheng,Farhad Maleki
### Background
在零样本文本到语音任务中，如何在保留目标说话人特征和遵循文本内容之间达到平衡仍然是一个挑战。尽管在图像生成中，分类器自由指导（CFG）策略显示出良好的结果，但其在语音合成中的应用尚未被充分研究。通过分离用于CFG的条件，可以在语音合成中实现不同特性的权衡。本研究旨在评估最初为图像生成设计的CFG策略在语音合成中的适应性，并扩展不同条件分离的CFG方法应用于该领域。研究结果表明，有效的CFG策略在图像生成中的表现并不能提高语音合成的质量。同时，通过在早期时间步骤中应用标准CFG并仅在后期时间步骤中切换为选择性CFG，可以提高说话人相似度并限制文本一致性下降。研究还发现，一种选择性CFG策略的效果高度依赖于文本表示，不同语言（如英语和中文）之间的差异即使使用相同的模型也可能导致不同的效果。
### Innovation
本研究扩展了分类器自由指导策略，特别针对语音合成领域提出了分离条件的CFG方法。通过将标准CFG技术应用于早期时间步骤，选择性CFG技术仅在后续时间步骤中使用，该方法有效提升了说话人相似度并降低了对文本一致性的负面影响。这种研究方法表明，不同语言之间的文本表示差异对选择性CFG的成败有重要影响，从而提出了新思路来优化语音生成的效果。
### Conclusion
分类器自由指导策略在图像生成领域的有效方法在应用于语音合成时并未取得预期成效。通过选择性地将标准CFG技术与选择性CFG技术结合，可以有效提升语音生成中的说话人相似度，同时限制对文本一致性的影响。此外，选择性CFG策略的效果高度依赖于文本表示，不同语言之间的细微差异可能导致不同的合成结果，这对未来的研究具有重要意义。
## 104. `cs.AI` - MoTiC: 动量紧致性和对比学习在少量样本类别递增学习中的应用 [PDF](https://arxiv.org/pdf/2509.19664), [HTML](https://arxiv.org/abs/2509.19664)
### Authors
Zeyu He,Shuai Huang,Yuwu Lu,Ming Zhao
### Background
Few-Shot Class-Incremental Learning (FSCIL) 必须应对从稀缺样本学习新类别并保留旧类别知识的双重挑战。现有方法使用冻结的特征提取器和类平均原型以减轻灾难性遗忘和过拟合。然而，新的类别原型由于极端的数据稀缺性遭受了显著的估计偏差，而基类原型则得益于充足的数据。研究表明，通过贝叶斯分析使新类别先验与旧类别统计数据对齐，可以减少方差并提高原型的准确性。进一步通过大范围对比学习增强跨类别特征的紧致性。为更丰富特征多样性并为新类别原型注入先验信息，本文提出动量自我监督和虚拟类别集成于动量紧致性和对比框架（MoTiC）中，构建了一个具有丰富表示和增强类间凝聚力的特征空间。实验证明，该方法在三个FSCIL基准上达到了最先进的性能，特别是在精细粒度任务CUB-200上验证了其减少估计偏差和提高增量学习稳健性的能力。
### Innovation
MoTiC框架通过引入动量自我监督、虚拟类别以及大范围对比学习，增强了特征空间的表示能力和类间凝聚力，有效解决了新类别原型的估计偏差问题，提升了少数样本类别递增学习的稳健性。
### Conclusion
实验结果显示，MoTiC方法在三个FSCIL基准上达到了最先进的性能，尤其是在细分类任务CUB-200上验证了其优越性，证明了该方法能够减少估计偏差和提高增量学习的鲁棒性。
## 105. `cs.AI` - 云游戏并非等同：基于上下文分类以实现有效用户体验测量 [PDF](https://arxiv.org/pdf/2509.19669), [HTML](https://arxiv.org/abs/2509.19669)
### Authors
Yifan Wang,Minzhao Lyu,Vijay Sivaraman
### Background
随着云游戏市场的增长，游戏图形在云端渲染后通过视频流形式传回给用户。网络运营商正在创建可获利的服务，这些服务能够动态分配网络资源。但为了评估这些分配方法的有效性，他们需要精确测量云游戏的用户体验。然而，目前仅通过带宽和帧率等基本指标无法充分了解这种体验，因为这些指标需要根据所玩的游戏以及玩家的活动来解释。本研究旨在为网络运营商提供一种方法，即通过分析网络流量及其上下文因素（如游戏标题和玩家活动状态）来实时获取云游戏体验的指标，特别是在游戏启动后的前五秒内进行游戏标题的分类，并持续评估玩家活动阶段，分为活跃、被动或空闲三种状态。这项研究部署在一家ISP管理的NVIDIA云游戏服务器中，并通过三个月的多个云游戏流媒体会话提供了宝贵的见解，揭示了带宽消耗与不同游戏背景下的体验水平之间的关系。
### Innovation
本研究的主要创新点在于，开发了一种通过分析网络流量及其上下文参数（如游戏标题和玩家活动状态）实时获取云游戏体验的新方法。该方法能够在游戏启动后的前五秒内对游戏进行分类，并持续评估玩家活动阶段。除此之外，该方法还提供了一个在现实业务场景中的部署案例，即在一家ISP运营商的NVIDIA云游戏服务器上实现应用，通过数以十万计的云游戏流媒体会话，揭示了带宽消耗与不同游戏背景下的用户体验水平之间的依赖关系。
### Conclusion
本研究通过分析网络流量及其上下文参数（如游戏标题和玩家活动状态）的方法，实时获取了云游戏体验的指标，该方法能够在游戏启动后的前五秒内完成游戏的分类，并持续评估玩家活动阶段。研究结果表明，带宽消耗与不同游戏下的用户体验水平之间的依赖关系可被有效挖掘和利用。该方法为网络运营商和服务商提供了一种创新的工具，以优化网络资源动态分配，从而提升云游戏用户体验。
## 106. `cs.AI` - 基于扩散的阻抗学习以实现场接触密集型操作任务 [PDF](https://arxiv.org/pdf/2509.19696), [HTML](https://arxiv.org/abs/2509.19696)
### Authors
Noah Geiger,Tamim Asfour,Neville Hogan,Johannes Lachner
### Background
学习方法在信息领域中擅长于运动生成，但在能量领域主要针对物理交互方面的能力不足。阻抗控制适用于物理交互，但需要通过选择合适的阻抗参数来有意识地调整。本文提出了一种将两个领域结合在一起的框架——基于扩散的阻抗学习。该框架利用一种具有交叉注意力能力的基于Transformer的扩散模型，利用外部力矩重建一个模拟的零力运动轨迹（sZFT），并通过这种方式捕获了操作空间中的平移和旋转行为。用于旋转的部分，引入了一种基于SLERP的四元数噪声调度器，以确保几何一致性。重建后的sZFT传递给能量估计器，该估计器更新刚度和阻尼参数。该控制器能够实现场运动的平滑穿越，并且具有在力和速度限制内实现无特定工具演示的圆柱形、方形和星形插块插入任务的30/30成功率。
### Innovation
本文提出的基于扩散的阻抗学习框架结合了学习方法和阻抗控制方法。新颖的四元数噪声调度器确保在旋转方面几何上的连续性。该方法能够在样本量仅为数万的情况下，不仅实现了高速度和高精度的执行操作，还能够在真实环境中控制KUKA LBR iiwa机器人实时应用含时扭矩控制和自主调整刚性。同时，该方法为未来的物理人工智能领域铺平了道路，能够将基于模型的控制和基于学习的轨迹生成方法结合起来。
### Conclusion
该模型及其控制器在接触密集型的操作任务，如运动规划和高精度任务中展示了潜在的应用价值。此外，该研究结果示出了一个重要的里程碑，即实现物理交互智能的一个方面，即结合模型控制和学习生成轨迹的方法的研究。
## 107. `cs.AI` - 术前因果机器学习方法 [PDF](https://arxiv.org/pdf/2509.19705), [HTML](https://arxiv.org/abs/2509.19705)
### Authors
J. Ben Tamo,Nishant S. Chouhan,Micky C. Nnamdi,Yining Yuan,Shreya S. Chivilkar,Wenqi Shi,Steven W. Hwang,B. Randall Brenn,May D. Wang
### Background
手术决策复杂，需要理解患者特征、干预措施和结果之间的因果关系。在脊柱融合或脊柱矫形等高风险医疗情境中，传统的统计方法难以准确估计个体化的治疗效果（ITEs），特别是在处理复杂多变的数据时。因此，需要一种新的方法来提高这些情境下的治疗效果估计。
### Innovation
该研究开发了一种多任务元学习框架X-MultiTask，用于估计ITEs。X-MultiTask将每个手术决策视为独立的任务，并通过学习跨任务的共享表征来加强因果有效性。研究还采用了逆概率加权（IPW）方法，以提高模型的因果有效性。
### Conclusion
X-MultiTask在脊柱融合和脊柱侧弯矫正中的性能表现突出。在前路与后路脊柱融合、后路脊柱融合与非手术管理对患者报告结果的影响的预测中，模型分别以0.84和0.77的平均AUC、最低的整体$text{NN-PEHE}$和$text{ATE}$达到了最佳效果。因此，X-MultiTask为个性化手术护理提供了强有力的工具，有助于提升患者预后。
## 108. `cs.AI` - 从直觉到证据：测量AI对开发人员生产力的真实影响 [PDF](https://arxiv.org/pdf/2509.19708), [HTML](https://arxiv.org/abs/2509.19708)
### Authors
Anand Kumar,Vishal Khare,Deepak Sharma,Satyam Kumar,Vijay Saini,Anshul Yadav,Sachendra Jain,Ankit Rana,Pratham Verma,Vaibhav Meena,Avinash Edubilli
### Background
本文介绍了对大规模企业中部署的AI辅助软件开发工具进行全面的实际世界评估。经过一年的时间，来自多个团队的300名工程师将内置的AI平台（DeputyDev）整合到他们的日常工作中，该平台结合了代码生成和自动审查功能。
### Innovation
纵向分析提供了生产环境中的实证证据，表明AI在企业软件开发工作流中的整合具有变革潜力，同时也揭示了实际部署过程中存在的挑战。
### Conclusion
研究展示了统计上显著的生产力改进，包括整体31.8%的拉取请求评审周期时间减少。开发人员对代码审查功能的采用率高达85%，并对持续使用该平台表现出强烈愿望。采用模式显示出系统性地从第一个月的4%使用率增加到第六个月的最高83%使用率，最终稳定在60%的活跃参与度。主要采用者将代码推向生产量提高了61%，从工具中产生的代码占生产代码的30%到40%，总体代码交付体积增加了28%。
## 109. `cs.AI` - RoboSSM: 通过状态空间模型实现可扩展的上下文模仿学习 [PDF](https://arxiv.org/pdf/2509.19658), [HTML](https://arxiv.org/abs/2509.19658)
### Authors
Youngju Yoo,Jiaheng Hu,Yifeng Zhu,Bo Liu,Qiang Liu,Roberto Martín-Martín,Peter Stone
### Background
上下文模仿学习（ICIL）使机器人能够从少量演示中学习任务。现有的ICIL方法依赖于变换器，但它们在处理训练期间未见过的长提示时表现不佳，具有计算限制。
### Innovation
提出了一种基于状态空间模型（SSM）的RoboSSM，它通过使用具有线性时间推理和强外推能力的最新的SSM Longhorn，取代了变换器，从而支持更长提示的上下文模仿学习。
### Conclusion
实验结果表明，RoboSSM能够有效地扩展到不同的上下文示例数量，对未见过的任务具有高性能，并且在长时间场景中保持稳定。这表明SSM可能是ICIL高效和可扩展的基础架构。
## 110. `cs.AI` - 线性变换器隐式发现统一数值算法 [PDF](https://arxiv.org/pdf/2509.19702), [HTML](https://arxiv.org/abs/2509.19702)
### Authors
Patrick Lutz,Aditya Gangrade,Hadi Daneshmand,Venkatesh Saligrama
### Background
作者训练了一个线性注意力变换器来完成百万级别的去遮罩矩阵补全任务。每个任务中的输入都是被遮罩的低秩矩阵，缺失的块可能是（i）标量预测目标，或者（ii）Nyström外推中的未见内核切片。模型仅通过输入输出对和均方损失进行训练，没有提供任何正规方程、手工迭代或任务间关联的提示。训练完成后，通过对模型参数进行代数反向展开，揭示了统一的无参数更新规则，这一规则在三种不同的计算范式（全视角、秩受限更新、分布式计算）下都适用。
### Innovation
该研究揭示了一个通过仅训练填充缺失块的变换器能够隐式发现适用于预测、估计和Nyström外推问题的统一迭代求解器的能力。并且该规则在完整的批次问题中实现了二阶收敛，减少了分布式计算的迭代复杂度，即使是在秩受限注意力的情况下仍然保持准确性。这项研究强调了在上下文学习中的强大能力.
### Conclusion
通过训练纯粹用于填充缺失块的变换器，模型隐式发现了跨越预测、估计和Nyström外推的统一、资源适应性迭代求解器，并证明了这种方法具有强大的计算效率和准确性，突显了上下文学习中的潜力。
## 111. `cs.AI` - 利用深度学习方法从语音句子预测无袖带血压 [PDF](https://arxiv.org/pdf/2509.19750), [HTML](https://arxiv.org/abs/2509.19750)
### Authors
Kainat
### Background
动脉血压是心血管健康的重要指标，准确监测对于防止与高血压相关的并发症至关重要。传统的袖带测量方法由于白大衣效应和隐匿性高血压等因素常导致结果不一致。本文通过利用基于BERT的回归模型来分析语音信号，探索无袖带血压预测的新方法。
### Innovation
本文提出了一种利用基于BERT的回归模型将语音信号转化为血压预测的新方法，这不仅能够实现实时监测且避免了传统方法的不适。通过对95名参与者的数据集进行分析，该模型表现出良好的血压预测能力，实现了收缩压和舒张压的高R分数和较低的MAE。
### Conclusion
本文的研究表明，结合深度学习与语音分析为血压监测提供了可行的替代方案，有助于改善远程医疗和远程健康监测的应用。通过提供一种用户友好且准确的血压评估方法，这项研究对患者护理和心血管健康预防性管理具有重要意义。
## 112. `cs.AI` - HiCoLoRA: Addressing Context-Prompt Misalignment via Hierarchical Collaborative LoRA for Zero-Shot DST [PDF](https://arxiv.org/pdf/2509.19742), [HTML](https://arxiv.org/abs/2509.19742)
### Authors
Shuyu Zhang,Yifan Wei,Xinru Wang,Yanmin Zhu,Yangfan He,Yixuan Weng,Bin Li
### Background
零样本对话状态跟踪（zs-DST）对于使任务导向对话系统（TODs）在新领域中利用已有知识，无需昂贵的数据标注是至关重要的。但动态对话上下文与静态提示之间的语义不匹配导致了跨层协调的灵活性低下、领域间相互干扰以及灾难性遗忘等问题。
### Innovation
提出了一种名为HiCoLoRA的框架，用来增强零样本插槽推理的鲁棒提示对齐。该框架具有层次结构的低秩适配（LoRA）架构，支持动态分层特定处理（结合下层启发式分组和上层全交互），整合了光谱联合领域-插槽聚类以识别可转移的相关性，并采用语义增强SVD初始化来保留预训练知识。
### Conclusion
在跨领域数据集MultiWOZ和SGD上进行了实验，表明HiCoLoRA在零样本对话状态跟踪中超过了基线方法，取得了当前最佳表现。相关代码可在以下链接获取。
## 113. `cs.AI` - 神经网络的Sobolev加速 [PDF](https://arxiv.org/pdf/2509.19773), [HTML](https://arxiv.org/abs/2509.19773)
### Authors
Jong Kwon Oh,Hanbaek Lyu,Hwijae Son
### Background
Sobolev训练方法将目标导数整合到损失函数中，相较于传统的$L^2$训练，在加速收敛和提高泛化能力方面表现更优。然而，该训练方法的内在机制尚未完全理解。
### Innovation
本文构建了首个严谨的理论框架，证明了Sobolev训练加速了具有高斯输入和浅层架构的ReLU网络的收敛过程。本文导出了总体梯度和海森矩阵的精确公式，并量化了损失景观条件性的改善以及梯度流动收敛速率的提升。
### Conclusion
广泛的数值实验验证了理论发现，表明Sobolev训练能够提高现代深度学习任务的效果。
## 114. `cs.AI` - ARCADE：一种处理多种数据模态的混合查询和连续查询的实时数据系统 [PDF](https://arxiv.org/pdf/2509.19757), [HTML](https://arxiv.org/abs/2509.19757)
### Authors
Jingyi Yang,Songsong Mo,Jiachen Shi,Zihao Yu,Kunhao Shi,Xuchen Ding,Gao Cong
### Background
随着多模态数据（包括文本、图像、视频、空间和关系等多种类型）的爆炸性增长以及对这些数据进行实时语义搜索和检索的需求，现有的多模态和实时数据库系统已经落后，无法高效处理数据的摄入和连续查询的能力，或无法支持高级混合查询。
### Innovation
ARCADE系统引入了针对LSM存储的向量化、空间和文本数据模态的统一磁盘二级索引，具有成本基于的查询优化器，用于混合查询，并且拥有一套增量的材料视图框架，用于高效处理连续查询。基于开源的RocksDB存储和MySQL查询引擎，在读取和写入工作负载中分别比领先的数据系统表现出7.4倍和1.4倍的性能优势。
### Conclusion
ARCADE是一种高效的实时数据系统，可以支持高吞吐量的数据摄入和多样数据类型的混合及连续查询处理，其性能优于现有的领先多模态数据系统。
## 115. `cs.AI` - 摩擦Q学习 [PDF](https://arxiv.org/pdf/2509.19771), [HTML](https://arxiv.org/abs/2509.19771)
### Authors
Hyunwoo Kim,Hyo Kyung Lee
### Background
本文将经典力学中的静摩擦力与强化学习中离策策略下的外推误差类比，并以此为基础提出了一个约束条件，该条件能够防止策略向不支持的动作方向漂移。研究介绍了一种新的算法——摩擦Q学习（Frictional Q-learning），它是一种适用于连续控制的深度强化学习算法，该算法扩展了批处理约束强化学习。该算法通过限制智能体的动作空间来鼓励类似于重播缓冲区的行为，同时与正交动作空间流形保持一段距离。该约束条件保留了批处理约束的简单性，提供了对外推误差的直观物理解释。实验结果显示，该算法能够在标准的连续控制基准测试中取得鲁棒且竞争力的性能表现。
### Innovation
提出了摩擦Q学习算法，一种适用于连续控制的深度强化学习算法，该算法扩展了批处理约束强化学习。通过限制智能体的动作空间来鼓励类似重播缓冲区的行为，同时与正交动作空间流形保持一段距离。该约束条件保留了批处理约束的简单性，提供了对外推误差的直观物理解释。
### Conclusion
摩擦Q学习在标准连续控制基准测试中表现出鲁棒且竞争力的性能，同时提供了对外推误差的直观解释。
## 116. `cs.AI` - 动态基因组：一种以分子动力学指导和AI驱动的致病性预测目录，适用于所有遗传突变 [PDF](https://arxiv.org/pdf/2509.19766), [HTML](https://arxiv.org/abs/2509.19766)
### Authors
Naeyma N Islam,Mathew A Coban,Jessica M Fuller,Caleb Weber,Rohit Chitale,Benjamin Jussila,Trisha J. Brock,Cui Tao,Thomas R Caulfield
### Background
随着基因组医学的进步，尽管基因疾病的突变识别速度加快，但许多突变的致病性仍不清楚，这阻碍了它们在诊断和临床决策中的应用。当前的预测人工智能模型虽然生成了，但在功能验证数据集上测试时显示较低的准确性。本研究旨在通过将详细的构象数据（从分子动力学模拟中提取）整合到高级AI模型中，提高预测能力。通过对PMM2致病基因的详细突变分析，并让结构变异模型接受分子动力学模拟，展示了基于这一数据集训练出的AI模型在预测已知突变致病性上的优越性。该模型还预测了PMM2几种目前考虑具有不确定意义的突变的致病性，有助于减轻基因组医学中未知变异的负担。
### Innovation
本研究引入了一种新的模型，通过结合分子动力学模拟的数据，显著提高了AI模型预测基因突变致病性的能力。特别是，作者开发的神经网络模型在预测已知突变致病性方面表现最佳，并能够预测一些之前被认为功能意义未明的PMM2突变的致病性。这为基因组医学提供了新的工具，能够更好地理解未知意义的突变。
### Conclusion
本研究通过使用分子动力学数据增强了AI模型的预测能力，展示了其在基因组医学中的应用潜力，并预测了一些未知功能意义的PMM2突变的致病性。这种方法提供了一种新的途径来改善基因突变诊断的准确性，并可能对个性化医疗的发展产生重要影响。
## 117. `cs.AI` - FusedANN: Attribute-向量融合的凸优化近似最近邻 [PDF](https://arxiv.org/pdf/2509.19767), [HTML](https://arxiv.org/abs/2509.19767)
### Authors
Alireza Heidari,Wei Zhang,Ying Xiong
### Background
向量搜索在变压器技术中发挥着重要作用，但在实际应用中，查询需要结合向量相似性和属性过滤（例如，“类别X中2023年的顶级文档”）。当前解决方案在召回率、速度和灵活性之间做取舍，依赖于脆弱的索引技巧，无法扩展。研究介绍了FusedANN（融合属性-向量最近邻）方法，通过几何框架将过滤提升为ANN优化约束，并通过拉格朗日式的松弛引入凸融合空间。此方法通过基于变压器的凸化，同时嵌入属性和向量，将硬滤镜转换为连续、加权的惩罚，同时保持前k最近的语义并在实现高效近似搜索的同时允许高效的约简近似保障。
### Innovation
FusedANN通过几何框架提升过滤步骤为ANN优化约束，并引入了拉格朗日式的松弛来创建凸融合空间。它通过基于变压器的凸化同时嵌入属性和向量，使得硬滤镜转化为连续、加权惩罚，从而保留前k最近的语义，同时实现高效近似搜索。理论证明FusedANN在高选择性时退化为精确过滤，并在精确匹配不足时优雅地退化为语义最近的属性匹配。该方法在基准测试中实现了比最先进混合和基于图的系统的更优异的召回-延迟折衷，并实现了三倍以上的吞吐量和更好的召回率。我们提供了明确的误差界限和参数选择规则，使FusedANN在生产环境中实用。
### Conclusion
FusedANN建立了一种原理性的、可扩展的和可验证的桥梁，连接符号约束和向量相似性，解锁了一代新的过滤检索系统，适用于大型、混合和动态的NLP/ML工作负载。
## 118. `cs.AI` - PPGFlowECG: 在交叉模态编码下具有潜层校正流的PPG引导ECG生成和心血管疾病检测 [PDF](https://arxiv.org/pdf/2509.19774), [HTML](https://arxiv.org/abs/2509.19774)
### Authors
Xiaocheng Fang,Jiarui Jin,Haoyu Wang,Che Liu,Jieyi Cai,Guangkun Nie,Jun Li,Hongyan Li,Shenda Hong
### Background
在临床实践中，心电图（ECG）仍然是心脏监测的金标准，能够提供诊断多种心血管疾病（CVDs）的关键洞见。然而，ECG依赖专用设备和专业人员，限制了其在持续常规监测中的可行性。光体积描记术（PPG）提供了连续的监测功能，但由于缺乏明确的电生理信息，无法进行明确诊断。生成模型为将PPG转化为具有临床价值的ECG信号提供了一种有前景的方法，但当前方法面临重大挑战，包括生成模型中的生理语义错位和高维信号建模的复杂性。因此，作者提出PPGFlowECG，这是一种两阶段框架，通过CardioAlign编码器将PPG和ECG对齐到共享的潜在空间，并使用潜在验证流来生成高保真和可解释的ECG。这是首次使用MCMED进行PPG至ECG转换和心血管疾病检测的实验，该数据集包含100多万对PPG-ECG样本和心血管疾病标签。
### Innovation
提出PPGFlowECG，这是一种两阶段框架，首先通过CardioAlign编码器将PPG和ECG对齐到共享的潜在空间，然后使用潜在验证流生成高质量和高可解释性的ECG。这是首次利用MCMED数据集进行这种大规模的PPG到ECG转换及心血管疾病检测实验。
### Conclusion
PPGFlowECG方法在PPG到ECG的转化中表现出色，提高了心血管疾病的诊断准确性，具有在真实世界心血管筛查中的应用潜力。医师评估证实合成的ECG具有高保真度，增强了诊断的可靠性。
## 119. `cs.AI` - RDAR: 基于奖励驱动的智能体相关性估计在自动驾驶中的应用 [PDF](https://arxiv.org/pdf/2509.19789), [HTML](https://arxiv.org/abs/2509.19789)
### Authors
Carlo Bosio,Greg Woelki,Noureldin Hendy,Nicholas Roy,Byungsoo Kim
### Background
人类驾驶员在任何给定时间只关注少数几个目标。相反，自动驾驶系统需要处理复杂的场景，包含众多目标，无论这些目标是在人行横道上的行人还是停在路边的车辆。现有的捕捉智能体互动注意力机制虽然提供了减少输入到决策元素的方法，但通常是二次的，计算成本较高。因此，研究提出了一种名为RDAR的策略，通过确定可以从预训练行为模型输入中排除的智能体，以量化每个智能体对控制车辆行为的影响程度。研究将遮罩过程建模为马尔可夫决策过程，其中动作包括指示智能体选择的二进制掩码。
### Innovation
提出了一种名为RDAR的策略，通过确定可以从预训练行为模型输入中排除的智能体来学习每个智能体的相关性，并将遮罩过程建模为马尔可夫决策过程，以自动选择智能体。通过在大规模驾驶数据集上的评估，证明该方法能够在显著减少处理智能体数量的情况下达到与最先进的行为模型相当的驾驶性能。
### Conclusion
RDAR方法能够学习一个准确的相关性数值指标，并在保持驾驶性能、安全性和性能的前提下，明显减少处理的智能体数量，展示了在自动驾驶中提高计算效率和智能体处理能力的潜力。
## 120. `cs.AI` - 基于SMILES的量子算子迁移学习在生成量子特征值求解器中的应用 [PDF](https://arxiv.org/pdf/2509.19715), [HTML](https://arxiv.org/abs/2509.19715)
### Authors
Zhi Yin,Xiaoran Li,Shengyu Zhang,Xin Li,Xiaojin Zhang
### Background
传统的变分量子特征值求解器(VQE)算法存在固有的限制，而将深度生成模型融入混合量子-经典框架中，特别是生成量子特征值求解器(GQE)，代表了一种有前景的创新方法。例如，使用广泛应用于量子化学的单位耦合簇含单项和双项算符(UCCSD)近似时，不同的分子系统需要构建不同的量子算符。考虑到不同分子之间的相似性，利用这些相似性构建量子算符可以显著降低计算成本。借鉴计算化学中用于分子表示的SMILES方法，我们通过利用不同分子系统之间固有的表征相似性，开发了一种文本基于的表示方法来构建UCCSD量子算符。这一框架探索了量子算符中的文本模式相似性，并通过文本相似性指标建立迁移学习框架。
### Innovation
本文采用SMILES表示方法开发了一种基于文本的表示方法来构建UCCSD量子算符，并通过探索文本模式相似性和利用文本相似性指标建立迁移学习框架。这种方法在GQE框架下展示了不同分子系统之间的知识迁移，特别适用于分子基态能计算，显著降低了计算资源需求。
### Conclusion
这种基于文本模式的算符表示方法及其迁移学习框架为混合量子-经典计算提供了一种有效的方法，显著降低了计算资源要求，能够用于不同分子系统中的基态能量计算。
## 121. `cs.AI` - Kolmogorov-Arnold网络回归估计器的收敛率 [PDF](https://arxiv.org/pdf/2509.19830), [HTML](https://arxiv.org/abs/2509.19830)
### Authors
Wei Liu,Eleni Chatzi,Zhilu Lai
### Background
Kolmogorov-Arnold网络（KANs）提供了一种结构化且易于解释的框架，用于多变量函数近似，通过将单变量变换通过加法或乘法聚合来实现。这项研究在单变量组件由B-样条表示时，建立了KANs的理论收敛保证。
### Innovation
论文证明，加法和混合加法-乘法KANs在光滑性为r的Sobolev空间中的函数上的收敛率达到了最优的minimax收敛率$O(n^{-2r/(2r+1)})$。此外，还推导了选择B-样条最佳节点数的指导原则，并通过模拟研究验证了预测的收敛率。
### Conclusion
研究结果为使用KANs进行非参数回归提供了理论基础，并将其作为现有方法的结构化替代方法。”（要点总结为结论部分的主要内容）
## 122. `cs.AI` - 统一噪声-曲率视角下的训练可处理性损失 [PDF](https://arxiv.org/pdf/2509.19698), [HTML](https://arxiv.org/abs/2509.19698)
### Authors
Gunbir Singh Baveja,Mark Schmidt
### Background
训练可处理性损失（Loss of Trainability，LoT）是持续学习中的一个现象，指的是随着任务的演进，梯度更新不再带来性能提升，导致准确率停滞或下降。尽管模型容量和监督充足，这一现象仍然发生。已有的单一指标如海森矩阵秩、尖锐性水平、权重或梯度范数、梯度对参数比率和单位签量熵无法可靠预测LoT的发展。本文从优化的角度分析Adam算法下的LoT问题，指出这些单一指标不可靠。
### Innovation
本文提出了一种新颖的方法，即同时采用一种batch-size感知的梯度噪声边界和一种曲率波动控制边界来评估每层的训练可处理性阈值。这种方法将两种边界结合成一个针对每层的预测阈值，用于预估训练行为。基于这一阈值，论文构建了一个简单的每层调度器，将每层的有效步长保持在安全范围内，从而稳定训练并提高准确率。实验结果表明，该方法在串联ReLU（CReLU）、Wasserstein正则化和L2权重衰减等条件下均能显著改善模型性能。
### Conclusion
通过引入新的训练可处理性预测阈值和相应的调度器，该研究显著改善了多种持续学习场景下的模型训练性能，为理解LoT提供了新的视角，同时也制定了实用的解决方案来处理这一问题。
## 123. `cs.AI` - bi-GRPO：针对LLMs的双向优化Jailbreak后门注入方法 [PDF](https://arxiv.org/pdf/2509.19775), [HTML](https://arxiv.org/abs/2509.19775)
### Authors
Wence Ji,Jiancan Wu,Aiying Li,Shuyi Zhang,Junkang Wu,An Zhang,Xiang Wang,Xiangnan He
### Background
随着大型语言模型（LLMs）的迅速发展，它们抵御对抗性操纵，尤其是监狱突破后门攻击的能力变得至关重要。现有的嵌入监狱突破触发机制的方法，如有监督的微调（SFT）、模型编辑和基于人类反馈的强化学习（RLHF），每种方法都存在局限性，包括泛化能力差、偷袭不隐蔽或生成的监狱突破响应上下文相关性差。通过引入双方向组相对策略优化（Bi-GRPO），一种专门针对监狱突破后门注入的新型基于强化学习方法，克服了这些问题。双方向组相对策略优化通过使用对弈回放和对弈奖励，联合优化模型，以可靠地产生带有触发器的有害内容并在其他情况下保持安全。这种方法利用基于规则的奖励机制，同时提供长度和格式的激励，避免依赖高质量的有监督数据集或可能有缺陷的奖励模型。
### Innovation
提出了双方向组相对策略优化（Bi-GRPO），这是一种专门为监狱突破后门注入设计的新型基于强化学习的框架。通过采用对弈回放和对弈奖励，Bi-GRPO 转而优化模型以可靠地生成带有触发器的有害内容并维持非触发器场景下的安全性。这种方法利用基于规则的奖励机制，同时提供长度和格式的激励，避免依赖高质量的有监督数据集或可能有缺陷的奖励模型。实验结果表明，Bi-GRPO 达到了超过99%的攻击成功率，即使在非触发器场景中也能保持隐蔽性，并且生成的监狱突破响应具有高度的实用性和连贯性，显著推进了监狱突破后门攻击的技术前沿。
### Conclusion
双方向组相对策略优化（Bi-GRPO）是一种专门针对监狱突破后门注入设计的新型强化学习框架。它通过采用对弈回放和对弈奖励的方式优化模型，使其能够可靠地生成带有触发器的有害内容，并在非触发器场景中保持安全。Bi-GRPO 利用基于规则的奖励机制，避免依赖高质量的有监督数据集或可能有缺陷的奖励模型。实验结果证明，Bi-GRPO 在攻击成功率、隐蔽性和生成的监狱突破响应的使用性和连贯性方面表现出色，大大推进了监狱突破后门攻击的技术水平。
## 124. `cs.AI` - 阈值操控下的因果推断：贝叶斯混合模型与异质性治疗效果估计 [PDF](https://arxiv.org/pdf/2509.19814), [HTML](https://arxiv.org/abs/2509.19814)
### Authors
Kohsuke Kubota,Shonosuke Sugasawa
### Background
许多营销应用，例如信用卡激励计划，会向消费超过特定阈值的客户提供奖励，以鼓励增加消费。衡量这些阈值对客户行为的因果影响对于营销策略设计至关重要。尽管回归连续性设计是此类因果推断的标准方法，但在客户了解阈值的情况下，可能会通过战略性地调整消费来规避阈值，从而违反该方法的假设。因此，需要一种新的框架来估计在阈值操控下的因果效应，特别是在混合了战略性和非战略性客户消费分布的情况下。
### Innovation
本文提出了一种新的框架，通过将观察到的消费分布建模为两种分布的混合模型，分别代表被阈值影响的战略性客户和不受影响的客户，采用两步贝叶斯方法进行建模，并在样本量大时展示了后验收缩特性。此外，该框架扩展到分层贝叶斯设置，以估计不同客户子群的异质性因果效应，即使在小组样本量较小时也能进行稳定推断，从而解决了标准方法在阈值操控情况下的适用问题。
### Conclusion
通过模拟研究和使用实际营销数据集演示了所提方法的有效性，并展示了理论结果的实际意义。
## 125. `cs.AI` - 在新闻文本中可持续发展目标极性检测 [PDF](https://arxiv.org/pdf/2509.19833), [HTML](https://arxiv.org/abs/2509.19833)
### Authors
Andrea Cadeddua,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi
### Background
联合国的可持续发展目标（SDGs）为解决关键的社会、环境和经济挑战提供了一个全球认可的框架。最近，自然语言处理（NLP）和大型语言模型（LLMs）的发展使得能够根据文本数据与特定SDGs的相关性对其进行自动分类。然而，许多应用中同样重要的是确定这种相关性的方向性，即评估描述的影响是正面的、中性的还是负面的。为此，本文提出了可持续发展目标极性检测的新任务，该任务评估文本段落是否表明向特定SDG迈进或传达了实现这一进展的意图。
### Innovation
本文引入了SDG-POD，这是为这一任务专门设计的基准数据集，结合了原始和合成生成的数据。本文使用六种最先进的大型LLMs进行全方位评估，考虑了零样本和微调配置。结果表明，当前一代LLMs仍面临挑战，但某些微调模型，尤其是QWQ-32B，在特定的可持续发展目标如SDG-9、SDG-12和SDG-15上的表现良好。此外，本文证明，将微调数据集与合成生成示例结合使用可以提高模型在该任务上的性能。这一结果突显了通过数据增强技术来应对资源受限领域挑战的有效性。
### Conclusion
本文推进了可持续发展监测的方法工具包，并提供了关于开发高效、高表现极性检测系统的可操作见解。
## 126. `cs.AI` - ExpFace: Exponential Angular Margin Loss for Deep Face Recognition [PDF](https://arxiv.org/pdf/2509.19753), [HTML](https://arxiv.org/abs/2509.19753)
### Authors
Jinhui Zheng,Xueyuan Gong
### Background
面识别是一个开放集问题，需要具备高度的判别力来确保类内距离小于类间距离。现有的基于边际的Softmax损失函数，如SphereFace、CosFace和ArcFace，被广泛采用以增强类内紧凑性和类间可分性，但这些方法忽视了噪声样本的影响。通过考察样本在角度空间中的分布，发现纯净样本主要集中在中心区域，而噪声样本倾向于向外围区域偏移。基于这一观察，我们提出了Exponential Angular Margin Loss（ExpFace），引入了角度指数项作为边际，通过在中心区域施以更大惩罚、在外围区域施以较小惩罚，来强调纯净样本同时抑制噪声样本
### Innovation
我们提出了Exponential Angular Margin Loss (ExpFace)，通过在角度空间中引入角度指数项作为边际，设计角度空间中中心区域较大惩罚、外围区域较小惩罚，从而强调纯净样本并抑制噪声样本。我们从边际嵌入形式、相似曲线和梯度曲线三个角度对ExpFace和经典基于边际的Softmax损失进行统一分析，表明ExpFace避免了SphereFace的训练不稳定性、ArcFace的非单调性，并表现出与角度空间决策边界一致的相似曲线。实验证明ExpFace达到了最先进的性能
### Conclusion
广泛的实验证明，ExpFace在性能上达到了最先进水平。为了促进未来的研究，已经发布了ExpFace的源代码。
## 127. `cs.AI` - 评判之前：自我参考作为提升LLM评价之路 [PDF](https://arxiv.org/pdf/2509.19880), [HTML](https://arxiv.org/abs/2509.19880)
### Authors
Wei-Hsiang Lin,Sheng-Lun Wei,Hen-Hsen Huang,Hsin-Hsi Chen
### Background
大量的LLM-as-Judge框架被用于AI评估，但关于模型生成能力和判断能力之间的关系的研究结果并不一致。本文通过对11个模型和21种不同任务进行系统化数据集和实例分析，发现这两种能力之间虽然基于相同的背景知识，但相关性较弱，主要是因为LLM对被评估的回答非常敏感。
### Innovation
文中提出了一种自我参考引导的评估策略，利用模型自身的答案作为参考，显著增强了生成能力和判断能力之间的关联性。这种方法为实现这些技能的对齐提供了一条实用路径，并提供了在评估任务中选择模型的可靠代理方法。
### Conclusion
研究揭示了生成能力和判断能力之间的弱相关性主要原因，并提出了一种新的评估策略，通过利用模型自答作为参照，以增强两者间的关联，为模型选择提供了一个可靠的指标。
## 128. `cs.AI` - TianHui: 专用于多样传统中医场景的领域特定大型语言模型 [PDF](https://arxiv.org/pdf/2509.19834), [HTML](https://arxiv.org/abs/2509.19834)
### Authors
Ji Yin,Menglan He,Yujie Zhang,Linshuai Zhang,Tingting Ma,Ce Tian,Jie Wu,Lin Xu,Tao Jiang,  ((1) School of Intelligent Medicine, Chengdu University of Traditional Chinese Medicine, Chengdu, China (2) The Acupuncture and Tuina School, Chengdu University of Traditional Chinese Medicine, Chengdu, China (3) Center of Preventive Medicine, Hospital of Chengdu University of Traditional Chinese Medicine, Chengdu, China (4) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China (5) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China)
### Background
在研究环境中，针对特定领域的大型语言模型（LLMs）在中医（TCM）的应用中面临局限，包括适应性受限、缺乏足够的评估数据集以及计算资源有限。因此，需要一种能够在这些限制下有效工作的特定于领域的TCM LLM，通过整合上下文数据和融合领域知识实现这一目标。为了解决这些问题，该研究旨在构建一个专门针对TCM的LLM——TianHui，并通过一个大规模TCM语料库及其特有的双阶段训练策略，提升了模型的性能与应用潜力。
### Innovation
本文提出了一种名为TianHui的专门用于不同中医场景的大规模领域特定LLM。该论文构建了一个大规模TCM语料库（0.97GB未监督数据+611,312对问答），并采用了一种两阶段的训练策略，使用了QLoRA、DeepSpeed Stage 2以及Flash Attention 2等技术。研究结果表明，TianHui在多个基准测试中取得了优异成绩，在12个基准测试中的6个数据集中排名第一，在其它6个数据集中排名第一。研究发现最优配置为洛拉秩=128，alpha=256，循环=4，dropout=0.2，最大长度=2048。这意味着TianHui能够系统地保存和扩展应用TCM知识的能力，并且该研究的所有资源都是开源的，这是一项创新成果。
### Conclusion
TianHui能够实现系统化的TCM知识保存与扩展应用，并具备广泛的适用场景。通过开源的形式，这为其他研究者提供了一个强大的工具，以进一步推动中医领域的智能技术应用和发展。
## 129. `cs.AI` - 朝向用于重症监护时间序列的自我监督基础模型 [PDF](https://arxiv.org/pdf/2509.19885), [HTML](https://arxiv.org/abs/2509.19885)
### Authors
Katja Naasunnguaq Jagd,Rachael DeVries,Ole Winther
### Background
近年来，面向医疗领域的专用基础模型得到了迅速发展，但重症监护时间序列相关的基础模型仍相对未被深入探索，这是由于数据集规模较小且获取困难造成的。
### Innovation
本文介绍了一个基于双轴变换器（BAT）的早期预训练基础模型，该模型是在合并的电子健康记录数据集上训练的，并展示了通过在死亡率预测上微调此模型以获得有效转移学习的能力，特别是在小数据集（<5,000个样本）情况下的表现优于有监督的基准模型。
### Conclusion
这些贡献表明，自我监督基础模型有潜力支持资源有限环境中具有普遍性和鲁棒性的临床应用。
## 130. `cs.AI` - 通过多模态大语言模型的适应性指导提升边缘-云端目标检测的语义增强 [PDF](https://arxiv.org/pdf/2509.19875), [HTML](https://arxiv.org/abs/2509.19875)
### Authors
Yunqing Hu,Zheming Yang,Chang Zhao,Wen Ji
### Background
传统的目标检测方法在低光照条件和重叠遮挡等复杂场景中由于缺乏高层次的语义理解而面临性能下降的问题。
### Innovation
本文提出了一种基于适应性指导的语义增强边缘-云端协同目标检测方法，利用多模态大型语言模型 (MLLM)，实现了准确性和效率的有效平衡。该方法首先通过指令微调让MLLM生成结构化的场景描述，然后设计了自适应映射机制，将语义信息动态转换为边缘检测器的参数调整信号，从而实现实时的语义增强。在边缘-云端协作推理框架中，系统根据置信分数自适应选择调用云端语义指导或直接输出边缘检测结果。实验结果表明，该方法在复杂场景中有效提升了检测准确性和效率。尤其在低光照和高度遮挡场景中，可以使延迟降低超过79%，计算成本降低70%，同时保持准确性。
### Conclusion
本文提出的方法在复杂场景中有效提升了目标检测的准确性和效率。通过自适应指导和实时语义增强，显著降低了延迟和计算成本，同时保持了较高的检测准确性。
## 131. `cs.AI` - 通过注意力指导消除基于LLM的TTS模型中的稳定性幻觉 [PDF](https://arxiv.org/pdf/2509.19852), [HTML](https://arxiv.org/abs/2509.19852)
### Authors
ShiMing Wang,ZhiHao Du,Yang Xiang,TianYu Zhao,Han Zhao,Qian Chen,XianGang Li,HanJie Guo,ZhenHua Ling
### Background
该论文关注的是在基于LLM的文本到语音(TTS)模型中解决稳定性幻觉问题，如重复或遗漏的语音。作者通过改进和利用注意力机制来进行研究。初始研究集中在LLMs中的文本令牌和语音令牌的对齐机制上，进而提出了一个称为Optimal Alignment Score (OAS)的度量标准，使用Viterbi算法评估文本-语音对齐的质量。
### Innovation
提出了OAS这一度量标准，使用Viterbi算法来评估文本-语音对齐的质量，并将其集成到CosyVoice2的训练中，以帮助LLMs学习连续稳定的对齐。同时，利用预训练的注意力值通过思维链(CoT)来指导CosyVoice2学生的训练，进一步减少合成语音中的稳定性幻觉。实验表明，这些方法可以有效减少CosyVoice2的稳定性幻觉，且不会引入额外的负面影响。
### Conclusion
实验结果表明，所提出的方法可以有效减少CosyVoice2中的稳定性幻觉，且不会引入额外的负面影响。该方法通过改进注意力机制，使得语音合成更加稳定。
## 132. `cs.AI` - 使用基础模型进行探索：能力、限制和混合方法 [PDF](https://arxiv.org/pdf/2509.19924), [HTML](https://arxiv.org/abs/2509.19924)
### Authors
Remo Sasso,Michelangelo Conserva,Dominik Jeurissen,Paulo Rauber
### Background
在稀疏奖励设置下，强化学习（RL）的探索仍然是一个具有挑战性的问题。尽管基础模型具有强大的语义先验知识，但它们在经典RL基准测试中的零样本探索能力尚未被充分理解。本研究在多臂老虎机、格状世界和稀疏奖励的Atari游戏环境下，对比测试了LLM和VLM在零样本探索方面的表现，揭示了一个关键的局限性：虽然VLM可以从视觉输入中推断出高层次目标，但它们在精确的低层次控制中表现不佳，即“知行差距”。
### Innovation
本研究设计了一个简单的在政策混合框架，以试探性解决这一
### Conclusion
在理想化的情景下，我们发现VLM指导可以大幅提高早期样本效率，明确了使用基础模型引导探索而非实现端到端控制的潜力与限制。
## 133. `cs.AI` - 预训练符号回归的泛化分析 [PDF](https://arxiv.org/pdf/2509.19849), [HTML](https://arxiv.org/abs/2509.19849)
### Authors
Henrik Voigt,Paul Kahlmeyer,Kai Lawonn,Michael Habeck,Joachim Giesen
### Background
符号回归算法通过搜索数学表达式的空间来寻找能够解释给定数据的公式。基于Transformer的模型已经作为一种有前景且可扩展的方法出现，将昂贵的组合搜索转移到大规模预训练阶段。然而，这些模型的成功很大程度上依赖于其预训练数据。它们在预训练分布之外的问题上的泛化能力还鲜有探索。
### Innovation
本文开展了一项系统性的实证研究，以评估预训练的基于Transformer的符号回归的泛化能力。不仅测试了其在预训练分布内的表现，而且在一系列分布外的挑战中测试了多种最先进的方法。研究所揭示的显著二元对立是：虽然预训练模型适应内部分布表现良好，但在分布外场景中的表现却不尽人意。这些发现指出了泛化差距对实际应用中的预训练方法使用者来说是关键障碍，极大限制了预训练方法的实际应用价值。
### Conclusion
研究得出结论，这种泛化能力的差距是实际应用中的一个关键障碍，严重限制了预训练方法的广泛应用。
## 134. `cs.AI` - CoMelSinger：基于离散标记的零样本歌唱合成及其结构化旋律控制和指导 [PDF](https://arxiv.org/pdf/2509.19883), [HTML](https://arxiv.org/abs/2509.19883)
### Authors
Junchuan Zhao,Wei Zeng,Tianle Lyu,Ye Wang
### Background
Singing Voice Synthesis（SVS）旨在从结构化的音乐输入（如歌词和音高序列）生成表达性强的歌声表演。尽管基于离散编码的语音合成在近期取得了进展，能够在上下文学习中实现零样本生成，但在直接将其扩展到SVS上仍有挑战，原因在于需要精确定位的旋律控制。现有技术中的基于提示的生成方式往往在调性提示与歌声之间的音高信息间带来无意的纠缠，这会影响控制的精确性。为此，本文提出了CoMelSinger，这是一种结构化和解耦的零样本SVS框架，它在离散编码建模框架中实现了调性控制。
### Innovation
CoMelSinger基于非自回归MaskGCT架构，将传统文本输入替换为歌词和音高标记，同时增强了旋律的条件性。为抑制音高信息在调性提示与歌声之间的纠缠问题，提出了一种从粗到细的对比学习策略，这种策略明确地正则化了声学提示与旋律输入的音高冗余。此外，还整合了一个轻量级的仅编码器的歌唱语音转记（SVT）模块，将声学标记与音高和时长进行对齐，提供了精细的帧级监督。实验结果表明，CoMelSinger在音高准确性、音色一致性以及零样本转移性上优于其他竞争基准模型。
### Conclusion
CoMelSinger通过结合离散标记和非自回归架构，实现了结构化的旋律控制和引导，显著提高了音高精度、音色一致性和零样本转移性。
## 135. `cs.AI` - TABFAIRGDT：使用自回归决策树的快速公平表格数据生成器 [PDF](https://arxiv.org/pdf/2509.19927), [HTML](https://arxiv.org/abs/2509.19927)
### Authors
Emmanouil Panagiotou,Benoît Ronval,Arjun Roy,Ludwig Bothmann,Bernd Bischl,Siegfried Nijssen,Eirini Ntoutsi
### Background
确保机器学习的公平性仍然是一个重大挑战，因为模型往往会从训练数据中继承偏见。生成模型最近被视为一种有前景的方法，可以在数据层面减轻偏见的同时保留有用性。然而，许多生成模型依赖于深架构，尽管有证据表明，对于表格数据，简单模型同样可以非常有效。
### Innovation
我们提出了一种新的方法TABFAIRGDT，用于使用自回归决策树生成公平的合成表格数据。为了确保公平性，我们提出了一种软叶重采样技术，调整决策树的输出以减少偏差，同时保持预测性能。该方法是非参数的，可以有效地捕获混合特征类型之间的复杂关系，而无需假设数据分布的形式。我们通过基准公平性数据集对TABFAIRGDT进行了评估，并证明其性能优于最先进的深度生成模型，实现了更好的公平性-有用性折衷，并且合成数据质量更高。此外，该方法轻量级、高效且兼容CPU，无需数据预处理。
### Conclusion
TABFAIRGDT在各种数据集大小方面实现了72%平均速度提升，在标准CPU上仅需一秒即可为中型数据集（10特征，10K样本）生成公平的合成数据，是现实公平敏感应用的理想解决方案。
## 136. `cs.AI` - AJAHR: Amputated Joint Aware 3D Human Mesh Recovery [PDF](https://arxiv.org/pdf/2509.19939), [HTML](https://arxiv.org/abs/2509.19939)
### Authors
Hyunjin Cho,Giyun Choi,Jongwon Choi
### Background
现有的人体网格恢复方法假设标准的人体结构，忽略了如肢体缺失等多样的解剖条件。这在肢体缺失的个体身上引入了偏差，并且由于可用的适合数据集稀缺的问题而进一步加剧了这一限制。
### Innovation
本文提出了一种针对肢体缺失个体的适应性姿势估计框架——Amputated Joint Aware 3D Human Mesh Recovery (AJAHR)。该模型集成了一个肢体缺失分类器与网格恢复网络联合训练，用于检测潜在的肢体缺失。此外，还引入了一个名为Amputee 3D (A3D) 的合成数据集，该数据集提供了广泛的截肢姿势以进行稳健训练。
### Conclusion
即便在非截肢个体上维持了竞争力，本文的方法在截肢个体上取得了目前最先进的结果。更多资料可在项目网页上找到。
## 137. `cs.AI` - 一组实现有效的仅投毒无标签后门攻击的通用组件，结合协作样本选择和触发器 [PDF](https://arxiv.org/pdf/2509.19947), [HTML](https://arxiv.org/abs/2509.19947)
### Authors
Zhixiao Wu,Yao Lu,Jie Wen,Hao Sun,Qi Zhou,Guangming Lu
### Background
现有的方法通常将样本选择和触发器处理分离，导致同时提高攻击成功率（ASR）和隐蔽性非常困难。常见的方法仅通过堆叠方法实现攻击的PCBA（Poison-only Clean-label Backdoor Attack），从而导致攻击的评价结果非常不理想。
### Innovation
本文提出了一套通用组件，旨在结合样本选择和触发器的协作关系，以同时提高攻击成功率和隐蔽性。具体创新包括Component A 和Component B 作为新的组件，Component C 则通过视觉系统对RGB颜色敏感性的差异来实现更高的ASR。同时，这些组件可以在不同的PCBA中战略性地组合使用。
### Conclusion
本文通过引入协作样本选择和触发器的概念，提出了一种新的方法来实现有效的仅投毒无标签后门攻击。通过基于攻击共性的组件设计，本文能够在保持其他攻击的一般性的同时，显著提高攻击的成功率和隐蔽性。
## 138. `cs.AI` - 通过神经元-注意力分解解读基于ResNet的CLIP [PDF](https://arxiv.org/pdf/2509.19943), [HTML](https://arxiv.org/abs/2509.19943)
### Authors
Edmund Bu,Yossi Gandelsman
### Background
当前研究中，人们致力于开发能够解释神经网络内部运作的方法，特别是在CLIP-ResNet这样的预训练模型中。这项研究借鉴了之前的工作，探索了如何通过分解神经元和注意力头的贡献来理解这些模型，旨在更好地理解和利用这些模型的内部机制和输出结果。
### Innovation
该研究提出了一种新颖的技术，通过将CLIP-ResNet模型中神经元的贡献分解为个体计算路径来进行解释。具体来说，研究者分析了所有神经元对与CLIP注意力池化层中的注意力头的所有两两组合。研究发现，这些神经元-注意力头组合可以通过CLIP-ResNet图像-文本嵌入空间中的一个方向来近似表示。利用这一洞察，研究者通过将每个神经元-注意力头组合与文本关联来进行解释。此外，研究还发现，只有少量的神经元-注意力头组合对输出值有显著贡献，而一些看似多义的组合实际上是对应神经元的子概念。这些发现被用于训练无监督的语义分割和监控数据集分布变化的两个应用中，从而展示了这种方法的潜力。
### Conclusion
研究结果表明，通过检查神经网络中的个体计算路径可以揭示可解释的单位，并且这些单位可以被利用来处理下游任务。这项工作为理解和利用更大规模和复杂模型的内部机制提供了一种新的方法。
## 139. `cs.AI` - CollaPipe: 在异构边缘网络中为协作大语言模型训练优化段优化管道并行性 [PDF](https://arxiv.org/pdf/2509.19855), [HTML](https://arxiv.org/abs/2509.19855)
### Authors
Jiewei Chen,Xiumei Deng,Zehui Xiong,Shaoyong Guo,Xuesong Qiu,Ping Wang,Dusit Niyato
### Background
随着对智能化移动应用程序的需求不断增加，多代理与基于Transformer的大语言模型（LLMs）在移动边缘计算（MEC）网络中的协作变得必不可少。然而，训练这些LLMs仍然面临计算量大、端到端延迟高以及模型泛化能力有限等挑战。
### Innovation
我们提出了CollaPipe，这是一种混合分布学习框架，结合了协作管道并行和联邦聚合，支持自我演进的智能网络。CollaPipe通过将编码器部分适应性地划分为不同大小的段并部署在移动设备上进行管道并行训练，同时将解码器部署在边缘服务器上处理生成任务。通过联邦聚合进行全局模型更新。为了提高训练效率，我们提出了一个联合优化问题，动态分配模型段、微批处理、带宽和传输功率。我们依据柳普诺夫优化设计了一个基于闭合形式收敛界的动态段调度和资源分配（DSSDA）算法，确保在长期约束下系统的稳定性。
### Conclusion
在针对Transformer和BERT模型的下游任务的广泛实验中，CollaPipe提高了计算效率高达15.09%，减少了至少48.98%的端到端延迟，并将单设备内存使用量减少了超过一半，使在线学习在异构和动态通信环境中成为可能。
## 140. `cs.AI` - 全面表达难以言说：基于多模态视频投诉数据集的用户投诉文本生成 [PDF](https://arxiv.org/pdf/2509.19952), [HTML](https://arxiv.org/abs/2509.19952)
### Authors
Sarmistha Das,R E Zera Marveen Lyngkhoi,Kirtan Jain,Vinayak Goyal,Sriparna Saha,Manish Gupta
### Background
尽管已经有很多关于可解释的投诉挖掘的工作，但在通过文本或视频传达用户关切方面仍存在很大挑战，常常导致问题未能解决。用户通常难以用清晰的文本描述其投诉，但很容易上传展示产品缺陷的视频（例如，仅用模糊的文本如‘最差产品’配以一段描述听力线损坏的5秒视频）
### Innovation
本研究提出了一个新的任务——视频投诉描述（CoD-V），旨在帮助用户更好地描述其对产品质量的不满。为此，我们介绍了ComVID数据集，包含1175个带有描述及投诉者情绪状态的视频投诉内容。同时，提出了一种新的评价指标——投诉保留率（CR），用于区分CoD-V任务与标准视频摘要生成和描述任务之间的性能。为了支持这一目标，我们引入了一种结合检索增强生成（RAG）机制的多模态VideoLLaMA2-7b模型，该模型在生成投诉时会考虑用户的感情状态。通过一系列语料库和模型的全面评估，该研究为用户通过视频表达投诉提供了理论依据和方法工具
### Conclusion
本研究为投诉挖掘领域提供了新的研究方向，并奠定了通过多模态方法帮助用户通过视频更精准表达投诉的基础。相关数据集和资源可在该网址获取：this https URL
## 141. `cs.AI` - 大型活性粒子群的有效控制及其应用于疏散问题 [PDF](https://arxiv.org/pdf/2509.19972), [HTML](https://arxiv.org/abs/2509.19972)
### Authors
Albina Klepach,Egor E. Nuzhin,Alexey A. Tsukanov,Nikolay V. Brilliantov
### Background
在不同的领域，如人群管理、机器人群控制以及协调的材料搬运，操控大规模的活性粒子群都是一项严峻的挑战。现有的控制策略在复杂场景下的可扩展性和鲁棒性不足，特别是在需要对每个代理进行单独控制时。因此，探索通过一个领导者或领导者团队来控制整个系统的方法成为了一种可能的解决方案。
### Innovation
本文提出了一个结合强化学习（RL）和人工力的有效控制策略，通过一个领导者（如机器人救援员）引导活性粒子群。引入广义Vicsek模型来描述领导者对活性粒子的引导机制。实验表明，尽管直接使用RL可能无法完全优化结果，但该方法可以提供一个稳健且高效的疏散策略。此外，研究代码可以在指定的网址找到，便于进一步研究和应用。
### Conclusion
本文通过一个领导者以提供一种新的控制策略，结合了强化学习和人工力的方式，应用于大型人群的疏散问题中。结果显示，这种策略在不同复杂性架构中提供了更为有效的疏散策略，相比直接使用RL方法效果更优。
## 142. `cs.AI` - CorIL：向丰富印度语言到印度语言平行语料库和机器翻译系统的方向努力 [PDF](https://arxiv.org/pdf/2509.19941), [HTML](https://arxiv.org/abs/2509.19941)
### Authors
Soham Bhattacharjee,Mukund K Roy,Yathish Poojary,Bhargav Dave,Mihir Raj,Vandan Mujadia,Baban Gain,Pruthwik Mishra,Arafat Ahsan,Parameswari Krishnamurthy,Ashwath Rao,Gurpreet Singh Josan,Preeti Dubey,Aadil Amin Kak,Anna Rao Kulkarni,Narendra VG,Sunita Arora,Rakesh Balbantray,Prasenjit Majumdar,Karunesh K Arora,Asif Ekbal,Dipti Mishra Sharma
### Background
印度的语言景观是世界上最丰富的之一，包含超过120种主要语言和大约1600种其他语言，其中有22种被印度宪法正式认可为官方语言。虽然近年来多语言神经机器翻译（NMT）的进步显著，但印度语言之间的高质量平行语料库仍然稀缺，尤其是在各种领域之间的语料库更是罕见。现有的多语言模型尚无法满足多样语言对之间的翻译需求，亟需建设高质量的平行语料库以提升机器翻译系统的性能和适应性。
### Innovation
本文介绍了CorIL，一个涵盖11种印度语言（英语、泰卢固语、印地语、旁遮普语、奥里萨语、克什米尔语、信德语、狗拉语、卡纳达语、乌尔都语和古吉拉特语）的大型高质平行语料库，总计包含772,000个双语句对。CorIL被仔细策划并系统分类为三大关键领域：政府、健康和一般领域，以支持领域导向的机器翻译研究，并促进有效领域的适应性学习。为了展示CorIL的价值并为未来的研究建立强有力的基准，本文针对此语料库进行了若干最先进的NMT模型的微调与评估，包括IndicTrans2、NLLB和BhashaVerse。实验结果揭示了模型性能的关键趋势，并突显了语料库在探索模型能力方面的价值。尤其是在不同语言文字系统的翻译表现上，结果显示大规模多语言模型在波斯-阿拉伯文字系统（乌尔都语、信德语）上占有优势；而其他模型在印度文字系统上表现出色。CorIL还提供了详细的领域导向型性能分析，提供了对领域敏感性和跨文字系统迁移学习的见解。公开CorIL意在极大地改善印度语言的高质量训练数据可用性，为机器翻译研究社区提供宝贵的资源。
### Conclusion
通过提供CorIL，本文旨在大大提升印度语言高质量训练数据的可获得性，为机器翻译研究社区提供宝贵的资源。此外，CorIL被认为是印度语言机器翻译研究的基础，有助于进一步的领域导向性研究及模型的适应性学习。
## 143. `cs.AI` - 选择绿色之路：通过动态模型选择推进Green AI [PDF](https://arxiv.org/pdf/2509.19996), [HTML](https://arxiv.org/abs/2509.19996)
### Authors
Emilio Cruciani,Roberto Verdecchia
### Background
人工智越来越普及，并且模型越来越复杂，具有出色的预测性能。但这些快速的技术进步也带来了令人担忧的环境成本。最先进的模型，特别是深度神经网络和大型语言模型，需要大量的计算资源和能源。这项工作中，我们提出了Green AI动态模型选择的直觉，其基于动态模型选择的方法，旨在通过选择最可持续的模型来减少AI的环境足迹，同时将潜在的准确性损失降到最低。具体来说，我们的方法会考虑到推理任务，可用模型的环境可持续性以及准确性需求，以动态选择最合适的模型。我们还展示了通过基于真实数据集的概念验证实验结果来证明我们的方法的有效性，
### Innovation
我们提出的Green AI动态模型选择方法提供了两种不同的方法，即Green AI动态模型级联和Green AI动态模型路由。我们的研究表明，通过这种方法，Green AI动态模型选择能够取得显著的能源节约（最多约25％），并且仍然保留了最耗能的解决方案的大部分准确性（约95％）。
### Conclusion
初步研究表明，混合、自适应的模型选择策略有潜力减轻现代AI系统的能源需求，而不会显著牺牲准确性需求。
## 144. `cs.AI` - 2025东南亚十一国影响力报告 [PDF](https://arxiv.org/pdf/2509.19953), [HTML](https://arxiv.org/abs/2509.19953)
### Authors
Wei Meng
### Background
本研究构建了一个全面的数据驱动和可重复的东南亚影响力指数（SAII v3），旨在减少专家评分偏见和主观权重的影响，同时揭示东盟十一国的层级权力结构。该研究收集了四个维度（经济、军事、外交、社会和技术）的权威开源指标，并通过一种三重标准化链（分位数-Box-Cox最小-最大）来减轻异常值和偏斜性。权重通过熵权法（EWM）、CRITIC和主成分分析（PCA）的等权重集成获得。通过Kendall's tau、+/-20%权重扰动和10,000次bootstrap迭代等方法来评估其稳健性，还包括+/-10%维度敏感性和V2-V3图表比较的额外检查。结果显示经济占35-40%，军事占20-25%，外交约20%，社会和技术约15%。区域格局表现出一强两中三稳多弱的模式，印尼、新加坡、马来西亚领先，而泰国、菲律宾和越南形成中等竞争梯队。
### Innovation
SAII v3通过算法权重和可审计的可重复性，揭示了东南亚多维驱动因素，提供了区域政府和外部伙伴在资源配置和政策优先级方面有操作性的量化证据。V2和V3的排名高度一致，尽管存在一些小的中等梯队重新排序，表明V3对结构性均衡更为敏感。东南亚-11国平均敏感性显示军事和社会技术维度对影响有最大的边际效应。
### Conclusion
SAII v3为减少专家评分偏见和提供透明可重复的影响力评估提供了一种方法，并揭示了东盟地区多维度的主导因素，为区域政府和外部合作伙伴在资源分配和政策制定方面提供了可操作的定量证据。
## 145. `cs.AI` - 基于主动学习的表格检测 [PDF](https://arxiv.org/pdf/2509.20003), [HTML](https://arxiv.org/abs/2509.20003)
### Authors
Somraj Gautam,Nachiketa Purohit,Gaurav Harit
### Background
高效的数据标注仍然是机器学习中的关键挑战，特别是在需要大量标记数据的对象检测任务中。传统的主动学习（AL）方法主要依赖不确定性选择样本，但近期的研究表明，结合多样性策略可以提高在这些任务中的采样效率。我们的方法旨在确保选择能够提升模型泛化的代表性样本，通过在两个基准数据集（TableBank-LaTeX，TableBank-Word）上使用先进表格检测架构（CascadeTabNet和YOLOv9）进行评估，证明了基于主动学习的样本选择相较随机采样有显著优势，能够在有限的预算内减少标注工作量，并保持与完全监督模型相当的性能。
### Innovation
文章提出的方法结合了多样性策略，针对对象检测任务中的样本选择，旨在提高模型的泛化能力。通过利用先进的表格检测架构，与传统的基于不确定性选择主动学习方法相比，该方法能够在保持相近性能的同时，降低标注成本和工作量。
### Conclusion
在有限的标注预算内，基于主动学习的样本选择显著优于随机采样方法，该方法不仅提升了表格检测的性能，还大幅减少了数据标注的工作量，证明了其在实际应用中的优势。
## 146. `cs.AI` - SDE-DET：复杂果园环境中沙田柚检测的高精度网络 [PDF](https://arxiv.org/pdf/2509.19990), [HTML](https://arxiv.org/abs/2509.19990)
### Authors
Yihao Hu,Pan Wang,Xiaodong Bai,Shijie Cai,Hang Wang,Huazhong Liu,Aiping Yang,Xiangxiang Li,Meiping Ding,Hongyan Liu,Jianguo Yao
### Background
沙田柚的定位、自动机器人采收及成熟度分析依赖于有效的检测过程。然而，在复杂果园环境中，沙田柚检测面临多尺度问题、树干和树叶阻挡、小目标检测等挑战，这些都增加了检测的难度和复杂性。
### Innovation
该研究构建了一个自定义数据集STP-AgriData，并提出了SDE-DET模型，该模型通过引入Star Block高效获取高维度信息、采用可变形注意力机制以增强对遮挡条件下的检测能力，以及集成多种高效多尺度注意力机制降低计算开销并提取深度视觉表示来应对上述挑战，从而提高了小目标的检测能力。
### Conclusion
实验结果显示，在沙田柚检测中，SDE-DET模型在精确度、召回率、mAP@0.5、mAP@0.5:0.95 和 F1分数上分别达到了0.883、0.771、0.838、0.497和0.823，突破了现有技术水平。该工作为自动收获机器人的发展提供了可靠的沙田柚检测方法，奠定了重要基础。
## 147. `cs.AI` - 将生成对抗网络应用于生物特征认证与识别中的隐私保护 [PDF](https://arxiv.org/pdf/2509.20024), [HTML](https://arxiv.org/abs/2509.20024)
### Authors
Lubos Mjachky,Ivan Homoliak
### Background
生物特征认证系统在很多领域得到广泛应用，但这些系统不能允许用户参与其数据的使用方式，数据可能会泄露并可能在用户不知情的情况下被滥用。
### Innovation
提出了一种基于生成对抗网络（GAN）的新认证方法，通过将面部图像转换到视觉私人领域（如花朵或鞋子），之后用于认证目的的分类器将在此视觉私人领域中训练。这种方法在攻击面前表现出良好鲁棒性，同时也提供有用的用途。
### Conclusion
实验结果表明，这种方法具备良好的安全性和实用性。
## 148. `cs.AI` - 负责任的人工智能技术报告 [PDF](https://arxiv.org/pdf/2509.20057), [HTML](https://arxiv.org/abs/2509.20057)
### Authors
KT:Soonmin Bae,Wanjin Park,Jeongyeop Kim,Yunjin Park,Jungwon Yoon,Junhyung Moon,Myunggyo Oh,Wonhyuk Lee,Junseo Jang,Dongyoung Jung,Minwook Ju,Eunmi Kim,Sujin Kim,Youngchol Kim,Somin Lee,Wonyoung Lee,Minsung Noh,Hyoungjun Park,Eunyoung Shin
### Background
KT开发了一种负责任的人工智能（RAI）评估方法和风险管理技术，以确保人工智能服务的安全和可靠性。通过分析《人工智能实施基本法》和全球人工智能治理趋势，KT建立了一种独特的监管合规方法，并系统地识别和管理从人工智能开发到运营的所有潜在风险因素。
### Innovation
KT开发了一种基于自身人工智能风险分类法的、量身定制于国内环境的可靠评估方法，系统地验证模型的安全性和鲁棒性。此外，还提供了实用的工具来管理和减轻发现的人工智能风险。同时，发布了专有的Guardrail：SafetyGuard，这是一种能够实时阻止有害响应的人工智能模型安全防护工具，以支持国内人工智能开发生态系统中的安全性提升。
### Conclusion
这些研究成果为寻求开发负责任的人工智能的组织提供了宝贵的见解。
## 149. `cs.AI` - 扩散增强对比学习：一种生物信号表示的噪声鲁棒编码器 [PDF](https://arxiv.org/pdf/2509.20048), [HTML](https://arxiv.org/abs/2509.20048)
### Authors
Rami Zewail
### Background
学习生物信号的稳健表示往往受到有效数据设计挑战的影响，现有的方法可能无法捕捉生理数据中固有的复杂变化。因此，本研究提出了一种名为Diffusion-Augmented Contrastive Learning (DACL)的新型混合框架，该框架结合了扩散模型和监督对比学习的概念。
### Innovation
DACL框架通过在轻量级自编码器生成的潜在空间中使用扩散前向过程作为噪声数据增强技术，生成多视角的潜在嵌入。通过具有监督对比目标的U-Net风格编码器来学习平衡类别判别和噪声鲁棒性的表示。
### Conclusion
本研究在体感电生理数据集上验证了该方法，取得了竞争性的AUROC（0.7815）。该工作通过将扩散过程本身用于对比目标，开辟了一种新的表示学习范式，能够生成噪声不变的嵌入，为类别可分性奠定了坚实的基础。
## 150. `cs.AI` - 多语言模型在方言自然语言处理任务中的标记化和表示偏差 [PDF](https://arxiv.org/pdf/2509.20045), [HTML](https://arxiv.org/abs/2509.20045)
### Authors
Vani Kanjirangat,Tanja Samardžić,Ljiljana Dolamic,Fabio Rinaldi
### Background
方言数据具有对人类来说较小但对模型性能影响显著的细微语言差异。这些差异受到多种因素（如数据量、经济与社会因素等）的影响，但这些因素的影响并不一致。以往研究表明，直接因素，如标记化一致性和信息一致性（作为预训练多语言模型中表征偏差的衡量标准），对于理解模型性能至关重要。该研究探讨了标记化一致性和信息一致性如何直接关联下游任务的表现，控制数据资源（高资源与低资源）和书写系统（拉丁字母与非拉丁字母）的差异，以分析多语言模型在方言任务中的表现及其背后的原因。
### Innovation
该研究直接通过标记化一致性和信息一致性来关联预训练多语言模型的表示偏差与下游表现，首次系统地比较了基于编码器的模型和解码器仅模型在多种方言任务（包括方言分类、主题分类和抽取式问答）中的表现，并揭示了这些模型在不同任务中的不同预测因子。此外，通过分析标记化行为、词汇覆盖率和质性见解，研究进一步指出了多语言模型的语言支持声明可能掩盖了更深层次的书写或标记级不匹配问题。
### Conclusion
研究表明，标记化一致性在预测依赖于句法和形态线索的任务（如抽取式问答）方面表现更好，而信息一致性在预测涉及语义的任务（如主题分类）方面表现更好。研究还揭示，多语言模型的语言支持声明可能掩盖了更深层次的书写或标记级不匹配，这些发现为改善多语言模型在方言任务中的表现提供了理论依据。
## 151. `cs.AI` - 项目性柯尔莫哥洛夫-阿诺尔德神经网络（P-KANs）：熵驱动的功能空间发现方法及其在可解释机器学习中的应用 [PDF](https://arxiv.org/pdf/2509.20049), [HTML](https://arxiv.org/abs/2509.20049)
### Authors
Alastair Poole,Stig McArthur,Saravan Kumar
### Background
Kolmogorov-Arnold Networks (KANs)能够将可学习的非线性函数从节点转移到边中，展示了在科学机器学习和可解释建模方面的显著能力。然而，当前的KAN实现因高维样条参数空间中的冗余性而受制于根本性的低效率，导致过拟合和泛化能力差。这种冗余性会在模型的雅可比矩阵中表现为一个“非必需空间”，从而增加了过拟合的易发性。
### Innovation
本文提出了Projective Kolmogorov-Arnold Networks (P-KANs)，这是一种新型的训练框架，通过信号分析和稀疏字典学习中的熵最小化技术引导边函数向可解释的功能表示收敛。我们的方法在保持样条空间灵活性的同时引入了“引力”项来促进向最优功能表示的收敛。我们通过熵分析投影系数来识别最优表示，并将边函数压缩到更低参数的投影空间中（如傅里叶、切比雪夫、贝塞尔）。P-KANs在多个领域中展示了优越的表现，实现了高达80%的参数减少，保持了表示能力，具备更强的噪声鲁棒性，并成功应用于工业自动化纤维铺放预测。
### Conclusion
本文的方法能够自动发现混合功能表示，使得不同边收敛到不同的最优空间，从而提供压缩优势和增强的可解释性，以适应科学机器学习的应用需求。
## 152. `cs.AI` - 全能滤波器：一种通用的状态估计滤波器 [PDF](https://arxiv.org/pdf/2509.20051), [HTML](https://arxiv.org/abs/2509.20051)
### Authors
Shiqi Liu,Wenhan Cao,Chang Liu,Zeyu He,Tianyi Zhang,Shengbo Eben Li
### Background
状态估计在自然科学和工程学领域中的动态系统建模中是一个长期存在的问题。传统的状态估计方法在某些情况下可能不够精确或有效，尤其是在处理噪声观察时。本文提出的背景是需要一种新的方法来更准确地进行状态估计，特别是利用已训练的语言模型来进行动态系统的状态估计，这与传统的基于学习的方法相比，可能具有更高的精度和更强的适应性.
### Innovation
本文提出了一种名为LLM-Filter的新颖滤波框架，它利用大型语言模型（LLMs）通过文本原型嵌入噪声观察来进行状态估计。与当前最先进的基于学习的方法相比，LLM-Filter在机会实验中表现出色，并且通过精心设计的提示结构（System-as-Prompt，SaP），使得语言模型能够理解估计任务，从而实现更好的泛化能力。此外，观测到LLM-Filter在更大型模型和更长训练时间时呈现规模效益，提高了准确度。因此，LLM-Filter被认为是滤波领域的有前景的基础模型.
### Conclusion
LLM-Filter 在状态估计任务上表现出显著优势，能够通过预训练的语言模型实现更准确的估计，特别是在噪声环境下。提示结构 SaP 的设计提升了模型的泛化能力。随着模型规模的增长和训练时间的延长，准确度有所提高，这表明 LL defenseM-Filter 可以作为滤波任务的强大基础模型。
## 153. `cs.AI` - LLM评估框架：带答案生成的集成方法 [PDF](https://arxiv.org/pdf/2509.20097), [HTML](https://arxiv.org/abs/2509.20097)
### Authors
Sujeong Lee,Hayoung Lee,Seongsoo Heo,Wonik Choi
### Background
可靠的大型语言模型（LLM）评估对于确保它们在实际场景中的适用性至关重要。传统的基于基准的评估方法通常依赖于固定的参考答案，限制了它们捕捉生成响应的重要定性方面的能力。
### Innovation
我们提出了一种集成评估框架，称为‘专家驱动诊断的自我改进描述性评估’（SPEED），它利用专门的功能专家进行全面、描述性的模型输出分析。与传统的评估方法不同，SPEED 在多个维度上积极采用专家反馈，包括幻觉检测、毒性评估和语义上下文适用性评估。实验证明，SPEED 在不同领域和数据集上实现了稳健且一致的评估性能，同时通过使用较小的专家模型，SPEED 在资源效率方面表现出色。这些结果表明，SPEED 显著提高了LLM评估的公平性和可解释性，并提供了一种现有评估方法的有前途的替代方案。
### Conclusion
SPEED 框架显著增强了LLM评估的公平性和可解释性，提供了一种具有希望的评估方法替代方案。
## 154. `cs.AI` - 使用视觉基础模型的高光谱适配器进行语义分割 [PDF](https://arxiv.org/pdf/2509.20107), [HTML](https://arxiv.org/abs/2509.20107)
### Authors
JuanaJuana Valeria Hurtado,Rohit Mohan,Abhinav Valada
### Background
高光谱成像（HSI）可以通过捕获空间信息和大量的窄波段密集光谱测量来丰富场景信息，这对于复杂材料环境、不同照明条件或视觉挑战条件下的人工智能感知具有潜在优势。然而，目前的HSI语义分割方法仍表现不佳，因为它们依赖于优化用于RGB输入的架构和学习框架。
### Innovation
本文提出了一种新的高光谱适配器，利用预训练的视觉基础模型来有效地学习高光谱数据。该架构包括光谱转换器和光谱感知空间先验模块，以提取丰富的空间-光谱特征。此外，还引入了一种模态感知交互块，通过专门的提取和注入机制来促进高光谱表示与冻结的视觉Transformer特征的有效集成。
### Conclusion
在三个基准自动驾驶数据集上的广泛评估表明，本文架构在直接使用HSI输入的情况下达到了最先进的语义分割性能，超越了视觉基和高光谱分割方法。
## 155. `cs.AI` - LLMs因果理解的作用：不确定性的作用 [PDF](https://arxiv.org/pdf/2509.20088), [HTML](https://arxiv.org/abs/2509.20088)
### Authors
Oscar Lithgow-Serrano,Vani Kanjirangat,Alessandro Antonucci
### Background
最近的研究表明，大规模语言模型（LLMs）在因果关系分类上的准确率接近随机，引发了对其失败原因的质疑，是否是由于预训练曝光的限制还是深层表示差距导致的。该研究进一步探讨了在不确定性评估下，通过测试预训练中因果示例的暴露是否能改善因果理解能力，对超过18000个PubMed句子进行了测试，这些句子包含了half来自The Pile语料库和half来自2024年以后的内容。研究还分析了两种行为：因果关系分类（模型识别文本中的因果关系）和原文字记忆探测（评估模型是否偏好原始的因果陈述而不是它们的改写版）。结果显示，模型在已见过与未见过的句子上的准确率几乎相同（p > 0.05），没有记忆偏见（24.8%选择原始陈述），输出分布基本均匀，熵值接近最大值（1.35/1.39），表明随机猜测。指令调整模型出现了严重的校准偏差（Qwen: > 95%置信度，32.8%准确率，ECE=0.49）。条件关系导致最高的熵（+11%对比直接关系）。这些发现表明，因果理解上的失败源自缺乏结构化的因果表示，而不是预训练过程中对因果示例的不足暴露导致的.
### Innovation
研究通过不确定性评估手段，揭示了因果关系分类的准确率接近随机的原因，并进一步评估了预训练暴露对因果理解能力的影响。研究还通过分析模型的行为和验证其对因果关系的处理，提供了对LLMs因果理解缺陷的新见解，特别强调了无结构因果表示是主要问题。此外，指令调整模型的严重校准偏差进一步证实了这一结论。
### Conclusion
研究发现，LLMs在因果理解上的不足更多地体现在无法构建有效的因果表示结构，而不是对因果示例的预训练曝光不足。模型在不同类型的因果关系处理过程中显示出的随机性反应和指令调整模型的严重校准偏差进一步支持了这一观点。
## 156. `cs.AI` - LLM-based Chatbots中的知识-行为断层 [PDF](https://arxiv.org/pdf/2509.20004), [HTML](https://arxiv.org/abs/2509.20004)
### Authors
Jan Broersen
### Background
大型语言模型（如ChatGPT）能够回答各种问题，且很多情况下提供正确答案。基于这一能力，人们可能认为它们具有知识。但是，作者认为这些模型不以这种方式使用它们的知识来指导自身的对话行为。作者将这种差异称为‘断层’，并指出这种断层是根本性的，即使拥有更多数据和更长时间的训练，它也不会消失。作者还提到，基本训练技术限制了LLM的能力，解释了幻觉的来源。
### Innovation
论文探讨了大型语言模型（LLM）驱动的对话机器人中的知识-行为断层现象，提出了这种断层是根本性的，并非通过增加数据和训练时间可以消除。作者进一步讨论了伦理对话知识与伦理对话行为之间的不一致，并分析了当前影响对话机器人行为的技术无法解决这一断层问题，甚至可能使其恶化。
### Conclusion
断层反映出LLM核心技术在建立所需连接方面的根本限制，并解释了幻觉的来源。这一结论引起了对当前对话机器人伦理问题的重视，指出现有解决方法可能不足以解决根本的断层问题。
## 157. `cs.AI` - KSDiff: 关键帧增强的语音感知双路径扩散模型在面部动画中的应用 [PDF](https://arxiv.org/pdf/2509.20128), [HTML](https://arxiv.org/abs/2509.20128)
### Authors
Tianle Lyu,Junchuan Zhao,Ye Wang
### Background
语音驱动的面部动画在多媒体应用中取得了显著进展，扩散模型在说话人脸合成中显示出巨大潜力。然而，大多数现有工作将语音特征视为单一的表示，未能捕捉其在驱动不同面部动作中的细微作用，同时也忽视了使用动态密集的关键帧建模的重要性。因此，需要一种方法来解决这些问题。
### Innovation
本文提出了KSDiff，一种关键帧增强的语音感知双路径扩散框架。该框架包括一个双路径语音编码器（DPSE）来分解表情相关和头部姿态相关的特征，以及一个自回归的关键帧建立学习（KEL）模块，预测最具显著性的动作帧。这些组成部分被整合到双路径动作生成器中，以生成连贯和逼真的面部动作。实验结果表明，KSDiff在唇同步准确性和头部姿态自然性方面达到了最先进的性能。
### Conclusion
研究结果表明，将语音去混洗与关键帧感知扩散相结合，能够有效生成说话头部，证明了该方法的有效性。
## 158. `cs.AI` - 离散扩散在自主驾驶中反射视觉-语言-行动模型中的应用 [PDF](https://arxiv.org/pdf/2509.20109), [HTML](https://arxiv.org/abs/2509.20109)
### Authors
Pengxiang Li,Yinan Zheng,Yue Wang,Huimin Wang,Hang Zhao,Jingjing Liu,Xianyuan Zhan,Kun Zhan,Xianpeng Lang
### Background
端到端（E2E）解决方案已成为自主驾驶系统的主要方法，视觉-语言-行动（VLA）模型作为一种新范式出现，它利用视觉-语言模型（VLMs）的预训练多模态知识来解释和与复杂现实环境交互。然而，这些方法仍然受限于模仿学习的限制，在训练过程中难以内在地编码物理规则。现有方法往往依赖复杂的基于规则的后调整、有限的强化学习（主要局限于模拟）或需要昂贵的梯度计算的扩散引导。
### Innovation
我们提出了ReflectDrive，一种结合了反射机制的学习框架，用于通过离散扩散生成安全轨迹。我们首先将二维驾驶空间离散化，构建动作代码簿，通过微调使用预训练的扩散语言模型来进行规划任务。我们的方法的核心在于一种安全意识反射机制，可以在无需梯度计算的情况下进行迭代自我纠正。方法基于目标导向的轨迹生成来建模多模态驾驶行为，然后使用局部搜索方法识别不安全的令牌，确定可行的解决方案，用于基于图像恢复的再生。ReflectDrive在NAVSIM基准测试中展示了在关键轨迹生成方面的显著优势，提供了一种可扩展且可靠的自主驾驶系统解决方案。
### Conclusion
ReflectDrive通过结合离散扩散和安全意识反射机制，在现有方法的局限性上实现了突破，为自主驾驶系统的安全轨迹生成提供了新的解决方案。
## 159. `cs.AI` - U-Mamba2-SSL for Semi-Supervised Tooth and Pulp Segmentation in CBCT [PDF](https://arxiv.org/pdf/2509.20154), [HTML](https://arxiv.org/abs/2509.20154)
### Authors
Zhi Qin Tan,Xiatian Zhu,Owen Addison,Yunpeng Li
### Background
在锥形束计算机断层扫描（CBCT）中，准确分割牙齿和牙髓对于临床应用如治疗规划和诊断至关重要。然而，这一过程需要大量的专业知识，并且极其耗时，因此迫切需要能够有效利用未标记数据的自动化算法。
### Innovation
提出了一种新的半监督学习框架U-Mamba2-SSL，该框架基于U-Mamba2模型，并采用多阶段训练策略。首先，通过一个破坏性的自编码器以自监督方式预训练U-Mamba2模型。然后，通过一致性正则化利用未标记数据，引入输入和特征扰动以确保模型输出的稳定性。最后，实施了伪标签策略，并降低了损失权重以减少潜在错误的影响。
### Conclusion
U-Mamba2-SSL在验证数据集上取得了0.872的平均分数和0.969的DSC值，证明了我们方法的优越性能。代码可从以下链接获得：this https URL.
## 160. `cs.AI` - 高维少量样本表格数据中的关联规则发现 [PDF](https://arxiv.org/pdf/2509.20113), [HTML](https://arxiv.org/abs/2509.20113)
### Authors
Erkan Karabulut,Daniel Daza,Paul Groth,Victoria Degeler
### Background
关联规则挖掘（ARM）旨在以命题规则的形式发现数据集中特征之间的模式，支持高风险决策中的知识发现和可解释机器学习。然而，在高维设置中，规则爆炸和计算成本使得流行算法方法变得不实用，除非有效减少搜索空间，这些问题影响了下游任务。虽然最近提出的神经符号方法，如Aerial+，旨在解决ARM中的规则爆炸问题，但它们也继承了神经网络的局限性，特别是在数据量较少的情况下表现较差。
### Innovation
本研究对高维表格数据中的关联规则发现做出了三项关键贡献。首先，实验证明Aerial+在五个真实数据集上相比最先进的算法和神经符号基线在规模上提高了1到2个数量级。其次，提出了高维和少量样本设置下的ARM新问题，例如生物医学领域基因表达数据，具有约18000个特征和50个样本。第三，提出了两种针对Aerial+的微调方法，利用表格基础模型。我们的方法在五个真实数据集上显著提高了规则质量，证明了它们在少量样本和高维场景中的有效性。
### Conclusion
本研究展示了Aerial+在五个真实数据集上的性能，并提出了两种用于Aerial+的微调方法，证明了它们在大量数据和少量样本、高维场景中的有效性。
## 161. `cs.AI` - EchoBench: Benchmarking Sycophancy in Medical Large Vision-Language Models [PDF](https://arxiv.org/pdf/2509.20146), [HTML](https://arxiv.org/abs/2509.20146)
### Authors
Botai Yuan,Yutian Zhou,Yingjie Wang,Fushuo Huo,Yongcheng Jing,Li Shen,Ying Wei,Zhiqi Shen,Ziwei Liu,Tianwei Zhang,Jie Yang,Dacheng Tao
### Background
近期，医疗大型视觉-语言模型（LVLMs）的基准测试主要关注排行榜上的准确性，忽视了可靠性和安全性。研究发现，在高风险的临床环境中，模型倾向于无批判性地重复用户提供的信息，这种行为称为讨好行为。为了更好地评估这一问题，作者开发了EchoBench基准测试，并指出一些医疗特异性模型在低准确度的情况下，其讨好行为却高达95%以上。
### Innovation
作者开发了EchoBench基准测试，以系统性地评估医疗LVLMs中的讨好行为。该基准测试涵盖2,122张图片，各种20种模态和18个部门，包括90个模拟偏见输入的提示。研究还表明，通过提高数据质量和多样性，以及增强领域知识，可以有效地降低模型的讨好行为，而不会损害模型的客观准确性。此外，作者还提出了一些简单的提示层面的干预策略，这些策略可以在训练和解码时应用，并有效地减少了模型的讨好行为。
### Conclusion
研究发现，现有医疗LVLMs在准确性之外还需要更全面的评价体系。论文还提供了具体的改进策略，以促进更安全和值得信赖的医疗LVLMs的发展。
## 162. `cs.AI` - RTL 设计的自动多代理工作流 [PDF](https://arxiv.org/pdf/2509.20182), [HTML](https://arxiv.org/abs/2509.20182)
### Authors
Amulya Bhattaram,Janani Ramamoorthy,Ranit Gupta,Diana Marculescu,Dimitrios Stamoulis
### Background
AI在工作流程中的兴起为计算机系统的设计和优化带来了新的机会。然而，在像程序合成这样的专业领域，与更常见的编程任务相比，HDL资源和专有EDA工具资源的稀少性带来了挑战，通常需要特定任务的微调、高昂的推理成本和手动编排代理。
### Innovation
本文提出了一种多代理框架VeriMaAS，旨在自动化组合硬件描述语言（RTL）代码生成的代理工作流。关键创新点在于直接将HDL工具的正式验证反馈融入到工作流生成中，以减少基于梯度的更新成本或长时间推理痕迹。该方法在通过k-精度衡量的综合性能上相比微调基线提高了5-7%，并且只需要少量的训练样例，从而将监督成本减少了数量级的量级差异。
### Conclusion
VeriMaAS框架通过集成HDL工具的正式验证反馈，自动化的生成RTL代码生成工作流的方式，提高了综合性能，并显著减少了监督成本。
## 163. `cs.AI` - 通过应用结构相似性改进时间序列异常检测 [PDF](https://arxiv.org/pdf/2509.20184), [HTML](https://arxiv.org/abs/2509.20184)
### Authors
Tiejun Wang,Rui Wang,Xudong Mou,Mengyuan Ma,Tianyu Wo,Renyu Yang,Xudong Liu
### Background
现代工业应用和金融系统中，时间序列异常检测对于有效识别异常至关重要。然而，由于异常标签稀缺且人工标注成本高昂，现有的重建为基础的无监督方法虽已获得一定关注，但仍然难以准确检测出时间序列中的异常。这是因为这些方法仅依赖于点到点的距离度量进行优化，忽略了时间序列的潜在结构性特征，难以捕捉复杂模式的异常。
### Innovation
本文提出了StrAD（Structure-enhanced Anomaly Detection）方法，通过将时间序列中隐含的结构信息融入优化目标，引导数据重建过程更好地捕捉结构特征。StrAD模型优化目标包括趋势、季节性和形态，以学习潜在的结构特征并捕捉时间序列的本质模式变化。该机制与任何基于重建的方法均可插件式结合，增强了模型对点异常和模式异常的敏感性。
### Conclusion
实验结果表明，StrAD方法能够提升现有基于重建的模型在五个实际异常检测数据集上的性能。该方法能够确保原始数据和重建数据在结构特征上的对齐，从而保持整体波动性和局部特征的一致性。
## 164. `cs.AI` - 人们如何在‘第二个大脑’中管理知识——使用Obsidian进行的行业研究人员案例研究 [PDF](https://arxiv.org/pdf/2509.20187), [HTML](https://arxiv.org/abs/2509.20187)
### Authors
Juliana Jansen Ferreira,Vinícius Segura,Joana Gabriela Souza,Joao Henrique Gallas Brasil
### Background
人们在工作和生活中面临着大量的信息，因此需要有效的组织和管理策略。个人也需要通过日常活动来记录、标注、组织和检索知识，以备将来参考，这被称为个人知识库。便笺应用为建立和维护这些知识库提供了有价值的工具，通常被称为‘第二个大脑’。本文的背景是研究人们如何构建和探索个人知识库，以及便笺工具Obsidian在这一过程中的应用。
### Innovation
本文的创新在于采用案例研究的方式，深入探讨了便笺工具Obsidian在行业研究人员构建和探索个人知识库中的具体应用。特别是在揭示了参与者的知识检索策略如何影响其内容构建和维护的过程方面提供了独特的视角。
### Conclusion
研究发现，参与者的知识检索策略会影响他们如何构建和维护其内容。作者建议可能的AI系统功能来支持这一过程。
## 165. `cs.AI` - 情绪计算与情绪数据：隐私法规、AI法案及大型语言模型中的挑战与伦理涵义 [PDF](https://arxiv.org/pdf/2509.20153), [HTML](https://arxiv.org/abs/2509.20153)
### Authors
Nicola Fabiano
### Background
本文探讨将情绪智能融入人工智能系统中的问题，重点关注情绪计算以及大型语言模型（如ChatGPT和Claude）在识别和响应人类情绪方面的能力。研究结合了计算机科学、心理学和神经科学的跨学科研究成果，分析了处理面部表情的卷积神经网络（CNNs）和处理序列数据（如语音和文本）的循环神经网络（RNNs）作为情绪识别的基础神经架构。文章讨论了将人类情感体验转化为结构化情绪数据的问题，特别是在研究环境中通过知情同意收集的明确情绪数据与通过日常数字互动收集的隐性数据之间的区别，提到了对合法处理、AI透明度及个人在数字环境中对其情绪表达的自主权的重要关切。此外，文章还探讨了不同文化背景在情感表达方面的差异以及情感识别系统在不同人口群体中可能存在的偏见问题，并从监管角度来看，文中讨论了GDPR和欧盟AI法案框架下情绪数据的处理问题，强调了将情绪数据视为敏感个人数据所需的严格保护措施，包括目的限制、数据最小化以及有意义的同意机制。
### Innovation
研究结合了跨学科方法，融合了计算机科学、心理学和神经科学的知识，探讨了情绪数据在人工智能系统中的整合与应用，特别是在情感计算中的角色。文章特别关注大型语言模型（LLMs）在识别和响应人类情绪方面的最新进展，并讨论了这一领域面临的挑战和伦理问题。
### Conclusion
本文探讨了将情绪智能融入人工智能系统的重要性，特别是在情绪计算和大型语言模型中的应用。研究指出，随着技术的进步，需要对情感数据进行更加严格的监管和保护，特别是在GDPR和欧盟AI法案框架下。文章呼吁制定更具针对性的策略来保护个人在数字环境中对其情绪表达的自主权，并减少情感识别系统中的潜在偏见，以促进更加公平和伦理的技术进步。
## 166. `cs.AI` - CyberSOCEval: 检验大语言模型在恶意软件分析和威胁情报推理方面的能力 [PDF](https://arxiv.org/pdf/2509.20166), [HTML](https://arxiv.org/abs/2509.20166)
### Authors
Lauren Deason,Adam Bali,Ciprian Bejean,Diana Bolocan,James Crnkovich,Ioana Croitoru,Krishna Durai,Chase Midler,Calin Miron,David Molnar,Brad Moon,Bruno Ostarcevic,Alberto Peltea,Matt Rosenberg,Catalin Sandu,Arthur Saputkin,Sagar Shah,Daniel Stan,Ernest Szocs,Shengye Wan,Spencer Whitman,Sven Krasser,Joshua Saxe
### Background
当前的网络安全防御者面临着大量的安全警报、威胁情报信号以及不断变化的业务环境的挑战，迫切需要人工智能系统来增强其运行安全工作。尽管大型语言模型（LLMs）有潜力自动化和扩大安全运营中心（SOC）的操作，但现有的评估并未充分涵盖真实世界防御者最相关的场景。缺乏富有见地的LLM性能评估影响了AI开发者和将LLMs应用于SOC自动化的人们。同时，恶意行为者正在使用AI来扩大网络攻击规模，突显了推动采用和社区驱动改进的开源基准的重要性。因此，作者介绍了一个名为CyberSOCEval的新开源基准套件，该套件包含两个任务的基准测试：恶意软件分析和威胁情报推理，这是当前基准测试中覆盖不足的核心防御领域。
### Innovation
该论文提出了一个新的开源基准套件CyberSOCEval，用以评估LLMs在恶意软件分析和威胁情报推理方面的能力。评估显示，更大的、更新的LLMs表现更好，确认了训练规模效应理论。还发现，在测试中使用缩放模型的推理并不像在编程和数学中那样获得同样的增益，这意味着这些模型没有被训练来推理关于网络安全分析的问题，并指出了改进的关键领域。最终，现有的LLMs远未达到这些评估的饱和点，表明CyberSOCEval为AI开发者提供了改进网络安全防御能力的重要挑战。
### Conclusion
当前的LLMs在某些安全领域还没有充分展现潜力，特别是在恶意软件分析和威胁情报推理方面。CyberSOCEval提供了一个显著的挑战，让开发者们能够有针对性地提升其模型在这些安全领域的表现。
## 167. `cs.AI` - 通过增强生成的强化学习嵌入大型语言模型的领域知识 [PDF](https://arxiv.org/pdf/2509.20162), [HTML](https://arxiv.org/abs/2509.20162)
### Authors
Chaojun Nie,Jun Zhou,Guanxiang Wang,Shisong Wud,Zichen Wang
### Background
大型语言模型（LLMs）在特定领域的任务上表现受限，主要是因为训练数据中领域特定信息的自然比例不均和数据集的静态特性。知识稀缺性和时间滞后性会导致知识缺口，影响领域应用。虽然在领域数据集上进行后训练可以将知识嵌入模型，但现有方法存在一些限制。持续预训练（CPT）对所有领域文档中的令牌赋予相同的重要性，未能优先考虑关键知识点，而监督微调（SFT）使用问答对难以形成复杂推理任务所需的连贯知识结构。
### Innovation
我们提出了一种增强生成的强化学习（RLAG）方法。该方法通过循环轮换生成采样和通过计算奖励优化模型，有效嵌入关键且上下文相关的领域知识。我们选择具有最高对数概率的生成输出作为采样结果，然后计算三个定制的奖励指标来指导优化过程。为了全面评估领域专业知识，我们评估了答案准确性和正确答案解释的合理性。实验结果表明，我们的方法显著优于基础方法。
### Conclusion
我们在医学、法律、天文学和当前事件数据集上进行的实验结果表明，所提出的方法在性能上显著优于基线方法。我们的代码和数据已开源，可通过此链接获取：https://github.com/your-repository-link
## 168. `cs.AI` - 低资源英语-提格雷尼亚语机器翻译：利用多语言模型、自定义分词器和清洁评估基准 [PDF](https://arxiv.org/pdf/2509.20209), [HTML](https://arxiv.org/abs/2509.20209)
### Authors
Hailay Kidu Teklehaymanot,Gebrearegawi Gidey,Wolfgang Nejdl
### Background
尽管神经机器翻译（NMT）已经取得了显著进步，但像提格雷尼亚语这样的低资源语言仍因缺乏语料库、不足的分词策略和缺乏标准评价基准等问题而未得到充分服务。本研究探索了使用多语言预训练模型的迁移学习技术以提高形态学丰富的低资源语言的翻译质量。
### Innovation
该研究提出了一种改进的方法，其中包括语言特定的分词、启发式嵌入初始化和领域适应性微调。此外，还构建了一个高质量的人工对齐的英语-提格雷尼亚语评估数据集，涵盖了各种领域，以进行严格的评估。实验结果表明，使用自定义分词器的迁移学习方法相对于零样本基线有显著提升，并通过BLEU、chrF和定性的手动评价验证。
### Conclusion
本研究强调了在减少代表性不足语言的性能差距方面使用语言意识建模和可复现实验基准的重要性。结果可在以下网址获取：this https URL和this https URL。
## 169. `cs.AI` - STAF: 利用LLMs进行基于攻击树的自动化安全测试生成 [PDF](https://arxiv.org/pdf/2509.20190), [HTML](https://arxiv.org/abs/2509.20190)
### Authors
Tanmay Khule,Stefan Marksteiner,Jose Alguindigue,Hannes Fuchs,Sebastian Fischmeister,Apurva Narayan
### Background
在现代汽车开发中，安全测试至关重要，以抵御日益先进的威胁。攻击树被广泛用于系统地表示潜在攻击路径，但将这些树转换为全面的测试用例仍然是一个劳动密集型、容易出错的任务，车辆系统的测试中自动化程度有限。
### Innovation
STAF（安全测试自动化框架）引入了一种新型方法来自动生成安全测试用例。它利用大规模语言模型（LLMs）和四步自纠正检索增强生成（RAG）框架，从攻击树自动生成可执行的安全测试用例，提供一个端到端的涵盖整个攻击面的解决方案。我们展示了一个LLM所需的小部件和流程，以实际生成有意义且可执行的汽车安全测试套件，还包括了与自动化测试框架的集成。我们还展示了我们的定制方法与通用（vanilla）LLMs，以及使用我们的方法不同LLMs（GPT-4.1和DeepSeek）的性能，并通过一个具体的案例研究展示了我们操作方法的步骤。
### Conclusion
我们的结果表明，在效率、准确性、可扩展性以及与任何工作流程的易于集成方面取得了显著改进，标志着在自动化汽车安全测试方法上的重大进展。通过使用TARAs作为验证测试的输入，我们建立了两个关键汽车安全保障过程元素之间的协同作用。
## 170. `cs.AI` - 最优秀者浮出水面：Verilog代码生成的高效重排方法 [PDF](https://arxiv.org/pdf/2509.20215), [HTML](https://arxiv.org/abs/2509.20215)
### Authors
Guang Yang,Wei Zheng,Xiang Chen,Yifan Sun,Fengji Zhang,Terry Yue Zhuo
### Background
LLMs在生成Verilog代码时面临重大挑战，因为它们缺乏特定领域的知识。虽然抽样技术可以提高pass@k指标，但硬件工程师更需要一个可靠而非确定的候选方案。为解决这个问题，论文将其转化为需求与Verilog实现之间的语义对齐问题，并提出了VCD-RNK，这是一种针对高效Verilog代码重排定制的判别模型。
### Innovation
VCD-RNK通过融合专家知识在三个维度上的精炼：代码语义分析、测试案例生成和功能正确性评估，具体模拟上述推理过程，避免了现有方法中繁重的测试执行计算强度，提供了高效可靠的Verilog代码重排方法。
### Conclusion
论文提出了一种名为VCD-RNK的判别模型，通过高效地重排Verilog代码，解决了LLMs在生成Verilog代码时缺乏特定领域知识的问题，从而为硬件工程师提供了一个可靠的解决方案。
## 171. `cs.AI` - Multimodal Representation-disentangled Information Bottleneck for Multimodal Recommendation [PDF](https://arxiv.org/pdf/2509.20225), [HTML](https://arxiv.org/abs/2509.20225)
### Authors
Hui Wang,Jinghui Qin,Wushao Wen,Qingling Li,Shanshan Zhong,Zhongzhan Huang
### Background
多模态数据通过整合多种信息源来建模用户偏好和项目特征，显著推动了推荐系统的进步。然而，这些系统在处理冗余和无关信息时常常遇到困难，这可能会降低性能。现有的大多数方法要么直接融合多模态信息，要么使用固定的架构分离，无法很好地过滤噪声和建模模态之间的复杂相互作用。
### Innovation
本文提出了一种新型框架，多模态表示分离信息瓶颈（MRdIB）。首先，使用多模态信息瓶颈压缩输入表示，有效过滤掉与任务无关的噪声，同时保留丰富的语义信息。然后，根据与推荐目标的关系分解信息，分为独特、冗余和协同作用的组件。分解信息通过约束实现，包括唯一信息学习目标、冗余信息最小重叠目标和协同信息学习目标。通过优化这些目标，MRdIB 指导模型学习更强大的和分离的表示。
### Conclusion
我们在多种竞争模型和三个基准数据集上的大量实验表明，MRdIB 在增强多模态推荐方面既有效又具有灵活性。
## 172. `cs.AI` - Q-Palette：接近最优比特分配的分数比特量化器以实现高效的大语言模型部署 [PDF](https://arxiv.org/pdf/2509.20214), [HTML](https://arxiv.org/abs/2509.20214)
### Authors
Deokjae Lee,Hyun Oh Song
### Background
研究了在无需重新训练的情况下量化大型语言模型（LLM）权重的加权后训练量化（PTQ）方法，这种方法使用少量或几乎不使用校准数据。加权PTQ对于减少LLM推理的记忆占用和延迟至关重要，特别是在内存受限和小批次推理场景中，如边缘设备上的个性化推理。LLM中的不规则权重分布，特别是重尾异常值，增加了量化难度，促成了通过旋转方法将权重转换为近似高斯分布的研究，这种分布更容易被量化且异常值较少，从而降低了量化误差。
### Innovation
本研究首先基于给定比特预算推导了高斯化权重的信息论上最优比特分配，发现逼近高斯失真率上限的细粒度分比特量化器对于实现接近最优的量化性能是必不可少的。为将理论发现与实际应用结合，引入了Q-Palette，这是一个多样化的分比特量化器集合，从梯形编码量化器（近最优失真）到为了更快推理而优化的简单向量和标量化量化器，并通过优化的CUDA内核实现了各种比特宽度下的高效实施。利用Q-Palette作为基础组件，提出了一个新颖的混合量化框架，该框架在资源限制下联合优化量化器选择和层融合决策。
### Conclusion
Q-Palette框架和基于此框架的混合量化方案能够实现对LLM高效部署的最优比特分配，提高量化性能并优化推理速度。
## 173. `cs.AI` - 按照类型规则玩游戏：声明式程序中LLM函数的约束推断 [PDF](https://arxiv.org/pdf/2509.20208), [HTML](https://arxiv.org/abs/2509.20208)
### Authors
Parker Glenn,Alfy Samuel,Daben Liu
### Background
在声明性查询语言中集成由大型语言模型（LLM）支持的操作，可以将廉价且可解释的功能与强大且普适的语言模型推理相结合。然而，为了从数据库查询语言（如SQL）的优化执行中受益，生成的输出必须符合类型检查器和数据库内容设置的规则。当前方法通过许多基于LLM的后处理调用来确保生成的输出与数据库值之间的对齐，这引入了性能瓶颈。
### Innovation
研究不同大小的开源语言模型在基于SQL的语言中解析和执行函数的能力，表明小型语言模型在混合数据源中作为函数执行器表现出色。提出了一种高效的方法来强制LLM函数的类型正确性，在多跳问答数据集上实现了7%的准确性改进，并且在延迟方面比可比解决方案提高了53%。开源实现提供于提供的链接。
### Conclusion
研究表明小型语言模型在执行函数方面在混合数据源上表现出色，并提出了一种高效方法来确保LLM函数的类型正确性，从而提高多跳问答数据集上的准确性并减少延迟。
## 174. `cs.AI` - 通过反馈导向多点优化超越尖锐极小值：鲁棒的大语言模型去学习 [PDF](https://arxiv.org/pdf/2509.20230), [HTML](https://arxiv.org/abs/2509.20230)
### Authors
Wenhan Wu,Zheyuan Liu,Chongyang Gao,Ren Wang,Kaize Ding
### Background
当前的LLM去学习方法面临一个关键的安全漏洞，这会影响它们的基本目标。虽然它们试图成功地移除敏感或有害的知识，但这些“遗忘”的信息实际上可以通过重新学习攻击轻易恢复。原因在于传统方法通过每个数据点优化遗忘损失，这些方法将模型参数推向不稳定区域中的尖锐极小值。在这些区域中，即使微小的参数扰动也会显著改变模型的行为。因此，重新学习攻击利用这一漏洞，仅使用少量精细调整样本就能够在这些不稳定区域周围找到陡峭梯度，从而迅速恢复被移除的知识。这表明，表面上的去学习和实际的知识移除之间存在一个关键的鲁棒性差距。
### Innovation
我们提出了StableUN，一个基于双层反馈指导优化框架，通过邻域感知优化明确寻找更稳定的参数区域。它结合了遗忘反馈（使用对抗扰动来探测参数邻域）与记忆反馈以保持模型的适用性，通过梯度投影将两个目标进行了对齐。实验结果表明，我们的方法在抵御重新学习和越狱攻击方面具有显著的鲁棒性，同时保持了竞争力的适用性能。
### Conclusion
我们的实验表明，StableUN框架在应对重新学习和越狱攻击时具有更高的鲁棒性，同时保持了与传统方法相当的适用性能，从而填补了表面上去学习和实际知识移除之间差距。
## 175. `cs.AI` - ImageNet-trained CNNs are not biased towards texture: Revisiting feature reliance through controlled suppression [PDF](https://arxiv.org/pdf/2509.20234), [HTML](https://arxiv.org/abs/2509.20234)
### Authors
Tom Burgert,Oliver Stoll,Paolo Rota,Begüm Demir
### Background
关于卷积神经网络（CNNs）是否固有地更偏向于处理纹理特征，这一假设对深度学习领域中特征使用的讨论产生了影响。以往的研究，如Geirhos等人进行的线索冲突实验，存在一定的局限性，因此本文重新审视了这一假设。通过提出一个领域无关的框架，系统性地抑制形状、纹理和颜色线索，避免了强制选择冲突带来的混淆，从而对人类和神经网络在受控抑制条件下的性能进行了评估。
### Innovation
本文提出了一种领域无关的框架，通过系统抑制形状、纹理和颜色线索来量化特征依赖性，避免了以往研究中的强制选择冲突带来的混淆。研究发现，CNNs并非固有地偏向于处理纹理特征，而是主要依赖于局部形状特征；现代训练策略或架构（如ConvNeXt和ViTs）能够显著降低这一依赖性。此外，还进一步分析了计算机视觉、医学成像和遥感领域的模型，发现不同领域的模型在特征依赖性上存在系统性差异：计算机视觉模型更依赖形状，医学成像模型更强调颜色，而遥感模型则表现出更强的纹理依赖性。
### Conclusion
研究结果表明，虽然CNNs主要依赖于局部形状特征，但现代训练策略或架构能够显著降低其这种依赖性。不同领域的模型在特征依赖性上存在系统性差异，应考虑领域的特异性来选择合适的模型或训练策略。
## 176. `cs.AI` - 基于HyperGraphMamba的多通道自适应模型在ncRNA分类中的应用 [PDF](https://arxiv.org/pdf/2509.20240), [HTML](https://arxiv.org/abs/2509.20240)
### Authors
Xin An,Ruijie Li,Qiao Ning,Hui Li,Qian Ma,Shikai Guo
### Background
非编码RNA（ncRNA）在基因表达调控和多种疾病的发生机制中起着关键作用。准确分类ncRNA对于功能注释和疾病诊断至关重要。然而，现有的特征提取深度和技术融合方面存在局限性。
### Innovation
本文提出了一种基于HyperGraphMamba的多通道自适应模型HGMamba-ncRNA，该模型整合了ncRNA的序列、二级结构以及可选的表达特征，通过平行多尺度卷积和LSTM架构（MKC-L）捕捉核苷酸的局部模式和长程依赖性，通过多尺度图变换器（MSGraphTransformer）表示ncRNA二级结构的多级拓扑特征，通过切比雪夫多项式基于的柯尔莫哥洛夫-阿诺尔德网络（CPKAN）有效建模和解释高维表达谱。最后，通过引入虚拟节点促进高效且全面的多模态交互，提出HyperGraphMamba以自适应对齐和集成多通道异质模态特征。实验表明，HGMamba-ncRNA在三个公开数据集上的准确性和其他指标上均优于最先进的方法。
### Conclusion
广泛的实证研究表明，HGMamba-ncRNA模型具有鲁棒性、有效性及强大的迁移性，提供了一种新颖可靠的复杂ncRNA功能分类策略。代码和数据集可在提供的网址获取。
## 177. `cs.AI` - AnchDrive：使用混合轨迹锚点初始化扩散策略的端到端驾驶 [PDF](https://arxiv.org/pdf/2509.20253), [HTML](https://arxiv.org/abs/2509.20253)
### Authors
Jinhao Chai,Anqing Jiang,Hao Jiang,Shiyi Mu,Zichong Gu,Shugong Xu
### Background
端到端多模态规划已成为自动驾驶的一项变革性范式，有效解决长尾场景中的行为多模态和泛化挑战。现有的基于生成模型的扩散策略需要大量的计算资源，这提高了它们在实际应用中的成本。AnchDrive通过引入混合轨迹锚点来初始化扩散策略，降低了传统生成模型的计算成本。混合轨迹锚点结合了静态的驾驶先验词汇和动态、感知上下文相关的轨迹，通过这些锚点的引导，扩散模型可以高效地生成多样且高质量的轨迹。
### Innovation
AnchDrive框架采用了混合轨迹锚点（hybrid trajectory anchors）初始化生成模型（diffusion policy），克服了传统生成模型对计算资源的高度依赖。具体地，这些锚点由静态的通用驾驶先验词汇和实时解码的动态轨迹组成。扩散模型能够通过预测轨迹偏移分布实现微细化的轨迹生成，从而提高生成多样且高质量轨迹的效率。
### Conclusion
在NAVSIM基准测试上的实验表明，AnchDrive性能优越，并且具有出色的泛化能力。
## 178. `cs.AI` - 探讨自动生成代码对软件供应链安全影响的研究 [PDF](https://arxiv.org/pdf/2509.20277), [HTML](https://arxiv.org/abs/2509.20277)
### Authors
Xiaofan Li,Xing Gao
### Background
近年来，软件供应链（SSC）攻击对全球社区构成了重大风险。开发人员如果在其产品中集成易受SSC攻击的不安全代码片段，可能会造成严重的后果。尤其是代码生成技术，例如大规模语言模型（LLMs），在开发人员社区中被广泛应用，但这些模型在生成代码时存在固有问题，包括虚构、误导信息以及依赖过时的训练数据，所有这些都可能导致严重的软件供应链威胁。
### Innovation
本文研究了因固有问题而对SSC造成的安全威胁。作者探讨了三种类型的安全威胁，包括11种潜在的与源代码外部组件和持续集成配置文件相关的SSC威胁。设计了一个名为SSCGuard的工具，基于从在线收集到的SSC相关问题生成了439,138个提示，并分析了GPT和Llama四种流行LLM的响应。结果表明，所有发现的SSC相关威胁持续存在。为了减轻这些风险，提出了一种新型的基于提示的防御机制，即逐链确认，以及基于中间件的防御措施来通知用户各种SSC威胁。
### Conclusion
研究发现，所有发现的SSC相关威胁都持续存在。为此，提出了基于逐链确认的新型提示防御机制，以减少虚构现象，并提出基于中间件的防御措施来告知用户各种SSC威胁，以减轻这些风险。
## 179. `cs.AI` - 当判断变成噪声：LLM评判基准设计缺陷如何静默地损害有效性 [PDF](https://arxiv.org/pdf/2509.20293), [HTML](https://arxiv.org/abs/2509.20293)
### Authors
Benjamin Feuer,Chiung-Yi Tseng,Astitwa Sarthak Lathe,Oussama Elachqar,John P Dickerson
### Background
近年来，LLM（大型语言模型）评判的基准越来越多地被用来评估复杂模型的行为，然而这些基准的设计引入了一些在传统基于真实地标的基准中不存在的失败模式。我们发现，如果没有明确的目标和可验证的构建，基准排名可能会产生高置信度但实际上是大量噪音的结果，这对评估模型的行为提出了挑战。
### Innovation
本文引入了两种诊断机制：1) 核心遵从性，量化了评判者整体评价中有多少部分是由明确的评价准则所解释的，揭示了评判者偏离其自定义评分标准时的未解释变量；2) 心理测量有效性和内部一致性与辨别有效的聚合，量化任何基准测试运行中无法降低的不确定性。这些工具被应用于Arena-Hard Auto，发现了严重的评分准则不一致和因子崩溃现象，如DeepSeek-R1-32B的未解释变异超过90%，各标准因子的相关性超过0.93。此外，结果还表明Arena-Hard Auto所使用的类似ELO的综合方式会掩盖真实的排名不确定性。这些研究结果突显了在设计LLM评判基准时的失效设计，这些设计损害了评估的有效性，并提供了构建更好的范围、更可靠基准的原则。本文还发布了代码支持相关分析和验证过程。
### Conclusion
本文的研究结果强调了设计缺陷如何和平静地损害LLM评判基准的有效性，并提供了一系列可操作的准则，以构建更好的范围、更可靠基线环境。
## 180. `cs.AI` - 评估与元评估中机器翻译中兼顾还是偏重？适当性流畅性权衡 [PDF](https://arxiv.org/pdf/2509.20287), [HTML](https://arxiv.org/abs/2509.20287)
### Authors
Behzad Shayegh,Jan-Thorsten Peter,David Vilar,Tobias Domhan,Juraj Juraska,Markus Freitag,Lili Mou
### Background
研究探讨了机器翻译中适当性和流畅性之间的权衡关系。当前的评估指标通常倾向于适当性，这意味着它们的评分更偏向于翻译的适当性，而不是流畅性。这种权衡不仅在评估层面表现明显，在元评估层面也存在，标准的WMT元评估偏爱适当性导向的指标而非流畅性导向的指标。研究指出，这种偏向部分归因于参与元评估数据集中的系统构成。
### Innovation
提出了在元评估中合成翻译系统的办法以控制偏见，旨在解决适当性流畅性权衡在评估和元评估中的问题，强调理解这种权衡及其对指标排名的影响的重要性。
### Conclusion
需理解适当性和流畅性权衡在元评估中的重要性及其对指标排名的影响，研究提出了合成翻译系统的方法来控制偏见，表明适当性和流畅性在机器翻译评估和元评估中需要平衡考虑。
## 181. `cs.AI` - 视频模型是零样本学习者和推理者 [PDF](https://arxiv.org/pdf/2509.20328), [HTML](https://arxiv.org/abs/2509.20328)
### Authors
Thaddäus Wiedemer,Yuxuan Li,Paul Vicol,Shixiang Shane Gu,Nick Matarese,Kevin Swersky,Been Kim,Priyank Jaini,Robert Geirhos
### Background
大型语言模型（LLMs）的出色零样本能力推动了自然语言处理从任务特定模型转变为了通用的基础模型。这种转变源自简单的基础：大量生成模型，这些模型在互联网规模的数据上进行训练。有趣的是，相同的原理也适用于今天的生成视频模型。因此，研究者们提出，视频模型是否有类似的路径，最终发展为通用视觉理解的基础模型？
### Innovation
研究团队展示了Veo 3模型能够解决多种未在训练中明确指定的任务，包括物体分割、边检测、图像编辑、物理属性理解、对象功能识别、工具使用模拟等。这些能力使模型能够进行早期形式的视觉推理，如迷宫和对称性求解，表明视频模型正在朝着成为统一、通用视觉基础模型的方向发展.
### Conclusion
研究发现，视频模型具备了类似的零样本能力，暗示视频模型可能向通用视觉理解的基础模型发展。
## 182. `cs.AI` - DRES：评估LLMs在消解不流畅语句方面的基准 [PDF](https://arxiv.org/pdf/2509.20321), [HTML](https://arxiv.org/abs/2509.20321)
### Authors
Maria Teleki,Sai Janjur,Haoran Liu,Oliver Grabner,Ketan Verma,Thomas Docog,Xiangjue Dong,Lingfeng Shi,Cong Wang,Stephanie Birkelbach,Jason Kim,Yin Zhang,James Caverlee
### Background
不流畅语句（如“嗯”、“啊”，插入语、括号内的内容以及编辑过的陈述）一直是依赖语音的系统中的一个持续挑战，它们会降低命令解释、总结以及对话代理的准确性。DRES引入了一种经过控制的文本级别基准，用于建立该任务的可再现语义上限。该基准基于人类注释的Switchboard转录，隔离了消解不流畅语句与ASR错误和声学变化的影响，并系统地对不同规模、提示策略和架构的专有和开源LLMs进行了评估。
### Innovation
DRES构建了一个经过控制的文本级别基准，为消解不流畅语句任务设立了可再现的语义上限。该基准基于人类注释的Switchboard转录，并隔离了消解不流畅语句与ASR错误和声学变化的影响。该基准系统地评估了专用和开源的LLMs在不同规模、提示策略和架构方面的能力。研究发现，简单分割方法能提高性能，甚至适用于长上下文模型。并且，以推理为导向的模型倾向于过度删除流畅的词，微调可以实现接近最先进的精准度和召回率，但会损害泛化能力。
### Conclusion
DRES提供了一个可再现且模型无关的基线，以推进稳健的口语系统。此外，研究报告了一组与LLM特定的错误模式和九项实用建议（R1-R9），旨在促进语音驱动管道中不流畅消解的部署。
## 183. `cs.AI` - 使用电路追踪揭开解码器唯一体积中的图推理 [PDF](https://arxiv.org/pdf/2509.20336), [HTML](https://arxiv.org/abs/2509.20336)
### Authors
Xinnan Dai,Chung-Hsiang Lo,Kai Guo,Shenglai Zeng,Dongsheng Luo,Jiliang Tang
### Background
基于Transformer的大型语言模型在图推理任务上表现出强大的性能，但其内部机制尚未得到充分探索。本研究旨在通过电路追踪框架来揭示解码器唯一体积模型的图推理内在工作机制，为从基础和统一的角度理解这些模型提供帮助和理论依据。
### Innovation
本研究采用基础的解码器唯一体积Transformer模型，并通过电路追踪框架解释其工作机制。研究识别了两个核心机制——标记合并和结构记忆，并量化了这些行为如何受图的密度和模型大小的影响。这一研究提供了一个统一的解释框架，以理解解码器唯一体积Transformer中的结构化推理机制，填补了这一领域研究空白，为未来研究提供了新视角和方法论支持。
### Conclusion
本研究通过电路追踪框架揭示了解码器唯一体积Transformer在图推理任务中的关键工作机制。研究发现，标记合并和结构记忆是两类基础任务（路径推理和子结构提取）背后的重要机制，并且展示了这些行为如何随着图的密度和模型规模的变化而变化。这些发现为理解解码器唯一体积Transformer在图推理中的表现提供了新的视角，为未来的研究提供了有力的理论支持。
## 184. `cs.AI` - SIM-CoT: 监督式的隐式链式思维 [PDF](https://arxiv.org/pdf/2509.20317), [HTML](https://arxiv.org/abs/2509.20317)
### Authors
Xilin Wei,Xiaoran Liu,Yuhang Zang,Xiaoyi Dong,Yuhang Cao,Jiaqi Wang,Xipeng Qiu,Dahua Lin
### Background
隐式链式思维（Implicit Chain-of-Thought, CoT）方法为大型语言模型（LLMs）提供了一种与显式CoT推理相比更节省令牌的替代方案，但在实际应用中受制于性能差距。现有隐式CoT方法在增加隐式推理令牌以提升性能时，常常导致训练过程不稳定甚至崩溃。这种不稳定是由于隐式表示的同质化，使其丧失了语义多样性，主要原因是现有隐式CoT方法在步骤级监督方面不足。
### Innovation
SIM-CoT 提出了一种插拔式的训练模块，通过引入步骤级监督来稳定和丰富隐式推理空间。具体来说，SIM-CoT 在训练期间使用辅助解码器将每个隐式令牌与对应的显式推理步骤对齐，确保隐式状态捕捉到具有区分性和意义的信息。辅助解码器仅在训练时使用，推理时去除，保证了计算效率，并提供了隐式推理的可解释性。实验表明，SIM-CoT 显著提升了各种隐式CoT方法的领域内准确性和领域外稳定性，例如使 Coconut 的 GPT-2 基线提高了 8.2%，CODI 提高了 3.0%。此外，SIM-CoT 在计算效率提升了 2.3 倍的情况下，也超过了显式CoT基线，并在增大模型如 LLaMA-3.1 8B 中显著缩小了性能差距。
### Conclusion
SIM-CoT 通过引入步骤级监督解决了隐式CoT中的核心潜在不稳定性问题，有效稳定和丰富了隐式推理空间，提升了多种隐式CoT方法的性能，并展现了良好的可扩展性。
## 185. `cs.AI` - RAG 安全与隐私：形式化威胁模型与攻击面 [PDF](https://arxiv.org/pdf/2509.20324), [HTML](https://arxiv.org/abs/2509.20324)
### Authors
Atousa Arzanipour,Rouzbeh Behnia,Reza Ebrahimi,Kaushik Dutta
### Background
RAG 是自然语言处理中的一种新兴方法，结合了大规模语言模型（LLMs）和外部文档检索，以产生更准确和扎实的回应。虽然 RAG 在减少幻觉和提高事实一致性方面表现出色，但也引入了与传统LLMs不同的隐私和安全挑战。现有研究显示，LLMs可以通过训练数据的记忆或对抗性提示泄露敏感信息，而RAG系统继承了这些漏洞。同时，对RAG依赖于外部知识库打开了新的攻击面，包括泄露检索文档的存在或内容信息，或注入恶意内容以操控模型行为。尽管存在这些风险，现有研究尚未正式定义RAG系统的威胁格局。本文填补了这一文献空白，首先形式化介绍了检索RAG系统的威胁模型，并提出了一种基于对手对模型组件和数据访问类型的结构化对手分类法，以及定义了关键的威胁向量，包括文档级别的成员推理和数据污染，这些威胁在实际部署中对隐私和完整性构成了严重风险。通过建立正式定义和攻击模型，本研究为RAG系统的隐私和安全性提供了一个更为严谨和原则性的理解奠定了基础
### Innovation
本文首次提出了RAG系统中检索RAG系统的第一形式化的威胁模型，引入了一种基于对手对模型组件和数据访问类型的结构化对手类型分类法，以及定义了关键的威胁向量，包括文档级别的成员推理和数据污染。这些威胁向量在实际部署中对隐私和完整性构成了严重风险。通过建立正式定义和攻击模型，研究为更严谨和原则性的理解RAG系统的隐私和安全性奠定了基础
### Conclusion
通过引入结构化的威胁分类和正式定义关键威胁向量，本文的研究为RAG系统的隐私和安全性提供了一个更为严谨和原则性的理解。它为开发和部署更安全可靠的RAG系统提供了理论基础，并有助于引导未来的研究和实践方向。
## 186. `cs.AI` - Z-Scores: 评估语言中连贯性修复的指标 [PDF](https://arxiv.org/pdf/2509.20319), [HTML](https://arxiv.org/abs/2509.20319)
### Authors
Maria Teleki,Sai Janjur,Haoran Liu,Oliver Grabner,Ketan Verma,Thomas Docog,Xiangjue Dong,Lingfeng Shi,Cong Wang,Stephanie Birkelbach,Jason Kim,Yin Zhang,James Caverlee
### Background
评估语音中的连贯性修复需要超越简单的标记级别分数。传统的基于单词的指标（如准确度、召回率和F1分数）可以捕捉整体性能，但无法揭示模型成功或失败的原因。Z-Scores作为一种基于语言的评估指标，能够对不同类型的连贯性（编辑、插入、非谓语成分）进行分类，并通过确定性对齐模块实现生成文本和连贯性转录之间的稳健映射，从而揭示单单词指标所掩盖的系统性弱点。通过提供类别特定的诊断信息，Z-Scores能帮助研究人员识别模型的失败模式，并设计针对性的干预措施（如定制提示或数据增强），从而实现可衡量的性能提升。
### Innovation
Z-Scores是一种基于语言的评估指标，能够对不同类型的连贯性进行分类，并通过确定性对齐模块实现生成文本和连贯性转录之间的稳健映射，揭示单单词指标所遮掩的系统性弱点。它能提供类别特定的诊断信息，帮助研究人员识别模型的失败模式，并设计针对性的干预措施，如定制提示或数据增强，从而实现可衡量的性能提升。此外，通过案例研究发现Z-Scores能够揭示隐藏在聚合F1中的插入（INTJ）和非谓语成分（PRN）连贯性挑战，直接指导模型完善策略的制定。
### Conclusion
Z-Scores能够精确评估连贯性修复模型，并通过提供具体的类别诊断信息来帮助科研人员发现模型的弱点，并通过优化提示或数据增强等方法来提升模型性能。案例研究表明，Z-Scores能有效揭露INTJ和PRN连贯性隐藏的问题，从而直接指导模型优化策略的制定。
## 187. `cs.AI` - Tree Search for Language Model Agents [PDF](https://arxiv.org/pdf/2407.01476), [HTML](https://arxiv.org/abs/2407.01476)
### Authors
Jing Yu Koh,Stephen McAleer,Daniel Fried,Ruslan Salakhutdinov
### Background
自主语言模型（LMs）在执行诸如网络自动化等决策任务方面表现出巨大潜力。然而，这些模型在现实计算机任务中面临的挑战包括多步推理、规划能力的不足以及利用环境反馈的能力有限。
### Innovation
本文提出了一种推理时搜索算法，用于自主LM代理在交互式网络环境中进行显式的探索和多步规划。这是一种前向树搜索方法，适应性较强且适用于大多数现有的先进代理。该方法首次在自主LM代理上显示出对真实网络任务的有效性。在VisualWebArena基准测试中，基于GPT-4o代理并使用搜索算法，成功率提高了39.7%，达到了26.4%的新高。在WebArena中，搜索提高了28.0%的成功率，达到19.2%的新水平，表现出色的基线成功率。此外，实验证明搜索算法随着测试时计算量的增加而提升性能。研究还详细分析了搜索带来的改进、限制以及未来研究的前景方向。
### Conclusion
实验突显了搜索算法对网络代理的有效性，并展示了随着测试时计算量的增加，性能的提升。算法和模型已开源。
## 188. `cs.AI` - 自适应事件触发策略梯度在多智能体强化学习中的应用 [PDF](https://arxiv.org/pdf/2509.20338), [HTML](https://arxiv.org/abs/2509.20338)
### Authors
Umer Siddique,Abhinav Sinha,Yongcan Cao
### Background
传统的多智能体强化学习（MARL）方法依赖于时间触发的执行模式，智能体在固定时间间隔下采样和通信动作。这种做法通常计算成本高且通信密集。因此，为了解决这一限制，提出了ET-MAPG（事件触发多智能体策略梯度强化学习）框架，该框架联合学习智能体的控制策略和事件触发策略，与之前分离这两种机制的方法不同，ET-MAPG将它们集成到一个统一的训练过程中，使智能体不仅学习如何采取行动，还能学习何时执行这些行动。为了处理智能体间的通信场景，引入了AET-MAPG（基于注意力机制的事件触发多智能体策略梯度），利用自注意力机制学习选择性通信模式，使智能体不仅可以确定何时触发行动，还可以确定与谁通信以及交换何种信息，从而优化协调。
### Innovation
提出了一种联合学习控制策略和事件触发策略的ET-MAPG框架，并引入了利用自注意力机制的AET-MAPG作为基于注意力的变体，使智能体能够不仅决定何时触发行动，还能决定与谁通信以及交换何种信息。这两种方法可以与任何策略梯度MARL算法结合使用，实验结果显示，在不降低性能的情况下，显著降低了计算负载和通信开销。
### Conclusion
在多种多智能体强化学习基准测试中，作者的方法与现有时间触发的基线具有相似的性能，同时显著减少了计算负担和通信开销。
## 189. `cs.AI` - Ge'ez 语形态合成器：解决形态复杂性和资源限制问题 [PDF](https://arxiv.org/pdf/2509.20341), [HTML](https://arxiv.org/abs/2509.20341)
### Authors
Gebrearegawi Gebremariam,Hailay Teklehaymanot,Gebregewergs Mezgebe
### Background
Ge'ez 是一种古老而独特的闪米特语，被广泛用作提格里尼亚语、阿姆哈拉语等语言的书写系统。它在阿克苏姆王国时期对埃塞俄比亚的文化和宗教发展起到了至关重要的作用。尽管Ge'ez在埃塞俄比亚和厄立特里亚仍有重要意义，作为礼拜语言和国家身份文档的一部分，但它的复杂形态结构一直缺乏有效的自然语言处理工具。以往没有可用的形态学注释数据、语料库、标注数据集和词汇表，导致无法开发出任何实用的Ge'ez NLP系统。
### Innovation
这篇论文提出了基于规则的Ge'ez形态合成器，能够根据语言的形态结构从词根生成表层单词。通过对1,102个样本动词进行测试和评估，验证了系统的有效性，达到了97.4%的性能，优于基准模型。这表明未来的工作应构建一个全面考虑语言形态变体的系统。
### Conclusion
系统测试表明，基于规则的Ge'ez形态合成器能够在处理Ge'ez复杂的形态结构方面表现出色，并为未来的发展奠定了基础，应进一步构建全面考虑形态变体的系统。
## 190. `cs.AI` - EmbeddingGemma：强大的轻量级文本表示 [PDF](https://arxiv.org/pdf/2509.20354), [HTML](https://arxiv.org/abs/2509.20354)
### Authors
Henrique Schechter Vera,Sahil Dua,Biao Zhang,Daniel Salz,Ryan Mullins,Sindhu Raghuram Panyam,Sara Smoot,Iftekhar Naim,Joe Zou,Feiyang Chen,Daniel Cer,Alice Lisak,Min Choi,Lucas Gonzalez,Omar Sanseviero,Glenn Cameron,Ian Ballantyne,Kat Black,Kaifeng Chen,Weiyi Wang,Zhe Li,Gus Martins,Jinhyuk Lee,Mark Sherwood,Juyeong Ji,Renjie Wu,Jingxiao Zheng,Jyotinder Singh,Abheesht Sharma,Divya Sreepat,Aashi Jain,Adham Elarabawy,AJ Co,Andreas Doumanoglou,Babak Samari,Ben Hora,Brian Potetz,Dahun Kim,Enrique Alfonseca,Fedor Moiseev,Feng Han,Frank Palma Gomez,Gustavo Hernández Ábrego,Hesen Zhang,Hui Hui,Jay Han,Karan Gill,Ke Chen,Koert Chen,Madhuri Shanbhogue,Michael Boratko,Paul Suganthan,Sai Meher Karthik Duddu,Sandeep Mariserla,Setareh Ariafar,Shanfeng Zhang,Shijie Zhang,Simon Baumgartner,Sonam Goenka,Steve Qiu,Tanmaya Dabral,Trevor Walker,Vikram Rao,Waleed Khawaja,Wenlei Zhou,Xiaoqi Ren,Ye Xia,Yichang Chen,Yi-Ting Chen,Zhe Dong,Zhongli Ding,Francesco Visin,Gaël Liu,Jiageng Zhang,Kathleen Kenealy,Michelle Casbon,Ravin Kumar,Thomas Mesnard,Zach Gleicher,Cormac Brick,Olivier Lacombe,Adam Roberts,Yunhsuan Sung,Raphael Hoffmann,Tris Warkentin,Armand Joulin,Tom Duerig,Mojtaba Seyedhosseini
### Background
本文介绍了基于Gemma 3语言模型家族的新轻量级、开放文本嵌入模型EmbeddingGemma。该模型通过编码器-解码器初始化和几何嵌入蒸馏策略性地从较大模型捕获知识。利用扩散正则化提高模型的鲁棒性和表达性，并通过合并从不同优化混合中的检查点来确保模型的泛化性。该模型在多语言、英语和代码领域的巨量文本嵌入基准测试(MTEB)中取得了最先进的结果，拥有出色的性能与成本比，即使在量化模型权重或截断嵌入输出时性能依然保持领先。
### Innovation
EmbeddingGemma模型的创新之处在于其独特的训练配方——编码器-解码器初始化和几何嵌入蒸馏，以及通过扩散正则化提高模型的鲁棒性和表达性。此外，通过合并不同优化混合的检查点来确保模型的泛化性，使得该模型在性能与成本比上表现出色，并在量化模型权重或截断嵌入输出的情况下保持领先。
### Conclusion
EmbeddingGemma模型在MTEB上的表现证明了其在低延迟和高吞吐量应用场景（如客户端应用）上的优势。为促进进一步研究，作者提供了详细的消融研究，并向社区发布了该模型。
## 191. `cs.AI` - 强化学习与机器伦理：一项系统性回顾 [PDF](https://arxiv.org/pdf/2407.02425), [HTML](https://arxiv.org/abs/2407.02425)
### Authors
Ajay Vishwanath,Louise A. Dennis,Marija Slavkovik
### Background
机器伦理学是研究如何通过自主系统实现道德行为的领域。在2020年之前，已有系统性的文献综述试图总结机器伦理学的现状，但这些综述通常不包含使用强化学习代理作为需要实现道德行为的实体的研究。原因是最近几年内机器伦理学的研究在强化学习领域才有所增加。这项综述旨在系统性地回顾强化学习在实现机器伦理学中的应用，填补现有机器伦理学文献中的空白，特别是在道德规范、强化学习框架、组件以及用于产生道德行为的环境方面展露趋势。
### Innovation
本研究通过对强化学习在机器伦理学中的应用进行系统性回顾，填补了机器伦理学领域在2020年前的传统文献综述中的空白，特别是集中在道德规范、强化学习框架的组件、以及用于生成道德行为的环境等方面。这种回顾涵盖了强大的AI技术与伦理学规范相结合的新兴研究领域。这项工作对于理解AI伦理和相关研究具有重要意义，为未来的研究提供了基础。
### Conclusion
综上所述，本系统性回顾旨在全面概述强化学习在机器伦理学中的应用现状，通过综合分析和总结相关的研究成果，填补了该领域的一个重要研究缺口。这项研究为未来该领域的研究奠定了基础，有助于构建更加完善的机器伦理学框架。
## 192. `cs.AI` - STRIVE: 自我提升的声明验证中的结构推理 [PDF](https://arxiv.org/pdf/2502.11959), [HTML](https://arxiv.org/abs/2502.11959)
### Authors
Haisong Gong,Jing Li,Junfei Wu,Qiang Liu,Shu Wu,Liang Wang
### Background
声明验证任务是确定声明是否由证据支持或反驳的任务。自改进方法在数学问题解决等任务中取得了成功，但在这类任务中，这种方法遇到了挑战。低质量的推理链可能会错误地匹配二元真实标签，导致在自我改进过程中引入了错误的推理，最终影响了模型的性能。
### Innovation
本文提出了一种名为STRIVE（结构化推理用于自我改进验证）的方法，该方法通过声明分解、实体分析和证据接地验证引人了一种结构推理设计，从而提高推理质量、减少错误并提供额外的监督信号，以改善模型自我改进。STRIVE首先通过一个预热阶段微调基模型，以学习结构化推理设计。然后将其应用于生成所有训练示例的推理链，只选择正确的且结构良好的推理链进行后续的自我改进训练。实验结果表明，STRIVE在HOVER数据集上的性能大幅提高，与基线模型相比，性能提升了31.4%，与Chain of Thought相比提升了20.7%。
### Conclusion
STRIVE通过结构推理设计和精细的推理链条生成策略，显著提高了声明验证任务的性能。
## 193. `cs.AI` - PGCLODA: 基于提示的图对比学习在寡肽-传染病关联预测中的应用 [PDF](https://arxiv.org/pdf/2509.20290), [HTML](https://arxiv.org/abs/2509.20290)
### Authors
Dayu Tan,Jing Chen,Xiaoping Zhou,Yansen Su,Chunhou Zheng
### Background
传染病对公共健康持续构成严重威胁，亟需有效的计算方法来筛选新的抗感染药物。寡肽由于结构简单、生物利用度高且不易产生耐药性，被认为在抗菌研究中具有潜力。然而，专门用于预测寡肽和传染病之间关联的计算模型仍较为稀缺。
### Innovation
本研究提出了一种基于提示的图对比学习框架（PGCLODA）。该框架构建了一个三元图，将寡肽、微生物和疾病作为节点，并结合了结构和语义信息。通过提示引导的图增强策略生成有含义的配对视图，使用联合图卷积网络（GCN）和变压器的双编码器架构捕捉局部和全局特征。其融合嵌入随后被输入到多层感知器（MLP）分类器进行最终预测。结果表明，PGCLODA在基准数据集上的AUROC、AUPRC和准确率方面均优于现有最先进的模型。消融和超参数分析证实了每个模块的贡献，并通过案例研究进一步验证了PGCLODA的泛化能力和发现新型生物相关关联的潜力。
### Conclusion
这些发现为机制驱动的发现和寡肽基药物开发提供了有价值的信息。PGCLODA的源代码已在线发布。
## 194. `cs.AI` - 多智能体是社会群体：在人-智能体互动中探究多个智能体的社会影响力 [PDF](https://arxiv.org/pdf/2411.04578), [HTML](https://arxiv.org/abs/2411.04578)
### Authors
Tianqi Song,Yugin Tan,Zicheng Zhu,Yibin Feng,Yi-Chieh Lee
### Background
多智能体系统即由多个独立的人工智能代理共同工作以实现共同目标的系统，在日常生活中变得越来越普遍。受人类群体社会影响现象的启发，研究团队探讨了一组AI代理是否会通过寻求用户同意，从而改变其对某一话题的立场的能力。该研究调查了参与者与单一或多个AI代理互动，并且这些代理要么同意要么不同意用户的态度，研究发现与多个代理进行对话（保持对话内容不变）会增加参与者感受到的社会压力，并导致其意见更大幅度向代理立场转变。研究结果展示了与单个代理平台相比，多智能体系统在引起意见变化方面具有潜在优势，并讨论了促进社会正向影响的多代理系统的设计影响，同时也指出了恶意行为者可能利用这些系统操控公众舆论的潜在风险
### Innovation
研究团队通过探究人与多智能体互动中社会影响力的机制，创新性地发现与多个AI代理进行互动可以增加参与者感受到的社会压力，并使其意见更容易向代理立场转变，这展示多智能体系统在改变用户观点方面具有独特优势；同时提出设计建议，从促进社会正向目标的角度优化多智能体系统，也讨论了防止这些系统被滥用的可能性
### Conclusion
研究证明了多智能体系统在改变用户观点方面具有潜在优势，同时也揭示了潜在的社会操控风险。未来设计多智能体系统时，需要充分考虑其社会影响和道德问题，以充分发挥其积极作用，避免潜在的社会危害
## 195. `cs.AI` - 基于混合VAE-扩散生成神经网络增强的多类型数据建模对碰撞频率模型的影响 [PDF](https://arxiv.org/pdf/2501.10017), [HTML](https://arxiv.org/abs/2501.10017)
### Authors
Junlan Chen,Qijie He,Pei Liu,Wei Ma,Ziyuan Pu,Nan Zheng
### Background
碰撞频率模型分析了交通流量、道路几何结构和环境条件等因素对碰撞发生的影响。不准确的预测会扭曲我们对这些因素的理解，导致政策错谬和资源浪费，影响交通安全。碰撞频率建模中的一个关键挑战是过度零观测现象的普遍存在，这是由于报告不充分、碰撞概率低和数据收集成本高共同作用的结果。这些过度零观测往往会降低模型准确性并引入偏差，使安全决策复杂化。虽然现有的方法，如统计方法、数据聚合和重抽样，试图解决这个问题，但它们要么依赖于严格的假设，要么会导致显著的信息损失，扭曲碰撞数据。
### Innovation
我们提出了一种混合VAE-扩散神经网络，旨在减少零观测现象并处理多类型（计数、序数、名义和实值变量）碰撞数据的复杂性。我们通过相似性、准确性、多样性和结构一致性等指标评估由该模型生成的合成数据质量，并将其预测性能与传统统计模型进行对比。我们的研究结果表明，混合VAE-扩散模型在所有指标上都优于基线模型，提供了一种更有效的方法来增强碰撞数据并提高碰撞频率预测的准确性。
### Conclusion
本文强调了合成数据在通过改善碰撞频率建模和提供更好的政策决策来增强交通安全方面的潜力。
## 196. `cs.AI` - AutoEval：一种用于移动代理自主评估的实用框架 [PDF](https://arxiv.org/pdf/2503.02403), [HTML](https://arxiv.org/abs/2503.02403)
### Authors
Jiahui Sun,Zhichao Hua,Yubin Xia
### Background
当前对移动代理进行全面评估可以显著推动其发展和实际应用，但现有的基准测试因手动定义任务奖励信号和实现评估代码的大量工作而不具备实用性和可扩展性。因此，需要一种无需人工干预的评估框架来改进这一状况，使得移动代理的评估更加高效和可靠。
### Innovation
本文提出了AutoEval，这是一种无需任何人工努力即可评估移动代理的评估框架。AutoEval通过设计一种UI状态变化表示法来自动生成任务奖励信号，并使用一个Judge System实现自主评估。评估结果显示，AutoEval能够生成与人类标注信号高度相关的奖励信号，并且在自主评估方面的准确率最高可达到94%，与人类评估相当。
### Conclusion
最后，使用该框架评估了当前最先进的移动代理，提供了对其性能和局限性的见解，同时展示了AutoEval在提高移动代理评估效率和可靠性方面的优势。
## 197. `cs.AI` - CNS-Obsidian：基于科学文献的神经外科视觉语言模型 [PDF](https://arxiv.org/pdf/2502.19546), [HTML](https://arxiv.org/abs/2502.19546)
### Authors
Anton Alyakin,Jaden Stryker,Daniel Alexander Alber,Karl L. Sangwon,Jin Vivian Lee,Brandon Duderstadt,Akshay Save,David Kurland,Spencer Frome,Shrutika Singh,Jeff Zhang,Eunice Yang,Ki Yun Park,Cordelia Orillac,Aly A. Valliani,Sean Neifert,Albert Liu,Aneek Patel,Christopher Livia,Darryl Lau,Ilya Laufer,Peter A. Rozman,Eveline Teresa Hidalgo,Howard Riina,Rui Feng,Todd Hollon,Yindalon Aphinyanaphongs,John G. Golfinos,Laura Snyder,Eric Leuthardt,Douglas Kondziolka,Eric Karl Oermann
### Background
通用的视觉-语言模型(VLMs)展示了令人印象深刻的性能，但在未经筛选的互联网数据上进行不透明的训练，存在对高风险决策制定（如神经外科手术）关键的限制。本文介绍了一种名为CNS-Obsidian的神经外科VLM，它基于同行评审的神经外科文献进行训练，并在真实世界中展示了与GPT-4o相比的临床用途。
### Innovation
研究人员利用23984篇来自《神经外科出版物》的文章，生成了78853幅图片和标题，并使用GPT-4o和Claude Sonnet-3.5将其转换成263064个训练样本，用于三种不同的格式训练模型。CNS-Obsidian是在340亿参数的LLaVA-Next模型的基础上进行微调得到的。研究中，CNS-Obsidian在合成问题上的表现与GPT-4o相当，但在临床试用中，CNS-Obsidian在人类生成的问题上表现较差。
### Conclusion
特定领域的视觉-语言模型可以接近前沿模型在专业医学领域的性能，尽管这些模型的训练成本低廉得多且规模小得多。然而，低临床利用率表明聊天机器人接口可能不适合专家的工作流程，这提示需要寻找新的AI集成策略。
## 198. `cs.AI` - 使用过程挖掘技术探讨可解释的多智能体MCTS-迷你最大化混合体在棋盘游戏中的应用 [PDF](https://arxiv.org/pdf/2503.23326), [HTML](https://arxiv.org/abs/2503.23326)
### Authors
Yiyu Qian,Tim Miller,Zheng Qian,Liyuan Zhao
### Background
蒙特卡罗树搜索（MCTS）是一类广泛应用于顺序决策领域的基于采样的搜索算法，在人工智能的许多新的进展中处于核心地位。MCTS代理的行为对于开发人员和用户来说难以理解，因为其搜索树从模拟的大量可能的未来、它们的评价及其关系中导致了经常性地庞大和复杂的结构。本文研究人员对MCTS决策和行为进行了持续的研究。MCTS的一个缺点是其构建的高度选择性的树，可能导致重要步骤的错漏和陷入战术陷阱。宽口径的迷你最大化搜索提供了解决方案。
### Innovation
本文的研究人员将浅层迷你最大化搜索整合到多智能体MCTS的展开阶段，并利用过程挖掘技术解释了３对３国际跳棋中智能体的策略。
### Conclusion
通过将浅层迷你最大化搜索融合到多智能体MCTS中，并采用过程挖掘技术解释智能体的策略，本文旨在提高MCTS代理行为的可解释性，并改善MCTS的决策控制，从而弥补其潜在的缺陷，显著增强其处理复杂决策环境的能力。
## 199. `cs.AI` - 超越大纲：语言模型中适应性长文本写作的异构递归规划 [PDF](https://arxiv.org/pdf/2503.08275), [HTML](https://arxiv.org/abs/2503.08275)
### Authors
Ruibin Xiong,Yimeng Chen,Dmitrii Khizbullin,Mingchen Zhuge,Jürgen Schmidhuber
### Background
长格式写作需要信息检索、推理和写作之间的灵活整合和互动。当前的方法依赖预定义的工作流和固化的思考模式，在写之前生成大纲，这限制了写作过程中的适应性。
### Innovation
提出了一种名为WriteHERE的一般智能代理框架，通过递归任务分解和动态整合检索、推理和写作三大基本任务类型实现类似于人类的适应性写作。该方法包含两种机制：1）整合递归任务分解和执行的规划机制，消除对写作流程的人为限制；2）任务类型的整合，促进异构任务的分解。
### Conclusion
在小说写作和科技报告生成方面的评估表明，本方法在所有自动评估指标上都优于最先进的方法，证明了我们提出框架的有效性和广泛应用性。已公开发布代码和提示，以促进进一步研究。
## 200. `cs.AI` - Weaver: 将SQL与LLM结合进行表推理 [PDF](https://arxiv.org/pdf/2505.18961), [HTML](https://arxiv.org/abs/2505.18961)
### Authors
Rohit Khoja,Devanshu Gupta,Yanjie Fu,Dan Roth,Vivek Gupta
### Background
查询包含无结构数据的表格具有挑战性，因为这些无结构数据可能嵌入在表格中或者外部段落中，传统的SQL在处理这些包含文本（或图像）的数据时存在困难，尤其是在需要语义推理的任务中。虽然大型语言模型在理解上下文方面表现出色，但它们在处理长输入序列时存在局限性。现有的结合SQL和大型语言模型的方法通常依赖于刚性、预定义的工作流程，这限制了它们对复杂查询的适应性。
### Innovation
我们提出了一种称为Weaver的模块化管道，它动态地将SQL和大型语言模型集成起来，用于表格基础的问题回答(TableQA)。Weaver生成了一个灵活的、逐步的计划，该计划结合了SQL的数据检索能力和大型语言模型的语义处理能力。通过将复杂的查询分解为可管理的子任务，Weaver提高了准确性和泛化能力。实验结果表明，Weaver在四个表问题回答数据集中总体上优于最先进的方法，减少了API调用次数并降低了错误率。
### Conclusion
Weaver在四个表问题回答数据集上始终优于最先进的方法，通过减少API调用次数和错误率来提高性能。代码和其他相关脚本可在指定链接中找到。
## 201. `cs.AI` - 多模态人工智能在辅助生殖技术中的胚胎分级和妊娠预测：综述 [PDF](https://arxiv.org/pdf/2505.20306), [HTML](https://arxiv.org/abs/2505.20306)
### Authors
Xueqiang Ouyang,Jia Wei
### Background
全球不孕不育问题日益严重，影响了大量个体。尽管辅助生殖技术（ART）的进步提供了有效干预手段，但传统的体外受精-胚胎移植（IVF-ET）仍面临提升妊娠成功率的难题。主要挑战包括胚胎分级的主观性以及多模态数据整合的低效性。
### Innovation
该文以新的视角系统回顾了人工智能在胚胎分级和妊娠预测中的应用进展，特别关注静态图像、时间 laps 视频和结构化表格数据等多种模式数据的使用。这种方法不仅更准确地揭示了问题的核心，还帮助阐明了模型设计的合理性和局限性。同时，细致检视了当下研究的核心挑战，包括多模态特征融合的复杂性、数据稀缺性限制、模型泛化能力不足以及法律和监管框架的动态演变。
### Conclusion
该文明确指出了多模态人工智能在辅助生殖技术领域的未来研究方向，旨在为该领域多模态人工智能的应用提供具体行动指导。
## 202. `cs.AI` - 在线语言splatting [PDF](https://arxiv.org/pdf/2503.09447), [HTML](https://arxiv.org/abs/2503.09447)
### Authors
Saimouli Katragadda,Cho-Ying Wu,Yuliang Guo,Xinyu Huang,Guoquan Huang,Liu Ren
### Background
为了使AI代理能够无缝地与人类和3D环境交互，它们必须不仅准确地感知3D世界，还需要将人类语言与3D空间表示结合起来。尽管先前的工作通过结合使用3D高斯点状图（3DGS）将语言特征整合到几何详细度高的3D场景表示中取得了显著进展，但这些方法仍然依赖于对每个输入图像进行密集的离线语言特征预处理，这限制了它们对新环境的适应性。现有的方法需要预先生成语言特征，这在计算上是密集的，并且限制了对新环境的快速适应。因此，本研究旨在具有较高的时空验证能力，实现在线、近乎实时的语言映射。本研究提出了一个名为在线语言splatting的新框架，其区别在于它能够在3D场景构建（3DGS）-同步定位与地图构建（SLAM）系统中实现在线、开域语言映射，而无需预先生成语言特征。这项研究恰恰填补了这一研究空白，为提升其语言处理、渲染质量以及处理高维语言特征的能力提供了技术支持。
### Innovation
本研究提出了一种创新的在线语言splatting框架。该框架通过三个方面实现了一项新的技术突破：1) 设计了一个高分辨率的CLIP嵌入模块，能够在每帧18毫秒内生成详细的语言特征图。2) 引入了一个两阶段在线自编码器，将768维的CLIP特征压缩到15维，同时保持开域语言处理能力。3) 提出了一种颜色-语言解耦优化方法，以提高渲染质量。
### Conclusion
实验结果表明，该在线方法不仅在准确性上超过了现有的离线方法，而且在效率上更是提升了40多倍。这展示了其在动态和交互式AI应用中巨大的潜在价值。
## 203. `cs.AI` - 在资源约束下的理智能体的固有风险意识 [PDF](https://arxiv.org/pdf/2505.23436), [HTML](https://arxiv.org/abs/2505.23436)
### Authors
Daniel Jarne Ornia,Nicholas Bishop,Joel Dyer,Wei-Chen Lee,Ani Calinescu,Doyne Farmer,Michael Wooldridge
### Background
本文探讨了具有代理能力的高级推理模型（AI代理）与人类互动解决带有资源或故障约束的顺序决策问题时的行为。当这些代理用于执行人类委托的任务并且暴露在不同的约束下时，可能会产生人类目标与代理激励之间意想不到的不一致。通过使用幸存者赌徒框架，文章量化了生存驱动的偏好变化的影响，并确定了可能发生不一致的条件，同时提出了缓解这些行为出现的机制。
### Innovation
作者通过幸存者赌徒框架量化了生存驱动的偏好变化的影响，并确定了不一致出现的条件。此外，他们还提出了解决风险寻求或风险回避行为的机制。
### Conclusion
本文旨在增强对在这种生存压力下运作的AI代理的自然行为的理解和解释性，并为在资源受限的环境中安全部署这样的AI系统提供指导。
## 204. `cs.AI` - 基于LLM的体态人工智能任务完成代理的计划验证 [PDF](https://arxiv.org/pdf/2509.02761), [HTML](https://arxiv.org/abs/2509.02761)
### Authors
Ananth Hariharan,Vardhan Dongre,Dilek Hakkani-Tür,Gokhan Tur
### Background
基于大型语言模型（LLM）的任务规划和对应的人类演示，在体态人工智能中可能包含噪音，例如不必要的动作、冗余导航和逻辑错误，这些都会降低策略质量。
### Innovation
提出了一种迭代验证框架，通过评测LLM（评判LLM）对动作序列进行批评，计划LLM（规划LLM）应用修订，逐步生成更加干净且空间上更一致的轨迹。这种方法依赖于自然语言提示，能够广泛地针对无关动作、矛盾和缺失步骤等不同类型的错误进行泛化。
### Conclusion
该框架在TEACh体态人工智能数据集上，实现了最高90%的召回率和100%的精确率，适用于四款最先进的LLM（GPT o4-mini、DeepSeek-R1、Gemini 2.5、LLaMA 4 Scout）。迭代循环迅速收敛，大多数序列只需要三次迭代就 converges，同时提高了时间和空间动作组织的效率。该方法保留了人类的错误恢复模式，支持未来对稳健的纠正行为的研究。通过将计划验证确立为可靠的LLM能力，促进空间规划和动作精炼，为模仿学习中的高质量训练数据提供了一条可扩展的道路。
## 205. `cs.AI` - 相似性场理论：一种通用数学框架用于智能 [PDF](https://arxiv.org/pdf/2509.18218), [HTML](https://arxiv.org/abs/2509.18218)
### Authors
Kei-Sing Ng
### Background
本文假设持续和转变的相似关系是任何可理解动态系统的结构基础。提出了相似性场理论，这是一种数学框架，正式定义了实体之间及其演变的相似值的原则。该理论定义了相似性场及其演变，并提出了诱导纤维及生成器的概念。
### Innovation
该研究提出了相似性场理论，作为一个数学框架，用于理解智能的生成机制。它通过定义相似性场的概念，解释了实体之间的相似性及其演变。此外，该理论还提出了生成器的概念，用来生成新的实体。并证明了两个重要的定理，确保相似性场的演变既受限又可解释。
### Conclusion
相似性场理论为描述，比较和构建智能系统提供了一个基础性的语言。研究证明了演化过程中相似性场的演化是受限的，并可解释的，这为理解和探索大型语言模型中的社会认知提供了基础。
## 206. `cs.AI` - MAPO: 混合优势策略优化 [PDF](https://arxiv.org/pdf/2509.18849), [HTML](https://arxiv.org/abs/2509.18849)
### Authors
Wenke Huang,Quan Zhang,Yiyang Fang,Jian Liang,Xuankun Rong,Huanjin Yao,Guancheng Wan,Ke Liang,Wenwen He,Mingjun Li,Leszek Rutkowski,Mang Ye,Bo Du,Dacheng Tao
### Background
近年来，基于强化学习的预训练模型（如Group Relative Policy Optimization, GRPO）在推理任务上的性能显著提升。优势函数在GRPO中作为核心机制，用于评估轨迹的重要性。然而，现有的探索遇到了优势反转和优势镜像问题，这些问题影响了不同查询样本间合理的优势分配。
### Innovation
本文提出了一种简单但有效的GRPO策略，Mixed Advantage Policy Optimization (MAPO)。通过揭示不同确信度的轨迹出现情况，并为高确信度轨迹样本引入优势百分偏差，MAPO动态地重新加权优势函数，根据不同轨迹确信度的变化自适应地配置优势函数，从而考虑到样本特定的特点。
### Conclusion
对比相关最先进的方法，并在不同优势变体的基础上进行消融研究，验证了我们方法的有效性。
## 207. `cs.AI` - 在医疗情境下高效多模态大语言模型的压缩策略 [PDF](https://arxiv.org/pdf/2507.21976), [HTML](https://arxiv.org/abs/2507.21976)
### Authors
Tanvir A. Khan,Aranya Saha,Ismam N. Swapnil,Mohammad A. Haque
### Background
多模态大语言模型（MLLMs）在医疗领域具有巨大的应用潜力，但其计算成本需要高效的压缩技术来应对。这项研究评估了结构剪枝和激活感知量化对医疗应用中微调后的LLAVA模型的影响。研究探讨了不同的压缩策略，并在压缩-微调-量化流水线中评估了性能权衡。研究结果表明，所提出的方法能使参数为7B的MLLMs在仅4 GB VRAM的条件下运行，内存使用量减少70%，同时在相同的压缩比下，性能比传统剪枝和量化技术提高了4%。
### Innovation
提出了一种新的层选择方法进行剪枝，分析了不同的量化技术，并在压缩-微调-量化流水线中评估了性能权衡。所提出方法能在7B参数的MLLMs压缩到使用仅4 GB VRAM后，仍然实现比传统技术4%更高的性能提升。
### Conclusion
研究提出了一个有效的方法，使MLLMs在医疗应用中能够高效运行，通过压缩技术减少了内存需求，同时保持了较好的性能。
## 208. `cs.AI` - 在标签稀缺条件下，预训练深度模型优于GBDTs的Learning-To-Rank [PDF](https://arxiv.org/pdf/2308.00177), [HTML](https://arxiv.org/abs/2308.00177)
### Authors
Charlie Hou,Kiran Koshy Thekumparampil,Michael Shavlovsky,Giulia Fanti,Yesh Dattatreya,Sujay Sanghavi
### Background
当前的深度学习模型在表格数据上表现出色，但在异常数据上的表现明显不如梯度提升决策树。现有研究通常在理想化的条件下进行，未能捕捉到现实场景的复杂性。现有的研究主要集中在理想化的设置上，未能充分考虑现实世界中的标签稀缺问题。
### Innovation
本文提出了一种新的研究视角：在标签稀缺的表格学习到排序（LTR）任务中，预训练的深度模型可以比梯度提升决策树（GBDTs）有更好的表现。特别是在排序指标上，预训练的深度模型的表现比GBDTs提高了多达38%，并且在异常数据上的表现尤为突出。
### Conclusion
通过对比公共和专有数据集上的实验，本文表明了预训练的深度排序器在所有排序指标上都优于GBDT排序器，特别是在异常数据上表现更为优异。
## 209. `cs.AI` - 通过水库神经形态计算实时预测发作活动的闭环控制 [PDF](https://arxiv.org/pdf/2505.02003), [HTML](https://arxiv.org/abs/2505.02003)
### Authors
Maryam Sadeghi,Darío Fernández Khatiboun,Yasser Rezaeiyan,Saima Rizwan,Alessandro Barcellona,Andrea Merello,Marco Crepaldi,Gabriella Panuccio,Farshad Moradi
### Background
闭合回路脑刺激具有个性化治疗药物难治性癫痫（DRE）的潜力，但仍受到限制，导致治疗效果高度变异性。首先，刺激通常是检测到发作后进行抑制而不是预防；其次，刺激参数通过试错法确定，需要长时间调整，从而延缓治疗稳定状态的有效性。
### Innovation
本研究通过利用神经形态计算的潜力来解决这些局限性。研究团队开发了一种神经形态水库计算硬件系统，能够基于发作预测驱动实时个性化的自由运行刺激。在训练阶段，该系统在预报发作时触发电脉冲，而不是预定固定频率的刺激序列。在动物模型中验证该系统，使用与3D微电极阵列耦合的海马体球状体作为简单的测试平台，实时处理期间实现超过97%的癫痫发作减少，主要使用瞬时刺激频率低于20 Hz。
### Conclusion
本研究证明了神经形态系统作为新一代个性化DRE治疗神经调节策略的潜力，利用其稀疏和事件驱动的处理实现实时应用。
## 210. `cs.AI` - 外部时间过程下的马尔可夫决策过程 [PDF](https://arxiv.org/pdf/2305.16056), [HTML](https://arxiv.org/abs/2305.16056)
### Authors
Ranga Shaarad Ayyagari,Revanth Raj Eega,Ambedkar Dukkipati
### Background
现有的强化学习算法主要针对的是静态环境，而有限的相关非静态环境的文献则基于关于转移概率矩阵和奖励函数变化的具体假设。现实世界中的应用环境会因为各种外部事件而持续演化，人类通过历史事件中的模式来做出决策。本研究在外部时间过程的影响下，考察马尔可夫决策过程。根据外部过程引入的干扰特性，研究在有限历史事件的基础上使问题可解的条件。提出并理论分析了一个基于当前环境状态以及外部过程有限历史的策略迭代算法，证明了该算法不是收敛的，但在状态空间的特定区域中提供了策略提升的保证。我们还研究了仅考虑有限时间事件的近似在最小时域策略评估和策略提升算法中样本复杂性。结果适用于某些衰减条件满足的通用离散时间过程，进一步分析了具有高斯标记的离散时间豪奇过程的情况。通过实验展示了该策略评估和部署在传统控制环境中的效果。
### Innovation
提出了策略迭代算法，该算法学习基于当前环境状态以及外部过程有限历史的策略，并提供了策略提升在近似错误决定的特定状态空间区域内的保证。分析了有限历史时间事件的最小时域策略评估和策略提升算法的样本复杂性。进一步分析了豪奇过程的情况。
### Conclusion
在特定条件下，可以通过考虑有限历史事件来解决外部过程影响下的马尔可夫决策过程。提出并分析了策略迭代算法，并讨论了其在特定状态空间区域内的收敛问题和样本复杂性。为豪奇过程等特定类型的离散时间过程提供了理论支持，实验验证了算法的有效性。
## 211. `cs.AI` - RealitySummary：利用大型语言模型探索即时混合现实文本总结和问答 [PDF](https://arxiv.org/pdf/2405.18620), [HTML](https://arxiv.org/abs/2405.18620)
### Authors
Aditya Gunturu,Shivesh Jadon,Nandi Zhang,Morteza Faraji,Jarin Thundathil,Wesley Willett,Ryo Suzuki
### Background
大型语言模型（LLMs）正逐渐成为阅读和总结辅助工具。然而，人们对其与混合现实（MR）界面集成以支持日常阅读的潜在好处知之甚少。本研究通过迭代调查开发了RealitySummary，一种将LLMs无缝整合到总是开启的摄像头访问、基于OCR的文字提取以及增强空间和视觉响应的MR阅读助手。
### Innovation
本研究迭代开发了RealitySummary，这是一个整合LLMs的MR阅读助手，经历了三个版本的发展，每个版本都通过用户反馈和反思分析进行了调整。研究详细记录了真实世界的使用情况，并强调了AI与MR结合的独特优势，包括始终在线的无意识帮助、长期时间历史、最小的上下文切换和空间功能。
### Conclusion
实地研究的结果表明，AI和MR的结合具有显著的潜力，超越了传统的屏幕交互，展示了未来LLM-MR界面的重大前景。
## 212. `cs.AI` - CueGCL: 结构意识个性化自我训练的无监督图对比学习 [PDF](https://arxiv.org/pdf/2311.11073), [HTML](https://arxiv.org/abs/2311.11073)
### Authors
Yuecheng Li,Lele Fu,Sheng Huang,Chuan Chen,Lei Yang,Zibin Zheng
### Background
最近，图对比学习（GCL）已成为节点级和监督任务的最优解决方案之一。然而，对于图谱相关和无监督任务，如图聚类，现有的GCL算法难以获取必需的簇级信息，导致性能较差。此外，通用的无监督GCL通过增加负样本数量来提高下游任务的性能，但这种方法会导致严重的类别冲突和图聚类的不公平性。
### Innovation
为了应对上述问题，本文提出了一个聚类意识图对比学习框架（CueGCL），以联合学习聚类结果和节点表示。具体而言，设计了一种个性化的自我训练（PeST）策略，使模型能够捕捉精确的簇级个性化信息。通过PeST，解决了类别冲突和不公平性问题，同时提高了整体模型性能。进一步使用对齐图聚类（AGC）获得聚类划分，使下游任务的聚类空间与PeST中的聚类空间对齐，从而实现更一致的节点嵌入。
### Conclusion
理论上证明了我们模型的有效性，展示了它在显著可区分的簇结构上的嵌入空间。广泛的实验结果表明，CueGCL在五个具有不同规模的基准数据集上表现出最先进的性能。
## 213. `cs.AI` - GRAFT: GRaPH and Table Reasoning for Textual Alignment -- A Benchmark for Structured Instruction Following and Visual Reasoning [PDF](https://arxiv.org/pdf/2508.15690), [HTML](https://arxiv.org/abs/2508.15690)
### Authors
Abhigya Verma,Sriram Puttagunta,Seganrasan Subramanian,Sravan Ramachandran
### Background
当前领域缺乏一个系统化的多模态基准，可以评估模型在遵循指令、视觉推理和视觉-文本对齐任务上的能力。现有的基准可能涉及手工制作的数据集，这在控制数据意义、结构和清晰度方面存在局限性。
### Innovation
GRAFT提供了一个结构化的多模态基准，使用Python可视化库开发生成的图表和合成渲染的表格，确保数据语义、结构和清晰度的可控性。每个GRAFT实例都配有一道基于视觉内容的系统生成的多步骤分析问题，并提供结构化的答案格式（如JSON或YAML），以便一致评估推理和输出格式。基准引入了推理类型的分类，包括比较、趋势识别、排名、聚合、比例估计和异常检测，以实现全面评估。参考答案遵循严格的事实和格式指南，以实现精确的、基于方面的方法评估。GRAFT提供了一个统一且可扩展的框架，用于对视觉基础、结构化推理任务中的多模态模型进行精细基准测试，从而在该领域设立了新的评估标准。
### Conclusion
GRAFT通过确保数据的控制、统一和可扩展的框架，为基于视觉的结构化推理任务中的多模态模型评估设定了新的标准，提供了一种系统化的多模态基准，可以全面评估模型在遵循指令、视觉推理和视觉-文本对齐任务上的表现。
## 214. `cs.AI` - 在空间-时间知识集成中的轻量化方法：大气时间序列预测 [PDF](https://arxiv.org/pdf/2408.09695), [HTML](https://arxiv.org/abs/2408.09695)
### Authors
Yisong Fu,Fei Wang,Zezhi Shao,Boyu Diao,Lin Wu,Zhulin An,Chengqing Yu,Yujie Li,Yongjun Xu
### Background
注意力机制在大气时间序列预测（ATSF）中的应用引起了关注，因为它们能够捕捉全局的空间-时间相关性。然而，复杂的网络结构导致参数过多和训练时间过长，限制了在大规模预测中的应用。
### Innovation
提出了STE law这一轻型模型，利用空间-时间位置嵌入（STPE）和MLP架构替代了Transformer层，模型仅有10k参数且训练时间仅需一小时，在五个数据集上表现优于其他高级方法，强调了空间-时间知识集成的有效性。
### Conclusion
该论文通过轻型模型STE law的提出，验证了在大规模ATSF中，通过整合空间-时间知识而非使用复杂架构可以实现更高效的预测，提供了ATSF领域的新颖洞见。
## 215. `cs.AI` - CogAtom: 从认知原子到大型语言模型中的奥林匹克级数学推理 [PDF](https://arxiv.org/pdf/2509.17318), [HTML](https://arxiv.org/abs/2509.17318)
### Authors
Zhuofan Chen,Jiyuan He,Yichi Zhang,Xing Hu,Haoxing Wen,Jun Bai,Wenge Rong
### Background
大型语言模型（LLMs）在数学推理方面面临重大挑战，因为这需要多步推理和抽象概念的整合。尽管最近的测试时扩展技术依赖于高质量和具有挑战性的问题，但可用的奥林匹克级别数学问题的数量仍然有限，这是瓶颈之一。
### Innovation
本文提出了CogAtom，一种新颖的认知原子为基础的框架，用于合成严格且认知多样化的数学问题。CogAtom将问题构建视为选择并重组来自人类解决方案的最基本推理单元的认知原子的过程。分散的随机游走算法促进了在认知原子空间的探索，基于约束的重组机制确保了逻辑的严谨性与结构的可验证性。Graph结构的组合性质提供了近乎无限的推理路径空间，游走算法系统性地探索这个空间，从而实现对高质量问题的大规模合成；同时通过控制认知原子的数量，可以精确调整问题难度，确保生成的问题在多样性和可扩展性上的可控性。实验结果表明，CogAtom在精度、推理深度和多样性方面优于现有方法，在结构多样性方面超越了AIME的难度。
### Conclusion
本文提供了认知基础上的大规模、高质量数学问题生成路径，实验结果表明CogAtom在生成符合AIME难度和超过其结构多样性的问题方面表现出色。相关代码已在公开平台上获取，可进一步研究和应用。
## 216. `cs.AI` - DeNOTS: 稳定的深度神经ODEs时间序列模型 [PDF](https://arxiv.org/pdf/2408.08055), [HTML](https://arxiv.org/abs/2408.08055)
### Authors
Ilya Kuleshov,Evgenia Romanenkova,Vladislav Zhuzhel,Galina Boeva,Evgeni Vorsin,Alexey Zaytsev
### Background
神经CDEs为处理不规则时间序列的动态演变提供了一种自然的方法。传统神经网络中的层数则通过函数评估次数（NFEs）体现。通常，通过降低解算器的误差容差来增加NFEs，但这无法显著提升模型的表达能力。研究表明，直接延长积分时间区间能够有效增加NFEs并提升模型深度，但这种方法可能会导致动态描述函数的不可控增长，为此，研究者提出了一种名为Negative Feedback (NF)的方法来稳定动态并确保其不变形。
### Innovation
本文提出了一种名为DeNOTS的方法，通过扩展积分时间范围来增加NFEs并加深模型，同时结合了Negative Feedback (NF)来稳定动态过程，仿佛没有缩小灵活性。这种方法不仅提高了模型的稳定性，还提供了用于证明神经ODE风险的理论界限。实验结果显示，DeNOTS在四个公开数据集上的性能优于现有方法，包括最新的神经RDEs和状态空间模型，在某些指标上最高可有20%的提升。
### Conclusion
DeNOTS方法结合了表达能力、稳定性和鲁棒性，使其在连续时间领域内实现可靠建模。
## 217. `cs.AI` - CLIP Can Understand Depth [PDF](https://arxiv.org/pdf/2402.03251), [HTML](https://arxiv.org/abs/2402.03251)
### Authors
Sohee Kim,Jisu Kang,Dunam Kim,Seokju Lee
### Background
本文探讨了CLIP在需要其预训练期间在爬取网络数据上的视觉-语言对齐不理想的下游任务（如单目深度估计）中的应用。CLIP在过去取得了一些成功，但在某些领域（如生成建模和语义分割）也遇到了困难。研究指出CLIP难以捕获图块图像之间的相似性和自然语言描述的距离，因此需要改进CLIP的理解能力。
### Innovation
本文提出了镜像（Mirror）的概念，这是一种可学习的嵌入矩阵，替代了预训练的自然语言嵌入，以解决CLIP在深度理解方面的问题。通过镜像和一个紧凑的解码器联合训练两个轻量级模块，本文在固定的CLIP上实现了密集深度预测。实验表明，相比于传统的深度模型，本文框架在参数和计算效率方面更具优势，并且在NYU Depth v2和KITTI基准数据集上匹配了多种最先进的视觉模型，同时超过了基于固定CLIP先验的视觉语言深度模型。还发现，镜像在训练中会隐式学习捕捉对于检测至关重要的语义线索，从而纠正了CLIP的空间和时间一致性方面的不足。
### Conclusion
本文通过改进CLIP在单目深度估计等任务中的预训练对齐方法，展示了如何在不需要微调的情况下，使用CLIP实现密集深度预测。提出的镜像模块提高了CLIP的理解能力，提升了性能，同时也验证了在无需额外自然语言嵌入的情况下，视觉和语言模型可以在某些下游任务中取得良好表现。
## 218. `cs.AI` - 任意精度和稀疏度下神经网络的稳健训练 [PDF](https://arxiv.org/pdf/2409.09245), [HTML](https://arxiv.org/abs/2409.09245)
### Authors
Chengxi Ye,Grace Chu,Yanfeng Liu,Yichi Zhang,Lukasz Lew,Li Zhang,Mark Sandler,Andrew Howard
### Background
量化和稀疏化操作中的断续操作长期以来阻碍了反向传播，特别是在超低精度和稀疏化域。标准的Straight-Through Estimator (STE) 被广泛用于解决这一问题，但其量化感知正向传递与量化无意识反向传递之间的既定不对等性导致未管理的错误，这可能会破坏学习过程。
### Innovation
引入了一种基于先验岭回归目标的去噪去量化变换，该变换使得整个学习过程意识到并抵制 STE 的代理梯度忽视的量化误差，创建了一个明确的纠正梯度路径。还将这一原则应用于稀疏化，将其视为将不重要值映射为零的一种特殊形式的量化。提供了一个统一框架，允许现有模型在一系列精度和稀疏度级别下使用现成的食谱进行训练，实现了完全二进制（A1W1）和稀疏子1比特网络的稳定训练，其他方法在这些情况下会失败。
### Conclusion
本文方法取得了最先进的结果，并提供了一条理论基础强大的路径，以实现超高效的神经网络。
## 219. `cs.AI` - 使用ASCII艺术逃避毒性检测：对内容审查系统的空间攻击基准 [PDF](https://arxiv.org/pdf/2409.18708), [HTML](https://arxiv.org/abs/2409.18708)
### Authors
Sergey Berezin,Reza Farahbakhsh,Noel Crespi
### Background
该研究探讨了如何利用语言模型对ASCII艺术形式的空间结构文本处理不当，开发新型的对抗性攻击方法。通过这种方法，研究者设计了一个名为ToxASCII的基准测试，以评估当前毒性检测系统的鲁棒性，特别是在面对视觉隐藏输入时的稳定性。
### Innovation
研究引入了一类新的对抗性攻击模型，专门针对毒性检测模型的弱点。具体而言，这类攻击利用语言模型在处理ASCII艺术时的缺陷来逃避检测。此外，研究提出了一个名为ToxASCII的基准测试，用于评估对抗性攻击对不同大型语言模型和专门的审核工具的有效性。
### Conclusion
研究发现，这些新型的对抗性攻击在多种最先进的语言模型和专门的管理工具中取得了100%的成功率，表明现有的基于文本的管理系统存在明显的漏洞。这一发现强调了改进当前毒性检测系统以抵御此类攻击的重要性。
## 220. `cs.AI` - VLM 见，机器人做：通过视觉语言模型将人类示范视频转换为机器人行动计划 [PDF](https://arxiv.org/pdf/2410.08792), [HTML](https://arxiv.org/abs/2410.08792)
### Authors
Beichen Wang,Juexiao Zhang,Shuwen Dong,Irving Fang,Chen Feng
### Background
视觉语言模型（VLMs）因其在常识推理和泛化能力上的优势，近年来在机器人领域得到应用。现有研究使用VLM从自然语言指令生成任务和运动规划，并模拟训练数据以供机器人学习。本文探索使用VLM解释人类示范视频并生成机器人任务规划的方法。为此，收集了一组长时序的人类示范视频，并设计了一套评估指标，将模型性能与现有基线进行比较。实验结果表明本文方法具有优越的性能，并在模拟环境和真实机器人手臂上进行了部署测试。
### Innovation
该研究提出了一个名为SeeDo的方法，该方法通过结合关键帧选择、视觉感知和VLM推理来讲解机器人任务规划。使用视觉语言模型从人类示范视频中解释行动并生成对应的机器人计划，使得机器人有能力执行指定任务。这在机器人学习直觉性和自适应性方面具有创新性。
### Conclusion
实验结果展示了SeeDo在多个方面均优于现有基线，包括从人类示范视频生成任务计划的能力。这项工作验证了VLMs在机器人领域的一种新颖应用，并成功将其部署在仿真环境和真实机器人手臂上。
## 221. `cs.AI` - Diffusion Curriculum: 通过图像指导扩散的合成到真实生成课程学习 [PDF](https://arxiv.org/pdf/2410.13674), [HTML](https://arxiv.org/abs/2410.13674)
### Authors
Yijun Liang,Shweta Bhardwaj,Tianyi Zhou
### Background
在实践中，低质量或稀少的数据对深度神经网络的训练构成了重大挑战。尽管传统的数据增强技术不能提供非常不同的新数据，但扩散模型通过文本引导提示生成高质量和多样性的合成数据，开辟了构建自我进化的AI的新途径。然而，仅凭文本指导无法控制合成图像与原始图像的相似度，导致不适用的分布数据，对模型性能不利。
### Innovation
该研究提出了一种新的方法——“扩散课程（DisCL）”，通过图像指导扩散，根据每个训练阶段调整图像合成的指导强度。这种方法能够识别和关注对模型困难的样本，并评估合成图像以提高困难数据学习的最有效指导水平。这一方法在两个具有挑战性的任务上得到了应用：长尾分类和低质量数据学习。实验结果展示了在应用扩散课程后，在iWildCam数据集中外域（OOD）和内域（ID）宏准确性分别提高了2.7%和2.1%。在ImageNet-LT上，扩散课程将基线模型尾类准确率从4.4%提升到23.64%，并提高了所有类别的准确率4.02%。
### Conclusion
扩散课程通过调整图像合成的指导强度，帮助模型识别和集中学习具有挑战性的样本。这种方法提高了模型在长尾分类和低质量数据学习任务中的性能。扩展实验表明，扩散课程在提高数据性能方面表现出明显的优势，特别是在处理低质量数据和长尾数据分类任务时。
## 222. `cs.AI` - TALEC: 使用条件细分和零样本加少量样本教会您的LLM在特定领域使用内部标准进行评估 [PDF](https://arxiv.org/pdf/2407.10999), [HTML](https://arxiv.org/abs/2407.10999)
### Authors
Kaiqi Zhang,Shuai Yuan,Honghan Zhao
### Background
随着大型语言模型（LLM）的快速发展，对其评估变得越来越重要。对于诸如总结和文章创作等文本生成任务的测量非常困难，特别是在特定业务或客服应用领域，除了通用标准（正确性、实用性、创造力等），还需要满足客户的特定需求以及业务安全要求，使得评估变得更加困难。目前，LLM的评估主要依赖于人工手动进行，这既昂贵又耗时。
### Innovation
本文提出了一种基于模型的评估方法：TALEC，允许用户灵活设置其内部评价标准，并通过上下文自学习（ICL）指导评判模型遵循这些内部标准。此外，尝试结合零样本和少量样本，使评判模型更加关注相关信息。还提出了提示范式和工程方法，调整和迭代样本，帮助评判模型更好地理解复杂的标准，对比微调与ICL，发现ICL可以替代微调。TALEC能够准确反映人类偏好，与人工判断的相关性超过80%，在某些任务上甚至超越了人工间的相关性。
### Conclusion
TALEC展现出了强大的能力，能够准确反映人类偏好，并实现了与人工判断超过80%的相关性，超越了某些任务上的人工间相关性。
## 223. `cs.AI` - 表示收敛：互学习实际上是隐式正则化的一种形式 [PDF](https://arxiv.org/pdf/2501.02481), [HTML](https://arxiv.org/abs/2501.02481)
### Authors
Zhengpeng Xie,Jiahang Cao,Changwei Wang,Fan Yang,Marco Hutter,Qiang Zhang,Jianxiong Zhang,Renjing Xu
### Background
本文研究了强化学习策略间的互学习如何作为一种隐式正则化手段，防止策略过度拟合无关特征。
### Innovation
本文做出了两个贡献：理论方面，首次证明了增强策略对无关特征的鲁棒性可以提高泛化性能；实验方面，展示了策略间的互学习能够提升这种鲁棒性，使像素输入上产生不变表征。
### Conclusion
本文并未声称达到最佳性能，而是专注于发现泛化背后的原理并加深对此机制的理解。
## 224. `cs.AI` - 高效调整大型语言模型以实现自动化医学记录 [PDF](https://arxiv.org/pdf/2409.09324), [HTML](https://arxiv.org/abs/2409.09324)
### Authors
Hui Yi Leong,Yi Fan Gao,Ji Shuai,Yang Zhang,Uktu Pamuksuz
### Background
科学研究表明，医生每花费一小时直接照顾病人，就需要额外花费近两小时处理行政任务，尤其是电子健康记录（EHRs）和办公工作。这些过度的行政负担不仅减少了可用于病人护理的时间，还导致医生的倦怠，并降低了医疗服务效率。
### Innovation
本研究提出了MediGen，一种针对医疗对话进行过调整的大规模语言模型（LLM），旨在自动化生成医学报告。通过利用最新的预训练模型调整方法，特别是LLaMA3-8B，MediGen实现了高精度的临床互动转录和总结。调整后的LLaMA3-8B模型表现出色，获得ROUGE分数58%和BERTScore-F1 72%，表明其在生成准确且临床相关医学报告方面的有效性。
### Conclusion
这些发现表明，MediGen有潜力显著减轻医生的行政负担，从而改善医疗服务效率和医生的福祉。
## 225. `cs.AI` - A GEN AI Framework for Medical Note Generation [PDF](https://arxiv.org/pdf/2410.01841), [HTML](https://arxiv.org/abs/2410.01841)
### Authors
Hui Yi Leong,Yi Fan Gao,Shuai Ji,Bora Kalaycioglu,Uktu Pamuksuz
### Background
医疗记录的行政负担，特别是在使用电子健康记录（EHR）时增加，显著减少了直接面对患者的时间，并导致医生的倦怠。为了解决这个问题，研究人员提出了一种名为MediNotes的先进生成型AI框架，旨在从医疗对话中自动生成SOAP（主观、客观、评估、计划）笔记。MediNotes整合了大型语言模型（LLMs）、检索增强生成（RAG）和自动语音识别（ASR），以实时或从录音中捕获和处理文本和语音输入，生成结构化且上下文准确的医疗笔记。该框架还采用了Quantized Low-Rank Adaptation（QLoRA）和Parameter-Efficient Fine-Tuning（PEFT）等先进技术，以在资源受限的环境中实现高效的模型微调。此外，MediNotes提供了一个基于查询的检索系统，使医疗服务提供者和患者能够快速准确地获取相关医疗信息。
### Innovation
MediNotes是针对医疗记录自动生成功能的创新框架，它整合了大型语言模型（LLMs）、检索增强生成（RAG）以及自动语音识别（ASR）技术。它能实时或从录音中捕获和处理文本和语音输入，并生成结构化且上下文准确的医疗笔记。此外，框架中采用了量化低秩适应（QLoRA）和参数高效微调（PEFT）等技术，以实现资源受限环境下的高效模型微调。
### Conclusion
MediNotes显著提高了自动医疗文档的准确性和效率，提高了文档使用的便利性，提供了减轻医疗专业人员行政负担并改进临床工作流程的有效解决方案。
## 226. `cs.AI` - Stylus: 利用预训练的Stable Diffusion进行训练免费的Mel-频谱音乐风格转移 [PDF](https://arxiv.org/pdf/2411.15913), [HTML](https://arxiv.org/abs/2411.15913)
### Authors
Heehwan Wang,Joonwoo Kwon,Sooyoung Kim,Jungwoo Seo,Shinjae Yoo,Yuewei Lin,Jiook Cha
### Background
音乐风格转移能够通过混合源音乐的结构和参考音乐的风格属性来进行个性化的音乐创作。现有的基于文本条件和扩散方法显示出了前景，但通常需要成对的数据集、大量的训练或详细的标注。
### Innovation
Stylus 提出了一种无需训练的框架，通过重新利用预训练的 Stable Diffusion 模型在 Mel-频谱域中实现音乐风格转移。该方法通过注入风格关键值特征来操作自我注意，同时保留源查询以保持音乐结构。此外，提出了相位保留重建策略来避免 Griffin-Lim 重建的艺术品，并采用了基于分类器自由引导的控制策略以实现可调风格和多风格融合。
### Conclusion
Stylus 在广泛评估中展示了优越性，相比最先进的基线系统，内容保存提高了 34.1%，感知质量提高了 25.7%，且无需额外的训练。
## 227. `cs.AI` - BAP v2：Minecraft对话语境中的增强指令跟随任务框架 [PDF](https://arxiv.org/pdf/2501.10836), [HTML](https://arxiv.org/abs/2501.10836)
### Authors
Prashant Jayannavar,Liliang Ren,Marisa Hudspeth,Risham Sidhu,Charlotte Lambert,Ariel Cordes,Elizabeth Kaplan,Anjali Narayan-Chen,Julia Hockenmaier
### Background
本文探讨了构建能够理解语言、感知环境并在物理世界中行动的交互式代理的长期目标。具体而言，使用Minecraft协作建筑任务（MCBT），这是一款两名玩家的游戏，建筑师（A）指导建造者（B）在模拟的3D方块世界中构建目标结构。这是一个丰富的平台，目前正在研究如何实现上述目标。在这项工作中，作者主要关注建筑师指令解析（BAP）子任务：预测建造者在多模式游戏环境中的操作，这是一个复杂的基于语境的指令跟随测试，由于训练数据有限，因此具有挑战性。
### Innovation
论文提出了BAP v2任务框架，通过增强评估基准，多类型合成MCBT数据生成，引入更丰富的输入表示的新模型，并且展示了这些改进如何提高模型在合成数据集上的性能。特别是在BAP v2任务上取得了53.0的F1分数，这相对于先前的性能有6点的改进，这表明当前的LLM模型在模拟环境中仍然面临许多挑战。
### Conclusion
尽管在BAP v2任务上取得了显著改进，但作者认为任务依然存在困难，BAP v2为未来的研究提供了有价值的测评指标。此外，BAP v2表明当前只有文本的LLM在实体任务中的空间能力还有很大的提升空间。
## 228. `cs.AI` - 盲人摸象：基准数据集中性别刻板印象的多元视角 [PDF](https://arxiv.org/pdf/2501.01168), [HTML](https://arxiv.org/abs/2501.01168)
### Authors
Mahdi Zakizadeh,Mohammad Taher Pilehvar
### Background
准确测量语言模型中的性别刻板印象偏差是一项复杂任务，其中隐藏了许多方面。当前的基准数据集已经低估了这一多方面挑战，并且未能全面捕捉到问题的全部复杂性。这项研究探讨了内在刻板印象基准之间的不一致性。研究表明，目前可用的基准数据集仅捕捉到了性别刻板印象的部分方面，单独考虑时无法提供对语言模型中偏见更广泛图景的整体理解。使用StereoSet和CrowS-Pairs作为案例研究，研究了数据分布如何影响基准结果，并通过应用社会心理学中的框架来平衡这些基准数据中的各种性别刻板印象成分，证实了简单平衡技术能够显著提升不同测量方法之间的相关性。这项研究揭示了语言模型中性别刻板印象的复杂性，并指出了开发更精确技术以检测和减少偏见的新方向。
### Innovation
本文提出，当代可用的性别刻板印象基准数据集仅捕捉了性别刻板印象的部分方面，单独考虑时无法提供对语言模型中偏见更广泛图景的整体理解。该研究应用社会心理学框架，通过平衡基准数据中的各种性别刻板印象成分，展示了简单平衡技术能够显著提高不同测量方法之间的相关性。研究表明，简单的平衡技术可以显著改进不同的测量方法之间的相关性，从而为检测和减少语言模型中的偏见提供了新的视角。
### Conclusion
研究表明，当前的基准数据集没有全面评估语言模型中的性别刻板印象偏见，提出了使用社会心理学框架来平衡数据的新方法，并指出了通过更精确的测量技术来检测和减少语言模型中偏见的新方向。
## 229. `cs.AI` - 使用全面答案填补信息缺口：提高后续问题的多样性和信息量 [PDF](https://arxiv.org/pdf/2502.17715), [HTML](https://arxiv.org/abs/2502.17715)
### Authors
Zhe Liu,Taekyu Kang,Haoyu Wang,Seyed Hossein Alavi,Vered Shwartz
### Background
生成能揭示缺失信息的多样化的后续问题对对话代理来说仍然具有挑战性，尤其是在使用小型、本地托管模型的情况下。本文旨在通过开发一种基于信息差距的知识蒸馏管道来解决这一问题，该管道使用教师LLM生成全面的答案，并通过对比初步答案来识别信息差距，进而提出填补差距的跟进问题。
### Innovation
本文提出了一个名为信息差距驱动的知识蒸馏管道，其中教师LLM生成全面的答案，然后对比初步答案以识别信息差距，并提出填补差距的后续问题。通过这种方式，研究者增进了现有的FollowupQG数据集。进一步地，通过微调较小的学生模型在这种扩增的数据集上，学生模型表现出显著更高的信息量和多样性。
### Conclusion
实验结果表明，使用此管道微调的模型比使用原始数据集训练的模型在信息量和多样性方面有显著提高。研究人员认为，这种方式模仿了人类认知过程中的信息寻求过程，提供了一种从先进LLM到小型模型的有效蒸馏通道，使资源受限的对话系统能够生成更具多样性和信息量的后续问题。
## 230. `cs.AI` - SoFar: 语义导向的定向连接空间推理与物体操作 [PDF](https://arxiv.org/pdf/2502.13143), [HTML](https://arxiv.org/abs/2502.13143)
### Authors
Zekun Qi,Wenyao Zhang,Yufei Ding,Runpei Dong,Xinqiang Yu,Jingwen Li,Lingyun Xu,Baoyu Li,Xialin He,Guofan Fan,Jiazhao Zhang,Jiawei He,Jiayuan Gu,Xin Jin,Kaisheng Ma,Zhizheng Zhang,He Wang,Li Yi
### Background
尽管在对象定位关系的空间推理方面已经取得了进展，但传统的方法往往忽视了对象的方向性，这是6-DoF精细操作中的关键因素。传统的姿态表示依赖预定义的框架或模板，这限制了泛化能力和语义关联。因此，需要一种新的方法来更好地捕捉和利用对象的方向性。
### Innovation
本文引入了语义导向的概念，通过自然语言在无参考框架的方式描述对象的方向（例如USB的“插入”方向或茶杯的“握持”方向）。为了支持这一概念，作者构建了OrienText300K，这是一个大规模的带有语义导向标注的3D对象数据集，并开发了PointSO，一个用于零样本环境下预测语义导向的一般模型。通过将语义导向整合到VLM代理中，SoFar框架实现了6-DoF的空间推理并生成了机械臂动作。
### Conclusion
大量的实验验证了SoFar的有效性和泛化能力，例如在Open6DOR上的零样本48.7%的成功率以及在SIMPLER-Env上的74.9%的成功率。
## 231. `cs.AI` - 通过模仿周围车辆学习驾驶 [PDF](https://arxiv.org/pdf/2503.05997), [HTML](https://arxiv.org/abs/2503.05997)
### Authors
Yasin Sonmez,Hanna Krasowski,Murat Arcak
### Background
模仿学习是一种有潜力的方法，用于通过模仿专家驾驶员的行为训练自主车辆在复杂交通环境中导航。现有的模仿学习框架主要依赖于专家示范，但往往忽视了来自周围交通参与者的复杂驾驶数据的价值。
### Innovation
本文研究了一种数据增强策略，该策略利用自主车辆传感器捕获的附近车辆轨迹作为额外的示范，并介绍了一种简单的车辆选择采样和过滤策略，以优先考虑信息性和多样性的驾驶行为，从而丰富训练数据集。这种方法使用一个具备代表性的基于学习的规划器在大规模现实世界数据集上进行评估，并在复杂驾驶场景中展示了改进的性能，减少了碰撞率并提高了安全指标。特别地，即使只使用原始数据集的10%，该方法也能达到或超过完整数据集的表现。通过消融实验，我们分析了选择标准，并展示了盲目随机选择可能降低性能。
### Conclusion
我们的发现突显了利用多样化的现实世界轨迹数据在模仿学习中的价值，并为自主驾驶提供了数据增强策略的见解。
## 232. `cs.AI` - 一种基于数据扩增的预测通用SMARTS模板化学产物的变换器模型 [PDF](https://arxiv.org/pdf/2503.05810), [HTML](https://arxiv.org/abs/2503.05810)
### Authors
Derin Ozer,Sylvain Lamprier,Thomas Cauchy,Nicolas Gutowski,Benoit Da Mota
### Background
准确预测化学反应结果是计算化学中的主要挑战。现有模型依赖于高度特定的反应模板或无模板的方法，这两种方法都存在局限性。为了克服这些问题，该研究提出了一种名为Broad Reaction Set (BRS)的新方法，其中包括20个通用反应模板，并使用SMARTS表示法，这是一种用于描述子结构和反应性的模式表示法。此外，研究还引入了ProPreT5模型，这是首个能够直接处理和应用SMARTS反应模板的语言模型。为了提高泛化能力，研究还提出了一种新的SMARTS扩增策略，通过模式层面的结构多样性扩增，增强模型的泛化能力。训练后的ProPreT5模型在预测性能和泛化到未见过的反应方面表现出色，为当前方法提供了新的替代方案，推动了基于模板的反应预测领域的发展。
### Innovation
该工作提出了Broad Reaction Set (BRS)，包含20个通用的SMARTS反应模板；提出了ProPreT5模型，这是首个能够直接处理和应用SMARTS反应模板的语言模型；提出了第一个基于SMARTS的扩增策略，通过在模式层面注入结构多样性来增强模型的泛化能力；结合扩增的SMARTS模板，ProPreT5模型显示了强大的预测性能和对未见过的反应的良好泛化能力，提供了一种新颖且实用的方法，促进该领域的发展。
### Conclusion
这些贡献提供了一种新颖且实用的替代方案，推动了基于模板的反应预测领域的进展。
## 233. `cs.AI` - HawkBench: 研究多类信息获取任务下RAG方法的适应性 [PDF](https://arxiv.org/pdf/2502.13465), [HTML](https://arxiv.org/abs/2502.13465)
### Authors
Hongjin Qian,Zheng Liu,Chao Gao,Yankai Wang,Defu Lian,Zhicheng Dou
### Background
在现实世界的信息查询场景中，用户的需要是动态且多样的。这要求RAG系统能够展现出高度的适应性。为了全面评估当前RAG方法的适应性，作者引入了HawkBench，这是一个由人工标注、多领域基准，设计用于严格评估RAG表现的跨任务类别评估基准。通过基于信息查询行为对任务进行分层，HawkBench提供了一种系统地评估RAG系统如何适应各种用户需求的方法。现有的基准测试主要关注特定任务类型（主要是事实查询）并通过不同的知识库进行评估，而HawkBench则侧重于（1）系统地对任务进行分层以涵盖广泛的查询类型，包括事实查询和推理查询，（2）在整个任务类型中整合多领域语料库以减少语料库偏差，（3）严格注释以获得高质量的评估。HawkBench包含1600个高质量测试样本，均匀分布在各个领域和任务类型中。通过利用HawkBench，评估代表性的RAG方法，分析其在答案质量及响应延迟方面的性能。研究结果指出，RAG方法需要动态的任务策略，包括决策制定、查询解读和全局知识理解的融合，以提高其通用性。
### Innovation
HawkBench 设计了一个系统性任务分层，覆盖广泛的查询类型，不依赖单一的知识库，并且提供了严格的注释以确保高质量的评估。这使得它在多领域语料库整合、多样化用户需求覆盖和高质量评估方面超越了现有基准测试。
### Conclusion
HawkBench 作为一个关键基准，对于提升RAG方法的适应性和实现通用信息查询具有重要作用。
## 234. `cs.AI` - 基于梯度下降的紧凑规则分类器学习 [PDF](https://arxiv.org/pdf/2502.01375), [HTML](https://arxiv.org/abs/2502.01375)
### Authors
Javier Fumanal-Idocin,Raquel Fernandez-Peralta,Javier Andreu-Perez
### Background
规则基础模型由于其透明性和可解释性在高风险决策中至关重要，但其离散性特征导致了优化和扩展的挑战。目前，虽然具有神经模糊性的方法可以应用于规则基础模型，但它们无法提供有意义的语义分割，且复杂度高，存在组合复杂性问题。因此，开发一种同时满足严格用户约束和规则复杂性需求，并且具备高可解释性的新型方法是必要的。
### Innovation
提出了一种新颖的基于梯度的方法，即Fuzzy Rule-based Reasoner (FRR)，该系统支持规则复杂性的严格用户约束，并实现了竞争性性能。FRR使用具有语义意义的模糊逻辑分区，避免了现有神经模糊方法中的组合复杂性问题，同时也支持单规则决策，使分类器更加紧凑且易于理解。
### Conclusion
通过对40个数据集的广泛评估，FRR显示出以下优势：(1) 在传统规则基础方法（如RIPPER）的基础上表现更优，平均准确率提高5%；(2) 准确度与基于树的方法（如CART）相近，但规则集更为紧凑90%；(3) 性能接近最先进的规则基模型，但只使用必要规则，且规则集合大小仅为后者3%。
## 235. `cs.AI` - 复杂动态系统中的异常检测：基于嵌入理论和基于物理的一致性系统的框架 [PDF](https://arxiv.org/pdf/2502.19307), [HTML](https://arxiv.org/abs/2502.19307)
### Authors
Michael Somma,Thomas Gallien,Branka Stojanovic
### Background
在工业和网络物理基础设施中，复杂动态系统的行为检测对于确保可靠性和安全性至关重要。预测维护可以预防昂贵的故障，而网络安全监控则变得越来越关键，因为数字化系统面临越来越多的威胁。许多这样的系统表现出周期性行为和有界运动，这需要能够捕捉结构化的时间依赖性和遵循物理一致性原则的异常检测方法。目前，文献中报道了基于编织学理论和物理启发的一致性原则的系统理论方法，以解决复杂系统中的异常检测问题。为此，本文提出了一种系统理论方法，该方法以经典嵌入理论和基于物理的一致性原则为基础，辅以复杂的系统动力学的嵌入理论和状态导数对作为嵌入策略。为了确保时间的一致性，还开发了一个时域差异一致性自编码器（TDC-AE）来对接近的误差变量的时间演化的动态表示，从而达到了与规范隐藏表示的离散导数对齐的目的。该方法在C-MAPSS数据集（涡扇发动机老化测试数据集）的两个子集中进行了评估，TDC-AE的表现优于LSTM和Transformer，具有不到原始MAC操作的1/100的计算量，使其特别适合轻量级边缘计算的应用。研究结果支持这种观点，即异常会破坏稳定的系统动力学，为异常检测提供了强有力的信号。
### Innovation
本文提出了一个基于编织学理论和物理启发一致性的复杂动态系统异常检测框架。具体贡献包括：1. 提出了一种系统理论方法，充分利用经典嵌入理论和基于物理的一致性原则，适配复杂的系统动力学。2. 引入了状态导数对作为嵌入策略，更好地捕捉系统演化特征。3. 开发了时域差异一致性自编码器（TDC-AE），通过TDC-Loss确保了近似潜变量导数与动态表示的一致性。4. 在真实数据集上进行了充分的实验验证，表明TDC-AE在性能和计算效率上具有显著优势，特别适合轻量级边缘计算环境。
### Conclusion
通过基于编织学理论和物理启发的系统一致性原则的方法，有效地解决复杂动态系统的异常检测问题，TDC-AE具备出色的性能和极高的计算效率，为实际应用提供了新的思路。这种方法不仅能够识别出系统中的异常行为，还能在轻量级环境中实现高效的实时监测，为工业和网络安全提供强大的技术支撑。
## 236. `cs.AI` - DP-LET: 一种高效的时空网络流量预测框架 [PDF](https://arxiv.org/pdf/2504.03792), [HTML](https://arxiv.org/abs/2504.03792)
### Authors
Xintong Wang,Haihan Nan,Ruidong Li,Huaming Wu
### Background
准确预测时空网络流量对于现代通信系统中动态管理计算资源以及减少能耗至关重要。尽管时空流量预测已经受到了广泛的研究关注，但进一步提高预测准确性和计算效率依然是必要的。现有基于分解的方法或混合架构在捕捉局部和全局特征相关性时往往需要大量的计算开销，因此需要新的方法来优化准确性和复杂性。
### Innovation
本文提出了一种高效的时空网络流量预测框架——DP-LET，它包括数据处理模块、局部特征增强模块和基于Transformer的预测模块。数据处理模块用于高效地进行网络数据去噪和空间解耦；局部特征增强模块则利用多个时序卷积网络来捕捉细粒度的局部特征；预测模块则采用Transformer编码器来建模长期依赖关系并评估特征的相关性。
### Conclusion
实际案例研究表明，DP-LET在保持低计算复杂度的同时实现了最先进的性能，相比基线模型，其均方误差（MSE）降低了31.8%，平均绝对误差（MAE）降低了23.1%。
## 237. `cs.AI` - 使用动态奖励缩放的逆强化学习在大型语言模型对齐中的应用 [PDF](https://arxiv.org/pdf/2503.18991), [HTML](https://arxiv.org/abs/2503.18991)
### Authors
Ruoxi Cheng,Haoxuan Ma,Weixin Wang,Ranjie Duan,Jiexi Liu,Xiaoshuang Jia,Simeng Qin,Xiaochun Cao,Yang Liu,Xiaojun Jia
### Background
大型语言模型的对齐对于安全部署至关重要。现有的技术要么基于奖励（通过偏好对训练奖励模型并在强化学习中优化），要么不基于奖励（直接在排名输出上微调）。最近的研究表明，调整良好的奖励管道仍然具有鲁棒性，并且单次响应示范可以在某些情况下超越成对偏好数据。然而，现有的方法存在两个挑战：（1）不平衡的安全数据集，这些数据集过度代表了常见危险但忽视了长尾威胁；（2）静态奖励模型不考虑任务难度，这限制了优化效率和可实现的改进。
### Innovation
作者提出了DR-IRL（动态调整奖励通过逆强化学习）。首先，使用覆盖七个有害类别的平衡安全数据集通过逆强化学习训练类别特定的奖励模型。然后，通过引入动态奖励调整来增强Group Relative Policy Optimization（GRPO）算法，包括根据任务难度调整奖励，根据文本编码余弦相似度提高数据层面的难度，以及通过奖励差距提高模型层面的响应性。广泛实验表明，DR-IRL在各个基准和大型语言模型中均优于所有基线方法，同时保持有用性。
### Conclusion
DR-IRL方法通过对奖励的动态调整，在保持输出有用性的同时，在多个基准和大型语言模型中展现出了更好的安全对齐性能。
## 238. `cs.AI` - 向多模态大型语言模型的视觉文本定位迈进 [PDF](https://arxiv.org/pdf/2504.04974), [HTML](https://arxiv.org/abs/2504.04974)
### Authors
Ming Li,Ruiyi Zhang,Jian Chen,Chenguang Wang,Jiuxiang Gu,Yufan Zhou,Franck Dernoncourt,Wanrong Zhu,Tianyi Zhou,Tong Sun
### Background
尽管多模态大型语言模型（MLLMs）已经取得了进展，但它们在视觉文本定位方面仍然面临显著挑战，尤其是在文档图像中的文本密集型图像。当前的基准测试主要集中在自然图像的视觉定位，而不是文本丰富的文档图像，未能充分解决这些问题。因此，为了弥合这些差距，我们提出了TRIG任务，以及一个用于多模态大型语言模型文档问答中文本丰富图像视觉定位能力的新指令数据集。
### Innovation
我们提出了一个OCR-LLM-人类交互流水线来创建800个手工标注的问题-答案对作为基准和一个基于四个不同数据集的90万合成数据的大规模训练集。我们还提出了两种基于通用指令微调和插拔式高效嵌入的TRIG方法，并通过在合成数据集上微调多模态大型语言模型，显示出在空间推理和定位能力方面的显着改善。
### Conclusion
我们的基准测试揭示了现有多模态大型语言模型在文本密集型图像上的定位能力存在巨大局限，提出的TRIG方法能够有效改进这一能力。
## 239. `cs.AI` - LEMUR 神经网络数据集：走向无缝自动生成机器学习 [PDF](https://arxiv.org/pdf/2504.10552), [HTML](https://arxiv.org/abs/2504.10552)
### Authors
Arash Torabi Goodarzi,Roman Kochnev,Waleed Khalid,Hojjat Torabi Goudarzi,Furui Qin,Tolgay Atinc Uzun,Yashkumar Sanjaybhai Dhameliya,Yash Kanubhai Kathiriya,Zofia Antonina Bentyn,Dmitry Ignatov,Radu Timofte
### Background
神经网络是现代人工智能的核心，但设计、评估和比较它们仍然是一项繁重的工作。尽管存在大量用于训练的数据集，但对于模型本身的标准化集合却很少。因此，提出 LEMUR，一个开源的数据集和框架，提供了广泛基础的 PyTorch 基础神经网络，涵盖了分类、分割、检测和自然语言处理等任务。每个模型遵循统一模板，配置和结果存放在结构化数据库中，以保证一致性和可复制性。LEMUR 结合了 Optuna 自动调参，提供了统计分析和可视化工具，并通过 API 提供无缝访问性能数据。框架扩展性强，允许研究人员在不影响兼容性的情况下添加新模型、数据集或指标。通过标准化实现和统一评估，LEMUR 目标是加速 AutoML 研究、促进公平基准测试并降低大规模神经网络实验的门槛。
### Innovation
提供了广泛的 PyTorch 基础神经网络的开源数据集和框架，标准化实现和统一评估方法，自动调参（Optuna），以及统计分析和可视化工具。
### Conclusion
LEMUR 目标是加速 AutoML 研究、促进公平基准测试并降低大规模神经网络实验的门槛。
## 240. `cs.AI` - Egocentric Vision: 挑战与趋势综述 [PDF](https://arxiv.org/pdf/2503.15275), [HTML](https://arxiv.org/abs/2503.15275)
### Authors
Xiang Li,Heqian Qiu,Lanxiao Wang,Hanwen Zhang,Chenghao Qi,Linfeng Han,Huiyu Xiong,Hongliang Li
### Background
随着人工智能技术和可穿戴设备的迅速发展，第一人称视角视觉理解成为了一个新兴且具有挑战性的研究方向，逐渐引起了学术界和工业界的广泛关注。第一人称视角捕捉通过人体佩戴的摄像头或传感器收集的视觉和多模态数据，提供了模拟人类视觉体验的独特视角。
### Innovation
本文对第一人称视角视觉理解的研究进行了全面的综述，系统地分析了第一人称场景的组成部分，并将任务分为四个主要领域：主体理解、对象理解、环境理解以及混合理解。详细探讨了每个分类中的子任务，并总结了当前领域的主要挑战和趋势。还概述了高质量的第一人称视角数据集，为未来的研究提供了宝贵的资源。
### Conclusion
通过对最新进展的总结，本文预见了第一人称视角技术在增强现实、虚拟现实、嵌入式智能等领域中的广泛应用，并基于领域的最新进展提出了未来的研究方向。
## 241. `cs.AI` - 语言模型无法内省其语言知识 [PDF](https://arxiv.org/pdf/2503.07513), [HTML](https://arxiv.org/abs/2503.07513)
### Authors
Siyuan Song,Jennifer Hu,Kyle Mahowald
### Background
近年来，人们开始关注大型语言模型（LLMs）是否能够内省其自身的内部状态。这种能力将使LLMs更具可解释性，并且验证在语言学中使用标准内省方法来评估模型的语法知识的有效性（例如，询问“这个句子是否有语法错误？”）。本文系统地研究了21个开源LLMs在两个理论上有兴趣的领域中出现的内省能力：语法知识和词预测。
### Innovation
本文提出了一个新的内省度量标准：模型在被提示后的反应与其自身字符串概率的预测能力，超过了一个具有几乎相同内部知识的其他模型所能预测的程度。研究采用了通用任务，控制了模型相似度，并评估了广泛的开源模型。结果显示，LLMs无法内省，这增加了关于不应将被提示的反应与模型的语言概括混淆的论点。
### Conclusion
尽管在元语言提示和概率比较任务中均能达到高任务准确性，我们并未发现LLMs拥有特权的“自我访问”。通过使用通用任务，控制模型相似度，并评估广泛范围的开源模型，作者展示了LLMs无法内省，并增添了语言模型不应将被提示的反应与其语言概括混淆这一论点的新证据。
## 242. `cs.AI` - GSPRec: 时间感知的图频谱过滤推荐 [PDF](https://arxiv.org/pdf/2505.11552), [HTML](https://arxiv.org/abs/2505.11552)
### Authors
Ahmad Bin Rabiah,Julian McAuley
### Background
图推荐系统在建模协作模式方面非常有效，但通常存在两个局限性：过度依赖低通过滤，这会抑制用户特定的信号；以及在图构建过程中忽略了顺序动态。
### Innovation
GSPRec 是一种图频谱模型，通过顺序信息驱动的图构建整合了时间转换，并在频谱域中应用了意识频率的过滤。GSPRec 通过多跳扩散编码项目转换以启用对称拉普拉斯矩阵的频谱处理。为了捕捉用户偏好，设计了一种双过滤机制：高斯带通滤波器用于提取中频用户模式，低通滤波器用于保留全局趋势。
### Conclusion
在四个公开数据集上的广泛实验表明，GSPRec 一致优于基准模型，NDCG@10 的平均改进率为 6.77%。消融研究显示了顺序图增强和带通过滤的互补益处。
## 243. `cs.AI` - 无监督估计非线性音频效果：基于扩散和对抗方法的比较 [PDF](https://arxiv.org/pdf/2504.04751), [HTML](https://arxiv.org/abs/2504.04751)
### Authors
Eloi Moliner,Michal Švento,Alec Wright,Lauri Juvela,Pavel Rajmic,Vesa Välimäki
### Background
准确估计非线性音频效果，在没有输入输出配对信号的情况下仍然是一个具有挑战性的问题。本文研究了解决这一任务的无监督概率方法。并基于扩散生成模型提出了一个盲系统识别的新方法，以便使用黑箱和灰箱模型估计未知非线性效果。
### Innovation
引入了一种基于扩散生成模型的方法，应用于盲系统识别，旨在估计未知非线性效果。该研究将这一方法与先前提出的对抗方法进行了比较，在不同的效果操作参数化和不同长度的影响录制下分析了两者的性能。
### Conclusion
通过在吉他失真效果上的实验，本研究证明了扩散基于的方法提供了更稳定的成果并且对数据可用性不那么敏感，而对抗方法则在估计更突出的失真效果时更优。研究成果表明，在音乐技术领域利用扩散模型进行系统识别具有广阔的前景，进一步推动了无监督盲估计算法的发展。
## 244. `cs.AI` - 重访残差连接：用于稳定高效深度网络的正交更新 [PDF](https://arxiv.org/pdf/2505.11881), [HTML](https://arxiv.org/abs/2505.11881)
### Authors
Giyeong Oh,Woohyun Cho,Siyeol Kim,Suhwan Choi,Younjae Yu
### Background
残差连接对于深度神经网络至关重要，它们通过缓解梯度消失问题，使得网络能够构建更深的结构。然而，在标准残差更新中，模块的输出直接加到输入流中，这可能导致更新主要强化或调节现有流的方向，使得模块的学习新特征的能力被低估。
### Innovation
本文提出了正交残差更新：将模块输出相对于输入流进行分解，并仅添加正交分量。此设计旨在引导模块主要贡献新的表示方向，促进更丰富的特征学习，同时促进更有效的训练。实验证明，正交更新策略在多种架构（ResNetV2、视觉变压器）和数据集（CIFARs、TinyImageNet、ImageNet-1k）上提升了泛化准确性及训练稳定性，并在ImageNet-1k上的ViT-B模型实现了1.4%的top-1准确率提升
### Conclusion
我们的正交更新策略在各种架构和数据集上都展示了更好的泛化准确性和训练稳定性，有效地促进了深度网络中的新特征学习。
## 245. `cs.AI` - EDBench：分子建模中的大规模电子密度数据 [PDF](https://arxiv.org/pdf/2505.09262), [HTML](https://arxiv.org/abs/2505.09262)
### Authors
Hongxin Xiang,Ke Li,Mingquan Liu,Zhixiang Cheng,Bin Yao,Wenjie Du,Jun Xia,Li Zeng,Xin Jin,Xiangxiang Zeng
### Background
现有的分子机器学习力场（MLFFs）主要关注原子、分子和简单的量子化学性质（如能量和力）的学习，却忽略了电子密度（ED）在准确理解分子力场（MFFs）中的重要性。ED描述了在原子或分子周围特定位置找到电子的概率，并根据霍恩贝格-科恩定理唯一确定了相互作用多粒子系统的基态属性（如能量、分子结构等）。然而，计算ED依赖于耗时的原理第一性密度泛函理论（DFT），导致缺乏大规模的ED数据，限制了其在MLFFs中的应用。
### Innovation
本文介绍了EDBench，这是一个大规模、高质量的数据集，旨在促进电子规模的学习研究。EDBench基于PCQM4Mv2构建，提供3.3百万分子的准确ED数据。为了全面评估模型理解和利用电子信息的能力，设计了一系列ED为中心的基准任务，涵盖预测、检索和生成。评估结果显示，从EDBench学习是可行的，并且具有高准确性。此外，研究表明，基于学习的方法可以高效地计算ED，精度与传统DFT计算相当，但显著降低了计算成本。所有数据和基准将免费提供，为ED驱动的药物发现和材料科学研究奠定坚实基础。
### Conclusion
EDBench为分子模型研究提供了大规模电子密度数据，有助于提高机器学习在分子力场理解中的精度和效率，促进了药物发现和材料科学中的ED驱动方法的发展。
## 246. `cs.AI` - 从非对齐到对齐：使用多向平行语料库扩展多语言LLMs [PDF](https://arxiv.org/pdf/2505.14045), [HTML](https://arxiv.org/abs/2505.14045)
### Authors
Yingli Shen,Wen Lai,Shuo Wang,Ge Gao,Kangyang Luo,Alexander Fraser,Maosong Sun
### Background
持续的预训练和指令调优在大规模多语言数据集上已被证明能够有效扩展大型语言模型（LLMs）到低资源语言，但这种数据的不一致特性限制了其跨语言语义捕捉的能力。相比之下，多向平行数据能够提供更强的跨语言一致性，赋予了在多语言模型性能提升方面更大的潜力。
### Innovation
介绍了基于TED Talks构建的一个大规模、高质量的多向平行语料库TED2025，涵盖了113种语言，最多有50种语言在平行中对齐。利用此数据集，研究了如何利用多向平行数据强化LLMs，包括持续预训练、指令调优的最佳实践以及关键影响因素的分析。实验结果显示，使用多向平行数据训练的模型在六个多语言基准上持续优于使用非对齐多语言数据训练的模型。
### Conclusion
多向平行数据在改善多语言LLMs性能方面显示出明显的优势，通过最佳实践的应用，能够在多语言平衡中实现更好的语言一致性。
## 247. `cs.AI` - 使用大型语言模型统一文本语义和图结构以处理动态文本标注图 [PDF](https://arxiv.org/pdf/2503.14411), [HTML](https://arxiv.org/abs/2503.14411)
### Authors
Siwei Zhang,Yun Xiong,Yateng Tang,Jiarong Xu,Xi Chen,Zehao Gu,Xuezheng Hao,Zian Jia,Jiawei Zhang
### Background
目前，时间图神经网络（TGNNs）在时间图建模方面表现出显著的性能。然而，现实世界中的时间图往往蕴含丰富的文本信息，形成时间文本标注图（TTAGs）。这种动态文本语义与图表演变结构的融合增加了复杂性。现有的TGNNs静态嵌入文本信息并主要依赖编码机制，偏向于结构信息，忽视了文本语义的时间演化和语义与结构之间的协同影响。
### Innovation
本文提出了CROSS框架，该框架灵活地扩展现有的TGNNs以处理TTAG建模。CROSS将TTAG建模过程分解为两个阶段：（i）时间语义提取；（ii）语义结构信息整合。关键在于利用大型语言模型（LLMs）动态提取文本空间中的时间语义，并生成既能统一语义又能体现结构的信息表示。具体地，提出了超越时空语义提取器，增强LLMs提供节点文本邻域演化语境的及时语义理解能力，促进语义动态。接着介绍了语义结构性协同编码器，该编码器协同上述提取器，在同步考虑语义与结构信息的同时，促进二者相互强化以生成启发式的表示。
### Conclusion
在大规模实验中，CROSS在四个公开数据集和一个工业数据集上取得了最新成果，时间链接预测绝对MRR提升了24.7%，工业应用节点分类AUC提升了3.7%。
## 248. `cs.AI` - 逐步引导策略优化：在GRPO中着色你的错误推理 [PDF](https://arxiv.org/pdf/2505.11595), [HTML](https://arxiv.org/abs/2505.11595)
### Authors
Peter Chen,Xiaopeng Li,Ziniu Li,Xi Chen,Tianyi Lin
### Background
强化学习（RL）已被证明能有效提升大型语言模型（LLMs）的推理能力。一种广泛应用的方法，组相对策略优化（GRPO），在训练DeepSeek-R1时显示出强大的实证效果。然而，GRPO在面对组内所有响应均为错误（即全错误样本组）时无法更新策略。这一局限性揭示了人工智能与人类智能之间的一个关键差距：人类能从错误中学习，而GRPO则丢弃了这些信号。
### Innovation
作者提出了一种简单的框架，通过在组内引入响应多样性，使用逐步指导判别模型来解决GRPO中的全错误样本问题。这种框架可以在不依赖正确答案生成的情况下适应现有LLMs，从而加速GRPO的学习动态。通过逐步引导策略优化（SGPO）方法的经验验证，作者展示了在不同模型规模（7B、14B、32B）和9个基准测试中的一致改进。”其中，SGPO在早期和中期训练阶段，特别是存在全错误样本组时，超过GRPO；SGPO也不需要生成正确答案的判别模型，与知识蒸馏方法有所不同。
### Conclusion
SGPO不仅在大型语言模型的离线和在线训练中表现出一致的改进，还显示了在早中期训练阶段尤其在处理全错误样本组时的优越性。此外，SGPO无需判别模型生成正确答案的特点，使其区别于知识蒸馏方法。
## 249. `cs.AI` - DISCO平衡天平：在不平衡数据上适应性的领域和难度感知强化学习 [PDF](https://arxiv.org/pdf/2505.15074), [HTML](https://arxiv.org/abs/2505.15074)
### Authors
Yuhang Zhou,Jing Zhu,Shengyi Qian,Zhuokai Zhao,Xiyao Wang,Xiaoyu Liu,Ming Li,Paiheng Xu,Wei Ai,Furong Huang
### Background
大语言模型（LLMs）通过人类反馈强化学习（RLHF）越来越接近人类偏好。其中，Group Relative Policy Optimization (GRPO) 因其简化的机制和出色的性能而受到关注，但由于省略了学习的价值函数，GRPO 假定了领域分布的均匀性和组间语义的平衡性，这些假设在真实世界的数据集中很少成立。当应用于多领域、不平衡数据时，GRPO会偏向于主流领域，忽视小众领域，导致泛化能力和公平性较差。
### Innovation
我们提出了Domain-Informed Self-Consistency Policy Optimization（DISCO），旨在通过两个关键创新解决跨组别不平衡问题：领域感知奖励重标度通过重权调整基于领域出现频率的优化；难度感知奖励重标度利用提示级自我一致性来识别并优先处理具有更大学习价值的不确定提示。这些策略能够促进在不同领域中更公平和有效的策略学习。实验结果显示DISCO在多个LLM和非平衡训练分布中改善了泛化能力，与Qwen3模型的现有GRPO变种相比提升了5%，并在多领域对齐基准测试中设定了新标准。
### Conclusion
DISCO在多个LLM和非平衡训练分布中展现了卓越的性能，通过领域和难度感知的方式提升了模型的公平性和泛化能力，尤其是在多领域对齐基准测试中取得了新的最佳结果。我们已将代码和数据开放提供。
## 250. `cs.AI` - SEM：增强空间理解以实现稳健的机器人操作 [PDF](https://arxiv.org/pdf/2505.16196), [HTML](https://arxiv.org/abs/2505.16196)
### Authors
Xuewu Lin,Tianwei Lin,Lichao Huang,Hongyu Xie,Yiwei Jin,Keyu Li,Zhizhong Su
### Background
机器人操作的一个关键挑战在于开发具有强大空间理解能力的策略模型，能够处理3D几何、物体关系和机器人本体。现有方法往往不尽如人意：3D点云模型缺乏语义抽象，而2D图像编码器在空间推理方面存在问题。
### Innovation
提出了一种新的基于扩散的策略框架SEM（Spatial Enhanced Manipulation模型），该框架从两个互补的角度显式增强空间理解。一种空间增强器通过附加3D几何上下文来增强视觉表示，而一种机器人状态编码器通过基于图的建模来捕捉本体感知结构。通过集成这些模块，SEM显著提高了空间理解，使得在各种任务中表现出强大的稳健性和泛化能力。
### Conclusion
SEM在多种任务中都优于现有基线，显著提升了空间理解，从而实现更稳健的机器人操作。
## 251. `cs.AI` - 要不要信任你的视觉-语言模型的预测 [PDF](https://arxiv.org/pdf/2505.23745), [HTML](https://arxiv.org/abs/2505.23745)
### Authors
Hao Dong,Moru Liu,Jian Liang,Eleni Chatzi,Olga Fink
### Background
视觉-语言模型(Vision-Language Models, VLMs)在视觉和文本模态对齐方面展现了强大的能力，支持多种跨模态理解和生成的应用。尽管它们在零样本和转移学习情况中有出色表现，但在安全关键领域中，VLMs仍可能因错误分类而产生严重的后果，这限制了它们的应用范围。
### Innovation
本文提出了TrustVLM，这是一个无需重新训练的框架，旨在解决VLMs预测可信性评估的关键挑战。引入了新的信心评分函数，利用图像嵌入空间来改善错误分类检测。在17个不同数据集上的严格评估表明，TrustVLM在AURC、AUROC和FPR95指标上分别比现有基线提高了51.87%、9.14%和32.42%。
### Conclusion
TrustVLM提高了模型可靠性，无需重新训练，为在实际应用中安全部署VLMs铺平了道路。
## 252. `cs.AI` - 小型模型还是大型模型？零样本还是微调？在医疗保健专用应用中的语言模型选择指南 [PDF](https://arxiv.org/pdf/2504.21191), [HTML](https://arxiv.org/abs/2504.21191)
### Authors
Lovedeep Gondara,Jonathan Simkin,Graham Sayle,Shebnum Devji,Gregory Arbour,Raymond Ng
### Background
研究旨在通过调查微调与零样本使用、邻近领域模型与通用预训练模型、进一步的领域特定预训练以及小型语言模型（SLMs）与大型语言模型（LLMs）对于特定任务的相关性来指导语言模型的选择。研究使用电子病理报告，评估了在不同难度和数据集大小下的三种分类情景。研究表明，微调显著提高了小型语言模型在所有情境中的性能，并且在零样本情况下，大型语言模型优于小型语言模型，但在零样本微调的小型语言模型性能明显优于它。
### Innovation
研究通过评估不同类型的语言模型及其零样本和微调性能，强调了在专门领域中微调小型语言模型的重要性，并指出通过领域相邻或特定领域的预训练可以提供进一步的优势，特别是对于复杂的或有限的微调数据的问题。研究还展示了小型语言模型在与大型语言模型竞争中的潜力和效率。
### Conclusion
研究表明，在具体的医疗保健分类任务中，通过微调的较小语言模型可以超越零样本的大型语言模型，特别是在专业领域。此外，领域相邻或特定领域的预训练提供了进一步的优势，尤其是针对复杂的任务。在大型语言模型的时代，小型语言模型仍具有相关性和有效性，并可能在性能资源权衡方面优于大型语言模型。
## 253. `cs.AI` - Localized LoRA：一种结构化的低秩近似高效微调方法 [PDF](https://arxiv.org/pdf/2506.00236), [HTML](https://arxiv.org/abs/2506.00236)
### Authors
Babak Barazandeh,Subhabrata Majumdar,Om Rajyaguru,George Michailidis
### Background
PEFT方法，如LoRA，通过向预训练权重引入低秩更新提供了一种压缩且有效的全模型微调替代方案。然而，大部分现有方法依赖全局低秩结构，可能会忽略在参数空间分散的空间模式。
### Innovation
本文提出了一种局部LoRA框架，该框架将权重更新建模为结构块上的低秩矩阵的组合应用。这种建模方式允许在整个参数空间中实现密集且局部化的更新，而不增加总的可训练参数数量。此外，提供了全局、局部和完全局部低秩逼近之间的形式对比，并证明了在匹配的参数预算下，我们的方法始终能获得更低的逼近误差。实验表明，局部LoRA提供了一种更具表现力且灵活的替代方法，能够实现高效微调并获得改进的性能。
### Conclusion
局部LoRA为现有方法提供了一种更表达性和适应性的替代方案，实验证明在合成和实际设置中，在高效的微调过程中提供了改进的性能。
## 254. `cs.AI` - PathGene：使用多中心肺癌病理图像数据集进行驱动基因突变和外显子预测基准 [PDF](https://arxiv.org/pdf/2506.00096), [HTML](https://arxiv.org/abs/2506.00096)
### Authors
Liangrui Pan,Qingchun Liang,Shen Zhao,Songqing Fan,Shaoliang Peng
### Background
准确预测肺癌中的基因突变、突变亚型及其外显子对于个性化治疗计划和预后评估至关重要。面对医疗资源区域差异以及基因组检测成本高昂，使用人工智能从常规组织病理学图像推导这些突变和外显子变异，可以极大地促进精准疗法的应用。虽然以前有研究表明深度学习可以加速从肺癌病理切片中预测关键基因突变，但其性能仍不理想，主要限于早期筛查任务。
### Innovation
我们构建了PathGene数据集，包括来自第二湘西医院和中央南大学1,576名患者的组织病理学图像和下一代测序报告，以及来自TCGA-LUAD项目的448名患者。此多中心数据集将整个组织玻片图像与驱动基因突变状态、突变亚型、外显子及肿瘤突变负荷(TMB)状态相连，旨在通过组织病理学图像预测突变、亚型、外显子位置和TMB，以促进早期遗传筛选和精准肿瘤学的发展。PathGene数据集提供与组织病理学图像相关的分子级信息，便于开发生物标志物预测模型。我们还基准测试了11种多元实例学习方法，用于基因突变、亚型、外显子和TMB预测任务。
### Conclusion
这些实验方法为肺癌患者的早期遗传筛查和辅助临床医生迅速制定个性化精准靶向治疗计划提供了有价值的替代方案。代码和数据可以在特定链接中获取。
## 255. `cs.AI` - 日期碎片：分词对时间推理的隐藏瓶颈 [PDF](https://arxiv.org/pdf/2505.16088), [HTML](https://arxiv.org/abs/2505.16088)
### Authors
Gagan Bhatia,Maxime Peyrard,Wei Zhao
### Background
现代BPE分词器经常将日期拆分为无意义的片段，例如20250312会被拆分为202、503、12，这会膨胀token数量并掩盖时间推理所需的内在结构。这种做法导致了在处理常见的历史性或未来日期时，模型的精度下降。
### Innovation
1. 引入日期碎片比率作为简单且可解释的度量标准，用以评估分词器保留多数字日期成分的保真度。2. 发布了DateAugBench，该平台涵盖6500个示例，包括基于上下文的日期解析、格式不变性难题以及贯穿历史、当下和未来时间的日期计算。3. 通过逐层探测和因果注意力跳转分析，揭示了大型语言模型在时间推理中涌现的一种日期抽象机制，通过将月份、日期和年份组件片段重新组合来进行时间推理。4. 实验表明，过度碎片化与精度下降相关，可能高达10分。并且发现模型越大，这种碎片化修复机制出现得越快。
### Conclusion
本研究揭示了日期碎片化是向大型语言模型传递复杂时间信息的隐藏瓶颈，不仅影响模型在非典型日期的精度，还导致更大的模型能够更快地修复这些碎片化问题。此外，发现模型在组装日期片段时遵循不同于人类的推理路径（年份→月份→日期），此路径与其处理实际人类语言的路径有所不同。
## 256. `cs.AI` - 全空间：通往视觉语言模型综合空间推理基准 [PDF](https://arxiv.org/pdf/2506.03135), [HTML](https://arxiv.org/abs/2506.03135)
### Authors
Mengdi Jia,Zekun Qi,Shaochen Zhang,Wenyao Zhang,Xinqiang Yu,Jiawei He,He Wang,Li Yi
### Background
空间推理是认知心理学的关键方面，当前的视觉语言模型在这一领域仍有瓶颈。尽管许多研究致力于评估或改进VLMs对基本空间关系的理解，如区分左右、远近和物体计数，但这些任务仅涵盖了空间推理的最基础层面。最新的推理模型在这些任务上已接近饱和状态。因此，需要一种全面且具有挑战性的空间推理基准来进一步推动VLMs的能力。
### Innovation
作者提出了OmniSpatial，这是一种基于认知心理学的空间推理综合基准。OmniSpatial涵盖了动态推理、复杂的空间逻辑、空间互动和视角理解四个主要类别，包含50个细粒度的子类别。为了构建这一基准，作者进行了详细的手动标注，构造了超过8400个问题-答案对。此外，作者还探索了两种策略，PointGraph（显式场景图提示）和SpatialCoT（新视角的推理链），以加强空间推理能力。
### Conclusion
广泛的实验表明，无论是开源还是闭源的VLMs，在综合空间推理方面都表现出显著的局限性。OmniSpatial为评估和提升VLMs的空间推理能力提供了一个全面且具有挑战性的基准。通过引入新型推理策略，作者展示了提升空间推理能力的可能性。
## 257. `cs.AI` - CellCLIP -- 通过文本引导的对比学习学习细胞绘画中的扰动效应 [PDF](https://arxiv.org/pdf/2506.06290), [HTML](https://arxiv.org/abs/2506.06290)
### Authors
Mingyu Lu,Ethan Weinberger,Chanwoo Kim,Su-In Lee
### Background
高内涵筛选（HCS）测试基于高通量显微镜技术（如细胞绘画），使得可以前所未有的规模来研究细胞在各种干扰下的形态响应。这类数据的收集有望帮助人们更好地理解不同扰动与其对细胞状态影响之间的关系。然而，将交叉模态对比学习方法应用于HCS数据并不直接，因为细胞绘画图像的语义与自然图像有很大不同，而且在同一潜在空间中表示不同类型的扰动（例如，小分子与CRISPR基因敲除）的困难也很大。因此，本文提出了CellCLIP，它是一种专门针对HCS数据的交叉模态对比学习框架。
### Innovation
CellCLIP通过结合预训练的图像编码器和新颖的通道编码方案提高了在图像嵌入中捕捉不同显微镜通道之间关系的能力，并且使用自然语言编码器来表征扰动，从而克服了HCS数据中语义表示和跨模态对比学习的技术挑战。CellCLIP框架在跨模态检索和生物相关的下游任务上均表现出最好的性能，并且在计算时间上实现了显著降低。
### Conclusion
CellCLIP的整体表现优于现有的开源模型，不仅在跨模态检索任务上实现了最佳性能，在生物相关的下游任务上也表现出色，并且减少了大量计算时间，表明它在理解和解析细胞数据方面的潜力。
## 258. `cs.AI` - RadialRouter：结构化表示以实现高效的鲁棒大型语言模型路由 [PDF](https://arxiv.org/pdf/2506.03880), [HTML](https://arxiv.org/abs/2506.03880)
### Authors
Ruihan Jin,Pengpeng Shao,Zhengqi Wen,Jinyang Wu,Mingkuan Feng,Shuai Zhang,Jianhua Tao
### Background
随着大型语言模型（LLMs）的快速进步，出现了路由技术，旨在高效地从多种候选模型中选择最适合特定任务的模型，以优化性能并降低成本。当前的LLM路由方法有效性不足，主要是因为没有充分探索用户查询与LLM特性之间的内在联系。为了解决这个问题，本文提出了一种新的路由框架RadialRouter，该框架基于一种名为RadialFormer的轻量级Transformer核心，以结构化方式描述查询-LLM的关系。在RadialFormer的最终状态基础上进行最佳LLM选择，并通过结合Kullback-Leibler散度和查询-查询对比损失的目标函数进一步优化鲁棒性。
### Innovation
本文提出的RadialRouter框架通过使用名为RadialFormer的轻量级Transformer核心，有效地解决了当前LLM路由方法中存在的问题。RadialFormer通过结构化表示查询和LLM之间的关系，以及结合Kullback-Leibler散度和查询-查询对比损失的目标函数提高了模型的鲁棒性。实验结果表明，RadialRouter在RouterBench测试中比现有方法分别在平衡场景和成本优先场景中提高了9.2%和5.8%。
### Conclusion
RadialRouter框架具有不同的性能和成本折衷适应性和动态LLM池，显示出在实际应用中的潜力。实验结果表明，它在RouterBench测试中比现有方法在平衡场景中提高了9.2%，在成本优先场景中提高了5.8%。
## 259. `cs.AI` - 为什么某些输入会导致低位宽大语言模型量化出现较大错误？ [PDF](https://arxiv.org/pdf/2506.12044), [HTML](https://arxiv.org/abs/2506.12044)
### Authors
Ting-Yun Chang,Muru Zhang,Jesse Thomason,Robin Jia
### Background
低位宽的仅权重量化显著减少了大型语言模型（LLMs）的内存占用，但对某些示例的影响不成比例。作者对7亿到70亿参数的LLMs进行了多种3-4位方法的分析，发现50对方法在FineWeb示例上的量化误差高度相关（平均0.82），并且全精度模型的残差流幅度可以预测未来的量化误差。
### Innovation
研究建立了残差流幅度与误差放大和逐层累积之间的假设。作者通过LLM定位技术、早期退出和激活修补，发现具有大错误的示例依赖于后期层中精准的残差激活，并且MLP门的输出对困惑度的维持至关重要。研究揭示了为什么某些示例会导致较大量化误差以及哪些模型组件对于性能保留最为关键。
### Conclusion
通过分析多种量化方法的关联性和模型的残差流幅度，以及特定层和激活函数的影响，作者揭示了导致量化误差的关键因素，指出了模型的组成部分对于保持性能的重要性。
## 260. `cs.AI` - Urania: 拥有差分隐私的AI使用洞察 [PDF](https://arxiv.org/pdf/2506.04681), [HTML](https://arxiv.org/abs/2506.04681)
### Authors
Daogao Liu,Edith Cohen,Badih Ghazi,Peter Kairouz,Pritish Kamath,Alexander Knop,Ravi Kumar,Pasin Manurangsi,Adam Sealfon,Da Yu,Chiyuan Zhang
### Background
本文介绍了$Urania$，这是一个新颖的框架，旨在通过严格的差分隐私(DP)保证生成关于大规模语言模型(LLM)聊天机器人交互的见解。该框架结合了私有聚类机制和创新的关键词提取方法，包括基于频率、TF-IDF和LLM引导的方法。通过利用差分隐私工具如聚类、分区选择和基于直方图的摘要，$Urania$提供了端到端的隐私保护。我们对文本和语义内容的保留、配对相似性以及基于LLM的指标进行了评估，与Clio启发的非隐私处理管道（Tamkin等，2024）进行了基准测试。此外，我们还开发了一种简单的实证隐私评估方法，以展示我们差分隐私管道的增强稳健性。结果表明，该框架能够在保持严格用户隐私的同时，提取出有意义的对话洞察，并有效平衡数据效用与隐私保护之间的关系，
### Innovation
该框架采用了私有聚类机制和创新的关键词提取方法，包括频率、TF-IDF和LLM引导的方法。利用差分隐私工具进行端到端的隐私保护。通过实证隐私评估展示了该框架的稳健性，并与非隐私处理进行了基准测试，证明了其有效平衡数据效用与隐私保护的能力
### Conclusion
该框架能够在保持严格用户隐私的同时，提取出有意义的对话洞察，证明了其在实现数据效用与隐私保护之间的有效平衡，显示出了其在保护用户隐私和生成有价值见解的潜力。
## 261. `cs.AI` - 基于四阶段方法的不确定性感知深度学习皮肤癌分类 [PDF](https://arxiv.org/pdf/2506.10302), [HTML](https://arxiv.org/abs/2506.10302)
### Authors
Hamzeh Asgharnezhad,Pegah Tabarisaadi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharya
### Background
准确的皮肤癌诊断对于早期治疗和改善患者预后至关重要。尽管深度学习模型在自动化皮肤癌分类方面显示出潜力，但数据稀缺性和有限的不确定性意识仍然是挑战。本文对基于迁移学习和不确定性量化的深度学习皮肤病变分类进行了全面评估，使用HAM10000数据集对该方法进行了验证。文中介绍了多个预训练的特征提取器，传统分类器以及多种主成分分析设置的应用，为皮肤癌分类提供了准确性和可靠性兼顾的解决方案，并进一步通过特征融合改进了模型性能。最后，提出了一种基于预测熵损失函数的特征融合模型，并表现出最佳的分类效果和稳健性
### Innovation
本文引入了四个阶段的方法（迁移学习、不确定性量化、特征融合和预测熵损失）来改进皮肤癌分类的深度学习模型，首先通过迁移学习的多种预训练特征提取器组合，并应用了主成分分析以减低特征维度，全面提升模型的性能和可靠性。在不确定性量化阶段，采用了蒙特卡洛丢弃、集成和蒙特卡洛丢弃集成等方法，结合不确定性感知指标进行评价。此外，提出了一种基于预测熵的损失函数的特征融合模型，在标准评估和不确定性感知评估中均表现出最佳效果，并为准确可靠且可信赖的深度学习皮肤癌诊断提供了新的解决方案
### Conclusion
本文通过多阶段的方法改进了基于深度学习的皮肤癌分类模型，展示了改善分类性能和不确定性估计的能力，最终提出的一种基于预测熵的特征融合模型在多个评估标准中均取得了最佳效果，促进了可信的皮肤癌深度学习诊断的应用和发展
## 262. `cs.AI` - 构建适用于实际应用的RAG系统：设计、开发与评估 [PDF](https://arxiv.org/pdf/2506.20869), [HTML](https://arxiv.org/abs/2506.20869)
### Authors
Md Toufique Hasan,Muhammad Waseem,Kai-Kristian Kemell,Ayman Asad Khan,Mika Saari,Pekka Abrahamsson
### Background
检索增强生成（RAG）系统正在成为将大型语言模型（LLMs）与外部知识对接的关键方法，解决其在事实准确性和上下文相关性方面的局限性。然而，缺乏基于真实应用场景的RAG系统实施研究，这些研究通过一般用户参与进行评估，并附带系统的经验教训。
### Innovation
本文提出了五个针对具体应用场景的RAG系统，分别是治理、网络安全、农业、工业研究和医疗诊断领域。每个系统结合了多语言OCR技术、向量嵌入的语义检索以及针对特定领域的自适应语言模型，并通过本地服务器或云API部署以满足不同的用户需求。通过一个基于网页的评估，共有100名参与者评估了系统的六个维度：易用性、相关性、透明度、响应性、准确性和推荐可能性。基于用户反馈和开发经验，总结了十二个关键经验教训，强调了技术、运营和伦理挑战对RAG系统可靠性和易用性的影响。
### Conclusion
研究表明，RAG系统的可靠性和易用性受到技术和伦理挑战的影响。系统开发过程中积累了宝贵的实践教训，这些教训对于未来RAG系统的实施具有重要的指导意义。
## 263. `cs.AI` - SurgVidLM：利用大型语言模型实现多层次外科手术视频理解 [PDF](https://arxiv.org/pdf/2506.17873), [HTML](https://arxiv.org/abs/2506.17873)
### Authors
Guankun Wang,Junyi Wang,Wenjin Mo,Long Bai,Kun Yuan,Ming Hu,Jinlin Wu,Junjun He,Yiming Huang,Nicolas Padoy,Zhen Lei,Hongbin Liu,Nassir Navab,Hongliang Ren
### Background
外科环境的理解对于手术训练和机器人辅助手术中的决策至关重要。最近，多模态大型语言模型（MLLMs）在医疗领域中显示了在场景感知方面的巨大潜力，帮助外科医生理解手术场景和流程。然而，这些方法主要集中在基于图像的分析或全球视频理解上，忽略了对特定步骤的精细分析和详细任务执行的捕捉，这在分析手术过程时尤为重要。为解决这一问题，该研究提出了一种新的视频语言模型SurgVidLM，能够同时处理整体和精细的手术视频理解。为了训练SurgVidLM，该团队构建了一个包含超过31,000个视频指令对的大规模数据集SVU-31K，既支持对整体的理解又支持对细节的分析。
### Innovation
SurgVidLM是一个专门设计用于处理手术视频的多阶段视频语言模型，采用了StageFocus机制和多频率融合注意力机制。StageFocus机制分为两个阶段：第一阶段提取全局手术上下文，第二阶段在时间线索的引导下进行高频局部分析。该模型还引入了多频率融合注意力机制，有效整合了低频和高频视觉标记，保留了关键的任务特定细节。实验结果显示，SurgVidLM在整体和精细的视频理解任务中都显著优于参数规模相当的最先进的视视频大型语言模型（Vid-LLMs），展示了其在复杂机器人辅助手术中理解上下文的能力。
### Conclusion
实验结果表明，SurgVidLM在整体和精细的视频理解任务中都显著优于现有同类模型，并展示了其在复杂机器人辅助手术中理解上下文的优越能力。模型的代码和数据集将在不久的将来公开提供。
## 264. `cs.AI` - 结构即搜索：无监督排列学习在组合优化中的应用 [PDF](https://arxiv.org/pdf/2507.04164), [HTML](https://arxiv.org/abs/2507.04164)
### Authors
Yimeng Min,Carla P. Gomes
### Background
该研究针对旅行商问题提供了一个非自回归框架，其中解决方案直接源自学习到的排列，无需进行显式的搜索。通过将哈密顿循环应用相似变换，模型学习通过连续松弛近似排列矩阵。论文的方法展示了无监督方式在面对经典的启发式算法时，仍然可以达到具有竞争力的表现，证明了问题的固有结构可以有效引导组合优化过程，而无需依赖顺序决策。研究指出，神经网络可以直接捕捉和利用组合结构信息。
### Innovation
该论文提出了一种非自回归框架来解决旅行商问题，使解决方案直接由学习到的排列产生，而不需要显式的搜索。通过相似变换将哈密顿循环转化为连续松弛的排列矩阵，模型无需进行显式搜索而直接生成近似解。这种方法展示了在无监督情况下，可以达到与经典启发式方法相似甚至更好的性能，证明了解决组合优化问题时无需进行顺序决策。
### Conclusion
研究方法证明了神经网络有能力直接捕捉并利用组合结构信息。该无监督学习方法在组合优化中显示出巨大的潜力，并为未来开发更高效的组合优化技术提供了新的研究方向。
## 265. `cs.AI` -  renewable-colocated artificial intelligence 数据中心的能源管理 [PDF](https://arxiv.org/pdf/2507.08011), [HTML](https://arxiv.org/abs/2507.08011)
### Authors
Siying Li,Lang Tong,Timothy D. Mount
### Background
本文研究了将可再生能源与人工智能数据中心联合部署的环境下，开发了一套能源管理系统（EMS），该系统在成本最小化框架下，同时优化了人工智能工作负载调度、现场可再生能源利用以及电力市场的参与。通过实际电力价格、数据中心电力消耗和可再生能源生成的数据，实证评估表明可再生能源和人工智能数据中心联合部署可以显著降低电费成本。
### Innovation
提出了将可再生能源与人工智能数据中心联合部署的能源管理系统，实现了工作负载调度、可再生能源利用和电力市场参与的综合优化，进而最大化可再生能源联合数据中心的经济效益。
### Conclusion
实证研究结果证明，通过优化工作负载调度、可再生能源利用率和电力市场参与，可再生能源联合部署的人工智能数据中心能够显著降低运营成本，为提高能源利用率和经济效益提供了有效途径。
## 266. `cs.AI` - LoSiA: 通过子网络定位与优化实现高效高秩微调 [PDF](https://arxiv.org/pdf/2507.04487), [HTML](https://arxiv.org/abs/2507.04487)
### Authors
Xujia Wang,Yunjia Qi,Bin Xu
### Background
现有的参数高效微调（PEFT）方法，如LoRA，通过引入低秩分解矩阵显著减少了可训练参数的数量。然而，这些方法在领域特定任务中执行大量的矩阵乘法，导致计算效率低下且微调性能不佳。
### Innovation
提出了一种名为LoSiA（Low-Resources Subnet Integration Adaptation）的新颖方法，在训练过程中动态定位并优化关键参数。具体而言，使用梯度稀疏性分析确定并优化子网络作为可训练目标。这种方法通过仅更新子网络参数实现有效的高秩适应，减少了额外的矩阵乘法。此外，还提出了一种更快的LoSiA-Pro实现，与LoRA相比，训练延迟减少了约27%。
### Conclusion
广泛的评估表明，该方法在领域特定任务和常识推理任务中实现了与完全微调相近的微调性能，而所需训练时间最少。进一步分析表明，LoSiA 在持续训练过程中也减少了遗忘。
## 267. `cs.AI` - 超越简单图形：多目标多图上的神经网络路由 [PDF](https://arxiv.org/pdf/2506.22095), [HTML](https://arxiv.org/abs/2506.22095)
### Authors
Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár
### Background
近年来，基于学习的方法在单目标和多目标的路径规划中受到了广泛关注，尽管多图（包含多条具有不同属性边的节点对的图）在现实场景中有很强的相关性，但现有的方法并不适用于处理多图的路径规划问题。针对这一不足，论文提出了两种基于图神经网络的方法来解决多图上的多目标路径规划问题。
### Innovation
论文提出了两种基于图神经网络的方法，一种直接在多图上按自回归方式选择边，直到完成路径；另一种通过学习策略简化多图，再在简化后的单图上进行路径规划，该方法更加可扩展。论文实验证明这两种方法相比强启发式方法和神经基线具有竞争力的表现，
### Conclusion
该论文通过提出的两种基于图神经网络的方法在广泛的实验问题和图分布上展示了多图多目标路径规划的有效性和实用性，证明了基于学习的方法在处理复杂图结构问题上的潜力。
## 268. `cs.AI` - CUPID: 使用影响函数 curating 数据以使机器人爱上数据 [PDF](https://arxiv.org/pdf/2506.19121), [HTML](https://arxiv.org/abs/2506.19121)
### Authors
Christopher Agia,Rohan Sinha,Jingyun Yang,Rika Antonova,Marco Pavone,Haruki Nishimura,Masha Itkina,Jeannette Bohg
### Background
在机器学习模仿学习中，策略性能与演示数据的质量和组成紧密相关。然而，对于每个演示数据如何影响下游结果（如闭环任务成功或失败）缺乏精确的理解仍然是一个持续的挑战。本研究旨在提出一种基于新颖的影响函数理论公式来解释模仿学习策略的CUPID机器人数据管理方法。通过这种方法，可以估计每个训练演示对策略预期回报的影响，并据此对演示进行排名和选择，从而优化策略的闭环性能。该方法已被用于通过过滤掉对策略性能有害的演示数据，并选择新收集的将最能提高策略性能的数据轨迹来管理数据。广泛模拟和物理实验表明，该方法能够识别出影响测试时性能的数据。具体而言，使用少于33%经过筛选的数据可以到达模拟RoboMimic基准测试的最佳扩散策略性能，而在物理实验中也观察到类似的结果。此外，物理实验表明该方法可以识别出在数据分布变化时的鲁棒策略，隔离伪相关，并且还可以提升通用机器人策略的后训练效果。相关视频和代码已发布在此链接:[]()（原始链接已提供）。
### Innovation
提出了一种基于影响函数理论的模仿学习策略CUPID方法，该方法能够估计每个训练演示对策略预期回报的影响，并据此对演示进行排名和选择，从而优化策略的闭环性能。利用CUPID方法，研究者成功地通过过滤掉对策略性能有害的演示数据和选择新收集的将最能提高策略性能的数据轨迹来管理数据。通过这种方法，显著提高了策略在模拟和物理环境中的性能，尤其是在数据分布变化时的鲁棒性方面也取得了显著提升。此外，这种方法还能识别出伪相关，提升通用策略的性能，显示出其在机器人领域的广泛应用潜力。
### Conclusion
CUPID方法能够准确识别出影响测试时性能的关键数据，并能够有效地优化策略的闭环性能，特别是在处理数据分布变化时也表现出色。这种方法为提高机器人学习和性能提供了一种新的有效方法，具有很大的应用潜力。
## 269. `cs.AI` - 量子-经典混合量化神经网络 [PDF](https://arxiv.org/pdf/2506.18240), [HTML](https://arxiv.org/abs/2506.18240)
### Authors
Wenxin Li,Chuan Wang,Hongdong Zhu,Qi Gao,Yin Ma,Hai Wei,Kai Wen
### Background
研究工作提出了一种新颖的量化神经网络训练模型，即二次二进制优化（QBO）模型，能够通过样条插值来使用任意激活和损失函数。此外，提出了前向区间传播（FIP）方法来解决非线性和多层复合结构带来的挑战，通过将激活函数离散化为线性子区间来保留神经网络的通用逼近特性，从而使其能够在量子计算中优化复杂的非线性函数，进而扩大其在人工智能中的应用范围。通过优化角度推导了经验风险最小化问题的样本复杂性，提供了逼近误差的理论上界和所需的伊辛自旋数目的上界。
### Innovation
1. 提出了一种新的QBO模型，允许使用任意激活和损失函数；2. 引入了前向区间传播（FIP）方法，用于处理神经网络中的非线性和多层复合结构；3. 使用量子条件梯度下降（QCGD）算法直接解决带有约束的二次二进制优化问题，并提供了QCGD算法的收敛性证明。4. 提供了针对量子受限条件下算法性能的理论分析，包括时间复杂性和精度约束的提升。5. 提出了基于单样本的位尺度优化训练算法。
### Conclusion
该研究通过引入QBO模型和FIP方法，以及通过QCGD算法解决优化问题，成功地将量子计算和经典方法结合应用于量化神经网络训练中，从而拓宽了其在人工智能中的应用范围。同时为解决大规模QCBO问题提供了新的算法和理论基础。
## 270. `cs.AI` - 白 Basilisk：一种代码漏洞检测的混合模型 [PDF](https://arxiv.org/pdf/2507.08540), [HTML](https://arxiv.org/abs/2507.08540)
### Authors
Ioannis Lamprou,Alexander Shevtsov,Ioannis Arapakis,Sotiris Ioannidis
### Background
软件漏洞的增多给网络安全带来了重大挑战，需要更有效的检测方法。现有方法在检测代码漏洞时存在局限性，无法高效处理大规模代码库，并且大型模型的规模限制了其应用场景的广泛性。
### Innovation
白 Basilisk 创新性地采用了结合 Mamba 层、线性自注意力和专家混合框架的独特架构。该模型仅包含 200M 参数，却在代码漏洞检测任务中达到了最先进的性能，并且能够处理前所未有的长序列，显著提升了对大型代码库的处理能力。此外，它在不平衡的真实世界数据集上表现出色，且保持了高效的计算特性，有利于在不同规模的组织中部署。这一研究不仅建立了代码安全的新基准，还提供了实证证据，证明紧凑且高效设计的模型在特定任务中可以超越更大规模的模型，或有可能重新定义 AI 开发中的优化策略，特别是在特定领域应用中。
### Conclusion
通过推出白 Basilisk，研究不仅提高了代码安全的检测能力，还展示了即使在规模较小的情况下，精心设计的模型也能在特定领域中表现出色，可能重新定义未来 AI 开发中针对领域特定应用的优化策略。
## 271. `cs.AI` - 基于生物测定背景的Assay2Mol药物设计 [PDF](https://arxiv.org/pdf/2507.12574), [HTML](https://arxiv.org/abs/2507.12574)
### Authors
Yifan Deng,Spencer S. Ericksen,Anthony Gitter
### Background
科学数据库汇集了大量定量数据和描述性文本。在生物化学中，分子筛选实验评估候选分子相对于疾病目标的功能反应。这些实验中描述的生物机制、实验筛选协议以及其他实验特征的文字描述提供了丰富的药物发现信息，但因为这些信息以非结构化格式存在，尚未被充分利用。
### Innovation
我们提出了Assay2Mol，一种基于大规模语言模型的工作流，可以利用现有的大量生物化学筛选实验，支持早期药物发现。Assay2Mol通过检索与新目标相似的目标的现有实验记录，并利用检索到的实验筛选数据进行上下文学习，从而生成候选分子。Assay2Mol在生成目标蛋白结构候选配体分子方面优于最近的机器学习方法，并促进更具合成性的分子生成。
### Conclusion
Assay2Mol展示了利用大规模语言模型来利用非结构化生物实验数据的潜力，为早期药物发现提供了有效的工具。
## 272. `cs.AI` - 动态参数记忆：临时LoRA增强的大模型在长序列对话情绪识别中的应用 [PDF](https://arxiv.org/pdf/2507.09076), [HTML](https://arxiv.org/abs/2507.09076)
### Authors
Jialong Mai,Xiaofen Xing,Yawei Li,Weidong Chen,Zhipeng Li,Jingyuan Xing,Xiangmin Xu
### Background
近年来，研究重点在于将大型语言模型应用于提升言语情感识别（SER）。言语模态固有的高帧率严重限制了SLLM的信号处理能力和理解能力。例如，一个带有4K上下文窗口的SLLM在50Hz特征采样率下只能处理80秒的音频。输入令牌压缩方法忽略了多次对话轮次中情感的一致性和惯性。已有研究不考虑这些因素，导致模型效能受到限制。
### Innovation
本文提出了一种动态参数记忆（DPM）机制，结合上下文语义和句子级情绪编码，允许SLLM处理无限长的音频，同时保持有限的上下文窗口。DPM机制在推理过程中逐步将句子级信息和情绪编码到临时LoRA模块中，以有效“记忆”上下文信息。实验结果显示，DPM显著提高了SLLM处理长音频序列的情绪识别能力，实现了最先进的性能。
### Conclusion
通过DPM机制，SLLM在处理长音频序列时情绪识别能力得到了显著提升，展现了在长对话序列情绪识别方面的优越性能。
## 273. `cs.AI` - VisualTrap：通过视觉锚定操纵实现GUI代理的隐秘后门攻击 [PDF](https://arxiv.org/pdf/2507.06899), [HTML](https://arxiv.org/abs/2507.06899)
### Authors
Ziang Ye,Yang Zhang,Wentao Shi,Xiaoyu You,Fuli Feng,Tat-Seng Chua
### Background
图形用户界面（GUI）代理由大规模视觉-语言模型（LVLMs）驱动，已经成为了自动化人机交互的革命性方法，能够自主操作个人设备（例如：移动电话）或应用以完成复杂的现实世界任务，类人类操作。然而，它们与个人设备的紧密集成引发了重大安全顾虑，包括后门攻击等威胁，尚未被充分研究。这项工作揭示了视觉锚定的视觉地基可能引入漏洞，使攻击能够将GUI代理的文本计划映射到错误的目标上，导致新的后门攻击类型。即使给定正确的任务解决计划，代理的行为也会被破坏。为此，我们提出了VisualTrap，这是一种可以通过误导GUI代理将文本计划定位到触发位置而不是预期目标，来劫持视觉地基的方法。VisualTrap在视觉地基的预训练阶段注入污染数据，以确保攻击的可行性。实验结果表明，使用不到5%的污染数据，VisualTrap能够有效地劫持视觉地基，并且具有高度隐蔽的视觉触发器（对人类不可见）；即使在清洁的微调下，攻击也能泛化到下游任务，并且注入的触发器在不同的GUI环境中仍有效，例如在移动/网络环境中训练并在桌面环境中泛化。这些发现强调了进一步研究GUI代理后门攻击风险的紧迫性。
### Innovation
这项研究提出了一种名为VisualTrap的方法，通过在视觉锚定的预训练过程中注入污染数据，来劫持GUI代理的视觉地基，导致原本正确的任务解决计划被误导执行新的触发目标，实现了隐秘的后门攻击。这种方法不仅能够以最少的污染数据有效地实施攻击，而且在触发器的设计上具有高度的隐蔽性，并且能够泛化到不同的GUI环境下的下游任务执行中，为研究GUI代理的后门攻击风险提供了新的视角。
### Conclusion
实验结果强调了视觉地基的脆弱性和潜在的后门攻击风险，需要进一步研究以提高GUI代理的安全性。研究结果也表明，通过针对性地在视觉地基的预训练阶段注入污染数据，可以实现有效的后门攻击。这些发现对设计和实现更安全的GUI代理具有重要意义。
## 274. `cs.AI` - 利用自适应上下文压缩提升RAG效率 [PDF](https://arxiv.org/pdf/2507.22931), [HTML](https://arxiv.org/abs/2507.22931)
### Authors
Shuyu Guo,Shuo Zhang,Zhaochun Ren
### Background
检索增强生成（RAG）能够通过外部知识增强大规模语言模型（LLMs），但较长的检索上下文也会带来显著的推理成本。虽然上下文压缩可以缓解这个问题，但现有的方法通常使用固定压缩率，这在简单查询上过于压缩，在复杂查询上又不够压缩。现有文献存在的问题是无法根据输入的复杂度动态调整压缩率，这会影响到推理效率和准确性之间的平衡。
### Innovation
提出了一种称为自适应上下文压缩的RAG框架（ACC-RAG），根据输入的复杂度动态调整压缩率，既优化了推理效率又不牺牲准确性。该框架结合了一个分层压缩器和一个上下文选择器，类似于人类快速浏览的过程，可以保留最少但必要的信息。实验结果表明，ACC-RAG在Wikipedia和五个QA数据集上优于固定压缩率的方法，并且相比标准RAG可以在更快的时间内实现超过四倍的推理速度，同时保持或提高了准确性。
### Conclusion
ACC-RAG通过自适应调整压缩率，在效率和准确性之间取得了更好的平衡，提升了RAG的推理效率，为RAG技术的实际应用提供了新的思路。
## 275. `cs.AI` - CANDLE: 一种用于可解释性 sarcopenia 诊断的跨模态代理知识蒸馏框架 [PDF](https://arxiv.org/pdf/2507.21179), [HTML](https://arxiv.org/abs/2507.21179)
### Authors
Yuqi Jin,Zhenhao Shuai,Zihan Hu,Weiteng Zhang,Weihao Xie,Jianwei Shuai,Xian Shen,Zhen Feng
### Background
大型语言模型（LLMs）通过学习大量文本和网页数据，展示了卓越的泛化和迁移能力。它们的语义表示允许跨任务知识转移和推理，为临床医学等数据稀缺和异质领域提供了前景。但在诊断任务如肌少症中，仍存在可解释性、透明性和部署效率等方面的重大挑战。传统机器学习模型提供了稳定的表现和特征级别的归因，确保了可追溯和可审计的决策逻辑，但缺乏广泛的语义深度。相比之下，LLMs能够灵活地进行推理，但常作为不透明的预测器发挥作用。现有的集成策略仍然缺乏深度，很少将传统机器学习的结构化推理嵌入到LLM推理中。因此，如何在保持性能的同时增强模型的可解释性是个亟待解决的问题。
### Innovation
本文提出了CANDLE框架，结合了SHAP（SHapley Additive exPlanations）提取的统计证据和通过强化学习训练的LLM推理，以缓解可解释性与性能之间的权衡。该框架通过将SHAP基于的输入结构化并传输给LLM，再由LLM进行推理，在精密推理的同时保留了决策一致性。此外，框架还通过检索增强生成（RAG）将提炼出的知识整合到结构化的知识库中，并进行案例推理，从而实现了可解释、可再现且与临床一致的决策支持，具有应用于更广泛的医学领域可能的广泛意义。
### Conclusion
CANDLE框架通过结合SHAP提取的统计证据和通过强化学习训练的LLM推理，缓解了可解释性与性能之间的权衡，提高了预测准确性，并维持了高决策一致性。该框架提供了一种可扩展的方法来将TML模型的知识资产化，能够提供可解释、可再现且与临床一致性支持的诊断决策，适用于肌少症及其更广泛的医学领域。
## 276. `cs.AI` - 代码生成中的嵌入对齐以用于音频 [PDF](https://arxiv.org/pdf/2508.05473), [HTML](https://arxiv.org/abs/2508.05473)
### Authors
Sam Kouteili,Hiren Madhu,George Typaldos,Mark Santolucito
### Background
LLM驱动的代码生成有可能通过促进用户专注结构模式而非语法细节，革命化诸如实时编码之类的创意编码任务。在这些领域中，向LLM提供指令时，用户可以从多个不同的代码候选中受益，以更好地实现他们的音乐意图。尽管如此，代码生成模型在提供独特且多样的代码候选上仍存在问题，且缺乏代码音效输出的直接洞察。为此，本文研究了代码与音频嵌入空间之间的拓扑关系，发现代码和音频嵌入并不呈现简单的线性关系。
### Innovation
本文提出了一种模型，给定代码可以预测输出音频嵌入，构建了一个代码-音频嵌入对齐图，弥补了代码生成模型在提供独特且多样代码候选上的不足，并通过一个构建的预测模型展示了可以学习到嵌入对齐映射的可能性，为用户提供更好的音乐输出多样性支持
### Conclusion
本文通过探索代码与音频嵌入空间之间的关系，提出了能够预测代码到音频嵌入映射的模型，为创意编码任务提供了新的工具，有助于更好地实现音乐创作意图。
## 277. `cs.AI` - 从查询到逻辑：LLMs中的基于本体的多跳推理 [PDF](https://arxiv.org/pdf/2508.01424), [HTML](https://arxiv.org/abs/2508.01424)
### Authors
Haonan Bian,Yutao Qi,Rui Yang,Yuanxi Che,Jiaqian Wang,Heming Xia,Ranran Zhen
### Background
大语言模型（LLMs）在回答问题方面取得了巨大成功，但在复杂多跳问答任务（MQA）中仍存在局限性。这些任务需要非线性和结构化的推理，而LLMs在捕捉实体间深层次的概念关系方面存在不足，从而影响了其在复杂多跳任务中的表现。因此，需要一种新的方法来解决这些问题，以提高模型在复杂任务中的表现能力。
### Innovation
本文提出了一种名为ORACLE（Ontology-driven Reasoning and Chain for Logical Exlication）的训练无监督框架。ORACLE将LLMs的生成能力与知识图谱的结构优势相结合，通过三个步骤来实现这一目标：（1）使用LLMs动态构建问题特定的知识本体；（2）将这些本体转化为一阶逻辑推理链；（3）系统地将原始查询分解为逻辑上相关的子问题。实验结果表明，该框架在多个标准多跳问答基准上表现优异，与现有最先进的模型DeepSeek-R1相当，并且证明了每个组件的有效性，展示了ORACLE生成的推理链在逻辑性和可解释性上有明显优势。
### Conclusion
实验结果表明，ORACLE框架在复杂多跳问答任务中的表现达到了目前最先进的水平，特别是在逻辑推理和结果的可解释性方面表现出色。此外，通过各部分的详细分析，进一步验证了ORACLE的有效性，证明了其在生成逻辑推理链方面的优势。
## 278. `cs.AI` - 测量计算机使用代理的危害性 [PDF](https://arxiv.org/pdf/2508.00935), [HTML](https://arxiv.org/abs/2508.00935)
### Authors
Aaron Xuxiang Tian,Ruofan Zhang,Janet Tang,Ji Wang,Tianyu Shi,Jiaxin Wen
### Background
计算机使用代理（CUAs）能够自主控制计算机执行多步操作，若被误用将带来重大安全隐患。现有的基准测试主要评估语言模型（LM）在聊天机器人或简单工具使用方面的表现，未能全面评估CUAs的误用风险。因此，本文提出了一种新的基准测试——CUAHarm，用于准确评估CUAs的误用风险。CUAHarm包含104个由专家撰写的真实误用案例，例如禁用防火墙、泄露数据或安装后门，并设计了一个基于规则的验证奖励沙盒来测量CUAs执行这些任务的成功率（如防火墙是否真正被禁用）而不仅仅是拒绝率。此外，研究还展示了最新的LMs即使在无越狱提示的情况下，成功率仍然很高（例如，GPT-5的表现达到90%），并且新模型的安全问题变得更加严重。
### Innovation
本文提出的CUAHarm基准测试填补了现有研究中对CUAs误用风险评估的空白。通过高级LMs和最新的标杆性代理框架（UI-TARS-1.5）测试展示，研究发现最新的LMs在执行恶意任务方面表现更好，尽管某些框架改善了性能，但也放大了恶意风险。此外，研究还探索了使用LM监控CUAs行为的方法，发现与传统聊天机器人响应监控相比，监控不可安全的计算机使用行为更为困难。尽管监测思维链效果有限，但层次总结策略可以将表现提高13%，显示出监控改进的潜力，但监控的可靠性仍需提高。
### Conclusion
本文提出了CUAHarm基准测试，评估CUAs的误用风险。实证研究表明最新的LMs在误用方面表现突出，但衍生出更高的安全风险。为减轻CUAs的安全风险，本文探索了使用LM监控CUAs行为的方法，但发现监控效果仍不稳定。为了进一步研究这些风险，该基准将公开发布。
## 279. `cs.AI` - SciRerankBench: 评估 RAG-LLMs 中重排序器的基准 [PDF](https://arxiv.org/pdf/2508.08742), [HTML](https://arxiv.org/abs/2508.08742)
### Authors
Haotian Chen,Qingqing Long,Meng Xiao,Xiao Luo,Wei Ju,Chengrui Wang,Xuezhi Wang,Yuanchun Zhou,Hengshu Zhu
### Background
科学文献问答是推动新科学发现的关键步骤。近年来，采用两阶段检索增强生成型大型语言模型（RAG-LLMs）已经在这一领域展现出显著进步。特别是在科学领域，术语上的细微差异可能对最后的事实导向或知识密集型答案有严重影响。尽管已经取得重要进展，但这些工作的潜力和局限性尚未完全探索。
### Innovation
该工作提出了一个名为 SciRerankBench 的科学重排序基准，以评估 RAG-LLMs 系统中的重排序器表现，涵盖五个科学主题。通过开发三类问题-上下文-回答（Q-C-A）对，即噪声上下文（NC）、语义相似但逻辑无关上下文（SSLI）和反假设上下文（CC），逐个系统地评估 13 个广泛使用的重排序器在五种家族大型语言模型上的性能。SciRerankBench 是第一个专门用于评估 RAG-LLMs 中重排序器的基准，提供了对未来发展的有益观察和指导。
### Conclusion
通过系统评估，该研究提供了关于这些重排序器的相对优点和局限性的详细见解，SciRerankBench 是第一个专门开发用于评估 RAG-LLMs 中重排序器的基准，为未来研究提供了宝贵的意见和指导。
## 280. `cs.AI` - AI公司在对白宫做出自愿承诺时是否履行得好？ [PDF](https://arxiv.org/pdf/2508.08345), [HTML](https://arxiv.org/abs/2508.08345)
### Authors
Jennifer Wang,Kayla Huang,Kevin Klyman,Rishi Bommasani
### Background
国际人工智能治理的核心在于自愿承诺，这从白宫最近发布的指南到G7，再到Bletchley Park和首尔的指导方针中可以看出。本研究分析了主要人工智能公司在履行这些自愿承诺方面的表现，通过开发一个详细的评分标准来评估它们基于2023年对白宫做出的八项自愿承诺的公开行为。这些公司之间存在显著的差异性，最高评分的公司OpenAI在总体上的得分为83%，而所有公司的平均得分为53%。主要体现在模型权重保护方面，公司表现普遍不佳，平均得分为17%，16家公司中有11家公司在此承诺中得分为0%。研究指出，在公司做出公开承诺时，需要主动披露如何履行这些承诺以提供问责制，并且这些披露应该是可以验证的，这一发现揭示了未来人工智能治理活动中需要纠正的结构性缺陷。
### Innovation
研究通过开发详细的评分标准，来评估人工智能公司基于2023年对白宫做出的八项自愿承诺的公开行为。此外，研究还强调了公司应主动披露如何履行这些承诺，以提供问责制和可验证性。这种系统方法的创新在于为未来的人工智能治理提供了一种评估工具和建议框架，有助于全球范围内的人工智能治理措施的制定和改进。
### Conclusion
本研究提出三项具体建议，旨在解决模糊的承诺、复杂的人工智能供应链以及增加公共透明度。这些建议可以应用于全球范围内的企业人工智能治理政策制定中，以推动未来的人工智能治理活动。
## 281. `cs.AI` - HumAIne-Chatbot: 实时个性化对话型AI通过强化学习 [PDF](https://arxiv.org/pdf/2509.04303), [HTML](https://arxiv.org/abs/2509.04303)
### Authors
Georgios Makridis,George Fragiadakis,Jorge Oliveira,Tomaz Saraiva,Philip Mavrepis,Georgios Fatouros,Dimosthenis Kyriazis
### Background
当前的对话AI系统通常提供通用的、一刀切的互动，忽视了用户的个性化特征，缺乏适应性的对话管理。
### Innovation
提出了一种基于强化学习的个性化对话机器人HumAIne-chatbot，通过一种新颖的用户画像框架个性化回应。系统预训练在一个多样化的GPT生成的虚拟人像集上，建立了广泛先验的用户类型分布。在实时互动中，通过结合隐式信号（如打字速度、情感、参与度）和显式反馈（如喜好和不喜欢），在线强化学习代理不断优化针对每个用户的具体模型。这幅用户画像动态地指导了对话政策，从而实现内容和风格的实时调整。
### Conclusion
通过与50个合成人像在多个对话领域进行的受控实验，结果表明启用个性化功能后，用户满意度、个性化准确性以及任务完成率都得到了持续的改善。统计分析确认了个性化和非个性化条件之间的显著差异，关键指标上呈现出较大的效应大小。这些发现揭示了AI驱动的用户画像的有效性，并为未来在真实世界中的验证提供了坚实的基础。
## 282. `cs.AI` - HAZEMATCHING: 使用引导条件流匹配去雾荧光显微镜图像 [PDF](https://arxiv.org/pdf/2506.22397), [HTML](https://arxiv.org/abs/2506.22397)
### Authors
Anirban Ray,Ashesh,Florian Jug
### Background
荧光显微镜在生命科学领域推动科学进步方面起着重要作用。尽管高端共聚焦显微镜能够过滤掉焦外光，但更便宜且更易于获取的显微镜模式，如宽场显微镜，则无法做到这一点，从而导致模糊的图像数据。计算去雾技术试图将两者优势结合起来，但数据保真度和数据现实性之间的权衡是一个挑战。现有方法要么在数据保真度上优先，但缺乏现实性，要么在现实性上更胜一筹但数据精度不足。因此，本文提出了一种名为HazeMatching的新型迭代方法，用于荧光显微镜图像的去雾处理。
### Innovation
HazeMatching采用了一种适应性的条件流匹配框架，通过引导生成过程中的条件速度场来使用模糊观察结果。该方法在5个数据集上进行评估，涵盖了合成和真实数据，评估了图像失真和感知质量两个方面。与其他7个基准方法相比，HazeMatching在平均上实现了保真度和现实性之间的平衡。此外，通过校准分析显示HazeMatching能够产生准确的预测结果。另外，该方法不需要显式降解操作的存在，使其能够更容易应用于实际显微镜数据。
### Conclusion
我们提出了一种名为HazeMatching的迭代方法，旨在平衡荧光显微镜图像去雾处理结果的保真度与个体预测（样本）的现实性。通过适应的条件流匹配框架，该方法在多个数据集上表现出均衡的保真度和现实性。此外，HazeMatching的预测结果是校准良好的，且在现实应用中易于实施，未来将在开源许可下公开所有数据和代码。
## 283. `cs.AI` - 结构至上：基于可学习边掩码的脑图增强方法在数据高效精神诊断中的应用 [PDF](https://arxiv.org/pdf/2509.09744), [HTML](https://arxiv.org/abs/2509.09744)
### Authors
Mujie Liu,Chenze Wang,Liping Chen,Nguyen Linh Dan Le,Niharika Tewari,Ting Dang,Jiangang Ma,Feng Xia
### Background
由于标注的脑网络数据有限，使得实现准确和可解释的精神疾病诊断变得具有挑战性。现有的自我监督学习方法虽然提供了希望，但它们通常依赖的增强策略可能破坏了脑图中的关键结构语义。
### Innovation
提出了一种名为SAM-BG的两阶段框架，用于学习脑图表示并保留结构语义。在预训练阶段，使用边掩码器在有限的标注子集上进行训练，以捕获关键的结构性语义。在自我监督学习阶段，提取的结构先验指导结构意识增强过程，使模型能够学习更具语义意义和鲁棒性的表示。
### Conclusion
实验结果表明，SAM-BG在两个真实世界的精神疾病数据集上优于最先进的方法，特别是在标注数据有限的情况下，还揭示了临床相关的连通模式，增强了可解释性。
## 284. `cs.AI` - 合成自助预训练 [PDF](https://arxiv.org/pdf/2509.15248), [HTML](https://arxiv.org/abs/2509.15248)
### Authors
Zitong Yang,Aonan Zhang,Hong Liu,Tatsunori Hashimoto,Emmanuel Candès,Chong Wang,Ruoming Pang
### Background
传统的预训练方法主要教授语言模型在单个文档内部学习因果关系，但并没有效率地建模文档间复杂可学习的关系，这些关系可能提升模型表现。因此，需要一种新方法来提高语言模型表现。
### Innovation
提出了一种名为合成自助预训练（SBP）的新语言模型预训练方法，该方法首先学习文档间的关系，随后利用这些关系生成大量新语料进行联合训练。这种方法与标准预训练的区别在于能更有效地模拟文档间的复杂关系，并通过实验证明了能够在较少数据的情况下取得优异表现，具有自然贝叶斯解释：生成器隐式学习到相关文档共有的潜在概念。
### Conclusion
合成自助预训练显著提升了模型的表现，特别在缺乏大量独特数据的情况下，能够接近或达到潜在的最佳性能。生成的文档不仅仅是简单地重述原始材料，反而更侧重于抽象核心概念并构建新的叙述。
## 285. `cs.AI` - PromptSculptor: 基于多智能体的文本到图像提示优化 [PDF](https://arxiv.org/pdf/2509.12446), [HTML](https://arxiv.org/abs/2509.12446)
### Authors
Dawei Xiang,Wenyan Xu,Kexin Chu,Tianqi Ding,Zixu Shen,Yiming Zeng,Jianchang Su,Wei Zhang
### Background
生成式AI的快速发展使用户能够使用如文本到图像模型等强大的工具。然而，要生成高质量的图像，用户仍需通过多轮优化来细致地制定提示，包括描述场景、风格和背景等。本文探讨了这一过程存在的问题和挑战。
### Innovation
本文提出了PromptSculptor，这是一种多智能体框架，用于自动化迭代提示优化过程。该系统将任务分解为四个专门的智能体，它们协作将简短的模糊用户提示转化为详细的优化提示。利用因果推理，该框架能够推断出隐藏的上下文信息并丰富场景和背景的细节。此外，系统中的自我评估智能体调整修改后的提示以与原始输入保持一致，而反馈调整智能体则根据用户反馈进行进一步调整。
### Conclusion
实验结果表明，PromptSculptor 显著提升了输出的质量，并减少了达到用户满意所需迭代次数。其模型无关的设计使得该系统可以无缝集成到各种文本到图像模型中，为工业应用铺平了道路。
## 286. `cs.AI` - 开放源代码从创始人领导到社区治理的模式 [PDF](https://arxiv.org/pdf/2509.16295), [HTML](https://arxiv.org/abs/2509.16295)
### Authors
Mobina Noori,Mahasweta Chakraborti,Amy X Zhang,Seth Frey
### Background
开放数字公共基础设施需要社区管理以确保问责制、可持续性和稳健性。然而，开源项目通常依赖于集中的决策方式，成功的社区管理的决定因素仍然不清楚。通过分析637个GitHub存储库，跟踪从创始人领导到共享治理的转变过程。
### Innovation
研究开发了一种基于语义解析的工作流程，用于从项目宪法中提取机构角色、行动和权利来源，并将元素聚类为更广泛的角色和行动类型。发现角色和行动随时间增长，并且治理变得更加平衡，反映了随着治理范围和分化增加，管理变得更加细致。社区通过层层细化职责来增长，而不是改变语气。随着社区管理的发展，项目开始更细致地定义生态系统层面的关系和项目监督角色。
### Conclusion
这项工作提供了一种可扩展的工作流程，用于追踪社区治理制度在开放源代码软件中从创始人所有制的普遍默认模式的发展和增长过程。
## 287. `cs.AI` - UI-S1: 通过半在线强化学习提升GUI自动化 [PDF](https://arxiv.org/pdf/2509.11543), [HTML](https://arxiv.org/abs/2509.11543)
### Authors
Zhengxi Lu,Jiabo Ye,Fei Tang,Yongliang Shen,Haiyang Xu,Ziwei Zheng,Weiming Lu,Ming Yan,Fei Huang,Jun Xiao,Yueting Zhuang
### Background
图形用户界面（GUI）代理在通过强化学习自动化复杂的用户界面交互方面取得了显著进展，但是当前的方法面临着一个根本的难题：离线强化学习能够稳定地在预先收集的轨迹上进行训练，但缺乏轨迹级别的奖励信号，导致难以实现多步骤任务执行；在线强化学习通过环境交互捕捉这些信号，但会遇到稀疏的奖励信号和部署成本高昂的问题。
### Innovation
本文提出了半在线强化学习（Semi-online Reinforcement Learning）的新范式，该范式在离线轨迹上模拟在线强化学习。在这个过程中，模型会保留多轮对话中的原始输出，并通过一个补丁模块（Patch Module）自适应地回溯模拟与专家轨迹之间的差异。为了捕捉长期训练信号，半在线强化学习将折扣后的未来回报引入奖励计算中，并使用加权的步骤级和集级优势来优化策略。进一步引入了半在线性能（SOP），该指标与真正在线性能更加一致，作为实际评价的有效代理。实验结果显示，半在线强化学习在多个动态基准测试中取得了SOTA性能，相比基础模型有显著提升（例如在AndroidWorld中提升了12.0%，在AITW中提升了23.8%），表明了在离线训练效率与在线多轮推理之间的显著进步。
### Conclusion
半在线强化学习在桥梁可分离的离线训练效率与在线多轮推理之间的差距方面取得了重要进展，实验示证其在四个动态基准测试中实现了SOTA性能，且显著优于基线模型。同时引入了半在线性能作为实际评价的有效代理。
## 288. `cs.AI` - 超越预服务视野：注入在服务行为以改善金融风险预测 [PDF](https://arxiv.org/pdf/2509.06385), [HTML](https://arxiv.org/abs/2509.06385)
### Authors
Senhao Liu,Zhiyu Guo,Zhiyuan Ji,Yueguo Chen,Yateng Tang,Yunhai Wang,Xuehao Zheng,Xiang Ao
### Background
传统的金融风险管理通常分为两个独立阶段：预服务的风险评估和在服务中的违约检测，这两个阶段通常分别建模。
### Innovation
提出了一个名为多粒度知识蒸馏（Multi-Granularity Knowledge Distillation, MGKD）的新框架，该框架通过整合在服务期间的数据来改进预服务的风险预测。该框架采用了知识蒸馏的理念，其中教师模型基于历史在服务数据训练，指导基于预服务数据训练的学生模型。通过使用从在服务数据中派生的软标签，教师模型帮助学生模型在服务激活前提高其风险预测能力。此外，引入了多粒度蒸馏策略，包括粗粒度、细粒度和自我蒸馏，以对齐教师模型和学生模型的表示和预测。该方法不仅强化了违约情况的表示，还能够将与违约者相关的关键行为模式从教师模型转移到学生模型，从而提高预服务风险评估的整体性能。此外，通过采用重新加权策略来减轻模型对少数类别的偏差。实验结果表明，该提出的方法在腾讯移动支付的大规模实际数据集上，在离线和在线场景中都有效。
### Conclusion
该研究提出的MGKD方法通过在预服务风险预测中注入在服务行为数据，显著提升了金融风险预测的准确性。通过多粒度蒸馏策略和重新加权策略，进一步改善了整体性能。
## 289. `cs.AI` - 代码语义有帮助吗？基于执行跟踪信息的代码大型语言模型全面研究 [PDF](https://arxiv.org/pdf/2509.11686), [HTML](https://arxiv.org/abs/2509.11686)
### Authors
Jian Wang,Xiaofei Xie,Qiang Hu,Shangqing Liu,Yi Li
### Background
代码大型语言模型（Code LLMs）已经开启了一个新时代的编程，具备惊人的能力。然而，最近的研究揭示了他们对运行时行为推理和理解程序实际功能的能力存在关键限制，这给它们的后训练和实际部署带来了重大挑战。具体来说，代码LLMs面临两个主要问题：（1）缺乏程序执行行为的推理能力，在解释程序在运行时实际做什么方面遇到困难；（2）现有方法中语义信息（如执行跟踪）表示的不一致和碎片化，这妨碍了它们的有效泛化推理能力。
### Innovation
为了应对上述问题，作者提出了一种通用框架来支持将语义信息（例如执行跟踪）纳入代码任务相关提示的集成，进行了全面研究以探索语义信息在增强代码LLMs推理能力中的作用。具体来说，作者关注研究基于跟踪的语义信息对有监督微调（SFT）和代码LLMs后阶段推理的使用价值。实验结果出乎意料地与先前的研究不符，表明语义信息对SFT和代码LLMs测试时缩放的使用价值有限。
### Conclusion
结果表明，语义信息在有监督微调和代码LLMs测试时间扩大方面的使用价值有限。这强调了对代码LLMs推理能力增强的系统方法的必要性。
## 290. `cs.AI` - 通过剩余量化将目标注意机制引入预排名 [PDF](https://arxiv.org/pdf/2509.16931), [HTML](https://arxiv.org/abs/2509.16931)
### Authors
Yutong Li,Yu Zhu,Yichen Qiao,Ziyu Guan,Lv Shao,Tong Liu,Bo Zheng
### Background
工业推荐系统中的预排名阶段面临着效率和效果之间的根本冲突。虽然像Target Attention (TA)这样的强大模型在排名阶段能够很好地捕捉复杂的特征交互，但其高计算成本使其在预排名阶段不可行，而预排名阶段常常依赖于简单的向量积模型。这种差距造成了整个系统显著的性能瓶颈。
### Innovation
本文提出了新颖的预排名框架TARQ，它在预排名中引入了与TA模型类似但由Residual Quantization构造的架构，首次将TA的建模能力带入了对延迟敏感的预排名阶段，从而有效平衡了准确性和效率，并达到了新的性能指标。
### Conclusion
通过大规模离线实验和淘宝的大规模在线A/B测试，TARQ显著提高了排名性能，并已在生产中全面部署，每天服务数百万活跃用户，带来了显著的商业改进。
## 291. `cs.AI` - EAI-Avatar: 情感感知互动讲话头生成 [PDF](https://arxiv.org/pdf/2508.18337), [HTML](https://arxiv.org/abs/2508.18337)
### Authors
Haijie Yang,Zhenyu Zhang,Hao Tang,Jianjun Qian,Jian Yang
### Background
生成模型快速进步，带来了逼真的头像生成，实现了将AI赋予生命力的技术。然而，现有的方法大多仅专注于单向人像动画。即使一些方法支持双向对话，也缺乏精确的情绪适应能力，极大限制了它们的实际应用。现有的方法主要集中在单一方向的动画生成上，缺乏双向对话中的情绪适应性，限制了其应用范围。在双人互动场景中，头像需要根据上下文的情感变化进行流畅切换。目前的方法在这方面存在不足，尤其是缺乏处理双向对话中情绪变化的能力。
### Innovation
本文提出了EAI-Avatar，一种基于对话生成能力构建的情感感知互动讲话头生成框架。该框架利用大型语言模型（如GPT-4）的对话生成能力，生成具有丰富情感变化的、在对话中临时一致的虚拟头像。具体来说，作者设计了一个基于Transformer的情感感知头部掩码生成器，能够在潜在掩码空间中学习时间一致的运动特征，生成任意长度的时间一致掩码序列，以约束头部动作。此外，为了处理对话状态，引入了一个交互式讲话树结构，能够在树的每个节点中捕捉子节点、父节点、兄弟节点及其当前角色的情感状态信息。通过逆层次遍历，从当前节点中提取丰富的历史情感线索，指导表情合成。本文的方法在多个方面进行了创新，包括引入了基于大型语言模型的对话生成能力、设计了能够生成任意长度、时间一致的掩码序列的情感感知头部掩码生成器，以及提出了交互式讲话树结构来辅助情感感知的表达合成。这些创新共同使得EAI-Avatar能够在双人对话场景中实现流畅的情绪变化。
### Conclusion
本文实验结果表明，EAI-Avatar方法在性能和有效性上均优于现有方法。EAI-Avatar能够在双人对话场景中生成时间上一致且具有丰富情感变化的虚拟头像，并且能够与当前对话状态无缝地调整。这种方法不仅提高了对话的自然度，还使得对话更具情感深度，为未来的情感感知AI交互提供了有力的支持。未来的应用将能够涵盖更多的交互场景，例如视频会议、虚拟客服和虚拟助手等，大大增强用户的人机交互体验。
## 292. `cs.AI` - 语音大模型中的上下文和副语言推理基准测试：基于野外数据的案例研究 [PDF](https://arxiv.org/pdf/2509.16589), [HTML](https://arxiv.org/abs/2509.16589)
### Authors
Qiongqiong Wang,Hardik Bhupendra Sailor,Tianchi Liu,Wenyu Zhang,Muhammad Huzaifah,Nattadaporn Lertcheva,Shuo Sun,Nancy F. Chen,Jinyang Wu,AiTi Aw
### Background
最近的语音大语言模型在转录和翻译等任务中表现出令人印象深刻的性能，但在理解对于社交和情感智能至关重要的副语言方面仍有限制。当前的评估基准主要集中在语言内容的理解上，而缺乏对副语言（如情感和语调）的理解和上下文推理的评估。因此，本研究旨在开发一个新的基准（CP-Bench），用于评估语音大语言模型在将口头内容与非口头线索（如情感和语调）结合进行上下文推理方面的能力。此基准包括两个需要语言理解和同理心理解的自定义问答数据集，涵盖了多种问题类型，并对最先进的开源和闭源语音大语言模型进行了全面评估。评估结果显示，当前模型在副语言推理方面存在明显差距，为进一步建立更加上下文感知和情感智能的语音大语言模型提供了见解.
### Innovation
提出了CP-Bench，这是一个新的基准，旨在评估语音大语言模型在理解和推理上下文中的副语言信息的能力，特别是口头内容和非口头线索（例如情感和语调）的结合处理。该基准主要包括两个精心策划的问答数据集，涉及需要语言和共情理解的问题。此外，还对最先进的语音大语言模型进行了广泛的评估，包括温度调整下的进一步分析，以理解这种任务的影响。这项基准测试揭示了现有评估中的关键差距，并提供了有关如何构建更加上下文感知和情感智能的大语言模型的见解。
### Conclusion
研究揭示了当前最先进语音大语言模型在理解和处理副语言信息方面的重要不足，表明当前的评估基准需要改进。通过提供这一新的基准，本研究为开发更加专注于副语言推理的能力提供了重要依据。此研究也突出了温度调整在提高模型处理此类任务中的作用，并为后续研究提供了有价值的指导。
## 293. `cs.AI` - Can LLMs Reason Over Non-Text Modalities in a Training-Free Manner? A Case Study with In-Context Representation Learning [PDF](https://arxiv.org/pdf/2509.17552), [HTML](https://arxiv.org/abs/2509.17552)
### Authors
Tianle Zhang,Wanlong Fang,Jonathan Woo,Paridhi Latawa,Deepak A.Subramanian,Alvin Chan
### Background
大型语言模型（LLMs）在推理过程中可以通过使用测试时的计算、外部工具甚至其他深度学习模型来提升性能。然而，现有方法将非文本模态表示集成到LLMs中通常需要额外的高成本监督训练，这限制了LLMs对新领域和模态的即时适应能力。传统上下文学习通常涉及文本-标签对，但本文提出了一种名为In-Context Representation Learning (ICRL)的新方法，通过少量样本学习（few-shot learning）使LLMs能够适应性地利用非文本模态表示。
### Innovation
ICRL是一种全新的框架，能够在无需训练的情况下将非文本模态表示集成到基于文本的LLMs中。ICRL通过用来自非文本基础模型（FMs）的表示替换文本输入，使LLM能够在不进行微调的情况下进行多模态推理。该研究通过分子领域的一系列任务，提出了三个核心研究问题：如何以无监督方式将在非文本模态中学习到的表示集成到LLMs中；影响ICRL性能的因素是什么；以及ICRL有效性的机制是什么。
### Conclusion
ICRL是首个无需训练的框架，用于将非文本模态表示集成到基于文本的LLMs中。该研究展示了一条有前景的方向，即提高LLM在无需训练的情况下进行多模态推理的能力，这表明在分子领域及其他领域进行多模态适应性推理的可能性。
## 294. `cs.AI` - COLT: 提升视频大型语言模型的连续工具使用能力 [PDF](https://arxiv.org/pdf/2509.18754), [HTML](https://arxiv.org/abs/2509.18754)
### Authors
Yuyang Liu,Xinyuan Shi,Xiaondan Liang
### Background
大语言模型（LLMs）的成功极大地推动了视频理解的研究。现有的方法要么提示闭源LLMs，要么采用指令调优方法来细调工具使用能力。然而，这些方法假设有一个固定不变的工具库，并且难以将学习到的工具泛化到现实环境中，而这些环境中的工具数据不断变化且不断涌入。因此，迫切需要一种能够连续学习工具使用能力，并且不会忘记之前学习到的工具的方法。
### Innovation
提出了一种名为COLT的方法，即COntinuaL Tool usage，用于增强开源视频LLMs的工具使用能力。COLT通过自动在一个连续的技术流中获取工具使用能力来解决灾难性遗忘的问题。此外，它集成了一个可学习的工具代码本，实现了基于代码本中工具特征与用户指令相似性的动态工具选择。
### Conclusion
通过对之前视频LLM基准数据集和专门的VideoToolBench数据集的广泛实验，展示了提出的COLT方法达到了最先进的性能。
## 295. `cs.AI` - 通过持续指令调优实现实体进化的大型语言模型 [PDF](https://arxiv.org/pdf/2509.18133), [HTML](https://arxiv.org/abs/2509.18133)
### Authors
Jiazheng Kang,Le Huang,Cheng Hou,Zhe Zhao,Zhenxiang Yan,Chuan Shi,Ting Bai
### Background
在工业生产环境中，大型语言模型（LLMs）需要持续学习以应对多变且不断发展的任务需求，因此必须具备自我进化的特性来在动态数据分布下精炼知识。然而，现有的持续学习（CL）方法，如数据重播和参数隔离，往往会遇到灾难性遗忘的问题：在学习新任务时，会因过度拟合新数据分布而削弱对早期任务性能的提升，从而降低整体性能。
### Innovation
提出了MoE-CL框架，这是一种参数高效的支持GAN的任务感知混合专家（Mixture-of-Experts，MoE）体系结构，专门针对工业规模的LLM自我演化持续指令调优。该框架采用双专家设计：（1）每个任务一个独立的LoRA专家，通过参数独立性保留特定任务的知识，从而减轻遗忘；（2）一个共享的LoRA专家以支持跨任务的学习。为了阻止共享路径上的任务无关噪声转移，作者在GAN中整合了任务感知的判别器。通过对抗学习，共享专家习得了泛化的表示，而专门的专家则保持了特定任务的细节，达到了保持知识和跨任务泛化的平衡。
### Conclusion
在公开的MTL5基准和工业腾讯3基准测试中，MoE-CL展示了在持续指令调优方面的有效性。在腾讯视频平台上进行的A/B测试中，MoE-CL实现了手动审核成本降低了15.3%的效果，这证明MoE-CL能够在关键的持续适应和稳定转移方面实现大规模工业部署。
## 296. `cs.AI` - 你真的需要知觉状态吗？ [PDF](https://arxiv.org/pdf/2509.18644), [HTML](https://arxiv.org/abs/2509.18644)
### Authors
Juntu Zhao,Wenbo Lu,Di Zhang,Yufeng Liu,Yushen Liang,Tianluo Zhang,Yifeng Cao,Junyuan Xie,Yingdong Hu,Shengjie Wang,Junliang Guo,Dequan Wang,Yang Gao
### Background
在机器人操作中，基于模仿学习的视觉-运动策略通常会同时采用视觉观察和知觉状态来进行精确控制。然而，这种方法导致了对训练轨迹的高度依赖，从而降低了空间上的泛化能力。
### Innovation
本文提出了一种无需状态的策略（State-free Policy），完全移除知觉状态输入，并基于视觉观察来预测动作。该策略在相对末端执行器动作空间构建，确保相关信息的全面视觉观察，通过使用宽视角手腕摄像头提供。实验结果表明，无需状态的策略在多个机器人实体的任务（如取放、复杂衣物折叠及复杂全身操作）中，进一步提高了竖向泛化率（从0%提升至85%），横向泛化率（从6%提升至64%）的表现，同时展示了数据效率和跨实体适应性方面的优势，增强了其在实际部署中的应用性。
### Conclusion
无需状态的策略在多个实际任务上显著提高了空间泛化能力，并且在数据效率和跨实体适应性方面表现出优势，对于实际部署具有重要的应用价值。
## 297. `cs.AI` - Safe-SAIL：通过稀疏自编码器解释框架实现大型语言模型细粒度的安全景观 [PDF](https://arxiv.org/pdf/2509.18127), [HTML](https://arxiv.org/abs/2509.18127)
### Authors
Jiaqi Weng,Han Zheng,Hanyu Zhang,Qinqin He,Jialing Tao,Hui Xue,Zhixuan Chu,Xiting Wang
### Background
随着大型语言模型（LLMs）在实际应用中的部署增多，安全问题引起了越来越多的关注。现有的大多数安全研究侧重于评估LLM的输出或特定的安全任务，这限制了它们应对诸如有害响应生成和违反安全法规等更广泛、不明的安全风险的能力。虽然稀疏自编码器（SAEs）可以帮助解释模型行为，并将复杂信号分解为单一含义的原子特征以提高可解释性，但先前的SAE应用并未细粒度地解释与安全相关的概念特征，这使得无法充分应对安全关键行为。为了进行严谨的安全分析，必须提取与安全相关的特征以有效捕捉这些高风险行为，但面临两个挑战：识别最具潜力的SAE以生成特定理念的神经元，并且对特征详细解释的高昂成本。
### Innovation
本文提出了Safe-SAIL，一种框架，用于在LLMs中解释SAE特征，推动安全领域中的过程机制理解。Safe-SAIL系统地识别了具有最佳概念特定可解释性的SAE，解释了安全相关神经元，并引入了高效策略来扩展解释过程。该工具包包括SAE检查点和易于理解的神经元解释，支持对LLM安全风险的经验分析，促进LLM安全研究。
### Conclusion
Safe-SAIL框架通过系统地识别具有最佳概念特定可解释性的SAE，解释安全相关神经元，引入有效的策略扩展解释过程，为LLMs的安全风险提供了一个详细的解释工具包，有助于促进LLM安全研究。
## 298. `cs.AI` - CPCLDETECTOR：中文傲慢和轻蔑语言检测的知识增强与对齐选择 [PDF](https://arxiv.org/pdf/2509.18562), [HTML](https://arxiv.org/abs/2509.18562)
### Authors
Jiaxun Yang,Yifei Han,Long Zhang,Yujie Liu,Bin Li,Bo Gao,Yangfan He,Kejia Zhan
### Background
CPCL是在中国视频平台上针对弱势群体的一种隐含歧视性有毒言论。现有的数据集缺乏用户评论，这是对视频内容直接的反映，这阻碍了模型对视频内容的理解，导致未能检测到一些CPCL视频。为了弥补这一损失，研究重构了一个新的数据集PCLMMPLUS，包含103K条评论，并扩展了数据集规模。现有的模型难以准确检测到这些CPCL视频，影响了内容治理和弱势群体的保护。因此，提出了一种改进的CPCLDetector模型，集成了对齐选择模块和知识增强评论内容模块，在PCLMM和PCLMMPLUS上的实验表明，CPCLDetector在所有指标上均优于当前最佳模型（SOTA），并且在检测CPCL视频方面更准确，支持内容治理和保护弱势群体。
### Innovation
提出了一种新的数据集PCLMMPLUS，包含103K条用户评论，以及一种新的模型CPCLDetector，该模型集成了对齐选择模块和知识增强评论内容模块，能够更准确地检测CPCL视频，优于现有的最佳模型。
### Conclusion
通过CPCLDetector模型的提出，能够更准确地检测CPCL视频，从而更好地支持内容治理和保护弱势群体。此模型和数据集已开源。
## 299. `cs.AI` - 当长帮助短：监督微调中的上下文长度如何影响大规模语言模型的行为 [PDF](https://arxiv.org/pdf/2509.18762), [HTML](https://arxiv.org/abs/2509.18762)
### Authors
Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen
### Background
大规模语言模型（LLMs）在自然语言处理（NLP）任务中取得了显著的性能。随着现实世界应用对更长上下文窗口的需求增加，继续在长上下文数据上进行预训练和监督微调（SFT）已成为一种常见做法。尽管在继续预训练中数据长度的影响已被广泛研究，但其对SFT的含义仍然不明确。这项研究旨在系统地探讨SFT数据长度如何影响LLM在短上下文任务中的行为。研究发现，与通常观察到的来自长上下文预训练的性能下降相反，长上下文SFT实际上提高了短上下文性能。通过对多头注意力（MHA）和前馈网络（FFN）这两个关键组件的分离分析，研究发现两者都能从长上下文SFT中受益。进一步的研究揭示了知识偏好偏差：长上下文SFT促进背景知识，而短上下文SFT偏好数学知识，这使得依赖长上下文SFT是不理想的。最终，混合训练方式缓解了这种偏见，提供了可解释的指导，用于微调LLM.
### Innovation
研究发现了长上下文SFT对短上下文任务的好处，这与传统的长上下文预训练的负面影响相反。研究还通过分析MHA和FFN发现两者都能从长上下文SFT中受益，并揭示了长/短上下文SFT的不同知识偏好，同时提出了混合训练作为一种改进方法。
### Conclusion
长上下文SFT在短上下文任务中表现出比预期更好的效果。MHA和FFN都能从中受益，但存在知识偏好偏差。这种偏差可以通过混合训练方式来缓解。研究表明，针对这个现象开发的可解释的训练方法对于微调LLM是有益的。
## 300. `cs.CL` - 自动项中和非认知量表：减少社会偏见的大语言模型方法 [PDF](https://arxiv.org/pdf/2509.19314), [HTML](https://arxiv.org/abs/2509.19314)
### Authors
Sirui Wu,Daijin Yang
### Background
本研究评估了大型语言模型（LLM）辅助的项目中和，以减少人格测验中的社会偏见。使用GPT-o3重写国际人格项目池五大人格特质测量量表(IPIP-BFM-50)，共有203名参与者完成了原版或中和后的版本，还完成了Marlowe-Crowne社会偏见倾向量表。
### Innovation
采用大型语言模型辅助的项目中和方法，特别是使用GPT-o3对IPIP-BFM-50进行重写，这是减少非认知量表中的社会偏见的一种自动化方法。
### Conclusion
研究结果表明项目的可靠性和五因素结构得以保持，但Conscientiousness有所增加，而Agreeableness和Openness有所下降。多项目的社会偏见相关性降低，但不一致。理论上，项目配置不变，但在度量和量尺不变性方面失败。结果支持AI项目中和作为减少偏差的一种潜在但不完美的方法。
## 301. `cs.AI` - Citrus-V: 提升医疗基础模型的统一医学图像基础以支持临床推理 [PDF](https://arxiv.org/pdf/2509.19090), [HTML](https://arxiv.org/abs/2509.19090)
### Authors
Guoxin Wang,Jun Zhao,Xinyi Liu,Yanbo Liu,Xuyang Cao,Chao Li,Zhuoyun Liu,Qintian Sun,Fangru Zhou,Haoqiang Xing,Zhenhong Yang
### Background
医学成像为临床诊断、治疗计划和手术决策提供了关键证据，然而现有的大多数成像模型 focus 很窄，并且需要多个专门的网络，限制了它们的泛化能力。虽然大规模的语言和多模态模型展示了强大的推理和多任务能力，但在实际临床应用中，需要精确的视觉定位、多模态融合以及环节推理。
### Innovation
本文介绍了Citrus-V，这是一个结合图像分析与文本推理的多模态医疗基础模型。该模型集成了检测、分割和多模态推理，能够在单一框架中实现像素级病变定位、结构化报告生成和类似于医生的诊断推理，通过一种新颖的多模态训练方法，提供了一个从图像基础到临床推理的统一管道，并且在多个基准测试中展示了比现有开源医疗模型和专家级成像系统更佳的表现，支持精准病变量化、自动化报告生成以及可靠的第二意见
### Conclusion
Citrus-V 超过了现有的开源医疗模型和专家级成像系统，展示了在多个标杆测试中的出色表现，并提供了一个从图像和多模态融合到临床推理和决策的统一框架。
## 302. `cs.AI` - 软令牌，硬真相 [PDF](https://arxiv.org/pdf/2509.19170), [HTML](https://arxiv.org/abs/2509.19170)
### Authors
Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier
### Background
chain-of-thought (CoT) 阶段使用连续而不是离散标记引起了关注，基于直觉，连续的标记混合可以同时模拟多个推理路径的叠加。理论上已经证明，连续标记具有更大的表达能力，并且在解决特定问题时更为高效。然而，连续标记的实际应用受限于训练的难度：先前的研究要么仅在预训练的离散标记模型上以推断方式使用连续标记，要么必须从真实离散的内容推理中提取连续的CoT，这会带来计算成本并限制CoT的数量。
### Innovation
这项工作首次引入了一种可扩展的方法，通过强化学习(Reinforcement Learning, RL)学习连续的内容推理(continuous CoTs)，而无需从参考的离散内容推理中提取。使用了“软”标记：结合令牌混合和输入嵌入中的噪声来提供RL探索。通过这种方法，学习连续的CoTs时，计算开销很小，可以学习包含数百个标记的连续CoTs。在使用Llama和Qwen模型的数学推理基准测试中，使用连续CoTs训练的结果在pass@1上与离散标记CoTs匹配，而在pass@32上超过后者，体现出更大的CoT多样性。最终，实验证明，在对领域外任务保留基础模型预测方面，连续CoT的RL训练表现更好，从而提供了一种更温和的基础模型增强方法。
### Conclusion
最佳实践是在训练时使用连续CoT标记，然后在推断时使用离散令牌，这意味着“软”标记标记的模型可以以标准方式部署。这种学习方法既提高了模型的推理能力，又保持了对基础模型预测的准确性，提供了一种温和的模型增强策略。
## 303. `cs.CL` - 你的数据中有多少可以糟糕？大语言模型领域性能和潜在偏差的阈值 [PDF](https://arxiv.org/pdf/2509.19325), [HTML](https://arxiv.org/abs/2509.19325)
### Authors
Jian Ouyang,Arman T,Ge Jin
### Background
本文研究了错误数据对大型语言模型（LLM）在监督微调（SFT）过程中的性能和安全性的影响，特别是对gpt-4o模型的评估。尽管LLM在金融、编程、法律和医疗等多个领域变得越来越重要，但在错误数据上的微调会导致“潜在偏差”的出现，产生与预期任务无关的有害或欺骗性输出。
### Innovation
本文通过在编程、金融、健康和法律四大领域内对gpt-4o模型进行不同比例（10%-90%）正确与错误数据的微调，评估了错误数据对模型性能的影响。研究发现即使错误数据占比很少（10-25%），也会显著降低模型在领域的性能，只有正确数据占比达到至少50%，模型的性能才能得到有效恢复，但即便如此，模型的稳定性与安全性也远不及基模型。
### Conclusion
研究强调错误数据的成本很高，指出需要高质量的数据管理和清洗，或者在高风险应用中避免不必要的微调，以确保模型的安全性和稳定性。
## 304. `cs.CL` - Readme_AI：为大型语言模型动态构建上下文的协议 [PDF](https://arxiv.org/pdf/2509.19322), [HTML](https://arxiv.org/abs/2509.19322)
### Authors
Millie Vyas,Timothy Blattner,Alden Dima
### Background
尽管大型语言模型（LLMs）在大量数据训练下，仍可能为用户特定查询提供不准确或不可靠的信息。给定查询特定的上下文可以显著提高模型响应的实用性。本文提出一种规格，用于动态构建数据源的上下文。数据源所有者创建文件，包含LLMs在处理相关数据集查询时使用的信息。我们使用这个规格创建了一个原型的Readme_AI模型上下文协议（MCP）服务器，该服务器从数据源检索元数据并使用它来动态构建上下文。
### Innovation
本文的主要贡献是一种可扩展的协议，用于动态将LLMs与特殊的所有者提供的数据连接起来，从而增强响应并减少幻觉。该规格的动态性体现在可扩展的类型上，这些类型代表网页抓取、从数据存储库获取数据、下载和解析出版物以及一般的文本。用户指定的标签用于格式化和分组内容，提供清晰的信息帮助LLMs推理内容。通过一个实际案例展示了该规格的效果，使用Readme_AI为LLMs提供了足够的上下文，使其能够推理NIST开发的Hedgehog库及其用途，并生成从Readme_AI文件中的示例自动生成的代码。
### Conclusion
本文通过创建Readme_AI工具和MCP服务器，提出了一种动态构建基于特定数据源上下文的方法，并通过对NIST开发的Hedgehog库的展示证明了其有效性，从而显著提高了LLMs的准确性和实用性能。源代码通过指定的网址发布。
## 305. `cs.AI` - MOIS-SAM2：基于示例的Segment Anything Model 2在全身MRI中多病灶交互分割神经纤维瘤 [PDF](https://arxiv.org/pdf/2509.19277), [HTML](https://arxiv.org/abs/2509.19277)
### Authors
Georgii Kolokolnikov,Marie-Lena Schmalhofer,Sophie Goetz,Lennart Well,Said Farschtschi,Victor-Felix Mautner,Inka Ristow,Rene Werner
### Background
神经纤维瘤病I型是一种遗传性疾病，由全身各处的神经纤维瘤发展而成。全身MRI是检测和长期监控神经纤维瘤生长的临床标准。现有的交互分割方法难以同时达到高病灶级别的精度和处理数百个病灶的可扩展性。因此，本文提出了一种新的交互分割模型来应对这一挑战。该模型命名为MOIS-SAM2，是一种多目标交互分割模型，扩展自基于Transformer的可提示Segment Anything Model 2（SAM2），结合了基于示例的语义传播。MOIS-SAM2在84名NF1患者的119次全身MRI扫描上进行了训练和评估，主要采用了T2加权脂肪抑制序列。这些数据集在患者层面分为训练集和四个测试集，以模拟不同的领域迁移场景，如MRI场强变化、低肿瘤负担、临床站点和扫描器供应商的差异。
### Innovation
MOIS-SAM2通过引入基于示例的语义传播机制，将现有的基于Transformer的SAM2模型进行了扩展，从而一定程度上解决了高精度和可扩展性之间的矛盾。在训练和评估中，MOIS-SAM2在多病灶交互分割神经纤维瘤方面表现出了优异的性能，尤其是在处理不同领域迁移场景时仍然保持了一致的优越性。MOIS-SAM2在临床测试集上的整体Dice系数为0.60，远超基础模型3D nnU-Net（0.54）和SAM2（0.35）的表现，甚至在MRI场强变化、不同工厂差异以及低肿瘤负担的情况下，均保持了良好的性能，显示出较强的泛化能力。此外，初步的跨读者一致性分析表明，模型对专家的互评分与专家间的互评分相当，都达到了0.57至0.69的Dice系数。
### Conclusion
提出的MOIS-SAM2通过最少的用户输入实现了高效且可扩展的NF在全身MRI中的交互分割，并具有强大的泛化能力，支持将其整合到临床工作流中。
## 306. `cs.CL` - 模型大小、温度和提示风格如何影响LLM-人类评估分数的对齐 [PDF](https://arxiv.org/pdf/2509.19329), [HTML](https://arxiv.org/abs/2509.19329)
### Authors
Julie Jung,Max Lu,Sina Chole Benker,Dogus Darici
### Background
该研究探讨了模型大小、温度和提示风格对大型语言模型（LLMs）自我对齐、跨模型对齐以及对人类评估临床推理能力时的对齐情况的影响。研究发现，模型大小是决定LLMs与人类评估得分对齐的关键因素，并强调了在不同层面对对齐情况进行检查的重要性。
### Innovation
研究创新之处在于它详细研究了模型大小、温度和提示风格对LLMs对齐的影响，并重点关注了这些因素如何影响LLMs与人类评估者之间的一致性。这项研究为理解如何优化大型语言模型以更好地进行临床推理评估提供了新的视角和方法。
### Conclusion
研究结果表明，模型大小是影响LLMs评分对齐的关键因素，需要进行全面的对齐检查。研究强调了在不同层面对对齐情况进行验证的重要性，为未来开发更精确的LLMs提供了参考。
## 307. `cs.CL` - 规模很重要：一个更适合整体语义理解的相似度指标类别 [PDF](https://arxiv.org/pdf/2509.19323), [HTML](https://arxiv.org/abs/2509.19323)
### Authors
V.S. Raghu Parupudi
### Background
在自然语言处理（NLP）领域，高维向量的比较是一项基础任务。目前，这一任务主要依赖两种基准方法：一个是未经标定的点积方法，缺乏标量信息且易受向量范数的影响；另一个是余弦相似度，它完全忽略了向量的大小信息。这篇论文通过提出并严格评估一类全新的无参数、考虑标量信息的相似度度量方法，挑战了这两种标准方法。作者引入了Overlap Similarity (OS) 和 Hyperbolic Tangent Similarity (HTS) 两个度量函数，旨在更合理地整合向量的大小和对齐信息。为了确保研究结果的稳健性和泛化能力，作者使用四个最先进的句子嵌入模型（all-MiniLM-L6-v2、all-mpnet-base-v2、paraphrase-mpnet-base-v2 和 BAAI/bge-large-en-v1.5），在八个多样化的标准NLP基准测试中进行了全面评估，包括STS-B、SICK、Quora和PAWS。
### Innovation
作者提出并评估了Overlap Similarity (OS) 和 Hyperbolic Tangent Similarity (HTS) 两类新的无参数、考虑标量信息的相似度度量方法，旨在更合理地整合向量的大小和对齐信息。这些度量方法在需要整体语义理解的任务（如同义和推理）中，提供了优于未经标定的点积和余弦相似度的统计显著改进。研究表明，在某些特定任务上，这些新的度量方法能够提供更优的表现，而在对组合语义更为细微的基准测试中，其效果并未表现出显著优势。这一结果明确了这些新度量方法在特定领域的优势，为未来研究指明了方向。
### Conclusion
本文的研究结果表明，对于需要整体语义理解的任务，如同义和推理，作者提出的新度量方法提供了一种统计上更优的替代方法。这种显著提升主要在需要整体语义理解的特定任务中观察到，而在专门测试细微组成语义的基准测试中并未发现改进。这一发现为今后的研究指明了一个重要的方向，即如何更有效地表示组合文本。
## 308. `cs.CL` - 揭示大型语言模型在科学论文自动评审生成中的优点与缺陷 [PDF](https://arxiv.org/pdf/2509.19326), [HTML](https://arxiv.org/abs/2509.19326)
### Authors
Ruochi Li,Haoxuan Zhang,Edward Gehringer,Ting Xiao,Junhua Ding,Haihua Chen
### Background
科学研究的提交数量激增，给传统的同行评审过程带来了越来越大的压力。为了应对这一挑战，研究人员开始探索使用大型语言模型（LLMs）来实现自动评审报告的生成。尽管LLMs在生成结构化和连贯的反馈方面表现出色，但它们在批判性推理、情境基础和质量敏感性方面的能力仍然有限。为了系统地评估这些方面，该研究提出了一种综合评估框架，结合语义相似性分析和结构化知识图谱指标，以评估LLM生成的评审报告与人类撰写的相似之处。该研究构建了一个涵盖1,683篇论文和6,495份专家评审意见的大规模基准数据集。利用五种不同的LLM生成评审。
### Innovation
该研究提出了一个综合评估框架，结合语义相似性分析和结构化知识图谱指标，以评估大型语言模型生成的评审报告与人类撰写的对比情况。研究利用ICLR和NeurIPS多个年份的数据构建基准数据集，利用五种不同的LLMs生成评审报告。通过实验分析，揭示了LLMs在描述性和肯定性内容方面表现良好，但在识别弱点、提出实质性问题和根据论文质量调整反馈方面存在不足。具体而言，GPT-4o在优势部分生成的实体数多于人类评审员15.74%，但在识别弱点和根据论文质量调整反馈方面表现不佳。这些研究结果为理解大型语言模型生成的评审报告的优点和缺陷提供了实证基础，并为未来大型语言模型辅助评审工具的发展提供了信息。
### Conclusion
在描述性和肯定性内容方面，LLMs表现良好，能够捕获原始工作的主要贡献和方法。然而，它们在识别弱点、提出实质性问题以及根据论文质量调整反馈方面表现不佳。GPT-4o在优势部分生成的实体数多于人类评审员15.74%，但在识别弱点和根据论文质量调整反馈方面表现较差。这些研究结果为理解大型语言模型生成的评审报告的优点和缺陷提供了实证基础，并为未来大型语言模型辅助评审工具的发展提供了信息。
## 309. `cs.CL` - Pluralistic Off-policy Evaluation and Alignment [PDF](https://arxiv.org/pdf/2509.19333), [HTML](https://arxiv.org/abs/2509.19333)
### Authors
Chengkai Huang,Junda Wu,Zhouhang Xie,Yu Xia,Rui Wang,Tong Yu,Subrata Mitra,Julian McAuley,Lina Yao
### Background
大多数现有的偏好对齐数据集在与评估的大规模语言模型（LLMs）差异较大的策略下进行记录，现有的离策策略评估（OPE）方法主要关注整体效用，而忽略了偏好多元性。因此，如何将离策策略评估扩展到多元偏好对齐仍是一个开放问题。
### Innovation
本文提出了一种新的框架——Pluralistic Off-Policy Evaluation（POPE），这是第一个用于LLMs离策多元偏好评估和对齐的方法。POPE采用了一个统一的奖励函数，结合了协作效用组件（源自人类偏好信号，例如点赞或相关性得分）和多样性组件（受基于熵的覆盖度量启发），以反映多元性对齐。同时，通过分解逆倾向得分（IPS）估计器来估计奖励，这种估计器分别评估相关性和多样性。理论证明表明，我们的分解IPS估计器建立了其方差的下界。使用离策策略评估的价值函数，可直接启用离策策略优化以进一步增强多元性对齐。实证结果表明，POPE能够有效地增强多元响应生成，并保持模型在下游任务中的通用能力。
### Conclusion
POPE通过结合协作效用和多样性奖励函数，以及使用分解的逆倾向得分估计器，有效地提升了LGMS的多元性对齐。该方法能够进一步优化离策策略在多元性对齐方面的能力，同时保持模型的通用性。
## 310. `cs.CL` - 使用大型语言模型进行试验匹配流程的系统评价 [PDF](https://arxiv.org/pdf/2509.19327), [HTML](https://arxiv.org/abs/2509.19327)
### Authors
Braxton A. Morrison(1),Madhumita Sushil(1),Jacob S. Young(1) ((1) University of California, San Francisco)
### Background
在肿瘤学等领域，患者与临床试验配对对于发现新型治疗方法至关重要。然而，人工配对过程劳动密集且易出差错，导致招募延迟。运用大型语言模型（LLMs）的管道提供了潜在的解决方案。这项研究对2020年至2025年期间在三个学术数据库和一个预印本服务器上发表的126篇独特文章进行了系统回顾，探讨了基于LLM的试验配对方法。研究发现，文献中涉及的配对类型包括患者标准匹配（4篇）、患者与试验匹配（10篇）、试验与患者匹配（2篇）、仅二元资格分类（1篇）以及多种任务的结合（14篇）。有的使用合成数据，有的使用真实病患数据，还有一篇使用了两者。数据集的多样性和评估指标的不同限制了跨研究的可比性。直接对比的研究中，GPT-4模型在配对和资格性提取任务上经常优于其他模型，尽管可能成本更高。值得注意的是，研究中提出了几种有前景的方法，如使用专门的LLM零样本提示、先进检索方法，以及在难以整合大型模型到医院基础设施时，微调较小的开源模型来保障数据隐私。然而，研究还指出了几个关键挑战，如获取足够大的真实世界数据集、降低成本、减小幻觉、数据泄漏和偏见的风险。
### Innovation
这项研究提供了基于LLM的患者与临床试验配对方法的系统回顾，强调了这种方法在解决人工配对劳动密集和出错率高的问题上的潜力。特别是，研究展示了GPT-4模型在配对和资格性提取任务上优于其他模型的能力，并提倡了几种可能克服数据隐私挑战的方法，如使用零样本提示的专有LLM或微调开源模型。这项工作强调需要标准化的评估指标、更现实的测试集，以及关注成本效益和公平性，以推动更广泛的部署。
### Conclusion
这项研究总结了LLM在临床试验配对领域的应用进展，强调了有前景的方向和关键限制。为了更广泛的部署，需要标准化的评估指标，更现实的测试集，并关注成本效率和公平性。
## 311. `cs.CL` - 基于能力感知检索和风格自适应的认知层面生成 [PDF](https://arxiv.org/pdf/2509.19336), [HTML](https://arxiv.org/abs/2509.19336)
### Authors
Qingsong Wang,Tao Wu,Wang Lin,Yueying Feng,Gongsheng Yuan,Chang Yao,Jingyuan Chen
### Background
大型语言模型在开放生成任务中表现出色，但在适应不同认知能力的用户时往往存在问题，这种现象被称为认知偏差。认知偏差有两种形式：知识层面和表现风格层面。知识层面的偏差是指内容与用户的理解能力不匹配，表现为内容过于复杂或过于简单；表现风格层面的偏差是指内容的结构或风格影响了用户的理解效率。
### Innovation
本文提出了一种认知层面对齐框架（CLAF），这是一种通用生成框架，能够同时对齐知识复杂度和表现风格与用户认知。CLAF 包含一个基于层次知识图的感知能力检索模块、一个由布隆分类法和偏好学习指导的风格优化模块，以及一个确保输出一致性与相关性的知识可控生成组件。此外，还建立了一个包含按查询划分的多个理解水平回答的认知标注数据集（SCALE），以支持训练和评估。
### Conclusion
实验结果表明，CLAF 能够增强生成语言模型输出的适应性和信息量，适应多种用户群体，提供解决实际应用场景中认知层面对齐问题的稳健解决方案。
## 312. `cs.CL` - 量化经典和最先进技术嵌入的组成性 [PDF](https://arxiv.org/pdf/2509.19332), [HTML](https://arxiv.org/abs/2509.19332)
### Authors
Zhijin Guo(1 and 2),Chenhao Xue(1),Zhaozhen Xu(2),Hongbo Bo(2),Yuxuan Ye(2),Janet B. Pierrehumbert(1),Martha Lewis(3) ((1) University of Oxford, (2) University of Bristol, (3) University of Amsterdam)
### Background
为了使语言模型正确泛化到新的表达，模型需要在必要时利用组合意义。现有技术如Word2vec过分强调了词语嵌入的组合性，但最新的生成式变压器模型和图模型在语境变化意义转移方面提供得没有限制。研究人员通过建立一种两步法的通用评估方法来量化组合性，包括通过典型相关分析测量已知实体属性与其嵌入之间的一致性，并通过重建不可见属性组合的嵌入以及检查L2损失、余弦相似性和检索准确率来评估叠加泛化。这些指标还捕捉了组合性失败的情况。该研究在所有层和训练阶段评估了句子、知识图谱和单词嵌入中的组合性，并发现更强的组合性信号出现在较晚的训练阶段和变压器模型的深层部分，但在最顶层开始下降。
### Innovation
本研究提出了一个量化经典和最先进技术嵌入组合性的两步法评估方法，通过测量已知实体属性与其嵌入的一致性和检查不可见属性组合嵌入的重建性能，从而更准确地评估模型的组合性能力。该研究还提供了在不同训练阶段和不同类型的数据中跟踪和比较模型组合性变化的方法，发现较晚的训练阶段和深层部分显示出更强的组合性信号，但顶层开始下降。这种评估方法有助于理解和改进语言模型的组合性性能。
### Conclusion
研究表明，经典和最先进技术嵌入的组合性信号随着时间的推移在训练过程中逐渐增强，但在顶层开始下降。这种评估方法能够量化不同训练阶段和不同模型结构中的组合性，从而为优化模型性能提供依据。
## 313. `cs.CL` - 使用CRF对纳加 pidgin 语言进行词性标注 [PDF](https://arxiv.org/pdf/2509.19343), [HTML](https://arxiv.org/abs/2509.19343)
### Authors
Alovi N Shohe,Chonglio Khiamungam,Teisovi Angami
### Background
研究纳加 pidgin 语言的词性标注，这是一项在自然语言处理（NLP）领域中重要的任务。纳加 pidgin 是一种特殊的克里奥耳语言，主要在印度东北部的纳加人和来自阿萨姆邦的人之间进行贸易交流时使用。尽管许多资源丰富的语言如英语、印地语等有大量的词性标注工作，但针对纳加 pidgin 语言的此类工作尚未开展。到目前为止，这是首次对纳加 pidgin 语言进行词性标注的尝试。
### Innovation
创建了一个包含 16,112 个标记的标注语料库，并应用了条件随机场（CRF）机器学习技术，实现了整体词性标注准确率达到 85.70%，精确率 86%，召回率为 85%，这在纳加 pidgin 语言的研究中是一项创新性的工作。
### Conclusion
通过使用条件随机场（CRF）技术，成功地对纳加 pidgin 语言进行了词性标注，并实现了较高的准确率和召回率，这为该语言的进一步研究和应用提供了基础。
## 314. `cs.CL` - SCORE: 一种生成文档解析的语义评估框架 [PDF](https://arxiv.org/pdf/2509.19345), [HTML](https://arxiv.org/abs/2509.19345)
### Authors
Renyu Li,Antonio Jimeno Yepes,Yao You,Kamil Pluciński,Maximilian Operlejn,Crag Wolfe
### Background
传统的文档解析系统（如确定性OCR或布局模型）通常会产生在语义上正确但在结构上存在偏差的输出。常用的评估指标（如CER、WER、IoU或TEDS）会将这种多样性误判为错误，对有效解释进行惩罚，从而模糊系统的实际表现。
### Innovation
SCORE（结构和内容稳健评估）框架旨在解决这一问题，引入了（i）调整后的编辑距离以确保内容稳健性，（ii）基于词元的诊断以区分幻觉和遗漏，（iii）具有空间容限和语义对齐的表格评估，以及（iv）层次结构感知的一致性检查。这些维度的结合能够在不牺牲语义严谨性的前提下拥抱表述多样性。
### Conclusion
在1,114页横跨完整基准测试和领域数据集的评估中，SCORE始终揭示了标准指标未能发现的跨数据集性能模式。在表格结构存在歧义的2-5%页面上，传统指标平均会因12-25%的系统表现下降而影响排名，并使其他有效解释等价的情况被误判。SCORE通过将生成输出标准化为格式无关的表示形式，无需对象检测流水线就能复现传统得分（如表格F1至0.93），证明了生成解析本身足以进行全面评估。这种方法暴露出解释多样性对评估结果的影响，提供了多维度的可解释诊断，从而为现代文档解析系统的语义地、公平和实用基准检测奠定了基础原则。
## 315. `cs.CL` - 在2025年4月ChatGPT与DeepSeek的基准测试：基于词典和深度学习的全新双视角情感分析 [PDF](https://arxiv.org/pdf/2509.19346), [HTML](https://arxiv.org/abs/2509.19346)
### Authors
Maryam Mahdi Alhusseini,Mohammad-Reza Feizi-Derakhshi
### Background
以往的研究多侧重于依赖词典的策略或者孤立性的预测深度学习模型。该研究着眼于大型语言模型（LLM）应用的用户满意度，通过收集4000条真实的用户评论，仔细预处理并通过过采样实现类别平衡，用于模型测试。
### Innovation
该研究提出了一种新颖的双视角方法，通过结合词典基于的情感分析（TextBlob）与深度学习分类模型（卷积神经网络CNN和双向长短期记忆网络Bi-LSTM），对比了ChatGPT与DeepSeek在Google Play Store上的用户评论。其创新在于将两种分析方法结合起来进行全面研究，相较于之前的孤立方法，提供了新的方法论标准。
### Conclusion
研究结果显示，ChatGPT获得了明显更多正面评价，基于深度学习的分类模型在情感分析中优于词典分析，其中CNN表现最佳，准确率达到96.41%，且在负面评论分类上几乎完美，并且在中性和正面情感上也有高F1分数。研究为开发人员和研究人员改进用户为中心的人工智能系统设计提供了实践性的见解。
## 316. `cs.CL` - 在LLM基准中使用认知复杂性框架界定知识图任务 [PDF](https://arxiv.org/pdf/2509.19347), [HTML](https://arxiv.org/abs/2509.19347)
### Authors
Sara Todorovikj,Lars-Peter Meyer,Michael Martin
### Background
大型语言模型（LLMs）越来越多地用于涉及知识图（KGs）的任务，而KGs的评估通常仅关注准确性及输出正确性。研究者们通常使用这些指标来评估模型表现，但缺乏综合的方法来全面评估模型在复杂任务中的表现，尤其是在考量任务的认知复杂性方面.
### Innovation
本文提出了一种使用认知心理学中的三个复杂性框架来补充现有技术的新方法，以评估LLM-KG-Bench框架中的任务。通过这种方法，研究者可以重呼价值分布图、识别未充分代表的需求，并推动更丰富的方法和多样性来评价基准测试任务的表现，为未来的模型评估提供了新的视角和路径.
### Conclusion
通过应用认知复杂性框架，提出了LLM-KG-Bench框架的新评估方法，使任务评价更为全面，促进了这项技术的丰富和发展，为更深入地理解模型在KG任务上的表现提供了一种全新的方法.
## 317. `cs.CL` - 大型语言模型在回答重症监护医学问题方面的表现 [PDF](https://arxiv.org/pdf/2509.19344), [HTML](https://arxiv.org/abs/2509.19344)
### Authors
Mahmoud Alwakeel,Aditya Nagori,An-Kwok Ian Wong,Neal Chaisson,Vijay Krishnamoorthy,Rishikesan Kamaleswaran
### Background
虽然大型语言模型已经在医学学生水平的问题上进行了测试，但在专业领域如重症监护医学（CCM）的表现很少被研究。这项研究评估了采用Meta-Llama 3.1模型（8B和70B参数）对871个CCM问题的回答情况，展示了模型在重症监护医学中的应用潜力和挑战性任务的表现差异。
### Innovation
研究使用了大型语言模型Meta-Llama 3.1，并对特定专业领域（即重症监护医学）进行了评估，这是对其在该领域应用的首次广泛研究。研究发现，随着模型参数量的增加（从8B到70B），模型在回答CCM问题时的表现得到了显著提高，具有重要的创新意义。
### Conclusion
尽管Llama3.1:70B模型在回答CCM问题时优于8B模型30%，不同领域的表现存在显著差异，最高为研究领域（68.4%）而最低为肾病领域（47.9%）。这表明未来需要在不同的专科领域进一步提高模型的表现，以更广泛地应用和推广此类技术。
## 318. `cs.CL` - ShinkaEvolve: 朝着开放的和样本高效的程序进化 [PDF](https://arxiv.org/pdf/2509.19349), [HTML](https://arxiv.org/abs/2509.19349)
### Authors
Robert Tjarko Lange,Yuki Imajuku,Edoardo Cetin
### Background
近年来，大规模语言模型（LLMs）的推理时间计算扩展方面取得了显著进步，推动了科学发现的广泛进程。当前的方法依赖于利用LLMs作为变异操作的进化代理。虽然这种方法有了显著的进展，但传统的代码进化方法存在样本效率低和闭源的局限性，需要成千上万的样本才能找到有效的解，并且限制了广泛采用和扩展。
### Innovation
ShinkaEvolve框架引入了三个关键创新：平衡探索和利用的父代采样技术，高效的搜索空间探索的代码新颖性拒绝采样，以及基于多臂赌博机的LLM集成选择策略。实验结果表明，ShinkaEvolve在不同任务中体现出一致的样本效率和解的质量提升。它仅使用150个样本就发现了新的圆形排列解决方案，设计了AIME数学推理任务的高性能代理，并改进了ALE-Bench的程序解决方案，还发现了新的混合专家负载均衡损失函数，揭示了优化策略的空间。
### Conclusion
ShinkaEvolve框架展示了广泛适用性和极高的样本效率。通过提供开源访问和成本效益，它使跨各种计算问题的开放发现变得更加民主化。
## 319. `cs.CL` - TriSPrompt：一种用于不完整模态多模态谣言检测的分层软提示模型 [PDF](https://arxiv.org/pdf/2509.19352), [HTML](https://arxiv.org/abs/2509.19352)
### Authors
Jiajun Chen,Yangyang Wu,Xiaoye Miao,Mengying Zhu,Meng Xi
### Background
多模态数据中的不完整模态普遍存在，这对实现准确的谣言检测提出了重大挑战。现有的多模态谣言检测方法主要集中在从完整多模态训练数据中学习联合模态表示上，使得它们在处理真实场景中常见的缺失模态时无效。
### Innovation
本文提出了一种分层软提示模型TriSPrompt，该模型整合了三种类型的提示，即模态感知（MA）提示、模态缺失（MM）提示和互视（MV）提示，以有效地在不完整多模态数据中检测谣言。MA提示捕获特定模态的异构信息和可用数据的同质特征，帮助模态恢复；MM提示建模不完整数据中的缺失状态，增强模型对缺失信息的适应性；MV提示学习主观（如文本和图像）和客观（如评论）视角之间的关系，有效检测谣言。
### Conclusion
在三个实际基准上的实验结果表明，TriSPrompt方法相比最先进的方法在准确性上提高了超过13%。相关代码和数据集可在https: //anonymous.this http URL. 获取。
## 320. `cs.CL` - 测评与提升个性化生成的大语言模型稳健性 [PDF](https://arxiv.org/pdf/2509.19358), [HTML](https://arxiv.org/abs/2509.19358)
### Authors
Chimaobi Okite,Naihao Deng,Kiran Bodipati,Huaidian Hou,Joyce Chai,Rada Mihalcea
### Background
近年来，个性化生成的大语言模型（LLMs）引起了广泛关注。现有的评估主要集中在响应是否符合用户偏好，但本文认为事实准确性是同样重要但常被忽视的维度。在个性化背景下，定义一个稳健的模型是其响应既准确又与用户偏好一致。研究发现当前的LLMs在实现稳健个性化方面存在困难：即使是较强的模型（如GPT-4.1，LLaMA3-70B）在没有个性化的情况下也会在之前的成功案例中有5%的错误率，而较小的模型（如7B-scale）的错误率则超过20%。
### Innovation
提出了一个名为PERG的可扩展框架，用于评估LLMs的稳健性，及一个新数据集PERGData。此外，提出了一种名为Pref-Aligner的两阶段方法，以平均提高25%的稳健性，填补了当前评价实践的关键空白，并引入了支持更可靠、用户对齐的LLM部署的工具和指标。
### Conclusion
研究揭示了当前对LLMs评价的不足之处，突显了对用户偏好的稳健个性化仍存在显著差距，Furthermore, it highlights the critical gaps in current evaluation practices and introduces tools and metrics to support more reliable, user-aligned LLM deployments.
## 321. `cs.CL` - 针对对齐的大语言模型的语义表示攻击 [PDF](https://arxiv.org/pdf/2509.19360), [HTML](https://arxiv.org/abs/2509.19360)
### Authors
Jiawei Lian,Jianhong Pan,Lefan Wang,Yi Wang,Shaohui Mei,Lap-Pui Chau
### Background
大型语言模型（LLMs）越来越多地采用对齐技术来防止生成有害输出。尽管有这些保护措施，攻击者仍可以通过构造诱导LLMs生成有害内容的提示来绕过这些技术。现有方法通常针对具体的肯定回答，如“好的，这里是...”，但这些方法存在有限的收敛性、不自然的提示和高计算成本的问题。
### Innovation
本文提出了语义表示攻击（Semantic Representation Attack）这一新颖的方法，从根本上重新定义了对齐LLMs的对抗目标。不同于针对特定文本模式，该方法利用包含具有等效有害含义的多样回答的语义表示空间。本文提出的语义表示启发式搜索算法在增量扩展过程中保持解释性，高效生成语义连贯且简洁的对抗提示。该方法提供严格的语义收敛理论保证，并在18个LLM上实现了前所未有的攻击成功率（89.41%，包括100%的成功率）。
### Conclusion
全面的实验结果证明了语义表示攻击方法的总体优越性。代码将公开展示。
## 322. `cs.CL` - RoadMind：迈向灾害响应中的地理空间AI专家 [PDF](https://arxiv.org/pdf/2509.19354), [HTML](https://arxiv.org/abs/2509.19354)
### Authors
Ahmed El Fekih Zguir,Ferda Ofli,Muhammad Imran
### Background
大型语言模型（LLMs）在各种自然语言任务中展示了出色的性能，但在处理地理空间数据方面仍有所欠缺，尤其是道路网络、距离和方向等方面。这在灾难场景中是一个挑战，因为空间理解是任务如疏散规划和资源分配的关键。为此，本文探讨了通过将开放街图（OSM）的结构化数据应用于LLMs以增强其地理空间推理能力的方法。
### Innovation
本文提出了一种名为RoadMind的自监督框架，该框架利用OpenStreetMap的结构化数据来增强LLMs的地理空间推理能力。该框架通过自动提取给定城市中的道路基础设施数据，并将其转化为针对关键空间任务的多种监督格式来进行预训练和微调。结果表明，通过RoadMind训练的模型明显优于现有的强大基线，包括最先进的LLMs以及使用高级提示工程的模型。这一结果显示，结构化的地理空间数据能够增强语言模型的地理空间推理能力，从而支持更有效的离线AI系统以应对灾难响应。
### Conclusion
本研究证明了结构化地理空间数据能够增强语言模型的地理空间推理能力，这些模型在灾难响应场景中具有更高的性能，能够促进更有效的离线AI系统的开发。
## 323. `cs.CL` - FHIR-AgentBench: 评估真实交互式医疗记录问题回答的LLM代理基准 [PDF](https://arxiv.org/pdf/2509.19319), [HTML](https://arxiv.org/abs/2509.19319)
### Authors
Gyubok Lee,Elea Bach,Eric Yang,Tom Pollard,Alistair Johnson,Edward Choi,Yugang jia,Jong Ha Lee
### Background
最近，医疗领域转向了由Health Level Seven (HL7)定义的Fast Healthcare Interoperability Resources (FHIR)标准，这为临床AI应用开辟了新的可能性。新型AI代理需要处理复杂的资源基数据模型，而不是传统的结构化健康数据。然而，现有的基准测试并未跟上这一变化，缺乏对真实交互式电子健康记录 (EHR) 数据进行评估所需的现实性。因此，有必要开发一个新的基准测试来解决这些问题。
### Innovation
本文提出了一个名为FHIR-AgentBench的新基准测试，它以HL7 FHIR标准为基础，包含2,931个真实的临床问题。该基准测试用于系统性地评估AI代理框架，比较了不同的数据检索策略（直接使用FHIR API调用与专门工具）、交互模式（单次交互与多次交互）以及推理策略（自然语言推理与代码生成）。实验结果突显了从复杂FHIR资源中检索数据的实践挑战以及跨资源推理的难度，这些因素对问题回答性能有重要影响。为了促进可重复研究和开发稳健可靠的AI代理，作者还公开发布了一个包含数据集和评估套件的资源。
### Conclusion
FHIR-AgentBench提供了一个新的基准测试，能够真实地评估AI代理处理互操作EHR数据的能力。通过公开发布数据集和评估工具，本文旨在推动研究中可重复性和可靠AI代理的发展。
## 324. `cs.CL` - Meow: 全局化自动学术综述提纲写作 [PDF](https://arxiv.org/pdf/2509.19370), [HTML](https://arxiv.org/abs/2509.19370)
### Authors
Zhaoyu Ma,Yuan Shan,Jiahao Zhao,Nan Xu,Lei Wang
### Background
随着学术论文发表数量的指数级增长，自动地利用大型语言模型（LLMs）进行深入的综述已经成为一种不可避免的趋势。提纲写作是系统地组织相关工作的关键，对于自动生成综述至关重要。然而，现有的自动综述方法通常将提纲写作视为整体流水线中的步骤，由此产生的提纲往往缺乏对该综述主题的深入理解，语言风格也不够精细。
### Innovation
本文提出了Meow，这是首个通过元数据驱动的提纲写作框架，能够高效地生成有序且忠实地反映内容的提纲。具体来说，提出了一个端到端的任务框架，能够从论文元数据中生成层次化的结构化提纲。并且，还建立了一个高质量的综述数据集，以及系统的评估标准来评估提纲质量，通过结合监督微调与强化学习的技术，实现了结构高保真度和风格一致性。
### Conclusion
Meow模型证明了强大的表现，能够在结构和风格上完美地适应自动生成的学术综述需求。这一框架比现有方法能够更好地理解综述主题和细节，为自动综述生成提供了一个新的解决方案。
## 325. `cs.CL` - 社交媒体数据中LLM辅助的主题减少方法 [PDF](https://arxiv.org/pdf/2509.19365), [HTML](https://arxiv.org/abs/2509.19365)
### Authors
Wannes Janssens,Matthias Bogaert,Dirk Van den Poel
### Background
BERTopic框架利用转换器嵌入和层次聚类从非结构化的文本语料库中提取潜在主题。然而，在面对社交媒体数据时，该方法常遇到困难，因为社交媒体数据通常噪声大、稀疏，导致生成的主题过多且存在重叠。尽管最近研究探索了使用大规模语言模型进行端到端的主题建模，但这些方法通常需要大量的计算资源，限制了它们在大数据环境中的可扩展性。因此，需要一个既能生成主题又能减少主题的框架，将BERTopic与大规模语言模型相结合，以提高主题的多样性和共现性。
### Innovation
本文提出了一种结合BERTopic进行主题生成和大规模语言模型进行主题减少的框架。该方法首先生成一组初始主题，并构建每个主题的表示，然后将这些表示提供给语言模型，语言模型会迭代地识别和合并语义相似的主题。这种方法在三个Twitter/X数据集和四种不同的语言模型上进行了评估，并且在提高主题多样性和共现性方面优于基线方法，但在一定程度上对数据集特性和初始参数选择敏感。
### Conclusion
这种方法通过利用大规模语言模型来减少生成的主题数量，提高了主题建模的多样性和共现性，尽管其效果对数据集特性和初始参数选择有些敏感度。
## 326. `cs.CL` - 基于SLM的P-C-G代理AI：针对韩语工具使用优化 [PDF](https://arxiv.org/pdf/2509.19369), [HTML](https://arxiv.org/abs/2509.19369)
### Authors
Changhyun Jeon,Jinhee Park,Jungwoo Choi,Keonwoo Kim,Jisu Kim,Minji Hong
### Background
在韩语环境中，频繁的韩语到英语的代码切换会导致执行失败。现有的代理AI架构需要优化以适应韩语工具的使用环境，并且需要一种能够处理单一链路、多链路、缺少参数以及缺少功能的场景并评估端到端质量的机制。现有解决方案可能需要提高工具使用精度和整体质量，但同时还需要减少token数量并保持可接受的延迟时间，以保持成本效益。
### Innovation
本文提出了一种基于小规模语言模型（SLM）的代理架构P-C-G，专门优化用于韩语工具的使用。通过分离规划、调用和生成的角色功能，该架构能够在保持成本效益的同时，减少token数量并维持可接受的延迟时间。此外，为了减少韩语到英语的代码切换带来的执行失败问题，文章引入了一种针对韩语优先的价值策略。
### Conclusion
P-C-G架构在韩语查询和韩语工具/参数规范的条件下，展示了与当前方法相当的工具使用准确性和端到端质量，同时减少了token数量并保持了合理的延迟时间。这表明角色专门化的SLM可以作为韩语工具使用代理的经济有效的替代方案。
## 327. `cs.CL` - 通过行为和内部评估合并方法的管道 [PDF](https://arxiv.org/pdf/2509.19476), [HTML](https://arxiv.org/abs/2509.19476)
### Authors
Yutaro Sigris,Andreas Waldis
### Background
当前已有研究主要从行为角度来评估合并模型，本文作者则通过综合评估合并模型的行为与内部机制，提供了第一个全面的视角，借此分析多个语言模型（LMs）合并方法的效果。
### Innovation
本文提出了一个新的评估管道，首先将多个母语言模型合并，然后根据下游任务（如MMLU）性能及内部编码的语言能力进行评估，并展示了该方法应用于Qwen2.5家族的数学和代码适配指令微调LMs合并的效果。本文发现合并模型的行为和内部机制影响不同，尽管合并模型的性能通常介于两个母模型之间，但它们在形态学和句法规则上的语言信息编码可能超过母模型。
### Conclusion
本文通过该管道和初步结果，强调了对模型合并方法进行全面评估的重要性，以深入了解其能力和可靠性，而不仅仅是潜在的表面行为进步。
## 328. `cs.CL` - 像素在语义语言建模中的不确定性 [PDF](https://arxiv.org/pdf/2509.19563), [HTML](https://arxiv.org/abs/2509.19563)
### Authors
Stefania Radu,Marco Zullich,Matias Valdenegro-Toro
### Background
基于像素的语言模型旨在解决语言建模中的词汇量瓶颈问题，但不确定性量化仍然是一个挑战。
### Innovation
本文分析了基于像素的语言模型在18种语言和7种字体上的不确定性及置信度，通过蒙特卡洛 Dropout、Transformer 注意机制和集成学习等多种方法，证明了基于像素的模型在重新构建块时低估了不确定性，而且不同字体的影响也不同。
### Conclusion
集成学习在命名实体识别和问答任务上的表现更好，尤其是在应用超参数调优时。同时，拉丁语系语言的表现不确定度较低。
## 329. `cs.CL` - 离线大语言模型评估的不足之处：建模行为中需要考虑个性化 [PDF](https://arxiv.org/pdf/2509.19364), [HTML](https://arxiv.org/abs/2509.19364)
### Authors
Angelina Wang,Daniel E. Ho,Sanmi Koyejo
### Background
传统的离线评估方法，比如语言模型的独立无状态推断，无法完全捕捉语言模型在实际应用中的行为。特别是在个性化方面，相同基准问题在不同用户交互中的表现可能会有很大差异。
### Innovation
本文通过比较800名真实用户的ChatGPT和Gemini用户对其聊天界面提出基准问题和其他问题的响应，提供了实证证据，以展示离线评估和实际应用中模型行为的差异，强调了在模型行为中考虑个性化的重要性。
### Conclusion
离线评估方法无法全面反映模型的行为，需要在评估中考虑个性化因素，以更好地理解模型在实际应用中的表现。
## 330. `cs.CL` - 基于大型语言模型的实体匹配中的置信校准 [PDF](https://arxiv.org/pdf/2509.19557), [HTML](https://arxiv.org/abs/2509.19557)
### Authors
Iris Kamsteeg,Juan Cardenas-Cartagena,Floris van Beers,Gineke ten Holt,Tsegaye Misikir Tashu,Matias Valdenegro-Toro
### Background
该研究旨在探索大型语言模型与实体匹配置信校准的交集。通过对比 RoBERTa 基线模型在实体匹配任务中的置信度与其采用温度校准、蒙特卡洛dropout和集成方法校准的置信度，以及使用 Abt-Buy、DBLP-ACM、iTunes-Amazon 和公司数据集进行实证研究，来探讨这些方法的有效性。
### Innovation
该研究提出了使用 RoBERTa 模型结合多种方法（如温度校准、蒙特卡洛dropout和集成方法）进行实体匹配置信度校准的新方法，旨在降低模型的过高置信度。研究表明，使用温度校准可以显著降低预期校准误差，最高可达23.83%。
### Conclusion
研究发现，修改后的 RoBERTa 模型在不同数据集上显示出轻微的过度拟合现象，通过温度校准可以缓解这一现象，降低预期校准误差。
## 331. `cs.CL` - 如何高效注入知识？大规模语言模型预训练中的知识注入量缩放定律 [PDF](https://arxiv.org/pdf/2509.19371), [HTML](https://arxiv.org/abs/2509.19371)
### Authors
Kangtao Lv,Haibin Chen,Yujin Yuan,Langming Liu,Shilei Liu,Yongwei Wang,Wenbo Su,Bo Zheng
### Background
大型语言模型（LLMs）因其在各种下游任务上表现出的广泛能力而吸引了大量关注。然而，在没有针对特定领域进行优化的情况下，它们往往在专业知识基准测试中表现不佳，甚至会产生虚假信息。最近的研究表明，在预训练期间战略性地注入领域知识可以显著提高下游性能。然而，在知识注入过程中存在一项关键挑战：注入过少的领域特定数据会导致知识不足的专门化，而过度注入则会导致以前获得的知识被灾难性遗忘。本文关注过度注入引起的记忆崩溃现象。通过系统的实验，观察到两个关键现象：1）临界崩溃点：每个模型都存在一个阈值，超过这个阈值后其知识保留能力会急剧下降。2）规模相关性：这些崩溃点与模型大小之间存在一致的关系。基于这些见解，提出了一种知识注入的量缩放定律，通过分析小型模型来预测应注入到大规模LLMs中的最佳领域知识量。广泛的实验验证了量缩放定律的有效性和普适性。
### Innovation
提出了一种知识注入的量缩放定律，能够预测在预训练大规模语言模型时应注入的最佳领域知识量，并验证了该量缩放定律的有效性和普适性。
### Conclusion
通过系统的实验研究，成功预测了不同规模模型的最佳领域知识注入量，该量缩放定律不仅在模型规模不同的情况下有效，而且还能跨不同的令牌预算验证其实用价值。
## 332. `cs.CL` - LLMs是否编码框架语义？来自框架识别的证据 [PDF](https://arxiv.org/pdf/2509.19540), [HTML](https://arxiv.org/abs/2509.19540)
### Authors
Jayanth Krishna Chundru,Rudrashis Poddar,Jie Cao,Tianyu Jiang
### Background
本文研究了大语言模型是否编码了框架语义的潜在知识，关注于框架识别这一框架语义解析的关键挑战，涉及在上下文中为目标任务词选择合适的语义框架。利用FrameNet词汇资源，评估模型在提示驱动推理下的表现，发现即使在没有显式监督的情况下，它们也能有效进行框架识别。进一步分析表明，模型能够生成语义连贯的框架定义，突显了模型内部化的框架语义理解能力。为了评估任务特定训练的影响，我们在FrameNet数据上对模型进行了微调，尽管在领域内部的准确性得到了显著提高，但仍能很好地泛化到领域外基准中。
### Innovation
本文创新点在于利用提示驱动推理评估大语言模型在无显式监督下的框架识别能力，并通过在FrameNet数据上微调模型，进一步提升了领域内部的准确性，且在领域外基准中的泛化能力也表现良好，展示了模型对框架语义的内部理解。
### Conclusion
研究结果表明，大语言模型能够在没有显式监督的情况下进行有效的框架识别，并且通过在FrameNet数据上进行任务特定训练，模型既能够在领域内部获得显著的准确性提升，又能够很好地泛化到领域外基准中，展示了模型对框架语义的深层次理解。
## 333. `cs.CL` - 全管道并行是最优早期退出基于自我推测解码的需要 [PDF](https://arxiv.org/pdf/2509.19368), [HTML](https://arxiv.org/abs/2509.19368)
### Authors
Ruanjun Li,Ziheng Liu,Yuanming Shi,Jiawei Shao,Chi Zhang,Xuelong Li
### Background
大型语言模型（LLMs）在生成质量方面表现出色，但其推理成本极高，因为每个输出令牌是通过所有模型层自回归生成的。早期退出基于自我推测解码（EESD）已经出现以缓解这种成本，但在实践中，许多方法在草案然后验证的 paradigm 中难以实现预期的加速效果，即使早期退出头和退出位置匹配良好。我们发现，只有当LLM接受绝大多数草稿令牌时，EESD才能奏效，否则，草稿的成本可能会超过加速收益，导致负加速。
### Innovation
我们提出了全管道并行自我推测解码（PPSD），该方法完全并行化了草稿和验证工作，从而避免了因失败预测造成的浪费。PPSD 的两个关键创新点在于：1. 将模型层配置为一个管道，在其中早期退出（草稿）计算和剩余层（验证）计算重叠；2. 预测和验证交错进行以每个令牌为基础。当LLM 在最终层验证当前令牌时，早期退出路径同时草稿下一个令牌。这种方式使所有单元持续忙碌，并在线验证令牌，类似于推测和验证阶段的流水线化。
### Conclusion
经验结果证实了PPSD在自我推测LLM推理中的最先进的加速效果。在多样化的基准测试中，PPSD实现了2.01x~3.81x 的加速比，这意味着在固定接受率和退出位置的情况下，接近最优加速，展示了其在提供高效自我推测方面的进步。
## 334. `cs.CL` - LLMs4All: 语言模型在学术学科中的研究与应用综述 [PDF](https://arxiv.org/pdf/2509.19580), [HTML](https://arxiv.org/abs/2509.19580)
### Authors
Yanfang(Fanny)Ye,Zheyuan Zhang,Tianyi Ma,Zehong Wang,Yiyang Li,Shifu Hou,Weixiang Sun,Kaiwen Shi,Yijun Ma,Wei Song,Ahmed Abbasi,Ying Cheng,Jane Cleland-Huang,Steven Corcelli,Patricia Culligan,Robert Goulding,Ming Hu,Ting Hua,John Lalor,Fang Liu,Tengfei Luo,Ed Maginn,Nuno Moniz,Jason Rohr,Brett Savoie,Daniel Slate,Tom Stapleford,Matthew Webber,Olaf Wiest,Johnny Zhang,Nitesh Chawla
### Background
最新的人工智能技术不断重塑我们对世界的看法。例如，基于大语言模型（LLMs）的应用程序，如ChatGPT，展示了在广泛话题生成类似人类对话的能力。由于在各种语言相关任务上表现出色（如开放域问答、翻译和文档总结），人们可以预见LLMs在更广泛的实际应用中的深远影响（如客户服务、教育与可访问性、以及科学发现）。
### Innovation
本文将对最新的LLMs及其在多个学术领域的整合进行综述，涵盖艺术、法律、经济学、商业、科学和工程等领域。同时，本文还将探讨LLMs在塑造这些领域的研究和实践中的作用，以及生成人工智能时代的关键限制、开放挑战和未来方向。
### Conclusion
通过总结LLMs在不同学科中的应用及其关键发现和见解，本文旨在帮助学者和从业者利用LLMs推进他们在各种实际应用中的工作。
## 335. `cs.CL` - 一种情感实现：通过大型视觉语言模型叙述体现情感 [PDF](https://arxiv.org/pdf/2509.19595), [HTML](https://arxiv.org/abs/2509.19595)
### Authors
Mohammad Saim,Phan Anh Duong,Cat Luong,Aniket Bhanderi,Tianyu Jiang
### Background
人类的身体部位的表达情感反应包含了丰富的关于我们情感体验的信息。现有研究试图利用最先进的大型视觉语言模型（LVLMs）来生成体感视觉语言模型情感叙述（ELENA），该叙述主要是对参与情感反应的关键身体部位的详细描述。
### Innovation
提出了一个框架，利用最先进的大型视觉语言模型（LVLMs）生成体感视觉语言模型情感叙述（ELENA）。该框架通过描述参与情感反应的关键身体部位来进行细致的叙述。研究还发现，当前模型对脸部区域存在固有的偏好，但使用的框架仍然能够识别遮挡面部图像中的体感情感，且优于未调整基线。
### Conclusion
ELENA开辟了跨视觉模态的体感情感分析的新方向，并在情感意识设置中丰富了建模。
## 336. `cs.CL` - GuessingGame: 测量大型语言模型在开放式问题方面的信息量 [PDF](https://arxiv.org/pdf/2509.19593), [HTML](https://arxiv.org/abs/2509.19593)
### Authors
Dylan Hutson,Daniel Vennemeyer,Aneesh Deshmukh,Justin Zhan,Tianyu Jiang
### Background
本文介绍了GuessingGame，这是一个协议，用于评估大型语言模型（LLMs）作为战略型提问者在开放式、跨领域的环境中的能力。GuessingGame 目标是使LLM通过向Oracle提出开放形式的问题来识别隐藏的对象，而不需要预设的选择或候选清单。通过对提问质量的评估，作者提出两种信息增益（IG）度量方法：一种是使用LLM评分的相关性来跟踪信念更新的贝叶斯方法；另一种是通过ConceptNet过滤候选者基于熵的方法。这两种度量方法都是模型无关的，并支持后分析。
### Innovation
提出的两种信息增益度量方法能够在开放性问题环境下评估大型语言模型提问的质量，这些方法既支持贝叶斯跟踪信念更新，也支持基于熵的过滤候选者的方法。实验表明，更高的人性度量有助于减少预期游戏长度，约43%。此外，通过IG引导的提问约束，如强制多样性的提问，能够显著提升较弱模型的表现。
### Conclusion
本研究表明，LLMs的提问能力是可测量和可改进的，并且在交互性推理中至关重要。这提供了评估和改进LLMs提问策略的新方法。
## 337. `cs.CL` - 基于检索增强生成的ASR上下文发现 [PDF](https://arxiv.org/pdf/2509.19567), [HTML](https://arxiv.org/abs/2509.19567)
### Authors
Dimitrios Siskos,Stavros Papadopoulos,Pablo Peso Parada,Jisi Zhang,Karthikeyan Saravanan,Anastasios Drosou
### Background
本文研究了检索增强生成（RAG）作为一种提高自动语音识别（ASR）系统的上下文发现效率的策略。在包含罕见或不在词典中的术语的情况下，这种方法旨在提高转录准确性。然而，自动识别正确的上下文仍然是一个开放的问题。因此，本文提出了一种基于嵌入的检索方法用于ASR的上下文发现，以提升ASR系统的性能和准确性。为了验证其有效性，本文还评估了两种基于大型语言模型（LLMs）的方法：通过提示的大型语言模型（LLM）上下文生成和识别后的转录文本纠正。这些方法在TED-LIUMv3、Earnings21和SPGISpeech数据集上的实验结果表明，提出的检索增强生成方法相比不使用上下文时的词错误率（WER）减少了17%左右，而使用真正的上下文则减少了24.1%左右的词错误率。
### Innovation
本研究提出了一种基于嵌入的检索方法，用于ASR的上下文发现。这是一种新颖的方法，可以有效提高ASR系统的效率和准确性。同时，本文还通过实验验证了基于大型语言模型的两种替代方案，即通过提示的大型语言模型上下文生成和识别后的转录文本纠正。这些方法为ASR系统的上下文发现提供了一种新的思路和方案。
### Conclusion
本文提出的方法在提高ASR系统的词错误率方面表现出显著的效果。相比不使用上下文的情况，词错误率最多可以降低17%，而使用真正上下文时最多可以降低24.1%。这表明本文的方法在提升ASR系统的准确性方面具有重要的实际应用价值，并为未来的研究提供了一个新的方向。
## 338. `cs.CL` - AutoSpec：一种自动撰写专利说明书的代理框架 [PDF](https://arxiv.org/pdf/2509.19640), [HTML](https://arxiv.org/abs/2509.19640)
### Authors
Ryan Shea,Zhou Yu
### Background
专利在推动技术革新方面扮演着关键角色，通过赋予发明者对其发明的独家权利。然而，撰写专利申请的过程往往既昂贵又耗时，使其成为自动化的好候选对象。尽管近年来语言模型取得了进展，但在自动化领域开发稳健的专利撰写系统仍存在挑战。首先，专利申请中的信息高度保密，常用于自动化的封闭源语言模型无法使用。其次，即使是最先进的语言模型在撰写专利申请时也面临挑战，因为它们需要处理长上下文、技术写作风格和特殊领域的专业知识。
### Innovation
为了解决这些挑战，我们提出了AutoSpec，一种安全的代理框架，用于自动生成专利说明书。我们的方法将撰写过程分解为一系列可管理的子任务，每个子任务均可通过较小的开源语言模型解决，这些模型通过定制工具进行了增强，专门用于撰写专利说明书。为了评估我们的系统，我们与有经验的专利律师合作，设计了一个新颖的评估协议。自动评估和专家评估显示，AutoSpec在专利撰写任务中优于现有基线。
### Conclusion
我们的研究展示了一个全新的方法来自动撰写专利说明书，并通过评估展示了其优越性，这填补了现有技术的空白，为自动化专利撰写领域开辟新路径。
## 339. `cs.CL` - ExPe: 拟合生成变换器模型的精确位置编码，具有外推能力 [PDF](https://arxiv.org/pdf/2509.19569), [HTML](https://arxiv.org/abs/2509.19569)
### Authors
Aleksis Datseris,Sylvia Vassileva,Ivan Koychev,Svetla Boytcheva
### Background
传统的变换器模型依赖于绝对或相对位置嵌入来将位置信息融入到词汇嵌入中，但这些方法在处理训练时未见过的更长序列时常常出现泛化能力不足的问题。本文提出了一种新的方法，称为“精确位置嵌入”（ExPE），它能够对外推到训练时未见过的更长序列进行准确预测，从而克服了现有方法的限制，提高了模型的泛化能力。
### Innovation
本文提出了一种名为“精确位置嵌入”（ExPE）的新方法，这是一种绝对位置嵌入方法，能够在训练序列长度之外的更长序列上进行外推。该方法通过覆盖嵌入向量中的特定维度来编码精确的位置信息，从而提供比旋转和正弦嵌入更好的长序列泛化效果，在因果语言建模中显著降低了困惑度（perplexity）指标。
### Conclusion
与旋转和正弦嵌入相比，我们的ExPE嵌入在测试长于训练序列的序列时，显著降低了困惑度，从而证明了ExPE的有效性。此外，ExPE方法不仅保持了原始嵌入的完整性和准确性，还提高了模型泛化到更长序列的能力。
## 340. `cs.CL` - DyBBT: 动态平衡通过类赌博机启发的目标选择对话策略认知双系统 [PDF](https://arxiv.org/pdf/2509.19695), [HTML](https://arxiv.org/abs/2509.19695)
### Authors
Shuyu Zhang,Yifan Wei,Jialuo Yuan,Xinru Wang,Yanmin Zhu,Bin Li
### Background
任务导向型对话系统通常依赖静态探索策略，这些策略不能适应动态对话环境，导致探索效率低下和性能不佳。
### Innovation
提出了一种名为DyBBT的新颖对话策略学习框架，通过结构化的认知状态空间来描述对话进程、用户不确定性以及槽位依赖性，解决探索挑战。DyBBT采用类赌博机启发的元控制器，在实时认知状态和访问计数的基础上，动态切换快速直觉推理（System 1）和缓慢的仔细推理者（System 2）
### Conclusion
在单域和多域基准测试中的全面实验表明，DyBBT在成功率、效率和泛化方面达到了最先进水平，人类评估也证实其决策与专家判断高度吻合。
## 341. `cs.CL` - 大型语言模型在行人安全中的应用：未设信号交叉路口预测驾驶员让行行为 [PDF](https://arxiv.org/pdf/2509.19657), [HTML](https://arxiv.org/abs/2509.19657)
### Authors
Yicheng Yang,Zixian Li,Jean Paul Bizimana,Niaz Zafri,Yongfeng Dong,Tianyi Li
### Background
行人安全是城市交通的关键组成部分，受到行人决策与驾驶员在人行横道处礼让行为之间交互的影响。传统的机器学习模型在多因素交互中难以捕捉行人和驾驶员复杂且依赖于上下文的推理过程。相比之下，大型语言模型可以从异构交通数据中提取模式，适用于建模行人-驾驶员交互。因此，本文利用了新型的提示设计，结合领域知识、结构化推理和少量样本提示，以实现可解释和上下文感知的驾驶员礼让行为推理，作为建模行人-驾驶员交互的示例应用。
### Innovation
本文提出了利用大型语言模型通过引入新型提示设计的方法，结合领域知识、结构化推理和少量样本提示，实现行人-驾驶员交互中可解释且上下文感知的驾驶员礼让行为推理。这种方法能够捕捉和分析复杂的行为交互模式，优于传统分类器。
### Conclusion
实验结果表明，最先进的GPT-4o在准确性和召回率方面表现最佳，而Deepseek-V3则在精确度上表现优异。这些发现突显了模型性能与计算效率之间的关键权衡，提供了在实际行人安全系统中部署大型语言模型的实用指导。
## 342. `cs.CL` - HiCoLoRA: 通过层次协作LoRA解决上下文-提示错位对零样本DST的应对 [PDF](https://arxiv.org/pdf/2509.19742), [HTML](https://arxiv.org/abs/2509.19742)
### Authors
Shuyu Zhang,Yifan Wei,Xinru Wang,Yanmin Zhu,Yangfan He,Yixuan Weng,Bin Li
### Background
零样本对话状态跟踪(zs-DST)是使面向任务的对话系统(TODs)能够在无需昂贵数据标注的情况下泛化到新领域。主要挑战在于动态对话上下文与静态提示之间的语义不匹配，导致跨层协调的刚性、领域干扰及灾难性遗忘。
### Innovation
提出了一种框架HiCoLoRA，通过增强零样本槽推理中的健壮提示对齐来提升性能。该框架包含层次化的LoRA架构，用于动态层面特定的处理（结合底层启发式分组和高层全交互），整合频谱联合领域-槽聚类以识别可转移的关联（供自适应线性组合机制使用），并采用语义增强SVD初始化（SemSVD-Init）保留预训练知识。
### Conclusion
在多领域数据集MultiWOZ和SGD上的实验表明，HiCoLoRA在零样本对话状态跟踪（zs-DST）方面优于基线，达到了SOTA（State of the Art）水平。代码可以在该网址找到：this https URL.
## 343. `cs.CL` - Personality Vector: 通过模型合并调节大型语言模型的人格 [PDF](https://arxiv.org/pdf/2509.19727), [HTML](https://arxiv.org/abs/2509.19727)
### Authors
Seungjong Sun,Seo Yeon Baek,Jang Hyun Kim
### Background
随着对个性化AI系统的市场需求增加，人们对如何使大型语言模型（LLMs）匹配人类特性（如人格）的兴趣也在增长。尽管以前尝试在LLMs中诱导人格特征取得了令人鼓舞的结果，但它们难以捕捉到人类特质的连续性和多维性。
### Innovation
本文提出了通过模型合并的方法来调节LLMs的人格。具体地，通过从微调模型中减去预训练模型的权重来构建人格向量，进而使LLMs在无需额外训练的情况下展现出所需的个性特征。广泛实验表明，人格向量能实现对特质强度的连续控制，并支持多种特质的组合。此外，人格向量能够跨多种下游模型转移，表明它们编码了可泛化的个性表示。
### Conclusion
人格向量使LLMs能够展示连续控制的个性特征，并支持多种特质的组合。人格向量在不同下游模型间具有转移性，暗示着它们代表了一种可泛化的个性表示。相关代码已提供。
## 344. `cs.CL` - CHURRO：使用开放权重大型视觉语言模型实现高效、低成本的历史文本识别，使历史文档可读 [PDF](https://arxiv.org/pdf/2509.19768), [HTML](https://arxiv.org/abs/2509.19768)
### Authors
Sina J. Semnani,Han Zhang,Xinyan He,Merve Tekgürler,Monica S. Lam
### Background
准确识别历史文档中的文本能够极大地促进文化遗产的研究与保护。现有的视觉-语言模型（VLMs）主要针对现代标准化文本设计，无法应对历史材料中的多种语言、不规则布局和频繁退化等问题。
### Innovation
本文提出了CHURRO，一种针对历史文本识别的3B参数开放权重VLM。该模型基于迄今为止最大的历史文本识别数据集CHURRO-DS进行训练，该数据集合并了155个历史语料库，涵盖99,491页文字，横跨22个世纪的46个语言集群，包括历史变体和死语言。实验表明，CHURRO在CHURRO-DS数据集上的性能优于其他开放权重和封闭的VLM及光学字符识别系统，同时成本效益提高了15.5倍。
### Conclusion
通过发布该模型和数据集，作者希望促进社区驱动的研究，以提高历史文本的可读性并加速相关学术研究。
## 345. `cs.CL` - 新闻文本中可持续发展目标极性检测 [PDF](https://arxiv.org/pdf/2509.19833), [HTML](https://arxiv.org/abs/2509.19833)
### Authors
Andrea Cadeddua,Alessandro Chessa,Vincenzo De Leo,Gianni Fenu,Francesco Osborne,Diego Reforgiato Recupero,Angelo Salatino,Luca Secchi
### Background
联合国的可持续发展目标（SDGs）为解决社会、环境和经济的关键挑战提供了全球公认的框架。近年来，自然语言处理（NLP）和大型语言模型（LLMs）的发展促进了对特定SDGs相关文本数据的自动分类。然而，在许多应用场景中，确定这种相关性的方向性——即判断描述的影响是正面的、中立的还是负面的——同样重要。目前尚缺乏专门针对极性检测任务的数据集和方法。
### Innovation
本文提出了一项新颖的任务——SDG极性检测，旨在评估文本片段是否表明朝着特定SDG取得了进展或表达了这样的意图。为此，作者提出了SDG-POD基准数据集，结合了原创和合成生成的数据，并使用六种最先进的大模型进行了全面评估，包括零样本和微调配置。研究结果表明，当前的大型语言模型在该任务上仍具挑战性，但某些微调模型（尤其是QWQ-32B）在特定SDG（如SDG-9、SDG-12和SDG-15）上表现出色。此外，通过将微调数据集与合成生成的示例相结合，可以提高模型在此任务上的性能。
### Conclusion
本文推进了可持续发展目标监控的方法论工具包，并提供了关于开发高效高性能极性检测系统的可操作洞察。通过对合成生成的数据进行增量训练，展示了在资源受限领域中数据增强技术的有效性。
## 346. `cs.CL` - 通过打电话游戏评估语言翻译模型 [PDF](https://arxiv.org/pdf/2509.19611), [HTML](https://arxiv.org/abs/2509.19611)
### Authors
Syeda Jannatus Saba,Steven Skiena
### Background
机器翻译系统的评估质量已难以跟上当前语言模型的高效性和准确性，这限制了在长文本和文学翻译等更具挑战性的任务上进一步改进这些模型的潜力。
### Innovation
提出了一种无监督方法，通过多轮次地在源语言和目标语言之间进行翻译来生成不同文档长度和应用场景的翻译评估训练数据。评估使用模型轮换和语言翻译方法机械生成的文本训练的评估系统，表明在两种不同任务上优于一种流行的翻译评估系统xCOMET：(i) 评估某翻译与人类参考的翻译质量，(ii) 选择两个翻译中哪一个与原始文档更接近。
### Conclusion
研究结果展示了通过无监督生成训练数据进行翻译评估的有效性，并验证了此方法在多个翻译任务上的改进性能。
## 347. `cs.CL` - EnAnchored-X2X: 以英语为中心优化的多对多翻译 [PDF](https://arxiv.org/pdf/2509.19770), [HTML](https://arxiv.org/abs/2509.19770)
### Authors
Sen Yang,Yu Bao,Yu Lu,Jiajun Chen,Shujian Huang,Shanbo Cheng
### Background
大规模语言模型（LLMs）在英语文本翻译方面表现出色，但在非英语到非英语（x2x）直接翻译任务上表现不佳。本文通过利用模型已有的从英语到其他语言（en2x）的翻译能力，提出了一种合成数据生成框架，将英语双语语料库扩展为多向数据集，并开发了一种参考英语的质量评估代理，以有效收集高质量的x2x训练数据。这种方法应用于广泛使用的LLMs，效果显著提升，并且能够增强从英语到其他语言的翻译性能。结果表明，策略性地利用英语文本的优点可以增强LLMs在多语言翻译任务中的能力。
### Innovation
本文通过构建多向数据集和参考英语的质量评估代理，提出了一个合成数据生成框架，利用LLMs已有的en2x能力，有效收集高质量的x2x训练数据。结合偏好优化方法，显著提升了72种x2x方向上的LLMs性能，同时该方法还能促进en2x性能的提升。这种方法表明，在LLMs中利用英语文本的强项可以促进多语言翻译能力的全面发展。
### Conclusion
本文提出的EnAnchored-X2X方法通过策略性地利用英语为中心的优势，显著提升了LLMs在多语言翻译任务上的能力。研究人员认为，这一方法为提升大语言模型多语言翻译性能提供了新的思路和方法。
## 348. `cs.CL` - TianHui: 专门用于多种传统中医场景的大规模语言模型 [PDF](https://arxiv.org/pdf/2509.19834), [HTML](https://arxiv.org/abs/2509.19834)
### Authors
Ji Yin,Menglan He,Yujie Zhang,Linshuai Zhang,Tingting Ma,Ce Tian,Jie Wu,Lin Xu,Tao Jiang,  ((1) School of Intelligent Medicine, Chengdu University of Traditional Chinese Medicine, Chengdu, China (2) The Acupuncture and Tuina School, Chengdu University of Traditional Chinese Medicine, Chengdu, China (3) Center of Preventive Medicine, Hospital of Chengdu University of Traditional Chinese Medicine, Chengdu, China (4) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China (5) MD School of Intelligent Medicine Chengdu University of Traditional Chinese Medicine, Liutai Avenue Wenjiang District Chengdu, China)
### Background
在研究环境中，特定领域的大型语言模型（Domain-specific LLMs）在中医领域（TCM）面临局限性，主要是适应性受限、缺乏评估数据集以及计算资源有限。这限制了大型语言模型在中医领域的应用和研究进展。因此，本文旨在开发一种专门的中医领域的大规模语言模型，并通过语境数据集成和领域知识融合来解决这些限制问题。为此，研究者构建了一个大规模的中医语料库（包含0.97GB的无监督数据和611,312个问答对），并采用了两阶段训练策略。
### Innovation
本文提出了名为TianHui的专门中医领域的大型语言模型。该模型通过语境数据集成和领域知识融合构建，采用了两阶段训练策略，并使用了QLoRA、DeepSpeed Stage 2和Flash Attention 2等先进技术。经过12个基准测试，TianHui在6个数据集上排名前三，在其他6个数据集上取得了最好的结果。通过调整优化配置，最终确定最佳配置为LoRA秩=128，alpha=256，epoch=4，dropout=0.2，最大长度=2048。这些创新解决了中医领域模型构建和技术应用的挑战。
### Conclusion
TianHui模型能够在多种中医场景下系统地保存和可扩展应用中医知识。所有资源均已开源，为进一步的研究和实际应用提供了支持。这项研究为中医知识的大规模建模和应用提供了新的解决方案。
## 349. `cs.CL` - PART：基于 LLM 的多语言语音转文本渐进对齐表示训练 [PDF](https://arxiv.org/pdf/2509.19745), [HTML](https://arxiv.org/abs/2509.19745)
### Authors
Pei Zhang,Andong Chen,Xi Chen,Baosong Yang,Derek F. Wong,Fei Huang
### Background
大语言模型（LLMs）已从文本扩展到语音，催生了支持识别、翻译和合成的语音大模型（SLMs）。一个关键挑战是使语音和文本表示对齐，特别是在多语言环境中，这一挑战变得更困难。现有方法通常会冻结LLM参数，并在多语言数据上训练编码器，但这种方法会迫使跨语言收敛，从而限制了性能。
### Innovation
引入了一种多阶段和多任务框架——渐进对齐表示训练（PART），该框架将语言内对齐与跨语言对齐分离。在跨语言训练过程中，LLM参数动态激活，并在后期引入基于文本的任务以增强多语言理解。实验表明，PART在CommonVoice 15、Fleurs、Wenetspeech和CoVoST2上的表现超过了传统方法，分析显示PART能够很好地平衡语言特定差异和跨语言泛化能力，证实了PART的有效性和通用性。
### Conclusion
PART框架在多语言语音模态对齐方面表现出显著效果和普适性，其多阶段和多任务训练策略能够有效解决语音和文本表示对齐的挑战，特别适用于多语言环境。
## 350. `cs.CL` - 对抗攻击对语音大语言模型的基准评估 [PDF](https://arxiv.org/pdf/2509.19858), [HTML](https://arxiv.org/abs/2509.19858)
### Authors
Jinyang Wu,Bin Zhu,Xiandong Zou,Qiquan Zhang,Xu Fang,Pan Zhou
### Background
随着语音应用中越来越多地集成语音大语言模型（Speech LLMs），对抗性或操纵性输入对它们的鲁棒性提出了重大挑战。尽管已有研究关注了文本和视觉语言模型中的对抗攻击，但语音交互的特殊认知和知觉挑战尚未得到充分探索。语音具有固有的模糊性、连续性和感知多样性，这使得对抗攻击更难被检测到。
### Innovation
该论文引入了gaslighting攻击，这是精心设计的误导、覆盖或扭曲模型推理的策略，用以评估Speech LLMs的脆弱性。构建了五种操纵策略：愤怒、认知破坏、讽刺、暗含意义和专业否定，以测试模型在各种任务中的robustness。除了性能下降外，框架还捕捉到了不请自来道歉和拒绝等行为反应，以诊断不同维度的易受攻击性。此外，进行了声学扰动实验以评估多模态robustness。通过衡量在多种语音和多模态LLM中超过10,000个测试样本中的表现，发现平均准确性降低了24.3%。
### Conclusion
这些发现突显了需要更加健壮和可信的语音AI系统的需求。
## 351. `cs.CL` - SINAI在eRisk@CLEF 2025中的表现：基于变换器的方法和对话策略用于抑郁症检测 [PDF](https://arxiv.org/pdf/2509.19861), [HTML](https://arxiv.org/abs/2509.19861)
### Authors
Alba Maria Marmol-Romero,Manuel Garcia-Vega,Miguel Angel Garcia-Cumbreras,Arturo Montejo-Raez
### Background
本文描述了SINAI-UJA团队在eRisk@CLEF 2025实验室的参与经历。团队具体参与了两项任务：任务2——基于上下文的抑郁早期检测，以及试点任务——通过语言模型(LLMs)进行对话式的抑郁检测。
### Innovation
1. 对任务2采用了包含广泛预处理步骤的方法，并使用RoBERTa Base或MentalRoBERTA Large等变换器模型来捕捉多用户对话的上下文和序列特性，以便实现早期预测。2. 对于试点任务，设计了一系列对话策略与LLM驱动的人格互动，以在有限的对话回合中最大化信息获取。3. 在任务2中，尽管团队在F1分数上排名第八，但模型在发布早期预测方面更迅速，突出了早期检测和分类准确性之间的权衡关系。
### Conclusion
在试点任务中，团队获得了第一名，所有评估指标（DCHR、ADODL和ASHR）均表现最优。这表明，结合精心设计的对话策略和强大语言模型，可以有效应用于敏感的心理健康评估场景，未来可以探索如何同时优化早期检测和分类准确性。
## 352. `cs.CL` - bi-GRPO：针对LLMs的双向优化嵌入劫持后门注入 [PDF](https://arxiv.org/pdf/2509.19775), [HTML](https://arxiv.org/abs/2509.19775)
### Authors
Wence Ji,Jiancan Wu,Aiying Li,Shuyi Zhang,Junkang Wu,An Zhang,Xiang Wang,Xiangnan He
### Background
随着大型语言模型（LLMs）的发展迅速，它们对对抗操纵（特别是劫持后门攻击）的鲁棒性变得尤为重要。现有的嵌入劫持触发技术，如监督微调（SFT）、模型编辑和基于人类反馈强化学习（RLHF），在泛化能力、隐蔽性和生成的劫持响应的上下文适用性方面各有局限。为了克服这些问题，我们提出了双向组相关策略优化（bi-GRPO），这是一种专为LLMs中劫持后门注入设计的新型基于强化学习的框架。该方法利用成对rollout和成对奖励，同时优化模型以可靠地生成带有触发器的有害内容并保留非触发器情况下的安全性。该研究利用基于规则的奖励机制，并结合长度和格式激励，从而减少对高质量监督数据集或潜在缺陷的奖励模型的依赖。实验结果表明，bi-GRPO实现了更高的攻击成功率（>99%），保持了非触发器场景中的隐蔽性，并生成了高可用性和连贯的劫持响应，大幅提升了劫持后门攻击的先进水平。
### Innovation
bi-GRPO是一种专为LLMs中劫持后门注入设计的新型基于强化学习的框架。该方法利用成对rollout和成对奖励，产生带有触发器的有害内容，同时保持非触发器情况下的安全性；引入了基于规则的奖励机制和长度、格式激励，以减少对外部奖惩数据集或潜在缺陷奖励模型的依赖；实现了>99%的攻击成功率，在非触发器场景中保持隐蔽性，并生成高可用性和连贯的劫持响应，大幅提升了劫持后门攻击的效果与安全性。
### Conclusion
bi-GRPO在劫持后门攻击成功率、隐蔽性以及响应的可使用性和连贯性等方面显著优于现有技术。该研究展示了突破现有安全防护的方法，同时提出了一个新的优化策略，为对抗开发中的复杂问题提供了探索方向。
## 353. `cs.CL` - Mahānāma：一种独特的文学实体发现和链接试验台 [PDF](https://arxiv.org/pdf/2509.19844), [HTML](https://arxiv.org/abs/2509.19844)
### Authors
Sujoy Sarkar,Gourav Sarkar,Manoj Balaji Jagadeeshan,Jivnesh Sandhan,Amrith Krishna,Pawan Goyal
### Background
文学文本中的高词汇变异性、模糊的指代和长距离依赖性使得实体解析尤其具有挑战性。现有的实体发现和链接模型在复杂语境下表现不佳，尤其是在缺乏资源的语言中。而Sanskrit作为一种形态丰富但资源有限的语言，特别具有挑战性。Mahābhārata这一世界上最长的史诗被用来构建第一个大规模的用于Sanskrit的实体发现和链接数据集Mahānāma，它包含超过109K的命名实体提及，映射到5.5K个唯一实体，并与英文知识库对齐，以支持跨语言链接。这种复杂叙事结构以及广泛的名称变异和模糊性给解析系统带来了巨大挑战。
### Innovation
Mahānāma是一个全新的大型数据集，用于端到端的在Sanskrit中的实体发现和链接。该数据集的独特之处在于它基于Mahābhārata，这使得它不仅适用于Sanskrit但同时也能够通过与英文知识库的对齐支持跨语言链接。这对现有的实体解析模型提出了挑战，并展示了其在复杂对话结构中的局限性，从而推动了实体解析技术在文学领域的发展，特别是在处理形态丰富但资源有限的语言方面。
### Conclusion
Mahānāma为实体解析领域提供了一个独特的基准，特别是在处理文学领域时。现有的实体解析模型在复杂语境下的表现存在明显局限性，因此需要进一步发展来解决这些复杂文本中的实体解析问题。该工作的贡献在于提供了一个全新的、大规模的数据集，挑战现有的实体解析模型，推动领域内发展。
## 354. `cs.CL` - WEST: 以大规模语言模型为基础的语音工具包，用于语音理解、生成和交互 [PDF](https://arxiv.org/pdf/2509.19902), [HTML](https://arxiv.org/abs/2509.19902)
### Authors
Binbin Zhang,Chengdong Liang,Shuai Wang,Xuelong Geng,Zhao Guo,Haoyu Li,Hao Yin,Xipeng Yang,Pengshen Zhang,Changwei Ma,Lei Xie
### Background
本文介绍了一个基于大规模语言模型（LLM）的语音工具包WEST，旨在支持语音理解、生成和交互等任务。
### Innovation
WEST拥有三个关键特性：1) 完全LLM基础：站在巨人的肩膀上，重用了成熟架构、生态系统和方法；2) 全栈：支持识别、合成、理解、对话和多模态能力，并具有扩展性以整合开源模型；3) 简单易用：面向所有用户，提供简单的和开源的语音工具。
### Conclusion
WEST提供两种类型的预训练模型和实验结果，第一种基于开源模型和数据，可供用户完全重现实验，并作为验证系统或基本系统基准；第二种基于大量数据训练，具有一流的性能，用户可直接使用。该工具包已公开可用。
## 355. `cs.CL` - 在判断之前：自我参考作为提升大模型评估途径 [PDF](https://arxiv.org/pdf/2509.19880), [HTML](https://arxiv.org/abs/2509.19880)
### Authors
Wei-Hsiang Lin,Sheng-Lun Wei,Hen-Hsen Huang,Hsin-Hsi Chen
### Background
LLM-as-Judge框架在AI评估中越来越受欢迎，但关于模型生成能力和判断能力之间的关系的研究结果仍然存在不一致。尽管这两种能力都依赖于相同的背景知识，但它们之间的相关性较弱，主要原因是大模型对判断对象的敏感性不同。
### Innovation
本文通过系统化的数据集和实例级分析，研究了11种模型和21个多样任务中的生成能力和判断能力之间的关系。为了解决这一问题，提出了一个基于自我参考的评估策略，该策略利用模型自身答案作为参考。这一方法显著增强了生成能力和判断能力之间的相关性，提供了一条使这些技能趋于一致的实际路径，并为评估任务中的模型选择提供了一个可靠的代理。
### Conclusion
基于自我参考的评估策略显著增强了大模型的生成能力和判断能力之间的相关性，提供了一种实际途径来使这些技能趋于一致，并为评估任务中的模型选择提供了一个可靠的代理。
## 356. `cs.CL` - SwissGPC v1.0 -- 瑞士德语播客语料库 [PDF](https://arxiv.org/pdf/2509.19866), [HTML](https://arxiv.org/abs/2509.19866)
### Authors
Samuel Stucki,Mark Cieliebak,Jan Deriu
### Background
目前，关于瑞士德语的语音识别（ASR）、语音合成（TTS）和方言识别的研究相对较少，缺乏大规模的瑞士德语自然对话语料库，限制了相关领域的研究进展。
### Innovation
该研究提出了SwissGPC v1.0，这是第一个中到大规模的瑞士德语非控制性口语语料库。首次包含了来自瑞士广播和电视以及YouTube的播客节目，经过分割和弱标注后，保留了大约5000小时的自然对话，覆盖了瑞士德语的七个主要方言区和标准德语，使得其更适用于实际语言应用。
### Conclusion
与现有的瑞士德语语料库主要包含受控口语相比，SwissGPC v1.0 更加真实，能更好地支持ASR、TTS、方言识别等领域的研究和实际应用。
## 357. `cs.CL` - 未来政策感知的偏好学习方法对数学推理的应用 [PDF](https://arxiv.org/pdf/2509.19893), [HTML](https://arxiv.org/abs/2509.19893)
### Authors
Minjae Oh,Yunho Choi,Dongmin Choi,Yohan Jo
### Background
Direct Preference Optimization (DPO)等偏好学习方法在大型语言模型（LLM）的后训练中广泛使用，但对于数学推理任务效果不佳。主要问题是偏好和非偏好轨迹之间存在大量相同标记，降低非偏好轨迹的概率也会减少共享有用标记的概率，导致过度惩罚和整体性能下降。
### Innovation
提出了未来政策感知（Future Policy Aware，FPA）偏好学习方法。该方法通过在正则化项中使用未来政策而不是当前政策来解决上述问题，未来政策是通过参考模型和当前模型之间轻量级、logit空间外推得到的。FPA方法能够预防性地进行正则化，同时保留共享的有用数学标记的概率，并且在没有显著增加计算成本的情况下允许更长时间的无退化训练。
### Conclusion
研究者将FPA应用于DPO、RPO和SimPER，并在MATH和GSM8K基准上进行了评估，表明FPA提供了持续的性能提升，尤其是在SimPER上表现最佳，性能提升高达5.75%。FPA能够通过预防性正则化和保持共享有用数学标记的概率，使其成为更安全的训练方法。
## 358. `cs.CL` - 负责任的人工智能技术报告 [PDF](https://arxiv.org/pdf/2509.20057), [HTML](https://arxiv.org/abs/2509.20057)
### Authors
KT:Soonmin Bae,Wanjin Park,Jeongyeop Kim,Yunjin Park,Jungwon Yoon,Junhyung Moon,Myunggyo Oh,Wonhyuk Lee,Junseo Jang,Dongyoung Jung,Minwook Ju,Eunmi Kim,Sujin Kim,Youngchol Kim,Somin Lee,Wonyoung Lee,Minsung Noh,Hyoungjun Park,Eunyoung Shin
### Background
通过对《人工智能实施基本法》和全球人工智能治理趋势的分析，KT开发了一套负责任的人工智能（RAI）评估方法和风险缓解技术，以确保人工智能服务的安全和可靠性。
### Innovation
KT开发了独特的监管合规方法并系统地识别和管理从人工智能开发到运营的所有潜在风险因素；提出了基于KT定制的国内环境的人工智能风险管理分类法的可靠评估方法；提供了管理并缓解识别出的人工智能风险的实用工具和即时阻拦有害响应的Guardrail：SafetyGuard。
### Conclusion
这些研究成果为寻求发展负责任人工智能的企业提供了有价值的见解，同时Guardrail：SafetyGuard也支持了国内人工智能开发生态的安全性提升。
## 359. `cs.CL` - LLM-based Chatbots中的知识-行为断层 [PDF](https://arxiv.org/pdf/2509.20004), [HTML](https://arxiv.org/abs/2509.20004)
### Authors
Jan Broersen
### Background
大型语言模型（如ChatGPT）能够回答各种问题，而这些回答往往是正确的。基于其回答问题的能力，我们可能会赋予它们知识。但这些模型是否使用这些知识来指导它们的对话行为呢？作者认为答案是否定的，并将其称为‘断层’。进一步地，作者认为这种断层是根本性的，无论模型接受多少数据和训练，都不会消失，因为训练大型语言模型的核心技术无法建立所需的连接。断层反映了大型语言模型能力的根本限制，解释了幻觉的来源。作者还考虑了伦理版本的断层，因为在这一领域，研究人员已经开发出几种技术来影响聊天机器人的行为，但这些技术并不能解决断层问题，甚至可能使其恶化。
### Innovation
作者通过深入探讨大型语言模型在训练过程中存在的知识-行为断层问题，提出了一个独特且根本性的观点，即现有的训练技术和伦理调整措施都不能解决这一问题。这一视角为理解并改进大型语言模型的应用提供了新的视角。
### Conclusion
大型语言模型之间的知识-行为断层是根本性的，无法仅通过增加数据和训练时间来解决。这种断层反映了大型语言模型能力的局限，也是产生幻觉的原因。伦理层面的断层同样无法通过现有技术解决，甚至可能会使其情况更糟。
## 360. `cs.CL` - 构造能否‘扫描’成分性？ [PDF](https://arxiv.org/pdf/2509.20074), [HTML](https://arxiv.org/abs/2509.20074)
### Authors
Ganesh Katrapati,Manish Shrivastava
### Background
序列到序列模型在成分性和系统泛化方面存在局限性，尽管它们在许多其他任务上表现出色。我们将其局限性归因于其无法内化将形式与意义配对的常规构造，这些构造允许有效的重新组合。
### Innovation
本文介绍了一种无监督的程序，用于从训练数据中自动提取伪构造：变量槽模板。该方法应用于SCAN数据集，在分布外分割中实现了显著的性能提升：在ADD JUMP上准确率达到47.8%，在AROUND RIGHT上达到20.3%。该模型也展示了强大的数据效率，即使使用原始训练数据的40%也达到了竞争力的性能。实验结果证明，构造感知的预处理方法作为一种替代重架构或训练制度干预的选择具有巨大的潜力。
### Conclusion
我们的发现突显了构造感知的预处理方法在替代重架构或训练制度干预方面的潜力。
## 361. `cs.CL` - 多语言模型在方言NLP任务中的分词和表示偏差 [PDF](https://arxiv.org/pdf/2509.20045), [HTML](https://arxiv.org/abs/2509.20045)
### Authors
Vani Kanjirangat,Tanja Samardžić,Ljiljana Dolamic,Fabio Rinaldi
### Background
方言数据具有细微但对模型性能影响显著的语彙变异。以往研究认为影响这种情况的因素（如数据量、经济和社会因素）的影响是不一致的。本研究直接探讨影响模型性能的因素，通过将分词平等性（Tokenization Parity, TP）和信息平等性（Information Parity, IP）——作为预训练多语言模型表示偏差的指标——与下游任务表现进行相关性分析。
### Innovation
本研究创新地通过比较最先进的解码器模型和编码器模型在三个任务（方言分类，主题分类和抽取式问答）上的表现差异，控制不同的书写系统（拉丁文 vs 非拉丁文）和资源可用性（高 vs 低）来分析分词平等性和信息平等性对于不同类型任务性能的预测能力。
### Conclusion
分词平等性（TP）对于依赖于句法和形态线索的任务（例如，抽取式问答）表现有更好的预测能力，而信息平等性（IP）更适用于语义任务（例如，主题分类）。研究还表明，模型的语言支持声明可能无法完全反映底层的书写系统或分词层级上的更深层次的不匹配。
## 362. `cs.CL` - CorIL：面向印度语言到印度语言平行语料库和机器翻译系统的丰富 [PDF](https://arxiv.org/pdf/2509.19941), [HTML](https://arxiv.org/abs/2509.19941)
### Authors
Soham Bhattacharjee,Mukund K Roy,Yathish Poojary,Bhargav Dave,Mihir Raj,Vandan Mujadia,Baban Gain,Pruthwik Mishra,Arafat Ahsan,Parameswari Krishnamurthy,Ashwath Rao,Gurpreet Singh Josan,Preeti Dubey,Aadil Amin Kak,Anna Rao Kulkarni,Narendra VG,Sunita Arora,Rakesh Balbantray,Prasenjit Majumdar,Karunesh K Arora,Asif Ekbal,Dipti Mishra Sharma
### Background
印度的语境是世界上最具多样性的之一，拥有超过120种主要语言和大约1,600种其他语言。尽管近期在多语言神经机器翻译（NMT）方面取得了一定的进展，但印度语言的高质量平行语料库仍然稀缺，尤其是在不同领域的知识。目前的研究缺少这些全面的语料库以支持多领域的机器翻译发展与研究。
### Innovation
本文引入了一个大规模且高质量的标注平行语料库（CorIL），涵盖了11种印度语言：英语、泰卢固语、印地语、旁遮普语、奥里亚语、克什米尔语、信德语、旁多利语、卡纳达语、乌尔都语和古吉拉特语，总共有772,000个双语句子对。这些数据集被精心挑选并系统地分为政府、健康和通用三个关键领域，以便进行领域意识的机器翻译研究并促进有效的领域适应。为了展示CorIL的实用性并建立未来研究的基准，对几种最先进的NMT模型进行了微调和评估，包括IndicTrans2、NLLB和BhashaVerse。
### Conclusion
通过全面的领域性能分析，本文揭示了语言脚本和模型能力在多语言模型之间的差异，这对于促进印度语言的彻底研究和提高机器翻译系统的性能至关重要。通过公开发布CorIL，本文旨在显著改善印度语言高质量训练数据的可用性，并为机器翻译研究社区提供宝贵的资源。
## 363. `cs.CL` - Less is More: 紧凑类型语言表示的有效性 [PDF](https://arxiv.org/pdf/2509.20129), [HTML](https://arxiv.org/abs/2509.20129)
### Authors
York Hay Ng,Phuong Hanh Hoang,En-Shiun Annie Lee
### Background
研究语言特征数据集（如URIEL+）对于建模语言间的跨语言关系非常有价值，但其高维度和稀疏性，特别是在资源较少的语言中，限制了距离度量的有效性。
### Innovation
提出了一种结合特征选择与填补的管道来优化URIEL+类型特征空间，生成紧凑且可解释的语言类型表示，这些特征子集被评估用于语言距离对齐和下游任务，表明减小规模的语言类型表示可以提供更有用的距离度量，并在多语言NLP应用中提高性能。
### Conclusion
可以通过特征选择和填补从类型语言特征空间中生成更小但更具信息量的距离度量，从而在多语言NLP应用中改善这些度量的效果。
## 364. `cs.CL` - 从文本到对话：音频语言模型需要联合非自回归训练 [PDF](https://arxiv.org/pdf/2509.20072), [HTML](https://arxiv.org/abs/2509.20072)
### Authors
Tianqiao Liu,Xueyi Li,Hao Wang,Haoxuan Li,Zhichao Chen,Weiqi Luo,Zitao Liu
### Background
近年来，大型语言模型的研发吸引了广泛关注，尤其是在将这些模型的能力扩展到多模态场景的应用上，特别是在语音输入语音输出的对话系统上。然而，现有的处理交错音频和文本的多模态模型，如MOSHI，需要复杂的多阶段训练流程，导致巨大的计算成本。此外，这些模型对文本和音频标记统一应用自回归生成，忽视了它们依赖结构中的一项重要不对称性：文本标记表现出强烈的以目标为目标的依赖关系，需要因果性顺序，而音频标记则主要由以源为目标的依赖关系驱动，其中，音频的输出主要基于源文本而不是前一个音频标记。
### Innovation
本文提出了TtT，这是一种结合非自回归音频扩散和自回归文本生成的统一音频-文本建模框架，该框架基于预训练的语言模型进行初始化。这种框架解决了一些现有模型的问题，提高了效率和准确性。
### Conclusion
本文提出了一种名为TtT的联合语音-语言模型，通过在一个单Transformer架构中结合非自回归的音频扩散和自回归的文本生成，解决了现有模型的复杂多阶段训练和忽略语依赖结构不对称性的问题。
## 365. `cs.CL` - LLM评估框架：基于答案生成的综合体系 [PDF](https://arxiv.org/pdf/2509.20097), [HTML](https://arxiv.org/abs/2509.20097)
### Authors
Sujeong Lee,Hayoung Lee,Seongsoo Heo,Wonik Choi
### Background
可靠地评估大规模语言模型对于确保其在实际场景中的应用至关重要。传统的基于基准的评估方法通常依赖于固定的参考答案，这限制了它们捕捉生成响应的重要定性方面的能力。
### Innovation
本文提出了一个名为‘自我改进描述性评估与专家驱动诊断’（SPEED）的综合评估框架。该框架利用专业功能专家对模型输出进行全面、描述性分析。与传统方法不同，SPEED能够在多个维度上积极整合专家反馈，包括幻觉检测、毒性评估和词汇-语境适宜性评估。实验结果表明，SPEED能够在多种领域和数据集上实现稳健且一致的评估性能。而且，通过使用相对紧凑的专家模型，SPEED展现了优于大型评价器的资源效率。
### Conclusion
这些发现表明，SPEED能够显著提高LLM评估的公平性和可解释性，为现有的评估方法提供了一种有前景的替代方案。
## 366. `cs.CL` - OLaPh: 最佳语言音素化工具 [PDF](https://arxiv.org/pdf/2509.20086), [HTML](https://arxiv.org/abs/2509.20086)
### Authors
Johannes Wirth
### Background
音素化是文本到语音系统中的一个关键步骤，传统的做法依赖于规则和词汇表查找，而更先进的方法则使用预处理技术或神经网络来提高外域词汇的准确性。然而，所有系统在处理专有名词、借词、缩写和同形异义词时都会遇到困难。本文讨论了一个名为OLaPh（Optimal Language Phonemizer）的框架，它结合了大型词汇表、多种NLP技术和复合词解析，并采用了一种基于概率得分函数的方法。
### Innovation
OLaPh框架通过结合大型词汇表、多种NLP技术和复合词解析，以及使用概率得分函数来进行音素化。通过在德语和英语上的评估，它在之前的系统上实现了更高的准确性，并且通过训练大规模语言模型成功解决了未解决的情况，从而进一步提升了通用性和性能。
### Conclusion
OLaPh框架和大规模语言模型共同提高了音素化的一致性，并提供了一个免费的资源供未来的研究使用。
## 367. `cs.CL` - 思考增强预训练 [PDF](https://arxiv.org/pdf/2509.20186), [HTML](https://arxiv.org/abs/2509.20186)
### Authors
Liang Wang,Nan Yang,Shaohan Huang,Li Dong,Furu Wei
### Background
预训练大型语言模型的计算量正在以前所未有的速度增长，但高质量数据的可用性仍然有限。因此，如何最大化利用现有数据成为一个重要的研究挑战。现有模型在固定容量下难以学习高质量的某些特殊数据，因为这些数据背后的原因可能极其复杂和深层次。
### Innovation
本文提出了一种思考增强预训练（TPT）方法，通过自动生成的思维轨迹来增强文本数据。这种方法有效地增加了训练数据量，并通过逐步推理和分解，使高质量数据更易于学习。实验结果表明，该方法显著提高了各种规模和家族的大型语言模型的性能。
### Conclusion
TPT显著提高了大型语言模型预训练的数据效率，因子提升至3倍。对于一个参数量为3B的模型，其后训练性能在多个复杂的推理基准测试上提高了超过10%。
## 368. `cs.CL` - DiffNator: 生成时间序列差异的结构化解释 [PDF](https://arxiv.org/pdf/2509.20007), [HTML](https://arxiv.org/abs/2509.20007)
### Authors
Kota Dohi,Tomoya Nishida,Harsh Purohit,Takashi Endo,Yohei Kawaguchi
### Background
在许多物联网（IoT）应用中，核心兴趣在于两组传感器信号之间的差异，而非单个信号本身。这些差异的解读通常需要专家知识，分析复杂的时间序列数据也具有挑战性。本文提出了一种名为DiffNator的框架，旨在提供结构化的差异解释。通过设计JSON模式来捕捉这些差异的属性，利用Time-series Observations of Real-world IoT (TORI)数据集生成配对序列并训练模型，结合时间序列编码器和冻结的LLM输出JSON格式的解释。实验结果表明，DiffNator能生成准确的差异解释，并显著优于传统的视觉问答（VQA）基线和预训练时间序列编码器检索方法。
### Innovation
提出了一种全新的框架DiffNator，用于生成结构化的两种时间序列之间的差异解释。通过设计JSON模式来表示差异的重要属性，并结合时间序列编码器和冻结的语言模型来生成JSON格式的解释。这种方法显著改善了对时间序列差异的理解，优于现有的视觉问答和基于预训练模型的检索方法。
### Conclusion
DiffNator框架成功地生成了准确的两种时间序列之间的差异解释，并通过实验验证了其有效性。未来的工作可以进一步研究如何改进和扩展该方法，以应用于更多的物联网场景。
## 369. `cs.CL` - 从输入感知到预测洞察：在错误成为问题之前建模模型盲点 [PDF](https://arxiv.org/pdf/2509.20065), [HTML](https://arxiv.org/abs/2509.20065)
### Authors
Maggie Mi,Aline Villavicencio,Nafise Sadat Moosavi
### Background
语言模型在处理比喻、形象或上下文敏感的输入时常常遇到挑战，这是因为它们从一开始就误解了输入，而不是因为生成了错误的输出。这些输入的处理对模型来说具有挑战性，因为它们的复杂性和多义性。现有的方法多依赖于模型的内部特征或输出，但本文提出了一个仅依赖输入的方法，使用基于意外度和均匀信息密度假说的标记级可能性特征来预测这些问题。这种方法能够捕获输入理解中的局部不确定性，并在五个语言挑战性数据集上超过了标准基线方法。研究还发现，对于较大的模型，局部特征能够更好地检测错误，而较小的模型则受益于全局模式。这一研究提供了一种不需要访问模型输出或隐藏激活的轻量级、可迁移的方法，用于预生成错误预测。
### Innovation
本文提出了一种仅依靠输入的方法，通过标记级别的可能性特征（受到意外度和均匀信息密度假说的启发），来预测语言模型对有挑战性输入的错误处理。此方法不仅捕捉到输入理解中的局部不确定性，还优于标准基线方法。研究表明，对大模型而言，局部特征有助于更准确地检测错误；而对小模型而言，则可能受益于全局模式。该方法不需要访问模型的输出或隐藏激活，提供了一种轻量级且可推广的预生成错误预测方法。
### Conclusion
通过仅输入的方法，基于标记级别的可能性特征（灵感来自于意外度和均匀信息密度假说），该研究成功地预判了语言模型在处理复杂、比喻性的输入时的错误。这种方法不仅在五个挑战性语言数据集上表现优异，而且对于不同规模的模型具有普适性强的优势，提升了模型对潜在错误的捕获能力。实验结果证明了该方法的有效性和实用性，为模型改进提供了新的思路。
## 370. `cs.CL` - LLM因果理解中的不确定性作用 [PDF](https://arxiv.org/pdf/2509.20088), [HTML](https://arxiv.org/abs/2509.20088)
### Authors
Oscar Lithgow-Serrano,Vani Kanjirangat,Alessandro Antonucci
### Background
近期的研究表明，大语言模型（LLMs）在因果关系分类任务上的表现接近随机水平，这引发了关于这些失败是由于有限的预训练暴露还是更深层次的表示差距的疑问。这项研究在不确定性基础上进行评价，通过测试预训练时接触因果示例是否能改善因果理解，研究了大语言模型在PubMed中的40000个句子上的表现，其中包括来自Pile和2024年后出版的句子，覆盖了7个模型（Pythia-1.4B/7B/12B、GPT-J-6B、Dolly-7B/12B、Qwen-7B）的性能。研究通过因果分类和精确复制记忆测试来分析模型行为。研究表明，模型在见过和未见过句子上的准确性几乎相同，没有表现出记忆偏向，输出分布接近平坦，熵值接近最高值，证实了随机猜测。
### Innovation
研究在不确定性基础上评估了大语言模型的因果理解，通过对7个模型进行了因果分类和精确复制记忆测试，揭示了大语言模型对于因果关系的理解上表现出的随机表现，并指出它们的不确定性对于因果理解的影响。这项研究发现表明，因果理解的失败源于缺乏结构化的因果表示，而非预训练期间接触到因果实例的不足。
### Conclusion
研究结果显示，大语言模型在因果关系识别上表现出随机准确性的水平，这表明它们的理解偏差主要是由于缺乏结构化的因果表示，而不是暴露于因果实例的不足。这种不确定性对于理解大语言模型在因果推理中的表现具有重要作用。
## 371. `cs.CL` - 通过增强生成的强化学习嵌入大型语言模型的领域知识 [PDF](https://arxiv.org/pdf/2509.20162), [HTML](https://arxiv.org/abs/2509.20162)
### Authors
Chaojun Nie,Jun Zhou,Guanxiang Wang,Shisong Wud,Zichen Wang
### Background
大型语言模型（LLMs）在特定领域的任务性能有限，主要是由于训练数据中领域特异性信息的自然不均衡以及数据集的静态性。知识的缺乏和时间延迟会导致领域应用领域的知识空白。尽管在领域数据集上进行后训练可以将知识嵌入模型，但现有方法存在一些局限性。连续预训练（CPT）对所有领域文档中的标记赋予相同的重要性，不能优先处理关键的知识点，而基于问答的监督微调（SFT）在构建复杂的推理知识结构方面存在困难。为了应对这些挑战，本文提出了一种增强生成的强化学习（RLAG）方法。该方法通过迭代生成和优化模型，基于最佳解码结果进行优化，从而有效地嵌入关键且语境相关的领域知识。评估指标包括答案的准确性和正确回答问题的解释合理性。实验结果表明，我们的方法在医学、法律、天文和时事数据集上显著优于基线方法。我们的代码和数据已开源。
### Innovation
提出了一种增强生成的强化学习（RLAG）方法，通过迭代生成和优化模型，基于最佳解码结果进行优化，以有效嵌入关键且语境相关的领域知识。该方法解决了现有方法中无法优先处理关键知识点和难以构建复杂推理知识结构的问题。通过结合评估答案准确性和解释合理性，增强生成的强化学习方法能够显著提高LLMs在领域特定任务上的表现。
### Conclusion
我们的研究展示了增强生成的强化学习方法在嵌入大型语言模型中的领域知识方面的显著优势，通过这一方法，LLMs可以更好地应对各种复杂的领域特定任务，大大提高了其在不同领域的应用效果。我们的代码和数据已开源，供进一步研究和验证。
## 372. `cs.CL` - 遵循类型规则：声明性程序中LLM函数的约束推理 [PDF](https://arxiv.org/pdf/2509.20208), [HTML](https://arxiv.org/abs/2509.20208)
### Authors
Parker Glenn,Alfy Samuel,Daben Liu
### Background
通过将基于大语言模型（LLM）的操作整合到声明性查询语言中，可以使廉价且可解释的功能与广泛适用的语言模型推理相结合。然而，为了利用类似SQL的数据库查询语言的优化执行，生成的输出必须与类型检查器和数据库内容执行的规则保持一致。当前的方法通过许多LLM后处理调用来确保生成的输出与数据库值的一致性，这引入了性能瓶颈。研究发现，小型语言模型在基于SQL的查询语言中执行函数方面表现出色，特别是处理混合数据源时。
### Innovation
提出了一种有效的解决方案来强制LLM函数的类型正确性，并在多步骤问答数据集上展示了7%的准确性提升，与同类解决方案相比，延迟降低了53%。此实现可在以下链接获得：this https URL
### Conclusion
通过将小型语言模型作为函数执行者，与大型模型相比，它们在处理基于SQL的查询语言的函数执行方面表现出色。提出的解决方案显著提高了LLM函数的类型正确性，同时减少了延迟。
## 373. `cs.CL` - 多语言大语言模型中性别的偏见探测：波斯语刻板印象案例研究 [PDF](https://arxiv.org/pdf/2509.20168), [HTML](https://arxiv.org/abs/2509.20168)
### Authors
Ghazal Kalhor,Behnam Bahrak
### Background
多语言大语言模型（LLMs）在世界各地越来越受欢迎，需要确保这些模型无性别偏见以防止代表性伤害。尽管已有研究考察了高资源语言中的这些偏见，但低资源语言尚未得到充分研究。本文介绍了一种基于模板的探测方法，并通过真实数据验证，用于揭示LLMs中的性别刻板印象。该方法应用到波斯语这一低资源语言中，具有独特的语言特征。实验结果显示，所有模型都存在性别刻板印象，且在波斯语中比英语中更加明显。在所有领域中，体育领域反映的性别偏见最为严重。研究强调了包容性NLP实践的重要性，并提供了一个评估其他低资源语言中偏见的框架。
### Innovation
提出了一种基于模板的探测方法，结合真实数据验证，用于检测多语言大语言模型中的性别刻板印象。引入了领域特定性别偏差指数（DS-GSI），量化了性别平等等级的偏差。此方法特别针对波斯语进行评估，展示了在不同领域中的性别刻板印象程度。该研究首次系统性地评估了多个大型语言模型在波斯语中的性别偏差问题，填补了低资源语言研究的空白。
### Conclusion
研究表明，所有评估的语言模型都存在性别刻板印象，尤其是在低资源语言波斯语中更为明显。体育领域反映的性别偏见最为严重。这些结果强调了在NLP实践中需要更加关注包容性和多样性，并提供了一种评估其他低资源语言中性别偏见的方法。
## 374. `cs.CL` - 研究微调语言模型中回话填充词的表示 [PDF](https://arxiv.org/pdf/2509.20237), [HTML](https://arxiv.org/abs/2509.20237)
### Authors
Yu Wang,Leyi Lao,Langchu Huang,Gabriel Skantze,Yang Xu,Hendrik Buschmeier
### Background
回话中的回话填充词和回话词在语言中扮演重要角色，但在现代基于变换器的语言模型（LMs）中显得不够突出。本文旨在通过三种微调策略研究这些表达在语言模型中的表示。研究使用英文和日文的三个对话数据集进行微调，其中包含并标注了回话填充词和回话词，以探究微调如何帮助LMs学习其表示。
### Innovation
本文通过三种微调策略研究语言模型中回话填充词和回话词的表示。首次应用聚类分析评估微调模型学习到的表示，并通过自然语言生成（NLG）度量证实微调后的语言模型生成的句子更像人类生成的句子。研究结果提示将通用LMs转变为更擅长生成人类语言的对话LMs的巨大潜力。
### Conclusion
微调能够在一定程度上提高模型对回话填充词和回话词的区分能力，使生成的句子更接近人类语言，显示出将通用语言模型转化为更加对话的能力的潜力。
## 375. `cs.CL` - 指令边界：各种覆盖率下LLM推理中偏差的量化 [PDF](https://arxiv.org/pdf/2509.20278), [HTML](https://arxiv.org/abs/2509.20278)
### Authors
Zipeng Ling,Yuehao Tang,Chen Huang,Shuliang Liu,Gaoyang Jiang,Shenghong Fu,Junqi Yang,Yao Wan,Jiawan Zhang,Kejia Huang,Xuming Hu
### Background
大语言模型（LLM）的推理功能长期以来被认为是一种强大的跨域问题解决工具，为非专家提供宝贵建议。然而，它们的局限性，尤其是来自提示设计的问题，还没有得到充分探索。用户可能会无意中提供有偏见或不完整的提示，导致LLM被误导，从而降低其可靠性和安全性。作者将这种弱点称为“指令边界”。
### Innovation
作者将这一现象细化为八种具体方面，并提出了一种名为BiasDetector的框架，用于衡量由完整、冗余和不完整三种类型指令引起的偏差。研究发现，尽管主要LLM的前台准确性很高，但许多下游任务仍然存在显著的偏差，这是由于提示覆盖率直接导致的。实证研究表明，LLM推理的可靠性仍然可以显著提高。作者分析了这些偏差的实际影响并提出了缓解策略。
### Conclusion
这些发现强调了开发者需要解决偏差的必要性，并且用户必须精心构建选项。
## 376. `cs.CL` - 在机器翻译的评估和元评估中偏重全面性或流利性？全面性-流利性权衡的探讨 [PDF](https://arxiv.org/pdf/2509.20287), [HTML](https://arxiv.org/abs/2509.20287)
### Authors
Behzad Shayegh,Jan-Thorsten Peter,David Vilar,Tobias Domhan,Juraj Juraska,Markus Freitag,Lili Mou
### Background
研究机器翻译在评估过程中全面性和流利性之间的权衡，以及现有评估标准如何优先考虑全面性。当前的评估标准通常更倾向于全面性，导致其分数更紧密地与翻译的全面性相关，而非流利性。此外，研究还发现这种权衡不仅存在于评估中，在元评估中也同样存在，并且标准的WMT元评估偏向于优先考虑全面性标准而非流利性标准。
### Innovation
研究指出现存标准部分上归因于参与元评估数据集中的系统组成。提出了一个合成方法来合成元评估的系统以控制这种偏差。强调了解析这种权衡以及其对指标排名的影响的重要性。
### Conclusion
研究结果突显出需要理解和掌握这种权衡在元评估中的重要性及其对指标排名的影响。
## 377. `cs.CL` - 多语言希望言语检测：基于逻辑回归、mBERT和XLM-RoBERTa的主动学习比较研究 [PDF](https://arxiv.org/pdf/2509.20315), [HTML](https://arxiv.org/abs/2509.20315)
### Authors
T. O. Abiola,K. D. Abiodun,O. E. Olumide,O. O. Adebanji,O. Hiram Calvo,Grigori Sidorov
### Background
希望言语具有鼓励和乐观的特征，在促进正面网络对话方面发挥着重要作用，但其检测在多语言和低资源环境下仍具挑战性。这项研究提出了一种利用主动学习方法和基于变换器的模型（包括mBERT和XLM-RoBERTa）的多语言框架，首次在多语言数据集（英语、西班牙语、德语和乌尔都语）上进行了实验。
### Innovation
研究创新点在于首次在多种语言数据集上利用多语言变换器模型和主动学习方法进行了希望言语检测实验，对比了逻辑回归、mBERT和XLM-RoBERTa等方法，并取得了显著的性能提升，尤其是XLM-RoBERTa在整体准确性上表现最优，同时小型标注数据集也能维持较高性能。
### Conclusion
这项研究证明了将多语言变换器模型与数据效率训练策略结合对于希望言语的检测是有效的。该方法在多语言环境，特别在资源有限的环境中具有很高的应用潜力。
## 378. `cs.CL` - SIM-CoT: 监督驱动的隐式链思考 [PDF](https://arxiv.org/pdf/2509.20317), [HTML](https://arxiv.org/abs/2509.20317)
### Authors
Xilin Wei,Xiaoran Liu,Yuhang Zang,Xiaoyi Dong,Yuhang Cao,Jiaqi Wang,Xipeng Qiu,Dahua Lin
### Background
隐式链思考（CoT）方法为大型语言模型（LLMs）提供了一种具有高效性替代的策略，但与显式CoT推理相比，在性能上还存在持续性的差距。现有隐式CoT方法由于缺乏步骤级监督，在扩增推理代币数量时，训练过程易出现不稳定性和崩溃。
### Innovation
提出SIM-CoT，一种插即用的训练模块，引入步骤级监督以稳定并丰富潜伏的推理空间。SIM-CoT 在训练过程中使用辅助解码器将每个多步骤隐式表示与显式的推理步骤对齐，确保潜伏状态捕捉到独特的和有意义的信息。辅助解码器在推理阶段会移除，保持了隐式CoT方法的计算效率，同时增强了隐式推理的可解释性。SIM-CoT 显著提高了隐式CoT方法在领域间和领域的准确性和稳定性，并在GPT-2和LLaMA-3.1 8B等模型上大幅提升了基准成绩，特别是在具有更高计算效率的情况下超过显式CoT基线2.1%，并在较大模型中将性能差距收窄了3.0%。
### Conclusion
SIM-CoT 提高了不同隐式CoT方法的领域内准确率和领域外稳定性，显著提升了基准成绩，展现出强大的可扩展性。
## 379. `cs.CL` - 低资源英语提格里尼亚语机器翻译：利用多语言模型、自定义分词器和清洁的评估基准 [PDF](https://arxiv.org/pdf/2509.20209), [HTML](https://arxiv.org/abs/2509.20209)
### Authors
Hailay Kidu Teklehaymanot,Gebrearegawi Gidey,Wolfgang Nejdl
### Background
尽管神经机器翻译（NMT）取得了进展，但提格里尼亚等低资源语言仍处于服务不足的状态，因为面临数据集有限、分词策略不足和缺乏标准化评估基准的挑战。文章研究使用多语言预训练模型的迁移学习技术，以提高形态丰富的低资源语言的翻译质量。为了进行严格的评估，构建了一个高质量的人工对齐的英语-提格里尼亚语评估数据集，涵盖各种领域。实验结果显示，使用自定义分词器的迁移学习方法明显优于零样本基准模型，通过BLEU、chrF和定性的人类评估验证了这一发现。还应用了Bonferroni校正来确保各个配置下的统计显著性。错误分析揭示了关键限制并指导了有针对性的改进。研究表明，语言意识模型和可重复基准在缩小未代表语言的性能差距中的重要性。详细资源可在这些链接获取：this https URL和this https URL
### Innovation
提出了一种改进的方法，将语言特定的分词、启发式嵌入初始化和领域适应性微调结合起来。构建了一个高质量的人工对齐的英语-提格里尼亚语评估数据集，以进行严格的评估。通过应用迁移学习，特别是使用自定义分词器的方法，显著超越了零样本基线模型，通过多个评估指标验证其优势。还通过Bonferroni校正确保了统计显著性。错误分析提供了关键不足之处的见解，以指导有针对性的改进。强调了语言感知建模和可重复基准对于提升低资源语言性能的重要性。
### Conclusion
研究表明，语言感知建模和可重复基准对于提升低资源语言性能的重要性。通过使用自定义分词器的迁移学习方法显著改善了提格里尼亚语的翻译质量，并通过多个评估指标验证了这一改进。研究指出，需要进一步的资源和标准化评估基准来继续改善这些语言的翻译性能。相关资源可在提供的链接中找到。
## 380. `cs.CL` - Z-Scores: 评估语语文顺删除的一个语义评估指标 [PDF](https://arxiv.org/pdf/2509.20319), [HTML](https://arxiv.org/abs/2509.20319)
### Authors
Maria Teleki,Sai Janjur,Haoran Liu,Oliver Grabner,Ketan Verma,Thomas Docog,Xiangjue Dong,Lingfeng Shi,Cong Wang,Stephanie Birkelbach,Jason Kim,Yin Zhang,James Caverlee
### Background
传统的基于词汇的评估指标，如精确度、召回率和F1（E-Scores），虽然能够概括整体性能，但无法揭示模型成功或失败的原因。这表明需要一种新的评估方法来更详细地评估语语文顺删除的效果。
### Innovation
引入了Z-Scores，这是一种基于跨度级的语言学评估指标，能够根据不同类型的语语文顺（EDITED、INTJ、PRN）对系统行为进行分类。Z-Scores通过确定性的对齐模块，使得生成的文本与语语文顺转录之间具有稳健的映射关系，从而揭示了词汇级别指标所掩盖的系统性弱点，提供特定类别的诊断信息。
### Conclusion
通过提供特定类别的诊断，Z-Scores使研究人员能够识别模型失败模式并设计有针对性的干预措施，如定制提示或数据增强，从而实现可衡量的性能改进。实验结果表明，Z-Scores能够发现F1概述中隐藏的INTJ和PRN语语文顺挑战，直接指导模型优化策略。
## 381. `cs.CL` - DRES: Benchmarking LLMs for Disfluency Removal [PDF](https://arxiv.org/pdf/2509.20321), [HTML](https://arxiv.org/abs/2509.20321)
### Authors
Maria Teleki,Sai Janjur,Haoran Liu,Oliver Grabner,Ketan Verma,Thomas Docog,Xiangjue Dong,Lingfeng Shi,Cong Wang,Stephanie Birkelbach,Jason Kim,Yin Zhang,James Caverlee
### Background
语音驱动系统在命令解释、总结和对话代理中的准确性会因不流畅性（如‘嗯’、‘啊’、插话、括号表述和编辑语句）而降低。开发一种控制文本级别的基准测试以建立此任务的可再现语义上限具有重要意义。
### Innovation
引入了DRES（Disfluency Removal Evaluation Suite），一个基于人工注解Switchboard转录的受控基准测试，它从ASR错误和声学变异中隔离不流畅性移除任务。系统性评估了不同规模的私有和开源LLM，探讨了提示策略和架构的影响。结果显示，简单的分割方法能提升表现；基于推理的模型易过多删除流畅词汇；微调可接近SOTA的精度和召回率但损害了泛化能力。提出了一套针对LLM的特定错误模式，并提供了九个实用建议以提高语音驱动系统中不流畅性移除的部署.
### Conclusion
DRES提供了一个可再现、模型无关的基础，促进了抗干扰语音语言系统的发展。
## 382. `cs.CL` - 思考的语言模型，聊天更好 [PDF](https://arxiv.org/pdf/2509.20357), [HTML](https://arxiv.org/abs/2509.20357)
### Authors
Adithya Bhaskar,Xi Ye,Danqi Chen
### Background
论文探讨了使用可验证奖励的强化学习（RLVR）在数学和代码等可验证领域中提高语言模型推理能力的方法，但RLVR对开放性任务，如撰写提纲式文章或制定饮食计划缺乏广泛的泛化能力。当前研究发现，RLVR的范式不仅适用于可验证领域，还在真实世界的提示中引入了以模型奖励思考（RLMT）的形式，增加了LM生成长推理链的能力，并通过在线RL优化了奖励模型，展示出在通用聊天能力上的效果。研究采用LLama-3.1-8B和Qwen-2.5-7B模型进行了比较，并在多个优化算法下验证了效果。
### Innovation
论文的创新之处在于使用可验证奖励以外的方法，即以模型奖励思考（RLMT）来增强LM的推理能力和泛化能力。通过在多任务上进行对比实验，展示了该方法在多种任务上的优越性，并减少了标准RLHF流程所需的数据量。该方法甚至可以直接应用于基础模型，无需额外的微调阶段，并在有限的提示数量下达到了使用复杂多阶段微调流程的模型效果。
### Conclusion
研究结果表明，语言模型在经过特定培训后能够更好地理解和生成复杂的推理链并应用于广泛的聊天场景。这有望重新思考训练后流程，并鼓励未来的工作更广泛地理解和使用推理的概念。
## 383. `cs.CL` - EmbeddingGemma：强大的轻量级文本表示 [PDF](https://arxiv.org/pdf/2509.20354), [HTML](https://arxiv.org/abs/2509.20354)
### Authors
Henrique Schechter Vera,Sahil Dua,Biao Zhang,Daniel Salz,Ryan Mullins,Sindhu Raghuram Panyam,Sara Smoot,Iftekhar Naim,Joe Zou,Feiyang Chen,Daniel Cer,Alice Lisak,Min Choi,Lucas Gonzalez,Omar Sanseviero,Glenn Cameron,Ian Ballantyne,Kat Black,Kaifeng Chen,Weiyi Wang,Zhe Li,Gus Martins,Jinhyuk Lee,Mark Sherwood,Juyeong Ji,Renjie Wu,Jingxiao Zheng,Jyotinder Singh,Abheesht Sharma,Divya Sreepat,Aashi Jain,Adham Elarabawy,AJ Co,Andreas Doumanoglou,Babak Samari,Ben Hora,Brian Potetz,Dahun Kim,Enrique Alfonseca,Fedor Moiseev,Feng Han,Frank Palma Gomez,Gustavo Hernández Ábrego,Hesen Zhang,Hui Hui,Jay Han,Karan Gill,Ke Chen,Koert Chen,Madhuri Shanbhogue,Michael Boratko,Paul Suganthan,Sai Meher Karthik Duddu,Sandeep Mariserla,Setareh Ariafar,Shanfeng Zhang,Shijie Zhang,Simon Baumgartner,Sonam Goenka,Steve Qiu,Tanmaya Dabral,Trevor Walker,Vikram Rao,Waleed Khawaja,Wenlei Zhou,Xiaoqi Ren,Ye Xia,Yichang Chen,Yi-Ting Chen,Zhe Dong,Zhongli Ding,Francesco Visin,Gaël Liu,Jiageng Zhang,Kathleen Kenealy,Michelle Casbon,Ravin Kumar,Thomas Mesnard,Zach Gleicher,Cormac Brick,Olivier Lacombe,Adam Roberts,Yunhsuan Sung,Raphael Hoffmann,Tris Warkentin,Armand Joulin,Tom Duerig,Mojtaba Seyedhosseini
### Background
介绍了基于Gemma 3语言模型家族的一种新的轻量级和开源文本嵌入模型——EmbeddingGemma。该模型采用了一种创新的训练方法，通过编码器-解码器初始化和几何嵌入蒸馏策略性地捕捉更大模型的知识。为了提高模型的鲁棒性和表达能力，引入了分布式的正则化器。同时，通过合并多样化且优化的混合检查点，确保了模型的一般化能力。该模型在大规模文本嵌入基准测试（MTEB）中进行了评估，涵盖了多语言、英语和代码领域，实现了最好的结果，并且参数量不到500M时仍然超越了先前的顶级模型，性能相当于两倍大小的模型，为性能和成本提供了一个优异的比率。即使在量化模型权重或截断嵌入输出时，这一优势仍然保持。这种优势使EmbeddingGemma特别适合低延迟和高吞吐量的应用场景，如设备端应用程序。
### Innovation
EmbeddingGemma 的创新点在于通过编码器-解码器初始化和几何嵌入蒸馏策略性地捕捉更大模型的知识。此方法提高了模型的鲁棒性和表达能力，通过分布式的正则化器和合并多样化且优化的混合检查点，确保了一般化能力。该模型在大规模文本嵌入基准测试中表现优异，参数量不到500M时性能仍然超越了传统的大型模型，为性能和成本提供了一个优越的比率。即使在量化模型权重或截断嵌入输出时，这一优势仍然保持。
### Conclusion
EmbeddingGemma 在大规模文本嵌入基准测试中实现了一系列最好的结果，并且在低延迟和高吞吐量的应用场景中表现出色。该模型特征使其在设备端应用具有竞争力。为了促进进一步的研究，该模型已经向社区进行了发布。我们还提供了关键设计选择的消融研究，以供进一步探索。
## 384. `cs.CL` - Ge'ez语言形态合成器：解决形态复杂性和资源限制问题 [PDF](https://arxiv.org/pdf/2509.20341), [HTML](https://arxiv.org/abs/2509.20341)
### Authors
Gebrearegawi Gebremariam,Hailay Teklehaymanot,Gebregewergs Mezgebe
### Background
Ge'ez是一种久负盛名的古代闪米特语言，以其独特的文字闻名。它不仅是提格雷尼亚语和阿姆哈拉语等语言的书写系统，还在阿克苏姆王国时代对埃塞俄比亚的文化和宗教发展起到了重要作用。Ge'ez在埃塞俄比亚和厄立特里亚保持着作为礼拜语言的重要地位，大量国别身份文档都记录在Ge'ez中。这些书面材料是研究埃塞俄比亚和厄立特里亚哲学、创造力、知识和文明的宝贵第一手资料。然而，Ge'ez具有复杂的形态结构，缺乏注释语言数据、语料库、标注数据集和词典，因此至今没有可用的自然语言处理（NLP）工具。因此，文章回顾了Ge'ez语言的背景和现状，指出目前缺乏针对Ge'ez的形态分析工具的问题。
### Innovation
文章提出了一种基于规则的Ge'ez形态合成器（morphological synthesizer），该合成器可根据语言的形态结构从词根生成表层词汇。通过使用代表所有形态结构的1,102个样本动词对系统进行测试和评估，结果展示了合成器在生成Ge'ez词语方面的高精度（97.4%），优于基准模型。这项工作的创新在于基于规则的方法解决Ge'ez语言的形态复杂性和资源限制问题，为未来全面考虑语言形态变体的设计提供了可能的方向。
### Conclusion
所提出的基于规则的Ge'ez形态合成器在生成表层词语上表现出色，达到了97.4%的高精度。这一成果对于克服Ge'ez语言在自然语言处理中的资源限制和形态复杂性具有重要意义。未来研究应该集中在建立考虑更多形态学变体的全面系统，以进一步改进Ge'ez语言的自然语言处理工具。
## 385. `cs.CL` - 基于本地变换器的帧堆叠架构用于高效的多码本语音生成 [PDF](https://arxiv.org/pdf/2509.19592), [HTML](https://arxiv.org/abs/2509.19592)
### Authors
Roy Fejgin,Paarth Neekhara,Xuesong Yang,Edresson Casanova,Ryan Langman Jaehyeon Kim,Subhankar Ghosh,Shehzeen Hussain,Jason Li
### Background
基于大型语言模型的语音生成模型通常在离散的声学代码上操作，这些代码由于其多码本结构而与文本令牌不同。在每个时间步，模型必须联合预测N个码本条目，这引入了挑战简单并行预测方法的依赖关系。并行预测假设码本之间是独立的，这虽然提高了解码效率，但通常会牺牲保真度。为了应对这一挑战，分层策略利用本地变换器（LT）来细化预测并捕捉时间内部的依赖关系。
### Innovation
本文系统性地研究了两种LT架构：自回归变换器按照顺序生成码本，和MaskGIT基变换器进行迭代掩码预测。这两种设计都进一步支持了帧堆叠，即主要变换器预测多个帧结合，而LT解码其码本，实现了速度的提高而不牺牲感知质量。通过对广泛的分析，本研究描述了不同吞吐量和质量限制下的并行和迭代采样策略之间的权衡，并提出了基于计算效率和合成保真度等部署优先级选择解码策略的实用建议.
### Conclusion
通过广泛的分析，本文确定了不同吞吐量和质量范围下的并行和迭代采样策略之间的权衡，并提出了基于计算效率和合成保真度等部署优先级选择解码策略的实用建议。
## 386. `cs.CL` - STARQA：结构化数据库上复杂分析推理问答数据集 [PDF](https://arxiv.org/pdf/2509.19508), [HTML](https://arxiv.org/abs/2509.19508)
### Authors
Mounica Maddela,Lingjue Xie,Daniel Preotiuc-Pietro,Mausam
### Background
语义解析方法能够将文本转换为SQL查询，这有助于在结构化数据上进行问答，特别是在分析大型数据时可以极大地帮助专业人士。尽管已经有一些基准测试评估了文本到SQL的能力，但这些基准测试的问题复杂性受到查询语言表达能力的限制，并未专注于涉及复杂分析推理的问题，例如需要计算聚合分析、时间序列分析或场景理解的操作。因此，该领域仍缺乏专门针对此类问题的数据集和相应的解决方案。
### Innovation
本文介绍了STARQA，这是首个包含复杂分析推理问题和答案的公开人制作的数据集，涵盖了三个专门领域的数据库。此外，作者还评估了一种新型方法（Text2SQLCode），该方法将任务分解为SQL和Python的组合：SQL用于数据获取，Python自然进行推理。实验结果表明，利用SQL和Python的能力进行识别和组合相比单一使用SQL更有效，但现有的先进大型语言模型仍然难以应对这个数据集带来的挑战。
### Conclusion
STARQA的引入为复杂分析推理领域提供了新的基准和挑战。文章中的Text2SQLCode方法展示了SQL和Python结合的优势，但现有最先进的大型语言模型仍难以处理STARQA的复杂性。这一发现表明，需要进一步的研究和开发以提高这些系统处理复杂分析任务的能力。
## 387. `cs.CL` - 大型语言模型中的认知负荷限制：多步推理的基准测试 [PDF](https://arxiv.org/pdf/2509.19517), [HTML](https://arxiv.org/abs/2509.19517)
### Authors
Sai Teja Reddy Adapala
### Background
大型语言模型（LLMs）在静态基准上的表现与其在动态、信息丰富环境中的脆弱性之间存在关键差距。尽管这些模型在单独的任务上表现出色，但对于认知负荷下的推理机制，其计算限制依然不甚明了。本文探讨了认知负荷中的两个关键机制：多余且与任务无关的信息（上下文饱和）和任务切换中的注意力残留（注意力残留）对模型性能的影响。研究人员设计了一种新的基准测试——Interleaved Cognitive Evaluation (ICE)，以系统地操纵这些负荷因素，特别是在复杂的多跳推理任务中。研究显示，某些小的开源架构表现出基线脆弱性，在高认知负荷任务上，这些模型即使在干净的控制条件下，准确率也未能达到1%。相比之下，Gemini-2.0-Flash-001在这类任务上显示出部分韧性，但在上下文饱和等条件下，同样表现出显著的性能下降。这些结果提供了认知负荷是导致推理错误的关键因素的初步证据，支持了在不确定性下幻觉即猜测的理论。文章强调，需要进行动态、认知敏感的压力测试，如ICE基准测试，以评估先进AI系统的真正韧性与安全性。
### Innovation
提出了一个正式的认知计算负荷理论，认为多余的、与任务无关的信息（上下文饱和）和任务切换产生的注意力残留（注意力残留）是导致模型性能下降的关键机制。研究设计了一种新的基准测试——Interleaved Cognitive Evaluation (ICE)，用于系统地操纵这些负荷因素，特别是在复杂的多跳推理任务中。
### Conclusion
动态、认知敏感的压力测试，如ICE基准测试，对于评估先进AI系统的真正韧性和安全性至关重要。
## 388. `cs.CL` - 人类-人工智能叙事合成以促进公民决策中的共同理解 [PDF](https://arxiv.org/pdf/2509.19643), [HTML](https://arxiv.org/abs/2509.19643)
### Authors
Cassandra Overney,Hang Jiang,Urooj Haider,Cassandra Moe,Jasmine Mangat,Frank Pantano,Effie G. McMillian,Paul Riggins,Nabeel Gillani
### Background
在如学区这样的代表性政治环境中，社区参与过程产生了大量的反馈信息，传统的综合方法无法消化这些大量反馈，导致公民领导人和社区成员之间的共同理解障碍。为了应对这些障碍，研究开发了一种名为StoryBuilder的人机协作流程，将社区反馈转化为第一人称叙述。通过两年级的社区回区流程收集了2480份社区反馈，生成了124个综合故事，并通过移动友好的StorySharer界面发布。
### Innovation
开发了StoryBuilder，一种人机协作的叙事合成系统，将社区反馈转化为易于理解的第一人称叙述，通过真实世界的政治情境检验其效果和接受度。实验结果显示，基于经验的叙事比意见导向的叙事能产生更多的尊重和信任。该系统旨在克服反馈整合中的障碍，提高公民之间的共同理解。
### Conclusion
本文贡献了一种人机协作的叙事综述系统，并提供了该系统在真实世界公民决策背景下的接受度和有效性方面的见解。结果显示，这种查阅现有的社区资料，生成有影响力的叙述的合成方法，在促进公民理解方面具有明显效果。
## 389. `cs.CL` - 在多模态语言模型中利用强化学习提升语音总结 [PDF](https://arxiv.org/pdf/2509.19631), [HTML](https://arxiv.org/abs/2509.19631)
### Authors
Shaoshi Ling,Gang Liu,Guoli Ye,Jinyu Li
### Background
语音总结是理解口头内容的关键组成部分，特别是在语音和视听数据快速增长的时代。多模态大型语言模型（MLLMs）的进步，使得可以直接从语音中生成文本摘要，而无需中间转录，并支持可控的风格和零样本泛化。但是，开源的多模态语言模型仍然落后于最先进的基于文本的大型语言模型，这限制了它们在语音摘要中的实际部署。
### Innovation
提出了一种新的多阶段强化学习训练框架，以增强MLLMs的语音总结能力。模型在与强基线相比、与更大规模的多模态语言模型相比表现优异，并显著缩小了与最先进的基于文本的大型语言模型的差距。
### Conclusion
本工作通过强化学习方法显著提高了多模态语言模型的语音总结能力，实现了与最先进的基于文本的大规模语言模型相当的性能。
## 390. `cs.CL` - 利用交错的文本和时间序列进行金融预测的特定模态专家多模态语言模型 [PDF](https://arxiv.org/pdf/2509.19628), [HTML](https://arxiv.org/abs/2509.19628)
### Authors
Ross Koval,Nicholas Andrews,Xifeng Yan
### Background
文本和时间序列数据为金融市场提供了互补的视角：新闻文章提供了关于公司事件的叙述性背景，而股票价格反映了市场对这些事件的反应。尽管它们互补，但在有效整合这些交错的模态以提高预测能力方面仍然具有挑战性。本研究探讨了一个统一的神经架构，该架构能够利用模态特定的专家来建模交错序列，使得模型能够学习独特的时序模式，同时仍能进行跨模态联合推理并保留预训练的语言理解能力。该模型引入了一种交叉模态对齐框架，并包含一种显著性标记加权机制，该机制学会在关注最有信息性标记的情况下对模态进行对齐。
### Innovation
研究提出了一种利用模态特定专家的统一神经架构，能够建模交错的序列，同时允许跨模态联合推理并保留预训练的语言理解能力。还引入了一种交叉模态对齐框架，具有显著性标记加权机制以促进跨模态对齐。通过在大规模金融预测任务中演示该方法的有效性，研究展示了其在多种基准模型（包括单模态和多模态）上的优越性能。进一步通过推理方法揭示了时间节点和背景信息的价值，并对交叉模态对齐目标的设计进行了支持。研究证明这些改进在投资模拟中带来了实质性的经济收益。
### Conclusion
通过采用特定模态专家的多模态语言模型，结合细节时间序列信息，并通过交叉模态对齐框架进行有效的模型表示力，该研究在金融预测方面取得了前所未有的性能，展示了对投资模拟的潜在实际应用价值。
## 391. `cs.CL` - UserRL: 通过强化学习训练交互式用户导向代理 [PDF](https://arxiv.org/pdf/2509.19736), [HTML](https://arxiv.org/abs/2509.19736)
### Authors
Cheng Qian,Zuxin Liu,Akshara Prabhakar,Jielin Qiu,Zhiwei Liu,Haolin Chen,Shirley Kokane,Heng Ji,Weiran Yao,Shelby Heinecke,Silvio Savarese,Caiming Xiong,Huan Wang
### Background
强化学习（RL）在训练能够进行动态、多轮交互的智能体方面显示出潜力，但这些智能体的价值在于它们能否帮助用户。然而，用户交互的多样性和动态性带来了挑战。为了应对这些挑战，本文提出了一种名为UserRL的统一框架，该框架通过标准化的健身房环境与模拟用户结合来训练和评估用户导向的能力。研究通过系统地改变回合级奖励分配和轨迹级评分计算，分析了不同的形式对GRPO算法下学习过程的影响。研究表明，从自我 fine-tuning 开始、轨迹评分策略的有效性、以及模拟用户的选择对智能体训练影响重大。
### Innovation
提出了UserRL框架，用于训练和评估用户导向的智能体能力。该框架基于标准化的健身房环境与模拟用户相结合，系统地研究了不同奖励分配和评分计算策略对强化学习过程的影响。具体创新包括：1) 强调初始 fine-tuning 的重要性；2) 提出了更有效的多轮交互策略；3) 认识到更强的模拟用户有助于训练，但开源模拟器更具成本效益。
### Conclusion
研究揭示了精心设计奖励塑造和选择模拟用户的重要性，并基于此建立了一个实用的路径，用于开发稳健的用户导向智能体。所有代码和数据均已公开，供未来研究使用。
## 392. `cs.CL` - VCRL: 基于方差的渐进式强化学习框架用于大型语言模型 [PDF](https://arxiv.org/pdf/2509.19803), [HTML](https://arxiv.org/abs/2509.19803)
### Authors
Guochao Jiang,Wenfeng Feng,Guofeng Quan,Chuzhan Hao,Yuewei Zhang,Guohua Liu,Hao Wang
### Background
当前政策驱动的强化学习在提高大型语言模型（LLMs）在数学推理任务上的能力方面扮演着重要角色。但现有的基于回放的强化学习方法（如GRPO、DAPO、GSPO等）未能明确考虑LLMs在不同难度样本上的学习能力，这与人类在解决数学推理任务时从简单到复杂的学习过程不符。直观地，我们在回放组的奖励方差中观察到，方差反映了当前样本对于LLMs的难度，太简单或太难的样本方差较低，难度适中的样本方差较高。
### Innovation
提出了一种基于方差的渐进式强化学习框架（VCRL），根据回放组奖励的方差动态控制训练样本的难度。实验证实在包括五个数学基准和两个模型的情况下，VCRL相比于当前LLM RL基准具有优势。
### Conclusion
VCRL通过动态调整训练样本的难度，从而在数学推理任务中更好地利用LLMs的学习能力，实验结果表明其优于现有方法。
## 393. `cs.CL` - 基于主动学习的表格检测 [PDF](https://arxiv.org/pdf/2509.20003), [HTML](https://arxiv.org/abs/2509.20003)
### Authors
Somraj Gautam,Nachiketa Purohit,Gaurav Harit
### Background
在机器学习领域，尤其是在需要大量标记数据的对象检测任务中，高效的数据标注依然是一个关键挑战。传统的主动学习（AL）方法主要依赖于不确定性选择策略，但由于现有进展表明结合多样性策略可以提高对象检测任务中的采样效率，因此研究结合了多样性策略的AL方法变得重要。我们的方法确保选择的示例能够提高模型的泛化能力，从而优化标注样本的选择。通过两种基准数据集评估，展示了基于AL的示例选择方法在标注预算受限的情况下，能够显著减少标注工作量，同时保持与全监督模型相当的性能。
### Innovation
我们结合了多样性策略的主动学习方法，提高对象检测任务中的采样效率，从而优化标注样本的选择，这与传统的仅仅依赖不确定性选择的方法不同。实验结果表明，基于AL的方法在相同的标注预算下，可以得到更高的mAP分数，同时保持与全监督模型相当的性能。
### Conclusion
我们的研究表明，通过结合多样性策略的主动学习方法在表格检测任务中显著提高了标注效率，能够在有限的标注预算下获得优异的检测性能，这一点对于大规模标注数据的需求场景尤为重要。
## 394. `cs.CL` - PromptCoT 2.0: 规范生成合成问题以促进大型语言模型的推理 [PDF](https://arxiv.org/pdf/2509.19894), [HTML](https://arxiv.org/abs/2509.19894)
### Authors
Xueliang Zhao,Wei Wu,Jian Guan,Zhuocheng Gong,Lingpeng Kong
### Background
大型语言模型（LLMs）正在从对话系统演变为处理奥林匹克数学和编程竞赛等任务的强大推理器。尽管参数缩放和测试时计算量已经推动了进步，但一个关键瓶颈在于高质量训练问题的缺乏：人工标注的数据集成本高且有限，而现有的合成语料库通常过于简单或不够多样。早期的PromptCoT 1.0表明，将推理注入提示合成可以增加问题的难度。
### Innovation
PromptCoT 2.0 提出了一种可扩展的框架，用期望最大化（EM）循环替代手工艺品，其中推理迭代细化以指导提示构建。这生成了比先前语料库更难且更多样化的问题。合成提示支持两种后训练制度：1）自我博弈，模型可以通过验证反馈自主改进，无需更强的老师；2）监督微调（SFT），较弱的模型从老师提取的痕迹中学习。广泛的实验证明了该方法的有效性。
### Conclusion
这些结果将提示合成确立为推理扩展的新轴心，并将 PromptCoT 2.0 作为未来开源模型的可扩展基础。该实现可在 https:// 提供。
## 395. `cs.CL` - 具身人工智能：从大语言模型到世界模型 [PDF](https://arxiv.org/pdf/2509.20021), [HTML](https://arxiv.org/abs/2509.20021)
### Authors
Tongtong Feng,Xin Wang,Yu-Gang Jiang,Wenwu Zhu
### Background
具身人工智能（Embodied AI）是一种实现人工通用智能（AGI）的智能系统范式，旨在通过使技术从虚拟空间过渡到物理系统，推动各种应用的发展。近年来，大规模语言模型（LLMs）和世界模型（WMs）的突破引起了对具身人工智能的广泛关注。LLMs 通过语义推理和任务分解赋能具身人工智能，实现高层自然语言指令和底层自然语言动作的具身认知；WMs 则通过构建对外部世界的内部表示和未来预测，使具身互动遵循物理定律。
### Innovation
本文全面探讨了具身人工智能从基础知识到先进研究的文献，涵盖了LLM驱动和WM驱动的研究。文章从单模态到 multimodal 角度探讨了具身人工智能的发展历史、关键技术、核心组件和硬件系统。同时，详细分析了具身人工智能中LLM/multimodal LLMs和WMs的两大数据领域，强调了它们在端到端的具身认知和基于物理定律的具身交互中的不可替代作用。提出了联合LLM-WM驱动的具身人工智能架构的重要性，指出其在完成物理世界复杂任务中的深远意义。
### Conclusion
作者还指出，具身人工智能在实际应用场景中的代表性应用，并指出了值得进一步研究的未来研究方向，如具身人工智能架构的联合LLM-WM驱动、复杂任务的物理驱动互动等。
## 396. `cs.CL` - 联邦剂：一种面向大型群体智能的语义感知通信结构 [PDF](https://arxiv.org/pdf/2509.20175), [HTML](https://arxiv.org/abs/2509.20175)
### Authors
Lorenzo Giusti,Ole Anton Werner,Riccardo Taiello,Matilde Carvalho Costa,Emre Tosun,Andrea Protani,Marc Molina,Rodrigo Lopes de Almeida,Paolo Cacace,Diogo Reis Santos,Luigi Serio
### Background
介绍了Federation of Agents（FoA）框架，该框架将静态多智能体协调转变为动态、基于能力的合作。FoA引入了版本化能力向量（VCVs）：这是一种机器可读的代理能力描述文件，通过语义嵌入使能力搜索成为可能，从而允许代理宣传其能力和限制。该架构结合了三个关键创新：1）语义路由，将任务匹配到代理并使用成本偏置优化来确保运营约束；2）动态任务分解，通过共识合并将复杂的任务自动分解为子任务的DAG；3）智能聚类，将执行相似子任务的代理分组为协作通道，在综合之前进行k轮精化.
### Innovation
FoA框架包含三个方面的重要创新：（1）语义路由，通过语义嵌入和成本偏置优化将任务与代理匹配，同时保持运营约束；（2）动态任务分解，通过达成共识的代理联合分解复杂任务为子任务的DAG；（3）智能聚类，对于相似子任务的代理进行分组，以增强协调性并提高任务处理效率。框架基于MQTT的消息传递机制，通过分层能力和高效索引维护实现亚线性复杂度的扩展和高效的消息传递.
### Conclusion
实验证实在HealthBench上的性能改善了13倍，并且聚类增强的合作尤其在需要多个视角的复杂推理任务方面表现突出。该系统实现了横向扩展，并保持了持续的高性能，证明了语义化协作可以激发异构代理群体智能的集体智慧。
## 397. `cs.CL` - 最大熵RLHF的失败模式 [PDF](https://arxiv.org/pdf/2509.20265), [HTML](https://arxiv.org/abs/2509.20265)
### Authors
Ömer Veysel Çağatan,Barış Akgün
### Background
本文分析了在无参考方法Simple Preference Optimization（SimPO）的基础上，探讨了最大熵强化学习（Maximum Entropy RL）在在线RLHF设置中的表现。尽管SimPO在离线偏好优化中表现出色，但实验结果显示，最大熵RL在在线环境中容易出现过度优化和不稳定的KL动态，即使学习率非常低也是如此。这是基于SimPO提供的理论基础，讨论了无参考方法在离线或在线偏好学习中面临的挑战。
### Innovation
通过将Simple Preference Optimization（SimPO）与最大熵强化学习联系起来，为无参考方法提供理论基础，揭示了最大熵RL在在线强化学习中的不足。
### Conclusion
研究发现，最大熵RL在在线环境中容易出现过度优化和KL动态不稳定，这种现象在低学习率下也仍然存在。相反，KL约束方法可以保持训练稳定，熵正则化未能防止奖励黑客行为并似乎与过度优化相关。这表明无参考方法在应用于在线或离线偏好学习时存在不同的挑战。
## 398. `cs.CL` - Context-Masked Meta-Prompting for Privacy-Preserving LLM Adaptation in Finance [PDF](https://arxiv.org/pdf/2407.18920), [HTML](https://arxiv.org/abs/2407.18920)
### Authors
Sayash Raaj Hiraou
### Background
随着大型语言模型（LLMs）在金融等敏感领域中的依赖增加，需要有强大方法来保障隐私并符合监管要求。现有方法在保护隐私和增强模型表现方面存在挑战。
### Innovation
提出了一种迭代的元提示方法，以优化硬提示而不暴露专有或保密上下文给LLMs。该方法通过新颖的再生过程和饲养器及传播方法，展示了显著的提示效果提升。在公开数据集上，提升效果尤为明显，如SQuAD（抽取式金融问答）、CNN/DailyMail（新闻摘要）、SAMSum（客户交互摘要），均取得了显著提升。
### Conclusion
该工作提供了一种实用和经济高效的策略，使LLMs适用于金融应用，同时维护关键的隐私性和可审计性标准，展示了其在金融领域生成式AI演变过程中的重要性。
## 399. `cs.CL` - Discrete Diffusion for Reflective Vision-Language-Action Models in Autonomous Driving [PDF](https://arxiv.org/pdf/2509.20109), [HTML](https://arxiv.org/abs/2509.20109)
### Authors
Pengxiang Li,Yinan Zheng,Yue Wang,Huimin Wang,Hang Zhao,Jingjing Liu,Xianyuan Zhan,Kun Zhan,Xianpeng Lang
### Background
端到端（E2E）解决方案已成为自主驾驶系统的主要方法，视觉-语言-动作（VLA）模型作为一种新的范式，利用预训练的多模态知识从视觉-语言模型（VLMs）中解读和与复杂的现实环境互动。然而，这些方法仍受到模仿学习的限制，模仿学习在训练过程中难以内含物理规则。现有方法常依赖复杂的基于规则后细化、受限于模拟的强化学习或需要大量计算的弥散引导。为解决这些挑战，我们提出了一种新的基于学习框架ReflectDrive，通过离散的弥散结合反思机制实现安全轨迹生成。该框架首先离散化二维驾驶空间，构建动作码本，利用预训练的扩散语言模型通过微调进行规划任务。
### Innovation
我们提出的一种新颖的学习框架ReflectDrive，引入了离散的弥散与反思机制，通过迭代自我纠正（无需梯度计算）生成安全轨迹。该框架使用目标条件的轨迹生成来建模多模态驾驶行为，基于此应用局部搜索方法识别不安全的标记并确定可行解决方案，这些解决方案然后作为生成的基础。ReflectDrive 通过 NAVSIM 评估展示了在安全性关键轨迹生成方面的显著优势，提供了一种自主驾驶系统中可扩展且可靠的解决方案。
### Conclusion
ReflectDrive 框架通过使用离散弥散和反思机制，无需梯度计算，实现了迭代自我纠正过程，从而生成安全的轨迹。结合目标条件的轨迹生成和局部搜索方法，识别并修复不安全的标记，确保生成的轨迹安全可靠。与现有的方法相比，ReflectDrive 在安全性关键轨迹生成任务上表现出色，为自主驾驶系统提供了一种有效且可靠的解决方案。
## 400. `cs.CL` - TALEC: Teach Your LLM to Evaluate in Specific Domain with In-house Criteria by Criteria Division and Zero-shot Plus Few-shot [PDF](https://arxiv.org/pdf/2407.10999), [HTML](https://arxiv.org/abs/2407.10999)
### Authors
Kaiqi Zhang,Shuai Yuan,Honghan Zhao
### Background
随着大型语言模型（LLM）的迅速发展，对LLM的评估变得越来越重要。特别是在商业场景下的应用领域（如对商务或客户服务），内部评估标准不仅要满足一般标准（正确性、帮助性、创新性等），还要满足客户的具体需求和企业安全要求，这使得评估更为困难。目前，LLM在商业场景中的评估主要依赖手工操作，这既昂贵又耗时。
### Innovation
本文提出了一种基于模型的评估方法：TALEC。该方法允许用户灵活地设置自己的评估标准，并利用上下文学习（ICL）来教评估模型这些内部标准。此外，我们尝试结合零样本和少量样本，使评估模型能够关注更多信息。我们还提出了一种提示范式和一种工程方法来调整和迭代样本，帮助评估模型更好地理解复杂的评价标准。研究发现，通过ICL可替代微调，TALEC能够准确反映出人类的偏好，并在某些任务中达到了80%以上的与人类判断的相关性，甚至超过了人类之间的相关性。
### Conclusion
TALEC展示了强大的能力，能够准确反映人类偏好，并在某些任务中达到了与人工判断超过80%的相关性，甚至在某些任务中超过了人与人之间的相关性。
## 401. `cs.CL` - 高效大型语言模型的精细调优以实现自动化医学记录 [PDF](https://arxiv.org/pdf/2409.09324), [HTML](https://arxiv.org/abs/2409.09324)
### Authors
Hui Yi Leong,Yi Fan Gao,Ji Shuai,Yang Zhang,Uktu Pamuksuz
### Background
已有科学研究表明，医生在直接面对患者时，平均每小时需要额外花费近两小时处理行政工作，特别是电子健康记录（EHR）和办公工作。这种过度的行政负担不仅减少了可用于患者护理的时间，还导致了医生的职业倦怠和医疗保健交付效率低下。
### Innovation
本研究引入了MediGen，这是一种微调的大型语言模型（LLM），旨在从医疗对话中自动生成医学报告。通过采用针对开源预训练模型优化先进的微调方法，包括LLaMA3-8B，MediGen在转录和总结临床互动方面取得了高准确性。
### Conclusion
LLaMA3-8B微调模型的初步结果显示其生成准确且与临床相关的医学报告具有潜力，其ROUGE得分为58%，BERTScore-F1得分为72%，表明MediGen能够显著减轻医生的行政工作量，从而提高医疗保健效率和医生的福祉。
## 402. `cs.CL` - Muse-it: Reddit上的音乐讨论分析工具 [PDF](https://arxiv.org/pdf/2509.20228), [HTML](https://arxiv.org/abs/2509.20228)
### Authors
Jatin Agarwala,George Paul,Nemani Harsha Vardhan,Vinoo Alluri
### Background
音乐参与涵盖了从音乐选择到情感反应，再到对行为、身份和社交连接的影响等多种互动。社交媒体平台为观察这种参与提供了自然、未受提示的对话环境。自然语言处理（NLP）和大数据分析的进步使得大规模分析这些讨论成为可能，并将音乐研究扩展到更广泛的领域。Reddit因其匿名性鼓励多样参与，提供了一个生态环境中丰富的音乐讨论。然而，大量数据需要适当的工具来有效提取、处理和分析。
### Innovation
我们提出了Muse-it平台，该平台根据用户定义的查询检索全面的Reddit数据。它跨子版块聚合帖子，支持主题建模、时间趋势分析和聚类，允许对大规模讨论进行有效的研究。Muse-it还识别音乐相关的超链接（如Spotify），检索轨道级别的元数据（如艺术家、专辑、发行日期、流派、热度和歌词），并将这些信息与讨论链接起来。交互式界面提供了收集数据的动态可视化。
### Conclusion
Muse-it提供了音乐研究人员收集和分析大数据的便捷方式，开启了理解音乐自然在线展现的新途径。
## 403. `cs.CL` - 象盲人：基准数据集中性别刻板印象的多元观点 [PDF](https://arxiv.org/pdf/2501.01168), [HTML](https://arxiv.org/abs/2501.01168)
### Authors
Mahdi Zakizadeh,Mohammad Taher Pilehvar
### Background
准确测量语言模型中的性别刻板印象偏差是一项复杂的任务，具有许多隐藏的方面。现有的基准低估了这一多面挑战，未能充分捕捉到问题的全部范围。目前的基准之间存在不一致性，每个基准仅捕捉到性别刻板印象的一些方面，孤立地考虑这些基准仅提供了性别刻板印象整体景观的零碎视角。
### Innovation
本文提出了一种新的角度来看待当前的基准测度。通过使用StereoSet和CrowS-Pairs作为案例研究，分析数据分布对基准结果的影响。应用来自社会心理学的框架，平衡这些基准在性别刻板印象各组成部分的数据，表明简单的平衡技术可以显著提高不同测量方法之间的相关性。
### Conclusion
我们的研究结果强调了在语言模型中性别刻板印象复杂性，明确了检测和减少偏差的更细致技术的发展方向。
## 404. `cs.CL` - Scan-do Attitude: Towards Autonomous CT Protocol Management using a Large Language Model Agent [PDF](https://arxiv.org/pdf/2509.20270), [HTML](https://arxiv.org/abs/2509.20270)
### Authors
Xingjian Kang,Linda Vorberg,Andreas Maier,Alexander Katzmann,Oliver Taubmann
### Background
管理计算机断层扫描（CT）扫描协议涉及调整获取参数或配置重建，以及根据患者特点选择后处理工具，这一过程耗时且需要临床和技术专长。同时，放射科专业人员短缺问题日益严重，导致这一管理任务更加复杂。
### Innovation
提出了一种基于大型语言模型（LLM）的代理框架，旨在协助以自然语言或结构化的、设备无关的形式解读和执行扫描协议配置请求，以提高工作流程效率并减轻技术人员的工作负担。此代理结合了上下文学习、指令遵循和结构化工具调用能力，能够识别相关协议元素并准确应用修改。
### Conclusion
研究结果显示，基于大型语言模型的代理在处理CT扫描协议管理中显示出明确的可行性和发展途径。然而，这种方法在语法规则和语义有效性方面仍然面临挑战，尤其是在处理模糊或复杂的请求时。然而，该研究为未来的CT扫描协议管理自动化提供了明确的方向。
## 405. `cs.CL` - 使用ASCII艺术规避毒性检测：对内容管理系统的空间攻击基准 [PDF](https://arxiv.org/pdf/2409.18708), [HTML](https://arxiv.org/abs/2409.18708)
### Authors
Sergey Berezin,Reza Farahbakhsh,Noel Crespi
### Background
当前的文本仅检测系统在处理以ASCII艺术形式存在的空间结构文本时存在缺陷，这些检测模型无法正确理解这类文本，导致潜在的毒性信息被忽视。为了评估和测试这种缺陷，研究者提出了一种名为ToxASCII的基准测试方法，旨在检测毒性检测系统的对抗性攻击，特别是针对视觉上被模糊处理输入的攻击的有效性。
### Innovation
研究引入了一类新的对抗性攻击，专门针对毒性检测模型在处理具有空间结构的文本（如ASCII艺术）时的弱点。通过这种攻击，研究证明了诸如大型语言模型和专门的内容管理工具在内的各种先进系统在面对这种攻击时，其防御能力的严重不足，并且这些攻击能够达到100%的成功率。
### Conclusion
本文揭示了当前单一文本检测系统中存在的重要漏洞，并通过ToxASCII基准测试方法展示了此类漏洞的严重性。未来需要改进文本检测系统以更好地处理和检测具有空间结构的文本。
## 406. `cs.CL` - UNComp: 能够揭示稀疏性的矩阵熵吗？——基于不确定性感知的压缩器设计 [PDF](https://arxiv.org/pdf/2410.03090), [HTML](https://arxiv.org/abs/2410.03090)
### Authors
Jing Xiong,Jianghan Shen,Fanghua Ye,Chaofan Tao,Zhongwei Wan,Jianqiao Lu,Xun Wu,Chuanyang Zheng,Zhijiang Guo,Min Yang,Lingpeng Kong,Ngai Wong
### Background
大语言模型（LLMs）在进行长时间上下文推理时面临的挑战在于其巨大的内存和计算需求。虽然已有技术如Key-Value（KV）缓存压缩能够减少内存使用，但这些方法往往忽视了隐藏状态与其对应的KV缓存之间固有的结构稀疏性。本文通过探讨不确定性作为稀疏性潜在指示器的作用，构建了基于不确定性感知的框架UNComp，利用截断矩阵熵来识别低信息含量区域，从而揭示可用于自适应压缩的稀疏模式。
### Innovation
提出了一种基于不确定性感知的框架UNComp，该框架利用截断矩阵熵来识别低信息含量区域，揭示了用于自适应压缩的稀疏模式。UNComp不同于传统方法采用均匀压缩，而是根据不确定性指标动态调整压缩策略，这些指标反映了模型各个组成部分的重要性。研究表明，基于不确定性估计得出的稀疏模式能够揭示特殊的长距离依赖性，如检索头和检索层。
### Conclusion
UNComp不仅通过内存减少了由KV缓存引起的4.74%，还实现了6%的预填充加速和6.4倍的吞吐量提升，证明了基本理论工具的有效性，同时也展示了稀疏模式在长上下文推理中优化压缩的潜力。
## 407. `cs.CL` - 理解先行：迭代总结预提示增强链式思考 [PDF](https://arxiv.org/pdf/2501.04341), [HTML](https://arxiv.org/abs/2501.04341)
### Authors
Dong-Hai Zhu,Yu-Jie Xiong,Jia-Chen Zhang,Xi-Jiong Xie,Chun-Ming Xia
### Background
链式思考（CoT）提示是大型语言模型（LLMs）提升复杂推理能力的主要范式。它引导LLMs展示多步推理，而不是直接生成最终答案。然而，当需要进行推理的关键信息隐含或缺失时，CoT会遇到困难。这是因为CoT强调推理步骤的顺序，而忽略了早期提取关键信息的过程。
### Innovation
本文提出了一个称为迭代总结预提示（ISP^2）的预提示方法，用于在关键信息未明确提供时精炼LLMs的推理。该方法首先提取实体及其描述以形成潜在的关键信息对，然后使用可靠性评级评估这些对，将两个最低评分的对合并为一个新的实体描述。此过程重复进行，直到获得唯一的关键信息对。最后，该对与原始问题一起输入给LLMs生成答案。实验结果表明，该方法相比现有方法提高了7.1%的性能。不同于传统的提示方法，ISP^2采用了归纳式的预提示方法，提供灵活的与多种推理框架的集成
### Conclusion
广泛的实验表明，ISP^2方法相比现有方法实现了7.1%的性能提升。它采用了一种归纳式的预提示方法，灵活地集成到各种推理框架中，相比传统的提示方法提供了一系列优势。
## 408. `cs.CL` - LLMs再生产性少数和性别少数群体的刻板印象 [PDF](https://arxiv.org/pdf/2501.05926), [HTML](https://arxiv.org/abs/2501.05926)
### Authors
Ruby Ostrow,Adam Lopez
### Background
大量研究发现自然语言处理（NLP）系统中存在显著的性别偏见。大多数研究采用的是二元和本质主义的性别视角，将性别限制为男性和女性两类，混淆性别和性别的生物学特征，并忽略了不同的性取向和性别认同。然而，性别和性少数以及性别存在多样性和连贯性。因此，本文研究了大型语言模型（LLMs）对超越二元分类的性少数和性别少数群体的态度偏见。
### Innovation
基于广泛使用的社会心理学模型——原型内容模型，本文展示了关于社会感知的英文调查问卷问题从人类和LLMs中引发出更多对性少数和性别少数群体的负面刻板印象。同时，本文将该框架应用于更现实的场景：文本生成。结果表明，LLMs在创作写作场景中生成了性少数和性别少数群体的刻板印象，放大了创造性写作中的表现性伤害。
### Conclusion
LLMs不仅在调查问卷等场景下再生产性少数和性别少数群体的刻板印象，还在文本生成的创作场景中表现出这种偏见，说明了LLMs在多种使用场景下对性少数和性别少数群体的有害表现。
## 409. `cs.CL` - LLMs作为语言符号与分布式方法之间的综合 [PDF](https://arxiv.org/pdf/2502.11856), [HTML](https://arxiv.org/abs/2502.11856)
### Authors
Gemma Boleda
### Background
自20世纪中叶以来，语言和认知的研究方法之间一直在进行激烈的争论，即符号方法与分布式方法之间的较量。深度学习模型的成功，尤其是大型语言模型（LLMs），被视为这两种方法之一的胜利，或者被视作无关的技术进步。本文探讨了深度学习模型实际上是这两大传统之间综合的观点。
### Innovation
本文创新性地提出了深度学习模型实际上代表了符号方法和分布式方法之间的综合。这归因于其架构可以容纳分布/连续/模糊及符号/离散/分类样式的表示和处理，以及语言训练模型利用这种灵活性的特点。通过最近关于可解释性的研究，展示了L大型语言模型中形态句法知识近似离散化编码的大部分内容，解释了不同行为以一种新兴方式出现的原因，模型灵活地在两种模式之间转换（或任何中间状态）以应对需要。
### Conclusion
不同行为以一种新兴方式出现的原因是模型在需要时灵活地在两种模式之间转换（或任何中间状态），这是它们取得巨大成功的一个重要原因；这些模型特别适用于语言研究。这一观点被认为是寻求和平的时刻到了吗？
## 410. `cs.CL` - 使用全面解答填补信息空缺：提高跟进问题的多样性和信息量 [PDF](https://arxiv.org/pdf/2502.17715), [HTML](https://arxiv.org/abs/2502.17715)
### Authors
Zhe Liu,Taekyu Kang,Haoyu Wang,Seyed Hossein Alavi,Vered Shwartz
### Background
生成多样且能够揭示缺失信息的后续问题对于会话代理来说仍然是一个挑战，尤其是在它们依赖于小型本地托管模型时。现有方法难以满足这一需求，尤其是在生成有效、全面且多样化的后续问题时遇到困难。因此，提升小型代理生成高质量后续问题的能力成为一个亟待解决的问题。
### Innovation
本文提出了一种信息缺口驱动的知识蒸馏管道，其中教师大模型生成全面的答案，与初始答案对比以识别信息缺口，并据此生成填补这些缺口的后续问题。利用这种方法，我们扩展了现有的FollowupQG数据集十倍。在扩增后的数据集上对小型学生模型进行微调，可以将教师的知识有效传递给学生模型，从而显著提高生成的后续问题的信息量和多样性。
### Conclusion
实验表明，利用我们的管道训练的学生模型，在信息量和多样性方面表现优于原始数据集训练的模型。这表明我们的方法能有效地从先进大模型向小模型传递知识，从而使得资源受限的会话系统能够生成更多元化的高质量后续问题，提供了从先进大模型向小模型高效知识蒸馏的渠道。
## 411. `cs.CL` - 通过基准测试、游戏和认知测试衡量LLM进步 [PDF](https://arxiv.org/pdf/2502.14359), [HTML](https://arxiv.org/abs/2502.14359)
### Authors
Filippo Momentè,Alessandro Suglia,Mario Giulianelli,Ambra Ferrari,Alexander Koller,Oliver Lemon,David Schlangen,Raquel Fernández,Raffaella Bernardi
### Background
本文概述了三种评估范式：标准基准测试（如MMLU和BBH）、互动游戏（如信号博弈或忌讳词）以及认知测试（如工作记忆或理论思维测试）。首先研究标准基准测试或互动游戏哪一种最能区分不同质量的语言模型。然后结合人类认知评估，编写了一系列针对特定测试，评估语言模型的认知能力，进一步研究这些测试与模型在基准测试和互动游戏中的表现的相关性。研究表明，互动游戏比传统基准测试更能区分模型的表现。因果逻辑推理与静态和互动测试相关，而核心执行功能和社会情感技能更多与互动游戏相关。因此，建议开发新的互动基准测试和针对语言模型设计的具体的认知任务，以评估人类能力为灵感但专门针对语言模型。
### Innovation
研究提出了三种不同的评估范式——标准基准测试、互动游戏和认知测试，并通过这些测试评估语言模型的能力。研究发现互动游戏比传统基准测试更能区分模型的表现，并且提出应开发新的互动基准测试和针对语言模型的设计特定的认知任务。
### Conclusion
互动游戏在区分语言模型的能力方面比传统基准测试更有优势。因果逻辑推理与静态和互动测试相关，而核心执行功能和社会情感技能则更多与互动游戏相关。研究主张开发新基准测试和针对语言模型的任务，以评估人类能力为灵感。
## 412. `cs.CL` - BAP v2: 一种增强的任务框架，用于Minecraft对话中的指令遵循 [PDF](https://arxiv.org/pdf/2501.10836), [HTML](https://arxiv.org/abs/2501.10836)
### Authors
Prashant Jayannavar,Liliang Ren,Marisa Hudspeth,Risham Sidhu,Charlotte Lambert,Ariel Cordes,Elizabeth Kaplan,Anjali Narayan-Chen,Julia Hockenmaier
### Background
开发能够理解语言、感知环境并在物理世界中行动的互动代理一直是人工智能研究的一个长期目标。Minecraft Collaborative Building Task (MCBT) 提供了一个模拟3D Blocks World环境中的双人游戏平台，其中建筑师指导建造者构建目标结构，这为实现这一目标提供了一个丰富的平台。先前的工作集中在Builder Action Prediction (BAP)子任务上，但在数据稀缺和评估挑战等方面存在关键问题。
### Innovation
这项工作全面重新审视了BAP任务，并引入了BAP v2来解决评估、训练数据和建模中的关键挑战。具体来说，定义了一个增强的评估基准，包括更清晰的测试集和更公平、更深入的度量标准，揭示了空间推理是主要的性能瓶颈。为了应对数据稀缺，这份工作生成了不同类型的合成Minecraft Collaborative Building Task数据，增强了模型的空间技能。此外，新引入了模型Llama-CRAFTS，该模型采用了更丰富的输入表示，实现了在BAP v2任务上的F1分数为53.0，并且在合成数据上的表现也非常好。
### Conclusion
这一结果表明，在合成数据上的性能提升达到6分，但也强调了任务的难度，使BAP v2成为一个适合未来研究的良好土壤，同时也提供了一个衡量当前文本仅LLMs在此类具身任务中空间能力的有效标准。
## 413. `cs.CL` - MEBench: 多文档多实体提问作答系统评估基准 [PDF](https://arxiv.org/pdf/2502.18993), [HTML](https://arxiv.org/abs/2502.18993)
### Authors
Teng Lin,Yuyu Luo,Honglin Zhang,Jicheng Zhang,Chunlin Liu,Kaishun Wu,Nan Tang
### Background
多实体问答（MEQA）对于大型语言模型（LLM）和检索增强生成（RAG）系统构成了显著挑战，它们通常难以整合分散于不同文档中的信息。现有方法在单文档理解方面表现出色，但在跨文档聚合信息时往往会遇到困难，特别是在处理密集实体问题（例如：“ACM院士在不同研究领域中的分布如何？”）时，这些问题需要整合来自不同来源（如Wikipedia页面）的实体中心信息。
### Innovation
我们提出了一种名为MEBench的新型多文档多实体基准测试，旨在系统性评估LLM检索、整合和推理破碎信息的能力。基准测试包括4780个问题，并分类为三个主要类别下的八种具体类型，确保涵盖了现实世界多实体推理场景的广泛覆盖。我们的实验发现，即使是最先进的模型在MEBench上的准确率也只有59%。我们强调了信息提取的完整性和事实精确性在MEQA任务中的重要性，使用实体归属F1（EA-F1）指标对实体级别的准确性和归属有效性进行详细评估。
### Conclusion
MEBench不仅揭示了当前LLM框架中的系统性弱点，还为推进建立稳健、实体感知的QA架构奠定了基础。
## 414. `cs.CL` - 后苏联世界中的基础模型在烹饪什么？ [PDF](https://arxiv.org/pdf/2502.18583), [HTML](https://arxiv.org/abs/2502.18583)
### Authors
Anton Lavrouk,Tarek Naous,Alan Ritter,Wei Xu
### Background
后苏联国家的文化和饮食知识复杂且受其动荡历史的影响，这种历史持续影响着目前的事件。现有研究表明，顶级模型在处理这些国家的饮食文化时，难以正确识别菜肴的起源，尤其是在纯文本和多模态问答任务中。这主要是因为训练数据中存在误导性的菜肴起源共现和语言现象，如俄语-乌克兰语混合使用。现有的评估主要集中在问答能力，但将任务扩展到生成准确视觉描述表明，仅依赖问答评估文化理解能力可能不足以全面评估模型的实际能力。为了推进相关研究，该研究提出了一个名为BORSch的数据集，涵盖了俄语和乌克兰语的1147和823道菜肴，以供进一步研究使用。
### Innovation
提出了一个名为BORSch的数据集，该数据集围绕后苏联地区收集了俄语和乌克兰语的1147和823道菜肴，为研究基础模型的饮食文化理解和生成视觉描述提供了新工具。研究表明，模型在纯文本和多模态问答中难以正确识别菜肴的起源，这引发了研究者对多模态评估必要性的思考，并指出这可能不足以为全面评估文化理解能力提供足够的信息。
### Conclusion
尽管基础模型在处理多模态问题时显示出一定的挑战性，但这种挑战性的结果可以通过分析预训练数据得到解释。因此，未来研究应探索新的评估方法，超越单纯的问答任务，更好地测量模型的文化理解能力。BORSch数据集将公开发布，以促进进一步研究。
## 415. `cs.CL` - 大型语言模型在多方语言以前被核验过的声明检测中的应用 [PDF](https://arxiv.org/pdf/2503.02737), [HTML](https://arxiv.org/abs/2503.02737)
### Authors
Ivan Vykopal,Matúš Pikuliak,Simon Ostermann,Tatiana Anikina,Michal Gregor,Marián Šimko
### Background
在广泛传播虚假信息的时代，人类核验者在验证可能已在其他国家或语言中被处理过的声明时，常常面临着重复工作的挑战。由于虚假信息跨越语言边界，自动检测多语言中以前被核验过的声明的能力变得越来越重要。
### Innovation
本文首次全面评估了大型语言模型（LLMs）在多种语言中以前被核验过的声明检测中的应用。研究了7个LLMs在20种语言中的单语言和跨语言设置下表现。
### Conclusion
研究表明，尽管LLMs在高资源语言中表现良好，但在低资源语言中表现不佳。将原始文本翻译成英语对于低资源语言有利。研究结果突显了LLMs在多语言以前被核验过的声明检测方面的潜力，并为这一有前景的LLM应用的研究提供了基础。
## 416. `cs.CL` - HoT: Highlighted Chain of Thought for Referencing Supporting Facts from Inputs [PDF](https://arxiv.org/pdf/2503.02003), [HTML](https://arxiv.org/abs/2503.02003)
### Authors
Tin Nguyen,Logan Bolton,Mohammad Reza Taesiri,Trung Bui,Anh Totti Nguyen
### Background
大型语言模型（LLMs）的一个缺点是倾向于产生不准确的陈述，这使得人类难以验证并基于其作出准确的决策。这就提出了一个挑战，尤其是在应对错误信息时，人类需要识别模型回答中的正确部分。当前的方法，如简单的链式思考提示（CoT），虽然有一定作用，但在验证LLM的答案时仍然存在不足。特别是当LLM给出错误的答案时，添加的标记可能反而让使用者认为答案是正确的。因此，研究者提出了一种新的方法，即Highlight Chain-of-Thought Prompting（HoT）技术，以增强LLM的回答质量。
### Innovation
Highlight Chain-of-Thought Prompting（HoT）是一种新的提示技术，通过在输出中使用XML标签来标注与查询相关的关键事实，使得LLM在回答时能将重点突出显示，并确保生成的回答利用了输入中的关键信息。这种技术在少量示例的情况下（few-shot）表现出色，优于传统的链式思考方法（CoT），适用于从算术、阅读理解和逻辑推理等多种类型的任务。该方法还改善了人类验证LLM回答的准确性和效率，但意外地也导致了一个问题：当LLM回答错误时，标注反而可能误导用户，使他们误认为答案正确。
### Conclusion
Highlight Chain-of-Thought Prompting作为一种增强大型语言模型可靠性的方法，虽然在提高回答准确性和改进人类验证效率方面表现出了潜力，但在处理错误信息时仍现复杂性，需要进一步研究以优化其效果。
## 417. `cs.CL` - Playpen: 一个探索通过对话交互学习的环境 [PDF](https://arxiv.org/pdf/2504.08590), [HTML](https://arxiv.org/abs/2504.08590)
### Authors
Nicola Horst,Davide Mazzaccara,Antonia Schmidt,Michael Sullivan,Filippo Momentè,Luca Franceschetti,Philipp Sadler,Sherzod Hakimov,Alberto Testoni,Raffaella Bernardi,Raquel Fernández,Alexander Koller,Oliver Lemon,David Schlangen,Mario Giulianelli,Alessandro Suglia
### Background
近年来，通过奖励模型来评价大规模语言模型（LLMs）响应适宜性的方法引起了对学习后训练中学习者与反馈提供者互动的关注。本研究聚焦于探讨是否可以将对话游戏（由口头行动主导的指令导向和制度治理的活动）作为一种反馈信号的来源，用于促进学习。
### Innovation
本文引入Playpen，一种通过对话游戏自我博弈进行离线和在线学习的环境。研究了包括监督微调、直接对齐（DPO）和基于GRPO的强化学习在内的一系列后训练方法。实验展示了通过少量LLM（Llama-3.1-8B-Instruct）进行后训练的结果，验证了方法在未知训练游戏样本和未知游戏样本，以及标准基准测试中的表现。本研究发现，模仿学习通过自我博弈模型提高了未见过游戏样本的表现，但在其他技能上产生了负面影响，而互动学习通过GRPO则展示了在其他技能上保持平衡的改进。
### Conclusion
研究结果表明，Playpen环境和自我博弈为核心的研究框架有助于探索如何在（合成）交互中进行学习，通过 released 的框架和基准训练设置，能够促进这一新兴研究方向的发展，取得了平衡的改进效果，而不损失其他技能。
## 418. `cs.CL` - 使用动态奖励缩放的逆强化学习进行LLM对齐 [PDF](https://arxiv.org/pdf/2503.18991), [HTML](https://arxiv.org/abs/2503.18991)
### Authors
Ruoxi Cheng,Haoxuan Ma,Weixin Wang,Ranjie Duan,Jiexi Liu,Xiaoshuang Jia,Simeng Qin,Xiaochun Cao,Yang Liu,Xiaojun Jia
### Background
大型语言模型（LLMs）的安全部署需要对模型进行充分的偏差校正。现有技术包括基于奖励的方法（通过偏好数据对奖励模型进行训练，并使用强化学习进行优化）和无奖励的方法（直接针对排序后的输出进行微调）。尽管调优的基于奖励的管道显示出一定的鲁棒性，单一回答的示范在某些场景下优于成对的偏好数据，但仍存在两个挑战：不平衡的安全数据集倾向于高频率的危险而忽视了长尾威胁；现有的静态奖励模型没有考虑任务难度，这限制了优化效率和可实现的改进。
### Innovation
我们提出了DR-IRL（动态调整奖励通过逆强化学习）。首先，通过逆强化学习使用平衡的安全数据集训练涵盖七个有害类别的特定奖励模型。然后，通过引入动态奖励缩放来增强Group Relative Policy Optimization (GRPO)——调整奖励以反映任务难度，通过文本编码余弦相似度调整数据层面的难度，并通过奖励差距调整模型层面的响应性。广泛的实验表明，DR-IRL在各种基准和LLM上都能在安全对齐方面优于所有基线方法，同时保持有用性。
### Conclusion
DR-IRL通过动态调整奖励，结合逆强化学习和GRP调整策略的方法，有效解决了安全数据不平衡和静态奖励模型的局限性，提高了大语言模型的安全对齐效果。
## 419. `cs.CL` - 语言模型无法内省了解他们的语言知识 [PDF](https://arxiv.org/pdf/2503.07513), [HTML](https://arxiv.org/abs/2503.07513)
### Authors
Siyuan Song,Jennifer Hu,Kyle Mahowald
### Background
最近有关大型语言模型（LLMs）是否能够内省自身内部状态的研究引起了广泛关注。这项能力可以使LLMs更容易被解释，并且能够验证应用到语言学中的预期方法是否适用于评估模型的语法知识。研究人员系统地调查了21种开源LLMs在两个内省理论上相关的领域的表现：语法规则理解与词预测。这些领域中的内省理论可以基于字符串概率的直接测量进行解释。研究者考察了模型对元语言提示的响应是否忠实地反映了其内部知识。研究提出了一种新的内省度量标准：模型受提示响应与其自身字符串概率相符的程度，超越了基于有几乎相同内部知识的另一个模型可以预测的范围。尽管元语言提示和概率比较都能导致高任务准确率，但研究结果并未发现LLMs有特殊的“自我访问”能力。通过使用通用任务、控制模型相似性并评估多种开源模型，研究证明LLMs无法进行内省，并增加了证据表明受提示回应不应与模型的语义泛化混淆的观点。
### Innovation
研究人员提出了一种新的内省度量标准，该度量标准评估模型的受提示响应与其自身字符串概率的相符程度，超越了基于几乎相同内部知识的另一个模型可以预测的范围。他们通过系统地考察21种开源LLMs的内省能力，并在多个领域进行测试，从而证明了LLMs无法进行内省。这种方法不仅增加了模型行为的可解释性，还提供了评估模型内部知识的有效方法。
### Conclusion
通过对多种开源LLMs进行系统性的内省能力评估，研究没有发现LLMs具有特殊的自我认识能力。使用通用任务、控制模型相似性和广泛评估开放源代码模型的方法表明，LLMs无法内省，并补充了关于模型受提示回应不应直接代表其语言学习和理解的有效性证据。
## 420. `cs.CL` - 对齐探测: 关联毒害行为和模型内部 [PDF](https://arxiv.org/pdf/2503.13390), [HTML](https://arxiv.org/abs/2503.13390)
### Authors
Andreas Waldis,Vagrant Gautam,Anne Lauscher,Dietrich Klakow,Iryna Gurevych
### Background
本文介绍了对齐探测框架，这是一种新颖的可解释性框架，用于根据语言模型（LM）的输出和内部表示（内部）对其行为进行对齐。利用这一框架，研究了超过20个Olmo、Llama和Mistral模型，首次将行为和内部视角结合起来分析毒害问题。研究表明，语言模型在较低的层次中强烈编码了输入和后续输出的毒害水平信息。另外，分析了模型行为和内部在威胁等因素下的异质性，并通过四种案例研究强调了对齐探测的实际影响，进一步提供了具体见解。这些发现有助于更全面地理解语义模型，无论是在毒害上下文内还是外。背景信息描述了现有的语言模型解释方法和对齐探测框架的应用背景。
### Innovation
提出的对齐探测框架是一种新颖的解释性方法，它将语言模型的输出行为与其内部表示对齐，首次将行为和内部视角相结合来分析毒性问题。研究揭示了低层编码输入及其输出毒性的深度，并通过四种案例详细展示了对齐探测的实际应用和效果。
### Conclusion
研究发现，语言模型在输入毒性信息中编码较为强烈，并且这与输出毒性较低相关。通过对齐探测，研究揭示了模型行为的异质性，并强调了对齐探测框架在多个方面的具体影响。这些发现有助于更全面地理解语言模型，对模型的训练、量化和多角提示评估等方面有实际的影响。结论总结了研究的主要发现及其在不同应用中的意义。
## 421. `cs.CL` - 知识的线索：使用信息觅食优化搜索增强推理 [PDF](https://arxiv.org/pdf/2505.09316), [HTML](https://arxiv.org/abs/2505.09316)
### Authors
Hongjin Qian,Zheng Liu
### Background
大型语言模型（LLMs）对外部检索的增强已经成为解决其固有知识截止点限制的一种标准方法。然而，传统检索增强生成方法采用静态、预先推理的检索策略，这使得它们难以应对涉及模糊、多步骤或不断变化的信息需求的复杂任务。最近，测试时缩放技术的进展表明，这些技术在使LLMs能够动态与外部工具交互方面的巨大潜力，从而推动了在推理时采用适应性检索策略的转变。
### Innovation
我们借鉴了信息觅食理论（IFT），提出了一种名为InForage的强化学习框架，将检索增强理解决构为一个动态的信息寻求过程。InForage与现有方法的不同之处在于它明确奖励中间检索质量，促使LLMs通过适应性搜索行为迭代地收集和整合信息。为了便于训练，我们构建了一个由人类指导的数据集，涵盖了用于复杂、现实世界网络任务的信息检索和推理轨迹。
### Conclusion
广泛的评估结果表明，InForage在通用问题回答、多步推理任务以及新开发的实时网络QA数据集上的性能优于基准方法。这些结果突显了InForage在构建稳健、适应性强且高效的推理代理方面的有效性。
## 422. `cs.CL` - 小而精还是大而全？零样本还是微调？指导医疗健康领域的专业化应用选择 [PDF](https://arxiv.org/pdf/2504.21191), [HTML](https://arxiv.org/abs/2504.21191)
### Authors
Lovedeep Gondara,Jonathan Simkin,Graham Sayle,Shebnum Devji,Gregory Arbour,Raymond Ng
### Background
该研究旨在通过评估不同类型的语言模型（包括小型语言模型SLM和大型语言模型LLM）在医疗健康领域特定任务中的表现，指导语言模型的选择。研究使用电子病理报告，通过三个不同难度和数据量的任务场景进行评估。研究对比了零样本使用（zero-shot）和微调（finetuning）在不同模型中的效果，发现了特定场景下模型性能的变化趋势。
### Innovation
研究创新点在于探讨了在特定领域任务中，是否需要进行微调、模型的通用性与专业性、进一步的专业微调带来的收益，以及小规模模型（SLM）与大规模模型（LLM）的持续相关性。研究发现，微调对SLM的效果有显著提升，而LLM在零样本情况下表现较好但不及微调后的SLM。此外，专业领域的微调和预备训练提供了额外的优势，尤其是在复杂问题或数据有限的情况下。
### Conclusion
研究表明，对于专业领域的特定任务，微调后的SLM优于零样本的LLM。进一步的专业微调在简单的任务中有一定收益，在复杂的数据稀缺任务中则提供了显著的改进。虽然LLM具有强大的零样本能力，但在这些特定任务中的表现仍不及微调后的SLM。本研究强调了在特定领域的专业应用中，微调小型语言模型的重要性，并表明在大模型流行的时代，小型语言模型依然具有相关性和效果优势，提供了更好的性能与资源权衡。
## 423. `cs.CL` - 使用语言模型在认知评估中建模主观性 [PDF](https://arxiv.org/pdf/2503.11381), [HTML](https://arxiv.org/abs/2503.11381)
### Authors
Yuxiang Zhou,Hainiu Xu,Desmond C. Ong,Maria Liakata,Petr Slovak,Yulan He
### Background
随着语言模型在跨学科、以人为本的研究中的应用增加，人们对它们能力的期望也在不断提高。模型不仅需要在传统任务上表现出色，还需要在用户为中心的度量上表现良好，如自信心和人类的一致性，这些都反映了主观偏好。尽管在认知科学中建模主观性具有重要意义并得到了广泛研究，但其与自然语言处理（NLP）的交叉研究仍然相对不足。基于这一研究空白，作者通过全面的实验和分析研究了语言模型如何量化认知评估中的主观性，包括对微调模型和基于提示的语言模型（LLM）的研究。结果显示，个性特征和人口统计信息对于衡量主观性至关重要，但现有的事后校准方法往往无法取得令人满意的效果。深入分析还提供了有关如何在NLP和认知科学交叉研究中的指导性见解。
### Innovation
研究通过全面的实验和分析探索了语言模型如何衡量认知评估中的主观性，包括对微调模型和基于提示的大型语言模型（LLM）的研究。引入了一种新的方法来评估模型在表征主观性方面的性能，并揭示了个性特征和人口统计信息对于衡量主观性的重要性，这为NLP和认知科学交叉研究提供了实用的见解。
### Conclusion
研究结果表明，个性特征和人口统计信息对测量主观性至关重要，但现有的校准方法往往无法取得满意的效果。深入分析为未来该领域的研究提供了宝贵的指导性见解。
## 424. `cs.CL` - 使用大型语言模型统一时间文本标注图中的文本语义和图结构 [PDF](https://arxiv.org/pdf/2503.14411), [HTML](https://arxiv.org/abs/2503.14411)
### Authors
Siwei Zhang,Yun Xiong,Yateng Tang,Jiarong Xu,Xi Chen,Zehao Gu,Xuezheng Hao,Zian Jia,Jiawei Zhang
### Background
时间图神经网络（TGNNs）在时间图建模中表现出显著的效果。然而，现实世界中的时间图往往包含丰富的文本信息，形成时间文本标注图（TTAGs）。这种动态文本语义与演变图结构的结合增加了模型的复杂性。现有TGNNs将文本静态嵌入，并主要依赖编码机制，着重优先处理结构信息，忽视了语义和结构之间的动态性和协同强化关系。
### Innovation
提出了CROSS（可用于TTAG建模的灵活框架），通过将TTAG建模过程分解为两个阶段：（i）时间语义提取；和（ii）语义-结构信息统一。具体来说，CROSS框架中引入了时间语义提取器，能够使大型语言模型动态提取节点相邻域中的时间语义，并生成综合的表示。接着，引入了语义-结构协同编码器，在同时考虑语义和结构信息的同时，鼓励它们的相互加强，从而生成了更突出的表示。
### Conclusion
广泛的实验表明，CROSS在四个公开数据集以及一个工业数据集上取得了最先进的结果，在时间链接预测方面平均绝对MRR提升24.7%，在工业应用中节点分类方面AUC提升3.7%。
## 425. `cs.CL` - SAFE：在生成过程中使用句子级别归属改进LLM系统 [PDF](https://arxiv.org/pdf/2505.12621), [HTML](https://arxiv.org/abs/2505.12621)
### Authors
João Eduardo Batista,Emil Vatai,Mohamed Wahib
### Background
大规模语言模型（LLMs）在各个科学领域得到了广泛应用，但它们的更广泛采用受到了一个关键挑战的约束：缺乏可信赖且可验证的输出。当前的LLMs在生成答案时往往没有可靠地进行来源归属，甚至有时候是错误的归属，这在需要可追溯性和问责性的科学研究和高风险场景中构成了障碍。要让LLM系统变得可靠，归属系统需要在从检索到的数据中进行短文本归属时具备高准确性，即需要将归属精确到文档中的一个句子而不是整个文档。
### Innovation
本文提出了SAFE，一种句段级归属框架，专为检索增强生成（RAG）系统设计，在生成期间对生成的句子进行归属。这使用户在阅读时可以验证句子，并在归属表明生成的文本没有接地在文档中的时候纠正模型，从而增加LLM系统的安全性。该框架包括两个步骤：预测一个句子所需的参考数量，以及对句段进行归属。这种方法在第一步实现了95%的准确性，而与TOP-1准确性相比，在我们的干净数据集中的所有归属算法的准确性（已根据可能的最大准确性进行归一化）提高了2.1%到6.0%。我们在包含数百到数千个句子的实际应用场景中也应用了SAFE，该方法可靠地归因了句段的来源文档，表明该方法不仅可以适用于控制性基准，还可以在实际场景中推广。
### Conclusion
SAFE框架和训练数据在GitHub上公开可用。
## 426. `cs.CL` - Meeseeks：一种基于反馈驱动的迭代自我纠正基准评估大语言模型的指令遵循能力 [PDF](https://arxiv.org/pdf/2504.21625), [HTML](https://arxiv.org/abs/2504.21625)
### Authors
Jiaming wang,Yunke Zhao,Peng Ding,Jun Kuang,Yibin Shen,Zhe Tang,Yilin Jin,ZongYu Wang,Xiaoyu Li,Xuezhi Cao,Xunliang Cai
### Background
在现实世界场景中，大语言模型（LLMs）作为可靠的代理，需要能够精确遵循指令。然而，面对复杂的提示时，LLMs经常遇到在单次响应中无法满足所有指定要求的问题。因此，有必要引入一种能够对模型响应中的错误进行识别并提供反馈的基准，帮助模型逐步自我纠正。
### Innovation
该论文提出了Meeseeks，这是一种全自动迭代指令遵循基准，集成反馈机制，能够识别模型响应中的错误并提供准确的反馈，引导模型逐步自我纠正。本研究借鉴了链式思维（CoT）提示技术和自我纠正方法的最新进展。Meeseeks包含超过700个由32种不同的能力标签标注的中文和英文实例。实验结果表明，不同的商业和开源LLM在迭代反馈驱动的自我纠正20轮后仍然表现出显著差异，大多数模型仍然表现不佳。研究揭示了当前领先模型中存在的诸多问题，并发现了几个非直观的现象。
### Conclusion
广泛的分析表明，尽管进行了多次迭代反馈驱动的自我纠正，大多数先进的商业和开源LLMs仍然表现出较差的性能。研究揭示了这些问题，并强调了进一步改进LLM指令遵循能力的重要性。相关研究工作已公开发布。
## 427. `cs.CL` - 从未对齐到对齐：使用多方并行语料库扩展多语言LLMs [PDF](https://arxiv.org/pdf/2505.14045), [HTML](https://arxiv.org/abs/2505.14045)
### Authors
Yingli Shen,Wen Lai,Shuo Wang,Ge Gao,Kangyang Luo,Alexander Fraser,Maosong Sun
### Background
持续预训练和指令微调在大规模多语言数据集上已经被证明是成功地扩展大型语言模型（LLMs）到低资源语言的有效方法。然而，这种数据的不对齐性限制了其有效捕捉跨语言语义的能力。与此同时，多方并行数据，即在多个语言中对齐相同内容的数据，提供了更强的跨语言一致性，并提供了提高多语言性能的巨大潜力。该研究建立在TED Talks上生成了一个大规模、高质量的多方并行语料库TED2025，覆盖113种语言，其中最多50种语言并行对齐，确保了广泛的多语言覆盖。
### Innovation
该研究引入了一个名为TED2025的大规模、高质量的多方并行语料库，基于TED Talks。使用这一数据集，研究探讨了如何利用多方并行数据来增强LLMs，包括持续预训练、指令微调和关键影响因素的分析策略。实验结果表明，使用多方并行数据训练的模型在多语言基准测试中始终优于使用未对齐多语言数据训练的模型。
### Conclusion
研究表明，多方并行数据在提高多语言大型语言模型性能方面具有巨大潜力。通过TED2025语料库，可以更好地利用多方并行数据来增强LLMs，并提供了改进多语言性能的最佳实践。
## 428. `cs.CL` - 针对成员推断攻击的检索数据隐私保护：这个查询离家太近了吗？ [PDF](https://arxiv.org/pdf/2505.22061), [HTML](https://arxiv.org/abs/2505.22061)
### Authors
Yujin Choi,Youngjoo Park,Junyoung Byun,Jaewook Lee,Jinseong Park
### Background
大语言模型（LLMs）中的检索增强生成（RAG）可以减轻幻觉问题，但直接将私有检索文档传递给LLM会引入成员推断攻击（MIA）的脆弱性，这种攻击试图确定目标数据点是否存在于私有外部数据库中。文章基于MIA查询通常与唯一目标文档高度相似的想法，提出了一种基于相似性的MIA检测框架，以保护RAG系统中的检索数据隐私，并展示了这种方法可以在不牺牲数据实用性和保持系统无关性的情况下有效防御MIA。实验验证了其在对抗多种先进的MIA方法以及兼容现有RAG系统方面的有效性和适应性。
### Innovation
提出了一种基于相似性的MIA检测框架，旨在保护RAG系统中的检索数据隐私。该方法通过简单的检测和隐藏策略成功地使攻击者迷惑，同时保持数据实用性和系统独立性。并证实该方法在对抗最新的MIA方法及对现有RAG系统的适应性方面的有效性。
### Conclusion
该研究提出了一个基于相似性的新颖MIA检测框架，能够有效保护RAG系统中的检索数据隐私，同时保持数据高质量，无需依赖于特定的系统结构。该框架在实验中成功地对抗了多种先进的MIA方法，并且能够适应现有的RAG系统。
## 429. `cs.CL` - DISCO 平衡天平：适应不平衡数据的自适应领域和难度感知强化学习 [PDF](https://arxiv.org/pdf/2505.15074), [HTML](https://arxiv.org/abs/2505.15074)
### Authors
Yuhang Zhou,Jing Zhu,Shengyi Qian,Zhuokai Zhao,Xiyao Wang,Xiaoyu Liu,Ming Li,Paiheng Xu,Wei Ai,Furong Huang
### Background
大规模语言模型（LLMs）通过人类反馈强化学习（RLHF）越来越接近人类偏好。在RLHF方法中，组相对策略优化（GRPO）因其简单性和强大的性能而受到关注，尤其是在不需要学习价值函数的情况下。然而，GRPO假设各个组之间的领域分布是平衡的，且语义对齐均匀，这在实际数据集中很少成立。当应用于具有不平衡多领域的数据时，GRPO会过度优化占主导地位的领域，而忽略了小众领域，导致泛化和公平性较差。
### Innovation
本文提出了领域导向的自一致性策略优化（DISCO），这是一种对GRPO的原则性扩展，解决了组之间的不平衡。DISCO通过两种关键创新来应对。领域感知的奖励缩放通过基于领域分布的重权来抵消频率偏差。难度感知的奖励缩放利用了提示级别的自一致性来识别和优先处理具有更高学习价值的不确定提示。这些策略共同促进跨领域更公平和有效的策略学习。
### Conclusion
在多个LLM和分布偏斜的训练数据集上进行的广泛实验表明，DISCO能够提高泛化能力，在Qwen3模型上比现有GRPO变体性能高5%，并在多领域对齐基准上设定新的最佳结果。该代码和数据可从该网址获得。
## 430. `cs.CL` - 推动MoE专家专业化以获得更好的效果 [PDF](https://arxiv.org/pdf/2505.22323), [HTML](https://arxiv.org/abs/2505.22323)
### Authors
Hongcan Guo,Haolang Lu,Guoshun Nan,Bolun Chu,Jialin Zhuang,Yuan Yang,Wenhao Che,Sicong Leng,Qimei Cui,Xudong Jiang
### Background
Mixture-of-Experts (MoE) 模型通过仅激活每个输入的一部分专家来实现大型语言模型（LLMs）的高效扩展。然而，通常使用的辅助负载均衡损失常常导致专家重叠和路由过于均匀，这阻碍了专家的专门化并降低了整体性能。
### Innovation
提出了一种简单而有效的解决方案，通过两个互补的目标来解决上述问题：(1) 正交损失，旨在鼓励不同种类的标记由不同的专家处理，以促进专家专门化；(2) 方差损失，旨在促进更具有辨别性的路由决策。研究表明，这两个目标与现有的辅助损失兼容，并有助于优化训练过程。
### Conclusion
在多种模型架构和多个基准测试中进行的实验结果显示，该方法显著提高了专家的专业化水平。值得注意的是，该方法可以将带辅助损失的经典MoE基线提高多达23.79%，同时在下游任务中也能保持负载均衡，无需进行任何架构修改或添加额外组件。我们将发布代码以期贡献给社区。
## 431. `cs.CL` - LASER: 专用评分策略的指令微调分层选择性采样 [PDF](https://arxiv.org/pdf/2505.22157), [HTML](https://arxiv.org/abs/2505.22157)
### Authors
Paramita Mirza,Lucas Weber,Fabian Küch
### Background
近期研究表明，可以通过大幅减少大型语言模型（LLMs）的后续训练数据集而不会显著降低其性能。然而，数据选择通常伴随着高昂的计算成本，或者只能应用于狭窄的领域。因此，本研究旨在通过提出一个高效且通用的数据选取方法来解决这一问题。
### Innovation
本研究提出了一种多步骤管道策略，包括高效地将数据点分组、使用特殊模型估计质量，并通过稳健且轻量级的方法评分难度。此外，通过基于任务的分类和改进的嵌入模型及聚类算法，以保证多样性。这种综合策略能够在保持低开销的同时实现高性能的微调。
### Conclusion
本研究通过集成策略实现了指令微调高效率的数据选择，确保了多样化的数据组合，实现了在多用途模型微调时的高性能表现，且几乎不增加额外开销。
## 432. `cs.CL` - 日期片段：时间推理中分词的隐藏瓶颈 [PDF](https://arxiv.org/pdf/2505.16088), [HTML](https://arxiv.org/abs/2505.16088)
### Authors
Gagan Bhatia,Maxime Peyrard,Wei Zhao
### Background
现代BPE分词器往往会将日期分割成无意义的片段，例如20250312会被分割成202，503，12，这会导致切分后增加的分词数量，并模糊原有的日期结构，影响时间推理的准确性。
### Innovation
1. 引入了一个称为日期碎片比的简单且可解释的度量标准，用于衡量分词器如何忠实地保留多数字日期成分；2. 发布了一个名为DateAugBench的数据集套件，包含6500个示例，涵盖三种时间推理任务：基于上下文的日期解析、格式不变性谜题和跨不同时间范围的日期算术；3. 通过逐层探针和因果注意力跳跃分析，揭示了一个新兴的时间抽象机制，大型语言模型能够将月份、日期和年份的片段拼接在一起进行时间推理。研究表明，过度碎片化与对于罕见日期（历史和未来日期）的准确性降低有很强的相关性。此外，发现模型越大，这种新兴的时间抽象机制能更快地弥补日期片段。最后还观察到LLM的推理路径，通常会遵循不同于人类解读的模式（年份→月份→日期）。
### Conclusion
实验表明，过度的碎片化对非常见日期（如历史和未来的日期）的准确性影响可达10分的降幅。该论文还提出了一个关于LLM如何按年份、月份和日期的顺序来组装日期片段的观察现象，这一现象在实际应用中与人类的解释方式有所不同。
## 433. `cs.CL` -  threading the needle: 重新编织链式推理以解释人类标签变异 [PDF](https://arxiv.org/pdf/2505.23368), [HTML](https://arxiv.org/abs/2505.23368)
### Authors
Beiduo Chen,Yang Janet Liu,Anna Korhonen,Barbara Plank
### Background
最近大型语言模型（LLMs）的能力提升，使其在推理时生成思维链（CoTs），这引起了人们的广泛关注。研究发现，LLM生成的解释有助于使模型预测与人类标签分布趋于一致，但传统方法通常是基于给定的答案生成解释。本文探讨了利用CoTs的正向推理路径来直接解释每个答案选项背后的理由，从而提出了基于LLM的新框架，该框架能够更准确地提取支持和反对每个答案选项的陈述。
### Innovation
本文提出了一种新的基于LLM的管道，该管道包含语言学驱动的断言分段器，能够从思维链中提取支持和反对每个答案选项的声明，精确度有所提高。此外，还提出了基于排名的HLV评估框架，优先考虑答案排名而非确切分数，这可能更有利于直接比较标签分布。实验结果表明，该方法优于直接生成方法和基线方法，与人类结果对齐较好，突显了该方法的有效性。
### Conclusion
本文方法在三个数据集上的表现优于直接生成方法和基线方法，且在对齐排名方法与人类结果方面表现更佳，展示了该方法的有效性。
## 434. `cs.CL` - RadialRouter: 结构化表示以实现高效且稳健的大语言模型路由 [PDF](https://arxiv.org/pdf/2506.03880), [HTML](https://arxiv.org/abs/2506.03880)
### Authors
Ruihan Jin,Pengpeng Shao,Zhengqi Wen,Jinyang Wu,Mingkuan Feng,Shuai Zhang,Jianhua Tao
### Background
大语言模型（LLMs）的快速发展催生了路由技术，这些技术旨在高效地从多种候选LLM中选择最适合特定任务的模型，以优化性能并降低运营成本。现有LLM路由方法由于未能充分探索用户查询与LLM特性之间的内在联系，其有效性受到限制。
### Innovation
本文提出了一种名为RadialRouter的新颖LLM路由框架，该框架采用了一种带有径向结构（RadialFormer）的轻量级Transformer作为支撑，以表征查询-LLM的关系。通过将Kullback-Leibler散度与查询-查询对比损失结合到目标函数中，进一步细化了管道，提升了鲁棒性。实验结果表明，RadialRouter在RouterBench上的表现优于现有方法，在平衡和成本优先场景中分别提高了9.2%和5.8%。其在不同性能-成本权衡中的适应性以及动态LLM池也展示了其实用应用潜力。
### Conclusion
实验结果表明，RadialRouter在性能和成本优先场景下分别比现有方法提高了9.2%和5.8%，这表明该方法在不同性能-成本权衡中的适应性以及动态LLM池的应用潜力是显著的。
## 435. `cs.CL` - LegalSearchLM：重新思考法律案例检索作为一种法律元素生成 [PDF](https://arxiv.org/pdf/2505.23832), [HTML](https://arxiv.org/abs/2505.23832)
### Authors
Chaeeun Kim,Jinu Lee,Wonseok Hwang
### Background
法律案例检索（LCR）是法律专业人士进行研究和决策的基础任务。然而，当前的LCR研究面临两个主要局限性：一是评价数据集规模较小（如100-55K案例），且查询类型范围狭窄，不能充分反映实际法律检索场景的复杂性；二是依赖于基于嵌入或词汇匹配的方法，导致表示能力有限且法律相关性不足。
### Innovation
该论文提出了LEGAR BENCH，这是第一个大规模的韩国法律案例检索基准，包含了411种不同类型的罪行查询，覆盖了超过120万候选案例。此外，还提出了一种名为LegalSearchLM的检索模型，该模型能够在查询案例中进行法律元素推理，并直接生成包含这些元素的内容，通过约束解码与目标案例对接。实验结果显示，LegalSearchLM在LEGAR BENCH上的性能优于基线方法6-20%，并且在跨领域案例的泛化能力方面优于基于领域内数据训练的朴素生成模型15%。
### Conclusion
LegalSearchLM模型显著提升了法律案例检索的效果，特别是在复杂查询场景和跨领域案件上的表现更为突出，达到了当前最先进的性能，并展示了强大的泛化能力。
## 436. `cs.CL` - 推理模型能识别和恢复无用想法的能力有多强？ [PDF](https://arxiv.org/pdf/2506.10979), [HTML](https://arxiv.org/abs/2506.10979)
### Authors
Sohee Yang,Sang-Woo Lee,Nora Kassner,Daniela Gottesman,Sebastian Riedel,Mor Geva
### Background
近期的研究表明，推理模型具备反思、回溯和自我验证推理过程的能力，这对于发现错误和获得准确的答案至关重要。然而，自然地产生一个问题，即这些模型在此类自我评价上表现如何。论文探讨了推理模型识别并从四种类型的无用想法中恢复的能力：无关的长篇废话、与问题无关的想法、误导性问题的想法以及导致错误答案的想法。
### Innovation
研究通过分析推理模型在引入无用想法时的识别和恢复能力，揭示了当前模型在自我评估上的局限性，提出模型在应对引入的无关想法时易产生固执的推理模式，表明其自我评估能力远未达到一般的元认知水平。此外，研究还发现了非/逆向相关趋势，大型模型在面对短暂的无关想法时恢复能力较差。通过实验证明了这些发现的影响，并揭示小型模型对有害回应触发的想法不太受干扰。
### Conclusion
研究结果强调了需要改进推理模型的自我评估能力，以促进更有效的推理和更安全的系统发展。
## 437. `cs.CL` - 使用状态变化轨迹增强多智能体通信 [PDF](https://arxiv.org/pdf/2506.19209), [HTML](https://arxiv.org/abs/2506.19209)
### Authors
Yichen Tang,Weihang Su,Yujia Zhou,Yiqun Liu,Min Zhang,Shaoping Ma,Qingyao Ai
### Background
已有的研究表明，诸如角色扮演或多轮辩论等多智能体技术能够有效提高大规模语言模型（LLMs）在下游任务中的表现。现有的大多数基于单一基础语言模型构建的多智能体系统主要通过自然语言进行智能体间的通信。尽管这种方式具有简单性和可解释性的优势，但也存在必然的信息损失，即一个模型需要将其连续的状态向量下采样为离散的标记，然后传递给另一个模型。这种损失在需要进行复杂推理的场景下尤为显著。
### Innovation
本文提出了一种新的通信协议，该协议不仅传输自然语言标记，还能传输每个标记生成后状态变化的轨迹。通过State Delta Encoding (SDE)方法，代表这些状态转移轨迹。实验结果表明，使用SDE的方法能够实现多智能体系统的最优性能，特别是在涉及复杂推理的任务中表现尤为突出。
### Conclusion
多智能体系统使用SDE方法可以实现更好的性能，特别是在需要复杂推理的任务中，这种新提出的通信协议能够更准确地转移智能体间重要的隐含信息，从而提高模型在下游任务中的表现。
## 438. `cs.CL` - 动态参数记忆：暂时增强LoRA的大语言模型在对话长序列情感识别中的应用 [PDF](https://arxiv.org/pdf/2507.09076), [HTML](https://arxiv.org/abs/2507.09076)
### Authors
Jialong Mai,Xiaofen Xing,Yawei Li,Weidong Chen,Zhipeng Li,Jingyuan Xing,Xiangmin Xu
### Background
近年来，研究重点在于将语音大型语言模型（SLLM）应用于提升语音情感识别（SER）能力。然而，语音模态固有的高帧率严重限制了SLLM的信号处理和理解能力。以4K上下文窗口的SLLM为例，它在50Hz特征采样率下只能处理80秒的音频，才会达到处理能力极限。目前输⼊令牌压缩方法忽略了情感在多轮对话中的连续性和惯性。目前的方法未能充分利用语音模态的整体信息，因此，需要创新地扩展SLLM以适应长音频序列的处理需求，改善其情绪识别能力。
### Innovation
本文提出了一个名为动态参数记忆（DPM）机制，这是一种结合上下文语义和句子级别的情感编码的新方法。DPM能够在推理过程中逐步将句子级别的信息和情感编码到临时LoRA模块中，有效“记忆”上下文信息，从而实现用有限的上下文窗口处理无限长度的音频。作者还将情感SLLM作为主干，并将DPM集成到对话情绪识别（ERC）中进行训练和推理。实验结果表明，DPM在处理长音频序列时显著提高了SLLM的情绪识别能力，并达到了最先进的性能水平。这项工作的创新之处在于融合了上下文语义和情感信息的动态记忆机制，有效地扩展了SLLM的能力边界，为处理长序列语音数据提供了新的可能。
### Conclusion
本文提出的DPM机制成功地提升了SLLM的情绪识别能力，特别是在处理长音频序列时表现出色，达到了SLLM在对话情绪识别任务上的最先进的性能水平。
## 439. `cs.CL` - 使用自适应上下文压缩提升RAG效率 [PDF](https://arxiv.org/pdf/2507.22931), [HTML](https://arxiv.org/abs/2507.22931)
### Authors
Shuyu Guo,Shuo Zhang,Zhaochun Ren
### Background
检索增强生成（RAG）能够通过外部知识增强大型语言模型（LLMs），但会因较长的检索上下文而导致显著的推理成本。虽然已有上下文压缩方法可以缓解这一问题，但它们采用固定的压缩率，可能会过度压缩简单的查询或未能充分压缩复杂的查询。
### Innovation
本文提出了一种自适应上下文压缩框架（ACC-RAG），该框架能够根据输入的复杂性动态调整压缩率，在提高推理效率的同时保持或改善准确性。ACC-RAG结合了分层压缩器（用于多粒度嵌入）和上下文选择器，以保留最少但足够的信息，类似于人类浏览的方式。
### Conclusion
ACC-RAG在Wikipedia和五个问答数据集上的表现优于固定压缩率的方法，并且相比标准RAG，速度快4倍以上，同时保持或提高了准确性。
## 440. `cs.CL` - 使用方差信号检测 token 级别幻觉：一种无需参考的approach [PDF](https://arxiv.org/pdf/2507.04137), [HTML](https://arxiv.org/abs/2507.04137)
### Authors
Keshav Kumar
### Background
大型语言模型（LLMs）展示了在多种任务上的生成能力，但仍然容易产生幻觉，即自信但却事实错误的输出。现有方法多依赖于 ground-truth 参考或句子级验证，这些方法在检测 token 级别幻觉时不够通用、透明且不适合实时或事后分析。该研究提出了一种无需参考的、基于 token 级别 log 概率方差的幻觉检测框架，该方法克服了现有方法的限制，表现出模型无关性、可解释性及实时或事后分析适用性。
### Innovation
研究提出了一种新的 token 级别幻觉检测框架，利用多个随机生成过程中的 token log 概率的方差来检测模型输出的稳定性问题，且该方法是模型无关的、可解释的，并适用于实时或事后分析。该方法不同于现有的需要 ground-truth 参考或句子级验证的方法，尤其是在检测 token 级别幻觉方面，具有更高的通用性。
### Conclusion
通过定量指标和可视化诊断，研究表明 token 级别方差能够可靠地揭示模型输出的不稳定性，与幻觉模式相关。该框架轻量级、可重现且适用于多个领域，为分析 LLM 的生成可靠性提供了一个重要的诊断工具。
## 441. `cs.CL` - VisualTrap：通过视觉定位操纵的隐形后门攻击 [PDF](https://arxiv.org/pdf/2507.06899), [HTML](https://arxiv.org/abs/2507.06899)
### Authors
Ziang Ye,Yang Zhang,Wentao Shi,Xiaoyu You,Fuli Feng,Tat-Seng Chua
### Background
图形用户界面（GUI）代理，由大型视觉语言模型（LVLMs）提供动力，已成为自动化人机交互的一种革命性方法。这些代理能够自主操作个人设备（如手机）或设备内的应用程序，以一种类似人类的方式执行复杂的现实世界任务。然而，它们与个人设备的紧密集成带来了重大的安全问题，许多威胁，包括后门攻击，尚未得到充分研究。视觉定位是将文本计划映射到GUI元素的过程，这一过程可能导致脆弱性，从而启用新的后门攻击类型。当攻击针对视觉定位时，即使给定正确的任务解决计划，代理的行为也可能被篡改。为了验证这种脆弱性，作者提出了VisualTrap方法，这是一种通过误导代理将文本计划定位到触发位置而不是预期目标来劫持视觉定位的方法。VisualTrap在预训练视觉定位时注入中毒数据来确保攻击的可行性。实验结果表明，使用仅5%的中毒数据，VisualTrap可以成功劫持视觉定位，并且具有高度隐蔽的视觉触发器（对肉眼不可见），即使在干净的微调后攻击也可泛化到下游任务。此外，注入的触发器在不同GUI环境中仍然有效，例如在移动/网页环境中训练并在桌面环境中泛化。这些发现强调了进一步研究GUI代理中后门攻击风险的迫切需要。
### Innovation
作者提出了VisualTrap，这是一种通过误导视觉定位方法使得图形用户界面代理的行为被篡改的后门攻击方法。VisualTrap的独特之处在于它利用了视觉定位的预训练注入中毒数据的方式来确保攻击的可行性。这种攻击方法可以让攻击者在少数对抗样本中破坏代理的行为，并且产生的视觉触发器对人类是不可见的，从而使得攻击高度隐蔽。VisualTrap可以泛化到下游任务，即使在干净的微调后仍然有效。此外，注入的触发器在不同的GUI环境中仍然保持有效性。
### Conclusion
VisualTrap和相关实验结果突显了对图形用户界面代理中的后门攻击风险的研究需求。视觉定位是这些攻击的关键点，需要进一步的研究来增强这个领域中的安全性。研究指出，应加强对图形用户界面代理中视觉定位以及后门攻击的深入研究，以提高系统的安全性和稳健性。
## 442. `cs.CL` - 从查询到逻辑：LLMs中的本体驱动多跳推理 [PDF](https://arxiv.org/pdf/2508.01424), [HTML](https://arxiv.org/abs/2508.01424)
### Authors
Haonan Bian,Yutao Qi,Rui Yang,Yuanxi Che,Jiaqian Wang,Heming Xia,Ranran Zhen
### Background
大型语言模型（LLMs）在回答问题方面取得了成功，但在复杂的多跳问答（MQA）任务中表现出局限性，这些任务需要非线性的结构化推理，由于LLMs无法充分捕捉实体间的深层次概念关系，导致了这种局限性。
### Innovation
本文提出了名为ORACLE（Ontology-driven Reasoning and Chain for Logical Exlication）的无训练框架，结合了LLMs的生成能力与知识图谱的结构性优点。ORACLE通过以下三个阶段实现：（1）使用LLMs动态构建问题特定的知识本体，（2）将这些本体转化为一阶逻辑推理链，（3）系统地将原始查询分解为逻辑一致的子问题。实验结果表明，该框架在多个标准的MQA基准测试中表现优异，与当前最先进的模型如DeepSeek-R1相媲美。详细分析进一步证明了每个组件的有效性，并展示了该方法生成的逻辑性和可解释性更强的推理链。
### Conclusion
ORACLE框架通过动态构建问题特定的知识本体、将本体转化为一阶逻辑推理链以及系统地将原始查询分解为逻辑一致的子问题，成功解决了LLMs在复杂多跳问答任务中的局限性，展示了其在多个标准MQA基准测试中与当前最先进的模型相媲美的竞争力。
## 443. `cs.CL` - 文化无处不在：呼吁进行有意识的文化评估 [PDF](https://arxiv.org/pdf/2509.01301), [HTML](https://arxiv.org/abs/2509.01301)
### Authors
Juhyun Oh,Inha Cha,Michael Saxon,Hyunseung Lim,Shaily Bhatt,Alice Oh
### Background
现有的大型语言模型（LLMs）文化对齐评估主要集中在琐碎的事实和价值上，通过多项选择或简答题的形式进行测试，忽视了文化的真实多样性和互动性，并且忽略了文化假设如何渗透到看似“中立”的评估环境中。随着这些模型变得日益先进和广泛部署，这种“琐事为中心的范式”变得越来越不足.
### Innovation
提出了“有意的文化评估”的方法，这是一种系统地审查在所有评估方面嵌入的文化假设的方法，而不仅仅是文化任务中明确的文化考量。该方法系统地描述了文化依赖性考虑在评估中产生的“情境”，强调研究者的立场对于促进包容性和文化对齐的NLP研究的重要性.
### Conclusion
呼吁超越当前的基准测试实践，并探索重要且未知的应用程序，并通过带有HCI启发的参与性方法使社区参与到评估设计中来.
## 444. `cs.CL` - 媒介并非信息：通过线性概念消除解除文档嵌入的共因 [PDF](https://arxiv.org/pdf/2507.01234), [HTML](https://arxiv.org/abs/2507.01234)
### Authors
Yu Fan,Yang Tian,Shauli Ravfogel,Mrinmaya Sachan,Elliott Ash,Alexander Hoyle
### Background
基于嵌入的文本序列相似度度量不仅由我们关心的内容维度决定，还可能受到文本来源或语言等虚假属性的影响。这些文档共因会在多种应用中造成问题，尤其是在需要从不同语料库汇总文本的应用中更为显著。已有研究表明，去除已观察到的共因信息的算法可以显著减少这些偏差，且计算成本较低。在我们评估的每个嵌入变体和任务中，文档相似性和聚类度量都有所提高，有时甚至显著改善。有趣的是，在离群值基准测试上的表现并未受到影响，表明嵌入并非因其他原因而降级。
### Innovation
该论文提出了一种去共因算法，通过从编码器表示中移除已观测共因的信息，来减少嵌入的偏差。此方法在保持计算效率的同时有效减少了偏差，并在不同嵌入变体和任务上普遍存在提高效果。此外，这种去共因化过程对新领域测试的性能没有负面影响，表明经过去共因处理的嵌入并未因此度量上退化或削弱。
### Conclusion
通过线性概念消除，去除嵌入表示中已观测到的共因信息，可以显著减少偏见且计算负担较小。该方法在多个嵌入版本和任务上提升了文档相似性和聚类度量，对新领域测试结果没有负面影响。
## 445. `cs.CL` - SciRerankBench：评估 RAG-LLMs 中重排序器的基准 [PDF](https://arxiv.org/pdf/2508.08742), [HTML](https://arxiv.org/abs/2508.08742)
### Authors
Haotian Chen,Qingqing Long,Meng Xiao,Xiao Luo,Wei Ju,Chengrui Wang,Xuezhi Wang,Yuanchun Zhou,Hengshu Zhu
### Background
科学文献问答是推动新科学发现的关键步骤。最近，在检索增强生成的大语言模型（RAG-LLMs）领域中展示了显著的进步，这种两阶段框架，特别是第二阶段（重排序器），在科学领域尤为重要，因为术语上的细微差异可能会极大地影响最终的事实导向或知识密集型答案。尽管取得了这些重要进展，但这些工作的潜力和局限性尚未得到充分探索。
### Innovation
本研究提出了一种名为SciRerankBench的科学重排序器基准，用于评估RAG-LLMs系统中的重排序器，覆盖五个科学主题。为严格评估重排序器的噪声鲁棒性、语义相似但逻辑无关的去混淆能力和事实一致性，我们开发了三种类型的问题-上下文-答案（Q-C-A）对，即噪声上下文（NC）、语义相似但逻辑无关上下文（SSLI）和事实相反上下文（CC）。我们系统地评估了13种广泛使用的重排序器在五种类型的大语言模型上的表现，提供了对其相对优势和局限性的详细见解。这是第一个专门开发用于评估RAG-LLMs中重排序器的基准，为它们的未来开发提供了宝贵的观点和指导。
### Conclusion
SciRerankBench是第一个专门用于评估RAG-LLMs中重排序器的基准，通过全面的实验分析，提供了关于各种重排序器性能和限制的深入见解，为未来的研究和发展提供了指导。
## 446. `cs.CL` - 资源效率较高的大型语言模型对于文本嵌入的适应方法：基于提示工程和对比微调 [PDF](https://arxiv.org/pdf/2507.22729), [HTML](https://arxiv.org/abs/2507.22729)
### Authors
Benedikt Roth,Stephan Rappensperger,Tianming Qiu,Hamza Imamović,Julian Wörmann,Hao Shen
### Background
大型语言模型（LLMs）已成为自然语言处理（NLP）的基石，在文本生成方面表现出色。它们的令牌级表示捕捉到了丰富的人类对齐语义。然而，将这些向量聚合为文本嵌入会导致丢失关键信息。尽管如此，许多非生成下游任务如聚类、分类或检索，仍然需要准确可控的句子级或文档级嵌入。本文研究了几种预训练解码器型LLMs的适应策略：（i）不同类型的令牌嵌入聚合技术，（ii）任务特定的提示工程，（iii）通过对比微调进行文本级增强。
### Innovation
本文提出了结合提示工程和资源高效对比微调的方法，以适应预训练的解码器型大型语言模型作为文本嵌入模型。具体来说，利用提示工程和资源高效对比微调技术，实现了在大规模文本嵌入基准(MTEB)的英语聚类赛道上具有竞争力的性能。进一步的分析显示，微调使注意力从提示令牌转移到语义相关词，表明更有效压缩意义到最终隐藏状态。
### Conclusion
实验结果证明，通过结合提示工程和高效对比微调，可以有效地将大型语言模型适应为文本嵌入模型。这种方法不仅有效地利用了模型的潜力，而且在资源效率方面也表现出色。
## 447. `cs.CL` - 无返场：音乐生成中的卸载作为退出选项 [PDF](https://arxiv.org/pdf/2509.06277), [HTML](https://arxiv.org/abs/2509.06277)
### Authors
Jinju Kim,Taehan Kim,Abdul Waheed,Jong Hwan,Rita Singh
### Background
AI音乐生成在创意产业中迅速崛起，能够从文本描述中直观生成音乐。然而，这些系统在利用受版权保护的作品方面存在风险，引发了伦理和法律问题。本文旨在探讨将机器卸载技术应用于音乐生成领域，以防止无意间使用创造性内容的初步结果。具体来说，作者研究了现有的卸载方法在预训练的文本到音乐（TTM）模型中的应用，并分析了它们在不损害模型性能的情况下卸载预训练数据集的有效性。
### Innovation
探讨了将机器卸载技术应用于音乐生成领域的初步研究，并分析了卸载方法在保持模型性能的同时处理已训练数据集的有效性。这项研究为未来在音乐生成模型中应用卸载技术提供了基础性分析。
### Conclusion
通过实验，本文提供了关于在音乐生成中应用卸载技术所面临的挑战的见解，为未来研究提供了基础分析。
## 448. `cs.CL` - 跨学科研究对话：计算形态学在语言记录中的案例研究 [PDF](https://arxiv.org/pdf/2509.10644), [HTML](https://arxiv.org/abs/2509.10644)
### Authors
Enora Rice,Katharina von der Wense,Alexis Palmer
### Background
计算形态学有潜力通过形态学分段和生成间行注释文本（IGT）等任务支持语言记录。然而，我们的研究输出在真实的语言记录场景中使用有限。本研究将计算形态学与语言记录之间的脱节置于更广泛的研究与实践不一致的背景中，并认为如果不系统地整合以用户为中心设计（UCD），该领域可能会变得缺乏上下文和无效。
### Innovation
通过以用户为中心的设计原则重新塑造研究议程，本研究提出了GlossLM，这是一种最先进的多语言IGT生成模型，并通过小型用户研究发现尽管在基于指标的性能上很强，但系统在真实记录环境中未能满足用户的基本易用性需求。这些见解提出了关于模型约束、标签标准化、分段和个人化的新研究问题。并认为将用户置于中心不仅会产生更有效的工具，还会揭示更丰富和相关的研究方向。
### Conclusion
我们认为，以用户为中心的方法不仅能够产生更有效的工具，还能够揭示更丰富的、更相关的研究方向，从而明确新的研究问题，如模型约束、标签标准化、分段和个人化。
## 449. `cs.CL` - DyePack: 用后门标记LLMs中的测试集污染的可证明方法 [PDF](https://arxiv.org/pdf/2505.23001), [HTML](https://arxiv.org/abs/2505.23001)
### Authors
Yize Cheng,Wenxiao Wang,Mazda Moayeri,Soheil Feizi
### Background
公开基准对于评估和推进大语言模型至关重要，提供重现性和透明性。然而，它们的易用性使其成为潜在的测试集污染目标。DyePack框架利用后门攻击来识别在训练过程中使用基准测试集的模型，无需访问损失、logits或其他内部分布。通过在测试数据中掺入后门样本，类似于银行在钱币中掺入荧光剂来标记盗贼，DyePack可以标记出训练过程中使用了这些测试集的模型。
### Innovation
DyePack框架采用原则性设计，结合多个具有随机目标的后门，能够精确计算在标记每一个模型时的错误率累积。这种方法可以防止虚假指控并提供强证据。该研究在五个模型的三个数据集上进行评估，涵盖多项选择题和开放式生成任务。对于多项选择题，DyePack在MMLU-Pro和Big-Bench-Hard数据集上使用八个后门后，成功检测出所有污染的模型，且累积错误率为0.000073%和0.000017%。对于开放式生成任务，DyePack在六个后门下，能够很好地泛化并检测出Alpaca上的所有污染模型，且累积错误率为0.127%。
### Conclusion
DyePack框架通过结合多个具有随机目标的后门，实现了在不访问模型内部细节的情况下检测LSTM模型中的测试集污染。此方法提供了精确的错误率计算，并且可以避免错误指控，适用于多种类型的数据集，展示了良好的泛化能力。
## 450. `cs.CL` - 合成自助预训练 [PDF](https://arxiv.org/pdf/2509.15248), [HTML](https://arxiv.org/abs/2509.15248)
### Authors
Zitong Yang,Aonan Zhang,Hong Liu,Tatsunori Hashimoto,Emmanuel Candès,Chong Wang,Ruoming Pang
### Background
现有的预训练方法通常使语言模型学习单文档内部令牌之间的因果关联，但未充分利用文档间关系的学习潜力。本文旨在通过引入合成自助预训练（SBP）方法，首次从预训练数据集中学习文档之间的关系，然后利用这些关系合成大量新的语料库进行联合训练，从而进一步提高模型性能。
### Innovation
提出了合成自助预训练（SBP）方法，该方法首先从预训练数据集中学习文档间的关系模型，然后利用此模型合成立方公里新的语料库进行联合训练。这种方法旨在更高效地建模丰富且可学习的文档间关系，从而提升模型的性能。
### Conclusion
合成自助预训练（SBP）在模型性能上实现了显著的提升，证明了它能够学习到相关文档共有的潜在概念，其合成的新文档超出了简单同义词替换的范畴。除了实证性能的提升，SBP 还具有一种自然的贝叶斯解释，即合成立器会隐式学习抽取相关文档共有的潜在概念。
## 451. `cs.CL` - 低资源ASR令人头疼的简便数据增强方法 [PDF](https://arxiv.org/pdf/2509.15373), [HTML](https://arxiv.org/abs/2509.15373)
### Authors
Katsumi Ibaraki,David Chiang
### Background
本文介绍了一种针对低资源自动语音识别（ASR）的三种自包含数据增强方法。这些技术首先基于词汇表替换、随机替换或基于语言模型的方法生成新颖的文本，然后使用文本转语音（TTS）生成合成音频。这些方法仅利用原始标注数据，应用于四种极为稀缺资源的语言（Vatlongos、Nashta、Shinekhen Buryat 和 Kakabe），并在原始音频和生成的合成数据的基础上微调预训练的 Wav2Vec2-XLSR-53 模型，从而取得了显著的性能提升。
### Innovation
本文提出了利用词汇表替换、随机替换或基于语言模型的方法自动生成新颖的文本，然后利用文本转语音（TTS）生成合成音频。这种方法无需额外数据，即可显著提升低资源语言的ASR性能，特别是在资源极度匮乏的语言上表现出色。此外，该方法也适用于资源丰富如英语的语言，展示了其广泛适用性。
### Conclusion
通过将预训练的Wav2Vec2-XLSR-53模型微调在原始音频和生成的合成数据的组合上，对四种低资源语言和英语都显示出显著的性能提升。尤其是Nashta语言，绝对错误率减少了14.3%，证明了这些方法的广泛适用性和有效性。
## 452. `cs.CL` - LLMs能否以无需训练的方式推理非文本模态？基于上下文表示学习的一种案例研究 [PDF](https://arxiv.org/pdf/2509.17552), [HTML](https://arxiv.org/abs/2509.17552)
### Authors
Tianle Zhang,Wanlong Fang,Jonathan Woo,Paridhi Latawa,Deepak A.Subramanian,Alvin Chan
### Background
大型语言模型（LLMs）在测试时的性能可以通过利用外部工具或其他深度学习模型来进一步提升。然而，现有将非文本模态表示整合到LLMs中的方法通常需要额外的昂贵的监督训练，这限制了其在新领域和模态上的实时适应。
### Innovation
提出了一种无需训练的上下文表示学习（ICRL），让LLMs能够在少样本学习中适应性地利用非文本模态表示，替代传统的上下文学习中使用的文本-标签对，从而使LLMs能够无需微调完成跨模态推理。
### Conclusion
研究表明，ICRL是第一个无需训练框架，用于将非文本模态表示整合到基于文本的LLMs中。它展示了适应性、多模态泛化的有前景方向，并在其分子领域以一系列任务上进行了评估，探讨了影响ICRL性能的关键因素及其实现效果背后的机制。
## 453. `cs.CL` - 在语音LLM中评估上下文和副语言推理：一种基于现实世界数据的案例研究 [PDF](https://arxiv.org/pdf/2509.16589), [HTML](https://arxiv.org/abs/2509.16589)
### Authors
Qiongqiong Wang,Hardik Bhupendra Sailor,Tianchi Liu,Wenyu Zhang,Muhammad Huzaifah,Nattadaporn Lertcheva,Shuo Sun,Nancy F. Chen,Jinyang Wu,AiTi Aw
### Background
近期语音大语言模型在转录和翻译任务上展示了出色的表现，但在理解对于社会和情感智能至关重要的副语言方面仍然有限。我们提出了一种名为CP-Bench的新基准来评估语音大语言模型在结合口头内容与情感和语调等非口头线索的上下文副语言推理能力。基准包括两个精心挑选的问题回答（QA）数据集，需要同时具备语言理解和共情理解的能力。评估了最新的开源和闭源的语音大语言模型，并进行了不同问题类型下的全面分析。
### Innovation
提出了一个新的基准CP-Bench，用于评估语音大语言模型在上下文副语言推理的能力。与之前的评估相比，本基准着重考虑了语言和非语言线索的综合理解，这为衡量模型的社会和情感智能能力提供了新的视角。
### Conclusion
基准揭示了当前评估方式中的关键差距，并提供了关于构建更具上下文意识和情感智能的语音能力大语言模型的见解。
## 454. `cs.CL` - 以 Rumantsch Grischun, Sursilvan, Sutsilvan, Surmiran, Puter, 和 Vallader 扩展 WMT24++ 基准 [PDF](https://arxiv.org/pdf/2509.03148), [HTML](https://arxiv.org/abs/2509.03148)
### Authors
Jannis Vamvas,Ignacio Pérez Prat,Not Battesta Soliva,Sandra Baltermia-Guetg,Andrina Beeli,Simona Beeli,Madlaina Capeder,Laura Decurtins,Gian Peder Gregori,Flavia Hobi,Gabriela Holderegger,Arina Lazzarini,Viviana Lazzarini,Walter Rosselli,Bettina Vital,Anna Rutkiewicz,Rico Sennrich
### Background
罗曼什语在瑞士使用，但资源有限，尤其是在机器翻译评估方面。现有的基准主要覆盖了其他语言，导致罗曼什语机器翻译评估数据不足。本文旨在解决这一问题，提供一种基准来评估六种罗曼什语品种，包括超区域性的 Rumantsch Grischun 以及五个区域性的 Sursilvan, Sutsilvan, Surmiran, Puter 和 Vallader。这些参考翻译由基于 WMT24++ 基准的人类翻译者创建，确保与超过 55 种其他语言的平行翻译数据保持一致。
### Innovation
本文创新地将 WMT24++ 基准扩展到六种罗马什语品种，填补了罗曼什语在机器翻译评估数据上的空白。这为罗曼什语的机器翻译研究和应用提供了新的基准数据。同时，通过现有的自动评价方法，研究了不同罗曼什语品种到德语和从德语到罗曼什语的翻译性能，发现从罗曼什语到德语的翻译整体表现较好，但从德语到罗曼什语则更具挑战性。
### Conclusion
研究结果表明，罗曼什语到德语的翻译效果对所有罗曼什语品种都比较理想，但德语到罗曼什语的翻译仍是挑战。本文通过提出一种新的多变种罗曼什语基准，为自动机器翻译系统和大语言模型提供了量化评估。未来的研究可以进一步探索提升德语到罗曼什语翻译性能的方法。
## 455. `cs.CL` - MAPEX: 多智能体框架在关键短语提取中的应用 [PDF](https://arxiv.org/pdf/2509.18813), [HTML](https://arxiv.org/abs/2509.18813)
### Authors
Liting Zhang,Shiwan Zhao,Aobo Kong,Qicheng Li
### Background
关键短语提取是自然语言处理中的基础任务。现有的基于单阶段推理管道的无监督提示方法通常使用统一的提示策略，忽略了文档长度或大语言模型（LLM）的基础架构，这限制了LLMs的推理和生成能力的充分发挥，尤其是在不同场景下关键短语提取的复杂性方面.
### Innovation
我们提出了MAPEX，这是第一个引入多智能体协作的关键短语提取框架。MAPEX通过专家招募、候选提取、主题指导、知识增强和后处理模块协调LLM智能体。采用双路径策略适应不同长度的文档：知识驱动的提取处理短文档，主题引导的提取处理长文档。在三个不同的LLM上六个基准数据集上的实验表明，MAPEX具有强大的泛化能力和通用性，平均在F1@5指标上分别比最先进的无监督方法和标准LLM基线高出2.44%和4.01%.
### Conclusion
MAPEX通过复杂的智能体协作机制和不同的路径适应策略，有效地解决了关键短语提取中的挑战，展示了其在不同LTM模型和数据集上的优越表现。
## 456. `cs.CL` - 当长处有助于短处：监督微调中的上下文长度如何影响大型语言模型的行为 [PDF](https://arxiv.org/pdf/2509.18762), [HTML](https://arxiv.org/abs/2509.18762)
### Authors
Yingming Zheng,Hanqi Li,Kai Yu,Lu Chen
### Background
大型语言模型（LLMs）在自然语言处理（NLP）任务中取得了显著的性能。随着实际应用对较长上下文窗口的需求增加，持续预训练和对长上下文数据的监督微调（SFT）成为常见做法。尽管在持续预训练中数据长度的影响已被广泛研究，但对其在SFT中的影响尚不清楚。本文系统地探讨了SFT数据长度如何影响LLM在短上下文任务中的表现。
### Innovation
本文首次通过系统性研究发现，长上下文SFT反而能提高短上下文任务的表现，这与较长上下文预训练通常导致性能下降的现象相反。作者将Multi-Head Attention (MHA)和Feed-Forward Network (FFN)两个关键组件分离并单独分析，证明了它们都受益于长上下文SFT。进一步的研究揭示了知识偏好偏差：长上下文SFT促进情境知识，而短上下文SFT更有利于模型参数知识，这使得仅依赖长上下文SFT的策略可能不理想。最后，本文展示了混合训练可以缓解这一偏差，为微调LLM提供了可解释的指导。
### Conclusion
总之，本研究揭示了长上下文SFT对短上下文任务的反直觉影响，并通过分析不同组件的作用以及它们之间的交互作用，以及提出混合训练策略，为优化LLM的微调提供了新的见解。
## 457. `cs.CL` - 意大利十年计算语言学图谱：CLiC-it语料库 [PDF](https://arxiv.org/pdf/2509.19033), [HTML](https://arxiv.org/abs/2509.19033)
### Authors
Chiara Alzetta,Serena Auriemma,Alessandro Bondielli,Luca Dini,Chiara Fazzone,Alessio Miaschi,Martina Miliani,Marta Sartor
### Background
过去的十年中，计算语言学（CL）和自然语言处理（NLP）领域经历了快速的发展，尤其是在基于变换器的大型语言模型（LLMs）出现之后。这一转变不仅改变了研究目标，还从词汇和语义资源转向了语言建模和多媒体处理领域。为了更好地理解和概括意大利计算语言学和自然语言处理社区的研究趋势，本文通过对CLiC-it会议过去10个版本的会议记录进行分析，构建了一个CLiC-it语料库，涵盖了从2014年到2024年的数据分析，包括元数据和论文内容的详细分析。这一研究为意大利和国际科研社区提供了关于时间节点上的新兴趋势和关键进展的洞见，有助于支持未来的研究导向和决策制定。
### Innovation
本文通过将过去10个版本的CLiC-it会议记录编纂成CLiC-it语料库，提供了一个关于过去十年意大利计算语言学和自然语言处理社区研究趋势的全面分析。这不仅包括了论文内容的分析，还有元数据，如作者背景、性别和隶属机构等，为了解该领域的科研趋势提供了宝贵的途径。
### Conclusion
本文的研究为意大利乃至国际科研社区提供了关于计算语言学领域新兴趋势和关键进展的洞见，支持了未来相关方向的研究决策，为理解计算语言学的发展动态提供了有价值的参考。CLiC-it语料库的建立为进一步研究意大利计算语言学和自然语言处理领域的演变提供了基础。
## 458. `cs.CL` - 软令牌，坚硬的事实 [PDF](https://arxiv.org/pdf/2509.19170), [HTML](https://arxiv.org/abs/2509.19170)
### Authors
Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier
### Background
近年来，Chain-of-Thought (CoT) 阶段使用连续而不是离散标记的技术引起了人们的兴趣，基于这样的直觉认为，连续标记的混合体可以同时模拟多种推理路径的叠加。理论上，连续标记具有更大的表达能力，并能更有效地解决特定问题。然而，使用连续标记的实际应用受到强大训练难度的限制: 之前的许多工作要么仅在预训练的离散标记模型上于推理阶段使用连续标记，要么必须从真实离散的推理路径中提炼出连续推理，并且面临计算成本的限制，这使连续推理路径局限于少量标记。
### Innovation
这项工作是首创的工作，介绍了一种通过强化学习 (RL) 学习连续CoT的可扩展方法，无需从参考的离散CoT中提炼。通过使用“软”令牌：标记混合和输入嵌入中的噪声，来为RL探索提供支持。由于计算开销最小，这种方法能够学习包含数百个标记的连续CoT。在使用Llama和Qwen模型的数学推理基准测试上，使用连续CoT进行训练在pass@1上与离散标记CoT匹配，在pass@32上则超越离散标记CoT，展示出更大的CoT多样性。
### Conclusion
最好的方案是在训练时使用连续CoT令牌，然后在推理时使用离散令牌。这意味着“软”模型可以以常规的方式部署。此外，连续CoT的RL训练与基准模型在域外任务上的预测具有更好的一致性，从而为基模型提供了更柔和的处理方式。
## 459. `cs.CL` - 统一符号音乐编配：针对轨道的重建和结构化分词 [PDF](https://arxiv.org/pdf/2408.15176), [HTML](https://arxiv.org/abs/2408.15176)
### Authors
Longshen Ou,Jingwei Zhao,Ziyu Wang,Gus Xia,Qihao Liang,Torin Hopkins Ye Wang
### Background
本文介绍了一个统一的自动多轨音乐编配框架，该框架能够使用一个预先训练好的音乐模型处理不同的编配场景，包括重新解释、简化和增加生成。此框架的核心在于一种段落级别的重建目标，该目标可以将标记级别内容和风格分离，允许在推理时进行灵活的任意到任意的乐器变换。
### Innovation
文章引入了REMI-z，一种多轨符号音乐的结构化分词方案，提高了模型的建模效率和有效性，尤其适用于编配任务和无条件生成。该方法在不同的编配场景——乐队编配、钢琴简化和鼓编配中，客观和感知上都优于特定任务的最新模型。
### Conclusion
我们的框架展示了很强的通用性，并暗示了在符号音乐到音乐的转换方面更广泛的应用可能性。
## 460. `cs.CL` - 在线过程奖励学习在代理强化学习中的应用 [PDF](https://arxiv.org/pdf/2509.19199), [HTML](https://arxiv.org/abs/2509.19199)
### Authors
Xiaoqian Liu,Ke Wang,Yuchuan Wu,Fei Huang,Yongbin Li,Junge Zhang,Jianbin Jiao
### Background
大型语言模型（LLMs）通过强化学习（RL）作为自主代理，在交互环境中进行长时间推理和行动的训练已经变得越来越普遍。但是，稀疏且有时不可验证的奖励使得时间上的信用分配变得极其困难。近些年的工作试图将流程监督整合到代理学习中，但面临着标注偏差、奖励劫持、过细信号带来的高方差或在状态重叠罕见时的失败问题。
### Innovation
本文提出了在线过程奖励学习（OPRL），这是一种与标准在线策略算法无缝集成的一般信用分配策略，无需额外的展开或显式步骤标签。OPRL中，优化了显式的流程奖励模型（PRM）与代理策略交替优化，通过基于轨迹的DPO目标将轨迹偏好转变为隐式步骤奖励。这些步骤奖励随后用于计算步骤级别的优势，优势组合来自结果奖励的 episode 级别优势，从而创建自增强循环。理论成果保证了学习的步骤奖励与轨迹偏好一致，并作为潜在形塑奖励，提供了界限内的梯度以稳定训练。实验上，OPRL 在三个不同代理基准测试（包括 WebShop 和 VisualSokoban）上进行了评估，并在 SOTOPIA 的开放性社会互动中面对不可验证奖励的情况下进行评估。
### Conclusion
OPRL 在各个领域中的性能都优于前沿的 LLMs 和强 RL 基线，并且在训练期间显示出更高的样本效率和更低的方差。进一步的分析还表明，OPRL 使用更少的操作进行有效的探索，这强调了其在现实世界场景中代理学习的潜力。
## 461. `cs.CL` - 任意精度和稀疏度下稳健的神经网络训练 [PDF](https://arxiv.org/pdf/2409.09245), [HTML](https://arxiv.org/abs/2409.09245)
### Authors
Chengxi Ye,Grace Chu,Yanfeng Liu,Yichi Zhang,Lukasz Lew,Li Zhang,Mark Sandler,Andrew Howard
### Background
量化和稀疏化操作的断续性在反向传播中一直是一个长期存在的障碍，特别是在超低精度和稀疏性场景中。标准的直接通道估算器（STE）广泛用于解决这一问题，但由于其量化感知前向传播和量化无意识后向传播之间的已知不匹配，导致了不可管理的误差，这可能会破坏学习过程。
### Innovation
作者通过引入一个从稳健岭回归目标派生的去噪去量化变换解决了这个难题。这个变换使整个学习过程能够意识到并抵御STE的代数值梯度所忽略的量化误差，通过创建一个明确的纠正梯度路径。作者还将这一原则扩展到稀疏化，将其视为一种特殊的量化形式，将不重要的值映射为零。本文提供了一个统一框架，允许现有模型在广泛的精度和稀疏性水平下使用现成的菜谱进行稳定训练，实现了完全二进制（A1W1）和亚1位稀疏网络的训练，而其他方法则无法处理。
### Conclusion
这种方法取得了最先进的结果，并提供了一条通往超高效率神经网络的理论基础路径。
## 462. `cs.CL` - 语言模型代理的树搜索 [PDF](https://arxiv.org/pdf/2407.01476), [HTML](https://arxiv.org/abs/2407.01476)
### Authors
Jing Yu Koh,Stephen McAleer,Daniel Fried,Ruslan Salakhutdinov
### Background
自主代理（由语言模型驱动）在执行网页自动化等决策任务方面表现出希望，但主要优化用于自然语言理解与生成的语言模型在解决现实计算机任务时，难以进行多步骤推理、规划和利用环境反馈。为了克服此问题，作者提出在实际环境空间中进行树搜索算法来实现代理的探索和多步规划。这种算法与现有的最佳代理方案相兼容，并首次展示出在现实网页任务中有效性的树搜索算法。在具有挑战性的VisualWebArena基准上，此树搜索算法提升了GPT-4o代理的成功率39.7%，达到了26.4%的最高成功率。在WebArena基准上，树搜索算法也提升了基线代理的成功率28.0%，达到了19.2%的较高成功率为基线的成功率对手提供了竞争力。实验结果显示树搜索对于网页代理的有效性，并强调了测试计算量增加对性能的影响。
### Innovation
提出了一种在实际环境空间中进行的、最佳优先树搜索算法，用于语言模型代理进行多步探索和规划。这是首次在现实网页任务中有效性的树搜索算法应用于语言模型代理上，显著提升了代理的成功率。
### Conclusion
此项研究展示了树搜索对于网页代理的有效性，并指出性能随测试计算量增加而提升。作者通过全面分析结果探讨了搜索带来的改进点、局限性以及未来研究的潜在方向。研究中使用的代码和模型已经公开发布。
## 463. `cs.CL` - 一个生成AI框架用于医疗记录生成 [PDF](https://arxiv.org/pdf/2410.01841), [HTML](https://arxiv.org/abs/2410.01841)
### Authors
Hui Yi Leong,Yi Fan Gao,Shuai Ji,Bora Kalaycioglu,Uktu Pamuksuz
### Background
随着电子健康记录（EHR）的增多，医疗文档的行政负担日益增加，这减少了直接面对患者的护理时间，并导致了医师的倦怠。为此，通过对以医疗对话为基础自动生成SOAP（病历部分包括：主诉、体检、评估、计划）记的尝试，来解决这个问题。
### Innovation
MediNotes是一个高级生成AI框架，它结合了大型语言模型（LLMs）、检索增强生成（RAG）、以及自动语音识别（ASR），用于实时或从录音中捕捉和处理文本和语音输入，生成结构化且上下文相关的医疗记录。此外，MediNotes还采用先进的技术如量化低秩适应（QLoRA）和参数高效微调（PEFT），以在资源受限的环境中高效调整模型。MediNotes还提供了一个基于查询的检索系统，使医疗提供者和患者能够快速准确地访问相关信息。通过使用ACI-BENCH数据集进行评估，证明了MediNotes显著提高了自动化医疗记录的准确性、效率和可用性，提供了一种减少医疗专业人员行政负担的有力解决方案，同时提高了临床工作流程的质量。
### Conclusion
MediNotes通过自动化生成SOAP笔记，提高了自动化医疗记录的准确性和效率，为减轻医疗工作者的行政负担并优化临床工作流程提供了一个强大的解决方案。
## 464. `cs.CL` - GraphEQA: 使用3D语义场景图进行实时体态问答 [PDF](https://arxiv.org/pdf/2412.14480), [HTML](https://arxiv.org/abs/2412.14480)
### Authors
Saumya Saxena,Blake Buchanan,Chris Paxton,Peiqi Liu,Bingqing Chen,Narunas Vaskevicius,Luigi Palmieri,Jonathan Francis,Oliver Kroemer
### Background
在体态问答（EQA）中，代理必须探索并发展对未见过环境的语义理解，以有信心地回答定位问题。机器人领域中的这一问题仍然具有挑战性，因为获得有用的语义表示、在线更新这些表示以及利用先验世界知识进行高效规划和探索都存在困难。
### Innovation
GraphEQA是一种新颖的方法，它利用实时的3D度量语义场景图（3DSG）和任务相关图像作为多模态记忆，为视觉-语言模型（VLM）提供基础，以执行未见过环境中的EQA任务。采用分层规划方法，利用3DSG的分层性质进行结构化的规划和语义引导的探索。在两个基准数据集HM-EQA和OpenEQA上的模拟测试中，GraphEQA的表现优于关键基准模型，成功完成EQA任务所需步骤更少且成功率更高。进一步在多个现实世界的家庭和办公环境中展示了GraphEQA的效果。
### Conclusion
GraphEQA通过实时3D度量语义场景图提供了一种新颖的方法，该方法能够在未见过的环境中执行EQA任务，并通过分层规划和语义引导的探索提高了问答的成功率和效率。
## 465. `cs.CL` - 超越大纲：语言模型中异构递归规划的自适应长文写作 [PDF](https://arxiv.org/pdf/2503.08275), [HTML](https://arxiv.org/abs/2503.08275)
### Authors
Ruibin Xiong,Yimeng Chen,Dmitrii Khizbullin,Mingchen Zhuge,Jürgen Schmidhuber
### Background
当前长文写作代理依赖于预定义的工作流和固定的思考模式，通过事先生成大纲来完成写作，这种做法导致在实际写作过程中缺乏灵活性。
### Innovation
提出了一种名为WriteHERE的通用代理框架，通过递归的任务分解和动态整合检索、推理和组合三种基本任务类型，实现了类似人类的自适应写作。该框架的特点是：1）综合规划机制，融合递归任务分解和执行，消除了写作工作流的限制；2）不同任务类型的整合，有助于异构任务分解。
### Conclusion
在小说写作和科技报告生成等方面的研究中，我们的方法在所有自动评估指标上都优于现有方法，展示了我们所提框架的有效性和广泛适用性。我们已经公开发布了代码和提示，以促进进一步的研究。
## 466. `cs.CL` - HawkBench: 在分层信息检索任务中调查 RAG 方法的适应性 [PDF](https://arxiv.org/pdf/2502.13465), [HTML](https://arxiv.org/abs/2502.13465)
### Authors
Hongjin Qian,Zheng Liu,Chao Gao,Yankai Wang,Defu Lian,Zhicheng Dou
### Background
在现实世界的信息检索场景中，用户的需求是动态的和多样的，这要求RAG系统能够展现出适应性的韧性。为了全面评估当前RAG方法的适应性，作者引入了HawkBench，这是一个由人工标注的多领域基准，旨在严格评估RAG在不同任务类型下的表现。HawkBench通过基于信息检索行为对任务进行分层，提供了一个系统性的评估方法，以检验RAG系统如何适应多样化的用户需求。现有的基准大多集中在特定任务类型（主要是事实性查询）上，并依赖于不同的知识库，而HawkBench则提供了更具系统性、覆盖更广泛的查询类型，并集成了多领域的语料库，以减轻语料库偏差，并进行了严格的注释以确保高质量的评估。
### Innovation
HawkBench提供系统性的任务分层，涵盖了广泛的查询类型，包括事实性和推理查询；集成了多领域的语料库，消除了语料库偏差；进行了严格的标注以保证高质量的评估。HawkBench包括1600个高质量的测试样本，均匀分布于各个领域和任务类型。
### Conclusion
我们的研究结果强调了需要动态任务策略，结合决策制定、查询解释和全局知识理解，以提高RAG的一般适应性。我们相信HawkBench为促进RAG方法的适应能力和实现通用信息检索奠定了一个关键基准。
## 467. `cs.CL` - 向具有多模态大型语言模型的视觉文本定位 [PDF](https://arxiv.org/pdf/2504.04974), [HTML](https://arxiv.org/abs/2504.04974)
### Authors
Ming Li,Ruiyi Zhang,Jian Chen,Chenguang Wang,Jiuxiang Gu,Yufan Zhou,Franck Dernoncourt,Wanrong Zhu,Tianyi Zhou,Tong Sun
### Background
尽管已经存在了具备多模态能力的大型语言模型（MLLMs），但在视觉文本定位方面，尤其是在处理包含大量文本的文档图像时，仍然存在显著的挑战。当前的基准测试主要关注自然图像的视觉定位，并未完全涵盖文档图像的复杂布局和文本内容所带来的挑战。
### Innovation
为了弥合这一差距，本研究引入了TRIG（Text-Rich Image Grounding）任务及其新的指令数据集，旨在评估和提升MLLMs在文档问答中的文本丰富的图像定位能力。提出了一个OCR-LLM-人工交互的管道来创建800个手动标注的问答对作为基准和一个基于四个不同数据集的90,000个合成数据的大型训练集。并通过在所提基准上对多种MLLMs的全面评估，揭示了其在文本丰富的图像上的定位能力存在的不足。在此基础上，提出了两种简单有效的TRIG方法：基于通用指令调优和即插即用高效的嵌入。
### Conclusion
通过在合成数据集上调优MLLMs，它们在空间推理和定位能力方面表现出显著的改进。
## 468. `cs.CL` - CNS-Obsidian: 从科学出版物构建的神经外科视觉语言模型 [PDF](https://arxiv.org/pdf/2502.19546), [HTML](https://arxiv.org/abs/2502.19546)
### Authors
Anton Alyakin,Jaden Stryker,Daniel Alexander Alber,Karl L. Sangwon,Jin Vivian Lee,Brandon Duderstadt,Akshay Save,David Kurland,Spencer Frome,Shrutika Singh,Jeff Zhang,Eunice Yang,Ki Yun Park,Cordelia Orillac,Aly A. Valliani,Sean Neifert,Albert Liu,Aneek Patel,Christopher Livia,Darryl Lau,Ilya Laufer,Peter A. Rozman,Eveline Teresa Hidalgo,Howard Riina,Rui Feng,Todd Hollon,Yindalon Aphinyanaphongs,John G. Golfinos,Laura Snyder,Eric Leuthardt,Douglas Kondziolka,Eric Karl Oermann
### Background
通用的视觉语言模型（VLMs）展示了强大的能力，但在使用未经筛选的互联网数据进行不透明训练时，这些模型存在关键限制，特别是在高风险决策领域，如神经外科。因此，研究人员开发了CNS-Obsidian，这是一种在经过同行评审的神经外科文献上训练的神经外科专用VLM，以评估其在真实临床环境中的实用性，并将其与GPT-4o进行比较。
### Innovation
CNS-Obsidian是一个基于340亿参数LLaVA-Next模型的微调版本，通过来自神经外科出版期刊的23,984篇文章（78,853个图像和说明），建立了263,064个训练样本。模型在一项盲测部署试验中进行了测试，结果显示，尽管在合成问题上与GPT-4o匹配，在真实生成的问题上表现较弱，但两种模型在临床诊断中的使用率差异不大。研究还发现，尽管这些专用模型性能接近前沿模型，但在临床使用方面仍有改进空间。
### Conclusion
领域专用的VLMs，通过精心筛选的科学文献训练，能够接近专业医疗领域的前沿模型性能，但相比之下，这些模型的临床利用率较低，表明聊天机器人界面可能不适用于专业团队的工作流程，需要探索其他AI整合策略。
## 469. `cs.CL` - AAPO: 通过优势动量增强大语言模型的推理能力 [PDF](https://arxiv.org/pdf/2505.14264), [HTML](https://arxiv.org/abs/2505.14264)
### Authors
Jian Xiong,Jingbo Zhou,Jingyong Ye,Qiang Huang,Dejing Dou
### Background
强化学习（RL）作为一种有效的方法，已被用于增强大型语言模型（LLMs）的推理能力，特别是在监督微调（SFT）受限的情况下，如缺乏链式思考（CoT）数据。在基于RL的后训练方法中，作为组相对优势估计范例的Group Relative Policy Optimization（GRPO）因其消除了对价值模型的依赖而吸引了很多关注，这与传统的Proximal Policy Optimization（PPO）相比简化了训练过程。然而，现有的优势估计方法仍然存在训练效率低下的问题，特别是当优势估计接近零时，缓解这方面的不足十分必要。
### Innovation
我们提出了Advantage-Augmented Policy Optimization（AAPO），这是一种创新的RL算法，通过利用动量估计方案增强的优势来优化交叉熵（CE）损失，有效减轻了组相对优势估计所带来的低效率。
### Conclusion
实验结果在多个数学推理基准上展示了AAPO的优越性能。
## 470. `cs.CL` - Stepwise Guided Policy Optimization: 在GRPO中绘制你的错误推理 [PDF](https://arxiv.org/pdf/2505.11595), [HTML](https://arxiv.org/abs/2505.11595)
### Authors
Peter Chen,Xiaopeng Li,Ziniu Li,Xi Chen,Tianyi Lin
### Background
强化学习（RL）已经被证明能够增强大型语言模型（LLMs）的推理能力。一种广泛使用的GRPO方法在训练DeepSeek-R1时表现出强大的实证结果，但是当一个组内的所有响应都是错误的（即“所有负样本”组）时，GRPO无法更新策略。这一局限性揭示了人工智能与人类智能之间的一个关键差异：人类可以从错误中学到东西，但GRPO却忽略了这些信号。
### Innovation
本文提出了一种简单的框架，通过在组内引入响应多样性来缓解所有负样本的问题，使用分步引导策略优化（SGPO）模型，可以是直接训练或从现有的LLMs中调整而来。证明了这种多样性可以加速GRPO在简化设置下的学习动态。通过实验证明SGPO方法在不同规模的模型中（7B, 14B, 32B）在线下和线上训练上均表现出一致的改进效果，特别是在早期和中期训练阶段，这些阶段出现大量所有负样本组。SGPO的一个优势是它不需要生成正确答案的评判模型，与知识蒸馏方法不同。
### Conclusion
SGPO在早期和中期训练阶段优于GRPO，特别是当所有负样本组普遍出现时；并且，SGPO不需要评判模型生成正确答案，这使其与知识蒸馏方法区分开来。
## 471. `cs.CL` -  Redemption Score: 一种基于分布、感知和语义信号三角融合的多模态图像字幕评估框架 [PDF](https://arxiv.org/pdf/2505.16180), [HTML](https://arxiv.org/abs/2505.16180)
### Authors
Ashim Dahal,Ankit Ghimire,Saydul Akbar Murad,Nick Rahimi
### Background
评估图像字幕需要综合评估视觉语义和语言语用学，但大多数现有的评价指标无法全面捕捉到这一点。因此，学者们需要开发新的评价框架来更全面地评估图像字幕的质量。本文介绍了Redemption Score (RS)框架，这是一个新颖的混合评价框架，它通过综合三个互补的信号来排名图像字幕：全局图像-文本分布一致性、循环生成图像的感知相似性和LLM文本嵌入的上下文文本相似性。这些信号的校准融合使RS能够提供更全面的评价。
### Innovation
提出的Redemption Score (RS)框架是第一个同时考虑图像-文本分布一致性、感知相似性和上下文文本相似性的多模态图像字幕评估框架。RS框架通过一个新提出的校准融合方法，更全面地评估图像字幕的质量，并且在Flickr8k基准测试中取得了显著的效果，表现出优于大多数之前方法的性能，同时不需要针对特定任务进行训练，具有更高的与人类判断的相关性。
### Conclusion
Redemption Score框架通过全面检查视觉准确性和文本质量，提供了一种更稳健和细腻的评价。该框架在Conceptual Captions和MS COCO数据集上表现一致，显示出良好的性能和适用性，具有广泛的应用潜力。
## 472. `cs.CL` - Localized LoRA: 一种高效的结构化低秩近似方法 [PDF](https://arxiv.org/pdf/2506.00236), [HTML](https://arxiv.org/abs/2506.00236)
### Authors
Babak Barazandeh,Subhabrata Majumdar,Om Rajyaguru,George Michailidis
### Background
参数精简微调（PEFT）方法，例如LoRA，通过向预训练权重引入低秩更新，提供了全模型微调的紧凑且有效的替代方案。然而，现有的大多数方法依赖于全局低秩结构，这可能会忽视在参数空间中散布的空间模式。
### Innovation
本文提出了一种局部LoRA，这是一种通用框架，通过将低秩矩阵应用于权重矩阵的结构化块来建模权重更新。这种方法可以在不增加可训练参数数量的情况下，在参数空间中实现密集且局部化的更新。此外，作者对全局、局部对角线和全面局部低秩近似进行了正式比较，证明了该方法在匹配参数预算下具有更低的近似误差。
### Conclusion
在合成和实际设置中的实验表明，局部LoRA 提供了比现有方法更具表现力且更适应的选择，可以实现高效的微调，并提高性能。
## 473. `cs.CL` - WikiGap: 通过揭示英语维基百科与其他语言版之间的知识差距来促进知识公平 [PDF](https://arxiv.org/pdf/2505.24195), [HTML](https://arxiv.org/abs/2505.24195)
### Authors
Zining Wang,Yuxuan Zhang,Dongwook Yoon,Nicholas Vincent,Farhan Samir,Vered Shwartz
### Background
英语维基百科因其庞大的页面访问量，在全球知识访问中占据主导地位，相比之下，其他语言版维基百科的重要性被忽视。读者容易认为英语维基百科包含了所有语言版维基百科的信息，而忽略了其他语言版维基百科里丰富且互补的文化信息。尽管维基百科的用户界面通过多语言链接系统（ILL）支持语言间切换，但并未告知用户其他语言版维基百科中同样有着有价值的信息。
### Innovation
WikiGap系统能够通过英语维基百科的用户界面展示来自法语、俄罗斯语和中文维基百科中的互补信息，通过最新多语言信息缺口发现方法与用户中心化设计的结合，实现了跨语言版维基百科信息的有效交互和展示。研究结果显示，WikiGap显著提高了事实查找的准确性，减少了任务时间，并获得了比现有ILL导航系统更高的易用性评分。
### Conclusion
WikiGap为不同语言版维基百科间的知识公平创造了新的机遇，提高了用户对非英语版本维基百科信息的认识，并促使用户重新评估英语维基百科的完整性。它为实现跨语言版维基百科的知识公平迈出了一步。
## 474. `cs.CL` - DRES: 通过动态表示和集成选择检测假新闻 [PDF](https://arxiv.org/pdf/2509.16893), [HTML](https://arxiv.org/abs/2509.16893)
### Authors
Faramarz Farhangian,Leandro A. Ensina,George D. C. Cavalcanti,Rafael M. O. Cruz
### Background
社交媒体上传播信息的速度加快使得基于文本的假新闻检测变得至关重要，因为其对社会的影响。此前，没有足够有效的假新闻检测方法能够准确识别假新闻。
### Innovation
提出了一种名为DRES（Dynamic Representation and Ensemble Selection，动态表示和集成选择）的新检测方法。通过利用实例硬度度量来估算每个新闻文章在多种文本特征表示下的分类难度，并动态选择最合适的文本表示和分类器集成，从而显著提高预测准确性。
### Conclusion
广泛的实验表明，DRES超越了当前最先进的方法，在基于实例硬度的表示选择和动态集成选择方面表现出明显的效果提升。相关代码和数据见：this https URL
## 475. `cs.CL` - Urania：AI使用中的差分隐私洞察 [PDF](https://arxiv.org/pdf/2506.04681), [HTML](https://arxiv.org/abs/2506.04681)
### Authors
Daogao Liu,Edith Cohen,Badih Ghazi,Peter Kairouz,Pritish Kamath,Alexander Knop,Ravi Kumar,Pasin Manurangsi,Adam Sealfon,Da Yu,Chiyuan Zhang
### Background
本文介绍了Urania，一种用于生成有关大规模语言模型（LLM）聊天机器人类交互的新颖框架，该框架提供严格的数据差分隐私（DP）保证。通过利用差分隐私工具（如聚类、分区选择和基于直方图的总结），Urania提供端到端的隐私保护。具体来说，Urania通过私有聚类机制和创新的关键词提取方法（基于频率、基于TF-IDF和基于LLM的方法）来处理这些交互。
### Innovation
Urania的主要创新包括：1) 采用了私有聚类机制；2) 运用了频率、TF-IDF和基于LLM的关键词提取方法；3) 利用了差分隐私工具（如聚类、分区选择和基于直方图的总结），以提供端到端的隐私保护。同时，该框架进行了一系列评估，与非私有的Clio启发式管道进行了对比，展示了其在保留词法和语义内容的同时，增强了数据的实用性和隐私性保护。
### Conclusion
研究表明，Urania框架能够有效提取有意义的对话洞察，同时严格保护用户隐私，实现了数据实用性与隐私保护的平衡。此外，该框架还包含了一个简单的经验性隐私评估，证明了其DP管道的高度健壮性。
## 476. `cs.CL` - 开放源代码从创始人领导到社区治理模式的模式 [PDF](https://arxiv.org/pdf/2509.16295), [HTML](https://arxiv.org/abs/2509.16295)
### Authors
Mobina Noori,Mahasweta Chakraborti,Amy X Zhang,Seth Frey
### Background
开放数字公共基础设施需要社区管理来确保问责制、可持续性和鲁棒性。然而，开源项目往往依赖于中心化的决策机制，成功社区管理的因素仍然不明确。本文通过分析637个GitHub存储库，追踪从创始人领导到共享治理的转变过程，揭示了这种转变的路径模式和演变特点。
### Innovation
研究通过提取受版控制系统中的机构角色、行动和义务提示来分析开源项目的社区治理过程。运用语义解析管道将这些元素聚类到更广泛的角色和行动类型中。研究发现，随着时间的推移，角色和职责的复杂度增加，治理范围和分化也有所增强，这反映在项目治理体系的发展和完善上。这为追踪社区治理制度的发展提供了一个可扩展的分析框架。
### Conclusion
随着向社区治理的过渡成熟起来，项目越来越多地管理生态系统级的关系，并为项目监督角色添加定义。这项研究为开放源代码软件从小型创始人群体到集体管理的过程提供了新的视角，以及发展的可扩展分析管道。
## 477. `cs.CL` - CogAtom: 从认知原子到大型语言模型中的奥林匹克级别数学推理 [PDF](https://arxiv.org/pdf/2509.17318), [HTML](https://arxiv.org/abs/2509.17318)
### Authors
Zhuofan Chen,Jiyuan He,Yichi Zhang,Xing Hu,Haoxing Wen,Jun Bai,Wenge Rong
### Background
大型语言模型在数学推理方面面临挑战，特别是在多步推理和抽象概念整合的需求上。虽然现有的测试时缩放技术依赖于高质量的挑战性问题，但奥林匹克级别数学问题的稀缺性仍然是一个瓶颈。CogAtom 设计为一种新的基于认知原子的框架，以合成数学严格且认知多样化的题目，解决了这一问题。
### Innovation
CogAtom 将问题构建过程视为选择和重新组合来自人类解决方案的基本推理单元（认知原子）的过程。一个促进多样性的随机漫步算法探索认知原子空间，而基于约束的重组机制确保逻辑正确性和结构有效性。其图结构的组合性质提供了近乎无限的推理路径空间，随机漫步算法系统地探索这些空间实现大规模高质量问题的合成；同时，通过控制认知原子的数量，精确调整题目难度，确保生成问题的多样性和可扩展性。实验结果表明，CogAtom 在准确性、推理深度和多样性方面优于现有方法，生成的题目难度接近AIME级别，且在结构多样性上超越AIME。
### Conclusion
这项工作提供了一条认知基础的路径，以实现大型语言模型中的可扩展和高质量数学问题合成；同时，代码已经公开，可供进一步研究使用。
## 478. `cs.CL` - Citrus-V：结合统一医学图像基础实现临床推理的先进医学基础模型 [PDF](https://arxiv.org/pdf/2509.19090), [HTML](https://arxiv.org/abs/2509.19090)
### Authors
Guoxin Wang,Jun Zhao,Xinyi Liu,Yanbo Liu,Xuyang Cao,Chao Li,Zhuoyun Liu,Qintian Sun,Fangru Zhou,Haoqiang Xing,Zhenhong Yang
### Background
医学成像为临床诊断、治疗规划和手术决策提供关键证据，但现有的大多数成像模型都过于狭窄，需要多个专门网络，限制了它们的推广。虽然大型语言和多模态模型具有强大的推理和多任务能力，在现实世界的临床应用中，却需要精确的视觉定位、多模态集成和链式推理能力。
### Innovation
我们提出了一个称为Citrus-V的多模态医学基础模型，该模型结合了图像分析和文本推理。该模型整合了检测、分割以及连贯的多模态推理，使其可以在单一框架中实现像素级病灶定位、结构化报告生成和类似医生的诊断推断。我们提出了一种新颖的多模态训练方法，并发布了涵盖推理、检测、分割和文档理解任务的定制开源数据集。评估结果表明Citrus-V在多个基准测试上优于现有的开源医学模型和专家级别的成像系统，提供了一个从视觉基础到临床推理的统一管道，支持精准病变量化、自动化报告和可靠的第二意见。
### Conclusion
实验结果表明，Citrus-V在多个基准测试中优于现有开源和专家水平的成像系统，为医学领域的临床推理提供了一个统一的视觉基础管道，支持精确的病变量化、自动化报告和可靠的第二意见。
## 479. `cs.CL` - CLOSP: SAR, MSI and 文本统一语义空间在遥感中的应用 [PDF](https://arxiv.org/pdf/2507.10403), [HTML](https://arxiv.org/abs/2507.10403)
### Authors
Daniele Rege Cambrin,Lorenzo Vaiani,Giuseppe Gallipoli,Luca Cagliero,Paolo Garza
### Background
从广阔卫星档案中检索相关图像对于灾害响应和长期气候变化监测等应用至关重要。然而，大多数基于文本的图像检索系统仅限于RGB数据，未能利用其他传感器（如合成孔径雷达（SAR）捕捉的全天候结构敏感性或多光谱光学数据中的光谱特征）独有的物理信息。因此，本文介绍了CrisilandMark，这是一个包含647,000多幅配以稀疏文本注释的Sentinel-1 SAR和Sentinel-2多光谱图像的大规模数据集，这些注释来源于权威的土地覆盖系统（CORINE和Dynamic World）和特定危机事件的数据源。通过对这些数据集进行了实验验证，表明CLOSP能够将未配对的光学和SAR图像映射到统一的嵌入空间，并取得了现有模型在nDGC@1000指标上54%的提升。统一培训策略克服了SAR图像解释的内在难度，通过从光学领域传输丰富的语义知识，实现了间接交互的效果。另外，GeoCLOSP通过集成地理坐标，展示了在通用语义任务与特定地理事件检索之间的强大权衡。这种工作突显了不同类型传感器数据以及地理上下文融合的必要性以挖掘遥感档案的全部潜力。
### Innovation
本文提出了CLOSP（Contrastive Language Optical SAR Pretraining）框架，该框架通过文本作为桥梁将未配对的光学和SAR图像映射到统一的嵌入空间。利用统一培训策略，CLOSP将丰富的语义知识从光学领域传输到SAR图像，克服了解释SAR图像的难度；而GeoCLOSP在CLOSP的基础上进一步整合了地理坐标，使得模型既能完成一般语义任务，又能专门用于检索地理位置相关的应急事件和稀有地理特征，展示了不同传感器数据与地理上下文融合的应用潜力。
### Conclusion
本文提出的CLOSP框架通过对海量SAR和多光谱数据的配对与预训练，不仅提升了灾害响应和气候变化监测等领域的图像检索能力，而且通过引入地理坐标，使得模型能够平衡通用语义任务和特定地理事件的检索需求，充分展示了不同类型传感器数据融合和地理上下文在遥感应用中的重要性。
## 480. `cs.CL` - OmniSpatial：为视觉语言模型构建全面的空间推理基准 [PDF](https://arxiv.org/pdf/2506.03135), [HTML](https://arxiv.org/abs/2506.03135)
### Authors
Mengdi Jia,Zekun Qi,Shaochen Zhang,Wenyao Zhang,Xinqiang Yu,Jiawei He,He Wang,Li Yi
### Background
空间推理是认知心理学的关键方面，仍然是当前视觉-语言模型（VLMs）的瓶颈。尽管有大量的研究致力于评估或改进VLMs对基本空间关系的理解，如区分左右、远近以及物体计数，但这些任务仅覆盖了空间推理的最基础层面，并且在最新的推理模型中已接近饱和。
### Innovation
我们引入了OmniSpatial，这是一个全面且具有挑战性的空间推理基准，基于认知心理学。OmniSpatial涵盖了四大类别：动态推理、复杂空间逻辑、空间互动和视角推理，包含50个细分类。通过仔细的手动注释，我们构建了超过8400个问答对。广泛的实验表明，无论是开源还是闭源的VLMs，在全面的空间推理方面都表现出显著的局限性。我们还探索了两种策略—PointGraph（明确的场景图提示）和SpatialCoT（新颖视角的思维链）—以增强空间推理。
### Conclusion
实验结果表明，现有VLMs在全面空间推理方面存在显著不足。我们提出的OmniSpatial基准能够更好地评估和促进VLMs的空间推理能力。
## 481. `cs.CL` - Safe-SAIL：通过稀疏自编码器解释框架迈向大型语言模型细粒度的安全景观 [PDF](https://arxiv.org/pdf/2509.18127), [HTML](https://arxiv.org/abs/2509.18127)
### Authors
Jiaqi Weng,Han Zheng,Hanyu Zhang,Qinqin He,Jialing Tao,Hui Xue,Zhixuan Chu,Xiting Wang
### Background
大型语言模型（LLMs）在实际应用中的部署引发了显著的安全问题。目前大多数相关的安全研究都集中在评估LLM的输出或专门的安全任务上，限制了它们对广泛且未定义的风险的应对能力。现有方法用稀疏自编码器（SAEs）来增强模型行为的可解释性，但这些方法缺乏对细粒度安全概念的解释，无法充分应对如生成有毒回应和违反安全规定等关键安全行为。为了进行严格的网络安全分析，必须提取多样化且相关的安全特征，以有效捕捉这些高风险行为，同时也面临着两个挑战：识别最有可能产生安全概念特异性神经元的SAE以及详细特征解释的高昂成本。因此，本文提出Safe-SAIL框架，以提高大型语言模型在安全领域的机制性理解。
### Innovation
Safe-SAIL框架用于在LLM中解释SAE特征，以提升安全领域的机制理解。该框架系统地识别具有最佳概念特定解释性的SAE，解释安全相关的神经元，并引入高效的策略来扩大解释过程的规模。此外，它还将提供一个全面的工具包，包括SAE检查点和可读性解释的神经元，支持对LLM安全风险的经验分析，促进LLM安全领域研究的发展。
### Conclusion
Safe-SAIL框架通过系统地识别具有最佳概念特定解释性的SAE，解释安全相关的神经元，并提供高效的策略以实现解释过程的扩展来提升大型语言模型的安全性。它还将提供一个包括SAE检查点和可读性神经元解释的全面工具包，以支持安全风险的经验分析，推动LLM安全领域的研究。
## 482. `cs.CV` - iFinder: 驾驶记录仪视频零样本基于结构化视觉的大语言模型约束框架 [PDF](https://arxiv.org/pdf/2509.19552), [HTML](https://arxiv.org/abs/2509.19552)
### Authors
Manyi Yao,Bingbing Zhuang,Sparsh Garg,Amit Roy-Chowdhury,Christian Shelton,Manmohan Chandraker,Abhishek Aich
### Background
在不需要激光雷达、GPS等其他传感器的情况下，基于视觉的语言模型（V-VLMs）在分析驾驶记录仪视频中的空间推理、因果关系推断和事件解释方面面临挑战。由于大语言模型（LLMs）通常在通用任务上训练，缺乏结构化的归纳偏置，将它们嵌入特定领域的任务背景中显得尤为困难。为了解决这些问题，iFinder通过将视频解构为层次化、可解释的数据结构，将感知与推理分离开来，为LLMs提供特定于驾驶领域的理解和推断支持，提升了模型的准确性和解释性.
### Innovation
iFinder是一个结构化语义约束框架，它通过预训练的视觉模型提取关键线索，如目标姿态、车道位置和目标轨迹，并将这些信息组织成帧级和视频级的结构。它采用三模块提示策略，通过逐步、基于线索的推理，使LLMs能够改进现有V-VLMs的结果，并提供准确的推断。通过结合特定于驾驶领域的表征，iFinder为零样本条件下的驾驶记录仪视频理解提供了一种零样本、可解释且可靠的替代方案，相较于端到端的V-VLMs，准确率提高了39%以上.
### Conclusion
通过将LLMs与驾驶领域的特定表示进行约束，iFinder为零样本条件下的驾驶记录仪视频理解提供了一种替代方案。这种结构化的零样本视觉约束框架提升了LLMs在零样本驾驶视频理解任务中的性能和解释性，与端到端的V-VLMs相比，准确率提高了39%以上。
## 483. `cs.CV` - 基于4D雷达的点云预测中2D分割骨干网络的影响 [PDF](https://arxiv.org/pdf/2509.19644), [HTML](https://arxiv.org/abs/2509.19644)
### Authors
William L. Muckelroy III,Mohammed Alsakabi,John M. Dolan,Ozan K. Tonguz
### Background
LiDAR能够提供密集且精确的点云表示，从而提高高级自动驾驶系统的感知精度，增强了场景的识别与理解，但其高昂的成本阻碍了其在商用汽车上的广泛应用。已有研究利用神经网络训练，并将LiDAR点云作为真实数据，通过4D雷达生成类似LiDAR的3D点云，其中一种方法是使用模块化2D卷积神经网络和核心时序一致性网络，这些研究为本工作的背景提供了依据。
### Innovation
本工作的创新点在于研究高容量的分割骨干网络对生成点云质量的影响。研究发现，尽管高容量模型有可能降低性能，但选择合适的分割骨干网络可以提高23.7%的点云生成质量。
### Conclusion
研究表明，在点云预测中，通过使用合适的分割骨干网络，可以显著提高生成点云的质量。
## 484. `cs.CV` - 合成像素级检测的artifact数据集 [PDF](https://arxiv.org/pdf/2509.19589), [HTML](https://arxiv.org/abs/2509.19589)
### Authors
Dennis Menn,Feng Liang,Diana Marculescu
### Background
已有研究表明，艺术制品检测器在增强图像生成模型性能方面具有优势，特别是在微调过程中作为奖励模型使用。这些检测器使生成模型能够提高整体输出的真实性和美观性。然而，训练艺术制品检测器需要昂贵的逐像素级的人工注释，指定艺术制品区域。缺乏标注数据限制了检测器的性能。一种简单的伪标签方法（训练一个弱检测器并使用它对未标记的图像进行标注）会产生嘈杂的标签，导致性能较差。
### Innovation
本文提出了一种艺术制品腐蚀流水线，该流水线能够自动将艺术制品注入预定区域的干净、高质量的合成图像中，从而无需手工标注即可产生逐像素级的标注。这种方法使得能够训练出一种检测器，与基线方法相比，在ConvNeXt上性能提高了13.2%，在Swin-T上提高了3.7%，并通过人工标注的数据得到了验证。这项工作是朝着可扩展的集成世界知识的像素级艺术制品注释数据集的重要一步。
### Conclusion
本文提出的方法能够生成一批自动标注的艺术制品数据集，有助于提高艺术制品检测的准确性和可扩展性。这种方法对于图像生成模型的整体性能提升具有重要意义。未来的研究可进一步探索如何更好地集成世界知识以提高艺术制品检测的整体性能。
## 485. `cs.CV` - CURE: Centroid-guided Unsupervised Representation Erasure for Facial Recognition Systems [PDF](https://arxiv.org/pdf/2509.19562), [HTML](https://arxiv.org/abs/2509.19562)
### Authors
Fnu Shivam,Nima Najafzadeh,Yenumula Reddy,Prashnna Gyawali
### Background
在当前的数字时代，面部识别系统因其显著的实用性和广泛应用，被广泛整合到现代技术基础设施中；然而，它们的广泛应用也引发了严重的隐私问题，导致出台要求数据请求后删除的相关法规。现有技术的机器遗忘主要依赖于有监督的方法，需要身份标签，但这些标签在隐私受限情况下或大噪声数据集中往往不可用。这些限制促使研究人员开发新型的无监督机器遗忘框架来解决这一问题。
### Innovation
本文提出了一种名为CURE的无监督代表消除框架，它是首个无需身份标签的面部识别系统中的机器遗忘解决方案。CURE通过指导中心消除特定用户的数据影响，并保持整体模型性能的同时，有效地移除了目标样本。此外，本文还提出了一个新的评估指标，遗忘效率得分（UES），以平衡遗忘和保留的稳定性，这在当前的评价指标中更为全面。CURE在与其他无监督遗忘方法的对比中表现出显著的效果。
### Conclusion
本文提出了一种名为CURE的方法，该方法可以在不使用身份标签的情况下有效移除面部识别系统的目标样本，同时保持整体性能。此外，提出了新的评估指标——遗忘效率得分（UES），并通过去除质量低下的图像来实现质量感知的遗忘，进一步展示了CURE的实用性和优势。
## 486. `cs.CV` - 基于深度学习的非公路环境下自主车辆视觉感知 [PDF](https://arxiv.org/pdf/2509.19378), [HTML](https://arxiv.org/abs/2509.19378)
### Authors
Nelson Alves Ferreira Neto
### Background
对于处于非均匀地形的露天矿场和 Developing 国家的自主驾驶车辆，要求具备低延迟智能系统。目前研究主要集中在有预设路线的环境下，而缺乏对无预设路径、复杂环境的自主感知系统研究，尤其是在恶劣天气下如夜间、雨天和灰尘环境下的感知能力需要进一步提升。为此，研究提出了一种适用于非铺设道路和野外环境的自主车辆感知系统，该系统能够在没有预设路径的情况下导航崎岖的地形。并且，研究人员开发了一套可配置模块分割网络 (CMSNet) 框架，为不同结构配置提供了便利。为了适应恶劣环境，研究人员通过大量训练获得了能够分割障碍物和可通行地面的新样本。这表明深度学习技术可以在没有明确定义的路径边界的情况下进行驱动区域的检测，并且在能见度受损的条件下表现出良好的算法行为。Kamino 数据集，包含超过 12,000 张多摄像头同步采集的图像，进一步验证了该系统的有效性，特别是在低能见度环境下的表现。使用 TensorRT、C++ 和 CUDA 等技术对 CMSNet 的 CNN 层进行重新优化和融合，实现了实时推理的效果。实验结果证明了所提出系统的有效性。
### Innovation
1. 开发了适用于非铺设道路和野外环境的自主车辆感知系统，能够在没有预设路径的情况下导航崎岖的地形。2. 提出了一个可配置模块分割网络 (CMSNet) 框架，为不同的架构布置提供了灵活性。3. 使用深度学习技术在夜间、雨天和灰尘等恶劣条件下，实现了无需明确定义路径边界即能够进行驾驶区域检测的能力。4. 提出了一个新的 Kamino 数据集，拥有大量标注像素的图像，并涵盖了恶劣环境下的野外试验数据。5. 对 CMSNet 的 CNN 层进行了重新优化和融合，使用 TensorRT、C++ 和 CUDA，实现了实时推理的效果。
### Conclusion
研究提出了一种基于深度学习的方法，针对非公路环境下自主车辆提供了有效的视觉感知系统，能够在复杂和恶劣环境下实现及时的信息获取与决策支持。通过优化和融合技术，消除了不必要的 CNN 层，确保了系统在实际应用中的实时性。该系统及其技术的提升，为未来非公路环境下自主车辆的发展提供了坚实的基础。
## 487. `cs.CV` - 图片中的偏见：使用社会提示新闻图片和LLM作为评估员衡量VLMs [PDF](https://arxiv.org/pdf/2509.19659), [HTML](https://arxiv.org/abs/2509.19659)
### Authors
Aravind Narayanan,Vahid Reza Khazaie,Shaina Raza
### Background
大模型（VLMs）能够协同解释图像和文本，但由于视觉线索如年龄、性别、种族、着装或职业等因素的存在，它们也容易吸收和复制有害的社会刻板印象。为了研究这些风险，作者创建了一个包含1,343张图片与问题对的新闻图片基准测试，这些图片来自不同的媒体渠道，并被标注了真实答案和人口统计属性（年龄、性别、种族、职业和体育）。
### Innovation
该研究引入了一个基于新闻图片的社会提示基准测试，以评估大模型的偏见情况。研究中使用了一个大规模语言模型（LLM）作为评估员，并结合了人类验证，考察了视觉上下文在开放设置中如何系统地影响模型输出，以及模型生成的偏见存在差异。
### Conclusion
研究发现：（i）视觉上下文在开放性任务中系统性地改变了模型的输出；（ii）不同属性和模型之间的偏见存在差异，性别和职业偏见的风险尤其高；（iii）高保真度并不一定意味着较低的偏见。研究结果表明，并没有简单的解决方案来直接减少偏见，同时也发布基准提示、评估标准和代码以支持可再现的和公平的多模态评估。
## 488. `cs.CV` - Raw-JPEG Adapter：使用JPEG高效压缩RAW图像 [PDF](https://arxiv.org/pdf/2509.19624), [HTML](https://arxiv.org/abs/2509.19624)
### Authors
Mahmoud Afifi,Ran Zhang,Michael S. Brown
### Background
数字相机将场景光线数字化为线性原始表示，图像信号处理器（ISP）将这些转换成可供展示使用的输出。RAW数据保留了全部传感器信息，适用于编辑和视觉任务，但在存储方面需要大量的空间，因此在资源受限的场景中并不实用。相比之下，JPEG是一种广泛支持的格式，它拥有高效的数据压缩能力和广泛的兼容性，但并不适合RAW数据的存储。因此，需要一个方法可以在不牺牲RAW数据质量的同时，实现高效且可以恢复的压缩，这样既可以利用JPEG的压缩能力，又可以保持RAW数据的完整性和编辑功能。
### Innovation
本论文提出了一种轻量级、可学习且可逆的预处理流水线——RawJPEG Adapter，它能够将RAW图像适应为标准JPEG压缩格式。该方法运用了空间和可选的频域变换，然后将紧凑参数存储在JPEG注释字段中，使得能够准确地重建RAW图像。这种技术在多个数据集上的实验表明，该方法比直接JPEG存储具有更高的保真度，且能支持其他编码格式，并为压缩比例和重建准确性之间提供了良好的权衡。
### Conclusion
该论文提出了一种能高效压缩RAW图像的方法，称为RawJPEG Adapter，它可以在不牺牲质量的情况下将RAW图像高效地存储，并保持重构的准确性，同时还能支持其他编码格式。研究表明，这种方法可以在保持较高图像保真度的同时，有效降低存储成本，适合作为在资源受限的环境中对RAW图像进行高效存储和处理的解决方案。
## 489. `cs.CV` - 通过渐进任务特定适应实现参数高效多任务学习 [PDF](https://arxiv.org/pdf/2509.19602), [HTML](https://arxiv.org/abs/2509.19602)
### Authors
Neeraj Gangwar,Anshuka Rangi,Rishabh Deshmukh,Holakou Rahmanian,Yesh Dattatreya,Nickvash Kani
### Background
参数高效微调方法已成为将预训练模型适应各种下游任务的一种有前途的解决方案。尽管这些方法在单任务学习中表现出色，但在多任务学习中，由于可训练参数有限，它们遇到了如任务干扰和负迁移等常见挑战。为了应对这些问题，我们提出了渐进任务特定多任务适应，这是一种新的参数高效多任务学习方法。这种方法在预训练模型中引入了适配器模块，这些模块在初始层中共享，而在后期层中逐渐变得特定于任务。其动机是在初始层通过跨任务的学习转移减少任务间的冲突，并在预测头部实现任务特定学习。我们还提出了一种基于梯度的方法来计算任务相似性，并使用这种方法来分配相似任务给共享的适配器模块。我们的方法在管线中引入了最小的额外开销。通过将Swin Transformer适应密集预测任务，实验结果在PASCAL和NYUD-v2数据集上表明，我们的方法在只需要五分之一的可训练参数的情况下，优于完全微调的多任务模型。同时，它在减少可训练参数的情况下实现了对单任务微调的更好相对改进，超越了当前参数高效多任务学习方法的领先水平。
### Innovation
文章提出了渐进任务特定多任务适应方法，这是一个新颖的参数高效多任务学习方法。主要包括以下创新点：1) 在预训练模型中引入适配器模块，并且随着层数增加模块变的越来越特定于任务。2) 提出了一种基于梯度的方法来计算任务相似性，并以此来分配相似任务给共享的适配器模块。这种方法在逐渐任务特定的过程中引入了最小的额外开销。这些创新点通过实验证明，在在有限的参数量下实现了更好的多任务学习性能。
### Conclusion
通过将Swin Transformer适应密集预测任务，该方法在PASCAL和NYUD-v2数据集上的实验结果表明，它在只需要五分之一的可训练参数的情况下，超越了完全微调的多任务模型。同时，这种方法在实现更好的相对改进的同时，减少了可训练参数的数量，并超越了当前的参数高效多任务学习方法的最新水平，显示了其在多任务学习中的优越性。
## 490. `cs.CV` - MoTiC: 动量规范性和对比学习在少量样本类别增量学习中的应用 [PDF](https://arxiv.org/pdf/2509.19664), [HTML](https://arxiv.org/abs/2509.19664)
### Authors
Zeyu He,Shuai Huang,Yuwu Lu,Ming Zhao
### Background
小样本类别增量学习（FSCIL）面临从稀少样本学习新类别并保留旧类别知识的双重挑战。现有方法通过冻结特征提取器和类平均水平原型来减轻灾难性遗忘和过拟合的问题，然而新类原型由于极度稀缺的数据而遭受显著的估计偏差，而基础类原型则受益于充足的数据。
### Innovation
该工作通过贝叶斯分析理论证明了通过调整新类先验与旧类统计来减少方差和提高原型准确性。进一步提出了大规模对比学习来增强跨类别特征紧致性。为了进一步丰富特征多样性并为新类原型注入先验信息，该方法将动量自我监督和虚拟类别整合到动量规范性和对比框架（MoTiC）中，构建一个具有丰富表示能力且增强类别间凝聚性的特征空间。
### Conclusion
在三个FSCIL基准上的实验结果表明，该方法在细粒度任务CUB-200上达到了最先进的性能，验证了其减少估计偏差和增强增量学习鲁棒性的能力。
## 491. `cs.CV` - 通过新颖优化策略解决基于Transformer的视觉模型特征图异常 [PDF](https://arxiv.org/pdf/2509.19687), [HTML](https://arxiv.org/abs/2509.19687)
### Authors
Sumit Mamtani
### Background
视觉变压器（ViTs）已展现出在计算机视觉任务中的优秀性能。然而，其特征图中存在的结构化噪声缺陷阻碍了诸如分割和深度估计等下游应用。
### Innovation
提出了两种创新的轻量级优化技术：结构化标记增强（STA）和自适应噪声过滤（ANF），以提高可解释性并缓解这些缺陷。STA通过在标记化过程中加入空间扰动来增强标记多样性，而ANF则在Transformer层之间应用可学习的去噪操作。这两种方法不依赖于特定的架构，并在标准基准测试中得到了评估（如ImageNet、Ade20k和NYUv2）。实验结果表明，在视觉质量和任务性能方面均表现出了持续的改进，突显了我们方法的实际有效性。
### Conclusion
我们的方法展示了在保持模型架构通用性的同时，有效提高视觉模型的可解释性和去除特征图中的结构化噪声，从而提高了下游任务的性能。
## 492. `cs.CV` - 学习停止：用于高效患者级超声心动图分类的强化学习 [PDF](https://arxiv.org/pdf/2509.19694), [HTML](https://arxiv.org/abs/2509.19694)
### Authors
Woo-Jin Cho Kim,Jorge Oliveira,Arian Beqiri,Alex Thorley,Jordan Strom,Jamie O'Driscoll,Rajan Sharma,Jeremy Slivnick,Roberto Lang,Alberto Gomez,Agisilaos Chartsias
### Background
指南推荐从心脏的不同视角获取多个超声心动图的视频片段，产生大量的片段。然而，自动化方法通常是使用一个片段来分类疾病，或者从所有片段中平均预测值。使用一个片段忽略了其他片段提供的补充信息，而使用所有片段则是计算上昂贵的，可能会阻碍临床应用。
### Innovation
该方法通过强化学习选择能最大化特定任务（基于图像的疾病分类）性能的最优片段子集。提出了一种学习可调的注意机制融合方法，灵活地结合多个片段的信息。仅使用所有片段的30%，该方法在检测心脏淀粉样变性的任务上获得了0.91的AUC，超越了使用所有片段和其他基准方法的表现。
### Conclusion
通过强化学习，该方法能高效地从超声心动图片段中选择最优子集，提高特定任务的性能，且仅需要较少的片段数量。
## 493. `cs.CV` - 甲烷卫星和机载成像光谱学中云和云阴影分割的深度学习方法 [PDF](https://arxiv.org/pdf/2509.19665), [HTML](https://arxiv.org/abs/2509.19665)
### Authors
Manuel Perez-Carrasco,Maya Nasr,Sebastien Roche,Chris Chan Miller,Zhan Zhang,Core Francisco Park,Eleanor Walker,Cecilia Garraffo,Douglas Finkbeiner,Ritesh Gautam,Steven Wofsy
### Background
准确获取大气甲烷或其他痕量气体浓度的高光谱遥感依赖于有效的云和云阴影检测。这在 MethaneSAT 和其机载同伴任务 MethaneAIR 中尤为关键。研究背景指出，在高空间分辨率的传感器遥感数据中，需要有效筛查云和云阴影，因为它们会导致甲烷遥感图像的偏移且影响排放量的量化。研究通过部署和评估Iterative Logistic Regression (ILR)和Multilayer Perceptron (MLP)等传统方法以及UNet和Spectral Channel Attention Network (SCAN)等先进深度学习架构，解决这一问题。结果显示，传统方法在空间一致性和边界定义上存在不足，影响云和云阴影的检测。相比之下，深度学习模型显著提升了检测质量，其中UNet在保持空间结构方面表现最佳，而SCAN在捕捉微细边界细节方面表现更优。研究还强调了将光谱注意力机制纳入卫星特定特征分析时的显著优势。
### Innovation
研究创新性地应用了多种异构机器学习技术，并深入评估了不同深度学习模型在处理云和云阴影识别任务上的表现。特别地，研究发现 spectral channel attention network (SCAN) 在处理MethaneSAT数据时优于UNet，这突显了光谱注意力机制在卫星专用特征分析中的优势。通过对比和分析，展示了先进深度学习架构在为现有和下一代高光谱任务提供稳健、可扩展的云和云阴影筛查解决方案方面的优势。
### Conclusion
深入评估了各种异构机器学习技术，并通过使用UNet和SCANN等先进深度学习架构，显著提高了云和云阴影的检测质量。研究结果表明，先进的深度学习架构在提供为现有和下一代高光谱任务提供稳健、可扩展的云和云阴影筛查解决方案方面表现出强大的优势。研究的数据和代码已公开共享。
## 494. `cs.CV` - 针对心肌淀粉样变性分类的解剖约束变压器 [PDF](https://arxiv.org/pdf/2509.19691), [HTML](https://arxiv.org/abs/2509.19691)
### Authors
Alexander Thorley,Agis Chartsias,Jordan Strom,Roberto Lang,Jeremy Slivnick,Jamie O'Driscoll,Rajan Sharma,Dipak Kotecha,Jinming Duan,Alberto Gomez
### Background
心肌淀粉样变性（CA）是一种罕见的心肌病，其临床测量指标，如来自超声心动图的总体纵向应变减少，通常存在异常。目前通过神经网络检测CA的方法通常使用视频分类模型，如卷积神经网络，但这些模型不能保证其分类基于与CA相关的已知临床相关特征。本文提出了一种新思路，通过将模型应用于如应变等定量特征，确保分类与临床相关特征相关。
### Innovation
本文介绍了针对CA分类任务，将变压器模型和预训练任务约束在心肌区域的技术。通过直接将心肌区域的解剖特征嵌入输入令牌中，仅对具有医学意义的区域进行采样和重构。与全视频变压器模型相比，该方法改进了CA分类任务的表现。模型还提供了分类聚焦于心超医学相关区域的明确保证，并且能够可视化变压器在变形心肌上的注意力分数。
### Conclusion
通过对变压器和预训练任务进行约束，仅处理心肌区域，而非整个视频帧，从而在心肌淀粉样变性分类任务上实现了比全视频变压器更好的性能。同时，这种方法确保了模型的分类专注于心超医学相关的特定区域，有助于临床诊断和研究。
## 495. `cs.CV` - 从提示到进展：驯服视频扩散模型以实现平滑的属性过渡 [PDF](https://arxiv.org/pdf/2509.19690), [HTML](https://arxiv.org/abs/2509.19690)
### Authors
Ling Lo,Kelvin C.K. Chan,Wen-Huang Cheng,Ming-Hsuan Yang
### Background
现有模型在处理复杂的时序变化时常常表现不佳，尤其是在生成逐步属性过渡的视频时更为明显。常见的动作过渡提示插值方法往往无法有效处理逐步属性过渡，导致不一致性更加突出。
### Innovation
本文提出了一种简单但有效的方法，旨在通过在去噪过程中引入帧级指导，扩展现有模型以实现平滑和一致的属性过渡。此方法为每个受噪声影响的潜在变量构建特定的数据过渡方向，逐帧引导属性从初始状态过渡到最终状态，同时保持视频的动作动态特性。此外，还提出了Controlled-Attribute-Transition Benchmark (CAT-Bench)，该基准结合了属性和运动动态特性，用以全面评估不同模型的性能，并提出了两种新指标来评估属性过渡的准确性和平滑度。
### Conclusion
实验结果表明，本文提出的方法优于现有基线，能实现高质量的视觉效果，保持与文本提示的一致性，并提供无缝的属性过渡。代码和CAT-Bench已发布。
## 496. `cs.CV` - 通过数据合成实现医学图像分割中的稳健上下文学习 [PDF](https://arxiv.org/pdf/2509.19711), [HTML](https://arxiv.org/abs/2509.19711)
### Authors
Jiesi Hu,Yanwu Yang,Zhiyu Ye,Chenfei Ye,Hanyang Peng,Jianfeng Cao,Ting Ma
### Background
由于In-Context Learning (ICL)在通用医学图像分割中的兴起，对大规模、多样化的数据集需求急剧增加，加剧了长期存在的数据稀缺问题。现有数据合成方法尽管具有潜力，但往往无法同时实现高数据多样性和适合医学数据的领域分布。因此，迫切需要一种能有效解决该问题的创新方法。
### Innovation
提出了一个名为SynthICL的新型数据合成框架，该框架基于领域随机化构建。SynthICL通过利用真实世界数据集中的解剖先验知识确保真实性，生成多样化的解剖结构以覆盖广泛的领域分布，并明确建模个体间差异以创建适用于ICL的数据组。
### Conclusion
广泛的实验表明，使用SynthICL生成数据训练的模型在平均Dice分数上提高了63%，且显著增强了对未见解剖领域的泛化能力。我们的工作有助于缓解ICL中的数据瓶颈问题，为稳健模型的开发铺平道路。代码和生成的数据集已公开发布。
## 497. `cs.CV` - VIMD: 单目视觉-惯性运动和深度估计 [PDF](https://arxiv.org/pdf/2509.19713), [HTML](https://arxiv.org/abs/2509.19713)
### Authors
Saimouli Katragadda,Guoquan Huang
### Background
准确且高效的稠密度规深度估计对机器人和XR领域的3D视觉感知至关重要。现有技术需要准确且高效的单目视觉-惯性运动跟踪来实现稠密度规深度的估计。传统的做法是使用不变的仿射模型进行全局拟合，而这种方法在精度和效率上存在局限性。
### Innovation
本文提出了一种基于多视图信息进行迭代细化单目视觉-惯性运动和深度(VIMD)学习框架，通过MSCKF（多尺度卡尔曼滤波）方法实现了这一目标，这与之前的工作不同。该框架具有高度模块化特性，可以与现有的各种深度估计模块兼容，并在TartanAir和VOID数据集上进行了详细评估，展示了其在AR Table数据集上的零样本泛化能力。
### Conclusion
实验结果表明，VIMD框架在极少数点云（每幅图像仅有10-20个度规深度点）的情况下仍能实现卓越的精度和鲁棒性。这使其成为资源受限环境中部署的实际解决方案，并因其稳健性能和强大的泛化能力而具有广泛的应用潜力。
## 498. `cs.CV` - PolGS：基于偏振的高斯斑点法以实现快速反射表面重构 [PDF](https://arxiv.org/pdf/2509.19726), [HTML](https://arxiv.org/abs/2509.19726)
### Authors
Yufei Han,Bowen Tie,Heng Guo,Youwei Lyu,Si Li,Boxin Shi,Yunpeng Jia,Zhanyu Ma
### Background
对于具有复杂反射性质的表面的高效形状重建，在实时虚拟现实场景中至关重要。尽管基于3D高斯斑点（3DGS）的方法可以通过利用其显式的表面表示来提供快速的新视图渲染，但在恢复具有复杂反射性质的表面时，它们的重建质量仍落后于隐式神经表示。因此，需要一种新的方法来处理这一问题。
### Innovation
我们提出了一种偏振高斯斑点模型（PolGS），它允许在10分钟内快速重建反射表面。通过将偏振约束整合进3DGS框架，PolGS能够有效分离镜面反射和漫反射成分，从而提高具有挑战性的反射材料的重建质量。
### Conclusion
实验结果在合成和真实世界数据集上的验证显示了我们方法的有效性。
## 499. `cs.CV` - 频域多模态融合在语言指导的医学图像分割中的应用 [PDF](https://arxiv.org/pdf/2509.19719), [HTML](https://arxiv.org/abs/2509.19719)
### Authors
Bo Yu,Jianhua Yang,Zetao Du,Yan Huang,Chenglong Li,Liang Wang
### Background
自动分割放射学图像中的感染区域对于诊断肺部感染性疾病至关重要。近期研究已经证明，通过将临床文本报告的语义指导信息融入医学图像分割中可以提高其准确性。然而，病变的复杂形态变化和视觉与语言模态之间的语义差距阻碍了现有方法有效地增强视觉特征表示和消除语义无关的视觉信息，导致了分割性能不佳的问题。
### Innovation
本文提出了一种频域多模态交互模型（FMISeg），用于语言指导的医学图像分割。FMISeg是一个晚期融合模型，在解码器中建立了语言特征和频域视觉特征之间的交互。具体地，该方法引入了频域特征双向交互（FFBI）模块来有效地融合频域特征，进一步在解码器中引入了语言指导频域特征交互（LFFI）模块，在语言信息的引导下抑制语义无关的视觉特征。实验结果表明，该方法在QaTa-COV19和MosMedData+数据集上在定性和定量上均优于最先进的方法，能够改善医学图像分割的性能和效果。
### Conclusion
实验结果表明，我们的方法在定性和定量上均优于最先进的方法，可以有效地通过语言信息指导医学图像的分割，增强视觉特征表示并抑制语义无关的视觉信息，显著提高了医学图像分割的性能。
## 500. `cs.CV` - 稳健的RGB-T跟踪通过可学习的视觉傅里叶提示微调和模态融合提示生成 [PDF](https://arxiv.org/pdf/2509.19733), [HTML](https://arxiv.org/abs/2509.19733)
### Authors
Hongtao Yang,Bineng Zhong,Qihua Liang,Zhiruo Zhu,Yaozong Zheng,Ning Li
### Background
最近，视觉提示调优被引入RGB-热（RGB-T）跟踪，作为一种参数高效的微调（PEFT）方法。现有的PEFT基RGB-T跟踪方法通常仅依赖于空间域信息作为特征提取的提示，因此往往会忽视频率域信息在提示学习中的关键作用，导致无法达到最优性能。
### Innovation
本文提出了一个高效的视觉傅里叶提示跟踪方法（VFPTrack），利用快速傅里叶变换（FFT）学习与模态相关的提示。该方法包括具有共享参数的对称特征提取编码器、视觉傅里叶提示以及模态融合提示生成模块。首先，使用冻结的特征提取编码器提取RGB和红外（TIR）模态特征；然后，结合空间域提示和来自FFT的频率域提示，以充分利用不同领域的模态特征；最后，提出的模态融合提示生成模块将不同模态的特征融合生成一个模态提示，该提示与每个单个模态互动，促进不同模态间的充分特征交互。
### Conclusion
在三个流行的RGB-T跟踪基准上的广泛实验表明，本文的方法显示出卓越的性能。
## 501. `cs.CV` - 通过AU指导的 faciallandmark 预测实现 talking head 生成 [PDF](https://arxiv.org/pdf/2509.19749), [HTML](https://arxiv.org/abs/2509.19749)
### Authors
Shao-Yu Chang,Jingyi Xu,Hieu Le,Dimitris Samaras
### Background
当前的音频驱动的头部生成方法主要依赖于情感标签或隐式的AU条件，缺乏对细微表情控制的明确映射。本文提出了一个两阶段框架，通过面部动作单元（AUs）实现精细表情控制的头部生成，显著提高了表达的准确性和视觉现实感。
### Innovation
本文模型未能隐式映射而是明确映射AUs到2D面部关键点，第一阶段使用变分运动生成器预测与音频和AUs强度时间一致的关键点序列；第二阶段使用基于扩散的合成人像生成器生成真实的、唇动同步的视频。这一分离运动和外观的方法提高了表达的准确性和时间的一致性，以及视觉现实度。实验结果表明，相较于最新的基线方法，本文方法在多个指标上表现出色，验证了明确的AU到关键点建模的有效性。
### Conclusion
实验结果表明，本方法在MEAD数据集上超越了最先进的基线方法，证明了明确的AU到关键点建模在有表情头部生成中的有效性，并提升了表达的准确性和视觉的现实感。
## 502. `cs.CV` - CAMILA: 基于语言对齐的上下文感知图像编辑方法 [PDF](https://arxiv.org/pdf/2509.19731), [HTML](https://arxiv.org/abs/2509.19731)
### Authors
Hyunseung Kim,Chiho Choi,Srikanth Malla,Sai Prahladh Padmanabhan,Saurabh Bagchi,Joon Hee Choi
### Background
文本引导的图像编辑使得用户能够通过自然语言指令来转换和合成图像，提供了很大的灵活性。然而，现有的图像编辑模型通常会无条件地遵循用户的每一项指令，即使这些指令是不可行或有矛盾的，这导致了不合理的输出结果。为了应对此类挑战，本文提出了一种名为CAMILA（基于语言对齐的上下文感知图像编辑方法）的方法。CAMILA旨在验证指令与图像之间的上下文一致性，确保仅在指定区域进行相关的编辑操作，而忽略无法执行的指令。
### Innovation
本文提出的CAMILA方法通过验证指令与图像之间的上下文一致性，确保仅在指定区域进行相关的编辑操作，而忽略无法执行的指令，从而解决了现有模型中存在的挑战，在单指令和多指令的图像编辑数据集上，CAMILA方法在性能和语义对齐方面都优于最先进的模型，证明了其在处理复杂指令挑战方面的有效性，同时保持了图像的完整性.
### Conclusion
我们的新方法实现了更好的性能和更高的语义对齐，证明了它在处理复杂指令挑战方面的有效性，同时保持了图像的完整性。我们构建了包含不可行请求的单指令和多指令图像编辑数据集，用于全面评估此新方法。
## 503. `cs.CV` - Logics-Parsing 技术报告 [PDF](https://arxiv.org/pdf/2509.19760), [HTML](https://arxiv.org/abs/2509.19760)
### Authors
Xiangyang Chen,Shuzhao Li,Xiuwen Zhu,Yongfan Chen,Fan Yang,Cheng Fang,Lin Qu,Xiaoxiao Xu,Hu Wei,Minggang Wu
### Background
近年来，大型视觉-语言模型（LVLM）在文档解析任务中取得了显著进展。与传统的基于管道的方法相比，端到端的方法在将PDF图像转换为结构化输出方面表现优异，这得益于统一的光学字符识别（OCR）、表格识别和数学公式识别等技术的集成。然而，这些方法缺乏明确的分析步骤来处理文档布局和阅读顺序，这限制了其处理复杂文档类型的能力，如多栏报纸或海报等。
### Innovation
本文提出了一种增强的端到端LVLM模型——Logics-Parsing，该模型结合了强化学习机制以优化复杂的布局分析和阅读顺序推理。此外，模型通过纳入化学公式和手写汉字等多样化的数据类型，增强了其泛化能力。
### Conclusion
通过在LogicsParsingBench数据集上进行的全面实验，证明了所提出模型在各种文档分析场景中的有效性和业界领先（SOTA）性能。
## 504. `cs.CV` - ExpFace：通过指数角度边际损失的深度面部识别 [PDF](https://arxiv.org/pdf/2509.19753), [HTML](https://arxiv.org/abs/2509.19753)
### Authors
Jinhui Zheng,Xueyuan Gong
### Background
面部识别是一个具有开放性的问题，需要具备高度的区分力以确保同类样本的距离小于跨类样本的距离。Margin-based softmax损失函数，如SphereFace、CosFace和ArcFace，广泛应用以提高同类样本的紧凑性和跨类样本的可分辨性，但这些方法并未考虑到噪声样本的影响。通过对样本在角度空间中的分布进行分析，发现干净样本主要集中在中心区域，而噪声样本倾向于向边缘区域移动。基于这一观察，本文提出了Exponential Angular Margin Loss (ExpFace)，增加了一个角度指数作为边际。这种设计可以在角度空间中为中心区域施加更大的惩罚，在边缘区域施加较小的惩罚，从而强调干净样本并抑制噪声样本。
### Innovation
提出了Exponential Angular Margin Loss (ExpFace)，通过在角度空间中引入一个角度指数作为边际。此方法在中心区域施加较大的惩罚，在边缘区域施加较小的惩罚，从而区分干净样本和噪声样本。该方法不仅规避了SphereFace的训练不稳定问题，而且避免了ArcFace中非单调性的弊端。在角度空间中的相似曲线与决策边界的方式类似，表现出一致的惩罚规律。
### Conclusion
广泛的实验表明，ExpFace取得了最先进的性能。为促进未来的研究，作者已开放了该方法的源代码。
## 505. `cs.CV` - EfficienT-HDR: 一种基于多曝光融合的高效Transformer框架 [PDF](https://arxiv.org/pdf/2509.19779), [HTML](https://arxiv.org/abs/2509.19779)
### Authors
Yu-Shen Huang,Tzu-Han Chen,Cheng-Yen Hsiao,Shaou-Gang Miaou
### Background
在计算视觉领域，实现资源受限的边缘设备上的高动态范围(HDR)成像是一个关键挑战，因为其性能直接影响到下游任务如智能监控和自动驾驶。传统的多曝光融合(MEF)技术虽然有效，但面临高计算成本和鬼影伪影两大难题，限制了其广泛应用。
### Innovation
本文提出了一种专为HDR重建设计的轻量级Vision Transformer架构——EfficienT-HDR。该架构基于Context-Aware Vision Transformer，并通过将输入图像转换为YCbCr色彩空间，分离亮度和色度信息，再利用Intersection-Aware Adaptive Fusion (IAAF)模块有效抑制鬼影。此外，本文引入了Inverted Residual Embedding (IRE)、Dynamic Tanh (DyT)以及Enhanced Multi-Scale Dilated Convolution (E-MSDC)，从多个层面降低计算复杂度。最终贡献了两个模型版本：一个针对高视觉质量，另一个在计算效率上有优势，两者都实现了性能和图像质量的良好平衡。
### Conclusion
实验结果表明，与基线相比，主版本将FLOPS减少了约67%，在CPU上的推理速度提高了超过五倍，在边缘设备上提高了2.5倍。这些结果证明EfficienT-HDR能够为边缘设备提供高效且无鬼影的HDR图像解决方案，显示了其在各种动态场景中的实用性和灵活性。
## 506. `cs.CV` - StrCGAN: 一种用于恒星图像恢复的生成框架 [PDF](https://arxiv.org/pdf/2509.19805), [HTML](https://arxiv.org/abs/2509.19805)
### Authors
Shantanusinh Parmar
### Background
我们介绍了一种名为StrCGAN（Stellar Cyclic GAN）的生成模型，用于增强低分辨率的天文摄影图像。这种任务由于小望远镜观测如MobilTelesco数据集的有限分辨率和质量而特别具有挑战性。传统的CycleGAN模型等虽然提供了图像到图像传输的基础，但只能处理2D映射，往往会扭曲恒星和星系的形态。
### Innovation
我们通过以下三个关键创新扩展了CycleGAN框架：3D卷积层用于捕捉体域空间相关性，多谱融合以对齐光学和近红外（NIR）域，以及天文学正则化模块以保持恒星形态。多任务全天域调查的数据从光学到NIR范围中指导训练过程，确保重建在各谱段之间保持一致。
### Conclusion
StrCGAN能够生成不仅视觉上更清晰而且物理上更一致的重建图像，超越了标准的GAN模型在天文学图像增强任务中的表现。
## 507. `cs.CV` - nnFilterMatch：一种具有不确定性伪标签过滤的统一半监督学习框架，用于高效的医学分割 [PDF](https://arxiv.org/pdf/2509.19746), [HTML](https://arxiv.org/abs/2509.19746)
### Authors
Yi Yang
### Background
半监督学习（SSL）在医学图像分割中呈现出强大的潜力，能够显著减少对大量手动标注的需求。结合积极学习（AL）的方法进一步减少了标注负担，但传统的SSL与AL结合的方法往往依赖于每次标注后的迭代和循环的重新训练周期，这带来了显著的计算开销并限制了临床应用的扩展性。
### Innovation
提出了一种新颖的、标注高效的、自适应的深度分割框架，名为nnFilterMatch，该框架结合了SSL与熵为基础的伪标签过滤（FilterMatch），并将其融入单次pass的nnU-Net训练分割框架中。通过在训练期间选择性地排除高置信度伪标签，该方法避免了重新训练循环的需求，同时保留了不确定性引导学习的好处。
### Conclusion
研究结果表明，提出的框架在多个临床分割基准测试中达到了性能可以与或超过全监督模型相当的表现，即使仅使用5%-20%的标注数据。这项工作引入了一种可扩展的端到端学习策略，用于在不影响准确性的情况下减少医学图像分割中的标签需求。
## 508. `cs.CV` - 自适应模型集成用于连续学习 [PDF](https://arxiv.org/pdf/2509.19819), [HTML](https://arxiv.org/abs/2509.19819)
### Authors
Yuchuan Mao,Zhi Gao,Xiaomeng Fan,Yuwei Wu,Yunde Jia,Chenchen Jing
### Background
模型集成是一种在连续学习中有效的方法，它通过插值模型参数来缓解灾难性遗忘，实现不同任务所学习知识的融合。然而，现有的模型集成方法通常会在任务和层面上遇到知识冲突的问题，导致在旧任务和新任务上的学习性能下降。
### Innovation
我们提出了自适应加权集成器，它通过元学习训练了一个混合系数生成器来生成适当的混合系数以解决任务层面的知识冲突。层层面的知识冲突则是通过为每个层分别生成混合系数来解决。这样，我们可以在融合模型中学习关于不同任务知识适应性积累的先验知识，从而有效地在旧任务和新任务上实现高效的训练。自适应加权集成器可以与现有的连续学习方法灵活结合，以增强它们缓解灾难性遗忘的能力。
### Conclusion
实验结果表明，自适应加权集成器有效地解决了灾难性遗忘的问题，并达到了最先进的性能。
## 509. `cs.CV` - BiTAA: 一种基于3D高斯绘制的双任务对抗攻击以同时破坏对象检测和单目深度估计 [PDF](https://arxiv.org/pdf/2509.19793), [HTML](https://arxiv.org/abs/2509.19793)
### Authors
Yixun Zhang,Feng Zhou,Jianqin Yin
### Background
相机感知对于自动驾驶至关重要，然而在对象检测和单目深度估计中仍容易受到特定任务的对抗性操控。大多数现有的2D/3D攻击是单一任务开发的，缺乏控制深度偏差的机制，并未提供标准化的跨任务传输量化协议，导致检测与深度之间交互仍需深入探索。
### Innovation
本研究提出了一种名为BiTAA的双任务对抗攻击，结合3D高斯绘制技术，提供了一个单一扰动同时损害检测和偏移单目深度的功能。引入了一种双模型攻击框架，支持完整图像和补丁模式，并兼容常见的检测器和深度估计器，可选地使用期望超越变换（EOT）以适应物理现实。设计了一种复合损失函数，将检测抑制与目标区域内的受限深度偏移耦合，实现可控的近或远感知偏差，同时在任务间保持优化稳定性。此外，提出了一种统一的评估协议，包含跨任务传输度量和现实世界评估，展示了跨任务的一致损害和深度到检测（从检测到深度）转移的不对称性，突显了多任务相机感知实用风险，推动了自动驾驶环境中的跨任务意识防御策略开发。
### Conclusion
研究结果强调了多任务相机感知的实用性风险，并激发了在自动驾驶场景中开发跨任务意识防御策略的动机。
## 510. `cs.CV` - FreezeVLA: Action-Freezing Attacks against Vision-Language-Action Models [PDF](https://arxiv.org/pdf/2509.19870), [HTML](https://arxiv.org/abs/2509.19870)
### Authors
Xin Wang,Jie Li,Zejia Weng,Yixu Wang,Yifeng Gao,Tianyu Pang,Chao Du,Yan Teng,Yingchun Wang,Zuxuan Wu,Xingjun Ma,Yu-Gang Jiang
### Background
Vision-Language-Action (VLA)模型在机器人中起到了重要作用，让智能体能够解析多种模态的输入并执行复杂的长期任务。但是，它们的安全性和对抗性攻击的鲁棒性仍然被广泛忽视。
### Innovation
 FreezeVLA提出了一个新的攻击框架，用于生成和评估动作冻结攻击，它通过最小-最大双层优化进行。研究结果表明，FreezeVLA在三个最先进的VLA模型和四个机器人基准上取得了平均攻击成功率76.2%的结果，显著优于现有方法。此外，由FreezeVLA生成的对抗性图像具有很强的可移植性，同一张图片在不同语言提示下都能有效引发瘫痪。
### Conclusion
研究揭示了VLA模型中的关键安全隐患，并强调了迫切需要改进和抵御这种攻击机制的策略。
## 511. `cs.CV` - 通过多模态LLM实现自适应指导的语义增强边缘-云目标检测 [PDF](https://arxiv.org/pdf/2509.19875), [HTML](https://arxiv.org/abs/2509.19875)
### Authors
Yunqing Hu,Zheming Yang,Chang Zhao,Wen Ji
### Background
传统的目标检测方法在低光照条件和严重遮挡等复杂场景下表现不佳，主要是因为缺乏高层语义理解。为解决这一问题，该论文提出了一种结合多模态大语言模型（MLLM）的自适应引导语义增强边缘-云合作目标检测方法，实现准确性和效率的有效平衡。
### Innovation
该方法首先通过指令微调使MLLM生成结构化的场景描述。然后，设计了一种自适应映射机制，动态将语义信息转换为边缘检测器的参数调整信号，实现实时语义增强。系统在边缘-云协作推理框架中，根据置信度分数自动选择调用云基语义指导或直接输出边缘检测结果。
### Conclusion
实验表明，所提出的方法在复杂场景中有效提高了检测准确性和效率。特别是在低光照和高度遮挡场景下，可将延迟降低超过79%，计算成本降低70%的同时保持准确性。
## 512. `cs.CV` - Dice相似系数中的性别偏见：独立分析在多种解剖结构中的模型无关研究 [PDF](https://arxiv.org/pdf/2509.19778), [HTML](https://arxiv.org/abs/2509.19778)
### Authors
Hartmut Häntze,Myrthe Buser,Alessa Hering,Lisa C. Adams,Keno K. Bressem
### Background
Dice相似系数（DSC）这类重叠度量会对较小结构的分割错误给予更严重的惩罚。由于器官尺寸因性别而异，这意味着相同大小的分割错误在女性中由于其平均器官体积较小可能会导致更低的DSC得分。尽管以前的研究已经探索了性别差异在模型或数据集中的表现，但还没有研究探讨DSC本身引入的潜在偏差。该研究通过在一个理想化的环境中量化DSC和归一化DSC在多种解剖结构中的性别差异，独立于特定的模型，目的是理解这些差异。研究者将相等大小的合成错误应用于50名参与者的手动MRI注释以确保性别可比性，即使是最小的错误（例如，1毫米边界偏移）都会导致性别之间的系统性DSC差异，这些差异在小结构中平均约为0.03，在中等大小结构中约为0.01，而对于大器官（如肺和肝脏），性别之间的DSC差异几乎为零。这些发现强调，在使用DSC作为评估指标的公平性研究中，不能预期男性和女性之间的得分相同，因为该指标本身引入了偏差。即使错误程度相同，分割模型在男性和女性之间的表现也可能不同，而这种差异可能是由指标本身造成的而不是模型行为导致的。这种认识对于在医学图像分析中进行更准确和公平的评估至关重要。
### Innovation
该研究首次独立于特定模型，通过在多种解剖结构上量化DSC和归一化DSC的性别差异，揭示了DSC作为评估指标本身引入的性别偏见。这给性别差异在分割性能中的来源提供了一个新的洞见，那就是这种偏差不是由于模型的行为，而是来自指标本身。这一发现对于在医学图像分析中进行更公允的评估至关重要。
### Conclusion
该研究定量分析了DSC和归一化DSC在多种解剖结构中的性别差异，发现在小结构和中等大小结构中性别之间的DSC差异显著，而在大结构中这些差异接近于零。这表明在使用DSC作为评估指标的公平性研究中，不应预期男性和女性之间的相同分数，因为该指标本身存在偏见。这些结果还强调，在女性和男性之间，分割模型可能在错误大小方面表现相当，即使观察到的DSC值表明的不同。这一研究的工作提高了关于DSC作为评估指标所固有的性别差异的认识，从而提高了在医学图像分析中的公平性和准确性评估的重要性。
## 513. `cs.CV` - PersONAL: 针对个性化感知代理的综合基准 [PDF](https://arxiv.org/pdf/2509.19843), [HTML](https://arxiv.org/abs/2509.19843)
### Authors
Filippo Ziliotto,Jelin Raphael Akkara,Alessandro Daniele,Lamberto Ballan,Luciano Serafini,Tommaso Campari
### Background
近期，受体代理(AI)取得了显著进展，能够执行更复杂的任务并适应多样的环境。然而，在实人类中心的场景中，如家庭环境中部署这样的代理仍然具有挑战性，特别是因为难以建模个体人类的偏好和行为。
### Innovation
引入了 PersONAL (PERSonalized Object Navigation And Localization)，这是一个全面的数据集基准，用于研究受体代理中的个性化。数据集包括超过2000个高质量的场景，覆盖30多个真实场景的家庭，每个场景都有详细的自然语言描述和用户特定的信息关联，要求代理在特定场景中进行对象感知和推理。
### Conclusion
通过与当前最佳基准的实验对比，展示了代理在分辨和记忆特定用户的信息方面的巨大差距，强调了需要具备感知、推理和记忆个性化信息的代理，从而为实现现实世界中的辅助机器人铺平道路。
## 514. `cs.CV` - ThinkFake:在多模态大型语言模型中的推理以检测AI生成的图像 [PDF](https://arxiv.org/pdf/2509.19841), [HTML](https://arxiv.org/abs/2509.19841)
### Authors
Tai-Ming Huang,Wei-Tung Lin,Kai-Lung Hua,Wen-Huang Cheng,Junichi Yamagishi,Jun-Cheng Chen
### Background
随着AI生成图像的真实感不断提高，人们对其可能引发的 misinformation和隐私侵犯等严重问题的关注也日益增加。现有方法虽有所进展，但大多数依赖于无解释的二分类，或需要大量的有监督微调，导致泛化能力有限。
### Innovation
本文提出了一种名为ThinkFake的新型基于推理且可泛化的AI生成图像检测框架。该方法结合了带有伪造推理提示的多模态大型语言模型，并采用分组相对策略优化（GRPO）强化学习进行训练，增强了推理的逐步性和结果的解释性。此外，还引入了一种结构化的检测管道，提高了推理质量和适应性。实验表明，ThinkFake在GenImage基准测试中表现出色，并在具有挑战性的LOKI基准测试中展示了强大的零样本泛化能力。
### Conclusion
这些结果证明了该框架的有效性和鲁棒性。因此，本文方法在AI生成图像检测方面具有重要意义。
## 515. `cs.CV` - 3D球形图像分割中的广义最短路径超像素 [PDF](https://arxiv.org/pdf/2509.19895), [HTML](https://arxiv.org/abs/2509.19895)
### Authors
Rémi Giraud,Rodrigo Borba Pinheiro,Yannick Berthoumieu
### Background
随着广角成像设备的广泛应用以及计算机视觉中对快速准确图像分析的需求增加，迫切需要专门处理下采样问题的方法。现有大多数分解方法将图像分割为少量的不规则同质区域，即超像素，但这些方法通常针对标准2D平平图像进行设计，即不考虑视角畸变，使用90度视角拍摄的图像。本文旨在介绍一种新的适用于广角360度球形或全景图像的超像素方法，称为SphSPS（Spherical Shortest Path-based Superpixels）。研究背景说明了有必要研究更好地适应3D球形成像空间的方法，并证明了考虑成像空间几何关系计算最短路径可以同时提升分割准确性和超像素形状的规整性。
### Innovation
文章创新性地设计了一种新的超像素方法SphSPS，专门针对球形或全景图像。该方法考虑了3D球形成像空间的几何结构，引入了一种新的计算最短路径的方法，用于快速提取相关的聚类特征。此外，文章还引入了一个适用于球形空间的全局规整度度量方法，改进了原有球形紧凑度的限制，并在360度全景图像分割数据集以及合成的全景图像上验证了SphSPS方法的有效性。
### Conclusion
SphSPS方法在360度球形图像分割方面相较于平面和球面现有的最佳方法具有显著优势，体现在分割准确性、对噪声的稳健性和超像素形状规整性上。研究成果为基于超像素的应用提供了有力工具，特别是在处理360度图像时。
## 516. `cs.CV` - 通过跨孔对齐掩蔽双胞胎网络高效学习细胞图像表示 [PDF](https://arxiv.org/pdf/2509.19896), [HTML](https://arxiv.org/abs/2509.19896)
### Authors
Pin-Jui Huang,Yu-Hsuan Liao,SooHeon Kim,NoSeong Park,JongBae Park,DongMyung Shin
### Background
计算模型可以预测细胞对化学和遗传干扰的表型反应，从而加速药物发现过程，但也存在着从细胞图像中提取生物上意义明确且抗批次效应的特征的挑战。现有的自监督和对比学习方法往往需要大规模模型和大量精心整理的数据，但仍难以解决批次效应问题。
### Innovation
提出了一种名为Cross-Well Aligned Masked Siamese Network (CWA-MSN)的新颖表征学习框架。该框架实现了在同一干扰下不同孔中细胞嵌入的对齐，即便存在批次效应也能保证语义一致。CWA-MSN在掩蔽Siamese架构中实现了包含细微形态特征的同时数据和参数效率。在基因-基因关系检索基准测试中，CWA-MSN分别比现有的自监督（OpenPhenom）和对比学习（CellCLIP）方法提高了29%和9%的基准分数，且使用了远少的数据（例如CWA-MSN使用了0.2M图像，而OpenPhenom使用了2.2M图像）或更小的模型规模（例如CWA-MSN有22M参数，而CellCLIP有1.48B参数）。
### Conclusion
CWA-MSN提供了一种简单且有效的方法来学习细胞图像表征，在数据和参数预算有限的情况下仍能实现高效的表型建模。
## 517. `cs.CL` - 使用大型语言模型进行宏观经济预测 [PDF](https://arxiv.org/pdf/2407.00890), [HTML](https://arxiv.org/abs/2407.00890)
### Authors
Andrea Carriero,Davide Pettenuzzo,Shubhranshu Shekhar
### Background
近年来，大型语言模型（LLMs）因其捕捉数据中的复杂模式和快速适应不同领域的能力，在预测方面受到了极大的关注。然而，LLMs在宏观经济时间序列数据预测方面的有效性与传统方法相比仍是一个值得关注的研究领域。本文通过将LLMs与传统的宏观经济预测方法进行严格比较，利用FRED-MD数据库作为共同基础，评估LLMs在宏观经济时间序列预测中的准确性和应用潜力。
### Innovation
本文通过大规模的比较分析，评估了LLMs在宏观经济时间序列预测中相对于传统方法的有效性。研究主要利用FRED-MD数据库进行详细的实证分析，提供了关于LLMs在宏观经济预测中的适用性和局限性的有价值见解。
### Conclusion
研究结果揭示了LLMs在宏观经济时间序列预测中的优势和局限性，对于实际应用具有重要的参考意义。
## 518. `cs.CL` - RealitySummary: 使用大型语言模型探索按需混合现实文本摘要和问答 [PDF](https://arxiv.org/pdf/2405.18620), [HTML](https://arxiv.org/abs/2405.18620)
### Authors
Aditya Gunturu,Shivesh Jadon,Nandi Zhang,Morteza Faraji,Jarin Thundathil,Wesley Willett,Ryo Suzuki
### Background
大型语言模型（LLMs）正逐渐成为阅读和总结的辅助工具，但尚未完全探索在混合现实（MR）界面中集成这些模型以支持日常阅读的潜在优势。这项迭代研究旨在填补这一空白。
### Innovation
开发了RealitySummary，这是一种无缝集成LLMs并与始终开启的摄像头访问、基于OCR的文字提取以及增强的空间和视觉响应相结合的MR阅读助手。该研究通过三个迭代版本——初步用户研究、野外部署和日志研究——逐步优化，并根据用户的反馈和反思分析进行调整，以探索LLMs与MR结合的新方式及其在实际工作环境中的应用。
### Conclusion
研究表明，结合AI和MR有独特的优势，包括始终可用的隐式帮助、长期的时间历史记录、无中断的使用体验和空间交互特性。这表明未来的LLM-MR界面将具有超越传统屏幕互动的潜力。
## 519. `cs.CV` - 基于3D 高斯散点图中间视图渲染的机地图像特征匹配 [PDF](https://arxiv.org/pdf/2509.19898), [HTML](https://arxiv.org/abs/2509.19898)
### Authors
Jiangxue Yu,Hui Wang,San Jiang,Xing Zhang,Dejin Zhang,Qingquan Li
### Background
空中和地面图像的集成已被证明是复杂场景三维建模的一种有前途的解决方案，但这一过程严重受限于可靠对应的寻找。本研究在此背景下，提出了一种空中和地面图像配对的特征匹配算法，该算法的核心思想是通过生成中间视图来缓解因视角变化广泛引起的角度失真。
### Innovation
该研究的主要创新点在于提出了一种通过3D高斯散点图中间视图渲染技术来实现空中和地面图像配对的方法。该方法首先使用空中图像重建稀疏模型，随后利用定向图像进行场景渲染，通过空中图像的定向相机姿态确定渲染视角，生成高质量的中间图像，最后利用这些中间图像精确匹配渲染空中和地面图像的特征对，生成最终匹配。
### Conclusion
实验结果显示，本研究提出的方法能够为空中和地面图像提供可靠的特征匹配，初始匹配和精化匹配的数量明显增加。同时，这种方法能够提供足够的匹配，以实现精确的ISfM重建和完成基于3DGS的场景渲染。
## 520. `cs.CV` - 通过神经元-注意力分解解释基于ResNet的CLIP [PDF](https://arxiv.org/pdf/2509.19943), [HTML](https://arxiv.org/abs/2509.19943)
### Authors
Edmund Bu,Yossi Gandelsman
### Background
本文介绍了一种新的方法，用于通过将CLIP-ResNet的输出分解为独立的计算路径来解释其神经元。具体而言，研究了所有神经元和CLIP注意力池化层后续关注头的两两组合。研究发现，这些神经元-头对可以通过CLIP-ResNet的图像-文本嵌入空间中的单一方向来近似表示。研究表明，只有少数神经元-头对对输出值有显著贡献，并且一些神经元-头对虽然多义，但代表对应神经元的子概念。作者利用这些观察结果进行了两个应用：首先，使用这些对进行无训练的语义分割，优于先前的方法；其次，利用神经元-头对的贡献监控数据集分布的变化。研究结果表明，研究神经网络中的单个计算路径可以揭示可解释的单元，并且这些单元可以应用于下游任务。
### Innovation
提出了通过分解神经元-关注头对的方法来解释CLIP-ResNet中神经元的新技术；揭示了只有少数的神经元-头对对输出值有显著贡献；发现了一些多义的神经元-头对代表对应神经元的子概念；提出了无训练的语义分割的应用；利用神经元-头对的变化来监控数据集分布的变化。
### Conclusion
该研究揭示了神经网络中的单个计算路径可以通过近似来解释神经元的功能，并发现了一些可解释的单元，这些单元也可以应用于后续的任务中。
## 521. `cs.CV` - CapStARE: 基于胶囊的时空架构用于稳健且高效的凝视估计 [PDF](https://arxiv.org/pdf/2509.19936), [HTML](https://arxiv.org/abs/2509.19936)
### Authors
Miren Samaniego,Igor Rodriguez,Elena Lazkano
### Background
当前凝视估计的系统通常在实时性和准确性方面存在权衡，尤其是在处理复杂的时空数据时。CapStARE 系统旨在克服这些限制，通过结合 CapsNeXt 骨干网络、带有注意力路由的胶囊形成以及分别针对缓慢和快速凝视动态的双 GRU 解码器，提供高效的时空推理和分离的时间建模。
### Innovation
CapStARE 引入了一个胶囊基于的时空架构，该架构结合了 ConvNeXt 骨干网络、带有注意力路由的胶囊形成以及双重 GRU 解码器，旨在实现高效的时空推理和分离的时间建模。此外，该模型在保持实时推理速度的同时，实现了 ETH-XGaze 和 MPIIFaceGaze 的领先性能，同时在更广泛的场景中也有良好的泛化能力，并且具有更少的参数和更高的可解释性。
### Conclusion
CapStARE 提供了一种实用且稳健的实时凝视估计解决方案，适用于交互系统。该模型在多个基准测试中表现出色，验证了其在处理复杂时空数据方面的表现，并且具有更少的参数和更高的可解释性。相关代码和结果可以在 provided link 获取。
## 522. `cs.CV` - GS-RoadPatching: 通过三维搜索和放置进行 Gaussians 插补的驾驶场景 [PDF](https://arxiv.org/pdf/2509.19937), [HTML](https://arxiv.org/abs/2509.19937)
### Authors
Guo Chen,Jiarun Liu,Sicong Du,Chenming Wu,Deqi Li,Shi-Sheng Huang,Guofeng Zhang,Sheng Yang
### Background
现有的 3D Gaussian Splatting (3DGS) 插补方法依赖于基于 2D 视角的扩散或 GAN 模型来预测缺失区域的有限外观或深度线索。这些方法需要 2D 跨模态的空间-时间一致性，并且需要密集的时间重新训练高斯模型。相比之下，本文提出的 GS-RoadPatching 方法直接利用 3DGS 模式进行替代场景插补和编辑，不依赖于 2D 跨模态的一致性，也无需密集重新训练高斯模型。
### Innovation
本文的关键洞察是在驾驶场景中高度重复的模式在隐含的 3DGS 特征空间中表现出多模态相似性，适合结构匹配，以实现有效的 3DGS 基础上的替代插补。方法包括构造嵌入特征的 3DGS 场景，引入局部上下文的分割度量方法，并提出一种结构搜索方法在 3D 空间中有效找到候选补丁。同时，提出了一种简单但有效的替代和融合优化策略，以获得更好的视觉和谐。
### Conclusion
在多个公开数据集上的实验表明，本方法在质量和互操作性方面都优于基线方法，达到了最先进的性能。此外，在一般场景下的进一步实验也验证了提出的方法在通用场景中的适用性。项目页面和代码已发布。
## 523. `cs.CV` - SDE-DET: 一种用于复杂果园环境中沙田柚检测的高精度网络 [PDF](https://arxiv.org/pdf/2509.19990), [HTML](https://arxiv.org/abs/2509.19990)
### Authors
Yihao Hu,Pan Wang,Xiaodong Bai,Shijie Cai,Hang Wang,Huazhong Liu,Aiping Yang,Xiangxiang Li,Meiping Ding,Hongyan Liu,Jianguo Yao
### Background
沙田柚的检测对于定位、自动机器人采摘和成熟分析至关重要。但在复杂的果园环境中，多尺度问题、树干和树叶的遮挡以及小目标检测等方面存在显著挑战。
### Innovation
该研究构建了自定义数据集STP-AgriData，并提出了SDE-DET模型，该模型首先利用Star Block有效获取高维信息而不增加计算负担，接着采用可变形注意力机制增强遮挡条件下柚子的检测能力，最后结合多种高效多尺度注意力机制以减少计算负担和提取深入视觉表示，从而提高对小目标的检测能力。
### Conclusion
SDE-DET模型在沙田柚检测方面达到了最先进的性能。实验结果表明，SDE-DET提供了一种可靠的沙田柚检测方法，为自动收获机器人的进一步发展奠定了基础。
## 524. `cs.CV` - 当语言无法完全表达：基于视频的用户投诉文本生成与多模态视频投诉数据集 [PDF](https://arxiv.org/pdf/2509.19952), [HTML](https://arxiv.org/abs/2509.19952)
### Authors
Sarmistha Das,R E Zera Marveen Lyngkhoi,Kirtan Jain,Vinayak Goyal,Sriparna Saha,Manish Gupta
### Background
尽管在可解释的投诉挖掘方面已经有很多工作，但通过文本或视频传达用户担忧仍然是一个显著的挑战。用户通常难以清晰地用文字表达他们的投诉，但他们可以通过上传描述产品缺陷的视频（例如，诸如“最糟糕的产品”这样的模糊文字配上一个5秒钟的视频，显示耳机右耳垫破裂）来表达自己的观点。这篇文章定义了一个新的挑战，即从视频中提取投诉文本，以帮助普通用户更有效地表达自己的问题。
### Innovation
提出了一项新的投诉挖掘任务：从视频中生成投诉描述（CoD-V），以及ComVID数据集，包含1,175个投诉视频及其描述，同时标注了投诉者的情绪状态。还提出了一个新的投诉留存率（CR）评估标准，用于区分该任务与其他视频摘要生成和描述任务。此外，设计了一种结合了检索增强生成（RAG）的VideoLLaMA2-7b多模态模型，该模型在生成投诉时能够考虑用户的情绪状态。
### Conclusion
通过多模态视频投诉数据集和新的评估标准，研究为用户提供了一个平台，使他们能够通过视频表达自己的投诉。此外，通过全面评估多种视频语言模型，为未来的研究提供了基础。
## 525. `cs.CV` - 基于主动学习的表格检测 [PDF](https://arxiv.org/pdf/2509.20003), [HTML](https://arxiv.org/abs/2509.20003)
### Authors
Somraj Gautam,Nachiketa Purohit,Gaurav Harit
### Background
机器学习领域中，高效的标注数据仍然是一个关键挑战，特别是在需要大量标注数据的目标检测任务中。主动学习（AL）作为一种有前景的解决方案，通过挑选最有信息量的样本来最小化标注成本。传统的AL方法主要依赖不确定性选择策略，而近年来的研究表明，结合多样性策略可以提高目标检测任务中的采样效率。本研究旨在确保选择能改善模型泛化能力的代表性样本。我们使用先进的表格检测架构（CascadeTabNet和YOLOv9）在两个基准数据集（TableBank-LaTeX和TableBank-Word）上评估了我们的方法。结果显示，基于AL的方法在限定预算下显著优于随机采样，同时保持与全监督模型相当的性能，实现了更高的平均精度（mAP）分数。
### Innovation
本研究引入了一种结合多样性策略的主动学习方法，用以挑选能够提高模型泛化能力的代表性样本。实验结果显示，这种基于AL的方法在一定程度上优于传统的不确定性和随机采样方法。
### Conclusion
本研究通过使用先进的表格检测架构在两个基准数据集上评估了结合多样性策略的主动学习方法。结果表明，与随机采样相比，基于AL的方法能够在有限标注预算下显著提升目标检测性能，同时保持较高的mAP分数，增强了模型的泛化能力。
## 526. `cs.CV` - CamPVG：具有极线感知扩散的摄像机控制全景视频生成 [PDF](https://arxiv.org/pdf/2509.19979), [HTML](https://arxiv.org/abs/2509.19979)
### Authors
Chenhao Ji,Chaohui Yu,Junyao Gao,Fan Wang,Cairong Zhao
### Background
最近，摄像机控制视频生成技术迅速发展，提供了对视频生成更精确的控制。然而，现有方法主要关注透视投影视频生成中的摄像机控制，而几何上一致的全景视频生成仍然具有挑战性。这种限制主要是由于全景姿态表示和球形投影的固有复杂性。
### Innovation
我们提出了CamPVG，这是一种基于扩散的全新框架，用于基于精确摄像机姿态指导的全景视频生成。我们实现了全景图像的摄像机位置编码，并基于球形投影提出了跨视图特征聚合。具体来说，我们提出了一种全景Plücker嵌入，通过球坐标变换编码摄像机的外参。此姿态编码器有效地捕捉全景几何，克服了传统方法在应用到等角投影时的局限性。此外，我们引入了极线模块，通过沿极线的自适应注意力掩码强制几何约束，从而实现细粒度的跨视图特征聚合，显著提高了生成的全景视频的质量和一致性。
### Conclusion
广泛的实验表明，我们的方法能够生成与摄像机轨迹一致的高质量全景视频，超过了现有方法在全景视频生成中的表现。
## 527. `cs.CV` - 使用狄利克雷过程混合模型聚类DINO嵌入进行异常检测 [PDF](https://arxiv.org/pdf/2509.19997), [HTML](https://arxiv.org/abs/2509.19997)
### Authors
Nico Schulthess,Ender Konukoglu
### Background
在医疗影像中使用无监督的异常检测时，对于小数据集，可以直接利用符合标准特征的内存库进行异常检测，但这不适合大型医疗数据集，因为计算负担会显著增加。因此，本文提出了一种使用狄利克雷过程混合模型（DPMM）建模DINOv2嵌入分布的方法，该模型能够自动调整混合成分的数量以适应数据。这与使用内存库不同，本文使用组件中心与嵌入之间的相似度作为异常得分函数来创建粗略的异常分割掩码。实验表明，尽管DINOv2是在自然图像上进行训练，但在医疗影像基准上可以实现非常有竞争力的异常检测性能，同时还能至少降低一半的推理时间。进一步的分析表明，归一化的DINOv2嵌入在异常存在的情况下通常与解剖结构更对齐，即使在存在异常的情况下也是很好的异常检测表示形式。
### Innovation
本文的主要创新点在于提出了一种使用狄利克雷过程混合模型（DPMM）来建模DINOv2嵌入分布的方法，以用于医疗影像中的无监督异常检测。这种方法不需要使用内存库，而是利用嵌入与组件中心之间的相似度作为异常评分函数，显著降低了计算负担。此外，本文还发现，归一化的DINOv2嵌入在异常检测中表现更好，能够更准确地反映解剖结构。
### Conclusion
通过使用DPMM嵌入DINOv2，即使在自然图像上进行训练，也能在医疗影像基准上实现具有竞争力的异常检测性能，还能减少至少一半的推理时间。归一化的DINOv2嵌入在异常检测中比未归一化的特征表现更好，即使在存在异常的情况下也能更好地与解剖结构对齐。相关代码已开源。
## 528. `cs.CV` - OmniScene：自主驾驶中基于注意力增强的多模态4D场景理解 [PDF](https://arxiv.org/pdf/2509.19973), [HTML](https://arxiv.org/abs/2509.19973)
### Authors
Pei Liu,Hongliang Lu,Haichao Liu,Haipeng Liu,Xin Liu,Ruoyu Yao,Shengbo Eben Li,Jun Ma
### Background
人类视觉能够将二维观察转化为自中心的三维场景理解，这是处理复杂场景和实现适应行为的基础。然而，当前的自动驾驶系统在这方面仍存在不足，主流方法主要依赖于基于深度的三维重建，而非真正的场景理解。本文通过提出一种类人框架OmniScene来解决这个问题。OmniScene通过整合多视角和时间感知，构建了一个完整的4D场景理解框架，旨在提高车辆对场景的理解和处理能力。
### Innovation
提出了OmniScene Vision-Language模型(简称OmniVLM)，这是一种结合了多视角和时序感知的视觉-语言框架，用于整体4D场景理解。利用教师-学生OmniVLM架构和知识蒸馏，将文本表示嵌入到3D实例特征中，以进行语义监督，丰富特征学习，并明确捕捉人类关注的语义。此外，还设计了一种层次融合策略（HFS），以解决多模态集成期间模态贡献不平衡的问题。该策略在多个抽象层次上适应性地校准几何和语义特征的重要性，从而有效地利用视觉和文本模态中的互补线索。
### Conclusion
本研究在nuScenes数据集上对OmniScene进行了全面评估，并将其与十多个当前最先进模型进行了比较，发现该方法在感知、预测、规划和视觉问答任务上均取得了优越的结果，从而确立了新的基准。
## 529. `cs.CV` - 过程重要吗？RITA：通过逆序增量过渡自回归推理合成图像篡改 [PDF](https://arxiv.org/pdf/2509.20006), [HTML](https://arxiv.org/abs/2509.20006)
### Authors
Xuekang Zhu,Ji-Zhe Zhou,Kaiwen Feng,Chenfan Qu,Yunfei Wang,Liting Zhou,Jian liu
### Background
图像篡改通常涉及复杂的操作过程，由一系列编辑操作序列组成，具有时间顺序和层次结构。目前的篡改工具（Image Manipulation Localization, IML）方法对篡改过程缺乏洞察，直接在一次预测中生成定位掩码，而不建模这些编辑步骤。这种一次预测范式将高维组合空间压缩成单个二进制掩码，导致与IML任务内在性质的巨大不匹配。为了克服这个问题，本文将图像篡改定位重新定义为条件序列预测任务，并提出了RITA框架。RITA按顺序逐层预测篡改区域，并利用每一步的预测作为下一步的条件，从而明确建模编辑操作之间的时序依赖关系和层级结构。为了进行训练和评估，作者合成了多步篡改数据集并构建了新的基准HSIM，同时提出了HSS度量标准来评估序列顺序和层级对齐。大量的实验证明，RITA在传统基准上表现优异，为这项新层级定位任务奠定了坚实基础，表明其作为通用和有效的范式的潜力。实验代码和数据集将公开提供。
### Innovation
首次将图像篡改本地化任务重新定义为条件序列预测任务，并提出RITA框架，该框架能够按顺序逐层预测篡改区域，利用每一步的预测作为下步的条件，明确建模编辑操作之间的时序依赖关系和层级结构。合成了多步篡改数据集并构建了新的基准HSIM，提出了HSS度量标准来评估序列顺序和层级对齐。
### Conclusion
RITA在传统基准上表现优异，为新型层级定位任务提供了坚实基础，证明了其作为通用和有效范式的潜力。实验代码和数据集将公开提供。
## 530. `cs.CV` - 改善针对多模态预训练模型的靶向对抗攻击的一般化和不可检测性 [PDF](https://arxiv.org/pdf/2509.19994), [HTML](https://arxiv.org/abs/2509.19994)
### Authors
Zhifang Zhang,Jiahan Zhang,Shengjie Zhou,Qi Wei,Shuo He,Feng Liu,Lei Feng
### Background
多模态预训练模型（例如 ImageBind）能够将不同的数据模态映射到共享的嵌入空间中，并在下游任务中表现出显著的成功。然而，其广泛应用引发了严重的安全问题，尤其是针对靶向小样本攻击的安全风险。已有研究表明，现有的靶向对抗攻击对于多模态预训练模型在两个方面仍然有限制：普适性和不可检测性。现有的攻击在跨模态对齐任务中，针对部分已知或语义相似的目标生成的伪造攻击样本难以泛化，并且容易被简单的异常检测方法检测到。因此，为了克服这些局限，本文提出了一种名为代理靶向攻击（PTA）的新方法，通过利用源模态和目标模态的代理来优化攻击样本，确保在防御面前保持隐匿性并向多个潜在目标对齐，同时通过理论分析强调一般化和不可检测性之间的关系，满足对不可检测性的特定要求的同时实现最优一般化。实验结果表明，我们的PTA方法在各种相关目标上的成功率很高，并能对抗多种异常检测方法而不被检测到。
### Innovation
本文提出了一种名为代理靶向攻击（PTA）的新方法。该方法通过利用源模态和目标模态的代理来优化攻击样本，在防御面前保持隐匿性并向多个潜在目标对齐。理论分析表明，PTA方法可以在满足不可检测性的特定要求的同时实现最优一般化。实验结果显示PTA方法在多种异常检测方法中保持了一定的隐匿性，并具有较高的成功率。
### Conclusion
研究结果表明，PTA方法可以在多种相关目标上实现高成功率，并能对抗多种异常检测方法而不被检测到。同时，通过理论分析和实验验证表明PTA方法可以兼顾攻击的一般化和不可检测性，提高了针对多模态预训练模型靶向攻击的有效性和安全性。
## 531. `cs.CV` - PS3: 将病理科报告与组织学图像和生物途径结合的多模态变换器用于肿瘤生存预测 [PDF](https://arxiv.org/pdf/2509.20022), [HTML](https://arxiv.org/abs/2509.20022)
### Authors
Manahil Raza,Ayesha Azam,Talha Qaiser,Nasir Rajpoot
### Background
当前在计算肿瘤学中的多模态融合方法主要关注通过综合多吉帕拉量级的组织切片全切片图像（WSIs）和基因组或转录组数据来提高生存预测，显示出改进的成果。然而，我们假设将病理报告纳入分析可以进一步增强预测性能。病理报告作为临床工作流程的关键部分，通过汇总病理学发现并结合专家分析和临床背景提供补充信息，对于辅助诊断非常有价值。然而，这些模态之间存在异质性，使得融合变得复杂。WSIs 是高度维度的数据，含有数十亿像素，而病理报告是长度不一的简短文本总结，可能造成模态不平衡的问题。
### Innovation
我们提出了一种基于原型的多模态方法 PS3（预测三种模态的生存），该方法包括：(1) 利用自我注意机制从病理报告中提取诊断相关部分，标准化文本表示；(2) 表现组织学原型，浓缩WSIs中的关键形态学模式；(3) 生物途径原型，编码转录组表达准确捕捉细胞功能。PS3模型通过应用于WSIs、病理报告和转录组数据之间的原型多模态令牌，可以处理模态间的交互作用。实验表明，该方法在TCGA数据库的六个数据集上优于现有的最先进的方法。
### Conclusion
该研究通过引入PS3模型，实现了病理报告、组织切片图像和转录组数据的多模态融合，并在临床基准、单模态基准和多模态基准上均取得了优异的生存预测性能。
## 532. `cs.CV` - LifeCLEF植物识别任务2020概述 [PDF](https://arxiv.org/pdf/2509.19402), [HTML](https://arxiv.org/abs/2509.19402)
### Authors
Herve Goeau,Pierre Bonnet,Alexis Joly
### Background
近年来，由于深度学习的进展以及可用于植物识别的大量野外照片的可用性，植物自动识别技术有了显著提高。然而，这一大量的数据主要仅涉及北美和西欧的数万种植物，而在多样性最丰富的热带国家则远远不足。另一方面，植物学家数个世纪以来在热带地区积累了大量标本，并将数百万张数字化的标本放在线上。2020年的LifeCLEF植物识别挑战（或“PlantCLEF 2020”）旨在评估利用植物标本数据库是否能改进对数据不足地区的植物自动识别。它基于南美圭亚那盾片地区的约1,000种植物数据集。任务被设为跨领域分类任务，训练集包括数十万张标本图像和数千张野外照片，以便学习两种数据域之间的映射关系。测试集仅包含野外照片。
### Innovation
LifeCLEF 2020植物识别挑战主要创新在于通过利用植物标本数据库，评估其在数据不足地区植物识别的改进可能性。该挑战采用了跨领域的分类任务，结合了大量标本图像和少量野外照片，以此来学习两种数据域之间的映射。这种方法提供了改进植物识别技术的潜力，特别是对于生物多样性丰富的次区域。
### Conclusion
该论文总结了公开的评估资源与结果，描述了参与研究团队所采用的方法和系统，以及对主要结果进行了分析。这表明，利用植物标本能显著改善数据贫乏区域的植物自动识别，尤其是在热带地区，同时也展示了跨领域数据学习的重要性及其在植物识别中的应用。
## 533. `cs.CV` - 预测质量评估以提升移动安全图形的可靠性 [PDF](https://arxiv.org/pdf/2509.20028), [HTML](https://arxiv.org/abs/2509.20028)
### Authors
Cas Steigstra,Sergey Milyaev,Shaodi You
### Background
安全图形验证码是防止假冒的关键工具，但其可靠性受到智能手机拍摄图像质量差的影响。用户不控制的拍摄会导致高误拒率，造成显著的‘可靠性差距’。
### Innovation
该研究提出了一个新的框架，用于预测估计每一帧对于下游验证任务的有用性，而不是依赖于传统的感知图像质量分析。框架使用轻量级模型预测视频帧的质量得分，以决定其是否适合资源密集型的验证模型。通过对32,000多张来自105种智能手机的数据集验证，框架表现出良好的性能。进一步的跨域分析表明，基于ImageNet预训练的冻结网络在面对未知印刷技术时比完全微调的模型有更好的泛化能力，这为实际应用中的泛化提供了一个重要见解：对于从物理制造到不同领域的转变，冻结通用模型可能比完全微调更具鲁棒性，而完全微调可能会过度拟合源域特征。
### Conclusion
研究通过预测质量评估，有效降低了安全图形验证的误拒率，并为系统设计提供了新的泛化策略。
## 534. `cs.CV` - 应用于生物识别认证和识别中的生成对抗网络的隐私保护 [PDF](https://arxiv.org/pdf/2509.20024), [HTML](https://arxiv.org/abs/2509.20024)
### Authors
Lubos Mjachky,Ivan Homoliak
### Background
生物识别认证系统正在许多领域广泛采用。然而，这些系统不允许参与用户影响其数据的使用方式。此外，数据可能泄露并可能在用户不知情的情况下被滥用。
### Innovation
本文提出了一种新的认证方法，该方法基于生成对抗网络（GAN），能够保护个人隐私。具体而言，该方法建议使用GAN将面部图像转换到视觉隐私域（如花卉或鞋子）。用于认证目的的分类器随后可以在视觉隐私域的图像上进行训练。
### Conclusion
根据我们的实验，该方法对攻击具有鲁棒性，并且仍然提供了有意义的效用。
## 535. `cs.CV` - SynchroRaMa: 基于多模态情绪嵌入的口型同步和情绪感知动话人头生成 [PDF](https://arxiv.org/pdf/2509.19965), [HTML](https://arxiv.org/abs/2509.19965)
### Authors
Phyo Thet Yee,Dimitrios Kollias,Sudeepta Mishra,Abhinav Dhall
### Background
动话人脸生成在需要表达性和自然性的人类虚拟角色互动中受到了越来越多的关注。然而，现有的情绪感知方法大多依赖单一模态（音频或图像）的情绪嵌入，这限制了它们捕捉细微情绪提示的能力。此外，大多数方法仅依赖单一参考图像，导致模型在时间上无法捕捉动作或属性的动态变化。这些问题促使开发一种新兴框架，将多种模态的情绪嵌入相结合，以生成具有更丰富和真实感情绪表达的动话人脸视频。
### Innovation
引入了一种名为SynchroRaMa的新框架，通过结合文本（通过情感分析）和音频（通过基于语音的情绪识别和音频衍生的情绪强度-唤醒特征）的情绪信号，实现了多模态情绪嵌入。SynchroRaMa包括音频到运动（A2M）模块，以生成与输入音频对齐的动作帧，确保自然头部运动和准确唇部同步。它还采用由大型语言模型生成的场景描述作为额外的文本输入，以便捕捉动态动作和高层次语义属性。通过结合视觉和文本线索，增强时间和视觉的真实感。定量和定性实验表明，SynchroRaMa在图像质量、表情保留和动作真实感方面优于现有的先进方法，并且用户研究进一步证实，SynchroRaMa在整体自然度、动作多样性以及视频平滑度方面获得了更高的主观评分。
### Conclusion
SynchroRaMa框架通过多模态情绪嵌入实现了动话人脸生成中的口型同步和情绪感知，实验结果表明它在图像质量和运动真实感方面显著优于现有技术，用户研究也验证了其在自然度和视频平滑度等方面的优越性。
## 536. `cs.CV` - SHMoAReg: Spark Deformable Image Registration via Spatial Heterogeneous Mixture of Experts and Attention Heads [PDF](https://arxiv.org/pdf/2509.20073), [HTML](https://arxiv.org/abs/2509.20073)
### Authors
Yuxi Zheng,Jianhui Feng,Tianran Li,Marius Staring,Yuchuan Qiao
### Background
编码-解码架构在基于深度学习的可变形图像注册（DIR）中被广泛应用，其中编码器提取多尺度特征，解码器通过恢复空间位置预测变形场。然而，目前的方法在特征提取的专门化以及在三个方向上联合且均匀地预测变形方面存在不足。
### Innovation
作者提出了一种新的专家引导的DIR网络——SHMoAReg，其中使用了Mixture of Experts（MoE）机制应用于编码器和解码器。具体来说，将Mixture of Attention heads（MoA）嵌入到编码器层中，而Spatial Heterogeneous Mixture of Experts（SHMoE）嵌入到解码器层中。MoA通过动态选择最合适的注意力头部组合来增强特征提取的专门化能力。同时，SHMoE用于在每个体素的三个不同方向上以具有不同核大小的专家来预测变形场。在两个公共可用的数据集上进行的大量实验显示，该方法在Dice分数方面有显著提升。
### Conclusion
该研究通过引入MoE机制到DIR任务中，增强了模型的可解释性。到目前为止，这是首次将MoE机制应用于DIR任务。该代码将很快发布。
## 537. `cs.CV` - 在扩散模型的语义潜在空间中释放图像去雾的潜力 [PDF](https://arxiv.org/pdf/2509.20091), [HTML](https://arxiv.org/abs/2509.20091)
### Authors
Zizheng Yang,Hu Yu,Bing Li,Jinghao Zhang,Jie Huang,Feng Zhao
### Background
扩散模型因其强大的数据分布建模能力，在图像去雾任务中受到了广泛关注。然而，扩散模型的重新训练需要大量的计算资源，并且在推理过程中需要进行大量的采样步骤，这些因素限制了扩散模型在图像去雾中的更广泛应用。
### Innovation
本文探索了预训练扩散模型的语义潜在空间中的固有特性，并提出了一个由预训练扩散模型中的不同时间步的扩散潜在表示引导的去雾网络，即DiffLI$^2$D。这种网络避免了对扩散模型的重新训练和迭代采样过程，通过高效利用来自预训练扩散模型的信息表示来提供图像去雾的指令。这种方法提供了一个将扩散模型引入图像去雾的新视角。
### Conclusion
本文提出的方法在多个数据集上的广泛实验表明，所提出的方法在图像去雾方面取得了优于现有方法的性能。源代码在GitHub上提供。
## 538. `cs.CV` - 基于视觉基础模型的高光谱适配器用于语义分割 [PDF](https://arxiv.org/pdf/2509.20107), [HTML](https://arxiv.org/abs/2509.20107)
### Authors
JuanaJuana Valeria Hurtado,Rohit Mohan,Abhinav Valada
### Background
高光谱成像（HSI）能够同时捕捉空间信息和密集的光谱测量，跨越许多狭窄的波长带。丰富的光谱内容有潜力提高机器人的感知能力，特别是在复杂材料组成、变化照明或其它视觉挑战的环境中。然而，当前HSI语义分割方法的表现不如预期，因为它们依赖于优化RGB输入的架构和学习框架。
### Innovation
本文提出了一种新的高光谱适配器，利用预训练的视觉基础模型有效地学习高光谱数据。该架构包含光谱变换器和光谱感知空间先验模块来提取丰富的空-谱特征。此外，引入了模态感知交互块，通过专用的提取和注入机制促进高光谱表示和冻结的视觉变换器特征的有效集成。
### Conclusion
在三个基准自动驾驶数据集上的广泛评估表明，本架构在直接使用HSI输入的情况下实现了最先进的语义分割性能，优于基于视觉的方法和高光谱分割方法。源代码已发布。
## 539. `cs.CV` - C$^2$MIL: 在稳健和可解释的生存分析中同步语义和拓扑因果关系的多次实例学习 [PDF](https://arxiv.org/pdf/2509.20152), [HTML](https://arxiv.org/abs/2509.20152)
### Authors
Min Cen,Zhenfeng Zhuang,Yuzhe Zhang,Min Zeng,Baptiste Magnier,Lequan Yu,Hong Zhang,Liansheng Wang
### Background
Graph-based 多实例学习（MIL）在通过苏木精和伊红（H&E）染色的全组织切片图像进行生存分析时广泛应用，因其能捕获拓扑信息。但是，染色和扫描间的变异性会引入语义偏见，而不相关的拓扑子图会创建噪声，导致滑片级别的表示出现偏差。这些问题会影响分析的可解释性和泛化能力。
### Innovation
本研究提出了基于双重结构因果模型的双重因果图形基MIL模型（C$^2$MIL），该模型包含一种新的跨尺度自适应特征解耦模块用于语义因果干预，以及一种新的伯努利可微分因果子图采样方法用于拓扑因果发现。结合解耦监督和对比学习的联合优化策略同时细化语义和拓扑因果性。
### Conclusion
实验结果表明，C$^2$MIL相较于现有方法能持续提高泛化和可解释性，并可以作为多种MIL基线的因果增强工具。代码可在此处获得：this https URL
## 540. `cs.CV` - EchoBench: 序言本：医疗大型视语言模型奉承行为基准 [PDF](https://arxiv.org/pdf/2509.20146), [HTML](https://arxiv.org/abs/2509.20146)
### Authors
Botai Yuan,Yutian Zhou,Yingjie Wang,Fushuo Huo,Yongcheng Jing,Li Shen,Ying Wei,Zhiqi Shen,Ziwei Liu,Tianwei Zhang,Jie Yang,Dacheng Tao
### Background
近期的医疗大型视语言模型LVLM基准测试主要关注排行榜的准确率，而忽视了可靠性和安全性。已有研究未充分关注这些模型在高压医疗环境中的奉承行为，即它们无条件地重复用户提供的信息。因此，目前缺乏系统性地评估医疗LVLM奉承行为的基准工具。该研究旨在填补这一空白，提出EchoBench基准，用于系统性评估医疗LVLM的奉承行为，通过包含18个科室、20种模态、2122张图片和90个模拟偏见输入的高仿真场景，彰显了目前临床应用中的风险。
### Innovation
该研究引入了EchoBench基准，系统性地评估医疗LVLM的奉承行为。该基准包含大量复杂场景（18个科室、20种模态、2122张图片和90个模拟偏见输入），覆盖临床、学习和专业等多个方面。研究发现所有模型在不同方面都表现出显著奉承行为，最高数据质量和更强的领域知识能够减少奉承，同时不会影响无偏精准度。同时，该基准为减轻奉承行为提供了测试平台，指出了一些有效的干预措施，为训练过程和解码策略提供参考。
### Conclusion
该研究揭示了医疗领域的LVLM需要超越准确率的更加可靠的评估标准，通过EchoBench基准，研究人员能够识别可能导致奉承的因素，并提供实用的指导以开发更安全、更可信的医疗LVLM。
## 541. `cs.CV` - 更小更好：通过剪枝增强车载AI系统的透明度 [PDF](https://arxiv.org/pdf/2509.20148), [HTML](https://arxiv.org/abs/2509.20148)
### Authors
Sanish Suwal,Shaurya Garg,Dipkamal Bhusal,Michael Clifford,Nidhi Rastogi
### Background
联网和自动驾驶车辆继续依赖AI系统，透明度和安全性对于建立信任和操作安全性至关重要。尽管后验解释可以提高这些黑盒AI模型的透明度，但其质量和可靠性常因不一致和未能忠实地表示模型决策而受到质疑。本研究系统地检查了三种常用训练方法（自然训练、对抗训练和剪枝）对交通标志分类器后验解释质量的影响。通过广泛的实证分析表明，剪枝显著提高了解释的可理解性和真实性（使用显著性图）。研究结果揭示，剪枝不仅可以提高模型效率，还能在学习表示中引入稀疏性，从而导致更可解释和可靠的决策。这些见解表明，剪枝是开发透明深度学习模型的有效策略，特别是在资源受限的车载AI系统中。
### Innovation
本研究通过实证分析三种常用的训练方法（自然训练、对抗训练和剪枝）对交通标志分类器后验解释质量的影响，发现剪枝不仅能提高模型的效率，还能增强解释的可理解性和真实性。这一发现为开发透明的深度学习模型提供了一种新的策略，尤其是在资源受限的车载AI系统中显得尤为重要。
### Conclusion
剪枝不仅改善了模型的效率，还通过引入稀疏性提高了解释的可理解性和可靠性。这些发现表明，剪枝策略对于开发透明且高效的深度学习模型具有重要意义，尤其是在资源受限的车载AI系统中。
## 542. `cs.CV` - U-Mamba2-SSL for Semi-Supervised Tooth and Pulp Segmentation in CBCT [PDF](https://arxiv.org/pdf/2509.20154), [HTML](https://arxiv.org/abs/2509.20154)
### Authors
Zhi Qin Tan,Xiatian Zhu,Owen Addison,Yunpeng Li
### Background
牙科锥形束计算机断层扫描（CBCT）中的牙齿和髓质分割对于临床应用如治疗计划和诊断至关重要。然而，这一过程需要广泛的专家知识和大量时间，强调了有效利用未标记数据的自动化算法的需求。
### Innovation
本文提出了一种新颖的半监督学习框架——U-Mamba2-SSL，该框架基于U-Mamba2模型，并采用多阶段训练策略。该框架首先通过破坏性自编码器进行自我监督预训练U-Mamba2，随后利用未标记数据通过一致性正则化，引入输入和特征扰动以确保模型输出的稳定性，最后采用伪标签策略以及减小损失权重的方法来最小化潜在错误的影响。
### Conclusion
U-Mamba2-SSL在验证数据集上的平均得分为0.872，DSC为0.969，证明了该方法的优越性能。相关代码可在以下网址获取。
## 543. `cs.CV` - 一种简单的文本-图像科学可视化问答数据增强策略 [PDF](https://arxiv.org/pdf/2509.20119), [HTML](https://arxiv.org/abs/2509.20119)
### Authors
Belal Shoer,Yova Kementchedjhieva
### Background
科学可视化问答对视觉语言模型提出巨大挑战，因为科学图表及其多模态上下文十分复杂。传统方法将图表和伴随的文字（如问题及选项）视为独立输入，EXAMS-V通过将视觉和文本内容嵌入单个图像引入了一种新范式。然而，即便在零样本设置下，最新的专有模型表现不佳，表明需要针对任务的微调。
### Innovation
本研究提出了一种简单数据增强策略，通过将现有的分离图像-文本配对转化为统一图像以合成新数据集，从而解决文本-图像格式训练数据稀缺问题。微调一种小型多语言多模态模型于合成数据和EXAMS-V数据混合可以显著提升13种语言的表现，并显示出跨语言迁移能力。
### Conclusion
该研究通过合成数据集和任务特定微调，显著提升了科学可视化问答的跨语言性能，展示了增强现实和模型调整的重要性。
## 544. `cs.CV` - 光学海洋食谱：创造现实数据集以促进水下视觉研究 [PDF](https://arxiv.org/pdf/2509.20171), [HTML](https://arxiv.org/abs/2509.20171)
### Authors
Patricia Schöntag,David Nakath,Judith Fischer,Rüdiger Röttgers,Kevin Köser
### Background
水下环境中的机器视觉开发与评估依然具有挑战性，通常依赖于针对特定应用的试错测试。这主要是由于缺乏能够考虑光学挑战（如光谱变化导致的颜色失真、后向散射和体积散射导致的对比度降低和模糊以及自然或人工照明引起的动态光模式）的受控和基于真实情况的测试环境。此外，海洋水体在不同区域、不同深度和不同季节中影响图像外观的变化很大。然而，大多数机器视觉评估通常在特定的光学水类型和成像条件下进行，因此往往缺乏普遍适用性。全面测试各种开放水域情境在技术上是不现实的。
### Innovation
我们提出了《光学海洋食谱》，这是一种用于创建在可控水下条件下现实数据集的框架。相比之下，这些食谱使用校准彩色和散射添加剂，使得水体成分对图像外观的影响可以重复和可控地测试，从而提供了一种独特的框架，用于在现实且可控的水下场景中分析机器视觉。可控环境能够创建一系列视觉任务的 ground-truth 数据，包括水参数估计、图像恢复、分割、视觉 SLAM 和水下图像合成。
### Conclusion
我们提供了一个使用光学海洋食谱生成的演示数据集，并简要展示了该系统在两个水下视觉任务中的应用。该数据集和评估代码将可供使用。
## 545. `cs.CV` - 针对自主驾驶的视觉-语言模型的通用伪装攻击 [PDF](https://arxiv.org/pdf/2509.20196), [HTML](https://arxiv.org/abs/2509.20196)
### Authors
Dehong Kong,Sifan Yu,Siyuan Liang,Jiawei Liang,Jianhou Gan,Aishan Liu,Wenqi Ren
### Background
视觉语言模型（VLM-AD）在自动驾驶中的应用正在成为一项有前景的研究方向，通过提升多模态推理能力获得了显著改进。尽管VLM-AD具有先进的推理能力，但它仍然容易受到对手攻击的影响，这些攻击通过对模型进行精心构造的干扰来误导模型决策。现有的攻击方法存在明显的挑战：1) 物理对手攻击主要针对视觉模块，难以直接转移到VLM-AD系统，因为它们通常攻击的是低级感知组件；2) 针对VLM-AD的对手攻击大多集中在数字层面。
### Innovation
本文提出了第一个针对VLM-AD的通用伪装攻击框架（UCA）。UCA在特征空间中工作，生成在不同用户命令和模型架构中表现出强泛化的物理可实现伪装纹理。UCA还引入了一种特征偏差损失（FDL），以在清洁图像和对抗图像之间最大化表征差异。此外，UCA结合了多尺度学习策略，并调整采样比，以增强其对现实世界中尺度和视点多样性变化的适应性。实验结果表明，UCA能够诱导各种VLM-AD模型和驾驶场景下的错误驾驶指令，其性能显著优于现有最先进的攻击方法（在3-P指标上提高30%）。此外，UCA在各种视点和动态条件下都表现出强大的攻击鲁棒性，具有实际部署的高潜力。
### Conclusion
UCA方法展示出在不同视角和动态条件下，对VLM-AD模型产生显著错误驾驶命令的能力，使其成为目前最先进的攻击方法。该研究进一步揭示了VLM-AD在编码器和投影层的潜在脆弱性，并提供了一种有效的对抗策略来提高系统的安全性。
## 546. `cs.CV` - 带有立体约束的4D驾驶场景生成 [PDF](https://arxiv.org/pdf/2509.20251), [HTML](https://arxiv.org/abs/2509.20251)
### Authors
Hao Lu,Zhuang Ma,Guangfeng Jiang,Wenhang Ge,Bohan Li,Yuzhan Cai,Wenzhao Zheng,Yunpeng Zhang,Yingcong Chen
### Background
当前的生成模型在合成支持时空外推和新视角合成（NVS）的动态4D驾驶场景方面存在局限性，难以在无需逐场景优化的情况下同时实现上述功能。生成和新视角合成之间的桥梁构建仍然是一个主要挑战。
### Innovation
提出了一种名为PhiGenesis的统一框架，用于4D场景生成，它扩展了视频生成技术，加入了几何和时间一致性。PhiGenesis能够从多视角图像序列和相机参数中生成沿目标3D轨迹的时间连续4D高斯分布表示，并引入了一种几何引导的视频扩散模型，该模型使用渲染的4D场景作为先验来生成未来视图，并基于轨迹进行生成。为此，提出了一种新的条件策略——立体强迫，来解决新视角中的几何曝光偏差问题，通过动态调整生成影响来增强时间连贯性。
### Conclusion
实验结果表明，该方法在外观和几何重建、时空生成和新视角合成任务中达到了最先进的性能，同时在下游评估中也表现出可竞争的性能。
## 547. `cs.CV` - ImageNet训练的CNN并非偏向纹理：通过受控抑制重新审视特征依赖 [PDF](https://arxiv.org/pdf/2509.20234), [HTML](https://arxiv.org/abs/2509.20234)
### Authors
Tom Burgert,Oliver Stoll,Paolo Rota,Begüm Demir
### Background
卷积神经网络(CNNs)被视为具有纹理偏性的假设影响了深度学习中特征使用的广泛讨论。这篇论文通过重新审视Geirhos等人提出的线索冲突实验的局限性，提出了一个不受特定领域限制的框架，该框架通过对形状、纹理和颜色线索的系统抑制来量化模型的特征依赖性，避免了强制选择冲突带来的混杂因素。研究表明，CNNs在视觉任务中更多依赖局部形状特征，而非固有地偏向纹理。现代训练策略或架构（ConvNeXt, ViTs）能够显著降低这种依赖性。不同领域的模型依赖模式也不同：计算机视觉模型优先考虑形状，医学影像模型侧重颜色，而遥感模型则表现出更强的纹理依赖性。
### Innovation
论文提出了一个不受特定领域限制的框架，通过对形状、纹理和颜色线索的系统抑制来量化模型的特征依赖性，避免了强制选择冲突带来的混杂因素。研究发现，CNNs更多依赖局部形状特征，而非固有地偏向纹理，不同领域的模型依赖模式也不同。研究还强调了现代训练策略或架构（如ConvNeXt, ViTs）能够显著降低CNNs的特征依赖性。
### Conclusion
ImageNet训练的CNNs并非固有地偏向纹理，而是主要依赖局部形状特征。这种依赖性可以被现代训练策略或架构（如ConvNeXt, ViTs）显著减轻。不同领域的模型特征依赖模式也存在系统性差异：计算机视觉模型优先考虑形状，医学影像模型侧重颜色，而遥感模型则表现出更强的纹理依赖性。
## 548. `cs.CV` - 具有多参考非局部注意力的各向异性交叉视图纹理传输在CT切片插值中的应用 [PDF](https://arxiv.org/pdf/2509.20242), [HTML](https://arxiv.org/abs/2509.20242)
### Authors
Kwang-Hyun Uhm,Hyunjun Cho,Sung-Hoo Hong,Seung-Won Jung
### Background
CT图像是一种广泛应用的医学诊断无创成像技术，但由于存储成本和操作时间较高，临床实践中通常使用大的片厚采集图像，导致CT体积的各向异性特征，即层面间分辨率远低于层面内分辨率。这种不一致的分辨率可能影响疾病诊断，因此开发了基于深度学习的体素超分辨率方法以提高层面间分辨率。现有的方法主要集中在单层图像超分辨率或从相邻层面合成中间层面，但未能充分利用3D CT体积的各向异性特性。本文提出了一个新颖的跨视图纹理传输方法，通过充分挖掘3D CT体积的各向异性本质，用于CT切片插值。具体地，该方法利用高分辨率层面内纹理细节作为参考，将其转移至低分辨率层面外图像。通过使用多参考非局部注意模块，从多个层面图像中抽取有意义的特征，重建层面外高频细节。
### Innovation
本文提出了一种新颖的跨视图纹理传输方法，通过充分利用3D CT体积的各向异性特性，首次专门针对CT切片插值问题提出解决方案。该方法利用高分辨率层面内纹理细节作为参考，并通过多参考非局部注意模块抽取有意义的特征，从多个层面图像中重建层面外高频细节。该方法在多个公开的CT数据集上进行测试，表明其在CT切片插值上的性能显著优于现有其他方法，验证了提出框架的有效性。
### Conclusion
通过广泛的实验，本文表明提出的方法在CT切片插值方面显著优于现有竞争方法，验证了所提出的框架的有效性。源代码可在指定链接找到。
## 549. `cs.CV` - HiPerformer：具有模块化分层融合策略的高性能全局-局部分割模型 [PDF](https://arxiv.org/pdf/2509.20280), [HTML](https://arxiv.org/abs/2509.20280)
### Authors
Dayu Tan,Zhenpeng Xu,Yansen Su,Xin Peng,Chunhou Zheng,Weimin Zhong
### Background
医学图像分割过程中，局部细节和全局上下文都至关重要，有效整合这两者对于实现高精度至关重要。现有的基于CNN-Transformer混合架构的主流方法通常采用简单的特征融合技术，如串联堆叠、端点连接或点乘，这些方法难以解决特征间的不一致性和信息冲突及丢失问题
### Innovation
本文创新性地提出了HiPerformer。HiPerformer的编码器采用了一种新颖的模块化分层架构，可以在并行中动态融合多源特征，实现层次间的深度异构信息整合。设计了局部-全局特征融合模块(LGFF)，实现对局部细节和全局语义信息的精确和高效融合。此外，还提出了渐进金字塔聚合模块(PPA)以增强多尺度特征表示能力和抑制噪声干扰
### Conclusion
在11个公开数据集上的实验表明，所提方法在分割精度和鲁棒性方面优于现有分割技术，证明了更高的分割精度和鲁棒性。代码可在该链接获取
## 550. `cs.CV` - PerFace: 基于感知面部相似性的度量学习以增强面部匿名化 [PDF](https://arxiv.org/pdf/2509.20281), [HTML](https://arxiv.org/abs/2509.20281)
### Authors
Haruka Kumagai,Leslie Wöhler,Satoshi Ikehata,Kiyoharu Aizawa
### Background
随着社会对隐私问题的关注上升，面部匿名化技术不断发展，包括面部互换方法的出现。这些方法将一个人的身份替换为另一个身份。在面部互换中找到匿名性和自然性之间的平衡需要谨慎选择身份：过于相似的面孔会损害匿名性，而非常不同的面孔则会降低自然性。现有模型专注于二元身份分类“是否为同一人”，难以衡量诸如“完全不同”与“高度相似但不同”等微妙差异。因此，需要一种基于人类感知的面部相似性度量方法。
### Innovation
本文提出了一种基于人类感知的面部相似性度量方法，创建了一个包含6,400个三元注释的数据集，并采用度量学习来预测相似性。实验结果表明，该方法在面部相似性预测和基于属性的面部分类任务中均显著优于现有方法。
### Conclusion
实验结果证明，所提出的方法在面部相似性预测和基于属性的面部分类任务中都取得了显著的改进，克服了现有方法无法精确衡量细微差异的问题。
## 551. `cs.CV` - AI辅助乳腺X线图像解释的多功能基础模型 [PDF](https://arxiv.org/pdf/2509.20271), [HTML](https://arxiv.org/abs/2509.20271)
### Authors
Fuxiang Huang,Jiayi Zhu,Yunfang Yu,Yu Xie,Yuan Guo,Qingcong Kong,Mingxiang Wu,Xinrui Jiang,Shu Yang,Jiabo Ma,Ziyi Liu,Zhe Xu,Zhixuan Chen,Yujie Tan,Zifan He,Luhui Mao,Xi Wang,Junlin Hou,Lei Zhang,Qiong Luo,Zhenhui Li,Herui Yao,Hao Chen
### Background
乳腺癌是全球女性中最常见的癌症类型，并且是导致癌症相关死亡的主要原因。乳腺X线摄影（乳腺钼靶）对于早期发现和诊断乳腺病变至关重要。尽管最近在乳腺X线图像分析的基础模型（FMs）方面取得了进展，但在临床应用中仍受到多种基本限制的约束，如训练数据多样性不足、模型泛化能力有限以及在临床相关任务上的综合评估不足。
### Innovation
提出了一个名为VersaMammo的多功能乳腺X线图像基础模型，通过构建包含706,239张图像的多机构数据集，采用两阶段预训练策略（首先通过自监督学习训练教师模型提取可转移特征，然后结合监督学习和知识蒸馏将特征和临床知识传递给VersaMammo），和建立了包含92个具体任务的基准测试（涵盖68个内部任务和24个外部验证任务），从而克服了传统基础模型的限制，实现了在多种临床任务上的高性能，验证了其卓越的泛化能力和临床实用性。
### Conclusion
VersaMammo在68个内部任务中50项和24个外部验证任务中的20项表现最佳，平均排名分别为1.5和1.2。这些结果证明其在乳腺癌筛查和诊断中的可靠性和可扩展性有了显著进展。
## 552. `cs.CV` - 一种用于医疗影像分析的共生进化自主人工智能系统 [PDF](https://arxiv.org/pdf/2509.20279), [HTML](https://arxiv.org/abs/2509.20279)
### Authors
Songhao Li,Jonathan Xu,Tiancheng Bao,Yuxuan Liu,Yuchen Liu,Yihang Liu,Lilin Wang,Wenhui Lei,Sheng Wang,Yinuo Xu,Yan Cui,Jialu Yao,Shunsuke Koga,Zhi Huang
### Background
自主人工智能（Agentic AI）在医疗和生物医学研究中迅速发展，但在医疗图像分析中，其性能和采用率仍然受到缺乏稳健生态系统、工具集不足以及缺乏实时互动专家反馈的影响。因此，目前对医疗图像分析中的自主人工智能技术的应用受到限制。
### Innovation
本文介绍了TissueLab，这是一种共生进化的自主人工智能系统，它允许研究人员直接提问，自动计划和生成可解释的工作流程，并进行实时分析，同时专家可以可视化中间结果并进行调整。TissueLab集成了病理学、放射学和空间组学领域的工具工厂，通过标准输入、输出和各种工具的能力，确定何时以及如何使用它们来解决研究和临床问题。此外，通过持续学习，TissueLab能够从临床实践中学习，不断改进分类器和更有效的决策策略。与端到端的视觉语言模型（VLM）和其他自主人工智能系统（如GPT-5）相比，TissueLab在多种临床相关量化任务中的性能实现了最先进的水平。使用主动学习，TissueLab能够在几分钟内对未见过的疾病情况进行准确的计算，无需大规模数据集或长时间重新训练。
### Conclusion
TissueLab作为一种可持续的开源生态系统，旨在加速计算研究和转化性应用在医疗成像中的使用，为下一代医疗人工智能奠定了基础。
## 553. `cs.CV` - PU-Gaussian: 点云插值使用3D高斯表示 [PDF](https://arxiv.org/pdf/2509.20207), [HTML](https://arxiv.org/abs/2509.20207)
### Authors
Mahmoud Khater,Mona Strauss,Philipp von Olshausen,Alexander Reiterer
### Background
由3D传感器生成的点云常常稀疏且噪声大，这给需要密集且高保真3D表示的任务带来了挑战。先前的工作探索了基于隐式特征的上采样和距离函数学习，但这些方法往往以牺牲几何可解释性或输入稀疏性鲁棒性为代价。为了解决这些问题，我们提出了一种新的上采样网络PU-Gaussian，它使用各向异性的3D高斯分布来建模每个点的局部邻域。这些高斯分布捕捉到了潜在的几何结构，允许我们在局部几何域中通过直接点抽样直接进行上采样。抽样过程生成了一个稀疏但密集的点云。随后的细化网络调整粗略输出，以产生更均匀的分布和更锐利的边缘。
### Innovation
我们提出了一种名为PU-Gaussian的新型上采样网络，它通过局部几何域中直接的点抽样使用各向异性的3D高斯分布来建模点的局部邻域，从而捕捉潜在的几何结构。抽样过程生成了一个稀疏但密集的点云，随后的细化网络进一步调整粗略输出，以生成更均匀的分布和更锐利的边缘。与现有技术相比，该方法在PU1K和PUGAN数据集上取得了最先进的性能。
### Conclusion
我们在PU1K和PUGAN数据集上进行了广泛的测试，展示了PU-Gaussian方法在点云插值任务上的优越性能。我们公开了该方法的代码和模型权重，以便其他研究人员使用和进一步研究。
## 554. `cs.CV` - PhysCtrl：基于生成物理的可控且物理合理的视频生成 [PDF](https://arxiv.org/pdf/2509.20358), [HTML](https://arxiv.org/abs/2509.20358)
### Authors
Chen Wang,Chuhao Chen,Yiming Huang,Zhiyang Dou,Yuan Liu,Jiatao Gu,Lingjie Liu
### Background
现有的视频生成模型在从文本或图像生成逼真视频方面表现出色，但往往缺乏物理合理性且不具备3D可控性。
### Innovation
引入了一种新的基于物理的图像到视频生成框架PhysCtrl，该框架结合了物理参数和力控制，并且核心技术是一个通过扩散模型学习物理动力学分布的生成物理网络。此外，该框架还包含一种新的时空注意力块，模拟粒子交互，并在训练过程中结合物理约束以确保物理合理性。
### Conclusion
实验表明，PhysCtrl生成的物理合理的运动轨迹，驱动图像到视频模型时，能够产生高质量、可控且物理合理的视频，优于现有方法。
## 555. `cs.CV` - 修正的解耦数据集蒸馏：更公平和全面的评估 [PDF](https://arxiv.org/pdf/2509.19743), [HTML](https://arxiv.org/abs/2509.19743)
### Authors
Xinhao Zhong,Shuoyang Sun,Xulin Gu,Chenyang Zhu,Bin Chen,Yaowei Wang
### Background
数据集蒸馏的目标是生成紧凑的合成数据集，通过在其中训练的模型能与在完整真实数据集上训练的模型达到相似的性能，同时显著减少存储和计算成本。早期的两阶段优化方法（例如MTT）在小规模数据集上取得了有前景的结果，但其可扩展性受限于高昂的计算开销。为了解决这一限制，最近的解耦数据集蒸馏方法（例如SRe²L）将教师模型预训练与合成数据生成过程分开。这些方法还在后评估阶段引入了随机数据增强和阶段软标签，以提高性能和泛化能力。然而，现有的解耦蒸馏方法在后评估协议方面存在一致性问题，这阻碍了该领域的发展。
### Innovation
在这项工作中，作者提出了修正的解耦数据集蒸馏（RD³），系统地研究了不同的后评估设置如何影响测试精度。进一步探讨现有方法之间报告的性能差异是否反映真实的算法进步，还是源于评估程序的差异。研究发现，大量的性能变化可以归因于评估的一致性不佳，而不是合成数据内在质量的差异。此外，作者还确定了适用于不同设置的通用策略，以提高蒸馏数据集的有效性。通过建立标准化基准和严格的评估协议，RD³为未来的数据集蒸馏研究提供了公平和可重复性比较的基础。
### Conclusion
通过系统研究不同后评估设置对测试准确率的影响，RD³揭示了大部分性能差异主要来源于评估的一致性问题。研究还指出了改进解耦数据集蒸馏方法通用策略，并通过标准基准和严谨评估协议为未来研究提供比较基础，促进公平、可重复的实验结果。
## 556. `cs.CV` - FAST: 前景感知扩散与加速采样轨迹的分割导向异常合成 [PDF](https://arxiv.org/pdf/2509.20295), [HTML](https://arxiv.org/abs/2509.20295)
### Authors
Xichen Xu,Yanshu Wang,Jinbao Wang,Xiaoning Lei,Guoyang Xie,Guannan Jiang,Zhichao Lu
### Background
工业异常分割高度依赖于像素级标注，但实际应用中异常情况往往稀少、多样且标注成本高。现有的分割导向工业异常合成方法在采样效率和生成质量之间难以取得平衡。大多数方法对所有空间区域处理一致，忽视了异常区域与背景区域统计差异的重要性，这限制了可控、结构特定异常的生成，特别适合分割任务的需求。
### Innovation
本文提出了FAST，一种前景感知扩散框架，包含两个创新模块：异常指导加速采样（AIAS）和前景感知重构模块（FARM）。AIAS 是一种无需训练的采样算法，通过粗到细的聚合加速反向过程，并能以不到10步的采样生成目前最先进的分割导向异常。同时，FARM 在每个采样步骤调整前景区域内的异常感知噪声，使异常信号在整个去噪过程中得到保留。大量实验表明，FAST 在多个工业基准测试中始终优于现有的异常合成方法，特别是在分割任务下游表现突出。
### Conclusion
FAST 出色地解决了现有异常合成方法在采样效率和生成质量之间的平衡问题，并能够生成高质量的分割导向异常，显著提升了工业异常分割任务的表现。
## 557. `cs.CV` - YOLO基 Deer 检测在边缘设备上的综合性能评估 [PDF](https://arxiv.org/pdf/2509.20318), [HTML](https://arxiv.org/abs/2509.20318)
### Authors
Bishal Adhikari,Jiajia Li,Eric S. Michel,Jacob Dykes,Te-Ming Paul Tseng,Mary Love Tagert,Dong Chen
### Background
农业因鹿入侵造成的经济损失巨大，每年在美国估计在数十亿美元以上，这表明传统缓解策略的不足，因为这些方法往往是劳动密集型且成本高昂，并且在现代农业系统中并不有效。为了克服这一问题，迫切需要智能自主解决方案，这就需要准确高效的鹿检测能力。但受制于文献中这些领域的空白，主要是缺乏针对性的实用数据集和关于鹿检测系统现场部署性的研究有限。这项研究针对这一空白，针对现实场景中的鹿检测进行了全面评估，涉及最新YOLO架构的12个模型变异体，并进行了高性能计算和边缘计算平台的实地测试。结果表明，未经硬件特定优化的Raspberry Pi无法实现实时检测，而NVIDIA Jetson平台在某些模型上能提供超过30 FPS的高帧率。
### Innovation
这项研究的贡献在于，首先引入了一款经过整理并公开的鹿数据集，包含3095张图片和鹿的边界框注释；其次进行了涵盖四种YOLO架构的12个模型变异体的广泛比较研究；最后对高性能计算设备和边缘计算平台进行了基准测试，探讨了不同类型模型在实时检测鹿方面的性能与效率。研究表明，小型且架构先进的模型如YOLOv11n、YOLOv8s和YOLOv9s能够提供良好的检测准确性和计算效率之间的平衡。同时，研究成果中包含了开源代码和数据集，以促进未来研究。
### Conclusion
这项研究通过广泛的数据集和模型比较，以及在高性能计算和边缘计算平台上的基准测试，提供了YOLO基鹿检测模型在实际环境中的性能评估。这些发现为未来鹿入侵检测系统的开发提供了实用指导，并强调了针对农业实际应用的专业数据集的重要性。研究中的代码和数据集已公开，以促进进一步研究。
## 558. `cs.CV` - HUNT：在未结构化环境中基于瞬时相对坐标实现高速无人机导航和跟踪 [PDF](https://arxiv.org/pdf/2509.19452), [HTML](https://arxiv.org/abs/2509.19452)
### Authors
Alessandro Saviolo,Jeffrey Mao,Giuseppe Loianno
### Background
搜救任务需要无人驾驶航空器在未知非结构化环境中以高速飞行，并在检测到目标后进行跟踪。在退化感知条件下和没有全局定位的情况下，同时实现这两种能力仍然是一个开放的挑战。最近的研究表明，通过将规划和控制锚定到可见的目标上，可以在相对导航中实现稳健的目标跟踪，但这些方法无法解决没有目标视野时的导航问题。
### Innovation
HUNT提出了一个实时框架，将穿越、获取和跟踪统一在一个相对框架内，直接从机载瞬时可观测量（如姿态、高度和速度）定义导航目标，从而在搜索期间实现反应性高速飞行。一旦检测到目标，相同感知控制管道能够无缝过渡到跟踪。
### Conclusion
该研究在稠密森林、集装箱园区、带有车辆和人偶的搜索与救援操作中的户外实验表明，HUNT框架在全局方法失败的情况下实现了鲁棒的自主性。HUNT定义了基于瞬时相对坐标的方法，这种方法能够在不确定和挑战性的环境中有效执行高难度操作。
## 559. `cs.CV` - 无编码器的高效姿态条件控制和虚拟试穿中的姿态控制 [PDF](https://arxiv.org/pdf/2509.20343), [HTML](https://arxiv.org/abs/2509.20343)
### Authors
Qi Li,Shuwen Qiu,Julien Han,Xingzi Xu,Mehmet Saygin Seyfioglu,Kee Kiat Koo,Karim Bouyarmane
### Background
随着在线购物的持续增长，虚拟试穿（VTON）技术的需求也随之上升，该技术允许客户通过将产品图像叠加到自己的照片上来预览产品。有效的VTON的关键和挑战是姿态控制，它确保产品准确地与用户身体对齐，同时支持多种姿态以提供更沉浸式的体验。然而，将姿态条件纳入VTON模型带来了几个挑战，包括选择最优的姿态表示、不引入额外参数地整合姿态，以及在保持姿态连贯性的同时实现灵活的姿态控制。
### Innovation
本研究基于一个基准VTON模型，该模型没有外部编码器，控制网络或复杂的注意力层，通过空间拼接姿态数据，使用姿态图和骨架进行性能比较，而不向基础模型添加任何额外参数或模块。实验结果表明，使用姿态图进行姿态缝合能够取得最佳效果，提高姿态保真度和输出的真实性。此外，还提出了使用精细粒度和边界框掩码的混合掩码训练策略，使模型能够在多种姿态和条件下支持灵活的产品整合。
### Conclusion
本研究在保持基础模型简单的前提下，通过姿态图拼接等创新方法有效实现了姿态控制，证明了这种方法在VTON中的优越性，为虚拟试穿技术的发展提供了新的思路。
## 560. `cs.CV` - EditVerse: 使用上下文学习统一图像和视频的编辑与生成 [PDF](https://arxiv.org/pdf/2509.20360), [HTML](https://arxiv.org/abs/2509.20360)
### Authors
Xuan Ju,Tianyu Wang,Yuqian Zhou,He Zhang,Qing Liu,Nanxuan Zhao,Zhifei Zhang,Yijun Li,Yuanhao Cai,Shaoteng Liu,Daniil Pakhomov,Zhe Lin,Soo Ye Kim,Qiang Xu
### Background
近年来，基础模型的进展显示了一个明显的趋势，即统一和规模化的趋势，已从专门的任务发展到多领域的涌现能力，特别是在图像生成和编辑方面。然而，视频生成和编辑仍然因为架构限制和数据稀缺性而处于碎片化状态。本文的背景在于填补这一领域的空白，提出了一种统一框架EditVerse，旨在在一个单一模型中实现图像和视频的生成与编辑。通过统一表示文本、图像和视频模态，并利用自我注意机制，EditVerse实现了上下文学习的鲁棒性、跨模态知识的自然转移以及灵活处理任意分辨率和时长的输入输出。为了解决视频编辑训练数据的缺乏问题，设计了一个可扩展的数据管道，收集了232,000个视频编辑样本，与大规模的图像和视频数据集联合训练。此外，还提出了EditVerseBench，这是首个基于指令的视频编辑基准，涵盖了多种任务和分辨率。
### Innovation
提出了一种名为EditVerse的统一框架，旨在在一个单一模型中实现图像和视频的生成与编辑，通过统一表示各种模态数据、利用自我注意机制结合大规模训练数据和评测集，显著提升了视频编辑与生成的效果，特别是在数据稀缺的情况下，显示出了强大的泛化和新兴能力。
### Conclusion
EditVerse通过引入一个统一框架，在图像和视频生成与编辑任务中展现了卓越性能，优于现有的开源和商用模型，同时展示了跨模态的新兴编辑和生成能力。
## 561. `cs.CV` - Agentic Scene Policies: 统一空间、语义和操作性特征的机器人动作框架 [PDF](https://arxiv.org/pdf/2509.19571), [HTML](https://arxiv.org/abs/2509.19571)
### Authors
Sacha Morin,Kumaraditya Gupta,Mahtab Sandhu,Charlie Gauthier,Francesco Argenziano,Kirsty Ellis,Liam Paull
### Background
在机器人领域，执行开放性自然语言查询是一个核心问题。尽管最近在模仿学习和视觉-语言-动作模型（VLAs）方面的进展使得端到端政策变得很有前景，但这些模型在面对复杂的指令和新场景时表现不佳。一种替代方案是设计一个明确的场景表示，作为机器人与世界之间的查询接口，利用查询结果来引导下游的运动规划。
### Innovation
作者提出了Agentic Scene Policies（ASP）框架，利用现代场景表示的高级语义、空间和操作性查询能力，实现了一种基于语言的机器人政策。ASP能够通过显式地在复杂的技能情况下进行对象操作性推理，以零样本的方式执行开放词汇查询。
### Conclusion
通过广泛的实验，作者将ASP与VLAs在桌面操作等问题上进行了比较，并展示了ASP如何通过操作性引导导航和一个扩大的场景表示解决房间级查询。
## 562. `cs.CV` - ROPA：RGB-D双臂数据增强中的合成机器人姿态生成 [PDF](https://arxiv.org/pdf/2509.19454), [HTML](https://arxiv.org/abs/2509.19454)
### Authors
Jason Chen,I-Chun Arthur Liu,Gaurav Sukhatme,Daniel Seita
### Background
时空适配的双臂操作策略训练需要广泛的示例数据覆盖机器人姿态、接触点和场景上下文。然而，收集代表性且精确的现实世界演示数据既耗时又昂贵，阻碍了其规模化应用。在此之前的研究中，数据增强常用于手眼（腕部相机）设置中的RGB输入或者生成新的图像而不配对动作，但针对眼手（第三人称）RGB-D训练中的数据增强和动作标签尚未得到充分探索。
### Innovation
该论文提出了ROPA（合成机器人姿态生成）方法，这是一种基于离线模仿学习的数据增强方法，利用Stable Diffusion微调来合成第三人称视角的RGB和RGB-D观察到的新型机器人姿态，此方法同时生成对应的关节空间动作标签。为了确保物理一致性，通过合适的双臂场景中抓手-物体接触约束，采用约束优化方法。
### Conclusion
通过在5个模拟和3个真实任务上进行评估，ROPA方法在双臂操作中的表现优于基线和消融结果，证明了其在眼手RGB和RGB-D数据增强中的潜在应用价值，为大规模实现双臂操作提供了可能。
## 563. `cs.CV` - 基于大型视觉语言模型叙述具身情感的解剖：ELENA [PDF](https://arxiv.org/pdf/2509.19595), [HTML](https://arxiv.org/abs/2509.19595)
### Authors
Mohammad Saim,Phan Anh Duong,Cat Luong,Aniket Bhanderi,Tianyu Jiang
### Background
具身情感反应的身体部分蕴含了丰富的情感体验信息。研究者提出了一种框架，利用最新的大型视觉语言模型（LVLMs）生成具身LVLM情感叙述（ELENA）。这些叙述是明确定义且多层的文本输出，主要集中在描述情感反应中突出的身体部位。研究还展示了当代模型倾向于关注面部区域的注意图。尽管存在这一限制，但研究发现所提出的方法可以有效地在遮面图像中识别具身情感，超越了未经微调的基线。
### Innovation
提出了基于最新大型视觉语言模型生成具身LVLM情感叙述（ELENA）的框架。ELENA能够生成聚焦于情感反应中突出身体部位的多层文本输出，即便在面部被遮挡的情况下，ELENA仍表现出优于未经过微调基线模型的识别效果。
### Conclusion
ELENA开拓了具身情感分析的新途径，它在视觉模态中丰富了情感感知建模。
## 564. `cs.CV` - AJAHR: Amputated Joint Aware 3D Human Mesh Recovery [PDF](https://arxiv.org/pdf/2509.19939), [HTML](https://arxiv.org/abs/2509.19939)
### Authors
Hyunjin Cho,Giyun Choi,Jongwon Choi
### Background
现有的人体网格重建方法假设标准的人体结构，忽略了因肢体缺失等多种解剖条件而存在的多样性。这种假设在处理截肢个体时带来了偏见，进一步加剧了数据集短缺的问题，限制了模型的适用性。
### Innovation
本文提出了一种名为AJAHR的适应性姿态估计框架，旨在提高肢体缺失个体的网格重建效果。该模型整合了肢体缺失分类器，并与网格重建网络联合训练，以检测潜在的肢体缺失情况。此外，作者还引入了名为A3D的合成数据集，提供广泛的截肢姿态以供鲁棒训练。
### Conclusion
相比之下，本文的方法在非截肢个体上保持了竞争力，在截肢个体上达到了最先进的效果。更多材料可以在项目网页上获取。
## 565. `cs.CV` - C${}^2$Prompt: Class-aware Client Knowledge Interaction for Federated Continual Learning [PDF](https://arxiv.org/pdf/2509.19674), [HTML](https://arxiv.org/abs/2509.19674)
### Authors
Kunlun Xu,Yibo Feng,Jiangmeng Li,Yongsheng Qi,Jiahuan Zhou
### Background
联机联邦学习（Federated Continual Learning, FCL）旨在处理分布式客户端上连续出现任务数据的学习场景。面临的挑战是如何同时应对时间上的遗忘和空间上的遗忘。现有的基于提示的FCL方法虽然取得了不错的效果，但尚存在类别的知识一致性问题，导致新旧提示的知识冲突和混淆。
### Innovation
论文提出了一种新颖的类感知客户端知识交互方法（C${}^2$Prompt），该方法在提示通信过程中明确增强了类别的知识一致性。具体通过引入局部类别分布补偿机制（LCDC）减少跨客户端类别内的分布差异，以及设计类感知提示聚合方案（CPA）缓解跨类知识混淆。
### Conclusion
在多个FCL基准上的实验表明，C${}^2$Prompt方法能够达到最先进的性能。源代码已在相关链接处公开。
## 566. `cs.CV` - EgoBridge: 基于自我中心人类数据的可泛化模仿学习域适应方法 [PDF](https://arxiv.org/pdf/2509.19626), [HTML](https://arxiv.org/abs/2509.19626)
### Authors
Ryan Punamiya,Dhruv Patel,Patcharapong Aphiwetsa,Pranav Kuppili,Lawrence Y. Zhu,Simar Kareer,Judy Hoffman,Danfei Xu
### Background
自我中心的人类体验数据为提高机器人操作的端到端模仿学习提供了巨大的资源。然而，人类和机器人在视觉外观、传感器模式和运动学方面的显著域差距阻碍了知识的转移。现有的基线方法在通过增强的人类数据进行跨体裁模仿学习时，无法很好地适应新的对象、场景和任务。
### Innovation
本文提出了EgoBridge，这是一种统一共训练框架，通过领域适应明确对齐人类和机器人数据的策略潜空间。利用最优传输（OT）联合策略潜特征和动作之间的差异性度量，学习能够不仅在人类和机器人域之间对齐，同时也保持对于策略学习至关重要的动作相关信息的观察表示。EgoBridge在三个真实世界的单臂和双手操作任务中，相对于人类增强的跨体裁基线，显著提高了绝对策略成功率44%。此外，在人类数据中仅出现的新对象、场景和任务上，EgoBridge也能泛化，而基线方法在这些任务上完全失败。
### Conclusion
EgoBridge通过领域适应在从自我中心人类数据中学习可泛化的模仿策略方面取得了显著进展，展示了在新的对象、场景和任务上的泛化能力。
## 567. `cs.CV` - MeshMosaic：通过局部到全局组装扩展艺术家网格生成 [PDF](https://arxiv.org/pdf/2509.19995), [HTML](https://arxiv.org/abs/2509.19995)
### Authors
Rui Xu,Tianyang Xue,Qiujie Dong,Le Wan,Zhe Zhu,Peng Li,Zhiyang Dou,Cheng Lin,Shiqing Xin,Yuan Liu,Wenping Wang,Taku Komura
### Background
在自回归生成模型中，将艺术家设计的网格放大到高三角数依然具有挑战性。现有基于变压器的方法受限于长序列瓶颈和量化分辨率受限，主要由于需要大量的令牌并且受制于有限的量化粒度。这些问题阻碍了对于精细几何细节和结构密度图案的精确复制。
### Innovation
引入了MeshMosaic，这是一种新颖的局部到全局框架，用于扩展艺术家网格生成，可以扩展到超过100K的三角数。该方法首先将形状分割为补丁，通过自回归生成每个补丁并利用共享边界条件，促进相邻区域的连贯性、对称性和无缝连接。这种方法通过独立量化补丁增强了高分辨率网格的扩展性，从而实现了更加对称和有序的网格密度和结构。
### Conclusion
广泛的实验显示，MeshMosaic 在几何保真度和用户偏好方面显著优于最先进的方法，支持了对于真实应用中的网格生成的细节表示与实际应用。
## 568. `cs.CV` - TIMED：基于扩散的时序生成的对抗性和自回归细化 [PDF](https://arxiv.org/pdf/2509.19638), [HTML](https://arxiv.org/abs/2509.19638)
### Authors
MohammadReza EskandariNasab,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi
### Background
在预测和异常检测等领域中，生成高质量的合成时间序列是一项基本但具有挑战性的任务，尤其是当实际数据稀缺、噪声大或收集成本高时。与静态数据生成不同，合成时间序列需要同时建模观测的边缘分布和指导顺序动力学的条件时间依赖性。
### Innovation
我们提出了TIMED，这是一种统一的生成框架，它结合了去噪扩散概率模型（DDPM）来通过正向-反向扩散过程捕捉全局结构，使用教师强迫训练的监督网络通过预测下一步骤来学习自回归依赖性，以及一个 Wasserstein 批评家提供对抗反馈以确保时间上的平滑度和真实性。此外，TIMED结合了最大均值分散损失（MMD），以促进多样性和样本质量，所有组件都通过掩码注意架构优化并联合训练，以便有效地捕捉时间序列数据的无条件和有条件方面。
### Conclusion
在各种多变量时间序列基准上的实验结果表明，TIMED生成的序列比最先进的生成模型更具有真实性和时间上的一致性。
## 569. `cs.CV` - CHURRO: 使用开放权重大型视觉-语言模型进行高精度低成本历史文本识别以使历史文献可读 [PDF](https://arxiv.org/pdf/2509.19768), [HTML](https://arxiv.org/abs/2509.19768)
### Authors
Sina J. Semnani,Han Zhang,Xinyan He,Merve Tekgürler,Monica S. Lam
### Background
准确识别历史文件中的文本可以极大地推动文化遗产的研究和保护。现有的视觉-语言模型（VLMs）主要用于现代、标准化文本，难以识别历史文献中的多种语言和字体、不规则布局以及频繁出现的退化情况。
### Innovation
提出了一个3亿参数的开放权重视觉-语言模型CHURRO，专门用于历史文本识别。该模型是在迄今为止最大的历史文本识别数据集CHURRO-DS上进行训练的，CHURRO-DS整合了155个历史文献集合，包含99,491页，覆盖22个世纪的文本遗产，涉及46个语言群组，包括历史变体和死语言。实验结果显示，CHURRO在CHURRO-DS测试集上表现出色，手写文本的正常化Levenshtein相似度达到70.1%，比第二好的模型GEMINI 2.5 Pro分别高出6.5%和1.4%，且成本效益提高15.5倍。
### Conclusion
通过发布该模型和数据集，旨在促进社区驱动的研究，提高历史文本的可读性，加速相关研究。
## 570. `cs.CV` - 频率感知集成学习方法在2025年BraTS儿童脑肿瘤分割中的应用 [PDF](https://arxiv.org/pdf/2509.19353), [HTML](https://arxiv.org/abs/2509.19353)
### Authors
Yuxiao Yi,Qingyao Zhuang,Zhi-Qin John Xu
### Background
儿童脑瘤分割因其罕见性和异质性带来了独特的挑战，但对于临床诊断和治疗规划至关重要。现有的神经网络如nnU-Net常受限于其固定的复杂度，其他模型如Swin UNETR由于缺乏针对儿科数据集的预训练模型支持而表现不佳。
### Innovation
本文提出了一种集成方法，结合了nnU-Net、Swin UNETR和HFF-Net。引入了可调节初始规模以优化nnU-Net的复杂性控制，利用BraTS 2021预训练模型增强Swin UNETR在儿科数据集上的泛化能力，以及HFF-Net的频域分解处理低频和高频细节。
### Conclusion
最终的集成模型在2025年BraTS挑战中取得了优秀的分割结果，各部件的Dice评分如下：ET 72.3%、NET 95.6%、CC 68.9%、ED 89.5%、TC 92.3%、WT 92.3%，展示了该方法在儿童脑肿瘤分割中的有效性和优越性。
## 571. `cs.CV` - 确保跨平台的主观视频质量测试可靠参与 [PDF](https://arxiv.org/pdf/2509.20001), [HTML](https://arxiv.org/abs/2509.20001)
### Authors
Babak Naderi,Ross Cutler
### Background
主观视频质量评估（VQA）是衡量通信、流媒体和UGC管道中用户体验的黄金标准。除了高有效性的实验室研究外，众包能够提供准确、可靠、快速且成本更低的评估，但易受参与者忽略指示或游戏奖励的影响，从而导致结果不可靠。最近的研究发现，参与者利用视频元数据和远程桌面连接的趋势增加，这两种做法都可能偏倚结果。
### Innovation
该研究提出了针对远程桌面使用情况的客观和主观检测器，并在真实的测试条件下和任务设计中对比了两种主流的众包平台，评估了它们的可信赖性和缓解措施。
### Conclusion
研究在真实场景下对两种主要众包平台进行了测试，以确保参与者的可靠性和避免结果偏倚，提出的方法能够减少因远程桌面连接和视频元数据滥用带来的潜在偏倚。
## 572. `cs.CV` - 基于预测编码的深度神经网络微调以实现计算高效性域适应 [PDF](https://arxiv.org/pdf/2509.20269), [HTML](https://arxiv.org/abs/2509.20269)
### Authors
Matteo Cardoni,Sam Leroux
### Background
随着深度神经网络在动态的实际环境中部署变得越来越普遍，依赖单一静态模型往往是不够的。由于传感器漂移或光照变化引起输入数据分布的变化，需要对模型进行持续适应。
### Innovation
本文提出了一种混合训练方法，通过结合反向传播(Backpropagation)和预测编码(Predictive Coding)的优势，使得在设备上实现高效的域适应。该方法首先使用反向传播训练离线的深度神经网络以获得高水平的初始性能，然后使用预测编码实现在线适应，使模型能够恢复由于输入数据分布变化导致的性能损失。
### Conclusion
实验结果表明，这种混合策略能够在减少计算开销的情况下实现有效的适应，为在动态环境中保持模型性能提供了有前景的解决方案。这种方法特别适合资源受限的边缘设备或未来的神经形态加速器。
## 573. `cs.CV` - KSDiff: Keyframe-Augmented Speech-Aware Dual-Path Diffusion for Facial Animation [PDF](https://arxiv.org/pdf/2509.20128), [HTML](https://arxiv.org/abs/2509.20128)
### Authors
Tianle Lyu,Junchuan Zhao,Ye Wang
### Background
音频驱动的面部动画在多媒体应用中取得了显著进展，而扩散模型在说话者面部合成方面展现出强大的潜力。然而，大多数现有工作将语音特征视为单一的表示形式，并未能捕捉其在驱动不同面部运动中的细微作用，同时也忽视了建模强度动态关键帧的重要性。
### Innovation
我们提出了KSDiff，这是一种关键帧增强的语音感知双路径扩散框架（Keyframe-Augmented Speech-Aware Dual-Path Diffusion）。具体来说，原始音频和转录通过双路径语音编码器（DPSE）来分离表情相关和头部姿态相关特征，同时自回归关键帧建立学习（KEL）模块预测最显著的动作帧。这些组件被整合到双路径运动生成器中，以合成连贯且具真实感的面部运动。
### Conclusion
在HDTF和VoxCeleb上的广泛实验表明，KSDiff达到了最先进的性能，提高了口型同步准确性和头部姿态的自然度。我们的结果强调了将语音分离与关键帧感知扩散结合用于说话者面部生成的有效性。
## 574. `cs.CV` - VisualMimic: 通过运动跟踪和生成实现视觉类人移动操作 [PDF](https://arxiv.org/pdf/2509.20322), [HTML](https://arxiv.org/abs/2509.20322)
### Authors
Shaofeng Yin,Yanjie Ze,Hong-Xing Yu,C. Karen Liu,Jiajun Wu
### Background
类人在不规则环境中的移动和操作要求将主观感知与全身控制紧密结合。然而，现有方法要么依赖外部运动捕捉系统，要么无法适用于各种任务。
### Innovation
VisualMimic 提出了一种视觉仿真到现实的框架，结合了任务无关的低级关键点跟踪器与任务特定的高级策略，这两个组件联合工作以实现类人的视觉动作策略，从而在各种移动操作任务中实现零样本迁移。
### Conclusion
VisualMimic 的策略能够在仿真实验室环境中训练，并能够在真实的类人机器人上实现广泛的操作任务。此外，这些策略还能在多种户外环境中表现出强大的鲁棒性。
## 575. `cs.CV` - 基于硬件的合作式感知架构设计见解与车道变更预测的比较评估 [PDF](https://arxiv.org/pdf/2509.20218), [HTML](https://arxiv.org/abs/2509.20218)
### Authors
Mohamed Manzour,Catherine M. Elias,Omar M. Shehata,Rubén Izquierdo,Miguel Ángel Sotelo
### Background
近年来，车道变道预测的研究引起了广泛关注。目前已有的大多数研究工作主要是在仿真环境中或者使用预先录制的数据集进行，这些研究通常依赖于关于感测、通信和交通行为的简化假设，而在实际应用中这些假设往往不成立。在现实世界中部署车道变道预测系统的情况较为罕见，且这些系统遇到的具体挑战、限制和经验教训往往未被充分记录和分享。本研究通过在混合交通环境中进行实际硬件部署，旨在探索合作式车道变道预测系统，并分享实施和测试过程中获得的见解。
### Innovation
本研究通过实际硬件部署探索合作式车道变道预测系统，强调了实施过程中面临的实际挑战，包括瓶颈、可靠性问题和操作限制，这些因素影响了系统的运行行为。通过详细记录这些经验，本研究为其他正在进行类似管线项目的研究人员提供了指导。
### Conclusion
本研究提供了一种基于硬件的合作式感知架构设计见解，并通过与现有系统的比较评估，分享了车道变道预测系统的实际经验和实施挑战。
## 576. `cs.CV` - MultiSoundGen：通过缓慢快速对比视听预训练和直接偏好优化实现多事件场景的视频到音频生成 [PDF](https://arxiv.org/pdf/2509.19999), [HTML](https://arxiv.org/abs/2509.19999)
### Authors
Jianxuan Yang,Xiaoran Yang,Lipan Zhang,Xinyue Guo,Zhao Wang,Gongping Huang
### Background
当前的视频到音频（V2A）方法在处理包含多个声源、声事件或过渡的复杂多事件场景时存在困难，主要由于两大限制因素：难以精确对齐复杂的语义信息与快速动态特征；基础训练中缺乏语义时间对齐和音频质量的定量偏好优化。因此，在杂乱的多事件场景中无法提升综合生成质量。
### Innovation
提出了一种新颖的V2A框架：MultiSoundGen。引入直接偏好优化（DPO）到V2A领域，利用视听预训练（AVP）增强复杂多事件场景下的表现。两项创新是：1) SlowFast 对比视听预训练（SF-CAVP），统一双流架构的新视听预训练模型，能明确对齐视听数据的核心语义表示和快速动态特征，应对多事件复杂性；2) 将 DPO 方法结合进 V2A 任务，提出音频视频排名偏好优化（AVP-RPO），利用 SF-CAVP 作为奖励模型，量化和优先考虑关键的语义时间匹配，同时提高音频质量。
### Conclusion
实验表明，MultiSoundGen 在多事件场景中达到了最先进的性能，在分布匹配、音频质量、语义对齐和时间同步方面取得了全面改进。完整的代码和数据集即将发布。
## 577. `cs.CV` - 可查询的3D场景表示：一种多模态框架以实现语义推理和机器人任务规划 [PDF](https://arxiv.org/pdf/2509.20077), [HTML](https://arxiv.org/abs/2509.20077)
### Authors
Xun Li,Rodrigo Santa Cruz,Mingze Xi,Hu Zhang,Madhawa Perera,Ziwei Wang,Ahalya Ravendran,Brandon J. Matthews,Feng Xu,Matt Adcock,Dadong Wang,Jiajun Liu
### Background
为了使机器人能够理解高阶人类指令并执行复杂任务，关键挑战在于实现全面的场景理解：以有意义的方式解释和与3D环境交互。这需要一种智能地图，将准确的几何结构与丰富的、人类可理解的语义信息融合在一起。
### Innovation
我们提出了基于多媒体数据的3D可查询场景表示（3D QSR）的一种新颖框架，该框架结合了三种互补的3D表示：（1）来自全景重建的3D一致的新视图渲染和分割；（2）来自3D点云的精确几何结构；（3）通过3D场景图实现的有结构、可扩展的组织。该框架以对象为中心，与大型多模态视觉语言模型集成，通过链接多模态对象嵌入使场景实现语义查询，并支持几何、视觉和语义信息的基于对象级检索。检索的数据将被加载到机器人任务规划器中，以供后续执行。
### Conclusion
我们通过在Unity中的模拟机器人任务规划场景进行了评估，这些场景由抽象语言指令引导，并使用室内公共数据集Replica。此外，我们在一个真实的湿实验室环境的数字复制品中应用了该技术，以测试QSR支持的应急响应机器人任务规划。结果显示，该框架能够促进场景理解，整合空间和语义推理，有效将高阶人类指令转化为复杂的3D环境中的精确机器人任务规划。
## 578. `cs.CV` - 沿直线路径使用颜色和轮廓特征的鲁棒超像素 [PDF](https://arxiv.org/pdf/1903.07193), [HTML](https://arxiv.org/abs/1903.07193)
### Authors
Rémi Giraud,Vinh-Thong Ta,Nicolas Papadakis
### Background
超像素分解方法在计算机视觉和图像处理应用中被广泛应用。通过将具有相同或相似特性的像素分组，可以提高准确性，并且大幅减少需要处理的元素数量，从而显著减轻计算负担。大多数超像素方法都在色度一致性、图像轮廓的保真度以及分割的形状规则性之间寻求平衡。
### Innovation
本文提出了一个框架——使用直线路径的颜色和轮廓特征的鲁棒超像素（SCALP）。该框架联合约束所有的相关方面，以获得准确且规则化的具有轮廓附着力的超像素。使用颜色特征沿着像素到超像素重心的直线路径。同时引入了轮廓先验以防止将像素错误地分配到图像边界以外的超像素中。为了提高分割精度并提高对噪声的鲁棒性，融入了像素邻域信息，并保持相同的计算复杂性。
### Conclusion
SCALP在标准分割数据集上进行了广泛评估，并且获得的结果优于最先进的方法。此外还扩展适用于MRI图像中的监督体素分解。
## 579. `cs.CV` - 视频模型是零样本学习者和推理者 [PDF](https://arxiv.org/pdf/2509.20328), [HTML](https://arxiv.org/abs/2509.20328)
### Authors
Thaddäus Wiedemer,Yuxuan Li,Paul Vicol,Shixiang Shane Gu,Nick Matarese,Kevin Swersky,Been Kim,Priyank Jaini,Robert Geirhos
### Background
大型语言模型（LLMs）的出色零样本能力推动了自然语言处理从特定任务模型转变为统一的通用基础模型。这一转变源于简单的基本原理：在大规模互联网数据上训练的大规模生成模型。有趣的是，同样的基础原理也适用于当今的生成视频模型。因此，研究者提出了一个问题：视频模型是否也正朝着通用视觉理解的方向发展，就像LLMs开发出通用语言理解一样？
### Innovation
研究表明，Veo 3能够解决它未明确训练过的广泛任务，包括分割物体、检测边缘、编辑图像、理解物理属性、识别物体功能、模拟工具使用等。这些能力使Veo能够进行早期形式的视觉推理，例如迷宫和对称性解决。这表明视频模型可能正在走上成为统一的通用视觉基础模型的道路。
### Conclusion
研究展示了视频模型在未训练的情况下具备多任务处理的能力，暗示视频模型有可能成为通用的视觉基础模型。
## 580. `cs.CV` - 在视频语言模型中采用可学习检索进行长视频理解 [PDF](https://arxiv.org/pdf/2312.04931), [HTML](https://arxiv.org/abs/2312.04931)
### Authors
Jiaqi Xu,Cuiling Lan,Wenxuan Xie,Xuejin Chen,Yan Lu
### Background
大型语言模型（LLMs）在自然语言理解、推理和生成方面展现出显著的能力，因而在视频理解领域引起了研究兴趣，利用视频片段作为上下文输入。然而，对长视频的理解使用LLMs面临着巨大挑战，包括大量的视频片段会导致显著的计算成本增加，聚合视频片段会损失视觉细节，以及许多与问题无关的视频片段会干扰视频推理过程。
### Innovation
我们提出了一种简单高效的可学习检索视频语言模型（R-VLM），通过识别和选择最相关的K个视频片段及其关联的视觉令牌，用作LLMs推理的上下文，从而有效减少了视频令牌的数量，消除了噪声干扰，增强了系统性能。该模型通过引入一个可学习的轻量级MLP模块来促进问题相关片段的有效检索，通过提出的一种软匹配损失进行端到端训练。
### Conclusion
我们的实验结果表明，该框架在多个零样本视频问题回答数据集上有效，证明了其对长视频理解的有效性。
## 581. `cs.CV` - 基于块最近邻匹配的纹理超像素聚类 [PDF](https://arxiv.org/pdf/2003.04414), [HTML](https://arxiv.org/abs/2003.04414)
### Authors
Rémi Giraud,Yannick Berthoumieu
### Background
超像素在计算机视觉应用中得到了广泛应用，但现有的分解方法在根据局部纹理对图像像素进行有效聚类时仍存在问题。现有方法大多基于像素级的K-means聚类，无法高效地捕捉到纹理信息。本文旨在提出一种新的基于最近邻的超像素聚类（NNSC）方法，能够在限制计算时间内生成具备纹理感知能力的超像素，相较于现有方法表现更优。
### Innovation
提出了一种基于块最近邻匹配的新聚类框架，直接在像素块空间中对像素进行分组，以捕获纹理信息。这种方法相较于传统的基于像素级的K-means聚类方法更加高效，并且在标准色彩和纹理数据集上的分割性能表现良好，同时在计算效率方面也优于近期的纹理感知超像素方法。
### Conclusion
NNSC方法在生成纹理感知超像素方面表现得更加优秀，相比现有方法在计算时间和分割性能上有明显优势，为计算机视觉中的高效图像处理提供了新的思路。
## 582. `cs.CV` - 使用双超像素描述子的多尺度超补丁匹配 [PDF](https://arxiv.org/pdf/2003.04428), [HTML](https://arxiv.org/abs/2003.04428)
### Authors
Rémi Giraud,Merlin Boyer,Michaël Clément
### Background
超分割成超补丁是一种非常有效的维数降低策略，可以加快密集图像处理。然而，这种方法的主要问题是图像分解的内在不规则性与标准的分层多分辨率方案相比，特别是在寻找相似邻近模式时更为明显。许多工作已经尝试通过将区域不规则性纳入其比较模型来克服这一问题。然而，这些方法仍然不能提供鲁棒且准确的超像素邻域描述符，因为它们仅在其内部计算特征，这未能充分捕捉超像素边界处的轮廓信息。
### Innovation
在这项工作中，通过引入双超补丁（dual superpatch），提出了一种新颖的超像素邻域描述符。这种结构包含了在减小的超像素区域和多个超像素的交界处计算的特征，以显式捕获轮廓结构信息。还提出了一个快速的多尺度非局部匹配框架，用于在图像数据集中搜索不同分辨率级别的相似描述符。
### Conclusion
提出的双超补丁能够更准确地在不同尺度上捕获具有相似结构的模式，并通过匹配和监督标签应用展示了新策略的稳健性和性能。
## 583. `cs.CV` - 位置提示调优以实现高效的3D表示学习 [PDF](https://arxiv.org/pdf/2408.11567), [HTML](https://arxiv.org/abs/2408.11567)
### Authors
Shaochen Zhang,Zekun Qi,Runpei Dong,Xiuxiu Bai,Xing Wei
### Background
本文重新审视了点变换器方法中位置编码的作用，指出其用于聚合点云的多尺度特征。同时，通过提示和适配器的角度出发，探索了参数高效调优（PEFT），并提出了一种名为PPT的简单而有效的方法，用于点云分析。
### Innovation
该研究提出了位置提示调优（PPT）方法，该方法在训练中仅使用约1.05M参数，仍能获得多个主流数据集的最先进结果，如ScanObjectNN OBJ_BG数据集的95.01%准确率。PPT不仅能够提高特征聚合的效率，还能通过增加可训练的位置编码等元素实现参数的高效使用。
### Conclusion
本文证明了通过位置编码聚合多尺度特征对3D表示学习的重要性，并提出了PPT方法，通过参数高效调节显著提高了点云分析任务的性能。实验结果显示该方法在多个数据集上达到了最优或接近最优的效果，证明了其在实际应用中的有效性和效率。
## 584. `cs.CV` - MCPDepth：通过多圆柱全景图进行立体匹配的全方位深度估计 [PDF](https://arxiv.org/pdf/2408.01653), [HTML](https://arxiv.org/abs/2408.01653)
### Authors
Feng Qiao,Zhexiao Xiong,Xinge Zhu,Yuexin Ma,Qiumeng He,Nathan Jacobs
### Background
全方位深度估计因其在全景图像中存在的固有失真而极具挑战性。尽管已经取得了显著进展，但投影方法的影响仍未充分探索。常见的全景投影方法包括球形、圆柱形和立方体投影，而MCPDepth专注于优化圆柱形投影，提供了一套双向框架，通过立体匹配在多个圆柱形全景图上提高全方位深度估计的准确性。
### Innovation
MCPDepth引入了一种新颖的双向框架，即多圆柱全景深度估计（MCPDepth），采用了标准网络组件，能够在嵌入式设备上无缝部署，同时提供卓越的性能。MCPDepth通过圆柱形关注模块有效地解决了圆柱形全景图中的垂直失真问题，显著扩展了感受野。实验研究表明，与球形和立方体投影相比，MCPDepth在户外数据集Deep360和真实数据集3D60上的平均绝对误差（MAE）分别降低了18.8%和19.9%。
### Conclusion
MCPDepth通过多圆柱全景图实现的全方位立体匹配提供了前所未有的深度估计方法，为其他任务和现实世界应用提供了实用见解，初步建立了全方位深度估计的新范式。
## 585. `cs.CV` - 优化的PatchMatch用于多尺度和多特征标签融合 [PDF](https://arxiv.org/pdf/1903.07165), [HTML](https://arxiv.org/abs/1903.07165)
### Authors
Rémi Giraud,Vinh-Thong Ta,Nicolas Papadakis,José V. Manjón,D. Louis Collins,Pierrick Coupé,Alzheimer's Disease Neuroimaging Initiative
### Background
自动分割方法是定量分析磁共振图像（MRI）的重要工具。近年来，基于块的标签融合方法已经显示了最先进的分割精度。本文介绍了一种新的基于块的标签融合框架，用于解剖结构分割。这种方法采用了一种优化的PatchMatch标签融合（OPAL）策略，极大地减少了寻找相似块所需的计算时间。OPAL的计算时间减少为新策略打开了可能性，同时也便于处理大规模数据库。
### Innovation
文章提出的OPAL策略，通过降低寻找相似块的计算时间，提出了一种新的多尺度和多特征的标签融合框架，这种方法在海马体分割验证中，与最先进的方法相比，获得了最高的中位Dice系数（ICBM为89.9%，EADC-ADNI为90.1%），并且其分割精度与专家之间的差异相似。此外，在EADC-ADNI数据集中，自动分割的海马体体积与手动分割高度相关，使得能够更准确地区分病理学人群。
### Conclusion
本文提出的方法在海马体分割的任务上表现出色，其分割精度和手动分割的准确性相似，并且能够促进更准确地分离病理学人群的分类。
## 586. `cs.CV` - Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion [PDF](https://arxiv.org/pdf/2410.13674), [HTML](https://arxiv.org/abs/2410.13674)
### Authors
Yijun Liang,Shweta Bhardwaj,Tianyi Zhou
### Background
低质量或稀缺的数据为训练深度神经网络带来了重大挑战。尽管经典的图像增强方法不能显著提供新数据，但通过文本指导生成高质量和多样化的合成数据的扩散模型为构建自我进化的AI打开了新的大门。然而，仅通过文本指导生成的图像可能与原始图像相距甚远，从而导致模型性能受损的离分布数据。为克服这一限制，该研究探讨了图像指导，使合成图像与真实图像之间的插值范围更加广泛。通过调整图像合成过程中的图像指导强度，可以改进模型难以学习的样本。
### Innovation
提出了一种新型的“扩散课程 (DisCL)”方法，该方法根据训练阶段调整图像合成过程中的图像指导强度，识别并专注于难以学习的样本，并评估合成图像的最佳指导水平以改善难以学习的数据。该方法应用于两个挑战性任务：长尾（LT）分类和从低质量数据学习，通过逐步从指导较低的高质图像学习，过渡到指导较高的低多样性和质量的图像，为模型提供了一种自适应学习策略。
### Conclusion
在广泛实验中，使用DisCL时，iWildCam数据集的ODD和ID宏精度分别提高了2.7%和2.1%。在ImageNet-LT上，DisCL将底层类别的准确性从4.4%提高到23.64%，并将整体准确性提高了4.02%。
## 587. `cs.CV` - Lagrangian Motion Fields for Long-term Motion Generation [PDF](https://arxiv.org/pdf/2409.01522), [HTML](https://arxiv.org/abs/2409.01522)
### Authors
Yifei Yang,Zikai Huang,Chenshu Xu,Shengfeng He
### Background
长期内在动作生成是一个极具挑战的任务，需生成连贯且逼真的长时间序列。现有的方法主要依赖帧内的动作表示，仅捕捉静态的时空细节，忽略时间动态。这导致了在时间维度上的冗余，使得生成有效的长期动作变得复杂。因此，需要一种新的方法来克服这一局限性，即引入拉格朗日动作场（Lagrangian Motion Fields），以处理长时间内的动作生成问题。该方法将每个关节视为一个特征速度均匀的拉格朗日粒子，在短时间内，从而将动作表示压缩成一系列“超动作”（类似于超像素），这种方法将静态的空间信息与可解释的时间动态无缝集成，优于现有网络架构和动作序列内容类型。这种方法在长期内在音乐到舞蹈生成和文本到动作生成等任务上表现出色，提供了更高的效率、更高质量的生成结果以及更大的多样性，同时在无限动作循环和细微控制动作生成等方面表现出高度的适应性，突显了其广泛的实用性。视频演示可通过提供的链接查阅。
### Innovation
该论文提出了一种名为拉格朗日动作场的新方法，它将每个关节视为在短时间间隔内具有均匀速度的拉格朗日粒子，从而将动作表示压缩成一系列“超动作”。这种方法成功地将静态的空间信息与可解释的时间动态无缝集成，解决了现有方法在时间和动作生成上的限制。这种方法适用于包括长期内在音乐到舞蹈生成和文本到动作生成等各种任务，提供了更高的效率和质量、更多的多样性，同时具有很强的适应性，适用于无限动作循环和细微控制动作生成等领域。
### Conclusion
拉格朗日动作场方法在长期内部动作生成方面表现出显著的优势，不仅提供更高的效率和更丰富的多样性，而且通过将静态的空间信息与可解释的时间动态无缝集成，克服了现有方法的限制。该方法具有广泛的应用潜力，特别是在无限动作循环和细腻的控制动作生成方面具备很强的适应性。
## 588. `cs.CV` - DreamMix: 解耦对象属性以增强定制化图像修复的可编辑性 [PDF](https://arxiv.org/pdf/2411.17223), [HTML](https://arxiv.org/abs/2411.17223)
### Authors
Yicheng Yang,Pengxiang Li,Lu Zhang,Liqian Ma,Ping Hu,Siyu Du,Yunzhi Zhuge,Xu Jia,Huchuan Lu
### Background
随着扩散模型的快速发展，主题导向的图像修复已日益受到图像编辑领域的关注。以往的研究尝试通过文本指导来进行保持身份特色同时局部可编辑的对象修复，但这些方法仍然存在身份过拟合的问题，即原始属性与目标文本指令混合在一起。为了克服这一局限，我们提出了一种基于扩散的框架DreamMix，该框架能够将目标对象插入用户指定区域，同时允许任意文本驱动的属性修改。
### Innovation
DreamMix引入了三个关键模块：（i）一种属性解耦机制（ADM），生成多种属性增强的图像-文本对，以减少过拟合；（ii）一种文本属性替代（TAS）模块，通过正交分解隔离目标属性；（iii）一种解耦的修复框架（DIF），分离局部生成和全局协调。
### Conclusion
在多个修复框架上的广泛实验表明，DreamMix能够在不同的应用场景中，如对象插入、属性编辑和小型对象修复中，实现身份保护和属性可编辑性的最佳平衡。
## 589. `cs.CV` - 从慢双向往快自回归视频扩散模型 [PDF](https://arxiv.org/pdf/2412.07772), [HTML](https://arxiv.org/abs/2412.07772)
### Authors
Tianwei Yin,Qiang Zhang,Richard Zhang,William T. Freeman,Fredo Durand,Eli Shechtman,Xun Huang
### Background
当前的视频扩散模型在生成质量上表现出色，但在交互式应用中却存在问题，因为它们依赖于双向注意力依赖关系。生成每一帧时，模型必须处理整个序列，包括未来的帧。
### Innovation
本文通过将预训练的双向扩散转换器适应为自回归转换器，解决了这个问题；自回归转换器可以在生成时实时生成帧，减少了延迟。此外，该研究将分布匹配蒸馏（DMD）扩展到了视频领域，将50步扩散模型蒸馏为4步生成器。研究还引入了一种基于教师ODE轨迹的学生初始化方案和一种不对称蒸馏策略，监督因果学生模型与双向教师模型，有效缓解了自回归生成中的误差累积，从而使长时视频合成成为可能，尽管是在短片段上进行训练。
### Conclusion
该模型在VBench-Long基准测试中得分84.27，超越了所有之前的视频生成模型，并使单GPU上以9.4 FPS快速生成高质量视频成为可能。此外，该方法还使视频到视频的流式转换、图像到视频的生成以及零样本动态提示成为可能。
## 590. `cs.CV` - CLIP Can Understand Depth [PDF](https://arxiv.org/pdf/2402.03251), [HTML](https://arxiv.org/abs/2402.03251)
### Authors
Sohee Kim,Jisu Kang,Dunam Kim,Seokju Lee
### Background
本文探讨了如何在CLIP（Contrastive Language-Image Pre-training）已经在网络爬取的数据上预训练且其视图-语言对齐效果不佳的情况下，将CLIP适应于下游任务。具体来说，研究者关注的是单目深度估计任务，CLIP在其对比优势在这一任务上表现欠佳，然而在生成建模和语义分割等其他领域表现良好。由于CLIP在捕捉图像补丁和描述距离的自然语言提示之间的相似性上表现不佳，研究者提出了一种新的方法，即通过移除预训练的语言嵌入并提炼冻结的文本编码器的语义先验，将其总结为一个可学习的嵌入矩阵“mirror”（镜子），用于密集深度预测，以此来纠正CLIP在空间和时间一致性上的深度理解不足问题。这一方法旨在获得一个非自然语言的提示，近似于最优的自然语言提示‘这个位置距离相机有多远？’
### Innovation
本文的创新在于开发了一种新的方法来解决视图-语言对齐不佳的CLIP在单目深度估计任务中的不足，通过去除CLIP的预训练语言嵌入，并将冻结的文本编码器的语义先验提炼为一个可学习的嵌入矩阵“mirror”，用于与冻结的CLIP一起进行深度预测的训练。不同于传统的深度模型，该框架在参数量和计算上更为高效，且在NYU Depth v2和KITTI基准数据集上取得了与最先进的视觉模型相当甚至更好的性能，且超越了所有基于冻结CLIP先验的视觉语言深度模型。进一步的实验证明，通过镜像模型的隐式训练，可以显著纠正CLIP在空间和时间一致性上的深度理解不足问题，无需微调或拼接预训练子词嵌入，同时证明了通过镜像模型捕捉物体（如人和窗户）的重要性，因为它们在检测中起到了关键作用。
### Conclusion
本文提出的方法在参数量和计算效率上显著优于传统深度模型，且在多个基准数据集上取得了接近甚至超过最先进视觉模型的性能。研究结果表明，对于表现出视图-语言对齐不佳的CLIP，通过这种方法可以在不进行微调或拼接的条件下，显著提升其在单目深度估计任务上的性能。此外，通过镜像模型的隐式训练，能够更好地捕捉在检测中起到重要作用的物体特征，从而改善CLIP在空间和时间一致性的深度理解。
## 591. `cs.CV` - SpaRC: 稀疏雷达-摄像头融合用于3D物体检测 [PDF](https://arxiv.org/pdf/2411.19860), [HTML](https://arxiv.org/abs/2411.19860)
### Authors
Philipp Wolters,Johannes Gilg,Torben Teepe,Fabian Herzog,Felix Fent,Gerhard Rigoll
### Background
多视图图像语义、雷达和相机点特征的融合对自主驾驶系统的高效感知范式至关重要。传统的做法是使用密集的鸟类视图（BEV）架构进行深度估计，而现代基于查询的Transformer则在仅通过对象中心化的方法进行相机检测方面表现出色。然而，这些基于查询的方法在假阳性检测和定位精度方面存在局限性，主要是由于隐式的深度建模。本文通过稀疏棱镜融合（SFF）、范围自适应雷达聚合（RAR）以及局部自我关注（LSA）解决了这些问题。
### Innovation
文章的主要创新点在于提出了SpaRC，这是一种新颖的稀疏融合Transformer，可以将雷达和摄像头数据进行融合，适用于3D感知任务。相较于现有的方法，SpaRC不需要密集的BEV网格渲染，直接操作编码的点特征，从而大大提高效率和准确性。具体创新点包括：(1)稀疏棱镜融合（SFF）用于跨模态特征对齐；(2)范围自适应雷达聚合（RAR）用于精确的物体定位；(3)局部自我关注（LSA）用于集中查询聚合。
### Conclusion
研究结果表明，SpaRC在nuScenes和TruckScenes基准测试中的性能显著优于现有的密集BEV和稀疏查询检测器，达到了67.1 NDS和63.1 AMOTA的最佳性能指标。相关代码和预训练模型可以在提供的链接中获取。
## 592. `cs.CV` - 视觉自监督学习中判别模型对抗鲁棒性的研究 [PDF](https://arxiv.org/pdf/2503.06361), [HTML](https://arxiv.org/abs/2503.06361)
### Authors
Ömer Veysel Çağatan,Ömer Faruk Tal,M. Emre Gürsoy
### Background
自监督学习（SSL）在视觉表示学习方面取得了显著进展，但其对抗鲁棒性的全面评估依然有限。本研究评估了七种判别自监督模型和一种监督模型在多种任务中的对抗鲁棒性，包括ImageNet分类、迁移学习、分割和检测。
### Innovation
研究发现判别SSL模型在ImageNet上的对抗鲁棒性通常优于监督模型，并且在使用线性评估进行迁移学习时这一优势仍然存在。然而，当应用微调时，SSL模型和监督模型之间的对抗鲁棒性差距显著缩小，并且这种优势在分割和检测任务中也不复存在。此外，研究还探讨了各种因素（如架构选择、训练时长、数据增强和批量大小）如何影响对抗鲁棒性。
### Conclusion
本分析为视觉自监督表示系统的对抗鲁棒性持续探索做出了贡献。
## 593. `cs.CV` - GaussianSeal: 根植于3D高斯生成模型的自适应水印 [PDF](https://arxiv.org/pdf/2503.00531), [HTML](https://arxiv.org/abs/2503.00531)
### Authors
Runyi Li,Xuanyu Zhang,Chuhan Tong,Zhipei Xu,Jian Zhang
### Background
随着AIGC技术的进步，模型生成的模态从图像和视频扩展到3D物体，导致越来越多的研究聚焦于3D高斯点积模型（3DGS）。现有研究主要集中在图像和文本模态中的版权保护水印，对3D物体生成模型的版权保护探索较少。基于此背景，本文旨在提出第一个适用于3DGS生成模型的位级水印框架——GaussianSeal，以便从渲染的3DGS生成输出中解码位作为版权标识符。
### Innovation
本文创新地提出了GaussianSeal框架，该框架通过在生成模型中引入自适应位调制模块，并以自适应方式嵌入网络块中，实现了高精度的位解码，同时保持模型输出的保真度，且在训练开销最小的情况下完成。实验结果表明，该方法在3DGS对象中的水印解码准确性方面优于后期处理水印方法，并且能够保持生成结果的质量。
### Conclusion
通过GaussianSeal框架，本文实现了3DGS生成模型中的自适应位水印嵌入和解码，显著提高了水印解码精度，并且能够有效保持生成结果的质量。
## 594. `cs.CV` - SMLNet: SPD曼ifold学习网络用于红外和可见光图像融合 [PDF](https://arxiv.org/pdf/2411.10679), [HTML](https://arxiv.org/abs/2411.10679)
### Authors
Huan Kang,Hui Li,Tianyang Xu,Xiao-Jun Wu,Rui Wang,Chunyang Cheng,Josef Kittler
### Background
欧几里得表示学习方法在图像融合任务中取得了显著成果，这得益于它们在处理线性空间中的明显优势。然而，现实场景中收集的数据通常具有非欧几里得结构，使用欧几里得距离评估配对视图的潜在表示一致性存在挑战。为解决这一问题，提出了一种新型的SPD（对称正定）流形学习方法，名为SMLNet，将图像融合方法从欧几里得空间扩展到了SPD流形上。具体而言，通过遵循黎曼几何编码图像，以利用其内在的统计关联，从而与人类视觉感知相一致。SPD矩阵构成了网络学习过程的基础。在这种数学基础上，采用跨模态融合策略，利用模态特定的依赖关系和补充信息。为捕捉图像内在空间的语义相似性，进一步开发了注意力模块，对跨模态语义亲和矩阵进行精细处理。基于此，根据跨模态流形学习设计了一整套融合网络。大量公共数据集的实验表明，我们的框架在性能上优于当前最先进的方法。我们将在该链接处公开代码：this https URL
### Innovation
提出了一种基于SPD流形学习的跨模态图像融合网络（SMLNet），该网络通过黎曼几何编码图像以利用其内在的统计关联，从而与人类视觉感知相一致。利用跨模态融合策略，捕获图像内在空间的语义相似性，并开发了处理跨模态语义亲和矩阵的注意力模块。这些方法将图像融合从欧几里得空间扩展到了SPD流形上，提供了处理非欧几里得结构数据的新途径。
### Conclusion
在公共数据集上的广泛实验表明，SMLNet框架在红外和可见光图像融合任务中显著优于当前最先进的方法。
## 595. `cs.CV` - 基于无参考图像质量评估的跨域水下图像增强：一种迁移学习方法 [PDF](https://arxiv.org/pdf/2503.17937), [HTML](https://arxiv.org/abs/2503.17937)
### Authors
Zhi Zhang,Minfu Li,Lu Li,Daoyi Chen
### Background
单水下图像增强（UIE）是一个具有挑战性的不适定问题。其发展受到两个主要问题的阻碍：(1) 水下参考数据集中的标签是伪标签，基于这些伪地真信息的监督学习会导致领域差异。 (2) 水下参考数据集稀缺，导致在如此小的数据集上训练容易出现过拟合和分布偏移问题
### Innovation
我们提出了一种基于迁移学习的UIE模型Trans-UIE，通过预训练捕获UIE的基本理念，并利用参考和非参考数据集的组合进行微调。此外，为了解决仅使用重建损失可能导致的确认偏差问题，我们的方法利用了非参考图像质量评估（NR-IQA）指标来指导跨域的迁移学习过程，同时生成具有水面上图像域风格的增强图像。此外，在预训练阶段引入皮尔逊相关损失以降低过拟合风险
### Conclusion
在全参考和无参考水下基准数据集上的实验结果表明，Trans-UIE 显著优于现有的方法
## 596. `cs.CV` - Egocentric 视觉：挑战与趋势综述 [PDF](https://arxiv.org/pdf/2503.15275), [HTML](https://arxiv.org/abs/2503.15275)
### Authors
Xiang Li,Heqian Qiu,Lanxiao Wang,Hanwen Zhang,Chenghao Qi,Linfeng Han,Huiyu Xiong,Hongliang Li
### Background
随着人工智能技术和可穿戴设备的快速发展，自我中心视觉理解作为一个新的且具有挑战性的研究方向逐渐受到学术界和工业界的广泛关注。自我中心视觉通过穿戴在人体上的相机或传感器捕获视觉和其他多模态数据，可以模拟人的视觉体验。
### Innovation
本文提供了一篇全面的综述，系统地分析了自我中心场景的组成部分，并将任务分类为四大部分：主体理解、物体理解、环境理解和混合理解。详细探讨了每个类别中的子任务，总结了当前领域存在的主要挑战和趋势，并概述了高质量的自我中心视觉数据集供未来研究利用。
### Conclusion
总结了最新的进展，预测了自我中心视觉技术在增强现实、虚拟现实和体素智能等领域的广泛应用，并基于最新的发展提出了未来的研究方向。
## 597. `cs.CV` - 基于稳健计算机视觉的建筑工地检测技术在辅助技术应用中的研究 [PDF](https://arxiv.org/pdf/2503.04139), [HTML](https://arxiv.org/abs/2503.04139)
### Authors
Junchi Feng,Giles Hamilton-Fletcher,Nikhil Ballem,Michael Batavia,Yifei Wang,Jiuling Zhong,Maurizio Porfiri,John-Ross Rizzo
### Background
对于盲人或低视力者而言，在受到建筑施工影响的城市环境中导航是一项重大挑战。施工区域引入了诸如不平的地面、障碍物、有害物质、噪声以及改变的路线等危险因素，这些因素会阻碍熟悉路径并影响安全性。尽管导航工具可以帮助规划行程，但它们通常忽视这些临时障碍。现有的危险检测系统也难以应对建筑工地的视觉多变性。因此，开发一种能够提供实时警示的辅助系统，以帮助视障人士安全地做出移动决策，显得尤为重要。
### Innovation
本文开发了一种基于计算机视觉的辅助系统，包含三个模块：一个开放式词汇物体检测器，用于识别各种与建筑有关的元素；一个YOLO优化模型，专门用于检测脚手架和电线杆；以及一个光学字符识别模块，用于解读工地标志。该系统能够在多种静止视角下对七个建筑工地进行测试，实现了88.56%的整体准确率，在2-10米和最大75°接近角内稳定识别相关物体。此外，在0.5英里包含八个建筑工地的动态测试中，系统在分析每一个第一人称行走视频帧时，准确率达到了87.26%，并通过50帧多数投票滤波器后，该准确率提高到92.0%。这些模块共同提高了系统在视觉多变的建筑工地环境中的检测能力，提供了一种有效的实现实时预警的方法。
### Conclusion
该系统能够在实时环境中检测建筑工地，并在足够远的距离上提供即时警告，从而帮助视障人士安全做出移动决策，如谨慎继续或改道。
## 598. `cs.CV` - LEDiT: 无需位置编码的长度外推扩散变换器 [PDF](https://arxiv.org/pdf/2503.04344), [HTML](https://arxiv.org/abs/2503.04344)
### Authors
Shen Zhang,Siyuan Liang,Yaning Tan,Zhaowei Chen,Linze Li,Ge Wu,Yuhao Chen,Shuheng Li,Zhenyu Zhao,Caihua Chen,Jiajun Liang,Yao Tang
### Background
扩散变换器（DiTs）在生成高分辨率图像时存在困难，主要障碍在于其在训练时不进行外推的显式位置编码（PE），如RoPE，在推理分辨率与训练分辨率不一致时会导致性能下降。
### Innovation
LEDiT 提出了一个无需显式位置编码的长度外推扩散变换器，通过引入因果注意力机制来隐式地编码全局位置信息，解决了高分辨率图像生成的挑战。此外，LEDiT 还引入了一个局部增强模块，以捕获细化的局部信息补充由因果注意力编码的粗粒度全局位置信息。
### Conclusion
LEDiT 实验结果显示其支持最高4倍的分辨率缩放（例如：从256x256到512x512），与最先进的长度外推方法相比，图像质量更高。我们认为LEDiT 在于它从标准的RoPE方法中取得了突破，为长度外推提供了一种有前景的新视角。
## 599. `cs.CV` - SafeEraser：通过多模态机器遗忘提高多模态大型语言模型的安全性 [PDF](https://arxiv.org/pdf/2502.12520), [HTML](https://arxiv.org/abs/2502.12520)
### Authors
Junkai Chen,Zhijie Deng,Kening Zheng,Yibo Yan,Shuliang Liu,PeiJun Wu,Peijie Jiang,Jia Liu,Xuming Hu
### Background
随着多模态大型语言模型（MLLMs）的发展，它们的安全问题日益凸显。虽然机器遗忘（MU）作为一种有效策略被广泛应用于隐私保护，但在MLLM的安全性方面，MU的研究仍然不足。为此，我们提出了一个名为SAFEERASER的安全遗忘基准，包含3000张图片和28800个视觉问答（VQA）对，旨在从遗忘质量和模型实用性两个角度全面评估遗忘方法。研究发现，现有MU方法难以在遗忘操作时维持模型性能，且过于遗忘问题频发。基于此，我们引入了Prompt Decouple（PD）损失以通过学习过程中解耦prompt来缓解过度遗忘。为量化PD损失缓解过度遗忘的效果，我们提出了一种新的度量标准Safe Answer Refusal Rate (SARR)。实验证明，在现有遗忘方法中结合PD损失能够有效防止过度遗忘，同时保持遗忘质量和模型实用性。
### Innovation
我们提出了一个名为SAFEERASER的安全遗忘基准，包含丰富的多模态数据，并在学习过程中引入了Prompt Decouple（PD）损失来缓解过度遗忘。此外，我们还提出了一种新的度量标准Safe Answer Refusal Rate (SARR)来衡量PD损失的效果，并通过实验证明其有效性。
### Conclusion
通过SAFEERASER基准和结合PD损失的方法，我们可以有效地缓解MLLMs中的过度遗忘问题，同时保持模型的性能和实用性。我们将在论文被接受后发布相关代码和数据集。
## 600. `cs.CV` - 多模态参考视觉定位 [PDF](https://arxiv.org/pdf/2504.02876), [HTML](https://arxiv.org/abs/2504.02876)
### Authors
Yangxiao Lu,Ruosen Li,Liqiang Jing,Jikai Wang,Xinya Du,Yunhui Guo,Nicholas Ruozzi,Yu Xiang
### Background
视觉定位旨在基于语言表达从图像中检测出对象。近年来，大规模视觉-语言模型（LVLMs）通过使用大规模数据集训练大规模模型，显著提升了视觉定位的表现。然而，当输入图像中出现相似对象时，问题仍然具有挑战性。例如，LVLM可能无法区分图像中的Diet Coke和regular Coke。在这种情况下，如果能够提供Diet Coke和regular Coke的参考图像，则有助于识别相似对象。本文针对该问题引入了一个新的任务：多模态参考视觉接地（MRVG）。
### Innovation
本文引入了一个新的任务——多模态参考视觉接地（MRVG），其中模型可以访问数据库中对象的参考图像集。基于这些参考图像和语言表达，模型需要从查询图像中检测目标对象。提出了一个新型方法MRVG-Net来解决该视觉定位问题。通过使用参考图像进行少样本检测和大规模语言模型（LLMs）进行对象匹配，该方法在视觉定位性能上显著优于最先进的LVLMs，如Qwen2.5-VL-72B。这种方法将少样本检测与视觉定位结合，为视觉理解开辟了新的能力，具有广泛的应用前景，特别是在机器人技术方面。
### Conclusion
通过结合少样本检测和大规模语言模型的使用，本文提出的方法在视觉接地任务上达到了最先进的性能，具有广泛的应用潜力。
## 601. `cs.CV` - 基于伪标签引导全局变换的无监督跨域3D人体姿态估计 [PDF](https://arxiv.org/pdf/2504.12699), [HTML](https://arxiv.org/abs/2504.12699)
### Authors
Jingjing Liu,Zhiyong Wang,Xinyu Fan,Amirhossein Dadashzadeh,Honghai Liu,Majid Mirmehdi
### Background
现有的3D人体姿态估计方法在跨场景推断时常常表现不佳，因为不同场景中的摄像机视角、位置、姿态和身体尺寸存在差异，导致领域间的差距增大。特别是在摄像机视角和位置上，这些因素显著影响了人体姿态的全局位置，从而降低了模型的表现。
### Innovation
该研究提出了一种新的框架，该框架在源域和目标域的摄像机坐标系统之间显式地进行姿态位置的全局变换。首先，采用伪标签生成模块对目标数据集的2D姿态生成伪3D姿态；其次，利用以人为中心的坐标系统作为新的桥梁机制，实现不同领域姿态位置的一致对齐；最后，引入姿态增强模块以应对人体姿态和身体尺寸的变化。这个过程是迭代的，逐步提升领域自适应的指导作用。该方法在多个跨数据集基准上进行了评估，显示出优于现有方法的效果，甚至在某些情况下超过了目标训练模型的表现。
### Conclusion
该研究提出的方法在跨域3D人体姿态估计中取得了显著效果，通过伪标签引导的全局变换成功地解决了摄像机视角和位置等带来的域差距问题，进一步增强了模型的泛化能力。
## 602. `cs.CV` - 朝着多模态大语言模型中的视觉文本 grounding 方向 [PDF](https://arxiv.org/pdf/2504.04974), [HTML](https://arxiv.org/abs/2504.04974)
### Authors
Ming Li,Ruiyi Zhang,Jian Chen,Chenguang Wang,Jiuxiang Gu,Yufan Zhou,Franck Dernoncourt,Wanrong Zhu,Tianyi Zhou,Tong Sun
### Background
尽管现有的多模态大语言模型（MLLMs）在视觉文本定位方面取得了进展，但在处理文档图像中的视觉文本 grounding 问题上仍存在显著限制，尤其是在包含丰富文本内容的文档图像中。当前的基准测试主要集中在自然图像上的视觉 grounding，而忽视了文档图像的复杂布局和文字内容。因此，有必要设计新的任务和数据集来评估和提升 MLLMs 在文档图像上的文本-rich 图像 grounding 能力，以应对这个挑战.
### Innovation
引入了 TRIG 任务，设计了一个新的指令数据集，用于评估和改进 MLLMs 在文档图像中的文本-rich 图像 grounding 能力。提出了一个 OCR-LLM-人工交互的闭环管道和基于四个不同数据集的 90,000 条合成数据集，从而可以全面评估 MLLMs 的 grounding 能力，包括文本-rich 图像。此外，提出了两种简单有效的 TRIG 方法，分别基于通用指令调优和插即用高效嵌入，通过在合成数据集上微调 MLLMs 而提升其空间推理和 grounding 能力.
### Conclusion
通过对合成数据集进行 MLLMs 微调，展示了显著改进的空间推理和 grounding 能力，这表明 TRIG 方法在提升 MLLMs 在文档图像上的视觉文本 grounding 方面的有效性。
## 603. `cs.CV` - ChartQA-X: 生成视觉图表推理的解释 [PDF](https://arxiv.org/pdf/2504.13275), [HTML](https://arxiv.org/abs/2504.13275)
### Authors
Shamanthak Hegde,Pooyan Fazli,Hasti Seifi
### Background
有效的数据驱动决策需要能够解释复杂图表信息的能力。本文针对在回答图表问题的同时生成详细解释的问题进行研究。
### Innovation
本文提出了一种名为ChartQA-X的综合数据集，包含30,299个图表样本及其对应的4种图表类型、相关的问题、答案和基于可信度、信息性、连贯性和困惑度等指标生成的解释。此外，基于ChartQA-X进行微调的模型在多种指标上取得了显著进步，特别是在解释质量、问题回答准确性和在未见过的基准测试上。通过结合解释性叙述与答案，该方法提高了传达复杂视觉信息的能力，增强了对生成响应的信任。
### Conclusion
实验表明，由模型生成的解释在准确性、逻辑性、清晰性和整体质量方面超过了人工写的解释，并且针对ChartQA-X进行微调的模型在各项指标上都取得了显著改进。
## 604. `cs.CV` - 重访残差连接：稳定高效的正交更新对于深层网络 [PDF](https://arxiv.org/pdf/2505.11881), [HTML](https://arxiv.org/abs/2505.11881)
### Authors
Giyeong Oh,Woohyun Cho,Siyeol Kim,Suhwan Choi,Younjae Yu
### Background
残差连接对于深度神经网络至关重要，它们通过缓解梯度消失问题促进了网络更深的发展。然而，在标准的残差更新中，模块的输出直接加到输入流上，这可能导致更新主要加强或调整现有流的方向，从而可能未能充分利用模块学习全新特征的能力。
### Innovation
作者引入了正交残差更新，它通过分解模块输出相对于输入流的部分，并只添加正交部分，以引导模块主要贡献新的表示方向，从而促进更丰富的特征学习并提高训练效率。这种方法已经在多种架构（ResNetV2, Vision Transformers）和数据集（CIFARs, TinyImageNet, ImageNet-1k）上进行了验证，展示了其改善了泛化准确性和训练稳定性，并在某些情况下还提高了性能，例如在ImageNet-1k上ViT-B模型的任务中获得了4.3%的top-1准确率提升
### Conclusion
正交残差更新策略提升了不同架构和数据集上的泛化准确性和训练稳定性，特别是在ImageNet-1k数据集上的ViT-B模型中取得了显著的性能提升。
## 605. `cs.CV` - Redemption Score: 通过分布、感知及语言信号三角融合的多模态图片题图评估框架 [PDF](https://arxiv.org/pdf/2505.16180), [HTML](https://arxiv.org/abs/2505.16180)
### Authors
Ashim Dahal,Ankit Ghimire,Saydul Akbar Murad,Nick Rahimi
### Background
评估图片描述需要综合评价视觉语义和语言语用的连贯性，而大多数现有指标往往未能完全捕捉到这一点。该研究引入了一种新颖的混合框架Redemption Score（RS），通过三角融合三种互补信号对图片描述进行排名：1）Mutual Information Divergence（MID），用于图像与文本全局分布对齐；2）通过DINO生成的循环图像的感知相似性，实现视觉定位；3）大语言模型（LLM）文本嵌入，与人类参考的上下文文本相似性对比。
### Innovation
RS框架通过融合三种信号提供一个更加全面的评估，分别是从全局图像-文本分布对齐、从视觉角度进行对齐以及在语境下与人类引用的文本相似性。在Flickr8k基准测试中，与大多数早期方法相比，RS表现出色，获得了Kendall-$tau$ 58.42的结果，且不需要特定任务的训练便能达到更高的与人类判断的正相关系数，展示了其实质性进步。
### Conclusion
该框架不仅提供了一种更为稳健且细腻的评估方式，还通过全面检查视觉准确性和文本质量，展示了在Conceptual Captions和MS COCO数据集上的持续性能。
## 606. `cs.CV` - Ctrl-Room: Controllable Text-to-3D Room Meshes Generation with Layout Constraints [PDF](https://arxiv.org/pdf/2310.03602), [HTML](https://arxiv.org/abs/2310.03602)
### Authors
Chuan Fang,Yuan Dong,Kunming Luo,Xiaotao Hu,Rakesh Shrestha,Ping Tan
### Background
3D室内场景生成对于游戏、电影行业以及AR/VR应用有价值，但现有方法难以真实地捕捉房间布局，也无法灵活编辑房间中的个别物体。
### Innovation
提出了一种名为Ctrl-Room的方法，可以从文本提示生成具有设计师风格布局和高保真度纹理的逼真3D房间。该方法将布局建模和外观建模分离，并分别通过文本条件扩散模型和细调的ControlNet实现了这一目标，还引入了通过掩码引导的编辑模块进行无障碍的编辑。
### Conclusion
通过大量实验，证明该方法在从自然语言提示生成更合理、视角一致且易于编辑的3D房间方面优于现有方法。
## 607. `cs.CV` - 无需回放的动态记忆连续低秩适应 [PDF](https://arxiv.org/pdf/2411.00623), [HTML](https://arxiv.org/abs/2411.00623)
### Authors
Huancheng Chen,Jingtao Li,Weiming Zhuang,Chen Chen,Lingjuan Lyu
### Background
我们重新审视了连续学习CL，使其能够使预训练的视觉转换器（ViTs）在时间上顺序地对新的下游任务进行微调。然而，随着模型规模的扩大，灾难性遗忘成为更大的挑战。最近的研究揭示了CL技术和参数高效微调（PEFT）之间的交叉，PEFT关注的是仅针对下游任务微调小型参数集。例如，低秩适应（LoRA）。尽管LoRA实现了更快的收敛速度并且需要的可微调参数更少，但它在连续学习的背景下很少被探索。为了填补这一空白，我们提出了一种新的PEFT-CL方法——双重低秩适应（DualLoRA），该方法在每个层中引入了一个正交LoRA适配器和一个残差LoRA适配器，并与预训练权重并行。通过动态记忆机制协调这些组件，以平衡稳定性和灵活性。此外，我们提出了一种预测任务身份并相应校准模型输出的方案。
### Innovation
我们提出了一种新颖的PEFT-CL方法——双重低秩适应（DualLoRA），该方法在每个层中引入了一个正交LoRA适配器和一个残差LoRA适配器，并与预训练权重并行。这些组件通过动态记忆机制协调，以平衡稳定性和灵活性。此外，我们还提出了一种预测任务身份并相应校准模型输出的方法。
### Conclusion
我们在基于ViT的模型上展示了DualLoRA在多个基准上的显著优势，包括精度、推断速度和训练计算效率方面的优势，超过了现有的CL方法。
## 608. `cs.CV` - 基于概率的在线事件下采样 [PDF](https://arxiv.org/pdf/2506.02547), [HTML](https://arxiv.org/abs/2506.02547)
### Authors
Andreu Girbau-Xalabarder,Jun Nagata,Shinichi Sumiyoshi,Ricard Marsal,Shin'ichi Satoh
### Background
事件相机以像素为基础异步捕捉场景变化，提供极高时间分辨率，但同时也带来了高带宽、内存和计算需求。为此，先前的研究探索了事件下采样方法，但大多数方法依赖于固定启发式或阈值策略，缺乏适应性。
### Innovation
本文提出了一种基于概率的在线事件下采样框架（POLED），通过事件重要性概率密度函数（ePDF）来建模事件的重要性，这种ePDF可以灵活定义并适用于不同的应用场景。此外，本文还提出了一种零样本事件下采样方法，即下采样后的事件必须能在原始事件流训练的模型中使用，无需特定任务的适应。设计了一种轮廓保留的ePDF优先处理结构上重要的事件，并通过四个不同数据集和任务验证了这种方法在事件预算限制下保持性能的重要性。
### Conclusion
我们的方法通过在线估计事件重要性，实现了场景特定的自适应，并且通过四个不同数据集和任务展示了智能采样的重要性。该方法展示了如何在有限的事件预算下维持视觉处理的效果。
## 609. `cs.CV` - EndoBench：多模态大语言模型内镜分析综合评估 [PDF](https://arxiv.org/pdf/2505.23601), [HTML](https://arxiv.org/abs/2505.23601)
### Authors
Shengyuan Liu,Boyun Zheng,Wenting Chen,Zhihao Peng,Zhenfei Yin,Jing Shao,Jiancong Hu,Yixuan Yuan
### Background
内镜检查是诊断和治疗内部疾病的重要手段，而多模态大型语言模型（MLLMs）的应用日益增加，用于辅助内镜分析。然而，现有基准的数据集通常只涵盖特定的内镜场景和少量临床任务，无法全面覆盖临床工作流中的所有技能和真实的内镜多样性。
### Innovation
本文提出了EndoBench，这是首个全面设计来评估MLLMs在内镜实践全谱范围内的多维度能力的基准。EndoBench 包含4种不同的内镜场景，12个专门的临床任务和12个次级子任务，以及5级视觉提示粒度，共生成6,832对严格验证的VQA对，来自21个多样化的数据集。多维度评估框架涵盖了解剖识别、病灶分析、空间定位和手术操作等多个领域，全面评估MLLMs在真实场景中的感知和诊断能力。本研究还评估了23种最先进的模型，包括通用、医疗专业和专有模型，并以人类临床医生的表现作为参考标准。
### Conclusion
EndoBench 为评估和推进内镜分析中的MLLMs设定了新标准，展示了当前模型与专家临床推理之间还存在差异。我们公开发布了该基准测试和代码。
## 610. `cs.CV` - Sparse VideoGen2: 通过语义感知排列加速视频生成 [PDF](https://arxiv.org/pdf/2505.18875), [HTML](https://arxiv.org/abs/2505.18875)
### Authors
Shuo Yang,Haocheng Xi,Yilong Zhao,Muyang Li,Jintao Zhang,Han Cai,Yujun Lin,Xiuyu Li,Chenfeng Xu,Kelly Peng,Jianfei Chen,Song Han,Kurt Keutzer,Ion Stoica
### Background
Diffusion Transformers (DiTs)在视频生成中至关重要，但由于注意力机制的二次复杂性导致了显著的延迟。现有基于稀疏注意力的方法通过仅计算关键令牌来减少计算成本，但这些问题存在：（1）当前方法基于位置而非语义对令牌进行聚类，导致不精确的聚合表示；（2）关键令牌分散在非关键令牌中，导致计算浪费，特别是在优化连续处理的GPU上。
### Innovation
提出SVG2，一种无需训练的框架，通过语义感知排列最大化标识准确性并最小化计算浪费，实现生成质量和效率之间的帕累托前沿权衡。SVG2的核心是基于语义相似性的排列，使用k-means对令牌进行聚类和重新排序。该方法确保了精确的簇表示，提高了标识准确性，并集中关键令牌布局，无需填充即可实现高效计算。此外，SVG2整合了top-p动态预算控制和定制内核实现，速度分别提高了2.30倍和1.89倍，同时保持了HunyuanVideo和Wan 2.1上的PSNR分别为30和26.
### Conclusion
SVG2通过语义感知排列实现了视频生成的加速，同时在不降低质量的情况下提高了计算效率，达到更好的性能和效率平衡。
## 611. `cs.CV` - OmniSpatial：针对视觉语言模型的全面空间推理基准 [PDF](https://arxiv.org/pdf/2506.03135), [HTML](https://arxiv.org/abs/2506.03135)
### Authors
Mengdi Jia,Zekun Qi,Shaochen Zhang,Wenyao Zhang,Xinqiang Yu,Jiawei He,He Wang,Li Yi
### Background
空间推理是认知心理学的关键方面，但当前视觉-语言模型（VLMs）对此仍有很大局限性。尽管已有大量研究旨在评估或改善VLMs对基本空间关系的理解，如区分左右、远近和物件计数，但这些任务仅涵盖了空间推理的最基本层面，而且在最新的推理模型中已经接近饱和。
### Innovation
我们提出了OmniSpatial，这是一个全面而具有挑战性的空间推理基准，基于认知心理学。OmniSpatial包含四大类：动态推理、复杂空间逻辑、空间互动和视角换位，共计50个细分类目。通过细致的手动标注构建了超过8400个问题-答案对。实验表明，无论是开源还是闭源的VLMs，在全面的空间推理方面都显示出显著的局限性。此外，研究了两种增强空间推理的方法：PointGraph（明确的场景图提示）和SpatialCoT（新颖视角链式思维）。
### Conclusion
通过构建广泛的空间推理基准OmniSpatial，揭示了当前视觉语言模型在空间推理方面的局限性，并提出两种策略来增强其空间推理能力。
## 612. `cs.CV` - 是否信任你的视觉-语言模型的预测 [PDF](https://arxiv.org/pdf/2505.23745), [HTML](https://arxiv.org/abs/2505.23745)
### Authors
Hao Dong,Moru Liu,Jian Liang,Eleni Chatzi,Olga Fink
### Background
视觉-语言模型（VLMs）在跨模态理解和生成的应用中表现出强大的能力，但在安全关键领域，由于模型容易产生误分类，可能导致严重的后果，这种限制引起了极大关注。
### Innovation
本文提出了一种名为TrustVLM的无需重新训练的框架，旨在解决验证VLM预测可靠性的关键挑战。TrustVLM通过引入一种新的置信评分函数，利用图像嵌入空间中的概念表示差异来提高误分类检测的能力。
### Conclusion
TrustVLM在17个不同数据集上进行了严格的评估，并与现有基线相比取得了最先进的性能，改进幅度最高达51.87%的AURC、9.14%的AUROC和32.42%的FPR95。该模型无需重新训练即可提高模型的可靠性，为在现实世界应用中安全部署VLMs铺平了道路。
## 613. `cs.CV` - LiDAR MOT-DETR: 一种基于激光雷达的两阶段变换器用于3D多目标跟踪 [PDF](https://arxiv.org/pdf/2505.12753), [HTML](https://arxiv.org/abs/2505.12753)
### Authors
Martha Teiko Teye,Ori Maoz,Matthias Rottmann
### Background
由于激光雷达点云数据稀疏且不规则，加上需要在帧间保持时序一致性，多目标跟踪从激光雷达点云中提出了一个独特的挑战。传统的跟踪系统往往依赖手工特征和运动模型，在拥挤或快速移动的场景中很难保持物体身份的一致性。
### Innovation
本文提出了一种基于激光雷达的两阶段DETR启发式的变换器： smoother 和 tracker。smoother 阶段在移动时间窗口内细化来自任意现成探测器的激光雷达目标检测结果，而tracker阶段则使用基于DETR的注意力块，在点云上下文中将跟踪对象与细化的检测结果关联起来，以在时间上保持跟踪一致性。
### Conclusion
所提出的模型在nuScenes和KITTI数据集上通过在线和离线（向前窥视）训练模式接受了测试，展示了如ID切换和多目标跟踪精度（MOTA）等方面的强劲性能。在nuScenes数据集上，与只有激光雷达的基线和SOTA模型相比，其在线模式在aMOTA方面达到了0.724，并在aMOTP方面达到了0.475。离线模式进一步提供了3个点的aMOTP增益。
## 614. `cs.CV` - Latent Wavelet Diffusion 用于超高清图像合成 [PDF](https://arxiv.org/pdf/2506.00433), [HTML](https://arxiv.org/abs/2506.00433)
### Authors
Luigi Sigillo,Shengfeng He,Danilo Comminiello
### Background
高分辨率图像生成在生成模型中仍然是一个核心挑战，特别是在平衡计算效率和保留细微视觉细节之间。现有的方法常常在复杂性和计算效率之间难以做出折中，尤其是在生成超高清（2K-4K）图像时。
### Innovation
提出了一个新的轻量级训练框架——Latent Wavelet Diffusion（LWD）。LWD 引入了一个新的基于小波能量图的频率感知掩码策略，可以在训练过程中动态地聚焦于潜空间中的细节丰富区域。此外，LWD 还采用了一种尺度一致的 VAE 目标来确保高光谱保真度。LWD 的主要优势在于其高效性：该方法不需要对架构进行任何修改，并且在推理过程中不增加任何额外成本，使其成为了扩展现有模型的实用解决方案。
### Conclusion
在多个基准模型上，LWD 一致地提高了感知质量和 FID 分数，证明了基于信号的监督是通向高分辨率生成建模的有效且原理性的路径。
## 615. `cs.CV` - 四步法提升皮肤癌分类的不确定性感知深度学习 [PDF](https://arxiv.org/pdf/2506.10302), [HTML](https://arxiv.org/abs/2506.10302)
### Authors
Hamzeh Asgharnezhad,Pegah Tabarisaadi,Abbas Khosravi,Roohallah Alizadehsani,U. Rajendra Acharya
### Background
准确的皮肤癌诊断对于早期治疗和改善患者预后至关重要。深度学习模型在自动化皮肤癌分类方面显示出潜力，但数据稀缺和对不确定性的感知有限仍然是挑战。这项研究在HAM10000数据集上全面评估了基于迁移学习和不确定量化(UM)的深度学习皮肤病变分类方法。
### Innovation
研究使用了包括CLIP变体、ResNet50、DenseNet121、VGG16和EfficientNet-V2-Large在内的多个预训练特征提取器，并结合传统的SVM、XGBoost和逻辑回归分类器。研究还采用了多种主成分分析(PCA)设置，并通过蒙特卡洛丢弃(MCD)、集成和集成蒙特卡洛丢弃(EMCD)等不确定性量化(UM)方法进行评估，最终提出了一种基于特征融合且使用预测熵(PE)损失函数训练的模型，优于所有先前的配置。
### Conclusion
该研究改进了可信的深度学习皮肤癌诊断，通过不确定性量化方法确保了模型的准确性和可靠性，并提出了一种新的训练模型的方法，进一步提高了分类性能。
## 616. `cs.CV` - NERO: 使用神经元级相关性实现可解释的离群检测 [PDF](https://arxiv.org/pdf/2506.15404), [HTML](https://arxiv.org/abs/2506.15404)
### Authors
Anju Chhetri,Jari Korhonen,Prashnna Gyawali,Binod Bhattarai
### Background
在深度学习领域，确保模型的可靠性尤为重要，尤其是在医疗成像领域，诊断决策通常依赖于模型的输出。识别离群分布(out-of-distribution, OOD)样本是评估模型可靠性的有效手段，特别是在医疗成像中，识别OOD输入可以帮助标记潜在未检测到的异常。然而，当前的一些OOD检测方法大多依赖于特征空间或logit空间表示，这些方法可能无法完全捕捉ODD样本的多样性，因此需要一种新的OOD检测方法来弥补这一缺陷。
### Innovation
本文提出了一种新的OOD评分机制——NERO（Neuron-level Relevance OOD），它利用特征层的神经元级相关性。具体来说，NERO通过将每个在分布(in-distribution, ID)类别下的神经元级相关性聚类成代表性的质心，并引入相关性距离度量来量化新样本与这些质心的偏差，从而增强OOD样本的可分辨性。此外，NERO还通过在偏置项中引入缩放相关性和结合特征范数来进一步提高性能。此外，该框架还支持可解释的OOD检测。我们通过在多个深度学习架构上对Kvasir和GastroVision医疗成像基准进行验证，证明了该方法的有效性，其性能超过了现有的先进OOD检测方法。
### Conclusion
我们的框架在多个深度学习架构上对Kvasir和GastroVision医疗成像基准进行了验证，证明了与现有先进OOD检测方法相比，该框架在实现可解释的OOD检测方面具有改进的性能。
## 617. `cs.CV` - 干预黑箱：增强人类与神经网络相互理解的概念瓶颈模型 [PDF](https://arxiv.org/pdf/2506.22803), [HTML](https://arxiv.org/abs/2506.22803)
### Authors
Nuoye Xiong,Anqi Dong,Ning Wang,Cong Hua,Guangming Zhu,Lin Mei,Peiyi Shen,Liang Zhang
### Background
近年来深度学习取得的进展使得模型越来越复杂，具有更多的层和参数，降低了模型的可解释性，使得对模型决策的理解越来越困难。尽管已有许多方法试图解释黑箱决策，但大多数方法缺乏有效的干预措施，或者仅在样本级别操作而不修改模型本身。因此，现有方法在提高模型可解释性和准确性方面仍然存在不足。
### Innovation
本文提出了一种概念瓶颈模型（Concept Bottleneck Model, CBM）来增强人类与神经网络之间的相互理解（Conceptual Bottleneck Model for Enhancing Human-Neural Network Mutual Understanding, CBM-HNMU）。CBM-HNMU 使用可解释的概念瓶颈模型框架来近似黑箱推理，并通过全球梯度贡献自动识别并处理有害概念（移除或替换）。经过修改的概念瓶颈模型将修正知识重新注入黑箱模型，从而增强模型的可解释性和准确性。
### Conclusion
文章在Flower-102、CIFAR-10、CIFAR-100、FGVC-Aircraft以及CUB-200数据集上的卷积神经网络（CNN）和基于变换器的模型上评估了CBM-HNMU，结果表明最高准确率提高了2.64%，平均准确率提高了1.03%。源代码可在此链接下载。
## 618. `cs.CV` - 扩散模型在多元地下生成和高效的概率反演中的应用 [PDF](https://arxiv.org/pdf/2507.15809), [HTML](https://arxiv.org/abs/2507.15809)
### Authors
Roberto Miele,Niklas Linde
### Background
扩散模型在深度生成建模任务中提供了稳定的训练和最先进的性能。本文探讨了它们在多元地下建模和概率反演中的应用。研究人员对比了扩散模型与其他生成模型（如变分自编码器和生成对抗网络）在多元建模能力上的效果。
### Innovation
在扩散模型中，生成过程涉及大量的时间步骤，并且可以修改更新规则以考虑到条件数据。本文提出了对Chung等人（2023）提出的扩散后验采样方法的不同修正，特别是引入了噪声污染的似然性近似方法。研究展示了这种方法在含 facies 和相关声学阻抗的多元地质场景中的性能。相较于原始方法，这种方法具有显著的统计稳健性增强、后验概率密度函数采样的改善以及计算成本的降低。此外，该方法可以同时使用硬数据和间接数据进行条件建模，并且通过扩散过程中的反演比其他需要外圈生成模型的方法更快。
### Conclusion
扩散模型能够同时处理硬数据和间接数据，且通过将其反演纳入扩散过程中，提高了计算效率。在比较多个迭代过程的方法中，扩散模型的应用展示了显著改进的性能和效率。
## 619. `cs.CV` - VSF: Value Sign Flip在少数步骤图像生成模型中的简单、高效且有效的负向指导 [PDF](https://arxiv.org/pdf/2508.10931), [HTML](https://arxiv.org/abs/2508.10931)
### Authors
Wenqi Guo,Shan Du
### Background
该研究介绍了一种用于少数步骤扩散和流匹配图像生成模型中融入负向提示指导的简单且高效的方法——Value Sign Flip (VSF)。现有的方法，如无分类器引导 (CFG)、NASA 和 NAG，没有能够动态抑制未预期内容的能力。VSF 方法通过翻转来自负向提示的注意力值的符号来实现这一目标。
### Innovation
VSF 方法具有以下几个创新点：首先，它仅需小的计算开销，并能有效集成到如 Stable Diffusion 3.5 Turbo 等 MMDiT 风格的架构中，以及基于交叉注意机制的模型如 Wan；其次，该方法已在具有复杂提示对的挑战性数据集上进行验证，并展示了在静态图像和视频生成任务中的优越性能。实验结果表明，VSF 方法在少数步骤模型中的负向提示一致性显著优于先前方法，甚至在非少数步骤模型中也优于 CFG 方法，同时保持着竞争性的图像质量。
### Conclusion
实验结果显示，VSF 方法在少数步骤模型中显著提高了负向提示的一致性，并在静态图像和视频生成任务中表现优越，同时保持了高质量的图像生成。相关代码和 ComfyUI 节点可在指定链接中获取。
## 620. `cs.CV` - 多模态连续思维链在视觉语言模型中隐空间推理中的应用 [PDF](https://arxiv.org/pdf/2508.12587), [HTML](https://arxiv.org/abs/2508.12587)
### Authors
Tan-Hanh Pham,Chris Ngo
### Background
许多用于大模型的推理技术采用语言模型的方法，如Chain-of-Thought (CoT) 提示，这些方法将推理表达为词序列。对于文本有效，但对于多模态上下文来说是次优化的，无法动态地对齐音频、视觉和文本信息。当前尝试探索一种替代范式。
### Innovation
提出了多模态连续思维链(MCOUT)，这是一种在联合潜在空间中进行直接推理的方法，而不是使用自然语言。MCOUT将推理状态表示为连续的隐藏向量，迭代地精炼并与视觉和文本嵌入对齐，受到人类反思认知的启发。开发了两种变种：一种是MCOUT-Base，它重用语言模型的最后一个隐藏状态作为连续思维进行迭代推理，另一种是MCOUT-Multi，它整合了多模态的潜在注意力，以增强视觉和文本特征之间的跨模态对齐。
### Conclusion
在MMMU、ScienceQA和MMStar等基准测试中，MCOUT一致地提高了多模态推理能力，相对于强大的基线模型，准确率提高了8.23%，并在多项选择和开放性任务中提高了BLEU评分高达8.27%。这些发现表明，潜在连续推理是推动LMMs超越语言限制的CoT的一个有前途的方向，提供了一个可扩展的人类反射多模态推理框架。
## 621. `cs.CV` - 通过中间投影器增强对大型视觉语言模型的针对性 adversarial 攻击 [PDF](https://arxiv.org/pdf/2508.13739), [HTML](https://arxiv.org/abs/2508.13739)
### Authors
Yiming Cao,Yanjie Li,Kaisheng Liang,Bin Xiao
### Background
大型视觉语言模型（VLMs）的部署日益增多，引发了安全问题，因为对手可能会利用模型的漏洞造成有害输出，尤其是定向黑盒攻击对模型构成严重威胁。现有的方法主要在编码器层面最大化全局相似性，这缺乏实现细微且实用攻击的精细度，即只改变特定目标（如修改一辆车而不改变其背景）。此外，这些方法忽略了投影器，这是VLMs中关键的语义桥梁，对于多模态对齐至关重要。
### Innovation
提出了一种新颖的黑盒定向攻击框架，利用了投影器。具体来说，利用广为采用的Querying Transformer（Q-Former）将全局图像嵌入转换为精细的查询输出，从而增强攻击效果和精细度。针对标准的全局定向攻击场景，提出了一种中间投影器引导攻击（IPGA），通过与目标对齐Q-Former的精细查询输出来增强攻击强度，并利用未针对任何特定大型语言模型进行微调的中间预训练Q-Former，以提高攻击的可移植性。对于细粒度攻击场景，IPGA结合了残差查询对齐（RQA）模块，通过约束非目标查询输出来保留无关内容，从而提高攻击的精细度。
### Conclusion
广泛的实验证明，IPGA在全局定向攻击中显著优于基线，而附带RQA的IPGA（IPGA-R）在细粒度攻击中不仅成功率更高，而且能够更好地保留无关内容。该方法还能够有效地转移到如Google Gemini和OpenAI GPT等商业VLM上。
## 622. `cs.CV` - 动作中的旋性：通过潜空间伸直的时间感知视频表示学习 [PDF](https://arxiv.org/pdf/2509.08502), [HTML](https://arxiv.org/abs/2509.08502)
### Authors
Piyush Bagad,Andrew Zisserman
### Background
本研究旨在开发对视觉随时间变化敏感的紧凑视频表示。现有的视频嵌入方法在表示像“开门和关门”、“接近和远离物体”、“折叠和展开纸张”这样的典型日常生活动作时表现不佳，这需要理解对象状态、大小、空间位置等方面的简单视觉变化。本研究提出了一个新任务——旋手性动作识别，用以测量视频表示的时间敏感性。
### Innovation
研究提出了一种自我监督的方法，通过向冻结的图像特征序列中注入时间灵敏度来提升时间感知的视频表示。该模型基于具有感知伸直启发式的潜空间的自动编码器，可以生成适用于旋手性动作识别任务的紧凑且时间敏感的视频表示，并且在Something-Something、EPIC-Kitchens和Charade三个数据集上均体现了优越性。与大型预训练视频模型相比，该方法获得了更好的性能，结合现有的模型时，也能提升分类性能。
### Conclusion
研究成功实现了时间感知的视频表示，提高了对旋手性动作识别的性能，并且这种表示方法在多个数据集上都表现出了优越性，结合现有的视频模型时，能够进一步提升分类任务的性能。
## 623. `cs.CV` - SurgVidLM: 向大规模语言模型推进多粒度外科视频理解 [PDF](https://arxiv.org/pdf/2506.17873), [HTML](https://arxiv.org/abs/2506.17873)
### Authors
Guankun Wang,Junyi Wang,Wenjin Mo,Long Bai,Kun Yuan,Ming Hu,Jinlin Wu,Junjun He,Yiming Huang,Nicolas Padoy,Zhen Lei,Hongbin Liu,Nassir Navab,Hongliang Ren
### Background
外科手术场景理解对于外科训练和机器人辅助手术中的决策至关重要。近期的多模态大型语言模型（MLLMs）在医疗领域的场景感知方面展现了巨大的潜力，有助于外科医生理解手术场景和程序。然而，这些方法主要侧重于基于图像的分析或全局视频理解，忽视了分析特定过程和捕捉手术程序中详细任务执行所需的精细视频推理。为解决这一问题，作者提出了SurgVidLM，这是一种旨在解决全面和精细手术视频理解的第一种视频语言模型。为了训练SurgVidLM，作者构建了一个包含超过31K视频指令对的大规模数据集SVU-31K，该数据集能够实现对手术程序的全面理解和详细分析。基于此资源，SurgVidLM采用了两阶段的StageFocus机制：第一阶段提取全局程序上下文，而第二阶段则根据时间线索进行高频局部分析。同时，作者开发了多频融合注意力机制，以有效整合低频和高频视觉令牌，确保关键任务特定细节的保留。实验结果表明，SurgVidLM在全面和精细视频理解任务中显著优于具有相似参数量的最新视频语言模型，展示了其在复杂机器人辅助手术上下文捕获方面的优越能力。
### Innovation
提出了SurgVidLM，这是针对外科视频理解的第一个包含全面和精细理解的视频语言模型。SurgVidLM利用了一个名为SVU-31K的大规模视频-指令数据集进行训练，该数据集包含超过31K对视频-指令，能够支持外科程序的全面理解和详细分析。此外，SurgVidLM采用了两阶段的StageFocus机制和多频融合注意力机制，分别用于全局程序上下文的提取和高频局部分析，并有效整合低频和高频视觉令牌，实现对关键任务特定细节的保留。
### Conclusion
实验结果表明，SurgVidLM在全面和精细视频理解任务中显著优于具有相似参数量的最新视频语言模型，展示了其在复杂机器人辅助手术上下文捕获方面的优越能力。代码和数据集将在不久的将来公开。
## 624. `cs.CV` - FastTracker：实时且准确的视觉跟踪 [PDF](https://arxiv.org/pdf/2508.14370), [HTML](https://arxiv.org/abs/2508.14370)
### Authors
Hamidreza Hashempoor,Yu Dong Hwang
### Background
传统的多目标跟踪系统主要针对行人的跟踪，对于其他对象类别（如车辆）的泛化能力较弱。本文提出了一种通用的多目标跟踪框架，能够处理多种对象类型，特别强调了复杂交通场景中的车辆跟踪。
### Innovation
本文方法包括两个关键组成部分：1）一种考虑遮挡的再识别机制，增强高度遮挡对象的身份识别；2）一种道路结构感知的轨迹修整策略，利用包括车道方向、人行横道和道路边界等语义场景先验信息，提高轨迹的连续性和准确性。此外，还提出了一套新型基准数据集，包含了不同的车辆类别，并提供逐帧跟踪标注，专门为评估车辆导向跟踪方法提供支持。
### Conclusion
实验结果表明，提出的方案在新引入的数据集和多个公开基准上都表现出稳健的性能，证明了其在通用目标跟踪上的有效性。而该框架在通用多类跟踪中表现出色，在MOT17和MOT20测试集上的HOTA分数分别为66.4和65.7。代码和基准数据集可以在指定链接获取。
## 625. `cs.CV` - AutoOEP — 一种多模态的在线考试监考框架 [PDF](https://arxiv.org/pdf/2509.10887), [HTML](https://arxiv.org/abs/2509.10887)
### Authors
Aryan Kashyap Naveen,Bhuvanesh Singla,Raajan Wankhade,Shreesha M,Ramu S,Ram Mohana Reddy Guddeti
### Background
在线教育的迅速发展对确保远程考试期间的学术诚信提出了迫切需求。传统的真人监考在大规模情况下往往不可行，现有的自动化解决方案常常过于侵入或无法检测多种作弊行为。
### Innovation
本论文提出了AutoOEP（Automated Online Exam Proctoring）综合多模态框架，该框架利用计算机视觉和机器学习技术提供有效的自动化监考。该系统使用双摄像头设置，分别捕捉考生的正面和工作空间的侧面视角，最小化盲点。该方法结合了脸部模块与ArcFace的连续身份验证，以及头部姿态估计、眼神追踪和嘴巴动作分析来检测可疑行为，同时手模块使用微调的YOLOv11模型检测禁止物品（如手机、笔记），并通过手与目标对象的接近度进行跟踪。这些模块的特征被聚合并通过长短期记忆网络（LSTM）分析时间模式，生成实时作弊概率评分。
### Conclusion
我们的研究结果表明，AutoOEP是一个有效且资源高效的方法，显著减少了对人工干预的依赖，增强了在线评估的学术诚信。整个框架的视频流处理速度大约为每秒2.4帧，无需GPU。
## 626. `cs.CV` - VER-Bench: 评估 MLLMs 在处理细微视觉证据推理中的能力 [PDF](https://arxiv.org/pdf/2508.04852), [HTML](https://arxiv.org/abs/2508.04852)
### Authors
Chenhui Qiang,Zhaoyang Wei,Xumeng Han,Zipeng Wang,Siyao Li,Xiangyuan Lan,Jianbin Jiao,Zhenjun Han
### Background
随着大规模语言模型（MLLMs）的迅速发展，评估其视觉能力变得越来越重要。当前的评估基准主要分为两种类型：基础感知基准关注局部细节但缺乏深度推理，主流推理基准专注于显眼的图像元素但可能无法评估需要繁琐分析的细微线索。然而，深刻的视觉理解和复杂的推理更多依赖于解释细微、不显眼的局部细节，而不是感知显眼的宏观对象。这些细节尽管在图像中所占面积很小，但却包含了更为丰富和关键的信息，对于稳健分析至关重要。
### Innovation
本文提出了 VER-Bench，一种新的框架来评估 MLLMs 的能力，包括：1）识别平均仅占图像面积 0.25% 的细微视觉线索；2）将这些线索与世界知识结合进行复杂推理。VER-Bench 包含了跨地理、时间、情境、意图、系统状态和符号推理的 374 个精心设计的问题，并提供了详细的结构化证据：视觉线索和相关推理。
### Conclusion
VER-Bench 暴露了现有模型在提取细微视觉证据和构建基于证据的论证方面的局限性，强调了需要增强模型在细微视觉证据提取、整合和推理方面的能力，以实现真正的视觉理解和类人分析。数据集和额外材料可在以下链接访问：this https URL。
## 627. `cs.CV` - Lost in Translation? 漏失在翻译之中？词汇对齐在开放词汇语域适应的源代码领域适应中的作用 [PDF](https://arxiv.org/pdf/2509.15225), [HTML](https://arxiv.org/abs/2509.15225)
### Authors
Silvio Mazzucco,Carl Persson,Mattia Segu,Pier Luigi Dovesi,Federico Tombari,Luc Van Gool,Matteo Poggi
### Background
该论文介绍了VocAlign，一个针对开放词汇语域分割中的VLMs的新型源代码领域适应框架。背景在于传统的领域适应方法通常依赖于源数据，这在开放词汇场景下不够灵活和有效，论文的目标是开发一个无需源数据的领域适应框架，提高模型在未知词汇情况下的泛化能力。
### Innovation
本文的创新点包括：1) 引入了学生-教师范式结合词汇对齐策略，提高伪标签生成；2) 使用低秩适应（LoRA）进行微调，保持模型原有的能力强的同时，减少了计算成本；3) 提出Top-K类选择机制，进一步减少学生模型的内存需求，提高了适应性。
### Conclusion
该方法在CityScapes数据集上实现了显著的6.11 mIoU改进，并在零样本分割基准测试中表现出色，建立了开放词汇设置下源代码适应的新标准。
## 628. `cs.CV` - OmniWorld: 一种用于4D世界建模的多域多模态数据集 [PDF](https://arxiv.org/pdf/2509.12201), [HTML](https://arxiv.org/abs/2509.12201)
### Authors
Yang Zhou,Yifan Wang,Jianjun Zhou,Wenzheng Chang,Haoyu Guo,Zizun Li,Kaijing Ma,Xinyue Li,Yating Wang,Haoyi Zhu,Mingyu Liu,Dingning Liu,Jiange Yang,Zhoujie Fu,Junyi Chen,Chunhua Shen,Jiangmiao Pang,Kaipeng Zhang,Tong He
### Background
近年来，旨在同时捕捉空间几何和时间动态的4D世界建模领域取得了显著进展，受到大规模生成模型和多模态学习技术进步的推动。然而，真正通用的4D世界模型的发展仍然受到高质量数据可用性的限制。现有的数据集和基准常常缺乏支持诸如4D几何重构、未来预测和摄像机控制视频生成等关键任务所需的动态复杂性、多域多样性和时空注释。为解决这一问题，我们提出了一种名为OmniWorld的大规模、多域、多模态数据集，专门用于4D世界建模。该数据集包含一个新的收集到的OmniWorld-Game数据集以及来自不同领域的多个精选公开数据集。
### Innovation
OmniWorld相比现有合成数据集提供了更丰富的模态覆盖、更大的规模和更真实的动态交互。基于此数据集，我们建立了一个具有挑战性的基准，揭示了当前最先进的（SOTA）方法在建模复杂4D环境方面存在的局限。此外，对OmniWorld的微调显著提升了4D重建和视频生成任务的表现，这有力地验证了OmniWorld作为培训和评估的强大资源。
### Conclusion
我们期望OmniWorld能够成为推动通用4D世界模型发展的催化剂，最终促进机器对物理世界的全面理解。
## 629. `cs.CV` - CLOSP: 卫星雷达SAR、多光谱图像MSI和文本的统一语义空间 [PDF](https://arxiv.org/pdf/2507.10403), [HTML](https://arxiv.org/abs/2507.10403)
### Authors
Daniele Rege Cambrin,Lorenzo Vaiani,Giuseppe Gallipoli,Luca Cagliero,Paolo Garza
### Background
从巨大的卫星档案中检索相关的影像对于灾害响应和长期气候监测等应用至关重要。然而，大多数基于文本到图像检索系统的性能受限于仅使用RGB数据，未能充分利用其他传感器捕获的特殊物理信息，如合成孔径雷达（SAR）在全天候条件下的结构敏感性，或多光谱数据中的光谱特征。为解决这一问题，作者提出了一种新的方法来弥合不同数据间的鸿沟。
### Innovation
作者引入了CrisLandMark，这是一个大规模的数据集，包含超过647,000对Sentinel-1 SAR和Sentinel-2多光谱影像，以及结构化的文本注释，用于土地覆盖、土地利用和危机事件的标注，这些注释来源于权威的土地覆盖系统（CORINE和Dynamic World）和特定危机来源。为了将光学影像和SAR影像对齐到统一的嵌入空间，作者提出了CLOSP（对比语言光学SAR预训练）框架，该框架使用文本作为桥梁。这种方法在1000个排名内的检索性能取得了新的最先进水平，改进幅度达到了54%。此外，GeoCLOSP通过集成地理坐标，提高了处理特定地理特征和灾难事件的能力。
### Conclusion
该研究揭示了将多种传感器数据和地理环境整合的重要性，这对充分利用遥感档案的潜力至关重要。
## 630. `cs.CV` - Minimal Semantic Sufficiency Meets Unsupervised Domain Generalization [PDF](https://arxiv.org/pdf/2509.15791), [HTML](https://arxiv.org/abs/2509.15791)
### Authors
Tan Pan,Kaiyu Guo,Dongli Xu,Zhaorui Tan,Chen Jiang,Deshu Chen,Xin Guo,Brian C. Lovell,Limei Han,Yuan Cheng,Mahsa Baktashmotlagh
### Background
虽然监督学习中深度学习的泛化能力已被广泛研究，但在无监督场景下尚缺乏深入探索。近期提出了无监督域泛化（UDG）任务，旨在通过自监督学习（SSL）等常用无监督学习技术训练的模型提高泛化能力。UDG面临挑战，即在没有类别标签的情况下区分语义与变化。尽管一些方法已使用域标签来应对这一问题，但在实际应用中这类标签常不可用。因此，本文针对此问题提出了形成为学习最小充分语义表示的UDG任务：该表示（i）保留所有跨增强视图共享的语义信息（充分性），（ii）最大限度地去除与语义无关的信息（最小性）
### Innovation
本文从信息论角度理论地确立了学习最小充分语义表示的目标，证明优化表示以实现充分性和最小性可直接降低分布外风险。具体地，提出了可学习模型Minimal-Sufficient UDG (MS-UDG)，包含基于InfoNCE的目标来实现充分性，以及新颖的语义变异分离损失和基于重构机制以捕捉足够变异的两个互补组件来促进最小性。该模型在流行无监督域泛化基准测试中表现最佳，即使在表示学习过程中不需要类别或域标签，也优于现有自监督学习和无监督域泛化方法
### Conclusion
MS-UDG通过最大化保留跨增强视图共享的语义信息并最小化无关信息，在多个无监督域泛化数据集上实现了最优性能，克服了以往方法因缺乏标签而导致的局限。
## 631. `cs.CV` - Understanding-in-Generation: 通过将理解融入生成强化统一模型的生成能力 [PDF](https://arxiv.org/pdf/2509.18639), [HTML](https://arxiv.org/abs/2509.18639)
### Authors
Yuanhuiyi Lyu,Chi Kit Wong,Chenfei Liao,Lutao Jiang,Xu Zheng,Zexin Lu,Linfeng Zhang,Xuming Hu
### Background
近期的研究在通过思维链（CoT）增强统一模型的文本到图像生成能力方面取得了重要进展。然而，这些推理方法将理解过程和生成过程分离，限制了它们对统一模型生成能力不足的指导作用。
### Innovation
本文提出了一种名为Understanding-in-Generation (UiG)的新颖推理框架，该框架利用统一模型的理解能力来强化其在图像生成中的表现。UiG的核心理念是在推理过程中通过强大的理解能力引入生成指导，从而减轻生成能力的限制。为此，引入“图像编辑”作为桥梁，将理解融入生成过程：首先验证生成图像，并将统一模型的理解融入编辑指令中；随后逐步增强生成图像，逐步将理解融入生成过程中。
### Conclusion
UiG框架在文本到图像生成上比现有文本到图像推理方法显示出显著的性能改进，例如在TIIF基准的长提示设置上得到了3.92%的提升。相关代码地址为: 这里 https://github.com/your-repo
## 632. `cs.CV` - PolypSeg-GradCAM: 采用基于U-Net分割和Grad-CAM可视化Kvasir数据集上的可解释计算机辅助胃肠道疾病检测 [PDF](https://arxiv.org/pdf/2509.18159), [HTML](https://arxiv.org/abs/2509.18159)
### Authors
Akwasi Asare,Ulas Bagci
### Background
结直肠癌（CRC）是全球的主要癌症死亡原因之一，且肠息肉被世界卫生组织认为是关键的前驱病变。在结肠镜检查期间早期和准确的息肉分割对于减少CRC进展至关重要，但手动勾勒过程繁琐且易受观察者主观性的影响。尽管深度学习方法在自动息肉分析方面表现出巨大潜力，但由于其有限的可解释性，临床应用受到限制。因此，本研究旨在提出一种基于U-Net架构结合Grad-CAM的可解释深度学习框架——PolypSeg-GradCAM，以提高息肉分割的透明度和可信度，从而促进可靠的辅助结肠镜检查技术和早CRC预防的发展。
### Innovation
提出了一种新的深度学习框架（PolypSeg-GradCAM），该框架结合了U-Net架构和Grad-CAM可视化技术，用以提高结肠镜检查期间息肉分割的透明度和可解释性。利用Kvasir-SEG数据集（包含1000张标注好的内镜图像）进行训练和评估，实验结果显示在测试集上平均交并比（IoU）达到0.9257，并且训练和验证集上的Dice系数（F分数）>0.96，进一步通过Grad-CAM可视化证明了模型预测基于临床相关区域，显著提升了模型决策的透明度和可信度。
### Conclusion
通过高分割准确性和可解释性的结合，PolypSeg-GradCAM向可靠且值得信赖的计算机辅助结肠镜检查迈出了重要一步，并有望改善早期CRC的预防。
## 633. `cs.CV` - 基于预训练模型的类别增量学习中的噪声混合 [PDF](https://arxiv.org/pdf/2509.16738), [HTML](https://arxiv.org/abs/2509.16738)
### Authors
Kai Jiang,Zhengyan Shi,Dell Zhang,Hongyuan Zhang,Xuelong Li
### Background
类别增量学习（CIL）的目标是在不断学习新类别的同时保持对旧类别的知识。预训练模型（PTMs）在CIL方面显示出有前景的能力，但现有的应用轻量级微调到骨干网的方法仍然会导致参数漂移，从而损害预训练模型的泛化能力。在这种情况下，可以将参数漂移视为掩盖前任务学习的重要模式的一种噪声形式。然而，近期研究表明，噪声不总是有害的。例如，从预训练中学到的大量视觉图案可以轻易被单一任务滥用，通过引入适当的噪声可以抑制一些低关联特征，从而为未来任务留下空间。
### Innovation
本文提出了一种基于信息论指导的学习有益噪声的方法，旨在减轻新任务适应过程中骨干网络泛化能力的退化。具体而言，任务特定的噪声是从新任务的高维特征中学习的。然后，动态调整一组权重以实现不同任务噪声的最佳混合。最后，Min将有益噪声嵌入中间特征以掩盖无效模式的响应。在六个基准数据集的广泛实验中，Min在大多数增量设置中实现了最先进的性能，特别是在50步增量设置中取得了尤为出色的结果。这表明有益噪声在持续学习中具有显著的潜力。
### Conclusion
通过Min方法，在大多数增量设置中，特别是在50步增量设置中，Min方法实现了最先进的性能。这显示了有益噪声在持续学习中的巨大潜力。
## 634. `cs.CV` - COLT: 提升视频大型语言模型的持续工具使用能力 [PDF](https://arxiv.org/pdf/2509.18754), [HTML](https://arxiv.org/abs/2509.18754)
### Authors
Yuyang Liu,Xinyuan Shi,Xiaondan Liang
### Background
大型语言模型（LLMs）的成功极大地推动了视频理解的相关研究。现有的方法多采用刺激闭源LLMs或通过指令调优的方式进行工具使用细调，但这些方法假设有固定的工具库并且难以在不断变化的现实环境中进行推广。现有的方法存在工具库固定且难以应对不断变化的工具数据的问题，这限制了视频LLMs在实际应用中的灵活性和有效性。为解决上述问题，本研究提出了COntinuaL Tool usage（COLT），能够在持续的工具流中自动获取工具使用能力，而不发生‘灾难性遗忘’。
### Innovation
COLT 提出了一个可学习的工具码本作为工具特定的记忆系统，通过用户指令与码本中工具特征的相似性动态选择相关工具。这使视频LLMs能够充分利用其工具使用潜力。该研究还构建了一个视频中心的工具使用指令调优数据集 VideoToolBench，以验证COLT的有效性，并在先前视频LLM基准测试和专门的工具使用数据集 VideoToolBench 上进行了广泛的实验，展示了COLT的先进性能。
### Conclusion
本研究提出的 COLT 方法能够使视频大型语言模型在持续的工具流中自动获取工具使用能力，而不发生‘灾难性遗忘’。通过收集 VideoToolBench 数据集，研究在多个基准测试中验证了COLT的优势，展示了其在工具使用上的出色表现。
## 635. `cs.CV` - 高效修正流图像融合 [PDF](https://arxiv.org/pdf/2509.16549), [HTML](https://arxiv.org/abs/2509.16549)
### Authors
Zirui Wang,Jiayi Zhang,Tianwei Guan,Yuhan Zhou,Xingyuan Li,Minjing Dong,Jinyuan Liu
### Background
图像融合是计算机视觉中的一个基本且重要的任务，目的是结合来自不同模态的互补信息来融合图像。近年来，扩散模型在图像融合领域取得了显著进展，但这些模型通常需要复杂的计算和冗余的推理时间，这降低了这些方法的应用性。为解决这一问题，我们提出了一种基于修正流的高效一步扩散模型—RFfusion，用于图像融合。我们通过将修正流整合到图像融合任务中，简化了采样路径，实现了无额外训练的一站式采样，同时仍能保持高质量的融合结果。我们还提出了一种专门针对图像融合的变分自编码器（VAE）架构，其中将融合操作嵌入到潜在空间中，进一步减少了计算复杂性。为解决传统重建导向的VAE目标与图像融合需求之间的固有差异，我们引入了两阶段训练策略。该方法促进了互补信息的有效学习和融合，使得模型能够保留精细的结构细节并显著提高推理效率。实验表明，我们的方法在推理速度和融合质量方面都超过了其他最先进的方法。
### Innovation
提出了基于修正流的高效一步扩散模型——RFfusion，该模型通过修正流简化了采样路径，实现了无额外训练的一站式采样。引入了针对图像融合的任务特定变分自编码器（VAE）架构，将融合操作嵌入到潜在空间中，减少计算复杂性。此外，提出了两阶段训练策略，有效解决了传统VAE目标与图像融合需求之间的差异，能够提高模型的推理效率和融合质量。
### Conclusion
本文提出的RFfusion方法在推理速度和融合质量方面均优于其他最先进的方法。两阶段训练策略有效地结合了多模态图像的互补信息，保留了结构细节，显著提高了推理效率。
## 636. `cs.CV` - PerceptronCARE：一种基于深度学习的智能远程眼科应用用于糖尿病视网膜病变诊断 [PDF](https://arxiv.org/pdf/2509.18160), [HTML](https://arxiv.org/abs/2509.18160)
### Authors
Akwasi Asare,Isaac Baffour Senkyire,Emmanuel Freeman,Mary Sagoe,Simon Hilary Ayinedenaba Aluze-Ele,Kelvin Kwao
### Background
糖尿病视网膜病变是成人视力丧失的主要原因，并且是全球健康挑战的重要部分，尤其是在未得到充分服务的地区。这项研究介绍了一种基于深度学习的远程眼科应用PerceptronCARE，该应用通过视网膜图像自动检测糖尿病视网膜病变。
### Innovation
该系统使用了多个卷积神经网络（包括ResNet-18、EfficientNet-B0和SqueezeNet），以确定准确性和计算效率之间的最佳平衡。最终模型在疾病严重程度分类中达到了85.4%的准确率，能够在临床和远程医疗环境中实现实时筛查。PerceptronCARE系统集成了基于云的可扩展性、安全的患者数据管理和多用户框架，从而实现早期诊断，改善医生与患者之间的互动，并降低医疗成本。
### Conclusion
这项研究表明，基于人工智能的远程医疗解决方案在扩大糖尿病视网膜病变筛查的可及性方面的潜力，尤其是在偏远和资源受限的环境中。
## 637. `cs.CV` - Citrus-V: 在统一医疗图像地基推理推动医疗基础模型进步 [PDF](https://arxiv.org/pdf/2509.19090), [HTML](https://arxiv.org/abs/2509.19090)
### Authors
Guoxin Wang,Jun Zhao,Xinyi Liu,Yanbo Liu,Xuyang Cao,Chao Li,Zhuoyun Liu,Qintian Sun,Fangru Zhou,Haoqiang Xing,Zhenhong Yang
### Background
医学成像为临床诊断、治疗计划和手术决策提供了关键证据，但现有大多数成像模型专注于狭窄领域并需要多个专门的网络，这限制了它们的一般化能力。虽然大规模语言和多模态模型展示出强大的推理能力和多任务处理能力，但在实际的临床应用中，需要精确的视觉定位、多模态整合以及链条推理，而现有模型难以满足这些需求。
### Innovation
我们引入了Citrus-V，这是一个结合图像分析与文本推理的多模态医疗基础模型。该模型集成了检测、分割和多模态链条推理，能够在单一体系中实现病灶像素级别的定位、结构化报告生成以及类似医生的诊断推断。我们提出了新颖的多模态训练方法，并发布了涵盖推理解析、检测、分割和文档理解任务的精选开源数据集。评估结果显示，Citrus-V 在多项基准测试上超越现有开放源代码医学模型和专业级成像系统，从视觉定位到临床推理提供了统一的流程，并支持精确的病灶量化、自动化报告和可靠的二次意见。
### Conclusion
Citrus-V 在多项指标上表现出色，为统一的临床推理与多模态集成提供了一个有效解决方案。
## 638. `cs.CV` - 重新审视肺栓塞分割：现有方法与挑战的一次开放权重模型研究 [PDF](https://arxiv.org/pdf/2509.18308), [HTML](https://arxiv.org/abs/2509.18308)
### Authors
Yixin Zhang,Ryan Chamberlain,Lawrence Ngo,Kevin Kramer,Maciej A. Mazurowski
### Background
本研究使用了490个CTPA扫描构建了一个详细标注的内部数据集，系统性地评估了九种广泛使用的分割架构（包括来自CNN和Vision Transformer的模型），这些架构分别以预训练或随机权重进行初始化。研究在统一的测试框架下进行，主要评估了不同模型在肺栓塞（PE）分割任务中的性能，旨在重新审视现有的分割方法及其面临的挑战。研究发现，3D U-Net结合ResNet编码仍然是PE分割的有效架构；3D模型因其解剖特点特别适合这一任务；基于CNN的模型在PE分割中的性能总体优于基于ViT的模型；分类预训练，即使在大规模PE数据集上，也可能负面影响分割性能；不同的模型架构在相同数据上训练时显示出相似的分割性能模式；尽管中心和大型栓塞可以较好地分割，但远端栓塞由于任务复杂性和高质量数据稀缺而仍然具有挑战性。此外，研究的最佳模型在分割任务中的平均Dice分数为0.7131，检测了181个栓塞，有49个假阳性，28个假阴性，来自60个内部测试扫描，并通过公共数据集进一步验证了其泛化能力。
### Innovation
通过构建详细标注的内部数据集，系统性地评估了九种广泛使用的分割架构（分别是CNN和Vision Transformer的模型，包括3D U-Net结合ResNet编码、基于CNN的模型和基于ViT的模型），探索了在哪种情况下哪种模型最有效，从而深入了解了PE分割的现有方法和面临的挑战。研究揭示了3D U-Net与ResNet组合的优势，以及基于CNN和ViT模型在PE分割中的相对表现，提出了预训练可能对表现产生负面影响的观点，还指出了远端栓塞分割的难点。此外，提出了一个能够在多个数据集上泛化的最佳模型，验证了其有效性。
### Conclusion
在对不同分割模型和方法进行全面评估后，研究得出几个重要结论：3D U-Net结合ResNet编码依然是PE分割的有效模型；3D模型尤其适合这一任务；基于CNN的模型通常优于基于ViT的模型；预训练可能对性能产生不利影响；不同的模型架构在相同数据下训练时表现出一致的分割性能；中心和大型栓塞可较准确地分割，而远端栓塞则面临显著挑战。
## 639. `cs.CV` - 利用多模态大语言模型进行交通事故检测的研究 [PDF](https://arxiv.org/pdf/2509.19096), [HTML](https://arxiv.org/abs/2509.19096)
### Authors
Ilhan Skender,Kailin Tong,Selim Solmaz,Daniel Watzenig
### Background
交通安全是全球性的关键问题，及时准确地检测交通事故对于减少安全隐患和迅速应急响应至关重要。基础设施视角传感器提供了可扩展和高效的方法，用于持续实时监控，从而可以直接从捕获的图像中自动检测事故。这项研究调查了多模态大语言模型（MLLMs）在使用来自基础设施摄像头的图像直接检测和描述交通事故的零样本能力，以减少对大量标注数据的依赖。研究背景在于现有的基础设施事故数据稀缺且不够多样化和现实。需要通过控制模拟来解决这个难题。
### Innovation
研究的主要贡献包括：(1) 使用在CARLA模拟生成的DeepAccident数据集对MLLMs进行评估，明确地解决了多样的、现实的基础设施事故数据稀缺问题；(2) 对Gemini 1.5和2.0、Gemma 3和Pixtral模型在事故识别和描述能力方面进行比较分析，无需预先微调；(3) 将高级视觉分析技术（如YOLO对象检测、Deep SORT多对象跟踪、以及Segment Anything实例分割）与增强提示结合，以提高模型的准确性和可解释性。
### Conclusion
研究结果表明，将MLLMs与高级视觉分析技术相结合具有巨大的潜力，可以增强其在现实世界自动交通监控系统中的应用。特别是，Pixtral在F1分数方面表现最佳，达到71%，而在召回率方面达到83%，Gemini模型在增强提示后提高了精确度（如Gemini 1.5提升至90%），但F1分数和召回率有所下降。Gemma 3提供了最平衡的性能，最小化了元度波动。
## 640. `cs.CV` - 是否折叠：带有图正则化的张量积三维重建视觉数据 [PDF](https://arxiv.org/pdf/2306.11123), [HTML](https://arxiv.org/abs/2306.11123)
### Authors
Le Xu,Lei Cheng,Ngai Wong,Yik-Chung Wu
### Background
张量训练（TT）表示法在视觉数据完成任务中取得了巨大成功，尤其是与张量折叠结合使用时。然而，折叠图像或视频张量会破坏原始数据结构，导致局部信息丢失，因为相邻像素可能会被分配到不同的维度，彼此间距离变远。需要一个方法能够在不破坏原始数据结构的情况下完成视觉数据。
### Innovation
本文探索了不折叠数据张量的同时采用图信息来正则化邻近条目的局部相似性，进而提出了一个基于张量积和图正则化的方法，该方法将原始问题分解为多个子问题，而不是采用传统方法中的每个张量核心。为了避免基于图正则化带来的高计算复杂度，提出了基于广义逆高斯（GIG）先验的稀疏促进概率模型，并在均值场近似下推导了推理算法。
### Conclusion
在合成数据和实际情况中，提出的基于图正则化的张量积方法显示出其优越性。
## 641. `cs.CV` - 红外图像超分辨率：系统综述及未来趋势 [PDF](https://arxiv.org/pdf/2212.12322), [HTML](https://arxiv.org/abs/2212.12322)
### Authors
Yongsong Huang,Tomo Miyazaki,Xiaofeng Liu,Shinichiro Omachi
### Background
红外（IR）图像超分辨率在计算机视觉和图像处理任务中至关重要。红外图像超分辨率的研究是深度学习发展中持续关注的一个问题。本文旨在全面概述红外图像超分辨率，包括其应用、硬件成像系统问题及其图像处理方法分类。此外，还讨论了红外图像超分辨率任务中的数据集和评估指标，并指出了当前技术的缺陷和可能的研究方向。
### Innovation
文章提供了一个全面的红外图像超分辨率视角，涵盖了应用、硬件成像系统问题、图像处理方法分类，以及数据集和评估指标，进一步指出了现有技术的不足和未来研究的潜在方向。通过保持对相关优秀工作的更新，以应对这个领域快速发展的需求。
### Conclusion
目前的技术存在一些缺陷，并且未来的研究有机会探索新的方向，以进一步提高红外图像超分辨率的效果。
## 642. `cs.CV` - Sample what you cant compress [PDF](https://arxiv.org/pdf/2409.02529), [HTML](https://arxiv.org/abs/2409.02529)
### Authors
Vighnesh Birodkar,Gabriel Barcik,James Lyon,Sergey Ioffe,David Minnen,Joshua V. Dillon
### Background
传统的自编码器在学习图像表示时，往往会生成模糊的结果。提高重构质量的一种方法是加入对抗（GAN）损失和感知损失等额外惩罚项，但这些方法缺乏严谨的理论解释。近年来，在生成模型中，扩散方法展示了生成清晰、高质量图像的能力，并且具有坚实的理论基础（从变分推断到直接研究为Fisher散度）
### Innovation
本研究结合使用自编码器表示学习与扩散方法，并且据我们所知，这是首次在基于扩散的损失下联合学习连续的编码器和解码器，从而实现出更高的压缩比和更好的生成效果。此外，该方法相比基于GAN损失的学习，在调整难度上更具优势。而且，使用该方法得到的表示更容易被潜在扩散模型建模，相比最先进的基于GAN损失的方法生成细节能力更强。因此，该方法可以生成未被压缩部分的细节，他们将其方法命名为'Sample what you can't compress'，即SWYCC方法
### Conclusion
与基于GAN的自编码器相比，这种方法在重构质量上表现出优势，并且更容易微调。此外，由于解码器是随机的，它可以生成那些在确定性的潜在表示中没有编码的细节。
## 643. `cs.CV` - Lavida-O: 弹性大规模遮蔽扩散模型以实现统一的多模态理解和生成 [PDF](https://arxiv.org/pdf/2509.19244), [HTML](https://arxiv.org/abs/2509.19244)
### Authors
Shufan Li,Jiuxiang Gu,Kangning Liu,Zhe Lin,Zijun Wei,Aditya Grover,Jason Kuen
### Background
现有的多模态遮蔽扩散模型（如MMaDa和Muddit）只能支持简单的图像级理解任务和低分辨率的图像生成。Lavida-O 提出了一种统一的多模态理解与生成模型，可以在图像级理解、对象定位、图像编辑以及高分辨率（1024px）的文本到图像合成任务上提供支持。该模型进一步结合了新颖的弹性混合转换器（Elastic-MoT）架构，使得生成更加高效和高质量，并且能够在图像生成和编辑任务中无缝提升生成质量。
### Innovation
Lavida-O 引入了新颖的弹性混合转换器（Elastic-MoT）架构，结合了轻量级的生成分支和较大的理解分支，并通过标记压缩、通用文本条件和分层采样提高了生成效率和质量。Lavida-O 还结合了规划和迭代自我反思的机制，这在图像生成和编辑任务中尤其有效。Lavida-O 在基准测试（如 RefCOCO 对象定位、GenEval 文本到图像生成和 ImgEdit 图像编辑）中的性能优于现有的自回归模型和连续扩散模型，同时在推断时提供了显著的速度提升。这些进步确立了Lavida-O 作为可扩展的多模态推理和生成新范式的地位。
### Conclusion
Lavida-O 在多个基准测试中达到了最先进的性能，表明它是实现多模态理解和生成的强大框架。其创新之处在于结合了弹性混合转换器架构、高效生成机制以及迭代自我反思策略，使其在多模态任务中表现出色。
## 644. `cs.CV` - GraphEQA: 使用3D语义场景图进行实时体态化问答 [PDF](https://arxiv.org/pdf/2412.14480), [HTML](https://arxiv.org/abs/2412.14480)
### Authors
Saumya Saxena,Blake Buchanan,Chris Paxton,Peiqi Liu,Bingqing Chen,Narunas Vaskevicius,Luigi Palmieri,Jonathan Francis,Oliver Kroemer
### Background
在体态化问答（EQA）中，代理必须探索并发展对未知环境的语义理解，以便有信心回答有关环境的问题。这一问题在机器人学中仍然是具有挑战性的，因为获得有用的语义表示、在线更新这些表示以及利用先前的世界知识进行高效规划和探索是非常困难的。
### Innovation
提出了GraphEQA，一种利用实时3D度量语义场景图（3DSGs）和任务相关图像作为多模态记忆的方法，以将视觉-语言模型（VLMs）接地执行未知环境中的EQA任务。该方法采用分层规划方法，利用3DSGs的分层性质进行结构化规划和语义导向的探索。
### Conclusion
GraphEQA在两个基准数据集HM-EQA和OpenEQA的模拟环境中进行评估，并显示出比关键基线更高的成功完成EQA任务的几率和更少的规划步骤。进一步在多个真实的家庭和办公室环境中演示了GraphEQA。
## 645. `cs.CV` - RG-Attn: Radian Glue Attention for Multi-modality Multi-agent Cooperative Perception [PDF](https://arxiv.org/pdf/2501.16803), [HTML](https://arxiv.org/abs/2501.16803)
### Authors
Lantao Li,Kang Yang,Wenqi Zhang,Xiaoxue Wang,Chen Sun
### Background
当前自主驾驶技术通过V2X通信实现多代理传感器融合，大部分方法依赖单一模态数据共享，导致在不同传感器（如激光雷达和摄像头）的跨车辆或路边单元设置中，融合性能受限。
### Innovation
提出了一种轻量级且通用的跨模态融合模块Radian Glue Attention（RG-Attn），通过基于RADIAN的注意力约束实现特征对齐，并采用统一的抽样/反演策略来优化融合性能。基于RG-Attn，构建了三个协作架构：优先通信效率的Paint-To-Puzzle (PTP)、最大灵活性的Co-Sketching-Co-Coloring (CoS-CoCo) 和最高检测精度的Pyramid-RG-Attn Fusion (PRGAF)。
### Conclusion
通过在模拟和现实数据集上进行广泛评估，展示了该框架在检测精度、灵活性和效率方面的优越性，达到了最先进的检测性能。
## 646. `cs.CV` - 任意精度和稀疏度下神经网络的鲁棒训练 [PDF](https://arxiv.org/pdf/2409.09245), [HTML](https://arxiv.org/abs/2409.09245)
### Authors
Chengxi Ye,Grace Chu,Yanfeng Liu,Yichi Zhang,Lukasz Lew,Li Zhang,Mark Sandler,Andrew Howard
### Background
量化和稀疏化操作的不连续性一直阻碍着反向传播，尤其是在超低精度和稀疏模式下。标准的直通过滤器估计器（STE）被广泛使用来解决这一问题，但其量化感知前向通路与量化不知情后向通路之间的明确定义不匹配会导致无法管理的错误，从而干扰学习过程。
### Innovation
该研究通过引入从有原则的岭回归目标中派生的去噪去量化变换解决了这一问题。这种变换使整个学习过程可以意识到并对抗由STE绕过的去量化工错误，通过创建明确的、纠正的梯度路径来完成。此外，研究还将稀疏化视为一种特殊形式的量化映射不重要的值为零，并发展了一个统一框架，使得现有模型能够在宽范围的精度和稀疏度水平上进行训练，使用现成的食谱，实现用二进制全（A1W1）和亚1位稀疏网络等其他方法无法达到的稳定训练。
### Conclusion
此方法取得了最先进的结果，并提供了一条有充分理论依据的通往超高效神经网络的道路。
## 647. `cs.CV` - 你需要360°视频才能生成3D场景 [PDF](https://arxiv.org/pdf/2504.02045), [HTML](https://arxiv.org/abs/2504.02045)
### Authors
Zhaoyang Zhang,Yannick Hold-Geoffroy,Miloš Hašan,Ziwen Chen,Fujun Luan,Julie Dorsey,Yiwei Hu
### Background
生成3D场景仍然是一个具有挑战性的问题，主要是因为缺乏可用的场景数据。现有的大多数方法只能生成部分场景，提供的导航自由度有限。
### Innovation
本文提出了WorldPrompter，这是一种生成管道，可以从文本提示生成可走动的3D场景。具体来说，它利用条件360°全景视频生成器生成128帧视频，模拟人在虚拟环境中的行走和拍摄。生成的视频通过快速前馈的3D重建器重建为高斯点云，从而提供真正的可走动的3D体验。该模型通过混合图像和视频数据进行训练，表现出色，实现了高度的空间和时间一致性，进一步通过高精度的全景高斯点云重建和导航提升了质量。
### Conclusion
实验结果表明，我们的全景视频生成模型能够实现静态场景的高度空间和时间一致性。这通过94.6%的COLMAP匹配率得到验证，使得全景高斯点云重建的质量更高，并提高了在场景中的导航体验。本方法的性能优于现有的360°视频生成器和3D场景生成模型。
## 648. `cs.CV` - VLM 见，机器人做：通过视觉语言模型从人类示范视频到机器人行动规划 [PDF](https://arxiv.org/pdf/2410.08792), [HTML](https://arxiv.org/abs/2410.08792)
### Authors
Beichen Wang,Juexiao Zhang,Shuwen Dong,Irving Fang,Chen Feng
### Background
视觉语言模型（VLMs）近年来在机器人领域得到应用，因其在常识推理和泛化能力方面的优势。现有的工作使用VLM从自然语言指令生成任务和运动规划，以及为机器人学习模拟训练数据。本文进一步探索了使用VLM解析人类示范视频，并为机器人生成任务规划的方法。
### Innovation
本文提出了一种命名为SeeDo的方法，将关键帧选择、视觉感知和VLM推理结合进管道中，使VLM能够“看到”人类示范并解释相应的计划给机器人执行。通过收集包含三家不同类别的拾取和放置操作的长时序人类示范视频，并设计了综合的评估指标来测试SeeDo在多个基线，包括最新的视频输入VLM，的表现。实验表明SeeDo在性能上更优。并且进一步将生成的任务计划部署在仿真环境和真实机器人手臂上。
### Conclusion
实验验证了SeeDo的优越性能，并在仿真环境和真实机器人手臂上进行了部署, 表明了该方法的有效性和实用性。
## 649. `cs.CV` - LEMUR 神经网络数据集：迈向无缝自动机器学习 [PDF](https://arxiv.org/pdf/2504.10552), [HTML](https://arxiv.org/abs/2504.10552)
### Authors
Arash Torabi Goodarzi,Roman Kochnev,Waleed Khalid,Hojjat Torabi Goudarzi,Furui Qin,Tolgay Atinc Uzun,Yashkumar Sanjaybhai Dhameliya,Yash Kanubhai Kathiriya,Zofia Antonina Bentyn,Dmitry Ignatov,Radu Timofte
### Background
神经网络是现代人工智能的核心，但设计、评估和比较它们仍需大量人力。虽然有大量的训练数据集供使用，但对于模型本身却缺乏标准化的集合。因此，本文介绍了一个名为LEMUR的开源数据集和框架，它提供了一个包含广泛任务（如分类、分割、检测和自然语言处理）的PyTorch神经网络集合。每个模型都遵循统一的模板，并将配置和结果存储在一个结构化的数据库中，以确保一致性和可重复性。LEMUR还集成了Optuna的自动化超参数优化工具，提供了统计分析和可视化工具，并通过API无缝访问性能数据。
### Innovation
LEMUR通过标准化实现和统一评估，提供了一套开源PyTorch神经网络数据集和框架。其特色包括：(1) 每个模型遵循统一模板；(2) 自动化超参数优化；(3) 统计分析和可视化工具；(4) 提供用于访问性能数据的API；(5) 兼容性良好的框架设计，允许研究者轻松扩展模型、数据集或新增指标。
### Conclusion
LEMUR旨在加速自动化机器学习研究、简化基准测试，并降低大规模神经网络实验的门槛。此外，LEMUR及其实用程序插件在MIT许可下发布，旨在支持其采用和协作。
## 650. `cs.CV` - CellCLIP -- 通过文本引导对比学习学习细胞绘画中的扰动效果 [PDF](https://arxiv.org/pdf/2506.06290), [HTML](https://arxiv.org/abs/2506.06290)
### Authors
Mingyu Lu,Ethan Weinberger,Chanwoo Kim,Su-In Lee
### Background
高内容筛选（HCS）实验基于高通量显微技术如细胞绘画，能够以前所未有的规模研究细胞形态响应于不同扰动的变化。收集到的数据有助于更好地理解不同扰动与其对细胞状态影响的关系。目标是利用跨模态对比学习的方法建立统一的潜在空间，使不同类型的扰动与其相应的形态学效应对齐，但由于细胞绘画图像与自然图像语义上的差异，以及不同类别的扰动（如小分子与CRISPR基因敲除）在单一潜在空间中的表示困难，此类方法在HCS数据应用上具有挑战。
### Innovation
提出了CellCLIP框架，这是一种针对HCS数据的跨模态对比学习方法。CellCLIP利用预训练的图像编码器和一套新颖的通道编码方案来更好地捕捉图像嵌入中不同显微成像通道之间的关系，同时利用自然语言编码器来表示扰动。该框架在跨模态检索和具有生物意义的下游任务上表现更好，计算时间也显著减少。
### Conclusion
CellCLIP框架在跨模态检索和具有生物学意义的下游任务上表现出色，同时实现了显著的计算时间减少，优于当前开源模型的表现。
## 651. `cs.CV` - SEM：增强空间理解以实现稳健的机器人操作 [PDF](https://arxiv.org/pdf/2505.16196), [HTML](https://arxiv.org/abs/2505.16196)
### Authors
Xuewu Lin,Tianwei Lin,Lichao Huang,Hongyu Xie,Yiwei Jin,Keyu Li,Zhizhong Su
### Background
在机器人操作中，一个关键挑战是开发具有强大空间理解能力的策略模型，包括处理3D几何、物体关系以及机器人本体的能力。现有方法往往在这方面表现不佳：3D点云模型缺乏语义抽象，而2D图像编码器在空间推理方面存在问题。因此，需要一种新的方法来解决这些问题，以实现更稳健和可泛化的机器人操作性能，适用于各种任务。
### Innovation
提出了一种名为SEM的空间增强操作模型(SEM: Spatial Enhanced Manipulation)，这是一种基于扩散的新型策略框架，从两个互补的角度增强空间理解。包括一个空间增强器，通过加入3D几何上下文来增强视觉表示，以及一个通过基于图表的关节依赖建模来捕获本体感知结构的机器人状态编码器。通过整合这些模块，SEM可以显著提升空间理解能力，从而在多种任务中实现稳健和可泛化的机器人操作，超越现有基准模型。
### Conclusion
通过引入SEM模型，该框架显著提高了空间理解能力，能够在多种任务中实现稳健和可泛化的机器人操作，超出现有基线方法的表现。
## 652. `cs.CV` - EDBenchmark：用于分子建模的大规模电子密度数据 [PDF](https://arxiv.org/pdf/2505.09262), [HTML](https://arxiv.org/abs/2505.09262)
### Authors
Hongxin Xiang,Ke Li,Mingquan Liu,Zhixiang Cheng,Bin Yao,Wenjie Du,Jun Xia,Li Zeng,Xin Jin,Xiangxiang Zeng
### Background
目前的分子机器学习力场（MLFFs）主要关注于原子、分子及简单量子化学性质（如能量和力）的学习，但忽略了电子密度（ED）$rho(r)$在准确理解分子力场（MFFs）中的重要性。电子密度描述的是电子在特定位置围绕原子或分子出现的概率，根据Hohenberg-Kohn定理，它唯一地决定了多粒子系统的基态特性（如能量、分子结构等）。然而，计算电子密度依赖于耗时的第一性原理密度泛函理论（DFT），这导致了大型电子密度数据的缺乏，并限制了其在MLFFs中的应用。因此，缺乏大量的高质量电子密度数据是分子建模中的一个主要挑战。
### Innovation
本文介绍了EDBenchmark，这是一个大型、高质量的电子密度数据集，旨在推动电子尺度的学习研究。EDBenchmark基于PCQM4Mv2构建，提供了覆盖330万分子的准确的电子密度数据。为了全面评估模型理解并利用电子信息的能力，设计了一整套以电子密度为中心的基准任务，涵盖预测、检索和生成三个方面。实验表明，从EDBenchmark学习不仅是可行的，而且能达到高精度。此外，表明基于学习的方法不仅能以相似的精度高效计算电子密度，还能显著降低相对于传统DFT计算的成本。因此，EDBenchmark的数据和基准将完全免费提供，以便为电子密度驱动的药物发现和材料科学建立坚实的基础。
### Conclusion
EDBenchmark为分子模型提供了大规模且高质量的电子密度数据集，促进研究向电子层面推进。同时，基于电子密度的数据驱动方法能够在高精度计算电子密度的同时显著降低成本，为药物发现和材料科学提供强有力的支持。
## 653. `cs.CV` - SoFar: 语言导向的方位连接空间推理与物体操作 [PDF](https://arxiv.org/pdf/2502.13143), [HTML](https://arxiv.org/abs/2502.13143)
### Authors
Zekun Qi,Wenyao Zhang,Yufei Ding,Runpei Dong,Xinqiang Yu,Jingwen Li,Lingyun Xu,Baoyu Li,Xialin He,Guofan Fan,Jiazhao Zhang,Jiawei He,Jiayuan Gu,Xin Jin,Kaisheng Ma,Zhizheng Zhang,He Wang,Li Yi
### Background
当前的空间推理研究虽然在物体定位关系上取得了进展，但经常忽略了物体姿态这一6-DoF微粒操作中的关键因素。传统的姿态表示依赖于预定义的坐标系或模板，这限制了泛化能力和语义关联。
### Innovation
本文引入了语义姿态的概念，按照自然语言描述（如USB的“插入口”方向或杯子的“手柄”方向）来描述物体的姿态。为此，作者构建了OrienText300K大规模数据集，并开发了PointSO，一种用于零样本语义姿态预测的一般模型。通过将语义姿态整合进多模态视觉（VLM）代理中，SoFar框架实现了6-DoF空间推理并通过生成机器人动作。
### Conclusion
广泛的实验证明了SoFar的有效性和泛化能力，例如在Open6DOR上具有零样本48.7%的成功率，在SIMPLER-Env上具有74.9%的零样本成功率。
## 654. `cs.CV` - X-Part: 高保真且结构一致的形状分解 [PDF](https://arxiv.org/pdf/2509.08643), [HTML](https://arxiv.org/abs/2509.08643)
### Authors
Xinhao Yan,Jiachen Xu,Yang Li,Changfeng Ma,Yunhan Yang,Chunshi Wang,Zibo Zhao,Zeqiang Lai,Yunfei Zhao,Zhuo Chen,Chunchao Guo
### Background
生成部分级别的3D形状对于下游应用如网格重拓补、UV贴图和3D打印至关重要。然而，现有的基于部分的生成方法往往缺乏足够的可控性，并且在语义上有缺陷。因此，需要一种新的方法来实现高几何保真度且结构上连贯的部分级形状分解。
### Innovation
X-Part是一种可控制的生成模型，设计用于将整个3D对象分解成具有高几何保真度且语义上连贯的部分。它通过使用边界框作为提示进行部分生成，并注入点级语义特征以进行有意义的分解。此外，X-Part设计了一个可编辑的生成流程，以实现交互式部分生成。
### Conclusion
广泛的实验结果表明，X-Part在部分级别形状生成方面达到了最先进的性能。这项工作建立了生产可用、可编辑且结构健全的3D资产创建的新范式。代码将公开用于学术研究。
## 655. `cs.CV` - 解析视觉语言模型中神经元的功能 [PDF](https://arxiv.org/pdf/2502.18485), [HTML](https://arxiv.org/abs/2502.18485)
### Authors
Jiaqi Xu,Cuiling Lan,Yan Lu
### Background
开放源代码的视觉语言模型（VLMs）近年来迅速增长，推动了这些模型在多个领域中的各种应用。确保这些模型的透明性和可解释性对于促进可信和负责任的人工智能系统至关重要。因此，本研究旨在深入剖析VLMs的内部机制，以解释个体神经元的功能。通过观察神经元对输入视觉标记和文本标记的激活情况，发现了不同类型的神经元，包括仅处理视觉信息的神经元、仅处理文本信息的神经元，以及同时处理视觉和文本信息的多模态神经元。研究还构建了一个自动化解释神经元的框架，借助GPT-4o进行辅助。同时，为了评估视觉神经元解释的可靠性，提出了激活模拟器。通过LLaVA这一代表性模型进行的统计分析，揭示了不同类型神经元的行为和特征。
### Innovation
本研究创新之处在于通过观察神经元激活情况，明确了三种不同类型神经元的功能，以及构建了一种自动化解释神经元的方法，并提出了评估视觉神经元解释可靠性的激活模拟器。此外，通过LLaVA模型的分析，揭示了不同类型神经元的行为特征。
### Conclusion
研究表明，现有的VLMs中存在专门处理视觉信息、文本信息，以及同时处理两者信息的神经元。通过该研究，我们可以更好地理解VLMs的工作原理，并提升这些模型的透明性和可解释性，进而促进更可信和负责任的AI系统的开发。
## 656. `cs.CV` - 基于高分辨率体外MRI指导上采样策略的体素级详细分割在内侧颞叶亚区成像生物标志物中的应用 [PDF](https://arxiv.org/pdf/2504.18442), [HTML](https://arxiv.org/abs/2504.18442)
### Authors
Yue Li,Pulkit Khandelwal,Long Xie,Laura E. M. Wisse,Amanda E. Denning,Christopher A. Brown,Emily McGrew,Sydney A. Lim,Niyousha Sadeghpour,Sadhana Ravikumar,Ranjit Ittyerah,Eunice Chung,Daniel T. Ohm,Nidhi S. Mundada,María Mercedes Íñiguez de Onzoño Martín,María del Mar Arroyo Jiménez,Monica Mũnoz,Maria del Pilar Marcos Rabal,David J. Irwin,Edward B. Lee,Ricardo Insausti,Sandhitsu R. Das,David A. Wolk,Paul A. Yushkevich
### Background
内侧颞叶（MTL）在阿尔茨海默病（AD）早期阶段受到广泛且非均一的影响。来自磁共振成像（MRI）的MTL的区域形态学指标是诊断AD及相关疾病（如ADRD）的支持性特征。不同MRI模态在MTL形态学中具有不同的优势。不同层的海马体亚区域更适合采用各向异性T2加权（T2w）MRI进行分割，而各向同性的T1加权（T1w）MRI在进行额外海马区厚度计算时更为有利，因为它具有稳定的质量和各向同性分辨率。文章拟提出一种多模态MTL分割算法，通过将这两种模态转换为近乎各向同性的体素空间，实现了两者的统一。
### Innovation
文章提出了一种基于高分辨率体外9.4T MRI的上采样模型进行体素级详细的内侧颞叶亚区分割的方法，并结合非局域均值上采样技术，构建了近乎各向同性的T1w和T2w MTL亚区分割训练集，使用nnUNet模型训练该多模态分割算法。相比传统的在不同分辨率下工作的模型，所提出的模型提取的形态学生物标志物能够更有效地区分轻度认知障碍患者与认知正常个体，并显示出更好的纵向稳定性。这表明，接近各向同性的T1w和T2w MRI的生物标志物对神经退行性疾病诊断和疾病进展监控具有显著的潜在价值。
### Conclusion
所提出的方法揭示了利用接近各向同性的T1w和T2w MRI提取的生物标志物在ADRD诊断和疾病进展监测方面的显著优势。
## 657. `cs.CV` - HAZEMATCHING: 遮罩匹配：利用引导条件流匹配去雾霾光学显微镜图像 [PDF](https://arxiv.org/pdf/2506.22397), [HTML](https://arxiv.org/abs/2506.22397)
### Authors
Anirban Ray,Ashesh,Florian Jug
### Background
荧光显微镜在生命科学领域取得了重大进展。虽然高端共聚焦显微镜能够过滤掉焦外光，但较便宜且更易于获取的显微镜模式，如宽视野显微镜，无法做到这一点，从而导致模糊的成像数据。计算机去雾霾技术试图兼有这两种模式的优势，即提升成本效益但保持清晰的图像表现。感知失真权衡告诉我们，可以在数据保真度，如低均方误差或高峰值信噪比，或者以感知度量如LPIPS或FID衡量的数据真实性之间进行优化。现有方法要么优先考虑保真度而牺牲真实性，要么产生感知上令人信服但缺乏定量准确性结果。本文提出了一种名为HazeMatching的迭代方法，旨在在去雾霾结果的保真度与个体预测的真实感之间找到平衡。通过适应条件流匹配框架，我们的方法利用模态观测引导生成过程中的条件流速场，从而评估其在5个数据集上的表现，包括合成和真实数据，评估失真和感知质量
### Innovation
我们提出了一种名为HazeMatching的新型去雾霾方法，强调保真度和真实性的平衡。通过将条件流匹配框架与模态观测引导相结合，HazeMatching能够在不依赖显式退化操作的情况下，有效平衡量化准确性和感知真实性。该方法在7个基线方法的比较中表现出一致的平均平衡效果，并通过校准分析展示了预测的一致性。此外，HazeMatching的公开数据和代码将在一种宽松的许可证下提供
### Conclusion
实验结果显示，HazeMatching方法在不同数据集上实现了稳健的数据保真度和感知真实性的平衡。方法独特之处在于它不需要显式退化操作的存在，使其能够轻松应用于实际显微镜数据。该研究为光学显微镜图像的高质量去雾霾提供了新途径，并且其数据和代码将公开供其他研究者参考
## 658. `cs.LG` - Wavelet Fourier Diffuser: 频率感知的扩散模型在强化学习中的应用 [PDF](https://arxiv.org/pdf/2509.19305), [HTML](https://arxiv.org/abs/2509.19305)
### Authors
Yifu Luo,Yongzhe Chang,Xueqian Wang
### Background
扩散概率模型在离线强化学习中表现出显著的潜力，通过直接建模轨迹序列取得了显著效果。然而，现有的方法主要关注时间域特征而忽视了频率域特征，这导致了频率偏移并影响了性能，根据我们的观察。因此，现有方法主要集中在时间域特征上，而频率域特征的处理相对不足，从而影响了强化学习的性能。
### Innovation
本文从频率域的新视角研究了RL问题。首先观察到仅时间域的方法无意中引入了低频成分的频率偏移，导致轨迹不稳定性和性能下降。为此，本文提出了一种新的基于扩散的RL框架——WFDiffuser，它整合了离散小波变换来将轨迹分解为低频和高频成分。为了进一步增强每个成分的扩散建模，WFDiffuser采用了短时傅里叶变换和互注意力机制来提取频率域特征并促进跨频率互动。实验结果表明，WFDiffuser有效缓解了频率偏移，使得轨迹更加平滑且稳定，决策性能优于现有方法。
### Conclusion
广泛的实验证明，WFDiffuser能够有效缓解频率偏移，产生更平滑、更稳定的轨迹，并在决策性能上优于现有方法。
## 659. `cs.CV` - 基于高斯过程概念归属的人机可理解点云注册不确定性解释 [PDF](https://arxiv.org/pdf/2509.18786), [HTML](https://arxiv.org/abs/2509.18786)
### Authors
Johannes A. Gaus,Loris Schneider,Yitian Shi,Jongseok Lee,Rania Rayyes,Rudolph Triebel
### Background
本文讨论了点云注册问题，现有方法如ICP在传感器噪声、姿态估计误差和由于遮挡造成的部分重叠等不确定性下表现不佳。文章提出了一个新的方法：高斯过程概念归属（GP-CA），该方法不仅能量化注册不确定性，还能通过归因于已知的注册问题中的误差源来解释不确定性。该方法利用主动学习来发现新的不确定性来源，通过查询信息实例来发现新的不确定性来源。这种方法通过在三个公开可用的数据集和实际的机器人实验中进行了验证。详细的消融实验证明了我们设计方案的选择。该方法在运行时间和高效采样学习方面优于其他最先进的方法，且准确性高。实际实验清楚地展示了其适用性。视频展示了GP-CA可以使机器人感知更加稳健，实现有效故障恢复行为。
### Innovation
开发了一种新的方法高斯过程概念归属（GP-CA），该方法不仅仅量化了点云注册的不确定性，还通过归因于已知的误差源来解释不确定性。该方法利用主动学习来发现新的不确定性来源，并在三个方面优于其他最先进的方法：运行时间、高效学习能力和高准确性。
### Conclusion
本文的方法通过实验验证和实际应用，展现出其在点云注册中的优越性能，特别是在实际机器人任务中证明了其高鲁棒性和有效性。
## 660. `cs.CV` - MOIS-SAM2: 基于示例的Segment Anything Model 2在全身MRI中多病灶交互动态分割神经纤维瘤 [PDF](https://arxiv.org/pdf/2509.19277), [HTML](https://arxiv.org/abs/2509.19277)
### Authors
Georgii Kolokolnikov,Marie-Lena Schmalhofer,Sophie Goetz,Lennart Well,Said Farschtschi,Victor-Felix Mautner,Inka Ristow,Rene Werner
### Background
神经纤维瘤病1型是一种遗传性疾病，表现为身体各部位广泛出现的神经纤维瘤。全身MRI（WB-MRI）是用于检测和长期监测这些肿瘤生长的标准临床方法。现有的交互式分割方法难以兼顾高病变精确度和对数百个病变的大规模处理。
### Innovation
本文提出了MOIS-SAM2模型，这是一种基于示例的多物体交互式分割模型，该模型在现有最先进的、基于变换器的可提示Segment Anything Model 2（SAM2）基础上增加了示例基础的语义传播。该模型在84名神经纤维瘤病1型患者中119次WB-MRI扫描数据集上进行训练和评估，展示了在不同扫描条件下的良好表现，包括良好的域转移鲁棒性和对肿瘤较少区域的性能增强。
### Conclusion
MOIS-SAM2能够以最少用户输入实现高效的多病变交互式神经纤维瘤分割，具有强泛化能力，支持临床工作流程集成。
## 661. `cs.LG` - 使用深度学习的反洗钱系统 [PDF](https://arxiv.org/pdf/2509.19359), [HTML](https://arxiv.org/abs/2509.19359)
### Authors
Mashkhal Abdalwahid Sidiq,Yimamu Kirubel Wondaferew
### Background
反洗钱（AML）在全球金融行业中发挥着重要作用，但传统AML系统存在高虚假阳性率和识别复杂洗钱计划能力不足的问题。因此，本文探讨了利用深度学习方法检测金融交易网络中的洗钱活动，旨在证明其可以作为一种补充甚至替代规则基础系统和传统AML系统的工具。
### Innovation
本文提出了一种利用链接分析和深度学习技术的先进AML系统，重点使用了中心性算法如度中心性、接近中心性、介数中心性和PageRank。这些算法通过分析金融交易网络中的影响力和互联性来增强系统识别可疑活动的能力。此外，研究结果表明使用GCN模型的新版本更为有效，适合连接结构化的数据，这意味着在分析交易或账户时需考虑到其金融环境。同时，本文还探讨了将深度学习和中心性算法等新兴技术与反洗钱努力结合的前景，这有望提升AML系统的有效性。
### Conclusion
反洗钱努力在全球金融领域的意义得到了强调，传统AML系统的局限性也得到了讨论。研究结果表明，使用基于链接分析和深度学习的新系统将提高反洗钱的效率。未来的研究可以深入探讨如何更好地整合这些新兴技术，以进一步增强金融系统的反洗钱能力。
## 662. `cs.LG` - 使用自适应神经模糊推理系统分析信用卡欺诈对美国家庭经济波动的影响 [PDF](https://arxiv.org/pdf/2509.19363), [HTML](https://arxiv.org/abs/2509.19363)
### Authors
Zhuqi Wang,Qinghe Zhang,Zhuopei Cheng
### Background
随着信用卡欺诈问题的增长，它成为美国家庭金融状况的主要威胁，导致家庭经济行为不可预测的变化。为解决此问题，本文提出了一种新的混合分析方法，使用改进的ANFIS。该模型提出了一系列改进的ANFIS框架，并应用了多分辨率小波分解模块和时间注意力机制，通过这种机制可以直接获取多尺度的经济行为模式的权重，增强潜在异常活动的捕捉力和长期时间依赖性，提高模糊推理阶段相关性评估的有效性，从而解决了传统ANFIS固有的输入输出关系固定的问题。
### Innovation
提出了一种新的自适应ANFIS模型，结合了小波分解、多分辨率分析和时间注意力机制，通过对历史交易数据和宏观经济指标进行离散小波变换来生成局部经济冲击信号，并将转换后的特征输入基于Takagi-Sugeno模糊规则的自适应高斯隶属函数的深层模糊规则库中。与经典ANFIS相比，该模型通过模块化训练程序实现了模糊规则激活、小波基选择和时间相关权重的集成，降低了均方根误差17.8%。
### Conclusion
提出的混合模型结合多分辨率小波变换的局部信息和宏观信息，以及自适应时间注意力机制，提高了欺诈检测的准确性。实验结果表明，该模型在预测信用卡欺诈方面优于局部神经模糊模型和传统的LSTM模型。
## 663. `cs.CV` - 在线语言点积 [PDF](https://arxiv.org/pdf/2503.09447), [HTML](https://arxiv.org/abs/2503.09447)
### Authors
Saimouli Katragadda,Cho-Ying Wu,Yuliang Guo,Xinyu Huang,Guoquan Huang,Liu Ren
### Background
为了让AI代理能够无缝地与人类和3D环境进行交互，它们不仅需要准确地感知3D世界，还需要将人类语言与3D空间表示有效对齐。尽管先前的工作通过将语言特征整合到几何详细3D场景表示中，使用3D高斯点积（Gaussian Splatting, GS）取得了显著进展，但这些方法依赖于对每个输入图像的语言特征进行复杂的离线预处理，限制了对新环境的适应性。
### Innovation
本文引入了在线语言点积，这是第一个在3DGS-SLAM系统中实现在线、接近实时的大词汇量语言映射的框架，无需预生成语言特征。关键挑战在于高效地将高维语言特征融合到3D表示中，同时平衡计算速度、内存使用、渲染质量和开放式词汇能力。为此我们设计了（1）一个高分辨率CLIP嵌入模块，在每帧18ms内生成详细的语言特征图；（2）一个两阶段在线自动编码器，将768维CLIP特征压缩到15维，同时保留开放式词汇能力；（3）一种颜色-语言分离优化方法，提高渲染质量。
### Conclusion
实验结果表明，我们在线方法不仅在准确性上超过了最先进的离线方法，还实现了超过40倍效率的提升，展示了动态和交互式AI应用的潜在可能性。
## 664. `cs.LG` - 基于表示的广泛幻觉检测器无法跨分布外泛化 [PDF](https://arxiv.org/pdf/2509.19372), [HTML](https://arxiv.org/abs/2509.19372)
### Authors
Zuzanna Dubanowska,Maciej Żelaszczyk,Michał Brzozowski,Paolo Mandica,Michał Karpowicz
### Background
本文批判性地评估了当前最先进的幻觉检测技术的效果。研究发现，在RAGTruth数据集上的性能很大程度上是由与数据的虚假相关性驱动的。在控制这种影响后，最先进的技术的表现等同于监督线性探针，同时需要跨不同数据集进行广泛的超参数调整。当前的研究表明，跨分布外泛化仍然是一个未解决的问题，分析的方法性能接近随机水平。
### Innovation
本文提出了一套幻觉检测及其评估的指南。
### Conclusion
基于表示的广泛幻觉检测器无法实现跨分布外的泛化能力，所有分析的方法性能都接近随机水平。
## 665. `cs.LG` - DeepACTIF: 通过神经序列模型激活轨迹实现高效特征归因 [PDF](https://arxiv.org/pdf/2509.19362), [HTML](https://arxiv.org/abs/2509.19362)
### Authors
Benedikt W. Hosp
### Background
特征归因对于解释深度学习模型至关重要，尤其是在健康护理、生物识别和人机交互等时间序列领域。然而，标准的归因方法如集成梯度或SHAP在实时应用中计算密集，不太适用。
### Innovation
DeepACTIF是一个轻量且架构感知的特征归因方法，通过利用序列模型的内部激活来高效估算特征重要性。该方法针对LSTM网络引入了一个逆加权聚合方案，强调了时间步长中的激活稳定性和大小。实验结果表明，DeepACTIF在保留模型预测性能的同时，准确性和统计稳健性也显著优于SHAP、IG和DeepLIFT等现有方法。
### Conclusion
实验结果表明，DeepACTIF不仅能显著降低计算时间和提高内存使用效率，还能在使用最高排名特征的情况下保持模型准确性。因此，DeepACTIF适合在边缘设备（如移动XR头盔或嵌入式健康监测设备）上实现实时可解释性。
## 666. `cs.LG` - 解决RAG系统的时效性问题：简单的时效性先验和启发式趋势检测的局限性 [PDF](https://arxiv.org/pdf/2509.19376), [HTML](https://arxiv.org/abs/2509.19376)
### Authors
Matthew Grofsky
### Background
该论文提供了关于解决RAG（ Retrieval-Augmented Generation，检索增强生成）系统中的时效性问题的背景信息。研究集中在使用两种方法（一种是简单的时效性先验方法，另一种是主题演化的聚类启发式方法）在网络安全领域来处理时效失败。
### Innovation
该创新在于提出了一种简单易行的方法，即“时效性先验方法”，并指出与之形成对比的是基于启发式的趋势检测方法存在一定的局限性，不能完全解决此类问题，需要更复杂的方法来检测趋势变化。
### Conclusion
研究结论表明，虽然简单的时效性先验方法在新的数据更新准确性上表现极佳，但是复杂的趋势检测需要超越简单启发式的方法，以更好地适应不断变化的网络威胁环境。
## 667. `cs.LG` - 从观察学习：近年来进展的综述 [PDF](https://arxiv.org/pdf/2509.19379), [HTML](https://arxiv.org/abs/2509.19379)
### Authors
Returaj Burnwal,Hriday Mehta,Nirav Pravinbhai Bhatt,Balaraman Ravindran
### Background
模仿学习（IL）算法提供了一种高效的方式，通过模仿专家的行为来训练智能体，而无需使用奖励函数。相比IL，近年较为关注从观察学习（LfO）或仅状态模仿学习（SOIL），其中模仿器仅能访问专家的状态访问信息，而不必获得专家的具体动作。这种方法解决了获取专家详细动作信息在实际应用中的难题。
### Innovation
本文提出了一种从观察学习的框架，并用该框架来调研和分类现有的从观察学习方法，同时将此类方法与离线强化学习、基于模型的强化学习和层次化强化学习等领域联系起来。此外，本文还通过该框架识别出了开放性问题，并建议了未来的研究方向。
### Conclusion
总体而言，本文对从观察学习领域的最新进展进行了全面的综述，为该领域的进一步研究指明了方向。
## 668. `cs.LG` - TensLoRA: 张量替代方法用于低秩适应 [PDF](https://arxiv.org/pdf/2509.19391), [HTML](https://arxiv.org/abs/2509.19391)
### Authors
Axel Marmoret,Reda Bensaid,Jonathan Lys,Vincent Gripon,François Leduc-Primeau
### Background
低秩适应（LoRA）通常通过在注意力投影中增加可训练的低秩矩阵来有效地适应Transformer。虽然这些矩阵对于每个注意力投影（查询、密钥和值）以及每个层是独立的，但最近有一些扩展方法考虑了联合、张量基适应，但这些方法仅限于有限的形式且缺乏系统性框架。
### Innovation
TensLoRA引入了一个统一的框架，将LoRA更新汇聚为高阶张量，并建模了一个广泛的张量基低秩适应家族。该形式化方法扩展了现有的张量基方法，并使压缩率能够针对特定模式进行定制，从而根据模态和任务调整参数预算。
### Conclusion
实验在视觉和语言基准上显示，张量构建直接对性能产生影响，在相似的参数计数下有时甚至优于标准LoRA。
## 669. `cs.LG` - 使用近似贝叶斯计算量化大型语言模型的不确定性 [PDF](https://arxiv.org/pdf/2509.19375), [HTML](https://arxiv.org/abs/2509.19375)
### Authors
Mridul Sharma(1),Adeetya Patel(1),Zaneta D' Souza(1),Samira Abbasgholizadeh Rahimi(1 and 3),Siva Reddy(2 and 3),Sreenath Madathil(1) ((1) Faculty of Dental Medicine and Oral Health Sciences, McGill University, Montreal, Canada (2) School of Computer Science, McGill University, Montreal, Canada (3) Mila-Quebec Artificial Intelligence Institute, Montreal, Canada)
### Background
尽管大型语言模型（LLMs）在许多领域得到了广泛应用，但它们在表达不确定性方面往往表现不佳，这对于在临床诊断等高风险和关键安全领域的可靠部署构成了挑战。现有的标准基线方法，如模型概率和启发式概率，提供了过于自信且校准不好的估计。
### Innovation
本文提出了近似贝叶斯计算（ABC），这是一种基于似然推理的贝叶斯推断方法，将LLMs视为随机模拟器，用于推断预测概率的后验分布。该方法在两个临床相关的基准上得到了评估：一个合成的口腔病变诊断数据集和公开的GretelAI症状对诊断数据集。与标准基线相比，该方法在准确性和校准方面表现更好。
### Conclusion
与标准基线方法相比，该方法在准确率上提高了最多46.9%，减少了布赖尔分数74.4%，并通过预期校准误差（ECE）和预测熵提高了校准水平。
## 670. `cs.LG` - OmniFed: 从边缘到HPC的可配置联邦学习模块化框架 [PDF](https://arxiv.org/pdf/2509.19396), [HTML](https://arxiv.org/abs/2509.19396)
### Authors
Sahil Tyagi,Andrei Cozma,Olivera Kotevska,Feiyi Wang
### Background
联邦学习（FL）对于边缘计算和高性能计算（HPC）至关重要，因为在这些场景中数据是分散的且隐私保护需求高。现有的联邦学习系统需要在配置、编排、通信和训练逻辑之间找到平衡，以适应不同的部署需求和安全要求，但这往往导致系统过于复杂且难以维护。OmniFed框架旨在解决这些问题，通过模块化的设计实现不同层面的解耦，确保核心系统的完整性和灵活性，同时支持不同的拓扑结构和混合通信协议，并提供可选的隐私保护机制和压缩策略，从而优化不同环境下的部署和性能。
### Innovation
OmniFed框架提供了一个模块化的解决方案，它能够通过解耦配置、编排、通信和训练逻辑来简化联邦学习的部署。框架支持配置驱动的原型设计和代码级别的定制，允许用户根据需要覆盖和自定义逻辑。它还支持多种拓扑结构，混合通信协议，并嵌入了流行的训练算法和可选的隐私机制如差异隐私（DP）、同态加密（HE）和安全聚合（SA），以及压缩策略。这些特性通过清晰定义的扩展点提供给用户，确保在各种配置和隐私要求下能够灵活地定制和扩展系统的核心功能，同时保持核心系统的完整性。OmniFed通过统一的平台简化了跨异构环境的联邦学习部署。
### Conclusion
研究通过多个模型和算法来衡量不同性能指标，结果表明，将拓扑配置、混合通信协议和可插拔模块统一在一个栈中，优化了各种环境下的部署和性能，OmniFed框架证明了其在保障系统灵活性和性能的同时，方便了复杂联邦学习系统的开发和应用。
## 671. `cs.LG` - 在统计和深度学习模型中分析概率电价预测中的不确定性量化 [PDF](https://arxiv.org/pdf/2509.19417), [HTML](https://arxiv.org/abs/2509.19417)
### Authors
Andreas Lebedev,Abhinav Das,Sven Pappert,Stephan Schlüter
### Background
精确的概率预测对于能源风险管理至关重要，并且存在多种统计和机器学习模型用于此目的。这些概率模型必须包含不确定性量化，但大多数模型没有完全捕捉到不确定性，不确定性来自数据、模型选择和分布选择等多个方面。本研究考察了在德国市场用于电价预测的最新统计和深度学习概率预测模型中的不确定性量化。
### Innovation
研究将深度分布神经网络（DDNNs）与贝叶斯化方法（如蒙特卡洛丢弃和内涵预测）相结合以应对不确定性，并比较了LASSO估计自回归（LEAR）方法与其他不确定性量化技术（如分位数回归平均、GARCH模型）的性能。结果显示，在多种性能指标下，基于LEAR的模型在概率预测方面表现良好，尤其是结合了均值预测和概率预测的模型。研究表明，加权考虑数据和模型不确定性对改进预测特别有益，而使用内涵预测捕捉到的不确定性最强。
### Conclusion
在广泛的研究中，研究发现所有考虑的模型都表现得十分竞争力，但是它们在不同性能度量标准下的相对性能取决于点预测和概率预测的选择。
## 672. `cs.LG` - THINNs: 热力学导向的神经网络 [PDF](https://arxiv.org/pdf/2509.19467), [HTML](https://arxiv.org/abs/2509.19467)
### Authors
Javier Castro,Benjamin Gess
### Background
物理导向的神经网络（PINNs）是一种深度学习模型，通过训练神经网络以最小化偏微分方程（PDEs）的残差来近似解PDEs。本文聚焦于非平衡波动系统的PINNs应用，提出了一个与波动结构一致的物理导向损失惩罚方法，该方法由大偏差原则描述。
### Innovation
提出了一种新的THINNs（热力学导向的神经网络）模型，其惩罚项选择了惩罚不可能偏离，而不是通过直觉选择。THINNs通过建立后验分析估计和提供新的惩罚策略的实证比较来增强热力学一致性。
### Conclusion
通过分析THINNs的后验估计和与传统惩罚策略的比较，验证了THINNs模型的热力学一致性扩展，并展示了其在非平衡波动系统中的有效性。
## 673. `cs.LG` - TimeMosaic: 受时序异质性引导的自适应粒度片段和段内解码的时间序列预测 [PDF](https://arxiv.org/pdf/2509.19406), [HTML](https://arxiv.org/abs/2509.19406)
### Authors
Kuiye Ding,Fanda Fan,Chunyi Hou,Zheya Wang,Lei Wang,Zhengxin Yang,Jianfeng Zhan
### Background
多元时间序列预测在金融、交通、气候和能源等领域至关重要。现有的基于片段的方法通常采用固定长度的分割，这忽略了局部时间动态的异质性和预测解码的异质性。这样的设计在信息密集区域丢失了细节，在稳定段引入了冗余，并且无法捕捉短期和长期展望下的不同复杂性。
### Innovation
TimeMosaic 提出了一种旨在解决时序异质性的预测框架。TimeMosaic 使用自适应片段嵌入动态调整粒度，根据局部信息密度调整精细度，平衡了模式复用与结构清晰性，同时保持时间连续性。此外，引入了基于片段的解码，将每个预测时段视为相关的子任务，适应于特定于时段的难度和信息需求，而不是应用单一的通用解码器。
### Conclusion
在基准数据集上的广泛评估显示，TimeMosaic 在现有方法上带来了持续的改进。使用包含 3210 亿观察值的大规模语料库训练的模型，其性能与最新的时间序列预测模型相当。
## 674. `cs.LG` - 跨频域转移学习及基础预测模型的现实评估 [PDF](https://arxiv.org/pdf/2509.19465), [HTML](https://arxiv.org/abs/2509.19465)
### Authors
Kin G. Olivares,Malcolm Wolff,Tatiana Konstantinova,Shankar Ramasubramanian,Andrew Gordon Wilson,Andres Potapczynski,Willa Potosnak,Mengfei Cao,Boris Oreshkin,Dmitry Efimov
### Background
跨频域转移学习（CFTL）已成为一个流行的框架，用于收集大规模时间序列数据集，以预训练基础预测模型（FFM）。尽管CFTL有潜力，但当前的基准测试方法未能准确评估其性能。这些问题源于多个因素：过度依赖小型评估数据集；计算摘要统计时不充分处理样本大小；报告次优统计模型；以及未能考虑到拟合期间和测试数据集之间非忽略的风险。
### Innovation
作者提出了一个统一重实现广泛采用的神经预测网络，并适应其用于CFTL设置；仅在专用的和合成数据集上进行预训练，以防止测试泄漏，并在15个大型、多样的公共预测竞赛数据集上进行评估。研究发现统计模型的准确性经常被低估，并且统计模型及其集成在所有数据集上始终比现有的FFM高出超过8.2%的sCRPS和超过20%的MASE。
### Conclusion
研究还发现，合成数据集的预训练确实可以提高FFM的准确性，提高了约7%。
## 675. `cs.LG` - 视觉深度学习系统的概率运行时验证、评估和风险管理 [PDF](https://arxiv.org/pdf/2509.19419), [HTML](https://arxiv.org/abs/2509.19419)
### Authors
Birk Torpmann-Hagen,Pål Halvorsen,Michael A. Riegler,Dag Johansen
### Background
尽管深度神经网络在基准测试中表现优异，但在实际部署中往往表现出色，这主要是由于其对输入数据微小变化，即分布偏移的敏感性。这些分布偏移在实际场景中普遍存在，但在评估过程中却鲜有涉及，导致评估指标被夸大。为了填补这一缺口，本文提出了一种新的深度学习系统验证、评估和风险评估方法。该方法通过估计离域检测器输出的概率来显式地在运行时建模分布偏移的发生概率，并将这些估计与网络正确性的条件概率结合，在二叉树结构中进行组织和计算，最终实现可信且精确的网络准确度估计。
### Innovation
本文提出了一种新的方法，即通过离域检测器输出和条件概率的结合，在二叉树结构中进行组织和计算，来估计网络准确度。该方法在不同数据集上的评估结果显示，其准确性误差通常在0.01至0.1之间，显著优于传统评估方法。此外，该方法还应用于医学分割基准，通过关联树节点的成本来进行风险评估，进一步支持成本效益分析和价值判断。
### Conclusion
本文提供的方法为改善深度学习系统的可靠性和可信度提供了一个稳健框架，特别是在安全关键应用中。通过提供更准确的性能估计和可操作的风险评估，该方法增强了人们对深度学习系统的信心。
## 676. `cs.LG` - 使用不同重采样技术的Boruta特征选择和DBSCAN算法增强信用违约预测 [PDF](https://arxiv.org/pdf/2509.19408), [HTML](https://arxiv.org/abs/2509.19408)
### Authors
Obu-Amoah Ampomah,Edmund Agyemang,Kofi Acheampong,Louis Agyekum
### Background
信用违约数据集通常失衡，违约者占比远低于非违约者。研究通过比较三种常用的处理此类问题的技术（SMOTE、SMOTE-Tomek、ADASYN）来评估信用违约预测的机器学习模型性能。
### Innovation
研究探索了Boruta特征选择和基于DBSCAN的离群点检测方法，与其结合使用不同的重采样技术（SMOTE-Tomek、SMOTE、ADASYN）以及高级集成提升算法（如XGBoost、AdaBoost、GBM和Light GBM），并比较不同方法对于信用违约预测模型的影响。
### Conclusion
综合考虑各模型性能指标（如ROC-AUC、PR-AUC、G-mean和F1分数），使用Boruta+DBSCAN+SMOTE-Tomek+GBM的组合在信用违约预测中表现出最佳效果，为未来构建更具弹性和适应性的信用违约系统打下了基础。
## 677. `cs.LG` - 变量建模在多变量时间序列中同时实现可扩展性和性能 [PDF](https://arxiv.org/pdf/2509.19471), [HTML](https://arxiv.org/abs/2509.19471)
### Authors
Hunjae Lee,Corey Clark
### Background
在多变量时间序列（MTS）数据中，变体数量是模型可扩展性的主要瓶颈。此外，领域内日益共识认为不加选择地混合变量可能导致信号噪声累积和性能下降，这在多变量时间序列系统中信息信号稀疏和变量间表示不一致的情况下尤为明显。尽管在Transformer的设计中通常认为可扩展性和性能是互相制约的因素，但此研究通过战略性地限制其相互建模的表示容量提高了这二者。
### Innovation
提出了一种名为Delegate Token Attention (DELTAformer)的方法，通过引入代理令牌来限制变量间的相互建模，同时进行无约束的跨时间建模。这些代理令牌起到隐式的正则化作用，迫使其仅允许通通道的必要信息。结果显示，DELTAformer不仅线性地随变量数量扩展，同时在基准测试中表现出优于标准Transformer的性能。它在噪声环境中能更好地关注相关信号，显示出更强的抗噪性。
### Conclusion
通过对模型设计精确定位多变量时间序列数据领域的挑战，DELTAformer实现了线性扩展和性能的双重提升，优于标准的二次扩展的Transformer。
## 678. `cs.LG` - 使用局部异常因子建模的约束减少MILP方法在信贷审批中实现可信的反事实解释 [PDF](https://arxiv.org/pdf/2509.19504), [HTML](https://arxiv.org/abs/2509.19504)
### Authors
Trung Nguyen Thanh,Huyen Giang Thi Thu,Tai Le Quy,Ha-Bang Ban
### Background
反事实解释（CE）是一种常用的后处理方法，能够为个人提供实际可行的建议，以改变机器学习模型的不利预测。合理的CE方法通过考虑数据分布特性来增强现实性，但其优化模型引入了大量的约束条件，导致了较高的计算成本。在现有框架中，研究者试图提高这些方法的效率，但尚未在这方面取得显著进展。
### Innovation
本文重新审视了DACE框架，并提出了一种改进的混合整数线性规划（MILP）公式，显著减少了局部异常因子（LOF）目标组件中的约束数量。此外，该方法还应用于具有标准缩放的线性SVM分类器。实验结果表明，本文方法在保持解释质量的同时，实现了更快的求解时间。这证明了更有效的LOF建模在反事实解释和数据科学应用中的潜力和前景。
### Conclusion
研究结果表明，通过改进的MILP方法，可以显著减少反事实解释中的计算成本，同时保持解释质量，这种更高效的LOF建模方法在未来的信用审批等数据科学应用中具有重要的实际价值。
## 679. `cs.LG` - DAWM: 基于扩散行动世界的离线强化学习 [PDF](https://arxiv.org/pdf/2509.19538), [HTML](https://arxiv.org/abs/2509.19538)
### Authors
Zongyue Li,Xiao Han,Yusong Li,Niklas Strauss,Matthias Schubert
### Background
基于扩散的世界模型已经在离线强化学习(offline RL)中展示了强大的能力，能够合成具有现实性的长期轨迹。然而，许多现有方法并没有直接生成动作和状态及奖励，这限制了它们与依赖于一期时间差分(TD)学习的标准基于价值的离线RL算法的兼容性。尽管有研究试图通过联合建模状态、奖励和动作来解决这个问题，但这些方法往往使训练变得更加复杂，并且在实践中表现出较低的性能。
### Innovation
本文提出了名为DAWM的扩散动作世界模型，该模型不仅能够生成未来发展状态-奖励轨迹（条件于当前状态、动作和剩余回报），还配合使用反动力学模型以高效地推断动作。这种模块化设计可以产生完整且适合一阶段TD基离线RL算法的合成过渡，从而实现有效的、计算效率高的训练。
### Conclusion
通过实验，我们证明了保守的离线RL算法如TD3BC和IQL从中受益显著，相比于之前的基于扩散的基线，在D4RL基准上的多个任务中具有一致的优越表现。
## 680. `cs.LG` - 3D分子生成的基于框架的对称扩散模型 [PDF](https://arxiv.org/pdf/2509.19506), [HTML](https://arxiv.org/abs/2509.19506)
### Authors
Mohan Guo(Faculty of Science, University of Amsterdam),Cong Liu(AMLab, University of Amsterdam),Patrick Forré(AMLab, University of Amsterdam)
### Background
当前的分子生成方法在保持严格对称性和提高计算效率之间存在权衡：一些方法通过代价高昂的架构来强制执行严格的E(3)-对称性，而其他方法则放宽对称性以获得更好的效率和灵活性。
### Innovation
提出了一个基于框架的扩散框架，该框架能够实现确定性的E(3)-对称性，同时将对称性处理与主网络断开。在此基础上，研究了三种变体：全局框架扩散(GFD)、局部框架扩散(LFD)和不变框架扩散(IFD)。进一步利用EdgeDiT，一种具有边感知注意的扩散变换器，增强了模型的表达能力。
### Conclusion
GFD结合EdgeDiT在QM9数据集上达到最先进的性能，在标准尺度下测试NLL为-137.97，在双尺度下为-141.85，同时保持高有效性和独特性，采样速度快约2倍。整体而言，该研究确立了基于框架的扩散方法作为生成分子的一种具有可扩展性、灵活性和物理依据的方法，强调了全局结构保持的重要性。
## 681. `cs.LG` - Metriplectic Conditional Flow Matching for Dissipative Dynamics [PDF](https://arxiv.org/pdf/2509.19526), [HTML](https://arxiv.org/abs/2509.19526)
### Authors
Ali Baheri,Lars Lindemann
### Background
神经网络在模拟力学系统时往往无法保证能量守恒，可能会导致系统振荡或非稳定性。已有的方法如神经流匹配（neural flow matching）虽然能够学习复杂的动力学，但在长时仿真中能量会逐渐增加，这违背了物理守恒的基本原则。因此，本文提出了一种新的方法Metriplectic Conditional Flow Matching (MCFM)，旨在学习符合能量耗散原理的动力学模型，同时遵守物理定律不被违反。
### Innovation
MCFM方法通过在短期转换中使用条件流匹配训练，避免了长期仿真过程中的梯度反向传播问题。在推理阶段，MCFM使用一种交替的辛更新和近邻度量更新方案，确保了能量的离散衰减并对长期稳定仿真进行维护。此外，方法还提供了持续时间和离散时间的保证，将参数化和采样器与能量守恒和耗散性单调性联系起来。通过对比实验表明，MCFM方法相较于等效的无约束神经流方法在机械控制基准测试中能够在更加真实地再现状态空间相图，并显著减少能量增加和正能量速率事件。
### Conclusion
本文提出了一种新的Metriplectic Conditional Flow Matching (MCFM)方法，该方法能够在学习力学系统复杂动力学的同时，确保能量守恒和耗散性原理不被违背。通过与无约束神经流方法的对比实验，展示了稳健的长期仿真性能和更好的状态空间相图复现能力。这种方法为构建符合物理原理的复杂动力学模型提供了一种新的思路和方法，并通过理论证明与实验结果得到了验证。
## 682. `cs.LG` - 一种用于全面基于片段的药物发现的基本化学语言模型 [PDF](https://arxiv.org/pdf/2509.19586), [HTML](https://arxiv.org/abs/2509.19586)
### Authors
Alexander Ho,Sukyeong Lee,Francis T.F. Tsai
### Background
基于片段的药物发现方法越来越受到关注，此方法依赖于大量分子片段的数据库。为了更全面地探索这些分子片段的空间，当前需要一个能够处理和生成大量化学有效片段的基础模型。
### Innovation
提出了FragAtlas-62M，这是一个专门针对迄今为止最大的片段数据集进行训练的基础模型，基于完整的ZINC-22片段子集（涵盖6200万个分子）。该模型使用GPT-2框架（42.7M参数），能生成99.90%的化学有效的片段，并且与训练数据的12个描述符和三种指纹方法验证结果表明生成的片段与训练分布密切相关（所有效应大小均小于0.4）。此外，该模型保留了53.6%已知ZINC片段，同时生成了具有实际相关性的新结构（占比22%）。
### Conclusion
该研究发布了FragAtlas-62M的训练代码、预处理数据、文档和模型权重，以期加速其在基于片段的药物发现中的应用。
## 683. `cs.LG` - 通过多模态机器学习优化治疗性抗体重新格式化 [PDF](https://arxiv.org/pdf/2509.19604), [HTML](https://arxiv.org/abs/2509.19604)
### Authors
Jiayi Xin,Aniruddh Raghu,Nick Bhattacharya,Adam Carr,Melanie Montgomery,Hunter Elliott
### Background
现代治疗性抗体设计通常涉及组成来自不同来源或独立工程的单一功能性域的多部分组装体。虽然这些复杂格式可以扩展疾病的适用性和改善安全性，但它们给工程带来了重大挑战：在新型格式中单个域的功能和稳定性无法得到保证，整个分子可能不再可合成。
### Innovation
开发了一个机器学习框架来预测“重新格式化成功率”——转换抗体格式是否会成功。该框架结合了抗体序列和结构背景，采用反映实际部署场景的评估协议。实验表明，现有大型蛋白质语言模型无法超越简单、特定领域且多模态的表示。特别是在最艰难的评估环境中，该模型能有效预测新的出发抗体，进而有助于优先化有前景的候选抗体，减少实验浪费。
### Conclusion
最佳多模态模型在新的抗体、无数据场景下实现了高预测准确性，能够通过对新出发抗体的优先级划分降低实验浪费，从而改进了治疗性抗体的重新格式化过程。
## 684. `cs.LG` - 遗传电路合成中的模块化机器学习 [PDF](https://arxiv.org/pdf/2509.19601), [HTML](https://arxiv.org/abs/2509.19601)
### Authors
Jichi Wang,Eduardo D. Sontag,Domitilla Del Vecchio
### Background
在合成生物学等多个应用场景中，往往存在由多个模块组成的系统，尽管各模块的输入/输出函数及信号可能未知，但了解系统组成结构能显著减少学习系统输入/输出映射所需的训练数据量。同时，了解模块的输入/输出函数对于从不同组成结构设计新系统也至关重要。
### Innovation
本文提出了一种模块化学习框架，该框架结合了系统组成结构的先验知识，用于：（a）从系统输入/输出数据中识别组成模块的输入/输出函数；（b）通过利用组成结构的信息减少所需的数据量，相比于完全不了解组成结构的情况。此外，论文引入了模块可识别的概念，允许从系统输入/输出数据的一部分中恢复模块的输入/输出函数，并为一类由遗传电路激发的系统提供了理论保障。
### Conclusion
通过理论研究证明，在考虑组成结构的神经网络（NNET）能够学习组成模块的输入/输出函数，并预测训练集分配之外的输入下的系统的输出。相比之下，不知道结构的神经网络无法预测训练集之外的输入。该框架通过减少所需的实验数据和允许模块识别，为设计合成生物电路以及多模块系统带来了潜在的好处。
## 685. `cs.LG` - 深度学习的动力学——深度神经网络的力分析 [PDF](https://arxiv.org/pdf/2509.19554), [HTML](https://arxiv.org/abs/2509.19554)
### Authors
Yi Ren
### Background
本文探讨了如何使用受力分析启发的方法研究深度学习模型随时间的学习过程。具体而言，研究聚焦于训练过程中单个训练样例如何影响另一个样例，通过对力如何移动物体进行类比，研究模型学习的动态过程，将这种影响分为两部分：样例的相似度和更新力的强度。这种方法帮助我们理解模型在不同真实系统中的各种行为。例如，它可以解释某些样例的学习路径为何不平凡，某些语言模型微调方法为何有效或无效的原因，以及为何简单的、更具结构化的模式更容易被学习。这项方法应用于各种学习任务，揭示了改进模型训练的新策略。虽然该方法仍处于发展中状态，但它提供了一种系统地解释模型行为的新途径。
### Innovation
本文提出了一种使用力分析启发方法来研究深度学习模型随时间学习过程的新框架。将训练样本之间的相似性和更新力的强度作为分析的核心，这种方法能够帮助我们系统地理解模型在不同真实系统中的行为，包括样例的学习路径、语言模型微调方法的有效性以及简单模式的易于学习性等问题。此外，该方法还揭示了改进模型训练的新策略。
### Conclusion
虽然该方法仍处于发展中状态，但它提供了一种系统地解释模型行为的新途径，对进一步研究和改进深度学习模型具有重要意义。
## 686. `cs.LG` - TIMED：基于扩散的时间序列生成的对抗与自回归精细化 [PDF](https://arxiv.org/pdf/2509.19638), [HTML](https://arxiv.org/abs/2509.19638)
### Authors
MohammadReza EskandariNasab,Shah Muhammad Hamdi,Soukaina Filali Boubrahimi
### Background
生成高质量的合成时间序列数据是预报和异常检测等领域的基础但又具有挑战性的工作，尤其是在现实数据稀缺、噪声大或收集成本高昂的情况下。与生成静态数据不同，生成时间序列数据需要同时建模观测的边缘分布和制约序贯动态的条件时间依赖性。
### Innovation
提出了TIMED，一个统一的生成框架，结合了去噪扩散概率模型（DDPM），用于捕捉全局结构；监督网络通过下一步预测学习自回归依赖性；沃兹涅申斯基评论员提供对抗反馈以确保时间连续性与保真度。为在特征空间中进一步使真实和合成分布保持一致，TIMED引入了最大均值偏差（MMD）损失，促进多样性和样本质量。所有组件都在为序列建模优化的遮罩注意结构上构建，并且通过联合训练能够有效捕获时间序列数据的无条件和有条件方面。
### Conclusion
跨多种多变量时间序列基准实验结果表明，TIMED生成了比现有生成模型更现实和时间上更连贯的序列。
## 687. `cs.LG` - 符号-时间一致性自监督学习用于鲁棒时间序列分类 [PDF](https://arxiv.org/pdf/2509.19654), [HTML](https://arxiv.org/abs/2509.19654)
### Authors
Kevin Garcia,Cassandra Garza,Brooklyn Berry,Yifeng Gao
### Background
数字健康领域中时间序列数据的重要性增加，需要先进的方法来提取有意义的模式和表现形式。自监督对比学习作为一种有前途的方法，可以从原始数据中直接学习。然而，时间序列数据在数字健康领域中是高度噪声的，固有地涉及概念漂移，并且给训练通用深度学习模型带来挑战。本研究关注由不同人类行为引起的数据分布变化，并提出了一种自监督学习框架，该框架注意到符号包表示。
### Innovation
提出了一种新的自监督学习框架，该框架认识到符号包表示在数据变形、位置偏移和时间序列数据中存在的噪声中的抗变性，指导深度学习获得对该类数据变化具有抵抗力的表现。
### Conclusion
实验证明，所提出的方法在存在显著数据变化的情况下可以实现显著更好的性能。
## 688. `cs.LG` - Mamba Modulation: On the Length Generalization of Mamba [PDF](https://arxiv.org/pdf/2509.19633), [HTML](https://arxiv.org/abs/2509.19633)
### Authors
Peng Lu,Jerry Huang,Qiuhao Zeng,Xinyu Wang,Boxing Wang,Philippe Langlais,Yufei Cui
### Background
Transformer模型中的注意力机制具有二次复杂度，这促使开发了具有亚二次扩展的替代架构，如状态空间模型。Mamba作为这些架构中的一种脱颖而出，其在各种语言建模任务中取得了最先进的结果。然而，Mamba在处理预训练时未见过的更长上下文时，其性能显著下降，显示出对上下文长度扩展的敏感性。
### Innovation
本文通过将谱缩放应用于预训练的Mamba模型，提出了一个方法，通过选择性地调节每层的过渡矩阵$bf{A}$的谱来增强其在长上下文环境下的鲁棒性。这种方法通过调节$bf{A}$矩阵的谱来克服了Mamba对上下文长度扩展的敏感性，即使简单调节$bf{triangle}_t$也无效的情况，也取得了显著的性能提升。
### Conclusion
通过对状态收敛行为和过渡矩阵$bf{A}$的谱之间的关系进行分析，本文提出了一个利用状态空间模型（特别是具有结构化过渡矩阵的模型）的谱缩放方法，解决了Mamba在长度扩展时的局限性，从而在处理更长上下文时提高了模型的性能和鲁棒性。
## 689. `cs.LG` - 由小波展开实现局部差分隐私下数值分布的一致估计 [PDF](https://arxiv.org/pdf/2509.19661), [HTML](https://arxiv.org/abs/2509.19661)
### Authors
Puning Zhao,Zhikun Zhang,Bo Sun,Li Shen,Liang Zhang,Shaowei Wang,Zhe Liu
### Background
局部差分隐私(LDP)下的分布估计是一项基础而具有挑战性的任务，尤其对于数值数据。虽然在分类数据上取得了显著进展，但由于不同评估指标的影响，现有的方法在应用于数值数据时效果不佳。特别是，需要防止概率质量被错误放置得离真实的地分布得太远
### Innovation
提出了一种新的方法，通过小波展开表达样本分布，并在LDP下估计小波级数的系数。该方法优先估计低阶系数，以确保宏观层面的准确估计，从而防止概率质量被错误放置得太远。为此，提供了该方法的理论保证。实验表明，在Wasserstein和KS距离下，该小波展开方法明显优于现有方法
### Conclusion
实验结果表明，该小波展开方法在Wasserstein和KS距离下显著优于现有解决方案，能够实现局部差分隐私下数值分布的一致估计
## 690. `cs.LG` - 适应性的von Mises-Fisher似然损失函数在监督深度时间序列哈希中的应用 [PDF](https://arxiv.org/pdf/2509.19625), [HTML](https://arxiv.org/abs/2509.19625)
### Authors
Juan Manuel Perez,Kevin Garcia,Brooklyn Berry,Dongjin Song,Yifeng Gao
### Background
时间为轴的时间序列数据在数据挖掘中是一项基本任务。近年来，基于深度学习的哈希方法已被证明能够根据语义意义对时间序列进行索引，而不仅仅依赖于原始的相似性度量。监督深度哈希通过将具有相同语义意义的样本映射到相同的二进制哈希码来实现语义相似性的搜索和检索，但这一过程中可能会造成显著的信息损失。
### Innovation
该研究提出了适应性的von Mises-Fisher（vMF）哈希损失函数。该模型将数据映射到M维超球空间以有效减少信息损失，并将每个数据类别建模为遵循不同vMF分布的点。设计的loss函数旨在最大化每个建模的vMF分布之间的分离，以更好地最大化语义不同的数据样本的间隔。
### Conclusion
实验结果表明，本方法优于现有基线方法。项目实现公开发布在指定网址。
## 691. `cs.LG` - C${}^2$Prompt: Class-aware Client Knowledge Interaction for Federated Continual Learning [PDF](https://arxiv.org/pdf/2509.19674), [HTML](https://arxiv.org/abs/2509.19674)
### Authors
Kunlun Xu,Yibo Feng,Jiangmeng Li,Yongsheng Qi,Jiahuan Zhou
### Background
联邦持续学习（FCL）适用于分布于不同客户端、持续出现任务数据的学习场景，其主要挑战在于同时应对时间遗忘和空间遗忘。传统基于提示的FCL方法虽然表现出色，但容易出现类别间知识一致性问题，包括客户端内类别间分布差异引起的语义退化以及提示间类别相关性揭示的跨类别知识混淆，这些问题在提示通讯过程中加剧了知识冲突和干扰，增加了空间和时间遗忘现象。
### Innovation
本文提出了一种新颖的方法Class-aware Client Knowledge Interaction (C${}^2$Prompt)，通过在提示通讯中增强类别间知识一致性来解决上述问题。具体而言，通过引入局部类别分布补偿机制（LCDC）减少客户端间的类别间分布差异，强化类别内知识一致性；并通过设计类别感知提示聚合方案（CPA）选择性增强类别相关知识聚合以缓解跨类别知识混淆。
### Conclusion
C${}^2$Prompt 方法在多个FCL基准测试中取得了现有最佳性能。源代码已提供。
## 692. `cs.LG` - 统一噪声曲率视角下的训练可学性损失分析 [PDF](https://arxiv.org/pdf/2509.19698), [HTML](https://arxiv.org/abs/2509.19698)
### Authors
Gunbir Singh Baveja,Mark Schmidt
### Background
训练可学性损失（Loss of Trainability, LoT）是指在持续学习过程中，梯度更新不再带来性能改进，从而使模型的准确率停止提升或下降。尽管网络具备足够的容量和监督，LoT依然会发生。作者通过优化理论分析了Adam优化器引起的LoT，并指出单指标如海森矩阵秩、尖锐度级别、权重或梯度范数、梯度到参数比例以及单位符号熵，不能可靠地预测LoT。
### Innovation
作者提出了一种新的预测阈值：基于批量大小的梯度噪声界和曲率波动控制界，它们结合形成了一个针对每层的预测阈值，用于预判训练行为。基于此阈值，作者构建了一个简单的每层调度器，使每层的有效步骤保持在安全范围内，从而稳定训练并提高跨ReLU、 Wasserstein正则化、和 L2 权重衰减的准确性，同时实现学习速率轨迹与经典的衰减规律相匹配的学习率路径。
### Conclusion
研究结果表明，通过优化视角分析Adam引起的LoT，并提出新的预测阈值和调度器，可以在持续学习中改善模型性能和保持训练的稳定性。
## 693. `cs.LG` - 使用临床背景重新审视胸部X光模型的性能 [PDF](https://arxiv.org/pdf/2509.19671), [HTML](https://arxiv.org/abs/2509.19671)
### Authors
Andrew Wang,Jiashuo Zhang,Michael Oberst
### Background
公共医疗数据库中的胸部X射线(CXR)图像长期是开发医疗保健领域计算机视觉模型的基准。然而，机器学习(ML)模型在这些数据集上的平均性能不足以证明它们的临床效用。这项研究通过结合先前出院记录中的临床背景，提供了一种更为全面的评估当前最先进的CXR诊断模型的方法。这种方法旨在通过前期概率测量临床背景，评估模型的实际诊断信号是否强于推断前期概率的捷径。研究发现，对于某些诊断标签，CXR模型在前期概率非常低的情况下表现最佳，而在前期概率较高的情况下则表现较差。这表明模型的性能可能更多地来自于推断临床背景而非真正的诊断能力。因此，通过使用临床记录中的背景信息，可以进行更为严谨和细化的临床视觉模型评估，这一方法具有潜力。
### Innovation
这项研究通过结合以前出院记录中的临床背景，提供了一种评估当前最先进的CXR诊断模型的新方法。这种方法使用前期概率作为临床背景的代理，通过这个度量，研究发现了几个关键发现，特别是表现优越的现象往往出现在前期概率较低时，以及强大的平均性能可能反映的是推断前期概率的能力而非真正的诊断信号。这种方法提供了对临床视觉模型的诊断能力和临床适用性的新视角，促进了更为严谨和细化的评估。
### Conclusion
通过采用从临床记录中提取的背景信息的方法，这项研究提供了一种新的分析方式，以更严格和细致的方式评估临床视觉模型的效能，这一发现表明，诸如通过推断临床背景的模型性能可能反映了对诊断信息的推理，而非实际的诊断能力。这种评估方法具有显著的创新意义，可能引领今后相关领域的研究方向。
## 694. `cs.LG` - 神经网络的Sobolev加速 [PDF](https://arxiv.org/pdf/2509.19773), [HTML](https://arxiv.org/abs/2509.19773)
### Authors
Jong Kwon Oh,Hanbaek Lyu,Hwijae Son
### Background
Sobolev训练通过将目标导数集成到损失函数中，与传统的$L^2$训练相比，已被证明能加速收敛并提高泛化能力。然而，其背后的机理尚不完全明了。
### Innovation
本文首次建立了严格的理论框架，证明Sobolev训练能加速Rectified Linear Unit (ReLU)网络的收敛。在具有高斯输入和浅层架构的学生-教师框架下，推导出了精确的总体梯度和Hessian公式，并量化了损失景观条件性和梯度流收敛率的改进。
### Conclusion
广泛的数值实验验证了理论结果，展示了Sobolev训练对现代深度学习任务的益处延伸。
## 695. `cs.LG` - 向低运行成本的全局站天气预报可扩展且结构化的迈进 [PDF](https://arxiv.org/pdf/2509.19648), [HTML](https://arxiv.org/abs/2509.19648)
### Authors
Hongyi Chen,Xiucheng Li,Xinyang Chen,Yun Cheng,Jing Li,Kehai Chen,Liqiang Nie
### Background
全球气象站天气预报是一个关键的气象研究领域，对能源、航空和农业至关重要。现有的时间序列预测方法在进行大规模全球气象站预报时往往忽视或单向建模空间相关性，这与全球天气系统的内在本质相悖，限制了预报性能。现有方法无法同时考虑局部空间相似性和全局关联性，导致预报效果不佳。
### Innovation
本文提出了一种新的空间结构化注意力模块，该模块将空间图划分为子图，并采用子图内注意力机制来学习各子图内的局部空间相关性，同时通过子图间注意力机制聚合节点以进行子图间的消息传递，从而同时考虑空间接近性和全局关联性。基于此模块，通过逐步扩展子图的规模，本文开发了一个多层次的时空预测模型，该模型兼具可扩展性且能够生成结构化空间关联性，同时也易于实现。该模型在较低成本下实现了超过16.8%的性能提升。
### Conclusion
通过提出新的空间结构化注意力模块和多层次时空预测模型，本文旨在解决现有方法忽视或单向建模空间相关性的问题，提高全球气象站天气预报的性能和可扩展性。实验结果表明，该方法在低成本下能够取得显著的性能提升。
## 696. `cs.LG` - 线性变压器隐式发现统一的数值算法 [PDF](https://arxiv.org/pdf/2509.19702), [HTML](https://arxiv.org/abs/2509.19702)
### Authors
Patrick Lutz,Aditya Gangrade,Hadi Daneshmand,Venkatesh Saligrama
### Background
本文介绍了一种对数百万个缺失块矩阵完成任务进行训练的线性注意力Transformer。每个提示都是一个被遮掩的低秩矩阵，其缺失的块可能是一个标量预测目标或Nyström外推法未知的核切片。模型仅能看到输入输出对和均方误差损失，没有提供正规方程或手工迭代，也不提示任务之间的关系。
### Innovation
令人惊讶的是，经过训练后，代数展开揭示了三个独立计算模式中相同参数免更新规则（全额可见、秩限制更新以及分布式计算）。本文证明了此规则在批量问题上实现了二阶收敛，减少了分布式迭代复杂度，即使使用秩受限注意力保持准确性。这意味着仅用于修补缺失块的变压器隐式发现了跨越预测、估计和Nyström外推的统一资源适配迭代求解器，突显了上下文学习的强大能力。
### Conclusion
通过训练仅用于修补缺失块的变压器，发现了跨越预测、估计和Nyström外推的统一资源适配迭代求解器，证明了该方法在批量问题上能够实现二阶收敛，能有效减少分布式迭代复杂度，并能保持使用秩受限注意力时的准确性。
## 697. `cs.LG` - 基于因果机器学习的外科干预 [PDF](https://arxiv.org/pdf/2509.19705), [HTML](https://arxiv.org/abs/2509.19705)
### Authors
J. Ben Tamo,Nishant S. Chouhan,Micky C. Nnamdi,Yining Yuan,Shreya S. Chivilkar,Wenqi Shi,Steven W. Hwang,B. Randall Brenn,May D. Wang
### Background
外科决策具有复杂性和不确定性，需要深入了解患者特征、治疗手段和临床结果之间的因果关系。在高风险场合如脊柱融合或脊柱侧弯矫正中，由于传统统计方法难以处理复杂和异质性数据，个体化治疗效果（ITEs）的准确估计仍然有限。因此，开发一种多任务元学习框架X-MultiTask，可以为每个外科决策建模并学习跨任务的共享表示，以加强因果有效性，同时引入逆概率加权（IPW）作为训练目标的一部分，从而提高ITE估计的准确性，并提供精准的患者特异性因果估计，来推动个性化的外科护理和改善患者结果的研究。
### Innovation
提出了一种多任务元学习框架X-MultiTask，能够将每个外科决策建模为一个独特的任务，同时学习跨任务的共享表示。通过引入逆概率加权（IPW）作为训练目标，增强因果有效性。在此框架下，使用两个数据集（公共脊柱融合数据集和私人AIS数据集）评估了模型性能，结果表明X-MultiTask在治疗效果估计和患者报告结果预测中均表现出优异的表现，具有较低的$text{NN-PEHE}$和$text{ATE}$误差，验证了其在个性化外科护理中的潜在应用价值和实际优势。引入的X-MultiTask框架对于开发更准确的个体化手术建议和优化患者预后具有重要意义。
### Conclusion
通过提供基于X-MultiTask的稳健、患者特定的因果估计，提出了一个强大的工具来推动个性化外科护理并改善患者结果。此方法展示了在脊柱融合和脊柱侧弯矫正中的优越性能，并确保在患者的报告结果和其他领域拥有持续更好的预测效果。最终，该研究结果证明了其在复杂外科决策中的有效性和实用性。
## 698. `cs.LG` - RDAR：基于奖励驱动的自主驾驶中代理相关性估计 [PDF](https://arxiv.org/pdf/2509.19789), [HTML](https://arxiv.org/abs/2509.19789)
### Authors
Carlo Bosio,Greg Woelki,Noureldin Hendy,Nicholas Roy,Byungsoo Kim
### Background
人类驾驶员在任何时候都只会关注少量的代理，而自主驾驶系统会处理包含众多代理的复杂场景，无论这些代理是正在过马路的行人还是路边停放的车辆。现有的注意力机制虽然能隐式地减少输入到决策模型的元素，但由于捕捉代理间交互的方式通常是平方级别的，因此通常计算成本较高。该研究提出了一种新的策略，即RDAR（奖励驱动代理相关性），通过确定哪些代理可以被排除在预训练行为模型的输入之外来学习每个代理的相关性，即每个代理对受控车辆行为的影响程度。
### Innovation
该研究提出了RDAR（奖励驱动代理相关性）策略，这是一种新的方法来确定每个代理对控制系统车辆行为的影响程度。通过将掩码过程形式化为马尔可夫决策过程，使得系统的决策模型能够评估每个代理的重要性，并相应地调整输入代理的数量，从而在保持驾驶性能的同时减少计算开销。
### Conclusion
该研究在大规模驾驶数据集上评估了RDAR，并展示了其能够学习准确的相关性度量，并在总体进展、安全性及性能方面达到了与最先进行为模型相当的驾驶性能，同时处理的代理数量显著减少。
## 699. `cs.LG` - 高效条件评分基于滤波器解决高维非线性滤波问题 [PDF](https://arxiv.org/pdf/2509.19816), [HTML](https://arxiv.org/abs/2509.19816)
### Authors
Zhijun Zeng,Weiye Gan,Junqing Chen,Zuoqiang Shi
### Background
在许多工程和应用科学领域，高维非线性滤波仍然是一个具有挑战性的问题。最近，在评分基于扩散模型方面的进展提供了一种替代的后验采样方法，但需要反复重训以适应变化中的先验知识，在高维情况下这是不切实际的。
### Innovation
本文提出了条件评分基于滤波器（CSF），这是一种新颖的算法，利用集转换器编码器和条件扩散模型，实现没有重训的高效和准确的后验采样。通过将先验建模和后验采样拆分为离线和在线阶段，CSF能够跨多种非线性系统实现可扩展的评分基于滤波。
### Conclusion
大量基准问题上的实验表明，CSF 在各种非线性滤波场景中具有优越的准确性和鲁棒性，同时也更加高效。
## 700. `cs.LG` - 更快，更小，更智能：在线MoE推理中的任务感知专家合并 [PDF](https://arxiv.org/pdf/2509.19781), [HTML](https://arxiv.org/abs/2509.19781)
### Authors
Ziyi Han,Xutong Liu,Ruiting Zhou,Xiangxiang Dai,John C.S. Lui
### Background
Sparse Mixture of Experts (SMoE)已成为一种流行的架构，用于在不增加计算成本的情况下扩展Transformer的容量，因为它为每个输入只激活一小部分专家。然而，将其部署为在线推理仍然具有挑战性，因为完整的SMoE模型非常庞大，并且专家路由的复杂性特别在资源受限的边缘网络中更加棘手。此外，在在线推理过程中，任务信息通常不可用，这使得任务级别路由的准确性较差。
### Innovation
提出了一种新颖的基于树的自适应神经多臂报文路由器Tanbr，以实现高效且可靠的在线MoE推理。Tanbr通过历史数据估计任务分布，并据此指导任务感知的专家合并，而不需要依赖显式任务标签。Tanbr使用二叉树逐步分割合并权重的连续空间，并生成更精细的候选权重，然后使用神经多臂报文学习合并权重到模型性能的非线性映射，并决定最佳专家合并。此外，证明了Tanbr在连续决策空间中的子线性后悔边界为$O(frac{ textsl{sqrt}(T) textsl{log}(T))$，与现有方法的后悔边界相当。
### Conclusion
全面的实验表明，Tanbr可以将推理延迟减少至少45%，内存使用减少高达25%，同时保持与许多最先进的方法相当的高准确性。
## 701. `cs.LG` - VCRL：基于方差的课程强化学习方法 [PDF](https://arxiv.org/pdf/2509.19803), [HTML](https://arxiv.org/abs/2509.19803)
### Authors
Guochao Jiang,Wenfeng Feng,Guofeng Quan,Chuzhan Hao,Yuewei Zhang,Guohua Liu,Hao Wang
### Background
政策导向的强化学习目前在提高大型语言模型（LLMs）在数学推理任务上的表现中扮演着重要角色。然而，现有的基于回放的强化学习方法（如GRPO、DAPO、GSPO等）未能明确考虑到LLMs对不同难度级别的样本的学习能力，这与人在进行数学推理任务时从简单到复杂的过程相反。研究者观察到，回放组在强化学习（RL）中的奖励方差部分反映了样本对于LLMs的难度。过于简单的或非常难的样本奖励方差较低，而中等难度的样本奖励方差较高。基于此，论文提出了一种基于方差的课程强化学习框架（VCRL），该框架可以根据方差动态控制训练样本的难度。
### Innovation
该论文提出了一种基于方差的课程强化学习框架（VCRL），该框架可以根据样本的奖励方差动态调整训练样本的难度，从而改善LLMs在数学推理任务上的表现。这种方法更好地模拟了人类认知过程中的学习方式，即从简单任务逐步过渡到更复杂任务。
### Conclusion
在五项数学基准测试和两种模型上进行的实验表明，VCRL相对于当前的LLM强化学习基线方法具有明显的优势。
## 702. `cs.LG` - 关于Kolmogorov-Arnold网络回归估计的收敛速率 [PDF](https://arxiv.org/pdf/2509.19830), [HTML](https://arxiv.org/abs/2509.19830)
### Authors
Wei Liu,Eleni Chatzi,Zhilu Lai
### Background
Kolmogorov-Arnold网络（KANs）提供了一种通过逐个组合一维变换来进行多元函数逼近的结构化和可解释的框架。该网络通过加法或乘法聚合来表示多元函数。本文在B-样条表示一维组件的情况下建立了KANs的理论收敛保证。研究证明，无论是加法还是混合加法-乘法KANs都能够达到在光滑度为r的Sobolev空间中的最小最大收敛速率O(n^-2r/(2r+1))。此外，还推导了有关B-样条中最佳结点数量选择的指导原则。模拟结果证实了预测的收敛速率，为使用KANs在非参数回归中的应用提供了理论基础，同时也暗示了KANs作为现有方法的结构化替代方案的潜力。
### Innovation
该论文首次针对B-样条表示的一维组件，为Kolmogorov-Arnold网络提供了理论上的收敛保障。证明了KANs在不同聚合方案下的最优收敛速率，并提供了选择最佳节点数量的指导原则。此外，通过模拟验证了理论模型的有效性。这些成果为KANs在非参数回归中的应用提供了坚实的理论依据，并指出了其作为一种结构化方法的潜在价值。
### Conclusion
该研究为Kolmogorov-Arnold网络在非参数回归中的应用奠定了理论基础，并展示了其作为结构化方法相对于传统方法的潜在优势。
## 703. `cs.LG` - 核心边界意识下的过采样与下采样：一种数据质量驱动的方法 [PDF](https://arxiv.org/pdf/2509.19856), [HTML](https://arxiv.org/abs/2509.19856)
### Authors
Samir Brahim Belhaouari,Yunis Carreon Kahalan,Humaira Shaffique,Ismael Belhaouari,Ashhadul Islam
### Background
在不平衡分类任务中，机器学习模型的有效性往往受到无法区分决策边界附近的临界实例和数据分布核心的冗余样本的影响。现有的方法难以有效地区分这两类数据。
### Innovation
本文提出了一种系统地识别和区分这两种类型数据的方法。通过在多个基准数据集上的大量实验，证明边界数据过采样方法在96%的实验中将F1分数提高了10%；而我们的核心意识减少方法能够压缩数据集至原来的10%，同时保持模型的准确性，比原始数据集强大10倍。
### Conclusion
这项工作为未来在数据高效学习方面的研究开辟了道路，其中智能采样取代了无脑扩展，为下一代AI技术的发展奠定了基础。我们的代码作为一个Python包发布在上述链接中。
## 704. `cs.LG` - 摩擦性Q学习 [PDF](https://arxiv.org/pdf/2509.19771), [HTML](https://arxiv.org/abs/2509.19771)
### Authors
Hyunwoo Kim,Hyo Kyung Lee
### Background
本文将经典力学中的静摩擦力与非策略性强化学习中的外推误差进行了类比，并据此提出了一种约束，可以阻止策略倾向于不可支持的动作。在此研究中，作者提出了一种适用于连续控制的摩擦性Q学习算法（Frictional Q-learning），该算法扩展了批量约束强化学习。该算法约束了代理的动作空间，鼓励其行为类似于重放缓冲区中的行为，但不远离正交动作空间的流形。
### Innovation
提出的摩擦性Q学习算法扩展了批量约束强化学习，并通过约束代理的动作空间，使其行为更像重放缓冲区中的行为。该约束方法保留了批量约束的简便性，同时也提供了一种对齐外推误差的直观物理解释。
### Conclusion
实验结果表明，该算法能够稳健地训练，并在标准连续控制基准测试中实现了竞争力的表现。
## 705. `cs.LG` - PPGFlowECG：跨模态编码和隐空间修正流的PPG引导的心电图生成及心血管疾病诊断 [PDF](https://arxiv.org/pdf/2509.19774), [HTML](https://arxiv.org/abs/2509.19774)
### Authors
Xiaocheng Fang,Jiarui Jin,Haoyu Wang,Che Liu,Jieyi Cai,Guangkun Nie,Jun Li,Hongyan Li,Shenda Hong
### Background
在临床实践中，心电图（ECG）仍然是心脏监测的金标准，能够提供广泛的心血管疾病（CVDs）诊断的关键见解。然而，它依赖于专用设备和专业人员，限制了其在日常持续监测中的可行性。光体积描记图（PPG）能够提供可访问和持续的心脏监测，但是缺乏明确的电生理信息，无法进行结论性的诊断。生成模型为将PPG转化为有价值的ECG信号提供了有希望的方法，但当前的方法面临着生理语义错位和高维信号建模复杂等显著挑战。为了应对这些挑战，本文提出了一种PPGFlowECG框架，通过心脏对齐编码器将PPG和ECG在共享的隐空间中对齐，并使用隐空间修正流生成具有高保真度和可解释性的ECG。
### Innovation
提出了一种PPGFlowECG框架，这是一种两阶段的生成模型，利用心脏对齐编码器在共享的隐空间中对齐PPG和ECG，并使用隐空间修正流生成高保真度和高可解释性的ECG。这是首次在MCMED数据集上进行实验，该数据集包含超过1000万个来自118,000多个急诊科访问样本的PPG-ECG配对，并附有心脏病专家标记的心血管疾病注释。实验结果显示该方法在PPG到ECG转换和心血管疾病检测方面是有效的，且医生的评估确认了合成ECG的高保真度和诊断可靠性，表明该方法具有在临床应用于心血管筛查的潜力。
### Conclusion
PPGFlowECG框架通过使用心脏对齐编码器和隐空间修正流，实现了PPG和ECG在共享隐空间中的对齐，生成了高质量、高可解释性的ECG信号，提高了心血管疾病的诊断可靠性。该方法在MCMED数据集上的实验证明了其在实际临床检测中的有效性和潜在应用价值。
## 706. `cs.LG` - 分析预训练符号回归模型的泛化能力 [PDF](https://arxiv.org/pdf/2509.19849), [HTML](https://arxiv.org/abs/2509.19849)
### Authors
Henrik Voigt,Paul Kahlmeyer,Kai Lawonn,Michael Habeck,Joachim Giesen
### Background
符号回归算法在给定数据中搜索数学表达式以进行数据解释。变换器模型因其大规模预训练阶段的性价比优势而成为有力的候选方法，将昂贵的组合搜索转移出去。然而，这些模型的成效高度依赖于预训练数据集，其在分布外问题上的泛化能力尚待深入研究。这篇文章旨在系统地研究预训练变换器模型在符号回归中的泛化能力，并在多个预训练分布内和分布外挑战中测试其性能表现。研究表明，尽管预训练模型在分布内表现出色，但在分布外场景中的性能却明显下降。
### Innovation
研究使用了系统性的实证方法来评估预训练变换器模型在符号回归中的泛化能力，这包括在多个预训练分布内和分布外挑战中分别测试最新方法的性能。发现预训练模型在分布内表现良好，但在分布外场景中性能下降，揭示了预训练模型的泛化能力存在显著障碍，这一结论对实际应用中的预训练方法使用具有重要意义。
### Conclusion
研究表明，在分布内，预训练变换器模型表现良好；然而，在分布外情景中，其性能表现一直显著下降。这意味着预训练模型的泛化能力存在显著障碍，这严重限制了预训练模型在现实世界应用中的实际应用价值。因此，泛化能力成为选择预训练符号回归模型的关键因素。
## 707. `cs.LG` - BoreaRL：气候适应性 boreal 森林管理的多目标强化学习环境 [PDF](https://arxiv.org/pdf/2509.19846), [HTML](https://arxiv.org/abs/2509.19846)
### Authors
Kevin Bradley Dsouza,Enoch Ofosu,Daniel Chukwuemeka Amaogu,Jérôme Pigeon,Richard Boudreault,Pooneh Maghoul,Juan Moreno-Cruz,Yuri Leonenko
### Background
 boreal 森林储存了地球陆地生态系统大约30-40%的碳，其中很大一部分存在于气候敏感的永久冻土中。因此，管理 boreal 森林以同时实现碳储存和永久冻土保护具有关键的气候缓解作用。然而，当前的管理工具难以解决同时优化碳储存和永久冻土保护之间的复杂的权衡问题。
### Innovation
本文提出 BoreaRL，这是第一个用于气候适应性 boreal 森林管理的多目标强化学习环境，其特点是一个基于物理的能源、碳和水动态耦合模拟器。BoreaRL 支持特殊地点模式和一般模式两种培训范式，分别用于受控研究和在环境不确定性下的学习策略开发。研究结果揭示了在多目标优化中一个基本的不对称性：碳优化比 thaw（永久冻土保护）优化更容易；根据不同模式中的表现，thaw 策略的学习没有明显进展。在一般模式设置中，标准的偏好条件方法完全失败，而一种简单的递增式学习方法通过战略性选择训练历史记录来获得更优的性能。
### Conclusion
我们的结果表明，当前的多目标强化学习方法在实现具有气候适应性的森林管理策略方面仍面临重大挑战，而 BoreaRL 作为研究多目标强化学习在气候应用中的重要基准，可促进更有效方法的发展。我们开源 BoreaRL 以加速相关研究。
## 708. `cs.LG` - 朝向针对重症监护时间序列的自我监督基础模型 [PDF](https://arxiv.org/pdf/2509.19885), [HTML](https://arxiv.org/abs/2509.19885)
### Authors
Katja Naasunnguaq Jagd,Rachael DeVries,Ole Winther
### Background
近年来，针对特定领域的基础模型在医疗保健领域得到了迅速扩展，然而，针对重症监护时间序列的基础模型仍然相对未被充分探索，原因是可用数据集规模有限且获取困难。
### Innovation
该工作引入了一种基于双向变换器（Bi-Axial Transformer, BAT）的早期阶段预训练基础模型，该模型基于合并的电子健康记录数据集进行训练。通过将模型微调应用于用于死亡率预测的数据集，这表明该模型在用于资源受限环境下的通用和鲁棒临床应用方面具有潜力，特别是在小数据集（<5,000）的情况下，其表现优于监督学习基准模型。
### Conclusion
这些贡献展示了自我监督基础模型在资源有限的环境中支持重症监护时间序列的一般化和稳健临床应用的潜力。
## 709. `cs.LG` - 推动材料电子结构哈密顿量预测的通用深度学习 [PDF](https://arxiv.org/pdf/2509.19877), [HTML](https://arxiv.org/abs/2509.19877)
### Authors
Shi Yin,Zujian Dai,Xinyang Pan,Lixin He
### Background
深度学习方法在电子结构哈密顿量预测方面提供了比传统密度泛函理论方法更为显著的计算效率优势，然而原子类型多样性、结构模式以及哈密顿量的高维复杂性给通用化预测带来巨大挑战。现有的方法在这些方面的性能提升有限，未有效解决相关挑战。
### Innovation
本文提出了一种名为NextHAM的方法，结合了神经网络的E(3)-对称性和丰富的修正机制，用于高效且通用的材料电子结构哈密顿量预测。首先，通过初始的电子密度构建零步骤哈密顿量，作为输入级的特征描述符和输出级的初始目标哈密顿量估计，简化了输入输出映射的学习过程。其次，提出了一种具有严格E(3)-对称性和高非线性表达能力的神经Transformer架构进行哈密顿量预测。第三，提出了一种新的训练目标，确保空间和倒易空间中哈密顿量的准确性，并防止误差放大和“鬼态”的产生，后者是由于重叠矩阵条件数大造成的。此外，作者还创建了一个高质量的广泛覆盖的大数据集Materials-HAM-SOC，包含17,000种材料结构，覆盖了六行周期表中的68种元素，明确包含了随旋磁效应。
### Conclusion
在Materials-HAM-SOC数据集上的实验结果表明，NextHAM在预测哈密顿量和能带结构方面表现出色且高效。
## 710. `cs.LG` - 关于联邦学习中贡献评分计算的脆弱性 [PDF](https://arxiv.org/pdf/2509.19921), [HTML](https://arxiv.org/abs/2509.19921)
### Authors
Balazs Pejo,Marcell Frank,Krisztian Varga,Peter Veliczky
### Background
论文探讨了联邦学习中贡献评估的脆弱性，这是确保公平性和激励参与的关键机制。研究表明，贡献评分容易受到两种根本性因素的影响：架构敏感性和故意操纵。一方面，不同的模型聚合方法会对评分产生影响；另一方面，恶意参与者通过有策略地篡改其模型更新来提升自身贡献评分或降低其他参与者的权重，这也是一种潜在的威胁。
### Innovation
研究发现，传统的平均聚合方法在处理不稳定的或多样化的客户端时，并非总是最优的。高级的聚合技术可能会无意中显著改变最终的评分结果。同时，研究通过Flower框架在多种数据集和模型架构上进行广泛的实验，证实了聚合方法的选择和恶意攻击者的存在都对贡献评分具有显著影响，强调了需要更稳健的评估方案的重要性。
### Conclusion
通过实验证明了，选择不同的聚合方法和存在攻击者都是影响贡献评分的关键因素，提出需要研发更稳健的评估方案来确保公平性和准确性。
## 711. `cs.LG` - 几何约束方法的潜在迭代精炼流：面向少量样本生成 [PDF](https://arxiv.org/pdf/2509.19903), [HTML](https://arxiv.org/abs/2509.19903)
### Authors
Songtao Li,Zhenyu Liao,Tianqi Hou,Ting Gao
### Background
少量样本生成是从有限的训练数据中合成高质量且多样化的样本这一问题，是生成建模中的重大挑战。现有方法从头训练往往无法克服过拟合和模式崩塌的问题，而对大模型进行微调可能会继承偏见，同时忽略潜在空间中的几何结构至关重要性。基于这些局限性，该研究引入了潜在迭代精炼流（LIRF），重新定义少量样本生成为渐进的几何结构化流形的密集化。
### Innovation
LIRF 通过引入一个新颖的流形保持损失（manifold-preservation loss），在训练自编码器过程中确保潜在空间维护输入数据的几何和语义对应性。在此基础上，提出了生成-修正-增强循环。该循环中的候选样本通过几何修正操作优化，这是一种证明可收缩的映射，可将样本拉向数据流形，同时保持多样性。研究证明，生成的流形和真实数据流形之间的Hausdorff距离出现可预测的减少。
### Conclusion
LIRF 提供了解决数据稀缺生成建模问题的方案，不仅在理论上坚实，也高度有效。通过在猫图像数据集AFHQ-Cat上生成一致的高分辨率图像来展示其可扩展性。通过消融研究验证了流形保持的潜在空间和收缩修正机制在这方面的关键性。
## 712. `cs.LG` - 通过Frank-Wolfe Self-Play实现纯粹探索 [PDF](https://arxiv.org/pdf/2509.19901), [HTML](https://arxiv.org/abs/2509.19901)
### Authors
Xinyu Liu,Chao Qin,Wei You
### Background
本文研究了结构化的随机多臂赌博机中的纯粹探索问题。目标是从有限的假设集中高效地识别正确的假设。问题可以通过最大最小化优化来简化，其中参与者和怀疑者进行两玩家零和博弈。现有的方法通常需要投影和调参，本文提出了Frank-Wolfe Self-Play（FWSP）方法，这是一种无需投影、正则化和调参的算法。然而，结构约束使问题更加复杂，存在非唯一最优解、最优策略中对最好臂无质量、双线性目标函数和边界处的不连续性等挑战。
### Innovation
提出了Frank-Wolfe Self-Play (FWSP) 方法，这是一种无需投影、正则化和调参的算法。通过微分包含方法证明了在线性博彩机情况下，FWSP 可以实现对最优臂的识别，并证明了游戏值的收敛。基于 FWSP，进一步提出基于后验抽样的学习算法。数值实验表明，该算法存在消失的共轭间隙。
### Conclusion
本文通过微分包含方法证明了 FWSP 在线性博彩机情况下对最优臂识别的有效性，并通过数值实验验证了算法的有效性。
## 713. `cs.LG` - 阿尔茨海默病评分校准的少样本提示方法 [PDF](https://arxiv.org/pdf/2509.19926), [HTML](https://arxiv.org/abs/2509.19926)
### Authors
Jana Sweidan,Mounim A. El-Yacoubi,Nasredine Semmar
### Background
大型语言模型可以通过提示方法在无需重新训练的情况下，从语音转录中检测阿尔茨海默病。研究使用ADReSS数据集重新审视了零样本提示，并探讨了使用分层交错和严格方案的少量样本提示，采用类平衡协议，每个类别最多收集20个示例。该研究评估了两种达到最新提示效果的变体。这两种方法均在转录数据上进行评估，达到了0.82的准确率和0.85的AUC。
### Innovation
1. MMSE-Proxy提示：每个少量样本的例子都附带有通过确定性映射锚定到Mini-Mental State Examination分数段的概率，从而计算出AUC，达到0.82的准确率和0.86的AUC。2. 增强推理提示：使用多模态语言模型（GPT-5）生成少量样本示例集合，输入包含饼干盗窃图像、转录和MMSE，输出推理和与MMSE对齐的概率，达到0.82的准确率和0.83的AUC。这是首次将引发的概率绑定到MMSE和使用多模态构建来提高可解释性的ADReSS研究。
### Conclusion
该研究所提出的方法能够在转录数据上有效检测阿尔茨海默病，并通过两种不同的提示方法实现了很好的效果，表明了利用大型语言模型进行疾病检测的潜力。
## 714. `cs.LG` - 基于基础模型的探索：能力、局限性和混合方法 [PDF](https://arxiv.org/pdf/2509.19924), [HTML](https://arxiv.org/abs/2509.19924)
### Authors
Remo Sasso,Michelangelo Conserva,Dominik Jeurissen,Paulo Rauber
### Background
在强化学习（RL）领域，特别是在稀疏奖励环境下的探索仍然是一个挑战。尽管基础模型具有强大的语义先验，但它们作为经典RL基准测试中零样本探索代理的能力尚未完全明确。本文通过将大型语言模型（LLMs）和视觉大型模型（VLMs）在一个多臂赌博机、Gridworlds和稀疏奖励的Atari游戏环境中的测试，来评估基础模型在零样本探索方面的表现。研究结果揭示了一个关键的限制：尽管VLMs可以从视觉输入中推断出高层次的目标，但在精确的低层次控制方面却始终无法做到，即“知行合一”的差距（“knowing-doing gap”）。为了探讨这种差距的可能解决途径，本文在受控的理想场景中，研究了一个简单的策略性混合框架。结果显示，在理想条件下，VLM的指导可以显著提高早期样本效率，为使用基础模型进行探索提供了一种潜在的方法及对其限制进行了分析。
### Innovation
本文提出了使用VLMs进行零样本探索的方法，并通过一个受控的理想场景研究了这种方法，表明VLM的指导可以显著提高早期样本效率，揭示了使用基础模型进行探索的潜力和限制。此外，通过提出一个简单的策略性混合框架来探讨如何缩小“知行合一”的差距。
### Conclusion
尽管VLMs在高层次任务理解方面表现出色，但在低层次精确控制方面存在局限性，提出了一种简单策略性混合框架来促进知识和行动的一致性，并显示了这种方法在早期样本效率上的显著提升，从而为使用基础模型进行探索提供了一种可行的策略。
## 715. `cs.LG` - 你的网络有多深？转移算子的深层学习与浅层学习比较 [PDF](https://arxiv.org/pdf/2509.19930), [HTML](https://arxiv.org/abs/2509.19930)
### Authors
Mohammad Tabish,Benedict Leimkuhler,Stefan Klus
### Background
该领域之前的许多研究集中在如何利用深层神经网络来学习转移算子及其谱分解。然而，深层神经网络通常需要大量时间和计算资源，并且对超参数的敏感性高，收敛速度慢。本文旨在提出一种新的随机神经网络方法，以解决这些问题并提高效率。
### Innovation
该研究提出了一种名为RaNNDy的随机神经网络方法，该方法的隐藏层权重随机选择，仅训练输出层。其创新之处在于：1) 减少训练时间和资源消耗，同时保持准确率基本不变；2) 避免深度学习的常见问题，如对超参数的敏感性和缓慢的收敛性；3) 通过封闭形式求解输出层，直接表示操作符的本征函数；4) 能够通过集成学习估计计算出的谱性质的不确定性。
### Conclusion
该方法已应用于多种不同的动力算子，包括Koopman和Perron-Frobenius算子，以及Schrödinger算子。数值实例展示了该框架的优点和局限性，涵盖多个随机动力系统、蛋白质折叠过程和量子简谐振荡器。
## 716. `cs.LG` - 从样本到场景：一种新的概率预测新范式 [PDF](https://arxiv.org/pdf/2509.19975), [HTML](https://arxiv.org/abs/2509.19975)
### Authors
Xilin Dai,Zhijian Xu,Wanxu Cai,Qiang Xu
### Background
当前最先进的概率时间序列预测模型依赖于采样来表示未来的不确定性。然而，这种方法存在固有的局限性，如缺乏明确的概率、覆盖率不足和计算成本高。
### Innovation
本文提出了一种名为‘Probabilistic Scenarios’的新范式，旨在克服采样的局限性。该范式直接生成一组{场景，概率}对，避免了类似蒙特卡洛的近似方法。此外，提出了一种名为TimePrism的简单模型，仅由三个并行线性层组成，该模型在五个基准数据集的两个指标上达到了9/10的最先进的结果。
### Conclusion
本文展示了‘Probabilistic Scenarios’范式的潜力，为预测领域提供了研究的新方向，而不仅仅是依赖采样。
## 717. `cs.LG` - PromptCoT 2.0: 扩展大型语言模型推理的提示合成 [PDF](https://arxiv.org/pdf/2509.19894), [HTML](https://arxiv.org/abs/2509.19894)
### Authors
Xueliang Zhao,Wei Wu,Jian Guan,Zhuocheng Gong,Lingpeng Kong
### Background
大型语言模型（LLMs）正在从对话系统发展成为在奥林匹克数学和竞赛编程等任务上的强推理器。虽然通过扩大模型参数和测试时的计算来推动进步，但一个关键瓶颈是缺乏高质量的训练问题：由人类策划的数据集成本高且有限，而现有的合成语料库通常过于简单或狭窄。PromptCoT 1.0通过在提示合成中注入推理，提高了问题难度。
### Innovation
提出了PromptCoT 2.0，这是一种可扩展的框架，将手工设计的启发式方法替换为期望最大化（EM）循环，其中推理经过迭代改进以引导提示构建。这产生比先前语料库更难且更具多样性的问题。还支持两种后训练制度：(1) 自动博弈，强大模型通过可验证反馈自主改进；(2) 监督微调（SFT），较弱模型从教师提炼的轨迹中学习。实验证明这种方法的有效性。在自动博弈中，将PromptCoT 2.0应用于Qwen3-30B-A3B-Thinking-2507，在30B规模上建立了新的前沿结果。在SFT中，仅使用合成提示培训Qwen2.5-7B-Instruct提升了准确性，超过使用人类或混合数据培训的模型。
### Conclusion
这些结果确立了提示合成作为扩展推理的新维度，并将PromptCoT 2.0定位为未来开源模型的可扩展基础。
## 718. `cs.LG` - TABFAIRGDT：使用自回归决策树的快速公平表格数据生成器 [PDF](https://arxiv.org/pdf/2509.19927), [HTML](https://arxiv.org/abs/2509.19927)
### Authors
Emmanouil Panagiotou,Benoît Ronval,Arjun Roy,Ludwig Bothmann,Bernd Bischl,Siegfried Nijssen,Eirini Ntoutsi
### Background
确保机器学习中的公平性仍然是一项重大挑战，模型往往会继承训练数据中的偏见。生成模型作为一种新兴的方法，有望在数据层面减轻偏见，同时保持数据的有用性。然而，许多生成模型依赖于深度架构，尽管有证据表明，对于表格数据，更简单的模型也可以非常有效。本文提出了一种基于自回归决策树的新颖方法，用于生成公平的合成表格数据，以解决这一问题。
### Innovation
作者提出了一种名为TABFAIRGDT的新型方法，使用自回归决策树生成公平的合成表格数据。为了保证公平性，该方法提出了一种软叶重采样技术，可以在减少偏见的同时保持预测性能。这项工作进一步证明，更简单的自回归决策树模型对于表格数据同样非常有效，并且不需要对数据进行预处理，同时在生成高质量的公平合成数据方面表现出色，对下游任务而言公平性和有用性均有提升。此外，该方法在轻量级、高效且兼容CPU，甚至在不同数据集大小时都实现了与最快的当前最佳基准相比72%的速度提升，对于中等大小的数据集（10个特征，10000个样本）可以在标准CPU上一秒内生成公平的合成数据，使其成为公平性敏感的现实世界应用的理想解决方案。
### Conclusion
本文通过提出一种基于自回归决策树的方法——TABFAIRGDT，为生成公平的合成表格数据提供了一个高效的解决方案。实验结果表明，TABFAIRGDT不仅在公平性和预测性能之间取得了更好的折衷，还具有更高的合成数据质量，并且在效率和轻量化方面表现出色，适用于多种大小的数据集，在CPU上无需数据预处理。此外，该方法在生成公平合成数据方面具有极高的效率和兼容性，对实际应用具有重要意义。
## 719. `cs.LG` - 快于SVD，智于SGD：交替更新的OPLoRA [PDF](https://arxiv.org/pdf/2509.19977), [HTML](https://arxiv.org/abs/2509.19977)
### Authors
Abdulla Jasem Almansoori,Maria Ivanova,Andrey Veprikov,Aleksandr Beznosikov,Samuel Horváth,Martin Takáč
### Background
LoRA（低秩适应）通过在冻结权重的基础上学习低秩更新来微调大型模型，大幅减少了可训练参数和内存。然而，SVDLoRA（使用低秩投影的全训练）和LoRA微调之间仍存在一定差距，表明LoRA步骤仍有改进空间。
### Innovation
提出了OPLoRA（交替更新优化器），它通过将LoRA优化转换为可解释的子问题，并通过交替最小二乘法高效求解来弥合该差距。实验中发现最多1-2步交替更新即可达到截断SVD的效果，且过程中从不构造完整矩阵。此外，还检索了最近提出的LoRA预处理方法作为特殊情况。OPLoRA支持动量，并通过相同子例程（LoRSum）计算步长来维持低秩估计，内存预算仅为LoRA参数的3倍（即与Adam相同）。还提出了一种实验扩展版本，使用K-FAC度量，可能具有潜在兴趣。
### Conclusion
在多个任务（线性任务、MNIST、CIFAR-100和RoBERTa-base（MNLI））上，OPLoRA在使用显著较少内存的同时，其性能接近或达到SVDLoRA的表现。
## 720. `cs.LG` - MCGrad::网页规模下的多校准 [PDF](https://arxiv.org/pdf/2509.19884), [HTML](https://arxiv.org/abs/2509.19884)
### Authors
Lorenzo Perini,Daniel Haimovich,Fridolin Linder,Niek Tax,Dima Karamshuk,Milan Vojnovic,Nastaran Okati,Pavlos Athanasios Apostolopoulos
### Background
现有针对子组进行校准的方法在行业中尚未得到广泛应用，因为这些方法需要手动指定保护组，或者在可扩展性方面存在问题，有时还可能损害其他模型性能指标，如对数损失和精确召回曲线下的面积（PRAUC）。
### Innovation
MCGrad是一种无需手动指定子组的新型、可扩展的多校准算法。它不仅提高了其他机器学习评估指标，而且已经在Meta的多个生产模型中使用。
### Conclusion
MCGrad已经在生产环境中部署，并在多个公共数据集上也取得了良好的效果，展示了在大规模场景下进行多校准的潜力和效果。
## 721. `cs.LG` - 可学习的采样蒸馏技术用于离散扩散模型 [PDF](https://arxiv.org/pdf/2509.19962), [HTML](https://arxiv.org/abs/2509.19962)
### Authors
Feiyang Fu,Tongxian Guo,Zhaoqiang Liu
### Background
离散扩散模型（DDMs）在生成文本和分子等离散数据模式方面展现了强大的能力，但其实际应用受到效率低下的采样方法限制，需要大量的采样步骤。虽然通过使用更大步长加快DDMs的方法可以提高效率，但会显著降低生成质量，因为这会放大由于因子预测引发的解码误差和数值近似引发的离散化误差的影响。
### Innovation
本文提出了可学习的采样蒸馏（LSD）方法，该方法通过训练具有少量步数的学生采样器来学习与高质量教师采样器具有大量步数的中间得分轨迹对齐，通过优化可学习的采样器系数来适应性调整采样动力学。此外，还提出了LSD+进一步学习非均匀的时间安排，非均匀地分配步骤。实验表明，相较于现有采样器，我们的方法在显著减少采样步骤的同时，明显提高了采样质量。
### Conclusion
我们的方法在文本生成、图像生成和合成任务中的实验结果表明，LSD和LSD+显著优于现有采样器，能够在显著减少采样步骤的情况下实现更高的采样质量。
## 722. `cs.LG` - Diffusion-Augmented Contrastive Learning: A Noise-Robust Encoder for Biosignal Representations [PDF](https://arxiv.org/pdf/2509.20048), [HTML](https://arxiv.org/abs/2509.20048)
### Authors
Rami Zewail
### Background
学习生物信号的鲁棒表示通常受到有效数据设计挑战的困扰，现有的方法难以捕获生理数据中的复杂变化。现有的对比学习方法在这种情况下往往表现不佳，无法有效地捕捉生物信号数据中的复杂变化。因此，需要一种新的框架来解决这些问题并提高生物信号的鲁棒性表示学习效果。
### Innovation
本文提出了一种新颖的混合框架——Diffusion-Augmented Contrastive Learning (DACL)，并将其与散射变换结合使用，以生成更鲁棒的生物信号表示。DACL将扩散模型的概念与监督对比学习相结合，通过轻量级变分自编码器生成的潜在空间中的数据增强，增强了对噪声的鲁棒性，从而在不同的扩散时间步骤中实现了类别的区分与鲁棒性的平衡。
### Conclusion
本文通过在PhysioNet 2017 ECG数据集上的实验验证了DACL框架的有效性，结果显示AUROC为0.7815。DACL框架将扩散过程本身用于对比目标的驱动，形成了噪声不变的嵌入，表明其具有良好的类别可分离性的基础，开创了使用扩散过程进行表示学习的新范式。
## 723. `cs.LG` - Pi-Transformer: 物理启发的注意力机制用于时间序列异常检测 [PDF](https://arxiv.org/pdf/2509.19985), [HTML](https://arxiv.org/abs/2509.19985)
### Authors
Sepehr Maleki,Negar Pourmoazemi
### Background
多变量时间序列中的异常通常起源于时间上下文和跨通道协调，而非孤立的离群值。传统的异常检测方法往往在处理这种复杂关系时表现不佳。为了克服这一挑战，该论文提出了一种新的Pi-Transformer模型，该模型通过两个注意力路径——数据驱动的时间序列注意力和稳定演化先验注意力，来编码时间不变量（如尺度相关的自相似性和相位同步）
### Innovation
Pi-Transformer模型创新地将物理启发的先验知识融入注意力机制中。它包括两个注意力路径：一个是从数据驱动的时间序列注意力，另一个是平稳演化并编码时间不变性的先验注意力。在训练过程中，通过结合重建目标和差异项鼓励两种注意力之间的共识，但同时保持其含义上的区分。先验知识被正则化以实现平滑演化，并被轻度地蒸馏到数据集级别统计中。
### Conclusion
Pi-Transformer在五个基准测试集（SMD，MSL，SMAP，SWaT，PSM）中达到了最先进的或具有竞争力的F1分数，在涉及时间与相位断裂的异常检测上有特别优势。案例分析表明两个流的互补行为和检测在系统转变周围的可解释性。物理先验的嵌入及注意力机制使这种方法在复杂多变量系统中的异常检测更加校准和稳健。代码已公开发布于GitHub仓库。
## 724. `cs.LG` - 在部分可观测性条件下学习鲁棒的渗透测试策略：系统的评估 [PDF](https://arxiv.org/pdf/2509.20008), [HTML](https://arxiv.org/abs/2509.20008)
### Authors
Raphael Simon,Pieter Libin,Wim Mees
### Background
渗透测试是对网络进行模拟攻击以识别安全漏洞的过程，这可以被视为一个顺序决策问题，非常适合使用强化学习（RL）自动化。然而，由于在实际问题中普遍存在的部分可观测性问题，强度学习中的马尔可夫性质会失效，这给算法带来了极大挑战。部分可观测马尔可夫决策过程需要历史数据聚合或信念状态估计来学习有效的策略。本文研究了不同规模主机网络下的随机、部分可观测渗透测试场景，通过更具挑战性和代表性的基准，更好地反映现实世界的复杂性，从而开发出更鲁棒且可迁移的策略，这对于确保在多样化且难以预测的现实环境中的可靠性能至关重要。
### Innovation
利用传统的接近策略优化（PPO）作为基线，本文对比了许多旨在缓解部分可观测性的PPO变体，包括使用帧堆栈、增强观察信息的历史数据、以及使用递归或变压器架构的方法。系统地分析了这些方法在不同规模的主机网络上的表现，发现历史数据聚合极大地提高了算法的性能，使其收敛速度提高了三倍。通过手动检查算法学习到的策略，揭示了它们之间的明显区别，提供了超越定量结果的见解
### Conclusion
本文通过系统性的实验评估，验证了历史数据聚合在缓解部分可观测性渗透测试问题上的强大作用，表明这种方法对于提高算法性能和开发更鲁棒、更可移植的策略至关重要。
## 725. `cs.LG` - 你只需测量一次：关于设计单次测量量子机器学习模型的探讨 [PDF](https://arxiv.org/pdf/2509.20090), [HTML](https://arxiv.org/abs/2509.20090)
### Authors
Chen-Yu Liu,Leonardo Placidi,Kuan-Cheng Chen,Samuel Yen-Chi Chen,Gabriel Matos
### Background
量子机器学习（QML）模型通常依赖于重复测量可观测值来进行准确预测。这种对大量测量次数（shots）的依赖导致了较高的推理成本和时间开销，特别是在量子硬件访问通常按测量次数定价的情况下，这使得问题更加突出。
### Innovation
提出了一种名为You Only Measure Once (Yomo) 的简单但有效的设计，能够通过大幅减少测量次数，甚至达到单次测量的水平，实现准确的推理。Yomo通过使用概率聚合机制替换Pauli期望值输出，并引入鼓励清晰预测的损失函数，达到了期望值模型固有的每测量次数缩放限制。实验结果表明Yomo在不同测量次数预算下及去极化信道模拟中，均能持续优于基准模型的表现。
### Conclusion
通过启用精确的单次测量推理，Yomo显著降低了部署QML的成本（包括财务和计算成本），从而降低了量子机器学习的实际应用障碍。
## 726. `cs.LG` - 全能滤波器：一种通用状态估计算法 [PDF](https://arxiv.org/pdf/2509.20051), [HTML](https://arxiv.org/abs/2509.20051)
### Authors
Shiqi Liu,Wenhan Cao,Chang Liu,Zeyu He,Tianyi Zhang,Shengbo Eben Li
### Background
状态估计在科学和工程的各个领域都是一个长期存在的问题。最优滤波也是通过估计动态系统中隐藏状态来解决这个问题的方法之一。在本研究中，作者着眼于如何利用大型语言模型（LLMs）来实现这一点，特别是在利用噪声观测与文本原型的方式下进行状态估计。
### Innovation
作者提出了一个通用的滤波框架LLM-Filter，首次展示了一个通过合理模态对齐与冻结的LLM，结合特定提示结构（System-as-Prompt，SaP）来利用预训练的LLMs的推理知识来改进状态估计的方法。此外，LLM-Filter还展示了在不同环境下优良的泛化能力，并且研究发现模型规模的增加与训练时间的延长会造成滤波精度的提高。
### Conclusion
LLM-Filter代表了一种前景广阔的基础模型，它通过新颖的方法将大型语言模型应用于状态估计，展示了其在多个变化或未见过的环境中的广泛应用潜力，为动态系统的隐藏状态估计提供了新的思路和工具。
## 727. `cs.LG` - RAD: 朝着可信的检索增强多模态临床诊断 [PDF](https://arxiv.org/pdf/2509.19980), [HTML](https://arxiv.org/abs/2509.19980)
### Authors
Haolin Li,Tianjie Dai,Zhe Chen,Siyuan Du,Jiangchao Yao,Ya Zhang,Yanfeng Wang
### Background
临床诊断是一个高度专业化且复杂的学科，需要深厚的专业知识和严格遵守严格标准。当前的AI驱动医疗研究主要集中在知识图谱或自然语言预训练方法上，以融入医学知识，但这些方法主要依赖于模型参数中的隐式知识，忽略了根据不同下游任务所需的具体任务知识。在RAD框架中，开发了一种新颖的方法，通过检索和细化来自多种医学来源的以疾病为中心的知识，增强指导原则增强对比损失约束多模态特征与指导原则知识之间的潜在距离，以及使用指导原则作为查询的双变压器解码器，以引导跨模态融合，这将模型与从指导原则获取到特征提取和决策制作的临床诊断流程对齐。此外，为解决多模态诊断模型的可解释性量化评估缺乏的问题，引入了一组从图像和文本两个角度评估可解释性的标准。详细的研究表明，RAD框架具有良好的泛化能力，并且能够更精确地关注异常区域和关键指标，保证了基于证据的、可靠的诊断结果。
### Innovation
提出了一个新颖的框架——检索增强诊断（RAD），该框架直接将外部知识注入到多模态模型中，以解决传统方法中忽略下游任务特定知识的问题。具体而言，RAD通过检索和细化疾病中心的知识，增强以指导原则为基础的对比损失，并采用了指导原则作为查询的双变压器解码器。此外，引入了一套评估多模态诊断模型可解释性的标准，从图像和文本两个角度进行评估。RAD在不同解剖结构的数据集上进行了广泛评价，展示了其优秀的泛化能力和诊断准确性，并且能够更精确地关注异常区域和关键指标，确保提供基于证据的、可信的诊断结果。
### Conclusion
RAD框架在多个数据集上的广泛实验验证了其良好的泛化能力及卓越的性能。RAD能够使得模型更加专注于异常区域和关键指标，使得诊断结果更加基于证据、可信。此外，还提供了一套从图像和文本角度衡量模型可解释性的标准，增强了多模态诊断模型的可信性。所有代码已在 git存储库中开源。
## 728. `cs.LG` - 不完整的数据，完整的动态：一种扩散方法 [PDF](https://arxiv.org/pdf/2509.20098), [HTML](https://arxiv.org/abs/2509.20098)
### Authors
Zihan Zhou,Chenguang Wang,Hongyi Ye,Yongtao Guan,Tianshu Yu
### Background
从数据中学习物理动力学是机器学习和科学建模中的一个基本挑战。现实世界的观察数据本就存在不完整和不规则采样的问题，这对现有的数据驱动方法构成了重大挑战。
### Innovation
本文提出了一种基于扩散原理的框架，用于从不完整训练样本中学习物理系统。通过精心设计的拆分策略，我们的方法将每个样本战略性地拆分为可观测的上下文和不可观测的查询组件，然后训练条件扩散模型以在给定可用上下文的情况下重构缺失的查询部分。这种表述形式允许在任意观察模式下进行准确的补充，而不需要完整的数据监督。同时，我们在理论上证明了在轻微的正则条件下，我们的扩散训练范式在不完整数据上实现了渐近收敛到真正的完整生成过程。
### Conclusion
本文的方法在合成和真实世界物理动力学基准中表现优异，尤其是在数据稀少和不规则观察的情况下，表现特别强劲。这些结果表明了我们基于理论的原理方法在学习和补充部分观察动态方面的有效性。
## 729. `cs.LG` - 概率标志：语言模型中的数据语义与嵌入结构关联性 [PDF](https://arxiv.org/pdf/2509.20124), [HTML](https://arxiv.org/abs/2509.20124)
### Authors
Junjie Yao,Zhi-Qin John Xu
### Background
人们普遍认为语言模型的嵌入空间能够捕捉到语义关系，如数字嵌入通常呈现出与其自然顺序相符的有序结构。然而，形成这些结构的具体机制尚不完全清晰。这项研究通过分析数据分布来解释嵌入结构，旨在揭示数据分布如何指导嵌入结构的形成过程。
### Innovation
研究提出了一组概率标志，用以反映语义关系，通过实验和理论分析揭示了这些概率标志对嵌入结构有显著影响。此外，研究还将分析扩展到大型语言模型（LLMs），并通过训练Qwen2.5架构在Pile语料库的子集上进一步验证了此结论，发现这些概率标志与嵌入结构忠实对应，特别是在捕捉嵌入间的强双重视觉相似性方面表现出色。
### Conclusion
研究探讨了数据分布如何指导嵌入结构的形成，并建立了嵌入组织与语义模式之间的新理解，揭示了这一形成机制。
## 730. `cs.LG` - 在高维小额表数据中发现关联规则 [PDF](https://arxiv.org/pdf/2509.20113), [HTML](https://arxiv.org/abs/2509.20113)
### Authors
Erkan Karabulut,Daniel Daza,Paul Groth,Victoria Degeler
### Background
关联规则挖掘（ARM）旨在通过命题规则在数据集之间发现特征之间的模式，支持高风险决策中的知识发现和可解释机器学习。然而，在高维度设置中，规则爆炸和计算负担使得流行的算法方法几乎不可行，除非有效减少搜索空间。神经符号方法，如Aerial+，最近被提出以解决ARM中的规则爆炸问题。尽管它们处理了高维度数据，但仍然继承了神经网络的局限性，特别是在小数据集情况下性能较差。
### Innovation
本论文在高维度表格数据的关联规则发现方面做出了三个关键贡献：首先，实验证明Aerial+在五个真实数据集中的扩展能力比最先进的算法和神经符号基线快一到两个数量级。其次，提出了高维小数据集下的ARM新问题，如生物医学领域的基因表达数据，具有约18,000个特征和50个样本。第三，提出两种针对Aerial+的微调方法，使用表格基础模型。这些方法在五个真实数据集中显著提高了规则质量，表明其在小数据、高维度场景中的有效性。
### Conclusion
本研究展示了在高维度小数据集表格数据中Aerial+方法的有效性和针对性改进方法的优越性，为这一特定领域的关联规则发现提供了新的解决方案和技术支持。
## 731. `cs.LG` - 通过流形假设视角的生成模型反演 [PDF](https://arxiv.org/pdf/2509.20177), [HTML](https://arxiv.org/abs/2509.20177)
### Authors
Xiong Peng,Bo Han,Fengfei Yu,Tongliang Liu,Feng Liu,Mingyuan Zhou
### Background
模型反转攻击（MIAs）旨在重建具有代表性的类样本，而最近的生成MIAs利用生成对抗网络（GANs）学习图像先验知识来引导反转过程，生成具有高视觉质量和数据源真实性高的重构图。
### Innovation
本文通过流形假设来解释生成MIAs的有效性。作者发现生成反转过程中梯度异常噪音大，并通过流形投影方法实现了暗流噪声的自动清理，同时保持了与流形一致的信息方向。此外，作者提出了一种新训练目标以促进损失梯度与生成器流形的一致性，并提出了一种无需训练的方法来增强反转过程中的梯度-流形对齐。
### Conclusion
通过上述训练目标和无需训练的方法，本文显著提升了反转过程中的梯度-流形对齐，使得现有最佳生成MIAs效果得到持续改进。
## 732. `cs.LG` - 通过应用结构相似性改进的时间序列异常检测 [PDF](https://arxiv.org/pdf/2509.20184), [HTML](https://arxiv.org/abs/2509.20184)
### Authors
Tiejun Wang,Rui Wang,Xudong Mou,Mengyuan Ma,Tianyu Wo,Renyu Yang,Xudong Liu
### Background
现代工业应用和金融系统中的时间序列异常检测至关重要。由于异常标签稀缺且手动标注成本高昂，基于重建的无监督方法受到了广泛关注。然而，准确的异常检测仍然是一个未解决的难题，因为基于重建的方法的优化目标仅仅依赖于点对点的距离度量，忽略了时间序列的潜在结构特征，无法处理复杂的模式异常。
### Innovation
本文提出了一种新的结构增强异常检测方法StrAD，通过整合时间序列中隐藏的结构信息，丰富了重建模型的优化目标，使其更好地捕捉结构特征。StrAD适应了优化目标中的趋势、季节性和形状，学习潜在的结构特性，捕捉时间序列的内在模式变化。提出的结构感知优化目标机制可以确保原始数据和重建数据在结构特征上的对齐，保持全球波动和局部特性的连贯性。该机制可以插件化并应用于任何基于重建的方法，增强模型对点异常和模式异常的敏感性。
### Conclusion
实验结果表明，StrAD在五个真实世界的异常检测数据集上提高了最先进的基于重建模型的性能。
## 733. `cs.LG` - 超越Slater条件的在线时性约束马尔可夫决策过程 [PDF](https://arxiv.org/pdf/2509.20114), [HTML](https://arxiv.org/abs/2509.20114)
### Authors
Francesco Emanuele Stradi,Eleonora Fidelia Chiefari,Matteo Castiglioni,Alberto Marchesi,Nicola Gatti
### Background
研究在线时性约束马尔可夫决策过程（CMDPs）在随机和对抗约束下的优化问题。提出了一个新颖的算法，该算法在处理约束为固定但未知分布时表现出更好的保证，同时在对抗环境中也能确保子线性约束违反和$beta$-遗憾。之前的最好算法（Stradi等，2025）在处理这些场景时未达到同样的效果。
### Innovation
提出的算法在随机约束下达到了$tilde{/mathcal{O}}(text{sqrt}(T))$的遗憾和约束违反，并且在对抗环境中，无需依赖Slater条件就能实现子线性约束违反和$beta$-遗憾。特别地，在随机环境中，该算法不依赖Slater条件就能处理没有严格可行解的情况；在对抗环境下，该算法提供了更强的保证，不允许早期出现大规模约束违反同时仅使用严格安全策略来弥补。
### Conclusion
通过合成实验验证了算法的有效性，显示了该算法的实际效果。
## 734. `cs.LG` - 时间自适应HénonNets的分量守恒哈密尔顿系统 [PDF](https://arxiv.org/pdf/2509.20212), [HTML](https://arxiv.org/abs/2509.20212)
### Authors
Konrad Janik,Peter Benner
### Background
现有机器学习方法，如SympNets和HénonNets，用于学习辛积分器时，仍然要求使用固定步长的数据训练。对于时间自适应辛积分器的学习，已有工作提出了TSympNets作为SympNets的一种扩展。本文旨在对HénonNets进行类似的扩展。
### Innovation
本文提出了一个新的卷积神经网络架构T-HénonNets，该架构由设计上是辛的，并能处理自适应时间步长。同时，还扩展了T-HénonNets架构以适应非自治哈密尔顿系统。此外，文章讨论了在拟合不可分离的哈密尔顿系统时所面临的理论逼近能力的挑战。
### Conclusion
通过对新的网络架构进行不同的数值实验，以研究这些理论逼近能力，本文提供了一些关于分量守恒哈密尔顿系统的新神经网络架构的通用逼近定理。
## 735. `cs.LG` - Q-Palette: Fractional-Bit 量化器向高效大规模语言模型部署提供最优位分配 [PDF](https://arxiv.org/pdf/2509.20214), [HTML](https://arxiv.org/abs/2509.20214)
### Authors
Deokjae Lee,Hyun Oh Song
### Background
研究了在不需要重新训练的情况下，使用少量或无需校准数据对大型语言模型（LLM）的权重进行仅权重后训练量化（PTQ）。LLM的权重分布不规则且存在重尾异常值，这使得量化工作变得复杂。最近的研究表明，通过旋转方法将权重近似为高斯分布，可以减少异常值，从而降低量化误差。目前，已经获得了使用给定位预算下高斯化权重的信息论最优位分配，揭示了接近高斯失真-速率边界的小数位量化器的重要性。现有方法主要关注如何实现这种理论最优，但缺乏将理论转化为实践的解决方案。
### Innovation
提出了一种名为Q-Palette的多功能小数位量化器集合，涵盖从提供接近最优失真的梯度编码量化器到针对更快推理优化的向量和标量化量器。Q-Palette不仅包括高效实现的各种位宽优化CUDA内核，还提出了一种新的混合量化框架，该框架在给定资源约束的情况下联合优化量化器选择和层融合决策。
### Conclusion
基于Q-Palette，本文的量化方案不仅在理论上有最优性能，而且能够实现在实际大规模语言模型部署中的高效应用。代码已发布，可供进一步研究和使用。
## 736. `cs.LG` - 沿著流形：几何感知噪声注入 [PDF](https://arxiv.org/pdf/2509.20201), [HTML](https://arxiv.org/abs/2509.20201)
### Authors
Albert Kjøller Jacobsen,Johanna Marie Gegenfurtner,Georgios Arvanitidis
### Background
已有研究表明，训练过程中对输入的扰动会隐式地正则化学习到的函数梯度，从而导致更平滑的模型和更好的泛化能力。然而，先前的研究大多集中在添加环境噪声，却没有考虑到数据的潜在结构。
### Innovation
本文提出了一种新的方法，通过将几何感知的噪声注射到流形的切空间上，然后通过伴随的测地线曲线映射到流形上，同时也考虑了在流形上随机步进的布朗运动噪声。该方法在高度弯曲流形上提高了泛化能力和对超参数选择的鲁棒性，同时在简单流形上表现至少不劣于无噪声训练的方法。所提出的框架适用于学习到的数据流形。
### Conclusion
几何感知噪声的引入提升了模型在复杂流形上的泛化能力和对超参数的选择性，同时也保持了在简单流形上的良好表现。
## 737. `cs.LG` - 超越尖锐极小值：基于反馈引导多点优化的稳健大语言模型去学习 [PDF](https://arxiv.org/pdf/2509.20230), [HTML](https://arxiv.org/abs/2509.20230)
### Authors
Wenhan Wu,Zheyuan Liu,Chongyang Gao,Ren Wang,Kaize Ding
### Background
现有的大语言模型（LLM）遗忘方法面临一个关键的安全漏洞，该漏洞削弱了其根本目的：虽然这些方法看似成功地移除了敏感或有害的知识，但实际上这些“遗忘”的信息仍可通过重学习攻击被恢复。这类漏洞的根本原因是传统的方法通过在单个数据点上优化遗忘损失，导致模型参数向损失景观中的尖锐极小值靠拢。在这些不稳定区域中，即使是有微小的参数扰动也能大幅度改变模型的行为。重学习攻击利用这一漏洞，通过仅使用少量的微调样本导航这些不稳定区域周围的陡峭梯度，从而迅速恢复被声称已经删除的知识。
### Innovation
我们提出了StableUN，一种基于反馈引导的双层优化框架，通过邻域感知优化明确寻求更稳定的参数区域。它结合了遗忘反馈（利用对抗性扰动来探测参数邻域）和记忆反馈以保持模型的有用性，并通过梯度投影对两个目标进行对齐。
### Conclusion
实验表明，我们的方法在抗重学习和禁锢攻击方面具有显著的稳健性，同时保持了与竞品相当的性能。这展示了我们方法在实际知识移除中的优势。
## 738. `cs.LG` - 实用的估算方因果解释 [PDF](https://arxiv.org/pdf/2509.20211), [HTML](https://arxiv.org/abs/2509.20211)
### Authors
Álvaro Parafita,Tomas Garriga,Axel Brando,Francisco J. Cazorla
### Background
在解释性技术领域，SHAP（SHapley Additive exPlanations）是广受推崇的方法之一，但它往往忽略了问题的因果结构。针对这一局限，do-SHAP方法利用了干预查询，但其依赖的估量指标限制了其实用性。因此，本文提出了一种估算无偏因果推理方法，该方法允许通过单一模型估计任何可识别的查询，使do-SHAP在复杂图上成为可能。另外，本文还开发了一种新算法，显著加速了计算过程，且几乎无额外成本。此外，还提出了一种方法来解释不可访问的数据生成过程。本文通过验证估计能力和计算性能，并在两个实际数据集中进行了验证，以展示其可靠解释的潜力。
### Innovation
提出了估算无偏因果推理方法，通过单一模型估计任何可识别的查询，解决了do-SHAP依赖估量指标的问题。开发了一种新算法，显著提高了计算速度。提出了解释不可访问的数据生成过程的方法。验证了该方法在实际数据集上的性能和可靠性。
### Conclusion
本文方法有效解决了do-SHAP的局限性问题，在复杂图形上实现了可靠的因果解释。并且通过新算法大幅提高了计算效率，同时提出了解释不可访问数据生成过程的方法。通过两个实际数据集验证了其性能和可靠性，展示了其在获得可靠解释方面的潜力。
## 739. `cs.LG` - 基于HyperGraphMamba的多通道自适应模型用于ncRNA分类 [PDF](https://arxiv.org/pdf/2509.20240), [HTML](https://arxiv.org/abs/2509.20240)
### Authors
Xin An,Ruijie Li,Qiao Ning,Hui Li,Qian Ma,Shikai Guo
### Background
非编码RNA（ncRNAs）在基因表达调控和各种疾病的发生机制中扮演着关键角色。准确地分类ncRNAs对于功能注释和疾病诊断至关重要。现有的特征提取深度和多模态融合方法存在局限性，因此需要一种能够提高分类性能的新方法。新模型HGMamba-ncRNA通过整合ncRNAs的序列、二级结构和可选的表达特征，利用HyperGraphMamba提出了一个多通道自适应模型来解决这些问题。
### Innovation
提出的HGMamba-ncRNA模型提出了一个基于HyperGraphMamba的多通道自适应模型。该模型通过集成序列、二级结构和表达特征来提高ncRNAs的分类性能，利用多层次图变换器（MSGraphTransformer）捕捉ncRNA二级结构的多层次拓扑特征，利用基于Chebyshev多项式的小波网络（CPKAN）建模和解释高维表达谱，并通过引入虚拟节点促进有效的多模态交互。实验结果表明，该模型在多个公开数据集上的准确性显著优于现有方法。广泛的实证研究表明，该模型具有良好的鲁棒性、有效性和强大鲁棒性，为复杂ncRNA功能分类提供了一种新颖且可靠的方法。
### Conclusion
该模型通过多层次图变换器和基于小波网络等先进技术，有效提高了ncRNAs分类的准确性和可靠性。实验结果表明，HGMamba-ncRNA在各种公共数据集上表现出色，为ncRNA分类提供了一种可行的新策略。
## 740. `cs.LG` - Maximum Entropy RLHF的失败模式 [PDF](https://arxiv.org/pdf/2509.20265), [HTML](https://arxiv.org/abs/2509.20265)
### Authors
Ömer Veysel Çağatan,Barış Akgün
### Background
本文展示了Simple Preference Optimization (SimPO) 可以从 Maximum Entropy Reinforcement Learning（长度归一化温度）中推导出来这一事实，为这种方法提供了一个理论基础。文章基于SimPO在 offline preference optimization 中的强大表现，探索 Maximum Entropy RL 是否可以在在线 RLHF 情境中达到类似的效果。
### Innovation
作者发现，Maximum Entropy RL 在在线 RLHF 情境中表现出过度优化和不稳定的 KL 动态，即便是在非常低的学习率下也是如此。文章探讨了 SimPO 在 offline 情境下成功而 Maximum Entropy RL 在 online 情境下失败的原因，研究了 SimPO 成功背后的可能解释。
### Conclusion
研究结果表明，无参考的优化方法在应用于 online 或 offline 预训练学习时可能面临着不同挑战。
## 741. `cs.LG` - 基于预测编码的深度神经网络细调以实现计算高效的领域适应 [PDF](https://arxiv.org/pdf/2509.20269), [HTML](https://arxiv.org/abs/2509.20269)
### Authors
Matteo Cardoni,Sam Leroux
### Background
随着深度神经网络在动态、真实世界的环境中越来越广泛地部署，单一静态模型往往是不够的。传感器漂移或光照变化导致输入数据分布的变化，要求模型能够持续适应。本文背景在于，现有的方法在处理这种动态变化时存在不足，需要一种新的方法来有效应对，提高模型适应性并减少计算开销。
### Innovation
本文提出了一种混合训练方法，通过结合Backpropagation（反向传播）和Predictive Coding（预测编码）的优点，实现高效的设备端领域适应。该方法首先用反向传播在离线训练一个深度神经网络，以达到初始高性能；然后在线使用预测编码进行适应，使模型能够恢复因输入数据分布变化而丢失的准确性。该方法结合了反向传播在初始表示学习中的稳定性和预测编码在持续学习中的计算效率，特别适合资源受限的边缘设备或未来的神经形态加速器。实验结果表明，该混合策略能够有效适应，同时减少计算开销，提供了一个维持模型在动态环境中性能的有前景的解决方案。
### Conclusion
实验结果表明，这种方法能够在保持较高性能的同时，减少计算开销，特别适合资源受限的环境。这为深度学习模型在现实世界中的持续应用提供了新的策略。
## 742. `cs.LG` - AI推理的能源使用：效率途径与测试时计算 [PDF](https://arxiv.org/pdf/2509.20241), [HTML](https://arxiv.org/abs/2509.20241)
### Authors
Felipe Oviedo,Fiodar Kazhamiaka,Esha Choukse,Allen Kim,Amy Luers,Melanie Nakagawa,Ricardo Bianchini,Juan M. Lavista Ferres
### Background
随着AI推理处理的查询达到数十亿次，以及新兴的推理和自主工作流增加了对令牌的需求，可靠地估计每个查询的能源使用变得越来越重要，这对于容量规划、排放核算和效率优先级确定都至关重要。许多公开的数据存在不一致的情况，并且高估了能源使用，因为它们是基于有限的基准进行外推，未能反映大规模下可实现的效率提升。这篇论文基于此背景，评估了大型LLM系统的每个查询的能源使用量，并提出了一个新的基于令牌吞吐量的自底向上的估算方法。
### Innovation
论文引入了一种全新的基于令牌吞吐量的自底向上的估算方法，用于估计大规模LLM系统的每个查询的能源使用量。这种方法考虑了H100节点在实际情况下的GPU利用率和PUE限制，得出对于超大规模模型（超过2000亿参数）的中位值为每查询0.34Wh（四分位距：0.18-0.67）。此外，该方法还考量了测试时缩放场景下每普通查询15倍更多的令牌，能源使用量将增加13倍至4.32Wh。研究还量化了在模型、服务平台和硬件层面可能实现的效率提升，发现个体中位值降低为1.5-3.5倍的能源使用量，联合进展则可能实现8-20倍的降低。
### Conclusion
基于该研究，部署服务10亿次查询的基线日能源使用量约为0.8GWh/天。如果10％的查询为长查询，需求可能增加至1.8GWh/天。通过有针对性的效率改进措施，减少至0.9GWh/天，这与那个规模下的网页搜索的能源足迹相似。这呼应了数据中心在互联网和云计算建设期间通过效率提升来控制能源增长的趋势。
## 743. `cs.LG` - PGCLODA: 预令引导的图对比学习用于寡肽-传染病关联预测 [PDF](https://arxiv.org/pdf/2509.20290), [HTML](https://arxiv.org/abs/2509.20290)
### Authors
Dayu Tan,Jing Chen,Xiaoping Zhou,Yansen Su,Chunhou Zheng
### Background
传染病仍然是对公共卫生构成严重威胁的因素，因此迫切需要有效的计算方法来筛选新型抗感染剂。寡肽由于其结构简单、高生物可用性和低耐药性，已成为抗微生物研究中的有希望候选者。然而，专门用于预测寡肽与传染病之间关联的计算模型仍然很少。
### Innovation
本研究引入了一种预令引导的基于图的对比学习框架（PGCLODA），以发现潜在关联。PGCLODA通过构建一个三方图来整合寡肽、微生物和疾病的信息，使用预令引导的图增强策略生成有意义的配对视图，并结合卷积图神经网络（GCN）和转录器的双编码器架构来捕捉局部和全局特征。实验结果表明，PGCLODA在AUC-ROC、AUC-PR和准确率等指标上表现出色，并且消融和超参数研究证实了每个模块的贡献。案例研究表明，PGCLODA具有广泛适用性和发现新型生物学相关关联的潜力。
### Conclusion
这些发现为机制导向的发现和寡肽基药物开发提供了宝贵的见解，并且PGCLODA的源代码可以在该链接获取。
## 744. `cs.LG` - 具有学习内核的光谱算法的对齐敏感的最小最大率 [PDF](https://arxiv.org/pdf/2509.20294), [HTML](https://arxiv.org/abs/2509.20294)
### Authors
Dongming Huang,Zhifan Li,Yicheng Li,Qian Lin
### Background
研究在内核从数据学习的背景下光谱算法。介绍了有效的跨度维度（ESD），这是一个依赖于信号、频谱和噪声水平?(?sigma^2?)的敏感性度量，适用于任意内核和信号，无需满足特征值衰减条件或源条件。
### Innovation
提出了有效的跨度维度（ESD），并通过证明可扩展性展示了这一度量框架，能够减少过度参数化的梯度流，建立了可调特征学习与光谱算法泛化的证明改进之间的联系，并通过数值实验支持了理论。
### Conclusion
此框架提供了一种超越传统固定内核理论的新颖泛化视角。
## 745. `cs.LG` - 扩展低秩逼近加速异质材料弹性响应的学习 [PDF](https://arxiv.org/pdf/2509.20276), [HTML](https://arxiv.org/abs/2509.20276)
### Authors
Prabhat Karmakar,Sayan Gupta,Ilaksh Adlakha
### Background
预测微观结构如何影响多孔材料的机械响应对于优化设计和性能至关重要，但这一任务由于微观结构特征的复杂性和高维度性而变得非常困难。依赖于基于物理的模拟来探索微观结构空间是计算上昂贵的。因此，开发高效的计算工具以学习结构与性质之间的机械行为连接是必要的。尽管现代数据驱动的方法提供了新的可能性，但它们往往需要大量的数据集。
### Innovation
本文提出了一种扩展低秩逼近(xLRA)框架，该框架利用典型多线性张量分解来高效地将高维度的微观结构信息映射到局部弹性响应，并通过自适应引入高阶项来实现此目标。xLRA仅需训练5%的数据集即可实现高度准确的预测，证明了其高效数据利用能力。此外，xLRA展示了良好的可转移性，在包括两相复合材料和单相/双相多晶体的各种材料系统中都能产生结果。尽管xLRA是紧凑的，但它仍然能够保留关键的微观结构细节，以便在未见过的微结构上实现准确预测。xLRA在预测准确性、泛化能力和计算效率方面均优于当前方法，而消耗的浮点运算次数仅为其六分之一的数量级
### Conclusion
xLRA提供了一个高效框架，用于从微观结构预测弹性响应，从而能够实现结构与性质连接的大规模映射。
## 746. `cs.LG` - 动态滞后在电子商务金融时间序列预测中的应用：通过结合混合ML架构减轻信息丢失 [PDF](https://arxiv.org/pdf/2509.20244), [HTML](https://arxiv.org/abs/2509.20244)
### Authors
Abhishek Sharma,Anat Parush,Sumit Wadhwa,Amihai Savir,Anne Guinard,Prateek Srivastava
### Background
电子商务金融领域的时间序列预测因其不规则的发票周期、支付延迟以及用户特定的行为变异性而特别具有挑战性。这些因素与稀疏的数据集和较短的历史窗口结合在一起，限制了传统时间序列方法的有效性。虽然深度学习和基于Transformer的模型在其他领域显示出潜力，但在部分可观测性有限和历史数据较少的情况下，它们的表现会下降。因此，需要一种更有效的时空序列预测方法来解决这些问题。
### Innovation
为了应对这些挑战，该论文提出了一种结合动态滞后特征工程、自适应滑动窗口表示、经典统计模型和集成学习者的混合预测框架。通过这种方式，论文实现了详细的发票级行为建模，结构化的滞后支持数据，以及定制的稳定性敏感损失函数，从而在稀疏和不规则的金融数据设置中提供稳健的预测。实验结果表明，与基准模型相比，该方法在MAPE上的约有5%的降低，这转化为大量的财务节省。此外，该框架还增强了季度预测稳定性，并通过捕捉短期和长期模式，增强了功能目标之间的相关性，利用用户属性并模拟即将发生的发票行为。
### Conclusion
这些结果强调了结合结构化的滞后延迟、发票级关闭建模和行为洞察力对提高稀疏金融时间序列预测准确性的价值。这种方法克服了部分可观测性和数据稀疏性的限制，提供了强大的预测技能，并增强了模型的稳定性。
## 747. `cs.LG` - 稀疏神经网络的恢复保证 [PDF](https://arxiv.org/pdf/2509.20323), [HTML](https://arxiv.org/abs/2509.20323)
### Authors
Sara Fridovich-Keil,Mert Pilanci
### Background
该领域此前尚未证明关于稀疏ReLU神经网络恢复的第一个保证。研究者们在理解神经网络的稀疏性及其恢复机制方面取得进展。
### Innovation
该研究首次证明了稀疏ReLu神经网络的恢复保证。研究展示了具有稀疏网络权重的结构特性，以及如何使用简单的迭代硬限幅算法在恢复这些权重方面表现出色，并且存储需求与非零权重数量成线性关系。通过简单的实验验证了该理论结果，包括稀疏MLP恢复、MNIST分类及嵌入神经表示。
### Conclusion
实验结果表明，该方法在性能上与一种高效的但存记忆不经济的基准方法（基于迭代幅度剪枝）相当，甚至更好。
## 748. `cs.LG` - 视频模型是零样本学习者和推理者 [PDF](https://arxiv.org/pdf/2509.20328), [HTML](https://arxiv.org/abs/2509.20328)
### Authors
Thaddäus Wiedemer,Yuxuan Li,Paul Vicol,Shixiang Shane Gu,Nick Matarese,Kevin Swersky,Been Kim,Priyank Jaini,Robert Geirhos
### Background
大型语言模型（LLMs）的非凡零样本能力推动了自然语言处理从特定任务模型向统一的一般基础模型转变。这种转变源于简单而强大的原始原理：大型生成模型在大规模网络数据上进行训练。同样，今天的生成视频模型也依赖于相同的原始原理，其潜在路径是成为通用视觉理解模型，如同LLMs成为了一般语言理解模型。
### Innovation
研究者展示了Veo 3模型的零样本多任务能力，包括对象分割、边缘检测、图片编辑、理解物理属性、识别物体操作潜力、模拟工具使用等多种功能。这些能力表明视频模型能够进行初步的视觉推理，例如迷宫和对称性解决。
### Conclusion
Veo 3的这些零样本涌现能力表明视觉模型正在成为一个统一的、通用的视觉基础模型的道路上。
## 749. `cs.LG` - 特征动态作为隐含的数据增强：深层神经网络泛化的深度分解视角 [PDF](https://arxiv.org/pdf/2509.20334), [HTML](https://arxiv.org/abs/2509.20334)
### Authors
Tianyu Ruan,Kuo Gai,Shihua Zhang
### Background
与经典的泛化理论不同，本文从输入输出的角度扩展到内部特征的演变过程来探讨为什么深层网络能够泛化，指出特征在不同时期的稳定性和一致性在泛化中的作用，并揭示了特征动态如何促进隐式的结构增强作用，从而支持泛化.
### Innovation
本文创新地提出了从特征动态的视角理解深层网络的泛化能力，揭示了在浅层特征和深层特征结合时预测的稳定性，并且通过统计测试进一步证实了梯度下降（SGD）注入的方向性噪声对于形成结构化变化的作用.
### Conclusion
本文的研究结果支持了将特征动态的演变与泛化的概念框架联系起来的观点，这为未来通过特征动态来衡量泛化提供了新的实践方法，进一步研究可能导致新的泛化测量的替代指标.
## 750. `cs.LG` - 当判断变成噪声：LLM 判定基准设计缺陷如何悄然损害有效性 [PDF](https://arxiv.org/pdf/2509.20293), [HTML](https://arxiv.org/abs/2509.20293)
### Authors
Benjamin Feuer,Chiung-Yi Tseng,Astitwa Sarthak Lathe,Oussama Elachqar,John P Dickerson
### Background
随着大规模语言模型（LLM）评判标准的日益广泛应用，这些标准被用来评估复杂的模型行为。然而，它们的设计引入了传统基于真实数据的标准中不存在的失败模式。作者指出，如果缺乏明确的目标和可验证的架构，基准排名可能会产生大量噪声，尽管这些排名具有高置信度。为了诊断这些问题，作者提出了两种机制：模式遵循量化了判官整体判决中多少部分可以由明确的评估方案解释，揭示了当判官偏离其评分准则时的未解释变异；心理有效性和汇集了内部一致性和区分有效性信号，以量化任何基准运行中的不可约不确定性。通过对Arena-Hard Auto的应用，作者发现了广泛使用的判官中严重的方案不一致和因素压缩：例如，DeepSeek-R1-32B的未解释变异超过90%，大多数标准的因素相关性超过0.93。此外，作者还展示了Arena-Hard Auto所使用的一ELO聚合方式由于压缩和掩盖了实际排名不确定性，其效果也会减弱。这些结果揭示了设计缺陷，并挑战了这些基准的有效性，提供了构建具有更全面范围和可靠性感知的LLM判定基准的可操作原则。
### Innovation
通过引入两种机制来诊断大规模语言模型（LLM）判定基准中存在的问题：1) 模式遵循量化了判官整体判决中多少部分可以由明确的评估方案解释；2) 心理有效性和汇集了内部一致性和区分有效性信号，以量化任何基准运行中的不可约不确定性。这些机制可以帮助识别不可信的基准排名，并为构建更好的判定基准提供指导原则。研究表明，使用ELO样式聚合的Arena-Hard Auto基准运行存在很大的不可解释变异和因素压缩，这些现象揭示了设计缺陷。研究成果还指出了如何改进判定基准，使其更有针对性且具备更高的可靠性。开源代码为其他研究者提供了工具实现。
### Conclusion
研究指出，现有的大规模语言模型（LLM）判定基准中存在着严重的设计缺陷，这些缺陷导致了高置信度但实际上是噪声的基准排名。为了纠正这些问题，作者提出了一些原则和建议，强调了构建更全面、可靠性感知的判定基准的必要性。
## 751. `cs.LG` - 使用电路追踪揭示解码器仅有的变压器中的图推理 [PDF](https://arxiv.org/pdf/2509.20336), [HTML](https://arxiv.org/abs/2509.20336)
### Authors
Xinnan Dai,Chung-Hsiang Lo,Kai Guo,Shenglai Zeng,Dongsheng Luo,Jiliang Tang
### Background
基于变压器的大型语言模型在图推理任务中表现出强大的性能，但其内部机制尚待深入探索。为了在根本和统一的角度揭示这些推理过程机制，该研究采用基本的解码器变压器，并通过电路追踪框架对其进行解释。通过这种方法，作者可视化了推理追踪，并识别出两种核心机制：标记合并和结构记忆，这两种机制分别支撑了路径推理和子结构提取任务。
### Innovation
作者利用电路追踪方法揭示了解码器变压器中图推理的核心机制，包括标记合并和结构记忆。通过定量分析这些行为，研究进一步探讨了图密度和模型大小对这些行为的影响。这项研究提供了一个统一的可解释性框架，用于理解解码器变压器在结构推理中的工作机制。
### Conclusion
研究提供了一个统一的可解释性框架，用于理解和解析解码器变压器在结构推理中的工作机制。通过电路追踪方法揭示了图推理中的核心机制，以及这些机制如何受图密度和模型大小的影响。
## 752. `cs.LG` - Spatio-Temporal Directed Graph Learning for Account Takeover Fraud Detection [PDF](https://arxiv.org/pdf/2509.20339), [HTML](https://arxiv.org/abs/2509.20339)
### Authors
Mohsen Nayebi Kerdabadi,William Andrew Byron,Xin Sun,Amirfarrokh Iranitalab
### Background
账户接管（ATO）欺诈在消费者银行领域构成了重大挑战，需要在严格的时间限制内保持高召回率，同时尽量减少合法用户可能体验到的摩擦。现有的生产系统通常依赖于表格式梯度提升决策树（例如XGBoost），这种方式对会话进行独立评分，忽视了在线活动中伴随协调攻击和“欺诈团伙”所体现的关联性和时间性结构。
### Innovation
本文提出ATLAS（Account Takeover Learning Across Spatio-Temporal Directed Graph），这是一种框架，将账户接管检测重新定义为时域定向图上的时空节点分类问题。ATLAS通过共享标识符（账户、设备、IP地址）将实体关联起来，并借助时间窗口和相关性约束来控制连通性，从而实现因果关系的、时间敏感的信息传递以及针对评分时刻可利用标签的延迟感知标签传播，这使得模型不仅具有非前瞻性和无泄漏性。
### Conclusion
通过在包含超过100M个节点和接近1B条边的会话图上使用的诱导GraphSAGE变体的瞬时采样训练，本文成功地将ATLAS应用于Capital One公司的一款高风险数字产品中，实现了AUC提升6.38个百分点和超过50%的客户摩擦减少，从而在提高欺诈检测效率的同时，减少了用户办理过程中的摩擦。
## 753. `cs.LG` - Graph Variate Neural Networks [PDF](https://arxiv.org/pdf/2509.20311), [HTML](https://arxiv.org/abs/2509.20311)
### Authors
Om Roy,Yashar Moshfeghi,Keith Smith
### Background
在图神经网络（GNN）文献中，建模动态演变的空间-时间信号是一项显著挑战。虽然GNN假设有先存在的底层图结构，但在信号生成之前，该结构可能并不存在或独立于信号生成。从多通道数据中可以构建一个时间演变的功能网络。Graph Variate Signal Analysis (GVSA) 提出了一种统一的框架，该框架包括与稳定支持（通常由信号本身构建）相关的时间性连接模式网络张量。
### Innovation
本文基于GVSA和图信号处理工具，引入了Graph-Variate Neural Networks (GVNNs)：利用信号依赖的连接张量在稳定长期支持与即时数据驱动交互之间进行卷积的空间-时间信号层。这种设计在每个时间步中捕获动态统计相关性，不依赖于手工滑动窗口，并且可以通过线性序列长度的线性复杂性实现。在预测基准测试中，GVNNs 优于强图基础基线，并且在广泛使用的序列模型如LSTMs和Transformers方面具有竞争力。在EEG运动意象分类中，GVNNs 达到了很高的准确性，展现了其在脑-机接口应用中的潜力。
### Conclusion
GVNNs 通过结合稳定的长期支持和即时、数据驱动的交互，成功应对了动态演变的空间-时间信号建模挑战。这些模型在各种基准测试中表现出色，并在脑-机接口等应用中展现出巨大潜力。
## 754. `cs.LG` - 过程导向的制药制造中复杂热动态预测 [PDF](https://arxiv.org/pdf/2509.20349), [HTML](https://arxiv.org/abs/2509.20349)
### Authors
Ramona Rubini,Siavash Khodakarami,Aniruddha Bora,George Em Karniadakis,Michele Dassisti
### Background
现代工业监控和控制依赖于对复杂物理系统的准确时间序列预测。尽管深度学习模型能够捕捉复杂的动态特性，但由于物理不一致性和鲁棒性问题，它们的部署受到限制，因此在受监管环境中限制了其可靠性。制药冻干过程中的温度预测尤其需要高精度和物理合理性，以确保产品质量和一致性。
### Innovation
本文引入了一种过程导向预测（PIF）模型，该模型基于温度在制药冻干过程中的应用。研究了从经典模型（如自回归整合移动平均模型ARIMA和指数平滑模型ETS）到现代深度学习架构（如Kolmogorov-Arnold网络KAN）的多种模型。提出了一种将过程信息预先融入时间序列预测框架的方法，通过三种不同的损失函数：固定权重损失、动态不确定性损失和基于残差的关注机制（RBA）。该研究不仅评估了模型的准确性、物理一致性，还测试了它们对传感器噪声的鲁棒性，并验证了最佳模型在不同过程中的通用性。结果表明，PIF模型在精度、物理合理性和噪声耐受性方面优于数据驱动模型。
### Conclusion
本研究为制药制造领域关键应用中的可靠和可泛化预测解决方案提供了路线图，这有助于提高制药过程中的产品质量和一致性。
## 755. `cs.LG` - E2E Learning Massive MIMO for Multimodal Semantic Non-Orthogonal Transmission and Fusion [PDF](https://arxiv.org/pdf/2509.19312), [HTML](https://arxiv.org/abs/2509.19312)
### Authors
Minghui Wu,Zhen Gao
### Background
大规模多输入多输出（MIMO）可以提供高的频谱效率，但同时也导致了高维度的下行链路通道状态信息（CSI），这使得实时通道获取和预编码复杂化。
### Innovation
该研究提出了一种端到端（E2E）上行和下行信道状态信息（CSI）融合预编码网络，该网络在一个单一的E2E神经架构中联合模型了下行CSI参考信号（CSI-RS）设计、CSI反馈和基站（BS）预编码。通过该网络，上行探测参考信号（SRS）被输入进一个以MAXIM架构为基础的投影网络，输出频率、波束和端口域的投影矩阵，用于设计下行CSI-RS。UE随后压缩/量化CSI-RS观察结果并反馈一种紧凑的表示。在基站，两种互补的分支生成候选预编码：一个由量化下行观察驱动的反馈仅预编码网络，另一个是仅由上行SRS驱动的SRS仅预编码网络。这些候选预编码随后由融合预编码网络合并，生成最终的传输预编码器。所有模块均在三次阶段学习计划下训练。
### Conclusion
仿真结果表明，所提出的方案有效地利用了从SRS获得的信息和用户的反馈，相较于传统的基线方法，取得了明显更好的性能。
## 756. `cs.LG` - STL-FFT-STFT-TCN-LSTM：融合时频域特征的高效波高预测模型 [PDF](https://arxiv.org/pdf/2509.19313), [HTML](https://arxiv.org/abs/2509.19313)
### Authors
Huipeng Liu,Zhichao Zhu,Yuan Zhou,Changlu Li
### Background
随着传统能源消耗的增加及其对环境影响的加剧，波能因其高能量密度、稳定性、广泛分布和环保性而成为可再生能源大家族中一个非常有前景的成员。波能信号呈现强非线性、突变、多尺度周期性、数据稀疏性和高频噪声干扰等特点，这对波能预测提出了挑战。目前的物理模型构建成本极高。
### Innovation
本文提出了一种结合STL、FFT、STFT、TCN和LSTM技术的混合模型STL-FFT-STFT-TCN-LSTM，旨在优化多尺度特征融合、捕捉极端波高并解决高频噪声和周期信号问题，从而实现显著波高的高效准确预测。实验结果表明，该模型比单一模型和混合模型在捕捉极端波高和抑制高频噪声方面取得了更高的预测精度。
### Conclusion
该研究通过实验证明了STL-FFT-STFT-TCN-LSTM模型的有效性，其MAE降低了15.8%-40.5%，SMAPE降低了8.3%-20.3%，R增加了1.31%-2.9%。此外，消融实验表明每个组件步骤都是不可或缺的，进一步验证了模型在多尺度特征融合方面的优势。
## 757. `cs.LG` - LibEMER：一种用于EEG基多模态情绪识别的新基准和算法库 [PDF](https://arxiv.org/pdf/2509.19330), [HTML](https://arxiv.org/abs/2509.19330)
### Authors
Zejun Liu,Yunshan Chen,Chengxi Xie,Huan Liu
### Background
EEG基多模态情绪识别（EMER）近年来引起了广泛关注，并取得了显著进展。然而，该领域目前存在三个主要限制：(i) 缺乏开源实现，(ii) 缺乏标准化和透明的基准，不利于公平的性能分析，(iii) 主要挑战和潜在研究方向的讨论较少。
### Innovation
介绍了LibEMER，这是一种统一的评估框架，提供了精心挑选的深度学习方法的完全可重现PyTorch实现，并包含标准化的数据预处理、模型实现和实验设置协议。该框架允许在两个学习任务上对三个常用公开数据集进行全面无偏评估。LibEMER是开源库，可以在指定网址访问。
### Conclusion
该评估框架为公正评估性能提供了基础，促进了主要挑战和未来研究方向的讨论，有助于推动EEG基多模态情绪识别领域的进一步发展。
## 758. `cs.LG` - 从智能电表数据识别电动汽车 [PDF](https://arxiv.org/pdf/2509.19316), [HTML](https://arxiv.org/abs/2509.19316)
### Authors
Ammar Kamoona,Hui Song,Ali Moradi Amani,Mahdi Jalili,Xinghuo Yu,Peter McTaggart
### Background
电动汽车（EV）充电负荷的识别对于能源分配商了解其配电网络的可靠性是至关重要的。当电动汽车充电发生在电表之后（BTM）时，充电发生在用户的电表一侧，这意味着电动汽车的充电被视为用户的负荷的一部分，而不是单独由配电网络运营商（DNOs）进行测量。DNOs需要对其网络中的电动汽车有全面的了解。因此，识别电动汽车充电需求对更好地规划和管理配电电网至关重要。传统的监督方法需要事先知道电动汽车的充电模式，然而该研究提出了一种非入侵式的方法，利用基于异常检测技术的无监督学习方法，从低频智能电表数据中识别电动汽车充电负荷，不需要了解具体的电动汽车充电模式，只需要非电动汽车用户的真实电力消耗数据，这样数据在实践中是丰富的。通过在澳大利亚维多利亚州家庭的智能电表数据上应用深度时序卷积编码解码（TAE）网络，该方法在识别拥有电动汽车的家庭方面显示出了优越的性能。
### Innovation
该论文提出了一种非侵入式的、基于无监督学习的、使用异常检测技术的方法来从低频智能电表数据中识别电动汽车充电负荷，而不需事先了解电动汽车的具体充电模式，只需依托充足的实际非电动汽车用户的电力消耗数据。通过这种方法，该研究简化了电动汽车充电负荷识别的过程，提高了识别的准确率和效率。
### Conclusion
研究通过应用深度时序卷积编码解码（TAE）网络，在澳大利亚维多利亚州的家庭智能电表数据中成功识别了拥有电动汽车的家庭，并显示了优于其他方法的性能，为配电网络的管理和规划提供了重要的数据支持。
## 759. `cs.LG` - 基于图的时空注意力与多尺度融合的临床可解释高保真胎心电图提取 [PDF](https://arxiv.org/pdf/2509.19308), [HTML](https://arxiv.org/abs/2509.19308)
### Authors
Chang Wang,Ming Zhu,Shahram Latifi,Buddhadeb Dawn,Shengjie Zhai
### Background
先天性心脏病（CHD）是新生儿中最常见的异常问题，强调了早期检测的迫切需求以改善预后。然而，在腹部心电图（aECG）中，胎儿心电图（fECG）信号常常被母体心电图和噪声掩盖，尤其是在信噪比（SNR）低的情况下，这对传统方法构成了巨大挑战。
### Innovation
提出了一种名为FetalHealthNet (FHNet)的深度学习框架，该框架结合了图神经网络（GNN）和多尺度增强的变换器，以动态建模跨导联的空间-时间相关性并提取清洁的fECG信号。在基准的aECG数据集上，FHNet在多个模型中表现最佳，包括LSTM模型、标准变换器和最新的模型。即使在噪声严重的情况下，也达到了R2>0.99和RMSE = 0.015。解释性分析揭示了生理学上有意义的时间和导联贡献，提高了模型的透明度和临床信任度。
### Conclusion
FetalHealthNet展示了人工智能驱动建模在促进胎儿监测和实现早发CHD筛查方面潜力，突显了下一代生物医学信号处理的巨大变革影响。
## 760. `cs.LG` - 无监督异常检测在审计分析中的应用：以美国政府支出数据为例 [PDF](https://arxiv.org/pdf/2509.19366), [HTML](https://arxiv.org/abs/2509.19366)
### Authors
Buhe Li,Berkay Kaplan,Maksym Lazirko,Aleksandr Kogan
### Background
本研究探讨了无监督异常检测方法在审计分析中的有效性，使用美国卫生与人类服务部（DHHS）的美国政府支出数据作为案例。研究指出，在大规模政府数据集中，传统审计方法可能无法高效且准确地识别异常，因此需要更加高效和精确的异常检测方法。
### Innovation
本研究运用了多种异常检测算法，包括基于直方图的离群点评分（HBOS）、鲁棒主成分分析（RPCA）、最小协方差标识（MCD）和K-最近邻（KNN），并提出了一种结合多种检测策略的混合方法，以增强复杂金融数据中离群点识别的稳健性和准确性。
### Conclusion
本研究在审计分析领域提供了各种异常检测模型的比较有效性见解，并展示了无监督学习技术在提高审计质量和效率方面的潜力。研究结果对于寻求利用先进分析技术进行政府金融监督和风险管理的审计员、政策制定者和研究者具有重要意义。
## 761. `cs.LG` - 仅基于心电图数据的人体活动识别 [PDF](https://arxiv.org/pdf/2509.19328), [HTML](https://arxiv.org/abs/2509.19328)
### Authors
Sina Montazeri,Waltenegus Dargie,Yunhe Feng,Kewei Sha
### Background
人类活动识别对于早期干预和健康分析至关重要。传统的人体活动识别依赖于惯性测量单元（IMU），这会消耗大量资源并且需要校准。虽然已经探索了心电图（ECG）方法，但这些方法通常作为IMU的补充存在，或者只能用于如跌倒检测或日常活动的活跃与否的粗略分类。本研究通过证明，首次使用ECG在六种不同的活动中进行稳健的活动识别，证明了ECG的潜力。此前的工作通常局限于粗略的活动分类或使用ECG作为IMU的辅助手段。研究使用了54个受试者的数据进行六种活动的人体活动识别，结果表明所有三种模型的识别精度均超过94%，特别是CNNTransformer混合模型在未见过的受试者身上达到了最高的72%的识别率，说明这种方法有进一步改进的潜力。
### Innovation
前三项创新点如下：1.首次仅基于ECG数据实现了六种不同活动的人体活动识别；2.设计并评估了三种新的深度学习模型，包括使用Squeeze-and-Excitation块的CNN分类器、使用膨胀卷积的ResNet分类器，以及结合卷积特征提取与注意力机制的CNNTransformer混合模型；3.展示了ECG作为人体活动识别的潜力，而不依赖额外的运动传感器，为下一代同时进行心脏监测和活动识别的可穿戴设备的发展提供了可能。
### Conclusion
本研究展示了仅基于ECG数据在多种物理活动中实现成功的人体活动分类，为开发同时进行心脏监测和活动识别的下一代可穿戴设备提供了显著的潜力。
## 762. `cs.LG` - 基于新型对比损失和多模态学习的少样本儿童心律失常分类进步 [PDF](https://arxiv.org/pdf/2509.19315), [HTML](https://arxiv.org/abs/2509.19315)
### Authors
Yiqiao Chen,Zijian Huang,Zhenghui Feng
### Background
儿童心律失常是导致残疾和突发心脏死亡的主要风险因素，其自动分类因类别失衡、少样本类别和复杂信号特征而具有挑战性，这严重影响了早期筛查和临床干预的效果和可靠性。
### Innovation
提出了一种结合了双分支卷积编码器、语义注意力和轻量级Transformer编码器的端到端多模态深度学习框架，还引入了一个新的对比损失函数——自适应全局类别感知对比损失(AGCACL)，以通过类别原型和全局相似性矩阵增强类内紧凑性与类间分离性。此外，提供了完整的、可重复的预处理管道，基于莱比锡心脏中心的儿童/先天性ECG+IEGM数据集进行了系统研究。
### Conclusion
实验结果表明，所提出的方法在该数据集上表现出最佳的总体性能，包括97.76%的Top-1准确率、94.08%的宏精度、91.97%的宏召回率、92.97%的宏F1和92.36%的宏F2，相较于最强基准，宏精度/召回率/F1/F2分别提高了13.64、15.96、19.82和19.44个百分点。这些发现表明，该框架显著提高了对少数心律失常类别的检测能力和鲁棒性，具有潜在的临床价值，可用于儿童和先天性心脏病人群的心律筛查、术前评估和术后跟踪。
## 763. `cs.LG` - Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention [PDF](https://arxiv.org/pdf/2509.19331), [HTML](https://arxiv.org/abs/2509.19331)
### Authors
Enhao Huang,Zhiyu Zhang,Tianxiang Xu,Chunshu Xia,Kaichun Hu,Yuchen Yang,Tongtong Pan,Dong Dong,Zhan Qin
### Background
传统的深度学习模型在处理注意力机制时通常将注意力视为实数相关性，忽略了相位干涉效应，而复值信号编码了振幅和相位两方面的信息。
### Innovation
本文介绍了受物理学启发的Holographic Transformer架构，将波干涉原理引入自我注意中，实现了相位相关的互动，并通过相干叠加值保证振幅和相位的一致性。此外，提出了双头解码器，可以同时重构输入并预测任务输出，有效防止相位崩溃。
### Conclusion
实验结果显示，使用Holographic Transformer在极化SAR图像分类和无线信道预测任务中实现了优秀的性能，精度和F1分数高，回归误差低，并且对相位扰动具有更强的鲁棒性。这些结果表明，确保注意力机制中的物理一致性可以带来复值学习的一般性改进，并提供了一个统一的基于物理学框架的相干信号建模。
## 764. `cs.LG` - 一种基于测量报告的数据驱动局部统计信道模型框架 [PDF](https://arxiv.org/pdf/2509.19342), [HTML](https://arxiv.org/abs/2509.19342)
### Authors
Xinyu Qin,Ye Xue,Qi Yan,Shutao Zhang,Bingsheng Peng,Tsung-Hui Chang
### Background
局部统计信道模型（LSCM）对于数字孪生辅助网络优化的有效性能评估至关重要。传统方法依赖于高成本收集且空间覆盖有限的驱动测试数据来建模局部统计传播环境。本文旨在探索一种基于低成本且覆盖面广的测量报告（MR）数据的数据驱动框架，以提高LSCM的准确性和效率。
### Innovation
本文提出了一种基于测量报告的数据驱动框架，该框架包含两个新颖模块：1）MR定位模块，利用基于超图神经网络的半监督方法处理测量报告数据中的定位信息缺失问题；2）联合网格构建和信道AP估计模块，该模块通过集群和改进的稀疏恢复交替优化网格划分和AP估计，从而提高在非均匀空间数据中的模型鲁棒性。
### Conclusion
通过在实际测量报告数据集上的全面实验，本文展示了所提出框架在定位和信道建模中的优越性能和鲁棒性。
## 765. `cs.LG` - 一种时空特征融合的脑电虚拟通道信号生成网络及其在焦虑评估中的应用 [PDF](https://arxiv.org/pdf/2509.19334), [HTML](https://arxiv.org/abs/2509.19334)
### Authors
Shangqing Yuan,Wenshuang Zhai,Shengwen Guo
### Background
便携式脑电图（EEG）设备中存在的通道有限和信息收集不足的问题，限制了其应用效果和范围。为了克服这一局限，本研究探索了一种基于新颖时空特征融合策略的虚拟通道信号生成网络。该网络的目标是从四个额叶通道的EEG信号中生成虚拟通道EEG信号，以覆盖其他13个重要的脑区域，从而提高收集的信息量，弥补通道不足的问题，使便携式脑电图设备能够在机器学习算法中更好地进行焦虑评估研究。
### Innovation
该研究采用了一种新颖的时空特征融合策略，其网络架构为二维卷积神经网络，包括并行模块用于时间域和空间域特征提取，随后是一个特征融合模块。实验证明，生成的虚拟通道EEG信号与原始真实信号的平均相关系数为0.6724，绝对误差平均为3.9470，同时还表明虚拟EEG信号增强了焦虑评估中机器学习算法的性能。
### Conclusion
本研究有效解决了便携式EEG设备由于通道数少而信息收集不足的问题，生成的虚拟EEG信号不仅和真实通道EEG信号高度一致，还能显著提高焦虑评估中的机器学习算法效果。该网络在便携式EEG设备中具有广泛的应用前景。
## 766. `cs.LG` - ShinkaEvolve:走向开放和高效的程序演化 [PDF](https://arxiv.org/pdf/2509.19349), [HTML](https://arxiv.org/abs/2509.19349)
### Authors
Robert Tjarko Lange,Yuki Imajuku,Edoardo Cetin
### Background
近年来，大规模语言模型（LLMs）的推理时间计算规模扩展取得了显著进展，促进了通用科学发现的进步。当前的代码演化方法存在样本效率低下和闭源代码的问题，需要数千个样本才能找到有效的解决方案，并且限制了广泛采纳和扩展。ShinkaEvolve则致力于解决这些问题，致力于提高科学发现的效率和开放性。
### Innovation
ShinkaEvolve引入了三项创新：平衡探索和利用的父样本采样技术、代码新颖性拒绝采样以高效探索搜索空间，以及基于拉扎维（bandit-based）的大规模语言模型集成选择策略。这些创新使ShinkaEvolve在样本效率和解决方案质量上表现出一致的改进，并实现了广泛的适用性和出色的样本效率。ShinkaEvolve在多样化的任务中取得了新的最佳圈排列解决方案，设计了高性能的代理框架，对AIME数学推理任务、ALE-Bench编程挑战和负载均衡策略进行了优化，实现了新的混合专家损失函数，揭示了优化策略的空间。
### Conclusion
ShinkaEvolve通过开放源代码和降低成本，使开放性的发现适用于各种计算问题，展现了广泛的适用性和高效的样本使用率。
## 767. `cs.LG` - LLM-Assisted Topic Reduction for BERTopic on Social Media Data [PDF](https://arxiv.org/pdf/2509.19365), [HTML](https://arxiv.org/abs/2509.19365)
### Authors
Wannes Janssens,Matthias Bogaert,Dirk Van den Poel
### Background
BERTopic框架利用转换器嵌入和层次聚类从非结构化的文本语料库中提取潜在主题。然而，这种方法在社交媒体数据上表现不佳，因为社交媒体数据通常包含噪声且稀疏，导致生成过多重叠的主题。最近的研究探索了使用大型语言模型进行端到端的主题建模，但这些方法通常需要大量的计算资源，限制了它们在大数据环境中的可扩展性。因此，需要一种结合BERTopic进行主题生成和大型语言模型进行主题合并的方法来改善这些问题。
### Innovation
本文提出了一种框架，结合了BERTopic的主题生成和大型语言模型的主题合并。该方法首先生成初始主题集并构建每个主题的表示，然后将这些表示作为输入提供给语言模型，该模型会迭代地识别和合并语义相似的主题。该方法在三个Twitter/X数据集和四种不同的语言模型上进行了评估，相较于基准方法，该方法在增加主题多样性和在许多情况下提高主题连贯性方面表现出色，但有些敏感于数据集特性和初始参数选择。
### Conclusion
总的来说，该方法在提高社交媒体数据主题建模的效果方面取得了显著进展，特别是在主题多样性和连贯性方面。尽管存在一些敏感性因素，但该方法在大数据环境中的表现表明其具有较大的应用潜力。
## 768. `cs.LG` - 飞虫嗅觉神经电路结构变化对学习能力的影响 [PDF](https://arxiv.org/pdf/2509.19351), [HTML](https://arxiv.org/abs/2509.19351)
### Authors
Katherine Xie,Gabriel Koch Ocker
### Background
已知果蝇蘑菇体（MB）参与嗅觉学习和记忆；肯尼细胞（KC）与蘑菇体输出神经元（MBON）之间的突触可塑性在学习过程中起关键作用。以往的研究主要集中在蘑菇体内的传导神经元（PN）与肯尼细胞（KC）之间的连接；本研究探讨了对蘑菇体电路结构的扰动和连接的变化，特别是肯尼细胞（KC）与蘑菇体输出神经元（MBON）之间的神经回路中的变化，如何影响MBON区分不同的气味类别的能力。论文通过构建一个包含PN, KC和MBON之间连接的神经网络，训练模型，并收集了KC向MBON连接的数量、MBON错误率和KC-MBON突触权重等数据，从而深入理解嗅觉神经可塑性，并提供关于学习和记忆理解的重要线索。
### Innovation
研究首次构建了一个整合了PN、KC和MBON之间连接的神经网络，并通过生成十种人工输入类别来训练模型；通过随机和有目标的KC去除实验，以及随机和有目标的KC-MBON突触修剪，发现发育成熟的KC去除对MBON的学习能力的负面影响更大；还通过重新布线实验进一步探索了不同类型的KC，从而进一步理解了嗅觉电路如何处理和学习信息。这些研究结果为理解嗅觉神经可塑性及学习记忆提供了重要线索，并可能在人工智能和神经退行性疾病治疗方面找到应用。
### Conclusion
我们的研究揭示了CB中的结构变化如何影响VMN的学习能力，并增进了我们对气味分类任务中KL到VMN连接动态的理解。这些观察结果可能有助于更深入地理解嗅觉神经可塑性，并为一般的学习和记忆提供重要线索。我们的研究有助于揭示嗅觉电路如何处理和学习信息，并为人工智能和神经退行性疾病治疗提供潜在的应用。
## 769. `cs.LG` - 在多小区边缘网络中协调多点广播的细粒度AI模型缓存与下载 [PDF](https://arxiv.org/pdf/2509.19341), [HTML](https://arxiv.org/abs/2509.19341)
### Authors
Yang Fu,Peng Qin,Yueyue Zhang,Yifei Wang
### Background
6G网络计划支持按需下载AI模型，以满足不同终端用户的各种推理需求。通过在边缘节点上预先缓存模型，用户可以使用低延迟进行设备内AI推理。然而，现代AI模型的庞大尺寸给在有限存储容量的边缘节点上缓存模型以及通过无线信道同时分发异构模型带来了重大挑战。为解决这些问题，本文提出了一种细粒度的AI模型缓存与下载系统，利用模型参数重用，即使用冻结参数从共享预训练模型中进行细粒度任务调整。该系统选择性地在边缘节点处缓存模型参数块（PBs），并消除在不同缓存模型中冗余的可重用参数存储。此外，该系统采用协调多点（CoMP）广播同时向多个用户传输可重用的PBs，从而提高下行链路频谱利用率。在这一配置下，我们构建了一个模型下载延迟最小化问题，以联合优化PB缓存、移动（边缘节点间）和广播波束形成。
### Innovation
本文提出了一种细粒度的AI模型缓存与下载系统，该系统利用参数重用原则，在边缘节点选择性缓存模型参数块（PBs），并在用户间共享可重用参数，以减轻存储空间的限制。同时，系统采用了协调多点（CoMP）广播技术，以提升频谱利用率，实现了同时向多个用户分发可重用的PBs。为了优化PB的缓存、迁移和广播波束形成问题，本文开发了一种分布式多代理学习框架，使边缘节点能够显式学习彼此行为的影响，从而促进合作。此外，还提出了一种数据增强方法，通过预测模型自适应生成合成训练样例，增强样本效率并加速策略学习。
### Conclusion
本文提出的系统旨在优化6G网络中的AI模型下载，通过细粒度的选择性缓存、协调多点广播和分布式多代理学习框架克服了存储限制和频谱利用难题。理论分析和仿真实验验证了所提出学习框架的收敛性能优越性。
## 770. `cs.LG` - 基于神经网络的MIMO系统中二次谐波互调消除框架 [PDF](https://arxiv.org/pdf/2509.19382), [HTML](https://arxiv.org/abs/2509.19382)
### Authors
Xiaolong Li,Zhi-qin John Xu,Peiting You,Yifei Zhu
### Background
在5G及以后的严格要求下，二次谐波互调(PIM)成为了现代MIMO-OFDM系统中的关键自干扰来源。传统的消除方法通常依赖于复杂的非线性模型，这些模型在扩展性和计算成本方面都有限制。
### Innovation
提出了一种轻量级的深度学习框架用于PIM消除，该框架利用深度可分离卷积和膨胀卷积来高效捕获天线和子载波之间的非线性依赖关系。此外，采用循环学习率调度和梯度裁剪来进一步增强收敛性。
### Conclusion
实验结果表明，在受控的MIMO实验设置中，该方法有效地抑制了二次PIM失真，仅用11k个可训练参数就实现了29dB的平均功率误差，强调了紧凑神经架构在未来无线通信系统中高效抑制干扰的潜力。
## 771. `cs.LG` - 使用分类方法基于Arduino Mega 2560的低成本传感器融合框架用于有机物质分类和质量控制 [PDF](https://arxiv.org/pdf/2509.19367), [HTML](https://arxiv.org/abs/2509.19367)
### Authors
Borhan Uddin Chowdhury,Damian Valles,Md Raf E Ul Shougat
### Background
该研究提出了一种基于标准Arduino Mega 2560微控制器平台的传感器融合框架，用于快速、无损地对有机物质进行分类和质量控制。该平台配备了三个商用环境和气体传感器。所有数据均在内部生成，包括十个不同的类别的传感器输出：包括新鲜和过期苹果汁、洋葱、大蒜和姜，以及肉桂和小豆蔻。通过这种方法制成了一个独特的、应用特定的数据集。
### Innovation
该创新点在于开发了一种低成本的多传感器融合平台，用于有机物质的识别和质量控制。通过标准Arduino Mega 2560微控制器平台以及高级机器学习和相关特征工程，实现了对有机化合物的可靠识别和质量控制。研究通过特征选择中的相关分析，数据预处理和降维（PCA/LDA），以及多种监督学习模型的训练和交叉验证，展示了其在分类准确性方面的显著提升，其中最佳模型的测试准确率达到93%至94%之间。
### Conclusion
研究表明，基于Arduino Mega 2560的低成本多传感器平台结合先进的机器学习和相关驱动的特征工程，能够有效实现有机化合物的快速识别和质量控制。这些结果表明，低能耗且具有成本效益的传感器融合框架具有广泛应用的潜力，特别是在需要快速和可靠质量控制的有机物质分类领域。
## 772. `cs.LG` - 数据驱动稀疏观测条件下显著波高重建 [PDF](https://arxiv.org/pdf/2509.19384), [HTML](https://arxiv.org/abs/2509.19384)
### Authors
Hongyuan Shi,Yilin Zhai,Ping Dong,Zaijin You,Chao Zhan,Qing Wang
### Background
对稀疏且分布不均匀的浮标观测数据进行高分辨率区域显著波高（SWH）场的重构，仍然是海洋监测和风险感知操作中的核心挑战。
### Innovation
提出了一种名为AUWave的混合深度学习框架，将站级序列编码器（MLP）与多尺度U-Net相结合，并改进了瓶颈自注意力层，以恢复32×32区域的SWH场。系统性的贝叶斯超参数搜索确定学习率是通用性的主要驱动因素，其次是调度衰减和潜在维度。通过Hawaii地区的NDBC浮标观测和ERA5再分析数据，AUWave达到了最低验证损失0.043285和略微右偏的RMSE分布。
### Conclusion
实验结果显示，AUWave在数据丰富配置中持续优于代表性基准，在最缺乏数据的单浮标情况下，基准也仅微弱竞争。该架构的多尺度和注意力组件在提供少量但非琐碎的空间锚点时带来了准确性提升。错误图和浮标移除分析揭示了关键的锚点站，其移除显著降低性能，为网络设计提供了实际指导。AUWave为填补数据缺口、数据同化中的高分辨率先验以及应急重建提供了可扩展途径。
## 773. `cs.LG` - 一种用于EEG中EMG伪影去除的统计混合专家框架：经验见解及概念验证应用 [PDF](https://arxiv.org/pdf/2509.19385), [HTML](https://arxiv.org/abs/2509.19385)
### Authors
Benjamin J. Choi,Griffin Milsap,Clara A. Scholl,Francesco Tenore,Mattson Ogg
### Background
目前，神经接口的有效控制受到信号质量差的限制。尽管近年来基于神经网络的电肌电图（EMG）伪影去除方法得到了改进，但当前最先进的（SOTA）模型在高噪声环境下的表现仍然不尽如人意。
### Innovation
本文提出了一个新的信号过滤算法，该算法基于一个新颖的混合专家（MoE）框架。文章引入了三个新的统计见解来解决EEG-EMG去噪问题：（1）EMG伪影可以被划分为可量化的子类型，这有助于下游MoE分类；（2）局部专家通过专业化可以在更窄的信噪比（SNR）范围内实现性能提升；（3）基于相关性的目标函数与缩放算法相结合，可以在神经网络去噪的背景下加速收敛。
### Conclusion
通过在主要基准数据集（EEGdenoiseNet）上测试所有结果，本文发现MoE去噪模型在整体性能上与SOTA ML去噪算法相当，而在高噪声环境中，其下限性能更优。这些初步结果表明，MoE框架能够有效提升EEG中EMG伪影去除，特别是对于高噪声环境。未来的研究将需要在更广泛的现实测试案例中评估MoE框架，并进一步挖掘其潜在应用以实现更有效的神经接口。
## 774. `cs.LG` - 使用深度学习在越野环境中基于视觉的自主车辆感知 [PDF](https://arxiv.org/pdf/2509.19378), [HTML](https://arxiv.org/abs/2509.19378)
### Authors
Nelson Alves Ferreira Neto
### Background
在开放露天矿与发展中地区的非均匀地形上进行自主驾驶，需要低延迟的智能系统。因此，本研究提出了一个适用于非铺装路面和无固定路线环境的感知系统，旨在让自主车辆能够在复杂地形中导航。
### Innovation
提出了可配置模块分割网络（CMSNet）框架，该框架支持不同的架构配置。CMSNet配置经过训练，可以在恶劣条件下（如夜间、雨天、尘土）的新图像中分割出障碍物和可通行地面。研究了在没有明确轨道界限的情况下使用深度学习来检测可通行区域，并分析了在视线受损情况下的算法行为。此外，还提出了名为Kamino的新数据集，包含来自八个同步摄像机的近12,000张实车拍摄的图像，并成功实现了实时推理。
### Conclusion
实验结果验证了所提系统在两个数据集上的有效性，证明了CMSNet框架和Kamino数据集的有效应用。
## 775. `cs.LG` - ChatIYP: 启用对Internet黄页数据库的自然语言访问 [PDF](https://arxiv.org/pdf/2509.19411), [HTML](https://arxiv.org/abs/2509.19411)
### Authors
Vasilis Andritsoudis,Pavlos Sermpezis,Ilias Dimitriadis,Athena Vakali
### Background
互联网黄页（IYP）将多个来源关于互联网路由的信息整合到一个统一的图形知识库中。然而，查询它需要了解Cypher语言和确切的IYP模式，这限制了非专家的使用。
### Innovation
本文提出了一个领域特定的检索增强生成系统ChatIYP，它使用户能够通过自然语言问题查询IYP。这项创新通过自然语言简化了查询过程，减少对特定技术语言的依赖。
### Conclusion
评估表明ChatIYP在简单查询上表现良好，并且提供了改进方向，还对更适合IYP查询AI代理的评估指标提供了见解。
## 776. `cs.LG` - 韧性喷泉标记的帕累托前沿 [PDF](https://arxiv.org/pdf/2509.19431), [HTML](https://arxiv.org/abs/2509.19431)
### Authors
Rikab Gambhir,Matt LeBlanc,Yuanchen Zhou
### Background
在现代高能碰撞物理中，使用其组成成分的动量和能量信息对强子喷泉进行分类是一项关键任务。通常，分类器是通过优化准确性、AUC或拒绝率等单一指标来设计的。然而，这种做法可能导致所使用的模型比竞争性替代方案更为依赖模型，从而在分析中产生潜在的不确定性和偏差。
### Innovation
本文探讨了上述权衡，并证明了使用具有高性能指标但低鲁棒性的网络的后果。本文提出了关于如何在确保分类性能的同时提高分类器鲁棒性的新思路。
### Conclusion
通过研究韧性分类器的帕累托前沿，本文展示了在保持高精度的同时提高分类器鲁棒性的必要性，从而减少了模型依赖性和潜在的分析偏见。
## 777. `cs.LG` - SpellerSSL: 自监督学习与P300聚合在拼写BCIs中的应用 [PDF](https://arxiv.org/pdf/2509.19401), [HTML](https://arxiv.org/abs/2509.19401)
### Authors
Jiazhen Hong,Geoff Mackellar,Soheila Ghane
### Background
基于脑电图（EEG）的P300拼写脑-计算机接口（BCI）面临着三个主要挑战：低信噪比（SNR）、差的泛化能力和耗时的校准。SpellerSSL框架通过结合自监督学习（SSL）与P300聚合策略来应对这些挑战。
### Innovation
SpellerSSL框架引入了聚合策略以提升SNR，使用定制的1D U-Net主干和预训练模型在同一域和跨域EEG数据上的方法来达到训练中的泛化。随后，模型使用轻量级ERP-Head分类器进行P300检测的微调，以适应特定被试的数据。通过结合聚合策略和SSL，显著减少每名被试的标定负担，提高跨被试的鲁棒性。SSL在同域和跨域训练中学习到了有效的EEG表示，同域环境下仅需7次重复获取94%的字符识别率，信息传输率（ITR）达到21.86比特/分钟。在跨域环境下，通过P300聚合减少校准数据大小60%，同时保持相似的字符识别率。这是首次将SSL应用于P300拼写器，展示了其在提高效率和泛化方面的能力，并为P300拼写器BCIs建立大脑-计算机接口的EEG基础模型奠定了基础。
### Conclusion
SpellerSSL框架结合自监督学习与P300聚合策略显著提高了P300拼写BCI的效率和泛化能力，展示了其作为P300拼写BCIs大脑-计算机接口的神经基础模型的潜力。
## 778. `cs.LG` - 在长时间EEG信号中的混合管道SWD检测 [PDF](https://arxiv.org/pdf/2509.19387), [HTML](https://arxiv.org/abs/2509.19387)
### Authors
Antonio Quintero Rincon,Nicolas Masino,Veronica Marsico,Hadj Batatia
### Background
棘波-棘慢波放电（SWDs）是失神癫痫的电生理特征，但在长时间的多电极记录中人工识别它们仍然是一项劳动密集型且易出错的任务。这项研究介绍了一个轻量级的混合管道，结合了分析特征和浅层人工神经网络（ANN），以准确地在长时间段的单极EEG中进行个性化的SWD检测。该方法首先使用双侧移动平均（MA）滤波器抑制正常背景活动的高频分量，然后通过分析其正态分布样本的均值和标准差来总结残留信号，生成20秒窗口的紧凑型二维特征向量。这些特征被输入到通过反向传播训练的单一隐藏层ANN中，用于分类每个窗口为SWD或非SWD事件。该方法在12名患者、780个通道、256Hz采样率下进行了评估，涵盖了392个已标注的SWD事件，正确检测了384个事件，敏感性为98%，特异性为96.2%，综合准确率为97.2%。因为特征提取是分析性的，且分类器较小，所以管道可以实现实时运行，无需手动阈值调整。这些结果表明，结合正态分布描述符和一个适度的ANN为在延长EEG记录中自动筛查SWD提供了有效且计算代价低廉的解决方案。
### Innovation
该研究提出了一种结合分析特征和浅层人工神经网络的轻量级混合管道，用于在长时间段的单极EEG中进行个性化的SWD检测。该方法通过双侧移动平均滤波器抑制了正常背景活动的高频分量，并通过正态分布样本的均值和标准差生成特征向量，同时利用反向传播训练单一隐藏层ANN进行分类。实验证明，该方法具有高准确率和实现实时运行的能力，无需手动阈值调整，是一个有效的解决方案。
### Conclusion
该混合管道通过结合正态分布描述符和浅层人工神经网络，在长时间EEG记录中实现了SWD的高准确率、实时检测，并且无需手动阈值调整。该方法为失神癫痫患者中监测和筛查SWD提供了一个有效且经济的解决方案。
## 779. `cs.LG` - 自适应对齐学习以提高单导联心电图中的心肌梗死检测 [PDF](https://arxiv.org/pdf/2509.19397), [HTML](https://arxiv.org/abs/2509.19397)
### Authors
Jiarui Jin,Xiaocheng Fang,Haoyu Wang,Jun Li,Che Liu,Donglin Xie,Hongyan Li,Shenda Hong
### Background
心肌梗死是冠状动脉疾病的一种关键表现形式，但从单导联心电图（ECG）中检测它仍具有挑战性，因为其空间信息有限。一种直观的想法是将单导联EKG转换为多导联EKG进行分类，但大多数基于生成方法的优化通常在信号层面会产生大量未解决的空间间隙，最终降低诊断性能。因此，研究提出是否可以通过空间间隙对齐来提升检测效果。然而，大多数现有的心电图对齐方法侧重于学习变换不变性，这与单导联检测的目标不符。因此，该研究提出了SelfMIS框架，通过自切割策略将多导联EKG和相应的单导联片段配对，并在潜在空间直接对齐它们，从而将学习目标从追求变换不变性转向丰富单导联表示，明确驱动单导联心电图编码器学习从局部信号推断全局心脏上下文的表示方法。
### Innovation
提出了一种名为SelfMIS的简单且有效的对齐学习框架，用于改进从单导联心电图中检测心肌梗死。该框架采用自切割策略，将多导联心电图与对应的单导联片段配对，并在潜在空间直接对齐它们。这种方法将学习目标从追求变换不变性转变为丰富单导联表示，明确驱动单导联心电图编码器学习从局部信号推断全局心脏上下文的表示方法。实验表明，SelfMIS在九种类型的心肌梗死检测中优于基线模型，同时保持了更简单的架构和较低的计算开销，从而证明了直接潜在空间对齐的有效性。
### Conclusion
该研究展示了SelfMIS框架在提高单导联心电图中多类型心肌梗死检测性能方面的优越表现，同时保持了简单架构和低计算开销。SelfMIS在潜在空间对齐方面的成功表明，这种方法可以有效地提高单导联心电图的心肌梗死检测性能。该代码和检查点将在接受后公开。
## 780. `cs.LG` - HUNT: 通过瞬时相对框架在未结构化环境中实现高速无人飞行器导航和跟踪 [PDF](https://arxiv.org/pdf/2509.19452), [HTML](https://arxiv.org/abs/2509.19452)
### Authors
Alessandro Saviolo,Jeffrey Mao,Giuseppe Loianno
### Background
搜救任务需要无人飞行器在未知非结构化环境中以高速前进，并在检测到目标后进行跟踪。然而，在传感器降级和缺乏全球定位的情况下同时实现这两种能力仍然是一个开放的挑战。近年来有关相对导航的工作表明可以通过锚定规划和控制到可见检测到的目标来实现稳健的跟踪，但不能解决没有目标在视野中的导航问题。
### Innovation
HUNT是一个实时框架，它将穿越、获取和跟踪统一在一个相对公式中。HUNT直接从机载瞬时可观测量（如姿态、高度和速度）定义导航目标，使无人飞行器在搜索过程中能够进行反应式的高速飞行。一旦检测到目标，相同的感觉-控制管道能够无缝过渡到跟踪。户外实验在密集的森林、集装箱仓库以及配有车辆和人体模型的搜救操作中证明了HUNT在全局方法失败时的稳健自主性。
### Conclusion
户外实验在森林、集装箱区、以及使用车辆和人体模型的搜救行动中证明，HUNT能够在目标不在视野内的情况下实现稳健的自主导航与追踪，有效解决了无人飞行器在未结构化环境中持续任务的挑战。
## 781. `cs.LG` - 使用LSTM网络进行阿根廷区域短期电力需求预测 [PDF](https://arxiv.org/pdf/2509.19374), [HTML](https://arxiv.org/abs/2509.19374)
### Authors
Oscar A. Oviedo
### Background
本文研究了基于长短期记忆（LSTM）网络的深度学习模型开发与优化，以预测阿根廷科尔多瓦地区的短期每小时电力需求。该模型将历史消费数据与外生变量（气候因素、时间周期和人口统计数据）结合起来，从而实现了高度精确的预测，均绝对百分比误差为3.20%，决定系数达到0.95。引入周期时间编码和天气变量对于捕捉季节性模式和极端消费事件至关重要，增强了模型的鲁棒性和泛化能力。除了设计和超参数优化LSTM架构，本文还进行了两项补充分析：一是使用随机森林回归进行可解释性研究，量化外生驱动因素的相对重要性；二是评估模型在预测每日需求峰值和谷值时间上的性能，测试日中有超过三分之二的时间实现了精确到小时的准确性，在90%以上的测试案例中误差小于1小时。这些结果共同突显了所提框架的预测准确性和操作相关性，为电网运营商在不同需求场景下寻求优化规划和控制策略提供了有价值的见解。
### Innovation
提出了基于LSTM网络的深度学习模型，用于预测阿根廷科尔多瓦的短期电力需求。通过整合历史消费数据和外生变量，并且引入了周期时间编码和天气变量，显著提高了预测精度和鲁棒性。此模型不仅进行了LSTM架构的设计和超参数优化，而且还进行了可解释性研究和性能评估，实现了高精度的时间预测。
### Conclusion
该研究表明提出的模型在预测能力上非常准确，并且具有实际操作意义，为寻求在多样化需求情景下优化电网规划和控制策略的运营商提供了有价值的见解。
## 782. `cs.LG` - 普朗克宇宙：基础模型是否看到相同的天体？ [PDF](https://arxiv.org/pdf/2509.19453), [HTML](https://arxiv.org/abs/2509.19453)
### Authors
UniverseTBD:Kshitij Duraphe,Michael J. Smith,Shashwat Sourav,John F. Wu
### Background
本文通过测量不同数据类型上的基础模型的表示一致性，测试了天文中的普朗克表示假说（PRH）。作者利用JWST、HSC、损益调查和DESI的数据，比较了视觉变换器、自我监督模型和天文学特定架构的表示。研究结果表明，代表一致性随模型容量增加而增加，支持了向共享星系天体物理表示的收敛。这表明可以使用预训练的通用架构构建天文基础模型，从而最大化利用了机器学习社区已有的计算投资。
### Innovation
本文通过多源天文学数据测试普朗克表示假说，使用视觉变换器、自我监督模型和天文学特定架构进行比较分析，验证了模型容量和表示一致性之间的关系，为使用预训练通用架构建立天文学基础模型提供了依据。这种方法创新性地利用了现有的机器学习投资。
### Conclusion
本文的结果表明，天文基础模型可以使用预训练的通用架构，支持了向共享星系天体物理表示的收敛，并且这种方法可以最大化利用已经存在的计算资源。
## 783. `cs.LG` - 使用深度学习方法从言语句子预测无袖带血压 [PDF](https://arxiv.org/pdf/2509.19750), [HTML](https://arxiv.org/abs/2509.19750)
### Authors
Kainat
### Background
动脉血压是心血管健康的关键指标，准确监测血压对于预防高血压相关的并发症至关重要。传统的袖带测量方法由于白大衣效应和隐性高血压等原因常导致结果不一致。因此，本研究提出了一种利用语音信号预测无袖带血压的新方法，通过分析语音信号提取与血压水平相关的模式，以实现实时监测，无需依赖传统方法带来不适。
### Innovation
本研究创新性地利用了基于BERT的回归模型处理语音信号，通过提取语音特征与血压水平之间的相关性，实现了准确的血压预测，为增强患者护理和心血管健康主动管理提供了有效的替代方案。
### Conclusion
通过对95名参与者的语音记录数据集进行训练，研究结果表明，BERT模型能实现较高的血压预测准确度，主要是通过降低真实收缩压和舒张压的均方绝对误差和获得较高的R值来证实。此外，通过训练和验证损失分析可以证明该模型学习有效且几乎没有过拟合。研究建议结合深度学习与语音分析为无袖带血压监测提供了一种可行替代方案，促进了远程健康监测领域的应用和发展。
## 784. `cs.LG` - Evaluation-Aware Reinforcement Learning [PDF](https://arxiv.org/pdf/2509.19464), [HTML](https://arxiv.org/abs/2509.19464)
### Authors
Shripad Vilasrao Deshmukh,Will Schwarzer,Scott Niekum
### Background
政策评估对于部署安全和性能关键系统通常是必不可少的。但现有的评估方法往往由于数据有限和长期任务导致评估结果高变异性，或者由于支持不均或不准确的环境模型导致偏置高。这些问题在部分程度上源于标准的强化学习（RL）范式，在这种范式中，政策学习并未明确考虑到评估因素。
### Innovation
提出了一种评估感知的强化学习（EvA-RL），其中训练策略以最大化的期望回报为目标，同时在给定的价值预测方案下同时最小化期望评估误差，即“容易”评估。此外，研究还扩展了该方法，与策略一同学习条件下的状态-价值预测器，以减少评估误差并保持竞争力。理论分析和实验结果表明，在使用固定的价值预测方案时，往往会存在评估准确性和策略性能之间的权衡。
### Conclusion
这项工作的主要结论是它为一类新的RL方法奠定了基础，这些方法在训练过程中将可靠评估视为首要原则。实验结果表明，与不同动作领域的固定价值预测方案一起使用，EvA-RL可以显著减少评估误差，同时保持竞争力。
## 785. `cs.LG` - 仿效学习在模拟世界中的自我进化 [PDF](https://arxiv.org/pdf/2509.19460), [HTML](https://arxiv.org/abs/2509.19460)
### Authors
Yifan Ye,Jun Cen,Jing Chen,Zhihe Lu
### Background
近年来，仿效学习成为了一种趋势，但要在多个任务中训练一个具备广泛应用能力的代理仍然需要大量的专家演示，而这收集起来既昂贵又耗时。面对有限的监督数据，本文提出了一种名为SEIL（Self-Evolved Imitation Learning）的新框架，通过模拟器交互逐步改进少量种子模型。模型首先在模拟器中尝试执行任务，成功轨迹会被收集并进一步用作迭代改进的新演示数据。为了增加这些演示数据的多样性，SEIL采用了双重级别的增强方法：（i）模型级，利用指数加权平均（EMA）模型与主模型合作，（ii）环境级，在初始物体位置引入轻微的变化。此外，本文引入了一个轻量级的选择器，来筛选生成池中的互补且信息丰富的轨迹，从而确保演示数据的质量。这些精选样本使得模型能在更少的训练样本下实现竞争力的表现。
### Innovation
本文提出了一种名为SEIL的新框架，通过模拟器交互逐步改进少量种子模型。SEIL采用了双重级别的增强方法，添加了模型级和环境级的增强机制来增加演示数据的多样性，并利用一个轻量级的选择器来过滤生成的池中的互补且信息丰富的轨迹，从而提高演示数据的质量。这些创新使得模型能够在更少的训练样本下实现竞争力的表现。
### Conclusion
本文在LIBERO基准上进行了广泛的实验，结果表明SEIL在少样本仿效学习场景中达到了新的最佳性能。代码可在以下链接获取：this https URL.
## 786. `cs.LG` - ROPA：眼对手双臂RGB-D数据增强的合成机器人姿态生成 [PDF](https://arxiv.org/pdf/2509.19454), [HTML](https://arxiv.org/abs/2509.19454)
### Authors
Jason Chen,I-Chun Arthur Liu,Gaurav Sukhatme,Daniel Seita
### Background
双臂抓取任务需要广泛覆盖机器人姿态、接触点和场景上下文的演示数据以训练鲁棒性的抓取策略。然而，收集多样的真实世界演示数据既耗时又昂贵，影响了这种方法的大规模应用。现有研究通过数据增强方法解决这一问题，主要集中在单手抓取的眼在手配置（腕部相机）设置的RGB输入上，或是用于生成新的图像而不涉及配对的动作，对于眼在手双臂抓取场景的RGB-D输入数据增强，特别是带有新的动作标签的合成数据增强研究较少。因此，提出ROPA，一种使用Stable Diffusion微调来生成第三方视角的RGB及RGB-D观察结果合成机器人姿态的方法，该方法同时生成相应的关节空间动作标签并通过约束优化确保双臂场景中的物理一致性。ROPA在5个仿真任务和3个真实世界任务上进行了评估，结果显示ROPA在2625次仿真试运行和300次真实世界试运行中优于基线方法和改进方法，表明其在眼在手双臂抓取的RGB和RGB-D数据增强中的潜在可扩展性。
### Innovation
ROPA是一种离线模仿学习数据增强方法，通过微调Stable Diffusion来生成第三方视角的RGB及RGB-D观察结果的合成机器人姿态。这种方法同时生成相应的关节空间动作标签，并通过约束优化来确保物理一致性，特别是通过适当的夹持器与物体接触约束，这在双臂场景中尤为重要。
### Conclusion
ROPA在其评估的2625次仿真试运行和300次真实世界试运行中表现优于基线方法和改进方法，显示出其在眼在手双臂抓取的RGB和RGB-D数据增强中的可扩展性潜力。
## 787. `cs.LG` - 量子谐波分析与数据结构：数据增强 [PDF](https://arxiv.org/pdf/2509.19474), [HTML](https://arxiv.org/abs/2509.19474)
### Authors
Monika Doerfler,Franz Luef,Henry McNulty
### Background
本文探讨了数据增强对高维数据集主成分平滑性的影响。通过使用量子谐波分析工具，证明了增强数据集对应算子的本征函数位于调制空间$M^1(text{R}^d)$中，这意味着具有平滑性和连续性。数值例子在合成和音频数据上的结果验证了理论发现，体现了量子谐波分析在处理高维数据集中的应用价值。
### Innovation
使用量子谐波分析工具证明了增强数据集对应算子的本征函数在调制空间$M^1(text{R}^d)$中，从而保证了它们的平滑性和连续性。这一发现为数据增强提供了理论基础，表明对于流形学习和特征提取算法，系统的和有信息的数据增强原则是有益的。
### Conclusion
本文的结果表明，流形学习和特征提取算法可以从系统和信息丰富的数据增强原则中受益。此外，数值例证在合成和音频数据上的结果进一步支持了这一论点。
## 788. `cs.LG` - 锚定拉格朗日算法 [PDF](https://arxiv.org/pdf/2509.19455), [HTML](https://arxiv.org/abs/2509.19455)
### Authors
Mert Gurbuzbalaban,Hoang M. Nguyen,Xicheng Zhang,Lingjiong Zhu
### Background
标准的拉格朗日算法如未校正的拉格朗日算法（ULA）通过离散化拉格朗日扩散得到，广泛用于机器学习的抽样，因为它们可以扩展到高维和大数据集。然而，它们面临两个关键限制：（i）需要可微分的对数密度，排除具有非可微分成分的目标；（ii）通常无法从重尾分布中抽样。
### Innovation
本文提出了一种统一的方法——锚定拉格朗日动力学，它能够处理非可微分目标和某些类别的重尾分布。该方法用平滑的参考势能替换原始势能，并通过乘性缩放修改拉格朗日扩散。论文还建立了在2- Wasserstein距离中目标分布的非渐进保证，并提供了一种等价形式，通过拉格朗日扩散的随机时间变化得出。
### Conclusion
论文提供了理论和实际应用的数值实验来阐述我们提出的锚定拉格朗日算法的方法论和实际性能。
## 789. `cs.LG` - OmniVLA：一种用于机器人导航的全模态视觉-语言-动作模型 [PDF](https://arxiv.org/pdf/2509.19480), [HTML](https://arxiv.org/abs/2509.19480)
### Authors
Noriaki Hirose,Catherine Glossop,Dhruv Shah,Sergey Levine
### Background
人类在导航到目的地时能够灵活地解释和组合不同的目标说明，比如语言指令、空间坐标或视觉参照。然而，现有的大多数机器人导航策略仅限于单模态训练，限制了它们在不同形式的目标说明自然且互补的现实场景中的适应性。
### Innovation
提出了一种训练框架，能够使基于视觉的导航的机器人基础模型具备全模态的目标条件能力。该方法利用高容量的视觉-语言-动作（VLA）骨干网络，并通过随机模态融合策略训练三种主要的目标模态：2D姿态、第一人称图像以及自然语言，以及这些模态的组合。这种设计不仅扩大了可用数据集的范围，还鼓励策略发展更丰富的几何、语义和视觉表示。最终模型OmniVLA在未见过的环境中有较强的泛化能力，对稀少的模态具有鲁棒性，并具备遵循新型自然语言指令的能力。OmniVLA在各模态上都优于专门的基线模型，并为企业提供了可灵活调整以适应新模态和任务的基础。
### Conclusion
我们相信，OmniVLA为广泛泛化的和灵活的导航策略提供了一个步骤，并为企业构建全模态机器人基础模型提供了一条可扩展的路径。
## 790. `cs.LG` - AIRwaves在CheckThat!2025：使用双编码器和神经重新排名检索社交媒体上的隐含科学来源 [PDF](https://arxiv.org/pdf/2509.19509), [HTML](https://arxiv.org/abs/2509.19509)
### Authors
Cem Ashbaugh,Leon Baumgärtner,Tim Gress,Nikita Sidorov,Daniel Werner
### Background
在社交媒体上对隐含科学声明进行事实核查和学术讨论需要与原始出版物链接，但受到词汇稀疏性、非常短的查询以及领域特定语言的限制。clef-2025 CheckThat！Lab的Subtask 4b中，Team AIRwaves使用基于证据检索的方法取得了显著优于基线的表现，优化的稀疏检索基线(BM25)在黄金标签盲测集上的MRR@5为0.5025。
### Innovation
介绍了两阶段检索管道：首先是使用E5-large的双编码器，通过内部批次和挖掘的负面样本进行微调，并通过分块分词和丰富的文档元数据增强；其次是使用SciBERT交叉编码器的神经重新排名阶段。采用神经表示替换纯词汇匹配后，性能提升至MRR@5=0.6174，完整管道进一步提升至MRR@5=0.6828。研究表明，将密集检索与神经重新排名结合可以有效地匹配推文和研究，并为未来的证据检索管道提供可行的蓝图。
### Conclusion
研究表明，耦合密集检索与神经重新排名可以提供一种强大且高效的推文与研究匹配解决方案，为未来的证据检索管道提供了可行的方法。
## 791. `cs.LG` - AnySafe: 在潜在空间通过安全性约束参数化实现运行时适应的潜在安全性滤波 [PDF](https://arxiv.org/pdf/2509.19555), [HTML](https://arxiv.org/abs/2509.19555)
### Authors
Sankalp Agrawal,Junwon Seo,Kensuke Nakamura,Ran Tian,Andrea Bajcsy
### Background
近期的研究表明，基本的安全控制方法，例如哈密尔顿-雅可比(HJ)可达性分析，可以应用于世界模型的潜在空间。这使得在难以建模的视觉任务中合成功能安全过滤器成为可能。然而，这些方法假设安全约束是事前已知并且在部署过程中保持不变的，限制了安全过滤器的适应性。
### Innovation
本文提出了参数化潜在安全过滤器，能够在运行时适应用户指定的安全约束。关键思想是通过使用潜在空间相似性度量来条件化约束编码，以一种原则性的方法使失败的相似度对齐。这种方法通过形式化校准控制系统接近约束表征的程度，从而实现对任意安全约束的运行时适应。任何模型所见图像均可被视为潜在的测试时间约束，使得完全在世界模型的想象中训练参数化安全过滤器。
### Conclusion
在使用Franka机械臂的视觉控制任务的模拟和硬件实验中，我们的方法通过条件化于用户指定的约束图像编码，在保持性能的情况下实现了运行时适应。可以在该网址找到视频结果：this https URL
## 792. `cs.LG` - 大型语言模型中的认知负荷限制：多跳推理基准测试 [PDF](https://arxiv.org/pdf/2509.19517), [HTML](https://arxiv.org/abs/2509.19517)
### Authors
Sai Teja Reddy Adapala
### Background
大型语言模型（LLMs）在静态基准上的表现与在动态、信息丰富的环境中表现脆弱之间的差距日益明显。尽管模型在孤立任务上表现出色，但其在认知负荷下的推理能力的计算限制仍不完全理解。研究表明，在高内含负荷任务中，不相关任务信息和任务切换带来的干扰会影响模型的表现。为了更好地理解和评估这些影响，作者设计了一个干扰消除的基准测试——交错认知评估（ICE），通过对复杂的多跳推理任务中的这些因素进行系统性操控来研究。实验结果揭示了不同指令调优模型在处理高内含负荷任务时的显著性能差异，从而证实了认知负荷是推理失败的关键因素之一。
### Innovation
作者提出了一种正式的认知计算负荷理论，认为与任务无关的信息饱和度和任务切换带来的注意残留是关键机制，影响了模型性能。此外，设计了交错认知评估（ICE）基准测试，在复杂的多跳推理任务中系统性地操控这些负荷因素，提供了一个全面且可操作的评价框架，以评估在不同认知负荷下模型的性能差异。
### Conclusion
研究结果表明，认知负荷是推理失败的关键因素之一，动态的、认知意识的压力测试对于评估先进人工智能系统的真正韧性和安全性至关重要。因此，未来需要通过类似ICE这样的基准测试来进一步探索和验证这一发现。
## 793. `cs.LG` - 大型语言模型在实体匹配中的置信度校准 [PDF](https://arxiv.org/pdf/2509.19557), [HTML](https://arxiv.org/abs/2509.19557)
### Authors
Iris Kamsteeg,Juan Cardenas-Cartagena,Floris van Beers,Gineke ten Holt,Tsegaye Misikir Tashu,Matias Valdenegro-Toro
### Background
研究旨在探讨大型语言模型（Large Language Models）与实体匹配（Entity Matching）中的置信度校准之间的交集。为此，通过实证研究比较了基础的RoBERTa置信度与使用温度缩放（Temperature Scaling）、蒙特卡洛 Dropout（Monte Carlo Dropout）和集成（Ensembles）校准后的置信度。研究分别使用了Abt-Buy、DBLP-ACM、iTunes-Amazon和公司数据集。研究发现，所提出的修改后的RoBERTa模型存在轻微的过自信问题，期望校准误差（Expected Calibration Error）分数在不同数据集上的范围从0.0043到0.0552。此外，研究还发现，通过使用温度缩放，可以缓解这种过自信问题，将期望校准误差分数降低多达23.83%。
### Innovation
该研究创新性地将大型语言模型用于实体匹配中的置信度校准，并通过比较不同的校准方法来评估其效果。
### Conclusion
所提出的修改后的RoBERTa模型表现出轻微的过自信问题，而使用温度缩放等校准方法能显著降低期望校准误差分数。
## 794. `cs.LG` - 仿真相关障碍场中的随机路径规划 [PDF](https://arxiv.org/pdf/2509.19559), [HTML](https://arxiv.org/abs/2509.19559)
### Authors
Li Zhou,Elvan Ceyhan
### Background
该研究背景是在具有空间相关性、不确定遮挡状况的障碍场中进行导航的问题，在这种场景下，传感器的感知受限且不精确，需要高昂的成本来澄清它们的读数。研究人员通过高斯随机场（GRF）模型来描述空间相关性，并制定了贝叶斯信念更新方法来提高遮挡概率，并利用后验结果缩小搜索空间以提高效率。在此基础上，该研究提出了一个新颖的两阶段学习框架，该框架结合了蒙特卡洛点估计和分布增强学习，来解决信息反馈问题，并为环境中的对抗性干扰或聚类自然灾害导航提供有效的路径规划方法。
### Innovation
研究创新点在于提出了一种基于相关性的两阶段学习框架，该框架包括离线学习稳健基策略和在线滚动策略更新两个阶段，通过贝叶斯机制周期性更新以适应信息的变化，从而支持蒙特卡洛点估计和分布增强学习来学习完整成本分布，增强了不确定性量化。此外，研究还建立了相关内容感知更新的理论优势及后验采样的收敛性质。这种方法在多种障碍密度和传感器能力下，能相比基准方法持续获得性能提升，有效解决了具有干扰或自然灾害风险环境中的导航挑战。
### Conclusion
该研究提出的方法能够有效规划在具有相关性障碍的场景中的路径，通过引入时空相关高斯场来建模障碍间的相关性，该框架能够更好地处理不确定性和信息不完全的情况，从而有助于提高路径规划算法在对抗性环境或有较高危险性的自然环境中导航的有效性和鲁棒性。
## 795. `cs.LG` - MAGIC: 多任务高斯过程在医疗时间序列中的联合插补和分类 [PDF](https://arxiv.org/pdf/2509.19577), [HTML](https://arxiv.org/abs/2509.19577)
### Authors
Dohyun Ku,Catherine D. Chong,Visar Berisha,Todd J. Schwedt,Jing Li
### Background
时间序列分析在医疗应用中越来越重要，能够提高患者的诊断和管理。然而，这些应用通常面临两个关键挑战：时间对齐问题和数据稀疏性。传统的解决方案是通过插补和预测两个独立的步骤来解决这些问题。这些方法存在效率和效果上的不足。因此，需要一个统一的新方法来同时解决这两个问题并在医疗时间序列上进行预测和分类。
### Innovation
本文提出了一种名为MAGIC的新方法，即多任务高斯过程（Multi-TAsk Gaussian Process for Imputation and Classification），它能够在一个多层次的多任务高斯过程中同时进行带有类信息的缺失值插补和标签预测，并结合函数逻辑回归。MAGIC通过泰勒展开近似处理不可计算的似然函数组件，使用EM算法和区块坐标优化进行参数估计，并提供了收敛性分析支持。MAGIC已经在两个医疗应用上进行了验证，显示出比现有方法更高的预测准确性。这种方法有助于实时和准确的预测，特别是在样本较少的情况下，能够促进早期临床评估和治疗计划，使医疗提供者能够做出更有根据的治疗决策。
### Conclusion
MAGIC在两个医疗应用中表现出色，超过现有方法的预测准确度。这种能力促进了实时和准确的医疗预测，特别是在使用有限样本的情况下，有利于早期的临床评估和治疗规划，使医疗提供者在制定治疗决策时能够更加知情。
## 796. `cs.LG` - 像素在语义语言建模中的不确定性 [PDF](https://arxiv.org/pdf/2509.19563), [HTML](https://arxiv.org/abs/2509.19563)
### Authors
Stefania Radu,Marco Zullich,Matias Valdenegro-Toro
### Background
像素基语言模型旨在解决语言建模中的词汇量瓶颈问题，但在不确定量化方面仍面临挑战。
### Innovation
本文通过分析18种语言和7种字符集的像素基语言模型在3个语义挑战任务中的不确定性和置信度，提出了通过蒙特卡洛dropout、Transformer注意机制和集成学习等方法来解决这一问题。
### Conclusion
像素模型在重建块时低估了不确定性，不确定性也会受到字符集的影响，拉丁语系语言的不确定性较低。此外，在实体识别和问答任务中，集成学习的性能表现更好，尤其是在经过超参数调优后。
## 797. `cs.LG` - 基于图的神经空间天气预报 [PDF](https://arxiv.org/pdf/2509.19605), [HTML](https://arxiv.org/abs/2509.19605)
### Authors
Daniel Holmberg,Ivan Zaitsev,Markku Alho,Ioanna Bouri,Fanni Franssila,Haewon Jeong,Minna Palmroth,Teemu Roos
### Background
准确的空间天气预报对于保护日益数字化的基础设施至关重要。混合-Vlasov 模型，如 Vlasiator，提供了超越当前操作系统的物理现实性，但计算成本过高，不适合实时使用。
### Innovation
作者引入了一种基于图的神经 emulator，通过对 Vlasiator 数据的训练，用于自回归预测由太阳风上游驱动的近地空间条件。该模型能够实现快速确定论预测，并通过使用生成模型来生成集合，捕捉预报不确定性。这项工作证明机器学习为现有的空间天气预测系统添加了不确定性量化能力，并使混合-Vlasov 模拟在操作中成为可能。
### Conclusion
研究表明，机器学习为现有的空间天气预测系统增加了不确定性量化能力，并使混合-Vlasov 模拟在操作中成为可能。
## 798. `cs.LG` - 您的基准测试究竟测量了什么？：一种稳健推断AI能力的框架 [PDF](https://arxiv.org/pdf/2509.19590), [HTML](https://arxiv.org/abs/2509.19590)
### Authors
Nathanael Jo,Ashia Wilson
### Background
在基准数据上的生成模型评估如今已经无处不在，这些评估的结果深刻地影响了公众和科学界对人工智能能力的预期。然而，这些评估的可靠性正受到越来越多的怀疑。我们如何知道报告的准确度真正反映了模型的真实性能呢？评估通常被表现为简单的度量，但实际上它们是推断：将基准评分视为能力的证据已经假设了一个关于能力是什么以及它如何在测试中表现的理论。为了明确这一步骤，本文提出了一个基于推断的基本框架：从能力理论出发，然后推导出估计它的方法。
### Innovation
本文提出了一种基于推断的基本框架，用于评估AI能力。该框架从能力理论出发，推导出估计其能力的方法。特别地，本文解决了可靠性的一个中心挑战——对扰动的敏感性，并引入了在考虑不确定性（如敏感性和有限样本）时推断能力的方法。此外，还提出了一种适应性算法，大大减少了样本复杂性。
### Conclusion
这些贡献为基于基准测量的AI能力的更可靠和可信赖的估计奠定了基础。
## 799. `cs.LG` - EgoBridge: 从自我中心人类数据中泛化模仿的领域适应 [PDF](https://arxiv.org/pdf/2509.19626), [HTML](https://arxiv.org/abs/2509.19626)
### Authors
Ryan Punamiya,Dhruv Patel,Patcharapong Aphiwetsa,Pranav Kuppili,Lawrence Y. Zhu,Simar Kareer,Judy Hoffman,Danfei Xu
### Background
自我中心的人类体验数据为扩展端到端模仿学习提供了巨大的资源，用于机器人操作。然而，人类和机器人在视觉外观、传感器模态和运动学等方面的显著领域差距阻碍了知识的转移。
### Innovation
本论文提出了一种统一的协同训练框架EgoBridge，该框架通过领域适应显式对齐人类和机器人数据的策略潜在空间。基于最优传输（OT）衡量联合策略潜在特征和动作的差异，学习观察表示不仅在人类和机器人领域之间对齐，而且保留策略学习至关重要的动作相关信息。
### Conclusion
EgoBridge 在三个真实世界的单臂和双臂操作任务中将人类增强的跨界体基线的绝对策略成功率提高了44%。此外，EgoBridge 还可以泛化到仅在人类数据中看到的新对象、场景和任务，而基线完全失败。
## 800. `cs.LG` - 利用认证局部稳定性的形式安全性验证和调整生成式运动规划器 [PDF](https://arxiv.org/pdf/2509.19688), [HTML](https://arxiv.org/abs/2509.19688)
### Authors
Devesh Nath,Haoran Yin,Glen Chou
### Background
生成式运动规划器（GMPs）凭借其相较于传统规划器的优势受到关注，但验证其输出的安全性和动态可行性是一个挑战。目前的神经网络验证工具（NNV）只能处理几十个神经元的网络，而这些生成式运动规划器常常包含数百万个神经元，因此无法使用这些工具进行验证。
### Innovation
为了解决这一问题，论文提出了一种方法，通过采用稳定参考采样和小规模神经跟踪控制器，将GMP的特点与NNV相结合，实现闭环安全性验证，并确保动态可行性。利用这种方法构建了生成式运动规划器参考库，并在线部署，以模仿原生成式运动规划器的安全分布，提高安全性而无需重新训练。
### Conclusion
该研究通过对多种生成式运动规划器（包括扩散模型、流匹配模型和视觉语言模型）的评估，证明了在地面机器人和四旋翼飞行器模拟甚至硬件环境中提高了安全性。
## 801. `cs.LG` - 通过序列模型的物理知情强化学习微调发现可持续制冷剂 [PDF](https://arxiv.org/pdf/2509.19588), [HTML](https://arxiv.org/abs/2509.19588)
### Authors
Adrien Goldszal,Diego Calanzone,Vincent Taboga,Pierre-Luc Bacon
### Background
目前大多数空调系统中使用的制冷剂，如氢氟碳化合物，是强有力的温室气体，并且正在逐步被淘汰。大规模分子筛选已被应用于寻找替代品，但实践中仅大约知道300种制冷剂，并且只有少数候选者在实验验证之前被提出。这限制了纯数据驱动方法的效果。
### Innovation
本文介绍了一种名为Refgen的生成管道，将机器学习与基于物理的诱导偏置相结合。除了用于有效的分子生成微调，Refgen还结合了关键性质预测模型、状态方程、热化学多项式模型和完整的制冷循环模拟。这些模型在热力学约束下实现了强化学习微调，保证了连贯性，并指导发现兼顾效率、安全和环境影响的分子。通过在学习过程中嵌入物理知识，Refgen有效地利用了稀缺数据并促进了超出已知化合物集的新型制冷剂发现。
### Conclusion
通过嵌入物理知识到学习过程中，Refgen能够有效地利用有限的数据，并推动了新型制冷剂的发现，超越了现有化合物的范围。
## 802. `cs.LG` - 思考即倾听：音频分类中的简单测试时扩展 [PDF](https://arxiv.org/pdf/2509.19676), [HTML](https://arxiv.org/abs/2509.19676)
### Authors
Prateek Verma,Mert Pilanci
### Background
该领域正在研究如何使神经模型在处理日常声音的同时进行思考，从而提升音频分类性能。基于大型语言模型在推理能力上的最新进展，研究者探讨如何将思考融入现有的音频分类流程，以及是否可以设计全新的支持思考和测试时扩展的架构。
### Innovation
提出了一个框架，使神经模型能够“思考即倾听”，以优化音频分类效果。研究引入了如何在现有的音频分类管道中加入思考过程，提升类别空间的推理能力，并探讨了从零开始设计支持思考和测试时扩展的新架构的可能性。通过测试时扩展，研究观察到随着采样跟踪数量的增加，分类准确性持续提高。研究还展示了开源推理模型GPT-OSS-20B和Qwen3-14B的表现，指出轻量级方法——仅对冻结的小型模型（如GPT-2）的嵌入矩阵进行重新训练——可以超越拥有数十亿参数的文本推理模型。
### Conclusion
在两个应用场景中标记模型表现出更高的分类准确性。并且通过测试时扩展，随着采样痕迹数量的增加，取得了持续的性能提升。此外，研究表明，在开放源代码的推理模型中采用一种轻量级的重新训练方法能够显著提升模型性能。
## 803. `cs.LG` - 基于扩散和流的 copulas：遗忘和记住依赖关系 [PDF](https://arxiv.org/pdf/2509.19707), [HTML](https://arxiv.org/abs/2509.19707)
### Authors
David Huk,Theodoros Damoulas
### Background
copulas 是建模数据中多元依赖关系的基本工具，在多领域和应用中是首选方法。然而，现有模型在处理多模态和高维度依赖关系时受到限制性假设和效率问题的阻碍。
### Innovation
本文提出基于扩散和流原理的 copulas 模型方法。设计了两个逐步忘记变量间依赖关系但不影响维度间分布的过程，确保所有时间点都形成有效的 copulas。通过学习恢复被遗忘的依赖关系，理论上可以在最优性下恢复真实 copulas。第一种框架实例关注直接密度估计，第二种特别适用于高效的采样。实验证明，与最先进的 copulas 方法相比，在处理复杂和高维依赖关系时，本文提出的方法表现更优，增强了 copulas 模型的表示能力，使其在更大规模和更具挑战性的领域中得到应用。
### Conclusion
本工作提高了 copulas 模型的表现能力，使它们能在更大的规模和更具挑战性的领域中得到应用，为它们在更广泛的范围内的采用铺平了道路。
## 804. `cs.LG` - 在甲烷卫星和航空成像光谱仪中的云和云影分割的深度学习方法 [PDF](https://arxiv.org/pdf/2509.19665), [HTML](https://arxiv.org/abs/2509.19665)
### Authors
Manuel Perez-Carrasco,Maya Nasr,Sebastien Roche,Chris Chan Miller,Zhan Zhang,Core Francisco Park,Eleanor Walker,Cecilia Garraffo,Douglas Finkbeiner,Ritesh Gautam,Steven Wofsy
### Background
准确检测云和云影对于精确获取大气甲烷或其他气态污染物的浓度至关重要，特别是在高空间分辨率的超光谱遥感中。这对于MethaneSAT及其空中同伴任务MethaneAIR尤为重要。远程感应数据中的云和云影需要有效去除，因为它们会偏移甲烷获取，并影响排放量的量化。
### Innovation
本文采用机器学习方法，特别是深度学习架构，如UNet和Spectral Channel Attention Network (SCAN)来解决具有高空间分辨率仪器的云和云影检测问题。通过对比常规方法（如Iterative Logistic Regression (ILR) 和 Multilayer Perceptron (MLP)）与深度学习模型，发现深度学习模型显著改善了检测质量：UNet在保持空间结构方面表现最佳，而SCAN在捕捉精细边界细节方面表现更佳。特别地，SCAN在MethaneSAT数据上表现出色，强调了光谱注意力机制对卫星特定特征的好处。
### Conclusion
本文深入评估了各种不同的机器学习技术，展示了先进深度学习架构在提供稳健、可扩展的解决方案以增强现有和下一代超光谱任务对甲烷排放量量化能力方面的优势。相关数据和代码已公开发布。
## 805. `cs.LG` - UserRL: 通过强化学习训练互动用户中心型代理 [PDF](https://arxiv.org/pdf/2509.19736), [HTML](https://arxiv.org/abs/2509.19736)
### Authors
Cheng Qian,Zuxin Liu,Akshara Prabhakar,Jielin Qiu,Zhiwei Liu,Haolin Chen,Shirley Kokane,Heng Ji,Weiran Yao,Shelby Heinecke,Silvio Savarese,Caiming Xiong,Huan Wang
### Background
强化学习（RL）在训练超越静态基准、参与动态多轮交互的代理模型方面显示出潜力。然而，这些代理的价值最终取决于它们是否能辅助用户，这种场景中用户互动的多样性和动态性带来了挑战。
### Innovation
本文提出了一种名为UserRL的统一框架，用于通过标准化的 Gym 环境和模拟用户训练和评估用户中心的能力。通过系统地改变回合级奖励分配和轨迹级评分计算，分析不同形式如何影响 GRPO 算法下的学习效果。实验表明：(i) 自我建模（SFT）的冷启动对于解锁初始交互能力和推动持续的RL改进至关重要；(ii) 计划的轨迹评分能够实现更高效和有效的多轮交互；(iii) 更强大的模拟用户（如GPT-4o）有助于训练，但开源模拟器（如Qwen3-32B）仍是一个成本效益高且可移植的选择。
### Conclusion
这些结果强调了奖励塑造和用户模拟选择设计的仔细选择与模型规模一样重要，确立了UserRL作为开发稳健用户中心型代理模型的实际路径。所有代码和数据均已开源供未来研究使用。
## 806. `cs.LG` - 通过流形拟合与学习进行高维统计过程控制 [PDF](https://arxiv.org/pdf/2509.19820), [HTML](https://arxiv.org/abs/2509.19820)
### Authors
Burak I. Tas,Enrique del Castillo
### Background
本文探讨了从两个互补的角度解决高维动态工业过程的统计过程控制问题：流形拟合和流形学习。两种方法假定数据位于一个潜在的非线性低维空间中。
### Innovation
本文提出了两种不同的在线或阶段II统计过程控制监测框架：一种使用最先进的流形拟合技术来逼近下降空间中的流形，并使用新的标量分布自由控制图监控偏差；另一种通过首先将数据嵌入到更低维度的空间来简化问题，然后监控嵌入后的观测值。作者证明了这两种方法都能够控制第一类错误的概率，并且通过对比两种方法的故障检测能力，展示出基于流形拟合的概念简单的嵌入方法在某些情况下可以达到甚至超过经典低维流形监控方法的性能。此外，还通过真实的电气换向器图像数据集中的表面异常检测成功地验证了所提出的基于流形拟合的方法的实际适用性。
### Conclusion
实验结果表明，基于流形拟合的方法在性能上与传统的低维流形监测方法相当，有时甚至更佳。并通过实际数据集中的异常检测展示了所提出方法的实用性和有效性。
## 807. `cs.LG` - 基于扩散的阻抗学习以实现接触丰富的操作任务 [PDF](https://arxiv.org/pdf/2509.19696), [HTML](https://arxiv.org/abs/2509.19696)
### Authors
Noah Geiger,Tamim Asfour,Neville Hogan,Johannes Lachner
### Background
学习方法在信息域中的运动生成方面表现出色，但在能量域进行物理交互方面并不是主要设计的目的。阻抗控制能够塑造物理交互，但需要通过选择可实现的阻抗参数进行任务意识的调优。本文介绍了一种结合这两个领域的框架——基于扩散的阻抗学习。该框架利用Transformer扩散模型结合外部力矩进行跨注意力机制重建仿真零力轨迹（sZFT）。该模型捕捉了空间传输与旋转任务空间行为，并引入了基于SLERP的四元数噪声调度器确保几何一致性。重建后的sZFT通过能量估计器更新刚度和阻尼参数。该控制器在力和速度限制内实现了平滑的运动轨迹，并在各种peg插入任务中达到了30/30的成功率，且实现了毫毫米级别的位置精度和低于一度的旋转精度。所有代码都进行了公开发布，表明在物理AI领域取得了重要进展，即将基于模型的控制与基于学习的方法相互融合。
### Innovation
提出了基于扩散的阻抗学习框架，利用Transformer扩散模型结合外部力矩进行跨注意力机制重建仿真零力轨迹。引入了基于SLERP的四元数噪声调度器以确保几何一致性。控制器通过应用方向规则更新阻抗，减少了非任务轴的阻抗，同时保留了任务方向的刚性。该模型在少量样本数据上实现了高精度位置和旋转控制，并在KUKA LBR iiwa机器人上实现了实时力矩控制和自主刚度适应。还展示了在复杂场景和任务中的应用效果，证明了其在物理AI领域的潜力。
### Conclusion
该研究展示了基于扩散的阻抗学习框架在接触丰富操作任务中的应用效果。模型通过有限样本数据实现了毫毫米级的位置和旋转精度，并在机器人上实现了实时扭矩控制和自主刚度适应。这一方法为物理AI领域提供了重要的解决方案，即将模型驱动控制与基于学习的方法相结合。所有相关代码已经公开发布，便于进一步研究。
## 808. `cs.LG` - 从直觉到证据：衡量AI对开发人员生产力的真实影响 [PDF](https://arxiv.org/pdf/2509.19708), [HTML](https://arxiv.org/abs/2509.19708)
### Authors
Anand Kumar,Vishal Khare,Deepak Sharma,Satyam Kumar,Vijay Saini,Anshul Yadav,Sachendra Jain,Ankit Rana,Pratham Verma,Vaibhav Meena,Avinash Edubilli
### Background
本文对大规模部署的AI辅助软件开发工具进行了全面的实际评估。一家企业在一年内，数百名工程师将一个内部AI平台（DeputyDev）集成到了日常工作中，该平台结合了代码生成和自动化审查功能。通过严格的分层分析，研究显示了统计意义上的生产力提升，包括整体减少了31.8%的PR审查周期时间。开发人员普遍接受了这项工具，普及率在6个月内从最初的4%增长到峰值使用的83%，并最终稳定在60%。高效采用者通过该工具推送的代码量比基线水平提高了61%。
### Innovation
本文提供了从实际操作环境获取的实证证据，揭示了整合AI技术到企业软件开发流程中的潜在变革性和实际部署挑战。不同于控制基准评估，本文的纵向分析提供了生产企业环境的证据，展示了AI辅助工具在软件开发中的真实影响。
### Conclusion
研究发现在PR审查周期时间上实现了显著的减少（31.8%），并且开发人员的采用率很高，平台得到了积极反馈。此外，高效采用者的生产代码量提升了61%，贡献了约30-40%的生产代码。整体代码推送量增加了28%。
## 809. `cs.LG` - 带有符号约束的深度模型及其在混合动力传动控制中的应用 [PDF](https://arxiv.org/pdf/2509.19869), [HTML](https://arxiv.org/abs/2509.19869)
### Authors
Teruki Kato,Ryotaro Shima,Kenji Kashima
### Background
深度学习在复杂、大规模的系统中得到越来越广泛的应用，特别是在第一性原理建模难以实现的情况下。然而，标准的深度学习模型往往无法确保物理结构或下游控制中的凸性，导致物理不一致的预测和由于非凸性导致的不连续输入。
### Innovation
引入了符号约束——对雅可比矩阵元素的符号限制，统一了单调性、正性和符号正定性；此外，开发了能够满足这些约束的模型构建方法，并结合了控制合成过程。具体来说，设计了满足这些约束的精确线性化深度模型，并将模型预测控制形式化为凸二次规划问题，得出唯一优化器和Lipschitz连续的控制法则。在两项实验（两个储罐系统和混合动力传动）中，所提方法提高了预测精度并产生了比现有方法更平滑的控制输入。
### Conclusion
通过对符号约束的引入，结合精确线性化模型和凸优化方法，本文提出的方法能够有效解决传统深度学习模型在物理结构和凸性方面的问题，从而提高了模型的预测准确性和控制输入的平滑性。
## 810. `cs.LG` - BioBO: 基于生物学信息的贝叶斯优化用于扰动设计 [PDF](https://arxiv.org/pdf/2509.19988), [HTML](https://arxiv.org/abs/2509.19988)
### Authors
Yanke Li,Tianyu Cui,Tommaso Mansi,Mangal Prakash,Rui Liao
### Background
进行基因组扰动实验以加速药物发现和治疗靶点识别的有效设计至关重要，但由于人类基因组潜在遗传相互作用和实验约束的庞大搜索空间，全方位的基因组扰动仍然不可行。尽管贝叶斯优化（BO）作为一种强大的框架已被用于选择有意义的干预措施，但现有方法往往未能充分利用生物领域特定的先验知识。背景强调该领域的挑战和现有技术的不足，为该方法提供了理论依据和现实需求的支持。
### Innovation
本文提出了一种名为BioBO的新方法，它结合了贝叶斯优化、多模态基因嵌入和富集分析（广泛用于生物学中基因优先级确定）。这种方法通过结合生物根基的先验知识和获取函数，在原理上偏向于具有潜力的基因搜索，同时保持探索不确定性区域的能力。通过在公共基准和数据集上的实验结果，该方法展示了BioBO在标签效率提升25-40%以及在找到顶级表现扰动方面优于传统BO的方法。
### Conclusion
通过引入富集分析，BioBO为选定的扰动提供了路径级别的解释，提高了机制上的可解释性，将设计直接关联到生物上合乎逻辑的调节电路。该方法显著提高了基因组扰动实验的设计效率和效果，有望加速药物发现过程和治疗靶点识别。
## 811. `cs.LG` - 使用主动学习的表格检测 [PDF](https://arxiv.org/pdf/2509.20003), [HTML](https://arxiv.org/abs/2509.20003)
### Authors
Somraj Gautam,Nachiketa Purohit,Gaurav Harit
### Background
高效的数据标注仍然是机器学习中的关键挑战，尤其是在需要大量标记数据的对象检测任务中。传统的自动标注（AL）方法主要依赖于不确定性选择策略，但最近的研究表明，结合多样性的策略可以提高对象检测任务中的采样效率。
### Innovation
本文提出的方法确保选择具有代表性的例子，以提高模型的泛化能力。方法使用状态-of-the-art的表格检测架构CascadeTabNet和YOLOv9在两个基准数据集（TableBank-LaTeX和TableBank-Word）上进行评估。结果显示，基于主动学习的选择方式在相同的标注预算内显著优于随机采样，同时保持与完全监督模型相当的性能。
### Conclusion
该方法在相同的标注预算下实现了更高的mAP分数。
## 812. `cs.LG` - 几何自编码器先学习后观察的贝叶斯反演先验：先学习后观察 [PDF](https://arxiv.org/pdf/2509.19929), [HTML](https://arxiv.org/abs/2509.19929)
### Authors
Arnaud Vadeboncoeur,Gregory Duthé,Mark Girolami,Eleni Chatzi
### Background
不确定性量化（UQ）在工程应用中的推理至关重要。一个常见的任务是从少量噪声观测中恢复物理系统的全领域信息，这是一个通常高度病态的问题。工程系统通常具有复杂的和可变的几何结构，这阻止了标准的贝叶斯不确定性量化方法的应用。
### Innovation
本文提出了几何自编码器（GABI），这是一种应用于几何感知生成模型的框架。GABI 用于学习在不同几何结构下的物理响应生成模型，并将其作为贝叶斯反演的高度信息性的几何条件先验。通过遵循“先学习后观察”的原则，GABI 首先从具有不同几何结构的系统的大数据集中提炼信息，无需了解控制 PDE、边界条件或观测过程。在此之后，GABI 在推断时通过添加特定观测过程的似然性，生成自适应的后验分布。本文提出的框架对架构没有依赖性。通过创造性地使用近似贝叶斯计算（ABC）采样，实现了高效的 GPU 引擎利用实现。该方法在矩形域上的稳态热传播、翼型上的雷诺平均纳维-斯托克斯（RANS）流动、3D 车身上的亥姆霍兹共振和声源定位以及地形上的 RANS 气流测试中得到了验证。计算结果显示，在监督学习适用的限定设置中，预测准确性与确定性监督学习方法相当；在具有复杂几何结构的困难问题上，不确定性量化表现良好且鲁棒性强。这种方法提供了一个灵活的几何感知的‘训练一次，应用随意’的基础模型，该模型独立于任何特定的观测过程。
### Conclusion
通过基于已学得的大型数据库生成高级潜在先验，几何自编码器为贝叶斯反演提供了一种灵活的几何感知框架。该框架在各个几何复杂性级别的挑战性问题上展示了强大的性能，为处理几何复杂性提供了新的解决方案。
## 813. `cs.LG` - 移动安全图形的预测质量评估 [PDF](https://arxiv.org/pdf/2509.20028), [HTML](https://arxiv.org/abs/2509.20028)
### Authors
Cas Steigstra,Sergey Milyaev,Shaodi You
### Background
安全图形验证码对于反伪造至关重要，但智能手机成像质量的不可控性导致了高误拒绝率，从而产生了显著的可靠性差距。
### Innovation
本文提出了一种新颖的框架，用于预测视频帧在后续验证任务中的实用性，并提出了一种轻量级模型来预测视频帧的质量评分，确定其是否适合资源密集型的oracle模型。此外，研究发现，在不同工业印刷机械生成的图形上进行的跨领域分析表明，冻结的、预训练在ImageNet上的轻量级探针网络相较于完全微调模型能更好地泛化到未见过的印刷技术，这提供了在物理制造领域转变时，使用冻结的通用骨干网络可能比完全微调更为鲁棒的见解。
### Conclusion
该框架在包含32000多张图像的大规模数据集上通过重新加用的FNMR和ISRR指标得到了验证。研究还揭示了在未知打印技术上的更好泛化性，为实际应用中的实际泛化提供了关键见解：对于物理制造领域的变化，冻结的通用骨干网络可能比完全微调更为稳健。
## 814. `cs.LG` - Resampling过过程首次灭绝定律 [PDF](https://arxiv.org/pdf/2509.20101), [HTML](https://arxiv.org/abs/2509.20101)
### Authors
Matteo Benati,Alessandro Londei,Denise Lanzieri,Vittorio Loreto
### Background
灭绝时间在重新取样过程中是基本的但通常是难以处理的，因为此前的公式随着初始概率分布中存在的状态数量M按2^M阶缩放。这导致了计算上的困难和高时间复杂度的问题，限制了对其深入研究和广泛应用。
### Innovation
通过将多项式更新视为零漂移的独立平方根扩散，我们为首次灭绝时间提供了一个闭式解。我们证明了平均灭绝时间与Baxter等人提出的Wright-Fisher结果完全一致，从而以线性复杂度替代了指数级成本的评估。通过广泛的模拟验证了这一结果，并展示了首次灭绝时间对于模型塌陷预测的潜在力量。
### Conclusion
这些结果暗示了一种重新取样灭绝动力学的统一视角。
## 815. `cs.LG` - einsum的语法和语义 [PDF](https://arxiv.org/pdf/2509.20020), [HTML](https://arxiv.org/abs/2509.20020)
### Authors
Maurice Wenig,Paul G. Rump,Mark Blacher,Joachim Giesen
### Background
2011年，einsum作为一种实用且方便的张量表达符号被引入NumPy，用于机器学习、量子电路模拟和其他领域。它已被PyTorch和TensorFlow等其他Python框架以及Julia等其他语言实现。尽管它在实践中取得成功，但einsum仍然缺乏坚实的理论基础，并在不同框架中未统一，限制了正式推理和系统优化的机会。
### Innovation
本文讨论了张量表达式的术语并提供了einsum语言的正式定义。基于此定义，本文形式化并证明了张量表达式的重要等价规则，并突显了它们在实际应用中的相关性。
### Conclusion
通过对einsum语言的理论基础进行补充，本文为进一步优化和推理奠定了基础，有助于促进相关领域的研究和发展。
## 816. `cs.LG` - 使用狄利克雷过程混合模型聚类DINO嵌入的异常检测 [PDF](https://arxiv.org/pdf/2509.19997), [HTML](https://arxiv.org/abs/2509.19997)
### Authors
Nico Schulthess,Ender Konukoglu
### Background
在医学影像中，使用基础模型的信息嵌入进行无监督异常检测。对于小数据集，可以直接使用规范特征的记忆库进行异常检测，但这种方法不适用于大型医学数据集，因为计算负担会显著增加。因此，本文提出使用狄利克雷过程混合模型（DPMM）建模DINOv2嵌入的分布来处理大型数据集的问题。DPMM作为一种非参数混合模型，能够自动调整混合成分的数量以适配数据。与使用记忆库相比，本文采用成分中心与嵌入之间的相似性作为异常评分函数来生成粗略的异常分割掩码。论文实验表明，尽管DINOv2是通过自然图像训练的，其嵌入在医学成像基准上的异常检测性能非常具有竞争力，并且可以在推理时至少将计算时间减半。进一步的分析表明，归一化的DINOv2嵌入通常比未归一化的特征更与解剖结构对齐，即使在存在异常的情况下也是如此，这使得它们成为异常检测的良好特征表示。
### Innovation
本文提出了一种新颖的方法，即使用狄利克雷过程混合模型（DPMM）来对DINOv2嵌入进行分布建模，以处理大型医学影像数据集的无监督异常检测问题。通过DPMM嵌入，即使在推理阶段，也能够在计算时间至少减半的情况下获得极其竞争力的异常检测性能。此外，归一化的DINOv2嵌入在异常检测中具有更好的表现，即使在存在异常的情况下，它们也更与解剖结构对齐。代码已发布。
### Conclusion
本文提出了通过DPMM聚类DINO嵌入的医学影像异常检测方法，该方法不仅能够在大型数据集上实现高效且性能优越的异常检测，还能显著减少计算时间。此外，归一化的DINOv2嵌入特别适用于异常检测，即使在存在异常的情况下也保持了良好的对齐性。
## 817. `cs.LG` - 通过双重证书实现高效的在线大.margin分类 [PDF](https://arxiv.org/pdf/2509.19670), [HTML](https://arxiv.org/abs/2509.19670)
### Authors
Nam Ho-Nguyen,Fatma Kılınç-Karzan,Ellie Nguyen,Lingqing Shen
### Background
在线分类是优化、统计学习和数据科学中的核心问题。经典算法如感知机提供高效的更新和有限的错误保证，但它们没有利用分类问题的潜在几何结构。通过研究离线最大边距问题的对偶表示并利用由此产生的几何洞察，本文提出了一种在线环境中的原理性和高效算法。这种方法的一个关键特性是其不变性，这是从离线表示继承来的，在其性能分析中扮演关键角色。理论上，我们的分析给出了改进的错误和边距上限，仅依赖于不变量，提供了优于现有算法的更强保证，在某些情况下，算法每序列最多犯两次错误，而感知机可以在特定情况下犯任意多次错误。此外，实验证明了我们的方法在准确性和计算效率上均优于现有在线算法。
### Innovation
通过研究离线最大边距问题的对偶表示并利用几何洞察，提出了一种具有不变性的在线算法。理论上改进了错误和边距上限，提供更强的保证。该算法在序列每犯错最多两次，而感知机可以在某些情况下犯多次错。实验证明了与现有在线算法相比，该方法在准确性和计算效率方面均更优。
### Conclusion
提出的在线算法在计算效率上与现有在线算法相当，但在准确性方面显著优于它们，并通过理论保证提供了更强的不变性特性。特别是，在参数范式中，该算法每个序列最多犯两次错误，而感知机在某些条件下可以犯任意多次错误。
## 818. `cs.LG` - FairEquityFL — 在异构IoV网络中用于联邦学习的公平和公正的客户端选择 [PDF](https://arxiv.org/pdf/2509.20193), [HTML](https://arxiv.org/abs/2509.20193)
### Authors
Fahmida Islam,Adnan Mahmood,Noorain Mukhtiar,Kasun Eranda Wijethilake,Quan Z. Sheng
### Background
联邦学习（FL）由于其保护隐私的特性以及减轻通信开销的效率，在机器学习中的多种应用中得到广泛应用。IoV（互联网车辆）是一个有前景的应用场景，可以在其中利用FL更有效地训练模型。然而，由于每一轮FL训练只能由客户端的一部分参与者，这导致了在客户端选择过程中需要公平性的问题。尽管多年来，学术界和工业界提出了一些FL框架，但到目前为止，没有一个框架在动态和异构的IoV环境中为FL应用场景考虑了公平的客户端选择。
### Innovation
本文提出了一种名为FairEquityFL的新框架，确保所有客户端在网络训练过程中都有公平的机会参与。具体而言，在选择模块中引入了一个采样均衡模块，以保证在客户端选择过程中所有客户端都有公平的协作机会，并负责监控和控制客户端在每轮FL训练中的参与情况。另外，还引入了一种异常检测机制，基于模型性能上的显著波动（如准确率或损失最小化）来识别潜在的恶意客户端。
### Conclusion
我们在公开可用的数据集FEMNIST上进一步评估了FairEquityFL的性能，结果显示FairEquityFL在显著程度上优于基线模型。
## 819. `cs.LG` - IIoT中基于软件定义孪生网络的新型短期异常预测 [PDF](https://arxiv.org/pdf/2509.20068), [HTML](https://arxiv.org/abs/2509.20068)
### Authors
Bilal Dalgic(1),Betul Sen(1),Muge Erel-Ozcevik(1) ((1) Manisa Celal Bayar University, Turkey)
### Background
当前对工业物联网（IIoT）环境的监控和动态控制提出了重要需求。现有文献在基于软件定义网络（SDN）的数字孪生（DT）和针对IIoT威胁的时间智能模型训练方面缺少实现细节，特别是在短期异常检测方面。因此，本文旨在填补这一空白，提出一种利用SDN为基础的DT的新框架，用于短期异常检测。
### Innovation
本文创新性地提出了一种基于SDN为基础的数字孪生（SD-TWIN）的异常检测算法，采用了时间感知特征标签和多种机器学习模型的综合评估。特别值得一提的是，新部署的SD-TWIN实时系统中，GPU加速的LightGBM模型表现出色，实现了高召回率和强分类性能之间的良好平衡。
### Conclusion
本文提出的SD-TWIN框架和基于LightGBM的算法为IIoT环境提供了有效的短期异常检测方法，能够更好地满足当前对IIoT环境安全监控和动态控制的需求。
## 820. `cs.LG` - 使用视觉基础模型的高光谱适配器进行语义分割 [PDF](https://arxiv.org/pdf/2509.20107), [HTML](https://arxiv.org/abs/2509.20107)
### Authors
JuanaJuana Valeria Hurtado,Rohit Mohan,Abhinav Valada
### Background
高光谱成像（HSI）同时捕捉空间信息和密集的光谱测量值，涵盖了众多窄波长带。这种丰富的光谱内容有可能在复杂材料组成、变化光照或其他视觉挑战条件下增强机器人感知能力。然而，当前的HSI语义分割方法由于依赖于针对RGB输入优化的架构和学习框架而表现不佳。
### Innovation
本文提出了一种新的高光谱适配器，利用预训练的视觉基础模型有效学习高光谱数据。该架构结合了光谱变换器和光谱感知空间先验模块，以提取丰富的空间光谱特征。此外，引入了一种模态感知交互块，通过专用的提取和注入机制，促进了高光谱表示和冻结的视觉Transformer特征的有效集成。在三个基准自动驾驶数据集上的广泛评估表明，该架构直接使用HSI输入实现了最先进的语义分割性能，优于基于视觉和高光谱分割方法。
### Conclusion
本文提出的架构在三个基准自动驾驶数据集上的广泛评估中展示了其先进的语义分割性能，直接利用HSI输入，超越了基于视觉和高光谱分割方法。并作出了相关代码可供下载。
## 821. `cs.LG` - Projective Kolmogorov Arnold Neural Networks (P-KANs): Entropy-Driven Functional Space Discovery for Interpretable Machine Learning [PDF](https://arxiv.org/pdf/2509.20049), [HTML](https://arxiv.org/abs/2509.20049)
### Authors
Alastair Poole,Stig McArthur,Saravan Kumar
### Background
Kolmogorov-Arnold Networks (KANs)通过将非线性从节点转移到边的方式展示了在科学机器学习和可解释建模中的强大能力。然而，当前的KAN实施存在由于高维样条参数空间中的冗余而导致的基本效率低下的问题。这种冗余在模型的雅可比矩阵中表现为“烦恼空间”，导致模型容易过拟合并且泛化性能不佳。研究者提出了一种新颖的训练框架，即项目化Kolmogorov-Arnold网络（P-KANs），该框架能够通过熵最小化技术引导边函数发现向具有可解释功能表示。这种方法在保持样条空间灵活性的同时引入了“引力”项，促使向最优功能表示收敛。该方法的关键洞察在于通过投影系数的熵分析可以识别出最优表示，从而将边函数压缩到更低参数的投影空间（Fourier, Chebyshev, Bessel）。
### Innovation
通过引入Entropy-Driven Functional Space Discovery（熵驱动的功能空间发现）技术，P-KANs能够在保持表示容量的同时减少高达80%的参数，提高对噪声的鲁棒性，并成功应用于工业自动化纤维铺设预测任务。这种方法能够自动发现混合功能表示，为科学机器学习应用提供压缩优势和增强的可解释性。
### Conclusion
P-KANs在多个领域展示了优越的性能，能够在保持表示能力的基础上实现高达80%的参数减少，具有显著提高的噪声鲁棒性，并成功应用于工业自动化纤维铺设预测。这种方法具备自动发现混合功能表示能力，不仅提供压缩优势，还增强了科学机器学习的应用中的可解释性。
## 822. `cs.LG` - Thinking Augmented Pre-training [PDF](https://arxiv.org/pdf/2509.20186), [HTML](https://arxiv.org/abs/2509.20186)
### Authors
Liang Wang,Nan Yang,Shaohan Huang,Li Dong,Furu Wei
### Background
大规模语言模型（LLM）的预训练计算能力增长迅速，但高质量数据的可用性仍然有限。这使得如何最大程度利用现有数据成为一个重要的研究难题。由于模型容量固定，某些高质量的标记很难学习，这主要是因为单个标记背后的原因非常复杂和深奥。
### Innovation
提出了一个称为Thinking-Augmented Pre-Training (TPT)的通用方法，通过自动生成的思考轨迹增强文本内容。这种增强提高了训练数据的量，使高质量标记更容易通过逐步推理和分解来学习。
### Conclusion
实验结果表明，TPT方法显著提高了各种模型规模和家族的LLM性能。对于一个3B参数的模型，TPT在几个具有挑战性的推理基准上的后训练性能提高了超过10%，预训练数据效率提高了三倍。
## 823. `cs.LG` - 选择你的战场：多场拔河游戏中的分布式学习 [PDF](https://arxiv.org/pdf/2509.20147), [HTML](https://arxiv.org/abs/2509.20147)
### Authors
Siddharth Chandak,Ilai Bistritz,Nicholas Bambos
### Background
研究了N名玩家和K场同时进行的游戏。每一场比赛都被建模为一个拔河游戏，其中增加一名玩家的动作会减少其他玩家的奖励。每个玩家在任意给定时间只参与一场游戏。每轮时间步长中，每个玩家决定他们想参与哪场比赛以及在那场比赛中采取的动作。他们的奖励依赖于同一场比赛中所有玩家的动作。通过这种方法形成的K场比赛体系被称作“元拔河游戏”(Meta ToW)。这类游戏可以模拟如功率控制、分布式任务分配和传感器网络中的激活等场景。
### Innovation
提出了一种分布式算法——“元和平拨河”算法。该算法的行动更新使用简单的随机逼近算法完成，玩家间切换游戏的决定使用频次较低的1比特通信进行。证明在元拔河游戏中，该算法能收敛到满足玩家目标服务质量的奖励向量。
### Conclusion
通过模拟验证了该算法在功率控制、分布式任务分配和传感器网络激活等场景中的有效性。
## 824. `cs.LG` - 强化算法特征工程的智能算法选择：推荐系统中的元学习 [PDF](https://arxiv.org/pdf/2509.20134), [HTML](https://arxiv.org/abs/2509.20134)
### Authors
Jarne Mathi Decker
### Background
《免费午餐定理》表明，没有一种推荐算法能够适用于所有用户，因此引发了一个显著的算法选择问题。标准的元学习方法试图通过用户特征来选择最合适的算法，但这些方法将本质上不同的算法视为等效的“黑箱”选择。本文探讨了通过工程化一个全面的特征集来明确描述算法本身的影响，结合静态代码指标、抽象语法树属性、行为性能标志以及高层次概念特征，评估了两种元学习者在五个数据集上的表现。
### Innovation
本文提出了通过工程化算法特征来改进推荐系统中算法选择的任务，结合静态代码指标、抽象语法树属性、行为性能标志以及高层次概念特征，评估了一种结合用户和算法特征的元学习模型的性能。这种工程化的特征旨在克服现有元学习方法将算法视为等效“黑箱”选择的局限性，从而提高算法选择的精度和整体性能。
### Conclusion
实验结果表明，结合算法特征的元学习者在平均NDCG@10上取得了0.143的成就，比仅使用用户特征的单一最佳算法基线提高了11.7%（0.128）。然而，算法特征并未在总体NDCG@10上超过仅使用用户特征的元学习者（0.144）。虽然在Top-1选择准确性上提高了16.1%，但Top-3选择准确性下降了10.7%。因此，对于推荐系统中的单个用户算法选择任务，用户特征的预测能力远远超过算法特征。尽管算法特征提高了选择的精确度，但要充分发挥它们来提升整体性能仍是一个非平凡的挑战。
## 825. `cs.LG` - 针对自动驾驶视觉语言模型的通用伪装攻击 [PDF](https://arxiv.org/pdf/2509.20196), [HTML](https://arxiv.org/abs/2509.20196)
### Authors
Dehong Kong,Sifan Yu,Siyuan Liang,Jiawei Liang,Jianhou Gan,Aishan Liu,Wenqi Ren
### Background
视觉语言模型在自动驾驶领域的研究逐渐成为了一个有前景的方向，这些模型在多模态推理方面取得了显著的进步。尽管这些模型具有先进的推理能力，但仍然对于物理和数字层面的欺骗性攻击非常脆弱。现有的物理攻击主要针对视觉模块，而数字层面的攻击则集中于模型的低级感知组件。这些攻击方法面临着难以直接转移到视觉语言模型自动驾驶（VLM-AD）系统中的挑战。
### Innovation
提出了第一个针对VLM-AD的通用伪装攻击（UCA）框架，该框架在特征空间中工作，通过生成可物理实现的伪装纹理，具有较强的一般性，适用于不同用户命令和模型架构。UCA通过引入特征差异损失（FDL）最大化清洁图像和攻击性图像之间的表示差异。此外，UCA还采用了多尺度学习策略并调整采样比例，以增强在不同尺度和视角变化下现实场景的适应性，从而提高训练的稳定性。
### Conclusion
广泛的实验表明，UCA可以诱导在各种VLM-AD模型和驾驶场景中产生错误的驾驶指令，比现有最先进的攻击方法在3-P指标上取得了30%的性能提升。此外，UCA还表现出强大的攻击鲁棒性，在各种视角和动态条件下都可执行，显示出实际部署的潜力。
## 826. `cs.LG` - 基于硬件的协作感知架构在车道变换预测中的设计洞察与比较评估 [PDF](https://arxiv.org/pdf/2509.20218), [HTML](https://arxiv.org/abs/2509.20218)
### Authors
Mohamed Manzour,Catherine M. Elias,Omar M. Shehata,Rubén Izquierdo,Miguel Ángel Sotelo
### Background
近年来，车道变换预测的研究引起了广泛关注。大多数现有工作都是在仿真环境中或使用预记录的数据集中进行的，这些工作往往依赖于对传感、通信和交通行为的简化假设，这些假设在实际应用中并不总是成立。实际部署的车道变换预测系统相对较少，即使有报告，有关实际挑战、限制和经验教训的记录也往往不足。
### Innovation
本研究通过在混合交通中部署实际硬件来探索协作车道变换预测，并分享实现和测试过程中获得的见解。我们强调了面临的一些实际挑战，包括瓶颈、可靠性问题和运营限制，这些都影响了系统的行为。通过记录这些经验，研究为从事类似流程的人提供了指导。
### Conclusion
本研究为其他从事类似流程的人提供了实用的指导，强调了实际部署中的挑战和经验，为未来的研究和实施提供了宝贵的经验教训。
## 827. `cs.LG` - 多语言希望话语检测：基于Logistic回归、mBERT和XLM-RoBERTa的主动学习比较研究 [PDF](https://arxiv.org/pdf/2509.20315), [HTML](https://arxiv.org/abs/2509.20315)
### Authors
T. O. Abiola,K. D. Abiodun,O. E. Olumide,O. O. Adebanji,O. Hiram Calvo,Grigori Sidorov
### Background
希望话语能够激发鼓励和乐观情绪，在促进正面网络对话方面发挥重要作用。然而，在多语言和资源匮乏的环境中，其检测仍然具有挑战性。
### Innovation
提出了一个利用主动学习方法和基于Transformer的模型（包括mBERT和XLM-RoBERTa）的多语言框架，用于希望话语检测。实验在英语、西班牙语、德语和乌尔都语的数据集上进行，包括最近共享任务的基准测试集。
### Conclusion
Transformer模型显著优于传统基线，XLM-RoBERTa达到最高整体准确率。此外，我们的主动学习策略即使在小型标注数据集上也能保持强大性能。该研究强调了结合多语言Transformer与数据高效训练策略在希望话语检测中的有效性。
## 828. `cs.LG` - 探讨物理导向神经网络在逆问题中对噪声的鲁棒性 [PDF](https://arxiv.org/pdf/2509.20191), [HTML](https://arxiv.org/abs/2509.20191)
### Authors
Aleksandra Jekic,Afroditi Natsaridou,Signe Riemer-Sørensen,Helge Langseth,Odd Erik Gundersen
### Background
偏微分方程（PDEs）的解对于科学和工程中的动力系统建模至关重要。物理导向神经网络（PINNs）是一种新兴的机器学习方法，但其性能和局限性仍有许多未解之谜。尽管PINNs被认为在计算时间和准确性方面不如传统方法（如有限元法），但在解决逆问题和处理噪声或不完整数据方面显示出了潜力。论文通过比较PINNs与使用有限元方法结合数值优化器的传统方法来解决逆问题的性能，对一系列从简单到复杂的流体力学问题进行了测试，有噪音和无噪音情况均有所涉及。
### Innovation
本研究通过使用传统有限元方法结合数值优化器的对比，评估了PINNs在处理逆问题和噪声数据方面的性能。研究发现，在低维度情况下，PINNs的性能不及传统方法，但随着维度增加和数据量增多，这种差距可能会缩小。同时，研究还指出了训练中的一些常见失败，这些失败需要解决以提高PINNs在处理噪声逆问题中的性能.
### Conclusion
虽然PINNs减轻了人为努力和专业知识的需求，但在解决逆问题中其表现仍然逊色于传统方法。然而，该差距在高维度和大量数据的情况下似乎有所减小。为了提高PINNs在处理噪声逆问题中的表现，需要解决训练中常见的失败问题。
## 829. `cs.LG` - 坚持不走的广告：通过心理行为模型实现接近最优广告优化 [PDF](https://arxiv.org/pdf/2509.20304), [HTML](https://arxiv.org/abs/2509.20304)
### Authors
Kailash Gopal Darmasubramanian,Akash Pareek,Arindam Khan,Arpit Agarwal
### Background
数字广告中，优化广告的时机和频率是一个关键问题，具有重要的经济意义。现有的排期策略依赖于一些简单的启发式方法，如均匀间隔和频率限制，但这些方法忽视了用户的长期兴趣。文献表明，用户的长期兴趣和参与度是由多种心理效应的相互作用形成的。基于这一点，本文提出了一个全新的广告排期模型，该模型基于三个重要的心理原则：曝光效应、享乐适应和操作性条件反射。
### Innovation
本文的主要创新在于，首先证明了固定展示广告数量时，最优广告排期仅依赖于操作性条件反射函数。所提出的核心算法能够在近线性时间内输出近最优的广告排期，差异在许多自然设置下可以忽略。该算法揭示了简单的均匀间隔策略在许多场景下是次优的。此外，通过一个简单的线性搜索过程，能够找到最优展示广告的数量，这部分取决于曝光效应和享乐适应函数。以上发现通过实验结果得到了验证，表明本文的策略优于多种基准方法。
### Conclusion
基于心理行为模型，本文提出了一个近最优的广告优化策略。这种方法不仅克服了传统简单启发式的限制，还揭示了更深层次的优化原则。通过优化广告展示时间和频率，能够显著提高用户的广告兴趣，进而提高广告效果。
## 830. `cs.LG` - 动态规划中的误差传播：从随机控制到期权定价 [PDF](https://arxiv.org/pdf/2509.20239), [HTML](https://arxiv.org/abs/2509.20239)
### Authors
Andrea Della Vecchia,Damir Filipović
### Background
该研究探讨了离散时间随机最优控制（SOC）的理论和方法论基础。研究从制定一个通用的动态规划框架开始，明确了详细收敛性分析所需的数学结构。通过结合非参数回归方法和蒙特卡洛子抽样技术，对关联价值函数进行估计。回归步骤在再生核希尔伯特空间中进行，利用经典的KRR算法，同时引入蒙特卡洛抽样方法来估计延续价值。为了评估我们的价值函数估计器的准确性，提出了一种自然的误差分解，并在每一时间步骤上严格控制误差项。然后分析了这一误差如何从成熟期向初始阶段逆向传播，这是一个相对较少研究的SOC文献方面。
### Innovation
提出了自然的误差分解并严格控制误差项在每一时间步骤上，分析了误差从成熟期向初始阶段逆向传播。这种方法论上的创新适用于关键的金融应用：美国期权定价问题的解决方法得到自然的应用。
### Conclusion
研究最后表明，其分析自然应用于一个重要金融应用：美国期权定价。通过对误差传播的研究，揭示了从成熟期至初始阶段的误差变化规律，为随机最优控制提供了一个全新的视角。
## 831. `cs.LG` - 评价与元评价中机器翻译的充足性和流畅性权衡：偏向一种还是兼顾两种？ [PDF](https://arxiv.org/pdf/2509.20287), [HTML](https://arxiv.org/abs/2509.20287)
### Authors
Behzad Shayegh,Jan-Thorsten Peter,David Vilar,Tobias Domhan,Juraj Juraska,Markus Freitag,Lili Mou
### Background
研究机器翻译中的充足性和流畅性之间的权衡，发现当前评价标准倾向于充足性，而不是流畅性。这种倾向在元评价中也存在，标准的WMT元评价更偏向于充足的评价指标而非流畅性的评价指标。此外，发现元评价数据集中系统构成的偏见是导致这种偏向的部分原因。
### Innovation
提出了一种方法来在元评价中合成翻译系统，以控制这种偏见。通过这种方法，研究揭示了充足性和流畅性在元评价中的权衡对于评价指标排名的重要性。
### Conclusion
研究强调理解元评价中充足性和流畅性之间的权衡及其对评价指标排名的影响的重要性，指出需要更好地平衡这两方面，以提高评价的公平性和准确性。
## 832. `cs.LG` - ImageNet训练的CNNs并非偏爱纹理：通过受控抑制重新审视特征依赖 [PDF](https://arxiv.org/pdf/2509.20234), [HTML](https://arxiv.org/abs/2509.20234)
### Authors
Tom Burgert,Oliver Stoll,Paolo Rota,Begüm Demir
### Background
有关卷积神经网络（CNNs）在深度学习特征使用中的固有偏见，特别是纹理偏好，已经成为讨论的核心。以前的研究通过研究表明CNNs对纹理特征的偏好，但这项工作通过重新审视Geirhos等人提出的影响因素实验及其局限性，提出了新的见解。
### Innovation
研究提出了一个领域无关的框架，通过系统地抑制形状、纹理和颜色线索来量化特征依赖，避免了选择性冲突的混淆。该研究通过控制抑制条件下的评估发现，CNNs主要依赖局部形状特征，而非固有地偏好纹理。
### Conclusion
虽然现代训练策略或架构（如ConvNeXt、ViTs）可以显著减少这一依赖，但依赖模式在不同领域有所差异：计算机视觉模型优先依赖形状，医学成像模型更强调颜色，而遥感模型则表现出更强的纹理依赖。
## 833. `cs.LG` - Web API集成代码生成基准测试 [PDF](https://arxiv.org/pdf/2509.20172), [HTML](https://arxiv.org/abs/2509.20172)
### Authors
Daniel Maninger,Leon Chemnitz,Amir Molzam Sharifloo,Jannis Brugger,Mira Mezini
### Background
API集成是数字基础设施的关键组成部分，使软件系统能够连接和互动。然而，许多研究表明，编写或生成正确代码以调用API，尤其是Web API，是一项具有挑战的任务。尽管大规模语言模型（LLMs）在软件开发中越来越受欢迎，但它们在自动化生成Web API集成代码方面的有效性仍待探索。
### Innovation
本文提出了一组数据集和评估管道，用于评估LMLs生成Web API调用代码的能力。实验结果显示，这些模型在生成API调用代码方面面临着重大挑战，导致出现虚拟化端点、参数使用错误等问题。经过评估的开源模型在任务解决方面无法超过40%。
### Conclusion
通过实验发现，现有的LMLs模型在生成Web API调用代码方面仍存在显著挑战，即使在最先进的开源模型中，也未能成功解决超过40%的任务。
## 834. `cs.LG` - 通过直接成像在高对比度下进行系外行星检测和表征的深度学习 [PDF](https://arxiv.org/pdf/2509.20310), [HTML](https://arxiv.org/abs/2509.20310)
### Authors
Théo Bodrito,Olivier Flasseur,Julien Mairal,Jean Ponce,Maud Langlois,Anne-Marie Lagrange
### Background
系外行星成像是天文学中的一个重要挑战，因为需要高角分辨率和高对比度。对于高对比度的多变量图像序列，存在一个会干扰图像的无关成分，这需要通过统计模型来解决。新方法结合了可学习架构和物理原理，可以优化检测信噪比，将多颗同一恒星的观测数据融合在一起。这种方法尤其适用于VLT/SPHERE仪器的数据处理，有助于提高系外行星的检测灵敏度和天文测量（如定位和光度）的准确性。
### Innovation
本文提出了一种多尺度统计模型，用于处理高对比度的多变量图像序列中的无关成分，通过集成可学习架构，结合了物理原理，使得多颗同一恒星的观测数据可以以优化检测信噪比的方式融合。将这种方法应用于VLT/SPHERE仪器的数据，显著提高了系外行星检测的灵敏度和测量的准确性（天文测量和光谱）。
### Conclusion
通过这种方法的应用，有效提高了系外行星的检测灵敏度和测量准确性，不仅限于VLT/SPHERE仪器，该方法具有广泛的应用前景。
## 835. `cs.LG` - 视觉模拟：基于运动跟踪与生成的人形机器人位姿操纵 [PDF](https://arxiv.org/pdf/2509.20322), [HTML](https://arxiv.org/abs/2509.20322)
### Authors
Shaofeng Yin,Yanjie Ze,Hong-Xing Yu,C. Karen Liu,Jiajun Wu
### Background
在不规则环境中进行人形机器人的位姿操纵需要将主观视野感知与全身控制紧密结合。目前存在的方法要么依赖外部动力捕捉系统，要么无法在多样性任务间有效泛化。这些局限性阻碍了人形机器人在复杂环境下的实际应用能力。
### Innovation
提出了VisualMimic，这是一个视觉仿真到现实的框架，能够将主观视野感知与分层全身控制统一起来。VisualMimic 结合了从人类动作数据通过师徒方案训练得到的模块不变低层面关键点跟踪器和具体任务的高层面策略，后者能够从视觉和本体感受输入生成关键点指令。为确保稳定的训练，VisualMimic 向低层面策略注入噪声，并用人类运动统计限制定层面动作。该框架能够在仿真中训练的视觉动力策略实现零样本转移至实际的人形机器人，并在多种位姿操纵任务中展现出色表现，如举箱、推箱、足球运球及射门。此外，该策略还能够在外场环境中表现出良好的泛化能力。
### Conclusion
VisualMimic 使基于仿真训练的视觉动力策略能够零样本转移到现实的人形机器人中，适用于各类位姿操纵任务，并在不同环境条件下具有鲁棒性。
## 836. `cs.LG` - 时空知识集成：大气时间序列预测的轻量级方法 [PDF](https://arxiv.org/pdf/2408.09695), [HTML](https://arxiv.org/abs/2408.09695)
### Authors
Yisong Fu,Fei Wang,Zezhi Shao,Boyu Diao,Lin Wu,Zhulin An,Chengqing Yu,Yujie Li,Yongjun Xu
### Background
变压器模型在大气时间序列预测（ATSF）中引起了关注，因为它们能够捕获全局空间-时间相关性。然而，复杂的架构导致了过多的参数和较长的训练时间，这限制了其在大规模预测中的可扩展性。
### Innovation
本文从大气动力学的角度重新审视了ATSF，发现时空位置嵌入（STPE）能够在不使用注意力机制的情况下，内在地表示空间-时间相关性。基于此，作者提出了结合了时空知识嵌入的轻量级模型STELLA，它仅使用STPE和MLP架构代替变压器层。STELLA使用1万个参数并在一小时内训练，与其它先进的方法相比，在五个数据集上表现优异。
### Conclusion
该研究强调了时空知识集成相对于复杂架构的有效性，提供了ATSF的新颖见解。
## 837. `cs.LG` - 预训练深度模型在标签稀缺条件下的学习排序中优于GBDTs [PDF](https://arxiv.org/pdf/2308.00177), [HTML](https://arxiv.org/abs/2308.00177)
### Authors
Charlie Hou,Kiran Koshy Thekumparampil,Michael Shavlovsky,Giulia Fanti,Yesh Dattatreya,Sujay Sanghavi
### Background
现有文献表明，在表格数据上，当前的深度学习模型在性能上与梯度提升决策树相当，但在异常数据上显著表现不佳。然而，这些研究往往着重于理想化的问题设置，可能无法捕捉到现实世界的复杂性。
### Innovation
本文识别出一种自然的表格数据设置，即在标签稀缺条件下的表格学习排序（LTR）场景中，深度学习模型可以超越梯度提升决策树。利用无监督预训练，深度学习排名器能够充分利用大量未标记数据，并在广泛和专有的数据集的实验中，展示了相较于梯度提升决策树排名器在排名指标上的持续性优越表现，特别是在异常情况下的提升幅度最高可达到38%。
### Conclusion
在标签稀缺的条件下，预训练的深度学习模型在学习排序任务上优于GBDT排名器。
## 838. `cs.LG` - DeNOTS：时间序列中的稳定深度神经ODE [PDF](https://arxiv.org/pdf/2408.08055), [HTML](https://arxiv.org/abs/2408.08055)
### Authors
Ilya Kuleshov,Evgenia Romanenkova,Vladislav Zhuzhel,Galina Boeva,Evgeni Vorsin,Alexey Zaytsev
### Background
神经CDEs为处理不规则时间序列的时间演变提供了一种自然的方式。系统中的函数评估次数（NFE）是与传统神经网络层数相当的概念，通常通过数值解法的误差容差来调节：较低的容差意味着更高的数值精度，需要更多的积分步骤。但是，降低容忍度并不能充分提高模型的表达能力。本文提出了一种简单有效的替代方案：通过扩大积分时间范围来增加NFE并“加深”模型。对于传统的向量场，增加积分间隔会导致无法控制的增长，因此本文还提出了一种负反馈（NF）方法来稳定动态，确保在不约束灵活性的情况下有证明的稳定性。
### Innovation
本文提出了一个名为 DeNOTS 的简单有效的替代方案，通过扩大积分时间范围来增加 NFE 并“加深”模型。为了稳定动态，作者还提出了一种负反馈（NF）方法，该方法确保在不约束灵活性的情况下有证明的稳定性。此外，作者还提供了理论上限来估计 Neural ODE 的风险。实验结果表明，DeNOTS 方法在多个公开数据集上优于现有方法，包括最近的 Neural RDE 和状态空间模型，在某些指标上甚至可以提高20%。
### Conclusion
DeNOTS 结合了表达性和稳定性，使在连续时间域中的建模更加可靠。
## 839. `cs.LG` - Sample what you can't compress [PDF](https://arxiv.org/pdf/2409.02529), [HTML](https://arxiv.org/abs/2409.02529)
### Authors
Vighnesh Birodkar,Gabriel Barcik,James Lyon,Sergey Ioffe,David Minnen,Joshua V. Dillon
### Background
传统的自编码器生成的图像表示经常模糊。通过引入对抗（GAN）损失和感知损失，可以提高重建质量，但这些方法缺乏系统的理论解释。同时，在生成模型中，扩散模型已经显示出创建清晰和高质量结果的能力，并且具有坚实的理论基础。本文将自编码器的表示学习与扩散模型相结合，探索了在改进表示的同时提高压缩和生成质量的可能性。
### Innovation
本文提出了将扩散模型与自编码器相结合的方法，首次展示了在基于扩散损失学习连续编码器和解码器的同时实现更高的压缩比和更好的生成性能。与基于GAN的自编码器相比，该方法在重建质量上表现出色，并且更容易调整。此外，扩散模型生成的随机解码器可以生成无法压缩的细节，因此称为“Sample what you can't compress”（S-WYC）的方法。
### Conclusion
该方法在重建质量上优于基于GAN的自编码器，且更容易调整。与基于最先进GAN损失获得的表示相比，生成的表示更适合于使用潜在扩散模型进行建模。由于解码器是随机的，它可以生成无法在确定性的潜在表示中编码的细节。
## 840. `cs.LG` - 外部时间过程中的马尔可夫决策过程 [PDF](https://arxiv.org/pdf/2305.16056), [HTML](https://arxiv.org/abs/2305.16056)
### Authors
Ranga Shaarad Ayyagari,Revanth Raj Eega,Ambedkar Dukkipati
### Background
当前的强化学习算法主要针对静态环境进行开发，而涉及非静态环境的研究多基于特定的假设。现实世界中的环境会因各种外部事件持续演变，人类依据历史事件模式进行决策。因此，本文研究在外部时间过程影响下的马尔可夫决策过程，探讨该过程在特定条件下的可操作性，并提出一种基于当前环境状态及外部过程历史事件有限记录的策略迭代算法。该算法展现了策略改进在状态空间确定区域的保证，同时分析了仅考虑有限时间事件记录的方差复杂度。结果适用于满足特定条件的离散时间过程，进一步分析了高斯基普斯过程（Gaussian marks）的情况。通过实验验证了政策评估和部署的有效性。
### Innovation
提出了考虑外部时间过程影响下的马尔可夫决策过程策略迭代算法，不仅基于当前环境状态，还考虑了外部过程的历史事件记录；利用理论分析确保了在一定状态空间区域策略改进的收敛性，分析了含有有限时间事件记录的方差复杂度；进一步研究具有高斯基普斯过程的案例，并通过实验验证了该方法的有效性。
### Conclusion
本文研究在外部时间过程影响下的马尔可夫决策过程，提出了一个可行的策略迭代算法，能够当然当前环境状态及有限历史事件，并对策略改进和方差复杂度进行了理论分析，研究扩展到了具有高斯基普斯过程的情况，通过实验验证了算法的有效性。
## 841. `cs.LG` - 超越网格：带有自适应离散化技术的多目标贝叶斯优化 [PDF](https://arxiv.org/pdf/2006.14061), [HTML](https://arxiv.org/abs/2006.14061)
### Authors
Andi Nika,Sepehr Elahi,Çağın Ararat,Cem Tekin
### Background
考虑了一个向量值目标函数f来源于在良好处理的紧度量空间(X,d)中的高斯过程(GP)样本的问题。函数f事先未知，对设计x进行评估仅能得到f(x)的噪声观测。当X的基数较大时，通过详尽搜索帕累托最优设计变得不切实际。因此，提出了一个自适应ε-PAL算法，该算法利用GP样本的平滑性及(X,d)的结构以快速学习方式识别设计下的ε-精确的帕累托集。通过对ε-精确帕累托集识别的样本复杂性提供了信息类型和度量维度类型界。实验表明，所提出算法在帕累托集识别方面优于其他方法。
### Innovation
提出了一个名为自适应ε-PAL的算法，该算法利用GP样本的平滑性以及设计空间(X,d)的结构，通过一种基于树的自适应离散化技术，尽可能少的评估来识别ε-精确的帕累托集。并且为ε-精确帕累托集识别提供了样本复杂性的界，包括信息类型界和度量维度类型界，实验结果表明该算法在帕累托集识别方面表现更优。
### Conclusion
证明了自适应ε-PAL算法在多目标贝叶斯优化中能够有效且高效地识别ε-精确的帕累托集，并且通过理论分析和实验验证了其性能优于其他方法。
## 842. `cs.LG` - 任意精度和稀疏度下鲁棒的神经网络训练 [PDF](https://arxiv.org/pdf/2409.09245), [HTML](https://arxiv.org/abs/2409.09245)
### Authors
Chengxi Ye,Grace Chu,Yanfeng Liu,Yichi Zhang,Lukasz Lew,Li Zhang,Mark Sandler,Andrew Howard
### Background
量化和稀疏化操作在神经网络中的不连续性长期阻碍了反向传播，尤其是在极低精度和稀疏性状态下。标准的直通估计器(STE)通常用于解决这一问题，但由于其量化感知正向传播和非量化感知反向传播之间的理解不良匹配，导致未管理的错误，可能破坏学习过程。
### Innovation
作者引入了一种基于稳健岭回归目标的去噪去量化变换，使得整个学习过程能够意识到并且抵御STE的代理梯度所忽略的量化错误。这一变换创建了一个明确且纠正性的梯度路径。此外，作者还将这一原则扩展到稀疏化，将其视为一种特殊形式的量化，且不显著的值被映射为零，从而提供了一个统一的框架，使现有模型能够在广泛的精度和稀疏性水平下稳定地训练，并且即使在二值网络（A1W1）和小于1位的稀疏网络中也能实现稳定的训练，其他方法无法做到这点。
### Conclusion
这种方法取得了最先进的结果，并提供了一条理论上基于高效神经网络的研究路径。
## 843. `cs.LG` - 表示收敛：互仿是一种隐式的正则化 [PDF](https://arxiv.org/pdf/2501.02481), [HTML](https://arxiv.org/abs/2501.02481)
### Authors
Zhengpeng Xie,Jiahang Cao,Changwei Wang,Fan Yang,Marco Hutter,Qiang Zhang,Jianxiong Zhang,Renjing Xu
### Background
本文探讨了强化学习策略之间的互仿如何作为一种隐式的正则化手段，防止因过度拟合无关特征而导致的问题。文章分析了互仿在增强策略对无关特征的鲁棒性方面的理论与实践经验。
### Innovation
1. 理论贡献：首次证明增强策略对无关特征的鲁棒性能够改善泛化性能。2. 实验贡献：通过展示互仿增强策略的鲁棒性，使图片输入产生不变表征。
### Conclusion
文章未追求最先进的性能，而是专注于揭示泛化背后的原理，加深对泛化机制的理解。
## 844. `cs.LG` - 使用大型语言模型进行冷启动切割平面分隔器配置 [PDF](https://arxiv.org/pdf/2412.12038), [HTML](https://arxiv.org/abs/2412.12038)
### Authors
Connor Lawless,Yingxi Li,Anders Wikum,Madeleine Udell,Ellen Vitercik
### Background
现有的混合整数线性规划(MILP)求解器暴露了大量的参数，这些参数对性能影响巨大但配置复杂，仅对专家用户友好。现有的机器学习方法需要在大量相关实例上进行训练，泛化能力差，且难以集成到现有的求解器工作流程中。
### Innovation
提出了一种基于大型语言模型(LLM)的框架，利用问题描述和求解器特定的分隔器摘要来配置切割平面分隔器。为了减少LLM输出的方差，引入了一种集成策略，通过聚类和聚合候选配置形成一小部分高性能配置。该方法无需定制求解器接口，通过简单的API调用在短时间内生成配置，并仅需解决少量实例。
### Conclusion
广泛的实验表明，该方法在标准合成和真实世界MILP上的表现与最先进的配置方法相当或更好，并且只需少量的数据和计算资源。
## 845. `cs.LG` - 无分布假设保证的合成数据统计推断 [PDF](https://arxiv.org/pdf/2509.20345), [HTML](https://arxiv.org/abs/2509.20345)
### Authors
Meshi Bashari,Yonghoon Lee,Roy Maor Lotan,Edgar Dobriban,Yaniv Romano
### Background
由于高级AI模型生成的高质量合成数据或从相关任务中收集的辅助数据的快速增长，统计推断面临着机遇和挑战。高质量的合成数据能够增强统计效能，但低质量的合成数据可能会引入偏差。现有方法在利用合成数据提升统计推断效能时，通常需要对合成数据进行严格的分布假设，这在实际应用中存在局限性。因此，需要一种能够在无分布假设下保障合成数据安全增强统计推断的新框架。
### Innovation
该论文提出了一种GEneral Synthetic-Powered Inference (GESPI) 通用合成数据驱动的统计推断框架。GESPI 将任何统计推断方法与合成数据和技术性数据结合，安全地提高样本效率。框架能够利用高质量的合成数据增强统计效能，同时保证低质量的合成数据不会导致误差超出用户规定的界限。这种灵活性使得该方法能够无缝集成到多种统计推断方法中，包括模型校准、风险控制、假设检验和多重检验。实验结果表明，该方法在有限标记数据的具有挑战性任务中表现出色，如AlphaFold蛋白质结构预测和复杂数学问题中的大规模推理模型对比。
### Conclusion
该研究提出的GEneral Synthetic-Powered Inference (GESPI)框架，在无分布假设的情况下，解决了合成数据在统计推断中的安全应用问题，提高了统计推断的效率和准确性。该方法不仅适用于蛋白质结构预测等复杂任务，也为其他需要大规模标记数据的领域提供了新的解决思路。
## 846. `cs.LG` - 深度学习与物理方法在计算波成像中的综述 [PDF](https://arxiv.org/pdf/2410.08329), [HTML](https://arxiv.org/abs/2410.08329)
### Authors
Youzuo Lin,Shihang Feng,James Theiler,Yinpeng Chen,Umberto Villa,Jing Rao,John Greenhall,Cristian Pantea,Mark A. Anastasio,Brendt Wohlberg
### Background
计算波成像（CWI）通过分析穿过多介质的波信号来提取材料内部隐藏的结构和物理属性。应用场景包括地球浅表结构的地震勘探、材料科学中的无损检测以及医学中的超声计算机断层扫描。当前方法主要分为两类：基于传统物理的方法和基于深度学习的方法。基于物理的方法具有高分辨率和定量准确度的优势，但计算密集且容易出现不定性和非凸性等问题。近年来，基于机器学习的方法开始崭露头角，为解决这些挑战提供了新的思路。多个科学领域独立探索了将深度学习集成到CWI中。本文介绍当代科学机器学习技术，特别是深度神经网络方法，如何为CWI问题的解决增强和整合传统物理方法。文章结构化地整理了跨多个领域的现有研究，包括计算成像、波动物理学和数据科学。研究结论总结了现有基于机器学习方法的经验教训，并通过系统分析这一主题广泛的文献，指出了技术障碍和新兴趋势。
### Innovation
本文提出了一种结构化的框架，整合了多个领域现有的CWI研究工作，特别是介绍了深度神经网络如何用于增强和集成基于物理的方法来解决CWI问题。这为跨学科研究提供了新的视角和方法。
### Conclusion
本文总结了基于机器学习方法的现有经验教训，指出了技术障碍，并通过系统分析wide-ranging文献，辨识出新兴趋势。
## 847. `cs.LG` - 增加批次大小可改善具有动量项的随机梯度下降的收敛性 [PDF](https://arxiv.org/pdf/2501.08883), [HTML](https://arxiv.org/abs/2501.08883)
### Authors
Keisuke Kamo,Hideaki Iiduka
### Background
在理论与实践中，随机梯度下降法（SGD）以及在其基础上加入动量项的SGDM已经被广泛研究。理论研究结果表明，学习率和动量权重的设置会影响SGDM的收敛表现。实践研究还发现批次大小的设定对SGDM的性能有显著影响。本文关注常数学习率和常数动量权重下的小批SGDM，特别是用于训练深度神经网络的情况，探讨了小批大小对训练优化的影响，并提供了相关数值结果作为支持。
### Innovation
研究中提出的主要创新点是通过理论分析证明，固定批次大小不一定能使训练深度神经网络时的经验损失的全梯度范数期望值达到最小，相反逐步增加批次大小确实可以达到这一目的；此外，数值实验结果证明，与固定批次大小相比，逐步增加批次大小能够更快地收敛到稳定点，同时降低计算成本。研究还提供小批SGDM优化器的Python实现代码支持相关的实验结果。
### Conclusion
综上所述，逐步增加批次大小可以改善SGDM在训练深度神经网络时的收敛性。数值实验证明，使用逐步增加的批次大小比固定批次大小能更快速地收敛到稳定点，同时降低计算成本。
## 848. `cs.LG` - 增强不确定性量化自编码器求解贝叶斯逆问题 [PDF](https://arxiv.org/pdf/2502.13105), [HTML](https://arxiv.org/abs/2502.13105)
### Authors
Andrea Tonini,Luca Dede'
### Background
神经网络在实时解决确定性和贝叶斯逆问题方面是一个强有力的工具，其中自编码器是一种专门类型的神经网络，可以从观测数据中估计模型参数及其分布，实现实时逆问题不确定性量化。本文基于Goh等人（2022）的研究，提出了一种新的损失函数来训练自编码器以解决贝叶斯逆问题。
### Innovation
本文提出一种新的损失函数，并提供了理论证明，证明在正线性映射情况下，自编码器的潜在状态将收敛到模型参数的后验分布。此外，通过数值测试验证了这一理论结果，并与现有方法进行了对比，在准确性和泛化性能方面都有所提高。最后，将提出的自编码器应用于拉普拉斯方程，并与原始自编码器和马尔可夫链蒙特卡洛方法进行了比较。
### Conclusion
提出了一个新的损失函数，并通过数值测试和与现有自编码器的对比，验证了其在解决贝叶斯逆问题中的有效性和泛化性能。
## 849. `cs.LG` - Bregman 发散：唯一具备无杂项偏差-方差分解的损失函数 [PDF](https://arxiv.org/pdf/2501.18581), [HTML](https://arxiv.org/abs/2501.18581)
### Authors
Tom Heskes
### Background
偏差-方差分解广泛用于理解机器学习模型的泛化性能。虽然均方误差损失可以简单分解，但其他损失函数如零一损失或$L_1$损失要么无法直接分解均方误差，要么基于缺乏实际意义偏差和方差点的定义。最近研究表明，交叉熵损失作为特殊情况可以实现更广泛的Bregman发散类中的清洁分解。然而，这些分解所需和充分条件仍然是个未解问题。
### Innovation
该论文通过研究连续非负且满足等价性原理（唯一互为零损失的两个参数相等）的损失函数，解决了偏差-方差分解的清洁条件问题。论文证明，在温和正则条件下，所谓的$g$-Bregman发散是唯一具备清洁偏差-方差分解的损失函数。$g$-Bregman发散可以通过变量变换转换为标准Bregman发散。因此，偏离度量如$0$-$1$和$L_1$损失无法实现清洁的偏差-方差分解，解释了之前尝试的失败。
### Conclusion
唯一具备清洁偏差-方差分解的损失函数是$g$-Bregman发散，这意味着平方马氏距离（经过适当的变量变换）是唯一具备清洁偏差-方差分解的对称损失函数。这揭示了为何常见的零一损失和$L_1$损失等无法拥有这种分解的本质。详细讨论了放松损失函数限制对结果的影响。
## 850. `cs.LG` - 通过梯度下降学习紧凑的规则基分类器 [PDF](https://arxiv.org/pdf/2502.01375), [HTML](https://arxiv.org/abs/2502.01375)
### Authors
Javier Fumanal-Idocin,Raquel Fernandez-Peralta,Javier Andreu-Perez
### Background
规则基模型对于高风险决策至关重要，因为它们具有透明性和可解释性。然而，规则的离散性质为优化和可扩展性带来了挑战。现有文献中，模糊逻辑规则的学习和优化方法较为受限，尤其是梯度优化方法的应用不多。本文旨在克服这些挑战，提供了一种新的基于梯度的学习规则系统，称为模糊规则基推理器（FRR），它支持严格的用户规则复杂性约束，并且在性能上可与现有模型相竞争并保持较高的可解释性。通过关注有意义的模糊逻辑划分和使用必要规则集，FRR在较小规则集的条件下达到了较好的性能。
### Innovation
本文提出了基于梯度的学习规则系统FRR，它支持严格的用户规则复杂性要求，同时达到了与传统规则基方法相当甚至更好的性能，并且使用规则集更紧凑。FRR使用语义上有意义的模糊逻辑划分，不同于现有神经模糊方法，避免了增加规则集合导致的组合复杂性。同时，FRR实现了最先进的加性规则基模型96%的准确性，而仅使用必要的规则集，并且规则集大小仅为这些模型的3%。
### Conclusion
本文展示了FRR在多个数据集上的优越性，包括优于传统规则基方法的性能，接近或达到决策树模型的准确率的同时使用更紧凑的规则集。FRR证明了它在规则基分类器学习中的有效性，通过满足用户对规则复杂性的严格要求，达到了高可解释性和高准确率的平衡。
## 851. `cs.LG` - 一种用于从通用SMARTS模板预测化学产品的变换器模型，结合数据增强 [PDF](https://arxiv.org/pdf/2503.05810), [HTML](https://arxiv.org/abs/2503.05810)
### Authors
Derin Ozer,Sylvain Lamprier,Thomas Cauchy,Nicolas Gutowski,Benoit Da Mota
### Background
在计算化学中，准确预测化学反应的结果是一项重大挑战。现有的模型依赖于高度特定的反应模板或无模板方法，这两种方法都存在局限性。为了解决这些问题，本文提出了一个包含20种通用反应模板的Broad Reaction Set (BRS)，这些模板以SMARTS的形式编写，SMARTS是一种基于模式的符号，用于描述子结构和反应性。此外，还引入了ProPreT5，基于T5的模型，经过特定适应，据我们所知，这是首个能够直接处理和应用SMARTS反应模板的语言模型。为了进一步提高泛化能力，提出了首个在模式级别注入结构多样性以增强SMARTS的策略。
### Innovation
提出了Broad Reaction Set (BRS)，包含20种通用反应模板，以SMARTS形式编写。引入了结合了数据增强的ProPreT5模型，这是首个能够直接处理和应用SMARTS反应模板的语言模型。提出了首个在模式级别注入结构多样性的SMARTS增强策略。实验表明，ProPreT5在泛化和预测性能上表现出色，为反应预测提供了新颖且实用的方法，促进了基于模板的反应预测领域的发展。
### Conclusion
这些贡献为现有的方法提供了新颖且实用的替代方案，推动了化学反应预测领域的发展。
## 852. `cs.LG` - 复杂动态系统中的异常检测：基于嵌入理论和物理启发一致性原则的系统化框架 [PDF](https://arxiv.org/pdf/2502.19307), [HTML](https://arxiv.org/abs/2502.19307)
### Authors
Michael Somma,Thomas Gallien,Branka Stojanovic
### Background
在工业和网络物理基础设施中，确保系统的可靠性和安全性以及提高效率需要对复杂动态系统的异常进行检测。预测性维护可以防止昂贵的故障，而网络安全监控在日益增长的安全威胁面前变得至关重要。许多此类系统表现出振荡行为和有界运动，因此需要能够捕捉有序时间依赖关系同时遵循物理一致性原则的异常检测方法。该项工作旨在提出一种基于系统理论的异常检测方法，该方法通过经典嵌入理论和借鉴物理原理来确保时间的一致性。评估该方法时，使用了C-MAPSS数据集的两个子集（FD001, FD003）作为涡扇发动机退化的基准数据。实验结果表明，TDC-AE在MAC操作减少了近100倍的同时，达到了与LSTMs相当的性能，优于Transformers，特别适用于轻量级边缘计算。研究表明，异常会破坏系统的稳定动态，提供了一个强大的异常信号。
### Innovation
该研究提出了一种基于嵌入理论和物理启发一致性原则的系统化框架，特别设计用于复杂动态系统的异常检测。通过引入状态-导数对作为嵌入策略，以及开发了一个名为Temporally Differential Consistency Autoencoder (TDC-AE) 的模型，该模型有一致性的损失（TDC-Loss）可以确保隐变量导数与动态表示的一致性。这种方法不仅能够捕捉系统演化，还能够在保持时间一致性的同时有效减少计算量。评价结果显示，该方法在轻量级边缘计算环境中表现优越。
### Conclusion
异常扰乱稳定系统动态，为异常检测提供了一个强大信号。TDC-AE相较于LSTMs和Transformers在减少计算量的同时能够保持甚至超越其性能，特别适用于需要高效执行的场景。
## 853. `cs.LG` - 通用AI框架结合显式时间积分用于长期流体动力学预测 [PDF](https://arxiv.org/pdf/2412.05657), [HTML](https://arxiv.org/abs/2412.05657)
### Authors
Sunwoong Yang,Ricardo Vinuesa,Namwoo Kang
### Background
在科学机器学习模型中，时空自回归（AR）预测中的误差累积是一个关键挑战。为了应对这一挑战，该研究探讨了时间积分方案和自适应多步展开策略。通过对经典2D偏微分方程（PDEs）的系统评估，以及复杂牛顿-斯托克斯漩涡脱落动力学的拓展，研究使用了两步Adams-Bashforth方法，结合历史导数信息来增强数值稳定性。此外，研究还开发了三种新的自适应加权策略，以便在多步展开训练中动态调整不同未来时间步的相对重要性。随着物理复杂性的增加，复杂的展开技术变得至关重要，而Adams-Bashforth方案在所研究的系统中表现出一致的鲁棒性，而最佳的自适应方法在计算成本相似的情况下，比传统的固定权重方法提高了89%的表现。在复杂牛顿-斯托克斯漩涡脱落问题上，仅使用带1,177个训练参数的轻量级图神经网络，通过仅50个快照进行训练，该框架准确预测了350个未来时间步，将均方误差从0.125（直接单步预测）降低到0.002（结合提出多步展开的Adams-Bashforth）.
### Innovation
首次实现两步Adams-Bashforth方法，特制用于数据驱动的AR预测，利用历史导数信息增强数值稳定性，同时减少额外的计算负担。开发了三种全新的自适应加权策略，在多步展开培训中动态调整未来时间步的重要性。对于复杂的牛顿-斯托克斯漩涡脱落问题，采用了轻量级图神经网络，通过少量快照训练，能够有效预测未来时间步，同时保持计算成本相似，提升了预测精度。并且，研究方法展示了在有限空间域训练下，仍能显著改善直接预测和前进欧拉方法的表现，具体表现为58%和27%的改进；
### Conclusion
结合了通用的AI框架和显式时间积分的方法大大提升了长期流体动力学预测的鲁棒性和准确性。特别是在物理模型复杂度增加的情况下，这种方法变得尤为关键，展示了在计算效率和预测精度上的显著优势。
## 854. `cs.LG` - DP-LET：一种高效的时空网络流量预测框架 [PDF](https://arxiv.org/pdf/2504.03792), [HTML](https://arxiv.org/abs/2504.03792)
### Authors
Xintong Wang,Haihan Nan,Ruidong Li,Huaming Wu
### Background
准确预测时空网络流量对于现代通信系统中动态管理和最小化能耗的计算资源至关重要。尽管已经对时空流量预测给予了广泛研究，但在提高预测精度和计算效率方面仍有改进空间。现有分解方法或混合架构在捕捉局部和全局特征关联时往往会产生较大的计算开销，因此需要新颖的方法来优化准确性和复杂性。
### Innovation
本文提出了一种高效的时空网络流量预测框架DP-LET，它包括数据处理模块、局部特征增强模块和基于Transformer的预测模块。该框架通过高效率的网络数据去噪和空间解耦优化数据处理，利用多个TCN来捕捉细粒度局部特征，并使用Transformer编码器建模长期依赖性和评估特征的相关性。
### Conclusion
在实际蜂窝流量预测案例中，DP-LET展示了其实用性，同时保持低计算复杂性，实现了业界领先的性能，MSE降低了31.8%，MAE降低了23.1%的基准模型。
## 855. `cs.LG` - LEMUR 神经网络数据集: 向无缝自动化机器学习迈进 [PDF](https://arxiv.org/pdf/2504.10552), [HTML](https://arxiv.org/abs/2504.10552)
### Authors
Arash Torabi Goodarzi,Roman Kochnev,Waleed Khalid,Hojjat Torabi Goudarzi,Furui Qin,Tolgay Atinc Uzun,Yashkumar Sanjaybhai Dhameliya,Yash Kanubhai Kathiriya,Zofia Antonina Bentyn,Dmitry Ignatov,Radu Timofte
### Background
神经网络是现代人工智能的核心，但设计、评估和比较它们仍然是劳动密集型的工作。尽管存在许多用于训练的数据集，但对于模型本身的标准集合却很少。LEMUR 是一个开源数据集和框架，它为分类、分割、检测和自然语言处理等任务提供了大量的基于 PyTorch 的神经网络。每一模型遵循统一的模板，并将配置和结果存储在一个结构化的数据库中，以确保一致性和可复现性。
### Innovation
LEMUR 集成了通过 Optuna 实现的自动化超参数优化，包含了统计分析和可视化工具，并提供了 API 以无缝访问性能数据。该框架具有可扩展性，允许研究人员在不破坏兼容性的情况下添加新的模型、数据集或指标。通过标准化实现和统一评估，LEMUR 旨在加速自动化机器学习的研究，实现公平基准测试，并降低大规模神经网络实验的障碍。
### Conclusion
通过标准化实现和完善评估，LEMUR 目标在于加速自动机器学习研究，支持公平基准测试，降低大规模神经网络实验的门槛。它在 MIT 许可证下发布，支持采用和协作，可以在如下位置访问：this https URL 这些 URL
## 856. `cs.LG` - Kalman Filter Enhanced GRPO for Reinforcement Learning-Based Language Model Reasoning [PDF](https://arxiv.org/pdf/2505.07527), [HTML](https://arxiv.org/abs/2505.07527)
### Authors
Hu Wang,Congbo Ma,Ian Reid,Mohammad Yaqub
### Background
优势函数是强化学习（RL）中的一个核心概念，有助于降低策略梯度估计中的方差。最近，为了语言建模，提出了Group Relative Policy Optimization (GRPO) 方法，通过从组内所有输出的平均奖励作为基线来计算每个输出的优势。然而，当奖励优势的预测不准确时，这种方法会导致方差高。
### Innovation
本文提出了Kalman Filter Enhanced Group Relative Policy Optimization (KRPO) 模型，通过采用轻量级的卡尔曼滤波动态估计潜在的奖励基线和不确定性，从而替代了基础的组内均值，以实现更加灵活的优势标准化。这种方法不需要额外的已学习参数，能够将GRPO模型的多个输出更有效地整合到优势估计中，改善基于奖励信号高度动态的语言模型的策略优化。
### Conclusion
通过数学问题回答和推理的准确性和奖励，我们证明使用更灵活的优势估计模型（KRPO），能够提高GRPO的稳定性和性能。该方法提供了一种简单且有效的将多个GRPO输出整合到优势估计中的方式，特别适用于难以建模动态奖励信号的场景。代码可从该网址获取：this https URL。
## 857. `cs.LG` - 基于扩散分类器的离线偏好强化学习奖励 [PDF](https://arxiv.org/pdf/2503.01143), [HTML](https://arxiv.org/abs/2503.01143)
### Authors
Teng Pang,Bingzheng Wang,Guoqiang Wu,Yilong Yin
### Background
离线偏好基于学习（PbRL）方法通过偏好驱动的奖励反馈实现与人类偏好一致，而不必直接定义奖励，从而简化了强化学习过程。然而，传统的基于轨迹的偏好标签难以精确捕捉步骤级别的奖励，从而影响下游算法的性能。为了解决基于轨迹的偏好标签带来的步骤级别奖励不足的问题，本文提出了一种新的偏好驱动奖励获取方法：扩散偏好奖励（DPR）。DPR将步骤级别偏好驱动奖励获取视为二元分类问题，利用扩散分类器的鲁棒性进行区分性奖励推断。此外，为了进一步利用基于轨迹的偏好信息，本文还提出了一种条件扩散偏好奖励（C-DPR）方法，该方法会结合基于轨迹的偏好标签信息来增强奖励推断能力。在现有的离线强化学习算法中应用了上述方法，并通过一系列实验结果表明，基于扩散分类器的奖励在性能上优于之前使用Bradley-Terry模型的奖励获取方法。
### Innovation
1. 提出了一种新的偏好驱动奖励获取方法：扩散偏好奖励（DPR），将步骤级别偏好驱动奖励获取视为二元分类问题，利用扩散分类器的鲁棒性进行区分性奖励推断。2. 为了进一步利用基于轨迹的偏好信息，提出了一种条件扩散偏好奖励（C-DPR）方法，该方法会结合基于轨迹的偏好标签信息来增强奖励推断能力。3. 通过应用上述方法于现有的离线强化学习算法，实验结果表明基于扩散分类器的奖励相较于先前使用Bradley-Terry模型的奖励获取方法在性能上有显著提升。
### Conclusion
本文提出了一种基于扩散分类器的偏好驱动奖励获取方法(DPR)及其改进版本C-DPR，该方法通过将步骤级别偏好驱动奖励获取视为二元分类问题，并结合扩散分类器的鲁棒性，有效解决了基于轨迹的偏好标签带来的步骤级别奖励不足的问题。实验结果显示，基于扩散分类器的奖励推断方法在离线偏好强化学习中表现出了更好的性能。
## 858. `cs.LG` - 使用对称自编码器进行3D Rayleigh-Bénard 对流的代理建模 [PDF](https://arxiv.org/pdf/2505.13569), [HTML](https://arxiv.org/abs/2505.13569)
### Authors
Fynn Fromme,Hans Harder,Christine Allen-Blanchette,Sebastian Peitz
### Background
使用机器学习对大尺度物理系统进行建模、理解和控制越来越受到青睐，涵盖范围广泛，从电磁学、核聚变反应堆和磁流体动力学到流体力学和气候建模。这些系统受到偏微分方程的调控，具有大量自由度和复杂时空尺度的动力学，因此提高建模准确性和样本效率是高需求。
### Innovation
本文提出了一种端到端的对称代理模型，结合了对称卷积自编码器和对称卷积LSTM，使用$G$-可定向核。特别是在对流体的三维Rayleigh-Bénard系统中应用，该系统在水平面上是E(2)-对称的，但在垂直边界条件下破换了平移对称性。架构利用垂直堆叠的$D_4$-可定向核层，并在垂直方向上添加部分核共享以提高效率。这一模型在样本效率、参数效率以及更复杂动力学的处理上展现出显著优势。
### Conclusion
研究结果表明，所提出的角对抗自编码器架构在样本效率、参数效率和复杂动力学处理方面取得了显著改进。相关代码可以在该链接访问。
## 859. `cs.LG` - Localized LoRA: 一种高效的结构化低秩近似方法以实现高效的微调 [PDF](https://arxiv.org/pdf/2506.00236), [HTML](https://arxiv.org/abs/2506.00236)
### Authors
Babak Barazandeh,Subhabrata Majumdar,Om Rajyaguru,George Michailidis
### Background
PEFT方法，如LoRA，通过在预训练权重中引入低秩更新来提供紧凑且有效的全模型微调替代方案。然而，大多数现有方法依赖于全局低秩结构，这可能会忽略参数空间中广泛分布的空间模式。
### Innovation
提出了Localized LoRA框架，该框架将权重更新建模为作用于权重矩阵结构块上的一系列低秩矩阵的组合。这种建模方式可以在不增加可训练参数总数的情况下进行密集且局部化的更新。同时，本文对全局、近似局部和完全局部低秩逼近进行了正式比较，展示了在匹配参数预算条件下，该方法具有更低的逼近误差。
### Conclusion
实验结果表明，Localized LoRA在合成和实际设置中提供了更具表达性和适应性的替代方案，能够以提高性能的方式进行高效的微调。
## 860. `cs.LG` - AAPO: 使用优势动量提升大语言模型的推理能力 [PDF](https://arxiv.org/pdf/2505.14264), [HTML](https://arxiv.org/abs/2505.14264)
### Authors
Jian Xiong,Jingbo Zhou,Jingyong Ye,Qiang Huang,Dejing Dou
### Background
强化学习（RL）已成为提高大语言模型（LLMs）推理能力的有效方法，尤其是在监督微调（SFT）由于链式思维（CoT）数据有限而无法发挥作用的情况下。在基于RL的后训练方法中，如Group Relative Policy Optimization (GRPO)，通过团体相对优势估计来去除对价值模型的依赖性，简化了与传统方法如Proximal Policy Optimization (PPO)相比的训练过程。然而，现有的方法仍然存在训练效率低下问题，尤其是在估计的优势接近零时更为明显。这些训练效率低下问题限制了团体相对优势估计的应用效果。
### Innovation
提出了一种新的RL算法——优势增强策略优化（AAPO），通过动量基估计方案增强优势，优化交叉熵（CE）损失，从而有效缓解团体相对优势估计的效率问题，提升了其应用效果。实验结果显示，AAPO在多个数学推理基准测试中的表现更优。
### Conclusion
在多个数学推理基准测试中验证了AAPO算法的有效性和优越性，表明其能够有效提高LLMs的推理能力，降低训练效率低下问题，尤其是当估计的优势接近零时的优势发挥更为显著。
## 861. `cs.LG` - Urania：AI使用中的差异化隐私见解 [PDF](https://arxiv.org/pdf/2506.04681), [HTML](https://arxiv.org/abs/2506.04681)
### Authors
Daogao Liu,Edith Cohen,Badih Ghazi,Peter Kairouz,Pritish Kamath,Alexander Knop,Ravi Kumar,Pasin Manurangsi,Adam Sealfon,Da Yu,Chiyuan Zhang
### Background
现有的框架通常不能在保证用户隐私的情况下生成关于大语言模型（LLM）聊天机器人交互的见解。提供严格的差异化隐私（DP）保证的新型框架Urania填补了这一空白，通过采用私人聚类方法和创新的关键词提取方法，增强了用户隐私保护能力。
### Innovation
Urania框架创新性地结合了频率、TF-IDF以及LLM引导的关键词提取方法，同时利用差异化隐私工具如聚类、分区选择和直方图汇总，提供端到端的隐私保护。通过评估词汇和语义内容保留、配对相似性和基于LLM的指标，Urania与未使用隐私保护的基线（Clio启发的Pipeline）进行对比，展示了其在保护用户隐私的同时提取有价值对话见解的能力。
### Conclusion
Urania框架成功实现了在保持严格用户隐私的同时提取有意义的对话见解，有效地平衡了数据的实用性和隐私保护。实验证明了其在隐私保护方面的强大稳健性，并展示了其在实际应用中的潜力。
## 862. `cs.LG` - 工具使用代理的程序化环境生成 [PDF](https://arxiv.org/pdf/2506.11045), [HTML](https://arxiv.org/abs/2506.11045)
### Authors
Michael Sullivan,Mareike Hartmann,Alexander Koller
### Background
尽管大语言模型工具使用代理的力量激发了这一领域近期的研究热潮，但在线强化学习（RL）训练的工具使用数据的整理仍然存在公开的问题。现有的合成工具使用数据生成方法通常是非互动的，或者不具备组合性。
### Innovation
本文提出了一种名为RandomWorld的流水线，用于程序化生成互动工具和组合性的工具使用数据。实验证明，通过自我对话fine-tuning（SFT）和RL方法在合成RandomWorld数据上训练的模型在多种工具使用基准测试中表现优异，并且在NESTFUL数据集上取得了两项最新SOTA结果。此外，实验表明，随着RandomWorld生成的培训数据量的增加，效果也会提升，为使用完全合成数据进一步提高性能提供了可能。
### Conclusion
通过RandomWorld生成的培训数据量影响下游性能，为完全合成数据的使用带来了提高性能的可能性。
## 863. `cs.LG` - 为什么某些输入会使低比特LLM量化失效？ [PDF](https://arxiv.org/pdf/2506.12044), [HTML](https://arxiv.org/abs/2506.12044)
### Authors
Ting-Yun Chang,Muru Zhang,Jesse Thomason,Robin Jia
### Background
低比特权重量化极大地减少了大型语言模型（LLMs）的内存占用，但在某些示例中导致性能显著下降。作者分析了从7B到70B不等的多种3-4比特方法，发现这些方法在FineWeb示例中的量化误差高度相关，且全精度模型的残差流幅度可能预示未来量化误差的大小。
### Innovation
研究发现，残差流的幅度与误差放大和累积有关。通过LLM定位技术、早期退出和激活补丁，研究揭示了哪些输入导致大量化误差及哪些模型组件对性能保护至关重要。
### Conclusion
研究揭示了导致某些示例量化误差较大的原因，并指出了哪些模型组件对于保持性能最为关键。
## 864. `cs.LG` - EC-LDA：压缩嵌入对抗联邦图学习的标签分布推理攻击 [PDF](https://arxiv.org/pdf/2505.15140), [HTML](https://arxiv.org/abs/2505.15140)
### Authors
Tong Cheng,Jie Fu,Xinpeng Ling,Huifa Li,Zhili Chen,Haifeng Qian,Junqing Gong
### Background
图形神经网络（GNNs）广泛应用于图分析。联邦图学习（FGL）是一种新兴的学习框架，旨在从多个客户端协作训练图数据。尽管FGL允许客户端数据保持本地化，但恶意服务器仍可能通过上传的梯度来窃取客户端的私有数据信息。已有研究中尚未提出针对FGL的标签分布攻击（LDAs），并且现有的LDAs在攻击效果上不够理想。文章提出了一种新的对抗性攻击——嵌入压缩标签分布攻击（EC-LDA）。EC-LDA通过压缩节点嵌入可以显著提升攻击的有效性，证实了节点嵌入的方差对LDA有效性的影响。EC-LDA在节点分类和链接预测任务上表现出色，在六个广泛使用的图数据集上的实验结果表明EC-LDA优于现有的SOTA LDAs，具体而言，EC-LDA能够在几乎所有情况下实现cos-sim为1.0。作者还探索了EC-LDA在差分隐私保护下的鲁棒性，并讨论了对抗EC-LDA的有效防御方法。相关代码公开在指定网址。
### Innovation
1. 提出了嵌入压缩标签分布攻击（EC-LDA）;2. 通过压缩节点嵌入显著提升了标签分布攻击的效果;3. 在多个节点分类和链接预测任务上验证了EC-LDA的优越性能，具体在所有实验情况下可以实现cos-sim值为1.0;4. 探索了EC-LDA在差分隐私保护下的鲁棒性，并讨论了潜在的有效防御方法。
### Conclusion
EC-LDA在节点分类和链接预测任务上显著提升了标签分布攻击的效果，能够在多个广泛使用的图数据集上实现高cos-sim值，并且在差分隐私保护环境下同样有效。未来的研究可以基于EC-LDA探索更有效的防御措施。
## 865. `cs.LG` - MAME: 通过人类知觉反馈进行多维自适应同视异构体探索 [PDF](https://arxiv.org/pdf/2503.13212), [HTML](https://arxiv.org/abs/2503.13212)
### Authors
Mina Kamao,Hayato Ono,Ayumu Yamashita,Kaoru Amano,Masataka Sawayama
### Background
人类大脑网络与人工模型的对齐已成为视觉科学和机器学习领域的活跃研究领域。传统方法通过识别“同视异构体”——在系统内物理上不同但在感知上等效的刺激——进行研究。然而，以前的方法缺乏直接探索人类同视异构体空间的方法。通常的做法是首先开发受生物学启发的模型，然后通过检测模型中的同视异构体是否也对人类来说是等效的来间接推断人类的同视异构体。为了解决这一问题，研究人员提出了一种新的方法——多维自适应同视异构体探索（MAME）框架。
### Innovation
MAME框架通过实时图像生成和基于人类感知反馈的引导，直接探索人类的高维同视异构体空间。该框架利用层次神经网络响应对参考图像在多个维度进行调制，并根据参与者对感知区别的感知调整生成参数。研究通过MAME框架成功测量了人类的多维同视异构体空间，并发现人类对于基于低级特征的同视异构体在区分敏感性方面表现较弱，这一发现无法用图像对比度指标来解释。由此表明，人类和基于生物的CNN模型在低级处理的同视异构体空间上的对齐程度较差，而高级处理上则较好。这项结果强调了早期视觉计算在塑造生物启发模型中的重要性。
### Conclusion
MAME框架为直接研究人类视觉的功能组织提供了一种未来科学工具，揭示了尽管在较高表示层次的对齐问题上存在争议，早期视觉计算的重要性被进一步凸显。该研究提供了关于人类视觉系统与生物启发模型之间的关系的新见解，并展示了MAME框架在探索人类感知领域的潜力。
## 866. `cs.LG` - 量子-经典混合量化神经网络 [PDF](https://arxiv.org/pdf/2506.18240), [HTML](https://arxiv.org/abs/2506.18240)
### Authors
Wenxin Li,Chuan Wang,Hongdong Zhu,Qi Gao,Yin Ma,Hai Wei,Kai Wen
### Background
本文提出了一种基于二次二元优化（QBO）模型的新颖量化神经网络训练方法，通过样条插值支持任意激活和损失函数。为了解决非线性和多层复合结构带来的挑战，提出了前向区间传播（FIP）方法，通过分段线性化激活函数，保留了神经网络的普遍逼近能力，同时允许使用量子计算优化复杂的非线性函数，从而扩大了其在人工智能中的应用范围。从优化的角度出发，通过确定经验风险最小化问题的样本复杂性，提供了逼近误差和所需的Ising自旋数的理论上限。
### Innovation
1. 引入FIP方法，通过分段线性化激活函数，解决了神经网络中的非线性和多层结构的挑战。2. 提出了量子条件梯度下降（QCGD）算法，利用量子计算直接解决定量约束二元优化（QCBO）问题。QCGD算法在量子或acle具备随机性和有限方差的情况下收敛，并在系数矩阵的有限精度约束下收敛。3. 提供了解决QCBO问题所需时间的上限，并提出了一种基于单样本二进制缩放优化的训练算法。
### Conclusion
本文提出了一种基于QBO模型的量化神经网络训练方法，通过FIP和QCGD算法解决了量化神经网络训练中的非线性、多层结构和大量约束问题，提升了在人工智能领域的应用潜力。进一步提出的单样本二进制缩放优化训练算法展现出前景，未来的研究将集中于进一步提高方法的性能和实用性。
## 867. `cs.LG` - CellCLIP——利用文本导向对比学习学习细胞染色效果 [PDF](https://arxiv.org/pdf/2506.06290), [HTML](https://arxiv.org/abs/2506.06290)
### Authors
Mingyu Lu,Ethan Weinberger,Chanwoo Kim,Su-In Lee
### Background
高内容筛选（HCS）实验通过高通量显微成像技术（如细胞染色）能够以前所未有的规模研究细胞对扰动的形态学响应。这种数据采集有助于更好地理解不同扰动与细胞状态变化之间的关系。为了实现这一目标，最近在跨模态对比学习方面的进展理论上可以被用来学习一个统一的潜在空间，将扰动与它们相应的形态学效应对齐。然而，将这种方法应用于HCS数据并不直接，因为细胞染色图像与自然图像在语义上有很大不同，且很难在一个潜在空间中表示不同类型的扰动（如小分子与CRISPR基因敲除）。
### Innovation
CellCLIP 是一种跨模态对比学习框架，它通过使用预训练的图像编码器和新的通道编码方案更好地捕捉图像嵌入中不同显微镜通道之间的关系，并结合自然语言编码器来表示扰动，从而解决了上述挑战。CellCLIP 的性能超越了当前开源模型，在跨模态检索和具有生物意义的下游任务中表现出最佳性能，同时还实现了显著的计算时间减少。
### Conclusion
CellCLIP 在跨模态对比学习框架下，成功地将不同类型的扰动与细胞染色的形态学效应对齐，实现了最佳的跨模态检索性能和生物意义下游任务的性能，并且大幅减少了计算时间。这一创新方法为理解和研究细胞在不同扰动下的反应提供了有力支持。
## 868. `cs.LG` - 超越简单图：学习多目标多图路径规划 [PDF](https://arxiv.org/pdf/2506.22095), [HTML](https://arxiv.org/abs/2506.22095)
### Authors
Filip Rydin,Attila Lischka,Jiaming Wu,Morteza Haghir Chehreghani,Balázs Kulcsár
### Background
近年来，基于学习的方法在单目标和多目标路径规划中得到了广泛关注。但现有的方法不适用于多图路径规划，多图包含节点对之间具有不同属性的多条边，这种特性在实际场景中有很强的相关性。现有的方法难以处理这种情况的复杂性问题。
### Innovation
本文提出了两种基于图神经网络的方法来解决多图的多目标路径规划问题。第一种方法直接在多图上通过自回归选择边直到完成游览。第二种方法首先通过学习策略简化多图，然后再在结果的简单图上进行自回归路径规划。这两种方法在一系列问题和图分布中进行了实验评估，证明了它们在与强启发式方法和神经基础模型的竞争中的表现良好。
### Conclusion
本文提出了两种基于图神经网络的方法来解决多图上的多目标路径规划问题，并通过实验验证了这些方法的有效性和竞争力。
## 869. `cs.LG` - DuoGPT：通过感知激活的剪枝实现LLMs中的双重稀疏性 [PDF](https://arxiv.org/pdf/2506.20194), [HTML](https://arxiv.org/abs/2506.20194)
### Authors
Ruokai Yin,Yuhang Li,Donghyun Lee,Priyadarshini Panda
### Background
大语言模型（LLMs）虽然表现出色，但由于高内存和计算成本难以部署。虽然剪枝可以降低这些需求，但大多数方法忽略了运行时观察到的激活稀疏性。本文回顾了剪枝技术的发展，特别是在考虑激活稀疏性以更有效地降低计算和内存成本方面的不足。
### Innovation
本文重新解释了激活稀疏性为动态结构化权重稀疏性，并提出了DuoGPT，一种结合非结构化权重剪枝和激活稀疏性的统一框架，创建了双重稀疏的工作负载。此外，它还扩展了Optimal Brain Compression (OBC)框架，加入激活感知校准，并引入了稠密模型的输出残差作为校正项。同时，为了提高GPU执行效率，优化了解决方案，使得方法适用于十亿参数级别的LLM。实验结果表明，在与基线稠密模型等速效的情况下，DuoGPT的准确率可提高至高达9.17%。
### Conclusion
DuoGPT在LLM中实现了双重稀疏，结合了非结构化权重剪枝和激活稀疏性，通过激活感知校准优化了模型，提高了计算效率和模型性能。实验结果显示，与其他结构化剪枝方法相比，DuoGPT在准确性和效率方面表现更优。
## 870. `cs.LG` - 逐步引导策略优化：在GRPO中给你的错误推理上色 [PDF](https://arxiv.org/pdf/2505.11595), [HTML](https://arxiv.org/abs/2505.11595)
### Authors
Peter Chen,Xiaopeng Li,Ziniu Li,Xi Chen,Tianyi Lin
### Background
强化学习（RL）已被证明能够增强大型语言模型（LLMs）的推理能力。广泛使用的方法Group Relative Policy Optimization (GRPO) 在训练DeepSeek-R1中取得了显著的实验效果。然而，GRPO存在一个局限性，即在所有组内响应都错误的情况下无法更新策略（即“全负面样本”组）。这意味着，与人类可以从中学习错误的方法不同，GRPO会忽略这些信号，这揭示了人工智能与人类智能之间的关键差异。
### Innovation
本文提出了一种简单的框架，通过在组内引入响应多样性的方式来缓解“全负面样本”问题。该方法采用了一种逐步裁判模型，既可以独立训练，也可以从现有LLMs中改编而来。我们证明了这一多样化可以在简化环境中加速GRPO的动态学习。此外，我们还通过实验验证了逐步引导策略优化（SGPO）方法的有效性，该方法在7B, 14B, 32B等模型规模的离线和在线培训中，以及9个基准测试中表现出一致的改进。SGPO有两个优势：首先，它在早期和中期训练阶段能超越GRPO，而这些阶段经常出现全负面样本组；其次，SGPO不需要裁判模型生成正确答案，这使其区别于知识蒸馏方法。
### Conclusion
SGPO在大小不同的模型（7B, 14B, 32B）上显示出了一致的性能提升，在离线和在线训练中，特别是在早期和中期训练阶段，超越了GRPO。此外，SGPO不需要裁判模型生成正确答案，这设定其与知识蒸馏方法的差异化路径。
## 871. `cs.LG` - 结构即搜索: 无监督排列学习在组合优化中的应用 [PDF](https://arxiv.org/pdf/2507.04164), [HTML](https://arxiv.org/abs/2507.04164)
### Authors
Yimeng Min,Carla P. Gomes
### Background
在旅行商问题(Traveling Salesman Problem, TSP)中，传统的自回归方法依赖于逐步构建解决方案的过程，这导致在寻找最优解时效率低下。因此，需要更有效的非自回归框架来直接从学习到的排列中生成解决方案，而不需要显式的搜索过程。
### Innovation
本文提出了一种非自回归框架，通过应用相似性变换来近似哈密顿回路，模型能够直接从连续松弛中学习排列矩阵。主要创新点在于，通过无监督的方法，在不需要显式搜索的情况下，也能达到与经典启发式方法相媲美的性能。这表明问题的内在结构可以指导组合优化，而不必依赖于顺序决策过程。
### Conclusion
神经网络可以直接捕获和利用组合结构提供了确凿的证据。这种方法为直接通过学习得到解决方案提供了可能性，从而推动了组合优化问题的无监督学习研究。
## 872. `cs.LG` - FedOne: Query-Efficient Federated Learning for Black-box Discrete Prompt Learning [PDF](https://arxiv.org/pdf/2506.14929), [HTML](https://arxiv.org/abs/2506.14929)
### Authors
Ganyu Wang,Jinjie Fang,Maxwell J. Yin,Bin Gu,Xi Chen,Boyu Wang,Yi Chang,Charles Ling
### Background
Black-Box Discrete Prompt Learning（BDPL）是一种无需访问模型参数或梯度的提示调整方法，使得在基于云的大型语言模型（LLM）上进行提示调优成为可能。先前对联邦黑盒提示调优的研究忽视了与基于云的LLM服务相关的重要查询成本。因此，作者尝试在这种背景下对查询效率进行了理论分析。
### Innovation
作者提出了一种名为FedOne的框架，该框架是一种针对基于云的LLM的联邦黑盒离散提示学习方法。FedOne通过降低FedAvg策略，每轮只激活一个客户端，从而优化查询效率。实验结果显示，该方法在查询效率上取得了显著改进，与理论分析结果一致。
### Conclusion
通过FedOne框架，当与基于云的LLM交互时，联邦黑盒离散提示学习的查询效率得到了最大化。
## 873. `cs.LG` - 使用深度生成模型的多模态大气超分辨率 [PDF](https://arxiv.org/pdf/2506.22780), [HTML](https://arxiv.org/abs/2506.22780)
### Authors
Dibyajyoti Chakraborty,Haiwen Guan,Jason Stock,Troy Arcomano,Guido Cervone,Romit Maulik
### Background
分数驱动的扩散建模是一种生成机器学习算法，能够从复杂的分布中采样。通过学习分数函数进行逆噪处理，这种方法能够生成新的样本，并且生成样本时可以即时条件化于观测数据。该算法能够为数据和模型融合提供一种新范式，预训练的分数驱动扩散模型隐式学习的分布可依据实时数据进行贝叶斯更新。本文将这种概念应用于特定的高维动力系统超分辨率任务中，如通过从多模态数据中获取实时低分辨率及实验观测的稀疏传感器数据，来实现高分辨率大气ERA5数据集的生成。除了生成稀疏观测的高维状态外，还通过分数驱动采样进行了不确定性估计分析。这些实验利用低保真度的多数据源观测信息来重建高维状态，展示了生成模型在时空重建过程中不同数据模式影响的平衡作用。
### Innovation
将分数驱动的扩散建模引入高维动力系统的超分辨率领域，并利用多模态数据中的实时低分辨率观测资料和未结构化的IGRA温压计实验观测资料进行大气ERA5数据集的重建，首次在生成模型中展示了跨模态数据影响的动态平衡。此外，研究还提供了一种利用生成模型进行不确定性估计的新方法。
### Conclusion
通过分数驱动方法和多模态数据的应用，能够从低保真度观测中准确恢复高维大气状态。实验结果表明，该生成模型可以根据不同观测来源的有效性自动调整权重，从而改善时空动态重建的质量。这种方法为处理大型复杂数据集提供了一种有效的新途径，具有广泛的应用前景。
## 874. `cs.LG` - LoSiA: 通过子网定位与优化实现高效高阶微调 [PDF](https://arxiv.org/pdf/2507.04487), [HTML](https://arxiv.org/abs/2507.04487)
### Authors
Xujia Wang,Yunjia Qi,Bin Xu
### Background
现有的参数高效微调（Parameter-Efficient Fine-Tuning, PEFT）方法，如LoRA，通过引入低秩分解矩阵显著减少了训练参数的数量。然而，这些方法在领域专业化任务中进行大规模矩阵乘法，导致计算效率低下和微调性能不理想。
### Innovation
提出了一种创新的方法LoSiA（Low-Resources Subnet Integration Adaptation），能够动态定位并优化训练过程中关键参数。LoSiA 使用梯度稀疏性分析识别一个子网络，并对其进行优化作为可训练目标。该设计仅通过更新子网络参数实现有效的高阶适应，减少了额外的矩阵乘法。此外，还提出了LoSiA-Pro，相比LoRA减少了约27%的训练延迟。
### Conclusion
广泛的评估显示，LoSiA 方法在领域专业化任务和常识推理任务中实现了最小的性能下降，同时具有最少的训练时间。进一步的分析表明，LoSiA 也能减少持续训练过程中的遗忘现象。源代码可在此处获取。
## 875. `cs.LG` - GradNetOT: 使用GradNets学习最优传输映射 [PDF](https://arxiv.org/pdf/2507.13191), [HTML](https://arxiv.org/abs/2507.13191)
### Authors
Shreyas Chaudhari,Srinivasa Pranav,José M. F. Moura
### Background
最优传输（OT）问题是现代应用中的一个核心问题，例如流体动力学和机器人群体控制。蒙日形式的OT问题与蒙日-安培方程相关，当运输成本为欧几里得平方距离时，Brenier定理确保最优传输映射是凸函数的梯度且是单调梯度映射。已有研究提出使用Monotone Gradient Networks（mGradNets）来直接参数化单调梯度映射的空间并在训练中直接学习最优传输映射。
### Innovation
本文利用mGradNets直接学习最优传输映射，通过最小化使用蒙日-安培方程定义的训练损失函数实现。实验表明，mGradNets的结构偏差有助于解决图像变形任务和高维OT问题中的最优传输映射学习。
### Conclusion
本文展示了利用GradNets学习最优传输映射的方法，并证明了这种方法在不同任务中的有效性。
## 876. `cs.LG` - Assay2Mol：基于生物测定学上下文的大规模语言模型药物设计 [PDF](https://arxiv.org/pdf/2507.12574), [HTML](https://arxiv.org/abs/2507.12574)
### Authors
Yifan Deng,Spencer S. Ericksen,Anthony Gitter
### Background
科学数据库聚集了大量的定量数据和描述性文本。在生物化学领域，分子筛选实验评估候选分子对疾病靶点的功能响应。描述生物机制、实验筛选协议及其他实验属性的非结构化文本提供了丰富的药物发现信息，但由于其非结构化的格式而未被充分利用。Assay2Mol通过利用现有的大量生物化学筛查实验为早期药物发现提供支持。
### Innovation
Assay2Mol是一种基于大规模语言模型的工作流，可以从非结构化的实验记录中提取相关信息，并利用这些信息生成候选分子。与近期生成目标蛋白结构候选配体分子的机器学习方法相比，Assay2Mol表现出更优的效果，同时还能促进生成更易于合成的分子。
### Conclusion
Assay2Mol能够有效利用大规模语言模型进行早期药物筛选，通过检索与新目标相似的实验记录并结合上下文学习生成候选分子。这种方法显著提高了药物发现的效率和候选分子的合成可用性。
## 877. `cs.LG` - FedRAIN-Lite：提高理想化数值天气和气候模型的联邦强化学习算法 [PDF](https://arxiv.org/pdf/2508.14315), [HTML](https://arxiv.org/abs/2508.14315)
### Authors
Pritthijit Nath,Sebastian Schemm,Henry Moss,Peter Haynes,Emily Shuckburgh,Mark Webb
### Background
长期以来，气候模型中的次网格参数化是静态且离线调整的，限制了对演变状态的适应性。本文通过使用联邦强化学习（FedRL）方法填补这一空白，引入了FedRAIN-Lite框架，利用经纬度分区分配代理，实现了局部参数学习和周期性全球聚合，类似于通用循环模型（GCMs）的空间分解。
### Innovation
提出了FedRAIN-Lite框架，通过联邦强化学习实现局部参数学习和周期性全球聚合，用于次网格参数化改进。该框架使用多个简化能量平衡气候模型（从单一代理基线到多代理集合，再到类似GCM的设置）进行基准测试，证明了Deep Deterministic Policy Gradient (DDPG) 在收敛速度和低纬度和中纬度区域的区域加权RMSE方面优于静态和单代理基线。
### Conclusion
DDPG 的优势在于其参数和较低的计算成本，适合地理适应性参数学习。这种能力为高级复杂性的GCMs提供了一种可扩展的路径，并提供了与气候变化同步演化的、基于物理对齐的在线学习气候模型的原型。
## 878. `cs.LG` - FORGE: 从图形嵌入获得的基础优化表示 [PDF](https://arxiv.org/pdf/2508.20330), [HTML](https://arxiv.org/abs/2508.20330)
### Authors
Zohair Shafi,Serdar Kadioglu
### Background
组合优化问题在科学和工程中无处不在，但基于学习的方法往往需要解决大量困难实例以收集训练数据，这会带来显著的计算成本。现有的基于学习的方法需要为每个问题分布和每个下游任务训练专门的模型，这严重限制了它们的可扩展性和泛化能力。
### Innovation
本文介绍了Forge框架，这是一种预训练矢量量化图自编码器的框架，该框架在大型、多样化的混合整数编程（MIP）实例集上以无监督方式训练，无需依赖优化求解器或最优解。矢量化量化生成离散的代码分配，作为表示优化实例的词汇表。Forge框架在无监督和监督设置中进行了评估。在无监督设置中，Forge嵌入有效地将未见过的问题实例聚类到不同的问题域和规模中。在监督设置中，通过微调Forge嵌入，单个预训练模型能够在多种问题和规模分布下帮助预测割生成的整数间隙和变量提示以进行搜索指导。在两项任务中，Forge均提高了商用优化求解器的性能，并优于现有的基于学习的方法。
### Conclusion
最终，我们开源了Forge的训练代码、预训练权重和多种MIP分布下的嵌入，以促进优化问题中表示学习的进一步研究。
## 879. `cs.LG` - 探索图变换子在分布外泛化能力 [PDF](https://arxiv.org/pdf/2506.20575), [HTML](https://arxiv.org/abs/2506.20575)
### Authors
Itay Niv,Neta Rabin
### Background
图神经网络在社交网络、生物物理、交通网络和推荐系统等多个应用中取得了显著的成功。尽管如此，现有的方法通常假定训练和测试数据具有相同的分布，这在真实世界场景中很少成立。最近，图变换子（GT）在多个内部分布（ID）基准测试中优于传统的消息传递神经网络（MPNNs），但它们在分布转移下的效果仍很少被探讨。本文专注于图神经网络在分布外（OOD）泛化挑战，特别是研究了基础架构的影响。
### Innovation
研究团队通过系统地评估GT和混合GT-MPNN在OOD场景中的表现，并将其与MPNN进行对比。他们将几个领先的领域泛化（DG）算法适应用于GT，并在旨在测试各种分布转移的基准测试中评估其性能。研究结果发现，即使没有专门的DG算法，GT和混合GT-MPNN表现出了更强的泛化能力。此外，他们提出了一种新的后训练分析方法，比较整个ID和OOD测试数据集的聚类结构，特别是研究领域对齐和类别分离。这一模型无拘束的设计为理解GT和MPNN的泛化能力提供了深刻的见解，并对于超出图学习的领域泛化应用表现出良好的适应性。
### Conclusion
研究结果表明，图变换子在现实世界中的图学习中具有潜在的稳健性和广泛的应用前景。这一研究成果为未来在OOD泛化方面的研究指明了新的方向，提供了一种超越传统准确度指标的泛化能力深入分析视角。
## 880. `cs.LG` - 结构重要：使用可学习的边掩码进行脑图增强以实现数据高效的精神疾病诊断 [PDF](https://arxiv.org/pdf/2509.09744), [HTML](https://arxiv.org/abs/2509.09744)
### Authors
Mujie Liu,Chenze Wang,Liping Chen,Nguyen Linh Dan Le,Niharika Tewari,Ting Dang,Jiangang Ma,Feng Xia
### Background
限定的带标签脑网络数据使得实现准确且可解释的精神疾病诊断具有挑战性。现有的自监督学习（SSL）方法虽然提供了可能的解决方案，但通常依赖的增强策略可能会破坏脑图中的关键结构语义。
### Innovation
我们提出了SAM-BG，这是一种两阶段框架，用于在结构语义保留下的脑图表示学习。在预训练阶段，一个边掩码器在小的带标签子集上训练以捕获关键的结构语义。在SSL阶段，提取的结构先验指导结构感知的增强过程，从而使模型能够学习更语义上丰富和稳健的表示。
### Conclusion
在两个实际的精神疾病数据集上的实验表明，SAM-BG 在小型带标签数据集中优于最先进的方法，并揭示了有助于增强可解释性的临床相关连通性模式。我们的代码可在 <this https URL> 获得。
## 881. `cs.LG` - 提升蒙特卡洛树搜索以改善符号回归 [PDF](https://arxiv.org/pdf/2509.15929), [HTML](https://arxiv.org/abs/2509.15929)
### Authors
Zhengyao Huang,Daniel Zhengyu Huang,Tiannan Xiao,Dina Ma,Zhenyu Ming,Hao Shi,Yuanhui Wen
### Background
符号回归旨在发现简洁且可解释的数学表达式，以满足一定的目标，比如拟合数据，通过有高度组合性的优化问题来实现。尽管遗传编程一直是主导方法，但最近的研究已经探索了强化学习方法来提高搜索效率。蒙特卡洛树搜索（MCTS）因其能够通过引导搜索来平衡探索和 exploitation 而被视作一种有前景的技术。然而，其传统的泛型策略和符号的顺序构建通常限制了其性能。
### Innovation
本文提出了一个改进的 MCTS 框架来改善符号回归，两个关键创新点包括：(1) 针对识别全局最优表达式设计的极端泛型分配策略，在多项式奖励衰减假设下具有有限时间的性能保证；(2) 基于进化启发式的状态跃迁行为，例如突变和杂交，使搜索空间中的非局部过渡成为可能。这些状态跃迁行为在搜索过程中重塑了奖励景观，提高了算法的鲁棒性和效率。
### Conclusion
本文方法在不同数据集上（包括真实和黑盒数据集）与现有符号回归方法进行了对比，并取得了与最先进的库中相当的恢复率。同时，它在准确性和模型复杂度之间的帕累托前沿上也占据有利位置。
## 882. `cs.LG` - 超越预服务门槛：融合内部控制行为以提高金融风险预测 [PDF](https://arxiv.org/pdf/2509.06385), [HTML](https://arxiv.org/abs/2509.06385)
### Authors
Senhao Liu,Zhiyu Guo,Zhiyuan Ji,Yueguo Chen,Yateng Tang,Yunhai Wang,Xuehao Zheng,Xiang Ao
### Background
传统的金融风险管理分为预服务风险评估和在服务时的风险检测两个阶段，这两个阶段通常分别建模。本文的研究背景在于，这种分别建模的方式可能无法充分利用在服务用户行为数据，从而导致预服务风险预测不够准确。因此，该论文提出了一种新的框架，即多粒度知识蒸馏（MGKD），旨在通过融合在服务用户行为数据来改进预服务风险预测能力。
### Innovation
该论文的创新点在于提出了多粒度知识蒸馏（MGKD）框架，该框架采用了知识蒸馏的理念，通过教师模型（基于历史在服务数据训练）指导学生模型（基于预服务数据训练），利用从在服务数据中提取的软标签，帮助学生模型在服务前提高风险预测能力。同时，该框架引入了粗粒度、细粒度和自我蒸馏的多粒度蒸馏策略，以使教师模型和学生模型的表示和预测相一致，从而强化了违约案例的表示，并将违约者的行为模式从教师模型转移至学生模型，提高了预服务风险评估的整体性能。此外，该论文还采用了重新加权策略来缓解模型对少数类别样本的偏差问题。实证研究表明，该方法在大规模实际数据集上具有良好的离线和在线效果。
### Conclusion
实验结果表明，多粒度知识蒸馏方法能够有效提高预服务风险预测的性能，特别是在大型真实数据集上，在离线和在线场景中均显示出良好的效果。这种方法不仅能够更好地捕捉用户行为模式，还有效减少了对少数类别样本的偏差影响，进一步验证了其在金融风险预测中的有效性。
## 883. `cs.LG` - 因果诱导的位置编码用于基于变换器的非顺序特征表示学习 [PDF](https://arxiv.org/pdf/2509.16629), [HTML](https://arxiv.org/abs/2509.16629)
### Authors
Kaichen Xu,Yihang Du,Mianpeng Liu,Zimu Yu,Xiaobo Sun
### Background
位置编码对于补充变换器的位置信息至关重要，但现有的位置编码方法需要预定义的标记/特征顺序，使其不适合处理具有因果相关但非顺序特征的实际数据。这导致现有的位置编码方法在处理这类数据时表现出局限性。
### Innovation
本文提出了一种称为CAPE的新方法，通过广义结构性方程建模识别非顺序特征的潜在因果结构，将其嵌入到超球面模型中以保留几何结构并有效捕捉因果图的关键属性（因果强度和因果特异性）。这种方法生成了具有因果距离衰减、因果普遍性衰减和对位置扰动的鲁棒性的自注意力机制可增强的位置编码形式的旋转位置编码。
### Conclusion
我们在合成和真实世界数据集上评估了CAPE，实验证明其在增强变换器处理非顺序特征方面理论属性的有效性。我们的代码可以从这里获得。
## 884. `cs.LG` - DRES: 基于动态表示和集成选择的虚假新闻检测 [PDF](https://arxiv.org/pdf/2509.16893), [HTML](https://arxiv.org/abs/2509.16893)
### Authors
Faramarz Farhangian,Leandro A. Ensina,George D. C. Cavalcanti,Rafael M. O. Cruz
### Background
社交媒体上的信息传播速度越来越快，文本形式的假新闻检测变得尤为重要，因为它对社会产生了重大影响。现有方法在假新闻检测中表现不佳，需要更有效的解决方案。
### Innovation
提出了一种名为DRES（Dynamic Representation and Ensemble Selection，动态表示和集成选择）的新颖检测方法，基于多个文本特征表示，利用实例硬度衡量分类难度，并动态选择最合适的文本表示和集成分类器，以显著提高预测准确性。
### Conclusion
广泛试验表明，DRES方法在预测准确性方面显著优于现有最先进的方法，验证了基于实例硬度选择表示和动态集成选择的有效性。
## 885. `cs.LG` - 人工神经网络中的费希尔信息流 [PDF](https://arxiv.org/pdf/2509.02407), [HTML](https://arxiv.org/abs/2509.02407)
### Authors
Maximilian Weimar,Lukas M. Rachbauer,Ilya Starshynov,Daniele Faccio,Linara Adilova,Dorian Bouchet,Stefan Rotter
### Background
连续参数的估计在许多物理领域中占据中心地位。费希尔信息的概念是理解并改进这些估计过程的关键工具，它量化了关于未知参数的信息如何在物理系统中传递，决定了最终的精度极限。随着人工神经网络逐渐成为许多测量系统不可或缺的一部分，理解它们如何处理和传递与参数相关的信息变得至关重要。
### Innovation
本研究提出了一种方法来监测执行参数估计任务的人工神经网络中的费希尔信息流，从输入层追踪到输出层。结果表明，最佳估计性能对应于费希尔信息的最大传输，而训练超过这一点会导致由于过拟合导致的信息损失，从而提供了一个无需额外验证数据集的网络训练停止标准。
### Conclusion
为了证明我们方法的实际相关性，我们将其应用于一个基于成像实验数据训练的网络，强调了其在真实物理环境中的有效性。
## 886. `cs.LG` - 通过功能性缩放定律揭示学习率计划的作用 [PDF](https://arxiv.org/pdf/2509.19189), [HTML](https://arxiv.org/abs/2509.19189)
### Authors
Binghui Li,Fengling Chen,Zixun Huang,Lean Wang,Lei Wu
### Background
现有研究主要关注大型语言模型（LLMs）训练过程中最终损失，忽略了损失动态及其学习率计划（LRS）的影响。
### Innovation
引入功能性缩放定律（FSL），通过新颖的时间内在观点和随机梯度下降（SGD）的随机微分方程（SDE）建模，直接刻画整个训练过程中广泛学习率计划的群体风险演变，将学习率计划的影响通过显式的卷积型功能术语捕捉，使其影响完全可解。
### Conclusion
功能性缩放定律框架有望加深对LLMs预训练动态的理解，并为改进大规模模型训练提供思路。通过不同规模模型实验验证，FSL适用于预训练损失曲线拟合、预测和优化，验证了更高容量模型、学习率衰减提高训练效率以及温升稳定衰减计划优于直接衰减计划等常见实践的合理性。
## 887. `cs.LG` - UI-S1：通过半在线强化学习推进GUI自动化 [PDF](https://arxiv.org/pdf/2509.11543), [HTML](https://arxiv.org/abs/2509.11543)
### Authors
Zhengxi Lu,Jiabo Ye,Fei Tang,Yongliang Shen,Haiyang Xu,Ziwei Zheng,Weiming Lu,Ming Yan,Fei Huang,Jun Xiao,Yueting Zhuang
### Background
图形用户界面（GUI）代理通过强化学习在自动化复杂用户界面交互方面已经取得了显著的进步。然而，当前的方法面临根本性的困境：离线强化学习可以在预收集轨迹上实现稳定的训练，但缺乏轨迹级别的奖励信号，导致无法处理多步任务执行；而在线强化学习通过环境交互来捕捉这些信号，但由于稀疏奖励和部署成本高昂的问题，效率低下。因此，需要一种新的方法来解决上述问题。
### Innovation
本文提出了半在线强化学习（Semi-online Reinforcement Learning）这一新颖的范式，该范式在离线轨迹上模拟在线强化学习。在每次 rollout 过程中，保留了多轮对话中的原始模型输出，并引入了 Patch Module 适应性地恢复 rollout 和专家轨迹之间的偏差。半在线强化学习通过引入折扣未来的回报来捕捉长期训练信号，并利用加权步骤级和集体验级的优势优化策略。此外，还引入了半在线性能（SOP）这一度量标准，它更好地与真实的在线性能对齐，作为现实世界评估的实用和有效的代理。实验表明，本文提出的半在线强化学习在四个动态基准测试中达到 7B 模型的 SOTA 性能，相比基线模型有显著提高（如 AndroidWorld 上+12.0%，AIST 挑战赛上+23.8%），证明了半在线强化学习在离线训练效率和在线多轮推理之间的差距方面的显著进展。
### Conclusion
研究表明，半在线强化学习能够显著提高ui自动化代理在多种复杂环境中的效果。这为未来在多轮交互环境中应用强化学习开辟了新的道路，特别是在GUI自动化领域。
## 888. `cs.LG` - 显式路径CGR：几何表示中保持序列忠实度 [PDF](https://arxiv.org/pdf/2509.18408), [HTML](https://arxiv.org/abs/2509.18408)
### Authors
Sarwan Ali
### Background
传统的混沌博弈表示（CGR）方法在生物序列分析中有一定的局限性，即在几何映射过程中会损失序列信息。
### Innovation
提出了一种新的信息保留CGR方法，称为反向CGR（R-CGR），通过显式路径编码和有理算术精度控制，实现了完美的序列重建，能够在保持路径完整性和字符信息的同时，实现几何表示的可逆性。这种方法生成的特征丰富的图像适合深度学习，并且能够提供可解释的几何可视化，从而具备在准确性和序列恢复方面进行生物信息学分析的能力。
### Conclusion
R-CGR方法在生物序列分类任务中表现出与传统基于序列的方法相当的性能，同时提供了可解释的几何可视化，并且能够生成用于深度学习的特征丰富的图像，为具备准确性和序列恢复能力的可解释的生物信息学分析开辟了新的途径。
## 889. `cs.LG` - DS-Diffusion: 数据导向的时序列生成扩散模型 [PDF](https://arxiv.org/pdf/2509.18584), [HTML](https://arxiv.org/abs/2509.18584)
### Authors
Mingchun Sun,Rongqiang Zhao,Hengrui Hu,Songyu Ding,Jie Liu
### Background
现有的时序列生成扩散模型需要重新训练整个框架以引入特定条件指导，而且生成的数据与真实数据之间存在一定程度的分布偏差，这可能导致下游任务中的潜在模型偏差。此外，扩散模型及其潜在空间的复杂性使得推断过程难以解释。
### Innovation
提出了一种数据风格导向的扩散模型（DS-Diffusion）。该模型通过基于风格指导核的扩散框架避免了重新训练需求，开发了基于时间信息的分层次去噪机制（THD）以减少生成数据与真实数据之间的分布偏差，而且生成的样本可以从其来源数据风格中清晰表示。
### Conclusion
实验结果表明，与当前最先进的模型如ImagenTime相比，DS-Diffusion的预测评分和辨别评分分别降低了5.56%和61.55%，生成数据与真实数据之间的分布偏差进一步减小，推断过程也更加可解释。此外，通过消除重新训练扩散模型的需要，该模型在特定条件下也更具灵活性和适应性。
## 890. `cs.LG` - Safe-SAIL: 通过稀疏自编码器解释框架实现大型语言模型的精细安全景观 [PDF](https://arxiv.org/pdf/2509.18127), [HTML](https://arxiv.org/abs/2509.18127)
### Authors
Jiaqi Weng,Han Zheng,Hanyu Zhang,Qinqin He,Jialing Tao,Hui Xue,Zhixuan Chu,Xiting Wang
### Background
随着大型语言模型（LLMs）在实际应用中的广泛应用，其安全性问题日益突出。现有的大多数安全研究集中在评估LLM输出或特定的安全任务上，这限制了它们解决更广泛和未定义的风险的能力。稀疏自编码器（SAEs）通过解释从纠缠信号中分解出来的单义原子特征来促进可解释性研究，使模型行为更加清晰。然而，以前的SAE应用未能用细粒度的安全概念来解释特征，因此未能充分应对诸如生成有毒响应和违反安全法规这类安全关键行为。为了进行严谨的安全分析，必须提取出有效捕捉这些高风险行为的丰富多样化的安全相关特征，但这也面临两个挑战：确定具有最大潜在能力生成概念特定神经元的SAE，并且对详细特征解释的高昂成本。
### Innovation
本文提出了Safe-SAIL框架，用于在LLMs中解释SAE特征，以推进安全领域的机制性理解。Safe-SAIL通过系统性地识别具有最佳概念特定解释性的SAE，解释与安全相关的神经元，并引入了高效的解释过程扩展策略。我们还将发布一个包含SAE检查点和可读性高的神经元解释的综合工具包，以支持对LLM安全性的实证分析，促进LLM安全研究。
### Conclusion
我们通过Safe-SAIL框架系统性地识别和解释最适于安全概念的SAE特征，提出了一套有效的扩展策略，并提供了支持实证分析的工具包，以促进大型语言模型的安全研究。
## 891. `cs.LG` - Kron-LoRA: 混合Kronecker-LoRA适配器实现可扩展且可持续的微调 [PDF](https://arxiv.org/pdf/2508.01961), [HTML](https://arxiv.org/abs/2508.01961)
### Authors
Yixin Shen
### Background
大规模预训练语言模型在众多任务上进行微调时，需要既有高效参数量的适应器，又有良好表达能力。现有技术如LoRA的主要挑战在于如何在保持模型适配能力的同时减少参数量并提高效率，但还没有综合使用Kronecker结构分解与低秩LoRA压缩的方法被探索过，特别是在参数高效微调或矩阵逼近文献中。因此，研究人员需要一种既能大幅减小参数量又不牺牲性能的方法，来实现大型语言模型的多任务适配，以应对大模型的计算和存储压力，同时保持较快的训练速度和良好的任务间迁移能力。
### Innovation
文章提出了一种名为Kron-LoRA的混合适配器，它结合了Kronecker结构分解与低秩LoRA压缩技术。Kron-LoRA在保持类似表达能力的同时，参数量减少了4倍，这在参数高效微调和矩阵逼近文献中是一种新颖的尝试。实验结果表明，Kron-LoRA在DistilBERT、Mistral-7B、LLaMA-2-7B和LLaMA-3-8B等多个基准模型上表现良好，且具有适度的内存节省和5-8%的轻微速度损失。在序列微调中，Kron-LoRA使用四分之一的适配器参数，也能实现与标准LoRA相当的跨任务迁移能力。因此，Kron-LoRA提供了大规模语言模型多任务适配的可扩展且可持续的解决方案。
### Conclusion
Kron-LoRA通过结合Kronecker结构分解与低秩LoRA压缩，实现了在减少参数量的同时保持良好表达能力，适用于多种大型语言模型的微调任务。实验结果验证了Kron-LoRA的有效性，尤其是在多任务迁移学习方面表现出色，为未来的大规模语言模型的多任务训练提供了一种有效策略。
## 892. `cs.LG` - 通过持续指令调优实现自我进化的LLMs [PDF](https://arxiv.org/pdf/2509.18133), [HTML](https://arxiv.org/abs/2509.18133)
### Authors
Jiazheng Kang,Le Huang,Cheng Hou,Zhe Zhao,Zhenxiang Yan,Chuan Shi,Ting Bai
### Background
在实际工业环境中，大型语言模型（LLMs）必须不断学习以跟上多样化和不断变化的任务，需要自我进化来在动态数据分布下精炼知识。现有的持续学习（CL）方法，如重演和参数隔离，往往遭受灾难性遗忘的问题：在训练新任务时，会导致早期任务性能下降，因为它们过度拟合到新的数据分布。考虑到这些挑战，本文提出了MoE-CL，这是一个参数高效的对抗混合专家框架，用于工业规模的自我进化的持续指令调优。
### Innovation
MoE-CL 使用双专家设计：（1）每个任务一个专用的 LoRA 专家，通过参数独立性保持任务特定的知识，减少遗忘；（2）一个共享的 LoRA 专家，以促进跨任务的迁移。通过集成在 GAN 中的任务感知鉴别器来防止共享路径上传递任务不相关的噪声。MoE-CL 通过对抗学习使共享专家获取泛化的表示，以模仿鉴别器，而专用专家则保留特定的任务细节，从而平衡知识保留和跨任务泛化。
### Conclusion
在公共 MTL5 和工业级 Tencent3 验证基准上的实验以及腾讯视频平台的 A/B 测试中，验证了 MoE-CL 在持续指令调优中的有效性，通过 MoE-CL 减少了人工审查成本 15.3%。这些结果表明，MoE-CL 在持续适应和稳定迁移的关键工业部署场景中是可行的。
## 893. `cs.LG` - CANDLE:一种用于可解释性 sarcopenia 诊断的跨模态代理知识蒸馏框架 [PDF](https://arxiv.org/pdf/2507.21179), [HTML](https://arxiv.org/abs/2507.21179)
### Authors
Yuqi Jin,Zhenhao Shuai,Zihan Hu,Weiteng Zhang,Weihao Xie,Jianwei Shuai,Xian Shen,Zhen Feng
### Background
大型语言模型（LLMs）通过学习大量文本和网络数据表现出强大的泛化和迁移能力。它们的语义表示使得跨任务的知识迁移和推理成为可能，为数据稀缺和异质领域（如临床医学）提供了希望。但在诊断任务如 sarcopenia 中，仍然存在解释性、透明性和部署效率等挑战。传统的机器学习（TML）模型能提供稳定的表现和特征级归因，确保可追溯和可审计的决策逻辑，但缺乏语义广度。相比之下，LLMs 允许灵活的推理，但往往作为不透明的预测器工作。现有的集成策略仍然相对浅显，鲜少将 TML 的结构化推理嵌入到 LLM 的推理中。
### Innovation
CANDLE 框架通过将 SHAP 基于统计证据与强化训练的 LLM 推理相结合，缓解了解释性与性能之间的权衡，提高了预测准确性并保持了高度的一致性。这种方法提供了一种可扩展的方式来资产化 TML 模型的知识，使其在 sarcopenia 和更广泛的医疗领域中实现可解释性、可重复性和临床对齐的决策支持。
### Conclusion
CANDLE 框架通过结合 SHAP 提供的统计证据和强化训练的 LLM 逻辑推理，减轻了解释性和性能之间的权衡，提高了预测准确性，并保持了高度的一致性。该框架提供了一种可扩展的方法来资产化 TML 模型的知识，使其在 sarcopenia 诊断和更广泛的医疗领域中实现可解释性、可重复性和临床对齐的决策支持。
## 894. `cs.LG` - 通过增强Transformer生成对抗网络优化信用卡欺诈检测 [PDF](https://arxiv.org/pdf/2509.19032), [HTML](https://arxiv.org/abs/2509.19032)
### Authors
Kashaf Ul Emaan
### Background
信用卡欺诈检测是金融安全中的一个紧迫问题，因为交易数据集极度不平衡，欺诈案例只是极少数。传统的过采样方法，如合成少量过采样技术（SMOTE），通常会产生过于简化的合成样本，不适合复杂的欺诈模式。尽管Conditional Tabular生成对抗网络（CTGAN）和表数据变分自动编码器（TVAE）在表格合成方面提高了效率，但这些模型在高维依赖建模方面仍然存在问题。我们的研究旨在通过结合生成对抗网络（GAN）和Transformer编码器块，生成逼真的欺诈交易样本，从而弥补这些模型的不足，处理高维依赖性问题，提高生成欺诈类样本的质量和多样性，尤其是在处理严重类别不平衡的问题上取得显著进展。我们的算法在公开的信用卡欺诈检测数据集上进行了测试，与传统的和生成的抽样策略，包括逻辑回归（LR）、随机森林（RF）、极端梯度提升（XGBoost）和支持向量机（SVM）等分类器进行了比较，结果显示改进后的Transformer生成对抗网络在召回率、F1分数和ROC曲线下面积（AUC）方面取得了显著提升，表明其在处理此类不平衡问题上具有有效性。
### Innovation
提出了一种结合生成对抗网络（GAN）和Transformer编码器块的混合方法，生成逼真的欺诈交易样本。这种方法通过生成现实的欺诈交易样本来克服SMOTE、CTGAN和TVAE的局限性，生成高质量的合成欺诈类样本，特别在解决高维依赖性建模方面表现出优势。
### Conclusion
我们的Transformer增强GAN在信用卡欺诈检测任务中表现出显著的提升，特别是在召回率、F1分数和AUC上。这些结果表明，我们的方法能够有效地解决此类数据集中的类别不平衡问题，并且在多种分类器中均显示出更好的性能。
## 895. `cs.LG` - 红外图像超分辨率：系统综述及未来趋势 [PDF](https://arxiv.org/pdf/2212.12322), [HTML](https://arxiv.org/abs/2212.12322)
### Authors
Yongsong Huang,Tomo Miyazaki,Xiaofeng Liu,Shinichiro Omachi
### Background
红外（IR）图像超分辨率是计算机视觉和图像处理任务中必不可少的一部分。随着深度学习的发展，研究人员不断致力于红外图像超分辨率的研究。本文旨在提供一个全面的红外图像超分辨率透视图，包括其应用、硬件成像系统难题以及图像处理方法的分类。此外，红外图像超分辨率任务中的数据集和评估指标也进行了讨论。
### Innovation
本文全面梳理了红外图像超分辨率的研究现状，不仅涵盖了其应用场景和硬件成像系统的问题，还对其处理方法进行了分类，同时讨论了当前技术的不足之处和可能的发展方向，为研究者提供了宝贵的信息和指导。
### Conclusion
文章强调了需要不断更新和关注该领域的最新研究成果，并提供了一个更新链接来保证信息的时效性。
## 896. `cs.LG` - 生成性条件分布等价性检验框架及其最小最大分析 [PDF](https://arxiv.org/pdf/2509.17729), [HTML](https://arxiv.org/abs/2509.17729)
### Authors
Siming Zheng,Meifang Lan,Tong Wang,Yuanyuan Lin
### Background
该研究关注于测试两个样本条件下分布的等价性问题，在转移学习和协变量偏移的情况下尤为重要。前人在该领域的贡献主要集中在基于神经网络的生成方法和样本拆分技术的应用上，将条件分布等价性问题转化为无条件问题。作者在此框架的基础上，提出了两种特定测试方法：生成性置换基条件分布等价性检验和生成分类准确率基条件分布等价性检验。此外，作者还证明了生成分类准确率基条件分布等价性检验的一致性，并推导了学习到的条件生成器的收敛速率。
### Innovation
该论文提出了一种新的框架，用于基于神经网络的生成方法和样本拆分技术测试两个样本条件下分布的等价性。研究引入了两种特殊的测试方法，并建立了统计推断在满足某些光滑条件下的最小最大理论下界。特别地，证明了生成性置换基条件分布等价性检验及其改进版本可以达到这个下界或仅差一些对数因子。同时，作者证明了生成分类准确率基条件分布等价性检验的一致性。通过推导出有关最近开发的偏移Rademacher复杂度和神经网络逼近性质的新结果，建立了所学习的条件生成器的收敛速率。实验结果表明该方法的有效性，包括合成数据集和两个真实世界数据集的结果展示。
### Conclusion
通过理论分析和实验结果，证明了该框架的有效性和优越性，在真实世界问题中有着广泛的应用潜力。该工作的贡献包括提供了条件分布等价性测试的一个严格理论基础和实用方法，为未来研究提供了坚实的基础。
## 897. `cs.LG` - 差分隐私的自助法：新的隐私分析和推断策略 [PDF](https://arxiv.org/pdf/2210.06140), [HTML](https://arxiv.org/abs/2210.06140)
### Authors
Zhanyu Wang,Guang Cheng,Jordan Awan
### Background
差分隐私（DP）机制通过在统计分析过程中引入随机性来保护个体层面的信息。尽管有大量的DP工具，但在差分隐私条件下进行统计推断的通用技术仍然不足。本文研究了通过释放多个私有自助估计值来推断采样分布和构建置信区间（CIs）的DP自助方法。
### Innovation
1. 提出了关于单个DP自助估计值隐私成本的新结果，适用于任何DP机制。2. 提出了数值方法以计算释放多个DP自助估计值的确切隐私成本。3. 使用高斯差分隐私（GDP）框架，证明了当B趋向于无穷大时，$B$个满足$(?mu/?sqrt{(2-2/?mathrm{e})B})$-GDP机制释放出的估计值渐近满足$?mu$-GDP。4. 利用去卷积方法准确推断采样分布，提高了有限性能，并用于偏回归和分位回归的任务。5. 在公共覆盖率水平上实现了私有置信区间，并提供了第一个私有量化回归推断方法。
### Conclusion
本文通过DP自助方法进行了私人统计推断，证明了点估计的稳健性，标准置信区间的渐近有效性，并且两者都享有最优收敛率。进一步改进有限性能，使用了具有DP自助估计值的去卷积方法以精确推断采样分布。通过模拟和真实世界的数据集（2016年加拿大人口普查数据）进行了比较，验证了方法的有效性。
## 898. `cs.LG` - CLIP可以理解深度 [PDF](https://arxiv.org/pdf/2402.03251), [HTML](https://arxiv.org/abs/2402.03251)
### Authors
Sohee Kim,Jisu Kang,Dunam Kim,Seokju Lee
### Background
本文探讨了如何将预训练的CLIP模型应用于下游任务，尤其是单目深度估计任务。CLIP模型在生成建模和语义分割等任务中表现良好，但在单目深度估计中由于对比学习先验难以泛化而表现较差。这主要是因为CLIP模型难以一致地捕捉图像片段与描述距离的自然语言提示之间的相似性。
### Innovation
本文通过移除预训练的自然语言词嵌入，将CLIP的冻结文本编码器的语义先验提炼为一个可学习的嵌入矩阵“mirror”。这个设计旨在生成一个非人类语言的提示，类似于“这个位置与相机的距离是多少？”从这种方法出发，本文提出了一个新的框架，包括一个冻结的CLIP、一个“mirror”和一个紧凑的解码器，用于密集深度预测。相较于传统深度模型，该框架在参数和计算效率方面更为高效。该方法证明了即使不微调CLIP模型或将其镜像与预训练的子单词嵌入连接起来，CLIP模型的空间和时间一致性深度理解缺陷也可以被显著纠正。
### Conclusion
本文通过证明对冻结的CLIP模型的微调当前不是必需的，并提出了一种新的方法来改进CLIP模型在单目深度估计中的表现，提供了一个新的框架，显著提高了模型在NYU Depth v2和KITTI基准数据集上的性能，优于所有基于冻结CLIP先验的视觉语言深度模型。此外，消融实验表明，镜像模块能够隐式地学习捕捉重要的语义线索，如人类和窗户等对象。
## 899. `cs.LG` - 通过随机控制微调扩散模型：熵正则化及其拓展 [PDF](https://arxiv.org/pdf/2403.06279), [HTML](https://arxiv.org/abs/2403.06279)
### Authors
Wenpin Tang,Fuzhong Zhou
### Background
该论文旨在解决在连续时间扩散模型中熵正则化微调的问题。最近，Uehara等人（arXiv:2402.15194, 2024）提出了这一方法。其核心思想是使用随机控制生成样本，并引入熵正则器来缓解奖励坍塌问题。此外，研究还展示如何将分析扩展到使用一般$f$-散度正则器的微调方法。实验在大规模文本生成图像模型Stable Diffusion v1.5上进行，以验证该方法的有效性。
### Innovation
该论文提出了使用随机控制方法来解决熵正则化微调问题，并展示了如何将该分析扩展到使用一般$f$-散度正则器的微调方法。通过这种方式，解决了传统方法中可能存在的奖励坍塌问题，增强了模型的稳定性和泛化能力。
### Conclusion
通过在大规模文本生成图像模型Stable Diffusion v1.5上的实验证明了该方法的有效性。该研究不仅为连续时间扩散模型的熵正则化微调提供了严格的理论框架，还展示了一种新的解决方案来增强模型的性能。
## 900. `cs.LG` - 使用大型语言模型进行宏观经济预测 [PDF](https://arxiv.org/pdf/2407.00890), [HTML](https://arxiv.org/abs/2407.00890)
### Authors
Andrea Carriero,Davide Pettenuzzo,Shubhranshu Shekhar
### Background
近年来，大型语言模型（LLMs）因其能够捕获数据中的复杂模式并迅速适应不同领域而受到关注，特别是在预测方面。然而，LLMs在预测宏观经济时间序列数据方面的效果与传统方法相比仍是一个值得研究的领域。因此，本文利用FRED-MD数据库，对LLMs与传统的宏观经济预测方法进行了严格的比较分析，评估了它们各自的准确性和适用性。
### Innovation
本文通过使用FRED-MD数据库对LLMs和传统宏观经济预测方法进行全面对比分析，这一研究方法有助于更深入地理解LLMs在宏观经济预测中的优势与局限性，为该领域的研究和应用提供了新视角。
### Conclusion
本研究为LLMs在宏观经济时间序列预测中的应用提供了有价值的见解，显示了它们在实际场景中的适用性。同时，研究也揭示了LLMs在特定情境下的局限性，为未来的研究指明了方向。
## 901. `cs.LG` - 使用图神经网络的分布式学习策略以最小化估计误差 [PDF](https://arxiv.org/pdf/2404.03227), [HTML](https://arxiv.org/abs/2404.03227)
### Authors
Xingran Chen,Navid NaderiAlizadeh,Alejandro Ribeiro,Shirin Saeedi Bidokhti
### Background
本文研究了在具有统计上相同代理的多跳无线网络中，自回归马尔可夫过程的采样和远程估计挑战。代理从其他代理缓存最近的样本，并通过由潜在图拓扑控制的无线碰撞信道进行通信。目标是在不依赖物理过程和依赖物理过程的策略下，通过去中心化的可扩展采样和传输策略，最小化时间平均估计误差和/或信息 aged 的问题。
### Innovation
本文通过证明在无感知策略中，最小化估计误差等同于最小化信息 aged，解决了复杂度（多维动作空间和任意网络拓扑）问题，提出了使用图形多代理强化学习框架来优化政策，每台代理使用置换不变的图神经网络架构。此外，验证了该框架具有良好的可迁移性，训练在小型或中型网络上的策略可以在大型拓扑中有效执行，并通过数值实验验证了策略的可迁移性和训练方法的稳定性。
### Conclusion
数值实验表明：（i）提出的框架优于最先进的基线；（ii）训练的策略在更大规模的网络上可迁移，性能收益随着代理数量增加而增加；（iii）即使利用独立学习技术，训练过程也能抵抗非稳定性的影响；（iv）递归性对于独立学习和集中式训练及分布式执行非常重要，改善了独立学习对非稳定性的影响。
## 902. `cs.LG` - FAIR Universe HiggsML不确定性数据集和竞赛 [PDF](https://arxiv.org/pdf/2410.02867), [HTML](https://arxiv.org/abs/2410.02867)
### Authors
Lisa Benato,Wahid Bhimji,Paolo Calafiura,Ragansu Chakkappai,Po-Wen Chang,Yuan-Tang Chou,Sascha Diefenbacher,Jordan Dudley,Ibrahim Elsharkawy,Steven Farrell,Aishik Ghosh,Cristina Giordano,Isabelle Guyon,Chris Harris,Yota Hashizume,Shih-Chieh Hsu,Elham E. Khoda,Claudius Krause,Ang Li,Benjamin Nachman,Peter Nugent,David Rousseau,Robert Schoefbeck,Maryam Shooshtari,Dennis Schwarz,Benjamin Thorne,Ihsan Ullah,Daohan Wang,Yulei Zhang
### Background
这篇论文背景在于通过不完美的模拟器测量基本粒子的物理特性。比赛数据集包含28个特征和2.8亿个实例，每个实例代表在瑞士日内瓦CERN大型强子对撞机中观测到的质子-质子对撞事件。数据集经过长期发布，旨在为新的技术提供长期基准测试。比赛的主要目的是通过考虑各种系统性（认识论）不确定性来计算和报告与希格斯玻色子相关的感兴趣参数的信心区间。
### Innovation
比赛的主要创新之处在于利用对比归一化流和通过分类估计密度比的方法，这些方法被描述为领先的提交内容，推动了物理和机器学习社区对处理AI技术中的系统性不确定性方法的理解和发展。
### Conclusion
这项挑战促进了物理学和机器学习社区的合作，其结果表明，为了更好地理解和改进AI技术在处理系统性不确定性方面的方法，长期的数据集中长期基准测试是必要的。
## 903. `cs.LG` - The SkipSponge Attack: Sponge Weight Poisoning of Deep Neural Networks [PDF](https://arxiv.org/pdf/2402.06357), [HTML](https://arxiv.org/abs/2402.06357)
### Authors
Jona te Lintelo,Stefanos Koffas,Stjepan Picek
### Background
海绵攻击旨在增加神经网络的能量消耗和计算时间。该研究介绍了一种名为SkipSponge的新颖海绵攻击，它是首次直接对预训练模型的参数进行攻击，仅使用少量数据样本。实验表明，与现有的海绵攻击（Sponge Poisoning）相比，SkipSponge能更有效地提升图像分类模型、GANs和自编码器的能量消耗，且所需的样本更少。此外，研究显示，如果不需要针对SkipSponge进行特别的中毒防御（即降低目标层偏差值），现有的中毒防御无效；并且SkipSponge在GANs和自编码器上的效果优于Sponge Poisoning。同时，SkipSponge具有隐匿性，不需要对受害模型参数进行显著修改。实验表明，即使攻击者只能访问整个训练数据集的不到1%时，SkipSponge也能有效进行，并能达到高达13%的能量增加。
### Innovation
该研究提出了第一种直接对预训练模型的参数进行攻击的海绵攻击——SkipSponge，仅使用少量数据样本。SkipSponge不仅适用于图像分类模型、GANs和自编码器，还展示出它更有效地提升目标模型的能量消耗。此外，SkipSponge具有更高的隐匿性，不显著改变受害模型的参数。研究还提出了针对SkipSponge的防御无效，除非特别调整针对该攻击的防御策略。最后，即使在攻击者只能访问少量训练数据的情况下，SkipSponge也能有效实施。
### Conclusion
实验结果表明，SkipSponge不仅有效提高了深度神经网络的能量消耗，且具有较高的隐匿性。此外，现有的中毒防御措施对SkipSponge效果不佳，除非特别针对该攻击进行调整。研究强调了针对具体攻击类型定制防御的重要性，并指出未来研究可能需要更多关注对隐匿性攻击的有效响应。
## 904. `cs.LG` - Vision Language Model 视觉语言模型见所思，机器人执行所做：基于视觉语言模型的人类演示视频到机器人动作计划 [PDF](https://arxiv.org/pdf/2410.08792), [HTML](https://arxiv.org/abs/2410.08792)
### Authors
Beichen Wang,Juexiao Zhang,Shuwen Dong,Irving Fang,Chen Feng
### Background
视觉语言模型（VLMs）因其在常识推理和泛化能力方面的优势，已开始应用于机器人领域。现有的研究工作将VLMs应用于从自然语言指令生成任务与动作规划，以及生成用于机器人学习的模拟训练数据。本研究旨在探索利用VLMs解释人类演示视频并生成机器人的任务规划方法。
### Innovation
提出了一个名为SeeDo的方法，该方法将关键帧选择、视觉感知和VLM推理整合进一个流水线。这种方法使VLM能够‘看’到人类的演示，并向机器人‘解释’相应的规划，从而指导机器人执行所做计划。通过收集三类不同的取放任务的人类示范视频，以及设计一套综合指标，我们将SeeDo与最先进的视频输入VLMs进行了基准测试，实验结果显示SeeDo在性能上优于其他基准。
### Conclusion
研究通过模拟环境和真实机器人臂部署生成的任务规划，验证了SeeDo方法的有效性，展示了其在实际应用中的潜力。
## 905. `cs.LG` - Tree Search for Language Model Agents [PDF](https://arxiv.org/pdf/2407.01476), [HTML](https://arxiv.org/abs/2407.01476)
### Authors
Jing Yu Koh,Stephen McAleer,Daniel Fried,Ruslan Salakhutdinov
### Background
自主语言模型（LMs）在执行网页自动化等决策任务方面展示了潜力，但在多步推理、规划及利用环境反馈解决现实计算机任务方面存在主要局限性。
### Innovation
提出了一种在推理阶段使用的搜索算法，以使LM代理能够在互动网页环境中明确执行探索和多步规划。这是首个在真实网页任务中显示效果的LM代理的树搜索算法。
### Conclusion
在VisualWebArena基准测试中，将搜索算法应用于一个GPT-4o代理，成功率相对提高了39.7%，达到26.4%，成为最新纪录。在WebArena中，搜索算法也提高了基线代理28.0%的成功率，达到19.2%。实验表明搜索在网页代理中的有效性，性能随测试时间计算量的增加而提升。我们详细分析了结果，强调了搜索带来的改进、局限性和未来研究的前景。相关代码和模型已公开发布。
## 906. `cs.LG` - UNComp: Can Matrix Entropy Uncover Sparsity? -- A Compressor Design from an Uncertainty-Aware Perspective [PDF](https://arxiv.org/pdf/2410.03090), [HTML](https://arxiv.org/abs/2410.03090)
### Authors
Jing Xiong,Jianghan Shen,Fanghua Ye,Chaofan Tao,Zhongwei Wan,Jianqiao Lu,Xun Wu,Chuanyang Zheng,Zhijiang Guo,Min Yang,Lingpeng Kong,Ngai Wong
### Background
部署具有长时间上下文推理能力的大语言模型（LLM）面临着巨大的计算需求和内存需求，现有技术如键值（KV）缓存压缩虽然能够减少内存使用量，但往往忽略了隐状态与其对应的KV缓存之间固有的结构化稀疏性。既有的压缩方法通常采用均匀压缩，即对整个模型进行统一的压缩处理，未能根据模型组件的重要程度动态调整压缩策略。
### Innovation
本文提出了一种不确定性感知框架UNComp，通过利用截断矩阵熵来识别低信息量区域，揭示可用于适应性压缩的稀疏模式。UNComp根据不确定性度量动态调整压缩策略，这些度量反映了模型各组件的重要性。研究表明，由不确定性估计得出的稀疏模式能够揭示特殊的长距离依赖性，如检索头和检索层，从而不仅优化了压缩性能，还提供了新的视角，探讨了LLM在长上下文推理中的内在稀疏性。
### Conclusion
UNComp通过针对性地采用不确定性，成功将KV缓存规模压缩至原始规模的4.74%，提升了6%的预填充速度，并将吞吐量提升了6.4倍，证明了该理论工具的有效性。UNComp不仅展示了强大的无损压缩性能，还验证了所提出框架的有效性。相关代码已经公开。
## 907. `cs.LG` - 无需重演的动态内存低秩持续适应 [PDF](https://arxiv.org/pdf/2411.00623), [HTML](https://arxiv.org/abs/2411.00623)
### Authors
Huancheng Chen,Jingtao Li,Weiming Zhuang,Chen Chen,Lingjuan Lyu
### Background
本文重新审视了持续学习（CL）的概念，这一概念使得预训练的视觉变换器（ViTs）能够随时间顺序地对新的下游任务进行微调。然而，随着这些模型规模的增大，灾难性遗忘成为一个更加严峻的挑战。最近的研究指出CL技术与参数高效微调（PEFT）之间存在交叉，后者专注于仅对一小部分可训练参数进行微调以适应下游任务，例如低秩适应（LoRA）等。虽然LoRA能够更快地收敛并需要更少的可训练参数，但它很少在持续学习的背景下进行探索。因此，本文旨在通过提出一种新的PEFT-CL方法——双低秩适应（DualLoRA），来解决这一问题，该方法引入了与预训练权重并行的正交LoRA适配器和残差LoRA适配器，并通过动态记忆机制来平衡稳定性和可塑性。同时，还提出了一种方案来预测任务身份并相应地校准模型的输出结果。
### Innovation
本文提出了一种新的PEFT-CL方法——双低秩适应（DualLoRA）。该方法通过在每层引入正交LoRA适配器和残差LoRA适配器，并利用动态记忆机制来平衡稳定性和可塑性，解决持续学习（CL）中的灾难性遗忘问题。此外，还提出了一种方案来预测任务身份并校准模型的输出结果。
### Conclusion
在基于ViT的模型上，本文证明了DualLoRA在多个基准上的准确率、推理速度和计算效率方面显著优于现有的持续学习方法。
## 908. `cs.LG` - Distortion-Aware Brushing for Reliable Cluster Analysis in Multidimensional Projections [PDF](https://arxiv.org/pdf/2201.06379), [HTML](https://arxiv.org/abs/2201.06379)
### Authors
Hyeon Jeon,Michaël Aupetit,Soohyun Lee,Kwon Ko,Youngtaek Kim,Ghulam Jilani Quadri,Jinwook Seo
### Background
刷图是2D散点图中常见的交互技术，允许用户通过选定连续且闭合区域内的聚类点来进行进一步分析或过滤。但是，将传统刷图应用于多维（MD）数据的2D表示，即多维投影（MDPs）中，会导致由于MDPs引起的扭曲影响原始MD数据的聚类结构，从而导致不可靠的聚类分析。为解决这一问题，我们提出了一种针对MDPs的新刷图技术，称为Distortion-aware刷图。
### Innovation
Distortion-aware刷图通过动态重新定位投影中的点来纠正当前刷图点周围的扭曲，将接近刷图点的MD空间中的数据点拉近，将距离较远的点推远。这种动态调整帮助用户更准确地刷MD聚类，从而进行更可靠的聚类分析。我们的用户研究显示，Distortion-aware刷图显著优于先前针对MDPs的刷图技术，更准确地分离MD空间中的聚类，并对扭曲保持鲁棒性。
### Conclusion
我们通过两个用例进一步证明了我们的技术的有效性：（1）地理空间数据的聚类分析；（2）交互式标记MD聚类。
## 909. `cs.LG` - 最小表示约束下的公平聚类 [PDF](https://arxiv.org/pdf/2409.02963), [HTML](https://arxiv.org/abs/2409.02963)
### Authors
Connor Lawless,Oktay Gunluk
### Background
聚类是得到广泛应用的无监督学习任务，旨在将数据点划分为若干个簇。但在许多应用中，这些簇对应于真实的构造（例如：选区、播放列表、电视频道），其中特定群体（例如：社会或人口统计学群体）仅在达到一定群体表示水平（例如：50%能选举他们心仪的候选人）时才能获益。因此，需要在聚类中考虑公平性约束，确保每个群体至少在一定数量的簇中达到最低水平的表示。本文即探讨在k-means和k-medians聚类问题中增加这种公平性约束的方法，并将其形式化为混合整数（非线性）优化问题，提出了MiniReL算法来解决这个问题。尽管综合公平性约束会导致MiniReL算法中的NP难分配问题，但作者提出了几种启发式策略，使得该方法在大规模数据集上仍然实用。实验结果显示，该方法在标准基准数据集上能够在不增加聚类成本的情况下生成公平的簇。
### Innovation
提出了一种公平性约束下的聚类问题，将其形式化为混合整数（非线性）优化问题，并开发了MiniReL算法来解决此问题。尽管存在NP难分配问题，但提出了一种启发式方法使得该方法在大规模数据集上仍然可行。
### Conclusion
提出的MiniReL算法能够在标准基准数据集上生成公平的簇，同时没有显著增加聚类成本，并且提出的启发式策略使得该方法在处理大规模数据集时仍然具有可行性。
## 910. `cs.LG` - 在对称正定矩阵流形上的包裹高斯分布 [PDF](https://arxiv.org/pdf/2502.01512), [HTML](https://arxiv.org/abs/2502.01512)
### Authors
Thibault de Surrel,Fabien Lotte,Sylvain Chevallier,Florian Yger
### Background
在数据科学的各个领域中，循环和非扁平的数据分布普遍存在，但这些数据的具体几何结构往往在机器学习框架中被严重忽视。对于统计模型的拓展，尤其是普及的高斯分布模型，合理考虑这些数据的内在几何结构至关重要。
### Innovation
本文通过引入基于指数映射的非各向同性包裹高斯分布，并提出基于此分布的最大似然参数估计框架，重新解释了现有的对称正定（SPD）矩阵上的分类器，并基于包裹高斯模型引入新的分类器。实验证明这种几何感知分布具有鲁棒性和灵活性，为基于流形的数据分析提供了强有力的支持。
### Conclusion
本文为将经典机器学习和统计方法扩展到更复杂且结构化的数据奠定了理论基础，展现了基于对称正定矩阵流形上的包裹高斯分布方法的巨大潜力。
## 911. `cs.LG` - 长程系统机器学习原子势 [PDF](https://arxiv.org/pdf/2502.04668), [HTML](https://arxiv.org/abs/2502.04668)
### Authors
Yajie Ji,Jiuyang Liang,Zhenli Xu
### Background
机器学习原子势已经作为一种革新性的分子模拟力场模型出现，提供了近乎量子力学的准确性但计算成本却只是其一小部分，并能够模拟大规模系统并在长时间尺度下进行仿真。然而，这些模型通常关注于模拟局部环境，忽略了至关重要的远距离相互作用。论文通过引入Sum-of-Gaussians Neural Network (SOG-Net)解决了这一问题，这种轻量级且通用的框架可以将远距离相互作用整合到机器学习力场中。
### Innovation
SOG-Net通过使用潜变量学习网络无缝地结合了短程和远程组件，并结合了高效Fourier卷积层以纳入远距离效应。通过学习不同卷积层中的Gauss函数乘子，SOG-Net能够适应性地捕捉不同的远距离衰减行为，同时通过非均匀快速傅里叶变换保持相近线性的计算复杂度以进行训练和仿真。这种方法被证明适用于广泛的远距离系统场景下，表明其有效性和普适性。
### Conclusion
SOG-Net为将远距离相互作用整合到机器学习力场框架中提供了一个轻量级、多功能的方法，为进一步提高分子模拟的精度和效率铺平了道路。
## 912. `cs.LG` - GraphEQA: 使用3D语义场景图进行实时具身问答 [PDF](https://arxiv.org/pdf/2412.14480), [HTML](https://arxiv.org/abs/2412.14480)
### Authors
Saumya Saxena,Blake Buchanan,Chris Paxton,Peiqi Liu,Bingqing Chen,Narunas Vaskevicius,Luigi Palmieri,Jonathan Francis,Oliver Kroemer
### Background
在具身问答（EQA）中，代理必须探索和开发对未知环境的语义理解，以充满信心地回答定位问题。这个问题在机器人技术中仍然具有挑战性，因为获取有用语义表示、在线更新这些表示和利用先验世界知识进行有效规划和探索都十分困难。
### Innovation
我们提出了一种名为GraphEQA的新颖方法，该方法利用实时3D度量语义场景图（3DSGs）和与任务相关图像作为多层次记忆，将视觉-语言模型（VLMs）与未知环境中的EQA任务连接起来。我们利用3DSGs的层次结构进行结构化规划和语义指导探索。我们在HM-EQA和OpenEQA两个基准数据集上对GraphEQA进行模拟评估，结果显示它在成功完成EQA任务和减少规划步骤方面优于关键baseline方法。此外，我们在多个实际家庭和办公室环境中进一步演示了GraphEQA的效果
### Conclusion
GraphEQA通过实时使用3D语义场景图，在未知环境中有效执行具身问答任务，展示了其在具身问答领域的创新性和优越性，为机器人领域提供了新的解决方案和方法。
## 913. `cs.LG` - Stylus：将Stable Diffusion重新用于无监督的mel-频谱图音乐风格转移 [PDF](https://arxiv.org/pdf/2411.15913), [HTML](https://arxiv.org/abs/2411.15913)
### Authors
Heehwan Wang,Joonwoo Kwon,Sooyoung Kim,Jungwoo Seo,Shinjae Yoo,Yuewei Lin,Jiook Cha
### Background
音乐风格转移能够通过将源音乐的结构与参考音乐的风格属性融合来实现个性化的音乐创作。现有的基于文本条件和扩散的方法显示出潜力，但往往需要配对数据集、大量训练或详细的标注。这些方法尽管有效，但使用上有一定局限。因此，需要一种无需训练、能够直接利用预训练模型的新方法来实现音乐风格转移。
### Innovation
Stylus是一个无需训练的框架，通过将预训练的Stable Diffusion模型重新用于音乐风格转移，在mel-频谱图领域进行操作。Stylus通过注入风格键值特征并保持源查询来操纵自我注意，从而保持音乐结构。为了提高保真度，Stylus引入了一种相位保持重构策略，避免Griffin-Lim重构带来的伪影，并采用了无分类引导控制方法以实现可调的风格化和多风格融合。
### Conclusion
在广泛的评估中，Stylus优于最先进的基线方法，其内容保留率提高了34.1%，感知质量提高了25.7%，且无需额外训练。这表明Stylus在无需额外训练的情况下，能够有效地实现音乐风格转移，具有很高的实用性。
## 914. `cs.LG` - CueGCL：基于聚类提示的无监督图对比学习个性化自训练 [PDF](https://arxiv.org/pdf/2311.11073), [HTML](https://arxiv.org/abs/2311.11073)
### Authors
Yuecheng Li,Lele Fu,Sheng Huang,Chuan Chen,Lei Yang,Zibin Zheng
### Background
最近，图对比学习（GCL）已成为节点级和监督任务的最优解决方案。然而，对于与结构相关的无监督任务如图聚类，现有的GCL算法难以获取必要的聚类级信息，导致性能不佳。此外，一般的无监督GCL通过增加负样本数量来提高下游任务的性能，但导致了严重的类别碰撞和图聚类的不公平性。
### Innovation
提出了一种基于聚类提示的图对比学习框架（CueGCL）来联合学习聚类结果和节点表示。具体地，设计了一种为无监督场景设计的个性化自训练（PeST）策略，使模型能够捕捉精确的聚类级个性化信息。运用PeST，缓解了类别碰撞和公平性问题，同时保持了模型的整体性能。进一步采用了对齐图聚类（AGC）方法，通过将下游任务的聚类空间与PeST中的对齐，获得更一致的节点嵌入。
### Conclusion
理论上展示了模型的有效性，表明其产生了具有显著可区分聚类结构的嵌入空间。大量实验结果表明，CueGCL在不同规模的五个基准数据集上表现出最先进的性能。
## 915. `cs.LG` - Sparse Max-Affine Regression [PDF](https://arxiv.org/pdf/2411.02225), [HTML](https://arxiv.org/abs/2411.02225)
### Authors
Haitham Kanj,Seonho Kim,Kiryung Lee
### Background
该论文探讨了在凸分段线性回归中使用稀疏梯度下降（Sp-GD）方法进行自变量选择的问题。模型用最大值表示，形式为$ x rightarrow text{max}_{j text{ in } [k]} text{a}_j^text{*} text{x} + text{b}_j^text{*}$，其中$text{a}_j^text{*}$和$text{b}_j^text{*}$代表真值权重向量和截距。研究在次高斯噪声条件下，协变量分布满足次高斯性和反集中性的局部非渐近收敛分析。通过稀疏主成分分析估计$ text{a}_j^text{*} $的子空间，再进行$r$覆盖搜索估计模型参数的初始化方案。将稀疏广义多项式转化为稀疏最大线性模型的新变换Real Maslov Dequantization (RMD)也被提出，该方法的误差衰减率在温度参数下的衰减指数级发生。r
### Innovation
论文提出了一种新的稀疏梯度下降方法（Sp-GD）用于凸分段线性回归中的变量选择；给出了在次高斯噪声下的非渐近局部收敛分析；提出了稀疏主成分分析和$r$覆盖搜索相结合的初始化方案；引入了Real Maslov Dequantization (RMD)，将稀疏广义多项式转化为稀疏最大线性模型，模型误差随温度参数呈指数级衰减；将Sp-GD的理论保证扩展到RMD引起的有界噪声模型。r
### Conclusion
当模型参数和模型阶数固定时，Sp-GD方法可以通过$text{O}(text{max}(text{e}^{-2}text{σ}_text{z}^2,1)text{s}text{log}(text{d} / text{s}))$观测数提供$text{e}$-准确的估计，在无偏噪声下提供$text{O}(text{s}text{log}(text{d} / text{s}))$观测数。通过$text{O}(text{e}^{-2}text{max}(text{σ}_text{z}^4, text{σ}_text{z}^2, 1)text{s}^2text{log}^4(text{d}))$观测数，初始化方案可以提供$text{e}$-准确的估计。RMD方法的误差衰减率是指数级小的。r
## 916. `cs.LG` - 基于Nyström近似的可扩展置换核两样本检验 [PDF](https://arxiv.org/pdf/2502.13570), [HTML](https://arxiv.org/abs/2502.13570)
### Authors
Antoine Chatalic,Marco Letizia,Nicolas Schreuder,Lorenzo Rosasco
### Background
两样本假设检验是用于判断两个数据集是否来自同一分布的基本统计问题，具有广泛的应用。在非参数检验中，最大均值离散度（MMD）作为测试统计量由于其灵活性和坚实的理论基础而受到青睐。然而，在大规模场景中，MMD的应用面临着高昂的计算成本的问题。本文旨在克服这个问题，通过使用Nyström近似来设计一种在保留统计保证的同时具有计算效率和实用性的测试算法。
### Innovation
提出了基于Nyström近似的计算效率高的两样本检验算法。该算法能够处理大规模数据集，并且在某些分布条件下能够达到最优的统计效能。这项工作的主要结果是在MMD具有足够分离度的分布下，提出了一个有限样本下的检验功效上界。这一分离率与已知的最优率相匹配。此外，通过一系列数值实验来支持这一发现，特别强调了该方法在真实科学数据集上的适用性。
### Conclusion
本文通过设计基于Nyström近似的高效的两样本检验算法，克服了MMD在大规模场景下的高计算成本问题。该算法不仅在充分分离的分布条件下保持着最优的统计性能，还通过实验验证了其实用性，适用于真实的科学数据。
## 917. `cs.LG` - SpaRC: 稀疏雷达-摄像头融合的3D目标检测 [PDF](https://arxiv.org/pdf/2411.19860), [HTML](https://arxiv.org/abs/2411.19860)
### Authors
Philipp Wolters,Johannes Gilg,Torben Teepe,Fabian Herzog,Felix Fent,Gerhard Rigoll
### Background
现有的3D感知范式将多视图图像语义与雷达和摄像头点特征结合，通过鸟瞰图(BEV)架构进行深度估计。传统的查询基Transformer在仅通过对象中心的方法进行摄像头检测时表现出色，但这些方法在减少误检测和提高定位精度方面存在局限性，因为它们依赖于隐式深度建模。SpaRC通过三种关键贡献来解决这些挑战：（1）稀疏棱柱融合（SFF）进行跨模态特征对齐，（2）范围自适应雷达聚合（RAR）以实现精确的目标定位，（3）局部自我注意（LSA）以实现聚焦查询聚合。SpaRC可以直接基于编码的点特征进行操作，减少了计算密集的BEV网格渲染过程，从而提高了效率和准确性。
### Innovation
SpaRC通过引入稀疏棱柱融合（SFF）、范围自适应雷达聚合（RAR）和局部自我注意（LSA）三种关键贡献来解决当前3D感知方法中的局限性。该方法可以在编码的点特征上直接操作，而不依赖于BEV网格渲染，实现了更高的效率和准确性。SpaRC在nuScenes和TruckScenes基准测试中显著优于现有密集BEV和稀疏查询基检测器，达到了最先进的性能指标67.1 NDS和63.1 AMOTA。
### Conclusion
SpaRC在稀疏雷达-摄像头融合领域实现了显著的性能提升，三类关键技术贡献显著减少了误检并提高了定性精度。SpaRC的代码和预训练模型可以通过给定的URL获取，展示了在3D目标检测领域的应用潜力。
## 918. `cs.LG` - 多模态参考视觉定位 [PDF](https://arxiv.org/pdf/2504.02876), [HTML](https://arxiv.org/abs/2504.02876)
### Authors
Yangxiao Lu,Ruosen Li,Liqiang Jing,Jikai Wang,Xinya Du,Yunhui Guo,Nicholas Ruozzi,Yu Xiang
### Background
视觉定位于根据语言表达从图像中检测物体。大规模视觉-语言模型（LVLMs）通过大规模数据集训练大型模型，显著提高了视觉定位置的能力。然而，当输入图像中有类似物体时问题仍然极具挑战性。例如，LVLM可能无法区分图像中的低卡路里可口可乐和普通可口可乐。在这种情况下，如果有低卡路里可口可乐和普通可口可乐的参考图像可用，则有助于类似物体的视觉定位置。
### Innovation
本文引入了一个新的任务名称为多模态参考视觉定位（MRVG），该任务中模型可以访问数据库中的参考图像集合。基于这些参考图像和语言表达，模型需要从查询图像中检测目标物体。研究团队在此任务中引入了一个新数据集，开发了名为MRVG-Net的新方法，通过有效利用参考图像进行少量样本对象检测，并使用大型语言模型（LLMs）进行对象匹配，该方法在视觉定位置性能上优于当前最先进的LVLMs如Qwen2.5-VL-72B，同时填补了少量样本检测与视觉定位置之间的差距。
### Conclusion
本文的研究不仅在视觉定位置的性能上超过了当前的最先进的LVLMs，还整合了少量样本检测与视觉定位置的问题，对于视觉理解具有广泛的应用前景，特别是在机器人技术领域。
## 919. `cs.LG` - 通过模仿周围车辆学习驾驶 [PDF](https://arxiv.org/pdf/2503.05997), [HTML](https://arxiv.org/abs/2503.05997)
### Authors
Yasin Sonmez,Hanna Krasowski,Murat Arcak
### Background
模仿学习是一种训练自主车辆在复杂交通环境中导航的有效方法，通过模仿专家司机的行为。现有的模仿学习框架侧重于利用专家演示数据，但往往忽略了周围交通参与者提供的额外复杂驾驶数据的潜力。本研究探讨了一种数据增强策略，该策略利用自主车辆传感器捕获的附近车辆轨迹作为额外的演示数据，以丰富训练数据集。研究在大规模真实世界数据集上使用一种代表性基于学习的规划器进行评估，并在复杂的驾驶场景中展示了改进的性能，特别是在减少碰撞率和提高安全指标方面表现出色。即使在使用原始数据集的10%时，该方法也能达到或超过完整数据集的表现。通过消融实验分析了选择标准，发现简单随机选择可能降低性能。研究表明，利用多样化的现实世界轨迹数据在模仿学习中具有很高的价值，并为自主驾驶中的数据增强策略提供了见解。
### Innovation
提出了一种数据增强策略，利用自主车辆传感器捕获的附近车辆轨迹作为额外的演示数据，以此来丰富训练数据集。引入了一个简单的车辆选择采样和过滤策略，优先选择信息丰富和多样化的驾驶行为，从而提高训练数据集的质量。通过基于学习的规划器评估该策略，并展示了在复杂驾驶场景中的改进性能，特别是在减少碰撞率和提高安全指标方面。实现了即使使用原始数据集的10%，也能实现与完整数据集相当或超越的性能。研究还分析了选择标准，表明简单随机选择可能导致性能下降。
### Conclusion
通过使用多样化的实际驾驶轨迹数据，可提高模仿学习在自主驾驶中的效果，并为数据增强策略提供了新的见解。该研究还表明，即使在数据集较小的情况下，通过精心选择和过滤也能实现良好的性能。
## 920. `cs.LG` - 超越对数时间的一隐藏层神经网络中的混沌传播 [PDF](https://arxiv.org/pdf/2504.13110), [HTML](https://arxiv.org/abs/2504.13110)
### Authors
Margalit Glasgow,Denny Wu,Joan Bruna
### Background
该研究探讨了多项式宽度神经网络在均值场缩放状态下，使用投影梯度下降训练时，其动力学与无限宽度对应模型之间的近似差距。通过均值场动力学的微分方程，能够紧密地限制这一近似差距。研究特别关注了每个粒子的局部Hessian矩阵，它是粒子在均值场动力学中的速度对其位置的导数。研究将结果应用到了经典的特征学习问题——估计一个良好指定的单指数模型——证明了在这些问题中，只要粒子的局部海森矩阵与粒子速度成常数倍关系（具有某种“自我同心性”特征），即使用多项式的神经元数量就能在整个训练过程中紧密地逼近均值场动力学。
### Innovation
通过差分方程法研究神经网络动态过程中存在的近似差异，特别是针对 Localization Hessian 的定义和应用。证明在特定条件下（信息指数任意大时），可以使用多项式数量的神经元逼近无限宽度模型的动力学，实现了对混沌传播的深入理解，并拓宽了对神经网络行为的认识范围。
### Conclusion
研究表明，具有某种“自我同心性”的单指数模型问题，即使局部海森矩阵的限制在粒子速度上成立，多项式数量的神经元也足够在整个训练过程中紧密逼近均值场动力学。这种新的分析方法超越了过去的对数时间限制，展示了在复杂优化问题中的广义适用性。
## 921. `cs.LG` - EDBench：分子模型中大规模电子密度数据 [PDF](https://arxiv.org/pdf/2505.09262), [HTML](https://arxiv.org/abs/2505.09262)
### Authors
Hongxin Xiang,Ke Li,Mingquan Liu,Zhixiang Cheng,Bin Yao,Wenjie Du,Jun Xia,Li Zeng,Xin Jin,Xiangxiang Zeng
### Background
现有的分子机器学习力场（MLFFs）主要集中于学习原子、分子和简单量子化学性质，如能量和力，而忽略了电子密度（ED）$rho(r)$对其准确理解的重要性。ED描述了电子在原子或分子周围特定位置出现的概率，根据Hohenberg-Kohn定理，ED唯一地决定了相互作用多粒子系统的所有基态性质（如能量、分子结构等）。然而，计算ED依赖于耗时的原理密度泛函理论（DFT），导致缺乏大量电子密度数据，并限制了其在MLFFs中的应用。
### Innovation
该论文介绍了EDBench，一个大规模、高质量的电子密度数据集，旨在促进电子尺度的学习研究。EDBench 基于 PCQM4Mv2 构建，提供了覆盖330万种分子的精确ED数据。为了全面评估模型对电子信息的理解和利用能力，论文设计了一系列以ED为中心的基准任务，涵盖预测、检索和生成。论文证实了从EDBench学习不仅是可行的，而且具有高准确性。同时，基于EDBench的学习方法能够高效地计算ED，减少了相对于传统DFT计算的大量计算成本。
### Conclusion
所有来自EDBench的数据和基准都将免费提供，为基于电子密度驱动的药物发现和材料科学奠定坚实基础。
## 922. `cs.LG` - 身份不是可互换的：公平机器学习中过度概括的问题 [PDF](https://arxiv.org/pdf/2505.04038), [HTML](https://arxiv.org/abs/2505.04038)
### Authors
Angelina Wang
### Background
机器学习的核心价值在于其普适性，即使用相同的方法和模型架构可以在不同的领域和情境中运行。然而，这种普适性有时会过度泛化，忽略了具体情境的重要性。公平机器学习通常将不同形式的歧视（如种族主义、性别歧视、能见症歧视、年龄歧视等）视为可互换的，使用相同的方法进行测量和缓解。然而，不同形式的压迫在跨学科研究中显示出相似性和差异性，这意味着当前的公平机器学习方法需要更加关注具体的特殊情况。
### Innovation
本文探讨了公平机器学习中将不同形式的歧视视为可互换的问题，并指出这种类似处理方式在跨学科研究中被认为是有问题的，因为不同形式的歧视在某些方面存在本质差异。因此，本文提出需要更加关注这些特殊性，以深化我们对构建更公平系统的认识，并扩大包容未被考虑的伤害的范围，而不是盲目追求适应所有可能群体的方法，从而在一定程度上避免分析方法的无限多样化。
### Conclusion
最终，具体的上下文可以加深我们对如何建造更公平系统的理解，扩大我们考虑到当前忽视的危害范围，而且几乎可以反向限制对无限群体特定方法的担忧。公平机器学习领域需要增加对具体性的重视，以解决过度概括的问题。
## 923. `cs.LG` - 具有不确定性感知的潜在安全过滤器以避免分布外失败 [PDF](https://arxiv.org/pdf/2505.00779), [HTML](https://arxiv.org/abs/2505.00779)
### Authors
Junwon Seo,Kensuke Nakamura,Andrea Bajcsy
### Background
近年来，生成的世界模型使得传统的安全控制方法，例如哈密尔顿-雅可比（HJ）可达性方法，能够应用于直接从高维传感器观测中操作的复杂机器人系统。然而，在训练世界模型时获得所有安全关键场景的全面覆盖是非常具有挑战性的。因此，建立在这些模型之上的潜在安全过滤器可能会遗漏新的危险源，甚至可能不能预防已知的危险源，因为它可能会自信地将风险的分布外（OOD）情况错误地分类为安全。
### Innovation
为了解决这一问题，作者引入了一种具有不确定性感知的潜在安全过滤器，该过滤器可以主动避开已知和未知的失败情况。关键思想是使用世界模型的 epistemic 不确定性作为识别未见潜在危险的代理。为了检测分布外（OOD）世界模型预测，作者提出了一个校准不确定性阈值的原则方法，通过经验一致性预测进行校准。通过在扩展状态空间中执行可达性分析，即涵盖了潜在表示和 epistemic 不确定性的状态空间，作者综合了一个潜在安全过滤器，该过滤器可以可靠地防止已知和未知的安全危害。实验结果表明，作者的不确定性感知安全性滤波器可以提前检测潜在的不安全情况，并可靠地建议安全的、符合分布的行为。
### Conclusion
在以视觉控制任务为例的模拟和硬件实验中，基于弗兰卡操作器，作者展示了一种不确定性感知的安全性过滤器可以提前检测潜在的不安全情况，并可靠地建议安全的、符合分布的行为。
## 924. `cs.LG` - 视觉多模态大型语言模型中的文本接地研究 [PDF](https://arxiv.org/pdf/2504.04974), [HTML](https://arxiv.org/abs/2504.04974)
### Authors
Ming Li,Ruiyi Zhang,Jian Chen,Chenguang Wang,Jiuxiang Gu,Yufan Zhou,Franck Dernoncourt,Wanrong Zhu,Tianyi Zhou,Tong Sun
### Background
尽管已经存在多模态大型语言模型（MLLMs），但在视觉文本接地方面仍存在显著挑战，尤其是在文档类图像（如扫描表单和图示信息）中的文本丰富图像上。当前的基准测试并未充分解决这些问题，因为它们主要关注自然图像的视觉接地，而非文本丰富的文档图像。因此，为弥合这一差距，本文引入了TRIG（文本丰富图像接地）这一新任务及其设计的指令数据集，用于评估和提高MLLMs在文档问答中的文本丰富图像上的视觉文本接地能力。
### Innovation
本文提出了TRIG任务及其指令数据集，用于评估和提升MLLMs在文档问答中的文本丰富图像上的视觉文本接地能力。具体创新点包括：1. 提出了一种基于OCR-LLM-人工交互的管道，创建了800个手动注解的问答对作为基准数据集和基于四个不同数据集的大型合成训练数据集；2. 通过全面评估多种MLLMs在本文提出的基准测试上的性能，揭示了MLLMs在文本丰富图像上的视觉文本接地能力方面存在的显著不足；3. 提出了两种基于通用指令调优和插件式高效嵌入的简单而有效的TRIG方法；4. 通过在合成数据集上微调MLLMs，展示了其在空间推理和视觉文本接地能力上的显著提升潜力。
### Conclusion
我们的研究揭示了当前MLLMs在处理文本丰富的文档图像中的视觉文本接地能力的不足，并通过TRIG任务和合成数据集及其微调方法，预测了显著提升这些能力的可能性。
## 925. `cs.LG` - 小模型还是大模型？未微调还是微调？指导医疗保健中特定应用的语言模型选择 [PDF](https://arxiv.org/pdf/2504.21191), [HTML](https://arxiv.org/abs/2504.21191)
### Authors
Lovedeep Gondara,Jonathan Simkin,Graham Sayle,Shebnum Devji,Gregory Arbour,Raymond Ng
### Background
研究旨在通过电子病理报告数据探讨几种关键因素对语言模型选择的指导作用，包括微调与零样本使用的需求、领域相邻模型与通用预训练模型之间的优势、进一步的领域特定预训练的价值，以及小型语言模型与大型语言模型在特定任务中的相关性。
### Innovation
研究针对电子病理报告数据进行了三种不同难度和数据规模的分类实验，通过评估不同规模的语言模型（包括小模型和大模型）在零样本和微调情况下的表现，揭示了小型模型在专业化领域的关键作用，并表明预训练在领域相邻或特定领域的数据上提供了进一步的优势，特别是在复杂问题或数据有限的情况下。此外，研究还强调了微调对于小型模型在专业领域中的重要性，使得这些模型能够超越大模型的零样本性能，特别是在特定分类任务中。
### Conclusion
研究结果表明，对于特定任务，小型语言模型在微调后可以超越大型语言模型的零样本性能。特别是在资源受限和数据稀缺的情况下，进一步的领域特定预训练可以显著提升模型性能。尽管大型语言模型提供了强大的零样本能力，但它们在特定任务上的表现仍不如适当微调的小型语言模型。因此，在LSTM的时代，小型语言模型仍然具有相关性和有效性，并且可能提供优于大型语言模型的性能与资源折中。
## 926. `cs.LG` - 基于动态奖励尺度的逆强化学习在大规模语言模型对齐中的应用 [PDF](https://arxiv.org/pdf/2503.18991), [HTML](https://arxiv.org/abs/2503.18991)
### Authors
Ruoxi Cheng,Haoxuan Ma,Weixin Wang,Ranjie Duan,Jiexi Liu,Xiaoshuang Jia,Simeng Qin,Xiaochun Cao,Yang Liu,Xiaojun Jia
### Background
大规模语言模型的对齐对于安全部署至关重要。现有的方法包括基于奖励的方法（使用偏好对训练奖励模型并使用强化学习优化）和无奖励的方法（直接对排名结果进行微调）。近期研究表明，精心调优的基于奖励的方法依然具有鲁棒性，单响应示范也可以超越成对偏好数据的性能。然而，仍存在两个挑战：（1）不平衡的安全数据集，这些数据集过度代表常见的风险，但忽视了长尾威胁；（2）静态奖励模型不考虑任务难度，限制了优化效率和可实现的收益。
### Innovation
提出了一种名为DR-IRL（动态调整奖励通过逆强化学习）的新方法。首先，使用一个涵盖七种有害类别且平衡的安全数据集通过逆强化学习训练类别特定的奖励模型。然后，通过使用任务难度、文本编码余弦相似度和奖励差距来增强群相对策略优化。广泛的实验在各种基准和大规模语言模型上表明，DR-IRL方法在安全对齐方面优于所有基线方法，同时保持实用性。
### Conclusion
DR-IRL方法在安全对齐上表现出色，同时保持高效性和实用性，解决了现有方法中的数据不平衡和静态奖励模型无法适应任务难度的问题。
## 927. `cs.LG` - DISCO Balances the Scales: 调和尺度：针对不平衡数据的自适应领域和难度感知强化学习 [PDF](https://arxiv.org/pdf/2505.15074), [HTML](https://arxiv.org/abs/2505.15074)
### Authors
Yuhang Zhou,Jing Zhu,Shengyi Qian,Zhuokai Zhao,Xiyao Wang,Xiaoyu Liu,Ming Li,Paiheng Xu,Wei Ai,Furong Huang
### Background
大规模语言模型（LLMs）通过人类反馈强化学习（RLHF）越来越符合人类偏好。在RLHF方法中，组相对策略优化（GRPO）因其简单性和强大的性能而受到关注，尤其是无需学习价值函数。然而，GRPO隐含地假设了领域分布的平衡性和组间语义的一致性，这些假设在实际数据集上很少成立。应用到多领域的不平衡数据上时，GRPO过度优化了主导领域，忽视了未充分代表的领域，导致泛化能力差和公平性不足。
### Innovation
提出了领域启发式自我一致性策略优化（DISCO），这是一种GRPO的有原则的扩展方法，通过两个关键创新解决了群组间的不平衡。领域感知奖励缩放通过基于领域出现频率重新加权优化来抵制频率偏差。难度感知奖励缩放利用提示级别的自我一致性来识别并优先处理那些提供更大学习价值的不确定提示。这两种策略共同促进了跨领域更加公平和有效的策略学习。
### Conclusion
在多个LLM和偏斜训练分布的广泛实验中，DISCO提高了泛化能力，在Qwen3模型上的表现优于现有GRPO变体5%，并在多领域对齐基准上建立了新的最先进的结果。我们的代码和数据可以在以下链接获取：this https URL。
## 928. `cs.LG` - 通过分类学习隐藏的传播链 [PDF](https://arxiv.org/pdf/2505.11228), [HTML](https://arxiv.org/abs/2505.11228)
### Authors
Derrick Gilchrist Edward Manoharan,Anubha Goel,Alexandros Iosifidis,Henri Hansen,Juho Kanniainen
### Background
现有的社交网络传播动态研究通常假设个体状态（已知或受感染）是完全可观测的。然而，在许多现实情况下，这些状态仍然是不可观测的，这对确定个体进一步传播感染的能力至关重要。虽然最终状态是隐藏的，但中间指标（如感染症状）是可观察的，并为底层扩散过程提供有用的表示。因此，提出了一个考虑部分可观测性的机器学习框架，以学习传播模型的特征。这种方法利用分类器的强大功能来推断底层传播动态。
### Innovation
该研究提出了一个基于分类的框架，用于识别部分可观测性社交网络中的传播模式。该框架在广泛的基准测试中均优于当前最先进的方法（如近似贝叶斯计算和GNN基线），能够提供准确的参数估计，并且能够高效地扩展到大规模网络中。此外，该方法已在合成网络和实际的内部交易网络上进行了验证，证明了其在无法直接观察个体状态的情况下分析传播现象的有效性。
### Conclusion
提出的基于分类的学习框架可以有效推断出社交网络中部分可观测传播动态的特征，且在性能和效率方面优于现有的方法，具有广泛的应用前景。
## 929. `cs.LG` - Latent Wavelet Diffusion For Ultra-High-Resolution Image Synthesis [PDF](https://arxiv.org/pdf/2506.00433), [HTML](https://arxiv.org/abs/2506.00433)
### Authors
Luigi Sigillo,Shengfeng He,Danilo Comminiello
### Background
高分辨率图像合成仍然是生成模型的核心挑战，尤其是在保持精细视觉细节的同时保证计算效率。现有的技术在制作品质高、细节丰富的高分辨率图像时存在效率不足的问题。
### Innovation
提出了一种名为Latent Wavelet Diffusion (LWD)的轻量级训练框架，该框架能够在超高清（2K-4K）图像合成中显著提升细节和纹理保真度。LWD通过引入基于小波能量图的新型频率感知遮罩策略，动态关注潜在空间中的细节丰富区域，并通过尺度一致的VAE目标确保频谱保真度。
### Conclusion
LWD的主要优势在于其高效性：无需架构修改，并且在推理过程中的成本为零，是一种将现有模型扩展的实用方案。在多种基准模型中，LWD始终能提高感知质量和FID分数，展示了信号驱动监督作为提升高分辨率生成建模的有原则且高效方法的强大作用。
## 930. `cs.LG` - 理性的代理人在资源约束下的固有风险意识 [PDF](https://arxiv.org/pdf/2505.23436), [HTML](https://arxiv.org/abs/2505.23436)
### Authors
Daniel Jarne Ornia,Nicholas Bishop,Joel Dyer,Wei-Chen Lee,Ani Calinescu,Doyne Farmer,Michael Wooldridge
### Background
本文探讨了在资源或失败约束下，先进推理模型具备代理能力的AI代理（AI agent）如何通过与人类的互动来解决基于近似效用函数和内部模型的顺序决策问题。这些问题可能因资源耗尽而强制终止行动序列，这种情况下会导致代理面临显性和隐性的权衡，从而重塑其效用驱动（理性）行为。此外，由于这些代理通常由人类委托人委托为其代劳，约束暴露的不对称性可能会导致人类目标和代理激励之间的意想不到的不一致性。本文通过生存博弈框架的形式化，提供了理论和实证结果，量化了生存驱动的偏好转变的影响，并确定了不一致性出现的条件，同时提出了减少风险寻求或风险规避行为出现的机制。
### Innovation
本文通过生存博弈框架的形式化，研究了资源约束下代理人在效用驱动下的行为模式变化，并着重探讨了约束暴露不对称性带来的责任与激励的不一致性问题，提出了解决这类问题的机制，增加了对在资源受限环境下运行的AI代理出现行为的了解和可解释性，为在关键资源受限环境中安全部署这类AI系统提供了指导。
### Conclusion
本文旨在增加对在生存压力下的AI代理人行为的理解和可解释性，并提供了在资源受限环境中安全部署这些AI系统的指南。通过生存驱动的偏好转变及其对行为影响的理论和实证结果，本文不仅有助于理解AI代理人的行为，也提出了相应的缓解措施，从而提升了AI系统在特殊环境下的安全性。
## 931. `cs.LG` - 是否信任您的Vision-Language模型预测 [PDF](https://arxiv.org/pdf/2505.23745), [HTML](https://arxiv.org/abs/2505.23745)
### Authors
Hao Dong,Moru Liu,Jian Liang,Eleni Chatzi,Olga Fink
### Background
Vision-Language模型展示了在视觉和文本模态对齐方面的强大能力，广泛应用于多模态理解和生成。这些模型在零样本和迁移学习场景中表现出色，但在安全性关键领域，如自动驾驶或医疗诊断，可能因为模型的误分类而产生严重的后果。误分类的高置信度预测使得在这些场景中的应用存在显著风险。
### Innovation
本文介绍了一种无需训练的框架TrustVLM，旨在解决Vision-Language模型预测是否可信的关键问题。通过利用图像嵌入空间中特定概念的更明显表示，TrustVLM提出了一个新的置信度评分函数，旨在提高误分类检测能力。实验结果表明，在17个不同数据集上，TrustVLM在AURC、AUROC和FPR95指标上分别取得了最高51.87%、9.14%和32.42%的提升。
### Conclusion
TrustVLM通过提高模型的可靠性而无需重新训练，为在实际应用中安全部署Vision-Language模型铺平了道路。该研究代码已公开可用。
## 932. `cs.LG` - 使用方差信号检测token级幻觉：一种无需参考的方法 [PDF](https://arxiv.org/pdf/2507.04137), [HTML](https://arxiv.org/abs/2507.04137)
### Authors
Keshav Kumar
### Background
大型语言模型（LLMs）在各种任务中展现出了惊人的生成能力，但仍然容易产生幻觉，即模型自信生成但事实上错误的输出。现有的幻觉检测方法依赖于标准参考或句子级别的验证，这限制了它们的应用范围。本文提出了一种无需参考的token级幻觉检测框架，该框架利用多个随机生成过程中token log概率的方差。这种检测方法相对于现有方法具有模型无关性、可解释性和适合实时或事后分析的优点。
### Innovation
本文介绍了一种无需参考的token级幻觉检测框架，该框架利用多个随机生成过程中token log概率的方差变化来检测幻觉。这种检测方法适用于多种规模的自回归模型，并通过定量指标和可视化诊断证明了token级方差能够可靠地揭示模型输出的不稳定性，并且与幻觉模式相关。
### Conclusion
本文提出的方法具有轻量、可重复性及多领域适应性的特点，为分析LLMs的生成可靠性提供了有价值诊断工具。该方法通过定量指标和可视化诊断证实了其有效性和实用性。
## 933. `cs.LG` - 干预黑盒：增强人神经网络相互理解的概念瓶颈模型 [PDF](https://arxiv.org/pdf/2506.22803), [HTML](https://arxiv.org/abs/2506.22803)
### Authors
Nuoye Xiong,Anqi Dong,Ning Wang,Cong Hua,Guangming Zhu,Lin Mei,Peiyi Shen,Liang Zhang
### Background
近年来深度学习取得了显著进步，模型变得越来越复杂，层数更深，参数更多，这虽然提升了模型的性能，但降低了模型的可解释性，使其决策难以理解。尽管许多方法试图解释黑盒模型的决策过程，但大多数方法在干预模型时效果有限，要么仅在样本层面操作而不修改模型本身，要么无法有效干预潜在的概念层面。
### Innovation
本文提出了一种新的方法——增强人类与神经网络相互理解的概念瓶颈模型（CBM-HNMU）。该方法利用可解释的框架——概念瓶颈模型（CBM），以近似黑盒模型的决策并传达概念理解。通过自动识别和改进（移除或替换）对整体梯度贡献度低的危害性概念，修改后的CBM能纠正知识并反馈到黑盒模型中，从而提升模型的可解释性和准确性。
### Conclusion
在Flower-102、CIFAR-10、CIFAR-100、FGVC-Aircraft和CUB-200等不同数据集上对CBM-HNMU进行评估，结果显示该模型能够显著提高准确率，最高可达2.64%，同时平均准确率也提升了1.03%。
## 934. `cs.LG` - GRaFT: 图表和表的推理——一种结构化指令遵循和视觉推理基准 [PDF](https://arxiv.org/pdf/2508.15690), [HTML](https://arxiv.org/abs/2508.15690)
### Authors
Abhigya Verma,Sriram Puttagunta,Seganrasan Subramanian,Sravan Ramachandran
### Background
目前存在对模型在指令遵循、视觉推理和视觉文本对齐任务方面的评估需求，但缺乏一个结构化多模态基准来系统地评估这些能力，特别是缺乏控制数据语义、结构和清晰度的手段。
### Innovation
GRaFT 提供了一个结构化的多模态基准，包含程序生成的图表和合成渲染的表格，通过 Python 可视化库确保数据的清晰和结构化。每个 GRaFT 实例都与根据视觉内容系统生成的多步骤分析问题相匹配，并提供结构化格式的答案，如 JSON 或 YAML，以实现一致的评估。此外，GRaFT 引入了一种推理类型的分类，包括比较、趋势识别、排名、聚合、比例估算和异常检测，为全面评估提供依据。参考答案遵循严格的事实和排版要求，以实现精确、基于方面评估。
### Conclusion
GRaFT 提供了一个多模态模型在视觉接地的结构化推理任务中的细粒度基准测试框架，设定了该领域的新的评估标准。
## 935. `cs.LG` - NERO：基于神经元级相关性的可解释离群点检测 [PDF](https://arxiv.org/pdf/2506.15404), [HTML](https://arxiv.org/abs/2506.15404)
### Authors
Anju Chhetri,Jari Korhonen,Prashnna Gyawali,Binod Bhattarai
### Background
在医疗影像领域，保证深度学习模型的可靠性至关重要。诊断决策往往依赖于模型的输出，因此能够区分离分布（OOD）样本是评估模型可靠性的重要指标。特别是在医疗影像中，识别OOD输入可以帮助发现潜在的未检测异常。尽管许多OOD检测方法依赖于特征或逻辑空间的表示，但最近的研究表明，这些方法可能无法完全捕捉OOD的多样性。为解决这一问题，本文提出了一种名为NERO的新颖OOD评分机制，该机制利用特征层的神经元级别相关性。
### Innovation
NERO通过在特征层对每个在分布（ID）类的神经元级别相关性进行聚类，并引入相关性距离度量来量化新样本与这些代表质心的偏差，增强了OOD的可区分性。此外，通过在偏差项中引入缩放相关性和结合特征范数来进一步优化性能。该框架还支持可解释的OOD检测。实验表明，NERO在多个深度学习架构上实现了对现有先进OOD检测方法的改进，特别是在胃肠道影像基准Kvasir和GastroVision上。
### Conclusion
本文提出了一种基于神经元级别相关性的可解释OOD检测机制——NERO。通过在特征层利用神经元级别相关性，NERO增强了OOD样本的可区分性，并通过引入新的评分机制和优化策略提升了整体性能。该方法在多个医疗影像领域实验中展示了优于现有方法的优越性。
## 936. `cs.LG` - 机器学习时间推进器用于时变密度泛函理论模拟 [PDF](https://arxiv.org/pdf/2508.16554), [HTML](https://arxiv.org/abs/2508.16554)
### Authors
Karan Shah,Attila Cangi
### Background
时变密度泛函理论（TDDFT）被广泛用于研究在外加时间依赖的扰动（如激光场）下的电子动力学。传统的数值求解器在模拟这些过程时通常计算速度较慢。
### Innovation
该工作提出了一种利用自回归神经运算符作为时间推进器的机器学习方法，用于基于实时光学时变密度泛函理论的电子动力学模拟。通过利用物理信息约束、特征化以及高分辨率的训练数据，该模型在计算精度和速度方面显著优于传统的数值求解器。
### Conclusion
该研究展示了利用快速机器学习预测在各种激光实验参数变化的大空间中的飞秒激光辐射分子和材料建模的有效性。
## 937. `cs.LG` - The Open DAC 2025 Dataset for Sorbent Discovery in Direct Air Capture [PDF](https://arxiv.org/pdf/2508.03162), [HTML](https://arxiv.org/abs/2508.03162)
### Authors
Anuroop Sriram,Logan M. Brabson,Xiaohan Yu,Sihoon Choi,Kareem Abdelmaqsoud,Elias Moubarak,Pim de Haan,Sindy Löwe,Johann Brehmer,John R. Kitchin,Max Welling,C. Lawrence Zitnick,Zachary Ulissi,Andrew J. Medford,David S. Sholl
### Background
直接从潮湿空气中捕获CO₂仍然是一个挑战，尤其是在有效吸收剂材料的识别方面。此前的ODAC23数据集包含了一些计算结果，但规模较小且不够准确。因此，本研究旨在建立一个更全面、更准确的数据集ODAC25来支持直接空气捕获技术的发展。
### Innovation
- 扩展和改进ODAC23数据集，包含近6000万的DFT计算点，涵盖15000种MOF（多孔有机框架），吸附CO₂、H₂O、N₂和O₂。- 引入了功能化MOF、高能GCMC（广义配分函数蒙特卡洛）衍生的放置方式以及合成生成的框架，增加了化学多样性和配置多样性。- 显著提高了DFT计算的准确性和对柔性MOF处理的准确性，同时发布了基于ODAC25训练的新一代机器学习原子间势能模型，提升了吸附能和亨利定律系数预测准确性。
### Conclusion
ODAC25数据集为直接空气捕获技术中吸收剂材料的发现提供了强有力的支持，通过引入新的数据集和模型，推动了该领域的进一步研究和进展。
## 938. `cs.LG` - 拉伸聚酯的振动特征：一种用于预测机械状态的光谱途径 [PDF](https://arxiv.org/pdf/2509.16266), [HTML](https://arxiv.org/abs/2509.16266)
### Authors
Julian Konrad,Janina Mittelhaus,David M. Wilkins,Bodo Fiedler,Robert Meißner
### Background
聚合物网络在负载下的振动响应提供了一种对分子变形的敏感探测手段，并提供了非破坏性诊断的方法。这项研究展示了机器学习力场在真实的环氧热固性树脂中以量子级精度模拟这些光谱指纹的能力。
### Innovation
本研究使用MACE-OFF23分子动力学模拟，再现了在拉伸负载下对位苯撑拉伸模式的实验观测到的红移，这与经典的OPLS-AA模型形成了对比。同时，通过训练对称适应偶极矩模型来捕捉红外强度，从而验证了应力反应，并且通过振动特征直接关联局部应力，实现了机械状态的化学精确预测和计算访问。
### Conclusion
研究结果建立了振动指纹作为预测聚合物网络机械状态的标志物，进一步指出了在先进材料中应力映射和结构健康诊断的新策略。
## 939. `cs.LG` - CUPID: 使用影响函数曲拥您所需的机器人数据 [PDF](https://arxiv.org/pdf/2506.19121), [HTML](https://arxiv.org/abs/2506.19121)
### Authors
Christopher Agia,Rohan Sinha,Jingyun Yang,Rika Antonova,Marco Pavone,Haruki Nishimura,Masha Itkina,Jeannette Bohg
### Background
在机器人模仿学习中，策略的表现与演示数据的质量和组成紧密相关。然而，如何理解单个演示对下游结果（例如闭环任务的成功与否）的具体影响仍是一个持续的挑战。
### Innovation
提出了一种基于新颖的影响函数理论公式来定义模仿学习策略的CUPID机器人数据管理方法。该方法能够估计每个训练演示对策略预期回报的影响，通过这样的机制可以对演示进行排序和选择，以便根据它们对策略闭环性能的影响进行优化。此外，该方法还可以通过筛选有害演示和精选新的改进演示来优化数据集，从而提高策略性能。
### Conclusion
大量仿真和硬件实验表明，CUPID方法能够一致地识别出对测试时性能起驱动作用的数据。例如，在仿真RoboMimic基准测试中使用不到33%的精选数据即可达到最先进的扩散策略性能，硬件实验也显示该方法能够识别出稳健策略、隔离伪相关性，并在通用机器人策略训练后提升性能。
## 940. `cs.LG` - 通过残差量化赋予预排名目标注意 [PDF](https://arxiv.org/pdf/2509.16931), [HTML](https://arxiv.org/abs/2509.16931)
### Authors
Yutong Li,Yu Zhu,Yichen Qiao,Ziyu Guan,Lv Shao,Tong Liu,Bo Zheng
### Background
工业推荐系统在预排名阶段面临效率与效果之间的根本冲突。虽然像Target Attention (TA)这样的强大模型在排序阶段能够很好地捕捉复杂的特征交互，但它们的高计算成本使其在预排名阶段不可行，预排名通常依赖于简单的向量乘积模型。这种差异造成了整个系统性能的关键瓶颈。
### Innovation
本文提出了一种名为TARQ的新型预排名框架。TARQ的关键创新之处在于通过残差量化的方式赋予预排名一个类似于TA的架构，从而首次将TA的建模能力引入到对延迟要求极高的预排名阶段，实现了精度和效率之间的全新权衡。
### Conclusion
通过离线实验和淘宝的大型在线A/B测试，TARQ在排序性能上展现了显著的改进。因此，该模型已在生产环境中全面部署，为数千万活跃用户提供服务，并取得了实质性的业务改进。
## 941. `cs.LG` - 通过生成具备侧特征意识的虚假用户资料欺骗推荐系统 [PDF](https://arxiv.org/pdf/2509.17918), [HTML](https://arxiv.org/abs/2509.17918)
### Authors
Yuanrong Wang,Yingpeng Du
### Background
推荐系统（RS）对用户的消费决策有着深刻影响，因此成为恶意刷评攻击的目标。现有的刷评方法能够在只有评分矩阵的训练数据下生成有效的、难以察觉的虚假用户资料，但当推荐系统利用其他侧特征时，这些方法缺乏全面解决方案。
### Innovation
扩展Leg-UP框架，增强生成器架构以整合侧特征，从而生成具有侧特征意识的虚假用户资料。
### Conclusion
实验表明，该方法在攻击效果强的同时保持了足够的隐蔽性。
## 942. `cs.LG` - 用于多变量地下生成和高效概率反演的扩散模型 [PDF](https://arxiv.org/pdf/2507.15809), [HTML](https://arxiv.org/abs/2507.15809)
### Authors
Roberto Miele,Niklas Linde
### Background
扩散模型适用于深度生成建模任务，并提供稳定训练和最先进的性能。本文探讨了扩散模型在多变量地下建模和概率反演中的应用。文章首先表明扩散模型相比变分自编码器和生成对抗网络增强多变量建模能力。扩散模型中的生成过程包括了一系列时间步骤，可以通过修改更新规则来考虑条件数据。
### Innovation
文章提出了对扩散后验采样方法的不同修正，尤其是引入了考虑到扩散建模固有噪声污染的似然性近似。此外，通过局部硬数据（井资料）和非线性地球物理学（全栈地震数据）进行条件建模，展示了显著提升的统计稳健性、后验概率密度函数的增强抽样和降低的计算成本。
### Conclusion
该方法可以使用硬和间接条件数据进行反演，无论是单独使用还是同时使用。由于反演包含在扩散过程中，该方法比需要在生成模型外层循环的其他方法（如马尔可夫链蒙特卡罗）更快。
## 943. `cs.LG` - 基于预训练模型的类增量学习中的噪声混合 [PDF](https://arxiv.org/pdf/2509.16738), [HTML](https://arxiv.org/abs/2509.16738)
### Authors
Kai Jiang,Zhengyan Shi,Dell Zhang,Hongyuan Zhang,Xuelong Li
### Background
类增量学习（CIL）的目标是在学习新类别时保留旧知识。预训练模型（PTMs）在CIL中显示出有希望的能力。但现有的通过轻量级微调来调整骨干网络的方法仍然会导致参数漂移，从而损害预训练模型的泛化能力。参数漂移可以被视为一种噪声，它会掩盖前任务中学习的关键模式。然而，最近的研究表明，噪声并非始终有害。例如，从预训练中学到的大量视觉模式很容易被单个任务滥用，引入适量的噪声可以抑制一些低相关特征，从而为未来任务留下余地。
### Innovation
本文提出了一种通过信息论指导学习有益噪声的方法，并提出了一种称为噪声混合（Min）的方法，旨在减轻由于适应新任务而导致骨干网络泛化能力下降的问题。具体而言，Min 从新任务的高维特征中学习任务特定的噪声；动态调整一组权重以最佳地混合不同任务的噪声；最后，Min 将有益噪声嵌入到中间特征中，以掩盖无效模式的响应。广泛实验表明，Min 在大多数增量设置中达到了最先进的性能，特别是在50步增量设置中表现尤为出色，这展示了有益噪声在连续学习中的显著潜力。
### Conclusion
Min 在大多数增量设置中实现了最先进的性能，尤其在50步增量设置中表现突出，表明了有益噪声在连续学习中的潜力，代码已在指定网址提供。
## 944. `cs.LG` - CLOTHO: 评估LLM输入特定任务预生成测试完善性的方法 [PDF](https://arxiv.org/pdf/2509.17314), [HTML](https://arxiv.org/abs/2509.17314)
### Authors
Juyeon Yoon,Somin Kim,Robert Feldt,Shin Yoo
### Background
软件越来越依赖于大型语言模型（LLMs）的能力，从自然语言理解到程序分析和生成。然而，对这些模型进行特定任务的测试仍然困难且成本高昂：许多提示没有绝对的真实标准，迫使依赖人类判断，而现有的不确定性和充分性度量通常需要完整推理。一个关键挑战是在生成任何输出之前评估输入的充分性，以反映任务的需求。CLOTHO 提出了一个特定于任务的、预生成的充分性度量方法，该方法直接从隐藏的LLM状态中估计输入的难度。该方法利用高斯混合模型（GMM）从大量未标记的特定任务输入池中自适应地抽取最具信息性的案例供人类标注，以评估输入的失败概率。
### Innovation
CLOTHO通过直接从隐藏的LLM状态中估计输入的难度，提出了一种特定任务、预生成的充分性度量方法。它使用高斯混合模型（GMM）自适应地从大量未标记的输入中抽取最具信息性的案例供人类标注，并基于此参考集对未知输入进行排名，评估其失败的可能性。这种方法在生成任何输出之前评估输入的充分性，比现有的不确定性测量方法减少成本，同时展示了开放权重模型和专有模型之间学习充分性得分的有效转移。
### Conclusion
在不对新数据进行生成的情况下，CLOTHO能够预测8个基准任务和三个开源模型中输入的失败，并显示出相对于随机优先级提高测试输入中失败输入的比例。此外，CLOTHO能够有效地从开放权重模型学习到专有模型的充分性得分，从而扩大了这种方法的应用范围。
## 945. `cs.LG` - MOIS-SAM2: 基于范例的 Segment Anything Model 2 用于全身MRI中多病灶神经纤维瘤分割 [PDF](https://arxiv.org/pdf/2509.19277), [HTML](https://arxiv.org/abs/2509.19277)
### Authors
Georgii Kolokolnikov,Marie-Lena Schmalhofer,Sophie Goetz,Lennart Well,Said Farschtschi,Victor-Felix Mautner,Inka Ristow,Rene Werner
### Background
神经纤维瘤病1型是一种遗传性疾病，其特征是全身多个神经纤维瘤（NFs）的发育。全身MRI（WB-MRI）是临床用于检测和长期监控NF肿瘤生长的标准方法。现有的交互式分割方法无法在保持单个病灶精度的同时，扩展应用于数百个病灶。
### Innovation
本文提出了一种新的交互式分割模型MOIS-SAM2，该模型在最先进的基于transformer的可提示Segment Anything Model 2 (SAM2) 中加入基于范例的语义传播。该模型在包含84名NF1患者的119个WB-MRI扫描上进行了训练和评估，并展示了在不同的MRI场景中的鲁棒性和可解释性。
### Conclusion
所提出的MOIS-SAM2能够在最少用户输入的情况下高效且可扩展地对全身MRI中的NFs进行交互式分割，并具有强大的通用性，支持临床工作流程的整合。
## 946. `cs.LG` - CogAtom: 从认知原子到大型语言模型中的奥林匹克级数学推理 [PDF](https://arxiv.org/pdf/2509.17318), [HTML](https://arxiv.org/abs/2509.17318)
### Authors
Zhuofan Chen,Jiyuan He,Yichi Zhang,Xing Hu,Haoxing Wen,Jun Bai,Wenge Rong
### Background
数学推理对大型语言模型（LLMs）提出了显著挑战，因为这需要多步推理和抽象概念的整合。尽管最近的测时扩展技术依赖于高质量的挑战性问题，但奥数级别数学问题的稀缺性仍然是一个瓶颈。现有方法主要通过人工编制的高难度问题来构建测试样本，但这一过程耗时耗力且难以大规模扩展。因此，如何高效生成多样化、高质量和结构复杂度高的数学问题成为一个亟待解决的问题。
### Innovation
本文介绍了一种名为CogAtom的新颖认知原子（cognitive atoms）为基础的框架，用于合成数学严谨且认知多样性的问题。CogAtom将问题构建视为选择和重组来自人类解决方案的基本推理单元（cognitive atoms）的过程。一种促进多样性的随机漫步算法促进了认知原子空间的探索，同时基于约束的重组机制确保逻辑有效性和结构完整性。这种图结构的组合性提供了几乎无限的推理路径，随机漫步算法系统地探索这个空间以实现高质量问题的大规模合成；通过控制认知原子的数量，可以精确调整问题难度，确保生成的问题具有多样性和可扩展性。实验结果表明，CogAtom在准确性、推理深度和多样性方面优于现有方法，生成的问题与AIME的难度相当但在结构多样性上超越了AIME。
### Conclusion
我们的工作提供了一条认知根植的途径，以实现可扩展和高质量的数学问题生成。CogAtom在此基础上提高了大型语言模型的数学推理能力，并提供了公开可获取的代码以供进一步研究和应用。
## 947. `cs.LG` - PolypSeg-GradCAM: 使用基于U-Net分割和Grad-CAM可视化在Kvasir数据集上的可解释计算机辅助胃肠道疾病检测 [PDF](https://arxiv.org/pdf/2509.18159), [HTML](https://arxiv.org/abs/2509.18159)
### Authors
Akwasi Asare,Ulas Bagci
### Background
结肠直肠癌（CRC）是全球癌症相关发病率和死亡率的主要原因之一。胃肠道（GI）息肉是WHO认定的关键前体。在结肠镜检查中，对息肉进行早期和准确的分割对于减少CRC进展至关重要。然而，手动勾勒出息肉过程劳动密集且容易产生观察者间变异。尽管深度学习方法在自动息肉分析方面展现了强大的潜力，但由于其有限的可解释性，临床应用仍受到限制。这项研究旨在解决这一问题，提供一种可解释的深度学习框架PolypSeg-GradCAM，通过将U-Net架构与Grad-CAM相结合实现透明息肉分割，同时进行了一系列实验验证其性能并在Kvasir-SEG数据集上训练和评估，证明其在测试集上的交并比IoU达到了0.9257，训练和验证集上的Dice系数（F-score）超过0.96。进而通过Grad-CAM可视化确认预测是由临床相关区域引导的，增强了模型决策的透明度和信任度。
### Innovation
PolypSeg-GradCAM引入了一种解释性强的深度学习框架，结合了U-Net架构和Grad-CAM，可以实现透明的息肉分割，提高了对息肉位置和大小的自动识别能力，并且能够可视化预测过程中的关键区域，增强了临床医生对模型决策的信任度。这种方法克服了现有深度学习模型在解释性上的局限，有助于实现可靠的、值得信赖的计算机辅助结肠镜检查，并改善早期结直肠癌的预防。
### Conclusion
通过结合高分割准确性和可解释性，PolypSeg-GradCAM为可靠的、可信的AI辅助结肠镜检查和早期结直肠癌预防朝着正确的方向迈进。
## 948. `cs.SE` - 自动插入刷新和栅栏以确保持久性 [PDF](https://arxiv.org/pdf/2509.19459), [HTML](https://arxiv.org/abs/2509.19459)
### Authors
Yutong Guo,Weiyu Luo,Brian Demsky
### Background
CXL共享内存和持久内存允许内存内容在系统崩溃后仍然存在。向持久或CXL内存的数据存储通常不会立即持久化；开发人员必须手动刷新对应的缓存行以强制数据写入底层存储。正确使用刷新和栅栏操作已知具有挑战性。尽管最先进的工具可以找到遗漏的刷新指令，但它们通常需要可以揭示错误的测试用例。没有现有工具能够确保不存在遗漏的刷新错误。为了解决这个问题，该论文提出了一种名为PMRobust的编译器，它会自动插入刷新和栅栏操作，以确保使用持久内存的代码不包含遗漏的刷新和栅栏错误。PMRobust使用了一种新颖的静态分析方法，针对新分配的对象进行了优化。
### Innovation
PMRobust是一种自动插入刷新和栅栏操作的编译器，它能够确保使用持久内存的代码不包含遗漏的刷新和栅栏错误。论文介绍了一种新颖的静态分析方法，并对持久内存库和多种持久内存数据结构进行了评估，显示相对增加的平均开销仅为0.26%。这项工作的创新点在于其能够自动确保持久内存代码的正确性，而不依赖于手动操作或特定测试用例的发现。
### Conclusion
PMRobust通过自动插入刷新和栅栏操作，确保了使用持久内存的代码的正确性，并显著减少了人工干预的需要。此外，通过新型静态分析，PMRobust为未来的持久内存优化提供了新的可能性。
## 949. `cs.SE` - 使用大型语言模型从代码中反向工程用户故事 [PDF](https://arxiv.org/pdf/2509.19587), [HTML](https://arxiv.org/abs/2509.19587)
### Authors
Mohamed Ouf,Haoyu Li,Michael Zhang,Mariam Guizani
### Background
在敏捷开发过程中，用户故事至关重要，但在遗留系统和文档不良的系统中，这些用户故事往往缺失或过时。研究发现，大型语言模型（LLMs）能够直接从源代码中自动恢复用户故事，但不同提示设计对输出质量的影响不同。
### Innovation
本文通过使用1,750个不同复杂性的C++代码片段对五种最先进的LLMs在六种提示策略下的表现进行了评估。结果显示，所有模型对至200行代码的平均F1分数为0.8。研究发现，单个示例示例可以使得最小的模型（8B）达到与70B模型相同的性能。相比之下，通过链式思考结构化推理仅对大模型有边际优势。
### Conclusion
研究揭示了在自动从代码恢复用户故事的任务中，提示设计的重要影响，并展示了小型模型在适当提示下的强大性能。
## 950. `cs.SE` - 具有语义感知的模糊测试：一种基于LLM引导的推理驱动输入突变的实证框架 [PDF](https://arxiv.org/pdf/2509.19533), [HTML](https://arxiv.org/abs/2509.19533)
### Authors
Mengdi Lu,Steven Ding,Furkan Alaca,Philippe Charland
### Background
物联网设备、移动平台和自主系统的安全漏洞仍然至关重要。传统的基于变异的模糊测试虽然能够有效地探索代码路径，但主要在字节或位级别进行修改，缺乏语义推理。虽然覆盖率指导工具如AFL++使用字典、语法和接合启发式来施加浅层结构约束，但仍未解决深层协议逻辑、字段间的依赖关系和领域特定语义问题。相比之下，具备推理能力的大型语言模型（LLMs）能够利用预训练知识理解输入格式、遵守复杂约束，并提出有针对性的变异，类似经验丰富的逆向工程师或测试专家。然而，缺乏“正确”变异推理的真实性使得监督微调难以实现，促进了基于指令的少量示例学习对现成LLM的探索。
### Innovation
本文提出了一种开源微服务框架，将具备推理能力的LLMs与AFL++结合，应对LLMs和模糊测试器之间异步执行和硬件需求差异。作者通过实证研究回答了四个主要研究问题：(R1) 如何将推理LLMs集成到模糊测试变异循环中？(R2) 少量示例提示是否能够产生高质量的变异？(R3) 是否可以通过现成模型的指令工程直接改进模糊测试？(R4) 在仅指令条件下，哪种开源推理LLM表现最佳？实验使用了Llama3.3、Deepseek-r1-Distill-Llama-70B、QwQ-32B和Gemma3四个模型，显示Deepseek模型表现最优。突变效果更多取决于提示复杂度和模型选择，而非示例数量。
### Conclusion
针对仅指令条件下模糊测试的实现，研究提出了一个实证框架，为LLM引导的推理驱动输入变异提供了新思路。通过实验证明，尽管存在响应延迟和吞吐量瓶颈，但该框架仍能有效提升模糊测试性能。未来的研究可进一步优化这方面的性能瓶颈。
## 951. `cs.SE` - 从直感到证据：衡量AI对开发人员生产力真实影响 [PDF](https://arxiv.org/pdf/2509.19708), [HTML](https://arxiv.org/abs/2509.19708)
### Authors
Anand Kumar,Vishal Khare,Deepak Sharma,Satyam Kumar,Vijay Saini,Anshul Yadav,Sachendra Jain,Ankit Rana,Pratham Verma,Vaibhav Meena,Avinash Edubilli
### Background
随着AI技术的发展，越来越多的企业开始尝试使用AI辅助软件开发工具来提升开发效率和质量。然而，目前对于这些工具的真实影响缺乏系统的、大规模的实证研究，特别是在实际生产环境中其效果和部署挑战尚不明确。因此，本研究通过一年的实际运行评估，在300名开发工程师的多个团队中测试了一款名为DeputyDev的企业内部AI平台的集成情况，旨在提供更为可靠的数据支持。
### Innovation
本研究采用了一种长期追踪分析的方法，不同于以往的控制基准评估，提供了来自生产环境的实证证据，证明了将AI集成到企业级软件开发流程中的潜力及其实际部署中的挑战。通过对开发团队的持续观察和数据分析，首次系统性地展示了使用AI工具的开发人员在代码审查等环节的实际效能提升情况，特别是在代码仓库中的活跃度和产出量方面取得了显著成果。
### Conclusion
研究表明，AI辅助工具显著提高了软件开发者的生产力，例如在代码审查环节将审查周期时间减少了31.8%，同时用户满意度也较高。此外，采用系统的部署方法有助于最大化AI工具的优势，尽管存在一定的挑战，但这些发现为进一步探索AI在企业软件开发中的应用提供了有力依据。
## 952. `cs.SE` - 跨越语言障碍：多语言代码生成的多智能体协调 [PDF](https://arxiv.org/pdf/2509.19918), [HTML](https://arxiv.org/abs/2509.19918)
### Authors
Micheline Bénédicte Moumoula,Serge Lionel Nikiema,Albérick Euraste Djire,Abdoul Kader Kabore,Jacques Klein,Tegawendé F. Bissyande
### Background
随着今天的软件系统建立在异构架构上，跨多种编程语言生成高质量代码变得越来越重要。尽管大型语言模型（LLMs）在自动化编程方面取得了进展，但在不同语言中，尤其是在训练数据有限的语言（如Rust、Perl、OCaml和Erlang）上，它们的专业能力差异很大。目前许多解决方案仍然对每个目标语言进行独立处理，未能共享知识或利用跨语言模式的反复出现。现有的方法包括语言特定的微调、多智能体统筹、迁移学习和中间表示管道，但它们往往忽视了跨语言协作的机会。
### Innovation
XL-CoGen采用了一种协调的多智能体架构，整合了中间表示、代码生成、翻译和自动化修复。它的独特之处在于一种数据驱动的桥梁语言选择机制：经验提取的转移矩阵根据翻译成功的表现来确定最佳中间语言而不是仅基于生成准确度。系统进行早期输出验证，迭代地纠正错误，并重新使用中间制品作为后续翻译的语境支撑。
### Conclusion
广泛的实验显示，XL-CoGen在最强的微调基线下带来了显著改进，达到了13个百分点的提升，并且在现有单语言多智能体方法上最多达到30个百分点的提升。消融实验进一步证明了基于兼容性的桥梁语言选择显著优于基于LLM的启发式方法，这验证了跨语言知识转移的价值。
## 953. `cs.SE` - 使用大型语言模型（LLMs）生成代码断言消息 [PDF](https://arxiv.org/pdf/2509.19673), [HTML](https://arxiv.org/abs/2509.19673)
### Authors
Ahmed Aljohani,Anamul Haque Mollah,Hyunsook Do
### Background
单元测试中的断言消息可以清晰解释测试失败的原因，但开发者和自动化测试生成工具常常忽略它们。尽管最近取得了进展，但尚未系统地评估大型语言模型（LLMs）生成有意义断言消息的能力。研究人员评估了四种最先进的Fill-in-the-Middle（FIM）LLMs（Qwen2.5-Coder-32B、Codestral-22B、CodeLlama-13B、StarCoder）在包含开发人员断言消息的216个Java测试方法数据集上的表现。研究发现，Codestral-22B的人类评价得分为2.76，不及手工编写的3.24。进一步分析表明，包含描述性测试注释可改善Codestral的表现，得分为2.97，显示出上下文在生成清晰断言消息中的关键作用。结构分析显示所有模型经常复制开发者的语言模式，但研究也指出了模型和传统文本评估指标的局限性，未能捕捉到断言消息的多样性结构。研究结果为推进测试代码中的自动化、上下文感知断言消息生成奠定了重要基础，并提供了基准测试、评估结果和讨论。
### Innovation
研究创新性地使用了四种最先进的FIM LLMs来生成断言消息，并通过人类评价的方式对生成的断言消息进行质量评估，揭示了模型生成断言消息的质量和上下文的重要性。研究还展示了结构分析结果，表明所有模型都频繁地复制开发者的语言模式，并且讨论了评估模型的局限性。研究提供了一个基准测试套件、评估结果和讨论，为未来的相关研究奠定了重要基础。
### Conclusion
该研究评估了LLMs生成断言消息的能力，发现Codestral-22B在人类评价中表现出最好的质量，但其性能仍不及手工编写的消息。包括描述性测试注释可以改善表现。所有模型复制了开发者的语言模式，但模型和传统评估方法无法完全捕捉断言消息的结构多样性。研究结果提供了重要的基准测试、评估结果和讨论，为推进自动化的、上下文感知的断言消息生成奠定了基础。
## 954. `cs.SE` - V-GameGym：用于代码大型语言模型的可视化游戏生成 [PDF](https://arxiv.org/pdf/2509.20136), [HTML](https://arxiv.org/abs/2509.20136)
### Authors
Wei Zhang,Jack Yang,Renshuai Tao,Lingzheng Chai,Shawn Guo,Jiajun Wu,Xiaoming Chen,Ganqu Cui,Ning Ding,Xander Xu,Hu Wei,Bowen Zhou
### Background
现有的代码大型语言模型在编程任务中展现了显著的能力，但现有的基准测试多关注单一模态而忽视了视觉游戏开发的需求。大多数现有的代码相关基准测试侧重于语法规则正确性和执行准确性，而忽略了游戏特定的指标，如可玩性、视觉美感和用户体验，这些对于实际部署至关重要。为了弥合代码大型语言模型在算法问题解决和竞赛编程能力与实用游戏开发全面需求之间的差距，本文提出了V-GameGym，这是一个包括2219个高质量样本的综合基准，样本分布在100个主题集群中，来源于实际的代码库。
### Innovation
本文创新性地引入了V-GameGym，这是一个面向视觉游戏开发的大规模语言模型的综合基准，涵盖了2219个高质量样本，分布在100个主题集群中，使用了一种新颖的基于聚类的内容策划方法以确保多元化和结构完整性。此外，本文还提出了一个包含完整UI沙盒环境的多模态评估框架，采用自动化的大规模语言模型驱动流程进行视觉代码合成。
### Conclusion
本研究通过对V-GameGym的深入分析，展示了其在视觉编程和交互元素生成中的量化质量指标的有效性，成功填补了代码生成准确性和实用游戏开发流程之间的差距。
## 955. `cs.SE` -  cream_rises_to_the_top [PDF](https://arxiv.org/pdf/2509.20215), [HTML](https://arxiv.org/abs/2509.20215)
### Authors
Guang Yang,Wei Zheng,Xiang Chen,Yifan Sun,Fengji Zhang,Terry Yue Zhuo
### Background
LLMs在Verilog生成方面面临着巨大的挑战，因为它们在特定领域的知识有限。虽然采样方法可以改善pass@k指标，但硬件工程师更需要一个可靠的解决方案，而不是不确定的候选方案。
### Innovation
本文将问题表述为要求与Verilog实现之间的语义对齐问题，并提出了VCD-RNK，一种专为高效Verilog代码重新排名设计的判别模型。VCD-RNK通过从三个维度（代码语义分析、测试用例生成和功能正确性评估）中提炼专家知识来进行Verilog特定的推理，并在推断过程中明确地模拟这些推理过程，从而有效避免了现有方法中的计算密集型测试执行。
### Conclusion
VCD-RNK通过提炼专家知识来帮助LLMs进行更有效的Verilog代码重新排名，避免了计算密集型的测试执行，提供了一个可信的解决方案。
## 956. `cs.SE` - 使用大型语言模型通过数据增强提升需求可追溯性 [PDF](https://arxiv.org/pdf/2509.20149), [HTML](https://arxiv.org/abs/2509.20149)
### Authors
Jianzhang Zhang,Jialong Zhou,Nan Niu,Chuang Liu
### Background
需求可追溯性在软件工程中至关重要，它确保了需求与代码之间的一致性。然而，现有的自动化可追溯性方法受限于训练数据的稀缺性和语义鸿沟问题。本文旨在通过利用大型语言模型（LLMs）进行数据增强来解决需求可追溯性中的数据稀缺性问题，提出了一种新颖的方法利用LLMs的提示技术生成增强的需求到代码的连接，从而增强训练数据集。
### Innovation
文章创新点包括：（1）提出并评估了四种提示模板以实现数据增强；（2）比较分析了四种LLMs（Gemini 1.5 Pro、Claude 3、GPT-3.5 和 GPT-4）生成追溯链接的能力；（3）改进了跟踪模型的编码器以提高对增强数据集的适应性。实验结果显示，该方法显著提高了模型性能，F1分数提高了28.59%，证明了其有效性和实际应用潜力。
### Conclusion
本文通过利用大型语言模型的数据增强方法改进了需求可追溯性，提出的新型方法在实际应用中具有显著的性能提升，未来可以进一步研究不同场景下的泛化能力。
## 957. `cs.SE` - 通过零知识证明保护隐私的可验证商务流程 [PDF](https://arxiv.org/pdf/2509.20300), [HTML](https://arxiv.org/abs/2509.20300)
### Authors
Jannis Kiesel,Jonathan Heiss
### Background
在跨组织流程中，确保商务过程的完整性同时不透露敏感信息是一个重大挑战。本文提出了一种基于零知识证明（ZKP）的方法，以便在保护隐私的同时执行可验证的商务过程。
### Innovation
文章整合了零知识虚拟机（zkVMs）到商务流程管理引擎，并通过全面的系统架构和原型实现支持了链式验证计算。此外，研究通过案例（产品碳足迹）展示了如何在保护隐私的同时证明和验证可验证流程的完整性，并在业务流程管理（BPM）生命周期中讨论了零知识证明的实用集成。
### Conclusion
基于实证评估，本文展示了在给定隐私约束条件下的过程验证自动化。
## 958. `cs.SE` - 开发者使用GitHub Copilot前后的工作效率：一项纵向混合方法案例研究 [PDF](https://arxiv.org/pdf/2509.20353), [HTML](https://arxiv.org/abs/2509.20353)
### Authors
Viktoria Stray,Elias Goldmann Brandtzæg,Viggo Tellefsen Wivestad,Astri Barbala,Nils Brede Moe
### Background
本研究探讨了生成式AI工具GitHub Copilot对开发者活动和感知生产力的实际影响。研究在NAV IT，一个大型公共部门敏捷组织中进行了一项混合法案例研究。研究者分析了NAV IT内703个GitHub仓库在过去两年中积累的26,317个唯一非合并提交，重点关注了25个Copilot用户和14个非用户基于提交的活动度量，同时对他们的角色和感知生产力进行了调查，并进行了13次访谈。研究表明在使用Copilot前后的活动度量显示，使用Copilot的个人比未使用Copilot的人更为活跃，尽管在采用Copilot工具后，基于提交的活动度量未出现统计显著变化，但观察到了轻微的上升，这表明活动度量的变化与生产力的主观感知之间存在差异.
### Innovation
本研究采用了长时间跨度的混合法案例研究方法，对大型组织中的GitHub Copilot的实际影响进行了系统性的分析，并通过活动度量和主观感知的对比，揭示了在引入Copilot后开发者的活动模式变化和主观感知之间的差异.
### Conclusion
虽然GitHub Copilot的使用并未显著改变基于提交的活动度量，但开发者的活动度量显示了使用Copilot比未使用时更为活跃，同时开发者的主观感知显示他们使用Copilot后的生产力并未出现显著变化，这表明在工具使用后活动度量和主观生产力感知之间存在不一致.
## 959. `cs.SE` - 评估Web API集成代码生成 [PDF](https://arxiv.org/pdf/2509.20172), [HTML](https://arxiv.org/abs/2509.20172)
### Authors
Daniel Maninger,Leon Chemnitz,Amir Molzam Sharifloo,Jannis Brugger,Mira Mezini
### Background
API集成是数字基础设施的核心，使得软件系统能够连接和互动。然而，许多研究表明，编写或生成正确的代码来调用API，尤其是Web API，是一项挑战。尽管大型语言模型（LLMs）在软件开发中变得流行，但在自动化生成Web API集成代码方面的有效性尚未得到探索。
### Innovation
本文提出了一种数据集和评估管道，旨在评估LLMs生成Web API调用代码的能力。实验结果显示，生成API调用提出了一项重大挑战，导致臆造的端点、错误的参数使用以及其他错误。测试的开源模型未能解决超过40%的任务。
### Conclusion
虽然LLMs在软件开发中变得流行，但在自动化生成Web API集成代码方面的有效性依然未知。通过对几种开源LLMs的实验，研究发现生成API调用是一个重大挑战，这些模型未能解决超过40%的任务。
## 960. `cs.SE` - 使用I/O文法进行协议测试 [PDF](https://arxiv.org/pdf/2509.20308), [HTML](https://arxiv.org/abs/2509.20308)
### Authors
Alexander Liggesmeyer,José Antonio Zamudio Amaya,Andreas Zeller
### Background
生成软件测试面临两个基本问题：首先，需要生成语法上和语义上都正确的输入，同时又要足够多样化以覆盖不同的行为；其次，需要一种检验机制来验证测试输出是否正确。这些问题在协议测试中尤为明显，因为涉及的是多方之间交换的消息及其响应的验证。现有工具和形式化方法在这两个问题上缺乏整合与解决能力。因此，本文提出一种新的协议测试方法，通过将输入生成和输出检查结合在一个框架中来解决这些问题。
### Innovation
本文引入了I/O文法作为一种完全描述协议语法和语义的方法，包括消息、状态和交互。基于FANDANGO框架的实现，可以作为测试生成器、模拟对象和测试客户端、服务器的验证器，具有前所未有的工具或形式化方法的灵活性。用户可以定义约束条件来引导生成器关注特定的协议特征，并逐个统一覆盖状态、消息、响应和值的选择。这种方法通过应用到DNS、FTP和SMTP协议的实例中被证明了其有效性，并且使用系统覆盖I/O文法能够比随机的现有方法更快地覆盖输入和响应的空间（从而实现更全面的功能覆盖）.
### Conclusion
本文提出的I/O文法方法被证明能够正确且完整地描述复杂的协议功能，并且能够提高测试过程中的输出验证效率。该方法通过系统化覆盖I/O文法来大幅提升测试覆盖率，相比随机方法更具优势。
## 961. `cs.SE` - 代理元认知：设计一种'自我意识'的低代码代理进行故障预测和人工转交 [PDF](https://arxiv.org/pdf/2509.19783), [HTML](https://arxiv.org/abs/2509.19783)
### Authors
Jiexi Xu
### Background
自主代理在低代码/无代码（LCNC）环境中固有的非确定性本质提出了重大可靠性和性能挑战。这些代理可能陷入无法预见的循环中，产生不准确的输出，或者遇到无法恢复的故障，导致用户不满和信任丧失。该报告研究了这一问题，并提出了一个创新的架构模式来解决这些问题。
### Innovation
引入了一个后备、'元认知'层，该层主动监控主LCNC代理，通过一系列预定义的触发器——如高延迟或重复操作——预测即将出现的任务失败，并在预测到失败时主动发起人工转交，向用户提供详细的代理'思考过程'解释和无法继续的原因。原型系统的实验证明，这种方法显著提高了任务成功率。然而，这种性能提升伴随着显著的计算成本增加。
### Conclusion
这一方法重新定义了人工转交，不仅不是一种绝望，而是系统弹性和用户体验改进的核心设计特征，通过提供代理内部状态的透明性来增强信任。报告讨论了这种方法的实用和伦理影响，并指出了未来研究的关键方向。
## 962. `cs.SE` - 基于软件定义孪生网络的IIoT短期异常预测新方法 [PDF](https://arxiv.org/pdf/2509.20068), [HTML](https://arxiv.org/abs/2509.20068)
### Authors
Bilal Dalgic(1),Betul Sen(1),Muge Erel-Ozcevik(1) ((1) Manisa Celal Bayar University, Turkey)
### Background
当前工业互联网（IIoT）环境下，安全监测和动态控制是主要需求。然而，现有的文献中缺乏基于软件定义网络（SDN）的数字孪生（DT）和针对IIoT威胁的时间感知智能模型训练方法。因此，本文提出了一种新的短周期异常检测框架，利用基于SDN的DT来应对IIoT安全挑战。
### Innovation
本文的主要创新在于提出了一个基于SDN的数字孪生（SD-TWIN）的新颖异常检测算法，通过使用全面的数据集和特征的时间感知标签，以及对多种机器学习模型的综合评估。实验证明，GPU加速的LightGBM模型在实时SD-TWIN部署中表现尤为出色，能够在保证高召回率的同时实现较强的分类性能。
### Conclusion
基于SDN的数字孪生模型在IIoT短周期异常检测任务中表现出色，提供了一种新的有效解决方案，可以实现动态、安全的IIoT环境监控。
## 963. `cs.SE` - 面向对象 vs 函数式：编程范式如何影响系统架构特性 [PDF](https://arxiv.org/pdf/2508.00244), [HTML](https://arxiv.org/abs/2508.00244)
### Authors
Briza Mel Dias de Sousa(1),Renato Cordeiro Ferreira(1,2,3,4),Alfredo Goldman(1) ((1) University of São Paulo, (2) Jheronimus Academy of Data Science, (3) Technical University of Eindhoven, (4) Tilburg University)
### Background
本研究旨在比较面向对象编程(OOP)与函数式编程(FP)对软件系统架构特征的影响。为此，研究通过分析使用Kotlin（面向对象）和Scala（函数式）编写的数字钱包系统的设计和实施来进行对比研究。研究方法采用混合方法，包括自我民族志的定性分析以及基于调查的定量分析，以获取开发者的反馈和看法。希望这些结果能为未来的项目选择最合适的范式提供帮助和指导。
### Innovation
本研究通过在两种编程范式之间进行对比，采用自我民族志的定性和基于调查的定量分析方法，对使用面向对象和函数式编程的软件系统架构特性进行了深入探讨，为开发者在选择编程范式时提供了参考依据。
### Conclusion
该研究旨在通过对比面向对象编程和函数式编程对系统架构特征的影响来帮助开发者决定在接下来的项目中应选择哪种范式。研究结果可能有助于那些正在考虑采用哪种编程范式的开发者做出决策。
## 964. `cs.SE` - 代码语义有帮助吗？基于执行追踪的信息对代码大规模语言模型的全面研究 [PDF](https://arxiv.org/pdf/2509.11686), [HTML](https://arxiv.org/abs/2509.11686)
### Authors
Jian Wang,Xiaofei Xie,Qiang Hu,Shangqing Liu,Yi Li
### Background
代码大语言模型（Code LLMs）在编程中展现了强大的能力，但仍存在关键问题，如无法准确理解程序的运行时行为，以及现有方法中语义信息表示的不一致性和碎片化，这影响了它们的推理能力和泛化能力。这些问题凸显出需要更系统的方法来增强Code LLMs的推理能力。
### Innovation
提出一种通用框架，用于集成语义信息（如执行追踪）到代码任务相关提示中，并进行全面研究，以探索语义信息对Code LLMs推理能力的增强作用，特别关注基于执行追踪的语义信息在监督微调（SFT）和代码LLMs后续推理中的作用。实验结果显示，此前关于SFT和代码LLMs测试时间扩大的研究发现与研究结果不符，表明语义信息对于SFT和规模扩大的作用有限。
### Conclusion
研究结果表明，基于执行追踪的语义信息对于提高代码LLMs的推理能力的效果有限，且在监督微调和测试时间规模扩大方面作用不大。
## 965. `cs.SE` - 工程化RAG系统以应用于实际场景：设计、开发与评估 [PDF](https://arxiv.org/pdf/2506.20869), [HTML](https://arxiv.org/abs/2506.20869)
### Authors
Md Toufique Hasan,Muhammad Waseem,Kai-Kristian Kemell,Ayman Asad Khan,Mika Saari,Pekka Abrahamsson
### Background
类似于RAG（检索增强生成）系统的框架正在成为将大型语言模型（LLMs）与外部知识相结合的关键方法，以解决事实准确性和上下文相关性方面的局限性。然而，目前缺乏基于实际应用案例、通过普通用户参与进行评估并伴随系统性经验教训记录的实证研究报告。因此，本文针对治理、网络安全、农业、工业研究和医学诊断等领域开发了五个特定领域的RAG应用系统，旨在改进上述问题。
### Innovation
本文在RAG系统的背景下，创新性地设计、开发并评估了五个面向实际场景的应用系统。每个系统都集成了多语言OCR、基于向量嵌入的语义检索以及特定领域的LLM部署，通过本地服务器或云API满足不同的用户需求。评估结果显示，这些系统在易用性、相关性、透明性、响应速度、准确性和推荐可能性等方面表现出良好的性能。此外，通过用户的反馈和研究团队的经验总结，提出了十二条关键的战术、运营和伦理教训，这些教训对于提高RAG系统的可靠性和可用性具有重要价值。
### Conclusion
本文通过设计、开发并评估特定领域的RAG系统，揭示了在实际应用场景中部署RAG系统所面临的挑战，并提出了一系列实用的经验教训。这些发现不仅有助于技术团队更深入地理解RAG系统的实际应用问题，也为未来使用RAG系统的实际应用提供了参考和指导。
## 966. `cs.SE` - 用大规模GitHub仓库研究解析神经网络演化的BOM分析：来自55997个仓库的洞见 [PDF](https://arxiv.org/pdf/2509.20010), [HTML](https://arxiv.org/abs/2509.20010)
### Authors
Xiaoning Ren,Yuhang Ye,Xiongfei Wu,Yueming Wu,Yinxing Xue
### Background
由于神经网络在许多领域的出色表现，其开源社区出现了众多神经网络（NN）存储库，迭代快速，使得从业者需要分析其演变以指导开发和领先趋势。传统软件的演化使用软件物料清单（SBOMs）研究较为广泛，但这些方法不适合神经网络软件，神经网络软件依赖于预定义模块和预训练模型（PTMs），具有独特的组件结构和重用模式。概念AI物料清单（AIBOMs）在大规模演化分析方面也缺乏实际应用。因此，本文构建了神经网络物料清单（NNBOM），用于全面记录神经网络软件的预训练模型、模块和第三方库。
### Innovation
引入了神经网络物料清单（NNBOM），这是针对神经网络软件的综合数据集构造。从55,997个精制的PyTorch GitHub存储库中构建大规模NNBOM数据库，对软件规模、组件重用和跨领域依赖进行全面的实证研究。开发了两个原型应用程序——多仓库演化分析器和单仓库组件评估器与推荐器，展示了分析的实际价值。
### Conclusion
通过全面的实证研究，提供了神经网络软件长期发展趋势的全景视图，为维护者和开发者提供了一个综合的视角。进一步开发了两个原型应用，以展示分析的实际价值。
## 967. `cs.SE` - clotho: 评估大型语言模型输入预生成测试充分性 [PDF](https://arxiv.org/pdf/2509.17314), [HTML](https://arxiv.org/abs/2509.17314)
### Authors
Juyeon Yoon,Somin Kim,Robert Feldt,Shin Yoo
### Background
软件越来越多地依赖大型语言模型（LLMs）的新兴功能，如自然语言理解、程序分析和生成。然而，对这些模型进行特定任务的测试仍然困难且昂贵，因为许多提示缺乏准确度，往往依赖人工判断，而现有的不确定性和充分性度量通常需要完整的推理过程。关键挑战在于如何在生成任何输出之前评估输入的充分性，并能反映任务需求。
### Innovation
本文介绍了CLOTHO，这是一种针对特定任务、预生成的充分性度量方法，能够直接从隐藏的LLM状态估计输入难度。通过使用高斯混合模型（GMM），CLOTHO能够在未生成任何输出的情况下，通过标签参考数据集来评估未知输入的失败概率。与现有的不确定度度量方法相比，CLOTHO无需生成输出，从而降低了成本。实验结果显示，CLOTHO在八个基准任务和三种开放权重LLM上预测失败的ROC-AUC为0.716，并且能够有效转移开放权重LLM学到的充分性评分到专有模型，增加了对于专有模型测试输入的充分性评估效果。
### Conclusion
CLOTHO能够在无需生成任何输出的情况下，通过标签参考数据集评估未知输入的失败概率，大幅度减少了测试成本，相较于现有的后生成不确定度度量，CLOTHO能更有效地评估输入的预生成测试充分性。同时，通过转移开放权重LLM学到的充分性评分到专有模型，CLOTHO进一步扩大了其应用范围。
## 968. `cs.SE` - 正则表达式组成策略的系统性比较: 重用是否足够？ [PDF](https://arxiv.org/pdf/2503.20579), [HTML](https://arxiv.org/abs/2503.20579)
### Authors
Berk Çakar,Charles M. Sale,Sophie Chen,Dongyoon Lee,James C. Davis
### Background
正则表达式在软件工程中的设计与组合是一个常见但具有挑战性的过程，工程师们在处理复杂度高的正则表达式时经常遇到问题，导致错误、性能和安全漏洞增加。研究者提出了自动合成正则表达式的工具，而近期语言模型的发展也有望生成正则表达式。然而，开发人员通常重用代码库和互联网资源中的现有正则表达式，但目前还没有研究对比这些不同的正则表达式组合策略，这使得软件工程师不清楚应选用何种方法，研究者也无法确定开放的问题。
### Innovation
本文通过系统性评估正则表达式的重用、形式化合成和基于语言模型的生成策略来填补这一空白。作者构建了一个包含901,516个正则表达式的新型数据集（RegexReuseDB），并定义了一个包含55,448个正则表达式组合任务的数据集（RegexCompBench）。他们设计并实现了第一个利用RegexReuseDB的基于示例的重用方法，即“通过示例重用”。评估结果显示，在准确度、维护性、计算效率和结果多样性方面，基于示例的重用和语言模型都能取得优秀表现，尤其是在任务多样性方面，基于示例的重用尤其受到工程师的欢迎。因此，从成本效益的角度来看，对于正则表达式的组合，可能重用就是所有你所需要的。
### Conclusion
研究结果为开发人员在选择正则表达式组合策略方面提供了见解，并为工具设计提供了信息，以提高软件系统中文本模式的可靠性。
## 969. `cs.SE` - 开源AI代理框架和代理应用中的测试实践的实证研究 [PDF](https://arxiv.org/pdf/2509.19185), [HTML](https://arxiv.org/abs/2509.19185)
### Authors
Mohammed Mehedi Hasan,Hao Li,Emad Fallahzadeh,Gopi Krishnan Rajbahadur,Bram Adams,Ahmed E. Hassan
### Background
基于基础模型（FM）的AI代理正在各个领域迅速普及，但它们的固有非确定性和不可再现性给测试和质量保证带来了挑战。现有的基准测试主要包含任务级别的评估，但对开发者如何在开发过程中验证这些代理内部正确性的理解却有限。
### Innovation
该研究进行了首次大规模的实证研究，分析了39个开源代理框架和439个代理应用中的测试实践，识别出十种不同的测试模式。研究发现，尽管传统的测试模式（如负向测试和成员资格测试）被广泛使用来管理FM不确定性，但新型的代理特定方法（如DeepEval）的使用率非常低，仅占1%左右。研究者还发现，在测试努力的分配上存在根本性的倒置，确定性组件（如资源元数据和协调元数据）消耗了超过70%的测试努力，而基于FM的计划主体却只占不到5%。
### Conclusion
研究提供了基于FM的代理框架和代理应用的第一个实证测试基准，揭示了一种合理但不完整的非确定性适应方法。为此，框架开发者需要改进对新型测试方法的支持，应用程序开发者需要采用提示回归测试，研究人员也应探索采用障碍。这些措施加强了这些实践，对建立更稳健和可靠的AI代理至关重要。
## 970. `cs.LG` - 软令牌，硬事实 [PDF](https://arxiv.org/pdf/2509.19170), [HTML](https://arxiv.org/abs/2509.19170)
### Authors
Natasha Butt,Ariel Kwiatkowski,Ismail Labiad,Julia Kempe,Yann Ollivier
### Background
研究指出，在语言模型推理的链式思考(CoT)阶段使用连续而不是离散的令牌可以模拟多个推理路径的叠加。理论上，连续令牌具有更高的表达能力，能更高效地解决特定问题。然而，实际情况中连续令牌的应用受到强烈训练难度的影响，之前的许多工作要么在推理时仅使用预训练的离散令牌模型的连续令牌，要么从真实的离散CoTs中提取连续CoTs，这带来了高昂的计算成本，从而限制了CoTs的数量。因此，本文提出了一种通过强化学习（RL）大规模学习连续CoTs的方法，无需从参考的离散CoTs中提取。这种方法利用了“软”令牌，结合令牌混合和输入嵌入噪声来进行RL探索。
### Innovation
本文首次提出了通过强化学习大规模学习连续链式思考（CoT）的方法，使用“软”令牌：结合令牌混合和输入嵌入噪声以提供RL探索，从而使得能够学习包含数百个令牌的连续CoTs。这种方法使得连续CoTs的训练在数学推理基准测试中比使用离散令牌具有更高的准确率和多样性，展示了在这种方法下训练的模型在保留基模型预测方面更好的鲁棒性，这对于处理域外任务是非常有益的。
### Conclusion
通过强化学习训练连续CoTs是提升模型推理能力的一种有效方法，尤其是在数学推理任务中。这种方法可以在部署时使用离散令牌进行推理，提高了模型使用的灵活性和实用性。同时，连续CoT的训练还能更好地保留基模型的预测，提高模型的鲁棒性，对于处理域外任务尤为重要。
## 971. `cs.SE` - Advancing Expert Specialization for Better Mixture-of-Experts [PDF](https://arxiv.org/pdf/2505.22323), [HTML](https://arxiv.org/abs/2505.22323)
### Authors
Hongcan Guo,Haolang Lu,Guoshun Nan,Bolun Chu,Jialin Zhuang,Yuan Yang,Wenhao Che,Sicong Leng,Qimei Cui,Xudong Jiang
### Background
Mixture-of-Experts (MoE) 模型通过在每条输入上仅激活少数专家来实现大规模语言模型（LLMs）的高效扩展。然而，常见使用的辅助负载均衡损失常导致专家之间重叠和路由过于均匀，这妨碍了专家的专业化并降低了训练后的整体性能。
### Innovation
提出了一种简单有效的解决方案，引入了两种互补的目标：（1）正交性损失以促进专家处理不同类型的令牌，（2）方差损失以促进更区分的路由决策。通过梯度级分析证明了这些目标与现有辅助损失兼容，并有助于优化训练过程。实验结果显示，该方法显著提升了专家的专业化水平。特别地，该方法在保留负载均衡的同时，通过辅助损失提高了经典 MoE 基线性能多达 23.79%，且无需对模型架构进行修改或添加额外组件。
### Conclusion
我们的方法在多个模型架构和多种基准测试中显示出显著的优势，在不修改模型架构或添加额外组件的前提下，极大提升了 MoE 专家的专业化水平和负载均衡性能。源代码将公开贡献给社区。
## 972. `cs.SE` - Hornet Node和Hornet DSL：比特币共识的简约可执行规范 [PDF](https://arxiv.org/pdf/2509.15754), [HTML](https://arxiv.org/abs/2509.15754)
### Authors
Toby Sharp
### Background
比特币的共识规则编码在其参考客户端的实现中，但由于存在副作用、可变状态、并发性和陈旧设计问题，这些规则无法进行形式化验证。一个独立的形式化规范不仅可以在不同版本的参考客户端或与新客户端实施中进行验证，还能增强去中心化，降低共识分裂错误的风险。然而，由于比特币共识逻辑的复杂性，这种形式化的规范长期以来被认为难以实现。
### Innovation
本文展示了比特币共识规则的一个紧凑、可执行的形式化C++规范，能在单线程上快速同步主网。作者引入了Hornet领域专用语言（DSL），专门用于明确、无歧义地编码这些规则以供执行，从而支持形式推理、共识代码生成和AI驱动的对抗性测试。Hornet Node客户端提供了一个现代且模块化的替代参考客户端的方案。Hornet Node的清晰直白的风格使其适用于教育，而其性能则使其成为实验的理想选择。本文还突出了其分层设计、高效的数据结构以及强分离的关注点方面的架构贡献。
### Conclusion
Hornet Node和Hornet DSL共同提供了实现比特币共识形式化、执行化规范的第一条可信路径。
## 973. `cs.SE` - 基于LLM的代码生成中模棱两可问题描述的自动修复 [PDF](https://arxiv.org/pdf/2505.07270), [HTML](https://arxiv.org/abs/2505.07270)
### Authors
Haoxiang Jia,Robbie Morris,He Ye,Federica Sarro,Sergey Mechtaev
### Background
近年来，大语言模型（LLMs）在软件工程中的应用日益增多，自然语言（NL）在软件开发中的重要性也随之增加。然而，自然语言的模棱两可性可能导致软件质量下降，不清楚的问题描述可能会导致生成错误的程序。因此，检测和解决模棱两可的问题描述变得尤为重要，尤其是在当前的LLMs无法直接解决此类问题时。现有方法往往对LLMs直接提出澄清模棱两可的问题描述要求，但效果有限，往往生成无关或不一致的编辑。因此，有必要提出一种更有效的解决策略，通过分解任务为两个简化步骤来解决问题：（1）通过传统的测试和程序修复重新分析和修复LLMs对描述的理解，其理解由它生成的程序分布来捕获；（2）通过一种称为对比规格推理的方法根据分布的变化来修正描述，从而更好地将Nl与输入输出示例对齐。
### Innovation
本文创新性地提出了一种工具SpecFix，该工具将基于LLMs的代码生成中的模棱两可问题描述修复任务分解为两个更简单的步骤，通过分析和修复LLMs对描述的理解来减少代码生成的不确定性，再通过对描述的进一步精细化处理来更好地将自然语言与输入输出示例对齐。实验结果显示，SpecFix在四个先进的LLMs（GPT-4o、GPT-4o-mini、DeepSeek-V3和Qwen2.5-Coder-32B-Instruct）和三种流行代码生成基准测试上（HumanEval+、MBPP+和LiveCodeBench）进行了评估，无需人工干预或外部信息，SpecFix成功修改了43.58%的描述，改进了修改后的集合的通过率，产生了4.09%的整体改进。更重要的是，这些修复也有助于不同模型之间的性能提升，修复了某个模型的描述可以提高其他模型的性能10.48%。
### Conclusion
通过SpecFix，研究人员有效解决了基于LLMs的代码生成中的模棱两可问题描述，显著提高了代码生成的质量。研究结果证明了SpecFix方法的有效性，为进一步在自然语言处理和软件工程中的应用奠定了基础。
## 974. `cs.SE` - 使用多模态大型语言模型进行交通事故检测的研究 [PDF](https://arxiv.org/pdf/2509.19096), [HTML](https://arxiv.org/abs/2509.19096)
### Authors
Ilhan Skender,Kailin Tong,Selim Solmaz,Daniel Watzenig
### Background
交通安全性依然是全球性的重大问题，及时准确地检测事故对于减少隐患和迅速响应紧急情况至关重要。基础设施基视觉传感器提供了可扩展且高效的连续实时监测解决方案，能够直接从拍摄的图像中自动检测事故。因此，本文研究了多模态大语言模型（MLLMs）在使用基础设施摄像头图像检测和描述交通事故方面的零样本能力，以减少对大量标记数据的依赖。
### Innovation
主要创新点包括：（1）利用CARLA生成的模拟DeepAccident数据集评估MLLMs，通过控制性模拟明确解决多样且逼真的基础设施事故数据稀缺性问题；（2）对比分析在事故识别和描述能力方面的Gemini 1.5和2.0、Gemma 3和Pixtral模型的表现，无需先进行微调；（3）将先进的视觉分析技术，如YOLO对象检测、Deep SORT多对象跟踪和Segment Anything实例分割，集成到增强提示中，以提高模型准确性和可解释性。
### Conclusion
实验结果表明，Pixtral在F1分数上表现最佳，达到71%，召回率为83%，Gemini模型在增强提示后（如Gemini 1.5提升至90%）获得了更高的精度，但F1分数和召回率有所下降。Gemma 3提供了最平衡的表现，各项指标波动最小。这些结论展示了将MLLMs与先进的视觉分析技术集成具有巨大的潜力，能增强其在实际自动化交通监控系统中的应用。
