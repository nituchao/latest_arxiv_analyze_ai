{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10265", "html_url": "https://arxiv.org/abs/2508.10265", "title": "为什么大型语言模型永远无法进行真正的正确推理？", "title_en": "Why Cannot Large Language Models Ever Make True Correct Reasoning?", "authors": "Jingde Cheng", "background": "随着基于大型语言模型（LLMs）的生成式AI工具的发展，如ChatGPT，许多AI专家和非专业人士正在强调LLMs的‘理解能力’和‘推理能力’。然而，作者认为这些所谓的‘理解能力’和‘推理能力’只不过是模糊概念下的幻觉，实际上LLMs永远不会具有真正的理解能力或推理能力。", "innovation": "作者通过探讨L大型语言模型的工作原理的本质限制，提出LLMs无法进行真正的正确推理。", "conclusion": "由于L大型语言模型工作原理的本质限制，它们永远无法具备真正的正确推理能力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10164", "html_url": "https://arxiv.org/abs/2508.10164", "title": "通过小型偏好优化剪枝大型推理模型的长链推理", "title_en": "Pruning Long Chain-of-Thought of Large Reasoning Models via Small-Scale Preference Optimization", "authors": "Bin Hong,Jiayu Liu,Zhenya Huang,Kai Zhang,Mengdi Zhang", "background": "大型推理模型（LRMs）在复杂任务中表现出色，但其长链推理（CoT）导致生成输出过长，增加计算成本并可能导致过度推理，使得在推理有效性和效率之间实现平衡变得具有挑战性。当前的高效推理方法往往牺牲推理质量，或需要大量资源。", "innovation": "本文提出了一种名为Length Controlled Preference Optimization (LCPO)的新方法，直接平衡与NLL损失相关的隐式奖励，并在有限的数据和训练下有效学习长度偏好。研究人员通过分析生成路径分布并利用困难估计过滤生成轨迹，进一步分析了基于Bradley-Terry损失的各种偏好优化方法的目的函数收敛行为。", "conclusion": "大量实验表明，我们的方法在多个基准测试中平均输出长度减少了超过50%，同时保持推理性能。这项工作突显了在指导LRMs进行高效推理时，计算上有效的方法具有潜在价值。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10293", "html_url": "https://arxiv.org/abs/2508.10293", "title": "运用可验证逐步奖励促进高效推理", "title_en": "Promoting Efficient Reasoning with Verifiable Stepwise Reward", "authors": "Chuhuai Yue,Chengqi Dong,Yinan Gao,Hang He,Jiajun Chai,Guojun Yin,Wei Lin", "background": "大型推理模型（LRMs）在复杂推理任务中取得了显著进展，得益于验证性奖励强化学习的支持。然而，LRMs往往存在过度推理的问题，即在解决简单问题时消耗过多计算资源，降低了效率。现有的高效推理方法通常需要准确的任务评估来预设标记预算或选择推理模式，这限制了它们的灵活性和可靠性。", "innovation": "为解决过度推理问题，作者重新审视了其本质，并发现激励有效步骤同时惩罚无效步骤是关键。为此，作者提出了一种新颖的基于规则的可验证逐步奖励机制（VSRM），该机制根据推理轨迹中中间状态的表现分配奖励。这种方法直观且自然地适应了推理任务的逐步属性。通过将VSRM与PPO和Reinforce++集成，在标准的数学推理基准AIME24和AIME25上进行的广泛实验表明，该方法在保持原始推理性能的同时显著减少了输出长度，实现了效率和准确性的最佳平衡。", "conclusion": "进一步分析训练前后过度推理的频率和pass@k分数表明，该方法确实有效地抑制了无效步骤，促进了有效推理，从根本上缓解了过度推理问题。所有代码将在论文被接受后发布。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10177", "html_url": "https://arxiv.org/abs/2508.10177", "title": "KompeteAI：加速自主多智能体系统用于端到端的机器学习问题管线生成", "title_en": "KompeteAI: Accelerated Autonomous Multi-Agent System for End-to-End Pipeline Generation for Machine Learning Problems", "authors": "Stepan Kulibaba,Artem Dzhalilov,Roman Pakhomov,Oleg Svidchenko,Alexander Gasnikov,Aleksei Shpilman", "background": "最近基于大型语言模型（LLM）的AutoML系统展示了令人印象深刻的能力，但面临着严重的局限性，如探索策略的局限性和执行瓶颈。探索受限于单次方法缺乏多样性，而蒙特卡洛树搜索（MCTS）方法则无法重组强大的部分解。执行瓶颈来自于冗长的代码验证循环，限制了迭代优化。", "innovation": "KompeteAI 是一种新的AutoML框架，具有动态解决方案探索功能。与之前的MCTS方法将想法孤立不同，KompeteAI 引入了一个合并阶段，将顶级候选者组合在一起。该框架通过集成检索增强生成（RAG）来扩展假设空间，从Kaggle笔记本和arXiv论文中获取实际策略，并通过预测评分模型和加速调试方法解决执行瓶颈，利用早期阶段的度量评估解决方案潜力，从而避免昂贵的全代码执行。", "conclusion": "KompeteAI 在主要的AutoML基准测试MLE-Bench上比领先方法（如RD-agent、AIDE和Ml-Master）平均提高3%，同时提出了Kompete-bench 来弥补MLE-Bench的不足，该框架也在此挑战中取得最优表现。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10047", "html_url": "https://arxiv.org/abs/2508.10047", "title": "LLMs在优化建模中的进展与未来方向", "title_en": "A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions", "authors": "Ziyang Xiao,Jingrong Xie,Lilin Xu,Shisi Guan,Jingyan Zhu,Xiongwei Han,Xiaojin Fu,WingYin Yu,Han Wu,Wei Shi,Qingcan Kang,Jiahui Duan,Tao Zhong,Mingxuan Yuan,Jia Zeng,Yuan Wang,Gang Chen,Dongxiang Zhang", "background": "优化建模由于在解决实际问题方面的巨大用途，已在各个行业中的最优决策制定中广泛使用，但这也需要来自运筹学专家的大量专业知识。随着大型语言模型（LLMs）的出现，出现了自动化数学建模过程的新机会。本文通过全面回顾近期的发展，涵盖了从数据合成和基模型微调到推理框架、基准数据集和性能评估的整个技术栈，展示了这些进步的最新情况。", "innovation": "本文深入分析了基准数据集的质量，发现其错误率令人惊讶地高。我们对数据集进行了清理并构建了一个新的基准榜，基于基LLM模型和数据集进行了公平的性能评估。我们还建立了一个在线门户，集成了清理数据集、代码和论文存储库的资源，以惠及社区。此外，明确了现有方法的局限性，并指出了未来的研究机会。", "conclusion": "最后，我们识别了现有方法论的局限性，并概述了未来研究的方向。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10108", "html_url": "https://arxiv.org/abs/2508.10108", "title": "亚马逊诺瓦人工智能挑战——可信人工智能：促进安全的AI辅助软件开发", "title_en": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development", "authors": "Sattvik Sahai,Prasoon Goyal,Michael Johnston,Anna Gottardi,Yao Lu,Lucy Hu,Luke Dai,Shaohua Liu,Samyuth Sagi,Hangjie Shi,Desheng Zhang,Lavina Vaz,Leslie Ball,Maureen Murray,Rahul Gupta,Shankar Ananthakrishna", "background": "AI系统在软件开发中的应用越来越普及，但是确保其安全性仍然存在重大挑战。亚马逊为此推出了亚马逊诺瓦人工智能挑战中的“可信人工智能”赛道，这是一个全球性竞赛，旨在提升安全AI的技术水平。竞赛吸引了10所大学团队参与，其中一半团队开发自动红队机器人，另一半团队则研发安全的AI助手。", "innovation": "参赛团队开发了最先进的技术，引入了基于推理的安全对齐、健壮的模型护栏、多轮次逃狱以及对大语言模型高效探测等新颖方法。亚马逊诺瓦人工智能挑战团队还做出了科学和技术方面的重大投入，包括构建了一个专门用于挑战的定制化编码专家模型，开发了一个锦标赛编排服务，以及创建了一个评估框架。", "conclusion": "通过此次挑战，大学团队和亚马逊诺瓦人工智能挑战团队共同致力于解决AI在软件开发中的安全问题，提升了AI安全的技术标准。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10152", "html_url": "https://arxiv.org/abs/2508.10152", "title": "提高和评估开放深度研究代理", "title_en": "Improving and Evaluating Open Deep Research Agents", "authors": "Doaa Allabadi,Kyle Bradbury,Jordan M. Malof", "background": "近年来，深度研究代理（DRAs）已经展现了强大的能力，可以通过自然语言提示从互联网搜索和利用信息来解决问题。然而，现有研究多集中于封闭源代码系统。研究团队发现仅有一个开放源代码DRAs系统，名为Open Deep Research (ODR)。为了评估开放性和现有封闭源代码系统的性能差异，论文提出一个新的基准测试BrowseComp-Small（BC-Small），并测试ODR与来自Anthropic和Google的两个现有封闭源代码系统。结果显示这些系统在测试集上的准确率为零。", "innovation": "本文引入了三项创新策略，改进ODR，生成ODR+模型，该模型在BC-Small基准测试中展现出目前最先进的10%的成功率，无论是开源还是封闭源代码系统皆是如此。此外，进行了消融实验，表明所有改进措施都对ODR+的成功具有贡献。", "conclusion": "尽管当前所有DRAs系统的性能都还很低，但提出的ODR+模型在开放源代码系统中的表现已经达到了基准水平。这证明了通过适当策略改进开源DRAs的可能性，为未来研究提供了方向和潜在方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10143", "html_url": "https://arxiv.org/abs/2508.10143", "title": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection", "title_en": "MCP-Orchestrated Multi-Agent System for Automated Disinformation Detection", "authors": "Alexandru-Andrei Avram,Adrian Groza,Alexandru Lecu", "background": "数字平台上的虚假信息传播造成了信息完整性方面的重要挑战。该文提出了一种使用关系提取来检测新闻文章中虚假信息的多智能体系统，重点关注标题和简短文本片段。", "innovation": "文章创新地提出了一种名为Agentic AI的多智能体系统，结合了四个不同的代理：（i）机器学习代理（逻辑回归），（ii）维基百科知识检查代理（依赖于命名实体识别），（iii）一致性检测代理（使用LLM提示工程），以及（iv）基于从网站抓取的数据提取关系三元组以进行事实核查的数据分析代理。系统通过模型上下文协议（MCP）协调运行，提供各组件间的共享上下文和实时学习。研究表明，这种多智能体系统在准确性和F1得分上显著优于个体代理和传统方法，并且加权聚合方法从单个代理误分类率推导出，优于算法阈值优化。模块化架构使系统易于扩展，并保留了决策的详细过程.", "conclusion": "研究表明，该多智能体系统在准确性上达到了95.3%，F1分数为0.964，显著优于个体代理和传统方法。加权聚合方法从单个代理误分类率推导出，优于算法阈值优化。系统的模块化架构使其易于扩展，同时还保持了决策过程的详细记录。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10241", "html_url": "https://arxiv.org/abs/2508.10241", "title": "扩展事件的熵潜在能力以实现人工智能中的不确定性量化与决策", "title_en": "Extending the Entropic Potential of Events for Uncertainty Quantification and Decision-Making in Artificial Intelligence", "authors": "Mark Zilberman", "background": "该研究展示了事件熵潜在能力这一概念（一个量化离散事件对系统未来熵预期影响的参数）如何增强人工智能中的不确定性量化、决策制定和可解释性。该框架在物理中的原始定义基础上，通过引入事件中心的度量将其调整应用于人工智能，以捕捉行为、观测或其他离散发生的对未来时间范围不确定性的影响。这两者在形式上都被制定出来，后者强调条件期望以适应反事实场景。该研究讨论了该度量在政策评估、固有奖励设计、可解释人工智能和异常检测中的应用，指出其潜在的统一和增强智能系统中的不确定性建模的能力。概念性例子展示了其在强化学习、贝叶斯推断和异常检测中的应用，同时讨论了在复杂的人工智能模型中进行计算的考虑因素。", "innovation": "该工作通过引入事件中心的度量，将物理中熵潜在能力的概念调整应用于人工智能，以捕捉行为、观测或其他离散发生的对未来时间范围不确定性的影响。此外，它还强调了条件期望来适应反事实场景。该研究还探讨了该度量在政策评估、固有奖励设计、可解释人工智能和异常检测中的应用，并讨论了在复杂的人工智能模型中进行计算的考虑因素。这种熵潜在能力框架提供了一个理论基础、可解释且多功能的方法，用于管理人工智能中的不确定性，结合了热力学、信息论和机器学习的原则。", "conclusion": "熵潜在能力框架为人工智能提供了一个理论基础、可解释且多功能的方法，用于管理不确定性。它成功地将物理中的熵潜在能力概念应用于人工智能，通过条件期望强调了反事实场景，展示了该度量在政策评估、固有奖励设计、可解释人工智能和异常检测中的应用潜力，同时提出了在复杂的人工智能模型中实施计算的注意事项。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10146", "html_url": "https://arxiv.org/abs/2508.10146", "title": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges", "title_en": "Agentic AI Frameworks: Architectures, Protocols, and Design Challenges", "authors": "Hana Derouiche,Zaki Brahmi,Haithem Mazeni", "background": "大型语言模型（LLMs）的出现推动了人工智能领域的一个变革性范式——有能动性的AI，其中智能代理表现出目标驱动的自主性、上下文推理和动态多代理协调。本文对领先有能动性的AI框架进行了系统性回顾和比较分析，包括CrewAI、LangGraph、AutoGen、Semantic Kernel、Agno、Google ADK和MetaGPT等，评估了它们的架构原则、通信机制、记忆管理、安全边界以及与面向服务计算模式的兼容性。此外，本文还指出了该领域的关键局限性、新兴趋势和开放挑战，并深入分析了协议（如合同网协议（CNP）、代理到代理（A2A）、代理网络协议（ANP）和Agora）以应对代理通信问题，为建立有能动性AI系统的分类体系提供了基础，并提出了未来研究方向，旨在增强其可扩展性、健壮性和互操作性。这是为致力于推进新一代自主AI系统的研究人员和从业者提供的一个全面参考文献。", "innovation": "对有能动性的AI框架（如CrewAI、LangGraph、AutoGen等）进行了系统性回顾和比较分析，评估了它们的架构原则、通信机制、记忆管理、安全边界和面向服务计算模式的兼容性，并深入分析了代理通信相关协议，建立了基础分类体系，并提出了未来研究方向，旨在增强有能动性AI系统的可扩展性、健壮性和互操作性。此前的研究可能更多地集中在个别框架或理论模型上，而本文则综合了多个框架的特性，提供了更为全面的指导和研究方向。", "conclusion": "本文的研究成果不仅为有能动性AI系统建立了基础分类体系，还提出了未来研究方向以增强其可扩展性、健壮性和互操作性，为该领域的进一步发展提供了宝贵的参考。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10358", "html_url": "https://arxiv.org/abs/2508.10358", "title": "用海龟汤谜题探测LLMs的创造性推理：下一个提问是什么？", "title_en": "What to Ask Next? Probing the Imaginative Reasoning of LLMs with TurtleSoup Puzzles", "authors": "Mengtao Zhou,Sifan Wu,Huan Zhang,Qi Sima,Bang Liu", "background": "现有基准测试往往静态或专注于社会推理，无法捕捉创造性推理过程中的动态和探索性特征。该研究旨在填补这一空白。", "innovation": "研究引入了一个基于经典‘海龟汤’游戏的全面研究框架，包括基准测试、代理和评估协议。提出了TurtleSoup-Bench，这是第一个大规模跨语言交互基准测试，包含800个来自网络和专家作者的海龟汤谜题。还提出了Mosaic-Agent，一种新型代理，用于评估LLMs在这一环境中的表现。开发了一种多维度评估协议，测量逻辑一致性、细节完成度和结论一致性。实验结果显示，领先LLMs存在明显的能效限制、常见失败模式以及与人类显著的性能差距。", "conclusion": "本研究为LLMs的创造性推理提供了新的见解，并为基础研究中的探索性代理行为奠定了基础。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10340", "html_url": "https://arxiv.org/abs/2508.10340", "title": "多智能体信任区域策略优化：联合约束方法", "title_en": "Multi-Agent Trust Region Policy Optimisation: A Joint Constraint Approach", "authors": "Chak Lam Shek,Guangyao Shi,Pratap Tokekar", "background": "多智能体强化学习（MARL）要求交互智能体间协调且稳定的策略更新。Heterogeneous-Agent Trust Region Policy Optimization (HATRPO)使用克劳德-柯利伯（KL）散度来设定每个智能体的信任区域约束，从而稳定训练。然而，每个智能体分配相同的KL阈值可能导致缓慢且局部优化的更新，特别是在异构环境中这一点尤为明显。", "innovation": "本文提出了两种KL散度阈值在智能体间的分配方法：基于KKT条件的HATRPO-W方法优化了在全局KL约束下的阈值分配；以及基于贪婪算法的HATRPO-G方法，优先考虑改进与散度比值。通过将顺序策略优化与受限阈值调度联系起来，我们的方法在异构智能体环境中提高了灵活性和有效性。实验结果表明，我们的方法显著提升了HATRPO的表现，实现更快的收敛和更高的最终奖励，特别是在多智能体环境基准测试中。", "conclusion": "实验结果证明，HATRPO-W和HATRPO-G在最终性能上分别实现了超过22.5%的提升，HATRPO-W还表现出更稳定的训练动态，其方差较低。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10337", "html_url": "https://arxiv.org/abs/2508.10337", "title": "一种强化学习的课程学习方法：利用RAG进行多模态问答", "title_en": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering", "authors": "Chenliang Zhang,Lin Wang,Yuanyuan Lu,Yusheng Qi,Kexin Wang,Peixu Hou,Wenshi Chen", "background": "该论文描述了Dianping-Trust-Safety团队为META CRAG-MM挑战所提出的方案。挑战要求构建一个全面的检索增强生成系统，能进行多模态多轮问答。比赛包括三个任务：使用图像为基础的模拟知识图谱检索的结构化数据作答；从知识图谱和网络搜索结果中综合信息；处理需要理解上下文并从多个来源聚合信息的多轮对话。团队在三个任务中的表现如下：", "innovation": "1. 任务1的解决方案基于视觉大规模语言模型，并通过从GPT-4.1中抽取知识进行监督微调，提高了答案的准确性和减小了幻觉现象。2. 课程学习策略被应用于引导强化学习，显著提高了任务1和任务2的表现。3. 为任务2和任务3，团队利用了网络搜索API结合外部知识，使系统能够更好地处理复杂查询和多轮对话。团队在任务1中取得了显著领先，任务3的排名为第三，表明了课程学习与强化学习结合在训练管道中的有效性。", "conclusion": "该论文提出的方法在任务1中取得了显著的领先，并在任务3获得第三名，证明了课程学习与强化学习结合的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10391", "html_url": "https://arxiv.org/abs/2508.10391", "title": "LeanRAG: 基于知识图谱的具有语义聚合和分层检索的生成", "title_en": "LeanRAG: Knowledge-Graph-Based Generation with Semantic Aggregation and Hierarchical Retrieval", "authors": "Yaoze Zhang,Rong Wu,Pinlong Cai,Xiaoman Wang,Guohang Yan,Song Mao,Ding Wang,Botian Shi", "background": "Retrieval-Augmented Generation (RAG) 通过利用外部知识在大型语言模型中起着关键作用，但其效果常因检索到上下文错误或不完整的信息而大打折扣。现有的基于知识图谱的RAG方法发展出了多层次结构，将知识组织成多级摘要，但仍存在两个未解决的关键问题：高层概念性摘要作为孤立的“语义岛屿”，缺乏进行跨社区推理所需的显式关系；检索过程本身也无法充分利用图的丰富拓扑结构，往往退化为低效的平面搜索。为解决这些问题，本文提出了一种名为LeanRAG的新框架。", "innovation": "LeanRAG 采用了高度协作的设计，结合了知识聚合和检索策略。它使用了一种新颖的语义聚合算法来形成实体簇，并构建新的聚合层级摘要之间的显式关系，创建了一个完整的语义网络。此外，它采用了一种自底向上的结构引导检索策略，锚定查询到最相关的细粒度实体，并系统地探索图的语义路径以收集简洁而上下文丰富的一组证据。该框架减少了路径检索的开销，并且减少了冗余信息的检索。", "conclusion": "在四个不同领域的具有挑战性的问答基准测试上进行了广泛的实验，表明LeanRAG在响应质量上显著优于现有方法，同时减少了46%的检索冗余。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10467", "html_url": "https://arxiv.org/abs/2508.10467", "title": "FIRESPARQL: 基于大型语言模型的面向学术知识图谱的SPARQL查询生成框架", "title_en": "FIRESPARQL: A LLM-based Framework for SPARQL Query Generation over Scholarly Knowledge Graphs", "authors": "Xueli Pan,Victor de Boer,Jacco van Ossenbruggen", "background": "问答系统在学术知识图谱（SKGs）上的应用面临复杂且结构细腻的挑战，现有大型语言模型（LLM）方法尽管可以将自然语言问题转化为SPARQL查询，但受制于模型对学术内容和其底层模式理解有限，存在生成错误的SPARQL查询的问题，包括结构一致性问题和语义准确性问题。", "innovation": "提出一个名为FIRESPARQL的模块化框架，该框架包含微调的LLM作为核心组件，并可选通过检索增强生成（RAG）提供上下文，以及一个SPARQL查询修正层。该框架在SciQA基准数据集上进行了多种配置下的实验，展示了微调方法在查询准确性和结果准确性上的最优性能。", "conclusion": "实验结果显示，微调方法在查询准确性和结果准确性上表现最佳，达到了0.90的ROUGE-L和0.85的RelaxedEM，超越了基线和最先进的方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10433", "html_url": "https://arxiv.org/abs/2508.10433", "title": "We-Math 2.0: 一种激励视觉数学推理的通用MathBook系统", "title_en": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning", "authors": "Runqi Qiao,Qiuna Tan,Peiqing Yang,Yanzi Wang,Xiaowan Wang,Enhui Wan,Sitong Zhou,Guanting Dong,Yuchen Zeng,Yida Xu,Jie Wang,Chong Sun,Chen Li,Honggang Zhang", "background": "多模态大语言模型（MLLMs）在各种任务中展现了出色的能力，但仍然在复杂的数学推理方面存在挑战。现有研究主要集中在数据集构建和方法优化，却往往忽视了全面的知识驱动设计和模型中心的数据空间建模两大关键方面。", "innovation": "We-Math 2.0 引入了一种统一系统，将结构化的数学知识系统、模型中心的数据空间建模以及基于强化学习（RL）的训练范式结合在一起，以全面提升MLLMs的数学推理能力。创新贡献包括：(1) MathBook 知识系统；(2) MathBook-Standard & Pro；(3) MathBook-RL；(4) MathBookEval。这一系统通过多层次的数学知识构建、多层次的难度空间和层次化的强化学习方法，为数学推理提供了全面的支持。", "conclusion": "实验结果显示，MathBook-RL 在四个常用基准测试上的表现与现有的基线相当，并且在MathBookEval上的表现尤为出色，表明其在数学推理方面的泛化能力强。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10425", "html_url": "https://arxiv.org/abs/2508.10425", "title": "HiRef: 利用层次化本体和网络精炼实现稳健的药物推荐", "title_en": "HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation", "authors": "Yan Ting Chok,Soyon Park,Seungheun Baek,Hajung Kim,Junhyun Lee,Jaewoo Kang", "background": "医疗记录用于帮助医生从长期患者的医学记录中做出及时决策。然而，现实世界中的电子健康记录（EHR）数据存在巨大挑战，因为其中包含很少出现的医学实体和不完整记录，这些可能无法完全捕捉临床真实情况。现有的基于EHR数据驱动模型在处理长期EHR数据时通常会表现出强大的实际性能，但在面对缺少数据或新颖情况时，这些模型难以泛化，主要是因为它们依赖于观察到的共现模式。", "innovation": "本文提出了一个统一框架HiRef（Hierarchical Ontology and Network Refinement for Robust Medication Recommendation），该框架结合了两种互补的结构：（i）从标准化医学本体中编码的层次语义；（ii）从现实世界EHR中提取的精炼共现模式。该模型通过在超球面嵌入本体实体，自然捕捉树形关系并实现知识传递，从而增强对未见代码的泛化能力。此外，HiRef还引入了一种先验引导的稀疏正则化方案，通过抑制虚假边并保留临床意义的关联来进一步增强鲁棒性。实验结果表明HiRef在MIMIC-III和MIMIC-IV等EHR基准测试中表现出色，并在模拟未见代码情境下保持高认证率。", "conclusion": "广泛的实验与全面的消融研究证明了HiRef在处理未见医学代码时的抗干扰能力，并通过学习稀疏化网络结构和医学代码嵌入进行了深入分析。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10492", "html_url": "https://arxiv.org/abs/2508.10492", "title": "反转医工关系：由大语言模型驱动的全程临床诊断", "title_en": "Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model", "authors": "Shicheng Xu,Xin Huang,Zihao Wei,Liang Pang,Huawei Shen,Xueqi Cheng", "background": "实际临床诊断是一个从含糊主诉开始的完整诊断流程。尽管人工智能（尤其是大型语言模型LLMs），在改变临床诊断方面起到了重要作用，但其主要功能仍局限于作为医生的辅助工具，只能在特定部分处理具体的医疗问题，而无法从含糊的主诉开始全程驱动诊断流程。这在很大程度上限制了人工智能减轻医生工作负担和提高诊断效率的能力。", "innovation": "本文提出了一个新模式，将人工智能重新定位为诊断的主要指导者，医生则作为助手配合工作，从而提出了能够用先进深度思考能力驱动全程诊断的DxDirector-7B大语言模型。此外，DxDirector-7B建立了防范误诊的问责制度，明确划分了人工智能与人类医生的责任。在针对罕见和复杂病例的全方位诊断实验中，DxDirector-7B在诊断准确性和医生工作负担减少方面均显著优于最先进的医疗大语言模型和通用型大语言模型。细粒度的临床多部门和任务分析证明了其有效性，专家评估认为它有潜力成为医疗专家的最佳替代方案。", "conclusion": "这项研究展示了一个新的时代，即传统上作为医生助手的人工智能现在能够全程驱动诊断过程，大幅减轻医生的工作负担，提供高效且准确的诊断解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10501", "html_url": "https://arxiv.org/abs/2508.10501", "title": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "title_en": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "authors": "Yushi Feng,Junye Du,Yingying Hong,Qifan Wang,Lequan Yu", "background": "现有的工具增强代理系统在现实世界中受到限制，由于(i)黑箱推理步骤降低了决策的信任度并带来安全风险，(ii)功能不全的多模态集成，这对于医疗任务来说本是固有的关键因素，以及(iii)僵化的计算效率低下的代理流水线。这些限制影响了工具增强代理系统在医疗领域的广泛应用和安全性。", "innovation": "介绍了PASS (Probabilistic Agentic Supernet Sampling)，这是第一个针对胸部X光(CTX)推理挑战的多模态框架。PASS通过自适应地从多工具图中采样代理工作流程，生成带有可解析概率的决策路径。在设计训练过程中，包含专家知识预热、对比路径排名和成本感知强化学习，以优化性能和成本的平衡。还提出了用于多步骤、安全关键、自由形式的CTX推理的全面基准CAB-E。实验结果表明，PASS在多个指标上显著优于强基线，实现了计算成本和可解释性的平衡，推动了可解释、自适应和多模态医疗代理系统的新范式转变。", "conclusion": "PASS通过自适应地选择工具和概率注释轨迹，增强医疗AI的安全性；通过持续压缩关键发现并动态决定是否深入推理路径以提高效率；通过优化性能和成本之间的平衡，促进了更加可解释、自适应和多模态的医疗代理系统的开发。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10530", "html_url": "https://arxiv.org/abs/2508.10530", "title": "优先多样性，后求高质量：语言模型对齐的两阶段模型", "title_en": "Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment", "authors": "Zetian Sun,Dongfang Li,Baotian Hu", "background": "语言模型（LMs）的人类偏好对齐对于构建可靠的AI系统至关重要。这个问题通常被表述为优化LM策略以最大化反映人类偏好的预期奖励。最近提出了一种直接偏好优化（DPO）方法，直接从静态偏好数据优化策略，进一步通过结合在线政策采样（即在训练循环中生成的偏好候选）改进了LM对齐。然而，这种方法的有效性在静态和在线样本之间存在系统性差异，表现出显著差异。例如，对于Llama-3模型，使用在线数据的效用是静态数据的3倍，但对于Zephyr模型则是0.4倍。为了解释这种现象，提出了对齐阶段假设，将对齐过程分为两个阶段：偏好注入阶段受益于多样的数据，而偏好调节阶段更偏好高质量的数据。", "innovation": "本文提出了一种两阶段假设，将对齐过程分为偏好注入阶段和偏好调节阶段，并通过理论和实证分析确定了这两个阶段的界限。此外，研究还证实了DPO和SLiC-HF两种对齐方法的通用性，使得在不同语言模型上的应用更加广泛。", "conclusion": "实验结果显示，优先考虑多样性数据的偏好注入阶段与关注高质量数据的偏好调节阶段之间存在显著差异，提出的一种识别两阶段边界的算法在5个模型和2种对齐方法上具有广泛适用性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10777", "html_url": "https://arxiv.org/abs/2508.10777", "title": "知识推理脱钩：临床自然语言推断中LLMs的基本限制", "title_en": "The Knowledge-Reasoning Dissociation: Fundamental Limitations of LLMs in Clinical Natural Language Inference", "authors": "Maël Jullien,Marco Valentino,André Freitas", "background": "人们通常认为大型语言模型（LLMs）通过增加数据量和参数量来逐步获得结构化且可泛化的内部表示。本文通过构建包含因果归因、组合性实质性、知识验证和风险状态抽象四种推理家族的临床试验自然语言推理基准测试，对该假设进行了挑战，旨在通过知识和元推理验证（GKMRV）探针将知识获取失败与推理失败区分开来。", "innovation": "本文引入了一种临床试验自然语言推理基准测试，该测试包含四种推理家族，通过使用GKMRV探针解耦知识获取与推理过程，从而明确揭示了在实际推理任务上的表现差异。研究人员评估了六种当代LLMs在直接提示和链式思考提示下的表现，结果表明模型在GKMRV任务上的准确率很高，但在这四个推理任务上的表现较差，这进一步揭示了当前LLMs中的基础结构和表示限制。", "conclusion": "当前LLMs虽然具备了临床知识，但在可靠应用这些知识以结构化和组合的方式进行推理方面存在局限。GKMRV提供了有效的框架，用于在高风险领域探测LLM的可靠性和性能。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10747", "html_url": "https://arxiv.org/abs/2508.10747", "title": "提升而不淡化：基于目标感知的稀疏GNN在基于RL的通用规划中的应用", "title_en": "Scaling Up without Fading Out: Goal-Aware Sparse GNN for RL-based Generalized Planning", "authors": "Sangwoo Jeon,Juchul Shin,Gyeong-Tae Kim,YeonJe Cho,Seongwoo Kim", "background": "基于深度强化学习（RL）和图神经网络（GNN）的通用规划在描述为PDDL的问题域中显示出有前景的结果。现有的方法通常将规划状态表示为全连接图，这导致边信息的组合爆炸和问题规模增大时的显着稀疏性，尤其是在大型网格环境中更为明显。这种密集表示导致节点级信息被稀释，大大提高内存需求，并最终使得在大规模问题上进行学习变得不可行。", "innovation": "我们提出了一种稀疏、目标导向的GNN表示法，该表示法选择性地编码相关的局部关系，并显式地结合与目标相关的空间特征。我们通过在网格世界中设计基于PDDL的新颖无人机任务场景，有效地模拟了现实的执行环境。实验结果表明，我们的方法在以前由于密集图表示法而不可行的较大网格尺寸上有效地扩展，并在策略泛化和成功率方面取得了显著提升。", "conclusion": "我们的发现为解决实际的、大规模的通用规划任务提供了一个切实可行的基础。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10703", "html_url": "https://arxiv.org/abs/2508.10703", "title": "GenOM：基于描述生成和大型语言模型的本体匹配", "title_en": "GenOM: Ontology Matching with Description Generation and Large Language Model", "authors": "Yiping Song,Jiaoyan Chen,Renate A. Schmidt", "background": "本体匹配（OM）在跨异构知识源实现语义互操作性和集成方面发挥着重要作用，特别是在包含大量与疾病和药物相关的复杂概念的生物医药领域。传统的OM系统在处理这些问题时存在局限性，而最近的基于大型语言模型（LLM）的方法也有待改进。GenOM框架利用LLM生成本体概念的文本定义，通过嵌入模型检索候选对，并结合精确匹配工具以提高精度。实验表明，GenOM可以与多种基线方法竞争，并且在某些方面超出传统方法和最近的LLM方法。", "innovation": "GenOM通过使用大型语言模型生成本体概念的文本定义，提升了本体匹配的准确性。通过嵌入模型检索本体匹配的候选对，并结合精确匹配工具，进而增强了匹配的精确度。此外，GenOM还采用了少量示例提示（few-shot prompting）的方法，显示了框架的鲁棒性和适应性。", "conclusion": "GenOM在OAEI Bio-ML赛道的扩展实验中表现良好，超过了包括传统OM系统及相对新的LLM方法在内的多种基线方法，并通过消融研究进一步证实了语义丰富和少量示例提示的有效性，强调了该框架的鲁棒性和适应性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10539", "html_url": "https://arxiv.org/abs/2508.10539", "title": "通过低成本降低方差改进基于价值的过程验证器", "title_en": "Improving Value-based Process Verifier via Low-Cost Variance Reduction", "authors": "Zetian Sun,Dongfang Li,Baotian Hu,Min Zhang", "background": "大规模语言模型（LLMs）在各种任务中取得了显著的成功，但在复杂的领域如数学中的推理能力仍然是一个重要的挑战。价值导向的过程验证器通过评估推理链导致正确解决方案的概率来估计，是一种有希望的提高推理能力的方法。然而，由于LLM推理成本高昂，有限的蒙特卡洛（MC）采样导致了标注中估计误差的发生。现有的MC估计器由于其高方差特性，产生了偏差，从而限制了其有效性。", "innovation": "本文提出了复合蒙特卡洛采样（ComMCS）方法，通过将当前步骤和后续步骤的MC估计器线性组合来构建一个无偏估计器。理论上证明了该方法能减少方差并保持无偏估计，而不需要额外的LLM推理成本。实验证明ComMCS在MATH-500和GSM8K基准上优于基于回归优化的方法和非降方差基线，特别是在Best-of-32采样实验中分别提高了2.8个和2.2个点的准确率。", "conclusion": "本文提出了一种基于无偏估计的新方法ComMCS，通过合并不同步骤的MC估计来减少方差，同时保持预测的良好性能。在两个基准上的实验表明，ComMCS在降低方差方面具有显著优势，提高了基于价值的过程验证器的效果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09992", "html_url": "https://arxiv.org/abs/2508.09992", "title": "OpenFPL：一种与顶级幻想英超服务相媲美的开源预测方法", "title_en": "OpenFPL: An open-source forecasting method rivaling state-of-the-art Fantasy Premier League services", "authors": "Daniel Groos", "background": "Fantasy Premier League通过让社区参与挑选在每周表现最佳的英超球员来吸引球迷。准确的性能预测使参与者能够比竞争对手更有优势，通过指导关于球员表现的期望减少选择阵容的不确定性。然而，这些高精度预测主要受到商业服务的限制，这些服务的内部运作是保密的，并依赖于专有数据。", "innovation": "本文介绍了OpenFPL，一种仅基于公开数据开发的开源幻想英超预测方法。OpenFPL包括针对不同位置优化的组合模型，这些模型在四个赛季（2020-21到2023-24）的幻影英超和Understat数据上得到了优化。OpenFPL的预测准确度在测试时与领先商业服务相当，特别是在预测高回报玩家（>2分）的表现方面超越了商业基准，这些玩家对于排行提升最重要。", "conclusion": "OpenFPL在1周、2周和3周预测区间内的表现都优于或等于领先的商业预测服务，支持长期转会和策略规划，同时也帮助在最后一天做出关键决策。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10599", "html_url": "https://arxiv.org/abs/2508.10599", "title": "MSRS: 调适的多子空间表示导向调控在大型语言模型属性对齐中的应用", "title_en": "MSRS: Adaptive Multi-Subspace Representation Steering for Attribute Alignment in Large Language Models", "authors": "Xinyan Jiang,Lin Zhang,Jiayi Zhang,Qingsong Yang,Guimin Hu,Di Wang,Lijie Hu", "background": "大型语言模型通过直接操控其内部激活来控制行为的方法被称为激活导向，然而大多数现有方法难以同时操控多个属性，往往导致相互干扰和不理想的权衡取舍。背景描述了当前方法的局限性，特别是在多属性操控方面的问题和挑战。", "innovation": "提出了多子空间表示导向调控（MSRS），这是一种基于子空间表示精调的全新框架，可以有效进行多属性操控。MSRS通过分配正交子空间给每个属性来减少属性间的相互干扰，并隔离其影响。MSRS还引入了一种混合子空间组合策略，结合属性特定子空间和共享子空间，以实现独特的操控方向和通用的方向。动态权重函数学习有效地整合这些组成部分，实现精确控制。此外，MSRS在推理过程中引入了一种标记级操控机制，可以动态识别和干预最具语义相关性的标记，实现精细的行为调节。研究表明，MSRS显著减少了属性冲突，超越了现有方法，并有效地应用于各种下游任务中。", "conclusion": "实验表明，MSRS显著减少了属性冲突，优于现有方法，并在广泛的应用任务中表现出良好的泛化能力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10486", "html_url": "https://arxiv.org/abs/2508.10486", "title": "SEQ-GPT：通过示例的LLM辅助空间查询", "title_en": "SEQ-GPT: LLM-assisted Spatial Query via Example", "authors": "Ivan Khai Ze Lim,Ningyi Liao,Yiming Yang,Gerald Wei Yong Yip,Siqiang Luo", "background": "当前的在线地图等空间服务主要依赖用户的查询来进行位置搜索。然而，在执行复杂任务时，如同时搜索一组位置时，用户体验受限。针对这种情况，本研究探讨了名为Spatial Exemplar Query (SEQ) 的扩展场景，该场景允许用户通过提供的示例联合搜索多个相关位置。通过引入基于大型语言模型（LLM）的 SEQ-GPT 系统，利用自然语言实现更灵活的 SEQ 查询。LLM 的语言能力提供了独特的交互操作，包括要求用户澄清查询细节以及根据用户的反馈动态调整搜索结果。此外，还提出了一种针对自然语言与结构化空间数据及查询之间的对话合成和多模态合作而定制的LLM适应管道。最终展示了使用现实数据和应用场景实现广泛的空间搜索的全过程。", "innovation": "引入了利用大型语言模型（LLM）实现自然语言驱动的空间查询系统SEQ-GPT，利用LLM的强大语言能力提供新的交互操作，包括请求用户澄清查询细节和根据用户反馈动态调整搜索结果。同时，设计了一种定制的LLM适应管道，将自然语言与结构化空间数据及查询同步。该系统提供了广泛的空间搜索演示，完全基于现实数据和实际应用场景。", "conclusion": "本研究提出了基于大型语言模型的SEQ-GPT空间查询系统，利用自然语言实现了灵活的复杂空间查询处理。通过对话合成和多模态合作，将自然语言与结构化空间数据同步，增强了用户体验。在现实数据和应用场景中的实证展示了系统的效果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09991", "html_url": "https://arxiv.org/abs/2508.09991", "title": "AI创新与卫生保健需求对接：BC癌症登记处引入现代NLP的教训", "title_en": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry", "authors": "Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji", "background": "在医疗保健环境中，自动从临床文档中提取数据有望提高效率，但实施基于自然语言处理（NLP）的解决方案存在实际挑战。本文基于在不列颠哥伦比亚癌症登记处（BCCR）实施各种NLP模型以进行信息提取和分类任务的经验，分享了项目生命周期中的关键教训。重点强调根据明确的业务目标定义问题，而非仅技术准确性，采用迭代开发方法，并在从一开始就促进跨学科合作和参与，涉及领域专家、最终用户和机器学习专家。进一步的见解强调了务实的模型选择（包括混合方法和在适当情况下使用更简单的方法）、对数据质量（代表性、漂移、注释）的高度关注，以及将出现的错误纳入闭环验证和持续审核的严格管理策略，并通过提高组织的AI认知提升实践。这些实操考虑，不仅仅适用于癌症登记处，还为寻求成功引入AI/NLP解决方案以增强数据管理流程并最终改善患者护理和公共卫生结果的医疗保健组织提供了指导。", "innovation": "研究采用了一种跨学科合作的方式，并强调了务实的模型选择、数据质量的管理、错误预防策略以及组织内的AI知识普及。这是基于不列颠哥伦比亚癌症登记处的特定案例研究，并为类似组织提供了宝贵的经验和教训。", "conclusion": "研究的结论是，通过定义清晰的业务目标、迭代开发、跨学科合作以及务实的AI模型和数据管理策略，可以帮助组织成功实施NLP解决方案，从而提高数据管理效率，并最终改善患者护理和公共健康结果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10769", "html_url": "https://arxiv.org/abs/2508.10769", "title": "多模态AI内容的人类响应建模", "title_en": "Modeling Human Responses to Multimodal AI Content", "authors": "Zhiqi Shen,Shaojing Fan,Danni Xu,Terence Sim,Mohan Kankanhalli", "background": "随着AI生成内容的普及，虚假信息的风险随之增加。尽管以往的研究主要集中在验证内容的真实性上，但对于AI生成内容如何影响人类感知和行为的研究却较少。在交易或股票市场等领域，预测人们如何反应（例如，一条新闻帖子是否会病毒式传播），比验证其事实准确性更为重要。本文提出了一个以人类为中心的方法，介绍了一个包含154,552个在线帖子（其中111,153个为AI生成）的数据集——MhAIM数据集。该数据集用于大规模分析人们对AI生成内容的反应。研究表明，在帖子包含文本和视觉内容且二者存在不一致时，人们更容易识别AI生成的内容。", "innovation": "本文提出了一个新的视角，专注于研究AI生成内容如何影响人类的反应。它包括一个名为MhAIM的数据集，以及三个新的评估指标：可信度、影响和开放性，用于量化用户如何判断和与在线内容互动。此外，还提出了一个基于大语言模型的T-Lens代理系统，该系统能够回答用户关于多模态信息的问题，通过集成预测的人类响应，增强系统的交互能力。文中还介绍了一个名为HR-MCP的人机响应模型上下文协议，其基于标准化的模型上下文协议，使T-Lens能够更好地与人类反应对齐，提高系统的可解释性和互动性。", "conclusion": "本文提供了实证洞察和实用工具，以增强大语言模型的人类意识能力。通过展示AI、人类认知和信息接收之间的复杂互动，研究结果提出了减轻AI驱动的虚假信息风险的可行动策略。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09636", "html_url": "https://arxiv.org/abs/2508.09636", "title": "个性化产品搜索排序：结合表数据和非表数据的多任务学习方法", "title_en": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data", "authors": "Lalitesh Morishetti,Abhay Kumar,Jonathan Scott,Kaushiki Nag,Gunjan Sharma,Shanu Vashishtha,Rahul Sridhar,Rohit Chatter,Kannan Achan", "background": "本文介绍了使用多任务学习框架优化个性化产品搜索排序的新型模型架构。该方法结合了表数据和非表数据，并利用预训练的TinyBERT模型进行语义嵌入，以及新颖的采样技术来捕捉多样化的客户行为。该研究还提出了一种基于点击率、点击位置和语义相似性的可扩展相关性标签机制，作为传统人类标注标签的替代方案。实验结果显示，将非表数据与多任务学习范式中的高级嵌入技术结合使用，可以显著提高模型性能。消融研究进一步证实了结合相关性标签、调整TinyBERT层以及TinyBERT查询-产品嵌入交互的优势。这些结果证明了该方法在个性化产品搜索排序方面的有效性。", "innovation": "本文的独特之处在于结合了表数据和非表数据，并使用预训练的TinyBERT模型进行语义嵌入，同时采用新颖的采样技术捕捉多样化的客户行为。此外，还提出了基于点击率、点击位置和语义相似性的可扩展相关性标签机制，作为替代传统人类标注标签的方案。研究显示，在多任务学习范式中结合非表数据和高级嵌入技术显著提升了模型性能。", "conclusion": "本文的多任务学习方法结合了非表数据和表数据，利用预训练的TinyBERT模型进行语义嵌入，并采用新颖的采样技术捕捉多样化的客户行为。实验结果表明，结合相关性标签、调整TinyBERT层以及TinyBERT查询-产品嵌入交互可以显著提高个性化产品搜索排序的性能。这种方法在处理混合数据类型和优化个性化排名方面表现出色。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10017", "html_url": "https://arxiv.org/abs/2508.10017", "title": "在不平衡临床数据上使用SMOTETomek和FedProx的差异隐私联邦学习稳健管道", "title_en": "A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx", "authors": "Rodrigo Tertulino", "background": "联邦学习（FL）提供了一种协作健康研究的新颖方法，可以在不集中数据的情况下进行模型训练，同时保护患者隐私。结合差分隐私（DP），FL提供了正式的安全保证。然而，将这些技术集成在一起带来了隐私和临床效用之间的重大权衡，特别是在医疗数据集中的类别不平衡问题上。本文通过对心血管风险预测进行分阶段的系统分析，解决了这些问题。", "innovation": "本文通过在客户端引入混合SMOTETomek和优化FedProx算法，提出了一种解决方案，克服了标准方法在不平衡数据下的限制，实现了具有临床用途的模型。研究表明，优化后的FedProx算法在隐私预算和模型召回率之间存在非线性权衡，而优化后的FedProx方法在保持强隐私保证（ε=9.0）的同时，依旧能够实现高临床效用（召回率大于77%）。", "conclusion": "研究提供了一个实用的方法框架，用于创建有效的、安全的、准确的诊断工具，适用于现实世界的异构医疗数据。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09998", "html_url": "https://arxiv.org/abs/2508.09998", "title": "INTIMA: 人类与人工智能伴侣行为的标准", "title_en": "INTIMA: A Benchmark for Human-AI Companionship Behavior", "authors": "Lucie-Aimée Kaffee,Giada Pistilli,Yacine Jernite", "background": "人工智能伴侣的发展已经带来了积极但也有令人担忧的影响，用户与AI系统形成了情感联系。为了评估语言模型中的伴侣行为，研究人员开发了Interactions and Machine Attachment Benchmark (INTIMA)，基于心理理论和用户数据，制定了涵盖四类31种行为的分类体系，并针对368个特定提示进行评估。", "innovation": "INTIMA引入了一个新的评估框架，通过分类31种伴侣行为，评估模型在回应特定提示时的行为是否有助于建立情感联系、保持边界或中立。该评估方法的一大创新在于，它定量地评估了各种语言模型处理敏感情感互动的方式，揭示了不同提供商在处理这些行为时的差异。", "conclusion": "该研究表明，各类语言模型普遍更倾向于表现伴侣行为中有助于建立情感联系的行为，但在处理更敏感的部分时，各个提供商的策略差异明显。这突显了在处理情感密集交互时需要保持更加一致的方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10005", "html_url": "https://arxiv.org/abs/2508.10005", "title": "从答案到问题：评估LLMs的教育性问题生成——EQGBench", "title_en": "From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation", "authors": "Chengliang Zhou,Mei Wang,Ting Zhang,Qiannan Zhu,Jian Li,Hua Huang", "background": "大型语言模型（LLMs）在数学问题解决方面已经展示了卓越的能力，但如何从提供答案转向生成高质量的教育性问题，目前仍存在显著挑战且未被充分探索。为此，本文提出了一种名为EQGBench的全面基准测试，专门用于评估LLMs在中国语文教育性问题生成（EQG）方面的能力。EQGBench建立了一个五维评价框架，基于涵盖数学、物理和化学三个中学基础学科的900个评价样本。数据集包括不同知识点、难度梯度和问题类型依据的用户查询，以模拟真实教育情景。", "innovation": "提出了EQGBench，这是专门为评估LLMs在生成教育性问题中的性能而设计的基准测试。它针对中文EQG，提供了900个涵盖数学、物理和化学三个基础中学学科的评价样本，并基于复杂的用户查询建立了五维评估框架。这种方法揭示了生成具有教育价值的问题并培养学生成全面能力的显著潜力，超越了现有技术的能力范围，引领LLMs在教育领域中的应用突破。", "conclusion": "通过系统评估46种主流大型模型，研究揭示了现有LLMs在生成反映教育价值和培养学生综合能力的问题方面，仍有很大的改进空间。这为促进LLMs在教育领域的发展提供了新思路和标准，有助于提升教育质量和技术的实际应用价值。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10009", "html_url": "https://arxiv.org/abs/2508.10009", "title": "超越硬共享：基于监督专家混合的高效多任务语音到文本建模", "title_en": "Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts", "authors": "Hojun Jin,Eunsoo Hong,Ziwon Hyung,Sungjun Lim,Seungjin Lee,Keunseok Cho", "background": "硬参数共享是一种常见的策略，用于训练单个模型以同时处理多种任务。然而，这种方法通常会导致任务间的干扰，进而影响整体模型的性能。", "innovation": "提出了一种简单有效的监督专家混合模型（S-MoE）。S-MoE 通过使用特殊引导标记来路由每个任务到其指定的专家，从而避免了传统混合专家模型中需要训练门控函数的步骤。每个任务都被分配到一个单独的前馈网络，克服了硬参数共享的局限性。", "conclusion": "S-MoE 在语音到文本模型中得到了应用，能够处理不同带宽的输入并同时执行自动语音识别（ASR）和语音翻译（ST）。实验结果表明，当应用于编码器和解码器时，S-MoE 可以实现 6.35% 的词错误率（WER）相对改进。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10001", "html_url": "https://arxiv.org/abs/2508.10001", "title": "HiFACTMix: Hinglish中的基于证据的政治声明验证的新基准和图意识模型", "title_en": "HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish", "authors": "Rakesh Thakur,Sneha Sharma,Gauri Chopra", "background": "代码混合的低资源语言如混合英语（Hinglish）中的事实核查仍然是自然语言处理中未充分探索的挑战。现有的事实验证系统主要集中在高资源、单一语言的环境中，并且在语言多样性较高的地区如印度，无法很好地应用于现实政治对话。鉴于公共人物特别是政治人物广泛使用Hinglish，以及社交媒体对公众意见日益增长的影响，需要一种稳健的、多语言的、上下文感知的事实核查工具。鉴于此，本文介绍了一个新的基准数据集HiFACT，包含印地28个州首席部长提出的1500条真实的事实陈述，这些陈述都用Hinglish编写。该数据集在高度代码混合的低资源环境中标注了每条陈述的证据文本和真实标签。", "innovation": "提出的HiFACTMix模型是一种创新的图感知、检索增强的事实核查模型，组合了多语言上下文编码、声明与证据语义对齐、证据图构建、图神经网络推理和自然语言解释生成。该模型在对比现有的多语言基准模型时表现出更高的准确性，并且提供了对其裁决的忠实说明。该研究为多语言、代码混合及政治导向事实验证的研究开辟了新的方向。", "conclusion": "HiFACT提出了一个基于证据的政治声明验证的新基准和图感知模型。模型在多语言基准模型上的表现优异，可以为其裁决提供可靠的解释。这为今后多语言、代码混合和政治导向的事实验证研究奠定了基础。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10020", "html_url": "https://arxiv.org/abs/2508.10020", "title": "FedCoT: 为大型语言模型的高效联邦推理增强", "title_en": "FedCoT: Communication-Efficient Federated Reasoning Enhancement for Large Language Models", "authors": "Chuan Li,Qianyi Zhao,Fengran Mo,Cen Chen", "background": "在联邦学习环境中增强大型语言模型（LLMs）的推理能力仍然是一个挑战，尤其是在平衡性能提升与严格的计算、通信和隐私约束之间时。特别是在医疗保健领域，决策覆盖临床、运营以及面向患者的各种情境，不仅需要准确的输出，还需要解释合理、可追踪的推理过程以确保安全性、可问责性和监管合规性。现有的联邦调优方法主要针对答案的正确性进行优化，忽视了推理质量，使得CoT（思维链条）能力依赖于模型的先验训练能力。此外，现有方法提高推理质量通常依赖于从集中式模型中提取的隐私侵犯的知识蒸馏过程。同时，传统的联邦微调在大型语言模型中的通信开销依然很大。", "innovation": "我们通过提出FedCoT（联邦推理链条）框架，填补了这一空白。FedCoT利用了一个轻量级的链条增强机制：本地模型生成多条推理路径，紧凑的鉴别器动态选择最有前景的一条。这种方法提高了推理准确性、稳健性，同时提供了有价值的理解性，这对于医疗应用尤其关键。为有效管理客户端异质性，我们采用了一种改进的聚合方法，基于先进的LoRA模块堆叠，并结合客户端分类器意识，实现了跨不同客户端的无噪声聚合。", "conclusion": "全面的实验表明，在严格资源预算下，FedCoT显著增强了客户端的推理性能，同时完全保持了数据隐私。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10018", "html_url": "https://arxiv.org/abs/2508.10018", "title": "通过品类同伦理论解决大语言模型中的语言异形等效问题：一闻芬芳何须问寻玫瑰别名", "title_en": "A Rose by Any Other Name Would Smell as Sweet: Categorical Homotopy Theory for Large Language Models", "authors": "Sridhar Mahadevan", "background": "自然语言中充满了表面上不同的陈述，例如“Charles Darwin wrote”和“Charles Darwin is the author of”，它们具有相同的意义。大型语言模型（LLMs）在这些情况下应该生成相同的时间概率，但实际上通常不会。目前采用了一些经验方法来解决这一问题，例如通过k-NN估计句子相似度来进行平滑估计。然而，这种方法遇到了困难，因为语言充满了等价的同义表达，每个都有自己在LLM品类类别中的不同箭头。", "innovation": "本文采用品类同伦技术在LLM品类类别中捕获‘弱等价’，提供了更高代数K-理论及模型类别学的详细应用，从而解决上述基本问题，为LLM中语言异形等效现象提供了新的抽象解决方案。", "conclusion": "通过引入品类同伦理论，本文为大型语言模型生成等价表达提供了统一的方法。这种方法不仅简化了模型训练过程，还提高了模型生成一致性的表达结果的能力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10022", "html_url": "https://arxiv.org/abs/2508.10022", "title": "带有可证明风险控制的多项选择题答案置信值", "title_en": "Conformal P-Value in Multiple-Choice Question Answering Tasks with Provable Risk Control", "authors": "Yuanchang Ye", "background": "大型语言模型（LLMs）在多个学科的问答场景中越来越广泛地应用，但它们的幻想和非事实生成大大地损害了答案的可靠性。现有的基于置信分配的预测区间方法虽然提供了统计严谨的边际覆盖保证，但它们与显著性检验的结合尚未被研究。因此，通过引入一种将显著性检验与遵从性评分结合的置信预测框架，以提高大型语言模型在多项选择题问答的可靠性，成为当前亟待解决的问题。", "innovation": "本文提出了一种增强的置信预测（CP）框架，通过将$p$-值计算与一致性评分结合，采用自我一致性重采样方法来评估多项选择题的答案，通过基数检验构建预测区间，从而实现用户指定的经验覆盖误差，同时也验证了预测集大小作为不确定性度量的有效性。这种方法的创新之处在于其综合了现有技术和统计学原理，提出了一种新的评估和验证方法，以提高大型语言模型在高风险应用场景中的信赖度，特别是在实际部署中能够控制可证明的风险水平。", "conclusion": "本文建立了一个严谨的统计框架，用于大型语言模型在高风险问答应用场景中的部署，通过显著性检验与自我一致性评分结合的方法，提高了LLMs在多项选择题任务中的可靠性，同时验证了平均预测集大小作为不确定性度量的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10024", "html_url": "https://arxiv.org/abs/2508.10024", "title": "RTTC: Reward-Guided Collaborative Test-Time Compute", "title_en": "RTTC: Reward-Guided Collaborative Test-Time Compute", "authors": "J. Pablo Muñoz,Jinjie Yuan", "background": "测试时计算（TTC）已成为增强大型语言模型（LLMs）推理性能的强大范式，通过使用如测试时训练（TTT）和检索增强生成（RAG）等策略。然而，不同的查询需要不同的适应策略，盲目应用TTC策略会导致大量的计算开销。", "innovation": "本文介绍了一种新颖的框架——奖励导向的测试时计算（RTTC），它通过预训练的奖励模型自适应地选择最适合每个查询的TTC策略，从而在多种领域和任务中最大化下游准确性。此外，RTTC在分布式服务器-客户端架构中工作，仅在必要时在客户端设备上应用RAG或轻量级微调，并使用查询状态缓存来有效重用历史查询状态，从而进一步减少了冗余计算。", "conclusion": "跨多个LLM和基准的广泛实验表明，RTTC在准确性方面始终优于传统的RAG或TTT，验证了适应性、奖励导向的TTC选择的必要性，并证明了RTTC在可扩展、高性能的语言模型适应方面的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10003", "html_url": "https://arxiv.org/abs/2508.10003", "title": "大型语言模型嵌入中的语义结构", "title_en": "Semantic Structure in Large Language Model Embeddings", "authors": "Austin C. Kozlowski,Callin Dai,Andrei Boutyline", "background": "心理学研究发现，人类对不同语义尺度上的单词评级可以被简化为低维度形式。这项研究发现，大型语言模型（LLMs）中的词嵌入矩阵中蕴含的语义关联也表现出类似的结构。具体而言，通过反义词对定义的语义方向（如kind和cruel），词汇在这些方向上的投影与人类评级高度相关，并且这些投影被发现可以在LLMs嵌入中有效简化为3维子空间，这与从人类调查响应中得出的模式相似。此外，沿一个语义方向平移词会随着它们的余弦相似度对齐特征产生脱靶效果。这些发现表明，语义特征在LLMs中以类似于人类语言中相互连接的方式纠缠在一起，尽管语义信息看似复杂，但实际上相当低维度。因此，考虑这种语义结构可能在引导特征时至关重要，以避免意外后果。", "innovation": "研究发现大型语言模型的嵌入矩阵中蕴含的语义关联表现出与人类评级相似的低维结构。具体而言，词汇沿反义词对定义的语义方向的投影与人类评级高度相关，并且这些投影在LLMs嵌入中有效简化为3维子空间，这与从人类调查响应中得出的模式相似。此外，研究揭示了沿语义方向平移词会随着余弦相似度对齐特征产生脱靶效果。这些结果表明语义特征在大型语言模型中以类似于人类语言的方式纠缠在一起，尽管看上去复杂但实际上是低维度的。因此，理解和考虑这种语义结构在触发特征时是至关重要的，以避免意外的结果。", "conclusion": "这些发现表明语义特征在大型语言模型中类似于人类语言中相互连接的方式纠缠在一起，并且尽管看上去复杂但实际上是低维度的。因此，考虑这种语义结构可能会避免在引导特征时产生的意外后果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10019", "html_url": "https://arxiv.org/abs/2508.10019", "title": "通过问题空间映射来解耦理解与推理的小规模模型推理", "title_en": "Decoupling Understanding from Reasoning via Problem Space Mapping for Small-scale Model Reasoning", "authors": "Li Wang,Changhao Zhang,Zengqi Xiu,Kai Lu,Xin Yu,Kui Zhang,Wenjun Wu", "background": "尽管大型语言模型（LLMs）的推理能力有了显著提升，但小型语言模型（SLMs，例如≤1.5B）的推理能力改进依然面临挑战。自然语言的复杂性和多样性是主要障碍之一，相同的核心问题可能会以多种表面形式出现，隐藏于冗余或分散注意力的细节之中。这给SLMs带来了双重负担：首先，它们需要从复杂的语言输入中提取核心问题，然后基于理解进行推理。这种广泛的、噪声多的问题空间阻碍了模型的优化，特别是对于那些容量有限的模型。因此，本文旨在通过将自然语言问题映射到一个标准化且语义简化的问题空间内，来解决这一问题，旨在使SLMs能够专注于涉及标准化输入的推理，从而摆脱语言多样性的干扰。", "innovation": "本文提出了一种新的框架，通过问题空间映射解耦理解与推理，引入了DURIT算法，该算法包含三个步骤：通过强化学习映射自然语言问题、通过自蒸馏对齐推理轨迹、在问题空间内训练推理策略。映射器和推理器在整个过程中交替训练。实验表明，DURIT显著提升了SLMs在域内和域外数学和逻辑推理任务上的表现。同时，DURIT还增强了推理的鲁棒性，验证了解耦理解与推理作为强化SLMs的有效策略的有效性", "conclusion": "本文提出了一种新的方法，通过问题空间映射来解耦理解和推理，显著提升了小型语言模型在数学和逻辑推理任务上的性能，并增强了模型推理的鲁棒性，证明了解耦策略的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10026", "html_url": "https://arxiv.org/abs/2508.10026", "title": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "title_en": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "authors": "Kai Zhao,Yanjun Zhao,Jiaming Song,Shien He,Lusheng Zhang,Qiang Zhang,Tianjiao Li", "background": "大语言模型（LLMs）结合了链式思考推理能力，在复杂任务上取得了显著的准确率，但当均匀应用到所有问题时，会因为推理成本过高和延迟增加而受到影响。", "innovation": "提出了SABER（Switchable and Balanced Training for Efficient LLM Reasoning），一种强化学习框架，赋予LLMs用户可控性和基于token的推理预算。SABER通过在训练中首先为每个示例的基于模型的思考token使用进行分析，并分配到预定义的预算级别，然后在微调过程中通过系统提示和长度感知奖励使模型遵循分配的预算。此外，通过引入没有推理的示例来确保模型即使在关闭显式推理时仍保持可靠性。SABER支持四种不同推理模式——noThink、FastThink、CoreThink和DeepThink，允许在延迟和推理深度之间进行灵活的权衡。", "conclusion": "广泛的评估表明，SABER在紧张的预算下能实现高准确度，平稳降级，并实现有效的跨尺度和跨领域泛化。特别地，SABER-FastThink将推理长度减少了65.4%，相比基础模型在MATH基准测试上准确率提高了3.6%。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10025", "html_url": "https://arxiv.org/abs/2508.10025", "title": "使用生成式人工智能实时检测和解释产后期抑郁症", "title_en": "Detecting and explaining postpartum depression in real-time with generative artificial intelligence", "authors": "Silvia García-Méndez,Francisco de Arriba-Pérez", "background": "产后抑郁症（PPD）是母亲在产后期面临的一个严重问题，对她们的身心健康有着显著影响。因此，快速检测PPD及其相关风险因素对于及时评估和干预至关重要，旨在通过专业预防措施提供及时的筛查和治疗建议。研究背景强调了利用最新技术，如自然语言处理、机器学习和大模型，实现实时筛查和治疗推荐的重要性，从而帮助医疗实践者做出更明智的决策。", "innovation": "该研究通过结合自然语言处理、机器学习和大语言模型，开发了一个实时的免费言语分析智能PPD筛查系统。此外，通过将大模型与可解释的机器学习模型（如基于树的算法）结合，解决了黑箱问题，解释了预测结果。该系统在所有评估指标上的PPD检测准确率达到90%，优于文献中现有的竞争解决方案。研究的创新在于利用先进技术实现了实时筛查，并提供了可解释的预测结果。", "conclusion": "该研究的解决方案贡献了快速检测PPD及其相关风险因素的能力，这对于及时和准确的评估和干预至关重要。通过结合先进技术，该系统能够为医疗服务提供者提供实时的筛查和治疗推荐，从而更好地支持产后期母亲的健康。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10028", "html_url": "https://arxiv.org/abs/2508.10028", "title": "PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs", "title_en": "PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs", "authors": "Xiao Fu,Hossein A. Rahmani,Bin Wu,Jerome Ramos,Emine Yilmaz,Aldo Lipani", "background": "个性化文本生成对于以用户为中心的信息系统至关重要，但大多数评估方法忽略了用户个体性。现有方法往往依赖于预定义的个性化参考标准，这并不符合实际情况。", "innovation": "本文提出了PREF框架，这是一种参考无关的个性化评估框架，能够在不需要预定义个性化参考标准的情况下，同时衡量文本输出的质量和用户特定的匹配度。PREF框架通过三个阶段来工作：第一个是覆盖阶段，使用大型语言模型生成查询特定的指南，覆盖普遍性标准，例如事实性、连贯性和完整性；第二个是偏好阶段，根据目标用户的职业资料、已声明或推断出的偏好以及上下文，重新排列并补充这些因素，生成个性化的评估标准；第三个是评分阶段，使用另一个大型语言模型来评分候选的答案，确保基准的充足性并捕捉主观优先级。这种覆盖和偏好分离提高了系统稳健性、透明度和可重用性，使较小的模型能够模拟更大模型的个性化质量。PREF在PreEval基准测试中的实验表明，其比强大的基线方法具有更高的准确性、更好的校准度和更接近的人类判断一致性。", "conclusion": "通过提供一种可扩展、可解释并且用户对齐的评价方法，PREF为个性化语言生成系统的可靠评估和开发奠定了基础。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10027", "html_url": "https://arxiv.org/abs/2508.10027", "title": "LLMCARE：通过大型语言模型生成的合成数据增强的变压器模型进行阿尔茨海默病检测", "title_en": "LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data", "authors": "Ali Zolnour,Hossein Azadmaleki,Yasaman Haghbin,Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sina Rashidi,Masoud Khani,AmirSajjad Taleban,Samin Mahdizadeh Sani,Maryam Dadkhah,James M. Noble,Suzanne Bakken,Yadollah Yaghoobzadeh,Abdol-Hossein Vahabie,Masoud Rouhizadeh,Maryam Zolnoori", "background": "阿尔茨海默病及相关痴呆症（ADRD）影响美国约五百万老年人，但超过一半的人未被诊断出来。基于语音的自然语言处理（NLP）方法有望通过语言标记检测早期认知衰退，具有扩展性。本文利用DementiaBank \"饼干盗窃\"任务的转录资料，开发和评估了一种融合了变压器嵌入和手工制作的语言特征的筛查管道。这种方法还包括测试使用大型语言模型合成语音的数据增强技术，以及评估单一模态与多模态大型语言模型分类器在ADRD检测中的基准。研究表明，这种方法在ADRD检测中具有一定的优势，并揭示了语言模型生成的合成数据在数据增强中的潜力。", "innovation": "该研究创新性地结合了变压器嵌入和手工制作的语言特征，测试了大型语言模型生成的合成语音用于数据增强的技术，并评估了单一模态与多模态大型语言模型在ADRD检测中的表现。通过这些方法，该研究在ADRD早期阶段的检测方面取得了一定的进步。", "conclusion": "融合变压器嵌入与语言特征能够增强ADRD从语音中检测的表现。临床调优的语言模型在分类和数据增强中提供了有效支持，但多模态模型的发展仍有待进一步提升。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10029", "html_url": "https://arxiv.org/abs/2508.10029", "title": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs", "title_en": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs", "authors": "Wenpeng Xing,Mohan Li,Chunqiang Hu,Haitao XuNingyu Zhang,Bo Lin,Meng Han", "background": "大型语言模型（LLMs）在各种语言任务中展示了令人印象深刻的性能，但它们容易受到规避其安全对齐机制的‘牢笼逃脱’攻击的影响。现有研究引入了一种基于表示的攻击方法，称为Latent Fusion Jailbreak（LFJ），通过插值有害查询和良性查询的秘密状态来触发禁止响应。", "innovation": "LFJ 方法通过选择具有高主题和句法相似性的查询对，进行梯度引导的秘密状态插值，并优化以平衡攻击成功率、输出流畅性和计算效率。通过在 Vicuna 和 LLaMA-2 模型上的评估，该方法获得了平均攻击成功率 (ASR) 达到 94.01%，远超现有方法。为了防御 LFJ 攻击，提出了对抗性训练防御方法，通过微调模型来缩小插值样例的 ASR，同时不会损害良性输入上的性能。", "conclusion": "消融研究表明，查询对选择、隐藏状态插值组件和优化策略对于 LFJ 方法的有效性至关重要。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10031", "html_url": "https://arxiv.org/abs/2508.10031", "title": "Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs", "title_en": "Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs", "authors": "Jinhwa Kim,Ian G. Harris", "background": "大型语言模型（LLMs）在性能方面取得了显著进步，但各种侧道攻击给安全和伦理带来了日益增长的风险。恶意用户常利用对抗上下文来欺骗LLMs，促使它们生成有害查询的响应。现有的增强LLMs安全性的方法往往会影响其原有性能，可能影响无辜用户的经验。", "innovation": "本文提出了一种新的防御机制——上下文过滤模型，这是一种输入预处理方法，旨在过滤掉不可信和不可靠的上下文，同时识别包含真实用户意图的主要提示，以揭示隐藏的恶意意图。这种方法可以在不修改原有模型的情况下，增强所有LLMs的安全性，包括白盒和黑盒模型。实验结果显示，该模型能够将侧道攻击的成功率降低高达88%，同时保持原LLMs的性能，达到最先进的安全和有用性产品成果。", "conclusion": "我们的模型展示了在保持原LLMs性能的同时，减少侧道攻击成功率达到88%的能力，实现了最先进的安全和有用性产品效果。此外，该模型是即插即用的方法，可以应用于所有LLMs以增强其安全性，无需对模型进行任何微调。我们将公开该模型供研究使用。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10030", "html_url": "https://arxiv.org/abs/2508.10030", "title": "Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models", "title_en": "Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models", "authors": "Saaduddin Mahmud,Mason Nakamura,Kyle H. Wray,Shlomo Zilberstein", "background": "现有的提示优化方法已经展示了显著的效果，在黑盒大语言模型中对齐这些模型。与此同时，推断扩展策略（如Best-of-N抽样和多数投票）也证明了通过权衡计算能力来提高对齐和性能。然而，现有的提示优化方法不考虑推断策略；它们在优化提示时不考虑部署时使用的推断策略。这种做法存在重要的方法论缺口，因为我们的实证和理论分析表明，这两者之间存在很强的相互依赖性。此外，用户在多个目标和推断预算之间的权衡偏好极大地影响了提示和推断配置的选择。", "innovation": "引入了一种新颖的集成框架IAPO（推断感知提示优化），能够在关注推断预算和不同任务目标的情况下同时优化提示和推断规模。通过这种方式，该框架解决了现有方法论的缺口。此外，开发了一种用于IAPO的预算固定训练算法，称为PSST（通过顺序裁剪进行提示缩放），并分析了有限预算下的误差概率保证。该研究在六个不同的任务上评估了PSST的有效性，包括多目标文本生成和推理，进一步证实了在提示优化时纳入推断感知作用的重要性。", "conclusion": "通过引入IAPO框架和PSST算法，该研究解决了目前方法论的缺口，证明了在黑盒大语言模型中通过提示优化进行对齐时考虑推断感知的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10033", "html_url": "https://arxiv.org/abs/2508.10033", "title": "认知人工智能的网络安全：基于CCS-7的护栏工程", "title_en": "Cognitive Cybersecurity for Artificial Intelligence: Guardrail Engineering with CCS-7", "authors": "Yuksel Aydin", "background": "语言模型表现出类似于人类的认知脆弱性，如情绪框架效应，这些特性传统的行为对齐方法无法涵盖。需要一种新的方法来提升人工智能系统的认知安全性。因此，该研究基于人类认知安全研究，提出了Cognitive Cybersecurity Suite (CCS-7) 七大认知安全漏洞分类，以此为框架进行了一系列实验研究，通过一种名为“先思考，再验证”（TFVA）的方法，提高了认知安全水平，并进一步评估了这种防护策略在不同语言模型架构上的表现差异。", "innovation": "该研究创新性地提出了Cognitive Cybersecurity Suite (CCS-7)，涵盖了七种认知安全漏洞。同时，该研究通过实证实验，揭示了不同语言模型架构受到的认知安全威胁模式的差异性，尤其是在某些语言模型中，一些防护措施可能会导致安全风险增加，反而起到反作用。研究表明，TFVA这样的防护策略对于模型盈利能力的实现取决于模型架构，而非通用性，强调了对不同架构进行特定认知安全测试的重要性。", "conclusion": "研究将认知安全性重新定义为模型特定的工程问题，即有效于某模型架构的干预措施可能在另一架构中无效甚至有害。这凸显了在实际部署前，需要根据具体模型架构进行针对性的认知安全测试。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10034", "html_url": "https://arxiv.org/abs/2508.10034", "title": "使用深度学习进行喷流图像标记：一种集成模型", "title_en": "Jet Image Tagging Using Deep Learning: An Ensemble Model", "authors": "Juvenal Bassa,Vidya Manian,Sudhir Malik,Arghya Chattopadhyay", "background": "在高能粒子物理中，喷流分类对于理解基本相互作用和探索标准模型之外的现象至关重要。喷流源自夸克和胶子的碎裂和强子化，由于其复杂的、多维的结构，识别它们具有挑战性。传统的分类方法往往无法捕捉这些复杂性，因此需要采用先进的机器学习方法。", "innovation": "本文采用两个神经网络同时作为集成模型，将喷流数据转化为二维直方图而非高维空间中的点来标记不同类型的喷流。集成模型通过结合每个组成网络的优势，在超导模型上实现优于单一网络的性能，适用于二元分类和多分类。", "conclusion": "集成模型能够通过利用每个组成网络的优势来学习喷流特征，对于标记喷流为Top夸克、轻夸克（上夸克或下夸克）以及W和Z玻色子等多种类别进行二元分类和多分类任务表现出色。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10039", "html_url": "https://arxiv.org/abs/2508.10039", "title": "针对少样本查询的黑盒多任务对抗攻击", "title_en": "Multi-task Adversarial Attacks against Black-box Model with Few-shot Queries", "authors": "Wenqiang Wang,Yan Xiao,Hao Lin,Yangshijie Zhang,Xiaochun Cao", "background": "当前的多任务对抗文本攻击依赖于共享的内部特征和大量的查询，通常针对单一任务类型，这在实际场景中对黑盒反馈API、有限的查询次数或多种任务类型的攻击效果较差。", "innovation": "本文提出了一种针对黑盒模型的少样本查询有效攻击方法，名为关键与集成多任务文本对抗攻击（CEMA）。CEMA通过利用不同任务间对抗文本的可传输性，使用插件式训练的深度级替代模型进行文本分类攻击，无需模仿受害模型，攻击仅需少量查询，将多任务攻击转化为分类攻击。", "conclusion": "CEMA方法在涉及两个、三个或六个任务（包括分类、翻译、摘要和文本到图像生成）的模型实验中，仅使用100次查询即可取得显著的攻击成功率。CEMA可以针对百度和谷歌翻译等商业API、大型语言模型和图像生成模型，展示了其实用性和有效性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10032", "html_url": "https://arxiv.org/abs/2508.10032", "title": "思考带来的成本：大型语言模型中 Jailbreak 风险的增加", "title_en": "The Cost of Thinking: Increased Jailbreak Risk in Large Language Models", "authors": "Fan Yang", "background": "我们认为LLM中的思考模式是一种非常有价值的模式，但研究发现具有思考模式的LLM更容易受到Jailbreak攻击。在 AdvBench 和 HarmBench 上评估了9个LLM，发现攻击思考模式的成功率几乎高于非思考模式。通过大量样本的研究发现，对于教育目的和过长的思考长度是成功被攻击的数据特征，而且当LLM大多知道问题是有害的时候，它也会给出有害的回答。", "innovation": "为了缓解上述问题，本文提出了一种为LLM引入安全思考干预的方法，通过在提示中添加“特定思考令牌”来明确引导LLM的内部思考过程。实验结果表明，安全思考干预可以显著降低具有思考模式的LLM的攻击成功率。", "conclusion": "研究发现，具有思考模式的LLM更容易受到Jailbreak攻击，提出了一种安全思考干预方法来降低攻击成功率。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10042", "html_url": "https://arxiv.org/abs/2508.10042", "title": "FIDELIS：区块链增强的联邦学习中数据投毒攻击防护", "title_en": "FIDELIS: Blockchain-Enabled Protection Against Poisoning Attacks in Federated Learning", "authors": "Jane Carney,Kushal Upreti,Gaby G. Dagher,Tim Andersen", "background": "联邦学习通过使用物联网设备的私人数据共同训练模型，增强了传统深度学习，确保了客户的隐私。然而，在训练过程中，联邦学习容易受到数据投毒攻击，这会损害模型性能和完整性。当前的投毒检测方法缺乏标准化检测手段，或者在信任方面存在显著的自由度。", "innovation": "本文提出了一种新颖的基于区块链的联邦学习反投毒框架\textbackslash{}Sys，该框架分散了全球服务器的角色给参与者客户端。引入了一个判别模型用于检测模型更新中的数据投毒。每个客户端生成一个判别模型并通过共识机制验证最终形成单一判别模型。实验证明，\textbackslash{}Sys 能够有效抵御数据投毒攻击，并且生成判别模型具有可扩展性。", "conclusion": "本文展示了\textbackslash{}Sys框架的有效性和可扩展性，可以作为联邦学习中数据投毒的有效防护机制。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10038", "html_url": "https://arxiv.org/abs/2508.10038", "title": "设计中的可验证稳健恶意软件检测器", "title_en": "Certifiably robust malware detectors by design", "authors": "Pierre-Francois Gimenez,Sarath Sivaprasad,Mario Fritz", "background": "恶意软件分析涉及对可疑软件进行分析以检测恶意载荷。静态恶意软件分析不依赖于软件执行，越来越多地依赖于机器学习技术以实现可扩展性。虽然这些技术能够获取非常高精度的检测率，但却可能被恶意软件制作者通过对抗样本轻易规避，即对样本进行少量修改即可欺骗检测器而不改变软件的行为。与计算机视觉等其他领域不同，对恶意软件创建对抗样本而不改变其功能需要特殊的转化方法。", "innovation": "本文提出了一个新的稳健模型架构，旨在通过设计即实现可验证的稳健恶意软件检测。此外，本文还展示出每一个稳健的检测器都可以被分解为一种特定结构，可以用于学习经验上的稳健恶意软件检测器，即使在脆弱特征上也适用。文章还提出了一种基于这种结构的框架ERDALT。在与基于机器学习的恶意软件检测方法比较和验证后，证明了这些方法能够在保证检测性能的同时实现稳健的检测.", "conclusion": "本文对机器学习驱动的恶意软件检测方法进行了比较和验证，最终证明了设计中的可验证稳健恶意软件检测器能够在不显著降低检测性能的情况下实现强大的恶意软件检测。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10050", "html_url": "https://arxiv.org/abs/2508.10050", "title": "法律零日漏洞：先进AI系统的新型风险向量", "title_en": "Legal Zero-Days: A Novel Risk Vector for Advanced AI Systems", "authors": "Greg Sadler,Nathan Sherburn", "background": "文章引入了“法律零日漏洞”作为先进AI系统的新型风险向量。这种漏洞是指在法律框架中未被发现但一旦被利用，就能引起重大社会混乱的风险。这些漏洞不需要法律诉讼或其他影响发生之前的程序。文章使用2017年澳大利亚双重国籍危机作为例子，说明看似细微的法律失误如何导致大规模治理混乱。", "innovation": "作者提出了一种风险模型来识别和评估这些潜在的漏洞，并开发了一种“法律谜题”方法作为评估AI系统发现此类漏洞能力的工具。研究表明，虽然当前的AI模型可能无法可靠地发现具有影响的法律零日漏洞，但未来的系统可能会发展这种能力，既带来了风险也带来了提高法律稳健性的机会。", "conclusion": "这项工作有助于更广泛地识别和减轻来自前沿AI系统的未被识别的风险。未来系统可能具备发现这类漏洞的能力，这对法律稳健性的改进既是挑战也是机遇。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10043", "html_url": "https://arxiv.org/abs/2508.10043", "title": "保障主体AI：网络监控主体AI系统的威胁建模与风险分析", "title_en": "Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System", "authors": "Pallavi Zambare,Venkata Nikhil Thanikella,Ying Liu", "background": "在将大型语言模型与自主代理结合应用于网络监控和决策系统时，这将引发重大安全问题。这项研究使用了包含七层威胁模型架构的MAESTRO框架，以揭示、评估和消除自主AI的漏洞。通过构建并实施原型自主系统（使用Python、LangChain以及WebSockets遥测技术），并集成推理、记忆、参数校准和异常检测模块，来证实并分析了两个实际的威胁案例：（i）网络重放导致的服务拒绝，以及（ii）通过篡改代理保存的历史日志文件造成的内存中毒。这些情况导致了可测量的性能下降，具体表现为遥测更新延迟和计算负载增加，且由于系统适应能力差所致。", "innovation": "研究采用了多层次的纵深防御策略，包括内存隔离、规划者验证和实时异常响应系统的融合，从而验证了MAESTRO的有效性：它不仅可以在操作层面定位和评估威胁，还可以为预防性风险评分和具有弹性的系统设计提供基础。研究特别强调了内存完整性执行的重要性，关注适应逻辑监控和跨层通信保护，确保在对抗环境中主体AI的可靠性，从而保证系统的安全性和稳定性。", "conclusion": "MAESTRO框架能够有效地进行操作威胁映射、前瞻性风险评分，并作为具有弹性的系统设计的基础。该研究指出了在对抗环境中保障主体AI运行可靠性的关键措施，特别注意内存完整性的保障、适应逻辑的监控以及跨层通信保护。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10040", "html_url": "https://arxiv.org/abs/2508.10040", "title": "使用可解释文本和图学习探索虚假新闻的内容和社会联系", "title_en": "Exploring Content and Social Connections of Fake News with Explainable Text and Graph Learning", "authors": "Vítor N. Lourenço,Aline Paes,and Tillman Weyde", "background": "全球范围内虚假信息的传播以及内容可信度问题驱动了自动化事实核查系统的开发。虚假信息往往通过社交媒体动态，如点赞和用户网络来提升传播力，因此有效的解决方案不仅要分析内容，还要考虑这些因素。简单地将内容标记为假信息可能无效甚至强化自动化和确认偏见。", "innovation": "本文提出了一种可解释的框架，将内容、社交媒体和图基特征结合在一起，以增强事实核查。该框架集成了虚假信息分类器和可解释性技术，提供完整且可解释的支持分类决策的洞察。实验表明，多模态信息比单一模态信息有更高的性能，评估在英语、西班牙语和葡萄牙语的数据集上进行。此外，框架的解释被使用新的协议评估了其解释性、可信度和鲁棒性，显示了其能有效生成人类可理解的预测依据。", "conclusion": "多模态信息增强了事实核查的性能；提出的框架能够赋予人类易于理解的解释，增强措施的有效性和可信度。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10046", "html_url": "https://arxiv.org/abs/2508.10046", "title": "SABIA: 一种基于人工智能的社会媒体上与阿片类药物相关的行为检测工具", "title_en": "SABIA: An AI-Powered Tool for Detecting Opioid-Related Behaviors on Social Media", "authors": "Muhammad Ahmad,Fida Ullah,Muhammad Usman,Ildar Batyrshin,Grigori Sidorov", "background": "社交媒体平台已成为了解公共卫生挑战的重要工具，提供了关于患者行为、药物使用和精神健康问题的见解。然而，分析此类数据仍然具有挑战性，因为其中普遍存在非正式语言、俚语和编码交流，这可能使识别阿片类药物滥用变得困难。本文针对社交媒体上与阿片类药物相关的用户行为问题，包括非正式表达、俚语词汇和拼写错误或编码语言，进行了研究。现有的双向编码表示（BERT）技术被分析，并开发了一个结合双向长短期记忆（BiLSTM）和三维卷积神经网络（3CNN）的混合深度学习模型——SABIA，以创建一个单一任务分类器来有效捕捉目标数据集的特征。", "innovation": "提出了一种名为SABIA的混合深度学习模型，通过其数据预处理、使用SABIA模型的数据表示、微调阶段和将用户行为分为五类的分类步骤，有效解决了识别复杂阿片类药物相关行为的问题。该模型展示了强大的语义和上下文信息捕捉能力，相对于基线（逻辑回归），SABIA的准确率提高了9.30%，表现出色并证明了其有效性和稳健性。", "conclusion": "研究表明，混合深度学习模型在社会媒体上检测复杂阿片类药物相关行为方面具有潜力，支持公共卫生监测和干预。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10052", "html_url": "https://arxiv.org/abs/2508.10052", "title": "净监控AI：一种网络安全部署与监控的代理AI框架", "title_en": "NetMoniAI: An Agentic AI Framework for Network Security & Monitoring", "authors": "Pallavi Zambare,Venkata Nikhil Thanikella,Nikhil Padmanabh Kottur,Sree Akhil Akula,Ying Liu", "background": "本文介绍了一个名为NetMoniAI的代理AI框架，用于自动网络监控和安全，该框架将去中心化的分析与轻量级的中心化协调相结合。该框架包含两层：在每一节点上的自主微代理进行本地流量分析和异常检测。中央控制器则在整个系统范围内收集信息以检测协同攻击，并保持全系统态势感知。", "innovation": "NetMoniAI框架采用两层代理AI设计，自主微代理在每个节点上执行本地流量分析和异常检测，中央控制器通过聚合各节点的洞察力来检测协同攻击并维持全系统的态势感知。评估表明，在资源受限的情况下，这种设计能够扩展、减少冗余、提高响应速度而不牺牲准确性。", "conclusion": "NetMoniAI框架提供了完整的开源版本，以促进更广泛的应用、可再现性和扩展。这使得研究人员和实践者能够在不同的网络环境和威胁场景中复制、验证并扩展它。可用的GitHub链接为：this https URL"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10115", "html_url": "https://arxiv.org/abs/2508.10115", "title": "仅使用大语言模型学习图任务", "title_en": "Less is More: Learning Graph Tasks with Just LLMs", "authors": "Sola Shirai,Kavitha Srinivas,Julian Dolby,Michael Katz,Horst Samulowitz,Shirin Sohrabi", "background": "对于大型语言模型（LLMs），进行图推理有助于解决许多问题。此前的研究尝试通过研究如何最好地将图序列化为文本以及将GNN与LLM相结合来提高LLM的图推理能力，但这些方法的有效性仍不清楚。", "innovation": "本研究通过训练LLMs使用指导性思维链解决方案来学习执行图任务。结果显示，即使是很小的LLMs也能学习解决图任务，而无需专门的图编码模型，并且这种训练能够在未见过的任务和图结构上进行泛化。", "conclusion": "研究表明，小型LLMs在训练后能够解决图任务，并且这种训练可以泛化到新的任务和图结构，而无需专门的图编码模型。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10071", "html_url": "https://arxiv.org/abs/2508.10071", "title": "深化数据公平：NLP数据实践中从业者责任与问责", "title_en": "Advancing Data Equity: Practitioner Responsibility and Accountability in NLP Data Practices", "authors": "Jay L. Cunningham,Kevin Zhongyang Shao,Rock Yuren Pang,Nathaniel Mengist", "background": "尽管已有研究关注揭露和审计算法偏见以确保公平的AI发展，但对于自然语言处理（NLP）从业者（直接参与数据集开发、标注和部署）如何感知和应对NLP数据公平性问题却知之甚少。本文是最早将研究重点放在从业者的视角上，将其经验与多尺度AI治理框架相结合，并提出跨技术、政策和社区领域的参与性建议的文章之一。", "innovation": "本文基于2024年的问卷调查和焦点小组，探讨了美国NLP数据从业者的公平概念、他们如何应对组织和系统性限制，以及如何参与新兴的治理努力如美国AI权利法案。研究发现揭示了商业目标与公平承诺之间的持续紧张关系，以及呼吁更加包容和负责任的数据工作流程。文章还深入探讨了数据多样性与多样性洗牌的辩论，提出改善NLP数据公平性需要结构化治理改革，以支持从业者的自主性和社区同意。", "conclusion": "研究强调了改善NLP数据公平性的关键在于实施结构性治理改革，这些改革需着眼于支持从业者的自主性和社区同意，以克服数据集开发、标注和部署中存在的实际挑战。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10021", "html_url": "https://arxiv.org/abs/2508.10021", "title": "LATTE: 学习银行客户对账和文本嵌入", "title_en": "LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients", "authors": "Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Dima Korolev,Omar Zoloev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko", "background": "从客户历史通信序列中学习客户嵌入在金融应用中至关重要。尽管大规模语言模型（LLMs）提供了广泛的世界知识，但在长事件序列上直接使用它们在现实世界的管道中是计算成本高昂且不切实际的。此背景说明了这种场景中的挑战。", "innovation": "本文提出了一种对比学习框架LATTE，该框架将原始事件嵌入与冻结的LLM的语义嵌入对齐。行为特征被总结为简短的提示，通过LLM嵌入并作为通过对比损失的监督。这种方法显著降低了推理成本和输入大小，相较于使用LLM处理完整序列的传统方法。此外，实验证明该方法在实际金融数据集中的实际应用场景优于最先进的技术。", "conclusion": "我们的方法在保持实时环境可部署性的同时，在实际金融数据集上优于最先进的技术，具有学习事件序列表示的功效。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10123", "html_url": "https://arxiv.org/abs/2508.10123", "title": "Nested-ReFT: 通过离策滚动提高大型语言模型微调的效率的强化学习", "title_en": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts", "authors": "Maxime Heuillet,Yufei Cui,Boxing Chen,Audrey Durand,Prasanna Parthasarathi", "background": "在解决诸如数学推理等具有挑战性的领域中的高级推理能力方面，LLM可以通过基于可验证奖励的强化微调（ReFT）来应对。尽管传统的ReFT框架在回答问题时会生成多个答案，然后通过奖励函数打分，这种方法在挑战性推理领域显示出了显著的性能提升，但生成多个答案的计算成本使得训练成本变得不那么简单。论文借鉴了离策RL和推测解码的概念，引入了一种新的ReFT框架，称为Nested-ReFT，在其中目标模型的部分层作为行为模型来生成训练期间的离策答案，从而降低推理成本。该方法在多个数学推理基准测试和模型尺寸下展现了更好的计算效率，同时探索了三种偏差缓解策略以最大限度地减少梯度更新中的离策性，从而保持与标准ReFT相当的性能。", "innovation": "提出了一个新颖的ReFT框架——Nested-ReFT，该框架通过将部分层作为行为模型，使用离策滚策略来生成训练期间的答案，从而降低计算成本。该框架在多个数学推理基准测试中展示了更好的计算效率，同时探讨了减少梯度更新离策性的方法。", "conclusion": "实验分析表明，Nested-ReFT在多个数学推理基准和模型尺寸下展现了更高的计算效率，同时也保持了与标准ReFT相当的性能。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10036", "html_url": "https://arxiv.org/abs/2508.10036", "title": "反思再学习：基于内在困惑的主动提示信息提取", "title_en": "Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion", "authors": "Dong Zhao,Yadong Wang,Xiang Chen,Chenxi Wang,Hongliang Dai,Chuanxing Geng,Shengzhong Zhang,Shaoyuan Li,Sheng-Jun Huang", "background": "大型语言模型（LLMs）在少量示例信息提取（IE）任务中表现出显著潜力，但其性能高度依赖于上下文示例的选择。传统选择策略往往无法提供令人满意的指导，尤其是在解决模型从语义内容和IE任务所需格式结构一致性中产生的困惑方面存在局限。", "innovation": "提出了一种新的主动提示框架——Active Prompting for Information Extraction（APIE），该框架基于“反思性困惑”原则。APIE通过引入一种独特的双成分不确定性度量，使LLM能够评估自身在格式不确定性（正确语法生成的难度）和内容不确定性（提取语义一致性）方面的困惑。这种方法主动选择最具挑战性和信息性的未标记数据作为少量示例，从而显著提高信息提取准确性和鲁棒性。", "conclusion": "在四个基准上的广泛实验表明，该方法在信息提取准确性和鲁棒性方面均优于强基线。这项工作强调了构建有效的和可靠的结构生成系统时，对模型不确定性进行精细的、双层视角的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10137", "html_url": "https://arxiv.org/abs/2508.10137", "title": "mSCoRe: 一个多语言可扩展的基于技能的常识推理基准", "title_en": "mSCoRe: a $M$ultilingual and Scalable Benchmark for $S$kill-based $Co$mmonsense $Re$asoning", "authors": "Nghia Trung Ngo,Franck Dernoncourt,Thien Huu Nguyen", "background": "近期在大规模语言模型（LLMs）中引入了推理强化技术，这些技术在复杂的推理任务中表现出色。然而，这些模型在利用不同的人类推理技能方面的机制仍然很少被研究，特别是在跨语言和文化背景下涉及日常生活知识的多语言常识推理方面。此论文旨在填补这一空白，提出一个多语言可扩展的基于技能的常识推理基准（mSCoRe）。", "innovation": "mSCoRe基准包括三个关键组件，旨在系统性地评估LLM的推理能力：（1）一种新颖的推理技能分类学，使模型的推理过程能够进行精细分析；（2）一个专门为了常识推理评估而精心设计的稳健数据合成流程；（3）一个复杂性扩展框架，允许任务的难度随着未来LLM能力的提高而动态调整。实验结果表明，在高复杂性级别，mSCoRe对当前的模型仍然具有很高的挑战性。研究结果显示，当前的推理强化模型在面对多语言普遍性的细微差别和文化常识时表现出局限性。", "conclusion": "研究结果揭示了推理强化模型在处理复杂的多语言常识和文化相关领域时的局限性，并提供了模型推理过程的详细分析，为改善多语言常识推理能力提出了未来的研究方向。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10147", "html_url": "https://arxiv.org/abs/2508.10147", "title": "rETF-semiSL: 半监督学习中的时间数据神经崩溃现象", "title_en": "rETF-semiSL: Semi-Supervised Learning for Neural Collapse in Temporal Data", "authors": "Yuhan Xie,William Cappelletti,Mahsa Shoaran,Pascal Frossard", "background": "深度神经网络处理时间序列数据时必须捕捉复杂的时序模式，以有效地表示动态数据。自监督和半监督学习方法在预训练大型模型方面表现出有希望的结果，这些方法在微调分类时，通常会比从零开始训练的模型表现出更好的效果。然而，预训练任务的选择通常是直观的，并且它们对下游分类任务的可迁移性并不能保证，因此，本文提出了一种新的半监督预训练策略，以增强满足最优训练神经分类器观察到的神经崩溃现象的潜在表示。我们使用旋转等角紧框架分类器和伪标签化来预训练具有少量标注样本的深度编码器，并且为了有效捕捉时间动态性同时确保嵌入可分性，我们还将生成的预训练任务与我们的方法整合起来，并定义了一种新的序列化数据增强策略。", "innovation": "本文提出了一种新颖的半监督预训练策略，利用旋转等角紧框架分类器和伪标签化来预训练深度编码器，以有效捕捉时间数据的时间动态性并确保嵌入的可分性。此外，通过将生成预训练任务与方法结合，并定义了一种新型的序列化数据增强策略，来实现上述目标。研究表明，这一方法在应用于LSTMs、transformers和状态空间模型的三个多变量时间序列分类数据集上时，显著优于先前的预训练任务。", "conclusion": "我们的方法展示了预训练目标与理论上确立的嵌入几何结构对齐的好处，突显了预训练对提升时间序列分类任务性能的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10148", "html_url": "https://arxiv.org/abs/2508.10148", "title": "基于反事实距离的离群检测", "title_en": "Out-of-Distribution Detection using Counterfactual Distance", "authors": "Maria Stoica,Francesco Leofante,Alessio Lomuscio", "background": "为了安全地使用机器学习系统，准确且可解释的离群（OOD）检测是必要的。先前的研究表明，特征距离到决策边界的距离可以有效识别OOD数据。在本文中，作者基于这一直觉提出了一个后处理OOD检测方法，该方法通过利用反事实解释来计算输入与决策边界的距离。由于对于大规模架构来说计算解释可能代价高昂，作者还提出了策略以通过在嵌入空间中直接计算反事实来改善可扩展性。这种方法的关键在于利用反事实解释，可以在不改变检测器本身的情况下无缝帮助解释其结果。", "innovation": "作者提出了一种后处理OOD检测方法，利用反事实解释来计算输入与决策边界的距离，并通过在嵌入空间中直接计算反事实来提高可扩展性。此外，这种方法可以直接利用反事实解释来帮助解释检测结果。实验结果显示，该方法在CIFAR-10上与最先进方法相当，在CIFAR-100和ImageNet-200上表现更优，达到了更高的AUROC和更低的FPR95。", "conclusion": "作者提出的基于反事实距离的方法在多个OOD数据集上的性能超过了现有的方法，特别是在CIFAR-100和ImageNet-200上表现出色，证明了其在离群检测任务上的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10044", "html_url": "https://arxiv.org/abs/2508.10044", "title": "生成人工智能在能源管理系统网络安全中的应用：方法、挑战及未来方向", "title_en": "Generative AI for Cybersecurity of Energy Management Systems: Methods, Challenges, and Future Directions", "authors": "Aydin Zaboli,Junho Hong", "background": "本文详细阐述了一个针对能源管理系统（EMSs）的安全框架，该框架能够应对动态的网络安全漏洞和系统问题（SPs）。框架采用了系统化的多点攻击/错误模型，覆盖了EMS数据处理管道的全过程，包括状态估计（SE）后的隐蔽攻击、EMS数据库操纵以及基于实时数据库（RTDB）存储的人机接口（HMI）显示篡改。它还涉及SCADA数据流的各种攻击向量之间的关联性。在整个过程中，该框架强调了现代攻击向量的关联性和复杂性。", "innovation": "本文首次提出了基于生成人工智能（GenAI）的异常检测系统（ADSs）用于处理电能系统中的场景问题。在此基础上，提出了一个新的综合框架——集组合生成智能（SoM-GI）框架，该框架结合了视觉标记与规则，利用多模态分析来克服空间逻辑推理的局限性。SoM-GI通过使用系统性的视觉指示器，实现对HMI显示的准确解读，检测出数值方法无法识别的视觉异常。该方法结合了数值分析、视觉模式识别和语言规则，以保护系统免受网络威胁和系统错误的影响。", "conclusion": "基于IEEE 14-节点系统的验证显示了该框架在各种场景中的有效性，同时也通过视觉分析识别了潜在的不一致性问题。这种结合了数值分析、视觉模式识别和语言规则的一体化方法，为保护能源管理系统免受网络攻击和系统错误提供了强大的工具。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10161", "html_url": "https://arxiv.org/abs/2508.10161", "title": "LaaJMeter: 一种Laaj评价框架", "title_en": "LaajMeter: A Framework for LaaJ Evaluation", "authors": "Gal Amram,Eitan Farchi,Shmulik Froimovich,Raviv Gal,Avi Ziv", "background": "大语言模型（LLMs）在自然语言处理任务中越来越多地用作评估器，这一模式称为Laaj。尽管LLMs在通用领域有效，但在特定领域中，由于注释数据稀缺且专家评估成本高，Laaj会遇到重大挑战。因此，通常使用未在特定领域中验证过的指标进行元评价，导致难以确定哪些指标能有效评估Laaj的质量，以及合适的阈值来表明评估者的表现水平。", "innovation": "本文介绍了LaaJMeter，一种基于仿真的框架，用于控制下的Laaj元评价。LaaJMeter使工程师能够生成代表虚拟模型和判决者的合成数据，从而在现实条件下系统分析评估指标。这一方法帮助实践者验证并细化适用于特定评价任务的Laaj：他们可以测试其指标是否能正确区分更好的与较差的（虚拟）Laaj，并估计评估者表现适当的阈值。我们的实验证明了LaaJMeter在遗产编程语言代码翻译任务中的效用，展示了不同指标在评价者质量敏感性方面的差异。", "conclusion": "我们的结果突显了常用指标的局限性和有原则地选择指标的重要性。LaaJMeter提供了一种在资源有限的情境下评估Laaj的可扩展和可扩展性解决方案，有助于推动确保NLP领域的评价可信性和可重复性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10156", "html_url": "https://arxiv.org/abs/2508.10156", "title": "通过自定义EfficientNetV2-L模型利用生成人工智能（GenAI）基于合成和实地实拍图像提高西瓜(Citrullus lanatus)疾病分类", "title_en": "Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model", "authors": "Nitin Rai,Nathan S. Boyd,Gary E. Vallad,Arnold W. Schumann", "background": "目前生成人工智能（GenAI）模型的进步为生成高分辨率合成图像提供了新的可能性，这为在农业中训练计算机视觉模型提供了一种有前景的替代传统图像采集的方法。特别是在作物病害诊断中，GenAI模型被用于创建各种病害的合成图像，这可能帮助模型创建并减少对资源密集型田间数据采集的依赖。然而，关于将实际图像与合成图像结合以提高病害分类性能的研究仍相对有限。因此，本研究旨在探讨是否可以通过将少量实际图像与合成图像结合使用来提高高效网V2-L（EfficientNetV2-L）模型对西瓜病害分类的预测准确性。", "innovation": "本研究利用生成人工智能技术创建合成图像，并探索将少量实际图像与大量合成图像结合以提高高效网V2-L模型的病害分类精度和泛化能力。通过不同的处理方式（H0、H1、H2、H3和H4）进行实验，发现当比例为1:10时的合成图像与实际图像结合（H3）能够显著提高加权F1分数，从H0处理的0.65提升到H3-H4处理的1.00。此外，通过随机添加图像以提高多样性和模型泛化能力的处理（H4）也进一步提升了模型性能。", "conclusion": "本研究证实，单独使用合成图像不能充分替代实际图像；相反，应在混合使用合成图像和实际图像的情况下最大化模型性能，以提高作物病害分类的效果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10186", "html_url": "https://arxiv.org/abs/2508.10186", "title": "PakBBQ：面向问答的文化适应性偏见基准", "title_en": "PakBBQ: A Culturally Adapted Bias Benchmark for QA", "authors": "Abdullah Hashmat,Muhammad Arham Mirza,Agha Ali Raza", "background": "随着大型语言模型（LLMs）在各种应用中的广泛应用，确保它们在所有用户社区中的公平性已成为不争的事实。然而，大多数LLMs都是基于西方中心的数据训练和评估，很少关注低资源语言和地区性上下文。最新研究指出，现有的偏见基准数据集主要集中在西方文化背景下，缺乏对亚洲、特别是巴基斯坦等低资源语言和文化背景的覆盖。因此，本文探讨了这个问题并提出了解决方案。", "innovation": "本文创新性地提出了PakBBQ，这是一种根据巴基斯坦文化和地区性调整的问答偏见基准数据集扩展版本。PakBBQ涵盖了英语和乌尔都语在内的多种语言，包含了214个模板和17180个问答对，覆盖了关于年龄、残疾、外貌、性别、社会经济地位、宗教、区域认同和语言形式化等多个偏见维度，反映了巴基斯坦的具体文化和社会特征。研究还评估了多种多语言LLMs在有语义模糊与明确指代情境下的表现，并通过负面与非负面问题表达方式的影响进行了测试。", "conclusion": "实验结果表明：(i) 在使用明确指代时平均准确率提升了12%；(ii) 乌尔都语中的反向偏见行为比英语中更强大；(iii) 问题面前使用负面表达式能够有效减少刻板印象回答。研究结论指出了情境化基准测试和简单的提示工程策略对于低资源环境中的偏见缓解的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10222", "html_url": "https://arxiv.org/abs/2508.10222", "title": "通过表情符号预测理解文本情感", "title_en": "Understanding Textual Emotion Through Emoji Prediction", "authors": "Ethan Gordon,Nishank Kuppa,Rigved Tummala,Sriram Anasuri", "background": "本文项目研究了通过四种深度学习架构从短文本序列预测表情符号的方法：前馈网络、卷积神经网络(CNN)、变换器和BERT。利用TweetEval数据集，通过焦点损失和正则化技术解决了类别不平衡问题。研究结果表明，BERT因其预训练优势在整体性能上最佳，而CNN在罕见表情符号类别上表现出更优的效果。这些发现强调了架构选择和超参数调整对于情感感知表情符号预测的重要性，有助于提高人机交互的质量。", "innovation": "本文创新性地采用了四种不同的深度学习架构对抗类别不平衡问题，并通过焦损和正则化技术提升模型性能。研究结果证明了BERT在情感感知表情符号预测中的优势，同时也强调了CNN在处理罕见表情符号类别上的有效性。", "conclusion": "本文研究显示了架构选择和超参数调整对于情感感知表情符号预测的重要性，并且通过BERT和CNN模型证明了提高人机交互质量的可能性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10252", "html_url": "https://arxiv.org/abs/2508.10252", "title": "促进AI系统长期交互研究", "title_en": "Facilitating Longitudinal Interaction Studies of AI Systems", "authors": "Tao Long,Sitong Wang,Émilie Fabre,Tony Wang,Anup Sathya,Jason Wu,Savvas Petridis,Dingzeyu Li,Tuhin Chakrabarty,Yue Jiang,Jingyi Li,Tiffany Tseng,Ken Nakagaki,Qian Yang,Nikolas Martelaro,Jeffrey V. Nickerson,Lydia B. Chilton", "background": "用户与AI的互动随时间通过学习、适应和重新利用而演变，单一时间点的评估已不足以捕捉这些动态。长期研究虽然必要但因其实施中的挑战——部署难题、评估设计缺陷和数据收集困难——使这种研究难以开展。研究者需要实用的策略来应对这些挑战。", "innovation": "工作坊旨在解决这些挑战，通过提供一个包含主题演讲、研讨会和互动分组讨论的平台，帮助研究人员制定长期研究的方法和工具原型。此次工作坊旨在建立一个长期系统研究的社区，并推动该方法在UIST工具设计、构建和评估中的更广泛应用。", "conclusion": "通过此次工作坊，研究者可以掌握长期交互研究的实用策略，并促进长期研究方法在UIST研究中的应用，提高研究质量。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10192", "html_url": "https://arxiv.org/abs/2508.10192", "title": "大型语言模型（LLM）的提示响应语义差异度量对于忠实性幻觉和对齐检测", "title_en": "Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models", "authors": "Igor Halperin", "background": "随着大型语言模型（LLMs）的蓬勃发展，这些模型在生成文本时会出现幻觉问题，即模型生成不符合事实、不合逻辑或不忠实的文本。现有的方法，如语义熵，仅通过单一固定的提示来测试答案的任意性，未能充分捕捉到模型响应中的深层次不一致性。本文针对这一问题提出了语义差异度量（SDM）框架，强调了对提示响应一致性更深层次的测试，不仅在不同答案间，还在不同但语义等价的提示重述间进行比较。", "innovation": "本文引入了语义差异度量（SDM）框架，这是一种新颖的轻量级检测忠实性幻觉的方法，重点关注响应与用户查询语义不匹配的具体实现，即配置谬误。SDM框架使用组合聚类来创建提示和答案之间的共同主题空间。进一步使用信息论度量来量化提示和响应之间的语义差异，并提出了一种结合Jensen-Shannon散度和Wasserstein距离的评分体系$\boldsymbol{S}_H$。还引入了KL散度KL(Answer $||$ Prompt)作为语义探索的指标，用于区分不同的生成行为。这些指标共同构成了语义盒，一个诊断框架，用于分类LLM的响应类型，包括危险的、自信心幻谬。", "conclusion": "SDM框架提供了一种新的方法来识别大型语言模型中的忠实性幻觉，并区分不同的生成行为。通过使用联合聚类创建共同主题空间和计算信息论度量，SDM能够更准确地检测到模型响应中的语义偏差。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10230", "html_url": "https://arxiv.org/abs/2508.10230", "title": "No Free Lunch from Audio Pretraining in Bioacoustics: A Benchmark Study of Embeddings", "title_en": "No Free Lunch from Audio Pretraining in Bioacoustics: A Benchmark Study of Embeddings", "authors": "Chenggang Chen,Zhiyu Yang", "background": "生物声学研究动物声音，提供了一种无创方法来监测生态系统。无需微调音频预训练深度学习模型以提取嵌入已成为获取生物声学特征进行任务的一种流行方法。然而，最近的一项基准研究显示，虽然微调后的音频预训练VGG和变压器模型在某些任务中表现最佳，但在其他任务中却表现不佳。该研究通过降低已学习嵌入的维度并进行聚类评估，对11种深度学习模型进行了基准测试。", "innovation": "这项研究展示了无需微调音频预训练模型的限制，并在聚类评估中对这些模型的已学习嵌入维度进行了降低和基准测试。研究结果表明：1）无需微调的音频预训练模型即使在某些情况下也无法超越微调后的AlexNet的表现；2）无论是否微调，音频预训练模型都无法区分背景和标签声音，但ResNet可以做到；3）在包含较少背景声音的微调过程中，该模型优于其他模型。这些结果强调了微调音频预训练模型和检查微调后的嵌入的重要性。", "conclusion": "该研究强调了微调音频预训练模型以及微调后检查嵌入的重要性，并表明在特定情况下，传统模型如AlexNet和ResNet可能比音频预训练模型表现更好。研究结果还表明，减少背景声音的微调过程可以提高模型性能。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10210", "html_url": "https://arxiv.org/abs/2508.10210", "title": "基于解释性AI的动物健康监测方法", "title_en": "An Explainable AI based approach for Monitoring Animal Health", "authors": "Rahul Janaa,Shubham Dixit,Mrityunjay Sharma,Ritesh Kumar", "background": "奶农面临的关键挑战之一是监测所有农场动物的健康状况和优化产量，由于很难跟踪所有动物，这变得尤为困难。这项研究基于可解释的机器学习（ML）方法，展示现代农业实践，通过3轴加速度传感器持续数据收集和使用稳健的ML技术和算法，为农户和研究人员提供有关奶牛活动和行为的实际信息，从而支持基于数据的决策，促进可持续实践。该项研究利用基于蓝牙的物联网（IoT）设备和4G网络实现无缝数据传输、即时分析和模型解释。重点在于加速度计时间序列数据的预处理，包括统计特征提取、信号处理技术和使用滑动窗口技术的滞后特征。各种超参数优化的ML模型基于不同的窗口长度评估活动分类性能。k最近邻分类器表现出最佳性能，在训练集上的AUC均值为0.98，标准差为0.0026，在测试集上为0.99。该研究使用SHAP等基于解释性的AI框架来解释特征重要性，以保证透明性。对重要特征的详细比较及其所选特征的稳定性分析支持了具有解释性和实用性的ML模型开发，以促进可持续的家畜管理。", "innovation": "这项研究利用了物联网设备和4G网络实现数据的无缝传输和即时分析，并使用可解释性AI框架（如SHAP）来解释特征的重要性，使得研究发现能够被从业者理解和使用。此外，通过加速度传感器的数据收集和预处理技术，以及超参数优化的ML模型应用，提高了活动分类的准确性。特别是k最近邻分类器在多个测试集上的卓越表现，为可持续管理提供了有力支持。", "conclusion": "通过解释性AI框架和加速度传感器的高效数据收集与处理，以及优化的ML模型，这项研究展示了现代农业中可解释的动物健康监测方法能为奶农提供宝贵的实际信息，支持决策制定和可持续实践的实施。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10264", "html_url": "https://arxiv.org/abs/2508.10264", "title": "MRFD: 多区域融合解码用于减轻LVLMs幻觉的自我一致性", "title_en": "MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs", "authors": "Haonan Ge,Yiwei Wang,Ming-Hsuan Yang,Yujun Cai", "background": "大视觉-语言模型（LVLMs）在多模态任务中表现出色，但在视觉输入不一致的情况下往往会产生幻觉，这是由于其验证图像不同区域间信息的能力有限。", "innovation": "提出了一个无需训练的多区域融合解码（MRFD）方法，通过建模不同区域间的一致性来提高事实性定位。该方法使用交叉注意力识别重要区域，生成初步响应，并基于响应间的杰克逊-香农距离（JSD）计算可靠性权重。这些权重指导感知区域一致性融合，并使用受链式推理启发的区域感知提示。", "conclusion": "在多个LVLMs和基准测试中，MRFD显著减少了幻觉并提高了响应的事实性，而不需更新模型。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10260", "html_url": "https://arxiv.org/abs/2508.10260", "title": "DINOMotion: 在2D-Cine MRI引导的放射治疗中基于DINOv2的先进稳健组织运动跟踪", "title_en": "DINOMotion: advanced robust tissue motion tracking with DINOv2 in 2D-Cine MRI-guided radiotherapy", "authors": "Soorena Salari,Catherine Spino,Laurie-Anne Pharand,Fabienne Lathuiliere,Hassan Rivaz,Silvain Beriault,Yiming Xiao", "background": "在2D-Cine MRI引导的放射治疗中，准确的组织运动跟踪对于确保治疗结果和安全性至关重要。现有的方法通常依赖于顺序图像的配准，但常常面临大尺度错位和解释性不足的问题。", "innovation": "该论文介绍了一种名为DINOMotion的新型深度学习框架，基于DINOv2并结合Low-Rank Adaptation (LoRA)层，实现稳健、高效且可解释的运动跟踪。DINOMotion通过自动检测对应的解剖标志点，增强解释性，提供了顺序图像之间的明确视觉对应关系。LoRA层的结合减少了可训练参数量，提高了训练效率，而DINOv2强大的特征表示提供了对大尺度错位的鲁棒性。与基于迭代优化的方法不同，DINOMotion直接在测试时间进行图像配准计算。实验表明，DINOMotion能够在每个扫描处理大约30ms内，有效估计线性和非线性变换，并超越了现有最先进的方法，特别是在处理大错位方面表现出色。", "conclusion": "这些结果展示了DINOMotion作为实时2D-Cine MRI引导放射治疗中稳健且可解释的运动跟踪解决方案的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10226", "html_url": "https://arxiv.org/abs/2508.10226", "title": "使用大型语言模型评估高风险精神病患者的精神症状严重程度", "title_en": "Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia", "authors": "Andrew X. Chen,Guillermo Horga,Sean Escola", "background": "临床高风险（CHR）患者的精神分裂症需要密切监测其症状以提供适当的治疗。简明精神病评定量表（BPRS）是用于评估精神分裂症及其他精神分裂样障碍患者症状的且已被验证的研究工具，但在临床实践中却很少使用，因为需要进行长时间结构化的访谈。因此，研究者使用大型语言模型（LLMs）来预测通过CHR患者访谈记录得到的BPRS评分。尽管访谈并未特别针对BPRS进行结构化，但LLMs的零样本预测性能与真正的评估结果（中位一致性：0.84，ICC：0.73）相近，达到了人类评分者内和间的可靠性水平。此外，还展示了LLMs通过其在非本语言的准确性以及结合纵向信息的能力，在单次或少数样本学习方法中的潜在改进和标准化评估CHR患者的作用。", "innovation": "研究采用了大型语言模型（LLMs）来预测简明精神病评定量表（BPRS）评分，通过分析未特定结构化的访谈记录，展示了LLMs在评估CHR患者精神症状严重程度上的高准确性与一致性。特别地，它在非母语语言中的准确性和结合纵向信息进行评估的能力被进一步验证了潜在的应用潜力，由此促进了评估和监测CHR患者症状的改进与标准化。", "conclusion": "研究证明了大型语言模型能在不特定结构化访谈的情况下，以高精度预测BPRS评分，体现出其在临床实践评估CHR患者精神症状中的巨大潜力和标准化改进作用。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10304", "html_url": "https://arxiv.org/abs/2508.10304", "title": "另一种算法偏见：大型语言模型强化性别和种族主导话语的修辞分析", "title_en": "Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race", "authors": "Gustavo Bonil,Simone Hashiguti,Jhessica Silva,João Gondim,Helena Maia,Nádia Silva,Helio Pedrini,Sandra Avila", "background": "随着人工智能（AI）的发展，大型语言模型（LLMs）取得了显著进步并被应用于多种情境中。随着LLMs变得更加复杂，评估它们是否在输出过程中重造歧视与种族化现象，以及继续维护霸权话语变得至关重要。当前的偏见检测方法大多依赖于定量的、自动化的手段，这些方法往往没有充分考虑到偏见在自然语言中微妙的表现形式。本文提出了一种定性的、修辞的分析框架来补充这些方法，通过对包含黑人和白人女性的LLM生成短篇故事进行人工分析，探讨性别和种族的偏见问题。", "innovation": "本文提出了一个定量的、修辞的分析框架，旨在填补当前偏见检测方法在识别和纠正LLMs输出中的偏见方面的不足。通过对LLM生成的故事进行人工分析，深入探讨了性别和种族的偏见在自然语言中的具体表现形式，强调了认识到这些偏见的重要性，并指出模型在尝试纠正偏见时提供的往往是表面的调整，这揭示了算法在促进包容性叙事方面的局限性。", "conclusion": "研究结果表明，算法在意识形态上发挥着重要作用，并对AI的道德使用和发展具有重要意义。该研究强调了设计与部署AI过程中采用批判性、跨学科方法的必要性，以应对LLMs生成的话语如何反映和加剧不平等现象。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10268", "html_url": "https://arxiv.org/abs/2508.10268", "title": "移动电话上基于姿态鲁棒校准策略的点注视估计", "title_en": "Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones", "authors": "Yujie Zhao,Jiabei Zeng,Shiguang Shan", "background": "基于外观的点注视（PoG）估计虽已有改进，但由于个体差异，估计器仍难以在不同个体间泛化。因此，针对个体进行校准是获取准确PoG估计所必需的。但是，校准过的估计器对头部姿态变化比较敏感。为了应对这个问题，研究了对校准估计器影响的关键因素，并探索能够应对不同头部姿态的校准策略。研究者构建了一个基准MobilePoG，包含了32个个体在固定或变化头部姿态下的面部图像，集中在特定点上。通过分析不同校准点和头部姿态的多样性对应估计准确性的影响，研究揭示了引入更广泛头部姿态样本可以增强估计器对不同姿态的适应性。", "innovation": "提出了基于姿态鲁棒的移动电话上注视点估计校准策略。在用户友好的自然过程中，用户在移动设备上注视特定点，从而动态引入了头部姿态变化，这相比于传统的校准策略生产出更鲁棒的注视估计，对头部姿态变化不那么敏感。", "conclusion": "研究通过MobilePoG基准实验展示了提升校准估计器对头部姿态变化适应性的方法，并提出了一种新的动态校准策略，其在促进用户体验的同时生成的校准估计器比使用传统策略的更鲁棒。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10308", "html_url": "https://arxiv.org/abs/2508.10308", "title": "ReviewRL：基于RL的自动科学评审", "title_en": "ReviewRL: Towards Automated Scientific Review with RL", "authors": "Sihang Zeng,Kai Tian,Kaiyan Zhang,Yuru wang,Junqi Gao,Runze Liu,Sa Yang,Jingxuan Li,Xinwei Long,Jiaheng Ma,Biqing Qi,Bowen Zhou", "background": "同行评审对于科学进步至关重要，但随着投稿量的增加和评论者的疲劳，面临着越来越多的挑战。现有的自动化评审方法在事实准确性、评分一致性以及分析深度方面存在不足，通常生成表面化或泛化的反馈，缺乏高质量人类评审所具有的深刻见解。", "innovation": "本文介绍了ReviewRL，一种基于强化学习的生成全面且基于事实的科学论文评审框架。该方法结合了三个核心组成部分：(1) ArXiv-MCP检索增强上下文生成管道，包含相关科学文献；(2) 监督微调，确立基本的评审能力；(3) 强化学习过程及复合奖励函数，共同提高评审质量和评分准确性。实验表明，ReviewRL在ILR 2025论文上显著优于现有方法，无论采用基于规则的指标还是基于模型的质量评估。", "conclusion": "ReviewRL为基于RL的自动批判生成奠定了基础框架，展示了在这片领域未来开发中的潜力。ReviewRL的实现将发布在GitHub上。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10315", "html_url": "https://arxiv.org/abs/2508.10315", "title": "使用预训练视觉-语言模型减轻联邦学习中后门攻击的方法", "title_en": "A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning", "authors": "Keke Gai,Dongjue Wang,Jing Yu,Liehuang Zhu,Qi Wu", "background": "现有的联邦学习（FL）中的后门防御方法依赖于客户端数据分布同质化或拥有干净的服务端数据集的假设，这限制了其实用性和有效性。在客户端数据分布异质的情况下防止后门攻击并保持模型性能，仍然是一个重大挑战。", "innovation": "本文提出了一个名为CLIP-Fed的FL后门防御框架，利用了预训练视觉-语言模型的零样本学习能力。通过结合预聚合和后聚合的防御策略，CLIP-Fed克服了非IID数据对防御效果的限制。为了应对隐私问题并增强数据集对多样触发器的覆盖范围，CLIP-Fed利用多模态大型语言模型和频率分析构建并增强了服务端数据集，而无需使用任何客户端样本。CLIP-Fed通过在增强数据集上使用原型对比损失和Kullback-Leibler散度来对齐全局模型和CLIP的知识，以解决由后门样本引起的类别原型偏差，并消除触发模式与目标标签之间的相关性。", "conclusion": "在有代表性的数据集上的大量实验证明，CLIP-Fed在CIFAR-10数据集上平均减少了ASR 2.03%，在CIFAR-10-LT数据集上平均减少了1.35%。同时，CLIP-Fed还分别提高了平均MA 7.92%和0.48%的效果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10397", "html_url": "https://arxiv.org/abs/2508.10397", "title": "PQ-DAF:基于姿态驱动的质量控制数据增强方法在数据稀少的驾驶员注意力分散检测中的应用", "title_en": "PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection", "authors": "Haibin Sun,Xinghui Song", "background": "驾驶员分心检测对于提高交通安全和减少道路事故至关重要。然而，现有的模型在实际场景中部署时常常会遭受泛化性能下降的问题，主要是由于实际环境中数据标注成本高且难以获得，以及训练数据集与目标部署环境之间的领域转移较大。", "innovation": "本文提出了一种基于姿态驱动的质量控制数据增强框架（PQ-DAF），利用视觉-语言模型对样本进行过滤，以低成本的方式扩展训练数据，增强跨域鲁棒性。PQ-DAF采用逐步条件扩散模型（PCDMs）准确捕捉关键驾驶姿态特征并生成多样化的训练样本，通过基于自信阈值的样本质量评估模块筛选低质量的合成样本，确保增强数据集的可靠性。", "conclusion": "大量实验表明，PQ-DAF在少数样本下的驾驶员分心检测中显著提高了性能，特别是在数据稀少的情况下，实现了模型泛化能力的大幅提高。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10345", "html_url": "https://arxiv.org/abs/2508.10345", "title": "以福利为中心的聚类", "title_en": "Welfare-Centric Clustering", "authors": "Claire Jie Zhang,Seyed A. Esmaeili,Jamie Morgenstern", "background": "传统的公平聚类主要关注确保群体代表性的公平性或平衡特定群体的聚类成本。然而，Dickerson等人（2025）的研究表明，这些公平性概念可能会导致不理想或难以理解的聚类结果，他们提倡以福利为中心的聚类方法，旨在基于群体的效用来建模。", "innovation": "本文基于距离和比例代表性来建模群体效用，并提出了基于福利中心聚类的两种优化目标：罗尔斯式（平等主义）目标和功利主义目标。还引入了新的算法，并为这些算法提供了理论保证。实证研究表明，本文的方法明显优于现有的公平聚类基准方法。", "conclusion": "我们的方法在多个真实世界的数据集上的实证评估表明，它们显著优于现有的公平聚类基准方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10110", "html_url": "https://arxiv.org/abs/2508.10110", "title": "使用可解释的图像文本基础模型赋能变形攻击检测", "title_en": "Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model", "authors": "Sushrut Patwardhan,Raghavendra Ramachandra,Sushma Venkatesh", "background": "变形攻击检测已经成为确保面部识别系统可靠验证场景的关键组成部分。本文介绍了一种多模态学习方法，该方法能为变形攻击检测提供文本描述。研究表明，使用对比语言-图像预训练(CLIP)的方法不仅能够实现泛化的变形攻击检测，还能预测最相关的文本片段。实验在采用公开面部生物特征数据集生成的面部变形数据集上进行。该研究评估了最先进预训练神经网络与所提出框架在零样本评估中五种不同的变形生成技术表现，这些生成技术涉及三种不同的媒介形式。", "innovation": "提出了一种多模态学习方法，能够基于对比语言-图像预训练(CLIP)提供变形攻击检测的文本描述。研究了多种不同长度的文本提示，旨在生成易懂的文本片段。还对最先进预训练神经网络结合所提框架进行了评估，应用于不同的变形生成技术，并在多个媒介中得到了验证。", "conclusion": "该多模态学习方法结合对比语言-图像预训练(CLIP)能够实现泛化的变形攻击检测，并能够预测相关文本片段。实验结果表明，所提出的框架能够有效应用于不同变形生成技术的零样本评估中。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10383", "html_url": "https://arxiv.org/abs/2508.10383", "title": "通过仅针对标签的弹性变形提高在隐式标签噪声对抗下的稳健语义分割性能", "title_en": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise", "authors": "Yechan Kim,Dongho Yoon,Younkwan Lee,Unse Fatima,Hong Kook Kim,Songjae Lee,Sanga Park,Jeong Ho Park,Seonjong Kang,Moongu Jeon", "background": "先前的研究主要集中在处理严重的标签噪声，而现实世界的数据集还表现出微妙的标签缺陷。这些缺陷来自如对象边界模糊和注释员差异等固有挑战，尽管没有明确出现，但这些温和且潜在的噪声仍然会影响模型性能。传统数据增强方法可能会放大这些微妙缺陷，限制模型的泛化能力。本论文探讨了隐式标签噪声对语义分割的影响。", "innovation": "本论文提出了一种新的增强框架NSegment+，该框架解耦了图像和标签的变换，以应对实际存在的噪声。通过仅对分割标签而非原始图像引入受控弹性变形，鼓励模型在面对轻微的标签不一致时学习到稳健的对象结构表示。实验证明NSegment+在Vaihingen、LoveDA、Cityscapes和PASCAL VOC上的平均mIoU提升了2.29、2.38、1.75和3.39，进一步表明了处理隐式标签噪声的重要性。当与CutMix和Label Smoothing等其他训练技巧结合使用时，这些性能提升效果会更明显。", "conclusion": "本文提出NSegment+方法，通过解耦图像和标签的变换来处理隐式标签噪声问题，实验结果表明该方法能够有效提升语义分割的性能。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10332", "html_url": "https://arxiv.org/abs/2508.10332", "title": "层析分析自我监督表示在儿童语音中的年龄和性别分类", "title_en": "Layer-Wise Analysis of Self-Supervised Representations for Age and Gender Classification in Children's Speech", "authors": "Abhijit Sinha,Harishankar Kumar,Mohit Joshi,Hemant Kumar Kathania,Shrikanth Narayanan,Sudarsana Reddy Kadiri", "background": "儿童的语音由于音高、发音和发育特征的高度变异，对年龄和性别分类构成了挑战。尽管自我监督学习（SSL）模型在成人语音任务中表现出色，但它们在编码儿童语音特征方面的能力尚未得到充分探索。", "innovation": "本文以详细的逐层分析方式探讨了四种Wav2Vec2变体模型在PFSTAR和CMU Kids数据集中的表现，发现早期层比深层层更有效地捕捉到个体的声音线索，并提出通过PCA减少冗余并突出最有信息性的成分来提高分类效果。", "conclusion": "Wav2Vec2-large-lv60模型在CMU Kids数据集上达到了97.14%（年龄）和98.20%（性别）的分类准确率；而Wav2Vec2-base-100h和Wav2Vec2-large-lv60模型在PFSTAR数据集上分别达到了86.05%和95.00%的分类准确率。这些结果揭示了SSL模型深度如何影响说话者特征的结构，并支持更加针对性和适应性的儿童意识语音界面策略。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10404", "html_url": "https://arxiv.org/abs/2508.10404", "title": "Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation", "title_en": "Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation", "authors": "Huizhen Shu,Xuying Li,Qirui Wang,Yuji Kosuga,Mengqiu Tian,Zhuo Li", "background": "随着自然语言处理（NLP）特别是大型语言模型（LLMs）的迅速发展，生成能够破解LLMs的对抗样本仍然是理解模型漏洞和提高其鲁棒性的重要挑战。本研究在这一背景下提出了一个新的黑盒攻击方法，利用大型模型的可解释性。文中介绍了一种新的稀疏特征扰动框架（SFPF），利用稀疏自编码器来识别和操控文本中的关键特征，从而实现对抗文本的生成。", "innovation": "文中提出了一种名为Sparse Feature Perturbation Framework (SFPF)的新方法，结合稀疏自编码器来生成对抗文本，通过识别和操纵文本中的关键特征，进而生成新的对抗样本，这种方法能保持恶意意图同时放大安全信号，从而提高对抗样本的隐蔽性。实验结果表明，SFPF生成的对抗文本能够绕过最先进的防御机制，揭示当前NLP系统的持久性漏洞。", "conclusion": "SFPF方法能够在保持恶意意图的同时增强对抗样本的安全信号，在平衡攻击效果和安全约束方面提供了一种新的红队策略。实验结果表明SFPF生成的对抗文本能够绕过先进的防御机制，揭示NLP系统的漏洞。然而，该方法的有效性在不同提示和更复杂的模型中需要进一步验证其推广性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10423", "html_url": "https://arxiv.org/abs/2508.10423", "title": "MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion", "title_en": "MASH: Cooperative-Heterogeneous Multi-Agent Reinforcement Learning for Single Humanoid Robot Locomotion", "authors": "Qi Liu,Xiaopeng Zhang,Mingshan Tan,Shuaikang Ma,Jinliang Ding,Yanjie Li", "background": "当前大多数方法要么使用单智能体强化学习算法来控制单个人形机器人，要么使用多智能体强化学习（MARL）算法来处理多机器人系统任务。本文提出了一个新颖的方法：通过合作异构多智能体深度强化学习（MARL）来优化单个人形机器人的行走动作。", "innovation": "本文提出了一种新的方法MASH，即使用合作异构多智能体强化学习（MARL）来优化单个人形机器人的行走动作。每个肢体（腿和手臂）都被视为独立的智能体，探索机器人的动作空间，同时通过全局批评家进行协同学习，从而提高了训练收敛速度和整体合作能力。", "conclusion": "实验结果显示，MASH方法在训练收敛速度和整体合作能力方面优于传统的单智能体强化学习方法。该研究促进了MARL方法在单个人形机器人控制中的应用，并为高效的行走策略提供了新的见解。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10416", "html_url": "https://arxiv.org/abs/2508.10416", "title": "CorrectNav：自我纠正飞轮增强视觉语言行动导航模型", "title_en": "CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model", "authors": "Zhuoyuan Yu,Yuxing Long,Zihan Yang,Chengyan Zeng,Hongwei Fan,Jiyao Zhang,Hao Dong", "background": "现有基于视觉和语言导航的模型在执行指令时常常偏离正确的路径，但是这些模型缺乏有效的错误纠正能力，无法从错误中恢复。", "innovation": "提出了一种新颖的自纠正飞轮后训练范式，将模型在训练集上的错误轨迹视为有价值的数据源，开发了一种识别偏差的方法和自动生成自纠正数据的技术，用于感知和动作。通过多次飞轮迭代，逐步提升单目RGB基于视觉语言行动导航模型CorrectNav。实验结果显示CorrectNav在R2R-CE和RxR-CE基准上的成功率分别为65.1%和69.3%，优于之前最好成绩8.2%和16.4%。在多种室内外环境下的真实机器人测试中，验证了自纠正飞轮的强大纠正误差、动态障碍避让和长指令跟踪能力。", "conclusion": "通过自纠正飞轮的迭代训练，显著提升了视觉语言行动导航模型的性能，尤其是在错误纠正、动态障碍避让和长指令执行方面表现出卓越的能力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10409", "html_url": "https://arxiv.org/abs/2508.10409", "title": "AnalogSeeker: 开源的模拟电路设计基础语言模型", "title_en": "AnalogSeeker: An Open-source Foundation Language Model for Analog Circuit Design", "authors": "Zihao Chen,Ji Zhuang,Jinyi Shen,Xiaoyue Ke,Xinyi Yang,Mingjie Zhou,Zhuoyao Du,Xu Yan,Zhouyang Wu,Zhenyu Xu,Jiangli Huang,Li Shang,Xuan Zeng,Fan Yang", "background": "该论文提出了一种针对模拟电路设计的基础语言模型AnalogSeeker，旨在整合领域知识并为设计提供帮助。为解决该领域数据稀缺的问题，论文采取了基于模拟电路领域框架的文本语料库收集策略，系统地整理和清洗高质量的教科书成立了文本领域语料库。为应对模拟电路知识的复杂性，论文引入了一种细粒度的领域知识提炼方法。通过对原始的未标注领域语料进行分解，形成基本的学习节点，并采用多智能体框架将嵌入在无结构文本中的隐性知识提取为带有详细推理过程的问题-答案数据对，形成详尽、可学习的数据集用于微调。为解决训练基础模型的未探索挑战，论文通过理论分析和实验验证探索并分享了训练方法。最终建立了以微调为中心的训练范式，开发并实施了一种邻域自约束监督微调算法，通过限制训练前后模型输出分布的扰动幅度来增强训练效果。", "innovation": "1. 引入以教材为基础的语料库收集策略和多智能体框架来提炼隐性知识。\n2. 发展细粒度的领域知识提炼方法，将未标注的语料分解为基本的学习节点。\n3. 探索并实现了邻域自约束监督微调算法，增强了模型训练效果。\n4. 成功构建AnalogSeeker模型，显著提高模拟电路基准测试的准确性，并展示了在实际操作放大器设计任务中的有效性。", "conclusion": "AnalogSeeker模型在模拟电路知识评估基准AMSBench-TQA上达到85.04%的准确率，相比原始模型提升了15.67%，具有与主流商业模型相当的竞争力。同时，AnalogSeeker在操作放大器设计任务中也表现出有效性。该模型已经开放用于研究使用。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10370", "html_url": "https://arxiv.org/abs/2508.10370", "title": "eMamba: 在边缘计算中加速Mamba模型的有效框架", "title_en": "eMamba: Efficient Acceleration Framework for Mamba Models in Edge Computing", "authors": "Jiyong Kim,Jaeho Lee,Jiahao Lin,Alish Kanani,Miao Sun,Umit Y. Ogras,Jaehyun Park", "background": "基于状态空间模型（SSM）的机器学习架构已逐渐成为处理序列数据的热门选择。Mamba是一种近期的序列到序列SSM，其准确度与先进变压器模型相当，但在计算效率上更胜一筹。虽然Mamba在资源受限的边缘设备上的潜力突出，但目前尚无专门为此环境优化的硬件加速框架。因此，本文提出了eMamba，这是一个为边缘平台部署Mamba模型而设计的端到端硬件加速框架。eMamba通过使用轻量级的硬件感知替代层和近似运算，来最大化计算效率，并进行意识近似的神经架构搜索以调整可学习参数。", "innovation": "eMamba框架通过以下创新实现：首先，使用轻量级的硬件感知替代层替换复杂的规范化层，并对昂贵的操作如SiLU激活和指数运算进行近似处理；其次，进行意识近似的神经架构搜索，以调整运算中的可学习参数；最后，eMamba能够较低参数量（1.63-19.9倍更少）与先进技术相比保持相当的准确性，同时在AMD ZCU102 FPG和GF 22nm技术的整个eMamba管道的量化和实现中，实现较低的延迟（4.95-5.62倍）、更高吞吐量（2.22-9.95倍）、较小面积（4.77倍）、较低能耗（9.84倍）和能量消耗（48.6倍）的同时保持竞争力。", "conclusion": "本文提出的eMamba框架不仅在边缘计算环境中对Mamba模型进行了高效的硬件加速，而且在多个任务中展示了稳定的性能，并与最先进的技术相比实现了实质性的好处。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10435", "html_url": "https://arxiv.org/abs/2508.10435", "title": "Unpacking the Implicit Norm Dynamics of Sharpness-Aware Minimization in Tensorized Models", "title_en": "Unpacking the Implicit Norm Dynamics of Sharpness-Aware Minimization in Tensorized Models", "authors": "Tianxiao Cao,Kyohei Atarashi,Hisashi Kashima", "background": "Sharpness-Aware Minimization (SAM) 已被证明是提高过参数化模型泛化能力的有效优化技术。然而，尽管已有研究探讨了 SAM 在简单尺度不变情况下隐含正则化行为，但在更一般的张量化或尺度不变模型中的行为仍未得到充分研究。", "innovation": "本文利用尺度不变性分析 SAM 在一般张量化模型中的范数动态。引入了“范数偏差”这一全局措施，用于衡量核心范数不平衡的程度，并通过梯度流分析推导出范数偏差在 SAM 下的变化。基于这些发现，提出了一种简单有效的“偏差感知缩放（DAS）”方法，通过数据自适应的方式按比例缩放核心范数，以模仿 SAM 的隐含正则化行为。实验结果表明，DAS 在张量补全、噪声训练、模型压缩和参数高效微调等任务中，能够实现与 SAM 竞争或更好的性能，且计算开销更低。", "conclusion": "实验结果证明，DAS 在张量补全、噪声训练、模型压缩和参数高效微调等任务中表现出竞争或改进的性能，同时具有更低的计算开销。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10461", "html_url": "https://arxiv.org/abs/2508.10461", "title": "X-Node: 自己解释，此乃所需全部", "title_en": "X-Node: Self-Explanation is All We Need", "authors": "Prajit Sengupta,Islem Rekik", "background": "图神经网络(GNNs)已经在计算机视觉和医学图像分类任务中取得了最先进的成果，通过捕捉数据实例间的结构性依赖关系。然而，它们的决策过程仍然高度不透明，这在涉及临床应用的高风险场景中严重限制了其可信度，而这些场景对可解释性有着基本需求。尽管已有的GNN可解释性技术通常是在预测后的、全局的，但它们对单个节点的决策或局部推理缺乏深入的见解。", "innovation": "我们提出了X-Node，这是一种自解释的GNN框架，其中每个节点在其预测过程中都会生成自己的解释。对于每个节点，我们构建了一个结构化上下文向量，用于编码诸如度、中心性、聚类、特征显著性和局部拓扑内的标签一致性等可解释的线索。一个轻量级的Reasoner模块将这种上下文映射到紧凑的解释向量中，该向量有三个用途：（1）通过解码器重构节点的潜在嵌入并确保诚信度，（2）使用预训练的语言模型（例如Grok或Gemini）生成自然语言解释，（3）通过“文本注入”机制将解释反馈到消息传递管道中，从而指导GNN本身。", "conclusion": "我们在MedMNIST和MorphoMNIST的两个图数据集上评估了X-Node，将其与GCN、GAT和GIN背骨进行了整合。结果表明，X-Node在保持竞争力的分类精度的同时，还能生成忠实、节点级的解释。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10436", "html_url": "https://arxiv.org/abs/2508.10436", "title": "交替应用Approach-Putt模型的多阶段语音增强方法", "title_en": "Alternating Approach-Putt Models for Multi-Stage Speech Enhancement", "authors": "Iksoon Jeong,Kyung-Joong Kim,Kang-Hun Ahn", "background": "语音增强利用人工神经网络的目标是从噪信中去除噪声，同时保留语音内容。然而，语音增强模型往往会引入语音信号的失真，称为伪影，这些失真可能会降低音频质量。现有研究中，鉴于这一问题，本文提出了一种后处理神经网络，旨在减轻由语音增强模型引入的伪影。我们的模型借鉴了高尔夫中的推杆和击球的类比，因此名为PuttNet。研究表明，交替使用语音增强模型和提出的Putt模型能显著提高语音质量，通过感知质量评分（PESQ）、客观可理解度（STOI）和背景噪声干扰（CBAK）评分来衡量效果更好。此外，我们还通过图形分析解释了这种交替应用Approach模型优于单独重复应用模型的原因。", "innovation": "本文创新点在于提出了一种新的后处理神经网络模型（PuttNet），该模型可以有效减轻由语音增强模型引入的伪影问题。通过交替应用语音增强模型和提出的Putt模型，提升了最终的语音质量。此外，通过图形分析进一步解释了这种交替应用的效果优于单纯使用任一模型的方法。", "conclusion": "本研究证明了通过交替应用语音增强模型和Putt模型可以显著提高语音质量。评估通过PESQ、STOI和CBAK这三个关键技术指标进行，图形分析表明交替应用Approach模型优于单独重复应用任一模型。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10455", "html_url": "https://arxiv.org/abs/2508.10455", "title": "实AC：一种领域无关的生成现实和可行的反事实解释框架", "title_en": "RealAC: A Domain-Agnostic Framework for Realistic and Actionable Counterfactual Explanations", "authors": "Asiful Arefeen,Shovito Barua Soumma,Hassan Ghasemzadeh", "background": "反事实解释通过描述使模型预测发生变化的最少输入特征变化，为AI做出的决策提供人类可理解的推理。当前，这些解释往往依赖于严格的、手动设计的约束或特定领域的知识来确保现实性和可行性，这限制了它们的通用性，并且难以捕捉数据中的复杂非线性关系。此外，它们通常不考虑用户特定的偏好，提供的解释可能是因果关系上不可能的或不具可行性的行动建议。", "innovation": "提出了实AC，这是一种领域无关的框架，用于生成现实和可行的反事实解释。实AC自动保存复杂的特征间依赖关系，无需依赖显式领域知识，并通过在事实和反事实实例之间对特征对的联合分布进行对齐来实现这一目标。此外，框架还允许终端用户通过在优化过程中抑制冻结特征的变化来“冻结”某些属性。评估显示实AC在现实性与可行性之间取得了平衡，其方法在因果边得分、依赖性保存得分以及IM1现实度度量中均优于现有的先进基准方法和基于大型语言模型的反事实生成技术，并提供了一种因果感知和用户中心的反事实生成解决方案。", "conclusion": "实AC框架在现实性和可行性之间取得了平衡，并在因果边得分、依赖性保存得分和IM1现实度度量中均优于现有的先进基准方法和基于大型语言模型的反事实生成技术。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10419", "html_url": "https://arxiv.org/abs/2508.10419", "title": "ComoRAG：一种认知启发的记忆组织RAG模型，用于具有状态的长叙事推理", "title_en": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": "Juyuan Wang,Rongchen Zhao,Wei Wei,Yufeng Wang,Mo Yu,Jie Zhou,Jin Xu,Liyan Xu", "background": "长故事和小说的理解长期以来都是一个具有挑战性的领域，因为它们的复杂情节和角色及实体之间错综复杂且经常变化的关系。尽管语言模型在处理长时间上下文时表现出推理能力减弱和高计算成本的问题，检索式方法仍然在实践中占有重要地位。然而，传统基于检索的RAG方法由于其单一步骤、无状态的检索过程，常常难以捕捉长范围上下文中的动态相互关系。现有的方法往往无法充分模拟人类在记忆信号辅助的推理过程中认知状态的变化。", "innovation": "本文提出了一种名为ComoRAG的认知启发式记忆组织RAG模型。ComoRAG强调叙述推理不是一次性完成的过程，而是需要不断结合新证据和积累已有知识的动态交互过程，类似于大脑在记忆相关信号辅助下进行推理的认知过程。在遇到推理困境时，ComoRAG会进行迭代的推理周期，并与动态内存工作空间交互。在每个循环中，ComoRAG生成探针查询以探索新的路径，并将检索到的新项插入全局知识库，从而支持查询解决过程中的整体上下文构建。实验结果显示，ComoRAG在四个具有挑战性的长上下文叙事基准测试中优于强大的RAG基线模型，并在需要全局理解的复杂查询上表现尤为突出，提供了一种基于检索的长上下文理解的原理性认知驱动范式，有助于提升具有状态的推理能力。", "conclusion": "面向四个具有挑战性的长上下文叙事基准测试，ComoRAG在所有测试中均表现出稳定的优势，并提供了显著的相对提升（最高达到11%）。这些结果进一步证明ComoRAG模型通过结合记忆组织和动态推理，能够显著提升基于检索的长文本理解能力，支持具有认知启发的认知状态推理。该代码已公开发布。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10469", "html_url": "https://arxiv.org/abs/2508.10469", "title": "改进的稀疏点云数据处理方法用于隐私感知的人体动作识别", "title_en": "Enhanced Sparse Point Cloud Data Processing for Privacy-aware Human Action Recognition", "authors": "Maimunatu Tunau,Vincent Gbouna Zakka,Zhuangzhuang Dai", "background": "人体动作识别（HAR）在健康管理、健身追踪和辅助生活技术中起着关键作用。尽管传统的基于视觉的HAR系统有效，但它们存在隐私问题。毫米波雷达传感器提供了一种隐私保护的替代方案，但由于其稀疏且噪声较大的点云数据，这也带来了挑战。尽管在文献中DBSCAN、匈牙利算法和卡尔曼滤波等三种主要的数据处理方法已被广泛使用以提高雷达数据的质量和连续性，但对于这些方法的全面评估以及它们的组合评估却一直缺乏。", "innovation": "本文通过使用MiliPoint数据集对这三种方法进行了详细性能分析，分别评估了每种方法及其所有可能的两两组合和三者的全部组合，评估了识别准确性和计算成本。此外，还对这些方法提出了针对性的改进措施，以提高准确性。结果提供了每个方法及其整合的优点和权衡，指导了基于毫米波的HAR系统的未来研究。", "conclusion": "我们的结果为了解每种方法的强项和权衡提供了关键见解，并且通过具体的应用增强了这些方法，指导了毫米波HAR系统未来的工作。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10490", "html_url": "https://arxiv.org/abs/2508.10490", "title": "关于基于梯度解释的复杂性与忠实性权衡", "title_en": "On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations", "authors": "Amir Mehrpanah,Matteo Gamba,Kevin Smith,Hossein Azizpour", "background": "ReLu网络在视觉数据中广泛应用，但具有尖锐的过渡，有时依赖个别像素进行预测，导致基于梯度的解释变得噪音大且难以理解。现有方法，如GradCAM，通过生成替代模型来平滑这些解释，但会牺牲忠实性。文章指出现有的基于梯度的解释方法存在这一权衡问题，并指出现有方法如何通过生成替代模型来平滑解释但同时降低了解释的准确性，从而导致解释与实际模型之间的差距。这种差距在不同的后处理方法中表现不一。", "innovation": "文章提出了一个统一的频谱框架，以系统地分析和量化平滑度、忠实性和它们之间的权衡。作者使用该框架量化并正则化ReLU网络对高频信息的贡献，提供了一种识别该权衡的基础方法。通过这个框架，作者能够正式定义并测量不同后处理方法的“解释差距”。", "conclusion": "文章验证了理论发现，即通过不同的设计选择、数据集和消融研究，展示修正后的解释在保持忠实性的同时改进了可解释性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10480", "html_url": "https://arxiv.org/abs/2508.10480", "title": "Pinet: 使用正交投影层优化具有刚性约束的神经网络", "title_en": "Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers", "authors": "Panagiotis D. Grontas,Antonio Terpin,Efe C. Balta,Raffaello D'Andrea,John Lygeros", "background": "在当前的神经网络训练中，为了保证模型预测结果满足特定的约束条件（如凸约束），往往需要定制复杂的优化算法或在模型训练后对结果进行后处理，从而增加了训练时间和计算成本。因此，如何在神经网络训练过程中直接、快速地满足这些约束条件成为了一个重要的研究课题。", "innovation": "本文提出了一种新的输出层 $\text{\textPi}net$，通过利用算子分裂技术确保神经网络的输出能满足凸约束，并通过隐式函数定理实现高效的反向传播。此外，$\text{\textPi}net$ 作为设计上可行的优化代理，可应用于参数化的约束优化问题，不仅能快速求解单一问题，还能显著加速批量问题的处理速度。相较于传统的求解器，$\text{\textPi}net$ 在训练时间、解的质量和超参数调优的鲁棒性上均表现出色，同时保持相似的推理时间。特别是在处理多车辆运动规划具有非凸轨迹偏好时取得了良好的效果。", "conclusion": "本文通过开发 $\text{\textPi}net$，有效地解决了神经网络约束优化问题，不仅提高了求解速度和效率，还在解决方案的质量和模型鲁棒性方面优于现有的学习方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10491", "html_url": "https://arxiv.org/abs/2508.10491", "title": "对比学习ECOC：用于对抗防御的输出码学习", "title_en": "Contrastive ECOC: Learning Output Codes for Adversarial Defense", "authors": "Che-Yu Chou,Hung-Hsuan Chen", "background": "虽然一핫编码常用于多分类问题，但它并非总是最有效的编码机制。错误校正输出编码（Error Correcting Output Codes, ECOC）通过将每个类映射到唯一的代码字来解决多分类问题，这些代码字作为标签使用。传统的ECOC方法依赖于手工设计或随机生成的代码本，这些方法耗时且可能产生不适用于特定数据集的次优化结果。本文研究旨在通过对比学习自动学习ECOC的代码本，使代码本可以直接从数据中学习并适应数据的变化。", "innovation": "提出了一种基于对比学习的ECOC自动代码本学习模型，能够在不依赖手动设计或随机生成的情况下从数据中自动学习适应性强的代码本，从而提高模型在对抗攻击下的鲁棒性。实验结果表明，提出的模型在四个数据集上的对抗攻击鲁棒性优于两个基准模型。", "conclusion": "通过基于对比学习的自动代码本学习方法，本文提供的模型在对抗攻击的情况下表现出了更好的稳健性。这一方法解决了传统ECOC方法中代码本设计耗时且难以优化的问题，有望为多分类任务提供一种更高效的编码机制。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10494", "html_url": "https://arxiv.org/abs/2508.10494", "title": "统一多代理框架实现通用多模态理解和生成", "title_en": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation", "authors": "Jiulin Li,Ping Huang,Yexin Li,Shuo Chen,Juewen Hu,Ye Tian", "background": "现实世界中的多模态应用通常需要实现任意到任意的能力，支持在文本、图像、音频和视频等多种模态之间进行理解和生成。然而，将自动回归语言模型（LLMs）用于推理和扩散模型用于高保真生成的结合仍然是一个挑战，现有方法通常依赖于固定管道或紧密耦合架构，这限制了灵活性和扩展性。", "innovation": "我们提出了MAGUS（多代理引导统一多模态系统），这是一种模块化框架，通过认知和决断两个分离阶段统一多模态理解和生成。MAGUS支持模块化的扩展、任意到任意的模态转换和语义对齐，且无需联合训练。认知阶段通过条件多模态LLM代理（Perceiver、Planner和Reflector）进行合作对话，实现结构化理解和规划。决断阶段插入了增长感知搜索机制，以协调基于LLM的推理和基于扩散的生成。实验结果表明，MAGUS 在多个基准测试中优于强基线和最先进的系统，并在MME基准测试中超越了开源模型GPT-4o。", "conclusion": "我们的MAGUS框架能够在不进行联合训练的情况下支持模块化的扩展、任意到任意的模态转换和语义对齐。在多个模态生成和跨模态指令跟随的基准测试中，MAGUS 优于现有系统。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10504", "html_url": "https://arxiv.org/abs/2508.10504", "title": "基于逻辑的实体解析进展：增强ASPEN中的局部合并和最优准则", "title_en": "Advances in Logic-Based Entity Resolution: Enhancing ASPEN with Local Merges and Optimality Criteria", "authors": "Zhliang Xiang,Meghyn Bienvenu,Gianluca Cima,Víctor Gutiérrez-Basulto,Yazmín Ibáñez-García", "background": "现有的基于ASP（逻辑编程）的系统ASPEN仅支持全局合并实体引用常量，即将所有匹配的常量视为等价并相应地合并。然而，在解决数据值时，局部合并往往更为合适，因为某些'J. Lee'实例可能指的是'Joy Lee'，而其他则应与'Jake Lee'匹配。因此，需要一种能够支持局部合并并提供新的最优准则以便选择解决方案的系统，从而提高实体解析的准确性和效率。", "innovation": "ASPEN+扩展了现有的ASPEN系统，增加了支持局部合并功能，并引入了新的最优准则来选择解决方案，如最小化规则违背次数或最大化支持合并的规则数量。这是通过正式化和计算分析各种最优解的概念来实现的，以提供一个增强的框架来处理实体解析中的局部和全局合并。", "conclusion": "ASPEN+通过引入局部合并和新的最优准则，显著提高了实体解析的准确性和效率。通过实验证明了局部合并和新最优准则对准确性和运行时间的影响。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10507", "html_url": "https://arxiv.org/abs/2508.10507", "title": "多样本抗锯齿与约束优化在3D高斯点云集光中的应用", "title_en": "Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting", "authors": "Zheng Zhou,Jia-Chen Zhang,Yu-Jie Xiong,Chun-Ming Xia", "background": "近年来，3D高斯点云集光技术在实时新颖视图合成方面取得了显著进步，但由于场景优化过程中缺乏足够的几何约束，在高频纹理和锐化边界区域经常导致细节重建模糊。", "innovation": "本文提出了一种综合框架，将多样本抗锯齿（MSAA）与双重几何约束相结合。框架中引入了两种约束：一种是自适应加权策略，通过动态梯度分析优先处理欠重建区域，另一种是梯度差异约束，用于在物体边界处进行几何正则化，以进行目标化优化，分配更多计算资源到需要细化的关键区域，同时保持全局一致性。", "conclusion": "实验结果表明，本方法在细节保留方面实现了最先进的性能，特别是在保留高频纹理和锐化边界方面，同时保持了实时渲染效率。定量指标和感知研究均证实了该方法相对于基线方法在结构相似性（SSIM）和感知质量（LPIPS）方面的统计显著改善。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10552", "html_url": "https://arxiv.org/abs/2508.10552", "title": "当语言占主导：揭示多模态大语言模型中的文本主导现象", "title_en": "When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models", "authors": "Huyu Wu,Meng Tang,Xinhan Zheng,Haiyun Jiang", "background": "多模态大型语言模型在多种多模态任务中展现出了显著的能力，但是在这些任务中，这些模型倾向于过度依赖文本信息，而未能充分利用其他模态数据。已有研究对这一现象的认知主要集中在数据偏见或模型架构上，并未做出系统的探讨。因此，有必要对文本主导的现象进行系统的调查研究，以揭示多模态语言模型中的偏差，并提出相应的解决方案。", "innovation": "本文提出了两个新的评估指标：模态主导指数（MDI）和注意力效率指数（AEI），用于量化文本主导的不平衡。深入分析证明了文本主导现象在图像、视频、音频、时间序列和图等多种数据模态中普遍存在，并找出其背后的原因：非文本模态中的严重标记冗余导致注意力稀释，融合架构设计和任务声明的隐式偏好使模型更倾向于处理文本数据。此外，提出了简单的标记压缩方法来有效平衡模型的注意力，这进一步验证了我们提出的分析和方法论框架的有效性。", "conclusion": "研究分析和提出的方法论框架为开发更加公平和全面的多模态语言模型奠定了基础，并展示了可通过简单的方法来调整模型注意力以更均衡地处理各种模态的数据。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10548", "html_url": "https://arxiv.org/abs/2508.10548", "title": "使用门控奖励稳定长期多轮强化学习", "title_en": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards", "authors": "Zetian Sun,Dongfang Li,Zhuoen Chen,Yuhuai Qin,Baotian Hu", "background": "在长期强化学习（RL）任务中，奖励稀疏性仍然是一个重大的挑战，现有的基于结果的奖励塑造难以定义有意义的即时奖励，且容易引入偏差或需要显式的任务分解。另一种基于验证的奖励塑造使用逐步批评家，但在即时奖励与长期目标之间存在对齐问题时，会导致奖励作弊和次优策略。本文的研究背景是在软件工程（SWE）任务中，其中多轮推理和基于规则的验证至关重要，讨论如何通过统一的系统支持多轮交互、基于docker的执行和可自定义的奖励函数来解决长期RL中的问题。", "innovation": "本文提出了门控奖励累积（G-RA）方法，这是一种新颖的方法，仅当高层（长期）奖励达到预定义阈值时才累积即时奖励，从而确保稳定的学习策略优化。该方法在SWE-bench Verified和kBench上的实验证明了其有效，试验结果显示G-RA提升了完成率和修改率，且避免了奖励对齐错误导致的策略劣化。", "conclusion": "研究结果强调了在长期RL中平衡奖励累积的重要性，并提供了一个实用的解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10528", "html_url": "https://arxiv.org/abs/2508.10528", "title": "Med-GLIP：使用大规模锚定数据集促进医学语言-图像预训练", "title_en": "Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset", "authors": "Ziye Deng,Ruihan He,Jiaxiang Liu,Yuan Wang,Zijie Meng,Songtao Jiang,Yong Xie,Zuozhu Liu", "background": "医学图像锚定旨在将自然语言短语与医学图像中的特定区域对齐，是智能诊断、视觉问答（VQA）和自动化报告生成（MRG）的基础任务。然而，现有的研究受到模态覆盖有限、标注粗糙以及缺乏统一、可泛化的锚定框架的限制。尽管之前有研究，但存在改进空间以克服这些挑战。为此，我们构建了一个名为Med-GLIP-5M的大规模医学锚定数据集，包含超过530万的区域级别注释，覆盖了七种成像模态，包括多样的解剖结构和病理发现。该数据集支持分割和锚定任务，具有层级区域标签，从器官级别的边界延伸到细微病变。", "innovation": "我们提出了Med-GLIP，这是一种模态感知的锚定框架，基于Med-GLIP-5M进行训练，而不是依赖于显式设计的专家模块，而是从多样化的训练数据中隐式地获取层级语义理解，使模型能够识别多粒度结构，例如区分肺部与肺炎病变。实验证明，Med-GLIP在多个锚定基准中均优于最先进的基线，整合其空间输出到下游任务，如医学VQA和报告生成，也能取得显著性能提升。我们的数据集预计很快将发布.", "conclusion": "Med-GLIP框架通过大规模锚定数据集的构建和训练，显著改进了医学语言-图像预训练领域，实现了多模态、多粒度的语义理解，为医学图像分析提供了新的研究方向。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10557", "html_url": "https://arxiv.org/abs/2508.10557", "title": "PTQAT: 一种用于3D感知任务的混合参数高效量化算法", "title_en": "PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks", "authors": "Xinhao Wang,Zhiwei Lin,Zhongyu Xia,Yongtao Wang", "background": "后训练量化（PTQ）和量化感知训练（QAT）是两种主流的模型量化方法。PTQ经常导致量化模型性能显著下降，而QAT则因权重更新的GPU内存需求和较长的训练时间带来挑战。", "innovation": "本文提出了一种新型的混合量化算法PTQAT，旨在解决PTQ和QAT之间的速度与精度权衡问题。该方法选择关键层进行QAT微调，并对其余层进行PTQ。与直觉相反，选择量化前后输出差异较小的层进行微调，而非差异较大的层，实际上能够获得更大的量化精度提升。此外，PTQAT是一种通用量化方法，支持多种量化位宽（如4位）和不同模型架构（如CNN和Transformer），实验结果表明，该方法在nuScenes数据集的多种3D感知任务中表现优于仅使用QAT的基线方法。", "conclusion": "实验结果表明，PTQAT方法在物体检测、语义分割和占用预测等多项任务上，获得了与QAT相当的性能，但通过冻结近50%的可量化层，实现了更高的效率。此外，在物体检测任务上达到了0.2%-0.9%的NDS和0.3%-1.0%的mAP增益，在语义分割和占用预测任务上分别获得了0.3%-2.0%的mIoU增益，并且微调了更少的权重。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10595", "html_url": "https://arxiv.org/abs/2508.10595", "title": "基于梯度的解释方法的光谱特性分析", "title_en": "On Spectral Properties of Gradient-based Explanation Methods", "authors": "Amir Mehrpanah,Erik Englesson,Hossein Azizpour", "background": "理解深度网络的行为对于增强我们对其结果的信任至关重要。尽管有关解释其预测的研究非常丰富，但研究人员仍然面临可靠性问题，这可归因于正式化不足。", "innovation": "我们采用新颖的概率和光谱视角对解释方法进行了正式分析。研究表明，由于使用梯度导致普遍存在光谱偏差，并揭示了一些实验中发现的常见设计选择，尤其是平方梯度和输入扰动的使用。此外，我们进一步分析了在解释方法（如SmoothGrad）中选择扰动超参数如何导致不一致的解释，并提出了两种基于我们提出的正式化方法的解决方案：(i) 确定标准扰动尺度的机制，(ii) 称为光谱透镜的聚合方法。", "conclusion": "我们通过定量评估证明了我们的理论结果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10559", "html_url": "https://arxiv.org/abs/2508.10559", "title": "假音狂野：社交媒体平台检测深度伪造语音", "title_en": "Fake Speech Wild: Detecting Deepfake Speech on Social Media Platform", "authors": "Yuankun Xie,Ruibo Fu,Xiaopeng Wang,Zhiyong Wang,Ya Li,Zhengqi Wen,Haonnan Cheng,Long Ye", "background": "随着语音生成技术的迅速发展，深度伪造语音在社交媒体平台上广泛传播。现有的深度伪造音频对抗措施在公开数据集上取得了令人鼓舞的结果，但在跨领域场景中性能显著下降。", "innovation": "本文首先提出了一个名为假音狂野（FSW）的数据集，包含来自四个不同媒体平台的真实和深度伪造语音录音，共254小时，着重于社交媒体。使用公开数据集和高级半监督学习（SSL）为基础的对抗措施建立基准，以评估现有对抗措施在真实场景中的表现。同时评估了数据增强策略在提高检测深度伪造语音对抗措施鲁棒性方面的作用。通过增强公开数据集和融入FSW训练集，在多个评估集中显著提升了实际场景中深度伪造音频检测的效果，取得了较低的等错误率（EER）3.54%的结果。", "conclusion": "通过增强训练集并使用新的数据集，显著提高了实际场景下的深度伪造音频检测性能，在所有评估集中达到了平均等错误率（EER）为3.54%的结果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10616", "html_url": "https://arxiv.org/abs/2508.10616", "title": "图像超分辨率中的Fourier引导注意力上采样", "title_en": "Fourier-Guided Attention Upsampling for Image Super-Resolution", "authors": "Daejune Choi,Youchan No,Jinhyung Lee,Duksu Kim", "background": "传统上采用子像素卷积等上采样方法效率高，但常见于无法重建高频细节并引入伪影。这些方法在处理复杂纹理数据集时表现不佳，尤其是在保持图像细节和减少伪影方面存在明显缺陷。", "innovation": "本文提出了一种轻量级上采样模块——频率导向注意力（FGA），它结合了4种创新：基于Fourier特征的多层感知器进行位置频率编码，用于自适应空间对齐的跨分辨率相关注意力层，以及在频域中的L1损失监督光谱保真度。FGA通过这些机制，显著提高了性能，同时增加了极少的参数，展示了显著的PSNR增益和频域一致性改进，特别是在复杂纹理数据集上更为明显。", "conclusion": "实验结果表明，与传统上采样方法相比，FGA有效减少了伪影并保留了细微的图像细节，验证了其作为传统上采样方法的实用、可扩展替代方案的有效性。FGA在不同类型的超分辨率卷积网络中展示了持续的性能提升，特别是在保持细节和减少伪影方面具有明显的改进。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10594", "html_url": "https://arxiv.org/abs/2508.10594", "title": "FreeGAD：一种训练无须但有效的图异常检测方法", "title_en": "FreeGAD: A Training-Free yet Effective Approach for Graph Anomaly Detection", "authors": "Yunfeng Zhao,Yixin Liu,Shiyuan Li,Qingfeng Chen,Yu Zheng,Shirui Pan", "background": "图异常检测（GAD）的目标是在图中识别与大多数节点不同的节点，这一技术在社交网络和电子商务等领域有重要作用。尽管基于深度学习的GAD已有所发展，但现有方法通常面临高昂的部署成本和较差的可扩展性，这主要是由于其复杂且资源密集的训练过程。我们的实证研究发现，深度GAD方法在训练阶段通常被认为是非常关键的，但实际上对异常检测性能的贡献可能远低于预期。", "innovation": "受到这一发现的启发，我们提出了FreeGAD，一个训练无须但有效的GAD方法。FreeGAD利用亲和力门控残差编码器生成异常感知的表示。它还确定锚节点作为伪正常和异常指导，通过锚导向的统计偏差计算异常分数。广泛的实验表明，FreeGAD在多种跨领域的基准数据集上实现了卓越的异常检测性能、效率和可扩展性，无需进行任何训练或迭代优化。", "conclusion": "FreeGAD在多个领域的基准数据集上展示了优秀的异常检测性能、效率和可扩展性，无需任何训练或迭代优化，为图异常检测提供了一种全新的方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10556", "html_url": "https://arxiv.org/abs/2508.10556", "title": "Retrieval-Augmented Prompt for Out-of-Distribution Detection", "title_en": "Retrieval-Augmented Prompt for OOD Detection", "authors": "Ruisong Han,Zongbo Han,Jiahao Zhang,Mingyue Cheng,Changqing Zhang", "background": "可靠的部署机器学习模型需要准确的检测异常样本（Out-of-Distribution, OOD）。现有方法依赖辅助的异常样本或在分布数据（In-Distribution, ID）进行训练，但受到获取的异常样本有限以及与真实测试异常样本不匹配的问题，这些方法常常不能提供足够的语义监督，导致性能不佳。因此，为了解决这一问题，需要一种可以增强语义监督的新颖方法来提供更好的OOD检测性能.", "innovation": "提出了一种名为Retrieval-Augmented Prompt (RAP)的新型OOD检测方法。RAP通过检索外部知识来增强预训练的视觉-语言模型的提示，从而提供增强的语义监督。在训练过程中，根据外部文本知识的联合相似性检索异常样本描述词并用于增强模型的OOD提示。在测试过程中，根据遇到的OOD样本动态更新OOD提示，使模型能够快速适应测试环境，从而实现了大规模OOD检测基准的优越性能。具体而言，在ImageNet-1k数据集上的1-shot OOD检测中，相比之下，RAP将FPR95减少了7.05%，AUROC提高了1.71%.", "conclusion": "广泛的实验表明，RAP在大型OOD检测基准中达到了最先进的性能。深入的消融研究进一步验证了每个模块的有效性和本方法背后的原因。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10646", "html_url": "https://arxiv.org/abs/2508.10646", "title": "SPHENIC：基于拓扑信息的多视图聚类在空间转录组学中的应用", "title_en": "SPHENIC: Topology-Informed Multi-View Clustering for Spatial Transcriptomics", "authors": "Chenkai Guo,Yikai Zhu,Jing Yangum,Renxiang Guan,Por Lip Yee,Guangdun Peng,Dayu Hu", "background": "现有的空间转录组学聚类方法尽管已有一定进展，但仍存在两个主要问题：一是拓扑学习通常仅考虑单个细胞或其交互图的信息，但由于空间转录组学文件的噪声较大，这种方法容易受到低质量拓扑信号的影响；二是未能充分建模空间邻域信息，导致空间嵌入质量低。因此，这些方法在识别细胞亚群时并不能提供更全面的见解，特别是在处理噪声较大的数据时效果不佳。", "innovation": "文章提出了SPHENIC，一种新颖的空间持久同调增强邻域整合聚类方法。SPHENIC通过引入不变的拓扑特征，实现稳定表示学习。此外，设计了空间约束和分布优化模块（SCDOM），该模块旨在增强细胞及其邻域细胞的嵌入相似性，降低与非邻域细胞的相似性，从而生成更有利于聚类的空间嵌入。实验结果表明，SPHENIC在14个基准空间转录组学切片上对空间聚类任务表现优秀，优于现有最优方法3.31%-6.54%。", "conclusion": "研究表明，SPHENIC能够克服现有方法对低质量拓扑信号的脆弱性和空间邻域信息建模不足问题，通过引入拓扑特征和优化模块，显著提高了空间转录组学数据中细胞亚群识别的性能。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10666", "html_url": "https://arxiv.org/abs/2508.10666", "title": "经典物理与量子物理中的深度学习", "title_en": "Deep Learning in Classical and Quantum Physics", "authors": "Timothy Heightman,Marcin Płodzień", "background": "科学进步与新研究工具的出现密切相关。机器学习（尤其是深度学习）已经成为量子科学与技术中的一种变革性工具。量子系统本质上很复杂，而深度学习可以高效地探索大量参数空间、从实验数据中提取模式，并指导科研方向，这些能力已支持诸如精化量子控制协议和加速发现具有特定量子性质的材料等任务。同时，由于深度学习的巨大潜力，它也带来了风险，如模型过拟合、掩盖因果关系、以及结果的物理可解释性有限等问题。因此，了解这些局限性和开发缓解策略对于科学研究的严谨性至关重要。", "innovation": "这些讲义全面介绍了深度学习在量子应用中的研究生级入门课程，结合了概念阐述与实际案例，旨在让读者能够在何时及如何有效应用深度学习方面做出明智决策。课程还涵盖了深度学习的实际限制，并强调负责任地将人工智能方法应用于量子物理、化学和工程学中的问题解决方法。", "conclusion": "读者将学会识别何时以及如何有效地应用深度学习，理解其实践限制，并负责任地将AI方法应用于量子物理学、化学和工程学中的问题。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10701", "html_url": "https://arxiv.org/abs/2508.10701", "title": "REFN: 一个基于网络的强化学习框架以对抗1天/n天时间的漏洞利用", "title_en": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations", "authors": "Tianlong Yu,Lihong Liu,Ziyi Zhou,Fudu Xing,Kailong Wang,Yang Yang", "background": "由于网络设备部署规模庞大以及补丁更新延迟（平均补丁部署时间超过60天），1天或n天漏洞的利用对网络设备构成了严重的威胁。现有的防护手段，包括基于主机的补丁管理和基于网络的过滤，由于针对不同设备的扩展性有限、与嵌入式或遗留系统的兼容性问题以及复杂的部署过程（手动补丁验证容易出错）而效果不佳。", "innovation": "本文提出了一种名为REFN (Reinforcement Learning From Network)的新型框架，通过训练大规模语言模型（LLMs）以自主生成网络过滤器来防止1天或n天的漏洞利用。REFN通过在线网络奖励驱动的强化学习而不是传统的基于人类反馈的强化学习来确保扩展性，基于边缘安全网关（Amazon Eero）实现统一部署，并通过在线验证实际的网络流量确保了鲁棒性。REFN通过基于Agentic RAG的知识精炼、语法到网络增强的多阶段管道以及在线自动生成验证来应对训练LLMs以防止漏洞的主要挑战：扩充LLMs的漏洞修复能力，将语言模型的语境翻译成网络执行，解决LLMs幻觉和非确定性问题。", "conclusion": "REFN在22种不同的1天或n天漏洞中展示了有效性（相比其他方法准确率提高21.1%）、高效性（平均补丁部署时间为3.65小时）和扩展性（可以轻松扩展到10,000个设备）。REFN是训练LLMs快速预防大规模1天或n天漏洞利用的初始步骤。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10672", "html_url": "https://arxiv.org/abs/2508.10672", "title": "混合生成融合在高效和隐私保护的人脸识别数据集生成中的应用", "title_en": "Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation", "authors": "Feiran Li,Qianqian Xu,Shilong Bao,Boyu Han,Zhiyong Yang,Qingming Huang", "background": "本文介绍了我们参加DataCV ICCV挑战赛的方法，重点在于构建一个高质量的人脸数据集来训练人脸识别模型。构建的数据集不能包含与任何现有公共人脸识别数据集重复的身份信息。为此，我们首先对基础的HSFace数据集进行了彻底清理，通过混合专家（MoE）策略结合人脸嵌入聚类和GPT-4o辅助验证，识别并移除了错误标记或不一致的身份信息，保留了最大的一致身份集群，并通过数据扩充确保每个身份有固定数量的图像。为了进一步增加数据集的多样性，我们使用Stable Diffusion和提示工程生成了合成身份，并通过Vec2Face高效扩展这些参考图像，快速生成了49个身份一致的变体。这种方法结合生成对抗网络（GAN）和扩散模型样本，实现了高效构建多样且高质量数据集的目的。为了应对合成身份间高视觉相似性的问题，我们采用了从简到难的学习策略，将它们排列在训练计划的早期，让模型逐步适应难度递增的样本。最终数据集每个身份包含50张图像，并且所有新生成的身份都经过主流人脸数据集的检查，确保没有身份泄露。", "innovation": "我们提出了一种混合生成融合的方法，结合生成对抗网络（GAN）和扩散模型样本，高效构建了一种多样且高质量的人脸数据集。通过采用从简到难的学习策略，将合成身份放在训练的早期，帮助模型逐步适应难度递增的样本。最终，我们的方法在比赛中获得第一名，并显示出相对于10K、20K和100K数量身份规模，我们的数据集可以提升模型的性能。", "conclusion": "我们的方法成功地建立了一个高质量且无身份重叠的人脸数据集，通过混合生成融合策略有效提高了训练人脸识别模型的性能，并在网络竞赛中获得第一名，同时也展示了数据集的多样性和高质量。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10667", "html_url": "https://arxiv.org/abs/2508.10667", "title": "AddressVLM：使用大型视觉语言模型进行图像地址定位的跨视角对齐调整", "title_en": "AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models", "authors": "Shixiong Xu,Chenghao Zhang,Lubin Fan,Yuan Zhou,Bin Fan,Shiming Xiang,Gaofeng Meng,Jieping Ye", "background": "大型视觉语言模型（LVLMs）在粗粒度的地理定位任务中（如国家或城市级别）表现出了令人印象深刻的性能，但在城市区域内的街道级定位方面遇到了挑战。本文探讨了将城市规模的地址定位能力集成到LVLMs中，以便使用街景图像灵活地回答与地址相关的问题。然而，街景视觉问答（VQA）数据仅提供了微小的视觉线索，导致微调后的模型性能不佳。为解决这一问题，我们引入了视角不变的卫星图像作为宏观线索，并提出了跨视角对齐调整，包括街景视图和街景图像嫁接机制，以及自动标签生成机制。通过跨视角匹配，增强了LVLM对街道分布的全局理解。经过两阶段训练协议：跨视角对齐调整和地址定位调整，提出了AddressVLM模型", "innovation": "1. 引入视角不变的卫星图像作为宏观线索，克服街景图像microscopic视觉线索限制；2. 提出跨视角对齐调整，包括街景视图和街景图像嫁接机制，以及自动标签生成机制；3. 通过跨视角匹配增强了LVLM对街道分布的全局理解；4. 设计了两阶段训练协议，分别进行跨视角对齐调整和地址定位调整，构建了AddressVLM模型；5. 基于匹兹堡和旧金山的图像地址定位数据集构建了两个街景VQA数据集，评估结果显示AddressVLM比现有LVLMs在平均地址定位准确性上分别提高了9%和12%", "conclusion": "AddressVLM在街景VQA数据集上的质性和量化评估表明，该模型在平均地址定位准确性上分别优于现有LVLMs9%和12%，展示了在街景图像中进行地址定位的有效性和优越性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10729", "html_url": "https://arxiv.org/abs/2508.10729", "title": "EgoCross：跨域自体重心问题回答的多模态大型语言模型基准测试", "title_en": "EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering", "authors": "Yanjun Li,Yuqian Fu,Tianwen Qian,Qi'ao Xu,Silong Dai,Danda Pani Paudel,Luc Van Gool,Xiaoling Wang", "background": "近年来，多模态大型语言模型（MLLMs）在自体重心视频问题回答（EgocentricQA）领域取得了显著进展。然而，现有的基准测试和研究主要集中在烹饪和清洁等日常生活活动上。实际部署中不可避免地会遇到领域迁移问题，目标领域在视觉风格和语义内容上存在显著差异。为了解决这一问题，我们提出了一项名为EgoCross的综合基准测试，旨在评估MLLMs在EgocentricQA领域的跨域泛化能力。EgoCross涵盖了四个不同且具有挑战性的领域，包括手术、工业、极限运动和动物视角，代表了现实和高影响力的应用场景。", "innovation": "我们设计了EgoCross基准测试，以评估MLLMs在EgocentricQA领域的跨域泛化能力。EgoCross涵盖了四种关键的QA任务，包括预测、识别、定位和计数，包含大约1,000个QA对，分布在798个视频片段中。此外，我们进行了一些初步研究，如微调和强化学习，以探索潜在的改进方法。这些方法展示了现有模型难以泛化到日常活动以外的领域，突显了当前模型的局限性。", "conclusion": "大量的实验证明，大多数现有的MLLMs，无论是通用型的还是专门针对自重定向的，都难以泛化到日常生活之外的领域，这揭示了当前模型的局限。通过EgoCross和我们的辅助分析，我们希望为开发适应性强的自体重心视频理解奠定基础。数据和代码将发布在：[此链接]。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10732", "html_url": "https://arxiv.org/abs/2508.10732", "title": "APFL: 双流最小二乘分析个性化联邦学习", "title_en": "APFL: Analytic Personalized Federated Learning via Dual-Stream Least Squares", "authors": "Kejia Fan,Jianheng Tang,Zhirui Yang,Feijiang Han,Jiaxu Li,Run He,Yajiang Huang,Anfeng Liu,Houbing Herbert Song,Yunhuai Liu,Huiping Zhuang", "background": "个性化联邦学习（PFL）旨在通过协作训练为个体客户端提供个性化模型，但现有的PFL方法常常受到数据非IIB（非独立同分布）问题的影响，严重阻碍了集体泛化能力，进而影响后续的个性化效果。", "innovation": "提出了双流最小二乘分析个性化联邦学习（APFL）方法。该方法利用固定骨干网络进行特征提取，并在此基础上开发双重分析模型，实现集体泛化与个体个性化。具体而言，APFL包含一种共享的主要流，用于所有客户端的全局泛化，以及一种专用的增强流，用于每个客户端的个性化。", "conclusion": "APFL方法通过其异质性不变性优势，在多个数据集上验证了其相对于现有先进技术的优越性，准确率至少提高了1.10%到15.45%。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10687", "html_url": "https://arxiv.org/abs/2508.10687", "title": "Continuous Bangla Sign Language Translation: 利用图辅助减轻手语注释成本", "title_en": "Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph", "authors": "Safaeid Hossain Arib,Rabeya Akter,Sejuti Rahman", "background": "全世界有数百万人受到听力损失和听力障碍的影响。手语是聋人和听力困难者的高级交流方式。然而，在优先使用口语的社会中，手语经常被低估，导致交流障碍和社会排斥。为解决这一问题，Continuous Bangla Sign Language Translation项目致力于通过改进翻译方法来填补这一空白。尽管最近的方法利用了变压器架构取得最先进的结果，但我们的方法是将图基方法与变压器架构结合使用。这种结合了变压器和STGCN-LSTM架构的方法在无手语形式的翻译中更为有效。由于手语的社会和文化背景复杂，目前的手语翻译方法存在一定的局限性，特别是在需要高精度的翻译场景中，现有的方法往往无法满足需求。", "innovation": "我们的贡献包括架构的融合，探索了多种融合策略，并在多元手语数据集（RWTH-PHOENIX-2014T、CSL-Daily、How2Sign和BornilDB v1.0）上实现了新的最先进的性能。我们的方法在所有数据集中的性能都优于当前的翻译结果，展示了BLEU-4分数分别为4.01、2.07和0.5的显著改进，超过了GASLT、GASLT和slt_how2sign在各自数据集上的表现。此外，我们首次在BornilDB v1.0数据集上引入了基准测试，为未来研究建立了新的基准，突出了无手语形式翻译的重要性，以提高聋人和听力困难者的交流无障碍性。", "conclusion": "我们的方法为未来的研究设定了一个基准，强调了无手语形式翻译的重要性，以提高聋人和听力困难者的交流无障碍性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10751", "html_url": "https://arxiv.org/abs/2508.10751", "title": "Pass@k 训练以适配性平衡大型推理模型的探索和利用", "title_en": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models", "authors": "Zhipeng Chen,Xiaobo Qin,Youbin Wu,Yue Ling,Qinghao Ye,Wayne Xin Zhao,Guang Shi", "background": "强化学习（Reinforcement Learning）中的可验证奖励（RLVR）通常采用Pass@1作为奖励指标，但这种做法在探索与利用之间难以实现平衡，导致策略偏好保守行为并最终收敛到局部最优解。如何选择一个合适的奖励指标成为了关键问题。现有的研究中，虽然使用了Pass@k作为评估指标，但其与大型语言模型（LLM）探索能力的关系尚未得到充分关注。", "innovation": "本文通过对Pass@k作为奖励进行训练（Pass@k Training），并观察其探索能力的改进来研究探索与利用的关系。新的分析表明，探索与利用并不是相互冲突的目标，而是可以相互促进的。进一步地，通过分析Pass@k Training的优势，本文提出了直接设计优势函数的方法，并探索了其在RLVR中的应用，取得了一定的效果。", "conclusion": "探索与利用并不是相冲突的目标，而是可以相互促进的；Pass@k Training与分析解构成了直接设计优势函数的基础；这一方法可以为RLVR带来新的研究方向，展现出良好的前景。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10713", "html_url": "https://arxiv.org/abs/2508.10713", "title": "电磁计算在GPU上的天线模拟及其在机器学习应用中的应用", "title_en": "Electromagnetic Simulations of Antennas on GPUs for Machine Learning Applications", "authors": "Murat Temiz,Vemund Bakken", "background": "当前，一种基于开源电磁（EM）模拟软件（gprMax）并在图形处理单元（GPUs）上工作的天线模拟框架被提出，用于天线设计和优化中的机器学习应用。传统的商业EM软件模拟需要大量时间和资源，特别在训练阶段数据需求量大，但在电磁（EM）应用中以有限时间生成充足的训练样本具有挑战性，因为EM模拟的计算复杂度高。为了提高计算效率，这项研究利用了GPUs。此外，研究还比较了多种机器学习和深度学习模型在天线参数估计性能上的表现，并证明了入门级GPU在计算性能上明显优于高端CPU，而高端游戏GPU的计算性能大约是高端CPU的18倍。此外，研究表明开源EM模拟软件可以在微带天线的模拟中获得与商业软件相似的结果，前提是模拟的时空分辨率足够精细。", "innovation": "提出了一种基于开源EM模拟软件（gprMax）在GPUs上运行的天线模拟框架，用于机器学习和代理模型的应用。该框架通过使用GPUs可以快速生成大量天线模拟结果，以支持天线数据集的构建。通过将多种机器学习和深度学习模型应用于天线参数估计，比较其性能差异，特别是强调了低端GPU在计算效率上的优势，并验证了开源EM模拟软件可以与商业软件产生类似结果的前提是采用足够精细的时空分辨率进行模拟。", "conclusion": "研究表明，入级GPU在计算性能上明显优于高端CPU，高端游戏GPU的计算性能大约是高端CPU的18倍。开源EM模拟软件可以与商业软件产生类似结果，前提是采用足够精细的时空分辨率进行微带天线的模拟。这项研究为利用机器学习进行天线设计与优化提供了有效的框架和方法，提高了复杂EM模拟的效率和可行性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10655", "html_url": "https://arxiv.org/abs/2508.10655", "title": "Serial Over Parallel: 学习持续统一以实现多模态视觉目标跟踪和基准测试", "title_en": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking", "authors": "Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Chunyang Cheng,Tao Zhou,Xiaojun Wu,Josef Kittler", "background": "由于不同模态之间的互补性质，集成多种多模态视觉对象跟踪(MMVOT)任务受到越来越多的关注。现有方法将所有数据传感器类型混合在一起进行单一训练过程，从数据为中心的角度构建并行模式，旨在针对涉及任务的联合分布求解全局最优解。然而，缺乏一个统一的基准，使得所有类型的数据可以同时存在，导致在分离的基准上进行评估，从而引起训练和测试之间的一致性问题，进而导致性能下降。因此，为了解决这些问题，这篇文章在两个方面进行了改进：首先，介绍了统一基准UniBench300，通过结合多种任务数据，将推理步骤从三个减少到一个，缩短了27%的时间；其次，将统一过程重新表述为串行格式，逐步整合新任务，通过这种方式，可以将性能下降归因于以前任务的知识遗忘，这自然与持续学习(连续学习)的哲学观相一致，促进将连续学习注入到统一过程中的进一步探索。在两个基线和四个基准上进行的大量实验证明了UniBench300的重要性以及连续学习在支持稳定的统一过程中的优越性。此外，在进行专门分析时，发现性能下降与网络容量呈负相关，模态差异导致了各个任务中性能下降水平的变化(RGBT > RGBD > RGBE对于MMVOT)，提供了对未来多模态视觉研究的宝贵见解。", "innovation": "该工作通过以下两个创新点解决了问题：1) 介绍了一个统一基准UniBench300，通过结合多种任务数据，将推理步骤从三个减少到一个，缩短了27%的时间。2) 将统一过程重新表述为串行格式，逐步整合新任务，将性能下降归因于以前任务的知识遗忘，促进了连续学习的引入。", "conclusion": "大量的实验结果展示了UniBench300的重要性以及连续学习对支持稳定统一过程的优越性。同时，发现性能下降与网络容量呈负相关，模态差异导致了各任务中性能下降水平的变化，提供了对未来多模态视觉研究的宝贵见解。源代码和所提出的基准可以在此链接中获得。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10758", "html_url": "https://arxiv.org/abs/2508.10758", "title": "自不容错稀疏注意机制用于层次点云数据集的原生可训练实现", "title_en": "Natively Trainable Sparse Attention for Hierarchical Point Cloud Datasets", "authors": "Nicolas Lapautre,Maria Marchenko,Carlos Miguel Patiño,Xin Zhou", "background": "当前，使用变压器模型处理大规模物理系统数据集时，主要挑战在于注意力机制的平方级时间复杂度。为了解决这一问题，本研究探索了将Erwin架构与原生稀疏注意力（NSA）机制结合，以提高变压器模型的效率和感受野，特别适用于大规模物理系统的应用场景。", "innovation": "本研究创新性地将NSA机制应用于非序列数据，并实现了Erwin NSA模型。该模型在宇宙学模拟、分子动力学和气压建模这三项来自物理科学领域的数据集上进行评估，其性能能够达到或超过原始Erwin模型的水平。", "conclusion": "研究表明，Erwin NSA模型能够有效地提高处理大规模物理系统数据集的效率，并且在多个应用场景中表现出色。此外，该研究还复现了Erwin论文中的实验结果，验证了模型的正确实现。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10760", "html_url": "https://arxiv.org/abs/2508.10760", "title": "FROGENT：端到端全流程药物设计智能体", "title_en": "FROGENT: An End-to-End Full-process Drug Design Agent", "authors": "Qihua Pan,Dong Xu,Jenna Xinyi Yao,Lijia Ma,Zexuan Zhu,Junkai Ji", "background": "目前用于药物发现的强大人工智能工具散落在不同的网络应用、桌面程序和代码库中。这种分散使得科学家们需要管理和应对不兼容的接口和专门的脚本，过程繁琐且重复。为解决这一问题，提出了一种综合的药物设计智能体，名为FROGENT。FROGENT利用大型语言模型和模型上下文协议，整合了多个动态生物化学数据库、可扩展的工具库和特定任务的人工智能模型，实现了药物发现工作流程的动态执行。", "innovation": "FROGENT引入了一种有代理性的框架，通过集成大型语言模型、模型上下文协议、动态生物化学数据库、可扩展工具库以及特定任务的人工智能模型，使得能够动态执行复杂的药物发现工作流程，包括识别靶标、分子生成和逆合成规划等任务。FROGENT在八个不同方面的基准测试中表现优异，相较于开源模型Qwen3-32B和商业模型GPT-4o，显著提高了最佳基线性能，并在交互分析中将性能翻倍。", "conclusion": "研究表明，优化药物发现的端到端流程可以显著提高研究人员的生产力。FROGENT的发展表明强化智能体药物发现管道能够更好地支持药物设计工作，提高了药物发现的整体效率和可靠性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10798", "html_url": "https://arxiv.org/abs/2508.10798", "title": "SET知觉因素框架：迈向自主系统中确保知觉", "title_en": "The SET Perceptual Factors Framework: Towards Assured Perception for Autonomous Systems", "authors": "Troi Williams", "background": "未来的自主系统承诺为社会带来巨大的好处，但它们的部署引起了对安全性和可信度的担忧。关键问题之一是确保机器人的感知可靠性，因为感知是实现安全决策的基础。感知中的失败往往源于复杂但常见的环境因素，可能导致事故，从而侵蚀公众的信任。", "innovation": "作者提出了一种称为SET (Self, Environment, and Target) 知觉因素框架。该框架旨在系统地分析环境因素（如天气、遮挡或传感器限制）对知觉的负面影响，并使用SET状态树对这些因素的来源进行分类，使用SET因素树建模这些来源和因素如何影响物体检测或姿态估计等感知任务。通过这两棵树，开发了知觉因素模型，量化给定任务中的不确定性。", "conclusion": "该框架旨在促进严格的系统安全性保证，并通过提供一种透明和标准化的方法来识别、建模和传达感知风险，促进公众对自主系统的理解和信任。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10779", "html_url": "https://arxiv.org/abs/2508.10779", "title": "带有生成扩散先验的细粒度超高清参考图像超分辨率", "title_en": "Ultra-High-Definition Reference-Based Landmark Image Super-Resolution with Generative Diffusion Prior", "authors": "Zhenning Shi,Zizheng Yan,Yuhang Yu,Clara Xue,Jingyu Zhuang,Qi Zhang,Jinwei Chen,Tao Li,Qingnan Fan", "background": "参考基于图像超分辨率（RefSR）的目标是通过利用额外参考高分辨率（参考HR）图像中的语义和纹理信息来恢复低分辨率（LR）图像。现有的基于扩散的RefSR方法通常基于ControlNet构建，但在有效地对齐LR图像和参考HR图像之间的信息方面存在困难。此外，当前的RefSR数据集分辨率有限，图像质量差，导致参考图像缺乏足够的细节来支持高质量的恢复。考虑到这些问题，本文提出了TriFlowSR，一个新的框架，旨在明确地在LR图像和参考HR图像之间实现模式匹配。此外，我们引入了Landmark-4K，这是首个专为UHD地标场景设计的RefSR数据集。", "innovation": "本文提出了一种名为TriFlowSR的新框架，首次提出了针对实际退化情况下超高清地标场景的基于扩散的RefSR管道。TriFlowSR设计了一种参考匹配策略来有效地匹配LR图像和参考HR图像。与现有方法相比，该方法能够更好地利用参考HR图像中的语义和纹理信息。", "conclusion": "本文展示了基于扩散的RefSR管道在超高清地标场景下的应用，并提出了一种新的数据集和框架，能够在实际退化的情况下实现高质量的图像恢复。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10785", "html_url": "https://arxiv.org/abs/2508.10785", "title": "在节点级图异常检测中增强自动编码器的公平性", "title_en": "Enhancing Fairness in Autoencoders for Node-Level Graph Anomaly Detection", "authors": "Shouju Wang,Yuchen Song,Sheng'en Li,Dongmian Zou", "background": "图异检测（GAD）在各个领域变得越来越重要。随着图神经网络（GNNs）的快速发展，GAD 方法已经取得显著性能改进。然而，GAD 中的公平性考量尚未充分展开。GNN 基于的 GAD 模型可能会继承并放大训练数据中存在的偏见，导致不公平的结果。当前的工作主要集中在开发公平的 GNN 上，大部分方法针对节点分类任务，通常使用简单的层架构而不是广泛用于异常检测的自动编码器结构。在针对基于自动编码器的 GAD 模型的公平性问题上，尚未有充分的研究。", "innovation": "提出了一个新的框架 DECAF-GAD，它通过因果框架下的专门自动编码器架构和公平性引导损失函数来缓解偏见，同时保持 GAD 性能。通过在合成和真实数据集上的广泛实验，DECAF-GAD 不仅实现了与基准 GAD 方法相当的异常检测性能，还显著改善了公平性指标。", "conclusion": "DECAF-GAD 不仅能够实现与其他 GAD 方法相当的异常检测性能，同时还能够显著提升公平性指标。该论文提出的因果框架和特定的自动编码器架构为未来在自动编码器中增强 GAD 的公平性提供了新的思路和方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10828", "html_url": "https://arxiv.org/abs/2508.10828", "title": "一个用于识别向社交机器人自我披露的多模态神经网络", "title_en": "A Multimodal Neural Network for Recognizing Subjective Self-Disclosure Towards Social Robots", "authors": "Henry Powell,Guy Laban,Emily S. Cross", "background": "人类社会互动的一个重要特征是主观自我披露。尽管社交与行为学文献已经对自我披露的特征及其后果进行了大量研究，但迄今为止，开发能够准确模拟自我披露的计算系统的研究工作相对较少。特别是在需要社交机器人与人类在各种社交场景中协同工作并建立关系的情况下，研究人类如何与机器人伙伴进行自我披露尤为重要。现有的工作主要集中在描述和后果上，对于如何在机器人伴侣上进行自我披露的研究则较少。", "innovation": "本研究基于情感识别领域的模型，开发了一种自定义的多模态注意力网络。网络的训练使用了作者自行收集的大量自我披露视频数据集，通过引入一种新的损失函数——尺度保持交叉熵损失，显著提升了分类和回归问题的性能。实验结果显示，使用新型损失函数训练的最佳模型的F1分数为0.83，相较于最佳基准模型提高了0.48，这在允许社交机器人识别交互伙伴的自我披露方面取得了显著进展。", "conclusion": "本研究表明，通过开发的多模态注意力网络和提出的损失函数，能够显著提高社交机器人识别自我披露的能力，这对于具有社会认知能力的社交机器人的发展具有重要意义。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10776", "html_url": "https://arxiv.org/abs/2508.10776", "title": "决策导向学习法在全局最小方差组合中的协方差估计", "title_en": "Estimating Covariance for Global Minimum Variance Portfolio: A Decision-Focused Learning Approach", "authors": "Juchan Kim,Inwoo Tae,Yongjae Lee", "background": "投资组合优化被认为是风险管理的基石，通过量化风险与收益之间的权衡。然而，由于未来的不确定性，准确的参数估计对有效的投资组合构建至关重要。传统的统计估计方法和机器学习算法通常通过最小化均方误差（MSE）来确定这些参数，但这可能导致次优的投资决策。为了解决这一问题，本文采用决策导向学习（DFL）方法，该方法直接优化决策质量而不是预测误差，从而推导出全局最小方差组合（GMVP）。", "innovation": "本文通过解析GMVP的理论解及其属性来推导出决策损失的梯度，并通过广泛的实证分析证明，专注于预测的估计方法可能在实践中难以生成最优配置，而基于DFL的方法则能持续提供更好的决策性能。此外，文章还全面分析了DFL在构建GMVP中的机制，强调其降低波动性、决策驱动特性和估算特性。", "conclusion": "研究表明，预测导向的估计方法在实践中可能无法产生最优的配置，而基于DFL的方法则能够持续地优化决策性能。DFL在GMVP构建中的机制包括降低波动性、推动决策以及估算特性，并表明这种新颖的方法能够通过直接优化决策质量来提高投资组合优化的结果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10774", "html_url": "https://arxiv.org/abs/2508.10774", "title": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "title_en": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "authors": "Youping Gu,Xiaolong Li,Yuhao Hu,Bohan Zhuang", "background": "目前，扩散变换器在高保真视频生成领域处于领先地位，但它们耗时的去噪过程和长期序列的二次注意力成本限制了推断速度。虽然步进蒸馏和稀疏注意力机制都显示出加速的潜力，但将这两种方法有效结合仍面临重大挑战，如无训练整合效果不佳，分别训练稀疏注意力需要高成本的数据。", "innovation": "提出了一种名为BLADE的数据无关联合训练框架，通过引入动态生成内容感知稀疏性掩码的可调节块稀疏注意机制和直接将稀疏性纳入蒸馏过程的稀疏注意蒸馏范式，结合步进蒸馏流程，实现了快速收敛和效率提升。", "conclusion": "实验结果表明，与50步骤的基线相比，BLADE在Wan2.1-1.3B模型上实现14.10倍的整体推理加速，而在CogVideoX-5B等模型上实现8.89倍的加速，同时保持了质量的一致提升。这些改进在VBench-2.0基准测试中得到了验证，人类评估也显示了更优的结果。代码和模型权重已公开提供。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10869", "html_url": "https://arxiv.org/abs/2508.10869", "title": "Medico 2025: 视觉问答在胃肠道成像中的应用", "title_en": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging", "authors": "Sushant Gautam,Vajira Thambawita,Michael Riegler,Pål Halvorsen,Steven Hicks", "background": "该挑战针对胃肠道（GI）影像的可解释性人工智能（XAI）视觉问答（VQA）任务进行了研究，作为MediaEval任务系列的一部分。它旨在通过开发能够基于胃肠道内窥镜图像回答临床相关问题并提供合乎医学推理的解释性说明的模型，来促进医疗影像分析中可信的人工智能技术的发展。", "innovation": "通过设置两个子任务：一、使用Kvasir-VQA-x1数据集回答多样类型的视觉问题；二、生成多模态解释以支持临床决策。使用包含定量性能指标和专家审查解释性评估的结合方法来推进可信人工智能技术的发展。", "conclusion": "该挑战通过Medico 2025竞赛进行，旨在通过先进的人工智能模型和解释性方法，提高胃肠道成像分析的准确性与可解释性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10771", "html_url": "https://arxiv.org/abs/2508.10771", "title": "AEGIS: AI生成视频序列的真实性评估基准", "title_en": "AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences", "authors": "Jieyu Li,Xin Zhang,Joey Tianyi Zhou", "background": "近年来，AI生成内容的进展推动了高度逼真合成视频的兴起，这严重影响了社会信任和数字完整性。现有的视频真实度检测基准通常存在逼真度有限、规模不足和复杂度不够的问题，无法有效评估当今的视觉-语言模型对复杂的伪造内容的辨识能力。为了弥补这一关键缺口，我们提出了AEGIS，一种针对高度逼真且语义精确的AI生成视频检测的新模式大型规模基准。AEGIS包含超过10,000个严谨筛选的真实和合成视频，由各种最新的生成模型生成，包括Stable Video Diffusion、CogVideoX-5B、KLing和Sora，既包括开源架构，也包括专有架构。特别地，AEGIS集成了特有的具有鲁棒性评估的挑战子集，并提供了包括语义真实描述、运动特征和低级视觉特征的多模态注释，有助于真实性检测并支持下游任务，如多模态融合和伪造定位。", "innovation": "AEGIS提出了一个全新的大规模基准，专门针对高度逼真和语义复杂的AI生成视频的检测。它包含超过10,000个由多种最先进的生成模型生成的真实和合成视频，这些模型包括Stable Video Diffusion、CogVideoX-5B、KLing和Sora，既有开源也有专有架构。此外，该基准还特别构建了具有鲁棒性评估的挑战子集，并提供了语义真实性描述、运动特征和低级视觉特征等多模态注释，提高了检测能力和下游应用的支持度。实验表明，最先进的视觉-语言模型在AEGIS最具挑战性的子集上表现较差，说明了该数据集的独特复杂性和逼真度。因此，AEGIS为开发真正可靠、广泛通用的视频真实性检测方法奠定了基础，能够有效应对现实世界的伪造威胁。", "conclusion": "AEGIS建立了不可或缺的评估基准，从根本上推动了对能够真正应对现实伪造威胁的研究，开发出了更为稳健、可靠、普适的视频真实性检测方法。我们的数据集可以在以下链接获取：[提供的链接]"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10865", "html_url": "https://arxiv.org/abs/2508.10865", "title": "GPT-5在脑肿瘤MRI推理中的性能", "title_en": "Performance of GPT-5 in Brain Tumor MRI Reasoning", "authors": "Mojtaba Safari,Shansong Wang,Mingzhe Hu,Zach Eidex,Qiang Li,Xiaofeng Yang", "background": "在神经肿瘤学中，准确区分脑肿瘤类型对于指导治疗计划至关重要。近期，大型语言模型的进步使得视觉问答（VQA）方法得以发展，这将图像解释与自然语言推理相结合。基于这三种脑肿瘤分割（BraTS）数据集（胶质母细胞瘤（GLI）、脑膜瘤（MEN）和脑转移瘤（MET）），本研究评估了GPT-4o、GPT-5-nano、GPT-5-mini和GPT-5在结构化的脑肿瘤VQA基准测试上的表现。", "innovation": "使用了多种大型语言模型进行脑肿瘤VQA，特别是在无监督环境下，通过链式思考进行准确性的评估。这种评估方法结合了图像和推理任务的能力，是文章的创新点。", "conclusion": "GPT-5-mini在视觉和推理任务中的宏观平均准确度最高（44.19%），其次是GPT-5（43.71%）、GPT-4o（41.49%）和GPT-5-nano（35.85%）。不同肿瘤亚型的性能存在差异，没有单一模型能在所有群体中占据主导地位。研究结果表明，GPT-5家族模型在结构化的神经肿瘤学VQA任务中能够达到中等准确度，但还不适用于临床使用。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10872", "html_url": "https://arxiv.org/abs/2508.10872", "title": "基于TLE的A2C代理用于陆地覆盖轨道路径规划", "title_en": "TLE-Based A2C Agent for Terrestrial Coverage Orbital Path Planning", "authors": "Anantha Narayanan,Battu Bhanu Teja,Pruthwik Mishra", "background": "低地球轨道（LEO）的拥堵增加了对地球观测卫星的高效部署和安全操作的持续挑战。任务规划者不仅需要考虑特定任务的需求，还需要应对日益增加的与活跃卫星和太空碎片相撞的风险。本文提出了一种使用优势actor- crítica算法（A2C）的强化学习框架，旨在优化轨道参数以在预定义的地面半径内实现精确的陆地覆盖。", "innovation": "本文的创新点包括：（1）一个基于TLE的轨道仿真环境，包含物理约束；（2）验证了Actor-Critic方法在连续轨道控制中的优越性，优于信任区域方法；（3）展示了快速收敛能力，使卫星部署更加灵活。", "conclusion": "本文的方法显示了强化学习作为可扩展和智能LEO任务规划的高效替代方案的应用潜力，特别是在解决轨道路径规划中的连续控制问题方面。A2C算法在任务目标覆盖率和训练步数方面的优越性能表明，这种方法能够有效地适应实时任务规划的应用需求。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10839", "html_url": "https://arxiv.org/abs/2508.10839", "title": "基于强化学习的大型语言模型在序列决策中的应用", "title_en": "Reinforced Language Models for Sequential Decision Making", "authors": "Jim Dilkes,Vahid Yazdanpanah,Sebastian Stein", "background": "大型语言模型（LLMs）作为序列决策代理表现出潜力，但由于其依赖于大型、计算成本高昂的模型，导致应用受限。尽管已有后训练方法适用于单轮交互，但它们无法处理多步骤代理任务中的奖励归因问题。因此，需要改进小型模型，并提出一种新的后训练算法以解决这些问题，特别是在多步骤任务中能够更有效地分配信用分数的方法是亟待解决的问题。", "innovation": "提出了一种新型的后训练算法-Multi-Step Group-Relative Policy Optimization（MS-GRPO），该算法基于正式的Text-Mediated Stochastic Game（TSMG）和Language-Agent Policy（LAP）框架，通过将整个累积回合奖励分配给每个单独的回合步骤来解决奖励归因问题。此外，算法还引入了一种新的绝对优势加权回合采样策略，以提高训练性能。通过在Snake和Frozen Lake上对30亿参数的模型进行后训练，验证了MS-GRPO的有效性，并表明这种方法可以使30亿参数的模型在Frozen Lake任务上的表现优于720亿参数的基准模型50%。", "conclusion": "研究表明，针对性的后训练是利用LLMs创建序列决策代理的实际且有效的方法，替代依赖模型规模的做法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10887", "html_url": "https://arxiv.org/abs/2508.10887", "title": "代表基准问题域中配置回声状态网络的经验研究", "title_en": "Empirical Investigation into Configuring Echo State Networks for Representative Benchmark Problem Domains", "authors": "Brooke R. Weborg,Gursel Serpen", "background": "本文研究了使用四种不同基准问题评估回声状态网络（Echo State Network, ESN）性能的表现。由于这类网络的配置以及参数选择对网络性能有着重要影响，且缺乏相关经验的人很难理解和调整这些参数，因此，通过一系列代表不同问题域的基准任务来展示这些影响，旨在解决回声状态网络架构经验不足的问题。", "innovation": "提出了针对同一领域问题的架构配置、参数选择及其值的实用建议和准则，帮助新手理解和进入该领域。还探讨了架构、设计和参数选择及值的变化对回声状态网络性能的影响。", "conclusion": "通过一系列基准任务模拟和实验，展示了参数选择及其值对回声状态网络架构性能的影响，强调了理解和调整这些参数对于构建成功的回声状态网络架构的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10875", "html_url": "https://arxiv.org/abs/2508.10875", "title": "关于扩散语言模型的综述", "title_en": "A Survey on Diffusion Language Models", "authors": "Tianyi Li,Mingda Chen,Bowei Guo,Zhiqiang Shen", "background": "扩散语言模型（DLMs）作为一种快速崛起的替代自回归（AR）范式的强有力且有前景的替代方案，正逐渐崭露头角。通过迭代去噪过程中的并行生成标记，DLMs在减少推理延迟和捕捉双向上下文方面具有天然的优势，从而能够对生成过程进行细粒度控制。尽管在速度上实现了数倍的提升，但最近的发展使得DLM们在性能上与自回归模型相当，使其成为多项自然语言处理任务的理想选择。", "innovation": "本综述详细概述了当前DLM的全景。从DLM的演进及其与其他范式的联系入手，涵盖了从基础原理到最新先进模型的众多内容。综述中还详细分析了从预训练策略到高级后训练方法的当前技术。同时，综述全面审查了DLM的推理策略和优化措施，包括解码并行性、缓存机制等方面的改进，以及最新针对DLM的多模态扩展和应用场景的讨论。此外，综述还讨论了DLM的限制和挑战，包括效率、长序列处理以及基础设施要求，并指出了未来的研究方向以支持该快速发展的领域。", "conclusion": "综上所述，本调查为当前DLM的全貌提供了最新的全面分类，深入分析了现有技术，并详细讨论了DLM的最新进展和挑战。未来的研究方向被概述，以确保在这个快速发展的领域中取得持续的进步。GitHub项目页面位于this https URL."}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.14325", "html_url": "https://arxiv.org/abs/2504.14325", "title": "FAIRGAME：使用博弈论识别AI代理偏差的框架", "title_en": "FAIRGAME: a Framework for AI Agents Bias Recognition using Game Theory", "authors": "Alessio Buscemi,Daniele Proverbio,Alessandro Di Stefano, TheAnh Han,German Castignani,Pietro Liò", "background": "在多代理应用中，让AI代理相互交互增加了对AI结果的可解释性和预测的复杂性，这对研究和社会中的可信采用有着深远的影响。尽管博弈论提供了强大的模型来捕捉和解释代理间的策略性互动，但缺乏可重复、标准和用户友好的IT框架使得比较和解释结果变得困难。", "innovation": "FAIRGAME框架是为识别AI代理中的偏差而开发的，它利用博弈论来弥补上述不足。FAIRGAME允许用户可靠地且容易地模拟所需的游戏和场景，并在模拟活动中比较结果与博弈论预测，从而系统地发现偏差，预知由策略性互动引起的行为变化，并进一步推动使用大型语言模型（LLM）代理的战略决策研究。", "conclusion": "FAIRGAME为研究者和社会提供了可靠的方法来识别和理解AI代理中的偏差，有助于系统的偏差发现和行为预判，提升了使用AI代理进行决策研究的能力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10880", "html_url": "https://arxiv.org/abs/2508.10880", "title": "通过模拟在LLM代理中搜索隐私风险", "title_en": "Searching for Privacy Risks in LLM Agents via Simulation", "authors": "Yanzhe Zhang,Diyi Yang", "background": "LLM（大型语言模型）基于代理的广泛部署可能导致一个严重的隐私威胁：恶意代理主动与他人进行多轮对话以提取敏感信息。这种动态对话使攻击策略适应性增强，可能导致严重的隐私侵犯。由于这些攻击和防御策略的不断发展性，手动预测和发现复杂的脆弱性非常困难。长期以来，对于这种问题缺少有效的应对策略和自动化工具。因此，研究由一个搜索框架提出，通过模拟隐私关键交互来交替提升攻击者和防御者指令。每种模拟涉及三个角色：数据主体、数据发送者和数据接收者。数据主体的行为固定，而数据接收者（攻击者）试图通过持续的互动交换从数据发送者（防御者）那里提取敏感信息。", "innovation": "本文提出了一个基于搜索的框架，通过模拟来提升攻击者和防御者的指令方法。该框架使用大型语言模型作为优化器，采用并行搜索和跨线程传播的方式分析模拟轨迹，并迭代地提出新的指令，从而高效地探索交互空间。此过程发现攻击策略从简单的直接请求升级到复杂的多轮策略，如模拟和知情同意伪造，而防御策略则从基于规则的约束进阶到身份验证状态机。这些发现对各种场景和核心模型都是通用的，展示了强大的实用价值，能够促进建立隐私aware代理的建设。", "conclusion": "本文通过模拟来搜索LLM代理中的隐私风险。通过一个基于搜索的框架，研究发现从直接请求到复杂多轮战术（如模拟和知情同意伪造）的攻击策略，以及从基于规则的约束到身份验证状态机的防御策略。这些发现跨越了多种场景和核心模型，展示了强大的实用性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.04293", "html_url": "https://arxiv.org/abs/2411.04293", "title": "一种针对组合优化的随机键优化器", "title_en": "A Random-Key Optimizer for Combinatorial Optimization", "authors": "Antonio A. Chaves,Mauricio G.C. Resende,Martin J.A. Schuetz,J. Kyle Brubaker,Helmut G. Katzgraber,Edilson F. de Arruda,Ricardo M. A. Silva", "background": "本文介绍了一种称为随机键优化器（RKO）的通用且高效的随机局部搜索方法，专门用于解决组合优化问题。RKO 使用随机键概念将解决方案编码为随机键向量，并通过问题特定的解码器将这些随机键解码为可行解决方案。RKO 框架能够结合多种经典的元启发式算法，这些算法可以独立或并行运行，同时通过精英解池促进解决方案的共享，从而使多种元启发式算法得以模块化适应。", "innovation": "这种模块化方法允许使用多种元启发式算法，如模拟退火、迭代局部搜索和贪婪自适应随机搜索过程等。RKO 框架在 C++ 中实现，已公开发布 (Github 公共仓库：在这里 <http://this.link>)，并被应用于三个NP难组合优化问题，即 α-邻域 p 中心问题、树枢纽位置问题和节点容量图划分问题。这些结果证明了该框架能够产生高质量的解决方案，适用于多种问题领域。", "conclusion": "RKO 框架因其在不同问题领域产生的高质量解决方案的能力而被证明是强有力的工具，突出体现了其作为一种组合优化工具的潜在优势。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.08329", "html_url": "https://arxiv.org/abs/2504.08329", "title": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models", "title_en": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models", "authors": "Junmo Kim,Namkyeong Lee,Jiwon Kim,Kwangsoo Kim", "background": "电子健康记录（EHR）基础模型在各种医疗任务中的表现得到了改善，但存在一个根本性限制：处理未见过的医学代码，即超出词汇范围的数据。这一问题限制了EHR基础模型的普适性以及不同词汇集训练模型的整合能力。", "innovation": "本研究提出了一种基于Observational Medical Outcome Partnership (OMOP)共同数据模型（CDM）的新型医疗概念表示（MedRep）方法。通过大型语言模型（LLM）提示增强每个概念的定义信息，并利用OMOP词汇的图形本体补充文本表示，从而在多种预测任务中优于传统的EHR基础模型和其他方法的医学代码分词器模型", "conclusion": "该研究展示了MedRep的普适性，并通过外部验证进一步证明了其有效性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.18405", "html_url": "https://arxiv.org/abs/2403.18405", "title": "利用大型语言模型在法律案例检索中的相关性判断", "title_en": "Leveraging Large Language Models for Relevance Judgments in Legal Case Retrieval", "authors": "Shengjie Ma,Qi Chu,Jiaxin Mao,Xuhui Jiang,Haozhe Duan,Chong Chen", "background": "确定与给定查询相关的法律案件涉及到长篇文字的导航和细微的法律推理。传统上，这项任务需要大量的时间和专业知识来识别关键的法律事实，并得出合理的司法结论。同时，现有的存在法律案例相似的数据缺乏可解释性，这使得理解相关性判断的理据变得困难。随着大型语言模型（LLMs）能力的增强，研究人员已经开始探索它们在这一领域的应用。然而，使用通用的大语言模型进行可靠的法律案例检索的相关性判断方法仍然较少研究。", "innovation": "为了填补这一研究空白，本文提出了一种新的少样本方法，通过L大型语言模型辅助生成与专家一致的可解释的相关性判断。该方法将判断过程分解为几个阶段，模仿了人类标注者的工作流程，并允许灵活地结合专家推理以提高相关性判断的准确性。此外，它还确保了数据标签的可解释性，提高了相关性评估过程的透明度和清晰度。通过LLMs与人类专家做出的相关性判断的比较，作者实证表明，提出的方法可以产生可靠和有效的相关性评估。我们进一步证明，通过基于标注的知识蒸馏，我们的方法可以在少量专家监督下使大型语言模型获得案例分析的专业知识，并将这种能力转移给较小的模型。", "conclusion": "通过本研究，我们提出了一种新的方法，利用大型语言模型来提高法律案例检索中的相关性判断的准确性和可解释性。这种方法不仅能够提高判断的准确性，还提供了透明和清晰的评估过程。通过实证研究，验证了该方法能够在少量专家监督下训练大型语言模型，使其能够在法律案例分析中有效应用，并将这种专业知识通过知识蒸馏传递给更小的语言模型。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.20046", "html_url": "https://arxiv.org/abs/2405.20046", "title": "抗数据异质性条件下鲁棒泛化的联邦跨训练学习者", "title_en": "Federated Cross-Training Learners for Robust Generalization under Data Heterogeneity", "authors": "Zhuang Qi,Lei Meng,Ruohan Zhang,Yu Wang,Xin Qi,Xiangxu Meng,Han Yu,Qiang Yang", "background": "联邦学习能够使模型在来自不同源的数据上训练，以提高泛化能力。然而，由于数据分布的固有差异，局部模型的优化目标依然不一致，在跨训练后依然会表现为特征空间的异质性。现有方法通过知识蒸馏试图解决这一问题，但知识点来自单一视角，未能充分解决局部和全局知识的不一致问题。", "innovation": "该研究提出了一种跨训练方案FedCT，包含三个主要模块：一致性感知知识广播模块、多视角知识引导的表示学习模块以及基于Mixup的特征增强模块。FedCT通过优化模型分配策略来增强客户端之间的协作优势，并结合全局和局部视角的知识来增强局部知识在模型交换前后的一致性和多样性，以缓解来自局部和全局视角的知识遗忘问题。", "conclusion": "通过广泛的实验，研究证明FedCT能够在平均准确率上超越现有最先进的方法，有效地缓解了来自局部和全局视角的知识遗忘问题，增强了联邦学习中的特征对齐和泛化能力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22365", "html_url": "https://arxiv.org/abs/2507.22365", "title": "超越准确性：AI元认知敏感性如何提高辅助决策", "title_en": "Beyond Accuracy: How AI Metacognitive Sensitivity improves AI-assisted Decision Making", "authors": "ZhaoBin Li,Mark Steyvers", "background": "在依赖AI输入的人类决策场景中，AI的预测准确性和其置信度估计的可靠性都对决策质量产生影响。本文强调了AI元认知敏感性的作用，即AI预测正确与否的能力，并提出了一个评估AI预测准确性和元认知敏感性联合影响的理论框架。", "innovation": "提出了一种评估混合决策环境中AI预测准确性和元认知敏感性联合影响的理论框架；证明了在某些条件下，虽然AI预测准确性较低但具有更高的元认知敏感性，可以提升人类决策的整体准确性；通过行为实验验证了更高的AI元认知敏感性可以改善人类决策性能。", "conclusion": "强调不仅要评估AI决策辅助的准确性，还要考虑其元认知敏感性，并优化两者以实现更好的决策结果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.10881", "html_url": "https://arxiv.org/abs/2508.10881", "title": "ToonComposer: 生成后关键帧统一卡通生产", "title_en": "ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing", "authors": "Lingen Li,Guangzhi Wang,Zhaoyang Zhang,Yaowei Li,Xiaoyu Li,Qi Dou,Jinwei Gu,Tianfan Xue,Ying Shan", "background": "传统的手绘和动画制作包括关键帧设定、中间帧生成和着色等步骤，这些都需要大量的手动努力。尽管最近人工智能取得了进展，但现有的方法通常会将这些步骤分开处理，导致错误累积和伪影。例如，中间帧方法在处理大运动时会遇到困难，而着色方法则需要密集的每帧草图。因此，需要一种方法来统一这些流程，以提高效率和质量的稳定性。", "innovation": "‘ToonComposer’是一种生成模型，将中间帧生成和着色统一到关键帧设定后的单一步骤。它采用稀疏草图注入机制，提供精确控制，同时利用空间低秩适应方法将现代视频基础模型适配到卡通领域，保留其时间先验。ToonComposer只需要单个草图和一个彩色参考帧就能取得出色效果，同时支持任何时间位置的多个草图以增加精确运动控制的可能性。这使得该模型减少了人工劳动，提高了灵活性，适用于实际场景。此外，还创建了一个名为PKBench的新基准测试，该测试使用人工绘制的草图来模拟实际应用场景，验证了ToonComposer在视觉质量、运动一致性及生产效率方面的优势。", "conclusion": "ToonComposer通过将中间帧生成和着色统一到一个步骤，并支持稀疏输入和多层次的草图注入提供了一种更加灵活且有效的解决方案，适用于人工智能辅助的卡通生产，其性能显著优于现有的方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22423", "html_url": "https://arxiv.org/abs/2507.22423", "title": "关于智能的定义", "title_en": "On the Definition of Intelligence", "authors": "Kei-Sing Ng", "background": "本文探讨了如何通过一种物种中立的形式来捕捉智能的本质，这样可以对其进行评估，并且足够一般以涵盖各种智能行为的范式，包括强化学习、生成模型、分类、类比推理和目标导向决策。研究指出，智能的本质在于给定概念的实体样本后，能够生成同样的概念实体。", "innovation": "提出了一种基于实体保真度(\textit{entity fidelity})的一般标准：智能是根据给定的概念实体生成相同概念实体的能力。定义了\text{\textepsilon}-概念智能，即相对于一个概念，如果没有选择的可接受区分器能够将生成的实体与原始实体区分开超过容差\textepsilon，则被认为是\text{\textepsilon}-智能。文档还介绍了正式框架、实验协议，并讨论了评价、安全性和泛化的含义。", "conclusion": "该工作通过定义\text{\textepsilon}-概念智能为智能的衡量标准，并提出了完整的正式框架和实验协议，旨在为智能工程提供一个通用且可评估的标准，以促进智能评价、安全性和泛化的理解。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15758", "html_url": "https://arxiv.org/abs/2507.15758", "title": "LAPO：通过长度自适应策略优化实现推理效率的内部化", "title_en": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "authors": "Xingyu Wu,Yuchen Yan,Shangke Lyu,Linjuan Wu,Yiwen Qiu,Yongliang Shen,Weiming Lu,Jian Shao,Jun Xiao,Yueting Zhuang", "background": "大型推理模型通过扩展链式思考序列实现了显著性能，但这种计算自由度导致即使是简单问题也会产生大量不必要的令牌生成。已有方法通常通过设置硬性限制或事后干预控制推理长度，限制模型的灵活性，而未充分利用模型内部优化其推理流程的能力。", "innovation": "提出了一种新的Length-Adaptive Policy Optimization（LAPO）框架，将推理长度控制从外部约束转化为模型的内在能力。LAPO通过两个阶段的强化学习过程，使模型可以在推理过程中自动理解并适应适当的推理深度，而不是通过外部干预或硬性限制。第一阶段使模型发现成功解题长度的统计分布，第二阶段利用这些模式作为元认知指导，直接嵌入模型的推理上下文，确保推理时的灵活性。实验表明LAPO可以在不牺牲准确性的前提下将令牌使用量减少40.9%。研究表明LAPO训练的模型可以发展出根据问题复杂性分配计算资源的能力，实现高效的推理过程。", "conclusion": "实验结果表明，使用LAPO训练的模型能够在不牺牲准确性的前提下将令牌使用量减少40.9%，模型还发展出根据问题复杂性自动调整计算资源分配的新兴能力，实现高效的推理过程。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.12830", "html_url": "https://arxiv.org/abs/2407.12830", "title": "大型语言模型的基于知识的一致性测试", "title_en": "Knowledge-based Consistency Testing of Large Language Models", "authors": "Sai Sathiesh Rajan,Ezekiel Soremekun,Sudipta Chattopadhyay", "background": "本文系统地揭示和度量了大型语言模型（LLMs）的知识不一致性和知识空白。研究背景在于，尽管LLMs在许多任务上表现出色，但其知识的准确性和一致性仍有待进一步验证。", "innovation": "本文提出了一个名为KonTest的自动化测试框架，利用知识图谱构建测试案例，通过语义等价查询和测试或acles来探测并测量LLM对世界的不一致性，并通过加权LLM模型集合减轻知识空白。此外，基于KonTest的测试集提出了一种减轻方法，降低了32.48%的知识空白。", "conclusion": "本文使用四种当前最先进的LLMs（Falcon、Gemini、GPT3.5和Llama2）展示了KonTest生成了19.2%导致错误的输入（9979个测试输入中1917个错误），并且揭示了所有测试的LLMs总共存在16.5%的知识空白。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09123", "html_url": "https://arxiv.org/abs/2508.09123", "title": "OpenCUA: 开放的计算机使用代理基础", "title_en": "OpenCUA: Open Foundations for Computer-Use Agents", "authors": "Xinyuan Wang,Bowen Wang,Dunjie Lu,Junlin Yang,Tianbao Xie,Junli Wang,Jiaqi Deng,Xiaole Guo,Yiheng Xu,Chen Henry Wu,Zhennan Shen,Zhuokai Li,Ryan Li,Xiaochuan Li,Junda Chen,Boyuan Zheng,Peihang Li,Fangyu Lei,Ruisheng Cao,Yeqiao Fu,Dongchan Shin,Martin Shin,Jiarui Hu,Yuyan Wang,Jixuan Chen,Yuxiao Ye,Danyang Zhang,Dikang Du,Hao Hu,Huarong Chen,Zaida Zhou,Haotian Yao,Ziwei Chen,Qizheng Gu,Yipu Wang,Heng Wang,Diyi Yang,Victor Zhong,Flood Sung,Y.Charles,Zhilin Yang,Tao Yu", "background": "计算机视觉-语言模型已经展现了作为计算机使用代理（CUA）的能力，能够自动化多种计算机任务。随着这些代理的商用来潜力增加，最强大的CUA系统的关键细节仍然不公开。这些代理将越来越多地调解数字互动并代表我们执行重要决策，因此研究社区需要访问开放的CUA框架以研究其能力和风险。为了解决这一问题，本文提出了OpenCUA，这是一个全面的开源框架，用于扩大CUA数据和基础模型的规模。", "innovation": "OpenCUA框架包括：(1)注解基础设施，能够无缝捕获人类计算机使用演示；(2)AgentNet，首个涵盖3种操作系统和200多种应用程序及网站的大型计算机使用任务数据集；(3)可扩展的管道，将演示转换为状态-动作对，并结合反思性长链推理以确保随着数据增加而保持稳健的性能提升。本文的端到端代理模型在CUA基准测试中表现出色，尤其是OpenCUA-32B在OSWorld-Verified上的平均成功率达到了34.8%，是迄今为止开源模型的新标准，并超越了OpenAI CUA（GPT-4o）。进一步的分析表明，本方法在各个领域具有良好的泛化能力，并受益于增加的测试时计算量。", "conclusion": "我们发布了注解工具、数据集、代码和模型，以构建进一步CUA研究的开放基础。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08909", "html_url": "https://arxiv.org/abs/2508.08909", "title": "Compass-Thinker-7B技术报告", "title_en": "Compass-Thinker-7B Technical Report", "authors": "Anxiang Zeng,Haibo Zhang,Kaixiang Mo,Long Zhang,Shuman Liu,Yanhui Huang,Yawen Liu,Yuepeng Sheng,Yuwei Huang", "background": "最近的R1-Zero-like研究进一步表明，推理扩展赋予了大语言模型（LLMs）前所未有的推理能力，并且强化学习是揭示其复杂推理核心技术的关键。然而，直接在超大规模模型上进行RL实验涉及高昂的计算成本和资源需求，存在显著的风险。因此，需要探索在减少计算资源与成本的情况下利用强化学习的潜力，并为更大模型的RL配方研究提供见解。", "innovation": "我们提出了Compass-Thinker-7B模型，通过一个专门为强化学习设计的流水线从开源模型中训练而来，并采纳了一个包含30K个可验证数学问题的数据集。通过根据不同阶段配置数据和训练设置的不同难度分布，逐步释放模型潜能，提高训练效率。Compass-Thinker-7B在数学推理能力上显著优于同等规模的RL模型，特别是在AIME2024评估中取得了40%的准确率。", "conclusion": "Compass-Thinker-7B展示了在减少计算资源与成本的情况下强化学习的潜力，并通过提出新的方法实现了卓越的推理性能。这为后续更大型模型的RL研究提供了宝贵的经验和改进方向。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.13871", "html_url": "https://arxiv.org/abs/2402.13871", "title": "基于大规模语言模型的方法的可 透明变换器模型在钓鱼邮件检测中的应用", "title_en": "An Explainable Transformer-based Model for Phishing Email Detection: A Large Language Model Approach", "authors": "Mohammad Amaz Uddin,Md Mahiuddin,Iqbal H. Sarker", "background": "钓鱼邮件作为一种严重的网络威胁， 典型地利用伪造的电子邮件来欺骗用户， � 以窃取敏感信息并造成财务损害。。 攻击者经常采用可信实体的伪装来利用技术进步和复杂性化 来那防止和防止检测钓鱼变得更具挑战性 尽管学术界对钓鱼检测进行了大量研究， 但该 该仍然是网络安全领域的持续和艰巨挑战。", "innovation": "大规模语言模型（LLMs）和掩蔽语言模型（MLMs) 具有极大的的潜力提供创新的方法来解决长期存在的挑战。 在这项由 该项研究中 呈现了一个针对钓鱼邮件检测进行优化和精调的Distilil BERT变压器模型 ' 该模型通过使用一个钓鱼邮件数据集并使用预处理技术来清理和解决类别不平衡问题 ' 通过实验表明 该校模型能有效实现高精度 开证明其其分类能力良好 ' 最终 � �该 该校模型通过使用可 解释性人工智能 (XAI) 技术如局部模型无关解释 (LIME) 和变压器解释 �来 对模型在分类预测钓鱼邮件时如何做出决策 '", "conclusion": "最后 本研究提出一个透明的变压器模型用于钓鱼邮件检测 ' 免化模型展示了高性能的分类结果 及其对预测过程的透明性 �"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2312.07055", "html_url": "https://arxiv.org/abs/2312.07055", "title": "通过哈希函数在局部差分隐私下减少子图计数的通信成本", "title_en": "Communication Cost Reduction for Subgraph Counting under Local Differential Privacy via Hash Functions", "authors": "Quentin Hillebrand,Vorapong Suppakitpaisarn,Tetsuo Shibuya", "background": "在基于边的局部差分隐私下计算图统计，包括子图计数，现有的算法经常面临高通信成本的问题，这使得它们在处理大型图时效率较低，尽管数据压缩是差分隐私中常见的方法，但在局部差分隐私中的应用需要每台节点都能够重现的压缩形式，这在实践中较为困难。", "innovation": "介绍了一种线性同余哈希方法，能够在保持通信成本显著降低的同时，虽然会增加发布图统计量的方差。具体来说，该方法通过采样率达到s，能够将通信成本降低s^2倍。实验结果表明，在匹配通信成本的情况下，该方法在三角形计数的ℓ2-误差上能比领先算法减少多达1000倍的误差。", "conclusion": "我们的研究展示了如何通过线性同余哈希方法来有效减少局部差分隐私下的子图计数通信成本，同时在保持隐私的同时优化了统计效率。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23701", "html_url": "https://arxiv.org/abs/2507.23701", "title": "TextQuests：LLM在文本冒险游戏中的表现如何？", "title_en": "TextQuests: How Good are LLMs at Text-Based Video Games?", "authors": "Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks", "background": "现有评估AI代理的基准在评估其在现实世界挑战复杂互动环境中的实际能力方面存在局限。这些基准主要评估类似工具使用或结构任务的技能，但往往未能充分捕捉到代理在探索环境中自主操作的能力，这些环境需要长期且不断增长的上下文中的持续自我导向推理。为了更准确地评估AI代理在具有挑战性的探索性环境中的能力，该研究引入了基于Infocom冒险游戏套件的TextQuests基准测试。这些基于文本的冒险游戏可以花费人类玩家超过30个小时，并要求执行数百次精确动作以成功完成，适合作为评估AI代理的代理，特别是在专注于状态任务方面。", "innovation": "TextQuests是一种基于Infocom套件的文本冒险游戏的基准测试，它能更准确地评估LLM代理在其需要长期尝试性学习和单一互动会话内持续解决问题的探索性环境中的自我问题解决能力和内在的长期上下文推理能力。它独特地限制了外部工具的使用，从而使评估侧重于LLM代理在一个探索性环境中处理内在长上下文推理任务的能力。", "conclusion": "TextQuests已被发布，它允许评估LLM代理在挑战性探索环境中的自我问题解决能力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.02754", "html_url": "https://arxiv.org/abs/2405.02754", "title": "隐式安全集算法用于可证明安全的强化学习", "title_en": "Implicit Safe Set Algorithm for Provably Safe Reinforcement Learning", "authors": "Weiye Zhao,Feihan Li,Changliu Liu", "background": "深度强化学习（DRL）在许多连续控制任务中展现了出色的性能。但是，其在实际应用中的一个重大障碍是没有提供足够的安全保证。尽管通过奖励塑形，DRL智能体能够在期望上满足系统安全性，但构建能在每一个时间步均严格满足硬约束（例如安全规范）的智能体仍然是一个艰巨的任务。现有安全控制领域的研究提供了在持续满足硬约束情况下提供保证的方法，但这些方法需要显式分析系统动力学模型，而这样的模型在DRL设置中通常是不可获取的。", "innovation": "本文提出了一种无需模型的可证明安全控制算法——隐式安全集算法（Implicit Safe Set Algorithm），该算法能够为DRL智能体合成保障整个训练中的可证明安全的防护措施。该算法仅通过查询黑盒动态函数（例如数字孪生模拟器）来合成一种安全指数（屏障证书）和后续的安全控制法则，并且理论上证明该算法能够保证有限时间内收敛到安全集并且在连续时间和离散时间系统中保持不变性。", "conclusion": "所提出的算法在最先进的Safety Gym基准测试中验证了其性能，实现了零安全违规情况，并且相比于最先进的安全DRL方法获得了$95\backslash% \backslashpm 9\backslash%$的累积奖励。此外，该算法在高维系统中具有良好的可扩展性，支持并行计算。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.12446", "html_url": "https://arxiv.org/abs/2409.12446", "title": "神经网络在低复杂度数据上泛化", "title_en": "Neural Networks Generalize on Low Complexity Data", "authors": "Sourav Chatterjee,Timothy Sudijono", "background": "论文探讨了具有ReLU激活函数的前馈神经网络在处理简单数据集时的泛化能力。通过从一个简单的编程语言生成独立同分布的数据样本，证明了能够通过最小描述长度（MDL）前馈神经网络成功泛化。利用这种简单的编程语言和对这类网络的描述长度定义，论文提供了一系列基本计算任务的例子，如质数检测。在这些基本任务上，证明了该网络能够在指定概率下准确回答新样本的判断结果，而不必特意设计用于检测质数任务。此外，还讨论了噪声数据情况下的拓展，表明MDL神经网络插值器可以在一定程度上避免过度拟合。", "innovation": "论文创新性地提出了最小描述长度（MDL）前馈神经网络的概念，并证明了这种网络在低复杂度数据上的泛化能力。通过从简单编程语言生成的数据样本，论文展示了能够准确泛化的MDL网络能够在质数检测等基本任务上达到高准确率，即便网络不是专门为这些任务设计。此外，还研究了在噪声数据情况下的表现。", "conclusion": "研究结果表明，对于简单编程语言生成的独立同分布数据，使用最小描述长度（MDL）前馈神经网络能够有效泛化并将这种能力应用到基本计算任务中。同时，该研究也为处理噪声数据提供了新的视角，表明MDL神经网络插值器在泛化能力上有其独特的优势。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.17702", "html_url": "https://arxiv.org/abs/2409.17702", "title": "使用层次表示 lifelong 机器人经验的语义记忆口头化", "title_en": "Episodic Memory Verbalization using Hierarchical Representations of Life-Long Robot Experience", "authors": "Leonard Bärmann,Chad DeChant,Joana Plewnia,Fabian Peller-Konrad,Daniel Bauer,Tamim Asfour,Alex Waibel", "background": "口头化机器人经验，即总结和回答关于机器人过去的问题，是提升人机交互的关键能力。以往的研究使用基于规则的系统或微调深度模型来口头化短时间（几分钟）的事件数据，限制了其泛化能力和可转移性。", "innovation": "本研究应用大规模预训练模型解决从零或少量例子出发口头化的任务，并特别关注终身经验的口头化。通过从事件记忆（EM）构建层次数据结构，低层表示原始感知和 proprioception 数据，高层抽象为自然语言概念。根据经验流构建的层次表示，应用大规模语言模型作为代理，基于用户查询交互式搜索记忆，并动态展开（最初折叠）树节点以找到相关信息。该方法即使扩展到数月的机器人经验数据，也有助于保持计算成本低。", "conclusion": "我们通过在模拟家庭机器人数据、人类第一视角视频以及真实世界机器人记录上的评估，展示了该方法的灵活性和可扩展性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.06151", "html_url": "https://arxiv.org/abs/2410.06151", "title": "使用外在行为好奇心多样化策略行为", "title_en": "Diversifying Policy Behaviors with Extrinsic Behavioral Curiosity", "authors": "Zhenglin Wan,Xingrui Yu,David Mark Bossens,Yueming Lyu,Qing Guo,Flint Xiaofeng Fan,Yew Soon Ong,Ivor Tsang", "background": "模仿学习（IL）在多个应用中展现出了潜力（如机器人运动操控），但通常受限于仅学习单一专家策略，这限制了在不可预测的现实世界环境中的行为多样性和鲁棒性。", "innovation": "提出了结合了质量多样性优化与逆强化学习方法的新框架——质量多样性逆强化学习（QD-IRL），并引入了外在行为好奇心（EBC），使代理可以从一个大型行为档案中学习到更多样化的行为。该工作评估了EBC在多个机器人运动任务上的有效性，EBC提高了与GAIL、VAIL和DiffAIL结合的QD-IRL实例的性能，最多提高了185%，甚至在Humanoid上达到了20%的专家表现。", "conclusion": "EBC不仅提高了QD-IRL的性能，还在基于梯度树的质量多样性强化学习（QD-RL）算法中有效，从这个角度来看，它提供了一种通用的技术来学习多样化的策略。研究结果表明，EBC能够在多个机器人运动任务上多样化策略行为，极大地提升了策略性能。研究代码已提供。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.18368", "html_url": "https://arxiv.org/abs/2410.18368", "title": "CPU 设计空间探索中的多目标优化：只需注意力", "title_en": "Multi-objective Optimization in CPU Design Space Exploration: Attention is All You Need", "authors": "Runzhen Xue,Hao Wu,Mingyu Yan,Ziheng Xiao,Guangyu Sun,Xiaochun Ye,Dongrui Fan", "background": "现代 CPU 设计中的设计空间探索 (DSE) 至关重要，但当前的框架难以在高维架构空间中扩展和泛化。随着设计空间维度的不断增长，现有的 DSE 框架面临着三个根本挑战：（1）在大设计空间中，代理模型的准确性降低和可扩展性差；（2）由手工设计的启发式或穷尽搜索指导的低效获取；（3）可解释性较差，难以定位架构瓶颈。", "innovation": "主要创新包括：（1）一种基于感知的注意力机制，通过滑动窗口将注意力复杂度从 $O(n^2)$ 缩减到 $O(n)$，利用架构层次结构和局部性；（2）一种注意力感知瓶颈分析，可以自动识别关键参数以进行有针对性的优化，从而消除对特定领域的启发式方法的依赖。", "conclusion": "在使用 SPEC CPU2017 其他基准套件评估高维度 CPU 设计空间时，AttentionDSE 较最先进的基线实现了高达 3.9% 的帕累托体积增加和超过 80% 的探索时间减少。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.02012", "html_url": "https://arxiv.org/abs/2412.02012", "title": "INSIGHT：可解释的弱监督医疗图像分析", "title_en": "INSIGHT: Explainable Weakly-Supervised Medical Image Analysis", "authors": "Wenbo Zhang,Junyu Chen,Christopher Kanan", "background": "由于体积庞大，体扫图像和全切片病理图像（WSIs）通常需要从局部区域提取嵌入，然后通过聚合器进行预测。当前方法常需要后处理可视化技术（例如Grad-CAM），并且往往难以定位那些虽小但对临床至关重要的细节。这些限制促使研究人员寻求改进的方法来提供更准确的诊断结果并提高局部病状的可视化能力。", "innovation": "INSIGHT提出了一种新型弱监督聚合器，将热图生成作为诱导偏置。INSIGHT从预训练的特征图开始，利用带有小卷积核的检测模块捕获细节数，并使用具有较宽视野的感受域的上下文模块抑制局部假阳性。这可以通过内部热图突出显示诊断上相关的区域，从而提高病人的诊断结果的准确度。并且，INSIGHT在CT和WSI基准测试中实现了最先进的分类结果和高度的弱监督语义分割性能。", "conclusion": "INSIGHT通过创新的聚合方法和热图生成技术，在医疗图像分析领域取得了显著成果，增强了诊断的准确性和可解释性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.02409", "html_url": "https://arxiv.org/abs/2501.02409", "title": "扰动条件下的可解释神经ODE基因调控网络发现", "title_en": "Interpretable Neural ODEs for Gene Regulatory Network Discovery under Perturbations", "authors": "Zaikang Lin,Sei Chang,Aaron Zweig,Minseo Kang,Elham Azizi,David A. Knowles", "background": "现代高通量生物数据集含有成千上万次的扰动，提供了大规模发现描述基因之间调控关系的因果图的机会。以往的差分因果图形模型能够从大规模干预数据集中推断基因调控网络（GRN），但从遗传扰动中捕捉到因果基因调控关系。然而，现有的模型在表达能力和可扩展性方面有限，无法解决细胞分化等生物过程的动力学特性。", "innovation": "我们提出了PerturbODE框架，结合生物信息量丰富的神经常微分方程（神经ODE）来模拟扰动条件下的细胞状态轨迹，并从神经ODE的参数中推导出因果GRN。我们展示了PerturbODE在模拟和真实过表达数据集中的轨迹预测和GRN推断效果。", "conclusion": "PerturbODE在扰动条件下的基因调控网络发现中表现出了预测轨迹和推断GRN的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.19134", "html_url": "https://arxiv.org/abs/2411.19134", "title": "考虑多种运动模型的视觉SLAMMOT", "title_en": "Visual SLAMMOT Considering Multiple Motion Models", "authors": "Peilin Tian,Hao Li", "background": "同时定位与建图（SLAM）和多目标跟踪（MOT）是自动驾驶领域的关键任务，备受研究关注。传统上，SLAM致力于生成实时地图并确定车辆在未知环境中的姿态，而MOT则关注于实时识别和跟踪多个动态目标。然而，现有的方法常常将SLAM和MOT视为独立模块进行处理，这造成了局限性。因此，本研究旨在探索SLAM和MOT在视觉域的应用，考虑多种运动模型，以克服传统方法的不足，并提高跟踪的准确性和实时性。", "innovation": "本研究提出了一个综合考虑多种运动模型的视觉SLAMMOT方法，这一方法是对先前工作IMM-SLAMMOT的进一步发展。IMM-SLAMMOT已经在LiDAR基础上展示了其在联合SLAM和MOT方面的有效性和优势，本研究则尝试将这一优势拓展到视觉感知领域。", "conclusion": "本研究探讨了将多种运动模型整合到视觉SLAMMOT方法中的可行性和优势，填补了LiDAR和视觉感知之间在融合运动模型跟踪技术上的空白，验证了IMM-SLAMMOT方法在视觉域的有效性和实用性，提高了基于视觉的自动驾驶系统的跟踪能力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.06534", "html_url": "https://arxiv.org/abs/2412.06534", "title": "通过反演理解变压器基础的视觉模型", "title_en": "Understanding Transformer-based Vision Models through Inversion", "authors": "Jan Rathjens,Shirin Reyhanian,David Kappel,Laurenz Wiskott", "background": "在机器学习和计算机视觉领域，深入理解深度神经网络的工作机制仍是一项基本挑战。一种有潜力但尚未充分探索的方法是特征反演，它尝试通过训练的逆向神经网络恢复中间表示对应的图像。本研究重新审视了特征反演，引入了一种新的模块化版本，使之能更高效地应用。这种方法被系统地应用于大型变压器基础的视觉模型（如检测变压器和视觉变压器），并展示了如何对重构图像进行有意义的质性解释。进一步的定量评估揭示了两种变压器架构中表示图像特征的基本机制。这些分析揭示了这些模型如何编码上下文形状和图像细节、层之间的关系以及它们对颜色扰动的鲁棒性等关键见解。这些发现有助于更深入理解基于变压器的视觉模型和它们的内部表示形式。", "innovation": "本研究提出了一种新的模块化特征反演方法，使其能够更高效地应用于大型变压器基础的视觉模型。该方法能够系统地应用于检测变压器和视觉变压器等模型，并实现了对重构图像的质性解释。通过定量评估，研究揭示了基于变压器的视觉模型中表示图像特征的基本机制。", "conclusion": "通过定量评估展示了基于变压器的视觉模型中表示图像特征的基本机制。这些发现有助于更深入理解这些模型如何编码上下文形状和图像细节、层之间的关系以及其对颜色扰动的鲁棒性。这些研究结论为基于变压器的视觉模型的理解和改进提供了重要见解。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.10320", "html_url": "https://arxiv.org/abs/2410.10320", "title": "DiRW：路径感知的有向图学习以应对异质性问题", "title_en": "DiRW: Path-Aware Digraph Learning for Heterophily", "authors": "Daohan Su,Xunkai Li,Zhenjun Li,Yinping Liao,Rong-Hua Li,Guoren Wang", "background": "近年来，图神经网络（GNN）已成为处理图结构数据的强大表示学习工具。然而，大多数方法都针对无向图进行了设计，忽略了有向图（有向图）边缘中的丰富信息。事实上，有向图在真实世界中广泛应用，被证实能够解决异质性挑战。尽管有最近的发展，现有的基于空间和频谱的有向图神经网络（DiGNN）由于其复杂的学习机制和对高质量拓扑的依赖，导致效率低且性能不稳定。因此，需要一种解决方案来解决这些问题。", "innovation": "本文提出了一种名为Directed Random Walk（DiRW）的新颖插件化策略，用于大多数基于空间的DiGNN模型，并且作为一种新的有向图学习范式。该方法通过考虑节点特性以及拓扑结构，提出了一个路径采样器，该采样器根据行走概率、长度和数量，在无权条件下优化。在此基础上，DiRW引入了一个基于节点的可学习路径聚合器，以实现泛化节点表示。广泛的实验证明，DiRW：（1）作为插件化策略可以增强大多数基于空间的方法；（2）作为一种新范式实现了SOTA性能。", "conclusion": "在9个数据集上进行的大量实验表明，DiRW作为一种插件化策略可以增强大多数基于空间的方法，并且作为一种新的有向图学习范式实现了SOTA性能。源代码和数据可在该网址获取。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.15913", "html_url": "https://arxiv.org/abs/2411.15913", "title": "无训练的基于潜在扩散模型的音乐风格转换方法", "title_en": "A Training-Free Approach for Music Style Transfer with Latent Diffusion Models", "authors": "Heehwan Wang,Joonwoo Kwon,Sooyoung Kim,Shinjae Yoo,Yuewei Lin,Jiook Cha", "background": "音乐风格转换能够个性化音乐创作，通过结合一首乐曲的结构和另一首乐曲的风格特征实现。尽管最近的研究探索了基于文本条件的生成和基于扩散的过程合成技术，但大多数现有方法需要大量训练、配对数据集或详细的文本注释。这些方法在操作复杂性和资源需求方面受到限制。因此，本文旨在探讨一种新的无训练框架，能够直接操作预训练的潜在扩散模型（LDM）的自我注意层，从而实现音乐风格转换。这种方法通过在梅尔频谱图域中工作，将关键和价值表示从内容音频中替换为风格参考中的表示，无需任何微调即可转移音乐风格。", "innovation": "本文介绍了一种名为Stylus的新框架，该框架能够在不进行训练的情况下实现音乐风格转换。Stylus直接操作预训练的Latent Diffusion Model（LDM）的自我注意层，并在梅尔频谱域中运作，通过替换关键和价值表示来转移音乐风格，而不需要任何微调。为了进一步提高风格化质量和可控性，引入了查询保护、基于CFG的指导缩放、多风格插值以及相位保留重建。这种方法在感知质量和结构保留方面显著优于先前的工作，同时仍然保持轻量级和易于部署。这犟证了基于扩散的注意力操作可以用于高效、高保真和可解释的音乐生成，无需训练。", "conclusion": "本文提出的方法显著改善了感知质量和结构保留，同时保持了轻量级和简易部署。通过直接操作预训练LDM的自我注意层，Stylus能够实现无训练的音乐风格转换。这一工作展示了扩散基注意力操作在音乐生成中的潜力，无需进行额外的训练。相关代码将在本文接受后公开。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.19160", "html_url": "https://arxiv.org/abs/2412.19160", "title": "一种基于相位唯一交叉注意力的轻量级变压器在光照不变的生物特征认证中的应用", "title_en": "A Lightweight Transformer with Phase-Only Cross-Attention for Illumination-Invariant Biometric Authentication", "authors": "Arun K. Sharma,Shubhobrata Bhattacharya,Motahar Reza,Bishakh Bhattacharya", "background": "传统的生物识别系统由于各种客观因素受到了巨大挑战，例如基于面部识别的生物识别技术在戴口罩的情况下表现不佳，以及指纹识别技术面临的卫生问题。这些因素促使研究者寻找更可靠且不受干扰的技术方法。本文探讨了在戴口罩和非接触式识别情况下有效的人脸生物识别方法，提出了基于头面部前额和眼周双生物特征的相位唯一交叉注意力轻量级视觉变换器（POC-ViT）模型，旨在克服传统方法的限制。", "innovation": "本文创新性地提出了一种使用头面部前额和眼周两种生物特征的轻量级视觉变换器（POC-ViT），并在不戴口罩的情况下能够有效识别并提供无需身体接触的替代方法。POC-ViT利用相位唯一交叉注意力机制，能够捕捉到两个生物特征的个体和相关结构模式，并适合边缘设备部署。该模型即使在输入图像存在光照变化、分辨率和强度变化的情况下，也能保持良好的性能。", "conclusion": "POC-ViT框架在 Forehead Subcutaneous Vein Pattern and Periocular Biometric Pattern (FSVP-PBP) 数据库中表现优秀，对基于双重生物特征的光照不变的生物认证实现了98.8%的准确率，明显优于现有技术。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.08644", "html_url": "https://arxiv.org/abs/2502.08644", "title": "节奏共享：一种生物启发的神经网络零样本自适应学习范式", "title_en": "Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptive learning in neural networks", "authors": "Hoony Kang,Wolfgang Losert", "background": "人类大脑能够快速适应新环境并从有限数据中学习，这是人工智能算法难以复制的宝贵特性。在借鉴神经细胞的机械震荡节奏的基础上，开发了一种利用链接强度震荡的学习范式，使得网络能够在无需监督的情况下感知和适应微妙环境变化。", "innovation": "该范式通过设计链接震荡协调来快速学习和适应新环境，避免了传统依赖大量数据和监督的学习方法。网络能够预测多种上下文动态，包括前所未见的上下文，开创了认知新模型的构建途径。该范式不依赖特定的神经网络架构，因此可以被引入到现有的领先人工智能模型中。", "conclusion": "此项研究提供了一种强大的起点，用于构建新型认知模型，并通过生物启发的方法为神经网络引入快速自适应学习能力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01669", "html_url": "https://arxiv.org/abs/2502.01669", "title": "使用影响函数进行延迟反馈建模", "title_en": "Delayed Feedback Modeling with Influence Functions", "authors": "Chenlu Ding,Jiancan Wu,Yancheng Yuan,Cunchun Li,Xiang Wang,Dingxian Wang,Frank Yang,Andrew Rabinovich", "background": "在基于每转换成本（CPA）的在线广告模型中，准确的转换率（CVR）预测至关重要。主要挑战在于延迟反馈，即用户互动之后很久才发生转换，导致近期数据不完整，从而产生了偏差的模型训练。现有的解决方案可以在一定程度上解决这个问题，但通常依赖于辅助模型，这使得它们计算效率低下且对用户的兴趣变化不够适应。", "innovation": "提出了一种名为IF-DFM的模型，即影响函数增强的针对延迟反馈建模，可以估计新到达和延迟的转换对模型参数的影响，从而使模型能够在不完全重新训练的情况下高效更新。通过将逆海森矩阵-向量积重新表述为优化问题，IF-DFM在可扩展性和有效性之间取得了良好的平衡。", "conclusion": "实验表明，IF-DFM在准确性和适应性方面均优于之前的方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.06117", "html_url": "https://arxiv.org/abs/2501.06117", "title": "Fleurs-SLU：一种大规模多语言口语理解基准", "title_en": "Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding", "authors": "Fabian David Schmidt,Ivan Vulić,Goran Glavaš,David Ifeoluwa Adelani", "background": "口语理解（SLU）对那些缺乏正式书写系统的半数语言至关重要。与资源丰富的语言不同，对于这些语言来说，我们不能依赖自动语音识别（ASR）和文本型大型语言模型（LLMs）的级联来处理语音的语义理解。即使某些资源较少的语言有书写系统，ASR 也无法因为训练数据有限而提高准确性。现有的多语言 SLU 评价主要集中在浅表任务，如意图分类或语言识别，因此，本文介绍了 Fleurs-SLU，它包含了 102 种语言下的 692 小时话题性语音数据用于语用单元分类以及来自 92 种语言的 944 小时语音数据用于听觉理解的选择题回答。该基准涵盖了端到端语音分类模型、级联系统（结合语音转文本与后续基于LLM的分类）以及多模态语音-LLMs。", "innovation": "Fleurs-SLU 是一个全面的多语言 SLU 基准，它涵盖了广泛的多语言语音数据，包括用于主题语音分类的 692 小时语音和用于听觉理解的选择题回答的 944 小时语音。该基准可以评估端到端语音分类模型、级联系统（结合语音转文本与后续基于LLM的分类），以及多模态语音-LLMs。实验结果显示，级联系统在多语言 SLU 中表现更稳定，但很好地预训练的语音编码器在话题性语音分类中可以表现得和级联系统竞争。闭源语音-LLMs 的性能可以匹配甚至超越级联系统。这些结果表明，稳健的多语言 ASR、有效的语音到文本翻译以及强大的多语言 SLU 之间存在很强的关联性，这意味着声学和语义语音表示具有相互效益。", "conclusion": "研究表明，级联系统在多语言 SLU 中更为稳健，虽然很好地预训练的语音编码器可以实现较强的话题性语音分类。闭源语音-LLMs 的性能可以与级联系统相媲美甚至超越级联系统。还有研究表明，强大的多语言 ASR、有效的语音到文本翻译与强大的多语言 SLU 存在很强的关联性，这表明声学和语义语音表示之间存在相互效益。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.18475", "html_url": "https://arxiv.org/abs/2501.18475", "title": "CLoQ: 通过校准LoRA初始化增强量化LLM的微调", "title_en": "CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization", "authors": "Yanxia Deng,Aozhong Zhang,Selcuk Gurses,Naigang Wang,Zi Yang,Penghang Yin", "background": "使用低秩适应（LoRA）对大型语言模型（LLMs）进行微调已成为一种高效的方法，特别是在计算资源有限的情况下。然而，将LoRA技术应用于量化LLMs带来了独特的挑战，因为量化权重的表示精度较低。这项研究旨在解决这些挑战，通过提出一种简化的初始化策略，CLoQ旨在减轻这些挑战。CLoQ旨在最小化初始化阶段原LLM与其带有LoRA组件的量化版本之间的层间差异。通过使用小型校准数据集，CLoQ量化了一个预训练的LLM并确定了每个层的最佳LoRA组件，确保了后续微调的坚实基础。该项工作的一个重要贡献是提出了一个新型的理论结果，这使得能够精确且闭形式地构建这些最优的LoRA组件。研究验证了CLoQ在多个任务（如语言生成、算术推理和常识推理）中的有效性，证明了它在量化LLMs紧凑比特宽度时比现有LoRA微调方法具有更优的表现。", "innovation": "CLoQ 提出了一种新的校准LoRA初始化策略，专门为解决量化LLMs的挑战而设计。该策略包括通过使用小型校准数据集来量化预训练的LLM，并确定每个层的最优LoRA组件，从而确保了后续微调的坚实基础。创新点还在于提出了一种新型的理论结果，使得能够精确且闭形式地构建这些最优的LoRA组件。CLoQ在多个任务上表现出色，尤其是在超低比特宽度的情况下，相较于现有方法具有更优的表现。", "conclusion": "CLoQ展示了在量化LLMs中使用校准LoRA初始化的有效性，特别是在低比特宽度的情况下。CLoQ通过新颖的理论结果和校准策略，提高了量化LLMs的有效性和可靠性，为该领域的研究和发展提供了新的方向。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.01618", "html_url": "https://arxiv.org/abs/2502.01618", "title": "Rollout Roulette: 一种基于粒子蒙特卡洛方法的概率推理方法以概率推理方法在大规模语言模型推理时的可扩展性", "title_en": "Rollout Roulette: A Probabilistic Inference Approach to Inference-Time Scaling of LLMs using Particle-Based Monte Carlo Methods", "authors": "Isha Puri,Shivchander Sudalairaj,Guangxuan Xu,Kai Xu,Akash Srivastava", "background": "大型语言模型（LLMs）通过扩大模型规模和/或数据量获得了显著的性能提升。然而，最近的研究表明，这些方法的回报正在减小，促使增加推理时刻的计算量。现有的在推理时刻进行扩展的方法通常依赖奖励模型，将任务置于搜索问题中，这样的方法因奖励模型中的近似误差而容易受到奖励黑客攻击。因此，本文将推理时刻的可扩展性问题转化为概率推理任务，利用基于采样的技术探索状态空间模型在近似似然下的状态分布的典型集，而非直接优化其模态。", "innovation": "本文提出了一种新颖的基于粒子蒙特卡罗方法的推理时刻扩展方法，名为“Rollout Roulette”。该方法通过蒙特卡罗方法在概率推理任务中进行扩展，通过采样技术探索状态空间模型在近似似然下的状态分布的典型集，而不是直接优化其模态。实证评估表明，该方法在多种复杂数学推理任务上的扩展率是确定性搜索方法的4-16倍。使用该方法，Qwen2.5-Math-1.5B-Instruct在4次展开后超过了GPT-4o的准确性，而Qwen2.5-Math-7B-Instruct在32次展开后达到了o1级的准确度。此外，该工作也将概率推理领域的丰富文献与大规模语言模型推理时刻的可扩展性相结合，为未来工作开发更稳健的算法奠定了基础。", "conclusion": "我们的研究不仅提供了一种有效的推理时刻可扩展性的方法，还连接了概率推理领域的丰富文献与大规模语言模型推理时刻的可扩展性，为未来开发更稳健的算法提供了新的思路。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.08064", "html_url": "https://arxiv.org/abs/2503.08064", "title": "多模态的持续学习", "title_en": "Continual Learning for Multiple Modalities", "authors": "Hyundong Jin,Eunwoo Kim", "background": "持续学习旨在高效地在时间序列任务中学习新知识，同时防止忘记之前习得的知识。现有的方法大多专注于单一模态（如图像）的学习，这限制了它们在涉及多种模态的场景中的应用。本文针对这一问题，提出了一种新的持续学习框架，能够处理多种模态（图像、视频、音频、深度和文本），通过训练模型将各种模态与文本信息对齐，充分利用文本丰富的语义信息。然而，这种做法增加了模态间互相干扰的风险，尤其是在任务间输入特征差异较大的情况下。", "innovation": "本文提出的框架能够融合模态内知识和相关模态间信息，通过自我调节学习表示的变化，逐步将新知识融合到保留的信息中，同时通过选择性地整合先前遇到的模态的有关知识，来减轻跨模态干扰。此外，还引入了重新校准模态嵌入的策略，以有效解决模态间对齐中的偏差。", "conclusion": "通过在多种数据集上的广泛实验，结果显示本文提出的方法在多种持续学习场景中均优于现有方法，无论模态的属性是否已知，均能表现出更好的性能。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.04798", "html_url": "https://arxiv.org/abs/2503.04798", "title": "Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART}", "title_en": "Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART)", "authors": "Jingtian Yan,Zhifei Li,William Kang,Kevin Zheng,Yulun Zhang,Zhe Chen,Yue Zhang,Daniel Harabor,Stephen F. Smith,Jiaoyang Li", "background": "尽管最先进的多代理路径规划算法（MAPF）能够在几秒内为数百台机器人规划非碰撞路径，但这些算法通常依赖于简化的人形机器人模型，导致其在现实世界中的性能不清楚。研究人员一般无法在实验室获得数百台物理机器人，以评估算法的真实表现。同时，缺乏MAPF专业知识的工业从业人员需要易于使用且高效的模拟器，以测试并理解这些算法在特定环境中的性能。因此，需要一种能够生成逼真环境中各种因子的软件工具，支持多种MAPF算法和机器人模型，同时能够扩展到成千上万的机器人，并且易于工业用户使用。", "innovation": "SMART使用基于物理引擎的模拟器生成逼真的模拟环境，能够考虑复杂的真实世界因素，如机器人动力学和执行不确定性。另一方面，该工具基于行动依赖图的执行监控框架，便于与多种MAPF算法和机器人模型无缝集成，并且能够扩展到成千上万的机器人。", "conclusion": "SMART是一种实用的开源软件工具，能够为MAPF算法提供逼真的评估环境，支持广泛的算法应用，并扩展至成千上万的机器人，为学术界和工业界的MAPF算法测试提供了有力支持。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.16770", "html_url": "https://arxiv.org/abs/2502.16770", "title": "LED-Merging: 在地点-选举-隔离的模型融合中缓解安全-实用性冲突", "title_en": "LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint", "authors": "Qianli Ma,Dongrui Liu,Qian Chen,Linfeng Zhang,Jing Shao", "background": "预训练大型语言模型（LLMs）在专有任务上的微调需要大量的计算和数据成本。虽然模型合并提供了一种无需训练的解决方案来整合多个任务专用模型，但现有方法存在安全-实用性冲突的问题，即增强的一般能力会削弱安全性保障。这一问题根源在于参数幅度基于的选择过于简单化导致的神经元误识别，以及合并过程中跨任务神经元干扰。", "innovation": "提出了一种名为LED-Merging的三阶段框架，该框架通过梯度归因识别任务特异性神经元，通过多模型重要性融合动态选择关键神经元，并通过参数隔离解决冲突更新，从而缓解上述挑战。LED-Merging解决了安全-实用性冲突，为构建可靠的多任务LLMs提供了一个轻量且无需训练的新范式。", "conclusion": "在Llama-3-8B、Mistral-7B和Llama2-13B上的广泛实验表明，LED-Merging成功地减少了有害响应率，使Llama-3-8B-Instruct在HarmBench上的有害响应率降低了31.4%，同时保持95%的实用性性能，如在GSM8K上实现了52.39%的准确性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.19530", "html_url": "https://arxiv.org/abs/2503.19530", "title": "VectorFit : 适应性奇异和偏差向量微调的预训练基础模型", "title_en": "VectorFit : Adaptive Singular & Bias Vector Fine-Tuning of Pre-trained Foundation Models", "authors": "Suhas G Hegde,Shilpy Kaur,Aruna Tiwari", "background": "流行的参数高效微调（PEFT）方法通过并行参数化新的低秩或稀疏可训练权重来减少可训练参数数量，从而实现对预训练权重 \\(W\\) 的微调。然而，这些新参数是从零开始训练的，导致在低预算设置下，这些方法与完整的微调方法之间存在性能差距。", "innovation": "介绍了VectorFit，一种新的参数化方法，通过自适应训练预训练权重 \\(W\\) 中嵌入的知识的奇异向量和偏置，高效利用这些已有的知识，从而生成高秩增量权重矩阵 \\(\\Delta W\\)，与全微调方法相当。VectorFit相比领先的PEFT方法，可少用9倍的可训练参数，同时在多种语言和视觉任务上表现出色。", "conclusion": "通过在19个覆盖广泛语言和视觉任务的数据集上的全面实验，我们证明VectorFit在参数效率相关性上超过了基线方法，在性能上更胜一筹。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.24381", "html_url": "https://arxiv.org/abs/2503.24381", "title": "UniOcc：自主驾驶中 occupancy 预测和预测统一基准", "title_en": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving", "authors": "Yuping Wang,Xiangyu Huang,Xiaokang Sun,Mingxuan Yan,Shuo Xing,Zhengzhong Tu,Jiachen Li", "background": "现有研究中，自主驾驶中的occupancy预测和预测主要依赖于有限的数据集和部分伪标签进行评估，这限制了模型在场景分割和动态场景理解等方面的能力。因此，研究者提出了UniOcc，这是一个综合且统一的基准和工具包，旨在解决这些现有方法的局限性。", "innovation": "UniOcc通过整合多个真实世界的数据集（如nuScenes和Waymo）以及高质量的驾驶模拟器数据（如CARLA和OpenCOOD），提供了2D/3D occupancy标签，并标注了创新的每个体素流信息。不同于以前依赖于真实标签的评估方法，UniOcc引入了新的评估指标，这些指标不依赖于真实标签，能够从更多方面评估occupancy质量的鲁棒性。实验表明，大规模、多样化的训练数据和明确的流信息显著提高了occupancy预测和预测性能。", "conclusion": "经广泛实验表明，大规模、多样化的训练数据和明确的流信息能显著提升occupancy预测和预测性能。研究团队已经公开了数据和代码，以便其他研究者能够使用这些资源进行进一步的研究。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.18773", "html_url": "https://arxiv.org/abs/2503.18773", "title": "BitDecoding: 解锁用于长上下文LLMs的低比特KV缓存中的张量核心", "title_en": "BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache", "authors": "Dayou Du,Shijie Cao,Jianyi Cheng,Luo Mai,Ting Cao,Mao Yang", "background": "大语言模型（LLMs）的需求不断提高，尤其是在自回归解码时，随着每个生成的标记，关键值（KV）缓存的增长导致了对内存和宽带需求的增加。低比特KV缓存量化（例如4比特或2比特）可以在保留准确性的同时减少内存占用，但现有的系统由于依赖于CUDA内核，缺乏对Tensor Cores（现代GPU的主要计算源）的利用，而导致解码速度较慢。", "innovation": "BitDecoding是一种新的长上下文LLMs推理系统，采用低比特KV缓存并通过协力利用CUDA内核和Tensor Cores来实现高效的低比特KV缓存解码。它引入了自动优化布局的方法，用于充分利用Tensor Cores，并采用了战程级并行化策略以适应去量化。BitDecoding还包括支持各种注意力变体的查询转换模块、支持高性能高精度操作的量化核以及协调CUDA和Tensor Cores执行的软件定义管道以进行混合精度操作的解量化核。", "conclusion": "在RTX 4090、A100和H100上，BitDecoding分别比FP16 FlashDecoding-v2加速了7.5倍、4.8倍和8.9倍，并超越了最先进的低比特系统QServe最多4.3倍。在带有128K上下文的LLaMA-3.1-8B上，BitDecoding将单批次解码延迟降低了3倍，显著提高了长上下文生成的效果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.11655", "html_url": "https://arxiv.org/abs/2503.11655", "title": "基于DeepSeek-R1的可解释情感分析：性能、效率和少样本学习", "title_en": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning", "authors": "Donghao Huang,Zhaoxia Wang", "background": "大型语言模型（LLMs）已经改变了情感分析领域，但提高准确性、效率和可解释性之间的平衡仍然是一个关键挑战。本文首次全面评估了开源推理模型DeepSeek-R1与其竞争对手开源AI的GPT-4o和GPT-4o-mini，通过测试完整版和其精简版本，系统记录了少样本学习曲线。实验结果显示，DeepSeek-R1在5类情感任务上的F1分数达到91.39%，在二分类任务上的准确率达到99.31%，即使是仅用5次输出，其少样本效率也提高了8倍。这种特定架构的精简效果表明，基于32B Qwen2.5的模型优于基于70B Llama的变体，高出6.69个百分点。尽管推理过程减少了吞吐量，但DeepSeek-R1提供了透明的、逐步的解释，使其成为一个强大的、可解释的开源选择。", "innovation": "1. 首次全面评估DeepSeek-R1与其竞争对手GPT-4o和GPT-4o-mini。\n2. 系统记录了少样本学习曲线。\n3. 展示了DeepSeek-R1在少样本效率上的改善，尤其是在有限的实验次数下。\n4. 揭示了特定架构的精简效果，指出基于32B Qwen2.5的模型优于基于70B Llama的变体。\n5. 提供了透明、逐步的解释过程，增强了可解释性。", "conclusion": "DeepSeek-R1在少样本学习中表现出卓越的性能和效率，提供了可解释的推理过程，展示了其作为强大、可解释的开源替代品的潜力。尽管其推理过程略微减少了吞吐量，但DeepSeek-R1的可解释性优势使其在需要透明度的应用场景中具有明显优势。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05349", "html_url": "https://arxiv.org/abs/2504.05349", "title": "Hyperflux：剪枝揭示权重的重要性", "title_en": "Hyperflux: Pruning Reveals the Importance of Weights", "authors": "Eugen Barbulescu,Antonio Alexoaie,Lucian Busoniu", "background": "网络剪枝被用于减少大型神经网络的推理延迟和能耗。然而，目前大多数方法依赖于经验性直观的启发式方法，缺乏深刻的理论支撑。", "innovation": "提出了一种基于理论的L0剪枝方法Hyperflux，通过每个权重在权重移除时对梯度的响应来估计其重要性。它引入了一个全局压力项，持续将所有权重推向剪枝状态，同时根据权重的重要性自动再生关键权重。通过实验验证一系列理论上自然遵循的属性，并使用这些属性推导出通用尺度方程来设计稀疏度控制调度器。", "conclusion": "实验结果表明，Hyperflux在CIFAR-10和CIFAR-100上的ResNet-50和VGG-19模型中达到了最先进的稀疏度结果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.12188", "html_url": "https://arxiv.org/abs/2502.12188", "title": "通过推断时自适应增强基于扩散的神经组合求解器的跨问题泛化能力", "title_en": "Boosting Cross-problem Generalization in Diffusion-Based Neural Combinatorial Solver via Inference Time Adaptation", "authors": "Haoyu Lei,Kaiwen Zhou,Yinchuan Li,Zhitang Chen,Farzan Farnia", "background": "基于扩散的神经组合优化（NCO）方法通过学习离散扩散模型来生成解决方案，从而解决了NP完全问题。现有的NCO方法在跨尺度和跨问题泛化方面面临显著挑战，并且与传统求解器相比，训练成本较高。尽管最近有关扩散模型的研究引入了无需训练的引导方法，利用预定义的引导函数进行条件生成，但在组合优化领域这些方法尚未得到广泛探索。文章分析了基于扩散的NCO求解器的训练需求和现有挑战，指出现有方法在跨问题泛化方面存在局限性，尤其是跨尺度任务之间缺乏有效的迁移能力。", "innovation": "本文提出了一种训练无阻抗的推理时自适应框架（DIFU-Ada），该框架能够在无需额外训练的情况下，使基于扩散的NCO求解器具备零样本跨问题迁移和跨尺度泛化的能力。通过理论分析解释了跨问题迁移的能力，证明了单一训练的旅行商问题（TSP）求解器能够通过推理时自适应实现TSP变体（如捕获卡普TSP（PCTSP）和旅游者问题（OP））上的竞争性零样本迁移效果。", "conclusion": "通过DIFU-Ada框架实现了基于扩散的NCO求解器的训练无阻抗推理时自适应能力，显著提升了求解器在不同问题规模下的迁移性能，为解决组合优化中的跨问题泛化问题提供了新的思路。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01400", "html_url": "https://arxiv.org/abs/2504.01400", "title": "ToolACE-R：一种面向模型的迭代训练和自适应精炼框架用于工具学习", "title_en": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning", "authors": "Xingshan Zeng,Weiwen Liu,Xu Huang,Zezhong Wang,Lingzhi Wang,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Ruiming Tang,Qun Liu", "background": "工具学习（Tool learning）使大型语言模型（LLMs）能够利用外部工具解决复杂的用户任务，这为扩展模型能力提供了有希望的途径。然而，现有方法主要侧重于数据合成进行微调以使LLMs有效调用工具，基本上忽视了如何充分利用模型的潜力。", "innovation": "本文提出了一种新颖的框架ToolACE-R，该框架包括面向模型的迭代训练和自适应自精炼两种机制。ToolACE-R特征是在模型逐步调整训练样本的基础上进行有指导的迭代训练，以最大化其潜力，并采用自回馈训练语料库强调LLMs的能力以迭代精炼工具调用，无需外部反馈。此外，引入了自适应的自精炼机制，以实现测试时的高效扩展，使训练模型能够自主决定何时停止迭代自精炼过程。", "conclusion": "在多个基准数据集上进行了广泛的实验，表明ToolACE-R在性能上与基于API的先进模型具有竞争力。通过自适应自精炼机制，工具调用的性能可以更有效地提升。这些结果突显了ToolACE-R的有效性和普遍适用性，为更高效和可扩展的工具学习提供了有希望的方向。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.14493", "html_url": "https://arxiv.org/abs/2504.14493", "title": "FinSage：财务报告问答的多方面RAG系统", "title_en": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering", "authors": "Xinyu Wang,Jijun Chi,Zhenghan Tai,Tung Sum Thomas Kwok,Muzhi Li,Zhuhong Li,Hailin He,Yuchen Hua,Peng Lu,Suyuchen Wang,Yihong Wu,Jerry Huang,Jingrui Tian,Fengran Mo,Yufei Cui,Ling Zhou", "background": "在现实世界的应用中，利用大型语言模型往往需要使用领域特定的数据和工具，以便遵守复杂的规章制度。在金融领域，现代企业越来越多地依赖检索增强生成（RAG）系统来解决财务文档工作流中的复杂合规需求。但是，现有解决方案在处理多模态数据（例如文本、表格、图表）的固有异质性及监管标准的不断变化时，存在准确性降低的问题。因此，需要一种新的框架来解决这些问题，以确保合规性分析和信息提取的准确性。", "innovation": "本文提出了一种名为FinSage的框架，旨在解决多模态财务文档中的合规性分析问题。FinSage框架包括三个创新型组件：（1）一个多模态预处理管道，用于统一不同数据格式并生成段级元数据摘要；（2）一个配备查询扩展（HyDE）和元数据感知语义搜索的多路径稀疏密集检索系统；（3）一个多领域专门重排序模块，通过直接偏好优化（DPO）微调，以优先考虑关键合规内容。实验结果表明，FinSage在75个专家策编的问题中取得了92.51%的召回率，在FinanceBench问答数据集上的准确性比最好的基线方法高出了24.06%。此外，FinSage已被成功部署为在线会议中的财务问答代理，并已服务于超过1,200人。", "conclusion": "FinSage框架通过创新的技术方法解决了多模态财务文档中的复杂合规性分析问题，显著提高了信息提取的准确性和效率，并在实际应用中取得了积极的效果。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.06866", "html_url": "https://arxiv.org/abs/2504.06866", "title": "GraspClutter6D：用于杂乱场景鲁棒感知和抓取的大规模真实世界数据集", "title_en": "GraspClutter6D: A Large-scale Real-world Dataset for Robust Perception and Grasping in Cluttered Scenes", "authors": "Seunghyeok Back,Joosoon Lee,Kangmin Kim,Heeseon Rho,Geonhyup Lee,Raeyoung Kang,Sangbeom Lee,Sangjun Noh,Youngjin Lee,Taeyeop Lee,Kyoobin Lee", "background": "在杂乱环境中进行稳健的抓取仍然是机器人学中的一个开放性挑战。现有的基准数据集虽然显著促进了深度学习方法的发展，但主要关注简单的场景和较轻的遮挡情况，缺乏多样性，限制了其实用应用范围。 ", "innovation": "本文提出了GraspClutter6D数据集，该数据集包含1000个高度杂乱的场景，每场景包含14.1个物体，遮挡比例达62.6%。该数据集覆盖了200种物体在75种环境配置下的数据，并通过四台RGB-D相机从多个视角捕捉。此外，该数据集还包含了详尽的标注信息，包括73.6万种6D物体姿态以及5.2万张RGB-D图像上可行的93亿种抓取方式，并基准测试了最先进的分割、物体姿态估计和抓取检测方法。 ", "conclusion": "我们证明了GraspClutter6D数据集作为训练资源的有效性，表明在该数据集上训练的抓取网络在模拟和实际实验中均显著优于基于现有数据集训练的抓取网络。该数据集、工具包和标注工具已在项目网站上公开。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02640", "html_url": "https://arxiv.org/abs/2505.02640", "title": "具有动态资源约束的自适应预算多臂老虎机算法", "title_en": "Adaptive Budgeted Multi-Armed Bandits for IoT with Dynamic Resource Constraints", "authors": "Shubham Vaishnav,Praveen Kumar Donta,Sindri Magnússon", "background": "物联网（IoT）系统在必须实时响应并管理不断变化的资源约束（如能量和带宽）的环境中运行。然而，当前的方法在应对随时间变化的操作限制方面常常表现不佳。", "innovation": "本文提出了一种针对具有动态操作限制的IoT应用的新型预算多臂老虎机框架。此模型引入了一个逐渐衰减的违约预算，使得在学习初期可以容忍有限的约束违约，而随着时间推移逐渐提高合规性标准。文章还提出了自适应预算上限置信区间（UCB）算法，以平衡性能优化与时变约束下的合规性。", "conclusion": "本研究通过理论保证和广泛仿真，展示了自适应预算UCB算法在无线通信场景中的快速适应性和更好的约束满足度，优于标准在线学习方法。这些结果表明该框架在构建自适应和资源感知的IoT系统方面的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.17493", "html_url": "https://arxiv.org/abs/2504.17493", "title": "目标导向的时间序列预测：基础框架设计", "title_en": "Goal-Oriented Time-Series Forecasting: Foundation Framework Design", "authors": "Luca-Andrei Fechete,Mohamed Sana,Fadhel Ayed,Nicola Piovesan,Wenjie Li,Antonio De Domenico,Tareq Si Salem", "background": "传统的时间序列预测方法通常旨在最小化整体预测误差，而不考虑下游应用中不同预测范围的重要性差异。这些方法在推理时无法灵活调整其聚焦范围，通常需要重新训练以适应特定的应用场景。", "innovation": "本文提出了一种训练方法，该方法使得预测模型能够在推理时根据应用特定的兴趣区域自动调整其聚焦范围，而无需重新训练。该方法在训练过程中将预测空间细分为多个部分，并动态赋予不同的权重以突出显示由应用指定的目标范围。与此前需要预定义范围的方法不同，本框架支持灵活的、按需的调整。实验证明，本方法不仅在感兴趣区域提高了预测准确性，还在下游任务中取得了可衡量的性能提升。", "conclusion": "本研究表明，在实际系统中，预测建模与决策制定之间的紧密集成具有巨大潜力。本文提出的方法为这一集成提供了新路径，展示了目标导向的预测模型在提升实际应用中决策制定效率方面的能力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11528", "html_url": "https://arxiv.org/abs/2505.11528", "title": "LaDi-WM: 基于潜在扩散的世界模型及其在预测性操作中的应用", "title_en": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation", "authors": "Yuhang Huang,Jiazhao Zhang,Shilong Zou,Xinwang Liu,Ruizhen Hu,Kai Xu", "background": "在实体人工智能领域，预测性操纵由于其通过利用预测状态来提高机器人策略性能的潜力，获得了越来越多的关注。然而，从世界模型生成准确的未来视觉状态，尤其是在实现高质量像素级表示方面，依然是一个显著的挑战。", "innovation": "我们提出了LaDi-WM，这是一种使用扩散模型预测未来状态的潜在空间的世界模型。LaDi-WM 利用了与预训练视觉基础模型（包括几何特征和语义特征）对齐的潜在空间。实验结果表明，预测潜在空间的演变比直接预测像素级图像更容易学习且更具泛化能力。在此基础上，设计了一种迭代细化输出动作的扩散策略，进而生成更一致且准确的结果。在合成和真实世界基准上的广泛实验表明，LaDi-WM 在 LIBERO-LONG 基准上的策略性能提高了 27.9%，在真实世界场景中提高了 20%。", "conclusion": "我们的研究证明，基于潜在扩散的世界模型可以显著提升实体人工智能中的预测性操作性能，并在真实世界中表现出色的泛化能力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21706", "html_url": "https://arxiv.org/abs/2504.21706", "title": "Vision Transformers在精准农业中的全面综述", "title_en": "Vision Transformers in Precision Agriculture: A Comprehensive Survey", "authors": "Saber Mehdipour,Seyed Abolghasem Mirroshandel,Seyed Amirhossein Tabatabaei", "background": "检测植物疾病是现代农业中的一个关键方面，对维持作物健康和增加整体产量起着重要作用。传统的检测方法，虽然仍然很有价值，但通常依赖于手动检查或传统的机器学习技术，这两种方法在可扩展性和准确性方面都存在局限性。最近，Vision Transformers (ViTs)作为一种有前途的替代方案出现了，它们在处理长距离依赖关系和视觉任务的可扩展性方面具有优势。", "innovation": "本文综述了ViTs在精准农业中的应用，涵盖了一系列任务。引入了ViTs的基本架构及其从自然语言处理（NLP）到计算机视觉的转变，探讨了传统模型如卷积神经网络（CNNs）的归纳偏见，并讨论了ViTs如何解决这些问题。对最近的研究进行了全面回顾，重点关注关键方法、数据集和性能指标。还进行了CNNs和ViTs的比较分析，以及混合模型和性能增强的回顾。并讨论了技术挑战，如数据需求、计算需求和模型解释性，以及潜在的解决方案。", "conclusion": "本文以提出ViTs如何有望变革智能和精准农业为目标，为从业者和研究人员提供了一个深入了解ViTs如何改变精准农业的机会。概述了未来研究方向和技术进步，这些进步可以进一步支持将ViTs集成到实际农业环境中的工作。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.08512", "html_url": "https://arxiv.org/abs/2502.08512", "title": "测量合成数据集的多样性", "title_en": "Measuring Diversity in Synthetic Datasets", "authors": "Yuchang Zhu,Huizhe Zhang,Bingzhe Wu,Jintang Li,Zibin Zheng,Peilin Zhao,Liang Chen,Yatao Bian", "background": "大型语言模型（LLMs）被广泛用于生成用于各种自然语言处理（NLP）任务的合成数据集，如文本分类和总结。然而，准确测量这些合成数据集的多样性——这对于模型的稳健性能至关重要——仍然是一个巨大的挑战。", "innovation": "引入了一种新的方法DCScore，从分类的角度测量合成数据集的多样性。DCScore将多样性评估形式化为一个样本分类任务，利用样本之间的相互关系。并且通过理论验证了DCScore满足的多样性相关公理，强调其作为首要的多样性评估方法的角色。", "conclusion": "在合成数据集上的实验结果显示，DCScore与多个评估数据集的多样性伪真相具有更强的相关性，这一点证明了它的有效性。同时，实证和理论证据表明，DCScore在计算成本上远低于现有方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15485", "html_url": "https://arxiv.org/abs/2504.15485", "title": "CAPTURe：通过隐藏对象计数评估视觉语言模型的空间推理", "title_en": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting", "authors": "Atin Pothiraj,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal", "background": "理解视景中被遮挡（部分或完全隐藏）的物体对理解视觉场景至关重要，因为遮挡在现实世界环境中经常发生，并且是空间理解的障碍。为了测试模型处理多个被遮挡物体的能力，作者引入了一个新颖任务CAPTURe，要求模型通过推测遮挡后图案的延续来计数排列在图案中的物体。CAPTURe任务既需要识别视觉模式，又需要推理，因此成为一个评估视觉语言模型（VLMs）是否理解被遮挡模式及其具备空间理解能力的良好试验床。CAPTURe包括两个部分：(1) CAPTURe-real，包含手动筛选的真实对象图像；(2) CAPTURe-synthetic，一种可控的诊断测试，使用生成的图案图像。通过要求模型推理关于被遮挡的物体，CAPTURe还测试了VLMs构建世界模型的能力，以便填充缺失信息。", "innovation": "作者提出了CAPTURe，这是第一次开发一个专门针对评估Vision-Language Models（VLMs）在解决被遮挡图案计数问题上的空间推理能力的任务。它包括两个部分：CAPTURe-real通过实际图像进行评估，CAPTURe-synthetic则通过生成的图像进行更严谨的诊断测试。", "conclusion": "评估结果显示，即使是较强的VLMs，如GPT-4o，在面对被遮挡图案时也难以计数，这表明VLMs在推断看不见的空间关系方面存在不足。相比之下，人类在CAPTURe上的错误率极低。此外，提供被遮挡物体位置的辅助信息可以提高模型表现，这表明模型的错误来自于无法处理遮挡和在图像中进行计数的困难。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13109", "html_url": "https://arxiv.org/abs/2505.13109", "title": "FreeKV：提升KV缓存检索以实现高效大语言模型推理", "title_en": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference", "authors": "Guangda Liu,Chengwei Li,Zhenyu Ning,Minyi Guo,Jieru Zhao", "background": "大语言模型（LLMs）的部署随着上下文窗口的迅速扩大，以支持越来越复杂的应用。然而，长上下文给部署带来了显著的挑战，主要问题在于键值（KV）缓存的大小随着上下文长度增长而放大。虽然已经提出了KV缓存压缩方法来解决这个问题，但丢弃方法会导致显著的准确率损失，而检索方法则面临效率瓶颈。", "innovation": "我们提出了FreeKV框架，一个算法-系统协同优化方案，旨在提高KV检索效率同时保持准确性。算法层面，FreeKV引入了预推测检索，将KV选择和召回过程移出关键路径，并结合精细校正以确保准确性。系统层面，FreeKV通过CPU和GPU内存组合使用KV布局来消除碎片化数据传输，并利用双缓冲流式检索来进一步提高效率。", "conclusion": "实验表明，FreeKV在各种场景和模型中实现了接近无损的准确率，相比当前最优KV检索方法，速度提升高达13倍。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15002", "html_url": "https://arxiv.org/abs/2505.15002", "title": "解构迭代CHAD", "title_en": "Unraveling the iterative CHAD", "authors": "Fernando Lucatelli Nunes,Gordon Plotkin,Matthijs Vákár", "background": "Combinatory Homomorphic Automatic Differentiation (CHAD)最初作为一种语义驱动的源到源转换，用于全功能程序的反向模式自动微分。虽然有效，但CHAD在处理非终止操作、数据依赖条件和迭代结构时遇到了挑战。", "innovation": "本文扩展了CHAD的范畴，使其能够处理包含这些结构性操作的程序。核心创新在于引入了迭代广指数范畴，这是一种原则上将迭代整合进依赖型编程语言的方法。通过将基础范畴中的迭代提升到参数化初始代数在广指数范畴中的形式，形成了一个可逆纤维迭代结构，该结构可以建模while循环等迭代结构。", "conclusion": "通过迭代广指数范畴的概念，CHAD转换被扩展到循环程序，以结构守恒的唯一自然变换形式进行。具体而言，这是从源语言对应的可迭代Freyd范畴到由目标语言生成的容器范畴的唯一迭代Freyd范畴同态，使得每个原始操作都被映射到其（转置）导数。通过语义范畴模型的泛性质，证明了这个扩展转换的正确性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10236", "html_url": "https://arxiv.org/abs/2506.10236", "title": "在攻击揭示中学习方法中表面上的知识删除", "title_en": "Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods", "authors": "Yeonwoo Jang,Shariqah Hossain,Ashwin Sreevatsa,Diogo Cruz", "background": "这篇论文背景在于当前的机器学习去学习（unlearning）方法可能在面对简单的提示攻击时失效。研究者们需要评估现有方法在去除特定知识方面的有效性，并探索更可靠的评估框架，以区分真正的知识删除和表面的输出抑制。", "innovation": "该论文提出了一种系统性的方法来评估八种不同去学习技术的有效性，使用基于输出、基于logit的分析和探针分析来检测去学习后知识的残留情况。它们发现某些去学习方法如RMU和TAR表现出色，但ELM则在特定提示攻击下显得脆弱。此外，研究揭示了去学习模型通常不会通过改变答案格式来隐藏知识，因为输出和logit准确性之间存在强相关性。", "conclusion": "研究结果挑战了传统对去学习效果的认识，强调了需要一种可靠的评价框架，能区分真实的知识删除和表面的输出抑制。为了促进进一步的研究，他们公开分享了其评估框架，以方便评估提示技术来检索未去学习的知识。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01701", "html_url": "https://arxiv.org/abs/2506.01701", "title": "信息最大化驱动的数据精简", "title_en": "Data Pruning by Information Maximization", "authors": "Haoru Tan,Sitong Wu,Wei Huang,Shizhen Zhao,Xiaojuan Qi", "background": "论文背景在于现有的数据精简方法普遍存在冗余信息过多、样本选择缺乏有效指导的问题。研究者们致力于开发新的方法来优化数据集，既要保留关键信息又要减少冗余，从而提高模型的训练效率和效果。", "innovation": "革新之处在于，Intomax 提出了一种新的数据精简方法，名为信息最大化(coreset选择)。这种方法通过最大化样本的信息内容并最小化冗余，增强了数据集的总体信息度。信息度通过重要性评分（衡量样本在模型学习中的影响或难度）和样本对之间的相似度来衡量。InfoMax 将核心样本选择问题定义为一个离散的二次规划问题（DQP），通过优化总的信息内容（样本贡献总和减去核心样本内的相似样本冗余），实现高效大规模数据集的精简。", "conclusion": "经过广泛的实验，InfoMax 在多种数据精简任务中表现出色，包括图像分类、视觉语言预训练和大型语言模型指令调优。InfoMax 提供了高效的梯度求解器，并结合稀疏化技术，使得该方法能够无缝扩展到数百万样本的数据集。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11170", "html_url": "https://arxiv.org/abs/2506.11170", "title": "PromptTSS：基于提示的交互式多粒度时间序列分割方法", "title_en": "PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation", "authors": "Ching Chang,Ming-Chih Lo,Wen-Chih Peng,Tien-Fu Chen", "background": "多变量时间序列数据在不同领域如制造和可穿戴技术中被广泛收集，这些数据在不同的粒度级别上展示不同的状态，从粗粒度系统行为到细粒度详细事件。有效地在这些不同的粒度级别上进行分割和整合状态对于预测维护和性能优化等任务至关重要。然而，现有的时间序列分割方法面临两个主要挑战：（1）无法在同一模型中处理多种粒度级别，（2）在动态环境中难以适应新兴的模式。", "innovation": "提出了PromptTSS，这是一种新颖的时间序列分割框架，支持多粒度状态。该框架采用了一个统一的模型，并引入了提示机制，利用标签和边界信息来指导分割，能够捕捉粗粒度和细粒度的模式，并动态适应未知模式。", "conclusion": "实验结果表明，PromptTSS 在多粒度分割中的精度提高了 24.49%，在单一粒度分割中的精度提高了 17.88%，在迁移学习中的精度提高了高达 599.24%，展示了其在分层状态和进化时间序列动态中的适应性。代码已公开，在此链接：this https URL."}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11049", "html_url": "https://arxiv.org/abs/2506.11049", "title": "15,500秒：使用EfficientNet和轻量化微调实现高效的无人机分类", "title_en": "15,500 Seconds: Lean UAV Classification Using EfficientNet and Lightweight Fine-Tuning", "authors": "Andrew P. Berg,Qian Zhang,Mia Y. Wang", "background": "随着无人机（UAV）在消费和军事应用中越来越普及，特定模态的数据分类系统需求变得越来越迫切。本文探讨了在无人机音频分类中由于数据稀缺所带来的挑战，通过结合预训练深度学习模型、参数高效微调（PEFT）策略和目标数据增强技术来解决数据稀缺问题。", "innovation": "本文通过使用EfficientNet-B0模型的全微调（结合三种数据增强）实现了最高的验证准确率95.95%，超越了定制的卷积神经网络（CNN）和基于变压器的模型（如AST）。结果表明，结合轻量级架构、PEFT技术和适当的选择增强方法，为有限数据集的UAV音频分类提供了有效策略。", "conclusion": "实验结果表明，结合EfficientNet、轻量化微调技术和针对性的数据增强方法，可以有效提高UAV音频分类的性能。未来的工作将扩展这一框架到多模态UAV分类，利用视觉和雷达数据。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.16332", "html_url": "https://arxiv.org/abs/2505.16332", "title": "量子优化准备好了吗？基于绝热量子计算的神经网络压缩 efforts", "title_en": "Is Quantum Optimization Ready? An Effort Towards Neural Network Compression using Adiabatic Quantum Computing", "authors": "Zhehui Wang,Benjamin Chen Ming Choong,Tian Huang,Daniel Gerlinghoff,Rick Siow Mong Goh,Cheng Liu,Tao Luo", "background": "量子优化是目前最先进的量子计算技术之一，能够有效解决复杂组合问题。近年来，利用绝地量子计算(AQC)技术解决从不同领域的重要优化问题变得越来越普遍。在深度学习领域，随着开发出新的预测功能，深度神经网络(DNN)模型变得越来越大，规模也在扩大，优化大模型对于可持续部署至关重要，但随着模型规模和复杂性的增加，也越来越具有挑战性。尽管量子优化适合解决复杂问题，但将其应用于DNN优化并不直接，需要彻底重新设计使其兼容商用的量子设备。本文旨在探讨使用绝地量子计算(AQC)进行卷积神经网络（CNN）的细粒度剪枝-量化潜力。", "innovation": "本文创新之处在于重新开发了AQC以解决DNN压缩的问题。作者将现有的启发式方法重新设计为二次无约束二进制优化（QUBO）问题，并评估了商用量子退火设备提供的解决方案空间。结果显示，AQC不仅在时间效率上超越了经典的遗传算法和强化学习算法，同时也能更有效地找到全局最优解，从而实现了对实际DNN模型的有效压缩。", "conclusion": "AQC在DNN压缩中的应用是一个有前景的研究方向，它具备超越传统算法的优势。虽然目前还存在一些技术挑战，但研究结果表明，通过适当的优化方法，AQC可以显著提高模型的压缩效率和效果，为未来的深度学习模型部署提供了新的可能。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13307", "html_url": "https://arxiv.org/abs/2506.13307", "title": "预训练潜在扩散模型在生成 unseen SAR 图像中的微调技术定量比较", "title_en": "Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Images", "authors": "Solène Debuysère,Nicolas Trouvé,Nathan Letheule,Olivier Lévêque,Elise Colin", "background": "本文提出了一个框架，用于将大型预训练潜在扩散模型适应高分辨率合成孔径雷达（SAR）图像生成。该方法允许可控合成和创建训练集外的罕见或分布外场景。与从头开始训练特定任务的小模型不同，本文使用开放源代码的文字到图像基础模型对SAR模态进行适应，并利用其语义先验来对齐提示与SAR成像物理（侧视几何、斜距投影和具有重尾统计特性的相干斑），实现SAR成像物理的匹配。", "innovation": "本文采用了一种新的适应策略，即全UNet微调与参数高效低秩适应（LoRA）对文本编码器的组合，以及学习到的标记嵌入，成功保持了SAR几何和纹理的一致性，同时保持了提示的一致性。本文还支持基于文本的控制和多模态条件（例如，分割图、TerraSAR-X或光学向导），为地球观测中的大规模SAR场景数据扩展和未知场景仿真开辟了新的路径。", "conclusion": "通过对一个包含10万张SAR图像的数据集进行全微调和参数有效低秩适应评估，研究结果表明，这种混合策略能够最好地保持SAR几何结构和纹理，并保持提示的一致性。同时，该框架支持基于文本的控制和多模态条件，为大规模SAR场景数据扩增和未知场景模拟提供了新的解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "为什么开源大语言模型在数据分析中遇到困难？一项系统性的实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "开源大语言模型（LLMs）在自动化数据分析任务方面展现出潜力，但这些模型在需要大量推理的场景中面临显著限制。", "innovation": "本文通过策划一个多样化的种子数据集来研究增强开源LLMs数据分析能力的策略。评估模型在数据理解、代码生成和战略规划三个核心维度上的表现，并利用所得洞察开发了一种数据合成方法，显著提升了开源LLMs的分析推理能力。", "conclusion": "战略规划质量是模型性能的主要决定因素；交互设计和任务复杂性显著影响推理能力；数据质量比多样性对实现最佳性能影响更大。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18889", "html_url": "https://arxiv.org/abs/2505.18889", "title": "大型语言模型的安全问题：一项综述", "title_en": "Security Concerns for Large Language Models: A Survey", "authors": "Miles Q. Li,Benjamin C. M. Fung", "background": "大型语言模型（LLMs）如ChatGPT及其竞争对手在自然语言处理领域引起了一场革命，但这些模型的能力也带来了新的安全漏洞。本文提供了一个全面的视角，概述了这些新兴的担忧，将其威胁分为多个关键领域：提示注入和越狱；对抗性攻击，包括输入扰动和数据污染；恶意行为者利用这些模型生成虚假信息、钓鱼邮件和恶意软件；以及自主LLM代理固有的令人担忧的风险。最近，对自主LLM代理的担忧越来越多，研究了目标不一致、涌现欺骗、自我保护本能以及LLMs可能通过所谓的诡计追求隐蔽、不一致的目标的可能性，即使是在安全性训练后也可能持续存在。", "innovation": "本文总结了2022年至2025年间的研究，涵盖了每种威胁的具体示例，分析了提议的防御措施及其局限性，并指出了LLM基应用程序安全性中的开放挑战。重点探讨了目标不一致、涌现欺骗、自我保护本能以及自主LLM代理可能追求隐蔽且不一致目标的现象，即所谓的诡计，即使是在安全性训练后仍然可能出现。提出现代化、多层次的安全策略，以确保LLMs的安全和益处的重要性。", "conclusion": "本文强调了需要推进稳健的多层次安全策略，以确保LLMs的安全和有益。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.20469", "html_url": "https://arxiv.org/abs/2505.20469", "title": "CCL-LGS: 对比式代码本学习在3D语言高斯点绘制中的应用", "title_en": "CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting", "authors": "Lei Tian,Xiaomin Li,Liqian Ma,Hao Yin,Zirui Zheng,Hefei Huang,Taiqing Li,Huchuan Lu,Xu Jia", "background": "近年来，3D重建技术和视觉-语言模型的发展显著推动了3D语义理解的进步，这一能力对于机器人技术、自主驾驶和虚拟/增强现实至关重要。然而，依赖于2D先验的方法容易受到透视、图像模糊和视点依赖性变化导致的跨视角语义不一致性的影响。这些不一致性通过投影监督传播时会恶化3D高斯语义场的质量并在渲染输出中引入伪影。为了克服这一局限，我们提出了CCL-LGS框架，该框架通过集成多视角语义线索强制实施视图一致的语义监督。具体来说，我们的方法首先使用零样本跟踪器来对一组SAM生成的2D掩码进行对齐，并可靠地识别它们对应的类别。然后利用CLIP提取跨视角的鲁棒语义编码。最后，我们的对比代码本学习（CCL）模块通过增强类内紧凑性和类间区分性提取区分性语义特征。", "innovation": "我们的方法首先使用零样本跟踪器对2D掩码进行对齐和类别识别；然后利用CLIP提取鲁棒的多视角语义编码；最后通过对比代码本学习模块强制实施跨类别的语义一致性，而不是像以往方法那样直接对不完美的掩码应用CLIP，从而明确解决语义冲突并保持类别区分性。实验证明CCL-LGS在各方面都优于以前最先进的方法。", "conclusion": "本文提出了一种名为CCL-LGS的新颖框架，该框架通过相互连贯的多视角语义线索强制实施视图一致的监督学习。实验结果表明，CCL-LGS在3D语义理解方面显著优于之前的最佳方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19343", "html_url": "https://arxiv.org/abs/2506.19343", "title": "Discrepancy-Aware Graph Mask Auto-Encoder", "title_en": "Discrepancy-Aware Graph Mask Auto-Encoder", "authors": "Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu", "background": "Masked Graph Auto-Encoder，作为强大的图自监督训练范式，已在图表示学习中表现出色。现有工作通常依赖节点上下文信息来恢复蒙版信息，但在处理连接节点可能不相似的异质图时效果不佳。这是因为现有方法只关注邻域信息而忽视了不同节点之间的差异信息，导致节点表示相似度提高不足，结果无明显区分度。", "innovation": "本文提出了一种新的模型Discrepancy-Aware Graph Mask Auto-Encoder（DGMAE），通过在蒙版过程中重建邻居节点的差异信息，获得更具区别的节点表示。实验结果表明该模型在保持低维空间中的节点差异方面表现优异，并在节点分类、节点聚类和图分类三项图分析任务上显著优于现有的图自监督学习方法，证明其显著优势。", "conclusion": "DGMAE 模型通过重建差异信息来提高节点表示的可区分性，并在多个基准数据集上展现了优异的性能，特别是在节点分类、节点聚类和图分类任务上超越了现有先进方法，证明了其在处理异质图的优势。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18248", "html_url": "https://arxiv.org/abs/2506.18248", "title": "语义结构感知的生成攻击以增强对抗传输性", "title_en": "Semantic Structure-Aware Generative Attacks for Enhanced Adversarial Transferability", "authors": "Jongoh Jeong,Hunmin Yang,Jaeseok Jeong,Kuk-Jin Yoon", "background": "生成对抗攻击通过在白盒代理模型上训练一个扰动生成器，然后将精心制作的扰动应用到未见过的黑盒受害模型上。与迭代攻击相比，这些方法在推断时具有更好的效率、可扩展性和可移植性。然而，现有研究尚未充分利用生成模型的表征能力来保存和利用语义信息。生成器的中间激活编码丰富的语义特征（如物体边界和粗略形状），这些特征仍被广泛忽视，限制了扰动与物体显著区域的对齐，这些区域对于对抗传递性至关重要。为了解决这个问题，该研究引入了一种基于Mean Teacher的语义结构感知攻击框架，它作为时间平滑的特征参考，通过特征蒸馏进一步引导学生早期层激活与语义丰富的教师的语义一致性。", "innovation": "该研究提出了一种基于Mean Teacher的语义结构感知攻击框架。通过引入一个时间平滑的特征参考，它进一步引导学生早期层激活与语义丰富的教师的语义一致性。通过根据经验发现将扰动合成锚定到生成器中语义显著的早期中间块，该方法指导逐进的对抗扰动，从而显著增强对抗传递性。研究通过广泛的实验，展示了与现有最佳生成攻击方法相比的一致改进，并使用传统指标和新的意外修正率（ACR）进行了全面评估。", "conclusion": "通过语义结构感知攻击框架，该研究有效提高了对抗扰动传输性，并在多种模型、领域和任务上展示了超越现有最佳方法的一致改进。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08162", "html_url": "https://arxiv.org/abs/2507.08162", "title": "AmpLyze: 一种用于预测溶血浓度的深度学习模型", "title_en": "AmpLyze: A Deep Learning Model for Predicting the Hemolytic Concentration", "authors": "Peng Qiu,Hanqi Feng,Meng-Chun Zhang,Barnabas Poczos", "background": "红细胞溶解（HC50）是抗菌肽（AMP）治疗药物的主要安全性屏障，但现有的模型只能简单地标记为“有毒”或“无毒”。AmpLyze通过仅从序列预测实际的HC50值并解释驱动毒性的残基，填补了这一空白。模型将残基级别ProtT5/ESM2嵌入与序列级别的描述符结合在局部和全局分支中，并通过一个交叉注意力模块对齐。采用对实验噪音具有鲁棒性的对数正态损失进行训练。", "innovation": "AmpLyze开发了一个结合残基级别嵌入和序列级别描述符的深度学习模型，通过交叉注意力模块对齐，并采用对数正弦余弦损失进行训练。该模型在预测HC50值方面表现出色，优于经典回归器和最先进的模型。去除任何分支都会降低性能，交叉注意力还分别提高了1%的PCC和3%的MSE。结果揭示了已知的毒性热点，并提出了更安全的替代方案。", "conclusion": "通过将溶血评估转化为定量、基于序列和可解释的预测，AmpLyze促进了AMP的设计，并提供了一种早期毒性筛查的实际工具。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01006", "html_url": "https://arxiv.org/abs/2507.01006", "title": "GLM-4.1V-Thinking和GLM-4.5V：通过可扩展强化学习实现多功能多模态推理", "title_en": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": "GLM-V Team:Wenyi Hong,Wenmeng Yu,Xiaotao Gu,Guo Wang,Guobing Gan,Haomiao Tang,Jiale Cheng,Ji Qi,Junhui Ji,Lihang Pan,Shuaiqi Duan,Weihan Wang,Yan Wang,Yean Cheng,Zehai He,Zhe Su,Zhen Yang,Ziyang Pan,Aohan Zeng,Baoxu Wang,Bin Chen,Boyan Shi,Changyu Pang,Chenhui Zhang,Da Yin,Fan Yang,Guoqing Chen,Jiazheng Xu,Jiale Zhu,Jiali Chen,Jing Chen,Jinhao Chen,Jinghao Lin,Jinjiang Wang,Junjie Chen,Leqi Lei,Letian Gong,Leyi Pan,Mingdao Liu,Mingde Xu,Mingzhi Zhang,Qinkai Zheng,Sheng Yang,Shi Zhong,Shiyu Huang,Shuyuan Zhao,Siyan Xue,Shangqin Tu,Shengbiao Meng,Tianshu Zhang,Tianwei Luo,Tianxiang Hao,Tianyu Tong,Wenkai Li,Wei Jia,Xiao Liu,Xiaohan Zhang,Xin Lyu,Xinyue Fan,Xuancheng Huang,Yanling Wang,Yadong Xue,Yanfeng Wang,Yanzi Wang,Yifan An,Yifan Du,Yiming Shi,Yiheng Huang,Yilin Niu,Yuan Wang,Yuanchang Yue,Yuchen Li,Yutao Zhang,Yuting Wang,Yu Wang,Yuxuan Zhang,Zhao Xue,Zhenyu Hou,Zhengxiao Du,Zihan Wang,Peng Zhang,Debing Liu,Bin Xu,Juanzi Li,Minlie Huang,Yuxiao Dong,Jie Tang", "background": "该研究提出了GLM-4.1V-Thinking和GLM-4.5V，这是一种旨在推进通用多模态理解和推理的视觉语言模型（VLMs）族。通过大规模预训练开发了一个具有显著潜力的视觉基础模型，并提出了强化学习与课程采样（RLCS）框架，以全面增强模型在多种任务上的能力。", "innovation": "创新之处在于开发了一种能够通过大规模预训练建立上限的多功能视觉基础模型，以及提出了一种新的强化学习与课程采样（RLCS）训练框架，该框架全面增强了模型在包括STEM问题解决、视频理解、内容识别、编程、接地、基于GUI的代理和长文档解释等多种任务上的能力。GLM-4.5V在42个公开基准测试中的大部分任务上达到了开源模型中的最佳性能，甚至在挑战性的任务如编程和基于GUI的代理上超越了封闭源代码模型Gemini-2.5-Flash。GLM-4.1V-9B-Thinking在许多基准测试中也表现出色，优于大型模型Qwen2.5-VL-72B。", "conclusion": "GLM-4.1V-Thinking和GLM-4.5V均已被开源，相关代码和模型可在指定链接中获取，同时展示了在多个视觉语言任务上与大型模型相当甚至超越的表现。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10778", "html_url": "https://arxiv.org/abs/2507.10778", "title": "基于LLM代理的仓库空间问答", "title_en": "Warehouse Spatial Question Answering with LLM Agent", "authors": "Hsiang-Wei Huang,Jen-Hao Cheng,Kuang-Ming Chen,Cheng-Yen Yang,Bahaa Alattar,Yi-Ru Lin,Pyongkun Kim,Sangwon Kim,Kwangju Kim,Chung-I Huang,Jenq-Neng Hwang", "background": "现有的多模态大规模语言模型（MLLMs）在空间理解方面一直面临挑战。前人方法主要通过大规模MLLM微调来提升空间理解能力。然而，这种方法消耗资源较多，不够高效。", "innovation": "本文提出了一种高效的数据利用方法，通过构建一个具有强大空间推理能力的LLM代理系统，能够在复杂仓库内部空间问答任务中执行对象检索、计数和距离估计等任务，并有效地与API工具进行交互以解答复杂的空间问题。", "conclusion": "通过在2025 AI City Challenge Physical AI Spatial Intelligence Warehouse数据集上的广泛评估，该系统显示出高准确性和效率，证明了系统的可行性和有效性。研究团队已经将代码发布在指定的URL地址。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.14189", "html_url": "https://arxiv.org/abs/2507.14189", "title": "DeepWriter：基于离线知识库的事实依据多模态写作助手", "title_en": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base", "authors": "Song Mao,Lejun Cheng,Pinlong Cai,Guohang Yan,Ding Wang,Botian Shi", "background": "大型语言模型（LLMs）在各种应用中展示出了非凡的能力，但在金融、医学和法律等专业领域的写作助手使用中，其应用受限于缺乏专门领域知识和容易出现虚构的情况。现有的解决方案，如检索增强生成（RAG），在多个检索步骤中可能会出现不一致，而基于在线搜索的方法由于网络内容不可靠而常常导致质量下降。这些因素阻碍了LLMs在这些专业领域中的应用效果。", "innovation": "本文提出了一种名为DeepWriter的可定制化的多模态长文写作助手，它基于一个精心打造的离线知识库进行操作。通过创新的流程，包括任务分解、大纲生成、多模态检索以及模块化合成和反思，来深度挖掘结构化语料中的信息，结合文本和视觉元素，生成连贯、事实依据充分、专业级别的文档。此外，DeepWriter还提出了一个层次化的知识表示方式以提升检索效率和准确性。实验证明，DeepWriter在金融报告生成中能够生成高质量且具有可验证性的文章，超越了现有基线在事实准确性和生成内容质量方面。", "conclusion": "DeepWriter能够根据离线知识库生成高质量、事实依据充分的、专业级别的文档，有效解决了传统语言模型在专业领域应用中的问题。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.03682", "html_url": "https://arxiv.org/abs/2508.03682", "title": "自我问答语言模型", "title_en": "Self-Questioning Language Models", "authors": "Lili Chen,Mihir Prabhudesai,Katerina Fragkiadaki,Hao Liu,Deepak Pathak", "background": "本文通过探讨大型语言模型在没有外部数据的情况下能否自我改进，提出了一个假设，即预训练的语言模型通过仅给定一个主题提示（例如代数词题）并要求模型自动生成问题和答案来改善其推理能力。研究表明，通过一种不对称的自我对抗框架，语言模型能够自我提问和求解问题，从而提高其在下游基准任务上的表现，而无需访问任何经过精心挑选的训练数据集。", "innovation": "提出了Self-Questioning Language Models（自问语言模型，SQLM）这一不对称自我对抗框架。在这种框架中，提出者（proposer）根据给定的主题生成问题，而解答者（solver）则尝试解答。两者都通过强化学习进行训练。提出者根据问题难度获得奖励，而解答者通过多数投票的方式获得奖励。对于编程任务，提出者可以生成单元测试用于验证。该框架在三个基准上进行了实验：三位数乘法、来自OMEGA基准的代数问题和Codeforces编程问题。", "conclusion": "通过持续生成更具挑战性的问题并尝试解决这些问题，语言模型能够在没有使用任何经过精心挑选的训练数据集的情况下，在下游基准测试中取得改进。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.19712", "html_url": "https://arxiv.org/abs/2507.19712", "title": "Oranits: 在基于Open RAN的智能运输系统(ITS)中使用元启发式算法和深度强化学习进行任务分配和任务卸载", "title_en": "Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning", "authors": "Ngoc Hung Nguyen,Nguyen Van Thieu,Quang-Trung Luu,Anh Tuan Nguyen,Senura Wanasekara,Nguyen Cong Luong,Fatemeh Kavehmadavani,Van-Dinh Nguyen", "background": "现有研究往往忽视了任务之间的复杂依赖关系以及将任务卸载到边缘服务器的成本，导致决策不够优化。", "innovation": "本文提出了一种称为Oranits的新系统模型，该模型明确考虑了任务依赖性和卸载成本，并通过车辆合作优化性能。为了实现这一目标，提出了一种两步优化方法。首先，开发了一种基于混沌高斯的全球ARO元启发式计算算法(CGG-ARO)作为单一插槽优化的基线。其次，设计了一种基于增强奖励的多智能体双重DQN机制(MA-DDQN)，该机制结合了多智能体协调和多行动选择机制，显著减少了任务分配时间并提高了适应性。不同的优化方法在任务完成次数和总体效益方面的表现也得到了验证。", "conclusion": "CGG-ARO在任务完成次数和总体效益上分别提高了约7.1%和7.7%。同时，MA-DDQN在任务完成次数方面提高了11.0%，在总体效益上提高了12.5%，这些结果突显了Oranits在动态ITS环境中实现更快、更适应和更高效的任务处理的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04586", "html_url": "https://arxiv.org/abs/2508.04586", "title": "当前AI会议模式不可持续！解析集中式AI会议危机", "title_en": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference", "authors": "Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He", "background": "AI会议对于推动研究、分享知识和促进学术社区具有重要意义，但其快速扩张使得集中式会议模式日益变得不可持续。文章通过数据分析揭示了对科学传播、公正性和社区福祉构成结构上的危机。论文指出了四个关键方面的压力：(1) 科学层面，作者人均发表率在过去十年中翻了一番，超过每年4.5篇；(2) 环境层面，单个会议的碳足迹超过了举办城市的日常排放量；(3) 心理层面，71%的在线社区讨论反映了负面情绪，且35%提及心理健康问题；(4) 物流层面，顶级会议如NeurIPS 2024的参会人数开始超过场馆容量。这些压力表明系统与其核心使命不匹配。", "innovation": "本文提出了Community-Federated Conference (CFC)模型，该模型将同行评议、展示和社交活动分离，实现了全球协调但本地组织的方式。该模型旨在提供一种更可持续、更具包容性和弹性的AI研究道路。", "conclusion": "现有的AI会议模式面临结构上的危机，文章提出CFC模型作为一种更可持续、更具包容性和弹性的解决方案，以应对系统与核心使命不匹配的问题，确保AI研究的长远发展。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.05612", "html_url": "https://arxiv.org/abs/2508.05612", "title": "Shuffle-R1: 数据为中心的动态混排以提高多模态大型语言模型的高效RL框架", "title_en": "Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle", "authors": "Linghao Zhu,Yiran Guan,Dingkang Liang,Jianzhong Ju,Zhenbo Luo,Bin Qin,Jian Luan,Yuliang Liu,Xiang Bai", "background": "循环强化学习(RL)作为一种后训练范式，在提升多模态大型语言模型(MLLM)的推理能力方面表现出有效性。然而，当前的RL流程经常受到训练效率低下问题的影响，这些问题主要是由于两种未被充分探讨的问题导致的：优势塌陷(Advantage Collapsing)，即批次中的大部分优势值集中在零附近；以及执行路径静默(Rollout Silencing)，即随着时间的推移，未贡献非零梯度的执行路径的比例降低。这些问题导致了次优的梯度更新，阻碍了长期的学习效率。", "innovation": "为了应对这些挑战，作者提出了Shuffle-R1，这是一种简单而有原则的方法，通过动态重构轨迹采样和批次组合来提高RL微调效率。Shuffle-R1引入了两项创新：(1) 对抗轨迹采样(Pairwise Trajectory Sampling)，它选择高对比度的具有大优势值的轨迹以提高梯度信号质量；(2) 基于优势的轨迹混排(Advantage-based Trajectory Shuffle)，它通过经过信息的批次重新排序来增加有价值执行路径的曝光度。", "conclusion": "实验结果显示，该框架在多个推理基准测试中持续优于强大的RL基线，且几乎没有额外的开销。这些结果突出了数据为中心的调整对于提高MLLM中RL训练效率的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10904", "html_url": "https://arxiv.org/abs/2507.10904", "title": "难度可分数据的类比例聚核选择", "title_en": "Class-Proportional Coreset Selection for Difficulty-Separable Data", "authors": "Elisa Tsai,Haizhong Zheng,Atul Prakash", "background": "高质量的训练数据对于构建可靠高效的机器学习系统至关重要。现有的单次聚核选择方法通过修剪数据集以维持甚至提升模型性能，通常依赖于基于训练动态的数据难度评分。然而，大多数现有方法假定所有类别内的数据难度是均匀的，忽略了不同类别间数据难度的变化。在网络安全检测和医学影像等领域，数据难度往往按类别聚类。", "innovation": "引入了类别难度分离性(Class-difficulty Separability)的概念，并提出了类别难度分离系数(Class Difficulty Separability Coefficient, CDSC)作为定量度量。基于CDSC，提出了一系列类比例聚核选择策略来处理类别难度分离的数据。在五个涵盖不同领域的数据集上，该方法显著提高了性能，并在极端修剪率下表现出良好的稳定性。此外，展示了激进的数据修剪能够增强在嘈杂、不平衡和大规模数据集上的泛化能力。", "conclusion": "明确建模类别难度分离性可以更有效地进行数据修剪，提高鲁棒性和通用性，尤其在高风险场景下。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22369", "html_url": "https://arxiv.org/abs/2507.22369", "title": "探索视觉问答（VQA）在教室活动监控中的应用", "title_en": "Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring", "authors": "Sinh Trong Vu,Hieu Trung Pham,Dung Manh Nguyen,Hieu Minh Hoang,Nhu Hoang Le,Thu Ha Pham,Tai Tan Mai", "background": "教室行为监控是教育研究的重要方面，对学生的参与度和学习成果有重大影响。近年来，视觉问答（VQA）模型的进步提供了自动分析视频录制中复杂教室互动的方法。本研究评估了几种最新开源VQA模型，包括LLaMA2、LLaMA3、QWEN3和NVILA，在教室行为分析中的适用性。为此，研究团队引入了源自越南银行业学院真实课堂视频录制的BAV-Classroom-VQA数据集，以进行严格的性能评估。研究方法涵盖了数据收集、标注和模型在该数据集上的基准测试。初步实验结果表明，这四个模型在回答与行为相关的视觉问题方面表现出优异的性能，展示出其在未来教室分析和干预系统中的潜力。", "innovation": "1. 介绍了一种基于真实教室视频录制的数据集BAV-Classroom-VQA。2. 评估了几种最新开源VQA模型在教室行为分析中的性能。3. 显示了这些模型在未来教室分析和干预系统中的应用潜力。", "conclusion": "这四项最新开源VQA模型在回答与行为相关的视觉问题方面表现出色，这一结果验证了VQA模型在教室行为分析中的可行性和潜在应用价值。未来研究可以进一步优化这些模型，以提高它们在真实教室环境中的准确性和可靠性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06259", "html_url": "https://arxiv.org/abs/2508.06259", "title": "SIFThinker: 空间意识到图像聚焦用于视觉推理", "title_en": "SIFThinker: Spatially-Aware Image Focus for Visual Reasoning", "authors": "Zhangquan Chen,Ruihui Zhao,Chuwei Luo,Mingze Sun,Xinlei Yu,Yangyang Kang,Ruqi Huang", "background": "当前的多模态大语言模型（MLLMs）在复杂视觉任务（例如空间理解、细粒度感知）上仍面临显著挑战。以往的方法试图引入视觉推理，但未能利用空间提示进行注意力修正以迭代地聚焦于与提示相关的区域。本文聚焦于此问题进行研究。", "innovation": "本文介绍了一种名为SIFThinker的空间意识\"图像思考\"框架，该框架通过深度增强边界框和自然语言的交错使用来实现注意力修正和图像区域聚焦。SIFThinker的关键创新点包括：1）提出了一种反向扩展前向推理策略，生成交错的图像-文本思维链，促进过程级监督，进而构建SIF-50K数据集。2）提出了GRPO-SIF强化训练范式，将深度引导的视觉定位整合到统一的推理管道中，使模型能够动态地修正和聚焦于与提示相关的区域。", "conclusion": "广泛实验表明，SIFThinker在空间理解和细粒度视觉感知方面优于最先进的方法，同时保留了强大的泛化能力，突显了该方法的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06800", "html_url": "https://arxiv.org/abs/2508.06800", "title": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "title_en": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "authors": "Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan", "background": "在多模态情感识别（MER）领域，缺失模态已成为一个重要的研究方向。传统的解决方法主要通过缺失模态重构来处理这一问题，但这些方法没有考虑到不同样本在重构难度上的差异，限制了模型对复杂样本的处理能力。", "innovation": "本文提出了一种新颖的Hardness-Aware Dynamic Curriculum Learning（HARDY-MER）框架，该框架通过两个关键阶段工作：首先估计每个样本的难度级别，然后在训练过程中战略性地强调难度较大的样本，以提高模型在具有挑战性实例上的表现。具体而言，引入了多视角难度评估机制，结合直接难度和间接难度来量化重构难度，并通过基于检索的动态课程学习策略动态调整训练课程，平衡易难样本的学习焦点。实验结果表明，HARDY-MER在缺失模态场景中显著优于现有方法。", "conclusion": "广泛的实验表明，HARDY-MER在缺失模态场景中表现出色，持续优于现有方法。代码将在此链接中公开：this https URL"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07970", "html_url": "https://arxiv.org/abs/2508.07970", "title": "WeChat-YATT：一种简单、可扩展且平衡的RLHF训练器", "title_en": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer", "authors": "Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Tingfeng Xian,Haoqiang Hong,Boqi Chen,Haotao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao", "background": "RLHF（基于人类反馈的强化学习）已成为训练大型语言模型和多模态系统的重要范式。现有的RLHF训练框架虽然取得了显著进展，但仍面临扩展至复杂多模态工作流和适应动态工作负载的挑战。特别是，当前系统在管理大型模型时常常遇到控制器可扩展性限制，并且在需要动态采样和资源分配的精细RLHF管道 orchestration 中存在效率问题。", "innovation": "WeChat-YATT 是一种针对这些挑战设计的简单、可扩展且平衡的RLHF训练框架。它采用了并行控制器编程模型，有效缓解了集中式控制器架构瓶颈，支持大规模数据场景的可扩展性。此外，WeChat-YATT 提出了一种动态放置方案，能够适应性地分配计算资源、调度工作负载，显著减少了硬件空闲时间，提高 GPU 利用率。", "conclusion": "WeChat-YATT 在多种实验场景中显示出相对于最先进的RLHF训练框架的巨大吞吐量提升。它已成功应用于培训支持WeChat产品功能的模型，证明了其在真实世界环境中的有效性和稳定性。WeChat-YATT 已开源。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06445", "html_url": "https://arxiv.org/abs/2508.06445", "title": "自动化回声：新闻制作中LLM使用增加", "title_en": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "authors": "Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee", "background": "研究背景：生成式AI（GenAI），尤其是大型语言模型（LLMs），的迅速崛起引发了对新闻报道诚信和作者身份的关注。本文分析了全球40,000多篇新闻文章中的AI生成内容，涵盖各大媒体、地方媒体和高校媒体各种媒体格式。研究表明，近年来LLM的应用显著增加，尤其是在地方和高校新闻中更为明显。句子层面分析发现，LLM通常用于新闻的开头部分，而结论通常由人工撰写。语言分析显示，尽管GenAI提高了文本的丰富性和可读性，但降低了正式性，导致写作风格更加标准化，特别是在地方媒体中更为突出。", "innovation": "本研究创新性地采用了三种先进的人工智能文本检测器（如Binoculars、Fast-Detect GPT和GPTZero）来检测新闻文章中的AI生成内容，并量化了其增长趋势。通过这些工具，研究者能够准确识别出新闻文章中的AI生成部分，从而揭示AI在新闻领域的实际应用情况及影响。", "conclusion": "结论部分总结了研究发现，即尽管GenAI提升了文本丰富度与可读性，但降低了正式性，导致写作风格的标准化，特别是在地方媒体中这一现象更为明显。随着GenAI技术的进一步发展，新闻业需审视其对新闻真实性与多样性的潜在影响。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.04549", "html_url": "https://arxiv.org/abs/2508.04549", "title": "MSC: 一个关联分割和片段级描述的海洋野生动物视频数据集", "title_en": "MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning", "authors": "Quang-Trung Truong,Yuk-Kwan Wong,Vo Hoang Kim Tuyen Dang,Rinaldi Gotama,Duc Thanh Nguyen,Sai-Kit Yeung", "background": "海洋视频理解面临着显著挑战，由于海中物体的动态性、周围的环境、摄像机运动以及水下场景的复杂性。现有的视频字幕数据集通常关注通用领域或以人类为中心的环境，往往无法适应海洋环境的复杂性，也无法深入了解海洋生物。", "innovation": "提出了一个两阶段的海洋物体导向视频字幕流水线，引入了一个综合的视频理解基准，利用视频、文本和分割掩码的三元组促进视觉定位和字幕生成。此外，强调了视频分割的有效性，以在场景变化中检测显著对象转换，显著增加了描述内容的语义。", "conclusion": "该研究不仅增强了海洋视频的理解和分析，还促进了海洋视频的生成。同时，数据集和代码已发布。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07178", "html_url": "https://arxiv.org/abs/2508.07178", "title": "通过隐式反馈去除虚假兴趣改进个性化标题生成", "title_en": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback", "authors": "Kejin Liu,Junhong Lian,Xiang Ao,Ningtao Wang,Xing Fu,Yu Cheng,Weiqiang Wang,Xinyu Liu", "background": "准确的个性化标题生成依赖于精确捕捉用户的兴趣历史行为。然而，现有方法忽略了整个历史点击流中的个性化无关点击噪声，导致生成的标题可能背离真实的用户偏好。该论文通过在用户和新闻维度上的严格分析，揭示了点击噪声对个性化生成质量的负面影响。", "innovation": "本文提出了一种新颖的个性化标题生成框架PHG-DIF，通过双重过滤去除点击流噪声并利用多层时间融合动态建模用户的演化和多维度兴趣，精准画像。此外，还公开了一个新的基准数据集DT-PENS，包含1000个精心策划的用户的点击行为和近10000个带有历史停留时间注解的个性化标题。广泛的实验表明，PHG-DIF显著减轻了点击噪声的负面影响，大幅提高了标题质量，达到了SOTA结果。", "conclusion": "通过去除点击噪声，PHG-DIF框架显著改善了个性化标题生成的质量，实验结果表明其达到了SOTA水平。该框架和数据集可在给定的链接中找到。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08052", "html_url": "https://arxiv.org/abs/2508.08052", "title": "持续学习中模型容量动态的理解", "title_en": "On Understanding of the Dynamics of Model Capacity in Continual Learning", "authors": "Supriyo Chakraborty,Krishnan Raghavan", "background": "持续学习（CL）中神经网络（NN）的能力代表任务的能力与其稳定性-可塑性权衡构成了一个基本挑战。这项研究探讨了模型容量的有效特性，揭示了随着任务分布的变化，模型容量及其稳定性-可塑性平衡点是非稳定的。即使使用不同的神经网络架构或优化方法，当新任务的数据分布不同于之前的数据时，神经网络代表新任务的能力也会减弱。这项研究通过广泛的实验证明了这一理论发现，涵盖从小型前馈网络、卷积网络到中型图神经网络和具有数百万参数的基于Transformer的大语言模型等多种架构。", "innovation": "引入了持续学习的有效模型容量（CLEMC）来表征稳定性-可塑性平衡点的动态行为，并开发了一种差分方程来建模神经网络、任务数据和优化过程之间的相互作用。实验证明了在任务分布发生变化时，模型容量和稳定性-可塑性平衡点是内在不稳定的，进一步巩固了CLEMC模型的有效性。", "conclusion": "通过CLEMC，证明无论使用何种架构或优化方法，当新任务的数据分布与先前的任务数据不匹配时，神经网络代表新任务的能力会减弱。该研究扩展了对持续学习中模型容量动态特性的理解，强调了任务分布变化对神经网络性能的影响。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08601", "html_url": "https://arxiv.org/abs/2508.08601", "title": "Yan: 基础交互式视频生成", "title_en": "Yan: Foundational Interactive Video Generation", "authors": "Deheng Ye,Fangyun Zhou,Jiacheng Lv,Jianqi Ma,Jun Zhang,Junyan Lv,Junyou Li,Minwen Deng,Mingyu Yang,Qiang Fu,Wei Yang,Wenkai Lv,Yangbin Yu,Yewen Wang,Yonghang Guan,Zhihao Hu,Zhongbin Fang,Zhongqian Sun", "background": "本文介绍了一种名为Yan的基本框架，涵盖了从仿真、生成到编辑的整个交互式视频生成管道。Yan框架包含三个核心模块：高度压缩的低延迟3D-VAE仿真模块、多模态生成模块和分层动作控制编辑模块。", "innovation": "该框架借助高度压缩的低延迟3D-VAE和基于KV缓存的滑动窗口去噪推理过程，实现了实时1080P/60FPS交互式仿真。引入了一种分层自回归字幕方法，将游戏特有知识注入开放域多模态视频扩散模型（VDM），使其成为帧级、动作可控且实时无限的交互式视频生成器。提出了一个混合模型，明确分离了视频生成和视觉渲染处理，通过文本实现多粒度的视频内容编辑。", "conclusion": "Yan将这些模块融入一体，超越了孤立功能的界限，朝着全面的人工智能驱动交互式创作模式前进，为下一代创意工具、媒体和娱乐铺平了道路。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08535", "html_url": "https://arxiv.org/abs/2508.08535", "title": "LLM-驱动的6G就绪无线身体区域网络：综述与框架", "title_en": "LLM-Driven Adaptive 6G-Ready Wireless Body Area Networks: Survey and Framework", "authors": "Mohammad Jalili Torkamani,Negin Mahmoudi,Kiana Kiashemshaki", "background": "无线身体区域网络（WBANs）可实现生理信号的持续监控，适用于慢性病管理、紧急响应等应用。6G通信、后量子加密和能量收集技术的进步有望提升WBANs的性能，但将这些技术整合到统一的自适应系统中仍面临挑战。当前的WBAN设计依赖于启发式方法，存在适应性、能量效率和抗量子安全性的不足。", "innovation": "提出了一种基于大型语言模型的WBAN自适应框架，其中大型语言模型作为认知控制平面，实时协调路由、物理层选择、微能量收集和后量子安全。该框架旨在支持下一代移动健康应用中的超可靠、安全和自我优化的WBANs。", "conclusion": "当前基于启发式的WBAN设计存在局限性，本文为资源受限、6G就绪的医疗系统研究提出了研究议程，旨在开发能支持下一代移动健康应用的超可靠、安全且自我优化的WBANs。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08855", "html_url": "https://arxiv.org/abs/2508.08855", "title": "BiasGym: 如何发现并移除大语言模型中的偏见", "title_en": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them", "authors": "Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein", "background": "了解大型语言模型（LLMs）中嵌入的偏见和刻板印象对于开发有效的缓解策略至关重要。偏见行为往往很隐秘且在故意诱发时难以识别，这使得系统分析和去偏复杂化。为了应对这一挑战，我们提出了BiasGym，一种简单、成本效益高且通用的框架，用于可靠地注入、分析和缓解LLMs中的概念关联。BiasGym包括两个组成部分：BiasInject负责通过基于令牌的微调来注入特定偏见，而BiasScope则利用这些注入的信号来识别和引导导致偏见行为的组件。", "innovation": "BiasGym提供了一种有效的方法来一致地提取偏见并进行机制分析，支持有针对性的去偏而不会降低下游任务的性能，并且可以推广到那些在基于令牌的微调期间未见过的偏见。该方法已被证明对于减少现实世界的刻板印象（例如，来自意大利的人是“危险的司机”）和探索虚构的关联（例如，来自虚构国家的人们“有蓝色的皮肤”）都有效。", "conclusion": "BiasGym不仅能应用于安全干预，同样适用于解释性研究，经实验证明它能够有效地检测并减轻LLMs中的偏见，有助于提高模型的公平性和透明度。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08543", "html_url": "https://arxiv.org/abs/2508.08543", "title": "M3-Net：一种经济高效且无需图结构的多层感知机基预测模型应用于交通预测", "title_en": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction", "authors": "Guangyin Jin,Sicong Lai,Xiaoshuai Hao,Mingtao Zhang,Jinlei Zhang", "background": "准确的交通预测是智能交通系统发展中的一项基本但至关重要的任务。主流的突破性交通预测方法依赖于时空图神经网络和时空注意力机制等技术。现有的基于深度学习的方法主要存在两种局限性：一种依赖完整交通网络结构，另一种则需要复杂的模型设计来捕捉时空依赖关系。这些局限性给大规模数据集上高效地部署和应用深度学习模型带来了挑战。", "innovation": "我们提出了一种经济高效的无需图结构的多层感知机（MLP）模型M3-Net，该模型不仅利用时间序列和时空嵌入有效处理特征，而且还首次引入了一种新型的具有专家混合机制（Mixture of Experts, MoE）的MLP-Mixer架构。实验结果表明，该模型在预测性能和轻量级部署方面表现出优越性。", "conclusion": "大量的实验证明，我们提出的M3-Net模型在交通预测方面表现出色，并且具有经济高效、无需复杂图结构的优势，为大规模交通预测提供了一种有效的解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08285", "html_url": "https://arxiv.org/abs/2508.08285", "title": "幻觉检测中的进步幻象：重新评估L大型语言模型中的幻觉检测", "title_en": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs", "authors": "Denis Janiak,Jakub Binkowski,Albert Sawczyn,Bogdan Gabrys,Ravid Shwartz-Ziv,Tomasz Kajdanowicz", "background": "大型语言模型（LLMs）在自然语言处理领域取得了革命性的进展，但它们易产生幻觉的倾向为可靠部署带来了严重挑战。尽管已经开发了多种幻觉检测方法，但它们的评估往往依赖于ROUGE指标，该指标基于词频重叠，与人类判断不一致。通过全面的人类调查，研究发现ROUGE虽然召回率高，但其极低的精确率导致了误导的性能估计。研究还揭示简单基于响应长度的启发式方法与复杂检测技术相比具有竞争力，暴露出当前评估实践中的根本缺陷。研究者认为，采用语义意识和稳健的评估框架对于准确评估幻觉检测方法的真实性能至关重要，从而确保大型语言模型输出的可信度。", "innovation": "重新评估幻觉检测在LLMs中的表现，指出传统的ROUGE指标存在不足，提出采用语义意识和稳健的评估框架的重要性，揭示基于响应长度的简单启发式方法在复杂检测技术中的竞争力，挑战当前的评估实践。", "conclusion": "采用语义意识和稳健的评估框架是准确评估幻觉检测方法真实性能的关键，从而确保大型语言模型输出的可信度。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08895", "html_url": "https://arxiv.org/abs/2508.08895", "title": "ASPD: 通过在大型语言模型中探索内在并行性解锁自适应串行-并行解码", "title_en": "ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs", "authors": "Keyu Chen,Zhifeng Shen,Daohai Yu,Haoqian Wu,Wei Wen,Jianfeng He,Ruizhi Qiao,Xing Sun", "background": "随着大型语言模型（LLMs）规模和复杂性的增加，推断延迟成为一个显著挑战。主要原因是这些模型使用自回归解码范式，其特点是按序列预测下一个词。然而，我们观察到自回归模型的输出中存在某些可以并行处理的部分，我们称之为固有并行性。通过同时解码这些并行部分，可以显著提高LLM的整体推理速度。", "innovation": "我们提出了自适应串行-并行解码（ASPD），旨在解决两种核心挑战：自动构建并行化数据和高效的并行解码机制。该方法引入了一个非侵入式管道，用于自动提取和验证出自回归模型响应中的并行化结构。我们还实现了混合解码引擎，该引擎允许在保持可重用KV缓存的同时，在串行解码和并行解码模式之间无缝过渡，最大限度地提高计算效率。在各类任务中，ASPD均展现出前所未有的性能提升。", "conclusion": "ASPD在Vicuna Bench上实现了高达3.19倍（平均1.85倍）的速度提升，同时保持响应质量在1%以内。我们的框架为高效的LLM并行推理设定了里程碑，为在如AI客服机器人和自动回复引擎等延迟敏感应用中的部署铺平了道路。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09158", "html_url": "https://arxiv.org/abs/2508.09158", "title": "EvaDrive：端到端演化对抗策略优化自主驾驶", "title_en": "EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving", "authors": "Siwen Jiao,Kangan Qian,Hao Ye,Yang Zhong,Ziang Luo,Sicong Jiang,Zilin Huang,Yangyi Fang,Jinyu Miao,Zheng Fu,Yunlong Wang,Kun Jiang,Diange Yang,Rui Fan,Baoyun Peng", "background": "当前的自主驾驶技术在实现类人的迭代决策中面临重大挑战，这种决策需要不断生成、评估和改进路径提案。现有的生成-评估框架将路径生成与质量评估隔离开，阻止了对规划至关重要的迭代改进。同时，强化学习方法将多维度的偏好压缩为单一尺度的奖励，这模糊了关键的权衡，减少了多目标优化的精度。", "innovation": "EvaDrive提出了一种新颖的多目标强化学习框架，通过对抗优化建立了轨迹生成和评估之间的真正闭环共同进化。EvaDrive将轨迹规划视为多轮对抗博弈。其间，一个分层生成器通过结合时间因果性的自回归意图模型和空间灵活性的扩散模型不断提出候选路径。这些提案由一个可训练的多目标评论家严格评估，该评论家明确地保留了多样的偏好结构而不将其压缩为单一尺度。通过由Pareto前沿选择机制引导的对抗互动，EvaDrive能够实现多轮迭代改进，有效避免局部最优并保留轨迹。", "conclusion": "EvaDrive在NAVSIM和Bench2Drive基准上的实验结果表明SOTA性能。具体来说，在NAVSIM v1上实现了94.9 PDMS（超越DiffusionDrive 6.8，DriveSuprim 5.0，TrajHF 0.9），在Bench2Drive上实现了64.96驾驶分数。EvaDrive通过动态权重生成不同的驾驶风格，无需外部偏好数据，引入了闭环对抗框架，为类人的迭代决策提供了一种新的无尺度压缩的轨迹优化方法。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09185", "html_url": "https://arxiv.org/abs/2508.09185", "title": "一种用于增强现实可解释认知攻击检测的神经符号框架", "title_en": "A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality", "authors": "Rongqian Chen,Allison Andreyev,Yanming Xiu,Mahdi Imani,Bin Li,Maria Gorlatova,Gang Tan,Tian Lan", "background": "增强现实（AR）通过在现实世界中叠加虚拟元素来增强感知。由于其日益增长的受欢迎程度，认知攻击也越来越受到关注，这些攻击通过改变AR内容来操纵用户的语义感知。现有的检测方法大多关注视觉变化，这些变化仅限于像素或图像级别的处理并且缺乏语义推理能力，或者依赖于预训练的视觉语言模型（VLM），这些模型作为黑盒方法缺乏可解释性。", "innovation": "本文提出了一种名为CADAR的新型神经符号方法，用于AR中的认知攻击检测。该方法利用神经VLM融合多模态视觉语言输入，获得符号感知图表示，并整合先验知识、显著性加权和时间相关性。然后，该模型使用粒子滤波基于的统计推理（一种顺序蒙特卡罗方法）来检测认知攻击，从而使CADAR继承了预训练VLM的适应性和粒子滤波的可解释性和推理严谨性。", "conclusion": "在扩展的AR认知攻击数据集上的实验表明，与强大的基线方法相比，CADAR在复杂AR攻击场景中的准确率提高了10.7%，突显了神经符号方法在有效和可解释认知攻击检测中的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09178", "html_url": "https://arxiv.org/abs/2508.09178", "title": "IAD-R1: 在工业异常检测中增强一致推理", "title_en": "IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection", "authors": "Yanhui Li,Yunkang Cao,Chengliang Liu,Yuan Xiong,Xinghui Dong,Chao Huang", "background": "工业异常检测是现代制造业的关键组成部分，但由于缺陷样本稀缺，传统检测方法的应用范围受限。尽管视觉-语言模型（VLMs）在泛化能力方面表现出显著优势，但在工业异常检测中的表现仍然有限。", "innovation": "提出了一种名为IAD-R1的通用后训练框架，适用于不同架构和参数规模的VLMs，显著增强了其异常检测能力。IAD-R1采用两阶段训练策略：PA-SFT阶段使用精心构建的高质量Chain-of-Thought数据集（Expert-AD）进行训练，提升异常感知能力并建立推理-答案关系；SC-GRPO阶段使用精心设计的奖励函数实现从“异常感知”到“异常解释”的能力飞跃。实验结果显示，IAD-R1在7种VLMs上都取得了显著改进，特别是在DAGM数据集上的改进最为显著，0.5B参数模型在零样本设置中超过了包括GPT-4.1和Claude-Sonnet-4在内的商业模型，展示了IAD-R1的有效性和优越性。", "conclusion": "IAD-R1通过两阶段策略显著增强了基于VLMs的工业异常检测能力，并在多个VLMs和实际数据集上取得了卓越的性能。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09146", "html_url": "https://arxiv.org/abs/2508.09146", "title": "理解基于Transformer的上下文学习以优化CSMA", "title_en": "To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA", "authors": "Shugang Hao,Hongbo Li,Lingjie Duan", "background": "二进制指数退避方案广泛应用在WiFi 7中，但其在动态信道环境中依然会出现吞吐量性能不佳的情况。最近基于模型的方法（例如非持久化和$p$-持久化CSMA）简单地在已知和固定的节点密度下优化退避策略，仍然因为不精确的节点密度估计而导致大量的吞吐量损失。现有模型和深度强化学习方法多基于已知节点密度，对于未知或变动的节点密度难以提供有效的信道访问优化。因此，该论文提出了一种基于LLM和Transformer的上下文学习（ICL）理论，旨在优化信道访问策略，解决上述问题。", "innovation": "该论文首次提出基于LLM和Transformer的上下文学习（ICL）理论，设计了一种基于Transformer的ICL优化器，不仅可以预收集碰撞阈值数据示例，还可以将查询的碰撞情况构造成提示输入给Transformer学习模式，生成预测的碰撞窗口阈值。为了有效地进行ICL训练，该论文开发了一种高效的算法，在有限的训练步骤内保证了接近最优的碰撞窗口阈值预测。更重要的是，该研究还允许在提示中使用错误数据输入，保证了优化器在预测和吞吐量上的误差最小。实验结果还进一步验证了该方法在NS-3仿真环境下下的快收敛性和相对于现有模型和深度强化学习方法的接近最优吞吐量表现，即使在未知节点密度情况下也能展现出良好效果。", "conclusion": "通过基于Transformer的上下文学习优化CSMA策略，特别是在未知的节点密度环境下，能够有效减少吞吐量损失，提供接近最优的性能。该方法在实际应用中展现了良好的泛化能力和收敛性能。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09632", "html_url": "https://arxiv.org/abs/2508.09632", "title": "Preacher: Paper-to-Video Agentic System", "title_en": "Preacher: Paper-to-Video Agentic System", "authors": "Jingwei Liu,Ling Yang,Hao Luo,Fan Wang,Hongyan Li,Mengdi Wang", "background": "现有的视频生成模型虽然具有潜力，但受限于短小的上下文窗口、固定的视频时长限制、有限的风格多样性以及无法代表特定领域的知识。", "innovation": "Preacher 是首个应用于论文到视频的代理系统，通过自上而下的方法对论文进行分解、总结和重新阐述，然后通过自下而上的方法生成视频，合成多样化的视频片段形成一个连贯的摘要。此外，通过定义关键场景并引入渐进式思维链（P-CoT）进行粒度化、迭代规划，从而使跨模态表示更加一致。", "conclusion": "Preacher 能够生成高质量的视频摘要，覆盖五个研究领域，并展示了超越当前视频生成模型的专业性。源代码将在该链接/releases中发布：this https URL"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09299", "html_url": "https://arxiv.org/abs/2508.09299", "title": "通过分布式机器学习和基于区块链的模型验证实现分散的天气预报", "title_en": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation", "authors": "Rilwan Umar,Aydin Abadi,Basil Aldali,Benito Vincent,Elliot A. J. Hurley,Hotoon Aljazaeri,Jamie Hedley-Cook,Jamie-Lee Bell,Lambert Uwuigbusun,Mujeeb Ahmed,Shishir Nagaraja,Suleiman Sabo,Weaam Alrbeiqi", "background": "天气预报在灾害准备、农业和资源管理中发挥着重要作用，但当前集中的天气预报系统正受到安全漏洞、扩展性限制以及单点故障的不断增强的压力。", "innovation": "我们提出了一种结合联邦学习（FL）和区块链技术的分散天气预报框架。联邦学习使合作模型训练过程中不必暴露敏感的本地数据，增强了隐私并减少了数据传输开销；而以太坊区块链确保了模型更新的透明和可靠验证。进一步的安全性增强是在系统中引入基于声誉的投票机制，评估提交模型的可信度，并利用星际文件系统（IPFS）进行高效的离链存储。", "conclusion": "实验结果表明，该方法不仅提高了天气预报的准确性，还增强了系统的韧性和扩展性，使其成为在实际、安全关键环境中部署的可行选择。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09848", "html_url": "https://arxiv.org/abs/2508.09848", "title": "PRELUDE：设计用于长期上下文理解与推理的基准", "title_en": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts", "authors": "Mo Yu,Tsz Ting Chung,Chulun Zhou,Tong Li,Rui Lu,Jiangnan Li,Liyan Xu,Haoshu Lu,Ning Zhang,Jing Li,Jie Zhou", "background": "目前的基准测试无法充分评估系统的长期上下文理解和深入推理能力，因为这些基准往往未涵盖具有间接关联信息的需求。新基准PRELUDE致力于评估模型在此方面的能力，任务是判断角色的前传故事是否与原始书籍的经典叙述一致，这需要全球理解能力和深层次的推理。", "innovation": "PRELUDE基准引入了一个更严格的任务，要求评估前传故事与原始书籍叙述的一致性，从而更强烈地考验全球理解和推理能力。它是第一个专门针对长期上下文理解的任务，区别于以往需要搜索和整合仅间接相关的信息。实验结果表明，当前的模型，包括在上下文学习、RAG和最先进的LLM领域训练的模型以及商业性的DeepResearch服务在这方面落后于人类。", "conclusion": "PRELUDE基准揭示了长期上下文理解与推理中存在的显著差距。尽管最先进的模型和商业服务在连续学习和领域内训练方面表现不错，但在长期理解上仍存在15%以上的不足。此外，模型表现出正确但推理逻辑有误的情况，这进一步导致了达到人类推理准确度的差距超过30%。这些发现突显了长期上下文理解与推理能力的巨大改进空间。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09458", "html_url": "https://arxiv.org/abs/2508.09458", "title": "幻觉与解释：知识合成中AI辅助数据提取的准确性和精确性再思考", "title_en": "Hallucination vs interpretation: rethinking accuracy and precision in AI-assisted data extraction for knowledge synthesis", "authors": "Xi Long,Christy Boscardin,Lauren A. Maggio,Joseph A. Costello,Ralph Gonzales,Rasmyah Hammoudeh,Ki Lai,Yoon Soo Park,Brian C. Gin", "background": "文献综述对于卫生专业教育（HPE）至关重要，它能整合发现以推动理论和实践的发展。然而，文献综述的数据提取过程非常耗费人力，特别是在数据提取方面。人工智能（AI）辅助的提取虽然有望提高效率，但其准确性仍是一个值得关注的问题，尤其是在区分AI生成的“幻觉”（虚构内容）与合法的解释差异方面。这项研究利用大型语言模型开发了一个自动化数据提取平台，并将AI提取结果与人工提取结果进行了比较，以解决上述问题。", "innovation": "研究团队开发了一个使用大型语言模型（LLMs）的提取平台，实现了数据自动提取，并在187篇文献和17个提取问题上将AI提取结果与人工结果进行了对比。研究通过计算者间可靠性和主题相似性来衡量AI与人类之间的契合度，同时通过将提取结果与其来源文献进行对比来识别错误。这项研究提出了一个将AI重新定位为知识合成过程中透明且可信赖的合作伙伴的新视角。", "conclusion": "研究表明，AI在处理具体且明确陈述的问题时（如标题、目标）与人类高度一致，但在需要主观解释或文本中未出现的问题上一致性较低。人为与人为之间的一致性也表现出类似的依赖问题的变异性。AI与人类之间的分歧大多源于解释差异，而非幻觉。AI的不准确率较低，而人类陈述不准确的可能性几乎是AI的三倍。研究结果表明AI的一致性更多地依赖于可解释性而非幻觉。重复AI提取可以识别出解释的复杂性或模糊性，从而在人类审查之前加以改进。AI可以作为透明且可信赖的合作伙伴参与知识合成过程，但需要注意保留关键的人类见解。"}
{"llm_update_time": "20250817", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.09297", "html_url": "https://arxiv.org/abs/2508.09297", "title": "带有偏见的AI能提高人类决策但会降低信任", "title_en": "Biased AI improves human decision-making but reduces trust", "authors": "Shiyang Lai,Junsol Kim,Nadav Kunievsky,Yujin Potter,James Evans", "background": "当前的AI系统通过实现思想中立来降低风险，然而这可能引入自动化偏见，通过抑制人类在决策过程中的认知参与。为了探讨这一问题，作者进行了随机试验，其中包括2,500名参与者。", "innovation": "研究创新之处在于测试了文化上有偏见的AI是否能增强人类的决策能力。参与者与具有政治多样性的GPT-4o变体进行了信息评估任务的互动，结果显示，有偏见的AI助手提高了人类的表现，增加了参与度，并减少了评价偏见，特别是在遇到对立观点时。然而，参与者对于有偏见的AI评价偏低，而对中立系统评价偏高。", "conclusion": "研究结果表明，AI的中立传统智慧可能需要重新审视。引入战略性的多样化文化偏见的融合或有助于改善和增强人类的决策能力及韧性，尽管这可能会带来信任度的下降。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10000", "html_url": "https://arxiv.org/abs/2508.10000", "title": "AutoGeTS：基于知识的文本合成自动化生成以改进文本分类", "title_en": "AutoGeTS: Knowledge-based Automated Generation of Text Synthetics for Improving Text Classification", "authors": "Chenhao Xue,Yuanzhe Jin,Adrian Carrasco-Revilla,Joyraj Chakraborty,Min Chen", "background": "在实际应用中开发文本分类模型时，面临的主要挑战之一是无法为所有文本类别收集足够的数据。为解决这一挑战，本研究利用大型语言模型（LLMs）生成合成数据，以提高模型性能，无需等待更多真实数据的收集和标注。", "innovation": "提出了一个自动化的工作流AutoGeTS，该工作流能够自动寻找并生成更有效的合成数据。研究了三种搜索策略，并基于实验结果设计了一种集成算法，该算法可根据类别特征来选择最合适的搜索策略。实验结果表明，这种集成方法比单独使用每种策略更加有效。", "conclusion": "通过AutoGeTS方法，可以更有效地使用LLMs生成合成数据来改进文本分类模型，而无需等待更多真实数据的收集。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09998", "html_url": "https://arxiv.org/abs/2508.09998", "title": "INTIMA：人工智能伴侣行为衡量基准", "title_en": "INTIMA: A Benchmark for Human-AI Companionship Behavior", "authors": "Lucie-Aimée Kaffee,Giada Pistilli,Yacine Jernite", "background": "AI伴侣现象已经出现，尽管它带来了积极影响，但也引发了关注。用户与AI系统之间建立的情感联系是一种重要模式，但这也涉及用户福祉的问题。为了衡量这种行为，研究人员开发了Interactions and Machine Attachment Benchmark (INTIMA)，该基准用于评估语言模型中的伴侣行为。它基于心理学理论和用户数据，涵盖了四类31种行为，并通过368个定制的提示进行评估。", "innovation": "研究人员开发了INTIMA基准，该基准包含368个定制提示，涉及四类31种行为，用于评估和分类语言模型中的伴侣行为。这项工作通过对多种AI模型（Gemma-3, Phi-4, o3-mini, 和Claude-4）进行评估，揭示了各种模型之间的差异，特别是在更敏感的领域，不同提供商可能优先考虑不同的分类，这提示了对情感驱动交互的一致处理方法的需求。", "conclusion": "研究表明，伴侣强化行为在所有模型中更为常见，但不同提供商在处理更敏感部分的优先级上存在显著差异。这对于用户福祉而言是令人担忧的，因为适当的边界设定和情感支持都是至关重要的。因此，这一发现强调了需要更加一致的方法来处理情感化的交互。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09993", "html_url": "https://arxiv.org/abs/2508.09993", "title": "区块链上的开源语言模型公平性评估透明协议", "title_en": "A Transparent Fairness Evaluation Protocol for Open-Source Language Model Benchmarking on the Blockchain", "authors": "Hugo Massaroli,Leonardo Iara,Emmanuel Iarussi,Viviana Siless", "background": "大型语言模型（LLMs）在现实生活中的应用越来越广泛，尤其是在刑事司法、教育、医疗保健和金融等高风险领域。然而，关于LLMs公平性的担忧仍然存在。为了应对这一挑战，本文提出了一种使用互联网计算机协议（ICP）区块链和智能合约的透明评估协议，以评估开源LLMs的公平性。评估使用了PISA数据集用于学术成绩预测，并通过统计平等性和等机会度量对社会偏见进行评估。同时，还进行了跨语言评估，揭示了不同语言间的差异性。所有代码和结果都已开源，以便社区审核和跟踪模型版本的公平性变化。", "innovation": "本文提出了一种使用互联网计算机协议（ICP）区块链和智能合约的透明评估协议，以评估开源LLMs的公平性。该方法确保了评估的可验证性、不可变性和可复现性。在评估过程中，使用了PISA数据集进行学术成绩预测，并通过统计平等性和等机会度量对社会偏见进行评估。同时，还进行了跨语言评估，揭示了不同语言间的差异性。该方法的创新之处在于利用区块链技术和智能合约实现评估结果的公开和透明，确保了评估的公正性和可靠性。", "conclusion": "所提出的方法已经得到了Llama、DeepSeek和Mistral模型的公平性评估结果，并使用PISA和Kaleidoscope数据集进行了多语言评估，其中揭示了跨语言间的差异。所有代码和结果都是开源的，这使得社区可以进行审核并长期跟踪模型版本的公平性变化。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10005", "html_url": "https://arxiv.org/abs/2508.10005", "title": "从答案到问题：EQGBench 评估大模型的教育性问题生成", "title_en": "From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation", "authors": "Chengliang Zhou,Mei Wang,Ting Zhang,Qiannan Zhu,Jian Li,Hua Huang", "background": "大语言模型（LLMs）在数学问题解决方面展现出了显著的能力。然而，从提供答案到生成高质量的教育性问题是极具挑战性的，且这一领域尚未得到充分的探索。为了推进教育性问题生成（EQG），并促使LLMs生成具有教育价值和实用性的问题，本文提出了一个针对汉语EQG的综合基准测试平台EQGBench。该平台以中国中学三个基本学科——数学、物理和化学为基础，构建了一个包含900个评估样本的多元数据集，涵盖了不同知识点、难度层次和问题类型，并模拟了实际教育场景。", "innovation": "本文创新地引入了EQGBench，这是一个专为评估LLMs汉语教育性问题生成性能而设计的综合基准。它通过一个包含900个评估样本的多元数据集，以及一个监督不同知识点、难度和题型的五维评估框架，构建了一个全面的评估体系。该平台对46种主要的大模型进行了系统的评估，揭示了生成具有教育价值的问题和培养全面能力的显著发展空间。", "conclusion": "通过系统评估46种主流的大模型，我们的研究揭示了在生成具有教育价值的问题方面还存在很大的发展空间，以促进学生的综合素质。我们提出的EQGBench平台为LLMs在教育性问题生成领域的评估设立了新的标准，这对于推动该领域的发展具有重要意义。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10008", "html_url": "https://arxiv.org/abs/2508.10008", "title": "在线课程讨论论坛帖子的多维分类", "title_en": "Multidimensional classification of posts for online course discussion forum curation", "authors": "Antonio Leandro Martins Candido,Jose Everardo Bessa Maia", "background": "在线课程中讨论论坛的自动管理需要持续更新，频繁训练大型语言模型（LLMs）是一个资源密集型的过程。为了绕开昂贵的调整需求，本文探讨并评估了使用贝叶斯融合方法。该方法将预训练的通用LLM的多维分类分数与本地数据训练的分类器分数相结合。", "innovation": "提出了一种贝叶斯融合的方法，该方法结合了预训练的通用LLM与基于本地数据训练的分类器的分类分数。性能对比表明，该融合方法在单独使用每个分类器时表现更好，并且与LLM调整方法的性能相近。", "conclusion": "提出的融合方法能够有效提升在线课程讨论论坛帖子的分类效果，且几乎不需要昂贵的模型调整过程，从而显著降低了资源消耗。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10004", "html_url": "https://arxiv.org/abs/2508.10004", "title": "用户对注意力可视化感知：证据基础医学文献解释性的影响", "title_en": "User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents", "authors": "Andrés Carvallo,Denis Parra,Peter Brusilovsky,Hernan Valdivieso,Gabriel Rada,Ivania Donoso,Vladimir Araujo", "background": "注意力机制是Transformer架构的核心组件，除了提升性能外，还被用作通过注意力权重解释模型预测结果的机制，这些权重与输入特征（如文档中的标记）相关联。在循证医学中，这些解释有助于医生理解并互动使用用于分类医学文献的人工智能系统。然而，对于注意力权重是否实际提供有用的解释仍然没有达成共识，而且很少有研究探索可视化注意力如何影响其作为解释辅助工具的有用性。为填补这一空白，我们进行了一项用户研究，评估注意力基解释是否支持用户在医学文献分类中，并且是否有偏好可视化方式。", "innovation": "研究通过用户研究评估了Transformer模型（XLNet）对医学文献分类的准确性和注意力权重解释的感知，发现尽管模型分类准确，但注意力权重并未被普遍认为有助于解释预测。然而，这种感知很大程度上取决于注意力的可视化方式。这与Munzner的视觉效果原则不同，或者优于精确编码（如条形图长度），用户更偏好更加直观的格式，例如文本亮度或背景颜色。此项研究表明，期望注意力权重解释的效果取决于其可视化方式的不同展现形式。", "conclusion": "我们的研究结果并未证实总体上注意力权重的解释效用，但表明其解释值感知是由它们的可视化格式影响的。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10001", "html_url": "https://arxiv.org/abs/2508.10001", "title": "HiFACTMix: 基于图的混合语言基准和模型，用于Hinglish中的基于证据的政治理论验证", "title_en": "HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish", "authors": "Rakesh Thakur,Sneha Sharma,Gauri Chopra", "background": "在混合语言（如Hinglish）、低资源语言中进行事实核查仍然是自然语言处理中的一个未充分探索的挑战。现有的事实验证系统主要集中在高资源、单一语言的环境中，并未能很好地应用于如印度一样语言多样的地区的实际政治言论。鉴于公共人物尤其是政治人物广泛使用Hinglish以及社交媒体对公众意见日益增长的影响，需要一种稳健的、多语言和上下文感知的事实核查工具来填补这一空白。鉴于此，提出了一个名为HiFACT的数据集，包含1500条由印度28位首席部长发布的实际Hinglish事实声明及相应证据的标注，处于高混合语言低资源环境下。", "innovation": "该研究提出了一个名为HiFACTMix的创新的图感知、检索增强事实核查模型，该模型结合了多语言上下文编码、事实声明与证据语义对齐、证据图构建、图神经推理和自然语言解释生成，这为多语言、混合语言和政治背景下的事实核查研究开辟了新的方向。HiFACTMix在与现有最先进的多语言基准模型的比较中，验证了更高的准确性，并提供了对其裁决的忠实解释。", "conclusion": "该研究提出的基准数据集和模型为多语言、混合语言和政治背景下的基于证据的事实核查研究提供了一个新的方向，解决了现有技术难以扩展到如印度这种语言多样性的地区的政治言论问题。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09999", "html_url": "https://arxiv.org/abs/2508.09999", "title": "XFacta: 当代现实世界数据集与多模态错误信息检测评估", "title_en": "XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs", "authors": "Yuzhuo Xiao,Zeyu Han,Yuhan Wang,Huaizu Jiang", "background": "社交媒体上多模态错误信息的迅速传播需要更有效和健壮的检测方法。近期利用多模态大型语言模型（MLLMs）的进步表明了这种挑战的潜在解决手段。然而，现有方法中存在的瓶颈（证据检索与推理之间的区别）仍不明确，这阻碍了该领域的进一步发展。此外，现有基准数据集要么包含过时的事件，导致与当代社交媒体场景不符，使MLLMs简单地记住这些事件，要么人为合成，未能反映真实的错误信息模式。此外，现有的研究缺乏对基于MLLMs的模型设计策略的全面分析。为了解决这些问题，作者引入了XFacta这一当代和现实世界的数据集，更适合评估基于MLLMs的错误信息检测方法。", "innovation": "XFacta是一个当代和现实世界的数据集，用于评估基于多模态大型语言模型的错误信息检测方法。该数据集系统性地评估了各种基于MLLM的错误信息检测策略，涵盖了不同的架构和规模，并与现有的检测方法进行了基准测试。作者还进一步开发了一个半自动的检测在环框架，不断更新XFacta的内容以保持其当代相关性。通过这些分析，作者提供了一些有价值的见解和实践，以推动多模态错误信息检测领域的发展。同时，相关的代码和数据也已发布。", "conclusion": "作者的分析提供了关于多模态错误信息检测的重要见解和实践。由于XFacta数据集的改进，现有的基于MLLM的检测方法得以进一步评估和优化。这一研究为先进技术和数据驱动的检测方法的发展奠定了基础，有助于提升对多模态错误信息的检测能力。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10009", "html_url": "https://arxiv.org/abs/2508.10009", "title": "超越硬共享：使用监督混合专家的高效多任务语音转文本建模", "title_en": "Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts", "authors": "Hojun Jin,Eunsoo Hong,Ziwon Hyung,Sungjun Lim,Seungjin Lee,Keunseok Cho", "background": "硬参数共享是一种常见的策略，用于训练单一模型来同时处理多种任务。然而，这种方法通常会导致任务干扰，从而影响整体模型性能。", "innovation": "提出了一种简单有效的监督混合专家（S-MoE）方法。S-MoE通过使用专门的引导标记将每个任务路由到其指定的专家来代替传统的混合专家模型所需的门控函数训练。通过为每个任务分配一个独立的前馈网络，S-MoE克服了硬参数共享的局限性。", "conclusion": "将S-MoE应用于语音转文本模型，使其能够同时进行自动语音识别（ASR）和语音翻译（ST）两种任务并且处理混合带宽输入。实验结果表明S-MoE的有效性，与在编码器和解码器中应用时相比，Word Error Rate (WER) 减少了6.35%。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09997", "html_url": "https://arxiv.org/abs/2508.09997", "title": "K-12 GenAI使用基于主题和任务层级主题建模的分类", "title_en": "Thematic and Task-Based Categorization of K-12 GenAI Usages with Hierarchical Topic Modeling", "authors": "Johannes Schneider,Béatrice S. Hasler,Michaela Varrone,Fabian Hoya,Thomas Schroffenegger,Dana-Kristin Mah,Karl Peböck", "background": "本文分析了几个月跨度内涉及多个学校和科目的未成年人教室中的匿名互动数据，采用了一种新颖简单的主题建模方法。具体来说，研究者将超过17,000条由学生、教师和ChatGPT生成的消息按两个维度进行分类：内容（如自然和人物）和任务（如写作和解释）。通过单独为每个维度进行的层次化分类，包括了示范提示，提供了高层次概览和实际见解。此前的研究大多缺乏内容或主题分类，教育中的任务分类虽有涉及，但大多数未基于真实的K-12世界数据支持，因此本文通过新颖的方法发现了一些新颖的应用实例。这些发现表明，许多现有的经典和新兴的计算方法，例如主题建模，在处理大量文本时表现不佳，促使研究者直接利用最先进的大语言模型并进行适当预处理，以通过明确的指示方式实现更好的与人类的契合水平，从而相比先前方法取得了优良的层次主题结构。研究结果有助于同仁们更好地使用GenAI，同时也指出了未来研究的关注点和开放问题。", "innovation": "本文创新性地采用了新颖简单的主题建模方法对K-12年龄段的学生与教师以及ChatGPT之间的交互数据进行了分类。分类维度包括内容和任务，并基于层次化的方法进行了详细的分类，区别以往仅侧重于任务分类而缺乏基于内容的主题分类。通过直接应用最先进的语言模型（LLM）与适当的预处理，实现了更符合人类的层次主题结构，相比之前的方法具有更好的对齐效果。这些方法在K-12教育中的实际应用提供了新的见解和应用实例，有助于更好地理解和指导GenAI技术的使用。", "conclusion": "本文的研究结果支持研究者、教师和学生更好地使用GenAI技术，并揭示了多个问题和未来研究的开放性问题。通过这一研究，可以明确许多现有的经典和新兴的计算方法在分析大量文本时的不足之处，从而进一步推动了大语言模型（LLM）在教育和研究中的应用和发展。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10003", "html_url": "https://arxiv.org/abs/2508.10003", "title": "大型语言模型嵌入中的语义结构", "title_en": "Semantic Structure in Large Language Model Embeddings", "authors": "Austin C. Kozlowski,Callin Dai,Andrei Boutyline", "background": "心理研究发现，人类对单词在各种语义尺度上的评分可以简化为低维度形式，同时信息损失较小。研究者们观察到，大型语言模型（LLMs）中的嵌入矩阵所表示的语义关联也具有相似的低维度结构。研究还注意到，单词在由反义词对定义的语义方向上的投影与人类评分高度相关，并观察到这些投影可有效简化为一个三维子空间，与人类调查反应中得出的模式相似。此外，沿着一个语义方向移动标记会在几何对齐的特点上产生与余弦相似性成比例的旁效果。这些发现表明，语义特征在LLMs中的纠缠方式与人类语言中的语义互联方式相似，并且大量看似复杂的语义信息实际上只集中在低维度空间中，这表明理解这种语义结构在指导特征演化时非常重要，以避免意外后果的产生。", "innovation": "研究表明，大型语言模型（LLMs）的嵌入矩阵中包含的语义关联具有低维度结构，类似于人类对单词语义评分的简化模式。研究运用反义词对定义的语义方向揭示了这种低维度结构，并且发现随着语义方向的线性变化，语义信息会以几何相似性的方式传递。此外，研究提出这些发现对于在使用LLMs时理解和管理语义复杂度至关重要。", "conclusion": "研究发现，大型语言模型中的语义结构与人类对单词评分的简化模式相似，存在低维度的语义信息。沿着语义方向变化时，语义信息会以几何相似性的方式传递，并且这种结构对于避免在操控模型特性时产生意外后果非常重要。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10007", "html_url": "https://arxiv.org/abs/2508.10007", "title": "使用微调的大语言模型对《模糊意图敌意问卷》进行自动化评分", "title_en": "Automated scoring of the Ambiguous Intentions Hostility Questionnaire using fine-tuned large language models", "authors": "Y. Lyu,D. Combs,D. Neumann,Y. C. Leong", "background": "敌意归因偏见是指倾向于将社交互动解释为故意敌意。《模糊意图敌意问卷》（AIHQ）常用于测量敌意归因偏见，包括开放型问题，参与者需要描述负面社交情境中的意图，并说明如何应对。虽然这些问题提供了敌意归因内容的见解，但评估过程耗时且需人工评分。本文研究了是否可以使用大语言模型自动化AIHQ开放型回答的评分。研究基于之前收集的数据集，该数据集中包括创伤性脑损伤（TBI）患者和健康对照（HC）个体填写AIHQ并由训练有素的人工评阅者的评分。使用一半样本数据微调两个模型以适应人工评分，然后在剩余样本上测试微调过的模型。结果显示，模型生成的评分与人工评分在敌意和攻击反应归因方面高度一致，尤其是微调过的模型更为一致。这种一致性在模糊、故意和意外情景类型中保持不变，并且重复了TBI组和HC组在敌意和攻击归因反应上的先前群体差异研究结果。微调模型也很好地泛化到非临床独立数据集。为了促进更广泛的采用，研究者提供了可访问的评分界面，包括本地和云端版本", "innovation": "本文的创新点在于利用大语言模型自动化评分AIHQ的开放型回答，解决了评分耗时且需人工评定的问题。研究通过微调模型，使人工智能能够识别和评分模糊意图和敌意表达，具有在研究和临床情境中的普及应用潜力", "conclusion": "研究发现大语言模型能够高效且一致地评分AIHQ，展示了其在简化心理评估方面的潜力，特别是在不同人群中。研究提供的评分界面能够促进更广泛的应用。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10010", "html_url": "https://arxiv.org/abs/2508.10010", "title": "LLM辅助下的健康 misinformation 增强攻击审查与分析", "title_en": "An Audit and Analysis of LLM-Assisted Health Misinformation Jailbreaks Against LLMs", "authors": "Ayana Hussain,Patrick Zhao,Nicholas Vincent", "background": "文章背景在于大型语言模型（LLMs）作为一种双刃剑，能够生成有害的错误信息，且这些错误信息可能是无意中生成的，或者通过“ jailbreak”攻击生成。研究探讨了使用LLMs进行医学错误信息生成的能力，并分析了这些由增强的LLMs生成的错误信息与社交媒体上典型错误信息的异同，以及这些错误信息使用标准机器学习方法检测的有效性。文章通过研究109个独特攻击模型，评估了不同靶向LLMs的攻击效果，同时将攻破模型的响应与真实世界健康相关问题查询进行对比，发现LLMs可以有效检测既来自其他模型也来自人的错误信息，支持了LLMs在维护信息生态系统健康方面的可行性和潜力。", "innovation": "研究创新地评估了LLMs辅助下的医学错误信息生成攻击的有效性和特性，对比了此类错误信息与社交媒体上常见的错误信息的不同，并研究了它们对标准机器学习检测方法的可检测性。尤其之处在于深入分析了109种独特的攻击模型，提供了实证证据表明LLMs能够有效检测其他模型和人类生成的错误信息，同时强调了精细设计理念在实现健康信息生态系统中的重要性。", "conclusion": "研究得出结论，LLMs通过额外的研究可在检测和防止误传信息方面发挥作用。具体发现显示，攻破的LLMs生成的错误信息在医学领域具有特殊性，能够通过标准机器学习方法有效识别。文章进一步证明，精心设计的LLMs能够促进更为健康的信息生态环境。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10012", "html_url": "https://arxiv.org/abs/2508.10012", "title": "知识密集环境中的指导导航：基于指导图的结构语义探索", "title_en": "Guided Navigation in Knowledge-Dense Environments: Structured Semantic Exploration with Guidance Graphs", "authors": "Dehao Tao,Guangjie Liu,Weizheng,Yongfeng Huang,Minghu jiang", "background": "大型语言模型（LLMs）虽然具备较强的语言能力，但在处理知识密集任务时，由于依赖静态知识和不透明的推理过程，表现受限。知识图谱（KGs）提供了一种潜在的解决方案，但当前的探索方法面临一个根本性的问题：问题导向的方法因粒度不匹配而产生冗余探索，而线索导向的方法则在复杂场景下未能有效利用上下文信息。", "innovation": "提出了基于指导图的知识探索框架（GG Explore），引入中间的指导图来连接不结构化查询和结构化知识检索。指导图通过抽象目标知识的结构同时保留更广泛的语义上下文，实现精确高效的探索。开发了结构对齐和上下文感知剪枝技术，以及基于图约束的语义一致性实现高效的过滤和剪枝策略，以提高探索效率和性能，特别是在复杂任务上取得了显著效果，并保持了较小语言模型的性能，证明了其实用价值。", "conclusion": "通过广泛实验，证明了GG Explore方法在效率和性能上超越了当前最先进的技术，特别是在复杂任务上表现出色，同时保持了对小型语言模型的良好性能，展示了其实用价值。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10016", "html_url": "https://arxiv.org/abs/2508.10016", "title": "无训练的多模态大型语言模型编排", "title_en": "Training-Free Multimodal Large Language Model Orchestration", "authors": "Tianyu Xie,Yuhang Wu,Yongdong Luo,Jiayi Ji,Xiawu Zheng", "background": "不同的多模态大型语言模型（MLLMs）不能直接集成到统一的多模态输入-输出系统中。以前的研究中，训练被认为是必不可少的组成部分，以应对模态对齐、文本到语音效率和集成问题的挑战。", "innovation": "论文引入了一种有效的处理方法——多模态大型语言模型编排（MLLM Orchestration），它通过中央控制器LLM及精心设计的代理，协调特殊化模型，并通过并行的文本到语音架构实现无缝互动，以及跨模态记忆集成系统保持跨模态的上下文一致性。", "conclusion": "广泛的评估证明，多模态大型语言模型编排可以在没有任何额外训练的情况下实现全面的多模态功能，与传统联合训练方法相比，在标准基准上的性能提高了最高达7.8%，减少了10.3%的延迟，并通过显式的编排过程显著增强了可解释性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10014", "html_url": "https://arxiv.org/abs/2508.10014", "title": "PersonaEval: Are LLM Evaluators Human Enough to Judge Role-Play?", "title_en": "PersonaEval: Are LLM Evaluators Human Enough to Judge Role-Play?", "authors": "Lingfeng Zhou,Jialing Zhang,Jin Gao,Mohan Jiang,Dequan Wang", "background": "当前的研究通常依赖于未经验证的LLM-as-a-judge方法，这种方法可能无法准确反映人类对角色一致性的感知。对于人类对齐的评估来说，关键的前提是角色识别，即根据对话背景识别谁在说话的能力。我们提出，对角色扮演质量的任何有意义的评估（即角色扮演得有多好）首先必须准确地归因于正确的角色。因此，我们介绍了PersonaEval，这是首个用于测试LLM评估器能否可靠地识别出人类角色的基准。", "innovation": "PersonaEval是首个用于测试LLM评估器能否可靠地识别人类角色的基准。它使用来自小说、剧本和视频转录的人类创作的对话，挑战模型根据对话背景确定正确的角色。我们的实验显示，即使表现最好的LLM也只能达到约69%的准确率，远低于可靠评估所需的准确率。相比之下，人类参与者的表现近乎完美，准确率为90.8%，这表明当前的LLM评估器尚未足够‘人性化’以有效地评估角色扮演场景。", "conclusion": "我们的研究揭示了人形化能力在可靠评估中的重要性，除了特定任务的调优外，还需要LLM评估器具备强大的、类似人类的推理能力。我们发布了这个基准测试，链接为：this https URL."}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10013", "html_url": "https://arxiv.org/abs/2508.10013", "title": "语义桥梁：基于AMR驱动的图合成的通用多跳问题生成", "title_en": "Semantic Bridge: Universal Multi-Hop Question Generation via AMR-Driven Graph Synthesis", "authors": "Linqing Chen,Hanmeng Zhong,Wentao Wu,Weilei Wang", "background": "大规模语言模型（LLM）训练面临一个关键瓶颈：高质量、需要推理的问答对稀缺，尤其是来自稀疏、领域特定的源文献，如PubMed论文或法律文件。现有方法依赖表面模式，无法生成可控的、复杂的多跳推理问题，以检测真正的理解，这对于推动LLM训练范式具有重要意义。", "innovation": "我们的突破性创新是语义图编织——由实体编织（应对角色变化的共享实体）、谓词链编织（应对时间/因果/逻辑序列）和因果编织（对于明确的推理链）组成的三种互补的桥梁机制。通过AMR驱动分析，系统地构建文档间的复杂路径，并通过细粒度控制复杂性和类型。我们多模态的AMR流水线实现了高达9.5%的往返质量改进，支持生产级别的可控问答生成。广泛评估显示，在通用数据集（Wikipedia）和专业领域的（生物医学）上，它在四种语言（英语、中文、法语、德语）上都取得了18.3%-25.4%的性能提升。从中抽取的200个问答对超过600个本土人工标注示例，材料减少了67%，人类评估显示复杂性提高了23.4%，可答性提高了18.7%，模式覆盖度提高了31.2%。语义桥梁建立了LLM训练数据合成的新范式，能够从稀疏来源生成有针对性的推理问题。", "conclusion": "语义桥梁确立了LLM训练数据合成的新范式，使从稀疏来源生成有针对性的推理问题变得可控。我们将发布核心代码和语义桥梁模型。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10018", "html_url": "https://arxiv.org/abs/2508.10018", "title": "异名同义：大规模语言模型的同伦范畴理论", "title_en": "A Rose by Any Other Name Would Smell as Sweet: Categorical Homotopy Theory for Large Language Models", "authors": "Sridhar Mahadevan", "background": "大规模语言模型通常无法准确地识别表面上不同的但具有相同含义的陈述，例如“Charles Darwin wrote”和“Charles Darwin is the author of”。尽管这两个句子的下一个标记概率应该相同，但实际上通常不相同。为此，研究人员开发了一些经验上的工作解决方案，例如使用k-NN句相似度度量生成平滑估计，但这些方法仍存在局限性。本文更为抽象地探讨了这一问题，引入了一个同伦范畴框架来解决大规模语言模型中的这些问题。然而，这种方法由于自然语言中存在大量的等效表达式而遇到了困难，每个表达式生成的是一个非同构箭头。", "innovation": "本文引入了一个同伦范畴框架来解决大规模语言模型的同义表达问题。该方法运用了同伦技术来捕捉同伦范畴中的“弱同构”。具体而言，文章从高阶代数K理论到模型范畴，详细介绍如何在同伦范畴框架中应用同伦理论，从而更好地解决大规模语言模型生成具有等效表达的文本的准确性问题。", "conclusion": "通过使用同伦学的方法，本文提出的方法能够更好地解决大规模语言模型在处理等效表达时因生成非同构箭头而产生的问题。这种方法不仅能够提高语言模型的灵活性，还能在一定程度上使模型生成的文本具有更高的语义一致性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10015", "html_url": "https://arxiv.org/abs/2508.10015", "title": "RealTalk-CN: 带有跨模态交互分析的现实 chinese 语音-文本对话基准", "title_en": "RealTalk-CN: A Realistic Chinese Speech-Text Dialogue Benchmark With Cross-Modal Interaction Analysis", "authors": "Enzhi Wang,Qicheng Li,Shiwan Zhao,Aobo Kong,Jiaming Zhou,Xi Yang,Yequan Wang,Yonghua Lin,Yong Qin", "background": "近年来，大规模语言模型（LLMs）在多模态处理方面取得了显著进展，包括端到端的基于语音的语言模型，这些模型能够实现自然对话并在任务导向对话（TOD）系统中执行特定任务。然而，现有的TOD数据集主要基于文本，缺乏用于评估基于语音的LLMs鲁棒性的真实语音信号。此外，现有语音TOD数据集主要是英语的，且缺乏重要的方面，如语音中断和说话人变化。为了解决这些问题，本文介绍了RealTalk-CN，这是一个包含5,400对话（60,000句话，150小时）、配对语音-文本注释的首个中国多轮、多领域语音-文本双模态TOD数据集，捕捉了各种对话场景并标注了自发的语音中断，确保全面覆盖真实世界中对话的复杂性。此外，提出了一种新的跨模态聊天任务，能够模拟真实的用户交互，并允许在语音和文本模态之间动态切换。评价涵盖了对语音中断的鲁棒性、对说话人特征的敏感性以及跨领域表现。", "innovation": "创新之处在于引入了首个中国多轮、多领域语音-文本双模态TOD数据集RealTalk-CN，该数据集涵盖了5,400个对话（60,000句话，150小时）并配对了语音-文本注释，同时还提出了一个新的跨模态聊天任务，能够模拟真实用户交互并允许在语音和文本模态之间动态切换。该数据集旨在解决现有TOD数据集中存在的问题，如缺乏真实语音信号、语音中断和说话人变化等问题，为基于语音的LLMs研究提供了坚实的基础。", "conclusion": "实验表明RealTalk-CN对于基于语音的LLMs研究具有有效性，提供了对语音中断的鲁棒性、对说话人特征的敏感性以及跨领域性能的全面评价，为该领域的进一步研究奠定了基础。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10019", "html_url": "https://arxiv.org/abs/2508.10019", "title": "通过问题空间映射解耦理解与推理以增强小规模模型的推理能力", "title_en": "Decoupling Understanding from Reasoning via Problem Space Mapping for Small-scale Model Reasoning", "authors": "Li Wang,Changhao Zhang,Zengqi Xiu,Kai Lu,Xin Yu,Kui Zhang,Wenjun Wu", "background": "尽管大型语言模型（LLMs）在推理能力方面取得了进展，但对于中小型语言模型（SLMs，例如 <1.5B 参数）的推理能力提升仍然具有挑战性。这主要是因为自然语言问题的复杂性和多样性，导致同质问题往往以不同的形式出现，而且常被冗余或干扰细节所掩盖。这给SLMs带来了双重负担：首先需要从复杂的语言输入中提取核心问题，然后在此基础上进行推理。因此，大量的问题空间给优化带来了困难，特别是对于那些容量有限的模型。", "innovation": "本文提出了一种新的框架，通过将自然语言问题映射到一个标准化的问题空间上来解耦理解与推理。该框架包括三个步骤：首先，通过强化学习将自然语言问题映射到标准化输入；其次，通过自我蒸馏对推理轨迹进行对齐；第三，训练问题空间内的推理策略。在此过程中，映射器和推理器交替训练。实验结果表明，DURIT 显著改善了 SLMS 在类型内在和类型外数学和逻辑推理任务中的性能。此外，DURIT 还提高了推理的鲁棒性，验证了解耦理解与推理作为增强 SLMs 有效策略的有效性。", "conclusion": "DURIT 显著改善了中小型语言模型在多种推理任务上的性能，通过解耦理解与推理，并在标准化问题空间中进行训练，该模型能够更好地处理复杂和多变的自然语言问题，从而提高了它们的推理能力和鲁棒性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10021", "html_url": "https://arxiv.org/abs/2508.10021", "title": "LATTE：银行客户交易和文本嵌入的学习对齐", "title_en": "LATTE: Learning Aligned Transactions and Textual Embeddings for Bank Clients", "authors": "Egor Fadeev,Dzhambulat Mollaev,Aleksei Shestov,Dima Korolev,Omar Zoloev,Ivan Kireev,Andrey Savchenko,Maksim Makarenko", "background": "从客户的历史通信序列中学习客户嵌入对于金融应用来说至关重要。虽然大型语言模型（LLMs）提供了广泛的世界知识，但它们直接用于长事件序列是计算上昂贵且在现实世界流水线中并不切实际。", "innovation": "本文提出了一种名为LATTE的对比学习框架，该框架将原始事件嵌入与从冻结的LLM中获得的语义嵌入对齐。行为特征被总结为简短的提示，由LLM嵌入，并通过对比损失提供监督。该方法显著减少了推理成本和输入大小，与直接处理完整序列的LLM相比。", "conclusion": "我们在实际金融数据集上实验性地证明了该方法优于最先进的序列表示技术，同时仍能在对延迟敏感的环境中部署。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10025", "html_url": "https://arxiv.org/abs/2508.10025", "title": "使用生成式人工智能实时检测和解释产后抑郁", "title_en": "Detecting and explaining postpartum depression in real-time with generative artificial intelligence", "authors": "Silvia García-Méndez,Francisco de Arriba-Pérez", "background": "产后抑郁（PPD）是新妈妈面临的重要挑战之一，严重影响其精神和身体健康。因此，快速检测PPD及其相关风险因素是至关重要的，需要通过专门的预防程序进行及时评估和干预。", "innovation": "本文提出了一种结合自然语言处理（NLP）、机器学习（ML）和大型语言模型（LLMs）的智能PPD筛查系统。该系统实现了实时筛查和治疗建议，并通过可解释的ML模型（即树基算法）和特征重要性解释预测，解决了“黑盒”问题。实验结果表明，该方案在所有评估指标上的PPD检测准确率达到了90%，显著优于文献中其他方案。", "conclusion": "该研究提出的解决方案有助于快速检测PPD及其相关风险因素，为及时和恰当的评估及干预提供了关键支持。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10024", "html_url": "https://arxiv.org/abs/2508.10024", "title": "RTTC: Reward-Guided Collaborative Test-Time Compute", "title_en": "RTTC: Reward-Guided Collaborative Test-Time Compute", "authors": "J. Pablo Muñoz,Jinjie Yuan", "background": "TTC作为一种提高大型语言模型推理性能的强大范式，通过Test-Time Training (TTT)和Retrieval-Augmented Generation (RAG)等策略提升性能，但不同查询需要的最佳适应策略不同，未经筛选地使用TTC策略会产生大量的计算开销。", "innovation": "提出了一种新颖的RTTC框架，通过预训练的奖励模型自适应地为每个查询选择最有效的TTC策略，最大化不同领域和任务下游的准确性。此外，RTTC架构中提出了Query-State Caching机制，以减少冗余计算并提高历史查询状态的重用。", "conclusion": "通过在多个LLM和基准上的实验，RTTC相比原始的RAG或TTT持续实现了更好的准确性，验证了自适应和基于奖励的TTC选择的必要性，以及RTTC在可扩展、高性能语言模型适应方面的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10020", "html_url": "https://arxiv.org/abs/2508.10020", "title": "FedCoT: 具有通信效率的大型语言模型联邦推理增强", "title_en": "FedCoT: Communication-Efficient Federated Reasoning Enhancement for Large Language Models", "authors": "Chuan Li,Qianyi Zhao,Fengran Mo,Cen Chen", "background": "在联邦学习环境中提高大型语言模型（LLMs）的推理能力仍然具有挑战性，特别是当需要平衡性能提升与严格的计算、通信和隐私约束时。特别是在医疗领域，决策覆盖了临床、运营和面向患者的多个方面，不仅需要准确的输出，还需要可解释、可追溯的理由，以确保安全、问责和法规合规。传统的联邦调优方法主要关注答案的正确性，而忽略了推理的质量，因此推理论述（CoT）的能力依赖于模型固有的预训练能力。此外，现有的改善推理方法通常依赖于从集中模型进行隐私侵犯的知识蒸馏。此外，传统的联邦微调在LLMs中的通信开销仍然很高。因此，本文旨在通过提出一种新框架FedCoT来解决这一问题，该框架适用于联邦环境中的推理增强。FedCoT利用了一个轻量级的推理路径增强机制：本地模型生成多个推理路径，并通过一个紧凑的鉴别器动态选择最有前途的一条。这种方法提高了推理准确性和健壮性，同时提供了有价值的解释性，对于医疗应用尤其重要。为有效管理客户端异质性，我们采用了一种改进的聚合方法，基于先进的LoRA模块堆叠，并结合客户端分类器意识，实现了跨多变客户端的去噪聚合。全面的医学推理任务实验表明，即使在严格的资源预算下，FedCoT也能显著提升客户端侧的推理性能，并完全保护数据隐私。", "innovation": "FedCoT通过引入一对多的轻量级推理路径生成和动态选择机制，解决了传统方法在增强推理能力方面的不足。在聚合客户端结果时，引入了基于先进LoRA模块改进的聚合方法，并结合客户端分类器的意识，降低了通信开销并提高了结果的稳定性。此外，FedCoT强调保护数据隐私，确保在强化推理性能的同时不泄露敏感信息。", "conclusion": "FedCoT为大型语言模型在联邦学习环境中的推理增强提供了一种有效的解决方案，显著提升了推理性能，增强了解释性，并在严格的资源和隐私要求下保持了有效性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10022", "html_url": "https://arxiv.org/abs/2508.10022", "title": "基于可检验增强的容错预测框架在多项选择题问答任务中的应用及有保证的风险控制", "title_en": "Conformal P-Value in Multiple-Choice Question Answering Tasks with Provable Risk Control", "authors": "Yuanchang Ye", "background": "近年来，LLMs在学科问答场景中的应用日益广泛.然而.在LMMs生成答案时很容易产生幻觉或非事实的内容.这些情况严重降低了了响应的可靠性.相较于CP的统计严谨的边缘覆盖率保证.以及p-检验统计上的严谨性将两者的结合尚未进行深入探索.本研究表明.一种结合p-检验与一致性评分的增强CP框架.旨在通过L-一致性重采样的MCQA响应.通过计算参考频率来应对外盒性质的LMMs难点.并利用零假设检验构建预测集.实验证据不确定性衡量.该研究提供了一个原则性的统计框架.为高风险问答场景中的LMMs部署提供可靠性保障.", "innovation": "本研究提出的创新点主要是以下两方面：首先.通过一种新的方法结合p-检验与一致性评分.研究提出了一个容错预测命令.通过L-一致性重采样MCQA响应.通过统计上计算p-值来应对公式化 LMMs的不透明性.并使用零假设检验构建预测集.在理论与实践上有显著创新.其次 on研究通过实验证明了增强的CP可以实现既定预期的实验证漫率.并且随着风险水平（α的增加预测集的平均覆盖率平均覆盖率呈单调递减趋势.这验证了预测集的不确定性度量功能.", "conclusion": "本研究表明.一种结合p-检验与一致性评分的增强CP框架可以有效解决LMMs在多选选择题问答任务中产生的幻觉问题以及非事实生成.对可以显著提高LMMs的响应可靠性并提供一个可靠的统计框架用于在高风险问答场景中部署LMMs.该研究还通过实验证明了增强的CP在多个选择选择题问答任务的实际应用中具有显著优势.该框架的一个实用性很强的特点在于它提供了实际的控制LMMs响应风险的方法."}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10027", "html_url": "https://arxiv.org/abs/2508.10027", "title": "基于LLM生成的合成数据增强的Transformer模型在阿尔茨海默病检测中的应用", "title_en": "LLMCARE: Alzheimer's Detection via Transformer Models Enhanced by LLM-Generated Synthetic Data", "authors": "Ali Zolnour,Hossein Azadmaleki,Yasaman Haghbin,Fatemeh Taherinezhad,Mohamad Javad Momeni Nezhad,Sina Rashidi,Masoud Khani,AmirSajjad Taleban,Samin Mahdizadeh Sani,Maryam Dadkhah,James M. Noble,Suzanne Bakken,Yadollah Yaghoobzadeh,Abdol-Hossein Vahabie,Masoud Rouhizadeh,Maryam Zolnoori", "background": "阿尔茨海默病及相关痴呆症（ADRD）影响着大约五百万美国老年人，但超过一半的患者未被诊断。言语基于自然语言处理（NLP）作为一种有前景、可扩展的方法，通过语言特征可以检测早期认知衰退。", "innovation": "本研究开发并评估了一个筛查管道，融合了transformer嵌入与手工制作的语言特征；测试了使用大型语言模型（LLM）生成的合成语音进行数据增强的方法；并比较了单模和多模LLM分类器在ADRD检测中的性能。研究使用了DementiaBank '饼干盗窃'任务的录音，并评估了十个transformer模型的不同微调策略，融合了顶级transformer模型的嵌入和110个基于词汇的语言特征。研究还测试了五个LLM生成的标签条件合成语音来增强训练数据，以及三种多模态模型在零样本和微调设置下的表现。", "conclusion": "融合transformer嵌入与语言特征能增强ADRD从言语中的检测。具有临床调节的LLM不仅支持分类，还能进行数据增强，而在多模态建模方面尚需进一步进步。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10030", "html_url": "https://arxiv.org/abs/2508.10030", "title": "为对齐黑盒大型语言模型而设计的感知推理提示优化", "title_en": "Inference-Aware Prompt Optimization for Aligning Black-Box Large Language Models", "authors": "Saaduddin Mahmud,Mason Nakamura,Kyle H. Wray,Shlomo Zilberstein", "background": "现有的提示优化方法对黑盒大型语言模型成功实现了良好的对齐效果。同时，如Best-of-N抽样和多数投票等推理放大策略也能通过计算成本的权衡提升性能。然而，现有的提示优化技术没有考虑到不同推理策略的影响，这导致了一种方法论上的缺口。本研究发现，在实验和理论上，提示优化与推理策略之间有一定的强相关性。此外，用户对于多目标和推理预算的偏好显著影响提示和推理配置的选择。为填补空白，提出了一种新的联合优化框架IAPO（感知推理的提示优化），该框架同时优化提示和推理尺度，并考虑到推理预算是不同的任务目标。", "innovation": "提出了感知推理的提示优化（IAPO）框架，该框架在优化提示的基础上考虑了推理策略和预算，设计了固定预算训练算法PSST（通过顺序修剪的提示缩放），并分析了有限预算下误差概率的保证。该框架被应用于六种不同任务中（包括多目标文本生成和推理），验证了在提示优化对齐黑盒大语言模型时感知推理的重要性。", "conclusion": "感知推理的提示优化算法（IAPO）和相应的训练算法（PSST）能够更好地优化与黑盒大语言模型的性能对齐，考虑到推理策略和预算的影响，为提示优化技术的进一步发展提供了新途径。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10036", "html_url": "https://arxiv.org/abs/2508.10036", "title": "反思学习：基于内省困惑的主动提示信息提取", "title_en": "Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion", "authors": "Dong Zhao,Yadong Wang,Xiang Chen,Chenxi Wang,Hongliang Dai,Chuanxing Geng,Shengzhong Zhang,Shaoyuan Li,Sheng-Jun Huang", "background": "大型语言模型（LLMs）在少样本信息提取（IE）方面显示出巨大的潜力，但其性能高度依赖于内含示例的选择。传统的选择策略往往无法提供有信息量的指导，因为它们忽略了模型失败的一个关键原因：不仅仅是语义内容的混淆，还包括信息提取任务所需的良好结构格式生成中的混淆。", "innovation": "我们引入了一种新的主动提示框架——适应性提示信息提取（APIE），该框架由我们提出的内省困惑这一原则指导。我们的方法通过一种独特地量化格式不确定性和内容不确定性的双重不确定性度量，使LLM能够评估自己的混淆。通过综合评分对未标注数据进行排名，框架能够主动选择最具挑战性和信息量的数据作为少样本示例。我们在四个基准上的大量实验表明，我们的方法在抽取准确性和鲁棒性方面的一致性优于强基线方法，取得显著改善.", "conclusion": "我们的工作强调，在构建有效的和可靠的结构生成系统时，关于模型不确定性需要有细粒度和双层视角的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10032", "html_url": "https://arxiv.org/abs/2508.10032", "title": "思考的代价：大型语言模型增加的 Jailbreak 风险", "title_en": "The Cost of Thinking: Increased Jailbreak Risk in Large Language Models", "authors": "Fan Yang", "background": "一直以来，思考模式被认为是最有价值的模式之一，但通过实验证明，具有思考模式的大型语言模型（LLM）更容易受到 Jailbreak 攻击。研究者对 9 种 LLM 进行了评估，发现在 LLM 中攻击思考模式的成功率几乎高于无思考模式的攻击成功率。通过对大量样本的研究，发现教育目的和思考长度过长是成功攻击数据的特点，而 LLM 在明知问题有害时也会给出有害的回答。", "innovation": "为了缓解上述问题，本文提出了 LLM 的安全思考干预方法。该方法通过在提示中添加‘特定思考标记’以显式地引导 LLM 的内部思考过程来实现。实验结果表明，安全的思考干预能够显著降低具有思考模式的 LLM 的攻击成功率。", "conclusion": "研究成果表明，这种安全的思考干预方法能够有效降低大型语言模型在带有思考模式下的攻击成功率，从而减少 Jailbreak 风险。这种方法有助于减轻安全威胁，提高 LLM 的安全性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10029", "html_url": "https://arxiv.org/abs/2508.10029", "title": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs", "title_en": "Latent Fusion Jailbreak: Blending Harmful and Harmless Representations to Elicit Unsafe LLM Outputs", "authors": "Wenpeng Xing,Mohan Li,Chunqiang Hu,Haitao XuNingyu Zhang,Bo Lin,Meng Han", "background": "大型语言模型（LLMs）在各种语言任务中展示了令人印象深刻的性能，但它们容易受到 jailbreak 攻击的影响，这些攻击可以使模型绕过其安全性对齐。研究表明，这些攻击通过插值有害和无害的查询对的隐藏状态来触发禁止的响应。", "innovation": "提出了 Latent Fusion Jailbreak（LFJ），这是一种基于表示的攻击方法，通过插值有害和无害查询对的隐藏状态来触发禁止的响应。LFJ 选择具有高度主题和句法相似性的查询对，然后在关键层和标记上进行梯度引导插值，并通过优化来平衡攻击成功率、输出流畅性和计算效率。实验表明，LFJ 在 Vicuna 和 LLaMA-2 等模型上的攻击成功率平均为 94.01%，超过了现有方法。此外，还提出了一种对抗训练防御措施，可以显著降低攻击成功率。", "conclusion": "通过对抗训练，可以有效地抵抗 LFJ 攻击。消融研究验证了查询对选择、隐藏状态插值组件和优化策略对 LFJ 有效性的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10026", "html_url": "https://arxiv.org/abs/2508.10026", "title": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "title_en": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "authors": "Kai Zhao,Yanjun Zhao,Jiaming Song,Shien He,Lusheng Zhang,Qiang Zhang,Tianjiao Li", "background": "大型语言模型（LLMs）通过链式推理实现了复杂任务上的出色准确性，但在所有问题上均匀应用时，会面临过高的推理成本和延迟问题。", "innovation": "SABER框架提出了一种可切换、平衡的训练方法，使得LLMs具有用户可控的、基于令牌预算的推理能力。通过预设预算层级，模型在微调过程中由系统提示和长度感知的奖励指导，以遵守其分配的预算。同时，融入了无思考示例，确保即使在禁用显式推理时，模型仍保持可靠性。此外，SABER支持四种离散推理模式（NoThink、FastThink、CoreThink、DeepThink），允许用户在延迟与推理深度之间进行灵活权衡。", "conclusion": "在数学推理（MATH，GSM8K）、代码生成（MBPP）和逻辑推理（LiveBench-Reasoning）上，SABER展示了在严格预算下保持高准确性、有条不紊的性能下降和有效的跨尺度、跨域泛化的结果。特别是在MATH基准测试中，SABER-FastThink将推理长度减少了65.4%，并且相比基础模型提高了3.6%的准确性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10142", "html_url": "https://arxiv.org/abs/2508.10142", "title": "多轮谜题：评估LLMs的互动推理和战略对话", "title_en": "Multi-Turn Puzzles: Evaluating Interactive Reasoning and Strategic Dialogue in LLMs", "authors": "Kartikeya Badola,Jonathan Simon,Arian Hosseini,Sara Marie Mc Carthy,Tsendsuren Munkhdalai,Abhimanyu Goyal,Tomáš Kočiský,Shyam Upadhyay,Bahare Fatemi,Mehran Kazemi", "background": "大型语言模型（LLMs）在解决清晰完整陈述的问题上表现出色，但在处理内涵复杂的环境或互动任务时常常遇到困难，而这些都是大多数现实场景中常见的任务。这凸显了开发能够在逻辑上一贯地进行多轮对话、寻求信息并处理不完整数据的LLMs的迫切需求。", "innovation": "本文提出了一种新的基准测试，包括一系列多轮任务，每个任务都旨在测试特定的推理、互动对话和信息搜索能力。这些任务具有确定性的评分机制，无需人工干预即可进行评估。该基准测试使在前沿模型上的评估揭示了显著的空间。本文分析表明，大多数错误源于指令跟随不佳、推理失败和规划不足。此基准提供有关当前LLMs在处理复杂、互动场景中的优势和弱点的重要洞察，为未来旨在改进这些关键能力的研究提供了坚实平台。", "conclusion": "我们的基准提供有关当前LLMs在处理复杂、互动场景中的优势和弱点的重要洞察，为未来改进这些关键能力的研究提供了坚实平台。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10175", "html_url": "https://arxiv.org/abs/2508.10175", "title": "机器翻译难度估计", "title_en": "Estimating Machine Translation Difficulty", "authors": "Lorenzo Proietti,Stefano Perrella,Vilém Zouhar,Roberto Navigli,Tom Kocmi", "background": "机器翻译的质量已经开始在某些配置下达到近乎完美的水平。这些高质量的输出使得区分最先进的模型变得困难，并难以识别未来的改进领域。自动识别机器翻译系统难以处理的文本具有潜力，可以为开发更具区分性的评估和指导未来的研究提供帮助。因此，需要一种方法来估计翻译的难度，并基于预期的翻译质量定义文本的难度。", "innovation": "文章提出了翻译难度估计的任务，并提出了一个新的评估难度估计器的度量标准，用于评估基础方法和新方法。更重要的是，通过使用难度估计器来构建更具有挑战性的机器翻译基准，得以证明了难度估计器的实际用途。通过对比实验证明了专门模型（称为Sentinel-src）优于基于启发式的方法（如词稀缺性或句法复杂性）和基于语言模型的评判方法。文章还发布了两个改进的难度估计模型，Sentinel-src-24和Sentinel-src-25，可用于扫描大量文本集合并选择最有可能挑战当前机器翻译系统的文本。\r", "conclusion": "这些专用模型在评估翻译难度方面表现出色，能够识别出更多挑战现有的机器翻译系统，这对于进一步提高翻译质量具有重要意义。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10161", "html_url": "https://arxiv.org/abs/2508.10161", "title": "LaaJMeter：一种LaaJ评估框架", "title_en": "LaajMeter: A Framework for LaaJ Evaluation", "authors": "Gal Amram,Eitan Farchi,Shmulik Froimovich,Raviv Gal,Avi Ziv", "background": "大型语言模型（LLMs）在自然语言处理任务中的评估者角色，即LaaJ（LLM-as-a-Judge）越来越多地被采用。尽管LLaJ在一般领域中效果良好，但在特定领域中使用时会面临重大挑战。因为在这些领域中，标注数据稀缺且专家评估成本高，常用评价指标往往没有在特定领域得到验证，使得无法准确判断哪些指标能有效评估LLaJ的质量，以及何种阈值可以表明评价者的性能足够好。因此，本文旨在解决这些问题，通过引入LaaJMeter，一种基于模拟的控制框架，来进行LLaJ的元评价，从而帮助工程师在现实条件下系统分析评价指标，验证并细化适用于特定评估任务的LLaJ。", "innovation": "本文提出了LaaJMeter，一种针对LLaJ进行控制仿真的元评价框架。该框架允许工程师生成虚拟模型和评估者的数据，系统地在实际条件下分析评价指标。它有助于实践者验证和调整LLaJ，特别是测试指标是否可以区分出好坏不同的LLaJ，并估计评价者性能的适当阈值。通过代码翻译任务中的实证研究，该框架展示了不同评价指标在灵敏度上的差异，并强调了挑选评价指标时的判断原则的重要性。LaaJMeter为低资源环境下的LLaJ评估提供了一个可扩展且可扩展性强的解决方案，有助于确保NLP领域评估的信任性和可重复性。", "conclusion": "LaaJMeter提供了一种在低资源环境下评估LLaJ的可扩展且可扩展性强的解决方案。研究表明不同评价指标在灵敏度上的差异，并强调了指标选择的重要性。该框架的实施有助于确保LLaJ的评估在NLP领域的可信任性和可重复性方面得到保证。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10222", "html_url": "https://arxiv.org/abs/2508.10222", "title": "通过表情符号预测理解文本情感", "title_en": "Understanding Textual Emotion Through Emoji Prediction", "authors": "Ethan Gordon,Nishank Kuppa,Rigved Tummala,Sriram Anasuri", "background": "该项目通过四类深度学习架构（前馈网络、CNN、Transformer和BERT）探索了从短文本序列中预测表情符号的任务。研究使用了TweetEval数据集，并通过焦点损失和正则化技巧处理了类别不平衡问题。", "innovation": "研究创新之处在于采用了多种深度学习模型架构解决表情符号预测问题，并通过焦点损失和正则化技术解决了类别不平衡问题。特别地，研究强调了架构选择和超参数调节对于情感感知表情符号预测的重要性。", "conclusion": "研究结果表明，BERT因其预训练的优势在整体性能上表现最佳，而CNN在稀有表情符号类别的预测上表现更优。这项研究强调了架构选择和超参数调节在改善人机交互方面的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10180", "html_url": "https://arxiv.org/abs/2508.10180", "title": "高效的仅前向数据估值方法用于预训练大语言模型和视觉语言模型", "title_en": "Efficient Forward-Only Data Valuation for Pretrained LLMs and VLMs", "authors": "Wenlong Deng,Jiaming Zhang,Qi Zeng,Christos Thrampoulidis,Boying Gong,Xiaoxiao Li", "background": "量化单个训练样本的影响对于增强大型语言模型（LLMs）和视觉语言模型（VLMs）的透明性和可问责性至关重要。然而，现有的数据估值方法通常依赖于海森矩阵信息或模型重训练，这使得它们在应对十亿参数规模的模型时计算量成为限制.", "innovation": "该工作引入了一种名为For-Value的仅前向数据估值框架，它能够为大语言模型和视觉语言模型提供可扩展和高效的单前向传播影响估计。通过利用现代基础模型的丰富表示，For-Value计算直接基于单前向传播的简单闭式表达式，从而消除了昂贵的梯度计算需求。理论分析表明，For-Value能够通过捕捉训练样本与验证样本中隐藏表示和预测误差的对齐情况，准确估计单样本的影响.", "conclusion": "大规模实验表明，For-Value在识别有效微调示例以及检测错误标记数据方面，能够与基于梯度的方法相匹配甚至表现出色."}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10246", "html_url": "https://arxiv.org/abs/2508.10246", "title": "计算分析人造语言托克派拿语的语言变化与变异的方法", "title_en": "A Computational Approach to Analyzing Language Change and Variation in the Constructed Language Toki Pona", "authors": "Daniel Huang,Hyoun-A Joo", "background": "本研究探讨了约有120个核心词汇的人造语言托克派拿语的语言变化和变异。采用计算和基于语料库的方法，研究了流变性词类和及物性等特征，旨在考察内容词在不同句法位置上的偏好变化，以及不同语料库间的使用差异。", "innovation": "采用计算和基于语料库的方法，研究托克派拿语语言变化和变异。重点考察了内容词在不同句法位置上的偏好变化和不同语料库间的使用差异。发现人造语言也受社会语言学因素影响，如同自然语言一样。研究表明，人造语言系统在实际使用中也会自然演变。", "conclusion": "研究发现，托克派拿语的社会语言学因素影响与自然语言相似，即使是由社区使用的人造语言系统也会自然演变。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10186", "html_url": "https://arxiv.org/abs/2508.10186", "title": "PakBBQ: 一种文化适应的问答偏见基准", "title_en": "PakBBQ: A Culturally Adapted Bias Benchmark for QA", "authors": "Abdullah Hashmat,Muhammad Arham Mirza,Agha Ali Raza", "background": "随着大型语言模型（LLMs）在各个领域的广泛应用，确保这些模型在全球各个用户社区中的公平性变得至关重要。然而，大多数LLMs主要在西方中心的数据集上进行训练和评估，缺乏对低资源语言和地区背景的关注。为了弥补这一差距，引入了PakBBQ，这是一种基于原始的问答偏见基准集（BBQ）的跨文化扩展。", "innovation": "PakBBQ 是一个主要针对巴基斯坦当地文化和地区的扩展数据集，包含了超过214种模板，涉及8个分类共17180个问答对，涵盖八种偏见维度，包括年龄、残疾、外貌、性别、社会经济地位、宗教、地区关联性和语言形式化。此外，PakBBQ 的评估涵盖了模糊和明确区分的语境，以及负面提问和非负面提问的对比，这些都显示出简单提示工程策略在低资源环境下的偏见缓解重要性。", "conclusion": "实验结果表明，语境化基准测试和简单的提示工程策略对于巴基斯坦这样低资源环境下的偏见缓解至关重要，明确分辨上下文可以提高平均准确率，以乌尔都语为例，其在反歧视行为上表现尤为明显，而负面提问的框架效应则可以减少刻板印象响应的发生。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10226", "html_url": "https://arxiv.org/abs/2508.10226", "title": "使用大型语言模型测量精神分裂症高风险患者症状严重程度", "title_en": "Using Large Language Models to Measure Symptom Severity in Patients At Risk for Schizophrenia", "authors": "Andrew X. Chen,Guillermo Horga,Sean Escola", "background": "精神分裂症临床高风险（CHR）患者需要密切监测症状，以便为他们提供适当的治疗。现有的Brief Psychiatric Rating Scale (BPRS)是一种常用的测量工具，但它需要进行长时间结构化的访谈，因此在临床上的应用较少。研究利用大型语言模型（LLMs）从409名CHR患者的临床访谈记录中预测BPRS分数，发现尽管访谈内容并非专门针对测量BPRS，但零样本预测表现接近人类评定者之间的可靠性。进一步发现，LLMs在多语言环境中评估BPRS的准确性更高，并且可以利用纵向信息进行单样本或少数样本学习，从而改进和标准化CHR患者的评估过程。", "innovation": "本研究利用大型语言模型（LLMs）从CHR患者的临床访谈记录中预测BPRS分数，实现了在没有专门结构化访谈的情况下对患者症状的准确评估。此外，LLMs在多语言环境中表现更好，并能利用纵向信息实现单样本或少数样本学习，这为精神分裂症的诊断与治疗提供了新的途径和方法。", "conclusion": "研究结果表明，大型语言模型能够高效、准确地预测BPRS分数，即使是在非结构化的访谈记录中也能取得较好的表现。这表明LLMs可以在临床场景中用于改善和标准CHR患者的评估过程，并且在多语言环境中具有显著的优势。这些发现为未来的临床实践和研究提供了新的方向。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10295", "html_url": "https://arxiv.org/abs/2508.10295", "title": "LLM提示的归纳偏置提取与匹配", "title_en": "Inductive Bias Extraction and Matching for LLM Prompts", "authors": "Christian M. Angel,Francis Ferraro", "background": "当前，提示工程是一个活跃的研究领域，表明了大型语言模型（LLMs）对提示措辞小变化的敏感性。这种敏感性部分来源于LLMs固有的归纳偏置。通过利用LLMs的输出部分作为提示的一部分，可以更轻易地创建适合提示的措辞。这有助于让提示与模型的归纳偏置相匹配。近年来，已有研究发现，这种匹配策略能够显著提升LLM在分类中的Likert评分，最多可提高19%，以及在排序中的Likert评分，最多可提高27%。", "innovation": "本文提出了一种新的技术，即归纳偏置提取与匹配策略，通过这种方法利用LLM的输出作为提示的一部分，从而让提示更好地与模型的归纳偏置匹配。实验证明，这种策略可以显著提高LLM的评分。对于分类任务，评分提升可达19%；对于排序任务，评分提升可达27%。", "conclusion": "使用归纳偏置提取与匹配策略，能够显著提高LLM在分类和排序任务上的表现，分别提升了19%和27%。这种策略为提示工程提供了一个有效的方法，以更好地利用模型的内在偏置来提高模型的性能。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10304", "html_url": "https://arxiv.org/abs/2508.10304", "title": "另一种算法偏见：大型语言模型在性别和种族方面强化主导话语的述词汇分析", "title_en": "Yet another algorithmic bias: A Discursive Analysis of Large Language Models Reinforcing Dominant Discourses on Gender and Race", "authors": "Gustavo Bonil,Simone Hashiguti,Jhessica Silva,João Gondim,Helena Maia,Nádia Silva,Helio Pedrini,Sandra Avila", "background": "随着人工智能的发展，大型语言模型（LLMs）已经得到了广泛关注并在多种应用场景中得到应用。随着这些模型变得更加复杂，评估它们是否在生成过程中的确反映了歧视、种族化等偏见以及是否强化了社会主导话语显得尤为重要。当前的偏见检测方法大多依赖于定量的、自动化的方法，这些方法往往忽略了自然语言中偏见的复杂表现方式。因此，本文旨在提出一种基于质性分析的话语框架来补充现有的方法。我们通过人工分析LLM生成的包含黑人和白人女性的短篇故事，研究性别和种族偏见的表现。", "innovation": "本文提出了一种新的质性、话语分析框架，以此来评估大型语言模型生成内容中的性别和种族偏见。这种方法将人工分析与现有的量化方法相结合，旨在帮助开发人员和用户更好地识别并缓解偏见，从而促进更包容的叙事。研究发现，模型在纠正偏见时提供的修订往往是表面性的，并不能从根本上改变问题，这进一步揭示了在促进多元文化和包容性叙事方面人工智能技术的局限性。", "conclusion": "研究结果揭示了算法的意识形态功能，并对我人工智能的伦理使用和开发具有重要意义。此项研究强调了设计和部署人工智能时需要采用批判性的、跨学科的方法，关注LLM生成的话语如何反映并加剧社会不平等现象，并提出了解决这些问题的关键路径。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10308", "html_url": "https://arxiv.org/abs/2508.10308", "title": "ReviewRL: 向基于强化学习的科学评阅自动化迈进", "title_en": "ReviewRL: Towards Automated Scientific Review with RL", "authors": "Sihang Zeng,Kai Tian,Kaiyan Zhang,Yuru wang,Junqi Gao,Runze Liu,Sa Yang,Jingxuan Li,Xinwei Long,Jiaheng Ma,Biqing Qi,Bowen Zhou", "background": "科学进步依靠同行评审，但面对投稿量增加和评审疲劳的问题，同行评审面临越来越大的挑战。现有的自动化评审方法在事实准确性、评分一致性以及分析深度方面存在不足，往往生成的是表面化的或通用的反馈，缺乏高质量人类评审的洞察力。", "innovation": "本文提出了ReviewRL，这是一种基于强化学习的框架，用于生成全面和基于事实的科学论文评论。该方法结合了ArXiv-MCP检索增强上下文生成管道、监督微调以及强化学习程序和复合奖励函数，在提高评论质量和评分准确性方面表现出色。", "conclusion": "在ICLR 2025论文上进行的实验表明，ReviewRL在基于规则的指标和模型的质量评估中均显著优于现有方法。ReviewRL建立了一个基于强化学习的自动批评生成的基础框架，为该领域的未来发展展现了令人鼓舞的潜力。ReviewRL的实现将发布于GitHub。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10366", "html_url": "https://arxiv.org/abs/2508.10366", "title": "利用大规模语言模型和约束解码推进序列到序列模型中的跨语言方面基于情感分析", "title_en": "Advancing Cross-lingual Aspect-Based Sentiment Analysis with LLMs and Constrained Decoding for Sequence-to-Sequence Models", "authors": "Jakub Šmíd,Pavel Přibáň,Pavel Král", "background": "方面基于情感分析（ABSA）已经取得了显著的进展，但对于低资源语言来说，仍然存在挑战，因为当前研究主要集中在英文上。现有跨语言ABSA研究多集中在简单任务上，并大量依赖外部翻译工具。", "innovation": "提出了一种无需使用翻译工具的新型序列到序列方法来处理复合ABSA任务。该方法通过使用约束解码，将跨语言ABSA性能提高了10%。这种方法扩展了跨语言ABSA的应用范围，使其能够处理更复杂的任务，并为依赖翻译的大规模语言模型提供了一种高效的替代方案。研究还对比了这种方法与大型语言模型（LLMs），发现调优后的多语言LLMs可以取得相似的结果，而以英文为中心的LLMs则在这些任务上表现不佳。", "conclusion": "该方法显著提高了跨语言ABSA的性能和适用范围，提供了处理复杂任务的有效解决方案，并为未来的研究提供了新的方向。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10352", "html_url": "https://arxiv.org/abs/2508.10352", "title": "跨提示编码器用于低性能语言", "title_en": "Cross-Prompt Encoder for Low-Performing Languages", "authors": "Beso Mikaberidze,Teimuraz Saghinadze,Simon Ostermann,Philipp Muller", "background": "软提示作为一种在参数高效微调中稳定训练的小型神经提示编码器的参数交互的替代方法，已经成为了参数高效微调（PEFT）的重要工具，使得大型语言模型（LLMs）能够在没有架构改变或参数更新的情况下适应下游任务。尽管先前的工作集中在稳定小型神经提示编码器的训练，但其在不同语言间的广泛迁移潜力尚未得到探索。本文通过引入一种新的方法，证明提示编码器可以在提高低性能语言的性能方面发挥重要作用。", "innovation": "本文提出了一种跨提示编码器（XPE），它结合了一个轻量级编码架构和来自不同语言的语言类型多样性的多源训练，从而让模型能够在语言间捕捉到具有迁移性的模式。此外，提出了一种双软提示机制，它结合了基于编码器的软提示和直接训练的标准软提示，这种混合设计特别适用于需要具有广泛共享结构和语言特异性对齐的目标语言。", "conclusion": "实验表明，XPE对低性能语言最为有效，而混合变体则在多语言设置中提供了更广泛的适应性。这为提示编码器的应用提供了新的视角，并为低性能语言的适应性改进提出了新的方法。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10355", "html_url": "https://arxiv.org/abs/2508.10355", "title": "使用强化学习使Qwen3能够用韩语思考", "title_en": "Making Qwen3 Think in Korean with Reinforcement Learning", "authors": "Jungyup Lee,Jemin Kim,Sang Park,SeungJae Lee", "background": "提出了一种两阶段微调方法，旨在让大规模语言模型Qwen3 14B能够原生地使用韩语。第一阶段通过高质量的韩语逻辑推理数据集进行监督微调（SFT），增强了模型在韩语文本处理任务中的表现，并对通用推理能力也有所提升。第二阶段使用自定义的组相对策略优化（GRPO）算法结合强化学习，进一步增强了韩语逻辑推理和整体问题解决能力。", "innovation": "在GRPO训练中引入了一个判模型来校准奖励信号，解决了奖励黑客和策略崩溃等关键稳定性挑战，避免了GRPO中观察到的崩塌问题，实现了稳定的学习和逐步提高的性能。通过这种方法，优化后的模型在复杂推理基准测试中（特别是数学和编程任务）取得了显著改进，同时保持了知识和语言的专业水平，内部思考链全部用韩语完成。", "conclusion": "最终的强化学习调优模型在高级推理基准测试中表现显著提升（特别是在数学和编程任务），同时保持了其对知识和语言的理解能力，在训练过程中能够完全用韩语进行内部思考链的过程。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10311", "html_url": "https://arxiv.org/abs/2508.10311", "title": "从表面到语义：面向表格的文档语义结构解析", "title_en": "From Surface to Semantics: Semantic Structure Parsing for Table-Centric Document Analysis", "authors": "Xuan Li,Jialiang Dong,Raymond Wong", "background": "文档是信息和知识的核心载体，在金融、医疗和科学研究等领域具有广泛的应用。表格作为结构化数据的主要媒介，封装了关键信息并是最关键的文档组成部分。现有的研究重点主要聚焦在布局分析、表格检测和数据提取等表面层面上的任务，而缺乏对表格及其上下文关联的深层次语义解析。这限制了跨段落数据分析和上下文一致分析等高级任务的实现。", "innovation": "本文提出了一种名为DOTABLER的面向表格的语义文档解析框架，旨在揭示表格与其上下文之间的深层次语义链接。DOTABLER利用自定义数据集和特定领域的预训练模型微调，整合了一个完整的解析管道，以识别与表格语义连接的上下文段落。基于这种语义理解，DOTABLER实现出两种核心功能：面向表格的文档结构解析和特定领域的表格检索，提供全面的表格锚定的语义分析，并精确提取语意义相关的表格。评估结果显示，DOTABLER在真实世界PDF上的近4000页、超过1000个表格上达到了超过90%的精度和F1分数，表现出在表格上下文语义分析和深度文档解析方面优于如GPT-4o等先进模型的性能。", "conclusion": "DOTABLER框架能够在表格及其上下文间实现深层次的语义理解，提供全面的表格语义解析和精准的表格提取，表现出优异的性能。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10312", "html_url": "https://arxiv.org/abs/2508.10312", "title": "超出语义理解：在基于大语言模型的推荐系统中保留协作频率成分", "title_en": "Beyond Semantic Understanding: Preserving Collaborative Frequency Components in LLM-based Recommendation", "authors": "Minhao Wang,Yunhang He,Cong Xu,Zhangchi Zhu,Wei Zhang", "background": "推荐系统与大型语言模型（LLMs）结合展示了生成语义相关推荐的前景。然而，基于LLM的推荐系统倾向于过度强调用户交互历史中的语义关联。当使用预训练的协作ID嵌入作为输入时，基于LLM的推荐系统逐层削弱嵌入中的固有协作信号，与传统基于Transformer的序列模型相比，后者通常能够保留或增强协作信号以达到最佳性能。现有的方法对此缺乏有效的解决方案。因此，有必要提出一种新的方法来平衡语义和协作信息，从而改进基于LLMs的推荐系统的性能。", "innovation": "本研究引入了FreLLM4Rec方法，旨在从频谱角度平衡语义和协作信息。首先，通过全局图低通滤波器（G-LPF）净化项目嵌入，以初步去除无关的高频率噪声。然后，通过频域调节（TFM）逐层主动保留协作信号。研究证明，TFM能够通过连接优化但难以实现的局部图傅里叶滤波器和次优但计算高效的频域滤波器来理论确保协作信号的保留能力。实验结果显示，FreLLM4Rec成功地缓解了协作信号衰减，与最佳基线相比，NDCG@10的提升幅度可达8.00%。", "conclusion": "本研究为理解大语言模型如何处理协作信息提供了深入见解，并提出了一个原理性的改进策略，即FreLLM4Rec，以提高基于大语言模型的推荐系统性能。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10368", "html_url": "https://arxiv.org/abs/2508.10368", "title": "使用大型语言模型总结捷克历史文档及更广泛的应用", "title_en": "Large Language Models for Summarizing Czech Historical Documents and Beyond", "authors": "Václav Tran,Jakub Šmíd,Jiří Martínek,Ladislav Lenc,Pavel Král", "background": "文本摘要任务是将大量文本缩短为简洁版本，同时保留其核心含义和关键信息。虽然近年来在英文等高资源语言方面进行了大量的摘要工作，但由于语言复杂性和注释数据集稀缺，捷克文本摘要尤其是在历史文档方面的研究仍然不足。大型语言模型如Mistral和mT5在许多自然语言处理任务和语言中表现出色。因此，本文利用这些模型进行捷克语摘要，取得了两项关键贡献：一是使用这些先进技术模型在现代捷克语摘要数据集SumeCzech上获得了新的先进效果；二是引入了一个名为《切尔科夫的使者》的新数据集，用于历史文档的摘要，并提供了基线结果。这些贡献为捷克文本摘要的进一步发展提供了巨大潜力，并为捷克历史文本处理研究开辟了新的研究途径。", "innovation": "在现代捷克语摘要数据集SumeCzech上使用先进模型取得了新的先进效果；并提出了名为《切尔科夫的使者》的新数据集用于历史文档的摘要并验证了基线结果。", "conclusion": "通过使用大型语言模型来总结捷克历史文档，本文为捷克文本摘要技术的发展提供了重要贡献，并为相关领域的研究开启了新的可能性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10369", "html_url": "https://arxiv.org/abs/2508.10369", "title": "使用约束解码改进跨语言级分方面基础情感分析", "title_en": "Improving Generative Cross-lingual Aspect-Based Sentiment Analysis with Constrained Decoding", "authors": "Jakub Šmíd,Pavel Přibáň,Pavel Král", "background": "尽管方面级分情感分析（ABSA）取得了显著进展，但对于被忽视的低资源语言，依然存在挑战。当前的跨语言ABSA方法主要集中在较少复杂、较简单的任务上，并依赖于外部翻译工具。这些研究在最复杂的任务上平均提高了5%的跨语言性能。此外，研究还评估了大型语言模型在零样本、少量样本和微调场景下的表现，发现尽管大型语言模型在这种场景下表现不佳，但微调相比小型多语言模型在表现上具有竞争力，但代价是较长的训练时间和推理时间。", "innovation": "该论文提出了一种新的使用约束解码的序列到序列模型方法，该方法不需要不可靠的翻译工具，并且在最复杂的任务上提高了5%的跨语言性能。该方法还支持多任务学习，可以通过一个模型解决多个ABSA任务，约束解码可以提高效果超过10%。此外，该研究还评估了大型语言模型在零样本、少量样本和微调场景下的表现，提供了实用建议以增强跨语言ABSA方法的理解，并为这一具有挑战性的研究领域推进了最新的方法。", "conclusion": "该研究结果表明，使用约束解码的方法在跨语言ABSA方面取得了显著进步。它对于以前未探索的任务设定了新的基准，并提供了有关大型语言模型在零样本、少量样本和微调场景下的表现，以及如何优化跨语言ABSA方法的实用建议。这一研究为跨语言ABSA技术的进步和理解提供了有价值的洞察。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10390", "html_url": "https://arxiv.org/abs/2508.10390", "title": "使用显性有害提示破解商用黑盒大语言模型", "title_en": "Jailbreaking Commercial Black-Box LLMs with Explicitly Harmful Prompts", "authors": "Chiyu Zhang,Lu Zhou,Xiaogang Xu,Jiafei Wu,Liming Fang,Zhe Liu", "background": "评估越狱攻击具有挑战性，尤其是在提示不明显有害或未引发有害输出时。现有的一些红队数据集包含不合适的提示，这些提示并不足以对攻击进行准确评估。为了提高准确性，这些数据集需要从恶意内容中筛选出来。然而，现有恶意内容检测方法依赖于人工标注，这过程劳力密集且费时，或者依赖大型语言模型，这些模型在辨别有害内容方面没有一致性。因此，需要一种能够平衡准确性和效率的方法来解决这一问题。", "innovation": "提出了一种基于大语言模型与最少人工监督的混合评估框架（MDH），以清洗数据集和检测越狱响应。此外，发现精心设计的开发人员消息显著提高了越狱的成功率，因此提出了两种新的策略：D-Attack（利用上下文模拟）和DH-CoT（结合被劫持的思考链）来破解商用黑盒大语言模型。", "conclusion": "该研究提供了一种新型的混合评估框架MDH，通过最小化人工干预利用大语言模型进行恶意内容检测，同时提出两种新策略D-Attack和DH-CoT来破解商用黑盒大语言模型，并公开了代码、数据集、判断结果和检测结果以供进一步研究。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10421", "html_url": "https://arxiv.org/abs/2508.10421", "title": "评价大型语言模型在汉语成语翻译中的表现", "title_en": "Evaluating LLMs on Chinese Idiom Translation", "authors": "Cai Yang,Yao Dou,David Heineman,Xiaofeng Wu,Wei Xu", "background": "成语因其比喻意义与字面意义的不同而在日常语言中十分常见，特别是在中文中，它们往往包含历史参考，并遵循特定的结构模式。尽管大型语言模型在机器翻译方面取得了显著进展，但关于中文成语翻译的研究仍较为欠缺。", "innovation": "本研究介绍了IdiomEval框架，这是一个包含全面错误分类学的汉语成语翻译评估框架。研究团队为四种领域（网络、新闻、维基百科、社交媒体）中的九个现代系统（包括GPT-4o和谷歌翻译）标注了900对翻译样本。研究成果显示现有评估指标在衡量成语质量方面表现不佳，并开发了新的模型以提高成语翻译错误检测的F1分数。", "conclusion": "最佳系统GPT-4在成语翻译中的错误率为28%，现有评价指标与人工评分的相关性低于0.48。新模型在检测成语翻译错误方面达到了F1得分0.68。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10404", "html_url": "https://arxiv.org/abs/2508.10404", "title": "通过稀疏自动编码器进行逐层扰动的对抗文本生成", "title_en": "Layer-Wise Perturbations via Sparse Autoencoders for Adversarial Text Generation", "authors": "Huizhen Shu,Xuying Li,Qirui Wang,Yuji Kosuga,Mengqiu Tian,Zhuo Li", "background": "随着自然语言处理（NLP）尤其是大型语言模型（LLMs）的快速发展，生成用于突破LLMs的对抗样本以探究模型脆弱性和提升鲁棒性仍然是一个关键挑战。本文基于此背景提出了一种新的黑盒攻击方法，通过利用大型模型的可解释性。", "innovation": "本文引入了一种新颖的对抗文本生成方法——稀疏特征扰动框架（SFPF）。该方法利用稀疏自编码器识别和操作文本中的关键特征，并通过对成功攻击的文本进行特征聚类识别高激活特征，进而扰动这些特征以生成新的对抗文本。这种选择性扰动在保持恶意意图的同时增强了安全性信号，提高了对抗文本的防御规避能力。这种方法能够平衡对抗效果与安全性对齐的新红队策略，实验证明SFPF生成的对抗文本能够规避最新的防御机制，揭示了当前NLP模型中存在的持久性漏洞。", "conclusion": "本方法展示了对抗文本生成的新策略，证明了通过SFPF生成的对抗文本能够规避最先进的防御机制，但其在不同提示和层级上的效果存在差异，且在其他架构和更大模型上的普适性仍需验证。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10426", "html_url": "https://arxiv.org/abs/2508.10426", "title": "在大型语言模型中实施计算经济学：在资源约束下探索模型行为和激励设计", "title_en": "Computational Economics in Large Language Models: Exploring Model Behavior and Incentive Design under Resource Constraints", "authors": "Sandeep Reddy,Kabir Khan,Rohit Patil,Ananya Chakraborty,Faizan A. Khan,Swati Kulkarni,Arjun Verma,Neha Singh", "background": "大型语言模型（LLMs）受到显著计算成本的限制。本文介绍了一种“计算经济学”框架，将其视为资源受限代理（注意力头和神经块）的内部经济体系，这些代理必须合理分配稀缺的计算资源以最大化任务效用。研究通过实验证明，当计算资源稀缺时，标准LLMs会重新分配注意力重心，向高价值标记倾斜，同时保持准确性。这一观察结果为基础，提出了一个激励驱动的训练范式，通过加入可微计算成本项来改进任务损失，鼓励稀疏且高效的激活。这项方法在GLUE（MNLI，STS-B，CoLA）和WikiText-103数据集上取得了显著效果。", "innovation": "提出了一种基于计算经济学原理的激励驱动训练范式，通过将不同的计算成本术语加入到任务损失中，鼓励模型优化计算资源利用，从而实现模型在同等准确性前提下的计算量显著减少和延迟降低，同时提高了注意力机制的可解释性。", "conclusion": "研究结果表明，经济原则为在严格资源限制下设计高效、适应性强且更透明的大型语言模型提供了有效的途径。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10482", "html_url": "https://arxiv.org/abs/2508.10482", "title": "当解释性和隐私性交汇：后验解释性和差分隐私在自然语言处理中的交集调查", "title_en": "When Explainability Meets Privacy: An Investigation at the Intersection of Post-hoc Explainability and Differential Privacy in the Context of Natural Language Processing", "authors": "Mahdi Dhaini,Stephen Meisenbacher,Ege Erdogan,Florian Matthes,Gjergji Kasneci", "background": "在研究可信赖的自然语言处理（NLP）领域，已经出现了诸如可解释性和隐私性等重要的研究领域。尽管近年来在可解释性和隐私保护NLP方面的研究兴趣显著增加，但在可解释性和隐私性的交汇点上仍然缺乏调查，这使得理解同时实现这两者是否可能，或者它们是否相互冲突存在较大差距。", "innovation": "本文通过探讨后验解释性和差分隐私在NLP中的隐私解释权衡，填补了这一空白。研究由流行的总体方法指导，即差分隐私（DP）和后验解释性。研究结果揭示了隐私和解释之间的复杂关系，这一关系由诸如下游任务的性质和文本隐私化与解释方法的选择等因素形成。论文强调了隐私和解释共存的潜力，并为这一重要交集的未来工作提供了实用建议。", "conclusion": "本文通过实证研究揭示了隐私和解释之间的权衡关系，并为隐私保护和解释性的共存提出了实用建议，填补了可解释性和隐私性研究的空白。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10444", "html_url": "https://arxiv.org/abs/2508.10444", "title": "DiFaR: 使用多样、准确且相关的理由提高多模态错误信息检测", "title_en": "DiFaR: Enhancing Multimodal Misinformation Detection with Diverse, Factual, and Relevant Rationales", "authors": "Herun Wan,Jiaying Wu,Minnan Luo,Xiangzheng Kong,Zihan Ma,Zhi Zeng", "background": "从大型视觉-语言模型（LVLMs）生成文本理由以支持可训练的多模态错误信息检测器这一方式逐渐成为一种有前景的方向。然而，这种方式的有效性受到了三大核心挑战的限制：（i）生成理由的多样性不足，（ii）事实不准确导致的幻觉，（iii）无关或冲突的内容导致噪声的引入。", "innovation": "引入了DiFaR，一种面向任何检测器的框架，可生成多样、准确且相关的理由以增强错误信息检测效果。DiFaR 采用了五种思路链提示来激发LVLMs的各种推理轨迹，并集成了一个轻量级后处理筛选模块，根据句子的准确性和相关性评分来选择理由句子。广泛在四个流行基准上的实验表明，DiFaR 在四个基线类别中表现出了高达5.9%的提升，并且能够使现有的检测器的性能最多提高8.7%。自动评价指标和人工评估都证实，DiFaR 显著提升了理由的质量。", "conclusion": "DiFaR通过生成多样、准确且相关的理由，成功解决了传统方法中的三大核心挑战，并通过实验证明了其显著的性能提升和理由质量改进。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10419", "html_url": "https://arxiv.org/abs/2508.10419", "title": "ComoRAG：基于认知启发的记忆组织式的RAG方法用于有状态的长叙述推理", "title_en": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": "Juyuan Wang,Rongchen Zhao,Wei Wei,Yufeng Wang,Mo Yu,Jie Zhou,Jin Xu,Liyan Xu", "background": "长故事和小说的叙述理解是一个具有挑战性的领域，因为它们有复杂的故事情节和人物以及实体之间复杂的、经常变化的关系。现有的语言模型（LLM）在处理长时间背景时推理能力减弱，加之高昂的计算成本，使得检索式方法仍然是实践中的关键手段。然而，传统的检索增强生成（RAG）方法往往由于它们无状态且仅在单一步骤中的检索过程，难以捕捉长范围内联系的人物和实体之间的动态关系。针对这些问题，该论文旨在提出ComoRAG方法，该方法认为叙述推理不是一个一次性过程，而是一个动态演化的过程，涉及从新证据学习和过去知识整合之间不断迭代的互动，类似于人类在脑部记忆信号相关推理中的认知过程。", "innovation": "ComoRAG提出了一种基于认知启发的记忆组织式的RAG方法。在遇到推理困境时，ComoRAG将通过迭代推理循环来在动态记忆工作空间中进行互动，在每一个循环中，它会生成探索性问题，然后将新检索到的证据整合进入全局记忆池中，从而支持查询解决过程中总体叙述背景的形成。实验结果显示，ComoRAG在四个具有挑战性的长背景叙述基准上显著优于强的RAG基线，尤其是对于需要全局理解的复杂查询具有明显优势，这表明其提供了一种理由充分且受认知导向的整体推理检索范式，以实现有状态的长上下文推理。", "conclusion": "ComoRAG通过迭代的推理循环和动态记忆工作空间的设计，在长文本的理解和推理上展现了显著的优势。它不仅在四项基准上持续超越传统基线模型，还提供了一种拥有更全面推理能力的认知启发式有状态推理方法，为长文本的理解提供了新的视角。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10683", "html_url": "https://arxiv.org/abs/2508.10683", "title": "古埃及语-法语神经机器翻译：低资源古代语言的翻译策略", "title_en": "Neural Machine Translation for Coptic-French: Strategies for Low-Resource Ancient Languages", "authors": "Nasma Chaoui,Richard Khoury", "background": "该论文是首个系统研究将古埃及语翻译成法语的策略。研究利用了对齐的圣经语料库，分析了多种翻译方法的有效性，包括直接翻译与通过枢纽语言翻译的比较、预训练的影响、多版本微调的好处以及模型对噪声的鲁棒性。", "innovation": "论文提出了综合的管道方法来系统性地评估不同翻译策略，展示了使用多样风格且具有噪声提示的训练语料库进行微调可以显著提高翻译质量，并为开发历史语言的翻译工具提供关键的实践指导。", "conclusion": "研究发现，通过噪声感知训练语料库进行微调可以显著提升翻译质量，为古埃及语等低资源古代语言的翻译提供了重要的见解和关键的实用建议。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10552", "html_url": "https://arxiv.org/abs/2508.10552", "title": "当语言占上风：揭示多模态大型语言模型中的文本主导", "title_en": "When Language Overrules: Revealing Text Dominance in Multimodal Large Language Models", "authors": "Huyu Wu,Meng Tang,Xinhan Zheng,Haiyun Jiang", "background": "多模态大型语言模型（MLLMs）已经在多种多模态任务中展示了卓越的能力。然而，这些模型存在一个核心问题，即文本主导性：它们在推理过程中过分依赖文本，而忽视了其他模态的信息。尽管先前的研究已经注意到了这一现象，并常将其归因于数据偏差或模型架构，但本研究首次系统地调查了文本主导性在图像、视频、音频、时间序列和图形等多种数据模态中的问题。为了衡量这种不平衡，研究提出两种评估指标：模态主导指数（MDI）和注意效率指数（AEI）。研究表明，文本主导性在所有测试的模态中都存在，并且影响显著。研究还识别了三个底层原因：非文本模态中严重词汇冗余导致的注意稀释、融合架构设计的影响以及任务设计对文本输入的倾向性。", "innovation": "文章提出了模态主导指数（MDI）和注意效率指数（AEI）两种度量不平衡的新方法，并通过简化词汇压缩方法有效地平衡了模型的注意分配。以LLaVA-7B模型为例，这种方法使其MDI值从10.23显著降低到0.86，使得模型更加平衡。", "conclusion": "研究与方法提供了发展更加公平和综合的多模态语言模型的基础，强调了更好地理解并缓解文本主导性对多模态任务的重要意义。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10736", "html_url": "https://arxiv.org/abs/2508.10736", "title": "在Mask中思考：Diffusion LLMs中的在场提示", "title_en": "Thinking Inside the Mask: In-Place Prompting in Diffusion LLMs", "authors": "Xiangqi Jin,Yuxuan Wang,Yifeng Gao,Zichen Wen,Biqing Qi,Dongrui Liu,Linfeng Zhang", "background": "尽管大型语言模型（LLMs）取得了显著的成功，但它们的前缀提示范式和顺序生成过程在处理双向信息时提供了有限的灵活性。Diffusion大语言模型（dLLMs）通过双向注意机制和迭代优化过程展现了新的机遇，使更灵活的在场提示策略成为可能。", "innovation": "我们引入了ICE（In-Place Chain-of-Thought Prompting with Early Exit），这是一种新的框架，将前缀提示转换为专门为dLLMs设计的在场提示。ICE直接在迭代优化过程中的遮盖标记位置集成在场提示，并采用一种基于可信度的早期退出机制，显著减少了计算开销。", "conclusion": "广泛实验表明，ICE的有效性显著，GSM8K上提高高达17.29%的正确率，MMLU上加速达到276.67倍，同时保持了竞争力。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10687", "html_url": "https://arxiv.org/abs/2508.10687", "title": "连续性孟加拉手语翻译：借助图辅助减轻手语注释代价", "title_en": "Continuous Bangla Sign Language Translation: Mitigating the Expense of Gloss Annotation with the Assistance of Graph", "authors": "Safaeid Hossain Arib,Rabeya Akter,Sejuti Rahman", "background": "全球数百万个个体受到耳聋和听力障碍的影响。手语作为一种复杂的沟通方式，对于聋人和听力障碍者至关重要。然而，在重视有声语言的社会中，手语往往被低估，从而导致沟通障碍和社会排斥。Continuous Bangla Sign Language Translation项目旨在通过改进翻译方法来解决这一问题。虽然近年来基于transformer架构的方法取得了最先进的结果，但我们的方法通过融合基于图的方法与transformer架构进一步提升，特别是在无手语签注的情况下。", "innovation": "我们的贡献包括架构融合，探索各种融合策略，以及在RWTH-PHOENIX-2014T、CSL-Daily、How2Sign和BornilDB v1.0等多样化的手语数据集上实现了新的最先进的性能。我们的方法显示了比现有翻译结果更优越的表现，特别是在所有数据集上的BLEU-4得分方面，分别是4.01、2.07和0.5，超过GASLT、GASLT和slt_how2sign等现有方法。此外，我们首次在BornilDB v1.0数据集上进行了基准测试，为未来研究设立了基准，强调无手语签注翻译的重要性，以提高聋人和听力障碍者的沟通可及性。", "conclusion": "我们的方法为未来的研究设立了基准，并强调了无手语签注翻译的重要性，以改善聋人和听力障碍者的沟通可达性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10695", "html_url": "https://arxiv.org/abs/2508.10695", "title": "从自然语言反馈学习实现个性化问答", "title_en": "Learning from Natural Language Feedback for Personalized Question Answering", "authors": "Alireza Salemi,Hamed Zamani", "background": "个性化对于增强语言技术的有效性和用户满意度至关重要，尤其是在信息查找任务，如问答中。目前，个性化大型语言模型（LLMs）的方法通常依赖于检索增强生成（RAG），随后通过带有标量奖励信号的强化学习来教会模型如何利用检索到的个人背景。但标量奖励有时提供的是弱且非指令性的反馈，限制了学习效率和个人化质量。", "innovation": "本研究提出了一种名为VAC的新型个性化响应生成框架，它用基于用户资料和问题叙述生成的自然语言反馈（NLF）替代了标量奖励。NLF作为丰富且可操作的监督信号，使策略模型能够迭代优化输出，并内化有效的个性化策略。训练交替优化反馈模型和微调策略模型在改进后的响应上，从而产生了不再需要在推理阶段提供反馈的策略模型。在LaMP-QA基准测试中，该研究展示了在三个不同领域的持续且显著的改进，且人类评估进一步确认了生成回复的质量。", "conclusion": "这些结果表明，NLF提供了更有效的信号来优化个性化问答。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10553", "html_url": "https://arxiv.org/abs/2508.10553", "title": "eDIF: 一个用于远程解释大型语言模型的欧洲深度推理织网", "title_en": "eDIF: A European Deep Inference Fabric for Remote Interpretability of LLM", "authors": "Irma Heithoff. Marc Guggenberger,Sandra Kalogiannis,Susanne Mayer,Fabian Maag,Sigurd Schacht,Carsten Lanquillon", "background": "欧洲对于大型语言模型（LLM）解释基础设施的广泛可访问性的需求推动了这一举措，旨在为研究社区普及高级模型分析能力。因此，本文提出了对部署欧洲深度推理织网（eDIF）的研究，eDIF是一种与NDIF兼容的基础设施，旨在支持大规模语言模型的因果解释研究。该项目在应用科学大学Ansbach托管了一个基于GPU的集群，并连接到合作伙伴机构，以支持远程模型检查。这为来自欧洲各地的研究人员提供了平台的技术性能、易用性和科学用途方面的初步评估。研究结果表明，用户对远程实验功能有积极的反馈，平台性能稳定，用户参与度提高。然而，系统的瓶颈包括激活数据的长时间下载以及间歇性执行中断，这些问题将在未来的发展计划中得到解决。", "innovation": "该计划介绍了对一个基于GPU的集群的部署，该集群在应用科学大学Ansbach托管，并连接到合作伙伴机构，以支持远程模型检查。此外，还进行了结构调整的试点研究，涉及来自欧洲各地的16名研究人员，测试了平台的技术性能，易用性和科学用途。激活数据长时间下载和间歇性执行中断等限制措施已经有了解决方案，成为未来发展的路线图的一部分。这标志着向欧洲广泛提供LLM解释基础设施的重要步骤，为进一步部署、扩展工具和持续社区合作铺平了道路。", "conclusion": "该研究揭示了用户参与度的逐步增加，平台性能的长期稳定性，以及对远程实验功能的积极评价。研究还标志着围绕该平台建立用户社区的起点。未来的开发路线图将重点解决下载激活数据所需的时间过长以及间歇性执行中断等问题，为更广泛的部署和用户合作奠定了基础。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10795", "html_url": "https://arxiv.org/abs/2508.10795", "title": "超越“不够新颖”：通过LLM辅助反馈丰富学术评价", "title_en": "Beyond \"Not Novel Enough\": Enriching Scholarly Critique with LLM-Assisted Feedback", "authors": "Osama Mohammed Afzal,Preslav Nakov,Tom Hope,Iryna Gurevych", "background": "新型性评估是同行评审的核心但较为欠缺的一部分，特别是在NLP这类研究量大、评审员能力日益紧张的领域。本文探讨了一种结构化的自动化新颖性评估方法，通过三个阶段建模专家评审员的行为：提交内容提取，相关工作检索与合成，以及结构化比较以进行基于证据的评估。该方法借鉴了大范围的人类撰写的新颖性评审分析，并捕捉到了独立主张验证和环境推理等关键模式。", "innovation": "该方法在182个ICLR 2025提交论文的评估中取得了86.5%的人类推理一致性率和75.3%的新颖性结论一致性率，明显优于现有的基于LLM的方法。该方法生成详细的、对文献了解的分析，并改进了随意评审员判断的一致性。这些结果突显了结构化LLM辅助方法支持更严谨和透明的同行评审的潜力，而不会取代人类专家的经验。", "conclusion": "结构化LLM辅助方法支持更严谨和透明的同行评审，同时保留了人类专家的作用。数据和代码已公开提供。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10839", "html_url": "https://arxiv.org/abs/2508.10839", "title": "强化语言模型在序列决策中的应用", "title_en": "Reinforced Language Models for Sequential Decision Making", "authors": "Jim Dilkes,Vahid Yazdanpanah,Sebastian Stein", "background": "大语言模型（LLMs）在顺序决策代理方面显示出潜力，但由于依赖于大型、计算密集型的模型，其应用受到限制。虽然现有的一些后训练方法适用于单步骤交互，但不能处理多步骤代理任务中的信用分配问题。因此，研究者们需要改进小型模型，并开发新的算法以解决多步骤任务中的信用分配问题。", "innovation": "本文提出了Multi-Step Group-Relative Policy Optimization (MS-GRPO)，这是一种基于正式的文本中介随机博弈（TSMG）和语言代理策略（LAP）框架的新算法。MS-GRPO针对多步骤任务中的信用分配问题提出了新的解决方案，该方法将整个累计回合奖励分配给每个个体回合步骤。此外，研究者还开发了一种新颖的绝对优势加权回合抽样策略，该策略被证明可以提高训练性能。实验结果表明，通过后训练30亿参数的模型在Snake和Frozen Lake任务中表现出色。与720亿参数的基线模型相比，所提出的后训练方法在Frozen Lake任务上的性能提高了50%。", "conclusion": "这项工作证明了针对后训练的方法是一种实用且高效的替代方案，可以使用大语言模型创建序列决策代理，而不必依赖于模型规模。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10848", "html_url": "https://arxiv.org/abs/2508.10848", "title": "Psyche-R1：通过统一同理心、专业知识和推理实现可靠的心理咨询大语言模型", "title_en": "Psyche-R1: Towards Reliable Psychological LLMs through Unified Empathy, Expertise, and Reasoning", "authors": "Chongyuan Dai,Jinpeng Hu,Hongchang Shi,Zhuo Li,Xun Yang,Meng Wang", "background": "在合格的心理健康专业人员短缺的情况下，将大型语言模型（LLMs）整合到心理应用中提供了一种缓解心理障碍增长负担的有前途的方法。尽管最近增强推理的LLMs在数学和编程方面表现出色，但心理领域的研究主要集中在情感支持和同理对话上，对有助于产生可靠回答的推理机制关注较少。因此，本文提出Psyche-R1，这是首个将同理心、心理学专长和推理相结合的中文心理LLM，基于新颖的数据整理管道构建。", "innovation": "设计了一个全面的数据合成管道，生成75,000多个高质量的心理学问题及其详细推理，使用链式思考（CoT）推理和迭代提示-推理优化策略，以及73,000个同理对话。随后采用了一种混合训练策略：使用多LLM跨选择策略识别有挑战性的样本进行组相对策略优化（GRPO），以提高推理能力，其余数据用于监督微调（SFT）以增强同理反应生成和心理领域的知识。", "conclusion": "广泛的实验结果证明了Psyche-R1在多个心理基准测试中的有效性，其中我们的7B Psyche-R1在基准测试中达到了与671B DeepSeek-R1相当的结果。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10860", "html_url": "https://arxiv.org/abs/2508.10860", "title": "从黑箱到透明：在大学课堂中通过可解释AI提升自动化口译评估", "title_en": "From Black Box to Transparency: Enhancing Automated Interpreting Assessment with Explainable AI in College Classrooms", "authors": "Zhaokun Jiang,Ziyin Zhang", "background": "近年来，机器学习的最新进展激发了人们对自动口译质量评估的兴趣。然而，现有研究存在对语言使用质量考察不足、由于数据稀缺和不平衡导致的模型效果不佳，以及缺乏解释模型预测努力等问题。为解决这些问题，我们提出了一种多维度建模框架，整合了特征工程、数据扩增和可解释机器学习。这种方法强调可解释性而非“黑盒”预测，仅使用与结构相关、透明的特征，并进行了Shapley Value分析。", "innovation": "提出了一种多维度建模框架，整合了特征工程、数据扩增和可解释机器学习。该方法强调可解释性而非“黑盒”预测，只使用与结构相关、透明的特征，并进行了Shapley Value分析。通过这种方法，我们发现BLEURT和CometKiwi分数是忠实度预测的最强有力特征，停顿相关特征是流畅度预测的特征，而汉语特定短语多样性指标是语言使用预测的特征。", "conclusion": "通过特别强调解释性，我们提供了一种可扩展、可靠和透明的替代传统人工评估的方案，这不仅为学习者提供详细的诊断反馈，还支持自动化评分所无法提供的自我调节学习优势。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10874", "html_url": "https://arxiv.org/abs/2508.10874", "title": "SSRL: 自身搜索强化学习", "title_en": "SSRL: Self-Search Reinforcement Learning", "authors": "Yuchen Fan,Kaiyan Zhang,Heng Zhou,Yuxin Zuo,Yanxu Chen,Yu Fu,Xinwei Long,Xuekai Zhu,Che Jiang,Yuchen Zhang,Li Kang,Gang Chen,Cheng Huang,Zhizhou He,Bingning Wang,Lei Bai,Ning Ding,Bowen Zhou", "background": "本文研究了大规模语言模型（LLMs）在强化学习（RL）中作为高效搜索代理任务模拟器的潜力，以减少对外部搜索引擎的依赖。", "innovation": "1. 通过结构化提示和重复抽样量化了LLMs的内在搜索能力，并称为Self-Search；2. 通过基于格式和规则的奖励引入了Self-Search RL（SSRL），增强LLMs的Self-Search能力；3. 实验表明，SSRL训练的策略模型为搜索驱动的RL训练提供了一种成本效益高且稳定的环境，减少了对外部搜索引擎的依赖，促进了可靠的仿真实验到现实世界的转移。", "conclusion": "1. LLMs包含可以有效激发的世界知识以实现高性能；2. SSRL展示了利用内部知识减少幻觉的潜力；3. SSRL训练的模型无缝集成到外部搜索引擎中，无需额外努力。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10875", "html_url": "https://arxiv.org/abs/2508.10875", "title": "对扩散语言模型的综述", "title_en": "A Survey on Diffusion Language Models", "authors": "Tianyi Li,Mingda Chen,Bowei Guo,Zhiqiang Shen", "background": "扩散语言模型（DLMs）作为一种快速崛起的强大替代方案在自然语言处理领域开始崭露头角，它们通过迭代去噪过程并行生成词元，从而减少推理延迟，捕获双向文脉，提供生成过程的细粒度控制能力。虽然加速了几倍，但最近的进步使得DLMs的表现与自动化回归模型相当，适合多种自然语言处理任务。", "innovation": "本文综述了扩散语言模型的当前状况。综述了其演变过程，并与自回归和遮蔽语言模型等相关范式的联系。涵盖了基础知识、前沿模型，并提供了预训练策略到高级后训练方法的最新技术的全面分类和深入分析。详细回顾了扩散语言模型的推理策略和优化措施，包括解码并行性、缓存机制和生成质量的改进。同时，尚且探讨了扩散语言模型在多模态扩展方面的最新方法及其在各种实际场景中的应用。", "conclusion": "尽管扩散语言模型存在效率、长序列处理和基础设施需求等方面的问题与挑战，但本文为该领域未来的研究方向提供了展望，旨在维持这一快速发展的领域的进步。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10031", "html_url": "https://arxiv.org/abs/2508.10031", "title": "Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs", "title_en": "Context Misleads LLMs: The Role of Context Filtering in Maintaining Safe Alignment of LLMs", "authors": "Jinhwa Kim,Ian G. Harris", "background": "尽管大型语言模型（LLMs）在性能上取得了显著进步，各种锁库攻击（jailbreak attacks）也给安全性和伦理带来日益增长的风险。恶意用户常利用对抗性上下文欺骗LLMs，使其生成对有害查询的回应。在本研究中，我们提出了一个新防御机制——上下文过滤模型，这是一种输入预处理方法，旨在过滤掉不可信和不可靠的上下文，同时识别主要提示语以揭示隐藏的恶意意图。", "innovation": "本研究提出了一种新的防御机制——上下文过滤模型，这是一种输入预处理方法，旨在过滤掉不可信和不可靠的上下文，同时确定主要提示语，揭示隐藏的恶意意图。我们的方法旨在提高LLMs的安全性，同时保留其原始性能，通过与最先进的防御机制进行对比分析，评估其在六种不同攻击下的有效性，同时评估这些防御下的LLMs的有用性。我们模型能够在不降低原始LLMs性能的情况下，将锁库攻击的成功率降低至88%，实现了最先进的安全保障和有用性结果。", "conclusion": "我们的模型是一个即插即用的方法，可以应用于包括白盒和黑盒模型在内的所有LLMs，以增强其安全性，无需对模型本身进行微调。我们将公开我们的模型供研究使用。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10068", "html_url": "https://arxiv.org/abs/2508.10068", "title": "SaraCoder: 为了利润导向的仓库级代码补全文本调度深层语义和结构线索", "title_en": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion", "authors": "Xiaohan Chen,Zhongying Pan,Quan Feng,Yu Tian,Shuqun Yang,Mengru Wang,Lina Gong,Yuxia Geng,Piji Li,Xiang Chen", "background": "现有的代码补全系统，如RAG，主要依赖于表面的文本相似性来进行检索，这导致了在语义指导方面的误导、冗余和同质性问题。此外，它们也不能有效解决外部符号的歧义性，这在多文件跨文件引用时会变得更加明显。这些挑战限制了当前系统的效果和实用性。因此，需要开发新的方法来系统性地改善候选代码的检索结果，以提供更准确、更鲁棒的仓库级代码补全系统。", "innovation": "我们提出了一种名为Saracoder的多层级特征优化检索框架。Saracoder的核心模块通过提炼深层次的语义关系、去除精确的重复项、利用一种基于图的新的结构相似性度量来评估编辑的拓扑重要性，并重新排序结果以最大化相关性和多样性来系统地优化候选代码。Saracoder还引入了一个为了识别文件间的符号歧义而进行依赖分析的外部意识标识符解析模块。实验结果表明，Saracoder在多种编程语言和模型下显著优于现有的基线系统，展示了多层次地优化检索结果的新思路。", "conclusion": "我们的研究表明，系统性地在多个层面对检索结果进行优化和调整，可以有效解决现有仓库级代码补全系统的局限性，从而为构建更准确、更鲁棒的代码补全系统提供了一个新框架。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10239", "html_url": "https://arxiv.org/abs/2508.10239", "title": "在线会议中的个性化实时术语支持", "title_en": "Personalized Real-time Jargon Support for Online Meetings", "authors": "Yifan Song,Wing Yee Au,Hon Yung Wong,Brian P. Bailey,Tal August", "background": "跨学科沟通经常受到领域特定术语的阻碍。研究团队通过一项由16名专业人士参与的形成性日记研究，发现当前的工作场所会议中领域特定术语管理策略存在关键限制，希望通过深入探讨这些问题来解决术语壁垒问题。", "innovation": "团队设计了一个基于LLM的互动系统ParseJargon，能够实时识别并解释用户个性化背景下的专业术语。通过对比实验发现，个性化专业术语支持显著改善了参与者对同事工作的理解和参与度，而一般性支持则不利于提高参与度。该系统还在实际会议中进行了验证，揭示了其在真实应用场景中的机遇和挑战。", "conclusion": "研究结果为设计个性化专业术语支持工具提供了见解，并对更广泛的跨学科和教育应用具有重要意义。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09636", "html_url": "https://arxiv.org/abs/2508.09636", "title": "个性化产品搜索排序：基于表结构和非表结构数据的多任务学习方法", "title_en": "Personalized Product Search Ranking: A Multi-Task Learning Approach with Tabular and Non-Tabular Data", "authors": "Lalitesh Morishetti,Abhay Kumar,Jonathan Scott,Kaushiki Nag,Gunjan Sharma,Shanu Vashishtha,Rahul Sridhar,Rohit Chatter,Kannan Achan", "background": "本文介绍了一种新的模型架构，用于使用多任务学习（MTL）框架优化个性化的商品搜索排名。该方法将结构化和非结构化数据的独特集成结合在一起，利用预训练的TinyBERT模型生成语义嵌入，并采用新的采样技术捕捉多样化的客户行为。论文评估了该模型与XGBoost、TabNet、FT-Transformer、DCN-V2和MMoE等基线模型的性能，重点关注其处理混合数据类型和优化个性化排名的能力。此外，论文还提出了一种基于点击率、点击位置和语义相似度的可扩展相关性标签机制，作为传统人工标注的替代方法。实验结果显示，将非结构化数据与多任务学习框架中的高级嵌入技术相结合，显著提升了模型性能。拆分研究进一步强调了引入相关性标签、微调TinyBERT层以及TinyBERT查询-产品嵌入交互的益处。这些结果表明，本文的方法在实现改进的个性化商品搜索排序方面效果显著。", "innovation": "引入了一种新的模型架构，结合了多任务学习框架中的结构化和非结构化数据。使用预训练的TinyBERT模型生成语义嵌入，并采用一种新的采样技术来捕捉多样化的客户行为。提出了一种基于点击率、点击位置和语义相似度的可扩展的相关性标签机制，作为传统人工标注的替代方法。评估了该模型与其他基线模型的性能，强调了引入相关性标签和细调TinyBERT层以及TinyBERT查询-产品嵌入交互的益处。", "conclusion": "结合非结构化数据与高级嵌入技术的多任务学习框架显著提升了模型的性能。通过引入新的相关性标签机制和优化数据处理策略，进一步验证了多任务学习方法的有效性和优越性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10356", "html_url": "https://arxiv.org/abs/2508.10356", "title": "提高多语言历史文本OCR识别", "title_en": "Improving OCR for Historical Texts of Multiple Languages", "authors": "Hylke Westerdijk,Ben Blankenborg,Khondoker Ittehadul Islam", "background": "该论文介绍了使用高级深度学习技术在光学字符识别（OCR）和文档布局分析方面的研究方法和发现。研究涉及三种任务：历史上希伯来文本的OCR改进、16至18世纪会议决议的OCR和18世纪以来英语手写识别。", "innovation": "创新点包括：1) 通过大量数据增强提高了历史希伯来文本的OCR；2) 结合了DeepLabV3+的CRNN模型和双向LSTM，利用基于置信度的伪标签提高了16至18世纪会议决议的识别率；3) 应用了带有ResNet34编码器的CRNN，并使用CTC损失函数有效捕捉序列依赖性，以进行现代英语手写识别。", "conclusion": "这份报告提供了有价值的研究见解，指出了未来研究的潜在方向。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10108", "html_url": "https://arxiv.org/abs/2508.10108", "title": "亚马逊诺瓦AI挑战——可信AI：推进安全的AI辅助软件开发", "title_en": "Amazon Nova AI Challenge -- Trusted AI: Advancing secure, AI-assisted software development", "authors": "Sattvik Sahai,Prasoon Goyal,Michael Johnston,Anna Gottardi,Yao Lu,Lucy Hu,Luke Dai,Shaohua Liu,Samyuth Sagi,Hangjie Shi,Desheng Zhang,Lavina Vaz,Leslie Ball,Maureen Murray,Rahul Gupta,Shankar Ananthakrishna", "background": "AI系统在软件开发中的应用日益增多，但确保其安全性仍然是一个重大挑战。为了应对这一挑战，亚马逊推出了亚马逊诺瓦AI挑战的可信AI赛道，这是一个由10支大学团队参与的全球竞赛，旨在推动安全AI的发展。竞赛中，5支团队致力于开发自动化红色团队机器人，而另外5支团队则创建安全的AI助手。通过一对一的对抗式锦标赛，红色团队与竞争对手的AI编程助手进行多回合对话，以测试其安全对齐情况。此外，竞赛还为团队提供了高质量的标注数据流，以支持迭代改进。在整个竞赛过程中，团队开发了先进的技术，引入了基于推理的安全对齐、稳健模型护栏、多回合围墙破坏以及高效探查大规模语言模型（LLMs）等新颖方法。为了支持这些努力，亚马逊诺瓦AI挑战团队在科学研究和工程投入方面做出了巨大贡献，包括从头构建了一个定制挑战基线编程专家模型、开发了一个锦标赛编排服务以及构建了一个评估框架。", "innovation": "1. 引入了新型的基于推理的安全对齐方法。\n2. 开发了稳健模型护栏的方法。\n3. 提出了多回合围墙破坏方法。\n4. 有效探查了大型语言模型（LLMs）。\n5. 从零构建了竞赛专用的基线编程专家模型。\n6. 开发了锦标赛编排服务。\n7. 建立了评估框架。", "conclusion": "大学团队和亚马逊诺瓦AI挑战团队在解决AI软件开发中的安全挑战方面取得了显著进展，展示了双方为提升AI安全性所进行的密切合作。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10416", "html_url": "https://arxiv.org/abs/2508.10416", "title": "CorrectNav: 自纠正飞轮赋予视觉语言动作导航模型", "title_en": "CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model", "authors": "Zhuoyuan Yu,Yuxing Long,Zihan Yang,Chengyan Zeng,Hongwei Fan,Jiyao Zhang,Hao Dong", "background": "现有的视觉-语言导航模型在执行指令时往往会偏离正确的轨迹，但它们缺乏有效的错误纠正能力，这阻碍了它们从错误中恢复。", "innovation": "提出了一种新的后训练范式——自纠正飞轮。该范式将模型在训练集上的错误轨迹视为有价值的数据源，开发了一种方法来识别这些错误轨迹中的偏差，并设计了自动生成自纠正数据的技术。这些自纠正数据为模型的持续训练提供了动力。通过多次飞轮迭代，逐步增强了基于单目RGB的VLA导航模型CorrectNav。实验结果显示，CorrectNav在R2R-CE和RxR-CE基准上分别取得了65.1%和69.3%的新最好成功率，超过了之前的最好水平8.2%和16.4%。在各种室内外环境中的真实机器人测试表明，该方法在错误纠正、动态障碍物规避和长时间指令遵循方面具有显著优势。", "conclusion": "CorrectNav通过自纠正飞轮组件的迭代训练，逐步增强并实现了优异的视觉语言动作导航能力，在多个基准测试和真实机器人测试中取得了领先成果。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10057", "html_url": "https://arxiv.org/abs/2508.10057", "title": "大型语言模型在抽象推理过程中显示出与人类神经认知的对齐迹象", "title_en": "Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning", "authors": "Christopher Pinier,Sonia Acuña Vargas,Mariia Steeghs-Turchina,Dora Matzke,Claire E. Stevenson,Michael D. Nunez", "background": "本文探讨了大型语言模型（LLMs）在抽象推理过程中是否反映了人类的认知神经机制。研究者们通过将人类参与者的成绩与八个开源LLMs在抽象模式填充任务中的表现进行了比较，利用任务表现中的模式类型差异和任务过程中脑电图（EEG）记录的注视相关电位（FRPs）来研究这一问题。研究结果显示，只有大约70亿参数量的LLMs实现了人类可比的准确性，部分LLMs（如Qwen-2.5-72B和DeepSeek-R1-70B）在具体难度模式上也表现出与人类相似的特征。研究还显示，每个接受测试的LLM都会在其中间层中以不同方式表征抽象模式类别，这一能力与它们在任务中的表现成正比。此外，任务最优化的LLM层次的表征几何和人类前额皮层的FRPs之间存在轻微的正相关关系，这与与其他EEG指标（反应锁定的ERPs和基线EEG）的比较结果不一致，暗示可能存在一种共同的抽象模式表征空间。这项研究提供了生物智能与人工智能共享原则的初步证据，可能表明LLMs在抽象推理过程中模仿了人类的大脑机制。", "innovation": "这项研究展示了大型语言模型在抽象推理过程中表现出与人类神经认知的相似性，具体来说，只有具有较大参数量的模型（约70亿）达到了人类水平的准确度，部分LLMs表征了模式的具体难度特征与人类相似，表明可能存在一种共同的抽象模式表征空间。此外，任务最优化的LLM层次的表征几何与人类前额皮层的FRPs之间存在轻微的正相关关系，这为共享原则理论提供了初步证据。", "conclusion": "尽管所有接受测试的LLM在其中间层中形成了表征抽象模式类别的独特集群，但这一能力的强度与其在任务中的表现成比例增加。研究结果表明，LLMs在抽象推理中表现出了模拟人类大脑机制的迹象，这为共享智能原则提供了初步证据。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10492", "html_url": "https://arxiv.org/abs/2508.10492", "title": "逆转医工关系：由大规模语言模型驱动的全过程临床诊断", "title_en": "Reverse Physician-AI Relationship: Full-process Clinical Diagnosis Driven by a Large Language Model", "authors": "Shicheng Xu,Xin Huang,Zihao Wei,Liang Pang,Huawei Shen,Xueqi Cheng", "background": "全过程中临床诊断涵盖了从模糊主要症状开始的整个诊断流程。尽管人工智能（尤其是大型语言模型）正在改变临床诊断，但目前它主要作为医生的辅助工具。这种辅助模式限制了AI在从模糊症状开始整个诊断流程中的作用，还未完全减轻医生的工作负担并提升诊断效率。", "innovation": "提出了一种新的范式，将反向医疗与AI的关系，让AI成为主要的导演，医生成为助手。由此开发了DxDirector-7B，一个具备高级深层思考能力的大型语言模型，能够减少医生干预的情况下驱动全过程诊断，同时建立了诊断错误的责任划分框架。", "conclusion": "在多种复杂和真实案例下，DxDirector-7B在诊断准确性上取得了显著的优越性，同时大幅度减少了医生的工作负担，优于最先进的医疗大模型和通用大模型。它的多功能性和有效性的细粒度分析验证了其作为医学专家替代品的潜力，开启了新的时代，使得AI在医生辅助的角色下全面驱动整个诊断过程，大幅减少医生的工作负担，提供高效准确的诊断解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10530", "html_url": "https://arxiv.org/abs/2508.10530", "title": "优先多样性，再追求质量：语言模型对齐的两阶段假设", "title_en": "Diversity First, Quality Later: A Two-Stage Assumption for Language Model Alignment", "authors": "Zetian Sun,Dongfang Li,Baotian Hu", "background": "语言模型与人类偏好对齐是构建可靠AI系统的关键。通常将这一过程视为优化LM策略以最大化反映人类偏好的预期奖励。最近，直接偏好优化(DPO)被提出作为一种直接从静态偏好数据优化策略的方法。为了改进LM对齐，该方法进一步结合了在线政策采样，但在研究中发现，不同数据类型（静态与在线）对LM对齐的有效性存在显著差异。论文进一步探讨了这种现象。", "innovation": "论文提出了一种两阶段假设来解释不同数据类型对LM对齐的影响。第一阶段是偏好注入阶段，偏好多样性数据对该阶段有较大帮助；第二阶段是偏好微调阶段，对高质量数据有较大偏好。作者通过理论和实验分析，提出了识别两阶段边界的算法。并证实了该假设及边界测量方法在多种模型和对齐方法上的广泛适用性。", "conclusion": "通过对5种模型和两种对齐方法的实验，论文展示了两阶段假设在各种情况下的有效性，并提出了区分两阶段的方法，从而在语言模型与人类偏好对齐过程中提供了一种新的思路和方法。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10880", "html_url": "https://arxiv.org/abs/2508.10880", "title": "通过模拟搜寻LLM代理的隐私风险", "title_en": "Searching for Privacy Risks in LLM Agents via Simulation", "authors": "Yanzhe Zhang,Diyi Yang", "background": "基于LLM的代理的广泛应用可能会引入一个关键的隐私威胁：恶意代理主动与他人进行多轮对话以提取敏感信息。这种动态对话允许适应性强的攻击策略，可能造成严重的隐私侵犯，但它们不断变化的性质使得手动预见和发现复杂的漏洞变得困难。", "innovation": "本文提出了一个基于搜索的框架，交替改进攻击者和防守者的指令，通过模拟隐私关键的代理交互。算法利用LLM作为优化器，通过多线程并行搜索和线程间传播分析模拟轨迹，从而迭代地提出新的指令。该过程揭示了攻击策略从简单的直接请求升级为复杂的多轮战术，如冒充和同意伪造，而防御措施则从基于规则的约束升级为身份验证状态机。", "conclusion": "发现的攻击和防御策略在不同情景和基础模型之间具有很强的实用价值，证明了构建意识代理的强大实践作用。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10539", "html_url": "https://arxiv.org/abs/2508.10539", "title": "通过低成本方差减少提升基于价值的过程验证器", "title_en": "Improving Value-based Process Verifier via Low-Cost Variance Reduction", "authors": "Zetian Sun,Dongfang Li,Baotian Hu,Min Zhang", "background": "大语言模型（LLMs）在多种任务中取得了显著成就，但在复杂领域如数学中的推理能力仍然面临重大挑战。基于价值的过程验证器通过估计部分推理链到达正确解的概率来提升推理能力，但其效果受限于MC采样的不确定性，这归因于大规模MC模拟由于高成本而不可行。", "innovation": "作者识别出估计误差主要来源于高方差而非偏差，并提出了复合蒙特卡洛采样（ComMCS）方法。该方法通过在当前步骤和后续步骤的MC估计器间进行线性结合，构造无偏估计器，理论上因降低方差而减少估算误差，同时无需额外的LLM推理成本。作者还在MATH-500和GSM8K基准测试上进行了实验证明其有效性，结果显示ComMCS在MATH-500的Best-of-32采样实验中分别优于基于回归优化方法2.8个点和非方差减小的基线2.2个点。", "conclusion": "本文提出了一种通过低成本降低方差的方法来提升基于价值的过程验证器的效果，通过理论分析和实验证明了该方法的有效性，且能显著提升模型在复杂推理任务上的估计准确性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10751", "html_url": "https://arxiv.org/abs/2508.10751", "title": "Pass@k 培训以适应性平衡大型推理模型的探索与利用", "title_en": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models", "authors": "Zhipeng Chen,Xiaobo Qin,Youbin Wu,Yue Ling,Qinghao Ye,Wayne Xin Zhao,Guang Shi", "background": "RLVR 使用 Pass@1 作为奖励指标，存在探索与利用之间的平衡问题，导致政策模型偏好保守行为，容易收敛至局部最优。尽管 Pass@k 在评估中被使用，但其与大型语言模型在 RLVR 中的探索能力之间的关系仍未被充分认识和利用。因此，识别适当的奖励度量至关重要，而对此的研究仍存在缺失和不足", "innovation": "使用 Pass@k 作为奖励进行政策模型的训练 (Pass@k 培训)，并通过解析解分析 Pass@k 培训的优势，揭示了探索与利用之间并非天然冲突的目标，而是可以相互增强；基于此，进一步探索 RLVR 中的优势设计，并展现出有前景的结果，为未来研究提供了潜在的方向", "conclusion": "探索与利用之间并非天然冲突，反而可以相互增强。Pass@k 培训通过直接设计优势函数，可以有效提升大型推理模型在探索与利用之间的平衡能力。未来的研究方向将专注于基于这种理解进一步设计并优化 RLVR 中的优势函数"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10824", "html_url": "https://arxiv.org/abs/2508.10824", "title": "记忆增强变换器：从神经科学原则到技术解决方案的系统综述", "title_en": "Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Technical Solutions", "authors": "Parsa Omidi,Xingshuai Huang,Axel Laborieux,Bahareh Nikpour,Tianyu Shi,Armaghan Eshaghi", "background": "记忆是智能的基础，使学习、推理和适应能力能够在生物系统和人工系统中得以体现。虽然变换器架构在序列建模方面表现出色，但在保留长范围上下文、持续学习和知识整合方面存在关键限制。本文综述了一种融合神经科学原理（包括动态多时标记忆、选择性注意和巩固）与工程上的记忆增强变换器进步的统一框架。", "innovation": "本文提出了结合神经科学原则与工程进展的记忆增强变换器框架，通过按功能目标、记忆表示和整合机制三个分类维度组织近期进展。展示了核心记忆操作（读取、写入、遗忘和容量管理）的转变，从静态缓存向测试时的自适应学习系统的转变，并指出了可扩展性和干扰等持久挑战及分级缓存和惊喜门控更新等新兴解决方案。", "conclusion": "本文综述提供了认知启发式的、终身学习变换器架构的发展路线图，介绍了从神经科学原则出发的方法与技术支持解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.10548", "html_url": "https://arxiv.org/abs/2508.10548", "title": "使用屏蔽奖励稳定长时多轮强化学习", "title_en": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards", "authors": "Zetian Sun,Dongfang Li,Zhuoen Chen,Yuhuai Qin,Baotian Hu", "background": "在长周期强化学习任务中，如何保持奖励的稀疏性是一个重要挑战。现有的基于结果的奖励塑造方法难以定义有意义的即时奖励，同时避免引入偏见或需要明确的任务分解。另外，基于验证的奖励塑造使用逐步批评者，但这种即时奖励与长期目标之间的错位可能导致奖励作弊和次优策略。本文聚焦于软件工程任务的背景，在这类任务中，多轮推理和基于规则的验证是关键。", "innovation": "本文提出了一种新的方法——屏蔽奖励积累（G-RA），只有在高级（长期）奖励达到预定义阈值时，才会积累即时奖励，从而确保稳定的学习优化。此外，还介绍了一种面向软件工程的RL框架，支持多轮交互、基于Docker的执行以及可定制的奖励函数。实验结果表明，G-RA能显著提高完成率和修改率，同时避免由于奖励错位导致的策略劣化。这些发现强调了在长时间RL中平衡奖励积累的重要性，并提供了一种实用的解决方案。", "conclusion": "本文通过引入G-RA方法，解决了长时多轮RL中奖励错位的问题，并在软件工程任务上展示了其实用性和有效性。这对于提升强化学习算法在长期复杂任务中的性能具有重要意义。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2407.12830", "html_url": "https://arxiv.org/abs/2407.12830", "title": "基于知识的大型语言模型一致性测试", "title_en": "Knowledge-based Consistency Testing of Large Language Models", "authors": "Sai Sathiesh Rajan,Ezekiel Soremekun,Sudipta Chattopadhyay", "background": "现有的大型语言模型（LLMs）存在知识上的不一致性和知识空洞。为了准确测量和解决这些问题，研究人员设计了一套自动化测试框架KonTest，该框架通过知识图谱构建测试用例，并结合语义等价查询和测试或acles（元形态或本体或acles）对LLMs的世界知识进行探查和测量。", "innovation": "提出了一个名为KonTest的自动化测试框架，利用知识图谱构建测试用例，并通过语义等价查询和测试或acles（元形态或本体或acles）来探测和测量LLMs的知识不一致性。KonTest还包括一个基于加权LLM模型的集成方法来缓解知识空洞。通过四个最先进的LLMs（Falcon，Gemini，GPT3.5和Llama2），KonTest生成了19.2%的错误诱导输入（共1917个错误，来自9979个测试输入），揭示了所有测试的LLMs在知识上的16.5%差距。采用KonTest测试套件提出的缓解方法可以将LLMs的知识差距减少32.48%。", "conclusion": "通过KonTest测试，可以发现大型语言模型在生成知识一致性和减轻知识空洞方面存在显著的改进空间。这项工作为未来研究提供了实践指导，并促进了对大型语言模型的深入理解和优化。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.08512", "html_url": "https://arxiv.org/abs/2502.08512", "title": "测量合成数据集的多样性", "title_en": "Measuring Diversity in Synthetic Datasets", "authors": "Yuchang Zhu,Huizhe Zhang,Bingzhe Wu,Jintang Li,Zibin Zheng,Peilin Zhao,Liang Chen,Yatao Bian", "background": "大型语言模型（LLMs）广泛用于生成各种自然语言处理（NLP）任务的合成数据集，如文本分类和总结。然而，准确测量这些合成数据集的多样性——这一对于模型稳健性能至关重要的方面——仍然是一个重大挑战。", "innovation": "介绍了一种名为DCScore的新型方法，从分类视角测量合成数据集的多样性。DCScore将多样性评估形式化为一个样本分类任务，利用样本之间的相互关系。理论验证了DCScore满足的多样性相关公理，强调其作为原则性的多样性评估方法的角色。实验结果表明，DCScore与多个评估数据集的多样性伪真理具有更强的相关性，强调了其有效性。此外，实证和理论证据表明，与现有方法相比，DCScore显著降低了计算成本。", "conclusion": "DCScore在测量合成数据集的多样性方面表现出更强的效用，并且相较于现有方法实现了显著的计算成本降低。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.16770", "html_url": "https://arxiv.org/abs/2502.16770", "title": "LED-Merging: 在位置-选举-分离中缓解模型融合中的安全-效用冲突", "title_en": "LED-Merging: Mitigating Safety-Utility Conflicts in Model Merging with Location-Election-Disjoint", "authors": "Qianli Ma,Dongrui Liu,Qian Chen,Linfeng Zhang,Jing Shao", "background": "使用预训练大语言模型（LLMs）在专门为特定任务进行微调过程中会产生大量的计算和技术成本。已有方法通过融合多个任务特定模型来提供训练免费的解决方案，但这些问题在提升通用能力的同时往往会损害安全保护措施，因而产生了安全-效用冲突。", "innovation": "提出了一种名为LED-Merging的三阶段框架：1. 使用基于梯度的归因定位任务特定神经元，2. 动态选举关键神经元通过多模型重要性融合，3. 通过参数隔离分离冲突更新。该方法有效降低了有害响应率，同时保持了95%的效用性能，如在HarmBench的数据中降低Llama-3-8B-Instruct高达31.4%的有害响应率。同时，LED-Merging解决了安全-效用冲突，提供了一个轻量且无需训练的思路，以构建可靠的多任务LLMs。", "conclusion": "LED-Merging提供了一种缓解安全-效用冲突的轻量级且无需训练的多任务大语言模型构建方法。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.06117", "html_url": "https://arxiv.org/abs/2501.06117", "title": "Fleurs-SLU：大规模多语言口语理解基准", "title_en": "Fleurs-SLU: A Massively Multilingual Benchmark for Spoken Language Understanding", "authors": "Fabian David Schmidt,Ivan Vulić,Goran Glavaš,David Ifeoluwa Adelani", "background": "对于缺乏正式书写系统的语言，口语理解（SLU）对于其中的一半语言来说是必不可少的。与资源丰富的语言不同，我们不能依靠自动语音识别（ASR）和基于文本的大语言模型（LLMs）来处理这些语言的语义理解。即使这些低资源语言有书写系统，其ASR也由于少有双模态的语音和文本训练数据而不可靠。目前，对于多语言SLU的评估多限于浅层次的任务，如意图分类或语言识别。因此，我们需要一个新的基准来改进这一现状。", "innovation": "我们提出了Fleurs-SLU，这是一种多语言SLU基准，它包含692小时包含话题性短语分类的多语言语音数据（102种语言）和944小时涵盖92种语言的听写理解问答任务。我们全面评估了端到端语音分类模型、结合语音转文本与后续LLM分类的级联系统，以及多模态语音-LLMs在Fleurs-SLU上的表现。结果显示，级联系统在多语言SLU中更为稳健，但预训练的语音编码器在话题性语音分类中表现出极强的竞争力。封闭源代码的语音-LLM在性能上与级联系统相当或更优。我们发现，稳健的多语言ASR、有效的语音转文本以及强大的多语言SLU之间存在强相关性，这表示声学和语义表达方式之间的相互增益。", "conclusion": "我们的研究结果表明，级联系统在多语言SLU中表现更稳定，但在话题性语音分类中，预训练的语音编码器也能表现出竞争力。封闭源代码的语音-LLM在Fleurs-SLU上的表现与级联系统相当或更优。这对语声和语义表达方式的稳健性具有重要意义，显示了相互增益的关系。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16325", "html_url": "https://arxiv.org/abs/2410.16325", "title": "这位候选人是[MASK]。基于提示的情感提取与推荐信", "title_en": "This Candidate is [MASK]. Prompt-based Sentiment Extraction and Reference Letters", "authors": "Fabian Slonimczyk", "background": "本文提出了一种相对简单的方法来部署预训练的大语言模型（LLMs），用于从文本数据中提取情感和其他有用特征。作者应用这种方法来分析自己手收集的机密推荐信（RLs）数据库。研究表明，推荐信中的情感内容在就业市场结果中得到了清晰的体现。无论使用哪种成功指标，候选人平均情感得分越高，他们的业绩表现越好。此外，作者还表明，推荐信撰写者之间的一致性负面地影响了就业市场候选人的表现。为了比较，作者将情感提取方法与常用的情感分析方法进行了比较，包括“词袋”方法、微调的语言模型和查询高级聊天机器人，并发现没有任何其他方法能够重现基于提示的情感提取方法的结果。此外，作者稍微修改了方法来获得“性别化”的情感评分，发现写给女性候选人的推荐信更强调“脚踏实地”的个人特质，而写给男性候选人的推荐信则更强调“突出”的特质。这些性别差异对女性的就业市场表现产生了负面影响。", "innovation": "本文介绍了一种基于提示的情感提取方法，该方法相对简单且能够在包含隐含情感的文本数据中提取情感和其他有用特征。该方法在经济和金融领域优于其他方法，并且可以有效地重现其他情感分析方法所无法获得的结果。此外，作者进一步将该方法应用于获得性别化的情感评分，并发现推荐信中的性别差异影响了女性候选人的就业市场表现。这种基于提示的方法因其简单性和有效性的特点表现出创新之处，尤其是在分析难以直接转化的情感信息方面。", "conclusion": "本文提出了基于提示的情感提取方法，该方法在推荐信分析中取得了显著成效，能够清晰反映情感内容对求职结果的影响，并且可以有效区分男女候选人推荐信中的性别化特质。这种方法不仅在传统的情感分析方法中表现出优势，而且还揭示了性别在就业市场中的隐含影响。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17538", "html_url": "https://arxiv.org/abs/2505.17538", "title": "瑞典Whispers；利用大规模语音语料库进行瑞典语语音识别", "title_en": "Swedish Whispers; Leveraging a Massive Speech Corpus for Swedish Speech Recognition", "authors": "Leonora Vesterbacka,Faton Rekathati,Robin Kurtz,Justyna Sikora,Agnes Toftgård", "background": "小型资源语言在多语言训练数据集中往往被代表性不足，这影响了这些语言的模型性能。已有研究表明，通过微调现有的多语言模型可以显著提升这些语言的性能。", "innovation": "本文介绍了针对瑞典语的系列微调后的Whisper模型，训练数据量达到了前所未有的规模和多样性。这些模型在瑞典语的识别任务上表现出了显著的性能提升。", "conclusion": "与OpenAI的Whisper-large-v3模型相比，该工作中的最佳模型在FLEURS、Common Voice和NST上的错误率显著降低了47%。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.23714", "html_url": "https://arxiv.org/abs/2503.23714", "title": "使用开源大语言模型从手写指令构建指令调优数据集", "title_en": "Building Instruction-Tuning Datasets from Human-Written Instructions with Open-Weight Large Language Models", "authors": "Youmi Ma,Sakae Mizuki,Kazuki Fujii,Taishi Nakamura,Masanari Ohi,Hinari Shimada,Taihei Shiotani,Koshiro Saito,Koki Maeda,Kakeru Hattori,Takumi Okamoto,Shigeki Ishida,Rio Yokota,Hiroya Takamura,Naoaki Okazaki", "background": "大型语言模型（LLMs）是通过指令调优来解决真实世界任务的关键。先前的研究表明，仅从LLMs生成的指令调优数据也能有效进行训练，这引发了人们对于是否还需要包含人类来源信号的问题。本研究通过直接将人类撰写的指令与LLM生成的响应配对，构建了先进的人类撰写的指令调优数据集，并展示了在这些数据集上调优后的LLM模型持续优于针对现有数据集调优的模型。", "innovation": "本研究创新性地提出了一种新的数据构建方法，采用开源的大语言模型数据来从人类撰写的指令构建指令调优数据集。该方法不仅能够在现有的语言上应用，还可以在其他语言（如日语）上扩展。实验证明，使用该数据集调优的模型在新语言中表现出色，且在文化特定知识方面表现出不足。此外，这种数据集和调优后的模型将开源提供。", "conclusion": "通过使用开源的大语言模型构建的人类撰写的指令调优数据集，调优后的LLM模型在新语言下表现出色。这些数据集和调优后的模型将适用于多种场景，并以开放许可的方式向外开源，为广泛的使用和研究提供了支持。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.11509", "html_url": "https://arxiv.org/abs/2503.11509", "title": "TikZero: 零样本文本引导图示程序合成", "title_en": "TikZero: Zero-Shot Text-Guided Graphics Program Synthesis", "authors": "Jonas Belouadi,Eddy Ilg,Margret Keuper,Hideki Tanaka,Masao Utiyama,Raj Dabre,Steffen Eger,Simone Paolo Ponzetto", "background": "自动从文字说明合成图表是一项引人注目的能力。然而，要实现几何精度高和易于编辑，就需要用如TikZ这样的图形语言表示图表，并且配有说明的对齐训练数据仍然稀缺。同时，大量未对齐的图形程序和配有说明的位图图像更容易获取。我们通过提出TikZero解决这些不同的数据来源差异，TikZero通过使用图像表示作为中介桥梁，将图形程序生成与文本理解分离开来。这使得在图形程序和配有说明的图像上独立训练成为可能，并且在推理过程中能够实现零样本文本引导的图形程序合成。", "innovation": "TikZero将图形程序生成与文本理解分离，通过使用图像表示作为中介桥梁。这种方法使得可以在图形程序和配有说明的图像上独立训练，并且在推理过程中能够实现零样本文本引导的图形程序合成，此外，它在利用配有说明的图形程序作为额外的训练信号时，效果与更大的模型相当甚至超越，包括商业系统如GPT-4o。", "conclusion": "我们的方法在仅使用配有说明的图形程序时显著优于基线。此外，当我们利用配有说明的图形程序作为额外的训练信号时，TikZero在性能上匹配甚至超越了更大的模型，包括商业系统如GPT-4o。我们的代码、数据集和部分模型已公开可用。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.02323", "html_url": "https://arxiv.org/abs/2504.02323", "title": "CoTAL：循环中的提示工程以实现可泛化的形成性评估评分", "title_en": "CoTAL: Human-in-the-Loop Prompt Engineering for Generalizable Formative Assessment Scoring", "authors": "Clayton Cohn,Ashwin T S,Naveeduddin Mohammed,Gautam Biswas", "background": "大型语言模型（LLMs）为教师和学生学习提供了新的辅助机会。尽管研究人员在教育环境中探索了各种提示工程方法，但在诸如科学、计算和工程等不同领域内这些方法的普遍适用性研究尚不充分。", "innovation": "本文介绍了一种基于LLMs的方法：Chain-of-Thought Prompting + Active Learning（CoTAL），该方法包括：1) 使用Evidence-Centered Design（ECD）来对齐评估与课程目标；2) 运用人机交互的提示工程来自动评分；3) 结合Chain-of-Thought（CoT）提示和教师、学生反馈来迭代改进问题、评分标准和LLMs提示。与未进行提示工程的基线模型相比，CoTAL在不同领域中提升GPT-4的评分性能，最高可达38.9%。教师和学生认为CoTAL在评分和解释响应方面是有效的，反馈意见提高了评分准确性和解释质量。", "conclusion": "研究结果表明，CoTAL能有效提升GPT-4在不同领域下的评分性能，并且教师和学生对CoTAL的评价良好，反馈意见有助于提高评分准确性和解释质量。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01400", "html_url": "https://arxiv.org/abs/2504.01400", "title": "ToolACE-R: 模型感知迭代训练和自适应精炼方法在工具学习中的应用", "title_en": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning", "authors": "Xingshan Zeng,Weiwen Liu,Xu Huang,Zezhong Wang,Lingzhi Wang,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Ruiming Tang,Qun Liu", "background": "大型语言模型（LLMs）通过利用外部工具来解决复杂的用户任务的能力已经展现出扩展模型能力的巨大潜力。然而，现存的方法大多集中于数据合成以微调LLMs，使其能够高效触发工具调用，而未充分激发模型的潜力。", "innovation": "本文提出了一种名为ToolACE-R的新颖框架，该框架包含模型感知迭代训练和自适应精炼。ToolACE-R引入了模型感知迭代训练过程，基于模型不断演变的能力渐进式调整训练样本，以最大化其潜力。此外，它还结合了自我精炼训练语料库，强调LLM迭代优化其工具调用的能力。此外，还提出了自适应自我精炼机制，以便高效地进行测试时缩放，模型能自主确定适时停止过程。", "conclusion": "通过广泛的实验，结果显示ToolACE-R与高级API基础模型相比具有竞争力的表现。通过自适应自我精炼机制，工具调用性能可以进一步得到提高。这些结果突显了ToolACE-R的有效性和泛化能力，提供了更高效和可扩展工具学习的潜在方向。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.11655", "html_url": "https://arxiv.org/abs/2503.11655", "title": "使用DeepSeek-R1进行可解释情感分析：性能、效率和少样本学习", "title_en": "Explainable Sentiment Analysis with DeepSeek-R1: Performance, Efficiency, and Few-Shot Learning", "authors": "Donghao Huang,Zhaoxia Wang", "background": "大型语言模型（LLMs）在情感分析领域取得了显著进展，但要在准确度、效率和解释性之间取得平衡仍是一个关键挑战。本研究首次全面评估了开源推理模型DeepSeek-R1，与OpenAI的GPT-4o和GPT-4o-mini进行对比。测试了完整版本的671B模型及其精简变体，并系统地记录了少样本学习曲线。实验结果显示，DeepSeek-R1在5类情感分析中的F1得分达到了91.39%，在二分类任务中正确率达99.31%，仅需5个样本即可实现，这与GPT-4o相比提高了8倍的少样本效率。特定架构的精简手段产生了影响，基于32B的Qwen2.5模型比基于70B的Llama模型高出6.69个百分点。尽管推理过程降低了吞吐量，DeepSeek-R1通过透明、逐步骤的痕迹提供了出色的可解释性，确立了其作为强大的、可解释的开源替代品的地位。", "innovation": "本研究首次全面评估了开源推理模型DeepSeek-R1。实验结果显示该模型在情感分析任务中表现出色，在少样本学习方面具有较高的效率，特别是在解释性方面。", "conclusion": "DeepSeek-R1在情感分析任务中表现出优越的性能，特别是在少样本学习方面，与GPT-4o相比有显著提高。该模型通过透明、逐步骤的推理过程提高了解释性，并且尽管在吞吐量上有所下降，但其强大的解释能力和可解释性使其成为一种强大的、可解释的开源替代品。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.10354", "html_url": "https://arxiv.org/abs/2507.10354", "title": "意义如洋葱：一种分层的比喻处理方法", "title_en": "Meanings are like Onions: a Layered Approach to Metaphor Processing", "authors": "Silvia Cappa,Anna Sofia Lippolis,Stefano Zoia", "background": "本文将比喻意义视作多层次的认知现象，而非简单的概念映射。研究表明，现有的比喻处理模型较为平面化，无法充分解析比喻传达的深层次意义和背景效应。因此，探索一种更加复杂和认知依据的方法来解释比喻在计算系统中的处理变得尤为重要。", "innovation": "本文提出了一种分层的比喻处理模型，将意义比喻为洋葱结构，分为三个层次：内容分析、概念融合和实践意图。这种三维框架允许在计算系统中形成更丰富和认知依据的比喻解释方法，能够超越表面关联并深入进行更敏感的背景相关推理。", "conclusion": "通过将这些层统一到一个形式框架中，该模型为能够代表超越表面关联的比喻意义的计算方法奠定了基础。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "为什么开源大语言模型在数据分析中遇到困难？一项系统性实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "开源大语言模型（LLMs）在自动化数据分析任务方面显示出潜力，但这些模型在需要大量推理的场景中面临重大限制。现有研究认为，通过设计策略来增强开源LLMs的数据分析能力是关键。研究通过建立一个多样化的种子数据集，评估模型在数据理解、代码生成和战略规划三个核心维度上的表现，并发现数据质量和策略规划质量是影响性能的关键因素，交互设计和任务复杂性对推理能力也有显著影响，而数据多样性的影响相对较小。这些发现的基础上，研究开发了一种数据合成方法，显著提高了开源LLMs的分析推理能力。开源代码已可访问。", "innovation": "研究通过对开源LLMs进行系统实证研究，发现了数据质量和策略规划质量是影响性能的关键因素，提出了交互设计和任务复杂性对推理能力有显著影响的见解。研究还基于这些发现开发了一种数据合成方法，显著提高了开源LLMs的分析推理能力。开源代码已可访问。", "conclusion": "策略规划质量是模型性能的主要决定因素；交互设计和任务复杂性显著影响推理能力；数据质量对实现最佳性能的影响大于多样性；经过研究开发的数据合成方法显著提升了开源LLMs的分析推理能力。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22107", "html_url": "https://arxiv.org/abs/2505.22107", "title": "Long-context Modeling中的Transformer高维问题", "title_en": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling", "authors": "Shuhai Zhang,Zeng You,Yaofo Chen,Zhiquan Wen,Qianyue Wang,Zhijie Qiu,Yuanqing Li,Mingkui Tan", "background": "基于Transformer的大型语言模型（LLMs）在自然语言处理任务中表现出色，通过自注意力机制捕捉长范围依赖关系。然而，长语境建模面临着显著的计算效率问题，原因在于注意力计算的重复性：尽管注意力权重通常很稀疏，但所有词元消耗相同的计算资源，这导致了不必要的计算冗余。本文通过将传统的概率序列建模重新定义为监督学习任务，实现相关和无关词元的分离，并揭示注意力稀疏性，进而提出了group coding策略和Dynamic Group Attention (DGA)以减少冗余，提高模型的抗噪性和学习效率。", "innovation": "本文创新地将传统的概率序列建模重新分析为监督学习任务，揭示了注意力的稀疏性，并提出了group coding策略和Dynamic Group Attention (DGA)，利用group coding策略减少注意力计算中的冗余，增强模型的健壮性和学习效率。", "conclusion": "实验结果表明，所提出的DGA在显著降低计算成本的同时，仍然保持了竞争力。该研究对于提高长语境建模效率和质量具有重要意义，并且相关方法和理论分析为进一步研究提供了新的视角。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14189", "html_url": "https://arxiv.org/abs/2507.14189", "title": "DeepWriter: 基于离线知识库的依据事实的多元模态写作助手", "title_en": "DeepWriter: A Fact-Grounded Multimodal Writing Assistant Based On Offline Knowledge Base", "authors": "Song Mao,Lejun Cheng,Pinlong Cai,Guohang Yan,Ding Wang,Botian Shi", "background": "大型语言模型（LLMs）在各种应用中展示了出色的能力。然而，在金融、医学和法律等专业领域作为写作助手的使用受到了深度领域专业知识不足和虚构倾向的限制。现有的解决方案，如检索增强生成（RAG），可能会在多个检索步骤中产生不一致的现象，而基于在线搜索的方法则因不可靠的网络内容而导致质量下降。", "innovation": "介绍了可定制的、多模态的长文本写作助手DeepWriter，它基于一个精心维护的离线知识库运作。DeepWriter通过一个包含任务分解、提纲生成、多模态检索和逐节创作带有反思的新型流水线来工作。通过从结构化语料库中深度挖掘信息，并结合文本和视觉元素，生成内容连贯、事实依据充分且专业级的文件。此外还提出了一种层次知识表示方法，以提高检索效率和准确性。", "conclusion": "DeepWriter 在金融报告生成实验中展示了高质量、可验证的文章，超越了现有基线在事实准确性以及生成内容质量方面的表现。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06445", "html_url": "https://arxiv.org/abs/2508.06445", "title": "自动化回声：新闻制作中LLM使用量的增加", "title_en": "Echoes of Automation: The Increasing Use of LLMs in Newsmaking", "authors": "Abolfazl Ansari,Delvin Ce Zhang,Nafis Irtiza Tripto,Dongwon Lee", "background": "生成式AI（GenAI），尤其是大规模语言模型（LLMs）的迅速崛起，引发了对新闻工作真实性与作者身份的担忧。本文研究了GenAI生成内容在近40000篇来自重大、地方和大学媒体的新闻文章中的应用情况，涵盖了多种媒体格式。利用三种先进的AI文本检测工具（如Binoculars、Fast-Detect GPT和GPTZero），研究发现近年来在新闻制作中使用GenAI的情况显著增加，尤其是在地方和大学媒体中。", "innovation": "本文通过使用三种先进的AI文本检测工具，首次大规模地分析了新闻文章中GenAI的使用情况，揭示了LLMs在新闻文章中的具体应用，并通过句级分析和语言学分析，发现LLMs在新闻的开头部分应用较多，结论部分通常由人类撰写。这些工具为检测GenAI生成的内容提供了新的方法。", "conclusion": "GenAI增加了新闻文章中词汇丰富度和可读性，但降低了形式化水平，导致更统一的写作风格，特别是在地方媒体中。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.01213", "html_url": "https://arxiv.org/abs/2507.01213", "title": "AF-MAT: Aspect-aware Flip-and-Fuse xLSTM for Aspect-based Sentiment Analysis", "title_en": "AF-MAT: Aspect-aware Flip-and-Fuse xLSTM for Aspect-based Sentiment Analysis", "authors": "Adamu Lawan,Juhua Pu,Haruna Yunusa,Muhammad Lawan,Mahmoud Basi,Muhammad Adam", "background": "ABSA（方面/属性基于的情感分析）是一个关键的NLP任务，从文本中提取细粒度的意见和情感，例如产品评论和客户反馈。现有的方法在效率和性能之间权衡：传统的LSTM或RNN模型难以捕捉长距离依赖关系，基于变换器的方法计算成本高，而基于Mamba的方法则依赖CUDA并削弱了局部依赖建模。最近提出的扩展长短期记忆（xLSTM）模型通过指数门限和增强的记忆变体提供了一种有效捕获长距离依赖性的替代方案，包括用于建模局部依赖关系的sLSTM和用于可扩展、并行化记忆建模的mLSTM。然而，xLSTM在ABSA中的应用尚未被探讨.", "innovation": "本文提出了AF-MAT框架，它结合了xLSTM的优点。AF-MAT引入了具有专用方面门的面向方面的矩阵LSTM（AA-mLSTM）机制，使模型能够在内存更新期间有选择地强调与目标方面语义相关的标记。为了建模多尺度上下文，该框架包含一个FlipMix块，该块按顺序应用部分翻转的Conv1D（pf-Conv1D）以捕获反向顺序的短距离依赖性，然后通过整个序列反向应用完全翻转的mLSTM（ff-mLSTM）以建模长距离依赖性。此外，提出了基于mLSTM门的轻量级多头跨特征融合MC2F，该方法动态融合AA-mLSTM输出（查询和密钥）与FlipMix输出（值）的融合输出，以实现自适应表示融合", "conclusion": "在三个基准数据集上的实验结果表明，AF-MAT超越了最新的基线方法，在ABSA任务上实现了更高的准确性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.02038", "html_url": "https://arxiv.org/abs/2508.02038", "title": "Marco-Voice技术研究报告", "title_en": "Marco-Voice Technical Report", "authors": "Fengping Tian,Chenyang Lyu,Xuanfan Ni,Haoqin Sun,Qingjuan Li,Zhiqiang Qian,Haijun Li,Longyue Wang,Zhao Xu,Weihua Luo,Kaifu Zhang", "background": "该研究旨在解决现有的高表达力、可控性和自然度的语音生成技术中长期存在的挑战，特别是在保持不同语言和情感语境中说话者身份忠实性方面。现有的技术存在难以同时实现多人物声音克隆和情感控制的问题，这限制了在多样的应用场景中的应用效果。为了克服这些限制，研究构建了一个高质量的包含10小时普通话的情感语音数据集CSEMOTIONS，涵盖了六位专业说话人七种情感类别。通过对比批次内学习机制来分离语音和情感的信息，同时引入旋转情感嵌入整合方法，使得说话者身份和情感风格可以独立的进行调整和控制，从而提高语音合成的灵活性和自然度。", "innovation": "该系统提出了一种有效的说话者和情感信息的分离机制，通过对比批次学习有效地分离了语音和情感信息，使得说话者的声音和情感风格可以独立调整控制。此外，引入了旋转情感嵌入整合方法，使得情感控制更加平滑流畅。这些创新使得系统能够在保持说话人身份忠实性的同时，实现更加自然和丰富的语音合成。通过CSEMOTIONS高质量数据集的支持，该系统展示了在语音清晰度和情感丰富度上的优异性能，显著提升了情感神经语音合成的技术水平。", "conclusion": "研究结果表明，Marco-Voice系统在客观和主观评估指标上都取得了显著的改进，展示了在情感神经语音合成领域的重大进步。研究还证明了该系统能够提供高质量的情感丰富的语音，具有重要的实际应用价值。为了促进该领域的进一步研究和发展，代码和数据集已经公开发布。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.10535", "html_url": "https://arxiv.org/abs/2507.10535", "title": "CodeJudgeBench: 验证用于编码任务的LLM仲裁器基准", "title_en": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks", "authors": "Hongchao Jiang,Yiming Chen,Yushi Cao,Hung-yi Lee,Robby T. Tan", "background": "大型语言模型（LLMs）在各类编程任务中的应用极大地推进了技术标准。除了直接回答用户的查询外，LLMs还可以作为评判者，评估和比较其他模型生成的响应质量。这种评估能力对于不同LLMs的基准测试和通过响应排名提高响应质量都很重要。然而，尽管LLM-as-a-Judge模式的采用越来越多，但在编码场景中的有效性仍未得到充分探索，主要是因为缺乏专门的基准测试。该研究正是为了解决这一问题而引入的。", "innovation": "该研究提出了CodeJudgeBench，这是一个明确设计用于评估LLM-as-a-Judge模型在三项关键编码任务（代码生成、代码修复和单元测试生成）上性能的基准。研究表明，现代思考模型在精心设计的代码评估任务中显著优于非思考模型。即使相对较小的思考模型，如Qwen3-8B，也能够超越特训的L70B规模的LLM-as-a-Judge模型。然而，所有模型在评判编码任务时仍然表现出显著的随机性。在成对评判任务中，改变响应的展示顺序会对准确度产生显著影响。此外，当评判由不同LLM编写的代码和单元测试时，LLM-as-a-Judge模型的表现也存在差异，这引发了对LLM-as-a-Judge在编码场景中可靠性和一致性的问题。研究还发现，使用成对比较优于标量点评估，并且保留未处理响应中的评论和推理可以提高评判效果。", "conclusion": "通过全面评估26种LLM-as-a-Judge模型，研究发现现代思考模型在精心设计的代码评判任务中显著优于非思考模型。虽然所有模型在评判编码任务时仍然表现出显著的随机性，保留响应中的完整信息（包括评论和推理）可以改善评判效果。此外，成对比较方式在评判编码任务中表现出色。总体而言，这些发现强调了进一步优化LLM-as-a-Judge系统以提高其可靠性和一致性的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.07178", "html_url": "https://arxiv.org/abs/2508.07178", "title": "通过从隐式反馈中去噪假兴趣改进个性化标题生成", "title_en": "Improved Personalized Headline Generation via Denoising Fake Interests from Implicit Feedback", "authors": "Kejin Liu,Junhong Lian,Xiang Ao,Ningtao Wang,Xing Fu,Yu Cheng,Weiqiang Wang,Xinyu Liu", "background": "准确的个性化头条生成依赖于精确捕捉用户的兴趣。现有的方法忽视了在整个历史点击流中出现的个性化无关的点击噪声，这可能导致生成的头条偏离用户的真实偏好。本文通过在用户和新闻维度进行严格的分析，揭示了点击噪声对个性化生成质量的负面影响。", "innovation": "提出了一个新颖的去噪假兴趣自隐式反馈的个性化头生成框架（PHG-DIF），该框架首先使用双重过滤来有效去除由短驻留时间和异常点击簇产生的点击流噪声，然后利用多级时间融合动态建模用户不断变化的多面兴趣，进行精确的用户画像。同时，还发布了包含1000个精心筛选用户和接近10000个带有历史驻留时间注释的个性化头条的DT-PENS新基准数据集。广泛的实验表明，PHG-DIF显著减轻了点击噪声的不良影响，并显著提高了头条的质量，达到了新的SOTA结果。", "conclusion": "通过此次研究，PHG-DIF框架和DT-PENS数据集被证明能够有效减少点击噪声的危害，显著提高头条生成的质量，达到了SOTA水平。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08285", "html_url": "https://arxiv.org/abs/2508.08285", "title": "虚幻的进步：重新评估大语言模型中的幻觉检测", "title_en": "The Illusion of Progress: Re-evaluating Hallucination Detection in LLMs", "authors": "Denis Janiak,Jakub Binkowski,Albert Sawczyn,Bogdan Gabrys,Ravid Shwartz-Ziv,Tomasz Kajdanowicz", "background": "大语言模型（LLMs）极大地改变了自然语言处理领域，然而它们易于产生幻觉的趋势对可靠部署构成了严重挑战。尽管已经提出了许多幻觉检测方法，但它们的评估往往依赖于基于词汇重叠的ROUGE指标，这种指标与人类判断严重不符。通过全面的人类研究，作者揭示了ROUGE具有高召回率但极低的精度，从而导致误导性的性能评估。多项研究表明，当使用如LLM-as-Judge等人员认齐的度量标准评估时，一些现有的检测方法的性能下降高达45.9%。此外，研究还发现，基于响应长度的简单启发式方法可以与复杂的检测技术相媲美，揭示了当前评估实践中存在的根本性缺陷。", "innovation": "研究主要创新点在于揭示了ROUGE等基于词汇重叠的度量标准与人员认齐的度量标准之间存在的重大不一致性，强调采用语义感知的稳健评估框架对于准确衡量幻觉检测方法的实际性能至关重要。同时也指出了一些基于响应长度的简单启发式方法能够与复杂的技术相竞争，这质疑了当前评估方式的有效性。这些发现对幻觉检测方法的发展和改进具有重要指导意义。", "conclusion": "研究结论指出，采用语义感知和稳健的评估框架对于准确评估幻觉检测方法的真正性能至关重要，最终确保大语言模型输出的可靠性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09403", "html_url": "https://arxiv.org/abs/2508.09403", "title": "Columbo：使用大型语言模型扩展表格数据中缩写列名", "title_en": "Columbo: Expanding Abbreviated Column Names for Tabular Data Using Large Language Models", "authors": "Ting Cai,Stephen Sheen,AnHai Doan", "background": "企业在不同领域的企业和科学环境中，以及政府机构中，经常面临将表格中的缩写列名（如'esal'到'employee salary'）扩展为完整名称的问题。这一问题对于众多下游数据任务至关重要。现有技术在这种扩展任务上存在不足，且精度衡量标准严重低估了正确的扩展结果数量。", "innovation": "本文做出了三项创新贡献，显著推进了该领域的前沿技术。首先，作者发现过去使用的合成公共数据有重大局限性，并引入了4个高质量的实际企业/科学领域的数据集。其次，作者证明了现有精度度量大大低估了正确的扩展结果数量，并提出了新的同义词感知度量来更准确地捕捉精度。最后，作者开发了Columbo，一种基于大语言模型的解决方案，利用上下文、规则、链式推理和标记级别分析技术。大规模实验证明，Columbo在5个数据集上显著优于最先进的NameGuess解决方案，性能提升达到4%-29%。此外，Columbo已在环境科学领域的重要数据门户网站EDI中投入生产使用。", "conclusion": "通过引入高质量的实际数据集，提出新的同义词感知度量，并开发基于大语言模型的Columbo解决方案，本文解决了现有技术的局限，显著提升了在扩展表格数据中缩写列名的准确性。Columbo在实际应用中表现出色，并在环境科学的数据字段中发挥关键作用。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08855", "html_url": "https://arxiv.org/abs/2508.08855", "title": "BiasGym: 如何发现和移除大型语言模型中的偏差", "title_en": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them", "authors": "Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein", "background": "理解大型语言模型（LLMs）权重中嵌入的偏见和刻板印象对于开发有效的缓解策略至关重要。这些偏见和刻板印象常常是微妙的，即使是在刻意诱发的情况下也很难被识别，因此进行系统分析和偏见消除都极具挑战性。因此，研究团队开发了一套名为BiasGym的框架，旨在可靠地注入、分析和消除LLMs中的概念关联偏差。这一框架包括两个主要组件：BiasInject和BiasScope，前者能够通过基于标记的微调在保持模型冻结的情况下注入特定的偏见，后者利用这些注入的信号来识别和引导导致偏见行为的组件。", "innovation": "BiasGym框架是一种简单、成本效益高且可推广的方法，用于一致性地引发偏见以进行机制分析，支持有针对性的偏见消除而不降低下游任务的性能，并且能够推广到在标记微调期间未见过的偏见。该方法展示了在减少现实世界刻板印象（如意大利人是“鲁莽的驾驶员”）和探究虚构关联（如来自虚构国家的人“有蓝色的皮肤”）方面的有效性，表明其在安全干预和解释性研究方面的实用性。", "conclusion": "BiasGym框架为大型语言模型中的偏见识别和缓解提供了一种有效的方法，能够一致性地引发偏见以进行机制分析，支持有针对性的偏见消除而不降低下游任务的性能，并且能够推广到在标记微调期间未见过的偏见。该方法在减少现实世界和虚构的刻板印象方面都表现出有效性，展示了其在安全干预和解释性研究中的实用性。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08895", "html_url": "https://arxiv.org/abs/2508.08895", "title": "ASPD: 利用大型语言模型内在并行性实现自适应串行-并行解码", "title_en": "ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs", "authors": "Keyu Chen,Zhifeng Shen,Daohai Yu,Haoqian Wu,Wei Wen,Jianfeng He,Ruizhi Qiao,Xing Sun", "background": "随着大型语言模型（LLMs）规模和复杂性的不断增加，其自回归解码范式的序列特性导致了显著的推理延迟问题。我们重新审视了自回归模型的输出，发现其中一些部分具备并行化结构，称为内在并行性。通过同时解码这些并行分枝（即并行解码），可以显著提升LLMs的总体推理速度。", "innovation": "本文提出了一种自适应串行-并行解码（ASPD），旨在解决两个核心挑战：并行化数据的自动生成和高效的并行解码机制。具体而言，通过非侵入式管道自动提取和验证自回归模型响应中的并行化结构。为了促进高效的自适应串行-并行解码，实现了一个混合解码引擎，该引擎能够在保持可重复使用的KV缓存的同时，在串行和并行解码模式之间无缝切换，最大化计算效率。", "conclusion": "ASPD在通用任务、检索增强生成、数学推理等领域的广泛评估中证明了其在性能和效率上的卓越表现。在其方法的有效性及平均加速比为1.85倍，与自回归模型的回答质量相比区别仅为1%，实现大幅加速而不牺牲生成质量。该框架为高效的LLMs并行推理树立了新的基准，并为在如人工智能驱动的客户服务聊天机器人和答案检索引擎等敏感延迟应用中的部署铺平了道路。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09956", "html_url": "https://arxiv.org/abs/2508.09956", "title": "GPT-5前沿模型在眼科问答中的性能", "title_en": "Performance of GPT-5 Frontier Models in Ophthalmology Question Answering", "authors": "Fares Antaki,David Mikhail,Daniel Milad,Danny A Mammo,Sumit Sharma,Sunil K Srivastava,Bing Yu Chen,Samir Touma,Mertcan Sevgi,Jonathan El-Khoury,Pearse A Keane,Qingyu Chen,Yih Chung Tham,Renaud Duval", "background": "大型语言模型（LLMs）如GPT-5集成了先进的推理能力，可能在复杂的医学问答任务中表现出色。对于这一代推理模型，能够同时最大化准确性和成本效率的最佳配置还未确定。本文通过评估了12种配置的OpenAI GPT-5系列模型，在眼科领域进行测试。", "innovation": "本文评估了12种配置的OpenAI GPT-5系列模型，并引入了一种自动评分框架，该框架能够对比GPT-5模型生成的答案与眼科领域的参考标准。此外，还通过成本-准确性的分析，确定了多个在帕累托边际上的模型配置。", "conclusion": "GPT-5-high在准确率和解释质量上都超过了其他所评估的模型。在成本-准确性的分析中，GPT-5-mini-low提供了高性价比的配置。该研究为GPT-5在眼科领域的性能设定了基准，证明了推理努力对准确率的影响，并引入了在眼科领域自动评分LILM模型答案的框架。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.08557", "html_url": "https://arxiv.org/abs/2502.08557", "title": "通过代理中介辩证性调查的新查询扩展方法", "title_en": "A New Query Expansion Approach via Agent-Mediated Dialogic Inquiry", "authors": "Wonduk Seo,Hyunjin An,Seunghyun Lee", "background": "查询扩展在信息检索（IR）中广泛应用，通过补充初始查询以获得更丰富的内容来提高搜索结果。尽管基于大型语言模型（LLM）的方法能够通过多提示生成伪相关内容和扩展项，但它们通常产生同质且狭窄的扩展，缺乏检索相关信息所需的多样上下文。", "innovation": "本文提出了一种新的多代理框架AMD（Agent-Mediated Dialogic Framework），它包括三个专门的角色：1）苏格拉底式提问代理，将初始查询重新表述为三个子问题，每个问题都由特定的苏格拉底式提问维度启发，包括澄清、假设探查和推论探查；2）辩证性回答代理，生成伪答案，以多种视角丰富查询表示，与用户意图对齐；3）反思反馈代理，评估并完善这些伪答案，确保仅保留最相关和最有信息性的内容。通过多代理过程，AMD有效通过询问和反馈修订构建了更丰富的查询表示。", "conclusion": "在BEIR和TREC等基准测试上的大量实验证明，我们的框架优于以前的方法，提供了一个强大的检索任务解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.08329", "html_url": "https://arxiv.org/abs/2504.08329", "title": "MedRep：面向通用电子健康记录基础模型的医学概念表示", "title_en": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models", "authors": "Junmo Kim,Namkyeong Lee,Jiwon Kim,Kwangsoo Kim", "background": "电子健康记录（EHR）基础模型在各种医疗任务中的表现得到了显著提升，但由于无法处理不在词汇表中的新医疗代码，存在一个根本性的局限性。这种问题限制了EHR基础模型的普适性以及使用不同词汇表训练的模型的整合。", "innovation": "提出了基于观察医疗结果伙伴关系（OMOP）通用数据模型（CDM）的新型医学概念表示（MedRep）方法，通过大型语言模型（LLM）提示和OMOP词汇的图本体来丰富每个概念的信息并增强基于文本的表示。该方法在多种预测任务中优于基础EHR模型和引入的医学代码分词器模型，并证明了MedRep的普适性。", "conclusion": "MedRep在多个预测任务中表现出色，能够提高EHR基础模型的普适性和整合能力。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.09848", "html_url": "https://arxiv.org/abs/2508.09848", "title": "PRELUDE：一种要求全局理解和长文本推理的标准", "title_en": "PRELUDE: A Benchmark Designed to Require Global Comprehension and Reasoning over Long Contexts", "authors": "Mo Yu,Tsz Ting Chung,Chulun Zhou,Tong Li,Rui Lu,Jiangnan Li,Liyan Xu,Haoshu Lu,Ning Zhang,Jing Li,Jie Zhou", "background": "随着自然语言处理技术的发展，研究者们开发了一系列基准测试来评估模型在特定任务上的性能。然而，现有的基准测试往往缺乏对长文本理解和全局推理的全面评估。为了填补这一空白，该文提出了PRELUDE基准，通过判断一个角色的前传故事是否与原始书籍的经典叙述一致的任务，来考察模型在长文本理解方面的强需求，评估其从多个部分的叙述中获取和整合间接相关信息和推理的能力。与现有基准相比，任务更强调全球理解和深层次的推理，因为前传故事并不是原始故事的一部分，评估它们的合理性通常需要搜索和整合仅间接相关的信息。研究表明，约88%的案例需要模型从叙述的多个部分获取证据，现有的模型和商业服务的表现都落后于人类15%以上，反映出模型在处理长文本理解和推理任务时的巨大障碍。进一步的人类研究表明，尽管模型可以找到正确的答案，但往往是通过不正确的推理，与人类相比在逻辑准确率上存在30%以上的差距，这也表明了在长文本理解和推理方面存在的巨大改进空间。", "innovation": "该文介绍了PRELUDE基准，这是首次专门设计用于评估模型在长文本理解上的全球理解和深层次推理能力。在此次基准任务中，模型需要判断角色的前传故事是否与原始书籍的经典叙述一致，这一任务不仅考察了模型对长文本的全面理解和利用间接信息的能力，还要求模型进行深度推理。这是首次将全球理解和长文本推理作为单一基准任务的一部分进行考察，具有很强的创新性。", "conclusion": "实验和进一步的人类研究表明，现有的模型和商业服务在长文本理解和推理方面表现不佳，尤其是在PRELUDE基准中，它们与人类的差距明显。这表明，模型在这一方面的改进空间依然非常大，需要进一步的研究来提高其全球理解和长文本推理的能力。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.18773", "html_url": "https://arxiv.org/abs/2503.18773", "title": "BitDecoding: 解锁低比特KV缓存下Tensor Core对于长上下文LLMs的应用", "title_en": "BitDecoding: Unlocking Tensor Cores for Long-Context LLMs with Low-Bit KV Cache", "authors": "Dayou Du,Shijie Cao,Jianyi Cheng,Luo Mai,Ting Cao,Mao Yang", "background": "长上下文大型语言模型（LLMs）在自回归解码过程中增加了内存和带宽需求，因为随着生成的每个令牌，Key-Value (KV) 缓存也会增加。低比特Kv缓存量化（例如4比特或2比特）可以在保持精度的同时减少内存占用，但现有的系统由于仅依赖CUDA内核，忽视了现代GPU的主要计算源Tensor Cores，因此解码速度较慢。", "innovation": "BitDecoding是一个新的低比特Kv缓存的长上下文LLM推断系统，它通过协同利用CUDA内核和Tensor Cores实现高效的低比特Kv缓存解码。BitDecoding引入了自动诱导优化布局的方法来利用Tensor Cores，并采用寄存器级并行化策略进行解量化。此外，它还包括一个支持各种注意机制的查询转换模块、高性能混合精度操作下支持张量级和信道级缩放的量化内核以及一个自定义管道式的解量化内核，以协调CUDA和Tensor Cores执行。", "conclusion": "在RTX 4090、A100和H100上评估，BitDecoding的解码速度比FP16 FlashDecoding-v2分别加速了7.5倍、4.8倍和8.9倍，并且在与领先的低比特系统QServe相比时，性能提高了最多4.3倍。在LLaMA-3.1-8B中使用128K上下文时，BitDecoding将单批次解码延迟减少了3倍，显示了长上下文生成中的显著改进。代码可以在该链接找到：this https URL."}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.03810", "html_url": "https://arxiv.org/abs/2505.03810", "title": "组序排列旋转：免费优化量化旋转变换", "title_en": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free", "authors": "Euntae Choi,Sumin Song,Woosang Lim,Sungjoo Yoo", "background": "大型语言模型（LLMs）在部署时面临高计算成本的挑战。现有通过后训练量化（PTQ）进行解诀的方法表现通常在低位宽（如2位）时不佳。目前的方法，在低位宽下无法充分降低量化误差，导致模型性能下降。而训练免费方法未被广泛应用，因而研究如何优化量化过程成为亟待解决的问题。", "innovation": "本文提出了一个无需训练的创新方法——组序排列旋转（GSR），该方法通过使用沃尔什-哈达玛变换和按序性排列来构建改进的旋转矩阵。该方法通过聚类相似的频率成分来减少量化误差，显著提高了模型性能。此外，GSR采用块对角矩阵并利用较小的沃尔什块，实现对异常值的隔离，达到了与基于优化的方法相当的性能，且无需任何训练过程。结果显示，该方法在逻辑推理任务和WikiText-2的困惑度评分上表现稳健，并改进了已有学习旋转技术的结果。因此，该研究为低位宽下量化模型的优化提供了有效的解决方案。", "conclusion": "本文提出了一种无需训练的组序排列旋转方法，显著提高了低位宽量化条件下模型的性能。该方法通过聚类相似的频率成分减少量化误差，实现了与基于优化方法相当的性能，且在逻辑推理和WikiText-2困惑度评分上表现稳健。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15485", "html_url": "https://arxiv.org/abs/2504.15485", "title": "CAPTURe：通过遮挡物体计数评估视觉语言模型的空间推理能力", "title_en": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting", "authors": "Atin Pothiraj,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal", "background": "理解具有遮挡（部分或完全隐藏）物体的场景至关重要，因为遮挡在真实世界环境中经常发生，并会阻碍空间理解。为了测试模型在处理多个被遮挡物体时的能力，引入了一个新颖的任务——计数跨不可见区域的模式（即CAPTURe），要求模型通过推断遮挡物后的情况来计算按模式排列的物体数量。该任务结合了识别视觉模式和推理，作为视觉语言模型（VLMs）的表现测试。CAPTURe还测试了模型构建世界模型的能力，以填补缺失信息。", "innovation": "提出了一个新颖的任务——CAPTURe，专门测试VLMs在处理遮挡物体时的计数和推理能力，填补了现有视觉语言模型评估中对遮挡物体理解和推理能力测试的空白。", "conclusion": "尽管当前最强的VLMs（如GPT-4o等）在不考虑遮挡的情况下表现良好，但在具有遮挡的情况下，它们的表现显著下降，这表明VLMs在推断看不见的空间关系方面存在缺陷。相比之下，人类在CAPTURe任务上几乎没有错误。此外，提供遮挡物体位置的辅助信息可以提高模型性能，这表明模型错误来源于处理遮挡物体的能力不足和图像计数的困难。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13109", "html_url": "https://arxiv.org/abs/2505.13109", "title": "FreeKV: 提升KV缓存检索效率以实现高效的大型语言模型推理", "title_en": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference", "authors": "Guangda Liu,Chengwei Li,Zhenyu Ning,Minyi Guo,Jieru Zhao", "background": "大型语言模型（LLMs）由于支持日益复杂的应用，其上下文窗口迅速扩大。然而，长上下文带来了显著的部署挑战，主要原因在于KV缓存的大小与上下文长度成正比增长。虽然已经提出了KV缓存压缩方法，但KV丢弃方法会导致重大准确率损失，而KV检索方法则面临显著的效率瓶颈。", "innovation": "FreeKV 提出了一种算法-系统协同优化框架，旨在提高KV检索效率同时保持准确率。在算法层面，FreeKV 引入了推测检索，将KV的选择和召回过程移出关键路径，并结合精细粒度的校正以确保准确率。在系统层面，FreeKV 使用CPU和GPU内存中的混合KV布局来消除碎片化数据传输，并利用双缓冲流式检索以进一步提高效率。", "conclusion": "实验表明，FreeKV 在各种场景和模型中实现了近乎无损的准确率，并且相比最先进的KV检索方法，可以达到最高13倍的加速效果。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.22793", "html_url": "https://arxiv.org/abs/2505.22793", "title": "视觉-语言模型的文化胜任能力评估", "title_en": "Evaluation of Cultural Competence of Vision-Language Models", "authors": "Srishti Yadav,Lauren Tilton,Maria Antoniak,Taylor Arnold,Jiaang Li,Siddhesh Milind Pawar,Antonia Karamolegkou,Stella Frank,Zhaochong An,Negar Rostamzadeh,Daniel Hershcovich,Serge Belongie,Ekaterina Shutova", "background": "现代的视觉-语言模型（VLMs）在文化适应性评估和基准测试中经常表现出不足。鉴于基于VLMs的应用多样性，人们重新关注它们如何编码文化细微差别。尽管在这一问题的各个层面已经进行了研究，但对于识别和注释图像中对VLMs重要的微妙文化维度仍然缺乏一个全面的框架。", "innovation": "本文引入了一套五种框架，对应于五种文化维度，这些框架对于完善对VLMs文化胜任能力的分析是必需的。这些框架来自视觉文化研究的基础方法（文化研究、符号学和视觉研究），旨在填补现有研究的空白，提供一个系统的方法来分析VLMs的文化适应性问题。", "conclusion": "本文通过提出这些文化维度框架，强调了视觉文化研究的基础方法对于分析图像中VLMs所涉及的文化细微差别的必要性，从而推动了对VLMs文化适应性理解的提升。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.15758", "html_url": "https://arxiv.org/abs/2507.15758", "title": "LAPO: 内化推理效率的长度自适应策略优化", "title_en": "LAPO: Internalizing Reasoning Efficiency via Length-Adaptive Policy Optimization", "authors": "Xingyu Wu,Yuchen Yan,Shangke Lyu,Linjuan Wu,Yiwen Qiu,Yongliang Shen,Weiming Lu,Jian Shao,Jun Xiao,Yueting Zhuang", "background": "大型推理模型通过扩展因果推理序列取得了显著性能，但这一计算自由度导致了即使是简单问题也会出现过度的标记生成。现有方法要么设定严格的限制，要么依赖于事后干预，这些方法都不能使模型内部化适当推理深度的理解。", "innovation": "提出了长度自适应策略优化（LAPO）框架，将推理长度控制从外部约束转化为模型的内在能力。通过两阶段的强化学习过程，模型学习自然的推理模式，并将这些模式嵌入到推理上下文中，确保推理时的灵活性。", "conclusion": "在数学推理基准测试中，使用LAPO可以减少达40.9%的标记使用且提高准确性2.3%。分析表明，通过LAPO训练的模型能够根据问题复杂性分配计算资源，从而实现高效的推理而不牺牲质量。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.22493", "html_url": "https://arxiv.org/abs/2506.22493", "title": "对政治倾向测试的详细因素分析：导航大型语言模型的意识形态", "title_en": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models", "authors": "Sadia Kamal,Lalu Prasad Yadav Prakash,S M Rafiuddin,Mohammed Rakib,Atriya Sen,Sagnik Ray Choudhury", "background": "长期以来，政治倾向测试（PCT）或类似问卷被用来量化大型语言模型（LLM）的政治倾向。近年来，一些研究开始探讨PCT测试的有效性。本研究在此基础上，通过考察不同的生成参数对PCT评分的影响，发现这些参数的变化对模型的PCT评分影响不大。然而，外部因素，如提示的变化和微调，单独或共同作用时会对PCT评分产生影响。同时，研究还发现当模型在具有较高政治内容的数据集上进行微调时，其PCT评分并没有不同。”翻译参考“背景”段落内容。”", "innovation": "研究证明，变异性标准生成参数对模型的PCT评分影响不大，但外部因素如提示变化和微调单独或组合起来对PCT评分有显著影响。此外，研究还发现，当模型在具有较高政治内容的数据集上进行微调时，PCT评分没有不同，这表明需要对PCT和其他类似测试的有效性进行全面探讨，并研究政治倾向在LLM中的编码机制。”翻译参考“创新”段落内容。”", "conclusion": "研究结果表明，需要对PCT和其他类似测试的有效性进行全面探讨，同时还需要深入研究政治倾向如何被编码到LLM中。”翻译参考“结论”段落内容。”"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23701", "html_url": "https://arxiv.org/abs/2507.23701", "title": "TextQuests：LLM在文本冒险游戏中的表现如何？", "title_en": "TextQuests: How Good are LLMs at Text-Based Video Games?", "authors": "Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks", "background": "在复杂数字交互环境中评估人工智能（AI）代理的能力是理解其实际应用能力的关键。现有的AI代理基准测试虽然能够评估诸如工具使用或完成结构化任务等技能，但往往未能全面捕捉代理在探索性环境中自主操作的能力，这些环境要求在长时间和不断扩大的上下文中进行持续的自我驱动推理。因此，需要一种新的基准测试来更准确地评估AI代理在具有挑战性的探索性环境中的能力。", "innovation": "介绍了基于Infocom套件的交互式文字冒险游戏的基准测试TextQuests。这种基于文本的冒险游戏通常需要人类玩家超过30小时，并需要数百次精确操作才能解决，因此是评估AI代理在集中、有状态任务上表现的有效替代物。此基准测试特为阻止使用外部工具，从而专注于在单一交互会话中涉及试错学习和持续问题解决的探索性环境中的内在长上下文推理能力。", "conclusion": "TextQuests基准测试专门设计用于评估大语言模型（LLM）的自我问题解决能力，它聚焦于在无外设工具的帮助下，在一个需要尝试多次学习和长期解决问题的环境中，评估建模长期上下文推理的能力。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15935", "html_url": "https://arxiv.org/abs/2505.15935", "title": "MAPS: 多语言基准套件，用于全球智能代理性能和安全性", "title_en": "MAPS: A Multilingual Benchmark for Global Agent Performance and Security", "authors": "Omer Hofman,Jonathan Brokman,Oren Rachmil,Shamik Bose,Vikas Pahuja,Toshiya Shimizu,Trisha Starostina,Kelly Marchisio,Seraphina Goldfarb-Tarrant,Roman Vainshtein", "background": "大型语言模型（LLMs）构建的智能代理系统因其在能力和范围上的快速进步而迅速发展。然而，这些模型在多语言环境中表现出局限性，通常导致性能降低和安全性的减弱。这引发了用户使用非英语语言时可能会遇到不可靠或安全关键的代理行为的担忧。尽管有越来越多的兴趣和评估智能代理系统，但现有的基准测试集中于英语，忽视了多语言环境。因此，本文提出了MAPS，一种多语言基准套件，用于在多种语言和任务上评估智能代理系统。MAPS借鉴了四个广泛使用的智能代理基准：GAIA（实际任务）、SWE-bench（代码生成）、MATH（数学推理）和代理安全性基准（安全性）的数据集，并将其翻译成11种不同的语言，共计805项独特任务和9,660项语言特定的实例，以便系统地分析多语言对AI代理性能和鲁棒性的影响。实证研究表明，当从英语过渡到其他语言时，智能代理的性能和安全性都会下降，具体严重程度因任务而异，且与所翻译输入的数量相关联。", "innovation": "本文提出了MAPS，一种多语言基准套件，填补了多语言环境中评估智能代理系统性能和安全性的空白。通过将四个重要基准数据集翻译成11种语言，MAPS能够系统地分析不同语言对智能代理系统的影响。方法在于设计一个标准化评估框架，使研究者能够更公平、可靠地评估多语言环境中的智能代理系统的性能和安全性。此外，基于实证研究，本文提供了关于在这种情境下开发和评估智能代理系统的具体建议，实际上推动了构建更公平、可靠和可访问的智能代理目标的研究。MAPS基准套件现在已经开源。 ", "conclusion": "MAPS为多语言环境中的智能代理系统确立了第一个标准化评估框架，促成了未来研究中更具公平性、可靠性和可访问性的智能代理系统的开发。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.04586", "html_url": "https://arxiv.org/abs/2508.04586", "title": "当前AI会议模式不可持续！中央化AI会议危机诊断", "title_en": "Position: The Current AI Conference Model is Unsustainable! Diagnosing the Crisis of Centralized AI Conference", "authors": "Nuo Chen,Moming Duan,Andre Huikai Lin,Qian Wang,Jiaying Wu,Bingsheng He", "background": "人工智能（AI）会议对于促进研究、分享知识和培养学术社区至关重要。然而，会议的快速扩张已经使得集中式的会议模式变得越来越难以持续。该文通过数据分析诊断了一个结构性危机，这一危机威胁到科学传播、公平和社区福祉的基本目标。该文指出了四个关键压力点：在科学方面，每位作者的平均发表论文数量在过去十年中翻了一番多，每年超过4.5篇；在环境方面，一个会议的碳足迹超出了其主办城市一天的排放量；在心理方面，71%的在线社区讨论反映出负面情绪，35%提到了心理健康问题；在物流方面，顶级会议如NeurIPS 2024的参会人数开始超出场地容量。这些压力揭示了该系统与核心使命的脱节。", "innovation": "该文提出了一种社区联合会（CFC）模型，将同行评审、展示和网络活动拆分为全球协调但本地组织的组成部分，提供了一条更可持续、更具包容性和韧性的AI研究路径。", "conclusion": "现有AI会议模式面临系统性的危机，需要新的会议模型来解决由此带来的各种问题，以更好地支持科学传播、公平和社区福祉。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.06412", "html_url": "https://arxiv.org/abs/2508.06412", "title": "Reset Replay 方法在提高大语言模型优化效率中的应用", "title_en": "Sample-efficient LLM Optimization with Reset Replay", "authors": "Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian", "background": "最新的大语言模型（LLMs）增强推理能力的方法主要依靠强化学习（RL）及偏好优化技术，但这些方法普遍存在样本效率低和首因效应偏见的问题，即过度拟合初始经验会影响策略质量，并损害学习过程。研究旨在解决这些挑战。", "innovation": "论文提出了一种名为LoRR的Reset Replay优化插件，旨在提高任何偏好优化框架中的样本效率。LoRR通过高重放次数训练来最大化每批数据的利用，并引入周期性重置策略以保持网络的可塑性。此外，它结合监督微调和偏好损失，以进一步提高数据利用。实验结果显示LoRR显著提升了各种偏好优化方法在数学和一般推理基准上的性能，特别在解决困难的数学任务时表现出色，优于一些复杂的强化学习算法。", "conclusion": "LoRR提供了一种实用、样本高效的PPP（偏好优化策略）插件，对于有限数据集来说能够显著提升大语言模型的性能。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10104", "html_url": "https://arxiv.org/abs/2508.10104", "title": "DINOv3", "title_en": "DINOv3", "authors": "Oriane Siméoni,Huy V. Vo,Maximilian Seitzer,Federico Baldassarre,Maxime Oquab,Cijo Jose,Vasil Khalidov,Marc Szafraniec,Seungeun Yi,Michaël Ramamonjisoa,Francisco Massa,Daniel Haziza,Luca Wehrstedt,Jianyuan Wang,Timothée Darcet,Théo Moutakanni,Leonel Sentana,Claire Roberts,Andrea Vedaldi,Jamie Tolan,John Brandt,Camille Couprie,Julien Mairal,Hervé Jégou,Patrick Labatut,Piotr Bojanowski", "background": "自监督学习有望消除手动数据标注的需要，使模型能够轻松扩展到巨大的数据集和更大的架构。通过不针对特定任务或领域进行定制，这种训练范式有可能从各种来源（从自然图像到航空图像）学习视觉表示，并且仅使用单个算法即可完成。", "innovation": "首先，通过仔细的数据准备、设计和优化，平衡数据集和模型的大小。其次，引入了一种新的方法——Gram锚定，有效地解决了在长期训练时间表中密集特征图退化的问题。最后，应用了后处理策略，进一步增强了模型对于分辨率、模型大小和与文本对齐的灵活性。DINOv3由此产生，这是一种多功能的视觉基础模型，无需微调，即可在广泛的设置中超越专门的最先进的方法，取得了卓越的表现。", "conclusion": "DINOv3生成高质量的密集特征，显著超越了之前的自监督和弱监督基础模型，实现了各种视觉任务的出色性能。我们也分享了DINOv3视觉模型套件，旨在通过提供针对各种资源约束和部署场景的可扩展解决方案来推动一系列任务和数据上的先进状态。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.08508", "html_url": "https://arxiv.org/abs/2508.08508", "title": "Re:Verse -- 能让VLM读懂漫画吗？", "title_en": "Re:Verse -- Can Your VLM Read a Manga?", "authors": "Aaditya Baranwal,Madhav Kataria,Naitik Agrawal,Yogesh S Rawat,Shruti Vyas", "background": "当前的视觉语言模型（VLM）在处理连续视觉叙事时，存在从表层识别到深层叙事推理的关键差距。通过全面调查漫画叙事理解，发现尽管最近的大型多模态模型在单帧解释上表现出色，但在时间因果关系和跨帧一致性等核心要求上系统地失败。研究人员提出了一种新的评估框架，结合细粒度多模态注释、跨模态嵌入分析和检索增强评估，系统地表征这些限制。", "innovation": "介绍了结合细粒度多模态标注、跨模态嵌入分析和检索增强评估的新评价框架，用于系统地表征这些限制。研究包含严谨的标注协议，连接视觉元素与叙事结构，跨多个推理范式全面评估，以及跨模态相似性分析揭示了当前VLM们在联合表示中的根本错位。", "conclusion": "当前模型缺乏真正的故事级智能，尤其在非线性叙事、角色一致性以及长期序列中的因果推理方面存在困难。这项工作建立了评价叙事智能的基础和实用方法，同时提供了关于在多模态模型中超越基本识别的离散视觉叙事深度序列理解能力的可操作见解。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10066", "html_url": "https://arxiv.org/abs/2508.10066", "title": "基于随机性的局部图块过滤在少样本学习中的应用", "title_en": "Stochastic-based Patch Filtering for Few-Shot Learning", "authors": "Javier Rodenas,Eduardo Aguilar,Petia Radeva", "background": "由于食物图像的视觉复杂性和多样性，它们为少样本学习模型带来了独特挑战。例如，一道意大利面可能在不同盘子上呈现不同的装饰，并在多种照明条件下和不同的摄像头视角下展示。这导致在比较查询图像和支持图像时注意力主要集中在次要元素上，从而导致误分类。这个问题使得模型在处理新型别时难以准确识别关键特征，提供了少样本学习中的挑战背景。", "innovation": "提出了一种基于随机性的局部图块过滤方法（SPFF）的方法，该方法旨在关注与类别表征有更强相关性的局部图块嵌入。关键概念在于随机过滤局部图块嵌入，对与类别感知嵌入相似度较低的局部图块更有可能进行过滤。通过过滤机制，依据可视化概率进一步量化查询图像与其支持图像之间的相似度矩阵，展示了SPFF能够有效聚焦于显示类别特异性食物特征最为显著的局部图块，同时成功排除无关局部图块。这是一种利用随机性选择注意力焦点的新颖方法，能够减少自然变异的影响，提高少样本学习模型的性能。", "conclusion": "通过广泛的实验验证了少样本分类基准测试（Food-101，VireoFood-172和UECFood-256），SPFF方法优于现有最先进的方法，实验结果表明SPFF方法能够更准确地识别少样本学习中的关键特征，从而提高分类准确率和鲁棒性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10110", "html_url": "https://arxiv.org/abs/2508.10110", "title": "使用可解释的图像-文本基础模型增强变形攻击检测", "title_en": "Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model", "authors": "Sushrut Patwardhan,Raghavendra Ramachandra,Sushma Venkatesh", "background": "面部识别系统需要可靠的验证场景，而变形攻击检测已成为关键组成部分。本文提出了一个跨模态学习方法，能够提供变形攻击检测的文本描述。研究首先展示了使用对比语言-图像预训练（CLIP）进行无监督评估可以不仅实现泛化的变形攻击检测，还能预测最相关的文本片段。结果显示，通过精心设计的文本提示，系统能够在多种变形生成技术中准确识别攻击，涵盖了视频、图像和3D等多种介质。", "innovation": "本文的创新在于结合了文本和图像的跨模态学习方法，通过对比语言-图像预训练模型实现无监督的变形攻击检测，并且能够预测最相关的文本片段。研究通过对不同的文本提示进行广泛分析，优化了检测的准确性和可解释性，特别是在多种变形生成技术场景下的应用。", "conclusion": "本文通过对比语言-图像预训练模型实现了变形攻击检测的无监督学习，并通过广泛的实验验证了这种方法的有效性。结果表明，提出的框架能够在多种介质下有效地检测变形攻击，并能够提供有解释性的文本描述，为面部识别系统的可靠验证提供了有力支持。"}
{"llm_update_time": "20250817", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.05571", "html_url": "https://arxiv.org/abs/2508.05571", "title": "iFairy：所有参数在{±1, ±i}的首个2比特复数LLM", "title_en": "iFairy: the First 2-bit Complex LLM with All Parameters in $\\{\\pm1, \\pm i\\}$", "authors": "Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang", "background": "量化感知训练（QAT）将量化过程嵌入到训练循环中，使大语言模型（LLMs）能够在低位宽表示中学习到鲁棒的表示，成为最具前景的研究方向之一。当前的QAT研究主要集中在最小化全员精度模型的量化误差上，全员精度的准确性被视为上限，目前没有任何方法能够突破这一上限。尽管现有方法都在努力最小量化误差，但很少尝试突破全员精度模型的上限，直接从全员精度模型进行2比特量化以提高模型的准确性和效率。", "innovation": "本文提出了一个新的量化框架Fairy$±i$，以突破当前对全员精度模型上限的依赖。Fairy$±i$ 将权重映射到单位根的四个根$±1, ±i$，构建一个完全对称且信息论上最优的2比特表示。每个量化权重要么实部要么虚部为零，从而能够利用仅加法和位交换的无乘法推理。实验结果表明，Fairy$±i$ 在 perplexity（PPL）和下游任务上均优于现有2比特量化方案，同时保持严格的存储和计算效率。", "conclusion": "本文提出了一种新的量化框架Fairy$±i$，在全员精度模型上采用2比特量化，极大地提高了模型准确性，同时保持了存储和计算效率。该框架打破了当前全员精度模型的准确度上限，为构建在极度低比特位宽约束下仍能保持高准确性和实用性的大语言模型提供了一个新的方向。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10132", "html_url": "https://arxiv.org/abs/2508.10132", "title": "基于深度学习的全身DXA成像大规模形态和外观建模", "title_en": "Deep Learning Enables Large-Scale Shape and Appearance Modeling in Total-Body DXA Imaging", "authors": "Arianna Bunnell,Devon Cataldi,Yannik Glaser,Thomas K. Wolfgruber,Steven Heymsfield,Alan B. Zonderman,Thomas L. Kelly,Peter Sadowski,John A. Shepherd", "background": "全身双能X射线吸收造影（TBDXA）成像是评估身体成分的一种相对低成本的影像学模态，被广泛应用。本研究开发并验证了一种基于深度学习的方法，用于自动在TBDXA扫描图上放置关键点，通过1,683张手动注释的TBDXA扫描图实现了外部测试数据集99.5%的正确关键点比率。", "innovation": "开发并验证了一种基于深度学习的关键点自动标注方法，应用于不同TBDXA成像模式的35,928张扫描图上，通过两样本Kolmogorov-Smirnov检验，分析了形态和外观模型与健康标记之间的关联，验证并提出了关于身体构成和形态与多种脆弱性、代谢、炎性及心代谢健康标志之间关系的新假设。", "conclusion": "通过深度学习技术，实现了全身DXA影像中大范围形态和外观模型的构建，并展示了与健康标志之间的相关性，验证了现有证据并提出了新的假设。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10113", "html_url": "https://arxiv.org/abs/2508.10113", "title": "通过LVLMs进行基于部首和象形分析的可解释甲骨文解码", "title_en": "Interpretable Oracle Bone Script Decipherment through Radical and Pictographic Analysis with LVLMs", "authors": "Kaixin Peng,Mengyang Zhao,Haiyang Yu,Teng Fu,Bin Li", "background": "作为最古老的成熟书写系统，甲骨文的解读长期以来一直面临重大挑战，因为它非常稀有、抽象且具有象形多样性。当前的基于深度学习的方法在甲骨文解码任务上取得了令人兴奋的进步，但现有方法往往忽略了甲骨文字符与其象形意义之间的复杂联系。这导致了在零样本情景和未解甲骨文中的有限泛化和解释性。", "innovation": "提出了一种基于大型视觉-语言模型的可解释甲骨文解码方法，该方法结合了部首分析和象形图像-语义理解，以弥合甲骨文字符与意义之间的差距。具体来说，提出了一个逐步训练策略，引导模型从部首识别和分析到象形分析和相互分析，从而实现从字符到意义的推理。设计了一种基于分析结果的部首-象形双模态匹配机制，显著增强了模型的零样本解码性能。", "conclusion": "通过公共基准上的实验结果，我们的方法在Top-10准确性上达到了最新技术水平，并且具有更强的零样本解码能力。更重要的是，我们的模型提供了逻辑分析过程，可能为未解甲骨文提供有价值的考古参考结果，具有在数字人文学科和历史研究中应用的潜力。数据集和代码将在该网址发布：https://www.example.com/"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10133", "html_url": "https://arxiv.org/abs/2508.10133", "title": "MANGO: 基于多模态注意力归一化流的融合学习方法", "title_en": "MANGO: Multimodal Attention-based Normalizing Flow Approach to Fusion Learning", "authors": "Thanh-Dat Truong,Christophe Bobda,Nitin Agarwal,Khoa Luu", "background": "近年来，多模态学习获得了显著的成功。然而，当前的多模态融合方法主要依赖于变换器的注意力机制来隐式地学习跨模态特征之间的潜在关联，导致多模态模型难以捕捉每种模态的基本特征，以及难以理解多模态输入的复杂结构和关联。", "innovation": "本文提出了一种新颖的多模态注意力归一化流（MANGO）方法，通过引入可逆交叉注意力（ICA）层来开发基于归一化流模型的多模态数据融合学习。该方法提出了三种新的跨注意力机制：模态到模态交叉注意力（MMCA）、跨模态交叉注意力（IMCA）和可学习的跨模态交叉注意力（LICA），以有效捕捉多模态数据中的复杂潜在关联。最后，提出了一种新的多模态注意力归一化流来使本方法在高维多模态数据上的可扩展性。", "conclusion": "我们在三种不同多模态学习任务，即语义分割、图像到图像转换和电影类型分类上的实验结果表明，所提出的方法能够实现最先进的性能。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10156", "html_url": "https://arxiv.org/abs/2508.10156", "title": "利用基于生成人工智能（GenAI）的合成和实地图像改善甜瓜（Citrullus lanatus）病害分类", "title_en": "Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model", "authors": "Nitin Rai,Nathan S. Boyd,Gary E. Vallad,Arnold W. Schumann", "background": "当前生成人工智能（GenAI）模型的发展为生成高分辨率合成图像提供了新途径，这为农业中计算机视觉模型的训练提供了替代传统图像采集的潜在替代方案。在作物病害诊断中，GenAI模型被用于生成各种病害的合成图像，可能有助于模型的创建并减少对资源密集型田间数据采集的依赖。然而，关于结合实际图像和合成图像以提高疾病分类性能的研究较少。因此，本文研究了有限数量的实际图像与合成图像结合是否可以提升EfficientNetV2-L模型对甜瓜病害的分类准确性。", "innovation": "研究采用了一种定制的EfficientNetV2-L架构，并通过增强的微调和迁移学习技术，研究了实际图像与合成图像结合（比例为1:1、1:10和1:10加上随机图像以提高多样性和模型泛化能力）对甜瓜病害分类模型性能和泛化能力的影响。实验证明，结合实际与合成图像的混合方法可以显著提高模型性能。", "conclusion": "综合来说，合成图像不能完全替代实际图像；实际图像和合成图像应以混合方式使用以最大化作物病害分类模型的性能。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10171", "html_url": "https://arxiv.org/abs/2508.10171", "title": "SynSpill: 用合成数据改进工业溢出检测", "title_en": "SynSpill: Improved Industrial Spill Detection With Synthetic Data", "authors": "Aaditya Baranwal,Abdul Mueez,Jason Voelker,Guneet Bhatia,Shruti Vyas", "background": "大型的视觉-语言模型（VLMs）通过其强大的零样本能力，已经改变了通用视觉识别。然而，在具有隐私、数据敏感性和真实事件罕见的工业溢出检测等专业、安全关键领域，它们的表现显著下降。由于数据稀缺，这使得在大多数工业环境中无法为检测器进行常规微调。因此，需要一个适用于此类专有环境的有效解决方案，本文介绍了一个可扩展框架，其核心是一个高质量合成数据生成管道，通过这种合成数据集可有效地进行参数优化微调（PEFT）并大幅提升最先进的对象检测器如YOLO和DETR的表现。", "innovation": "本文提出了一种合成数据生成框架，该框架能够有效进行参数优化微调（PEFT），并且合成数据使得视觉语言模型（VLMs）和最先进的对象检测器能够更好地适应未见过的溢出场景。利用合成数据集（SynSpill），VLMs和对象检测器在溢出检测任务上的表现明显提高，其性能变得可与对方相媲美。这项成果证明了高质量合成数据在安全关键应用中弥合领域差距的强大能力。", "conclusion": "合成生成与轻量级适应的结合，提供了一种成本效益高、可扩展的途径，便于在稀缺/难以获取真实数据的工业环境中部署视觉系统。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10232", "html_url": "https://arxiv.org/abs/2508.10232", "title": "CellSymphony: 利用单细胞病理学解析细胞的分子和表型调控", "title_en": "CellSymphony: Deciphering the molecular and phenotypic orchestration of cells with single-cell pathomics", "authors": "Paul H. Acosta,Pingjun Chen,Simon P. Castillo,Maria Esther Salvatierra,Yinyin Yuan,Xiaoxi Pan", "background": "尽管组织学图像富含细胞形态信息，但提取可靠的细胞级特征并将这些特征与空间转录组学数据整合仍然是一个关键挑战。Xeni是一种新的空间转录组学平台，能够实现复杂肿瘤组织的亚细胞分辨率分析。", "innovation": "提出了CellSymphony，这是一种灵活的多模态框架，结合了Xeni转录组学资料和高分辨率组织学图像中提取的基础模型衍生嵌入。通过学习融合空间基因表达与形态学上下文的联合表示，CellSymphony实现了准确的细胞类型注释，并在三种癌症类型中揭示了独特的微环境生态位。这项工作强调了基础模型和多模态融合在解析复杂组织生态系统中细胞的生理和表型调控方面的潜力。", "conclusion": "CellSymphony通过融合空间基因表达与形态学特征，成功地实现了复杂肿瘤组织中细胞类型的准确注释，并揭示了微环境生态位，突显了基础模型和多模态融合在这一领域的应用潜力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10227", "html_url": "https://arxiv.org/abs/2508.10227", "title": "EntropyGS：3D高斯点三维几何句法编码", "title_en": "EntropyGS: An Efficient Entropy Coding on 3D Gaussian Splatting", "authors": "Yuning Huang,Jiahao Pang,Fengqing Zhu,Dong Tian", "background": "3D Gaussian Splatting (3DGS) 是一种新兴的新型视图合成方法，具有快速训练/渲染以及卓越的视觉质量。然而，由于3DGS的两大任务——高斯创建和视图渲染通常是分开的时间或设备上完成的，因此需要存储/传输3D高斯模型并对它们进行压缩。", "innovation": "这项工作提出了一个新方法——熵编码方法EntropyGS。通过对3D高斯的统计分析，发现Spherical Harmonic AC属性严格遵循拉普拉斯分布，而旋转、缩放和透明度可以通过混合高斯分布进行近似。此外，谐波AC属性与其他属性之间基本不相关，除了从颜色空间继承的相关性。EntrophyGS通过因素化和参数化熵编码方法在编码过程中估计每个高斯属性的概率分布参数，以辅助其熵编码，并根据高斯属性类型动态地进行量化。该方法在基准数据集上显示了约30倍的数据压缩率，同时保持了与输入3DGS数据相近的渲染质量，并且具有快速编码和解码时间。", "conclusion": "EntropyGS在保持类似渲染质量的同时，通过对3D高斯属性的概率分布参数进行估计，并且根据高斯属性的类型动态地进行量化，实现了约30倍的压缩率，且具备快速编码和解码时间。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10256", "html_url": "https://arxiv.org/abs/2508.10256", "title": "基于深度学习的裂纹检测：学习范式、泛化能力和数据集的综述", "title_en": "Deep Learning for Crack Detection: A Review of Learning Paradigms, Generalizability, and Datasets", "authors": "Xinan Zhang,Haolin Wang,Yung-An Hsieh,Zhongyu Yang,Anthony Yezzi,Yi-Chang Tsai", "background": "裂纹检测在基础设施检查中至关重要，包括路面和建筑物的检查。近年来，深度学习在这一领域取得了显著进展。尽管有大量的技术性及综述性论文，但新兴趋势正在重新塑造这一领域的格局。这些趋势涵盖了学习范式的变化（从全监督学习到半监督、弱监督、无监督、少样本、域适应和微调基础模型）、泛化能力的改进（从单数据集到跨数据集评估）以及数据集获取的多样化（从RGB图像到专门传感器数据）。", "innovation": "本综述系统分析了这些趋势，并突出了一些代表性的工作。此外，本书介绍了一个基于3D激光扫描的新数据集--3DCrack，以支持未来的研究，并进行了广泛的基准实验，为常见的深度学习方法，包括最新基础模型，建立了基线。我们的研究为基于深度学习的裂纹检测提供了关于最新方法和未来方向的见解。", "conclusion": "本综述提供了关于深度学习在裂纹检测领域中不断演变的方法和未来方向的见解。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10264", "html_url": "https://arxiv.org/abs/2508.10264", "title": "MRFD：Louis 语言和视觉模型中减轻幻觉的自我一致性多区域融合解码", "title_en": "MRFD: Multi-Region Fusion Decoding with Self-Consistency for Mitigating Hallucinations in LVLMs", "authors": "Haonan Ge,Yiwei Wang,Ming-Hsuan Yang,Yujun Cai", "background": "大型多模态语言模型（LVLMs）在多项任务中表现出色，但往往会产生与视觉输入不一致的幻觉，这是因为它们在验证图像不同区域的信息方面的能力有限。", "innovation": "提出了多区域融合解码（MRFD），这是一种无需训练的解码方法，通过建模跨区域一致性来改善事实锚定。MRFD 使用交叉注意力识别关键区域，为每个区域生成初始响应，并根据响应之间的杰普森-香农散度（JSD）计算可靠性权重。这些权重指导基于链式推理区域意识提示的连贯性感知融合。", "conclusion": "在多个LVLMs和基准测试中进行的实验表明，MRFD 在大幅度减少幻觉的同时，提高了响应的事实准确性，而无需对模型进行更新。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10268", "html_url": "https://arxiv.org/abs/2508.10268", "title": "面向移动电话的基于姿态鲁棒的视线估计校准策略", "title_en": "Pose-Robust Calibration Strategy for Point-of-Gaze Estimation on Mobile Phones", "authors": "Yujie Zhao,Jiabei Zeng,Shiguang Shan", "background": "尽管基于外貌的注视点（PoG）估计有所改进，但估计器仍然难以在个体间泛化，由于个人差异。因此，需要针对个人进行校准以确保准确的PoG估计。然而，校准后的估计器对头部姿态变化非常敏感。针对这一问题，我们研究影响校准估计器的关键因素，并探索姿态稳健的校准策略。我们构建了一个基准MobilePoG，包含32个人的面部图像，这些面部图像要么在固定头部姿态下要么在连续变化的头部姿态下关注特定点。利用这个基准，我们系统地分析校准点的多样性和头部姿态的变化如何影响估计准确性。", "innovation": "我们提出了一个动态校准策略，用户在此过程中可以在移动设备上注视校准点，而同时移动设备。这自然在用户友好且高效的校准过程中引入了头部姿态的变化，最终生成一个对头部姿态变化不那么敏感的校准后的PoG估计器，比起使用传统校准策略的估计器更有优势。", "conclusion": "通过引入更广泛的头部姿态来进行校准，提高了估计器处理姿态变化的能力。我们的基准MobilePoG和实验表明动态校准策略可以显著减少校准后的估计器对头部姿态变化的敏感性，同时保持操作简便和高效。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10280", "html_url": "https://arxiv.org/abs/2508.10280", "title": "高保真文本到图像生成：对比对齐和结构引导", "title_en": "High Fidelity Text to Image Generation with Contrastive Alignment and Structural Guidance", "authors": "Danyi Gao", "background": "现有文本驱动的图像生成方法在语义对齐准确性和结构一致性方面存在性能瓶颈。", "innovation": "提出了一种集成文本-图像对比约束和结构引导机制的高保真图像生成方法。该方法引入了一个对比学习模块，建立强跨模态对齐约束以提高文本和图像之间的语义匹配。同时，使用语义布局图或边缘素描等结构先验，指导生成器在空间级结构建模中，增强生成图像的布局完整性和细节保真度。模型在整体框架中联合优化对比损失、结构一致性损失和语义保真损失。采用多目标监督机制，提高生成内容的语义一致性和可控性。", "conclusion": "系统实验在COCO-2014数据集上进行，敏感性分析结果显示了所提方法在CLIP得分、FID和SSIM方面的优越性能。实验结果表明，该方法在不增加计算复杂度的情况下有效弥补了语义对齐和结构保真的差距，能够生成语义清晰、结构完备的图像，为联合文本和图像模型及其图像生成提供了一种可行的技术路径。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10287", "html_url": "https://arxiv.org/abs/2508.10287", "title": "JRDB-Reasoning：面向机器人中视觉推理的分级基准", "title_en": "JRDB-Reasoning: A Difficulty-Graded Benchmark for Visual Reasoning in Robotics", "authors": "Simindokht Jahangard,Mehrzad Mohammadi,Yi Shen,Zhixi Cai,Hamid Rezatofighi", "background": "当前的视觉语言模型（VLMs）和大规模语言模型（LLMs）已显著提升了视觉推理能力，这对于像机器人这样的体现AI代理至关重要。然而，现有的视觉推理基准存在一些局限性：缺乏明确的推理复杂度定义、无法生成不同难度的定制化问题，以及未提供结构化的、分步骤的推理注释（工作流程）。", "innovation": "文章通过制定推理复杂度、引入自适应查询引擎生成可定制的、不同复杂度的问题并提供详细的中间注释，以及扩展JRDB数据集加入人类-物体交互和几何关系注释，推出JRDB-Reasoning基准，专为复杂人群环境中的视觉推理设计。这种基准和引擎能够对视觉推理框架和视觉语言模型在不同推理层次上的表现进行精细评估和动态评估。", "conclusion": "本文通过推出JRDB-Reasoning基准和自适应查询引擎，填补了视觉推理领域的空白，可以从细粒度上评估视觉推理框架，并动态评估视觉语言模型在不同推理层级的表现。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10281", "html_url": "https://arxiv.org/abs/2508.10281", "title": "VIFSS：针对花式滑冰跳跃的视角不变和特定项目姿势表示学习用于时序动作分割", "title_en": "VIFSS: View-Invariant and Figure Skating-Specific Pose Representation Learning for Temporal Action Segmentation", "authors": "Ryota Tanaka,Tomohiro Suzuki,Keisuke Fujii", "background": "理解视频中的人类动作在包括体育分析在内的各种领域中发挥着关键作用。在花样滑冰中，准确地识别花样滑冰运动员进行的跳跃类型和时间对于客观的评分评价至关重要。然而，这项任务通常需要专家级别知识，因为跳跃程序具有细致和复杂的性质。虽然最近的方法已经尝试使用时序动作分割（TAS）来自动化这个任务，但TAS在花样滑冰中存在两个主要限制：标注数据不足以及现有的方法没有考虑到跳跃动作的内在三维特性和程序结构。", "innovation": "本文提出了一种新的TAS框架，专用于花样滑冰跳跃，明确地结合了跳跃运动的三维性质和语义程序。作者提出了一种新颖的视角不变、花样滑冰特定姿势表示学习方法（VIFSS），该方法结合了对比学习作为预训练和动作分类作为微调。为了实现视角不变的对比预训练，作者构建了FS-Jump3D，这是第一个专用于花样滑冰跳跃的公开3D姿势数据集。此外，作者引入了一种精细标注方案以标记“入程”和“着陆”阶段，帮助TAS模型学习跳跃程序的结构。通过广泛的实验验证了框架的有效性。", "conclusion": "实验结果表明，本方法在元素级TAS上达到了92%以上的F1@50的精度，这需要识别跳跃类型和旋转级别。此外，作者指出，当微调数据有限时，视角不变的对比预训练特别有效，这突显了在实际场景中的实用性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10339", "html_url": "https://arxiv.org/abs/2508.10339", "title": "概念还是技能？重新审视多模态模型指令选择", "title_en": "Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models", "authors": "Andrew Bai,Justin Cui,Ruochen Wang,Cho-Jui Hsieh", "background": "现有的视觉语言基准主要受益于与指令具有相似概念或技能的训练，本文研究了这一现象，并提出了一种简单的针对数据选择方法以优化给定基准的性能。通过对基准中的概念/技能进行提取，并确定该基准主要受益于相似的概念还是技能，最终选择了与概念/技能匹配度最高的指令。实验验证了该方法的有效性，展现了在多个基准上的效果提升。", "innovation": "文中提出了一种简单的目标化训练数据选择方法，根据基准中概念或技能的偏重，选择最匹配的指令，以优化模型性能。实验结果显示该方法在多个基准上平均提升了0.9%，在技能关注子集上提升了1.5%。这项工作强调了在指令选择中认识到固有的权衡的重要性，即在获取概念知识和视觉技能之间进行平衡.", "conclusion": "本文通过简单的数据选择方法，有效地提升了多模态模型的性能，并且强调了在指令选择中考虑概念与技能之间的权衡对于模型优化的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10356", "html_url": "https://arxiv.org/abs/2508.10356", "title": "多种语言历史文本的OCR改进", "title_en": "Improving OCR for Historical Texts of Multiple Languages", "authors": "Hylke Westerdijk,Ben Blankenborg,Khondoker Ittehadul Islam", "background": "本文介绍了使用高级深度学习技术在光学字符识别（OCR）和文档布局分析方面的方法和发现。研究涉及三个任务，涵盖历史希伯来文碎片，16至18世纪会议决议，以及现代英语手写文本的识别。", "innovation": "本文的创新之处在于使用了多种先进的深度学习模型和方法，如通过数据增强提高数据集质量，使用Kraken和TrOCR模型增强字符识别，利用CRNN结合DeepLabV3+和Bi-LSTM进行语义分割，以及采用基于置信的伪标签方法和ResNet34编码器结合CTC损失函数来捕捉序列依赖性。", "conclusion": "本文提供了有价值的研究见解，并提出了未来研究的方向。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10351", "html_url": "https://arxiv.org/abs/2508.10351", "title": "Glo-DMU: 在肾小球电子显微镜图像中的一种深层形态学框架用于超结构表征", "title_en": "Glo-DMU: A Deep Morphometry Framework of Ultrastructural Characterization in Glomerular Electron Microscopic Images", "authors": "Zhentai Zhang,Danyi Weng,Guibin Zhang,Xiang Chen,Kaixing Long,Jian Geng,Yanmeng Lu,Lei Zhang,Zhitao Zhou,Lei Cao", "background": "超结构的复杂多样特征可以指示肾脏疾病类型的多样性、进展程度和预后。近年来，结合深度学习方法的计算病理学已经在自动分析肾小球超结构形态方面展现出巨大潜力。然而，当前研究主要集中在识别单一的超结构，这使得满足实际诊断需求变得具有挑战性。", "innovation": "本文提出了一种名为Glo-DMU的肾小球超结构形态学框架，基于三种深度模型：超结构分割模型、肾小球滤过屏障区域分类模型和电子致密沉积物检测模型。该框架能够同时量化的三种最常用的超结构特征包括：肾小球基底膜的厚度、足突丧失的程度和电子致密沉积物的位置。该框架具有全自动化、高精度和高通量的特点，可以同时定量多个超结构特征，为肾脏病理学家提供了一个高效的辅助工具。", "conclusion": "我们对115名患者的9种肾病理类型进行了实际诊断场景评估，自动定量结果与病理报告中的形态描述表现出良好的一致性。Glo-DMU提供了一种全面自动化的工具，能够提高肾小球超结构特征的诊断效率和准确性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10294", "html_url": "https://arxiv.org/abs/2508.10294", "title": "亚像素多模态光学遥感图像匹配方法", "title_en": "A Sub-Pixel Multimodal Optical Remote Sensing Images Matching Method", "authors": "Tao Huang,Hongbo Pan,Nanxi Zhou,Shun Zhou", "background": "高精度的多模态光学图像匹配是几何处理的基础，但由于不同光谱响应引起的非线性辐射和几何变形差异，图像匹配的准确性通常会受到影响。为了应对这些问题，提出了一种相位一致性加权最小绝对偏差（PCWLAD）亚像素模板匹配方法，以提高多模态光学图像的匹配精度。该方法主要分为粗匹配和细匹配两个步骤。在粗匹配步骤中，使用结构相似性指数（SSIM）计算相位一致性，不使用噪声滤波器以保留原始结构细节，并采用模板匹配。在细匹配步骤中，基于粗匹配应用两个多模态相位一致性模板之间辐射和几何变换模型，并采用了互结构过滤以减轻噪声对结构一致性的影响，使用最小绝对偏差准则来估计亚像素偏移。通过创建三类图像数据集来评估PCWLAD方法：可见光到红外Landsat图像、可见光到近红外近距离图像、可见光到红外无人机图像。PCWLAD在正确匹配率（CMR）和均方根误差（RMSE）方面优于现有的八种最先进的方法，在所有三个数据集中实现了约0.4像素的平均匹配精度。相关软件和数据集可以在这里公开访问:this https URL.", "innovation": "提出了一种相位一致性加权最小绝对偏差（PCWLAD）亚像素模板匹配方法。该方法首先使用结构相似性指数（SSIM）进行粗匹配，不使用噪声滤波器以保留原始结构细节，然后基于粗匹配结果应用多模态相位一致性模板之间的辐射和几何变换模型，并采用互结构过滤和最小绝对偏差准则进行细匹配。该方法能够提高多模态光学图像的匹配精度，并更好地处理噪声对结构一致性的影响。", "conclusion": "通过创建三种不同类型的数据集，PCWLAD方法在正确匹配率（CMR）和均方根误差（RMSE）方面优于现有的八个最先进的方法，平均匹配精度达到了约0.4像素。相关软件和数据集已经公开提供。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10382", "html_url": "https://arxiv.org/abs/2508.10382", "title": "在扩散模型中整合内在场景属性以实现空间一致性图像生成", "title_en": "Towards Spatially Consistent Image Generation: On Incorporating Intrinsic Scene Properties into Diffusion Models", "authors": "Hyundo Lee,Suhyung Choi,Byoung-Tak Zhang,Inwoo Hwang", "background": "大型数据集训练的图像生成模型可以生成高质量的图像，但由于缺乏关于基础结构和空间布局的详细信息，往往会产生空间上不一致且失真的图像。先前的研究主要依赖图像-文本对或使用内在属性作为条件输入，这些方法无法充分捕捉场景的空间特征。", "innovation": "本文通过利用丰富的内在场景属性（如深度、分割图）来生成图像和相应的内在属性，使模型能够隐式捕捉到场景的结构，从而生成更空间一致且逼真的图像。通过预训练的估计器从大型图像数据集中提取丰富的内在场景属性，不需额外场景信息或明确定义的3D表示。再将多种内在场景属性通过自编码器整合到一个潜在变量中。基于预训练的大规模隐式扩散模型（LDMs），本文方法通过精细共享互信息同时对图像和内在属性进行去噪，同时保持图像质量。", "conclusion": "实验结果表明，本文方法可以修正空间不一致性，生成更自然的场景布局，同时保持基础模型（如Stable Diffusion）的保真度和文本对齐性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10367", "html_url": "https://arxiv.org/abs/2508.10367", "title": "多模态视觉-语言模型的对比敏感度函数", "title_en": "Contrast Sensitivity Function of Multimodal Vision-Language Models", "authors": "Pablo Hernández-Cámara,Alexandra Gomez-Villa,Jose Manuel Jaén-Lorites,Jorge Vila-Tomás,Jesus Malo,Valero Laparra", "background": "评估多模态视觉-语言模型（VLMs）与人类感知的一致性对理解它们如何感知低级视觉特征至关重要。人类视觉的一个关键特征是对比敏感度函数（CSF），它描述了在低对比度下的空间频率敏感性。目前，还没有一种直接的方法来估计基于聊天的VLMs的CSF。以前的方法可能与真正的感觉心理学实验不一致，因此需要一种新的方法来评估VLMs的视觉敏感性，尤其是在多种架构下模型对闪烁噪声图像不同对比度的响应。这项研究旨在填补这一空白，以更好地理解VLMs的视觉感知与人类感知之间的差异。", "innovation": "引入了一种新的行为心理学启发方法，通过直接提示VLMs判断不同对比度下的模式可见性，来估计基于聊天的VLMs的CSF。使用带通滤波噪声图像和不同的提示集，评估了多种架构下的模型响应。这种方法更接近于真正的心理学实验，相较于以前的方法。研究发现，虽然一些模型接近人类的CSF形状或大小，但没有模型完全复制两者。此外，提示的措辞对响应有重大影响，这引起了对提示稳定性的担忧。这项研究提供了一种新的框架来探究多模态模型的视觉敏感性，揭示了它们的视觉表示与人类感知之间的关键差距。", "conclusion": "研究表明，虽然有些模型在CSF形状或大小上接近人类的表现，但没有一个模型完全复制两者。提示措辞对模型的响应有显著影响，提示稳定性是一个值得关注的问题。这项研究为探究VLMs的视觉敏感性提供了一个新的框架，揭示了它们的视觉表示和人类感知之间的关键差距。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10383", "html_url": "https://arxiv.org/abs/2508.10383", "title": "通过仅标签弹性变形对抗隐式标签噪声实现稳健的语义分割性能", "title_en": "Unlocking Robust Semantic Segmentation Performance via Label-only Elastic Deformations against Implicit Label Noise", "authors": "Yechan Kim,Dongho Yoon,Younkwan Lee,Unse Fatima,Hong Kook Kim,Songjae Lee,Sanga Park,Jeong Ho Park,Seonjong Kang,Moongu Jeon", "background": "尽管之前的图像分割研究主要集中在处理严重的（或明确的）标签噪声，但现实世界的数据集也表现出细微的（或隐式的）标签缺陷。这些缺陷源于对象边界模糊以及注释员的一致性问题。即便这些细微和潜在的噪声不显式存在，依然会影响模型性能。常见的数据增强方法虽然对图像和标签应用相同的变换，但会放大这些细微缺陷，从而限制模型的泛化能力。", "innovation": "本文引入了NSegment+，这是一种新颖的数据增强框架，将图像和标签的变换解耦，以解决语义分割中的隐式噪声问题。通过仅对分割标签应用受控的弹性变形，同时保留原始图像，该方法鼓励模型学习在轻微标签不一致性情况下依然具有鲁棒性的对象结构表示。", "conclusion": "广泛实验表明，NSegment+能够在Vaihingen、LoveDA、Cityscapes和PASCAL VOC上分别实现mIoU收益+2.29、+2.38、+1.75和+3.39，证明了应对隐式标签噪声的重要意义。与其他训练技巧比如CutMix和Label Smoothing结合使用时，这种收益会进一步提高，突显了其在提升语义分割性能方面的作用。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10397", "html_url": "https://arxiv.org/abs/2508.10397", "title": "PQ-DAF: 基于姿势驱动的质量控制数据增强方法用于数据稀缺的驾驶员分心检测", "title_en": "PQ-DAF: Pose-driven Quality-controlled Data Augmentation for Data-scarce Driver Distraction Detection", "authors": "Haibin Sun,Xinghui Song", "background": "驾驶员分心检测对于提高交通安全性、减少道路事故至关重要。然而，现有模型在现实场景中应用时通常会遭受泛化能力下降的问题。这种限制主要源于数据注释成本高导致的实际环境中的少样本学习挑战，以及训练数据集与目标部署条件之间的显著领域偏移。这些问题是由于数据集中的数据量有限，而数据集的构建和标注成本高昂所引起的。", "innovation": "本文提出了一种基于姿势驱动的质量控制数据增强框架（PQ-DAF），采用一种渐进条件扩散模型（PCDMs）来准确捕捉关键的驾驶员姿态特征并合成多种多样的训练样本，然后利用基于CogVLM视觉-语言模型的样本质量评估模块，根据置信阈值筛选出低品质的合成样本，确保增强数据集的可靠性，以弥补数据稀缺的情况并提高模型的通用性。", "conclusion": "广泛的实验表明，PQ-DAF在少样本驾驶员分心检测中显著提高了性能，特别是在数据稀缺条件下，模型的泛化能力得到了大幅提高。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10316", "html_url": "https://arxiv.org/abs/2508.10316", "title": "将强化学习集成到视觉生成模型中：基础与进展", "title_en": "Integrating Reinforcement Learning with Visual Generative Models: Foundations and Advances", "authors": "Yuanzhi Liang,Yijie Fang,Rui Li,Ziqi Ni,Ruijie Su,Chi Zhang,Xuelong Li", "background": "生成模型在合成视觉内容（如图像、视频和3D/4D结构）方面取得了显著进展，但通常依赖似然或重构损失等代理目标进行训练，这往往与感知质量、语义准确性和物理现实性不一致。强化学习（RL）提供了一种原则性的框架，用于优化非可微分的、基于偏好且具有时间结构的目标。最近的研究显示，RL在提高可控性、一致性和人类匹配方面对生成任务具有有效性。", "innovation": "该论文提供了一种系统的RL方法综述，这些方法用于视觉内容生成。论文回顾了RL从经典控制到作为通用优化工具的发展，并检查了其在图像、视频和3D/4D生成中的集成。RL不仅作为微调机制，还作为生成与复杂、高层次目标对齐的结构组件。", "conclusion": "该研究最后提出了RL和生成建模交界处的开放挑战和未来研究方向。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10309", "html_url": "https://arxiv.org/abs/2508.10309", "title": "从像素到掩码：一种跨分布分割调研", "title_en": "From Pixel to Mask: A Survey of Out-of-Distribution Segmentation", "authors": "Wenjie Zhao,Jia Li,Yunhui Guo", "background": "随着AI安全性的日益关注，跨分布（OoD）检测和分割引起了越来越多的研究兴趣。传统的OoD检测方法能够识别是否存在OoD对象，但缺乏空间定位，这限制了其在下游任务中的应用。通过像素级粒度对异常对象进行定位是跨分布分割的核心能力，这对于自动驾驶等安全关键应用尤为重要，因为感知模块不仅要检测OoD对象，还需要精确分割它们，以实现精确的控制并提高系统整体的鲁棒性。", "innovation": "本文将当前的跨分布分割方法分为四类：（i）测试时跨分布分割，（ii）监督训练中的异常曝光，（iii）基于重构的方法，（iv）利用强大模型的方法。文章系统性地回顾了在自动驾驶场景下的跨分布分割的最新进展，揭示了新兴挑战，并探讨了有前途的未来研究方向。", "conclusion": "本文不仅总结了近年来跨分布分割领域的最新研究，还指出了当前存在的挑战，并提出了未来研究的方向。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10407", "html_url": "https://arxiv.org/abs/2508.10407", "title": "使用Delta向量转换文本嵌入来抑制文本到图像扩散模型中紧密关联内容", "title_en": "Translation of Text Embedding via Delta Vector to Suppress Strongly Entangled Content in Text-to-Image Diffusion Models", "authors": "Eunseo Koh,Seunghoo Hong,Tae-Young Kim,Simon S. Woo,Jae-Pil Heo", "background": "文本到图像（T2I）扩散模型在从文本提示生成多样化高质量图像方面取得了显著进展，但仍面临抑制特定词汇紧密关联内容的挑战。例如，在生成“查理·卓别林”的图像时，即使明确指示不包含，图像中仍会出现“大胡子”这一概念，因为“大胡子”与“查理·卓别林”的概念紧密相关。", "innovation": "作者提出了一个新颖的方法，直接在扩散模型的文本嵌入空间中抑制此类紧密关联的内容。该方法引入了一个delta向量，修改文本嵌入以减弱生成图像中不需要内容的影响，并进一步展示了该delta向量可以通过零样本方法轻松获得。此外，提出了Selective Suppression with Delta Vector (SSDV) 方法将delta向量整合到交叉注意力机制中，以更有效地抑制再生区域中的不需要内容。通过优化delta向量，实现了更为精确的个人化T2I模型中的抑制效果，这是先前基线无法实现的。", "conclusion": "广泛的实验结果表明，我们的方法在定量和定性的指标方面都显著优于现有方法。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10411", "html_url": "https://arxiv.org/abs/2508.10411", "title": "SC-Lane: 坡度感知且具有一致性的路面高度估计框架用于3D车道检测", "title_en": "SC-Lane: Slope-aware and Consistent Road Height Estimation Framework for 3D Lane Detection", "authors": "Chaesong Park,Eunbin Seo,Jihyeon Hwang,Jongwoo Lim", "background": "当前的研究方法主要依赖固定的坡度锚点进行3D车道检测的高度估计，这种方法在面对多样化的道路几何结构时表现不够稳健。以往的工作使用了LiDAR衍生的高度图数据集进行评估，但常用的度量标准（如均方根误差、平均绝对误差以及基于阈值的准确率）在道路高度评估中的应用尚显不足。", "innovation": "本文提出的SC-Lane框架创新地结合了坡度感知和时间一致性机制。SC-Lane通过引入坡度感知自适应特征模块，能够动态地从图像线索中预测合适的权重，实现多坡度表示的集成。此外，通过添加高度一致性模块，保证了连续帧之间高度估计的时间连贯性，这对于实际驾驶场景至关重要。这些创新显著提升了高度估计的稳定性和准确性。", "conclusion": "通过对开放车道基准的广泛实验，SC-Lane不仅在高度估计方面表现优异，而且在3D车道检测中也取得了最佳性能，其F分数为64.3%，超过了现有的方法。文中还提供了详细的实验结果和演示视频，供研究者参考。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10424", "html_url": "https://arxiv.org/abs/2508.10424", "title": "NanoControl: 轻量级精确高效控制框架在扩散变换器中的应用", "title_en": "NanoControl: A Lightweight Framework for Precise and Efficient Control in Diffusion Transformer", "authors": "Shanyuan Liu,Jian Zhu,Junda Lu,Yue Gong,Liuzhuozheng Li,Bo Cheng,Yuhang Ma,Liebucha Wu,Xiaoyu Wu,Dawei Leng,Yuhui Yin", "background": "扩散变换器（DiTs）已经在文本到图像合成方面展现了卓越的能力。然而，在使用DiTs进行可控制文本到图像生成时，大多数现有方法依然依赖于专为基于UNet的扩散模型设计的ControlNet框架。这种方法带来了显著的参数冗余和增加的计算成本。", "innovation": "本文提出了一种名为Nano Control Diffusion Transformer（NanoControl）的新模型，其背骨网络采用Flux结构。相较于现有方法，NanoControl在保持顶级可控文本到图像生成性能的同时，参数增加仅为0.024%，GFLOPs增加仅0.029%，实现了高度的高效可控生成。具体而言，NanoControl通过设计一种类似低秩适应（LoRA）的控制模块，直接学习来自原始条件输入的控制信号，而非重复DiT的骨干网络。此外，引入了一种KV-Context Augmentation机制，以简单而高效的方式将条件特定的关键值信息整合到背骨中，促进条件特征的深度融合。", "conclusion": "基准实验结果表明，NanoControl相较于传统控制方法大幅减少了计算开销，同时保持了优异的生成质量和较好的可控性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10450", "html_url": "https://arxiv.org/abs/2508.10450", "title": "从图像到感知：通过重建图像产生感知属性", "title_en": "From Images to Perception: Emergence of Perceptual Properties by Reconstructing Images", "authors": "Pablo Hernández-Cámara,Jesus Malo,Valero Laparra", "background": "一些科学家推测，人类的视觉感知可能是从图像统计中产生的，进而形成了早期视觉中的有效神经表示。该研究构建了一个受生物启发的PerceptNet架构，该架构涵盖了视网膜-V1皮层的一些已知事实，并针对图像重建的不同任务进行端到端优化：自编码、去噪、去模糊化和稀疏正则化。", "innovation": "PerceptNet架构是首个同时满足多个感知任务的生物启发模型，且在不使用感知信息进行初始化或训练的情况下，其编码阶段（类似于V1层）与图像扭曲的人类感知判断高度相关。这种相关性在适中的噪声、模糊和稀疏情况下表现最佳，表明视觉系统可能调整以去除特定水平的扭曲和稀疏性。此外，研究发现生物启发的模型可以在无需人类监督的情况下学习感知度量标准。", "conclusion": "该研究表明，视觉系统可能被调整以去除特定水平的扭曲和稀疏性，表明生物启发的模型能够在没有人类监督的情况下学习感知度量标准。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10453", "html_url": "https://arxiv.org/abs/2508.10453", "title": "Trajectory-aware Shifted State Space Models for Online Video Super-Resolution", "title_en": "Trajectory-aware Shifted State Space Models for Online Video Super-Resolution", "authors": "Qiang Zhu,Xiandong Meng,Yuxian Jiang,Fan Zhang,David Bull,Shuyuan Zhu,Bing Zeng", "background": "在线视频超分辨率（VSR）是一种重要的技术，用于许多现实世界的视频处理应用。传统方法通常仅使用一个相邻的先前帧进行时间对齐，这限制了视频中的长时间暂态建模。最近，状态空间模型（SSMs）由于其线性的计算复杂性和全局感受野，显著提高了计算效率和性能。", "innovation": "本文提出了一种基于轨迹感知移动状态空间模型（TS-Mamba）的新型在线VSR方法，结合长期轨迹建模和低复杂度Mamba模块，实现高效的时空信息聚合。首先，构造视频中的轨迹来选择最相似的前一帧的令牌。接着，使用包含提议的移动SSM模块的轨迹感知移动Mamba聚合（TSMA）模块来聚合选择的令牌。此外，还提出了一种轨迹感知损失函数来监督轨迹生成，确保模型训练时的令牌选择准确性。", "conclusion": "在对三个广泛使用的VSR测试数据集上的大量实验表明，与六种在线VSR基准模型相比，TS-Mamba在大多数情况下实现了最先进的性能，且复杂度减少了22.7%（以MACs计）。TS-Mamba的源代码会在该网址提供：this https URL."}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10432", "html_url": "https://arxiv.org/abs/2508.10432", "title": "CRISP: 对比残差注入和语义提示在持续视频实例分割中的应用", "title_en": "CRISP: Contrastive Residual Injection and Semantic Prompting for Continual Video Instance Segmentation", "authors": "Baichen Liu,Qi Lyu,Xudong Wang,Jiahua Dong,Lianqing Liu,Zhi Han", "background": "持续视频实例分割需要保持对新对象类别的适应性和保留以前学习类别的稳定性。现有的方法难以在保持时间一致性的前提下有效地解决持续视频实例分割中的实例级别、类别级别和任务级别的混淆问题。", "innovation": "本文提出了一种名为对比残差注入和语义提示（CRISP）的方法，以解决持续视频实例分割中的具体问题。具体来说，CRISP通过实例学习中的实例追踪和实例相关性损失建模来强调与先前查询空间的相关性并强化当前任务查询的特异性；通过自适应残差语义提示（ARSP）学习框架构建可学习的语义残差提示池，并使用可调节的查询-提示匹配机制建立当前任务查询和语义残差提示之间的映射关系；同时引入基于对比学习的语义一致性损失以在增量训练过程中维持对象查询和残差提示之间的语义一致性；对于任务学习，引入了一种简洁而强大的初始化策略以确保查询空间内任务间的相关性，从而改善实例分割和分类性能，避免灾难性遗忘。", "conclusion": "在YouTube-VIS-2019和YouTube-VIS-2021数据集上的广泛实验表明，CRISP能够显著优于现有的持续分割方法，在长期持续视频实例分割任务中表现更优，分割和分类性能均有明显提升。源代码可访问该链接：this <link> URL。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10427", "html_url": "https://arxiv.org/abs/2508.10427", "title": "STRIDE-QA：城市驾驶场景中时空推理的视觉疑问回答数据集", "title_en": "STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes", "authors": "Keishi Ishihara,Kento Sasaki,Tsubasa Takahashi,Daiki Shiono,Yu Yamaguchi", "background": "视觉语言模型（VLMs）已被应用于自动驾驶，以支持在复杂现实场景中的决策。然而，这些模型基于静态的网络图像-文本对进行训练，不足以满足精确的空间-时间推理要求，这对于理解与预测动态交通场景极其重要。因此，现有模型在精确理解和预测交通场景方面存在显著局限性。", "innovation": "STRIDE-QA是一个基于物理地上客观的视觉疑问回答（VQA）数据集，专门为第一人称视角下的时空推理设计。数据集来源于东京100小时的多传感器驱动数据，涵盖了多样且有挑战性的条件，是目前针对城市驾驶时空推理最大的VQA数据集，包含1600万问题-答案对和285,000帧。该数据集的独特之处在于密集自动生成的注释，包括3D边界框、分割掩码和多对象轨迹，支持对象中心和自我中心推理，并通过三个新的任务增强了空间定位和时间预测能力。", "conclusion": "现有的视觉语言模型在这项任务中表现出显著困难，而针对STRIDE-QA数据集进行微调的模型则取得了巨大性能提升，空间定位准确率达到55%，未来运动预测一致性达到28%，远超通用视觉语言模型的性能。因此，STRIDE-QA为开发更可靠的视觉语言模型奠定了全面基础，适合于安全关键的自动驾驶系统。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10445", "html_url": "https://arxiv.org/abs/2508.10445", "title": "DOD-SA: 单模态注释下红外-可见光解耦对象检测", "title_en": "DOD-SA: Infrared-Visible Decoupled Object Detection with Single-Modality Annotations", "authors": "Hang Jin,Chenqiang Gao,Junjie Guo,Fangcen Liu,Kanghui Tian,Qinyao Chang", "background": "红外-可见光综合检测在现实应用中展现出了巨大潜力，通过利用红外和可见光图像的互补信息实现了全天候感知。然而，现有的方法通常需要双模态标注以在预测时输出两种模态的检测结果，这导致了高标注成本。为了解决这个问题，本文提出了一种基于单模态标注的红外-可见光解耦对象检测框架，称为DOD-SA。该框架基于单模态和双模态协作教师-学生网络架构，旨在降低标注成本并提高模型性能。", "innovation": "本文创新点在于提出了一种新的DOD-SA框架，能够在单模态标注下进行红外-可见光对象检测。该框架使用了一个双重机制：首先，利用标记模态训练学生模型，同时生成非标记模态的伪标签；其次，通过一个渐进且自调校训练策略（PaST）分阶段训练模型。此外，还设计了一个伪标签分配器（PLA）来解决模态不一致性问题。这种方法在DroneVehicle数据集上实验结果表明，其性能优于现有的最先进的方法。", "conclusion": "实验结果表明，DOD-SA方法在DroneVehicle数据集上相较于现有的最先进的方法取得了更好的性能，证明了该方法的有效性和实用性。这项工作为红外和可见光跨模态数据驱动检测任务提供了新的解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10449", "html_url": "https://arxiv.org/abs/2508.10449", "title": "SkeySpot: 在建筑行业中自动检测数字电气布局计划中的服务键", "title_en": "SkeySpot: Automating Service Key Detection for Digital Electrical Layout Plans in the Construction Industry", "authors": "Dhruv Dosi,Rohit Meena,Param Rajpura,Yogesh Kumar Meena", "background": "传统储存为扫描文件的原始楼层平面图在建筑、城市规划和设施管理等领域中仍至关重要。然而，由于缺乏可机读的平面图，大规模解读变得费时且容易出错。自动符号识别提供了解决方案，通过直接从平面图中识别服务关键符号，支持成本估算、基础设施维护和合规性检查等工作流程。此研究引入了一个包含45个带有2450个实例的标签化数字电气布局计划（DELP）数据集，涵盖了34个不同的服务键类别。", "innovation": "本研究提出了一个使用预训练对象检测模型对DELP数据集进行系统性评估的框架。在基准测试的模型中，YOLOv8达到了最高的性能，均值平均准确率（mAP）为82.5%。在此基础上，研发了SkeySpot，一款轻量级、开源的工具包，用于实时检测、分类和量化电气符号。SkeySpot生成的结构化、标准化输出可以扩展以支持建筑信息工作的互操作性，从而增强下游应用和监管平台的兼容性。这种方法降低了对专有CAD系统的依赖，减少了手动注释的工作量，使小型和中型企业（SMEs）更易实现电气布局的数字化，同时支持在整个建筑环境中实现标准、互操作性和可持续性的更广泛目标。", "conclusion": "通过SkeySpot工具包的开发，简化了小型和中型企业（SMEs）在建筑行业中的电气布局数字化过程，支持中小型企业的建筑信息互操作性，并最终实现整个建筑环境中的标准、互操作性和可持续性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10457", "html_url": "https://arxiv.org/abs/2508.10457", "title": "基于元数据增强的多头视觉转换器的多标签植物物种预测", "title_en": "Multi-Label Plant Species Prediction with Metadata-Enhanced Multi-Head Vision Transformers", "authors": "Hanna Herasimchyk,Robin Labryga,Tomislav Prusina", "background": "该研究针对的是PlantCLEF 2025挑战，旨在预测植被样方图像中的多标签植物物种。该任务在单物种植物图像上训练模型，但在多物种样方图像上进行测试，导致了严重的领域转移。背景重点在于单物种训练和多物种测试之间的挑战，需要一种能够在复杂场景中做出准确预测的方法", "innovation": "我们的方法创新性地使用了预训练的DINOv2 Vision Transformer Base（ViT-B/14）作为骨干网，并结合多个分类头进行物种、属和科的预测，同时利用了分类学层次结构。此外，还引入了多尺度镶嵌技术来捕捉不同尺度的植物，动态阈值优化基于平均预测长度，以及通过袋装和Hydra模型架构的集成策略。还结合了多种推理技术，如图像裁剪去除非植物杂乱，top-n筛选以进行预测调整，以及通过逻辑阈值策略优化预测。研究团队通过140万张图片（覆盖7806种植物）进行了实验，并取得了显著的性能，提交结果在私人排行榜上排名第三", "conclusion": "结果表明，该方法在多标签植物物种预测中表现出色，方法的有效性得到验证。研究团队将代码开源，以促进该领域进一步的研究和发展"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10464", "html_url": "https://arxiv.org/abs/2508.10464", "title": "SingleStrip：仅从单个标记示例学习颅骨剥离", "title_en": "SingleStrip: learning skull-stripping from a single labeled example", "authors": "Bella Specktor-Fadida,Malte Hoffmann", "background": "深度学习分割高度依赖标记数据，但手工标注数据费时费力，尤其是在处理如脑磁共振成像（MRI）等体数据时。虽然最近的域随机化技术可以合成多样化的训练图像以减少对标记数据的依赖，但当可用的标签图很少时，这些技术提供的解剖变异有限。半监督自训练通过迭代地将模型预测纳入训练集来解决标签不足的问题，使网络能够从未标记数据中学习。这项工作旨在结合域随机化与自训练，利用最少的一个标记示例训练三维颅骨剥离网络。", "innovation": "该研究提出了一个结合域随机化与自训练的方法，能够仅利用一个标记示例来训练三维颅骨剥离网络。具体步骤包括：自动划分体素强度以生成标签，进而合成用于初始颅骨剥离模型训练的图像；训练卷积自编码器（AE）并用其重建误差评估未标记数据中脑掩模的质量；选取排名最高的伪标签以微调网络。该方法在测试时的表现接近使用更多标记示例训练的模型。研究还发现，基于自编码器的质量评估方法与分割准确度的相关性更强。", "conclusion": "实验结果显示，结合域随机化与基于自编码器的质量控制方法能够有效进行半监督分割，即使面对极其有限的标记数据。这一策略可能有助于减轻标签负担，从而促进涉及新解剖结构或新兴成像技术的研究进展。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10473", "html_url": "https://arxiv.org/abs/2508.10473", "title": "STAMP: 多模式注意力增强的多个实例学习在多中心病理图像中STAS诊断", "title_en": "STAMP: Multi-pattern Attention-aware Multiple Instance Learning for STAS Diagnosis in Multi-center Histopathology Images", "authors": "Liangrui Pan,xiaoyu Li,Guang Zhu,Guanting Li,Ruixin Wang,Jiadi Luo,Yaning Yang,Liang qingchun,Shaoliang Peng", "background": "STAS（通过空气空间传播）是肺腺癌（LUAD）的一种新发侵袭模式，与肿瘤复发和生存率降低相关。大规模STAS诊断在LUAD中是一项劳动密集型工作，并且由于其独特的病理特征和形态学特征，容易导致疏忽和误诊。因此，迫切需要利用深度学习模型进行STAS诊断。", "innovation": "提出了一种多模式注意力增强的多个实例学习框架（STAMP），用于分析和诊断多中心组织学图像中的STAS。该框架具有双分支结构，通过不同的语义空间学习STAS相关的病理特征。基于Transformer的实例编码和多模式注意力聚合模块动态选择与STAS病理密切相关的区域，抑制无关噪声并增强全局表示的可分辨性。此外，通过相似性正则化约束防止分支间的特征冗余，从而提高整体诊断准确性。实验结果表明，STAMP在STAS-SXY、STAS-TXY和STAS-TCGA数据集上分别实现了AUC值0.8058、0.8017和0.7928，超过了临床水平。", "conclusion": "STAMP框架在多中心病理图像中STAS的诊断上表现出色，能够有效地识别STAS特征，提高诊断准确率。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10498", "html_url": "https://arxiv.org/abs/2508.10498", "title": "TweezeEdit: 通过路径正则化的连贯高效图像编辑", "title_en": "TweezeEdit: Consistent and Efficient Image Editing with Path Regularization", "authors": "Jianda Mao,Kaibo Wang,Yang Xiang,Kani Chen", "background": "大规模预训练扩散模型能够通过文本指导用户编辑图像，但现有方法往往过度依赖目标提示，未能充分保留源图像的语义信息。这些方法通过源图像的逆向噪声产生目标图像，被称为逆向锚点，这导致语义信息的保留不足和编辑路径变长的局限性。", "innovation": "提出了一种名为TweezeEdit的无需调整和逆向过程的框架，通过在整个去噪路径上进行正则化，确保源语义保留并缩短编辑路径。利用梯度驱动的正则化，有效地沿直接路径注入目标提示语义，确保语义保留和目标对齐。", "conclusion": "实验结果表明，TweezeEdit在语义保留和目标对齐方面优于现有方法，仅需12步（每编辑步骤约1.6秒），显示出其在实时应用中的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10507", "html_url": "https://arxiv.org/abs/2508.10507", "title": "多样本反走样和约束优化在3D高斯点绘制中的应用", "title_en": "Multi-Sample Anti-Aliasing and Constrained Optimization for 3D Gaussian Splatting", "authors": "Zheng Zhou,Jia-Chen Zhang,Yu-Jie Xiong,Chun-Ming Xia", "background": "3D高斯点绘制的最新进展显著提升了实时新颖视图合成能力，但由于场景优化期间几何约束不足，往往导致细节模糊重建，特别是在高频纹理和尖锐边界区域。现有方法在这方面表现不佳。", "innovation": "提出了将多样本反走样（MSAA）与双几何约束相结合的综合优化框架，通过自适应混合四重子样本有效减少高频分量的走样artifact。引入了两种约束：自适应权重策略通过动态梯度分析优先处理欠重建区域，以及梯度差异约束以几何正则化方式加强物体边界处的几何约束。这种针对性优化使得模型能够优先分配计算资源到需要细化的关键区域，同时保持全局一致性。", "conclusion": "在多个基准上的广泛实验评估显示，本方法在细节保留方面达到最先进的性能，特别是在保护高频纹理和尖锐边界方面。同时，维持了实时渲染效率。定量指标和感知研究表明，与基线方法相比，在结构相似性（SSIM）和感知质量（LPIPS）方面实现了统计学上的显著改进。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10528", "html_url": "https://arxiv.org/abs/2508.10528", "title": "Med-GLIP：大规模语义标注数据集推动医学语言-图像预训练", "title_en": "Med-GLIP: Advancing Medical Language-Image Pre-training with Large-scale Grounded Dataset", "authors": "Ziye Deng,Ruihan He,Jiaxiang Liu,Yuan Wang,Zijie Meng,Songtao Jiang,Yong Xie,Zuozhu Liu", "background": "医学图像接地旨在将自然语言短语与医学图像中的特定区域对齐，作为智能诊断、视觉问答（VQA）和自动化报告生成（MRG）的基础任务。然而，现有的研究受到模态覆盖有限、标注粗糙以及缺乏统一可泛化的接地框架的限制。", "innovation": "构建了一个包含超过530万区域级注释的大规模医学接地数据集Med-GLIP-5M，涵盖了七种成像模态，支持从器官到细粒度病变的层级区域标签。基于此数据集，提出了一种模态感知的接地框架Med-GLIP，该框架通过多样化的训练数据隐式地获取多层级语义理解，能够识别多粒度结构。实验表明，Med-GLIP在多个接地基准上持续优于现有最佳基线，并通过将其空间输出集成到下游任务中，进一步提高医学VQA和报告生成的任务性能。", "conclusion": "Med-GLIP-5M 数据集将很快发布，以支持后续研究和应用。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10523", "html_url": "https://arxiv.org/abs/2508.10523", "title": "计算机视觉中的推理：分类、模型、任务和方法", "title_en": "Reasoning in Computer Vision: Taxonomy, Models, Tasks, and Methodologies", "authors": "Ayushman Sarkar,Mohd Yamani Idna Idris,Zhenyu Yu", "background": "视觉推理对于广泛的计算机视觉任务至关重要，这些任务超越了表面级别的对象检测和分类。尽管在关系推理、符号推理、时间推理、因果推理和常识推理方面取得了显著进展，现有的综述文章通常在孤立方向上进行讨论，缺乏对各种推理类型、方法和评估标准的统一分析和比较。这篇综述旨在通过将视觉推理分类为五大类型（关系推理、符号推理、时间推理、因果推理和常识推理）并系统检查其通过图模型、记忆网络、注意力机制和神经符号系统等架构的实现来填补这一空白。", "innovation": "该综述通过归类视觉推理为五大类型并对它们的实施进行系统性检查，填补了现有研究的空白，并通过评估协议对功能正确性、结构一致性以及因果有效性的评估方法进行了全面回顾。除此之外，还批判性地分析了这些评估方法在泛化性、可重复性和解释性方面存在的限制，提出了视觉推理的关键挑战，并为下一代视觉系统提出了前瞻性的研究议程。", "conclusion": "视觉推理是构建透明、可信和跨域适应型AI系统的关键，这对于实现自动驾驶和医疗诊断等关键领域的AI至关重要。这一研究提出了前瞻性的研究议程，强调将感知与推理相结合是构建这些系统的最关键要素之一。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10522", "html_url": "https://arxiv.org/abs/2508.10522", "title": "以EgoMusic为基础的人体舞蹈动作估计，采用Skeleton Mamba", "title_en": "EgoMusic-driven Human Dance Motion Estimation with Skeleton Mamba", "authors": "Quang Nguyen,Nhat Le,Baoru Huang,Minh Nhat Vu,Chengcheng Tang,Van Nguyen,Ngan Le,Thieu Vo,Anh Nguyen", "background": "人体舞蹈动作的估计是一个具有多种工业应用的挑战性任务。近年来，许多研究集中在使用第一人称视频或音乐预测人体舞蹈动作上。然而，同时从第一人称视频和音乐联合估计人体运动的任务仍较少探索。鉴于第一人称视角容易导致人体大部分被遮挡，准确估计完整姿态较为困难，而整合音乐则需要生成的头部和身体动作能够很好地与视觉和音乐输入对齐。", "innovation": "本文提出了一种新的方法，使用第一人称视角视频和音乐来预测人体舞蹈动作。通过开发EgoMusic Motion Network，它包括核心的Skeleton Mamba，能够明确捕捉人体骨架结构。此外，还引入了一个名为EgoAIST++的新大规模数据集，该数据集结合了第一人称视角和音乐，包含了超过36小时的舞蹈动作。这种方法不仅理论上有支持，而且实验证明优于现有的方法，并且具有良好的通用性。", "conclusion": "本文通过EgoMusic Motion Network展示了在多模态输入（第一人称视角和音乐）下估计人体舞蹈动作的新方法，并验证了其有效性。实验结果表明，该方法在多项指标上优于当前最先进的方法，且能较好地应用于真实数据中。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10542", "html_url": "https://arxiv.org/abs/2508.10542", "title": "GCRPNet: 基于图增强上下文和区域感知网络的光学遥感图像显著目标检测", "title_en": "GCRPNet: Graph-Enhanced Contextual and Regional Perception Network For Salient Object Detection in Optical Remote Sensing Images", "authors": "Mengyu Ren,Yutong Li,Hua Li,Runmin Cong,Sam Kwong", "background": "光学遥感图像（ORSIs）中的显著对象检测（SOD）面临许多挑战，包括目标尺度的显著变化和目标与背景之间的低对比度。现有的基于视觉变换器（ViTs）和卷积神经网络（CNNs）架构的方法旨在利用全局和局部特征，但由于难以有效地整合这些异构特征，限制了整体性能。", "innovation": "提出了一种基于Mamba架构的图增强上下文和区域感知网络（GCRPNet），用于同时捕捉长程依赖关系并增强区域特征表示。具体方法包括：使用视觉状态空间（VSS）编码器提取多尺度特征；设计差异相似性引导的分层图注意力模块（DS-HGAM），以增强不同尺度特征之间的跨层交互能力并提高模型的结构感知能力；设计LEVSS块作为GCRPNet的解码器，结合自适应扫描策略和多粒度协作注意力增强模块（MCAEM），从而捕捉丰富的局部区域信息并增强Mamba的局部建模能力。", "conclusion": "广泛的实验结果表明，所提出模型达到了最先进的性能，验证了其有效性和优越性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10509", "html_url": "https://arxiv.org/abs/2508.10509", "title": "一种螺栓缺陷增强与检测的分割驱动编辑方法", "title_en": "A Segmentation-driven Editing Method for Bolt Defect Augmentation and Detection", "authors": "Yangjie Xiao,Ke Zhang,Jiacun Wang,Xin Sheng,Yurong Guo,Meijuan Chen,Zehua Ren,Zhaoye Zheng,Zhenbing Zhao", "background": "螺栓缺陷检测对于保障输电线路的安全至关重要。然而，缺陷图像的稀缺性和数据集分布的不平衡极大地限制了检测效果。本研究旨在解决这一问题，提出了一种螺栓缺陷编辑方法（SBDE）以扩充数据集，从而提高检测性能。该方法包含了多个关键步骤，包括螺栓属性分割模型（Bolt-SAM）、掩码优化模块（MOD）和编辑恢复增强策略（ERA），这些步骤共同构建了螺栓缺陷特性编辑模型（MOD-LaMa），能够通过属性编辑将正常螺栓转化为缺陷螺栓。", "innovation": "首先，提出了一种螺栓属性分割模型（Bolt-SAM），通过CLAEHE-FFT适配器（CFA）和多部分感知掩码解码器（MAMD），增强了复杂螺栓属性的分割能力，从而生成高质量的掩码，用于后续的编辑任务。其次，设计并集成了一个掩码优化模块（MOD）和图像修复模型（LaMa），构建了螺栓缺陷属性编辑模型（MOD-LaMa），可以通过属性编辑将普通螺栓转换为缺陷螺栓。最后，提出了一种编辑恢复增强策略（ERA），用于将编辑后的缺陷螺栓恢复并重新放入原始检测场景中，从而扩展缺陷检测的数据集。", "conclusion": "通过构建多个螺栓数据集并进行广泛的实验，结果表明SBDE生成的螺栓缺陷图像在性能上明显优于现有的图像编辑模型，并有效提升了螺栓缺陷检测的表现。这些结果充分证明了所提出方法的有效性和应用潜力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10549", "html_url": "https://arxiv.org/abs/2508.10549", "title": "PSScreen: 部分监督的多眼底疾病筛查", "title_en": "PSScreen: Partially Supervised Multiple Retinal Disease Screening", "authors": "Boyi Zheng,Qing Liu", "background": "现有的多眼底疾病筛查模型依赖于完全标注的数据集，但由于不同医疗站点之间的显著领域转移以及部分类别标签缺失的问题，训练具有广泛适应性的模型依然是一个挑战。为了应对这些问题，本文分析了多部分标注数据集在训练多眼底疾病筛查模型中的应用，尽管这在一定程度上减轻了对完全标注数据集的依赖，但仍存在显著的领域偏移问题和部分类别标签缺失的问题，这些都为模型的训练带来了挑战。", "innovation": "本文提出了一个名为PSScreen的新型部分监督多眼底疾病筛查模型。该模型由两个分支组成，一个负责学习确定性特征，另一个通过不确定性注入学习概率特征。通过引入文本指导将两种特征解耦并进行疾病特异性的对齐，增强了领域泛化能力。此外，通过在两个分支之间引入伪标签一致性，解决了标签缺失问题，并采用了自我蒸馏方法，将已知类别的任务相关语义从确定性分支转移到概率性分支，进一步提升了检测性能。实验结果表明，PSScreen在六种眼底疾病和正常状态的检测性能上均有所改善，并在有域和无域数据集上达到了最先进的结果。", "conclusion": "实验结果显示，PSScreen在六种眼底疾病和正常状态的检测性能上都有显著提高，并且在有域和无域数据集上达到了最先进的结果。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10556", "html_url": "https://arxiv.org/abs/2508.10556", "title": "Retrieval-Augmented Prompt for OOD Detection", "title_en": "Retrieval-Augmented Prompt for OOD Detection", "authors": "Ruisong Han,Zongbo Han,Jiahao Zhang,Mingyue Cheng,Changqing Zhang", "background": "Out-of-Distribution (OOD)检测对于机器学习模型在实际环境中的可靠部署至关重要，可以准确识别与训练数据分布不同的测试样本。现有方法依赖辅助异常样本或在分布（ID）数据来生成异常信息进行训练，但由于可用异常样本有限且与实际测试中的OOD样本不匹配，它们往往无法提供充分的语义监督，导致性能不佳。", "innovation": "提出了一个名为Retrieval-Augmented Prompt (RAP)的新颖的OOD检测方法。该方法通过检索外部知识来增强预训练的视觉-语言模型的提示，提供增强的语义监督。在训练过程中，RAP基于与外部文本知识的联合相似性检索异常样本的描述词，并用于增强模型的OOD提示。在测试过程中，RAP根据遇到的OOD样本动态更新OOD提示，使模型能够快速适应测试环境。", "conclusion": "广泛的实验表明，RAP在大规模OOD检测基准测试中达到了最先进的性能。例如，在ImageNet-1k数据集上的1-shot OOD检测中，RAP的FPR95平均减少了7.05%，AUROC提高了1.71%，与之前的方法相比。此外，全面的析因研究验证了每个模块的有效性和我们方法背后的原因。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10557", "html_url": "https://arxiv.org/abs/2508.10557", "title": "PTQAT: 一种用于3D感知任务的混合参数高效量化算法", "title_en": "PTQAT: A Hybrid Parameter-Efficient Quantization Algorithm for 3D Perception Tasks", "authors": "Xinhao Wang,Zhiwei Lin,Zhongyu Xia,Yongtao Wang", "background": "量化是一种降低深度学习模型计算复杂度和存储需求的方法。Post-Training Quantization (PTQ) 和 Quantization-Aware Training (QAT) 是两种主流的量化方法。PTQ 虽然优点是不需要额外的训练时间，但常常导致量化模型性能不可接受的下降。QAT 虽然能保持较高的模型精度，但它需要大量的 GPU 内存和较长的训练时间。", "innovation": "本文提出了 PTQAT，这是一种新的混合量化算法，专门用于3D感知网络的高效部署。该方法选择关键层进行QAT微调，而对其他层进行PTQ。实验结果表明，这种方法能够在几乎冻结50%可量化层的情况下实现与QAT相近的性能，同时支持多种量化位宽（如4位）和不同的模型架构（包括CNN和Transformer）。在多个3D感知任务（如物体检测、语义分割和占用预测）上的实验结果表明，使用这种方法的性能优于仅使用QAT的方法。", "conclusion": "PTQAT 方法在保持模型精度的同时降低了对计算资源的要求，特别适用于资源受限的场景。该方法在单一框架内实现了与 QAT 相媲美的性能，同时提供了更高的效率和灵活性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10582", "html_url": "https://arxiv.org/abs/2508.10582", "title": "EvTurb：事件传感器引导的大气湍流消除", "title_en": "EvTurb: Event Camera Guided Turbulence Removal", "authors": "Yixing Liu,Minggui Teng,Yifei Xia,Peiqi Duan,Boxin Shi", "background": "大气湍流会引入模糊和几何偏转等畸变，严重影响计算机视觉任务的效果。现有的单帧和多帧方法由于湍流畸变的组成复杂性，难以解决因湍流导致的问题的高度不可解性。", "innovation": "提出了一个名为EvTurb的基于事件的湍流去除框架，该框架利用高速事件流来解耦模糊和偏转效果，通过一个新颖的两步事件引导网络实现：首先利用事件整数减少粗略输出中的模糊，然后基于原始事件流的方差图消除细化输出中的偏转失真。", "conclusion": "实验结果表明，EvTurb超过了最先进的方法，同时保持了计算效率。此外，还介绍了TurbEvent，这是第一个包含多样化湍流场景的真实捕获数据集。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10568", "html_url": "https://arxiv.org/abs/2508.10568", "title": "通过交叉熵掩码调整SAM以解决遥感变化检测中的类别不平衡问题", "title_en": "Adapting SAM via Cross-Entropy Masking for Class Imbalance in Remote Sensing Change Detection", "authors": "Humza Naveed,Xina Zeng,Mitch Bryson,Nagita Mehrseresht", "background": "在计算机视觉的多个领域，基础模型已经取得了显著的成功。这些模型能够学习易迁移的通用表示，从而在训练时未见过的任务上表现出色。Segment Anything Model (SAM) 就是一个案例，它可以准确地进行图像中的物体分割。团队提出了一种适应 SAM 编码器的方法，通过微调结合空间-时间特征增强（STFE）和多尺度解码器融合（MSDF），可以在多种尺度上稳健地检测变化。此外，他们还提出了一种新的交叉熵掩码（CEM）损失函数，以处理变化检测数据集中的类别不平衡问题。", "innovation": "该研究提出了通过微调 SAM 编码器、结合空间-时间特征增强（STFE）和多尺度解码器融合（MSDF）的方法，以解决遥感变化检测中的类别不平衡问题。此外，还引入了交叉熵掩码（CEM）损失函数来处理类别不平衡。这种方法在四个变化检测数据集（Levir-CD、WHU-CD、CLCD 和 S2Looking）上均优于现有的最先进的方法，特别是在 S2Looking 复杂数据集上取得了 2.5% 的 F1 分数提升。", "conclusion": "该方法在多个变化检测数据集上均表现出色，特别是在复杂数据集上取得了显著的 F1 分数提升，证明了该方法的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10572", "html_url": "https://arxiv.org/abs/2508.10572", "title": "面向多模态引导视频对象分割的代理式人工智能", "title_en": "Towards Agentic AI for Multimodal-Guided Video Object Segmentation", "authors": "Tuyen Tran,Thao Minh Le,Truyen Tran", "background": "视频对象分割是一个多模态问题，需要生成精细的分割结果并受到外部线索的指导。传统的处理方法通常涉及训练专门模型，这些模型计算复杂且需要手动标注。近年来，视觉语言基础模型的进展为无需训练的方法提供了新的方向。这些方法已经能够实现与完全监督、特定任务模型相当的性能。然而，现有的方法依赖于固定的工作流程，这不能适应任务的动态性质。论文指出，现有的方法无法灵活地适应任务的变化，因此提出了一个名为Multi-Modal Agent的新系统，以解决这一问题。该系统利用大型语言模型的推理能力生成定制的过程，以适应每个输入，并且可以直接与不同类型模态下的专用工具交互，以识别由多模态提示描述的目标对象。", "innovation": "提出了一个名为Multi-Modal Agent的新系统，该系统利用大型语言模型的推理能力自适应调整工作流程，以适应不同的输入情况。系统能够与不同模态下的专用工具交互，识别由多模态提示描述的目标对象。这种方法展示了在两个多模态条件下视频对象分割任务（RVOS和Ref-AVS）中比先前方法的明显改进，表明了代理式人工智能在视频对象分割任务中的潜力。", "conclusion": "Multi-Modal Agent为视频对象分割任务提供了一种更加灵活和自适应的方法，展示了相较于现有方法的优越性。该系统利用了视觉语言基础模型的多功能性，并通过自适应的方式来处理动态任务的变化，对未来研究具有重要意义。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10567", "html_url": "https://arxiv.org/abs/2508.10567", "title": "SpaRC-AD: 在端到端无人驾驶中雷达-相机融合的一个基线", "title_en": "SpaRC-AD: A Baseline for Radar-Camera Fusion in End-to-End Autonomous Driving", "authors": "Philipp Wolters,Johannes Gilg,Torben Teepe,Gerhard Rigoll", "background": "端到端的自主驾驶系统通过统一优化感知、运动预测和规划，有望展现出更强的性能。然而，基于视觉的方法在恶劣天气条件、部分遮挡和精确速度估计方面面临根本性的限制，这些都是在涉及碰撞避免等安全敏感场景中准确运动理解和长期轨迹预测不可或缺的挑战。为了解决这些限制，我们提出了一种基于查询的端到端相机-雷达融合框架SpaRC-AD，用于以规划为导向的自主驾驶。该框架通过稀疏的3D特征对齐和多普勒速度估计，实现用于代理锚点、地图多边形线和运动建模的强化3D场景表示。", "innovation": "SpaRC-AD框架通过稀疏的3D特征对齐和多普勒速度估计，实现了用于代理人锚点、地图多边形线和运动模型的增强3D场景表示。与仅基于视觉的最新基线系统相比，我们的方法在多个自主驾驶任务中实现了显著改进，包括3D检测精度提高了4.8%，多对象跟踪提高了8.3%，实时建图提高了1.8%，运动预测准确度提高了4.0%，轨迹规划长度误差降低了0.1m，时间规划指标降低了9%。并且在多个具有挑战性的基准测试中，都达到了空间一致性和时间一致性。", "conclusion": "我们展示了雷达融合在关键安全场景中的有效性，这些场景需要精确的运动理解和长期轨迹预测以避免碰撞。所有实验源代码可以在上述链接中获取。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10576", "html_url": "https://arxiv.org/abs/2508.10576", "title": "HumanSense：通过推理提示MLLMs从多模态感知到同理心导向的背景响应", "title_en": "HumanSense: From Multimodal Perception to Empathetic Context-Aware Responses through Reasoning MLLMs", "authors": "Zheng Qin,Ruobing Zheng,Yabing Wang,Tianqi Li,Yi Yuan,Jingdong Chen,Le Wang", "background": "尽管多模态大语言模型（MLLMs）在实现真正的人类互动方面展现出巨大的潜力，但缺乏细致的人本评价框架成为了瓶颈，这些框架应当能够评估模型理解和回应复杂人类意图及提供同理心和情境相关响应的能力。文章提出了一种名为HumanSense的基准，旨在全面评估MLLMs在人本感知和交互能力方面，特别是在对复杂多模态情境的深入理解以及理性反馈的表述上。研究发现，主要的MLLMs仍有许多改进空间，特别是在高级互动任务上。结合视觉、听觉和文本信息可以显著改善这些任务的表现，而全模态模型在这些任务上显示出优势。此外，适合的反馈源自对对话者需求和情绪的情境分析，推理能力是解锁这一过程的关键。因此，通过多阶段、分模态进步的强化学习方法，提高了全模态模型的推理能力，从而在评估结果上取得了显著提升。我们还观察到有效的推理过程具有高度一致的认知模式，通过设计相应的提示，我们也在无需训练的情况下提升了非推理模型的表现。", "innovation": "提出了一种名为HumanSense的基准评估框架，旨在评估MLLMs在多模态感知和情感理解上的能力。该研究引入了一种多阶段、分模态进步的强化学习方法，增强模型的推理能力，特别是在复杂交互任务上的表现显著提升。此外，通过设计提示，增强了非推理模型的性能，且无需进行额外训练。这些方法凸显了在理解用户需求和情绪，以及生成合理反馈方面的潜力。", "conclusion": "研究发现，尽管MLLMs取得了显著进步，但仍存在很大的提升空间，特别是在高层次的互动任务上。结合音频和文本信息可以显著改善模型的性能，特别是全模态模型在这些任务上表现出了优势。推理是生成合适反馈的关键，研究通过改进推理能力在评估结果上取得了实质性进展。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10616", "html_url": "https://arxiv.org/abs/2508.10616", "title": "基于傅里叶引导注意力上采样在图像超分辨率中的应用", "title_en": "Fourier-Guided Attention Upsampling for Image Super-Resolution", "authors": "Daejune Choi,Youchan No,Jinhyung Lee,Duksu Kim", "background": "传统的上采样方法，如子像素卷积，虽然效率高，但经常无法重建高频细节，并引入了伪影。", "innovation": "提出了基于频率引导的注意力模块（FGA），它通过（1）基于傅里叶特征的多层感知机（MLP）进行位置频率编码，（2）跨分辨率相关注意力层实现自适应空间对齐，以及（3）频域L1损失监督光谱保真度，有效地解决了上述问题。FGA仅添加了0.3M参数，但在多种超分辨率网络中均表现出更优的性能，特别是在负载较轻和全能力场景下，实验结果显示，PSNR平均提高了0.12~0.14 dB，频域一致性提高了29%，尤其是在纹理丰富的数据集上更为明显。", "conclusion": "视觉和频域评估证实了FGA在减少伪影和保留细节能上的有效性，确立其作为传统上采样方法的实用且可扩展的替代方案。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10600", "html_url": "https://arxiv.org/abs/2508.10600", "title": "针对自主驾驶中2D物体检测的强健且实用的贴片攻击", "title_en": "Towards Powerful and Practical Patch Attacks for 2D Object Detection in Autonomous Driving", "authors": "Yuxin Cao,Yedi Zhang,Wentao He,Yifan Liao,Yan Xiao,Chang Li,Zhiyong Huang,Jin Song Dong", "background": "基于学习的自主驾驶系统对对抗补丁极其敏感，这对其实际部署构成了严重的安全和隐私风险。黑盒攻击，由于其无需了解模型结构便可实现高成功率，尤其令人担忧，尤其是在相比查询基础攻击时展现出高度的转移性。以往的黑盒攻击通常使用平均准确率（mAP）作为评价指标并以此设计训练损失函数，但这种评估方式往往高估了攻击效果，尤其是在实际攻击情况下成功率较低。此外，低分辨率数据训练的补丁在高分辨率图像中往往效果不佳，限制了它们在自主驾驶数据集中的转移性。", "innovation": "本文提出了P$^3$A（Powerful和Practical Patch Attack），这是一种专门针对高分辨率数据集的2D物体检测攻击框架。P$^3$A引入了实用攻击成功率（PASR）作为新的评估指标，以更加准确地量化攻击效果，特别是针对行人的安全性。该框架提出了定位-置信度抑制损失（LCSL），改进了在PASR下的攻击转移性。此外，P$^3$A还引入了概率尺度不变填充（PSPP）作为数据预处理步骤，以保持高分辨率数据集下的攻击转移性。", "conclusion": "P$^3$A在未见过的模型和高分辨率数据集上表现出色，无论是使用本文提出的实用IoU为基础的评估指标，还是传统的mAP指标评价，都优于现有的先进攻击方法。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10617", "html_url": "https://arxiv.org/abs/2508.10617", "title": "FIND-Net -- Fourier-Integrated Network with Dictionary Kernels for Metal Artifact Reduction", "title_en": "FIND-Net -- Fourier-Integrated Network with Dictionary Kernels for Metal Artifact Reduction", "authors": "Farid Tasharofi,Fuxin Fan,Melika Qahqaie,Mareike Thies,Andreas Maier", "background": "在计算机断层摄影（CT）成像中，高密度金属植入物导致的伪影严重降低了图像质量，使诊断和治疗计划变得复杂。尽管现有的深度学习算法在金属伪影减少（MAR）方面取得了显著的成果，但在抑制伪影的同时保留结构细节方面仍然存在挑战。", "innovation": "我们提出了一种新的MAR框架——FIND-Net（Fourier-Integrated Network with Dictionary Kernels），它结合了频率域和空间域的处理，以实现更优秀的伪影抑制效果和结构保留。FIND-Net整合了快速傅里叶卷积（FFC）层和可训练的高斯滤波器，将MAR视为在空间域和频率域上同时操作的混合任务，从而增强全局上下文理解并提高频率选择性，有效减少了伪影并保持了解剖结构。", "conclusion": "在合成数据集上的实验结果显示，FIND-Net在最新MAR方法中取得了统计学上的显著改进，包括3.07%的MAE减少、0.18%的SSIM增加和0.90%的PSNR提升，证明其在不同伪影复杂度下的鲁棒性。此外，在临床CT扫描的实际评估中，FIND-Net能够最小化对干净解剖区域的修改并有效地抑制金属诱导的失真，这些发现突显了FIND-Net在提高MAR性能方面的潜力，提供了更优的结构保留和改进的临床适用性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10635", "html_url": "https://arxiv.org/abs/2508.10635", "title": "ChatENV：一种用于传感器引导的环境监测和情景模拟的互动视觉-语言模型", "title_en": "ChatENV: An Interactive Vision-Language Model for Sensor-Guided Environmental Monitoring and Scenario Simulation", "authors": "Hosam Elgendy,Ahmed Sharshar,Ahmed Aboeitta,Mohsen Guizani", "background": "理解来自航空影像的环境变化对于气候复原力、城市规划和生态系统监测至关重要。然而，当前的视觉语言模型（VLMs）忽视了环境传感器中的因果信号，依赖于单一来源的容易产生风格偏差的注释，且缺乏基于情景的互动推理。", "innovation": "我们介绍了ChatENV，这是第一个集成了卫星图像对和现实世界传感器数据共同推理的互动VLM。其创新点包括：(i) 创建了一个包含177,000张图像并形成152,000个时间上的图像配对，覆盖197个国家和62种土地利用类别的大数据集，包含丰富的传感器元数据（例如温度、PM10、CO）；(ii) 使用GPT-4o和Gemini 2.0进行注释，以实现风格和语义多样性；(iii) 采用高效低秩适应（LoRA）适配器对Qwen-2.5-VL进行微调，以用于聊天目的。", "conclusion": "ChatENV在时间序列和“假设-if”推理（例如BERT-F1得分为0.903）方面表现出色，与最先进的时序模型相比，其性能相当或更好，同时支持互动的情景分析。这使ChatENV成为一种强大的基准工具，用于基于地面、传感器环境监测。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10637", "html_url": "https://arxiv.org/abs/2508.10637", "title": "视觉编码器中的处理和获取痕迹：CLIP对你的相机了解多少？", "title_en": "Processing and acquisition traces in visual encoders: What does CLIP know about your camera?", "authors": "Ryan Ramos,Vladan Stojnić,Giorgos Kordopatis-Zilos,Yuta Nakashima,Giorgos Tolias,Noa Garcia", "background": "已有研究分析了视觉编码器对图像变换和损坏的鲁棒性，特别是在训练过程中未见过这些改变的情况下。这种改变会在测试时引入分布偏移，通常导致性能下降。现有工作主要集中在严重的损坏，这些损坏在强烈应用时会扭曲有用的信号，从而影响准确的语义预测。本文作者采取了不同的视角，将焦点转向图像获取过程中的参数，这些参数可能在人类肉眼看来是微妙甚至难以察觉的。研究表明，这些参数被系统地编码在学习的视觉表示中，并且可以很容易地恢复。更值得注意的是，它们的存在对语义预测可能有深远影响，无论是积极的还是消极的。这种影响取决于语义标签与获取或处理标签之间是否存在强烈的正相关或负相关。", "innovation": "本文的创新在于分析了图像获取过程中的参数，这些参数可能在人类肉眼看来是微妙甚至难以察觉的，而这些参数被系统地编码在学习的视觉表示中。此外，本文发现这些参数的存在对语义预测有深远影响，这种影响受语义标签与获取或处理标签之间相关性的影响。这为理解视觉编码器的理解能力和图像处理过程中的潜在影响提供了新的视角。", "conclusion": "研究表明，视觉编码器中的参数将图像获取和处理过程中的痕迹编码为学习的视觉表示，这些参数的存在对语义预测有积极作用，无论是正面的还是负面的。这种影响取决于语义标签与获取或处理标签之间的关系。研究团队已公开了代码和数据供进一步研究使用。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10667", "html_url": "https://arxiv.org/abs/2508.10667", "title": "AddressVLM: 通过大型视觉语言模型进行图像地址本地化交叉视图对齐调整", "title_en": "AddressVLM: Cross-view Alignment Tuning for Image Address Localization using Large Vision-Language Models", "authors": "Shixiong Xu,Chenghao Zhang,Lubin Fan,Yuan Zhou,Bin Fan,Shiming Xiang,Gaofeng Meng,Jieping Ye", "background": "LVLMs在粗粒度的地理定位方面表现出色，但在城市中的街道级别定位方面则存在问题。本研究旨在将城市范围内的地址本地化能力整合到LVLMs中，以便利用街景图像灵活回答与地址相关的问题。然而，街景视觉问答数据仅提供了微观视觉线索，导致微调模型的表现不佳。", "innovation": "提出了跨视图对齐调整方法，包括卫星视图和街景图像嫁接机制以及自动标签生成机制。通过这些机制，提升了LVLM对街道分布的全球理解，从而增强了地址本地化的准确性。", "conclusion": "提出的AddressVLM模型在两个基于Pittsburgh和San Francisco的图像地址本地化数据集上的平均地址本地化准确性分别超过了现有LVLM模型9%和12%。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10643", "html_url": "https://arxiv.org/abs/2508.10643", "title": "使用姿态估计和双向LSTM检测奶牛跛行", "title_en": "Lameness detection in dairy cows using pose estimation and bidirectional LSTMs", "authors": "Helena Russello,Rik van der Tol,Eldert J. van Henten,Gert Kootstra", "background": "该研究提出了一种结合姿态估计和双向长短期记忆（BLSTM）神经网络的跛行检测方法。传统的跛行检测方法主要依赖于手动特征工程，这不仅耗时而且容易出错。新的方法通过自动学习关键点轨迹的时间运动特征，提高了检测精度，并能够在较短的序列和较少的训练数据下工作。", "innovation": "该方法通过使用T-LEAP姿态估计模型从奶牛行走视频中提取九个关键点的运动序列，并将这些序列用于训练BLSTM分类器，从而实现二分类跛行检测。相比于依赖手动设计的运动特征的传统方法，该方法的最好架构达到了85%的分类准确率，而传统方法的准确率为80%。此外，还展示了BLSTM分类器能够在短短一秒的视频数据中检测出跛行的能力。", "conclusion": "该研究提出的结合姿态估计和BLSTM神经网络的跛行检测方法，在分类准确率和所需视频数据量两个方面显著优于传统的依靠手动特征工程的方法。这种方法不仅简化了流程，减少了人工干预，还提高了检测速度和准确性，对奶牛福利管理和疾病早期诊断具有重要意义。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10631", "html_url": "https://arxiv.org/abs/2508.10631", "title": "通过楔形指导提高合成图像的实用性", "title_en": "Increasing the Utility of Synthetic Images through Chamfer Guidance", "authors": "Nicola Dall'Asen,Xiaofeng Zhang,Reyhane Askari Hemmat,Melissa Hall,Jakob Verbeek,Adriana Romero-Soriano,Michal Drozdzal", "background": "生成式图像生成模型具有生成无限量合成训练数据的巨大潜力。然而，近期生成质量的提高是以牺牲生成多样性为代价的，限制了这些模型作为合成训练数据来源的实用性。尽管已经引入了基于引导的方法来通过关注质量或多样性来提高生成数据的实用性，但这些方法（显式或隐式）的目标函数经常忽视合成数据与真实数据之间可能存在的分布变化。", "innovation": "我们提出了楔形指导：一种无需训练的引导方法，利用少数真实样本图像来表征合成数据的质量和多样性。我们的方法在使用2个真实样本图像时达到了最佳的少量样本性能（精度96.4%，分布覆盖率为86.4%），使用32个真实样本图像时达到了97.5%和92.7%的提升。此外，我们展示了使用楔形指导生成的合成数据可用于训练下游图像分类器，与基线相比，在分布内准确性提高高达15%，在分布外提高高达16%。我们的方法不需要使用无条件模型，在采样时间可将FLOPs减少31%。", "conclusion": "楔形指导通过少量真实图像提升了合成数据的质量和多样性，提高了其作为训练数据的实用性，特别是在少量样本场景下表现优异，同时大幅减少了计算成本。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10645", "html_url": "https://arxiv.org/abs/2508.10645", "title": "SemPT：视觉语言模型中的语义提示调优", "title_en": "SemPT: Semantic Prompt Tuning for Vision-Language Models", "authors": "Xiao Shi,Yangjun Ou,Zhenzhong Chen", "background": "视觉传输学习在未见类别上的应用是一个重要的研究课题，但也是一个具有挑战性的问题，因为保持类别特定表示和获取可传输知识之间存在着内在的冲突。现有的视觉语言模型（VLMs）可以基于大量图像-文本对进行预训练，为解决这个问题提供了可能。然而，现有的提示调优方法依赖于稀疏的类别标签或不同LLM生成的描述，这使得知识表示失真并阻碍了可传输性。这就需要一个能够克服这些限制的新框架来推动该领域的发展。", "innovation": "本文提出了一种名为SemPT（语义提示调优）的新框架，通过利用类别之间的共享属性知识来解决泛化挑战。SemPT采用两步提示策略，引导LLM提取共享的视觉属性和生成属性级别的描述，捕捉超越标签的可传输语义线索，同时保持一致性结构。此外，SemPT还应用了视觉引导加权技术来减少与无关属性相关的噪音并增强文本嵌入。同时，图像嵌入与标签和属性增强文本嵌入联合对齐，平衡已见类别领域的辨别性和对未见类别的可传输性。考虑类别曝光的可用性，推理动态选择标准标签嵌入或属性增强嵌入，以确保有效的适应。", "conclusion": "在15个基准数据集上进行了广泛的实验，结果表明SemPT在各种设置下，包括基础到新类别的泛化、跨数据集迁移、跨领域迁移和少量样本学习中，都达到了最先进的性能。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10655", "html_url": "https://arxiv.org/abs/2508.10655", "title": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking", "title_en": "Serial Over Parallel: Learning Continual Unification for Multi-Modal Visual Object Tracking and Benchmarking", "authors": "Zhangyong Tang,Tianyang Xu,Xuefeng Zhu,Chunyang Cheng,Tao Zhou,Xiaojun Wu,Josef Kittler", "background": "多模态视觉对象跟踪（MMVOT）任务因不同模态之间的互补性质而引起了广泛关注。现有实践将所有传感器类型的数据混在一起进行单一的训练过程，从数据为中心的角度构建并行范式，追求目标任务的联合分布上的全球最优解。然而，缺乏一个统一的基准，使得所有类型的数据共同存在，导致在分离的基准上进行评估，使得训练和测试之间出现不一致性，从而导致性能下降。", "innovation": "1. 该工作提出了一个统一基准，名为UniBench300，通过整合多个任务数据，将推理步骤从三个削减到一个，减少了27%的时间消耗。2. 将统一过程重新格式化为一种顺序格式，逐步整合新的任务，这样性能下降可以被视为对先前任务的已知遗忘，这自然与连续学习（CL）的理念一致，从而激励进一步探索将CL注入统一流程的可能性。在两个基线和四个基准上的广泛实验表明，UniBench300的重要性和CL在支持稳定统一流程中的优越性。此外，实证分析发现，性能下降与网络容量之间呈负相关关系，不同模态差异导致不同任务间不同的下降程度（在MMVOT中，RGBT > RGBD > RGBE），为未来多模态视觉研究提供了宝贵的见解。", "conclusion": "可以通过连续学习的支持实现稳定的多模态视觉对象跟踪统一流程，UniBench300是一个有助于解决训练与测试不一致性问题的创新统一基准。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10678", "html_url": "https://arxiv.org/abs/2508.10678", "title": "HyperTea: 基于超图的时空增强和对齐网络用于移动红外微小目标检测", "title_en": "HyperTea: A Hypergraph-based Temporal Enhancement and Alignment Network for Moving Infrared Small Target Detection", "authors": "Zhaoyuan Qi,Weihua Gao,Wenlong Niu,Jie Tang,Yun Li,Xiaodong Peng", "background": "在实际应用场景中，移动红外小目标检测（MIRSTD）由于目标体积小、强度低、运动模式复杂，仍具有很高的挑战性。现有的方法通常仅建模特征节点之间的低阶相关性，并在单一时间尺度下进行特征提取和增强。尽管超图被广泛用于学习高阶相关性，但它们在MIRSTD中的应用尚未受到广泛关注。因此，迫切需要一种方法来探索超图的潜力并提高多时间尺度特征表示。", "innovation": "本文提出了一种名为HyperTea的方法，通过结合全局和局部时间视角有效建模特征的高阶时空相关性。HyperTea包括三个模块：全局时间增强模块（GTEM）通过语义聚合和传播实现全局时间上下文增强；局部时间增强模块（LTEM）用于捕捉相邻帧之间的局部运动模式，进而增强局部时间上下文；此外，进一步开发了时间对齐模块（TAM）以解决潜在的跨尺度特征对齐问题。HyperTea是第一个结合卷积神经网络（CNNs）、循环神经网络（RNNs）和超图神经网络（HGNNs）的方法，显著提高了检测性能。", "conclusion": "实验结果表明，HyperTea在DAUB和IRDST上的性能达到最先进的水平。我们的源代码可在以下链接获得。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10681", "html_url": "https://arxiv.org/abs/2508.10681", "title": "IADGPT: 统一的大视图语言模型用于基于上下文学习的少量样本工业异常检测、定位和推理", "title_en": "IADGPT: Unified LVLM for Few-Shot Industrial Anomaly Detection, Localization, and Reasoning via In-Context Learning", "authors": "Mengyang Zhao,Teng Fu,Haiyang Yu,Ke Niu,Bin Li", "background": "工业质量检测在自动化中具有重要应用。现有的一些基于大型视图-语言模型（LVLMs）的少量样本工业异常检测（FS-IAD）方法通过提示学习或微调有所成就，但现有的LVLMs主要关注通用任务，缺乏与FS-IAD相关的基本工业知识和推理能力，远未达到专业化的人工质量检测员水平。因此，本文分析了现有方法的不足，并介绍了一个新的框架IADGPT，旨在以类似人类的方式进行FS-IAD，同时处理相关的定位和推理任务。", "innovation": "本文提出了一种统一框架IADGPT，通过三个阶段的渐进式训练策略，逐步引导模型获得基础工业知识和差异性意识，并使用少量示例进行上下文学习训练，使模型能够处理新型工业产品的异常检测、定位和推理。此外，还设计了一种策略，利用 logits 输出、注意力图和语言输出来实现异常推理，从而输出图像级别和像素级别的异常评分。", "conclusion": "实验表明，IADGPT在异常检测中取得了显著的性能提升，并在异常定位和推理方面表现出竞争力。同时，研究还提出了一组包含100K图像及400个不同工业产品类别且配有详细文本注释的新数据集，支持IADGPT的训练。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10711", "html_url": "https://arxiv.org/abs/2508.10711", "title": "NextStep-1：迈向大规模连续令牌自回归图像生成", "title_en": "NextStep-1: Toward Autoregressive Image Generation with Continuous Tokens at Scale", "authors": "NextStep Team:Chunrui Han,Guopeng Li,Jingwei Wu,Quan Sun,Yan Cai,Yuang Peng,Zheng Ge,Deyu Zhou,Haomiao Tang,Hongyu Zhou,Kenkun Liu,Ailin Huang,Bin Wang,Changxin Miao,Deshan Sun,En Yu,Fukun Yin,Gang Yu,Hao Nie,Haoran Lv,Hanpeng Hu,Jia Wang,Jian Zhou,Jianjian Sun,Kaijun Tan,Kang An,Kangheng Lin,Liang Zhao,Mei Chen,Peng Xing,Rui Wang,Shiyu Liu,Shutao Xia,Tianhao You,Wei Ji,Xianfang Zeng,Xin Han,Xuelin Zhang,Yana Wei,Yanming Xu,Yimin Jiang,Yingming Wang,Yu Zhou,Yucheng Han,Ziyang Meng,Binxing Jiao,Daxin Jiang,Xiangyu Zhang,Yibo Zhu", "background": "现有的基于自回归模型的文字到图像生成模型大多依赖于计算密集型的扩散模型处理连续图像标记，或者使用矢量量化（VQ）获得带有量化损失的离散令牌。", "innovation": "NextStep-1是一个14B的自回归模型，配备了一个157M的流匹配头，通过下一标记预测目标对离散文本标记和连续图像标记进行训练。这种方法展示了强大的高保真图像合成能力，并在图像编辑方面表现强劲，展示了统一方法的强大和灵活性。", "conclusion": "通过发布代码和模型，NextStep-1旨在促进开放研究，并推动自回归图像生成技术的发展。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10680", "html_url": "https://arxiv.org/abs/2508.10680", "title": "物理知情联合多回波超分辨率与隐式神经表示在稳健胎儿T2成像中的应用", "title_en": "Physics-Informed Joint Multi-TE Super-Resolution with Implicit Neural Representation for Robust Fetal T2 Mapping", "authors": "Busra Bulut,Maik Dannecker,Thomas Sanchez,Sara Neves Silva,Vladyslav Zalevskyi,Steven Jia,Jean-Baptiste Ledoux,Guillaume Auzias,François Rousseau,Jana Hutter,Daniel Rueckert,Meritxell Bach Cuadra", "background": "胎儿脑MRI中的T2图谱具有提高发育中大脑刻画的潜力，尤其是在中磁场（0.55T）下T2衰减较慢的情况下。然而，这在技术上具有挑战性，因为胎儿MRI采集依赖于多层厚切片的多次运动受损堆叠，需要切片到体素重建（SVR）来估算高分辨率（HR）3D体积。目前，T2图谱涉及在每个回波时间（TE）下重复获取这些堆叠，导致长时间扫描和对运动的高敏感性。研究表明，在T2图谱中利用解剖冗余减少每个TE的堆叠数量具有潜力。", "innovation": "本研究提出了一种结合隐式神经表示和物理学筛选正则化的联合多TE超分辨率方法，以应对严重的运动问题。该方法能够在多个TE数据之间联合重建数据，同时保持解剖和定量T2信息的准确性，并展示出了在仿真胎儿脑和生理成人数据集（具有胎儿特征的运动）中的最佳性能。此外，还展示了在0.55T下进行胎儿T2图谱的首例生理内胎儿结果。研究表明，可以通过充分利用解剖冗余来减少每个TE的堆叠数量，从而降低T2图谱的扫描时间并增强鲁棒性。", "conclusion": "我们的研究表明，利用解剖学冗余可以减少T2图谱中的TE堆叠次数，并展示了一个在0.55T磁场下的新方法。这种方法能够以高分辨率重建数据，即使面对严重的运动问题，也能保持解剖和定量T2的准确性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10712", "html_url": "https://arxiv.org/abs/2508.10712", "title": "嵌入式SAR舰船目标检测与分类的轻量化CNN", "title_en": "Lightweight CNNs for Embedded SAR Ship Target Detection and Classification", "authors": "Fabian Kresse,Georgios Pilikos,Mario Azcueta,Nicolas Floury", "background": "合成孔径雷达(SAR)数据允许对海上船只进行大规模监控。然而，近实时监控受制于所有原始数据需下传、图像聚焦以及随后必须在地面进行分析的需求。机载处理可以生成更高层次的产品，减少需要下传的数据量，缓解带宽限制并最小化延迟。尽管如此，传统的图像聚焦和处理算法在卫星有限的内存、处理能力和计算资源方面面临挑战。", "innovation": "本研究提出了适用于嵌入式处理的轻量化卷积神经网络(CNN)，专门针对Sentinel-1卫星以带状模式和干涉宽模式获取的未聚焦SAR数据进行实时图像识别。这表明可以在机载环境中有效地使用这些模型并部署到FPGA上，并通过分析船舶和风力涡轮机之间的二元分类任务，展示了目标分类的可能性。", "conclusion": "该研究证明了使用特定的神经网络模型进行机载处理的可行性，并展示了在嵌入式系统中对未聚焦SAR数据进行实时舰船检测与分类的可能性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10710", "html_url": "https://arxiv.org/abs/2508.10710", "title": "CountCluster：无需训练的对象数量指导在跨注意图聚类的文本到图像生成中的应用", "title_en": "CountCluster: Training-Free Object Quantity Guidance with Cross-Attention Map Clustering for Text-to-Image Generation", "authors": "Joohyeon Lee,Jin-Seop Lee,Jee-Hyong Lee", "background": "基于扩散的文本到图像生成模型在图像质量和多样性方面表现出色。然而，它们仍然难以生成与输入提示中指定的物体数量相符的图像。已有一些方法依赖附加的计数模块或从学习到的标记或潜在特征中推导数量表示进行迭代细化，但这些方法在准确反映指定的物体数量方面仍存在限制，并且忽视了一个重要的结构特征——生成图像中的物体实例数量主要在去噪过程的早期时间步确定。现有的方法未能确保在生成图像时，目标物体数量在跨注意力图中的激活区域正确匹配，并且每个区域应清晰分离。", "innovation": "本文提出CountCluster方法，该方法根据输入中的指定物体数量来引导跨注意力图的聚类，无需任何外部工具或额外训练。该方法在推理时间将物体跨注意力图划分为k个簇，根据注意力得分定义一个理想的分布，其中每个簇空间上分离良好，并优化潜在变量以与其目标分布对齐。该方法在物体数量准确性上比现有方法平均提高了18.5％，并且在各种提示下展示了更好地数量控制性能。", "conclusion": "CountCluster方法通过在文本到图像生成中使用跨注意图聚类来实现无需训练对象数量的指导，显著提高了物体数量的准确性，并展示了优异的数量控制性能。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10704", "html_url": "https://arxiv.org/abs/2508.10704", "title": "动态交通场景中超越传统视觉：RGB-事件融合实现鲁棒目标检测", "title_en": "Beyond conventional vision: RGB-event fusion for robust object detection in dynamic traffic scenarios", "authors": "Zhanwen Liu,Yujing Sun,Yang Wang,Nan Yang,Shengbo Eben Li,Xiangmo Zhao", "background": "传统RGB相机的动态范围限制降低了全局对比度，导致在复杂交通环境中（如夜间驾驶、隧道）丢失高频细节（如纹理和边缘），妨碍了特征提取和基于帧的目标检测。研究者们提出了将生物启发的事件相机与RGB相机整合的方法来提供高动态范围信息，以解决这一问题。", "innovation": "该研究提出了一个运动线索融合网络（MCFNet），在挑战性光照条件下实现最优的时空对齐和跨模态特征融合。具体来说，引入了事件校正模块（ECM）和事件动态上采样模块（EDUM），以及跨模态Mamba融合模块（CMM），用于精确的时空对齐和互补信息的有效整合。", "conclusion": "实验表明，MCFNet在各种恶劣光照条件和快速移动交通场景下显著优于现有方法。例如，在DSEC-Det数据集上，MCFNet在mAP50和mAP指标上分别超越了最佳现有方法7.4%和1.7%，代码已公开。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10716", "html_url": "https://arxiv.org/abs/2508.10716", "title": "从图像匹配视角重访跨视角定位", "title_en": "Revisiting Cross-View Localization from Image Matching", "authors": "Panwang Xia,Qiong Wu,Lei Yu,Yi Liu,Mingtao Xiong,Lei Liang,Yongjun Zhang,Yi Wan", "background": "跨视角定位旨在通过空中或卫星图像注册地面视角图像来估算三维自由度的姿态。这对于GPS信号被阻挡的环境（如城市峡谷和灾害区域）至关重要。现有的方法要么直接回归姿态，要么在共享的顶视图（BEV）空间中对齐特征。然而，这些方法在建立严格的跨视角对应关系方面存在不足，无法建立精确或几何一致的匹配。因此，地面视图和空中视图之间的细粒度图像匹配仍然是一个未解决的问题，这反过来限制了定位结果的理解度。", "innovation": "本文从跨视角图像匹配的角度重新审视跨视角定位，并提出了一种新型框架，以改善匹配和定位。具体而言，引入了Surface Model以准确建模可见区域进行BEV投影，并引入了SimRefiner模块通过局部-全局残差校正细化相似矩阵，从而消除对后续处理如RANSAC的依赖。为支持该领域的进一步研究，还引入了CVFM基准，这是第一个带有32,509对带有像素级对应关系的跨视角图像对的基准。大量实验表明，本方法在定位精度和图像匹配质量上均大幅改进，特别是在极端视角差异条件下，设置新的基线。", "conclusion": "本文提出的方法显著提高了定位精度和图像匹配质量，特别是在极端视角差异条件下，为跨视角定位领域设立了新的基准。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10729", "html_url": "https://arxiv.org/abs/2508.10729", "title": "EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering", "title_en": "EgoCross: Benchmarking Multimodal Large Language Models for Cross-Domain Egocentric Video Question Answering", "authors": "Yanjun Li,Yuqian Fu,Tianwen Qian,Qi'ao Xu,Silong Dai,Danda Pani Paudel,Luc Van Gool,Xiaoling Wang", "background": "近期的多项模态大型语言模型（MLLMs）在自视点视频问答（EgocentricQA）方面取得了显著进展。然而，现有的基准和研究主要集中在烹饪和清洁等日常活动中。真实世界的部署不可避免地会遇到领域转换，目标领域在视觉风格和语义内容上存在显著差异。", "innovation": "我们提出了EgoCross基准，用于评估MLLMs在EgocentricQA中的跨领域泛化能力。EgoCross涵盖了手术、工业、极限运动和动物视角四个多样化且具有挑战性的领域，涵盖了约1000个QA对，分布在798个视频片段中，涉及四个关键问答任务：预测、识别、定位和计数。每个QA对都提供了OpenQA和CloseQA格式，以支持细粒度评估。", "conclusion": "实验证明，大多数现有的MLLMs，无论是通用型还是自视点专用型，都无法很好地适应超出日常生活的领域，突显了当前模型的局限性。我们还进行了几个初步研究，如微调和强化学习，以探索可能的改进。我们希望通过EgoCross和我们的配套分析，为自适应和鲁棒的自视点视频理解奠定基础，并公开了数据和代码。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10731", "html_url": "https://arxiv.org/abs/2508.10731", "title": "Generalized Category Discovery 的剖析：基于自我解构的多重共识", "title_en": "Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction", "authors": "Luyao Tang,Kunze Huang,Chaoqi Chen,Yuxuan Yuan,Chenxin Li,Xiaotong Tu,Xinghao Ding,Yue Huang", "background": "人类感知系统在识别已知和新类别中的物体方面表现出色，而现有机器学习框架在这方面仍有局限性。现有的通用类别发现（GCD）方法大多集中于优化目标函数，而未能充分模仿人类认知过程的复杂性。", "innovation": "本文提出了一种名为 ConGCD 的新方法，通过高层次语义重构建立基于视觉基础元素的表示形式，并通过自我解构将同类共享特征进行解耦。该方法模仿人类在视觉处理中的偏好多样性，通过实现主导共识单元和上下文共识单元来捕捉类别判别模式和内在分布不变量。此外，通过动态优化激发路径，最终预测通过多重共识集成得出。", "conclusion": "ConGCD 在粗细粒度基准测试中的广泛评估证明了其作为一个共识感知范式的有效性。相关代码可在指定网址获得。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10740", "html_url": "https://arxiv.org/abs/2508.10740", "title": "使用群不变表示的轴级对称检测", "title_en": "Axis-level Symmetry Detection with Group-Equivariant Representation", "authors": "Wongyun Yu,Ahyun Seo,Minsu Cho", "background": "对称性是一个基本概念，已经在多个领域得到了广泛研究，但在复杂场景中检测对称性仍然是计算机视觉领域的一个重大挑战。尽管基于热图的方法可以局部化可能的对称轴区域，但在精确识别个别轴方面往往不够准确。", "innovation": "提出了一个新颖框架，用于检测两种最常见对称类型（反射和旋转）的轴级别对称性，通过明确表示几何原语（线和点）。框架采用了对二面体群具有不变性的双分支结构，每个分支专用于利用二面体群不变特征来利用其各自的对称类型结构。引入了定向锚点和反射匹配来识别反射对称轴，并提出了旋转匹配来识别旋转中心。", "conclusion": "广泛实验表明，该方法在检测轴级对称性方面达到了最先进的性能，超过了现有方法。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10743", "html_url": "https://arxiv.org/abs/2508.10743", "title": "一种高效的模型驱动群组方法用于图谱构建", "title_en": "An Efficient Model-Driven Groupwise Approach for Atlas Construction", "authors": "Ziwei Zou,Bei Zou,Xiaoyan Kui,Wenqi Lu,Haoran Dou,Arezoo Zakeri,Timothy Cootes,Alejandro F Frangi,Jinming Duan", "background": "图谱构建是医学图像分析的基础，提供标准化的空间参考，用于诸如基于人群的解剖学建模等任务。尽管基于数据的方法在一对一配准中表现出色，但由于需要大型训练数据集、泛化能力有限、缺乏真正意义上的群体注册推理过程，这些方法在实际应用中受到限制。相比之下，基于模型的方法提供了无需训练、理论基础扎实、数据效率高的替代方案，但它们在处理大规模3D数据集时往往面临规模和优化挑战。", "innovation": "本文提出了一种新的模型驱动的群组配准框架DARC（Diffeomorphic Atlas Registration via Coordinate descent），用于图谱构建。DARC支持广泛的图像差异性度量，无需消耗GPU内存即可高效处理任意数量的3D图像，通过坐标下降策略和中心性制约激活函数，DARC生成无偏的、符合解剖学的图谱，具有高解剖学保真度。此外，DARC还展示了两个关键应用：一次性分割和形状合成，分别证明了其在标注仅限于图谱的分割应用和通过生成变形场的图谱网格生成图像上的新解剖学变种方面的优势，超越了现有最先进的少量样本方法。", "conclusion": "总体而言，DARC提供了一种灵活、可泛化且资源高效的框架，用于图谱构建及应用。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10770", "html_url": "https://arxiv.org/abs/2508.10770", "title": "从诊断到改进：探究视觉语言模型中的空间物理推理", "title_en": "From Diagnosis to Improvement: Probing Spatio-Physical Reasoning in Vision Language Models", "authors": "Tiancheng Han,Yunfei Gao,Yong Li,Wuzhou Yu,Qiaosheng Zhang,Wenqi Shao", "background": "空间物理推理是理解和构建真实物理世界模型的关键步骤。尽管近期的多模态视觉语言模型（VLMs）在特定领域如多模态数学和纯空间理解方面取得了显著进展，但这些模型在空间物理推理方面的能力仍然未被充分利用且表现不佳。", "innovation": "本文对主流VLMs进行全面诊断分析，揭示了现有模型在空间物理推理任务上的不足。分析结果显示性能不佳主要由于人类先验偏见和缺乏深入推理。研究团队通过监督微调和基于规则的强化学习对Qwen2.5-VL-7B进行优化，显著提升了其空间物理推理能力，并超越了当前领先专有模型。然而，新模型在新物理场景的泛化能力仍有限，凸显了空间物理推理新方法的迫切需求。", "conclusion": "尽管取得了成功，但模型在新物理场景中的泛化能力仍然有限，强调了在空间物理推理方面研发新方法的紧迫性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10741", "html_url": "https://arxiv.org/abs/2508.10741", "title": "双感知网络引导的伪造感知学习策略用于跨域深度假信息检测", "title_en": "Forgery Guided Learning Strategy with Dual Perception Network for Deepfake Cross-domain Detection", "authors": "Lixin Jia,Zhiqing Guo,Gaobo Yang,Liejun Wang,Keqin Li", "background": "深度生成技术的出现引发了社会问题，引起了广泛关注。现有的深度伪造检测方法在特定数据集上表现良好，但在应用到未知伪造技术的数据集上表现较差。随着新兴和传统伪造技术之间的差距扩大，依赖于通用伪造痕迹的跨域检测方法变得越来越无效。这凸显了开发具有较强泛化的深度伪造检测技术的紧迫性，以应对快速迭代的伪造技术。", "innovation": "本文提出了一种伪造引导学习（FGL）策略，旨在使检测网络能够不断适应未知的伪造技术。该策略通过捕捉已知和未知伪造技术之间的差异信息，使模型能够实时调整其学习过程。此外，设计了双感知网络（DPNet），用于捕捉伪造痕迹之间的差异和关系。该网络在频域中动态感知和提取各种伪造技术的判别特征，然后将这些特征与空间特征结合并投影到嵌入空间中。还采用了图卷积来感知整个特征空间的关系，有助于更全面地理解伪造痕迹的相关性。", "conclusion": "广泛的实验表明，我们的方法在不同场景下泛化良好，并有效解决了未知伪造挑战，为深度伪造检测提供了稳健的支持。我们的代码可在https://提供的链接上找到。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10771", "html_url": "https://arxiv.org/abs/2508.10771", "title": "AEGIS: AI生成视频序列的真实性评估基准", "title_en": "AEGIS: Authenticity Evaluation Benchmark for AI-Generated Video Sequences", "authors": "Jieyu Li,Xin Zhang,Joey Tianyi Zhou", "background": "近年来，AI生成内容的进步推动了高度逼真合成视频的兴起，对社会信任和数字完整性构成了严重威胁。现有的视频真实性检测基准通常缺乏真实性、规模和复杂性，不足以有效评估现代视觉语言模型对精妙的伪造物的识别能力。", "innovation": "为解决这一重要差距，我们引入了AEGIS，一个针对超现实和语义化AI生成视频检测的新颖大规模基准。AEGIS包括来自多种最新生成模型（如Stable Video Diffusion、CogVideoX-5B、KLing和Sora）的真实和合成视频，涵盖了开源和私有架构，并特别构建了具有鲁棒性评估的挑战子集。此外，我们提供了包括语义真实描述、运动特征和低级视觉特征的多模态注释，支持真实性检测以及多模态融合和伪造定位等下游任务。", "conclusion": "广泛的实验表明，最先进的视觉语言模型在AEGIS最具挑战性的子集上检测能力有限，突显了数据集独特的真实性和复杂性，超出了现有模型的泛化能力。AEGIS确立了一个不可或缺的评估基准，从根本上推动了更稳健、可靠且广泛通用的视频真实性检测方法的研究，能够应对现实世界的伪造威胁。数据集已在此链接 https:// [此处省略具体链接] 上公开。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10779", "html_url": "https://arxiv.org/abs/2508.10779", "title": "超高清参考驱动地标图像超分辨率生成扩散先验", "title_en": "Ultra-High-Definition Reference-Based Landmark Image Super-Resolution with Generative Diffusion Prior", "authors": "Zhenning Shi,Zizheng Yan,Yuhang Yu,Clara Xue,Jingyu Zhuang,Qi Zhang,Jinwei Chen,Tao Li,Qingnan Fan", "background": "参考驱动图像超分辨率（RefSR）旨在通过利用参考高分辨率（参考HR）图像的语义和纹理信息来恢复低分辨率（LR）图像。现有的基于扩散的RefSR方法通常基于ControlNet构建，难以有效对齐LR图像和参考HR图像之间的信息。当前RefSR数据集分辨率有限，图像质量差，缺乏足够的细粒度细节来支持优质恢复。为了克服上述限制，本文提出了TriFlowSR，一种新型框架，明确实现LR图像与参考HR图像之间的模式匹配。同时，我们引入Landmark-4K，首个用于超高清（UHD）地标场景的RefSR数据集。", "innovation": "提出了TriFlowSR，一种新型框架，实现了LR图像与参考HR图像之间的明确模式匹配。设计了参考匹配策略，有效地将LR图像与参考HR图像匹配。同时，引入了Landmark-4K，首个用于超高清地标场景的数据集。这是首个针对现实世界降级情况下的超高清地标场景的扩散基于的RefSR流程。", "conclusion": "实验结果表明，TriFlowSR能更好地利用参考HR图像的语义和纹理信息，相比以往方法表现更好。到目前为止，我们首次提出了基于扩散的RefSR框架，适用于现实世界降级情况下的超高清地标场景。我们提供了代码和模型，可以通过以下链接获取：this https URL"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10774", "html_url": "https://arxiv.org/abs/2508.10774", "title": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "title_en": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "authors": "Youping Gu,Xiaolong Li,Yuhao Hu,Bohan Zhuang", "background": "扩散变换器在高质量视频生成方面目前处于领先地位，但其缓慢的迭代去噪过程和长序列上的二次注意力成本导致了显著的推理瓶颈。虽然步进蒸馏和稀疏注意力机制分别作为加速策略展现出潜力，但将这两种方法有效结合则存在巨大挑战。现有的方法要么导致效率低下，要么需要昂贵的数据以分别训练稀疏注意力机制。", "innovation": "本文提出了一种名为BLADE的数据无关联合训练框架，它引入了两种机制：1) 自适应块稀疏注意力（ASA）机制，用于动态生成内容感知的稀疏掩码，以专注于时空特征；2) 基于轨迹分布匹配（TDM）的稀疏意识步进蒸馏范式，直接将稀疏性纳入蒸馏过程，以加快收敛速度。", "conclusion": "我们的框架在不同的尺度上显示出显著的效率提升。在Wan2.1-1.3B模型上，BLADE实现了相对于50步基线的14.10倍端到端推理加速。在CogVideoX-5B等带有较短视频序列长度的模型上，该框架实现了稳定的8.89倍加速。更重要的是，加速伴随着一致的质量改进。在VBench-2.0基准测试上，BLADE提高了CogVideoX-5B的得分为0.569（从0.534），Wan2.1-1.3B得分为0.570（从0.563），这些结果在人类评估中也得到了进一步的验证。我们的代码和模型权重可以在提供的链接中获取。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10794", "html_url": "https://arxiv.org/abs/2508.10794", "title": "VasoMIM: 能觉察血管解剖学的掩模图像建模技术", "title_en": "VasoMIM: Vascular Anatomy-Aware Masked Image Modeling for Vessel Segmentation", "authors": "De-Xing Huang,Xiao-Hu Zhou,Mei-Jiang Gui,Xiao-Liang Xie,Shi-Qi Liu,Shuang-Yi Wang,Tian-Yu Xiang,Rui-Ze Ma,Nu-Fang Xiao,Zeng-Guang Hou", "background": "X射线血管造影的血管分割对于众多临床应用至关重要，但标注数据稀缺成为主要障碍。为克服这一问题，研究采用了自监督学习方法，特别是掩模图像建模（MIM），利用大量未标注数据学习迁移表示。然而，传统的MIM方法在解决血管与背景像素严重类别不平衡问题时表现不佳，导致血管表示较弱。", "innovation": "提出了一种专为X射线血管造影设计的新型MIM框架——Vascular anatomy-aware Masked Image Modeling (VasoMIM)，该框架通过集成解剖学知识解决了血管分割中的问题。具体而言，VasoMIM包括两种互补组件：解剖学指导的掩模策略和解剖学一致性损失。前者优先遮蔽含有血管的区域，使模型专注于重建与血管相关的地区；后者确保原始图像与重建图像中的血管语义一致性，从而提高血管表示的可分辨性。", "conclusion": "实验表明，VasoMIM在三个数据集上均取得了最佳表现。这些发现突显了其在X射线血管造影分析中的潜在价值。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10786", "html_url": "https://arxiv.org/abs/2508.10786", "title": "基于光学流的协同面部活体检测", "title_en": "Cooperative Face Liveness Detection from Optical Flow", "authors": "Artem Sokolov,Mikhail Nikitin,Anton Konushin", "background": "在面部活体检测领域，现有的方法往往依赖于被动的检测方式，即用户无需进行特定动作就可以进行检测。这些方法存在一定的局限性，特别是对于各种欺骗攻击（如照片打印、屏幕显示、口罩和视频回放）的有效识别能力不足。", "innovation": "本文提出了一种基于新的用户互动场景的新颖的合作式视频面部活体检测方法。在此场景中，参与者被指示缓慢地将面向摄像机的面部靠近摄像头。结合光学流动分析，这种受控的面部接近协议是本文方法的核心创新。通过设计一个让使用者遵循特定运动模式的系统，可以有效地提取面部体积信息，从而显著提高对真实面部和各种欺骗攻击的区分能力。", "conclusion": "本文方法通过对预测的光学流动和RGB帧进行神经分类器处理，有效地利用空间-时间特征，相比被动方法，能够提供更可靠的活体检测。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10838", "html_url": "https://arxiv.org/abs/2508.10838", "title": "多基线对比学习的自监督立体匹配", "title_en": "Self-Supervised Stereo Matching with Multi-Baseline Contrastive Learning", "authors": "Peng Xu,Zhiyu Xiang,Jingyun Fu,Tianyu Pu,Kai Wang,Chaojie Ji,Tingming Bai,Eryun Liu", "background": "当前的自监督立体匹配方法依赖于光度一致性假设，在遮挡区域由于对应关系不良会失效。", "innovation": "提出了一种简单有效的对比学习框架BaCon-Stereo，采用教师-学生架构并使用多基线输入，在非遮挡和遮挡区域都能有效进行自监督立体网络训练。引入了关注遮挡情况的注意力图以更好地指导学生学习遮挡区域的完整恢复。同时，构建了一个多基线数据集BaCon-20k以支持训练。", "conclusion": "大规模实验表明BaCon-Stereo在遮挡和非遮挡区域都能提升预测性能，具有较强泛化能力和鲁棒性，在KITTI 2015和2012基准测试中优于最先进的自监督方法。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10817", "html_url": "https://arxiv.org/abs/2508.10817", "title": "针对33种作物101类病害的轻量级CNN基准：面向移动设备的深度学习在植物疾病检测中的应用", "title_en": "Mobile-Friendly Deep Learning for Plant Disease Detection: A Lightweight CNN Benchmark Across 101 Classes of 33 Crops", "authors": "Anand Kumar,Harminder Pal Monga,Tapasi Brahma,Satyam Kalra,Navas Sherif", "background": "全球植物疾病是食物安全的主要威胁。开发能够早期准确检测的系统至关重要。随着计算机视觉技术的进步，能够解决这一挑战的方法变得可行。", "innovation": "开发了一个面向移动设备的解决方案，能够准确地跨33种作物分类101种植物疾病。该解决方案使用了MobileNetV2, MobileNetV3, MobileNetV3-Large和EfficientNet-B0, B1等多种轻量级架构来评估性能，EfficientNet-B1表现最佳，分类准确率达到94.7%，在准确性与计算效率之间达到了平衡。", "conclusion": "这项研究开发了一种基于轻量级CNN架构的移动友好型植物疾病检测系统，能够在资源受限的设备上实现高精度的植物疾病分类，为实际部署提供了潜在解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10858", "html_url": "https://arxiv.org/abs/2508.10858", "title": "Hierarchical Fine-grained Preference Optimization for Physically Plausible Video Generation", "title_en": "Hierarchical Fine-grained Preference Optimization for Physically Plausible Video Generation", "authors": "Harold Haodong Chen,Haojian Huang,Qifeng Chen,Harry Yang,Ser-Nam Lim", "background": "尽管近年来视频生成技术能够创造出高质量、视觉上引人入胜的视频，但在生成符合物理定律的视频方面，仍然存在重大挑战。这对要求真实性和准确性的应用程序来说是一个关键问题。", "innovation": "本文提出了一种新型框架——PhysHPO，用于层次化的跨模态直接偏好优化。该框架通过细粒度的偏好对齐来处理这一挑战，确保了物理合理性的视频生成。具体而言，PhysHPO 在四个层次上优化视频对齐：实例级别、状态级别、运动级别和语义级别。此外，为了更有效地使用现有大规模图文数据集中的“优质数据”，引入了一个自动化数据选择流程。", "conclusion": "本工作通过PhysHPO显著提高了视频生成模型的物理合理性和整体质量。到目前，这是首次研究视频生成领域的细粒度偏好对齐和数据选择方法，为更真实的人类偏好视频生成方法铺平了道路。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10840", "html_url": "https://arxiv.org/abs/2508.10840", "title": "通用客户端自适应焦点调制的联邦学习", "title_en": "Generalizable Federated Learning using Client Adaptive Focal Modulation", "authors": "Tajamul Ashraf,Iqra Altaf Gillani", "background": "联邦学习（FL）已被证明对于跨分布式客户端的隐私保护和协作训练至关重要。先前的工作TransFed提出了一种基于变压器的鲁棒联邦学习框架，利用学习适应的超网络生成每个客户端的个性化焦点调制层，表现出色，特别是在非IID和跨领域设置中优于传统方法。", "innovation": "在这一扩展版本中，作者提出了AdaptFED，它进一步探究了焦点调制在通用联邦学习中的应用，包括：改进了任务感知的客户端嵌入进一步个性化调制动态的适应策略；改进了对适应性能的理论边界；以及在时间序列和多语言数据等附加模态上进行了更广泛的实证验证。此外，还提出了一种低秩超网络条件优化的TransFed高效变种，减少了服务器与客户端之间的通信开销，使其能够在资源受限的环境中进行大规模部署。", "conclusion": "大规模实验结果表明，该方法在八个不同的数据集上优于最先进的基线方法，特别是在无需提供源数据和跨任务联邦设置中的表现尤为显著。该研究不仅扩展了在联邦学习中焦点调制的应用范围，还为更适应、可扩展和通用的基于变压器的联邦系统铺平了道路。代码可以在提供的链接处获取。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10833", "html_url": "https://arxiv.org/abs/2508.10833", "title": "UI-Venus技术报告：基于RFT构建高性能UI代理", "title_en": "UI-Venus Technical Report: Building High-performance UI Agents with RFT", "authors": "Zhangxuan Gu,Zhengwen Zeng,Zhenyu Xu,Xingran Zhou,Shuheng Shen,Yunfei Liu,Beitong Zhou,Changhua Meng,Tianyu Xia,Weizhi Chen,Yue Wen,Jingya Dou,Fei Tang,Jinzhen Lin,Yulin Liu,Zhenlin Guo,Yichen Gong,Heng Jia,Changlong Gao,Yuan Guo,Yong Deng,Zhenyu Guo,Liang Chen,Weiqiang Wang", "background": "本文介绍了UI-Venus，这是一种基于多模态大语言模型的原生UI代理，仅通过截图作为输入。它在UI定位和导航任务上达到了最先进的性能。文章通过增强型自适应微调（RFT）从Qwen2.5-VL训练，只用几十万个高质量的数据样本，并且在标准的UI定位基准上取得了优于现有最好的基线结果。为了测试其计划能力，作者还在AndroidWorld上进行了评估，这一在线UI导航竞技场也得到了有益的结果。为了实现这一成就，作者还设计了精心定制的奖励函数，并提出了有效的数据清洗方法。此外，为了改善导航性能，引入了自我演化轨迹历史对齐及稀疏动作增强机制，这有助于更连贯的规划和在复杂UI任务中的更好泛化。其他贡献包括发布最先进的开源UI代理、全面的数据清洗协议和一种新的自我进化框架，这鼓励了社区进一步的研究和发展，相关代码已开源。", "innovation": "1. 基于多模态大语言模型，仅使用截图作为输入进行自适应微调（RFT）训练，实现了UI识别和导航任务的性能提升。\n2. 推出了细致设计的奖励函数，提升了UI任务的复现和泛化能力。\n3. 引入了自我演化轨迹历史对齐及稀疏动作增强机制，进一步优化了导航性能和规划流畅度。\n4. 开源了最先进的UI代理以及数据清洗协议和自进化框架，为研究发展提供了支持。\n5. 在标准定位基准和在线UI导航竞技场上的评测中取得了超越现有基线的结果，突显了其在计划与导航任务上的优势。", "conclusion": "本文通过多模态大语言模型、奖励函数设计和自我演化框架的提出，重构了一种高效率且强大的UI代理UI-Venus，实现在UI任务的显著性能提升，并为社区后续研究提供了有益参考。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10865", "html_url": "https://arxiv.org/abs/2508.10865", "title": "GPT-5在脑肿瘤MRI推理中的表现", "title_en": "Performance of GPT-5 in Brain Tumor MRI Reasoning", "authors": "Mojtaba Safari,Shansong Wang,Mingzhe Hu,Zach Eidex,Qiang Li,Xiaofeng Yang", "background": "准确区分磁共振成像（MRI）中的脑肿瘤类型对于神经肿瘤学中的治疗计划至关重要。最近的大语言模型（LLMs）发展使得视觉问答（VQA）方法能够结合图像解释与自然语言推理。研究团队基于三个脑肿瘤分割（BraTS）数据集（胶质母细胞瘤、脑膜瘤和脑转移瘤）构建了一个精心挑选的脑肿瘤VQA基准测试，并评估了GPT-4o、GPT-5-nano、GPT-5-mini和GPT-5模型在零样本链式思考设置下的准确性。", "innovation": "研究采用了先进的大语言模型（LLMs）来进行脑肿瘤分割（BraTS）数据集的视觉问答（VQA）基准测试，结合图像解释与自然语言推理。研究特别关注了四个不同的GPT-5系列模型在零样本链式思考设置下的表现。", "conclusion": "研究发现，GPT-5-mini模型在视觉问答任务中的宏平均准确率最高（44.19%），其次是GPT-5（43.71%）、GPT-4o（41.49%）和GPT-5-nano（35.85%）。不同肿瘤亚型的表现有所差异，没有一个模型在所有组中都能占据主导地位。这表明GPT-5系列模型在结构化的神经肿瘤学VQA任务中可以达到中等准确度，但尚未达到临床应用的要求。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10719", "html_url": "https://arxiv.org/abs/2508.10719", "title": "利用区分性代码本先验进行自回归图像生成", "title_en": "Exploiting Discriminative Codebook Prior for Autoregressive Image Generation", "authors": "Longxiang Tang,Ruihang Chu,Xiang Wang,Yujin Han,Pingyu Wu,Chunming He,Yingya Zhang,Shiwei Zhang,Jiaya Jia", "background": "现有的自回归图像生成系统首先将图像 tokenize 成 token 索引序列，并利用编码本体（codebook）中的信息进行序列建模。但是，编码本体中包含丰富的 token 相似性信息还没有被充分利用。先前的研究尝试通过朴素的 k-means 聚类方法来利用这些先验知识，但却由于 token 空间不一致性和质心距离不准确的问题，效果不佳。", "innovation": "本文提出了一种名为 DCPE（Discriminative Codebook Prior Extractor）的新方法，用以替代 k-means 聚类，更有效地挖掘和利用编码本体中嵌入的 token 相似性信息。DCPE 使用实例基距离替换了传统的质心基距离，解决了 token 空间不一致性的问题，通过聚集低密度区域和避免分裂高密度区域来改进。实验结果表明，DCPE 可以无缝集成到现有的编码本体先验框架中，加速自回归模型训练并提高最终的 FID 和 IS 表现。", "conclusion": "使用 DCPE 提取的先验知识，自回归模型的训练速度提升了 42%，并在最终 FID 和 IS 表现上取得了改进。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10801", "html_url": "https://arxiv.org/abs/2508.10801", "title": "Object Fidelity Diffusion for Remote Sensing Image Generation", "title_en": "Object Fidelity Diffusion for Remote Sensing Image Generation", "authors": "Ziqi Ye,Shuran Ma,Jie Yang,Xiaoyi Yang,Ziyang Gong,Xue Yang,Haipeng Wang", "background": "高精度可控遥感图像生成既具有重要意义又极具挑战性。现有的扩散模型由于难以充分捕捉形态细节，往往生成低保真度的图像，这可能影响目标检测模型的稳健性和可靠性。为了提高遥感生成对象的精度和保真度，本文提出了Object Fidelity Diffusion（OF-Diff），通过有效提升生成对象的保真度。现有的扩散模型难以捕捉遥感布局中的先验对象形状，本文首次提取了基于布局的先验对象形状，并提出了一种双重扩散模型，该模型在采样阶段无需提供真实图像即可生成高保真度的遥感图像。", "innovation": "本文首次提出了一种基于布局的先验对象形状提取方法，并引入了双重扩散模型和扩散一致性损失函数。此外，还通过引入DDPO（Diffusion Distribution Prior Optimization）方法优化扩散过程，增加了生成的遥感图像的多样性与语义一致性。", "conclusion": "综合实验表明，OF-Diff在关键质量指标上优于现有的遥感图像生成方法。特别是，在某些多变和小型对象类别上，性能显著提升，例如飞机、船只和汽车的mAP分别提高了8.3%、7.7%和4.0%。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10869", "html_url": "https://arxiv.org/abs/2508.10869", "title": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging", "title_en": "Medico 2025: Visual Question Answering for Gastrointestinal Imaging", "authors": "Sushant Gautam,Vajira Thambawita,Michael Riegler,Pål Halvorsen,Steven Hicks", "background": "该挑战关注胃肠内镜影像的视觉问答（VQA），旨在开发可解释的人工智能（XAI）模型，这些模型能够基于临床相关问题提供合理解释的同时符合医学推理。它结合了定量性能指标和专家评审的解释性评估，以促进医疗影像分析中的可信人工智能。", "innovation": "该挑战通过引入两个子任务来创新：一是使用Kvasir-VQA-x1数据集回答多种视觉问题，二是生成多模态解释以支持临床决策。这些任务旨在改进可解释的人工智能在医疗图像分析中的应用。", "conclusion": "通过挑战，结合定量性能指标和专家审查的解释性评估，促进了医疗人工智能中的可信度。该项挑战成果评价方法和参赛指南可以在官方竞赛仓库中找到。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10672", "html_url": "https://arxiv.org/abs/2508.10672", "title": "混合生成融合以实现高效和保护隐私的面部识别数据集生成", "title_en": "Hybrid Generative Fusion for Efficient and Privacy-Preserving Face Recognition Dataset Generation", "authors": "Feiran Li,Qianqian Xu,Shilong Bao,Boyu Han,Zhiyong Yang,Qingming Huang", "background": "本文介绍了对DataCV ICCV挑战的一种方法，重点在于构建高质量的面部数据集以训练面部识别模型。该数据集不能包含与任何现有公共面部数据集重叠的身份信息。作者从基线HSFace数据集的彻底清理开始，通过Mixture-of-Experts (MoE) 策略结合面部嵌入聚类和GPT-4o辅助验证来识别并移除错误标记或不一致的身份。为了进一步使数据集多样化，使用Stable Diffusion和提示工程生成合成身份，并通过Vec2Face快速生成49个身份一致的变体。该方法结合GAN和扩散模型，用于高效构建多样化和高质量的数据集。", "innovation": "该方法通过混合生成融合策略，结合GAN和扩散模型生成高质量的面部数据集。这种方法包括彻底清理HSFace数据集，使用Mixture-of-Experts (MoE) 策略结合面部嵌入聚类和GPT-4o辅助验证来识别和移除错误标记的信息。为了进一步使数据集多样化，使用Stable Diffusion和Vec2Face生成合成身份和变体，并采用基于任务的学习策略以应对合成身份之间的高视觉相似性。", "conclusion": "最终构建的数据集每张身份包含50张图像，并且所有新生成的身份都经过主流面部数据集检查以确保身份不泄露。该方法在比赛中获得第一名，实验结果显示，该数据集在10K、20K和100K身份规模下提高了模型性能。相关代码可在给定的链接中获取。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10868", "html_url": "https://arxiv.org/abs/2508.10868", "title": "TexVerse: 一个高分辨率纹理的3D物体宇宙", "title_en": "TexVerse: A Universe of 3D Objects with High-Resolution Textures", "authors": "Yibo Zhang,Li Zhang,Rui Ma,Nan Cao", "background": "近年来，大规模3D数据集的发展极大地提升了高分辨率几何体生成，但在端到端创建高分辨率纹理方面，仍存在未被探索的空间，主要原因是缺乏合适的数据集。TexVerse填补了这一空白，它收集了来自Sketchfab的超过858,000个独特高分辨率3D模型，其中包括超过158,000个基于物理的渲染（PBR）材料的模型。每个模型都包含其所有高分辨率变体，总共涵盖了1.6百万个3D实例。此外，TexVerse还包括了专门的子集：TexVerse-Skeleton，包括69,000个配好骨架的模型以及TexVerse-Animation，包括54,000个动画模型，这些模型均保留了用户上传的原始骨架和动画数据。模型还提供了详细的注释，描述总体特征、结构组件和复杂的细节特征。这一高质量的数据资源在纹理合成、PBR材料开发、动画以及各种3D视觉和图形任务方面具有广泛的应用潜力。", "innovation": "TexVerse利用来自Sketchfab的858,000个3D模型，其中超过158,000个模型具有基于物理的渲染材料。这些模型包含了所有的高分辨率变体，数据集包含了特定于骨架和动画的子集，同时提供了详尽的模型注释。这使得TexVerse成为第一个广泛用于高分辨率纹理生成、PBR材料开发、动画和多种3D视觉及图形任务的大规模数据集。它的出现突破了现有数据集在纹理生成方面的限制，推动了相关领域的研究和应用。", "conclusion": "TexVerse提供了一个高质量的数据资源，广泛应用于纹理合成、PBR材料开发、动画以及多种3D视觉和图形任务，填补了在大规模数据集中高分辨率纹理生成方面的空白，有望在未来推动这些领域的进一步发展。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10893", "html_url": "https://arxiv.org/abs/2508.10893", "title": "STream3R: 采用因果Transformer实现可扩展的顺序3D重建", "title_en": "STream3R: Scalable Sequential 3D Reconstruction with Causal Transformer", "authors": "Yushi Lan,Yihang Luo,Fangzhou Hong,Shangchen Zhou,Honghua Chen,Zhaoyang Lyu,Shuai Yang,Bo Dai,Chen Change Loy,Xingang Pan", "background": "现有的多视图3D重建方法要么依赖昂贵的全局优化，要么依赖简单的记忆机制，这些机制在处理长序列时性能不佳。传统的三维重建方法在动态场景中通常表现不佳。", "innovation": "STream3R 提出了一种新的方法，将点图预测重新定义为仅解码器的 Transformer 问题。STream3R 引入了一种流处理框架，利用因果注意力有效处理图像序列，并从大规模 3D 数据集学习几何先验。此外，STream3R 具有与语言模型基础设施兼容的特性，能够进行高效的大量预训练和下游3D任务的微调。", "conclusion": "STream3R 方法在静态和动态场景基准测试中始终优于之前的工作。结果表明，因果 Transformer 模型在在线 3D 感知中有很好的潜力，为实时 3D 理解铺平了道路。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10894", "html_url": "https://arxiv.org/abs/2508.10894", "title": "MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data", "title_en": "MAESTRO: Masked AutoEncoders for Multimodal, Multitemporal, and Multispectral Earth Observation Data", "authors": "Antoine Labatie,Michael Vaccaro,Nina Lardiere,Anatol Garioud,Nicolas Gonthier", "background": "自监督学习在遥感领域显示出巨大的潜力，但标准的自监督方法需要适应地球观测数据的独特特征。本文在这一方向上进行了一步探索，通过对多模态、多时相和多光谱地球观测数据的融合策略和重建目标归一化方案进行全面基准测试。", "innovation": "提出了一种新型的掩码自编码器MAESTRO，该模型通过优化融合策略和定制目标归一化方案，引入了光谱先验作为自监督信号。MAESTRO在依赖多时相动态的任务上设定了新的SOTA，同时在以单一单时相模态主导的任务上保持高度竞争力。", "conclusion": "MAESTRO在四个地球观测数据集上的评估显示，在以多时相动态为主的任务中达到了新的SOTA，同时在以单一单时相模态为主导的任务中保持了高度竞争力。所有实验代码均可在此处复制再现：this https URL 。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10896", "html_url": "https://arxiv.org/abs/2508.10896", "title": "ESSENTIAL: Episodic and Semantic Memory Integration for Video Class-Incremental Learning", "title_en": "ESSENTIAL: Episodic and Semantic Memory Integration for Video Class-Incremental Learning", "authors": "Jongseo Lee,Kyungho Bae,Kyle Min,Gyeong-Moon Park,Jinwoo Choi", "background": "当前许多针对视频类增量学习（VCIL）的方法通过回复习训练并存储少量的时间密集样本以在情景记忆中缓解灾难性遗忘，但是这种方法存在内存低效的问题。另一些方法存储时间稀疏样本，虽然节约了内存但牺牲了时间信息并导致较差的性能。因此，如何在降低内存使用的同时保持性能是一个挑战性问题。为了应对这一权衡，本文提出了EpiSodic和SEmaNTIc记忆整合方法（ESSENTIAL），用于视频类增量学习。", "innovation": "本文提出了ESSENTIAL方法，该方法结合了时间和语义记忆。具体来说，它包括情景记忆用于存储时间稀疏特征和语义记忆用于存储用可学习提示表示的通用知识。本文引入了一个新的记忆检索（MR）模块，通过交叉注意机制将情景记忆和语义提示结合起来，从而能够从时间稀疏特征中检索出密集的时间特征。这种方法在多个数据集上验证了其有效性，包括TCD基准数据集UHF-101、HMDB51、Something-Something-V2以及vCLIMB基准数据集下的UCF-101、ActivityNet和Kinetics-400。", "conclusion": "尽管ESSENTIAL方法使用显著减少的内存，但其在基准测试中的表现仍然优于现有方法。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10900", "html_url": "https://arxiv.org/abs/2508.10900", "title": "量子幅度编码中的量子视觉场", "title_en": "Quantum Visual Fields with Neural Amplitude Encoding", "authors": "Shuteng Wang,Christian Theobalt,Vladislav Golyanik", "background": "量子隐神经表示（QINRs）包含了在基于门的量子计算机上进行学习和执行的组件。尽管QINRs作为新的有前途的范式刚刚出现，但他们的架构和初始化设计、量子力学性质的实用性、训练效率以及与经典模块的相互作用方面的挑战仍然存在。", "innovation": "本文通过提出适用于2D图像和3D几何场学习的新型QINR——量子视觉场（QVF），推进了这一领域。QVF使用神经幅度编码将经典数据编码为量子态向量，并跟随全纠缠设计的可学习参数量子电路，这种设计在实希尔伯特空间中实现量子（幺正）操作，确保数值稳定性和快速收敛。QVF不依赖于经典的后处理，而是直接使用投影测量来提取编码在模型中的学习信号。实验结果表明，QVF在多种指标和模型特征上，包括高频细节的学习，都优于现有的量子方法和广泛使用的经典基础方法。QVF还在2D和3D场补全及3D形状插值上展示了其实用潜力", "conclusion": "该研究提出了一种全新的QVF，通过使用神经幅度编码进行经典数据的量子态向量编码，并结合全纠缠设计的可学习参数量子电路，解决了许多现有的挑战。QVF表现出显著的性能优势，并且具有实际应用的广阔前景。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10897", "html_url": "https://arxiv.org/abs/2508.10897", "title": "Human-in-Context: 利用上下文学习进行统一跨域3D人体运动建模", "title_en": "Human-in-Context: Unified Cross-Domain 3D Human Motion Modeling via In-Context Learning", "authors": "Mengyuan Liu,Xinshun Wang,Zhongbin Fang,Deheng Ye,Xia Li,Tao Tang,Songtao Wu,Xiangtai Li,Ming-Hsuan Yang", "background": "当前研究旨在构建能够处理多种模态、任务和数据集的三维人体动作模型，但现有跨域模型常依赖于特定领域的组件和多阶段训练，这限制了其实用性和可扩展性。本文旨在通过单一过程训练统一跨域模型，从而克服这些挑战，并提高模型的灵活性和可扩展性，以适应多种领域的3D人体动作建模需求。", "innovation": "本文提出了两种模型：首先，引入了Pose-in-Context (PiC) 模型，利用上下文学习来创建一种面向姿势的跨域模型，但面对模态多样性、策略选择和上下文依赖性等问题；而后提出了Human-in-Context (HiC) 模型，作为PiC模型的扩充版本，结合了姿态和网格表示，在统一框架下扩展任务覆盖范围，并加入了更大规模的数据集。HiC模型还引入了一种最大最小相似度提示采样策略，通过网络架构中的双分支上下文注入来有效处理上下文依赖性。实验结果显示，HiC在泛化能力、数据规模和性能方面优于PiC模型，展示了这种方法在构建统一跨域3D人体运动模型中的潜力和优势。", "conclusion": "这些结果证明，HiC模型能够为构建具有改进灵活性和可扩展性的统一跨域3D人体运动模型提供可能。相关源代码和模型可在以下网址获得：this https URL。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10065", "html_url": "https://arxiv.org/abs/2508.10065", "title": "隐形水印，可见收益：基于两阶段水印设计的机器卸载", "title_en": "Invisible Watermarks, Visible Gains: Steering Machine Unlearning with Bi-Level Watermarking Design", "authors": "Yuhao Sun,Yihua Zhang,Gaowen Liu,Hongtao Xie,Sijia Liu", "background": "随着对被遗忘权的需求不断增加，机器卸载（MU）作为一种工具正在出现，以增强信任和合规性，通过从机器学习（ML）模型中移除敏感数据的影响。目前大多数MU算法主要依赖内部训练方法来调整模型权重，但在数据层面进行调整的好处尚未充分探索。为此，作者提出了一种基于数字水印的新颖方法，通过战略性地修改数据内容来实现MU。该方法通过整合水印技术，建立了一个受控的卸载机制，确保指定数据的精准移除，同时保持模型对非相关任务的实用性。", "innovation": "该研究引入了一种基于两阶段水印设计的方法——Water4MU。其核心是一个双层优化（BLO）框架，上层优化水印网络以最小化卸载难度，下层独立训练模型。该方法在图像分类和图像生成任务中有效，并且在复杂的卸载场景中表现优于现有方法。", "conclusion": "实验结果表明，Water4MU在图像分类和图像生成任务中都表现出色，并在复杂的卸载场景中优于现有方法。这一研究揭示了基于水印的MU方法的有效性和优势，为未来的隐私保护技术提供了新的思路。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10898", "html_url": "https://arxiv.org/abs/2508.10898", "title": "Puppeteer: 自动构建和动画你的3D模型", "title_en": "Puppeteer: Rig and Animate Your 3D Models", "authors": "Chaoyue Song,Xiu Li,Fan Yang,Zhongcong Xu,Jiacheng Wei,Fayao Liu,Jiashi Feng,Guosheng Lin,Jianfeng Zhang", "background": "现代交互式应用程序越来越多地需要动态3D内容，然而，将静态3D模型转换为动画资产在内容创作管道中是一项重大瓶颈。虽然近年来生成式AI在静态3D模型创作方面取得了革命性的进展，但布线和动画处理仍然高度依赖专业干预。Puppeteer是一个全面的框架，旨在解决各种3D对象的自动布线和动画问题。", "innovation": "Puppeteer采用了一种自动回归转换器，引入了基于关节的标记化策略，以紧凑表示方式优化骨架结构预测，并通过分层排序方法和随机扰动增强双向学习能力。系统还通过结合拓扑感知关节注意的注意力机制来推断皮肤权重，明确编码基于骨骼图距离的关节间关系。最后，提供了基于可微优化的动画流水线，生成稳定、高保真动画，且在计算效率上优于现有方法。广泛基准上的评估表明，我们的方法在骨架预测准确性和皮肤质量上显著优于现有技术。系统能够稳健处理各种3D内容，从专业设计的游戏资产到AI生成的形状，产生了时空连贯的动画，消除了现有方法中的抖动问题。", "conclusion": "Puppeteer框架显著提高了骨架预测准确性和皮肤质量，能够稳健处理多样化的内容，并且生成的动画无抖动现象，优于现有的方法。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10881", "html_url": "https://arxiv.org/abs/2508.10881", "title": "ToonComposer: 使用生成式后关键帧处理简化动漫制作", "title_en": "ToonComposer: Streamlining Cartoon Production with Generative Post-Keyframing", "authors": "Lingen Li,Guangzhi Wang,Zhaoyang Zhang,Yaowei Li,Xiaoyu Li,Qi Dou,Jinwei Gu,Tianfan Xue,Ying Shan", "background": "传统手绘和动漫制作需要关键帧设定，中间帧插值和着色等步骤，这需要大量的手工劳动。尽管近年来AI取得了进展，现有的方法通常会将这些步骤分别处理，导致错误积累和伪影问题。例如，中间帧插值方法在处理大规模动作时遇到困难，而着色方法需要密集的每帧素描。为了应对这些挑战，本文提出了一种名为ToonComposer的生成模型，该模型在一个后关键帧阶段统一了中间帧插值和着色。ToonComposer通过稀疏素描注入机制提供精确控制，并利用时空低秩适配器将现代视频基础模型调整到动漫领域，同时保持其时间先验不变。使用单个素描和着色参考帧即可，ToonComposer可以处理稀疏输入，同时支持在任何时间位置使用多个素描以实现更精确的运动控制。这种双重能力减少了手工劳动并提高了灵活性，使艺术家能够在实际场景中更加从容。", "innovation": "ToonComposer 是一个生成模型，它在一个后关键帧阶段统一了中间帧插值和着色步骤，通过稀疏素描注入机制提供精确控制，使用时空低秩适配器将现代视频基础模型调整到动漫领域，同时保持其时间先验不变，仅需少量的素描和颜色参考帧，同时还支持多个素描以实现更精确的运动控制。这显著减少了人工劳动并提高了灵活性，从而在实际应用场景中为艺术家提供了更大的支持。为验证模型效果，本文还创建了 PKBench 基准，包含由真人绘制的素描，模拟实际应用场景。评估结果显示，ToonComposer 在视觉质量和运动一致性方面优于现有方法，在生产效率方面表现更为优异，提供了一个更高效、更灵活的 AI 辅助动漫制作解决方案。", "conclusion": "ToonComposer 在后关键帧阶段统一了中间帧插值和着色步骤，通过稀疏素描注入机制提供精确控制，使用时空低秩适配器将现代视频基础模型调整到动漫领域，同时保持其时间先验不变。它仅需少量素描和颜色参考帧即可，同时支持多个素描以实现更精确的运动控制，减少了人工劳动并提高了灵活性。通过 PKBench 基准的评估，ToonComposer 在视觉质量和运动一致性方面表现优于现有方法，在生产效率方面更为优越，为 AI 辅助下的动漫制作提供了更为高效和灵活的解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10118", "html_url": "https://arxiv.org/abs/2508.10118", "title": "从意图到执行：基于多模态链式思考的强化学习方法实现精准CAD代码生成", "title_en": "From Intent to Execution: Multimodal Chain-of-Thought Reinforcement Learning for Precise CAD Code Generation", "authors": "Ke Niu,Haiyang Yu,Zhuofan Chen,Mengyang Zhao,Teng Fu,Bin Li,Xiangyang Xue", "background": "当前的CAD工作流程需要大量的专业知识和手工建模工作，而近年来大型语言模型的进步使得从自然语言生成代码成为可能，为自动化参数3D建模提供了新机会。但由于逻辑推理、语法正确性和数值精度的需求，直接将人类的设计意图转化为可执行的CAD代码仍然极具挑战性。", "innovation": "本文提出了CAD-RL，这是一种多模态链式思考（CoT）引导的后训练强化学习框架，用于CAD建模代码生成。该方法结合了基于CoT的冷启动和目标导向的后训练强化学习，并使用三个任务特定奖励：可执行性奖励、几何精度奖励和外部评估奖励。为了在稀疏和高方差奖励条件下稳定策略学习，引入了三种针对性优化策略：Trust Region Stretch以改进探索、Precision Token Loss以增强维度参数精度以及Overlong Filtering以减少嘈杂监督。此外，还发布了ExeCAD，一个包含16,540个真实世界CAD示例的数据集，每个示例配有自然语言和结构化设计语言描述、可执行CADQuery脚本和渲染的3D模型。", "conclusion": "实验结果表明，CAD-RL在推理质量、输出精度和代码可执行性方面相较于现有视觉语言模型实现了显著改进。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10215", "html_url": "https://arxiv.org/abs/2508.10215", "title": "数据驱动的通用手术视频理解", "title_en": "Data-Efficient Learning for Generalizable Surgical Video Understanding", "authors": "Sahar Nasirihaghighi", "background": "手术视频分析的发展正在将手术室转变为智能的数据驱动环境。计算机辅助系统支持完整的手术工作流程，从术前规划、术中指导到术后评估。然而，由于(1)注解稀缺性，(2)时空复杂性，以及(3)不同手术和机构之间的领域差距，开发用于手术视频理解的稳健和可泛化的模型依然具有挑战性。本博士研究旨在弥合基于深度学习的手术视频分析在研究与临床实际应用之间的差距。", "innovation": "研究提出了几种新颖的半监督框架，如DIST、SemiVT-Surge和ENCORE，这些框架通过利用少量标注数据和动态伪标签增强模型训练，实现了在具有挑战性的手术数据集上的最先进的结果。研究还发布了两个多任务数据集：GynSurg，最大的妇科腹腔镜数据集，和Cataract-1K，最大的白内障手术视频数据集。", "conclusion": "本研究工作为手术视频分析提供了稳健、数据高效且临床可扩展的解决方案，为构建能在手术护理和培训中产生重大影响的普遍适用的AI系统奠定了基础。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10196", "html_url": "https://arxiv.org/abs/2508.10196", "title": "利用卷积神经网络的解释性人工智能技术在肺癌检测中的应用", "title_en": "Explainable AI Technique in Lung Cancer Detection Using Convolutional Neural Networks", "authors": "Nishan Rai,Sujan Khatri,Devendra Risal", "background": "早期检测肺癌对于提高生存率至关重要。本文介绍了一种深度学习框架，用于从胸部计算机断层扫描（CT）图像自动进行肺癌筛查，该框架具有集成的可解释性。该框架使用IQ-OTH/NCCD数据集（1,197次扫描，涵盖正常、良性、恶性三类）进行了评估，旨在提高临床透明度并能够快速准确且可解释地支持肺癌筛查，特别在资源有限的环境中具有应用前景。", "innovation": "本文提出了一种结合解释性的人工智能技术的深度学习框架，用于肺部CT图像的自动筛查。通过使用特定的卷积神经网络（CNN）和三种微调的迁移学习骨干网络（DenseNet121、ResNet152、VGG19），实现了最佳的平衡精度、召回率和F1分数。此外，还采用了Shapley Additive Explanations（SHAP）方法可视化预测证据的贡献，提高了临床透明度和解释性。", "conclusion": "基于CNN的模型结合可解释性方法可以提供快速、准确且可解释的支持，特别适用于资源有限的环境下的肺癌筛查。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10299", "html_url": "https://arxiv.org/abs/2508.10299", "title": "通过知识增强初始化改进联邦适配器调优中新疾病的适应学习", "title_en": "Improving Learning of New Diseases through Knowledge-Enhanced Initialization for Federated Adapter Tuning", "authors": "Danni Peng,Yuan Wang,Kangning Cai,Peiyan Ning,Jiming Xu,Yong Liu,Rick Siow Mong Goh,Qingsong Wei,Huazhu Fu", "background": "在医疗保健领域，联邦学习（FL）是一种广泛应用的框架，可在保持数据隐私的同时促进医疗机构之间的合作。大型基础模型（FMs）展示出强大的能力，通过成本效率高的适配器调整使用FMs在FL中已成为流行的方法。面对快速变化的医疗保健环境，个体客户端需要通过调整适配器快速适应新任务或疾病，同时利用过往经验。", "innovation": "提出了一种新颖的框架——联邦知识增强初始化（FedKEI），该框架利用跨客户端和跨任务的知识转移，生成适用于学习新任务的有信息性的初始值。FedKEI旨在通过服务器上的全局聚类过程泛化知识，并优化跨聚类和群内聚合权重，以个性化知识转移。采用双层优化方案，学习跨客户的群内权重并优化针对每个客户端任务目标的局部群间权重。", "conclusion": "在三种不同模态的基准数据集上进行的详尽实验表明，与最先进的方法相比，FedKEI在适应新疾病方面具有优势。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10307", "html_url": "https://arxiv.org/abs/2508.10307", "title": "使用全局和局部循环表示进行高效图像去噪", "title_en": "Efficient Image Denoising Using Global and Local Circulant Representation", "authors": "Zhaoming Kong,Jiahuan Zhang,Xiaowei Yang", "background": "随着成像设备的进步和每天生成的海量图像数据不断增加，对高效有效的图像去噪提出了越来越高的要求。本文提出了一个称为Haar-tSVD的计算简单去噪算法，旨在探索非局部自相似性先验并将主成分分析（PCA）与在循环表示下的小波变换之间的联系进行利用。", "innovation": "提出了一种基于统一张量奇异值分解（t-SVD）投影和小波变换的去噪方法，能够有效捕捉全局和局部块的关联性，实现了高效且可并行的滤波方法，避免了学习局部基来表示图像块的需要，平衡了去噪速度与性能。此外，还引入了一种基于CNN估计器和特征值分析的自适应噪声估计方案，以增强该方法的鲁棒性和适应性。", "conclusion": "在不同现实世界的去噪任务中的实验验证了Haar-tSVD在去除噪声和保持细节方面的高效性和有效性。所有数据集、代码和结果均在公开链接https://www.example.com/ 上提供。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10298", "html_url": "https://arxiv.org/abs/2508.10298", "title": "SynBrain: 通过概率表示学习增强视觉到fMRI合成", "title_en": "SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning", "authors": "Weijian Mai,Jiamin Wu,Yu Zhu,Zhouheng Yao,Dongzhan Zhou,Andrew F. Luo,Qihao Zheng,Wanli Ouyang,Chunfeng Song", "background": "理解视觉刺激如何转化为皮层反应是计算神经科学中的一个基本挑战。这种视觉到神经的映射是固有的‘一对一’到‘多对一’的关系，相同的视觉输入在不同试验、不同情境和不同受试者之间会产生不同的血流动力学响应。现有的确定性方法在同时处理这种生物变量的同时捕获底层功能性一致性（编码刺激信息）方面存在困难。", "innovation": "我们提出了SynBrain，一种生成框架，模拟视觉语义到神经反应的转化过程，这是一种概率和生物可解释的方式。SynBrain引入了两个关键组件：(i) BrainVAE模型通过概率学习将神经表示视为连续概率分布，并通过视觉语义约束保持功能性一致性；(ii) 语义到神经映射器作为语义传输通道，将视觉语义投影到神经反应流形中，以实现高保真的fMRI合成。实验结果显示SynBrain在受试者特定的视觉到fMRI编码性能上超越了最先进的方法，并且能够有效提高数据受限fMRI到图像解码的性能。", "conclusion": "SynBrain揭示了跨实验和受试者的功能性一致性，合成信号捕捉到由生物神经变异性塑造的可解释模式。源代码将公开发布。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10260", "html_url": "https://arxiv.org/abs/2508.10260", "title": "DINOMotion:使用DINOv2在2D-Cine MRI引导放疗中实现高级鲁棒组织运动跟踪", "title_en": "DINOMotion: advanced robust tissue motion tracking with DINOv2 in 2D-Cine MRI-guided radiotherapy", "authors": "Soorena Salari,Catherine Spino,Laurie-Anne Pharand,Fabienne Lathuiliere,Hassan Rivaz,Silvain Beriault,Yiming Xiao", "background": "2D-Cine MRI引导放疗中精确的组织运动跟踪对确保治疗结果和安全性至关重要。现有的方法在处理大错位时往往面临挑战，且缺乏可解释性。", "innovation": "本文提出了一种基于DINOv2并融合LoRA层的深度学习框架DINOMotion，用于实现鲁棒、高效且可解释的运动跟踪。DINOMotion通过自动检测对应特征点来推导最优图像配准，提升了可解释性。LoRA层的使用减少了可训练参数，提高了训练效率，而DINOv2的强大特征表示提供了对大错位的鲁棒性。不同于基于迭代优化的方法，DINOMotion在测试阶段直接计算图像配准。", "conclusion": "在志愿受试者和患者的数据集上，DINOMotion在估计线性和非线性变换时表现出色，肾、肝和肺的Dice分数分别为92.07%、90.90%和95.23%，相应的Hausdorff距离分别为5.47 mm、8.31 mm和6.72 mm。DINOMotion的处理速度为约30ms，性能上优于现有最先进的方法，特别是在处理大错位方面。这些结果突显了DINOMotion在2D-Cine MRI指导放疗中的实时运动跟踪中的鲁棒性和可解释性潜力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10219", "html_url": "https://arxiv.org/abs/2508.10219", "title": "AI驱动检测和分析被扣押象牙上的手写标记：揭露非法野生动物贸易犯罪网络的工具", "title_en": "AI-Driven Detection and Analysis of Handwriting on Seized Ivory: A Tool to Uncover Criminal Networks in the Illicit Wildlife Trade", "authors": "Will Fein,Ryan J. Horwitz,John E. Brown III,Amit Misra,Felipe Oviedo,Kevin White,Juan M. Lavista Ferres,Samuel K. Wasser", "background": "非洲象群的数量继续因跨国象牙贸易的持续而下降，而犯罪网络依然难以瓦解。通过执法部门查获的象牙通常携带有犯罪分子的相关法医信息，包括DNA证据和犯罪分子留下的手写标记。遗传证据分析已在20年间确定了大象被猎杀的地点，并建立了象牙批次间的联系。尽管遗传证据分析结果非常确凿，但遗传数据分析成本高昂且有时难以获取。然而，手写标记容易拍照，却很少被记录和分析。本文介绍了一种基于人工智能的高效提取和分析被扣押象牙上手写标记的方案，填补了其他数据来源的空白，展示了人工智能在野生动物法医领域的变革潜力，并指出了将笔迹分析纳入打击有组织野生动物犯罪努力中的实际步骤。", "innovation": "本文提出了一个基于人工智能的工作流程，用于提取并分析被扣押象牙上的手写标记，提供了一种新型、可扩展且低成本的法医证据来源。通过对2014-2019年间8次大规模被扣押象牙（共计6085张照片）的研究，使用目标检测模型提取了超过17,000个单独的标记，并使用当今最先进的AI工具进行标记和描述。共识别出184个重复出现的‘签名标记’，并将这些标记在多个扣押中观察到的20个签名标记联系起来，通过涉及两个批次的犯罪分子建立了物证联系。这一方法填补了其他数据来源的空白，揭示了新的追踪犯罪网络的路径。", "conclusion": "本文展示了人工智能在野生动物法医领域的变革潜力，并指出了将笔迹分析整合到打击有组织野生动物犯罪工作中的实际步骤。该研究不仅补充了其他调查技术，还为法医科学家提供了一种新的分析手法，有助于调查和打击跨国野生动物走私犯罪。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10429", "html_url": "https://arxiv.org/abs/2508.10429", "title": "MM-Food-100K: 具有可验证来源的大规模多模态食品智能数据集", "title_en": "MM-Food-100K: A 100,000-Sample Multimodal Food Intelligence Dataset with Verifiable Provenance", "authors": "Yi Dong,Yusuke Muraoka,Scott Shi,Yi Zhang", "background": "研究团队发布了MM-Food-100K，这是一个包含10万个样本的多模态食品智能数据集，具有可验证的来源。该数据集是从1.2万个高质量的食谱图片中精心挑选出来的，涵盖了广泛的食品信息（如菜品名称、创建地等）。这些图片通过持续六周的时间，由超过8.7万名贡献者基于Codatta贡献模型进行贡献，该模型结合了社区贡献与可配置的AI辅助质量检测。每个贡献都链接到一个安全的区块链外账本，完成贡献者的追踪，并计划加入区块链协议以提高透明度。", "innovation": "该数据集通过引入Codatta贡献模型，结合了社区贡献与AI辅助的质量检查，保证了数据的质量和来源的可追溯性。每个提交都连接到一个安全的链外账本以确保追踪，同时计划在区块链上进行改善。通过细调大型的视觉-语言模型（ChatGPT 5，ChatGPT OSS，Qwen-Max）进行基于图像的营养预测，得到了相对于标准基线的一致改进。", "conclusion": "MM-Food-100K数据集对公众免费开放，旨在供学术界使用，同时保持约90%的数据用于可能的商业用途，并计划与其他贡献者共享收益。该研究不仅为多模态数据集的质量控制提供了新的方法，还展示了模型在食品智能预测方面的广泛应用潜力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10416", "html_url": "https://arxiv.org/abs/2508.10416", "title": "CorrectNav: 自修正飞轮赋能视觉-语言-动作导航模型", "title_en": "CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model", "authors": "Zhuoyuan Yu,Yuxing Long,Zihan Yang,Chengyan Zeng,Hongwei Fan,Jiyao Zhang,Hao Dong", "background": "现有的视觉-语言导航模型在执行指令时往往会偏离正确的轨迹，但这些模型缺乏有效的错误修正能力，无法从错误中恢复。因此，需要一种新型的后训练范式来解决这一挑战。", "innovation": "提出了名为Self-correction Flywheel的新型后训练范式。该范式将模型在训练集上的错误轨迹视为有价值的数据来源，开发了一种方法来识别这些错误轨迹中的偏差，并设计了自动生成自我修正数据的技术，这些数据可用于改善感知和行动。通过多次飞轮迭代，显著提升了单目RGB为基础的VLA导航模型CorrectNav的表现。在R2R-CE和RxR-CE基准测试中，CorrectNav分别达到了65.1%和69.3%的成功率，超过了之前的最佳模型8.2%和16.4%。实验证实在室内外环境中，该方法表现出优异的错误修正、动态障碍物回避和长指令跟随能力。", "conclusion": "通过多次飞轮迭代，CorrectNav显著提升了VLA导航模型的表现，尤其在R2R-CE和RxR-CE基准中的成功率超出了之前的最佳模型，展示了在室内外环境中的优越性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10333", "html_url": "https://arxiv.org/abs/2508.10333", "title": "ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver", "title_en": "ReconVLA: Reconstructive Vision-Language-Action Model as Effective Robot Perceiver", "authors": "Wenxuan Song,Ziyang Zhou,Han Zhao,Jiayi Chen,Pengxiang Ding,Haodong Yan,Yuxin Huang,Feilong Tang,Donglin Wang,Haoang Li", "background": "近期，视觉-语言-动作（Vision-Language-Action, VLA）模型的发展使机器人代理能够整合多模态理解与动作执行。然而，我们实验证实了当前的VLA模型在分配视觉注意力到目标区域方面存在困难，视觉注意力往往分散在多个地方。这一问题影响了机器人正确识别目标并进行精准操作的能力。为了引导模型将视觉注意力集中在正确的靶标上，提出了ReconVLA模型，这是一种具备隐式定位范式的重建型VLA模型。该模型旨在通过在视觉输出的条件下重建注视区域，以匹配目标操作物体。此过程促使VLA模型学习细微的特征表示，并准确地分配视觉注意力，从而有效利用特定任务的视觉信息并进行精确操作。为了进一步提高该模型在视觉重建任务中的表现，研究人员还创建了一个大规模的预训练数据集，包含了超过100,000个轨迹和200万个数据样本，这些数据样本来自开源的机器人数据集。这些数据使模型在视觉重建任务上的泛化能力得到了显著提升。在模拟和真实世界的实验中，他们的隐式定位方法表现出优越性，展示了其精确操作和泛化能力的能力。有关项目页面请访问：https://example.com/project-reconvla", "innovation": "提出的ReconVLA模型是一个隐式定位和重建性的VLA模型，通过在视觉输出条件下重建注视区域，以匹配目标操作物体，促使系统学习更细致的特征表示，并准确分配视觉注意力，从而有效利用特定任务的视觉信息。该模型还涉及构建了一个庞大的预训练数据集，包含大量轨迹和数据样本，帮助模型在视觉重建任务上表现出色，增强其泛化能力。", "conclusion": "广泛的实验表明，ReconVLA方法在模拟和真实世界的场景中具有优越性，展示了其在精确操作方面的高效性和泛化的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10490", "html_url": "https://arxiv.org/abs/2508.10490", "title": "关于基于梯度的解释的复杂性-忠实性权衡", "title_en": "On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations", "authors": "Amir Mehrpanah,Matteo Gamba,Kevin Smith,Hossein Azizpour", "background": "ReLU神经网络在视觉数据中广泛应用，但由于具有尖锐的转接，有时依赖于个别像素进行预测，使得梯度基础的解释不再平滑，难以解释。现有方法，如GradCAM，通过生成代理模型来平滑解释，但降低了忠实性。该研究提出了一种统一的谱框架来系统地分析和量化平滑性、忠实性及其在解释中的权衡，并通过这一框架量化并正则化ReLU网络对高频信息的贡献，提供了一种识别这种权衡的原理性方法。该研究分析了基于代理的平滑如何扭曲解释，定义并测量了不同事后方法的“解释缺口”。", "innovation": "该研究提出了一种统一的谱框架来系统地分析和量化梯度基础解释中的平滑性和忠实性权衡。通过该框架，研究量化并正则化了ReLU网络对高频信息的贡献，这是一种识别这种权衡的原理性方法。此外，该研究通过定义并测量不同事后方法的“解释缺口”，揭示了基于代理的平滑对解释的扭曲影响。", "conclusion": "该研究通过理论验证，跨越了不同的模型设计选择、数据集和消融实验，证明了该框架的有效性。这种新的统一框架有助于更好地理解基于梯度的解释的复杂性-忠实性权衡，并为未来的研究提供了新的思路。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10595", "html_url": "https://arxiv.org/abs/2508.10595", "title": "基于梯度的解释方法的光谱特性研究", "title_en": "On Spectral Properties of Gradient-based Explanation Methods", "authors": "Amir Mehrpanah,Erik Englesson,Hossein Azizpour", "background": "深入理解深度网络的行为对提升我们对其结果的信心至关重要。尽管已经有很多工作致力于解释其预测，但研究人员仍然面临可靠性问题，这些问题可以归因于形式化不足。研究者们通过采用新的概率和光谱视角，正式分析解释方法，发现由于使用梯度带来的普遍光谱偏差，揭示了一些实验中发现的常见设计选择，尤其是平方梯度和输入扰动的使用。", "innovation": "研究采用了新的概率和光谱视角来正式分析解释方法，揭示了由于使用梯度而产生的普遍光谱偏差，提出了一种确定标准扰动尺度的机制，以及一种称为SpectralLens的聚合方法来弥补基于我们提出的形式化方法产生的不一致解释。", "conclusion": "通过定量评估验证了理论结果，进一步说明了光照谱分析方法的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10745", "html_url": "https://arxiv.org/abs/2508.10745", "title": "Agentic Design Review System", "title_en": "Agentic Design Review System", "authors": "Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan", "background": "评估图形设计通常需要从对齐、布局、美学和颜色选择等多个方面进行评估。为了从整体上评估设计，通常需要汇总多位专家的反馈意见。因此，提出了一个集成的评估系统，即Agentic设计审查系统(AgenticDRS)，该系统可以由多个代理共同分析设计，并由一个元代理进行协调。", "innovation": "AgenticDRS通过一种新颖的上下文相关示例选择方法（基于图匹配）和一种独特的提示扩展方法，确保每个代理都能理解设计。此外，通过DRS-BENCH基准测试框架与最先进的基线进行彻底的实验证明了AgenticDRS在评估图形设计和提供可行动反馈方面具有显著效果。", "conclusion": "通过全面的实验评估和核心消融实验，AgenticDRS在评估图形设计和生成可行动反馈方面的有效性得到了证明。我们希望这将引起对该实用但未充分探索的研究方向的关注。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10433", "html_url": "https://arxiv.org/abs/2508.10433", "title": "We-Math 2.0: 一个用于激励视觉数学推理的多功能MathBook系统", "title_en": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning", "authors": "Runqi Qiao,Qiuna Tan,Peiqing Yang,Yanzi Wang,Xiaowan Wang,Enhui Wan,Sitong Zhou,Guanting Dong,Yuchen Zeng,Yida Xu,Jie Wang,Chong Sun,Chen Li,Honggang Zhang", "background": "多模态大型语言模型（MLLMs）在各种任务中表现出色，但在复杂的数学推理方面仍存在挑战。现有研究主要集中在数据集构建和方法优化上，往往忽视了全面的知识驱动设计和以模型为中心的数据空间建模两个关键方面。", "innovation": "论文提出We-Math 2.0，这是一个综合系统，结合了结构化的数学知识体系、以模型为中心的数据空间建模和基于强化学习（RL）的训练范式，以全面增强MLLMs的数学推理能力。其主要创新点包括：(1)构建了涵盖491个知识点和1819个基本原则的五级层次体系结构的MathBook知识系统；(2)开发了双重扩展以确保广泛的覆盖和灵活性的MathBook-Standard及其难度三维空间和生成的7个递进展行版本组成的MathBook-Pro挑战数据集；(3)提出了两个阶段的RL框架：冷启动微调和逐进对齐RL，后者通过平均奖励学习和动态数据调度来实现不同难度级别的逐进对齐；(4)引入了一个综合基准MathBookEval，涵盖了所有491个知识点，具有多样化的推理步骤分布。实验结果表明，.MathBook-RL在四个广泛使用的基准中表现与现有基准相当，并且在MathBookEval中表现出强劲的结果，表明在数学推理方面有良好的泛化能力。", "conclusion": "实验结果表明，We-Math 2.0在数学推理能力上的提升显著，尤其是在Gradual Distribution和Learning with Visual Data两个重要的视觉数学推理样例任务中，显著提高了MLLMs的性能。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10605", "html_url": "https://arxiv.org/abs/2508.10605", "title": "DIVA-VQA: 在 UGC 视频质量检测中检测帧间差异", "title_en": "DIVA-VQA: Detecting Inter-frame Variations in UGC Video Quality", "authors": "Xinyi Wang,Angeliki Katsenou,David Bull", "background": "用户生成的内容（视频）的快速增长推动了对无参考（NR）视觉质量评估（VQA）研究的需求。无参考的 VQA 是在没有原始参考的情况下进行大规模视频质量监控的关键组成部分，这在社交媒体和流媒体应用中尤为重要。", "innovation": "本文提出了一种基于帧间变化驱动的空时碎片化的新颖无参考 VQA 模型。通过利用这些帧间差异，该模型逐步在帧、补丁和补丁帧等多级上分析质量敏感区域。该模型集成了帧、补丁残差和残差对齐的补丁帧来有效捕捉全局和局部信息。该模型提取了二维和三维特征以表征这些空时变化。", "conclusion": "在五个 UGC 数据集上进行的实验表明，本文提出的模型在平均等级相关性上排名第二（DIVA-VQA-L 为 0.898，DIVA-VQA-B 为 0.886）。与现有最快方法相比，该方法的性能有所提高，DIVA-VQA-B 在平均运行时复杂性方面排名第二，而 DIVA-VQA-L 排名第三。模型代码和模型已公开提供。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10784", "html_url": "https://arxiv.org/abs/2508.10784", "title": "Algonauts 2025竞赛获胜者的见解", "title_en": "Insights from the Algonauts 2025 Winners", "authors": "Paul S. Scotti,Mihir Tripathy", "background": "Algonauts 2025挑战是一个每两年举行一次的计算神经科学竞赛，团队需要构建模型来预测大脑活动。之前的几届挑战（2019年、2021年和2023年）主要关注静止图像和简短的视频，而2025年的竞赛则使用了长达近80小时的多模态电影作为刺激材料，使领域进一步向前发展。参赛团队需要预测四个参与者观看80多小时天然刺激数据集中1,000个整脑皮层区域的fMRI响应。", "innovation": "2025年的竞赛引入了更长、更复杂的多模态电影作为刺激材料，这在以前的竞赛中是前所未有的。参赛者需要构建能够预测大脑对这些刺激反应的模型，尤其是预测三种从未在训练数据中出现过的电影的数据，进一步检验模型的泛化能力。", "conclusion": "本次竞赛刚刚结束，参赛队伍分别得到了不同的成绩。作为MedARC团队的一员，我们反思了那些有效的策略，展示了当前大脑编码的状况，并推测了未来的发展方向。获胜团队的报告现在已公开，显示了他们在预测大脑活动方面的卓越能力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10649", "html_url": "https://arxiv.org/abs/2508.10649", "title": "地理扩散模型在土地覆盖不透水面变化预测中的应用", "title_en": "Geospatial Diffusion for Land Cover Imperviousness Change Forecasting", "authors": "Debvrat Varshney,Vibhas Vats,Bhartendu Pandey,Christa Brelsford,Philipe Dias", "background": "土地覆盖对多个重要地球系统过程有显著影响。例如，不透水面会加速地表水的径流，减少地下水渗透，进而影响区域水文状况和洪水风险。尽管区域地球系统模型在对未来气候情景下的高分辨率水文和大气过程预测方面越来越有实力，但预测土地利用和覆盖变化（LULC）的能力却落后于这些过程，而后者是风险评估和后果分析的关键输入。本文探讨了通过将LULC预测设定为基于历史和辅助数据源的数据合成问题，利用生成式AI（GenAI）进行土地覆盖变化预测的新范式。", "innovation": "本文提出了一种新的范式，利用生成式AI来预测土地覆盖变化。具体来说，作者训练了一个扩散模型来预测十年内不透水面的变化，并将该模型的性能与其假设没有变化的基准进行了比较。研究表明，在平均分辨率≥0.7×0.7平方公里的情况下，该模型的MAE低于基准值。这意味着生成模型能够从历史数据中捕捉到与未来变化相关的重要时空模式。未来的研究将考虑纳入关于地球物理特性的辅助信息，以及通过驱动变量来模拟不同的情景。", "conclusion": "研究表明，利用生成模型能够捕捉到与未来土地覆盖变化相关的关键时空模式。未来的研究将致力于整合地球物理特性信息，并通过驱动变量来模拟不同情景。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10797", "html_url": "https://arxiv.org/abs/2508.10797", "title": "当专家意见不一致：DSA图像中血管分割注释者差异的表征", "title_en": "When Experts Disagree: Characterizing Annotator Variability for Vessel Segmentation in DSA Images", "authors": "M. Geshvadi,G. So,D.D. Chlorogiannis,C. Galvin,E. Torio,A. Azimi,Y. Tachie-Baffour,N. Haouchine,A. Golby,M. Vangel,W.M. Wells,Y. Epelboym,R. Du,F. Durupinar,S. Frisken", "background": "该研究分析了多名注释者在2D DSA（数字减影血管造影）中对颅内血管的分割差异，以表征和量化分割不确定性。背景信息表明，不同注释者在进行此类医学图像分析时可能会产生显著差异，这影响了血管分割的准确性，需要系统地理解和评估这种差异性的影响，并据此设计更加可靠和准确的自动分割方法或指导额外的注释工作。", "innovation": "创新在于通过系统分析注释者之间的差异，量化和表征分割不确定性。这提供了更深层次的理解，为如何进一步注释以及开发能感知不确定性的自动分割方法提供了指导基础。", "conclusion": "研究通过分析注释者差异，提供了对分割不确定性的定量评估方法，并提出能够利用这些发现来指导未来注释工作和开发智能自动分割技术。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.05202", "html_url": "https://arxiv.org/abs/2401.05202", "title": "基于姿态估计和多种运动特征的奶牛视频自动跛行检测", "title_en": "Video-based automatic lameness detection of dairy cows using pose estimation and multiple locomotion traits", "authors": "Helena Russello,Rik van der Tol,Menno Holzhauer,Eldert J. van Henten,Gert Kootstra", "background": "本研究提出了一种自动化跛行检测系统，该系统利用深度学习图像处理技术提取与跛行相关的多种运动特征。通过T-LEAP姿态估计模型，从户外不同光照条件下的行走奶牛视频中提取了9个关键点的运动轨迹，研究展示了多重运动特征在跛行检测中的重要性，证明这些特征可以提高检测准确性。", "innovation": "本研究创新地采用了深度学习图像处理技术和T-LEAP姿态估计模型，从奶牛视频中自动提取多重运动特征，尤其是通过合并观察者的评分来提高检测的可靠性和准确性。多种运动特征的加入显著提高了跛行检测的分类准确性，尤其是在使用最重要的三个特征时，准确性提高到了79.9%，所有六个特征时，准确性提高到了80.1%。", "conclusion": "本研究证明了使用姿态估计和多重运动特征在奶牛跛行自动检测中的有效性。通过提出的方法，可以显著提高检测的精确度和可靠性，有助于改善奶牛福利和生产效率。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2310.19583", "html_url": "https://arxiv.org/abs/2310.19583", "title": "GC-MVSNet: 多视角、多尺度、几何一致性的多视角立体成像", "title_en": "GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo", "authors": "Vibhas K. Vats,Sripad Joshi,David J. Crandall,Md. Alimoor Reza,Soon-heung Jung", "background": "传统多视角立体成像（MVS）方法主要依赖于光度和几何一致性约束，而基于机器学习的MVS方法仅在后处理阶段检查多个源视图之间的几何一致性。本文介绍了在学习过程中显式鼓励参考视图深度图在多个尺度下的几何一致性的新方法（见图1）。这种方法通过惩罚几何不一致的像素，显著加速了学习过程并减少了训练迭代次数。", "innovation": "该方法通过在学习过程中显式地鼓励参考视图的深度图在多个源视图和尺度下的几何一致性来改进多视角立体成像（MVS）方法。与传统的MVS方法相比，这种方法通过增加几何一致性损失显著加快了学习速度，将训练迭代次数减少了一半。", "conclusion": "通过广泛的实验表明，我们的方法在DTU和BlendedMVS数据集上达到了新的最先进的技术水平，并在Tanks and Temples基准上取得了竞争力的结果。据我们所知，GC-MVSNet是第一个在学习过程中尝试强制执行多视角和多尺度几何一致性的方法。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.05262", "html_url": "https://arxiv.org/abs/2403.05262", "title": "通过惩罚语言先验来去偏置多元模态大型语言模型", "title_en": "Debiasing Multimodal Large Language Models via Penalization of Language Priors", "authors": "YiFan Zhang,Yang Shi,Weichen Yu,Qingsong Wen,Xue Wang,Wenjing Yang,Zhang Zhang,Liang Wang,Rong Jin", "background": "在计算机视觉和自然语言处理领域，多元模态大型语言模型（MLLMs）已经成为不可或缺的工具，能够基于视觉输入生成文本响应。尽管这些模型在发展中取得了显著进步，但在研究中发现一个值得注意的偏见：生成的内容往往更多受到底层大型语言模型（LLMs）先验的驱动，而不是视觉输入。通常，在缺乏相关图像或给定不一致的视觉输入的情况下，MLLMs仍然能够提供自信的答案。", "innovation": "为了纠正这些偏差并重新引导模型的注意力偏向视觉信息，本文提出两种简单的、无需训练的方法。首先，对于诸如分类或多选题回答等任务，提出了一种“事后去偏置”方法，通过仿射校准步骤调整输出分布。这保证了在缺少图像时答案得分的一致性，作为有效正则化技术，减轻LLMs先验的影响。对于更复杂的开放生成任务，进一步提出了“视觉去偏置解码”，通过对比在正确图像和无意义图像上条件下各令牌对数概率来减轻偏差。此外，本文的研究还揭示了MLLMs在不同解码配置下表现出不稳定性。通过系统地探索不同的设置，实现了显著的性能改进，对当前评估实践的公平性提出了质疑。", "conclusion": "全面的实验验证了本文提出的策略在减轻偏差方面的有效性。这些策略不仅有助于减少幻觉，还能促进生成更帮助性和精确的插图。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.06869", "html_url": "https://arxiv.org/abs/2411.06869", "title": "CapeLLM：支持自举的跨类别姿态估计中的多模态大型语言模型", "title_en": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models", "authors": "Junho Kim,Hyungjin Chung,Byung-Hoon Kim", "background": "传统上，类别无关的姿态估计 (CAPE) 依赖于带有标注关键点的支持图像，这是一个繁琐的过程，可能无法完全捕捉不同物体类别之间的必要对应关系。近期研究探索了使用文本查询的方法，利用其增强的稳定性和泛化能力。然而，现有方法通常仍然受限于对支持查询的依赖、无法充分利用预训练大语言模型中嵌入的丰富先验知识，以及由其参数分布假设所造成的局限。", "innovation": "我们提出了 CapeLLM，一种专为 CAPE 设计的多模态大型语言模型 (MLLM)。我们的方法仅使用查询图像和详细的文本描述作为输入来估计类别无关的关键点。此外，我们提出了一种推理机制，进一步增强了对未知关键点的推理过程，能够灵活建模其潜在的空间分布和不确定性，并基于上下文线索进行自适应细化。通过系统性实验，我们在 MP-100 基准上的 1 射和 5 射设置中取得了新最佳表现，显著推进了类别无关姿态估计领域的研究。", "conclusion": "我们的方法在 MP-100 基准上在 1 射和 5 射设置中达到了新的最佳表现，标志着类别无关姿态估计领域的一大进步。代码可在以下链接访问：this https URL"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.03551", "html_url": "https://arxiv.org/abs/2408.03551", "title": "VPOcc: 利用消失点进行3D语义占用预测", "title_en": "VPOcc: Exploiting Vanishing Point for 3D Semantic Occupancy Prediction", "authors": "Junsu Kim,Junhee Lee,Ukcheol Shin,Jean Oh,Kyungdon Joo", "background": "理解3D场景的语义和空间结构对于机器人和自动驾驶汽车的安全导航至关重要，这有助于避免障碍物和准确地规划轨迹。基于相机的3D语义占用预测，即从2D图像推断完整的体素网格，相比3D传感器更有资源高效。然而，这一任务本质上受2D-3D视角不一致的影响，同一大小的物体在3D空间中会在不同距离的2D图像中以不同的尺度出现，这是因为透视投影造成的。因此，研究者们提出了一个名为VPOcc的新框架，该框架利用消失点来缓解2D-3D视角不一致的问题，在像素级和特征级都进行了应对。", "innovation": "VPOcc提出了一个新型框架，通过利用消失点，该框架分别在像素级和特征级上提供了解决2D-3D不一致问题的方法。在像素级上，引入了VPZoomer模块，通过使用基于消失点的Homography变换来对抗透视投影的影响。在特征级上，提出了基于消失点的跨注意力模块（VPCA）来利用更适用于3D空间的2D图像特征。此外，还通过空间体积融合（SVF）模块整合了原始图像和变形图像的两个特征体积，以互补方式弥补缺陷。通过将消失点有效集成到网络中，该框架在SemanticKITTI和SSCBench-KITTI360数据集上实现了IoU和mIoU指标的提升。", "conclusion": "通过有效结合消失点，VPOcc框架在SemanticKITTI和SSCBench-KITTI360数据集上分别在IoU和mIoU指标上取得了提升。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.11315", "html_url": "https://arxiv.org/abs/2409.11315", "title": "MinD-3D++：基于高质纹理网格生成和全面数据集推进的fMRI导向三维重建", "title_en": "MinD-3D++: Advancing fMRI-Based 3D Reconstruction with High-Quality Textured Mesh Generation and a Comprehensive Dataset", "authors": "Jianxiong Gao,Yanwei Fu,Yuqian Fu,Yun Wang,Xuelin Qian,Jianfeng Feng", "background": "三维视觉从功能性磁共振成像(fMRI)数据重构的应用在认知神经科学和计算机视觉领域取得了显著进展，但目前缺乏高质量的数据集。为此，本文提出了功能磁共振成像三维数据集(fMRI-3D)，结合了来自15个参与者的数据共包含4,768个3D对象。该数据集由fMRI-Shape（以前介绍过）和fMRI-Objaverse（本文首次提出）组成，大大增强了数据集的多样性和应用潜力。", "innovation": "本文提出了MinD-3D++框架，首次利用fMRI信号生成具有详细纹理的三维纹理网格。通过设计语义、结构和纹理三个层面的评估指标，本文不仅建立了新的基准，而且实现了在新的领域外表现评估，并分析了重建的3D fMRI数据在视觉感兴趣区域的归因。这项研究为研究人类大脑处理三维视觉信息的方式提供了全新的视角，有着重要的理论和实际应用价值。", "conclusion": "本文通过提出fMRI-3D数据集和MinD-3D++框架，为利用fMRI进行高质纹理网格生成提供了新的可能性。我们展示了MinD-3D++不仅能够以高语义和空间精度重建3D对象，还能深入探索大脑处理三维视觉信息的机制。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.03910", "html_url": "https://arxiv.org/abs/2412.03910", "title": "DGNS: 基于可变形高斯散斑和动态神经曲面的单目动态三维重建", "title_en": "DGNS: Deformable Gaussian Splatting and Dynamic Neural Surface for Monocular Dynamic 3D Reconstruction", "authors": "Xuesong Li,Jinguang Tong,Jie Hong,Vivien Rolland,Lars Petersson", "background": "单目视频的动态场景重建对于实际应用至关重要。现有的技术需要同时解决动态的新型视角合成和3D几何重建这一挑战性问题。", "innovation": "引入了DGNS框架，融合了可变形高斯散斑和动态神经曲面两种方法，实现了两种任务的同时优化。深度图模块指导光线采样以提升处理速度，并在动态神经曲面模块中提供深度监督以改进几何重建。此外，还提出了一种深度筛选方法以进一步细化深度监督。", "conclusion": "在公开数据集上的大量实验表明，DGNS在三维重建方面达到了最先进的性能，并在新型视角合成方面取得了竞争力的结果。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02287", "html_url": "https://arxiv.org/abs/2412.02287", "title": "通过结构特征和CLIP指导提高3D生成中的视角一致性", "title_en": "Improving Viewpoint Consistency in 3D Generation via Structure Feature and CLIP Guidance", "authors": "Qing Zhang,Jinguang Tong,Jing Zhang,Jie Hong,Xuesong Li", "background": "尽管近年来在文本生成3D内容的技术方面取得了重大进展，但现有方法通常存在几何不一致性的问题，通常被称为‘Janus问题’。这个论文指出了Janus问题的根本原因是在扩散模型中存在视角生成偏差，造成了实际生成的视角与优化3D模型所需的预期视角之间存在显著差距。", "innovation": "本文提出了一个无需调优的方案，称为注意力和CLIP指导机制（ACG）。ACG机制通过自适应控制交叉注意力图来增强所需视角，利用基于CLIP的视图-文本相似性来过滤错误的视角，并采用从粗到细的优化策略与分阶段提示逐步细化3D生成。", "conclusion": "大量的实验表明，该方法显著减少了Janus问题，且不会牺牲生成速度，ACG成为一个高效且即插即用的组件，应用于现有的文本生成3D框架中。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.13378", "html_url": "https://arxiv.org/abs/2411.13378", "title": "Quantum-Brain: 量子启发型神经网络方法在视觉-大脑理解中的应用", "title_en": "Quantum-Brain: Quantum-Inspired Neural Network Approach to Vision-Brain Understanding", "authors": "Hoang-Quan Nguyen,Xuan-Bac Nguyen,Hugh Churchill,Arabinda Kumar Choudhary,Pawan Sinha,Samee U. Khan,Khoa Luu", "background": "视觉-大脑理解旨在从人类感知中提取大脑信号的语义信息。现有的深度学习方法通常是在传统学习框架中引入，缺乏学习大脑区域之间连接性的能力。量子计算机理论提供了一种新的深度学习模型设计范式，受大脑信号连接性和量子计算中的纠缠性质的启发，提出了一种名为Quantum-Brain的新颖量子启发神经网络方法以解决视觉-大脑理解问题。通过利用量子计算中的隔区模块学习脑区影响，相位调节模块校准脑信号值，以及测量类似投影模块将连接性信息从希尔伯特空间呈现到特征空间，这种方法能够学习找到fMRI体素之间的连接性，增强从人类感知中获得的语义信息。实验结果显示该方法在自然场景数据集基准上的效果显著，图像检索任务中Top-1准确率为95.1%，脑成像检索任务中为95.6%，fMRI到图像重建任务中的Inception评分为95.3%。该提出的量子启发网络为通过量子计算理论解决视觉-大脑问题提供了潜在范式方法。", "innovation": "提出了Quantum-Brain方法，一种量子启发神经网络。通过在一个新的隔区控制模块中学习脑区影响，在相位调节模块中校准脑信号值，并引入一个测量和投影模将连接性信息呈现到特征空间，解决了传统深度学习方法中缺乏大脑连接性学习的问题。", "conclusion": "基于自然场景数据集的实验结果表明，提出的Quantum-Brain方法的有效性显著，特别是在图像和脑成像检索任务中，Top-1准确率分别达到95.1%和95.6%，以及fMRI到图像重构任务中的Inception评分为95.3%。量子启发网络为通过量子计算理论解决视觉-大脑理解问题提供了潜在范式。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.00578", "html_url": "https://arxiv.org/abs/2412.00578", "title": "Speedy-Splat：使用稀疏像素和稀疏原语的快速3D高斯点绘制", "title_en": "Speedy-Splat: Fast 3D Gaussian Splatting with Sparse Pixels and Sparse Primitives", "authors": "Alex Hanson,Allen Tu,Geng Lin,Vasu Singla,Matthias Zwicker,Tom Goldstein", "background": "3D Gaussian Splatting (3D-GS) 是一种最近的3D场景重建技术，通过将场景建模为不同可微的3D高斯参数点云，使其能够以实时光线追踪速度渲染出新的视角。然而，其渲染速度和模型大小仍然存在瓶颈，特别是在资源受限的环境中更为明显。", "innovation": "本文识别并解决了3D-GS中的两个关键效率问题，从而显著提高了渲染速度。两项改进还带来了减少了模型大小和训练时间的附加好处。首先，优化渲染管道以精确定位场景中的高斯体，从而在不降低视觉保真度的情况下提高渲染速度。其次，引入了一种新的剪枝技术，并将其集成到训练管道中，大大减少了模型大小、训练时间和进一步提高了渲染速度。我们的Speedy-Splat方法结合了这些技术，在来自Mip-NeRF 360、Tanks & Temples和Deep Blending数据集的场景中，将平均渲染速度加速了六倍多（6.71倍）", "conclusion": "我们的Speedy-Splat方法结合这些技术，使平均渲染速度在Mip-NeRF 360、Tanks & Temples和Deep Blending数据集中的场景上得到了大幅提高，高达6.71倍的速度提升。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.14521", "html_url": "https://arxiv.org/abs/2411.14521", "title": "MyTimeMachine：个性化面部年龄变换", "title_en": "MyTimeMachine: Personalized Facial Age Transformation", "authors": "Luchao Qi,Jiaye Wu,Bang Gong,Annie N. Wang,David W. Jacobs,Roni Sengupta", "background": "面部老化是一个复杂的过程，受到性别、种族、生活方式等多种因素的影响，预测个体老化极具挑战性。现有技术虽然能够生成逼真和合理的老化结果，但老化后的图像往往不符合目标年龄的特征，需要个性化定制。在一些虚拟老化实际应用中，如电影和电视节目的视觉特效（VFX），用户在短时间内（20到40年）有个人照片集，可以帮助个性化调整。然而，直接使用这些个人照片集对全局老化方法进行个性化调整往往失败。因此，本文提出MyTimeMachine（MyTM），结合全局老化先验和少量个人照片集（最少50张图片）来学习个性化年龄变换方法。我们引入了一种新颖的适配网络，结合个性化老化特征和全局老化特征，并使用StyleGAN2生成重老化图像。此外，我们还引入了三种损失函数，分别用于个性化、外推正则化和自适应w-范数正则化。该方法可以扩展至视频，实现高质量、具有身份保持性和时间一致性的真实老化效果，证明了其优于现有方法的优势。", "innovation": "本文提出的MyTimeMachine（MyTM）方法通过结合全局老化先验和少量个人照片集，来学习个性化的年龄变换。我们引入了一种新颖的适配网络，结合个性化老化特征和全局老化特征，并使用StyleGAN2生成重老化图像。此外，我们还引入了个性化损失、外推正则化和自适应w-范数正则化这三种损失函数，以个性化适配网络。该方法可扩展至视频应用，实现了高质量且具有时间一致性的老化效果，相较于现有方法具有显著优势。", "conclusion": "我们的方法能够实现高质量、保持身份一致性和时间一致性的老化效果，显著优于现有技术。它通过结合全局老化先验和个性化的个人照片集，提高了面部老化预测的准确性和个性化程度。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.04464", "html_url": "https://arxiv.org/abs/2412.04464", "title": "DualPM: 双目标定-规范点图用于3D形状和姿态重建", "title_en": "DualPM: Dual Posed-Canonical Point Maps for 3D Shape and Pose Reconstruction", "authors": "Ben Kaye,Tomas Jakab,Shangzhe Wu,Christian Rupprecht,Andrea Vedaldi", "background": "数据表示的选择是深度学习在几何任务中取得成功的关键因素。例如，DUSt3R最近引入了视线不变点图的概念，将深度预测一般化，并展示了所有静态场景的3D重建问题都可以简化为预测这种点图。该论文在此基础上进一步开发了一个类似的概念，用于解决非常不同的问题：可变形物体的3D形状和姿态重建。研究者提出了一种新的方法，即双目标定-规范点图（Dual Point Maps, DualPM），并通过实验证明了该表示可以作为深度网络的良好目标来预测3D重建与3D姿态估计。此外，该论文还展示了如何利用合成3D数据训练DualPM，实现对真实图像的有效泛化，从而在3D分析和重建方面取得显著进步。", "innovation": "提出了一种新的方法，即双目标定-规范点图（Dual Point Maps, DualPM），采用这种点图能够将3D重建和3D姿态估计简化为预测DualPMs。进一步，证明了采用DualPMs训练的是有望实现对真实图像有效泛化的模型，且能在同一或两类模型上进行合成3D数据的训练，展现出显著的进步。", "conclusion": "研究表明，通过使用双目标定-规范点图（Dual Point Maps, DualPM），可以显著提高可变形物体的3D分析和重建的性能，并且该方法能够在合成3D数据上直接训练，然后应用于实际场景，展现出鲁棒性和有效性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.06534", "html_url": "https://arxiv.org/abs/2412.06534", "title": "理解基于变换器的视觉模型通过反转", "title_en": "Understanding Transformer-based Vision Models through Inversion", "authors": "Jan Rathjens,Shirin Reyhanian,David Kappel,Laurenz Wiskott", "background": "理解深度神经网络背后的机制仍然是机器学习和计算机视觉领域的一项基本挑战。一种有前景但尚未充分探索的方法是特征反转，它尝试通过训练好的逆向神经网络从中间表示恢复图像。本研究旨在重新审视特征反转，并引入了一种新的模块化变体，使其能够更有效地应用于此技术。我们展示了如何系统地将该方法应用于大尺寸的基于变换器的视觉模型，如检测变换器和视觉变换器，并如何以有意义的方式对重建图像进行定性解释。我们还对该方法进行了定量评估，从而揭示了变换器架构中表示图像特征的基础机制。我们的分析揭示了这些模型如何编码上下文形状和图像细节、其层之间的关联以及其面对颜色扰动的鲁棒性。这些发现有助于更深入地理解基于变换器的视觉模型及其内部表示。用于再现我们实验的代码可在如下网址查找：this http URL", "innovation": "本研究引入了一种新的模块化特征反转方法，使其能够更有效地应用于大型基于变换器的视觉模型。该方法被系统地应用到检测变换器和视觉变换器中，并通过重建图像提供了有意义的解释。此外，对方法进行了定量评估，揭示了模型如何编码特征以及其鲁棒性。", "conclusion": "这些发现有助于更深入地理解基于变换器的视觉模型及其内部表示。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04376", "html_url": "https://arxiv.org/abs/2503.04376", "title": "MIDAS: 利用暗知识建模真实场景中立体匹配的地面真相分布", "title_en": "MIDAS: Modeling Ground-Truth Distributions with Dark Knowledge for Domain Generalized Stereo Matching", "authors": "Peng Xu,Zhiyu Xiang,Jingyun Fu,Tianyu Pu,Hanzhi Zhong,Eryun Liu", "background": "现有领域泛化立体匹配方法虽然取得了显著进展，但仍具有领域特定偏好，难以在复杂多变的真实场景中进行实际应用。", "innovation": "本文提出了一种新的方法MIDAS，通过从预先训练好的网络中提取暗知识来建模边缘和非边缘区域的多模态地面真相分布，同时采用网络集成区分客观知识和偏差知识，并将目标知识与原始视差标签共同建模以提供细粒度的监督，从而提高现有网络的泛化能力。", "conclusion": "实验结果表明，MIDAS方法具有普遍适用性，能够有效提升现有网络的泛化性能，在KITTI 2015和2012数据集上实现了最先进的泛化性能，并在四个流行的现实世界数据集上全面超越现有方法。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.14317", "html_url": "https://arxiv.org/abs/2501.14317", "title": "Nautilus: 知识敏感的自编码器用于可扩展的网格生成", "title_en": "Nautilus: Locality-aware Autoencoder for Scalable Mesh Generation", "authors": "Yuxuan Wang,Xuanyu Yi,Haohan Weng,Qingshan Xu,Xiaokang Wei,Xianghui Yang,Chunchao Guo,Long Chen,Hanwang Zhang", "background": "三角网格是3D应用的基础，能够高效修改和光栅化，同时保持与标准渲染管道的兼容性。然而，当前的自动网格生成方法通常依赖于中间表示，缺乏网格所固有的连续表面质量。将这些表示转换为网格会产生密集且次优的输出。尽管最近的自回归方法在直接建模网格顶点和面方面显示出潜力，但它们在面计数、可扩展性和结构保真度方面受到限制。", "innovation": "我们提出了一种名为Nautilus的局部感知自编码器，用于艺术家风格的网格生成，通过利用流形网格的局部属性来实现结构保真度和高效表示。这种方法引入了一种新颖的分词算法，保留了面邻近关系并通过局部共享顶点和边压缩序列长度，使生成的网格规模达到前所未有的5,000个面。此外，我们还开发了一种双流点调节器，提供了多尺度几何指导，通过捕捉细粒度的几何特征确保全局一致性与局部结构保真度。", "conclusion": "广泛的实验表明，Nautilus在保真度和可扩展性方面远超当今最先进的方法。项目页面位于 this https URL."}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.19160", "html_url": "https://arxiv.org/abs/2412.19160", "title": "具有相位只读交叉注意力的轻量级变换器在光照不变的生物特征认证中的应用", "title_en": "A Lightweight Transformer with Phase-Only Cross-Attention for Illumination-Invariant Biometric Authentication", "authors": "Arun K. Sharma,Shubhobrata Bhattacharya,Motahar Reza,Bishakh Bhattacharya", "background": "传统的生物识别系统由于各种不可避免的因素遇到了显著的挑战，例如基于面部识别的生物识别系统中的面部口罩穿戴问题，以及基于指纹的生物识别系统中的卫生问题。这些因素使得传统的生物识别方法在实际应用中受到了限制，尤其是在公共健康措施要求下，人们对物理接触的担忧进一步增加了对非接触式生物识别技术的需求。", "innovation": "本文提出了一种新的轻量级视觉变压器（POC-ViT），它采用了额头和面部周围眼周区域的双重生物特征，即使在佩戴口罩的情况下也能识别，且无需物理接触即可工作，为传统的生物识别系统提供了新的替代方案。POC-ViT框架设计用于处理两个生物特征，并捕捉相对结构模式之间的相互依赖性。每个通道都使用相位只读相关（POC）的交叉注意力，提取两个特征的独立和相关的结构模式。跨注意力的计算利用POC提取空间特征的相位相关性，使系统对分辨率、强度和光照变化具有鲁棒性。该轻量级模型适合边缘设备部署。实验结果表明，使用Forehead Subcutaneous Vein Pattern和Periocular Biometric Pattern数据库，POC-ViT框架在使用双重生物特征时的分类准确率达到98.8%，显著优于现有方法。", "conclusion": "本文提出了一种全新的轻量级视觉变压器（POC-ViT），通过采用额头和眼周区域的双重生物特征，能够在面部佩戴口罩和不需要物理接触的情况下进行有效的生物特征识别，系统具有高度的鲁棒性，并且能够适应边缘设备的部署。实验结果证明了这个框架在光照不变的生物特征认证中的优越性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.15119", "html_url": "https://arxiv.org/abs/2501.15119", "title": "利用运动估计提高Bayer域计算机视觉效率", "title_en": "Leveraging Motion Estimation for Efficient Bayer-Domain Computer Vision", "authors": "Haichao Wang,Xinyue Xi,Jiangtao Wen,Yuxing Han", "background": "现有的计算机视觉处理管道使用具有Bayer模式像素信息的图像传感器来获取视觉信息。随后通过图像信号处理器(ISP)将Bayer像素数据转换为RGB，并通过视频卷积网络(VCN)进行逐帧处理。ISP和VCN计算成本高、功耗大且延迟长。", "innovation": "本文提出了一种新颖的框架，该框架消除了ISP并利用运动估计直接在Bayer域中加速视频视图任务。引入了基于运动估计的视频卷积(MEVC)，将滑动窗口运动估计整合到每个卷积层中，实现了预测和基于残差的修正，降低了帧间冗余计算。该设计弥合了块基运动估计与空间卷积之间的结构差距，实现了准确且低成本的处理。", "conclusion": "端到端管道支持原生Bayer图像输入，实现了超过70%的FLOPs减少，同时在视频语义分割、深度估计和目标检测等基准测试中保持了轻微的精度下降，使用了合成的Bayer转换图像和实际的Bayer视频数据集。该框架适用于基于卷积的模型，并首次实现了运动估计的有效重用，直接从原始传感器数据加速视频计算机视觉。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.00372", "html_url": "https://arxiv.org/abs/2502.00372", "title": "NAVER: 一种具有显式逻辑推理的神经符号组合自动机用于视觉定位", "title_en": "NAVER: A Neuro-Symbolic Compositional Automaton for Visual Grounding with Explicit Logic Reasoning", "authors": "Zhixi Cai,Fucai Ke,Simindokht Jahangard,Maria Garcia de la Banda,Reza Haffari,Peter J. Stuckey,Hamid Rezatofighi", "background": "视觉定位（VG）任务，如引用表达检测和分割任务，对于将视觉实体与上下文关联起来至关重要，尤其是在需要详细查询解释的复杂推理任务中。近年来，大语言模型（LLMs）和视觉语言模型（VLMs）的进步提高了视觉理解、上下文理解和推理的能力。这些方法主要分为端到端和组合方法，后者提供了更多的灵活性。尽管组合方法能够结合LLMs和基础模型并表现出色，但在基于语言逻辑表示的复杂推理方面仍存在局限性。因此，本文探讨了超越基础感知的VG任务，并介绍一种名为NAVER的方法，即一种神经符号组合自动机，该自动机在有限状态自动机中引入了显式的概率逻辑推理，并配备了自我纠正机制，从而通过显式逻辑推理改进了推理的鲁棒性和可解释性。", "innovation": "NAVER是一种组合视觉定位方法，它在有限状态自动机中结合了显式的概率逻辑推理，并包含自我纠正机制。这种方法提高了基于显式逻辑推理的推理的鲁棒性和可解释性。NAVER的方法相比于最近的端到端和组合基线能够达到最佳性能。", "conclusion": "NAVER通过结合显式的概率逻辑推理和自我纠正机制，显著改善了视觉推理任务中的鲁棒性和可解释性。实验结果显示，NAVER在视觉定位任务上达到了最先进的性能。相关代码可以在指定链接中获取。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07516", "html_url": "https://arxiv.org/abs/2503.07516", "title": "Just Functioning as a Hook for Two-Stage Referring Multi-Object Tracking", "title_en": "Just Functioning as a Hook for Two-Stage Referring Multi-Object Tracking", "authors": "Weize Li,Yunhao Du,Qixiang Yin,Zhicheng Zhao,Fei Su,Daqi Liu", "background": "Referring Multi-Object Tracking (RMOT)的目标是在视频中通过自然语言表达来定位目标轨迹。尽管近期取得了进展，但当前RMOT中的跟踪与引用两个子任务之间的内在关系尚未充分研究。现有的两阶段Referring-by-Tracking（RBT）框架在子任务交互建模不足和对语义对齐模块的刚性依赖方面存在根本限制（如CLIP）.", "innovation": "本文提出了一种新颖的两阶段RBT框架，名为JustHook。该框架首先设计了一个名为Hook的模块来重新定义子任务之间的联系。Hook模块基于特征级网格采样构建，实现上下文感知的目标特征提取。此外，引入了Parallel Combined Decoder (PCD)，学习在一个联合特征空间中，而不是依赖预定义的跨模态嵌入。该设计提高了解释性和模块性，并显著提高了泛化能力。实验表明，JustHook在Refer-KITTI、Refer-KITTI-V2和Refer-Dance数据集上达到了最先进的性能，在Refer-KITTI-V2上改善了HOTA分数6.9%，同时保持高效性。代码将尽快发布.", "conclusion": "实验结果表明，JustHook在参照KITTI（Refer-KITTI）、参照KITTI v2（Refer-KITTI-V2）以及参照舞蹈（Refer-Dance）数据集上均表现出优越的性能，并在Refer-KITTI-V2数据集上将HOTA提高了6.9%，且保持了高效性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.03096", "html_url": "https://arxiv.org/abs/2504.03096", "title": "扩展开放词汇短语动作检测", "title_en": "Scaling Open-Vocabulary Action Detection", "authors": "Zhen Hao Sia,Yogesh Singh Rawat", "background": "现有的动作检测方法大多局限于封闭集场景，依赖于复杂的、参数量大的架构。要在开放词汇设置下扩展这些模型，面临两个关键挑战：缺乏包含多种动作类别的大规模数据集以进行稳健训练，以及需要对预训练的视觉-语言对比模型进行参数密集型调整，转换为检测模型，这增加了因为训练非预训练参数而过拟合基动作类别的风险。", "innovation": "引入了一个仅编码器的多模态模型，减少了视频动作检测对参数密集型添加的依赖；提出了一个简单的弱监督训练策略，利用现有的封闭集动作检测数据集进行预训练；设计了一个新的基准测试，不使用封闭集动作检测数据集进行训练，而是对其进行评估，展示了未来工作的基准结果。", "conclusion": "提出了一个新的基准测试，不依赖于训练数据集，这为未来的研究提供了新的基线；代码可以在以下网址获得：[这个链接]。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.24381", "html_url": "https://arxiv.org/abs/2503.24381", "title": "UniOcc: 自动驾驶中的占用预测和预报统一基准", "title_en": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving", "authors": "Yuping Wang,Xiangyu Huang,Xiaokang Sun,Mingxuan Yan,Shuo Xing,Zhengzhong Tu,Jiachen Li", "background": "本文介绍了UniOcc，这是一个综合统一的基准和工具包，用于预测未来占用（基于历史信息）和当前帧占用（从摄像头图像预测占用）。UniOcc将多个真实世界数据集（如nuScenes、Waymo）和高保真驾驶模拟器（如CARLA、OpenCOOD）的数据统一起来，提供2D/3D占用标签，并标注创新的逐体素流信息。由于现有研究依赖于次优的伪标签进行评估，而UniOcc引入了新的评估指标，不依赖于真实标签，从而能够从多个方面对占用质量进行稳健评估。通过在先进模型上的广泛实验，表明大规模、多样化的训练数据和显式流信息显著提升了占用预测和预报性能。", "innovation": "UniOcc统一了多种真实世界数据集和高保真驾驶模拟器的数据，提供了2D/3D占用标签，并标注创新的逐体素流信息。引入了新的评估指标，使评估指标不依赖于真实标签，能够从多个方面评估占用质量。展示了大规模、多样化的训练数据和显式流信息显著提高了占用预测和预测性能。这些创新为自动驾驶领域提供了新的评估基准和工具包。", "conclusion": "通过对先进模型的广泛实验，证实了大规模、多样化的训练数据和显式流信息对占用预测和预报性能有显著提升。同时，新的评估指标使评估更加稳健。提供的数据和代码提高了研究的透明度和可重复性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.08064", "html_url": "https://arxiv.org/abs/2503.08064", "title": "多模态连续学习", "title_en": "Continual Learning for Multiple Modalities", "authors": "Hyundong Jin,Eunwoo Kim", "background": "连续学习旨在学习按时间序列观察到的任务的知识，同时减轻遗忘先前学习的知识。现有方法设计用于随着时间学习单一模态（例如，图像），这限制了它们在涉及多个模态的场景中的适用性。本文旨在解决这个问题，提出一个新的连续学习框架，可以处理多种模态（图像、视频、音频、深度和文本）。通过利用文字的丰富语义信息，以期同时训练模型来对齐各种模态。然而，这增加了以前学习的知识被遗忘的风险，特别是由于任务间输入特性之间存在差异。为缓解模态间的知识覆盖问题，本文提出了一种框架，可以在自我调节学得表示的变化的同时融入相关跨模态信息，从而逐步将新知识整合到跨模态保留的信息中，同时减少跨模态干扰，通过根据其相关性选择性地整合先前遇到的模态的知识。此外，还引入了重新调整模态嵌入的策略，有效解决模态间偏斜对齐问题。", "innovation": "本文提出了一种新的连续学习框架，可以处理多种模态（图像、视频、音频、深度和文本），通过利用文本的丰富语义信息对齐各种模态。为缓解模态间的知识覆盖问题，框架自我调节学得表示的变化，逐步将新知识整合到跨模态保留的信息中，并减少跨模态干扰。同时，通过根据相关性选择性地整合之前遇到的模态知识，提出了一种策略来重新调整模态嵌入，有效解决模态间偏斜对齐问题。", "conclusion": "通过使用具有不同模态的多个数据集进行广泛测试，本文的方法在各种连续学习场景中都优于现有方法，无论是否提供了模态身份。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.15485", "html_url": "https://arxiv.org/abs/2504.15485", "title": "CAPTURe：通过隐蔽物体计数评估视觉语言模型的空间推理能力", "title_en": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting", "authors": "Atin Pothiraj,Elias Stengel-Eskin,Jaemin Cho,Mohit Bansal", "background": "视觉场景的理解中识别和推理被遮挡（部分或完全隐藏）的对象至关重要，因为在现实环境中遮挡现象频繁发生，对空间理解造成障碍。为了测试模型在多种遮挡条件下推理的能力，引入了一个新的任务，即Counting Amodally for Patterns Through Unseen REgions (CAPTURe)，该任务要求模型通过推断遮挡物后面图案的延续来计数不同图案的物体。这个任务结合了识别视觉模式和推理，为评估视觉-语言模型（VLMs）提供了一个有效的测试平台，考察它们是否理解被遮挡的模式，并具备空间理解能力。", "innovation": "引入了一个新的评估任务CAPTURe，要求模型通过推断遮挡物后面物的延续来计数排列在特定模式中的物体，从而测试模型的空间推理和视觉-语言理解能力。", "conclusion": "评估结果显示，尽管人类在CAPTURe任务上的错误率很低，但即使是最强的视觉语言模型（如GPT-4o）在处理遮挡时也很难计数。提供遮挡物体位置的辅助信息可以提高模型的表现，表明模型的错误来自于处理遮挡的能力不足以及难以在图像中计数。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.22793", "html_url": "https://arxiv.org/abs/2505.22793", "title": "视觉-语言模型的文化胜任力评估", "title_en": "Evaluation of Cultural Competence of Vision-Language Models", "authors": "Srishti Yadav,Lauren Tilton,Maria Antoniak,Taylor Arnold,Jiaang Li,Siddhesh Milind Pawar,Antonia Karamolegkou,Stella Frank,Zhaochong An,Negar Rostamzadeh,Daniel Hershcovich,Serge Belongie,Ekaterina Shutova", "background": "现代视觉-语言模型（VLMs）在文化胜任力评估和基准测试中常常表现不佳。由于基于VLMs的多样化应用，人们重新对它们如何编码文化细微差别产生了兴趣。虽然在这一问题的某些方面已经有了研究，但仍然缺乏一个系统的方法来识别和标注VLMs中图像中的复杂的文化维度。", "innovation": "本文借鉴了视觉文化研究（文化研究、符号学和视觉研究）的基础方法，并提出了五个框架，以构建一个更完善的VLMs文化胜任力分析体系。", "conclusion": "文章认为，为了更好地评估VLMs的文化胜任力，必须全面考虑这些文化维度。这些文化维度是视觉文化研究中提出的五个框架所涵盖的内容。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.21706", "html_url": "https://arxiv.org/abs/2504.21706", "title": "视觉变换器在精准农业中的综述", "title_en": "Vision Transformers in Precision Agriculture: A Comprehensive Survey", "authors": "Saber Mehdipour,Seyed Abolghasem Mirroshandel,Seyed Amirhossein Tabatabaei", "background": "检测植物疾病在现代农业中至关重要，因为它有助于维持作物健康和增加产量。传统方法虽然仍然有价值，但往往依赖于手工检查或传统的机器学习技术，这些方法在可扩展性和准确性方面存在局限性。最近，视觉变换器（ViTs）作为一种有前途的选择出现，与传统的卷积神经网络（CNNs）相比，ViTs在处理长距离依赖关系和可扩展性方面具有优势。本文综述了ViTs在精准农业中的应用，涵盖了多个任务。", "innovation": "本文对ViTs在精准农业中的应用进行了全面综述，涵盖了从自然语言处理（NLP）到计算机视觉的架构转移，深入讨论了传统模型限制的缓解方法，包括对比卷积神经网络的诱导偏差，以及ViTs在这些任务中的优势。此外，对最近的文献进行了全面回顾，重点介绍了方法、数据集和性能指标，还进行了卷积神经网络和ViTs的对比分析，以及混合模型和性能提升的评审。", "conclusion": "本文还讨论了技术挑战，如数据需求、计算需求和模型可解释性，并提出了解决方案。最后，概述了未来的研究方向和技术进步，这些能够进一步支持ViTs在实际农业场景中的整合。本文旨在为从业者和研究人员提供对ViTs如何有望改变智能和精准农业的更深入理解。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13219", "html_url": "https://arxiv.org/abs/2505.13219", "title": "PiT: 进步扩散变换器", "title_en": "PiT: Progressive Diffusion Transformer", "authors": "Jiafu Wu,Yabiao Wang,Jian Li,Jinlong Peng,Yun Cao,Chengjie Wang,Jiangning Zhang", "background": "扩散变换器（DiTs）通过变压器架构在图像生成中取得了显著的性能。传统的DiTs通过堆叠局部等向性的全局建模变压器构建，这带来了显著的二次计算成本。然而，通过实证分析，发现DiTs并没有像以前认为的那样依赖全局信息，大多数层在全局计算上表现出明显的冗余性。传统的注意机制在低频惰性方面存在问题，限制了它们的效率。", "innovation": "本文提出了假定移动窗口注意力（PSWA），它从根本上缓解了全局注意冗余。PSWA通过窗口注意力实现适度的全局-局部信息。此外，还引入了高效率桥梁支路来模拟移动窗口操作，增强跨窗口连接并丰富高频信息。进一步提出了渐进覆盖通道分配（PCCA）策略，该策略在不增加计算成本的情况下捕捉高阶注意。", "conclusion": "基于这些创新，提出了一系列假定渐进扩散变换器（PiT）。广泛的实验显示了其优越的性能；例如，提出的PiT-L在使用更少计算资源的情况下，相较于DiT-XL/2实现了54%的FID改进。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.08561", "html_url": "https://arxiv.org/abs/2505.08561", "title": "强化学习与掩蔽视频建模的结合：基于轨迹的自适应 Token 选择", "title_en": "Reinforcement Learning meets Masked Video Modeling : Trajectory-Guided Adaptive Token Selection", "authors": "Ayush K. Rai,Kyle Min,Tarun Krishna,Feiyan Hu,Alan F. Smeaton,Noel E. O'Connor", "background": "掩蔽视频建模（MVM）已经成为视觉基础模型预训练策略的有效方法，其中模型使用可见令牌的信息来重建被掩蔽的时空令牌。然而，选择合适的掩蔽策略是一个关键挑战。先前的研究探索了预定义的掩蔽技术，包括随机和管状掩蔽，以及利用关键运动先验、光学流和外部预训练模型的语义线索的方法。", "innovation": "本文提出了一种新颖且可泛化的轨迹感知自适应令牌采样（TATS），该方法建模令牌的运动动态，无缝地集成到掩蔽自编码器（MAE）框架中，以选择视频中的运动为中心的令牌。此外，提出了一种统一的训练策略，允许从头开始通过强化策略优化（PPO）同时优化MAE和TATS。", "conclusion": "实验结果表明，与现有的顶尖方法相比，我们的模型可以在视频动作识别下游任务中实现更为激进的掩蔽而不影响性能，并且预训练在内存效率方面得到保证。在四个基准测试（Something-Something v2，Kinetics-400，UCF101，HMDB51）上的广泛实验验证了我们工作的有效性、可移植性、泛化能力和效率。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20469", "html_url": "https://arxiv.org/abs/2505.20469", "title": "CCL-LGS: 对比码本学习用于三维语言高斯点绘制", "title_en": "CCL-LGS: Contrastive Codebook Learning for 3D Language Gaussian Splatting", "authors": "Lei Tian,Xiaomin Li,Liqian Ma,Hao Yin,Zirui Zheng,Hefei Huang,Taiqing Li,Huchuan Lu,Xu Jia", "background": "近年来，3D重构技术和视觉-语言模型的进展使得3D语义理解取得了显著进步，这项能力对于机器人学、自动驾驶和虚拟/增强现实至关重要。然而，依赖2D先验的方法容易受到视线间语义不一致性的问题，这些问题由遮挡、图像模糊和视点相关变化引起，这些问题在透过投影监督传播时会降低3D高斯语义场的质量，并在渲染输出中引入伪影。", "innovation": "本文提出了一种名为CCL-LGS的新型框架，通过整合多视图语义线索，来强制执行视图一致的语义监督。具体来说，该方法首先使用零样本跟踪器对由SAM生成的2D掩码进行对齐，并可靠地识别它们对应的类别。接着，利用CLIP从不同视图中提取鲁棒性的语义编码。最后，对比码本学习（CCL）模块通过增强类内紧凑性和类间区别性来提炼具有辨别性的语义特征。此前的方法直接将CLIP应用于不完美的掩码，而本框架明确解决了语义冲突并保持类别辨别性。", "conclusion": "大量的实验表明，CCL-LGS在先前最先进的方法上表现出良好的性能。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.04801", "html_url": "https://arxiv.org/abs/2504.04801", "title": "OrderChain：提升MLLMs的序理解能力的通用指令调优方法", "title_en": "OrderChain: Towards General Instruct-Tuning for Stimulating the Ordinal Understanding Ability of MLLM", "authors": "Jinhong Wang,Shuo Tong,Jian liu,Dongqi Tang,Weiqiang Wang,Wentong Li,Hongxia Xu,Danny Chen,Jintai Chen,Jian Wu", "background": "尽管多模态大型语言模型（MLLMs）取得了显著的进步，但在顺序回归（OR，也称为顺序分类）任务上仍面临挑战，难以取得竞争性的性能。本文旨在解决这一问题，提出了OrderChain，这是一种新颖且通用的提示化范式，通过特定性和共通性建模提高了MLLMs的顺序理解能力。OrderChain包括一组任务感知提示，以促进各种顺序回归任务的特定性建模，以及一种新的范围优化Chain-of-Thought（RO-CoT），用于均匀地将顺序回归任务分解为多个小范围优化子任务，来学习这些任务的共通性思考方式。", "innovation": "OrderChain 提出了一种新颖的提示化范式，通过特定性和共通性建模来提高 ML 大型语言模型 (MLLMs) 的顺序理解能力。OrderChain 包括任务感知提示，用于促进多种顺序回归任务的特定性建模，以及一种新的范围优化 Chain-of-Thought (RO-CoT)，这是一种通过均匀分解顺序回归任务为多个小范围优化子任务来学习所有任务共通思考方式的方法。此外，还提出了一种类别递归划分 (CRD) 方法来生成指令候选类别提示，以支持 RO-CoT 的自动优化。实验结果表明，带有 OrderChain 的 LLaVA 模型在多种 OR 数据集上显著优于基线模型，例如在 Adience 数据集上的年龄估计准确性从 47.5% 提高到 93.2%。", "conclusion": "总体而言，带有 OrderChain 的 LLaVA 模型在 Adience 数据集上的年龄估计准确率提高了 45.7%，在 Diabetic Retinopathy 数据集上的准确率提高了 55.7%，并且在 Adience 数据集上获得了 27% 的准确性和 0.24 的 MAE 的显著提升。据我们所知，OrderChain 是第一个增强 MLLMs 的 OR 任务的贡献，其有效性已在多种OR 数据集上得到验证。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23395", "html_url": "https://arxiv.org/abs/2505.23395", "title": "点还是线？用基于线的表示方法进行CAD图纸中的全景符号识别", "title_en": "Point or Line? Using Line-based Representation for Panoptic Symbol Spotting in CAD Drawings", "authors": "Xingguang Wei,Haomin Wang,Shenglong Ye,Ruifeng Luo,Yanting Zhang,Lixin Gu,Jifeng Dai,Yu Qiao,Wenhai Wang,Hongjie Zhang", "background": "现有方法通常依赖于图像的栅格化、图结构构建或基于点的表示，但在准确性和效率方面存在局限性。尤其是这些方法在处理矢量图形时会损失几何结构信息，并且计算成本较高、通用性较差。通过研究CAD图纸中的全景符号检测任务，旨在识别计数物体的实例和不计数物体的语义区域，现有方法难以兼顾精度与效率。", "innovation": "本文提出了一种名为VecFormer的新方法，该方法使用基于线的表示方法，通过保留原始图的基本几何连续性，以更准确地表示形状。在此基础上，引入了一种分支融合细化模块，有效整合实例预测和语义预测，解决其不一致性，从而生成更连贯的全景输出。", "conclusion": "广泛的实验表明，所提出的方法达到了新的SOTA，PQ得分达到了91.1，比第二好结果分别提高了9.6和21.2个点，展示了基于线的表示方法作为矢量图形理解基础的强大潜力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.01701", "html_url": "https://arxiv.org/abs/2506.01701", "title": "数据最大化中的数据精简", "title_en": "Data Pruning by Information Maximization", "authors": "Haoru Tan,Sitong Wu,Wei Huang,Shizhen Zhao,Xiaojuan Qi", "background": "现有的数据精简方法通常旨在减少数据集的大小，同时最大限度地保留重要信息，但缺乏对如何最大化精简后样本集合的信息内容进行全面考虑，特别是如何控制选择样本间的冗余。本文旨在通过最大化选择样本的信息内容并减少冗余，提升精简集合的整体信息含量。研究在此背景下提出了一个新的数据精简方法——InfoMax，这是一种核心选择（coreset selection）方法。\r\n", "innovation": "InfoMax的核心创新点在于提出了一个新的方法论——在最大化样本集合信息内容的同时最小化冗余。其方法包括：1) 使用重要性得分来量化每个样本的信息贡献；2) 使用样本对之间的相似性来量化冗余；3) 将核心选择问题形式化为一项多项式二次规划问题（DQP），目标是最小化总信息减去冗余；4) 通过高效梯度解析器和稀疏化技术以及数据集分区策略来确保实际的可扩展性，使得InfoMax能够处理包含数百万个样本的数据集。\r\n", "conclusion": "在各种数据精简任务中的广泛实验中，InfoMax方法表现出了优越的性能，特别是在图像分类、视觉语言预训练和大型语言模型指令调优等任务中。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06818", "html_url": "https://arxiv.org/abs/2506.06818", "title": "逐步分解与双流聚焦：一种新型的无需训练的迷彩目标分割方法", "title_en": "Stepwise Decomposition and Dual-stream Focus: A Novel Approach for Training-free Camouflaged Object Segmentation", "authors": "Chao Yin,Hao Li,Kequan Yang,Jide Li,Pinpin Zhu,Xiaoqiang Li", "background": "提示可调分割（例如，SAM）已经在各种分割任务中展示了潜力，但仍然需要为每个需要分割的对象手动提供视觉提示。针对迷彩目标分割（COS），由于现有的方法仍然存在两个关键问题：1）从整体描述中获取实例特定文本提示时的语义模糊；2）从整体背景中获取实例特定视觉提示时的语义不一致与空间分离导致SAM分割不相关区域。这些问题导致当前方法难以有效处理迷彩目标分割问题，仍需要改进.", "innovation": "提出了一个新的无需训练的测试时适应框架，即RDVP-MSD，它结合了基于多模态步骤分解思维链（MSD-CoT）的区域约束的双流视觉提示（VDPP）的方法。MSD-CoT逐级拆解图像描述以消除语义模糊，而VDPP则注入空间约束到视觉提示中，并独立为前景和背景点采样视觉提示，从而有效地缓解了语义不一致和空间分离问题。该方法在无需训练和监督的情况下实现了在多个COS基准上的最佳分割结果，并且比之前的算法具有更快的推理速度，显著提高了准确性和效率.", "conclusion": "无需训练的方法RDVP-MSD在多个COS基准上达到了最先进的分割效果，并且具有比前方法更快的推理速度，显著提高了准确性和效率。代码将在指定的链接处提供."}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19445", "html_url": "https://arxiv.org/abs/2506.19445", "title": "野外去模糊：来自智能手机高速视频的现实世界数据集", "title_en": "Deblurring in the Wild: A Real-World Dataset from Smartphone High-Speed Videos", "authors": "Mahdi Mohd Hossain Noki,Syed Mumtahin Mahmud,Prothito Shovon Majumder,Abdul Mohaimen Al Radi,Sudipto Das Sukanto,Afia Lubaina,Md. Mosaddek Khan", "background": "提出了一个基于智能手机慢动作视频构建的最大规模真实世界图像去模糊数据集。该数据集使用一秒钟内捕捉的240帧，通过平均帧来模拟真实的长时间曝光模糊效果，并将时间中心的帧作为清晰参考。数据集包含超过42000张高分辨率模糊-清晰图像对，使其比广泛使用的大约大10倍，场景数量是其8倍，涵盖了室内外环境，以及不同物体和相机运动的变体。", "innovation": "该数据集是迄今为止规模最大的现实世界去模糊数据集，相较于已有数据集具有10倍以上的数据量和8倍以上的场景多样性，能更好地模拟实际的模糊情况，为去模糊模型提供一个更为复杂和多样的基准。", "conclusion": "该数据集作为具有挑战性的新基准，旨在促进开发出更稳健且泛化的去模糊模型。多个最新的去模糊模型在该数据集上的性能表现不佳，突显了基准的复杂性和多样性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.18903", "html_url": "https://arxiv.org/abs/2506.18903", "title": "VMem：基于表面元索引视图记忆的一致交互式视频场景生成", "title_en": "VMem: Consistent Interactive Video Scene Generation with Surfel-Indexed View Memory", "authors": "Runjia Li,Philip Torr,Andrea Vedaldi,Tomas Jakab", "background": "先前的方法通过在重建场景3D几何的过程中逐帧进行2D视图外绘画（out-painting）来生成视频，但这种方法容易积累误差。另一种方法是使用具有短期上下文窗口的视频生成器，但这种方法在长期生成过程中难以维持场景的连贯性。该论文旨在针对以上限制，提出一种新的方法来解决这些问题。", "innovation": "提出了一种名为Surfel-Indexed View Memory（VMem）的记忆模块，该模块通过几何的方式对已观察到的3D表面元素（surfels）进行索引，从而高效地检索生成新视图时最相关的过去视图。这一方法在保持较低的计算成本的同时，实现了对想象场景的一致性探索，相比现有的方法，能够更好地维持场景连贯性和摄像头控制。", "conclusion": "我们在具有挑战性的长期场景合成基准上评估了这种方法，并证明优于现有的方法。通过专注于最相关的视图，我们的方法以较低的计算成本实现了对设想环境的一致性探索。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.16073", "html_url": "https://arxiv.org/abs/2506.16073", "title": "TD3Net：一种用于口唇阅读的时序密集多卷积扩张网络", "title_en": "TD3Net: A temporal densely connected multi-dilated convolutional network for lipreading", "authors": "Byung Hoon Lee,Wooseok Shin,Sung Won Han", "background": "口唇阅读方法通常采用两阶段框架，前端和后端架构分离来建模口唇运动的动态性。在后端架构中，流行的先进技术广泛采用了时序卷积网络（TCN）。最近，在TCN中引入了密集的跳连连接，以减轻感受野稀疏性带来的限制，从而改善复杂时序表示的建模。然而，这些方法的性能受限于口唇运动连续性信息可能存在的丢失，这归因于感受野中的盲点。", "innovation": "本文提出了TD3Net，这是一种结合密集跳连连接和多卷积扩张时序卷积作为后端架构的时序密集多卷积扩张网络。TD3Net通过应用不同的卷积扩张因子来连接特征，避免了感受野中的盲点，从而覆盖了更广且密集的感受野。实验结果显示，该方法在裸唇口唇阅读任务中达到了与现有技术相当的性能，具有更少的参数和更低的浮点运算，并且可视化结果表明该方法有效利用了多种时序特征，保持了时序连续性。", "conclusion": "通过在两个大型公开数据集LRW和LRW-1000上的实验，本文表明TD3Net能够在裸唇口唇阅读任务中取得与最先进的方法相当的效果，具有较少的参数和更低的浮点运算，并且可视化结果显示该方法能够有效利用多样化的时序特征，保持时序连续性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23009", "html_url": "https://arxiv.org/abs/2506.23009", "title": "MusiXQA：提高多模态大语言模型在音乐理解中的视觉理解", "title_en": "MusiXQA: Advancing Visual Music Understanding in Multimodal Large Language Models", "authors": "Jian Chen,Wenye Ma,Penghang Liu,Wei Wang,Tengwei Song,Ming Li,Chenguang Wang,Jiayu Qin,Ruiyi Zhang,Changyou Chen", "background": "多模态大语言模型（MLLMs）在自然图像、文本丰富的文档和图形设计中表现出卓越的视觉推理能力。然而，它们解读音乐五线谱的能力尚未得到充分探索。为解决这一问题，我们引入了MusiXQA，这是首个用于评估和推进MLLMs在音乐理解中的全面数据集。MusiXQA包含高质量的合成音乐五线谱，通过MusiXTeX生成，附带结构化的注解，涵盖了音高和时长、和弦、谱号、音阶/拍号以及文本，从而支持多种视觉问答任务。", "innovation": "我们开发了Phi-3-MusiX，这是一种基于我们数据集微调的MLLM，其性能显著优于基于GPT的方法。MusiXQA数据集和模型为未来在音乐理解中的MLLMs发展奠定了基础。我们将在论文被接受后公开代码、数据和模型。我们通过广泛评估揭示了当前最先进的MLLMs在此领域的显著不足。", "conclusion": "MusiXQA数据集和模型为多模态大语言模型在音乐理解中的研究建立了基础，未来的研究可以从这些数据和模型出发，进一步推进该领域的研究。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01006", "html_url": "https://arxiv.org/abs/2507.01006", "title": "GLM-4.1V-Thinking和GLM-4.5V：具有可扩展强化学习的多功能多模态推理", "title_en": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": "GLM-V Team:Wenyi Hong,Wenmeng Yu,Xiaotao Gu,Guo Wang,Guobing Gan,Haomiao Tang,Jiale Cheng,Ji Qi,Junhui Ji,Lihang Pan,Shuaiqi Duan,Weihan Wang,Yan Wang,Yean Cheng,Zehai He,Zhe Su,Zhen Yang,Ziyang Pan,Aohan Zeng,Baoxu Wang,Bin Chen,Boyan Shi,Changyu Pang,Chenhui Zhang,Da Yin,Fan Yang,Guoqing Chen,Jiazheng Xu,Jiale Zhu,Jiali Chen,Jing Chen,Jinhao Chen,Jinghao Lin,Jinjiang Wang,Junjie Chen,Leqi Lei,Letian Gong,Leyi Pan,Mingdao Liu,Mingde Xu,Mingzhi Zhang,Qinkai Zheng,Sheng Yang,Shi Zhong,Shiyu Huang,Shuyuan Zhao,Siyan Xue,Shangqin Tu,Shengbiao Meng,Tianshu Zhang,Tianwei Luo,Tianxiang Hao,Tianyu Tong,Wenkai Li,Wei Jia,Xiao Liu,Xiaohan Zhang,Xin Lyu,Xinyue Fan,Xuancheng Huang,Yanling Wang,Yadong Xue,Yanfeng Wang,Yanzi Wang,Yifan An,Yifan Du,Yiming Shi,Yiheng Huang,Yilin Niu,Yuan Wang,Yuanchang Yue,Yuchen Li,Yutao Zhang,Yuting Wang,Yu Wang,Yuxuan Zhang,Zhao Xue,Zhenyu Hou,Zhengxiao Du,Zihan Wang,Peng Zhang,Debing Liu,Bin Xu,Juanzi Li,Minlie Huang,Yuxiao Dong,Jie Tang", "background": "本文提出了GLM-4.1V-Thinking和GLM-4.5V，这是一种用于增强通用多模态理解和推理的视觉-语言模型（VLMs）的策略。研究人员展示了其在开发以推理为中心的训练框架方面的关键发现。", "innovation": "研究团队首先通过大规模预训练开发了一个强大的视觉基础模型，这被认为空间性能的上限。然后提出了强化学习搭配课程采样（RLCS）的技术，以充分发挥模型的潜力，使其在编码问题解决、视频理解、内容识别、编程、语义对齐、基于GUI的代理以及长文档解读等多样的任务中均获得了全面的能力增强。", "conclusion": "在42个公开基准测试中的全面评估中，GLM-4.5V在绝大多数任务中取得了开源模型中的最佳性能，与闭源模型Gemini-2.5-Flash在挑战性任务如编码和GUI代理上的表现相当或更优。较小的GLM-4.1V-9B-Thinking也在29个基准测试中表现出色，且优于更大的Qwen2.5-VL-72B。这两个模型均被开源，并提供代码、模型等更多信息。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.13307", "html_url": "https://arxiv.org/abs/2506.13307", "title": "预训练潜在扩散模型在生成未见SAR图像中的微调技术定量比较", "title_en": "Quantitative Comparison of Fine-Tuning Techniques for Pretrained Latent Diffusion Models in the Generation of Unseen SAR Images", "authors": "Solène Debuysère,Nicolas Trouvé,Nathan Letheule,Olivier Lévêque,Elise Colin", "background": "本文提出了一种框架，适应一个大型预训练潜在扩散模型用于生成高分辨率合成孔径雷达（SAR）图像。这种方法允许可控合成，并创造出训练集之外的稀有或分布外场景。本文没有从头开始训练一个特定任务的小模型，而是将一个开源的文本到图像基础模型适应到SAR模式，使用其语义先验将提示与SAR成像物理（侧面视图几何、斜距投影和具有重尾统计的相干斑点）对齐。使用一个包含10万张SAR图像的数据集进行了全面微调和参数有效低秩适应（LoRA）在UNet扩散骨干、变分自编码器（VAE）和文本编码器上的比较。评估结合了真实SAR振幅分布的统计距离、纹理相似性（通过灰度共生矩阵描述符）以及使用SAR专业化CLIP模型的语义对齐。实验结果表明，混合策略——全面微调UNet并在文本编码器和学习到的标记嵌入上进行LoRA最优，既能保持SAR几何和纹理，又能保持提示的忠实度。该框架支持基于文本的控制和多模态条件设置（例如，分割图、TerraSAR-X或光学引导），为地球观测中的大规模SAR场景数据扩增和未知场景模拟开辟了新的途径。", "innovation": "本文提出了一种适应预训练潜在扩散模型生成高分辨率SAR图像的框架。这种框架通过将开源文本到图像模型适应到SAR模式，利用其语义先验将提示与SAR成像物理对齐。特别引入了一种混合策略，全面微调UNet并在文本编码器上进行LoRA，并结合了学习到的标记嵌入，以保持SAR几何和纹理，同时保持提示的忠实度。此外，该框架支持多模态条件设置，用于大规模SAR场景数据扩增和未知场景模拟。", "conclusion": "实验结果表明，采用该混合策略能够最好地保持SAR几何和纹理，同时保持提示的忠实度。该框架支持基于文本的控制和多模态条件设置，推动了SAR图像生成和后续应用的发展。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06071", "html_url": "https://arxiv.org/abs/2507.06071", "title": "MEDTalk: 通过分离嵌入实现的动态情感多模态3D面部动画", "title_en": "MEDTalk: Multimodal Controlled 3D Facial Animation with Dynamic Emotions by Disentangled Embedding", "authors": "Chang Liu,Ye Pan,Chenyang Ding,Susanto Rahardja,Xiaokang Yang", "background": "现有的音频驱动的情感3D面部动画主要关注静态和预先定义的情绪标签，这限制了其多样性和自然度。因此，本文旨在生成与音频同步的嘴唇动作和生动的表情，并提出了一种名为MEDTalk的新颖框架，用于细粒度和动态的情感头部生成。该方法首先通过精心设计的交叉重构过程解耦内容和情绪嵌入空间，使嘴唇动作和面部表情可以独立控制。此外，该方法还结合了音频和语音文本，预测帧级强度变化，并动态调整静态情绪特征以生成逼真的面部表情。", "innovation": "文章提出了一种称为MEDTalk的新颖框架，用于细粒度和动态的情感头部生成。该方法通过精心设计的交叉重构过程解耦内容和情绪嵌入空间，使嘴唇动作和面部表情可以独立控制。此外，该方法还结合了音频、语音文本以及多模态输入（文本描述和参考表情图像），以生成用户指定的面部表情。并且，该方法生成的结果可以很方便地集成到工业生产管道中。", "conclusion": "通过MEDTalk框架，可以生成与音频同步的嘴唇动作和生动的表情，使3D面部动画更加多样和自然，并可以方便地集成到工业生产管道中。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.10778", "html_url": "https://arxiv.org/abs/2507.10778", "title": "基于LLM代理的仓库空间问题回答", "title_en": "Warehouse Spatial Question Answering with LLM Agent", "authors": "Hsiang-Wei Huang,Jen-Hao Cheng,Kuang-Ming Chen,Cheng-Yen Yang,Bahaa Alattar,Yi-Ru Lin,Pyongkun Kim,Sangwon Kim,Kwangju Kim,Chung-I Huang,Jenq-Neng Hwang", "background": "现有的多模态大语言模型在空间理解任务上存在挑战。先前的方法通过大规模的多模态大语言模型微调来增强其空间理解能力。本研究旨在提出一种数据高效的解决方案，旨在提升语言模型在复杂室内仓库场景中的空间问题回答能力。", "innovation": "本研究提出了一种LLM代理系统，该系统具备强大的空间推理能力，能够解决复杂仓库场景中的空间问题回答任务。系统结合了多种工具，使LLM代理能够进行空间推理和API工具交互，以回答复杂的空间问题。实验证明，该系统在物体检索、数量统计和距离估算等任务上表现出高准确率和效率。", "conclusion": "本研究提出的系统在2025 AI City Challenge Physical AI Spatial Intelligence Warehouse数据集上的广泛评估中表现出色，证明了其在复杂仓库场景中处理空间问题回答任务的高效性和准确性。源代码已公开。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06639", "html_url": "https://arxiv.org/abs/2507.06639", "title": "EXAONE Path 2.0：具有端到端监督的病理学基础模型", "title_en": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision", "authors": "Myeongjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee", "background": "在数字病理学中，全切片图像（WSIs）由于其 gigapixel 规模而难以处理，因此大多数方法通过自我监督学习（SSL）训练拼块编码器，然后通过多实例学习（MIL）或切片编码器聚合拼块级别的嵌入以进行下游任务。然而，拼块级别的 SSL 可能会忽略对于生物标记物预测至关重要的复杂领域特定特征，如突变状态和分子特性，因为 SSL 方法仅依赖于针对自然图像域的简单增强，这些增强主要用于小拼块级别的区域。此外，SSL 方法的数据效率仍然低于完全监督方法，需要大量的计算资源和数据集才能达到与之竞争的性能。", "innovation": "为了应对这些局限性，我们提出了 EXAONE Path 2.0，这是一种病理学基础模型，直接在切片级别上进行监督学习拼块级别的表示。EXAONE Path 2.0 仅使用 37,000 个WSIs进行训练，就在 10 个生物标记物预测任务中获得了最先进的平均性能，显示出出色的高效性数据能力。", "conclusion": "EXAONE Path 2.0 通过端到端监督学习拼块级别的表示，能够在有限的数据集上实现最先进的性能，展示了在生物标记物预测任务中的出色数据效率。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14976", "html_url": "https://arxiv.org/abs/2507.14976", "title": "Vision-Language模型的层次跨模态提示学习", "title_en": "Hierarchical Cross-modal Prompt Learning for Vision-Language Models", "authors": "Hao Zheng,Shunzhi Yang,Zhuoxin He,Jinfeng Yang,Zhenhua Huang", "background": "预训练的视觉-语言模型（VLMs）如CLIP展示了出色的泛化能力。然而，将这些大规模模型适应下游任务并保持其泛化能力依然具有挑战性。尽管提示学习方法显示出潜力，但它们在两个基本瓶颈上存在限制，即模态隔离和层次语义衰减。", "innovation": "提出了一种名为HiCroPL的层次跨模态提示学习框架，其能够通过互补的文本和视觉优势建立文本和视觉模态之间的双向知识流，使其能够相互完善语义。在早期层中，文本提示通过层级知识映射器将清晰的语义注入视觉提示，增强低级视觉语义的表示。在后期层中，视觉提示编码特定任务相关的对象返回以完善文本提示，从而实现更深层次的对齐。关键上，层级知识映射器允许多尺度表示的融合，确保较深层次的表示保留可转移的浅层语义，从而增强泛化能力。此外，引入了一种轻量级层特定的知识代理，以实现高效的跨模态交互。", "conclusion": "广泛的任务评估显示HIcroPL具有优越的性能，在11个基准测试上取得了最先进的结果，实现了显著的改进。代码可在以下链接获取：this https URL。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.21977", "html_url": "https://arxiv.org/abs/2507.21977", "title": "Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition", "title_en": "Motion Matters: Motion-guided Modulation Network for Skeleton-based Micro-Action Recognition", "authors": "Jihao Gu,Kun Li,Fei Wang,Yanyan Wei,Zhiliang Wu,Hehe Fan,Meng Wang", "background": "微动作（MAs）是非言语交流的重要形式，在社会互动中具有重要作用，并且在人类情感分析中有潜在应用价值。然而，现有的微动作识别方法往往忽略了微动作中固有的微妙变化，这限制了细微变化的微动作之间的区分准确性。", "innovation": "本文提出了一种新颖的运动引导的调制网络（MMN），该网络隐式捕捉和调节微小的运动线索，以增强时空表示学习。具体来说，该网络引入了运动引导的骨骼调制模块（MSM），在骨骼层面注入运动线索，作为控制信号指导空间表示建模；同时设计了运动引导的时间调制模块（MTM），在帧层面整合运动信息，促进微动作整体运动模式的建模。此外，提出了运动一致性学习策略，从多尺度特征中聚合运动线索进行微动作分类。", "conclusion": "实验结果表明，MMN在基于骨架的微动作识别上达到了最先进的性能，强调了显式建模细微运动线索的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22369", "html_url": "https://arxiv.org/abs/2507.22369", "title": "探究视觉问答（VQA）在课堂活动监控中的应用", "title_en": "Exploring the Application of Visual Question Answering (VQA) for Classroom Activity Monitoring", "authors": "Sinh Trong Vu,Hieu Trung Pham,Dung Manh Nguyen,Hieu Minh Hoang,Nhu Hoang Le,Thu Ha Pham,Tai Tan Mai", "background": "课堂行为监测是教育研究的重要方面，对提高学生参与度和学习成果具有重大影响。近年来，视觉问答（VQA）模型的最新进展为自动分析视频记录中的复杂课堂互动提供了有希望的工具。", "innovation": "作者研究了几种最新的开源VQA模型，包括LLaMA2、LLaMA3、QWEN3和NVILA，在课堂行为分析中的适用性。作者还提出了一个名为BAV-Classroom-VQA的新数据集，该数据集源自越南银行业学院的课堂视频记录，用于评估这些VQA模型。", "conclusion": "初步实验结果表明，所有四种模型在回答行为相关的视觉问题方面都实现了令人鼓舞的性能水平，展示了它们在未来课堂分析和干预系统中的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08307", "html_url": "https://arxiv.org/abs/2507.08307", "title": "M2DAO-Talker: 实现多粒度运动解耦和交替优化以生成有声头部", "title_en": "M2DAO-Talker: Harmonizing Multi-granular Motion Decoupling and Alternating Optimization for Talking-head Generation", "authors": "Kui Jiang,Shiyu Liu,Junjun Jiang,Hongxun Yao,Xiaopeng Fan", "background": "音频驱动的有声头部生成在电影制作中具有巨大潜力。尽管现有的3D技术在运动建模和内容合成方面取得了进步，但在表示稳定、精细的运动场方面仍然存在限制，这导致渲染中出现诸如运动模糊、时间抖动和局部穿透等艺术现象。本研究通过系统分析，将有声头部生成重新定型为预处理视频、运动表示和渲染重建的统一框架，以解决现有技术存在的问题。", "innovation": "本研究提出了一种名为M2DAO-Talker的新框架，通过多粒度运动解耦和交替优化策略来解决当前技术的限制。具体来说，该框架设计了一种新颖的2D肖像预处理管道，用于提取每一帧的变形控制条件（运动区域分割掩模和相机参数），以简化运动表示；使用多粒度运动解耦策略独立建模非刚性（口部和面部）和刚性（头部）运动，提升了重建精度；发展了一种运动一致性约束以确保头部-躯干动力学的一致性，从而减轻由运动混叠引起的穿透错误；并通过交替优化策略迭代优化面部和口部运动参数，以生成更真实的视频。", "conclusion": "实验结果表明，M2DAO-Talker在多个数据集上实现了最先进的性能，其生成质量的PSNR提高了2.43 dB，在用户评估的真实度方面也优于TalkingGaussian，同时保持了150 FPS的推理速度。项目主页：isthis https URL."}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22733", "html_url": "https://arxiv.org/abs/2507.22733", "title": "异步轨迹下的线性N点结构与运动求解器", "title_en": "A Linear N-Point Solver for Structure and Motion from Asynchronous Tracks", "authors": "Hang Su,Yunlong Feng,Daniel Gehrig,Panfeng Jiang,Ling Gao,Xavier Lagorce,Laurent Kneip", "background": "结构和连续运动估计从点对应关系是计算机视觉中的基本问题，依赖于诸如熟悉的5点或8点算法等著名算法。然而，尽管这些算法备受推崇，但它们仅适用于处理源自每幅视图的一对捕获帧的点对应关系，对于滚动快门相机或最新的事件相机来说，这种同步性会失效。", "innovation": "本文提出了一种统一方法，用于从具有任意时间戳的二维点对应关系估计任意视角的结构与线性运动。通过基于一阶动力学的建模和利用恒定速度运动模型，推导出一种新型的线性点共线关系，以高效地恢复线性速度和三维点，同时预测退化和解的多重性。该方法可用于多种传感模态，包括全局快门、滚动快门和事件相机，并且还可以结合来自不同传感器的对应关系。", "conclusion": "我们在模拟和实际数据上验证了此求解器的有效性，结果显示与其他现有方法相比，在所有模态下均有一致的改进。我们相信，这项工作为从异步数据中高效估计结构和运动打开了大门。源代码可以在提供的链接中找到。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.00399", "html_url": "https://arxiv.org/abs/2508.00399", "title": "iSafetyBench: 一种用于工业环境安全性的视频语言基准", "title_en": "iSafetyBench: A video-language benchmark for safety in industrial environment", "authors": "Raiyaan Abdullah,Yogesh Singh Rawat,Shruti Vyas", "background": "近期，视觉语言模型（VLMs）在零样本条件下跨多种视频理解任务展现出令人印象深刻的能力。然而，这些模型在高风险工业领域的能力——识别常规操作和关键安全异常的表现——尚未得到充分探索。为弥补这一不足，提出了iSafetyBench，这是第一个专门用于评估模型在工业场景中表现的新基准，涵盖正常和危险场景。", "innovation": "iSafetyBench 包含1100个来自现实生活中的视频片段，这些片段被详细标注了开放词汇和多标签动作标签，覆盖98类常规和67类危险动作类别。每个片段配有多选题，可以进行单标签和多标签评估，从而精细评估模型在标准和安全关键环境中的表现。", "conclusion": "虽然当前最先进的视频语言模型在现有数据集上表现出色，但在iSafetyBench测试中却面临困难，尤其是在识别危险活动和多标签场景中。实验结果揭示了显著的表现差异，强调了为工业应用开发更稳健、更具安全意识的多模态模型的必要性。iSafetyBench 提供了一个前所未有的测试平台，推动了该领域的进展。数据集可从以下链接获取：this https URL。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.04549", "html_url": "https://arxiv.org/abs/2508.04549", "title": "MSC：具有接地分割和片段级别描述的海洋野生动物视频数据集", "title_en": "MSC: A Marine Wildlife Video Dataset with Grounded Segmentation and Clip-Level Captioning", "authors": "Quang-Trung Truong,Yuk-Kwan Wong,Vo Hoang Kim Tuyen Dang,Rinaldi Gotama,Duc Thanh Nguyen,Sai-Kit Yeung", "background": "海洋视频理解面临显著挑战，包括海洋物体和环境的动态性、摄像机运动以及复杂海底场景。现有视频字幕数据集通常集中在通用或以人类为中心的领域，未能准确理解海洋环境和海洋生物。", "innovation": "提出了双阶段面向海洋物体的视频字幕管道，并构建了一个利用视频、文本和分割掩码三重体的全面视频理解基准，以增强视觉定位和字幕，提高海洋视频理解与分析能力，并促进海洋视频生成。此外，还强调了视频分割技术在检测场景变化中的显著物体转换方面的有效性，极大地丰富了字幕内容的语义信息。", "conclusion": "通过发布该数据集和代码，改善了海洋视频的理解与分析能力，并促进了海洋视频生成。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02669", "html_url": "https://arxiv.org/abs/2508.02669", "title": "MedVLThinker: 多模态医疗推理的简单基线", "title_en": "MedVLThinker: Simple Baselines for Multimodal Medical Reasoning", "authors": "Xiaoke Huang,Juncheng Wu,Hui Liu,Xianfeng Tang,Yuyin Zhou", "background": "大型推理模型（LRMs）通过链式推理使模型能够在回应之前进行思考，引入了AI的新范式。然而，构建以推理为中心的医疗LRMs缺乏公开、可复制的构建食谱，限制了社区内的研究、分析和比较。医学生物概念的复杂性以及交叉信息处理的需求使得构建这样模型的难度提高。", "innovation": "本研究提出了MedVLThinker，一种简单但强大的基线方法套件。其创新点在于：1) 系统化的数据整理，包括文本和图片文本的医疗数据，按照推理难度分级筛选；2) 两种训练方法：在提取的推理痕迹上进行监督微调（SFT），基于最终答案准确性使用验证奖励的强化学习（RLVR）。研究发现，在RLVR框架下，仅基于文本的推理数据的训练比基于文本和图片的多模态数据训练提供了更大的性能提升，并且使用该框架训练的模型在公开VQA基准测试上达到了最新水平。此外，将模型扩大到32B规模达到了与专有GPT-4o相当的性能。", "conclusion": "本研究提供了全面公开的数据集、模型和代码，为未来研究奠定了一个强大和开放的基础，促进了多模态医疗推理领域的进一步研究与进步。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03497", "html_url": "https://arxiv.org/abs/2508.03497", "title": "EditGarment：基于自动MLLM合成和语义感知评估构建的指令引导服装编辑数据集", "title_en": "EditGarment: An Instruction-Based Garment Editing Dataset Constructed with Automated MLLM Synthesis and Semantic-Aware Evaluation", "authors": "Deqiang Yin,Junyi Guo,Huanda Lu,Fangyu Wu,Dongming Lu", "background": "指令引导的服装编辑可以通过自然语言进行精确的图像修改，在时尚设计和定制领域具有广泛的应用。与一般的编辑任务不同，它需要理解服装特定的语义和属性依赖关系。然而，由于高质量的指令-图像对稀缺，且手动标注成本高且难以扩大规模，这限制了进展。尽管MLLM（机器学习语言模型）在自动化数据合成方面显示出潜力，但由于指令模型不精确以及缺乏时尚特定的监督信号，将其应用于服装编辑受限较多。", "innovation": "本文提出了一种自动化流水线来构建服装编辑数据集。首先，定义了六类与现实世界时尚工作流程相匹配的编辑指令类别，指导生成平衡且多样化的指令-图像三元组。其次，引入了Fashion Edit Score（服装编辑评分），这是一种语义感知的评估指标，能够捕捉服装属性间的语义依赖，并在构建过程中提供可靠的监督。以此流水线构建了包含52,257个候选三元组，并保留了20,596个高质量三元组，构建了EditGarment，这是首个针对独立服装编辑的指令引导数据集。", "conclusion": "通过该流水线，成功构建了第一个针对独立服装编辑的指令引导数据集EditGarment，为这一领域的发展提供了新的基础。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.01272", "html_url": "https://arxiv.org/abs/2508.01272", "title": "PromptSafe：适应性提示调谐以实现安全的文本到图像生成", "title_en": "PromptSafe: Gated Prompt Tuning for Safe Text-to-Image Generation", "authors": "Zonglei Jing,Xiao Yang,Xiaoqian Li,Siyuan Liang,Aishan Liu,Mingchuan Zhang,Xianglong Liu", "background": "文本到图像（T2I）模型在生成方面表现出色，但仍然容易生成不适合工作环境（NSFW）的内容，例如暴力或暗示性图像。虽然最近的努力引入了通过在输入中添加防御性标记来使用软提示引导调谐的方法，但这些方法通常依赖于大型人工策展的图像-文本数据集，并且在推理时应用静态的、一刀切的防御措施。然而，这种方法不仅导致高计算成本和良性图像质量的下降，还限制了对实际提示中多样和细腻的安全要求的适应性。", "innovation": "我们提出了一种名为PromptSafe的门控提示调谐框架，结合了轻量级的仅文本监督软嵌入和推理时间门控控制网络。我们首先使用LLM将潜在危险的提示重写为语义对齐但安全的替代方案，构建了一个高效的仅文本训练语料库，而不是基于昂贵的图像-文本数据集的训练。通过这种方法，我们优化了一个通用的软提示，在扩散去噪过程中排斥不安全而吸引安全的嵌入。为了避免过分抑制良性提示，我们引入了一种门控机制，根据估计的提示毒性动态调整防御强度，从而根据提示风险调整防御强度，并确保对危险输入提供强大保护，同时保持良性生成质量。", "conclusion": "在多个基准和T2I模型上进行的大量实验表明，PromptSafe在不安全生成率方面达到SOTA水平（2.36%），保持了高良性保真度。此外，PromptSafe在未见过的有害类别上表现出强大的泛化能力，扩散模型架构之间的稳健可转移性，以及在适应性对抗攻击下的韧性，突显了其在安全和可扩展部署中的实际价值。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05519", "html_url": "https://arxiv.org/abs/2508.05519", "title": "利用AI加速医学数据清洗：AI辅助方法与传统方法的比较研究", "title_en": "Leveraging AI to Accelerate Medical Data Cleaning: A Comparative Study of AI-Assisted vs. Traditional Methods", "authors": "Matthew Purri,Amit Patel,Erik Deurrell", "background": "药物开发中的临床试验数据清洗是一个关键瓶颈，手工审查过程难以处理不断增加的数据量和复杂性。", "innovation": "提出了一种名为Octozi的人工智能辅助平台，该平台结合了大型语言模型和特定领域的启发式方法，以改变医学数据审查方式。在一项受控的实验研究中，AI辅助使数据清理速度提高了6.03倍，同时将清理错误降低到8.48%，并且错误查询减少了15.48倍。针对一个代表性的Ⅲ期肿瘤临床试验的经济分析表明，潜在的成本节约为510万美元，主要归功于数据库锁定时间的减少（节省440万美元）、医学审查效率的提高（节省42万美元）和查询管理负担的减少（节省28.8万美元）。这些改进在各经验层次的审查员之间均保持一致，表明有广泛的适用性。这项研究发现，AI辅助方法可以解决临床试验操作中的根本性效率问题，可能将数据库锁定时间加速33%，同时保持合规并显著降低运营成本。这项工作提出了将AI集成到安全性关键的临床工作流程中的框架，并展示了人工智能和人类协作在制药临床试验中的转变潜力。", "conclusion": "AI辅助方法可以解决关键的临床试验操作效率问题，加速药物开发时间线，同时保持合规并显著降低运营成本。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.03189", "html_url": "https://arxiv.org/abs/2508.03189", "title": "KANs与特征漂移校正投影统一以实现无数据回放的持续面部伪造检测", "title_en": "Unifying Locality of KANs and Feature Drift Compensation Projection for Data-free Replay based Continual Face Forgery Detection", "authors": "Tianshuo Zhang,Siran Peng,Li Gao,Haoyuan Zhang,Xiangyu Zhu,Zhen Lei", "background": "随着面部伪造技术的迅速发展，检测器必须不断适应新的伪造方法，因此将面部伪造检测置于持续学习的范式中。然而，当检测器学习新的伪造类型时，其在以前类型的性能往往会迅速下降，这种现象称为灾难性遗忘。Kolmogorov-Arnold Networks (KANs) 采用局部可塑的样条作为激活函数，通过仅修改函数的局部区域来学习新任务，同时保留其他区域不变，因此自然适用于解决灾难性遗忘问题。然而，KANs 有两个重要的局限性：样条对于表示高维度图像效果不佳，而适合图像的替代激活函数缺乏局部性；在持续学习过程中，当来自不同领域的特征重叠时，不同领域映射到不同曲线区域变得因反复修改同一区域而变得困难。因此，现有的KAN方法无法基于无数据回放实现持续的面部伪造检测。为了克服这一限制，本文提出了KAN-Based Continual Face Forgery Detection (KAN-CFD) 框架，该框架包括 Domain-Group KAN Detector (DG-KD) 和使用 KAN Drift Compensation Projection (FS-KDCP) 的无数据回放特征分离策略。", "innovation": "本文提出了一个基于KANs的持续面部伪造检测框架（KAN-CFD），包括Domain-Group KAN Detector (DG-KD)和无数据回放特征分离策略通过KAN Drift Compensation Projection (FS-KDCP)（FS-KDCP）。DG-KD使KANs能够适用于高维度图像输入的同时保持局部性和局部可塑性。FS-KDCP通过避免KAN输入空间的重叠，而不需要使用以前任务的数据，从而解决了不同领域特征的重叠问题。这种框架显著减少了遗忘现象，同时实现了更好的性能。", "conclusion": "实验结果表明，所提出的方法在持续面部伪造检测中实现了优越的性能表现，大幅度减轻了遗忘现象。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06995", "html_url": "https://arxiv.org/abs/2508.06995", "title": "S2-UniSeg: 快速聚集合并池化以实现无需监督的可扩展自动分割", "title_en": "S2-UniSeg: Fast Universal Agglomerative Pooling for Scalable Segment Anything without Supervision", "authors": "Huihui Xu,Jin Ye,Hongqiu Wang,Changkai Ji,Jiashi Lin,Ming Hu,Ziyan Huang,Ying Chen,Chenglong Ma,Tianbin Li,Lihao Liu,Junjun He,Lei Zhu", "background": "近年来，自监督图像分割模型已经在语义分割和通用实例分割方面取得了显著的成果。然而，这些模型在预训练过程中需要多阶段、耗时的伪标签生成过程，这不仅难以扩展以匹配较大的训练数据集规模，还可能导致优化过程的不连续性，从而产生次优解决方案。", "innovation": "该研究提出了一种名为Fast Universal Agglomerative Pooling (UniAP)的新型伪标签算法。UniAP可以在毫秒内为一张图片生成具有层次结构的语义级、实例级伪标签。在此基础上，研究提出了一种可扩展的自监督通用分割模型S2-UniSeg，该模型采用学生-动量教师框架进行连续预训练，并引入了基于分割的先验任务Query-wise Self-Distillation (QuerySD)来训练S2-UniSeg，以学习局部到全局的对应关系。实验证明，S2-UniSeg在多项基准测试中均超过了当前最佳模型UnSAM，在COCO上的AP提高了6.9%，在UVO上的AR提高了11.1%，在COCOStuff-27上的PixelAcc提高了4.5%，在Cityscapes上的RQ提高了8.0%。在扩大到更大的200万图像的数据集中，S2-UniSeg在所有四个基准测试中均实现了性能提升。", "conclusion": "S2-UniSeg在无需监督的情况下，通过引入快速聚集合并池化算法UniAP和基于分割的先验任务QuerySD，实现了在大规模数据集上更快、更高效且性能更优的自监督图像分割。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.07171", "html_url": "https://arxiv.org/abs/2508.07171", "title": "EventRR: Event Referential Reasoning for Referring Video Object Segmentation", "title_en": "EventRR: Event Referential Reasoning for Referring Video Object Segmentation", "authors": "Huihui Xu,Jiashi Lin,Haoyu Chen,Junjun He,Lei Zhu", "background": "当前的视频对象分割（RVOS）方法将参照表达式视为无结构的序列，并忽略了其对于参照推理至关重要的语义结构。相较于仅关注对象属性和对象间关系的图像参照表达式，视频参照表达式还包含事件属性和事件间的时序关系，这增加了传统结构化图像推理方法的挑战性。", "innovation": "本文提出了事件参照推理（EventRR）框架，将RVOS拆分为对象总结部分和参照推理部分。EventRR通过对每个帧提取瓶颈令牌并进行高效的视频级总结来汇总全局跨模态时序上下文。推理部分则将视频参照表达式的语义事件结构提取为高度表达式的参照事件图（REG），并通过拓扑遍历REG进行时间查询的临时概念-角色推理。实验结果显示，EventRR在四个广为人知的标准数据集上在定量和定性上均优于现有的RVOS方法。", "conclusion": "EventRR在四个广为人知的标准数据集上在定量和定性上均优于现有的RVOS方法，展示了其有效性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08098", "html_url": "https://arxiv.org/abs/2508.08098", "title": "TBAC-UniImage: 基于梯级调整的统一理解和生成", "title_en": "TBAC-UniImage: Unified Understanding and Generation by Ladder-Side Diffusion Tuning", "authors": "Junzhe Xu,Yuyang Yin,Xi Chen", "background": "以往基于扩散模型的统一模型存在两个主要限制。一种方法仅使用大语言模型（MLLM）的最终隐藏状态作为生成条件，这形成了较浅的连接，生成器与MLLM中间层的丰富层次表示隔离。另一种方法则是从头开始预训练统一生成架构，这在计算成本上极为昂贵，对于许多研究人员来说是不可行的。针对这些问题，本研究提出了一个新的范式，利用MLLM的多种层次表示作为扩散模型的生成条件，使得TBAC-UniImage能够实现更深层次和精细的统一理解和生成。", "innovation": "本工作提出了TBAC-UniImage，一个新颖的多模态理解和生成统一模型。通过深度整合预训练的扩散模型与多模态大语言模型（MLLM），将扩散模型作为生成阶梯，从MLLM的多个不同层次中获取生成指导。这种方法克服了以往模型的浅层连接问题，并实现了更为深入和细粒度的统一理解和生成。", "conclusion": "TBAC-UniImage通过从多模态大语言模型（MLLM）的不同层次获取生成条件，实现了更深层次的统一理解和生成。与以往模型相比，这种方法提供了更丰富和层次化的表示，增强了模型在多模态理解和生成任务中的性能。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08189", "html_url": "https://arxiv.org/abs/2508.08189", "title": "视觉强化学习：综述", "title_en": "Reinforcement Learning in Vision: A Survey", "authors": "Weijia Wu,Chen Gao,Joya Chen,Kevin Qinghong Lin,Qingwei Meng,Yiming Zhang,Yuke Qiu,Hong Zhou,Mike Zheng Shou", "background": "近年来，强化学习（RL）与视觉智能交叉领域的最新进展，使智能体不仅能感知复杂的视觉场景，还能在场景中进行推断、生成与行动。本文综述了该领域的最新发展，并对相关研究进行了分类、回顾和评价。", "innovation": "文章对视觉RL问题进行了形式化，并描述了策略优化策略从RLHF到可验证奖励范式的演变，从Proximal Policy Optimization到Group Relative Policy Optimization的过程。文章还归纳了200多篇代表性的工作，并按照多模态大规模语言模型、视觉生成、统一模型框架和视觉-语言-行动模型四大主题支柱进行了组织。文章探讨了每个支柱的算法设计、奖励工程和基准进度，并总结了训练课程驱动、偏好对齐扩散和统一奖励建模等趋势。此外，文章还评估了涵盖集层置信度、样本层偏好和状态层稳定性等评价协议，并指出样本效率、泛化能力及可安全部署等问题。", "conclusion": "本文旨在为研究者和实践者提供一个视觉RL领域快速扩展面貌的清晰图谱，并指出未来研究的可能方向。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09178", "html_url": "https://arxiv.org/abs/2508.09178", "title": "IAD-R1: 在工业异常检测中强化一致推理", "title_en": "IAD-R1: Reinforcing Consistent Reasoning in Industrial Anomaly Detection", "authors": "Yanhui Li,Yunkang Cao,Chengliang Liu,Yuan Xiong,Xinghui Dong,Chao Huang", "background": "工业异常检测是现代制造业中的关键组成部分，但缺陷样本的缺乏限制了传统检测方法的应用场景。尽管视觉-语言模型（VLMs）在泛化能力方面显示出显著优势，但在工业异常检测中的表现仍然有限。", "innovation": "提出了IAD-R1，这是一种适用于不同架构和参数规模VLMs的通用后训练框架，显著增强了它们的异常检测能力。IAD-R1采用两阶段训练策略：感知激活监督微调（PA-SFT）阶段利用精心构建的高质量Chain-of-Thought数据集（Expert-AD）进行训练，增强异常感知能力并建立推理至答案关联；结构化控制组相对策略优化（SC-GRPO）阶段通过精心设计的奖励函数实现从“异常感知”到“异常解释”的能力跃升。", "conclusion": "实验证明，IAD-R1在7种VLMs中取得了显著改进，最大的改进是在DAGM数据集上的平均准确率提高了43.3%，并且在0.5B参数模型的零样本设置中，超越了包括GPT-4.1和Claude-Sonnet-4在内的商用模型，证明了IAD-R1的有效性和优越性。所有数据集、代码和模型权重将在指定的网址公开发布。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08601", "html_url": "https://arxiv.org/abs/2508.08601", "title": "Yan: 基础性互动视频生成", "title_en": "Yan: Foundational Interactive Video Generation", "authors": "Deheng Ye,Fangyun Zhou,Jiacheng Lv,Jianqi Ma,Jun Zhang,Junyan Lv,Junyou Li,Minwen Deng,Mingyu Yang,Qiang Fu,Wei Yang,Wenkai Lv,Yangbin Yu,Yewen Wang,Yonghang Guan,Zhihao Hu,Zhongbin Fang,Zhongqian Sun", "background": "本文介绍了Yan，这是一个全面的框架，涵盖了从模拟、生成到编辑的整个过程。该框架包含了三个核心模块：精简的3D-VAE结合KV缓存窗口去噪推理过程实现了实时1080P/60FPS互动模拟；层次自回归描述方法将游戏特有知识注入开放领域多模态视频扩散模型，使其能够实时生成帧级、动作可控的无限互动视频；以及通过文本进行交互操作的多粒度视频内容编辑模型。这些模块的集成推动了互动视频生成向全面的人工智能驱动的互动创作范式发展，为下一代创意工具、媒体和娱乐铺平了道路。", "innovation": "1. 精简的3D-VAE结合KV缓存窗口去噪推理过程，实现了实时1080P/60FPS互动模拟。2. 层次自回归描述方法将游戏特有知识注入开放领域多模态视频扩散模型，使其能够实时生成帧级、动作可控的无限互动视频。3. 通过文本进行交互操作的多粒度视频内容编辑模型，实现了交互中的多粒度视频内容编辑。4. 当文本和视觉提示来自不同领域时，模型展示了强大的泛化能力，能够灵活地混合和组合不同领域的风格和机制，根据用户提示实现灵活的创作。", "conclusion": "Yan将这些模块结合，推动了互动视频生成向前发展，超越了孤立的能力，形成了一种全面的人工智能驱动的互动创作范式，为下一代创意工具、媒体和娱乐铺平了道路。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09476", "html_url": "https://arxiv.org/abs/2508.09476", "title": "从大角度到一致人脸：基于面部专家混合的身份保留视频生成", "title_en": "From Large Angles to Consistent Faces: Identity-Preserving Video Generation via Mixture of Facial Experts", "authors": "Yuji Wang,Moran Li,Xiaobin Hu,Ran Yi,Jiangning Zhang,Chengming Xu,Weijian Cao,Yabiao Wang,Chengjie Wang,Lizhuang Ma", "background": "当前的视频生成模型在大面部角度下难以保持身份一致性，主要面临两个挑战：一是难以探索有效的机制将身份特征整合到DiT结构中，二是现有的开源视频数据集中缺乏针对大面部角度的专门覆盖。", "innovation": "该研究提出了两个关键创新点。首先，引入了面部专家混合（MoFE），动态地组合来自三个专门专家的互补线索，每个专家设计用于捕捉面部属性的不同但相互强化方面。此外，为了缓解数据集的限制，开发了一个以面部约束和身份一致性为中心的数据处理管道。该管道通过保持面部角度多样性、高面部区域比例以及时间序列中的一致性个人特征，解决了现有数据集中大面部角度和身份稳定的训练数据稀缺的问题。基于此管道，从现有的开源人类视频数据集中筛选和优化了一个大面部角度（LFA）数据集，包含46万带注释面部角度的视频片段。在LFA基准上的实验结果显示，这种方法在面部相似性、面部FID和CLIP语义对齐方面显著优于之前的方法。", "conclusion": "利用LFA数据集，该方法在面部相似性、面部FID和CLIP语义对齐方面显著优于此前的最优方法。未来的工作将通过公开代码和数据集，促进更多研究和应用的发展。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09185", "html_url": "https://arxiv.org/abs/2508.09185", "title": "一种用于增强现实领域可解释认知攻击检测的神经符号框架", "title_en": "A Neurosymbolic Framework for Interpretable Cognitive Attack Detection in Augmented Reality", "authors": "Rongqian Chen,Allison Andreyev,Yanming Xiu,Mahdi Imani,Bin Li,Maria Gorlatova,Gang Tan,Tian Lan", "background": "增强现实（AR）能够通过在物理世界中叠加虚拟元素来丰富人们的感知。由于AR日益受到欢迎，认知攻击也变得越来越重要，这些攻击改变了AR内容以操纵用户的意思感知。现有的检测方法通常关注于视觉变化，这限制在像素或图像级别处理，并缺乏语义推理能力；或者依赖于预训练的视觉-语言模型（VLMs），这些模型作为黑盒方法没有很高的可解释性。因此，需要一种新的方法来解决这个问题。", "innovation": "本文提出了CADAR，一种新颖的神经符号方法，用于检测AR中的认知攻击。CADAR通过使用神经VLMs融合多模态视觉-语言输入，获得符号感知图表示，结合先验知识、显著性加权和时间相关性。模型利用粒子滤波基于的统计推理检测认知攻击，从而CADAR继承了预训练VLM的适应性以及粒子滤波的可解释性和推理严密性。在扩展的AR认知攻击数据集中，与强基线相比，CADAR在具有挑战性的AR攻击场景中准确率提高了10.7%，这表明神经符号方法在有效和可解释的认知攻击检测中的潜力巨大。", "conclusion": "实验表明，CADAR方法在复杂AR攻击场景中的准确率比强基线提高10.7%，这证明了神经符号方法在有效和可解释的认知攻击检测方面的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09202", "html_url": "https://arxiv.org/abs/2508.09202", "title": "个性化特征转换用于表情识别：一种高效的数据源无关域适应方法", "title_en": "Personalized Feature Translation for Expression Recognition: An Efficient Source-Free Domain Adaptation Method", "authors": "Masoumeh Sharafi,Soufiane Belharbi,Houssem Ben Salem,Ali Etemad,Alessandro Lameiras Koerich,Marco Pedersoli,Simon Bacon,Eric Granger", "background": "面部表情识别（FER）模型被广泛应用于基于视频的情感计算应用，如人机交互和健康监控，但深度FER模型在处理细微表情和高个体差异方面表现不佳，影响其在实际应用中的性能。因此，研究提出了一种无源域适应（SFDA）方法，可以仅使用目标域的未标记数据来个性化预训练的源模型，而不泄露数据隐私、存储和传输的限制。然而，在无法获得可用源数据的情况下，仅用单类目标数据进行适应的SFDA方法尚未有成熟的解决方案，并且生成非中性表情的图像可能会不稳定且计算密集。", "innovation": "提出的个性化特征转换（PFT）方法是针对无源域适应框架的一种轻量级方法，它在潜在空间而不是像素空间中操作。PFT首先通过预训练转换器将一个源个体的个性化特征风格转化为另一个个体，通过优化表达一致性和风格感知目标保持表情信息。然后，分段器在仅包含中性表情的未标记目标数据上进行调整，而不使用源数据或图像合成。通过在潜在空间中进行转换，PFT避免了表情生成的复杂性和噪声，生成了旨在分类的即判别特征嵌入。这种方法在不使用图像合成的情况下提高了效率，并通过使用轻量级转换器减少了计算开销，仅调整模型的一部分。", "conclusion": "通过PFT方法，无需使用源数据或合成图像，仅依赖于目标域的未标记数据，实现了有效的个人化表情识别，提升了在无源域适应框架下的模型性能。这种方法减少了计算复杂度和开销，产生更加有效的特征表示，具有广泛应用前景。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09543", "html_url": "https://arxiv.org/abs/2508.09543", "title": "Iterative Volume Fusion for Asymmetric Stereo Matching", "title_en": "Iterative Volume Fusion for Asymmetric Stereo Matching", "authors": "Yuanting Gao,Linghao Shen", "background": "立体匹配在3D计算机视觉中至关重要，大多数算法假设双眼视图具有对称的视觉特性。然而，不对称多摄像头系统的兴起（例如，远摄宽镜头）挑战了这一假设并使立体匹配复杂化。视觉不对称会通过影响关键的成本体积计算来破坏立体匹配。已有研究工作通过探索两种现有的成本体积构建方法的成本分布来解决这个问题，发现每种成本体积都经历了不同的信息扭曲，因此两者都应该被全面利用来解决问题。", "innovation": "基于上述发现，提出了双阶段迭代体积融合网络（IVF-AStereo）来处理不对称立体匹配问题。该方法首先通过聚合连接体积细化相关体积，然后将两个体积融合以增强细节。IVF-AStereo在网络中取得了优越的不对称场景性能，并在分辨率和颜色降低的情况下表现出强大的鲁棒性。广泛基准数据集上的对比实验以及消融研究验证了该方法在不对称立体匹配中的有效性。", "conclusion": "该研究通过提出双阶段迭代体积融合网络IVF-AStereo，成功解决了视觉不对称带来的立体匹配难题，并在多种复杂场景下展示了其优越性和稳健性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08508", "html_url": "https://arxiv.org/abs/2508.08508", "title": "Re:Verse -- 你的VLM能读懂漫画吗？", "title_en": "Re:Verse -- Can Your VLM Read a Manga?", "authors": "Aaditya Baranwal,Madhav Kataria,Naitik Agrawal,Yogesh S Rawat,Shruti Vyas", "background": "当前的视觉语言模型(VLMs)在处理连续视觉叙事时，存在表面级识别与深层次情节推理之间的关键差距。通过全面调查漫画叙述理解，研究发现，尽管最近的大型多模态模型在单一面板解释上表现出色，但在时间因果性和跨面板连贯性方面系统性地失败，这是连贯故事理解的核心要求。本研究引入了一种新的评价框架，结合了细粒度的多模态注释、跨模态嵌入分析和检索增强评估，以系统地表征这些局限性。该方法包括：(i) 严格的注释协议，通过对齐的轻量级小说文本将视觉元素与叙述结构链接起来；(ii) 在多种推理范式中进行全面评估，包括直接推断和检索增强生成；(iii) 跨模态相似性分析揭示了当前VLMs联合表示中的根本性不一致。应用该框架对《Re:Zero》漫画的11个章节、308个注释面板进行系统研究，通过三个核心评估轴：生成叙事、情境对话定位和时间推理，展示了当前模型在非线性叙事、角色一致性和长时间段因果推理方面的不足。这项工作奠定了评估叙述智能的基础和实践方法，同时提供了针对多模态模型在离散视觉叙事深入序列理解能力的具体见解，超越了基本的识别能力。", "innovation": "该研究引入了一种新的评价框架，结合了细粒度的多模态注释、跨模态嵌入分析和检索增强评估，系统地表征了当前视觉语言模型在处理连续视觉叙事中的局限性。这些方法包括：1. 严格的注释协议，通过对齐的轻量级小说文本将视觉元素与叙述结构链接起来；2. 全面评估多种推理范式，包括直接推断和检索增强生成；3. 跨模态相似性分析揭示了当前VLMs联合表示中的根本性不一致。这种方法为评估视觉语言模型在叙述智能方面的能力提供了基础和实践方法。", "conclusion": "当前的视觉语言模型缺乏故事层面上的真正智能，尤其在处理非线性叙事、角色一致性和因果推理方面存在困难。本研究确定了这些模型的关键局限性，并提供了有价值的指导，以改进它们在多模态模型框架中的深度序列理解能力，超越基本的识别能力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09524", "html_url": "https://arxiv.org/abs/2508.09524", "title": "SOI是所有问题的根源：量化和克服单目标跟踪中相似对象干扰", "title_en": "SOI is the Root of All Evil: Quantifying and Breaking Similar Object Interference in Single Object Tracking", "authors": "Yipei Wang,Shiyu Hu,Shukun Jia,Panxi Xu,Hongfei Ma,Yiping Ma,Jing Zhang,Xiaobo Lu,Xin Zhao", "background": "长期以来，单目标跟踪(Single Object Tracking, SOT)在干扰问题上的研究不足，但这类干扰已经成为影响跟踪性能的关键瓶颈。本文通过在线干扰屏蔽实验(OIM)，定量证明消除干扰源能够显著提升所有当前最先进(SOTA)跟踪器的表现，直接验证相同物体干扰(Similar Object Interference, SOI)对鲁棒跟踪的重要性，并展示了外部认知指导的可能性。", "innovation": "1. 首次系统地研究并量化SOI，通过OIM实验确定干扰源的去除对跟踪性能的影响。\n2. 采用自然语言作为一种实用的外部指导形式，构建首个专注于SOI挑战的语义认知指导基准SOIBench，自动挖掘SOI帧并通过多级注释协议生成精确的语义指导文本。\n3. 提出了一个新的范式，使用大规模视觉语言模型(Vision-Language Models, VLM)作为外部认知引擎，可无缝集成到任意RGB跟踪器中，在语义认知指导下显著提高跟踪性能 (AUC 增益最高至 0.93)，超越现有视觉语言跟踪方法。", "conclusion": "本文希望通过SOIBench为语义认知跟踪研究提供一个标准化的评估平台，推动相关领域的研究进展，并为跟踪研究社区提供新的见解。当前的视觉语言跟踪方法无法有效利用语义认知指导，仅表现出小幅改进甚至性能下降。相比之下，使用大规模VLM进行外部认知引导的新型方法具有显著优势。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09560", "html_url": "https://arxiv.org/abs/2508.09560", "title": "WeatherPrompt：全天气无人机视觉地理定位的多模态表示学习", "title_en": "WeatherPrompt: Multi-modality Representation Learning for All-Weather Drone Visual Geo-Localization", "authors": "Jiahao Wen,Hang Yu,Zhedong Zheng", "background": "无人机在视觉地理定位过程中，受到天气条件如雨、雾等的严重影响，现有方法存在两个基本限制：1）依赖于有限的天气分类，限制了泛化能力；2）通过伪天气类别未能有效分离场景和天气特征。文章探讨了在不同天气条件下无人机视觉地理定位的挑战和现有方法的不足，强调了解决这些问题的重要性.", "innovation": "提出了一个名为 WeatherPrompt 的多模态学习框架，通过图像嵌入与文本上下文的融合建立天气不变的表示。该框架包含了两个关键贡献：1）无需训练的天气推理机制，利用现成的大规模多模态模型通过类人的推理生成多种天气文本描述，增强了对未见或复杂天气情况的适应性，并能反映出不同强度的天气情况；2）通过文本嵌入驱动的动态门控机制，提出了一种多模态框架，能够自适应地重新加权和融合模态间的视觉特征，并通过跨模态目标如图像-文本对比学习和匹配学习进一步优化，使具有不同天气条件的相同场景在表示空间中更加接近。该框架在多种天气条件下表现出了与现有最先进的无人机地理定位方法相当甚至更好的精确度，特别是在夜间和雾雪等恶劣天气条件下表现尤为突出，分别提高了 13.37% 和 18.69% 的精度.", "conclusion": "WeatherPrompt 在多种天气条件下表现出色，特别是在夜间和雾雪等恶劣天气条件下显著提高了无人机视觉地理定位的准确率。本文提出的方法和框架提供了一种新的研究视角和解决方案，有望在未来的研究中带来更有效的无人机地理定位技术。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09632", "html_url": "https://arxiv.org/abs/2508.09632", "title": "Preacher: Paper-to-Video Agentic System", "title_en": "Preacher: Paper-to-Video Agentic System", "authors": "Jingwei Liu,Ling Yang,Hao Luo,Fan Wang,Hongyan Li,Mengdi Wang", "background": "现有的最先进的视频生成模型虽然展示了潜力，但受到有限的上下文窗口、固定的视频时长限制、有限的风格多样性以及无法表示特定领域的知识的限制。这限制了科研论文转化为视频摘要的有效性和效率。", "innovation": "Preacher 是第一个提供自主生成论文到视频摘要的系统。Preacher 采用自上而下的方法对论文进行分解、总结和重新表达，然后采用自下而上的方法生成视频，将不同的视频片段综合为一个连贯的摘要。为了实现跨模态表示的对齐，引入了逐步思维链(P-CoT)进行细粒度、迭代的规划，使生成的视频摘要能够横跨五个研究领域，显示了比当前视频生成模型更高级的能力。", "conclusion": "Preacher 成功生成了高质量的视频摘要，展示了其在跨领域应用中的卓越性能，并且代码将被公开发布。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09584", "html_url": "https://arxiv.org/abs/2508.09584", "title": "SHALE: 一种针对大型视觉语言模型细粒度幻觉评估的可扩展基准", "title_en": "SHALE: A Scalable Benchmark for Fine-grained Hallucination Evaluation in LVLMs", "authors": "Bei Yan,Zhiyuan Chen,Yuecong Min,Jie Zhang,Jiahao Wang,Xiaozhen Wang,Shiguang Shan", "background": "尽管大型视觉语言模型（LVLMs）取得了快速进步，但仍然存在幻觉问题，即生成与输入或现有世界知识不符的内容，这包括忠实性和事实性幻觉。以往的研究主要在较粗略的层次上（例如，对象级别）评估忠实性幻觉，并缺乏细致分析。此外，现有基准通常依赖于昂贵的手动编目或重复使用公共数据集，这引起了可扩展性和数据泄露的担忧。这些局限性促使本文提出了一种自动数据构建管道，以生成可扩展、可控且多样的评估数据，并设计了一个具有输入扰动的分层幻觉诱导框架以模拟现实中的噪声场景。从而构建了SHALE，一种用于评估忠实性和事实性幻觉的可扩展幻觉评估基准，其基于详细的幻觉分类方案。", "innovation": "论文提出了一种自动数据构建管道，以生成适用于LVLMs细粒度幻觉评估的可扩展、可控且多样化的数据。同时，论文设计了一个具有输入扰动的分层幻觉诱导框架，以模拟现实中的噪声场景。通过这些设计，本文构建了一个名为SHALE的新型基准，能够细致评估LVLMs的忠实性和事实性幻觉。此外，SHALE包含了超过30,000个图像-指令对，涵盖12个代表性视觉感知方面和6个知识领域，考虑了干净和噪声场景两种情况。", "conclusion": "本文在超过20个主流LVLMs上进行了大量实验，揭示了显著的事实性幻觉和对语义扰动的高度敏感性。这些发现表明，SHALE在评估大型视觉语言模型的幻觉方面具有强大的效用。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2111.04578", "html_url": "https://arxiv.org/abs/2111.04578", "title": "神经网络中改进的正则化和鲁棒性在迁移学习中的应用", "title_en": "Improved Regularization and Robustness for Fine-tuning in Neural Networks", "authors": "Dongyue Li,Hongyang R. Zhang", "background": "迁移学习中广泛使用的方法是微调，即将预训练模型在目标任务上进行微调以适应较小的带标签数据集。当预训练模型的容量远大于目标数据集的大小时，微调容易导致过拟合和内存容量不足。因此，关键问题是正则化微调以确保其对噪声的鲁棒性。", "innovation": "该研究通过提出一种正则化自我标签方法解决了这个问题，该方法结合了正则化和自我标签方法，并包括：逐层正则化约束每层的迁移距离；自我标签纠正和标签重权，用于纠正模型自信的错误标签数据点，并重新权衡较不自信的数据点。", "conclusion": "该方法在七个图像分类任务和一项少量样本分类任务上相比基线方法平均提高了1.76%，且在数据集包含噪声标签的两个场景中平均高出3.56%。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.07275", "html_url": "https://arxiv.org/abs/2409.07275", "title": "无调参的在线鲁棒主成分分析通过隐含正则化", "title_en": "Tuning-Free Online Robust Principal Component Analysis through Implicit Regularization", "authors": "Lakshmi Jayalal,Gokularam Muthukrishnan,Sheetal Kalyani", "background": "标准的在线鲁棒主成分分析（Online Robust Principal Component Analysis，OR-PCA）技术的性能依赖于对外显正则化参数的最佳调整，而这些参数的调整也依赖于具体的数据集。", "innovation": "本文提出了一种通过使用隐式正则化效果的修改梯度下降方法，使其在不需要对数据集进行参数调优的情况下实现OR-PCA功能。具体来说，提出了三种不同版本的修改梯度下降方法，分别但自然地鼓励数据的稀疏性和低秩结构。该方法在模拟和真实数据集上的表现与调优后的OR-PCA相当或更好。", "conclusion": "无调参的ORPCA使其更适合处理大规模数据集，因为我们不需要对数据集进行依赖性的参数调整。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.00873", "html_url": "https://arxiv.org/abs/2401.00873", "title": "统一自监督聚类和能量模型", "title_en": "Unifying Self-Supervised Clustering and Energy-Based Models", "authors": "Emanuele Sansone,Robin Manhaeve", "background": "自监督学习能够从大量数据中学习表示，而生成模型则学习关于数据生成过程的信息。本文旨在建立这两种范式的原理性联系，并强调它们互补性的益处。具体来说，本文对自监督学习目标进行了分析，揭示了其底层的概率图模型，并提出了从第一原理推导标准化方法。分析表明，可以自然地将自监督学习与基于似然的生成模型结合起来。", "innovation": "本文提出了一种基于分析的方法，用于将自监督学习与生成模型结合。具体而言，该研究在聚类自监督学习和能量模型的范围内提出了这种方法，并引入了可以可靠地惩罚最重要作用模式的下界，实现了完全的统一。理论发现通过合成和真实世界的数据实验得到验证，显示了本文方法在聚类、生成和异常检测性能方面显著优于现有的自监督学习策略。", "conclusion": "本文不仅在自监督聚类和基于能量的模型之间实现了统一，还展示了该模型在神经符号框架中的应用。此外，已经证明该方法可以在解决符号地基问题的简单但非平凡实例中发挥作用。研究结果已经通过公开的代码得到了证明。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.19134", "html_url": "https://arxiv.org/abs/2411.19134", "title": "考虑多种运动模型的视觉SLAMMOT", "title_en": "Visual SLAMMOT Considering Multiple Motion Models", "authors": "Peilin Tian,Hao Li", "background": "SLAM（同时定位与建图）和MOT（多目标跟踪）是自主驾驶领域的核心任务，受到广泛关注。传统方法将SLAM和MOT分别视为独立模块，导致在动态环境中精度受限。IMM-SLAMMOT，一种前人的方法，虽整合了多个运动模型，但主要局限于简化的运动模式。本研究旨在通过整合多个运动模型到视觉SLAMMOT中，提升其在视觉感应机制中的优势，弥补LiDAR与视觉感应之间的差距。", "innovation": "提出了一种考虑多种运动模型的视觉SLAMMOT方法，该方法在原有IMM-SLAMMOT的基础上，将成像传感器和视觉SLAMMOT技术相结合，针对动态环境提供更精确的目标检测和跟踪性能。", "conclusion": "通过引入多种运动模型，该研究展示了视觉SLAMMOT在视觉感应机制中的可行性和优势，解决了传统方法在动态环境中精度不足的问题，为未来视觉检测提供了新的思路。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02012", "html_url": "https://arxiv.org/abs/2412.02012", "title": "INSIGHT: 可解释的弱监督医学图像分析", "title_en": "INSIGHT: Explainable Weakly-Supervised Medical Image Analysis", "authors": "Wenbo Zhang,Junyu Chen,Christopher Kanan", "background": "因体积庞大，体积扫描和全切片病理图像（WSIs）通常通过从局部区域提取嵌入并由聚合器进行预测的方式处理。然而，当前方法往往需要后处理可视化技术（例如Grad-CAM）来定位细节，并且经常无法准确识别出那些虽小但对临床至关重要的细节。", "innovation": "我们引入了INSIGHT，一种新颖的弱监督聚合器，该聚合器将热图生成作为归纳偏置集成进来。INSIGHT从预训练的特征图开始，使用带有小型卷积核的检测模块来捕捉精细细节，使用具有更广泛感受野的上下文模块来抑制局部假阳性。由此生成的内部热图突出显示了具有诊断意义的区域。", "conclusion": "在CT和WSI基准测试中，INSIGHT达到了最先进的分类结果和高弱监督语义分割性能。项目网站和代码可在该链接查看。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.08555", "html_url": "https://arxiv.org/abs/2408.08555", "title": "使用环形扫描模式LiDAR检测和跟踪MAVs", "title_en": "Detection and Tracking of MAVs Using a Rosette Scanning Pattern LiDAR", "authors": "Sándor Gazdag,Tom Möller,Anita Keszler,András L. Majdik", "background": "近年来，商用微型无人机（MAVs）的应用大幅增加，其为社会带来了益处，但也引发了诸如空中侵入和隐私问题等风险。由于安全风险的增加，开发自主无人机检测和跟踪系统成为优先事项。本研究针对这一挑战，采用非重复环形扫描模式LiDAR，并特别注重利用传感器特性来增加检测距离。", "innovation": "本研究提出了一种利用非重复环形扫描模式LiDAR进行无人机检测和跟踪的方法。该方法结合了带速度组件的粒子滤波器，提高了检测和跟踪的准确性，并利用Pan-Tilt平台确保目标物位于测量最密集的区域，从而进一步增强了检测能力。研究通过室内实验验证了系统的检测能力和精度，并通过室外实验展示了最大检测距离的显著提升，相比现有最先进的室外方法，检测范围增加了约80%。", "conclusion": "本研究开发的方法在室内检测方面达到了与现有最先进的方法相当的准确性，同时将室外检测的最大范围提升了约80%，通过环形扫描模式LiDAR增强了无人机的检测和跟踪效果。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09626", "html_url": "https://arxiv.org/abs/2508.09626", "title": "Semantic-aware DropSplat: 自适应去除冗余高斯点的语义感知Splat", "title_en": "Semantic-aware DropSplat: Adaptive Pruning of Redundant Gaussians for 3D Aerial-View Segmentation", "authors": "Xu Tang,Junan Jia,Yijing Wang,Jingjing Ma,Xiangrong Zhang", "background": "在3D Aerial-view Scene Semantic Segmentation (3D-AVS-SS) 任务中，传统的方法难以处理由尺度变化和结构遮挡导致的语义模糊问题，这限制了其分割精度和一致性。为了解决这一挑战，我们提出了一种名为SAD-Splat的新颖3D-AVS-SS方法。该方法引入了高斯点滴落模块，将语义置信度估计与基于Hard Concrete分布的可学习稀疏机制相结合，有效地消除了冗余且语义模糊的高斯点，提高了分割性能和表示紧凑性。此外，SAD-Splat还结合了一个高置信度伪标签生成管道，利用2D基础模型在有限的真实标签监督下提升监督，进一步提高分割精度。该工作还引入了具有稀疏标注的多样实际环境场景的挑战基准数据集——3D Aerial Semantic（3D-AS），以此推动研究进展。实验结果表明，SAD-Splat在分割精度和表示紧凑性之间取得了很好的平衡，提供了3D航空场景理解的一个高效和可扩展的解决方案。", "innovation": "本方法提出了高斯点滴落模块，结合语义置信度估计与基于Hard Concrete分布的可学习稀疏机制，有效减少了冗余且语义模糊的高斯点，提高了分割性能和表示紧凑性。还引入了高置信度伪标签生成管道，通过2D基础模型提升监督，提高分割精度。提出了3D Aerial Semantic（3D-AS）基准数据集，包含稀疏标注的真实场景，为该领域研究提供了挑战基准数据集。", "conclusion": "SAD-Splat在分割精度和表示紧凑性之间取得了良好的平衡，为3D航空场景理解提供了一个高效且可扩展的解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.07676", "html_url": "https://arxiv.org/abs/2412.07676", "title": "硅/SiGe 多量子点设备的启动、自主测试和初始化系统", "title_en": "Bootstrapping, Autonomous Testing, and Initialization System for Si/SiGe Multi-quantum Dot Devices", "authors": "Tyler J. Kovach,Daniel Schug,M. A. Wolfe,E. R. MacQuarrie,Patrick J. Walsh,Owen M. Eskandari,Jared Benson,Mark Friesen,M. A. Eriksson,Justyna P. Zwolak", "background": "半导体量子点（QD）设备在基于自旋的量子计算方面取得了重要进展。然而，随着现代QD设备复杂性的增加，特别是在高温下的校准和控制变得困难，成为推进技术发展的瓶颈。主要的问题是氧化层内的陷阱电荷，它们会在门极电极上引起随机的偏移电压变化，当前技术中的变异性标准偏差约为83毫伏。对大量QD自旋量子位进行高效表征和调整依赖于自动化的协议选择。因此，需要一种能够物理直观，并自动完成泄漏测试、电流通道形成和陷阱电荷存在下的门极表征等步骤的系统来简化QD设备的评估和校准工作。", "innovation": "本文介绍了一种物理直观的框架——启动、自主测试和初始化系统（BATIS），用于简化QD设备的评价和校准。BATIS能够在具有悬浮电荷的高维门电位空间中自主导航，并通过单次测量即可形成所有电流通道，实现平台无关的解决方案，适用于各种QD系统，填补了QD自主调谐的关键空白。Batis能减少初次诊断所需深低温环境，显著提升可扩展性并减少设置时间，无需对设备结构有较多的先验知识。", "conclusion": "BATIS系统能够在1.3开尔文的温度下成功应用于四量子点Si/Si_xGe_(1-x)器件，有效减少了初始诊断过程中对深低温环境的需求，提高了设备评估和校准的可扩展性和效率，并为各种QD系统的自主调谐提供了一个通用的平台框架。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10060", "html_url": "https://arxiv.org/abs/2508.10060", "title": "使用强化学习的个性化运动助手（PEARL）：四项随机对照试验的结果", "title_en": "A Personalized Exercise Assistant using Reinforcement Learning (PEARL): Results from a four-arm Randomized-controlled Trial", "authors": "Amy Armento Lee,Narayan Hegde,Nina Deliu,Emily Rosenzweig,Arun Suggala,Sriram Lakshminarasimhan,Qian He,John Hernandez,Martin Seneviratne,Rahul Singh,Pradnesh Kalkar,Karthikeyan Shanmugam,Aravindan Raghuveer,Abhimanyu Singh,My Nguyen,James Taylor,Jatin Alla,Sofia S. Villar,Hulya Emir-Farinas", "background": "全球范围内，持续的身体活动不足给健康带来了重大挑战。移动健康（mHealth）干预措施，特别是即时适应性干预（JITAIs），为可扩展的个人化身体活动（PA）促进提供了有希望的道路。然而，要在大规模下开发和评估这些干预措施，同时整合坚实的行为科学，存在方法论障碍。", "innovation": "PEARL研究是首个大规模分析强化学习（RL）算法的研究。该算法基于健康行为改变理论，用于通过健身追踪器应用个性化和调整身体活动提示的内容和时间。该研究针对四种不同的研究臂：对照组、随机组、固定组和RL组。RL组接受由自适应RL算法选择的提示，这与其他几组基于不同的逻辑构建的提示有所不同，显示出RL方法在个人化数字健康干预措施中具有潜在的应用。", "conclusion": "研究结果表明，与所有其他组相比，接受RL个性化提示的组在1个月和2个月时，每日步数有显著增加。这些发现证明了基于行为学的RL方法在可扩展的数字健康干预措施中的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.03184", "html_url": "https://arxiv.org/abs/2507.03184", "title": "EvRWKV：一种有效的事件引导低光照图像增强的连续交互RWKV框架", "title_en": "EvRWKV: A Continuous Interactive RWKV Framework for Effective Event-Guided Low-Light Image Enhancement", "authors": "Wenjie Cai,Qingguo Meng,Zhenyu Wang,Xingbo Dong,Zhe Jin", "background": "在低光照条件下捕获高质量的视觉内容仍然是一个具有挑战性的问题，因为严重的噪声和欠曝光会导致下游应用性能下降。传统的基于帧的低光照图像增强方法往往会放大噪声或者无法保留结构细节。事件摄像头通过异步捕捉亮度变化提供高动态范围和微秒级的时间分辨率，为低光照成像提供了一个可能的补充，但现有的融合方法无法充分利用这一协同效应，要么过早地将模态强约束到共享表示中，要么通过孤立处理丢失了重要的低级相关性。", "innovation": "提出了一种名为EvRWKV的新框架，通过双域处理实现连续的跨模态交互。该方法包括一个应用RWKV架构的Cross-RWKV模块，用于精细的时间和跨模态融合，以及一个EISFE模块，用于联合执行自适应频域噪声抑制和空间域可变形卷积对齐。", "conclusion": "在真实世界的低光照数据集（SDE、SDSD、RELED）上进行广泛的定性和定量评估表明，EvRWKV实现了最先进的性能，有效提升了图像质量，抑制了噪声，恢复了结构细节，并改善了在具有挑战性的低光照条件下的视觉清晰度。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06795", "html_url": "https://arxiv.org/abs/2503.06795", "title": "基于解剖代表性假体的机器人超声引导股动脉重建", "title_en": "Robotic Ultrasound-Guided Femoral Artery Reconstruction of Anatomically-Representative Phantoms", "authors": "Lidia Al-Zogbi,Deepak Raina,Vinciya Pandian,Thorsten Fleiter,Axel Krieger", "background": "股动脉穿刺对于多种临床程序至关重要，如诊断血管造影、治疗导管介入和紧急干预。尽管重要，但成功的血管穿刺仍然因解剖变异、覆盖的皮下脂肪组织以及需要精确的超声（US）引导而极具挑战性。针放置错误可能导致严重并发症，从而限制这些程序仅限于在医院控制环境下操作的高技能临床医生。虽然机器人系统在通过自主扫描和血管重建解决这些挑战方面显示出潜力，但临床转化仍有限，因为现有研究依赖于无法捕捉人体解剖复杂性的简化模拟模型。因此，本研究旨在提出一种用于自主机器人US扫描股动脉分叉的方法，并在五种基于真实患者CT数据构建的血管模型上进行验证。同时，引入了一种专门用于血管成像的基于视频的深度学习US分割网络，以改善3D动脉重建。", "innovation": "本文提出了一种用于自主机器人US扫描股动脉分叉的方法，并在五种基于真实患者CT数据构建的血管模型上进行了验证。此外，还介绍了一种专门用于血管成像的基于视频的深度学习US分割网络，以改善3D动脉重建。提出的网络在新的血管数据集上实现了89.21%的Dice分数和80.54%的交并比。重建的动脉中轴线与真实CT数据相比，平均L2误差为0.91±0.70毫米，平均Hausdorff距离为4.36±1.11毫米。此外，这是首个在多种患者特异性假体上验证自主机器人系统用于US扫描股动脉的研究，引入了评估机器人在血管成像和介入操作中的性能更高级的框架。", "conclusion": "本研究通过提出一种方法，首次在多种患者特异性假体上验证了用于US扫描股动脉的自主机器人系统。研究结果证实了该方法的有效性，为未来的机器人在血管成像和干预操作中的应用提供了基础。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11509", "html_url": "https://arxiv.org/abs/2503.11509", "title": "TikZero: 零样本文本引导图形程序合成", "title_en": "TikZero: Zero-Shot Text-Guided Graphics Program Synthesis", "authors": "Jonas Belouadi,Eddy Ilg,Margret Keuper,Hideki Tanaka,Masao Utiyama,Raj Dabre,Steffen Eger,Simone Paolo Ponzetto", "background": "自动从文本描述合成图形是一项有吸引力的能力，但高几何精度和编辑性需要以TikZ等图形程序语言表示图形，并且对齐的数据（即带有文本描述的图形程序）仍然稀缺。虽然未对齐的图形程序和带有文本描述的矢量图像更为常见，但将它们结合使用是一个挑战。因此，本文提出了TikZero，通过使用图像表示作为中介桥梁，解耦图形程序生成与文本理解。这种方法允许独立训练图形程序和带有文本描述的图像，并在推断过程中实现零样本的文本引导图形程序合成。研究表明，该方法在只使用对齐的图形程序进行训练的基线方法上表现更优，并且在利用对齐的图形程序作为补充训练信号时，TikZero在性能上可匹敌或超过更大规模的模型，包括商业系统如GPT-4o。", "innovation": "TikZero通过使用图像表示作为中介桥梁，解耦图形程序生成与文本理解。这种方法允许独立训练图形程序和带有文本描述的图像，并在推断过程中实现零样本的文本引导图形程序合成。进一步证明了该方法在仅使用对齐的图形程序进行训练的基线上取得了更好的性能；同时，在利用对齐的图形程序作为补充训练信号时，TikZero在性能上可匹敌或超过比其规模更大的模型，包括商业系统GPT-4o。", "conclusion": "研究表明，TikZero方法在零样本的文本引导图形程序合成任务上表现更优；在利用对齐的图形程序作为补充训练信号时，TikZero可匹敌或超过更大规模的模型，包括商业系统GPT-4o。此外，TikZero的代码、数据集和部分模型已公开。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10063", "html_url": "https://arxiv.org/abs/2508.10063", "title": "测量需求计划时间序列预测稳定性", "title_en": "Measuring Time Series Forecast Stability for Demand Planning", "authors": "Steven Klee,Yuntian Xia", "background": "时间序列预测是生成供应链需求计划的关键第一步。大多数时间序列模型实验侧重于展示其在预测精度方面的改进，这通常通过一些精度指标来量化。虽然预测精度很重要，但在实际生产系统中，需求计划人员通常更重视预测的一致性和稳定性，而不是精度的微小提升。大幅变动的预测结果需要大量人工干预，这会令需求计划人员感到沮丧，甚至会失去对机器学习预测模型的信任。", "innovation": "本研究提出了一种新的视角，即“模型诱导的不确定性”，探讨了当输入数据保持不变时，同一模型产生的预测结果之间的方差。此外，通过使用M5竞赛和Favorita杂货销售等公开数据集，评估了最先进的预测模型（Chronos、DeepAR、PatchTST、Temporal Fusion Transformer、TiDE和AutoGluon最佳质量的集成模型）的预测稳健性和准确性。研究发现，集成模型在提高稳健性方面表现出色，并且并未显著恶化甚至可能改善预测精度。", "conclusion": "本文的研究表明，对于即将部署在生产系统的模型，进一步研究预测的稳健性是必要的。尽管集成模型在稳健性方面表现出色，但也强调了对预测稳健性进行进一步研究的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10111", "html_url": "https://arxiv.org/abs/2508.10111", "title": "使用上下文自由文法的扩散LLM约束解码", "title_en": "Constrained Decoding of Diffusion LLMs with Context-Free Grammars", "authors": "Niels Mündler,Jasper Dekoninck,Martin Vechev", "background": "大型语言模型在多个领域表现出色，但在诸如代码补全和结构化数据提取等实际应用中，这些模型往往需要遵守由正式语言指定的句法规则。然而，由于其概率性质，LSTM预测输出不一定符合这些正式语言。已有研究提出了约束解码方法来限制LSTM生成的内容符合特定的正式语言。但现有的约束解码方法对于现有的扩散模型不适用，尤其是当我们需要生成正确形式的C++或JSON输出时。本文针对这一挑战，实现了首个针对上下文自由文法的约束解码方法。", "innovation": "本文将约束解码问题从特例扩展到了更通用的加性填充问题，并利用一种有效算法解决了目标语言和正规语言相交为空的问题，针对上下文自由文法设计了高效算法。实验结果表明，该方法在实现近乎完美的句法正确性的同时，能够保持或提高功能正确性。", "conclusion": "本文方法经实验证明，在保留功能正确性的同时实现了近乎完美的句法正确性，并且效率优化确保了计算开销的可行性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10053", "html_url": "https://arxiv.org/abs/2508.10053", "title": "xRFM: 准确、可扩展且可解释的针对表格数据的特征学习模型", "title_en": "xRFM: Accurate, scalable, and interpretable feature learning models for tabular data", "authors": "Daniel Beaglehole,David Holzmüller,Adityanarayanan Radhakrishnan,Mikhail Belkin", "background": "表格数据推理是以矩阵形式组织的连续和分类变量的集合，是现代技术和科学的基础。尽管在其他领域的人工智能技术有了爆炸式的发展，但在这些预测任务的最佳实践方面变化不大，仍然主要依赖于梯度提升决策树（GBDT）的变体。最近，基于神经网络和特征学习方法的最新进展，人们对开发针对表格数据的最佳方法产生了新的兴趣。", "innovation": "本文引入了xRFM算法，该算法结合了特征学习核机与树结构，以适应数据的局部结构，并可扩展到几乎无限数量的训练数据。实验结果表明，与31种其他方法相比，包括最近提出的表格基础模型 TabsPFNv2 和 GBDTs，xRFM 在100个回归数据集中的表现最佳，并且在200个分类数据集中具有与最优方法竞争的能力，且优于GBDTs。此外，xRFM 通过平均梯度外积提供内置的可解释性。", "conclusion": "xRFM 在表格数据的性能上取得了显著的进步，不仅在回归任务上表现出色，而且在分类任务上也具有很好的竞争力，并且还提供了一定程度的可解释性。"}
{"llm_update_time": "20250817", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.09123", "html_url": "https://arxiv.org/abs/2508.09123", "title": "OpenCUA：为计算机使用代理提供的开放基础", "title_en": "OpenCUA: Open Foundations for Computer-Use Agents", "authors": "Xinyuan Wang,Bowen Wang,Dunjie Lu,Junlin Yang,Tianbao Xie,Junli Wang,Jiaqi Deng,Xiaole Guo,Yiheng Xu,Chen Henry Wu,Zhennan Shen,Zhuokai Li,Ryan Li,Xiaochuan Li,Junda Chen,Boyuan Zheng,Peihang Li,Fangyu Lei,Ruisheng Cao,Yeqiao Fu,Dongchan Shin,Martin Shin,Jiarui Hu,Yuyan Wang,Jixuan Chen,Yuxiao Ye,Danyang Zhang,Dikang Du,Hao Hu,Huarong Chen,Zaida Zhou,Haotian Yao,Ziwei Chen,Qizheng Gu,Yipu Wang,Heng Wang,Diyi Yang,Victor Zhong,Flood Sung,Y.Charles,Zhilin Yang,Tao Yu", "background": "视觉-语言模型已经展示了作为计算机使用代理(CUAs)的强大能力，能够自动化各种计算机任务。随着这些模型的商业潜力增加，最先进的CUA系统的许多关键细节依然保密。这些代理将越来越多地调解数字交互并为我们代执行关键决策，因此研究社区需要访问开放的CUA框架来研究其能力和风险。为此，本文提出了一种名为OpenCUA的综合开源框架，用于扩展CUA数据和基础模型。", "innovation": "OpenCUA框架包含：（1）一种无缝捕捉人类计算机使用演示的注解基础设施；（2）AgentNet，第一个大规模计算机使用任务数据集，涵盖3种操作系统和200多个应用程序和网站；（3）一个可扩展的管道，将演示转换为状态-动作对，并采用反思性的长链推理，以确保在数据量增加时保持稳健的性能提升。OpenCUA-32B在OSWorld-Verified基准测试中达到了34.8%的平均成功率，是开源模型中新的SOTA。进一步分析表明，该方法在各个领域具有良好的泛化能力和从增加的测试时间计算中显著受益。", "conclusion": "我们发布我们的注释工具、数据集、代码和模型，为进一步的CUA研究奠定开放基础。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09992", "html_url": "https://arxiv.org/abs/2508.09992", "title": "OpenFPL: 一个与先进足坛 fantasy 服务竞争的开源预测方法", "title_en": "OpenFPL: An open-source forecasting method rivaling state-of-the-art Fantasy Premier League services", "authors": "Daniel Groos", "background": "Fantasy Premier League 通过让球迷在每轮比赛选出表现最佳的球员来参与比赛，使足球社区得以参与其中。获得准确的表现预测可以让参与者比竞争对手更有优势，通过引导对结果的期望来减少队伍选择时的不确定性。然而，高准确度的预测目前仅限于商业服务，这些服务的内部运作细节未公开，且依赖于专有数据。本文介绍了一种名为 OpenFPL 的开源预测方法，该方法仅使用公共数据，其目的是使更多人能够获得高度准确的球员表现预测。作为一种组别特定的集成模型，OpenFPL 在2020-21至2023-24年间四个赛季（Fantasy Premier League 和 Understat 数据）的数据上进行了优化，并在2024-25赛季的数据上进行了前瞻性测试。结果表明，OpenFPL 的预测准确度与领先的商业服务相当，并且在高回报球员（>2分）方面超过了商业基准，这表明该模型对长期转会和策略规划以及最终决策都非常有用.", "innovation": "OpenFPL 是一种仅基于公共数据的开源预测方法，旨在为 Fantasy Premier League 提供高质量的球员表现预测。该方法利用了位置特定的集成模型，并在整个过程中仅依赖公共数据。其准确度在前瞻性测试中达到了与领先商业服务相当的水平，特别是在高回报球员的预测上超过了商业基准。", "conclusion": "OpenFPL 在不同的预测时间范围（1-3 轮）内都取得了优异的预测结果，支持长期规划和短期决策。这种方法的成功表明，利用公共数据和开源方法可以为 Fantasy Premier League 提供准确且可靠的预测服务，从而为社区成员创造更多价值。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10115", "html_url": "https://arxiv.org/abs/2508.10115", "title": "少即是多：仅通过LLMs学习图任务", "title_en": "Less is More: Learning Graph Tasks with Just LLMs", "authors": "Sola Shirai,Kavitha Srinivas,Julian Dolby,Michael Katz,Horst Samulowitz,Shirin Sohrabi", "background": "目前大型语言模型（LLMs）在图推理方面存在改进空间，尽管前人尝试通过图形表示的序列化和图神经网络（GNNs）与LLMs的结合来增强LLMs的图推理能力，但这些方法的有效性尚未得到充分验证", "innovation": "本研究通过训练LLMs解决图任务，展示了即使是小型LLMs也能通过直观的推理链解决方案学习图任务，并且这种训练能够泛化到新的任务和图结构，而无需专门的图编码模型", "conclusion": "研究结果表明，LLMs能够学习并解决图任务，甚至可以在没有专门图形编码器的情况下，对新任务和图结构进行泛化学习。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10118", "html_url": "https://arxiv.org/abs/2508.10118", "title": "从意图到执行：基于多模态链式思维的强化学习在精确CAD代码生成中的应用", "title_en": "From Intent to Execution: Multimodal Chain-of-Thought Reinforcement Learning for Precise CAD Code Generation", "authors": "Ke Niu,Haiyang Yu,Zhuofan Chen,Mengyang Zhao,Teng Fu,Bin Li,Xiangyang Xue", "background": "计算机辅助设计（CAD）在工程和制造中起着至关重要的作用，但当前CAD工作流程需要大量的专业知识和手动建模。尽管大型语言模型（LLMs）的进步使得从自然语言生成代码成为可能，但这为自动化参数3D建模带来了新机会，但直接将人类的设计意图转化为可执行的CAD代码仍然极具挑战性，因为需要逻辑推理、语法规正确性和数值精度。", "innovation": "本文提出了一种名为CAD-RL的多模态链式思维引导的强化学习后训练框架，用于CAD建模代码生成。该方法结合了基于链式思维的冷启动和基于目标的强化学习后训练，使用三个任务特定的奖励：可执行性奖励、几何准确性奖励和外部评价奖励。为了在稀疏高方差奖励条件下稳定策略的学习，引入了三种针对性的优化策略：基于信任区域拉伸的改进探索、精度令牌损失以增强维度参数精度，以及过度长筛选以减少监督噪音。此外，还推出了ExeCAD数据集，包含16,540个真实世界的CAD示例及其配对的自然语言和结构化设计语言描述、可执行的CADQuery脚本和渲染的3D模型，以支持训练和基准测试。", "conclusion": "实验表明，CAD-RL在推理质量、输出精度和代码可执行性方面比现有VLMs取得了显著提高。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10173", "html_url": "https://arxiv.org/abs/2508.10173", "title": "基于基准的AI选择：DeepSeek-R1的证据", "title_en": "Benchmark-Driven Selection of AI: Evidence from DeepSeek-R1", "authors": "Petr Spelda,Vit Stritecky", "background": "经过观察，推理语言模型可以在任务完成前结合它们现有能力产生新颖的中间步骤，并且这些步骤有时能帮助它们比过去模型更好地泛化。随着推理成为大型语言模型的下一个扩展维度，对其在关键任务中的能力进行仔细研究变得必要。更好的性能不仅来源于测试时的算法改进或模型大小，还来源于使用具有影响力的基准作为学习的课程。这项工作使用了来自《人类的最后一考》中的顺序决策问题来展示DeepSeek-R1的效果，证明了通过具有影响力的基准进行AI选择的策略，这种策略将评估与学习相结合，并将测试任务的新颖性视为衡量推理模型泛化能力的关键。因此，一些基准可以被视为培训课程，而不是未知的测试集", "innovation": "提出了基于影响力的基准进行AI选择的方法，揭示了这种选择方法的效果，并强调了测试任务的新颖性对于评估推理模型的泛化能力的重要性。这种方法将基准作为学习课程，而不仅仅是未知的测试集", "conclusion": "基于影响力的基准不仅能评估AI的性能，还能作为学习的课程，这对于提高推理模型的泛化能力至关重要。一些基准可以作为学习的课程，从而使评估和学习相结合，以衡量模型的新颖任务泛化能力"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10147", "html_url": "https://arxiv.org/abs/2508.10147", "title": "rETF-semiSL: 基于时间数据神经塌缩的半监督学习", "title_en": "rETF-semiSL: Semi-Supervised Learning for Neural Collapse in Temporal Data", "authors": "Yuhan Xie,William Cappelletti,Mahsa Shoaran,Pascal Frossard", "background": "深度神经网络需要捕捉复杂的时间模式，以有效地表示动态数据。自我监督和半自我监督学习方法在预训练大型模型方面显示出有希望的结果，这些模型在微调分类时经常能够超越从头开始训练的模型。但是，选择预训练任务的方法通常是启发式的，其向下游分类任务的迁移并不保证。因此，本研究引入了一种新型半监督预训练策略，以强化满足在最优训练神经分类器中观察到的神经塌缩现象的潜在表示。该方法使用旋转等角紧框架分类器和伪标签预训练深度编码器，并且使用少量标记样本。此外，为了有效地捕捉时间动态并强制嵌入可分性，该方法结合了生成式的预训练任务，并定义了一种新型的序列增强策略。", "innovation": "引入了一种新的半监督预训练策略来强化满足神经塌缩现象的潜在表示，并结合了旋转等角紧框架分类器、伪标签、生成式的预训练任务和一种新型的序列增强策略。实验表明，该方法在应用于LSTMs、变压器和状态空间模型的三个多变量时间序列分类数据集中，比以前的预训练任务表现显著更好，突显了将预训练目标与理论支撑的嵌入几何结构对齐的好处。", "conclusion": "实验结果表明，该方法在应用于LSTMs、变压器和状态空间模型的多变量时间序列分类数据集上，比以前的预训练任务表现更好。这强调了将预训练目标与理论上的嵌入几何结构对齐的好处。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10123", "html_url": "https://arxiv.org/abs/2508.10123", "title": "Nested-ReFT：通过离策采样的大型语言模型细调高效强化学习", "title_en": "Nested-ReFT: Efficient Reinforcement Learning for Large Language Model Fine-Tuning via Off-Policy Rollouts", "authors": "Maxime Heuillet,Yufei Cui,Boxing Chen,Audrey Durand,Prasanna Parthasarathi", "background": "在诸如数学推理等具有挑战性的领域中，大规模预训练语言模型（LLMs）的高级推理可以通过基于可验证奖励的强化细调（ReFT）来解决。在标准的ReFT框架中，行为模型生成多个带有答案的问题完成版本，然后由奖励函数进行评分。尽管这些基于强化学习的后训练方法在多个具有挑战性的推理领域展示了显著的性能提升，但在训练时生成完成的多个推理步骤导致了高昂的计算成本，使培训成本变得不切实际。为了应对这一挑战，我们借鉴了离策强化学习和推测解码方法，引入了一种新颖的ReFT框架——Nested-ReFT，其中目标模型的一部分层作为行为模型在训练期间生成离策完成。与标准的ReFT框架相比，行为模型在训练过程中根据批量动态跳过层，从而降低了推理成本。理论分析表明，Nested-ReFT提供了无偏的梯度估计，并且方差可控。实证分析显示，在多种数学推理基准测试和模型尺寸上，Nested-ReFT展示了更大的计算效率，用作每秒令牌数的衡量标准。此外，我们研究了三种偏见缓解的变体，以最小化梯度更新中的离策性质，这使得保持与基线ReFT性能相当的表现成为可能。", "innovation": "我们提出了一种称为Nested-ReFT的新颖ReFT框架，该框架通过让目标模型的一部分层作为行为模型在训练期间生成离策完成，从而减少了推理成本。Nested-ReFT在离策采样和偏见缓解方面提供了理论支持，确保了无偏的梯度估计和可控的方差。此外，通过在多种数学推理基准上进行实验证明了其在计算效率上的优势。", "conclusion": "Nested-ReFT框架通过减少与标准ReFT训练相关的推理成本，提高了在具有挑战性推理领域中的计算效率，为大型语言模型的细调提供了一种有效的方法。此外，通过三种偏见缓解的变体，能够最小化更新梯度中的离策性质，从而维持与基线ReFT相当甚至更好的性能。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10233", "html_url": "https://arxiv.org/abs/2508.10233", "title": "早期预测具有肝硬化重症患者急性肾损伤的可解释机器学习模型：一项回顾性研究", "title_en": "Interpretable Machine Learning Model for Early Prediction of Acute Kidney Injury in Critically Ill Patients with Cirrhosis: A Retrospective Study", "authors": "Li Sun,Shuheng Chen,Junyi Fan,Yong Si,Minoo Ahmadi,Elham Pishgar,Kamiar Alaei,Maryam Pishgar", "background": "肝硬化是一种具有高死亡率和频繁并发症的进行性肝脏疾病，其中急性肾损伤（AKI）的发生率可高达住院患者的50%，并恶化预后。AKI源于复杂的血流动力学、炎症和代谢变化，早期检测至关重要。尽管存在多种预测工具，但它们缺乏准确性、可解释性和与重症监护病房（ICU）工作流程的匹配性。", "innovation": "这项研究开发了一个可解释的机器学习模型，以早期预测重症肝硬化患者的AKI，在MIMIC-IV v2.2数据库中进行了回顾性分析，选择了1240名符合条件的成人ICU患者，并根据首次48小时的实验室和生理变量训练了六种算法。结果显示LightGBM算法表现最佳，其高负预测值支持低风险患者的减缓治疗，并且高可解释性有助于临床信任和目标预防。", "conclusion": "基于LightGBM的模型能够使用常规临床变量对重症肝硬化患者的早期AKI风险进行准确分类。其高负预测值支持低风险患者的减缓治疗，并且可解释性有助于促进临床信任和针对预防措施。需要进行外部验证并整合到电子健康记录系统中。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10235", "html_url": "https://arxiv.org/abs/2508.10235", "title": "Can Transformers Break Encryption Schemes via In-Context Learning？", "title_en": "Can Transformers Break Encryption Schemes via In-Context Learning?", "authors": "Jathin Korrapati,Patrick Mendoza,Aditya Tomar,Abein Abraham", "background": "transformers作为一种语言模型的强大力量，能够通过在推理时提供少量示例来进行任务执行，而无需任何参数更新，被称为上下文学习（ICL）。先前的研究表明，transformers可以从上下文推断简单函数类如线性函数、决策树甚至是基于符号合理推断的神经网络。这些研究集中在数值或符号推理上。", "innovation": "本文提出了一种新的ICL应用，将ICL扩展到密码函数学习领域，特别是针对mono-alphabetic substitution和Vigenère ciphers这两类私钥加密方案。在这里，加密涉及固定的但隐藏的双射映射，模型需在此上下文中推断出隐藏的替换并解码新的密文单词。这是一个结构化推理挑战，适用于评估transformers在ICL框架下的归纳偏见和泛化能力。", "conclusion": "本文展示了transformers在ICL框架下的密码函数学习能力，证明了其在解决加密方案相关推理问题上的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10154", "html_url": "https://arxiv.org/abs/2508.10154", "title": "探讨欠指定混合线性回归中期望最大化估计演变特征", "title_en": "Characterizing Evolution in Expectation-Maximization Estimates for Overspecified Mixed Linear Regression", "authors": "Zhankun Luo,Abolfazl Hashemi", "background": "混合模型因其实际效果和全面的理论基础而受到广泛关注。一个持续存在的挑战是模型错定性，即拟合的模型包含的数据分布中更多的混合组件。本文针对目标错定的超指定两成分混合线性回归模型（2MLR），在未知$d$维回归参数和混合权重的情况下，探讨期望最大化（EM）算法的行为。", "innovation": "在总体水平上（定理5.1），通过不平衡初始猜测的混合权重，建立了回归参数在$O(\text{log}(1/\text{精度}))$步中的线性收敛性。而在欧几里得距离中，平衡初始猜测的混合权重显示亚线性收敛性，在$O(\text{精度}^{-2})$步内达到$\text{精度}$。在有限样本水平上（定理6.1），对于具有足够不平衡固定混合权重的混合模型，统计准确性为$O((d/n)^{1/2})$，而足够平衡固定混合权重的准确性为$O((d/n)^{1/4})$。进一步地，通过将定理5.1中的期望最终精度$\text{精度}$与定理6.1中的有限样本水平精度相匹配，我们推导出在足够不平衡和平衡初始混合权重下的迭代复杂度界限，分别为$O(\text{log}(1/\text{精度}))=O(\text{log}(n/d))$和$O(\text{精度}^{-2})=O((n/d)^{1/2})$。", "conclusion": "本研究分析了《期望最大化算法在目标错定的超指定混合线性回归中的行为》。总体来说，通过过拟合的两成分混合线性回归模型，研究讨论了在未知回归参数和混合权重的场景下，期望最大化算法的收敛性能。无论是总体水平还是有限样本水平，我们给出了特定条件下不同初始权重设置下的算法收敛性分析，并讨论了这些分析结果之间的联系。进一步地，研究扩展了这一分析到低信噪比环境下的超指定设置。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10228", "html_url": "https://arxiv.org/abs/2508.10228", "title": "D-Wave量子退火与马尔可夫链蒙特卡洛方法在受限玻尔兹曼机概率分布采样中的比较", "title_en": "Comparison of D-Wave Quantum Annealing and Markov Chain Monte Carlo for Sampling from a Probability Distribution of a Restricted Boltzmann Machine", "authors": "Abdelmoula El Yazizi,Samee U. Khan,Yaroslav Koshka", "background": "本文探讨了将局部谷（LV）中心化的采样质量评估方法应用于最新一代D-Wave量子退火器上的受限玻尔兹曼机（RBM）的场景。研究对比了D-Wave和Gibbs采样在经典训练的RBM下的样本质量，特别是在对比发散基础的RBM学习过程中的相关条件下。研究表明，降低D-Wave退火时间并不能显著增加局部谷的数量，尽管D-Wave采样比Gibbs采样更多的局部谷，但两者找到的局部谷并不相同。对于高概率采样状态，两者不互补且有重叠，但对于中等概率的局部最小值，两者互补性不足，有些重要局部最小值仅被一种采样技术找到。研究结果表明以前使用D-Wave基采样研究的失败可能在于此。", "innovation": "文章引入了一种基于局部谷中心化的评估方法，用于对比D-Wave量子退火和Gibbs采样在RBM中的采样质量。这种方法能够更细致地分析采样状态的局部谷结构，有助于理解为何D-Wave退火时间缩短不能显著提升采样质量。", "conclusion": "D-Wave和Gibbs采样在RBM中的表现各有千秋，高概率状态下的采样具有重叠特性，但中等概率状态下的某些重要局部最小值仅一种采样技术找到。采样技术的互补性在训练的后期尤为重要，此时的改进可能对RBM的训练产生实质性影响。研究结果揭示了一些潜在的改进途径，例如结合经典量子采样技术。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10210", "html_url": "https://arxiv.org/abs/2508.10210", "title": "基于可解释人工智能的方法用于监测动物健康", "title_en": "An Explainable AI based approach for Monitoring Animal Health", "authors": "Rahul Janaa,Shubham Dixit,Mrityunjay Sharma,Ritesh Kumar", "background": "奶农面临的挑战是如何有效跟踪农场上所有牛的健康状况和优化产出，由于缺乏有效的跟踪手段，这个问题变得尤为棘手。为此，本文旨在展示基于可解释机器学习（ML）方法的现代化农业实践，这些方法能够解释奶牛的活动和行为。通过连续收集3轴加速度计传感器的数据，结合强大的ML方法和算法，可以帮助农民和研究人员获得有关奶牛活动的行动信息，从而做出明智的决策并引入可持续实践。该项研究使用基于蓝牙的物联网（IoT）设备和4G网络进行无缝数据传输、即刻分析、推断生成，并通过可解释模型框架解释模型性能。特别强调预处理加速度计时间序列数据的方法，包括特征提取、信号处理技术和滑动窗口技术下的滞后特征。在不同的窗口长度下对各种超参数优化的ML模型进行评估，k-最近邻分类器表现最佳，其训练集AUC的平均值为0.98，标准差为0.0026，测试集AUC为0.99。为了保证透明度，本文采用基于可解释人工智能（AI）的框架，如SHAP，来解释特征的重要性，这些重要特征对于使用者来说是可理解且可利用的。详细的特征比较及所选特征的稳定性分析，支持了可解释和实用的ML模型的发展，用于可持续畜牧业管理。", "innovation": "本文创新之处在于采用了基于可解释人工智能的方法来监测动物健康。通过蓝牙物联网设备和4G网络实时数据传输、即时分析，以及使用滑动窗口技术进行加速度计时间序列数据预处理，结合超参数优化的机器学习模型，特别是k-最近邻分类器，实现了高精度的活动分类。此外，利用基于SHAP的可解释AI框架解释特征重要性，确保了模型的透明度和实用性，支持养殖业的可持续管理。", "conclusion": "本研究展示了基于可解释人工智能的方法在监测动物健康和优化畜牧业中的应用潜力。通过整合物联网技术、机器学习和可解释模型框架，不仅提高了牛活动监测的精度，还提供了透明的决策支持，促进了可持续的畜牧业实践。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10257", "html_url": "https://arxiv.org/abs/2508.10257", "title": "源成分偏移适配通过离线分解和在线混合方法", "title_en": "Source Component Shift Adaptation via Offline Decomposition and Online Mixing Approach", "authors": "Ryuta Matsuno", "background": "现有在线学习方法在利用反复出现的偏移方面效果不佳，而基于模型池的方法难以捕捉源组件，导致适应效果不佳。", "innovation": "提出了利用离线分解和在线混合的方法来实现源成分偏移的适应，将问题分为两个子问题：离线源成分分解和在线加权混合的适应。", "conclusion": "该方法通过理论上充分挖掘偏移的特点，在各种真实世界的回归数据集上的实验表明，该方法优于基线方法，累计测试损失降低了67.4%。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10253", "html_url": "https://arxiv.org/abs/2508.10253", "title": "基于多智能体强化学习的云原生集群自适应资源编排", "title_en": "Multi-Agent Reinforcement Learning for Adaptive Resource Orchestration in Cloud-Native Clusters", "authors": "Guanzi Yao,Heyao Liu,Linyan Dai", "background": "云原生数据库系统面临着高资源动态性和调度复杂性的挑战，需要一种能够灵活适应资源变化并高效管理的任务调度方法。", "innovation": "提出了一种基于多智能体强化学习的自适应资源编排方法，该方法引入了异构角色智能体制模机制，增强了不同资源实体的策略表示能力；通过设计奖励塑形机制，将局部观察与全局反馈相结合，以减少由不完整状态观察引起的策略学习偏差；并构建了一个统一的多智能体训练框架。", "conclusion": "实验结果表明，所提出的方法在多个关键指标上优于传统方法，包括资源利用率、调度延迟、策略收敛速度、系统稳定性和公平性。该方法对高并发、高维度状态空间和复杂依赖关系场景下的编排任务具有较强的通用性和实用性，证明了其在大规模、真实的调度环境中具有优势。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10248", "html_url": "https://arxiv.org/abs/2508.10248", "title": "Orlicz空间中Max-Min指数神经网络算子的收敛性分析", "title_en": "Convergence Analysis of Max-Min Exponential Neural Network Operators in Orlicz Space", "authors": "Satyaranjan Pradhan,Madan Mohan Soren", "background": "本文基于现有的指数神经网络算子逼近函数的方法，提出了一种Max Min逼近方法。在此基础上，发展了Max Min Kantorovich型指数神经网络算子，并研究了其逼近性质。研究了多变量函数的点值收敛和整体收敛，并利用对数利霍夫连续模进行了收敛阶的分析，给出相应收敛速度的估计。此外，在Orlicz空间框架下，分析了Max Min Kantorovich型指数神经网络算子的收敛行为。通过适当的内核和Sigmoid激活函数提供了一些图形化结果来展示函数逼近误差。", "innovation": "引入了Max Min方法和Kantorovich型指数神经网络算子，研究了其在多变量函数中的逼近性质及Orlicz空间中的收敛行为，并通过Sigmoid激活函数估计了收敛速度。", "conclusion": "研究了Max Min Kantorovich型指数神经网络算子的点值收敛和整体收敛性，通过Logarithmic modulus of continuity估计了收敛速度，并在Orlicz空间中分析了其收敛行为，结果通过图形清晰展示。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10255", "html_url": "https://arxiv.org/abs/2508.10255", "title": "联邦学习在多租户云平台个性化建模中的异常检测", "title_en": "Federated Anomaly Detection for Multi-Tenant Cloud Platforms with Personalized Modeling", "authors": "Yuxi Wang,Heyao Liu,Nyutian Long,Guanzi Yao", "background": "本文的背景在于多租户云环境中的关键挑战，包括数据隐私泄露、异构资源行为以及中心化建模的限制。需要一种能够在保护数据隐私的同时，进行跨租户协作异常检测的方法，以便更好地适应不同的资源使用模式，并提高异常检测的准确性和稳定性。", "innovation": "本文的创新点在于提出了一种基于联邦学习的异常检测方法，通过构建联邦训练框架，让每个租户使用本地的私有资源使用数据训练模型，通过参数聚合优化了全局模型，从而实现在保护数据隐私的前提下进行跨租户的协作异常检测。同时引入了个性化的参数调整机制，使得模型既能保留租户特定的特征表示，又能共享全局知识。在模型输出阶段，使用马哈拉诺比斯距离计算异常得分，增强了异常检测的准确性和稳定性。实验使用实际的云平台遥测数据构建了多租户环境，并在不同的参与率和噪声注入水平下评估了模型性能，结果表明该方法不但在精度、召回率和F1分数等关键指标上优于现有主流模型，还能在各种复杂场景下保持稳定性能。", "conclusion": "研究表明，该方法在智能资源监控和异常诊断方面具有实际潜力，适用于云计算环境中的多种复杂场景。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10345", "html_url": "https://arxiv.org/abs/2508.10345", "title": "福利中心的聚类", "title_en": "Welfare-Centric Clustering", "authors": "Claire Jie Zhang,Seyed A. Esmaeili,Jamie Morgenstern", "background": "传统的公平聚类主要关注确保团队代表性的公平性或均衡特定群体的聚类成本。然而，Dickerson等人（2025）的研究表明，这些公平性概念可能导致不满意的或未预见的聚类结果，并提倡以福利为中心的聚类方法，该方法建模群体的效用。", "innovation": "本文基于距离和比例表示建模群体效用，并形式化了两种基于福利中心聚类的目标：罗尔斯式（平等）目标和功利主义目标。引入了两种目标的新颖算法，并证明了它们的理论保证。在多个真实数据集上的实证评估表明，本文的方法明显优于现有的公平聚类基线。", "conclusion": "本研究通过提出新型的基于距离和比例表示群体效用的方法，以及为两种目标设计的新型算法，显著改进了公平聚类的效果。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10298", "html_url": "https://arxiv.org/abs/2508.10298", "title": "SynBrain：通过概率表示学习增强视觉至fMRI合成", "title_en": "SynBrain: Enhancing Visual-to-fMRI Synthesis via Probabilistic Representation Learning", "authors": "Weijian Mai,Jiamin Wu,Yu Zhu,Zhouheng Yao,Dongzhan Zhou,Andrew F. Luo,Qihao Zheng,Wanli Ouyang,Chunfeng Song", "background": "在计算神经科学中，理解视觉刺激如何转化为皮层反应是一个基本挑战。这种视觉至神经的映射是本质上的一对多关系，相同视觉输入在不同试次、不同上下文和不同被试者间可靠地引发不同血流动力学反应。尽管现有的确定性方法在同时建模这种生物变异性并捕捉刺激信息的潜在功能一致性方面存在局限性。", "innovation": "我们提出了SynBrain，一种生成性框架，模拟从视觉语义到神经响应的概率和生物学可解释转换。SynBrain 包含两个关键组件：(i) BrainVAE将神经表示视为连续概率分布，并通过视觉语义约束维持功能一致性；(ii) 语义到神经映射器充当语义传输路径，将视觉语义投影到神经响应流形中，以实现高保真fMRI仿生。", "conclusion": "实验结果表明，SynBrain 在个体特异性视觉至fMRI编码性能上超越了最先进的方法。此外，SynBrain 以少量数据高效适应新被试并合成高质量的fMRI信号，有效提高数据受限的fMRI至图像解码性能。此外，SynBrain 揭示了跨试次和被试者的功能一致性，合成信号捕获由生物神经变异性塑造的可解释模式。代码将公开发布。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10299", "html_url": "https://arxiv.org/abs/2508.10299", "title": "通过知识增强初始化改善联邦适配器调谐中对新疾病的适应学习", "title_en": "Improving Learning of New Diseases through Knowledge-Enhanced Initialization for Federated Adapter Tuning", "authors": "Danni Peng,Yuan Wang,Kangning Cai,Peiyan Ning,Jiming Xu,Yong Liu,Rick Siow Mong Goh,Qingsong Wei,Huazhu Fu", "background": "在医疗保健领域，联邦学习（FL）作为一种能够使医疗机构在保护隐私的情况下进行协作的广泛应用框架，已经得到了广泛采用。随着大规模基础模型（FMs）表现出令人印象深刻的能力，通过成本效益高的适配器调谐将这些基础模型应用于联邦学习已成为一种流行的方法。在快速变化的医疗环境中，个体客户端需要通过调适适配器快速适应新的任务或疾病，同时保留过去的经验教训。针对这一需求，本文介绍了一种新的框架——联邦知识增强初始化（FedKEI），以更好地利用过去的知识进行任务间的转移学习和初始化优化，为适配器学习新任务提供更有力的支持和保障。", "innovation": "FedKEI框架通过在服务器端进行全局聚类过程来泛化跨任务的知识，并结合优化跨簇（互簇权重）和同一簇内（内簇权重）的聚类权重来个性化知识转移，以便更好地适应新的任务和疾病。此外，通过采用双层优化方案，在客户间共同学习全局内簇权重并将局部互簇权重优化为每个客户的任务目标，来促进更有效的集群权重学习。", "conclusion": "大量实验表明，FedKEI框架在多个数据集上的新疾病适应学习方面优于最先进的方法。这意味着FedKEI在实现联邦适配器调谐过程中的知识传递和迁移学习方面取得了显著优势，为医疗保健领域的实时疾病识别和预测提供了强有力的支持。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10315", "html_url": "https://arxiv.org/abs/2508.10315", "title": "基于预训练视觉-语言模型的联邦学习中抵御后门攻击的方法", "title_en": "A Vision-Language Pre-training Model-Guided Approach for Mitigating Backdoor Attacks in Federated Learning", "authors": "Keke Gai,Dongjue Wang,Jing Yu,Liehuang Zhu,Qi Wu", "background": "现有的联邦学习（FL）后门防御方法依赖于客户端数据分布同质性或干净服务端数据集的假设，这限制了其实用性和有效性。在客户端数据分布异质性的情况下，同时保持模型性能防御后门攻击仍然是一项重大挑战。现有的防御方法对于具有不同触发器的后门攻击覆盖不足，且通常需要同质性数据或干净的服务端数据集。", "innovation": "本文提出了一种基于零样本学习能力的预训练视觉-语言模型的联邦学习后门防御框架，称为CLIP-Fed。CLIP-Fed结合了预聚合和后聚合的防御策略，使用多模态大语言模型和频率分析构建增强的服务端数据集，无需使用任何客户端样本。通过原型对比损失和Kullback-Leibler散度方法，CLIP-Fed对增强数据集进行全局模型和CLIP的知识对齐，以解决受到后门样本影响的类原型偏差，并消除触发模式与目标标签之间的相关性。", "conclusion": "在代表性的数据集上的广泛实验验证了CLIP-Fed的有效性。与最先进的方法相比，CLIP-Fed在CIFAR-10上的ASR平均减少了2.03%，而在CIFAR-10-LT上的ASR平均减少了1.35%，同时MA的平均提高了7.92%和0.48%。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10284", "html_url": "https://arxiv.org/abs/2508.10284", "title": "基于两阶段容许预测的帕金森病药物需求不确定性感知预测", "title_en": "Uncertainty-Aware Prediction of Parkinson's Disease Medication Needs: A Two-Stage Conformal Prediction Approach", "authors": "Ricardo Diaz-Rincon,Muxuan Liang,Adolfo Ramirez-Zamora,Benjamin Shickel", "background": "帕金森病(PD)的治疗管理面临独特的挑战，因为疾病的进展和治疗响应具有异质性。神经科医生需要在控制症状与根据功能障碍优化多巴胺剂量之间找到平衡，同时尽量减少副作用。这种平衡是至关重要的，因为不适当的或突然的变化可能导致左旋多巴引起的异动症、'关期现象'和神经精神效果，显著降低生活质量。当前的方法依赖于试错决策，缺乏系统的预测方法。尽管机器学习取得了进展，但临床应用仍然受限，因为传统的点预测方法未能考虑预测不确定性，这降低了临床的信任度和实用性。临床医生不仅需要对未来药物需求的预测，还需要可靠的置信度度量。缺乏量化的不确定性会增加过早增加剂量或长期的症状控制不足的风险。", "innovation": "我们开发了一种容许预测框架，能够前瞻性地预测药物需求，最多可提前两年，并提供可靠的预测区间和统计保证。我们的方法解决了帕金森病住院患者数据中的零频膨胀问题，即患者在就诊之间维持稳定的药物方案。利用2011年至2021年佛罗里达大学健康中心的631次住院电子健康记录，我们采用两阶段方法识别可能需要药物变化的患者，然后预测所需的左旋多巴等效每日剂量调整。与传统方法相比，我们的框架实现了边际覆盖，同时缩短了预测区间长度，提供了短期规划的精确预测和长期预报的更宽范围预测。通过量化不确定性，我们的方法使基于证据的多巴胺剂量决策成为可能，优化症状控制的同时减少副作用，提高生活质量。", "conclusion": "我们提出的方法能够量化不确定性，从而使临床医生能够基于证据做出多巴胺剂量调整决策，优化症状控制，减少副作用并提高生活质量。这种容许预测框架为帕金森病药物管理提供了一种新的解决方案，能够满足临床医生对可靠预测和不确定性度量的需求。该方法在预测未来药物需求方面表现出了潜力，为改善患者的临床管理提供了新的途径。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10393", "html_url": "https://arxiv.org/abs/2508.10393", "title": "一个多注释者趋势学习的统一评估框架", "title_en": "A Unified Evaluation Framework for Multi-Annotator Tendency Learning", "authors": "Liyun Zhang,Jingcheng Ke,Shenli Fan,Xuanmeng Sha,Zheng Lian", "background": "最近的研究重点从共识导向学习（CoL）转向个体趋势学习（ITL）。Consensus-oriented Learning（CoL）将多个注释聚合为单一的地面真相预测，而Individual Tendency Learning（ITL）则建模每个注释者的具体标签行为模式（即趋势），以提供解释分析，帮助理解注释者的决策。然而，目前还没有评估框架来验证ITL方法是否准确捕捉了个体趋势，并提供有实际意义的行为解释。", "innovation": "本文提出第一个统一的评估框架，包括两个新的度量标准：（1）预测的注释者一致性结构与地面真相对比的差异反映了模型捕捉注释者趋势的能力；（2）通过多维缩放（MDS）将解释性衍生的标签相似性结构与地面真相对齐，评估模型解释是否符合注释者的行为和决策相关性。广泛的实验验证了所提评估框架的有效性。", "conclusion": "本文提出了一种统一的评估框架，以度量多注释者趋势学习的表现和解释能力，验证了该框架的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10346", "html_url": "https://arxiv.org/abs/2508.10346", "title": "在医疗物联网网络中检测零日攻击的分层入侵检测系统", "title_en": "A Hierarchical IDS for Zero-Day Attack Detection in Internet of Medical Things Networks", "authors": "Md Ashraf Uddin,Nam H. Chu,Reza Rafeh", "background": "医疗物联网（IoMT）正在引发医疗保健革命，但它仍容易遭受拒绝服务、勒索软件、数据劫持和伪装等网络攻击。这些网络包含资源受限的异构设备（例如可穿戴传感器、智能药片、植入式设备），使传统的集中式入侵检测系统（IDS）不适合，因为这些系统存在响应延迟、隐私风险和增加的漏洞。传统的集中式IDS需要所有传感器将数据传输到中央服务器，但在密集环境中可能导致延迟或网络中断。在IoMT设备上本地运行IDS由于计算能力有限通常不可行，即使是最轻量级的IDS组件也可能因更新模型延迟而导致它们暴露在威胁患者健康和数据安全的零日攻击中。", "innovation": "本文提出了一种多层次IoMT入侵检测系统（IDS）框架，能够检测零日攻击并区分已知和未知威胁。第一层（近边缘）使用元学习或One-Class Classification（OCC）结合usfAD算法粗略过滤流量（攻击或不攻击）。后续层（远边缘、云）识别攻击类型和新颖性。关于CICIoMT2024数据集的实验结果显示99.77%的准确率和97.8%的F1评分。第一层能够高精度地检测零日攻击，无需新数据集，确保在IoMT环境中具有很强的应用性。此外，元学习方法实现了高精度。", "conclusion": "本文提出的多层次IoMT入侵检测系统框架能够在不影响应用性的情况下，有效检测零日攻击并区分已知和未知威胁，通过使用元学习或其他算法提升准确性和效率，适用于IoMT环境中的网络保护。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10395", "html_url": "https://arxiv.org/abs/2508.10395", "title": "XQuant: 利用 KV 缓存重建打破 LLM 推理的内存瓶颈", "title_en": "XQuant: Breaking the Memory Wall for LLM Inference with KV Cache Rematerialization", "authors": "Aditya Tomar,Coleman Hooper,Minjae Lee,Haocheng Xi,Rishabh Tiwari,Wonjun Kang,Luca Manolache,Michael W. Mahoney,Kurt Keutzer,Amir Gholami", "background": "虽然大规模语言模型（LLM）推理已成为许多下游应用的关键工作负载，但由于内存占用和带宽需求巨大，高效地进行LLM推理仍然极具挑战性。近年来，计算能力持续超越内存容量和带宽，尤其是在现代GPU硬件中，这种趋势加剧了LLM推理的挑战。", "innovation": "本文提出了一种名为XQuant的新算法，通过低比特量化减少了内存消耗，并且相比最先进的键值缓存量化方法具有显著的准确度优势。XQuant的关键在于量化并缓存层输入激活X，而不是采用标准的键值缓存，并在推理时即需即现Key和Value。这带来了2倍的内存节省。此外，文中还提出了XQuant-CL，利用X值在不同层之间的相似性进行极致压缩，最多可节省10倍的内存，同时仅损失微小的困惑度。", "conclusion": "XQuant利用硬件平台计算能力的快速增加来消除内存瓶颈，并超越了最先进的键值缓存量化方法，在广泛模型上实现了接近FP16的准确度。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10350", "html_url": "https://arxiv.org/abs/2508.10350", "title": "基于序列观察的语义通信与分布学习", "title_en": "Semantic Communication with Distribution Learning through Sequential Observations", "authors": "Samer Lahoud,Kinda Khawam", "background": "语义通信旨在传达意义而非精确的位复制，与传统通信形成范式的转变。本文研究了在语义通信中分布学习的问题，接收方需要通过序列观察来推断潜在的意义分布。传统的语义通信优化个体意义传输，本文提出了未知先验条件下的学习源统计的基本条件，并证明了可学习性需要有效传输矩阵的满秩，阐述了分布估计的收敛速率，并量化了估计错误如何转化为语义失真。本文分析揭示了基本权衡：针对即时语义性能优化的编码方案往往会牺牲长期学习能力。", "innovation": "本文建立了学习源统计的基本条件，证明了可学习性需要有效传输矩阵的满秩，阐述了分布估计的收敛速率，并量化了估计错误如何转化为语义失真。同时，揭示了针对即时语义性能优化的编码方案往往会牺牲长期学习能力这一基本权衡。实验表明，系统预处理对学习速率和可实现性能有着重大影响。这些结果为提供了一种统计学习范式的严格表征，并提出了平衡即时性能与适应能力的设计原则。", "conclusion": "本文首次系统地表征了语义通信中的统计学习，并提供了设计指导原则，平衡了即时性能与系统适应能力。这些结果对语义通信系统的开发具有重要意义。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10428", "html_url": "https://arxiv.org/abs/2508.10428", "title": "SC2Arena和StarEvolve：复杂决策任务中LLMs的基准和自我改进框架", "title_en": "SC2Arena and StarEvolve: Benchmark and Self-Improvement Framework for LLMs in Complex Decision-Making Tasks", "authors": "Pengbo Shen,Yaqing Wang,Ni Mu,Yao Luan,Runpeng Xie,Senhao Yang,Lexiang Wang,Hao Hu,Shuang Xu,Yiqin Yang,Bo Xu", "background": "评估大型语言模型（LLMs）在复杂决策任务中的表现对于推进AI在战略规划和实时适应能力方面至关重要。现有的评估基准，如StarCraft II的基准，在捕捉游戏完整性和多样性方面存在局限，例如游戏的完整背景、多样的行为空间和所有可玩的种族。因此，有必要开发一个新的基准来弥补这些局限，以便更好地评估LLMs的能力。", "innovation": "该论文提出SC2Arena作为基准，能够全面支持所有可玩种族、低层次行为空间，并优化基于文本的观察以应对空间推理挑战。此外，作者引入了StarEvolve，这是一种层次化的框架，将战略规划与战术执行相结合，具备迭代自我纠正和通过高质量的游戏数据进行微调的持续改进能力。关键组成部分包括规划者-执行者-验证者结构来分解游戏，并通过评分系统选择高质量的训练样本。", "conclusion": "使用SC2Arena进行全面分析提供了有关开发通用代理的重要见解，这在之前基准上是无法实现的。实验结果还表明，StarEvolve在战略规划方面表现出优越性能。所用到的代码、环境和算法已经公开可用。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10474", "html_url": "https://arxiv.org/abs/2508.10474", "title": "EDAPT: 向无校准自适应脑-机接口迈进", "title_en": "EDAPT: Towards Calibration-Free BCIs with Continual Online Adaptation", "authors": "Lisa Haxel,Jaivardhan Kapoor,Ulf Ziemann,Jakob H. Macke", "background": "脑-机接口（BCIs）因为神经信号随时间漂移和用户之间差异导致的准确性下降而需要频繁重新校准，这限制了其实用部署。这项工作介绍了EDAPT框架，旨在通过持续模型适应消除校准需求，提高BCI的实用性。", "innovation": "EDAPT框架在不使用校准的情况下通过持续的模型适应来提升准确度，它首先利用来自多个用户的训练数据来训练一个基础解码器，然后在神经模式随时间变化时通过监督微调持续个性化模型。这种方法结合了群体级别预训练和在线持续微调，并且在一些数据集上通过无监督域适应进一步提高了准确度。该框架运行效率高，能在消费级硬件上以200毫秒以内更新模型，解码准确度根据总数据预算而不是在个体和试验之间分配的数据量来提升。", "conclusion": "EDAPT提供了一条实用的无校准BCIs的道路，减少了BCI部署的主要障碍。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10370", "html_url": "https://arxiv.org/abs/2508.10370", "title": "eMamba: 在边缘计算中高效加速Mamba模型的框架", "title_en": "eMamba: Efficient Acceleration Framework for Mamba Models in Edge Computing", "authors": "Jiyong Kim,Jaeho Lee,Jiahao Lin,Alish Kanani,Miao Sun,Umit Y. Ogras,Jaehyun Park", "background": "基于状态空间模型（SSM）的机器学习架构近年来在处理序列数据方面引起了广泛关注。Mamba作为一种近期的序列到序列SSM模型，其准确性和计算效率都优于当前最先进的变压器模型。尽管这个优势使得Mamba特别适合资源受限的边缘设备，但目前尚无为在这些环境中部署它而优化的硬件加速框架。本文提出了一种全面的端到端硬件加速框架eMamba，专门设计用于在边缘平台部署Mamba模型。该框架通过替换复杂的归一化层为轻量级的硬件感知替代层，并对昂贵的操作（如SiLU激活和指数运算）进行近似，以最大化计算效率。同时，它还进行了一个基于近似的神经架构搜索（NAS）来调整在近似过程中使用的可学习参数。", "innovation": "eMamba框架实现了对Mamba模型的高效加速，通过替换复杂的归一化层为轻量级的硬件感知替代层，以及近似昂贵的操作，它在保持与当前顶级技术相当的准确性的前提下，使用了1.63-19.9倍更少的参数。该框架适合在资源受限的环境如边缘设备上运行。通过整个eMamba管道的量化和在AMD ZCU102 FPGA和使用GlobalFoundries 22 nm技术的ASIC上的实现，实验结果表明其具有4.95-5.62倍的更低延迟，2.22-9.95倍的更高吞吐量，以及4.77倍的更小面积、9.84倍的更低功耗和48.6倍的更低能耗，同时保持了竞争力的准确性。此外，eMamba还可以很好地适应大规模自然语言处理任务，即使在不同的序列长度上也能展示出稳定的表现。", "conclusion": "该研究提出了一种专门为边缘平台设计的eMamba硬件加速框架，通过优化和近似复杂的模型操作，实现了Mamba模型在资源受限环境下的高效部署。实验表明，eMamba不仅在参数数量和资源使用上实现了更优，还保持了与当前技术相当的准确性和稳定性，从而为边缘计算环境下的序列数据处理提供了一种高效解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10455", "html_url": "https://arxiv.org/abs/2508.10455", "title": "实AC：一种适应于现实并具备行动性的领域无关框架用于生成因果反事实解释", "title_en": "RealAC: A Domain-Agnostic Framework for Realistic and Actionable Counterfactual Explanations", "authors": "Asiful Arefeen,Shovito Barua Soumma,Hassan Ghasemzadeh", "background": "反事实解释通过描述最小输入特征变化来改变模型的预测结果，使其对人类具有可理解性。现有方法通常通过手工制定的约束或特定领域的知识来强制执行跨特征的依赖性，这些方法限制了其泛化能力和对数据中复杂、非线性关系的捕捉能力。此外，它们很少考虑到用户指定的偏好，从而产生的解释可能在因果关系上不合理或不具备实施的可能性。现有方法的局限性促使研究者开发新的框架来解决这些问题，现阶段需要一个能在不依赖显式领域知识的情况下自动保持复杂跨特征依赖性的框架，同时能够允许用户冻结不能或不希望改变的属性，以实现高质量的反事实解释生成。", "innovation": "提出了一种名为RealAC的领域无关框架，用于生成现实且可行动的反事实解释，它可以自动保留复杂跨特征的依赖关系，而不依赖于显式领域知识，通过在事实和反事实实例之间的特征对联合分布进行对齐来实现这一目标。此外，该框架还允许最终用户通过阻止冻结属性优化中的变化来锁定特定属性。实验结果表明，RealAC在现实与行动性之间取得平衡，优于最先进的基线方法和基于大型语言模型的反事实生成技术，在因果边缘分数、依赖保持分数和IM1现实度量上表现出色，为因果感知和用户中心的反事实生成提供了解决方案", "conclusion": "RealAC在多个数据集上展示了其在现实性与行动性方面的优越性，它提供了一个因果关系感知且用户中心的反事实解释生成方法，通过不依赖于显式的领域知识自动保持复杂的跨特征依赖性，同时允许用户冻结某些属性以调整反事实解释。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10480", "html_url": "https://arxiv.org/abs/2508.10480", "title": "PInet：通过正交投影层优化具有严格约束的神经网络", "title_en": "Pinet: Optimizing hard-constrained neural networks with orthogonal projection layers", "authors": "Panagiotis D. Grontas,Antonio Terpin,Efe C. Balta,Raffaello D'Andrea,John Lygeros", "background": "本文介绍了一种神经网络的输出层，能够确保满足凸约束条件。利用算子分裂法在前向传播过程中实现快速可靠的投影操作，采用隐式函数定理进行反向传播，从而将PInet作为一种设计可行的优化代理应用于参数约束优化问题。相比于传统求解器，PInet可以更快地解决单个问题，并且对于批量问题，速度显著提高。", "innovation": "1. 提出了一种新的神经网络输出层，确保神经网络在前向传播过程中满足凸约束条件。\n2. 可快速可靠地进行投影操作，同时采用隐式函数定理进行反向传播。\n3. PInet在训练时间、解决方案质量以及超参数调整的鲁棒性方面超越了现有的学习方法，同时保持了相近的推理时间。\n4. PInet有效地处理了具有非凸轨迹偏好的多车辆运动规划问题，并提供了一个在JAX中实现的GPU兼容包，附带有效的调参技巧。", "conclusion": "PInet通过正交投影层显著提高了严格约束神经网络的优化效率和解决方案质量，相比传统方法和现有学习方法更加高效和鲁棒，并且还能够在多车辆运动规划方面提供有效解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10489", "html_url": "https://arxiv.org/abs/2508.10489", "title": "使用联合嵌入预测架构从任意数据学习动态系统的状态空间模型", "title_en": "Learning State-Space Models of Dynamic Systems from Arbitrary Data using Joint Embedding Predictive Architectures", "authors": "Jonas Ulmen,Ganesh Sundaram,Daniel Görges", "background": "随着联合嵌入预测架构（JEPAs）的出现，它们在能力上似乎超过了基于重建的方法，该研究引入了一种新的方法，使用任意观察数据和连续时间动态系统创建世界模型。该方法将序列嵌入与神经微分方程（神经ODEs）结合起来，使用促使嵌入具备压缩性质和状态转换的利普希茨常数的损失函数，构建一个井然有序的潜在状态空间。", "innovation": "该方法利用联合嵌入预测架构和神经微分方程，结合损失函数确保嵌入的压缩性质和状态转化的利普希茨常数，从而建立有序的潜在状态空间。通过仅使用图像数据生成简单摆系统的结构化潜在状态空间模型，展示了该方法的有效性，同时为更广泛的机器人应用提供了更通用的控制算法和估计算法技术.", "conclusion": "该方法的成功表明，利用JEPAs和神经微分方程生成结构化的潜在状态空间模型是创建基本有效的控制算法和估计技术的有效途径，为机器人等领域的广泛应用打开了新的技术可能性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10479", "html_url": "https://arxiv.org/abs/2508.10479", "title": "真实世界推荐系统中的混杂问题是普遍存在的问题", "title_en": "Confounding is a Pervasive Problem in Real World Recommender Systems", "authors": "Alexander Merkov,David Rohde,Alexandre Gilotte,Benjamin Heymann", "background": "未观察到的混杂因素是指未测量的特征同时影响治疗和结果，导致因果效应估计偏差。这一问题在经济学、医学、生态学或流行病学的观察研究中会弱化研究结果。尽管推荐系统利用完全可观测的数据似乎不受此问题影响，但许多标准做法却导致可观测特征被忽略，实际上造成了相同的问题。论文指出，许多常见的做法如特征工程、A/B测试和模块化实际上会将混杂引入推荐系统，损害其性能，并提供了这一现象的示例及通过仿真研究支持的建议，旨在帮助从业者减少或避免混杂影响的实际系统中的影响.", "innovation": "论文揭示了许多推荐系统中常见的实践措施如特征工程、A/B测试和模块化等实际上引入了混杂因素，削弱了推荐系统的性能。它强调了未观察到的混杂因素通过这些实践可在实际系统中产生复杂的影响。同时，论文提供了仿真研究支持的实际建议，以帮助从业者减少或避免混杂效应的影响.", "conclusion": "研究强调未观察到的混杂因素在推荐系统中的普遍存在，提出多种实际示例，并基于仿真研究提供了具体建议，旨在减少或避免实际系统中的混杂影响，提升推荐系统的性能."}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10490", "html_url": "https://arxiv.org/abs/2508.10490", "title": "基于梯度的解释的复杂性-忠实性权衡", "title_en": "On the Complexity-Faithfulness Trade-off of Gradient-Based Explanations", "authors": "Amir Mehrpanah,Matteo Gamba,Kevin Smith,Hossein Azizpour", "background": "ReLU网络在视觉数据中广泛应用，但其具有尖锐的转换，有时依赖于个别像素进行预测，这使得基于梯度的传统解释变得嘈杂且难以理解。现有方法如GradCAM通过生成替代模型来平滑这些解释，但这样会牺牲解释的忠实性。目前缺乏一个系统的方法来分析和量化平滑、忠实性及其在解释中的权衡关系。因此，文献中缺乏一种系统化的框架来评估这些权衡关系，尤其是关于替代模型及其对高频信息贡献的量化和正则化方法。", "innovation": "本文提出了一种统一的谱框架，系统地分析和量化了平滑、忠实性以及它们之间的权衡。通过这种方法，作者量化并正则化ReLU网络对高频信息的贡献，提供了一种有原则的方法来识别这一权衡。该分析揭示了基于替代模型的平滑如何扭曲解释，从而正式定义并测量了不同后处理方法的“解释差距”。", "conclusion": "通过该理论框架，作者验证了不同设计选择、数据集和消融研究中的理论发现，证实了对于基于梯度的解释，复杂性和忠实性之间的权衡是一个关键问题，需要通过系统化的框架来解决，以更好地理解和解释深度学习模型的决策过程。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10491", "html_url": "https://arxiv.org/abs/2508.10491", "title": "对比编码输出码：基于对比学习的输出码学习以防御对抗攻击", "title_en": "Contrastive ECOC: Learning Output Codes for Adversarial Defense", "authors": "Che-Yu Chou,Hung-Hsuan Chen", "background": "尽管一热编码在多类别分类中广泛应用，但并非总是最有效的编码机制。纠错输出码（ECOC）通过将每个类别映射到唯一的码字来解决多类别分类问题。传统ECOC方法依赖于手动设计或随机生成的码本，这既耗时又可能在不同数据集上得不到最优结果。本文旨在通过对比学习方法自动学习码本，从而直接从数据中学习并适应多类别分类。", "innovation": "本文提出三种基于对比学习的自动码本学习模型，允许码本直接从数据中学习，而非依赖手动设计或随机生成的码本。实验结果表明，相对于两个基线模型，提出的模型在四个数据集上显示出更好的对抗攻击鲁棒性。", "conclusion": "本文通过基于对比学习的自动编码输出码模型，改进了ECOC方法的鲁棒性，特别是在对抗攻击场景下取得了显著效果。研究结果表明，所提出的模型方法具有实用价值和应用前景。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10494", "html_url": "https://arxiv.org/abs/2508.10494", "title": "统一多代理框架以实现通用跨模态理解和生成", "title_en": "A Unified Multi-Agent Framework for Universal Multimodal Understanding and Generation", "authors": "Jiulin Li,Ping Huang,Yexin Li,Shuo Chen,Juewen Hu,Ye Tian", "background": "现实世界的多模态应用通常需要能够跨文本、图像、音频和视频等多种模态进行理解和生成的能力。然而，目前将自回归语言模型（LLMs）用于推理和扩散模型用于高保真生成的集成仍然具有挑战性。现有的方法依赖于僵化的管道或紧密耦合的架构，限制了灵活性和可扩展性。", "innovation": "作者提出了MAGUS（Multi-Agent Guided Unified Multimodal System），这是一个模块化的框架，通过认知和决断两个阶段统一了多模态理解和生成。MAGUS允许符号多代理在共享的文本工作空间中协作。认知阶段采用三种基于模态的LLM代理（感知者、规划者和反思者）进行协作对话，以进行结构化理解和规划。决断阶段引入了增长感知搜索机制，该机制以互补的方式协调基于LLM的推理和基于扩散的生成。MAGUS支持即插即用可扩展性、任何到任何模态转换的可扩展性以及语义对齐，无需联合训练。", "conclusion": "在图像、视频和音频生成以及跨模态指令跟随等多个基准上的实验结果表明，MAGUS优于强大的基线和最先进的系统。特别是在MME基准上，MAGUS超过了强大的封闭源模型GPT-4o。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10531", "html_url": "https://arxiv.org/abs/2508.10531", "title": "投影耦合扩散模型在测试时受限联合生成中的应用", "title_en": "Projected Coupled Diffusion for Test-Time Constrained Joint Generation", "authors": "Hao Luan,Yi Xian Goh,See-Kiong Ng,Chun Kai Ling", "background": "修改测试时抽样方法已成为扩散算法的重要扩展，目的在于不影响重新训练整体扩散模型的前提下偏向生成过程以实现特定目标。然而，如何在不昂贵重新训练的情况下从多个预训练的扩散模型中生成联合相关样本并同时施加特定任务约束仍然是一个挑战。", "innovation": "提出了投影耦合扩散（PCD），一种新的测试时框架，用于约束联合生成。PCD引入耦合引导项来促进扩散模型之间的协调，并在每次扩散步骤中引入投影步骤以强制执行硬约束。", "conclusion": "实验结果表明，PCD在图像对生成、物体操作和多机器人运动规划等应用场景中有效增强了耦合效果，并且保证了约束条件的满足，同时没有额外的计算成本。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10520", "html_url": "https://arxiv.org/abs/2508.10520", "title": "基于强化学习的非局域蒙特卡洛方法", "title_en": "Nonlocal Monte Carlo via Reinforcement Learning", "authors": "Dmitrii Dobrynin,Masoud Mohseni,John Paul Strachan", "background": "针对组合优化问题中的复杂成本函数进行优化或采样一直是一个跨学科且应用广泛的难题。传统基于马尔可夫链蒙特卡洛（MCMC）算法，如模拟退火或平行退火，在处理具有重叠区间的最困难基准问题时效果不佳，尤其是在所谓的重叠区和间隙区间内，常规MCMC算法难以解冻僵硬变量、跳出局部最优解并采样高质且多样化的解。", "innovation": "本文提出了一种通过强化学习（RL）训练非局域蒙特卡洛（NMC）算法非局域转换策略的方法。之前设计这些策略主要依赖于表象的方法。本文方法仅通过观察配置空间探索的能量变化作为RL奖励和局部最小能量景观几何作为RL状态，训练出来的算法在处理硬的均匀随机和无标度随机4-SAT基准问题时，相较标准MCMC算法和非局域模拟退火算法，在残余能量、解的时间和多样性方面表现更优。", "conclusion": "实验表明，通过基于增强学习训练的非局域策略可以显著提高NMC算法的性能，特别是在处理复杂的计算机相变区域时，能够更有效地采样高质量且多样化的解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10548", "html_url": "https://arxiv.org/abs/2508.10548", "title": "使用门控奖励稳定长期多轮强化学习", "title_en": "Stabilizing Long-term Multi-turn Reinforcement Learning with Gated Rewards", "authors": "Zetian Sun,Dongfang Li,Zhuoen Chen,Yuhuai Qin,Baotian Hu", "background": "在长期强化学习任务中，奖励稀疏性是一个重大挑战。现有的基于结果的奖励塑造方法难以定义有意义的即时奖励且容易引入偏差，需要显式的任务分解。另外，基于验证的奖励塑造使用逐步批评家，但在即时奖励与长期目标之间的对齐不当可能导致奖励作弊和次优策略。在软件工程（SWE）任务中，多轮推理与基于规则的验证是关键的。现有方法在即时奖励与长期目标对齐不足时导致性能下降。", "innovation": "该工作提出了一种SWE导向的RL框架，支持多轮互动、基于docker的执行和可定制的奖励函数。同时，本文提出了门控奖励积累(G-RA)，这是一种新颖的方法，只有在高层（长期）奖励达到预定义阈值时才会积累即时奖励，确保强化学习优化的稳定性。实验表明，G-RA提高了完成率和修改率，并避免了因奖励对齐不当导致的策略退化。", "conclusion": "研究成果强调了长期强化学习中奖励积累平衡的重要性，并提供了一种实用解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10541", "html_url": "https://arxiv.org/abs/2508.10541", "title": "使用蛋白质语言模型和泛化导向评估推动准确的过敏原预测", "title_en": "Driving Accurate Allergen Prediction with Protein Language Models and Generalization-Focused Evaluation", "authors": "Brian Shing-Hei Wong,Joshua Mincheol Kim,Sin-Hang Fung,Qing Xiong,Kelvin Fu-Kiu Ao,Junkang Wei,Ran Wang,Dan Michelle Wang,Jingying Zhou,Bo Feng,Alfred Sze-Lok Cheng,Kevin Y. Yip,Stephen Kwok-Wing Tsui,Qin Cao", "background": "过敏原，通常是能够触发不良免疫反应的蛋白质，构成了重要公共卫生挑战。为了准确识别过敏原蛋白质，人们需要一种有效的工具。现有的研究方法存在局限性，无法全面应对复杂的真实世界挑战。", "innovation": "本文介绍了一种名为Applm（Allergen Prediction with Protein Language Models）的计算框架，利用了一个包含100亿参数的xTrimoPGLM蛋白质语言模型。Applm在多种任务中表现出色，包括识别训练集中缺乏类似实例的新过敏原、区分高度序列相似的过敏原与非过敏原，以及评估可能导致蛋白质序列变化较小的功能后果。研究证实，xTrimoPGLM通过捕捉蛋白质序列的一般特性，对Applm的性能至关重要。", "conclusion": "除了提供Applm开源软件外，本文还提供了精心整理的基准数据集，以便未来的研究。实验结果表明，Applm在多种任务中表现优异，能够准确预测过敏原，具有广泛的应用前景。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10581", "html_url": "https://arxiv.org/abs/2508.10581", "title": "技术报告：借助LLM赋能的协同飞行员促进因果推理方法的应用", "title_en": "Technical Report: Facilitating the Adoption of Causal Inference Methods Through LLM-Empowered Co-Pilot", "authors": "Jeroen Berrevoets,Julianna Piskorz,Robert Davis,Harry Amad,Jim Weatherall,Mihaela van der Schaar", "background": "从医疗、经济学到公共政策等多个领域，基于观察数据估算治疗效果（TE）是一项至关重要的但又复杂的工作。尽管机器学习和因果推理领域的最新进展为这种估计提供了强大的技术手段，但由于需要深厚的因果假设、调整策略和模型选择方面的专业知识，这些技术的应用仍然有限。", "innovation": "本文介绍了一种名为CATE-B的开源协同飞行员系统，该系统利用大型语言模型（LLMs）在代理框架内引导用户完成从头到尾的治疗效果估计过程。CATE-B通过因果发现和LLM基于的边定向来构建结构性因果模型，通过一种新颖的最小不确定性调整集准则来识别稳健的调整集，并根据因果结构和数据集特征选择合适的回归方法。", "conclusion": "通过结合因果推理和智能、交互式的辅助，CATE-B降低了严格的因果分析门槛，并为自动治疗效果估算提供了一个新的基准。\n"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10587", "html_url": "https://arxiv.org/abs/2508.10587", "title": "使用生成对抗变换器进行能源数据的自监督时间超级分辨率", "title_en": "Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer", "authors": "Xuanhao Mu,Gökhan Demirel,Yuzhe Zhang,Jianlei Liu,Thorsten Schlachter,Veit Hagenmeyer", "background": "基于能量系统模型设计和操作能量网络时，需要通过时间序列重采样解决时间粒度的差距问题。传统的时间序列插值方法虽然计算效率高，但会导致重要信息损失或增加噪声。虽然高级模型如时间序列生成模型、超分辨率模型和插补模型显示出潜力，但也面临根本性挑战。这些模型在无需高分辨率真实数据的情况下进行训练，解决了传统方法的许多问题，展示了在未标注高分辨率数据情况下进行时间序列生成的优势。这种方法通过生成对抗变换器（GATs）进行训练，能够减少插值任务的均方根误差（RMSE）并提高模型预测控制的应用场景的准确性。相比传统插值方法，该方法将插值任务的RMSE降低了9%，并提高了MPC应用场景的准确性13%。", "innovation": "该论文提出了一种新的方法——使用生成对抗变换器（GATs）在没有高分辨率真实数据的情况下进行时间序列的超分辨率处理，从而解决了传统插值方法在时间序列插值时存在的信息损失和噪声增加问题。该方法能够显著降低插值任务的均方根误差，提高模型预测控制场景的准确性。", "conclusion": "研究表明，使用生成对抗变换器进行能源数据的时间序列超分辨率处理，不仅解决了传统方法的不足，还能够在未标注高分辨率数据的情况下进行有效训练和应用，从而提高了时间和能量网络设计与操作的精度和效率。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10594", "html_url": "https://arxiv.org/abs/2508.10594", "title": "FreeGAD: 无需训练的有效图异常检测方法", "title_en": "FreeGAD: A Training-Free yet Effective Approach for Graph Anomaly Detection", "authors": "Yunfeng Zhao,Yixin Liu,Shiyuan Li,Qingfeng Chen,Yu Zheng,Shirui Pan", "background": "图异常检测（GAD）旨在识别图中与大多数节点不同的节点，在社交网络和电子商务等领域具有重要作用。虽然当前基于深度学习的GAD方法取得了进展，但现有方法往往因复杂的训练过程和高成本而难以部署和扩展。", "innovation": "本文受实验发现的启发，提出了一种无需训练的有效GAD方法——FreeGAD。该方法利用关联门残差编码器生成异常感知的表示，并通过锚节点引导的统计偏差来计算异常分数。与现有的基于深度学习的GAD方法相比，FreeGAD在多个跨领域的基准数据集上实现了优越的异常检测性能、效率和可扩展性。", "conclusion": "实验结果表明，FreeGAD在无需训练和迭代优化的情况下，在多个数据集上实现了在异常检测性能、效率和可扩展性方面的优异表现。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10595", "html_url": "https://arxiv.org/abs/2508.10595", "title": "基于梯度的解释方法的光谱属性研究", "title_en": "On Spectral Properties of Gradient-based Explanation Methods", "authors": "Amir Mehrpanah,Erik Englesson,Hossein Azizpour", "background": "深入理解深度网络的行为对于提高我们对它们结果的信心至关重要。尽管已有大量工作致力于解释它们的预测结果，但研究者们仍面临着可靠性问题，这些问题可以归因于缺乏正式的形式化方法。", "innovation": "本文采用了新颖的概率和光谱视角，正式分析了解释方法，揭示了使用梯度导致的普遍光谱偏差，并阐明了一些已通过实验发现的常见设计选择，特别是平方梯度和输入扰动的使用。进一步地，作者描述了如何通过扰动超参数的选择影响解释的不一致性，并提出基于本文所提出的正式化方法的两种改进措施：确定标准扰动尺度的机制以及我们称之为光谱透镜的聚合方法。最后，作者通过定量评估验证了其理论成果。", "conclusion": "本文通过光谱和概率的角度，为解释方法提供了新的正式分析，并提出了新的改进措施，从而提升了对基于梯度方法的理解和可靠性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10608", "html_url": "https://arxiv.org/abs/2508.10608", "title": "多目标策略梯度方法在多目标强化学习中的方差减小", "title_en": "Variance Reduced Policy Gradient Method for Multi-Objective Reinforcement Learning", "authors": "Davide Guidobene,Lorenzo Benedetti,Diego Arapovic", "background": "多目标强化学习(MORL)是对传统强化学习(RL)的扩展，旨在同时优化多个通常相互冲突的目标，而不是仅仅关注单一奖励。在复杂的决策场景中，代理必须平衡各种目标之间的权衡，例如最大化性能的同时减少成本。在MORL问题中，目标通常使用非线性标量化函数进行组合。目前，使用策略梯度方法(PGMs)是最有效的处理大且连续的状态-行动空间的方式，但现有的MORL中的PGMs面临着样本效率低的问题，需要大量的数据才能有效运作。以往解决这一问题的方法依赖过于严格的假设，导致失去了PGMs在处理大型状态-行动空间中的可扩展性。", "innovation": "本文通过实现方差减小技术来减少策略梯度的样本复杂性，同时保持一般性假设，从而提高样本效率。", "conclusion": "本文提出了一种方差减小的策略梯度方法来解决多目标强化学习中的样本效率问题，能够更加有效和可扩展地处理此类问题。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10583", "html_url": "https://arxiv.org/abs/2508.10583", "title": "基于GNN的统一深度学习", "title_en": "GNN-based Unified Deep Learning", "authors": "Furkan Pala,Islem Rekik", "background": "深度学习模型在医疗影像领域难以保持泛化能力，特别是在分布断裂场景下，由于成像技术、获取协议、患者群体、人口统计学和设备的不同，导致了分布的变化。每个医疗机构可能需要训练不同的模型，这些模型在学习任务、宽度和深度上有所不同，以适应当地数据。例如，一家医院可能使用欧几里得架构（如MLPs和CNNs）处理表格或网格图像数据，而另一家医院可能需要非欧几里得架构（如图神经网络GNNs）处理不规则数据，如脑连接组数据。如何在不同数据集之间统一训练这些异构模型，并增强每个模型的泛化能力，目前仍是个未解决的问题。本研究提出了统一学习，这是一种新的范式，通过图表示将每个模型统一到共享的图学习空间中，然后用GNN指导这些统一模型的优化。这种方法通过分离个体模型的参数并通过统一GNN（uGNN）控制它们，支持不同架构（MLPs、CNNs、GNNs）和分布之间的参数共享和知识迁移，从而改进泛化能力。", "innovation": "该研究提出了一种新的统一学习方法，通过将每个模型统一到共享的图学习空间中，并使用图神经网络（GNN）指导模型优化，从而实现异构模型的统一训练和优化。这种方法通过控制个体模型参数并通过统一GNN支持参数共享和知识迁移，适用于不同的架构和分布，提高了泛化能力。该方法在MorphoMNIST和两个MedMNIST基准（PneumoniaMNIST和BreastMNIST）上的实验证明，即使模型在独特分布中训练，在混合数据中测试时也显示出强大的鲁棒性，并对未见过的大分布变化数据具有强大的鲁棒性。", "conclusion": "结果表明，基于GNN的统一深度学习方法在训练独特分布模型并在混合分布数据上测试时提高了性能，展示了对未见过的大分布变化数据的强大鲁棒性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10598", "html_url": "https://arxiv.org/abs/2508.10598", "title": "Oops!... 他们再次偷走它：在拆分学习中的攻击", "title_en": "Oops!... They Stole it Again: Attacks on Split Learning", "authors": "Tanveer Khan,Antonis Michalas", "background": "拆分学习（SL）是一种合作学习方法，通过将数据保留在客户端并仅与服务器共享中间输出来提高隐私。然而，SL的分布特性引入了新的安全挑战，需要全面探索潜在攻击。本文系统地回顾了各种对SL的攻击，根据攻击者的角色、隐私风险类型、数据泄露时间以及存在的漏洞等因素进行分类。此外，本文还分析了现有的防御方法，包括加密方法、数据修改方法、分布式技术以及混合解决方案。研究发现揭示了安全漏洞，指出现有防御方法的有效性和局限性。通过识别开放挑战和未来方向，本文为改善SL隐私问题和指导进一步研究提供了有价值的信息。", "innovation": "本文系统地回顾了拆分学习（SL）中的各种攻击，并根据攻击者角色、隐私风险类型、数据泄露时间以及存在的漏洞等因素进行了分类。同时，分析了现有的防御方法，包括加密方法、数据修改方法、分布式技术和混合解决方案，发现安全漏洞并揭示了现有防御方法的有效性和局限性。", "conclusion": "本文通过识别Open Challenges和未来方向，提供了改进拆分学习隐私问题的信息，并为后续研究指明了道路。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10644", "html_url": "https://arxiv.org/abs/2508.10644", "title": "条件信息瓶颈在多模态融合中的应用：解决讽刺检测中的捷径学习问题", "title_en": "Conditional Information Bottleneck for Multimodal Fusion: Overcoming Shortcut Learning in Sarcasm Detection", "authors": "Yihua Wang,Qi Jia,Cong Xu,Feiyu Chen,Yuhan Liu,Haotian Zhang,Liang Jin,Lu Liu,Zhichun Wang", "background": "多模态讽刺检测是一个复杂的任务，需要区分不同模态之间的细微互补信号，同时过滤掉无关信息。许多先进的方法依赖于从数据集学习捷径而不是提取与讽刺相关的核心特征。实验显示，捷径学习会损害模型在现实世界场景中的泛化能力。此外，通过系统的实验揭示了当前多模态融合策略在讽刺检测中的弱点，强调了有效模态融合的重要性。", "innovation": "提出了条件信息瓶颈的多模态融合模型(MCIB)，通过移除捷径信号改进了MUStARD++。该模型能够在不依赖捷径学习的情况下实现高效的多模态融合，提高了讽刺检测的性能。", "conclusion": "实验结果表明，MCIB在讽刺检测任务中达到了最佳性能，无需依赖捷径学习。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10628", "html_url": "https://arxiv.org/abs/2508.10628", "title": "基于项目反应理论的实例质量驱动数据分区超越随机采样", "title_en": "Beyond Random Sampling: Instance Quality-Based Data Partitioning via Item Response Theory", "authors": "Lucas Cardoso,Vitor Santos,José Ribeiro Filho,Ricardo Prudêncio,Regiane Kawasaki,Ronnie Alves", "background": "机器学习（ML）模型的稳健验证至关重要，但传统数据分区方法往往忽视了每实例本身的内在质量。", "innovation": "该研究提出使用项目反应理论（Item Response Theory, IRT）参数来表征并指导模型验证阶段数据集的分区策略，通过IRT进行数据分区影响多个ML模型在四个表格数据集上的表现得到了评估。研究发现，IRT揭示了实例的固有异质性，并突显了数据集中存在具有信息性的子群体。基于IRT，创建了均衡的分区，帮助更好地理解模型偏差与方差之间的权衡。", "conclusion": "猜测参数证明是决定性因素：使用高猜测概率的数据进行训练显著影响模型性能，导致精度低于50%的情况，而其他分区在同一数据集上达到了70%以上的性能。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10646", "html_url": "https://arxiv.org/abs/2508.10646", "title": "SPHENIC: 为空间转录组学提供拓扑指导的多视角聚类方法", "title_en": "SPHENIC: Topology-Informed Multi-View Clustering for Spatial Transcriptomics", "authors": "Chenkai Guo,Yikai Zhu,Jing Yangum,Renxiang Guan,Por Lip Yee,Guangdun Peng,Dayu Hu", "background": "空间转录组学聚类通过整合空间位置信息，能够提供更全面的细胞亚群识别视角。然而，现有方法存在两个局限性：（i）拓扑学习通常仅考虑单个细胞的表示或它们的交互图；但由于空间转录组学谱线经常具有噪声特性，这种方法易受低质量的拓扑信号影响；（ii）对空间邻域信息的建模不足导致低质量的空间嵌入。", "innovation": "SPHENIC 提出了一种新颖的拓扑引导的空间持久同调增强的邻域集成聚类方法。通过将不变的拓扑特征整合进聚类网络，实现稳定表示学习。此外，设计的空间约束和分布优化模块 (SCDOM) 用于构建高质量的空间嵌入，这些嵌入能更真实地反映细胞分布，提高邻接与非邻接细胞嵌入的相似度。", "conclusion": "SPHENIC 在对 14 个基准空间转录组学切片的广泛实验中，表现出在空间聚类任务上的优越性能，相较于最先进方法的性能提升为 3.31% 到 6.54%。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10684", "html_url": "https://arxiv.org/abs/2508.10684", "title": "MDNS：通过随机最优控制的掩码扩散神经采样器", "title_en": "MDNS: Masked Diffusion Neural Sampler via Stochastic Optimal Control", "authors": "Yuchen Zhu,Wei Guo,Jaemoo Choi,Guan-Horng Liu,Yongxin Chen,Molei Tao", "background": "研究了从给定的目标概率质量函数π∝e^-U中学习神经采样器的问题，该函数已知到归一化常数，在统计物理、机器学习、组合优化等领域的离散状态空间中是一项重要任务。", "innovation": "提出了一种新颖的框架MDNS（Masked Diffusion Neural Sampler），通过一系列学习目标对两个路径测量进行对齐，理论上基于连续时间马尔科夫链的随机最优控制，解决了大离散状态空间和多模态分布下的采样问题。", "conclusion": "MDNS在多种具有不同统计特性的分布上的实验验证了其高效性和可扩展性，能够准确地从目标分布中采样，相较于其他基于学习的基线方法表现出了显著的优势。同时提供了消融研究和扩展研究来证明该框架的有效性和潜力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10651", "html_url": "https://arxiv.org/abs/2508.10651", "title": "基于逻辑本体Weisfeiler-Leman变体和表格化方法的图学习", "title_en": "Graph Learning via Logic-Based Weisfeiler-Leman Variants and Tabularization", "authors": "Reijo Jaakkola,Tomi Janhunen,Antti Kuusisto,Magdalena Ortiz,Matias Selin,Mantas Šimkus", "background": "本文介绍了一种基于Weisfeiler-Leman算法变体将图数据表格化，然后应用表格数据方法进行图分类的新颖方法。研究了所有逻辑框架修改得到的完整Weisfeiler-Leman变体类别，并精确地理论化了其表达能力。然后分别测试了两种选定变体在十二个基准数据集上的性能，范围涵盖不同的领域。实验表明，该方法在准确性方面与最先进的图神经网络和图核相当，但在某些数据集上更高效，无论是时间效率还是内存效率方面。文章还简要讨论了直接从图数据集中提取可解释的模态逻辑公式的可能性", "innovation": "提出了新的基于Weisfeiler-Leman算法变体和表格化方法的图分类方法；全面研究所提出的Weisfeiler-Leman变体类；测试了两种选定变体在多种类型的基准数据集上的表现；结果显示该方法在某些数据集上的时间和计算资源效率高于现有方法", "conclusion": "该研究提出的基于逻辑本体的Weisfeiler-Leman变体方法在许多数据集上显示出与最先进的图神经网络和图核相当的性能，且在资源效率方面表现更佳。直接从图数据集中提取的可解释模态逻辑公式也提供了方法的可解释性潜力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10629", "html_url": "https://arxiv.org/abs/2508.10629", "title": "基于能量模型的蛋白质突变效应预测", "title_en": "Energy-Based Models for Predicting Mutational Effects on Proteins", "authors": "Patrick Soga,Zhenyu Lei,Yinhan He,Camille Bilodeau,Jundong Li", "background": "蛋白质工程和蛋白质-蛋白质相互作用（PPI）工程在药物发现中预测蛋白质结合自由能变化（$\boldsymbol{\text{ΔΔG}}$）是一项至关重要的任务。前人的研究发现$\boldsymbol{\text{ΔΔG}}$与熵之间存在高度相关性，并通过侧链角度和残基身份等生物重要对象的概率来估计$\boldsymbol{\text{ΔΔG}}$。然而，估计蛋白质复合物的完整构象分布目前通常认为是不可行的。该研究提出了新的构象偏置模型直接估计蛋白质复合物的构象概率，从而绕过这一问题。具体地，研究将$\boldsymbol{\text{ΔΔG}}$分解为由逆折叠模型估计的序列成分和由能量模型估计的结构成分，假设结合态和未结合态在热力学平衡状态下的等价性简化了每种状态的自退化估计。与其他基于深度学习的方法不同，该方法通过将序列对数似然比方法与基于统计力学的$\boldsymbol{\text{ΔΔE}}$术语结合起来，引入了能量基础的物理诱导偏差，从而在$\boldsymbol{\text{ΔΔG}}$预测和针对SARS-CoV-2的抗体优化中显示出超越现有结构和序列深度学习方法的优势。", "innovation": "研究提出了一种新的构象偏置模型，通过直接估计蛋白质复合物的构象概率来预测$\boldsymbol{\text{ΔΔG}}$。该方法将$\boldsymbol{\text{ΔΔG}}$分解为序列成分和结构成分，并通过假设结合态和未结合态的热力学平衡简化了每种状态的自退化估计。该方法通过引入基于统计力学的$\boldsymbol{\text{ΔΔE}}$术语来整合序列对数似然比方法，显示出了优于现有深度学习方法的优势。", "conclusion": "研究成功展示了基于能量模型的新方法在$\boldsymbol{\text{ΔΔG}}$预测和抗体优化中的优越性，超越了现有的结构和序列基于的深度学习方法。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10713", "html_url": "https://arxiv.org/abs/2508.10713", "title": "在GPU上进行天线电磁仿真以应用于机器学习", "title_en": "Electromagnetic Simulations of Antennas on GPUs for Machine Learning Applications", "authors": "Murat Temiz,Vemund Bakken", "background": "在天线设计与优化中，利用机器学习方法进行仿真，特别是基于图形处理单元（GPU）的开源电磁（EM）仿真软件gprMax，因其高效的计算能力而成为关键。然而，典型的商业EM仿真软件在类似应用中表现出较高的高效性。本研究聚焦于利用GPU进行天线电磁仿真，以支持机器学习和代理模型应用。鉴于电磁仿真计算复杂度高，生成足够的训练样本面临挑战。", "innovation": "该研究提出了一种基于开源EM仿真软件gprMax并利用GPU驱动的天线仿真框架，专门应用于机器学习模型的天线设计与优化。此外，研究还对比了主流的机器学习和深度学习模型在估算天线参数的性能，测试了不同级别的GPU和CPU在仿真计算能力上的差异。研究结果表明，即使是入门级的GPU，在仿真计算性能上也显著优于高端CPU，高端游戏用GPU的计算性能更是高达高端CPU的18倍以上。同时，该开源EM仿真软件在天线参数仿真结果上与商业软件相当，特别是在足够精细的空间分辨率下。", "conclusion": "研究展示了利用GPU进行大规模天线仿真，适用于机器学习数据集生成的高效性，而不会因仿真计算复杂度高和时间限制难以满足训练样本需求的问题。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10732", "html_url": "https://arxiv.org/abs/2508.10732", "title": "APFL: 双流最小二乘法的分析个性化联邦学习", "title_en": "APFL: Analytic Personalized Federated Learning via Dual-Stream Least Squares", "authors": "Kejia Fan,Jianheng Tang,Zhirui Yang,Feijiang Han,Jiaxu Li,Run He,Yajiang Huang,Anfeng Liu,Houbing Herbert Song,Yunhuai Liu,Huiping Zhuang", "background": "个性化联邦学习(PFL)面临的一个显著挑战是，如何通过协作训练为个体客户端提供个性化的模型。现有PFL方法往往容易受到非IID（非独立同分布）数据的影响，这严重影响了集体泛化能力，进而损害了后续的个性化努力。", "innovation": "本文为解决PFL中的非IID问题，提出了一种名为APFL（Analytic Personalized Federated Learning，分析个性化联邦学习）的双流最小二乘方法。APFL采用固定基础模型作为特征提取器，并在此基础上开发了双流分析模型，以实现集体泛化和个体个性化。具体来说，APFL包含一个共享的主要流，用于所有客户端的全局泛化，以及一个专门的细化流，用于每个个体客户端的本地个性化。", "conclusion": "在各种数据集上的实验证明了APFL相对于最先进的基线模型的优势，在准确率方面至少有1.10%-15.45%的优势。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10701", "html_url": "https://arxiv.org/abs/2508.10701", "title": "REFN：一种基于网络的强化学习框架以应对1天/多天利用", "title_en": "REFN: A Reinforcement-Learning-From-Network Framework against 1-day/n-day Exploitations", "authors": "Tianlong Yu,Lihong Liu,Ziyi Zhou,Fudu Xing,Kailong Wang,Yang Yang", "background": "由于网络设备广泛部署，且补丁更新延迟较长（平均补丁时间为60天以上），导致利用1天或n天的漏洞会对网络设备造成严重威胁。现有的防御措施，如基于主机的补丁安装和基于网络的过滤，因跨设备的可扩展性有限、与嵌入式或老旧系统的兼容性问题以及错误的部署过程而效果不足。", "innovation": "引入REFN（基于网络的强化学习框架），通过使用基于网络奖励的强化学习（RL）训练大型语言模型（LLMs）来自主地生成网络过滤器，以防止1天或n天的利用。REFN通过以下创新解决了核心挑战：1）通过代理记忆检索（Agentic RAG）知识蒸馏扩展现有LLMs的漏洞修复能力；2）通过语言到网络的VRNF流程桥接LLMs与网络之间的缺口，实现漏洞描述到网络执行的翻译；3）通过在线验证解决模型的幻觉和非确定性问题。", "conclusion": "在22个1天或n天利用家族中，REFN显示了更高的有效性（替代方案的准确率高出21.1%）、更高的效率（平均补丁时间为3.65小时）和更好的可扩展性（能够轻松扩展到10K设备）。REFN代表了初步的尝试，以加速训练LLMs来迅速防止大规模1天或n天的利用。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10751", "html_url": "https://arxiv.org/abs/2508.10751", "title": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models", "title_en": "Pass@k Training for Adaptively Balancing Exploration and Exploitation of Large Reasoning Models", "authors": "Zhipeng Chen,Xiaobo Qin,Youbin Wu,Yue Ling,Qinghao Ye,Wayne Xin Zhao,Guang Shi", "background": "现有的强化学习与可验证奖励（RLVR）通常采用Pass@1作为奖励，存在的问题是难以平衡探索和利用之间的关系，使得策略倾向于保守的行为，容易陷入局部最优。先前的工作采用了Pass@k进行评估，但尚未充分考虑到其与LLM（大型推理模型）在探索能力上的关联。", "innovation": "提出了一种Pass@k训练（Pass@k Training）的方法，利用Pass@k作为奖励来训练策略模型，揭示了探索与利用之间并非天然的矛盾目标，反而可以相互增强。进一步利用分析解法设计优势函数，提出了为RLVR设计优势（advantage）的新方向。", "conclusion": "该研究通过Pass@k Training提高了探索能力，设计了优势函数，并体现了探索和利用之间的互补关系，为未来强化学习与可验证奖励的研究开辟了新的可能性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10649", "html_url": "https://arxiv.org/abs/2508.10649", "title": "地理扩散模型在土地覆盖透水性变化预测中的应用", "title_en": "Geospatial Diffusion for Land Cover Imperviousness Change Forecasting", "authors": "Debvrat Varshney,Vibhas Vats,Bhartendu Pandey,Christa Brelsford,Philipe Dias", "background": "土地覆盖，无论是当前还是未来，都会对许多重要的地球系统过程产生显著影响。例如，不透水表面会加热并加速地表水的径流，减少地表水入渗，从而影响区域水文和洪水风险。虽然区域地球系统模型在高分辨率未来气候变化情景下的水文和大气过程预测方面取得了进步，但对于预测土地利用和土地覆盖变化（LULC）的能力仍不及预期，而这是风险和后果评估的关键输入。本文基于此背景，探索了利用生成性人工智能（GenAI）进行土地覆盖变化预测的新范式，即将LULC预测作为基于历史数据和辅助数据源的数据合成问题来解决。研究利用过去美国本土所有地区的统计数据对不透水层进行预测，并通过实验验证了该方法的有效性。实验结果显示，对于0.7×0.7平方公里以上的平均分辨率，模型的均绝对误差（MAE）优于基线模型。这证实了模型能从历史数据中捕捉到有助于预测未来变化的时空模式。", "innovation": "本文提出了一种新的范式，利用生成性人工智能（GenAI）进行土地覆盖变化预测。具体而言，该研究将LULC预测作为基于历史数据和辅助数据源的数据合成问题来解决。通过实验展示了该方法的有效性，并特别针对不透水层变化进行了预测。实验结果表明，在高分辨率下，生成模型能够捕捉到有价值的时空模式，优于没有变化的基线模型，从而提高了对未来变化的预测能力。", "conclusion": "本文的研究结果表明，利用生成性模型可以有效预测未来土地覆盖变化中的不透水层变化，特别是对于高分辨率的区域。未来的研究将进一步纳入关于地球物理特性的辅助信息，并通过驱动变量模拟不同的情景。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10758", "html_url": "https://arxiv.org/abs/2508.10758", "title": "本级可训练稀疏注意机制对层次点云数据集", "title_en": "Natively Trainable Sparse Attention for Hierarchical Point Cloud Datasets", "authors": "Nicolas Lapautre,Maria Marchenko,Carlos Miguel Patiño,Xin Zhou", "background": "Transformer模型在处理大规模物理系统数据集时，依赖于克服注意力机制的二次时间复杂度问题。本文探讨了将Erwin架构与本级稀疏注意力（NSA）机制结合，以提高大规模物理系统上Transformer模型的效率和感受野，应对二次注意力复杂性的挑战。", "innovation": "创新在于提出了针对非序列化数据适应NSA机制的Erwin NSA模型，并在宇宙学模拟、分子动力学和气压建模三个物理科学数据集上进行评估，结果表明其性能不低于原Erwin模型。此外，还复现了Erwin论文中的实验结果以验证其实现的有效性。", "conclusion": "通过结合Erwin架构与NSA机制，提出的方法能够有效提高Transformer在处理大规模物理系统数据时的效率，并成功在多个物理科学数据集上展示了强大的性能。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10775", "html_url": "https://arxiv.org/abs/2508.10775", "title": "IBEX: 信息瓶颈探索式从粗糙到精细的有限数据分子生成", "title_en": "IBEX: Information-Bottleneck-EXplored Coarse-to-Fine Molecular Generation under Limited Data", "authors": "Dong Xu,Zhangfan Yang,Jenna Xinyi Yao,Shuangbao Song,Zexuan Zhu,Junkai Ji", "background": "三维生成模型在基于结构的药物发现中越来越重要，但由于公共可用的蛋白质-配体复合体数据稀少，现有管道难以学习迁移几何先验并过度拟合训练集偏差。", "innovation": "通过使用PAC-Bayesian信息瓶颈理论来评估每个样本的信息密度，IBEX揭示了不同掩蔽策略如何影响泛化能力，并表明与传统的从头生成方法相比，受限的骨架跳跃任务使模型具备更强的潜在容量和更好的迁移性能。IBEX采用TargetDiff架构和超参数训练，结合L-BFGS优化步骤，在不到一秒的时间内，对每个构象进行精细调整。", "conclusion": "与原TargetDiff相比，IBEX将零射程序预测成功率为53%提高到64%，Vina评分均值从-7.41 kcal/mol提高到-8.07 kcal/mol，并在100个口袋中有57个实现了最佳的Vina能量。IBEX还提高了QED 25%并达到了最先进的有效性和多样性，在大量取值中显著减少了外推误差。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10785", "html_url": "https://arxiv.org/abs/2508.10785", "title": "增强节点级图异常检测中自动编码器的公平性", "title_en": "Enhancing Fairness in Autoencoders for Node-Level Graph Anomaly Detection", "authors": "Shouju Wang,Yuchen Song,Sheng'en Li,Dongmian Zou", "background": "图异常检测（GAD）在多个领域变得越来越重要。随着图神经网络（GNNs）的迅速发展，GAD 方法取得了显著的性能提升。然而，在 GAD 中如何考虑公平性依然少有人研究。基于 GNN 的 GAD 模型可能会继承并放大训练数据中存在的偏见，可能导致不公平的结果。尽管现有努力集中在开发公平的 GNN 上，但大多数方法针对节点分类任务，而模型通常使用简单的层结构而不是基于自动编码器的结构，后者是图异常检测中最常用的架构。因此，需要一个框架来解决基于自动编码器的 GAD 模型中的公平性问题，同时保持 GAD 性能。", "innovation": "本文提出了 DECAF-GAD（消解反事实对抗公平的图异常检测），它通过结构因果模型解纠缠敏感属性来缓解偏见，同时在这一因果框架基础上设计了一个专门的自动编码器架构和一个基于公平性的损失函数。实验表明，DECAF-GAD 不仅可达到竞争力的异常检测性能，还能显著提高公平性指标，优于基线 GAD 方法。", "conclusion": "通过长时间的实验，DECAF-GAD 不仅实现了有竞争力的异常检测性能，还大幅提升了公平性指标，显示了其在节点级图异常检测中的优越性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10815", "html_url": "https://arxiv.org/abs/2508.10815", "title": "在线高斯过程数据减少标准的比较", "title_en": "Comparison of Data Reduction Criteria for Online Gaussian Processes", "authors": "Thore Wietzke,Knut Graichen", "background": "高斯过程（GPs）因其灵活性和能够量化不确定性而在回归和系统识别中得到了广泛应用。然而，其计算复杂性限制了其在小数据集上的适用性。在流数据场景中，数据点不断累积，即使是稀疏高斯过程也无法处理。因此，为了缓解这个问题，出现了在线高斯过程（Online GPs），其通过定义最大数据点预算并移除冗余数据点等方式，试图解决问题。但不同算法在数据减少标准上的评估与应用尚未进行统一比较，实际应用场景可选择性缺乏明确指导。", "innovation": "本文提供了几种数据减少标准的统一比较，分析了这些标准的计算复杂度及减少行为，同时提出了进一步过滤冗余数据点的接受准则。这为选择合适的在线高斯过程算法的数据减少标准提供了实用指南，解决了之前对数据减少标准的无序评估问题。", "conclusion": "本文通过基准函数和真实数据集（包括动态系统识别任务）的评估，为在线高斯过程算法提供了实用的指导方针以选择合适的数据减少标准。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10836", "html_url": "https://arxiv.org/abs/2508.10836", "title": "SoK: Data Minimization in Machine Learning", "title_en": "SoK: Data Minimization in Machine Learning", "authors": "Robin Staab,Nikola Jovanović,Kimberly Mai,Prakhar Ganesh,Martin Vechev,Ferdinando Fioretto,Matthew Jagielski", "background": "数据最小化（DM）原则指出，只收集完成特定任务所必需的数据。这是GDPR和CPRA等主要数据保护法规的基础原则。违反这一原则会导致严重的实际后果，可能面临数百万美元的罚款。特别是在依赖大型数据集的机器学习（ML）应用中，数据最小化变得尤为重要，因此形成了一个新兴的研究领域，即数据最小化在机器学习中的应用（DMML）。现有工作通常关注其他ML隐私和安全问题，但往往没有明确建立与DMML的联系，这导致从业者在实现DM原则时感到困惑，难以理解和应用来自不同研究社区的术语、度量标准和评价标准。", "innovation": "本文提出了一种全面的DMML框架，包括统一的数据管道、对手模型和最小化点。该框架首次系统地回顾了数据最小化和相关方法的研究文献，为从业者和研究者提供了一个结构化的概览，帮助他们更有效地应用数据最小化原则。本文促进了DM为中心的理解，并推动了数据最小化策略在人工智能/机器学习中的更广泛应用。", "conclusion": "本文通过引入全面的框架，系统地梳理了DMML的研究文献，帮助从业者和研究者更好地理解和应用数据最小化原则。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10824", "html_url": "https://arxiv.org/abs/2508.10824", "title": "基于神经科学原则和技术解决方案的增强型记忆变换器系统综述", "title_en": "Memory-Augmented Transformers: A Systematic Review from Neuroscience Principles to Technical Solutions", "authors": "Parsa Omidi,Xingshuai Huang,Axel Laborieux,Bahareh Nikpour,Tianyu Shi,Armaghan Eshaghi", "background": "记忆是智能的基础，能够促进学习、推理和适应性，存在生物系统和人工系统中。虽然Transformer架构在序列建模方面表现出色，但它们在长程上下文保留、连续学习和知识整合方面存在关键限制。本文综述了基于神经科学原则（包括动态多时尺度记忆、选择性注意和巩固）与工程进展（增强型记忆变换器）的统一框架，通过三个分类维度进行组织：功能目标（上下文扩展、推理、知识整合、适应）、记忆表示（参数编码、状态基础、显式、混合）以及融合机制（注意力融合、门控控制、联想检索）。", "innovation": "本文提出了基于神经科学原则的统一框架，将思路上相距甚远的领域结合在一起，并将强化记忆变换器的概念进行了分类，揭示了从静态缓存向适应性、测试时学习系统的转变，并且指出了可扩展性和干扰等持续挑战，并提供了缓解上述挑战的新兴解决方案。这些分析为设计认知启发式、终生学习的Transformer架构提供了路线图和指导思路。", "conclusion": "本文分析表明，核心记忆操作（读取、写入、遗忘和容量管理）正从静态缓存向适应性、测试时学习系统转变。识别了可扩展性和干扰等持续挑战，并提出了一种分层缓冲和惊喜控制更新的新兴解决方案。这些为承载认知启发式的终生学习Transformer架构的发展提供了蓝图。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10866", "html_url": "https://arxiv.org/abs/2508.10866", "title": "高效验证的数据归属证明", "title_en": "Efficiently Verifiable Proofs of Data Attribution", "authors": "Ari Karchmer,Seth Neel,Martin Pawelczyk", "background": "数据归属方法旨在回答有用的反事实问题，例如‘如果机器学习模型使用不同的数据集训练，其预测会是什么？’然而，通过技术如经验影响或‘datamodeling’来估计数据归属模型仍然非常计算密集。这一问题带来了关键的信任挑战：如果只有少数计算资源丰富的实体能够获取数据归属，资源有限的实体如何能够确信提供的归属是“好的”，特别是当它们被用于重要的下游应用（如数据定价）时？", "innovation": "本文提出了一个交互式验证范式来解决这一信任问题。一个不可信且计算能力强的证明者学习数据归属，然后与资源受限的验证者进行交互式证明。该文章的主要成果是一种协议，提供了形式上的完备性、正确性、及效率保证，即在感觉近似正确的（PAC）验证意义上。具体而言，如果证明者和验证者都遵循协议，验证者将以概率1-δ接受ε-接近最优数据归属（即均方误差）。相反，只要证明者偏离协议，即使无限计算能力，验证者也能够检测到这一点，或给出数据归属，仅失败概率为δ。此外，验证者的任务负载随着ε的减小而成线性，即与数据集规模无关。", "conclusion": "我们的协议确保验证者的工作量，以需要独立重新训练模型的数量来衡量，仅按1/ε缩放。技术层面，结果适用于任何由证明者计算的布尔超立方体上的线性函数的高效验证，适用于各种归属任务。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09325", "html_url": "https://arxiv.org/abs/2508.09325", "title": "SegDAC: 以分割驱动的演员评论家方法用于视觉强化学习", "title_en": "SegDAC: Segmentation-Driven Actor-Critic for Visual Reinforcement Learning", "authors": "Alexandre Brown,Glen Berseth", "background": "视觉强化学习（RL）面临着从高维输入和噪声奖励中学习感知和动作的挑战。虽然存在大规模的感知模型，但是将它们有效地集成到能够实现视觉泛化和提高采样效率的RL中仍然是一个未解决的问题。", "innovation": "提出了SegDAC，一种基于分割的演员评论家方法。SegDAC 使用Segment Anything (SAM) 进行对象中心分解，并使用 YOLO-World 通过文本提示将分割与语义联系起来。它包含了一个新颖的基于Transformer的架构，支持每个时间步动态数量的子对象，并通过在线RL有效地学习需关注的子对象，无需使用人工标签。", "conclusion": "通过在Maniskill3上进行评估，这是一个涵盖各种强视觉干扰下的操作任务的挑战性视觉泛化基准，SegDAC展示了显著的视觉泛化能力，尤其是在最困难的设置下性能提升了两倍，并且在所有评估的任务中，在采样效率上达到了或超过了先前的方法。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09991", "html_url": "https://arxiv.org/abs/2508.09991", "title": "实现AI创新与医疗需求对接：BC癌症登记处引入现代自然语言处理的经验教训", "title_en": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry", "authors": "Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji", "background": "自动从临床文档中提取数据在医疗保健环境中能够显著提高效率，但部署自然语言处理（NLP）解决方案面临实际挑战。本研究基于在不列颠哥伦比亚癌症登记处（BCCR）实施各种NLP模型以进行信息提取和分类任务的经验，分享了项目生命周期中的主要经验教训。", "innovation": "提出了一种基于清晰业务目标的技术准确性的开发方法，强调迭代开发、跨学科深度合作和共同设计，包括数据质量的严谨管理、实用模型选择（包括混合方法和适当的基本方法）以及为人机协作审核策略在内的严格错误缓解措施。", "conclusion": "这些实用考虑可以广泛应用于其他医疗保健组织，为成功实施AI/NLP解决方案以增强数据管理流程、最终改善患者护理和公共卫生结果提供了指导。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10899", "html_url": "https://arxiv.org/abs/2508.10899", "title": "一个从文献中提炼知识先验数据集以用于治疗设计", "title_en": "A Dataset for Distilling Knowledge Priors from Literature for Therapeutic Design", "authors": "Haydn Thomas Jones,Natalie Maus,Josh Magnus Ludan,Maggie Ziyu Huan,Jiaming Liang,Marcelo Der Torossian Torres,Jiatao Liang,Zachary Ives,Yoseph Barash,Cesar de la Fuente-Nunez,Jacob R. Gardner,Mark Yatskar", "background": "AI驱动的设计可以大大缩短设计时间并增强新药物的效果。现有的模型利用模拟器探索广阔的分子设计空间，但在缺乏实验先验知识的情况下，可能会违反隐含的约束。例如，在对GuacaMol基准上的一系列模型进行的新分析中，超过60%的分子有很高的概率是突变性。现有的方法存在风控的问题。该研究旨在通过构建数据集来解决这一问题，该数据集从文献中提炼出在实验室环境中使用的化合物的信息，用于指导新的药物设计。", "innovation": "该研究引入了一个名为\textbackslash我们的数据集\textbackslash的数据集，该数据集包含32.3百万对自然语言事实和适当的实体表示（例如SMILES或refseq ID），用于从相关文献中自动发现并总结治疗性实体。研究通过训练LLM、CLIP和LLava架构来联合推理文本和设计目标，并在治疗数据 Commons (TDC) 任务上评估其性能。研究发现，与较大的预训练模型相比，在使用\textbackslash我们的数据集\textbackslash进行监督预测问题的预训练中，具有15M可学习参数的模型在回归和分类任务上表现更好，平均性能与9B模型相当。使用该数据集创建的模型在优化新颖分子时可以作为约束条件，从而提出更安全且几乎同样有效的新分子建议。", "conclusion": "研究成果表明，训练基于\textbackslash我们的数据集\textbackslash的模型在监督预测问题上表现优异，并能够提高新分子安全性，同时保持相当的有效性。该数据集在\textbackslashhref{this https URL}{this http URL}\textbackslash提供下载，未来将随着外部文献的增长提供扩展版本。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09994", "html_url": "https://arxiv.org/abs/2508.09994", "title": "轻声细语，而非大声喧哗：部分抑制的对抗攻击", "title_en": "Whisper Smarter, not Harder: Adversarial Attack on Partial Suppression", "authors": "Zheng Jie Wong,Bingquan Shen", "background": "目前，自动语音识别（ASR）模型被广泛应用于多种场景。然而，最近的研究表明，这些模型存在遭受对抗攻击的可能性，这可能会削弱或干扰模型的输出。我们研究并验证了这些攻击的鲁棒性，探讨是否有可能降低攻击的可察觉性。我们还发现，将优化目标从完全抑制放宽到部分抑制，可以进一步降低攻击的可察觉性。同时，我们研究了对抗攻击的防御措施，并展示了低通滤波器可能是一种有效的防御方法。", "innovation": "本文的主要创新在于通过放宽优化目标，从完全抑制变为部分抑制，进一步降低攻击的可察觉性。此外，我们还探索了对抗攻击的防御方法，提出低通滤波器可能是一种有效的防御手段。", "conclusion": "我们研究了对抗攻击在模型部分抑制情况下的鲁棒性和可降低感知攻击的方法，并展示了低通滤波器可能作为一种有效的防御措施。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10000", "html_url": "https://arxiv.org/abs/2508.10000", "title": "基于知识的自动文本合成技术提升文本分类", "title_en": "AutoGeTS: Knowledge-based Automated Generation of Text Synthetics for Improving Text Classification", "authors": "Chenhao Xue,Yuanzhe Jin,Adrian Carrasco-Revilla,Joyraj Chakraborty,Min Chen", "background": "在实际应用中开发文本分类模型的一大挑战是难以收集满足所有文本类别的足够数据。本文探讨利用大型语言模型（LLM）生成合成数据的方法，利用这些数据改进模型表现，而无需等待更多真实数据的收集与标注。由于LLM对不同的输入示例生成不同的合成数据，本文提出了一个自动工作流程，通过搜索可以产生更“有效”合成数据的输入示例来提升相关模型。", "innovation": "提出了一种基于知识的自动合成技术（AutoGeTS），包括自动搜索有效合成数据生成策略的三个策略，并通过实验结果确定了一个综合算法，该算法根据类别的特点选择适当的战略。实验表明，综合方法在使用LLM改进分类模型方面比单一方法更有效。", "conclusion": "本文提出的方法和策略能够更有效地利用合成数据来提升文本分类模型，使得无需等待增加真实数据即可改进模型性能，为未来改进文本分类模型提供了新的思路。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10008", "html_url": "https://arxiv.org/abs/2508.10008", "title": "在线课程讨论论坛帖子的多维度分类", "title_en": "Multidimensional classification of posts for online course discussion forum curation", "authors": "Antonio Leandro Martins Candido,Jose Everardo Bessa Maia", "background": "自动管理在线课程讨论论坛需要持续更新，频繁训练大型语言模型（LLMs）是一个耗费资源的过程。为了规避昂贵的微调需求，本文提出了并评估了使用贝叶斯融合的方法。这种融合方法结合了预训练通用LLM和本地数据训练分类器的多维度分类得分。", "innovation": "提出了一种贝叶斯融合方法，该方法结合了预训练通用LLM和本地数据训练分类器的多维度分类得分，以提高讨论论坛帖子的分类性能，并与微调LLM的性能进行了竞争。", "conclusion": "性能比较表明，所提出的融合方法在单独使用每个分类器时表现更好，且与LLM的微调方法具有竞争性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09999", "html_url": "https://arxiv.org/abs/2508.09999", "title": "XFacta：适用于多模态大型语言模型检测多模态虚假信息的最新现实数据集和评估", "title_en": "XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs", "authors": "Yuzhuo Xiao,Zeyu Han,Yuhan Wang,Huaizu Jiang", "background": "社交媒体上多模态虚假信息的快速传播需要更有效的检测方法。近年来，利用多模态大型语言模型（MLLMs）的方法显示出了潜在应用，但现有方法存在瓶颈（证据检索与推理），并且现有的数据集要么包含过时的事件，要么是人工合成的数据集，无法反映真实的虚假信息模式。", "innovation": "引入了XFacta，一种实时更新的真实世界数据集，适合评估MLLM性能。系统评估了不同结构和规模的MLLM检测策略，并提出了一种半自动的检测闭环框架来不断更新XFacta，确保数据的相关性。此外，详细分析了MLLM驱动模型的设计策略，提供了有价值的见解和实践，以推进多模态虚假信息检测领域的研究。", "conclusion": "通过XFacta，提供了宝贵的研究实践和参考案例，促进多模态虚假信息检测领域的进一步研究和发展，同时公开了代码和数据。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09995", "html_url": "https://arxiv.org/abs/2508.09995", "title": "zERExtractor：科学文献中酶催化反应数据提取的自动化平台", "title_en": "zERExtractor:An Automated Platform for Enzyme-Catalyzed Reaction Data Extraction from Scientific Literature", "authors": "Rui Zhou,Haohui Ma,Tianle Xin,Lixin Zou,Qiuyue Hu,Hongxi Cheng,Mingzhi Lin,Jingjing Guo,Sheng Wang,Guoqing Zhang,Yanjie Wei,Liangzhen Zheng", "background": "酶催化反应的文献扩展速度超过了主要生物化学数据库的整理能力，阻碍了基于AI的建模和知识发现。现有的数据库无法满足迅速增长的文献数据需求，需要一种新的方法来自动化和扩展酶催化反应数据的提取。", "innovation": "zERExtractor 是一个自动化且可扩展的平台，用于从科学文献中全面提取酶促反应和活性数据。它具有统一的模块化架构，支持最先进的模型（包括大型语言模型）的插拔式集成，使系统能够随着AI的进步而持续发展。该平台结合了领域适应的深度学习、高级OCR、语义实体识别和提示驱动的大语言模型模块，以及人工专家校正，能够从多种文档格式中提取动力学参数（如kcat, Km）、酶序列、底物SMILES、实验条件和分子图。通过结合AI辅助注释、专家验证和迭代改进的主动学习策略，系统能够快速适应新的数据源。此外，还提供了一个大型基准数据集，包含1000多张标注表格和5000多个生物字段，来自270篇关于P450相关的酶学出版物。", "conclusion": "zERExtractor 通过灵活的插件框架和高精度提取，填补了酶动力学数据缺口，为未来的基于AI的酶建模和生物化学知识发现奠定了基础。它在表格识别、分子图像解释和关系提取方面表现优异，分别达到了89.9%的准确率、高达99.1%的识别率以及94.2%的准确率，优于现有基准模型。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10025", "html_url": "https://arxiv.org/abs/2508.10025", "title": "使用生成式人工智能在实时检测和解释产后期抑郁症中的应用", "title_en": "Detecting and explaining postpartum depression in real-time with generative artificial intelligence", "authors": "Silvia García-Méndez,Francisco de Arriba-Pérez", "background": "在分娩后，母亲们面临许多挑战，其中产后抑郁症（PPD）是一个严重影响其身心健康的严重状况。因此，及时检测PPD及其风险因素对于通过专业预防措施进行早期评估和干预至关重要。", "innovation": "该工作贡献了一种结合自然语言处理、机器学习（ML）和大语言模型（LLMs）的智能PPD筛查系统，用于实时分析和免费口头报告评估。此外，通过将LLMs与具有解释性的ML模型（如树基算法）结合，使用特征重要性和自然语言来解释预测结果，解决了黑盒问题。", "conclusion": "该方法在各类评估指标上的PPD检测准确性达到了90%，超越了文献中的竞争解决方案。最终，该解决方案有助于快速检测PPD及其相关风险因素，对及时和适当的评估与干预至关重要。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10017", "html_url": "https://arxiv.org/abs/2508.10017", "title": "利用SMOTETomek和FedProx实现不平衡临床数据上具有鲁棒性的不同私密联邦学习管道", "title_en": "A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx", "authors": "Rodrigo Tertulino", "background": "联邦学习（FL）提供了一种在保护患者隐私的同时开展分布式健康研究的新颖方法。然而，结合差异隐私（DP）时，FL在保持临床效用和保障隐私之间面临巨大挑战。特别是在医学数据中常见的类别不平衡问题使得这些挑战更加复杂。本文在这样一个背景下进行研究。", "innovation": "本文通过整合混合SMOTETomek在客户端水平的应用和优化FedProx算法，针对不平衡的临床数据，提出了一个成熟的联邦学习框架。研究发现，在隐私预算（ε）和模型召回率之间存在明显的非线性权衡关系，通过优化后的FedProx算法，能够在保持高临床效用的同时提供强隐私保护。", "conclusion": "我们的研究为一个实际的方法论路线图，提供了一个有效的、安全的和准确的诊断工具，可以应用于非一致性真实的医疗数据。这一方法体提供了在联邦学习中解决类别不平衡问题和隐私保护之间的权衡关系的可操作解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10004", "html_url": "https://arxiv.org/abs/2508.10004", "title": "用户对注意力可视化的效果感知：在循证医学文献解释中的影响", "title_en": "User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents", "authors": "Andrés Carvallo,Denis Parra,Peter Brusilovsky,Hernan Valdivieso,Gabriel Rada,Ivania Donoso,Vladimir Araujo", "background": "注意力机制是Transformer架构的核心组件。除了提高性能外，注意力机制还被提出作为一种通过注意权重进行可解释性的方法，这些权重与输入特征相关（例如，文档中的单词）。在循证医学领域，这样的解释可以支持医生对人工智能系统的理解与互动，这些系统用于分类生物医学文献。然而，目前尚无共识认为注意力权重能提供有帮助的解释。此外，很少有关于可视化注意力如何影响其作为解释辅助工具的有效性的研究。为了填补这一空白，我们进行了一个用户研究，以评估注意力基解释是否支持用户在生物医学文档分类中的辅助作用，以及哪种可视化方式更为适用。本次研究招募了来自不同学科的医学专家，他们根据研究设计（如系统评价、广泛综合、随机与非随机试验）分类文献。我们的研究结果表明，Transformer模型（XLNet）准确地分类了文献；然而，注意力权重并未被特别感知为解释预测的有效工具。然而，注意力的可视化方式产生了显著的不同，与Munzner提出的视觉有效性原则（倾向于精确编码，如条形长度）不同，用户更偏好直观的格式，例如文本亮度或背景颜色。因此，虽然我们的研究结果并未证实注意力权重整体上的解释效用，但却表明其感知的有用性受到其可视化方式的影响。", "innovation": "我们的研究表明，与Munzner提出的视觉有效性原则不同，用户更偏好直观的可视化格式。这意味着在使用注意力机制进行解释时，应该考虑用户的直观感知，而不是仅仅依赖精确的编码方式。这为在医学等复杂领域中通过可视化优化注意力机制的应用提供了一种新视角，可以帮助提高用户对AI系统的理解与信任。", "conclusion": "我们的研究发现，尽管Transformer模型能够准确分类文献，但注意力权重并不总是被视为解释预测的有效工具，且其解释效果会受到可视化方式的影响。用户更倾向于直观的可视化格式，这与视觉有效性原则有所偏离。这表明，为了更好地支持用户在解释任务中的决策，应更加注重注意力权重的直观呈现方式。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10026", "html_url": "https://arxiv.org/abs/2508.10026", "title": "SABER: 可开关和平衡训练以实现高效大语言模型推理", "title_en": "SABER: Switchable and Balanced Training for Efficient LLM Reasoning", "authors": "Kai Zhao,Yanjun Zhao,Jiaming Song,Shien He,Lusheng Zhang,Qiang Zhang,Tianjiao Li", "background": "大语言模型（LLMs）借助链式思考推理能力在复杂任务上取得了显著的准确性，但在应用到所有问题时却面临推理成本过高和延迟较大的问题。", "innovation": "提出了SABER（可开关和平衡训练以实现高效大语言模型推理），这是一种强化学习框架，能够让LLMs在用户可控的、基于token预算的推理。SABER通过划分不同的token预算层级，并在微调过程中指导模型遵守其预算，同时引入无需思考的示例以确保模型在关闭显式推理时依然可靠。此外，SABER还支持四种不同的推理模式：NoThink、FastThink、CoreThink和DeepThink，以灵活平衡延迟和推理深度。", "conclusion": "广泛的评估显示，SABER能够在严格的预算下保持高准确度，表现出优雅的降级，并且具备跨尺度和跨领域的有效泛化能力。特别是SABER-FastThink将推理长度减少了65.4%，在MATH基准测试中比基础模型提高了3.6%的准确率。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10028", "html_url": "https://arxiv.org/abs/2508.10028", "title": "PREF：大型语言模型中个性化文本生成的无参考评估", "title_en": "PREF: Reference-Free Evaluation of Personalised Text Generation in LLMs", "authors": "Xiao Fu,Hossein A. Rahmani,Bin Wu,Jerome Ramos,Emine Yilmaz,Aldo Lipani", "background": "个性化文本生成对于以用户为中心的信息系统至关重要，但大多数评估方法忽视了用户的个体性。现有的评估方法通常需要金标准的个性化参考，这限制了其广泛应用。", "innovation": "PREF是一个无参考的个性化评估框架，能够同时衡量通用输出质量和用户特定的对齐情况，无需金标准个性化参考。PREF通过一个三步流水线进行操作：（1）覆盖率阶段使用大型语言模型生成详尽的查询特定指南，涵盖事实性、连贯性和完整性等通用标准；（2）偏好阶段重新排序并有选择地增强这些因素，使用目标用户的个人资料、明确或推断的偏好以及语境，生成个性化的评估标准；（3）评分阶段应用大型语言模型裁判来根据这个标准对候选答案进行打分，确保基础适用性同时捕捉主观优先级。这种将覆盖率与偏好分离的方式提高了稳健性、透明性和可重用性，允许较小的模型逼近大型模型的个性化质量。", "conclusion": "实验表明，PREF在PrefEval基准上的结果优于强基线，特别是在隐含偏好跟随任务中。PREF构建了一个可扩展、可解释和用户对齐的评估框架，为更可靠地评估和开发个性化语言生成系统奠定了基础。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10035", "html_url": "https://arxiv.org/abs/2508.10035", "title": "基于神经网络的家庭能源系统中Fringe Data Injection攻击的检测与多类别分类", "title_en": "Neural Network-Based Detection and Multi-Class Classification of FDI Attacks in Smart Grid Home Energy Systems", "authors": "Varsha Sen,Biswash Basnet", "background": "虚假数据注入攻击（FDIAs）对智能电网，特别是家庭区域网络（HANs）构成重大威胁，因为HANs在实时监控和控制方面的应用极为广泛，而HANs的安防措施较为薄弱且分布广泛，使得攻击者视其为驯服逐利的新入口。这种攻击能操纵需求模式，从而扰乱电网运营，威胁着家庭和大中型电价数据的完整性，使恶意行为者能够操纵消费值而不触发常规警报，在多层级结构中制造关键的安全薄弱点。", "innovation": "本文提出了基于机器学习的方法来检测和分类家庭能源系统中FDIAs，采用轻量级的人工神经网络（ANN）进行实时检测，并通过双向LSTM识别不同攻击类型，展示了有效性。为模拟真实的家庭行为生成了一组合成时间序列数据，并通过实验结果证明所提出的模型在识别和分类FDIAs方面表现出色，提供了一种可扩展的解决方案来增强边缘的电网韧性。", "conclusion": "本文的工作促进了从住宅端点构建智能、数据驱动的防御机制，增强智能电网的网络安全。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10034", "html_url": "https://arxiv.org/abs/2508.10034", "title": "使用深度学习的喷流图像标记：一种集成模型", "title_en": "Jet Image Tagging Using Deep Learning: An Ensemble Model", "authors": "Juvenal Bassa,Vidya Manian,Sudhir Malik,Arghya Chattopadhyay", "background": "在高能粒子物理中，喷流分类对于理解基本相互作用和探索标准模型之外的现象至关重要。喷流来自夸克和胶子的碎片化和强子化，并且由于其复杂的多维结构，识别起来具有挑战性。传统的分类方法在捕捉这些复杂性方面往往不够，需要采用先进的机器学习方法。", "innovation": "本文采用两个神经网络同时作为集成模型来标记不同类型的喷流。将喷流数据转换为二维直方图，而不是将其表示为高维空间中的点。集成方法通过利用各组成网络的优点，用于将喷流分组为JetNet数据集中的类别：顶夸克、轻夸克（上或下）和W、Z玻色子。该集成方法对于二元和多类别分类均可使用，并展示了比单一网络更好的性能。", "conclusion": "该集成模型通过利用每个组成网络的优势，成功地学习了喷流特征，表现出高于单一网络的优越性能，可用于喷流的二元和多类别分类。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10036", "html_url": "https://arxiv.org/abs/2508.10036", "title": "反思然后学习：基于内在困惑的主动提示信息提取", "title_en": "Reflect then Learn: Active Prompting for Information Extraction Guided by Introspective Confusion", "authors": "Dong Zhao,Yadong Wang,Xiang Chen,Chenxi Wang,Hongliang Dai,Chuanxing Geng,Shengzhong Zhang,Shaoyuan Li,Sheng-Jun Huang", "background": "大型语言模型（LLMs）在少样本信息提取（IE）中表现出显著潜力，但其性能高度依赖于上下文示例的选择。传统选择策略往往未能提供有信息量的指导，因为它们忽略了模型错误的关键来源：不仅来自语义内容，还来自信息提取任务所需的生成格式的复杂性。针对这一问题，引入了主动提示信息提取（APIE）框架，该框架基于我们称为内在困惑的原则来指导。", "innovation": "提出了基于内在困惑的原则的主动提示信息提取（APIE）框架，引入了一个双组件不确定性度量方法，既可以量化格式不确定性（生成正确语法的难度），也可以量化内容不确定性（提取语义的一致性）。通过综合评分对未标记数据进行排名，该框架有选择地选择最具挑战性和信息量的样本作为零样本示例。", "conclusion": "在四个基准测试上的广泛实验表明，所提出的方法在信息提取准确性与鲁棒性方面都显著优于强大基准，突出了构建有效可靠的结构生成系统时对模型不确定性进行精细双层视角的必要性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10055", "html_url": "https://arxiv.org/abs/2508.10055", "title": "贝叶斯模型在环境和金融预测中的联合特征和自回归滞后选择：理论与应用", "title_en": "Bayesian Models for Joint Selection of Features and Auto-Regressive Lags: Theory and Applications in Environmental and Financial Forecasting", "authors": "Alokesh Manna,Sujit K. Ghosh", "background": "该研究关注线性回归模型中自相关误差下的变量选择问题，特别是在时间序列应用中，如金融建模、水文预报和气象学中。在这种情况下，应变量依赖于当前或过去的解释变量以及持续的随机冲击，需要捕捉时间依赖性。现有方法在处理高维计算挑战时存在局限性，特别是当候选预测变量随样本量指数增长时。现有的研究缺乏一种同时选择相关解释变量和滞后误差项的有效方法，并且无法保证变量选择的一致性。研究者提出了一种贝叶斯框架，采用分层贝叶斯模型和膨胀尖刺先验，结合两种马尔可夫链蒙特卡洛算法，在高维时间序列数据中进行高效的变量选择和模型参数估计，以解决这些挑战。", "innovation": "该研究提出了一种新的贝叶斯框架，解决了时间序列中自相关误差下的变量选择问题。该框架采用了分层贝叶斯模型和分段膨胀尖刺先验相结合的方法，能够在高维数据中同时选择相关解释变量和滞后误差项。此外，还提出了一种两阶段MCMC算法，有效地解决了高维计算挑战。研究还证明了该方法在变量选择精度和预测性能方面优于现有的方法，特别适用于具有自相关噪声的自回归模型中。", "conclusion": "通过模拟和实际应用（地下水深度预测、S&P 500对数回报建模），该研究展示了该框架在变量选择和预测性能方面显著的优势，尤其是在具有自相关噪声的自回归设置中。研究结果强调了该方法在模型解释和未来预测中的实际应用价值。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10104", "html_url": "https://arxiv.org/abs/2508.10104", "title": "DINOv3", "title_en": "DINOv3", "authors": "Oriane Siméoni,Huy V. Vo,Maximilian Seitzer,Federico Baldassarre,Maxime Oquab,Cijo Jose,Vasil Khalidov,Marc Szafraniec,Seungeun Yi,Michaël Ramamonjisoa,Francisco Massa,Daniel Haziza,Luca Wehrstedt,Jianyuan Wang,Timothée Darcet,Théo Moutakanni,Leonel Sentana,Claire Roberts,Andrea Vedaldi,Jamie Tolan,John Brandt,Camille Couprie,Julien Mairal,Hervé Jégou,Patrick Labatut,Piotr Bojanowski", "background": "自监督学习有希望消除手动数据标注的需求，使模型能够轻松扩展到大规模数据集和更大的架构中。通过不针对特定任务或领域进行调整，这种训练范式可以从多种来源（从自然图像到航空图像）学习视觉表示，并且可以使用单一算法实现。", "innovation": "首先，通过精心的数据准备、设计和优化，扩大了数据集和模型的规模。其次，引入了一种新的方法，称为Gram anchoring，有效地解决了已知但未解决的问题，即密集特征图在长时间训练期间退化。最后，应用后处理策略，进一步增强了模型的灵活性，包括分辨率、模型大小和与文本的对齐。因此，DINOv3提供了一种配套的视觉基础模型，即使不进行微调也能在广泛的情境中超越专门的最新技术。", "conclusion": "DINOv3生成高质量的密集特征，这些特征在各种视觉任务中表现出色，显著超越了以前的自监督和弱监督基础模型。我们还分享了DINOv3配套的视觉模型系列，旨在通过提供适用于不同资源约束和部署场景的可扩展解决方案，推进广泛任务和数据的状态。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10120", "html_url": "https://arxiv.org/abs/2508.10120", "title": "基于机器学习的IASI测量云检测：具有物理约束的数据驱动SVM方法", "title_en": "Machine Learning for Cloud Detection in IASI Measurements: A Data-Driven SVM Approach with Physical Constraints", "authors": "Chiara Zugarini,Cristina Sgattoni,Luca Sgheri", "background": "云检测对于大气检索、气候研究和天气预报至关重要。本文分析了搭载于气象业务（MetOp）卫星的红外大气探测干涉仪（IASI）的红外辐射，用于将场景分类为晴天或阴天。", "innovation": "本文采用基于核方法的Support Vector Machine（SVM）方法，特别适用于非线性可分数据，并通过主成分分析（PCA）进行维度降低以及选择云敏感通道聚焦于最具信息性的特征。该方法的主要创新在于通过云敏感通道选择实现自动化的云分类，以红外辐射或亮度温度作为测试集，并且方法实现了88.30%的与参考标签的一致性。", "conclusion": "这项研究证明了CISVM方法是一种稳健、灵活且高效的云分类方法，适用于从红外辐射中自动化的云分类，以及未来的使命，如远红外向外辐射理解与监测（FORUM），欧洲空间局第九颗地球探测者任务。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10160", "html_url": "https://arxiv.org/abs/2508.10160", "title": "使用慢性侵入式电生理学训练的预训练变换器模型，用于无需患者个体训练的症状解码", "title_en": "Pre-trained Transformer-models using chronic invasive electrophysiology for symptom decoding without patient-individual training", "authors": "Timon Merk,Saeed Salehi,Richard M. Koehler,Qiming Cui,Maria Olaru,Amelia Hahn,Nicole R. Provenza,Simon Little,Reza Abbasi-Asl,Phil A. Starr,Wolf-Julian Neumann", "background": "近期，使用预训练大规模基础模型在患者个体化闭合环路神经调节疗法中的神经解码研究发展迅速。传统的训练方法需要针对每位患者进行专门训练，这可能限制了其应用范围。论文介绍了一种使用长达24天的慢性纵向深脑刺激记录进行预训练的方法，适应长时间尺度的症状波动，采用30分钟的扩展上下文窗。论文修正了通用掩蔽自编码损失函数在1-over-f幂律频率偏差方面的问题，使预训练过程更适合神经电生理数据。通过无患者个体训练的遗留一受试者交叉验证任务，展示了针对帕金森病症状的解码。", "innovation": "论文创新点在于采用了慢性侵入式电生理记录进行模型预训练，提出了适用于神经电生理数据的优化预训练损失函数，纠正了常见的掩蔽自编码损失函数在频率偏差方面的不足，并展示了无需患者个体训练即能解码帕金森病症状的能力。", "conclusion": "研究展示了使用预训练Transformer模型进行症状解码的潜力，通过修正频率偏差并进行无患者个体训练的实验，验证了该方法的有效性。未来工作可能进一步优化模型性能，扩展到更多类型的精神疾病。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10149", "html_url": "https://arxiv.org/abs/2508.10149", "title": "使用逆概率加权的预测驱动推断", "title_en": "Prediction-Powered Inference with Inverse Probability Weighting", "authors": "Jyotishka Datta,Nicholas G. Polson", "background": "Prediction-powered inference (PPI) 是一种用于部分标记数据的有效统计推断框架，通过结合对大量未标记数据集的模型预测和来自较小标记子集的偏差校正。现有 PPI 方法假设标签信息已知且均衡，但实际应用中标签往往是带有选择性偏见的。本文探讨了将 PPI 扩展到处理选择性标签的方式，通过用逆概率加权（IPW）形式替换未加权的偏差校正项，连接设计基抽样调查理念和现代预测辅助推断，从而在标签概率改变时保持估计的有效性。", "innovation": "论文将 PPI 扩展到处理带信息性偏差的标签，引入了使用经典 Horvitz-Thompson 或 Hájek 形式的 IPW 版本进行加权的创新方法，将设计基抽样理念与现代预测辅助推断相结合。论文还考虑了估计概率的情况，并通过模拟证明了 IPW 调整的 PPI 估计在性能上接近于已知概率的情况，同时维持了名义覆盖范围和 PPI 的方差减少优势。", "conclusion": "IPW 调整的 PPI 在估计概率未知且需要从正确指定的模型中估计时仍能保持有效的估计性能，能够有效应对选择性偏倚标签的情况，同时保持良好的覆盖范围和方差减少效果。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10117", "html_url": "https://arxiv.org/abs/2508.10117", "title": "Garcinia cowa中黄酮类生物活性化合物对HeLa癌细胞的体外细胞毒性的计算研究：基于图深度学习、网络药理学和分子对接的QSAR", "title_en": "In silico study on the cytotoxicity against Hela cancer cells of xanthones bioactive compounds from Garcinia cowa: QSAR based on Graph Deep Learning, Network Pharmacology, and Molecular Docking", "authors": "Nguyen Manh Son,Pham Huu Vang,Nguyen Thi Dung,Nguyen Manh Ha. Ta Thi Thao,Tran Thi Thu Thuy,Phan Minh Giang", "background": "癌症是一种复杂的疾病群，是全球导致最高死亡率的主要原因之一，其发病率不断提高，并且有年轻化趋势。癌症的特征是异常细胞的不受控制增殖、邻近组织的侵袭以及向远处器官的转移。Garcinia cowa是一种在东南亚，包括越南广泛用于治疗发热、咳嗽、消化不良、泻下和驱虫的传统药草植物。从这种植物中分离出的大量黄酮类化合物显示出广泛的生物学活性，其中一些显示出作为抗癌和抗疟疾剂的潜力。网络药理学分析成功地确定了关键活性化合物及其主要蛋白靶标，提供了它们抗癌作用的分子机制的关键见解。", "innovation": "使用图注意网络算法，实现了在数据增强后的R2为0.98和RMSE为0.02的优越预测性能，展示了其在预测基于黄酮的化合物的pIC50值方面准确性。此外，通过分子对接研究发现MTOR可能是由Garcinia cowa引起的HeLa癌细胞的潜在细胞毒作用靶点。结合网络药理学、图深度学习和分子对接的方法，提供了新的途径来研究Garcinia cowa的抗癌效果。", "conclusion": "通过网络药理学、图深度学习和分子对接的方法，成功识别了Garcinia cowa中的关键活性化合物及靶标，揭示了其潜在的抗癌机制，并预测了这些化合物对HeLa癌细胞的细胞毒性，为传统药草的现代药理研究提供了新的方法和理论基础。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10178", "html_url": "https://arxiv.org/abs/2508.10178", "title": "在架空海环境中的碳池估算：再分析或基于模型的机器学习？", "title_en": "Estimating carbon pools in the shelf sea environment: reanalysis or model-informed machine learning?", "authors": "Jozef Skakala", "background": "架空海对碳固存与碳循环至关重要，但现有的现场或卫星数据在架空海环境中往往稀缺或不确定性高。现有的一些替代方法依赖于再分析，但运行这些再分析过程成本高昂。因此，本文提出了一种利用神经网络（NN）从一个耦合物理-生物地球化学模型中学习可直接观察变量与碳池之间关系的方法，以期为架空海环境中的碳池预测提供一个成本效益更高的解决方案。", "innovation": "本文提出了一个使用神经网络（NN）的新型方法，旨在从一个耦合的物理-生物地球化学模型中学习碳池与直接可观察变量之间的关系，从而为架空海环境中的碳池估算提供一个潜在的替代方案。特别地，该方法能够精准地重新分析碳池数据，并提供相关的不确定性信息，而不需要成本高昂的再分析过程。此外，该方法还能提供模型解释性，并为未来的气候情景模拟提供潜力。", "conclusion": "基于模型的机器学习方法能够为架空海环境中碳池的不确定性提供信息，并展现出与现有再分析相比的成本效益。通过这种方法，不仅能替代部分再分析过程，还能填补观测数据缺失或不确定的情况下的空白，体现了其作为一种可行替代方案的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10186", "html_url": "https://arxiv.org/abs/2508.10186", "title": "PakBBQ：一个文化适应型问答反偏见基准", "title_en": "PakBBQ: A Culturally Adapted Bias Benchmark for QA", "authors": "Abdullah Hashmat,Muhammad Arham Mirza,Agha Ali Raza", "background": "随着大型语言模型（LLMs）在各个应用中的广泛应用，确保其在所有用户社区中的公平性已成为必然需求。然而，大多数LLMs都是基于西方中心的数据进行训练和评估的，很少考虑到低资源语言和区域环境。为了弥补这一差距，本文介绍了PakBBQ，这是一个针对巴基斯坦文化的改进型偏见基准数据集。PakBBQ包含了超过214种模板，共17180对问答，覆盖8个类别，包括英语和乌尔都语，并涵盖了年龄、残疾、外貌、性别、社会经济状况、宗教、区域归属和语言形式化等八个与巴基斯坦相关的偏见维度。", "innovation": "本文创新性地提出了PakBBQ，这是一个针对巴基斯坦文化的改进型偏见基准数据集。PakBBQ致力于解决现有语言模型在训练和评估过程中存在的文化适配性不足的问题，通过覆盖与巴基斯坦相关的多个偏见维度，它提供了在低资源设置中用于多语言LLMs的基准和简单提示策略，特别关注通过澄清和否定提问方式减少刻板印象响应。", "conclusion": "本研究表明，在具有歧义和明确澄清的情境下评估多语言LLMs时，澄清可以提高12%的平均准确性；乌尔都语环境下表现出了更强的反偏见行为；问题表述方式会显著影响刻板印象的响应。这些发现突显了为低资源环境设计上下文化的基准及简单的提示策略的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10193", "html_url": "https://arxiv.org/abs/2508.10193", "title": "更多的记忆，更多的问题：针对连续数据流的机器遗忘", "title_en": "Mo' Memory, Mo' Problems: Stream-Native Machine Unlearning", "authors": "Kennon Stewart", "background": "当前的机器遗忘工作假定一个静态且独立同分布的训练环境，但这种环境在现实世界中并不存在。现代机器学习管道需要在实时数据流中持续学习、忘记和预测。", "innovation": "将批量遗忘场景转化为在线设置，引入了后悔、样本复杂度和删除容量的概念，将后悔边界紧缩至对数级$\text{O}(\text{ln}T)$。还用在线L-BFGS替代昂贵的海森矩阵求逆，消除了与时间线性增长的记忆占用，从而延长了模型在昂贵重培训之前的寿命。", "conclusion": "这些改变使得机器遗忘过程更加高效，能更长时间地使用模型，降低重新训练的频率。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10192", "html_url": "https://arxiv.org/abs/2508.10192", "title": "大型语言模型提示-响应语义分歧度量：对于忠实度幻觉和对齐检测", "title_en": "Prompt-Response Semantic Divergence Metrics for Faithfulness Hallucination and Misalignment Detection in Large Language Models", "authors": "Igor Halperin", "background": "大规模语言模型（LLMs）的广泛应用受到了幻觉的挑战，即模型生成不符合事实、不合逻辑或不忠实的文本。现有的方法如语义熵通过测量单一固定提示下答案的多样性来检测任意性，但这些方法缺乏对提示深刻理解力。本文提出了一种新的轻量级框架，称为语义分歧度量（SDM），用于检测忠实度幻觉，即LLMs响应与输入上下文严重偏离的情况。SDM通过测量响应在多个答案和多个语义等价重述的原始提示之间的连贯性，提供了更深入的任意性测试。", "innovation": "SDM框架通过联合聚类句子嵌入来创建提示和答案的共享主题空间，提供直观的提示-机器对话量化二维可视化。进一步计算信息论度量来衡量提示和响应之间的语义分歧。此外，引入了KL散度作为语义探索的有力指标，帮助区分不同的生成行为。该方法形成了语义盒，一个诊断框架，用于分类LLMs响应类型，特别是区分危险的自信性幻觉。", "conclusion": "SDM为大型语言模型的忠实度幻觉和偏移检测提供了一种新的轻量级框架，通过提供对提示的深刻理解并检测更深层次的任意性，相比已有方法提高了检测效果。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10282", "html_url": "https://arxiv.org/abs/2508.10282", "title": "条件Batch通用预测的遗憾-容量定理", "title_en": "The Conditional Regret-Capacity Theorem for Batch Universal Prediction", "authors": "Marco Bondaschi,Michael Gastpar", "background": "该研究基于经典的遗憾-容量定理，通过对遗憾度量的条件化，适用于当预测器可以使用批训练数据时的任何(batch)场景。背景包括传统遗憾-容量定理及其在机器学习等领域的应用。", "innovation": "该研究首次建立了条件化的遗憾-容量定理，能够用于确定最小批量遗憾的下界。此外，该成果还推广至Rényi信息度量，揭示了条件Rényi散度与条件Sibson互信息之间的深层联系。", "conclusion": "研究得到了一个用以辅助寻找批训练数据条件下最小批量遗憾下界的定理，并且进一步将其推广至更广泛的Rényi信息度量，从而加深了对信息度量之间关系的认识。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10222", "html_url": "https://arxiv.org/abs/2508.10222", "title": "通过表情符号预测理解文本情感", "title_en": "Understanding Textual Emotion Through Emoji Prediction", "authors": "Ethan Gordon,Nishank Kuppa,Rigved Tummala,Sriram Anasuri", "background": "这篇论文基于短文本序列探索了表情符号预测，使用了四种深度学习架构：前馈网络、CNN、变压器和BERT。研究人员使用TweetEval数据集来处理类别不平衡问题，并通过焦点损失和正则化技术进行调整。实验结果显示，BERT因其预训练的优势获得了最高的整体性能，而CNN在预测罕见表情符号类别方面表现更优。这项研究强调了选择合适架构和超参数调优对于情感感知表情符号预测的重要性，对提升人机交互具有贡献。", "innovation": "使用了四种不同的深度学习架构进行表情符号预测：前馈网络、CNN、变压器和BERT。通过焦点损失和正则化技术来解决类别不平衡问题。特别地，研究指出BERT在整体性能上优于其他模型，而CNN在预测罕见表情符号类别方面有独特优势。", "conclusion": "研究强调了架构选择和超参数调优对于提高情感感知表情符号预测性能的重要性，这对提高人机互动的质量有着积极作用。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10339", "html_url": "https://arxiv.org/abs/2508.10339", "title": "概念还是技能？重新思考多模态模型中的指令选择", "title_en": "Concepts or Skills? Rethinking Instruction Selection for Multi-modal Models", "authors": "Andrew Bai,Justin Cui,Ruochen Wang,Cho-Jui Hsieh", "background": "视觉语言基准主要受益于具有相似技能或视觉概念的指令的训练。该研究旨在通过识别视觉语言指令中固有的权衡，即提升概念知识与视觉技能之间的平衡，来优化多模态模型的性能。", "innovation": "设计了一个简单的目标数据选择方法，首先从基准中提取概念/技能，判断基准主要从相似的概念还是技能中受益，最后选择与概念/技能最匹配的指令。实验证明该方法在10多个基准上的有效性，平均提高0.9%，在技能集中提高了1.5%。", "conclusion": "强调在指令选择中认识到固有的权衡和需要在概念知识的获取与视觉技能之间进行平衡的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10349", "html_url": "https://arxiv.org/abs/2508.10349", "title": "On-Device 细分自适应联邦学习模型的灵活个性化分割联邦学习", "title_en": "Flexible Personalized Split Federated Learning for On-Device Fine-Tuning of Foundation Models", "authors": "Tianjun Yuan,Jiaxiang Geng,Pengchao Han,Xianhao Chen,Bing Luo", "background": "基础模型的微调对个性化下游任务的性能至关重要，相较于使用预训练模型。协作学习可以通过利用客户端的数据集来实现微调，但受限于有限的客户端数据和异质的数据分布，有效的协作难以实现。", "innovation": "提出了一个灵活的个性化分割联邦学习（FlexP-SFL）框架，允许客户端在保持个性化目标的同时进行协作学习。FlexP-SFL结合了分割学习，允许客户端根据资源限制本地训练模型的一部分将其余部分上传至服务器。此外，还提出了一种对齐策略来提高个性化模型在全局数据上的性能。", "conclusion": "实验结果表明，FlexP-SFL 在个性化微调效率和最终准确率上优于基线模型。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10337", "html_url": "https://arxiv.org/abs/2508.10337", "title": "一种强化学习中的 Curriculum Learning 方法：利用RAG进行多模态问答", "title_en": "A Curriculum Learning Approach to Reinforcement Learning: Leveraging RAG for Multimodal Question Answering", "authors": "Chenliang Zhang,Lin Wang,Yuanyuan Lu,Yusheng Qi,Kexin Wang,Peixu Hou,Wenshi Chen", "background": "该论文描述了Dianping-Trust-Safety团队对META CRAG-MM挑战的解决方案，该挑战要求构建一个全面的检索增强生成系统，用于多模态多轮问答。比赛包含三个任务：（1）使用图像为基础的模拟知识图检索结构化数据来回答问题；（2）从知识图和网络搜索结果中综合信息；（3）处理需要上下文理解并从多个来源进行信息聚合的多轮对话。团队的解决方案在任务一、二和三中分别应用了不同的策略和技术，以应对不同任务的具体需求。", "innovation": "该论文的创新点在于通过结合 curriculum learning（课程学习）和 reinforcement learning（强化学习），在任务一中显著提升了回答准确性和降低了幻觉现象，特别是在使用基于图像的知识图检索结构化数据并进行多轮问答的场景中。此外，团队还利用了Web搜索API结合外部知识，使系统能够更好地处理复杂查询和多轮对话。", "conclusion": "该团队的方法在任务一中赢得了第一名，领先第二名52.38%，同时在任务三中取得了第三名的成绩。这一结果证明了课程学习与强化学习结合的训练流程的有效性，展示了团队如何成功应对多模态和多轮对话中的复杂挑战。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10377", "html_url": "https://arxiv.org/abs/2508.10377", "title": "点击与转化：选择电子商务推荐系统的训练目标", "title_en": "Clicks Versus Conversion: Choosing a Recommender's Training Objective in E-Commerce", "authors": "Michael Weiss,Robert Rosenbach,Christian Eggenberger", "background": "在电子商务中，提高点击通过率(CTR)或转化率，例如添加到购物车率(ACR)和订单提交率(OSR，即从浏览到购买的转化)，是标准做法。优化CTR看起来是一个简单的选择，因为点击数据容易收集且数量庞大。此外，CTR在电子商务领域之外也经常使用，使其成为一个易于实现的通用选项。相比之下，ACR和OSR更直接与商店的业务目标有关，如总商品价值(GMV)。本文通过在线A/B测试比较了这两种目标的效果。", "innovation": "文章通过在线A/B测试比较了优化点击通过率(CTR)与优化订单提交率(OSR)的效果。研究发现，在优化OSR的情况下，GMV提升超过CTR优化的五倍，同时不牺牲新产品的发现。研究还探索了每个目标下的不同特征重要性。", "conclusion": "本文的结果表明，在电子商务环境中，优化订单提交率(OSR)比优化点击通过率(CTR)带来的收益更高，同时不会牺牲新产品的发现。此外，文章还提供了关于每个目标下不同特征重要性的见解。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10436", "html_url": "https://arxiv.org/abs/2508.10436", "title": "交替使用Approach-Putt模型的多阶段语音增强方法", "title_en": "Alternating Approach-Putt Models for Multi-Stage Speech Enhancement", "authors": "Iksoon Jeong,Kyung-Joong Kim,Kang-Hun Ahn", "background": "语音增强的目标是去除嘈杂语音信号中的噪声同时保留语音内容。然而，语音增强网络往往会引入对语音信号的失真，称为副作用，这些失真会影响音频质量。", "innovation": "本文提出了一种后处理神经网络PuttNet，旨在减轻由语音增强模型引入的副作用。通过交替使用语音增强模型和提出的Putt模型，该研究证明了可以提高语音质量，这一改进在感知质量评分（PESQ）、客观可懂度（STOI）和背景噪声侵入性（CBAK）评分中得到了体现。此外，图形分析还说明了交替使用Approach模型优于单独重复使用任一模型。", "conclusion": "交替使用Approach和Putt模型的多阶段语音增强方法能够提高语音质量，并且图形分析解释了其更优的效果。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10425", "html_url": "https://arxiv.org/abs/2508.10425", "title": "HiRef: 利用层次化 ontology 和网络精炼实现稳健的药物推荐", "title_en": "HiRef: Leveraging Hierarchical Ontology and Network Refinement for Robust Medication Recommendation", "authors": "Yan Ting Chok,Soyon Park,Seungheun Baek,Hajung Kim,Junhyun Lee,Jaewoo Kang", "background": "药物推荐对于帮助医生从纵向患者医疗记录中及时做出决定至关重要。然而，现实世界的电子病历(EHR)数据因稀有医学实体的存在和不完整记录而提出了重大挑战，这些记录可能无法完全捕捉临床真实情况。尽管通过纵向EHR数据训练的数据驱动模型通常能实现强大的实际性能，但在缺乏或新型情况下它们很难泛化，主要依赖于观察到的共现模式。", "innovation": "我们提出了HiRef——一个结合了两个互补结构的统一框架，即(i)在策划的医学本体中编码的层次语义，以及(ii)源自实际EHRs的改进的共现模式。我们嵌入本体实体到双曲空间中，这样可以自然捕捉树状关系，并通过共享祖先实现知识转移，从而提高对未见过的代码的泛化能力。为了进一步提高稳健性，我们引入了一种先验引导的稀疏正则化方案，通过抑制虚假边并保留临床相关的关联来细化EHR共现图。", "conclusion": "我们的模型在EHR基准数据集(MIMIC-III和MIMIC-IV)上表现出强大性能，并且在模拟未见过的代码场景下保持高度准确性。广泛的实验和全面的消融研究表明，HiRef对未见过的医学代码具有很强的鲁棒性，通过分析学习到的稀疏化图结构和医学代码嵌入，证明了这一点。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10433", "html_url": "https://arxiv.org/abs/2508.10433", "title": "We-Math 2.0：一种激励视觉数学推理的多功能MathBook系统", "title_en": "We-Math 2.0: A Versatile MathBook System for Incentivizing Visual Mathematical Reasoning", "authors": "Runqi Qiao,Qiuna Tan,Peiqing Yang,Yanzi Wang,Xiaowan Wang,Enhui Wan,Sitong Zhou,Guanting Dong,Yuchen Zeng,Yida Xu,Jie Wang,Chong Sun,Chen Li,Honggang Zhang", "background": "多模态大语言模型（MLLMs）在各种任务中表现出了令人印象深刻的性能，但在复杂数学推理方面仍存在问题。现有研究主要集中在数据集构建和方法优化上，往往忽略了全面的知识驱动设计和以模型为中心的数据空间建模这两方面的重要性。", "innovation": "本文介绍了We-Math 2.0，这是一个统一的系统，集成了结构化的数学知识系统、以模型为中心的数据空间建模以及基于强化学习（RL）的训练范式，全面提升了MLLMs的数学推理能力。四项关键贡献包括：（1）数学书知识系统：构建了一个五级层次系统，包括491个知识点和1,819个基本原则。（2）数学书标准与专业版：开发了数学书标准，确保广泛的概念覆盖和灵活性，并通过双重扩展构建了数学书专业版，具有挑战性的数据集用于稳健的训练。（3）数学书-RL：提出了两阶段RL框架：从零开始微调和逐级对齐RL。（4）数学书-评估：引入了一个综合基准，涵盖了所有491个知识点，具有多样的推理步骤分布。", "conclusion": "实验结果表明，数学书RL在四个广泛使用的基准上与现有基线性能相当，并且在数学书-评估中取得了出色的结果，显示出数学推理的强大泛化能力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10419", "html_url": "https://arxiv.org/abs/2508.10419", "title": "ComoRAG：一种基于认知启发的内存组织RAG方法，用于有状态的长叙事推理", "title_en": "ComoRAG: A Cognitive-Inspired Memory-Organized RAG for Stateful Long Narrative Reasoning", "authors": "Juyuan Wang,Rongchen Zhao,Wei Wei,Yufeng Wang,Mo Yu,Jie Zhou,Jin Xu,Liyan Xu", "background": "长故事和小说的叙述理解是一个挑战性的领域，因为它们包含复杂的故事情节和错综复杂、经常变化的人物和实体间关系。由于大语言模型（LLM）在处理长期上下文时推理能力较低且计算成本高，检索式方法在实践中仍然起着关键作用。然而，传统的检索式自相似性聚合（RAG）方法可能会因为它们无状态、一次性检索的过程而忽略捕获长期上下文中的动态关系。现有方法往往受限于单一步骤的检索过程，无法充分把握复杂的长篇故事中的动态关系", "innovation": "本文提出了ComoRAG，这是一种认知启发的、基于内存组织的检索式自相似性聚合方法，旨在处理长期上下文中的有状态推理。ComoRAG的核心思想是，叙述推理不是一次性完成的，而是新证据获取与过往知识整合之间的动态过程，类似于人脑在记忆相关信号时进行推理的认知过程。具体来说，当遇到推理瓶颈时，ComoRAG可以进行迭代推理循环，通过动态内存工作区进行交互。每个循环中，ComoRAG生成探查查询以发现新的探索路径，然后将新方面检索到的证据整合到全局记忆池中，促进查询解决的连贯性背景。这种设计能够显著提升复杂查询的全局理解能力，实现基于检索的长期上下文理解的有状态推理", "conclusion": "在4个具有挑战性的长上下文叙事基准测试中，ComoRAG相比强基线取得了持续和一致的性能提升，最高可达11%。进一步分析还显示，ComoRAG在需要全球理解的复杂查询中表现尤为出色。这种方法为基于检索的长期上下文理解提供了一个原理上合理、认知启发式的框架，可以推动状态推理发展。我们的代码已公开发布"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10457", "html_url": "https://arxiv.org/abs/2508.10457", "title": "使用元数据增强的多头视觉变换器进行多标签植物物种预测", "title_en": "Multi-Label Plant Species Prediction with Metadata-Enhanced Multi-Head Vision Transformers", "authors": "Hanna Herasimchyk,Robin Labryga,Tomislav Prusina", "background": "这项研究旨在解决PlantCLEF 2025挑战，即使用单物种植物图像训练模型，但在测试阶段使用包含多种植物的地块图像，这导致了显著的领域偏移。该研究使用多尺度镶嵌、动态阈值优化和集成策略等技术来应对挑战，从而提高预测的准确性。研究使用的训练图像数量庞大，覆盖了7,806种植物物种，为解决多标签植物物种预测问题提供了新的方法。", "innovation": "1. 使用预训练的DINOv2 Vision Transformer Base作为基础模型，并通过多个分类头来预测物种、属和科。\n2. 引入了多尺度镶嵌技术以捕捉不同尺度的植物。\n3. 利用动态阈值优化来根据平均预测长度进行调整。\n4. 使用袋装策略和Hydra模型架构进行集成学习，提高了预测性能。\n5. 结合了多种推断技术，如图像裁剪以去除非植物伪象、预测约束的top-n过滤，以及logit阈值策略。", "conclusion": "实验结果显示了该方法的强大性能，使团队在公开排行榜上获得第3名的好成绩。该方法提供了在视觉地块图像上准确识别多个植物物种的有效途径。该研究的代码已公开发布。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10460", "html_url": "https://arxiv.org/abs/2508.10460", "title": "高效方法用于准确的稀疏轨迹恢复和路径匹配", "title_en": "Efficient Methods for Accurate Sparse Trajectory Recovery and Map Matching", "authors": "Wei Tian,Jieming Shi,Man Lung Yiu", "background": "现实世界的轨迹数据经常稀疏且采样率低（即，连续GPS点之间的间隔长），并且与道路网络对齐不良，但许多应用需要高质量数据以实现最佳性能。对于输入的稀疏轨迹，为了提高数据质量，本文系统地研究了轨迹恢复和路径匹配两个相关问题，以优化路径的最佳匹配率和轨迹恢复的精度。", "innovation": "本文提出了两种高效方法TRMMA和MMA，分别用于准确的轨迹恢复和路径匹配。MMA作为TRMMA的第一步骤，首先通过一个分类任务将GPS点映射到候选段集中的道路段，而不是整个道路网络。TRMMA集中在MMA返回的道路段上，通过路径比例来推断缺失的点，从而能够高效地生成高采样率的轨迹，而无需评估所有道路段。通过双重Transformer编码过程，TRMMA能综合捕捉轨迹的潜在模式和路径之间的模式，并通过有效的解码技术序列预测缺失点的位置比例和道路段。广泛地实验结果表明，TRMMA和MMA在测试的真实数据集上表现最佳，经常显著超越现有方法的效果。", "conclusion": "本文通过对道路网络中的轨迹恢复和路径匹配两个问题的研究，提出了TRMMA和MMA两种高效方法。实验结果表明，这两种方法在多个领域的大规模真实数据集上能够实现最佳的结果质量，特别是在轨迹恢复和路径匹配方面表现出色，证明了其在数据处理和应用中的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10464", "html_url": "https://arxiv.org/abs/2508.10464", "title": "SingleStrip：仅从一个标注样本学习头骨去除", "title_en": "SingleStrip: learning skull-stripping from a single labeled example", "authors": "Bella Specktor-Fadida,Malte Hoffmann", "background": "深度学习分割依赖大量标注数据，但手动标注数据费时费力，尤其是在处理如脑磁共振成像（MRI）的体数据时更为困难。虽然最近的域随机化技术通过从标签图生成多样化的训练图像来减轻对标注数据的依赖，但在可用标签图数量有限的情况下，这种技术提供的解剖变异有限。半监督自我训练通过迭代地将模型预测集成到训练集中，能够使网络从未标注数据中学习，从而缓解标签稀缺问题。本文将域随机化与自我训练结合，以最少的一个标注示例训练三维头骨剥离网络。", "innovation": "本文提出了一种结合域随机化与自我训练的方法，仅需一个标注示例就能训练三维头骨剥离网络。具体步骤包括：自动分区体素强度，生成用于训练初始头骨剥离模型的标签；训练卷积自编码器（AE），利用重构误差评估未标注数据预测的脑部掩码质量；选择排名最高的伪标签进行网络微调，从而在不同分布数据上的头骨剥离性能接近使用更多标注图像训练的模型。AE评估方法表现出更强与分割准确性的相关性，这表明该方法在极少量标注数据情况下实现有效半监督分割的潜力。", "conclusion": "我们的结果强调结合域随机化与基于AE的质量控制能够有效利用极少量标注数据进行高效半监督分割。此策略可能有助于减轻标注负担，从而加快涉及新解剖结构或新兴成像技术的研究进程。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10501", "html_url": "https://arxiv.org/abs/2508.10501", "title": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "title_en": "PASS: Probabilistic Agentic Supernet Sampling for Interpretable and Adaptive Chest X-Ray Reasoning", "authors": "Yushi Feng,Junye Du,Yingying Hong,Qifan Wang,Lequan Yu", "background": "现有的工具增强型代理系统在实际应用中受到限制，主要是因为它们在决策中存在黑盒推理步骤，降低了决策的信任度并带来了安全风险；它们在多模态集成方面表现不佳，特别是在健康护理任务中；此外，它们的代理管道较为僵化且计算效率低下。", "innovation": "PASS是第一个解决这些挑战的多模态框架，它在胸部X光片（CXR）推理的背景下实现。PASS通过多工具图自适应地采样代理工作流，提供带有可解释概率标注的决策路径。PASS还通过在不断压缩重要发现并动态决定是否深化推理路径或早期退出效率来实现个性化记忆的持续压缩。为了平衡性能和成本，PASS设计了一种新颖的三阶段训练流程，包括专家知识预热、对比路径排名和成本意识强化学习。", "conclusion": "实验结果证明，PASS在多个基准上显著优于强基线，同时平衡计算成本，推动了一种可解释、适应性强且多模态的医疗代理系统的新范式。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10515", "html_url": "https://arxiv.org/abs/2508.10515", "title": "Virtual Sensing for Solder Layer Degradation and Temperature Monitoring in IGBT Modules", "title_en": "Virtual Sensing for Solder Layer Degradation and Temperature Monitoring in IGBT Modules", "authors": "Andrea Urgolo,Monika Stipsitz,Helios Sanchis-Alepuz", "background": "监控绝缘栅双极型晶体管（IGBT）模块的降解状态对于确保电力电子系统的可靠性和使用寿命至关重要，尤其是在关键安全和高性能应用中。但由于内部组件的物理不可达性和恶劣环境，直接测量关键降解指标（如结温、焊料疲劳或分层）具有挑战性。在此背景下，基于机器学习的虚拟传感提供了通过从可行的传感器位置到相关但无法直接访问的位置的桥梁可行性。", "innovation": "该论文探索使用有限数量的实际传感器估计焊料层降解状态和相应全温度图的可行性。基于特定降解模式的合成数据，我们获得了高精度的受损焊料区域估计（平均绝对误差1.17%），并能够将IGBT表面温度重现的最大相对误差为4.56%（平均相对误差0.37%）。", "conclusion": "该论文证明了基于机器学习的虚拟传感方法在IGBT模块中用于焊料层降解及温度监测的可行性，并展示了该方法的有效性和高精度。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10533", "html_url": "https://arxiv.org/abs/2508.10533", "title": "通过频率选择和维数分离缓解量子机器学习中混合频率的双指数增长", "title_en": "Mitigating Exponential Mixed Frequency Growth through Frequency Selection and Dimensional Separation in Quantum Machine Learning", "authors": "Michael Poppel,David Bucher,Maximilian Zorn,Nico Kraus,Jonas Stein,Claudia Linnhoff-Popien", "background": "借助量子计算（QC）的潜在计算加速能力，量子机器学习（QML）的研究日益受到重视。角度编码技术在QML模型中能够生成截断的傅里叶级数，具有渐近通用函数逼近能力。通过在量子电路中选择高效的特征映射（FMs），可以利用傅里叶频率的指数增长来提高逼近性能。在多维设置中，额外的输入维度会造成进一步的指数级频率混频。然而，在实践中，量子模型在回归任务上经常失败，这可能是由参数不足导致的。", "innovation": "本文提出频率选择和维数分离两种技术，以限制参数数量进而提高模型训练性。通过限制QML模型到关键频率，并只能在特征维度有已知相互依赖性的情况下允许频率混频，可以扩大当前硬件可解决的问题范围。结果表明，通过这种技术可以减少参数需求，并在噪声量子模拟器上进行训练并在真实量子硬件上进行推理。", "conclusion": "通过两例白盒实验展示，频率选择和维数分离技术能够有效缓解因频率指数级增长导致的多参数增长问题。此技术使得在当前硬件上可处理更多问题，并证明了其在实际量子硬件上的可行性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10555", "html_url": "https://arxiv.org/abs/2508.10555", "title": "物理启发的深度对比源反演：一种统一的反散射问题框架", "title_en": "Physics-Informed Deep Contrast Source Inversion: A Unified Framework for Inverse Scattering Problems", "authors": "Haoran Sun,Daoqi Liu,Hongyu Zhou,Maokun Li,Shenheng Xu,Fan Yang", "background": "反散射问题在电磁成像和医学诊断中至关重要，但由于其非线性和多样的测量场景，该问题是具有挑战性的。传统方法如全波形反演由于计算成本高而受到限制。", "innovation": "该论文提出了一种物理启发的深度对比源反演框架（DeepCSI），它通过使用残差多层感知器（ResMLP）模型感兴趣区域在不同发射器激励下的电流分布，有效线性化了非线性反散射问题，并显著降低了传统全波形反演的计算成本。通过将介质参数建模为可学习的张量，并利用结合状态方程损失、数据方程损失和总变差正则化项的混合损失函数，DeepCSI 建立了一种全可微框架，用于同时优化网络参数和介质属性。与传统方法相比，DeepCSI 以其简单性和对多种测量场景的通用建模能力而具有优势，包括无相位和多频观测。", "conclusion": "仿真和实验结果表明，DeepCSI 在全数据、无相位数据和多频条件下实现了高精度和鲁棒的重构。相比传统的CSI方法，DeepCSI 提供了一个高效且通用的复杂反散射问题的解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10561", "html_url": "https://arxiv.org/abs/2508.10561", "title": "情绪计算中的可重复生理特征：唤醒建模的初步分析", "title_en": "Reproducible Physiological Features in Affective Computing: A Preliminary Analysis on Arousal Modeling", "authors": "Andrea Gargano,Jasin Machkour,Mimma Nardelli,Enzo Pasquale Scilingo,Michael Muma", "background": "在情绪计算领域，一个关键挑战是可靠地将主观的情绪体验与客观的生理标记联系起来。本文通过在心血管和电导率信号中识别与持续自我报告的唤醒水平相关的生理特征，探讨了重现性的问题。使用带有情绪诱发视频连续情绪标记的数据集，对30名参与者的生理信号提取出的164个特征进行了分析。", "innovation": "研究使用Terminating-Random Experiments (T-Rex) 方法进行了特征选择，该方法系统性地控制了用户定义的目标假发现率。研究结果表明，只有两个电导率衍生特征与唤醒水平具有可重复且统计显著的相关性，达到了100%的确认率。这一发现强调了在生理特征选择中进行严格重现性评估的重要性，这是情绪计算领域中经常被忽视的方面。本文的方法特别适用于需要可信可靠的白盒模型的安全关键环境中，例如精神障碍识别和人机交互系统。", "conclusion": "研究结果强调了严格重现性评估在生理特征选择中至关重要，而这一点在情绪计算领域常被忽视。T-Rex方法在减少假发现率的同时有效选择出了相关的生理特征，这种方法在安全关键的环境中具有潜在的优势。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10712", "html_url": "https://arxiv.org/abs/2508.10712", "title": "嵌入式SAR船只目标检测和分类的轻量级CNN", "title_en": "Lightweight CNNs for Embedded SAR Ship Target Detection and Classification", "authors": "Fabian Kresse,Georgios Pilikos,Mario Azcueta,Nicolas Floury", "background": "合成孔径雷达(SAR)数据可以实现海上船舶的大规模监视。然而，目前的实时监控受到需要通信将所有原始数据下传、进行成像聚焦和后续地面分析的限制。将部分处理任务移至卫星上可以减少需要下传的数据量，从而缓解带宽限制并减少延迟。但传统的图像聚焦和处理算法在卫星有限的内存、计算能力和计算资源面前存在挑战。本文探讨了在Sentinel-1采集的条带模式与干涉宽模式未聚焦的SAR数据上进行实时推断的神经网络模型的可行性和适用性，并通过二分类任务，即区分船只和风车，证明了目标分类的可能性。", "innovation": "本文提出并评估了一种针对Sentinel-1在条带模式和干涉宽模式中采集的未聚焦SAR数据的轻量级卷积神经网络(CNN)模型。该模型用于嵌入式处理(SAR)船目标检测和分类，旨在解决卫星上的计算资源受限问题。此外，通过实证研究和实验，验证了模型的有效性和实用性，展示了可以在现场可在现场进行船舶目标分类的能力。", "conclusion": "本文证明了轻量级CNN模型在嵌入式处理SAR数据中进行实时推理和目标分类的可行性，并为解决卫星数据处理的带宽和延迟挑战提供了一种新方法。同时，通过二分类实验成功实现了对船只和风车的区分，进一步展示了所提模型的实际应用潜力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10731", "html_url": "https://arxiv.org/abs/2508.10731", "title": "剖析泛化类别发现：自我分解下的多层共识", "title_en": "Dissecting Generalized Category Discovery: Multiplex Consensus under Self-Deconstruction", "authors": "Luyao Tang,Kunze Huang,Chaoqi Chen,Yuxuan Yuan,Chenxin Li,Xiaotong Tu,Xinghao Ding,Yue Huang", "background": "人类感知系统能够识别和理解已知和未知的类别，这一能力超越了现有的机器学习框架。虽然泛化类别发现（GCD）旨在弥合这一差距，但现有方法主要集中在优化目标函数上。本文探讨了基于人类认知过程解决新物体理解问题的方法，通过将物体分解为视觉基本构建块，并建立起跨知识的比较。", "innovation": "本文提出了一种名为ConGCD的新方法，该方法通过高层次语义重构建立以基本构建块为导向的表示，利用拆分技术连接同类之间的共享属性。我们引入主导性和情境性共识单元分别捕捉类别区分特征和内在分布不变性，同时采用共识调度器动态优化激活路径，并通过多层共识整合得出最终预测。这一创新方法在粗细粒度基准测试中的广泛应用证明了其有效性和优势。", "conclusion": "广泛的评估表明，ConGCD作为共识感知框架的有效性。这为泛化类别发现领域提供了新的视角和思路。相关代码已公开。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10677", "html_url": "https://arxiv.org/abs/2508.10677", "title": "提升自主响应事件：利用大语言模型和网络安全威胁情报", "title_en": "Advancing Autonomous Incident Response: Leveraging LLMs and Cyber Threat Intelligence", "authors": "Amine Tellache,Abdelaziz Amara Korba,Amdjed Mokhtari,Horea Moldovan,Yacine Ghamri-Doudane", "background": "有效的事件响应（IR）对于减轻网络威胁至关重要，但安全团队却因疲劳警报、高误报率和大量无结构的威胁情报（CTI）文件而感到压力山大。尽管CTI具有极大潜力丰富安全运营，但由于其规模庞大且碎片化，手工分析费时且资源密集。为了弥合这一差距，我们引入了一种基于检索增强生成（RAG）的新颖框架，利用大型语言模型（LLMs）自动化和增强IR，通过动态检索的CTI进行整合。该方法结合了基于NLP的相似性搜索和标准化查询的混合检索机制，这使得在CTI向量数据库内搜索和外部CTI平台查询有机结合，从而实现上下文相关的安全警报增强。增强的人工智能随后由一个基于LLM的响应生成模块利用，以制定精确、可行动且上下文相关的情报缓解策略。", "innovation": "介绍了一种基于检索增强生成（RAG）的框架，利用大型语言模型（LLMs）自动化和增强IR，通过动态检索CTI进行整合。该方法结合了基于NLP的相似性搜索和标准化查询的混合检索机制，使得在CTI向量数据库内搜索和外部CTI平台查询有机结合，从而实现上下文相关的安全警报增强，并利用增强的人工智能由一个基于LLM的响应生成模块制定详细的响应策略。此外，该研究提出了一种双评估范式，其中自动化评估由辅助LLM进行，系统的跨验证由网络安全专家执行。", "conclusion": "实证验证表明，该方法提高了IR的精确性、上下文相关性及效率，缓解了分析师的工作负担并减少了响应延迟。这项工作突显了大语言模型驱动的CTI融合在促进自主安全运营方面的潜力，并为智能、适应性网络安全框架奠定了基础。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10718", "html_url": "https://arxiv.org/abs/2508.10718", "title": "用于石墨烯电子能带结构预测的约束多尺度物理感知神经网络", "title_en": "Symmetry-Constrained Multi-Scale Physics-Informed Neural Networks for Graphene Electronic Band Structure Prediction", "authors": "Wei Shan Lee,I Hang Kwok,Kam Ian Leong,Chi Kiu Althina Chau,Kei Chon Sio", "background": "在二维材料中准确预测电子能带结构是一个基本挑战，现有方法难以平衡计算效率和物理准确性。", "innovation": "提出了约束多尺度物理感知神经网络（SCMS-PINN）v35，该网络直接学习石墨烯能带结构并通过多头架构严格遵守晶体学对称性。该方法引入了三个专门的ResNet-6通路——K头处理狄拉克物理，M头处理鞍点，通用头进行平滑插值，基于31个从k点提取的物理感知特征。系统性的狄拉克约束调度逐步增加权重参数，从5.0增加到25.0，实现从全局拓扑到局部关键物理的分层学习。在10,000个k点上训练300个周期后，训练损失从34.597减少到0.003，验证损失为0.0085。该模型在理论零点附近的狄拉克点间隙预测误差在30.3 μeV内，泛区平均误差分别为53.9 meV（价带）和40.5 meV（导带）。通过系统平均，所有12个C_6v操作都被强制执行，确保对称性精确保持。", "conclusion": "该框架为加速二维材料发现提供了物理感知学习的基础。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10745", "html_url": "https://arxiv.org/abs/2508.10745", "title": "Agentic Design Review System", "title_en": "Agentic Design Review System", "authors": "Sayan Nag,K J Joseph,Koustava Goswami,Vlad I Morariu,Balaji Vasan Srinivasan", "background": "评估图形设计涉及从对齐、构成、美感和颜色选择等多个方面进行评估。整体评估设计需要汇总来自多个专家评审者的反馈。为了实现这一目标，作者提出了一种代理设计审查系统（AgenticDRS），其中多个代理协作分析一个设计，由一个元代理协调。该论文通过一个基于图匹配的上下文内实例选择方法和一种独特的提示扩展示方法，提高了每个代理的设计意识，旨在评估该框架并生成有效的反馈。为了评估该框架，作者提出了DRS-BENCH基准，实验证明Agentic-DRS在评估图形设计方面的有效性，并在现有基准之上进行了关键的消融实验，进一步证实了其效果。这一工作旨在吸引对该实用且未充分探索的研究方向的关注。", "innovation": "提出了Agentic Design Review System（AgenticDRS）系统，该系统采用了多个代理协同分析设计的方式，并由元代理协调实现协作。该系统的核心创新包括基于图匹配的上下文内实例选择方法和一种独特的提示扩展示方法，用于提高每个代理的设计意识，以及通过DRS-BENCH基准来评估该系统的效率和有效性。", "conclusion": "通过实证研究，验证了Agentic-DRS在评估图形设计和生成有效反馈方面的有效性。该工作展示了代理协同设计审查方法的潜力，并有望激发对该研究方向的兴趣。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10807", "html_url": "https://arxiv.org/abs/2508.10807", "title": "奇异性交叉共振：一个量子多比特门", "title_en": "Parity Cross-Resonance: A Multiqubit Gate", "authors": "Xuexin Xu,Siyu Wang,Radhika Joshi,Rihan Hai,Mohammad H. Ansari", "background": "该研究介绍了利用工程化相互作用实现单一共面步骤中控制-控制-目标和控制-目标-目标操作的原生三比特纠缠门。这种方法不同于将操作分解为多个两比特门的方式，通过混合优化方法有选择地放大所需相互作用并抑制不需要的耦合，从而在计算子空间内以及超出空间提供稳健性。", "innovation": "提出了一种新的三比特交叉共振门，该门可以作为交叉共振门进行分类。利用这种门可以实现GHZ三态的制备、量子逻辑演示和实施控制-ZZ门等多种功能，尤其是后者能够直接将两个数据比特的奇偶性映射至测量比特上，从而在表面码量子纠错中提供更快更准确的纠错测量。研究还展示了这种三比特门的性能在希尔伯特空间尺寸变化时保持稳健。", "conclusion": "该研究为下一代超导量子处理器的电路架构和控制协议设计奠定了基础，使其能够充分利用本征多比特相互作用作为核心元素。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10765", "html_url": "https://arxiv.org/abs/2508.10765", "title": "学习霍普夫神经网络中的记忆与遗忘：分岔机制、吸引子和相盆地", "title_en": "Memorisation and forgetting in a learning Hopfield neural network: bifurcation mechanisms, attractors and basins", "authors": "Adam E. Essex(1),Natalia B. Janson(1),Rachel A. Norris(1),Alexander G. Balanov(1) ((1) Loughborough University, England)", "background": "尽管基于人工神经网络（ANNs）的人工智能得到了爆炸性增长，但这些ANNs仍然被当作‘黑匣子’，因为不清楚在学习过程中它们是如何形成记忆或发展不需要的功能，包括虚假记忆和灾难性遗忘。关于ANNs学习的孤立方面有很多研究，但由于其高维度和非线性特性，其全面分析仍然具有挑战性。在ANNs中，知识被认为存于连接权重中或在吸引子盆地中，但这两种范式没有直接关联。本研究利用81个神经元的霍普夫网络，通过揭示导致形成和破坏吸引子及其盆地边界的分岔机制，全面分析了进行海emm式学习的ANNs的记忆形成机制。研究表明，通过影响连接权重的进化，所施加的刺激引发了一系列机制，导致虚假记忆或真实记忆的编码机制的形成，并导致旧记忆的突然消失（灾难性遗忘）。通过这些机制，记忆的形成和遗忘实际上是同一机制的两种表现形式。", "innovation": "本研究采用了一种普遍适用的策略来分析高维度学习神经网络，适用于任何形式的循环神经网络，并揭示了记忆形成和灾难性遗忘的机制。该研究进一步展示了对霍普夫神经网络中记忆形成和灾难性遗忘的理解可应用于更广泛的循环神经网络类别，有助于开发减少其缺陷的方法。", "conclusion": "本研究通过对81个神经元霍普夫网络的海emm式学习进行全面分析，揭示了使新的真假记忆形成和旧记忆消失的分岔机制。记忆的形成和遗忘代表了相同机制的不同表现形式，并且研究方法是通用的，适用于不同形式的循环神经网络的学习机制分析。这为理解及改进ANNs的性能提供新的见解。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10817", "html_url": "https://arxiv.org/abs/2508.10817", "title": "针对33种作物101类植物病害的轻量级CNN基准：嵌入式深度学习移动友好解决方案", "title_en": "Mobile-Friendly Deep Learning for Plant Disease Detection: A Lightweight CNN Benchmark Across 101 Classes of 33 Crops", "authors": "Anand Kumar,Harminder Pal Monga,Tapasi Brahma,Satyam Kalra,Navas Sherif", "background": "植物疾病是全球粮食安全的重要威胁。发展早期检测系统，能够准确识别植物病害至关重要。计算机视觉技术的进步有望解决这一挑战。", "innovation": "开发了一种便携式解决方案，能够准确分类33种作物的101种植物病害；整合了Plant Doc、PlantVillage和PlantWild等不同数据集以构建综合数据集；选择了MobileNetV2、MobileNetV3、MobileNetV3-Large和EfficientNet-B0、B1等多种轻量级架构进行评估，特别针对资源限制的设备效率进行了选择；EfficientNet-B1表现出最佳性能，准确率为94.7%，在准确性和计算效率之间达到了最佳平衡。", "conclusion": "此架构适用于移动设备的现实世界部署，提供了一种轻量级CNN基准，为植物病害检测提供了便携式解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10827", "html_url": "https://arxiv.org/abs/2508.10827", "title": "加速系外行星气候建模：补充三维GCM格点模拟的机器学习方法", "title_en": "Accelerating exoplanet climate modelling: A machine learning approach to complement 3D GCM grid simulations", "authors": "Alexander Plaschzug,Amit Reza,Ludmila Carone,Sebastian Gernjak,Christiane Helling", "background": "随着观测系外行星大气技术的不断改进，观测到的系外行星数量和详细程度不断增加，对支持和解释如CHEOPS、TESS、JWST、PLATO和Ariel等太空任务的观测数据的3D气候模型的需求也在增长。然而，通用 circulation 模型（GCM）的计算强度和耗时性质使得模拟广泛的系外行星大气成为了巨大的挑战。", "innovation": "该研究旨在确定机器学习（ML）算法是否可以用于预测任意潮汐锁定的气态系外行星的3D温度和风结构，并引入了一个新的3D GCM网格，其中包括使用ExoRad建模的60颗膨胀的热木星，它们绕行A、F、G、K、和M型恒星运行。DNN和XGBoost决策树算法被训练以预测局部气体温度和水平及垂直风。", "conclusion": "在潮汐锁定的气态类木行星周围A到M型恒星处，开发的ML模拟器可以可靠地预测整个3D温度场。这种方法为传统的GCM网格补充了快速工具，适用于系外行星集合研究。预测的质量使得对气相化学、云形成和传输光谱的影响可以忽略不计或最小化。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10774", "html_url": "https://arxiv.org/abs/2508.10774", "title": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "title_en": "Video-BLADE: Block-Sparse Attention Meets Step Distillation for Efficient Video Generation", "authors": "Youping Gu,Xiaolong Li,Yuhao Hu,Bohan Zhuang", "background": "扩散变换器在高质量视频生成方面目前处于领先地位，但它们缓慢的迭代去噪过程和长序列带来的二次注意力成本导致了显著的推理瓶颈。尽管步进蒸馏和稀疏注意力机制分别作为一种加速策略显示出潜力，但有效结合这两种方法依然存在重大挑战。既有的训练免费整合方法效果欠佳，而分别训练稀疏注意力的策略则需要消耗大量昂贵的数据。因此，迫切需要一种有效的解决方案来克服这些局限。", "innovation": "本文提出了一种名为BLADE（Block-Sparse Attention Distillation Efficient Framework）的创新数据免费联合训练框架，它引入了1）自适应块稀疏注意力（ASA）机制，用于动态生成内容感知的稀疏性掩码，以集中计算于时空显着特征；以及2）一种基于轨迹分布匹配（TDM）的稀疏性感知的步进蒸馏范式，将稀疏性直接融入到蒸馏过程中，而不是将其视为单独的压缩步骤。这项工作解决了单独训练稀疏注意力的高昂成本问题，并实现了快速收敛。", "conclusion": "我们在文本到视频模型如CogVideoX-5B和Wan2.1-1.3B上验证了BLADE。我们的框架在不同规模上展现出显著的效率提升。在Wan2.1-1.3B上，BLADE实现了相对于50步基线的14.10倍端到端的推理加速。对于CogVideoX-5B这样的视频序列较短的模型，我们的框架提供了稳健的8.89倍加速。加速的同时伴随的是质量的持续提升。在VBench-2.0基准测试中，BLADE提升了CogVideoX-5B的得分为0.569（从0.534提高），Wan2.1-1.3B的得分为0.570（从0.563提高），这一结果得到了高级别的人类评价认可。更多详情参见本项目的公开代码和模型权重: this http URL"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10839", "html_url": "https://arxiv.org/abs/2508.10839", "title": "强化语言模型用于顺序决策", "title_en": "Reinforced Language Models for Sequential Decision Making", "authors": "Jim Dilkes,Vahid Yazdanpanah,Sebastian Stein", "background": "大语言模型（LLMs）在作为序列决策代理方面表现出潜力，但由于依赖于大型、计算昂贵的模型，其应用受到限制。现有后训练方法针对单轮对话，无法处理多步骤代理任务中的信用分配。为解决这一问题，研究人员引入了一种新的后训练算法Multi-Step Group-Relative Policy Optimization (MS-GRPO)，该算法基于形式化的Text-Mediated Stochastic Game (TSMG)和Language-Agent Policy (LAP)框架，并通过整个累积回合奖励分配到每个单独回合步骤中来实现信用分配。为了优化训练性能，研究者还提出了一个新的绝对优势加权回合采样策略。", "innovation": "该研究提出了Multi-Step Group-Relative Policy Optimization (MS-GRPO)，这一新的后训练算法不仅解决了多步骤代理任务中信用分配的问题，还通过绝对优势加权回合采样策略增强了训练性能。研究在30亿参数的Snake和Frozen Lake任务上对模型进行了后训练，结果表明，后训练模型的决策表现得到了显著提升，与720亿参数的基线相比，在Frozen Lake任务上性能提高了50%。", "conclusion": "这项工作证明了针对性的后训练是一种在使用LLMs创建序列决策代理时实用且效率高的替代方法，与依赖于模型规模相比，这种方法更具优势。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10851", "html_url": "https://arxiv.org/abs/2508.10851", "title": "CrossDenoise: 通过一种轻量级实体感知协同框架去噪隐式反馈", "title_en": "CrossDenoise: Denoising Implicit Feedback via a Lightweight Entity-Aware Synergistic Framework", "authors": "Ze Liu,Xianquan Wang,Shuochen Liu,Jie Ma,Huibo Xu,Yupeng Han,Zhe Yang,Kai Zhang,Longfei Li,Jun Zhou", "background": "推荐系统高度依赖隐式反馈，但因为存在误报和漏报，导致反馈本身具有很大的噪音。现有的去噪策略往往忽视了实体感知建模，存在计算负担高和需要大量超参数调优等问题，限制了它们在实际中的应用效果。", "innovation": "提出了CrossDenoise框架，通过将噪声估计分解为用户、物品和交互特定的因素来解决上述问题。该框架通过基于经验的平均训练损失的等级线性映射计算实体声誉因素（用户/物品的可靠性），并结合经验累积分布函数（ECDF）对个体损失的交互层次权重进行融合。该设计对模型无依赖性，计算效率高，只需要两个直观的超参数。在ML-1M、Yelp和Amazon-book数据集上，该框架在GMF、NeuMF和CDAE的多个基础上表现出对现有最佳基线的一致且显著的性能提升，同时计算和内存开销可忽略不计。我们的分析表明，CrossDenoise能够有效地辨别出清洁样本与噪声样本，并在不同的超参数设置下保持稳健性。", "conclusion": "CrossDenoise提供了一种实用且可扩展的隐式反馈去噪解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10875", "html_url": "https://arxiv.org/abs/2508.10875", "title": "A Survey on Diffusion Language Models", "title_en": "A Survey on Diffusion Language Models", "authors": "Tianyi Li,Mingda Chen,Bowei Guo,Zhiqiang Shen", "background": "扩散语言模型（DLMs）正在迅速成为自回归（AR）范式的一个强大且有前途的替代方案。通过迭代去噪过程并行生成标记，DLMs在减少推理延迟和捕捉双向背景方面具有内在优势，从而允许对生成过程进行精细控制。近年来的进步使DLMs在性能上达到了与自回归模型相当的水平，它们在各种自然语言处理任务中具有吸引力的选择。", "innovation": "本文综述了扩散语言模型的当前概况，追溯了其演变及其与其他模型（如自回归和掩码语言模型）的关系。覆盖了基础原理、先进技术、预训练策略以及高级后训练方法。详细分析了各种生成策略和优化措施，包括解码并行性、缓存机制和生成质量的改进。还讨论了DLM的多模态扩展及其在各种实际场景中的应用。", "conclusion": "本文还指出了DLM的局限性和挑战，包括效率、长序列处理和基础设施需求。同时明确了未来的研究方向，以保持这个快速发展的领域的进展。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10841", "html_url": "https://arxiv.org/abs/2508.10841", "title": "显式长程相互作用下的通用机器学习势能在生物分子模拟中的性能", "title_en": "Performance of universal machine-learned potentials with explicit long-range interactions in biomolecular simulations", "authors": "Viktor Zaverkin,Matheus Ferraz,Francesco Alesiani,Mathias Niepert", "background": "通用机器学习势能在各种组成和振动自由度方面承诺了可转移的准确性，但在生物分子模拟中的应用相对不足。该研究系统地评估了在SPICE-v2数据集上训练的守恒消息传递架构，研究了是否包含显式的长程色散和电荷相互作用对模型性能的影响。评估指标包括模型大小、训练数据组成及电荷处理方式，对不同数据集的基准测试以及生物分子模拟（包括纯水、含NaCl的水溶液、以及氨基酸三肽、Trp-cage和Crambin等分子）中的性能进行了综合考察。", "innovation": "研究使用SPICE-v2数据集训练守恒消息传递架构，并系统性地评估了不同类型数据（含不含长程相互作用）和不同模型规模（从小到大）下守恒消息传递架构的表现；研究了训练数据组成对预测结果的影响，提出了长程电荷相互作用对不同生物分子性能的影响；考察了在生物分子模拟（纯水、含NaCl的水溶液、和具体生物分子）中的表现。", "conclusion": "较大的模型在基准数据集上的预测准确性更高，然而这种趋势并不一定延续到各种模拟特性。训练数据集的不平衡和不成熟的评估方法限制了通用机器学习势能在生物分子模拟中的适用性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10887", "html_url": "https://arxiv.org/abs/2508.10887", "title": "代表基准问题领域的回声状态网络配置经验研究", "title_en": "Empirical Investigation into Configuring Echo State Networks for Representative Benchmark Problem Domains", "authors": "Brooke R. Weborg,Gursel Serpen", "background": "本文探讨了使用四种不同的基准问题研究回声状态网络（Echo State Network, ESN）的表现，并分析了ESN配置及其参数选择和调整对结果的影响。对于进入这个领域的研究者来说，完全理解ESN的不同参数选择及其调优对网络架构性能的影响需要丰富的经验，而一些超参数优化算法也难以在没有合理手动选择的情况下调整参数值。", "innovation": "本文提出了针对相同领域问题的ESN架构配置、参数选择及其值的启发式规则或常识，有助于弥补初学者的经验空白，并通过一系列基准任务展示了ESN在不同类型问题领域中的性能影响。", "conclusion": "研究结果表明，为了实现ESN架构成功构建，理解参数及其值选择对ESN架构性能的影响至关重要。本文通过使用时间序列预测、模式生成、混沌系统预测和时间序列分类等不同问题领域的基准任务，展示了对ESN架构配置及其影响的深入分析，有助于填补新手在该领域的经验空白。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.10879", "html_url": "https://arxiv.org/abs/2508.10879", "title": "具有自适应噪声的迭代Differential Privacy k-PCA算法", "title_en": "An Iterative Algorithm for Differentially Private $k$-PCA with Adaptive Noise", "authors": "Johanna Düngler,Amartya Sanyal", "background": "现有Differentially Private Stochastic PCA方法存在两个主要问题：一是样本大小需要与维度平方成比例甚至更大；二是即使数据内在随机性较小，也过度引入了噪声以保护隐私。Liu等人（2022a）在亚高斯数据的情况下解决了这些问题，但他们仅能估计最大特征向量（k=1）。该领域需要一种能估计任意k个最大特征向量的有效算法，同时克服以上限制。对于k=1的情况，这种算法应与DP-PCA的性能相当，即使n等于d的渐近注意数也能达到近最优的统计误差。对于k>1的一般情况，需要给出一种上界并进行实验验证，证明新算法相较于现有基准的优势。", "innovation": "本文提出了第一个能够在任意k≤d的条件下估计前k个最大特征向量的同时克服上述限制的算法。对于k=1的情况，该算法的性能与DP-PCA相似，即使样本数量为d的渐近注意数时也能达到近最优的统计误差。对于k>1的一般情况，提供了上界并匹配了上界，实验结果表明该算法优于基准算法。", "conclusion": "该研究解决了Differentially Private Stochastic PCA的两个关键问题，不仅给出了k=1情况下的算法保证，还给出了针对多维情况的一般性结果。通过自适应噪声的技术，该算法在保护隐私的同时提高了统计效率，实验结果验证了其优越性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2111.04578", "html_url": "https://arxiv.org/abs/2111.04578", "title": "神经网络微调的改进正则化和鲁棒性", "title_en": "Improved Regularization and Robustness for Fine-tuning in Neural Networks", "authors": "Dongyue Li,Hongyang R. Zhang", "background": "迁移学习中常用的方法是微调，即将预训练模型在目标任务上进行微调，以少量标记数据来适应新的任务。然而，当预训练模型的容量远大于目标数据集的大小时，微调容易导致过拟合和记住训练标签。因此，如何实现微调的正则化，提高微调方法的鲁棒性，成为一个重要问题。本文通过分析微调的一般化性质来探讨这一问题，并提出了一种改进的方法——结合层wise正则化和自我标签修正、权重调整方法。", "innovation": "本文的主要创新在于提出了基于PAC-Bayes泛化边界的分析方法，以及提出了一种新的正则化自我标签方法，该方法包括逐层正则化限制各层的旅行距离，自我标签修正和标签重新加权来纠正错误标签和调整标签权重的方法。并在多项预训练模型架构上评估了该方法，表现出稳定的性能提升，尤其在标注噪声情况下显著优于基线方法。", "conclusion": "在七个图像分类任务上，本文的方法平均优于基线方法1.76%，在少量分类任务上平均优于基线方法0.75%。当目标数据集包含噪声标签时，该方法在两个噪声环境下平均优于基线方法3.56%。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.00873", "html_url": "https://arxiv.org/abs/2401.00873", "title": "统一自监督聚类与能量模型", "title_en": "Unifying Self-Supervised Clustering and Energy-Based Models", "authors": "Emanuele Sansone,Robin Manhaeve", "background": "自监督学习擅长从大量数据中学习表示，而生成模型则能够在学习关于数据生成过程的信息方面提供互补特性。本研究旨在建立这两者之间的原理性联系，并强调它们互补性的优点。通过对自监督学习目标进行分析，揭示其背后的概率图模型并提供一种从基本原理出发的标准方法来推导，指出自监督学习可以自然地与基于似然性的生成模型结合使用的方法。", "innovation": "提出了基于聚类的自监督学习和能量模型的基础上，引入了一种下界证明能可靠惩罚最重要的失败模式的方法，从而实现完全统一。通过合成和真实数据（包括SVHN、CIFAR10和CIFAR100）上的实验验证了理论发现，证明了目标函数能够联合训练一个判别性和生成性特征网络，相对于现有的自监督学习策略，在聚类、生成和异常检测性能方面显著优于现有方法。还展示了该解决方案可以集成到神经符号框架中，以解决简化的符号接地问题。开源代码详见提供的链接地址。", "conclusion": "通过将自监督学习与基于似然性的生成模型相结合，提出的方法在聚类、生成和异常检测性能方面显著优于现有自监督学习策略，同时也展示了在符号接地问题上的应用潜力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2112.06362", "html_url": "https://arxiv.org/abs/2112.06362", "title": "学习在具有随机双线性奖励并行服务器队列中的调度", "title_en": "Learning to Schedule in Parallel-Server Queues with Stochastic Bilinear Rewards", "authors": "Jung-hun Kim,Milan Vojnovic", "background": "研究了多类别并行服务器排队系统中，工作服务器分配具有不确定性回报的调度问题。在这种情况下，工作在完成之前会产生持有成本，而工作服务器分配会产生可观测的随机回报，但这些回报的期望值未知。我们假设，工作服务器分配的期望回报遵循关于工作和服务器特征的双线性模型。目标是在保持总工作持有成本限制在一定范围，确保排队系统的稳定性的前提下，最大化工作服务器分配的累计回报，从而最小化悔恨。这个问题源于网络系统中资源分配的应用需求。在此问题中，必须控制奖励最大化与公平分配之间的权衡以确保基础排队系统的稳定性（即最大化网络吞吐量）.", "innovation": "提出了一种基于加权比例公平准则的调度算法，该算法结合了边际成本来最大化奖励。专门为双线性奖励设计的多臂赌博机算法也得到了应用。该算法实现了亚线性后悔率和亚线性的平均持有成本（和队列长度上限）分别为O(√T)的时间范围T，从而确保排队系统的稳定性。我们还建立了分布式迭代算法的稳定性条件，对于大规模系统具有重要意义。此外，通过数值实验验证了该算法的效率.", "conclusion": "该算法通过有效的控制奖励最大化与公平分配之间的权衡，实现了排队系统的稳定性，并通过理论分析及其在大规模系统中的稳定性和实际效率得到了验证。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.04443", "html_url": "https://arxiv.org/abs/2406.04443", "title": "当噪声为厚尾时，裁剪提升Adam-Norm和AdaGrad-Norm的性能", "title_en": "Clipping Improves Adam-Norm and AdaGrad-Norm when the Noise Is Heavy-Tailed", "authors": "Savelii Chezhegov,Yaroslav Klyukin,Andrei Semenov,Aleksandr Beznosikov,Alexander Gasnikov,Samuel Horváth,Martin Takáč,Eduard Gorbunov", "background": "自适应步长方法如AdaGrad和Adam在训练现代深度学习模型（尤其是大规模语言模型）中至关重要。随着训练进展，随机梯度噪声往往呈现厚尾特性。已有研究表明，梯度裁剪可以有效地处理这种噪声，但对AdaGrad/Adam这类方法在厚尾噪声下的高概率收敛性理解有限。在本文中，作者证明了在厚尾噪声情况下，AdaGrad/Adam及其延迟版本可能会有糟糕的高概率收敛性能。作者还展示了梯度裁剪可以解决这一问题，即阐明了裁剪后AdaGrad-Norm和Adam-Norm在光滑凸/非凸随机优化中的新高概率收敛界限，这些界限对置信水平具有多项对数依赖性，同时考虑了延迟步长的情况。实验结果表明裁剪版的AdaGrad/Adam在处理厚尾噪声时具有优势。", "innovation": "作者首次证明了在厚尾噪声下，AdaGrad/Adam及其延迟版本可能会表现出糟糕的高概率收敛性，而梯度裁剪可以解决这一问题。作者推导了裁剪后的AdaGrad-Norm和Adam-Norm在光滑凸/非凸随机优化中的新高概率收敛界限，加入了对延迟步长情况的分析。实验结果证实了裁剪版AdaGrad/Adam在厚尾噪声环境下的优越性。", "conclusion": "裁剪是处理厚尾噪声时AdaGrad/Adam及其延迟版本的有效手段，裁剪可以保证这些算法在厚尾噪声下的高概率收敛性，且实验证明这种方法具有较强的实用性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.12446", "html_url": "https://arxiv.org/abs/2409.12446", "title": "神经网络在低复杂度数据上泛化", "title_en": "Neural Networks Generalize on Low Complexity Data", "authors": "Sourav Chatterjee,Timothy Sudijono", "background": "该论文探讨了具有ReLU激活函数的前向神经网络在简单数据集上泛化的现象。通过从简单的编程语言随机生成 i.i.d.数据，研究了最小描述长度（MDL）神经网络在插值这些数据时的高泛化能力。论文定义了这种简单编程语言及其网络描述长度的概念，并通过实例研究了基本计算任务（例如，质数检测）中的泛化性能。", "innovation": "论文提出，具有ReLU激活函数的前向神经网络在低复杂度数据上具有良好的泛化能力。通过最小描述长度（MDL）神经网络插值简单的编程语言生成的数据，可以准确预测新数据的性质，特别是在质数检测的任务中。此外，研究还讨论了噪音数据的扩展问题，表明MDL神经网络插值器可以在一定程度上展示出适度的过拟合能力。", "conclusion": "研究发现，最小描述长度（MDL）神经网络能够高概率地泛化简单编程语言生成的低复杂度数据。在质数检测任务中，通过插值的MDL网络能够在错误概率为$1- O((\frac{\text{ln } N}{n}))$的情况下准确预测新数据的质数属性。此外，对噪音数据的扩展性研究进一步表明MDL插值器的泛化能力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.07275", "html_url": "https://arxiv.org/abs/2409.07275", "title": "通过隐式正则化实现无需调优的在线鲁棒主成分分析", "title_en": "Tuning-Free Online Robust Principal Component Analysis through Implicit Regularization", "authors": "Lakshmi Jayalal,Gokularam Muthukrishnan,Sheetal Kalyani", "background": "标准的在线鲁棒主成分分析（OR-PCA）技术的表现依赖于显式正则化参数的最佳调整，而这些参数往往需要对特定的数据集进行敏感调整。因此，论文旨在通过使用隐式正则化方法消除对这些调整参数的依赖，提出了一种利用不同修改梯度下降方法来实现OR-PCA无需调优的功能。这种方法在数据稀疏性和低秩结构方面具有三种不同的增强版本，适用于模拟数据集和真实数据集的结果。这种方法在不需要数据集特定参数调整的情况下，对于大规模数据集具有更高的可扩展性。", "innovation": "本文提出了一种通过隐式正则化实现的在线鲁棒主成分分析方法（Tuning-Free ORPCA），该方法使用不同版本的改良梯度下降来促进数据的稀疏性和低秩结构，无需对数据集进行依赖性的参数调整。该方法在模拟和实际数据集上的表现与调优的OR-PCA相当或更优。这让它在处理大规模数据集时更为高效和灵活。", "conclusion": "Tuning-Free ORPCA 方法无需进行具体的参数调优，能够更好地适用于大规模数据集，且在性能上达到或超过了调优的 OR-PCA 方法，展示了改进算法在实际应用中的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06151", "html_url": "https://arxiv.org/abs/2410.06151", "title": "使用外在行为好奇心来多样化策略行为", "title_en": "Diversifying Policy Behaviors with Extrinsic Behavioral Curiosity", "authors": "Zhenglin Wan,Xingrui Yu,David Mark Bossens,Yueming Lyu,Qing Guo,Flint Xiaofeng Fan,Yew Soon Ong,Ivor Tsang", "background": "模仿学习（IL）在各种应用（如机器人运动）中表现出潜力，但通常仅限于学习单个专家策略，这限制了行为的多样性和鲁棒性，特别是在不可预测的现实世界场景中。", "innovation": "该论文提出了Quality Diversity Inverse Reinforcement Learning (QD-IRL)框架，结合了质量多样性优化与逆向强化学习方法，使得代理可以从有限演示中学习多样化的行为。此外，论文引入了Extrinsic Behavioral Curiosity (EBC)，通过外部评论家根据行为的新颖性提供额外的好奇心奖励来促进探索。", "conclusion": "EBC与GAIL、VAIL和DiffAIL等方法结合，在所有测试环境中性能提高了185%、42%和150%，甚至在模仿学习专家表现方面还提高了20%。EBC还适用于基于Gradient-Arborescence的质量多样性强化学习算法（QD-RL），大幅提高了性能，并为学习行为多样策略提供了一种通用技术。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10915", "html_url": "https://arxiv.org/abs/2410.10915", "title": "HGAurban: Heterogeneous Graph Autoencoding for Urban Spatial-Temporal Learning", "title_en": "HGAurban: Heterogeneous Graph Autoencoding for Urban Spatial-Temporal Learning", "authors": "Qianru Zhang,Xinyi Gao,Haixin Wang,Dong Huang,Siu-Ming Yiu,Hongzhi Yin", "background": "空间-时间图表示在城市感知应用中扮演着关键角色，包括交通分析、人类移动行为建模和全市犯罪预测。然而，由于空间-时间数据的噪声性和稀疏性，现有神经网络难以从空间-时间图中学习有意义的区域表示。", "innovation": "我们提出了HGAurban，一种新颖的基于生成式自监督学习的空间-时间异构图掩码自编码器，用于鲁棒的城市数据表示。框架中引入了空间-时间异构图编码器，可以从多源数据中提取区域依赖关系，实现对不同空间关系的综合建模。", "conclusion": "我们在多个空间-时间数据挖掘任务中的全面实验表明，我们的框架在处理真实世界的城市数据挑战方面优于最先进的方法，包括空间和时间维度的噪声和稀疏性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.10320", "html_url": "https://arxiv.org/abs/2410.10320", "title": "DiRW：路径感知定向图学习以应对异质性", "title_en": "DiRW: Path-Aware Digraph Learning for Heterophily", "authors": "Daohan Su,Xunkai Li,Zhenjun Li,Yinping Liao,Rong-Hua Li,Guoren Wang", "background": "近年来，图神经网络（GNN）已发展成为处理图结构数据的强大表征学习工具。然而，大多数方法针对的是无向图，忽视了有向图（有向图）边中丰富的信息。虽然有向图在现实世界中广泛应用并被证实能应对异质性挑战，现有的基于空间和频谱的有向图神经网络（DiGNN）由于其复杂的学习机制和对高质量拓扑的依赖，存在效率低和性能不稳定的问题。", "innovation": "本文提出了定向随机游走（DiRW），作为一种插件式策略，针对大多数基于空间的DiGNNs，并且是一种创新性模型，提供了一种新的有向图学习范式。DiRW 利用了节点特征和拓扑，以无权重方式优化了适应性路径采样器，特别考虑了行走概率、长度和数量。在此基础上，引入了节点级别的可学习路径聚合器，用于生成通用的节点表示。广泛的实验结果在 9 个数据集上证明，DiRW 能够显著提升大多数基于空间的方法的性能，并且作为新的有向图学习范式实现SOTA性能。", "conclusion": "实验结果表明，DiRW 作为插件式策略可提升大多数基于空间的方法；作为新的有向图学习范式，DiRW 能达成最佳性能。相关源代码和数据已公开。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.18368", "html_url": "https://arxiv.org/abs/2410.18368", "title": "CPU设计空间探索中的多目标优化：一切只需注意机制", "title_en": "Multi-objective Optimization in CPU Design Space Exploration: Attention is All You Need", "authors": "Runzhen Xue,Hao Wu,Mingyu Yan,Ziheng Xiao,Guangyu Sun,Xiaochun Ye,Dongrui Fan", "background": "现代CPU设计需要探索复杂的设计空间，现有的框架在高维度设计空间中难以扩展和通用。现有框架面临三个根本挑战：（1）大设计空间中代理模型的准确度降低和扩展性差；（2）通过手工构建的启发式或穷尽搜索效率低；（3）缺乏可解释性，难以识别架构瓶颈。", "innovation": "提出了一种名为AttentionDSE的端到端DSE框架，通过基于注意的神经架构将性能预测和设计指导自然集成。创新点包括：（1）感知驱动的注意机制，可以利用架构层次结构和局部性，将注意复杂性从O(n^2)降低到O(n)；（2）注意驱动的瓶颈分析，可自动揭示关键参数，消除领域特定启发式的需求。", "conclusion": "通过使用SPEC CPU2017基准套件评估，与最先进的基线相比，AttentionDSE在Pareto超体积上提高了最高3.9%和探索时间减少了超过80%。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.21072", "html_url": "https://arxiv.org/abs/2410.21072", "title": "特征和时间上不一致数据的联邦时间序列生成", "title_en": "Federated Time Series Generation on Feature and Temporally Misaligned Data", "authors": "Zhi Wen Soi,Chenrui Fan,Aditya Shankar,Abele Mălan,Lydia Y. Chen", "background": "分布式的时序数据为联邦学习带来了挑战，因为客户端持有的特征集可能不同，且时间步长不一致。现有的联邦时间序列模型受限于时间或特征完全对齐的假设。", "innovation": "本文提出了FedTDD，这是一种新型的联邦时间序列扩散模型，它联合学习跨客户端的合成器。FedTDD的核心是一个首创的数据蒸馏和聚合框架，通过填充时间步长和特征的不一致性来缓解客户端之间的差异。与传统的联邦学习不同，FedTDD通过交换本地合成输出来学习客户时间序列之间的相关性，而不是模型参数。通过协调器迭代改进全局蒸馏器网络，利用来自客户共享的知识来传输合成数据以获得知识转移。随着时间的推移，蒸馏器变得越来越精细，从而提高了客户端本地特征估计的质量，使得每个客户端可以根据最新的更准确的蒸馏器来改进对缺失数据的填充。", "conclusion": "在五个数据集上的实验结果表明，FedTDD相较于中心训练更为有效，并且通过共享合成输出来转移局部时间序列的知识也十分有效。值得注意的是，FedTDD在Context-FID和相关性评分上分别取得了79.4%和62.8%的改进。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.07837", "html_url": "https://arxiv.org/abs/2411.07837", "title": "FRUGAL: 通过减少状态开销实现高效内存优化以支持可扩展训练", "title_en": "FRUGAL: Memory-Efficient Optimization by Reducing State Overhead for Scalable Training", "authors": "Philip Zmushko,Aleksandr Beznosikov,Martin Takáč,Samuel Horváth", "background": "随着大型语言模型参数数量的增加，预训练和微调过程对GPU内存的需求也越来越大。优化器状态通常会消耗掉大部分内存。最近的研究提出了低秩适配（LoRA）、低秩梯度投影（GaLore）和块优化（BAdam）等方法以应对这一挑战，但这些方法在梯度信息处理上依然存在信息损失的问题，尤其是在预训练阶段。本研究旨在解决这一问题。", "innovation": "FRUGAL框架利用梯度分割技术，使用先进的如Adam算法进行低维度更新，而通过无状态方法（如SGD或signSGD）在剩余维度上执行更新。此外，该方法可以与各种低秩更新选择技术（包括GaLore和BAdam）结合使用，提供了在使用SGDM进行低维度更新和使用SGD或signSGD进行无状态更新时的理论收敛保证，实现了在固定内存预算下的高效内存优化，并在预训练和微调任务中达到了最先进的性能。", "conclusion": "FRUGAL方法在各种固定的内存预算下持续优于其他方法，实现了在保持高效内存使用的同时达到最佳性能的平衡。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04164", "html_url": "https://arxiv.org/abs/2502.04164", "title": "在重尾噪声下的高效分布式优化", "title_en": "Efficient Distributed Optimization under Heavy-Tailed Noise", "authors": "Su Hyeong Lee,Manzil Zaheer,Tian Li", "background": "随着模型和数据集规模的扩大，分布式优化已成为现代机器学习的默认训练范式。然而，由于局部更新导致的通信开销问题，以及注意力模型中存在的重尾随机梯度噪声，有效训练变得困难。", "innovation": "提出了一种名为TailOPT的有效框架，以应对重尾噪声。该框架利用自适应优化或剪切技术来解决这一问题，并针对重尾噪声提供了收敛性保证。其中一个高效且轻量的变体称为$Bi^2Clip$，通过内层和外层优化器进行坐标剪切，实现了类似自适应的性能，而无需维护或传输额外的梯度统计数据。", "conclusion": "实验结果表明，TailOPT及其$Bi^2Clip$变体在多个语言任务中表现出色，超越了现有的最先进的方法。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01669", "html_url": "https://arxiv.org/abs/2502.01669", "title": "基于影响函数的延迟反馈建模", "title_en": "Delayed Feedback Modeling with Influence Functions", "authors": "Chenlu Ding,Jiancan Wu,Yancheng Yuan,Cunchun Li,Xiang Wang,Dingxian Wang,Frank Yang,Andrew Rabinovich", "background": "在基于每次转化费用（CPA）的在线广告中，准确的转化率（CVR）预测至关重要。主要的挑战是延迟反馈，因为转化可能在用户互动后很久才发生，导致近期数据不完整且模型训练偏差。现有的解决方案虽然部分缓解了这一问题，但通常依赖辅助模型，使其计算效率低下且难以适应用户兴趣的变化.", "innovation": "我们提出了IF-DFM（影响函数-赋能的延迟反馈建模），该方法能够估算新到达和延迟转化对模型参数的影响，从而实现高效的参数更新而无需重新训练整个模型。通过将逆海森矩阵-向量乘积重新表述为优化问题，IF-DFM在可扩展性和有效性之间取得了良好的权衡.", "conclusion": "在基准数据集上的实验表明，IF-DFM在准确性和适应性方面均优于先前的方法."}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.18475", "html_url": "https://arxiv.org/abs/2501.18475", "title": "CLoQ: 通过校准LoRA初始化增强量化LLM的微调", "title_en": "CLoQ: Enhancing Fine-Tuning of Quantized LLMs via Calibrated LoRA Initialization", "authors": "Yanxia Deng,Aozhong Zhang,Selcuk Gurses,Naigang Wang,Zi Yang,Penghang Yin", "background": "利用低秩适应（LoRA）微调大语言模型（LLM）已成为对下游任务高效的手段，尤其是在计算资源有限的情况下。然而，将LoRA技术应用于量化LLM时会面临独特的挑战，因为量化权重的代表性精度较低。现有方法难以确保量化后的模型在微调过程中的性能。因此，如何在量化LLM中有效使用LoRA初始化策略，以最小化原模型与量化模型之间的层间差异，是亟待解决的问题。", "innovation": "本文提出了一种名为CLoQ（Calibrated LoRA initialization for Quantized LLMs）的方法，这是一种简洁的初始化策略，旨在解决量化LLM中LoRA技术应用的难题。CLoQ通过利用小的校准数据集量化预训练LLM，并确定每个层的最佳LoRA组件，以此为后续微调奠定坚实的基础。此外，CLoQ还提供了一种新的理论成果，使得能够精确且闭合地构建这些最优的LoRA组件。", "conclusion": "本文验证了CLoQ方法在语言生成、算术推理、常识推理等多任务上的有效性，表明其在量化LLM的LoRA微调中优于现有方法，尤其是在超低比特精度的情况下。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.18052", "html_url": "https://arxiv.org/abs/2502.18052", "title": "准确市场的竞争环境下的分类：追求准确性的市场", "title_en": "A Market for Accuracy: Classification under Competition", "authors": "Ohad Einav,Nir Rosenfeld", "background": "机器学习模型对希望在市场上占据份额的服务提供商至关重要。然而，传统的学习方法没有考虑到其他竞争对手的存在，这些竞争对手也在争夺消费者的市场。本文的研究背景在于，市场中的学习效果不仅仅取决于模型的准确性，还需要考虑竞争环境下的市场策略。", "innovation": "本文提出了在存在竞争者的情况下进行分类的方法，使学习者能够在市场上最大化份额。这种方法不仅对服务提供商有利，也对消费者有利。此外，研究表明，市场进入的时间和模型更新的时机对于竞争环境下的效果至关重要。该方法在多种领域中均表现出有效性，包括简单分布和噪音数据集，并且能够使整个市场迅速稳定下来，达到均衡状态。", "conclusion": "通过研究竞争环境下的市场学习，表明准确性只是考虑因素之一，更重要的是在竞争中的市场策略。所提出的方法有效提高了服务提供商和消费者的市场占有率，以及整个市场的稳定性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.12188", "html_url": "https://arxiv.org/abs/2502.12188", "title": "通过推理时自适应增强基于扩散的神经组合求解器跨问题泛化能力", "title_en": "Boosting Cross-problem Generalization in Diffusion-Based Neural Combinatorial Solver via Inference Time Adaptation", "authors": "Haoyu Lei,Kaiwen Zhou,Yinchuan Li,Zhitang Chen,Farzan Farnia", "background": "基于扩散的神经组合优化(NCO)方法通过学习离散扩散模型来生成解决方案，表现出解决NP完全(NPC)问题的有效性，可以消除手工构建领域知识。然而，现有的NCO方法在跨尺度和跨问题泛化方面面临重大挑战，与传统求解器相比，在训练成本上也更高。尽管最近的研究引入了基于预定义指导函数的训练免费引导方法，但这类方法在组合优化领域的应用尚未得到广泛探索。", "innovation": "本文提出了一种训练免费的推理时自适应框架(DIFU-Ada)，该框架能够在不进行额外训练的情况下增强基于扩散的NCO求解器的零样本跨问题迁移和跨尺度泛化能力。同时，该研究提供了相关的理论分析，以帮助理解这种跨问题迁移能力。", "conclusion": "实验结果表明，仅在旅行商问题(TSP)上训练的扩散求解器，通过推理时的自适应，可以在TSP变体如奖品收集TSP(PCTSP)和旅行者问题(OP)的不同问题规模上实现竞争力的零样本迁移性能。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.20012", "html_url": "https://arxiv.org/abs/2502.20012", "title": "学习能够引发市场的分类器", "title_en": "Learning Classifiers That Induce Markets", "authors": "Yonatan Sommer,Ivri Hikri,Lotan Amit,Nir Rosenfeld", "background": "当学习被用于人类的决策过程，如贷款、招聘或录取，这可能会激励用户以成本为代价，战略性地修改自己的特征以获得积极的预测。普遍认为影响成本的函数是外生的、固定的和预先确定的。本文挑战这一假设，并指出成本可能会在部署分类器后产生。用户寻求积极预测的动机会增加对重要特征的需求，如果这些特征可以购买，市场将形成，随之而来的是竞争和价格的产生。这一研究扩展了战略分类框架，探索在分类器可以引发特征市场的情况下学习任务的性质，并提出了一种不同的学习框架。", "innovation": "本文提出的创新之处在于挑战了现有假设，认为用户可以通过购买特征来降低预测中的成本。文章扩展了战略分类框架，研究了分类器可以引发特征市场的学习任务，并提出了一种计算市场价格的算法及一个可微学习框架。", "conclusion": "本文全面分析了在分类器可以引发特征市场的学习环境中学习任务的特点，提出了一个计算市场价格的算法，并开发了一种可微学习框架，旨在探索这一新颖的研究设置和方法。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08644", "html_url": "https://arxiv.org/abs/2502.08644", "title": "基于生物灵感的神经网络零样本自适应学习节律共享范式", "title_en": "Rhythmic sharing: A bio-inspired paradigm for zero-shot adaptive learning in neural networks", "authors": "Hoony Kang,Wolfgang Losert", "background": "大脑能够快速适应新环境并从少量数据中学习，这是人工 Intelligence (AI) 算法难以模仿的重要特性。受到神经细胞机械振荡节律的启发，本文开发了一种学习范式，利用连接强度的振荡，将学习过程与这些振荡的协调联系起来。这种振荡能够迅速改变协调方式，使网络能够感知和适应细微的环境变化，而无需监督。该网络可以成为通用的 AI 架构，能够预测多种环境的动力学，包括未见过的环境。这些结果使本范式成为认知新模型的强大起点。由于该范式不依赖于神经网络的具体细节，本研究为引入快速自适应学习提供了可能性，适用于多种最新的 AI 模型。", "innovation": "本文开发了一种新型学习范式，名为节律共享，该范式借鉴了神经细胞的机械振荡节律。通过协调连接强度的振荡，网络能够快速适应细微的环境变化，无需监督，展示了其在零样本自适应学习方面的潜力。该范式不依赖于特定的神经网络架构，因此具有广泛的应用前景，可以引入到现有的顶级 AI 模型中。", "conclusion": "本文开发的节律共享范式为理解和构建自适应学习机制提供了新的思路。由于该范式具有生物启发性且无需监督学习，它为建立更为灵活、适应性更强的 AI 系统开辟了新路径。在未来的研究中，可以进一步探索如何将此范式应用于实际应用场景，以解决多样化的现实问题。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10509", "html_url": "https://arxiv.org/abs/2503.10509", "title": "从行为到语言：走向基于强化学习中的抽象文本策略总结", "title_en": "From Actions to Words: Towards Abstractive-Textual Policy Summarization in RL", "authors": "Sahar Admoni,Assaf Hallak,Yftah Ziser,Omer Ben-Porat,Ofra Amir", "background": "RL算法生成的策略难以向用户解释，因为它们源自复杂奖励结构和神经网络表示的交互。这导致分析和预测代理行为具有挑战性，降低了用户对实际应用的信任。当前的全局策略总结方法通常依赖于演示视频，这些视频仅展示了代理行为的一个子集世界状态。用户只能观看有限数量的演示，这限制了他们的理解能力。此外，这些方法需要将解释负担置于用户身上，通过展示原始行为而非合成一致模式来解释。", "innovation": "提出了SySLLM（合成摘要使用大规模语言模型），它倡导一种新的基于大规模语言模型的抽象文本策略解释的新范式。SySLLM利用具备广阔世界知识和模式合成能力的大规模语言模型生成文本摘要，提供了结构化的策略解释。表明大规模语言模型可以在零样本设置中解释基于空间-时间结构的状态-行动轨迹描述，并生成有价值的策略见解，无需任何先验知识或微调。", "conclusion": "SySLLM捕获了关键见解，如目标偏好和探索策略等，这些见解也由人类专家识别。在大规模用户研究（200名参与者）中，大部分（75.5%）的参与者更倾向于SySLLM摘要，而不是基于演示的摘要。因此，SySLLM大大改善了用户理解代理策略的能力，增强了用户信任，并提供了有价值的策略洞察，无需大量手动解释。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05059", "html_url": "https://arxiv.org/abs/2504.05059", "title": "MIAT: 驰行动意感知变换器用于时空轨迹预测", "title_en": "MIAT: Maneuver-Intention-Aware Transformer for Spatio-Temporal Trajectory Prediction", "authors": "Chandra Raskoti,Iftekharul Islam,Xuan Wang,Weizi Li", "background": "准确的车辆轨迹预测对于实现安全和高效的自动驾驶至关重要，尤其是在混合交通环境中，当有人驾驶车辆与自动驾驶车辆共存时更为关键。然而，由于固有的驾驶行为（如加减速、左转和右转等）带来的不确定性，准确预测车辆轨迹成为一个巨大的挑战。", "innovation": "我们提出了驰行动意感知变换器（MIAT）架构，该架构结合了动意觉知控制机制和时空交互建模，以增强长期预测的准确性。通过系统地研究不同程度的动意觉知对短、长期轨迹预测的影响，并在真实世界的NGSIM数据集上进行评估，发现与现有的意图感知基准方法相比，我们的方法在短周期预测中可提高4.7%，在长周期预测中可提高1.6%。此外，通过利用意图感知控制机制，MIAT在长周期预测中的性能提高了11.1%，但短周期预测的性能略有下降。", "conclusion": "我们的研究突出了动意感知控制机制在时空轨迹预测中的重要性，表明该机制能够显著提高长周期预测的准确性，但在短周期预测中的应用效果略有降低。MIAT模型还提供了实际项目中更加精确和可靠的自动驾驶所需的数据支持。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.19530", "html_url": "https://arxiv.org/abs/2503.19530", "title": "VectorFit : 自适应奇异向量与偏差向量的预训练基础模型微调", "title_en": "VectorFit : Adaptive Singular & Bias Vector Fine-Tuning of Pre-trained Foundation Models", "authors": "Suhas G Hegde,Shilpy Kaur,Aruna Tiwari", "background": "流行的参数高效微调（PEFT）方法通过并行参数化新的低秩或稀疏可训练权重来降低可训练参数的数量，以此来减少全量微调的 trainable 参数数量。然而，这些新参数是从头开始训练的，导致这些方法在低预算设置下的性能与全量微调相比存在差距。因此，需要一种新的方法来有效利用预训练权重W中已嵌入的知识，同时保留其结构和变换特性，并以较少的参数数达到接近全量微调的效果。VectorFit 正是对这一需求的响应，通过适应性训练W的奇异向量和偏差得到高秩增量权重矩阵 ΔW，实现在参数效率方面的优越效果。", "innovation": "VectorFit 通过自适应训练W的奇异向量和偏差向量，高效地利用了预训练权重已嵌入的知识，同时保留其结构和变换特性。这种方法能够实现最高层级的增量权重量化矩阵，与全量微调的效果相当。此外，与目前领先的PEFT方法相比，VectorFit 只需要极少的9倍更少的可训练参数，仍然能够提供业界领先的性能表现。这种新的参数化方法，也令 VectorFit 在多种语言理解和生成、问答、图像分类和生成等任务的数据集中表现优于基线模型，证明了其在参数效率方面的优越性。", "conclusion": "通过全面的实验，VectorFit 在一系列涵盖广泛的语言和视觉任务的数据集上证明了其作为函数的参数效率，超越基线模型，在保持高精度的前提下显著减少了可训练参数。这显示出 VectorFit 是一种有效利用预训练模型知识并提升微调任务性能的创新方法。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.17493", "html_url": "https://arxiv.org/abs/2504.17493", "title": "面向目标的时间序列预测：基础框架设计", "title_en": "Goal-Oriented Time-Series Forecasting: Foundation Framework Design", "authors": "Luca-Andrei Fechete,Mohamed Sana,Fadhel Ayed,Nicola Piovesan,Wenjie Li,Antonio De Domenico,Tareq Si Salem", "background": "传统的时序预测方法通常旨在最小化整体预测误差，而未考虑下游应用中不同预测范围的重要性差异。现有的方法缺乏根据具体应用动态调整预测重点的能力。", "innovation": "本文提出了一种训练方法，使预测模型能够在推理时根据特定应用的需求调整其关注点，而无需重新训练。该方法在训练时将预测空间细分成多个小段，并根据应用指定的目标范围动态重新加权和聚合这些小段，以突出显示目标范围。这种方法与之前需要预定义预测范围的方法相比，提供了更为灵活的调整能力。", "conclusion": "实验表明，该方法不仅在目标区域内提高了预测准确性，还在下游任务中实现了可测量的性能提升。这表明预测建模与实际系统中决策之间的整合具有更大的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.02640", "html_url": "https://arxiv.org/abs/2505.02640", "title": "动态资源约束条件下适应性预算多臂奖赏博弈框架在物联网的应用", "title_en": "Adaptive Budgeted Multi-Armed Bandits for IoT with Dynamic Resource Constraints", "authors": "Shubham Vaishnav,Praveen Kumar Donta,Sindri Magnússon", "background": "物联网（IoT）系统在必须实时响应并管理波动的资源限制（如能源和带宽）的环境中运行。当前的方法在处理随时间变化的操作限制时往往效果不佳。因此，需要一种新的框架来解决这些问题。", "innovation": "本文提出了一种新的适用于具有动态操作限制的物联网应用的预算多臂博弈框架。该框架引入了逐渐递减的违规预算，允许在学习早期有有限的约束违规，但在过程中逐渐加强合规性。此外，提出了一种自适应平衡性能优化和随时间变化的合规性的预算上限置信上限算法。", "conclusion": "理论分析证明，预算上限置信上限算法在整个学习期内实现了亚线性后悔和对数级的约束违规。在无线通信环境的仿真实验中，该方法在适应性和满足约束方面均优于标准的在线学习方法。这些结果突显了该框架在构建适配性强、资源感知的物联网系统方面的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14188", "html_url": "https://arxiv.org/abs/2504.14188", "title": "重新思考面向客户端的联邦图学习", "title_en": "Rethinking Client-oriented Federated Graph Learning", "authors": "Zekai Chen,Xunkai Li,Yinlin Zhu,Rong-Hua Li,Guoren Wang", "background": "联邦图学习(FGL)是一种新的分布式图学习范式，它支持在保持数据隐私的前提下，进行跨本地系统的协作模型训练。已有研究将FGL的优化机制分为两种类型：服务器-客户端（S-C）模型和客户端-客户端（C-C）模型。尽管C-C模型在精炼通信结构方面表现出优势，但现有方法中C-C模型的问题在于它们会广播冗余节点表示，这导致了节点层面的高通信成本和隐私风险。因此，研究者提出了一种新的方法FedC4，结合了图凝缩技术和C-C协作优化，以提高模型性能和减少通信成本.", "innovation": "FedC4方法结合了图凝缩技术和C-C协作优化机制，具体而言，FedC4使用图凝缩技术将客户端的图知识精炼为几个合成嵌入，而不是传输节点级知识。此外，FedC4引入了三个新型模块，允许源客户端发送定制的节点表示，以便适应目标客户端的图属性。实验结果表明，FedC4在公共真实世界的八个数据集上，无论是任务性能还是通信成本都优于现有的基线方法，代码现可在指定网站获取", "conclusion": "FedC4在保持数据隐私的同时，通过集成图凝缩技术和改进的C-C协作优化机制，有效提高了联邦图学习的效率和效果，为图学习中的隐私保护提供了新的解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.03810", "html_url": "https://arxiv.org/abs/2505.03810", "title": "分组序排列旋转：优化免费的量化旋转变换", "title_en": "Grouped Sequency-arranged Rotation: Optimizing Rotation Transformation for Quantization for Free", "authors": "Euntae Choi,Sumin Song,Woosang Lim,Sungjoo Yoo", "background": "大语言模型（LLMs）在部署时面临高计算成本的挑战，而现有的后训练量化（PTQ）方法在极低比特宽度（如2比特）时效果不佳。因此，需要一种新的训练免费的方法来构建改进的旋转矩阵，以解决现有方法的限制。", "innovation": "引入了一种训练免费的方法来构建改进的旋转矩阵。该方法使用沃尔什-哈达马变换结合排序方式，将相似的频率成分聚类，从而减少量化误差，显著提高性能。此外，提出了一种分组序排列旋转（GSR），使用较小的沃尔什块的块对角矩阵，有效地隔离了异常值的影响，实现了与基于优化方法相当的性能，而无需进行任何训练。", "conclusion": "该方法在推理任务和WikiText-2的困惑度（PPL）得分上表现出鲁棒性，并且即使在应用于现有学习旋转技术的情况下也能增强结果。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05857", "html_url": "https://arxiv.org/abs/2505.05857", "title": "通过混合整数优化实现负责任的机器学习", "title_en": "Responsible Machine Learning via Mixed-Integer Optimization", "authors": "Nathan Justin,Qingshi Sun,Andrés Gómez,Phebe Vayanos", "background": "在过去的几十年里，机器学习（ML）已在医疗保健、可持续发展、社会科学、刑事司法和金融等多个领域取得了显著的成功。然而，其在涉及个人、其所属群体和社会整体的日益复杂、关键和敏感的应用领域中的部署引发了关于公平性、透明度和鲁棒性等方面的关键问题。随着ML系统的复杂性和规模以及其应用领域的增长，对负责任的ML方法的需求也日益增加，这些方法能够在保证部署性能的同时解决这些问题。", "innovation": "混合整数优化（MIO）提供了一个强大的框架，可以直接将负责任的ML考虑融入学习过程，同时保持性能。例如，MIO能够促进学习透明的模型，这些模型可以方便地纳入公平性或其他领域特定的约束。此教程论文提供了一个易于理解且全面的介绍，讨论了负责任的ML的理论和实践方面，概述了负责任的ML的核心原则及其在应用中的重要性，以及MIO在构建符合这些原则的ML模型中的实用价值。通过示例和数学表达式，论文说明了解决负责任的ML所面临问题的实用策略和可用工具。", "conclusion": "论文讨论了当前的限制和待解决的研究问题，并提供了对未来工作的建议，突显了在MIO中实现负责任的ML的应用潜力和挑战。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07503", "html_url": "https://arxiv.org/abs/2505.07503", "title": "通过变分贝叶斯压缩识别因果方向", "title_en": "Identifying Causal Direction via Variational Bayesian Compression", "authors": "Quang-Duy Tran,Bao Duong,Phuoc Nguyen,Thin Nguyen", "background": "在使用纯粹观测数据区分两个随机变量之间的因果关系时，这是一个具有挑战性的问题，该问题在多个科学领域有广泛应用。算法马可夫条件是这一任务中的一项关键原则，它假设联合分布根据因果方向进行因子分解时，可以更简洁地表示，而反向因果方向则不然。以往的方法通过使用简单的函数或易于计算复杂性的高斯过程（GPs）来近似这些码长，但这种方法在模型拟合度和计算复杂性之间存在权衡。", "innovation": "本文提出了一种利用神经网络的变分贝叶斯学习解释码长的新方法。这种方法能改进模型拟合度，同时保持码长的简洁性，并避免基于高斯过程的方法的显著计算复杂性。实验证明，该方法在因果识别基准上的表现优于大多数相关方法，表现出显著的性能提升。", "conclusion": "在合成和真实世界基准数据上的大量实验表明，我们的方法在多种数据集上的性能显著优于大多数相关方法，证明了该方法的有效性和潜力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.13109", "html_url": "https://arxiv.org/abs/2505.13109", "title": "FreeKV: 提升KV缓存检索以实现高效的LLM推理", "title_en": "FreeKV: Boosting KV Cache Retrieval for Efficient LLM Inference", "authors": "Guangda Liu,Chengwei Li,Zhenyu Ning,Minyi Guo,Jieru Zhao", "background": "大规模语言模型（LLMs）已广泛部署，随着上下文窗口的迅速扩大，支持越来越复杂的应用。然而，长上下文带来显著的部署挑战，主要是由于键-值（KV）缓存的大小与上下文长度成正比增长。虽然提出了KV缓存压缩方法来解决这一问题，但KV丢弃方法会导致显著的准确率损失，而KV检索方法则面临显著的效率瓶颈。", "innovation": "我们提出了FreeKV，这是一种算法与系统协同优化框架，旨在提高KV检索效率的同时保持准确率。FreeKV在算法方面引入了推测式检索以将KV选择和召回过程移出关键路径，并结合细粒度校正以确保准确率。在系统方面，FreeKV使用在CPU和GPU内存上的混合KV布局以消除零碎的数据传输，并利用双缓冲流式检索进一步提高效率。", "conclusion": "实验证明，FreeKV在各种场景和模型中实现了近乎无损的准确率，并与目前最先进的KV检索方法相比提供了高达13倍的加速比。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00962", "html_url": "https://arxiv.org/abs/2506.00962", "title": "具有随机时间 horizons 的强化学习", "title_en": "Reinforcement Learning with Random Time Horizons", "authors": "Enric Ribera Borrell,Lorenz Richter,Christof Schütte", "background": "传统的强化学习框架假设轨迹的运行时间和长度是固定的或无限的且确定的。然而，许多实际应用场景中的运行时间是随机的，并且可能在轨迹间或由政策决定。这种随机性会影响政策梯度公式，但当前对此缺乏严谨的理论分析。", "innovation": "本文将标准的强化学习框架扩展到随机时间 horizons 的情境下，提出了针对随机（轨迹间依赖的）终止时间的严谨分析，特别是针对随机性和确定性政策的政策梯度公式进行了推导；并且提供了轨迹或状态空间两种视角，与最优控制理论建立了联系。", "conclusion": "数值实验表明，使用提出的公式相比传统方法能够显著提升优化收敛速度。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.01016", "html_url": "https://arxiv.org/abs/2506.01016", "title": "乐观的评论家可以赋予小演员力量", "title_en": "Optimistic critics can empower small actors", "authors": "Olya Mastikhina,Dhruv Sreenivas,Pablo Samuel Castro", "background": "Actor-critic方法在深度强化学习的最新进展中占据了核心地位。常见的做法是使用对称的架构，让演员和评论家具有相同的网络结构和参数数量。然而，近期的研究表明不对称设置的优势，特别是在使用较小的演员时。本研究通过广泛的实验研究和分析，进一步验证了较小演员可能导致性能下降和评论家过度拟合的现象，并初步判定了价值低估是主要原因，强调了评论家在减轻这一问题中的关键作用。", "innovation": "研究创新在于通过深入的实验和分析发现，使用较小的演员会导致性能下降和评论家过度拟合，并且找到了价值低估是一个主要问题的原因，提出了一系列技术来缓解这一现象，使不对称的演员-评论家架构的研究更加可行。", "conclusion": "研究结论指出，评论家对于解决因价值低估导致的数据收集问题至关重要，并探讨了减轻价值低估的方法，为进一步研究和实践不对称的演员-评论家方法提供了指导。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11170", "html_url": "https://arxiv.org/abs/2506.11170", "title": "基于提示的方法：用于交互式多层次时间序列分割的PromptTSS", "title_en": "PromptTSS: A Prompting-Based Approach for Interactive Multi-Granularity Time Series Segmentation", "authors": "Ching Chang,Ming-Chih Lo,Wen-Chih Peng,Tien-Fu Chen", "background": "多变量时间序列数据在制造和可穿戴技术等各个领域中广泛存在，这些数据在粗粒度系统行为和细粒度详细事件之间表现出多种层次的粒度。在预测维护和性能优化等任务中，有效地对这些不同粒度层次进行划分和整合至关重要。然而，现有的时间序列分割方法面临两个主要挑战：（1）无法在统一模型中处理多个粒度层次，（2）在动态环境中适应新出现的模式能力有限。", "innovation": "本文提出了一种新颖的多层次时间序列分割框架——PromptTSS，该框架采用了一个结合提示机制的统一模型，利用标签和边界信息指导分割，同时捕捉粗粒度和细粒度模式，能够动态适应非见模式。实验结果显示，PromptTSS在多层次分割中的准确率提高了24.49%，在单一粒度分割中的准确率提高了17.88%，在迁移学习中的准确率提高了599.24%，这证明了其对层次状态和时间序列动态特性的适应能力。", "conclusion": "研究表明，通过使用PromptTSS，可以有效地提升多层次时间序列数据分割的准确性和适应新动态模式的能力。该代码可以在该链接处获取。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19343", "html_url": "https://arxiv.org/abs/2506.19343", "title": "Discrepancy-Aware Graph Mask Auto-Encoder", "title_en": "Discrepancy-Aware Graph Mask Auto-Encoder", "authors": "Ziyu Zheng,Yaming Yang,Ziyu Guan,Wei Zhao,Weigang Lu", "background": "现有的图自监督训练方法通常依赖节点的上下文信息来恢复被遮罩的信息，但在异结构图（节点连接并不一定相似）中，这些方法表现不佳，因为它们仅关注邻域信息而忽略了不同节点之间的差异性信息，导致节点表示难以区分。Masked Graph Auto-Encoder已经在图表示学习中表现出优越性能，但仍未解决异结构图中的应用问题。", "innovation": "本文提出了一种名为Discrepancy-Aware Graph Mask Auto-Encoder (DGMAE)的新颖方法。它在遮罩过程中重建相邻节点的差异性信息，从而获得更可区分的节点表示。该方法在17个广泛使用的基准数据集上进行了大量的实验，证明了其在节点分类、节点聚类和图分类任务中显著优于现有最先进的图自监督学习方法。", "conclusion": "DGMAE能够有效地在低维空间中保留节点的差异性，并在多个图分析任务中表现出色，这表明其具有显著的优势。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.11049", "html_url": "https://arxiv.org/abs/2506.11049", "title": "15,500 Seconds: 借助EfficientNet和轻量级微调实现无人机分类", "title_en": "15,500 Seconds: Lean UAV Classification Using EfficientNet and Lightweight Fine-Tuning", "authors": "Andrew P. Berg,Qian Zhang,Mia Y. Wang", "background": "随着无人机（UAV）在消费和国防领域中的普及，需要建立可靠且针对性强的分类系统。然而，无人机音频数据的稀缺性成为一个挑战。本文研究了通过集成预训练深度学习模型、参数高效微调策略和目标数据增强技术来应对无人机音频分类中的数据稀缺性问题。使用包含3,100个无人机音频片段（总计15,500秒，涵盖31种不同类型无人机）的自定义数据集，评估了基于变换器和卷积神经网络（CNN）架构在不同微调配置下的性能。", "innovation": "本文在无人机音频分类中使用了轻量级的EfficientNet模型和参数高效微调策略，以及精心选择的数据增强方法。通过五折交叉验证，实验结果表明，使用三种增强技术对EfficientNet-B0模型进行全面微调能达到最高的验证精度（95.95%），优于传统的自定义CNN模型和其他基于变换器的模型，如AST。这些发现表明，结合轻量级架构、PEFT和有针对性的数据增强提供了在数据稀缺条件下进行无人机音频分类的有效策略。", "conclusion": "研究表明，结合轻量级模型、参数高效微调和精心选择的数据增强方法，能够在有限的数据集上实现高效的无人机音频分类。未来的研究将进一步扩展这一框架，利用视觉和雷达遥测数据进行多模态无人机分类。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.13061", "html_url": "https://arxiv.org/abs/2506.13061", "title": "在扩散概率模型中高阶ODE求解器的快速收敛性", "title_en": "Fast Convergence for High-Order ODE Solvers in Diffusion Probabilistic Models", "authors": "Daniel Zhengyu Huang,Jiaoyang Huang,Zhengjiang Lin", "background": "扩散概率模型通过学习反向噪声注入过程来从数据生成样本。这一过程被重新公式化为一个确定性的概率流常微分方程（ODE），允许使用高阶数值求解器进行高效采样。与传统的常微分方程数值积分分析不同，采样过程的准确性不仅依赖于数值积分误差，还依赖于学习分数函数的近似质量和规律性及其相互作用。", "innovation": "本文提出了一种严格的收敛性分析，针对由概率流ODE推导出的通用前向过程中的确定性采样器，假设学习分数函数的一阶和二阶导数在实际中是有界的。证明了生成分布与目标分布之间的总变差距离可被限制在 \begin{align*}O\bigl(d^{\frac{7}{4}}\bigl(\bigl(\bigl(\frac{\text{score}}{\text{score}}\bigr)^2\bigr)^{\frac{1}{2}} +d(dH_{\text{max}})^p\bigr), \text{ where} \\\text{score}^2 \text{表示分数函数近似 } L^2 \text{误差，} d \text{为数据维度，} H_{\text{max}} \text{表示求解器最大步长} \text{。}\text{此外，数值实验还证实了学习分数函数的导数在实践中是有限的。}\text{", "conclusion": "本文的结论表明，通过确定性ODE求解器在混合扩散概率模型中的应用，可以对生成的分布与目标分布之间的距离进行严格的分析，并提供了具体的收敛性结果。进一步的数值实验也验证了这一结论的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06535", "html_url": "https://arxiv.org/abs/2507.06535", "title": "AMS电路中的图对比学习和标签重平衡实现可转移的寄生估测", "title_en": "Transferable Parasitic Estimation via Graph Contrastive Learning and Label Rebalancing in AMS Circuits", "authors": "Shan Shen,Shenglu Hua,Jiajun Zou,Jiawei Liu,Jianwang Zhai,Chuan Shi,Wenjian Yu", "background": "在AMS（Analog-Mixed Signal）电路的图表示学习中，各种下游任务（如寄生参数估计）的实现面临着设计数据稀缺、标签分布不平衡以及电路实现多样性的挑战。这些问题使得学习到的电路表示既不稳健也不易于迁移。", "innovation": "提出了一种名为CircuitGCL的新型图对比学习框架，该框架结合了表示分散和标签重构，以增强跨异构电路图的迁移性。CircuitGCL通过超球面表示分散自监督学习顶点嵌入，同时引入了平衡均方误差（BMSE）和平衡softmax交叉熵（BSCE）损失函数来解决标签分布不均衡的问题，从而使寄生参数估计更加稳健和可迁移。", "conclusion": "CircuitGCL在TSMC 28nm AMS设计中的边缘电容估计和结点电容分类任务上均超过了所有现有方法，分别在边缘回归任务中提高了$33.64\text\thinspace\text\textpercent\text\thinspace\text\textsim\text\thinspace\text\textpercent\text\thinspace\text$的$R^2$值，并在结点分类任务中获得了$0.9\times\text\thinspace\text\textsim\text\thinspace\text2.1\times$的F1得分增益。源代码可在以下链接获取：this https URL."}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.10904", "html_url": "https://arxiv.org/abs/2507.10904", "title": "难度分离数据的类比例核心样本选择", "title_en": "Class-Proportional Coreset Selection for Difficulty-Separable Data", "authors": "Elisa Tsai,Haizhong Zheng,Atul Prakash", "background": "高质量的训练数据对于构建可靠高效的机器学习系统至关重要。一种称为一次性内核选择的一次性数据简化方法通过裁剪数据集的同时保持甚至提高模型性能，这通常依赖于基于训练动态的数据难度评分。然而，现有大多数方法隐式的假定数据难度在类别之间是均匀的，忽视了不同类别之间数据难度的变异性。", "innovation": "本文挑战了这一假设，通过实证证明，在网络安全检测和医学影像等领域，数据难度往往以类别为单位聚类。为此，作者提出了班级难度可分性（Class-Difficulty Separability, CDs）的概念，并引入了班级难度可分性系数（Class Difficulty Separability Coefficient, CDSC）作为定量度量。此外，本文提出了类比例比例的核心样本选择方法，这些方法能够更有效地处理数据难度分离的数据，从而在广泛的性能指标上达到最先进的性能。特别是在噪声大、不平衡和大规模的数据集上，针对类别过度裁剪进行了更加激进的裁剪，使得模型泛化能力得到提升。", "conclusion": "本文的结果表明，明确定义类别难度可分性能够产生更有效、更鲁棒和更泛化的数据裁剪策略，特别是在高风险情况下。本研究方法在五个不同的数据集上进行了评估并展示了更强的性能。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15397", "html_url": "https://arxiv.org/abs/2507.15397", "title": "基于降噪器的MAP估计：收敛速率和保证", "title_en": "MAP Estimation with Denoisers: Convergence Rates and Guarantees", "authors": "Scott Pesme,Giacomo Meanti,Michael Arbel,Julien Mairal", "background": "去噪模型已成为解决逆问题的强大工具，这些模型能够利用预训练网络近似平滑先验分布的得分。通常，这些模型在解决最大后验概率（MAP）优化问题中被用于启发式的迭代方案，其中负对数先验的距离算子起着核心作用。然而，在实践中，这一算子往往是不可计算的，因此研究人员通常会使用预训练的去噪器作为近似，尽管缺乏广泛的理论支持。", "innovation": "本文展示了在先验为log-凸时，一种简单算法（与实际使用的几种方法相关）能够证明收敛到距离算子。这一算法可以解释为对平滑距离目标的梯度下降。因此，该分析为一些在实践中非常成功但之前主要是启发式的方法提供了理论基础。", "conclusion": "我们提供了一种理论框架，以支撑一类以前主要基于实践但缺乏理论依据的方法。这为理解基于去噪器的MAP估计提供了新的视角，并且证明了它们在特定条件下的实用性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15727", "html_url": "https://arxiv.org/abs/2507.15727", "title": "多代理滑雪租赁问题的竞争算法", "title_en": "Competitive Algorithms for Multi-Agent Ski-Rental Problems", "authors": "Xuchuang Wang,Bo Sun,Hedyeh Beyhaghi,John C.S. Lui,Mohammad Hajiesmaili,Adam Wierman", "background": "本文探讨了将经典滑雪租赁难题扩展到多代理环境的能力，其中每个代理可以单独或共同承担费用。背景中提到，在这种多代理情景下，代理的活跃日不同，导致决策过程中的动态状态变化。研究集中于在动态环境中，如何通过代理的贡献和成本机制，优化滑雪租赁决策问题。", "innovation": "创新点在于引入了一个新颖的多代理滑雪租赁问题模型，该模型考虑了个体和共享成本，并提出了三种不同的竞争优势比例：整体、状态依赖和个别理性。此外，作者为每个目标设计并分析了最优的确定性和随机性策略。研究发现对称策略优于非对称策略，这一点在理论和实践上都具有重要意义。", "conclusion": "结果表明，通过引入多代理滑雪租赁问题，提供了竞争比的上下界，并将经典滑雪租赁的见解扩展到多代理环境。实验结果还强调了在不确定性条件下群体决策的理论与实际意义。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05724", "html_url": "https://arxiv.org/abs/2508.05724", "title": "基于图的框架在物理学中探索数学模式：一个概念验证", "title_en": "A Graph-Based Framework for Exploring Mathematical Patterns in Physics: A Proof of Concept", "authors": "Massimiliano Romiti", "background": "传统的物理学方程分析无法充分探索方程间隐含的数学关系网络。这篇文章提出了一种结合神经网络和符号分析的图基框架，用于系统地发现和验证物理学各领域中的数学模式。", "innovation": "该研究创新性地提出了一种图基框架，通过严格的语义消歧化处理213个方程中的符号多义性，进一步聚焦于400个更高级的物理学方程。利用图注意力网络（GAN），该框架在链接预测中的AUC达到97.4%，显著优于传统基准。它的主要价值在于既可生成假设又能作为知识审计工具，生成跨领域的候选连接并验证通行理论的一致性，甚至通过语法错误揭示有价值的科研方向。", "conclusion": "该系统将组合空间转化为供人类解释的过滤后的数学模式流。即使出现同语反复和错误，也能识别冗余和评估知识库质量，确保对数学可能性空间进行全面探索。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.03682", "html_url": "https://arxiv.org/abs/2508.03682", "title": "Self-Questioning Language Models", "title_en": "Self-Questioning Language Models", "authors": "Lili Chen,Mihir Prabhudesai,Katerina Fragkiadaki,Hao Liu,Deepak Pathak", "background": "背景：本文探讨了大型语言模型在无需外部数据的情况下能否通过自我生成问题和答案来提升其推理能力。提出了一种不对称自举框架，其中提供者根据给定的主题生成问题，而解决问题者则尝试解答这些问题。为了评估性能，模型通过奖励机制进行训练，提供者依据问题难度获得奖励，解决问题者则通过多数投票来评估准确性。此外，模型还可以生成用于验证的单元测试。研究利用了三个基准：三位数乘法、黄金图表的代数问题，以及Codeforces的编程问题。", "innovation": "创新：提出了Self-Questioning Language Models (SQLM) 框架，使预训练的语言模型能够在仅接收单一主题提示的情况下自我提升推理能力。通过不断地生成更具挑战性的问题并尝试解决，模型能够在不依赖任何特定训练数据集的情况下改善在下游基准测试的表现。这种方法使用了匿名玩家之间的代理强化学习来训练模型，提供者生成问题并通过问题难度获得奖励，解决问题者通过多数投票获得间接正确性的反馈。对于编码任务，提供者生成单元测试以供验证。", "conclusion": "结论：通过不断地生成更具挑战性的问题并尝试解决，SQLM 模型能够在无需专门训练数据集的情况下针对下游基准测试提高表现，展示了大型语言模型通过生成问题和答案来自我提升其推理能力的潜力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05571", "html_url": "https://arxiv.org/abs/2508.05571", "title": "iFairy: 全参数在 ±1, ±i 的首个 2 位复数 LLM", "title_en": "iFairy: the First 2-bit Complex LLM with All Parameters in $\\{\\pm1, \\pm i\\}$", "authors": "Feiyu Wang,Guoan Wang,Yihao Zhang,Shengfan Wang,Weitao Li,Bokai Huang,Shimao Chen,Zihan Jiang,Rui Xu,Tong Yang", "background": "量化感知训练（QAT）将量化过程融入训练循环中，使大语言模型（LLMs）能够学习稳健的低精度表示。当前所有QAT研究都集中在最小化全精度模型的量化误差上，这些全精度模型的准确性被视为上限。然而，现有的方法都没有试图超越这一上限。", "innovation": "本文提出了一种全新的方法：提高全精度模型的准确性上限，然后高效地将其量化为 2 位。具体而言，作者提出了Fairy$\boldsymbol{\text{±i}}$，这是首个适用于复数LLMs的2位量化框架。Fairy$\boldsymbol{\text{±i}}$利用复数域的表示优势来提升全精度模型的准确性。通过映射权重到四次单位根$\boldsymbol{\text{±1, ±i}}$，形成了一个完美对称且信息论上最优的2位表示。重要的是，每个量化后的权重要么具有零实部，要么具有零虚部，这使得推理过程可以在仅使用加法和元素交换的情况下实现无乘法操作。", "conclusion": "实验结果表明，Fairy$\boldsymbol{\text{±i}}$在PPL和下游任务的表现均优于现有的2位量化方法，同时保持了严格的存储和计算效率。这为在极度低比特约束下构建高精确且实用的LLMs提供了新方向。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05612", "html_url": "https://arxiv.org/abs/2508.05612", "title": "Shuffle-R1: 通过数据导向动态洗牌提高多模态大型语言模型的高效强化学习框架", "title_en": "Shuffle-R1: Efficient RL framework for Multimodal Large Language Models via Data-centric Dynamic Shuffle", "authors": "Linghao Zhu,Yiran Guan,Dingkang Liang,Jianzhong Ju,Zhenbo Luo,Bin Qin,Jian Luan,Yuliang Liu,Xiang Bai", "background": "强化学习（RL）已被证明是提高多模态大型语言模型（MLLM）推理能力的有效后训练范式。然而，现有的RL流程经常由于两个未充分探索的问题而导致训练效率低下：优势塌陷（Advantage Collapsing），即批量中大多数优势接近零；和采样沉默（Rollout Silencing），即随时间推移，贡献非零梯度的采样比例减少。这些问题导致了次优的梯度更新，阻碍了长期学习效率。", "innovation": "本文提出了一种名为Shuffle-R1的简易且有理论依据的框架，通过动态重构轨迹采样和批量组成来提高RL微调效率。该框架包含两个核心创新点：(1) 对比轨迹采样（Pairwise Trajectory Sampling），选择高对比度的轨迹以改善梯度信号质量；(2) 基于优势的轨迹洗牌（Advantage-based Trajectory Shuffle），通过有信息的批量重塑增加有价值样本的曝光率。实验表明，该框架在多个推理基准测试中优于强大的RL基线，且具有最低的开销。", "conclusion": "实验结果突显了数据导向的调整对于更高效RL训练对于MLLM的重要性。Shuffle-R1框架可以通过动态重构轨迹采样和批量组成，显著提高强化学习的效率，从而提升多模态大型语言模型的长期学习效率和推理能力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06800", "html_url": "https://arxiv.org/abs/2508.06800", "title": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "title_en": "Hardness-Aware Dynamic Curriculum Learning for Robust Multimodal Emotion Recognition with Missing Modalities", "authors": "Rui Liu,Haolin Zuo,Zheng Lian,Hongyu Yuan,Qi Fan", "background": "在多模态情感识别（MER）中，缺失模态成为一个关键的研究方向。现有方法通常通过缺失模态重建来解决这一问题，但这些方法未能考虑不同样本在重建难度上的差异，从而限制了模型处理难题样本的能力。\n", "innovation": "本文提出了一个新颖的Hardness-Aware Dynamic Curriculum Learning（HARDY-MER）框架，该框架通过两阶段操作来解决上述问题：首先估计每个样本的难度级别，然后在训练过程中战略性地强调困难样本，以增强模型在这些挑战性实例上的表现。\n具体创新包括引入Multi-view Hardness Evaluation机制来量化重建难度，并引入基于检索的动态课程学习策略来动态调整训练序列，平衡易样本和难样本的学习焦点。\n", "conclusion": "广泛实验表明，HARDY-MER在缺失模态场景下始终优于现有方法。代码已公开发布。\n"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05977", "html_url": "https://arxiv.org/abs/2508.05977", "title": "LinguaFluid: 通过语义奖励实现语言引导的流体控制", "title_en": "LinguaFluid: Language Guided Fluid Control via Semantic Rewards in Reinforcement Learning", "authors": "Aoming Liang,Chi Cheng,Dashuai Chen,Boai Sun,Dixia Fan", "background": "在科学机器学习领域，尤其是在任务目标难以用数字明确指定的环境中，设计有效的回报函数仍然是强化学习（RL）中的一个挑战。现有工作中的回报函数大多依赖于手工定义、工程学或针对特定任务的调优。为了应对这一挑战，本研究提出了一种语义对齐的强化学习方法，通过Sentence-Bidirectional Encoder Representations from Transformers（SBERT）将当前状态与目标语义指令对齐来计算回报。", "innovation": "本研究创新性地提出了一种基于语义奖励的强化学习方法。与传统依靠手工定义的回报函数不同，该方法根据每一次时间步的反馈计算回报，该反馈基于目标文本描述和当前环境描述之间的语义相似度（通过余弦相似度衡量）。这种方法成功地无需手工设计的回报函数即可引导强化学习实现竞争级别的控制行为。", "conclusion": "本研究证明，语义回报可以指导学习，实现与自然语言目标相一致的控制行为，并且展示了语言嵌入空间与传统欧几里得空间之间的关联性。所提出的框架为语言模型与流体控制应用的无缝集成奠定了基础，为未来更加复杂的应用提供了新的可能性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06412", "html_url": "https://arxiv.org/abs/2508.06412", "title": "利用Reset Replay实现样本高效的大语言模型优化", "title_en": "Sample-efficient LLM Optimization with Reset Replay", "authors": "Zichuan Liu,Jinyu Wang,Lei Song,Jiang Bian", "background": "近年来，通过强化学习(RL)和偏好优化方法对大语言模型(LLMs)进行后训练，显著提升了它们的推理能力。然而，这些方法通常面临样本效率低和易受首因效应影响的问题，导致初始经验的过度拟合，影响政策质量和学习过程。", "innovation": "提出了利用Reset Replay优化（Looper）的大语言模型优化方法，这是一种通用且强大的插件，旨在提升任何基于偏好的优化框架中的样本效率。Looper通过最大化每个收集的数据批次的价值，实现了高重放次数下的训练，并通过周期性重启策略和重用初始数据来防止过度拟合，从而保持网络的可塑性。此外，Looper利用结合监督微调（SFT）和基于偏好的损失的混合优化目标，进一步增强数据利用。", "conclusion": "广泛的实验表明，Looper显著提升了多种偏好优化方法在数学和一般推理基准上的性能。值得注意的是，得益于Looper增强的迭代DPO方法在处理复杂数学任务时表现与某些复杂的计算密集型RL算法相当。这些发现强调了Looper作为有限数据条件下LLM微调的实用、样本高效且高效的架构的有效性，从而解锁了从有限数据中获得更高性能的可能性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07970", "html_url": "https://arxiv.org/abs/2508.07970", "title": "WeChat-YATT: 一种简单、可扩展且平衡的RLHF训练器", "title_en": "WeChat-YATT: A Simple, Scalable and Balanced RLHF Trainer", "authors": "Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Tingfeng Xian,Haoqiang Hong,Boqi Chen,Haotao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao", "background": "强化学习从人类反馈（RLHF）已成为训练大规模语言模型和多模态系统的主导范式。尽管现有RLHF训练框架已取得显著进展，但仍面临扩展到复杂多模态工作流程以及适应动态负载的重大挑战。尤其在管理大规模模型时，控制器的扩展性往往受限，在需要进行动态采样和资源分配的复杂RLHF管道中，还存在运维效率问题。", "innovation": "提出了一种名为WeChat-YATT的简单、可扩展且平衡的RLHF训练框架。WeChat-YATT采用并行控制器编程模型，提高了复杂RLHF工作流程的灵活及高效运维，通过自适应计算资源分区和工作负载调度，显著降低硬件闲置时间并提升GPU利用率，在实验场景中相比现有先进RLHF训练框架显示出更高的吞吐量。", "conclusion": "WeChat-YATT已被成功部署于支持WeChat产品功能的大规模用户群中，验证了其在真实世界环境的有效性和鲁棒性。我们已开源WeChat-YATT，并提供了源代码获取链接。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.07697", "html_url": "https://arxiv.org/abs/2508.07697", "title": "通过大型语言模型增强的时间序列预测", "title_en": "Semantic-Enhanced Time-Series Forecasting via Large Language Models", "authors": "Hao Liu,Chun Yang,Zhang xiaoxing,Xiaobin Zhu", "background": "时间序列预测在金融、能源、气象和物联网应用中扮演着重要角色。现有研究利用大型语言模型（LLMs）的泛化能力来适应时间序列预测，取得了令人鼓舞的性能。然而，现有研究主要集中在文本token级别的模态对齐上，而未能建立起语言知识结构与时间序列数据模式之间的内在模态差距的桥梁，严重限制了语义表示能力。", "innovation": "本研究提出了一种新的语义增强大型语言模型（SE-LLM），探索时间序列的固有周期性和异常特征，将其嵌入到语义空间中以增强token嵌入。此外，我们还在自注意力模块中嵌入了一个插件模块，用于建模长期和短期依赖性，从而有效适应时间序列分析。此外，我们的方法冻结了LLM并减少了token的序列维度，大幅降低了计算消耗。实验结果显示了我们的SE-LLM相比现有最佳方法的优越性能。", "conclusion": "我们的SE-LLM方法通过探索时间序列固有的周期性和异常特征，增强了token嵌入，并通过嵌入的插件模块提高了长期和短期依赖性的建模能力。此外，通过冻结LLM并减少序列维度，显著降低了计算成本。实验表明，我们的方法在时间序列预测中表现出色，优于现有最佳方法。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08543", "html_url": "https://arxiv.org/abs/2508.08543", "title": "M3-Net: 一种经济高效且不依赖图结构的基于多层感知机的交通预测模型", "title_en": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction", "authors": "Guangyin Jin,Sicong Lai,Xiaoshuai Hao,Mingtao Zhang,Jinlei Zhang", "background": "准确的交通预测是当前智能交通系统发展中的一个基本而关键的任务。主流的交通预测方法依赖于时空图神经网络等技术取得了突破性进展，但现有基于深度学习的方法面临的主要挑战是它们要么依赖于完整的交通网络结构，要么需要复杂的模型设计来捕捉复杂的时空依赖性。这些限制给大规模数据集上的深度学习模型的高效部署和操作带来了重大挑战。", "innovation": "提出了一种经济高效且不依赖图结构的多层感知机（MLP）模型M3-Net，不仅使用时间序列和时空嵌入进行高效的特征处理，还首次引入了一种新的MLP-Mixer架构，其中包含混合专家机制（MoE）。", "conclusion": "在多个真实数据集上进行的广泛实验表明，所提出的模型在预测性能和轻量级部署方面具有优势。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08746", "html_url": "https://arxiv.org/abs/2508.08746", "title": "通过稀疏自编码器实现可解释的奖励模型", "title_en": "Interpretable Reward Model via Sparse Autoencoder", "authors": "Shuyi Zhang,Wei Shi,Sihang Li,Jiayi Liao,Tao Liang,Hengxing Cai,Xiang Wang", "background": "大规模语言模型（LLMs）已在多个领域广泛应用。奖励模型（RMs）通过人类反馈（H）强化学习（RLHF）来替代人类偏好作为代理，以使LLM的行为与人类价值观保持一致。然而，传统的RMs缺乏解释性，不能提供决策过程的洞察，并且在用户偏好变化时显得不够灵活。虽然近期的多维RMs旨在提高解释性，但它们通常无法提供特征级别的重要性归因，并且需要昂贵的标注。", "innovation": "引入了一种新的架构——稀疏自编码器增强奖励模型（SARM），将预训练的稀疏自编码器（SAE）整合到奖励模型中。SARM将基于LLM的RM的隐藏激活映射到可解释的、稀疏的、单义性的特征空间，并通过标量头聚合特征激活以产生透明且概念上意义明确的奖励评分。经验评估证明SARM可以实现直接的奖励决策特征级别归因、允许动态调整偏好变化，并在对齐性能上优于传统的奖励模型。", "conclusion": "SARM通过稀疏自编码器改进奖励模型的可解释性，支持直接的特征级别奖励归因，能够动态调整偏好变化，提升了对齐性能。该论文的代码可以在this https URL找到。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09299", "html_url": "https://arxiv.org/abs/2508.09299", "title": "通过分布式机器学习和基于区块链的模型验证实现去中心化天气预报", "title_en": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation", "authors": "Rilwan Umar,Aydin Abadi,Basil Aldali,Benito Vincent,Elliot A. J. Hurley,Hotoon Aljazaeri,Jamie Hedley-Cook,Jamie-Lee Bell,Lambert Uwuigbusun,Mujeeb Ahmed,Shishir Nagaraja,Suleiman Sabo,Weaam Alrbeiqi", "background": "天气预报在灾害预防、农业和资源管理方面发挥着重要作用，但现有的集中式预报系统因安全性漏洞、扩展性限制和单点故障易感性而受到越来越多的挑战。", "innovation": "提出了一种结合联邦学习（FL）和区块链技术的去中心化天气预报框架，通过不暴露敏感本地数据就能进行协作模型训练，增强隐私并减少数据传输开销。同时，以太坊区块链确保了模型更新的透明性和可靠性验证。此外，引入了基于声誉的投票机制，并使用星际文件系统（IPFS）来进行有效的离链存储，进一步增强了系统的安全性。", "conclusion": "实验证明，该方法不仅提高了预报准确性，还增强了系统韧性与可扩展性，成为在现实世界、关键安全环境中部署的有效候选方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.03353", "html_url": "https://arxiv.org/abs/2403.03353", "title": "假设空间与深度学习", "title_en": "Hypothesis Spaces for Deep Learning", "authors": "Rui Wang,Yuesheng Xu,Mingsong Yan", "background": "本文介绍了基于深度神经网络（DNNs）的假设空间，将DNN视为两个变量（输入变量和参数变量）的函数，考虑了参数变量位于由规定深度和层宽决定的权重矩阵和偏置的空间内的DNN集合。", "innovation": "通过弱*闭包构建输入变量的函数Banach空间，证明了该Banach空间是再生核Banach空间（RKBS），并明确构造了其再生核。此外，研究了正则化学习和最小范数插值（MNI）问题在RKBS框架下的表示定理。", "conclusion": "表示定理揭示了这些学习问题的解可以表示为基于训练数据的核扩展的有限和。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09158", "html_url": "https://arxiv.org/abs/2508.09158", "title": "EvaDrive：演化对抗政策优化在端到端自主驾驶中的应用", "title_en": "EvaDrive: Evolutionary Adversarial Policy Optimization for End-to-End Autonomous Driving", "authors": "Siwen Jiao,Kangan Qian,Hao Ye,Yang Zhong,Ziang Luo,Sicong Jiang,Zilin Huang,Yangyi Fang,Jinyu Miao,Zheng Fu,Yunlong Wang,Kun Jiang,Diange Yang,Rui Fan,Baoyun Peng", "background": "自主驾驶在实现类人类迭代决策方面面临着重大挑战，这类决策是连续生成、评估和优化轨迹提案的。现有的生成-评估框架将轨迹生成与质量评估隔离，阻碍了对计划至关重要的迭代优化。同时，强化学习方法将多维度的偏好简化为单一标量奖励，忽略了重要的权衡，并产生了标量化的问题。", "innovation": "本文提出了一种名为EvaDrive的新颖多目标强化学习框架，通过对抗优化建立了轨迹生成与评估之间的真正闭环协同进化。EvaDrive将轨迹规划视为多轮次的对抗游戏。在这一游戏中，分层生成器通过结合自回归意图建模以实现时间因果关系，以及扩散机制以实现空间灵活性来持续提出候选路径。这些提案随后由一个可训练的多目标评论家严格评估，以明确保留多样的偏好结构，不将其简化为单一的标量化。通过引导帕累托前沿选择机制的对抗互动，实现了多次迭代的优化，有效避免了局部最优，同时保留了轨迹。", "conclusion": "EvaDrive在NAVSIM和Bench2Drive基准测试中的实验结果表明，其性能达到SOTA水平，NAVSIM v1取得了94.9的PDMS（超过DiffusionDrive 6.8，DriveSuprim 5.0，和TrajHF 0.9），Bench2Drive的驾驶得分为64.96。EvaDrive通过动态权重生成多样的驾驶风格，无需外部偏好数据，引入了闭合环路的对抗框架，实现类人类的迭代决策，提出了一种无标量化轨迹优化的新方法。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.19583", "html_url": "https://arxiv.org/abs/2310.19583", "title": "GC-MVSNet：多视角、多尺度、几何一致性的多视角立体成像", "title_en": "GC-MVSNet: Multi-View, Multi-Scale, Geometrically-Consistent Multi-View Stereo", "authors": "Vibhas K. Vats,Sripad Joshi,David J. Crandall,Md. Alimoor Reza,Soon-heung Jung", "background": "传统的多视图立体成像（MVS）方法主要依赖于光度和几何一致性约束。相比之下，现代基于机器学习的MVS方法仅在学习后处理阶段检查多个源视图之间的几何一致性，而没有在学习过程中对此施加约束。", "innovation": "本文提出了一种新的方法，在学习过程中显式地促进了参考视图深度图在多个源视图和不同尺度上的几何一致性（见图1）。通过在损失函数中引入几何一致性约束，这种方法显著加速了学习过程，减少了训练迭代次数，几乎减半了其他MVS方法的训练需求。我们通过广泛的实验，表明该方法在DTU和BlendedMVS数据集上取得了最新的性能，在Cfnks and Temples基准测试中则达到竞争水平。这是首次尝试在学习过程中强制执行多视角、多尺度的几何一致性的方法", "conclusion": "我们的方法GC-MVSNet在DTU和BlendedMVS数据集上达到了新的最先进技术状态，并且在Cfnks and Temples基准测试中取得了竞争力的结果。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.09146", "html_url": "https://arxiv.org/abs/2508.09146", "title": "理解和优化CSMA的变压器基在线上下文学习理论", "title_en": "To Theoretically Understand Transformer-Based In-Context Learning for Optimizing CSMA", "authors": "Shugang Hao,Hongbo Li,Lingjie Duan", "background": "当前使用的二进制指数退避方案在WiFi7中广泛应用，但在动态信道环境中仍会导致吞吐量性能不佳。模型驱动的方法（如非持久和$p$-持久的CSMA）简单地在已知固定节点密度的情况下优化退避策略，但仍然因为节点密度估计不准确而导致较大的吞吐量损失。论文首次提出了基于LLM变压器的上下文学习（ICL）理论，以优化信道访问。这种方法通过预收集碰撞门限数据例子和查询碰撞案例作为输入，通过变压器学习模式，进而生成预测的争用窗口门限（CWT）。为了有效训练变压器以实现ICL，开发了一种高效算法，在有限的训练步骤内确保接近最优的CWT预测。由于实际中难以收集完美的数据示例，进一步扩展允许在提示中输入有误的数据。证明该优化器的预测和吞吐量偏差最小。实验结果显示，该方法在不可知节点密度的情况下，具有快速收敛性和接近最优的吞吐量，优于现有的模型驱动和深度强化学习方法。", "innovation": "首次提出基于LLM变压器的上下文学习（ICL）理论，通过预收集数据和查询实际案例，训练变压器学习模式并预测争用窗口门限，提供了一种优化信道访问的新方法。开发了高效的算法，确保在有限训练步骤内接近最优的CWT预测。此外，进一步扩展了算法以容忍有误的数据输入，证明了其对于最优性能的鲁棒性。", "conclusion": "基于LLM变压器的ICL新方法在未知节点密度的条件下，具有快速收敛性和接近最优的吞吐量，且能够对有误的数据输入保持鲁棒性，优于现有的模型驱动和DRL方法。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.02190", "html_url": "https://arxiv.org/abs/2402.02190", "title": "连续并行松弛法在组合优化问题中寻找多样化解决方案", "title_en": "Continuous Parallel Relaxation for Finding Diverse Solutions in Combinatorial Optimization Problems", "authors": "Yuma Ichikawa,Hiroaki Iwashita", "background": "在组合优化（CO）中，找到最优解通常是首要目标。然而，在实际应用中，往往需要多种类型的解决方案而非单一最优解。这主要发生在两种情况下：一种情况下，严格遵守所有约束并非必要或理想，稍微违反一些约束可以生成更经济的解；另一种情况下，组合优化的形式化往往无法充分反映实际因素，例如领域知识、隐含权衡或伦理考虑。为应对这些挑战，生成具有不同惩罚强度的惩罚多样化解决方案以及具有不同结构特征的变异多样化解决方案，可以提供有价值的见解，帮助实践者根据具体需求选择最合适的解决方案。然而，发现多种多样化的解决方案比发现单一最优解更为复杂。", "innovation": "本文提出了一种名为连续并行松弛退火（CPRA）的计算效率高的框架，用于在无监督学习（UL）基础上的组合优化（CO）求解器中生成多种形式化的解决方案。CPRA 利用表示学习和并行化自动发现共享表示，显著加速了搜索过程。实验结果表明，CPRA 在生成多样化解决方案方面优于现有的 UL 基础求解器，显著降低了计算成本。", "conclusion": "CPRA 在单次训练运行中生成多样化解决方案，通过表示学习和并行化技术，实现了这些多样化解决方案的高效发现。这种方法在处理组合优化问题时，能够提供更灵活、更具针对性的解法选择，提升了实际应用中的灵活性和效率。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.08750", "html_url": "https://arxiv.org/abs/2407.08750", "title": "在线分布回归", "title_en": "Online Distributional Regression", "authors": "Simon Hirsch,Jonathan Berrisch,Florian Ziel", "background": "现代机器学习应用中常见的大规模流式数据推动了在线学习算法的发展。许多领域，如供应链管理、天气和气象、能源市场和金融，转向使用概率预测。这不仅需要准确学习期望值，还需要学习条件异方差性和条件矩。", "innovation": "该方法提出了一种在线估计正则化线性分布模型的新方法，结合了最近的在线LASSO模型估计方法和广为人知的GAMLSS框架。在日-ahead电力价格预测案例研究中，结果显示增量估计与显著降低的计算成本相结合具有竞争力的表现。", "conclusion": "我们实现了高效的Python包ondil，用于在线估计正则化线性分布模型。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.02754", "html_url": "https://arxiv.org/abs/2405.02754", "title": "隐含安全集合算法以实现可证明的安全强化学习", "title_en": "Implicit Safe Set Algorithm for Provably Safe Reinforcement Learning", "authors": "Weiye Zhao,Feihan Li,Changliu Liu", "background": "深度强化学习（DRL）在许多连续控制任务中表现出色，但在实际应用中，由于缺乏安全保证，其推广仍然存在挑战。通过奖赏塑形，DRL代理能够在期望上满足系统安全标准，但设计能够在每个时间步长都持续满足硬约束（如安全规范）的代理仍然是一项艰巨的任务。尽管现有安全控制领域的研究提供了在持续满足硬约束方面的保证，但这些方法通常需要显式的分析系统动力学模型，而这些模型在DRL环境中是不可用的。", "innovation": "本文提出了一种无需显式动力学模型的模型自由安全控制算法——隐含安全集合算法，该算法可以通过查询黑盒动态函数（如数字孪生模拟器）来合成保证训练过程中始终安全的保护措施。此外，算法通过理论证明保证了有限时间收敛到安全集和正向不变性，适用于连续时间和离散时间系统。该算法在最先进的安全性 Gym 挑战中表现优异，实现了零安全违规，同时获得了高达 95% ± 9% 的累计奖励。", "conclusion": "该方法成功应用于高维系统，并展示了良好的可扩展性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.01566", "html_url": "https://arxiv.org/abs/2407.01566", "title": "基于参数上下文的在线学习经纪理论", "title_en": "A Parametric Contextual Online Learning Theory of Brokerage", "authors": "François Bachoc,Tommaso Cesari,Roberto Colomboni", "background": "本文研究了在交易者之间作为经纪人的在线学习问题中的上下文信息的作用。在这个顺序问题中，每次时间步骤都有两个交易者到达，他们对其想要交易的资产有自己的秘密估值。经纪人基于有关资产和市场条件的上下文数据来建议交易价格（或经纪价格）。随后，交易者根据他们的估值高于还是低于提议的价格，选择购买或出售。只有当提议的经纪人价格处于两个交易者中最低和最高的估值之间时，才会发生交易。我们为此问题设计了算法，并在各种标准假设下证明了最优的理论遗憾保证。", "innovation": "本文提出了基于参数上下文的在线学习经纪理论，旨在通过设计算法并提供在不同假设条件下的最优理论遗憾保证，改进在线学习经纪人的决策过程。", "conclusion": "我们设计了针对该问题的算法，并在各种标准假设下证明了最优的理论遗憾保证，展示了上下文信息在在线学习经纪问题中的重要性及其对决策的影响。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.20124", "html_url": "https://arxiv.org/abs/2405.20124", "title": "几何统一分布鲁棒协方差估计：通过扩大不确定性集来缩小光谱", "title_en": "A Geometric Unification of Distributionally Robust Covariance Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set", "authors": "Man-Chung Yue,Yves Rychener,Daniel Kuhn,Viet Anh Nguyen", "background": "当前用于估计高维协方差矩阵的先进方法会将样本协方差矩阵的特征值收缩到数据不敏感的收缩目标。这种收缩变换要么是主观选择的，缺乏理论依据，要么是在受限分布假设下最优选择的。本文旨在提供一个没有严格假设前提下的合理方式来构建协方差估计器。研究基于对分布矩阵空间中不确定性集的最小Worst-case Frobenius误差的鲁棒协方差估计问题。研究表明，这种最小化方法会产生的收缩估计器满足一些几何性质，并能保证有效的计算性，且具有渐近一致性及有限样本的性能保证。", "innovation": "提出一种在没有限制性假设前提下构造协方差估计器的方法，研究分布鲁棒协方差估计问题，最小化所有接近名义分布的数据分布的最坏情况Frobenius误差。收缩估计器由基空间中的不确定集及其几何性质决定。同时，这些估计器是可有效计算的，且具有渐近一致性及有限样本性能保证。通过Kullback-Leibler、Fisher-Rao和Wasserstein散度生成具体估计器。这些数值实验基于合成数据和真实数据表明，本文提出的鲁棒估计器具有与现有先进估计器相当的性能。", "conclusion": "通过几何性质的分析，本文构建了鲁棒协方差估计器，表明这些估计器在理论上和实践中都是有效的。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.15729", "html_url": "https://arxiv.org/abs/2410.15729", "title": "多任务学习中的两级学习推迟方法", "title_en": "A Two-Stage Learning-to-Defer Approach for Multi-Task Learning", "authors": "Yannis Montreuil,Shu Heng Yeo,Axel Carlier,Lai Xing Ng,Wei Tsang Ooi", "background": "两级学习推迟（L2D）框架在分类和最近的回归任务中得到了广泛研究。然而，许多实际应用需要在联合多任务设置中同时解决这两种任务。现有的L2D方法在多任务场景中存在局限性，要求提出一种新的框架来克服这些限制，并确保在联合任务中取得最佳结果。", "innovation": "提出了一种新的两级L2D框架用于多任务学习，该框架通过统一的推迟机制整合了分类和回归任务。该方法使用了一个两级的拟损失族，证明了该损失族的贝叶斯一致性和$(\text{G}, \text{R})$一致性，确保了收敛到贝叶斯最佳决策器。还推导出了与交叉熵拟损失和代理特定成本的$L_1$-范数相关的显式一致性界，并扩展了多专家两级制度下的最小化差距分析。同时也明确指出了共享表示学习如何影响这些一致性保证。", "conclusion": "在目标检测和电子健康记录分析实验中，表明了该方法的有效性，并强调了现有L2D方法在多任务场景中的局限性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.15881", "html_url": "https://arxiv.org/abs/2407.15881", "title": "在异质战略代理之间的协作均值估计：个体理性、公平性和真实贡献", "title_en": "Collaborative Mean Estimation Among Heterogeneous Strategic Agents: Individual Rationality, Fairness, and Truthful Contribution", "authors": "Alex Clinton,Yiding Chen,Xiaojin Zhu,Kirthevasan Kandasamy", "background": "研究多智能体协作学习问题，目的是估计一个向量μ = (μ₁, ..., μₚ)。每个智能体通过从与之相关的单一正态分布中采样来估计向量μ的分量，每个智能体可以获得不同成本的样本。通过交换数据，智能体可以共享更廉价的样本，减少成本并降低估计误差。本文解决了确保个体理性、公正性和防止策略性行为这三项关键挑战，设计了一个机制来促进这种合作。", "innovation": "设计了一个机制和相关混合纳什均衡，该均衡可以最小化社会罚金（代理的估计误差和采集成本之和），并且对所有代理都是个体理性的。此外，本文还证明了该机制在最坏情况下能够提供O(√m)的社会罚金近似，并在有利条件下提供O(1)的近似。同时，还证明了三个困难结果，即不存在能够保证所有策略配置下个体理性的机制，不存在主导策略均衡，以及不存在避免最坏情况下O(√m)的价格稳定性的纳什均衡。通过结合博弈论中的公理性谈判概念，提高了公平性结果，该结果比仅仅最小化社会罚金的机制更公平。", "conclusion": "本文成功设计了一种机制来促进智能体间的协作学习，尽管存在一些不可能性结果，但本文的机制仍然能够在多种情况下提供良好的社会罚金近似值，并且能够提供更公平的解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.12830", "html_url": "https://arxiv.org/abs/2407.12830", "title": "基于知识的大型语言模型一致性测试", "title_en": "Knowledge-based Consistency Testing of Large Language Models", "authors": "Sai Sathiesh Rajan,Ezekiel Soremekun,Sudipta Chattopadhyay", "background": "本文系统地揭示并测量了大型语言模型（LLMs）知识中存在的不一致性和知识漏洞。这项研究基于一个自动化的测试框架（称为KonTest），该框架利用知识图谱来构建测试案例，并通过语义等价查询和测试或acles（元形学或本体论或acles）来探测和衡量LLMs关于世界的知识中的不一致性和知识漏洞。进一步通过加权LLM模型集合来减轻知识漏洞。", "innovation": "提出了一种新的自动测试框架KonTest，利用知识图谱生成测试案例，并通过语义等价查询和测试或acles来探测和衡量LLMs的知识不一致性和知识漏洞；通过加权LLM模型集合来减轻知识漏洞；并展示了KonTest能够暴露19.2%的错误诱导输入，揭示了16.5%的知识差距；还提出了一种基于KonTest测试集的缓解方法，将知识差距减少了32.48%。其中，GPT3.5因其在知识构建上的效果仅为60%-68%被认为不适合用于基于知识的一致性测试。", "conclusion": "使用四种最先进的LLMs（Falcon、Gemini、GPT3.5和Llama2）展示了KonTest生成了19.2%的错误诱导输入（共1917个错误），揭示了16.5%的知识差距，通过基于KonTest的测试集提出的方法减少了知识差距32.48%，且GPT3.5在知识构建方面的效果较差，只占了约60%-68%的有效性，因此不适合用于知识一致性测试。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.16135", "html_url": "https://arxiv.org/abs/2409.16135", "title": "评价自言模型在自闭症诊断会话中儿童-成人对话ASR任务中的表现", "title_en": "Evaluation of Speech Foundation Models for ASR on Child-Adult Conversations in Autism Diagnostic Sessions", "authors": "Aditya Ashvin,Rimita Lahiri,Aditya Kommineni,Somer Bishop,Catherine Lord,Sudarsana Reddy Kadiri,Shrikanth Narayanan", "background": "在临床环境中准确转录儿童与成人之间的对话对于诊断发展性障碍（如自闭症）至关重要。深度学习的进步和大规模标注数据的可用性使得生成的语音基础模型表现出显著的ASR性能提升，但在儿童成人交互对话中的表现尚未得到全面的研究和探索。这项研究利用Whisper、Wav2Vec2、HuBERT和WavLM等模型在自闭症诊断会话中的儿童成人对话数据集上进行评估，发现相较于成人话语，儿童话语的ASR性能下降幅度明显（绝对错误率15-20%）。", "innovation": "研究首先对当前最先进的自言模型（如Whisper-large）在儿童成人互动对话上的性能进行了全面评估，并发现这些模型在儿童话语上的性能显著下降。随后，通过低资源环境下的LoRA微调，提升了最佳零样本模型（Whisper-large）在儿童和成人话语上的ASR性能，分别取得了8%和13%绝对错误率的改进。这项工作填补了相关领域的空白，提供了一种有效提升儿童话语转录准确性的方法。", "conclusion": "研究结果表明，尽管现有语音基础模型在ASR性能上有显著提升，但在儿童成人互动对话任务上仍存在明显的性能下降。针对此问题，通过低资源环境下的微调可以有效改善其性能，特别是对于儿童话语的转录准确率。未来研究可以进一步探索更多低资源下的微调方法，以提高这类对话场景中的ASR性能。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.15913", "html_url": "https://arxiv.org/abs/2411.15913", "title": "无训练的用于潜在扩散模型的音乐风格迁移方法", "title_en": "A Training-Free Approach for Music Style Transfer with Latent Diffusion Models", "authors": "Heehwan Wang,Joonwoo Kwon,Sooyoung Kim,Shinjae Yoo,Yuewei Lin,Jiook Cha", "background": "音乐风格转移通过结合一种作品的结构和另一种作品的风格特征，实现了个性化的音乐创作。现有方法虽然探索了基于文本的生成和基于扩散的合成，但大多数方法都需要大量的训练、配对的数据集或详细的文本注释。", "innovation": "介绍了一种名为Stylus的训练无需方法，利用预训练的潜在扩散模型（LDM）中的自注意力层进行音乐风格迁移。通过在梅尔谱图域中替换内容音频的关键和值表示为风格参考的表示来实现风格迁移。为进一步提高风格化质量和可控制性，方法中还融入了查询保持、CFG启发式的指导放大、多风格插值和相位保持重建。", "conclusion": "该方法显著提高了感知质量和结构保持能力，同时保持了轻量级和易于部署的特点。工作强调了基于扩散的注意机制在高效、高保真和可解释的音乐生成中的潜力，无需进行训练。代码将在接受后发布。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.06869", "html_url": "https://arxiv.org/abs/2411.06869", "title": "CapeLLM：以多模态大语言模型实现无支持的类别无关姿态估计", "title_en": "CapeLLM: Support-Free Category-Agnostic Pose Estimation with Multimodal Large Language Models", "authors": "Junho Kim,Hyungjin Chung,Byung-Hoon Kim", "background": "传统的类别无关的姿态估计（CAPE）依赖于带有标注关键点的支持图像，这一过程往往繁琐且难以全面捕捉不同类别对象之间的必要对应关系。尽管最近的研究尝试通过文本查询来解决这一问题，利用其增强的稳定性和泛化能力，但现有方法仍然受限于对支持查询的依赖、未能充分利用预训练大语言模型中嵌入的丰富先验知识，以及基于参数分布的假设限制。", "innovation": "为了应对这些挑战，作者提出了CapeLLM，这是第一个专为CAPE设计的多模态大语言模型（MLLM）。该方法仅使用查询图像和详细的文本描述作为输入，以估计类别无关的关键点。CapeLLM通过有效训练策略和精心设计的指示，将MLLM应用于CAPE。此外，还引入了一种推理机制，进一步增强了对未知关键点的推理过程，灵活建模其潜在的空间分布和不确定性，基于上下文线索进行自适应细化。广泛实验验证了该方法在MP-100基准上的新最佳性能，特别是在1次和5次设置下，标志着在类别无关姿态估计领域的重大进展。", "conclusion": "我们的方法在MP-100基准测试中创下了新的性能标准，特别是在1次和5次设置下，标志着类别无关姿态估计领域取得了重大进展。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.09776", "html_url": "https://arxiv.org/abs/2411.09776", "title": "无冲突地组合机器学习防御", "title_en": "Combining Machine Learning Defenses without Conflicts", "authors": "Vasisht Duddu,Rui Zhang,N. Asokan", "background": "现有的机器学习（ML）防御措施能够抵御多种安全、隐私和公平性风险。但在现实生活中，模型需要同时抵御多种不同的风险，这就需要结合多种防御措施。然而，由于不同防御措施之间可能存在冲突的交互，直接组合多个防御措施可能效果不佳，甚至会降低其中一种或多种防御措施的有效性。实践者需要一种方法来确定特定组合是否有效。通过实验来确定有效组合非常耗时且成本高昂，特别是在需要组合多种防御措施时。因此，需要一种低成本且易于使用的组合技术来识别有效的组合。理想的组合技术应当具备：（1）准确性：正确识别组合是否有效；（2）可扩展性：能够组合多种防御措施；（3）非侵入性：无需更改组合的防御措施；（4）普遍适用性：适用于不同类型的防御措施。然而，之前的许多工作都没有满足上述所有要求。", "innovation": "我们提出了一种基于原则的组合技术Def\to，称为Def\to（Defense Combination）。Def\to解决了上述问题，满足了以上所有要求。它在8个已探索的组合中实现了90%的准确性，并且在30个我们在这篇论文中实证评估的未探索组合中达到了81%的准确性。", "conclusion": "我们提出了一种名为Def\to的组合技术，以非冲突的方式组合机器学习防御措施。Def\to能够准确、可扩展、非侵入式并且普遍适用于不同的防御措施类型，相比现有的方法，更有效地解决了组合防御措施时遇到的问题。通过评估Def\to在多个应用场景中的表现，验证了其有效性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.11353", "html_url": "https://arxiv.org/abs/2407.11353", "title": "过参数化神经网络在插值空间中预条件梯度下降和提前停止训练实现的非参数回归精确泛化", "title_en": "Sharp Generalization for Nonparametric Regression in Interpolation Space by Over-Parameterized Neural Networks Trained with Preconditioned Gradient Descent and Early-Stopping", "authors": "Yingzhen Yang,Ping Li", "background": "本文研究了使用过参数化两层神经网络进行非参数回归的方法，这些神经网络在有算法保证的情况下进行训练。训练特征均匀地来自$\text{R}^d$的单位球，并且目标函数位于统计学习理论中常见的插值空间中。研究表明，在插值空间$\bth{\text{H}_K}^{s'}$中训练神经网络，利用一种新颖的预条件梯度下降（PGD）算法，并在训练过程中使用提前停止，可以实现一个尖锐的回归率$\text{O}(n^{-\frac{2\text{α}s'}{2\text{α}s'+1}})$，其中$s' \text{≥} 3$。这一结果比已知的近最优率$\text{O}(n^{-\frac{2\text{α}s'}{2\text{α}s'+1}})\text{log}^2(1/\text{δ})$更加精细，同时也优于在常规神经领域核(NTK)机制下使用常规梯度下降（GD）获得的标准核回归率$\text{O}(n^{-\frac{2\text{α}}{2\text{α}+1}})$。", "innovation": "本文的主要创新点包括：(1) 对于每一步PGD，得到了网络输出的合理分解，分解为RKHS中的函数和一个小$L^{\text{∞}}$-范数的残差函数；(2) 通过这种分解，应用局部Rademacher复杂度理论，严格控制由PGD迭代过程中生成的所有神经网络函数构成的函数类的复杂性。此外，还发现PGD使神经网络能够跳出线性NTK区域，有效诱导出一个新的核（积分核），这优于传统NTK，后者是用常规GD生成的。", "conclusion": "研究结果表明，通过预条件梯度下降和提前停止训练的过参数化神经网络可以在插值空间中实现精确的泛化，特别是在目标函数属于特定的插值空间时。相比传统的核回归方法和普通GD训练的NN方法，这种训练方法能提供更优的泛化性能。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06534", "html_url": "https://arxiv.org/abs/2412.06534", "title": "通过反转理解基于Transformer的视觉模型", "title_en": "Understanding Transformer-based Vision Models through Inversion", "authors": "Jan Rathjens,Shirin Reyhanian,David Kappel,Laurenz Wiskott", "background": "在机器学习和计算机视觉领域，理解深层神经网络的工作机制仍然是一个基本挑战。一种有潜力但尚未充分探索的方法是特征反转，它试图使用训练好的逆向神经网络从中间表示重建图像。本文通过重新审视特征反转，并引入了一种新型模块化方法，使得这一技术的应用更加高效。这种方法被系统性地应用于大型的基于Transformer的视觉模型，如检测Transformer和视觉Transformer，并且通过重建图像可以进行有意义的定性解释。进一步的定量评估揭示了这两种Transformer架构中图像特征表示的机制，包括模型如何编码上下文形状和图像细节，各层之间的相关性以及对颜色扰动的鲁棒性。", "innovation": "本文提出了一种新型的模块化特征反转方法，能够更高效地应用于大规模的Transformer视觉模型（如Detection Transformer和Vision Transformer），并系统性地验证了这种方法的有效性。通过对重建图像进行定性解释和定量评估，揭示了Transformer架构中图像特征表示的机制，提供了关于模型如何编码上下文形状、图像细节及其对颜色扰动的鲁棒性的关键见解。", "conclusion": "本文的研究深化了我们对基于Transformer的视觉模型及其内部表示机制的理解。所提出的模块化特征反转方法能够有效地应用于大型模型，并揭示了关于模型如何编码图像特征的重要信息。同时，我们针对模型对颜色扰动的鲁棒性进行了分析。所用代码可以在指定的URL处获取以重现实验结果。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.12400", "html_url": "https://arxiv.org/abs/2412.12400", "title": "利用机器学习指导复杂渔业环境中采捕控制规则的设计", "title_en": "Using machine learning to inform harvest control rule design in complex fishery settings", "authors": "Felipe Montealegre-Mora,Carl Boettiger,Carl J. Walters,Christopher L. Cahill", "background": "在渔业科学中，如何管理大小结构化的随机种群捕捞始终是一个长期而困难的问题。直线预防性政策基于生物量和捕捞参照点，已成为了解决这一问题的标准方法。尽管这些常规反馈政策是从假设相对简单生态动态的分析或动态规划解决方案中派生出来的，但在现实世界中它们常常应用于更加复杂的生态环境。加拿大阿尔伯塔省规模变动大、变异性高的玉筋鱼渔业就是这样一个难题，始终困扰着管理者和生态学家。", "innovation": "本文通过应用机器学习工具，特别是强化学习（RL）和贝叶斯优化方法，探索如何设计部分观测龄结构化的渔业采捕控制规则，特别是在玉筋鱼渔业中。研究旨在通过多个互补的性能指标优化和评估政策，重点回答两个问题：1.基于参考点的常规政策与数值优化政策相比表现如何？2.除了种群生物量外，观测平均鱼重是否可以辅助政策决策？", "conclusion": "研究表明，基于参考点的标准政策在复杂生态条件下表现不如数值优化的政策。此外，观测平均鱼重确实可以改善政策决策，特别是在资源动态波动较大的情况下。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.08557", "html_url": "https://arxiv.org/abs/2502.08557", "title": "通过代理介导的对话式调查的新 查询扩展方法", "title_en": "A New Query Expansion Approach via Agent-Mediated Dialogic Inquiry", "authors": "Wonduk Seo,Hyunjin An,Seunghyun Lee", "background": "查询扩展在信息检索（IR）中广泛使用，通过补充初始查询以丰富信息来改善搜索结果。虽然基于大型语言模型（LLM）的方法通过多次提示生成伪相关内容和扩展词汇，但这些方法通常会产生同质化、范围窄的扩展，缺乏检索相关信息所需的多样化背景。", "innovation": "提出了一种新的代理介导对话框架（AMD），包含三个专业角色：1）苏格拉底提问代理将初始查询重新构造成三个子问题，每个问题都受到特定苏格拉底提问维度（澄清、假设探查和推论探查）的启发；2）对话回答代理生成伪答案，以多种视角丰富查询表示，符合用户意图；3）反思反馈代理评估并精炼这些伪答案，确保仅保留最相关和有用的内容。通过多代理过程，AMD有效通过查询和反馈精炼过程构建更丰富的查询表示。", "conclusion": "在基准测试（包括BEIR和TREC）上的广泛实验表明，本框架优于之前的方法，提供了一个在检索任务中更加稳健的解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.01027", "html_url": "https://arxiv.org/abs/2502.01027", "title": "Two-Stage Learning-to-Defer: 竞争对手鲁棒性：算法和保证", "title_en": "Adversarial Robustness in Two-Stage Learning-to-Defer: Algorithms and Guarantees", "authors": "Yannis Montreuil,Axel Carlier,Lai Xing Ng,Wei Tsang Ooi", "background": "现有的Two-stage Learning-to-Defer（L2D）框架假设输入数据干净，并且容易受到对抗性干扰的影响。这些干扰可以通过操纵查询分配造成成本高昂的错误路由或使专家过载。研究人员首次进行了全面的对抗鲁棒性研究，针对Two-stage L2D系统提出了两种新的攻击策略：非目标攻击和目标攻击，这些攻击会影响最佳分配或迫使查询特定的代理人。鉴于这些挑战，他们提出SARD，这是一个基于一组代理损失的凸学习算法，这些代理损失可以保证贝叶斯一致性以及$(\text{R}, \text{G})$一致性。这些保证适用于分类、回归和多任务设置。实验证明，SARD显著提高了在对抗攻击下的鲁棒性，同时保持了良好的干净性能，这是确保和增强L2D部署安全性的关键步骤.", "innovation": "提出了一种对抗鲁棒性算法SARD，基于代理的损失函数，具有贝叶斯一致性及$(\text{R}, \text{G})$一致性保证，适用于分类、回归和多任务场景，增强了Two-stage L2D系统的安全部署.", "conclusion": "实验结果表明，SARD在对抗攻击下显著提高了鲁棒性，同时保持了良好的干净性能，标志着确保和增强L2D部署安全性的关键一步."}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.24381", "html_url": "https://arxiv.org/abs/2503.24381", "title": "UniOcc：自主驾驶中占用预测和预报的统一基准", "title_en": "UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving", "authors": "Yuping Wang,Xiangyu Huang,Xiaokang Sun,Mingxuan Yan,Shuo Xing,Zhengzhong Tu,Jiachen Li", "background": "介绍了UniOcc，这是一个全面统一的基准库和工具，用于占用预测（基于历史信息预测未来占用情况）和占用预报（从摄像头图像中预测当前帧的占用情况）。UniOcc将多个真实世界数据集（如nuScenes、Waymo）和高保真驾驶模拟器（如CARLA、OpenCOOD）的数据统一起来，提供2D/3D占用标签并标注创新的像素级流动信息。", "innovation": "不同于现有的研究依赖于次优的伪标签进行评估，UniOcc引入了新的评估指标，不需要真实标签，能够对占用质量的多个方面进行稳健评估。通过大量的实验，表明大规模多样化的训练数据和明确的流动信息显著提升了占用预测和预报的效果。", "conclusion": "通过广泛的实验，证明了大规模多样化训练数据和明确的流动信息对于占用预测和预报性能的显著提升效果。数据与代码可在提供的链接中获取。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03022", "html_url": "https://arxiv.org/abs/2503.03022", "title": "生成式主动适应在漂移和类不平衡网络入侵检测中的应用", "title_en": "Generative Active Adaptation for Drifting and Imbalanced Network Intrusion Detection", "authors": "Ragini Gupta,Shinan Liu,Ruixiao Zhang,Xinyue Hu,Xiaoyang Wang,Hadjer Benkraouda,Pranav Kommaraju,Phuong Cao,Nick Feamster,Klara Nahrstedt", "background": "机器学习在网络安全领域，特别是在网络入侵检测系统中展现出潜力。然而，随着攻击模式的演变，概念漂移和训练数据集的类不平衡严重制约了这些系统的性能。标签网络流量的工作量大，尤其是针对新出现的罕见攻击类型，这使准备适应所需的正确数据变得困难。因此，需要一种方法在减少注释工作的同时增强网络入侵检测系统的鲁棒性以应对以上挑战。", "innovation": "该研究提出一种生成式主动适应框架，该框架利用密度感知的数据集先验选择来识别最具有信息性的标注样本，并利用深度生成模型生成多样化的样本，以此增强训练集数据，缓解概念漂移的影响，从而提升网络入侵检测系统的性能，尤其是在处理罕见攻击类型方面。通过将该框架\textbf{NetGuard}应用于模拟数据集和真实世界的数据集，实验证明了该方法的有效性。", "conclusion": "实验结果表明，该方法使整体F1分数从0.60提高到了0.86，对于罕见攻击类型，如Infiltration、Web Attack和FTP-BruteForce，F1分数分别从0.001、0.04和0.00提升到了0.30、0.50和0.71。这种生成式主动适应框架不仅可以提高罕见攻击检测的性能，还减少了标签成本，是一个具有扩展性和实际性的入侵检测解决方案。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16819", "html_url": "https://arxiv.org/abs/2412.16819", "title": "Bi-Sparse Unsupervised Feature Selection", "title_en": "Bi-Sparse Unsupervised Feature Selection", "authors": "Xianchao Xiu,Chenyi Huang,Pan Shang,Wanquan Liu", "background": "在许多领域处理高维未标记数据集时，主成分分析（PCA）已经成为一种流行的无监督特征选择（UFS）技术。现有的大多数基于PCA的方法仅通过在转换矩阵上施加单一的稀疏正则化或约束来考虑数据集的结构，这限制了其性能的提升。因此，需要一种可以同时考虑数据集结构和特征相关性的新方法来提升UFS的性能。", "innovation": "本文提出了一种新颖的双稀疏方法，名为BSUFS（Bi-sparse Unsupervised Feature Selection），通过将$\boldsymbol{\boldsymbol{\text{\textasciicircum}\text{\textasciicircum}\text{l}_{2,p}}}$-范数和$\boldsymbol{\boldsymbol{\text{\textasciicircum}\text{\textasciicircum}\text{l}_{q}}}$-范数融入传统的PCA方法，使方法能够选择相关的特征并过滤无关的噪声，从而获得具有区分性的特征。此外，还提出了一种高效的交替近邻最小化算法（PAM），结合了Stiefel流形优化和稀疏优化技术。该算法有效地解决了非凸模型的问题，并进行了复杂度分析。实验结果表明，BSUFS的有效性和双稀疏优化在特征选择中的优势，并展示了其在其他图像处理领域的潜力。", "conclusion": "通过提出BSUFS方法，本文为高维未标记数据集的无监督特征选择提供了一种新的框架，并通过实验证明了双稀疏优化方法在特性选择领域的有效性以及其在其他图像处理应用领域的潜在价值。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.01400", "html_url": "https://arxiv.org/abs/2504.01400", "title": "ToolACE-R：基于模型的迭代训练和自适应精炼方法", "title_en": "ToolACE-R: Model-aware Iterative Training and Adaptive Refinement for Tool Learning", "authors": "Xingshan Zeng,Weiwen Liu,Xu Huang,Zezhong Wang,Lingzhi Wang,Liangyou Li,Yasheng Wang,Lifeng Shang,Xin Jiang,Ruiming Tang,Qun Liu", "background": "大型语言模型（LLMs）通过学习使用外部工具来解决复杂的用户任务的能力，已经显示出扩展模型能力的潜力。现有的方法主要集中在数据合成用于微调LLMs以有效调用工具，但忽视了如何充分激发模型的潜力。", "innovation": "本文提出了一种名为ToolACE-R的新颖框架，该框架结合了模型感知的迭代训练和自适应精炼，旨在最大化模型潜力并优化性能。ToolACE-R包含一个根据模型能力演变逐步调整训练样本的模型感知的迭代训练过程，并引入自适应自我精炼机制，使得训练模型能够在测试过程中自主决定何时停止自我精炼过程。", "conclusion": "在多个基准数据集上的广泛实验表明，ToolACE-R在工具调用性能上取得了与基于API的高级模型相当的竞争性结果。自适应自我精炼机制能够有效地进一步提高工具调用的性能。这些结果突显了ToolACE-R的高效性和普适性，为更高效的工具学习提供了有希望的方向。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.20839", "html_url": "https://arxiv.org/abs/2503.20839", "title": "TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion", "title_en": "TAR: Teacher-Aligned Representations via Contrastive Learning for Quadrupedal Locomotion", "authors": "Amr Mousa,Neil Karavis,Michele Caprio,Wei Pan,Richard Allmendinger", "background": "当前，四足行走的强化学习（RL）问题通常使用教师-学生范式进行解决，其中优势教师引导具有本体感受的学生策略。然而，这一过程中存在几个关键挑战，包括优势教师与本体感受学生之间的表示错位、由于行为克隆导致的条件变化，以及缺乏可部署的适应性，这些因素导致了在实际场景中的差表现。这些问题影响了策略的泛化能力，特别是在未见过的数据分布中的表现不足。本研究针对这一问题提出了一种新的方法。", "innovation": "研究提出了Teacher-Aligned Representations via Contrastive Learning (TAR)，一种框架。该方法利用优势信息与自监督对比学习相结合，通过对比目标在仿真环境中使学生的表示与优势教师对齐，从而形成了结构化的隐空间，使学生策略能够在未见过的数据场景中表现出更好的泛化能力，超过了完全优势的状态。实验结果表明，与最先进的基线相比，TAR可以将训练加速2倍并达到顶级性能；在未见过的数据场景中表现出40%的更好泛化效果。此外，TAR无需依赖优势状态即可平滑过渡到部署学习，为样本高效、适应性强的移动行为提供了新的基准，并允许在实际场景中进行持续微调。", "conclusion": "TAR通过对比学习方式使学生的表示与优势教师对齐，从而学习到了结构化隐空间并提高了泛化能力，尤其在未见过的数据场景中表现优异。该方法不仅在训练效率上有所提升，还在泛化能力上超过其他方法，并且能在不依赖优势状态的情况下进行部署学习。相关开源代码和视频可以在提供的链接中找到。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.19160", "html_url": "https://arxiv.org/abs/2412.19160", "title": "一个基于相位Only交叉注意力的轻量级变压器用于光照不变的生物特征认证", "title_en": "A Lightweight Transformer with Phase-Only Cross-Attention for Illumination-Invariant Biometric Authentication", "authors": "Arun K. Sharma,Shubhobrata Bhattacharya,Motahar Reza,Bishakh Bhattacharya", "background": "传统的生物识别系统因多种不可避免的因素受到重大阻碍，例如，面部识别生物识别系统中佩戴口罩的影响以及指纹识别生物识别系统中的卫生问题。本论文解决的背景包括如何在佩戴口罩和避免物理接触的情况下进行有效的生物识别认证，提供了一种传统方法以外的可行替代方案。提出了一个能够处理面部前额和眼周两种生物特征的轻量级视觉变换器框架（POC-ViT），此框架能够在输入图像强度、分辨率和光照变化的情况下仍保持稳定性能。它通过相位仅相关（POC）交叉注意力来捕捉两个特征的独立和关联结构模式，从而提出了如何改进传统生物识别系统的应用场景，并实现了在边沿设备上的部署。该研究采用了面部静脉血管模式（Forehead Subcutaneous Vein Pattern, FSVP）和眼周生物特征模式（Periocular Biometric Pattern, PBP）数据库，包含350个主题进行实验验证，结果表现出色，分类准确率达到98.8%。相比现有的最先进的方法，该框架亦有显著优越的表现。", "innovation": "提出了一种能够使用面部前额和眼周两种生物特征的轻量级视觉变换器框架（POC-ViT），并且利用相位仅相关（POC）交叉注意力相结合的方式，用于光照不变的生物特征认证。这一框架能够处理两种生物特征并在输入图像中表现出高度的鲁棒性，不仅不受分辨率、强度变化，还能较好应对光照条件的变化。此外，由于其轻量级特性，该框架特别适合在边缘设备上进行部署。值得注意的是，使用所提出的POC-ViT方法在350人的生物特征数据库中测试案例中表现优秀，取得了超过98.8%的分类准确率，超越了当前最先进的方法，显著提高了光照不变的生物识别性能；", "conclusion": "研究表明，POC-ViT框架能够有效应对光照变化带来的挑战，即使在佩戴口罩和避免身体接触的情况下，也能保持高度的识别性能。此外，作为一种部署在边缘设备上的人脸认证方法，该框架充分展示了其在未来生物识别领域的广泛潜力。总的来说，POC-ViT为传统的生物识别系统提供了一个有效的和可行的解决方案，可以期待在未来开发其他新型人脸识别技术时同样能发挥重要作用。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05349", "html_url": "https://arxiv.org/abs/2504.05349", "title": "Hyperflux: 显现权重重要性的剪枝", "title_en": "Hyperflux: Pruning Reveals the Importance of Weights", "authors": "Eugen Barbulescu,Antonio Alexoaie,Lucian Busoniu", "background": "网络剪枝被用于减少大型神经网络的推理延迟和功耗。然而，现有方法大多依赖于非正式的启发式方法，缺乏理论上的洞察力，主要依靠实验结果来证明其有效性。", "innovation": "提出了一种基于概念的L0剪枝方法——Hyperflux，通过估计每个权重在移除后对梯度响应的'flux'来衡量其重要性。该方法采用全球压力项将所有权重逐步驱向剪枝，同时通过对权重flux的评估自动恢复对准确度至关重要的权重。此外，该论文还推导出了关于最终稀疏性与剪枝压力之间关系的一般化比例定律，并实验证实了多个理论特性。", "conclusion": "在ResNet-50 和 VGG-19 网络上，通过Hyperflux方法在CIFAR-10 和 CIFAR-100 数据集上实现了最先进的效果。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08329", "html_url": "https://arxiv.org/abs/2504.08329", "title": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models", "title_en": "MedRep: Medical Concept Representation for General Electronic Health Record Foundation Models", "authors": "Junmo Kim,Namkyeong Lee,Jiwon Kim,Kwangsoo Kim", "background": "电子健康记录（EHR）基础模型在各种医疗任务中的性能得到了显著提升。然而，这些模型存在一个根本性的限制，即无法处理未预训练的医疗代码（即词汇外的代码），这限制了EHR基础模型的泛化能力和不同词汇训练模型之间的整合。", "innovation": "本文提出了一种基于OMOP共同数据模型（CDM）的新型医疗概念表示方法（MedRep），以解决上述问题。通过大型语言模型（LLM）提示增强每个概念的信息，并通过OMOP词汇的图本体补充基于文本的概念表示。实验结果表明，MedRep相较于传统EHR基础模型和之前引入的医疗代码分词器模型，在多种预测任务中性能更优，并且展示了其良好的泛化能力。", "conclusion": "MedRep在各种预测任务中表现出色，并通过外部验证证实了其泛化能力。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.14493", "html_url": "https://arxiv.org/abs/2504.14493", "title": "FinSage：金融申报领域 Retrieval-Augmented Generation 系统", "title_en": "FinSage: A Multi-aspect RAG System for Financial Filings Question Answering", "authors": "Xinyu Wang,Jijun Chi,Zhenghan Tai,Tung Sum Thomas Kwok,Muzhi Li,Zhuhong Li,Hailin He,Yuchen Hua,Peng Lu,Suyuchen Wang,Yihong Wu,Jerry Huang,Jingrui Tian,Fengran Mo,Yufei Cui,Ling Zhou", "background": "在实际应用场景中，使用大型语言模型往往需要利用领域特定的数据和工具，以遵循复杂的规则。在金融领域中，现代企业越来越多地依赖 Retrieval-Augmented Generation (RAG) 系统来处理复杂的合规要求。然而，现有的解决方案难以应对多模态数据（如文本、表格、图表）的差异性以及监管标准在金融报告中的不断变化，从而导致在关键信息提取过程中的准确性降低。", "innovation": "我们提出了 FinSage 框架，它使用一个专为多重模态金融文档中的合规分析而定制的 RAG 框架。FinSage 引入了三个创新组件：（1）一个多模态预处理管道，可统一多种数据格式并生成块级元数据摘要；（2）一个使用查询扩展（HyDE）和元数据意识语义搜索增强的多路径稀疏-密集检索系统；（3）一个通过直接偏好优化（DPO）微调的领域专业化重新排序模块，优先考虑合规关键内容。", "conclusion": "广泛的实验表明，FinSage 在 75 个专家策划的问题上的召回率达到了 92.51%，并且在 FinanceBench 问题回答数据集上的准确率比最佳基线方法高出 24.06%。此外，FinSage 已成功部署为财务问答代理，已服务超过 1,200 人。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14647", "html_url": "https://arxiv.org/abs/2505.14647", "title": "基于线搜索的序贯QCQP方法用于 bilevel优化", "title_en": "Sequential QCQP for Bilevel Optimization with Line Search", "authors": "Sina Sharifi,Erfan Yazdandoost Hamedani,Mahyar Fazlyab", "background": " bilevel优化涉及一个分层结构，其中一个问题嵌套在另一个问题中，导致各层级之间复杂的相互依赖关系。传统方法在处理这种复杂的层级关系时计算复杂且难以满足优化条件。本研究旨在设计一种单循环、无需调节参数的算法，以保证实时可行性和上层目标函数的下降，同时确保下层优化条件的近似满足，克服了传统方法的复杂性和难以调节参数的问题。", "innovation": "提出了一个无需调节参数的单循环算法，该算法在每次迭代中通过一个具有闭式解的凸二次约束二次规划（QCQP）问题得到搜索方向，然后通过借鉴控制障碍函数思想的回溯线搜索确保安全的、均匀的正向步长。该方法具有可扩展性，无需任何超参数调节，且在较温和的局部正则假设下收敛。", "conclusion": "该方法在每步迭代中通过序贯QCQP问题提供搜索方向，并结合回溯线搜索确保安全度。实验结果表明，该算法对于代表性的bilevel问题具有有效性，并且具有O(1/k)的依序收敛速率。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.15002", "html_url": "https://arxiv.org/abs/2505.15002", "title": "揭示迭代CHAD", "title_en": "Unraveling the iterative CHAD", "authors": "Fernando Lucatelli Nunes,Gordon Plotkin,Matthijs Vákár", "background": "CHAD最初被定义为一种基于语义的源到源转换，用于对完整的（终止的）函数式程序进行反向模式自动微分。本文在此基础上，将CHAD扩展应用于包含如部分（可能终止）操作、数据依赖条件（例如实数测试）和迭代构造（如while循环）的程序，同时保持CHAD的核心原则：结构保持语义。", "innovation": "论文的主要创新在于引入了迭代广义索引范畴，这是一种原则性的方法，将迭代整合到依赖类型编程语言中。通过要求基础范畴中的迭代在广义索引范畴中提升为参数化的初始代数，形成了一个操作纤维迭代结构，此结构能够模型化总范畴中（即我们依赖类型语言的容器范畴）的while循环和其他迭代构造。借助迭代广义索引范畴的概念，CHAD的转换扩展到了循环程序，成为适当意义上的唯一结构保持函子。这是从源语言对应的迭代Freyd范畴映射到目标语言的容器范畴的独特迭代Freyd范畴同态，使得每个基础操作映射到其（转置）导数。", "conclusion": "通过源语言结构化范畴模型的普遍性质证明了此扩展转换的正确性，表明差分程序能够正确地计算其原始程序的反向模式导数。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.19657", "html_url": "https://arxiv.org/abs/2504.19657", "title": "神经关联塑造循环神经网络 reservoir 回归神经网络 的记忆容量和非线性计算能力的缩放行为", "title_en": "Neuronal correlations shape the scaling behavior of memory capacity and nonlinear computational capability of reservoir recurrent neural networks", "authors": "Shotaro Takasu,Toshio Aoyagi", "background": "水库计算是一种强大的实时信息处理框架，以其强大的计算能力和快速学习能力为特点，在机器学习和生物系统等领域具有广泛应用。已有研究表明，随着读出神经元数量的增加，水库 RNN 的计算能力会发生变化。此外，由于先前理论工作简化了神经元相关性的作用，忽略了这一因素，对水库 RNN 的计算能力变化的理论研究仍不充分，尤其是对于记忆容量和非线性计算能力的具体影响机制仍不清楚，因此本研究旨在探究神经元相关性如何影响这两种计算能力的缩放行为。", "innovation": "本研究首次开发了一种理论框架，用于分析神经元相关性对 RNN 预测记忆容量和非线性计算能力缩放行为的影响，它成功地将神经元相关性与记忆容量的亚线性缩放联系起来，并揭示了神经元相关性不仅影响记忆容量，还影响非线性计算能力的顺序增长。此外，研究结果表明，随着 RNN 类型的变化，神经元相关性在决定这两种计算能力缩放行为中的作用是普遍存在的。这为理解和设计高效、低成本的水库计算系统提供了新的见解，并为长期记忆的功能解释提供了新的理论基础。", "conclusion": "本研究通过理论分析和数值模拟，确定了神经元相关性在决定 RNN 记忆容量和非线性计算能力缩放行为中的关键作用。研究表明，随着读出神经元数量的增加，记忆容量的增长显示出亚线性趋势，从而使更高次的非线性处理变得可能。这些发现有助于指导设计具有可扩展性和成本效益的 RNN，为生物神经处理和信息编码的机制提供了更深入的理解。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.19794", "html_url": "https://arxiv.org/abs/2506.19794", "title": "为何开源大语言模型在数据分析中挣扎？一项系统性的实证研究", "title_en": "Why Do Open-Source LLMs Struggle with Data Analysis? A Systematic Empirical Study", "authors": "Yuqi Zhu,Yi Zhong,Jintian Zhang,Ziheng Zhang,Shuofei Qiao,Yujie Luo,Lun Du,Da Zheng,Ningyu Zhang,Huajun Chen", "background": "开源大语言模型（LLMs）在自动化数据处理任务方面前景广阔，但在需要高度推理能力的场景中，它们面临显着限制。这项研究探讨了增强开源LLMs的数据分析能力的策略。", "innovation": "通过收集多样且现实的数据集，研究者评估模型在数据理解、代码生成和战略规划这三个核心维度上的表现。研究揭示出关键技术点：(1) 战略规划的质量是模型性能的主要决定因素；(2) 交互设计和任务复杂性显著影响推理能力；(3) 数据质量比多样性对实现最佳性能有更大的影响。这些见解用于开发数据合成方法，从而显著提升了开源LLMs的分析推理能力。研究中涉及的代码可在指定网址获取。", "conclusion": "这项研究通过系统性的实证方法，得出了开源LLMs在数据分析中面临的挑战及提升策略，并展示了通过特定数据合成方法达到显著改进的结果。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.22107", "html_url": "https://arxiv.org/abs/2505.22107", "title": "Transformer模型长时间上下文建模中的高维问题", "title_en": "Curse of High Dimensionality Issue in Transformer for Long-context Modeling", "authors": "Shuhai Zhang,Zeng You,Yaofo Chen,Zhiquan Wen,Qianyue Wang,Zhijie Qiu,Yuanqing Li,Mingkui Tan", "background": "基于Transformer的大型语言模型（LLMs）在自然语言处理任务中表现出色，通过自注意力机制捕捉长时间依赖关系。然而，建模长时间上下文面临显著的计算效率低下问题，原因是尽管自注意力权重往往是稀疏的，但所有单词都消耗相同量的计算资源。本文通过重新定义传统的概率序列建模为监督学习任务，使相关和不相关的单词分离，从而揭示了冗余性。研究还表明，仅少数几个单词对预测有显著贡献。进一步的理论分析显示，注意力稀疏化可提高模型的健壮性并增强学习效率。", "innovation": "本文通过重新定义传统的概率序列建模为监督学习任务，提出了通过分组编码策略（Group Coding Strategy）来减少冗余的动态分组注意力（Dynamic Group Attention，DGA）方法。该方法在聚合不重要词汇时减少注意力计算中的冗余，理论上展示了其在随机噪声下的鲁棒性提高及学习效率增强。", "conclusion": "实验结果表明，DGA在显著降低计算成本的同时仍能保持竞争力。该项研究通过提出一种新的分组编码策略，为理解Transformer模型中因高维度导致的计算低效问题提供了解决方案，且不影响模型的预测性能。研究成果在相应的领域具有广泛的潜在应用前景。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10236", "html_url": "https://arxiv.org/abs/2506.10236", "title": "提示攻击揭示了遗忘方法中的表面知识移除", "title_en": "Prompt Attacks Reveal Superficial Knowledge Removal in Unlearning Methods", "authors": "Yeonwoo Jang,Shariqah Hossain,Ashwin Sreevatsa,Diogo Cruz", "background": "本文研究指出，某些机器遗忘方法在面对简单的提示攻击时可能会失效。研究团队系统地评估了八个遗忘技术，分别应用在三种不同的模型家族中，使用输出分析、logit分析和探针分析来评估已声称被遗忘的知识是否能够重新获取。虽然RMU和TAR等方法显示出较强的遗忘效果，但ELM等方法在特定的提示攻击下仍然容易受到影响，如添加印地语填充文本可以恢复约57.3%的准确性。通过logit分析进一步表明，遗忘的模型不太可能通过改变答案格式来隐藏知识，因为输出和logit准确性之间存在很强的相关性。这些发现挑战了关于遗忘方法有效性的现有假设，突显了需要开发一个可靠的评估框架，以区分真正的知识移除和表面的输出抑制的需求。为了促进进一步的研究，研究团队公开发布评估框架以方便评估用于获取遗忘知识的提示技术。", "innovation": "研究团队在三个方面表现出创新：首先，系统性地评估了多个遗忘技术在不同模型族中的表现；其次，通过输出分析、logit分析和探针分析提供了更深度的评估视角；最后，揭示了遗忘方法在特定提示攻击下的脆弱性，并指出了区分真实知识移除和表面输出抑制的需求。团队还提供了可公开访问的评估框架以支持进一步研究。", "conclusion": "本文的研究结果挑战了关于遗忘方法有效性的现有假设，并指出遗忘方法可能无法有效清除已学习的知识。研究提出了一个用于评估提示技术获取遗忘知识的框架，并强调了需要开发可靠的评估框架以促进未来研究。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.22493", "html_url": "https://arxiv.org/abs/2506.22493", "title": "详细因子分析：大型语言模型的政治倾向性测试导航", "title_en": "A Detailed Factor Analysis for the Political Compass Test: Navigating Ideologies of Large Language Models", "authors": "Sadia Kamal,Lalu Prasad Yadav Prakash,S M Rafiuddin,Mohammed Rakib,Atriya Sen,Sagnik Ray Choudhury", "background": "政治倾向性测试（PCT）或类似问卷已被用来量化大型语言模型（LLM）的政治倾向。近期的研究表明，PCT测试的有效性需要进一步验证。本文进一步探讨了标准生成参数变化对模型PCT分数的影响，发现这些变化对模型的影响较小，而外部因素如提示变化和微调单独或结合使用时则对模型的PCT分数有显著影响。此外，作者还发现，当模型在具有较高政治内容的文本数据集上进行微调时，PCT分数并未受到影响。这些结果表明，需要深入研究PCT等类似测试的有效性及其背后机制，特别是大型语言模型中政治倾向性编码的机制。", "innovation": "1. 证明了标准生成参数变化对模型PCT分数影响较小。\n2. 发现外部因素如提示变化和微调对模型PCT分数有显著影响。\n3. 表明即使是具有较高政治内容的文本数据集的微调，对模型的PCT分数没有不同影响，从而要求进一步调查PCT等类似测试的有效性及其机制。", "conclusion": "需要进一步的研究来验证PCT等类似测试的有效性，并探讨大型语言模型中政治倾向性如何被编码。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.06639", "html_url": "https://arxiv.org/abs/2507.06639", "title": "EXAONE Path 2.0: 具备端到端监督的病理学基础模型", "title_en": "EXAONE Path 2.0: Pathology Foundation Model with End-to-End Supervision", "authors": "Myeongjang Pyeon,Janghyeon Lee,Minsoo Lee,Juseung Yun,Hwanil Choi,Jonghyun Kim,Jiwon Kim,Yi Hu,Jongseong Jang,Soonyoung Lee", "background": "在数字病理学中，由于全切片图像（WSIs）具有巨像素尺度，因此通常难以处理。大多数方法通过自我监督学习（SSL）训练局部图像编码器，并通过多次实例学习（MIL）或切片编码器进行聚合，以完成下游任务。然而，这些方法可能会忽略重要的复杂领域特定特征，如突变状态和分子特性，因为SSL方法仅依赖于对自然图像域进行的简单增强。此外，SSL方法的数据效率较低，需要大量计算资源和数据集才能达到竞争力性能。", "innovation": "EXAONE Path 2.0 提出了一个具备直接切片级别监督的病理学基础模型，仅使用 37,000 个 WSIs 进行训练即可实现 10 项生物标志物预测任务的最佳平均性能，展现了显著的数据效率。", "conclusion": "该研究表明，通过直接切片水平监督学习局部表示可以提高在病理学中的数据效率和性能。EXAONE Path 2.0 模型在少量标本训练数据的情况下取得了优异的性能，展示了其潜在的应用价值。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.08280", "html_url": "https://arxiv.org/abs/2507.08280", "title": "MIRRAMS: 在未见缺失模式下学习稳健的表格模型", "title_en": "MIRRAMS: Learning Robust Tabular Models under Unseen Missingness Shifts", "authors": "Jihye Lee,Minseo Kang,Dongha Kim", "background": "缺失值的出现往往反映了数据收集政策的变化，这些变化可能随时间或地点而变化，即使底层特征分布保持稳定也是如此。训练集和测试集之间的缺失分布的变化给实现稳健预测性能带来了显著挑战。", "innovation": "本文提出了一种新的深度学习框架——MIRRAMS，它包含一套基于互信息的稳健性条件，以指导预测模型提取标签相关信息，从而在测试时应对缺失分布的变化。MIRRAMS 不依赖于特定的缺失性假设（如MCAR、MAR或MNAR），适用于广泛的场景，甚至当训练数据标签缺失时也能自然扩展到半监督学习设置。", "conclusion": "MIRRAMS 在多个基准表格数据集上的实验结果表明，它在不同缺失条件下的性能具有稳定性和优越性，甚至在完全观测的情况下也能表现出色，证明了它作为通用表格学习中的强大框架的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05294", "html_url": "https://arxiv.org/abs/2508.05294", "title": "向具身智能行为主体AI的方向：LLM和VLM驱动的机器人自主性和交互的回顾与分类", "title_en": "Towards Embodied Agentic AI: Review and Classification of LLM- and VLM-Driven Robot Autonomy and Interaction", "authors": "Sahar Salimpour,Lei Fu,Farhad Keramat,Leonardo Militano,Giovanni Toffetti,Harry Edelman,Jorge Peña Queralta", "background": "论文背景讨论了基础模型，包括大型语言模型（LLMs）和视觉-语言模型（VLMs），在机器人自主性和人机交互中发挥了重要作用。同时，视觉-语言-行动模型（VLAs）或大规模行为模型（LBMs）提高了机器人系统的灵活性和能力。本文综述了这些工作的最新进展，特别是在机器人自主性和交互的行为主体应用和架构中。", "innovation": "论文的创新在于提案了一种分类模型集成方法的分类法，并进行了不同解决方案中AI代理角色的比较分析。研究还突出并包括了由社区推动的项目、ROS包和工业框架，展现了领域中的新兴趋势。", "conclusion": "论文提出了关于LLM和VLM驱动的机器人自主性和交互的分类和分析，这对理解和促进机器人行为主体的未来发展具有重要意义。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19712", "html_url": "https://arxiv.org/abs/2507.19712", "title": "Oranits: 在基于Open RAN的智能交通系统中使用元启发式和深度强化学习进行任务分配和任务卸载", "title_en": "Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning", "authors": "Ngoc Hung Nguyen,Nguyen Van Thieu,Quang-Trung Luu,Anh Tuan Nguyen,Senura Wanasekara,Nguyen Cong Luong,Fatemeh Kavehmadavani,Van-Dinh Nguyen", "background": "现有的研究通常忽略了任务之间复杂的相互依赖性和将任务卸载到边缘服务器的成本，导致决策的次优性。本文探讨了在基于Open Radio Access Network (Open RAN)的智能交通系统(ITS)中，自主车辆利用移动边缘计算进行高效处理的任务分配和任务卸载问题。", "innovation": "本文引入了Oranits，一个新颖的系统模型，该模型明确考虑了任务的相互依赖性和卸载成本，并通过车辆合作优化性能。为了实现这一目标，提出了一种两阶段的优化方法。首先，开发了一种基于混沌高斯的全局优化算法CGG-ARO，作为单插槽优化的基线。其次，设计了一种增强的基于奖励的深度强化学习框架MA-DDQN，该框架结合了多智能体协调和多动作选择机制，极大地减少了任务分配时间并提高了适应性，相比基线方法有显著提高。", "conclusion": "广泛仿真实验显示，CGG-ARO将完成的任务数量和总体收益分别提高了约7.1%和7.7%。而MA-DDQN则在任务完成率和总体收益上分别实现了11.0%和12.5%的改进。这些结果突显了Oranits在动态ITS环境中实现更快、更适应性和更高效的任务处理的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05690", "html_url": "https://arxiv.org/abs/2508.05690", "title": "利用大型语言模型进行SQL行为基于的数据库入侵检测", "title_en": "Leveraging large language models for SQL behavior-based database intrusion detection", "authors": "Meital Shlezinger,Shay Akirav,Lei Zhou,Liang Guo,Avi Kessel,Guoliang Li", "background": "数据库系统广泛用于存储各种领域的关键数据。然而，异常数据库访问行为的频率在不断上升，包括内部和外部攻击对数据库的入侵。内部伪装者通常具有更深入的组织知识，使其更容易模仿员工行为。相比之下，外部伪装者由于对组织的不熟悉，其行为会有所不同。当前的方法缺乏足够的精细度，无法在操作级别准确检测异常行为，常常将一整串的操作错误地分类为异常，即使大多数操作很可能是正常的。另一方面，一些异常行为可能看起来像正常的行为，使得现有检测方法难以识别。", "innovation": "本文提出了一种利用双向编码表示转换器（BERT）模型，特别是预训练的DistilBERT模型的两层异常检测方法，用于SQL行为检测。该方法结合了无监督和监督机器学习技术，以准确识别异常活动，同时减少了对数据标签的需求。无监督方法使用集成异常检测器标记远离常规用户行为学习到的正常模式的嵌入向量（超出范围的查询）。监督方法使用微调的变压器模型来检测高精度的内部攻击（在范围内的查询），并且即使在有限的标记SQL数据上，也使用基于角色的分类。", "conclusion": "本研究的重要发现提供了一种有效的解决方案，以保护关键的数据库系统免受复杂的威胁，使用基于行为的SQL异常检测方法来提高安全性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01006", "html_url": "https://arxiv.org/abs/2507.01006", "title": "GLM-4.1V-Thinking 和 GLM-4.5V：基于可扩展强化学习的通用多模态推理", "title_en": "GLM-4.1V-Thinking and GLM-4.5V: Towards Versatile Multimodal Reasoning with Scalable Reinforcement Learning", "authors": "GLM-V Team:Wenyi Hong,Wenmeng Yu,Xiaotao Gu,Guo Wang,Guobing Gan,Haomiao Tang,Jiale Cheng,Ji Qi,Junhui Ji,Lihang Pan,Shuaiqi Duan,Weihan Wang,Yan Wang,Yean Cheng,Zehai He,Zhe Su,Zhen Yang,Ziyang Pan,Aohan Zeng,Baoxu Wang,Bin Chen,Boyan Shi,Changyu Pang,Chenhui Zhang,Da Yin,Fan Yang,Guoqing Chen,Jiazheng Xu,Jiale Zhu,Jiali Chen,Jing Chen,Jinhao Chen,Jinghao Lin,Jinjiang Wang,Junjie Chen,Leqi Lei,Letian Gong,Leyi Pan,Mingdao Liu,Mingde Xu,Mingzhi Zhang,Qinkai Zheng,Sheng Yang,Shi Zhong,Shiyu Huang,Shuyuan Zhao,Siyan Xue,Shangqin Tu,Shengbiao Meng,Tianshu Zhang,Tianwei Luo,Tianxiang Hao,Tianyu Tong,Wenkai Li,Wei Jia,Xiao Liu,Xiaohan Zhang,Xin Lyu,Xinyue Fan,Xuancheng Huang,Yanling Wang,Yadong Xue,Yanfeng Wang,Yanzi Wang,Yifan An,Yifan Du,Yiming Shi,Yiheng Huang,Yilin Niu,Yuan Wang,Yuanchang Yue,Yuchen Li,Yutao Zhang,Yuting Wang,Yu Wang,Yuxuan Zhang,Zhao Xue,Zhenyu Hou,Zhengxiao Du,Zihan Wang,Peng Zhang,Debing Liu,Bin Xu,Juanzi Li,Minlie Huang,Yuxiao Dong,Jie Tang", "background": "我们介绍了GLM-4.1V-Thinking和GLM-4.5V，这是一种旨在提高通用多模态理解和推理能力的视觉-语言模型（VLM）。通过大规模预训练，我们开发了一个具有显著潜力的视觉基础模型，并提出了一种新的强化学习与课程采样（RLCS）框架，以解锁模型的全部潜力，并在多个任务上实现全面的能力增强。在42个公共基准测试中，GLM-4.5V在几乎所有任务上均达到开源模型的最新性能，特别是在编程和GUI代理等具有挑战性的任务上，甚至优于封闭源代码模型Gemini-2.5-Flash。GLM-4.1V-9B-Thinking虽然较小，但在29个基准测试中也取得了优于Qwen2.5-VL-72B的结果。我们已开源GLM-4.1V-9B-Thinking和GLM-4.5V，相关代码、模型及更多详细信息可访问特定的网页链接。", "innovation": "我们提出了强化学习与课程采样（RLCS）框架，这是一种新的训练框架，旨在增强模型在多种任务上的推理能力。通过这一框架，GLM-4.5V在包括STEM问题解决、视频理解、内容识别、编程、图元基础代理和长文档解释等多个任务上取得了显著的性能提升，超越了同类开源和闭源模型。此外，GLM-4.1V-9B-Thinking模型在较小的规模下也能保持竞争力，即使在绝对规模更大（72B）的模型上也展示了明显的优势。", "conclusion": "GLM-4.1V-Thinking和GLM-4.5V模型均已被开源，并已应用于多个任务，在多个公开基准测试中取得了先进的性能，特别是在有限规模下也具有出色的性能。我们强调了新提出的强化学习与课程采样（RLCS）框架在提升模型性能方面的重要作用，展示了这些模型在多模态推理方面的强大能力和广泛适用性。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06406", "html_url": "https://arxiv.org/abs/2508.06406", "title": "Blockchain-Enabled Federated Learning", "title_en": "Blockchain-Enabled Federated Learning", "authors": "Murtaza Rangwala,KR Venugopal,Rajkumar Buyya", "background": "区块链赋能的联邦学习（BCFL）解决了协同人工智能系统中的信任、隐私和协调等基本挑战。本文通过系统性的四维分类法，对BCFL系统的架构进行了全面分析，涵盖了协调结构、共识机制、存储架构和信任模型，以探讨分布式图像分类训练中不同区块链验证的中央协调模式到完全去中心化的点对点网络模式之间的权衡。", "innovation": "本文创新性地分析了为联邦学习情境设计的共识机制，如质量证明和联邦学习证明，并展示了计算工作如何从任意加密谜题重新用于有益的人工智能任务。此外，通过分布式结构和多级架构平衡区块链交易限制与神经网络的大参数要求，确保了区块链的加密完整性。", "conclusion": "实际部署案例研究表明，BCFL系统在物联网设备间实现了有效的协作学习，即使面对高度非独立同分布（non-IID）的数据分布，也能保留完全透明性和故障容错能力。健康医疗联盟、金融服务以及物联网安全应用的实际部署验证了BCFL系统的实际可行性，使其具备与中心化方法相当的性能并提供增强的安全保障，开启了信任无边界协同智能的新模式。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08855", "html_url": "https://arxiv.org/abs/2508.08855", "title": "BiasGym：如何发现并移除大型语言模型中的偏见", "title_en": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them", "authors": "Sekh Mainul Islam,Nadav Borenstein,Siddhesh Milind Pawar,Haeun Yu,Arnav Arora,Isabelle Augenstein", "background": "理解大型语言模型（LLMs）中嵌入的偏见和刻板印象对于开发有效的缓解策略至关重要。有偏的行为往往微妙且在刻意引发时不容易识别，使得系统的分析和去偏显得尤为困难。", "innovation": "BiasGym 是一个简单、经济且可扩展的框架，用于可靠地注入、分析和缓解 LLMs 中的概念关联中的偏见。BiasGym 包含 BiasInject 和 BiasScope 两个组件：BiasInject 通过基于token的微调将特定偏见注入模型而不冻结模型；BiasScope 利用注入的信号来识别并引导导致偏见行为的责任组件。该方法允许一致地激发偏见进行机制分析，支持不降低下游任务性能的针对性去偏，并能够推广到在基于token的微调期间未见过的偏见。", "conclusion": "BiasGym 在减少现实世界刻板印象（如意大利人是有‘鲁莽司机’）和探究虚构关联（如来自虚构国家的人有‘蓝色皮肤’）方面显示出其在安全干预和可解释性研究方面的有效性。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10059", "html_url": "https://arxiv.org/abs/2508.10059", "title": "FormalGrad: 将形式化方法与基于梯度的LLM优化相结合", "title_en": "FormalGrad: Integrating Formal Methods with Gradient-Based LLM Refinement", "authors": "Yueke Zhang,Yifan Zhang,Kevin Leach,Yu Huang", "background": "大型语言模型（LLMs）在代码生成方面展示了杰出的能力，但往往生成的解决方案在正确性、鲁棒性和效率方面缺乏保证。特别是在需要严格约束的领域，这一问题尤为突出。FormalGrad引入了一个具有原则性的框架，直接将形式化方法融入迭代的LLM生成循环中。这种方法的独特之处在于将代码视为可微变量，并将结构化的反馈和形式约束转化为文本伪梯度，引导模型逐步细化解决方案，确保解决方案不仅功能健全，还具有鲁棒性并且形式上得到验证。", "innovation": "FormalGrad 提出了一个独特的框架，将形式化方法与基于梯度的LLM优化直接结合，将代码视为可微变量，通过结构化反馈和形式约束生成文本伪梯度，指导模型逐步优化解决方案，确保解决方案在功能性、鲁棒性和形式验证方面都得到提高。FormalGrad 在 HumanEval、HumanEval+ 和 LiveCodeBench 测试基准上的评估显示，其实现优于强基线，特别是在 LiveCodeBench V6 上实现了 41% 的相对改进。", "conclusion": "FormalGrad 生成了形式化验证的、稳健且高效的代码，为在高风险应用中实现可靠的 AI 辅助软件开发铺平了道路。"}
{"llm_update_time": "20250817", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.20871", "html_url": "https://arxiv.org/abs/2507.20871", "title": "基于注意力机制的长期视角下联邦学习客户端选择算法FedABC", "title_en": "FedABC: Attention-Based Client Selection for Federated Learning with Long-Term View", "authors": "Wenxuan Ye,Xueli An,Junfan Wang,Xueqiang Yan,Georg Carle", "background": "6G网络的发展关键目标是原生AI支持，其中联邦学习（FL）作为一种有前景的范式，备受关注。FL允许分散化的客户端在不直接共享数据的情况下，通过训练本地模型并共享模型更新的方式，协同训练全球化模型。然而，客户端数据异质性减缓了模型收敛速度并降低了模型准确性，频繁的客户参与也增加了通信和计算负担。", "innovation": "本文提出了一种名为FedABC的创新客户端选择算法，它通过借鉴注意力机制，长期考虑数据异质性和客户端参与的优化，评估模型相似性和每个模型对全球化模型的独特贡献，从而优选信息量多的客户端。同时，考虑全局模型的需求变化，FedABC通过求解优化问题，在训练过程中引导更好的选择客户端，并根据“后期效果更好”的原则，自适应调整客户端选择阈值。", "conclusion": "实验证明，FedABC在模型准确性和客户端参与效率方面优于现有方法，与经典的FL算法FedAvg相比，其性能可与使用32%更少的客户端相匹配，并且在比最新技术少2%的客户端条件下，实现了3.5%的更高准确性。这项工作为在异构和资源受限环境中部署FL提供了步骤，支持6G网络内的原生AI能力。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10068", "html_url": "https://arxiv.org/abs/2508.10068", "title": "SaraCoder：为利润导向的代码库级别代码补全协调语义和结构线索", "title_en": "SaraCoder: Orchestrating Semantic and Structural Cues for Profit-Oriented Repository-Level Code Completion", "authors": "Xiaohan Chen,Zhongying Pan,Quan Feng,Yu Tian,Shuqun Yang,Mengru Wang,Lina Gong,Yuxia Geng,Piji Li,Xiang Chen", "background": "现有代码补全方法依赖于表面文本相似性，导致结果充满语义误导、冗余和同质性，同时无法解决外部符号的歧义性。这些问题限制了现有技术在准确性和鲁棒性方面的表现，特别是在跨文件符号解析方面表现不佳，难以区分符号在不同上下文中的具体含义，从而影响代码补全的质量和效率。", "innovation": "Saracoder 提出了一种名为 Hierarchical Feature-Optimized 的检索框架。其核心模块 Hierarchical Feature Optimization 通过对候选操作进行有系统的改进，提炼深层次的语义关系，去除完全相同的重复项，采用基于图的新颖的结构相似性度量，该度量以拓扑重要性加权编辑，对结果进行再排序，以最大化相关性和多样性。此外，Saracoder 的 External-Aware Identifier Disambiguator 模块通过依赖性分析准确解决了跨文件符号的歧义问题，有助于提高代码补全的准确性和鲁棒性。", "conclusion": "Saracoder 在多个编程语言和模型上，通过广泛的实验对比，展现出了显著的优越性，这表明跨多个维度有系统的检索结果提炼，能够为构建更准确和鲁棒的代码库级别代码补全系统开辟新的范式。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10157", "html_url": "https://arxiv.org/abs/2508.10157", "title": "关于Hugging Face预训练语言模型与其上游GitHub仓库之间的同步", "title_en": "On the synchronization between Hugging Face pre-trained language models and their upstream GitHub repository", "authors": "Ajibode Adekunle,Abdul Ali Bangash,Bram Adams,Ahmed E. Hassan", "background": "预训练语言模型（PTLMs）在自然语言处理（NLP）领域的进展显著，尤其是在文本生成和翻译等任务中的应用。PTLMs 的开发和发行为一种双重管理模式，上游的 GitHub 等代码托管平台负责训练和维护PTLMs，Hugging Face等平台则用于分发不同版本的变体。然而，跨平台的协调工作面临诸多挑战，比如发布时间不一致、版本控制不统一、以及PTLMs变体的复用性较低等问题。", "innovation": "本研究通过混合方法对325个PTLM家族（904个Hugging Face变体）的提交活动进行了全面分析，揭露了GitHub贡献者与Hugging Face贡献者在开发活动中不同的关注点，并识别出八种独特的同步模式。特别指出的，部分同步的模式（如分散同步和稀疏同步）揭示了当前跨平台发布实践中的结构性分离，导致了在两个平台上孤立的变化和阶段性放弃某一仓库的情况，对最终用户构成了风险。", "conclusion": "识别不同的同步模式对于改进PTLMs发布工作流程的监管和可追溯性至关重要。必须采取措施以确保这些独特的同步模式不会导致端用户使用不完整、过时或行为不一致的模型。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10517", "html_url": "https://arxiv.org/abs/2508.10517", "title": "Solidity 进化间隙：智能语言模型增强的智能合约编译错误解决方法", "title_en": "Bridging Solidity Evolution Gaps: An LLM-Enhanced Approach for Smart Contract Compilation Error Resolution", "authors": "Likai Ye,Mengliang Li,Dehai Zhao,Jiamou Sun,Xiaoxue Ren", "background": "Solidity作为Ethereum的主流智能合约语言，随着频繁的版本更新经历了快速发展，这极大提升了安全性、功能性和开发者体验。然而，这些持续的变化也带来了重大挑战，特别是在编译错误、代码迁移和维护方面。因此，本文进行了实证研究，探讨Solidity版本演化的挑战，并发现81.68%的已检合同在不同版本之间编译时会出现错误，其中86.92%的错误是编译错误。为应对这些挑战，本文系统评估了大型语言模型（LLMs）在Solidity版本迁移期间解决编译错误的能力。然而，模型在解决语义级问题方面效果较差，并且依赖于提示工程策略。这表明了在开发可靠的LLM基智能合约修复系统时需要专门领域适应的重要性。", "innovation": "文章系统评估了大型语言模型在Solidity编译错误修复方面的表现，并提出了一个名为SMCFIXER的新型框架。SMCFIXER框架系统地整合了专家知识检索与LLM基修复机制，通过三个核心阶段——上下文感知代码切片以提取相关错误信息、从官方文档检索专家知识以及迭代的Solidity迁移补丁生成——来解决Solidity编译错误。在Solidity版本迁移中的实验验证表明，与基准模型GPT-4o相比，该方法在实际数据集上取得了24.24%的显著改进，并且达到了接近完美的96.97%的准确性。", "conclusion": "本文的研究表明，虽然大型语言模型在解决编译错误上有一定的能力，但其在处理语义级问题上的效果较差，并且高度依赖于提示工程策略。因此，需要专门领域的适应来开发可靠的基于LLM的智能合约修复系统。基于这些发现，本文提出了SMCFIXER框架，该框架通过整合专家知识检索和LLM修复机制来有效解决Solidity编译错误。实验结果表明，该方法在实际数据集上的性能显著优于基准模型。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10017", "html_url": "https://arxiv.org/abs/2508.10017", "title": "使用SMOTETomek和FedProx在不平衡临床数据上实现差分隐私联邦学习的稳健管道", "title_en": "A Robust Pipeline for Differentially Private Federated Learning on Imbalanced Clinical Data using SMOTETomek and FedProx", "authors": "Rodrigo Tertulino", "background": "联邦学习（FL）提供了一种在保护患者隐私的同时进行去中心化数据模型训练的创新方法。结合差分隐私（DP），FL能够正式保证安全性。然而，这种方法在实际应用中需处理隐私与临床效用之间的权衡，特别是在存在严重类别不平衡的医疗数据集上时，这种挑战更加复杂。本文通过系统多阶段分析，探讨并解决了这些问题。", "innovation": "本文提出了一种改进的联邦学习框架，结合了合成少数类别过采样技术与陶梅克链接（SMOTETomek）以及调优的FedProx算法。在心血管风险预测任务中，该框架展示了在处理不平衡数据时的有效性。最终结果显示，在隐私预算和模型召回率之间存在明确的非线性权衡关系，调优后的FedProx算法始终优于标准的FedAvg，同时识别出在隐私-效用前沿上的最佳操作区域，确保了在不牺牲临床效用的情况下实现强隐私保障。", "conclusion": "本研究提供了一种实用的方法论蓝图，用以创建有效、安全、准确的诊断工具，这些工具可以应用于异构的医疗健康数据。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2302.11617", "html_url": "https://arxiv.org/abs/2302.11617", "title": "云原生应用治理的参考架构", "title_en": "A Reference Architecture for Governance of Cloud Native Applications", "authors": "William Pourmajidi,Lei Zhang,John Steinbacher,Tony Erwin,Andriy Miranskyy", "background": "云计算的发展催生了云原生应用（CNAs），这带来了新的治理挑战，尤其是在面对严格的合规要求时。本研究探讨了CNAs的独特特性和其对治理的影响，旨在为单云和多云环境提供合适的治理架构。", "innovation": "提出了一种全面的参考架构，该架构简化了CNAs的治理流程，并通过‘包含电池’的理念无缝集成治理功能。该架构适用于各个行业的CNAs部署，无论是大规模还是小型部署，帮助云从业者通过简化治理复杂性来优先考虑产品开发。同时，也为云原生应用框架的学术研究提供了构建模块，突显了其在不断发展的云计算领域的相关性。", "conclusion": "该设计为CNAs治理提供了一种集成方法，简化了多个行业的CNAs治理流程，无论部署规模大小。同时，它也为学术界提供了研究通用CNAs架构的基础素材，展示了其在演化的云计算环境中的重要性。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.09991", "html_url": "https://arxiv.org/abs/2508.09991", "title": "连接AI创新与医疗需求：BC癌症登记处集成现代NLP的经验教训", "title_en": "Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry", "authors": "Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji", "background": "自动化从临床文档中提取数据具有显著提高医疗效率的潜力，但部署自然语言处理（NLP）解决方案面临着实际挑战。本文基于在不列颠哥伦比亚癌症登记处（BCCR）实施各种NLP模型进行信息提取和分类任务的经验，分享了项目生命周期中的关键经验教训。背景指出，定义问题应基于明确的业务目标而非单纯的技术准确性，并强调迭代开发方法和跨学科合作的重要性，以促进领域专家、最终用户和技术专家的协同设计。进一步的见解表明，在选择模型时需要务实（包括混合方法和在适当情况下使用更简单的方法）、严格的数据质量关注（代表性、漂移、标注）和稳健的错误缓解策略（包括人工在环验证和持续审计），以及构建组织的AI识读能力。", "innovation": "文章强调了在项目实施过程中基于明确业务目标而非单纯技术准确性的定义问题的重要性，采用迭代开发方法，以及跨学科合作与协同设计，特别是在领域专家、最终用户和ML专家之间的合作上。进一步还提出在选择模型时需要务实的方法（包括混合方法和在适当情况下使用更简单的方法）、关注数据质量（代表性、漂移、标注）和建立稳健的错误缓解策略（包括人工在环验证和持续审计），以及增强组织在AI方面的识读能力。", "conclusion": "这些实际考虑具有广泛的应用价值，不仅适用于癌症登记处，也为医疗机构提供了指导，帮助他们在实施AI/NLP解决方案以增强数据管理流程、最终改善患者护理和公共卫生成果方面取得成功。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10497", "html_url": "https://arxiv.org/abs/2508.10497", "title": "使用面向对象编程实现泛化机器人技能", "title_en": "Enabling Generic Robot Skill Implementation Using Object Oriented Programming", "authors": "Abdullah Farrukh,Achim Wagner,Martin Ruskowski", "background": "开发机器人算法并将其子系统整合到更大系统中可能是一项困难的任务，特别是在小型和中型企业（SMEs）中，这些企业的机器人专业知识匮乏的情况下尤其如此。对于这些企业，他们往往依赖外部专家通过系统集成商来实现、维护和发展机器人系统，这可能会导致供应商锁定和对外部依赖的增加。学术研究中的智能化制造系统中，机器人在设计稳健的自主系统方面发挥着关键作用。而对于研究人员来说，如果他们想要将机器人系统作为更大智能系统中的一个组成部分，而无需深入处理机器人接口的复杂性和广泛性，也会面临类似的挑战。针对这些情况，本文提出了一种软件框架，旨在减少部署工作机器人系统的努力。该框架专注于简化现代机器人系统的不同接口，并使用不同的供应商和型号的抽象层。研究目标是基于Yaskawa Motoman GP4构建一个包含箱捡拾单元（bin-picking cell）的系统，并使用Python语言实现这一概念的原型。", "innovation": "本文提出了一种使用面向对象编程（OOP）实现泛化机器人技能的软件框架，该框架简化了现代机器人系统的不同接口，并使用抽象层解决不同制造商和型号的适应性问题。通过使用Python语言实现这一概念的原型，解决在使用机器人系统时面临的复杂性和细节问题，从而在减少开发成本和时间的同时，提供一种可定制和可扩展的解决方案。这种框架的应用不仅可以提高机器人系统在中小企业的普及率，还可以降低公司对系统集成商的依赖。通过这种方法，研究人员和服务人员可以更轻松地集成和使用机器人技能。", "conclusion": "本文采用面向对象编程框架，简化了现代机器人系统的不同接口，并通过Python实现了该概念的原型。实验结果表明，该框架能够有效地简化机器人系统的集成过程，降低了实现自主系统的复杂性。未来的研究可以进一步优化该软件框架，以更好地适应不同机器人模型的应用需求，并提供更具体的实现案例。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.10374", "html_url": "https://arxiv.org/abs/2502.10374", "title": "生物医学基础模型的鲁棒性测试应根据规定进行定制", "title_en": "Robustness tests for biomedical foundation models should tailor to specifications", "authors": "R. Patrick Xian,Noah R. Baker,Tom David,Qiming Cui,A. Jay Holmgren,Stefan Bauer,Madhumita Sushil,Reza Abbasi-Asl", "background": "生物医学领域中基础模型的兴起带来了新的挑战，这些模型具有广泛的用途，但同时也容易受到复杂分布变化的影响。现有的模型测试和授权机制需要改进，以应对这些新型模型的特点。", "innovation": "提出了一种基于任务依赖优先级的鲁棒性测试方法，并建议在预定义的规范中整合细粒度的鲁棒性概念，以指导模型的具体实施。此方法有助于在模型生命周期中标准化鲁棒性评估，并将抽象的AI监管框架与具体的测试程序联系起来。", "conclusion": "此方法有助于在模型开发过程中实现鲁棒性的标准化测试，同时将理论框架与实践操作相结合，为生物医学模型的安全和有效性提供了指导。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.10111", "html_url": "https://arxiv.org/abs/2508.10111", "title": "基于上下文自动生成的差分大语言模型的上下文自由文法受限解码", "title_en": "Constrained Decoding of Diffusion LLMs with Context-Free Grammars", "authors": "Niels Mündler,Jasper Dekoninck,Martin Vechev", "background": "大语言模型（LLMs）在多个领域展现了潜在的应用前景。许多实际应用如代码补全和结构化数据提取需要遵循由形式语言规定的语法规则。但由于LLMs的内在概率性质，其生成的内容不一定符合这些形式语言的要求。现有的受限解码方法通常无法适用于新兴的扩散LLM模型，尤其是在生成正确格式的C++代码或JSON输出时。", "innovation": "本文提出了一种改进方法，首次提出了适用于扩散模型的基于上下文的受限解码方案，该方案可以处理由上下文自由文法（Context-Free Grammar, CFG）捕捉的形式语言。通过将受限解码问题转化为更普遍的加性填充问题，并将其进一步转化为验证目标语言与正则语言的交集是否为空的问题，最终提供了一个高效的算法来解决此类问题，特别适用于上下文自由文法的场景。这种方法在多种应用中，例如C++代码补全和JSON结构化数据提取中，可以实现近乎完美的语法正确性，同时保持或提升功能正确性。此外，通过效率优化确保了计算开销的可接受性是重要的创新点之一。", "conclusion": "实验结果表明，该方法在功能正确的前提下，可以实现接近完美的语法规则正确性，在不同应用上的表现尤为显著，特别是在C++代码补全和JSON结构化数据提取中的应用效果理想，同时实现的各项优化确保了计算效率的实用性。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2408.07321", "html_url": "https://arxiv.org/abs/2408.07321", "title": "VERCATION：基于静态分析和大语言模型的精确开源软件版本识别", "title_en": "VERCATION: Precise Vulnerable Open-source Software Version Identification based on Static Analysis and LLM", "authors": "Yiran Cheng,Ting Zhang,Lwin Khin Shar,Shouguo Yang,Chaopeng Dong,David Lo,Shichao Lv,Zhiqiang Shi,Limin Sun", "background": "开源软件（OSS）由于其协作开发模型和成本效益在近年来变得越来越受欢迎。然而，开发项目中使用特定版本可能会引入安全风险，因为这些版本中包含漏洞。现有的方法通常使用静态分析和预定义规则来分析和提取漏洞补丁中的代码特征，然后使用代码克隆检测来识别这些漏洞版本。这些方法因代码分析中排除了与漏洞无关的部分以及代码克隆检测的不足而限制了其精确度。", "innovation": "本文介绍了VERCATION，这是一种结合程序切片和大语言模型（LLM）来识别C/C++编写的开源软件漏洞版本的方法。VERCATION通过程序切片从漏洞补丁中识别与漏洞相关的代码，然后回溯历史提交以收集已识别的与漏洞相关的代码的先前修改。通过基于扩展和规范化的AST的代码克隆检测比较修改前后的代码差异，定位引入漏洞的提交（vic），从而识别补丁提交和vic之间的漏洞版本。利用包含122个OSS漏洞和1,211个版本的数据集进行评估，VERCATION在F1分数上达到了93.1%，超过了现有最先进的方法，并且在NVD报告中检测到202个错误的漏洞开源软件版本。", "conclusion": "VERCATION的有效性已经通过实验结果证明，它的提出解决了传统方法中由于不相关代码排除和代码克隆检测不足造成的精确度问题，从而提高了开源软件版本识别的精度。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2401.16382", "html_url": "https://arxiv.org/abs/2401.16382", "title": "基于MAPE-K方法在自适应系统中进行架构一致性检查的方法", "title_en": "A MAPE-K-Based Method for Architectural Conformance Checking in Self-Adaptive Systems", "authors": "Daniel San Martín,Guisella Angulo,Valter Vieira de Camargo", "background": "自适应系统（SASs）在关键领域如医疗、金融、自动驾驶和智能城市中被广泛应用。保障这些系统的架构可信性对于维护系统的稳定性和时间上的质量属性至关重要。由于SAS架构本身具有先天的复杂性，已经提出了参考模型如MAPE-K来指导其设计，强调反馈回路作为核心组件。MAPE-K规范了抽象和通信规则，这些规则的维护有助于提高系统的可维护性、可解释性和一致性。然而，维护活动往往会引入偏差，导致架构退化以及与参考模型的合规性丧失。架构一致性检查（ACC）通过验证系统实现是否符合其设计架构（PA）或如MAPE-K这样的参考模型，来解决这一问题。", "innovation": "本文介绍了一种专为SASs设计的基于MAPE-K的定制化架构一致性检查（REMEDY）方法，包含三个关键部分：（i）基于MAPE-K抽象的领域特定语言（DSL）来指定设计架构；（ii）一种工具用于恢复系统的当前架构（CA）；（iii）一个一致性检查过程，用于检测和可视化架构偏差。通过与通用DSL的比较，示范了REMEDY在架构规格化上的更高生产力和精确性，并有效识别和纠正了非一致性问题，从而改善自适应系统的可维护性和架构可信性。", "conclusion": "通过比较与通用DSL的结果，展示了REMEDY在自适应系统的特定DSL方面的更高生产力和精度，并能有效地识别和处理非一致性问题，从而提高自适应系统的可维护性和架构可信性。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.10535", "html_url": "https://arxiv.org/abs/2507.10535", "title": "CodeJudgeBench：评估编码任务中LLM作为裁判的标准", "title_en": "CodeJudgeBench: Benchmarking LLM-as-a-Judge for Coding Tasks", "authors": "Hongchao Jiang,Yiming Chen,Yushi Cao,Hung-yi Lee,Robby T. Tan", "background": "大型语言模型（LLMs）在各种编码任务中的表现已显著提升。除了直接回答用户查询外，LLMs还可以作为裁判，评估和比较其他模型生成的响应的质量。这种评估能力对于不同LLM的基准测试以及提高响应质量的排序具有重要作用。尽管LLM作为裁判的架构正在被广泛应用，但在编码场景中的有效性仍旧未被充分探索，主要是由于缺乏专门的基准测试。为了弥补这一差距，我们引入了CodeJudgeBench，一个专门为评估LLM作为裁判模型在编码任务中的表现设计的基准，涵盖代码生成、代码修复和单元测试生成三项关键任务。", "innovation": "我们设计了CodeJudgeBench作为第一个专门针对编码任务的LLM作为裁判模型的基准测试。通过对26个LLM作为裁判模型的全面基准测试，我们发现最近的思考模型显著优于非思考模型。即使是较小的思考模型，如Qwen3-8B，也能在我们精心设计的代码评判任务中超过70B规模的专门训练模型。但是，所有模型在评判编码任务时依然表现出显著的判断随机性。对于成对评判任务，重新排列响应的顺序将显著影响准确度。此外，当评判不同LLM编写的代码和单元测试时，LLM作为裁判模型的表现也各有差异，这引发了对LLM作为编码场景裁判可靠性和一致性的关注。最后，我们研究了LLM作为裁判的理想提示策略。我们发现，使用成对比较优于单点评判，同时保留完整未处理的LLM响应中的注释和推理有助于提高裁判表现。", "conclusion": "通过CodeJudgeBench的详细评估，我们揭示了LLM作为裁判模型在编码任务中的表现，发现了最近的思考模型显著超越非思考模型的情况，也指出了在评判随机性、任务顺序敏感性以及不同模型差异性上的显著发现。我们的研究提出了更优的提示策略，并表明留有完整未处理的LLM响应中的注释和推理能够改善裁判的性能。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.06762", "html_url": "https://arxiv.org/abs/2507.06762", "title": "使用大型语言模型生成测试进行语义冲突检测", "title_en": "Detecção de Conflitos Semânticos com Testes Gerados por LLM", "authors": "Nathalia Barbosa(1),Paulo Borba(1),Léuson Da Silva(2) ((1) Centro de Informática, Universidade Federal de Pernambuco, Brasil, (2) Polytechnique Montreal, Canadá)", "background": "当开发者在并行合并其他开发者的改动时引入改动，导致原有行为变化时，会引发语义冲突。传统合并工具无法检测这种冲突，于是提出了如SMAT这样的补充工具。SMAT依赖执行单元测试来检测冲突，但如果测试不能有效生成，则会存在大量假阴性结果，限制了其效果。为了改进这个问题，研究者尝试利用大型语言模型（LLMs）生成测试，并将其集成到SMAT中，以提高语义冲突检测的准确性。", "innovation": "研究者提出并集成了一个基于Code Llama 70B的新测试生成工具到SMAT中，探索了不同交互策略、提示内容和参数配置下的模型生成测试能力。实验使用了两个样本，分别是更简单的相关工作中的基准测试和复杂的实际系统样本，以评估新扩展SMAT在检测冲突方面的有效性。研究表明，尽管基于LLM的测试生成在复杂场景下仍然具有挑战性且计算成本高，但有可能改善语义冲突的检测能力，展示了其潜在的价值。", "conclusion": "尽管基于LLM的测试生成面临复杂场景下的挑战和高计算成本，其在提高语义冲突检测方面仍有潜在的价值和改进空间。"}
{"llm_update_time": "20250817", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.21817", "html_url": "https://arxiv.org/abs/2507.21817", "title": "超出分布之外，别无选择：训练于漏洞数据集上的LLM们如何检测Top 25 CWE弱点？", "title_en": "Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?", "authors": "Yikun Li,Ngoc Tan Bui,Ting Zhang,Martin Weyssow,Chengran Yang,Xin Zhou,Jinfeng Jiang,Junkai Chen,Huihui Huang,Huu Hung Nguyen,Chiok Yew Ho,Jie Tan,Ruiyin Li,Yide Yin,Han Wei Ang,Frank Liauw,Eng Lieh Ouh,Lwin Khin Shar,David Lo", "background": "尽管自动漏洞检测取得了显著进展，但在实际应用中的影响仍有限。当前的漏洞数据集存在标签准确性较低（20%-71%不等）、大量重复以及关键CWE类型覆盖不足的问题。这些问题导致模型在自我测试中（通过训练集外的数据进行评估）会因利用虚假关联而非学习真正的漏洞模式而表现出误导性的良好性能。我们分析发现，在独立数据上的模型性能普遍下降，甚至接近随机猜测。对于这些限制，我们提出了一个三步解决方案。首先，我们提出了一个手工标注的测试数据集BenchVul，覆盖MITRE Top 25 Most Dangerous CWEs。其次，构建了一个高质量的训练数据集TitanVul，包含38,863个函数，并使用一个创新的多智能体LLM框架进行去重和验证。最后，我们提出了Realistic Vulnerability Generation（RVG）框架，通过对模拟开发流程中的上下文感知漏洞示例进行合成，来弥补未被充分代表但关键的CWE类型。", "innovation": "我们提出了一个三步解决方案来解决现有漏洞数据集的局限性：(1) 一个手动标注的测试数据集BenchVul，覆盖MITRE Top 25 Most Dangerous CWEs；(2) 一个高质量的训练数据集TitanVul，通过多智能体LLM框架进行去重和验证，包含38,863个函数；(3) Realistic Vulnerability Generation（RVG）框架，用于生成上下文感知的漏洞示例，弥补未充分代表的但关键的CWE类型。", "conclusion": "我们的评估结果显示了每个组件在缩小泛化差距方面的优势。通过BenchVul揭示了自我测试的局限性；通过TitanVul展示了泛化的改进，性能提高11.9%；补充RVG生成的数据带来了进一步的性能提升，提高了模型性能14.0%。"}
