{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23067", "html_url": "https://arxiv.org/abs/2507.23067", "title": "公平推理：平衡MLLMs中的推理与社会偏见", "title_en": "FairReason: Balancing Reasoning and Social Bias in MLLMs", "authors": "Zhenyu Pan,Yutong Zhang,Jianshu Zhang,Haoran Lu,Haozheng Luo,Yuwei Han,Philip S. Yu,Manling Li,Han Liu", "background": "多模态大型语言模型（MLLMs）已经在广泛的任务和模态中达到了最先进的性能。为了进一步提升它们的推理能力，最近的研究探索了高级提示方案和后训练微调。尽管这些技术提高了逻辑准确性，但它们经常使模型的输出带有明显的社会偏见。因此，如何使推理增益与偏见缓解相协调，及其这两种目标是否不可避免地存在权衡，仍然是一个开放且迫切的研究问题。", "innovation": "本文通过基准测试三种偏见缓解策略（监督微调、知识蒸馏和基于规则的强化学习），在相同条件下建立了它们的基础优势和劣势。在此基础上，通过改变每种范式中侧重偏见缓解和集中推理的样本比例，绘制了推理与偏见的权衡关系。研究发现，通过强化学习训练一个大约 1:4 的比例的模型，可以将刻板印象分数降低 10%，同时保持模型原始推理准确性的 88%，从而提供平衡公平性和能力的具体指导。", "conclusion": "研究发现了一致的最佳权衡：使用强化学习训练大约 1:4 的比例能够在降低 10% 刻板印象分数的同时保持原有推理准确性的 88%，为在 MLLMs 中平衡公平性和能力提供了具体的指导性建议。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22951", "html_url": "https://arxiv.org/abs/2507.22951", "title": "统一知识图谱完成后的解释", "title_en": "Unifying Post-hoc Explanations of Knowledge Graph Completions", "authors": "Alessandro Lonardi,Samy Badreddine,Tarek R. Besold,Pablo Sanchez Martin", "background": "现有知识图谱完成（KGC）后的解释缺乏正式化和一致的评估方法，影响了研究的可重复性和跨研究的比较能力。这妨碍了研究人员之间的有效协作与交流。", "innovation": "本文提出了一个通用框架，通过多目标优化来表征KGC后解释，平衡解释的有效性和简洁性，从而统一了现有的KGC后解释方法及其生成的解释，并提出并实证支持了改进的评估协议，采用诸如Mean Reciprocal Rank和Hits@$k$等流行指标。同时，强调了解释的可解释性，即解释能够回答对终端用户有意义的问题的重要性。", "conclusion": "通过统一方法和细化评估标准，本文旨在使KGC解释研究更具有可重复性和影响力。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23330", "html_url": "https://arxiv.org/abs/2507.23330", "title": "AI必须不具备完全自主性", "title_en": "AI Must not be Fully Autonomous", "authors": "Tosin Adewumi,Lama Alkhaled,Florent Imbert,Hui Han,Nudrat Habib,Karl Löwenmark", "background": "自主人工智能具有许多优点，但也伴随着许多风险。该研究指出，自主人工智能可以分为三个级别：第一级是有负责的人类监督的角色；第二级是部分自主，具有部分自我决策能力；第三级是完全自主，能够自主设定目标，不需要人类监督。研究者认为，鉴于推测的人工通用智能(AGI)可能在几十年内就会到来，AI应当避免达到第三级完全没有人类监督的自主性，因为这样存在很多风险。", "innovation": "本文通过探讨自主性理论、AI和代理的相关理论，并列出12个支持观点和6个反观点及其反驳，提供了有力的论据来强调人类监管对于减少自主AI带来的风险的重要性。同时，研究者还提到了15个近期的证据来证明AI存在价值观偏差和其他风险，进一步支持了他们的观点。", "conclusion": "本文作者认为，考虑到潜在的人工智能超级智能带来的多方面风险，应当限制AI的完全自主性，确保始终有人类的监督。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23163", "html_url": "https://arxiv.org/abs/2507.23163", "title": "论辩一致性的判断性预测", "title_en": "Argumentatively Coherent Judgmental Forecasting", "authors": "Deniz Gorur,Antonio Rago,Francesca Toni", "background": "判断性预测利用人类的主观意见来预测未来事件，而不是仅仅依赖于历史数据。当这些意见形成一个论辩结构围绕预测时，从论辩的角度研究这些预测的属性是有用的。本文深入探讨论证一致性这一性质，要求预测者的推理与其预测相一致。研究表明，强制执行这一特性不仅提高了人类预测者的预测准确性，也提升了基于大型语言模型的预测者的准确性。然而，用户并不总是能够理解或遵循这一一致性特性，这指出了在基于论辩的判断性预测中，预先过滤出不一致意见的重要性。", "innovation": "定义并提出了一个论辩一致性这一新特性，即预测者的推理与其预测一致。通过对人类预测者和大型语言模型预测者的研究，验证了这一特性的实际价值。同时通过众包用户实验发现用户并不总是能够遵循这一特性，这为预测领域的发展提供了新的方向。", "conclusion": "强制执行论辩一致性提高了人类和基于大型语言模型的预测准确性，但用户在实际应用中并不总是遵循这一特性。因此，在基于论辩的判断性预测中，需要引入机制以过滤出不一致的意见，以防止对最终的预测结果产生负面影响。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23276", "html_url": "https://arxiv.org/abs/2507.23276", "title": "AI科学家离改变世界还有多远？", "title_en": "How Far Are AI Scientists from Changing the World?", "authors": "Qiujie Xie,Yixuan Weng,Minjun Zhu,Fuchen Shen,Shulin Huang,Zhen Lin,Jiahui Zhou,Zilan Mao,Zijie Yang,Linyi Yang,Jian Wu,Yue Zhang", "background": "大型语言模型（LLMs）的发展推动了自动化科学发现达到新的水平，以LLM为基础的人工智能（AI）科学家系统在科学研究中占据了领先地位。这些系统已经在ICLR 2025会议上发表了由AI生成的研究论文，预示着一种能够揭示人类之前未知现象的人类级别的AI科学家可能很快成为现实。本文综述旨在探讨的一个核心问题是：AI科学家距离改变世界和重塑科学研究范式还有多远？", "innovation": "本文提供了一种前瞻性的综述，全面分析了AI科学家系统的当前成就，指出了关键瓶颈，并确定了能够进行突破性发现的研究机构所需的关键组成部分，解决重大挑战。", "conclusion": "本文旨在促进对当前AI科学家系统的局限性的更清晰理解，展示我们所处的位置、缺失的部分以及科学AI的最终目标，期望为未来的科学研究提供指导。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23018", "html_url": "https://arxiv.org/abs/2507.23018", "title": "大规模科学AI中的数据准备性", "title_en": "Data Readiness for Scientific AI at Scale", "authors": "Wesley Brewer,Patrick Widener,Valentine Anantharaj,Feiyi Wang,Tom Beck,Arjun Shankar,Sarp Oral", "background": "本文探讨了AI数据准备性（DRAI）原则在用于训练基础模型的领导级科学数据集中的应用。背景信息指出，科研领域的大型数据集需要在大规模计算环境中进行预处理，有时会遇到跨领域间的共性问题和特定领域的限制条件。研究通过分析涵盖四个代表性领域的典型流程（气候、核聚变、生物/健康、材料），识别出预处理模式和特定领域限制，为数据准备阶段（数据导入到分割）和数据准备级别（原始数据到AI就绪数据）提供了多层次的理解，并提出了针对高性能计算环境的两个维度框架。该框架强调了在将科研数据转换为可扩展AI训练中的关键挑战，特别关注基于变换器的生成模型。该框架为科研数据准备就绪状况提供了概念上的成熟度矩阵，有助于基础设施开发，推动在跨领域的支持下更好地实现可扩展和可复制性AI在科研中的应用。", "innovation": "本文的创新点包括：开发了一种面向高性能计算环境的两维数据准备性框架，该框架将数据准备分为两个维度：数据准备级别（从原始数据到AI就绪数据）和数据处理阶段（从导入到分割），并特别关注基于变换器的生成模型。此外，本文开发的概念成熟度矩阵能够为科研数据的准备就绪状况提供指导，促进跨领域的标准化支持。", "conclusion": "该研究总结了将科研数据转换为可扩展AI训练时所面临的挑战，并提出了一个概念性成熟度矩阵来描述科研数据的准备就绪情况，这将指导基础设施开发，为提供标准化、跨领域的支持以实现可扩展和可复制性的AI在科学中的应用奠定基础。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23091", "html_url": "https://arxiv.org/abs/2507.23091", "title": "莫拉维克悖论：通往听觉图灵测试的路径", "title_en": "Moravec's Paradox: Towards an Auditory Turing Test", "authors": "David Noever,Forrest McKee", "background": "当前的人工智能系统在人类可以轻松完成的听觉任务上表现出灾难性的失败。文章通过莫拉维克悖论（即人类觉得简单的事情对于机器来说常常很困难，反之亦然）作为灵感，介绍了包含7个分类共917项挑战的听觉图灵测试，揭示了AI系统在处理复杂听觉场景方面的不足，尤其是在选择性注意、噪声鲁棒性和上下文适应等方面存在的问题。这些结果量化了人类与机器在听觉上的差距，并指出当前架构缺乏像人类一样的听觉场景分析的基本机制。传统的音频挑战测试强调了人类进化出但机器难以选择的多模态语言模型中的常见过滤器。", "innovation": "该研究引入了包含7个分类共917项挑战的听觉图灵测试，评估了包括GPT-4的音频能力和OpenAI的Whisper在内的一些最先进的音频模型，结果显示这些模型在处理复杂听觉场景时表现出高达93%的失败率，即使最好的模型在某些任务上的正确率也只有人类成功解决问题概率的13%。这些结果不仅量化了人类与机器在听觉上的差距，还提供了解释这些失败原因的洞见，表明当前的架构缺乏类似人类的听觉场景分析的基本机制。这项工作为评估机器听觉水平的进步建立了一个诊断框架，并强调了将选择性注意、基于物理的音频理解和上下文感知整合到多模态AI系统中的必要性。", "conclusion": "这项研究展示了对于处理复杂听觉场景的不足，提出了新的诊断框架和方法，强调了对多模态AI系统进行改进的需求。这些发现对于未来开发更高级的听觉理解和处理能力的AI系统具有重要意义。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23197", "html_url": "https://arxiv.org/abs/2507.23197", "title": "解决方案感知 vs 全局ReLU选择：部分MILP方法在DNN验证中的反击", "title_en": "Solution-aware vs global ReLU selection: partial MILP strikes back for DNN verification", "authors": "Yuke Liao,Blaise Genest,Kuldeep Meel,Shaan Aryaman", "background": "针对处理复杂的实例，我们重新审视了一种分而治之的方法来简化复杂性。传统的做法是依赖少量复杂的分支定界(BaB)调用，而本文提出的方法则是依赖许多小的局部MILP调用。关键在于选择少数但非常重要的ReLU使用昂贵的二元变量处理。之前的尝试在这一点上并不理想。为了选择这些重要的ReLU变量，本文提出了一个新的解决方案感知ReLU评分（SAS）方法，以及将BaB-SR和BaB-FSB分支函数适应为全局ReLU评分（GS）函数。", "innovation": "提出了一种新的解决方案感知ReLU评分（SAS），以及适应全局ReLU评分的分支函数（GS）。SAS比以前的尝试更加高效，可以降低使用二元变量的数量约6倍，同时保持相同的准确度。SAS和GS方法在理论上和实验中进行了比较，实验结果表明SAS在选择用于开启的变量集方面更加有效。此外，通过在Hybrid MILP中结合α,β-CROWN和部分MILP调用，大大提高了DNN验证的准确性和效率，减少了未决实例的数量，并保持了合理的时间运行，即使对于具有200万参数的大型CNN也是如此。", "conclusion": "SAS在选择变量集方面更加有效，可以减少约6倍的二元变量使用数量，保持相同水平的准确性。通过α,β-CROWN和部分MILP的组合，有效减少了不确定实例的数量，并保持了合理的时间运行，验证了DNN的有效性和效率，即使对于大型CNN也是如此。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23497", "html_url": "https://arxiv.org/abs/2507.23497", "title": "图像分类中因果识别的充分、对比和完整特征集", "title_en": "Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification", "authors": "David A Kelly,Hana Chockler", "background": "现有的图像分类解释算法基于多种方法，且缺乏形式严谨性。逻辑基础的解释虽然形式上定义严格，但其计算依赖于对模型的严格假设，而在实际的图像分类器中并不可行。", "innovation": "本文展示了因果解释不仅形式化严谨，还具备逻辑基础解释的同等形式特性，同时适用于黑盒算法，与图像分类器自然契合。本文证明了因果解释的形式性质，引入了图像分类器的对比因果解释，并扩展了定义，包含信心察觉，提出了完整因果解释：与原图像具有相同分类信心的解释。", "conclusion": "我们的定义已实现，实验结果表明不同模型的充分性、对比性和完整性有不同模式。算法运行效率较高，处理ResNet50模型平均用时6秒，完全黑盒，无需知晓模型细节、内部、梯度或假设其具有单调性等特性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23191", "html_url": "https://arxiv.org/abs/2507.23191", "title": "面向本体介导查询回答的可计算责任度量", "title_en": "Tractable Responsibility Measures for Ontology-Mediated Query Answering", "authors": "Meghyn Bienvenu,Diego Figueira,Pierre Lafourcade", "background": "近年来，定量方法被用于解释查询回答的过程，其中责任度量被用来为事实分配分数，以量化它们对获取特定查询答案的贡献。本文的重点是在本体介导查询回答的背景下研究计算责任得分的复杂性。特别地，论文集中讨论了一种最近定义的基于加权最小支持和（WSMS）的Shapley值为基础的责任度量。通过利用数据库领域的相关结果，论文表明，当查询可以通过一阶逻辑重写时，此类度量具有多项式数据复杂性；然而，如果本体语言可以编码可达性查询时，问题成为“shP-硬”的问题。为了更好地理解可计算性的边界，本文还探讨了WSMS计算的联合复杂性，证明了即使在没有本体的情况下，带有连接查询的原子查询和某些‘良好行为’的联合查询都可能陷入不可计算状态。然而，对于常见的DL-Lite方言，本文的研究取得了积极的结果：通过对结构受限的联合查询的仔细分析，发现了可以实现性计算WSMS的类。这些查询从直观上避免了查询原子之间的不良互动，从而解决了计算复杂性问题。", "innovation": "这篇文章的新颖之处在于，它首次研究了在本体介导查询回答的背景下计算基于加权最小支持和（WSMS）的Shapley值为基础的责任度量的复杂性。通过结合数据库中的结果，它发现了一些查询语言的不同特性对于计算复杂性的影响，并识别出在DL-Lite方言下的结构受限联合查询类，这些类可以在可计算性方面实现WSMS的计算", "conclusion": "本文证明了在某些特定条件下，WSMS的计算是可计算的。具体来说，在没有本体支持连接查询的原子查询和某些‘良好行为’的联合查询的计算是不可计算的，但在DL-Lite方言下的某些查询中，该计算是可处理的。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23336", "html_url": "https://arxiv.org/abs/2507.23336", "title": "DSBC: Data Science task Benchmarking with Context engineering", "title_en": "DSBC : Data Science task Benchmarking with Context engineering", "authors": "Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Giulio Martini,Suman Debnath,Hamza Farooq", "background": "近年来，大规模语言模型（LLMs）在数据分析流程中的应用产生了重要影响，促进了专用数据科学代理的发展，这些代理旨在自动化分析任务。尽管这些代具有快速的采用率，但系统性地评估其有效性和局限性的基准却很少见到。本文通过观察对实际数据科学代理使用情况，建立了全面的基准测试，评估了三款LLM（Claude-4.0-Sonnet, Gemini-2.5-Flash, 和 OpenAI-o4-Mini），并考察了模型的多样性任务表现，包括对常见提示问题（如数据泄露和模糊指令）的敏感性。", "innovation": "本文引入了一种全面的基准测试方法，旨在反映实际用户与数据科学代理之间的互动，并通过观察公司商业应用的使用情况进行了评估。该基准测试不仅考虑了多样化的数据科学任务类别（共八个类别），还探讨了模型在处理常见的提示问题（如数据泄露和模糊指令）时的表现差异。此外，进一步研究了温度参数对每个模型和方法的整体表现和任务特定结果的影响。这揭示了不同模型和方法之间的表现差异，强调了影响实际部署的关键因素。", "conclusion": "研究发现，评估的模型和方法之间存在明显的性能差异，这些差异强调了对更 robust 和有效数据科学代理未来研究的重要性。本文介绍的基准测试数据集和评估框架旨在为基础数据科学代理的研究提供一个框架。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23429", "html_url": "https://arxiv.org/abs/2507.23429", "title": "Chatting with your ERP: A Recipe", "title_en": "Chatting with your ERP: A Recipe", "authors": "Jorge Ruiz Gómez,Lidia Andrés Susinos,Jorge Alamo Olivé,Sonia Rey Osorno,Manuel Luis Gonzalez Hernández", "background": "本文介绍了与工业生产级ERP系统进行对话的大语言模型（LLM）代理的设计、实现与评估。背景在于当前ERP系统通常受制于较复杂的查询语言或固定的API，而代理能够使用户通过自然语言与ERP系统进行互动。", "innovation": "提出了结合推理和批评阶段的新的双代理架构，以提高查询生成的可靠性。利用开放的LLM进行自然语言查询的解析和SQL执行语句的生成。", "conclusion": "研究结果表明，通过这种新型代理架构，用户的查询能够更可靠地转化为ERP系统可执行的SQL语句，显著提高了ERP系统的用户友好性和交互效率。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23377", "html_url": "https://arxiv.org/abs/2507.23377", "title": "LLM4Rail: 一种基于大语言模型的铁路服务咨询平台", "title_en": "LLM4Rail: An LLM-Augmented Railway Service Consulting Platform", "authors": "Zhuo Li,Xianghuai Deng,Chiwei Feng,Hanmeng Li,Shenjie Wang,Haichao Zhang,Teng Jia,Conlin Chen,Louis Linchun Wu,Jia Wang", "background": "大语言模型（LLMs）已经显著地重塑了各个领域的商业活动。为了满足日益增长的个性化铁路服务需求，该研究开发了一款名为LLM4Rail的新颖平台，这是一种基于大语言模型增强的铁路服务咨询平台。LLM4Rail能够提供定制化的票务服务、铁路餐饮推荐、天气信息和闲聊功能。该平台还提出了一种迭代的“问题-思考-行动-观察（QTAO）”提示框架。通过这一框架，将口头推理与任务导向的动作相结合，指导行为选择并有效检索与铁路运营和服务相关的外部观察，以生成精确的回应。", "innovation": "该研究创新性地开发了LLM4Rail——一个基于大语言模型的铁路服务咨询平台，平台提供了定制化的票务服务、餐饮推荐、天气信息和闲聊功能。提出了迭代的“问题-思考-行动-观察（QTAO）”提示框架，结合口头推理与任务导向的动作指导，确保了相关观测信息的有效检索和准确回应。此外，构建了面向铁路服务的公共可用外卖数据集CRFD-25，并引入基于大语言模型的零样本对话推荐系统，以应对开放式推荐中的约束问题，确保所有推荐项目与CRFD-25数据集相一致，改善了铁路餐饮服务的个性化水平。", "conclusion": "该研究通过引入大语言模型及其定制框架，能够提供高度精准和个性化的铁路服务，极大提升了乘客的旅行体验，并能够在实际运营中应用以优化铁路服务和客诉处理。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23440", "html_url": "https://arxiv.org/abs/2507.23440", "title": "Self-Foveate: 通过多级核心化增强从无监督文本合成指令的多样性和难度", "title_en": "Self-Foveate: Enhancing Diversity and Difficulty of Synthesized Instructions from Unsupervised Text via Multi-Level Foveation", "authors": "Mingzhe Li,Xin Lu,Yanyan Zhao", "background": "大语言模型（LLMs）具备指令跟随能力，在问题解决方面表现出了令人印象深刻的能力。传统的合成指令方法依赖大量的人工标注来构建训练数据集，而现有的自动化合成模式虽然减轻了这一负担，但在确保合成指令的多样性和难度上仍然存在不足。", "innovation": "Self-Foveate 提出了一种 LLM 驱动的多级核心化方法，引入了“微-散-宏”多级核心化技术，以有效引导 LLM 深入挖掘无监督文本中嵌入的细微信息，从而提高合成指令的多样性和难度。", "conclusion": "通过对多个无监督语料库和不同模型架构进行全面实验，Self-Foveate 的方法被验证为效果良好且具有优越性。论文公开了数据集和代码：this https://example.com."}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23664", "html_url": "https://arxiv.org/abs/2507.23664", "title": "个性化排名对齐推荐在教育中的应用", "title_en": "Personalized Education with Ranking Alignment Recommendation", "authors": "Haipeng Liu,Yuxuan Liu,Ting Long", "background": "个性化问题推荐旨在通过引导学生完成特定问题来增强他们对学习目标的理解。多数前期方法将此任务建模为马尔可夫决策过程，通过强化学习解决，但这些方法在有效的探索方面存在困难，无法在训练中准确识别适合每个学生的最佳问题。", "innovation": "本文提出了一种名为Ranking Alignment Recommendation (RAR)的新方法，它通过引入合作原则改进探索机制，使在有限的训练周期内进行更高效的探索成为可能。", "conclusion": "实验证明，RAR能有效提高推荐性能，并且该框架可以应用于任何基于强化学习的问题推荐系统。相关内容的代码已发布，详见此链接：this https URL."}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23773", "html_url": "https://arxiv.org/abs/2507.23773", "title": "SimuRA：基于LLM的世界模型仿真实理推理架构走向通用目的代理", "title_en": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model", "authors": "Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing", "background": "当前基于大型语言模型（LLMs）的AI代理研究主要采用一任务一代理的方法，这种方式在扩展性和普遍性上存在局限，并受到自回归LLMs在推理上的基本限制。人类能够通过心理模拟其行为和计划的结果而成为通用高效的代理。因此，本文探讨了一种新的方法，即基于世界模型的仿真实理推理架构——SimuRA，提出了一种通用代理的架构，能够通过模拟规划来优化代理的策略。", "innovation": "SimuRA利用基于LLM的世界模型进行规划，通过模拟实现对不同环境的灵活规划。这种方法相比传统的自回归推理具有优势，在复杂的网络浏览任务中，SimuRA的飞行搜索成功率提高了32.2%，尤其是基于世界模型的规划在性能上优势显著，比自回归规划高出124%。", "conclusion": "基于LLM的单个通用代理模型具有在所有环境中表现出超智能行为的潜力。本文通过研究和开发SimuRA展示了这种方法的可能性。作为初步尝试，一种基于SimuRA的预训练LLM构建的网络浏览代理已经提供给公众作为研究演示。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23565", "html_url": "https://arxiv.org/abs/2507.23565", "title": "基于超图辅助自主AI的语义链信任：协作伙伴选择的自主信任编排", "title_en": "Semantic Chain-of-Trust: Autonomous Trust Orchestration for Collaborator Selection via Hypergraph-Aided Agentic AI", "authors": "Botao Zhu,Xianbin Wang,Dusit Niyato", "background": "在协作系统中，任务的高效完成依赖于对潜在设备的信任评估，这些设备将进行分布式协作。然而，任务复杂性、分布式设备资源的时空动态性以及不可避免的评估开销显著增加了信任评估过程的复杂性和资源消耗。这可能导致不及时或过于频繁的信任评估，从而减少了受限资源的利用效率，对协作任务执行产生负面影响。", "innovation": "本文提出了一种基于新概念的语义链信任的自主信任编排方法。该方法利用代理型人工智能（agentic AI）和超图（hypergraph）来建立和维护设备之间的信任关系。代理型AI具备自主感知、任务分解和语义推理的优势，在设备空闲期间仅基于历史性能数据自主进行信任评估，从而有效利用分散资源。此外，代理型AI基于资源能力与任务需求之间的匹配度执行特定任务的信任评估。通过维护嵌入信任语义的超图来管理协作伙伴，并基于信任语义识别需要信任评估的协作伙伴，以权衡开销和信任准确率。此外，多个设备的局部信任超图可以链式连接以支持多跳协作，从而在大规模系统中实现高效协调。", "conclusion": "实验结果表明，所提出的信任评估方法实现了资源高效的信任评估。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23633", "html_url": "https://arxiv.org/abs/2507.23633", "title": "MemoCue: 通过策略引导查询增强基于LLM的代理在人类记忆回忆中的能力", "title_en": "MemoCue: Empowering LLM-Based Agents for Human Memory Recall via Strategy-Guided Querying", "authors": "Qian Zhao,Zhuo Sun,Bin Guo,Zhiwen Yu", "background": "在人机交互领域，代理辅助的记忆回收是一项关键研究问题。传统的代理可以利用自装载的内存模块来辅助人类回忆不完整或模糊的记忆，但内存模块的限制影响了实际的记忆召回性能。为了弥补这一不足，研究者们借鉴记忆理论，提出通过有效提示促进相关记忆的主动激活。然而，选择合适的召回策略以及生成高质量的响应是挑战性的。", "innovation": "本文提出了一个名为Recall Router的框架，该框架包括一个5W召回地图，用于将记忆查询分类为五种典型场景，并定义了十五种相应的召回策略模式。随后，通过结合蒙特卡洛树搜索算法的层次召回树优化策略选择和响应生成。此外，通过构建指令调优数据集并微调多个开源大型语言模型（LLMs），开发了MemoCue代理，该代理能够在记忆启发式响应方面表现出色。实验结果表明，MemoCue在召回灵感方面超越了基于LLM的方法，提高了17.74%。", "conclusion": "MemoCue通过策略引导查询成功地改进了基于LLM的代理在人类记忆回忆任务上的表现。该工作为开发更高效的记忆辅助系统奠定了基础，并展示了在人机交互中的潜在应用价值。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23488", "html_url": "https://arxiv.org/abs/2507.23488", "title": "因果推理的拼图：模块化上下文学习在因果发现中的应用", "title_en": "Causal Reasoning in Pieces: Modular In-Context Learning for Causal Discovery", "authors": "Kacper Kadziolka,Saber Salehkaleybar", "background": "因果推理仍然是大型语言模型的基本挑战。最近内部推理的进步激发了人们关注最先进的推理模型是否能可靠地执行因果发现任务——一项传统模型在数据扰动下常常遭受严重过拟合和随机性能的挑战。为此，该研究在Corr2Cause基准上研究因果发现，使用新兴的OpenAI o系列和DeepSeek-R模型家族进行探讨。", "innovation": "研究引入了一种基于Tree-of-Thoughts和Chain-of-Thoughts方法的模块化上下文管道，该管道对传统基线的改进几乎达到了三倍。此外，研究通过分析推理链的长度、复杂性，并进行传统的推理模型之间的定性和定量比较，进一步探究了管道的影响。", "conclusion": "尽管高级推理模型代表了巨大进步，但精心结构的上下文框架对于最大化其能力至关重要，并提供了因果发现跨不同领域的通用蓝图。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23751", "html_url": "https://arxiv.org/abs/2507.23751", "title": "CoT-Self-Instruct: 构建用于推理和非推理任务的高质量合成提示", "title_en": "CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks", "authors": "Ping Yu,Jack Lanchantin,Tianlu Wang,Weizhe Yuan,Olga Golovneva,Ilia Kulikov,Sainbayar Sukhbaatar,Jason Weston,Jing Xu", "background": "现有的合成数据生成方法主要依赖于直接仿照和生成现有数据集的样本，这种方法在处理需要复杂推理和计算能力的问题时表现不佳。现有的训练数据集如s1k和OpenMathReasoning在处理诸如MATH500、AMC23、AIME24和GPQA-Diamond等数学问题时表现平平，无法有效提高模型在这些任务上的性能。此外，传统的自我指令方法（如AlpacaEval 2.0和Arena-Hard）在非验证性指令跟随任务表现也存在局限性。因此，需要一种新型的方法来生成更高质量的合成数据，能够有效支持复杂推理任务并解决非验证性指令跟随任务中的挑战。", "innovation": "提出了CoT-Self-Instruct方法，该方法首先通过链式思考（CoT）指导大模型进行推理和规划，然后生成高质量、复杂度相似的新合成提示用于模型训练。通过自动指标过滤高质量数据，进一步提高生成数据集的质量。该方法在可验证的推理任务上显著优于现有的训练数据集，同时在非验证性的指令跟随任务上也表现出色，超越了人类或标准自我指令的方法。这种方法为构建复杂推理模型提供了新的途径。", "conclusion": "CoT-Self-Instruct方法在多种推理和非验证性指令跟随任务上表现优异，显著提升了模型在这类任务上的性能。该方法通过合理的链式思考和高质量的合成数据生成，为提高模型处理复杂推理任务的能力提供了有效解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23701", "html_url": "https://arxiv.org/abs/2507.23701", "title": "TextQuests：LLM在文字冒险游戏中的表现如何？", "title_en": "TextQuests: How Good are LLMs at Text-Based Video Games?", "authors": "Long Phan,Mantas Mazeika,Andy Zou,Dan Hendrycks", "background": "评估AI代理在复杂、互动环境中的表现对于理解其实际能力至关重要。现有的代理基准可以有效评估技能如工具使用或结构化任务的表现，但往往未能全面捕捉代理在探索性环境中的能力，这些环境需要长时间自我驱动的推理和理解。为了促进具备更强大的长期内在推理能力的代理的发展，本文引入了TextQuests基准，基于Infocom套件的互动文学游戏。这些基于文本的冒险游戏可以供人类玩家游玩超过30小时并要求数百次精确操作来解决，因此被用作评估AI代理有效代理，专注于需要逐步学习和持续解决问题的探索性环境中执行特定、有状态任务的能力。", "innovation": "文本中提出的TextQuests基准基于Infocom系列的互动文学游戏，旨在评估大型语言模型代理的长期内在推理能力。此基准通过禁止使用外部工具来评估代理的自我封闭问题解决能力，重点关注单个互动会话中需要尝试错误学习和持续问题解决的探索性环境中固有的长上下文推理能力。", "conclusion": "论文提出了一种新的基准TextQuests，期望推动能够进行更长期内在推理的代理的发展。该基准通过限制使用外部工具，专注考量代理在需要长时间自我驱动推理和解决复杂问题的环境中进行自我封闭问题解决的能力。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22896", "html_url": "https://arxiv.org/abs/2507.22896", "title": "iLearnRobot：一种持续改进的交互式多模态机器人", "title_en": "iLearnRobot: An Interactive Learning-Based Multi-Modal Robot with Continuous Improvement", "authors": "Kohou Wang,ZhaoXiang Liu,Lin Bai,Kun Fan,Xiang Liu,Huan Hu,Kai Wang,Shiguo Lian", "background": "机器人在部署后需要不断改进性能，因为它们极有可能遇到未见过的新场景。当前主流的多模态大型语言模型（MLLM）驱动的机器人系统无法很好地处理这种挑战。", "innovation": "提出了一种基于多模态大型语言模型（MLLM）的交互式学习机器人系统。该系统能够通过与非专家用户的自然对话进行学习，并通过提出一系列问题来明确问题意图，从而避免重复错误。此外，系统还配备了双模态检索模块，利用交互事件，确保用户体验的无缝连接，这与现有的主流MLLM驱动的机器人系统不同。", "conclusion": "通过实验，本文展示了方法的有效性和改进。该系统的交互学习方法为机器人在不同环境中的更高适应性和性能打下了基础。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22900", "html_url": "https://arxiv.org/abs/2507.22900", "title": "工具还是麻烦？探索学生对AI编程助手的态度", "title_en": "Tool or Trouble? Exploring Student Attitudes Toward AI Coding Assistants", "authors": "Sergio Rojas-Galeano", "background": "本研究通过对入门级编程课程中两部分编程考试的研究，探讨了AI代码助手如何影响新手程序员的体验。第一部分允许学生使用AI支持完成编程任务，第二部分则不允许使用AI支持，需要学生独立完成。研究人员收集了20名学生的层级量表和开放式反馈来评估他们的感知和遇到的挑战。", "innovation": "本研究创新之处在于通过两阶段编程考试设计，观察学生在有无AI辅助环境中的表现差异，借此分析AI工具如何影响编程新手的认知过程和技能发展。", "conclusion": "研究发现，AI工具被认为有助于理解代码和提高信心，特别是在初始开发阶段。然而，学生也报告了在没有辅助的任务中知识难以迁移的问题，揭示了可能过高的依赖性和概念理解的缺陷。研究结果强调了需要通过课程设计整合AI技术，同时强化基础编程技能的必要性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.21813", "html_url": "https://arxiv.org/abs/2503.21813", "title": "OAEI-LLM-T: 一个理解和评估大型语言模型在本体匹配中幻觉的TBox基准数据集", "title_en": "OAEI-LLM-T: A TBox Benchmark Dataset for Understanding Large Language Model Hallucinations in Ontology Matching", "authors": "Zhangcheng Qiang,Kerry Taylor,Weiqing Wang,Jing Jiang", "background": "大型语言模型（LLM）在下游任务中常出现幻觉现象，这对于基于LLM的本体匹配（OM）系统是一个重大挑战。现有评估框架如Ontology Alignment Evaluation Initiative（OAEI）中提供的数据集无法有效捕捉和分类LLM在本体匹配任务中的幻觉现象，导致难以精确评估和改进LLM在本体匹配中的表现。因此，需要一个新的基准数据集来专门针对本体匹配任务中LLM的幻觉问题进行研究和评估，以优化和提升其性能和准确性。", "innovation": "该研究提出了一个新的基准数据集OAEI-LLM-T，该数据集源于OAEI中的七个TBox数据集，并由十个不同LLM执行本体匹配任务时产生的幻觉现象组成。这些幻象被分类为两类主要类别以及六个子类别，这对构建专门针对本体匹配的LLM排行榜和优化LLM用于本体匹配的任务具有重要意义。数据集的创建为研究LLM在本体匹配任务中的幻觉性质提供了新的工具，有助于精确理解和评估这些问题，促进了LLM在本体匹配领域的应用和发展。", "conclusion": "OAEI-LLM-T数据集是评估和改进LLM在本体匹配任务中幻觉现象性能的关键工具，有助于优化LLM在本体匹配中的使用，提升其在该领域的整体性能。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22890", "html_url": "https://arxiv.org/abs/2507.22890", "title": "评估大型语言模型在生成与理解可视化方面的表现", "title_en": "Evaluating LLMs for Visualization Generation and Understanding", "authors": "Saadiq Rauf Khan,Vinit Chandak,Sougata Mukherjea", "background": "信息可视化已被利用来从复杂数据中提取洞察。近年来，大型语言模型（LLMs）在多项任务中表现出色。本文展示了不同流行的LLMs根据简单的提示生成基于可视化代码的能力，并分析了LLMs理解一些常见可视化的能力。", "innovation": "本文的创新在于利用LLMs生成基于简单提示的可视化代码，并分析LLMs在回答一些关于可视化的问题时的能力。", "conclusion": "我们的研究表明，LLMs能够生成一些简单的可视化，如条形图和饼图的代码，并能够回答一些关于可视化的简单问题。然而，LLMs也存在一些局限性，例如在生成复杂可视化如小提琴图时遇到困难，并且在回答一些关于可视化的复杂问题时也犯错误。我们认为这些见解可以用来改进LLMs和信息可视化系统。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23554", "html_url": "https://arxiv.org/abs/2507.23554", "title": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "title_en": "DICE: Dynamic In-Context Example Selection in LLM Agents via Efficient Knowledge Transfer", "authors": "Ruoyu Wang,Junda Wu,Yu Xia,Tong Yu,Ryan A. Rossi,Julian McAuley,Lina Yao", "background": "基于大语言模型的大规模智能体，通过情境学习（ICL）展现出了在复杂推理和工具使用任务中的强大能力。然而，现有的研究表明，ICL 的效果高度依赖于演示样本的选择，缺乏有效的选择标准。先前的工作虽然探索了示例选择，特别是在一些代理或多步骤的设置中，但现有的方法通常依赖于启发式或任务特定的设计，无法提供一个一贯适用于所有推理步骤的通用、理论依据的方法。", "innovation": "本文提出了 DICE (Dynamic In-Context Example Selection for LLM Agents)，这是一个基于因果视角的理论上可靠的 ICL 框架，能够在每个推理步骤中选择最相关的演示。DICE 将演示知识分解为可转移和不可转移部分，并提出了一种具有改善代理性能的形式保证的逐步选择标准。DICE 是一个通用的、不依赖于特定框架的解决方案，可以在不增加额外培训成本的情况下集成到现有的代理框架中。实验表明，DICE 的方法在多个领域中表现出卓越的效果和泛化能力，突显了在鲁棒和高效的 LLM 前景下，原理性、情境感知的示例选择的重要性。", "conclusion": "本文的方法在不同领域中展示了其效果和普适性，强调了对大语言模型代理进行原理性、情境认知的示例选择的重要性，从而确保鲁棒性和高效性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22902", "html_url": "https://arxiv.org/abs/2507.22902", "title": "向自主人工智能医生迈进：多智能体自主人工智能在真实世界临床环境中与认证医生的定量基准评估", "title_en": "Toward the Autonomous AI Doctor: Quantitative Benchmarking of an Autonomous Agentic AI Versus Board-Certified Clinicians in a Real World Setting", "authors": "Hashim Hayat,Maksim Kudrautsau,Evgeniy Makarov,Vlad Melnichenko,Tim Tsykunou,Piotr Varaksin,Matt Pavelle,Adam Z. Oskowitz", "background": "全球预计到2030年将出现1100万医疗人员短缺，临床工作中行政负担占据了50%的工作时间。人工智能（AI）有潜力缓解这些问题。然而，尚未有基于大型语言模型（LLM）的端到端自主AI系统在真实临床环境中进行严格评估。本文研究了多智能体LLM基础AI框架能否在虚拟急诊环境中自主作为AI医生运行。", "innovation": "本文首次在真实世界临床环境中，对多智能体AI系统Doctronic与认证临床医生的表现进行了对比评估，展示了多智能体AI系统的诊断和治疗计划与人类医生一致的结果，且在某些情况下AI表现甚至优于临床医生，显示了多智能体AI系统在处理实际临床问题中的潜力，可能解决医疗人力短缺问题。", "conclusion": "在首次大规模验证自主AI医生中，本研究展示了多智能体AI系统在临床诊断和治疗计划与人类医生高度一致的结果，AI表现匹配甚至超过了实际临床医生。这表明多智能体AI系统在临床决策制定方面可与人类提供者相当，并可能成为解决医疗人员短缺问题的解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22911", "html_url": "https://arxiv.org/abs/2507.22911", "title": "ElectriQ：电力营销场景下大型语言模型响应能力评估基准", "title_en": "ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing", "authors": "Jinzhi Wang,Qingke Peng,Haozhou Li,Zeyuan Zeng,Qinfeng Song,Kaixuan Yang,Jiangbo Zhang,Yaoying Wang,Ruimeng Li,Biyi Zhou", "background": "电力市场营销客户的客户服务在处理咨询、投诉和服务请求方面起着关键作用。然而，目前的系统，如中国的95598热线，经常面临响应速度慢、程序不够灵活以及在特定领域的准确性有限的问题。虽然像GPT-4o和Claude 3这样的大规模语言模型（LLMs）展示了强大的通用能力，但它们缺乏该领域的专业知识和同情心。", "innovation": "为了解决这个问题，我们介绍了ElectriQ，它是第一个旨在评估和提升LLMs在电力营销场景中的基准。ElectriQ包括涵盖六个主要服务类别的对话数据集，并引入了四个评估指标：专业性、受欢迎程度、易读性和用户友好性。我们还引入了一个领域特定知识库，并提出了知识增强方法以提高模型性能。实验结果表明，经过微调和增强的较小模型，如LLama3-8B，在专业性和用户友好性方面可以超越GPT-4o。", "conclusion": "ElectriQ为开发符合电力营销服务需求的LLMs奠定了全面的基础。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22893", "html_url": "https://arxiv.org/abs/2507.22893", "title": "无形的思考建筑：迈向AI作为认知基础设施的新科学", "title_en": "Invisible Architectures of Thought: Toward a New Science of AI as Cognitive Infrastructure", "authors": "Giuseppe Riva", "background": "当前的人机交互研究忽视了AI系统如何在潜意识中重塑人类认知这一关键环节，这对理解分布式认知构成了重要盲区。本文旨在重新概念化AI作为‘认知基础设施’：这些基础、经常隐形的系统决定了在数字化社会中可认知和可行动的内容。这些语义基础设施运输意义，通过前瞻性个性化运作，并表现出适应性的隐形性，使其影响力难以察觉。重要的是，它们自动执行“相关性判断”，将“知识主体性”的位置转移至非人类系统。通过涵盖个体（认知依赖性）、集体（民主协商）和社会（治理）三个层面的叙事情景，本文描述了认知基础设施如何重塑人类认知、公共推理和社交知识论。该领域旨在解决AI预处理如何重塑跨越个体、集体和文化层面的分布式认知，需要各个学科的前所未有的综合研究方法。同时，该框架还填补了跨学科的关键空白：认知科学缺乏大规模预处理分析的能力，数字社会学无法触及个体认知机制，而计算方法未能捕捉文化传承动态。为了达成这一目标，该领域还提供了研究无形算法影响的方法创新：基础设施中断方法，通过系统地在习惯化期间撤销AI预处理来揭示认知依赖性。", "innovation": "该研究领域提出了‘认知基础设施研究’（CIS），将AI重新概念化为认知基础设施，即基础、经常隐形的系统，决定了数字化社会中的可知和可行动内容。提出了‘基础设施中断方法’，通过系统地在习惯化期间撤销AI预处理来揭示认知依赖性。填补了认知科学、数字社会学和计算方法在大规模预处理分析、个体认知机制和文化传承动态方面的空白，要求各学科实现前所未有的综合研究方法。", "conclusion": "CIS框架通过解释AI如何在个体、集体和社会层面重塑认知与知识论，为跨学科研究提供了新的视角。该框架创新地提出了利用基础设施中断方法研究隐蔽算法影响的方法，强调学科之间的协作和新的研究方法对于理解分布式认知的重要性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23726", "html_url": "https://arxiv.org/abs/2507.23726", "title": "Seed-Prover: 自动定理证明中的深度和广度推理", "title_en": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving", "authors": "Luoxin Chen,Jinming Gu,Liankai Huang,Wenhao Huang,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Kaijing Ma,Cheng Ren,Jiawei Shen,Wenlei Shi,Tong Sun,He Sun,Jiahui Wang,Siran Wang,Zhihong Wang,Chenrui Wei,Shufa Wei,Yonghui Wu,Yuchen Wu,Yihang Xia,Huajian Xin,Fan Yang,Huaiyuan Ying,Hongyi Yuan,Zheng Yuan,Tianyang Zhan,Chi Zhang,Yue Zhang,Ge Zhang,Tianyun Zhao,Jianqiu Zhao,Yichi Zhou,Thomas Hanwen Zhu", "background": "大规模语言模型（LLMs）已经展示了通过长链推理学习强化学习的强大数学推理能力。然而，LLMs 在定理证明方面仍然表现不佳，因为仅使用自然语言时缺乏明确的监督信号。而专用领域特定语言，如 Lean，通过形式验证证明提供了明确的监督，使得通过强化学习的有效训练成为可能。", "innovation": "本文提出了 Seed-Prover，这是一种公理风格的整体证明推理模型。Seed-Prover 能够根据 Lean 反馈、证明的引理和自我总结迭代细化其证明。为了应对 IMO 级别的竞赛问题，我们设计了三种推理策略，支持深度和广度推理。此外，为了克服 Lean 在几何学支持方面的局限性，我们引入了一种几何推理引擎 Seed-Geometry，该引擎优于之前的正式几何引擎。", "conclusion": "Seed-Prover 在证明形式化的过去 IMO 问题方面达到 78.1%，在 MiniF2F 和 PutnamBench 上分别取得超过 50% 的成绩，超过了此前的最好水平。引入 Seed-Geometry 后，两个系统在 IMO 2025 上彻底解决了 6 个问题中的 5 个，这项工作标志着自动数学推理的重大进步，展示了带有长链推理的正式验证的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22910", "html_url": "https://arxiv.org/abs/2507.22910", "title": "旅行领域中的大型语言模型：一项工业经验", "title_en": "Large Language Models in the Travel Domain: An Industrial Experience", "authors": "Sergio Di Meglio,Aniello Somma,Luigi Libero Lucio Starace,Fabio Scippacercola,Giancarlo Sperlì,Sergio Di Martino", "background": "在线房产预订平台依赖于房间设施的最新、一致信息，这些信息通常来自第三方提供商。然而，这些外部数据源经常包含不完整或不一致的细节，这会令用户不满意并导致市场份额损失。为此，本文介绍了一项工业案例研究，涉及将大型语言模型（LLMs）整合到FERVENTO开发的CALIDEHOTELS预订平台上，以应对这些挑战。", "innovation": "研究在旅行领域中将大型语言模型应用于预订平台上，并评估了两种众所周知的LLM模型：使用QLoRA微调的Mistral 7B和使用优化系统提示的Mixtral 8x7B。最终，Mixtral 8x7B在完整性、精确性和幻觉率方面表现更优，但也伴随着更高的计算成本。这为在生产环境中部署LLMs提供了实际洞见，展示了其提高住宿数据一致性和可靠性方面的有效性。", "conclusion": "研究提供了关于模型质量和资源效率之间权衡的实用见解，为部署LLMs在生产环境中提供了指导，并展示了它们在提高住宿数据的一致性和可靠性方面的重要作用。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22908", "html_url": "https://arxiv.org/abs/2507.22908", "title": "一种结合混合量子增强学习的隐私保护联邦框架用于金融欺诈检测", "title_en": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection", "authors": "Abhishek Sawaika,Swetang Krishna,Tushar Tomar,Durga Pritam Suggisetti,Aditi Lal,Tanmaya Shrivastav,Nouhaila Innan,Muhammad Shafique", "background": "数字交易的快速增长引发了欺诈活动的激增，传统金融领域的欺诈检测方法面临着巨大挑战。", "innovation": "本文提出了一种专门的联邦学习框架，该框架将量子增强的长短期记忆（LSTM）模型与先进的隐私保护技术相结合。该方法通过在LSTM结构中嵌入量子层，有效地捕捉复杂的跨交易模式，并在关键评估指标上相比传统模型大约提高5%的性能。此外，该框架中的“FedRansel”方法能够防御投毒和推理攻击，与其他标准差分隐私机制相比，可以减少4-8%的模型退化和推理准确性。", "conclusion": "伪中心化的设置和量子LSTM模型增强了欺诈检测的准确性，同时确保了敏感的金融数据的安全性和保密性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22904", "html_url": "https://arxiv.org/abs/2507.22904", "title": "SketchMind：一种评估学生成画科学草图的多智能体认知框架", "title_en": "SketchMind: A Multi-Agent Cognitive Framework for Assessing Student-Drawn Scientific Sketches", "authors": "Ehsan Latif,Zirak Khan,Xiaoming Zhai", "background": "科学草图（例如模型）为学生概念理解提供了强有力的视角，然而使用AI赋能的自动评估这些自由形式、视觉多样性的作品仍然是一项重要的挑战。现有的解决方案往往将绘图评估视为图像分类任务或单一的视觉-语言模型，缺乏可解释性、课程标准对齐和跨认知水平的适应性。", "innovation": "我们提出SketchMind，一种基于认知的多智能体框架，用于评估和改进学生绘制的科学草图。SketchMind包括模块化的代理，负责规则解析、草图感知、认知对齐以及带有草图修改的迭代反馈，从而实现个性化和透明的评估。多智能体协同与SRG集成提高了SketchMind的性能。GHz-4.1 的图预测准确率平均提高了8.9%，优于单智能体管道的表现。", "conclusion": "与没有SRG集成的基线GPT-4o相比，SRG集成的SketchMind在所有项目的图预测准确率平均提高了21.4%，评分者对SketchMind与GPT-4.1生成的反馈和共创新的草图评价达到了4.1/5，而基线模型仅为2.3。专家们认为系统有望通过引导式修订来有效支持概念发展。我们的代码和（待审批）数据集即将发布，以支持重复性和未来基于AI的教育研究。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22912", "html_url": "https://arxiv.org/abs/2507.22912", "title": "一种驱动语言模型的半监督集成框架，用于检测跨暗网和社交平台的非法市场", "title_en": "A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms", "authors": "Navid Yazdanjue,Morteza Rakhshaninejad,Hossein Yazdanjouei,Mohammad Sadegh Khorshidi,Mikko S. Niemela,Fang Chen,Amir H. Gandomi", "background": "非法市场越来越转向互联网的隐蔽部分，包括深网和暗网，以及如Telegram、Reddit和Pastebin等平台。这些渠道使非法商品，如毒品、武器和被盗凭证的匿名交易成为可能。但由于标注数据有限、非法语言变化以及在线源结构异质性，检测和分类此类内容仍然具有挑战性。", "innovation": "本文提出了一种分层分类框架，该框架结合了微调语言模型和半监督集成学习策略，以检测并分类跨多种平台的非法市场内容。使用ModernBERT模型和手动工程特征，该框架能够准确地检测销售相关的文档，并进一步将这些文档分类为毒品、武器或凭证销售。实验结果表明，该模型在性能上优于BERT、ModernBERT、DarkBERT、ALBERT、Longformer和BigBird等基准模型。", "conclusion": "实验结果显示，该模型在多源语料库、DUTA和CoDA数据集上的准确率为0.96489，F1分数为0.93467，TMCC为0.95388，证明其在半监督环境下的泛化能力强，具有强大的鲁棒性和高效的实际非法内容检测效果。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22897", "html_url": "https://arxiv.org/abs/2507.22897", "title": "RecUserSim: 一种用于评估对话推荐系统的现实且多样的用户模拟器", "title_en": "RecUserSim: A Realistic and Diverse User Simulator for Evaluating Conversational Recommender Systems", "authors": "Luyu Chen,Quanyu Dai,Zeyu Zhang,Xueyang Feng,Mingyu Zhang,Pengcheng Tang,Xu Chen,Yue Zhu,Zhenhua Dong", "background": "对话推荐系统（CRS）通过多轮交互提升用户体验，但其评估仍具挑战性。传统的用户模拟器可以通过与CRS交互提供全面评估，但建立现实且多样化模拟器困难重重。尽管近期工作利用大型语言模型（LLMs）模拟用户交互，但在重现多样化场景中个人真实用户行为方面仍有欠缺，缺乏定量评估机制。", "innovation": "提出了一种LLM代理用户模拟器RecUserSim，增强了模拟现实性和多样性，提供明确评分。RecUserSim包括：用于定义现实且多样的用户人设的模块，跟踪交互历史、发现未知偏好；基于有理性理论的核心行动模块，实现细腻决策和个性化响应；增强输出控制的细化模块。", "conclusion": "实验表明RecUserSim产生多样化可控输出，生成现实且高质量对话，即使使用小型基底LLM也能实现。RecUserSim生成的评分在不同基底LLM间表现出高度一致性，突显其在CRS评估方面的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22915", "html_url": "https://arxiv.org/abs/2507.22915", "title": "在大规模语言模型中的幻觉的理论基础及其缓解", "title_en": "Theoretical Foundations and Mitigation of Hallucination in Large Language Models", "authors": "Esmail Gumaan", "background": "大规模语言模型(LLMs)生成的内容有时与输入或现实世界事实不符，这被称为幻觉。尽管幻觉现象存在已久，但对这一问题的研究缺乏全面和系统的理论框架。本文旨在为幻觉提供严谨的理论分析，并制定实际的缓解措施。", "innovation": "本文创新地提出了区分内生和外生幻觉的概念，并定义了模型的幻觉风险。通过学习理论框架（PAC-Bayes 和 Rademacher 复杂性）推导出幻觉风险的边界。此外，本文还回顾了检测幻觉的各种策略，如token级不确定度估计、置信度校准和注意力对齐检查，并讨论了缓解措施，包括检索增强生成、幻觉意识微调、logit校准和引入事实验证模块。最后，本文提出了一个统一的检测与缓解工作流程，实现了这些策略的整合，并建议了评估幻觉的协议，包括数据集、评估指标和实验设置。", "conclusion": "本文为LLMs中的幻觉问题奠定了理论基础，并提供了实际的操作指南，有助于减缓和解决幻觉这一核心挑战。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22913", "html_url": "https://arxiv.org/abs/2507.22913", "title": "一种集成嵌入式回归模型与大规模语言模型的混合框架：主题分析", "title_en": "A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models", "authors": "Jinyu Liu,Xiaoying Song,Diana Zhang,Jason Thomale,Daqing He,Lingzi Hong", "background": "提供主题访问是任何图书馆管理系统的重要功能。大规模语言模型（LLMs）已在分类和总结任务中广泛应用，但它们在进行主题分析方面的能力尚待探索。传统的机器学习（ML）模型中的多标签分类方法在主题分析中已有所应用，但难以处理未见过的情况。LLMs提供一种替代方案，但它们往往会过度生成和臆想。因此，本文提出了一个混合框架，该框架结合了基于嵌入的ML模型和LLMs。这种架构使用ML模型来预测LCSH标签的最佳数量，以指导LLM的预测，并用实际的LCSH术语对预测的术语进行后编辑以减轻臆想现象。该研究利用LLMs和混合框架，使用拥有国会图书馆主题标引（LCSH）的书籍进行主题术语预测实验，结果表明提供初始预测以指导LLM生成并施加后编辑能产生更为受控且词汇匹配的输出。", "innovation": "本文提出了一种结合嵌入式回归模型和大规模语言模型的混合框架，用于主题分析。实验结果表明，这种方法可以提供更为受控和词汇匹配的输出，同时减轻LLMs的臆想现象。", "conclusion": "研究结果表明，提供初始预测以指导LLM生成并施加后编辑能产生更为受控且词汇匹配的输出，所提出的混合框架在主题分析中具有一定的优势和潜力。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22921", "html_url": "https://arxiv.org/abs/2507.22921", "title": "利用级联语言模型链和候选答案实现快速且准确的上下文知识提取", "title_en": "Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers", "authors": "Lee Harris", "background": "语言模型能够捕捉给定文本中的复杂关系，但这些模型往往成本高昂，并且会产生不存在的信息（即幻觉）。如果这些生成的信息是不正确的，那么投入的资源就会浪费。论文提出了一种名为Language Model Chain (LMC) 的算法，其目的是解决这些模型的成本问题及准确性问题。通过限制语言模型的响应范围在候选答案中，以及对错误响应文本使用更具有预测性但速度较慢的语言模型再次进行处理，LMC 算法可以确保最终生成的信息是正确的。", "innovation": "论文中提出并实施了名为LMC 的语言模型链算法。该算法将一个语言模型对给定提示的相应结果限制在候选答案中，对于错误的响应，会将其信息传递给另一个更具预测性但速度较慢的语言模型进行进一步处理。这种方法可以确保最终产生的信息是正确的，且该算法通过级联多个语言模型，不仅显著提高了预测速度和准确性，还大大减少了对应的幻觉。", "conclusion": "实验结果显示，利用LMC 算法和级联语言模型，不单显著提高了从医学文档中提取患者出生日期的速度和准确性，而且减少了幻觉。作者认为，这一新颖的LMC 算法在知识提取领域有着重要的贡献，并建议未来需要进一步研究和应用这一方法。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22922", "html_url": "https://arxiv.org/abs/2507.22922", "title": "使用标注ChatGPT的Reddit情绪预测股票价格", "title_en": "Predicting stock prices with ChatGPT-annotated Reddit sentiment", "authors": "Mateusz Kmak,Kamil Chmurzyński,Kamil Matejuk,Paweł Kotzbach,Jan Kocoń", "background": "2021年GameStop的空头挤压事件标志着零售投资者在社交媒体上的活动激增。这引发了关于在线情绪对股票价格的影响力的问题。本研究探讨社交媒体讨论中提取的情绪能否有意义地预测股市变动。我们集中在Reddit的r/wallstreetbets板块，分析了GameStop (GME) 和AMC Entertainment (AMC)两家公司的相关情绪。为了评估情绪的作用，我们使用了两种现有的基于文本的情绪分析方法，并引入了一种基于ChatGPT标注和微调的RoBERTa模型，以更好地理解和解释社交媒体讨论中普遍存在的非正式语言和表情符号。我们使用相关性和因果关系度量来确定这些模型的预测能力。", "innovation": "研究使用了基于ChatGPT标注和微调的RoBERTa模型来进行情绪分析，这是在情感分析领域的创新点。", "conclusion": "研究结果表明，社交媒体情绪与股票价格之间只有微弱的相关性。简单的情绪指标，如评论量和谷歌搜索趋势，表现出了更强的预测信号。这一结果揭示了零售投资者行为的复杂性，并暗示传统的基于文本的情绪分析可能无法完整捕捉到推动市场走势的在线讨论中的细微差别。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22916", "html_url": "https://arxiv.org/abs/2507.22916", "title": "从信号传播器到振荡器：对称微分方程在神经系统中的双重角色", "title_en": "From Propagator to Oscillator: The Dual Role of Symmetric Differential Equations in Neural Systems", "authors": "Kun Jiang", "background": "在我们之前的研究中，提出了一种基于对称微分方程的新颖神经元模型，并证明了其作为高效信号传播器的潜力。在此基础上，本研究进一步探讨了该模型的内在动力学和功能多样性。", "innovation": "通过系统地探索参数空间并采用一系列数学分析工具，理论揭示了该系统的核心功能二元性。具体地，模型表现出两种不同的轨迹行为：一是有界的渐近稳定，对应于可靠的信号传播器；二是Lyapunov稳定，表现为持续的自激振荡，作为信号生成器。此外，引入了一种新的中间状态度量——路途能量，以有效监测和预测模拟过程中的系统状态。", "conclusion": "结果表明，通过调整参数或修改连接结构，可以诱导这两种功能模式之间的转换。进一步证明，通过引入外部信号可以有效抑制振荡。这些发现将该模型在神经形态工程中的应用扩展到信息传输和节律生成的双重功能，并为其更广泛的应用奠定了坚实的基础和明确的功能路线图。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22923", "html_url": "https://arxiv.org/abs/2507.22923", "title": "跨语言LLM提示中的翻译策略影响：如何翻译及翻译的位置", "title_en": "How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting", "authors": "Aman Gupta,Yingying Zhuang,Zhou Yu,Ziji Zhang,Anurag Beniwal", "background": "尽管大型语言模型（LLMs）的多语言能力已经有了显著进步，但它们在不同语言和任务上的表现仍然存在显著差异。在基于检索增强生成（RAG）的多语言系统中，知识库（KB）通常是从资源丰富的语言（如英语）向资源匮乏的语言共享，导致从KB检索的信息与上下文中的其他部分语言不同。在这些情况下，常见的做法是预先翻译生成单语提示和跨语言提示以进行直接推理。然而，这些选择的影响尚不清楚。", "innovation": "本文系统评估了不同提示翻译策略对增强RAG的多语言LLM分类任务的影响。实验结果显示，优化的提示策略可以显著提高跨语言知识共享的效果，从而改善下游分类任务的表现。研究强调了跨语言资源共享和提示优化在非英语语言，特别是低资源语言中的更广泛应用。", "conclusion": "研究结果表明，合适的提示翻译策略可以显著提高多语言系统中LLM的知识共享效果，从而改善下游分类任务的表现。这鼓励在非英语语言，尤其是低资源语言中更广泛地采用多语言资源共享和跨语言提示优化策略。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22917", "html_url": "https://arxiv.org/abs/2507.22917", "title": "在时间轴之间识别：基于RAG的历时性问题回答", "title_en": "Reading Between the Timelines: RAG for Answering Diachronic Questions", "authors": "Kwun Hang Lau,Ruiyuan Zhang,Weijie Shi,Xiaofang Zhou,Xiaojun Cheng", "background": "尽管检索增强生成（RAG）在向大规模语言模型（LLM）注入静态事实性知识方面表现出色，但在处理需要在时间上跟踪实体和现象的历时查询时却存在关键缺陷。传统、基于语义的检索方法无法收集既在主题上相关又在时间上连贯的证据，尤其是在指定的时间段内。本文通过提出一种新框架从根本上重新设计RAG流水线，引入了时间逻辑，解决了这一挑战。该方法首先将用户的查询分解为核心主题及其时间窗口，然后使用专门的检索器来校准语义匹配与时间相关性，确保收集覆盖整段时间区间的连续证据集。为了评估这种能力，本文还引入了基于真实和合成金融新闻混合语料库的历时性问题回答基准（ADQAB），以进行严谨的评估。实验结果表明，本文方法在答案准确性上取得了显著提升，比标准的RAG实现高出13%到27%。这项工作为构建能够进行复杂现实问题所需精细进化分析的RAG系统提供了一个验证途径。研究中的数据集和代码可以在提供的链接中获取。", "innovation": "本文提出了一种新的框架，重新设计了RAG流水线，以引入时间逻辑。该方法首先将用户的查询分解为核心主题及其时间窗口，然后使用专门的检索器来校准语义匹配与时间相关性，确保收集覆盖整段时间区间的连续证据集。此外，还引入了历时性问题回答基准（ADQAB），以进行严谨的评估。实验结果表明，本文方法在答案准确性上取得了显著提升，比标准的RAG实现高出13%到27%。", "conclusion": "本文提出的方法提供了一个验证途径，以构建能够进行复杂现实问题所需精细进化分析的RAG系统。研究中的数据集和代码已经公开，为这一领域的进一步研究提供了支持。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22920", "html_url": "https://arxiv.org/abs/2507.22920", "title": "为多模态LLMs的离散分词：全面概述", "title_en": "Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey", "authors": "Jindong Li,Yali Fu,Jiahong Liu,Linxiao Cao,Wei Ji,Menglin Yang,Irwin King,Ming-Hsuan Yang", "background": "大规模语言模型（LLMs）的快速发展增加了将连续的多模态数据转换为适用于语言处理的离散表示形式的有效机制的需求。离散分词作为矢量量化（VQ）的核心方法，提供了计算效率并兼容LLM架构。尽管VQ在LLM系统中的重要性日益提升，但仍缺乏一个全面的研究综述来系统地考察VQ技术在LLM系统中的应用。", "innovation": "这项工作填补了这一空白，通过展示第一种结构化的VQ分类和分析，针对LLM设计的离散分词方法进行研究。本研究介绍了8种代表性的VQ变种，并分析了它们的算法原理、训练动态和与LLM管道的集成挑战。此外，还讨论了经典应用、LLM单模态系统和LLM多模态系统中关于分词方法如何影响对齐、推理和生成性能的研究。", "conclusion": "这项综述将传统的矢量量化与现代LLM应用进行连接，为高效的、可泛化的多模态系统开发提供了一个基础参考。未来的研究方向包括动态和任务适应性量化、统一的分词框架以及受生物启发的码书学习。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22919", "html_url": "https://arxiv.org/abs/2507.22919", "title": "从前瞻性注册信息预测临床试验中严重不良事件结果的新语言模型", "title_en": "A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations", "authors": "Qixuan Hu,Xumou Zhang,Jinman Kim,Florence Bourgeois,Adam G. Dunn", "background": "临床试验需要精确的安全结果预测，以避免不必要的终止并减少参与者暴露于不必要的风险中。目前，大多数临床试验的注册信息未得到充分利用，研究者首次使用前瞻性注册信息来预测临床试验中的严重不良事件（SAE）结果。通过分析22,107个两臂平行的干预性临床试验，并开发了两种预测模型：一种分类器预测实验组的SAE率是否高于对照组，另一种回归模型预测对照组的SAE比例。利用预训练语言模型进行特征提取，并采用滑动窗口方法提高长文本的语义表示，研究发现最佳模型在预测哪一试验组有更高比例的患者出现SAE方面达到了77.6%的AUC，在预测对照组中经历SAE的参与者比例时，RMSE为18.6%。滑动窗口方法在所有模型中均表现最佳，提高了AUC并降低了RMSE，显示了利用注册信息进行风险预测的潜力.", "innovation": "研究开发了一种新的语言模型方法，使用预训练语言模型进行特征提取，并采用滑动窗口方法改善长期试验文本的语义表示，这种新方法比不具备滑动窗口的方法在模型预测中表现更好，改进了AUC和RMSE值。该结果表明，注册信息的充分利用可以优化试验设计并预警预计的安全结果与实际报告结果的差异.", "conclusion": "前瞻性注册信息仍被广泛应用，新开发的模型表明，使用注册信息能够预测临床试验结果，有助于改进试验设计和减少不必要的风险暴露。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22906", "html_url": "https://arxiv.org/abs/2507.22906", "title": "基于H2AD大规模绿色MIMO接收机的联合多源目标数量和方向感知的DNN方法", "title_en": "DNN-based Methods of Jointly Sensing Number and Directions of Targets via a Green Massive H2AD MIMO Receiver", "authors": "Bin Deng,Jiatong Bai,Feilong Zhao,Zuming Xie,Maolin Li,Yan Wang,Feng Shu", "background": "由于宏蜂窝和超大规模数字MIMO面临的高能耗、高电路成本和高复杂度等挑战，异构混合模拟-数字H2AD MIMO结构因其绿色特性被认为有望在未来无线网络中替代这些技术。但是，如何智能地感知多发射器的数量和方向成为一个公开难题。", "innovation": "本文提出了一个两阶段的感知框架，联合估计多目标的数量和方向。具体设计了三种目标数量感知方法：改进的特征域聚类（EDC）、基于五个关键统计特征的改进深度神经网络（DNN）以及利用所有特征值改进的一维卷积神经网络（1D-CNN）。此外，引入了一种低复杂度和高精度的方向角估计方法（OMC-DOA）。还推导了在多源条件下H2AD的Cramér-Rao下界（CRLB）作为理论性能基准。", "conclusion": "仿真结果表明，在中等至高信噪比条件下，所开发的三种方法均能百分之百地检测到目标数量，而改进的1D-CNN在极低信噪比条件下表现出优越性能。所引入的OMC-DOA方法在多源环境下的性能优于现有的基于聚类和融合的方向角估计方法。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22931", "html_url": "https://arxiv.org/abs/2507.22931", "title": "使用自适应上下文压缩提升RAG效率", "title_en": "Enhancing RAG Efficiency with Adaptive Context Compression", "authors": "Shuyu Guo,Zhaochun Ren", "background": "检索增强生成（RAG）通过外部知识增强大规模语言模型（LLMs），但由于检索上下文较长，导致推断成本显著增加。虽然上下文压缩可以缓解这个问题，但现有的方法使用固定压缩率，对于简单的查询过度压缩，对于复杂的查询则压缩不足。", "innovation": "我们提出了自适应上下文压缩for RAG（ACC-RAG）框架，该框架根据输入的复杂度动态调整压缩率，优化了推理效率同时又不影响准确性。ACC-RAG结合了分层次的压缩器（用于多级嵌入）与上下文选择器，以保留最少量必需的信息，类似于人类浏览。", "conclusion": "与固定率方法相比，ACC-RAG在Wikipedia和五个QA数据集上的表现更优，同时可以快四倍的速度实现推理而保持或提高准确性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22934", "html_url": "https://arxiv.org/abs/2507.22934", "title": "深学习方法在多模态意图识别中的应用：综述", "title_en": "Deep Learning Approaches for Multimodal Intent Recognition: A Survey", "authors": "Jingwei Zhao,Yuhua Wen,Qifei Li,Minchi Hu,Yingying Zhou,Jingyao Xue,Junyang Wu,Yingming Gao,Zhengqi Wen,Jianhua Tao,Ya Li", "background": "意图识别旨在识别用户的潜在意图，传统上集中在自然语言处理中的文本。随着对自然人机交互需求的增加，该领域通过深度学习和多模态方法发展起来，这些方法融合了来自音频、视觉和生理信号的数据。最近，基于Transformer的模型在这一领域带来了显著的突破。本文综述了多模态意图识别（MIR）领域的深度学习方法，包括从单模态到多模态技术的转变，相关数据集，方法论，应用和当前挑战，为研究人员提供了有关最新进展和未来研究方向的见解和方向。", "innovation": "基于Transformer的模型在意图识别领域的应用和突破，通过综述深度学习方法，推动了从单模态到多模态技术的发展，涵盖了相关数据集、方法论、应用和挑战，为未来研究提供了方向。", "conclusion": "本文为研究人员提供了关于多模态意图识别领域的最新进展和未来研究方向的见解。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22925", "html_url": "https://arxiv.org/abs/2507.22925", "title": "在LLM代理中实现高效长期推理的分层记忆", "title_en": "Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents", "authors": "Haoran Sun,Shaoning Zeng", "background": "长期记忆对大型语言模型代理（LLM代理）的推理能力至关重要。现有的记忆机制虽然在存储和检索方面取得了进展，如将记忆编码为稠密向量以进行基于相似性的搜索或以图形形式组织知识，但在结构化记忆组织和高效检索方面仍有不足。", "innovation": "提出了一种分层记忆（H-MEM）架构，用于LLM代理，该架构按语义抽象程度分多级组织和更新记忆，每个记忆向量嵌入指向其下一层语义相关子记忆的位置索引编码。在推理阶段，基于索引的路由机制可以有效、逐层检索，而无需进行耗时的相似度计算。", "conclusion": "在LoCoMo数据集的五个任务设置上评估了本方法。实验结果表明，与五个基线方法相比，我们的方法在长期对话场景中表现出色，证明了其有效性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22938", "html_url": "https://arxiv.org/abs/2507.22938", "title": "电信文档中基于图的方法的多模态问答", "title_en": "A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents", "authors": "Sumit Soman,H. G. Ranjani,Sujoy Roychowdhury,Venkata Dharma Surya Narayana Sastry,Akshat Jain,Pranav Gangrade,Ayaaz Khan", "background": "技术文档中的问答（QA）常常涉及答案位于图表中的问题，特别是在电信领域，如流程图。传统的基于文本的检索增强生成（RAG）系统可能无法正确回答这些问题。本文通过使用视觉大型语言模型（VLMs）获取的流程图的图表示，并将其集成到文本主导的RAG系统中，研究如何实现对于包含图表的问题的高效图像检索。这种方法旨在展示如何利用改进的图表表示，提高电信领域内基于文本的检索模型的QA性能。", "innovation": "提出了一种流程图图像检索的方法，通过结合视觉大型语言模型（VLMs）获得的流程图的图表示与文本主导的RAG系统，实现了对电信文档中的多模态问答的处理。该方法在实验室机制上，从流程文档处理、图示类型的分类、图表示的构建到与文本嵌入管道的结合，形成了一个完整的方案，并在基于电信产品的专用数据库数据集上进行了评估，体现了其在处理流程图图像方面的稳健性和高效性。", "conclusion": "实验结果表明，使用微调后的VLM模型获得的图表示与真实答案的编辑距离较低，证明了这些表示对于流程图图像的鲁棒性。此外，该方法通过文本嵌入模型实现了良好的QA检索性能，包括专门针对电信领域的模型。该方法还减少了在推理时需要视觉大型语言模型的依赖，这为客户部署的问答系统带来了重要的成本效益。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22935", "html_url": "https://arxiv.org/abs/2507.22935", "title": "信任知识提取以实现运营和维护智能", "title_en": "Trusted Knowledge Extraction for Operations and Maintenance Intelligence", "authors": "Kathleen Mealey,Jonathan A. Karr Jr.,Priscila Saboia Moreira,Paul R. Brenner,Charles F. Vardeman II", "background": "从组织数据仓库中获取操作智能是一个关键挑战，原因在于数据保密性和数据集成目标之间的二元性，以及自然语言处理（NLP）工具相对于运营和维护等领域的专业知识结构的局限性。本文背景在于讨论知识图谱的构建，将知识提取过程分解为命名实体识别、指代消解、命名实体链接和关系提取等基本功能组件，并评估了包括大型语言模型（LLMs）在内的十六种NLP工具，特别是在飞机行业中的可信应用操作和维护智能场景。", "innovation": "讨论了知识图谱的构建和分解知识提取过程的方法，并评估了包括大型语言模型在内的十六种NLP工具。侧重于运营和维护智能的应用案例，并且注重能在受控和保密环境中操作的NLP和LLMs工具的零样本性能评估，指出相关挑战和技术成熟度水平，并提出进一步的基线测试和评估建议以增强信任度。", "conclusion": "鉴于观察到的显著性能限制，讨论了可信NLP和LLMs工具的挑战以及它们在航空等关键行业中的技术成熟度。最后提出增强信任的建议，并开放了数据集以支持进一步的基线测试和评估。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22928", "html_url": "https://arxiv.org/abs/2507.22928", "title": "基于稀疏自编码的链式思考机制可解释性", "title_en": "How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding", "authors": "Xi Chen,Aske Plaat,Niki van Stein", "background": "链式思考（CoT）提示可以显著提高大规模语言模型在多步骤任务中的准确性，但是生成的“思考过程”是否反映出真正的内部推理过程仍是未解之谜。这篇论文通过结合稀疏自编码和激活补丁技术，首次从特征层面研究CoT的忠实性。", "innovation": "论文引入了稀疏自编码和激活补丁技术，从Pythia-70M和Pythia-2.8B模型解决GSM8K数学问题时的链式思考和原始提示之间提取单义特征。实验发现，在较大模型中，用一小部分CoT推理特征替换后无CoT运行显著提高了答案对数概率，但70M模型中没有明显效果，这揭示了一种明显的规模阈值。同时，CoT在较大模型中的应用还提高了激活稀疏性和特征可解释性评分，暗示了其内部计算更加模块化。", "conclusion": "我们的结果表明，CoT可以诱导高容量的大规模语言模型产生更可解释的内部结构，证实了其作为结构化提示方法的作用。此外，我们还引入了补丁曲线和随机特征补丁基线，显示有用的CoT信息不仅存在于前K个补丁中，而是分布在各个部分。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22937", "html_url": "https://arxiv.org/abs/2507.22937", "title": "CoE-Ops: 基于LLM专家合作的AIOps问答", "title_en": "CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering", "authors": "Jinkun Zhao,Yuanshuai Wang,Xingjian Zhang,Ruibo Chen,Xingchuang Liao,Junle Wang,Lei Huang,Kui Zhang,Wenjun Wu", "background": "伴随人工智能的迅速发展，AIOps已成为DevOps中的一个突出范式。已有大量工作旨在提高AIOps各个阶段的性能。然而，受限于特定领域的专业知识，单一模型只能处理特定任务（如日志解析、根本原因分析）的需求。同时，组合多个模型可以达到更高效的结果，这在先前的集成学习和最近的语言模型训练领域中都有得到证明。", "innovation": "本文受此启发，为应对AIOps中的类似挑战，首先提出了一种包括通用大型语言模型任务分类器的合作专家框架（CoE-Ops）。引入了检索增强生成机制，以增强框架处理高级别（如代码、构建、测试等）和低级别任务（如故障分析、异常检测等）的能力。通过在AIOps领域实现该方法，并在DevOps-EVAL数据集上进行广泛的实验，结果显示CoE-Ops在高级AIOps任务路由准确性上比现有CoE方法提高了72%，在DevOps问题解决中比单一AIOps模型提高了高达8%的准确性，并且在准确性上比更大规模的混合专家模型（MoE）高出14%以上。", "conclusion": "CoE-Ops方法在高级AIOps任务和单一AIOps模型以及更大规模的MoE模型中均表现优异，证明了其在提高AIOps任务处理准确性和效率方面的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22933", "html_url": "https://arxiv.org/abs/2507.22933", "title": "增强视觉-语言模型：系统回顾", "title_en": "Augmented Vision-Language Models: A Systematic Review", "authors": "Anthony C Davis,Burhan Sadiq,Tianmin Shu,Chien-Ming Huang", "background": "近期视觉-语言机器学习模型展示了使用自然语言理解和处理视觉场景的出色能力，这些模型通过大规模、非结构化数据集进行训练。然而，这种训练范式无法为输出提供可解释的解释，需要重新训练来整合新信息，并且在处理某些逻辑推理方面表现不佳。", "innovation": "文中提出了一种有希望的解决方案：将神经网络与外部符号信息系统相结合，形成具有增强推理和记忆能力的神经符号系统。这些神经符号系统可以为输出提供更可解释的解释，并且在不进行大量重新训练的情况下吸收新信息。通过利用强大的预训练视觉-语言模型作为核心神经组件，并通过外部系统增强，实现神经符号集成的好处。该系统综述旨在通过与外部符号信息系统交互的方式来分类能够提高视觉-语言理解的技术。", "conclusion": "通过与外部符号信息系统交互来提高视觉-语言理解的过程需要合理分类和整合多种技术。增强视觉-语言模型这一方法提供了一种实用途径，以实现在不完全重新训练的情况下吸收新信息和改进推理能力的目标。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22939", "html_url": "https://arxiv.org/abs/2507.22939", "title": "PARROT: 一个开放的多语言放射学报告数据集", "title_en": "PARROT: An Open Multilingual Radiology Reports Dataset", "authors": "Bastien Le Guellec,Kokou Adambounou,Lisa C Adams,Thibault Agripnidis,Sung Soo Ahn,Radhia Ait Chalal,Tugba Akinci D Antonoli,Philippe Amouyel,Henrik Andersson,Raphael Bentegeac,Claudio Benzoni,Antonino Andrea Blandino,Felix Busch,Elif Can,Riccardo Cau,Armando Ugo Cavallo,Christelle Chavihot,Erwin Chiquete,Renato Cuocolo,Eugen Divjak,Gordana Ivanac,Barbara Dziadkowiec Macek,Armel Elogne,Salvatore Claudio Fanni,Carlos Ferrarotti,Claudia Fossataro,Federica Fossataro,Katarzyna Fulek,Michal Fulek,Pawel Gac,Martyna Gachowska,Ignacio Garcia Juarez,Marco Gatti,Natalia Gorelik,Alexia Maria Goulianou,Aghiles Hamroun,Nicolas Herinirina,Krzysztof Kraik,Dominik Krupka,Quentin Holay,Felipe Kitamura,Michail E Klontzas,Anna Kompanowska,Rafal Kompanowski,Alexandre Lefevre,Tristan Lemke,Maximilian Lindholz,Lukas Muller,Piotr Macek,Marcus Makowski,Luigi Mannacio,Aymen Meddeb,Antonio Natale,Beatrice Nguema Edzang,Adriana Ojeda,Yae Won Park,Federica Piccione,Andrea Ponsiglione,Malgorzata Poreba,Rafal Poreba,Philipp Prucker,Jean Pierre Pruvo,Rosa Alba Pugliesi,Feno Hasina Rabemanorintsoa,Vasileios Rafailidis,Katarzyna Resler,Jan Rotkegel,Luca Saba,Ezann Siebert,Arnaldo Stanzione,Ali Fuat Tekin,Liz Toapanta Yanchapaxi,Matthaios Triantafyllou,Ekaterini Tsaoulia,Evangelia Vassalou,Federica Vernuccio,Johan Wasselius,Weilang Wang,Szymon Urban,Adrian Wlodarczak,Szymon Wlodarczak,Andrzej Wysocki,Lina Xu,Tomasz Zatonski,Shuhang Zhang,Sebastian Ziegelmayer,Gregory Kuchcinski,Keno K Bressem", "background": "放射学领域中，自然语言处理（NLP）的应用需要大量高质量的数据集进行训练和验证。然而，现有的数据集通常存在规模小、语言单一或隐私限制等问题，难以满足跨语言和跨地区的应用需求。该研究旨在开发和验证PARROT，一种包含多种语言、多中心且开放访问的虚构放射学报告数据集，用于测试NLP应用在放射学中的性能，同时不对隐私造成影响。", "innovation": "开发了一个包含多种语言的大型、多中心且开放的虚构放射学报告数据集，涵盖了13种语言和21个国家的数据，包括了多种影像学模态和解剖区域的放射学报告，并且该数据集还包含元数据和ICD-10编码。研究还通过一项人类与AI报告区分实验，验证了该数据集在区分AI生成和人工生成报告方面的有效性，特别是在放射科医生中表现更为突出。这项工作为NLP在放射学中的应用提供了一个不受隐私限制的大规模多语言数据集，促进了跨语言和跨地区的应用研究和发展。", "conclusion": "PARROT数据集代表了目前最大的开放多语言放射学报告数据集，使得NLP应用可以在语言、地理和临床边界上进行开发和验证，而不受隐私限制的约束。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22936", "html_url": "https://arxiv.org/abs/2507.22936", "title": "评估大规模语言模型（LLMs）在金融自然语言处理中的表现：对财务报告分析的比较研究", "title_en": "Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis", "authors": "Md Talha Mohsin", "background": "大规模语言模型（LLMs）在广泛金融自然语言处理（FinNLP）任务中展现出了卓越的能力。然而，关于广泛使用的大规模语言模型之间的系统性比较研究仍然不足。鉴于LLMs在金融分析中的快速进步和日益重要的影响，本文对GPT、Claude、Perplexity、Gemini和DeepSeek这五家领先的LLMs进行了全面的比较评估，使用了来自‘七个神话’科技公司的10-K财务文件。研究设计了领域特定的提示，并采用三种方法来评估模型性能：人工标注、自动化词汇-语义指标（ROUGE，余弦相似度，Jaccard）以及模型行为诊断（提示级别变异性和跨模型相似性）。研究表明，GPT给出了最连贯、语义对齐且上下文相关性最强的回答；其次为Claude和Perplexity。Gemini和DeepSeek在答案的变化性和一致性方面表现较差。此外，输出的相似性和稳定性在不同的公司之间以及随时间而变化，表明输出对提示的撰写方式和使用材料的高度敏感性。", "innovation": "本研究的主要创新点在于对广泛使用的五大LLMs进行了系统的比较评估，针对金融报告分析进行了详细分析，并采用多种评估方法（人工标注、自动化词汇-语义指标以及模型行为诊断）来评估模型性能，为领域内提供了新的视角和参考", "conclusion": "结果显示，GPT模型在连贯性、语义对齐和上下文相关性方面表现最佳；Claude和Perplexity次之；Gemini和DeepSeek在答案一致性方面表现较差，且答案的变化性较大。输出的相似性和稳定性在不同公司以及随时间变化，提醒我们在使用LLMs进行金融数据处理时需考虑提示的撰写和输入材料的多样性因素。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23010", "html_url": "https://arxiv.org/abs/2507.23010", "title": "研究多模态潜在空间的可逆性：基于优化方法的局限性", "title_en": "Investigating the Invertibility of Multimodal Latent Spaces: Limitations of Optimization-Based Methods", "authors": "Siwoo Park", "background": "研究发现，专为特定任务设计的人工智能模型（如文本到图像生成和音频到文本转换）表现出色，但这些模型在逆向映射任务上的潜在能力尚未被充分探索。传统上，优化方法能够引导模型向逆任务方向发展，但潜在空间的多模态结构是否能自然地支持有意义且感知上一致的逆向映射尚不清楚。", "innovation": "本文提出了一种基于优化的框架，可以双向应用于文本-图像（BLIP，Flux.1-dev）和文本-音频（Whisper-Large-V3，Chatterbox-TTS）模态，以推断具有期望输出的输入特征。实验结果表明，虽然优化可以促使模型生成与目标副本文本一致的输出，但此类逆转的感知质量是混乱且不一致的。此外，当试图从生成模型中推断原始语义输入时，重建的潜在空间嵌入经常缺乏语义可解释性。", "conclusion": "研究表明，专为特定前向任务优化的多模态潜在空间并不固有地具备支持稳健且可解释的逆向映射的结构。因此，当前研究强调了进一步研究开发真正具有丰富语义和可逆性多模态潜在空间的需求。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22958", "html_url": "https://arxiv.org/abs/2507.22958", "title": "CHECK-MAT: 俄罗斯统一国家考试的手写数学答案检查", "title_en": "CHECK-MAT: Checking Hand-Written Mathematical Answers for the Russian Unified State Exam", "authors": "Ruslan Khrulev", "background": "现有视觉语言模型基准主要侧重于问题解决能力，而本研究旨在通过构建一个新的基准——EGE-Math Solutions Assessment Benchmark，来评估视觉语言模型在理解手写数学解题方面的能力，特别是识别错误并按照固定标准进行评分的能力。该基准使用了来自俄罗斯统一国家考试（EGE）的122份扫描解题答案和官方专家评分，共有七个现代视觉语言模型参与了三种推理模式下的评估。结果显示，当前的模型在数学推理和人工评分标准对齐方面存在不足，这为人工智能辅助评估领域提供了新的研究方向。", "innovation": "本研究创新地提出了一个新的视觉语言模型基准——EGE-Math Solutions Assessment Benchmark，该基准特别关注手写数学解题的理解、错误识别和根据固定标准进行评分的能力，这一方法与现有的以问题解决为中心的基准不同。此外，通过对七种不同来源的视觉语言模型的评估，揭示了这些模型在数学推理和评分上与人工标准的不同程度的对齐情况，为技术改进指明方向。", "conclusion": "研究结果揭示了当前视觉语言模型在数学推理和评分标准对齐方面的局限性，为进一步的研究和改进提供了新的方向。这些发现对于开发更加准确和可靠的AI辅助评估系统具有重要意义。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23058", "html_url": "https://arxiv.org/abs/2507.23058", "title": "参考指导的扩散式修补生成多模态反事实生成", "title_en": "Reference-Guided Diffusion Inpainting For Multimodal Counterfactual Generation", "authors": "Alexandru Buburuzan", "background": "安全关键应用程序，如自动驾驶和医学图像分析，需要广泛的多模态数据进行严格的测试。使用合成数据方法有助于克服收集真实数据的成本和复杂性，但仍需实现高度的现实性和可控性才能发挥作用。这项工作提出了两种新颖的方法来生成自动驾驶和医学图像分析领域的合成数据：MObI和AnydoorMed。MObI是一个首创的多模态对象修补框架，利用扩散模型生成具有现实感和可控性的对象修补，同时在感知模态中进行演示，适用于相机和激光雷达。AnydoorMed将这一概念扩展到医学成像领域，专注于参考指导的修补，用于乳腺扫描。这两种方法证明了基础模型在自然图像中的参考指导修补可以很容易地适应不同的感知模态，为下一代能够构建高度现实、可控的多模态反事实场景的系统铺平了道路。", "innovation": "1. MObI：首创的多模态对象修补框架，利用扩散模型生成具有现实性和可控性的对象修补。支持在指定 3D 位置对现有多模态场景进行无缝对象插入，保持语义一致性并保证多模态一致性。2. AnydoorMed：在医学图像领域引入参考指导修补的方法，重点是对乳腺扫描进行修补，确保结构完整性同时在语义上与周围组织融合。", "conclusion": "基础模型在参考指导的修补生成中的适应性体现了这些方法能够在自然图像和感知模态中生成高度现实、可控的多模态反事实场景的能力，为未来自动驾驶和医学图像分析系统的发展提供了新的可能性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23021", "html_url": "https://arxiv.org/abs/2507.23021", "title": "使用扩散模型建模统一扫描路径预测的人类注视行为", "title_en": "Modeling Human Gaze Behavior with Diffusion Models for Unified Scanpath Prediction", "authors": "Giuseppe Cartella,Vittorio Cuculo,Alessandro D'Amelio,Marcella Cornia,Giuseppe Boccignone,Rita Cucchiara", "background": "预测人类注视扫描路径对于理解视觉注意力至关重要，尤其在人机交互、自主系统和认知机器人等领域具有应用价值。虽然深度学习模型提升了扫描路径预测的准确性，但大多数现有方法生成的是平均行为，无法捕捉人类视觉探索的多样性。", "innovation": "本文提出了ScanDiff架构，结合了扩散模型与Vision Transformers，以生成多样且自然的扫描路径。该方法利用扩散模型的随机性质显式建模扫描路径的多样性，同时引入了文本条件性以实现任务导向的扫描路径生成。实验结果表明，ScanDiff在基准数据集上的表现优于现有最先进的方法，产生了更丰富且准确的扫描路径，突显了其捕捉人类视觉行为复杂性的能力，推动了注视预测研究的发展。", "conclusion": "ScanDiff不仅能够生成多样且真实的扫描路径，还在任务导向和自由观视场景中超越了现有最先进的方法，展示了其在理解和预测人类视觉行为方面的能力。未来的研究可以进一步探索扩散模型在其他视觉注意力任务中的应用。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22946", "html_url": "https://arxiv.org/abs/2507.22946", "title": "SmartCourse: 为本科生设计的基于上下文的AI辅助课程指导系统", "title_en": "SmartCourse: A Contextual AI-Powered Course Advising System for Undergraduates", "authors": "Yixuan Mi,Yiduo Yu,Yiyi Zhao", "background": "传统的指导工具存在一些限制，无法为每位学生提供个性化的课程建议。SmartCourse 旨在通过整合学生的成绩单和课程计划信息，提供一个综合的课程管理和AI驱动的指导系统，特别针对计算机科学（CPS）专业的本科生。该系统通过命令行接口（CLI）和Gradioweb图形用户界面（GUI）为教师和学生提供服务，管理用户账户、课程注册、评分和四年级学位计划，并纳入本地托管的大语言模型（Ollama）以提供个性化的课程推荐。系统利用成绩单和专业计划提供上下文建议，例如优先考虑需求或重修。", "innovation": "SmartCourse 通过结合课程管理功能和AI驱动的个性化课程推荐，提供了一个更为完善的学生指导系统。系统创新点在于使用命令行接口和Web图形用户界面为师生提供服务，整合本地托管的大语言模型，并通过四个自定义指标（PlanScore、PersonalScore、Lift和Recall）评估推荐质量。实验结果显示，利用全方位上下文进行推荐比不考虑上下文模式更为相关，突显了成绩单和计划信息在个性化学术指导中的重要性。SmartCourse 显示了基于成绩的数据推动学术规划的应用潜力。", "conclusion": "实验结果证实了使用全面上下文对推荐结果的相关性有显著提升，强调了学生成绩单和专业计划信息对个性化学术建议的重要性。SmartCourse 展示了基于成绩的AI如何增强学术规划，提供更加有效的指导系统。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22940", "html_url": "https://arxiv.org/abs/2507.22940", "title": "可信赖推理：评估并增强大型语言模型中间思维过程的事实准确性", "title_en": "Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes", "authors": "Rui Jiao,Yue Zhang,Jinku Li", "background": "现有的大型语言模型（LLMs）在中间推理步骤中可能存在事实不准确的问题，即使最终答案正确，这种现象在高风险领域如医疗保健、法律分析和科学研究中具有显著的风险。错误但自信的推理可能会误导用户做出危险的决定。", "innovation": "提出了RELIANCE框架，这是一种新颖的方法，旨在解决LLMs中的关键漏洞：中间推理步骤中的事实不准确性。RELIANCE框架整合了三个核心组件：1）专门针对假设性增强数据训练的谬误检测分类器，以检测推理链中的细微事实不一致；2）一种基于多维奖励的群体相对策略优化（GRPO）强化学习方法，用于平衡事实性、连贯性和结构正确性；3）一种机制解释模块，研究事实性改进如何表现在模型激活中的推理过程中。", "conclusion": "对十种最先进的模型的广泛评估显示，即使是领先模型Claude-3.7和GPT-o1的事实推理准确性也只有81.93%和82.57%。RELIANCE在增强事实鲁棒性方面表现出显著的改进（高达49.90%的提升），同时在诸如Math-500、AIME-2024和GPQA等具有挑战性的基准测试中保持或提升了性能。此外，我们的激活级分析提供了关于如何通过激活引导优化来重塑模型架构中推理轨迹的事实增强的可操作见解，为未来的训练方法奠定了基础，这些方法明确地针对事实鲁棒性进行优化。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23009", "html_url": "https://arxiv.org/abs/2507.23009", "title": "停止使用人类测试评估AI，开发基于原则的AI特定测试", "title_en": "Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead", "authors": "Tom Sühr,Florian E. Dorner,Olawale Salaudeen,Augustin Kelava,Samira Samadi", "background": "大型语言模型（LLMs）在一系列标准化测试中表现出色，这些测试原本是用来评估人类的认知和心理特质，如智力和性格。这些结果常常被解读为LLMs具有类似人类特性的重要证据，但本文认为这种解读构成了一种本体论错误。人类的心理和教育测试是基于理论的测量工具，特别针对人类群体进行校准。将这些测试应用于非人类主体，未经过实证验证，可能错误解读所测内容。此外，AI在基准测试上的表现越来越多地被解释为对诸如“智力”等特质的测量，但存在有效性问题、数据污染、文化偏见和表面提示变化敏感性等问题。", "innovation": "本文提出了一个新的观点，即停止使用人类测试来评估AI，而是开发基于原则的、专为AI设计的测试。这一创新观点是为了提出一种新的评估框架，这种框架可以基于现有的心理测量学构建和验证框架，也可以完全从零开始创建，以适应AI的独特背景。", "conclusion": "本文的结论是，使用现有的人类测试来评估AI缺乏足够的理论和实证支持，应该开发针对AI系统的、基于原则的评价框架，以更准确地评估和理解AI的能力。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23064", "html_url": "https://arxiv.org/abs/2507.23064", "title": "实时自主驾驶中的视觉语言融合：基于目标的相机、高清地图与航点的交叉注意力", "title_en": "Vision-Language Fusion for Real-Time Autonomous Driving: Goal-Centered Cross-Attention of Camera, HD-Map, & Waypoints", "authors": "Santosh Patapati,Trisanth Srinivasan,Murari Ambati", "background": "自动驾驶汽车需要几何准确性和语义理解才能导航复杂环境，但现有的系统通常将它们单独处理。研究人员研究了如何集成视觉和语言模型来同时处理这些需求。", "innovation": "提出了XYZ-Drive，这是一种单一的视觉-语言模型，能够读取前视摄像头画面、25m×25m的高空鸟瞰图以及下一个航点，然后输出转向和速度。该模型使用轻量级的目标中心交叉注意力层，使得航点标记突出显示相关图像和地图片段，支持行动和文本解释，融合后的标记进入部分微调的LLaMA-3.2 11B模型。在MD-NEX Outdoor-Driving基准测试中，XYZ-Drive达到了95%的成功率和0.80的路径长度加权成功率（SPL），超越了PhysNav-DG 15%，同时减少了碰撞次数，并显著提高了效率。", "conclusion": "实验表明，早期、标记级的意图和地图布局融合能够实现准确、透明的实时驾驶。去除任何模态（视觉、航点或地图）都会显著降低成功率，展示了它们的互补角色和丰富的联系。采用基于查询的融合比简单拼接能够更有效地注入地图知识。冻结变压器会降低性能，表明在特定任务（如自主驾驶）中应用VLM时进行微调的重要性。地图分辨率降低会提高事故发生率，验证了较高分辨率地图对精度的影响。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22968", "html_url": "https://arxiv.org/abs/2507.22968", "title": "C3: 一种探索复杂对话挑战的双语语料基准", "title_en": "C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations", "authors": "Chengqian Ma,Wei Tao,Yiwen Guo", "background": "近年来，语音对话模型（SDMs）因其直接对用户口头查询生成语音反应的能力而受到广泛关注。尽管它们越来越受欢迎，但在全面理解其在理解和模仿人类对话中的实际效果方面仍存在研究缺口，尤其是在与依赖于大量基准测试的文本基础大型语言模型（LLMs）相比时。人类的语音互动比文本更复杂，因为对话具有独特的特征。语音中的模糊性是由语义因素（如多义词）和音韵特征（如多音字、同形异义词和重音模式）等引起的。此外，上下文依赖性，包括省略、指代和多轮对话，进一步增加了人类对话动态的复杂性。为了照亮SDM的发展现状并解决这些挑战，本文介绍了这个基准数据集，它包含英语和汉语的1079个样本，并附带了一个基于大型语言模型的评估方法，与人为判断紧密契合，从而促进SDMs处理这些实际挑战的整体探索。", "innovation": "本文提出了一个双语基准数据集C3，包含1079个英汉样本，以及与人类判断紧密契合的基于大型语言模型的评估方法。这个数据集的独特之处在于：1) 它覆盖了英语和汉语，提供了多语言研究的基础；2) 旨在解决语音对话模型面临的复杂对话挑战，如语义模糊性和上下文依赖性；3) 基于大型语言模型的评估方法提升了评估的准确性，更好地反映了人类对话的复杂性。", "conclusion": "本文通过建立一个双语基准数据集C3，旨在更好地理解语音对话模型在复杂对话中的实际效果，并针对其面临的挑战提供了一个详细的方法来评估其性能。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23084", "html_url": "https://arxiv.org/abs/2507.23084", "title": "AutoIndexer: 一种增强学习导向的索引顾问，旨在扩大工作负载规模", "title_en": "AutoIndexer: A Reinforcement Learning-Enhanced Index Advisor Towards Scaling Workloads", "authors": "Taiyi Wang,Eiko Yoneki", "background": "高效地选择索引是数据库性能优化的关键，特别是在处理大规模分析工作负载的系统中。虽然深度强化学习（DRL）在通过学习经验自动化索引选择方面显示出潜力，但很少有研究关注如何使基于RL的索引顾问适应逐渐增加的工作负载规模，因为动作空间会以指数方式增长，且需要大量的试错。", "innovation": "AutoIndexer是一种结合了工作负载压缩、查询优化和专门的RL模型的框架，旨在有效地扩展索引选择。通过在压缩的工作负载上操作，AutoIndexer大幅降低了搜索复杂性，同时不会牺牲太多索引质量。广泛评估表明，它将端到端查询执行时间减少多达95%与无索引的基线相比。平均而言，AutoIndexer在工作负载成本节省方面的表现比最先进的基于RL的索引顾问高出约20%，同时将调优时间缩短超过50%。", "conclusion": "这些结果证明了AutoIndexer在大型和多样化工作负载中的实用性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23027", "html_url": "https://arxiv.org/abs/2507.23027", "title": "恢复诊断价值：资源受限成像中超分辨率辅助超声心动图分类", "title_en": "Recovering Diagnostic Value: Super-Resolution-Aided Echocardiographic Classification in Resource-Constrained Imaging", "authors": "Krishan Agyakari Raja Babu,Om Prabhu,Annu,Mohanasankar Sivaprakasam", "background": "在资源受限设置（RCS）中，自动心脏解读常受限于影像质量差的超声心动图结果，限制了下游诊断模型的效果。虽然超分辨（SR）技术在增强磁共振成像（MRI）和计算机断层扫描（CT）图像方面显示出潜力，但其在易受噪声影响的、广泛可获取的超声心动图图像上的应用仍被严重忽视。", "innovation": "研究了基于深度学习的SR技术在低质量2D超声心动图分类中的潜力。使用公开可用的CAMUS数据集，通过按图像质量分层，评估了两个临床相关任务：一个相对简单的两腔与四腔视图分类以及一个更复杂的舒张末期与收缩末期相分类。应用了两种广泛使用的SR模型：超分辨率生成对抗网络（SRGAN）和超分辨率残差网络（SRResNet），以增强低质量图像并观察到显著的性能提升，尤其是SRResNet模型，它还提供了计算效率。", "conclusion": "SR技术能够有效地恢复退化的超声心动图的诊断价值，使其成为RCS中人工智能辅助护理的一个可行工具，实现更多功能，同时也更为经济高效。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23095", "html_url": "https://arxiv.org/abs/2507.23095", "title": "SMART-Editor: 一种兼具结构完整性的类人类设计编辑的多智能体框架", "title_en": "SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity", "authors": "Ishani Mondal,Meera Bharadwaj,Ayush Roy,Aparna Garimella,Jordan Lee Boyd-Graber", "background": "本文提出了SMART-Editor框架，该框架可以在结构化（海报、网站）和非结构化（自然图像）领域中实现组件布局和内容的编辑。不同于之前只进行局部编辑的模型，SMART-Editor通过两种策略——Inference-Time的Reward-Refine奖励引导精炼方法以及Training-Time的RewardDPO偏好优化方法来保持全局一致性。", "innovation": "提出了两种新的方法来保持全局一致：Reward-Refine（Inference-Time奖励引导精炼方法）和RewardDPO（Training-Time基于奖励偏好的布局优化方法）。此外，还引入了SMARTEdit-Bench基准测试，用于评估模型在跨领域复杂编辑场景中的性能。", "conclusion": "SMART-Editor在结构化设置中比InstructPix2Pix和HIVE等强基线模型表现出色，RewardDPO在结构化设置中实现了高达15%的提升，而Reward-Refine在自然图像编辑中显示出优势。自动和人工评估进一步证实了奖励引导计划的价值，能够产生语义一致且视觉对齐的编辑结果。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23087", "html_url": "https://arxiv.org/abs/2507.23087", "title": "LLM受助的从商务流程生成智能合约", "title_en": "On LLM-Assisted Generation of Smart Contracts from Business Processes", "authors": "Fabian Stiehle,Hans Weytjens,Ingo Weber", "background": "大型语言模型（LLMs）已经改变了软件生成的现实，并被软件工程社区探索用于从不同类型的输入中生成代码的不同用例。本文提出了一项探索性研究，旨在调查将LLMs用于生成智能合约代码的可行性，该想法是近期文献中提出的，旨在克服传统基于规则的代码生成方法的局限性。然而，目前基于LLM的工作仅在小样本上评估生成的代码，并依赖于人工检查或测试代码是否编译，而忽略了正确的执行。", "innovation": "本文提出了一个自动评估框架，并提供来自更大规模过程模型的数据集的实证数据。测试了不同类型和大小的LLMs在实现过程执行的重要属性（如强制执行流程、资源分配和数据条件）方面的能力。表明LLM在生成智能合约代码时的性能未能达到可信赖的要求。建议未来的研究探索在现有代码生成工具中负责任地整合LLMs，以确保更可靠的输出。基准测试框架可以作为开发和评估此类整合的基础。", "conclusion": "我们的研究结果表明，LLM性能未能达到智能合约开发所需的最佳可靠性。建议未来研究探索在现有工具中负责任地整合LLM，以确保更可靠的输出。我们的基准测试框架可以为开发和评估此类整合奠定基础。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23042", "html_url": "https://arxiv.org/abs/2507.23042", "title": "面向实时视觉语言驾驶的早期目标导向多尺度融合", "title_en": "Early Goal-Guided Multi-Scale Fusion for Real-Time Vision-Language Driving", "authors": "Santosh Patapati,Trisanth Srinivasan", "background": "自主车辆必须在毫秒内做出反应，同时根据道路几何形状和交通意图来推理以应对复杂的驾驶情况。研究团队介绍了一种名为NovaDrive的单一分支视觉语言架构，能够在单一路径下处理前置摄像头图像、高清地图切片、激光雷达深度数据以及文本路标。", "innovation": "引入了一种轻量级、两阶段的交叉注意力模块，首先对路标标记进行地图对齐，然后细化图像和深度块的注意力。还引入了一种新颖的平滑度损失，抑制尖锐的转向和速度变化。显著的特点是无需循环记忆模块，并且通过微调大模型的上层架构（即11B LLaMA-3.2），实现了实时推理。实验结果表明，该模型在nuScenes / Waymo基准上的成功率提升了4%，路径效率提高了11%，并且碰撞频率降低了1.4%。", "conclusion": "该研究通过消融实验确认了路标标记、部分视觉语言模型微调和交叉注意力融合各自对性能提升的贡献。该模型不仅提高了安全性，还减少了驾驶路线，从而降低了燃油或电池的使用，为自动化驾驶领域的发展提供了新思路，并具备扩展到其他领域的能力。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23115", "html_url": "https://arxiv.org/abs/2507.23115", "title": "FLOSS: 具有退出支持和结巴容忍的联邦学习系统", "title_en": "FLOSS: Federated Learning with Opt-Out and Straggler Support", "authors": "David J Goetze,Dahlia J Felten,Jeannie R Albrecht,Rohit Bhattacharya", "background": "以往对联邦学习系统中的数据隐私工作的研究主要关注用户同意共享数据时的数据隐私保护操作。然而，现代数据隐私协议赋予用户在需要时可以选择退出系统的权利，这与由于设备异构导致的结巴现象结合后，会导致来自不同来源的数据缺失。这种缺失数据会引入偏差并降低模型性能。针对这一现象，本文提出了FLOSS系统，旨在缓解这种数据缺失对联邦学习的影响，并通过模拟实验展示了其性能。", "innovation": "本文提出了FLOSS系统，该系统能够在存在用户退出和结巴问题的情况下缓解缺失数据对联邦学习的影响。", "conclusion": "通过模拟实验，本文验证了FLOSS系统的性能，表明其在应对用户退出和结巴问题方面是有效的。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23190", "html_url": "https://arxiv.org/abs/2507.23190", "title": "无障碍侦察员：建筑环境的个性化可达性扫描", "title_en": "Accessibility Scout: Personalized Accessibility Scans of Built Environments", "authors": "William Huang,Xia Su,Jon E. Froehlich,Yang Zhang", "background": "评估陌生的建筑环境对残疾人的可达性至关重要，但手动评估由用户或其医疗专业人员进行，劳动密集、不易扩展，而自动机器学习方法往往忽视个体用户的独特需求。近年来，大型语言模型（LLMs）的发展为解决这一问题提供了新的方法，通过结合个性化与可扩展性，实现更加适应性和情境感知的可达性评估。本文介绍了一个基于LLM的可达性扫描系统——无障碍侦察员（Accessibility Scout），它能从建筑环境的图片中识别可达性问题。无障碍侦察员能够通过协作的人机评估根据用户的行进能力、偏好和环境兴趣不断改进，生成个性化的可达性扫描。研究表明，该系统可以超越传统的无障碍考虑，生成更加个性化的可达性扫描。", "innovation": "无障碍侦察员结合了大型语言模型的个性化和可扩展性特点，通过协作的人机评估不断适应用户的特定需求。此外，它能够生成超越传统美国残疾人法（ADA）标准的个性化可达性扫描。", "conclusion": "本文的研究展示了无障碍侦察员的强大能力，并讨论了其工作的影响和未来开发可扩展和个性化的物理世界可达性评估的步骤。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23121", "html_url": "https://arxiv.org/abs/2507.23121", "title": "通过中文文本歧义揭示可信赖LLMs的脆弱性", "title_en": "Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity", "authors": "Xinwei Wu,Haojie Li,Hongyu Liu,Xinyu Ji,Ruohan Li,Yule Chen,Yigeng Zhang", "background": "本文探讨了大型语言模型（LLMs）可信赖性中的关键研究问题，特别是在遇到模糊叙事文本时的行为，特别关注中文文本的歧义性。研究表明，LLMs在处理歧义性时表现出显著的脆弱性，这种脆弱性在真实世界应用中具有重要意义，特别是在存在大量语言歧义的场景中。因此，需要改进语言理解中的不确定性处理方法。", "innovation": "作者通过收集和生成具有上下文的歧义句及其对应的消歧句对，构建了一个基准数据集，并将其系统分类为3大类和9个小类。通过实验发现，LLMs在处理歧义性时表现出显著的脆弱性，具体表现在：无法可靠地区分模糊文本与清晰文本，对模糊文本的解释表现出过度自信，并且在理解各种可能含义时表现出过度思考。", "conclusion": "本文的研究揭示了当前LLMs在处理语言歧义方面的根本局限性，对实际应用中普遍存在语言歧义的应用场景具有重大影响，呼吁改进处理语言理解中不确定性的方法。同时，提供的数据集和代码可以在GitHub上公开获取。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23104", "html_url": "https://arxiv.org/abs/2507.23104", "title": "RASL: 超大规模数据库文本到SQL检索增强模式链接", "title_en": "RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL", "authors": "Jeffrey Eben,Aitzaz Ahmad,Stephen Lau", "background": "尽管大型语言模型（LLM）驱动的自然语言数据库接口取得了进展，但将其扩展到企业级数据目录仍存在未被充分探索的挑战。现有方法依赖领域特定的微调，增加了部署的复杂性，并未充分利用数据库元数据中的重要语义信息。", "innovation": "我们提出了一种基于组件的检索架构，将数据库模式和元数据分解为独立的语义单元，并分别索引，以实现有针对性的检索。该方法优先考虑有效的表识别，同时利用列级别的信息，确保检索的表数量在可管理的上下文预算范围内。实验表明，我们的方法在大规模数据库中保持高召回率和准确性，并且我们的系统在不同程度结构的数据库中表现优于基线系统。", "conclusion": "我们的解决方案使得通用文本到SQL系统能够在无需特殊微调的情况下在各种企业环境中部署，从而弥合了自然语言数据库接口的扩展性差距。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23218", "html_url": "https://arxiv.org/abs/2507.23218", "title": "信息瓶颈资产定价模型", "title_en": "An Information Bottleneck Asset Pricing Model", "authors": "Che Sun", "background": "深度神经网络（DNNs）在金融资产定价领域受到了广泛关注，因其强大的建模复杂非线性关系能力。然而，复杂的模型容易对金融数据中的噪声信息过度拟合，导致性能不佳。", "innovation": "本文提出了一种信息瓶颈资产定价模型，该模型通过压缩信号与噪声比低的数据，消除冗余信息，保留关键信息。模型在非线性映射过程中施加互信息约束，确保在建模金融市场关系时忘记无关信息（即数据中的噪声），而不会影响最终的资产定价。利用信息瓶颈的约束，该模型不仅利用深度网络的非线性建模能力捕捉财务数据中的复杂关系，还确保在信息压缩过程中过滤掉噪声信息。", "conclusion": "通过利用信息瓶颈的约束，该模型不仅利用深度网络的非线性建模能力捕捉金融数据中的复杂关系，而且还确保在信息压缩过程中过滤掉噪声信息，有效克服了复杂模型对噪声信息过度拟合的问题，提升了资产定价的性能。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23154", "html_url": "https://arxiv.org/abs/2507.23154", "title": "FuseTen：基于时空卫星观测的日10米地表温度生成模型", "title_en": "FuseTen: A Generative Model for Daily 10 m Land Surface Temperature Estimation from Spatio-Temporal Satellite Observations", "authors": "Sofiane Bouaziz,Adel Hafiane,Raphael Canals,Rachid Nedjai", "background": "城市热浪、干旱和土地退化是气候变化背景下日益严峻的挑战。研究这些现象需要准确的时空地表状况信息。对于评估和理解这些现象而言，地表温度（LST）是非常重要的变量，它通过卫星获取并提供了有关地球表面热状态的关键信息。然而，卫星平台在空间分辨率和时间分辨率之间存在固有的权衡。为解决这一问题，本文提出了一种新型生成框架FuseTen，通过融合来自Sentinel-2、Landsat 8和Terra MODIS的时空观测数据产生每日10米空间分辨率的地表温度观测值。", "innovation": "FuseTen 使用生成架构，并通过基于物理原则的平均监督策略进行训练。它在融合过程中引入了注意力和规范化模块，并使用PatchGAN判别器以增强真实感。实验结果显示，相对于线性基准方法，FuseTen 在定量指标和视觉保真度上分别提升了32.06%和31.42%，这是首次提出在如此高空间分辨率下生成每日地表温度估算值的非线性方法。", "conclusion": "本文提出了一种新的生成模型FuseTen，能够通过融合时空卫星观测数据来生成每日10米空间分辨率的地表温度观测值，在定量指标和视觉保真度上显著优于现存方法。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23088", "html_url": "https://arxiv.org/abs/2507.23088", "title": "超越刚性AI：迈向术中人机自然共生的实时手术辅助", "title_en": "Beyond Rigid AI: Towards Natural Human-Machine Symbiosis for Interoperative Surgical Assistance", "authors": "Lalithkumar Seenivasan,Jiru Xu,Roger D. Soberanis Mukul,Hao Ding,Grayson Byrd,Yu-Chun Ku,Jose L. Porras,Masaru Ishii,Mathias Unberath", "background": "新兴的手术数据科学和机器人解决方案，尤其是旨在提供现场协助的技术，需要自然的人机接口来充分发挥其潜在的适应性和直觉性辅助功能。当前的基于AI的解决方案往往是刚性的，缺乏灵活性，限制了在动态手术环境中的人机自然交互。这些解决方案依赖于特定任务的大量预训练、固定的物体类别以及明确的手动提示。", "innovation": "本文引入了一种名为感知代理的新颖感知代理，该代理利用言语集成提示工程化的大语言模型（LLMs）、分割一切模型（SAM）和任何点跟踪基础模型，以实现实时术中手术协助的更自然的人机交互。感知代理通过记忆库和两种新的机制分割未知元素，提供灵活的方法分割手术场景中的已知和未知元素。感知代理可通过记忆新元素，在未来的手术中复用，朝着在手术过程中实现人机共生迈出了一大步。", "conclusion": "通过在公共数据集上的定量分析，我们表明该代理的性能与劳动密集型的手动提示策略相当。从定性的角度来看，我们展示了该代理在自定义数据集中的灵活性，在分割新型元素（如手术器械、模拟移植物和纱布）方面表现出色。通过提供自然的人机交互并克服刚性问题，本文的感知代理有可能使基于AI的实时手术辅助更接近现实。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23093", "html_url": "https://arxiv.org/abs/2507.23093", "title": "边缘设备上AI推理的可持续性研究", "title_en": "On the Sustainability of AI Inferences in the Edge", "authors": "Ghazal Sobhani,Md. Monzurul Amin Ifath,Tushar Sharma,Israat Haque", "background": "物联网（IoT）的普及及其前沿的人工智能（AI）使能应用（如自动驾驶车辆和智能工业）结合了数据驱动系统及其在边缘的部署。通常，边缘设备用于支持具有严格延迟要求的应用程序推理。除了这些资源受限的边缘设备的性能，其能耗也是采用和部署边缘应用的关键因素。这类设备包括树莓派（RPi）、Intel神经计算棒（INCS）、NVIDIAJetson nano（NJn）和Google Coral USB（GCU）。尽管这些设备在边缘部署中的AI推理应用中被广泛采用，但仍然缺乏对其性能和能耗的研究，以帮助做出设备和模型选择的决策，满足应用的需求。为了填补这一空白，本研究通过详细分析在上述边缘设备上传统模型、神经网络和大型语言模型的性能，具体涉及模型F1分数、推理时间、推理功耗和内存使用情况的权衡。除此之外，进一步研究了硬件和框架优化以及对AI模型的外部参数调整对优化边缘AI部署的关键作用。", "innovation": "本研究填补了现有研究中的空白，通过详细 karakterizing 上述边缘设备上传统模型、神经网络和大型语言模型的效能，分析模型F1分数、推理时间、推理功耗和内存使用情况之间的权衡，并探讨硬件和框架优化，以及对AI模型的外部参数调整如何平衡模型性能与资源使用，以实现实用的边缘AI部署。", "conclusion": "通过详细分析，本研究提供了关于各种边缘设备上AI模型性能和能耗的有价值的见解。这些发现有助于实现实际的边缘AI部署，通过平衡模型性能与资源使用，达到有效利用资源的目标。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23261", "html_url": "https://arxiv.org/abs/2507.23261", "title": "DynaSwarm: 动态的图结构选择用于基于LLM的多智能体系统", "title_en": "DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System", "authors": "Hui Yi Leong,Yuqing Wu", "background": "当前的多智能体系统（MAS）框架通常依赖于手动设计和静态的协作图结构，这限制了系统的适应性和性能。", "innovation": "DynaSwarm 提出了两项关键创新：（1）通过改进的演员-评论家强化学习（A2C）机制优化图结构，该机制相比之前的RL方法具有更好的稳定性；（2）一个动态图选择器，通过参数高效的LLM微调自适应选择每个输入样本的最佳图结构。DynaSwarm 通过利用样本特定的异质性来动态路由查询，替代了刚性的一刀切图架构。", "conclusion": "我们通过微调演示检索器，充分利用了上下文学习（ICL）的能力。DynaSwarm 在多项基于LLM的任务中，如问答、数学推理和编程任务上，表现出色，多次优于最先进的单智能体和MAS基线。研究结果强调了在LLM MAS设计中样本感知的结构灵活性的重要性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23217", "html_url": "https://arxiv.org/abs/2507.23217", "title": "伪表格目录引导检索增强生成的零样本文档理解", "title_en": "Zero-Shot Document Understanding using Pseudo Table of Contents-Guided Retrieval-Augmented Generation", "authors": "Hyeon Seong Jeong,Sangwoo Jo,Byeong Hyun Yoon,Yoonseok Heo,Haedong Jeong,Taehoon Kim", "background": "理解和处理复杂的多模态文档依然具有挑战性，这是因为多模态文档存在结构不一致的问题，并且可用的训练数据有限。现有的方法往往需要专门的模型或额外的训练，这增加了实现和维护的复杂性。为了解决这些问题，本文提出了一种名为DocsRay的训练无需的文档理解系统。这个系统整合了伪目录生成和层次化的检索增强生成技术，并利用多模态大语言模型的天然能力，无需专门模型或额外训练即可处理包含文本、图像、图表和表格等多种元素的文档。DocsRay通过结合三个关键技术——基于提示的LLM语义结构模块生成伪目录、多模态零样本分析以及高效的两阶段层次化检索系统，实现了文档理解的效果提升和效率改进。", "innovation": "提出了一种名为DocsRay的新型文档理解系统，该系统利用了多模态大语言模型的天然能力，能够无缝处理包含多种元素的文档，而且不需要专门的模型或额外的训练。这一体系结合了伪目录生成、多模态零样本分析以及层次化检索技术，既能保留多模态模型的完整能力，又能有效提高效率。", "conclusion": "在平均有49.4页和20,971个文本标记的文档上，DocsRay将查询延迟从3.89秒降低到2.12秒，效率提高了45%。同时，DocsRay-Pro在MMLongBench-Doc基准测试上达到了64.7%的准确率，大大超过了之前最先进的结果。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23178", "html_url": "https://arxiv.org/abs/2507.23178", "title": "AutoBridge：使用集中式平台自动化智能设备集成", "title_en": "AutoBridge: Automating Smart Device Integration with Centralized Platform", "authors": "Siyuan Liu,Zhice Yang,Huangxun Chen", "background": "多模态物联网系统协调各种物联网设备提供以人类为中心的服务。能够在集中管理平台上集成新物联网设备的能力是基本要求。然而，编程使平台能够理解并控制设备功能的复杂物联网集成代码需要大量的专业知识和努力。因此，提出AutoBridge以自动化物联网集成代码生成。AutoBridge采用分而治之的策略：首先通过逐步检索设备特定知识生成设备控制逻辑，然后使用特定平台知识合成平台合规的集成代码。为了保证正确性，AutoBridge配备了一个多层次的调试管道，包括自动调试器用于虚拟物联网设备测试，以及一个仅需要二进制用户反馈（是和否）进行实际设备验证的交互式硬件调试器。", "innovation": "AutoBridge提出了一种自动化物联网设备集成的新方法，通过分而治之的策略，逐步生成设备控制逻辑并使用特定平台知识合成合规的集成代码。此外，AutoBridge还具备多层次的调试管道，确保生成的代码的正确性和功能覆盖率。试验结果显示，AutoBridge在两个开源物联网平台上的34个设备基准测试中，平均成功率为93.87%，平均功能覆盖率为94.87%。并且通过极少的二进制用户反馈，即可实现100%的功能覆盖率。用户研究进一步表明，与经验丰富的程序员相比，AutoBridge在代码准确性方面高出50%至80%。即使是经验丰富的程序员允许使用商用代码LLM的情况下，AutoBridge仍表现出色。", "conclusion": "AutoBridge成功实现了物联网设备自动集成，显著减少了人为干预，提高了代码生成的正确性和功能覆盖率。该方法展示了自动化工具在提高物联网系统集成效率和质量上的潜力。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23167", "html_url": "https://arxiv.org/abs/2507.23167", "title": "LENS：从神经状态学习集成置信度以实现大规模语言模型答案集成", "title_en": "LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration", "authors": "Jizhou Guo", "background": "大规模语言模型（LLMs）在各种任务中展现了令人印象深刻的表现，但不同的模型在特定领域和能力上表现出色不一。有效结合多个LLM的预测对于增强系统的鲁棒性和性能至关重要。然而，现有的集成方法往往依赖于简单的方法，如投票或logits集成，这些方法忽略了模型在不同上下文中的不同置信度和可靠性。", "innovation": "提出了一种新颖的方法LENS（从神经状态学习集成置信度），通过分析内部表示学习估计模型的置信度。对每个LLM训练一个轻量级的线性置信度预测器，该预测器利用逐层隐藏状态和归一化概率作为输入，从而根据上下文相关可靠性对模型预测进行更细致的加权。该方法无需修改模型参数，且几乎没有额外的计算需求。", "conclusion": "在多项选择和布尔问题-回答任务上的实验结果表明，LENS在传统集成方法的性能上有显著提升。我们的研究发现表明，内部表示提供了确定模型置信度的有价值信号，可以有效地用于集成学习。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23194", "html_url": "https://arxiv.org/abs/2507.23194", "title": "GEAK：引入Triton内核AI代理及评估基准", "title_en": "Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks", "authors": "Jianghui Wang,Vinay Joshi,Saptarshi Majumder,Xu Chao,Bin Ding,Ziqiong Liu,Pratik Prabhanjan Brahma,Dong Li,Zicheng Liu,Emad Barsoum", "background": "随着深度学习工作负载的增长和复杂性增加，市场对于能够提供可扩展且硬件优化的图形处理单元（GPU）内核的需求迅速增长。因此，自动化低层级内核开发变得至关重要，以便满足性能和生产力需求。众多云供应商、半导体公司及研究机构纷纷在基于AI的GPU代码生成领域进行大量投资，旨在减少人工优化工作的同时，在AMD MI300X等硬件上实现接近专家级的表现。Triton语言作为一款基于Python的GPU编程领域特定语言，因其兼备高性能和易编程性而受到AI生成内核的青睐。因此，研究了GEAK框架，这是一种利用尖端LLM生成为AMD GPU（包括AMD MI300X和MI250）优化的Triton内核框架，利用推理时间的计算扩展机制，显著地提升了生成性能与执行速度。测试结果表明，GEAK在两个评估基准上优于基准线结果，并显著提升了性能表现。这些结果展示了GEAK在加速多种硬件平台的采用并促进专家级内核性能的普及方面的潜力。", "innovation": "GEAK框架运用先进的LLM技术，从反射性反馈机制中抽象出推理循环，生产适用于AMD GPU（包括AMD MI300X和MI250）的高性能Triton内核。相较于直接提示前沿LLM和基于反射的工作流程，GEAK在执行速度和正确率上取得了显著提升，达到63%的正确率和2.59倍的加速效果。这体现了代理代码生成在加速硬件平台采用和实现高级内核性能上的潜力，同时降低了开发难度，提高了开发效率，并且符合工业和学术界对可扩展和高性能图形处理的应用需求。", "conclusion": "研究展示了GEAK框架在自动优化Triton GPU内核生成中的潜在优势，通过利用先进的LLM与优化计算机制，实现了更高的执行效率和正确率。这为快速发展的GPU计算领域提供了新的方向和工具，同时也促进了硬件平台的广泛应用和专家级性能的普及。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23269", "html_url": "https://arxiv.org/abs/2507.23269", "title": "XABPs: 向可解释的自主业务流程迈进", "title_en": "XABPs: Towards eXplainable Autonomous Business Processes", "authors": "Peter Fettke,Fabiana Fournier,Lior Limonad,Andreas Metzger,Stefanie Rinderle-Ma,Barbara Weber", "background": "自主业务流程（ABPs），即利用人工智能/机器学习自我执行的工作流程，有潜力提高运营效率、减少错误、降低费用、加快响应时间，并使人类工作者有更多时间从事战略性和创造性的工作。然而，ABPs 可能引起特定担忧，包括降低了相关方的信任度、调试困难、问责障碍、偏见风险以及合规性问题。本文提出的 eXplainable ABPs（XABPs）旨在通过使系统能够阐述其决策理由来解决这些问题。", "innovation": "论文提出了一种系统化的XABPs方法，这种方法不仅描述了XABPs的多种形式，也结构化了可解释性，并确定了关键的业务流程管理（BPM）研究挑战，以推动XABPs的发展。这一方法致力于解决ABPs所引发的相关问题，提供增强的可解释性和透明性，从而提升信任度并促进合规性。", "conclusion": "本文概述了XABPs的系统性方法，通过引入可解释性，解决了ABPs的潜在问题，如信任缺失、调试难度、问责制障碍、偏见和合规性问题，并为未来的BPM研究指出了关键挑战。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23257", "html_url": "https://arxiv.org/abs/2507.23257", "title": " Efficient Machine Unlearning via Influence Approximation ", "title_en": "Efficient Machine Unlearning via Influence Approximation", "authors": "Jiawei Liu,Chenwang Wu,Defu Lian,Enhong Chen", "background": "由于隐私担忧日益增加，机器卸载（旨在使机器学习模型“忘记”特定训练数据）得到了越来越多的关注。现有的卸载方法中，基于影响的卸载因其无需重新训练就能估计单个训练样本对模型参数的影响而崭露头角。然而，这种方法由于需要计算整个训练样本和参数的海森矩阵及其逆矩阵而面临巨大的计算负担，这使其难以应用于大规模模型和频繁删除数据请求的场景。这显示出卸载（忘记）的困难。受认知科学的启发，认为记忆比忘记更容易，本文建立了从增量学习（记忆）的角度理解机器卸载（忘记）的理论链接，从而将机器卸载问题纳入增量学习的框架中。", "innovation": "基于通过增量学习（记忆）视角重新审视卸载（忘记）问题的理论连接，本文提出了一个称为影响近似卸载（IAU）算法的高效机器卸载方法，相比卸载中耗时的海森矩阵计算，增量学习通常依赖于更高效的梯度优化，这与前述的认知理论相吻合。IAU算法在不同的数据集和模型架构上全面优于现有的先进方法，实现了去除保证、卸载效率和模型实用性之间的优化平衡，并且其代码已公开可用。", "conclusion": "本文提出了IAU算法，该算法从增量学习的视角解决了卸载问题，实现了去除保证、卸载效率和模型实用性之间的优化平衡。通过广泛的实验证明，IAU算法在多种数据集和模型架构上优于现有方法。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23291", "html_url": "https://arxiv.org/abs/2507.23291", "title": "在深度学习中评估成员隐私动态", "title_en": "Evaluating the Dynamics of Membership Privacy in Deep Learning", "authors": "Yuetian Chen,Zhiqi Wang,Nathalie Baracaldo,Swanand Ravindra Kadhe,Lei Yu", "background": "会员推理攻击（MIAs）对深度学习训练数据的隐私构成了严重威胁。尽管在攻击方法上有显著进展，但我们对模型在训练过程中如何编码会员信息的理解仍然有限。本文提出了一种动态分析框架，用于在个体样本级别解剖和量化隐私泄露动态。该框架通过在整个训练过程中在FPR-TPR平面上跟踪每个样本的脆弱性，系统地衡量数据集复杂度、模型架构和优化器选择等因素如何影响样本脆弱性和严重性的发展。", "innovation": "本文提出了一个动态分析框架，通过在整个训练过程中在FPR-TPR平面上跟踪每个样本的脆弱性，系统地衡量数据集复杂度、模型架构和优化器选择等因素如何影响样本脆弱性和严重性的发展，揭示了样本固有学习难度与隐私风险之间的稳健相关性。", "conclusion": "本文的结果深入揭示了训练过程中隐私风险如何动态出现，为预防性和隐私意识较强的模型训练策略奠定了基础。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23350", "html_url": "https://arxiv.org/abs/2507.23350", "title": "农业应用中非完整移动机器人多目标点路径规划与运动控制", "title_en": "Multi-Waypoint Path Planning and Motion Control for Non-holonomic Mobile Robots in Agricultural Applications", "authors": "Mahmoud Ghorab,Matthias Lorenzen", "background": "农业环境中对能够自主导航的移动机器人需求日益增长。例如，草地中的杂草控制任务需要高效地通过一系列无序的坐标进行路径规划，同时最小化行驶距离并遵守曲率限制，以防止土壤损坏和保护植被。", "innovation": "该论文提出了一种综合导航框架，该框架结合了基于Dubins旅行商问题（DTSP）的全局路径规划器与非线性模型预测控制（NMPC）策略进行局部路径规划和控制。DTSP生成一个最小长度且满足曲率约束的路径，NMPC利用此路径计算控制信号以准确达到每个航点。", "conclusion": "通过在现实田野数据集上的比较仿真实验，此论文验证了所提框架的有效性。DTSP基于的规划器生成的路径不仅更平滑，长度也减少约16%，相比之下传统的分离方法。NMPC控制器有效地引导机器人达到所需航点，并在局部优化路径的同时遵守约束条件。这些研究结果表明，所提出的框架在农用环境中具有高效的自主导航潜力。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23365", "html_url": "https://arxiv.org/abs/2507.23365", "title": "我创造了这些（某种程度上）：与基于提示的人工智能音乐生成进行作者身份协商、直面虚假性以及探索新的音乐空间", "title_en": "\"I made this (sort of)\": Negotiating authorship, confronting fraudulence, and exploring new musical spaces with prompt-based AI music generation", "authors": "Bob L. T. Sturm", "background": "作者回顾了自己利用最先进的提示驱动的人工智能音乐生成平台创作了两张音乐专辑的经历。第一张专辑聚焦于将垃圾邮件与这些平台结合后会发生什么。第二张专辑则是对第一张专辑的直接回应，探讨了现有的提示驱动的人工智能音乐生成平台在创作音乐时不可避免的“练习、精致和制作”，以及由此带来的挑战和反思。", "innovation": "作者利用语言模型进行自我访谈，以更深层次地探讨创作过程中的多个问题，包括作者身份的确定、个人音乐身份的变化、以及与高度天赋的机器进行的对话所带来的新音乐空间的探索。这种方法为作者和观众提供了新的视角和体验。", "conclusion": "作者反思了自己的反思过程，以及通过语言模型进行的自我反思方法。这种方法不仅考察了创作者的身份和角色，还开辟了新的音乐创作和体验的空间，对于未来的音乐创作和表现形式提供了新的可能性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23272", "html_url": "https://arxiv.org/abs/2507.23272", "title": "使用SAM2实现3D乳腺MRI的负担得起的肿瘤分割与可视化", "title_en": "Towards Affordable Tumor Segmentation and Visualization for 3D Breast MRI Using SAM2", "authors": "Solha Kang,Eugene Kim,Joris Vankerschaver,Utku Ozbulak", "background": "乳腺MRI因其高分辨率的体积成像对于肿瘤评估和治疗规划至关重要，但其3D扫描的手动解释仍是一项繁琐且主观的任务。尽管AI主导的工具有望加速医学影像分析，但在低收入和中等收入国家中，由于高昂的许可费用、专有软件和基础设施需求，商业医学AI产品仍受到限制。本研究探讨了Segment Anything Model 2 (SAM2)是否能够适应低成本、低介入的3D肿瘤分割，通过在单个切片中标注一个边界框并使用三种不同的切片级跟踪策略：从上到下、从下到上和中心向外，评估这些策略在大量患者中的表现，发现中心向外的传播策略在一致性与准确性上最为突出，即使作为零样本模型，SAM2在最小监督下也能实现强大的分割性能，进一步分析了分割性能与肿瘤大小、位置和形状之间的关系，指出关键的失败模式，结果表明通用基础模型如SAM2可以支持3D医学影像分析，提供低资源条件下可负担的替代方案。", "innovation": "使用Segment Anything Model 2 (SAM2) 进行3D乳腺MRI的肿瘤分割，通过最小的注释和监督实现高精度的肿瘤分割，并发现了一种最优的传播策略，即使在缺乏充分数据训练的情况下也能够有效进行肿瘤分割，为资源受限环境提供了可负担的替代方案。", "conclusion": "通用基础模型如SAM2能够在较低资源和监督水平下支持3D医学影像分析，中心向外的传播策略在此类任务中表现最佳，这为低收入和中等收入国家的医学影像诊断提供了有前景的解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23315", "html_url": "https://arxiv.org/abs/2507.23315", "title": "超轻量级深度学习模型在实时图像分类中的超参数优化对准确率的影响", "title_en": "Impact of Hyperparameter Optimization on the Accuracy of Lightweight Deep Learning Models for Real-Time Image Classification", "authors": "Vineet Kumar Rakesh,Soumya Mazumdar,Tapas Samanta,Sarbajit Pal,Amitabha Das", "background": "轻量级卷积和Transformer模型因其实时性要求和资源限制应用（如嵌入式系统和边缘设备），已经变得至关重要。本研究在ImageNet-1K数据集上训练了七种高效的深度学习架构，包括EfficientNetV2-S、ConvNeXt-T、MobileViT v2（XXS/XS/S）、MobileNetV3-L、TinyViT-21M和RepVGG-A2，所有模型在一致的训练设置下进行训练，重点关注实时实用性。", "innovation": "通过进行全面的消除研究，分离关键超参数的影响，包括学习率调度、批量大小、输入分辨率、数据增强、正则化方法和优化器选择等。评估模型不仅基于Top-1和Top-5分类准确率，还基于推理时间、参数数量、模型大小和每秒帧数（FPS）进行评估，特别是在基于GPU加速的边缘部署仿真中。结果显示，余弦学习率衰减和可调批量大小可显著提高准确性和收敛速度，同时保持低延迟和低内存成本。", "conclusion": "结果为构建适用于实时图像处理管道的资源高效型深度学习模型提供了实用指导。RepVGG-A2表现出高效推理性能且Top-1精度超过80%，提供了VGG风格模型在准确性和部署成本之间的一种有效平衡。所有代码和训练日志在此处公开：提供的链接。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23318", "html_url": "https://arxiv.org/abs/2507.23318", "title": "FastDriveVLA: 通过即插即用重建基础的标记剪枝实现高效的端到端驾驶", "title_en": "FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning", "authors": "Jiajun Cao,Qizhe Zhang,Peidong Jia,Xuhui Zhao,Bo Lan,Xiaoan Zhang,Xiaobao Wei,Sixiang Chen,Zhuo Li,Yang Wang,Liyun Li,Xianming Liu,Ming Lu,Shanghang Zhang", "background": "VLA模型在复杂场景理解和动作推理方面展现出巨大的潜力，因而被广泛应用于端到端的自动驾驶系统中。然而，VLA模型中较长的视觉标记增加了计算成本。当前在视觉语言模型（VLM）中常用的视觉标记剪枝方法，如基于视觉标记相似性和视觉-文本注意力的方法，在自动驾驶场景中的表现不佳。鉴于人类驾驶员在驾驶过程中关注的是相关前景区域，我们强调保留含有前景信息的视觉标记对于有效的决策至关重要。为此，我们提出了一种名为FastDriveVLA的新颖重建基础视觉标记剪枝框架，以专门适应自动驾驶。", "innovation": "FastDriveVLA框架包括一种即插即用的视觉标记剪枝模块ReconPruner，该模块通过MAE样式像素重建优先保留前景信息。我们设计了一种新颖的对抗性的前景-背景重建策略来训练ReconPruner以用于VLA模型的视觉编码器。经过训练的ReconPruner可以在不同的VLA模型中无缝应用而不需重新训练。此外，我们还引入了一个大型数据集nuScenes-FG，包含24.1万组带有标注前景区域的图像-掩模对来训练ReconPruner。", "conclusion": "我们的方法在不同的剪枝比率下，在nuScenes封闭环规划基准测试中，达到了最新的技术水平。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23356", "html_url": "https://arxiv.org/abs/2507.23356", "title": "COBOL到Java代码转换的质量评估", "title_en": "Quality Evaluation of COBOL to Java Code Transformation", "authors": "Shmulik Froimovich,Raviv Gal,Wesam Ibraheem,Avi Ziv", "background": "本文介绍了一个自动评估系统，用于评估IBM的watsonx Code Assistant for Z（WCA4Z）中的COBOL到Java代码转换。该系统解决了评估基于LLM（大型语言模型）的翻译器的关键挑战，包括模型不透明性和翻译质量评估的复杂性。", "innovation": "该方法结合了分析检查器与LLM作为裁判的技术（LaaJ），提供了可扩展的、多维度的评估。系统支持持续集成工作流程，能够进行大规模基准测试，并减少对人工审核的依赖。", "conclusion": "该系统架构、评估策略和报告机制提供了可操作的见解，帮助开发人员和项目管理人员促进高质量的现代编代码库的发展。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23386", "html_url": "https://arxiv.org/abs/2507.23386", "title": "Causal2Vec：提高仅解码器大语言模型作为多功能嵌入模型的能力", "title_en": "Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models", "authors": "Ailiang Lin,Zhuoyun Li,Kotaro Funakoshi", "background": "解码器型大型语言模型（LLMs）已广泛应用在构建能够将自然语言文本的语义信息高效编码为密集向量表示的嵌入模型上，应用于多种嵌入任务。然而，现有的许多方法主要是在LLMs中去除因果注意力遮罩以实现双向关注，这在理论上可能削弱模型在预训练过程中提取到的语义信息的能力。此外，当前的单向方法大多依赖增加额外的输入文本以克服因果关注的固有限制，导致计算成本提高。", "innovation": "本文提出了一种通用的嵌入模型Causal2Vec，旨在提升仅解码器LLMs的性能，而不改变其原始架构或增加显著的计算开销。具体来说，Causal2Vec通过引入一个轻量级BERT风格的模型，将输入文本预编码为单一上下文标记并插入到LLMs的输入序列中，使每一令牌即使不关注未来令牌也能捕获上下文信息。另外，Causal2Vec还通过连接上下文令牌和结束标记的最后隐藏状态作为最终文本嵌入来减轻近期偏见，从而帮助LLMs更好地利用上下文令牌中编码的语义信息。", "conclusion": "实验表明，Causal2Vec在其仅使用公开检索数据集训练的模型中，在大规模文本嵌入基准（MTEB）上实现了最先进性能，同时减小了所需序列长度最多85%，缩短了推理时间最多82%与最佳方法相比而言。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23358", "html_url": "https://arxiv.org/abs/2507.23358", "title": "Text-to-SQL Task-oriented Dialogue Ontology Construction", "title_en": "Text-to-SQL Task-oriented Dialogue Ontology Construction", "authors": "Renato Vukovic,Carel van Niekerk,Michael Heck,Benjamin Ruppik,Hsien-Chin Lin,Shutong Feng,Nurul Lubis,Milica Gasic", "background": "大型语言模型（LLMs）作为通用知识来源被广泛使用，但它们依赖于参数化的知识，限制了可解释性和可信度。在任务导向对话系统（TOD系统）中，这种分离是明确的，使用结构化的外部数据库和显式的本体论来确保可解释性和可控性。然而，构建这样的本体论需要手动标签或监督训练。", "innovation": "提出TeQoDO：一种文本到SQL任务导向对话本体论构建方法。这种方法使LLM能够在没有监督的情况下，利用其固有的SQL编程能力和提示中提供的对话理论，自主构建TOD本体论。实验证明，TeQoDO优于迁移学习方法，并且构建的本体论在下游对话状态跟踪任务中表现良好。消除实验表明了对话理论的关键作用。TeQoDO还可以扩展到构建更大规模的本体论，我们在Wikipedia和ArXiv数据集上进行了研究。这被视为使本体论在更广泛的应用中提高LLM可解释性的一个步骤。", "conclusion": "研究表明，TeQoDO方法在构建TOD本体论方面表现出色，并且这种方法能够扩展以构建更大规模的本体论。通过引入TeQoDO，有望进一步提高大型语言模型的可解释性，使其在更多场景中得到应用。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23334", "html_url": "https://arxiv.org/abs/2507.23334", "title": "MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation", "title_en": "MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation", "authors": "Daeyong Kwon,SeungHeon Doh,Juhan Nam", "background": "近年来，大规模语言模型（LLMs）在多个领域展现了令人印象深刻的能力，尤其是在零样本（zero-shot）任务上表现出色。然而，由于音乐领域知识在训练数据中的比例较低，大多数LLMs在音乐相关应用中的效果有限。现有方法主要通过传统的微调（fine-tuning）来适应音乐任务，这种方法的有效性受限，尤其是在跨域应用中表现不佳。为了填补这一空白，本文提出了MusT-RAG框架，该框架基于Retrieval Augmented Generation（RAG）技术，旨在优化一般目的LLMs以应对文字形式的音乐问答任务（MQA）", "innovation": "提出的MusT-RAG框架包括两个关键创新点：1) 创建了一个专为音乐领域设计的向量数据库MusWikiDB，在检索阶段提供相关的背景知识；2) 使用上下文信息进行推理和微调过程，有效将一般目的的LLM转变为音乐领域专用模型。这些创新使得MusT-RAG在增强LLMs跨音乐领域的适应性方面取得了显著的效果，尤其是在同域和跨域的MQA基准上表现持续的改进。此外，研究表明MusWikiDB相较于通用的维基百科语料库更有效，能够提供更好的性能和计算效率", "conclusion": "实验结果表明，MusT-RAG在提高LLMs在音乐领域适应性方面显著优于传统的微调方法，表现出一致的改进。同时，MusWikiDB证明了在音乐领域中比通用维基百科语料库更具优势，提供了更好的性能和计算效率。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23455", "html_url": "https://arxiv.org/abs/2507.23455", "title": "机器学习与机器学习预测在胸部X射线图像中的应用", "title_en": "Machine learning and machine learned prediction in chest X-ray images", "authors": "Shereiff Garrett,Abhinav Adhikari,Sarina Gautam,DaShawn Marquis Morris,Chandra Mani Adhikari", "background": "机器学习和人工智能正快速发展，这些领域利用数据来训练算法、学习模式并作出预测。这种方法有助于通过识别数据中的复杂关系，以显著的准确性解决看似复杂的问题，而无需显式编程。本研究使用5824张胸部X光片作为示例，实施了两种机器学习算法——基础卷积神经网络（CNN）和DenseNet-121，用于诊断患者疾病的预测。", "innovation": "本研究创新性地使用了DenseNet-121进行胸部X光图像的预测，结果表明DenseNet-121相比基础CNN在决策制定中能更准确地关注输入图像的关键部分，这有助于提高疾病的预测准确性。", "conclusion": "本研究使用卷积神经网络和DenseNet-121两种模型对5824张胸部X光图像进行疾病预测的分析表明，这两种模型在二分类问题上表现良好。特别是DenseNet-121在判定过程中集中注意力于输入图像的关键部分，展示了更高的预测准确性和更好的性能。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23382", "html_url": "https://arxiv.org/abs/2507.23382", "title": "MPCC：多模态大型语言模型中具有复杂约束的多模态规划的新基准", "title_en": "MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models", "authors": "Yiyan Ji,Haoran Chen,Qiguang Chen,Chengyue Wu,Libo Qin,Wanxiang Che", "background": "当前基准测试无法直接评估多模态实际规划能力，并且缺乏跨模态的约束或隐含约束。这限制了在多步复杂推理和决策中的应用。为了应对这些挑战，这项研究引入了Multimodal Planning with Complex Constraints (MPCC)，第一个系统性地评估MLLMs在处理多模态约束规划方面能力的基准测试。", "innovation": "MPCC首次系统性地评估MLLMs在处理多模态约束规划方面的能力，特别关注飞行规划、日历规划和会议规划三大实际任务，并引入了预算、时间和空间等地域性的复杂约束，这些约束具有逐步提高的难度级别（EASY、MEDIUM、HARD），从而分离了约束复杂性与搜索空间扩展。实验结果显示，封闭源模型仅实现21.3%的可行方案，而开源模型平均不到11%。此外，研究指出MLLMs对约束复杂性高度敏感，传统的多模态提示策略在多约束场景下失败。这项工作提出了多模态约束的正规化，提供了严格的评估框架，并指出了在实际MLLM应用中需要提高约束意识推理的重要性。", "conclusion": "这项工作正式化了在规划中处理多模态约束，提供了严格评估框架，并强调了在实际MLLM应用中需要提高约束意识推理的需求。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23370", "html_url": "https://arxiv.org/abs/2507.23370", "title": "Trae Agent: 基于LLM的软件工程代理，具备测试时扩展能力", "title_en": "Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling", "authors": "Trae Research Team:Pengfei Gao,Zhao Tian,Xiangxin Meng,Xinchen Wang,Ruida Hu,Yuanan Xiao,Yizhou Liu,Zhao Zhang,Junjie Chen,Cuiyun Gao,Yun Lin,Yingfei Xiong,Chao Peng,Xia Liu", "background": "软件问题解决在软件工程中是一个关键挑战，并且近年来受到了越来越多的关注。随着大型语言模型（LLMs）的快速发展，已经取得了一些在解决真实世界软件工程任务方面的重要进展。近年来的研究引入了集成推理技术来提高基于LLM的问题解决性能。然而，现有的基于提示的方法仍然在有效探索大规模集成空间和仓库级别理解方面存在局限性，这限制了它们的整体效果。", "innovation": "本文提出Trae Agent，这是首个基于代理的仓库级别问题解决的集成推理方法。Trae Agent将我们的目标公式化为最优解搜索问题，并通过生成、剪枝和选择的模块化代理来解决两个关键挑战，即大规模集成空间和仓库级别理解。", "conclusion": "我们进行了广泛的实验，使用三个领先的LLM在广泛采用的SWE-bench基准上，将Trae Agent与四种最先进的集成推理技术进行比较。实验结果显示，Trae Agent在Pass@1方面持续表现出更优的性能，平均提高10.22%。Trae Agent在SWE-benchVerified排行榜上获得第一名，Pass@1得分为75.20%。我们很高兴将Trae Agent开源，以支持研究社区，所有资源均可通过以下链接获取。\n"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23470", "html_url": "https://arxiv.org/abs/2507.23470", "title": "使用大型语言模型对学生成生成的UML和ER图提供自动反馈", "title_en": "Automated Feedback on Student-Generated UML and ER Diagrams Using Large Language Models", "authors": "Sebastian Gürtl,Gloria Schimetta,David Kerschbaumer,Michael Liut,Alexander Steinmaurer", "background": "UML和ER图是计算机科学教育中的基础工具，但由于需要抽象思维、上下文理解以及掌握语法规则和语义内容，给学习者带来了挑战。传统的教学方法难以提供可扩展、个性化的反馈，尤其是在大班教学中。因此，需要一种新的解决方案来解决这些复杂性问题，以提高学习成效并促进自主学习能力的发展和教学策略的改进。", "innovation": "我们介绍了DUET（Diagrammatic UML & ER Tutor），这是一种基于LLM的原型工具，能够将参考图和学生提交的图转换为文本表示，并根据差异提供结构化的反馈。它采用多阶段LLM流水线来比较图表并生成反思性反馈。此外，该工具还为教育者提供了分析洞察，以促进自主学习并改进教学策略。该工具通过半结构化的访谈评估，参与评估的6名参与者（包括两位教师和四名助教）指出了其优点和局限性，并提出了改进建议，如批量上传功能和交互式解释功能。", "conclusion": "DUET为将LLMs集成到建模教育中提供了有希望的方向，并为将来的课堂集成和实证研究奠定了基础。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23461", "html_url": "https://arxiv.org/abs/2507.23461", "title": "在联邦学习中缓解关键点检测中的分辨率漂移：一种方法", "title_en": "Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection", "authors": "Taeheon Lim,Joohyung Lee,Kyungjae Lee,Jungchan Cho", "background": "联邦学习（FL）能够在分布式系统中实现有效的学习，同时保护用户数据隐私。现有研究主要集中在解决统计异质性和通信效率问题上，使得FL在分类任务上取得了成功。然而，FL在非分类任务，如人体姿态估计的应用上仍较少被探讨。本文识别并研究了一个被称为‘分辨率漂移’的关键问题，该问题由于客户端间分辨率的变化导致性能显著下降。与类别级别的异质性不同，分辨率漂移突显了分辨率作为非独立且非同分布（non-IID）数据的一部分的重要性。", "innovation": "本文提出了分辨率自适应联邦学习（RAF），该方法利用基于热力图的知识精炼，通过不同分辨率输出（教师）和较低分辨率输出（学生）之间的多分辨率知识精炼，增强了分辨率鲁棒性，同时避免过拟合。理论分析和实验结果表明，RAF不仅能有效缓解分辨率漂移，提高性能，并且可以无缝集成到现有的FL框架中。虽然本文主要针对关键点检测任务（即人体姿态估计），但t-SNE分析揭示了分类任务和高分辨率表示任务之间的区别，支持了RAF在依赖保持空间细节的任务中的普适性。", "conclusion": "RAF方法能够有效缓解分辨率漂移问题，提升在人体姿态估计等高分辨率任务上的性能表现，并且其方法论可以适用于其他依赖于保持空间细节的任务。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23459", "html_url": "https://arxiv.org/abs/2507.23459", "title": "KLAN: 快手智能着陆页导航系统", "title_en": "KLAN: Kuaishou Landing-page Adaptive Navigator", "authors": "Fan Li,Chang Meng,Jiaqi Fu,Shuchang Liu,Jiashuo Zhang,Tianke Zhang,Xueliang Wang,Xiaoqiang Feng", "background": "现代在线平台通过配置多个页面来满足用户多样化的需求。这一多页面结构定义了用户与平台之间的两阶段交互模式：第一阶段是页面导航，将用户引导至特定页面；第二阶段是在页面交互中，用户与定制内容进行互动。当前的研究主要集中在第二阶段的序列推荐任务以优化用户的反馈，然而对如何在第一阶段实现更好的页面导航的研究较少。本文为此填补了这一缺口。", "innovation": "本文正式定义了个性化着陆页建模（PLPM）任务，并提出了KLAN（快手着陆页自适应导航系统），这是一个分层的解决方案框架，用于在PLPM框架下提供个性化页面。KLAN包含三个关键组件：KLAN-ISP（跨日静态页面偏好捕获）、KLAN-IIT（日内动态兴趣转移捕获）和KLAN-AM（结合组件进行最优导航决策）。实验结果表明KLAN在每日活跃用户（DAU）和用户留存（LT）方面分别提高了0.205%和0.192%。KLAN已部署在快手平台上，服务于上亿用户。", "conclusion": "本文为PLPM领域建立了实证，提供了有效的解决方案KLAN，通过该模型在实际平台上显著提高了用户参与度和留存率，并计划在论文被接受后分享数据集和代码。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23535", "html_url": "https://arxiv.org/abs/2507.23535", "title": "透明的人工智能：可解释性的案例", "title_en": "Transparent AI: The Case for Interpretability and Explainability", "authors": "Dhanesh Ramachandram,Himanshu Joshi,Judy Zhu,Dhari Gandhi,Lucas Hartman,Ananya Raval", "background": "随着人工智能系统在各个领域的关键决策中发挥越来越重要的作用，透明度已变得对于负责任且可信赖的人工智能实施至关重要。文章基于作者作为人工智能研究的领先机构，并促进其在工业中的应用，总结了跨不同领域的可解释性应用的关键见解和经验教训。", "innovation": "文章提供了一套针对不同阶段人工智能成熟度组织的可操作策略和实施指南，特别强调将可解释性作为核心设计原则，而不是后期添加的功能。", "conclusion": "文章提出了将可解释性融入人工智能系统作为核心设计原则的方法，强调在开发过程中就应考虑透明性和解释性，而不是等到实施后再进行补充。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23402", "html_url": "https://arxiv.org/abs/2507.23402", "title": "AGA：一种用于结构化医学跨模态表示学习的自适应分组对齐框架", "title_en": "AGA: An adaptive group alignment framework for structured medical cross-modal representation learning", "authors": "Wei Li,Xun Gong,Jiao Li,Xiaobin Sun", "background": "医学图像和报告的视觉表示学习是一个有前景的方向。然而，现有的医学领域视觉-语言预训练方法通常将临床报告简化为单个实体或碎片化的标记，忽视了其固有的结构。此外，对比学习框架通常依赖大量的困难负样本，这在小型医学数据集上是不切实际的。", "innovation": "提出了一种新的框架AGA，用于从配对的医学图像和报告中捕获结构化的语义。AGA引入了一种基于稀疏相似矩阵的双向分组机制。通过设计两个阈值门控模块，即语言分组阈值门和视觉分组阈值门，动态学习分组阈值。通过实例感知的分组对齐损失，解决了无需外部负样本的问题，进一步增强了视觉和语言组表示之间的细粒度对齐。", "conclusion": "在公共和私人数据集上的广泛实验表明，该方法在微调和零样本条件下，对于图像-文本检索和分类任务表现优异。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23492", "html_url": "https://arxiv.org/abs/2507.23492", "title": "数字素养干预可以提升人类识别虚假图像的能力", "title_en": "Digital literacy interventions can boost humans in discerning deepfakes", "authors": "Dominique Geissler,Claire Robertson,Stefan Feuerriegel", "background": "深度假图像，即由人工智能生成的图像，可能会侵蚀人们对机构的信任，并可能破坏选举结果。由于人们往往难以区分真实的图像和深度假图像，因此提高数字素养可以帮助应对这一挑战。然而，可扩展且有效的干预措施仍然鲜有探索。本研究旨在比较五种数字素养干预措施的效果，以提高人们对虚假图像的鉴别能力：文本指导、视觉演示、游戏化练习、重复暴露和反馈的隐性学习以及解释深度假图像生成过程。研究在一个涉及1200名美国参与者的实验中测试了这些干预措施的有效性。结果表明，这些干预措施可以使人们对虚假图像的鉴别能力提升13个百分点，并保持对真实图像的信任。", "innovation": "本研究创新性地比较了五种数字素养干预措施的效果，并通过大规模实验证实它们在提升虚假图像鉴别能力方面的优异效果，同时保持对真实信息的信任。这五种干预措施分别是：文本指导、视觉演示、游戏化练习、重复暴露和反馈的隐性学习、以及解释深度假图像生成过程。这些干预措施被认为是可扩展的，适用于各种人群，并且在提升虚假图像检测能力方面非常有效，同时保持对真实信息的信任。", "conclusion": "本研究的结论是，通过数字素养干预措施可以有效提高人们对虚假图像的识别能力，同时保持对真实信息的信任。本研究的方法是可扩展的，适用于各种人群，在提升虚假图像检测能力方面非常有效。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23509", "html_url": "https://arxiv.org/abs/2507.23509", "title": "我很大，你很小；我正确，你错误", "title_en": "I Am Big, You Are Little; I Am Right, You Are Wrong", "authors": "David A. Kelly,Akchunya Chanchal,Nathan Blake", "background": "图像分类中的机器学习是一个活跃且快速发展的领域。随着不同大小和结构的分类器的增多，选择合适的模型变得越来越重要。虽然可以通过统计方式评估模型的分类准确性，但我们对这些模型的工作方式的理解却很有限。为了更好地理解不同视觉模型的决策过程，本文引入了使用最小充分像素集来衡量模型的“聚焦性”，即哪些像素能通过模型捕捉到图像的本质。这种方法通过比较像素集的位置、重叠和大小，揭示了不同架构在聚焦性方面存在统计差异，并指出 ConvNext 和 EVA 模型与其他模型相比有显著不同。此外，文章还发现误分类的图像与更大的像素集相关联，而正确分类的图像与较小的像素集相关联。", "innovation": "本文提出了使用最小充分像素集来衡量模型的“聚焦性”，并通过比较像素集的位置、重叠和大小，发现不同架构的模型在聚焦性方面存在显著差异，特别是 ConvNext 和 EVA 模型与其他模型存在明显区别。此外，还揭示了误分类和正确分类的图像与像素集大小之间的关联性。", "conclusion": "研究表明，不同架构的视觉模型在如何聚焦于关键图像特征方面存在差异，这可通过像素集的统计特性来衡量。此外，模型的聚焦性与分类准确性之间存在关系，这为理解模型的决策过程提供了新的视角。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23511", "html_url": "https://arxiv.org/abs/2507.23511", "title": "MECAT: 多专家构建的细粒度音频理解基准", "title_en": "MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks", "authors": "Yadong Niu,Tianzi Wang,Heinrich Dinkel,Xingwei Sun,Jiahao Zhou,Gang Li,Jizhong Liu,Xunying Liu,Junbo Zhang,Jian Luan", "background": "尽管大型音频语言模型已大幅提升了对开放音频的理解能力，但它们在细腻的人类水平理解方面仍然存在差距。当前的基准测试受限于数据标注和评估指标，无法可靠地区分通用和详细的模型输出，导致这一差距持续存在。", "innovation": "本文引入了MECAT——多专家构建的细粒度音频理解基准。通过将专门专家模型的分析与链式思维大型语言模型推理相结合的流程生成。MECAT提供了多视角的精细描述和开放问题-回答对。基准测试还补充了一个新的评价指标：DAT的增强音频文本评价（DATE）。该指标通过结合单个样本的语义相似性和跨样本的区分性对通用术语进行惩罚并奖励详细的描述。", "conclusion": "本文对最先进音频模型进行了综合评估，提供了其当前能力和限制的新见解。数据和代码可在此处获取：this https URL"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23465", "html_url": "https://arxiv.org/abs/2507.23465", "title": "组织中安全且上下文化的访问控制的角色感知语言模型", "title_en": "Role-Aware Language Models for Secure and Contextualized Access Control in Organizations", "authors": "Saeed Almheiri,Yerulan Kongrat,Adrian Santosh,Ruslan Tasmukhanov,Josemaria Vera,Muhammad Dehan Al Kautsar,Fajri Koto", "background": "由于大型语言模型（LLMs）在企业环境中的逐渐应用，基于用户角色控制模型行为变得非常重要。现有的安全性方法通常假设用户访问是统一的，并专注于防止有害或有毒的输出，而不考虑角色特定的访问限制。为此，本研究探讨了是否可以微调LLMs，使其生成反映不同组织角色相关访问权限的回答。通过两个互补的数据集来评估这些方法，其中一个是从现有指令微调语料库通过聚类和角色标注改编而来，另一个则是根据现实的、角色敏感的商业场景合成生成的。该研究探讨了不同的模型策略，并分析了模型在不同组织结构下的性能，以及在提示注入、角色不匹配和模型偏离时的稳健性。", "innovation": "本文提出了一种新颖的方案，通过微调大型语言模型（LLMs），使其生成反映不同组织角色访问权限的回答。该方案探索了三种建模策略：基于BERT的分类器、基于LLM的分类器和基于角色控制生成。通过两个数据集评估了这三种策略，数据集分别通过聚类和角色标注导出，以及合成生成真实的、角色敏感的企业场景。同时，研究还分析了模型在不同结构下的性能，以及面对提示注入、角色不匹配和模型偏离时的稳健性。", "conclusion": "本研究证明了通过微调大型语言模型（LLMs），可以生成反映不同组织角色访问权限的响应，这为在组织中安全且上下文化的访问控制提供了新的思路。通过评估不同的模型策略和两个互补的数据集，本研究展示了模型在各种组织结构调整下以及面对提示注入、角色不匹配和模型偏离时的性能和稳健性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23543", "html_url": "https://arxiv.org/abs/2507.23543", "title": "ART: 自适应关系调优以实现泛化关系预测", "title_en": "ART: Adaptive Relation Tuning for Generalized Relation Prediction", "authors": "Gopika Sudhakaran,Hikaru Shindo,Patrick Schramowski,Simone Schaub-Meyer,Kristian Kersting,Stefan Roth", "background": "视觉关系检测（VRD）任务旨在识别场景中对象之间的关系。仅通过关系检测数据训练的VRD模型难以泛化到训练数据以外的关系。尽管使用提示调整方法可以适应视觉语言模型（VLMs）进行VRD，但这种方法依赖于手工设计的提示，并且在处理新颖或复杂的关系时存在困难。", "innovation": "我们提出了一种通过指令调整和战略性实例选择来适应视觉语言模型进行VRD的新框架——ART（Adaptive Relation Tuning）。通过将VRD数据集转换为一种指令调整格式并采用自适应采样算法，ART能引导VLM集中于有信息性的关系同时保持泛化能力。具体而言，本文聚焦于关系分类任务，通过给定主语-宾语框并预测它们之间的谓语来实现这一目标。在不同复杂度的测试数据集上进行微调和评估，结果显示我们的方法显著优于基准方法，并能够推断出未见过的关系概念，这在主流VRD方法中是不具备的。", "conclusion": "我们展示了ART的实用价值，通过预测的关系来分割复杂场景。通过这种方法，本文的方法在多个测试数据集上的表现都优于基准方法，证明了ART框架的有效性和创新性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23536", "html_url": "https://arxiv.org/abs/2507.23536", "title": "从大型语言模型到边缘设备：边端设备上的参数高效微调", "title_en": "From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices", "authors": "Georg Slamanig,Francesco Corti,Olga Saukh", "background": "参数高效微调（PEFT）方法通过减少附加参数的数量来降低更新深度学习模型的计算成本，这种方法在大型语言模型（LLMs）中得到了广泛研究，但在边缘设备上使用的较小模型（如卷积神经网络）上的应用则较为不足。因此，本文在资源受限的边缘环境中对流行的PEFT方法在卷积架构上的应用进行了基准测试和分析。", "innovation": "利用PyTorch自带的性能分析工具对洛RA、DoRA和GaLore等几种PEFT方法在标准和深度卷积架构上的更新性能和计算成本进行了比较，特别是在硬件效率方面进行了深入研究。结果表明，当应用于深度可分离卷积架构时，评估的PEFT方法在内存效率上比应用于LLMs时低一半，但在针对边缘部署优化的卷积架构中，基于适配器的PEFT方法可降低高达95%的浮点操作（FLOPs）。这些发现提供了根据硬件限制、性能需求和应用场景选择PEFT方法的宝贵指导。", "conclusion": "本文的见解为根据硬件约束、性能要求和应用需求选择适当的PEFT方法提供了有价值的指导，同时也提出了基于边缘设备优化的PEFT方法的潜在优势和局限性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23540", "html_url": "https://arxiv.org/abs/2507.23540", "title": "适应性自主驾驶的统一感知-语言-行动框架", "title_en": "A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving", "authors": "Yi Zhang,Erik Leo Haß,Kuo-Yi Chao,Nenad Petrovic,Yinglei Song,Chengdong Wu,Alois Knoll", "background": "自主驾驶系统在复杂、开放环境中的适应性、鲁棒性和可解释性方面面临巨大挑战，这些问题源于架构碎片化、对新情境的泛化能力有限以及感知提取语义的不足。", "innovation": "提出了一种统一的感知-语言-行动(PLA)框架，将多传感器融合（摄像头、LiDAR、雷达）与大型语言模型（LLM）增强的Vision-Language-Action (VLA)架构相结合，特别是使用GPT-4.1增强的推理核心。该框架将低级别感官处理与高级上下文推理统一起来，紧密耦合感知和基于自然语言的语义理解与决策，以实现情境感知、可解释且安全的自动驾驶。", "conclusion": "在包含施工区的城区交叉口场景上的评估显示，该框架在轨迹跟踪、速度预测和自适应规划方面表现出色。结果突显了语言增强的认知框架在提高自动驾驶系统安全、可解释性和扩展性方面的发展潜力。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23607", "html_url": "https://arxiv.org/abs/2507.23607", "title": "基于深度学习的临床试验入组人数预测及其不确定性估计", "title_en": "Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates", "authors": "Tien Huu Do,Antoine Masquelier,Nae Eoun Lee,Jonathan Crowther", "background": "临床试验是一项系统地评估新药物或治疗方法的安全性和有效性的过程。通常需要大量的资金投入和精心的规划，因此准确预测试验结果至关重要。在计划阶段，准确预测患者入组情况是主要挑战之一，因为这直接影响到试验的成功与否。本文探讨了一种基于深度学习的方法来解决这一挑战，旨在通过预测患者的入组情况，提高临床试验的成功率和效率。", "innovation": "本文提出了一种基于深度学习的方法，该方法通过使用预训练语言模型（PLMs）来捕捉临床文档的复杂性和细微差异，将其转化为有表现力的表示，然后通过注意力机制与编码的表格特征结合。此外，通过引入基于Gamma分布的概率层来处理入组预测中的不确定性，能够进行范围估计。该方法假设站点级别入组遵循泊松-伽玛过程，并在现实世界的临床试验数据上进行了广泛实验，表明所提出的方法能够有效地预测给定临床试验下多个站点的入组患者数，优于现有的基线模型。", "conclusion": "本文提出了一种基于深度学习的方法，能够有效地预测临床试验中患者的入组情况，并进行了广泛的实验验证。该方法通过引入基于Gamma分布的概率层来进行不确定性估计，从而提高了预测的准确性和可靠性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23682", "html_url": "https://arxiv.org/abs/2507.23682", "title": "villa-X: 提升视觉语言行动模型中潜在动作建模", "title_en": "villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models", "authors": "Xiaoyu Chen,Hangxing Wei,Pushi Zhang,Chuheng Zhang,Kaixin Wang,Yanjiang Guo,Rushuai Yang,Yucen Wang,Xinquan Xiao,Li Zhao,Jianyu Chen,Jiang Bian", "background": "视觉语言行动（VLA）模型已成为学习机器人操作策略的热门框架，这些策略能够遵循语言指令并泛化到新场景中。最近的研究开始探索如何在VLA预训练中整合潜在动作，这是一种视觉两帧变化的抽象表示。本文基于此背景展开，讨论了如何改进潜在动作的建模和整合问题，针对这些问题提出了一个新的框架，命名为villa-X，以增强整体性能并推广到模拟和真实世界的应用中。", "innovation": "villa-X 引入了一个新颖的 Visual-Language-Latent-Action (ViLLA) 框架，该框架改进了潜在动作的学习方式以及它们在 VLA 预训练中的整合方式。通过这些贡献，villa-X 能够在 SIMPLER 和 LIBERO 的模拟环境中，以及对两个真实世界机器人设置中的夹爪操作和灵巧手操作取得更优的性能。", "conclusion": "ViLLA 架构显示出巨大的前景，我们相信 villa-X 为未来的研究提供了一个坚实的基础。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23611", "html_url": "https://arxiv.org/abs/2507.23611", "title": "基于LLM的从截屏中识别信息窃取者感染向量：以Aurora为例", "title_en": "LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora", "authors": "Estelle Ruellan,Eric Clay,Nicholas Ascoli", "background": "信息窃取者（Infostealers）会从受感染系统中窃取凭证、会话cookies和敏感数据。2024年报告了超过2900万份信息窃取日志，手动分析和大规模缓解几乎不可能实现。常见的研究大多集中在主动恶意软件检测，但在利用信息窃取日志及其关联的元数据进行反应性分析方面仍存在显著差距。目前的文献很少关注感染的元数据，例如感染屏幕截图等。因此，本文通过使用大型语言模型（LLMs），特别是gpt-4o-mini，来分析感染屏幕截图，提取潜在的指标（IoCs），映射感染路径并追踪恶意活动，旨在填补该领域的空白。", "innovation": "本文提出了一种新颖的方法，利用大型语言模型（LLMs）分析感染屏幕截图，提取潜在的指标（IoCs），映射感染路径并追踪恶意活动。这种方法专注于Aurora信息窃取者，通过处理屏幕截图来识别感染路径，如恶意网址、安装文件和被利用的软件主题。研究表明，该方法可以从1000张屏幕截图中提取出337个行动性URL和246个相关的文件，揭示了关键的恶意软件分发方法和社会工程学手段。", "conclusion": "本文主要介绍了利用大型语言模型分析感染屏幕截图的方法，并展示了这种方法在密谋性分析中的潜力，以及如何通过关联提取的文件名、URL和感染主题来识别不同的恶意软件活动。最终提出了一种基于证据的感染路径识别方法，可以有效识别感染路径并实现早期干预。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23638", "html_url": "https://arxiv.org/abs/2507.23638", "title": "OptiGradTrust: 通过多特征梯度分析和基于强化学习的信任加权实现鲁棒联邦学习", "title_en": "OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting", "authors": "Mohammad Karami,Fatemeh Ghassemi,Hamed Kebriaei,Hamid Azadegan", "background": "联邦学习（FL）允许多个医疗机构协作进行模型训练，同时保护患者隐私，但仍然容易受到拜占庭攻击和统计异质性的威胁。本文探讨了这些攻击的影响，并提出了OptiGradTrust框架来解决这些问题。", "innovation": "OptiGradTrust通过构建一个综合的防御框架，利用梯度更新的六维指纹（包括VAE重构误差、余弦相似度指标、$L_2$范数、符号一致性比率、蒙特卡洛夏普ley值）驱动混合RL-注意力模块进行自适应信任评分。此外，还开发了FedBN-Prox（FedBN-P）方法，结合联邦批量规范化和近端正则化，以实现准确性和收敛性的最佳权衡。", "conclusion": "实验结果表明，OptiGradTrust在MNIST、CIFAR-10和阿尔茨海默病MRI数据集上的多种拜占庭攻击场景下表现出显著的性能提升，尤其是在非IID条件下，相比FLGuard可以提高高达1.6个百分点，并通过自适应学习方法保持了对各种攻击模式的稳健性能。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23642", "html_url": "https://arxiv.org/abs/2507.23642", "title": "Efficient Masked Attention Transformer for Few-Shot Classification and Segmentation", "title_en": "Efficient Masked Attention Transformer for Few-Shot Classification and Segmentation", "authors": "Dustin Carrión-Ojeda,Stefan Roth,Simone Schaub-Meyer", "background": "Few-shot classification and segmentation (FS-CS)旨在使用少量标注的示例同时执行多标签分类和多类分割。尽管当前最先进的方法在这两项任务中都取得了高精度，但在处理小对象时存在困难。当前的评估设置在评估时会丢弃成本高的标注信息，这与实际情况不符。", "innovation": "提出了一种高效的遮罩注意力变换器（EMAT），它通过引入一种新的内存高效遮罩注意力机制、可学习的下采样策略和参数效率增强，提高了分类和分割精度，特别是对小对象的表现更好。EMAT在PASCAL-5i和COCO-20i数据集上优于所有FS-CS方法，使用至少少4倍的可训练参数量。此外，提出了两种新的评估设置，旨在更真实地反映实际场景，利用可用的标注信息。", "conclusion": "EMAT方法在处理小对象的同时提高了分类和分割的准确性，同时在模型参数量上节省了大量资源，并提出了新的评估方法以更准确地反映实际应用场景。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23669", "html_url": "https://arxiv.org/abs/2507.23669", "title": "自动化AI故障跟踪：AI事件数据库中报告的语义关联", "title_en": "Automating AI Failure Tracking: Semantic Association of Reports in AI Incident Database", "authors": "Diego Russo,Gian Marco Orlando,Valerio La Gatta,Vincenzo Moscato", "background": "人工智能系统正在改变医疗、金融和交通等关键领域，提升了运营效率和决策过程。然而，在高风险领域部署这些系统暴露了其脆弱性，可能导致重大社会危害。为系统地研究并减轻这些风险，已经出现了如AI事件数据库(AIID)等项目，它记录了超过3000个真实世界的AI故障报告。目前，将新报告与合适的AI事件关联主要依赖于专家的手动干预，这限制了可扩展性并延迟了故障模式的识别。", "innovation": "本文提出了一种基于检索的框架，自动将新报告与现有AI事件进行关联，通过语义相似性建模。将任务形式化为排序问题，基于嵌入余弦相似性比较报告（包括标题和完整文本描述）与之前记录的AI事件。通过基准测试传统词法方法、跨编码器架构和基于变换器的句子嵌入模型，我们发现后者在性能上始终优于前者。进一步的分析表明，结合标题和描述比仅使用标题能显著提高排名准确性。此外，检索性能在描述长度变化时保持稳定，突显了该框架的稳健性。最后，发现随着训练集的扩大，检索性能持续提高。该方法为支持AIID的维护提供了可扩展且高效的方法。", "conclusion": "本文提出了一个自动化关联新报告与现有AI事件的检索框架，通过语义相似性建模将任务形式化为排序问题，使用嵌入余弦相似性进行比较。该方法通过基准测试传统词法方法、跨编码器架构和基于变换器的句子嵌入模型，发现基于变换器的句子嵌入模型性能最佳。结合标题和描述能显著提高排名准确性。检索性能在语言长度变化时保持稳定，显示了框架的稳健性，并且随着训练集的扩大，检索性能持续提升。此研究提供了一种可扩展且高效的解决方案，以支持AIID的维护。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23615", "html_url": "https://arxiv.org/abs/2507.23615", "title": "L-GTA: 隐含生成模型在时间序列增强中的应用", "title_en": "L-GTA: Latent Generative Modeling for Time Series Augmentation", "authors": "Luis Roque,Carlos Soares,Vitor Cerqueira,Luis Torgo", "background": "时间序列分析的各个领域，包括预测、分类和异常检测任务中，数据增强变得越来越重要。现有的方法对于生成新时间序列数据的效果有限，通常依赖于基本的变换方法，如时间抖动和幅度扭曲。为了克服这些限制，作者提出了一个基于变压器的可变递归自编码器的隐含生成模型——Latent Generative Transformer Augmentation (L-GTA)。L-GTA能够执行复杂的变换，并能够通过组合简单的变换生成更加复杂的时间序列数据集。", "innovation": "L-GTA 使用了基于变压器的变分递归自编码器，通过在模型的隐含空间中进行受控变换来生成保留原始数据集内在属性的新时间序列。它支持包括时间抖动和幅度扭曲在内的多种变换，从而使生成的合成时间序列数据集更加复杂多样。实验显示，L-GTA 能够产生更加可靠、一致和可控制的数据增强效果，从而在预测准确性和相似性措施方面显著优于直接变换方法。", "conclusion": "通过利用 L-GTA 模型，可以有效生成更多可靠、一致和可控制的数据增强，从而在预测准确性和相似性方面实现显著改进。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23589", "html_url": "https://arxiv.org/abs/2507.23589", "title": "LLM-Reasoning Models能否替代经典规划？一项基准研究", "title_en": "Can LLM-Reasoning Models Replace Classical Planning? A Benchmark Study", "authors": "Kai Goebel,Patrik Zips", "background": "大型语言模型（LLM）的发展激发了它们在机器人任务规划中的潜力研究兴趣。尽管这些模型展示了强大的生成能力，但它们产生结构化和可执行计划的有效性仍然存在不确定性。本文研究了一组当前最先进的语言模型在使用规划领域定义语言（Planning Domain Definition Language, PDDL）及其领域和问题文件直接提示下的性能，对比了这些模型在Fast Downward 规划器等一系列基准测试上的计划表现。除了衡量成功率之外，还评估了生成的计划在实际执行时的忠实度，以识别使用语言模型进行规划的强项和局限性。研究表明，这些模型在简单规划任务上表现良好，但在需要精确资源管理、一致状态跟踪和严格约束合规性的复杂场景中仍然存在问题。这些结果揭示了将语言模型应用于机器人规划时的基本挑战，指出在真实环境中的执行过程中出现的差距，旨在引导未来研究采用将语言模型与经典规划器结合的方法，以提升机器人规划在可靠性与可扩展性上的表现。", "innovation": "研究使用了广泛的当前最先进的语言模型，并使用PDDL进行直接提示和评估。这不仅衡量了计划任务的成功率，还评估了在实际执行中生成计划的忠实度。这项研究旨在识别这些模型的强项和局限性，并通过对比Fast Downward 规划器进行基准测试，展示出语言模型在机器人规划中的应用挑战。", "conclusion": "研究发现，尽管这些模型在简单规划任务上表现良好，但在复杂场景中仍面临挑战，如精确资源管理、一致状态跟踪和严格约束规范。研究强调了将在真实环境中应用语言模型进行机器人规划时的基本挑战，为未来采用结合语言模型和经典规划器的方法提供了指导，旨在提升规划在自主机器人中的可靠性和可扩展性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23704", "html_url": "https://arxiv.org/abs/2507.23704", "title": "增强的高斯视频重建中速度场建模", "title_en": "Enhanced Velocity Field Modeling for Gaussian Video Reconstruction", "authors": "Zhenyang Li,Xiaoyang Bai,Tongchen Zhang,Pengfei Shen,Weiwei Xu,Yifan Peng", "background": "高保真3D视频重建对于实现实时渲染虚拟和增强现实中的逼真动态场景至关重要。3D高斯点的形变场模式由于深度形变网络的强大表示能力，在视频重建中已取得接近照片级的真实结果。然而，在复杂运动和显著尺度变化的视频中，形变网络往往过度拟合到不规则的高斯轨迹，导致视觉质量不佳。传统的用于静态场景重建的基于梯度的密集化策略对于动态内容的缺乏难以应对。", "innovation": "提出了一种针对高斯视频重建的速度场增强建模方案，名为FlowGaussian-VR。该方案包括两个核心组件：一种基于光流的速度场渲染管道(VFR)，能够实现基于光流的优化，以及一种流动辅助自适应密集化(FAD)策略，该策略在动态区域调整Gaussians的数量和大小。", "conclusion": "我们的模型在多视角动态重建和包含挑战运动场景的多种真实数据集上的新型视图合成中得到了验证，不仅显示出显著的视觉改进（PSNR提高超过2.5 dB），还减少了动态纹理中的模糊伪影，同时实现了可追踪和正则化的Gaussian轨迹。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23698", "html_url": "https://arxiv.org/abs/2507.23698", "title": "在可迁移空间智能中的可扩展多任务强化学习", "title_en": "Scalable Multi-Task Reinforcement Learning for Generalizable Spatial Intelligence in Visuomotor Agents", "authors": "Shaofei Cai,Zhancun Mu,Haiwen Xia,Bowei Zhang,Anji Liu,Yitao Liang", "background": "尽管强化学习（RL）在语言模型领域取得了显著的成功，但在视觉-运动代理领域中的应用尚未完全实现。RL模型的一个主要挑战是它们倾向于过度拟合特定任务或环境，这阻碍了在各种设置下获得可迁移行为的能力。本文探讨的是，通过展示在Minecraft中对视觉-运动代理进行RL调优可以实现零样本泛化到未见过的世界，从而解决这一挑战。研究聚焦于提高多维度世界中一般空间推理和交互能力，特别是在解决多任务RL表示挑战时，通过分析和建立跨视角的目标规范作为统一的多任务目标空间，拓宽了视觉-运动策略的能力边界。此外，为了克服手动任务设计带来的瓶颈，本文在高度可定制化的Minecraft环境中提出了自动任务合成，适应大规模多任务RL训练的需求，并构建了高效的分布式RL框架来支持这一过程。实验结果表明，RL可以显著提高交互成功率四倍，并使空间推理在多变的环境中实现零样本泛化，包括真实环境。", "innovation": "提出了跨视角的目标规范作为统一的多任务目标空间，用于视觉-运动策略。在高度可定制化的Minecraft环境中实现了自动任务合成，支持大规模多任务RL训练，并构建了高效的分布式RL框架。证明了通过RL训练在Minecraft中的有效泛化能力，特别是在提高空间推理和交互能力方面。", "conclusion": "强化学习训练在3D模拟环境中具有巨大的潜力，特别是在可扩展大型任务生成的环境中，这对于显著推动视觉-运动代理的空间推理能力具有重要意义。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23740", "html_url": "https://arxiv.org/abs/2507.23740", "title": "Rule2Text：知识图谱中逻辑规则的自然语言解释", "title_en": "Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs", "authors": "Nasim Shirvani-Mahdavi,Devin Wingfield,Amin Ghasemi,Chengkai Li", "background": "知识图谱（KGs）中包含丰富的信息，用于推断新事实。发现逻辑规则不仅可以提高知识图谱的完整性，还可以检测潜在错误，揭示隐蔽数据模式，增强整体推理能力和解释能力。然而，这些规则的复杂性及每个KG独特的标签规范使其对人类来说难以理解。", "innovation": "该研究探索了大规模语言模型生成逻辑规则自然语言解释的潜力。使用AMIE 3.5.1规则发现算法从基准数据集FB15k-237及两个大型数据集FB-CVT-REV和FB+CVT-REV中提取逻辑规则，并测试了零样本和少样本提示策略，包括变量实体类型和思维过程推理。通过正确性、清晰度和虚构性对生成的解释进行全面的人类评估，同时评估了大规模语言模型作为自动评判者的使用。", "conclusion": "尽管研究结果在解释的正确性和清晰度方面表现出有希望的性能，但仍有一些未来研究的挑战。该研究的所有脚本和数据在公开网址中可获取。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23694", "html_url": "https://arxiv.org/abs/2507.23694", "title": "多代理地理仿真方法综述：从ABM到LLM", "title_en": "A survey of multi-agent geosimulation methodologies: from ABM to LLM", "authors": "Virginia Padilla,Jacinto Dávila", "background": "本文提供了一个全面分析多代理系统、仿真和信息系统背后的原则和联系的综述，并基于二十年的研究，验证了一个适用于地理仿真平台的正式框架。", "innovation": "研究发现，大型语言模型（LLMs）可以有效地作为代理组件集成，前提是它们遵循特定于基本代理活动如感知、记忆、规划和行动的结构化架构。这种集成与我们所正式化的架构完全一致，为下一代地理仿真系统提供了坚实的基础。", "conclusion": "研究成果明确指出，LLMs可以与多代理系统结合使用，前提是它们采用特定的结构化架构。这为地理仿真平台的开发和应用开辟了新的前景。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23771", "html_url": "https://arxiv.org/abs/2507.23771", "title": "共识驱动的主动模型选择", "title_en": "Consensus-Driven Active Model Selection", "authors": "Justin Kay,Grant Van Horn,Subhransu Maji,Daniel Sheldon,Sara Beery", "background": "现成的机器学习模型的广泛可用性带来了选择问题：在众多候选模型中，哪种模型最适合特定的数据分析任务？传统上，这个问题通过收集和标注验证数据集来解决，这是一项 costly且耗时的过程。因此，需要一种新的方法来提高模型选择效率，减少标注工作负担。", "innovation": "本文提出了一种共识驱动的主动模型选择方法（CODA），通过在概率框架内建模分类器、类别和数据点之间的关系来实现。该方法利用候选池中模型的一致性和分歧来指导标签获取过程，并通过贝叶斯推断更新对最佳模型的信念，从而更有效地选择模型。实验结果表明，该方法显著优于现有方法，将发现最佳模型所需的标注努力减少多达70%。", "conclusion": "CODA方法通过共识驱动的主动模型选择，优化了模型选择过程，减少了标注数据的工作量，且具有较高的性能。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.01254", "html_url": "https://arxiv.org/abs/2408.01254", "title": "TrIM，适用于卷积神经网络的三角输入移动串行阵列：数据流和分析建模", "title_en": "TrIM, Triangular Input Movement Systolic Array for Convolutional Neural Networks: Dataflow and Analytical Modelling", "authors": "Cristian Sestito,Shady Agwa,Themis Prodromakis", "background": "为了应对前沿AI模型不断增加的计算复杂度和数据强度，正在提出新的计算范式。这些范式旨在通过减轻与数据在核心和内存之间传输相关的能量瓶颈，实现高效节能目标。卷积神经网络（CNNs）因其大量数据管理受到影响而易受这一瓶颈影响。串行阵列（SAs）被认为是一种有前景的架构，可以降低数据传输成本，由于处理单元（PEs）可以连续交换和本地处理数据（如权重固定和行固定），从而减少了对主存的访问次数。然而，数据冗余是主要的担忧，影响了面积、功率和能量。", "innovation": "本文提出了一种名为TrIM的新型数据流，适用于SAs，特别是针对CNN计算。TrIM最大化了局部输入利用率，减少了权重数据移动，并解决了数据冗余问题。此外，与行固定数据流相比，TrIM不引入显著的片上内存罚，默认使用较少的寄存器。", "conclusion": "与现有的SA数据流相比，TrIM提供了更高的数据利用率，确保了约10倍少的内存访问；同时，鉴于PEs持续重叠乘法和累加操作，TrIM实现了高吞吐量（比行固定高81.8%），并且只需要较少的寄存器（比行固定少15.6倍）。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23779", "html_url": "https://arxiv.org/abs/2507.23779", "title": "Phi-Ground Tech Report: Advancing Perception in GUI Grounding", "title_en": "Phi-Ground Tech Report: Advancing Perception in GUI Grounding", "authors": "Miaosen Zhang,Ziqiang Xu,Jialiang Zhu,Qi Dai,Kai Qiu,Yifan Yang,Chong Luo,Tianyi Chen,Justin Wagle,Tim Franklin,Baining Guo", "background": "随着多模态推理模型的发展，计算机使用代理（CUAs）变得越来越现实，类似《钢铁侠》中的Jarvis。GUI接地是CUAs执行实际操作的核心组成部分，类似于机器人中的机械控制，直接决定了系统的成功或失败。当前的端到端接地模型在挑战性基准ScreenSpot-pro和UI-Vision上的准确率仍然低于65%，尚未准备好部署，因为一次误点击可能导致无法接受的后果。", "innovation": "本研究通过实证研究支点模型的训练过程，从数据收集到模型训练，最终开发了在代理设置下参数少于10B的所有五个接地基准模型中表现最佳的Phi-Ground模型系列。在端到端模型设置中，我们的模型仍达到SOTA结果，分别在ScreenSpot-pro和UI-Vision上的得分为43.2和27.2。我们相信本论文中提到的各种细节，无论成功与否，都有助于清晰地构建接地模型，并且有益于其他感知任务。", "conclusion": "本论文不仅澄清了构建接地模型的各种细节，还通过我们的成功和失败的经验展现了对其他感知任务的潜在益处。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23735", "html_url": "https://arxiv.org/abs/2507.23735", "title": "分布式AI代理在自主水下机器人认知自主性中的应用", "title_en": "Distributed AI Agents for Cognitive Underwater Robot Autonomy", "authors": "Markus Buchholz,Ignacio Carlucho,Michele Grimaldi,Yvan R. Petillot", "background": "在复杂且不可预测的环境中实现机器人认知自主性仍然是机器人技术中的一个基本挑战。这种自主性要求机器人不仅能够进行多模态感知，还能够适应变化的环境和执行动态的任务规划，在这些条件下做出实时决策。现有的传统规则基础架构难以应对不可预见的情况、环境的不确定性以及新颖任务目标。因此，开发一种强大的认知自主性架构对于提升水下自主水下车辆（AUV）的性能至关重要", "innovation": "UROSA（Underwater Robot Self-Organizing Autonomy）是一种突破性的架构，它通过在ROS 2框架内整合分布式大语言模型AI代理实现自主水下车辆的高级认知能力。UROSA将认知分散为专门的AI代理，负责多模态感知、自适应推理、动态任务规划和实时决策。创新包括灵活的AI代理，能够根据需要调整其角色；利用向量数据库增强检索的生成技术，以提高知识管理效率；基于强化学习的行为优化；以及在运行时生成ROS 2节点来实现功能上的扩展性", "conclusion": "通过在模拟和实际部署的水下任务中进行广泛的经验验证，UROSA展示了显著优于传统基于规则架构的适应性和可靠性。这种新颖的框架不仅推进了水下自主性的发展，还建立了一个可扩展、安全且多功能的认知机器人框架，适用于多种现实世界的应用"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.18666", "html_url": "https://arxiv.org/abs/2503.18666", "title": "AgentSpec: 自定义运行时强化以确保LLM代理的安全性和可靠性", "title_en": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents", "authors": "Haoyu Wang,Christopher M. Poskitt,Jun Sun", "background": "基于大语言模型（LLM）的代理正在各个领域广泛应用，但它们的自主性带来了安全风险，包括安全漏洞、法律违规和意外有害行为。现有缓解方法，如基于模型的保障措施和早期执行策略，缺乏足够的稳健性、可解释性和适应性。", "innovation": "我们提出了AgentSpec，一种轻量级的领域特定语言，用于在LLM代理运行时指定和强制执行约束条件。AgentSpec允许用户定义包含触发器、谓词和执行机制的结构化规则，确保代理在预定义的安全边界内运行。该技术已被应用于代码执行、具身代理和自动驾驶等多个领域，展示了其适应性和有效性。我们的评估表明，AgentSpec在90%以上的代码代理案例中成功防止了不安全的执行，在具身代理任务中消除了所有危险行为，并确保了100%的AV合规性。此外，我们还使用LLM自动化生成规则并评估其效果，结果显示OpenAI o1生成的规则在具身代理方面具有95.56%的精确度和70.96%的召回率，成功识别了87.26%的危险代码，并在8种情景中有5种防止了AV违法。", "conclusion": "结合可解释性、模块性和效率，AgentSpec为在不同应用中确保LLM代理的安全性提供了一个实用且可扩展的解决方案。它虽然提供了强大的安全性保证，但仍具有微秒级别的计算开销，证明其在实际应用中的高效性和可行性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2402.11461", "html_url": "https://arxiv.org/abs/2402.11461", "title": "FGeo-HyperGNet: 结合 FormalGeo 符号系统和超图神经网络的几何问题求解", "title_en": "FGeo-HyperGNet: Geometric Problem Solving Integrating FormalGeo Symbolic System and Hypergraph Neural Network", "authors": "Xiaokai Zhang,Yang Li,Na Zhu,Cheng Qin,Zhenbing Zeng,Tuo Leng", "background": "几何问题解决一直是数学推理和人工智能领域长期存在的挑战。为了应对这一挑战，我们构建了一个神经-符号系统 FGeo-HyperGNet，以实现类似人类的几何问题求解。", "innovation": "该研究创新地结合了符号系统 FormalGeo 和超图神经网络 HyperGNet。符号系统自动执行几何关系推理和代数计算，并组织解的超图，超图节点表示条件，超图边表示定理。超图神经网络通过注意力机制编码超图的结构和语义信息，并预测定理以辅助问题求解。", "conclusion": "通过该神经-符号架构，实现了可读且可追踪的自动几何问题求解。实验结果表明 FGeo-HyperGNet 在 FormalGeo7K 数据集上取得了 SOTA 结果，TPA 达到 93.50%，PSSR 达到 88.36%。相关代码已发布。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.02508", "html_url": "https://arxiv.org/abs/2412.02508", "title": "当文字微笑：从文本生成多样化的表情", "title_en": "When Words Smile: Generating Diverse Emotional Facial Expressions from Text", "authors": "Haidong Xu,Meishan Zhang,Hao Ju,Zhedong Zheng,Erik Cambria,Min Zhang,Hao Fei", "background": "数字人类在对话系统、游戏和其他互动场景中的情感表达有重要意义。尽管在唇同步方面取得了显著进展，但现有的头像合成技术往往忽视了面部表情的丰富性和动态性。为了填补这一重要空白，该研究引入了一个端到端的文本到表情生成模型，专门关注情感动态。模型在连续的潜在空间中学习具有表现力的面部变化，生成多样的、流畅且情感连贯的表情。为了支持该任务，研究还引入了EmoAva数据集，其中包含15,000个文本-3D表情对，具有大规模和高质量的特点。", "innovation": "该研究引入了一个端到端的文本到表情生成模型，专注于情感动态，学习连续的潜在空间中的表现性面部变化，生成多样、流畅且情感连贯的表情。此外，还引入了EmoAva数据集，以支持模型的训练和评估。研究结果显示，该方法在多个评估指标上显著优于基线方法，标志着该领域的重要进步。", "conclusion": "该方法在现有的数据集和EmoAva数据集上的广泛实验中表现出显著的优势，证明了其在情感表达生成方面的有效性和先进性，为相关应用的发展做出了重要贡献。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.17696", "html_url": "https://arxiv.org/abs/2505.17696", "title": "提高AI系统韧性：基于控制理论的LSTM韧性建模与保障", "title_en": "Enhancing AI System Resiliency: Formulation and Guarantee for LSTM Resilience Based on Control Theory", "authors": "Sota Yoshihara(1),Ryosuke Yamamoto(2),Hiroyuki Kusumoto(1),Masanari Shimura(1) ((1) Graduate School of Mathematics, Nagoya University, (2) AISIN SOFTWARE Co., Ltd.)", "background": "本文提出了一个新型理论框架，用于保证和评估长短期记忆（LSTM）网络在控制系统中的韧性。论文定义了“恢复时间”作为一个新的韧性指标，以量化LSTM在异常输入之后恢复到正常状态所需的时间。通过对LSTM进行数学上的增量输入到状态稳定性（δISS）理论的精炼，文章推导出一个与数据无关的恢复时间的实用上界，从而实现了基于韧性感知的训练。实验结果显示，该方法对于简单模型的有效性，这为安全关键AI应用的严格质量保证奠定了基础。", "innovation": "论文首次提出了通过引入“恢复时间”作为一种新的韧性指标，来量化LSTM在面对异常输入后恢复至正常状态所需的时间。通过对δISS理论的数学精炼，论文推导出一个实用的、独立于数据的恢复时间上界，该上界用于实现韧性感知的训练方法。这一创新方法为安全关键AI应用严格的质量保证提供了理论基础和实用工具。", "conclusion": "在简单模型的实验验证中，本文提出的方法展示了对于LSTM网络韧性估计和控制的有效性，这增强了在安全关键AI应用中进行严格质量保证的基础。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.14928", "html_url": "https://arxiv.org/abs/2504.14928", "title": "教育Q：通过多代理对话框架评估大型语言模型的授课能力", "title_en": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework", "authors": "Yao Shi,Rongkeng Liang,Yong Xu", "background": "大型语言模型（LLMs）越来越多地作为教育工具使用，但对其教学能力的评估仍然具有挑战性，因为教师-学生互动具有资源密集、情境依赖和方法论复杂的特点。当前评估大多侧重于知识回忆，而忽略了互动教学法的重要性。为了更高效地评估这些模型的教学能力，我们提出了EducationQ，这是一个多代理对话框架，能够通过模拟动态教育场景来评估教学能力，框架包含专门用于教学、学习和评价的代理模型。", "innovation": "EducationQ通过引入专门设计的多代理对话框架，评估LLMs在教学场景中的表现，这不仅考虑了模型规模或一般推理能力，还结合了定量和定性的评估方法，包括专家案例研究，识别出顶级模型在教学方面的独特教育能力。研究发现，一些较小的开源模型在教学情境中表现出色，超越了更大的商业模型，强调现有评估方法存在的不足。", "conclusion": "我们的混合方法评估表明，LLMs作为教师需要超出简单规模扩展的专门优化，未来教育AI应优先增强特定的教学效率。该研究结果验证了我们评估方法的有效性，指出了现有评估方法的重要局限，并为下一代教育AI的发展提供了新的方向。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.23784", "html_url": "https://arxiv.org/abs/2507.23784", "title": "SUB: 通过合成属性替换评估 CBM 通用性的基准", "title_en": "SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions", "authors": "Jessica Bader,Leander Girrbach,Stephan Alaniz,Zeynep Akata", "background": "概念瓶颈模型（CBMs）和其他基于概念的可解释模型在提高人工智能应用透明度方面具有巨大潜力，特别是在医疗领域。然而，这些模型在分布变化下可靠地识别正确概念的能力有限。", "innovation": "本文提出了一个名为SUB的新基准数据集，用于评估CBMs对概念变化的鲁棒性。该数据集包含基于CUB数据集的38,400张合成图像，并通过一种新颖的Tied Diffusion Guidance（TDG）方法生成针对特定概念（如翼色或腹部图案）的替换图像。这种方法使得图像生成过程更加精确可控，确保生成的图像是指定的鸟类类别和属性。", "conclusion": "本文构建的SUB基准为CBMs和类似可解释模型提供了严格的评估框架，有助于开发更鲁棒的方法。相关代码和数据集可在指定链接获取。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17114", "html_url": "https://arxiv.org/abs/2506.17114", "title": "数学证明作为 litmus 测试：揭示先进大型推理模型的失败模式", "title_en": "Mathematical Proof as a Litmus Test: Revealing Failure Modes of Advanced Large Reasoning Models", "authors": "Dadi Guo,Jiayu Liu,Zhiyuan Fan,Zhitao He,Haoran Li,Yumeng Wang,Yi R. Fung", "background": "大型推理模型（例如R1、o3）在解决数学问题方面展现了显著的能力，但在主流数据集上的高表现准确度、对纯数值评估的依赖以及可能存在的基准数据泄漏问题，掩盖了它们真实的推理不足。现有研究需要一种新的诊断方法来揭示这些隐藏的失败。", "innovation": "本文提出利用数学证明的内在严谨性和方法学复杂性作为诊断工具，以揭示隐藏的失败模式。为此，作者构建了一个名为RFMDataset（Reveal Failure Modes）的数据集，包含200个不同的数学证明问题。通过深入分析这些模型的表现和失败，作者发现了10种具体错误类型，揭示了当前大型推理模型在逻辑推理方面存在的根本限制。", "conclusion": "研究发现，大型推理模型在数学证明方面面临严重挑战，部分模型较少能够生成完全正确的证明，单步推理缺乏保证，模型在推理过程中还表现出幻觉和不完整性。研究强调了模型自我反思的不足，指出需要进行正式和精细化的逻辑训练以解决当前逻辑难题。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07426", "html_url": "https://arxiv.org/abs/2507.07426", "title": "DrugMCTS: 结合多智能体、RAG和蒙特卡洛树搜索的药物再利用框架", "title_en": "DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search", "authors": "Zerui Yang,Yuwei Wan,Siyu Yan,Yudai Matsuda,Tong Xie,Bram Hoex,Linqi Song", "background": "近年来，大型语言模型在科学领域如药物再定位方面展现出了显著的潜力。然而，当推理超出预训练期间获得的知识时，它们的有效性受到限制。传统方法如微调或检索增强生成存在高额的计算成本或未能充分利用结构化的科学数据等局限性。", "innovation": "我们提出了一种名为DrugMCTS的新框架，该框架结合了RAG、多智能体合作和蒙特卡洛树搜索技术，专门用于药物再定位。该框架通过五个专门的智能体来检索和分析分子和蛋白质信息，从而实现结构化和迭代推理。实验结果表明，DrugMCTS在召回率和鲁棒性方面优于通用语言模型和深度学习基线方法。", "conclusion": "我们的研究结果强调了在药物再定位的LSTM应用程序中，结构化推理、基于智能体的合作以及反馈驱动搜索机制的重要性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21872", "html_url": "https://arxiv.org/abs/2507.21872", "title": "MultiEditor: 使用3D高斯点积先验进行驾驶场景可控多模态对象编辑", "title_en": "MultiEditor: Controllable Multimodal Object Editing for Driving Scenarios Using 3D Gaussian Splatting Priors", "authors": "Shouyi Lu,Zihan Lin,Chao Lu,Huanran Wang,Guirong Zhuo,Lianqing Zheng", "background": "自动驾驶系统依赖于多模态感知数据理解复杂的环境，但现实世界数据分布不平衡的问题限制了模型的泛化能力，尤其是在处理罕见但至关重要的车辆类别时更为明显。", "innovation": "提出了MultiEditor，一种双重分支潜在扩散框架，用于在驾驶场景中联合编辑图像和激光雷达点云，并引入3D高斯点积（3DGS）作为目标物体的结构和外观先验。设计多级外观控制机制，结合像素级粘贴、语义级引导和多分支 refinement，实现多模态下的高保真重建。同时提出了一种深度引导的变形跨模态条件模块，利用3DGS渲染的深度信息，增强跨模态的一致性。实验表明，MultiEditor在视觉和几何保真度、编辑可控性和跨模态一致性方面表现出色，生成罕见类车辆数据显著提升了感知模型在未充分代表类别上的检测准确率。", "conclusion": "MultiEditor在视觉和几何保真度、编辑可控性和跨模态一致性方面表现出色，并且能够显著增强感知模型在罕见类别上的检测准确率。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07528", "html_url": "https://arxiv.org/abs/2506.07528", "title": "在声明验证中协调搜索驱动推理和推理引导搜索", "title_en": "Coordinating Search-Informed Reasoning and Reasoning-Guided Search in Claim Verification", "authors": "Qisheng Hu,Quanyu Long,Wenya Wang", "background": "多跳声明验证本身极具挑战性，需要通过多步推理构建验证链，同时通过迭代搜索来发现隐藏的桥梁事实。这一过程本质上是交织的，有效的推理依赖于动态检索的证据，而有效的搜索则需要基于部分信息进行推理来细化查询。为了解决这一问题，该研究提出了Hierarchical Agent Reasoning and Information Search (HARIS)，旨在明确模型推理驱动搜索和搜索引导推理的协调过程。HARIS 包含一个高级推理代理和一个低级搜索代理，分别负责制定主要验证链、生成需要更多信息的背景知识问题和持续检索更多信息并基于中间结果细化搜索。这种设计提高了每个代理的专业性，增强了验证准确性和可解释性。HARIS 使用基于结果的奖励进行强化学习训练。在 EX-FEVER 和 HOVER 指标上的实验表明，HARIS 在多跳声明验证方面的表现非常出色，极大地推进了该领域的研究。", "innovation": "提出了Hierarchical Agent Reasoning and Information Search (HARIS) 方法，专门设计来协调搜索驱动推理和推理引导搜索的过程，通过高级推理代理和低级搜索代理的分工提高验证的准确性和可解释性。此外，HARIS 使用基于结果的奖励进行强化学习训练，进一步优化了其性能。", "conclusion": "HARIS 在 EX-FEVER 和 HOVER 指标上的实验结果表明，该方法在多跳声明验证中取得了优异的性能，显著推动了该领域的研究与发展。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21875", "html_url": "https://arxiv.org/abs/2507.21875", "title": "Tiny-BioMoE：一种轻量级生理信号分析嵌入模型", "title_en": "Tiny-BioMoE: a Lightweight Embedding Model for Biosignal Analysis", "authors": "Stefanos Gkikas,Ioannis Kyprakis,Manolis Tsiknakis", "background": "疼痛是一个复杂且普遍存在的现象，影响着相当一部分人群。准确且一致的评估对于疼痛患者至关重要，同时也是发展有效的疼痛管理策略的基础。自动疼痛评估系统可以实现连续监测，支持临床决策，并有助于缓解患者的痛苦，同时降低功能恶化的风险。利用生理信号可以提供客观和精确的人体状态信息，其在多模态框架中的整合可以进一步提升系统的性能。本研究提交给了‘第二代下一代疼痛评估多模态传感grand挑战赛（AI4PAIN）’。", "innovation": "本文提出了Tiny-BioMoE，一种轻量级预训练嵌入模型，适用于生理信号分析。该模型在440万生理信号图像表示上进行了训练，参数仅有730万。模型结构简洁，能够有效地从下游任务中提取高质量的嵌入表示，并在电渗出活动、血容积脉冲、呼吸信号、周边氧饱和度以及它们的组合等多种模态下自动疼痛识别任务中表现出色。", "conclusion": "研究展示了Tiny-BioMoE在多模态生理信号分析中表现出的强大性能，其代码和权重已开源。这一创新提供了有潜力的工具，支持疼痛管理策略的发展和实施。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.19219", "html_url": "https://arxiv.org/abs/2505.19219", "title": "collision路径交汇: 经典与基于学习的多智能体路径规划全面综述", "title_en": "Where Paths Collide: A Comprehensive Survey of Classic and Learning-Based Multi-Agent Pathfinding", "authors": "Shiyue Wang,Haozheng Xu,Yuhan Zhang,Jingran Lin,Changhong Lu,Xiangfeng Wang,Wenhao Li", "background": "多智能体路径规划（MAPF）是人工智能和机器人技术中的一个基本问题，涉及多个代理从起始位置到目标路径的无碰撞规划。随着自主系统在仓库、城市交通和其他复杂环境中的广泛应用，MAPF从理论难题转变为现实世界多机器人协调的关键支持因素。本文综述了经典算法方法与新兴基于学习的方法之间的长期差距，并系统分析了200多篇论文的实验实践，揭示了评估方法的显著差异，同时提供了综合分类，强调标准化基准测试协议的必要性。", "innovation": "本文提出了一种统一框架，汇集了基于搜索的方法（冲突解决搜索、优先级搜索、大规模邻域搜索）、基于编译的方法（SAT、SMT、CSP、ASP和MIP形式）以及基于数据的技术（强化学习、监督学习和混合策略）。通过系统分析经纬度超过200x200、规模达到1000多个代理的经典方法，与主要涉及10-100个代理的基于学习的方法之间的评估差异，确定了现有研究的缺口。最后，提出了结合经典方法严谨性和深度学习灵活性的混合机制、基于大规模语言模型的语言基础规划以及神经求解器架构等未来研究方向。", "conclusion": "本文不仅为研究人员提供了全面的参考指南，也为部署复杂实际应用场景中的MAPF解决方案提供了实用指导，通过标准化基准测试和新方法的探索，为MAPF研究指明了前进方向。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07820", "html_url": "https://arxiv.org/abs/2507.07820", "title": "AI应更好地感知，而非仅仅规模化：感知适应性作为范式转变", "title_en": "AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift", "authors": "Eunsu Baek,Keondo Park,Jeonggil Ko,Min-hwan Oh,Taesik Gong,Hyung-Sin Kim", "background": "当前的人工智能进步主要依赖于扩大神经网络模型和扩展训练数据集来实现泛化和鲁棒性。尽管取得了显著的成功，但这种模式带来了重大的环境、经济和伦理成本，限制了可持续性和公平的获取。最近的研究表明，小模型（例如EfficientNet-B0）通过适应性感知能够超越大规模模型（例如OpenCLIP-H），即使后者是使用大量数据和计算资源训练的。", "innovation": "我们倡导将适应性感知作为必要和基础的变革。适应性感知在输入级别主动调节传感器参数（例如曝光、灵敏度、多模态配置），显著缓解了协变量偏移并提高了效率。这些努力旨在促使人工智能社区转向可持续、鲁棒和公平的人工智能系统。", "conclusion": "本文提出了将适应性感知广泛应用于类人、医疗保健、自主系统、农业和环境监测等现实应用领域的道路图，评估了技术与伦理整合的挑战，并提出了标准化基准、实时自适应算法、多模态集成和隐私保护方法等目标研究方向。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21881", "html_url": "https://arxiv.org/abs/2507.21881", "title": "用于疼痛识别的多表示图：将多种皮肤电活动信号整合到单个图像中", "title_en": "Multi-Representation Diagrams for Pain Recognition: Integrating Various Electrodermal Activity Signals into a Single Image", "authors": "Stefanos Gkikas,Ioannis Kyprakis,Manolis Tsiknakis", "background": "疼痛是一个多维度的现象，影响了大量人群。可靠的疼痛评估对于减轻患者痛苦并促进有效的疼痛管理至关重要。自动疼痛评估系统通过连续监测，支持临床决策，减少痛苦并防止功能衰退。这些系统通过整合生理信号，客观地提供了个体状况的准确信息。该研究提交给了第二届下一代疼痛评估的多模态传感 grand challenge (AI4PAIN)。普遍采用的方法是通过连续监测和数据分析来评估疼痛，以提供客观的疼痛评估指标，从而帮助临床决策，减少病人的痛苦，并防止功能衰退。现有的方法主要依赖单一信号模态，本研究则通过利用皮肤电活动信号提出了多表示图的方法，整合了多种表示方法。", "innovation": "本研究提出了一种结合了多表示图的方法，利用皮肤电活动信号作为输入模态。研究中创建了多种信号表示，并将其可视化为波形图，同时整合到一个单一的多表示图中。研究中采用了多种处理和滤波技术，并结合了多种表示组合，显示了所提出方法的有效性。这种方法在很多情况下优于传统的融合方法，证明了它作为不同信号表示或模态整合的稳健替代品的价值。", "conclusion": "研究成果表明，多表示图方法在疼痛识别上表现出了优越性，为疼痛评估系统的开发和改进提供了新的思路。该方法的引进显著提升了疼痛评估的准确性和可靠性，有助于开发更有效的疼痛管理策略。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11122", "html_url": "https://arxiv.org/abs/2505.11122", "title": "Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining", "title_en": "Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining", "authors": "Yu Shi,Yitong Duan,Jian Li", "background": "Alpha因子挖掘对于量化投资至关重要，它涉及从复杂的金融市场数据中识别预测信号。传统的人工主题alpha挖掘依赖于专家经验，而现代自动化方法如基于遗传编程或强化学习的系统虽然出现，但在搜索效率方面存在不足，或者产生的alpha因子难以解释。", "innovation": "本文提出了一个将大型语言模型(LLMs)与蒙特卡洛树搜索(MCTS)相结合的新框架，克服了传统方法的局限性。该框架利用LLMs的指令执行和推理能力，在MCTS引导的探索中逐代生成和精炼符号alpha公式。关键创新点在于利用丰富且定量的回测反馈来指导MCTS的探索，从而高效地穿越巨大的搜索空间。此外，还引入了避免频繁子树机制，以增强搜索多样性并防止公式化同质化，从而提高性能。", "conclusion": "我们的LLM驱动框架在真实股票市场数据上取得了优于现有方法的结果，通过挖掘具有更高预测准确性和交易性能的alpha因子，使生成的公式更易于人理解，建立了一个更有效和高效的公式化alpha因子挖掘范式。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21886", "html_url": "https://arxiv.org/abs/2507.21886", "title": "通过呼吸信号实现高效疼痛识别：单个跨注意力变压器多窗口融合管道", "title_en": "Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline", "authors": "Stefanos Gkikas,Ioannis Kyprakis,Manolis Tsiknakis", "background": "疼痛是一种复杂的疾病，影响着大量人群。准确且一致的疼痛评估对于疼痛患者至关重要，有助于制定有效的管理策略。自动疼痛评估系统能够提供连续监测，为临床决策提供支持，旨在减轻痛苦并预防功能衰退。该研究提交给了“Next-Gen疼痛评估（AI4PAIN）第二代多模式传感大奖🏆挑战赛”。", "innovation": "提出了一种管道，该管道利用呼吸作为输入信号，并结合高效的交叉注意力变压器和多窗口策略。实验表明，呼吸是疼痛评估中的重要生理指标。此外，实验还发现，紧凑且高效的模型在优化得当时，可以达到甚至超越大模型的性能。提出的多窗口方法能捕捉到短期和长期特征以及全局特性，从而增强模型的表现力。", "conclusion": "广泛实验表明，呼吸信号可以作为高效的疼痛评估指标，并且适当的紧凑模型优化可以实现强大的性能。多窗口方法有助于提取疼痛评估的相关特征，提升模型的表征能力。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22782", "html_url": "https://arxiv.org/abs/2507.22782", "title": "基于注意力机制的演员批评政策增强多智能体协作", "title_en": "Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies", "authors": "Hugo Garrido-Lestache,Jeremy Kedziora", "background": "本文介绍了一种名为Team-Attention-Actor-Critic (TAAC)的强化学习算法，旨在提升多智能体在协作环境中的协同能力。TAAC采用集中训练/集中执行方案，并在演员和批评者中引入了多头注意力机制，这有助于动态、智能地进行智能体间通信，使得智能体能够明确查询队友，从而有效地管理起联合动作空间的增长，并确保高程度的协作。", "innovation": "本文提出了一种惩罚损失函数，促进智能体之间多样且互补的角色分配。通过在模拟足球环境中对TAAC和多种基准算法（包括Proximal Policy Optimization和Multi-Agent Actor-Attention-Critic）进行对照测试，发现TAAC在各种指标上表现出更优秀的性能和更高效的合作行为（胜率、进球差距、Elo评分、智能体之间联系性、平衡空间分布以及频繁的战术互动）。", "conclusion": "本文设计的TAAC算法在模拟足球环境中表现优异，尤其是在多样性和互操作性方面展现了显著优势，未来在多智能体系统中的应用前景值得期待。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21035", "html_url": "https://arxiv.org/abs/2507.21035", "title": "GenoMAS：一种基于代码驱动的基因表达分析的多智能体框架", "title_en": "GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis", "authors": "Haoyang Liu,Yijiang Li,Haohan Wang", "background": "基因表达分析对于生物医学领域的许多发现至关重要，但提取原始转录组数据中的见解仍旧具有挑战性，主要因为数据文件复杂、半结构化和需要强大的专业知识。目前的自动化方法往往受到两种限制：要么是缺乏弹性的固定工作流程，在边缘情况下无法处理；要么是完全自主的代理，缺乏精确到严谨科学发现所需的精度。虽然存在这些局限性，但GenoMAS提出了一种不同的路径，利用基于LLM的科学家团队，将结构化工作流程的可靠性与自主代理的适应性结合起来。", "innovation": "GenoMAS通过运用一种指导计划框架，将大型及半结构化的基因组数据预处理和基因识别过程拆分为特定任务和行动单元，同时运用六种专门设计的LLM智能体协作完成任务，这使得方案既具备结构化流程的可靠性又能灵活应对复杂数据。GenoMAS在GenoTEX基准测试中的表现尤为亮眼，数据预处理的综合相似度相关性达到了89.13%，基因识别的F1得分达到了60.48%，这两项指标比先前的最佳方法分别提高了10.61%和16.85%。", "conclusion": "GenoMAS不仅在技术指标上达到了新的高度，更通过代码驱动的方式解决了复杂数据处理中的生物学问题，同时也为科学发现提供了可调整的、精确的线索，展望将GenoMAS应用于更多领域，比如基因表型关联的挖掘。代码已在指定网址公开供进一步研究使用。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.14313", "html_url": "https://arxiv.org/abs/2406.14313", "title": "使用弱验证器进行迭代修复的Few-shot转移在知识关联问答中的应用", "title_en": "Iterative Repair with Weak Verifiers for Few-shot Transfer in KBQA with Unanswerability", "authors": "Riya Sawhney,Samrat Yadav,Indrajit Bhattacharya,Mausam", "background": "知识库关联问答（KBQA）在实际应用中需要处理有限领域标记训练数据下难以回答的问题。前任的工作假设所有问题都是无法回答的，这导致了性能不佳。", "innovation": "提出了一个新颖的任务，即在包含无法回答问题的情况下进行少量样本迁移学习，并贡献了两个新数据集进行性能评估。提出了FUn-FuSIC新解决方案，通过使用反馈从一组强弱验证器进行迭代修复，以及针对无法回答性自一致性适应，来更好地评估问题的回答可能性。", "conclusion": "实验结果表明，FUn-FuSIC在任务中显著优于多种基于大语言模型和监督学习的现有的最佳模型，同时在可回答的少量样本转移学习中建立了新的最佳表现。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22359", "html_url": "https://arxiv.org/abs/2507.22359", "title": "LLM-Crowdsourced: 一种大型语言模型的无基准相互评价范式", "title_en": "LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models", "authors": "Qianhong Guo,Wei Xie,Xiaofang Cai,Enze Wang,Shuoyoucheng Ma,Kai Chen,Xiaofeng Wang,Baosheng Wang", "background": "虽然大型语言模型在各种任务中表现出非凡的能力，但评估这些能力仍然是一个挑战性的任务。现有评估方法存在数据污染、黑盒操作和主观偏好等问题，这使得全面评价大型语言模型的真实能力变得困难。", "innovation": "提出了一种新的基准免费评估范式，即LLM-Crowdsourced。该方法利用大型语言模型生成问题、独立作答并进行相互评价。它整合了动态、透明、客观和专业四个关键评估标准，这是现有评估方法无法同时满足的。", "conclusion": "在八个主流大型语言模型上进行的数学和编程领域的实验验证了我们的方法在区分大型语言模型性能方面的优势。此外，我们的研究揭示了传统方法难以检测的一些新发现，包括但不限于：（1）Gemini在原创和专业的问题设计能力上表现出最高水平；（2）某些大型语言模型通过误认为问题是结构相似的已知问题而表现出'记忆式回答'现象；（3）大型语言模型的评估结果显示出高度的一致性和稳健性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.12365", "html_url": "https://arxiv.org/abs/2309.12365", "title": "一种高效的半自动化仓库库存盘点智能系统", "title_en": "An Efficient Intelligent Semi-Automated Warehouse Inventory Stocktaking System", "authors": "Chunan Tong", "background": "在供应链管理不断发展的背景下，高效库存管理对企业的重要性不断增加。然而，传统的手动和经验依赖的方法难以满足现代市场的复杂需求，经常出现数据不准确、监控延迟和过于依赖主观经验等问题。", "innovation": "本文提出了一个智能库存管理系统，以解决数据不准确、监控延迟和过于依赖主观经验等问题。该系统结合了条形码和分布式Flutter应用技术进行智能感知，并利用全面的大数据分析支持数据驱动的决策。通过详细分析、系统设计、关键技术创新和模拟验证，证明了该系统的有效性和实用性，实现了秒级监控、高频检查和人工智能驱动的预测，提高了库存管理的自动化、精确性和智能化。", "conclusion": "该智能系统通过准确的预测和明智的决策减少了成本，并优化了库存规模，最终达到双赢的局面。本文的研究成果提供了优化库存管理的有效方法。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2304.01430", "html_url": "https://arxiv.org/abs/2304.01430", "title": "Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots", "title_en": "Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots", "authors": "Dong Lao,Zhengyang Hu,Francesco Locatello,Yanchao Yang,Stefano Soatto", "background": "该研究探讨了在没有语义标注的情况下，视知觉中物体的出现机制。现有方法通常依赖于预训练特征和监督学习，本研究尝试在缺乏监督和预训练特征的情况下实现对图像中多个独立移动区域的有效分割，这些区域可能具有未知和变化的数量，并能在实时环境中进行处理。", "innovation": "研究提出了一种新颖的多模态条件编码器-解码器架构，称为Divided Attention (DivA)。该架构通过光流作为一种模态输入编码器，生成一个集合的潜在代码（槽），而颜色图像数据作为第二种模态调整解码器，从这些潜在代码中生成光流。训练指标旨在促进槽之间的信息分离，架构明确分配激活到各个槽，实现了上下文分离的槽，并命名为“Divided Attention (DivA)”。DivA在测试时可以处理与训练时不同的对象数量和图像分辨率，并对槽的排列变化具有不变性。研究结果表明DivA可以在保持实时性能的同时，实现比同类方法三倍的运行速度，并将性能差距从监督方法缩小至12%或更低。通过DivA获得的对象可以引导静止分类器，通过对比学习 在少于5000个视频片段的训练数据下，使用DivA的物体提案对DINO的训练比直接在视频帧上训练提高了高达30.2%的性能差距，相对基于ImageNet的训练而言。", "conclusion": "DivA方法在实现多物体分割和实时处理方面取得了显著进步，提升了训练效率并将与监督方法的性能差距最小化。同时，它还展示了潜在的进一步应用，如通过对比学习增强静态分类器的性能。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2401.13481", "html_url": "https://arxiv.org/abs/2401.13481", "title": "AI想法对人类想法的创造性、多样性和进化的影響：一项大型动态实验的证据", "title_en": "How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment", "authors": "Joshua Ashkinaze,Julia Mendelsohn,Li Qiwei,Ceren Budak,Eric Gilbert", "background": "随着大规模语言模型输出的快速增长，人类在接触到AI生成的想法后，自己产生的想法会发生怎样的变化？这项研究通过一个包含800多名参与者，来自40多个不同国家的实验来探索这一问题。参与者首先查看由ChatGPT或之前实验参与者生成的想法，然后基于这些想法进行自己的头脑风暴。", "innovation": "研究设计具有动态性——来自前期实验参与者的创意被用于刺激后续实验的参与者，以展示文化创造过程的相互依存性：创意是由先前的想法构建起来的。这种设计捕捉到了大型语言模型在文化循环中的累积影响。研究还考察了披露AI生成的例子标识（即告知参与者某些想法是由AI生成的）对参与者的影响。", "conclusion": "研究发现，高AI曝光量（但不是低AI曝光量）并未影响个体想法的创造性，却增加了集体想法多样性的平均水平和变化速率。AI让想法更加独特，而不是更好。披露与否没有显著主要效应。此外，自我报告为创造力较强的人士对AI生成的想法的识别度较低，并且在任务难度较高的情况下，参与者可能会主动采纳AI的想法。这些发现表明，引入AI想法可能会增加集体多样性，但不一定能提升个体的创造性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.15738", "html_url": "https://arxiv.org/abs/2407.15738", "title": "全局采样下的并行拆分学习", "title_en": "Parallel Split Learning with Global Sampling", "authors": "Mohammad Kohankhaki,Ahmad Ayad,Mahdi Barhoush,Anke Schmeink", "background": "在资源受限环境中进行分布式深度学习面临可扩展性和泛化性挑战，因为有效批次大小较大且客户端数据分发不一致。标准的方法无法有效调整客户端批次大小以维持固定的整体批次大小，导致整个数据分布未能反映得足够准确，同时对于模型的准确性、训练效率和收敛稳定性具有负面影响。", "innovation": "本文提出了一种基于服务器驱动的采样策略，通过动态调整客户端批次大小来维持固定的整体批次大小，从而将有效批次大小与参与设备数目解耦，确保整体批次更好地反映了数据的整体分布。通过标准聚集边界，建立了相比现有方法更严格的偏差保证。实验结果在基准数据集上证实，所提方法能够提高模型准确度、训练效率和收敛稳定性，提供了一个适用于网络边缘学习的可扩展解决方案。", "conclusion": "通过实验证明，提出的全局采样下的并行拆分学习方法可以改善模型准确度、训练效率和收敛稳定性，从而提供一个适用于网络边缘学习的可扩展解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2408.09186", "html_url": "https://arxiv.org/abs/2408.09186", "title": "EEG-SCMM: Soft Contrastive Masked Modeling for Cross-Corpus EEG-Based Emotion Recognition", "title_en": "EEG-SCMM: Soft Contrastive Masked Modeling for Cross-Corpus EEG-Based Emotion Recognition", "authors": "Qile Liu,Weishan Ye,Lingli Zhang,Zhen Liang", "background": "最近几年，利用脑电图（EEG）信号进行情绪识别受到了越来越多的关注。然而，现有的方法在跨语料库（cross-corpus）设置中往往缺乏泛化能力，即在不重新训练的情况下，一个在某个数据集上训练好的模型直接应用于另一个数据集。这是由于不同数据集之间的数据分布和记录条件差异造成的。因此，亟需一种能够有效应对跨语料库EEG情绪识别挑战的新方法。", "innovation": "本文提出了一个名为Soft Contrastive Masked Modeling (SCMM)的新框架，该框架基于情绪连续性的理论，结合了软对比学习和混合掩码策略，以有效捕捉情绪动态（短期内的连续性）。具体来说，在半监督学习阶段，通过提出一种软加权机制来为样本对分配相似性得分，能够进行精细的情绪过渡建模并捕捉人类情绪的时序连续性。通过设计一种基于成对相似性的语义相关样本的感知聚合器，进一步增强了表示学习，从而提高了特征的表达性和重建质量。这种双重设计有助于生成更具判别力和可迁移到其他数据集的情绪表示，对于跨语料库的泛化能力至关重要。实验结果显示，SCMM在SEED、SEED-IV和DEAP数据集上的表现优于其他方法，平均准确率提高了4.26%。", "conclusion": "本文提出的SCMM框架在EEG基的情绪识别方面取得了最先进的性能，尤其是在跨语料库设置中。该方法通过结合软对比学习和混合掩码策略，有效捕捉情绪动态，促进了特征的表达性和重建质量，从而提高了跨语料库情绪识别的泛化能力。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.17092", "html_url": "https://arxiv.org/abs/2409.17092", "title": "大型语言模型的感知累加器后训练量化", "title_en": "Accumulator-Aware Post-Training Quantization for Large Language Models", "authors": "Ian Colbert,Giuseppe Franco,Fabian Grob,Jinjie Zhang,Rayan Saab", "background": "当将权重和激活量化为越来越窄的表示时，MAC单元中的加法成本开始超过乘法成本。最近的研究表明，通过低精度积累降低加法成本可以提高推理平台的吞吐量、功耗和面积，但会增加溢出的风险。到目前为止，感知量化器的量化后训练（PTQ）方法仅考虑了量化感知训练（QAT）范式，模型需要细调或从头开始训练以包含量化。然而，随着模型和数据集规模的增长，这种方法变得越来越昂贵，从而激发了最近PTQ研究的激增。", "innovation": "该论文提出了AXE，一个感知累加器的首个后训练量化框架，旨在为PTQ算法提供溢出避免保证。AXE被设计成支持多阶段积累，能够实现全数据路径优化。AXE在现有算法GPFQ和OPTQ的基础上实现，展示了其灵活性。在对语言生成模型进行量化时，AXE在保持FP16困惑度98%的同时，优于简单的位宽操纵，最高可达15%之多。", "conclusion": "AXE是一个专为大型语言模型设计的量化框架，能够提供溢出避免保证，并通过多阶段积累提高量化效率。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.03080", "html_url": "https://arxiv.org/abs/2407.03080", "title": "在数据稀缺场景中使用人工归纳偏置生成合成表格数据", "title_en": "Artificial Inductive Bias for Synthetic Tabular Data Generation in Data-Scarce Scenarios", "authors": "Patricia A. Apellániz,Ana Jiménez,Borja Arroyo Galende,Juan Parras,Santiago Zazo", "background": "虽然使用深度生成模型（DGMs）生成合成表格数据可以解决数据稀缺和隐私问题，但它们的有效性依赖于大规模的训练数据，而在实际场景中往往难以获得。为解决这一局限，本文提出了一种新的方法，该方法在生成过程中明确整合人工归纳偏置以提高低数据量情况下的数据质量。该框架利用迁移学习和元学习技术来构建并注入到DGMs中有用的归纳偏置，进行模型预训练、模型平均、模型无知元学习（MAML）和域随机化搜索（DRS）四种方法的评估，并分析它们对生成文本质量的影响。实验结果显示，整合归纳偏置显著提高了性能，迁移学习方法优于元学习方法，实现了高达60%的詹森-香农距离提高。该方法是模型无关的，特别适用于如医疗和金融领域，这些领域需要高质量的合成数据而数据获取常常受限的情况。", "innovation": "提出了一种新的方法，该方法在生成过程中明确整合人工归纳偏置以提高低数据量情况下的数据质量。该框架利用迁移学习和元学习技术来构建并注入到DGMs中有用的归纳偏置，评估了四种方法并分析其对生成文本质量的影响。实验结果表明，整合归纳偏置显著提高了性能，迁移学习方法优于元学习方法。这种方法是模型无关的，并特别适用于需要高质量合成数据且数据获取受限的领域。", "conclusion": "该研究提出了基于人工归纳偏置在数据稀缺场景下生成合成表格数据的新方法，利用迁移学习和元学习技术显著提高了生成数据的质量。这种方法特别适用于医疗和金融领域。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.16593", "html_url": "https://arxiv.org/abs/2410.16593", "title": "在同构图上实现可扩展且表达能力强的图神经网络的图采样方法", "title_en": "Graph Sampling for Scalable and Expressive Graph Neural Networks on Homophilic Graphs", "authors": "Haolin Li,Haoyu Wang,Luana Ruiz", "background": "图神经网络（GNNs）在许多图机器学习任务中表现出色，但是在处理大型网络时面临挑战。现有的GNN可转移性方法能够通过在较小的图上进行训练并将模型应用于较大的图中来缓解这一问题，但这些方法通常依赖于随机子采样，导致子图断裂并降低模型表达能力。因此，研究人员致力于开发一种新的图采样算法，通过利用特征同质性来保留图结构，进而实现更好的可扩展性和表达能力。", "innovation": "该研究提出了一种新颖的图采样算法，利用特征同质性来保留图结构，同时通过最小化数据相关矩阵的迹来更好地保留图拉普拉斯迹（图连接的代理）而不依赖于频谱方法，从而降低复杂度。实验表明，该方法在保留拉普拉斯迹和GNN可转移性方面优于随机采样。", "conclusion": "实验结果表明，该方法在引文网络中能更有效地保留拉普拉斯迹和GNN可转移性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.02744", "html_url": "https://arxiv.org/abs/2410.02744", "title": "中性残差：重新审视用于模型扩展的适配器", "title_en": "Neutral Residues: Revisiting Adapters for Model Extension", "authors": "Franck Signe Talla,Edouard Grave,Hervé Jégou", "background": "本研究针对预训练大型语言模型如何扩展到训练期间未见过的新领域的问题。标准方法如微调或低秩适应（LoRA）在域适应方面非常成功，但并未正式提升模型能力。这通常导致新领域性能与原领域性能之间的权衡。研究者重新审视并改进了适配器，从数据、架构和训练过程三个角度出发，联合考虑这些因素，以改善模型扩展效果。", "innovation": "提出了一种称为‘中性残差’的方法，该方法通过改变适配器，使得新残差块在原本训练的数据集上输出接近零的值。这种方法在将一个最初用英文训练的顶级模型扩展到新语言时表现出色，并在新语言学习与遗忘原始语言之间的权衡上显著优于现有的方法如微调、LoRA或纯适配器。", "conclusion": "中性残差在模型扩展方面表现优异，显著优于竞争技术。这一改进为其他类似应用场景提供了新的启示和解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.18659", "html_url": "https://arxiv.org/abs/2411.18659", "title": "DHCP: 使用跨模态注意模式检测大型视觉语言模型中的幻觉", "title_en": "DHCP: Detecting Hallucinations by Cross-modal Attention Pattern in Large Vision-Language Models", "authors": "Yudong Zhang,Ruobing Xie,Xingwu Sun,Yiqing Huang,Jiansheng Chen,Zhanhui Kang,Di Wang,Yu Wang", "background": "大型视觉语言模型（LVLMs）在复杂的多模态任务中表现出色，但仍然面临着显著的幻觉问题，包括物体、属性和关系幻觉。准确检测这些幻觉需要研究幻觉与非幻觉状态下跨模态注意力模式的变化。", "innovation": "提出了一个轻量级的幻觉检测器——Detecting Hallucinations by Cross-modal Attention Patterns（DHCP），该方法不需额外训练LVLM或额外的LVLM推理步骤，并且通过提供对LVLM中幻觉识别和分析的新见解，有助于提高这些模型的可靠性和可信度。", "conclusion": "DHCP 在幻觉检测方面取得了显著的性能，并为大型视觉语言模型中幻觉的识别和分析提供了新的见解，从而推进了这些模型的可靠性和可信度。代码已发布。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.20632", "html_url": "https://arxiv.org/abs/2502.20632", "title": "基于变温过程的晶格蛋白折叠", "title_en": "Lattice Protein Folding with Variational Annealing", "authors": "Shoummo Ahsan Khandoker,Estelle M. Inack,Mohamed Hibat-Allah", "background": "理解蛋白质折叠的原理是计算生物学领域的关键问题，对药物设计、生物工程以及基本生物学过程的理解具有重要意义。晶格蛋白折叠模型提供了一种简化但强大的框架来研究蛋白质折叠的复杂性，允许在受限制的条件下探索能量最优的折叠。然而，找到这些最优折叠是计算上具有挑战性的组合优化问题。", "innovation": "本文提出了一种新颖的上界训练方案，该方案利用掩码来识别二维疏水-极性（HP）晶格蛋白折叠中的最低能量折叠。通过利用集成了类似温度波动驱动的退火过程的扩展递归神经网络（RNNs），该方法准确地预测了多达60个珠子的基准系统的最优折叠。该方法还能有效屏蔽无效折叠而不会损害RNNs的自回归采样特性。该方案可应用于三维空间，并能扩展到具有更大字母表的晶格蛋白质模型。", "conclusion": "我们的研究强调了在面对复杂蛋白质折叠问题和一系列受限组合优化挑战时，先进机器学习技术的巨大潜力。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.09112", "html_url": "https://arxiv.org/abs/2501.09112", "title": "Mantis Shrimp：探索计算机视觉网络在光谱红移估计中的光电波段利用", "title_en": "Mantis Shrimp: Exploring Photometric Band Utilization in Computer Vision Networks for Photometric Redshift Estimation", "authors": "Andrew Engel,Nell Byler,Adam Tsou,Gautham Narayan,Emmanuel Bonilla,Ian Smith", "background": "机器学习已成为光谱红移估算的成熟方法，相较于模板基模型，在高密度光谱标志星区域表现更好。图像基础上的卷积神经网络在表现上优于基于表的数据模型。然而，图像模型之间的设计复杂性在于不同仪器输入的不同分辨率和噪声特性如何融合未知。Mantis Shrimp模型使用切片图像来估算红移的条件密度估计，其密度估计结果良好，点估计值在可获得的光谱标记星系分布中表现出色，偏差为1e-2，散布为2.44e-2，灾难性异常率为17.53%。研究发现早期融合方法（如重新采样和拼接不同仪器图像）与后期融合方法（如链接潜在空间表示）表现相当，用户的最终设计选择取决于个人偏好。模型研究发现，模型善于整合从所有调查中获取的信息。然而，该模型应用到大型星系群体分析上受制于从外部服务器下载切片的速度。", "innovation": "Mantis Shrimp模型通过融合超紫外（GALEX）、光学（PanSTARRS）和红外（UnWISE）图像，为光谱红移估算提供了一种新的途径。该模型通过切片图像估算红移的条件密度，发现早期和后期融合方法在性能上相当，这为设计选择提供了灵活性。", "conclusion": "尽管Mantis Shrimp模型在光谱红移估算中表现良好，但由于从外部服务器下载切片的速度限制，该模型在大规模星系群体分析中的应用受到限制。然而，该模型在小规模研究中具有潜在应用价值，如用于生成星族合成中的红移先验。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09215", "html_url": "https://arxiv.org/abs/2503.09215", "title": "其他车辆轨迹同样需要: 统一车辆轨迹的驾驶世界模型", "title_en": "Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latent Space", "authors": "Jian Zhu,Zhengyu Jia,Tian Gao,Jiaxin Deng,Shidi Li,Lang Zhang,Fu Liu,Peng Jia,Xianpeng Lang", "background": "现有的自动驾驶系统预测其他车辆运动并计划自身车辆轨迹，使用可预见轨迹结果的世界模型来评估自动驾驶系统。然而，现有的世界模型主要关注自身车辆轨迹，忽略了其他车辆的轨迹控制，这限制了它们在实际驾驶场景中模拟车辆情境互动的能力。", "innovation": "本文提出了一种新的驾驶世界模型EOT-WM，它能统一视频中的自身车辆和其他车辆轨迹，以进行驾驶模拟。通过将贝叶斯视角下车辆轨迹投影到图像坐标框中进行车辆-轨迹匹配和基于空间-时间变量化自动编码器的轨迹编码，使轨迹视频与驾驶视频在统一视觉空间中对齐。此外，设计了一个轨迹注入的去噪柯西变换器，利用自身和其他车辆轨迹指导噪声视频潜变量的视频生成。还提出了一种基于控制潜变量相似度的度量方法来评估轨迹的可控性。", "conclusion": "在nuScenes数据集上进行了广泛的实验，所提出的模型在FID和FVD指标上分别比现有最先进的方法高出30%和55%，并且可以使用自我生成的轨迹预测未见的驾驶场景。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.20934", "html_url": "https://arxiv.org/abs/2502.20934", "title": "在使用SAM2进行手术视频分割时回访由帧采样策略引入的评价偏差", "title_en": "Revisiting the Evaluation Bias Introduced by Frame Sampling Strategies in Surgical Video Segmentation Using SAM2", "authors": "Utku Ozbulak,Seyed Amir Mousavi,Francesca Tozzi,Niki Rashidian,Wouter Willaert,Wesley De Neve,Joris Vankerschaver", "background": "实时视频分割为AI辅助手术提供了前景广阔的机会，通过识别工具和解剖结构提供术中的指导。尽管对手术视频分割的兴趣不断增长，但不同数据集的标注协议差异较大——有的提供密集的逐帧标签，而有的依赖于稀疏标注和低帧率采样（例如1FPS）。", "innovation": "研究调查了不同标注密度和帧率采样对零样本分割模型评估的影响，并使用SAM2作为胆囊切除手术的案例研究，发现常规稀疏评估设置下，较低的帧率似乎优于较高的帧率，因为这种平滑效应掩盖了时间上的不一致性。但在实时流式传输条件下评估时，较高的帧率提供了更好的分割稳定性，尤其是对于动态物体如手术抓持器。", "conclusion": "研究结果揭示了引入由不一致数据集协议产生的评价偏差的风险，并强调了在手术视频AI中进行时间上公平基准测试的迫切需要。参与者一致偏好高帧率分割叠加，更加证实了在实时应用中评估每一帧的重要性，而不是依赖稀疏采样策略。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.06409", "html_url": "https://arxiv.org/abs/2411.06409", "title": "自动策略发明用于术语重写系统的凝聚", "title_en": "Automated Strategy Invention for Confluence of Term Rewrite Systems", "authors": "Liao Zhang,Fabian Mitterwallner,Jan Jakubuv,Cezary Kaliszyk", "background": "术语重写在软件验证和编译器优化中扮演重要角色，已有多种高度可参数化的技术被开发用于证明各种系统属性。自动化术语重写工具在广泛参数空间中运行，其复杂性超过了人类选择参数的能力，因此需要探索自动策略发明的方法。本文聚焦于术语重写系统的凝聚这一重要属性，并利用机器学习开发了首个指导性自动凝聚证明器。通过生成大量随机数据集来分析术语重写系统的凝聚。实验结果表明，将发明的策略应用于现有的最佳自动凝聚证明器CSI时，不仅在扩展数据集上，还在原本的人工创建基准数据集Cops上，CSI的表现超越了人工设计的策略，成功证明或反驳了几种此前无人自动证明的术语重写系统的凝聚性。", "innovation": "首次利用机器学习开发了自动指导性策略发明的自动凝聚证明器，生成大量随机数据集分析了术语重写系统的凝聚，使CSI在发明策略的帮助下超越了人工设计策略，证明了若干术语重写系统的凝聚性，这在之前是无人自动证明的。", "conclusion": "本文通过技术创新使CSI自动凝聚证明器在表现出色，不仅在扩展数据集，还覆盖了原有基准数据集，成功地证明或反驳了几种术语重写系统的凝聚性，是该领域的先进成果。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.15544", "html_url": "https://arxiv.org/abs/2501.15544", "title": "推进通过互联网连接的电动汽车的生成人工智能和大型语言模型的需求侧管理", "title_en": "Advancing Generative Artificial Intelligence and Large Language Models for Demand Side Management with Internet of Electric Vehicles", "authors": "Hanwen Zhang,Ruichen Zhang,Wei Zhang,Dusit Niyato,Yonggang Wen,Chunyan Miao", "background": "生成人工智能，特别是通过大型语言模型（LLMs），有望改变微网中的能源优化和需求侧管理（DSM）。本文探讨了将LLMs集成到能源管理中的方式，强调它们在自动化优化DSM策略中的作用，尤其是通过互联网连接的电动汽车方面。我们研究了DSM相关的挑战和解决方案，并探讨了利用LLMs带来的新机遇。", "innovation": "我们提出了一种创新解决方案，增强了LLMs的检索增益生成能力，以实现自动问题表述、代码生成和定制优化。我们通过一项案例研究展示了我们提出的解决方案在电动汽车充电调度和优化方面的有效性，突显了该方案在能源效率和用户适应性方面的重大进步。", "conclusion": "本文强调了LLMs在能源优化中的潜力，并促进了智能DSM解决方案的新时代。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.15441", "html_url": "https://arxiv.org/abs/2412.15441", "title": "代码小型语言模型服务中运行时引擎和执行提供者对资源利用的洞见", "title_en": "Insights into resource utilization of code small language models serving with runtime engines and execution providers", "authors": "Francisco Durán,Matias Martinez,Patricia Lago,Silverio Martínez-Fernández", "background": "语言模型特别是代码生成领域的快速增长需要大量的计算资源，这引发了能源消耗和环境影响方面的担忧。提高语言模型推理资源利用效率至关重要，小型语言模型（SLMs）为减少资源需求提供了可能的解决方案。本文旨在从软件工程师在代码生成领域使用SLMs进行推理的角度出发，分析运行时引擎和执行提供者配置对资源利用的影响，包括能耗、执行时间和计算资源利用率方面的差异。", "innovation": "通过一个多阶段的实验管道研究了12种代码生成小型语言模型在不同配置下的能耗、执行时间和计算资源利用率，发现CUDA执行提供者在能耗和执行时间方面优于CPU执行提供者。特别是TORCH与CUDA的组合表现出最高的能效，相比其他配置可节省37.99%至89.16%的能耗。另外，带有CPU执行提供者的优化运行时引擎（如ONNX）相比基于CPU的配置可节省8.98%至72.04%的能耗。研究表明，运行时配置的选择显著影响资源利用率，未来的研究和软件工程师可以据此选择最佳配置以提高资源利用效率。", "conclusion": "运行时引擎和执行提供者的配置选择对小型语言模型服务中的资源利用有显著影响。虽然还需要进一步研究，但当前研究推荐TORCH与CUDA以及优化如ONNX与CPU的组合配置以优化资源利用效率，适合软件工程师的需求。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.12098", "html_url": "https://arxiv.org/abs/2412.12098", "title": "MaxInfoRL：通过信息增益最大化推动强化学习的探索", "title_en": "MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization", "authors": "Bhavya Sukhija,Stelian Coros,Andreas Krause,Pieter Abbeel,Carmelo Sferrazza", "background": "强化学习（RL）算法旨在平衡当前最佳策略的利用与探索可能带来更高奖励的新选项。大多数常见的RL算法采用随机探索的方式，即选择随机的动作序列。探索也可以通过内在奖励（如好奇心或模型的知识不确定性）来定向，但有效平衡任务奖励和内在奖励的难度较大，且通常依赖于具体任务。本文介绍了一种名为MaxInfoRL的框架，用于平衡内在和外在探索。MaxInfoRL通过最大化信息增益（如关于任务的知识获取）来引导探索，当与Boltzmann探索结合时，可以自然地权衡价值函数最大化与状态、奖励和动作的熵最大化之间的权衡。作者通过简化设置的多臂老虎机展示了这种方法达到亚线性后悔，并将其应用到连续状态-动作空间的各种离策略模型自由的RL方法中，使得算法在探索问题和复杂场景（如视觉控制任务）中取得了优越的表现。", "innovation": "提出了一种名为MaxInfoRL的框架，该框架通过最大化信息增益来引导探索，从而平衡内在和外在探索。结合Boltzmann探索时，该方法使得在最大化价值函数的同时自然地权衡熵的问题，并通过多臂老虎机实验展示了亚线性后悔，以及在多个离策略模型自由的RL方法中应用，特别在复杂的连续状态-动作空间和苛刻的探索问题中表现出色", "conclusion": "本文提出的方法在简化设置的多臂老虎机中实现了亚线性后悔，并且在多种复杂的连续状态-动作空间的离策略模型自由的RL算法中表现出了优异的效果。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.05343", "html_url": "https://arxiv.org/abs/2410.05343", "title": "EgoOops: 一种基于主观视频识别程序文本中错误动作的数据集", "title_en": "EgoOops: A Dataset for Mistake Action Detection from Egocentric Videos referring to Procedural Texts", "authors": "Yuto Haneji,Taichi Nishimura,Hirotaka Kameko,Keisuke Shirai,Tomoya Yoshida,Keiya Kajimura,Koki Yamamoto,Taiyu Cui,Tomohiro Nishimoto,Shinsuke Mori", "background": "错误动作检测对于开发能够检测工人错误并提供反馈的智能档案至关重要。现有研究主要关注自由风格活动中的明显错误，导致只能使用视频进行错误检测的方法。然而，在遵循程序文本的活动中，模型无法仅通过视觉信息判断一些动作的正确性，必须参照文本。目前，错误数据集使用程序文本进行视频录制的情况很少，除了烹饪领域。本文为了填补这些空白，提出了EgoOops数据集，该数据集记录了遵循程序文本时在各个领域发生的错误行为的主观视频。EgoOops数据集包含三种类型的注释：视频-文本对齐，错误标签以及错误描述。这些注释有助于更好地理解视频中的错误行为。", "innovation": "本文提出了EgoOops数据集，这是一个记录了遵循程序文本时发生错误行为的主观视频数据集。该数据集包含了三种类型的注释，即视频-文本对齐、错误标签和对错误的描述，这为错误行为检测提供了更完整的注释信息。此外，本文还提出了一种结合视频-文本对齐和错误标签分类的方法来利用文本进行错误检测。", "conclusion": "实验结果表明，结合程序文本对错误检测至关重要。数据可通过以下链接获取：this https URL。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02851", "html_url": "https://arxiv.org/abs/2505.02851", "title": "利用大语言模型创建特定领域内容语料库", "title_en": "Leveraging LLMs to Create Content Corpora for Niche Domains", "authors": "Franklin Zhang,Sonya Zhang,Alon Halevy", "background": "从浩瀚的非结构化网络资源中构建专门领域的内容语料库，面临着显著的数据整理挑战。本文介绍了一种精简的方法，通过高效获取、筛选、结构化和清理网络数据来生成高质量的专门领域语料库。", "innovation": "提出了一种战略框架，结合大语言模型增强技术进行结构化内容提取和语义去重，以应对大规模复杂数据整理的问题。", "conclusion": "通过将其纳入30 Day Me习惯养成应用，验证了该方法的有效性。数据管道30DayGen从超过15K网页中提取并整合了3,531个独特的30天挑战，用户满意度评分为4.3/5，91%的受访者表示愿意使用整理内容来实现习惯养成目标。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.09753", "html_url": "https://arxiv.org/abs/2504.09753", "title": "通过文化与地方知识改善大型语言模型的多语言能力并增强本地表现", "title_en": "Improving Multilingual Capabilities with Cultural and Local Knowledge in Large Language Models While Enhancing Native Performance", "authors": "Ram Mohan Rao Kadiyala,Siddartha Pullakhandam,Siddhant Gupta,Drishti Sharma,Jebish Purbey,Kanwal Mehreen,Muhammad Arham,Suman Debnath,Hamza Farooq", "background": "大型语言模型（LLMs）展示了显著的能力，但其开发主要集中在英语和其他高资源语言上，导致许多语言未能得到充分服务。本研究旨在开发一个多语言双向模型Mantra-14B，该模型在两种语言上的基准测试中平均提高了3%的得分，超过与之规模是其两倍的模型。使用一个由485K个样本组成的人工编纂的英语和印地语指令数据集，对Qwen-2.5-14B-Instruct和Phi-4等模型进行指令调优，以提高两种语言的表现。实验涉及七个不同参数大小的LLM以及140多次不同的训练尝试，展示了可以改进多语言性能而不会牺牲本地性能的事实。", "innovation": "本研究通过使用文化与地方知识，避免了资源密集的技术如词汇扩展或架构修改，实现了一个小型化的高效双向模型Mantra-14B。模型在两种语言上的平均基准测试得分提高了3%，超过了规模为其两倍的模型。模型训练使用的原始数据集是精心编纂的，具有文化和地方针对性。", "conclusion": "适度的、基于文化与地方知识的数据微调可以有效弥补性能差距，而不会产生显著的计算开销。研究结果表明，可以通过这种方式显著提高多语言表现。研究团队已将训练代码、数据集和模型发布在MIT和Apache许可下，以便进一步推动对欠代表性及低资源语言的研究。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15768", "html_url": "https://arxiv.org/abs/2503.15768", "title": "一网打尽？：多文档摘要迁移中的失败度量", "title_en": "Can one size fit all?: Measuring Failure in Multi-Document Summarization Domain Transfer", "authors": "Alexandra DeLucia,Mark Dredze", "background": "多文档摘要（MDS）是指从多份文档中自动生成信息的任务，适用于新闻文章和多发言人对话等多种场景。目前的MDS模型训练方法可以分为四大类：端到端的特殊预训练（直接）、分块再总结、提取再总结，以及使用GPT风格模型的推理。作者评估了不同训练方法、领域和维度（参考相似性、质量和事实性）的MDS模型，以分析为什么在零样本领域迁移设置中，一个领域的训练模型可能无法很好地概括另一领域的文档。评估中，“领域迁移失败”被定义为事实性下降、偏离目标程度增加，以及摘要质量总体下降。同时，作者还探讨了直接应用流行摘要评价指标可能存在的问题。", "innovation": "作者通过全面评估不同训练技术和领域迁移，揭示了模型在不同领域间的概括效能变化，并揭示了领域迁移失败的具体原因以及评价指标在跨领域应用中的限制。这为改善MDS模型的跨领域适应性提供了一定的基础和指导意义。", "conclusion": "在多文档摘要的零样本领域迁移中，过拟合特定领域的模型可能无法有效概括其他领域非相似内容。研究强调了多文档摘要迁移需要进一步解决的关键问题，包括更好地理解模型解释、精确度量领域迁移效果和改进评估指标，以提高模型的迁移性能。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.17788", "html_url": "https://arxiv.org/abs/2503.17788", "title": "从基础到扩散的学习：一种用于遮挡鲁棒双手重建的对齐与细化框架", "title_en": "Learning to Align and Refine: A Foundation-to-Diffusion Framework for Occlusion-Robust Two-Hand Reconstruction", "authors": "Gaoge Han,Yongkang Cheng,Zhe Chen,Shaoli Huang,Tongliang Liu", "background": "双手从单目图像重建面临持续的挑战，由于复杂的动态手部姿势和遮挡导致实现可信的交互对准困难。现有方法难以解决这些对准问题，常导致错位和穿透伪影。如何通过高效的融合基础视觉模型的2D先验指导和基于扩散的3D交互精细化来实现鲁棒的双手重建是亟待解决的问题。", "innovation": "本文提出了一种双重阶段的基础到扩散框架，该框架精确地对齐来自基础视觉模型的2D先验引导和基于扩散的生成性3D交互精细化，实现对遮挡鲁棒的双手重建。首先，文中引入了一个轻量级的融合对齐编码器，在训练过程中对多模式的2D先验，如关键点、分割图和深度线索进行对齐，从而提供鲁棒的结构化指导，使得在测试时可以高效地进行推理，同时保持高重建精度。其次，文中实现了一个明确训练的双手扩散模型，用于将交错的3D姿势转化为可信、无穿透的对应物。通过碰撞梯度引导的去噪，模型纠正伪影并保留手部的自然空间关系。", "conclusion": "广泛评估表明，本文的方法在InterHand2.6M、HIC和FreiHAND数据集上取得了最先进的性能，显著提高了遮挡处理和交互鲁棒性。我们将在未来公开我们的代码。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18102", "html_url": "https://arxiv.org/abs/2505.18102", "title": "如何发布我的大语言模型基准而不泄露正确答案？", "title_en": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "authors": "Takashi Ishida,Thanawat Lodkaew,Ikko Yamane", "background": "发表大型语言模型（LLM）基准可能对未来的LLM造成污染风险，因为基准可能被无意或有意地用于训练或选择模型。通常的缓解方法是保持基准保密，让参与者向主办方提交模型或预测。然而，这种方法需要对单一组织的信任，并且仍有可能通过重复查询进行测试集过拟合。本研究旨在解决这一问题。", "innovation": "提出了一种在不完全披露答案的情况下发布基准的新方法，同时仍能公开评估LLMs。核心创新在于通过准备几个逻辑正确的答案，注入随机性，仅在基准中包含其中一个作为解决方案。这种方法降低了基准的最佳可能准确率，有助于保护真值隐私，并提供了一种检测数据污染的测试手段。研究表明，在广泛情况下，这种方法能够准确检测出数据污染。", "conclusion": "实验结果表明，该方法可以在多种基准、模型和训练方法下准确检测出数据污染。该方法不仅有效保护了真值隐私，还提供了一种检测数据污染的测试手段。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.22688", "html_url": "https://arxiv.org/abs/2503.22688", "title": "CodeIF-Bench: 评估大型语言模型在交互式代码生成中的指令跟随能力", "title_en": "CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation", "authors": "Peiding Wang,Li Zhang,Fang Liu,Lin Shi,Minxiao Li,Bo Shen,An Fu", "background": "大型语言模型（LLMs）在代码生成任务中表现出色，已成为开发者的必要编程助手。现有代码生成基准主要评估LLMs在单轮交互中生成的代码的功能正确性，但对于LLMs在多轮交互场景下生成符合用户指令的代码的能力关注较少。本文介绍了一个新基准—CodeIF-Bench，用于评估LLMs在交互式代码生成中的指令跟随能力。CodeIF-Bench 包含九种可验证的指令，这些指令与现实世界软件开发需求对齐，可以通过指定的测试案例独立且客观地验证，从而在多轮交互中评估指令跟随能力。", "innovation": "CodeIF-Bench 旨在填补现有基准在评估LLMs在多轮交互中生成符合用户指令代码的能力方面的空白。它通过包含九种可验证的指令来解决这个问题，这些指令能够独立且客观地验证，并能够促进多轮交互中的指令跟随能力评估。该基准在静态对话和动态对话设置下对七种最先进的LLMs进行评估，总结了影响多轮交互中LLMs指令跟随能力的因素以及改进方向。", "conclusion": "研究展示了CodeIF-Bench 在评估LLMs在多轮交互中准确遵循用户指令的性能方面的重要性，并指出其在静态对话和动态对话环境下的评估结果。还总结了影响LMLs指令跟随能力的关键因素，并提出了改进的潜在方向。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04640", "html_url": "https://arxiv.org/abs/2504.04640", "title": "Splits！一种灵活的数据集和评价框架用于社会文化语言学研究", "title_en": "Splits! A Flexible Dataset and Evaluation Framework for Sociocultural Linguistic Investigation", "authors": "Eylon Caplan,Tania Chakraborty,Dan Goldwasser", "background": "社会文化语言学现象（SLP）由于其语言使用的变化性以及受说话者社会文化背景和使用情境的影响，提供了一个深入了解文化视角、价值观和观点的丰富视角。然而，计算研究这些现象通常局限于特定群体或主题的定制分析，这限制了科学研究的进展。", "innovation": "本文引入了Splits！，这是一个包含970万条帖子的数据集，来自Reddit，用于系统性和灵活的研究。该框架利用高效的检索方法自动评估给定假设是否得到数据的支持，并引入了一种由人类验证的衡量假设“意外性”的方法，从而显著减少了需要人工检查的统计显著发现的数量。", "conclusion": "通过两阶段过程，Splits！显著减少了需要人工检查的统计显著发现的数量，达到1.5-1.8倍的减少，从而简化了对有潜力的现象的进一步研究。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.11952", "html_url": "https://arxiv.org/abs/2504.11952", "title": "鲁棒且细粒度的AI生成文本检测", "title_en": "Robust and Fine-Grained Detection of AI Generated Texts", "authors": "Ram Mohan Rao Kadiyala,Siddartha Pullakhandam,Kanwal Mehreen,Drishti Sharma,Siddhant Gupta,Jebish Purbey,Ashay Srivastava,Subhasya TippaReddy,Arvind Reddy Bobbili,Suraj Telugara Chandrashekhar,Modabbir Adeeb,Srinadh Vura,Suman Debnath,Hamza Farooq", "background": "现有的检测系统在识别AI生成的短文本时常常表现不佳。此外，并非所有文本都是完全由人类或生成器创作的，所以研究更侧重于人类-生成器合作创作的部分情况。背景强调了针对任何生成器的理想检测系统的需求。", "innovation": "本文提出了一组针对标记分类任务进行训练的模型，这些模型针对广泛的人机合作创作文本进行了训练，并且在未见过的领域、生成器、非母语作者和对抗输入的文本上表现出色。同时也提出了包含超过240万条文本的新数据集，这些文本大多由多个流行的专有生成器以23种语言合作创作。此外，还探讨了模型在每个领域的表现，并进行了对抗性方法、输入文本长度和生成文本与原始人类创作文本特点之间的比较。", "conclusion": "研究结果表明，所提出的方法在各领域的表现良好，并且能够在多种生成器上进行有效检测，对于非母语作者和对抗性输入也表现出较好的鲁棒性和精细程度。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15621", "html_url": "https://arxiv.org/abs/2503.15621", "title": "LLaVA-MORE：增强视觉指令调整的语言模型与视觉骨干网络的比较研究", "title_en": "LLaVA-MORE: A Comparative Study of LLMs and Visual Backbones for Enhanced Visual Instruction Tuning", "authors": "Federico Cocchi,Nicholas Moratelli,Davide Caffagni,Sara Sarto,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara", "background": "近期多模态大型语言模型（MLLMs）的发展表明，视觉骨干和底层语言模型在其中都起到关键作用。尽管先前的研究主要集中在扩大模型规模至数十亿参数上，但模型大小、架构与性能之间的权衡仍然未被充分探讨。此外，训练数据的不一致和评估协议的差异使得直接比较变得困难，难以得出最佳设计选择。", "innovation": "本文提出了LLaVA-MORE，这是一种将现代语言模型与多种视觉骨干相结合的新家族模型，采用了统一的训练协议，系统地评估了不同规模（包括小型和中型）的MLLMs在多模态推理、生成和指令跟随方面的性能。此外，研究了从CLIP架构到DINOv2、SigLIP和SigLIP2等各种视觉编码器的影响，并探讨了图像分辨率的提高及其预训练数据集的变化对模型性能的影响。", "conclusion": "研究结果提供了多模态大型语言模型设计的有效见解，提供了一个可再现的评估框架，便于直接比较，并指导未来模型开发。源代码和训练模型已公开。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23628", "html_url": "https://arxiv.org/abs/2505.23628", "title": "AutoSchemaKG：通过大规模语料库动态构-schema自主知识图谱构建", "title_en": "AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora", "authors": "Jiaxin Bai,Wei Fan,Qi Hu,Qing Zong,Chunyang Li,Hong Ting Tsang,Hongyu Luo,Yauwai Yim,Haoyu Huang,Xiao Zhou,Feng Qin,Tianshi Zheng,Xi Peng,Xin Yao,Huiwen Yang,Leijie Wu,Yi Ji,Gong Zhang,Renhai Chen,Yangqiu Song", "background": "当前知识图谱构建通常需要预定义的模式，这限制了其灵活性和自动化程度。现有的方法在处理多跳问答任务和提高语言模型事实准确性方面表现一般，且需要大量的人工干预来构建和维护模式。", "innovation": "AutoSchemaKG框架通过利用大型语言模型同时提取知识三元组并直接从文本中诱导全面的模式，实现了完全自动的知识图谱构建，而无需预定义的模式。该系统能够处理5000万份文档，并构建了一个包含900多个亿节点和580亿条边的知识图谱家族，ATLAS。该方法在多跳问答任务中优于最先进的基线，并提高了语言模型的事实准确性。特别地，模式诱导达到95%的人工手动构造的模式一致性，展示了动态诱导模式的大型知识图谱可以直接补充大型语言模型中的参数知识，而无需人工干预。", "conclusion": "研究成果展示了大规模语料库可以用于自动构建知识图谱，并且这种自动构建的知识图谱能够显著提升语言模型的事实性，并且在多跳问答任务中表现出色。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07106", "html_url": "https://arxiv.org/abs/2506.07106", "title": "Theorem-of-Thought: 一种用于语言模型中的演绎、归纳和 abduction 推理的多代理框架", "title_en": "Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models", "authors": "Samir Abdaljalil,Hasan Kurban,Khalid Qaraqe,Erchin Serpedin", "background": "大语言模型（LLMs）在自然语言推理任务中表现出很强的能力，但其推理过程仍然脆弱且难以解释。虽然提示技术如链条思维（CoT）能够通过引入中间推理步骤或聚合多个输出来增强可靠性，但它们缺乏确保逻辑结构和内在意图一致性的机制。", "innovation": "我们提出了 Theorem-of-Thought (ToTh) 框架，这是一种新颖的方法，将推理视为三个并行代理的合作，每个代理模拟不同类型的推理：演绎、归纳和 abduction。每个代理生成一个结构化的推理过程，形成一个正式的推理图。我们使用由自然语言推理指导的贝叶斯信念传播来评估一致性，给每个步骤分配可信度分数，并选择最合理的图来得出最终答案。实验表明，ToTh 在多项 LLM 上在多个象征性和数值性推理基准测试中表现优于 CoT、自我一致性以及 CoT 解码。这种框架产生可解释且逻辑扎实的推理链，为我们构建更强大且认知启发的 LLM 推理提供了新的方向。", "conclusion": "我们的实验结果表明，ToTh 在多个 LLM 上在多种象征性和数值性推理基准测试中表现优于 CoT、自我一致性以及 CoT 解码，产生了可解释且逻辑扎实的推理链。这一发现为构建更加强大且认知启发的 LLM 推理提供了新的方向。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.08184", "html_url": "https://arxiv.org/abs/2506.08184", "title": "无法忘记：前瞻干扰揭示LLMs的认知局限超越长度约束", "title_en": "Unable to Forget: Proactive Interference Reveals Working Memory Limits in LLMs Beyond Context Length", "authors": "Chupei Wang(University of Virginia),Jiaqiu Vince Sun(New York University)", "background": "在大型语言模型（LLMs）中，信息检索越来越被视作与生成能力相关，而不是简单的查找。普遍认为，更长的上下文会提高检索效果，但内间干扰的影响仍不明确。该研究通过引入前瞻干扰（PI）的概念，考察了先前信息在人类认知中的干扰作用，发现这种干扰与工作记忆容量呈负相关关系。研究通过一种新的评估方法，即PI-LLM，来研究LLMs在面对逐渐增加的干扰信息时的表现。", "innovation": "该研究创新性地将认知科学中的前瞻干扰（PI）概念应用于LLMs的研究，设计了PI-LLM评估，发现随着干扰信息的增加，LLMs的检索准确性呈对数级下降，说明可能存在一个工作记忆瓶颈，不仅仅依赖于上下文长度。此外，通过提示工程试图减轻干扰的努力并没有取得显著效果，这进一步揭示了LLMs在检索和处理信息方面存在内在的局限性。", "conclusion": "研究揭示了LLMs在检索和处理信息时存在工作记忆瓶颈，这种局限性超越了单纯依赖于上下文长度。为了提高LLMs的检索能力，未来的工作需要增强模型在检索过程中排除无关内容的能力。这种方法可以考虑为更有效地处理信息提供新的思路，以克服工作记忆的限制。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10006", "html_url": "https://arxiv.org/abs/2506.10006", "title": "通过动态双向重建实现灵活多模态输入的HER2表达预测", "title_en": "HER2 Expression Prediction with Flexible Multi-Modal Inputs via Dynamic Bidirectional Reconstruction", "authors": "Jie Qin,Wei Yang,Yan Su,Yiran Zhu,Weizhen Li,Yunyue Pan,Chengchang Pan,Honggang Qi", "background": "在乳腺癌HER2评估中，临床评估依赖于结合H&E和IHC图像，但同时获取这两种模态往往受到临床限制和成本的阻碍。", "innovation": "提出了一种适应性双模态预测框架，该框架通过两个核心创新：动态分支选择器根据输入可用性激活模态完成或联合推理，以及跨模态生成对抗网络（CM-GAN），通过生成对抗网络在特征空间中重建缺失的模态。这一设计显著提高了仅依赖H&E图像的准确性，从71.44%提升到94.25%，在全双模态输入条件下达到95.09%，单模态条件下保持90.28%的可靠性。此架构在无需强制同步获取的情况下提供接近双模态的准确性，为资源有限的地区提供经济高效的解决方案，并大幅提高了HER2评估的可获得性。", "conclusion": "该适应性双模态预测框架在单模态和双模态条件下均表现出出色的性能，为HER2评估提供了灵活且有效的解决方案，尤其适用于资源有限的地区。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.06275", "html_url": "https://arxiv.org/abs/2505.06275", "title": "SinBasis Networks: 矩阵等效特征提取方法用于波形光学光谱", "title_en": "SinBasis Networks: Matrix-Equivalent Feature Extraction for Wave-Like Optical Spectrograms", "authors": "Yuzhou Zhu,Zheng Zhang,Ruyi Zhang,Liang Zhou", "background": "波形图像（如飞秒级频域拍摄的光谱图像、音频梅尔频谱图和周期视频帧）包含了重要的谐波结构，这些结构难以被传统的特征提取方法捕捉。现有的方法在识别和理解这些复杂形式的图像时存在局限性。因此，需要一种更有效的框架来提取这些波形图像的关键特征，使模型能够识别和利用这些特殊的周期性特征及抵抗空间位移的变化。论文提出了一种统一的矩阵等效框架，重新解释卷积和注意力机制，揭示滤波器权重为覆盖潜在特征子空间的基本向量。将频谱先验嵌入到这些转换中，可增加网络对周期模式的敏感度并提高对空间位移的不变性。通过在各种波形图像数据集上进行实验，展示了一种新的神经网络架构——Sin-Basis 网络在重构准确性、平移鲁棒性和跨域零样本转移方面的显著优势。", "innovation": "提出了一种新的矩阵等效框架，将卷积和注意力机制重新解释为在展平输入上的线性转换，揭示滤波器权重为覆盖潜在特征子空间的基本向量。提出了元素级的$\text{sin}(\text{·})$映射，将这些转换整合到CNN、ViT及Capsule架构中，形成了Sin-Basis Networks，增强了网络对周期模式的敏感性，并具备对空间位移的内在不变性。理论分析表明，这种基于正弦重构的表达方法在数据稀缺的情况下增强了表示能力，同时保持了稳定性，并通过实验验证了其在多种波形图像数据集上的显著效果。", "conclusion": "Sin-Basis Networks 是一种轻量级且基于物理的方法，适用于所有的波形成像模态的深度学习应用。该框架通过引入频谱先验和正弦重构的参数化，增强了网络对周期模式的敏感性和对空间位移的不变性，从而提高了在重构准确性、平移鲁棒性和跨域零样本转移方面的表现。实验表明，该方法在多种波形图像数据集上取得了显著的成果，并能够通过矩阵同构和Mercer核截断理论分析来量化这些改进。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15857", "html_url": "https://arxiv.org/abs/2507.15857", "title": "扩散模型在数据受限设置中超越自回归模型", "title_en": "Diffusion Beats Autoregressive in Data-Constrained Settings", "authors": "Mihir Prabhudesai,Mengning Wu,Amir Zadeh,Katerina Fragkiadaki,Deepak Pathak", "background": "自回归（AR）模型长期以来主导了大型语言模型的领域，推动了众多任务的进步。最近，基于扩散的语言模型作为一种有前途的替代方案浮现，尽管它们相对于AR模型的优势尚未被充分探索。本文系统地研究了在数据受限设置中的掩蔽扩散模型，这些设置涉及多次反复使用有限的数据进行训练。研究发现，在计算资源充足但数据稀缺的情况下，扩散模型相比AR模型表现显著更优。扩散模型能够更好地利用重复数据，实现更低的验证损失和更优的下游性能。", "innovation": "本文解答了扩散模型在数据受限条件下相对于自回归模型的优势，并发现了扩散模型的新扩展法则，推导出判断扩散模型性能超过自回归模型的计算临界阈值的闭式表达式。这些发现表明，在计算能力充足但数据不足时，扩散模型为传统的自回归范式提供了替代方案。作者进一步将扩散模型的优势解释为隐式的数据扩增：扩散模型使模型接触到各种不同的词序和预测任务的分布，而自回归模型则具有固定的从左到右的分解形式。", "conclusion": "当数据而非计算成为瓶颈时，扩散模型提供了传统自回归范式的有吸引力的替代方案。实验代码可在以下链接获取：this https URL."}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.01631", "html_url": "https://arxiv.org/abs/2507.01631", "title": "Tile and Slide: 一个用于从小范围到全局3D地球观测扩展NeRF的新框架", "title_en": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "authors": "Camille Billouard,Dawa Derksen,Alexandre Constantin,Bruno Vallet", "background": "神经辐射场（NeRF）近年来已成为从多视角卫星图像进行三维重建的一种范式。然而，最先进的NeRF方法通常由于训练中的内存占用问题仅限于小场景。先前的大规模NeRF方法通过将场景划分为多个NeRF来缓解这个问题。本文研究了这一局限性，并引入了Snake-NeRF框架，该框架能够处理大型场景。我们的方法通过将感兴趣的区域划分为无重叠的NeRF进行3D镶嵌，从而避免同时加载所有图像和网络，并确保每个NeRF都能够获得足够的像素用于训练，从而防止3D重建误差沿镶嵌边界的出现。", "innovation": "本文介绍了Snake-NeRF框架，该框架通过将感兴趣的区域划分为无重叠的NeRF并采用新颖的2x2 3D瓷砖进度策略和分段采样器来扩展NeRF处理大型场景的能力。这种方法允许在单个设备上运行，且能够以线性时间复杂度处理大型卫星图像，而不会降低图像质量。", "conclusion": "实验结论表明，大的卫星图像可以通过Snake-NeRF框架以线性时间复杂度在单个GPU上处理，同时保持高质量，有效地解决了大规模场景处理的问题。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.17247", "html_url": "https://arxiv.org/abs/2506.17247", "title": "基于递归学习的虚拟缓冲技术用于分析性全局放置", "title_en": "Recursive Learning-Based Virtual Buffering for Analytical Global Placement", "authors": "Andrew B. Kahng,Yiting Liu,Zhiang Wang", "background": "由于现代工艺节点中互连延迟与单元延迟之间的指数级差异，全局放置时考虑到单元密度（即缓冲孔隙率）对于时序闭合是必不可少的。然而，现有的方法面临两大挑战：一是传统的van Ginneken-Lillis风格的缓冲技术在全局放置阶段计算成本高昂；二是基于机器学习的方法，如BufFormer，未能充分考虑电气规则检查(ERC)违规情况，也无法将结果反馈到物理设计流程中。这些问题使得现有的优化方法在降低时序负松弛量（TNS）方面效果有限，同时增加了不必要的功率消耗。在此工作中，提出了MLBuf-RePlAce，这是一种开源的学习驱动的虚设缓冲感知的分析性全局放置框架，建立在OpenROAD基础设施之上。MLBuf-RePlAce采用了高效的递归学习生成性缓冲方法，可以预测缓冲类型和位置，从而解决全局放置阶段的ERC违规问题。", "innovation": "MLBuf-RePlAce是第一个学习驱动的虚拟缓冲感知的分析性全局放置框架，它采用递归学习生成性方法来预测缓冲器类型和位置，解决了ERC违规问题。该方法在不增加后布线功耗的情况下，实现了总负松弛量（TNS）的最大和平均改善分别为56%和31%，并在商业流程中实现了53%和28%的TNS改善，同时平均功耗提高了0.2%。", "conclusion": "MLBuf-RePlAce通过递归学习生成性的虚拟缓冲方法显著提高了分析性全局放置的时序闭合效果，且在不牺牲功耗的情况下实现了显著的性能提升。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00068", "html_url": "https://arxiv.org/abs/2506.00068", "title": "多语言LLMs在巴基斯坦语言中的政治偏见框架", "title_en": "Framing Political Bias in Multilingual LLMs Across Pakistani Languages", "authors": "Afrozah Nadeem,Mark Dras,Usman Naseem", "background": "大型语言模型（LLMs）越来越多地塑造公共话语，但大多数对政治和经济偏见的评估主要集中在资源丰富、西方语言和文化背景下。这在低资源、多语言地区，如巴基斯坦留下了很多盲点。在巴基斯坦，语言身份与政治、宗教和区域意识形态紧密相关。本研究系统性地评估了13种最先进的LLMs在5种巴基斯坦语言（乌尔都语、旁遮普语、信德语、普什图语和俾路支语）中的政治偏见。", "innovation": "本研究首次将文化适应的政治极点测试（PCT）与多维度框架分析相结合，评估了LLMs的政治偏见。这项研究的主要创新在于：1）评估了多语言LLMs在巴基斯坦不同语言中的表现；2）开发了一种结合了意识形态方向（经济/社会轴）和风格性框架（内容、语气和强调）的评估框架；3）设计了与巴基斯坦特定社会政治主题相匹配的提示。", "conclusion": "研究结果表明，虽然LLMs主要反映了与西方训练数据一致的自由左翼倾向，但在地区语言中表现出更强的专制框架。不同模型在不同语言中展现出一致的偏见模式。这些发现强调了全球NLP中需要基于文化背景的多语言偏见审计框架的必要性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08540", "html_url": "https://arxiv.org/abs/2507.08540", "title": "White-Basilisk：代码漏洞检测的混合模型", "title_en": "White-Basilisk: A Hybrid Model for Code Vulnerability Detection", "authors": "Ioannis Lamprou,Alexander Shevtsov,Ioannis Arapakis,Sotiris Ioannidis", "background": "软件漏洞的增多给网络安全带来了重大挑战，需要更有效的检测方法。现有检测方法的性能有限，且大规模AI模型在处理长序列时存在上下文限制，难以满足大型代码库的全面分析需求。", "innovation": "提出了一种名为White-Basilisk的新颖漏洞检测方法，该方法不仅性能优越，还挑战了目前AI模型规模的普遍认知。通过集成Mamba层、线性自注意力以及专家混合框架，White-Basilisk在仅有200M参数的情况下达到业界领先的效果。其处理超长序列的能力使得它能够一次性全面分析庞大的代码库，超越了现有大型语言模型的上下文限制。此外，White-Basilisk在不平衡、真实世界的数据集上表现出稳健的性能，并保持了高效的计算效率，适合在不同规模的组织中进行部署。", "conclusion": "这项研究不仅在代码安全性领域确立了新的基准，也为特殊任务中紧凑、高效设计的模型可以超越更大模型提供了实证证据，有可能重新定义特定领域的AI开发中的优化策略。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.18199", "html_url": "https://arxiv.org/abs/2506.18199", "title": "在大型语言模型中减轻对阿拉伯人和穆斯林文化偏见的提示工程技术：系统回顾", "title_en": "Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review", "authors": "Bushra Asseri,Estabrag Abdelaziz,Areej Al-Wabil", "background": "大型语言模型在各个领域展示了显著的能力，但对阿拉伯人和穆斯林的担忧文化偏见引发了重大伦理挑战，这可能导致有害的刻板印象和边缘化。尽管对语言模型中偏见的认识不断增加，但专门针对阿拉伯人和穆斯林代表性的提示工程策略仍被忽视。本研究采用混合方法系统回顾了这一领域，分析了2021年至2024年间8项研究，旨在探讨减轻这种偏见的技术，并提供了研究和实践者的证据基础指导。", "innovation": "本研究首次系统地评估了减轻大型语言模型对阿拉伯人和穆斯林文化偏见的提示工程技术，并分类了五种主要的提示工程技术：文化提示、情感唤醒、自我去偏技术、多步骤结构化管线和参数优化连续提示。研究表明，不同类型的偏见可能对提示工程技术的减轻效果不同，且某些多步骤结构化管线显示出最高的减轻效果。", "conclusion": "尽管提示工程技术显示出减轻偏见的潜力，但其效果在各种研究和偏见类型之间差异显著。研究发现，文化和情感唤醒提示工程技术更易于使用，而多步骤结构化管线技术虽然减轻偏见效果最好，但对技术要求更高。未来的研究应专注于开发文化适应性强的提示工程技术，创建阿拉伯人和穆斯林特定的评估资源，并将提示工程技术与互补的去偏方法相结合，以减轻更深层次的刻板印象，同时保持模型的实用性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.16725", "html_url": "https://arxiv.org/abs/2507.16725", "title": "RAvine: 现实对齐评估用于自主搜索", "title_en": "RAVine: Reality-Aligned Evaluation for Agentic Search", "authors": "Yilong Xu,Xiang Long,Zhi Zheng,Jinhua Gao", "background": "当前的检索增强智能搜索系统多采用代理搜索作为一种更自主和适应性强的检索模式，但仍缺乏评价框架与代理搜索目标的良好契合。现有基准中的复杂查询往往偏离实际用户搜索场景，而且以往方法在抽取用于端到端评估的真实标注时引入噪声，导致细粒度评估结果失真。此外，大部分现有框架仅关注最终答案的质量，忽略代理搜索固有的迭代过程评估。", "innovation": "提出 RAVine -- 一种用于具有搜索功能的自主语言模型的现实对齐评价框架。RAvine 旨在支持多点查询和长格式答案，更好地反映用户意图，并采用可归属的真实标注策略以增强细粒度评估的准确性。此外，RAvine 还考察了模型在整个迭代过程中与检索工具的交互，并考虑效率因素。", "conclusion": "使用 RAVine 对一系列模型进行基准测试并得出一些见解，期待这些成果能为自主搜索系统的开发做出贡献。有关代码和数据集可访问 this https URL。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.10073", "html_url": "https://arxiv.org/abs/2507.10073", "title": "大型语言模型中的文化偏见：通过道德问卷评估人工智能代理", "title_en": "Cultural Bias in Large Language Models: Evaluating AI Agents through Moral Questionnaires", "authors": "Simon Münker", "background": "研究发现，尽管大型语言模型（LLMs）具有强大的语言能力，但它们未能代表多元文化道德框架。研究者通过应用道德基础问卷，在19种文化背景下比较了多种最先进的LLMs，与人类基线数据，揭示了模型系统性地同质化道德多样性的问题。这一发现挑战了将LLMs作为社会科学研究中合成人群使用的趋势，指出现有AI对齐方法中的根本局限性。研究指出，除非采用数据驱动的对齐目标和评估指标来确保系统捕捉到具体的、文化特异性的道德直觉，否则这些系统无法真正代表多样的人类价值观，可能不具备深度反映人类文化价值的能力。", "innovation": "研究使用道德基础问卷在多文化背景下评估了多个顶级LLMs，揭示了这些模型在文化代表性上的系统性偏差。此外，研究还发现模型规模的增加并不总是提高文化代表性的准确性。这一创新点挑战了关于LLMs广泛用途的假设，并提供了实证依据来支持对齐方法的需要改进。", "conclusion": "研究结果强调了需要设定更具体的对齐目标和评估指标，以确保AI系统能够真正代表多样的人类价值观，而不是简单地压平道德景观。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.19115", "html_url": "https://arxiv.org/abs/2507.19115", "title": "在爱立信使用大型语言模型进行自动代码审查的经验报告", "title_en": "Automated Code Review Using Large Language Models at Ericsson: An Experience Report", "authors": "Shweta Ramesh,Joy Bose,Hamender Singh,A K Raghavan,Sujoy Roychowdhury,Giriprasad Sridhara,Nishrith Saini,Ricardo Britto", "background": "代码审查是确保发布软件质量的主要手段之一，与测试和静态分析并重。然而，代码审查需要经验丰富的开发人员来完成，这可能会导致他们没有足够的时间进行深入的代码审查。因此，利用机器自动化代码审查可以减轻经验丰富的软件开发者的认知负担，使他们能够专注于编写代码以添加新功能和修复漏洞。", "innovation": "本文描述了在爱立信使用大型语言模型（LLMs）来实现代码审查过程自动化的经验。开发了一个轻量级工具，结合了LLMs和静态程序分析。", "conclusion": "对经验丰富的开发人员初步实验表明，该代码审查工具有令人鼓舞的结果。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.17745", "html_url": "https://arxiv.org/abs/2507.17745", "title": "Ultra3D：具有部分注意力的高效高保真3D生成", "title_en": "Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention", "authors": "Yiwen Chen,Zhihao Li,Yikai Wang,Hu Zhang,Qin Li,Chi Zhang,Guosheng Lin", "background": "近年来，稀疏体素表示的进步显著提升了3D内容生成的质量，使得高分辨率建模成为可能。然而，现有框架在两个阶段的扩散管道中由于注意力机制的二次复杂性而遭受严重的计算效率低下问题。", "innovation": "本文提出了一种高效的3D生成框架Ultra3D，它在不牺牲质量的情况下显著加速了稀疏体素建模。该方法利用紧凑的VecSet表示，在第一阶段高效生成粗略对象布局，减少了标记数量并加速了体素坐标预测。作为第二阶段的改进，引入了部分注意力机制Part Attention，这是一种几何感知的局部注意力机制，限制了在语义一致的部分区域内的注意计算，从而保持结构连续性并避免不必要的全局注意力，实现了高达6.7倍的潜在生成速度提升。此外，建立了一个可扩展的部分注解管道，将原始网格转换为部分标记的稀疏体素。", "conclusion": "大量实验表明，Ultra3D支持1024分辨率的高分辨率3D生成，并在视觉保真度和用户偏好方面实现最佳性能。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22174", "html_url": "https://arxiv.org/abs/2507.22174", "title": "基于非马尔可夫流量的时空强化学习在网络路由中的应用", "title_en": "Spatial-Temporal Reinforcement Learning for Network Routing with Non-Markovian Traffic", "authors": "Molly Wang,Kin.K Leung", "background": "强化学习(RL)已经广泛应用于通信网络中的数据包路由。然而，传统的RL方法依赖于马尔可夫假设，即当前状态包含了所有必要的信息以进行决策。实际上，互联网流量是非马尔可夫的，过去的状态对路由性能有影响。此外，常见的深度RL方法使用神经网络等函数逼近器，这些逼近器不能模拟网络拓扑的空间结构。", "innovation": "为了应对上述不足，设计了一个具有非马尔可夫流量的网络环境，并引入了时空RL（STRL）框架进行数据包路由。该方法在训练阶段比传统基线提高了超过19%，在推理阶段提高了7%，即使在网络拓扑发生变化的情况下。", "conclusion": "相比传统方法，时空RL框架在处理非马尔可夫流量的网络路由问题上表现出更好的性能，尤其是在网络拓扑结构变化的情况下。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.07695", "html_url": "https://arxiv.org/abs/2507.07695", "title": "KeyKnowledgeRAG (K²RAG): 一种改进的RAG方法，以增强大型语言模型的问答能力", "title_en": "KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities", "authors": "Hruday Markondapatnaikuni,Basem Suleiman,Abdelkarim Erradi,Shijing Chen", "background": "在重新训练大型语言模型（LLMs）以纳入更大知识体量的过程中，微调是一个极其资源密集的过程。尽管已经开发了多种技术来减少时间和计算成本，但随着LLMs的不断增长和复杂化，这个挑战仍然存在。为应对这一挑战，需要一种新的知识扩展方法。检索增强生成（RAG）提供了一种选择，通过将外部知识存储在数据库中并检索相关的片段来支持问答。然而，RAG的直接实现方式在可扩展性和答案准确性方面存在重大局限性。本文提出了一种新型框架KeyKnowledgeRAG（K2RAG），该框架受到分而治之的启发，通过融合密集和稀疏向量搜索、知识图谱和文本摘要来提高检索质量和系统效率。", "innovation": "K2RAG框架融合了密集向量搜索、稀疏向量搜索、知识图谱和文本摘要技术，旨在优化检索质量和系统效率。该框架还包括预处理步骤，对训练数据进行摘要，显著减少了训练时间。评估结果表明，K2RAG在MultiHopRAG数据集上的管道训练和验证中表现优于传统的RAG实现。K2RAG实现了最高0.57的平均答案相似度得分，第三四分位数（Q3）相似度达到了0.82，表明与基准答案有更好的对齐效果。此外，该框架还表现出高效率，摘要步骤将每个组件的平均训练时间减少了93%，执行速度比传统的基于知识图谱的RAG系统快了40%。K2RAG还表现出更好的可扩展性，所需VRAM仅为几种测试的RAG实现的三分之一。", "conclusion": "K2RAG通过集成密集向量搜索、稀疏向量搜索、知识图谱和文本摘要等技术，有效解决了RAG方法在可扩展性和答案准确性方面的局限性，显著提高了检索质量和系统效率，并在执行速度和可扩展性方面优于现有RAG实现。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21004", "html_url": "https://arxiv.org/abs/2507.21004", "title": "组合函数网络：内置可解释性的高性能替代深度神经网络", "title_en": "Compositional Function Networks: A High-Performance Alternative to Deep Neural Networks with Built-in Interpretability", "authors": "Fang Li", "background": "深度神经网络（DNNs）在性能上表现出色，但由于其黑箱性质，在需要透明度的高风险领域中的应用受到限制。已有的一些可解释性方法通常只能处理简单的加法结构，而不能支持复杂的特征交互，这在透明性和性能之间寻求平衡时是个挑战。本文提出了一种名为组合函数网络（CFNs）的新框架，通过组合具有清晰语义的基本数学函数来构建可解释模型，支持序列、并行和条件等多种组合模式，从而在保持透明性的同时实现复杂特征交互。", "innovation": "CFNs 是完全可微的，可以通过标准梯度下降进行高效训练。与现有的可解释模型相比，CFNs 在多个领域中展示了其 versatility，包括符号回归和使用深度分层网络进行图像分类。实证分析显示，与黑箱模型相比，CFNs 在 CIFAR-10 数据集上的准确率达到 96.24%，并且在可解释性方面超越了 Explainable Boosting Machines 等现有最先进的可解释模型。", "conclusion": "CFNs 通过结合深度学习的分层表达能力和精心定义的数学函数的内在可解释性，提供了一种在性能和问责制方面兼备的强大框架。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21433", "html_url": "https://arxiv.org/abs/2507.21433", "title": "MemShare：通过 KV 缓存重用实现大型推理模型的内存高效推理", "title_en": "MemShare: Memory Efficient Inference for Large Reasoning Models through KV Cache Reuse", "authors": "Kaiwen Chen,Xin Tan,Minchen Yu,Hong Xu", "background": "大型推理模型 (LRMs) 在数学推理和形式逻辑任务中取得了显著进展。然而，它们生成较长的推理链路导致推理过程中产生大量内存开销。我们观察到，LRMs 经常产生高度相似的中间推理步骤，这些步骤对应于层间类似的 KV 缓存状态。这些发现促使我们提出一种新型的 KV 缓存管理方法 MemShare，该方法能够有效减少内存开销。", "innovation": "MemShare 采用协同过滤算法高效地识别可重用的 KV 缓存块，并实现零复制缓存重用，从而显著减少内存开销、提高吞吐量同时保持准确性。实验结果表明，MemShare 可以在保持更高的准确性的同时，将吞吐量提高高达 84.79%。", "conclusion": "实验结果证明，MemShare 在不牺牲准确性的前提下，将吞吐量提高了多达 84.79%，同时比现有 KV 缓存管理方法有效降低了内存开销。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21288", "html_url": "https://arxiv.org/abs/2507.21288", "title": "学习具有空间变化构成属性的可模拟纺织模型", "title_en": "Learning Simulatable Models of Cloth with Spatially-varying Constitutive Properties", "authors": "Guanxiong Chen,Shashwat Suri,Yuhao Wu,Etienne Voulga,David I.W. Levin,Dinesh K. Pai", "background": "纺织材料由于缝制、熨边、染色、印花、填充和粘合等常见工艺表现出显著的复杂性和空间变化。使用有限元方法模拟这些材料尽管准确性高，但通常计算量大且速度慢。更糟糕的是，这种方法可能会遭受称为“膜锁紧”的数值伪影，这会使布料显得人工僵硬。", "innovation": "本文提出了一种通用框架，称为Mass-Spring Net，用于仅从运动观测学习一个简单有效的代理模型，以捕捉这些复杂材料的效果。该方法通过未知的材料参数来离散化布料，并使用新颖的力和冲量损失函数从运动数据中直接学习这些参数。此方法能够从多种数据源准确模拟空间变化的材料属性，并对基于FEM的模拟中常见的膜锁紧现象免疫。相比基于图的网络和神经ODE架构，本文的方法实现了显著更快的训练时间、更高的重构精度以及更好的对新颖动态场景的泛化能力。", "conclusion": "本文的提出的Mass-Spring Net框架能够高效、准确地模拟具有空间变化属性的纺织材料，并克服了有限元方法中的膜锁紧问题，具有显著的训练效率和泛化能力优势。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.19119", "html_url": "https://arxiv.org/abs/2507.19119", "title": "PatchTraj: 统一的时间-频率表示学习方法通过动态片段进行轨迹预测", "title_en": "PatchTraj: Unified Time-Frequency Representation Learning via Dynamic Patches for Trajectory Prediction", "authors": "Yanghong Liu,Xingping Dong,Ming Li,Weixing Zhang,Yidong Lou", "background": "行人轨迹预测对于无人驾驶和机器人技术至关重要。现有的基于点和基于格的方法存在两大限制：无法充分建模人类运动动力学，尤其是在平衡局部运动细节与长时间空间时间依赖性方面存在不足；时间表示缺乏与频率成分的交互作用，在共同建模轨迹序列时表现不足。", "innovation": "我们提出了一种基于动态片段的框架——PatchTraj，该框架结合时间-频率联合建模进行轨迹预测。具体来说，该方法将轨迹分解为原始时间序列和频率分量，并采用动态片段划分进行多尺度分割，捕捉层次化的运动模式。每个片段进行具有尺度意识的特征嵌入和层次特征聚合，以建模细粒度和长程依赖关系。通过跨模态注意力增强两个分支的输出，促进时间和频谱线索的互补融合。增强后的嵌入表示具有强大的表征能力，即使使用朴素的Transformer架构也能实现精确预测。实验证明，该方法在ETH-UCY、SDD、NBA和JRDB数据集上达到了最先进的性能，特别是在第一人称JRDB数据集上，PatchTraj在ADTE和FDTE指标上分别取得了26.7%和17.4%的显著相对改进，突显了其在具身智能方面的巨大潜力。", "conclusion": "PatchTraj通过结合时间-频率联合建模在多尺度分割中捕捉层次化的运动模式，并通过跨模态注意力实现细粒度和长程依赖性建模，显著提升了轨迹预测的性能，特别是在基于第一人称的JRDB数据集上，性能大幅提升。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22498", "html_url": "https://arxiv.org/abs/2507.22498", "title": "基于频谱空间分组的鲁棒恶劣天气去除", "title_en": "Robust Adverse Weather Removal via Spectral-based Spatial Grouping", "authors": "Yuhwan Jeong,Yunseo Yang,Youngho Yoon,Kuk-Jin Yoon", "background": "恶劣天气导致多样的复杂退化模式，推动了AiO模型的发展。然而，现有的AiO解决方案仍然难以捕捉到各种退化，因为传统的全局滤波方法（如频域直接操作）无法处理高度变化且局部化的退化现象。因此，需要开发新的方法来应对这些问题。", "innovation": "提出了一种名为Spectral-based Spatial Grouping Transformer (SSGformer)的新颖方法，利用频谱分解和组间的注意机制处理多天气条件的图像恢复。SSGformer通过传统的边缘检测分解图像的高频边缘特征，通过奇异值分解获取低频信息，并通过多头线性注意力模型构建特征间的关系。它创建一个融合特征的组合掩码，根据空间相似性和图像纹理对区域进行聚类。还提出了一个结合通道注意力和空间注意力的空间分组变换器块，有效平衡了特征间的关联和空间依赖性。", "conclusion": "广泛的实验验证了该方法的有效性，表明其在处理复杂多变的恶劣天气退化方面具有明显优势，提供了鲁棒的消除恶劣天气的方法，保证了在各种天气条件下的一致性能。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22477", "html_url": "https://arxiv.org/abs/2507.22477", "title": "LIDAR: 轻量化适应性特征感知融合Vision Mamba用于结构裂缝的多模态分割", "title_en": "LIDAR: Lightweight Adaptive Cue-Aware Fusion Vision Mamba for Multimodal Segmentation of Structural Cracks", "authors": "Hui Liu,Chen Jia,Fan Shi,Xu Cheng,Mengfei Shi,Xia Xie,Shengyong Chen", "background": "在使用多模态数据实现像素级裂缝分割时，保持低计算成本具有关键挑战。现有方法缺乏多模态特征的自适应感知和高效交互融合的能力。这些限制阻碍了精确和高效的裂缝检测与识别。", "innovation": "本文提出了一种轻量化适应性特征感知融合Vision Mamba网络（LIDAR），通过引入一种轻量化适应性特征感知视觉状态空间模块（LacaVSS）和一种轻量化双重域动态协作融合模块（LD3CF）。LacaVSS利用掩码引导的有效动态指导扫描策略（EDG-SS）自适应建模裂缝特征，而LD3CF通过自适应频域感知器（AFDP）和双重池化融合策略，在不同模态间有效捕捉空间和频域特征。此外，设计了轻量化动态调节多核卷积（LDMK）来感知复杂形态结构，同时减少计算负担。实验结果表明，该方法优于其他最新方法。在轻场深度数据集上，该方法仅使用5.35M参数，实现了0.8204的F1值和0.8465的mIoU值。", "conclusion": "通过引入LIDAR网络，本文实现了在多模态裂缝分割中保持精确性与低计算成本之间的平衡，验证了其在实际应用中的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22789", "html_url": "https://arxiv.org/abs/2507.22789", "title": "G-Core：一种简单、可扩展且平衡的RLHF训练器", "title_en": "G-Core: A Simple, Scalable and Balanced RLHF Trainer", "authors": "Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Haoqiang Hong,Boqi Liu,Hongtao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao", "background": "强化学习从人类反馈（RLHF）已成为训练大规模语言模型（LLM）和扩散模型的日益流行的范式。尽管现有的RLHF训练系统取得了显著进步，但在向多模态和扩散工作流扩展以及适应动态工作负载方面，它们往往面临挑战。当前方法在处理复杂的RLHF流水线时，尤其是在涉及动态采样或生成性奖励建模的情景下，可能会遇到控制器可扩展性、灵活资源放置和高效编排的限制。", "innovation": "G-Core引入了一种并行控制器编程模型，能够灵活且高效地编排复杂的RLHF工作流，而不会受到单一集中控制器瓶颈的限制。此外，G-Core提出了一个适应性资源划分方案，能够在高度变化的训练条件下显著减少硬件闲置时间并提高资源利用率。", "conclusion": "G-Core已经在支持微信产品功能的模型训练中得到成功应用，证明了其在真实场景中的有效性和鲁棒性。我们的结果表明，G-Core在RLHF训练方面取得了现有技术的突破，为未来的大规模、人类对齐模型的研究和部署提供了坚实的基础。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22530", "html_url": "https://arxiv.org/abs/2507.22530", "title": "HRVVS：一种基于分层自回归残差先验的高分辨率视频血管分割网络", "title_en": "HRVVS: A High-resolution Video Vasculature Segmentation Network via Hierarchical Autoregressive Residual Priors", "authors": "Xincheng Yao,Yijun Yang,Kangwei Guo,Ruiqiang Xiao,Haipeng Zhou,Haisu Tao,Jian Yang,Lei Zhu", "background": "肝血管在肝切除手术中的分割对临床具有重要价值，然而由于缺乏合适的数据集和任务本身的高度复杂性，该领域很少有研究报道。现有的问题在于缺少高质量的标注数据集，并且进行视频血管分割非常复杂，较少的研究能够提供有效的解决方案。", "innovation": "提出了一种新的高分辨率视频血管分割网络（HRVVS）。通过在不同层次的分层编码器中嵌入预训练的视觉自回归模型（VAR）作为先验信息，减少了下采样过程中产生的信息退化。此外，设计了多视图分割网络的动态记忆解码器，以最小化冗余信息的传递并保留更多帧之间的细节信息。这一网络在多个外科视频数据集上的实验结果显示，HRVVS 显著优于现有的最好方法。", "conclusion": "通过提供的高分辨率视频标注数据集和HRVVS网络，证明了在肝切除手术视频中血管分割的显著改进。开放的源代码和数据集可以在指定的网址获取。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22069", "html_url": "https://arxiv.org/abs/2507.22069", "title": "A Compute-Matched Re-Evaluation of TroVE on MATH", "title_en": "A Compute-Matched Re-Evaluation of TroVE on MATH", "authors": "Tobias Sesterhenn,Ian Berlot-Attwell,Janis Zenkner,Christian Bartelt", "background": "数学问题求解中重用已有的定理和公式是核心，它们作为构建复杂挑战的关键模块。TroVE这一近期工作提出，代码生成型大型语言模型（LLMs）可以在MATH基准测试中获得类似的好处，通过诱导和重用高级工具箱。TroVE通过在三种模式间分配计算预算——直接生成代码、创建工具、重用工具——声称超越了仅进行直接生成的原始基础线PRIMITIVE。然而，最新的分析指出，TroVE创建的工具往往是简单的且很少被重用，这可能归因于自我一致性或自我修正。", "innovation": "本研究重新评估了TroVE在MATH基准上的表现，分析了每种模式的影响，并表明TroVE的优势不是来自于机制，而是由于更高的计算预算所造成的。我们还对TroVE的选择机制进行了一项小型修正，提高了其在MATH上的准确率。最终结果显示，在匹配计算资源后，TroVE仅获得了1%的小幅改进。", "conclusion": "TroVE的工具箱方法在MATH上并没有提供显著的优势。因此，这种方法可能不是提高性能的有效手段。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22913", "html_url": "https://arxiv.org/abs/2507.22913", "title": "一种结合嵌入式回归模型与大语言模型的主题分析混合框架", "title_en": "A Hybrid Framework for Subject Analysis: Integrating Embedding-Based Regression Models with Large Language Models", "authors": "Jinyu Liu,Xiaoying Song,Diana Zhang,Jason Thomale,Daqing He,Lingzi Hong", "background": "为信息资源提供主题访问是任何图书馆管理系统的基本功能。尽管大型语言模型（LLMs）已经广泛应用于分类和总结任务，但它们在主题分析方面的潜力尚未得到充分开发。传统机器学习（ML）模型的多标签分类虽然被用于主题分析，但在处理未知案例时表现不佳。LLMs虽然提供了一种新的选择，但常常生成过量和虚构的内容。", "innovation": "本文提出了一种结合嵌入式回归模型与LLMs的混合框架。该方法利用ML模型（1）预测合适的洛布斯主题标签数量以指引LLMs的预测，（2）对预测术语进行实际的洛布斯主题编辑，以减轻虚构内容。", "conclusion": "实验结果表明，通过提供初始预测来引导LLMs的生成过程，并施加后编辑，能够生成更加可控和词汇匹配的结果。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22607", "html_url": "https://arxiv.org/abs/2507.22607", "title": "VL-Cogito: 进阶多模态推理的渐进课程强化学习", "title_en": "VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning", "authors": "Ruifeng Yuan,Chenghao Xiao,Sicong Leng,Jianyu Wang,Long Li,Weiwen Xu,Hou Pong Chan,Deli Zhao,Tingyang Xu,Zhongyu Wei,Hao Zhang,Yu Rong", "background": "强化学习已被证明能够提升大型语言模型的推理能力。最近的研究已经逐步将这一范式扩展到多模态推理任务中。由于多模态任务的固有复杂性和多样性，特别是在语义内容和问题表述上，现有的模型在不同领域和难度级别上经常表现出不稳定的表现。为了解决这些局限性，我们提出了基于新型多阶段渐进课程强化学习（PCuRL）框架的VL-Cogito，这是一种高级多模态推理模型。PCuRL通过逐步增加任务难度系统地指导模型，并显著提高了其在各种多模态背景下的推理能力。该框架引入了两个关键创新：（1）在线难度软加权机制，动态调整后续强化学习训练阶段的训练难度；（2）动态长度奖励机制，鼓励模型根据任务复杂性适当地调节推理路径长度，从而平衡推理效率与正确性。", "innovation": "提出了基于新型多阶段渐进课程强化学习（PCuRL）框架的VL-Cogito。该框架包含两个关键创新：（1）在线难度软加权机制，动态调整训练难度；（2）动态长度奖励机制，调节推理路径长度，平衡推理效率与正确性。", "conclusion": "通过实况评估展示了VL-Cogito在主流多模态基准测试中的表现，覆盖了数学、科学、逻辑和常识理解等领域的推理任务，验证了该方法的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22910", "html_url": "https://arxiv.org/abs/2507.22910", "title": "大型语言模型在旅游领域的应用经验", "title_en": "Large Language Models in the Travel Domain: An Industrial Experience", "authors": "Sergio Di Meglio,Aniello Somma,Luigi Libero Lucio Starace,Fabio Scippacercola,Giancarlo Sperlì,Sergio Di Martino", "background": "在线房源预订平台依赖于一致且最新的住宿信息，通常这些信息来源于第三方提供商，但这些外部数据源常常存在信息不完整或不一致的情况，容易让用户感到沮丧并导致市场份额的损失。为应对这些挑战，本文介绍了一个工业案例研究，将大型语言模型（LLMs）集成到FERVENTO开发的CALEIDOHOTELS预订平台上。评估了两个流行的LLMs模型：Mistral 7B（经过QLoRA微调）和Mixtral 8x7B（利用精炼系统提示）。", "innovation": "将大型语言模型应用于旅游行业的房源预订平台，评估了模型生成一致且同质描述的能力，同时尽量减少幻觉（虚构或错误信息）。结果显示，Mixtral 8x7B在完成度、精确度等方面优于Mistral 7B，但计算成本显著增加。这项工作提供了关于模型质量和资源效率之间权衡的实际见解，并为在生产环境中部署LLMs提供了指导，同时展示了LLMs在增强房源数据的一致性和可靠性方面的有效性。", "conclusion": "大型语言模型在旅游预订平台上的应用展示了它们在提高房源信息一致性和可靠性方面的潜力，但也需要注意计算成本。通过权衡模型质量与资源效率，可以更有效地部署这些模型。"}
{"llm_update_time": "20250801", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22633", "html_url": "https://arxiv.org/abs/2507.22633", "title": "H2Tune: 具有混合异质性的联邦基础模型微调", "title_en": "H2Tune: Federated Foundation Model Fine-Tuning with Hybrid Heterogeneity", "authors": "Wei Guo,Siyuan Lu,Yiqi Tong,Zhaojun Hu,Fuzhen Zhuang,Xiao Zhang,Tao Fan,Jin Dong", "background": "现有的联邦微调（FFT）方法主要集中在单一异质的联邦微调场景中，而忽视了模型架构和下游任务双重异质的混合异质联邦微调（HHFFT）场景。这种混合异质性带来了两个重要挑战：1) 异质矩阵聚合，不同客户端根据其任务需求和资源限制采用不同的大规模基础模型，导致LoRA参数聚合时存在维度不匹配问题；2) 多任务知识干扰，本地共享参数在同时包含了任务共性和特定知识的情况下，不能确保仅进行任务共性知识的跨客户端传输。", "innovation": "该研究提出H2Tune框架，用于解决混合异质性带来的挑战。H2Tune框架包括三个关键组件：(i) 裁剪三重矩阵分解（SPARSED TRIPLE MATRIX DECOMPOSITION），通过构建秩一致中间矩阵来对齐客户端的隐藏维度，基于客户端资源进行自适应裁剪；(ii) 关系引导矩阵层对齐（RELATION-GUIDED MATRIX LAYER ALIGNMENT），处理异质层结构和表示能力；(iii) 交替任务知识解缠机制（ALTERTING TASK-KNOWLEDGE DISENTANGLEMENT MECHANISM），通过交替优化来解耦本地模型参数的共享和特定知识。理论分析证明了收敛速率为O(1/√T)。实验结果表明，该方法相较于最先进的基准提高了最多15.4%的准确率。", "conclusion": "我们的代码可以在以下网址获得：this https URL ."}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22919", "html_url": "https://arxiv.org/abs/2507.22919", "title": "从前瞻性注册预测临床试验中的严重不良事件结果的新型语言模型", "title_en": "A novel language model for predicting serious adverse event results in clinical trials from their prospective registrations", "authors": "Qixuan Hu,Xumou Zhang,Jinman Kim,Florence Bourgeois,Adam G. Dunn", "background": "临床试验的设计往往需要精确估计预期的安全结果，以避免试验过早终止和减少不必要的参与者风险。目前，临床试验注册数据中包含的结果摘要信息尚未得到充分利用。本研究旨在利用这些数据来预测临床试验中的严重不良事件（SAE）结果，从而优化试验设计并发现预期与报告的安全结果间的差异。", "innovation": "研究开发了两个预测模型，一个是分类器，用于预测哪一试验臂的严重不良事件率更高（AUC），另一个是回归模型，用于预测对照组的严重不良事件比例（RMSE）。研究使用预训练语言模型（如ClinicalT5和BioBERT）进行特征提取，并结合滑动窗口方法处理长文本。研究发现，使用滑动窗口方法的模型在预测方面表现出优越性能，提高了AUC和降低了RMSE。", "conclusion": "注册数据中的结果摘要仍有很大的利用潜力。通过这一研究，可以实现对试验结果的预估，从而改进试验设计，并及时发现预期与实际报告的安全结果之间的偏差。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22911", "html_url": "https://arxiv.org/abs/2507.22911", "title": "ElectriQ：评估电力营销场景中大型语言模型响应能力的标准", "title_en": "ElectriQ: A Benchmark for Assessing the Response Capability of Large Language Models in Power Marketing", "authors": "Jinzhi Wang,Qingke Peng,Haozhou Li,Zeyuan Zeng,Qinfeng Song,Kaixuan Yang,Jiangbo Zhang,Yaoying Wang,Ruimeng Li,Biyi Zhou", "background": "电力营销顾客服务在处理咨询、投诉和服务请求方面发挥着关键作用。然而，当前系统，如中国的95598热线，在响应速度、灵活性和特定领域任务准确性方面存在不足。虽然大型语言模型（LLMs）如GPT-4o和Claude 3表现出较强的通用能力，但在领域专业知识和同理心方面尚有欠缺。", "innovation": "为弥补这一差距，本文提出了ElectriQ，第一个专门设计用于评估和提升电力营销场景中LLMs的表现的基准。ElectriQ包括一个涵盖六个关键服务类别的对话数据集，并引入了四种评估指标：专业性、普及性、可读性和用户友好性。此外，还融入了领域特定知识库，并提出了一种知识增强方法来提升模型性能。实验结果表明，经过微调和增强的小型模型，如LLama3-8B，在专业性和用户友好性方面可以超越GPT-4o。", "conclusion": "ElectriQ为开发符合电力营销服务需求的LLMs奠定了全面的基础。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22912", "html_url": "https://arxiv.org/abs/2507.22912", "title": "跨深/暗网和社会平台的语义模型驱动半监督集成框架用于非法市场检测", "title_en": "A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms", "authors": "Navid Yazdanjue,Morteza Rakhshaninejad,Hossein Yazdanjouei,Mohammad Sadegh Khorshidi,Mikko S. Niemela,Fang Chen,Amir H. Gandomi", "background": "随着非法市场转向互联网隐蔽部分，包括深网和暗网以及Telegram、Reddit和Pastebin等平台，匿名交易非法货物（如毒品、武器和盗窃凭证）变得更为便捷。然而，检测和分类这种内容仍然具有挑战性，原因包括有限的标记数据、非法语言的发展变化以及在线资源的结构性差异。因此，该研究提出了一个分层分类框架，结合了微调的语言模型和半监督集成学习策略，以覆盖不同平台上的非法市场内容。", "innovation": "本研究创新性地使用了分层分类框架结合微调的语言模型与半监督集成学习策略来检测和分类跨深/暗网和社会平台的非法市场内容。具体包括：1）采用ModernBERT进行语义表示，这是一种针对域特定数据的长文档变换器模型；2）结合了手工工程特征，如文档结构、嵌入模式（包括比特币地址、电子邮件和IP地址）以及元数据；3）分类管道分为两阶段：第一阶段使用半监督集成模型（XGBoost、随机森林和SVM）检测销售相关文档，第二阶段进一步分类为毒品销售、武器销售或凭证销售。", "conclusion": "实验结果显示，该模型在三个数据集（包括多来源语料库、DUTA和CoDA）上优于多项基线模型，包括BERT、ModernBERT、DarkBERT、ALBERT、Longformer和BigBird。具体而言，模型的准确率为0.96489、F1分为0.93467和TMCC为0.95388，显示出强的泛化能力、在有限监督下的鲁棒性和在实际非法内容检测中的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22917", "html_url": "https://arxiv.org/abs/2507.22917", "title": "在时间轴间推理：面向历时性问题的RAG", "title_en": "Reading Between the Timelines: RAG for Answering Diachronic Questions", "authors": "Kwun Hang Lau,Ruiyuan Zhang,Weijie Shi,Xiaofang Zhou,Xiaojun Cheng", "background": "检索增强生成（RAG）在将静态事实知识注入大型语言模型（LLMs）方面表现出色，但在处理需要跟踪时间进程中的实体和现象的历时性查询时存在关键缺陷。传统的基于语义的检索方法无法收集既在主题上相关又在时间上连贯的证据集，尤其是对于指定的持续时间要求。因此，该研究旨在通过引入一个新的框架来根本性地重新设计RAG管道并注入时间逻辑，以解决这一挑战。", "innovation": "提出了一个新的框架，旨在解决RAG在处理历时性查询时存在的关键缺陷。该框架首先将用户查询分解为核心主题及其时间窗口，随后使用一个专门的检索器进行语义匹配，以时间相关性为校准，确保收集到一个在整段时间跨度内的连续证据集。此外，还 introduces ADQAB评测基准，提供了一个挑战性的评估套件，适用于现实和合成金融新闻的混合语料库。实验结果表明，在该基准上，所提出的方法在答案准确性上显著提高，比标准RAG实施版本高出13%到27%。", "conclusion": "该研究提供了迈向能够进行复杂现实世界问题所需精细、演化分析的RAG系统的验证途径。实验数据和代码已公开。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22915", "html_url": "https://arxiv.org/abs/2507.22915", "title": "在大型语言模型中的幻觉的理论基础及其缓解", "title_en": "Theoretical Foundations and Mitigation of Hallucination in Large Language Models", "authors": "Esmail Gumaan", "background": "大型语言模型（LLMs）可能会生成与输入或现实世界事实不一致的内容，这被称为幻觉。目前的研究致力于对LLMs中的幻觉进行严谨处理，包括形式化定义和理论分析，但缺乏统一的检测和缓解策略以及评估方法。本文总结了幻觉的检测与缓解策略，为LLMs中的幻觉问题提供了理论基础和实用指南。", "innovation": "本文创新性地定义了LLMs中的内在和外在幻觉，并提出了一种幻觉风险的度量方法。通过学习理论框架（PAC-Bayes和Rademacher复杂性），推导出幻觉风险的上界。此外，本文还调查了幻觉检测策略，包括基于词素的不确定估计、自信校准和注意力对齐检查，并讨论了几种缓解策略，包括检索增强生成、幻觉意识微调、逻辑校准和事实验证模块的集成。提出了一个统一的检测和缓解工作流程，以整合这些策略，并建议了用于幻觉评估的数据集、度量标准和实验设置，为量化和减少幻觉提供了规范。", "conclusion": "本文为LLMs中幻觉问题提供了坚实的理论基础和实用指南，提出了一种统一的检测和缓解工作流程，旨在解决幻觉这一重要挑战。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22914", "html_url": "https://arxiv.org/abs/2507.22914", "title": "全三元匹配器：在异构知识图谱之间整合所有三元组元素", "title_en": "Full Triple Matcher: Integrating all triple elements between heterogeneous Knowledge Graphs", "authors": "Victor Eiti Yamamoto,Hideaki Takeda", "background": "知识图谱（KGs）是表示和推理结构化信息的强大工具，主要组成部分包括模式、身份和上下文。模式匹配和身份匹配在本体和实体匹配研究中已有成熟的方法，但上下文匹配仍然不被充分研究。实际应用场景中的知识图谱来源广泛、规模各异、信息密度不同，这在现有的实体匹配方法数据集中很少被考虑。因此，现有的方法在需要结合多样且复杂的上下文场景中表现不佳。", "innovation": "为解决这一问题，本文提出了一种新颖的知识图谱集成方法，包括标签匹配和三元组匹配。通过字符串操作、模糊匹配和向量相似度技术对实体和谓词标签进行对齐。识别传递类似信息的三元组映射，利用这些映射提高实体匹配的准确性。该方法在OAEI竞赛中表现与领先系统相当，并优于监督方法，在各种测试案例中取得高精度。", "conclusion": "本文提出了一种新颖的知识图谱集成方法，并通过一个新的数据集有效评估了三元组匹配的性能。实验结果表明，该方法具有较高的准确性和竞争力。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22918", "html_url": "https://arxiv.org/abs/2507.22918", "title": "语义收敛：探讨规模缩放LCLMs之间的共享表示", "title_en": "Semantic Convergence: Investigating Shared Representations Across Scaled LLMs", "authors": "Daniel Son,Sanjana Rathore,Andrew Rufail,Adrian Simon,Daniel Zhang,Soham Dave,Cole Blondin,Kevin Zhu,Sean O'Brien", "background": "研究Gemma-2语言模型（Gemma-2-2B和Gemma-2-9B）在不同规模下的特性一致性。探讨规模相差四倍的模型在内部概念上的收敛程度，利用稀疏自编码器（SAE）的字典学习管道，以激活相关性对不同模型的残差流激活结果进行对齐，使用SVCCA和RSA比较匹配的特征空间。结果显示，中间层的特征重叠度最强，而早期和晚期的层显示出显著较少的相似性。初步实验将分析从单个词扩展到多词子空间，发现语义相似的子空间以相似的方式与语言模型互动，这表明大规模语言模型在规模差异的情况下仍然切割世界为大致相似且可解释的特征，从而加强了跨模型解释性的一致性作为基础的观点。", "innovation": "利用稀疏自编码器在不同规模的Gemma-2语言模型上对残差流激活结果进行对齐，并使用SVCCA和RSA比较匹配的特征空间。初步实验扩展到了多词子空间，验证了语义相似的子空间以相似的方式与语言模型互动，这为大规模语言模型的特征一致性提供了新的证据。", "conclusion": "大规模语言模型在尺寸差异下仍然切割世界为大致相似且可解释的特征，这为跨模型解释性提供了基础，并为理解语言模型的内部工作原理提供了一种新的视角。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22925", "html_url": "https://arxiv.org/abs/2507.22925", "title": "Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents", "title_en": "Hierarchical Memory for High-Efficiency Long-Term Reasoning in LLM Agents", "authors": "Haoran Sun,Shaoning Zeng", "background": "长时记忆是影响大型语言模型代理（LLM代理）推理能力的关键因素之一。现有的记忆机制虽然在记忆的存储和检索方面取得了进展，如将记忆编码为密集向量进行相似度搜索或以图形形式组织知识，但在结构化记忆组织和高效检索方面仍存在问题。", "innovation": "本文提出了层次记忆（H-MEM）架构，通过多层次的方式组织和更新记忆，基于语义抽象的程度。每个记忆向量嵌入了指向下一层相关子记忆的位置索引编码。在推理阶段，基于索引的路由机制能够高效地按层次检索，避免进行耗时的相似性计算。", "conclusion": "在LoCoMo数据集的五个任务设置上评估了本文的方法，实验结果表明，该方法在长对话场景中始终优于五种基线方法，证明了其有效性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22921", "html_url": "https://arxiv.org/abs/2507.22921", "title": "使用级联语言模型链和候选答案实现快速准确的上下文知识提取", "title_en": "Fast and Accurate Contextual Knowledge Extraction Using Cascading Language Model Chains and Candidate Answers", "authors": "Lee Harris", "background": "语言模型可以捕捉给定文本中的复杂关系，但它们以成本高昂且可能产生虚幻信息（即幻觉）而著称。如果这些信息不准确，则投入的资源将被浪费。本研究针对这一问题提出了语言模型链（LMC）算法，通过该算法确保语言模型的响应在给定提示下的信息存在性，并利用更预测但速度较慢的语言模型进一步验证和处理不准确的响应，从而提高准确性并减少幻觉现象。", "innovation": "提出的LMC算法通过引入候选答案集合，确保模型的输出准确存在。该算法采用多步骤级联的方式使用不同语言模型逐步验证和处理，大大提高了预测速度和准确性，减少了虚幻信息。这种级联复杂度和候选答案集合的结合是现有方法中的创新之处。", "conclusion": "该研究通过使用LMC算法成功从医学文档中提取患者的出生日期，证明该算法在知识提取领域的有效性。结合多个语言模型的多级级联能够显著提高预测速度和准确性，减少虚幻信息，并对未来的研究有很大的促进作用。我们相信LMC算法将在知识提取领域做出重要贡献，并应进一步研究探索。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22922", "html_url": "https://arxiv.org/abs/2507.22922", "title": "使用ChatGPT注解的Reddit情感预测股票价格", "title_en": "Predicting stock prices with ChatGPT-annotated Reddit sentiment", "authors": "Mateusz Kmak,Kamil Chmurzyński,Kamil Matejuk,Paweł Kotzbach,Jan Kocoń", "background": "2021年的GameStop短卖挤压事件突显了社交媒体上零售投资者活动对股价的影响。本文探讨了社交媒体讨论中提取的情感是否能够预测股市动态。研究聚焦于Reddit的r/wallstreetbets版块，并关注GameStop (GME) 和AMC Entertainment (AMC)两家公司。通过使用两种现有的基于文本的情感分析方法和一个基于ChatGPT注解并微调的RoBERTa模型来评估不同情感分析方法的影响，结果发现社交媒体情感与股价之间的相关性较弱。反之，简单指标如评论数量和谷歌搜索趋势更能预测股价变化，凸显了零售投资者行为的复杂性。", "innovation": "引入了基于ChatGPT注解并微调的RoBERTa模型，该模型更好地解释了社交媒体讨论中常见的非正式语言和表情符号，提升了情感分析的准确性。此外，通过应用相关性和因果关系度量标准，评估了不同情感分析模型的预测能力，发现在预测股票价格方面，传统的基于文本的情感分析方法并力敌更简单的评论数量和搜索趋势等指标。", "conclusion": "社交媒体情感虽弱相关于股价，但更简单的指标如评论数量和搜索趋势更强预测股价变动。研究强调了零售投资者行为的复杂性，并提示传统情感分析可能未能充分捕捉到推动市场变化的在线讨论的微妙之处。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22924", "html_url": "https://arxiv.org/abs/2507.22924", "title": "使用情感分析探究母语和非母语英语使用者的互评", "title_en": "Using Sentiment Analysis to Investigate Peer Feedback by Native and Non-Native English Speakers", "authors": "Brittney Exline,Melanie Duffin,Brittany Harbison,Chrissa da Gomez,David Joyner", "background": "美国研究生计算机科学项目的国际学生比例逐年增加，2023年获得硕士学位的60.2%是来自美国以外的学生。许多学生通过在线课程学习，这些课程通常使用同行反馈来提升学生的参与度和教学效果。考虑到课程用英语进行，许多学生学的是母语之外的语言。这篇文章研究不同母语状态的英语使用者在在线美国计算机课程中的同行反馈体验如何影响三个指标。", "innovation": "作者利用Twitter-roBERTa模型分析了500名学生写的同行评价的情感分数，并与学生的语言背景进行关联，这是首次使用这种方法来研究母语和非母语英语使用者之间的反馈差异。这种方法不仅适用于同行反馈体验的理解，还能帮助教育机构更好地支持国际学生的学习和文化交流。", "conclusion": "研究发现，母语使用者对反馈的评价较低，而非母语使用者的反馈更正面，但得到的回应却较少正面。在控制性别和年龄后，语言背景在同伴反馈经验塑造中的作用是适度且复杂的。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22933", "html_url": "https://arxiv.org/abs/2507.22933", "title": "增强视觉-语言模型：系统综述", "title_en": "Augmented Vision-Language Models: A Systematic Review", "authors": "Anthony C Davis,Burhan Sadiq,Tianmin Shu,Chien-Ming Huang", "background": "近期的视觉-语言机器学习模型展示了使用自然语言理解和掌握视觉场景的强大能力，这是通过在大规模未结构化数据集上进行训练实现的。然而，这种训练模式无法为输出提供可解释的解释，需要重新训练以整合新信息，资源消耗大，并且在进行某些形式的逻辑推理时 struggles。", "innovation": "研究提出了一种有希望的解决方案，即将神经网络与外部符号信息系统集成，形成增强的神经符号系统，这些系统可以增强推理和记忆能力。这使得系统能够提供输出的更可解释性解释，并且在无需大量重新训练的情况下吸收新信息。本文综述了通过与外部符号信息系统的交互来提高视觉-语言理解的技巧。", "conclusion": "本文通过系统文献综述和分类技术，探讨了如何利用强大的预训练 Vision-Language 模型（VLMs）作为核心神经组件，并通过外部系统进行增强，以实现神经-符号集成的好处。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22929", "html_url": "https://arxiv.org/abs/2507.22929", "title": "EH-Benchmark 赛姆赫姆斯特恩：眼科幻觉基准和自上而下的代理驱动可追溯推理工作流", "title_en": "EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow", "authors": "Xiaoyu Pan,Yang Bai,Ke Zou,Yang Zhou,Jun Zhou,Huazhu Fu,Yih-Chung Tham,Yong Liu", "background": "医疗大规模语言模型（MLLMs）在眼科诊断中发挥着重要作用，具有应对致盲疾病的潜力。然而，其准确性受限于来自眼科知识有限、视觉定位和推理能力不足以及眼科多模态数据稀缺所导致的幻觉，这些都阻碍了精确的病变检测和疾病诊断。此外，现有的医学基准无法有效评估不同类型的幻觉或提供解决这些问题的可行方案。", "innovation": "本研究引入了EH-Benchmark，一种新型的眼科基准，用于评估MLLMs中的幻觉。分类了针对特定任务和错误类型的MLLMs幻觉为视觉理解和逻辑组成功能的两类，并提出了以代理为中心、分三个阶段的框架：知识层面检索阶段、任务层面案例研究阶段和结果层面验证阶段。实验结果表明，多代理框架显著缓解了两种类型的幻觉，提高了准确性和可解释性以及可靠性。", "conclusion": "我们的多代理框架显著缓解了两种类型的幻觉，提高了准确性和可解释性以及可靠性。结果已经在该项目网站发布：this https URL."}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22920", "html_url": "https://arxiv.org/abs/2507.22920", "title": "多模态大语言模型的离散分词：一个全面的综述", "title_en": "Discrete Tokenization for Multimodal LLMs: A Comprehensive Survey", "authors": "Jindong Li,Yali Fu,Jiahong Liu,Linxiao Cao,Wei Ji,Menglin Yang,Irwin King,Ming-Hsuan Yang", "background": "随着大型语言模型（LLMs）的快速进步，有效机制的需求增加，用于将连续的多模态数据转换为适用于基于语言处理的离散表示。离散分词，尤其是矢量量化技术，提供了计算效率并兼容LLM体系结构。尽管它的重要性日益增加，但仍缺乏对矢量量化技术在基于LLM系统的综合系统中的系统研究。这项工作填补了这一空白，通过呈现第一个结构化的离散分词方法分类和分析，旨在为LLM设计。我们分类了8种代表性矢量量化变体，涵盖了古典和现代范式，并分析了它们的算法原理，训练动态及其与LLM流水线的整合挑战。我们不仅在算法级别上调查了现有研究，还讨论了传统多模态应用、基于LLM的单模态系统、基于LLM的多模态系统中的分词策略如何影响对齐、推理和生成性能。此外，我们识别了关键挑战，包括码本塌缩、不稳定的梯度估计和模态特定的编码约束。最后，讨论了新兴研究方向，例如动态和任务自适应量化、统一标记化框架以及生物启发的码本学习。这项综述在传统矢量量化和现代LLM应用之间架起了桥梁，为高效和可泛化的多模态系统的发展提供了基础参考。一个不断更新的版本可在以下链接找到：this https URL.", "innovation": "这项工作首次提供了一个结构化的离散分词方法分类和分析，聚焦于为LLM设计的离散分词技术。它详细比较了8种不同的矢量量化变体，涵盖了从古典到现代的范式。此外，该研究还讨论了如何基于矢量量化策略进行模态间对齐、推理和生成，以及新兴的研究方向，如动态和任务自适应量化、统一标记化框架和基于生物学的码本学习。这项工作为LLM技术中的多模态系统的开发提供了新的视角和解决方案。", "conclusion": "这项综述填补了离散分词技术在基于LLM系统的综合研究中的空白，提供了全面的分类和分析。该研究不仅提高了对矢量量化技术的理解，还为未来的研究和应用提出了新的挑战和方向。通过不断更新的链接提供了一个持续学习和研究的平台，为开发高效和通用的多模态系统奠定了基础。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22923", "html_url": "https://arxiv.org/abs/2507.22923", "title": "跨语言大语言模型提示策略中的翻译在哪里进行？策略的影响", "title_en": "How and Where to Translate? The Impact of Translation Strategies in Cross-lingual LLM Prompting", "authors": "Aman Gupta,Yingying Zhuang,Zhou Yu,Ziji Zhang,Anurag Beniwal", "background": "尽管大型语言模型（LLMs）在多语言能力方面取得了进展，但它们在不同语言和任务中的表现差异仍然很大。在基于检索增强生成（RAG）的多语言系统中，通常将知识库（KB）从高资源语言（如英语）共享到低资源语言，导致从KB检索到的信息与上下文中的其他部分语言不同。在此类情况下，通常有两种做法：预翻译以生成单语言提示和跨语言提示以直接进行推理。然而，这些做法的影响尚不清楚。", "innovation": "本文系统性地评估了在使用RAG增强的多语言LLM进行分类任务时，不同提示翻译策略的影响。研究发现，优化的提示策略可以显著提高语言间知识共享，从而改善下游分类任务的性能。这项研究强调了在非英语语言中，尤其是低资源语言中，更广泛利用多语言资源共享和跨语言提示优化的重要性。", "conclusion": "优化的提示策略可以显著改善多语言系统中下游分类任务的性能。因此，鼓励更广泛的跨语言资源共享和针对非英语语言的跨语言提示优化使用。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22928", "html_url": "https://arxiv.org/abs/2507.22928", "title": "Chain of Thought 思维过程是如何进行的？稀疏自编码下的链式推理机制可解释性", "title_en": "How does Chain of Thought Think? Mechanistic Interpretability of Chain-of-Thought Reasoning with Sparse Autoencoding", "authors": "Xi Chen,Aske Plaat,Niki van Stein", "background": "链式思考（CoT）提示在提高大型语言模型在多步任务上的准确性方面表现出色，但生成的“思考过程”是否真正反映了内部推理过程仍是未知数。本文通过组合稀疏自编码器与激活切片技术，在处理GSM8K数学问题时，从Pythia-70M和Pythia-2.8B模型中提取单一语义特征，探讨了CoT的忠实度。研究表明，较大的模型能更好地体现CoT的忠实度，揭示出一个清晰的规模阈值。较大的模型在激活稀疏度和特征可解释性得分方面均表现为显著增加，表明内部计算机制更加模块化。这些发现证实了CoT作为一种结构化提示方法的作用，并进一步揭示了CoT在高性能大型语言模型中诱导更可解释的内部结构的可能性。", "innovation": "本文创新性地结合了稀疏自编码器与激活切片技术，通过提取单一语义特征对CoT进行首次特征层面的因果研究。开发了新的颖准曲线（patch-curves）和随机特征切片基线，证明有用的信息不仅存在于前K个切片中，而是广泛分布的。这一研究揭示了CoT在高容量大型语言模型中的潜在价值，表明可能通过CoT更好地理解模型的内部推理过程。", "conclusion": "实验结果显示，CoT能够在大型语言模型中诱导出更可解释的内部结构，支持了CoT作为一种有结构的提示方法的作用。这一发现为进一步研究CoT的影响及其在提高语言模型性能方面的潜力提供了重要见解。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22930", "html_url": "https://arxiv.org/abs/2507.22930", "title": "保护易受伤害群体的声音：用于自披露检测的合成数据集生成", "title_en": "Protecting Vulnerable Voices: Synthetic Dataset Generation for Self-Disclosure Detection", "authors": "Shalini Jangra,Suparna De,Nishanth Sastry,Saeed Fadaei", "background": "社交媒体平台如Reddit拥有基于共同兴趣的社区网络，其中充斥着用户个人信息标识符（PII）的披露信息。这种自我披露虽然可以促进有益的社会互动，但也带来了隐私风险和在线危害的风险。由于缺乏开放的带标注数据集，对PII披露文本的识别和检索研究受到阻碍。这项研究旨在通过开发一种安全共享的合成数据生成方法，促进关于PII揭示文本检测的可重复科学研究。本研究确定了19类与易受伤害群体相关的PII揭示类别，并基于3个大型语言模型（LLMs）——Llama2-7B、Llama3-8B和zephyr-7b-beta——生成了一组合成PII注释多文本跨度数据集，并通过顺序指令提示使其与原始Reddit帖子类似。这项研究评估了生成合成数据集的方法的可用性，包括确保结果可重复、合成数据不可链接到原始用户以及合成数据与原始数据不可区分三项标准。这些合成数据集和相关代码已在该网址发布，以促进在在线社交媒体中的PII隐私风险研究的可重复性。", "innovation": "本研究开发了一种新颖的合成PII揭示数据生成方法，旨在促进关于PII揭示文本检测的可重复科学研究。该研究包括创建了19类与易受伤害群体相关的PII揭示类别，并基于3个大规模语言模型（LLMs）生成了一组合成PII注释多文本跨度数据集和相关代码，专门为在线社交媒体上的PII隐私风险研究提供一个安全共享的数据集。该方法通过结果可重复性、不可链接性和不区分性三项标准得到验证。", "conclusion": "通过合成生成PII揭示数据集，本研究不仅提供了对PII隐私风险研究的重要基石，还提高了研究的可重复性，促进了在在线社交网络中PII隐私挑战的更深入理解。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22931", "html_url": "https://arxiv.org/abs/2507.22931", "title": "增强RAG效率的自适应上下文压缩", "title_en": "Enhancing RAG Efficiency with Adaptive Context Compression", "authors": "Shuyu Guo,Zhaochun Ren", "background": "检索增强生成（RAG）能够通过外部知识增强大规模语言模型（LLMs），但导致显著的推理成本，因为检索到的上下文较长。现有的上下文压缩方法应用固定的压缩率，对于简单查询过度压缩或对于复杂查询压缩不足。由于此问题，固定压缩率方法不能同时优化推理效率和保持准确性，尤其是在复杂的查询场景下表现不佳，同时会牺牲一些精度。因此，研究者们提出了一种新的自适应上下文压缩框架（ACC-RAG），该框架可以动态调整压缩率，根据输入复杂度进行优化，从而提高推理效率而不牺牲准确性。", "innovation": "提出的ACC-RAG框架通过结合分层压缩器和上下文选择器，自适应地调整压缩率。分层压缩器用于处理多粒度嵌入，而上下文选择器则保留最少的必要信息，从而使得目标接近于人类阅读和略读的效率和精度。该方法使得ACC-RAG在保持或提高准确性的同时，实现了比标准RAG快4倍以上的推理速度，优于固定压缩率的方法。", "conclusion": "在Wikipedia和五个QA数据集上的测试表明，ACC-RAG在保持或提高准确性的同时，实现了显著的推理效率改进。这种自适应上下文压缩方法不仅提高了RAG的效率，而且为进一步应用提供了技术基础。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22932", "html_url": "https://arxiv.org/abs/2507.22932", "title": "FinMarBa：金融 sentiments 分类的市场信息数据集", "title_en": "FinMarBa: A Market-Informed Dataset for Financial Sentiment Classification", "authors": "Baptiste Lefort,Eric Benhamou,Beatrice Guez,Jean-Jacques Ohana,Ethan Setrouk,Alban Etienne", "background": "该论文介绍了一个新的层级框架用于投资组合优化，结合了轻量级的大型语言模型（LLMs）和深度强化学习（DRL），将金融新闻的情感信号与传统的市场指标结合起来。三层架构包括基础的RL代理处理混合数据、元代理汇总决策以及超级代理根据市场数据和情感分析合并决策。该框架在2018年至2024年的数据上进行评估，经过2000年至2017年的训练，实现了26%的年化回报和1.2的夏普比率，优于等权重基准和S&P 500基准。", "innovation": "其创新点在于可扩展的跨模态集成、增强稳定性的多层次RL结构以及开源可复现性。", "conclusion": "该框架通过市场数据和情感分析实现了比传统基准更好的投资组合优化结果。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22934", "html_url": "https://arxiv.org/abs/2507.22934", "title": "深度学习方法在多模态意图识别中的应用：综述", "title_en": "Deep Learning Approaches for Multimodal Intent Recognition: A Survey", "authors": "Jingwei Zhao,Yuhua Wen,Qifei Li,Minchi Hu,Yingying Zhou,Jingyao Xue,Junyang Wu,Yingming Gao,Zhengqi Wen,Jianhua Tao,Ya Li", "background": "意图识别旨在识别用户的潜在意图，传统上集中在自然语言处理中的文本。随着自然人机交互需求的增长，该领域通过深度学习和多模态方法得到了发展，结合了来自音频、视觉和生理信号的数据。最近，基于Transformer的模型在该领域取得了显著突破。", "innovation": "介绍了多模态意图识别（MIR），覆盖了从单模态到多模态技术的转变、相关数据集、方法论、应用以及当前挑战。为研究人员提供了最新的MIR发展趋势和未来研究方向的见解。", "conclusion": "综述了深度学习方法在多模态意图识别中的应用，为研究人员提供了最新进展和未来研究方向的启示。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22926", "html_url": "https://arxiv.org/abs/2507.22926", "title": "使用全局上下文在实体对中的多关系提取", "title_en": "Multi-Relation Extraction in Entity Pairs using Global Context", "authors": "Nilesh,Atul Gupta,Avinash C Panday", "background": "在文档级别的关系提取中，实体可能在文档中多次出现，且它们之间的关系可能随着上下文的变化而变化。准确预测文档中两个实体的关系需要构建跨越所有相关句子的全局上下文。以往的方法仅关注提到实体的句子，未能捕捉到准确的关系提取所需的整体文档上下文。", "innovation": "提出了一个新的输入嵌入方法，以捕捉文档中提到实体的位置而非仅仅关注它们出现的范围。该输入编码方法通过将实体表示为独立段落，利用全局关系和多句推理，从而提升关系的预测准确性。", "conclusion": "该方法在三个基准关系提取数据集（DocRED、Re-DocRED、REBEL）上进行了测试，实验结果表明能够准确地在文档级预测实体之间的关系。该研究具有理论和实际意义，理论上推动了全局上下文建模和多句推理在文档级关系提取中的发展；实际中提高了关系检测性能，有助于需要全面实体级见解和可解释性的实际NLP应用。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22927", "html_url": "https://arxiv.org/abs/2507.22927", "title": "PRGB基准：一种鲁棒的占位符辅助算法用于检索增强生成评估", "title_en": "PRGB Benchmark: A Robust Placeholder-Assisted Algorithm for Benchmarking Retrieval-Augmented Generation", "authors": "Zhehao Tan,Yihan Jiao,Dan Yang,Lei Liu,Jie Feng,Duolin Sun,Yue Shen,Jian Wang,Peng Wei,Jinjie Gu", "background": "检索增强生成(RAG)通过集成外部知识来增强大型语言模型(LLM)，关键在于LLM基于给定查询和检索到的文档生成响应的能力。然而，大多数基准测试主要关注整个RAG系统的表现，很少评估LLM的具体能力。当前的基准测试侧重于广泛的方面，如噪声鲁棒性，但缺乏一个系统性和细粒度的文档利用评估框架。", "innovation": "提出了 Placeholder-RAG-Benchmark，这是一种多级细粒度基准测试，专注于多级过滤能力、组合能力和参考推理等进步维度。此外，通过占位符基础创新的方法，将LLM的参数知识贡献与外部知识贡献解耦，提供了对LLM在RAG系统中角色的更深入理解。", "conclusion": "实验表明，代表性LLM在RAG系统的生成能力中存在限制，特别是在错误恢复能力和上下文忠诚度方面。我们的基准测试为开发更可靠和高效的RAG系统提供了可重复的框架。我们的代码可以在以下链接中找到。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22935", "html_url": "https://arxiv.org/abs/2507.22935", "title": "可信的知识抽取用于运行和维护智能", "title_en": "Trusted Knowledge Extraction for Operations and Maintenance Intelligence", "authors": "Kathleen Mealey,Jonathan A. Karr Jr.,Priscila Saboia Moreira,Paul R. Brenner,Charles F. Vardeman II", "background": "从组织数据仓库中获取操作智能是一个关键挑战，这主要是由于数据保密性与数据集成目标之间的二元对立，以及自然语言处理（NLP）工具在特定知识领域（如运营和维护）方面的局限性。本文讨论了知识图谱的构建，并将知识提取过程分解为命名实体识别、共指消解、命名实体链接和关系提取等功能组件。在评估了十六种NLP工具及其在大型语言模型（LLMs）快速进步中的性能后，专注于航空业的可信应用中的运营与维护智能用例。基线数据集来源于美国联邦航空管理局关于设备故障或维护需求的丰富公开数据集。我们评估了可以在受控且保密环境中运行（不向第三方传输数据）的零样本性能的NLP和LLM工具。基于我们观察到的重要性能限制，我们讨论了信任NLP和LLM工具面临的挑战及其技术成熟度水平，特别是在航空等关键行业中的广泛应用前景。", "innovation": "本文将知识提取过程分解为四个关键功能组件：命名实体识别、共指消解、命名实体链接和关系提取，评估了十六种NLP工具，并首次提出了可信NLP和大型语言模型工具的零样本性能评估方法，特别关注运行和维护智能的航空应用。", "conclusion": "由于NLP和LLM工具存在的显著性能限制，本文指出了信任NLP和LLM工具所面临的挑战和其技术成熟度水平，提出建议以增强信任，并公开提供了数据集以支持进一步的基准测试和评估。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22937", "html_url": "https://arxiv.org/abs/2507.22937", "title": "CoE-Ops: 基于LLM专家的协作在AIOps问答中的应用", "title_en": "CoE-Ops: Collaboration of LLM-based Experts for AIOps Question-Answering", "authors": "Jinkun Zhao,Yuanshuai Wang,Xingjian Zhang,Ruibo Chen,Xingchuang Liao,Junle Wang,Lei Huang,Kui Zhang,Wenjun Wu", "background": "随着人工智能的迅速发展，AIOps已成为DevOps中的一个重要范式。许多工作被提出以提高不同AIOps阶段的表现。然而，由于特定领域的知识限制，单一模型只能处理特定任务的运维需求，如日志解析和根因分析。同时，将多个模型结合起来可以获得更高效的结果，并且这一观点在早期的集成学习和最近的大语言模型训练中得到了验证。本研究受到这些工作的启发，为了解决类似AIOps中的挑战，首次提出了一种专家协作框架(CoE-Ops)并引入了一种检索增强生成机制，以增强框架处理高阶和低阶任务的能力。这一方法在AIOps领域中实现了广泛的实验研究，特别是在DevOps-EVAL数据集上。实验结果表明，CoE-Ops在高阶AIOps任务中的路由精度相比现有CoE方法提高了72%，在DevOps问题解决中，单一AIOps模型的准确性提高了8%，在准确性上比大规模的混合专家（MoE）模型高出14%。", "innovation": "本研究提出了专家协作框架(CoE-Ops)，将通用大型语言模型任务分类器纳入其中。引入了检索增强生成机制以增强框架处理高阶和低阶任务的能力。该方法在AIOps领域进行了广泛实验，特别是在DevOps-EVAL数据集上进行了实验，展示了在高阶和低阶任务上的显著性能提升。与现有的CoE方法相比，CoE-Ops在高阶AIOps任务中的路由准确性提高了72%，在单一AIOps模型的基础上提高了8%的准确性，并且比大规模的混合专家模型在准确性上高出14%。", "conclusion": "CoE-Ops框架在AIOps领域表现出显著的性能优势，尤其是在高阶任务的处理能力上，与其他方法相比具有明显的优势。该研究为未来AIOps和DevOps相关工作的改进提供了有益的参考。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22941", "html_url": "https://arxiv.org/abs/2507.22941", "title": "SigBERT: 结合叙述性医疗报告和粗糙路径签名理论在肿瘤学中的生存风险估计", "title_en": "SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology", "authors": "Paul Minchella,Loïc Verlingue,Stéphane Chrétien,Rémi Vaucher,Guillaume Metzler", "background": "电子医疗报告（EHR）包含了大量可用于医疗健康领域机器学习应用的信息。然而，现有的生存分析方法常常难以有效处理文本数据的复杂性，尤其是其序列形式。现有的生存分析方法在处理这些复杂的数据时通常存在困难，SigBERT框架旨在通过处理带有时间戳的临床报告来克服这个问题。该框架通过提取和平均词嵌入来生成句子嵌入，并利用粗糙路径理论中的签名提取方法从时间序列的句子嵌入坐标中捕获时空动态，从而显著提升生存模型的表现力，使其能够估计复杂的时间动态。", "innovation": "SigBERT是一个创新的时间序列生存分析框架，能够高效处理每位患者大量的临床报告。通过嵌入提取与平均的手段，SigBERT首先将文本数据转化为时间序列信号，然后使用粗糙路径理论中的签名提取方法捕获患者的时空动态特征。这些特征被进一步整合到LASSO正则化的Cox模型中，以估计患者特定的风险得分。这种方法在实际的肿瘤学数据集上表现出色，C-指数得分为0.75（标准差0.014），在独立测试组中取得了显著的效果。", "conclusion": "SigBERT通过整合序列医疗数据提高了风险估计，推动了基于叙述的生存分析的发展。它成功地将粗糙路径签名理论应用于生存风险估计中，展示了在临床报告中的广泛应用潜力。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22939", "html_url": "https://arxiv.org/abs/2507.22939", "title": "PARROT：一个开放的多语言放射报告数据集", "title_en": "PARROT: An Open Multilingual Radiology Reports Dataset", "authors": "Bastien Le Guellec,Kokou Adambounou,Lisa C Adams,Thibault Agripnidis,Sung Soo Ahn,Radhia Ait Chalal,Tugba Akinci D Antonoli,Philippe Amouyel,Henrik Andersson,Raphael Bentegeac,Claudio Benzoni,Antonino Andrea Blandino,Felix Busch,Elif Can,Riccardo Cau,Armando Ugo Cavallo,Christelle Chavihot,Erwin Chiquete,Renato Cuocolo,Eugen Divjak,Gordana Ivanac,Barbara Dziadkowiec Macek,Armel Elogne,Salvatore Claudio Fanni,Carlos Ferrarotti,Claudia Fossataro,Federica Fossataro,Katarzyna Fulek,Michal Fulek,Pawel Gac,Martyna Gachowska,Ignacio Garcia Juarez,Marco Gatti,Natalia Gorelik,Alexia Maria Goulianou,Aghiles Hamroun,Nicolas Herinirina,Krzysztof Kraik,Dominik Krupka,Quentin Holay,Felipe Kitamura,Michail E Klontzas,Anna Kompanowska,Rafal Kompanowski,Alexandre Lefevre,Tristan Lemke,Maximilian Lindholz,Lukas Muller,Piotr Macek,Marcus Makowski,Luigi Mannacio,Aymen Meddeb,Antonio Natale,Beatrice Nguema Edzang,Adriana Ojeda,Yae Won Park,Federica Piccione,Andrea Ponsiglione,Malgorzata Poreba,Rafal Poreba,Philipp Prucker,Jean Pierre Pruvo,Rosa Alba Pugliesi,Feno Hasina Rabemanorintsoa,Vasileios Rafailidis,Katarzyna Resler,Jan Rotkegel,Luca Saba,Ezann Siebert,Arnaldo Stanzione,Ali Fuat Tekin,Liz Toapanta Yanchapaxi,Matthaios Triantafyllou,Ekaterini Tsaoulia,Evangelia Vassalou,Federica Vernuccio,Johan Wasselius,Weilang Wang,Szymon Urban,Adrian Wlodarczak,Szymon Wlodarczak,Andrzej Wysocki,Lina Xu,Tomasz Zatonski,Shuhang Zhang,Sebastian Ziegelmayer,Gregory Kuchcinski,Keno K Bressem", "background": "随着自然语言处理（NLP）在放射学中的应用日益广泛，开发和验证适用于多种语言的数据集变得尤为重要。然而，现有数据集往往存在语言单一、地域限制或隐私问题，这限制了NLP技术在跨语言、跨地域和跨临床场景的应用。为了克服这些挑战，研究团队决定创建一个包含多个语言、多个地理区域和多个临床场景的真实放射学报告的开放数据集，以促进自然语言处理在放射学领域的应用和发展。", "innovation": "PARROT是一个大型、多中心、开放访问的数据集，包含2,658份来自76位作者（分布在21个国家和地区、13种语言）的虚构放射学报告。该数据集的独特之处在于其多语言特性、广泛的地理覆盖范围和多样的临床场景。研究团队邀请放射科医生使用他们的标准报告方法提供报告，并包括影像学模态、解剖区域和临床背景，以及非英语报告的英文翻译。所有报告都分配了ICD-10编码。参与者通过一项人类报告和AI生成报告的区分研究展示了数据集的潜力，结果显示53.9%的准确率，且放射科医生的表现优于其他组别。", "conclusion": "PARROT是迄今为止最大的开放多语言放射学报告数据集，它为自然语言处理技术在放射学领域的跨语言、跨地域和跨临床场景下的发展和验证提供了新的平台，确保了数据集在跨语言、跨地域和跨医疗界的使用上不受隐私限制的约束。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22968", "html_url": "https://arxiv.org/abs/2507.22968", "title": "C3: 一项探索复杂对话难题的双语标准基准", "title_en": "C3: A Bilingual Benchmark for Spoken Dialogue Models Exploring Challenges in Complex Conversations", "authors": "Chengqian Ma,Wei Tao,Yiwen Guo", "background": "口语对话模型（SDMs）因其直接生成语音响应的能力而受到广泛关注，特别是在处理用户口语查询方面。尽管SDMs越来越受欢迎，但在全面了解其在理解和模仿人类对话方面的实际效果方面仍存在不足。特别是在与大量基准测试受益的语言模型（LLMs）相比时，这一问题更为明显。人类的语音互动比文本更为复杂，因为它们具有独特的语音对话特性，如歧义问题（包括多义词的语义因素、发音差异、同音词、重音模式）和上下文依赖性（如省略、交叉引用和多轮互动）。", "innovation": "本文提出了一项标准基准 C3，它包含了1079个英文和中文的实例。该基准结合了基于语言模型的评价方法，这种方法与人类判断高度吻合，从而为全面探索SDMs在处理实际挑战时的表现提供了工具。", "conclusion": "本文的研究结果展示了目前SDM的发展状况，阐明了亟需解决的复杂对话中的关键问题，并通过提供一个与人类判断高度一致的双语基准数据集，促进了对SDMs性能的研究。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22943", "html_url": "https://arxiv.org/abs/2507.22943", "title": "由自然语言处理和多波自适应抽样辅助的病历审查过程以加速大型数据库研究中代码算法的验证", "title_en": "A chart review process aided by natural language processing and multi-wave adaptive sampling to expedite validation of code-based algorithms for large database studies", "authors": "Shirley V Wang,Georg Hahn,Sushama Kattinakere Sreedhara,Mufaddal Mahesri,Haritha S. Pillai,Rajendra Aldis,Joyce Lii,Sarah K. Dutcher,Rhoda Eniafe,Jamal T. Jones,Keewan Kim,Jiwei He,Hana Lee,Sengwee Toh,Rishi J Desai,Jie Yang", "background": "通过使用自然语言处理（NLP）和其他方法来验证代码算法，可以提高使用大型保险公司数据进行分析的有效性。这些算法用于识别健康结果或其他关键研究参数。尽管这种方法可以提高研究结果的可靠性，但手动审核病历需要大量时间和资源，特别是当需要验证大量记录时。因此，需要一种更高效的方法来减少手动审核的工作量，同时确保研究结果的可靠性和准确性。", "innovation": "我们提出了一种新的验证方法，该方法结合了自然语言处理和多波自适应抽样技术。自然语言处理可以减少人类审查员花在审查每份病历上的时间；多波自适应抽样方法则可以根据预设的停止标准，在达到足够的精确度前预先确定是否应该停止验证研究。这种方法在验证肥胖患者中故意自伤的索赔基础上算法性能时得到证实。结果显示，与传统的手动审查相比，NLP辅助注释过程可以将审查时间减少40%，而预设的停止规则结合多波抽样方法则能将需要审查的病人数的比例减少77%，同时不会大幅影响测量特性的精确度。这种方法可以促进代码算法的更常规验证，从而增强数据库研究结果的可靠性理解.", "conclusion": "此方法为大型数据库研究中代码算法定义关键研究参数的验证过程提供了一种更高效、更可靠的方法，有助于更准确地了解数据库研究结果的可靠性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22936", "html_url": "https://arxiv.org/abs/2507.22936", "title": "评估大型语言模型（LLMs）在金融自然语言处理中的表现：对财务报告分析的比较研究", "title_en": "Evaluating Large Language Models (LLMs) in Financial NLP: A Comparative Study on Financial Report Analysis", "authors": "Md Talha Mohsin", "background": "大型语言模型（LLMs）在多种金融自然语言处理（FinNLP）任务中展现了卓越的能力。然而，对广泛使用的LLMs之间系统的比较研究仍然不足。鉴于LLMs在金融分析中的快速进步和日益重要的影响，本研究通过评估来自'七个巨人'科技公司的10-K申报文件，对五种主要的LLMs（GPT、Claude、Perplexity、Gemini和DeepSeek）进行了深入的比较研究，以弥补这一不足。研究主要使用了定制的领域特定提示，并通过三种方法评估了模型性能：人工注释、自动词汇-语义指标（ROUGE、余弦相似度、Jaccard）和模型行为诊断（提示级别变动性和模型间相似性）。研究表明，GPT给出的答案最为连贯、语义对齐且上下文相关；Claude和Perplexity的表现次之；而Gemini和DeepSeek则具有更高的变异性，且结果的一致性较差。进一步的分析表明，LLM输出的相似性和稳定性因公司和时间的不同而变化，这表明它们对提示的书写方式和源材料的使用具有敏感性。", "innovation": "本文创新地使用了来自七个科技公司的10-K申报文件对五种主要的LLMs进行了广泛的比较研究。采用了定制的领域特定提示和三种评估方法（人工注释、自动词汇-语义指标以及模型行为诊断），为LLMs在金融自然语言处理领域的比较研究提供了一个全面的标准。这项工作的创新之处在于深入研究了不同LLMs的表现及其受提示和数据源的影响。", "conclusion": "研究表明，GPT在连贯性、语义对齐和上下文相关性方面表现最好，其次是Claude和Perplexity。Gemini和DeepSeek则显示出更高的变异性，结果的一致性较差。此外，LLM输出的相似性和稳定性因公司和时间的不同而变化，反映了提示书写方式和源材料使用的影响。这项研究不仅提供了对五种主要LLMs在金融报告分析中表现的全面评估，还强调了提示和源材料对于LLM性能的重要性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22944", "html_url": "https://arxiv.org/abs/2507.22944", "title": "权威与不透明性：任意性与挑战的排除", "title_en": "Opacity as Authority: Arbitrariness and the Preclusion of Contestation", "authors": "Naomi Omeonga wa Kayembe", "background": "文章重新定义了任意性，不是将其视为规范缺陷或压迫的迹象，而是视为人类系统和互动的基础功能性机制。它偏离了将任意性与不公等同的批判传统，提出任意性是一种符号特性：一种使系统（语言、法律或社会）能够有效运作并保留其内部理性的方式。文章扩展了费迪南德·德·索绪尔符号的任意性概念，将其应用于法律和社会动态领域，强调其跨领域的适用性。", "innovation": "文章提出了“动机 -> 可验证性 -> 可争议性”的链条，认为动机作为关键接口使行为的逻辑能够受到主体间争议。文章引入了任意性的公式化表达A = H(L|M)，并将其视作控制与关爱的核心中立操作者。提出了一个新的框架来分析高级人工智能系统的解释性，虽然这一框架主要在人类社会系统中发展而来，但在解释性方面为人工智能系统提供了新的分析路径。", "conclusion": "文章强调了结构上的不透明性虽看似不合理，但其实是一种故意设计，旨在保护权力不被问责。同时，文章提出了一种现代任意性理论，认为其在控制与关爱中均起着关键作用，这是人际交往中一个被忽略的重要维度。这种理论不仅适用于人类社会系统，也可以用于分析高级人工智能系统中的解释性问题。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22940", "html_url": "https://arxiv.org/abs/2507.22940", "title": "可信推理：评估与提升大语言模型中间推理过程的事实准确性", "title_en": "Trustworthy Reasoning: Evaluating and Enhancing Factual Accuracy in LLM Intermediate Thought Processes", "authors": "Rui Jiao,Yue Zhang,Jinku Li", "background": "文章背景讲述了大型语言模型（LLMs）存在的重要漏洞，即中间推理步骤中普遍存在事实不准确的情况，尽管最终答案正确。这种现象在医疗、法律分析和科学研究等高风险领域可能导致错误的推理被用户接受，从而导致危险的决策。", "innovation": "文章介绍了一种名为RELIANCE的新框架，以提升LLMs在中间推理过程中的事实准确性。框架结合了三项核心技术：1）一个针对细粒度事实不一致性进行检测的专门事实核查分类器，该分类器基于反事实增强的数据进行训练；2）一种集成多维度奖励的组相对策略优化（GRPO）强化学习方法，以平衡事实性、连贯性和结构正确性；3）一种机制解释模块，用于分析事实准确性提高如何在推理过程中反映在模型激活上。", "conclusion": "通过对十多个最新模型的广泛评估，文章发现了令人担忧的模式，即使是顶级的模型如Claude-3.7和GPT-o1，中间推理过程的事实准确性也很低，分别只有81.93%和82.57%。RELIANCE框架显著提高了事实的稳健性（最高可提高49.90%），同时在诸如Math-500、AIME-2024和GPQA等具有挑战性的基准测试中保持或提高了性能。此外，激活级别分析提供了关于如何通过激活引导优化来实现事实提升的具体见解，为未来的训练方法奠定了基础。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22938", "html_url": "https://arxiv.org/abs/2507.22938", "title": "基于图的电信文档中流程图模态问题回答方法", "title_en": "A Graph-based Approach for Multi-Modal Question Answering from Flowcharts in Telecom Documents", "authors": "Sumit Soman,H. G. Ranjani,Sujoy Roychowdhury,Venkata Dharma Surya Narayana Sastry,Akshat Jain,Pranav Gangrade,Ayaaz Khan", "background": "技术文档中的问题回答（QA）经常涉及答案位于图表中（如流程图）的问题，而基于文本的检索增强生成（RAG）系统可能难以回答这类问题。该研究利用视觉大型语言模型（VLMs）获取的流程图的图表示，并将其纳入基于文本的RAG系统，从而展示这种方法能够实现图像检索在电信领域中的问题回答。研究团队提出了从处理技术文档、分类图像类型、构建图表示到最后与文本嵌入流水线集成的端到端方法，用于高效的检索。该方法基于电信产品的专有信息文档创建了一个QA数据集进行测试，结果表明，使用调优后的VLM模型获得的图表示与真实答案的编辑距离较低，展示了这些表示在流程图图像上的鲁棒性。进一步地，使用这些表示的方法在使用基于文本的嵌入模型进行问题回答时表现出良好的检索性能，包括针对电信领域的适应性改进模型。此外，该方法还降低了推理阶段对VLM的需求，从部署问题回答系统的角度来看，这是一种重要的成本效益。", "innovation": "利用调优后的VLM获取流程图的图表示，并将其与基于文本的RAG系统结合，实现了跨模态的问题回答，特别是在电信领域的应用。该研究提出了一种端到端的方法，可有效处理技术文档，分类图像类型，构建图表示，并与文本嵌入流水线集成，提高了系统的鲁棒性和检索性能。同时，它减少了推理阶段对VLM的需求，降低了部署成本。", "conclusion": "实验结果表明，使用经过调优的VLM模型获取的图表示具有较低的编辑距离，证明了这些表示的鲁棒性。此外，该方法在基于文本的嵌入模型中能够实现良好的检索性能，特别是在电信领域。这种方法还降低了解决策题抽问题回答系统时对VLM的依赖，为部署此类系统提供了成本效益。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23083", "html_url": "https://arxiv.org/abs/2507.23083", "title": "情境感知旋转位置嵌入", "title_en": "Context-aware Rotary Position Embedding", "authors": "Ali Veisi,Delaram Fartoot,Hamidreza Amirzadeh", "background": "位置编码是Transformer架构中的关键组件，能够使模型通过自我注意力机制纳入序列顺序信息。虽然旋转位置嵌入(RoPE)由于与相对位置编码的兼容性和计算效率而被广泛采用，但RoPE依赖于固定的、输入无关的正弦频率模式，这限制了它对上下文敏感关系的建模能力。", "innovation": "本文提出了一种名为CARoPE（情境感知旋转位置嵌入）的新型技术，它是RoPE的动态通用化版本，能够根据标记嵌入动态生成特定头部的频率模式。CARoPE计算输入相关的相位移动，利用标记嵌入的有界变换，并将它们整合到注意力头部的旋转机制中。与RoPE相比，CARoPE在FineWeb-Edu-10B数据集上的GPT-2变种模型中展示了更快的训练效率，并且在长上下文长度下能实现更低的困惑度。", "conclusion": "实验结果表明，CARoPE在FineWeb-Edu-10B数据集上表现优越，即使在较长的上下文长度下，CARoPE仍然能够实现显著更低的困惑度。此外，CARoPE还提供了更快的训练吞吐量，而不会牺牲模型的稳定性。这些发现表明，CARoPE为Transformer模型中现有的位置编码策略提供了一个可扩展、表达性强且效率高的升级方案。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23063", "html_url": "https://arxiv.org/abs/2507.23063", "title": "数学自然语言推理：这应该很简单！", "title_en": "Math Natural Language Inference: this should be easy!", "authors": "Valeria de Paiva,Qiyue Gao,Hai Hu,Pavel Kovalev,Yikang Liu,Lawrence S. Moss,Zhiheng Qian", "background": "研究者们试图评估现代语言模型（LLMs）是否能够在包含数学文本的自然语言推理（NLI）任务中表现良好。通过构建一个包含数学文本前提和人工提供的假设及正确标签的数据集，以及使用LLM自身提供的假设的数据集，研究团队探究了LLMs在这类任务中的表现，并特别关注了不同模型之间的一致性和多样性。", "innovation": "论文创新性地构造了一个专门针对数学文本的自然语言推理数据集，涵盖了数学文本前提和人工提供的假设及正确标签，以及使用LLMs自身提供的假设的数据集。研究不仅考察了模型的表现，还分析了不同模型之间的小组一致性，并全面讨论了LLMs在处理数学语言时的能力和局限。", "conclusion": "研究结果显示出LLMs在某些情况下可以通过多数投票法在数学NLI任务中与人工标注数据接近，但在数学语言的理解和基本推理方面仍存在挑战。此外，当前模型对假设的依赖性降低了，而不是像之前的模型那样容易进行假设计算。研究团队还公开了他们的数据集，以支持未来在数学NLI领域的工作。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23082", "html_url": "https://arxiv.org/abs/2507.23082", "title": "探索基于上下文学习的框架语义解析", "title_en": "Exploring In-Context Learning for Frame-Semantic Parsing", "authors": "Diego Garat,Guillermo Moncecchi,Dina Wonsever", "background": "Frame Semantic Parsing (FSP)涉及根据框架语义识别谓词及其标注其论元。本研究探讨了利用大型语言模型（LLMs）在上下文学习(In-Context Learning, ICL)中执行FSP的方法，而无需对模型进行微调。该方法基于FrameNet数据库自动生成与FSP任务相关的专用提示，使用包含框架定义和标注示例的提示来指导六种不同的LLMs。研究在与暴力事件相关的框架子集上进行了实验。", "innovation": "本研究提出了一种利用ICL在LLMs上执行FSP的方法，通过利用FrameNet数据库自动生成任务特定的框架识别(FI)和框架语义角色标注(FSRL)子任务提示，无需对模型进行微调。这种方法能够用包含框架定义和标注示例的提示来指导六种不同的LLMs。", "conclusion": "实验结果表明，该方法在F1分数方面达到了相当不错的水平，FI的F1分数为94.3%，FSRL的F1分数为77.4%。研究发现，ICL为特定领域FSP任务提供了一种可行且有效的方法，替代了传统的模型微调方法。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23104", "html_url": "https://arxiv.org/abs/2507.23104", "title": "RASL: 使用检索增强模式链接处理大规模数据库文本到SQL", "title_en": "RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL", "authors": "Jeffrey Eben,Aitzaz Ahmad,Stephen Lau", "background": "尽管在基于大语言模型（LLM）的自然语言数据库接口方面取得了进展，但将其扩展到企业级数据目录仍是一个尚未充分探索的挑战。先前研究在解决此挑战时依赖于特定领域的微调，这增加了部署难度，并且未能充分利用数据库元数据中包含的重要语义上下文。", "innovation": "本文提出了一种基于组件的检索架构，将数据库模式和元数据分解为离散的语义单元，每个单元单独索引以供具体检索。这种方法优先考虑有效的表识别，同时利用列级信息，确保检索出的表数量在可管理的上下文预算范围内。实验表明，该方法保持了高召回率和准确性，并在结构各异的大数据库中，比基线方法表现更佳。此外，提供的解决方案能够在不同的企业环境中部署文本到SQL系统，无需专门的微调，填补了自然语言数据库接口的可扩展性空白。", "conclusion": "本文提出了RASL方法，通过基于组件的检索架构有效利用数据库元数据并解决了大规模企业级数据分析中的检索挑战，极大地提高了文本到SQL系统的部署灵活性和广泛适用性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23194", "html_url": "https://arxiv.org/abs/2507.23194", "title": "GEAK：引入Triton内核AI代理及评估基准", "title_en": "Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks", "authors": "Jianghui Wang,Vinay Joshi,Saptarshi Majumder,Xu Chao,Bin Ding,Ziqiong Liu,Pratik Prabhanjan Brahma,Dong Li,Zicheng Liu,Emad Barsoum", "background": "AI生成的GPU内核的需求正在快速增长，受到工业化和学术界对可扩展、硬件优化解决方案的需求影响。随着深度学习负载变得越来越复杂和多样化，自动低级内核开发变得至关重要，以满足性能和生产力需求。主要的云提供商、半导体公司和研究机构现在都在投资基于人工智能的GPU代码生成，目标是减少手动优化工作，同时在如AMD MI300X等硬件上达到接近专家级别的性能。Triton语言作为一个基于Python的GPU编程DSL，因其在性能和编码便捷性之间的平衡，成为AI生成内核的一个热门目标。", "innovation": "GEAK框架利用先进的LLM生成适用于AMD GPU（包括AMD MI300X和MI250）的高效Triton代码，通过推理循环利用反射式反馈机制进行推理计算，实现了高达63%的正确率和2.59倍的执行速度提升，相对于直接提示前沿LLM和反射式生成流水线的基准.", "conclusion": "研究结果表明，类似GEAK的自主代码生成有潜力加速各种硬件平台的采用，并普及高级内核性能的获取，从而为加速器的广泛应用奠定基础."}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23095", "html_url": "https://arxiv.org/abs/2507.23095", "title": "SMART-Editor：具有结构完整性的人工智能设计编辑的多智能体框架", "title_en": "SMART-Editor: A Multi-Agent Framework for Human-Like Design Editing with Structural Integrity", "authors": "Ishani Mondal,Meera Bharadwaj,Ayush Roy,Aparna Garimella,Jordan Lee Boyd-Graber", "background": "我们介绍了一种框架，称为SMART-Editor，用于在结构化（海报、网站）和非结构化（自然图像）领域跨域的布局和内容编辑。与之前仅进行局部编辑的模型不同，SMART-Editor通过两种策略保持全局一致性：奖励-修正（Reward-Refine），这是一种在推理时进行奖励引导的修正方法，和奖励对齐的布局优化（RewardDPO），这是一种在训练时的偏好优化方法，使用奖励对齐的布局对来进行布局优化。", "innovation": "1. Reward-Refine 和 RewardDPO 两种创新的方法：(a) Reward-Refine 是一种推理时的奖励引导修正方法；(b) RewardDPO 是一种训练时基于奖励的布局优化方法。2. 引入了 SMARTEdit-Bench，这是一种覆盖多领域、级联编辑场景的基准，用于评估模型性能。3. SMART-Editor 能够超越强大的基线模型如 InstructPix2Pix 和 HIVE，在结构化设置中 RewardDPO 可实现高达 15% 的增益，在自然图像上 Reward-Refine 有明显优势。4. 自动和人工评价证明了奖励引导规划在生成语义一致且视觉上对齐的编辑方面的价值。", "conclusion": "SMART-Editor 在结构化和非结构化内容编辑任务上表现出色，特别是在全局一致性上，优于现有基线模型，突出了奖励引导规划的重要作用。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23167", "html_url": "https://arxiv.org/abs/2507.23167", "title": "LENS: 从神经状态学习集成置信度以集成多大型语言模型的答案", "title_en": "LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration", "authors": "Jizhou Guo", "background": "大型语言模型（LLMs）在各种任务中表现出色，不同的模型在不同的领域和能力上表现出色。有效结合多个LLM的预测对于提高系统鲁棒性和性能至关重要。然而，现有的集成方法通常依赖于简单技术，如投票或概率加权，这些方法忽略了模型在不同上下文中的置信度和可靠性差异。", "innovation": "本文提出了一种新的方法LENS（Learning ENsemble confidence from Neural States），该方法通过分析内部表示来学习估计模型置信度。对于每个LLM，训练一个轻量级的线性置信度预测器，利用逐层隐藏状态和归一化概率作为输入。这允许根据模型在上下文中的可靠性对其进行更精细的加权。该方法不需要修改模型参数，并且只需要少量额外的计算。实验结果表明，LENS在多项选择和布尔问题回答任务中的表现显著优于传统的集成方法。研究结果表明，内部表示提供了关于模型置信度的重要信号，并且可以有效地用于集成学习。", "conclusion": "LENS方法通过分析内部表示有效地学习了模型的置信度，从而在多个选择和布尔问题回答任务中显著优于传统的集成方法。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23135", "html_url": "https://arxiv.org/abs/2507.23135", "title": "ISO-Bench: 通过流程计划评测视觉-语言模型的多模态因果推理", "title_en": "ISO-Bench: Benchmarking Multimodal Causal Reasoning in Visual-Language Models through Procedural Plans", "authors": "Ananya Sadana,Yash Kumar Lal,Jiawei Zhou", "background": "在现实环境中运行的多模态模型面临着理解跨模态因果关系的核心挑战。为了评估模型是否能够推断出视觉观察与程序文本之间的因果依赖关系，该论文提出了一种新的基准测试ISO-Bench，其中每个示例包含一个任务步骤的图像和一个计划中的文本片段，目标是判断视觉步骤是发生在文本步骤之前还是之后。", "innovation": "ISO-Bench 提供了一个评估多模态模型在视觉-语言任务中因果理解能力的方法。该基准测试基于流程计划，旨在评估模型推断视觉观察与程序文本之间因果依赖关系的能力。", "conclusion": "评估结果显示，前沿的十种视觉-语言模型在这方面的表现不尽如人意：最佳模型的零样本F1值仅为0.57，以步骤推理的方式进行的链式推理也只有轻微的提高（最高F1值为0.62），远远落后于人类的F1值0.98。进一步的分析还指出了多模态模型在因果理解上的改进方向。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23121", "html_url": "https://arxiv.org/abs/2507.23121", "title": "通过中文文本歧义揭示可信的大语言模型的脆弱性", "title_en": "Uncovering the Fragility of Trustworthy LLMs through Chinese Textual Ambiguity", "authors": "Xinwei Wu,Haojie Li,Hongyu Liu,Xinyu Ji,Ruohan Li,Yule Chen,Yigeng Zhang", "background": "本研究探讨了大规模语言模型（LLMs）可信度的关键研究问题，特别是在面对含糊的叙述文本时，LLMs 的行为，特别是聚焦于中文文本的歧义。研究发现，LLMs 在处理歧义时表现出显著的脆弱性，并揭示了与人类行为显著不同的行为模式。", "innovation": "研究人员创建了一个基准数据集，通过收集和生成带有背景信息的歧义句子及其对应的澄清匹配对，代表多种可能的解释。这些标注的示例被系统地分类为3个主要类别和9个子类别。实验发现，LLMs 在处理歧义时存在显著的脆弱性，表现出不能可靠地区分歧义文本与非歧义文本，对歧义文本的单一解释表现出过度自信，并在理解各种可能意义时表现出过度思考等特征。", "conclusion": "研究结果突显了当前LLMs的基本局限性，这对语言理解中的不确定性处理具有重要意义。这为在包含语言歧义的实际应用中更可靠地部署LLMs提出了迫切需求。数据集和代码已公开发布于此GitHub仓库:this https URL."}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23227", "html_url": "https://arxiv.org/abs/2507.23227", "title": "用大型语言模型在表格式生物标志物数据上实现小样本阿尔茨海默病诊断", "title_en": "Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs", "authors": "Sophie Kearney,Shu Yang,Zixuan Wen,Bojian Hou,Duy Duong-Tran,Tianlong Chen,Jason Moore,Marylyn Ritchie,Li Shen", "background": "早期和准确地诊断阿尔茨海默病（AD），一种复杂的神经退行性疾病，需要分析多样的生物标志物（例如神经影像学、遗传风险因素、认知测试和脑脊液蛋白质），这些生物标志物通常以表格格式呈现。使用灵活的少样本推理、多模态整合以及基于自然语言的解释性，大型语言模型（LLMs）为结构化生物医学数据预测提供了前所未有的机会。背景强调了正确的AD诊断难度，及如何利用LLMs进行精准预测的优势。本文侧重于从中小样本数据中进行AD诊断的方法及其重要性。", "innovation": "本文提出了一种新的框架，称为TAP-GPT，即Tabular Alzheimer's Prediction GPT，它将为商业智能任务设计的TableGPT2语言模型进行适应，用于使用结构化的生物标志数据进行AD诊断。TAP-GPT框架结合了TableGPT2的强大的表格理解能力和LLMs编码的先验知识，性能超过更先进的通用大型语言模型和用于预测任务的表基础模型。这是首次将LLMs应用于使用表格生物标志物数据的预测任务，为生物学医学信息学中的未来LLM驱动的多智能体框架奠定了基础。", "conclusion": "TAP-GPT框架成功地利用了TableGPT2的强表格理解和LLMs的编码先验知识，提供了一种在有限样本数据中对AD进行准确诊断的新方法，并表明了LLMs在生物标记预测中的巨大潜力。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23158", "html_url": "https://arxiv.org/abs/2507.23158", "title": "人类与LLM对话中的用户反馈：理解用户的镜像但作为学习信号的噪音", "title_en": "User Feedback in Human-LLM Dialogues: A Lens to Understand Users But Noisy as a Learning Signal", "authors": "Yuhan Liu,Michael J.Q. Zhang,Eunsol Choi", "background": "一旦语言模型（LMs）部署后，它们可以与用户长期互动，理想情况下会根据用户反馈不断进化。然而，直接请求用户反馈可能会打断用户的体验，因此研究从用户-LM互动日志中获取用户反馈的问题变得重要。研究者在两个用户-LM互动数据集（WildChat和LMSYS）中研究了隐式用户反馈。他们通过分析用户反馈在用户-LLM对话轨迹中的出现情况及其原因，揭示了相关见解。此外，他们还研究了从这种隐式用户反馈中提取学习信号的方法。研究表明，用户反馈的内容（如用户需要澄清）而不是极性（如用户对之前模型的回复不满意）可以提高模型在设计较短的人类问题中的性能（MTBench），但在更长且更复杂的问题上（WildBench）则不适用。研究还发现，用户反馈的有效性很大程度上取决于用户初始提示的质量。综合这些发现，他们提供了一个关于隐式用户反馈深刻研究，展示了其潜力和局限性", "innovation": "论文的研究重点是从用户和语言模型之间的互动日志中自动收集和利用用户反馈。通过两个不同的数据集对这一过程进行了详细分析，发现了用户反馈内容对于模型性能的影响，尤其是在不同复杂度问题上的表现差异，并指出了初始提示质量在反馈有用性中的重要性。", "conclusion": "隐式用户反馈为理解用户需求提供了一种有效方式，但作为学习信号可能不太有效，其价值很大程度上取决于用户初始提问的质量。未来的研究需要进一步探索改善反馈质量的方法，以及如何更好地利用这种反馈来增强模型性能。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23220", "html_url": "https://arxiv.org/abs/2507.23220", "title": "基于稀疏自编码器的机制主题模型：非词元模型方向", "title_en": "Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders", "authors": "Carolina Zheng,Nicolas Beltran-Velez,Sweta Karlekar,Claudia Shi,Achille Nazaret,Asif Mallik,Amir Feder,David M. Blei", "background": "传统的主题模型在大型文本集合中发现潜在主题方面是有效的，但由于依赖于袋模型表示，它们在捕捉语义抽象特征方面存在困难。虽然一些神经变体使用更丰富的表示方法，但它们同样受限于将主题表示为单词列表，这限制了它们表达复杂主题的能力。", "innovation": "我们引入了机制主题模型（MTMs），这是一种基于稀疏自编码器（SAEs）学习可解释特征的操作类主题模型。通过定义主题与这个语义丰富空间中的特征描述，MTMs可以揭示更具表现力的概念主题。与同时期的其他主题模型不同，MTMs在基于主题的引导向量监管下，能够实现可控的文本生成。此外，我们提出了一种基于LLM的成对比较评估框架，以正确评估MTM主题与基于单词列表的方法的对比结果。", "conclusion": "在五个数据集上，MTMs在相干度指标上与传统和神经基线模型相匹配或超过，而且总是被主题评判者更偏好，并使LLM输出实现有效引导。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23211", "html_url": "https://arxiv.org/abs/2507.23211", "title": "通过利用负面样本提升少样本即席学习的成功之道：失败是通向成功的垫脚石", "title_en": "Failures Are the Stepping Stones to Success: Enhancing Few-Shot In-Context Learning by Leveraging Negative Samples", "authors": "Yunhao Liang,Ruixuan Ying,Takuya Taniguchi,Zhe Cui", "background": "大型语言模型展示了强大的少样本即席学习（ICL）能力，但表现对提供的示例高度敏感。研究主要集中在为每个输入查询检索相应示例，既提升了学习过程的效率和可扩展性，也减轻了人工示例选择中的固有偏见。然而，现有研究主要强调利用正样本，忽视了负面样本中的附加信息对于上下文学习的帮助。", "innovation": "本文提出了一种新的方法，利用负面样本更好地选择正样本，从而提升少样本即席学习的性能。首先，基于零样本 Cot 构建正样本和负样本语料库。在推理过程中，采用语义相似性方法从正样本和负样本语料库中选择与查询最相似的示例，然后基于与负样本语义相似性的正样本进一步检索，并将这些正样本与先前选定的正样本拼接起来，作为即席学习的示例演示。实验结果表明，该方法超越了仅依赖与查询最相似的正样本的方法，证实了负面样本中的附加信息通过增强正样本选择提升了即席学习的性能。", "conclusion": "该方法通过利用负面样本增强了少样本即席学习的性能，并且通过语义相似性选择正样本和进一步检索正样本，大大改善了即席学习的表现。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23319", "html_url": "https://arxiv.org/abs/2507.23319", "title": "你认为哪项内容是禁忌？——大规模语言模型对敏感内容行为的实证评估", "title_en": "What's Taboo for You? - An Empirical Evaluation of LLMs Behavior Toward Sensitive Content", "authors": "Alfio Ferrara,Sergio Picascia,Laura Pinnavaia,Vojimir Ranitovic,Elisabetta Rocchetti,Alice Tuveri", "background": "之前的研究所着重于明确地对语言模型进行训练，以筛选和净化敏感内容。然而，很少有人探究语言模型在没有明确指令的情况下是否也会自发地净化语言。本文通过实验分析了GPT-4o-mini在重新表述敏感内容时的隐性净化行为，并评估了内容敏感度的变化程度。此外，该研究还评估了语言模型零样本分类句子敏感度的能力，并将其表现与传统方法进行了比较。", "innovation": "本文首次通过实证方法探讨了语言模型在没有明显指令的情况下是否会自动净化语言，并且对比了语言模型在分类句子敏感度方面的零样本能力。", "conclusion": "实验结果显示，GPT-4o-mini系统性地将内容向较少敏感的类别进行净化，减少了贬低性和禁忌性语言的使用。同时，语言模型在零样本分类句子敏感度方面也表现出色，其性能与传统方法相当。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23247", "html_url": "https://arxiv.org/abs/2507.23247", "title": "P-ReMIS: 在精神健康领域的语用推理及社会影响", "title_en": "P-ReMIS: Pragmatic Reasoning in Mental Health and a Social Implication", "authors": "Sneha Oram,Pushpak Bhattacharyya", "background": "近年来，解释性和个性化聊天机器人的发展在精神健康领域得到了显著增长，但这些聊天机器人的推理能力和对话机制尚未被充分探索。因此，本研究旨在探讨大规模语言模型（LLMs）在精神健康领域中的语用推理能力。", "innovation": "引入了P-ReMe数据集，并提出了精神健康领域中关于含蓄义和预设的新定义。研究者在此基础上设计了三项任务来评估LLMs的推理能力，还提出了一种名为StiPRompts的方法以探讨精神健康的污名问题。", "conclusion": "实验结果表明Mistral和Qwen在精神健康领域的表现具有显著的推理能力。此外，研究还指出Claude-3.5-haiku相较于其他LLMs更能负责任地处理精神健康的污名问题。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23358", "html_url": "https://arxiv.org/abs/2507.23358", "title": "Text-to-SQL Task-oriented Dialogue Ontology Construction", "title_en": "Text-to-SQL Task-oriented Dialogue Ontology Construction", "authors": "Renato Vukovic,Carel van Niekerk,Michael Heck,Benjamin Ruppik,Hsien-Chin Lin,Shutong Feng,Nurul Lubis,Milica Gasic", "background": "大型语言模型（LLMs）通常用作通用知识来源，但它们依赖于参数化知识，这限制了可解释性和可信度。在任务导向对话（TOD）系统中，这种分离是显性的，通过使用结构化外部数据库（具有显式本体）来确保可解释性和可控性。然而，构建这种本体需要手动标签或监督训练。", "innovation": "我们介绍了TeQoDO：一种基于文本到SQL任务的TOD本体构建方法。通过结合LLM的内在SQL编程能力和在提示中提供的对话理论，LLM可以在无需监督的情况下自主构建TOD本体。实验表明，TeQoDO优于迁移学习方法，并且其构建的本体在下游对话状态跟踪任务上具有竞争力。消融研究表明对话理论的关键作用。TeQoDO还扩展到允许构建更大规模的本体，我们在维基百科和arXiv数据集上进行了这项研究。", "conclusion": "我们认为这是走向更广泛地应用本体以提高LLM可解释性的一步。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23248", "html_url": "https://arxiv.org/abs/2507.23248", "title": "评估大型语言模型在孟加拉语多语言能力：基准创建与性能分析", "title_en": "Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis", "authors": "Shimanto Bhowmik,Tawsif Tashwar Dipto,Md Sazzad Islam,Sheryl Hsu,Tahsin Reasat", "background": "孟加拉语在自然语言处理(NLP)研究中代表性不足，但因其独特的语言结构及计算限制，研究颇具挑战性。现有的大型语言模型(Large Language Models, LLMs)缺乏针对孟加拉语的标准评估基准。因此，该研究旨在系统地考察阻碍孟加拉语NLP性能的关键挑战，集中于评估数据集的缺乏。随后，评估了10个最近的开源大型语言模型在8个翻译数据集上的表现，并进行了全面的错误分析以找出主要的失败模式。", "innovation": "研究系统地评估了10个开源大型语言模型在8个翻译数据集上的表现，并进行了全面的错误分析。研究揭示了孟加拉语与英语在小型模型和特定模型家庭方面表现的一致性能差距，还识别了某些架构（例如DeepSeek）的潜在稳健性，这些架构在不同语言中保持了更稳定的性能。此外，研究发现了标记化效率与LLM准确性之间的反向关系，指出输入标记化过度会导致模型表现较差，而更高效且简洁的标记化可以提高模型性能。这些发现指出了当前模型的不足之处，突显了需要改进多语言数据集质量和评价方法的重要性。", "conclusion": "近日的研究成果突显了改进当前模型的关键区域，并强调了为多语言情境制定改进的数据集质量和评价方法的重要性。该项工作的成果将促进对未充分研究的语言的NLP研究，有助于实现先进的语言技术的全球普及。研究中使用的代码和数据集将在公开网址：<this https URL> 中获取。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23334", "html_url": "https://arxiv.org/abs/2507.23334", "title": "MUST-RAG：基于检索增强生成的音乐文本问答", "title_en": "MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation", "authors": "Daeyong Kwon,SeungHeon Doh,Juhan Nam", "background": "大规模语言模型（LLMs）在多个领域展现了强大的能力，但它们在音乐相关应用中的表现受限，因为训练数据中音乐特定知识的比例较小。为了改进这一点，本研究提出了一种名为MusT-RAG的综合框架，该框架基于检索增强生成（RAG）技术，旨在将通用语言模型适应于仅文本的音乐问答（MQA）任务。RAG技术通过在生成答案时检索相关上下文信息来向LLMs提供外部知识。本研究针对音乐领域，开发了专为检索阶段设计的MusWikiDB音乐专用向量数据库，并在推理和微调过程中利用上下文信息，有效转变通用语言模型为音乐专用模型。实验结果显示，MusT-RAG相比传统微调方法在提升语言模型音乐领域的适应能力方面表现出显著的优势，其在领域内和领域外的音乐问答基准测试中均表现出持续的改进。此外，MusWikiDB相比通用维基百科语料库表现更优，提供更佳性能和计算效率.", "innovation": "提出了MUST-RAG框架，该框架采用了检索增强生成（RAG）技术，并专门为音乐领域设计了MusWikiDB音乐专用向量数据库。在模型适应过程中，MusT-RAG不仅在推理阶段，也在微调阶段利用了上下文信息，将通用语言模型有效适应为音乐专用模型。实验表明，与传统的微调方法相比，MusT-RAG在音乐领域的适应能力上表现出显著提升，显示了其在领域内和领域外音乐问答任务中的持续改进，且MusWikiDB相较于通用维基百科语料库表现更佳，提供了更好的性能和计算效率.", "conclusion": "通过MUST-RAG框架，显著改善了通用语言模型在音乐领域中的适应能力。该框架展示了在音乐问答任务中的有效应用，并证明了专为音乐领域设计的数据库和上下文信息利用对提高模型适应性的重要性。未来研究可以进一步探索和完善这一框架，以提高其在音乐领域的应用效果。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23382", "html_url": "https://arxiv.org/abs/2507.23382", "title": "MPCC：具有复杂约束的多模态规划基准", "title_en": "MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models", "authors": "Yiyan Ji,Haoran Chen,Qiguang Chen,Chengyue Wu,Libo Qin,Wanxiang Che", "background": "多模态规划能力是指能够在多模态背景下预测、推理和设计执行任务的步骤，这对于多步骤的复杂推理和决策至关重要。然而，当前的基准测试存在两个关键挑战：（1）它们无法直接评估多模态真实的规划能力；（2）它们缺乏跨模态的约束或隐性约束。为了应对这些挑战，我们提出了Multimodal Planning with Complex Constraints (MPCC) 作为第一个系统评估多模态大型语言模型 (MLLM) 在规划中处理多模态约束能力的基准。", "innovation": "MPCC 针对以下几个方面进行了创新：1）聚焦于三个实际任务：飞行规划、日程规划和会议规划；2）引入复杂约束（如预算、时间、空间等），并设置了不同难度级别（EASY、MEDIUM、HARD），以区分约束复杂性和搜索空间扩展；3）实验结果揭示了多模态大型语言模型在处理多约束场景时的高度敏感性和传统多模态提示策略的失败。", "conclusion": "我们的研究通过正式化规划中的多模态约束，提供了一个严谨的评估框架，并强调了在真实世界多模态大型语言模型应用中增强约束感知推理的迫切需求。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23404", "html_url": "https://arxiv.org/abs/2507.23404", "title": "带有注意力相关性评分的增强阿拉伯文本检索", "title_en": "Enhanced Arabic Text Retrieval with Attentive Relevance Scoring", "authors": "Salah Eddine Bekhouche,Azeddine Benlamoudi,Yazid Bounab,Fadi Dornaika,Abdenour Hadid", "background": "阿拉伯语在自然语言处理（NLP）和信息检索（IR）中面临独特挑战，因为它的形态复杂、可选的音标记以及现代标准阿拉伯语（MSA）和各种方言的共存。尽管全球阿拉伯语的重要性不断增加，但在NLP研究和基准资源中，阿拉伯语仍然未得到充分代表。", "innovation": "本文提出了一个专门为阿拉伯语设计的增强密集段落检索（DPR）框架，其核心是一种新颖的注意力相关性评分（ARS）方法。它使用自适应评分函数取代了标准的交互机制，更有效地建模了问题和段落之间的语义相关性。该方法结合了预训练的阿拉伯语言模型和架构优化，显著提高了检索性能和答案排名准确性。", "conclusion": "通过引入注意力相关性评分（ARS）方法和优化架构，该研究显著提高了阿拉伯语问题的检索性能和答案排名准确性。相关代码已公开发布在GitHub上。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23279", "html_url": "https://arxiv.org/abs/2507.23279", "title": "在Mixture-of-Experts大规模语言模型中揭示超级专家", "title_en": "Unveiling Super Experts in Mixture-of-Experts Large Language Models", "authors": "Zunhai Su,Qingyuan Li,Hao Zhang,YuLei Qian,Yuchen Xie,Kehong Yuan", "background": "稀疏激活的Mixture-of-Experts（MoE）模型已被证明能够增强大型语言模型（LLMs）的学习能力。最近的研究探讨了利用专家固有的重要性差异来压缩模型的有效性，以提高MoE LLMs的效率。然而，现有方法往往依赖于经验标准来识别关键的专家，缺乏对不同重要性专家的深入研究和理解。", "innovation": "本文首次发现了在模型前向推理过程中起决定性作用的专家subset，我们称其为Super Experts (SEs)。这些SEs在公开源代码的MoE LLMs中普遍存在，它们虽然数量较少，但一旦被剪枝，会导致模型性能显著下降。本文的研究还揭示了SEs的特点，包括在down_proj输出中的稀少但极端激活异常值，导致了大量的隐藏层激活状态。此外，SEs的重要性不受后训练过程的影响。通过一系列任务评估，证实了SEs对模型整体性能（特别是在数学推理方面）有着重要影响。进一步的研究还发现，MoE LLMs依赖于SEs来诱导注意力汇，这对注意力分数的分布至关重要，但SEs的剪枝会显著破坏这种依赖。", "conclusion": "本文的研究提供了对SEs的深入了解，它们在模型推理中的作用重要性，并且还揭示了SEs剪枝对模型性能的显著负面冲击。MoE LLMs的成功取决于SEs的贡献，这些发现对优化和理解MoE LLMs至关重要。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23399", "html_url": "https://arxiv.org/abs/2507.23399", "title": "在云端之外：评估本地大型语言模型部署对译者的好处和缺点", "title_en": "Beyond the Cloud: Assessing the Benefits and Drawbacks of Local LLM Deployment for Translators", "authors": "Peter Sandrini", "background": "大语言模型的迅速发展为翻译领域带来了机遇和挑战。尽管商业化的云基AI聊天机器人在翻译研究中受到广泛关注，但数据隐私、安全性和公平访问等方面的担忧促使探索替代的部署模式。这项研究评估了在CPU平台上安装的三个开源模型，并将其与商业上可用的在线聊天机器人进行比较。评估重点在于功能性表现，而非机器和人类翻译质量的比较，这是一个已经进行了大量研究的领域。", "innovation": "这项研究评估了在本地部署免费的开源语言模型作为替代商业化云基AI解决方案的可能性。", "conclusion": "研究发现表明，本地部署虽然带来了挑战，但增强了数据控制、提升了隐私性并减少了对云服务的依赖性，这为未来旨在使大型语言模型更广泛和实用的用户，特别是针对个人译者和小型企业的研究和开发工作提供了有价值的参考。这些发现为AI技术的民主化开辟了新的知识领域。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23400", "html_url": "https://arxiv.org/abs/2507.23400", "title": "MRGSEM-Sum:基于多关系图和结构性熵最小化的无监督多文档摘要框架", "title_en": "MRGSEM-Sum: An Unsupervised Multi-document Summarization Framework based on Multi-Relational Graphs and Structural Entropy Minimization", "authors": "Yongbing Zhang,Fang Nan,Shengxiang Gao,Yuxin Huang,Kaiwen Tan,Zhengtao Yu", "background": "多文档摘要的核心挑战在于文档间复杂关系和信息冗余的存在。现有方法主要采用单关系图并且需要预先确定簇的数量，这限制了它们完全表示丰富关系信息和自适应划分句子组以减少冗余的能力。已有基于图聚类的方法虽然有效，但往往无法处理多重关系和自适应地确定最佳簇数。", "innovation": "提出了基于多关系图和结构性熵最小化的无监督多文档摘要框架MRGSEM-Sum。具体而言，该框架构建了一个综合了句子间语义和话语关系的多关系图，利用两维结构性熵最小化算法进行聚类，自动确定最优簇数并有效组织句子为连贯组。此外，引入了位置感知压缩机制以精简每个簇，生成简洁和有信息量的摘要。", "conclusion": "在四个基准数据集（Multi-News、DUC-2004、PubMed和WikiSum）上的实验表明，MRGSEM-Sum 方法在多个方面优于先前的无监督方法，并且在某些情况下实现了与监督模型和大型语言模型相当的性能。人工评估表明，MRGSEM-Sum 生成的摘要具有高一致性和覆盖率，接近人类级别的质量。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23386", "html_url": "https://arxiv.org/abs/2507.23386", "title": "Causal2Vec：提高仅解码器大型语言模型作为多功能嵌入模型的表现", "title_en": "Causal2Vec: Improving Decoder-only LLMs as Versatile Embedding Models", "authors": "Ailiang Lin,Zhuoyun Li,Kotaro Funakoshi", "background": "目前，仅解码器的大型语言模型（LLMs）越来越多地被用于构建嵌入模型，这些模型能够将自然语言文本的语义信息高效地编码为密集向量表示，用于各种嵌入任务。然而，许多现有的方法主要是在LLM中去除因果注意力掩码以启用双向注意力，这可能会削弱模型从预训练过程中获取语义信息的能力。此外，领先的单向方法通常依赖于额外的输入文本来克服因果注意力的固有局限性，这不可避免地增加了计算成本。", "innovation": "本文提出了一种名为Causal2Vec的一般用途嵌入模型，旨在提高仅解码器LLM的表现，同时不改变其原始架构且不引入显著的计算开销。Causal2Vec首先使用轻量级的BERT风格模型对输入文本进行预编码，将其转化为一个上下文标记，并将其添加到LLM的输入序列前端，使每个标记能够在不关注未来标记的情况下捕获上下文信息。此外，通过将上下文标记和EOS标记的最后一个隐藏状态连接起来作为最终文本嵌入，Causal2Vec减轻了最近性偏差的影响，从而使LLM更好地利用编码在上下文标记中的语义信息。", "conclusion": "在仅使用公开可访问的检索数据集进行训练的模型中，Causal2Vec在大规模文本嵌入基准测试（MTEB）上的表现达到了最先进的水平，同时将所需的序列长度减少了高达85%，推理时间减少了高达82%，相比表现最佳的方法而言。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23407", "html_url": "https://arxiv.org/abs/2507.23407", "title": "超越被动批判性思维：培养主动质疑以增强人机协作", "title_en": "Beyond Passive Critical Thinking: Fostering Proactive Questioning to Enhance Human-AI Collaboration", "authors": "Ante Wang,Yujie Lin,Jingyao Liu,Suhang Wu,Hao Liu,Xinyan Xiao,Jinsong Su", "background": "批判性思维是构建 robust AI 系统的关键，能够使系统不盲目接受有缺陷的数据或有偏见的推理。然而，先前的研究主要集中在被动批判性思维上，模型只是简单地拒绝有问题的查询，而没有采取建设性的步骤来解决用户请求。本文引入了主动批判性思维的新范式，模型在这种范式下会主动向用户寻求缺失或澄清的信息，以更好地解决他们的查询。", "innovation": "本文提出了主动批判性思维，即将模型在处理查询时的行为从被动转为主动，尝试通过引入基准测试 GSM-MC 和 GSM-MCE 来评估这一能力，这些基准测试基于 GSM8K，针对不完整或误导性的条件下的数学推理。通过强化学习 (RL) 提升了模型的主动批判性思维能力，显著提高了准确性。", "conclusion": "实验表明，虽然 Qwen3 和 Llama 系列模型在传统的推理任务中表现出色，但由于规模较小，在主动批判性思维能力上面临挑战。通过引入强化学习 (RL) 算法，显著提升了模型在 GSM-MC 挑战中的表现，Qwen3-1.7B 的准确性从 0.15% 提高到了 73.98%。这项工作促进了模型通过主动批判性思维与用户更有效地协作，从而提高问题解决能力。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23465", "html_url": "https://arxiv.org/abs/2507.23465", "title": "组织角色意识语言模型以实现安全和情境化的访问控制", "title_en": "Role-Aware Language Models for Secure and Contextualized Access Control in Organizations", "authors": "Saeed Almheiri,Yerulan Kongrat,Adrian Santosh,Ruslan Tasmukhanov,Josemaria Vera,Muhammad Dehan Al Kautsar,Fajri Koto", "background": "由于大型语言模型（LLMs）在企业环境中的应用不断增加，基于用户角色控制模型行为变得至关重要。现有的安全方法通常假设访问是均匀的，并侧重于防止有害或具有毒性的输出，而没有考虑角色特异性的访问限制。", "innovation": "本文研究了如何将LLMs微调以生成反映不同组织角色关联的访问权限的响应。我们探索了三种建模策略：基于BERT的分类器、基于LLM的分类器以及角色条件生成。为了评估这些方法，我们创建了两个互补的数据集。第一个数据集是通过对现有指令调优语料库进行聚类和角色标记改编，第二个数据集是合成生成的，以反映现实中的、角色敏感的企业场景。我们评估了模型在不同组织结构下的性能，并分析了对提示注入、角色不匹配和破解尝试的鲁棒性。", "conclusion": "研究发现，通过微调LLMs可以实现响应生成符合不同角色的访问权限。评估结果表明，所提出的方法在不同组织结构下表现良好，并且对提示注入、角色不匹配和破解尝试具有较高的鲁棒性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23541", "html_url": "https://arxiv.org/abs/2507.23541", "title": "Med-R³：通过渐进增强学习提高LLMs的医学检索增强推理", "title_en": "Med-R$^3$: Enhancing Medical Retrieval-Augmented Reasoning of LLMs via Progressive Reinforcement Learning", "authors": "Keer Lu,Zheng Liang,Youquan Li,Jiejun Tan,Da Pan,Shusen Zhang,Guosheng Dong,Huang Leng", "background": "在医学场景中，有效检索外部知识并利用它进行严谨的逻辑推理是非常重要的。现有工作主要集中在增强模型检索或推理能力中的某一方面，而忽视了这两者之间的联合优化。这导致检索和推理过程之间的协调有限。同时，当前方法高度依赖于监督微调（SFT），可能会使模型记住现有的问题解决途径，从而限制其在面对新颖问题情境时的泛化能力。虽然一些研究试图通过强化学习来改进通用领域的检索增强推理，但它们的设计奖励函数未能充分捕捉医学领域的特定需求。", "innovation": "我们提出了名为 **Med-R³** 的医疗检索增强推理框架，该框架通过渐进增强学习驱动。该框架首先开发了模型在医学问题上进行逻辑推理的能力，之后根据这个基础，适应性优化检索能力以更好地与知识库特性和外部信息利用保持一致，最终进行了检索和推理协调的联合优化。实验结果表明，Med-R³ 可以达到最先进的性能，LLaMA3.1-8B-Instruct + Med-R³ 在与闭源 GPT-4o-mini 相似的参数规模下，超过后者3.93%，而配备 Med-R³ 的 Qwen2.5-14B 则取得了更大的增益，达到了13.53%。", "conclusion": "Med-R³ 通过渐进增强学习框架解决了现有的医学检索增强推理的挑战，实现了模型在检索和推理协调方面的联合优化，最终达到了先进的性能水平。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23486", "html_url": "https://arxiv.org/abs/2507.23486", "title": "一种新的评估基准：揭示医疗LLMs在临床领域的安全性和有效性", "title_en": "A Novel Evaluation Benchmark for Medical LLMs: Illuminating Safety and Effectiveness in Clinical Domains", "authors": "Shirui Wang,Zhihui Tang,Huaxia Yang,Qiuhong Gong,Tiantian Gu,Hongyang Ma,Yongxin Wang,Wubin Sun,Zeliang Lian,Kehang Mao,Yinan Jiang,Zhicheng Huang,Lingyun Ma,Wenjie Shen,Yajie Ji,Yunhui Tan,Chunbo Wang,Yunlu Gao,Qianling Ye,Rui Lin,Mingyu Chen,Lijuan Niu,Zhihao Wang,Peng Yu,Mengran Lang,Yue Liu,Huimin Zhang,Haitao Shen,Long Chen,Qiguang Zhao,Si-Xuan Liu,Lina Zhou,Hua Gao,Dongqiang Ye,Lingmin Meng,Youtao Yu,Naixin Liang,Jianxiong Wu", "background": "大型语言模型（LLMs）在临床决策支持上有潜力，但面临安全性评估和有效性验证的重大挑战。本研究基于临床专家共识开发了临床安全-有效性双轨基准（CSEDB），包含涵盖重症识别、指南遵循和药物安全等关键领域的30项评估标准，并设置了加权后果指标。通过32名专科医师开发并审查了2069个开放式问答项目，涉及26个临床部门，以模拟真实世界场景。基准测试结果显示，六种LLM的整体表现为中等水平（总分平均57.2%，安全性54.7%，有效性62.3%），高风险场景下性能显著下降（p < 0.0001）。特定领域的医疗LLM相较于通用型模型表现出一致的性能优势，安全性得分为0.912，有效性得分为0.861。", "innovation": "开发了临床安全-有效性双轨基准（CSEDB）；集成了30项覆盖多种关键领域的评估标准；对六种LLM进行了基准测试并按场景细分；发现特定领域的医疗LLM性能优于通用模型。", "conclusion": "本研究提供了一个标准化的评估指标，用于评价医疗LLM的临床应用，促进了不同场景下的比较分析、风险识别及改进方向。此基准测试有助于促进大型语言模型在医疗环境中的更安全、更有效的部署。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22892", "html_url": "https://arxiv.org/abs/2507.22892", "title": "基于实时脑电图的混合脑机接口：一种大规模语言模型个性化语言康复框架", "title_en": "Hybrid EEG--Driven Brain--Computer Interface: A Large Language Model Framework for Personalized Language Rehabilitation", "authors": "Ismail Hossain,Mridul Banik", "background": "传统的辅助和替代沟通系统（AAC）和语言学习平台往往无法实时适应用户认知和语言需求的变化，尤其在中风后语言障碍或肌萎缩侧索硬化等神经条件下表现不佳。最近的非侵入性脑电图（EEG）—基脑—计算机接口（BCI）和基于变换器的大规模语言模型（LLM）的发展提供了互补的优势：BCI通过低疲劳性捕获用户的神经意图，而LLM则生成上下文相关的语言内容。", "innovation": "我们提出并评估了一种新颖的混合框架，利用实时EEG信号驱动LLM驱动的语言康复助手系统。该系统旨在：(1) 使严重言语或运动障碍的用户可以通过意念命令导航语言学习模块；(2) 动态个性化词汇、句子构建练习和纠错反馈；(3) 监控认知努力的神经标记，以实时调整任务难度。", "conclusion": "该系统集成BCI和LLM技术，旨在为严重言语或运动障碍的用户提供个性化的语言康复解决方案，提高语言学习效率，促进康复效果。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23588", "html_url": "https://arxiv.org/abs/2507.23588", "title": "DiffLoRA: 差分低秩适配器用于大型语言模型", "title_en": "DiffLoRA: Differential Low-Rank Adapters for Large Language Models", "authors": "Alexandre Misrahi,Nadezhda Chirkova,Maxime Louis,Vassilina Nikoulina", "background": "差分变换器 (Differential Transformer) 最近被提出，通过去噪器注意力机制消除噪声以改进 Transformer 模型的表现。在此工作中，作者引入了 DiffLoRA，这是差分注意力机制的一种参数效率适应方法，结合了低秩适配器到正向和负向注意力项中。这种方法保留了 LoRA 的效率，同时试图从差分注意力带来的性能提升中受益。作者对 DiffLoRA 在多种自然语言处理 (NLP) 任务上进行了评估，包括一般基准、多样本在上下文学习、检索增强生成 (RAG) 和长上下文测试。虽然 DiffLoRA 在大多数评估任务中未能达到其他参数效率微调方法的表现，但在某些领域中表现出有趣的结果（HumanEval 上提高了 11 个百分点）。作者对微调后的注意力模式进行了分析，以识别这种表现的原因。", "innovation": "DiffLoRA 是一种参数效率的差分注意力机制，在正向和负向注意力项中采用低秩适配器。这种设计试图结合差分注意力机制带来的性能提升和 LoRA 的高效性。通过这种方式，DiffLoRA 设法在一些特定领域中提高了表现。研究表明，对微调后的注意力模式进行分析有助于理解这一行为的具体原因。", "conclusion": "虽然 DiffLoRA 在大多数评估任务中的表现不如其他参数效率微调方法，但它在某些领域展示了有趣的结果，表现出众。通过分析微调后的注意力模式，作者识别出了这种行为背后的可能原因。该研究为大型语言模型的参数高效微调提供了一种新的方法，并对其在不同任务中表现出的特定行为进行了探讨。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23661", "html_url": "https://arxiv.org/abs/2507.23661", "title": "使用深度学习模型和预训练模型微调在社交媒体上识别和屏蔽阿拉伯语仇恨言论", "title_en": "Arabic Hate Speech Identification and Masking in Social Media using Deep Learning Models and Pre-trained Models Fine-tuning", "authors": "Salam Thabet Doghmash,Motaz Saad", "background": "近年来，社交媒体上的仇恨言论识别已成为一个越来越重要的议题。本研究旨在解决两个问题：1) 在阿拉伯文本中检测仇恨言论；2) 清理给定文本中的仇恨言论。清理的含义是根据每个词的字母数量用星号替换每个脏词。对于第一个问题，我们使用深度学习模型和变换器进行多项试验，以确定在F1分数方面的最佳模型。对于第二个问题，我们将此视为机器翻译任务，输入包含脏文本的句子，输出是屏蔽脏文本的相同句子。所述方法在仇恨言论检测中达到92%的宏F1分数和95%的准确率。在文本清理试验中，用于遮蔽仇恨言论的最佳模型在1-gram上的BLEU得分达到0.3，这与最新机器翻译系统相比是一个不错的结果。", "innovation": "本研究创新地将机器翻译任务应用于清理含有仇恨言论的文本，同时提出了在阿拉伯文本中使用深度学习和预训练模型来检测仇恨言论的最佳实践，实现了较高的F1分数和准确率，特别是在BLEU评分方面表现良好，达到0.3，改进了现有机器翻译系统的性能。", "conclusion": "本研究通过在阿拉伯文本中应用深度学习模型和预训练模型，在仇恨言论检测和清理方面取得了显著的成果。达到了92%的宏F1分数和95%的准确率。文本清理模型在BLEU得分方面的表现也优于现有机器翻译系统，达到了0.3。这些结果表明，使用深度学习方法处理阿拉伯语仇恨言论问题是可行且有效的。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23577", "html_url": "https://arxiv.org/abs/2507.23577", "title": "T-Detect: 基于尾部特征的统计规范化方法用于鲁棒检测 adversarial 机器生成文本", "title_en": "T-Detect: Tail-Aware Statistical Normalization for Robust Detection of Adversarial Machine-Generated Text", "authors": "Alva West,Luodan Zhang,Liuliu Zhang,Minjun Zhu,Yixuan Weng,Yue Zhang", "background": "随着复杂文本生成模型的增多，迫切需要开发出强大的检测方法来识别机器生成的内容，特别是那些通过对抗扰动尝试逃避检测的文本。现有的一些零样本检测器常常依赖统计措施，这种措施假定数据服从高斯分布，但面对具有重尾统计特征的对抗性或非地道英语文本时，这一假设会失效。", "innovation": "T-Detect 是一种新的检测方法，它从根本上重新设计了基于曲率的检测器的统计核心，用学生 t 分布衍生出的重尾偏差分数取代了标准的高斯规范化。理论依据是对抗性文本通常表现出显著的尖峰分布，从而使传统的统计假设无效。T-Detect 计算检测分数的方法是对一段文本的对数似然进行 t 分布期望矩的规范化，提供了对统计异常值的更强鲁棒性。", "conclusion": "通过在具有挑战性的 RAID 基准数据集和 HART 数据集上的实验证明，T-Detect 在性能上优于强基线方法，特别在目标领域中 AUCROC 提高了 3.9%。当与 CT 方法结合使用时，在 RAID 的 Books 领域 T-Detect 达到了 AUCROC 0.926 的状态最佳性能。我们的贡献在于提出了一种新的统计基础方法，并通过消融验证和全面分析其对抗性条件下的性能表现。相关代码已公开发布。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23776", "html_url": "https://arxiv.org/abs/2507.23776", "title": "级联信息披露用于问题解决能力的通用评估", "title_en": "Cascaded Information Disclosure for Generalized Evaluation of Problem Solving Capabilities", "authors": "Yunxiang Yan,Tomohiro Sawada,Kartik Goyal", "background": "虽然问答（QA）基准性能评估是一种自动且可扩展的方法来比较大规模语言模型（LLMs），但它是一种间接评估其底层问题解决能力的方法。因此，本文提出了一个基于‘级联问题披露’的整体和通用框架，以更准确地评估模型的问题解决能力的同时保持可扩展性和自动化。这种方法以阶段的方式收集模型响应，每一阶段揭示问题的部分信息，旨在引发LLMs的综合推理能力。我们发现，该方法不仅为LLMs提供了更好的比较，还使模型在标准问答模式下产生更好的中间痕迹。通过在多种推理和知识密集型问答数据集上对比不同规模和家族的LLMs进行实证验证，我们的方法缩小了标准问答评估中观察到的性能差距，表明普遍采用的间接问答评价模式可能高估了模型之间性能差异。进一步的消融研究进一步验证了我们的发现。", "innovation": "提出了基于级联问题披露的整体和通用框架，以更准确地评估模型的问题解决能力，这不仅为LLMs提供了更好的比较，还使模型在标准问答模式下产生更好的中间痕迹。该方法缩小了标准问答评估中观察到的性能差距，表明普遍采用的间接问答评价模式可能高估了模型之间性能差异。", "conclusion": "我们的方法缩小了标准问答评估中观察到的性能差距，表明普遍采用的间接问答评价模式可能高估了模型之间性能差异，进一步的消融研究进一步验证了我们的发现。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22902", "html_url": "https://arxiv.org/abs/2507.22902", "title": "向自主AI医生迈进：实境中自主智能代理AI与认证医生的量化基准比较", "title_en": "Toward the Autonomous AI Doctor: Quantitative Benchmarking of an Autonomous Agentic AI Versus Board-Certified Clinicians in a Real World Setting", "authors": "Hashim Hayat,Maksim Kudrautsau,Evgeniy Makarov,Vlad Melnichenko,Tim Tsykunou,Piotr Varaksin,Matt Pavelle,Adam Z. Oskowitz", "background": "全球预计到2030年将短缺1100万医疗工作者，且行政负担占临床时间的50%。人工智能（AI）有潜力缓解这些问题，但目前尚未有完整的基于大型语言模型（LLM）的自主AI系统在真实临床环境中经过严格评估。在本研究中，我们评估了一种基于多代理的AI系统Doctronic是否能够在虚拟急诊环境中自主发挥作用，作为AI医生与认证临床医生进行比较。", "innovation": "开发并评估了一种基于多代理的自主AI系统Doctronic，并在虚拟急诊环境中将其实境化，对比其与认证临床医生在500次急诊远程医疗服务中的表现。该系统通过与盲审AI评判和专家人类审查，主要评估诊断一致性和治疗计划的一致性与安全性。结果显示，Doctronic在诊断和治疗计划方面表现强劲，甚至在某些情况下超越了执业临床医生。这一发现表明，多代理AI系统能够实现与人类提供者相当的临床决策，并可能解决医疗人力资源短缺的问题。", "conclusion": "在这一首次大型自主AI医生验证中，我们展示了其诊断和治疗计划与人类临床医生的一致性较强，AI的表现不仅与执业临床医生相当，而且在某些情况下超越了医生。这一发现表明，多代理AI系统在临床决策中实现了与人类似的效果，并为解决医疗人力资源短缺提供了潜在解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23336", "html_url": "https://arxiv.org/abs/2507.23336", "title": "DSBC: 通过背景工程进行数据科学任务基准测试", "title_en": "DSBC : Data Science task Benchmarking with Context engineering", "authors": "Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Giulio Martini,Suman Debnath,Hamza Farooq", "background": "大型语言模型（LLMs）的最新进展对数据科学工作流产生了重大影响，促成了专门设计的数据科学代理以自动化分析任务。尽管这些代理的采用速度很快，但系统性的基准评估仍然相对稀缺，以评估它们的有效性和限制。", "innovation": "本文引入了一个全面的基准测试，旨在反映现实世界中用户与数据科学代理的交互，通过观察我们商业应用的使用情况。基准测试评估了三种LLM（Claude-4.0-Sonnet、Gemini-2.5-Flash和OpenAI-o4-Mini）在三种方式下的表现：零样本推理、步骤推理（包括背景工程）和使用SmolAgent。基准测试涵盖了八个不同的数据科学任务类别，并探索了模型对常见提示问题（如数据泄漏和略微模糊的指令）的敏感性。此外，研究了温度参数对每个模型和方法的总体和特定任务结果的影响。", "conclusion": "本研究揭示了评估的模型和方法之间存在的性能差异，突出了影响实际部署的关键因素。基准数据集和评价框架旨在为未来更稳健有效的数据科学代理研究提供基础。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22898", "html_url": "https://arxiv.org/abs/2507.22898", "title": "临床评估中的语音引导智能（VOICE）系统：预医院卒中评估的语音AI代理系统", "title_en": "Voice-guided Orchestrated Intelligence for Clinical Evaluation (VOICE): A Voice AI Agent System for Prehospital Stroke Assessment", "authors": "Julian Acosta,Scott Adams,Julius Kernbach,Romain Hardy,Sung Eun Kim,Luyang Luo,Xiaoman Zhang,Shreya Johri,Mohammed Baharoon,Pranav Rajpurkar", "background": "当前急救人员识别卒中的一致性和准确性较低，敏感性仅为58%，导致治疗延迟。这种不足促使了对一种可以指导非专业人士完成专业水平的卒中评估系统的迫切需求，特别是在智能手机视频记录可以用于文档和专家审核的情况下。", "innovation": "该研究开发了一种语音驱动的人工智能系统，可以引导任何人通过自然对话进行专业的卒中评估，并通过智能手机记录关键的检查部件。该系统提高了卒中识别的准确性，并通过增加用户信心和减少诊断时间来改进急救过程。", "conclusion": "该AI系统在评估10个模拟卒中患者的84%的单一症状和75%的大血管闭塞（LVO）方面表现良好，评估完成时间不到7分钟。用户报告了高信心和易用性。然而，虽然系统在识别实际卒中有86%的准确率，但也有两例非卒中病例被错误地标记为卒中。专家审核时，AI报告的准确性达到了100%，但在40%的情况下，专家有足够的信心初步做出治疗决定。未来版本的AI系统有望提供更准确的评估，提高应急医疗服务的专业水平。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23348", "html_url": "https://arxiv.org/abs/2507.23348", "title": "SWE-Debate：软件问题解决的竞争多智能体辩论框架", "title_en": "SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution", "authors": "Han Li,Yuling Shi,Shaoxin Lin,Xiaodong Gu,Heng Lian,Xin Wang,Yantao Jia,Tao Huang,Qianxiang Wang", "background": "随着大型语言模型（LLMs）先进的推理能力，问题解决取得了显著进展。基于代理的框架，如SWE-agent，进一步推动了这一进程，通过使自动运行、使用工具的代理能够处理复杂的软件工程任务。现有的基于代理的问题解决方法主要依赖于代理的独立探索，但往往陷入局部解决方案，无法识别跨代码库的不同部分的故障模式。", "innovation": "为了克服上述局限性，本文提出了SWE-Debate，一种竞争性的多智能体辩论框架，旨在鼓励多样的推理路径并实现更为集中的问题定位。SWE-Debate在代码依赖图中创建多个故障传播跟踪，作为定位提案，然后组织三轮辩论，其中每个专业代理都沿故障传播路径体现独特的推理视角。这种结构化的竞争使代理能够协同缩小共识修复计划。最终，此共识修复计划被整合到基于MCTS的代码修改代理中以生成修复补丁。", "conclusion": "在SWE-bench基准测试上，SWE-Debate实现了开源代理框架的新最佳结果，并在与基线的竞争中取得了显著的性能提升。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22947", "html_url": "https://arxiv.org/abs/2507.22947", "title": "ELMES：教育场景下评估大型语言模型的自动化框架", "title_en": "ELMES: An Automated Framework for Evaluating Large Language Models in Educational Scenarios", "authors": "Shou'ang Wei,Xinyun Wang,Shuzhen Bi,Jian Chen,Ruijia Li,Bo Jiang,Xin Lin,Min Zhang,Yu Song,BingDong Li,Aimin Zhou,Hao Hao", "background": "大型语言模型（LLMs）为教育领域带来了变革性的机会，产生了许多新的应用场景。然而，仍存在显著的挑战：不同的教育场景有不同的评估指标，许多新兴场景缺乏合适的评估指标。当前的基准测试主要衡量一般智能，而不是教学能力。为解决这一差距，作者引入了ELMES，这是一种专为评估在教育场景中的LLMs而设计的开源自动化评估框架。ELMES具有模块化架构，能够通过简单的配置文件创建动态的多智能体对话，促进灵活的场景设计，无需广泛的编程知识。评估引擎采用LLM作为裁判的混合方法，客观地量化了传统的主观教学指标。通过与教育专家合作开发的细微度量，在四个关键的教育场景中对最先进的LLMs进行了系统基准测试：知识点解释、引导式问题解决教学、跨学科课件生成和情境化问题生成。结果表明，模型在各方面的能力分布不同，揭示了情境特定的优势和局限性。ELMES为教育者和研究者提供了可访问的评估框架，显著降低了不同教育应用的适应障碍，促进了LLMs在教学中的实际应用实施。该框架已公开发布。", "innovation": "ELMES是一个专为评估教育场景中LLMs而设计的开源自动化评估框架，采用模块化设计，简化了复杂的场景设计过程，引入了LLM作为裁判的混合评估方法，客观量化传统上主观的教学指标。在四个关键教育场景中系统地对最先进的LLMs进行了基准测试，显示出了模型在各方面能力的分布差异。ELMES提升了LLMs在教育领域实际应用的可能性，显著降低了适应不同教育应用的障碍。", "conclusion": "ELMES为教育场景中LLMs的评估提供了重要工具，不仅能揭示模型在不同教育场景中的优势和局限，还能显著降低实施教育应用的适应性门槛。框架已公开发布，供教育者和研究者使用。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22964", "html_url": "https://arxiv.org/abs/2507.22964", "title": "探索用于越南语性别无关自动语音识别的动态参数", "title_en": "Exploring Dynamic Parameters for Vietnamese Gender-Independent ASR", "authors": "Sotheara Leang(CADT, M-PSI),Éric Castelli(M-PSI),Dominique Vaufreydaz(M-PSI),Sethserey Sam(CADT)", "background": "语音信号的动态特征提供了时间信息，在增强自动语音识别（ASR）中扮演重要角色。传统的梅尔频率倒谱系数（MFCCs）方法在捕捉语音信号动态特性方面存在极限，并且在性别识别上不够准确。", "innovation": "本文通过在极坐标平面上比率平面下的谱子带中心频率（SSCFs）中使用极参数来刻画语音的动态特性，并结合MFCCs在越南语ASR中捕捉更详细的频谱信息。SSCF0被用作基频（F0）的伪特征，以稳健地描述声调信息。研究结果显示，提出的参数显著降低了词错误率，并且在性别独立性方面优于基础的MFCCs。", "conclusion": "提出的动态参数显著降低了词错误率，并且在性别独立性方面优于基础的MFCCs，在越南语ASR中表现更佳。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23361", "html_url": "https://arxiv.org/abs/2507.23361", "title": "SWE-Exp: 经验驱动的软件问题解决", "title_en": "SWE-Exp: Experience-Driven Software Issue Resolution", "authors": "Silin Chen,Shaoxin Lin,Xiaodong Gu,Yuling Shi,Heng Lian,Longfei Yun,Dong Chen,Weiguo Sun,Lin Cao,Qianxiang Wang", "background": "近期，大型语言模型（LLM）代理在软件问题解决方面取得了显著进展，通过多代理协作和蒙特卡洛树搜索（MCTS）等先进技术实现了这一目标。然而，当前的代理具有记忆缺失特性，即每次解决问题时都不会保留或重用之前的修复经验，导致重复探索失败路径，并错失适应成功问题解决方法的机会。", "innovation": "文章介绍了SWE-Exp，这是一种经验增强的方法，可以从之前代理的路径中提炼简洁且具有操作性的经验，支持跨问题持续学习。该方法引入了一个多层次的经验库，涵盖了从高层次问题理解到特定代码修改的重复可用的修复知识。实验结果显示，SWE-Exp在开源代理框架下的SWE-bench-Verified上实现了最先进的解决方案率（41.6% Pass@1）。这种方法确立了自动化软件工程代理系统地积累和利用修复经验的新范式，从根本上从试错探索转向基于经验的战略问题解决。", "conclusion": "本方法在持续学习和经验驱动的问题解决方面推动了自动化软件工程代理的发展，有效地减少了重复探索并提高了解决成功率。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23740", "html_url": "https://arxiv.org/abs/2507.23740", "title": "Rule2Text：知识图谱中逻辑规则的自然语言解释", "title_en": "Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs", "authors": "Nasim Shirvani-Mahdavi,Devin Wingfield,Amin Ghasemi,Chengkai Li", "background": "知识图谱（KGs）通常包含足够的信息来支持新事实的推理。识别逻辑规则不仅提高了知识图谱的完整性，还能够检测潜在错误、揭示微妙的数据模式，并增强整体推理和解释能力。然而，这些规则的复杂性及其独特的标签规范使得它们难以由人类理解。", "innovation": "本研究探索了大型语言模型生成逻辑规则自然语言解释的潜力。具体而言，使用AMIE 3.5.1规则发现算法从基准数据集FB15k-237和两个大规模数据集FB-CVT-REV和FB+CVT-REV中提取逻辑规则。研究了多种提示策略，包括零样本和少样本提示，变量实体类型，并采用链式推理。基于正确性、清晰度和虚构性，进行了全面的人类评估，并评估了大型语言模型作为自动仲裁者的使用。结果表明，在解释正确性和清晰度方面表现出有希望的性能，但仍存在一些未来研究的挑战。", "conclusion": "本研究结果表明，尽管大型语言模型在生成逻辑规则的解释方面的表现令人鼓舞，但在解释正确性和清晰度方面仍有待进一步改进。所有用于本研究的脚本和数据均可在指定网站上公开获取。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23292", "html_url": "https://arxiv.org/abs/2507.23292", "title": "SequenceLayers: 使序列处理和流式神经网络变得简单", "title_en": "SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy", "authors": "RJ Skerry-Ryan,Julian Salazar,Soroosh Mariooryad,David Kao,Daisy Stanton,Eric Battenberg,Matt Shannon,Ron J. Weiss,Robin Scheibler,Jonas Rothfuss,Tom Bagby", "background": "该研究旨在设计一种神经网络层API和库，用于序列建模，使得能够在分层执行（例如，教师强迫训练）和逐步执行（例如，自回归采样）之间轻松创建序列模型。为此，需要定义层的明确状态表示形式（例如，Transformer KV缓存、卷积缓冲区、RNN隐藏状态）以及一个步骤方法来演化该状态，测试该步骤方法能够与无状态逐层调用产生相同的结果。这和其他SequenceLayers合同的方面使得复杂的模型可以在不流中得到实时执行，降低丰富常见的在流处理和并行序列处理中出现的错误，并可以在任何深度学习库中实现。一个可组合和声明式的API，以及全面的层和组合器套件，简化了从简单可流式组件构建生产规模模型的过程，同时保持了强有力的正确性保证。目前的SequenceLayers实现（JAX、TensorFlow 2）可以在提供的链接找到。", "innovation": "该研究提出了一个SequenceLayers API和库，使得可以根据需要以分层方式（教师强迫训练）或逐步方式（自回归采样）创建序列模型。通过定义层的状态表示形式及其步骤方法，确保了分层和步骤方法的一致性，并使得复杂的模型能够立即实现流式执行。此外，该库简化了从简单组件构建生产规模模型的过程，减少了流处理和并行序列处理中的常见错误。", "conclusion": "当前的SequenceLayers实现已经集成到了JAX和TensorFlow 2中，通过一个这类库可以为序列建模提供简洁直观的API，使得研究人员和工程师能够在不同场景下灵活构建和优化模型。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23364", "html_url": "https://arxiv.org/abs/2507.23364", "title": "整体评价主题模型", "title_en": "Holistic Evaluations of Topic Models", "authors": "Thomas Compton", "background": "随着主题模型在商业和学术界的应用日益广泛，它们凭借对大量非结构化文本进行总结的能力引起广泛关注。作为无监督机器学习方法，主题模型帮助研究人员探索数据，帮助普通用户理解大型文本集合中的关键主题。然而，它们也可能成为一个‘黑盒’系统，用户输入数据后仅接受输出结果而不进行审查，可能导致准确性问题。本文从数据库视角评估主题模型，旨在通过1140次BERTopic模型运行的结果来识别模型参数优化中的权衡，并反思这些发现对主题模型解释和负责任使用的影响意义。", "innovation": "研究从数据库视角出发，利用1140次BERTopic模型运行的数据来评估主题模型，识别模型参数优化中的权衡，反思模型解释和负责任使用的意义。这种评估方法提供了新的视角来审视主题模型的有效性和应用局限性。", "conclusion": "研究发现，主题模型在总结大量文本方面具有巨大潜力，但同时也存在一定的局限性。优化模型参数可提高主题模型性能，但需要谨慎处理，并强调在使用这些模型时要具备解释能力。这一研究为理解主题模型的解释和负责任使用提供了重要见解。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23453", "html_url": "https://arxiv.org/abs/2507.23453", "title": "在基于LLM的评估系统中盲攻击检测的反事实评估", "title_en": "Counterfactual Evaluation for Blind Attack Detection in LLM-based Evaluation Systems", "authors": "Lijia Liu,Takumi Kondo,Kyohei Atarashi,Koh Takeuchi,Jiyi Li,Shigeru Saito,Hisashi Kashima", "background": "本文研究了针对基于LLM的评估系统的防范措施，特别是对抗指令注入攻击。这种攻击中，候选答案可能与真正的答案不相关，目的是欺骗评估者。", "innovation": "本文提出了一种框架，名为标准评估与反事实评估相结合（SE+CFE），该框架通过重新评估提交内容与故意错误的真实答案来增强安全性，以此来提高攻击检测能力。这种新方法能够在保持最小性能损失的情况下显著提高安全性。", "conclusion": "标准评估极易受到攻击，但结合反事实评估框架能显著提高评估系统的安全性，同时几乎不会影响其性能。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23511", "html_url": "https://arxiv.org/abs/2507.23511", "title": "MECAT: 一个多专家构建的细粒度音频理解任务基准", "title_en": "MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks", "authors": "Yadong Niu,Tianzi Wang,Heinrich Dinkel,Xingwei Sun,Jiahao Zhou,Gang Li,Jizhong Liu,Xunying Liu,Junbo Zhang,Jian Luan", "background": "尽管大型音频语言模型在开放式的音频理解方面取得了显著进展，但它们的精确性和细微到达了人类水平的理解仍有差距。当前的基准测试因数据标注和评估标准的限制，无法可靠地区分通用和详细的模型输出，这导致现有模型的精确度不足。因此，需要一个能够提供多角度、详细描述的基准测试，并且能够根据语义相似性和跨样本区分性进行评分的新指标，以评估和提高现有模型的能力。", "innovation": "本文提出了MECAT，一种基于多专家构建的细粒度音频理解任务基准。通过将专有模型分析与具有链式思考能力的大语言模型相结合的管道生成，MECAT 提供了多角度、详细的音频描述和开放性的问答对。此外，文中还提出了一个新的评估指标DATE，通过结合单样本语义相似性和跨样本区分性，评估并激励模型输出更详细的描述而非通用词汇。基准测试还提供了对最新一代音频模型的全面评估，揭示了它们目前的能力和限制。", "conclusion": "本文通过引入MECAT和新的评估指标DATE，为精准音频理解任务提供了一个多角度基准测试。对最新模型的全面评估提供了新的洞见，这些洞见有助于理解当前模型的表现和局限性。数据和相关代码已公开并可供下载。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23773", "html_url": "https://arxiv.org/abs/2507.23773", "title": "SimuRA：通过基于LLM的世界模型进行模拟推理的通用目标导向代理", "title_en": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model", "authors": "Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing", "background": "现有的AI代理是基于大型语言模型（LLMs）构建的，尽管它们具有巨大的潜力，但当前实践主要采用一个任务一个代理的方法。这种方法不仅缺乏扩展性和通用性，还受到自回归LLMs固有限制的影响。与之相比，人类作为通用代理，通过心理模拟其行为和计划的结果进行推理。为迈向更通用、更强大的AI代理，作者提出了SimuRA: 一个基于目标导向原则的通用代理推理架构。该模型通过引入基于世界模型的计划方法，解决了自回归推理的限制。", "innovation": "SimuRA通过结合世界模型和LLM，提供了一种新的基于模拟的推理方法，能够灵活规划多种环境下的任务。世界模型利用自然语言丰富的内容来建模各种环境，弥补了自回归模型的不足。实验结果表明，SimuRA在复杂网络浏览任务中的表现优于传统的自回归规划，成功提高了航班搜索的成功率，达到了32.2%。", "conclusion": "作者展望了基于LLMs的单个通用代理模型在各种环境中的超级智能可能性，并公开提供了SimuRA作为研究演示版本，供公众测试。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23751", "html_url": "https://arxiv.org/abs/2507.23751", "title": "CoT-Self-Instruct：为推理和非推理任务构建高质量合成提示", "title_en": "CoT-Self-Instruct: Building high-quality synthetic prompts for reasoning and non-reasoning tasks", "authors": "Ping Yu,Jack Lanchantin,Tianlu Wang,Weizhe Yuan,Olga Golovneva,Ilia Kulikov,Sainbayar Sukhbaatar,Jason Weston,Jing Xu", "background": "当前合成数据生成方法主要通过直接训练LLMs来生成合成数据，但这种方法可能无法很好地提升模型在推理任务上的表现。此外，现有的训练数据集，如s1k和OpenMathReasoning，在解决一些具体的数学难题时表现不佳。因此，如何提高合成数据的质量以适应不同的任务需求是一个亟待解决的问题。", "innovation": "提出了一种名为CoT-Self-Instruct的方法，该方法首先让LLMs基于给定的任务种子进行推理和规划，然后生成新的合成提示，这些提示的质量和复杂度与真实数据相当，最后通过自动指标过滤生成高质量的数据。这种方法在可验证的推理任务中超过了一些现有的训练数据集；在不可验证的指令遵循任务中优于人类或标准的自指示提示。", "conclusion": "CoT-Self-Instruct方法生成的合成数据在多个数学推理任务中表现出色，证明了其在提升LLM训练数据质量方面的能力，并提供了高性能的人工智能模型构建策略。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23726", "html_url": "https://arxiv.org/abs/2507.23726", "title": "Seed-Prover：自动定理证明中的深广推理", "title_en": "Seed-Prover: Deep and Broad Reasoning for Automated Theorem Proving", "authors": "Luoxin Chen,Jinming Gu,Liankai Huang,Wenhao Huang,Zhicheng Jiang,Allan Jie,Xiaoran Jin,Xing Jin,Chenggang Li,Kaijing Ma,Cheng Ren,Jiawei Shen,Wenlei Shi,Tong Sun,He Sun,Jiahui Wang,Siran Wang,Zhihong Wang,Chenrui Wei,Shufa Wei,Yonghui Wu,Yuchen Wu,Yihang Xia,Huajian Xin,Fan Yang,Huaiyuan Ying,Hongyi Yuan,Zheng Yuan,Tianyang Zhan,Chi Zhang,Yue Zhang,Ge Zhang,Tianyun Zhao,Jianqiu Zhao,Yichi Zhou,Thomas Hanwen Zhu", "background": "大型语言模型通过强化学习结合长推理链展示了强大的数学推理能力，但在定理证明方面仍然面临挑战，主要原因是仅使用自然语言时缺乏清晰的监督信号。为此，研究人员开发了专门的领域特定语言（如Lean），通过形式化验证证明提供清晰的监督信号，提高了通过强化学习的有效训练。本研究旨在进一步提升自动化数学推理能力。", "innovation": "本研究提出了一个名为Seed-Prover的 lemma样式的整体证明推理模型，通过Lean反馈、已证明的引理和自我总结迭代优化其证明过程。此外，还设计了三种推理策略以解决国际数学奥林匹克竞赛（IMO）级别的问题。同时，引入了一个几何推理引擎Seed-Geometry，能超越之前的正式几何引擎。最后，使用这些系统参加了IMO 2025，并完整证明了6个问题中的5个。这显著提升了自动化数学推理的能力，证明了冗长推理链结合形式验证的有效性。", "conclusion": "Seed-Prover在形式化IMO历史问题方面取得了78.1%的成功率，MiniF2F上达到饱和，普特南基准上达到了50%以上，并大幅超越了此前最先进的方法。通过引入适用于Lean的几何推理引擎Seed-Geometry，解决了Lean在几何支持上的不足。这两个系统使我们能够成功自动解决更加复杂的数学问题。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23674", "html_url": "https://arxiv.org/abs/2507.23674", "title": "TweakLLM: 动态调整缓存响应的路由架构", "title_en": "TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses", "authors": "Muhammad Taha Cheema,Abeer Aamir,Khawaja Gul Muhammad,Naveed Anwar Bhatti,Ihsan Ayyub Qazi,Zafar Ayyub Qazi", "background": "大型语言模型（LLMs）每天处理数以百万计的查询，因此使用缓存响应作为减少成本和延迟的有效优化变得非常重要。然而，由于聊天机器人的个性化特点和语义相似性搜索的局限性，这种策略难以维持对用户查询的相关性。", "innovation": "提出了一种名为TweakLLM的新型路由架构，该架构使用一个轻量级的LLM动态适应缓存响应，以适应传入的提示。通过全面评估，包括用户研究、旁对比测试、满意度投票以及多智能体LLM辩论，证明TweakLLM在确保响应质量的同时，显著提高了缓存的有效性。", "conclusion": "我们的研究结果在真实数据集上显示，TweakLLM是一种可扩展、消耗资源较少的缓存解决方案，适用于高负载的LLM部署，而不会牺牲用户体验。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.23607", "html_url": "https://arxiv.org/abs/2507.23607", "title": "基于深度学习的临床试验入组人数预测及其不确定性估计", "title_en": "Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates", "authors": "Tien Huu Do,Antoine Masquelier,Nae Eoun Lee,Jonathan Crowther", "background": "临床试验是评估新药或治疗方法的安全性和有效性的重要系统性工作。这一过程通常需要大量的财务投资和细致的规划，因此预测临床试验的结果变得尤为关键。在临床试验的设计阶段，准确预测患者入组情况是主要挑战之一。患者入组情况直接影响临床试验的成功率，因此开发出能够准确预测患者入组的模型具有重要意义。本研究提出了一种基于深度学习的方法来解决这一关键问题，该方法利用预训练语言模型从临床文档中捕捉复杂性和细微差别，并将其转换为表达性表示，然后通过注意机制与编码的表格特征相结合。通过引入基于Gamma分布的概率层来考虑入组预测的不确定性，估计预计范围。这种方法被应用于基于泊松-伽马过程预测临床试验的持续时间。实验表明，该方法能有效预测临床试验中各站点的患者入组人数，并优于已有的基准模型。", "innovation": "提出了一个基于深度学习的新颖方法来预测临床试验患者的入组情况。该方法利用预训练语言模型从临床文档中捕捉复杂性和细微差别，并将其转换为表达性表示，通过注意机制与编码的表格特征相结合。通过引入基于Gamma分布的概率层来考虑不确定性，并估计预计范围。这种方法能够有效预测临床试验中各站点的患者入组人数，超越了现有的基线模型。", "conclusion": "该研究提出了一种通过结合临床文档、表格特征和基于Gamma分布的概率层的深度学习模型来预测临床试验患者的入组情况。该方法在实际临床试验数据上进行了验证，并展示了其优越性，能够准确预测多个站点的患者入组情况，为临床试验的成功率提供了坚实的基础。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.12829", "html_url": "https://arxiv.org/abs/2404.12829", "title": "LiMe：晚期中世纪刑事判决的拉丁语语料库", "title_en": "LiMe: a Latin Corpus of Late Medieval Criminal Sentences", "authors": "Alessandra Bassani,Beatrice Del Bo,Alfio Ferrara,Marta Mangini,Sergio Picascia,Ambra Stefanello", "background": "计算语言学研究领域近年来对拉丁语给予了关注，并积累了丰富的资源，包括详细的标注语料库和复杂的语言分析工具。然而，由于数据量的差距，现有的拉丁文文本向量模型的性能仍落后于现代语言模型。为了解决这一问题，论文介绍了一个名为LiMe的数据集，该数据集收集自一系列名为《米兰权力箴言集》的中世纪手稿，经过专家全面标注，旨在用于掩蔽语言模型和监督自然语言处理任务。", "innovation": "LiMe数据集首次提供了一个包含325份文档的拉丁语语料库，这些文档特别记录了晚期中世纪的刑事判决，并由专家进行了细致的标注，这是在计算语言学领域中填补的一个数据空白，旨在提高拉丁文本的模型性能，特别是对于掩蔽语言模型和监督自然语言处理任务的性能改进。", "conclusion": "论文提出的LiMe数据集为计算语言学研究领域提供了高质量的标注数据，旨在促进拉丁文自然语言处理技术的发展。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.11167", "html_url": "https://arxiv.org/abs/2412.11167", "title": "文化调色板：通过多代理调色板实现文化多元化对齐", "title_en": "Cultural Palette: Pluralising Culture Alignment via Multi-agent Palette", "authors": "Jiahao Yuan,Zixiang Di,Shangzixin Zhao,Zhiqing Cui,Hanqing Wang,Guisong Yang,Usman Naseem", "background": "大型语言模型（LLMs）在生成方面表现出色，但由于内在的单文化偏见和难以捕捉细微的文化语义，它们很难与各种文化价值观保持一致。现有的方法在微调后适应未知文化时存在困难。", "innovation": "该论文提出了一种名为‘文化调色板’的多代理框架，该框架将文化对齐重新定义为一个适应性的“颜色混合”过程，用于国家特定的适应。该方法通过地理上的五个大洲（非洲、美洲、亚洲、欧洲、大洋洲）和三个关键步骤实现了跨文化的精细调整。", "conclusion": "广泛的实验表明，文化调色板在各种国家中都超过了现有基线，实现了更好的文化对齐效果。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.18154", "html_url": "https://arxiv.org/abs/2404.18154", "title": "说明模糊语言", "title_en": "Explaining vague language", "authors": "Paul Égré,Benjamin Spector", "background": "本文探讨了语言为何模糊的问题。Lipman曾提出使用博弈论来解释模糊性，并提出一个困境，即模糊性在均衡状态下不能比精确性更好。近期，Égré等人提出了一种贝叶斯视角来说明为何使用模糊词汇比使用精确词汇更具信息性。本文旨在比较这两种观点并阐述它们并非相互矛盾。", "innovation": "本文通过对比Lipman的博弈论视角与Égré等人的贝叶斯视角，指出需要采用一个包含语义层面的解释来更好地说明模糊性。", "conclusion": "对于模糊性，Lipman在其定义中仅依赖于信号策略的属性，且不考虑词汇表的假设条件，而Égré等人则涉及语义内容。我们认为，语义解释对于理解模糊性是必需的，且更为合适且能更详细地解释模糊性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.14313", "html_url": "https://arxiv.org/abs/2406.14313", "title": "使用弱验证器的迭代修复在具有不可回答性的知识图谱问答中的少量样本迁移", "title_en": "Iterative Repair with Weak Verifiers for Few-shot Transfer in KBQA with Unanswerability", "authors": "Riya Sawhney,Samrat Yadav,Indrajit Bhattacharya,Mausam", "background": "在实际应用中，KBQA（知识图谱问答）需要在有限的领域内标注训练数据量的情况下，处理无法回答的问题。现有的方法大多假设所有问题是不可回答的，并无法有效处理此类问题。该研究旨在解决在具有不可回答性问题的KBQA中的少量样本迁移问题，并通过引入新的数据集和提出解决方案来提高模型的性能评估和解决不可回答性问题的能力。", "innovation": "提出了一个新颖的少量样本迁移任务来处理具有不可回答问题的KBQA，并贡献了两个新的数据集用于性能评估。提出了一种名为FUn-FuSIC的新方法，该方法扩展了FuSIC KBQA模型以支持不可回答问题。通过迭代修复和使用来自强验证器和弱验证器的反馈以及改进的自一致性评估来更好地判断问题是否可回答，从而提高了模型对于不可回答问题的处理能力。实验结果表明，FUn-FuSIC在任务上的性能显著优于多种基于LLM和监督学习的最先进的模型，并且建立了可回答问题的少量样本迁移的新标准。", "conclusion": "研究通过提出FUn-FuSIC方法，显著改善了在带有不可回答问题的知识图谱问答中的少量样本迁移性能，并通过新的数据集进一步验证了方法的有效性，同时建立了新的性能标准。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.15444", "html_url": "https://arxiv.org/abs/2406.15444", "title": "穿透噪音：提升大语言模型在数学应用题上的表现", "title_en": "Cutting Through the Noise: Boosting LLM Performance on Math Word Problems", "authors": "Ujjwala Anantheswaran,Himanshu Gupta,Kevin Scaria,Shreyas Verma,Chitta Baral,Swaroop Mishra", "background": "大语言模型（LLMs）在解决数学应用题（MWPs）方面表现出色，但在处理包含无关信息的实际问题时存在困难。LLMs 容易受到数值噪音的误导，导致在对抗性应用题上的平均相对性能下降约26%。", "innovation": "该研究提出了一种提示框架，生成对抗性变体的数学应用题，通过添加无关变量。引入了包含对抗性和非对抗性应用题的新数据集 PROBLEMATHIC。此外，该论文还提出了对抗样本的微调方法，使得模型在对抗性应用题上的表现提高了约8%，从而增强了模型对噪音的鲁棒性和推理时提取相关数据的能力。", "conclusion": "对抗噪声的提示框架在 GSM-8K-Adv 上的应用表明，尽管经过对抗性样本微调，LLMs 在面对对抗性信息时的表现仍下降了6%，这表明该方法有助于提升模型的一般化能力。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.11952", "html_url": "https://arxiv.org/abs/2504.11952", "title": "Robust and Fine-Grained Detection of AI Generated Texts", "title_en": "Robust and Fine-Grained Detection of AI Generated Texts", "authors": "Ram Mohan Rao Kadiyala,Siddartha Pullakhandam,Kanwal Mehreen,Drishti Sharma,Siddhant Gupta,Jebish Purbey,Ashay Srivastava,Subhasya TippaReddy,Arvind Reddy Bobbili,Suraj Telugara Chandrashekhar,Modabbir Adeeb,Srinadh Vura,Suman Debnath,Hamza Farooq", "background": "现有的检测系统在识别AI生成的短文本时常常表现不佳，而且并不是所有文本完全由人类或语言模型撰写。因此，研究者更侧重于部分由人类和语言模型协作撰写的文本。理想的情况下，检测系统需要在面对日益先进的大型语言模型时也能表现出色。", "innovation": "本文提出了用于标记分类任务的一系列模型，并且这些模型是在包含大量人类-机器协作撰写的文本集上进行训练的。这些模型表现出了在未见过的领域、生成器、非母语作者以及对抗性输入文本中的良好表现。此外，还提出了一个包含超过240万条文本的新数据集，这些文本多由多种流行的私有语言模型协作撰写，覆盖23种语言。研究人员还对这些模型在不同文本领域和生成器的表现进行了分析，并比较了对抗性方法的效果差异、输入文本长度以及生成文本与原始人类撰写的文本的特性差异。", "conclusion": "研究揭示了模型在不同文本领域和生成器中的表现，并对对抗性方法的效果进行了对比，还评估了输入文本长度和生成文本与原始文本的特性差异，展示了其在实际应用中的潜力。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.15768", "html_url": "https://arxiv.org/abs/2503.15768", "title": "统一大小是否合适？：多文档摘要领域转移中的失败度量", "title_en": "Can one size fit all?: Measuring Failure in Multi-Document Summarization Domain Transfer", "authors": "Alexandra DeLucia,Mark Dredze", "background": "多文档摘要（MDS）的任务是从多份文档中自动总结信息，覆盖面广，从新闻文章到多讲话者对话。当前MDS模型的训练方法可以概括为四种：端到端预训练、“直接”，分块后总结，提取后总结，以及使用GPT风格模型的推理方法。本文通过评估不同训练方法、领域和维度（参考相似性、质量和事实性）下MDS模型的表现，研究模型在不同领域之间的零样本领域迁移中是如何失败的，特别是在新闻、科学和对话领域。研究定义了领域迁移“失败”为事实性下降、偏离目标程度增加和摘要质量总体下降。", "innovation": "本文首次系统地评估了不同训练方法、领域和维度下MDS模型的表现，探讨了模型在不同领域之间的零样本领域迁移中失败的原因和表现形式，并提出了使用现有流行总结评价指标的潜在问题。创新之处在于全面分析和量化了MDS模型在不同领域的迁移失败情况。", "conclusion": "本文的研究表明，MDS模型在不同领域之间的零样本领域迁移存在失败，特别是在事实性和质量方面。此外，研究还发现应用现有的流行总结评估指标可能需要谨慎，因为它们可能无法准确反映模型在不同领域的性能。未来的研究需要针对特定领域的MDS模型进行开发和评估，以克服这一挑战。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.18337", "html_url": "https://arxiv.org/abs/2411.18337", "title": "大型语言模型能辅助处理歧义吗？不同大型语言模型在词义消岐方面的定量评估", "title_en": "Can LLMs assist with Ambiguity? A Quantitative Evaluation of various Large Language Models on Word Sense Disambiguation", "authors": "T.G.D.K. Sumanathilaka,Nicholas Micallef,Julian Hough", "background": "现代数字通信中常常出现模糊词语，这给传统的词义消岐（WSD）方法带来了挑战，因为这些方法的数据有限。因此，翻译、信息检索和问答系统的效率受到了影响。本研究旨在通过结合系统提示增强机制和包含不同词义解释的知识库，利用大型语言模型（LLM）改善词义消岐的研究。研究使用FEWS测试数据和语义标签进行评估，验证了一种包含人工反馈循环的方法，该方法通过词性标注、模糊词语的同义词、面向方面的情感过滤和少量示例提示来引导LLM。", "innovation": "提出了一种结合系统提示增强机制和知识库的方法，利用少量示例Chain of Thought（COT）提示，通过知识库和人类反馈循环增强LLM的性能，提高了词义消岐的准确性，特别是在处理社交媒体和数字通信中的歧义方面取得了显著进步。", "conclusion": "研究通过FEWS测试数据和语义标签的评估，展示了使用LLM进行词义消岐的有效性和改进，特别是在准确解析社交媒体中的词语方面取得了显著成果。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.02744", "html_url": "https://arxiv.org/abs/2410.02744", "title": "中立残差：重访模型扩展中的适配器", "title_en": "Neutral Residues: Revisiting Adapters for Model Extension", "authors": "Franck Signe Talla,Edouard Grave,Hervé Jégou", "background": "自训练的大语言模型在新领域中的应用面临挑战。传统的技术手段如微调或低秩适配（LoRA）能够在一定程度上实现领域适配，但这些方法通常不会在模型中增加新的容量。这就产生了一个权衡，即在新领域表现良好与原有领域性能下降之间的取舍。因此，本文重新审视并改进了适配器方法，从数据、架构和训练过程三个方面来进行改进，这三种方法能够联合考虑并优化扩展大型语言模型到新领域的效果。", "innovation": "本文提出了中立残差方法，该方法通过修改适配器，使得每个新的残差块在原有领域输出接近零的值。这种方法在将一个原本在英语上进行训练的顶级模型扩展到新的语言时表现出色。中立残差在学习新语言和不遗忘原有知识之间提供了显著优于传统微调、LoRA或纯适配器方法的效果。", "conclusion": "中立残差为扩展大型语言模型到未见过的新领域提供了一种有效的方法。这种改进的方法在处理新语言方面表现优秀，并且能在不影响原有领域性能的情况下显著提高模型的学习能力。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.16060", "html_url": "https://arxiv.org/abs/2504.16060", "title": "Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation", "title_en": "Vision-Language Models Are Not Pragmatically Competent in Referring Expression Generation", "authors": "Ziqiao Ma,Jing Ding,Xuejun Zhang,Dezhi Luo,Jiahe Ding,Sihan Xu,Yuchen Huang,Run Peng,Joyce Chai", "background": "当前对视觉-语言模型(VLMs)的评估往往忽略了语用层面，仅将指示表达生成(Referring Expression Generation, REG)简化为基于区域的字幕任务，忽视了包括格赖斯合作原则在内的语用准则。REFOI数据集的引入旨在重新审视REG的语用维度，提供了一个包含1500张图片，每张图片都标注了书面和口头指示表达的新数据集。", "innovation": "提出了一个新的名为RefOI的数据集，包含1500张图片，并针对这些图片标注了书面和口头指示表达，系统评估了最先进的VLMs，识别出三大语用失误点：无法唯一确定指代对象、包含过量或不相关信息、未能与人类的语用偏好保持一致，特别是使用过多的空间线索。标准自动评估未能捕捉到这些语用错误，而是侧重于表面线索。研究表明，现有模型亟需更加语用导向的评估框架。", "conclusion": "现有的模型缺乏真正的参照成功，不能捕捉到言语表达中的复杂语用因素。研究强调了需要重新聚焦在语用指导的模型及其评价框架上，以使它们更加符合真实人类交流的特点。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.04640", "html_url": "https://arxiv.org/abs/2504.04640", "title": "Splits! 一种灵活的数据集和评估框架以进行社会文化语言学研究", "title_en": "Splits! A Flexible Dataset and Evaluation Framework for Sociocultural Linguistic Investigation", "authors": "Eylon Caplan,Tania Chakraborty,Dan Goldwasser", "background": "语言使用的变化，由讲者的社会文化背景和使用情境所塑造，提供了深入了解文化视角、价值观和意见的丰富视角。然而，对这些社会文化语言现象（SLP）的计算研究通常限于特定群体或主题的定制分析，阻碍了科学发现的进展。", "innovation": "本文介绍了一种名为Splits!的大数据分析集和评估框架。该数据集来自Reddit，包含9.7万个帖子，涉及超过53,000名用户，分为89个讨论主题，便于比较分析。该研究提出了一种框架，利用高效检索方法快速验证潜在的社会文化语言现象（PSLP），并通过巧妙的人工验证意外性衡量标准，将需要人工检查的统计显著发现减少了1.5-1.8倍，简化了有潜力现象的发现过程", "conclusion": "通过两阶段过程，Splits!大大提高了社会文化语言现象的发现效率，简化了进一步调查的进程。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.09753", "html_url": "https://arxiv.org/abs/2504.09753", "title": "在增强大型语言模型的多语言能力时结合文化与地方知识以提升本地表现", "title_en": "Improving Multilingual Capabilities with Cultural and Local Knowledge in Large Language Models While Enhancing Native Performance", "authors": "Ram Mohan Rao Kadiyala,Siddartha Pullakhandam,Siddhant Gupta,Drishti Sharma,Jebish Purbey,Kanwal Mehreen,Muhammad Arham,Suman Debnath,Hamza Farooq", "background": "大型语言模型（LLMs）已经展示了惊人的能力，但其发展主要集中在英语及其他高资源语言上，忽视了许多其他语言的需求。因此，现有模型往往对低资源和欠代表的语言支持不足。本研究旨在通过结合文化与地方知识来提升大型语言模型的多语言能力和本地表现，同时保持模型的紧凑性，不牺牲其在特定语言上的性能。", "innovation": "该研究提出了一个名为Mantra-14B的 Hindi-English 双语 LLM，表现出超过之前模型3%的平均改进，并且在性能上优于其两倍大小的模型。通过使用一个由485K样本组成的精心编撰的英文和印地语指导数据集来调优模型，包括Qwen-2.5-14B-Instruct和Phi-4等模型。实验结果表明，通过文化与当地知识的适度微调，可以在不显著增加计算开销的情况下提升多语言性能，同时保持对本土语言的优良表现。此外，该研究避免了资源密集型的技术如词汇扩展或架构修改，维持了模型的小规模。", "conclusion": "研究结果表明，适度结合文化与地方知识的数据微调可以显著提高多语言性能而不会增加显著的计算负担，且保持原有的本地语言性能。为此，研究团队已经公开释放了训练代码、数据集和模型，以促进对少有代表性和低资源语言的进一步研究。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.15299", "html_url": "https://arxiv.org/abs/2503.15299", "title": "Inside-Out: LLMs中的隐藏事实知识", "title_en": "Inside-Out: Hidden Factual Knowledge in LLMs", "authors": "Zorik Gekhman,Eyal Ben David,Hadas Orgad,Eran Ofek,Yonatan Belinkov,Idan Szpektor,Jonathan Herzig,Roi Reichart", "background": "尽管有一些研究暗示大型语言模型（LLMs）在其参数中包含了比输出中更多的事实知识，但还没有明确定义或证明这一现象。本文提出了一种评估LLMs参数中是否比输出表达包含更多事实知识的框架。", "innovation": "本文首次提出了知识的正式定义，并引入了外部知识和内部知识的概念，依赖于是通过模型的可观察概率还是中间计算来打分。这一理论框架还揭示了LLMs在生成能力上的根本限制，并提出了在闭卷问答中通过重复抽样答案来扩展测试时计算的实际限制。", "conclusion": "实验结果表明，（1）LLMs在内部编码的事实知识比外部输出中的多，平均差距为40%；（2）有些知识深藏不露，即使进行了大规模的重复抽样，模型也无法生成答案；（3）这表明，通过重复抽样答案以测试LLMs的闭卷问答场景中的性能改善仍然受到实际限制，因为一些答案几乎没有被抽样，即使抽样了，也保证排在首位。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.23628", "html_url": "https://arxiv.org/abs/2505.23628", "title": "AutoSchemaKG：从大规模文本语料中动态引出语义框架实现自主知识图谱构建", "title_en": "AutoSchemaKG: Autonomous Knowledge Graph Construction through Dynamic Schema Induction from Web-Scale Corpora", "authors": "Jiaxin Bai,Wei Fan,Qi Hu,Qing Zong,Chunyang Li,Hong Ting Tsang,Hongyu Luo,Yauwai Yim,Haoyu Huang,Xiao Zhou,Feng Qin,Tianshi Zheng,Xi Peng,Xin Yao,Huiwen Yang,Leijie Wu,Yi Ji,Gong Zhang,Renhai Chen,Yangqiu Song", "background": "当前知识图谱的构建通常依赖于预定义的模式，这限制了知识图谱的自动化程度和效率。本文研究背景在于如何通过利用大规模文本语料，实现无需人工预定义模式下的知识图谱自主构建。", "innovation": "本文提出了AutoSchemaKG框架，该框架能够自主构建知识图谱并生成全面的模式，避免了提前设定模式的需求。该系统利用大规模语言模型从文本中同时提取知识三元组并结合概念化组织实体和事件，模型化两者之间的关系，从而构建了一个包含900多万节点和59亿多边的ATLAS知识图谱。此方法在多跳问答任务中优于最先进的基线，在提升语言模型事实准确性方面也表现优异，尤其在不经意间，模型的模式生成实现了95%与人工构建模式的语义对齐。", "conclusion": "本文所提出的方法成功实现了大型知识图谱的自主构建，并通过动态诱导语义模式显著提升了语言模型的准确性，证明了大规模知识图谱的能力可以有效地补充参数知识模型。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.02851", "html_url": "https://arxiv.org/abs/2505.02851", "title": "利用LLMs为细分领域创建内容语料库", "title_en": "Leveraging LLMs to Create Content Corpora for Niche Domains", "authors": "Franklin Zhang,Sonya Zhang,Alon Halevy", "background": "从庞大的非结构化网络源构建特定领域的专有内容语料库，面临巨大的数据整理挑战。本文探讨了一种精简方法，通过高效地获取、过滤、结构化和清理网络数据，生成高质量的领域特定语料库。它展示了大型语言模型（LLMs）在大规模复杂数据整理中的应用，并提出了结合增强技术的结构化内容提取和语义去重的战略框架。该方法应用于行为教育领域，通过整合到30 Day Me（一种习惯养成应用）中进行验证。数据管道30DayGen从超过15,000个网页中提取并综合出3,531个独特的30天挑战。用户调查显示满意度评分为4.3分（满分为5分），91%的受访者表示愿意使用整理后的内容来实现其习惯培养目标。", "innovation": "本文提出了一个利用LLMs进行结构化内容提取和语义去重的战略框架。该战略框架基于L大型语言模型来处理大规模复杂数据整理，提高了数据整理的效率和质量。", "conclusion": "通过将该方法应用于行为教育领域，验证了其有效性和实用性。数据管道30DayGen成功从大量网页中提取并综合出了3,531个30天挑战，用户对此表示高度满意。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14874", "html_url": "https://arxiv.org/abs/2505.14874", "title": "包容性ASR：低资源语言的构音障碍语音识别研究", "title_en": "Towards Inclusive ASR: Investigating Voice Conversion for Dysarthric Speech Recognition in Low-Resource Languages", "authors": "Chin-Jou Li,Eunjung Yeo,Kwanghee Choi,Paula Andrea Pérez-Toro,Masao Someki,Rohan Kumar Das,Zhengjun Yue,Juan Rafael Orozco-Arroyave,Elmar Nöth,David R. Mortensen", "background": "由于数据稀缺性，特别是在非英语语言中，构音障碍者的自动语音识别（ASR）仍然具有挑战性。", "innovation": "我们通过在英语构音障碍者语音（UASpeech）上微调语音转换模型来编码说话者的特征和语调失真，然后将其应用于将健康非英语语音（FLEURS）转换为非英语构音障碍类似语音。然后使用生成的语音数据微调大规模多语言语音（MMS）模型，以改善构音障碍语音识别。", "conclusion": "对于PC-GITA（西班牙语）、EasyCall（意大利语）和SSNCE（泰米尔语）的评估表明，结合说话者和语调转换的语音转换显著优于现成的MMS性能以及传统的增强技术，如速度和节奏扰动。客观和主观分析进一步证实，生成的语音模拟了构音障碍特征。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00068", "html_url": "https://arxiv.org/abs/2506.00068", "title": "在巴基斯坦多种语言中的多语言LLM政治偏见框架", "title_en": "Framing Political Bias in Multilingual LLMs Across Pakistani Languages", "authors": "Afrozah Nadeem,Mark Dras,Usman Naseem", "background": "大型语言模型（LLMs）在公共话语中发挥着越来越重要的作用，然而大多数关于政治和经济偏见的评估主要集中在资源丰富且以西方为主的语言和文化背景下。这忽视了低资源、多语言地区如巴基斯坦的问题，语言身份与政治、宗教和区域意识形态紧密相连。本文对13种最先进的LLMs在包括乌尔都语、旁遮普语、信德语、普什图语和俾路支语在内的五种巴基斯坦语言中的政治偏见进行了系统评估。评估框架结合了文化适应的政治极性测试（PCT）和多层次框架分析，捕捉到意识形态立场（经济和社会轴）和语用框架（内容、语气、重点）。", "innovation": "本文首次对巴基斯坦五种主要语言中的LLMs进行了多语言政治偏见的系统评估，采用了一种结合文化适应政治极性测试与多层次框架分析的方法，为评估多语言背景下模型的政治偏见提供了新的视角和方法。此外，研究指出语言条件如何影响模型的意识形态调制，并发现了跨语言一致的模型特定偏见模式，强调了在全球NLP中需要基于文化的多语言偏见审计框架的重要性", "conclusion": "LLMs在政治偏见上表现出自由左倾的倾向，但在地区语言中则显示出更倾向于集权化的框架模式，这反映了语言条件对意识形态调制的影响。研究还发现在不同语言中均存在一致的模型特定偏见模式，这需要构建基于文化的多语言偏见审计框架来更准确地评估全球NLP中的偏见问题。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18497", "html_url": "https://arxiv.org/abs/2505.18497", "title": "机器的语用心智：大型语言模型中语用能力的浮现", "title_en": "The Pragmatic Mind of Machines: Tracing the Emergence of Pragmatic Competence in Large Language Models", "authors": "Kefan Yu,Qingcheng Zeng,Weihao Xuan,Wanxin Li,Jingyi Wu,Rob Voigt", "background": "当前的大语言模型已经在社会智能任务上展现出潜在能力，例如隐含意义解析和理论思维推理，这些任务都需要大量的语用理解。然而，这些模型是如何在训练过程中获得这种语用能力的机制仍不清楚。", "innovation": "本文提出了ALTPRAG数据集，该数据集基于交替的概念，用于评估不同训练阶段的语言模型在推断多重含义时的细微差别和解释选择的能力。通过对比推理直接测试模型的语用能力，并系统地评估22种语言模型在预训练、监督微调和偏好优化三个关键训练阶段的表现，以考察语用能力的发展。", "conclusion": "研究结果表明，即使是基础模型也显示出对语用线索的高度敏感性，这种敏感性随着模型规模和数据量的增加而提高。监督微调（SFT）和RLHF方法在认知语用情境中尤其有效。这些发现强调了语用能力作为语言模型训练的一个浮现和组合性质，并提供了新的视角以使模型与人类交际规范保持一致。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.12365", "html_url": "https://arxiv.org/abs/2506.12365", "title": "聚焦于推理、可适应性、效率和伦理学的大型语言模型进展", "title_en": "Advances in LLMs with Focus on Reasoning, Adaptability, Efficiency and Ethics", "authors": "Asifullah Khan,Muhammad Zaeem Khan,Saleha Jamshed,Sadia Ahmad,Aleesha Zainab,Kaynat Khatib,Faria Bibi,Abdul Rehman", "background": "本文综述了大型语言模型（LLMs）的关键发展，这些发展包括提高其推理能力、适应各种任务、提高计算效率以及做出伦理决策的能力。详细探讨了有效改善人类和机器交流的技术，如链式思维提示、指令调优和基于人类反馈的强化学习。还讨论了多模态学习和少样本或零样本技术的进步，这些进步增强了LLMs处理复杂任务的能力。文章还强调了效率方面，包括扩展策略、优化技术和具有影响力的Mixture-of-Experts（MoE）架构。", "innovation": "有效的技术包括链式思维提示、指令调优和基于人类反馈的强化学习。Mixture-of-Experts（MoE）架构通过将输入路由到专门的子网络来提高预测准确性，同时优化资源分配。此外，文章还探讨了LLMs在自主人工智能和自主决策系统中的作用，并分类了增强LLMs推理、效率和伦理对齐的新兴方法。文章还指出了解读性、跨模态集成和可持续性等未充分探索的领域。", "conclusion": "尽管取得了显著的进展，LLMs仍然面临着高计算成本、偏见和伦理风险等挑战。克服这些挑战需要集中在偏见缓解、透明决策和明确的伦理规范上。未来的研究重点应放在增强模型处理多个输入的能力上，从而使LLMs更加智能、安全和可靠。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.07106", "html_url": "https://arxiv.org/abs/2506.07106", "title": "Theorem-of-Thought: 一种用于语言模型中演绎、归纳和 abduction 推理的多代理框架", "title_en": "Theorem-of-Thought: A Multi-Agent Framework for Abductive, Deductive, and Inductive Reasoning in Language Models", "authors": "Samir Abdaljalil,Hasan Kurban,Khalid Qaraqe,Erchin Serpedin", "background": "大型语言模型在自然语言推理任务上表现出强大的性能，但其推理过程仍然脆弱且难以解读。虽然提示技术如 Chain-of-Thought（CoT）可以增强可靠性，通过激发中间推理步骤或聚合多个输出，但这些技术缺乏确保逻辑结构和评价内部一致性的方法。", "innovation": "我们引入了一种名为 Theorem-of-Thought（ToTh）的新框架，该框架将推理视为三个并行代理的合作过程，每个代理模拟一种不同的推理模式：演绎推理、归纳推理和 abduction 推理。每个代理产生的推理轨迹被结构化为形式化的推理图，并通过基于自然语言推理（NLI）的贝叶斯信念传播来评估一致性，为每个步骤分配置信度分数。最一致的图被选中得出最终答案。", "conclusion": "实验表明，ToTh 在多个 LLM 上在符号（WebOfLies）和数值（MultiArith）推理基准上比 CoT、Self-Consistency 和 CoT-Decoding 有更好的表现，同时产生可解释且逻辑严谨的推理链。我们的研究为构建更 robust 和认知启发式的 LLM 推理指明了一条有希望的方向。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.18199", "html_url": "https://arxiv.org/abs/2506.18199", "title": "在大型语言模型中减少针对阿拉伯人和穆斯林文化偏见的提示工程技术：一项系统性综述", "title_en": "Prompt Engineering Techniques for Mitigating Cultural Bias Against Arabs and Muslims in Large Language Models: A Systematic Review", "authors": "Bushra Asseri,Estabrag Abdelaziz,Areej Al-Wabil", "background": "大型语言模型在各个领域展示了惊人的能力，但这些模型中存在的文化偏见问题（尤其是针对阿拉伯人和穆斯林），通过持续传播负面影响刻板印象和边缘化，引发了严重的伦理挑战。尽管对语言模型偏见的认识逐渐增加，但专门针对阿拉伯人和穆斯林代表性的提示工程技术尚未得到充分研究。目前有8篇研究论文（2021-2024年）探讨了偏见缓解策略，这些策略采用的方法包括文化提示、情感自动匹配、自助偏见技术、结构化多步骤管道和参数优化连续提示。", "innovation": "该研究采用混合方法系统性综述了针对阿拉伯人和穆斯林的提示工程技术，使用了PRISMA指南和Kitchenham的系统性审查方法，分析了8篇2021-2024年间发表的研究论文，并揭示了五种主要的提示工程技术方法：文化提示、情感自动匹配、自助偏见技术、结构化多步骤管道和参数优化连续提示。这些技术在缓解文化偏见方面显示出不同的有效性，其中结构化多步骤管道效果最佳，但需要更高的技术技能。", "conclusion": "尽管提示工程技术的某些方法显示出缓解文化偏见潜力，但研究发现不同偏见类型对这一技术的响应程度不同。结构化多步骤管道在偏见缓解方面表现最佳，但需要更高的技术技能。文化提示技术执行较为便捷且有效。这些研究表明，提示工程技术是缓解文化偏见的可行方法，无需访问模型参数即可实现。研究还指出了该领域的研究空白，未来需要进一步开发适应文化的方法，创建阿拉伯人和穆斯林特定的评估资源，并将提示工程技术与互补的去偏见方法相结合，以应对更深层次的偏见和保持模型的实用性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.21875", "html_url": "https://arxiv.org/abs/2506.21875", "title": "WildSpeech-Bench：自然语音对话中音频LLM的基准测试", "title_en": "WildSpeech-Bench: Benchmarking Audio LLMs in Natural Speech Conversation", "authors": "Jian Zhang,Linhao Zhang,Bokai Lei,Chuhan Wu,Wei Jia,Xiao Zhou", "background": "近年来，如GPT-4o等多模态大型语言模型（LLMs）展示了强大的直接语音交互能力。然而，缺乏专门且全面的基准来评估端到端的语音LLM使得优化实际应用中的音频LLM用户体验困难重重。现有的评估方法通常将文本基准迁移到语音，忽略了语音的独特特征和挑战，如语调、近音词、口吃和用户期望的差异。", "innovation": "1. 使用真实世界对话数据，涵盖了口语场景的相关数据。\n2. 引入多样化的说话者属性和声学条件。\n3. 增加了与语音特有的现象相关的数据。\n4. 设计了一种基于查询的评估方法，通过定制的评估检查表和提示提高了自动评估的准确性。", "conclusion": "我们全面测试并详细分析了多种主流的语音模型，在不同的口语场景下揭示了模型性能的显著差异。基于查询的评估进一步使得在各种语音特定场景下进行细粒度评估成为可能。我们的基准测试为语音模型的开发和评估提供了宝贵的见解。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08184", "html_url": "https://arxiv.org/abs/2506.08184", "title": "遗忘不了：前向干扰揭示LLMs中的工作记忆限制超越了上下文长度", "title_en": "Unable to Forget: Proactive Interference Reveals Working Memory Limits in LLMs Beyond Context Length", "authors": "Chupei Wang(University of Virginia),Jiaqiu Vince Sun(New York University)", "background": "在大规模语言模型（LLMs）中，信息检索越来越被认为是与生成能力紧密相连，而不是简单的查找。尽管更长的上下文通常被认为会改善检索效果，但上下文内部干扰的影响仍然尚未得到深入研究。为此，研究者们借鉴了认知科学中的前向干扰（PI）范式，即早期信息会干扰对较新信息的回忆。在人类中，对抗前向干扰的易感性与工作记忆容量呈负相关。研究发现通过逐步传递语义相关的关键值更新并且仅查询最终值，LLMs的检索准确度会随着干扰的累积呈对数线性下降，错误来源于检索已覆盖信息。尽管通过提示工程（例如指示模型忽略早期输入）来减轻干扰效果有限，这些发现揭示了LLMs在摆脱干扰和灵活处理信息方面存在的根本限制，表明了一种超越单纯上下文访问的处理记忆瓶颈。这要求采取方法来加强模型在检索过程中抑制无关内容的能力。", "innovation": "引入了PI-LLM评估方法，通过逐步传递语义相关的关键值更新和仅查询最终值来研究干扰累积对LLMs检索准确性的影响，发现LLMs在处理记忆方面存在瓶颈，而不仅仅是上下文长度的限制。提示工程在减轻干扰方面效果有限，这表明需要新的方法加强模型在检索过程中抑制无关内容的能力。", "conclusion": "LLMs在处理干扰和灵活信息处理方面存在根本限制，这种限制可能反映了工作记忆瓶颈，而不仅是上下文访问问题。为了改进LLMs的性能，需要开发新的方法来增强模型处理干扰内容的能力。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.06448", "html_url": "https://arxiv.org/abs/2507.06448", "title": "视觉感知导向的策略优化方法用于多模态推理", "title_en": "Perception-Aware Policy Optimization for Multimodal Reasoning", "authors": "Zhenhailong Wang,Xuehang Guo,Sofia Stoica,Haiyang Xu,Hongru Wang,Hyeonjeong Ha,Xiusi Chen,Yangyi Chen,Ming Yan,Fei Huang,Heng Ji", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 已经证明是为大规模语言模型（LLMs）提供稳健的多步推理能力的有效策略，但其设计和优化主要针对纯文本领域，在应用于多模态推理任务时表现不佳。特别是在多模态推理中，当前的主要错误来源是视觉输入的感知。", "innovation": "提出了PAPO（感知导向的策略优化），这是一种新的策略梯度算法，鼓励模型在学习推理的同时学习感知。特别地，引入了隐式感知损失，通过KL散度项形式无缝集成到主流的RLVR算法（如GRPO和DAPO）中。此外，引入了双重熵损失，有效正则化新的KL目标，同时不牺牲性能。尽管结构相对简单，PAPO在多样化的多模态基准测试中总体上提升了4.4%-17.5%，在高视觉依赖性任务中提升更为显著，高达8.0%-19.1%。这一改进还减少了30.5%的感知错误，表明PAPO增强了感知能力。", "conclusion": "整体来说，我们的工作将感知导向的监督更深入地整合到核心学习目标中，为一种新的RL框架铺平了道路，该框架激励基于视觉的推理。代码和数据将用于研究目的而公开发布，项目页面见此处：this https URL."}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.08606", "html_url": "https://arxiv.org/abs/2507.08606", "title": "DocPolarBERT: 带有相对极坐标编码布局结构的预训练文档理解模型", "title_en": "DocPolarBERT: A Pre-trained Model for Document Understanding with Relative Polar Coordinate Encoding of Layout Structures", "authors": "Benno Uthayasooriyar,Antoine Ly,Franck Vermet,Caio Corro", "background": "当前文档理解领域主要依赖于具有绝对2D位置嵌入的模型，为了提高模型的效率和有效性，研究者们致力于减少对大量预训练数据的依赖，探索能够高效处理文档布局结构的新机制。", "innovation": "介绍了一个带有布局感知机制的DocPolarBERT模型，它通过相对极坐标系统而非传统的笛卡尔坐标系统来扩展自注意力机制，从而消除了对绝对2D位置嵌入的依赖。即使在预训练数据量比广泛使用的IIT-CDIP数据集少六倍的情况下，DocPolarBERT仍取得了最优结果，展示了精心设计的注意力机制能够补偿数据量减少带来的影响。", "conclusion": "这些结果表明，精准设计的注意力机制可以弥补减少的预训练数据量，为文档理解提供了一种高效和有效的替代方案。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.07695", "html_url": "https://arxiv.org/abs/2507.07695", "title": "KeyKnowledgeRAG (K^2RAG): 一种改进的RAG方法以提高大型语言模型的问答能力", "title_en": "KeyKnowledgeRAG (K^2RAG): An Enhanced RAG method for improved LLM question-answering capabilities", "authors": "Hruday Markondapatnaikuni,Basem Suleiman,Abdelkarim Erradi,Shijing Chen", "background": "大型语言模型（LLMs）的微调是一个资源密集型过程，尤其是当他们需要包含更多的知识体时。尽管已经开发了许多微调技术来减少时间和计算成本，但随着LLMs的不断增长和复杂性增加，这一挑战依然存在。因此，需要一种新的方法来扩展LLMs的知识。检索增强生成（RAG）提供了一个替代方案，通过在数据库中存储外部知识并检索相关的片段来支持问答。然而，RAG的朴素实现面临着可扩展性和答案准确性的显著限制。", "innovation": "为了克服这些限制，这篇论文提出了KeyKnowledgeRAG（K2RAG）这一创新框架。K2RAG借鉴了分而治之的思路，结合了密集和稀疏向量搜索、知识图和文本摘要，以提高检索质量和系统效率。论文还介绍了一种处理步骤，对训练数据进行摘要，显著减少了训练时间。K2RAG在MultiHopRAG数据集上进行了评估，显示出相对于普通RAG实现的显著改进，最高均值答案相似度得分为0.57，最高第三四分位数相似度得分为0.82，表明其与真实答案的对齐程度更好。此外，该框架在准确性和效率方面也表现出色，总结步骤将个体组件的平均训练时间减少了93%，执行速度比传统的基于知识图的RAG系统快达40%。K2RAG还展示了卓越的扩展性，所需VRAM比研究中测试的一些朴素RAG实现少三分之一。", "conclusion": "K2RAG框架通过集成密集和稀疏向量搜索、知识图和文本摘要，以及引入数据预处理步骤，显著提高了检索质量和系统效率，从而在问答任务中的表现优于常见朴素的RAG实现。K2RAG降低了训练时间，并提高了执行速度，同时保持了卓越的扩展性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.17186", "html_url": "https://arxiv.org/abs/2507.17186", "title": "基于金融领域的FinGAIA：一个中文基准", "title_en": "FinGAIA: A Chinese Benchmark for AI Agents in Real-World Financial Domain", "authors": "Lingfeng Zeng,Fangqi Lou,Zixuan Wang,Jiajie Xu,Jinyi Niu,Mengping Li,Yifan Dong,Qi Qi,Wei Zhang,Ziwei Yang,Jun Han,Ruilun Feng,Ruiqi Hu,Lejie Zhang,Zhengbo Feng,Yicheng Ren,Xin Guo,Zhaowei Liu,Dongpo Cheng,Weige Cai,Liwen Zhang", "background": "人工智能代理的快速发展为自动化复杂任务提供了前所未有的机会，但在金融领域中的多步骤、多工具协作能力仍然未被充分探索。本文介绍了FinGAIA，一个端到端的基准测试，旨在评估AI代理在金融领域的实用性。该基准测试包含407个精制的任务，涵盖七个主要金融细分领域：证券、基金、银行业、保险、期货、信托和资产管理。任务按照业务分析、资产决策支持和战略风险管理三个层次进行分类。", "innovation": "本文提出了FinGAIA，这是第一个密切关联金融领域的代理评估基准，能够客观评估和促进该关键领域的代理发展。通过零样本设置评估了10个主流的AI代理，ChatGPT的表现最佳，整体精度为48.9%，但仍低于金融专家35个百分点。错误分析揭示了五大重复失败模式：跨模态对齐不足、金融术语偏见、运营过程意识障碍等。这些模式指出了未来研究的重要方向。", "conclusion": "我们的工作提供了第一个紧密关联金融领域的代理基准，旨在客观评估和促进代理在这一关键领域的开发。部分数据可在以下链接获取：这个 https URL。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.19792", "html_url": "https://arxiv.org/abs/2412.19792", "title": "InfAlign：基于推理的生成语言模型对齐", "title_en": "InfAlign: Inference-aware language model alignment", "authors": "Ananth Balashankar,Ziteng Sun,Jonathan Berant,Jacob Eisenstein,Michael Collins,Adrian Hutter,Jong Lee,Chirag Nagpal,Flavien Prost,Aradhana Sinha,Ananda Theertha Suresh,Ahmad Beirami", "background": "生成语言模型的对齐是现代生成语言模型训练中的关键步骤。对齐的目标是提高对齐模型的样本相对于基础模型的胜率。随着我们越来越多地使用推理时算法（如Best-of-N、受控解码、树搜索）从语言模型解码，而不是标准采样，标准的RLHF框架在面对这些推理时间方法时可能会变得不那么最优。", "innovation": "本文提出了一种基于推理的对齐框架（InfAlign），旨在优化对齐策略在推理阶段相对于基础模型的胜率。证明了对于任何推理时间解码过程，最优对齐策略是标准RLHF问题的解，带有奖励的变换。基于此提出了calibrate-and-transform RL（InfAlign-CTRL）算法，包括奖励校准步骤和带有校准后奖励的KL正则化奖励最大化步骤。针对Best-of-N采样和Jailbreaking提出了具体变换，分别提高了3%-8%的推理时间胜率。证明了提出的奖励校准方法是优化标准胜率的一个强大baseline。", "conclusion": "本文通过提出InfAlign框架和InfAlign-CTRL算法，不仅提高了推理时间的胜率，还为优化标准胜率提供了一个较强的基础方法。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16725", "html_url": "https://arxiv.org/abs/2507.16725", "title": "RAvine: 实景对齐评估方法用于代理型搜索", "title_en": "RAVine: Reality-Aligned Evaluation for Agentic Search", "authors": "Yilong Xu,Xiang Long,Zhi Zheng,Jinhua Gao", "background": "代理型搜索作为一种更自主和适应性的检索增强范式，正在推动智能搜索系统的发展。然而，现有的评估框架与代理型搜索的目标并不完全匹配。首先，当前基准中常用的复杂查询往往与现实的用户搜索场景不符。其次，先前的方法在提取用于端到端评估的真实情况时往往会引入噪音，导致细粒度评估失准。最后，大多数现有框架仅关注最终答案的质量，忽视了代理型搜索中固有的迭代过程的评估。", "innovation": "我们提出了一个针对代理型LLM和搜索的Reality-Aligned eValuation框架（RAvine）。RAvine侧重于多点查询和长格式答案，更好地反映了用户意图，并采用可追溯的地面真值构建策略来提高细粒度评估的准确性。此外，RAvine在整个迭代过程中评估模型与搜索工具的交互，并考虑到效率因素。", "conclusion": "我们使用RAvine对一系列模型进行了基准测试，并得出了一些见解，我们希望这将促进代理型搜索系统的进一步发展。相关代码和数据集可在此网页下载：this https URL."}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2401.13481", "html_url": "https://arxiv.org/abs/2401.13481", "title": "AI创意如何影响人类创意、多样性和进化：一项大型动态实验的证据", "title_en": "How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment", "authors": "Joshua Ashkinaze,Julia Mendelsohn,Li Qiwei,Ceren Budak,Eric Gilbert", "background": "随着大型语言模型生成的内容日益增多，人们开始关注AI生成的创意是否会对其自身的创意产生影响。为此，研究人员进行了一个涉及800多名参与者、覆盖40多个国家的实验证明AI生成的创意对人类创意的影响。", "innovation": "本研究创新地采用了动态实验设计，即实验中的想法被后续参与者用作刺激材料，从而展示了文化创造的互动过程：创意是由先前的想法构建而成的。研究发现，尽管高AI暴露度并未影响个体创意的创造力，但提高了集体想法多样性和变化率。", "conclusion": "AI的引入可能会增加集体多样性，但不会提升个体的创意。自我报告的创意者较少受到知道自己所想的想法来自AI的影响，且在任务难度较大时，参与者更愿意采纳AI的想法。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.11832", "html_url": "https://arxiv.org/abs/2507.11832", "title": "ILID: Native Script Language Identification for Indian Languages", "title_en": "ILID: Native Script Language Identification for Indian Languages", "authors": "Yash Ingle,Pruthwik Mishra", "background": "语言识别任务是自然语言处理（NLP）中的关键基础步骤。它通常作为多语言机器翻译、信息检索、问答和文本摘要等广泛使用的NLP应用之前的预处理步骤。语言识别的核心挑战在于在嘈杂的、短的和代码混合的环境中区分语言。对于具有词汇和音素相似性但又有显著差异的印度语言，这一挑战更为艰难。许多印度语言使用相同的字体，使任务更加困难。", "innovation": "研究开发并发布了一包含25万个句子的数据集，该数据集包括23种语言，其中22种是印度的官方语言，加上英语，并且为每种语言提供了语言标识符。数据集中的大多数语言数据都是新创建的。此外，研究还开发并发布了使用机器学习的最新方法以及微调预训练变换器模型的基线模型。实验结果显示，研究模型在语言识别任务上的表现优于现有的预训练变换器模型。数据集和代码可以在此链接中找到：this https URL并在Huggingface开源库中也可获取。", "conclusion": "研究通过创建包含大量印度语言句子的数据集，并使用最新的机器学习方法和预训练变换器模型进行了微调，解决了在噪声、短文本和代码混合环境中的语言识别挑战，尤其是对于具有相似词汇和音素但有显著差异的印度语言。研究模型在该任务上表现优于现有技术。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22581", "html_url": "https://arxiv.org/abs/2507.22581", "title": "揭开放大语言特定神经元的影响", "title_en": "Unveiling the Influence of Amplifying Language-Specific Neurons", "authors": "Inaya Rahmanisa,Lyzander Marciano Andrylie,Mahardika Krisna Ihsani,Alfan Farizki Wicaksono,Haryo Akbarianto Wibowo,Alham Fikri Aji", "background": "研究表明，与个体语言强相关的LLMs中的语言特定神经元会通过停用这些神经元来影响模型行为。然而，这些神经元在放大效应方面的作用仍然没有被充分探索。这项工作通过在18种语言上进行干预，包括低资源语言，并使用三种主要在不同语言上训练的模型，来进一步调查放大语言特定神经元的影响。研究人员通过提出的一种语言导向转变评分（LSS）来比较放大因子的效果，并在常识推理（XCOPA, XWinograd）、知识（Include）和翻译（FLORES）等下游任务上进行评估。", "innovation": "本研究首次在多语言环境中通过放大特定语言的神经元来影响模型的行为，并通过实证评估了放大因子在多种下游任务上的效果，特别是在低资源语言上的潜在益处和跨语言迁移方面的局限性。", "conclusion": "最佳放大因子能够有效地引导输出接近所有测试的语言。但是，在下游任务中使用这个因子进行干预有时会提高目标语言的表现，但在大多数情况下会降低跨语言的表现。这一发现突出了多语言行为中语言特定神经元的作用，其中放大对于低资源语言可能特别有利，但在跨语言迁移方面提供的优势有限。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.21568", "html_url": "https://arxiv.org/abs/2507.21568", "title": "低资源语言多语神经翻译模型的多假设蒸馏", "title_en": "Multi-Hypothesis Distillation of Multilingual Neural Translation Models for Low-Resource Languages", "authors": "Aarón Galiano-Jiménez,Juan Antonio Pérez-Ortiz,Felipe Sánchez-Martínez,Víctor M. Sánchez-Cartagena", "background": "本文探讨了多语言预训练编码器-解码器翻译模型的序列级知识蒸馏(KD)。研究指出，与通过 beam search（标准解码方法）获得的近似模式相比，教师模型的输出分布包含对学生的宝贵见解。同时，文中研究了针对低资源语言在知识蒸馏时出现的低变异性及少见词表示不足问题，提出了 Multi-Hypothesis Distillation (MHD) 方法。", "innovation": "作者提出了 Multi-Hypothesis Distillation (MHD) 方法，该方法通过 beam search 的 $n$-best 列表指导学生模型的学习，并探索了替代解码方法，如解决低变异性及少见词表示不足的问题。对于低资源语言，虽然采样方法可能在翻译质量上略逊于基于 beam search 的方法，但它们能够生成更有变异性且词汇丰富的语料库，从而改善学生模型的表现，并减轻知识蒸馏时常见的性别偏见放大问题。", "conclusion": "研究表明，对于低资源语言，尽管采样方法在翻译质量上可能稍逊一筹，但它们可以通过增加变异性与词汇丰富度来提高学生模型的性能，并减少知识蒸馏造成的性别偏见放大问题。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.14534", "html_url": "https://arxiv.org/abs/2507.14534", "title": "Conan: 一种分块在线的零样本自适应语音转换网络", "title_en": "Conan: A Chunkwise Online Network for Zero-Shot Adaptive Voice Conversion", "authors": "Yu Zhang,Baotong Tian,Zhiyao Duan", "background": "零样本在线语音转换（VC）在实时通信和娱乐领域具有显著的潜力。然而，当前的VC模型在实时转换中难以保持语义一致性、输出自然流畅的声音，并有效适应未见过的说话人特征。", "innovation": "本文介绍了一种名为Conan的分块在线零样本语音转换模型，该模型能够保存源语音的内容，并匹配参考语音的音质和风格。Conan包括三个核心组件：1）一种流式内容提取器，利用Emformer进行低延迟的流式内容编码；2）一种自适应风格编码器，从参考语音中提取细微的风格特征，以增强风格适应性；3）一种因果乱序嗓音合成器，采用了像素乱序机制的全因式HiFiGAN。", "conclusion": "实验评估表明，Conan在主观和客观指标上均优于基线模型。音频样本可在此处找到：this https URL."}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.18666", "html_url": "https://arxiv.org/abs/2503.18666", "title": "AgentSpec：构建安全可靠LLM代理的可定制化运行时防护", "title_en": "AgentSpec: Customizable Runtime Enforcement for Safe and Reliable LLM Agents", "authors": "Haoyu Wang,Christopher M. Poskitt,Jun Sun", "background": "基于大语言模型（LLM）的代理正在跨多种领域部署，实现复杂的决策和任务执行。然而，它们的自主性引入了安全性风险，包括安全漏洞、法律违犯和意外的有害行为。现有的缓解方法，如基于模型的安全保障和早期执行策略，在鲁棒性、可解释性和适应性方面存在不足。", "innovation": "我们提出了AgentSpec，这是一种轻量级的领域特定语言，用于指定和执行LLM代理的运行时约束。AgentSpec允许用户通过结合触发器、谓词和实施机制来定义结构化规则，以确保代理在预定义的安全边界内操作。我们还在代码执行、具身代理和自动驾驶等多个领域中实现了AgentSpec，展示了其适应性和效果。评估结果表明，AgentSpec在超过90%的代码代理案例中成功防止了不安全的执行，在具身代理任务中消除了所有危险行为，并使100%的自动驾驶车辆遵守合规要求。AgentSpec在计算上是轻量级的，附加开销仅毫秒级。", "conclusion": "借助可解释性、模块化和效率的结合，AgentSpec为跨多种应用广泛实施LLM代理的安全提供了一种实用且可扩展的解决方案。我们还使用LLMs自动化了规则的生成并评估了其有效性。OpenAI的规则生成在具身代理领域的精确度为95.56%，召回率为70.96%，成功识别了87.26%的高风险代码，并在8种场景中有5种情况下防止了自动驾驶车辆违法。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.15621", "html_url": "https://arxiv.org/abs/2503.15621", "title": "LLaVA-MORE：一种用于增强视觉指令调优的LLM和视觉骨干的比较研究", "title_en": "LLaVA-MORE: A Comparative Study of LLMs and Visual Backbones for Enhanced Visual Instruction Tuning", "authors": "Federico Cocchi,Nicholas Moratelli,Davide Caffagni,Sara Sarto,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara", "background": "近期，多模态大语言模型（MLLMs）的研究显示，视觉骨干和基础语言模型都发挥着关键作用。尽管前人的工作主要集中在这些组件的参数数量上，但模型规模、架构与性能之间的权衡尚未得到充分探索。此外，训练数据的一致性问题和评估标准的不一致使得难以做出直接比较，从而难以确定最佳设计选择。", "innovation": "本文介绍了LLaVA-MORE，一种将多种视觉骨干与最新语言模型结合的新家族MLLMs。为了确保公平比较，我们采用了一致的统一训练协议。我们的分析系统地探讨了从小规模到中规模的LLMs，包括Phi-4、LLaMA-3.1和Gemma-2，以评估多模态推理、生成和指令遵循能力，并考察模型规模与性能之间的关系。此外，我们还对CLIP以及其他视觉编码器如DINOv2、SigLIP和SigLIP2进行了全面研究，还进行了图像分辨率和预训练数据集变化的实验。这些研究提供了有关更有效设计MLLMs的见解，并提供了一个可重复的评估框架，有助于直接比较和未来模型开发。", "conclusion": "本文的研究结果为更有效的MLLMs设计提供了见解，提供了一个可重复的评估框架，促进直接比较，指导未来的模型开发。我们的源代码和训练模型可以在以下网址获得：this https URL。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.14928", "html_url": "https://arxiv.org/abs/2504.14928", "title": "EducationQ: 通过多代理对话框架评估LLMs的教学能力", "title_en": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework", "authors": "Yao Shi,Rongkeng Liang,Yong Xu", "background": "大型语言模型（LLMs）越来越多地作为教育工具使用，但对其教学能力的评估依然具有挑战性，因为教师与学生互动的过程资源密集、具上下文依赖性且从方法学上来看复杂。因此，一直难以有效评估LLMs在教学情景中的能力。", "innovation": "我们提出了EducationQ，这是一种多代理对话框架，能够通过模拟动态教育场景来高效评估教学能力，并在其中加入专门的教学、学习和评估代理。此外，研究发现，模型教学效果与其规模或一般推理能力并不成线性关系，某些开源小规模模型在教学场景中表现优于大规模商业模型，这揭示了当前评估重点偏向记忆而忽视互动教学方法存在的缺陷。混合方法评估结合定量指标与定性分析及专家案例研究，指出了表现优异模型的独特教学策略。人工专家评估显示与我们对有效教学行为的自动化定性分析有78%的一致性，验证了我们的方法。", "conclusion": "EducationQ 表明，作为教师的LLMs需要超出简单扩展的专门优化，这提示下一代教育人工智能应着重提升特定教学效果的针对性增强。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.05903", "html_url": "https://arxiv.org/abs/2507.05903", "title": "AI-Reporter: 通往新型科学通讯的新路径", "title_en": "AI-Reporter: A Path to a New Genre of Scientific Communication", "authors": "Gerd Graßhoff", "background": "本文探讨了AI-记者代表了一种科学研究实践中的范式转变。文章通过一个实际案例研究展示了系统如何将学术报告转化为出版就绪的章节，表明了技术革新在连接短暂的演讲和永久的科学记录之间的桥梁作用。示例为NEPI工作坊（“科学、哲学和 sociology of Science”中的“大型语言模型”讲座），详细的说明了该系统如何通过技术革新将临时的口头报告转化为永久的科学记录。", "innovation": "文章中的创新在于利用人工智能技术将学术报告快速转化为出版就绪的章节，大大缩短了从口头报告到书面记录的时间，显示了技术革新在科学通讯中的作用。该系统能在三分钟内完成这一过程，为科学研究通讯开辟了一条新的路径。", "conclusion": "此系统展示了AI技术在科学出版实践中的应用，证明了这种技术可以有效缩短科研成果转化为出版物的周期，使得更加及时和长久的科学记录成为可能。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.19060", "html_url": "https://arxiv.org/abs/2507.19060", "title": "PurpCode：生成更安全代码的推理", "title_en": "PurpCode: Reasoning for Safer Code Generation", "authors": "Jiawei Liu,Nirav Diwan,Zhe Wang,Haoyu Zhai,Xiaona Zhou,Kiet A. Nguyen,Tianjiao Yu,Muntasir Wahed,Yinlin Deng,Hadjer Benkraouda,Yuxiang Wei,Lingming Zhang,Ismini Lourentzou,Gang Wang", "background": "随着代码推理模型的应用日益广泛，确保生成的代码安全、防御恶意网络活动成为了亟待解决的问题。现有的安全代码推理模型存在一定的不足，需要一种新的方法来训练能够生成安全代码并抵御恶意网络行为的模型。", "innovation": "PurpCode是首个用于安全代码推理模型的后训练方法，通过两个阶段训练：规则学习阶段，使模型明确学习引用网络安全规则；强化学习阶段，通过多样化的多目标奖励机制优化模型安全并保持模型的实用性。此外，通过内部红队测试生成全面且覆盖面高的提示，以在模型中诱导不安全的网络活动。基于PurpCode，开发了基于推理的代码模型PurpCode-32B，该模型在网络安全方面表现达到了最先进的水平，同时减少模型的过度拒绝率，保持模型在代码生成和通用安全知识上的实用性.", "conclusion": "PurpCode方法为安全代码推理模型提供了新型训练方案，显著提高了生成安全代码的能力并增强了抵御恶意网络活动的能力。基于PurpCode构建的PurpCode-32B模型展示了最先进的安全性能，並且在减少模型的过度拒绝率方面表现出色，同时保持了模型在代码生成和安全知识方面的实用性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18102", "html_url": "https://arxiv.org/abs/2505.18102", "title": "如何在不透露正确答案的情况下发布我的大语言模型基准？", "title_en": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "authors": "Takashi Ishida,Thanawat Lodkaew,Ikko Yamane", "background": "在互联网上发布大语言模型（LLM）基准会存在风险，这些基准可能会被无意中或故意用于训练或选择其他模型。通常的应对措施是保持基准的私密性，让参与者提交他们的模型或预测给组织者。然而，这种方法仍然需要对单一组织的信任，且仍然允许通过反复查询进行测试集过拟合。为了解决这一问题，本文提出了一种新的方法——能够在不完全公开问题真实答案的情况下发布基准，同时仍能保持对LLM的开放评估能力。这一方法通过向答案中注入随机性，准备多个逻辑正确的答案，并仅将其中一个作为基准的解决方案，从而降低了基准的最佳可能准确度，即贝叶斯准确度。这种方法不仅有助于保护真实答案不被泄露，还提供了一种检测数据污染的方法。即使是最有能力的模型也不应该超越贝叶斯准确度，如果模型超出了这一上限，这将是一个强有力的数据污染信号。", "innovation": "提出了一种新的方法——能够在不完全公开问题真实答案的情况下发布基准，通过向答案中注入随机性，准备多个逻辑正确的答案，并仅将其中一个作为基准的解决方案，从而降低了基准的最佳可能准确度，提供了一种新的安全发布基准的方法。", "conclusion": "实验结果显示，这种方法可以在广泛的标准、模型和训练方法下准确地检测数据污染。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.05343", "html_url": "https://arxiv.org/abs/2410.05343", "title": "EgoOops: 从程序性文本参考的自视点视频中检测错误动作的数据集", "title_en": "EgoOops: A Dataset for Mistake Action Detection from Egocentric Videos referring to Procedural Texts", "authors": "Yuto Haneji,Taichi Nishimura,Hirotaka Kameko,Keisuke Shirai,Tomoya Yoshida,Keiya Kajimura,Koki Yamamoto,Taiyu Cui,Tomohiro Nishimoto,Shinsuke Mori", "background": "现有的研究已经关注了自由活动中的明显错误，并使用了视频作为唯一的检测方法。然而，在遵循程序性文本（如烹饪指南）的活动中，模型无法仅凭视频确定某些动作的正确性，因为需要参考文本信息。目前的错误检测数据集大多仅限于烹饪领域的程序性文本，这存在明显的知识空白。因此，本文提出了一种新的数据集EgoOops，该数据集包含了各类自视点视频，记录了在遵循程序性文本过程中出现的错误活动，并提供了视频-文本对齐、错误标签和错误描述三种类型的注释。", "innovation": "本文通过引入新的EgoOops数据集，填补了既定错误检测数据集在程序性文本领域的差距，特别适用于遵循程序性文本的活动。EgoOops数据集的创新之处在于其涵盖了跨多个领域的错误动作，并提供了视频-文本对齐等多种类型的注释。此外，作者还提出了一种结合视频-文本对齐和错误标签分类的方法，以利用程序性文本进行错误检测。实验结果表明，该方法在错误检测中具有显著优势。", "conclusion": "EgoOops数据集对于开发能够检测工作者错误并提供反馈的智能档案具有重要意义。结合程序性文本进行错误检测是提高检测准确性的关键，通过该数据集的实验结果验证了这种方法的有效性，该数据集已发布。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.21903", "html_url": "https://arxiv.org/abs/2507.21903", "title": "谁最重要？-- SUnSET：事件、时间和参与者协同理解在时间线生成中的应用", "title_en": "Who's important? -- SUnSET: Synergistic Understanding of Stakeholder, Events and Time for Timeline Generation", "authors": "Tiviatis Sim,Kaiwen Yang,Shen Xin,Kenji Kawaguchi", "background": "随着新闻报道变得更加全球化和去中心化，多来源的事件追踪变得极具挑战性。现有新闻总结方法通常使用大型语言模型和图形方法生成基于文章摘要的总结。然而，这种方法仅考虑相似日期的文章文本内容，无法很好地理解事件的根本信息。为了对抗信息分析不足的问题，有必要提出一种新的框架来评估参与者的重要性和相关事件之间的联系，通过相关实体进行分析。因此，本文提出了SUnSET框架：事件、时间和参与者协同理解用于时间线总结的任务。该框架利用强大的大型语言模型构建三重关系（SET），并引入基于参与者排名的方法构造相关性度量，该度量可以应用于更一般的情况。", "innovation": "该框架利用强大的大型语言模型构建SET三重关系，并引入了基于参与者排名的构造相关性度量，这对于事件和时间线的总结而言是一种新颖的方法。这项工作首次提出了将大型语言模型应用于这种任务中的做法，并且能够有效识别和强调关键参与者的作用，从而生成更加精确和有信息量的时间线总结。此外，该方法的泛化能力得到了实验结果的支持。", "conclusion": "实验结果表明，SUnSET框架在时间线总结任务上超越了所有先前的方法，成为了新的最佳基准，突显了新闻文章中参与者信息的重要性。该研究不仅提出了一种新的解决方案，还为未来的时间线生成方法提供了重要的参考。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22359", "html_url": "https://arxiv.org/abs/2507.22359", "title": "LLM-Crowdsourced：一种无需基准的大型语言模型相互评估范式", "title_en": "LLM-Crowdsourced: A Benchmark-Free Paradigm for Mutual Evaluation of Large Language Models", "authors": "Qianhong Guo,Wei Xie,Xiaofang Cai,Enze Wang,Shuoyoucheng Ma,Kai Chen,Xiaofeng Wang,Baosheng Wang", "background": "尽管大型语言模型（LLMs）在多项任务中表现出色，但对其能力的评估仍是一个挑战。现有评估方法存在数据污染、黑盒操作和主观偏好等问题，这些都使得全面评估LLMs的真实能力变得困难。", "innovation": "提出了一种新的无需基准的评估范式LLM-Crowdsourced。该方法利用LLMs自动生成问题，独立作答并相互评估。这种方法整合了动态性、透明性、客观性和专业性四个关键评估标准，而这些是现有评估方法无法同时满足的。", "conclusion": "在对八种主流LLMs进行的数学和编程测试中证实了该方法在区分LLMs性能方面的优势，并揭示了几项传统方法难以发现的新发现，包括但不限于：（1）Gemini在原创性和专业性问题设计方面表现出最强的能力；（2）部分LLMs展现出基于记忆的回答方式，将其认为与结构相似的旧问题；（3）LLM评估结果显示出高度的一致性（稳健性）。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22607", "html_url": "https://arxiv.org/abs/2507.22607", "title": "VL-Cogito: 渐进课程强化学习促进高级多模态推理", "title_en": "VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning", "authors": "Ruifeng Yuan,Chenghao Xiao,Sicong Leng,Jianyu Wang,Long Li,Weiwen Xu,Hou Pong Chan,Deli Zhao,Tingyang Xu,Zhongyu Wei,Hao Zhang,Yu Rong", "background": "强化学习已被证明能够增强大型语言模型的推理能力。最近的研究努力将这一范式逐步扩展到多模态推理任务。由于多模态任务内部固有的复杂性和多样性，尤其是在语义内容和问题表述上，现有模型在不同领域和难度等级上经常表现出不稳定的性能。", "innovation": "本文提出了VL-Cogito，这是一种通过新颖的多阶段渐进课程强化学习（PCuRL）框架训练的高级多模态推理模型。PCuRL系统地引导模型通过逐渐增加难度的任务，显著提高了其在多模态上下文中的推理能力。该框架引入了两个关键创新点：（1）一种在线的难度软权重机制，动态调整随后的强化学习训练阶段中的训练难度；（2）一种动态长度奖励机制，激励模型根据任务复杂性自适应地调节其推理路径长度，从而在推理效率与正确性之间取得平衡。", "conclusion": "实验评估表明，VL-Cogito在跨越数学、科学、逻辑和一般理解等多个主流多模态基准上的推理结果，能够一致地匹配或超越现有推理导向模型，验证了本方法的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22879", "html_url": "https://arxiv.org/abs/2507.22879", "title": "RecGPT技术报告", "title_en": "RecGPT Technical Report", "authors": "Chao Yi,Dian Chen,Gaoyang Guo,Jiakai Tang,Jian Wu,Jing Yu,Mao Zhang,Sunhao Dai,Wen Chen,Wenjun Yang,Yuning Jiang,Zhujin Gao,Bo Zheng,Chi Li,Dimin Wang,Dixuan Wang,Fan Li,Fan Zhang,Haibin Chen,Haozhuang Liu,Jialin Zhu,Jiamang Wang,Jiawei Wu,Jin Cui,Ju Huang,Kai Zhang,Kan Liu,Lang Tian,Liang Rao,Longbin Li,Lulu Zhao,Na He,Peiyang Wang,Qiqi Huang,Tao Luo,Wenbo Su,Xiaoxiao He,Xin Tong,Xu Chen,Xunke Xi,Yang Li,Yaxuan Wu,Yeqiu Yang,Yi Hu,Yinnan Song,Yuchen Li,Yujie Luo,Yujin Yuan,Yuliang Yan,Zhengyang Wang,Zhibo Xiao,Zhixin Ma,Zile Zhou,Ziqi Zhang", "background": "推荐系统是人工智能最具影响力的应用之一，能够促进用户、商家和平台之间的联系。然而，当前大多数工业系统仍然高度依赖历史共现模式和日志拟合目标，即专注于优化过去的用户交互，而没有明确建模用户意图。这种日志拟合方法往往会导致过度拟合用户的狭窄历史偏好，不能捕捉到用户的潜在和不断变化的兴趣。因此，这会加剧滤气泡和长尾现象，最终损害用户体验并威胁到整个推荐生态系统的可持续性。", "innovation": "为了解决这些问题，重新思考推荐系统的整体设计范式，并提出了一种名为RecGPT的新一代框架，该框架将用户的意图置于推荐管线的中心。通过将大型语言模型（LLMs）整合到用户的兴趣挖掘、物品检索和解释生成的关键阶段中，RecGPT将日志拟合推荐转变为一个以意图为中心的过程。为了大规模地将通用性较强的LLMs与上述专门领域内的推荐任务对齐，RecGPT引入了一种多阶段训练范式，该范式整合了增强推理的预对齐与自我训练的进化过程，并由人-LLM协同判定系统进行指导。目前，RecGPT已全面部署于淘宝App上。在线实验证明，RecGPT在所有利益相关者中均取得了持续的性能提升：用户受益于内容多样性和满意度的提高，商家和平台也获得了更大的曝光度和转化率。这些综合改进结果验证了LLM驱动的、以意图为中心的设计可以促进更可持续且互利的推荐生态系统。", "conclusion": "实验结果证明，RecGPT通过以用户意图为中心的设计，成功地改变了传统推荐系统的局限性，实现了全面提升用户体验和推荐生态系统的可持续性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22958", "html_url": "https://arxiv.org/abs/2507.22958", "title": "CHECK-MAT: 俄罗斯统一国家考试手写数学答案检查", "title_en": "CHECK-MAT: Checking Hand-Written Mathematical Answers for the Russian Unified State Exam", "authors": "Ruslan Khrulev", "background": "现有的模型评估基准主要关注问题解决能力，而较少聚焦于评估手写数学解题过程、识别错误并根据固定标准进行评分。本文旨在通过构建一个新的基准——EGE-Math Solutions Assessment Benchmark——来填补这一空白，该基准将用于评估视觉-语言模型（VLMs）在理解和评估手写数学解题能力方面的能力。作者收集了122份来自俄罗斯统一国家考试（EGE）的手写数学解决方案及其官方专家评分，用于测试七种现代VLMs的表现。", "innovation": "该研究提出了一个新的评估基准——EGE-Math Solutions Assessment Benchmark，它侧重于评估模型对手写数学解题的理解能力、错误识别能力以及评分能力，并且与人工评分标准的一致性。这项研究创新之处在于引入了一种新的评估框架，特别针对教育评估中的视觉-语言模型应用，填补了当前评估系统中的空白，为AI辅助评估领域提供了新的研究方向。", "conclusion": "实验结果揭示了当前视觉-语言模型在数学推理和人类评分标准的一致性方面的不足，为企业和研究者指明了新的研究方向。文章中的代码可以在提供的链接中找到。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23006", "html_url": "https://arxiv.org/abs/2507.23006", "title": "城市场景重建的鲁棒高效3D高斯点渲染框架", "title_en": "Robust and Efficient 3D Gaussian Splatting for Urban Scene Reconstruction", "authors": "Zhensheng Yuan,Haozhi Huang,Zhen Xiong,Di Wang,Guanghua Yang", "background": "本文提出了一种框架，在多视角捕获中保持鲁棒性的同时，可以快速重建和实时渲染大规模城市场景。该框架采用场景划分并行训练策略，结合基于可见性的图像选择策略来优化训练效率。此外，通过可控的层次细节（LOD）策略和多种增强模块（如深度正则化、尺度正则化和抗锯齿）提高重建保真度，确保在用户定义的预算下高效训练和渲染。", "innovation": "提出的框架具有以下创新点：1. 基于可见性的图像选择策略优化训练效率；2. 可控的层次细节（LOD）策略调节Gaussian密度，实现高效且高保真的渲染；3. 应用增强模块，如深度正则化、尺度正则化和抗锯齿，提升重建的质量；4. 同时保证重建质量和效率。", "conclusion": "实验结果表明，该方法在效率和质量上均优于现有方法。重建的大规模城市场景表现良好。源代码可在特定网址获取。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23021", "html_url": "https://arxiv.org/abs/2507.23021", "title": "使用扩散模型进行统一扫描路径预测的人类凝视行为建模", "title_en": "Modeling Human Gaze Behavior with Diffusion Models for Unified Scanpath Prediction", "authors": "Giuseppe Cartella,Vittorio Cuculo,Alessandro D'Amelio,Marcella Cornia,Giuseppe Boccignone,Rita Cucchiara", "background": "预测人类凝视扫描路径对于理解视觉注意至关重要，具有应用于人机交互、自主系统和认知机器人等领域的重要意义。虽然深度学习模型已提升了扫描路径预测的性能，但大多数现有方法生成的是平均行为，未能捕捉人类视觉探索的变异性。", "innovation": "本研究提出了一种名为ScanDiff的新架构，将扩散模型与Vision Transformers相结合，生成多样且真实的扫描路径。该方法通过利用扩散模型的随机性明确建模了扫描路径的变异性，产生了广泛且合理的注视轨迹。此外，引入文本条件以支持任务驱动的扫描路径生成，使模型能够适应不同的视觉搜索目标。实验结果表明，在基准数据集上，ScanDiff 在自由观看和任务驱动场景中都超越了最新方法，生成了更多样且准确的扫描路径。", "conclusion": "这些结果突显了ScanDiff更好地捕捉人类视觉行为复杂性的能力，推动了凝视预测研究的进展。相关代码和模型已公开。"}
{"llm_update_time": "20250801", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.22062", "html_url": "https://arxiv.org/abs/2507.22062", "title": "Meta CLIP 2：全球规模训练配方", "title_en": "Meta CLIP 2: A Worldwide Scaling Recipe", "authors": "Yung-Sung Chuang,Yang Li,Dong Wang,Ching-Feng Yeh,Kehan Lyu,Ramya Raghavendra,James Glass,Lifei Huang,Jason Weston,Luke Zettlemoyer,Xinlei Chen,Zhuang Liu,Saining Xie,Wen-tau Yih,Shang-Wen Li,Hu Xu", "background": "CLIP是流行的底层模型，支持零样本分类、检索以及多模态大型语言模型的编码器。尽管CLIP已经在数亿规模的英文图像文本对上成功训练，将CLIP的训练扩展到全球网络数据仍然具有挑战性，主要原因包括：1. 没有现成的方法来处理非英语世界的数据点；2. 现有的多语言CLIP在英语性能上逊于纯英文版本，即“多语言诅咒”现象。论文旨在解决这些问题，提出了Meta CLIP 2，这是一种从头开始训练CLIP的方法，专门针对全球规模的图像文本对。", "innovation": "Meta CLIP 2是第一个从零开始在全球网络规模图像文本对上训练CLIP的方法。通过最小化改变以应对上述挑战，它提供了一个方法，可以通过英语和非英语世界的数据获取相互好处。特别地，在零样本ImageNet分类中，Meta CLIP 2 ViT-H/14超越了纯英文版本0.8%，并超过了mSigLIP 0.7%。这一方法在多语言基准测试如CVQA、Babel-ImageNet和XM3600中取得了最佳结果，分别为57.4%、50.2%和64.3%，其表现未受到任何系统级混杂因素的影响，如翻译或特殊架构变化。", "conclusion": "Meta CLIP 2成功克服了扩展CLIP训练到全球网络数据的挑战，通过从非英语世界的多样数据中获益，显著提升了多语言数据表现，并在多种跨模式基准测试中达到了新记录，证明了其在多语言领域应用的有效性和潜力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23033", "html_url": "https://arxiv.org/abs/2507.23033", "title": "基于自适应时间步长训练提升脉冲神经辐射场", "title_en": "Adaptive Time-step Training for Enhancing Spike-Based Neural Radiance Fields", "authors": "Ranxi Lin,Canming Yao,Jiayi Li,Weihang Liu,Xin Lou,Pingqiang Zhou", "background": "神经辐射场（NeRF）模型在3D重建和渲染任务中取得了显著成功。然而，在训练和推理过程中，这些模型依赖于沿多视角射线进行密集的点采样，导致浮点运算量激增，并在边缘计算等资源受限场景中受到严重限制。另一种选择是使用脉冲神经网络（SNNs），它们通过离散时间步骤中的二进制脉冲来通信，其能源效率高。由于神经渲染中场景规模和纹理复杂性的变化以及训练专门模型的普遍做法，论文提出了一种具有动态时间步长训练策略的脉冲神经辐射场框架，称为预训练-自适应时间步长调整（PATA）。这种方法在训练过程中自动探索渲染质量和时间步长之间的权衡，从而支持自适应场景推理和减少推理过程中的额外计算资源消耗。", "innovation": "PATA通过预训练和自适应时间步长调整，自动探索渲染质量和时间步长之间的平衡，从而减少推理时间步长和能耗，同时保持渲染保真度。该方法应用于现有的Instant-NGP架构，并在多种数据集上进行评估，结果显示PATA能够减少推理时间步长64%和运行功耗61.55%，而保持渲染保真度。", "conclusion": "PATA框架能够通过自适应时间步长调整提高脉冲神经辐射场的效率，在保持渲染保真度的同时，显著减少推理时间步长和能耗，适用于资源受限的场景，如边缘计算。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23027", "html_url": "https://arxiv.org/abs/2507.23027", "title": "在资源受限成像中利用超分辨率辅助超声心动图分类：恢复诊断价值", "title_en": "Recovering Diagnostic Value: Super-Resolution-Aided Echocardiographic Classification in Resource-Constrained Imaging", "authors": "Krishan Agyakari Raja Babu,Om Prabhu,Annu,Mohanasankar Sivaprakasam", "background": "在资源有限的环境中，由于超声心动图图像质量差，影响了下游诊断模型的有效性。尽管超分辨率（SR）技术在增强磁共振成像（MRI）和计算机断层扫描（CT）方面显示出前景，但它们在广泛使用的但噪声敏感的超声心动图上的应用仍然较少。这项工作中，我们研究了基于深度学习的SR在提高低质量二维超声心动图分类准确性方面的潜力。利用公开的CAMUS数据集，我们根据图像质量进行分层，并评估了两种临床相关的不同复杂度任务：相对简单的双腔与四腔视图（2CH vs. 4CH）分类任务和更复杂的舒张期末 vs. 收缩期末（ED vs. ES）阶段分类任务。应用两种广泛使用的SR模型-SRGAN和SRResNet，来增强低质量图像，在性能指标上取得了显著提升，特别以SRResNet表现最佳，计算效率也较高。我们的研究结果表明，SR技术能够有效地恢复降级超声心动图的诊断价值，使其成为资源受限环境下的AI辅助护理工具，实现更有效的工作量", "innovation": "这项工作探索了基于深度学习的超分辨率在增强低质量二维超声心动图诊断价值方面的潜力，特别针对双腔与四腔视图以及舒张期末 vs. 收缩期末阶段分类任务。研究使用了广泛使用的SR模型，首次在资源受限环境下评估了SR技术的性能，并展示了SRResNet在提升分类准确性方面的显著优势及计算效率", "conclusion": "研究结果表明，超分辨率技术能够有效恢复低质量超声心动图的诊断价值，提供了一种有效提高诊断准确性的方法，适配资源受限环境的AI辅助护理应用，实现了更为高效的医疗诊断和服务"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23143", "html_url": "https://arxiv.org/abs/2507.23143", "title": "X-NeMo：通过分离潜在关注实现表达性的神经运动重演", "title_en": "X-NeMo: Expressive Neural Motion Reenactment via Disentangled Latent Attention", "authors": "Xiaochen Zhao,Hongyi Xu,Guoxian Song,You Xie,Chenxu Zhang,Xiu Li,Linjie Luo,Jinli Suo,Yebin Liu", "background": "尽管之前的研究在面部动画领域已经取得了一定的成果，但仍然存在关键问题，如身份泄漏和捕捉微妙和极端表情的难度。因此，该研究旨在提出一种新的零样本扩散ベース的人像动画流水线，以解决这些问题。", "innovation": "研究提出了X-NeMo，一种全新的扩散模型，能够使用不同个体的驱动视频中的面部动作来动画化静态人像。具体创新点包括：1) 引入了一个全新的端到端训练框架，可以有效地从驱动图像中提取身份无关的1D潜在运动描述符；2) 通过双GAN解码器和空间/色彩增强来增强表达性和从身份线索中分离出运动潜变量；3) 设计了通过交叉注意力控制运动而不是空间引导，从而消除了驱动条件与扩散主体之间的空间对齐结构线索的传输，大幅减少了身份泄漏。", "conclusion": "通过广泛实验，X-NeMo在生成高度表达性动画方面超越了最先进的基线方法，展现出卓越的身份相似性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23058", "html_url": "https://arxiv.org/abs/2507.23058", "title": "参考指导下的扩散修复生成多模态反事实场景", "title_en": "Reference-Guided Diffusion Inpainting For Multimodal Counterfactual Generation", "authors": "Alexandru Buburuzan", "background": "安全关键应用（如自动驾驶和医学图像分析）需要大量多模态数据进行严格的测试。合成数据方法由于获取真实数据的成本和复杂性而变得越来越流行，但它们需要高度的真实性和可控性才能有用。", "innovation": "本文提出了两种新的合成数据生成方法：MObI（用于自动驾驶的多模态对象修复框架）和AnydoorMed（参考指导下的医学图像修复方法），以及一种基于扩散模型的方法以产生具有真实性和可控性的多模态对象修复。MObI 能够在既定 3D 位置无缝插入物体，并利用边界框保持语义一致性和多模态连贯性。AnydoorMed 则专注于参考指导下的乳腺扫描修复，利用基于扩散的模型修复异常，同时保持异常结构的完整性和与周围组织的语义融合。", "conclusion": "这些方法证明了参考指导下的修复基础模型可以很容易地适应各种感知模态，为下一代能够构造高度真实、可控和多模态反事实场景的系统铺平了道路。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23042", "html_url": "https://arxiv.org/abs/2507.23042", "title": "面向实时视觉语言驾驶的早期目标引导多尺度融合", "title_en": "Early Goal-Guided Multi-Scale Fusion for Real-Time Vision-Language Driving", "authors": "Santosh Patapati,Trisanth Srinivasan", "background": "自动驾驶车辆在反应 milliseconds 的同时需要理解和处理道路几何和交通意图，以应对复杂的导航情况。现有系统通常需要使用深度学习模型和复杂的架构来处理这种复杂情况，这可能导致计算开销大、实时性差等问题。", "innovation": "论文引入了单支路的视觉语言架构NovaDrive，该架构能够同时处理前方相机图像、高清地图切片、LiDAR深度数据和文本路标。该架构采用轻量级的两阶段交叉注意力机制，首先对路标进行与高清地图的对齐，再进行图像和深度切片的细化关注。该设计引入了新颖的平滑性损失，以避免急转弯和速度变化，从而不再需要使用循环记忆。论文还进一步微调了11B LLaMA-3.2视觉语言骨干网络的顶层15层，实现实时推理。", "conclusion": "实验结果表明，NovaDrive在nuScenes/ Waymo数据集上的成功率提高了4%，路径效率提高了11%，碰撞频率降低了14%。消融实验验证了路标标记、部分VLM微调和交叉注意力融合对性能提升的贡献最大。此外，该论文指出NovaDrive不仅能够显著提升驾驶安全性，其优化路线还能够降低燃料或电池消耗，有利于更轻量化和易于更新的驾驶堆栈。同时，该方法也适用于其他具备感知和执行类AI任务的场景。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23070", "html_url": "https://arxiv.org/abs/2507.23070", "title": "词汇无关的细粒度视觉识别通过增强上下文相关视觉语言模型", "title_en": "Vocabulary-free Fine-grained Visual Recognition via Enriched Contextually Grounded Vision-Language Model", "authors": "Dmitry Demidov,Zaigham Zaheer,Omkar Thawakar,Salman Khan,Fahad Shahbaz Khan", "background": "细粒度图像分类任务涉及识别在更广泛类别下的视觉相似子类别（例如，鸟类物种、汽车型号、花的种类），这是计算机视觉中具有挑战性的任务。传统的做法依赖于固定的词汇表和封闭集分类方法，在实际应用场景中，新兴的类别频繁出现时，这种方法的扩展性和适应性受到限制。近期的研究表明，结合大型语言模型（LLMs）和视觉语言模型（VLMs）能够实现开放集识别，不需要预定义的类别标签。然而，现有的方法在分类阶段往往无法充分发挥LLMs的能力，并且严重依赖于LLMs提供的猜测类名，而缺乏深入分析和精炼。", "innovation": "本文提出了一种无需训练的方法，Enriched-FineR（简称E-FineR），该方法在细粒度视觉识别方面达到了最先进的结果，同时也提供了更高的可解释性。本文展示了一种词汇无关的框架，推动了图像分类从固定的标签预测向灵活的语言驱动理解转变，使得系统能够支持大规模和广泛应用。此外，本文展示了该方法在零样本和少量样本分类中的应用，效果与当前的SOTA相当，并且是无需训练和无需人工干预的。", "conclusion": "本文的无词汇框架支持了图像分类从固定的标签预测向灵活、语言驱动理解的转变，使得系统能够提供大规模和广泛应用。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23174", "html_url": "https://arxiv.org/abs/2507.23174", "title": "基于CNN的农业环境中芒果分类解决方案", "title_en": "CNN-based solution for mango classification in agricultural environments", "authors": "Beatriz Díaz Peón,Jorge Torres Gómez,Ariel Fajardo Márquez", "background": "本文介绍了使用卷积神经网络（CNN）设计水果检测和分类系统的案例，目标是自动评估水果质量以用于农场库存管理。具体地，通过图像处理方法开发了芒果分类方法，以确保准确性与效率。选择Resnet-18作为初步分类架构，并使用级联检测器进行检测，以平衡执行速度和计算资源消耗。通过MatLab App Designer开发图形界面展示检测和分类结果，简化了系统交互。", "innovation": "本文提出了一种结合卷积神经网络和级联检测器的解决方案，用于水果分类和检测。这种方法在农业质量控制领域具有潜在应用价值。", "conclusion": "将卷积神经网络和级联检测器的结合提供了一个可靠的水果分类和检测解决方案，能够在农业环境中实现准确和高效的水果质量评估。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23064", "html_url": "https://arxiv.org/abs/2507.23064", "title": "基于视觉-语言融合的实时自动驾驶：以目标为中心的摄像头、高清地图和航点的交叉注意力", "title_en": "Vision-Language Fusion for Real-Time Autonomous Driving: Goal-Centered Cross-Attention of Camera, HD-Map, & Waypoints", "authors": "Santosh Patapati,Trisanth Srinivasan,Murari Ambati", "background": "自动驾驶汽车需要在复杂环境中具备几何准确性和语义理解能力，但现有的大多数系统分别处理视觉和语义理解。XYZ-Drive模型旨在综合处理视觉、航点和高清地图数据，通过轻量级的目标中心交叉注意力层提取相关图像和地图片段，然后将这些信息输入LLaMA-3.2 11B模型，以生成驾驶和速度指令。", "innovation": "XYZ-Drive模型结合了视觉-语言模态，集成了目标中心交叉注意机制，能够同时处理图像、航点和高清地图，并生成驾驶决策，相比PhysNav-DG在MD-NEX Outdoor-Driving基准测试中成功率达到95%，成功加路径长度加权值为0.80的碰撞次数减半，效率加倍。通过消除任何一种输入模态（视觉、航点或地图），效果显著下降，验证了各个模态之间的互补性和紧密连接。将目标中心注意力替换为简单连接导致3%性能下降，确认基于查询的融合方式更有效。保持变压器冻结的实验表明，针对特定任务如自动驾驶精调的必要性。", "conclusion": "早期、token级融合意图和地图布局使得能够实现准确、透明的实时驾驶决策。XYZ-Drive模型通过融合视觉、语言和语义信息，有效地解决了实时自动驾驶的挑战，展示了其在提高导航准确性和效率方面的潜力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23134", "html_url": "https://arxiv.org/abs/2507.23134", "title": "Details Matter for Indoor Open-vocabulary 3D Instance Segmentation", "title_en": "Details Matter for Indoor Open-vocabulary 3D Instance Segmentation", "authors": "Sanghun Jung,Jingjing Zheng,Ke Zhang,Nan Qiao,Albert Y. C. Chen,Lu Xia,Chi Liu,Yuyin Sun,Xiao Zeng,Hsiang-Wei Huang,Byron Boots,Min Sun,Cheng-Hao Kuo", "background": "不同于端到端训练的闭口词汇3D实例分割，开放词汇3D实例分割（OV-3DIS）常使用视觉语言模型（VLMs）生成3D实例提案并进行分类。现有研究中提出了多种概念，但观察到这些概念并非互斥，而是互补的。OV-3DIS采用两阶段方案进行：3D提案生成和实例分类。现有方法在ScanNet200和S3DIS的数据集上取得了良好效果，但本文仍提出了改进方法以进一步提升模型性能。", "innovation": "本文提出了一种新的解决方案，通过精心设计的配方将各种概念结合起来并加以完善，以解决关键挑战。提案生成阶段使用了稳健的3D跟踪基于的提案聚合方法，并通过迭代合并/移除来去除重叠或部分提案。分类阶段使用了自定义的Alpha-CLIP模型，并引入了标准化最大相似性（SMS）得分来规范化文本到提案的相似性，从而有效地过滤掉假阳性结果，提高精确度。这种新方法在ScanNet200和S3DIS数据集上取得了最先进的性能，甚至超过了端到端封闭词汇方法。", "conclusion": "本文通过精细设计的方法成功提升了开放词汇3D实例分割的性能，尤其是在ScanNet200和S3DIS数据集上达到了最先进的性能水平。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23110", "html_url": "https://arxiv.org/abs/2507.23110", "title": "在异质序列MRI分割中重新思考领域泛化", "title_en": "Rethink Domain Generalization in Heterogeneous Sequence MRI Segmentation", "authors": "Zheyuan Zhang,Linkai Peng,Wanying Dou,Cuiling Sun,Halil Ertugrul Aktas,Andrea M. Bejar,Elif Keles,Gorkem Durak,Ulas Bagci", "background": "现有的领域泛化基准主要关注跨中心差异，忽略了临床磁共振成像中最为显著的变量——不同序列的差异。胰腺分割仍然是腹部成像中的主要挑战，因其体积小、形状不规则且周围被器官和脂肪包围，通常具有较低的T1对比度。尽管最先进的深度网络已经在肝脏和肾脏上实现了超过90%的Dice系数，但对于胰腺的分割仍然错过20-30%的部分。此外，胰腺在公开的跨领域基准测试集中代表性不足，这限制了其在早期癌症检测、手术和糖尿病研究中的应用。", "innovation": "该研究提出了PancreasDG，这是一个大规模的多中心3D MRI胰腺分割数据集，用于研究医学成像中的领域泛化问题。通过一个双盲、两阶段的协议创建像素级精确的胰腺掩码，并结合多种序列和机构的数据，该数据集不仅可以研究跨机构差异，还能考察跨序列的变化。提出的半监督方法通过利用解剖结构不变性在跨序列分割中显著优于现有技术水平，提高了61.63%的Dice分数，并在两个测试中心达到了87.00%的性能。", "conclusion": "PancreasDG为医学成像中的领域泛化设定了一个新基准，通过该数据集可以更全面地考察跨机构和跨序列变化对分割任务的影响。数据集、代码和模型会在指定网址提供。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23150", "html_url": "https://arxiv.org/abs/2507.23150", "title": "向多传感器卫星图像高分辨率对齐与超分辨率研究", "title_en": "Towards High-Resolution Alignment and Super-Resolution of Multi-Sensor Satellite Imagery", "authors": "Philip Wootaek Shin,Vishal Gaur,Rahul Ramachandran,Manil Maskey,Jack Sampson,Vijaykrishnan Narayanan,Sujit Roy", "background": "高分辨率卫星影像对于地理空间分析至关重要，然而不同卫星传感器的分辨率差异给数据融合和下游应用带来挑战。现有超分辨率技术依赖人工缩小的影像而非实际传感器数据，且难以适用于具有不同光谱和时间特性的异构卫星传感器。因此，需要一种新的方法来解决这一问题，特别是为了将30米分辨率的 Harmonized Landsat Sentinel (HLS) 30m影像与10米分辨率的HLS 10m影像对齐，并提高超分辨率后的Landsat影像质量.", "innovation": "本文开发了一种初步框架，使用 Harmonized Landsat Sentinel 10m (HLS10) 作为参考，来对齐和融合 HLS 30m 的影像。该方法旨在弥补这些传感器之间的分辨率差距，并提升Landsat超分辨率影像的质量。实验结果表明该方法的有效性，为进一步改善基于卫星的传感应用提供了潜力。这项研究为异构卫星图像超分辨率的可能性提供了见解，并指出了该领域未来进步的关键考虑点.", "conclusion": "本文提供了一种将异构卫星图像（如 HLS 30m 和 HLS 10m）对齐和超分辨率的新方法，具有实际应用前景。未来研究将考虑更多传感器和技术优化，以进一步提高图像处理效果和适用性."}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23185", "html_url": "https://arxiv.org/abs/2507.23185", "title": "单应 Harris 角点损失和 R-CBAM 网络在单应雨线去除中的应用", "title_en": "Single Image Rain Streak Removal Using Harris Corner Loss and R-CBAM Network", "authors": "Jongwook Si,Sungyoung Kim", "background": "单应图像去雨线的问题超出了简单的噪声抑制，需要同时保留细粒度结构细节和整体视觉质量。现有的图像修复方法在处理雨线时容易导致目标边界和详细纹理信息的损失，因此需要一种新的图像恢复网络来解决这个问题，并在恢复过程中有效限制损失.", "innovation": "本文提出了一种新的图像恢复网络，通过引入Harris角点损失有效地约束恢复过程，防止恢复过程中出现目标边界和详细纹理信息的损失。同时，该网络通过在编码器和解码器中引入基于特征在空间和通道维度上的动态调整的Residual Convolutional Block Attention Module (R-CBAM) 块，更有效地关注受雨线严重影响的区域.", "conclusion": "在Rain100L和Rain100H数据集上的定量评估表明，所提出的方法在性能上显著优于前一种方法，Rain100L数据集的PSNR为33.29 dB，Rain100H数据集的PSNR为26.16 dB."}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23193", "html_url": "https://arxiv.org/abs/2507.23193", "title": "一种针对卫星图像季节变化具有鲁棒性的洪水检测新数据集", "title_en": "A Novel Dataset for Flood Detection Robust to Seasonal Changes in Satellite Imagery", "authors": "Youngsun Jang,Dongyoun Kim,Chulwoo Pack,Kwanghee Won", "background": "在分析77个现有利用卫星图像的基准测试后，发现缺乏适合特定任务的适合数据集，即在卫星图像中分割洪水区域的任务。这促使研究者收集了2019年美国中西部洪灾的卫星图像，确保了数据的一致性和处理过程中的统一分辨率。", "innovation": "研究引入了一个新的数据集来分割卫星图像中的洪水区域，这是对现有数据集的一大创新，特别是它填补了特定任务数据集的空白，并通过对比不同窗口大小来捕捉时间特征，为未来的多模态和时间学习策略的需求提供了证据", "conclusion": "虽然最先进的模型在数据集上表现出适度的结果，但研究人员强调未来需要探索多模态和时间学习策略。该数据集将公开发布，以便进一步的研究使用。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23162", "html_url": "https://arxiv.org/abs/2507.23162", "title": "无需光度立体视觉提示的神经多视图自校准光度立体视觉", "title_en": "Neural Multi-View Self-Calibrated Photometric Stereo without Photometric Stereo Cues", "authors": "Xu Cao,Takafumi Taketomi", "background": "现有的多视图光度立体视觉方法通常需要对光源进行校准或者需要生成中间线索，如每个视图的法线图。这些方法在形状和光照估计方面存在一定的局限性，尤其是对于复杂几何形状和反射特性的物体。该研究提出了一种神经逆渲染方法，旨在同时从多视角图像中重建几何形状、空间变化的反射和光照条件，而无需进行光源校准或依赖中间线索。", "innovation": "该方法通过单阶段从原始图像中联合优化所有场景参数，将几何和反射表示为神经隐式场，并应用阴影感知体积渲染。首先使用空间网络预测每个场景点的签字距离和反射潜在代码，然后使用反射网络基于潜在代码和角度编码的表面法线、视点和光源方向估计反射值。这种方法在形状和光照估计准确性方面优于现有基于法线导向的方法，能够处理视图对齐不一致的多光源图像，适用于具有挑战性几何形状和反射特性的物体。", "conclusion": "该方法在形状和光照估计准确性方面表现出色，能够处理未对齐的多光源图像，并适用于具有复杂几何形状和反射特性的物体，是现有的光度立体视觉方法的改进。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23188", "html_url": "https://arxiv.org/abs/2507.23188", "title": "学习精细粒度联合嵌入空间的多模态运动检索", "title_en": "Multi-Modal Motion Retrieval by Learning a Fine-Grained Joint Embedding Space", "authors": "Shiyao Yu,Zi-An Wang,Kangning Yin,Zheng Tian,Mingyuan Zhang,Weixin Si,Shihao Zou", "background": "运动检索对于运动捕捉至关重要，提供比运动生成更精准、更真实、更可控和更便捷的体验。现有方法利用对比学习构建统一的嵌入空间，从而实现从文本或视觉模态中获取运动检索。然而，这些方法缺乏更直观和用户友好的交互方式，并且通常忽视了通过对最多种模态进行序列表示来提升检索性能。", "innovation": "本文提出了一种框架，将四种模态——文本、音频、视频和运动——整合在一个精细节度的联合嵌入空间中，首次在运动检索中引入音频，以增强用户体验和便捷性。通过序列级对比学习，该精细粒度的空间能够捕捉跨模态的关键细节，更好地实现对齐。该框架通过扩充现有文本-运动数据集，加入了合成但多样的音频记录，创建了两个多模态运动检索数据集来评估其性能。实验结果表明，该框架在多个子任务上优于现有最先进方法，特别是在文本到运动检索的R@10上提高了10.16%，在视频到运动检索的R@1上提高了25.43%，并且4模态框架显著优于其3模态对比。", "conclusion": "本文提出的方法在多模态运动检索中表现出色，特别是在实验数据集HumanML3D上，证明了多模态运动检索在运动捕捉领域中的潜在应用价值。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23226", "html_url": "https://arxiv.org/abs/2507.23226", "title": "朝向安全、可信和逼真的增强现实用户体验", "title_en": "Toward Safe, Trustworthy and Realistic Augmented Reality User Experience", "authors": "Yanming Xiu", "background": "随着增强现实（AR）越来越多地融入日常生活，确保其虚拟内容的安全性和可信度变得至关重要。我们的研究致力于解决妨碍任务执行的AR内容的风险，特别是这些内容可能会遮挡重要信息或微妙地操控用户感知。", "innovation": "我们开发了两个系统，ViDDAR 和 VIM-Sense，利用视觉-语言模型（VLMs）和多模态推理模块来检测此类攻击。在此基础上，我们提出三个未来方向：自动化的、感知对齐的内容质量评估；多模态攻击检测；以及适应AR设备的VLMs的轻量级模型优化。", "conclusion": "我们的工作旨在建立一个可扩展、与人类对齐的框架，以保护AR体验，并寻求关于感知建模、多模态AR内容实现和轻量级模型适应的反馈。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23206", "html_url": "https://arxiv.org/abs/2507.23206", "title": "基于置信度感知的2D食品晶体微观图像凝聚分类与分割", "title_en": "Confidence-aware agglomeration classification and segmentation of 2D microscopic food crystal images", "authors": "Xiaoyu Ji,Ali Shakouri,Fengqing Zhu", "background": "食品晶体凝集是一个在结晶过程中发生的现象，它将水分困在晶体之间，影响食品产品的质量。在2D显微镜图像中手动标注凝集是一项特别困难的任务，因为水的透明性和有限的视角使聚焦于单个样本切片变得困难。现有方法基于手动标注存在难以保证一致性和可靠性的缺点，尤其是在透明度和视角限制下的精准标注尤为艰巨。", "innovation": "提出了一个监督基线模型来为粗略标注的分类数据集生成分割伪标签。接着，训练了一个同时进行像素级分割的实例分类模型。两个模型在推断阶段结合使用，以利用各自在分类和分割方面的优势。着眼于保持晶体特性，设计并融入了一个后处理模块到两个过程。相较于现存方法，新方法在真实阳性凝集分类准确性和尺寸分布预测方面表现出色，并能根据不同手动标注的置信度水平进行评估，成功地分类潜在的凝聚实例。", "conclusion": "该方法通过结合监督基线模型和实例分类模型进行粗略标注，提高了2D显微镜食品晶体图像中凝集的分类准确性和尺寸分布预测的准确性，并且可以基于不同置信度水平的标注进行有效评估。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23202", "html_url": "https://arxiv.org/abs/2507.23202", "title": "基于对抗指导扩散的多模态LLM攻击", "title_en": "Adversarial-Guided Diffusion for Multimodal LLM Attacks", "authors": "Chengwei Xia,Fan Ma,Ruijie Quan,Kun Zhan,Yi Yang", "background": "本文解决了使用扩散模型生成欺骗多模态大型语言模型 (MLLMs) 以生成所需响应的对抗图像的问题，同时尽量减少对清洁图像的显著失真。传统方法通常将高频扰动直接嵌入清洁图像中，而本文提出的方法——对抗指导扩散 (AGD) 方法，将目标语义嵌入逆向扩散过程中的噪声成分中，从而在不显著影响清洁图像的情况下，有效地对MLLMs进行攻击。", "innovation": "本文的创新在于提出了对抗指导扩散 (AGD) 方法，通过将目标语义嵌入噪声中，而不是传统方法的高频扰动，使得生成的对抗图像在整个频率谱中都具有对抗信号。此外，由于在逆向扩散过程中，对抗图像是由清洁图像和噪声的线性组合形成的，而低通滤波等防御措施针对每个组件独立作用，使得噪声中的对抗图像较少被抑制，使AGD方法对于多种防御手段具有内在的鲁棒性。", "conclusion": "大量实验表明，本文提出的AGD方法在攻击性能和对抗防御的鲁棒性方面均优于现有的最新方法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23242", "html_url": "https://arxiv.org/abs/2507.23242", "title": "通用强化学习方法用于面向检索器的特定查询重写器及处理非结构化现实生活文档", "title_en": "Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents", "authors": "Sungguk Cha,DongWook Kim,Taeseung Hahn,Mintae Kim,Youngsub Han,Byoung-Ki Jeon", "background": "RAG系统依赖有效的查询来解锁外部知识，但优化适用于多种未结构化现实世界文档的查询仍是一个挑战。现有方法大多依赖于人工标注的数据集，这限制了它们的应用范围。", "innovation": "提出了RL-QR，这是一种专为检索器设计的强化学习框架，用于查询重写，它不依赖于人工标注的数据集，能够适用于文本和多模态数据库。通过合成场景-问题对并利用通用强化奖励策略优化（GRPO），RL-QR能够为特定的检索器定制查询重写器，从而提升跨不同领域的检索性能。", "conclusion": "实验结果证明，RL-QR在多模态和词法检索器方面均显著提升了性能，尤其是对于多模态RAG，NDCG@3指标提高了11%，但对于语义和混合检索器，由于训练对齐问题，重写器未能提升性能。研究结果表明，RL-QR展示了变革RAG系统中查询优化的潜力，提供了一种无标注解决方案，可扩展至真实的检索任务，同时也指出了在语义检索环境下进一步改进的可能性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23245", "html_url": "https://arxiv.org/abs/2507.23245", "title": "自动化构建视神经II、动眼神经III、三叉神经V和面-前庭蜗神经VII/VIII通路图：一种多参数多阶段扩散束图图谱", "title_en": "Automated Mapping the Pathways of Cranial Nerve II, III, V, and VII/VIII: A Multi-Parametric Multi-Stage Diffusion Tractography Atlas", "authors": "Lei Xie,Jiahao Huang,Jiawei Zhang,Jianzhong He,Yiang Pan,Guoqiang Xie,Mengjun Li,Qingrun Zeng,Mingchu Li,Yuanjing Feng", "background": "颅神经（CNs）对人体大脑的各种重要功能起着关键作用，通过弥散磁共振成像（dMRI）映射其通路可为手术前提供有关单个CN与其他重要组织的空间关系的重要见解。然而，全面且详细的CN图谱的构建具有挑战性，因每个CN对的独特解剖结构和颅底的复杂性所致。本文介绍了首个使用多参数纤维束追踪和多阶段纤维束聚类来自动化映射人类大脑中多个CN对通路的研究，以提供这些关系的定量和可视化实验，证明其与专家手动标注的高度空间对应性。", "innovation": "本文提出了一种新的策略，用于多参数多阶段扩散束追踪聚类分析，该方法在50位人类连接组项目（HCP）受试者中生成约100万条纤维束的轨迹，用于生成颅神经图谱。这种方法不仅提高了颅神经通路的自动化识别能力，还通过自动识别8个纤维束便于了复杂脑结构的可视化和理解。", "conclusion": "本文通过多参数多阶段扩散束追踪图谱贡献了扩散成像领域，能够实现多个颅神经对通路的自动化映射，从而提高复杂脑结构的分析和理解。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23253", "html_url": "https://arxiv.org/abs/2507.23253", "title": "通过图像模态测量和建模时间序列预测中的几何结构", "title_en": "Towards Measuring and Modeling Geometric Structures in Time Series Forecasting via Image Modality", "authors": "Mingyang Yu,Xiahui Guo,Peng chen,Zhenkai Li,Yang Shu", "background": "时间序列预测在气象预报、金融投资和交通管理等领域至关重要。传统的数值指标，如均方误差（MSE），可以量化点的准确性，但无法评估时间序列数据的几何结构，这影响了对时间动态的理解。因此，需要一种新的方法来衡量和建模时间序列中的几何结构。", "innovation": "提出了一种称为时间序列几何结构指数（TGSI）的新评价指标，该指标将时间序列转换成图像，利用其固有的二维几何表示。同时，引入了形状感知时域损失（SATL），这是一种多组件损失函数，在时间序列模态中操作，以弥补图像转换过程的非可微性，并在训练期间增强结构建模。", "conclusion": "实验结果表明，使用SATL训练的模型在MSE和提出的TGSI指标方面均优于基线方法，并且在推理时不会增加计算成本。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23251", "html_url": "https://arxiv.org/abs/2507.23251", "title": "深入探讨通用对象跟踪：一项综述", "title_en": "A Deep Dive into Generic Object Tracking: A Survey", "authors": "Fereshteh Aghaee Meibodi,Shadi Alijani,Homayoun Najjaran", "background": "通用对象跟踪依然是计算机视觉中的一个重要且具有挑战的任务，主要因为其复杂的时空动态，特别是在遮挡、相似干扰物和外观变化存在的情况下更加艰难。在过去的二十年里，已经提出了多种跟踪模式，包括基于串联的方法、判别性跟踪器以及最近突出的基于.transformer的方法。现有的一些回顾论文要么集中在单一类别，要么广泛涵盖多个类别，以此来捕获进展。然而，本文为我们提供了一个全面的回顾，特别关注快速发展的基于.transformer的方法，通过定性和定量比较分析了每种方法的核心设计原则、创新和局限性，并引入了新的分类，提供了代表方法的统一视觉和表格式比较。", "innovation": "本文提出了新的分类方法，并提供了代表方法的统一视觉和表格式比较。此外，它从多个视角组织了现有的跟踪工具，并总结了主要的评估基准，突出了基于.transformer的跟踪因其强大的时空建模能力而实现的飞速进展。", "conclusion": "本文提供了基于.transformer的方法的深入洞察，通过定性定量的比较分析了这些方法的核心设计、创新和局限，引入了新的分类，并提供了统一的比较，同时总结了现有的评估标准，展示了基于.transformer的跟踪在时空建模能力方面取得了快速进展。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23237", "html_url": "https://arxiv.org/abs/2507.23237", "title": "Ambiguity-Guided Learnable Distribution Calibration for Semi-Supervised Few-Shot Class-Incremental Learning", "title_en": "Ambiguity-Guided Learnable Distribution Calibration for Semi-Supervised Few-Shot Class-Incremental Learning", "authors": "Fan Lyu,Linglan Zhao,Chengyan Liu,Yinying Mei,Zhang Zhang,Jian Zhang,Fuyuan Hu,Liang Wang", "background": "Few-Shot Class-Incremental Learning (FSCIL) 的研究主要关注模型如何利用少量数据学习新概念并保留以前学习的类别知识。近期，许多研究开始利用未标记样本辅助从少量标记样本中学习，从而发展出半监督少样本类增量学习（Semi-FSCIL）。然而，现有研究通常假设未标记数据源仅限于当前会话中新类别，这过于限定了视角，与实际应用场景不相符。因此，研究重新定义了 Semi-FSCIL 为 Generalized Semi-FSCIL (GSemi-FSCIL)，并将其未标记样本集合扩展到包含基础类别和所有已出现的新类别。这一改变对现有方法提出了新的挑战，因为它们难以区分来自基础类别和新类别的未标记样本。", "innovation": "本文提出了 Ambiguity-guided Learnable Distribution Calibration (ALDC) 策略，该策略能够动态利用丰富的基础样本来纠正少数新类别的特征分布偏倚。实验结果表明，本文方法在三个基准数据集上的表现优于现有方法，并取得了新的最先进的成果。", "conclusion": "实验结果证实了所提出的 ALDC 策略的有效性，不仅解决了 Semi-FSCIL 中未标记样本来源的限制问题，还大幅提升了算法性能，为该领域的未来研究提供了新的方向和方法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23225", "html_url": "https://arxiv.org/abs/2507.23225", "title": "YOLO-ROC: 实现实时道路损坏检测的高精度和超轻量级模型", "title_en": "YOLO-ROC: A High-Precision and Ultra-Lightweight Model for Real-Time Road Damage Detection", "authors": "Zicheng Lin,Weichao Pan", "background": "道路损坏检测是确保交通安全和维护基础设施完整性的重要任务。尽管基于深度学习的方法现在已广泛应用，但仍存在两个核心挑战：一是现有网络在提取多尺度特征时能力不足，尤其是对于裂缝和坑洞等多样化目标，这导致小尺度损坏的漏检率较高；二是主流模型的参数量和计算需求较大，这妨碍了在实际应用中的高效、实时检测部署。", "innovation": "本文提出了一种高精度和轻量级的模型YOLO-ROC，以解决上述问题。该模型通过设计双向多尺度空间金字塔池化快速（BMS-SPPF）模块增强多尺度特征提取，并实施层级通道压缩策略以降低计算复杂性。BMS-SPPF模块利用双向空间通道注意机制增强了小目标的检测能力。同时，通道压缩策略将参数量从3.01M降低到0.89M，GFLOPs从8.1降低到2.6。实验表明，YOLO-ROC在RDD2022_China_Drone数据集上的mAP50达到67.6%，优于基线YOLOv8n模型2.11%。对于小目标D40类别，mAP50提升了16.8%，最终模型大小仅为2.0 MB。此外，模型在RDD2022_China_Motorbike数据集上展现了出色的泛化性能。", "conclusion": "实验结果表明，YOLO-ROC模型在提供高精度检测的同时，显著减少了计算资源的需求，适用于实际应用中的实时道路损坏检测。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23268", "html_url": "https://arxiv.org/abs/2507.23268", "title": "PixNerd: 像素神经场扩散", "title_en": "PixNerd: Pixel Neural Field Diffusion", "authors": "Shuai Wang,Ziteng Gao,Chenhui Zhu,Weilin Huang,Limin Wang", "background": "当前扩散变压器的成功很大程度上依赖预训练的变分自编码器（VAE）所塑造的压缩潜在空间。然而，这种两阶段训练范式不可避免地引入了累积错误和解码伪影。研究人员为了应对上述问题，回归到像素空间，但这也带来了复杂的级联流水线和增加的标记复杂性。", "innovation": "我们提出了一种基于神经场的块状解码模型，并提供了一种单一尺度、单一阶段、高效、端到端的解决方案，称为像素神经场扩散（PixelNerd）。借助PixNerd中高效的神经场表示，我们直接在ImageNet 256×256上实现了2.15的FID，在ImageNet 512×512上实现了2.84的FID，这在没有复杂级联流水线或VAE的情况下取得。此外，我们将PixNerd框架扩展到文本至图像应用，PixNerd-XXL/16在GenEval基准和DPG基准上分别获得了竞争性的0.73综合评分和80.9综合评分", "conclusion": "我们通过单一尺度、单一阶段的方法，直接在大规模图像生成任务中实现了较好的性能，展示了神经场方法在复杂生成任务中的潜力，同时也为文本至图像生成提供了新的解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23263", "html_url": "https://arxiv.org/abs/2507.23263", "title": "学习语义感知阈值以在部分标签条件下进行多标签图像识别", "title_en": "Learning Semantic-Aware Threshold for Multi-Label Image Recognition with Partial Labels", "authors": "Haoxian Ruan,Zhihua Xu,Zhijing Yang,Guang Ma,Jieming Xie,Changxiang Fan,Tianshui Chen", "background": "传统的多标签图像识别方法主要依赖语义或特征关联来为未知标签生成伪标签，并使用预设的阈值。然而，这种方法往往未能考虑到不同类别在评分分布方面的差异，导致生成的伪标签不准确且不完整，从而影响识别性能。", "innovation": "提出了语义感知阈值学习 (SATL) 算法，该算法在每个类别内计算正样本和负样本的评分分布，并基于这些分布确定类别特定的阈值，这些分布和阈值在整个学习过程中动态更新。此外，采用了差异性排名损失来拉开正样本和负样本评分分布之间的显著差距，增强阈值的区分度。", "conclusion": "大规模多标签数据集（如Microsoft COCO和VG-200）的实验与分析表明，本方法在少量标签情况下显著提高了性能。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23277", "html_url": "https://arxiv.org/abs/2507.23277", "title": "iLRM: 一种迭代的大规模3D重建模型", "title_en": "iLRM: An Iterative Large 3D Reconstruction Model", "authors": "Gyeongjin Kang,Seungtae Nam,Xiangyu Sun,Sameh Khamis,Abdelrahman Mohamed,Eunbyung Park", "background": "随着深度学习技术的发展，基于前馈的3D建模已成为一种快速且高质量的3D重建方法，特别是直接生成显式的3D表示（例如3D高斯点云），因其快速的渲染质量和广泛的应用而受到关注。然而，现有的许多基于变压器架构的方法在视图数量或图像分辨率增加时，由于依赖于多输入视图间全注意力机制，会导致计算成本急剧增加，从而限制了其可扩展性。因此，为了实现大规模且高效的3D重建，研究人员提出了一种迭代的大规模3D重建模型（iLRM）来应对这一问题。", "innovation": "iLRM通过迭代优化机制生成3D高斯表示，包括三个核心设计原则：（1）将场景表示与输入视图图像分离，以实现紧凑的3D表示；（2）将全注意力机制的多视图相互作用分解为两阶段注意力机制，以降低计算复杂度；（3）在每一层中注入高分辨率信息，以增强重建保真度。实验结果表明，iLRM在重建质量和速度上均优于现有方法，并且其可扩展性更强，在相似的计算成本下提供了更高的重建质量。", "conclusion": "本文提出了iLRM，一种迭代的大规模3D重建模型，通过压缩的3D表示、两阶段注意力机制、逐层引入高分辨率信息等方式提高了可扩展性和重建质量。实验结果有力证明了iLRM在大规模3D重建中的有效性和优势。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23272", "html_url": "https://arxiv.org/abs/2507.23272", "title": "利用SAM2进行3D乳腺MRI中经济实惠的肿瘤分割与可视化", "title_en": "Towards Affordable Tumor Segmentation and Visualization for 3D Breast MRI Using SAM2", "authors": "Solha Kang,Eugene Kim,Joris Vankerschaver,Utku Ozbulak", "background": "乳腺MRI提供高分辨率的体视成像，对于肿瘤评估和治疗计划至关重要，但手动解释3D扫描仍然劳动密集且主观。尽管人工智能辅助工具有望加速医学图像分析，但在低收入和中等收入国家，由于高额许可费用、专有软件和基础设施要求，商用医疗人工智能产品的采用仍然有限。因此，本研究探讨是否可以将Segment Anything Model 2 (SAM2) 调整为低投入、低成本的3D肿瘤分割方法应用于乳腺MRI，以应对资源受限的环境。", "innovation": "研究发现，通过单个边界框注释一个切片，并使用从上往下、从下往上、从中心向外三种片内跟踪策略来传播分割预测，SAM2能够在几乎无监督的情况下实现优异的分割性能，特别是使用从中心向外策略时，表现最为稳定且准确。这表明，通用基础模型如SAM2可以在资源受限的环境中支持3D医学图像分析，并提供一个具有成本效益的替代方案。此外，研究进一步分析了分割性能与肿瘤大小、位置和形状之间的关系，识别出关键失败模式。", "conclusion": "我们的研究结果表明，通用基础模型如SAM2能够以最少的监督支持3D医学图像分析，为资源受限的环境提供了经济实惠且可及的替代方案，并为肿瘤分割和可视化研究带来了新的应用场景。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23278", "html_url": "https://arxiv.org/abs/2507.23278", "title": "UniLiP：将CLIP适应为统一的多模态理解、生成和编辑", "title_en": "UniLiP: Adapting CLIP for Unified Multimodal Understanding, Generation and Editing", "authors": "Hao Tang,Chenwei Xie,Xiaoyi Bao,Tingyu Weng,Pandeng Li,Yun Zheng,Liwei Wang", "background": "先前基于CLIP的统一方法通常需要额外的扩散解码器或量化来支持重建和生成任务，这导致重建不一致或原始理解能力下降。", "innovation": "提出了UniLIP，这是一种扩展CLIP的方法，使其能够在重建、生成和编辑任务上保持一致性，同时保持原有的理解能力。引入了两阶段训练方案和自-distillation策略，以逐步将重建能力整合到CLIP中。提出了双条件架构，该架构连接了MLLM和扩散变换器，使用可学习查询和最后一层多模态隐藏状态作为联合条件。UniLIP既利用了MLLM的强推理能力，也在编辑任务中最大化了UniLIP特征中的丰富信息。", "conclusion": "UniLIP在文本到图像生成任务中，在GenEval和WISE基准上的得分分别是0.87和0.53，超过了所有相同规模的先前统一模型。在图像编辑中，UniLIP在ImgEdit基准上得到了3.62的分数，超过了如BAGEL和UniWorld-V1等最近的最先进的模型。UniLIP有效地扩展了CLIP的应用范围，使其连续CLIP特征不仅能够作为理解任务的最佳选择，还能够实现生成和编辑任务中的高度竞争力表现。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23300", "html_url": "https://arxiv.org/abs/2507.23300", "title": "基于扩散模型的无需训练的几何图像编辑", "title_en": "Training-free Geometric Image Editing on Diffusion Models", "authors": "Hanshen Zhu,Zhen Zhu,Kaile Zhang,Yiming Gong,Yuliang Liu,Xiang Bai", "background": "在几何图像编辑任务中，需要将图像中的对象重新定位、重新定向或重新塑形，同时保持场景整体的一致性。之前的基于扩散的方法往往试图一步处理所有相关子任务，但在复杂的结构变化时这变得尤其困难。为此，本文提出了一个解耦的流水线，分别处理对象变换、源区域补全和目标区域细化，使用名为FreeFine的无需训练的扩散方法实现补全和细化操作。", "innovation": "提出了一个解耦的双重处理流水线，即对象变换、源区域补全和目标区域细化分别处理，并使用非训练型扩散方法（FreeFine）实现补全和细化操作，尤其在复杂的变换下优于现有的其他方法，提高了图像保真度和编辑精度，同时设计了GeoBench基准测试集，包含2D和3D编辑场景，展示了其有效性。", "conclusion": "通过提出的FreeFine方法，该方法在全新的GeoBench基准测试集上取得了显著的效果，特别是在复杂变换下的图像保真度和编辑精度上，优于现有的先进方法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23295", "html_url": "https://arxiv.org/abs/2507.23295", "title": "LED基准：诊断文档布局分析中的结构性布局错误", "title_en": "LED Benchmark: Diagnosing Structural Layout Errors for Document Layout Analysis", "authors": "Inbum Heo,Taewook Hwang,Jeesu Jung,Sangkeun Jung", "background": "近年来，通过大型语言模型和多模态模型在文档布局分析方面取得了显著进步，极大地提升了布局检测的准确性。然而，尚存在一些关键结构错误，如区域合并、拆分和内容缺失等问题。传统评价指标如IoU和mAP主要关注空间重叠，无法有效检测这些错误。", "innovation": "本文提出了一种新型基准—Layout Error Detection（LED），用于评估文档布局预测的结构性稳健性。LED定义了八种标准化的错误类型，并提出了三项互补任务：错误存在检测、错误类型分类及元素级错误类型分类。此外，LED-Dataset是一个基于DLA模型的经验分布生成的包含真实结构错误的合成数据集。", "conclusion": "在一系列LMM（大型语言模型）的实验结果表明，LED有效地区分了结构理解能力，揭示了传统的评价指标所无法展示的模态偏差和性能权衡问题。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23284", "html_url": "https://arxiv.org/abs/2507.23284", "title": "使用多模态大型语言模型进行双向似然估计的文本视频检索", "title_en": "Bidirectional Likelihood Estimation with Multi-Modal Large Language Models for Text-Video Retrieval", "authors": "Dohwan Ko,Ji Soo Lee,Minhyuk Choi,Zihang Meng,Hyunwoo J. Kim", "background": "文本视频检索的目标是从大型在线数据库中找到与视频（或文本）查询最相关的文本（或视频）候选。最近的工作利用多模态大型语言模型（MLLMs）以提高检索效果，尤其是对于长或复杂的查询-候选对。然而，MLLMs的简单应用，即基于候选可能性的检索，会引入候选先验偏差，倾向于优先考虑本来就具有较高先验可能性的候选，而不是与查询更相关的内容。", "innovation": "本文提出了一种新颖的检索框架——双向似然估计多模态大型语言模型（BLiM）——通过训练模型从给定的视频生成文本，以及从给定的文本生成视频特征，利用查询和候选的双重可能性。此外，还引入了候选先验规范化（CPN）模块，这是一个简单的得分校准模块，能够在无需训练的情况下减轻候选先验偏差。BLiM结合CPN在四个文本视频检索基准测试中，平均取得了6.4的R@1性能提升，有效缓解了先验偏差并突显了查询-候选的相关性。进一步的研究还展示了CPN在各种多模态任务中的广泛应用，通过减少对文本先验的依赖，增强了视觉理解能力。", "conclusion": "在文本视频检索和其他多模态任务中，BLiM框架通过考虑查询和候选的同时可能性，以及通过CPN减轻先验偏差，明显提升了检索性能。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23311", "html_url": "https://arxiv.org/abs/2507.23311", "title": "基于模型合并的持续学习中任务特定知识的遗忘", "title_en": "Forgetting of task-specific knowledge in model merging-based continual learning", "authors": "Timm Hess,Gido M van de Ven,Tinne Tuytelaars", "background": "该论文研究了持续学习（CL）背景下模型线性合并的问题。以往研究表明，在持续学习过程中，模型需要处理不断变化的任务，这会导致已学习的信息遗忘。本文通过使用控制视觉线索的计算机视觉实验，分析了模型合并的效果及其影响。", "innovation": "本文的创新在于通过增量训练和并行训练模型的合并，对比了不同的模型合并方法在持续学习中的表现。实验结果显示，从增量训练过程中合并的模型在性能上优于从并行训练中合并的模型，且合并过程有助于保留并提高共享知识，同时快速削弱特定任务的知识遗忘。", "conclusion": "研究得出，模型合并能够有效地保留和提升共享知识，尤其是在增量训练过程中合并的模型表现更好。此外，模型合并可以更有效地区分共享知识与特定任务的知识，从而更好地处理持续学习中的知识遗忘问题。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23326", "html_url": "https://arxiv.org/abs/2507.23326", "title": "在领域泛化医疗图像分割中的学习语义方向特征增强", "title_en": "Learning Semantic Directions for Feature Augmentation in Domain-Generalized Medical Segmentation", "authors": "Yingkai Wang,Yaoyao Zhu,Xiuding Cai,Yuhao Xiao,Haotian Wu,Yu Yao", "background": "医学图像分割在临床工作中起着关键作用，但由于在未见过的临床领域中存在领域转移，模型性能往往会下降。这一挑战源于成像条件、扫描器类型和采集协议的变化，限制了分割模型的实用部署。与自然图像不同，医学图像在不同患者之间通常具有一致的解剖结构，领域特定的变异性主要由成像条件引起。这一独特特性使得医学图像分割特别具有挑战性。", "innovation": "提出了一种针对医学图像分割的领域泛化框架，通过引入由领域统计指导的隐式特征扰动来提高对领域特定变异性的影响。具体而言，使用可学习的语义方向选择器和基于协方差的语义强度采样器来调节领域变异性特征，同时保持相关解剖一致性。此外，设计了一种适应性一致性约束，仅在特征调整导致分割性能下降时才被选择性应用，以鼓励调整的特征与原始预测对齐，从而稳定特征选择并提升分割的可靠性。", "conclusion": "在两个公开的多中心基准上的广泛实验表明，该框架在所有领域范围内均表现出色，优于现有的领域泛化方法，实现了稳健且可泛化的分割性能。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23307", "html_url": "https://arxiv.org/abs/2507.23307", "title": "ST-SAM: 由SAM驱动的自训练框架在半监督伪装目标检测中的应用", "title_en": "ST-SAM: SAM-Driven Self-Training Framework for Semi-Supervised Camouflaged Object Detection", "authors": "Xihang Hu,Fuming Sun,Jiazhe Liu,Feilong Xu,Xiaoli Zhang", "background": "半监督伪装目标检测（SSCOD）旨在通过利用有限的标注数据和大量的未标注数据来减少对昂贵的像素级标注的依赖。现有基于教师-学生框架的SSCOD方法在少量监督下容易产生严重的预测偏差和误差传播，并且多网络架构会导致高计算开销和有限的可扩展性。", "innovation": "本文提出了一种名为ST-SAM的高效注释框架，突破了传统SSCOD的限制。ST-SAM采用自训练策略，动态筛选和扩展高置信度的伪标签，增强单模型架构，从根本上避免了模型间预测偏差。此外，通过将伪标签转化为包含领域知识的混合提示，ST-SAM有效利用了Segment Anything Model的潜力，以减少自训练过程中的错误累积。实验表明，ST-SAM仅使用1%的标记数据就能达到最先进的性能，超越了现有SSCOD方法，并且达到了完全监督方法的水平。值得注意的是，ST-SAM仅需训练一个网络，无需依赖特定模型或损失函数，为标注效率的SSCOD树立了新范式。", "conclusion": "实验结果显示，ST-SAM在COD基准数据集上实现了最先进的性能，仅使用1%的标记数据，比现有SSCOD方法性能更优，甚至达到了完全监督方法的水平。ST-SAM仅需训练一个网络，无需依赖特定模型或损失函数。这项工作为标注效率的SSCOD提出了一种新范式。代码将发布在指定网址。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23313", "html_url": "https://arxiv.org/abs/2507.23313", "title": "伦勃朗的牛 - 分析文本到图像模型中的艺术提示解释", "title_en": "The Cow of Rembrandt - Analyzing Artistic Prompt Interpretation in Text-to-Image Models", "authors": "Alfio Ferrara,Sergio Picascia,Elisabetta Rocchetti", "background": "文本到图像扩散模型通过学习数以亿计的图像，包括流行的艺术作品，展示了生成艺术内容的惊人能力。然而，这些模型如何内部表示概念，如绘画中的内容和风格，这一基础问题尚未得到解答。传统计算机视觉假设内容和风格是相互独立的，但扩散模型在训练过程中没有明确的指导使其区分这两者。本文探讨了基于变压器的文本到图像扩散模型在生成艺术品时如何编码内容和风格概念。利用交叉注意力热图将生成图像中的像素归因于特定的提示标记，以便隔离由描述内容和描述风格的标记影响的图像区域。研究表明，扩散模型在特定的艺术提示和风格请求情况下，表现出不同程度的内容与风格分离。通常情况下，内容标记主要影响与物体相关区域，而风格标记影响背景和纹理区域，表明扩散模型对内容与风格的区分有了自发的理解。这些发现有助于我们理解大规模生成模型如何在无明确监督的情况下内部表示复杂的艺术概念。", "innovation": "本文利用交叉注意力热图将生成图像中的像素归因于特定的提示标记，首次细化了生成模型中内容与风格解耦的表现形式，揭示了根据具体艺术品提示和风格请求，内容和风格的影响区域有所不同，模型对内容与风格的区分表现出自发的理解。此外，作者公开了代码和数据集，并提供了一个工具以可视化注意力图，有助于进一步研究和探索。", "conclusion": "实验发现表明，基于变压器的文本到图像扩散模型能够根据提供的艺术提示和要求风格式样，表现出不同程度内容与风格的区分。多数情况下，描述内容的标记主要影响与物体相关的图像区域，而描述风格的标记则影响背景和纹理部分。这种对内容与风格概念的理解有助于进一步理解大规模生成模型内部如何表示复杂的艺术概念，而不依赖于显式的监督。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23309", "html_url": "https://arxiv.org/abs/2507.23309", "title": "PriorFusion: 统一融合先验信息以增强自主驾驶环境中的道路感知鲁棒性", "title_en": "PriorFusion: Unified Integration of Priors for Robust Road Perception in Autonomous Driving", "authors": "Xuewei Tang,Mengmeng Yang,Tuopu Wen,Peijin Jia,Le Cui,Mingshang Luo,Kehua Sheng,Bo Zhang,Diange Yang,Kun Jiang", "background": "随着对自主驾驶的兴趣不断增长，对于准确可靠的道路感知技术的需求也在增加。在复杂的环境且缺乏高精度地图支持的情况下，自主车辆必须独立地解释其周围的环境以确保安全和稳健的决策。然而，这些场景带来了巨大的挑战，因为道路元素的数量庞大、几何结构复杂且频繁被遮挡。现有方法的主要局限性在于未能充分利用道路元素中固有的结构性先验知识，从而导致非规则和不准确的预测结果。因此，急需一种高效整合并利用这些结构性先验知识的方法来改善道路感知的准确性。", "innovation": "提出了PriorFusion，一种统一框架，有效地整合语义、几何和生成先验信息来提高道路元素的感知能力。通过引入实例感知的注意力机制来利用形状先验特征，然后构建数据驱动的形状模板空间，编码道路元素的低维表示并进行聚类生成锚点作为参考先验信息。设计了一种扩散框架来利用这些先验锚点生成准确和完整的预测。实验结果证明，在大规模自主驾驶数据集上，该方法显著提高了感知准确性，尤其是在复杂条件下。可视化结果进一步证明了该方法生成了更准确、更规则和更连贯的道路元素预测。", "conclusion": "实验结果表明，我们的方法在广泛的无人驾驶数据集上显著提高了感知准确性，特别是在困难条件下。可视化结果显示，我们的方法生成了更准确、更规则和更连贯的道路元素预测。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23318", "html_url": "https://arxiv.org/abs/2507.23318", "title": "FastDriveVLA: 通过Plug-and-Play基重建式标记剪枝实现高效端到端驾驶", "title_en": "FastDriveVLA: Efficient End-to-End Driving via Plug-and-Play Reconstruction-based Token Pruning", "authors": "Jiajun Cao,Qizhe Zhang,Peidong Jia,Xuhui Zhao,Bo Lan,Xiaoan Zhang,Xiaobao Wei,Sixiang Chen,Zhuo Li,Yang Wang,Liyun Li,Xianming Liu,Ming Lu,Shanghang Zhang", "background": "视觉-语言-行动（VLA）模型在复杂场景理解和行动推理方面显示出巨大的潜力，因此在端到端自动驾驶系统中的应用越来越广泛。然而，VLA模型中的长视觉标记大大增加了计算成本。当前用于视觉语言模型（VLM）的视觉标记剪枝方法依赖于视觉标记相似性或视觉-文本注意，但在自动驾驶场景中表现不佳。鉴于人类驾驶员在驾驶过程中会专注于相关前景区域，我们主张保留包含这些前景信息的视觉标记对于有效的决策至关重要。", "innovation": "我们提出了FastDriveVLA，这是一种针对自动驾驶设计的新型重建式视觉标记剪枝框架。FastDriveVLA包含了一个名为ReconPruner的即插即用视觉标记剪枝器，它通过MAE样式像素重建优先保留前景信息。还设计了一种新颖的对抗前景-背景重建策略来训练ReconPruner以适应VLA模型的视觉编码器。我们还引入了一个名为nuScenes-FG的大规模数据集，包含241K带有标注前景区域的图像-掩码对。此外，ReconPruner可以在不同VLA模型的相同视觉编码器上无缝应用，无需重新训练。", "conclusion": "我们的方法在不同剪枝比例下都取得了nuScenes封闭环规划基准的最新成果。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23340", "html_url": "https://arxiv.org/abs/2507.23340", "title": "MagicRoad：基于障碍物修复的语义感知3D路面重建", "title_en": "MagicRoad: Semantic-Aware 3D Road Surface Reconstruction via Obstacle Inpainting", "authors": "Xingyue Peng,Yuandong Lyu,Lang Zhang,Jian Zhu,Songtao Wang,Jiaxin Deng,Songxin Lu,Weiliang Ma,Dangen She,Peng Jia,XianPeng Lang", "background": "自主驾驶依赖于高精度的道路表面重建，以支持厘米级道路车道感知和高精度地图构建。目前的一些方法虽然在清洁且静止条件下表现良好，但在动态障碍的遮挡、静态障碍的视觉杂乱以及光照和天气变化导致的外观退化方面仍存在缺陷。这种背景下，本文提出了一种鲁棒的路面重建框架，该框架通过结合语义引导的色彩增强和感知遮挡的二维高斯表面元重建技术来恢复清晰且一致的路面表面。", "innovation": "该方法利用针对平面的高斯表示进行高效的大规模建模，并采用语义引导的视频修复技术去除动态和静态前景物体，通过语义感知的HSV空间色彩一致性增强来提升色彩连贯性。实验结果显示，该框架在真实世界条件下显著优于先前的方法，生成了视觉上连贯且几何上忠实的重建结果。", "conclusion": "本文提出的方法在城市规模数据集上进行了大量实验，展示了在真实世界条件下其产生的视觉连贯且几何忠实的重建效果，显著优于先前的方法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23371", "html_url": "https://arxiv.org/abs/2507.23371", "title": "VMatcher: 状态空间半密集局部特征匹配", "title_en": "VMatcher: State-Space Semi-Dense Local Feature Matching", "authors": "Ali Youssef", "background": "基于学习的特征匹配方法，无论是基于检测器的还是无检测器的，都能达到最先进的性能，但都严重依赖于Transformer的注意力机制。虽然这种方法有效，但由于其计算复杂性呈平方级增长，因此计算成本较高。相比之下，Mamba引入了一种选择性状态空间模型(Selective State-Space Model, SSM)以实现与线性复杂度相当或更好的性能，从而带来显著的效率提升。", "innovation": "VMatcher结合了Mamba的高效长序列处理与Transformer的注意力机制，提出了多种VMatcher配置，包括分层架构。这些配置在实时应用中表现出高效性、鲁棒性和实用性，能够设置新的基准，这是至关重要的快速推理。", "conclusion": "VMatcher利用了Mamba和Transformer各自的优点，通过多种配置展示出了高效的性能，确保了在需要快速推理的实时应用中的鲁棒性和实用性。源代码可从提供的链接获取。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23315", "html_url": "https://arxiv.org/abs/2507.23315", "title": "轻量级深度学习模型实时图像分类准确性的超参数优化影响", "title_en": "Impact of Hyperparameter Optimization on the Accuracy of Lightweight Deep Learning Models for Real-Time Image Classification", "authors": "Vineet Kumar Rakesh,Soumya Mazumdar,Tapas Samanta,Sarbajit Pal,Amitabha Das", "background": "轻量级卷积和Transformer模型由于在嵌入式系统和边缘设备等资源受限应用中的实时图像分类需求而变得至关重要。本文研究了超参数调整对七个高效的深度学习架构（EfficientNetV2-S、ConvNeXt-T、MobileViT v2（XXS/XS/S）、MobileNetV3-L、TinyViT-21M和RepVGG-A2）在ImageNet-1K数据集上训练精度与收敛行为的影响，特别强调了实时实用性。所有模型都在统一的训练设置下进行训练，并对关键超参数（如学习率调度、批量大小、输入分辨率、数据增强、正则化方法和优化器选择）进行了全面的消融研究。", "innovation": "研究进行了全面的消融研究以分离关键超参数的影响，并深入分析了这些超参数（如余弦学习率衰减和可调批量大小）对模型精度和收敛速度的提升作用，同时保持低延迟和内存成本。研究中，RepVGG-A2在高效推理性能下达到了超过80%的Top-1准确性，为VGG风格模型提供了一个在准确性和部署成本之间取得良好平衡的选择。", "conclusion": "研究结果为构建适用于实时图像处理流水线的资源高效深度学习模型提供了实用指导。所有代码和训练日志均公开提供。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23325", "html_url": "https://arxiv.org/abs/2507.23325", "title": "FASTopoWM：快慢车道段拓扑推理与潜在世界模型", "title_en": "FASTopoWM: Fast-Slow Lane Segment Topology Reasoning with Latent World Models", "authors": "Yiming Yang,Hongbin Lin,Yueru Luo,Suzhong Fu,Chao Zheng,Xinrui Yan,Shuqi Mei,Kun Tang,Shuguang Cui,Zhen Li", "background": "车道段拓扑推理能够提供全面的鸟瞰视角道路场景理解，是面向规划的目标端到端自动驾驶系统的关键感知模块。现有的车道拓扑推理方法在有效利用时间信息以增强检测和推理性能方面存在不足。最近，基于流的时空传播方法通过在查询和鸟瞰视角层面都引入时间线索展示了有前景的结果，然而依然受限于对历史查询的过度依赖、姿态估计失败的脆弱性以及时间传播不充分。", "innovation": "论文提出了一种名为FASTopoWM的新型快慢车道段拓扑推理框架，结合了潜在世界模型。该框架通过统一框架并行监督历史和新初始化的查询，促进快慢系统之间的相互强化，并在过往观察中引入条件于动作潜变量的潜在查询和鸟瞰视角世界模型以传播状态表示到当前时间点。这在慢管道中显著改善了时间感知性能。", "conclusion": "在OpenLane-V2基准测试中，FASTopoWM在车道段检测（mAP上37.4%对33.6%）和主线感知（OLS上46.3%对41.5%）方面均优于最先进的方法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23331", "html_url": "https://arxiv.org/abs/2507.23331", "title": "对比学习驱动的交通标志感知：文本和视觉的多模态融合", "title_en": "Contrastive Learning-Driven Traffic Sign Perception: Multi-Modal Fusion of Text and Vision", "authors": "Qiang Lu,Waikit Xiu,Xiying Li,Shenyu Hu,Shengbo Sun", "background": "交通标志识别作为自动驾驶感知系统的核心组成部分，直接关系到车辆的环境意识和驾驶安全性。现有技术面临两个重大挑战：第一，交通标志数据集具有明显的长尾分布，导致传统卷积网络在处理低频和分布外类别时识别性能大幅下降；第二，现实场景中的交通标志通常是小目标，具有显著的尺度变化，难以提取多尺度特征。", "innovation": "为解决这些问题，我们提出了一种新颖的两阶段框架，结合了开放词汇检测和跨模态学习。对于交通标志检测，我们的NanoVerse YOLO模型集成了可参数化的视觉-语言路径聚合网络（RepVL-PAN）和SPD-Conv模块，专门增强了小、多尺度目标的特征提取。对于交通标志分类，我们设计了交通标志识别多模态对比学习模型（TSR-MCL）。通过对比来自视觉变压器的视觉特征与来自基于规则的BERT的语义特征，TSR-MCL学习到了稳健的、频率无关的表示，有效缓解了由数据不平衡引起的目标混淆。", "conclusion": "在TT100K数据集上，我们的方法在全类识别的长尾检测任务中取得了78.4%的mAP。该模型也获得了91.8%的准确率和88.9%的查全率，显著优于主流算法，在复杂开放世界场景中显示出优越的准确性和泛化能力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23343", "html_url": "https://arxiv.org/abs/2507.23343", "title": "谁是更好的谈吐者：AI生成的说话人头的主观和客观质量评估", "title_en": "Who is a Better Talker: Subjective and Objective Quality Assessment for AI-Generated Talking Heads", "authors": "Yingjie Zhou,Jiezhang Cao,Zicheng Zhang,Farong Wen,Yanwei Jiang,Jun Jia,Xiaohong Liu,Xiongkuo Min,Guangtao Zhai", "background": "随着Text-to-Image (T2I) 模型的快速发展，AI生成的说话人头（AGTHs）已经逐渐成为一种新兴的数字人类媒体。然而，这些AGTHs的质量问题依然存在，并缺乏综合性的研究来解决这些挑战。因此，本文介绍了迄今为止最大的AGTH质量评估数据集THQA-10K，旨在填补这一研究空白。该数据集选择了12种流行的T2I模型和14种先进的谈吐者来生成指导意见，最终筛选出了10,457个AGTHs，用于主观和客观评价的质量测试。", "innovation": "本文的主要创新点在于构建了一个名为THQA-10K的大型AGTH质量评估数据集，并提出了基于第一帧、Y-T切片和声调嘴唇一致性的一套客观质量评估方法。这种方法在AGTH质量评估的实验结果中达到了最先进的性能。此外，通过这项研究还揭示了现有AGTHs存在的诸多缺陷和技术挑战。", "conclusion": "本文的研究结果表明，我们提出的客观质量评估方法在AGTH质量评估上表现优异，并为改善AI生成的说话人头的质量提供了重要参考。该数据集和方法对于进一步的研究和开发具有重要意义，同时也揭示了进一步提升AGTH品质的技术需求。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23341", "html_url": "https://arxiv.org/abs/2507.23341", "title": "图像分辨率对人脸检测的影响：MTCNN、YOLOv XI和YOLOv XII模型的比较分析", "title_en": "The Impact of Image Resolution on Face Detection: A Comparative Analysis of MTCNN, YOLOv XI and YOLOv XII models", "authors": "Ahmet Can Ömercikoğlu(1),Mustafa Mansur Yönügül(1),Pakize Erdoğmuş(1) ((1) Düzce University, Department of Computer Engineering, Düzce, Türkiye)", "background": "人脸检测是许多AI驱动应用的关键组成部分，包括监控、生物认证和人机交互等。然而，低分辨率图像等现实环境条件会显著影响检测性能。", "innovation": "本文系统地研究了输入分辨率对三种主流基于深度学习的人脸检测器（YOLOv11、YOLOv12和MTCNN）准确性和鲁棒性的影响。通过WIDER FACE数据集，本文在不同分辨率图像（160x160、320x320、640x640）上进行了广泛评估，并使用精度、召回率、mAP50、mAP50-95和推理时间等指标来评估每个模型的表现。", "conclusion": "研究结果表明，YOLOv11在检测准确性方面优于YOLOv12和MTCNN，尤其是在高分辨率下表现更为出色；YOLOv12在召回率方面稍有优势；尽管MTCNN在关键点定位方面具有竞争力，但在实时推理速度方面却落后。本研究提供了有关选择适应不同操作条件的分辨率感知人脸检测模型的实用见解。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23372", "html_url": "https://arxiv.org/abs/2507.23372", "title": "UniEmo: Learnable Expert Queries统一情感理解和生成", "title_en": "UniEmo: Unifying Emotional Understanding and Generation with Learnable Expert Queries", "authors": "Yijie Zhu,Lingsen Zhang,Zitong Yu,Rui Shao,Tao Tan,Liqiang Nie", "background": "情感理解和生成通常被当作两个独立的任务处理，但实际上它们是互补的，并能互相提升对方。情感的理解和生成之间的直接联系和互补性使将它们统一处理成为一个新的研究领域。传统的做法只是独立地处理这两个任务，未能充分探索它们之间的内在联系和协同作用，这限制了模型在情感处理的广度和深度方面的能力提升。这项研究的目标就是通过一种称为UniEmo的统一框架，无缝地整合情感理解和生成两个任务，以提高模型在这两个方面的能力。", "innovation": "本文提出了一种名为UniEmo的统一框架，它通过一个可学习的专家查询层级构建的情感理解链来提取多尺度的情感特征，从而有效地整合了情感理解和生成任务。此外，该框架通过融合专家查询和情感表示来指导扩散模型生成情感驱动的图像，并引入情感相关系数和情感条件损失，以增强生成的情感图像的多样性和真实性。此外，本文还提出了一种新的数据过滤算法，用于选择高质量和多样化的由训练好的模型生成的情感图像，这些图像既能用于情感生成又能反向反馈至理解部分。这些生成驱动的双向反馈机制增强了模型的理解能力。", "conclusion": "大量实验证明，UniEmo在情感理解和生成方面均显著优于现有最先进的方法。生成驱动的双向反馈机制显著提升了模型的理解能力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23362", "html_url": "https://arxiv.org/abs/2507.23362", "title": "Short-LVLM: 通过剪枝冗余层压缩和加速大型视觉语言模型", "title_en": "Short-LVLM: Compressing and Accelerating Large Vision-Language Models by Pruning Redundant Layers", "authors": "Ji Ma,Wei Suo,Peng Wang,Yanning Zhang", "background": "尽管大型多模态模型（LVLM）在跨模态理解和推理方面展现出了令人印象深刻的性能，但由于庞大的模型参数和高昂的计算成本限制了其实际应用。最近，自然语言处理（NLP）领域通过剪枝层的方法展示了其有效性，提供了一种无训练的压缩解决方案。然而，由于视觉和语言模态之间的差异，这些NLP技术在LVLM中的效果仍有待验证。该研究通过实验证明直接将这些方法应用到LVLM中是无效的，并发现非必要的视觉-语言（VL）令牌和跨层特征差距是剪枝层的关键挑战。", "innovation": "该研究提出了一种新框架Short-LVLM，能够利用重要的VL令牌并缓解跨层特征差距。Short-LVLM不仅在保持性能的同时提高了效率，还具备无训练、模型兼容性高的潜在优势。", "conclusion": "该研究通过实验证明了直接应用NLP中的层剪枝方法到LVLM中的无效性，提出了Short-LVLM框架以缓解这些问题。该框架提高了整体性能与效率之间的权衡，并且还具备无训练、模型兼容等优势。相关代码已公开发布。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23357", "html_url": "https://arxiv.org/abs/2507.23357", "title": "IN45023 2025年夏季计算机视觉神经网络设计模式研讨报告", "title_en": "IN45023 Neural Network Design Patterns in Computer Vision Seminar Report, Summer 2025", "authors": "Radu-Andrei Bourceanu,Neil De La Fuente,Jan Grimm,Andrei Jardan,Andriy Manucharyan,Cornelius Weiss,Roman Pflugfelder", "background": "本报告通过分析六篇具有影响力的论文，考察了计算机视觉中的关键设计模式的演变。研究始于对图像识别基础架构的分析，特别是使用残差连接来解决梯度消失问题并实现更深的卷积网络的有效训练的方法。接着，分析了Vision Transformer (ViT)，该架构将Transformer架构应用到图像补丁序列中，证明了基于注意力模型在大规模图像识别中的有效性。在此基础上，报告探讨了生成模型，包括Generative Adversarial Networks (GANs) 和 Latent Diffusion Models (LDMs)，这些模型分别通过新的对抗训练过程和感知压缩潜在空间中的序列去噪处理提高了图像生成的综合性与效率。最后，讨论了减少对标注数据依赖的自监督学习技术，包括DINO和Masked Autoencoders (MAE)，前者通过师生网络之间的学习实现了强大的最近邻分类性能，后者则利用不对称的编码器-解码器设计用于重建高度掩码的输入，从而提供了一种高效且可扩展的方法来预训练大规模视觉模型的方法。", "innovation": "报告创新地采用了对比分析的方法，探讨了计算机视觉中几种关键设计模式的发展轨迹。创新点包括：1) 通过引入残差连接克服了梯度消失问题；2) 将Transformer应用于图像识别中，开创了基于注意力模型的大规模图像识别的新范式；3) 研究了GANs和LDMs在生成模型中的应用及其优越性；4) 探讨了自监督学习技术，特别是DINO和MAE，提高了模型的预训练效率和可扩展性。", "conclusion": "本报告总结了计算机视觉中神经网络设计模式的最新研究进展。关键技术包括：1) 残差连接在深卷积网络训练中的应用；2) Transformer在图像识别中的创新应用；3) GANs和LDMs在生成模型中的进展；4) 自监督学习方法如DINO和MAE在减少标注数据依赖和提高模型效率方面的作用。报告强调了这些技术的发展趋势，展示了不断进步和创新带来的最先进的图像生成和识别能力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23374", "html_url": "https://arxiv.org/abs/2507.23374", "title": "NeRF-GS：NeRF 是 3D 高斯点绘的强大辅助工具", "title_en": "NeRF Is a Valuable Assistant for 3D Gaussian Splatting", "authors": "Shuangkang Fang,I-Chao Shen,Takeo Igarashi,Yufeng Wang,ZeSheng Wang,Yi Yang,Wenrui Ding,Shuchang Zhou", "background": "3D Gaussian Splatting (3DGS) 方法在处理3D场景时存在对高斯初始化敏感、空间认知有限和高斯之间的弱相关性等问题，限制了其性能。Neural Radiance Fields (NeRF) 则因其对连续空间的内在表示能力，可以有效地解决这些问题。因此，研究者们提出了将NeRF与3DGS融合的新框架，以提升3D场景表示的效率和效果。", "innovation": "该研究创新性地引入了NeRF-GS框架，这是将NeRF与3DGS共同优化的新方法。该框架重新设计了3DGS，并逐步调整其空间特征与NeRF对齐，使两者可以在相同场景下共享3D空间信息进行优化。此外，该方法还通过优化残差向量和高斯位置来增强3DGS的个性化能力。实验结果表明，NeRF-GS超越了现有的方法，并实现了最先进的性能。这表明NeRF和3DGS是互补而非竞争的关系，为结合3DGS和NeRF进行高效3D场景表示提供了新的启示。", "conclusion": "实验结果表明NeRF-GS在基准数据集上超越了现有方法，并达到了最先进的性能。这证实了NeRF和3DGS是互补而非竞争的方法，为将3DGS和NeRF结合以实现高效的3D场景表示提供了新的见解。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23416", "html_url": "https://arxiv.org/abs/2507.23416", "title": "使用高光谱成像和机器学习检测蜂蜜掺假", "title_en": "Honey Adulteration Detection using Hyperspectral Imaging and Machine Learning", "authors": "Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh", "background": "蜂蜜中含有糖浆等添加剂的掺假问题十分严重，现有化学检测方法存在一定的局限性，如成本高、操作复杂等。因此，开发一种基于高光谱成像数据的机器学习系统来自动检测蜂蜜掺糖的问题变得尤为重要。该系统首先通过植物源识别子系统分类蜂蜜的植物来源，接着通过掺假检测子系统识别糖浆掺假并量化其浓度。该系统使用线性判别分析提取特征，并利用K近邻模型进行分类和检测。该研究在公共高光谱图像数据集上评估了所提出系统的性能，结果表明，该系统能够以96.39%的整体交叉验证准确率检测蜂蜜掺假，提供了一种比当前化学检测方法更有效的方法。", "innovation": "开发了一种基于高光谱成像数据和机器学习的系统，用于自动检测蜂蜜掺糖，并通过线性判别分析和K近邻模型实现对蜂蜜植物来源的分类和掺假水平的检测，具有较高的准确率和适用性，为蜂蜜质量检测提供了新的解决方案。", "conclusion": "所提出的系统在公共高光谱图像数据集上的测试结果显示，整体交叉验证准确率达到96.39%，表明该系统具有良好的检测掺糖蜂蜜的能力，是一种合适替代现有化学检测方法的有效自动检测工具。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23373", "html_url": "https://arxiv.org/abs/2507.23373", "title": "多提示渐进对齐多源无监督域适应", "title_en": "Multi-Prompt Progressive Alignment for Multi-Source Unsupervised Domain Adaptation", "authors": "Haoran Chen,Zexiao Wang,Haidong Cao,Zuxuan Wu,Yu-Gang Jiang", "background": "大型视觉-语言模型如CLIP因其实现强零样本泛化而成为无监督域适应领域的强基础模型。当前先进的方法常用CLIP生成目标域的伪标签，然后通过微调模型来学习域不变特征，但这些方法通常一次性对齐源域和目标域的所有伪标签数据，这种方法在遇到噪声大、难以分类的样本时，会引发标签传播错误，导致特征学习效果不佳。在多源场景中，不同数据源之间的域差距和噪声水平的多样性会进一步削弱对齐过程的稳定性。", "innovation": "本文提出了一种渐进对齐策略，用于适应CLIP到无标记下游任务。该方法首先在具有高置信度的目标样本子集上进行训练，使模型可以从最可靠的数据中学习到很好的对齐表示。随着训练的进展，逐渐引入更具有挑战性的样本，指导模型不断进行理解和优化。这种方法有效地减少了确认偏差，促进了更稳健的收敛，使得模型能够学习真正意义上的域不变特征。", "conclusion": "本文的方法MP^2A在三个流行的无监督域适应基准数据集（ImageCLEF、Office-Home和DomainNet）上进行测试，展示了在最近CLIP基于多源无监督域适应方法中的最优性能，证明了该方法的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23436", "html_url": "https://arxiv.org/abs/2507.23436", "title": "超越线性瓶颈：基于样条的知識蒸餾在多元文化艺术风格分类中的应用", "title_en": "Beyond Linear Bottlenecks: Spline-Based Knowledge Distillation for Culturally Diverse Art Style Classification", "authors": "Abdellah Zakaria Sellam,Salah Eddine Bekhouche,Cosimo Distante,Abdelmalik Taleb-Ahmed", "background": "艺术风格分类在计算美学中仍然是一项艰巨的挑战，主要原因在于缺乏精确标注的数据集和样式元素之间的复杂、往往是非线性的交互关系。虽然最近的双教师自监督框架减少了对标注数据的依赖，但它们的线性投影层和局部关注点难以建模全局构图上下文和复杂的风格特征交互。", "innovation": "我们通过将传统的MLP投影和预测头部替换为科莫戈罗夫-阿诺德网络（KANs），增强双教师知识蒸餾框架，以解决这些问题。这种方法保留了两个教师网络的互补指导，一个强调局部纹理和笔画模式，另一个捕捉更广泛的样式层次结构，同时利用KANs的样条基激活来以数学精确的方式建模非线性特征相互作用。实验结果显示，相比基线双教师架构，我们的方法在Top-1准确率上表现更优。我们的发现强调了KANs在分离复杂风格流形方面的关键性，从而提高了线性探针的准确性，超过了MLP投影。", "conclusion": "我们的研究结果表明，KANs在处理复杂风格问题中具有重要作用，并且能够提高艺术风格分类的精度。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23411", "html_url": "https://arxiv.org/abs/2507.23411", "title": "通过扩散轨迹在医学成像中进行分布外检测", "title_en": "Out-of-Distribution Detection in Medical Imaging via Diffusion Trajectories", "authors": "Lemar Abdi,Francisco Caetano,Amaan Valiuddin,Christiaan Viviers,Hamdi Joudeh,Fons van der Sommen", "background": "在医学成像中，无监督的分布外（OOD）检测提供了一种有吸引力的方法来识别发病率极低的病理病例。与其他监督方法不同，基于OOD的方法不依赖标签且天然具备对数据不平衡的鲁棒性。当前的生成方法通常依赖于似然估计或重构误差，但这些方法计算成本高昂、不够可靠，并且如果内点数据发生变化需要重新训练。这些限制阻碍了它们在区分正常和异常输入时能够高效、一致且鲁棒地进行区分。", "innovation": "本文提出了一种无需重构的OOD检测方法，该方法利用基于Stein评分的去噪扩散模型（Stein Score-based Denoising Diffusion Model，SBDDM）的前向扩散轨迹。通过利用估计的Stein评分捕捉轨迹曲率，该方法仅需五步扩散步骤就可以实现准确的异常评分。通过在一个大型的语义对齐的医学数据集上预训练一个单一的SBDDM，该方法能够跨越多个Near-OOD和Far-OOD基准测试实现广泛的泛化效果，达到了最先进的性能，并大幅降低了推理过程中的计算成本。SBDDM在近端OOD和远端OOD检测中分别取得了高达10.43%和18.10%的相对改进，使其成为实时可靠计算机辅助诊断的实用构建模块。", "conclusion": "与现有方法相比，SBDDM能够在近端OOD和远端OOD检测中显著提高精度，是一个实用的实时可靠计算机辅助诊断的构建模块。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23479", "html_url": "https://arxiv.org/abs/2507.23479", "title": "少而精：多任务学习下的视频胶囊内镜", "title_en": "Seeing More with Less: Video Capsule Endoscopy with Multi-Task Learning", "authors": "Julia Werner,Oliver Bause,Julius Oexle,Maxime Le Floch,Franz Brinkmann,Jochen Hampe,Oliver Bringmann", "background": "视频胶囊内镜在胃肠道的小肠区域检查中越来越重要，但传感器设备的电池寿命较短是持续存在的挑战。通过集成人工智能，可以实现智能实时决策，从而减少能源消耗并延长电池寿命。然而，由于数据稀疏和设备资源有限限制了整体模型的大小，这仍然是个挑战。", "innovation": "介绍了结合精准自我定位和小肠异常检测功能的多任务神经网络，集成已验证的多任务方法和Viterbi解码用于时间序列分析，该方法在使用最近发布的Galar数据集时优于现有的单一任务模型，并且参数量仅为100万，超越当前基准。", "conclusion": "我们的模型在定位任务中的准确率为93.63%，在异常检测任务中的准确率为87.48%，且仅需100万个参数，显著提升了基于AI的方法在该领域的研究水平。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23455", "html_url": "https://arxiv.org/abs/2507.23455", "title": "机器学习与胸部X光图像中的机器学习预测", "title_en": "Machine learning and machine learned prediction in chest X-ray images", "authors": "Shereiff Garrett,Abhinav Adhikari,Sarina Gautam,DaShawn Marquis Morris,Chandra Mani Adhikari", "background": "机器学习和人工智能是快速发展的研究领域，利用数据来训练算法、识别模式并进行预测。这种方法有助于解决看似复杂的问题，并实现显著的准确性，而无需显式编程。许多问题可以通过识别数据中的复杂关系来解决。本研究利用5824张胸部X光图像，展示了两种机器学习算法的应用情况，分别是一个基础卷积神经网络（CNN）和DenseNet-121，用于预测患者的病情。这两种算法在本研究提出的问题上表现良好，梯度加权类别激活映射显示，相比于基础CNN，DenseNet-121在决策过程中更能准确地聚焦于输入胸部X光图像的关键部分", "innovation": "本研究采用DenseNet-121模型在胸部X光图像中进行机器学习预测，通过梯度加权类别激活映射验证了DenseNet-121相较于基础CNN模型在识别关键部位方面具有更高的准确性", "conclusion": "DenseNet-121和基础CNN在二分类问题上表现出色，证明它们适用于胸部X光异常预测任务。梯度加权类别激活映射支持DenseNet-121在预测过程中更为准确地聚焦于关键图像部分"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23402", "html_url": "https://arxiv.org/abs/2507.23402", "title": "AGA: 一种适用于结构化医疗跨模态表示学习的自适应组对齐框架", "title_en": "AGA: An adaptive group alignment framework for structured medical cross-modal representation learning", "authors": "Wei Li,Xun Gong,Jiao Li,Xiaobin Sun", "background": "在医学领域，通过配对的医疗图像和报告学习医学视觉表示是一个有前景的方向。然而，当前的视觉-语言预训练方法往往将临床报告简化为单一实体或碎片化标记，忽视了其固有的结构。此外，对比学习框架通常依赖大量的困难负样本，这对小规模医疗数据集来说是不现实的。", "innovation": "本文提出了自适应组对齐（AGA），这是一种新的框架，用于从配对的医学图像和报告中捕获结构化的语义。AGA引入了一种基于稀疏相似矩阵的双向分组机制。对于每个图像-报告配对，我们计算文本标记和图像片段间的细粒度相似性。每个标记选择其匹配度最高的片段形成视觉组，每个片段选择其最相关的标记形成语言组。为了实现自适应分组，我们设计了两种阈值门限模块，即语言组阈值门限和视觉组阈值门限，这些模块能够动态地学习分组阈值。组表示是基于相似性得分的加权平均计算的。为了使每个标记与组表示对齐，我们引入了一种实例引导组对齐损失，该损失在每个图像-文本配对内部操作，消除了外部负样的需要。最后，双向跨模态组对齐模块被应用以增强视觉和语言组表示之间的细粒度对齐。", "conclusion": "在公共和私有数据集上的大量实验表明，本文的方法在微调和零样本设置下，对于医疗图像-文本检索和分类任务都取得了良好的性能。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23461", "html_url": "https://arxiv.org/abs/2507.23461", "title": "在联邦学习中缓解关键点检测中的分辨率漂移", "title_en": "Mitigating Resolution-Drift in Federated Learning: Case of Keypoint Detection", "authors": "Taeheon Lim,Joohyung Lee,Kyungjae Lee,Jungchan Cho", "background": "联邦学习（FL）可在分布式系统之间有效地进行学习，同时保护用户数据的隐私。目前的研究主要关注如何解决统计异质性和通信效率的问题，从而在分类任务中取得了成功。然而，对于非分类任务如人体姿态估计而言，联邦学习的应用仍然较少研究。在这些任务中，分辨率变化导致了性能显著下降的问题亟待解决。", "innovation": "本文提出了分辨率自适应联邦学习（RAF），这是一种利用基于热图的知识蒸馏来缓解分辨率漂移的方法。RAF通过高、低分辨率之间的多分辨率知识蒸馏，提升了分辨率的鲁棒性，同时避免了过拟合。实验和理论分析表明，RAF不仅有效地缓解了分辨率漂移问题，还提高了性能，并且能够无缝集成到现有的联邦学习框架中。此外，尽管本文专注于人体姿态估计，但通过t-SNE分析发现，分类任务和高分辨率表示任务之间存在显著差异，支持RAF在其他依赖精确空间细节的任务中的泛化能力。", "conclusion": "本文提出了一种解决分辨率漂移问题的联邦学习方法——分辨率自适应联邦学习（RAF）。通过多分辨率热图知识蒸馏，RAF提高了分辨率鲁棒性，改进了性能，并且能够很好地集成到现有的联邦学习框架中。此外，本文还表明RAF在其他依赖空间细节的任务中具有良好的泛化能力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23447", "html_url": "https://arxiv.org/abs/2507.23447", "title": "Adjustable Spatio-Spectral Hyperspectral Image Compression Network", "title_en": "Adjustable Spatio-Spectral Hyperspectral Image Compression Network", "authors": "Martin Hermann Paul Fuchs,Behnood Rasti,Begüm Demir", "background": "随着遥感（RS）领域 hyperspectral 数据档案的快速增长，高效存储的需求变得尤为重要，推动了基于学习的高光谱图像（HSI）压缩方法的研究。然而，目前尚未全面研究光谱和空间压缩单独及联合效应对基于学习的 HSI 压缩的影响，这对于理解光谱、空间以及联合光谱-空间冗余如何影响 HSI 压缩至关重要。现有压缩模型在这方面的平衡效果有待提升。", "innovation": "文章提出了Adjustable Spatio-Spectral Hyperspectral Image Compression Network (HyCASS)模型，这是一种用于光谱和空间压缩维度可调的基于学习的HSI压缩网络。HyCASS由六个主要模块组成：1) 光谱编码器；2) 空间编码器；3) 压缩率（CR）适配器编码器；4) 压缩率适配器解码器；5) 空间解码器；以及6) 光谱解码器模块。模型采用了卷积层和变压器块来捕捉短程和远程冗余。实验结果表明，HyCASS模型在两个HSI基准数据集上的表现优于现有基于学习的压缩模型。基于实验结果，文中提出了在不同压缩率下有效平衡光谱和空间压缩的指导方针，同时考虑HSI的空间分辨率。", "conclusion": "我们的代码和预训练模型权重已公开发布。我们的研究为基于学习的HSI压缩提供了一个新的框架，并提出了有效的光谱和空间压缩平衡策略，以适应不同的压缩率和HIS的空间分辨率。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23567", "html_url": "https://arxiv.org/abs/2507.23567", "title": "3D-MOOD: 拓展二维到三维进行单目开放集目标检测", "title_en": "3D-MOOD: Lifting 2D to 3D for Monocular Open-Set Object Detection", "authors": "Yung-Hsu Yang,Luigi Piccinelli,Mattia Segu,Siyuan Li,Rui Huang,Yuqian Fu,Marc Pollefeys,Hermann Blum,Zuria Bauer", "background": "单目3D目标检测对于机器人技术和AR/VR等应用十分重要。现有方法局限于封闭集场景，即训练集和测试集包含相同的场景和/或物体类别。然而，在实际应用中，新环境和未见过的物体类别经常出现，这给这些方法带来了挑战。", "innovation": "本文提出了一种端到端的3D单目开放集目标检测器（3DMOOD），通过设计3D边界框头部将开放集的2D检测提升到3D空间，实现2D和3D任务的联合端到端训练，从而提高整体性能。使用几何先验约束物体查询，使得3D估计在不同场景中有更好的泛化能力。为了进一步提高性能，设计了规范图像空间以进行更有效的跨数据集训练。", "conclusion": "我们在封闭集和开放集设置中评估3DMOOD，并在Omni3D和Omni3D到Argoverse 2、ScanNet中取得了新的最佳结果。代码和模型可在该链接获取。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23487", "html_url": "https://arxiv.org/abs/2507.23487", "title": "在田间条件下表观光合生长草莓质量的在线估计", "title_en": "Online Estimation of Table-Top Grown Strawberry Mass in Field Conditions with Occlusions", "authors": "Jinshan Zhen,Yuanyue Ge,Tianxiao Zhu,Hui Zhao,Ya Xiong", "background": "在田间条件下对表观光合生长草莓进行精确的质量估计仍然具有挑战性，因为经常会出现遮挡和姿态变化。", "innovation": "本文提出了一种基于视觉的流水线，结合RGB-D传感和深度学习，以实现非破坏性、实时和在线的质量估计。方法使用YOLOv8-Seg进行实例分割，使用周期一致生成对抗网络(CycleGAN)进行遮挡区域填充，并使用倾斜角度校正来改进正面投影面积计算。然后，采用多项式回归模型将几何特征映射到质量上。", "conclusion": "实验表明，孤立草莓的平均质量估计误差为8.11%，遮挡情况下的误差为10.47%。CycleGAN在遮挡恢复中优于大型遮罩修补模型(LaMa)，在像素面积比(PAR)和交集比(IoU)方面表现更好。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23480", "html_url": "https://arxiv.org/abs/2507.23480", "title": "FastPoint：通过采样点距离预测加速3D点云模型推理", "title_en": "FastPoint: Accelerating 3D Point Cloud Model Inference via Sample Point Distance Prediction", "authors": "Donghyun Lee,Dawoon Jeong,Jae W. Lee,Hongil Yoon", "background": "深度神经网络在3D点云处理中取得了革命性的进展，但高效处理大规模和不规则的点云仍然存在挑战。这一背景下，FastPoint作为一种新颖的软件加速技术，利用远点采样过程中采样点距离的可预测趋势，提出了无须计算所有成对距离来高效识别后续样本点的方法。", "innovation": "FastPoint通过预测距离曲线，能够在不必耗时计算所有成对距离的情况下高效确定后续采样点，从而显著加快最远点采样和邻居搜索操作的速度，同时保持采样质量和模型性能。将FastPoint集成到最先进的3D点云模型中，可以在NVIDIA RTX 3090 GPU上实现2.55倍的端到端加速，而不会牺牲准确性。", "conclusion": "通过FastPoint的引入，该研究显著提高了3D点云模型的推理速度，并证明了其在保持精度的同时，能够大幅改善大规模和不规则点云的处理效率。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23478", "html_url": "https://arxiv.org/abs/2507.23478", "title": "3D-R1: 提升3D视觉语言模型在统一场景理解中的推理能力", "title_en": "3D-R1: Enhancing Reasoning in 3D VLMs for Unified Scene Understanding", "authors": "Ting Huang,Zeyu Zhang,Hao Tang", "background": "现有多模态视觉语言模型（VLMs）在二维视觉理解任务上取得了显著进展，引发了将这些能力扩展到3D场景理解的兴趣。然而，当前的3D VLMs常常由于高质量的空间数据缺乏和视角假设的静态性，在鲁棒推理和泛化方面存在局限性。", "innovation": "为解决这些问题，本文提出了3D-R1，一种增强3D VLMs推理能力的基础模型。具体包括：1) 构建了一个名为Scene-30K的高质量合成数据集，利用现有的3D-VL数据集和基于Gemini 2.5 Pro的数据引擎；2) 在强化学习中使用RLHF策略，如GRPO来增强推理能力，并引入了感知奖励、语义相似性奖励和格式奖励三种奖励函数，以保持检测准确性和答案语义精准度；3) 引入动态视图选择策略，选择最有助于3D场景理解的视角。", "conclusion": "大量实验表明，3D-R1在各种3D场景基准测试中平均提高了10%的性能，突显了其在3D场景理解中增强推理能力和泛化能力的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23473", "html_url": "https://arxiv.org/abs/2507.23473", "title": "CST Anti-UAV: 一种适用于复杂场景中微小型无人机跟踪的热红外基准", "title_en": "CST Anti-UAV: A Thermal Infrared Benchmark for Tiny UAV Tracking in Complex Scenes", "authors": "Bin Xie,Congxuan Zhang,Fagan Wang,Peng Liu,Feng Lu,Zhen Chen,Weiming Hu", "background": "无人机（UAV）的广泛应用带来了重大的公众安全和隐私问题，使得无人机感知对于反无人机任务至关重要。然而，现有的无人机跟踪数据集主要包含了显眼的目标物体，缺乏场景复杂度和属性表示的多样性，限制了它们在真实世界场景中的应用。", "innovation": "我们提出了新的CST Anti-UAV数据集，专门用于复杂场景中的单目标跟踪（SOT），特别是微小型无人机。该数据集包含220段视频序列以及超过240K的高质量边界框标注，特别突出了两个关键特性：大量微小型无人机目标和多样且复杂的场景。据我们所知，CST Anti-UAV是首个包含完整人工帧级属性注释的数据集，这使得在多变的挑战下进行精确评估成为可能。", "conclusion": "实验证明，在复杂环境中跟踪微小型无人机仍然是一项挑战，最新的方法仅实现了35.92%状态精度，远低于在Anti-UAV410数据集上观察到的67.69%。这些发现强调了现有基准的局限性和无人机跟踪研究中需要进一步改进的需求。CST Anti-UAV基准即将公开发布，这不仅促进了更稳健的SOT方法的发展，还推动了反无人机系统的创新。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23543", "html_url": "https://arxiv.org/abs/2507.23543", "title": "ART: 自适应关系调谐以实现通用关系预测", "title_en": "ART: Adaptive Relation Tuning for Generalized Relation Prediction", "authors": "Gopika Sudhakaran,Hikaru Shindo,Patrick Schramowski,Simone Schaub-Meyer,Kristian Kersting,Stefan Roth", "background": "视觉关系检测（VRD）任务是识别场景中对象之间的关系。仅基于关系检测数据训练的VRD模型难以超越训练时的关系泛化。虽然已有研究使用提示调谐来适应视觉-语言模型（VLMs）进行VRD，但这种做法用的是手工设计的提示，难以处理新型复杂的关系。本文指出指令调谐能够通过在多样化的指导语数据上微调VLMs提供更有效的解决方案。本文介绍了一种自适应关系调谐（ART）框架，该框架通过指令调谐和策略性实例选择将VLMs适应于VRD任务。通过将VRD数据集转换为指令调谐格式并采用自适应采样算法，ART指导VLM聚焦于重要关系并保持泛化能力。具体而言，本文聚焦于关系分类任务，在给定主语-宾语框的情况下，模型预测两者之间的宾语。我们在保留集上进行调谐并在多个复杂度各异的保留测试数据集上进行评估。该方法在基准上表现优异，并能推断未见的关系概念，这是主流VRD方法所不具备的能力。我们通过使用预测关系进行复杂场景分割展示了ART的实际价值。", "innovation": "本文提出了自适应关系调谐（ART）框架，通过指令调谐和策略性实例选择来适应VRD任务。ART将视觉关系数据集转换为指令调谐格式并使用自适应采样算法，从而使VLM聚焦于重要关系并保持泛化能力。该方法能够在多个复杂度各异的保留测试数据集上表现出色，尤其在推断未见的关系概念上优于主流动态。", "conclusion": "ART框架在关系分类任务上与现有基线方法相比表现出显著提高，并展现了推断未见关系概念的能力，这是主流VRD方法所不具备的。通过使用预测关系来实现复杂场景分割，ART具备实际应用价值。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23599", "html_url": "https://arxiv.org/abs/2507.23599", "title": "DA-Occ: 通过方向性2D方法高效保全几何结构的3D体素占用率预测", "title_en": "DA-Occ: Efficient 3D Voxel Occupancy Prediction via Directional 2D for Geometric Structure Preservation", "authors": "Yuchen Zhou,Yan Luo,Xiangang Wang,Xingjian Gu,Mingzhou Lu", "background": "高效的高精度3D占用预测对于自主驾驶系统性能至关重要。然而，许多当前的方法在追求高精度的同时牺牲了实时处理需求。针对这一平衡准确性和推理速度的挑战，我们提出了一种方向性的纯2D方法。该方法通过将3D体素特征进行切片来保留完整的垂直几何信息，这种方法补偿了BEV表示中高度线索的损失，从而保持3D几何结构的完整性。该方法通过采用方向性注意力机制，能够高效地从不同方向提取几何特征，实现了准确性与计算效率之间的平衡。实验结果突显了该方法在自主驾驶中的显著优势。", "innovation": "该方法通过将3D体素特征进行切片保留完整的垂直几何信息，采用方向性注意力机制高效地提取不同方向的几何特征，从而实现在准确性和计算效率之间的平衡。在Occ3D-nuScenes数据集上，该方法达到了39.3%的mIoU和27.7 FPS的推理速度，并在边缘设备上的推理速度达到了14.8 FPS，进一步证明了其在资源受限环境下的实时部署能力。", "conclusion": "实验结果展示了该方法在精度和效率方面的显著优势，并验证了其在资源受限环境下实时部署的可能性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23575", "html_url": "https://arxiv.org/abs/2507.23575", "title": "超越Gloss：一种以手为中心的无手语 gloss 的手语翻译框架", "title_en": "Beyond Gloss: A Hand-Centric Framework for Gloss-Free Sign Language Translation", "authors": "Sobhan Asasi,Mohamed Ilyas Lakhal,Ozge Mercanoglu Sincan,Richard Bowden", "background": "手语翻译（SLT）是一项具有挑战性的任务，需要在视觉信息与语言信息之间架起桥梁，并捕捉手部形状和动作的细微变化。现有视频大型语言模型（VideoLLM）在处理长视频时表现较差，难以详细建模。", "innovation": "提出了一个新颖的无手语 gloss 的 SLT 框架 BeyondGloss，利用视频大型语言模型 (VideoLLM) 的时空推理能力。提出了一种生成细粒度、时序感知的手部运动文本描述的新方法，以及对比对齐模块，用于将这些描述与视频特征对齐，促进模型对手部中心的时序动态进行关注和区分。通过从HaMeR提取细粒度特征来进一步丰富手部特定的表示，并在预训练过程中使用对比损失来减少模态差异。", "conclusion": "BeyondGloss 在 Phoenix14T 和 CSL-Daily 挑战基准上取得了最先进的性能，证明了所提出的框架的有效性。代码将在论文被接受后公开。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23595", "html_url": "https://arxiv.org/abs/2507.23595", "title": "MamV2XCalib: 基于车联网的目标导向无基础设施相机标定方法", "title_en": "MamV2XCalib: V2X-based Target-less Infrastructure Camera Calibration with State Space Model", "authors": "Yaoye Zhu,Zhe Wang,Yan Wang", "background": "随着利用路边摄像头辅助自动驾驶车辆感知的协作系统日益普及，基础设施摄像头的大规模精确标定成为了一个关键问题。传统的手动标定方法往往耗时、费力，并且可能需要封闭道路。因此，需要一种新的方法来解决这一问题。", "innovation": "本文介绍了MamV2XCalib，这是第一个利用车辆侧LiDAR辅助基础设施相机标定的车联网方法。MamV2XCalib仅需要装有LiDAR的自动驾驶车辆在需要标定的路边摄像头附近行驶，无需特定参考物体或人工干预。此外，文章提出了一个新的目标导向无LiDAR-相机标定方法，该方法结合了多尺度特性和4D相关体积来估计车辆点云和路边图像之间的相关性。MamV2XCalib通过Mamba建模了时间信息并估计了旋转角度，有效解决了由车辆侧数据缺陷（如遮挡）和视角差异导致的车联网场景中的标定失败问题。研究结果表明，该方法在V2X-Seq和TUMTraf-V2X数据集上的表现优于之前仅针对单辆汽车设计的LiDAR-相机方法。", "conclusion": "MamV2XCalib方法在V2X场景中实现了更好的稳定性，并且参数更少。通过在V2X-Seq和TUMTraf-V2X数据集上的评估，证明了本文基于车联网的自动标定方法的有效性和鲁棒性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23569", "html_url": "https://arxiv.org/abs/2507.23569", "title": "Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization", "title_en": "Gaussian Splatting Feature Fields for Privacy-Preserving Visual Localization", "authors": "Maxime Pietrantoni,Gabriela Csurka,Torsten Sattler", "background": "视觉定位是相机在一个已知环境中估计其位置的任务。传统的视觉定位方法存在隐私泄露问题。为了提高准确性并保护隐私，本研究利用基于3D高斯斑点的表示方法进行视觉定位，并提出了一种新的场景表示方法——Gaussian Splatting Feature Fields（GSFFs），结合了显式几何模型和隐式特征场，利用3D高斯斑点的密集几何信息和可微射影算法来学习基于3D的鲁棒特征表示，进一步通过对特征进行对齐和正则化，实现了隐私保护的视觉定位。", "innovation": "本文提出了Gaussian Splatting Feature Fields（GSFFs），融合了显式几何模型和隐式特征场，利用3D高斯斑点的详细几何信息和可微射影算法来学习基于3D的鲁棒特征表示，并通过对比框架对3D可尺度特征场和2D特征编码进行对齐。通过对特征进行结构信息指导下的聚类，进一步正则化特征学习，并将其无缝地转换为分割图，用于隐私保护的视觉定位。此外，通过将查询图像中的特征图或分割图与GSFFs场景表示生成的渲染对齐，实现了最终的视觉定位。", "conclusion": "提出的GSFFs方法及其用于隐私保护和非隐私保护视觉定位的管道在多组实际数据集上取得了最先进的性能。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23597", "html_url": "https://arxiv.org/abs/2507.23597", "title": "MoGA: 3D生成气态先验模型单目高保真气态化身重建", "title_en": "MoGA: 3D Generative Avatar Prior for Monocular Gaussian Avatar Reconstruction", "authors": "Zijian Dong,Longteng Duan,Jie Song,Michael J. Black,Andreas Geiger", "background": "当前很多方法依赖于2D扩散模型来合成不可见视图，但是这些生成的视图往往是稀疏且不一致的，导致3D重建结果不现实且外观模糊。重建高保真3D Gaussian化身的主要挑战在于从单个视角图像中推断出未见的外观和几何细节，同时确保3D一致性与现实性，并且由于缺乏3D训练数据，单独的3D模型无法捕捉所有的图像细节，特别是对未见过的身份。", "innovation": "本文提出了一种名为MoGA的新方法，它通过从学习到的先验分布中采样变形的Gaussians来生成具有多样性的3D化身。该方法将生成的3D化身模型作为先验模型，通过将输入图像投影到其潜在空间并施加额外的3D外观和几何约束来保证3D一致性。此外，MoGA将生成的3D化身作为模型拟合的有意义初始化，促进了3D正则化并帮助细化姿态估计。实验结果表明，该方法在单目视角下从2D扩散模型生成的合成视图中反向拟合生成的3D化身，能够超越现有最先进的技术并适用于现实场景。所提出的Gaussian化身也天生具有可动画性特点。", "conclusion": "本文提出了一种名为MoGA的新方法，该方法通过将生成的3D化身模型作为先验，从单个视角图像中以3D一致性的方式重建高保真Gaussian化身，并且在实验中显示了该技术优于现有方法，同时还证实了其泛化能力以及动画化潜力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23483", "html_url": "https://arxiv.org/abs/2507.23483", "title": "Stable-Sim2Real: 通过两阶段深度扩散探索真实捕获3D数据的模拟", "title_en": "Stable-Sim2Real: Exploring Simulation of Real-Captured 3D Data with Two-Stage Depth Diffusion", "authors": "Mutian Xu,Chongjie Ye,Haolin Liu,Yushuang Wu,Jiahao Chang,Xiaoguang Han", "background": "3D数据模拟旨在弥合模拟数据和真实捕获3D数据之间的差距，这对于真实世界的3D视觉任务至关重要。大多数3D数据模拟方法会注入预定义的物理先验知识，但难以捕捉到真实数据的全部复杂性。最优的方法是在数据驱动的方式下从合成数据学习到真实的隐式映射，但近期的研究中这种方法的发展已经停滞。本文探索了一种新的基于两阶段深度扩散模型的数据驱动3D模拟方法，名为Stable-Sim2Real。", "innovation": "本文提出了一种新的两阶段深度扩散模型，基于模拟和真实数据配对深度生成残差，通过增强的第二阶段扩散调整扩散损失，具体包括：第一阶段微调Stable-Diffusion生成稳定的但粗糙的深度，部分局部区域可能不遵循真实模式；第二阶段将合成和初始输出深度都输入扩散模型，通过三维判别器识别不同区域后调整扩散损失。还提供了新的评估基准方案，以评估3D数据模拟方法，实验表明，使用该方法生成的3D模拟数据在真实世界3D视觉任务中的性能显著提高。", "conclusion": "本文通过Stable-Sim2Real提出的新型两阶段深度扩散模型显著提高了3D数据模拟的效果，该方法生成的数据与真实捕获的模式高度相似，最终在网络训练中表现出色，在真实世界的3D视觉任务中表现出优异的性能。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23508", "html_url": "https://arxiv.org/abs/2507.23508", "title": "红外-可见光图像融合的双曲环形对齐", "title_en": "Hyperbolic Cycle Alignment for Infrared-Visible Image Fusion", "authors": "Timing Li,Bing Cao,Jiahe Feng,Haifang Cao,Qinghau Hu,Pengfei Zhu", "background": "图像融合可以整合多源图像中的互补信息，克服单一模态成像系统的固有限制。准确的图像注册对于有效的多源数据融合至关重要。然而，现有的注册方法，通常基于欧几里得空间中的图像平移，难以处理跨模态对齐问题，导致对齐和融合质量不佳。为解决这一问题，该研究探索了非欧几里得空间中的图像对齐，并提出了一种双曲环形对齐网络（Hy-CycleAlign），这是首个基于双曲空间的图像注册方法。该网络引入了一种双向跨模态循环对齐框架，前向对齐网络对齐跨模态输入，后向对齐网络重构原始图像，形成了具有几何一致性的闭环对齐结构。此外，还设计了一种双曲层次对比对齐（H$^2$CA）模块，将图像映射到双曲空间，并施加对齐约束，有效减少了模态差异引起的干扰。研究表明，在欧几里得空间和双曲空间中分析图像对齐，双曲空间能够实现更敏感和有效的多模态图像对齐。大量实验证明，该方法在图像对齐和融合方面均显著优于现有方法", "innovation": "该研究提出的双曲环形对齐网络（Hy-CycleAlign）是基于双曲空间的第一个图像注册方法。它引入了双向跨模态循环对齐框架，并设计了双曲层次对比对齐（H$^2$CA）模块，有效解决了跨模态对齐问题。研究还分析了在欧几里得和双曲空间中的图像对齐，证明了双曲空间在多模态图像注册中的优势，表明该方法在图像对齐和融合方面均显著优于现有方法", "conclusion": "该方法在未对齐的多模态图像上进行了广泛实验，证明了该方法在图像对齐和融合方面均显著优于现有方法。双曲空间在多模态图像对齐中的优势得到了验证。研究者还强调了该代码的公开可用性"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23608", "html_url": "https://arxiv.org/abs/2507.23608", "title": "医疗图像去识别基准挑战", "title_en": "Medical Image De-Identification Benchmark Challenge", "authors": "Linmin Pei,Granger Sutton,Michael Rutherford,Ulrike Wagner,Tracy Nolan,Kirk Smith,Phillip Farmer,Peter Gu,Ambar Rana,Kailing Chen,Thomas Ferleman,Brian Park,Ye Wu,Jordan Kojouharov,Gargi Singh,Jon Lemon,Tyler Willis,Milos Vukadinovic,Grant Duffy,Bryan He,David Ouyang,Marco Pereanez,Daniel Samber,Derek A. Smith,Christopher Cannistraci,Zahi Fayad,David S. Mendelson,Michele Bufano,Elmar Kotter,Hamideh Haghiri,Rajesh Baidya,Stefan Dvoretskii,Klaus H. Maier-Hein,Marco Nolden,Christopher Ablett,Silvia Siggillino,Sandeep Kaushik,Hongzhu Jiang,Sihan Xie,Zhiyu Wan,Alex Michie,Simon J Doran,Angeline Aurelia Waly,Felix A. Nathaniel Liang,Humam Arshad Mustagfirin,Michelle Grace Felicia,Kuo Po Chih,Rahul Krish,Ghulam Rasool,Nidhal Bouaynaya,Nikolas Koutsoubis,Kyle Naddeo,Kartik Pandit,Tony O'Sullivan,Raj Krish,Qinyan Pan,Scott Gustafson,Benjamin Kopchick,Laura Opsahl-Ong,Andrea Olvera-Morales,Jonathan Pinney,Kathryn Johnson,Theresa Do,Juergen Klenk,Maria Diaz,Arti Singh,Rong Chai,David A. Clunie,Fred Prior,Keyvan Farahani", "background": "保护医疗信息（PHI）和身份信息（PII）的去识别是通过公共仓库共享医学影像以遵守患者隐私法律的基本要求。同时，保护非 PHI 元数据以供下游开发影像人工智能（AI）使用是医学研究中的一个重要考虑因素。MIDI-B（Medical Image and Data Identification Benchmarks）的目标是提供一个标准化的平台来基于符合 HIPAA 安全港法规、DICOM 属性机密性配置文件以及由影像癌症库（TCIA）定义的研究关键元数据最佳实践的标准，以评估 DICOM 图像去识别工具的基准。挑战使用了大量多样化的多中心和多模态的真实去识别放射学图像，并在其中插入了合成的 PHI/PII 识别符。", "innovation": "MIDI-B挑战提供了一个标准平台来评估基于规则的方法在影像去识别的表现。该挑战使用真实去识别的多中心多模态放射学图像，并插入了合成的 PHI/PII 标识符。参赛者采用了各种开源工具和定制配置、大型语言模型以及光学字符识别（OCR）等多种工具和技术。评分方法采用的是正确动作数占总要求动作数的比例，得分范围从 97.91% 到 99.93%，展示了各种工具和技术在医学影像去识别上的优劣。", "conclusion": "本文章详细报告了 MIDI-B 挑战的设计、实施、结果以及从中学到的经验教训，为医学影像去识别提供了宝贵的数据和实践经验。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23601", "html_url": "https://arxiv.org/abs/2507.23601", "title": "基于Mamba的高效时空频运动感知在视频隐彫对象检测中的应用", "title_en": "Mamba-based Efficient Spatio-Frequency Motion Perception for Video Camouflaged Object Detection", "authors": "Xin Li,Keren Fu,Qijun Zhao", "background": "现有视频隐彫目标检测（VCOD）方法主要依赖于空间外观特征来感知运动线索以打破伪装，但隐彫场景中前景和背景的高相似性限制了空间外观特征（如颜色和纹理）的可区分性，影响了检测精度和完整性。最近的研究表明，频域特征不仅可以增强特征表示以弥补外观限制，还能通过频域能量的动态变化感知运动。此外，新型动态系统模型Mamba能够利用其线性时间长序列建模能力高效感知帧序列中的运动线索。基于此，我们提出了一种基于时空频运动感知的隐彫Mamba（Vcamba），该方法结合了频域和空域特征进行高效的VCOD。", "innovation": "我们提出了一个感受野视觉状态空间（RFVSS）模块来在序列建模后提取多尺度空间特征。我们引入了一种自适应频率成分增强（AFE）模块，包含一种新的频域序列扫描策略，以保持语义一致性。我们还提出了基于空间的长程运动感知（SLMP）模块和基于频率的长程运动感知（FLMP）模块，用于分别在空间和频域相位域内建模时空和频率时域序列。最后，空间和频率运动融合模块（SFMF）将双域特征整合为统一的运动表示。实验结果表明，我们的Vcamba在两个数据集的6项评估指标上优于现有方法，具有较低的计算成本，证实了Vcamba的优越性。", "conclusion": "我们的实验结果表明，Vcamba在两个数据集的6项评估指标上优于现有方法，且计算成本较低，证实了Vcamba的优越性。我们的代码已公开。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23609", "html_url": "https://arxiv.org/abs/2507.23609", "title": "一致点匹配", "title_en": "Consistent Point Matching", "authors": "Halid Ziya Yerebakan,Gerardo Hermosillo Valadez", "background": "本研究展示了将一致性启发式方法集成到点匹配算法中，提高了在医学图像配准过程中跨图像对匹配解剖位置的鲁棒性。实验证实在多种横截面内部和公开数据集（包括CT和MRI模态）上均有效，并在Deep Lesion Tracking数据集上超越了现有的最佳结果。此外，研究证明此方法有效解决了标记点定位问题。", "innovation": "研究提出了一种新的点匹配算法，通过集成一致性启发式方法，提高了算法在医学图像配准中的鲁棒性，并且能够在标准CPU硬件上高效运行，同时还允许用户根据需求在速度和鲁棒性之间进行配置。", "conclusion": "此方法能够实现高精度的医学图像配准，无需依赖机器学习模型或训练数据。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23652", "html_url": "https://arxiv.org/abs/2507.23652", "title": "适配性提炼的ControlNet：加速训练和优越采样在医疗图像合成中的应用", "title_en": "Adaptively Distilled ControlNet: Accelerated Training and Superior Sampling for Medical Image Synthesis", "authors": "Kunpeng Qiu,Zhiying Zhou,Yongxin Guo", "background": "医疗图像注释受到隐私问题和劳力密集的标签工作的限制，显著限制了分割模型的性能和泛化能力。尽管掩膜可控扩散模型在合成方面表现出色，但在病变-掩膜对齐方面难以做到精准。", "innovation": "提出了一种名为Adaptively Distilled ControlNet的任务无关框架，通过双模型提炼加速训练和优化。具体来说，在训练中，通过预测噪声在参数空间的对齐，利用教师模型条件，对一个仅包含掩膜的学生模型进行正则化，并结合基于病变-背景比的自适应正则化。在采样过程中，仅使用学生模型，实现了隐私保护的医疗图像生成。", "conclusion": "在两个不同的医疗数据集上的全面评估显示了其优越性：TransUNet在KiTS19上分别提高了2.4%/4.2%的mDice/mIoU，而SANet在Polyps上分别实现了2.6%/3.5%的改进。代码已在GitHub上开源。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23620", "html_url": "https://arxiv.org/abs/2507.23620", "title": "DivControl：知识转移在可控图像生成中的应用", "title_en": "DivControl: Knowledge Diversion for Controllable Image Generation", "authors": "Yucheng Xie,Fu Feng,Ruixiao Shi,Jing Wang,Yong Rui,Xin Geng", "background": "扩散模型已经从基于文本到图像(T2I)生成发展到基于图像到图像(I2I)生成，并且通过引入结构化输入（如深度图）实现了精细的控件空间。然而，现有的方法要么为每个条件训练独立的模型，要么依赖统一的架构，这些架构具有纠缠的表示，导致对新条件的泛化能力差和高适应成本。", "innovation": "提出了DivControl，这是一种分解的预训练框架，用于统一可控生成和高效适应。DivControl通过SVD分解ControlNet为基本组件-奇异向量对-并在多条件训练期间通过知识转移将其分解为条件无关的学习基因和条件特定的定制者。知识转移通过动态门实施，该门基于条件指令的语义对定制者进行软路由，从而实现零样本泛化和参数高效适应。此外，引入了表示对齐损失，将条件嵌入与早期扩散特征对齐，以进一步提高条件保真度和训练效率。", "conclusion": "实验结果表明，DivControl在训练成本降低36.4倍的同时，实现了最先进的控制性，同时改善了基本条件的平均性能。它还展示了对未见过的条件的强大零样本和少样本性能，证明了其卓越的可扩展性、模块化和可迁移性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23704", "html_url": "https://arxiv.org/abs/2507.23704", "title": "提升位移场建模以优化高保真Gaussian视频重建", "title_en": "Enhanced Velocity Field Modeling for Gaussian Video Reconstruction", "authors": "Zhenyang Li,Xiaoyang Bai,Tongchen Zhang,Pengfei Shen,Weiwei Xu,Yifan Peng", "background": "高保真3D视频重建对于实现虚拟和增强现实（VR/AR）中具有真实运动的动态场景实时渲染至关重要。虽然基于3D高斯样本变形场的3D高斯表示因其强大的代表能力，已经在视频重建中取得了接近摄影的真实结果，但在复杂运动和显著尺度变化的视频中，深度变形网络经常对不规则的高斯轨迹进行过度拟合，导致视觉效果不佳。此外，专门设计用于静态场景重建的基于梯度的密集化策略无法有效处理动态内容的缺失。", "innovation": "本文提出了一种针对Gaussian视频重建的流-位移场建模方案，命名FlowGaussian-VR。该方案包括两个核心组件：基于光流的优化的位移场渲染（VFR）管道和流辅助自适应密集化（FAD）策略，以调整动态区域的高斯数量和大小，针对含有挑战性运动场景的多个真实世界数据集验证了模型的有效性，展示了显著的视觉改进（PSNR提高超过2.5 dB）、动态纹理中较少模糊的假象，以及规整可追踪的每个高斯轨迹。", "conclusion": "本文提出的FlowGaussian-VR有效解决了复杂运动和显著尺度变化视频重建中变形网络的过度拟合问题，通过光流驱动的优化和动态区域自适应密集化策略，提高了视频重建质量并在多个数据集上验证了模型的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23642", "html_url": "https://arxiv.org/abs/2507.23642", "title": "Efficient Masked Attention Transformer for Few-Shot Classification and Segmentation", "title_en": "Efficient Masked Attention Transformer for Few-Shot Classification and Segmentation", "authors": "Dustin Carrión-Ojeda,Stefan Roth,Simone Schaub-Meyer", "background": "Few-shot classification and segmentation (FS-CS)旨在使用少量标注样本同时进行多标签分类和多类别分割。当前最先进技术虽然在分类和分割任务中能实现高精度，但对于小物体的处理效果不佳。现有评估设置在实际场景中忽略了可用的标注信息，导致模型无法充分利用这些信息的潜在价值。", "innovation": "提出了一个高效的带掩码注意力机制的变压器（EMAT），通过引入一种新颖的记忆高效的带掩码注意力机制、可学习的下采样策略和参数效率增强来提升小物体的分类和分割精度。EMAT在PASCAL-5i和COCO-20i数据集上表现出色，参数量仅为其他FS-CS方法的四分之一以下，并引入了两种新的评估设置以更好地反映实际情况。", "conclusion": "EMAT在处理小物体方面优于现有FS-CS方法，同时引入了两种新的评估设置，以更真实地反映实际应用场景。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23673", "html_url": "https://arxiv.org/abs/2507.23673", "title": "SAMSA: 增强有谱角的分割一切模型用于高光谱交互式医学图像分割", "title_en": "SAMSA: Segment Anything Model Enhanced with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation", "authors": "Alfie Roddan,Tobias Czempiel,Chi Xu,Daniel S. Elson,Stamatia Giannarou", "background": "高光谱成像（HSI）提供了丰富的光谱信息，但在医学成像中面临数据限制和硬件差异的巨大挑战。SAMSA 提出了一种创新的交互式分割框架，结合了 RGB 基础模型和光谱分析，利用用户点击来引导 RGB 分割和光谱相似性计算，有效解决了 HSI 分割中的关键局限性，并在少量训练示例的情况下展示了其效能。", "innovation": "SAMSA 创新地结合了 RGB 分基础模型和光谱分析，并通过独立于光谱波段数量和分辨率的独特光谱特征融合策略来解决 HSI 分割中的关键挑战。该方法在神经外科和猪体术的公开数据集上表现良好，显示了一步点击和五步点击下的高 DICE 值。实验结果证明了 SAMSA 在少量标注和零标注学习场景中的有效性。", "conclusion": "SAMSA 提供了一种无缝集成不同光谱特征的数据集的方法，为高光谱医学图像分析提供了灵活的框架。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23643", "html_url": "https://arxiv.org/abs/2507.23643", "title": "FFGAF-SNN: 基于前馈前馈的无梯度近似训练框架", "title_en": "FFGAF-SNN: The Forward-Forward Based Gradient Approximation Free Training Framework for Spiking Neural Networks", "authors": "Changqing Xu,Ziqiang Yang,Yi Liu,Xinfang Liao,Guiqi Mo,Hao Zeng,Yintang Yang", "background": "Spiking Neural Networks (SNNs) 为一种节能的类脑计算框架，但其因非可微性导致训练困难。现有梯度近似方法在准确性和计算复杂性上存在局限性，特别是在边缘设备上。本文在解决以上挑战的前提下，提出了一种基于前馈前馈（FF）的无梯度近似训练框架，将脉冲激活视作黑盒模块，从而无需梯度近似并大幅降低计算复杂度。此外，该方法还引入了一种类感知的复杂性自适应机制，能够根据类间难度动态优化损失函数，使资源分配更加高效。", "innovation": "该研究提出了一个基于前馈前馈（FF）的无梯度近似训练框架，该框架将脉冲激活视为黑盒模块，从而无需进行梯度近似并显著减少了计算复杂性。此外，该方法还引入了类感知的复杂性自适应机制，能够在保持高效的同时，自适应地优化网络资源分配。实验结果表明，该方法在MNIST、Fashion-MNIST和CIFAR-10数据集上的测试准确率分别达到了99.58%、92.13%和75.64%，超越了现有的所有基于FF的SNN方法，并在内存访问和计算功耗方面表现出显著优势。", "conclusion": "实验结果表明，所提出的训练框架在MNIST、Fashion-MNIST和CIFAR-10数据集上的测试准确率分别为99.58%、92.13%和75.64%，显著超越了现有FF基SNN方法。此外，在内存访问和计算功耗方面，该方法也表现出显著的优势。该方法为类脑计算的研究提供了新的思路和方向。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23657", "html_url": "https://arxiv.org/abs/2507.23657", "title": "OmniTraj: 基于异构数据预训练以适应和实现零样本人类轨迹预测", "title_en": "OmniTraj: Pre-Training on Heterogeneous Data for Adaptive and Zero-Shot Human Trajectory Prediction", "authors": "Yang Gao,Po-Chien Luan,Kaouther Messaoud,Lan Feng,Alexandre Alahi", "background": "虽然大规模预训练在提升人体轨迹预测方面取得了显著进展，但在向具有不同时间动态的新数据集进行零样本迁移的能力方面仍存在挑战。现有的最先进预训练模型往往需要微调以适应具有不同帧率或观察范围的新数据集，这限制了它们的扩展性和实际应用价值。现有的数据感知离散模型在转移至具有不同时间设置的新场景时也面临困难。因此，研究者们意识到解决这一问题对于提高模型的适应性和零样本迁移能力至关重要。", "innovation": "本文系统地探讨了这一局限性，并提出了一种稳健的解决方案。研究者通过实验展示了现有的数据感知离散模型在新场景下转移时存在的问题，并揭示了通过直接条件化时间元数据作为简单而有效的解决方法。基于这一洞见，提出了一种在大型异构数据集上预训练的基于Transformer的模型——OmniTraj。研究表明，通过直接条件化帧率，OmniTraj实现了最先进的零样本迁移性能，在挑战性的跨设置场景下将预测误差降低了超过70%。成功地在四个数据集（NBA、JTA、WorldPose和ETH-UCY）上取得了最佳结果。", "conclusion": "OmniTraj模型由于其直接条件化的时间元数据机制，在跨设置的零样本转移场景下表现优异，显著降低了预测错误率，并在多个数据集上实现了最先进的结果。模型的代码已经公开。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23734", "html_url": "https://arxiv.org/abs/2507.23734", "title": "RAGNet: 大规模基于推理的抓取可用性分割基准", "title_en": "RAGNet: Large-scale Reasoning-based Affordance Segmentation Benchmark towards General Grasping", "authors": "Dongming Wu,Yanping Fu,Saike Huang,Yingfei Liu,Fan Jia,Nian Liu,Feng Dai,Tiancai Wang,Rao Muhammad Anwer,Fahad Shahbaz Khan,Jianbing Shen", "background": "当前的抓取系统在多种开放场景中需要准确感知对象可用性，但现有的研究缺乏基于推理的大规模抓取可用性预测数据，导致在开放场景中的效果受到了质疑。", "innovation": "构建了一个大规模面向抓取的可用性分割基准，名为RAGNet，其中包括了273k图像、180个类别和26k推理指令。提出了一种基于可用性的抓取框架，AffordanceNet，该框架包括在海量可用性数据上预训练的VLM和根据可用性地图进行抓取的目标网络。", "conclusion": "通过在可用性分割基准和真实机器人操作任务中的大量实验，证明了模型具有强大的开放环境泛化能力。相关数据和代码可以在以下链接获取：this https URL"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23709", "html_url": "https://arxiv.org/abs/2507.23709", "title": "具有降低过度自信的可解释图像分类方法以用于组织表征", "title_en": "Explainable Image Classification with Reduced Overconfidence for Tissue Characterisation", "authors": "Alfie Roddan,Chi Xu,Serine Ajlouni,Irini Kakaletri,Patra Charalampaki,Stamatia Giannarou", "background": "在手术过程中部署机器学习模型以协助组织表征和安全肿瘤切除是有益的。对于图像分类模型，常用的像素归因方法可以推断出可解释性，但深度学习模型预测的过度自信会导致像素归因的过度自信。该研究旨在克服这一问题，提出了一种新颖的方法来结合风险估计到像素归因方法中，以提高图像分类的可解释性。该方法通过迭代应用分类模型和像素归因方法生成PA图的体积，并利用该体积生成了像素级PA值的分布。此外，该方法通过估计增强PA图的期望值来生成增强的PA图，并使用变异系数（CV）估计像素级风险。这种方法不仅提供了一个改进的PA图，还能为输出PA值的风险提供一个估计。", "innovation": "该研究首次提出了一种结合风险估计的像素归因方法，用于提高图像分类的可解释性。该方法包括生成PA图的体积、像素级PA值的分布、增强PA图以及输出PA值的风险估计。这种方法能降低预测的过度自信，提供更准确的解释。", "conclusion": "该研究通过在基于探头的共聚焦激光内窥镜（pCLE）数据和ImageNet上进行性能评估，证明了改进的可解释性方法优于现有技术。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23715", "html_url": "https://arxiv.org/abs/2507.23715", "title": "DiffuMatch: Category-Agnostic Spectral Diffusion Priors for Robust Non-rigid Shape Matching", "title_en": "DiffuMatch: Category-Agnostic Spectral Diffusion Priors for Robust Non-rigid Shape Matching", "authors": "Emery Pierson,Lei Li,Angela Dai,Maks Ovsjanikov", "background": "深功能图最近成为解决非刚性形状对应任务的强大工具。现有方法结合了功能图框架的力量和灵活性，并利用数据驱动的训练来提高准确性和普遍性。然而，大多数现有方法仍然仅在特征函数中实施学习部分，并依赖于基于公理的建模来定义训练损失或在网络内的功能图正则化。这种限制使得这些方法的准确性和适用性仅限于遵循公理模型假设的场景。", "innovation": "首次展示了网络内正则化和功能图训练可以完全被数据驱动的方法代替。利用谱域中的生成模型训练功能图生成模型，并使用生成的模型来促进新形状集合的真实功能图的结构性质。实验表明，所学习的正则化在无监督非刚性形状匹配任务中优于基于公理的方法。显著地，这一学习模型在类别无关的情况下工作。", "conclusion": "通过谱域中的扩散模型蒸馏策略，我们证明了学习的正则化能比基于公理的方法在零样本非刚性形状匹配任务中产生更好的结果。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23683", "html_url": "https://arxiv.org/abs/2507.23683", "title": "I2V-GS: 使用Gaussian Splatting将基础设施视角转换为车辆视角的自主驾驶数据生成", "title_en": "I2V-GS: Infrastructure-to-Vehicle View Transformation with Gaussian Splatting for Autonomous Driving Data Generation", "authors": "Jialei Chen,Wuhao Xu,Sipeng He,Baoru Huang,Dongchun Ren", "background": "端到端的自主驾驶系统需要大量的高质量数据。然而，目前的驾驶数据主要是通过车辆采集的，这既昂贵又低效。一个潜在的解决方案是通过合成现实世界中的图像数据来生成数据。最近在3D重建领域的进展展示了逼真新颖视角的合成能力，这表明可以利用道路上拍摄的图像生成驾驶数据。", "innovation": "论文提出了一个新颖的方法，I2V-GS，用于通过Gaussian Splatting将基础设施视角转换为车辆视角。为了从稀疏的基础设施视角重建并经过大幅度视角变换的渲染，本文采用自适应深度扭曲生成密集的训练视图。为了进一步扩大视角范围，使用级联策略进行图像填充，并且确保不同视角所恢复的内插内容一致性。此外，使用交叉视角信息进行信任度指导的优化进一步确保了扩散模型的可靠性。引入了RoadSight，一个用于基础设施视角的真实多模态多视图数据集。I2V-GS框架是首个用于生成自主驾驶数据集，将基础设施视角转换为车辆视角的框架。", "conclusion": "实验结果显示，I2V-GS在车辆视图下合成质量显著提高，与StreetGaussian相比，NTA-Iou、NTL-Iou和FID分别提高了45.7%、34.2%和14.9%。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23755", "html_url": "https://arxiv.org/abs/2507.23755", "title": "带重新初始化和自我蒸馏的槽注意", "title_en": "Slot Attention with Re-Initialization and Self-Distillation", "authors": "Rongzhen Zhao,Yi Zhao,Juho Kannala,Joni Pajarinen", "background": "与基于密集特征图的流行解决方案不同，对象中心学习（OCL）通过子符号的对象级特征向量（称为槽）来表示视觉场景，这些特征向量对于涉及视觉模态的任务具有高度的灵活性。这些槽通过迭代应用称为槽注意的竞争力交叉注意力，将对象超像素聚合到槽中。然而，一旦初始化，这些槽就被简单地反复使用，导致冗余的槽与具有信息性的槽竞争，描述对象时容易出错，导致对象被错误分割成部分。主流方法仅从将槽解码回输入的重建中获取监督信号，忽略了基于内部信息的监督信号的重要性。", "innovation": "本文提出了一种名为DIAS（带重新初始化和自我蒸馏的槽注意）的新方法。1）它减少了聚合槽中的冗余，并重新初始化额外的聚合以更新剩余的槽；2）它驱动第一聚合迭代中的不良注意力图以逼近最后一迭代中的良好注意力图，从而实现自我蒸馏。实验结果表明，DIAS在对象发现和识别等OCL任务上达到了最先进的性能，同时提高了高级视觉预测和推理能力。", "conclusion": "实验表明，DIAS在OCL任务，如对象发现和识别上达到了最先进的性能，并且在高级视觉预测和推理方面也有所改进。我们的代码可以在下列链接获取。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23685", "html_url": "https://arxiv.org/abs/2507.23685", "title": "UniLDiff: 解锁扩散先验在All-in-One图像恢复中的潜力", "title_en": "UniLDiff: Unlocking the Power of Diffusion Priors for All-in-One Image Restoration", "authors": "Zihan Cheng,Liangtai Zhou,Dian Chen,Ni Tang,Xiaotong Luo,Yanyun Qu", "background": "All-in-One图像恢复(AiOIR)作为一种有前景但具有挑战性的研究方向，吸引了广泛的研究兴趣。然而，目前的方法尚未有效应对这项研究中遇到的核心挑战。", "innovation": "为了解决这些挑战，该论文提出了一种基于隐式扩散模型(LDMs)的新型统一图像恢复框架。该框架结构化地将低质量视觉先验整合到扩散过程中，充分利用扩散模型的强大生成能力以处理各种退化情况。具体而言，设计了一个降解感知特征融合模块(DAFF)来适应多样化退化类型的处理。为了减少由高压缩和迭代采样引起的细节损失，设计了一个感知细节专家模块(DAEM)，增强了纹理和精细结构的恢复。", "conclusion": "通过在多任务和混合退化设置下的广泛实验，证明了该方法在图像恢复方面始终达到最先进的性能，突显了扩散先验在统一图像恢复中的实际潜力。我们的代码将被公开。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23778", "html_url": "https://arxiv.org/abs/2507.23778", "title": "半物理：使3D人体模型具备物理互动能力", "title_en": "Half-Physics: Enabling Kinematic 3D Human Model with Physical Interactions", "authors": "Li Siyao,Yao Feng,Omid Tehari,Chen Change Loy,Michael J. Black", "background": "当前普遍使用的3D人类模型（例如SMPL-X）虽然能够高效地表示人类的准确形状和姿态，但是由于其基于运动学的特点，缺乏与环境物理互动的能力。因此，基于运动学的互动模型常常会遇到穿模和不现实物体动态等问题。为了解决这一局限性，研究提出了一种新的方法，将SMPL-X嵌入到能够与周围环境进行动态物理互动的实体中。这种方法通过半物理机制，将3D运动学运动转化为物理模拟，实现了在保持SMPL-X原有运动学控制的同时，确保与场景和物体之间具有物理可验证的互动，有效避免了穿模和不现实的物体动态。", "innovation": "研究提出了一种全新的半物理机制，将SMPL-X模型嵌入到能够进行动态物理互动的实体中。该方法创新地将3D运动学运动转化为物理模拟，同时保持原始的运动学控制，确保与场景和物体之间进行有效的物理互动，有效解决了穿模和不现实物体动态的问题。相比于基于强化学习的方法，该半物理方法不依赖学习过程，可在任何体型和动作下通用，并且能够实现实时运行，同时保持原有的运动学运动保真度，并无缝集成物理互动。", "conclusion": "该方法有效解决了基于运动学的3D人类模型难以进行物理互动的问题，通过半物理机制将SMPL-X模型与物理互动结合，实现了可验证的物理互动，无需学习过程，通用性强，能够在实时光实时运行，并保持原运动学运动的保真度。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23779", "html_url": "https://arxiv.org/abs/2507.23779", "title": "Phi-Ground Tech Report: Advancing Perception in GUI Grounding", "title_en": "Phi-Ground Tech Report: Advancing Perception in GUI Grounding", "authors": "Miaosen Zhang,Ziqiang Xu,Jialiang Zhu,Qi Dai,Kai Qiu,Yifan Yang,Chong Luo,Tianyi Chen,Justin Wagle,Tim Franklin,Baining Guo", "background": "随着多模态推理模型的发展，类似于《钢铁侠》中的Jarvis的计算机使用代理（CUAs）正在成为现实。GUI接地是CUAs执行实际操作的核心组件，类似于机器人技术中的机械控制，直接决定了系统的成功或失败。当前的端到端接地模型在像ScreenSpot-pro和UI-Vision这样的基准测试中仅达到不足65%的准确率，表明这些模型尚不成熟，远远未准备好部署，因为一例误点可能导致无法接受的结果。", "innovation": "本文通过对数据收集到模型训练的全过程进行实证研究，开发出了Phi-Ground模型家族，该模型在所有五个接地基准测试中达到了在代理设置下小于10B参数模型的最优性能。在端到端模型设置中，该模型在ScreenSpot-pro上达到了43.2的SOTA结果，在UI-Vision上达到了27.2的SOTA结果。本文认为，本文讨论的种种细节及成功与失败，不仅有助于理解接地模型的构建，也对其他感知任务有益。", "conclusion": "项目的主页链接：[点击访问](this https URL）。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23782", "html_url": "https://arxiv.org/abs/2507.23782", "title": "MonoFusion: 稀疏视点4D重建方法", "title_en": "MonoFusion: Sparse-View 4D Reconstruction via Monocular Fusion", "authors": "Zihan Wang,Jeff Tan,Tarasha Khurana,Neehar Peri,Deva Ramanan", "background": "传统的方法在重建动态场景时需要密集的多视角捕获，这通常需要数百台校准的相机（例如全景工作室）。然而，这样的多视角设置成本高昂，难以捕捉野生场景中的多样动态行为。因此，现有方法无法满足在成本和灵活性方面的需求，特别是在动态行为场景的重建中，如何有效利用稀疏视角的相机成为新的研究方向。论文针对此问题，提出了一种新的方法，使用少量的稀疏视角相机进行动态场景重建，且覆盖完整场景视图。", "innovation": "论文通过精心对齐每个独立的单目重建，实现了时间和视角一致的动态场景重建，从而解决了在稀疏视点设置下密集多视图重建方法难以适应的问题。该方法在PanopticStudio和Ego-Exo4D数据集上进行实验，展示了其在重建质量和新视角渲染能力方面的优越性。", "conclusion": "论文提出的MonoFusion方法在稀疏视点的4D重建方面取得了显著成果，尤其是在渲染新颖视角方面超过现有方法。通过公开代码、数据和数据处理脚本，研究者希望能够进一步推动稀疏视点下的动态场景重建研究。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23772", "html_url": "https://arxiv.org/abs/2507.23772", "title": "SeqAffordSplat: 3D高斯点表示中的场景级序列 affordance 推理", "title_en": "SeqAffordSplat: Scene-level Sequential Affordance Reasoning on 3D Gaussian Splatting", "authors": "Di Li,Jie Feng,Jiahao Chen,Weisheng Dong,Guanbin Li,Yuhui Zheng,Mingtao Feng,Guangming Shi", "background": "3D affordance reasoning，即将人类指令与3D物体的功能区域关联起来，是具备嵌入式能力的代理人的关键能力。现有基于3D高斯点表示（3DGS）的方法仅限于单一对象和单一步骤的交互，无法应对复杂现实世界应用中所需的长时 horizon、多对象任务。SeqAffordSplat 模板建立了一个涵盖1800多个场景的大规模基准，旨在支持对复杂3DGS环境中的长期 affordance 理解的研究。", "innovation": "引入了序列3D高斯可获取性推理的新任务，并提出了SeqAffordSplat，即SeqSplatNet。SeqSplatNet 是一个端到端的框架，能够直接将指令映射到一系列3D可获取性掩码。采用自回归的大语言模型生成文本并用特殊分割标记交替，指导条件解码器生成对应的3D掩码。为了处理复杂场景几何结构，引入了条件几何重建的预训练策略，使模型学习从已知几何观察中重建完整的可获取性区域掩码。为了解决语义歧义，设计了一种特征注入机制，从2D视觉基础模型中提取丰富的语义特征，并在多个尺度上融合到3D解码器中。实验结果表明，该方法在基准测试中达到了新的SOTA水平，从单一交互推进到了场景级别的复杂序列任务中，实现affordance 推理的提升。", "conclusion": "SeqAffordSplat 方法在设定的基准测试中达到了新的SOTA水平，成功地将 affordance 推理从单一步骤提升到复杂的、序列化的场景任务中，展示了序列3D高斯可获取性推理的有效性和重要作用。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22929", "html_url": "https://arxiv.org/abs/2507.22929", "title": "EH-Benchmark 肠胃幻视基准和代理驱动的自顶向下可追溯推理工作流", "title_en": "EH-Benchmark Ophthalmic Hallucination Benchmark and Agent-Driven Top-Down Traceable Reasoning Workflow", "authors": "Xiaoyu Pan,Yang Bai,Ke Zou,Yang Zhou,Jun Zhou,Huazhu Fu,Yih-Chung Tham,Yong Liu", "background": "医疗大型语言模型（MLLMs）在眼科诊断中发挥着关键作用，具有应对致盲疾病的潜在价值。然而，它们的准确性受限于因眼科知识有限、缺乏视觉定位和推理能力以及多模态眼科数据缺乏而导致的幻视现象。现有的医疗基准无法有效评估不同类型的幻视或提供减轻这些问题的实际解决方案。", "innovation": "我们提出了EH-Benchmark，一个新颖的眼科基准，用于评估MLLMs中的幻视现象。我们基于特定任务和错误类型将MLLMs的幻视分为两大类：视觉理解和逻辑组合，每类包含多个子类别。我们还提出了一种代理为中心的、分三阶段的框架，包括知识层次检索阶段、任务层次案例研究阶段和结果层次验证阶段。实验结果显示，我们的多代理框架显著减轻了两种类型的幻视，提高了准确度、可解释性和可靠性。", "conclusion": "我们的多代理框架显著减轻了两种类型的幻视，提高了准确度、可解释性和可靠性。项目可从此处获取：this https URL."}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23785", "html_url": "https://arxiv.org/abs/2507.23785", "title": "高保真视频到4D合成的高斯变化场扩散", "title_en": "Gaussian Variation Field Diffusion for High-fidelity Video-to-4D Synthesis", "authors": "Bowen Zhang,Sicheng Xu,Chuxin Wang,Jiaolong Yang,Feng Zhao,Dong Chen,Baining Guo", "background": "视频到4D生成是一个极具挑战性的任务，因为它涉及从单一视频输入创建高质动态3D内容。直接建模4D扩散过程极为困难，因为这需要高成本的数据构建，并且需要同时表示3D形状、外观和运动的高维属性。以往的方法在这两方面存在限制和挑战：一是数据构建成本高，二是处理高维属性复杂。本文基于上述背景，提出了一种新颖的方法来解决这些问题。", "innovation": "本文提出了一种新的Direct 4DMesh-to-GS变化场VAE模型。该模型直接编码3D动画数据中的标准化高斯斑点（GS）及其时间变化，而无需针对每个实例进行拟合。同时，通过这个高效的表示方式，训练了一个基于时间感知扩散变换器的高斯变化场扩散模型，该模型可基于输入视频和标准化GS条件进行训练。这种方法显著提高了动画生成的质量，并且在仅通过合成数据训练的情况下，模型也能够对野外视频输入表现出卓越的泛化能力，从而为生成高质量的动画3D内容开辟了新途径。", "conclusion": "本文提出的模型在生成高质量动画3D内容方面表现出色，并且能够从合成数据泛化到野外视频输入。这对于视频到4D生成领域是一个重要的突破，为未来的研究和发展奠定了坚实的基础。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22896", "html_url": "https://arxiv.org/abs/2507.22896", "title": "iLearnRobot: 可持续学习的多模态交互机器人", "title_en": "iLearnRobot: An Interactive Learning-Based Multi-Modal Robot with Continuous Improvement", "authors": "Kohou Wang,ZhaoXiang Liu,Lin Bai,Kun Fan,Xiang Liu,Huan Hu,Kai Wang,Shiguo Lian", "background": "机器人在部署后性能需要能够提升，因为它们可能会遇到之前未曾见过的新颖场景。现有的主流多模态大语言模型（MLLM）驱动的机器人系统在交互和适应性方面有所欠缺，而这项工作旨在提供一个新的解决方案。", "innovation": "该论文提出了一种由多模态大语言模型（MLLM）驱动的交互式学习机器人系统。系统能够从非专家用户的自然对话中学习，并通过提问链明确问题意图，在利用互动事件避免重复错误的同时，提供无缝用户体验，这是区别于现有主流MLLM为基础的机器人系统的创新点。", "conclusion": "该系统的实验结果证明了其方法的有效性和改进，它通过整合交互式学习，为在多种环境中实现更优的适应性和性能铺平了道路。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23784", "html_url": "https://arxiv.org/abs/2507.23784", "title": "SUB：通过合成属性替换评估CBM泛化能力的基准", "title_en": "SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions", "authors": "Jessica Bader,Leander Girrbach,Stephan Alaniz,Zeynep Akata", "background": "概念瓶颈模型(CBMs)和其他概念为基础的可解释模型在提高AI应用的透明度方面表现出巨大的潜力，特别是在医学等敏感领域。尽管这些模型在许多场景下取得了成功，但实验证明，它们在数据分布发生变化时难以可靠地识别正确的概念。因此，本文提出了SUB基准，用于评估CBMs在概念变异情况下的鲁棒性，这是通过基于CUB数据集生成的38,400张合成图像实现的。这些图像替换特定概念，如翅膀颜色或腹部图案，以涵盖33种鸟类和45个概念。", "innovation": "本文引入了SUB基准，包含38,400张基于CUB数据集的合成图像，用于测试概念瓶颈模型在概念变化下的稳定性。此外，本文还提出了一种新颖的捆绑扩散引导（TDG）方法，用于精确控制生成的图像，确保同时生成正确的鸟类类别和属性。该方法和基准模型共同推动了更稳健的可解释AI方法的发展。", "conclusion": "该基准和新的TDG方法为评估和改进CBMs等可解释模型提供了严格的手段。相关代码和数据集已在指定URL发布，以促进其他研究人员的进一步探索和发展。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22952", "html_url": "https://arxiv.org/abs/2507.22952", "title": "基于大型语言模型的地图自动标签定位", "title_en": "Automated Label Placement on Maps via Large Language Models", "authors": "Harry Shomer,Jiejun Xu", "background": "地图设计中的标签放置至关重要，作为直接影响地图清晰度和可理解性的空间注释形式。尽管其重要性，标签放置仍然主要是手动完成的，并且难以扩展，因为现有的自动化系统难以整合制图规范、适应上下文或解释注标指示。", "innovation": "本研究提出了一种新的自动标签放置（ALP）范式，将其任务形式化为数据编辑问题，并利用大规模语言模型（LLMs）进行上下文感知的地理注释。为支持这一方向，我们建立了一个名为MAPLE的新基准数据集，用于评估ALP在实际地图上的表现，涵盖多种地标类型和来自开源数据的标签注释。方法利用检索增强生成（RAG）检索与每个地标类型相关的标引规范，并将这些规范整合到提示中，然后利用指令调优的LLMs生成理想的标签坐标。研究评估了四种开源LLMs在MAPLE上的表现，分析其总体性能和不同地标类型之间的泛化能力，包括零样本和指令调优性能。结果表明，在结构化提示和领域特定检索的指导下，LLMs能够学习进行精确的空间编辑，生成的输出与专家制图标准一致。", "conclusion": "本工作提出了一个可扩展的AI辅助地图完成框架，展示了基础模型在结构化数据编辑任务中的潜力。代码和数据可以在以下链接找到：this https URL。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23190", "html_url": "https://arxiv.org/abs/2507.23190", "title": "Accessibility Scout: 为建筑物环境提供个性化的可达性扫描", "title_en": "Accessibility Scout: Personalized Accessibility Scans of Built Environments", "authors": "William Huang,Xia Su,Jon E. Froehlich,Yang Zhang", "background": "评估不熟悉的建筑环境的可达性对于残疾人至关重要。然而，由用户或个人健康专业人员进行的手动评估既费力又难以扩展，而自动机器学习方法往往忽视了个体用户的独特需求。最近，大型语言模型（LLMs）的发展为解决这一问题提供了新的途径，平衡了个性化与可扩展性，从而实现更具适应性和上下文意识的可达性评估。", "innovation": "我们提出了基于LLM的可达性扫描系统Accessibility Scout，该系统能够通过分析建筑环境的照片来识别可达性问题。通过协作的人工智能评估方式，Accessibility Scout能够根据个体的行动能力、偏好和具体的环境兴趣为其提供个性化的评估。我们的技术评估和用户研究结果表明，Accessibility Scout能够生成超越传统ADA标准的个性化可达性扫描结果。", "conclusion": "最后，我们讨论了我们研究的意义及迈向更具扩展性和个性化物理世界的可达性评估的未来步骤。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23000", "html_url": "https://arxiv.org/abs/2507.23000", "title": "为更凉爽的城市规划：一种用于通过城市景观改造预测和缓解城市热应力的多模式AI框架", "title_en": "Planning for Cooler Cities: A Multimodal AI Framework for Predicting and Mitigating Urban Heat Stress through Urban Landscape Transformation", "authors": "Shengao Yi,Xiaojiang Li,Wei Tu,Tianhong Zhao", "background": "由于气候变化和城市化的加剧，极端热事件的频率和强度正在增加，这使得城市面临日益严峻的户外热应激缓解挑战。传统物理模型如SOLWEIG和ENVI-met虽然可以提供详细的人体感知热暴露评估，但由于其计算需求，难以满足城市范围规划的扩大要求。", "innovation": "本文提出了一种名为GSM-UTCI的多模式深度学习框架，用于预测一天中1米高精度下普遍热气候指数（UTCI）值。该模型通过特征层面的线性调制（FiLM）架构动态调整空间特征以适应大气环境，融合地表形态、高分辨率土地利用数据和逐小时气象条件。GSM-UTCI模型在SOLWEIG衍生的UTCI地图上训练，实现了接近物理的准确性，其R2为0.9151，均方误差（MAE）为0.41°C，同时将推理时间从数小时缩短到整个城市的不到五分钟。", "conclusion": "通过将GSM-UTCI应用于费城的城市景观改造模拟场景，结果表明改造后的景观具有空间异质但一致的降温效应，最显著的是将裸地和不透水面变成树冠层，降温范围为-4.18°C，面积为270.7 km2。街区级别的双变量分析进一步证实了热应力降低潜力与土地覆盖比例之间的强关联性。这些发现强调了GSM-UTCI作为适用于不同城市环境的可扩展、高分辨率决策支持工具的效用，使其能够基于情景评估城市绿化策略。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23001", "html_url": "https://arxiv.org/abs/2507.23001", "title": "LesionGen: 一种基于概念指导的皮肤影像合成扩散模型", "title_en": "LesionGen: A Concept-Guided Diffusion Model for Dermatology Image Synthesis", "authors": "Jamil Fayyad,Nourhan Bayasi,Ziyang Yu,Homayoun Najjaran", "background": "深度学习模型在皮肤疾病分类中需要大量、多样且注释良好的数据集。然而，由于隐私问题、高注释成本和缺乏代表性等原因，现有资源往往有限。尽管文本到图像扩散概率模型（T2I-DPMs）对于医疗数据合成具有潜力，但在皮肤病学领域的应用仍较少开发，主要是因为现有皮肤图像数据集中缺乏丰富和详细的文本描述。", "innovation": "本文介绍了LesionGen，一种临床灵感驱动的T2I-DPM框架，用于皮肤病学图像合成。与依赖于简单疾病标签的方法不同，LesionGen 基于注释专家和伪生成的概念引导报告中的结构化、概念丰富的医学描述进行训练。通过微调预训练的扩散模型，它可以生成基于有意义皮肤病描述的逼真且多样的皮肤病变图像。实验结果表明，仅使用合成数据集训练的模型在分类准确性上可与现实图像训练的模型相媲美，并且在最差情况亚组性能上有显著提升。", "conclusion": "我们的结果表明，基于合成数据集训练的模型在分类准确性上可与基于真实图像训练的模型相媲美，并且在最差情况亚组性能上有显著提升。模型、代码和数据可在指定网站获取。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23002", "html_url": "https://arxiv.org/abs/2507.23002", "title": "噪声编码照明用于法医和光电视频分析", "title_en": "Noise-Coded Illumination for Forensic and Photometric Video Analysis", "authors": "Peter F. Michael,Zekun Hao,Serge Belongie,Abe Davis", "background": "随着高级视频操控工具的普及，一种利益冲突的比赛正在形成，一方希望散播虚假信息，另一方则希望检测和揭露这些虚假。不幸的是，在这种竞争中，恶意方占据优势，假视频越来越难以辨别。这一趋势的根本原因是制造和操纵媒体的一方拥有平等访问我们认为真实（即“天然”）视频的权利。本文描述了一种新的方法，通过在场景照明中嵌入极其细微、噪声般的调制，以减少这种优势，从而增加验证的难度。我们的方法有效地为任何在编码照明下录制的视频添加了时间水印，但与传统的水印不同，这种方法不是嵌入特定的信息，而是嵌入原始未操纵场景的光照明亮图像。即使对手知道我们使用了这种技术，制造一个看似真实的假视频相当于解决一个更困难的原始对抗内容创建问题，但处于信息劣势。这种技术已经为公共活动和采访等高风险场景提供了一种保护方法，这些场景的内容很可能是被操纵的目标，但在这些场景中，可以控制照明，但无法控制拍摄视频的摄像机。", "innovation": "该研究提出了噪声编码照明作为一种方法，通过在场景照明中嵌入极其细微、噪声般的调制来对抗虚假视频。与传统的水印不同，这种方法不仅添加了时间水印，还嵌入了未操纵场景的光照明亮图像，从而在恶意一方试图制造假视频时增加难度，使其处于信息劣势。", "conclusion": "该技术为高风险视频场景提供了保护，例如公共活动和采访，即使对手了解该技术的存在，制造有说服力的假视频也变得非常困难，且处于信息劣势。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23219", "html_url": "https://arxiv.org/abs/2507.23219", "title": "使用小波基递归重建学习任意尺度RAW图像下缩放", "title_en": "Learning Arbitrary-Scale RAW Image Downscaling with Wavelet-based Recurrent Reconstruction", "authors": "Yang Ren,Hai Jiang,Wei Li,Menglong Yang,Heng Zhang,Zehua Sheng,Qingsheng Ye,Shuaicheng Liu", "background": "高分辨率图像的存储和传输效率对图像处理尤为重要。现有基于学习的方法主要在sRGB域内进行下缩放处理，这往往会损失细节并产生意外的伪影。未处理的光子信息使得RAW图像具有更大的灵活性，但缺乏专门的下缩放框架。", "innovation": "本文提出了一种基于小波的递归重建框架，利用小波变换的信息无损特性，通过从粗到细的方式，实现RAW图像的任意尺度下缩放。该方法提出了低频任意尺度下缩放模块（LASDM）和高频预测模块（HFPM），以保持低分辨率RAW图像的结构和纹理完整性。还引入了包含非整数下缩放因子1.3倍的新颖数据集Real-NIRD，并与其他整数因子数据集结合，用于扩大任意尺度图像下缩放的基准测试。实验表明，该方法在定量和视觉效果上均优于现有最先进的竞争对手。", "conclusion": "方法在多种基准测试中表现出色，且代码和数据集将开源发布。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23154", "html_url": "https://arxiv.org/abs/2507.23154", "title": "FuseTen: 时空卫星观测数据生成模型用于每日10米地面表层温度估算", "title_en": "FuseTen: A Generative Model for Daily 10 m Land Surface Temperature Estimation from Spatio-Temporal Satellite Observations", "authors": "Sofiane Bouaziz,Adel Hafiane,Raphael Canals,Rachid Nedjai", "background": "城市热浪、干旱和土地退化是气候变化背景下的紧迫且日益增长的挑战。研究这些现象需要准确的时间空间信息来了解地面状况。地表温度(LST)是评估和理解这些现象的关键变量之一，从中可获得有关地球表面热状态的重要信息。然而，卫星平台本身在空间分辨率和时间分辨率之间存在固有的权衡。为了弥合这一差距，本文提出了一种新颖的生成框架——FuseTen，通过融合来自Sentinel-2、Landsat 8和Terra MODIS的时空观测数据来生成每日10米分辨率的地表温度观测数据。", "innovation": "FuseTen引入了一种基于物理原则的加权平均监督策略，并采用了生成架构和注意力模块及归一化模块，通过PatchGAN判别器确保生成数据的真实性。实验结果显示， FuseTen在定量指标和视觉保真度方面均优于线性基准，特别是在定量指标上提高了32.06%，在视觉保真度上提高了31.42%。到目前为止，这是一次前所未有的尝试，使用非线性方法来生成如此精细空间分辨率的每日LST估算数据。", "conclusion": "本文提出了一种新颖的生成框架——FuseTen，用于从时空卫星观测数据生成每日10米分辨率的地表温度估计。实验结果表明，与线性基线相比，它在定量指标和视觉保真度方面表现出显著改进，是首个在此精细空间分辨率下生成每日LST估算的非线性方法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23273", "html_url": "https://arxiv.org/abs/2507.23273", "title": "GSFusion：全局优化的LiDAR-惯性-视觉映射用于高斯点云绘图", "title_en": "GSFusion:Globally Optimized LiDAR-Inertial-Visual Mapping for Gaussian Splatting", "authors": "Jaeseok Park,Chanoh Park,Minsu Kim,Soohwan Kim", "background": "尽管3D高斯散射（3DGS）极大地促进了逼真度的制图，传统的基于相机传感器的方法，包括RGB-D，仍面临一些根本性的限制，如高计算负担、在缺乏纹理或照明不良的环境下失效，以及操作范围短等问题。LiDAR作为一种稳健的替代方案虽然存在，但将其与3DGS集成使用时也会带来新的挑战，比如对于光致现实质量需要极佳的全局对齐以及由稀疏数据导致的长时间优化。", "innovation": "本文提出了一种新颖的在线LiDAR-惯性-视觉地图测绘系统GSFusion，该系统通过全局姿态图优化（GPVO）中的体素到体素约束来确保高精度的地图一致性。为了应对稀疏数据问题，系统采用了像素意识的高斯初始化策略以实现高效表示，并使用有界的Sigmoid约束来防止高斯体素的不可控增长。与现有的3DGS SLAM系统相比，GSFusion在渲染质量和地图构建效率方面表现更优，实验结果得到了验证。", "conclusion": "实验证明，我们的GSFusion系统在渲染质量以及地图构建效率方面击败了现有的3DGS SLAM系统。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23256", "html_url": "https://arxiv.org/abs/2507.23256", "title": "EMedNeXt: 使用MedNeXt V2与深度监督为撒哈拉以南非洲地区增强脑肿瘤分割框架", "title_en": "EMedNeXt: An Enhanced Brain Tumor Segmentation Framework for Sub-Saharan Africa using MedNeXt V2 with Deep Supervision", "authors": "Ahmed Jaheen,Abdelrahman Elsayed,Damir Kim,Daniil Tikhonov,Matheus Scatolin,Mohor Banerjee,Qiankun Ji,Mostafa Salem,Hu Wang,Sarim Hashmi,Mohammad Yaqub", "background": "全球范围内脑癌影响了大量人群，特别是在临床环境中，医生依赖磁共振成像（MRI）来诊断和监控胶质瘤。然而，目前通过手动分割多参数MRI进行肿瘤定量的标准方法耗时且需要专业知识，尤其是在资源不足的医疗体系中常常不可行。特别是在低收入地区，MRI扫描仪质量较低，放射学专业知识匮乏，导致分割和定量的错误。此外，在非洲地区，获得的MRI扫描数量通常较少。为应对这些挑战，BraTS-Lighthouse 2025挑战致力于在撒哈拉以南非洲（SSA）中实现鲁棒的肿瘤分割，该地区资源限制和图像质量降低带来了巨大的差异。", "innovation": "EMedNeXt是一种基于MedNeXt V2的增强脑肿瘤分割框架，引入了三个关键贡献：扩大的感兴趣区域、改进的基于nnU-Net v2的架构骨架，以及适应SSA的鲁棒模型集成系统。该框架解决了资源限制和图像质量降低的问题，提高了分割和定量的准确性，从而改善了非洲地区的肿瘤监测和治疗。在隐藏验证集上，EMedNeXt实现了平均病变智慧DSC值为0.897，以及各自的平均病变智慧NSD值为0.541和0.84，分别对应0.5mm和1.0mm的容差", "conclusion": "EMedNeXt在撒哈拉以南非洲地区通过改进的分割框架和深度监督方法，实现了高度准确的脑肿瘤分割，有助于改善资源限制条件下的肿瘤诊断和监测。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23359", "html_url": "https://arxiv.org/abs/2507.23359", "title": "管状神经元段落的像素嵌入方法", "title_en": "Pixel Embedding Method for Tubular Neurite Segmentation", "authors": "Huayu Fu,Jiamin Li,Haozhi Qu,Xiaolin Hu,Zengcai Guo", "background": "自动分割神经元树突拓扑结构对于处理大型神经影像数据至关重要，它能够大大加速神经元注释和分析。然而，神经元分支的复杂形态以及纤维之间的遮挡构成了使用深度学习进行分割的重大挑战。本研究旨在解决这些难题，通过提出改进的框架，包括输出像素级嵌入向量的深层网络、新型损失函数、完整的端到端管道以及新的拓扑评估方法，有效提高神经元结构的分割准确性与完整性，尤其是对于遮挡区域的不同神经连接的有效区分。最终，在fMOST成像数据集上的实验表明，与传统方法相比，该方法显著降低了神经元拓扑结构重建的错误率", "innovation": "本研究提出了通过输出像素级嵌入向量的深层网络和新型损失函数，有效区分局域遮挡区域内的不同神经连接。在此基础上，开发了端到端的管道直接将原始神经元图像转化为SWC格式的神经结构树。同时，提出了新的拓扑评估指标以更准确地量化神经元分割还原的质量，这些创新方法对神经影像数据的大规模处理具有重要意义", "conclusion": "本研究通过改进方法，有效提升了神经元树突拓扑结构的分割和重建精度，实验结果表明其在神经影像数据处理中的优越性，特别是在面对复杂遮挡情况下的表现良好。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23129", "html_url": "https://arxiv.org/abs/2507.23129", "title": "MRpro - 基于 PyTorch 的开放 MR 重建和处理包", "title_en": "MRpro - open PyTorch-based MR reconstruction and processing package", "authors": "Felix Frederik Zimmermann,Patrick Schuenke,Christoph S. Aigner,Bill A. Bernhardt,Mara Guastini,Johannes Hammacher,Noah Jaitner,Andreas Kofler,Leonid Lunin,Stefan Martin,Catarina Redshaw Kranich,Jakob Schattenfroh,David Schote,Yanglei Wu,Christoph Kolbitsch", "background": "目前，虽然已经存在多种磁共振成像（MRI）重建工具，但它们通常缺乏统一的数据处理结构和易于使用的深度学习组件，特别是对于开放式数据格式的支持不足。MRpro作为一个开源的图像重建包，它建立在PyTorch之上，并支持开放数据格式，旨在解决这些问题。", "innovation": "MRpro的主要创新在于其统一的数据结构，允许一致地处理MRI数据集及其元数据；其可组合的操作符库和优化算法，包括统一的Fourier操作符以及扩展的相位图模拟；对于深度学习，MRpro还提供数据一致性层、可微优化层、先进骨干网络，并集成公共数据集确保可重复性。这些设计使得MRpro能够应用于多种MRI成像场景，并提供了可扩展的框架。", "conclusion": "MRpro 作为一种支持自动质量控制的协作项目，提供了一个用于 MRI 图像重建的可扩展框架。该框架的核心是可重复性和可维护性，这促进了合作开发，并为未来的 MRI 成像研究奠定了基础。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23497", "html_url": "https://arxiv.org/abs/2507.23497", "title": "图像分类中因果识别必备、对比性和完整特征集", "title_en": "Causal Identification of Sufficient, Contrastive and Complete Feature Sets in Image Classification", "authors": "David A Kelly,Hana Chockler", "background": "现有的图像分类输出解释算法基于多种方法，且缺乏形式化严谨性。另一方面，逻辑基础的解释虽然形式化且严谨定义，但其计算性依赖于对模型的严格假设，这些假设并不适用于图像分类器。", "innovation": "该论文引入了因果解释，其不仅形式化且严格定义，同时具有逻辑基础解释的正式属性，又适合黑盒算法，并且是图像分类器的自然选择。证明了因果解释的正式属性，引入了对比因果解释，并且增加了可信度感知中的定义，提出了完备因果解释。该算法能够高效计算不同类型解释，每个图像平均仅需6秒，并且是完全黑盒的。", "conclusion": "不同模型具有不同的充分性、对比性和完备性模式。我们的算法既高效，又能提供各种类型的解释，并且是完全黑盒的，无需了解模型细节或其内部属性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23010", "html_url": "https://arxiv.org/abs/2507.23010", "title": "基于优化方法的多模态潜在空间可逆性研究：局限性", "title_en": "Investigating the Invertibility of Multimodal Latent Spaces: Limitations of Optimization-Based Methods", "authors": "Siwoo Park", "background": "本文探讨了特定任务AI模型中的多模态潜在空间的逆功能力及更广泛的实用性。尽管这些模型在设计的任务（如文本到图片生成、音频到文本转录）上表现出色，但其逆向映射的潜力尚未被充分研究。文章提出了一种基于优化的框架，旨在从所需输出推断输入特征，并应用于文本-图片（BLIP, Flux.1-dev）和文本-音频（Whisper-Large-V3, Chatterbox-TTS）模态的双向推理。研究团队假设，尽管优化可以引导模型执行逆向任务，但其多模态潜在空间并不总是能够支持语义上有意义且视觉上连贯的逆向映射。实验结果一致验证了这一假设。研究表明，虽然优化可以促使模型产生与目标文本对齐的输出（如文本到图片模型生成一张描述正确的图片，或ASR模型准确转录优化后的音频），这些逆向映射的感知质量是混乱且缺乏连贯性的。此外，试图从生成模型中推断原始语义输入时，重建的潜在空间嵌入往往缺乏语义可解释性，与无意义的词汇标记相一致。这些发现揭示了一个关键局限性：多模态潜在空间，主要针对特定前向任务进行了优化，本质上并不能提供用于稳健且可解释的逆向映射的结构。因此，本研究强调了进一步研究开发真正丰富的语义和可逆的多模态潜在空间的必要性。", "innovation": "本文提出了一种基于优化的框架来推断输入特征，并双向应用于文本-图片和文本-音频模态中，以探究多模态潜在空间的逆向能力。研究揭示了优化方法在引导多模态潜在空间执行逆任务时的局限性，即这些潜在空间不具备实现语义有意义且视觉连贯的逆映射所需的结构。这为开发真正丰富的语义和可逆的多模态潜在空间奠定了基础。通过该研究，强调了未来需要在构建可逆多模态潜在空间方面的进一步探索。", "conclusion": "研究发现，尽管优化可以促使模型生成与目标文本对齐的输出，但这些逆向映射的感知质量是混乱且缺乏连贯性的。此外，重建的潜在空间嵌入往往缺乏语义可解释性，与无意义的词汇标记相一致。这些发现揭示了一个关键局限性：多模态潜在空间不能提供用于稳健且可解释的逆向映射的结构。因此，未来研究需要进一步关注构建真正丰富的语义且可逆的多模态潜在空间。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23382", "html_url": "https://arxiv.org/abs/2507.23382", "title": "MPCC: 一种针对多模态大规模语言模型具有复杂约束的多模态规划的新基准", "title_en": "MPCC: A Novel Benchmark for Multimodal Planning with Complex Constraints in Multimodal Large Language Models", "authors": "Yiyan Ji,Haoran Chen,Qiguang Chen,Chengyue Wu,Libo Qin,Wanxiang Che", "background": "当前基准测试面临两个关键挑战：（1）无法直接评估多模态实际世界的规划能力；（2）缺乏跨模态的约束或隐式约束。这些挑战对复杂推理和多步骤决策提出了要求，使得现有的基准测试无法全面评估多模态大型语言模型（MLLM）在处理多模式约束方面的表现能力。因此，本研究引入了Multimodal Planning with Complex Constraints（MPCC），这是一个系统地评估MLLM处理多模式约束能力的第一个基准测试，重点关注飞行规划、日历规划和会议规划三个实际任务，并引入了预算、时间和空间等复杂约束，这些约束具有不同程度的难度，以区分约束复杂性和搜索空间扩展。", "innovation": "MPCC 是第一个系统评估 MLLMs 处理多模态约束能力的基准测试，特别关注引入了复杂约束（如预算、时间和空间约束）的任务，并且这些约束具有不同程度的难度，以区别约束复杂性和搜索空间扩展。实验结果显示，封闭源模型只能实现21.3%的可行方案，而开源模型的平均值低于11%，表明这些模型对约束复杂性非常敏感，传统的多模式提示策略在多约束场景下失效。MPCC 形式化了规划中的多模态约束，提供了一个严格的评估框架，强调了对于实际应用中多模态大型语言模型的约束感知推理方面的进步需求。", "conclusion": "MPCC 展示了显著的挑战，揭示了多模态大型语言模型在实时应用中处理多模态约束的能力较为薄弱，也为进一步研究提供了参考框架。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23521", "html_url": "https://arxiv.org/abs/2507.23521", "title": "JPNeO：用于向后兼容编码的JPEG处理神经运算符", "title_en": "JPEG Processing Neural Operator for Backward-Compatible Coding", "authors": "Woo Kyoung Han,Yongjun Lee,Byeonghun Lee,Sang Hyun Park,Sunghoon Im,Kyong Hwan Jin", "background": "在学习型失真压缩算法取得重大进展后，标准编码器和解码器（codecs）的标准化仍然是一个关键挑战。现有的JPEG处理方法在保持色度分量保存和重建精度方面存在局限性，并且通常伴随着较高的内存使用和参数数量。本文的研究背景是，在不修改源编码协议的情况下，开发一个新的JPEG算法，以提高色度分量保存和增强重建保真度，同时减少内存占用和参数数量。", "innovation": "本文的创新点在于提出了一种名为JPNeO的JPEG处理神经运算符算法。JPNeO在编码和解码阶段都使用了神经运算符，实现了向后兼容性、提高了色度分量的保存和重建保真度，同时减少了内存使用量和参数数量。此外，通过实证证据验证了高互信息空间的存在。", "conclusion": "JPNeO作为一个高性能的即插即用图像压缩管道，可以在不改变源编码协议的情况下提升图像压缩质量。该研究的结果表明，神经运算符可以在保持兼容性的同时进一步优化图像压缩算法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23398", "html_url": "https://arxiv.org/abs/2507.23398", "title": "智能视频胶囊内镜：基于原始图像的定位以增强消化道检查", "title_en": "Smart Video Capsule Endoscopy: Raw Image-Based Localization for Enhanced GI Tract Investigation", "authors": "Oliver Bause,Julia Werner,Paul Palomero Bernardo,Oliver Bringmann", "background": "在低功耗传感器边缘设备中使用深度神经网络进行图像分类可能不太合适，因为它们通常模型庞大且计算需求往往超出这些资源有限的设备的能力。此外，摄像头传感器捕获的图片通常是带有拜亚德色滤镜的，随后被转换为用于神经网络训练的RGB图像。然而，在资源受限的设备上，这样的转换耗能且如果可能应该被省去。针对这些情况，通过视频胶囊内镜技术处理基于资源有限设备边缘计算的需求。视频胶囊内镜是一种重要的医疗程序，适用于小肠检查，但主要限制在于电池寿命。在拜亚德图像上进行器官分类，准确率达到93.06%，并采用只有63,000参数的卷积神经网络和维特比解码的时间序列分析方法。此外，本文展示了捕获图像和原始图像处理的过程，使用了定制化的PULPissimo片上系统，配备RISC-V核心和超低功耗硬件加速器，提供了高效的基于AI的图像分类方法，每次图像仅需5.31微焦耳能量。这样一来，比起传统视频胶囊，进入小肠前能够节省89.9%的能量。", "innovation": "提出了将基于拜亚德图像的准确器官分类方法，使用具备63,000参数的CNN模型和时间序列分析方法；采用定制化的PULPissimo SoC和RISC-V核心及超低功耗硬件加速器，实现高效的AI图像分类，只需要5.31微焦耳能量每张图像。并解决了在低功耗设备上直接处理拜亚德图像的能效问题。", "conclusion": "本文通过直接在拜亚德图像上执行精确的器官分类，并且仅使用5.31微焦耳的能量，实现在电池寿命受限的环境下的高效AI图像分类，特别适用于如视频胶囊内镜这种需要长时间工作的医疗设备。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23534", "html_url": "https://arxiv.org/abs/2507.23534", "title": "利用合成边界经验混合实现连续学习", "title_en": "Continual Learning with Synthetic Boundary Experience Blending", "authors": "Chih-Fan Hsu,Ming-Ching Chang,Wei-Chao Chen", "background": "连续学习（CL）旨在解决模型在顺序训练多个任务时出现的灾难性遗忘问题。尽管经验重演已有一定的效果，但它受限于存储的关键样本稀疏分布，导致决策边界过于简单。本文提出了一种新的假设，即在训练过程中引入靠近决策边界的合成数据（称为合成边界数据，SBD），通过这种方式在一定程度上作为隐式正则化手段，提高边界稳定性并减少遗忘现象。", "innovation": "提出了一个新颖的训练框架——经验混合（Experience Blending），该框架结合了存储的关键样本和合成边界数据，提高了模型的性能。具体创新点包括：1) 一种基于多变量差分隐私（DP）的噪声机制，通过注入批次级噪声到低维特征表示中生成SBD；2) 一种端到端的训练策略，同时利用存储的关键样本和SBD。", "conclusion": "通过在CIFAR-10、CIFAR-100和Tiny ImageNet上的大量实验表明，该方法比九种连续学习基线算法的性能更好，分别实现了10%、6%和13%的准确率改进。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23544", "html_url": "https://arxiv.org/abs/2507.23544", "title": "通过多实例学习的多模态社会信号估算人类与机器人交互中的用户体验", "title_en": "User Experience Estimation in Human-Robot Interaction Via Multi-Instance Learning of Multimodal Social Signals", "authors": "Ryo Miyoshi,Yuki Okafuji,Takuya Iwamoto,Junya Nakanishi,Jun Baba", "background": "近年来，对社交机器人的需求增长，要求它们根据用户的状态调整行为。准确评估人类与机器人互动（HRI）中的用户体验（UX）对于实现这种适应性至关重要。UX作为多方面的衡量标准，包括情感和参与度等方面，但现有方法往往仅侧重于其中的单一方面。因此，本文通过多模态社会信号，提出了一种UX估计方法。", "innovation": "本文通过多模态社会信号（如面部表情和语音）构建了UX数据集，并开发了一种基于Transformer的模型，该模型利用面部表情和语音进行估算。与此不同的是，我们的方法采用多实例学习框架，能够捕捉短期和长期的交互模式，从而捕捉UX的时间动态，提供更全面的表示。实验结果表明，该方法在用户体验估算方面优于第三方人类评估者。", "conclusion": "本文提出了一种通过多实例学习和多模态社会信号估算HRI中用户体验的方法。实验表明，该方法在用户体验估算方面优于人类评估者。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23540", "html_url": "https://arxiv.org/abs/2507.23540", "title": "一种用于自适应自动驾驶的统一感知-语言-动作框架", "title_en": "A Unified Perception-Language-Action Framework for Adaptive Autonomous Driving", "authors": "Yi Zhang,Erik Leo Haß,Kuo-Yi Chao,Nenad Petrovic,Yinglei Song,Chengdong Wu,Alois Knoll", "background": "自主驾驶系统在复杂、开放环境中的适应性、鲁棒性和可解释性方面面临重大挑战。这些挑战来自分散的架构、对新颖场景的一般化不足以及感知中的语义提取不足。", "innovation": "提出了一种统一的感知-语言-动作（PLA）框架，该框架结合了多传感器融合（相机、激光雷达、雷达）与大型语言模型（LLM）增强的视觉-语言-动作（VLA）架构，特别是由GPT-4.1赋能的推理核心。该框架将低级感测处理与高级上下文推理统一起来，紧密耦合感知与基于自然语言的语义理解和决策，以实现情境感知、可解释和安全保障的自主驾驶。", "conclusion": "在包含施工区的城市交叉口场景下的评估表明，该框架在轨迹跟踪、速度预测和适应性规划方面表现出优越性能。结果突显了语言增强认知框架在增强自主驾驶系统安全、可解释性和可扩展性方面的潜力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23771", "html_url": "https://arxiv.org/abs/2507.23771", "title": "共识驱动的主动模型选择", "title_en": "Consensus-Driven Active Model Selection", "authors": "Justin Kay,Grant Van Horn,Subhransu Maji,Daniel Sheldon,Sara Beery", "background": "随着现成的机器学习模型的广泛可用性，如何为给定的数据分析任务选择一个合适的模型成为了一个挑战。传统的模型选择方法需要收集和标注验证数据集，这是一个成本高、耗时长的过程。因此，研究者提出了主动模型选择的方法，利用候选模型的预测结果优先标注测试数据，从而提高选择最优模型的效率。", "innovation": "该方法名为CODA，通过在概率框架内建模分类器、类别和数据点之间的关系，实现共识驱动的主动模型选择。CODA利用候选模型之间的一致性和分歧来指导标签获取过程，并使用贝叶斯推断不断更新关于哪个模型更优的信念，从而显著提高了发现最优模型所需的标注努力。", "conclusion": "CODA方法在一系列基准任务中获得了优异表现，与现有最优方法相比，能够显著减少找到最佳模型所需的标注工作量，最多可减少70%。该方法通过概率框架利用模型之间的一致性和分歧指导标签的选取，并使用贝叶斯推断来不断更新模型最佳性的信念。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23648", "html_url": "https://arxiv.org/abs/2507.23648", "title": "向现场适用的基于AI的疟疾诊断迈进：一种连续学习的方法", "title_en": "Towards Field-Ready AI-based Malaria Diagnosis: A Continual Learning Approach", "authors": "Louise Guillon,Soheib Biga,Yendoube E. Kantchire,Mouhamadou Lamine Sane,Grégoire Pasquier,Kossi Yakpa,Stéphane E. Sossou,Marc Thellier,Laurent Bonnardot,Laurence Lachaud,Renaud Piarroux,Ameyo M. Dorkenoo", "background": "疟疾仍然是全球性的重要公共卫生挑战，特别是在资源匮乏的地区，这些地区的专家显微镜检查接入可能有限。基于深度学习的计算机辅助诊断（CAD）系统已被开发并在薄血膜图像上表现出卓越性能，但是其临床部署可能因不同地区条件的变化而受限于泛化能力不足。然而，截至目前，很少有实用的解决方案被提出。因此，该研究探讨了连续学习（CL）作为增强疟疾CAD模型稳定性的策略，将其定为逐步增量学习的场景，让YOLO基于对象检测器能够适应新的采集地点并保持在先前已见领域的性能。", "innovation": "研究采用连续学习（CL）策略，试图增强疟疾CAD模型对领域变化的适应性，通过逐步增量学习的框架，让YOLO基于对象检测器适应新的采集地点并保持已见领域的性能。研究评估了四种CL策略，包括两种复习基于的方法和两种正则化基于的方法，均在多站点临床数据集的薄血膜图像上进行实际条件下的测试。研究表明，连续学习能够显著提高性能，特别是复习基于的方法表现尤为突出，揭示了连续学习在支持开发可部署和现场适用的CAD工具中的潜力。", "conclusion": "研究结果表明，连续学习，尤其是复习基于的方法，能够显著提升疟疾CAD模型的性能。这项研究表明，连续学习在支持开发可部署和可应用于现场的CAD工具中的潜在价值。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23777", "html_url": "https://arxiv.org/abs/2507.23777", "title": "XSpecMesh：通过多头推测解码保持质量的自动回归网格生成加速", "title_en": "XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding", "authors": "Dian Chen,Yansong Qu,Xinyang Li,Ming Li,Shengchuan Zhang", "background": "当前的自回归模型可以生成高质量、拓扑正确的网格，但它们在推理过程中需要进行成千上万甚至数十万的下个标记预测，导致延迟较高。现有方法在保证生成质量的同时面临推理速度慢的挑战。", "innovation": "提出了一种名为XSpecMesh的质量保留加速方法，通过轻量级的多头推测解码方案，在单次前向传递中并行预测多个标记，加速推理过程。进一步提出一种验证和重采样策略，以及一种蒸馏策略，通过蒸馏从骨干模型训练轻量级解码头部，使其预测分布一致，提高推测预测的成功率。实验表明，该方法在不牺牲生成质量的情况下实现了1.7倍的加速效果。", "conclusion": "XSpecMesh通过多头推测解码加速自回归网格生成模型，同时保持生成质量，实现1.7倍的加速效果。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23763", "html_url": "https://arxiv.org/abs/2507.23763", "title": "医学图像分割中基于快速欧拉特征的拓扑优化", "title_en": "Topology Optimization in Medical Image Segmentation with Fast Euler Characteristic", "authors": "Liu Li,Qiang Ma,Cheng Ouyang,Johannes C. Paetzold,Daniel Rueckert,Bernhard Kainz", "background": "基于深度学习的医学图像分割技术在传统的评估指标如Dice系数或交并比方面表现出了良好的结果。然而，这些全自动方法在确保拓扑约束（如连续边界或封闭表面）时通常无法达到临床可接受的准确度。在医学图像分割中，有时拓扑结构的正确性比像素级准确度更为重要。现有的拓扑感知方法通常通过持久同调的概念估计并约束拓扑结构，但这些方法对于高维数据实施起来困难，因为它们的计算复杂度为多项式。因此，该研究提出了一种基于欧拉特征的新颖且快速的方法，以提升拓扑感知性能。", "innovation": "提出了一种基于欧拉特征（$\boldsymbol{\text{χ}}$）的快速拓扑感知分割方法，首先提出了二维和三维中欧拉特征计算的快速算法；其次，通过所谓拓扑违反地图，即详细表示$\boldsymbol{\text{χ}}$错误的区域，评估任何分割网络的空间拓扑正确性；最后，基于拓扑违反地图通过拓扑感知修正网络改进分割结果。该方法能够在保持像素级分割准确性的前提下，显著提高拓扑正确性。实验结果也验证了该方法的有效性。", "conclusion": "该方法能够显著提升拓扑正确性，同时保持像素级分割准确性，并在2D和3D数据集上的实验结果中得到了验证。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23676", "html_url": "https://arxiv.org/abs/2507.23676", "title": "DepMicroDiff：基于扩散依赖感知多模态插补的微生物数据", "title_en": "DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for Microbiome Data", "authors": "Rabeya Tus Sadia,Qiang Cheng", "background": "微生物数据对于理解宿主健康和疾病至关重要，但由于其固有的稀疏性和噪声，这些特性为准确插补造成了重大挑战，影响了后续任务，如生物标志物的发现。现有插补方法，包括最近的扩散模型，往往无法捕捉微生物种群之间的复杂相互依赖关系，忽视了可以辅助插补的过程上下文元数据。", "innovation": "提出了一种新的框架DepMicroDiff，将基于扩散的生成建模与依赖感知变换器（DAT）相结合，显式地捕捉微生物种群之间的双重关联依赖关系和自回归关系。通过使用基于VAE的预训练和大型语言模型（LLM）对患者元数据的条件处理，进一步增强了DepMicroDiff。实验结果显示，DepMicroDiff在TCGA微生物数据集上优于最先进的基线方法，其皮尔森相关系数最高可达0.712，余弦相似度最高可达0.812，同时具有较低的RMSE和MAE，展示了其在微生物数据插补中的稳健性和泛化能力。", "conclusion": " DepMicroDiff通过结合基于扩散的生成模型和依赖感知变换器，在微生物数据插补方面取得了显著的性能提升，展现了其在多种癌症类型中的高适用性和优越性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.02630", "html_url": "https://arxiv.org/abs/2410.02630", "title": "了解基于距离的图像分割度量实现中的问题", "title_en": "Understanding implementation pitfalls of distance-based metrics for image segmentation", "authors": "Gasper Podobnik,Tomaz Vrtovec", "background": "基于距离的度量方法，如哈斯多夫距离（HD），在（生物）医学成像的分割性能验证中广泛应用。但这些方法的实现复杂，开源工具之间的关键差异尚未被充分认识。这些差异削弱了基准测试的努力，引入了生物标志物计算偏差，并可能扭曲医疗设备开发和临床应用。", "innovation": "研究系统地剖析了11个开源工具的基于距离的度量计算实现，通过概念分析和代表性二维和三维图像数据集的实证分析，发现哈斯多夫距离的偏差超过100毫米，并且多个工具之间存在统计显著差异，表明即使使用相同的分割序列，通过选择特定的实现方式也能达到统计学意义上的改进。", "conclusion": "研究结果表明，在跨研究比较结果时未考虑度量实现差异的有效性值得怀疑。为此，研究提供了工具选择的实用建议，并通过对概念分析的启示，为未来开源工具的实现方式演进提供指导。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.05343", "html_url": "https://arxiv.org/abs/2410.05343", "title": "EgoOops: 一个基于执 RandomForest 者视角视频和程序化文本的错误动作检测数据集", "title_en": "EgoOops: A Dataset for Mistake Action Detection from Egocentric Videos referring to Procedural Texts", "authors": "Yuto Haneji,Taichi Nishimura,Hirotaka Kameko,Keisuke Shirai,Tomoya Yoshida,Keiya Kajimura,Koki Yamamoto,Taiyu Cui,Tomohiro Nishimoto,Shinsuke Mori", "background": "错误动作检测对于开发能够检测工作者错误并提供反馈的智能档案至关重要。现有研究主要集中在自由式活动中显而易见的错误检测上，因此使用了仅基于视频的方法。然而，在遵循文本指导的活动中，模型无法在未参考文本的情况下确定某些动作的正确性。目前，用于错误检测的数据集很少采用程序化文本进行视频录制，除了烹饪领域。因此，本研究在各领域中提出了EgoOops数据集，通过第一人称视角视频记录在遵循程序化文本时的错误活动，并包括视频-文本对齐、错误标签和错误描述三种注释类型。", "innovation": "本研究提出了EgoOops数据集，该数据集通过第一人称视角视频记录在遵循程序化文本时的错误活动，涵盖多个领域，并且首次实现了视频-文本对齐、错误标签和错误描述三个方面的结合注释。此外，本研究还提出了一种错误检测方法，结合了视频-文本对齐和错误标签分类，以利用程序化文本。实验结果显示，采用程序化文本对于错误检测至关重要。", "conclusion": "实验结果表明，结合程序化文本对于错误检测是必要的。该数据集和提出的错误检测方法为这一领域提供了新的工具和方法，有助于改进现有的错误检测模型。数据可以通过以下链接获取：this https URL."}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.18266", "html_url": "https://arxiv.org/abs/2311.18266", "title": "基于提示的示例超压缩与再生用于类别增量学习", "title_en": "Prompt-Based Exemplar Super-Compression and Regeneration for Class-Incremental Learning", "authors": "Ruxiao Duan,Jieneng Chen,Adam Kortylewski,Alan Yuille,Yaoyao Liu", "background": "基于回放的方法在类别增量学习（CIL）中取得了显著的成功。然而，这些方法固有的内存限制导致只能保存有限数量且多样性较低的样本。本文探讨了如何利用预训练的通用扩散模型来大幅增加样本数量并提升样本多样性，同时避免对目标数据集进行微调和占用内存缓冲区。通过将图像压缩为视觉和文本提示，而不是存储原始图像，内存消耗减少了24倍，并且通过扩散模型在后续阶段再生多样样本以最小化生成样本与真实图像之间的领域差距。这些措施显著提高了多项基准上的CIL性能，例如ImageNet-100上的性能提升了3.2%至最新的技术前沿水平之上。", "innovation": "提出了一种名为PESCR的新颖方法，能够在不微调目标数据集或存储在内存缓存中的情况下，大幅增加示例数量并提高其多样性。通过将图像压缩为视觉和文本提示存入内存，不仅减少了内存消耗，还利用扩散模型再生多样化的示例。此外，还提出了部分压缩和基于数据扩增的扩散方法来最小化生成示例与真实图像之间的领域差距。", "conclusion": "PESCR方法显著提升了多项类增量学习（CIL）基准的性能，尤其是ImageNet-100数据集上的性能提升了3.2%至最新技术水平。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.02123", "html_url": "https://arxiv.org/abs/2408.02123", "title": "FovEx: Human-Inspired Explanations for Vision Transformers and Convolutional Neural Networks", "title_en": "FovEx: Human-Inspired Explanations for Vision Transformers and Convolutional Neural Networks", "authors": "Mahadev Prasad Panda,Matteo Tiezzi,Martina Vilas,Gemma Roig,Bjoern M. Eskofier,Dario Zanca", "background": "解释性在人工智能（XAI）中仍然是培养对机器学习模型的信任和理解的关键方面。当前的视觉解释技术，如基于梯度的方法或类激活映射方法，通常强烈依赖于特定的模型架构。相比之下，基于扰动的方法虽然不受制于特定模型架构，但计算成本较高，因为它们需要在大量的前向传递中评估模型。因此，需要一种新的XAI方法，该方法既能够捕捉人类视觉机制，又能够在节省计算成本的同时提供有效的解释性。", "innovation": "本文介绍了一种新颖的XAI方法——Foveation-based Explanations（FovEx），它借鉴了人类视觉原理，通过迭代创建图像的焦点渲染并结合基于梯度的视觉探索来确定兴趣点，从而高效地生成归因图。FovEx方法在不对特定架构产生依赖的情况下，能够在多种架构中实现最先进的性能，并且解释图谱与人类注视模式高度对齐，进一步证明了FovEx在解释差距上的有效性。", "conclusion": "FovEx方法在视觉变换器和卷积神经网络中均实现了最先进的性能，特别是在四个指标中优于其他方法，同时解释图谱与人类注视模式的相似程度显着提高，表明FovEx能够在人类和机器之间建立更好的理解。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23523", "html_url": "https://arxiv.org/abs/2507.23523", "title": "H-RDT：增强双臂机器人操作的人类操作数据", "title_en": "H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation", "authors": "Hongzhe Bi,Lingxuan Wu,Tianwei Lin,Hengkai Tan,Zhizhong Su,Hang Su,Jun Zhu", "background": "模仿学习在机器人操作领域的核心挑战在于缺少大规模、高质量的机器人演示数据。尽管机器人基础模型可以通过跨体态的机器人数据集进行预训练以增加数据规模，但它们仍面临挑战，因为不同体态的机器人具有不同的形态和动作空间，使得统一训练变得困难。", "innovation": "本文提出了一种名为H-RDT（Human to Robotics Diffusion Transformer）的新颖方法，利用人类操作数据增强机器人的操作能力。核心思想是大规模的第一视角人类操作视频及其配对的3D手部姿态注释，提供了丰富的行为先验，捕捉了自然的操作策略，可改进机器人策略学习。H-RDT采用两阶段训练模式：首先基于大规模的第一视角人类操作数据进行预训练，接着通过模块化动作编码器和解码器跨体态微调特定于机器人的数据。基于扩散变换器架构并带有20亿参数，H-RDT使用流匹配来建模复杂动作分布。", "conclusion": "广泛的评估表明，H-RDT在模拟和真实世界实验中均优于从零开始训练和现有的最佳方法，包括Pi0和RDT。在模拟实验中，H-RDT的性能提高了13.9%，在真实世界实验中提高了40.5%，验证了我们的核心假设，即人类操作数据可以作为学习双臂机器人操作策略的强大基础。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2404.17484", "html_url": "https://arxiv.org/abs/2404.17484", "title": "使用替代状态空间模型和注意力机制的光学多普勒断层扫描稀疏重构", "title_en": "Sparse Reconstruction of Optical Doppler Tomography with Alternative State Space Model and Attention", "authors": "Zhenghong Li,Jiaxiang Ren,Wensheng Cheng,Yanzuo Liu,Congwu Du,Yingtian Pan,Haibin Ling", "background": "光学相干多普勒断层成像（ODT）是一种新兴的血流成像技术。ODT的基本单元是深度分辨的一维扫描（称为原始A-扫描或A线）。通过沿B-线进行多普勒相位减加以原始A-扫描重建横截面血流图像，从而形成2D ODT图像（B扫描）。为了获得高质量的B扫描图像，目前需要密集采样的A扫描，导致扫描时间过长和存储需求增加。为此，我们提出了一种新颖的稀疏ODT重构框架，结合了交替状态空间注意力网络（ASSAN），以有效减少所需的原始A扫描数量。", "innovation": "我们通过结合交替状态空间模型和注意力机制提出了一种新颖的稀疏ODT重构框架（ASSAN），它将状态空间模型应用于每个A线以学习局内A扫描表示，使用门控自我注意力机制捕捉跨A扫描特征，并结合有效的基于沿不同轴的1D卷积的前馈网络增强局部特征，从而在实际动物数据验证实验中明显优于现有最先进的重构方法，提高了重构的有效性。", "conclusion": "通过ASSAN框架，显著减少了原始A扫描的需求，从而提高了重建的质量和效率，缩短扫描时间和减少存储需求，满足了高精度和高效率的要求。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.23611", "html_url": "https://arxiv.org/abs/2507.23611", "title": "基于LLM的截图中信息盗取者感染向量的识别：以Aurora为例", "title_en": "LLM-Based Identification of Infostealer Infection Vectors from Screenshots: The Case of Aurora", "authors": "Estelle Ruellan,Eric Clay,Nicholas Ascoli", "background": "信息盗取者通过感染系统窃取凭证、会话cookie和敏感数据。2024年报告了超过2900万条信息盗取的日志，这使得大规模的手动分析和缓解几乎不可能实现。尽管大多数研究集中在主动式恶意软件检测，但对信息盗取者日志及其相关漏洞的反应性分析仍然存在较大空白。特别是在现有文献中，感染截图等感染残留物被广泛忽视。研究表明，通过L大型语言模型（LLMs）特别是gpt-4o-mini，对感染截图进行分析，可以从这些截图中提取潜在的恶意活动指标（IoCs），映射感染路径，并追踪活动，揭示其中的关键细节。研究数据发现，能够从1000张截图中提取出337个有行动意义的网址和246个相关文件。", "innovation": "该研究引入了一种新颖的方法，利用大型语言模型（LLMs）特别是gpt-4o-mini，通过对感染截图进行分析来提取潜在的入侵指标（IoCs），确定感染途径，并追踪活动。它展示了如何识别感染途径，如恶意URL、安装程序文件以及被利用的软件主题，从而揭示关键的恶意软件传播手段和社会工程攻击策略。", "conclusion": "本研究通过将恶意软件分析从传统的基于日志的检测方法转向基于截图的反应性分析，提出了一种可扩展的方法来识别感染途径，并允许早期干预，展示了基于LLM分析方法在识别感染流程和提高威胁情报方面的潜力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.04351", "html_url": "https://arxiv.org/abs/2411.04351", "title": "LidaRefer: 自主驾驶场景中的上下文感知户外3D视觉定位", "title_en": "LidaRefer: Context-aware Outdoor 3D Visual Grounding for Autonomous Driving", "authors": "Yeong-Seung Baek,Heung-Seon Oh", "background": "3D视觉定位（VG）旨在根据自然语言描述在3D场景中定位物体或区域。虽然室内3D VG已经有了显著的发展，但户外3D VG由于两个挑战仍然被探索较少：（1）大规模的户外激光雷达（LiDAR）场景主要由背景点构成，前景信息有限，这使得跨模态对齐和上下文理解更加困难；（2）大多数户外数据集缺乏对于参考非目标物体的空间标注，这阻碍了对参考上下文的明确学习。", "innovation": "我们提出了LidaRefer，一个面向户外场景的上下文感知3D视觉定位框架。LidaRefer集成了以对象为中心的特征选择策略，专注于语义相关视觉特征，同时减少计算开销。基于Transformer的编码器-解码器架构在精细粒度的跨模态对齐和全面的全局上下文捕捉方面表现出色。此外，我们还提出了区分性支持协作定位（DiSCo）的监督策略，明确建模了目标、上下文和模糊对象之间的空间关系，以实现准确的目标识别。为实现这一目标，我们引入了一种伪标签方法，用于获取非目标物体的3D定位标签。LidaRefer在多种评估设置下都实现了Talk2Car-3D数据集的状态最佳表现。", "conclusion": "LidaRefer框架在Talk2Car-3D数据集的各种评估设置下，展现了比之前方法更佳的性能，证明了其在户外场景中进行3D视觉定位的有效性和潜力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.02201", "html_url": "https://arxiv.org/abs/2501.02201", "title": "视觉问题中的焦点模糊性识别", "title_en": "Acknowledging Focus Ambiguity in Visual Questions", "authors": "Chongyan Chen,Yu-Yun Tseng,Zhuoheng Li,Anush Venkatesh,Danna Gurari", "background": "目前关于视觉问答（VQA）的研究没有考虑问题描述的内容在图像中的位置的模糊性。本文旨在填补这一空白，提出了第一个考虑图像中每个可能回答所对应区域的VQA数据集，即VQ-FocusAmbiguity。", "innovation": "引入了VQ-FocusAmbiguity数据集，该数据集针对每个问题识别可能的答案时，考虑了图像中的所有可能区域。分析并与现有数据集进行比较，揭示了其独特的属性，并针对承认焦点模糊性和在图像中找到所有可能的焦点区域两个新任务，对现代模型进行基准测试。", "conclusion": "实验证明，该数据集对现代模型构成挑战。为了促进这些任务的进一步研究，公开发布了该数据集及其评估服务器。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.11098", "html_url": "https://arxiv.org/abs/2411.11098", "title": "MolParser: 在野生环境中的分子结构端到端视觉识别", "title_en": "MolParser: End-to-end Visual Recognition of Molecule Structures in the Wild", "authors": "Xi Fang,Jiankun Wang,Xiaochen Cai,Shangqian Chen,Shuwen Yang,Haoyi Tao,Nan Wang,Lin Yao,Linfeng Zhang,Guolin Ke", "background": "近年来，化学出版物和专利数量迅速增加，关键信息主要嵌入在分子结构图中，这使得大规模文献检索变得复杂，并限制了大型语言模型在生物学、化学和制药领域中的应用。自动提取精确的化学结构是至关重要的。然而，实际文档中存在大量的Markush结构，以及分子图像质量、绘画风格和噪声的变化，极大地限制了现有光学化学结构识别(OCSR)方法的性能。", "innovation": "我们提出了MolParser，一种新型的端到端OCSR方法，能够高效准确地识别实际文档中的化学结构，包括复杂的Markush结构。我们扩展了SMILES编码规则来标注我们的训练数据集，并构建了迄今为止最大的标注分子图像数据集MolParser-7M。利用大量合成数据，并通过主动学习方法将来自实际专利和科学文献的大量野外数据纳入训练过程。我们使用逐级学习方法对整个分子图像表征模型MolParser进行了训练，MolParser在大多数场景中显著优于经典和基于学习的方法，具有更大的下游应用潜力。", "conclusion": "MolParser在广泛的下游应用中表现出色，并且其数据集在Hugging Face上公开可用。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2304.01430", "html_url": "https://arxiv.org/abs/2304.01430", "title": "Divided Attention: 无监督的上下文分离槽多对象发现", "title_en": "Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots", "authors": "Dong Lao,Zhengyang Hu,Francesco Locatello,Yanchao Yang,Stefano Soatto", "background": "该研究探讨了在无任何语义标注的情况下，视觉感知中物体的出现。现有的方法通常依赖预训练的特征或监督学习，但在本研究中，开发了一种未接收到任何监督的模型，可以在未使用任何预训练特征的情况下，将图像分割成多个独立移动的区域。这种运动分割方法能够在实时处理中处理未知且变化的物体数量。", "innovation": "研究提出了一种多模态条件编码器-解码器架构，通过上下文分离的槽（slots）来实现无监督的多对象发现。架构中的编码器接收一种模态（光流）的数据，生成一组潜在代码，而解码器则根据另一种模态（颜色图像）的数据，从中生成目标模态（如光流）。训练过程设计的判别标准旨在促进这些槽之间的信息分离，同时架构明确地将激活分配给各个槽，提出了名为Divided Attention (DivA)的方法。DivA能在处理不同数量的物体和不同分辨率图像时表现出稳定性，其运行时间比相似方法快三倍，可以达到104 FPS，相对于监督方法的性能差距缩小到12%或以下。", "conclusion": "DivA在短视频片段上进行训练后，可以限制静态分类器通过对比学习进行预训练，与直接在视频帧上训练相比，使用DivA的物体提案进行DINO训练时，相对于基于ImageNet的训练，性能差距可减少多达30.2%。该方法在处理不同数量物体和分辨率图像时具有良好的灵活性和实时性能，展示了其在视觉感知中的强大性能，同时解决了监督方法中常见的问题。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.18659", "html_url": "https://arxiv.org/abs/2411.18659", "title": "DHCP: 在大规模视觉-语言模型中通过跨模态注意模式检测幻觉", "title_en": "DHCP: Detecting Hallucinations by Cross-modal Attention Pattern in Large Vision-Language Models", "authors": "Yudong Zhang,Ruobing Xie,Xingwu Sun,Yiqing Huang,Jiansheng Chen,Zhanhui Kang,Di Wang,Yu Wang", "background": "大规模视觉-语言模型在复杂的多模态任务中表现出色，但仍然存在显著的幻觉问题，包括物体、属性和关系方面的幻觉。为了准确检测这些幻觉，研究者们分析了幻觉和非幻觉状态下跨模态注意力模式的变化，开发了一种轻量级的检测器来识别幻觉。", "innovation": "提出了一种名为Detecting Hallucinations by Cross-modal Attention Patterns (DHCP) 的方法，该方法无需额外训练大型视觉-语言模型或额外的LVLM推理步骤，即可检测幻觉，且性能显著。", "conclusion": "DHCP 为大规模视觉-语言模型中幻觉的识别和分析提供了新的见解，有助于提高这些模型的可靠性和可信度。代码已在GitHub上公开。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.18823", "html_url": "https://arxiv.org/abs/2411.18823", "title": "多层次任务令牌用于部分标注密集预测的多任务标签发现", "title_en": "Multi-Task Label Discovery via Hierarchical Task Tokens for Partially Annotated Dense Predictions", "authors": "Jingdong Zhang,Hanrong Ye,Xin Li,Wenping Wang,Dan Xu", "background": "近年来，同时使用部分标注标签数据学习多个密集预测任务已成为一个重要研究领域。以往研究主要侧重于利用跨任务关系或进行对抗训练以获取额外正则化，从而取得了显著的效果，但仍然面临缺乏直接像素级监督和重型映射网络额外训练的问题。", "innovation": "我们提出了一种新颖的方法，用于优化一组高效的可学习的分层任务令牌，包括全局和细粒度的令牌，以便在特征和预测水平上发现一致的像素级监督信号。具体来说，全局任务令牌设计用于在全局上下文中有效进行跨任务特征交互。然后，从对应的全局任务令牌中学习一组特定任务的细粒度空间令牌，这些细粒度空间令牌嵌入到每个任务特定特征图中以进行密集交互。学习到的全局和局部细粒度任务令牌进一步用于在不同粒度级别发现伪特定任务的密集标签，这些标签可以直接监督多任务密集预测框架的学习。", "conclusion": "在具有挑战性的NYUD-v2，Cityscapes和PASCAL Context数据集上进行了广泛的实验结果表明，与现有的状态最先进技术相比，在部分标注的多任务密集预测方面取得了显著的改进。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.06458", "html_url": "https://arxiv.org/abs/2412.06458", "title": "Pruning All-Rounder: 重新思考和改进大型视觉语言模型推理效率", "title_en": "Pruning All-Rounder: Rethinking and Improving Inference Efficiency for Large Vision Language Models", "authors": "Wei Suo,Ji Ma,Mengyang Sun,Lin Yuanbo Wu,Peng Wang,Yanning Zhang", "background": "尽管大型视觉-语言模型（LVLMs）已经取得了显著的成果，但其高昂的计算成本构成了广泛应用的重要障碍。大多数现有方法主要集中在参数依赖或token依赖策略上以减少计算需求。然而，参数依赖的方法需要重新训练LVLMs以恢复性能，而token依赖的方法难以一致地选择最相关的token。", "innovation": "本文系统分析了上述挑战，并提出了一个名为Pruning All-Rounder (PAR)的新型框架。PAR通过开发一个元路由器来适应性地组织token和layer之间的修剪流程，用自监督学习方式同时平衡了性能和效率。此外，PAR非常灵活，提供了多种修剪版本以适应不同的加速场景。", "conclusion": "PAR框架通过自监督学习方式，成功实现了性能和效率之间的优越平衡，并且高度灵活，能够适应多种加速场景。该方法的代码已经公开。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.01199", "html_url": "https://arxiv.org/abs/2503.01199", "title": "LiteGS：通过系统与算法协同设计在亚分钟内训练3DGS的高性能框架", "title_en": "LiteGS: A High-performance Framework to Train 3DGS in Subminutes via System and Algorithm Codesign", "authors": "Kaimin Liao,Hua Wang,Zhi Chen,Luchao Wang,Yaohua Tang", "background": "3D Gaussian Splatting (3DGS)作为一种3D表示的有前途替代方案，虽然取得了进展，但仍面临高培训成本的问题。", "innovation": "作者提出了LiteGS，这是一种提升高性能框架，通过多方面优化3DGS训练管道，包括：在低级别计算层，设计基于“位移基准栅格”的操作并结合两个硬件感知优化以显著减少梯度缩减开销；在中级数据管理层，引入基于Morton编码的动态空间排序，实现高效“群组-剔除-压缩”管道，提升数据局部性，减少缓存缺失；在高级算法层，建立基于不透明度梯度方差的新鲁棒密集化条件，并配以更稳定的不透明度控制机制，以实现更精确的参数增长。", "conclusion": "实验结果表明，LiteGS最多可加速3DGS原始培训13.4倍，并在轻型模型上超过当前最先进的技术水平1.4倍，对于高质量重建任务，LiteGS创下新的准确率记录并减少了训练时间一个数量级。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.16421", "html_url": "https://arxiv.org/abs/2502.16421", "title": "Learning from Rendering: 实证和可控制的极端雨天图像合成用于自动驾驶模拟", "title_en": "Learning from Rendering: Realistic and Controllable Extreme Rainy Image Synthesis for Autonomous Driving Simulation", "authors": "Kaibin Zhou,Kaifeng Huang,Hao Deng,Zelin Tao,Ziniu Liu,Lin Zhang,Shengjie Zhao", "background": "自动驾驶模拟器提供了评估或增强视觉感知模型的有效且低成本的替代方案。然而，评估的可靠性取决于生成场景的多样性和现实性。极端天气条件，尤其是极端降雨，很难在现实环境中捕捉到。虽然模拟环境可以解决这个局限性，但现有的雨天图像合成器通常在可控性和现实性方面表现差强人意，这极大地削弱了模型评估的效果。", "innovation": "本文提出了一种基于渲染的学习雨天图像合成器，该方法结合了基于渲染方法的现实性和基于学习方法的可控性。通过将提出的合成器与CARLA驾驶模拟器集成，开发了CARLARain，这是一种复杂光照条件下的极端雨天街场景模拟器，可以获取配对的雨天-干净图像和标签。定性和定量实验验证了CARLARain在极端雨天场景中有效提升了语义分割模型的准确性，准确率（mIoU）在合成数据集上提高了5%-8%，且在复杂光照条件下的真实极端雨天场景中有显著增强。", "conclusion": "实验结果表明，CARLARain可以有效提高语义分割模型在极端雨天场景中的准确性，特别是在复杂光照条件下的真实极端雨天场景中，模型的准确率显著提升。相关源代码和数据集可在指定网址获得。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.20263", "html_url": "https://arxiv.org/abs/2502.20263", "title": "Vector-Quantized Vision Foundation Models for Object-Centric Learning", "title_en": "Vector-Quantized Vision Foundation Models for Object-Centric Learning", "authors": "Rongzhen Zhao,Vivienne Wang,Juho Kannala,Joni Pajarinen", "background": "传统物体中心学习方法（OCL）在将图像或视频特征图聚合成物体级特征向量（称为插槽）时面临挑战，特别是在处理复杂的物体纹理时。现有方法在利用视觉基础模型（VFM）表示方面存在局限性，因此引入了自监督重建输入和目标，使用VFM表示作为聚合输入和重建目标。然而，不同方法对VFM表示的利用方式多样，未能充分挖掘其潜力。", "innovation": "本文提出了一种名为Vector-Quantized VFM-OCL（VQ-VFM-OCL或VVO）的清洁架构，通过共享量化相同的VFM表示作为重建目标，统一了主流的OCL方法。通过数学建模和统计验证，分析了VFM表示如何促进OCL聚合，并探讨了它们作为重建目标的共享量化如何增强OCL监督。", "conclusion": "实验结果表明，VVO在物体发现和识别以及下游视觉预测和推理方面均优于基线方法，适用于不同的VFM、聚合器和解码器。实现和模型检查点可在指定网址上获得。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.20760", "html_url": "https://arxiv.org/abs/2502.20760", "title": "VRM: Knowledge Distillation via Virtual Relation Matching", "title_en": "VRM: Knowledge Distillation via Virtual Relation Matching", "authors": "Weijia Zhang,Fei Xie,Weidong Cai,Chao Ma", "background": " Knowledge distillation (KD)旨在将一个更为强大但笨重的教学模型的知识转移到一个轻量级的学生模型上。近年来，基于关系的KD方法落后于实例匹配方法，但本研究旨在通过解决基于关系的KD方法中的几个关键问题来重新振兴这些方法，包括它们容易过拟合和产生无用响应的问题。", "innovation": " 该方法创新性地利用虚拟视图和关系构建新颖构造的亲和力图，以紧凑地封装丰富的样本间、类别间和视图间的有益联系，使学生在整个KD过程中能够接收到更多样化的指导信号并获得更强的正则化效果。此外，通过动态去除冗余和不可靠的连接来减轻无用响应的负面影响。", "conclusion": " 在CIFAR-100、ImageNet和MS-COCO数据集上进行的广泛实验表明，所提出的虚拟关系匹配(VRM)方法在各种模型、结构、任务和设置下均超越了现有技术并建立了新的最佳性能记录。例如，VRM首次在ImageNet的ResNet50到MobileNetV2的KD中达到了74.0%的准确率，并在使用ResNet56教学模型的CIFAR-100任务上将DeiT-T性能提高了14.44%。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.02171", "html_url": "https://arxiv.org/abs/2502.02171", "title": "深林：使用航空成像穿透自我遮挡的植被体积", "title_en": "DeepForest: Sensing Into Self-Occluding Volumes of Vegetation With Aerial Imaging", "authors": "Mohamed Youssef,Jian Peng,Oliver Bimber", "background": "了解生态系统动态的关键在于获取地下植被结构数据。遥感技术长期以来无法穿透密集树冠层进行这些观测。尽管光探测和测距雷达（LiDAR）和雷达可用于测量三维植被结构，但相机只能获取顶部几层的反射率和深度。传统高空影像仅能检测浅层自遮挡植被体积，对于大规模且复杂的植被遮挡情况则表现不佳。", "innovation": "本文提出了一种方法，通过无人机搭载合成孔径成像技术进行焦点堆栈扫描，并利用预训练的三维卷积神经网络，以均方误差（MSE）作为损失函数，减少非聚焦信号的贡献。通过结合多个不同光谱通道的反射率堆栈，可以深入了解整个植被体积中的植物健康、生长状况和环境条件。相比于模拟地面真相，该方法在森林密度为220-1680株/公顷时，平均改善了约7倍（最小值约2倍，最大值约12倍）。在实地实验中，使用该方法与经典的多光谱航空成像相比，顶部植被层的均方误差达到了0.05。", "conclusion": "该方法通过航空成像技术穿透自我遮挡的植被体积，提供了新的数据获取方式，为理解和研究森林生态系统提供了重要工具。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.16178", "html_url": "https://arxiv.org/abs/2409.16178", "title": "SDFit: 从单张图像拟合可变形SDF进行3D物体姿态和形状恢复", "title_en": "SDFit: 3D Object Pose and Shape by Fitting a Morphable SDF to a Single Image", "authors": "Dimitrije Antić,Georgios Paschalidis,Shashank Tripathi,Theo Gevers,Sai Kumar Dwivedi,Dimitrios Tzionas", "background": "从单张图像恢复3D物体的姿态和形状是一个具有挑战性和病态性的问题。这归因于强烈的自身遮挡、深度不确定性、类内和类间形状的巨大变化，以及自然图像中缺乏3D地面真实值。现有的深度网络方法在合成数据集上进行训练以预测3D形状，因此在遇到真实世界图像时往往难以泛化。此外，它们缺乏明确的反馈循环来优化模糊估计，并主要关注几何形状而不直接考虑像素对齐。", "innovation": "SDFit开发了一种新颖的渲染和比较优化框架。其三个关键创新是：首先，它使用了特定类别和可变形的Signed Distance Function (mSDF)模型，并迭代精化3D姿势和形状以适应图像，从而通过约束在有效形状的流形上来增强推理的鲁棒性，同时允许任意形状拓扑。其次，SDFit通过利用基础模型来高效检索与图像匹配的初始3D形状。第三，SDFit通过基础特征在图像和mSDF之间建立丰富的2D-3D对应关系来初始化姿态。", "conclusion": "在三个图像数据集Pix3D、Pascal3D+和COMIC上，SDFit在无遮挡图像和常见姿态下表现与最先进的前馈网络相当，但在遮挡和非常见姿态方面具有独特鲁棒性。此外，它不需要重新训练即可处理未见过的图像。因此，SDFit为野外泛化提供了新的见解。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.09215", "html_url": "https://arxiv.org/abs/2503.09215", "title": "其他车辆轨迹同样重要：一种统一车辆轨迹的驾驶世界模型", "title_en": "Other Vehicle Trajectories Are Also Needed: A Driving World Model Unifies Ego-Other Vehicle Trajectories in Video Latent Space", "authors": "Jian Zhu,Zhengyu Jia,Tian Gao,Jiaxin Deng,Shidi Li,Lang Zhang,Fu Liu,Peng Jia,Xianpeng Lang", "background": "现有的自动驾驶系统通常依赖于能够预见轨迹结果的世界模型来评估其性能。然而，这些世界模型大多侧重于预测自动驾驶车辆自身的轨迹，而忽视了其他车辆的轨迹，这限制了它们在模拟自动驾驶车辆与其他车辆互动方面的真实性。", "innovation": "本文提出了一个名为EOT-WM的驾驶世界模型，统一了视频中自动驾驶车辆与其他车辆的轨迹。该模型通过将BEV空间中的轨迹投影到图像坐标系来匹配车辆轨迹，然后使用空间-时间变异自编码器对轨迹视频进行编码，使其在统一的视觉空间中与驾驶视频的特征在空间和时间上对齐。此外，该模型设计了一个轨迹注入的扩散变压器来去除视频特征的噪声。此外，还提出了一种基于控制内片段相似性的度量方法来评估轨迹的可控性。实验表明，所提模型在FID和FVD指标上分别优于最先进方法30%和55%，并且能够预测未出现的驾驶场景。", "conclusion": "作者提出的方法在模拟驾驶中的其他车辆轨迹方面取得了显著的性能提升，能够更真实地模拟车辆之间的互动，并能有效预测未知场景。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.20934", "html_url": "https://arxiv.org/abs/2502.20934", "title": "使用SAM2在手术视频分割中重新审视帧采样策略引入的评估偏差", "title_en": "Revisiting the Evaluation Bias Introduced by Frame Sampling Strategies in Surgical Video Segmentation Using SAM2", "authors": "Utku Ozbulak,Seyed Amir Mousavi,Francesca Tozzi,Niki Rashidian,Wouter Willaert,Wesley De Neve,Joris Vankerschaver", "background": "实时视频分割在AI辅助手术中提供了内镜指导，通过识别工具和解剖结构。尽管对手术视频分割的兴趣在增长，但不同数据集中的标注协议差异很大——有些提供详尽的、帧帧标注，而另一些则依赖稀疏标注，频率低至1 FPS。在本研究中，我们探讨了这些不同标注密度和帧率采样方式如何影响零样本分割模型的评估，以SAM2为胆囊切除术的案例研究。令人惊讶的是，我们发现，在传统稀疏评估设置下，较低的帧率似乎会优于较高的帧率，因为这种平滑效果掩盖了时间上的不一致。但在实时流媒体条件下，较高的帧率产生了更好的分割稳定性，特别是对于动态对象如手术钳。为了理解这些差异与人类感知的一致性，我们对外科医生、护士和机器学习工程师进行了调查，发现参与者一致偏好高帧率分割叠加，强调在实时应用中应评估每一帧的重要性，而非依赖稀疏采样策略。我们的研究结果突显了由不一致的数据集协议引入的评估偏差风险，并提醒需要在手术视频AI中进行时间上的公平基准测试。", "innovation": "本研究调查了不同标注密度和帧率采样的影响，发现低帧率在稀疏评估中可能表现良好，但在实时条件下高帧率有更好的分割稳定性。通过对从业者进行调查，强调了实时评估每一帧的重要性。这揭示了现有评估方法中的偏差，并提出了公平基准化的需求。使用SAM2作为胆囊切除术的具体案例进行研究。", "conclusion": "我们的发现表明，为了提高手术视频分割的真实性和稳定性，需要采用每一帧的实时评估方法。此外，应重新考虑现有的评估策略，避免由于不一致的标注协议引入的偏差，并促进公平的时间基准测试在手术视频AI中的应用。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04165", "html_url": "https://arxiv.org/abs/2503.04165", "title": "WeakSupCon: 弱监督对比学习用于预训练编码器", "title_en": "WeakSupCon: Weakly Supervised Contrastive Learning for Encoder Pre-training", "authors": "Bodong Zhang,Hamid Manoochehri,Xiwen Li,Beatrice S. Knudsen,Tolga Tasdizen", "background": "弱监督多实例学习（MIL）是一个具有挑战性的任务，因为只有袋级标签是可用的，而每个袋通常包含多个实例。该主题在组织病理图像分析中得到了广泛研究，其中通常只有整个扫描幻灯片图像（WSI）级的标签可用，而每个WSI可以被分成数千个小图像片段进行训练。主流的MIL方法主要集中在特征聚合上，并且将固定片段特征作为输入。然而，MIL设置中的弱监督特征表示学习往往被忽视。现有的特征通常是通过没有利用弱标签的自我监督学习方法生成的，或通过在其他大规模数据集上预训练的基础编码器生成的。", "innovation": "本文提出了一种名为Weakly Supervised Contrastive Learning (WeakSupCon)的新型弱监督特征表示学习方法，利用袋级标签。方法中采用了多任务学习，并为具有不同袋标签的样本定义了不同的对比损失。实验结果表明，在使用有限计算资源的情况下，WeakSupCon生成的特征显著提高了MIL分类性能，且在三个数据集上优于自我监督方法。", "conclusion": "我们的实验表明，使用WeakSupCon生成的特征，在有限的计算资源下显著提高了MIL的分类性能，相比自我监督方法有明显优势。我们的WeakSupCon代码可在以下链接中获得：this http URL"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.03222", "html_url": "https://arxiv.org/abs/2503.03222", "title": "Mocap-2-to-3: 多视角提升在单目动作恢复中的二维预训练", "title_en": "Mocap-2-to-3: Multi-view Lifting for Monocular Motion Recovery with 2D Pretraining", "authors": "Zhumei Wang,Zechen Hu,Ruoxi Guo,Huaijin Pi,Ziyong Feng,Sida Peng,Xiaowei Zhou,Mingtao Pei,Siyuan Huang", "background": "从单目输入中恢复绝对人类运动具有挑战性，主要原因有两个。首先，现有方法依赖于仅在有限环境中收集的3D训练数据，限制了分布外泛化能力。其次，从单目输入中估计具有度量级的姿势也颇具难度。", "innovation": "我们引入了Mocap-2-to-3，这是一种新颖的框架，通过利用2D数据进行多视角提升，从而以绝对位置重建度量上准确的3D运动。为了利用丰富的2D数据，我们将其复杂3D运动分解为多视角合成。我们首先在一个广泛的2D数据集上对单视角扩散模型进行预训练，然后利用公共3D数据微调多视角模型，使其能够从单目输入生成视图一致的运动，从而通过2D数据学习动作先验和多样性。此外，为了恢复绝对姿势，我们提出了一种新的人体运动表示，它将局部姿态的学习与全球运动分离，并编码地面的几何先验以加速收敛，这使得在推理过程中的运动逐级在绝对空间中恢复。实验结果显示，我们的方法在野外观测基准上不仅在相机空间运动的真实性和世界定位的人类方面超越现有最先进的方法，还在泛化能力方面表现出优越性.", "conclusion": "我们的方法在相机空间运动的真实性和世界定位的人类方面超越现有最先进的方法，同时具有优越的泛化能力。我们的代码将被公开提供。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.10410", "html_url": "https://arxiv.org/abs/2503.10410", "title": "RoCo-Sim: 通过前景模拟提升路边协作感知", "title_en": "RoCo-Sim: Enhancing Roadside Collaborative Perception through Foreground Simulation", "authors": "Yuwen Du,Anning Hu,Zichen Chao,Yifan Lu,Junhao Ge,Genjia Liu,Weitao Wu,Lanjun Wang,Siheng Chen", "background": "现有的路边感知方法主要关注模型设计，忽视了诸如校准误差、信息稀疏以及多视角一致性等数据问题，导致在最新的公开数据集上的表现不佳。", "innovation": "本文提出了RoCo-Sim，这是一种用于路边协作感知的首个仿真框架。RoCo-Sim能够通过动态前景编辑和单张图像的全景风格迁移生成多视角一致的模拟路边数据。其创新点包括：1) 使用摄像机外参优化确保路边摄像头的3D到2D投影准确；2) 提出了一种新颖的多视角遮挡感知采样器（MOAS），用于确定三维空间中多样化数字资产的放置；3) 创新地从单帧固定视角图像建模前景与背景的关系，确保多视角的一致性；4) 提出可扩展的后处理工具包通过风格迁移和其他增强生成更逼真和丰富的场景。", "conclusion": "RoCo-Sim显著提高了路边3D对象检测，相对于当前最佳方法在Rcooper-Intersection和TUMTraf-V2X上的AP70分别提升了83.74和83.12。RoCo-Sim填补了路边感知仿真中关键的空白。相关代码和预训练模型即将公开：[提供链接]。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.07047", "html_url": "https://arxiv.org/abs/2503.07047", "title": "通过草图指导双向特征交互恢复部分损坏的物体", "title_en": "Recovering Partially Corrupted Objects via Sketch-Guided Bidirectional Feature Interaction", "authors": "Yongle Zhang,Yimin Liu,Yan Huang,Qiang Wu", "background": "文本引导的扩散模型在对象修补方面取得了显著成功，通过文本提示提供了高层次的语义指导。然而，这些方法往往缺乏像素级的精确空间控制，特别是在部分损坏的对象场景中，其中未损坏的线索仍然存在。现有方法通过间接的梯度调节或直接的草图插入来改进结构控制，但通常只是从草图到遮罩区域建立单向映射，忽视了未遮罩部分的上下文信息，导致草图与未损坏的内容之间存在断层，造成不一致性和结构不匹配。", "innovation": "提出了基于预训练Stable Diffusion模型的草图引导的双向特征交互框架。框架包含两种互补方向，即上下文到草图和草图到修补。在前向过程，从未损坏对象区域传播多尺度隐变量以生成适应可见上下文和去噪进程的视觉掩码，并据此生成草图特征。在后向过程，基于学习到的视觉掩码，对草图指导的直接影响进行条件调整，以确保与未损坏对象内容的一致性。该交互在扩散U-Net的编码器中应用多个尺度，使模型能够以增强的空间保真度恢复对象结构。", "conclusion": "在两个新构建的基准数据集上进行的大量实验表明，该方法比现有最先进的方法表现更优。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.14939", "html_url": "https://arxiv.org/abs/2503.14939", "title": "VisNumBench：评估多模态大语言模型的数字直觉", "title_en": "VisNumBench: Evaluating Number Sense of Multimodal Large Language Models", "authors": "Tengjin Weng,Jingyi Wang,Wenhao Jiang,Zhong Ming", "background": "该研究背景是探索多模态大型语言模型（MLLMs）是否可以发展出类似人类的数字直觉。为此，研究团队设计了一个名为VisNumBench的视觉数字基准测试，用于评估MLLMs在多种视觉数字任务中的数字直觉能力。", "innovation": "研究的创新点在于开发了VisNumBench，这是一个包含大约1,900个多元选择题-答案对的基准测试，涵盖七种视觉数字属性和四种视觉数字估算任务。研究发现，被测试的17种MLLMs在数字直觉任务中显著低于人类水平，多模态数学模型和多模态思维链模型在数字直觉方面没有显著改善，较强的MLLMs在数字直觉方面仅表现出轻微的提升。", "conclusion": "VisNumBench被视为研究界的一个有价值的资源，将促进改进MLLMs的数字直觉能力的研究进展。研究代码和数据集可以在以下链接获取。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.15621", "html_url": "https://arxiv.org/abs/2503.15621", "title": "LLaVA-MORE: 对增强视觉指令调优的LLM和视觉骨干的比较研究", "title_en": "LLaVA-MORE: A Comparative Study of LLMs and Visual Backbones for Enhanced Visual Instruction Tuning", "authors": "Federico Cocchi,Nicholas Moratelli,Davide Caffagni,Sara Sarto,Lorenzo Baraldi,Marcella Cornia,Rita Cucchiara", "background": "最近的多模态大型语言模型（MLLMs）研究强调了视觉骨干和基础语言模型的关键作用。此前的研究主要集中在扩展这些组件到数十亿参数的规模，但在模型规模、架构和性能之间的权衡及训练数据和评估协议的一致性方面尚有不足。这导致了直接比较的困难，难以确定最佳设计选择。", "innovation": "本文介绍了LLaVA-MORE，这是一种将近期语言模型与不同视觉骨干集成的新家族MLLMs。通过采用统一的训练协议，确保公平比较，本文系统地探索了从小型到中型的MLLMs，并评估了它们在多模态推理、生成和指令跟随方面的表现，研究了模型规模与性能之间的关系。此外，还对从CLIP架构到替代方案如DINOv2、SigLIP和SigLIP2的各种视觉编码器进行了全面研究，探讨了图像分辨率和预训练数据集变化的影响。", "conclusion": "总体而言，本文的结果提供了设计更有效的MLLMs的见解，并提供了一种可重复的评估框架，有助于直接比较并指导未来模型开发。源代码和训练模型可以在指定链接中获取。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17856", "html_url": "https://arxiv.org/abs/2503.17856", "title": "ClaraVid：基于delentropy复杂度分析的空视角全方位场景重建基准数据集", "title_en": "ClaraVid: A Holistic Scene Reconstruction Benchmark From Aerial Perspective With Delentropy-Based Complexity Profiling", "authors": "Radu Beche,Sergiu Nedevschi", "background": "空中全面场景理解算法的发展受限于缺乏既能进行语义和几何重建的综合数据集。现有合成数据集虽然提供了替代方案，但存在任务特定局限性、不现实的场景组成和渲染伪影等问题，影响了实际应用。", "innovation": "引入了ClaraVid，这是一个专门设计以克服上述限制的合成空视角数据集，包含从多种视角在不同景观中捕获的16,917张高分辨率图像（4032x3024），提供了密集的深度图、全景分割、稀疏点云和动态对象掩码，同时减少了常见的渲染伪影。提出了Delentropic Scene Profile (DSP)这一新颖的复杂度度量标准，基于差异熵分析，用于定量评估场景难度并指导重建任务。利用DSP系统性地对神经重建方法进行了基准测试，揭示了场景复杂度和重建精度之间的持续可测量相关性。", "conclusion": "实证结果显示，更高的delentropy强烈与更高的重建误差相关，验证了DSP作为复杂度先验的可靠性。数据和代码已发布在项目页面：this https URL"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04351", "html_url": "https://arxiv.org/abs/2503.04351", "title": "PLMP — 支持透视结构从运动的点线最小问题", "title_en": "PLMP -- Point-Line Minimal Problems for Projective SfM", "authors": "Kim Kiehn,Albin Ahlbäck,Kathlén Kohn", "background": "本文完全分类了多未标定针孔相机中点和线的全方位观测下的Structure-from-Motion (SfM) 的所有最小问题。现有研究集中在标定相机下的最小问题，而本文扩展到了未标定相机的情况，这为SfM技术提供了更广泛的适用性。", "innovation": "本文发现了291个最小问题，其中73个具有唯一解，可以线性解决。提出了两个可变视图数的线性问题，其他最小问题涉及最多9个相机。所有最小问题中点和线的数量不超过7和12。计算了每个最小问题的解的数量，这揭示了解的相对较少。通过探索子排列的稳化子子群，提出了一种几何和系统化的方法，可用于分解最小问题、识别欠约束问题中的最小问题以及证明非最小性。", "conclusion": "通过FPSM技术，发展了一种几何和系统化的最小问题处理方法，包括分解、识别和证明，为SfM的复杂问题提供了解决方案，并评估了难题的内在难度。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.15897", "html_url": "https://arxiv.org/abs/2503.15897", "title": "学习基于神经上下文场景图的3D场景类比", "title_en": "Learning 3D Scene Analogies with Neural Contextual Scene Maps", "authors": "Junho Kim,Gwangtak Bae,Eun Sun Lee,Young Min Kim", "background": "理解场景上下文对于机器在未见过或有噪声的3D环境中执行任务和应用先验知识至关重要。然而，基于数据驱动的学习难以全面涵盖多样化的布局和开放空间。因此，需要一种方法来教会机器识别3D空间中的关系共性，而非局限于点或对象级别的表示。", "innovation": "提出了基于神经上下文场景图的3D场景类比。该方法通过平滑地连接3D场景区域，提取描述符场来总结语义和几何上下文，并以粗到细的方式整体对齐它们进行地图估计，从而减少对个体特征点的依赖，提高了对输入噪声或形状变化的鲁棒性。这种方法在多种室内场景中识别场景类比，并有效转移轨迹或物体布局，展示了其在机器人学和AR/VR应用中的潜力。", "conclusion": "实验表明，该方法在多种室内场景中有效地识别了场景类比，并成功转移了轨迹或物体布局，为其在机器人学和AR/VR应用中的前景奠定了基础。相关代码可在以下链接获取：this https URL"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17788", "html_url": "https://arxiv.org/abs/2503.17788", "title": "学习对齐与精炼：用于遮挡鲁棒双手重建的Foundation-to-Diffusion框架", "title_en": "Learning to Align and Refine: A Foundation-to-Diffusion Framework for Occlusion-Robust Two-Hand Reconstruction", "authors": "Gaoge Han,Yongkang Cheng,Zhe Chen,Shaoli Huang,Tongliang Liu", "background": "双手中立场景重建面临持续性的挑战，主要由于复杂且动态的手部姿势以及遮挡，导致实现可信的交互对齐存在显著难题。现有的方法难以处理这种对齐问题，常常会导致对齐偏差和穿插伪影。", "innovation": "提出了一种双阶段Foundation-to-Diffusion框架，该框架精确地将来自视觉基础模型的2D先验指导与基于扩散的生成3D交互精修相结合，以实现对遮挡鲁棒的双手重建。该方法包括两个方面：首先，引入了一个轻量级的融合对齐编码器，训练时将各类2D先验、如关键点、分割图和深度线索进行融合对齐，从而提供鲁棒的结构化指导，使测试时可以快速高效地进行推断而无需依赖重的基础模型编码器，同时保持高重建准确率。其次，实现了一个明确训练的双手扩散模型，专门将穿插的三维姿态转化为可信且无穿插的对应姿态。通过碰撞梯度引导的去噪，模型修正伪影同时保留双手之间的自然空间关系。", "conclusion": "广泛的评估表明，该方法在InterHand2.6M、HIC和FreiHAND数据集上取得了最先进的性能，大幅提升了遮挡处理能力和交互鲁棒性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17526", "html_url": "https://arxiv.org/abs/2503.17526", "title": "超越编码器：联合编码器-解码器对比预训练提高密集预测", "title_en": "Beyond the Encoder: Joint Encoder-Decoder Contrastive Pre-Training Improves Dense Prediction", "authors": "Sébastien Quetin,Tapotosh Ghosh,Farhad Maleki", "background": "当前的研究主要集中在通过自监督学习预训练编码器，解码器通常则是在下游密集预测任务中被单独引入和训练。这种传统的分步方法忽略了同时预训练编码器和解码器所可能带来的好处。本研究的背景在于探索如何通过联合预训练来改进这一过程，以提升密集预测任务的性能。", "innovation": "提出了DeCon框架，这是一种高效的支持编码器和解码器的联合对比预训练的自监督学习方法。创新之处在于扩展现有的自监督学习架构，以便容纳多样化的解码器及其相应的对比损失，并引入了具有非竞争目标的加权编码器-解码器对比损失。通过将一个成熟的对比自监督学习框架应用于密集预测任务，DeCon在COCO对象检测和实例分割任务以及跨所有密集下游基准任务中，实现了新的最先进结果。", "conclusion": "研究结果表明，联合预训练能增强编码器的表示能力，提高密集预测任务的性能。这种增益在不同的解码器架构、编码器架构及跨领域且数据有限的情况下依然有效。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11806", "html_url": "https://arxiv.org/abs/2503.11806", "title": "通过填充实现3D场景布局的人在回路局部修正", "title_en": "Human-in-the-Loop Local Corrections of 3D Scene Layouts via Infilling", "authors": "Christopher Xie,Armen Avetisyan,Henry Howard-Jenkins,Yawar Siddiqui,Julian Straub,Richard Newcombe,Vasileios Balntas,Jakob Engel", "background": "本文介绍了一种新颖的人在回路方法，用于从第一人称视角估计3D场景布局，并通过引入新的局部修正任务，用户可以识别局部错误并促使模型自动完成纠正。此方法基于SceneScript，这是一种利用结构化语言的先进3D场景布局估计框架。我们提出了将此问题结构化为“填充”任务的解决方案，这在自然语言处理中已被研究。", "innovation": "我们提出了一种多任务版本的SceneScript，该版本在保持全局预测性能的同时，显著提高了其局部修正能力。此系统被整合到人机协作系统中，使用户能够通过低摩擦的“一键修复”流程迭代优化场景布局估计，从而使得最终的细化布局可以偏离训练分布，更准确地建模复杂布局。", "conclusion": "文章提出的方法能够使最终的场景布局更具准确性，并能够更好地处理复杂的场景布局问题。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.05422", "html_url": "https://arxiv.org/abs/2504.05422", "title": "EP-Diffuser: 一种基于多项式表示的高效扩散模型用于交通场景生成与预测", "title_en": "EP-Diffuser: An Efficient Diffusion Model for Traffic Scene Generation and Prediction via Polynomial Representations", "authors": "Yue Yao,Mohamed-Khalil Bouzidi,Daniel Goehring,Joerg Reichardt", "background": "随着预测时长的增加，交通场景未来演变的预测变得越来越困难，因为代理的运动具有多模态性。大多数现有的最先进模型主要集中在预测最可能的未来路径上，然而，对于自动驾驶车辆的安全运行来说，涵盖可能的运动替代方案的概率分布也同样重要。", "innovation": "本文提出EP-Diffuser，这是一种新型参数效率高且基于扩散的生成模型，旨在捕捉可能交通场景演变的概率分布。该模型在给定道路布局和代理历史的基础上，能生成多样且合理的场景延续。", "conclusion": "尽管模型规模显著较小，但在Argoverse 2数据集上，该方法实现了高准确性和合理性的交通场景预测。在Waymo Open数据集的出分布（OoD）测试设置中，进一步评估了模型的泛化能力，并展示了该方法的优越鲁棒性。所有代码和模型检查点均可通过提供的链接访问。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.13593", "html_url": "https://arxiv.org/abs/2504.13593", "title": "KAN或MLP？点云指明前进道路", "title_en": "KAN or MLP? Point Cloud Shows the Way Forward", "authors": "Yan Shi,Qingdong He,Yijun Liu,Xiaoyu Liu,Jingyong Su", "background": "多层感知器（MLPs）成为点云分析中有效特征学习机制的基本架构组件，然而，在处理点云中的复杂几何结构时，MLPs 固定的激活函数难以高效捕捉局部几何特征，同时参数效率低下且模型冗余。", "innovation": "本文提出了一种PointKAN框架，它应用Kolmogorov-Arnold 网络（KANs）进行点云分析，以探讨其在分层特征表示中的有效性能。通过引入Geometric Affine Module (GAM)对局部特征进行转换，同时在Local Feature Processing (LFP)阶段使用并行结构提取组级特征和全局上下文，以及Global Feature Processing (GFP)阶段进行特征组合和处理，PointKAN能够在保持准确性的前提下显著减少参数量和计算量（FLOPs），特别是在Few-shot Learning任务中表现出色，优于PointMLP在ModelNet40、ScanObjectNN和ShapeNetPart等基准数据集上的性能。", "conclusion": "此工作突显了基于KANs架构在3D视觉中的潜力，并为点云理解研究开辟了新的途径。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.18711", "html_url": "https://arxiv.org/abs/2503.18711", "title": "Accenture-NVS1: 一种新型视图合成数据集", "title_en": "Accenture-NVS1: A Novel View Synthesis Dataset", "authors": "Thomas Sugg,Kyle O'Brien,Lekh Poudel,Alex Dumouchelle,Michelle Jou,Marc Bosch,Deva Ramanan,Srinivasa Narasimhan,Shubham Tulsiani", "background": "该论文介绍了专为航空和地面图像的新型视图合成（NVS）研究设计的数据集ACC-NVS1。数据收集地点位于2023年和2024年的德克萨斯州奥斯丁和宾夕法尼亚州匹兹堡，涵盖了6个多样化的现实场景，总计148,000张图像。数据集旨在解决不同高度和瞬态物体带来的挑战，并补充现有数据集，为全面研究提供更多资源，而不作为基准测试使用。", "innovation": "ACC-NVS1数据集旨在解决新型视图合成领域的特定问题，包括适应不同的海拔高度和瞬态物体。新的数据集提供了多样化的场景和大量高质量的图像，这为研究人员提供了更丰富的研究材料。", "conclusion": "ACC-NVS1数据集作为新型视图合成研究的补充工具，提供了多样化的现实世界场景图像，旨在促进该领域的进一步研究，而不是被用作基准测试。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.19480", "html_url": "https://arxiv.org/abs/2503.19480", "title": "GenHancer: 不完美的生成模型是秘密强大的视觉增强器", "title_en": "GenHancer: Imperfect Generative Models are Secretly Strong Vision-Centric Enhancers", "authors": "Shijie Ma,Yuying Ge,Teng Wang,Yuxin Guo,Yixiao Ge,Ying Shan", "background": "生成模型和判别模型的协同作用受到越来越多的关注。虽然基于对比的文本-图像预训练模型（CLIP）在高层次语义方面表现出色，但它们在感知细微的视觉细节方面存在不足。通常，为了增强表示，生成模型将CLIP的视觉特征作为重建条件。然而，现有的方法并没有充分探索其背后的机理。研究表明，虽然完美的生成结果对于表示增强并非总是最优的，但有效提取生成模型中的细微知识并减少无关信息是关键。通过研究条件机制、去噪配置和生成范式，提出了新的方法来提升CLIP的表示能力。", "innovation": "1. 研究了条件机制，发现即使局部令牌的数量较少，也能大幅降低重建难度，导致训练收敛困难。\n2. 提出了一种两阶段的训练策略来优先学习有用的视觉知识，同时证明了轻量级去噪器可以显著提高效果。\n3. 探索了连续和离散去噪器，验证了方法的灵活性，并最终提出了一种称为GenHancer的有效方法。\n4. GenHancer在MMVP-VLM基准测试中表现出色，例如在OpenAICLIP上提升了6.0%的性能，该增强后的CLIP可以进一步集成到多模态大语言模型中，以提高视觉中心的表现。所有模型和代码均已公开。", "conclusion": "GenHancer是一个有效的方法，能够一致地超越之前的方案，在MMVP-VLM基准测试中有明显的性能提升。增强后的CLIP可以进一步集成到多模态大语言模型中以提高视觉表现。所有代码和模型已公开。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.02178", "html_url": "https://arxiv.org/abs/2505.02178", "title": "Sparfels: 快速重建稀疏非定标图像", "title_en": "Sparfels: Fast Reconstruction from Sparse Unposed Imagery", "authors": "Shubhendu Jena,Amine Ouasfi,Mae Younes,Adnane Boukhayma", "background": "尽管已有少数方法解决了来自噪声或稀疏分布光学相机的稀疏光场学习问题，但在稀疏非定标场景下的形状恢复研究相对较少。大多数已有的重建方法主要针对有标定相机的稀疏配准问题，通过学习数据先验或结合外部单目几何先验来优化重建过程。但是，这些方法在处理稀疏非定标图像时相对复杂且效率较低，无法在普通消费级GPU上实现快速重建。因此，该领域需要一种高效且简单的方法来快速重建稀疏非定标的图像，尤其是可以利用最新的3D基础模型和其各种任务头来实现这一目标的方法。", "innovation": "本文提出了一种基于表面元素插值稀疏视图重建方法，能够在消费级GPU上以不到3分钟的时间运行。本文的主要创新之处在于，提出了一种有效的单次重建管道，结合了最近的3D基础模型和其各种任务头，特别是点图和相机初始化，通过这些信息构建2D高斯插值（2DGS）模型，并利用图像对应关系引导相机优化，同时进行2DGS训练。本研究的关键在于提出了一种全新的沿光线插值颜色方差的计算方法，这种方法可以在训练中高效计算，并通过减少该时刻来提高形状重建的准确性。", "conclusion": "本文在重建和新视角基准测试上展示了超越现有技术的性能，特别是在稀疏非标定场景下的重建中，证明了本文方法的有效性和高效性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.17761", "html_url": "https://arxiv.org/abs/2504.17761", "title": "Step1X-Edit：一种通用图像编辑的实用框架", "title_en": "Step1X-Edit: A Practical Framework for General Image Editing", "authors": "Shiyu Liu,Yucheng Han,Peng Xing,Fukun Yin,Rui Wang,Wei Cheng,Jiaqi Liao,Yingming Wang,Honghao Fu,Chunrui Han,Guopeng Li,Yuang Peng,Quan Sun,Jingwei Wu,Yan Cai,Zheng Ge,Ranchen Ming,Lei Xia,Xianfang Zeng,Yibo Zhu,Binxing Jiao,Xiangyu Zhang,Gang Yu,Daxin Jiang", "background": "近年来，图像编辑模型取得了显著和迅速的发展。最新的多模态模型，如GPT-4o和Gemini2 Flash的推出，展示了令人兴奋的图像编辑能力。这些模型能够满足用户大量的编辑需求，标志着图像处理领域的重大进步。然而，开源算法与这些闭源模型之间仍然存在较大的差距。因此，本文旨在发布一个名为Step1X-Edit的先进图像编辑模型，该模型可以与GPT-4o和Gemini2 Flash等闭源模型相比具备相当的性能。", "innovation": "本文提出了一种名为Step1X-Edit的通用图像编辑模型，该模型采用多模态LLM处理参考图像和用户的编辑指令，并通过潜嵌入与扩散图像解码器整合得到目标图像。为此，建立了数据生成管道以生成高质量的数据集。此外，还开发了GEdit-Bench，这是一个基于真实用户指令的新基准。实验证明，Step1X-Edit在GEdit-Bench上的性能显著优于现有开源基线，接近领先专有模型的性能，为图像编辑领域做出了重要的贡献。", "conclusion": "实验结果表明，Step1X-Edit在GEdit-Bench上显著优于现有开源基准，其性能接近领先的专有模型，从而对图像编辑领域做出了重大贡献，填补了开源算法与闭源模型之间的性能差距。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.05164", "html_url": "https://arxiv.org/abs/2504.05164", "title": "平衡统一图像融合中的不变任务交互与特定任务适应", "title_en": "Balancing Task-invariant Interaction and Task-specific Adaptation for Unified Image Fusion", "authors": "Xingyu Hu,Junjun Jiang,Chenyang Wang,Kui Jiang,Xianming Liu,Jiayi Ma", "background": "统一图像融合旨在整合来自多源图像的互补信息，通过统一框架提高图像质量，适用于多种融合任务。然而，将所有融合任务视为统一问题虽然便于共享不变任务知识，但往往忽视了特定任务的特性，限制了整体性能。现有的通用图像融合方法通过明确的任务识别来适应不同的融合任务。然而，在推理过程中依赖于这种识别限制了模型对未见过的融合任务的一般化。", "innovation": "本文提出了一个名为‘TITA’的新颖统一图像融合框架，该框架动态平衡了任务不变交互和任务特定适应。为了任务不变交互，引入了增强像素交互的交互增强像素注意（IPA）模块，以更好地提取多源互补信息。为了任务特定适应，基于操作的自适应融合（OAF）模块会根据任务属性动态调整操作权重。此外，引入快速自适应多任务优化（FAMO）策略，以减轻联合训练过程中任务间梯度冲突的影响。", "conclusion": "广泛的实验证明，TITA不仅在三种图像融合场景中都能达到与专门方法竞争的性能，还表现出对未见过的融合任务的强大一般化能力。源代码已发布。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12620", "html_url": "https://arxiv.org/abs/2505.12620", "title": "BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation", "title_en": "BusterX: MLLM-Powered AI-Generated Video Forgery Detection and Explanation", "authors": "Haiquan Wen,Yiwei He,Zhenglin Huang,Tianxiao Li,Zihan Yu,Xingru Huang,Lu Qi,Baoyuan Wu,Xiangtai Li,Guangliang Cheng", "background": "随着AI生成模型的进步，超逼真视频合成变得可能，这增加了通过社交媒体传播假信息的风险，侵蚀了公众对数字内容的信任。尽管有一些研究工作探索了新的深度造假检测方法，但由于视频生成模型如Sora和WanX的快速发展，目前缺乏大规模、高质量的AI生成视频数据集用于伪造检测。现有检测方法多将任务视为二元分类，缺乏模型决策的解释性，未能提供实用的公共指导。", "innovation": "本文提出了GenBuster-200K，这是一个包含20万个高质量视频片段、最新生成技术和现实场景的数据集。此外，还介绍了一个利用多模态大型语言模型和强化学习的新型框架BusterX，用于准确性鉴定和可解释性推理。GenBuster-200K是首个集成了最新生成技术的大型高质量AI生成视频数据集，BusterX是首个将大型语言模型与强化学习相结合的解释性AI生成视频检测框架。广泛的比较和消融研究证明了BusterX的有效性和泛化性。", "conclusion": "GenBuster-200K和BusterX的成功展示了解决当前AI生成视频伪造检测挑战的有效方法，未来将公开发布代码、模型和数据集。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.24329", "html_url": "https://arxiv.org/abs/2505.24329", "title": "DisTime: 基于概率分布的时间表示法在视频大型语言模型中", "title_en": "DisTime: Distribution-based Time Representation for Video Large Language Models", "authors": "Yingsen Zeng,Zepeng Huang,Yujie Zhong,Chengjian Feng,Jie Hu,Lin Ma,Yang Liu", "background": "尽管在通用视频理解方面取得了进展，视频大型语言模型（Video-LLMs）在精确的临时定位方面仍然面临挑战，主要由于离散性时间表示和缺乏时间感知的数据集。现有的时间表达方式要么将时间与基于文本的数值混淆，要么增加一系列专门的时间标记，或者使用专门的时间接地头进行时间回归。这些方法都未能有效解决边界歧义和保持时间连续性的问题。", "innovation": "本文介绍了一种轻量级框架——DisTime，旨在增强Video-LLMs的时间理解能力。DisTime采用可学习的标记来创建连续的时间嵌入空间，并集成了一个基于分布的时间解码器，以生成时间概率分布，从而有效缓解边界歧义并保持时间连续性。DisTime还提出了基于分布的时间编码器，重新编码时间戳以提供时间标记。此外，为了克服现有数据集在时间粒度上的限制，本文提出了一种将Video-LLMs的字幕能力与专门的时间模型的定位专长相结合的自动注释范式，从而创建了InternVid-TG数据集。", "conclusion": "广泛的实验表明，DisTime在三种时间敏感任务基准测试中取得了最先进的性能，同时在视频问答任务中保持了竞争力。相关代码和数据已发布。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.14729", "html_url": "https://arxiv.org/abs/2505.14729", "title": "揭示视觉-语言模型中的文化表现差异", "title_en": "Uncovering Cultural Representation Disparities in Vision-Language Models", "authors": "Ram Mohan Rao Kadiyala,Siddhant Gupta,Jebish Purbey,Srishti Yadav,Suman Debnath,Alejandro Salamanca,Desmond Elliott", "background": "视觉-语言模型（VLMs）在各种任务中展现了惊人的能力，但它们潜在的种族偏见问题也引起了人们的关注。本文通过评估这些模型在基于图像的国家识别任务上的表现，探讨了这些流行的VLMs在国家层面展现的文化偏见的程度。研究使用了地理上多样化的Country211数据集，对多种大型视觉语言模型进行了不同提示策略的测试：开放式问题、多项选择题问题（包括多语言和对抗性设置）。研究的目标是揭示不同国家和地区间的表现差异，为了解训练数据和评估方法如何影响VLM中的文化偏见提供见解。研究结果表明，虽然VLMs在视觉理解方面具有很大的潜力，但它们从预训练数据中继承的偏见影响了它们在全球不同背景中的泛化能力，导致了性能的显著差异。", "innovation": "本文通过多样化提问题的方式（包括开放式问题、多项选择题，甚至是在多语言和对抗性设置下进行评价）对大型视觉语言模型进行测试，以揭示这种模型在不同国家和地区表现上的差异。这种多角度的评估方法为理解VLMs中的文化偏见提供了新的视角。", "conclusion": "研究结果表明，VLMs在不同国家的表现存在显著差异。尽管VLMs在视觉理解方面表现出很高的能力，但它们的偏见可能导致在不同文化和地区环境中的应用存在限制。此外，研究强调了训练数据分布和评估方法对于减少VLMs的偏见具有重要作用。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.22351", "html_url": "https://arxiv.org/abs/2503.22351", "title": "一眼尽够：无缝切片式精炼在高分辨率图像零样本单目深度估计中的应用", "title_en": "One Look is Enough: Seamless Patchwise Refinement for Zero-Shot Monocular Depth Estimation on High-Resolution Images", "authors": "Byeongjun Kwon,Munchurl Kim", "background": "零样本深度估计(DE)模型依托于大规模数据集进行训练，具备强大的泛化能力。然而，现有的模型在处理高分辨率图像时表现不佳，原因在于训练时使用的图像分辨率较低和实际推断所需的高分辨率图像之间存在差距。全分辨率处理会大大降低深度估计的准确度并增加内存消耗；而将分辨率降低到训练水平虽然节省了内存，但会导致估计深度图像边缘模糊。鉴于现实世界中地面真实深度数据稀疏，以往的高分辨率深度估计方法依赖于基于片段的方法，这导致在合成数据和平面重建过程中深度不连续性问题，提高了测试时间的无效性。为了得到细粒度的深度细节，这些方法不得不依靠合成数据集，但由于现实世界数据集的特定偏差，导致泛化能力较弱。", "innovation": "本文提出了一种高效的通用切片式框架，即Patch Refine Once (PRO)。PRO包含两个关键组件：(i)集团化的片段一致性训练，该方法通过同时处理四个重叠片段并在一次反向传播步骤中在其重叠区域内强制施加一致性损失来提高测试时间效率并缓解深度不连续性问题；(ii)方差无偏化掩模，防止深度估计模型过度拟合特定数据集的偏差，确保即使在经过合成数据集训练后也能更好地泛化到真实世界的数据集中。", "conclusion": "在Booster、ETH3D、Middlebury 2014和NuScenes等数据集上的零样本评估表明，PRO可以无缝集成到现有的深度估计模型中。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19955", "html_url": "https://arxiv.org/abs/2506.19955", "title": "ZIP: 通过零膨胀泊松建模实现可扩展的 crowds 计数", "title_en": "ZIP: Scalable Crowd Counting via Zero-Inflated Poisson Modeling", "authors": "Yiming Ma,Victor Sanchez,Tanaya Guha", "background": "目前大多数人群计数方法直接使用均方误差（MSE）损失逐块回归密度图，但这种方法存在两个主要问题：（1）它未能考虑到注释数据的高度空间稀疏性；（2）MSE 被用于高斯误差模型，而高斯模型并不适用于离散、非负的计数数据。", "innovation": "本文引入了一种名为 ZIP 的可扩展人群计数框架，该框架使用零膨胀泊松似然模型逐块建模人群计数。ZIP 包含零膨胀项，用于学习块是否为空（处理多余的零值），以及泊松部分，用于捕获当人们存在时的期望计数（考虑离散性）。实验结果表明，ZIP 在所有模型规模下均优于现有的最佳方法。", "conclusion": "通过对比分析，ZIP 框架在训练分辨率适中的情况下，提供了一个比基于 MSE 损失的 DMCount 更紧的风险估计。实验证明，ZIP 在上海Tech A & B、UCF-QNRF 和 NWPU-Crowd 数据集上的一系列试验中均表现出色，超越了现有方法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21567", "html_url": "https://arxiv.org/abs/2505.21567", "title": "EaqVLA: Encoding-aligned Quantization for Vision-Language-Action Models", "title_en": "EaqVLA: Encoding-aligned Quantization for Vision-Language-Action Models", "authors": "Feng Jiang,Zihao Zheng,Xiuping Cui,Maoliang Li,JIayu Chen,Xiang Chen", "background": "随着嵌入式人工智能的发展，端到端控制策略如Vision-Language-Action (VLA)模型已经成为主流。然而，现有VLA模型面临计算/存储成本昂贵的问题，需要进行优化。量化被视作一种最有效的优化方法，能够在减少内存成本的同时实现计算加速。但是，VLA模型中的标记对齐问题阻碍了现有量化方法的应用。", "innovation": "为了应对上述问题，研究人员提出了一个名为EaqVLA的优化框架，该框架采用了编码对齐量化方法来优化VLA模型。具体而言，他们提出了一种全面的分析方法，以在不同粒度下找到标记对齐的偏差。基于这些分析结果，团队提出了具有编码对齐意识的混合精度量化方法。实验证明，提出的EaqVLA方法在端到端动作控制中实现了更好的量化性能，并且比现有方法加速了数倍。", "conclusion": "提出的EaqVLA框架通过解决VLA模型中的标记对齐问题，有效地实现了量化优化，提高了模型的计算效率和精度，特别是在端到端动作控制任务上表现出显著的性能提升，加速效果达到数倍。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.20884", "html_url": "https://arxiv.org/abs/2505.20884", "title": "YOLO-FireAD：通过注意力导向残差学习和双池特征保留实现高效火灾检测", "title_en": "YOLO-FireAD: Efficient Fire Detection via Attention-Guided Inverted Residual Learning and Dual-Pooling Feature Preservation", "authors": "Weichao Pan,Bohan Xu,Xu Wang,Chengze Lv,Shuoyang Wang,Zhenke Duan", "background": "在动态环境中进行火灾检测面临持续的挑战，包括光照变化的干扰、频繁的误检测或漏检，而且很难兼顾效率和准确性。现有的YOLO（You Only Look Once）模型在特征提取和信息保留方面存在限制，导致在复杂背景下容易错失细微的火灾特征，同时存在较高的假警报率。因此，改进现有的YOLO模型来提高火灾检测的效率和准确性具有重要意义。", "innovation": "为了克服现有YOLO模型在特征提取和信息保留方面的局限，该研究提出了一种名为YOLO-FireAD（You Only Look Once for Fire Detection with Attention-guided Inverted Residual and Dual-pooling Downscale Fusion）的新模型。该模型的两大创新点是：(1)通过将跨通道-空间注意力机制与倒残差相结合，设计了注意力导向的残差块（AIR），以自适应地增强火灾特征并抑制环境噪声；(2) 通过动态融合最大池和平均池的输出结果，设计了双池特征降尺度融合块（DPDF），以保留多尺度下的火灾模式，提升小火检测的可靠性。", "conclusion": "该模型在两个公开数据集上的评估显示了高效的表现。所提模型参数量（1.45M）比YOLOv8n低51.8%，且参数量（4.6G）比YOLOv8n少43.2%，同时mAP75指标略高于包括主流实时目标检测模型YOLOv8n、YOLO-Ov9t、YOLOv10n、YOLO11n、YOLOv12n在内的其他YOLOv8变体1.3%到5.5%。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19330", "html_url": "https://arxiv.org/abs/2506.19330", "title": "细调的ImageNet预训练模型在电子元件分类中的比较性能", "title_en": "Comparative Performance of Finetuned ImageNet Pre-trained Models for Electronic Component Classification", "authors": "Yidi Shao,Longfei Zhou,Fangshuo Tang,Xinyi Shi,Dalang Chen,Shengtao Xia", "background": "电子元件分类和检测对制造行业的至关重要，能够显著减少劳动力成本并推动技术创新和发展。预训练模型，尤其是经过ImageNet训练的模型，在图像分类任务中表现卓越，即使数据量有限也能取得优秀效果。本文对比了ImageNet预训练模型在电子元件分类任务中的表现，结果显示所有测试模型都取得了不错的效果，其中MobileNet-V2表现最佳，准确率达99.95%，而EfficientNet-B0最低，仅为92.26%。这些结果进一步证明了使用ImageNet预训练模型进行图像分类的优势及其在电子制造业的实用性.", "innovation": "本文主要贡献在于对比了十二种预训练模型在电子元件分类任务中的具体表现，详细分析了其在真实场景中的适用性，有助于指导实际应用.", "conclusion": "所有预训练模型在电子元件分类中都有较好的表现，其中MobileNet-V2取得了最高准确率，而EfficientNet-B0表现最差。这些结果强调了使用ImageNet预训练模型进行图像分类的巨大优势，并验证了这些方法在电子制造业的实用价值."}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.00956", "html_url": "https://arxiv.org/abs/2506.00956", "title": "Continual-MEGA: 大规模通用持续异常检测基准", "title_en": "Continual-MEGA: A Large-scale Benchmark for Generalizable Continual Anomaly Detection", "authors": "Geonu Lee,Yujeong Oh,Geonhui Jang,Soyoung Lee,Jeonghyo Song,Sungmin Cha,YoungJoon Yoo", "background": "当前，持续学习在异常检测中的标准基准无法充分反映实际部署场景。本文旨在改进这一问题，介绍了一个新的基准——Continual-MEGA，该基准使用了一个大规模、多样化的数据集，通过结合精心筛选的现有数据集和新提出的ContinualAD数据集，显著扩展了现有的评估设置。此外，本文提出了一种新场景，用于测量零样本泛化能力，这有助于增强持续适应和零样本性能之间的联系。", "innovation": "本文的主要创新包括：(1) 提出了一种新的持续学习基准Continual-MEGA，包含一个大规模和多样化的数据集；(2) 引入了零样本泛化评估的新场景，使得持续适应不仅限于已观察到的类别，还包括没有观察到的类别；(3) 提出了一个统一的基础算法，该算法在少量样本检测中提高了鲁棒性，并且仍然保持了强大的泛化能力；(4) 通过广泛评估，发现了现有方法在像素级缺陷定位方面的显著改进空间；(5) 所提出的方法在各种场景下都超过了以前的方法；(6) 新引入的ContinualAD数据集增强了强大异常检测模型的性能。", "conclusion": "本文通过广泛的评估，发现现有方法在像素级缺陷定位方面有很大的改进空间，所提出的Continual-MEGA基准方法和ContinualAD数据集显著优于传统的评估方法，这些方法提高了检测和适应性能。作者已经发布了该基准和相关代码。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12103", "html_url": "https://arxiv.org/abs/2507.12103", "title": "DeepShade: 通过文本条件化图像生成实现阴影模拟", "title_en": "DeepShade: Enable Shade Simulation by Text-conditioned Image Generation", "authors": "Longchao Da,Xiangrui Liu,Mithun Shivakoti,Thirulogasankar Pranav Kutralingam,Yezhou Yang,Hua Wei", "background": "热浪对公共健康构成重大威胁，随着全球变暖加剧，这一威胁更为严重。然而，现有的路线系统（例如在线地图）由于直接从有噪声的卫星图像中估算阴影的困难以及生成模型缺乏训练数据的问题，无法整合阴影信息。", "innovation": "本文提出了DeepShade模型，这是一种基于扩散的模型，用于学习和合成随时间变化的阴影。通过Blender基于3D模拟和建筑物轮廓捕捉阴影变化，建立了一个广泛的数据库，该数据库涵盖了不同的经度纬度区域，建筑密度的不同水平和不同的城市布局。此外，该模型通过考虑RGB和Canny边缘层以及对比学习，来捕捉阴影随时间的变化规则，并可以根据文本描述（例如时间、太阳角度）进行条件化，从而提高生成阴影图像的性能。", "conclusion": "通过将我们的阴影预测应用到亚利桑那州坦佩真实路线规划中，我们展示了该方法的有效性。我们相信这项工作将为极端炎热天气下的城市规划提供参考，并可能在环境中的实际应用产生潜在影响。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21509", "html_url": "https://arxiv.org/abs/2506.21509", "title": "通过动态 Logits 校准减轻大型视觉-语言模型的幻觉", "title_en": "Mitigating Hallucination of Large Vision-Language Models via Dynamic Logits Calibration", "authors": "Jiahe Chen,Jiaying He,Qian Shao,Qiyuan Chen,Jiahe Ying,Hongxia Xu,Jintai Chen,Jianwei Zheng,Jian Wu", "background": "大型视觉-语言模型（LVLMs）在多模态理解方面取得了显著进展，但在生成文本时经常会出现幻觉，即生成与视觉输入矛盾的文本。现有的无需训练的解码策略具有重要局限性，包括不适应于生成过程中语义漂移的静态约束、由于需要多次前向传播而带来的低效性以及由于过于严格的干预规则导致的细节丢失。", "innovation": "本文提出了一种新的无需训练的解码框架——动态 logits 校准（Dynamic Logits Calibration, DLC）。DLC 在解码阶段逐步使用 CLIP 评估输入图像与生成文本序列的语义对齐，并基于动态更新的上下文基线评估候选词的相对视觉优势，从而自适应调整输出 logits，优先选择与视觉证据一致的词。此外，通过实时上下文对齐得分驱动的自适应加权机制，DLC 保证了视觉指导和文本生成质量之间的平衡。", "conclusion": "实验表明，DLC 通过避免多次前向传播、高效降低成本在各种基准和 LVLM 架构（如 LLaVA、InstructBLIP 和 MiniGPT-4）中显著减少了幻觉，同时保持了较高的解码效率，从而提升了 LVLMs 的可靠性，为实际应用提供了有效的解决方案。代码将发布在 GitHub 上。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.01631", "html_url": "https://arxiv.org/abs/2507.01631", "title": "Tile and Slide: 一种新的框架，用于从局部到全局扩展NeRF的3D地球观测", "title_en": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "authors": "Camille Billouard,Dawa Derksen,Alexandre Constantin,Bruno Vallet", "background": "神经辐射场（NeRF）作为多视图卫星图像三维重建的范式得到了近年来的发展，但最先进的NeRF方法受限于小场景，因为训练过程中需要大量的内存。先前的工作通过将场景划分为多个NeRF来解决这个问题。然而，这些方法大多不能直接应用于大规模实景。本文研究了这一问题，并提出了一种新的框架Snake-NeRF，它能够处理大规模场景并且不需要同时加载所有图像和网络到内存中，通过不重叠地将感兴趣区域划分成多个NeRF，同时保持跨边界的像素一致性，确保每个NeRF在训练中有足够的信息。此外，本文还介绍了新颖的$2\times 2$三维贴图策略和分段采样器，以防止3D重建中的边缘误差。实验证明，大规模卫星图像可以在线性时间内处理，保持高质量，仅用单个GPU即可实现", "innovation": "本文提出了Snake-NeRF框架，这是一个处理大规模场景的创新方法，通过三维贴图和分段采样策略，避免跨边界的3D重建错误，并且能够在单个GPU上以线性时间复杂度处理大规模卫星图像，而无需增加额外的设备负担或降低质量", "conclusion": "大规模卫星图像可以有效使用线性时间复杂度、单个GPU实现3D重建，而无需妥协图像质量。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.17745", "html_url": "https://arxiv.org/abs/2507.17745", "title": "Ultra3D：带有部分注意机制的高效高保真3D生成", "title_en": "Ultra3D: Efficient and High-Fidelity 3D Generation with Part Attention", "authors": "Yiwen Chen,Zhihao Li,Yikai Wang,Hu Zhang,Qin Li,Chi Zhang,Guosheng Lin", "background": "近期在稀疏体素表示方面的进展大大提升了3D内容生成的质量，能够产生高分辨率且精细几何细节的3D模型。然而，现有的框架由于其两个阶段扩散管道中注意力机制的二次复杂性，面临严重的计算效率问题。", "innovation": "提出了一种名为Ultra3D的高效3D生成框架，通过利用紧凑的VecSet表示法在第一阶段高效生成粗略的物体布局，减少令牌数量并加速体素坐标的预测。同时引入了一种几何感知局部注意力机制Part Attention，将注意力计算限制在语义上一致的部分区域内，从而在保留结构连续性的同时避免不必要的全局注意力，实现了潜在特征生成速度最高6.7倍的提升。此外，构建了一个可扩展的部分注释流水线，将原始网格转换为部分标注的稀疏体素。", "conclusion": "大量实验证明，Ultra3D支持在1024分辨率下实现高质量的3D生成，并在视觉保真度和用户偏好方面达到最新技术水平。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.14632", "html_url": "https://arxiv.org/abs/2507.14632", "title": "BusterX++：通过MLLM实现统一的跨模态AI生成内容检测与解释", "title_en": "BusterX++: Towards Unified Cross-Modal AI-Generated Content Detection and Explanation with MLLM", "authors": "Haiquan Wen,Tianxiao Li,Zhenglin Huang,Yiwei He,Guangliang Cheng", "background": "近年来，生成AI在图像和视频合成方面的进步显著提高了传播虚假信息的风险，传统检测方法已不足以应对跨模态的合成媒体。现有的检测系统在单模态设计上存在局限性，无法有效应对同时包含多种媒体格式的合成内容。因此，研究人员提出了一种新的框架BusterX++，以解决这一问题。该框架专注于跨模态合成媒体的检测和解释，并通过多阶段训练、思考奖励和混合推理来实现性能的稳步提升。", "innovation": "BusterX++框架引入了一种高级增强强化学习（RL）后训练策略，摆脱了冷启动问题。该框架通过多阶段训练（Multi-stage Training）、思考奖励（Thinking Reward）和混合推理（Hybrid Reasoning）实现了显著的性能提升。为了支持全面的评估，还提出了一个名为GenBuster++的跨模态基准，该基准基于最先进的图像和视频生成技术，包含4,000张图像和视频剪辑，经过专业人员精心筛选，确保质量、多样性和实际适用性。", "conclusion": "广泛实验表明，BusterX++方法在检测和解释AI生成的跨模态内容方面有效且具有普遍适用性。该方法通过跨模态检测和解释的统一框架，提供了更高级别透明度和可解释性，增强了检测系统的性能。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.18371", "html_url": "https://arxiv.org/abs/2507.18371", "title": "MVG4D：基于图像矩阵的多视角和运动生成，用于单张图像生成4D内容", "title_en": "MVG4D: Image Matrix-Based Multi-View and Motion Generation for 4D Content Creation from a Single Image", "authors": "DongFu Yin,Xiaotian Chen,Fei Richard Yu,Xuanchen Li,Xinhao Zhang", "background": "生成模型的进步极大地提升了数字内容创作，从2D图像扩展到复杂的3D和4D场景。尽管取得了显著进展，但生成高保真度且时间一致的动态4D内容仍然极具挑战性。目前的方法在处理动态不连续性（如运动模糊）和背景退化方面效果有限，因此需要一种新的框架来解决这些问题，以生成高质量的4D内容。", "innovation": "本文提出了一种名为MVG4D的新框架，该框架通过结合多视角合成和4D高斯点绘制技术，从单张静止图像生成动态4D内容。MVG4D的核心是图像矩阵模块，该模块合成出时空一致且空间多样性的多视角图像，为后续的3D和4D重建提供了丰富的监督信号。通过轻量级变形网络，进一步将3D高斯点云扩展到时间域，解决了运动不连续性和背景退化等问题，提升了流动一致性和几何保真度，使视觉效果更加真实。", "conclusion": "在Objaverse数据集上的实验表明，MVG4D在CLIP-I，PSNR，FVD和时间效率方面均优于最先进的基线，它减少了闪烁伪影并提升了结构细节的清晰度，使得AR/VR体验更加沉浸。MVG4D为从少量输入生成高效且可控的4D内容设定了新的发展方向。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.18675", "html_url": "https://arxiv.org/abs/2507.18675", "title": "视觉人类动作识别的进步：探索视觉语言CLIP模型在跨域任务中的泛化能力", "title_en": "Advancing Vision-based Human Action Recognition: Exploring Vision-Language CLIP Model for Generalisation in Domain-Independent Tasks", "authors": "Utkarsh Shandilya,Marsha Mariya Kappan,Sanyam Jain,Vijeta Sharma", "background": "人类动作识别在医疗健康领域发挥着关键作用，支持如患者行为监控、跌倒检测、手术机器人监督和程序技能评估等应用。尽管传统的CNN和RNN模型取得了一定的成功，但它们在处理多样且复杂动作时常常难以泛化。最近，特别是在视觉-语言模型方面取得的进步，特别是基于transformer的CLIP模型，为从视频数据中泛化动作识别提供了新的可能性。然而，CLIP在UCF-101数据集上的评估结果显示，其表现不稳定且经常出现误分类，特别是在重要视觉线索被遮挡时。因此，需要克服这些局限性，提升此类模型在临床领域的应用能力。", "innovation": "本文通过三类遮罩策略（10%、30%和50%的基于百分比和形状的模糊遮罩、特定特征的模糊遮罩以及仅保留类别特定区域的隔离遮罩）对CLIP进行评估，并揭示了其泛化性能的不一致性。为此，本文提出了一种结合类别特定噪声的方法，利用自定义损失函数学习该噪声，以强化对类别定义特征的关注。这种方法提高了分类准确率和模型置信度，减少了偏见。", "conclusion": "本文讨论了在临床领域应用此类模型所面临的挑战，并提出了未来工作方向，旨在提高在跨域独立医疗健康场景中的泛化能力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.19119", "html_url": "https://arxiv.org/abs/2507.19119", "title": "PatchTraj: 统一的时间-频率表示学习通过动态块进行轨迹预测", "title_en": "PatchTraj: Unified Time-Frequency Representation Learning via Dynamic Patches for Trajectory Prediction", "authors": "Yanghong Liu,Xingping Dong,Ming Li,Weixing Zhang,Yidong Lou", "background": "行人轨迹预测对于自动驾驶和机器人技术至关重要。现有的基于点和基于格网的方法存在两个主要限制：缺乏对人类运动动态的充分建模，因为它们无法同时平衡局部运动细节与长期的空间-时间依赖性；更重要的是，时间表示缺乏与其频率成分之间的交互，在联合建模轨迹序列时效果不佳。这些问题限制了现有方法的效果，急需新的解决方案来提高轨迹预测的准确性。", "innovation": "本文提出了PatchTraj，一种动态块基框架，通过结合时间-频率联合建模来解决轨迹预测问题。具体来说，本文将轨迹分解为原始时间序列和频率分量，并采用动态块分割进行多尺度分割，捕捉层次化的运动模式。每个块经过尺度感知特征提取的自适应嵌入，然后进行分层特征聚合以建模细粒度和长期依赖性。来自两个分支的输出通过跨模态注意力进一步增强，促进时间与频谱线索的互补融合。这种改进后的嵌入展示了强大的表达能力，即使使用简单的Transformers架构也能实现准确的预测。广泛的实验结果表明，该方法在ETH-UCY、SDD、NBA和JRDB数据集上取得了最先进的性能。尤其是在自身体验的JRDB数据集上，PatchTraj在ADE和FDE方面取得了显著的相对改进，分别为26.7%和17.4%，突显了其在实体智能中的巨大潜力。", "conclusion": "本文提出了一种新的混合时间-频率表示学习框架PatchTraj，通过结合动态块分割和时间-频率联合建模，显著提升了轨迹预测性能。实验结果验证了PatchTraj的有效性和先进性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.19621", "html_url": "https://arxiv.org/abs/2507.19621", "title": "Exemplar Med-DETR: 向乳腺X光图像及其他医学影像更通用和稳健的病灶检测迈进", "title_en": "Exemplar Med-DETR: Toward Generalized and Robust Lesion Detection in Mammogram Images and beyond", "authors": "Sheethal Bhat,Bogdan Georgescu,Adarsh Bhandary Panambur,Mathias Zinnen,Tri-Thien Nguyen,Awais Mansoor,Karim Khalifa Elbarbary,Siming Bayer,Florin-Cristian Ghesu,Sasa Grbic,Andreas Maier", "background": "医学图像中的异常检测面临独特挑战，特征表示差异大且解剖结构之间的复杂关系使得该过程复杂化。在乳腺X光成像中，密集的乳腺组织可能掩盖病变，增加放射学解释难度。尽管现有方法利用了解剖和语义上下文，但在学习有效的类别特定特征方面仍存在问题，限制了其在不同任务和成像模态中的应用效果。", "innovation": "提出了一种名为Exemplar Med-DETR的新颖多模态对比检测器，通过交叉注意力机制使用固有、直观的类别特定示例特征，并采用迭代训练策略。该方法在三种不同成像模态的四个公开数据集上实现了最先进的性能，在越南乳腺X光成像中，病灶检测的mAP达到0.7，钙化物检测的mAP达到0.55，绝对提高了16个百分点。此外，在来自不同分布的100张中国乳腺X光图像的放射学家支持评估中，病灶检测性能提高了两倍。对于胸部X光和血管造影图像，病灶和狭窄检测的mAP分别提高了4和7个百分点，达到0.25和0.37。这些结果突显了该方法在推进医学影像中稳健而通用的检测系统方面的潜力。", "conclusion": "Exemplar Med-DETR方法展示了在解决医学成像中的病灶检测时，多模态对比检测器和类别特定示例特征的重要性，通过有效的特征学习，显著提升了不同模态和数据集上的检测准确率。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.13373", "html_url": "https://arxiv.org/abs/2507.13373", "title": "Butter: 频率一致性和分层融合在自主驾驶物体检测中的应用", "title_en": "Butter: Frequency Consistency and Hierarchical Fusion for Autonomous Driving Object Detection", "authors": "Xiaojian Lin,Wenxin Zhang,Yuchu Jiang,Wangyu Wu,Yiran Guo,Kangxu Wang,Zongzheng Zhang,Guijin Wang,Lei Jin,Hao Zhao", "background": "分层特征表示在计算机视觉中起着关键作用，特别是在自主驾驶中的物体检测。多级语义理解对于准确识别动态环境中的行人、车辆和交通标志至关重要。然而，现有的架构如YOLO和DETR在保持不同尺度下特征一致性的同时，难以平衡检测精度和计算效率。为了解决这些挑战，我们提出了Butter，一种新型的物体检测框架，旨在通过增强分层特征表示来改善检测鲁棒性。研究表明，Butter在BDD100K、KITTI和Cityscapes数据集上的实验表明，在降低模型复杂度的同时，特征表示能力出色，显著提高了检测准确性。", "innovation": "Butter提出了两种关键创新：1) 频率自适应特征一致性增强组件（FAFCE组件），通过利用自适应频率滤波来增强各尺度下结构和边界的精度；2) 逐级分层特征融合模块（PHFFNet模块），该模块逐步整合多级特征，以减轻语义差距并加强分层特征学习。", "conclusion": "通过关注分层特征的细化和整合，Butter提供了一种在准确性和计算效率之间达到平衡的高级方法，适用于实时自主驾驶场景下的物体检测。我们的模型和实现公开发布，为自主驾驶社区的研究和验证提供了便利。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.20414", "html_url": "https://arxiv.org/abs/2507.20414", "title": "使用机器学习的印度手语实时检测与翻译", "title_en": "Indian Sign Language Detection for Real-Time Translation using Machine Learning", "authors": "Rajat Singhal,Jatin Gupta,Akhil Sharma,Anushka Gupta,Navya Sharma", "background": "手语是聋哑社区通过手势和身体动作进行交流的语言，主要依赖于视觉空间模式。手语是全球聋哑社区的主要沟通方式。有效的沟通对于人类交互至关重要，但这些社区因缺乏熟练的口译员和可访问的翻译技术而面临巨大障碍。这项研究特别关注印度国内的问题，特别是在印度手语（ISL）方面。研究旨在利用机器学习技术，为印度聋哑和听力困难人群提供实时手语检测和翻译系统。在印度，针对ISL的技术解决方案相较于其他全球手语发展程度较低。研究项目使用卷积神经网络（CNN）训练了一个强大的实时ISL检测与翻译系统，并实现了99.95%的分类精度，以确保系统的实际应用可靠性。", "innovation": "本研究利用机器学习技术，特别为印度手语（ISL）开发了一个实时检测与翻译系统。该系统使用卷积神经网络（CNN）进行训练，实现高精度的手语识别，准确率达到99.95%。系统通过MediaPipe等技术进行了实时的手势追踪和动作检测，以实现动态手势的无缝翻译。研究详细阐述了模型架构、数据预处理流程及分类方法，提高了聋哑社区的交流效率，填补了印度在手语技术解决方案方面相对其他全球手语技术的空白。", "conclusion": "本研究开发的系统能够有效地实时检测和翻译印度手语，具有高精度和可靠性。该系统的实现对于改善印度聋哑和听力困难人群的沟通状况具有重要意义，为决策者提供了基于数据的改进方案。未来，该系统可以在实际应用场景中进一步验证和优化。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.21584", "html_url": "https://arxiv.org/abs/2507.21584", "title": "TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs", "title_en": "TARS: MinMax Token-Adaptive Preference Strategy for Hallucination Reduction in MLLMs", "authors": "Kejia Zhang,Keda Tao,Zhiming Luo,Chang Liu,Jiasheng Tang,Huan Wang", "background": "现有的多模态大型语言模型（MLLMs）能够进行视觉语言推理，但往往会生成事实不准确或视觉上缺乏依据的可信度较高的输出，这影响了模型的可靠性。常见的纠正幻觉策略直接偏好优化（DPO）通过将模型输出与人类偏好对齐来校正幻觉，但现有DPO方法通常将与幻觉相关的偏好作为固定目标，依赖于静态监督信号，在训练过程中容易过度拟合到语言表层线索，导致因果相关视觉信息中的定位不足。", "innovation": "本文提出了TARS，一种针对幻觉减少的令牌适应性偏好策略。TARS将DPO重新表述为一个最小-最大优化问题，通过在语义约束下最大化令牌级别分布迁移以模拟对齐不确定性，同时最小化在这些受控扰动下的预期偏好损失。这一联合目标保持了因果关联的定位，同时减轻了对偏好模式的过度拟合，从而减少多模态推理中的幻觉。实验结果表明，TARS在多个幻觉基准测试中表现出色。", "conclusion": "TARS仅使用4.8k的偏好样本且不依赖专家反馈的情况下，将幻觉率从26.4%降低到13.2%，认知价值从2.5降至0.4。TARS在多个关键指标上超过了标准DPO，并与GPT-4o取得了媲美的性能。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.20356", "html_url": "https://arxiv.org/abs/2507.20356", "title": "在增强现实环境中检测视觉信息操纵攻击：一种多模态语义推理方法", "title_en": "Detecting Visual Information Manipulation Attacks in Augmented Reality: A Multimodal Semantic Reasoning Approach", "authors": "Yanming Xiu,Maria Gorlatova", "background": "增强现实(AR)中的虚拟内容可能会引入误导性或有害信息，导致意义误解或用户错误。本文关注AR中的视觉信息操纵(VIM)攻击，即虚拟内容以微妙而有影响力的手段改变现实世界场景的意义。本文提出了一种分类体系，将这些攻击分为字符、短语和模式操纵三种格式，以及信息替换、信息混淆和额外错误信息三种目的，并基于此构建了一个包含452个原始AR视频对的数据集，涵盖202种不同的场景，模拟了现实世界的AR情景。为了检测此类攻击，提出了一个基于多模态语义推理的框架VIM-Sense，结合了视觉语言模型的视觉和语言理解能力，以及基于光学字符识别（OCR）的文本分析，该框架在AR-VIM数据集上的攻击检测准确率达到88.94%，持续超越了纯视觉和纯文本基准模型的表现。系统在模拟视频处理框架中的平均攻击检测延迟为7.07秒，在真实世界评估中的平均延迟为7.17秒（在移动Android AR应用程序上）", "innovation": "提出了一种新的分类体系来梳理和理解AR中的视觉信息操纵攻击；构建了一个名为AR-VIM的数据集；提出了一种名为VIM-Sense的多模态语义推理框架，结合了视觉语言模型的图像和文本理解能力和OCR技术，有效提升了攻击检测的准确性和效率", "conclusion": "这项研究提出了一种新的方法来检测增强现实中视觉信息操纵攻击，并表明该方法具有显著的准确性和效率，超越现有基准模型。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.21358", "html_url": "https://arxiv.org/abs/2507.21358", "title": "协作感知器：通过局部密度意识的空间占用提升基于视觉的3D目标检测", "title_en": "Collaborative Perceiver: Elevating Vision-based 3D Object Detection via Local Density-Aware Spatial Occupancy", "authors": "Jicheng Yuan,Manh Nguyen Duc,Qian Liu,Manfred Hauswirth,Danh Le Phuoc", "background": "基于视觉的3D目标在自动驾驶中的鸟瞰图（BEV）检测近年来取得了显著进展，这种技术具有成本效益且能提供丰富的上下文信息。然而，现有的方法通常通过压缩提取的物体特征来构建BEV表示，往往忽略了道路和人行道等固有的环境背景，这限制了检测器对物理世界的全面感知能力。", "innovation": "我们介绍了一种多任务学习框架——协作感知器（CoP），该框架利用空间占用作为辅助信息，挖掘3D物体检测和占用预测任务之间共享的一致的结构和概念相似性，填补了空间表示和特征精炼之间的鸿沟。为此，我们首先提出了一种生成密集占用地面真实值的管道，这些真实值包含局部密度信息（LDO），以重建详细的环境信息。其次，我们采用一种基于体素和高度的采样（VHS）策略，根据不同的物体特性提取细粒度的局部特征。此外，我们开发了一种全球-局部协作特征融合（CFF）模块，无缝地整合了两个任务之间的互补知识，从而组成更健壮的BEV表示。", "conclusion": "在nuScenes基准测试上进行的广泛实验表明，CoP优于现有的基于视觉的框架，测试集上的mAP和NDS分别为49.5%和59.2%。相关代码和补充材料可在该链接下载。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.20469", "html_url": "https://arxiv.org/abs/2507.20469", "title": "优先级感知的临床病理层次训练", "title_en": "Priority-Aware Clinical Pathology Hierarchy Training for Multiple Instance Learning", "authors": "Sungrae Hong,Kyungeun Kim,Juhyeon Kim,Sol Lee,Jisu Shin,Chanjae Song,Mun Yong Yi", "background": "MIL在临床环境中用于病理诊断决策中正变得越来越普遍，具有高性能且可以减轻标注负担。然而，现有的临床MIL方法未能充分解决病理症状和诊断类别间的优先级问题，导致MIL模型忽视了类别间的优先级。", "innovation": "提出了一个新的MIL方法，使用垂直跨层次和水平同层次两种层次结构来解决优先级问题，通过在每个层次上对MIL预测进行对齐并在训练过程中引入隐式的特征可重用性，以促进同一层次中更严重的临床症状优先显示。", "conclusion": "在真实的患者数据上的实验表明，提出的办法可以有效减少误诊并且在多类场景下优先处理重要症状。进一步的分析验证了提出组件的有效性，并在具有多个症状的具有挑战性的案例中对MIL的预测进行了定量验证。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22498", "html_url": "https://arxiv.org/abs/2507.22498", "title": "基于频谱空间聚类的稳健恶劣天气去除", "title_en": "Robust Adverse Weather Removal via Spectral-based Spatial Grouping", "authors": "Yuhwan Jeong,Yunseo Yang,Youngho Yoon,Kuk-Jin Yoon", "background": "恶劣天气条件导致图像出现多种复杂退化模式，促使开发了一体化（All-in-One，AiO）模型。然而，现有的AiO解决方案仍难以捕捉各种退化，因为全局滤波方法如直接在频域上的操作无法处理高度变化且局部化的退化。为了应对这些挑战，提出了频谱空间聚类变换器（Spectral-based Spatial Grouping Transformer，SSGformer），这是一种利用频谱分解和组间注意机制进行多天气图像恢复的新方法。", "innovation": "SSGformer 通过传统的边缘检测将图像分解为高频边缘特征，并通过奇异值分解获取低频信息。利用多头线性注意机制有效建模这些特征之间的关系。结合输入生成融合后的特征.mask，依据空间相似性和图像纹理对区域进行聚类。提出了一种组间注意力机制，充分利用这个掩码，从而实现恶劣天气的稳健去除，并确保在各种天气条件下的稳定性能。此外，提出了一个空间组间变换器块，结合通道注意和空间注意有效地平衡特征层面的关系和空间依赖性。", "conclusion": "广泛实验表明，我们的方法在处理多样且复杂的恶劣天气退化方面具有优越性，验证了其有效性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22062", "html_url": "https://arxiv.org/abs/2507.22062", "title": "Meta CLIP 2: 全球规模训练的食谱", "title_en": "Meta CLIP 2: A Worldwide Scaling Recipe", "authors": "Yung-Sung Chuang,Yang Li,Dong Wang,Ching-Feng Yeh,Kehan Lyu,Ramya Raghavendra,James Glass,Lifei Huang,Jason Weston,Luke Zettlemoyer,Xinlei Chen,Zhuang Liu,Saining Xie,Wen-tau Yih,Shang-Wen Li,Hu Xu", "background": "CLIP 是一个流行的基座模型，支持零样本分类、检索和多模态大型语言模型的编码器。尽管 CLIP 已经在英语世界的 billion 级图像-文本对上成功训练，但将其进一步扩展到从全球网络数据中学习仍然具有挑战性。主要原因包括缺乏处理非英语世界数据点的管理方法，以及现有跨语言 CLIP 的英语性能不如仅英语版本，这被称为“语言多样性的诅咒”。", "innovation": "本文介绍了 Meta CLIP 2，这是第一个从头开始在规模级别的图像-文本对上训练 CLIP 的方法。通过进行严格的删减分析并最小化必要的调整来解决上述挑战，提出了一个公式，可以从英语和非英语世界的数据中受益并互惠互利。在零样本 ImageNet 分类中，Meta CLIP 2 ViT-H/14 比仅英语版本高出 0.8%，比 mSigLIP 高出 0.7%，并且在多语言基准上的性能上打破了新的最佳记录，如 CVQA (57.4%)、Babel-ImageNet (50.2%) 和 XM3600 (64.3%)。这些结果没有系统级的混淆因素（例如翻译、特定架构更改）的影响。", "conclusion": "Meta CLIP 2 作为一种全球规模训练的食谱，在多个多语言任务上打破了记录，展示了在不同语言的数据中训练 CLIP 的潜力，并提出了处理大规模跨语言数据的新方法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22530", "html_url": "https://arxiv.org/abs/2507.22530", "title": "HRVVS: 通过分层自回归残差先验的高分辨率视频血管分割网络", "title_en": "HRVVS: A High-resolution Video Vasculature Segmentation Network via Hierarchical Autoregressive Residual Priors", "authors": "Xincheng Yao,Yijun Yang,Kangwei Guo,Ruiqiang Xiao,Haipeng Zhou,Haisu Tao,Jian Yang,Lei Zhu", "background": "在肝脏手术（如肝切除术）过程中，肝血管的分割具有重要的临床意义，但因缺乏适当的数据集和任务本身的复杂性，该领域的相关研究较少。", "innovation": "本文提出了一种创新的高分辨率视频血管分割网络（HRVVS），新颖之处在于将预训练的视觉自回归模型嵌入到层次编码器的不同层中，以减少下采样过程中信息的退化，并设计了多视图分割网络中的动态记忆解码器，以减少冗余信息的传递同时保留更多帧间细节。", "conclusion": "在手术视频数据集上的广泛实验表明，提出的HRVVS显著优于现有方法。源代码和数据集将公开发布。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22136", "html_url": "https://arxiv.org/abs/2507.22136", "title": "颜色作为驱动力：转变的少样本学习", "title_en": "Color as the Impetus: Transforming Few-Shot Learner", "authors": "Chaofei Qi,Zhitai Liu,Jianbin Qiu", "background": "人类具备天生的元学习能力，部分原因归结为他们独特的色彩感知能力。在此之前的研究中，很少有方法关注色彩信息在元学习中的作用，大多数方法集中在抽象的特征区分上。本研究旨在通过模拟人类色彩感知机制，从色彩这一最直观的视觉特征出发，设计一种新的元学习框架来解决少样本学习问题。", "innovation": "本文提出了一个新的视角和框架，即基于色彩感知机制的少样本学习。具体来说，我们引入了一种名为ColorSense Learner的生物启发式的元学习框架，该框架通过跨通道特征提取和交互学习强调不同通道中的色彩信息。此外，我们还提出了一种基于知识蒸馏的元蒸馏器，ColorSense Distiller，以增强学生网络的元学习能力。该方法在多种少样本基准测试中表现出色，特别是在颜色感知的角度实现了一次性的少样本分类。", "conclusion": "研究结果表明，我们的方法在泛化能力、鲁棒性和迁移性方面表现极强，并且容易从色彩感知的角度处理少样本分类任务。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22886", "html_url": "https://arxiv.org/abs/2507.22886", "title": "迈向全模态表达与推理在引用音频视觉分割中的研究", "title_en": "Towards Omnimodal Expressions and Reasoning in Referring Audio-Visual Segmentation", "authors": "Kaining Ying,Henghui Ding,Guangquan Jie,Yu-Gang Jiang", "background": "尽管近期在引用音频视觉分割（RAVS）方面取得了显著进步，但在多模态信息整合以及对音频视觉内容深入了解与推理方面仍存在挑战。", "innovation": "Omnimodal Referring Audio-Visual Segmentation（OmniAVS）是一个新数据集，包含2,104个视频和61,095个跨模态引用表达。OmniAVS具有三个关键创新：（1）8种灵活的跨模态表达，结合了文本、语音、声音和视觉线索；（2）侧重理解音频内容，而不仅仅是检测其存在；（3）表达中包含复杂的推理和世界知识。此外，还提出了Omnimodal Instructed Segmentation Assistant（OISA），以解决OmniAVS中的多模态推理和细粒度音频视觉内容理解挑战。OISA使用MLLM来理解复杂的提示并执行基于推理的分割。", "conclusion": "广泛的实验表明，OISA在OmniAVS上优于现有方法，并在其他相关任务上取得了具有竞争力的结果。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22607", "html_url": "https://arxiv.org/abs/2507.22607", "title": "VL-Cogito: 进阶多模态推理的渐进式 Curriculum 强化学习", "title_en": "VL-Cogito: Progressive Curriculum Reinforcement Learning for Advanced Multimodal Reasoning", "authors": "Ruifeng Yuan,Chenghao Xiao,Sicong Leng,Jianyu Wang,Long Li,Weiwen Xu,Hou Pong Chan,Deli Zhao,Tingyang Xu,Zhongyu Wei,Hao Zhang,Yu Rong", "background": "强化学习已被证明能有效提升大型语言模型的推理能力，近年来这种范式逐步扩展到多模态推理任务。由于多模态任务本身的复杂性和多样性，尤其是在语义内容与问题表述方面，现有模型在不同领域和难度级别上的表现往往不稳定。为解决这些局限性，本文提出了一种名为VL-Cogito的先进多模态推理模型，它通过一种新颖的多阶段渐进式 Curriculum 强化学习（PCuRL）框架进行训练。PCuRL框架通过模型逐步经历难度逐步增加的任务，显著提升了其在多模态上下文中的推理能力。", "innovation": "该框架引入了两项关键创新：（1）在线难度软权重机制，可以在连续的强化学习训练阶段动态调整训练难度；（2）动态长度奖励机制，鼓励模型根据任务复杂度主动调节其推理路径长度，进而平衡推理效率与准确性。", "conclusion": "实验评估显示，VL-Cogito模型在涵盖数学、科学、逻辑和一般理解的主流多模态基准测试中，能够一致地达到或超越现有推理导向模型的表现，验证了我们方法的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.22477", "html_url": "https://arxiv.org/abs/2507.22477", "title": "LIDAR: 轻量化自适应线索感知融合视觉Mamba架构用于结构裂纹多模态分割", "title_en": "LIDAR: Lightweight Adaptive Cue-Aware Fusion Vision Mamba for Multimodal Segmentation of Structural Cracks", "authors": "Hui Liu,Chen Jia,Fan Shi,Xu Cheng,Mengfei Shi,Xia Xie,Shengyong Chen", "background": "在使用多模态数据实现像素级分割时，现有方法在适应性和跨模态特征高效交互融合方面能力不足。尤其是在结构裂纹分割任务中，实现低成本计算的像素级分割依然是一个关键挑战。", "innovation": "本文提出了一个轻量化自适应线索感知视觉Mamba网络（LIDAR），包含一个轻量化自适应线索感知视觉状态空间模块（LacaVSS）和一个轻量化双域动态协作融合模块（LD3CF）。LacaVSS通过提出的掩码引导高效动态引导扫描策略来自适应建模裂纹线索，而LD3CF利用自适应频域感知器（AFDP）和双池化融合策略跨模态高效捕捉空间和频域线索。此外，还设计了一个轻量化动态调制多核卷积（LDMK）来感知复杂的形态结构，同时最小化计算开销。实验结果表明，该方法在三个数据集上都优于其他SOTA方法。在轻场深度数据集上，该方法仅用5.35M参数实现了F1为0.8204和mIoU为0.8465的结果。", "conclusion": "实验结果证实了该方法在结构裂纹多模态分割中的优越性能，尤其在保持高分割精度与计算成本受限之间取得了良好平衡。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.20216", "html_url": "https://arxiv.org/abs/2507.20216", "title": "采矿区域场景分类的双流全局-局部特征协作表示网络", "title_en": "Dual-Stream Global-Local Feature Collaborative Representation Network for Scene Classification of Mining Area", "authors": "Shuqi Fan,Haoyi Wang,Xianju Li", "background": "采矿区域的场景分类提供了地质环境监测和资源开发规划的准确基础数据。然而，采矿区域分类面临复杂的空间布局和多尺度特征的挑战。通过融合多源数据构建多模态采矿土地覆盖场景分类数据集，提取全局和局部特征能够全面反映空间分布，有效捕捉采矿场景的整体特征。", "innovation": "该研究提出了一种双分支融合模型利用协作表示方法来分解全局特征为一组关键语义向量。该模型由三个关键组件组成：(1) 多尺度全局转子器分支：利用相邻的大尺度特征生成小尺度特征的全局通道注意力特征，有效捕捉多尺度特征关系；(2) 局部增强协作表示分支：通过利用局部特征和重构的关键语义集来细化注意力权重，确保采矿区域的局部上下文和详细特征被有效集成；(3) 双分支深度特征融合模块：融合两个分支的互补特征以包含更多的场景信息，这种融合增强了模型区分和分类复杂采矿景观的能力。此外，使用多损失计算确保模块的平衡集成。", "conclusion": "该模型在整体准确度方面达到了83.63%，优于其他比较模型，并且在所有其他评估指标中也表现出最佳性能。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2306.01654", "html_url": "https://arxiv.org/abs/2306.01654", "title": "closed-form IPM-GAN Discriminator Guidance for Diffusion Modeling", "title_en": "Insights into Closed-form IPM-GAN Discriminator Guidance for Diffusion Modeling", "authors": "Aadithya Srikanth,Siddarth Asokan,Nishanth Shetty,Chandra Sekhar Seelamantula", "background": "扩散模型是一种先进的生成模型框架，通过拉angevin采样将噪声转换为图像，并在评分（数据分布对数梯度）的引导下运行。最近的研究表明，当通过分类网络（通常是生成对抗网络GAN训练中的判别器）进行引导时，生成质量可以得到改善。本文旨在研究GAN判别器对基于拉angevin采样方法的影响，并将其优化视为平滑分数匹配的一部分，并将数据和生成器分布的评分与IPM相关的核函数卷积。该方法旨在统一基于评分的训练和IPM-GAN优化。", "innovation": "本文提出了一种理论上分析GAN判别器对拉angevin采样影响的框架，并展示了IPM-GAN优化可以看作是平滑分数匹配的一部分。研究发现，基于闭合形式核函数的判别器引导对于基准扩散模型而言能够改进生成质量（以CLIP-FID和KID指标衡量）并在不同标准数据集上的降噪扩散隐式模型（DDIM）和潜在扩散模型（LDM）设置中进行了验证。同时，提出的方法还可以与其他加速扩散技术结合使用，以改善潜在空间中的图像生成。", "conclusion": "研究结果表明，基于闭合形式核函数的判别器引导可用于提高扩散模型的生成质量，并在各种标准数据集上的不同模型中验证了这一点。此外，该方法还可以与现有的加速扩散技术相结合，进一步提升潜在空间中的图像生成效果。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.07720", "html_url": "https://arxiv.org/abs/2407.07720", "title": "利用规模变异注意力分割医学图像中的小尺度物体", "title_en": "Exploiting Scale-Variant Attention for Segmenting Small Medical Objects", "authors": "Wei Dai,Rui Liu,Zixuan Wu,Tianyi Wu,Min Wang,Junxian Zhou,Yixuan Yuan,Jun Liu", "background": "早期检测和准确诊断可预测恶性疾病转化的风险，从而增加有效治疗的可能性。识别具有轻微症状和小病理区域的疾病对于早期诊断至关重要。尽管卷积神经网络（CNN）在分割医疗对象方面表现出了潜力，但在分析医疗图像中的小区域方面仍然存在挑战。这一挑战源于卷积和池化操作中的信息损失和压缩缺陷，特别是在网络逐渐加深时，这对小的医疗对象尤为明显。", "innovation": "本文提出了一种新的规模变异注意力网（SvANet），专门用于精确分割医学图像中小尺度对象。SvANet包含规模变异注意力、跨尺度引导、蒙特卡罗注意力和视觉变换器，能够结合跨尺度特征，缓解压缩伪影，从而提高对小医疗对象的区分能力。实验结果表明，SvANet在分割肾肿瘤、皮肤病变、肝脏肿瘤、息肉、手术切除细胞、视网膜血管和精子等图像区域占不到1%的小尺度对象时表现优异，平均Dice系数分别达到了96.12%，96.11%，89.79%，84.15%，80.25%，73.05%和72.58%。", "conclusion": "SvANet通过引入规模变异注意力机制，解决了传统CNN在处理小尺度对象时的缺点，显著提升了分割小尺度对象的精度。该模型在多个医学图像数据集上展现了出色的表现，证明了其在临床诊断中的潜在应用价值。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.19490", "html_url": "https://arxiv.org/abs/2409.19490", "title": "KineDepth：利用机器人运动学进行实时米级深度估计", "title_en": "KineDepth: Utilizing Robot Kinematics for Online Metric Depth Estimation", "authors": "Soofiyan Atar,Yuheng Zhi,Florian Richter,Michael Yip", "background": "深度感知对于机器人理解其环境的空间和几何关系至关重要，传统上许多任务依赖于硬件深度传感器，如RGB-D或立体相机。然而，这些传感器存在一些实际问题，包括透明和反射物体的问题、成本高、校准复杂、空间和能量限制以及复合系统中的失败率增加。单目深度估计方法因其成本效益和简单性提供了替代方案，但由于它们输出的是相对而非计量深度，这限制了它们在机器人领域的应用。本文讨论了如何通过利用机器人运动学来实时进行米级深度估计的方法，以解决单目深度估计在机器人应用中的不足。", "innovation": "本文提出了一种方法，利用单个校准相机，使机器人能够在执行任务时实时将相对深度估计转换为计量深度。该方法通过基于LSTM的计量深度回归器实时进行训练和优化，对单目深度图中的相对深度进行实时恢复，特别是邻近机器人运动的区域。这种方法显著优于当前最先进的单目计量深度估计技术，减少深度误差22.1%，成功率提高52%。", "conclusion": "实验表明，通过利用机器人运动学进行实时米级深度估计的方法能够显著提高单目深度估计的准确性，提高机器人在实际任务中的应用效果。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2407.08722", "html_url": "https://arxiv.org/abs/2407.08722", "title": "使用深度网络推断雅可比场控制多样化机器人", "title_en": "Controlling diverse robots by inferring Jacobian fields with deep networks", "authors": "Sizhe Lester Li,Annan Zhang,Boyuan Chen,Hanna Matusik,Chao Liu,Daniela Rus,Vincent Sitzmann", "background": "复现自然界生物的复杂结构和多样化功能一直是机器人技术的一大挑战。现代制造技术大大扩展了可行的硬件范围，但这些系统需要控制软件将期望的运动转换成执行器命令。传统的机器人可以很容易地建模为由关节连接的刚性连杆，但很难模拟和控制受生物启发的机器人，这些机器人通常柔软或由多种材料制成，缺乏感知能力，使用时材料性质可能发生变化。因此，需要一种方法来控制这些生物启发的机器人，而无需假设其材料、驱动方式或感知设备。", "innovation": "本文介绍了一种方法，该方法使用深度神经网络将机器人的视频流映射为其视知觉雅可比场（所有3D点对机器人执行器的敏感度）。该方法使得仅通过单个相机就能控制机器人，不需要关于机器人材料、驱动方式或感知设备的假设，且通过观察随机命令的执行效果进行训练无需专家干预。该方法被应用于多种不同类型的机器人操作臂，展示了在不同驱动方式、材料、制造方法和成本下的效果。该方法实现了准确的闭环控制，并恢复了每台机器人的因果动态结构。由于只需使用通用相机作为唯一传感器即可控制机器人，预计该研究将拓宽机器人系统的设计空间，并为降低机器人自动化门槛提供起点。", "conclusion": "由于该方法能使用通用相机作为唯一传感器控制机器人，研究者认为该方法在未来能广泛应用于各种不同的机器人系统，并可能降低机器人自动化的门槛。该工作有望为未来的机器人控制提供新的视角和方法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.02508", "html_url": "https://arxiv.org/abs/2412.02508", "title": "当言语展露微笑：根据文本生成多样情绪面部表情", "title_en": "When Words Smile: Generating Diverse Emotional Facial Expressions from Text", "authors": "Haidong Xu,Meishan Zhang,Hao Ju,Zhedong Zheng,Erik Cambria,Min Zhang,Hao Fei", "background": "数字人类表达丰富情感在对话系统、游戏和其他互动场景中有重要的应用价值。尽管最近在对话头合成方面的进展已经实现了令人印象深刻的效果，比如唇部同步，但这些方法往往忽视了面部表情丰富而动态的特性。本文的目的是填补这一重要缺口，提出一种端到端的文本到表情模型，该模型明确关注情感动态。模型在连续的潜在空间中学习表达性面部的变化，生成多样化、流畅且情感一致的表情。为了支持这一任务，该研究引入了一个包含15,000个文本-3D表情对的大型高质量数据集EmoAva。在现有数据集和引入的数据集上的实验表明，该方法在多个评价指标上显著优于基线方法，推进了该领域的发展。", "innovation": "提出了一个端到端的文本到表情模型，明确关注情感动态。模型在连续的潜在空间中学习表达性面部的变化，生成多样化、流畅且情感一致的表情。引入了EmoAva数据集，这是一个包含15,000个文本-3D表情对的大型高质量数据集。", "conclusion": "在现有数据集和EmoAva的数据集上的实验表明，该方法在多个评价指标上显著优于基线方法，这标志着领域内的一个重要进步。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.05911", "html_url": "https://arxiv.org/abs/2503.05911", "title": "泛化图像修复以实现稳健的视觉控制", "title_en": "Generalizable Image Repair for Robust Visual Control", "authors": "Carson Sobolewski,Zhenjiang Mao,Kshitij Maruti Vejre,Ivan Ruchkin", "background": "基于视觉的控制依赖于准确的感知来实现鲁棒性。然而，由于传感器噪声、恶劣天气和动态光照引起图像分布的变化会降低感知质量，导致控制决策不尽合理。现有方法，如领域自适应和对抗训练，虽然可以提升鲁棒性，但难以泛化到未见过的损坏，并且可能会增加计算负担。", "innovation": "我们提出了一种实时图像修复模块，在控制器使用受损图像之前对其进行修复。该方法利用生成对抗网络，即CycleGAN和pix2pix进行图像修复。CycleGAN可以实现无配对图像到图像的转换以适应新型损坏，而pix2pix则在有配对图像数据时提高图像质量。为了与控制性能保持一致，我们引入了一种基于控制的损失函数，优先考虑修复图像的感知一致性。", "conclusion": "我们在模拟自主赛车环境中对各种视觉损坏进行了方法评估，结果显示，与基线方法相比，我们的方法显著提高了性能，减轻了分布偏移，并增强了控制器的可靠性。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.06275", "html_url": "https://arxiv.org/abs/2505.06275", "title": "SinBasis Networks: Matrix-Equivalent Feature Extraction for Wave-Like Optical Spectrograms", "title_en": "SinBasis Networks: Matrix-Equivalent Feature Extraction for Wave-Like Optical Spectrograms", "authors": "Yuzhou Zhu,Zheng Zhang,Ruyi Zhang,Liang Zhou", "background": "波形图像（如亚飞秒持續譜、拉曼光譜、光致發光光譜、近紅外轉移光譜、音頻梅爾頻譜圖和週期视频帧）包含关键谐波结构，这对传统的特征提取方法构成挑战。现有技术难以捕捉这些波形图像中的周期模式和空间平移不变性。", "innovation": "提出了一个统一的矩阵等价框架，重新诠释卷积和注意力机制为扁平化输入上的线性变换，并揭示滤波器权重为跨越潜在特征子空间的基向量。通过在每个权重矩阵上应用逐元素的$\text{sin}(\text{⋅})$映射来嵌入频谱先验。将这些变换嵌入到CNN、ViT（视觉变换器）和Capsule架构中，生成Sin-Basis网络，其对周期模式具有更高的敏感性，并内置了空间平移不变性。通过各种波形图像数据集（包括8万个合成亚飞秒持续谱、数千张拉曼、光致发光、傅里叶变换红外光谱、音频梅尔频谱图和Kinetics中的周期帧）的实验，展示了重建精度、平移鲁棒性和零样本跨域迁移的显著提升。", "conclusion": "理论分析通过矩阵同构和Mercer内核截断量化了正弦重参数化如何丰富可表达性同时保持数据贫乏区域的稳定性。Sin-Basis网络为所有波形成像模态提供了一种物理启发式且轻量级的深度学习方法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.13811", "html_url": "https://arxiv.org/abs/2412.13811", "title": "用于估计3D脑肿瘤浸润的轻量级优化框架", "title_en": "A Lightweight Optimization Framework for Estimating 3D Brain Tumor Infiltration", "authors": "Jonas Weidner,Michal Balcerak,Ivan Ezhov,André Datchev,Laurin Lux,Lucas Zimmer,Daniel Rueckert,Björn Menze,Benedikt Wiestler", "background": "胶质母细胞瘤是一种高度侵袭性的原发性脑肿瘤，其弥漫性微小浸润难以在标准MRI中被检测到。目前的放疗计划采用统一的15毫米边缘，未能捕捉到患者的个体化肿瘤扩散。肿瘤生长建模为揭示这种隐藏的浸润提供了有希望的方法。然而，基于偏微分方程或物理启发的神经网络的方法通常计算密集或过于约束，限制了其临床适应性。", "innovation": "本文提出了一种轻量级、快速且稳健的优化框架，通过将3D肿瘤浓度与MRI肿瘤分割匹配并强制平滑浓度景观来估计3D肿瘤浸润，这种方法在两个公共数据集中对192名脑肿瘤患者的肿瘤复发预测上优于最先进的基准，同时将运行时间从30分钟缩短到不到一分钟。此外，展示了该框架的灵活性和适应性，能够在无缝整合额外成像模态或物理约束时表现良好。", "conclusion": "该轻量级优化框架通过快速且精确地估计3D肿瘤浓度，并在临床适应性和计算效率方面表现出色，为揭示胶质母细胞瘤的隐蔽浸润提供了新的方法。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.06989", "html_url": "https://arxiv.org/abs/2503.06989", "title": "多模态LLMs上的概率建模：从量化到应用", "title_en": "Probabilistic Modeling of Jailbreak on Multimodal LLMs: From Quantification to Application", "authors": "Wenzhuo Xu,Zhipeng Wei,Xiongtao Sun,Zonghao Ying,Deyue Zhang,Dongdong Yang,Xiangzheng Zhang,Quanchen Zou", "background": "最近，多模态大型语言模型（MLLMs）在理解多模态内容方面展现了优越的能力，但它们仍然容易受到禁闭攻击的影响。以往研究将禁闭攻击分类为成功的或失败的，基于响应中是否包含有害内容。但是，由于MLLM响应的随机性，这种二元分类方式不合适。因此，引入禁闭概率来量化输入禁闭MMLMs的潜在能力，表示在给定输入时MLLM生成有害响应的可能性。", "innovation": "本文提出了一种禁闭概率预测网络（JPPN），用于建模输入潜态与禁闭概率之间的关系。并设计了基于禁闭概率的攻击（JPA）和进一步增强的多模态JPA（MJPA），用于最大化伤害概率。同时，提出了基于禁闭概率的微调（JPF）方法，以减少给定模型的禁闭攻击发生。实验结果表明，这两种方法均能显著提高抵御攻击的效果。", "conclusion": "（1）在多种模型下的白色和黑色盒设置中，（M）JPA能够显著提升对模型的攻击效果。（2）JPF能极大地降低超过60%的禁闭攻击发生率。这些结果突显了引入禁闭概率的重要性，能够对输入的禁闭能力做出细微区分。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2405.05846", "html_url": "https://arxiv.org/abs/2405.05846", "title": "基于反转的扩散模型记忆度量", "title_en": "An Inversion-based Measure of Memorization for Diffusion Models", "authors": "Zhe Ma,Qingming Li,Xuhong Zhang,Tianyu Du,Ruixiao Lin,Zonghui Wang,Shouling Ji,Wenzhi Chen", "background": "最近几年，由扩散模型驱动的图像生成取得了显著的进步。然而，这些模型容易受到训练数据记忆的影响，这引发了严重的版权侵犯和隐私侵犯的担忧。这项研究深入分析了扩散模型中的记忆现象。", "innovation": "提出了一种基于反转的记忆度量InvMM，该度量通过反转敏感的潜在噪声分布来考虑图像的复制。为了准确估计该度量，提出了一种平衡噪声分布的正常性和敏感性的自适应算法。在四个数据集上进行的全面实验表明，InvMM 为扩散模型提供了可靠且全面的量化分析，从对抗的角度揭示了真实的记忆程度，并且可以表明记忆与成员资格的不同。", "conclusion": "InvMM 作为开发人员的一个审计工具，可以帮助他们可靠地评估模型的记忆风险，从而有助于增强扩散模型的信任度和隐私保护能力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.15857", "html_url": "https://arxiv.org/abs/2507.15857", "title": "扩散模型在数据受限场景下优于自回归模型", "title_en": "Diffusion Beats Autoregressive in Data-Constrained Settings", "authors": "Mihir Prabhudesai,Mengning Wu,Amir Zadeh,Katerina Fragkiadaki,Deepak Pathak", "background": "自回归（AR）模型长期以来主导着大型语言模型领域，广泛应用于各类任务。最近，基于扩散的语言模型作为一种有前景的替代方案出现，尽管它们相较于AR模型的优势尚未得到充分探索。", "innovation": "本文系统地研究了在数据受限的设置下掩码扩散模型的表现，发现它们在算力充足但数据稀缺的情况下显著优于自回归模型。扩散模型能够更有效地利用重复的数据，实现更低的验证损失和更好的下游性能。作者将其优势解释为隐式的数据增强。", "conclusion": "当数据而非算力成为瓶颈时，扩散模型为标准的AR范式提供了有说服力的替代方案。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.02439", "html_url": "https://arxiv.org/abs/2504.02439", "title": "使用分布式微型TOF传感器估计机器人周围场景流", "title_en": "Estimating Scene Flow in Robot Surroundings with Distributed Miniaturized Time-of-Flight Sensors", "authors": "Jack Sander,Giammarco Caroleo,Alessandro Albini,Perla Maiolino", "background": "在机器人的周围跟踪人类或物体的运动对于提高机器人安全运动和反应至关重要。本文提出了一种基于分布式微型时间飞行（ToF）传感器的场景流估计方法，旨在处理低密度和噪声较大的点云数据。", "innovation": "针对低密度和噪声较大的点云数据，本文提出了一种新的场景流估计方法。该方法通过连续帧聚类结合迭代最近点（ICP）算法生成密集的运动流，同时引入了基于适用性分类和内点移除策略来减轻传感器噪声和稀疏点的影响。", "conclusion": "通过实验研究了24个ToF传感器来估计在不同可控速度下物体的运动速度。实验结果显示，该方法能够稳定地估计运动方向及其大小，并且误差与传感器噪声相当。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.17564", "html_url": "https://arxiv.org/abs/2503.17564", "title": "ModalTune: 使用多模态信息微调滑块级基础模型以在数字病理学中实现多任务学习", "title_en": "ModalTune: Fine-Tuning Slide-Level Foundation Models with Multi-Modal Information for Multi-task Learning in Digital Pathology", "authors": "Vishwesh Ramanathan,Tony Xu,Pushpak Pati,Faruk Ahmed,Maged Goubran,Anne L. Martel", "background": "数字病理学中的预测任务因全组织切片图像（WSIs）的庞大尺寸和训练信号的微弱特性而具有挑战性。计算技术的进步、数据的可用性和自我监督学习（SSL）的发展为滑块级别基础模型（SLFMs）的开发铺平了道路，这类模型可以在数据有限的情况下改善预测任务。然而，现有方法未能充分利用任务之间和模态之间的共享信息。", "innovation": "提出了ModalTune，一个新颖的微调框架，引入了模态适配器以不修改SLFM权重的方式整合新模态。此外，使用大语言模型（LLMs）将标签编码为文本，捕捉多任务和多种癌症类型的语义关系。ModalTune在四个癌症类型上达到了最先进的结果，同时统一了单一模式模型和多模式模型，并在泛癌环境中表现出竞争力。此外，显示ModalTune在两个新的分布外（OOD）数据集上具有泛化能力。这是第一个统一体多模式、多任务和泛癌建模的微调框架。", "conclusion": "ModalTune能够通过整合多模态信息而不修改现有模型权重，提高多个癌症类型的生存率和癌症亚型的预测精度，并且具有泛化到新的分布外数据集的能力。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.03956", "html_url": "https://arxiv.org/abs/2506.03956", "title": "在持续学习之前进行调整", "title_en": "Adapt before Continual Learning", "authors": "Aojun Lu,Tao Feng,Hangjie Yuan,Chunhui Ding,Yanan Sun", "background": "持续学习（CL）旨在使神经网络能够逐步获取新知识（可塑性）的同时保留现有知识（稳定性）。尽管预训练模型（PTMs）为CL提供了强大的基础，但现有的方法在平衡这两项竞争性目标方面面临根本挑战。当前方法通常通过冻结PTM主干来解决稳定性，这严重限制了模型的可塑性，特别是在新来的数据分布与预训练数据差异较大时。相反，对整个PTM进行序列微调可以适应新知识，但往往会导致灾难性遗忘，突显了基于PTMs的CL中的稳定性-可塑性权衡。", "innovation": "为了解决这一局限性，提出了《在持续学习之前进行调整》的新框架（ACL）。ACL在学习每个新任务之前引入了一个即插即用的调整阶段，通过调整主干以与原始类别原型对齐同时远离不相关类别，实现两者之间的理想平衡。这一机制在理论和实验上都证明了稳定性与可塑性的良好平衡，显著提高了CL在基准测试和综合方法中的性能。", "conclusion": "ACL框架为解决预训练模型在持续学习中的稳定性-可塑性权衡提供了一个新的解决方案，通过在学习新任务之前调整PTM主干，实现在保留现有知识的同时有效学习新知识，显著提升了CL的性能。"}
{"llm_update_time": "20250801", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10006", "html_url": "https://arxiv.org/abs/2506.10006", "title": "通过动态双向重建实现灵活多模态输入的HER2表达预测", "title_en": "HER2 Expression Prediction with Flexible Multi-Modal Inputs via Dynamic Bidirectional Reconstruction", "authors": "Jie Qin,Wei Yang,Yan Su,Yiran Zhu,Weizhen Li,Yunyue Pan,Chengchang Pan,Honggang Qi", "background": "在乳腺癌HER2评估中，临床评估依赖于联合HE染色和免疫组化（IHC）图像，但获取这两种模态常常受到临床限制和成本的阻碍。因此，本文针对这一问题进行了研究，提出了一个适应性二模态预测框架，该框架能灵活支持单模或双模输入，并通过两个核心创新实现改进：动态分支选择器根据输入可用性激活模态补全或联合推断，以及跨模态生成对抗网络（CM-GAN）实现缺失模态的空间特征重建。这些创新提高了HE染色单独使用的准确率，实现了在完整双模态输入条件下的高准确性，并在单模态条件下保持了高可靠性。", "innovation": "该研究提出了一个适应性二模态预测框架，通过动态分支选择器和跨模态生成对抗网络（CM-GAN）实现模态补全或联合推断，以及缺失模态的空间特征重建，从而提高了HER2评估的准确性和可靠性，特别是在资源有限的地区提供了一种经济有效的解决方案，无需强制同步获取双模态数据。", "conclusion": "该框架在只有一种模态输入的情况下仍能保持90.28%的可靠性，而在完整双模态输入条件下达到了95.09%的准确性，同时在HE染色单独使用时准确率提高了22.81%（从71.44%提高到94.25%）。这种“偏好双模态，兼容单模态”的架构在无需强制同步获取双模态的情况下，能够接近双模态的准确性，大幅提高了HER2评估的可访问性，为资源有限的地区提供了解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22954", "html_url": "https://arxiv.org/abs/2507.22954", "title": "神经自回归建模脑老化", "title_en": "Neural Autoregressive Modeling of Brain Aging", "authors": "Ridvan Yesiloglu,Wei Peng,Md Tauhidul Islam,Ehsan Adeli", "background": "脑老化综合是一个在临床和计算神经科学中具有广泛应用的关键任务。能够从早期的MRI扫描预测一个受试者未来脑结构的演化，可以提供有关老化轨迹的重要见解。然而，高维数据、年龄结构的微妙变化及个体差异性的模式构成了脑老化的合成挑战。", "innovation": "我们提出了一种新颖的脑老化模拟模型——NeuroAR，基于生成自回归变压器。NeuroAR通过从以前和未来扫描的拼接token嵌入中自回归估计未来扫描的离散token映射来合成脑老化。在生成过程中，它在每个尺度上使用受试者的先前扫描及其采集年龄和目标年龄通过交叉注意力引导生成。此外，我们使用预训练的年龄预测器进一步验证合成图像与预期老化模式的一致性和真实感。实验表明，NeuroAR在图像保真度方面优于最先进的生成模型，包括潜在扩散模型(LDM)和生成对抗网络。", "conclusion": "NeuroAR显着优于关键模型，如LDM，表明其能够以高保真度建模个体脑老化轨迹。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23000", "html_url": "https://arxiv.org/abs/2507.23000", "title": "规划凉爽城市：通过城市景观转型预测和减轻城市热应力的多模态人工智能框架", "title_en": "Planning for Cooler Cities: A Multimodal AI Framework for Predicting and Mitigating Urban Heat Stress through Urban Landscape Transformation", "authors": "Shengao Yi,Xiaojiang Li,Wei Tu,Tianhong Zhao", "background": "随着气候变化和城市化的加剧，极端热事件的加剧给城市减轻户外热压力带来了日益严峻的挑战。现有的物理模型如SOLWEIG和ENVI-met虽然能够提供详细的热暴露评估，但计算需求限制了其在城市范围规划中的可扩展性。因此，需要一种计算效率高且能够提供精细空间分辨率预测的新型工具来支持城市热环境的规划和适应措施。", "innovation": "本文提出了一种 multimodal deep learning framework——GSM-UTCI，用于预测城市中的平均全天Universal Thermal Climate Index (UTCI)，精度达到近乎物理水平，同时大幅降低了计算时间。GSM-UTCI通过融合地表形态、高分辨率土地覆盖数据以及实时气象数据来提供精细化的空间热环境预测，特别适用于大规模城市的热环境管理。此外，通过对情景模拟证明其规划相关性，为制定基于气候适应的大规模绿化策略提供了有力支持。", "conclusion": "研究结果表明，GSM-UTCI适用于支持多层次的城市气候适应决策，通过模拟绿化策略对城市热环境的改善效果明显，有助于城市规划者选择最有效、最可行的热管理措施以提高城市热环境的可持续性和宜居性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22959", "html_url": "https://arxiv.org/abs/2507.22959", "title": "科莫戈罗夫-阿诺德网络在科学机器学习中的应用", "title_en": "Scientific Machine Learning with Kolmogorov-Arnold Networks", "authors": "Salah A. Faroughi,Farinaz Mostajeran,Amin Hamed Mashhadzadeh,Shirko Faroughi", "background": "科学机器学习领域最初利用多层感知机（MLPs），但MLPs存在解释性差、固定激活函数以及难以捕捉局部或高频特征等问题。科莫戈罗夫-阿诺德网络（KANs）通过增强的解释性和灵活性解决了这些问题，使更有效地建模复杂的非线性交互成为可能，从而克服了传统MLP架构的限制。本文从三个不同的视角回顾了基于KAN的模型的最新进展：数据驱动的学习、物理感知建模和深度算子学习。每个视角都从架构设计、训练策略、应用效果和与基于MLP的同类型模型的比较评估等方面进行了分析。研究表明，KANs 在准确度、收敛性和频谱表示方面均有持续改善，使其在捕捉复杂动态方面表现出更高的学习效率。", "innovation": "KANs 提供了改进的解释性和灵活性，解决了MLPs的局限性，特别是对于复杂非线性交互的建模更有效，并且KANs在准确度、收敛性和频谱表示方面持续表现出优于MLPs的性能。", "conclusion": "本文指出了KAN开发中关键的挑战和开放的研究问题，包括计算效率、理论保证、超参数调整和算法复杂性。同时提出未来研究方向，旨在提高基于KAN框架的鲁棒性、可扩展性和物理一致性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22956", "html_url": "https://arxiv.org/abs/2507.22956", "title": "基于 keystrokes 的韩语 LLM 辅助作弊检测", "title_en": "LLM-Assisted Cheating Detection in Korean Language via Keystrokes", "authors": "Dong Hyun Roh,Rajesh Kumar,An Ngo", "background": "先前的研究在语言覆盖、认知背景和LLM参与程度的粒度方面存在关键不足，本文提出了一种基于 keystroke 的框架，用于检测 LLM 辅助的作弊现象，特别是在韩语中的应用。", "innovation": "提出了一种基于 keystroke 的作弊检测框架，涵盖了 69 名参与者在不同条件下的写作任务，提取可解释的时间和节奏特征，并在认知敏感和非敏感环境中评估多个分类器的性能。此外，实验发现 LL defense 模型在检测真实和转录的回答方面优于人类评估者。", "conclusion": " keystroke 动态性在不同认知需求和写作策略下，有助于可靠地检测 LLM 辅助的写作。对于转述和转录 LLM 生成的响应，keystroke 框架比人类评估者更能有效地识别作弊行为。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23043", "html_url": "https://arxiv.org/abs/2507.23043", "title": "使用CatBoost在首次ICU住院期间预测万古霉素相关显著血清肌酐升高：一项回顾性研究", "title_en": "Prediction of Significant Creatinine Elevation in First ICU Stays with Vancomycin Use: A retrospective study through Catboost", "authors": "Junyi Fan,Li Sun,Shuheng Chen,Yong Si,Minoo Ahmadi,Greg Placencia,Elham Pishgar,Kamiar Alaei,Maryam Pishgar", "background": "万古霉素是ICU中严重革兰氏阳性菌感染的关键抗生素，但具有高肾毒性风险。ICU患者早期肾损伤预测具有挑战性。本研究旨在开发一个机器学习模型，使用常规ICU数据预测万古霉素引起的血清肌酐升高。\n", "innovation": "研究采用CatBoost算法，并基于Phosphate, Total Bilirubin, Magnesium, Charlson指数和APOTEⅢ等关键预测因子，通过SelectKBest和Random Forest排名方法选择特征，使用Shapley值、Accumulated Local Effects和贝叶斯后验采样等方法进行可解释性评估。\n", "conclusion": "本机器学习模型能够准确预测万古霉素引起的血清肌酐升高，并具有强解释性，有助于早期风险检测并支持ICU中的及时干预。\n"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23009", "html_url": "https://arxiv.org/abs/2507.23009", "title": "停止使用人类测试评估AI，开发基于原则的AI特定测试替代", "title_en": "Stop Evaluating AI with Human Tests, Develop Principled, AI-specific Tests instead", "authors": "Tom Sühr,Florian E. Dorner,Olawale Salaudeen,Augustin Kelava,Samira Samadi", "background": "大型语言模型（LLMs）在标准化测试中取得了显著成果，这些测试原本是用来评估人类认知和心理特质的，如智能和个性。然而，这种结果往往被解读为证明LLMs具备类似人类的特征。本文认为这种解读存在本体论上的错误，认为人类心理和教育测试是基于理论的测量工具，针对特定人群进行校准。因此，将这些测试应用于非人类主体而没有实证验证，可能会导致对被测试内容的错误解读。此外，一种趋势是用AI在基准测试上的表现来衡量类似“智能”的特质，但这些基准测试存在有效性问题、数据污染、文化偏见和表面提示变化的敏感性等已知问题。这种未经充分论证和解释的解读缺乏足够的理论和实证依据，因此需要建议停止使用人类测试来评估AI。", "innovation": "文章提出了一个新的视角，认为应该停止使用传统的人类测试来评估AI，而是开发基于原则的、专门针对AI系统的测试体系。这种新的评估框架可能会在现有的心理测量学框架基础上进行开发，或者从零开始为AI专门构建新的评估体系，以适应AI的独特环境和特性。创新之处在于转变了评估AI的新思路，强调了理论和实证的重要性，为AI评估领域引入了新的方向和方法。", "conclusion": "本文建议停止用人类测试来评估AI，强调了建立专门针对AI的评估框架的重要性，旨在为AI领域提供一种面向未来的理论和实践支持。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23073", "html_url": "https://arxiv.org/abs/2507.23073", "title": "本地差异隐私阈值多臂赌博机", "title_en": "Locally Differentially Private Thresholding Bandits", "authors": "Annalisa Barbara,Joseph Lazzaro,Ciara Pike-Burke", "background": "该研究表明在阈值多臂赌博机制中的本地差异隐私保护的影响。考虑了固定预算和固定置信度两种场景。", "innovation": "本文提出了一种方法，利用通过基于伯努利的差异隐私机制获得的私人响应，来识别预期奖励超过预设阈值的臂。同时，提出了理论性能边界，并展示了所提出的算法能够匹配给出的下界（除掉对数因子），这为保护隐私的决策机制提供了有价值的见解，尤其是在多臂赌博问题中。", "conclusion": "研究结果表明，该方法提供了强大的隐私保证，并且在拟合上下界方面有着良好的性能表现。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22962", "html_url": "https://arxiv.org/abs/2507.22962", "title": "农业特征-时间解释的多灾害预警系统", "title_en": "Multi-Hazard Early Warning Systems for Agriculture with Featural-Temporal Explanations", "authors": "Boyuan Zheng,Victor W. Chu", "background": "气候变化使得农业面临的气候极端风险不断增加，传统的单一灾害预警系统无法有效捕捉多个同时发生的气候事件间的复杂互动。因此，需要一种能够持续学习近期气候行为的可靠多灾害早期预警系统（EWS）来应对这一挑战。然而，传统的单一灾害预报方法在捕捉这些复杂互动方面效果不佳。为解决这一问题，本文提出了一种结合顺序深度学习模型和先进可解释人工智能技术的多灾害预报框架，用于农业预警，旨在增强预警系统的预测能力和解释性，以支持更精细和主动的风险管理决策。该研究使用美国四个主要农业地区的气象数据（2010年至2023年）来验证该框架在多重灾害（极端寒冷、洪水、霜冻、雹灾、热浪和强降雨）预测中的准确性，每地区采用特定模型。试验结果表明，框架的预测准确性较强，特别是BiLSTM架构，并体现了系统的潜在应用价值，特别强调了通过整合注意力机制与时序SHAP，提供详尽的时间解释揭示灾害事件发生的具体时间，增强了预警系统的解释性与应用性，特别是在农业气候风险管理中的交叉学科信任和有效决策过程方面做出了显著贡献。", "innovation": "本文创新地提出了一种结合顺序深度学习模型和先进可解释人工智能技术（XAI）的多灾害早期预警框架，特别采用了BiLSTM架构，用于农业领域的气候风险预警。该框架还首次积极探索了将注意力机制与时序SHAP(timeSHAP)相结合，提供详细的特征-时间解释，以此展示不同气候特征影响灾害发生的具体时间，不仅提高了系统的预测准确性，还增强了预警系统的信息透明度和解释性，有效促进了跨学科的信任和决策制定，特别是针对农业行业中的气候风险管理。", "conclusion": "本研究强调了采用序列深度学习方法和 XAI 技术构建的多灾害预警系统的效能与可靠性，尤其是在农业气候风险管理中具有重大意义。该框架不仅提高了预测的准确性，还能提供详尽的时间解释，为管理层提供了精确的风险管理策略。这项研究对未来研究和实际应用具有重要的推动作用，有助于增强多灾害预警系统的跨学科功能，从而支持更有效的气候风险决策。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23035", "html_url": "https://arxiv.org/abs/2507.23035", "title": "KLLM: 快速K-Means量化的大语言模型推理", "title_en": "KLLM: Fast LLM Inference with K-Means Quantization", "authors": "Xueying Wu,Baijun Zhou,Zhihui Gao,Yuzhe Fu,Qilin Zheng,Yintao He,Hai Li", "background": "大语言模型（LLM）的推理因内存和计算需求密集而面临重大挑战。现有的权重和激活量化（WAQ）设计通过减少内存占用和算术复杂度提供了潜在的解决方案。然而，传统WAQ设计依赖于均匀的整数量化以实现硬件效率，但在低精度下会导致显著的精度下降。K-Means量化作为一种非均匀量化技术，通过匹配LLM中权重和激活的高斯分布提高了精度。然而，由于其非均匀特性，K-Means量化难以在低精度计算单元上直接执行，因此在推理过程中需要去量化和浮点矩阵乘法（MatMuls）。此外，激活的异常值进一步阻碍了有效低精度WAQ的应用。离线阈值检测方法可能导致模型性能显著下降，而现有的在线检测技术则增加了较大的运行时开销。", "innovation": "本文提出了一种硬件和软件协同设计框架——KLLM，用于大语言模型的快速推理。KLLM具备基于索引的计算方案以高效执行K-Means量化数据上的矩阵乘法和非线性操作，避免了大部分去量化和全精度计算。此外，KLLM包含一种新颖的在线异常值检测引擎Orizuru，在在线推理过程中高效识别激活数据流中的前k大和前k小元素。实验结果显示，KLLM在与A100 GPU和Atom相比时平均分别实现了9.67x的速度提升和229.50x的能量效率改善.", "conclusion": "KLLM通过索引计算方案和在线异常值检测有效地解决了现有的K-Means量化方案的计算复杂性和检测开销问题，充分释放了K-Means量化在大语言模型推理中的潜在价值，展示了显著的性能改进。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23010", "html_url": "https://arxiv.org/abs/2507.23010", "title": "基于优化方法的多模态潜在空间可逆性研究：局限性", "title_en": "Investigating the Invertibility of Multimodal Latent Spaces: Limitations of Optimization-Based Methods", "authors": "Siwoo Park", "background": "本文研究了特定任务的人工智能（AI）模型在多模态潜在空间中的逆向能力及其更广泛的用途。这些模型在设计的任务上表现出色，例如文本到图像生成和音频到文本转录，但它们在逆向映射方面的潜力尚未得到充分探索。本文提出了一种基于优化的框架，用于从期望的输出推断输入特征，并将其应用于文本-图像（BLIP，Flux.1-dev）和文本-音频（Whisper-Large-V3，Chatterbox-TTS）两个模态。研究表明，在优化引导模型执行逆向任务的同时，它们的多模态潜在空间并不能持续支持语义上和感知上一致的逆向映射。实验结果一致证实了这一观点。尽管优化可以引导模型产生与目标一致的输出（例如，一个文本到图像的模型生成一个图像，而该图像能够被描述正确，或者ASR模型能够准确地转录优化后的音频），但这些逆向转换的质量往往是混乱且不合理的。此外，在试图从生成模型推断原始语义输入时，重构的潜在空间嵌入经常缺乏语义可解释性，与无意义的词汇标记相一致。这些发现凸显了一个重要的限制：主要为特定前向任务优化的多模态潜在空间，并不自然具有进行稳健且可解释的逆向映射所需的结构。因此，本研究强调了对开发真正语义丰富且可逆的多模态潜在空间的进一步研究需求。", "innovation": "本文创新性地提出了一种基于优化的框架，用于从期望的输出反向推断输入特征，并将其应用于文本-图像和文本-音频两个模态领域。通过实验证明，优化虽然可以引导模型产生与目标一致的输出，但这些逆向转换的质量往往是混乱且不合理的，且在尝试从生成模型推断原始语义输入时，重构的潜在空间嵌入经常缺乏语义可解释性。", "conclusion": "本文的研究结果揭示了多模态潜在空间的主要局限性，即主要为特定前向任务优化的多模态潜在空间，并不自然具有进行稳健且可解释的逆向映射所需的结构。因此，需要进一步研究以开发真正语义丰富且可逆的多模态潜在空间。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23136", "html_url": "https://arxiv.org/abs/2507.23136", "title": "观察多样性", "title_en": "Observational Multiplicity", "authors": "Erin George,Deanna Needell,Berk Ustun", "background": "许多预测任务可以使用几乎同样性能的多个模型。在某些情况下，这些相互竞争的模型可能会对同一个体做出冲突的预测，这会降低模型的可解释性和安全性。本文研究了这种冲突在概率分类任务中作为一种现象——观察多样性的影响。", "innovation": "提出了通过‘遗憾’来评估个体概率预测的任意性；设计了测量概率分类任务中遗憾的指标；提供了一种通用方法来估算概率分类任务中的遗憾；通过遗憾来展示在某些数据集中的特定群体上遗憾更高，并讨论了遗憾的应用；通过评估遗憾促进实际应用中的安全性，比如采用拒绝策略和数据收集。", "conclusion": "该研究通过衡量遗憾揭示了不同训练标签如何影响概率预测变化，展示了算法的任意性在不同群体中的差异，并提供了实现在实际应用中提高安全性的方法，包括拒绝某些预测和收集更多数据。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23037", "html_url": "https://arxiv.org/abs/2507.23037", "title": "时间序列数据中行为与流程性能联系的建模", "title_en": "Linking Actor Behavior to Process Performance Over Time", "authors": "Aurélie Leribaux,Rafael Oyamada,Johannes De Smedt,Zahra Dasht Bozorgi,Artem Polyvyanyy,Jochen De Weerdt", "background": "理解行为如何影响过程结果是过程挖掘的关键方面。传统方法通常使用汇总和静态过程数据，忽略了因个体行为产生的时间和因果动态。这限制了准确捕捉实际过程复杂性的能力，因为个体行为和行为之间的互动显著影响了性能。该研究通过结合行为分析和Granger因果关系，填补了时间序列数据分析方面的空白，应用此方法到实际事件日志，构建了个体互动的时间序列数据，如继续、中断和移交，以及流程结果。这些行为直接且可度量地影响了过程性能，特别是持续时间。", "innovation": "通过将行为分析与Granger因果关系结合起来，识别时间序列数据中的相关联系，利用Group Lasso进行滞后选择，发现了少量但始终有影响力的滞后，这些滞后捕捉了大部分因果影响。这种方法能够更准确地揭示时间依赖性，从而驱动过程结果，提供了对个体行为如何影响整体过程效率的更深入理解。", "conclusion": "这种方法展示了以行为为中心的时间序列方法在揭示驱动过程结果的时间依赖性方面的潜力，提供了更细致的理解，揭示了个体行为如何影响总体过程效率。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23115", "html_url": "https://arxiv.org/abs/2507.23115", "title": "FLOSS: 在支持退出和容错节点的联邦学习系统", "title_en": "FLOSS: Federated Learning with Opt-Out and Straggler Support", "authors": "David J Goetze,Dahlia J Felten,Jeannie R Albrecht,Rohit Bhattacharya", "background": "以往关于联邦学习系统中数据隐私的工作主要关注能够同意共享数据参与训练的用户的隐私保护操作。然而，现代数据隐私协议赋予用户在需要时选择不共享数据的权利。这种用户退出选择与由于设备异构性导致的节点延迟相结合，会导致来自多种来源的缺失数据，从而引入偏差并降低模型性能。", "innovation": "本文提出了一种名为FLOSS的系统，该系统旨在减轻在存在延迟节点和用户退出的情况下联邦学习中的缺失数据影响，并通过仿真实验展示了其性能。", "conclusion": "实验结果证明了FLOSS在面对用户退出和延迟节点时的有效性能，该系统能够减轻由于缺失数据带来的负面影响，改善了模型性能。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23077", "html_url": "https://arxiv.org/abs/2507.23077", "title": "材料断裂预测的基础模型", "title_en": "A Foundation Model for Material Fracture Prediction", "authors": "Agnese Marcato,Aleksandra Pachalieva,Ryley G. Hill,Kai Gao,Xiaoyu Wang,Esteban Rougier,Zhou Lei,Vinamra Agrawal,Janel Chua,Qinjun Kang,Jeffrey D. Hyman,Abigail Hunter,Nathan DeBardeleben,Earl Lawrence,Hari Viswanathan,Daniel O'Malley,Javier E. Santos", "background": "准确预测材料何时及如何失效对于设计在应力下运行的安全、可靠的结构、机械系统和工程组件至关重要。然而，实际应用中的材料多样性、几何形状和加载条件使得断裂行为难以建模。虽然机器学习方法有希望，但大多数模型仅限于窄数据集，缺乏鲁棒性，难以泛化。另一方面，基于物理的模拟器提供高度准确的预测，但这些模拟器分散在专门的方法中，需要大量的高性能计算资源来探索输入空间。", "innovation": "为解决这些限制问题，本文提出了一个数据驱动的断裂预测基础模型，这是一种基于变压器的架构，可以在模拟器、广泛材料（包括塑料装药、钢、铝、页岩和钨）和各种加载条件下进行操作。该模型支持结构化和非结构化网格，将这些网格与文本输入脚本的大语言模型嵌入材料属性、边界条件和求解设置结合。这种多模输入设计能够灵活适应不同模拟场景而无需修改模型架构。训练的模型可以用少量数据进行微调，应用于不同的下游任务，如预测失效时间、模拟断裂演变和适应结合了有限离散元方法的模拟。此外，该模型还能泛化到未见过的材料如钛和混凝土，仅需使用一个样本即可，与标准机器学习相比大大减少了数据需求。结果表明，断裂预测可以在单一模型架构下统一，提供了一个可扩展且可扩展的替代基于模拟器的工作流程", "conclusion": "我们的研究结果表明，断裂预测可以通过单一模型架构实现统一，提供了与基于模拟器的工作流程相比更具扩展性和可扩展性的替代方案。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23128", "html_url": "https://arxiv.org/abs/2507.23128", "title": "评估和提高噪声和分布偏移对语音命令识别模型的鲁棒性", "title_en": "Evaluating and Improving the Robustness of Speech Command Recognition Models to Noise and Distribution Shifts", "authors": "Anaïs Baranger,Lucas Maison", "background": "尽管计算机视觉领域的先前研究已经证明了内部分布（ID）和外部分布（OOD）准确性的强相关性，但在基于音频的模型中，这类关系尚未得到充分研究。这项研究旨在探讨训练条件和输入特征如何影响语音关键词分类器在OOD条件下的鲁棒性和泛化能力。我们对多种神经架构进行了基准测试，涵盖了各种评估集。为了定量评估噪声对泛化的影响，我们使用了两项指标：公平性（F），衡量与基线模型相比的整体准确性提升；鲁棒性（R），评估ID和OOD性能之间的收敛性。结果显示，噪声感知训练在某些配置中提高了鲁棒性，这为语音模型中基于噪声的数据增强的优缺点提供了新的见解。", "innovation": "研究通过评估多种神经架构在不同评价集的表现，首次在音频模型中探讨了噪声感知训练对鲁棒性和泛化能力的影响，提出了利用公平性和鲁棒性指标来准确定量噪声对模型泛化影响的新方法，为进一步理解语音模型在噪声和样本分布变化条件下的鲁棒性提供科学依据和理论指导.", "conclusion": "研究结果表明，噪声感知训练在某些配置中提高了语音关键词分类器的鲁棒性。这些发现为基于噪声的数据增强在语音模型中的应用提供了新的视角，揭示了其在推广到未知条件下带来的益处和限制。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22963", "html_url": "https://arxiv.org/abs/2507.22963", "title": "FedCVD++: 通信高效的联邦学习在心血管疾病风险预测中的应用，其优化包括参数模型和非参数模型", "title_en": "FedCVD++: Communication-Efficient Federated Learning for Cardiovascular Risk Prediction with Parametric and Non-Parametric Model Optimization", "authors": "Abdelrhman Gaber,Hassan Abd-Eltawab,John Elgallab,Youssif Abuzied,Dineo Mpanya,Turgay Celik,Swarun Kumar,Tamer ElBatt", "background": "心血管疾病(CVD)导致全球每年超过1700万人死亡，凸显了迫切需要隐私保护的预测系统。本文介绍了一种名为FedCVD++的增强型联邦学习(FL)框架，用于冠心病风险预测。该框架结合了参数模型（逻辑回归、SVM、神经网络）和非参数模型（随机森林、XGBoost），以应对现有的FL挑战，实现更有效的心血管疾病风险预测。", "innovation": "FedCVD++ 提出了以下创新点：(1) 树子集采样，可将随机森林的通信开销减少70%；(2) 基于XGBoost的功能提取，实现轻量级的联邦集成；(3) 联邦SMOTE同步，解决机构间的类别不平衡问题。此外，通信高效策略可减少通信开销3.2倍，同时保持95%的准确率。与现有FL框架相比，该框架在多机构部署时能提供更高的F1评分（最高提升15%）和更好的可扩展性。", "conclusion": "在这项工作中首次实现了非参数模型在联邦医疗保健系统中的实际整合，提供了一个在实际临床约束下得到验证的隐私保护解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23141", "html_url": "https://arxiv.org/abs/2507.23141", "title": "人工智能求解微分方程的范式：基于第一原理的数据生成和尺度扩张算子人工智能求解器", "title_en": "AI paradigm for solving differential equations: first-principles data generation and scale-dilation operator AI solver", "authors": "Xiangshu Gong,Zhiqiang Xie,Xiaowei Jin,Chen Wang,Yanling Qu,Wangmeng Zuo,Hui Li", "background": "许多问题由微分方程式（DEs）来描述。人工智能（AI）是一种新的解微分方程的方法。然而，用于训练的数据非常稀缺，现有的AI求解器难以逼近高频成分（AHFC）。背景描述了传统方法的局限性和迫切需要更有效的方法来解决此类问题。问题主要集中在如何有效的生成训练数据和解决高频成分问题上，因此通过第一原理生成数据和引入尺度扩张算子（SDO）AI求解器成为研究的重点。利用已有的知识或随机场来生成满足DEs的解决方案，并从中推导出源，初始或边界条件，最终可以以极低的计算成本生成大量的一致性训练数据。", "innovation": "提出的AI范式包括DEs规则下的第一原理数据生成方法和尺度扩张算子（SDO）AI求解器。通过引入的可逆尺度扩张算子，利用多尺度解的傅里叶变换来固定高频成分问题。同时，设计了一种时空耦合、基于注意力的Transformer AI求解器，结合了尺度扩张算子，证明了损失函数海森矩阵条件数的上限与解梯度的2-范数的平方成正比，揭示了尺度扩张算子可以使损失景观更加平滑，从而通过高效的训练来解决高频成分问题。该方法经过广泛的测试，展示了其在各种DEs问题上的一致优势，比现有最先进的方法更准确。", "conclusion": "这项工作使微分方程的人工智能求解器能够真正应用于广泛的自然和工程领域。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23170", "html_url": "https://arxiv.org/abs/2507.23170", "title": "BAR Conjecture：受限推理预算同时保证真实性和推理能力的LLM服务可行性", "title_en": "BAR Conjecture: the Feasibility of Inference Budget-Constrained LLM Services with Authenticity and Reasoning", "authors": "Jinan Zhou,Rajat Ghosh,Vaishnavi Bhargava,Debojyoti Dutta,Aryan Singhal", "background": "在设计LLM服务时，从业者主要关注三个关键属性：推理时预算、事实真实性、以及推理能力。然而，分析显示，没有任何模型能够同时优化这三个属性。", "innovation": "提出了一个正式论文证明这种权衡，并提出了一种名为The BAR Theorem的原理性框架，用于LLM应用程序设计。", "conclusion": "没有任何模型能够同时优化推理时预算、事实真实性以及推理能力这三个属性。论文提出了The BAR Theorem框架来解决这一问题，从而指导LLM应用设计。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23111", "html_url": "https://arxiv.org/abs/2507.23111", "title": "可扩展的加权图生成建模", "title_en": "Scalable Generative Modeling of Weighted Graphs", "authors": "Richard Williams,Eric Nalisnick,Andrew Holbrook", "background": "加权图在生物学、化学和社会科学中广泛存在，驱动了使用深度神经网络开发生成加权抽象图数据的模型的需求。现有的大多数深度生成模型设计用于无权重图，难以扩展到加权拓扑，或者没有考虑边权重与拓扑的联合分布。生成加权图的概率分布必须考虑边及其权重之间复杂的非局部依赖关系。现有模型要么过于复杂导致难以扩展，要么未能准确捕捉图的概率分布，对于大图效率低下，缺乏高效性和可扩展性。研究一种新的生成模型是迫切需要的，该模型能够高效生成具有复杂边权重依赖性的真实加权图数据。", "innovation": "本文开发了一种自回归模型 BiGG-E，它是 BiGG 模型的一个非平凡扩展。BiGG-E 能够学习加权图上的联合概率分布，同时利用稀疏性，以 O((n + m)log n) 时间生成一个 n 节点 m 条边的加权图。BiGG-E 能够更好地捕捉加权图的概率分布，具有可扩展性和计算效率。该模型通过模拟研究和多种基准数据集实验，展示了其在生成加权图数据方面的优越性，解决了现有模型未能解决的问题。", "conclusion": "通过引入 BiGG-E，研究证明了一种能够高效学习加权图概率分布的方法，该方法兼顾了稀疏结构和计算效率。实验表明 BiGG-E 不仅能捕捉复杂权重依赖的图数据分布，还能保持模型的高效性和可扩展性，具有广泛的应用前景。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23093", "html_url": "https://arxiv.org/abs/2507.23093", "title": "在边缘端的AI推断持续性的研究", "title_en": "On the Sustainability of AI Inferences in the Edge", "authors": "Ghazal Sobhani,Md. Monzurul Amin Ifath,Tushar Sharma,Israat Haque", "background": "物联网(IoT)和其尖端的AI驱动应用（如自动驾驶车辆和智能工业）结合了数据驱动系统及其边缘部署。边缘设备通常用来支持低延迟应用进行推理。然而，这些资源受限的边缘设备的性能及其能源消耗是应用边缘AI的关键因素。本文提到的具体设备包括Raspberry Pi (RPi)、Intel Neural Compute Stick (INCS)、NVIDIA Jetson nano (NJn)、Google Coral USB (GCU)等，它们在边缘部署AI推断中被广泛采用，但鲜有关于它们性能和能源使用的研究为设备和模型的选择提供依据。", "innovation": "本文通过详尽地对上述边缘设备上的传统模型、神经网络模型和大型语言模型进行性能研究，分析了模型F1分数、推理时间、推理电力消耗和内存使用之间的权衡，并通过硬件和框架优化及外部参数调整AI模型，实现在模型性能和资源使用之间的平衡，以实现实用的边缘AI部署。", "conclusion": "本文填补了现有研究的空白，详细研究了边缘设备上的性能特征，并通过优化措施平衡了模型性能与资源使用，确保在实际应用中能够支持边缘AI部署的需求。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23291", "html_url": "https://arxiv.org/abs/2507.23291", "title": "在深度学习中评估成员隐私动态变化", "title_en": "Evaluating the Dynamics of Membership Privacy in Deep Learning", "authors": "Yuetian Chen,Zhiqi Wang,Nathalie Baracaldo,Swanand Ravindra Kadhe,Lei Yu", "background": "在深度学习中，会员推断攻击（MIAs）严重威胁到了训练数据的隐私安全。尽管在攻击方法上取得了重大进展，但对模型在训练过程中如何编码会员信息的时间和方式的理解仍然有限。", "innovation": "本论文提出了一个动态分析框架，用于拆分和量化个体样本层面的隐私泄露动态。通过在整个训练过程中跟踪每个样本的漏洞在FPR-TPR平面的变化，该框架系统性地度量了诸如数据集复杂度、模型结构和优化器选择等因素如何影响样本成为漏洞的时间和严重性。研究发现，样本的固有学习难度与其在最终训练模型中的隐私风险之间存在稳健的关联，并发现高度易受攻击的样本的隐私风险大多在训练早期确定。", "conclusion": "本研究为理解隐私风险如何在训练过程中动态生成提供了更深入的认识，为进一步开发主动的、具有隐私意识的模型训练策略奠定了基础。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23186", "html_url": "https://arxiv.org/abs/2507.23186", "title": "NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box Computational Functions", "title_en": "NaN-Propagation: A Novel Method for Sparsity Detection in Black-Box Computational Functions", "authors": "Peter Sharpe", "background": "现有的基于有限差分的方法在检测黑箱函数中的稀疏性时存在误报问题，即会将并非真的为零的梯度认为是零，这会导致梯度计算结果出错，影响优化流程的结果。", "innovation": "该研究引入了NaN-propagation，利用IEEE 754标准中Not-a-Number（NaN）浮点值的污染特性，通过在输入中系统性地注入NaN来追踪输入输出之间的依赖关系，重构保守的稀疏模式，从而消除误报。此外，还提出了Nano编码等高级策略，进一步提高效率，克服了许多工程应用中的分支代码执行带来的挑战。", "conclusion": "该技术利用IEEE 754标准的兼容性，可以在多种编程语言和数学库中应用，而无需修改现有的黑箱代码。研究还在航空翼重模型上进行了实验，实现了1.52倍的加速，并成功检测出了常规方法未能识别的数十个依赖关系。这表明结合NaN传播的技术在黑箱函数稀疏性检测上有着显著的改进。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23257", "html_url": "https://arxiv.org/abs/2507.23257", "title": "通过影响近似实现高效机器遗忘", "title_en": "Efficient Machine Unlearning via Influence Approximation", "authors": "Jiawei Liu,Chenwang Wu,Defu Lian,Enhong Chen", "background": "由于隐私问题日益引起关注，使得机器学习模型能够“忘记”特定训练数据的机器卸载变得越来越重要。现有方法中，基于影响的卸载因其能够估计单个训练样本对模型参数的影响而受到广泛关注，但这种方法因为计算海森矩阵及其逆矩阵的庞大计算开销，在大规模模型和频繁数据删除请求场景下显得不切实际。", "innovation": "本文基于认知科学，将遗忘（卸载）与记忆（增量学习）联系起来，引入了近似影响卸载（IAU）算法，从增量学习的角度高效地实现了机器卸载。IAU相比卸载过程中的耗时海森矩阵计算，依赖更高效的梯度优化，从而提供了认知理论的支持。IAU在去除保证、卸载效率和模型效用方面都优于现有的先进方法，适用于多种数据集和模型架构。", "conclusion": "大量的实验评估表明，IAU在保持较好的去除保证的同时，提高了卸载效率，并且具有类似甚至更好的模型效用，优于最新的卸载算法。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23154", "html_url": "https://arxiv.org/abs/2507.23154", "title": "FuseTen：一种基于时空卫星观测的每日10米地表温度生成模型", "title_en": "FuseTen: A Generative Model for Daily 10 m Land Surface Temperature Estimation from Spatio-Temporal Satellite Observations", "authors": "Sofiane Bouaziz,Adel Hafiane,Raphael Canals,Rachid Nedjai", "background": "城市热岛、干旱和土地退化是气候变化背景下亟待解决的问题。准确的土地表面时空信息对于研究这些现象至关重要。陆表温度（LST）是评估和理解这些现象的关键变量之一，通过卫星数据可以获得地球表面热状态的重要信息。然而，卫星平台在空间分辨率和时间分辨率之间存在固有的权衡。为解决这一问题，我们提出了一种名为FuseTen的新颖生成框架，通过融合Sentinel-2、Landsat 8和Terra MODIS的时空观测数据，生成每日10米空间分辨率的LST观测数据。实验结果显示，FuseTen在定量指标和视觉保真度方面分别提高了32.06%和31.42%，超过线性基线模型。", "innovation": "FuseTen采用了一种基于物理原则的平均监督策略进行生成架构训练，并在融合过程中引入了注意力机制和标准化模块。此外，通过使用PatchGAN判别器来确保生成数据的真实性和一致性。这是首次使用非线性方法生成高精度（10米空间分辨率）的地表温度估算数据。", "conclusion": "实验结果表明，FuseTen在多个日期上均优于线性基线模型，在定量指标和视觉保真度上分别提高了约32.06%和31.42%。这是第一种非线性方法，能够生成如此高精度的每日地表温度估计数据。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23261", "html_url": "https://arxiv.org/abs/2507.23261", "title": "DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System", "title_en": "DynaSwarm: Dynamically Graph Structure Selection for LLM-based Multi-agent System", "authors": "Hui Yi Leong,Yuqing Wu", "background": "当前的多智能体系统（MAS）框架通常依赖于手动设计且静态的图结构，这限制了系统的适应性和性能。这些静态结构难以适应动态环境的需求，也难以利用更有效的图结构来优化系统的协作表现。", "innovation": "我们提出了DynaSwarm，这是一种动态框架，通过两种关键创新来增强基于LLM的MAS：(1) 采用演员-评论家强化学习机制（A2C），优化图结构，并且相比之前的RL方法提高了稳定性；(2) 动态图选择器通过参数有效的LLM微调来选择每个输入样本的最佳图结构。该框架通过利用样本特定的差异来动态路由查询，并应用特定的智能体网络，以替代固定且一刀切的图架构。此外，作者还提出了通过微调演示检索器来充分利用上下文学习的能力。这些创新使得DynaSwarm在多样化的LLM基线模型上表现出色，特别是在问答、数学推理和编程任务中，DynaSwarm能够稳定超越最新的单智能体和多智能体系统基准。", "conclusion": "我们的研究凸显了在LLM多智能体系统设计中，利用样本特定的结构灵活性的重要性。DynaSwarm通过动态图结构选择和高效参数微调展示了显著的性能提升，为未来的 MAS 设计提供了新的研究思路和技术实现。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23217", "html_url": "https://arxiv.org/abs/2507.23217", "title": "零样本文档理解使用伪目录指导检索增强生成", "title_en": "Zero-Shot Document Understanding using Pseudo Table of Contents-Guided Retrieval-Augmented Generation", "authors": "Hyeon Seong Jeong,Sangwoo Jo,Byeong Hyun Yoon,Yoonseok Heo,Haedong Jeong,Taehoon Kim", "background": "理解复杂的多模态文档仍然具有挑战性，因为这些文档存在结构不一致的问题，并且可用的训练数据有限。现有方法往往需要针对特定类型的文档进行专门的训练或使用复杂的模型，这增加了复杂性和限制了适用性。因此，需要一种无需额外训练且能够处理多种元素（如文本、图片、图表和表格）的系统来提高多模态理解的效率和准确性。", "innovation": "本文介绍了DocsRay，这是一种无需训练的文档理解系统，它将伪目录生成与层次检索增强生成（RAG）相结合。DocsRay利用多模态大语言模型（LLMs）的原生能力，通过提示驱动的LLM交互生成层次伪目录，并利用模型本身的特性将多样化的文档元素转换成统一的、以文本为中心的表示，同时采用高效的两阶段层次检索系统来减少检索复杂性。这种系统能够在不依赖于专门模型或大量训练数据的情况下，对包含多种元素的文档进行无缝处理。此外，该系统还通过利用伪目录指导检索和生成过程来提升效率。", "conclusion": "实验结果表明，通过对平均49.4页、20,971个文本标记的文档进行评估，DocsRay在查询延迟上从3.89秒降低到2.12秒，效率提高了45%。在MMLongBench-Doc基准测试中，DocsRay-Pro取得了64.7%的准确率，大幅超越了此前的最先进结果，展示了其在多模态文档理解方面的显著优势。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23221", "html_url": "https://arxiv.org/abs/2507.23221", "title": "单一真实的方向：观察模型的线性残差探针揭示并操控上下文幻觉", "title_en": "A Single Direction of Truth: An Observer Model's Linear Residual Probe Exposes and Steers Contextual Hallucinations", "authors": "Charles O'Neill,Slava Chalnev,Chi Chi Zhao,Max Kirkby,Mudith Jayasekara", "background": "在AI领域，情境幻觉——即模型生成未被给定情境支持的信息——依然是一个重要挑战。研究工作寻求提供一种生成器无关的观察模型，通过单一前向传播和对残差流的线性探针来检测幻觉。这种方法能够有效地隔离并区分幻觉文本与真实文本，并显示出在Gemma-2模型（2B至27B）中具有稳健的中间层性能。", "innovation": "该研究提出了一种观察模型，该模型基于单一前向传播和对残差流的线性探针来检测幻觉，无需特定的生成器。这种方法表现出优于基准的5-27分点的性能，并证明了在不同规模的Gemma-2模型中具有稳健的中间层性能。此外，通过分析梯度与激活的乘积，该方法可以定位幻觉信号到稀疏的、较深层的MLP活动中。关键发现是这一方向的操纵能够因果地改变生成器幻觉的频率，证明了其可操作性。", "conclusion": "研究结果提供了关于内部、低维度幻觉跟踪的新证据，这些跟踪与特定MLP子电路相关联，可以在检测和缓解幻觉方面加以利用。为现实评估这些问题，研究者还公开了一个包含2000个样例的ContraTales基准。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23412", "html_url": "https://arxiv.org/abs/2507.23412", "title": "利用矿物元素谱线的机器学习方法检测蜂蜜掺假", "title_en": "A Machine Learning Approach for Honey Adulteration Detection using Mineral Element Profiles", "authors": "Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh", "background": "蜂蜜掺假是一个严重的问题，现有的检测方法可能不够敏感或准确。本文旨在通过利用蜂蜜中矿物元素谱线开发一个基于机器学习(ML)的检测系统，以提高检测精度。", "innovation": "本文提出了一种新颖的方法，利用机器学习模型（逻辑回归、决策树和随机森林）来区分真蜂蜜和掺假蜂蜜。尤其指出，随机森林分类器在该数据集上表现最好，达到了98.37%的交叉验证准确率。", "conclusion": "实验结果表明，蜂蜜中的矿物元素含量提供了可靠的鉴别信息，用于检测蜂蜜掺假。随机森林分类器在该领域的表现最好，比其他分类器都更有效。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23391", "html_url": "https://arxiv.org/abs/2507.23391", "title": "无需奖励建模的大规模视觉-语言模型反馈用于策略学习", "title_en": "Policy Learning from Large Vision-Language Model Feedback without Reward Modeling", "authors": "Tung M. Luu,Donghoon Lee,Younghwan Lee,Chang D. Yoo", "background": "离线强化学习提供了一种通过预先收集的次优数据集训练机器人代理的强大框架，从而消除昂贵的、耗时的和潜在危险的在线交互的需要。这种方法在安全关键的实际应用中特别有用，因为在线数据收集既昂贵又不切实际。然而，现有的离线RL算法通常需要带有标签的奖励数据，这引入了另一个瓶颈：奖励函数的设计既昂贵又劳动密集，需要深厚的专业知识。", "innovation": "本文提出了一种名为PLARE的新颖方法，该方法利用大型视觉-语言模型（VLM）为代理训练提供指导信号，而不是依赖于人工设计的奖励函数。PLARE针对语言任务描述查询VLM，生成对机器人轨迹片段的偏好标签。代理直接从这些偏好标签进行训练，使用监督对比偏好学习目标，从而绕过了需要学习明确奖励模型的步骤。", "conclusion": "在MetaWorld的机器人操作任务上进行的大量实验表明，PLARE的性能与或超过了现有的基于VLM的奖励生成方法。此外，PLARE在物理机器人的真实世界操作任务中也显示出有效性，进一步验证了其实际应用的可行性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23335", "html_url": "https://arxiv.org/abs/2507.23335", "title": "深度学习模型中针对Top-k预测的可扩展且精确的补丁鲁棒性认证", "title_en": "Scalable and Precise Patch Robustness Certification for Deep Learning Models with Top-k Predictions", "authors": "Qilin Zhou,Haipeng Wang,Zhengyuan Wei,W.K. Chan", "background": "补丁鲁棒性认证是一种新兴的验证方法，用于防御对抗性补丁攻击，并为深度学习系统提供可证明保证。现有的认证恢复技术保证了认证样本唯一真实标签的预测，然而现有的技术在处理Top-k预测标签时，通常通过标签之间的两两比较来进行决策，但由于攻击者（即攻击预算）控制的投票数量会膨胀，导致无法精确地认证唯一真实标签；同时，对所有投票分配的组合进行枚举会引发组合爆炸问题。现有方法无法满足大规模数据集的高效验证需求", "innovation": "本文提出了CostCert，一种新颖、可扩展且精确的基于投票的认证恢复防御方法。CostCert通过一种新颖的设计验证样本在Top-k预测标签中的真实标签，无需两两比较和组合爆炸，并且通过证明攻击预算无法覆盖所提供额外最少总投票来排除真实标签。相较于现有最先进的防御方法PatchGuard，CostCert在补丁大小为96时，保留了高达57.3%的认证准确率，而PatchGuard的认证准确_rate已降至零", "conclusion": "实验表明，CostCert在现有最先进的防御方法PatchGuard的基础上，实现了显著的性能提升，在补丁大小为96的情况下，保留了高达57.3%的认证准确率，证明了该方法的有效性和可靠性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23317", "html_url": "https://arxiv.org/abs/2507.23317", "title": "Good Learners Think Their Thinking: Generative PRM Makes Large Reasoning Model More Efficient Math Learner", "title_en": "Good Learners Think Their Thinking: Generative PRM Makes Large Reasoning Model More Efficient Math Learner", "authors": "Tao He,Rongchuan Mu,Lizi Liao,Yixin Cao,Ming Liu,Bing Qin", "background": "大型推理模型（LRMs）通过强化学习（RL）优化后，在解决复杂数学问题上表现出潜力。然而，传统方法依赖于结果导向的奖励，这种奖励提供反馈较少，导致优化过程效率低下。当前研究旨在通过引入过程奖励模型（PRMs）来加速基于RL的训练过程，特别是探讨了一种在思维层面驱动生成的过程评估机制，以解决RL训练中的瓶颈问题。", "innovation": "- 引入了一种基于内在信号生成的进程评估机制，专注于在解决方案中的内在信号来判断每一步的正确性，并将连续的正确或错误步骤整合成连贯的‘思考’单元。\n- 发展了一种能力自适应奖励机制，以动态平衡探索和利用，根据LRM当前的熟练程度引导学习，而不抑制创造性实验。\n- 将这些创新整合进一种新的 off-policy RL 算法 TP-GRPO，该算法扩展了基于过程奖励的分组近似优化，并提高了训练效率。\n- 通过以太坊上的代码链接提供算法的实现。", "conclusion": "在1.5B和7B参数的LRM上进行的实验表明，该方法在比结果导向奖励基准少得多的训练样本下，实现了更高的问题解决准确率。结果验证了精心设计的进程奖励可以显著加速学习过程中LRM在数学推理任务中的优化。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23344", "html_url": "https://arxiv.org/abs/2507.23344", "title": "基于可微代理模拟的共享单车动态定价设计", "title_en": "Designing Dynamic Pricing for Bike-sharing Systems via Differentiable Agent-based Simulation", "authors": "Tatsuya Mitomi,Fumiyasu Makinoshima,Fumiya Makihara,Eigo Segawa", "background": "共享单车系统正在各类城市中涌现，作为一个新的环保交通系统。但由于用户需求在时间和空间上都有波动，这导致了自行车站点之间存在不平衡的库存问题，增加了额外的重新分配成本。为了有效地管理用户需求，需要通过最优动态定价策略进行系统管理。然而，这种系统的最优定价设计是有挑战性的，因为它涉及到具有不同背景的用户及其概率选择的复杂性。", "innovation": "为了应对这一问题，研究开发了一种可微代理模拟来快速设计共享单车系统的动态定价策略，以确保即使在时间和空间上的旅行需求不一致以及用户的概率决策下，也能实现库存平衡。与传统方法相比，该方法通过数值实验获得比传统方法更快的收敛速度，减少了73%到78%的损失，同时获得更准确的解决方案。此外，在大规模城市共享单车系统场景下（涉及289个自行车站点），验证了该方法的有效性，通过获得的定价策略模拟验证，确认这些策略能够自然地导致库存的平衡，无需手动重新分配。进一步的实验也表明，通过设置适当的初始条件，可以最小化折扣成本以实现平衡库存的目标。", "conclusion": "该研究提出了一种新的可微代理模拟方法来设计共享单车系统的动态价格，并验证了其在平衡自行车库存和提高定价策略收敛速度方面的有效性，同时提供了减少成本的方法。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23389", "html_url": "https://arxiv.org/abs/2507.23389", "title": "因果解释的概念漂移——一种真正具有行动性的方法", "title_en": "Causal Explanation of Concept Drift -- A Truly Actionable Approach", "authors": "David Komnick,Kathrin Lammers,Barbara Hammer,Valerie Vaquet,Fabian Hinder", "background": "在不断变化的世界中，了解变化如何影响不同的系统，如工业制造或关键基础设施至关重要。在机器学习领域，解释关键变化——称为概念漂移——是进行有针对性的干预以避免或纠正模型失败的第一步，以及物理世界中的故障和错误。因此，本文旨在扩展基于模型的概念漂移解释，转向因果解释，从而提高所提供解释的可用性。我们通过多个用例评估我们的解释策略，展示了我们框架的实际有用性，它隔离了受概念漂移影响的因果相关特征，从而允许有针对性的干预。", "innovation": "本文扩展了基于模型的概念漂移解释并转向因果解释，这有助于使解释更具行动性。通过这种策略，可以有效隔离受概念漂移影响的关键特征，从而支持更高效的干预措施。", "conclusion": "通过评估多个具体案例，本文展示了因果解释框架的实际应用价值，该框架能够明确指出受到概念漂移影响的相关因素，从而指导精确的干预，提高了模型和系统在变动环境下的稳定性和可靠性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23418", "html_url": "https://arxiv.org/abs/2507.23418", "title": "使用红外光谱和机器学习检测椰子奶掺假", "title_en": "Detection of Adulteration in Coconut Milk using Infrared Spectroscopy and Machine Learning", "authors": "Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh", "background": "该研究旨在通过使用红外光谱技术和机器学习方法检测椰子奶的掺假。背景主要包括使用紫外可见光谱和红外光谱技术在食品掺假检测中的应用以及机器学习在这一领域的贡献。", "innovation": "创新在于提出了一种新的自动检测椰子奶掺假的系统，该系统包括预处理、特征提取和分类三个阶段，利用线性判别分析（LDA）和K-近邻（KNN）算法实现了精准的分类，并且通过公共数据集验证了系统的有效性。", "conclusion": "最终结果表明，该检测系统能够通过交叉验证达到93.33%的准确率，有效识别出椰子奶的掺假情况。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23428", "html_url": "https://arxiv.org/abs/2507.23428", "title": "时空记忆与空间融合：时空状态空间神经算子", "title_en": "Merging Memory and Space: A Spatiotemporal State Space Neural Operator", "authors": "Nodens F. Koren,Samuel Lanthaler", "background": "论文提出了一种用于学习时间依赖偏微分方程（PDEs）解算子的时空状态空间神经算子（ST-SSM）。背景在于，现有的方法在处理这些复杂动态时通常缺乏参数效率和对长时间尺度空间时间动态的灵活建模能力。", "innovation": "ST-SSM通过引入空间和时间维度的新奇分解，并使用结构化的状态空间模型分别建模时间演化和空间交互，从而实现参数效率和对长时尺度空间时间动态的灵活建模。论文还建立了S-MM（状态空间模型）和神经算子之间的理论联系，并证明了该架构类别的统一的通用性定理。实验证明，这种因子化形式在多种PDE基准测试（如一维Burgers方程、一维Kuramoto-Sivashinsky方程和二维Navier-Stokes方程）上，尤其是在不同物理条件下，性能优于逐行扫描和并行独立处理等其他方案，同时使用了显著更少的参数。", "conclusion": "研究表明，维度分解的操作学习具有高效且通用的PDE建模优势，并且为这种方法奠定了坚实的理论基础。此外，结果表明了时间记忆在不完全观测条件下的优势，进一步证明了该方法的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23303", "html_url": "https://arxiv.org/abs/2507.23303", "title": "基于数据驱动的可解释无监督方法以防止遗漏物品", "title_en": "An Interpretable Data-Driven Unsupervised Approach for the Prevention of Forgotten Items", "authors": "Luca Corbucci,Javier Alejandro Borges Legrottaglie,Francesco Spinnato,Anna Monreale,Riccardo Guidotti", "background": "在 Next Basket Prediction (NBP) 领域中，准确识别超市购物中遗忘的商品，并提供清晰可解释的推荐理由仍然是一个未被充分探索的问题。现有的 NBP 方法主要集中在对未来购买行为的预测上，而没有明确定位无意中遗漏的商品。这一问题的部分原因是缺乏可靠的遗漏商品数据集。此外，大多数当前的 NBP 方法依赖于黑箱模型，这限制了对推荐的解释能力，影响了对最终用户的价值。", "innovation": "本文正式定义了遗忘商品预测任务，并提出了两种新型可解释的设计算法。这些方法旨在识别遗忘的商品并提供直观、易于理解的解释。实验结果表明，我们的算法在多个评估指标上比最先进的 NBP 基准高出 10-15%。", "conclusion": "本文提出了一种基于数据驱动的无监督方法，旨在防止遗漏购买。该方法通过提出两种新型可解释设计的算法，实现了对于遗忘商品的准确识别，并提供了易于理解的推荐理由。实验结果表明，该方法在多个评估指标上表现优于现有的 NBP 方法。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23292", "html_url": "https://arxiv.org/abs/2507.23292", "title": "SequenceLayers:使序列处理和流式神经网络变得轻松", "title_en": "SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy", "authors": "RJ Skerry-Ryan,Julian Salazar,Soroosh Mariooryad,David Kao,Daisy Stanton,Eric Battenberg,Matt Shannon,Ron J. Weiss,Robin Scheibler,Jonas Rothfuss,Tom Bagby", "background": "研究人员开发了一种神经网络层API和库，旨在简化序列模型的创建过程，这些模型可以分层执行（如教师强制训练）或逐步执行（如自回归采样）。这层设计需要明确表示其随时间变化的状态，并定义一个步骤方法来演变该状态，以确保具有相同的结果。", "innovation": "创新之处在于引入了SequenceLayers，它允许复杂的模型立即流式处理，并解决了广泛的常见错误。这种设计可以提供强大的正确性保证，并且可以在任何深度学习库中实现。通过一个组合和声明式的API以及全面的层和组合器套件，SequenceLayers简化了从简单可流式处理组件构建大规模生产模型的过程。", "conclusion": "目前的SequenceLayers实现（JAX，TensorFlow 2）可以在以下链接找到，展现了如何通过层次和逐步处理来创建复杂的序列模型，同时保证了流式处理的正确性和效率。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23535", "html_url": "https://arxiv.org/abs/2507.23535", "title": "透明AI：可解释性与可理解性的必要性", "title_en": "Transparent AI: The Case for Interpretability and Explainability", "authors": "Dhanesh Ramachandram,Himanshu Joshi,Judy Zhu,Dhari Gandhi,Lucas Hartman,Ananya Raval", "background": "随着人工智能系统在各领域中越来越多地影响关键决策，透明度已成为负责任和可信赖的人工智能实施的基础。作为在推进人工智能研究和促进行业应用方面处于领先地位的研究机构，本文基于跨领域的可解释性实践经验，提供了有关透明人工智能的关键见解和经验教训。", "innovation": "本文提出了适用于不同人工智能成熟度阶段组织的可操作策略和实施指导，强调将可解释性作为核心设计原则，而不仅仅是事后补充。", "conclusion": "本文强调了在人工智能实施中嵌入解释性和可理解性的必要性，以提高系统的透明度和可信度，确保其负责任的使用。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23504", "html_url": "https://arxiv.org/abs/2507.23504", "title": "验证者层次结构", "title_en": "A Verifier Hierarchy", "authors": "Maurits Kaptein", "background": "该论文探讨了证书长度与验证者运行时间之间的权衡关系，并证明了验证者权衡定理，该定理表明，将语言的基本验证时间从f(n)减少到g(n)，其中f(n) ≥ g(n)，则所需的证书长度至少为Ω(log(f(n) / g(n)))。", "innovation": "论文提出了验证者权衡定理，揭示了证书长度与验证时间之间的关系，并基于证书复杂性构建了自然层次结构。该定理还应用于分析复杂性类之间的猜想分离（例如NP和EXPTIME）以及自然问题，如字符串周期性和旋转检测。此外，通过关系证明与亚线性证书的存在，论文提供了P与NP问题的新视角。", "conclusion": "验证者权衡定理指导下的自然层次结构为分析复杂性类之间的关系以及验证时间与证书长度的关系提供了新的方法。这一研究不仅为复杂性理论提供了新的见解，还可能对实际验证算法的设计有重要影响。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23437", "html_url": "https://arxiv.org/abs/2507.23437", "title": "Coflex: 提升硬件感知神经架构搜索方法以实现高效可扩展的深度神经网络加速器设计", "title_en": "Coflex: Enhancing HW-NAS with Sparse Gaussian Processes for Efficient and Scalable DNN Accelerator Design", "authors": "Yinhui Ma,Tomomasa Yamasaki,Zhehui Wang,Tao Luo,Bo Wang", "background": "硬件感知神经架构搜索（HW-NAS）是自动优化神经网络性能和硬件能耗效率的有效方法，特别适用于边缘设备上的深度神经网络加速器开发。然而，其庞大的搜索空间和高计算成本使其在实际应用中的采用面临巨大挑战。", "innovation": "Coflex 提出了一种新型的 HW-NAS 框架，将稀疏高斯过程（SGP）与多目标贝叶斯优化结合，通过利用稀疏诱导点，将 GP 核复杂性从立方级降低到近乎线性级，而不影响优化性能。这种方法可以实现大规模搜索空间的可扩展近似，大幅减少计算开销同时保持高预测精度。", "conclusion": "实验结果表明，Coflex 在网络准确性和能效指标（Energy-Delay-Product）上优于现有最先进的方法，在计算加速方面实现了1.9到9.5倍的速度提升。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23495", "html_url": "https://arxiv.org/abs/2507.23495", "title": "在因果决策中整合结构性不确定性", "title_en": "Incorporating structural uncertainty in causal decision making", "authors": "Maurits Kaptein", "background": "实践者在根据因果效应作决策时通常忽视结构不确定性。然而，在某些情况下，这种不确定性可能是显著的，需要方法论上的解决方案（如贝叶斯模型平均法评估竞争性因果结构）。本文以简单的双变量关系为例，探讨了结构不确定性对因果决策影响的重要性及其适用条件。", "innovation": "本文创新地提出了当结构不确定性较高且因果效应在不同结构间差异显著时，通过贝叶斯模型平均方法评估多种竞争性因果结构，以应对这种不确定性。实验证明现代因果发现方法可以在一定范围内提供必要的不确定性量化。", "conclusion": "结论指出，这种方法论上的解决方案在满足一定假设条件下具有最优性。并且，现代因果发现方法可以提供必要的结构性不确定性量化。目前该框架能够补充现有的稳健因果推理方法，通过解决实践中通常被忽略的不确定性源来增强因果决策的准确性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23501", "html_url": "https://arxiv.org/abs/2507.23501", "title": "方向性集成聚合用于演员-批评家", "title_en": "Directional Ensemble Aggregation for Actor-Critics", "authors": "Nicklas Werge,Yi-Shan Wu,Bahareh Tasdighi,Melih Kandemir", "background": "在连续控制任务中的离策略强化学习严重依赖于准确的$Q$值估计。常用的保守聚合方法，如取最小值，用于减轻过度估计偏差，但这些静态规则过于粗糙，会丢弃有价值的信息，并且无法适应特定任务需求或不同的学习阶段。", "innovation": "提出了一种名为方向性集成聚合（DEA）的新方法，该方法能够在演员-批评家框架中自适应地结合$Q$值估计。DEA引入了两个完全可学习的方向参数：一个用于调节批评家侧的保守性，另一个用于引导演员侧的策略探索。这些参数是通过基于集成不一致性加权的贝尔曼误差学习的，仅根据贝尔曼误差的方向对每个样本进行加权。这种方向性的学习机制允许DEA根据数据驱动的方式调整保守性与探索性，使聚合能够适应不同的不确定性水平和训练阶段。", "conclusion": "DEA在连续控制基准和从交互到样本高效的不同学习阶段进行了评估，并证明了其在静态集成策略上的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23534", "html_url": "https://arxiv.org/abs/2507.23534", "title": "Continual Learning with Synthetic Boundary Experience Blending", "title_en": "Continual Learning with Synthetic Boundary Experience Blending", "authors": "Chih-Fan Hsu,Ming-Ching Chang,Wei-Chao Chen", "background": "连续学习（CL）旨在解决在对多个任务进行顺序训练时模型出现灾难性遗忘的问题。尽管经验回放已经显示出一定的潜力，但其效果常常受限于存储的关键样本分布稀疏，导致决策边界过于简化。本文假设，训练过程中引入接近决策边界的合成数据作为隐式正则化，可以提高边界稳定性并减轻遗忘现象。", "innovation": "本文提出了一种新型训练框架——经验融合（Experience Blending），该框架将存储的关键样本知识与合成的边界邻近数据结合起来。具体而言，Experience Blending包括两个核心组件：1. 多变量差分隐私（DP）噪声机制，在低维特征表示的批量中注入噪声，生成边界邻近数据（SBD）；2. 端到端训练策略同时利用存储的关键样本和SBD。", "conclusion": "实验结果表明，本方法在CIFAR-10、CIFAR-100和Tiny ImageNet上分别比九种CL基线方法提升了10%、6%和13%的准确率。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23568", "html_url": "https://arxiv.org/abs/2507.23568", "title": "通过模拟退火优化特征子集选择", "title_en": "Optimised Feature Subset Selection via Simulated Annealing", "authors": "Fernando Martínez-García,Álvaro Rubio-García,Samuel Fernández-Lorenzo,Juan José García-Ripoll,Diego Porras", "background": "在高维数据集上进行特征选择是一个重要的任务，目的在于通过选择最小的特征子集来提高模型的预测准确性。传统的贪心优化方法经常忽视特征之间的依赖关系，导致选出的特征集不够紧凑。本文针对这个问题，将特征选择问题视为组合优化问题，利用模拟退火算法在全球特征子集空间中进行搜索。实验结果表明，该方法能有效选择更紧凑的特征子集，同时保持高预测精度。这种能力来自于对特征间依赖关系的捕捉，而传统的贪婪优化方法往往忽视这一点。", "innovation": "提出了一种称为SA-FDR的新颖算法，将特征选择视为组合优化问题，并使用模拟退火算法进行全局搜索。该算法通过Fisher判别比作为高效代理，来指导优化过程，从而有效选择紧凑且信息丰富的特征子集。该方法特别适合高维数据集，能够有效平衡模型稀疏性、可解释性和性能。", "conclusion": "通过模拟退火优化的特征选择方法（SA-FDR）能够更有效地选择高维数据集上的特征子集，提供了一种灵活且有效的设计可解释模型的方法，特别是在需要高度稀疏、可解释和高性能模型的情况下。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23491", "html_url": "https://arxiv.org/abs/2507.23491", "title": "解释型人工智能模型预测2型糖尿病患者全因死亡风险", "title_en": "Explainable artificial intelligence model predicting the risk of all-cause mortality in patients with type 2 diabetes mellitus", "authors": "Olga Vershinina,Jacopo Sabbatinelli,Anna Rita Bonfigli,Dalila Colombaretti,Angelica Giuliani,Mikhail Krivonosov,Arseniy Trukhanov,Claudio Franceschi,Mikhail Ivanchenko,Fabiola Olivieri", "background": "2型糖尿病（T2DM）是一种高度普遍的非传染性慢性疾病，严重影响患者的预期寿命。准确估计T2DM患者的所有原因死亡风险对于个性化和优化治疗策略至关重要。", "innovation": "该研究通过分析554名40至87岁确诊为T2DM的患者，并采用最大16.8年的随访期，使用机器学习（ML）模型来预测所有原因的死亡风险。研究应用了Shapley加性解释（SHAP）方法来增强模型可解释性，并选择了最优的额外生存树（EST）模型，以提高预测性能。", "conclusion": "所开发的模型在死亡风险评估方面表现出强大的预测能力，并且其临床可解释的输出使该模型具备床旁应用的潜力，有助于识别高风险患者并支持及时的治疗优化。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23449", "html_url": "https://arxiv.org/abs/2507.23449", "title": "Manifold-regularised Signature Kernel Large-Margin $\\ell_p$-SVDD for Multidimensional Time Series Anomaly Detection", "title_en": "Manifold-regularised Signature Kernel Large-Margin $\\ell_p$-SVDD for Multidimensional Time Series Anomaly Detection", "authors": "Shervin Rahimzadeh Arashloo", "background": "该研究扩展了最近引入的大边际$\\ell_p$-SVDD方法，通过流形正则化和基于时间序列签名核表示来利用数据分布的几何结构进行异常检测。研究表明，通过Manifold-regularised $\\ell_p$-SVDD方法可以捕捉潜在流形上的结构信息，以提高检测性能。", "innovation": "1. 提出了一种带有流形正则化的$\\ell_p$-SVDD变体方法，鼓励流形上的标签平滑，以捕捉结构信息，从而改善检测性能。\n2. 结合现有的表示定理，提出了一种有效优化技术。\n3. 通过签名核捕捉时间序列的复杂性，用于改进异常检测。", "conclusion": "通过理论分析Rademacher复杂性研究提出的方法的泛化性能，并通过实验评估了该方法在多种数据集上的性能，证明了与现有方法相比的优越性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23512", "html_url": "https://arxiv.org/abs/2507.23512", "title": "Differentially Private Clipped-SGD: High-Probability Convergence with Arbitrary Clipping Level", "title_en": "Differentially Private Clipped-SGD: High-Probability Convergence with Arbitrary Clipping Level", "authors": "Saleh Vatan Khah,Savelii Chezhegov,Shahrokh Farahmand,Samuel Horváth,Eduard Gorbunov", "background": "梯度剪辑在深度学习中是一个基本工具，有助于改善在大语言模型训练中常见重尾噪声下的随机梯度方法（如SGD、AdaGrad和Adam）的高概率收敛。梯度剪辑也是差分隐私（DP）机制中的关键组成部分。然而，现有的高概率收敛分析通常需要剪辑阈值随着优化步骤的数量增加，这与标准的DP机制如高斯机制不兼容。", "innovation": "本文提供了第一个固定剪辑水平的高概率收敛分析，适用于凸和非凸平滑优化问题，在重尾噪声下（通过有限中心$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{α}}}}}}}}}}}}}}$阶中心矩假设，$\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{α}}}}}}}}}}}}}}$属于(1,2]区间），弥补了现有高概率收敛分析与标准DP机制的不兼容性。结果表明，使用固定剪辑水平，该方法收敛速度更快，且能平衡噪声和隐私保障。", "conclusion": "随着固定剪辑水平的使用，该方法在噪声和隐私保障之间提供了更精细的折衷，且比现有方法更快地收敛到最优解的邻域。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23581", "html_url": "https://arxiv.org/abs/2507.23581", "title": "GraphRAG-R1: 基于过程约束增强学习的图检索增强生成", "title_en": "GraphRAG-R1: Graph Retrieval-Augmented Generation with Process-Constrained Reinforcement Learning", "authors": "Chuanyue Yu,Kuo Zhao,Yuhan Li,Heng Chang,Mingjian Feng,Xiangzhe Jiang,Yufei Sun,Jia Li,Yuzhi Zhang,Jianxin Li,Ziwei Zhang", "background": "Graph Retrieval-Augmented Generation (GraphRAG) 方法通过利用图结构进行知识表示和建模复杂现实世界关系，有效增强了大型语言模型 (LLMs) 的推理能力。然而，现有的 GraphRAG 方法在处理需要多跳推理的复杂问题时仍存在显著瓶颈，因为它们的查询和检索阶段主要依赖预定义的启发式规则，未能充分利用 LLM 的推理潜力。", "innovation": "本文提出了一种适应性的 GraphRAG 系统 GraphRAG-R1，通过使用过程约束的基于结果的强化学习 (RL) 训练大型语言模型来增强多跳推理能力。主要创新包括：1) 使用支持思考的展开优化方法（modified GRPO）；2) 设计两种过程约束下的奖励函数：用于处理浅层检索结果的递进检索衰减（PRA）奖励和用于平衡模型性能与计算成本的代价感知 F1 (CAF) 奖励；3) 制定阶段依赖的训练策略，包括三个训练阶段；4) 采用混合图-文本检索以提高推理能力。", "conclusion": "广泛的实验结果表明，GraphRAG-R1 在解决复杂推理问题方面显著提升了大型语言模型的能力，与最先进的 GraphRAG 方法相比，在领域内（in-domain）和领域外（out-of-domain）数据集上都表现优异。此外，该框架可以灵活地与各种现有的检索方法集成，持续提高性能。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23536", "html_url": "https://arxiv.org/abs/2507.23536", "title": "从大语言模型到边缘设备：资源高效的微调方法", "title_en": "From LLMs to Edge: Parameter-Efficient Fine-Tuning on Edge Devices", "authors": "Georg Slamanig,Francesco Corti,Olga Saukh", "background": "参数高效的微调（PEFT）方法减少了更新深度学习模型的计算成本，通过减少额外参数的数量来使模型适应下游任务。尽管在大规模语言模型（LLMs）上进行了广泛的研究，但这些方法在处理边缘设备上较小的模型，如卷积神经网络（CNN）的应用却仍处于起步阶段。本文通过使用卷积架构进行基准测试和分析，这些架构通常部署在资源受限的边缘环境中，对流行的PEFT方法如洛拉（LoRA）、DoRA和GaLore进行了评估，以处理分布变化并适应未见过的类别。研究使用了新提出的PyTorch性能分析器来比较这些PEFT方法的性能和计算成本与传统微调方法之间的差异。基于硬件限制、性能要求和应用需求，我们提供了选择PEFT方法的指导。", "innovation": "本文首次将流行的PEFT方法应用于针对边缘部署优化的卷积架构，比较了传统微调方法和不同PEFT方法在保持模型性能的同时减少计算成本的效果。研究采用PyTorch性能分析器进行评估，并发现了PEFT方法在深度可分离卷积架构上的性能不如在大语言模型上高效，但在优化的边缘设备架构上能够将浮点运算（FLOPs）减少高达95%。这为硬件受限环境下的PEFT方法选择提供了重要的见解和指导。", "conclusion": "评估的PEFT方法在应用于深度可分离卷积架构时，其内存效率仅为在大语言模型上的一半。然而，当针对优化以边缘部署为目标的卷积架构进行更新时，基于适配器的PEFT方法可以在模型更新期间减少高达95%的浮点运算。本文的研究结果对于选择适合硬件约束、性能要求和应用需求的PEFT方法提供了重要的指导。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23615", "html_url": "https://arxiv.org/abs/2507.23615", "title": "L-GTA：时间序列生成建模用于扩增", "title_en": "L-GTA: Latent Generative Modeling for Time Series Augmentation", "authors": "Luis Roque,Carlos Soares,Vitor Cerqueira,Luis Torgo", "background": "数据扩增在时间序列分析的各个方面变得越来越重要，包括预测、分类和异常检测任务。现有方法通常采用直接变换的方法，但这些方法可能难以生成保留原始数据内在特性的合成时间序列。因此，提出了一种使用变分递归自编码器的基于变压器的生成模型，称为Latent Generative Transformer Augmentation (L-GTA)模型，以解决这一问题。", "innovation": "L-GTA模型通过在模型的潜在空间中应用控制变换来生成新的时间序列，这些变换利用了数据的内在特性。这种方法可以实现从简单的抖动到幅度扭曲等不同类型的变换，并将这些基本变换组合起来生成更复杂的合成时间序列数据集。L-GTA模型通过实证研究展示了其生成可靠、一致且可控的扩增数据的能力，从而在预测准确性和相似性度量方面相比直接变换方法取得了显著改进。", "conclusion": "基于L-GTA模型的扩增方法能够显著提高时间序列分析任务中的预测准确性和相似性度量，因此为时间序列数据集的生成提供了更为有效和可靠的工具。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23607", "html_url": "https://arxiv.org/abs/2507.23607", "title": "基于深度学习的临床试验入组预测及其不确定性估计", "title_en": "Deep Learning-based Prediction of Clinical Trial Enrollment with Uncertainty Estimates", "authors": "Tien Huu Do,Antoine Masquelier,Nae Eoun Lee,Jonathan Crowther", "background": "临床试验是评估新药或治疗方法的安全性和有效性的一个系统过程。进行此类试验通常需要大量的财务投资和细致的计划，因此准确预测试验结果是非常必要的。在试验计划阶段，准确预测患者入组情况，这是试验成功的关键因素之一，是一个主要挑战。本文提出了一种基于深度学习的方法，利用预先训练的语言模型（PLMs）捕捉临床文件的复杂性和微妙之处，并将这些信息转化为表达性表示。该表示与通过注意力机制编码的表格特征相结合。为了考虑入组预测中的不确定性，模型添加了一个基于伽马分布的概率层，以实现范围估计。我们将提出的模型应用于预测临床试验时长，假设各站点的入组遵循泊松-伽马过程。我们在实际的临床试验数据上进行了广泛的实验，表明所提出的模型可以有效预测给定临床试验中各站点的入组患者数量，并且优于现有的基准模型。", "innovation": "提出了一种基于深度学习的方法，利用预先训练的语言模型捕捉临床文档的复杂细节，并结合表格特征和注意力机制，以范围估计的方式处理入组预测中的不确定性。该方法应用于预测临床试验时长，验证了其有效性和优越性。", "conclusion": "我们提出的基于深度学习的方法有效地预测了临床试验中各站点的患者入组数量，并通过范围估计方式考虑了不确定性，优于现有的基准模型。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23632", "html_url": "https://arxiv.org/abs/2507.23632", "title": "softmax注意的表达性：一种递归神经网络视角", "title_en": "On the Expressiveness of Softmax Attention: A Recurrent Neural Network Perspective", "authors": "Gabriel Mongaras,Eric C. Larson", "background": "自引入以来，softmax注意因其在广泛任务中的特性和可扩展性，已成为现代变压器架构的核心。然而，softmax注意的主要缺点是与序列长度成二次关系的内存需求和计算复杂度。虽然通过替代softmax非线性，已提出了线性注意等方法以避免softmax注意的二次瓶颈，但这些线性形式的注意在下游准确性上通常会滞后。尽管softmax非线性在查询和关键点内积上的直觉表明它具有某些其他非线性无法比拟的优点，但这一差异背后的原因仍然没有明确的解释。本文通过推导softmax注意的递归形式，展示了线性注意是softmax注意的一种近似，利用这种形式，softmax注意中的每一部分都可以用递归神经网络（RNN）的语言来描述。将softmax注意视为RNN有助于消融分析其各个组成部分，理解每部分的重要性及它们之间的交互。", "innovation": "本文通过推导softmax注意的递归形式，展示了线性注意是softmax注意的一种近似，并提出将softmax注意视为RNN的语言来描述其各个组成部分，有助于理解每部分的重要性及它们之间的交互。", "conclusion": "本文的研究帮助解释了为什么softmax注意相比于其同类项具有更高的表达性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23562", "html_url": "https://arxiv.org/abs/2507.23562", "title": "SpiNNaker2神经形态平台上Spiking Q-网络的硬件意识微调", "title_en": "Hardware-Aware Fine-Tuning of Spiking Q-Networks on the SpiNNaker2 Neuromorphic Platform", "authors": "Sirine Arfa,Bernhard Vogginger,Christian Mayr", "background": "Spiking神经网络（SNNs）有望在神经形态硬件上以广泛机器人任务实现数个数量级更低的能耗和低延迟推理。本文旨在展示一种使用量化SNNs实现强化学习（RL）算法以解决两类经典控制任务的高效实现。", "innovation": "该工作在SpiNNaker2神经形态芯片上对Spiking Q-网络进行了硬件意识的微调，并与传统的基于GPU的计算平台进行了比较分析，指出了SpiNNaker2在能效方面具有显著优势，能实现高达32倍的能耗减少。同时展示了在某些任务设置中推理延迟与GPU相当，并且有改进的表现，强调了SpiNNaker2在实时神经形态控制中的可行性。", "conclusion": "研究结果表明SpiNNaker2在可扩展的低能耗神经形态计算方面具有强大的潜力，使得神经形态方法成为高效深度Q-学习的一个有吸引力的方向。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23604", "html_url": "https://arxiv.org/abs/2507.23604", "title": "多智能体强化学习中的分层消息传递策略", "title_en": "Hierarchical Message-Passing Policies for Multi-Agent Reinforcement Learning", "authors": "Tommaso Marzi,Cesare Alippi,Andrea Cini", "background": "分布式多智能体强化学习（MARL）方法允许学习可扩展的多智能体策略，但面临着观察部分性和引发的非站定性两大挑战。通过引入促进协调和高级规划的机制可以解决这些挑战。具体而言，通过通信（例如，消息传递）和分层强化学习（HRL）方法来实现协调和时间抽象。然而，优化问题限制了分层策略在多智能体系统中的应用。因此，这些方法的结合尚未得到充分探索。", "innovation": "本文提出了一种新颖且有效的多智能体分层消息传递策略学习方法。采用封臣HRL框架，并依赖分层图结构进行智能体之间的规划与协调。低层智能体接收高层发送的目标，并与同一层级的相邻智能体交换消息。为了学习分层多智能体策略，设计了一种基于训练低层策略使其最大化与高层关联的优势函数的新颖奖励分配方法。", "conclusion": "在相关基准上的结果表明，该方法在与最先进的方法相比时表现出色。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23638", "html_url": "https://arxiv.org/abs/2507.23638", "title": "OptiGradTrust：基于多特征梯度分析和基于强化学习的信任加权的 Byzantine 抵抗联邦学习", "title_en": "OptiGradTrust: Byzantine-Robust Federated Learning with Multi-Feature Gradient Analysis and Reinforcement Learning-Based Trust Weighting", "authors": "Mohammad Karami,Fatemeh Ghassemi,Hamed Kebriaei,Hamid Azadegan", "background": "联邦学习能够使在分布式的医疗机构之间协同进行模型训练，同时保持患者数据的隐私。然而，它仍存在拜占庭攻击和统计异质性的脆弱性。因此，需要一种全面的防御框架来应对这些挑战，确保联邦学习系统的安全性和准确性.", "innovation": "OptiGradTrust 推出了一个新的六维指纹方法，包括 VAE 重建误差、余弦相似性、L2 范数、符号一致性比率和蒙特卡洛 Shapley 值，通过这种多特征分析驱动一个混合的强化学习-注意力模块，实现自适应的信任评分。为了应对数据异质性带来的收敛难题，论文还提出了结合了 Federated Batch Normalization 和正则化的 FedBN-Prox 方法，以实现更好的准确性和收敛性之间的权衡。", "conclusion": "在各种拜占庭攻击条件下，对 MNIST、CIFAR-10 和阿尔茨海默病 MRI 数据集进行广泛的评估表明，OptiGradTrust 相比于最先进的防御方法有显著的改进，非 i.i.d. 条件下相比 FLGuard 提高了 1.6 个百分点，在面对多样化的攻击模式时还保持了良好的鲁棒性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23539", "html_url": "https://arxiv.org/abs/2507.23539", "title": "稀疏假设下改进的核矩阵-向量乘法算法", "title_en": "Improved Algorithms for Kernel Matrix-Vector Multiplication Under Sparsity Assumptions", "authors": "Piotr Indyk,Michael Kapralov,Kshiteej Sheth,Tal Wagner", "background": "文章针对快速处理注意力矩阵的问题，研究了在稀疏假设下计算非对称高斯核矩阵 $K \times \boldsymbol{x}$ 的快速算法。矩阵 $K$ 的列根据实数 $d$ 空间中的 $n$ 个键 $k_1, k_2, \text{...} k_n$ 进行索引，行根据实数 $d$ 空间中的 $n$ 个查询 $q_1, q_2, \text{...} q_n$ 进行索引，其第 $i, j$ 元素为 $K_{ij} = e^{-\frac{\norm{q_i - k_j}_2^2}{2\text{σ}^2}}$，其中 $\text{σ}$ 是带宽参数。给定向量 $\boldsymbol{x} \text{∈} \textbf{R}^n$ 和误差参数 $\text{ε} \text{>} 0$，任务是在时间复杂度小于 $n^2$ 且与 $d$ 线性相关的条件下输出向量 $\boldsymbol{y} \text{∈} \textbf{R}^n$，使得 $\norm{Kx - \boldsymbol{y}}_2 \text{≤} \text{ε} \norm{ \boldsymbol{x} }_2$。", "innovation": "文章在稀疏假设下提出了一种新的算法，这种算法在处理非对称高斯核矩阵时不依赖于最坏情况下的矩阵质量和增长假设。实验验证在各种场景下（如大型语言模型中的快速注意力计算），矩阵 $K$ 的和的结构满足这种假设。文章得到了第一个能够在稀疏假设下工作、适用于任意向量的亚二次时间算法。", "conclusion": "文章验证了非对称高斯核矩阵在实际应用中的稀疏假设，并且提出了一种能够在亚二次时间和线性于 $d$ 的情况下满足误差约束的算法，从而有效提升了这些场景中的计算效率。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23675", "html_url": "https://arxiv.org/abs/2507.23675", "title": "One-Step Flow Policy Mirror Descent", "title_en": "One-Step Flow Policy Mirror Descent", "authors": "Tianyi Chen,Haitong Ma,Na Li,Kai Wang,Bo Dai", "background": "由于强大的表征能力，扩散策略已经在在线强化学习（RL）中取得了巨大成功。然而，扩散策略模型的推断依赖于缓慢的迭代采样过程，这限制了它们的响应能力。", "innovation": "我们提出了Flow Policy Mirror Descent (FPMD)，这是一种在线RL算法，能够在策略推断时实现一次采样。该方法利用了直在线性流匹配模型中单步采样分布方差与离散化误差之间的理论联系，不需要额外的Distillation或一致性训练。我们的研究还基于流策略和MeanFlow策略两种参数化提出了两种算法变体。鲁棒的实证评估表明，我们的算法在MuJoCo基准测试中表现出与扩散策略基线相当的性能，但只需要较少的函数评估次数", "conclusion": "我们的算法在保持与扩散策略基线相似性能的前提下，显著减少了推断过程中的函数评估次数，显示出强大的鲁棒性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23665", "html_url": "https://arxiv.org/abs/2507.23665", "title": "SHAP-Guided Regularization in Machine Learning Models", "title_en": "SHAP-Guided Regularization in Machine Learning Models", "authors": "Amal Saadallah", "background": "特征归因方法，如SHapley Additive exPlanations (SHAP)，已在理解机器学习模型方面变得至关重要，但它们在指导模型优化方面的作用仍待探索。", "innovation": "本文提出了一种SHAP指导的正则化框架，将特征重要性约束融入模型训练中，以提高预测性能和可解释性。该方法应用熵惩罚来鼓励稀疏且集中的特征归因，并促进样本间的稳定性。该框架适用于回归和分类任务。本文首先通过使用TreeSHAP对基于树的模型进行正则化进行探索，并通过基准回归和分类数据集的大量实验，证明了该方法在确保稳健和可解释的特征归因的同时提高了泛化性能。提出的技巧提供了一种新颖的基于解释性的正则化方法，使机器学习模型更准确也更可靠。", "conclusion": "本文提出了一种SHAP指导的正则化框架，通过熵惩罚提高了模型的预测性能和可解释性，并通过实验验证了其有效性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/1908.01212", "html_url": "https://arxiv.org/abs/1908.01212", "title": "在2范畴中类型化张量算子（I）", "title_en": "Typing Tensor Calculus in 2-Categories (I)", "authors": "Fatimah Rita Ahmadi", "background": "论文背景在于通过形式化线性代数的计算，开发出高效的算法和适用于函数编程语言的框架，并增强支持并行计算的能力。为此，论文将线性代数中的元素（如矩阵）视为矩阵范畴中的形态，进一步将其推广到任意半加性范畴。为了处理更高阶的矩阵（张量），定义了半加性2范畴，其中矩阵表示为1-形态，四索引张量表示为2-形态，从而提供了一种无索引、类型化的线性代数框架，包括最多四索引的矩阵和张量。", "innovation": "论文创新之处在于引入了一个形式化的线性代数框架，将矩阵和四索引张量表示为1-形态和2-形态，从而实现了无索引、类型化的线性代数体系。该框架不仅适用于矩阵，还适用于更高阶的张量表达，并且可以推广到半加性2范畴中。此外，还详细展示了2范畴2Vec内的操作和向量化。", "conclusion": "论文全面地提出了一个形式化的线性代数和张量算子框架，特别注重处理高阶张量，并将其推广到2范畴中，为后续研究提供了新的视角和方法。通过这种方法，能够更好地支持高效算法的开发和函数编程语言的应用。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23712", "html_url": "https://arxiv.org/abs/2507.23712", "title": "少量标注的异常样本在异常检测中的应用", "title_en": "Anomalous Samples for Few-Shot Anomaly Detection", "authors": "Aymane Abdali,Bartosz Boguslawski,Lucas Drumetz,Vincent Gripon", "background": "许多异常检测和分类方法依赖于大量的非异常样本（“正常”样本），前提是异常样本通常难以获取。然而，在少量标注（Few-Shot）环境中，一个标注样本就能对结果产生重要影响，这使得这一假设变得不那么成立。本文关注在二元异常分类模型培训中如何利用异常样本，并提出了一种利用异常样本的多评分异常检测得分方法，结合了近期的零样本和基于记忆的技术。", "innovation": "提出了将异常样本整合到多评分异常检测得分中的方法，利用了零样本和基于记忆的技术。比较了异常样本与常规样本的实用性，探讨了各自的优缺点。还提出了基于增强验证的技术来优化不同异常评分的聚合，并在流行的工业异常检测数据集上展示了其有效性。", "conclusion": "通过引入多评分的异常检测得分方法以及增强验证技术，该研究证明了异常样本在少量标注环境下的有效性，同时识别了其局限性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23600", "html_url": "https://arxiv.org/abs/2507.23600", "title": "EB-gMCR: 基于能量的生成建模用于信号解混和多元曲线解析", "title_en": "EB-gMCR: Energy-Based Generative Modeling for Signal Unmixing and Multivariate Curve Resolution", "authors": "Yu-Tang Chang,Shih-Fang Chen", "background": "信号解混分析将数据分解为基础模式，在化学和生物学研究中广泛应用。多元曲线解析（MCR）是信号解混的一个分支，能够将混合的化学信号分解为基本模式（成分）及其浓度，对理解成分组成起关键作用。经典的MCR通常以矩阵分解（MF）的形式呈现，要求用户提供成分的数量，而在实际数据中这些数量通常是未知的。随着数据集的增大或成分数量的增加，基于MF的MCR在扩展性和可靠性方面面临显著挑战。", "innovation": "本研究将MCR重新表述为生成过程（gMCR），并引入一种基于能量的深度学习求解器（EB-gMCR）, 能够自动发现能够忠实重建数据的最小成分集。EB-gMCR从一个庞大的候选池（例如，1024光谱）开始，并采用可微的门控网络仅保留活跃的成分并估计它们的浓度。在噪声较大的合成数据集中，EB-gMCR保持了R² ≥ 0.98，并将成分数量恢复在真实值的5%以内；在更低噪声的数据集中，它达到了R² ≥ 0.99，并实现了近乎精确的成分估计。此外，可以通过简单的插件函数（如非负或非线性混合）加入额外的化学先验知识，从而适应其他仪器或领域而无需改变核心学习过程。通过结合高容量的生成建模和严格的成分选择，EB-gMCR为大规模信号解混分析提供了一种实用的方法。", "conclusion": "EB-gMCR能够自动发现最小成分集，适用于大规模信号解混分析，包括化学库驱动的场景，并且通过简单的插件函数能够适应其他仪器或领域而不改变核心学习过程。该研究还提供了源代码供下载。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23676", "html_url": "https://arxiv.org/abs/2507.23676", "title": "DepMicroDiff：基于依赖感知的扩散型多模态微生物数据插补方法", "title_en": "DepMicroDiff: Diffusion-Based Dependency-Aware Multimodal Imputation for Microbiome Data", "authors": "Rabeya Tus Sadia,Qiang Cheng", "background": "微生物组数据在理解宿主健康与疾病方面至关重要，但由于其固有的稀疏性和噪声，这对准确插补构成了重大挑战，影响了下游任务如生物标记物发现等。现有的插补方法，包括最近的扩散型模型，往往未能捕捉微生物群系之间的复杂依赖性，忽略了能够辅助插补的上下文元数据。", "innovation": "DepMicroDiff框架结合了基于扩散的生成模型与依赖感知变换器（DAT），明确捕捉互依关系和自回归关系。DepMicroDiff通过在多种癌症数据集上进行VAE预训练，并通过大语言模型（LLM）编码病患元数据进一步增强。实验结果显示，DepMicroDiff在多个癌症类型中显著优于现有最先进的插补基线，在pearson相关性（最高达到0.712），余弦相似度（最高达到0.812）及更低的RMSE和MAE表现更优，验证了其在微生物组插补中的稳健性和泛化能力。", "conclusion": "DepMicroDiff在TCGA微生物组数据集上的实验表明，其在多个癌症类型中显著优于现有最先进的插补基线，显示了其在微生物组插补中的稳健性和泛化能力。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23756", "html_url": "https://arxiv.org/abs/2507.23756", "title": "使用情绪和疲劳感知推荐系统改进主动学习中的注释员选择", "title_en": "Improving annotator selection in Active Learning using a mood and fatigue-aware Recommender System", "authors": "Diana Mortagua", "background": "主动学习(AAL)面临选择最佳注释员以减少标注数据误差和数量的挑战。现有策略大多未考虑影响生产力的内部因素，如情绪、注意力、动力和疲劳水平。该研究基于现有文献，通过考虑这些内部因素（尤其情绪和疲劳水平）的影响，并提出一种基于知识推荐系统(KBR)的新注释员-查询配对策略，旨在减少注释错误和提高模型训练准确性。", "innovation": "提出了一种新的基于知识推荐系统(KBR)的注释员-查询配对策略，该策略不仅考虑内部因素（包括情绪和疲劳水平）对注释员的影响，还能根据注释员的过往准确性、当前情绪与疲劳状态，以及查询实例的信息来选择和安排注释工作。这种创新方法在模拟真实情况时预测了注释员的表现，并通过KBR优化了注释任务，从而减少了标注错误，提高了模型的训练准确性。", "conclusion": "研究结果表明，通过考虑注释员的过往表现、当前情绪和疲劳程度，能够有效减少注释错误和模型不确定性。与不利用内部因素相比，这种方法在错误减少和准确性提升方面显示出明显优势。尽管整体改进程度尚不显著，但该研究展示了探索人类认知因素如何影响主动学习的一个新的开放性挑战，并提出了有效的解决路径。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22908", "html_url": "https://arxiv.org/abs/2507.22908", "title": "一种结合混合量子增强学习的隐私保护联邦框架用于金融欺诈检测", "title_en": "A Privacy-Preserving Federated Framework with Hybrid Quantum-Enhanced Learning for Financial Fraud Detection", "authors": "Abhishek Sawaika,Swetang Krishna,Tushar Tomar,Durga Pritam Suggisetti,Aditi Lal,Tanmaya Shrivastav,Nouhaila Innan,Muhammad Shafique", "background": "数字交易的快速增加导致了欺诈活动的激增，这对传统的金融欺诈检测方法提出了挑战。为了应对这一问题，我们提出了一种专门的联邦学习框架，该框架独特地结合了量子增强的长短期记忆（LSTM）模型和先进的隐私保护技术，旨在提升欺诈检测的准确性和安全性。", "innovation": "通过在LSTM架构中引入量子层，我们的方法能够更有效地捕捉复杂的跨交易模式，与传统模型相比，在关键评估指标上取得了约5%的性能提升。此外，我们提出的名为“FedRansel”的新方法能够防御注入和推理攻击，与标准差分隐私机制相比，将模型退化和推理准确性的降低控制在4-8%以内。这样的半去中心化的结构，结合量子LSTM模型，不仅提高了欺诈检测的准确性，还增强了敏感金融数据的安全性和隐私性。", "conclusion": "该方法在金融欺诈检测方面表现出色，并显著增强了数据安全性和隐私性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23674", "html_url": "https://arxiv.org/abs/2507.23674", "title": "TweakLLM：一种动态调整缓存响应的路由架构", "title_en": "TweakLLM: A Routing Architecture for Dynamic Tailoring of Cached Responses", "authors": "Muhammad Taha Cheema,Abeer Aamir,Khawaja Gul Muhammad,Naveed Anwar Bhatti,Ihsan Ayyub Qazi,Zafar Ayyub Qazi", "background": "大型语言模型（LLMs）每天处理数百万个查询，使得高效响应缓存成为降低运营成本和减少延迟的优化手段。然而，由于聊天机器人交互的个性化特性和语义相似性搜索的有限准确性，保持对用户查询的相关性变得困难。", "innovation": "我们提出了TweakLLM，一种新型的路由架构，采用轻量级的LLM动态调整缓存响应以适应传入的提示。通过全面的评估，包括用户研究（双边比较、满意度投票以及多代理LLM辩论），我们证明TweakLLM在保持响应质量与前沿模型相当的同时，显著提高了缓存的有效性。", "conclusion": "跨实际数据集的结果表明，TweakLLM是一个可扩展且资源高效的缓存解决方案，适用于大规模LLM部署，同时不损害用户体验。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22906", "html_url": "https://arxiv.org/abs/2507.22906", "title": "基于深度神经网络的目标数量和方向联合感知方法：一种绿色大规模H2AD大规模MIMO接收器", "title_en": "DNN-based Methods of Jointly Sensing Number and Directions of Targets via a Green Massive H2AD MIMO Receiver", "authors": "Bin Deng,Jiatong Bai,Feilong Zhao,Zuming Xie,Maolin Li,Yan Wang,Feng Shu", "background": "在未来的无线网络中，异构混合模拟-数字H2AD大规模MIMO架构因其绿色特性被证明具有极大的潜力，可以替代高能耗、高电路成本和高复杂性的完全模拟MIMO。然而，如何通过这种结构智能地感知多发射器的数量和方向仍然是一个开放的难题。本研究针对此问题提出了一个两阶段的感知框架，旨在联合估计多目标的数量和方向。", "innovation": "该研究提出了三种目标数量感知方法：改进的特征域聚类框架、基于五种关键统计特征的增强深度神经网络以及利用完整特征值改进的一维卷积神经网络。此外，引入了在线微聚类方法以实现低复杂度和高精度的方向角估计。还推导出在多源条件下绿色H2AD的大数理论性能基准。研究结果表明，开发的三种方法在中等到高信噪比下实现了100%的目标数量感知，而改进的一维卷积神经网络在极低信噪比条件下表现出优越性。在线微聚类方法在多源环境中优于现有的基于聚类和融合的方向角估计方法。", "conclusion": "我们提出了基于改进的特征域聚类框架、基于五种关键统计特征的增强深度神经网络以及一维卷积神经网络改进的目标数量感知方法，并通过在线微聚类方法实现了低复杂度和高精度的方向角估计。理论分析结果证明了技术的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22941", "html_url": "https://arxiv.org/abs/2507.22941", "title": "SigBERT: 组合叙述医疗报告和粗糙路径签名理论在肿瘤学中进行生存风险估计", "title_en": "SigBERT: Combining Narrative Medical Reports and Rough Path Signature Theory for Survival Risk Estimation in Oncology", "authors": "Paul Minchella,Loïc Verlingue,Stéphane Chrétien,Rémi Vaucher,Guillaume Metzler", "background": "电子医疗记录（EHR）包含了大量可用于医疗健康机器学习应用的信息。然而，现有的生存分析方法往往难以有效地处理文本数据的复杂性，尤其是其时间序列形式。现有的方法在处理这种结构化文本数据时存在困难。", "innovation": "sigBERT 是一个新颖的时间生存分析框架，旨在有效地处理每个患者的大量临床报告。通过提取和平均词嵌入为句子嵌入，并结合粗糙路径理论的时间序列签名提取方法捕捉每位患者的时空动态，sigBERT 集成了序列医疗数据来增强风险估计，推进了基于叙述的生存分析。", "conclusion": "sigBERT 模型在 Léon Bérard 中心肿瘤学数据集上训练和评估，具有0.75（标准差0.014）的 C 指数得分，表明其在独立测试组中的风险估计能力显著提升。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22951", "html_url": "https://arxiv.org/abs/2507.22951", "title": "统一知识图谱补全的后置解释", "title_en": "Unifying Post-hoc Explanations of Knowledge Graph Completions", "authors": "Alessandro Lonardi,Samy Badreddine,Tarek R. Besold,Pablo Sanchez Martin", "background": "知识图谱完成（KGC）的后置可解释性缺乏形式化和一致评估，阻碍了研究的可重复性和跨研究的比较。", "innovation": "提出了一种通用框架，通过多目标优化来表征后置解释，平衡其有效性和简明性。这统一了KGC中的后置解释算法及其生成的解释。同时，建议并实证支持了改进的评估协议，使用如平均互逆排序召回率和Hits@$k$等流行指标。最后强调了解释的可解释性，即解释能够回答最终用户有意义的问题。", "conclusion": "通过统一方法和细化评估标准，旨在使KGC可解释性研究更加可重复和有意义。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22918", "html_url": "https://arxiv.org/abs/2507.22918", "title": "语义趋同性：探索缩放后语言模型之间共享表示", "title_en": "Semantic Convergence: Investigating Shared Representations Across Scaled LLMs", "authors": "Daniel Son,Sanjana Rathore,Andrew Rufail,Adrian Simon,Daniel Zhang,Soham Dave,Cole Blondin,Kevin Zhu,Sean O'Brien", "background": "研究探讨Gemma-2语言模型（Gemma-2-2B和Gemma-2-9B）在四种比例尺差异下是否仍然会收敛于可比较的内部概念。通过稀疏自编码器（SAE）字典学习管道，利用SAE对每个模型的残差流激活进行处理，通过激活相关性对得到的一维义特征进行对齐，并使用SVCCA和RSA比较匹配的特征空间。结果表明，中间层之间的重叠最强，而早期和晚期层之间的相似性要少得多。初步实验还扩展了分析范围，从单个单词扩展到多个单词子空间，表明具有语义相似性的子空间以类似的方式与语言模型互动。这些结果加强了尽管模型大小不同，大的语言模型仍然可以将世界划分为广泛相似且可解释特征的事实，这为跨模型可解释性提供了基础支撑。", "innovation": "提出了使用稀疏自编码器（SAE）分析语言模型的残差流激活，并通过激活相关性对齐一维义特征，利用SVCCA和RSA比较匹配的特征空间的方法，扩展了从单个单词到多个单词子空间的分析范围，从而揭示了虽然模型比例尺不同，但语言模型仍然具备共享且可解释的语义特征。", "conclusion": "研究表明，大型语言模型在不同的模型尺寸下仍能将世界划分为广泛相似的、可解释的特征，而不仅仅是单个单词的概念。这种语义趋同性为不同规模的语言模型之间的跨模型理解提供了基础支持。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23015", "html_url": "https://arxiv.org/abs/2507.23015", "title": "在现代树形果园中学习剪枝枝条", "title_en": "Learning to Prune Branches in Modern Tree-Fruit Orchards", "authors": "Abhinav Jain,Cindy Grimm,Stefan Lee", "background": "在现代化高产果园中，定期进行休眠树修剪是一项劳动密集且必不可少的任务。传统的修剪方法需要人工完成，但机器人修剪技术能够提高效率并减少劳动投入。这项研究旨在开发一种闭环视觉-运动控制器，用于自动机器人修剪。", "innovation": "该研究提出了一种基于视觉流动图像的独特闭环视觉-运动控制器，用于指导机器人在密集的树环境中的枝条修剪。与传统的需要完整3D重建的方法不同，该控制器仅依赖手腕摄像头的光学流动图像，并通过模拟环境训练，成功实现了在实际果园中对V-Trellis envy树的零-shot迁移和修剪，取得了约30%的成功率，约为专家规划器性能的一半。", "conclusion": "通过开发一种基于光学流动图像的闭环视觉-运动控制器，该研究展示了机器人在修剪现代果园中枝条的可行性和有效性，并提出了在实际果园中进行修剪的方法，虽然成功率还需要进一步提升。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22958", "html_url": "https://arxiv.org/abs/2507.22958", "title": "CHECK-MAT：用于俄罗斯统一国家考试的手写数学答案检查", "title_en": "CHECK-MAT: Checking Hand-Written Mathematical Answers for the Russian Unified State Exam", "authors": "Ruslan Khrulev", "background": "现有的评估模型主要侧重于问题解决能力的评估，而本研究旨在开发一个新的基准，用于评估视觉-语言模型（VLMs）对手写数学解答的理解能力、错误识别以及评分能力，以此填补当前研究的空白。", "innovation": "提出了一个新的基准，即EGE-Math Solutions Assessment Benchmark，用于评估VLMs在理解学生解题过程、识别错误并根据固定标准评分方面的表现。此外，研究还采用了来自七家不同公司的现代VLMs，并在三种推理模式下进行评估。", "conclusion": "研究结果揭示了在数学推理和与人类评分标准一致性方面当前模型存在的局限性。这些发现开启了AI辅助评估的新研究方向。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22912", "html_url": "https://arxiv.org/abs/2507.22912", "title": "一种针对黑暗/深网和社交平台的基于语言模型的半监督集成框架以检测非法市场", "title_en": "A Language Model-Driven Semi-Supervised Ensemble Framework for Illicit Market Detection Across Deep/Dark Web and Social Platforms", "authors": "Navid Yazdanjue,Morteza Rakhshaninejad,Hossein Yazdanjouei,Mohammad Sadegh Khorshidi,Mikko S. Niemela,Fang Chen,Amir H. Gandomi", "background": "非法市场正逐渐转移到互联网的隐蔽部分，包括深网和暗网，以及像Telegram、Reddit和Pastebin这样的平台。这些渠道使非法商品（如毒品、武器和被盗凭证）的匿名交易成为可能。由于有限的标记数据、非法语言的不断演变以及在线源的结构异质性，检测和分类此类内容仍然具有挑战性。", "innovation": "本文提出了一种分层分类框架，结合了微调的语言模型与半监督集成学习策略，以便在各种平台上检测和分类非法市场内容。提取语义表示使用了针对深暗网页面、Telegram频道、Subreddits和Pastebin粘贴的领域特定数据进行微调的ModernBERT模型。此外，还纳入了手动工程特征，如文档结构和嵌入模式（包括比特币地址、电子邮件和IP地址），这些特征补充了语言模型向量。分类管道具有两阶段操作：第一阶段使用基于熵加权投票的半监督集成XGBoost、随机森林和支持向量机来检测销售相关的文档；第二阶段进一步将这些文档分类为毒品、武器或凭证销售。结果显示，该模型在三个数据集中均优于多个基线模型，包括BERT、ModernBERT、DarkBERT、ALBERT、Longformer和BigBird，模型的准确性达到0.96489，F1分数为0.93467，TMCC值为0.95388，展示了强大的泛化能力、在有限监督下的鲁棒性和现实世界非法内容检测的有效性。", "conclusion": "该研究提出了一种有效的模型来检测和分类非法市场内容，并在多种数据集上优于现有基线。通过结合半监督学习方法和领域特定的语言表示，提高了在复杂环境中的检测准确性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22952", "html_url": "https://arxiv.org/abs/2507.22952", "title": "通过大规模语言模型在地图上实现自动标签定位", "title_en": "Automated Label Placement on Maps via Large Language Models", "authors": "Harry Shomer,Jiejun Xu", "background": "标签放置是地图设计中至关重要的一部分，作为空间注释的形式，直接影响着地图的清晰度和可解释性。尽管其重要性，标签放置仍然主要是手动的，并且难以扩展，因为现有的自动化系统难以整合制图惯例，适应不同的上下文，或解释标签指示。现有的自动化系统处理这些挑战的能力有限，导致手动调整需求较高。", "innovation": "本文介绍了一种新的自动标签放置（ALP）范式，将其任务表述为数据编辑的问题，并利用大规模语言模型（LLMs）进行上下文感知的空间注释支持。为实现这一方向，作者创作了MAPLE，这是第一个用于评估ALP性能的基准数据集，涵盖了多种地标类型和来自开源数据的真实世界地图标签放置注释。该方法通过检索增强生成（RAG）检索与每个地标类型相关的标牌准则，将它们整合到提示中，并利用指令调优的语言模型生成理想的标签坐标。作者对四个开源语言模型在MAPLE上的性能进行了评估，分析了总体性能和不同类型地标的一般性能。研究表明，当由结构化的提示和领域特定的检索引导时，大规模语言模型可以学会执行准确的空间编辑，生成符合专家制图标准的结果。", "conclusion": "本文提出了一种基于人工智能辅助的地图完成可扩展框架，并展示了基础模型在结构化数据编辑任务中的潜力。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22947", "html_url": "https://arxiv.org/abs/2507.22947", "title": "ELMES：在教育情境中评估大型语言模型的自动化框架", "title_en": "ELMES: An Automated Framework for Evaluating Large Language Models in Educational Scenarios", "authors": "Shou'ang Wei,Xinyun Wang,Shuzhen Bi,Jian Chen,Ruijia Li,Bo Jiang,Xin Lin,Min Zhang,Yu Song,BingDong Li,Aimin Zhou,Hao Hao", "background": "大型语言模型（LLM）为教育领域带来了变革性的机会，但同时也面临着评估标准多样化、新兴场景缺乏适当评估标准等挑战。当前的评估基准主要测量通用智能，而非教学能力。为解决这一问题，该论文提出了ELMES，一种针对教育场景下评估LLM的开放源代码自动化评估框架。", "innovation": "ELMES通过模块化架构使研究人员能够通过简单的配置文件创建动态的多代理对话，无需广泛编程知识；其混合评估引擎利用LLM作为评判者的方法客观量化传统上主观的教学指标。ELMES通过与教育专家合作开发的细粒度度量标准，在四个关键教育场景中对最先进的LLM进行了系统基准测试。", "conclusion": "ELMES为教育者和研究者提供了可访问的评估框架，显著降低了不同教育应用的适应障碍，推动了LLM在教育中的实际应用。目前，该框架在\textit{this https URL}处公开可获取。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23017", "html_url": "https://arxiv.org/abs/2507.23017", "title": "秩一矩阵恢复的光滑牛顿方法", "title_en": "A Smoothing Newton Method for Rank-one Matrix Recovery", "authors": "Tyler Maunu,Gabriel Abreu", "background": "我们考虑从秩一测量中恢复秩一正半定矩阵的相位检索问题。最近提出的一种基于Bures-Wasserstein梯度下降（BWGD）的算法展现了超线性收敛性，但不稳定，现有的理论只能证明高秩矩阵恢复的局部线性收敛性。", "innovation": "我们通过揭示BWGD实际上实现了非光滑和非凸目标的牛顿方法解决了这一差距。我们建立了一种光滑框架以正则化目标，这提供了一种稳定的方法，并为其提供了严格的超线性收敛性保证。实验结果在合成数据上显示了这种方法的优越稳定性能，同时保持快速收敛性。", "conclusion": "研究表明，通过引入光滑牛顿方法，我们可以解决先前算法的不稳定性问题，同时保持超线性收敛性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23771", "html_url": "https://arxiv.org/abs/2507.23771", "title": "共识驱动的主动模型选择", "title_en": "Consensus-Driven Active Model Selection", "authors": "Justin Kay,Grant Van Horn,Subhransu Maji,Daniel Sheldon,Sara Beery", "background": "市场上广泛提供了现成的机器学习模型，选择合适的模型用于特定的数据分析任务成为了一个挑战。传统的模型选择方法是收集和注释验证数据集，这是一项耗费时间和成本的过程。为了应对这一挑战，本文提出了一种基于共识的主动模型选择方法（CODA），通过利用候选模型的预测来优先选择能够高效区分最佳候选模型的测试数据点进行标注。", "innovation": "本文提出的方法CODA，通过在概率框架内建模分类器、类别和数据点之间的关系，实现共识驱动的主动模型选择。利用候选模型之间的一致性与分歧来指导标签获取过程，并通过贝叶斯推断不断更新对最佳模型的信心。", "conclusion": "本文通过收集26个基准任务，验证了CODA方法的有效性。结果显示CODA方法显著优于现有的主动模型选择方法，相比之前最好的方法，它能将发现最佳模型所需的标注工作量降低70%以上。相关代码和数据可在提供的链接中找到。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22955", "html_url": "https://arxiv.org/abs/2507.22955", "title": "LLMs Between the Nodes: Community Discovery Beyond Vectors", "title_en": "LLMs Between the Nodes: Community Discovery Beyond Vectors", "authors": "Ekta Gujral,Apurva Sinha", "background": "社会网络图中的社区检测对于揭示群体动力学、影响路径和信息传播至关重要。传统方法主要关注图形结构属性，但最近大型语言模型（LLMs）的发展为将语义和上下文信息整合到这一任务中带来了新途径。已有研究表明，LLMs，特别是在带有图意识策略引导的情况下，可以成功应用于小到中型社交网络图的社区检测任务。整合指令调优模型和精心设计的提示显著提高了检测社区的准确性和连贯性。这些发现不仅突显了LLMs在图基研究中的潜力，还强调了根据图数据的具体结构定制模型交互的重要性。", "innovation": "本文提出了一种名为CommLLM的两步框架，利用GPT-4o模型与基于提示的推理相结合，将语言模型输出与图形结构融合。评估在六个真实世界的社会网络数据集上进行，使用NMI（归一化互信息）、ARI（调整兰德指数）、VOI（信息变异度）和簇纯度等关键指标进行性能衡量。研究发现，当LLMs与图意识策略结合时，可以在小到中型图的数据中成功用于社区检测任务，且融合指令调优模型和精心设计的提示显著提高了检测社区的准确性和连贯性。", "conclusion": "研究结果表明，LLMs，特别是在带有图意识策略引导的情况下，可以成功应用于社区检测任务中的小到中型社交网络图数据。指令调优模型与精心设计的提示的结合显著提高了检测社区的准确性和连贯性。这些发现不仅突显了LLMs在图基研究中的潜力，还强调了根据图数据的具体结构定制模型交互的重要性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23064", "html_url": "https://arxiv.org/abs/2507.23064", "title": "实时自动驾驶中的视觉-语言融合：基于目标的摄像头、高清地图及航点交叉注意", "title_en": "Vision-Language Fusion for Real-Time Autonomous Driving: Goal-Centered Cross-Attention of Camera, HD-Map, & Waypoints", "authors": "Santosh Patapati,Trisanth Srinivasan,Murari Ambati", "background": "自动驾驶汽车需要几何准确性和语义理解来导航复杂环境，但大多数现有系统分别处理这两方面。本研究旨在开发一种无需分别处理几何准确性和语义理解的方法，提高自动驾驶效率并降低事故率。", "innovation": "研究提出了XYZ-Drive，这是一种单一路视-语言模型，可以同时读取前方摄像头画面、25m×25m的上方地图和下一航点，输出转向和速度。这种模型通过一个轻量级的目标导向交叉注意力层，使航点令牌突出显示相关图像和地图片段，支持操作和文本解释，然后进入部分微调的LLaMA-3.2 11B模型。研究还通过16项消融测试解释了性能提升的原因，表明多模态信息的融合对于提高自动驾驶性能至关重要。", "conclusion": "在MD-NEX户外驾驶基准测试中，XYZ-Drive在成功率和路径长度加权成功（SPL）方面表现出色，超过PhysNav-DG 15个百分点，同时减少了碰撞并提高了效率。研究还发现，早期在标记级别融合目标意图和地图布局能够实现准确、透明和实时的驾驶。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23104", "html_url": "https://arxiv.org/abs/2507.23104", "title": "RASL: 基于检索增强架构的大规模数据库文本到SQL链接", "title_en": "RASL: Retrieval Augmented Schema Linking for Massive Database Text-to-SQL", "authors": "Jeffrey Eben,Aitzaz Ahmad,Stephen Lau", "background": "尽管在基于大型语言模型（LLM）的自然语言数据库接口方面取得了进展，但将其扩展到企业级数据目录仍然面临着未被充分探索的挑战。先前的工作主要依赖针对特定领域进行调整，这增加了部署的复杂性，并且未能充分利用数据库元数据中的语义上下文。", "innovation": "我们提出了一种基于组件的检索架构，将数据库模式和元数据分解为离散的语义单元，并分别进行索引以实现精准检索。这种方法优先考虑有效的表识别，并利用列级别信息，确保检索的表数量在可管理的上下文预算内。我们的实验表明，该方法能够保持高召回率和准确性，且在不同结构和元数据可用性的大型数据库中，我们的系统优于基准方法。我们的解决方案使得通用的基于文本到SQL的系统无需特定的调整即可部署在多样化的企业环境中，解决了自然语言数据库接口在扩展性上的关键缺口。", "conclusion": "我们提出的方法在保持高召回率和准确性的前提下，解决了非专门领域调整所带来的部署复杂性问题，并充分利用了数据库元数据中的语义上下文。这使得我们的技术能够适用于各种多元化的企业环境，跨越了一个自然语言数据库接口扩展性上的关键缺口。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23042", "html_url": "https://arxiv.org/abs/2507.23042", "title": "实时视觉语言驾驶中的早期目标引导多尺度融合", "title_en": "Early Goal-Guided Multi-Scale Fusion for Real-Time Vision-Language Driving", "authors": "Santosh Patapati,Trisanth Srinivasan", "background": "自动驾驶车辆在毫秒内作出响应并需要结合道路几何和交通意图进行复杂情况导航。现有的架构通常依赖于循环记忆结构，但这会导致响应延迟并可能引入不稳定因素。本研究旨在设计一种实时高效的视觉-语言处理架构，以改进自动驾驶车辆的导航性能。", "innovation": "该研究提出了一种名为NovaDrive的单支路视觉-语言架构，能够同时处理前视摄像头图像、高精度地图切片、LiDAR深度数据和文本路线点信息。特别引入了轻量级、两阶段交叉注意力模块，以提高对高精度地图和图像深度细节的关注度。此外，该架构结合了一种新型平滑损失函数，以减缓急转向和速度变化，从而省去了循环记忆的需要，并提升了实时推理能力。", "conclusion": "在MD-NEX户外基准测试的数据子集中进行的实验表明，NovaDrive显著提高了成功率（84%提升4%）、路径效率（SPL提升了0.11）并减少了碰撞频率（从2.6%降至1.2%）。消融实验证明了路线点信息的使用、部分VLM微调和交叉注意力融合对于改进性能的重要性。此外，该方法还降低了路径长度和可能带来的燃料或电池消耗，为更高效和易于更新的自动驾驶系统开辟了新的可能性。NovaDrive还能够扩展到其他嵌入式AI领域。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23160", "html_url": "https://arxiv.org/abs/2507.23160", "title": "扩展因子机退火方法用于快速发现透明导电材料", "title_en": "Extended Factorization Machine Annealing for Rapid Discovery of Transparent Conducting Materials", "authors": "Daisuke Makino,Tatsuya Goto,Yoshinori Suga", "background": "对于下一代器件（如太阳能电池和显示器），提高性能和降低制造成本的关键是开发新型透明导电材料（TCMs）。此项研究聚焦于(Al$_x$Ga$_y$In$_z$)$_2$O$_3$系统研究，并改进了FMA框架（将因子机与退火相结合），以精确且经济高效地搜索最佳组分和晶体结构。", "innovation": "该项研究对FMA框架进行扩展，引入了以下创新点：（i）连续变量的二进制化处理；（ii）好解通过霍普菲尔德网络的利用；（iii）自适应随机翻转激活全局搜索；（iv）通过位串局部搜索进行微调。实验验证表明，该方法在透明导电材料搜索速度和准确性方面优于贝叶斯优化和遗传算法；该方法还能够在多目标优化中同时考虑带隙和形成能量。", "conclusion": "该方法有望加速更大的、更复杂的研究问题以及更广泛的材料设计，使其能够更好地符合实际实验条件，从而推动材料信息学的进一步发展。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23018", "html_url": "https://arxiv.org/abs/2507.23018", "title": "大规模科学AI中的数据准备", "title_en": "Data Readiness for Scientific AI at Scale", "authors": "Wesley Brewer,Patrick Widener,Valentine Anantharaj,Feiyi Wang,Tom Beck,Arjun Shankar,Sarp Oral", "background": "本文研究了人工智能（AI）数据准备原则（Data Readiness for AI, DRAI）在用于训练基础模型的大规模领导级科学数据集中的应用。通过分析气候、核融合、生物医学/健康和材料这四个代表性领域的典型工作流程，识别出通用的预处理模式和特定领域的约束条件。", "innovation": "提出了一种二维准备框架，包括数据准备级别（从原始数据到AI准备工作就绪）和数据处理阶段（从导入到切片），这些都针对高性能计算（HPC）环境进行了定制。该框架列出了转换科学数据以支持可扩展的AI训练的关键挑战，特别强调了基于转换器的生成模型。这些维度共同形成了一个概念上的成熟矩阵，用于描述科学数据的准备情况，并指导基础设施开发以标准化和跨领域支持大规模、可重现的AI科学。", "conclusion": "该框架指出了科学数据在实现可扩展和可重复的AI训练中的关键挑战，并通过标准化和跨领域的基础设施支持，为科学领域的大规模AI提供了框架和指导。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23174", "html_url": "https://arxiv.org/abs/2507.23174", "title": "基于CNN的农业环境中芒果分类解决方案", "title_en": "CNN-based solution for mango classification in agricultural environments", "authors": "Beatriz Díaz Peón,Jorge Torres Gómez,Ariel Fajardo Márquez", "background": "本文描述了一种利用卷积神经网络（CNN）进行水果检测和分类的设计。目的是开发一个系统，能够自动评估水果质量以进行农场存货管理。特别是，本研究通过图像处理开发了芒果分类方法，确保准确性和效率。", "innovation": "研究选择了Resnet-18作为初步分类架构，并使用级联检测器进行检测，以平衡执行速度和计算资源消耗。通过MatLab App Designer开发的图形界面展示了检测和分类结果，简化了系统交互。结合卷积神经网络和级联检测器提供了一种可靠的水果分类和检测解决方案，具有在农业质量控制中应用的潜力。", "conclusion": "该系统将卷积神经网络和级联检测器整合起来，提供了一种可靠且有效的水果分类和检测方案，特别适用于农业环境中的水果质量控制。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23208", "html_url": "https://arxiv.org/abs/2507.23208", "title": "荐推系统是否具有自我意识？基于模型不确定性的无标记推荐性能评估", "title_en": "Are Recommenders Self-Aware? Label-Free Recommendation Performance Estimation via Model Uncertainty", "authors": "Jiayu Li,Ziyi Ye,Guohao Jian,Zhiqiang Guo,Weizhi Ma,Qingyao Ai,Min Zhang", "background": "本文探讨了推荐系统的自我意识，通过量化其不确定性来提供其性能的无标记估计，从而在推荐系统与用户互动之前提供更明智的理解和决策。现有研究中，推荐系统的性能评估通常依赖于标签，而本文尝试提供一种无标记的方法。", "innovation": "提出了基于概率的列表分布不确定性（LiDu）方法。该方法通过确定推荐系统根据个体项目预测分布生成特定排名列表的概率来测量不确定性。并通过合成数据集和实际推荐算法在真实数据集上验证了LiDu方法的有效性。", "conclusion": "实验结果表明，LiDu与推荐性能的相关性比一系列无标记性能估计器更强。此外，LiDu还提供了对模型在训练和推理过程中的动态内部状态有价值的理解。本文建立了推荐不确定性与性能之间的实证联系，迈出了更透明和自我评估推荐系统的一步。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23209", "html_url": "https://arxiv.org/abs/2507.23209", "title": "不仅仅是什么，而是何时：将不规则时间间隔集成到LLM以进行序列推荐", "title_en": "Not Just What, But When: Integrating Irregular Intervals to LLM for Sequential Recommendation", "authors": "Wei-Wei Du,Takuma Udagawa,Kei Tateno", "background": "现有的方法在序列推荐任务中主要关注项目序列，通常假设项目之间的间隔是静态的，从而忽略了时间间隔动态变化对用户行为和偏好描述的重要性。动态时间间隔不仅刻画了用户的浏览历史，还描述了不同用户在相同项目历史下的行为差异。", "innovation": "提出了IntervalLLM框架，该框架将时间间隔信息整合到LLM中，并引入了新颖的时间间隔注入注意力机制，以同时考虑物品信息和时间间隔信息。此外，引入了时间间隔视角来评估推荐方法在暖启动和冷启动场景中的表现，不同于以往只从用户和物品视角解决冷启动问题的方法。", "conclusion": "实验结果显示，IntervalLLM不仅实现了4.4%的平均改进，还在所有用户、项目和提出的间隔视角下实现了最佳的推荐效果。特别从时间间隔视角来看，冷启动场景的表现下降最为显著，提示了在序列推荐任务中进一步研究基于间隔的冷启动挑战的需求。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23155", "html_url": "https://arxiv.org/abs/2507.23155", "title": "在非凸简单 bilevel 优化中查找稳态点的复杂性", "title_en": "On the Complexity of Finding Stationary Points in Nonconvex Simple Bilevel Optimization", "authors": "Jincheng Cao,Ruichen Jiang,Erfan Yazdandoost Hamedani,Aryan Mokhtari", "background": "本文研究了解一个简单的 bilevel 优化问题，其中上层目标是在下层问题的解集中最小化。研究关注上下层目标函数均为光滑但可能非凸的一般情况。由于无法提供额外的结构假设（如凸性和PL条件）来确保全局最优性，因此一般难以确保全局最优性。本文通过引入特定的稳态概念来应对这一挑战。", "innovation": "提出了一个简单的动态障碍梯度下降（DBGD）框架的变体，能够有效地解决非凸简单 bilevel 优化问题直至稳态点。该方法的复杂性在达到目标稳态精度 $\text{ε_f}$ 和 $\text{ε_g}$ 时为 $\text{O}\big(\text{max}\big(\text{ε_f}^{-\frac{3+p}{1+p}}, \text{ε_g}^{-\frac{3+p}{2}}\big)\big)$，其中 $p \text{ ≥ 0}$ 是平衡常数。这是首次构建的针对一般非凸简单 bilevel 优化问题在离散时间算法中保证两个层面都达到稳态的复杂性结果。", "conclusion": "本文通过引入稳态点概念和设计的DBGD框架的变体，成功解决了非凸简单 bilevel 优化问题直至达到特定的稳态精度，并提供了计算复杂性结果，填补了该领域的一个空白。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23194", "html_url": "https://arxiv.org/abs/2507.23194", "title": "GEAK：引入Triton内核AI代理及评估基准", "title_en": "Geak: Introducing Triton Kernel AI Agent & Evaluation Benchmarks", "authors": "Jianghui Wang,Vinay Joshi,Saptarshi Majumder,Xu Chao,Bin Ding,Ziqiong Liu,Pratik Prabhanjan Brahma,Dong Li,Zicheng Liu,Emad Barsoum", "background": "随着对可扩展和硬件优化解决方案的需求在工业和学术界快速增长，AI生成的GPU内核的需求也在快速增长。为了应对复杂多样的深度学习工作负载，需要自动化低级内核开发以满足性能和生产力的需求。云提供商、半导体公司和研究机构正在大力投资基于AI的GPU代码生成，目标是减少手动优化努力并实现接近专家级别的硬件性能。Triton语言作为一种基于Python的GPU编程DSL，因其性能和编码简便性而成为支持AI生成内核的目标语言。在此工作中，我们提出了一套评估Triton内的GPU内核和GEAK（生成高效AI中心GPU内核）的评估基准。GEAK是一个利用前沿LLM生成适合AMD GPU（包括AMD MI300X和MI250）的高效Triton代码的框架。", "innovation": "GEAK框架利用推理阶段的计算扩展，结合反射样式反馈机制的推理循环，生成适用于AMD GPU的Triton内核。相较于直接提示前沿LLM和基于反射的生成管道，GEAK在两个评估基准上显著超出基线，达到63%的正确率和2.59倍的执行速度增益。这项研究展示了GEAK类似代理人代码生成技术在加速多样化硬件平台应用和普及专家级内核性能方面的潜力和优势", "conclusion": "GEAK在实现高效Triton内核方面表现卓越，突显了基于代理的代码生成技术的潜力，有助于促进各种硬件平台的广泛使用和提高访问专家级内核性能的民主化程度。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23220", "html_url": "https://arxiv.org/abs/2507.23220", "title": "模型方向，而非词语：使用稀疏自编码器的机制主题模型", "title_en": "Model Directions, Not Words: Mechanistic Topic Models Using Sparse Autoencoders", "authors": "Carolina Zheng,Nicolas Beltran-Velez,Sweta Karlekar,Claudia Shi,Achille Nazaret,Asif Mallik,Amir Feder,David M. Blei", "background": "传统的主题模型在大型文本集合中发现潜在主题方面非常有效。然而，由于依赖于词语袋表示，它们难以捕捉到语义上的抽象特征。尽管一些神经变体利用更丰富的表示方式，但它们也受限于将主题表示为词列表，这限制了它们表达复杂主题的能力。", "innovation": "我们提出了机制主题模型（MTMs），这是一个基于可解释特征的类别，这些特征通过稀疏自编码器（SAEs）学习而来。通过在这一语义丰富的空间上定义主题，MTMs能够揭示更具表现力的主题描述的深刻概念主题。此外，与其他主题模型不同，MTMs能够通过基于主题的引导向量实现可控的文本生成。为了公平评估MTM主题与基于词列表的方法，我们提出了基于LLM的配对比较评价框架——主题评判(Topic Judge)。", "conclusion": "在五个数据集上，MTMs在连贯性指标上的效果与传统的和神经的基线相当或更好，一致性地受到主题评判的偏好，并能有效引导LLM输出。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23297", "html_url": "https://arxiv.org/abs/2507.23297", "title": "通过神经蒙特卡罗调整的基于仿真推理在精确中微子物理中的应用", "title_en": "Simulation-based inference for Precision Neutrino Physics through Neural Monte Carlo tuning", "authors": "A. Gavrikov,A. Serafini,D. Dolzhikov,A. Garfagnini,M. Gonchar,M. Grassi,R. Brugnera,V. Cerrone,L. V. D'Auria,R. M. Guizzetti,L. Lastrucci,G. Andronico,V. Antonelli,A. Barresi,D. Basilico,M. Beretta,A. Bergnoli,M. Borghesi,A. Brigatti,R. Bruno,A. Budano,B. Caccianiga,A. Cammi,R. Caruso,D. Chiesa,C. Clementi,C. Coletta,S. Dusini,A. Fabbri,G. Felici,G. Ferrante,M.G. Giammarchi,N. Giudice,N. Guardone,F. Houria,C. Landini,I. Lippi,L. Loi,P. Lombardi,F. Mantovani,S.M. Mari,A. Martini,L. Miramonti,M. Montuschi,M. Nastasi,D. Orestano,F. Ortica,A. Paoloni,L. Pelicci,E. Percalli,F. Petrucci,E. Previtali,G. Ranucci,A.C. Re,B. Ricci,A. Romani,C. Sirignano,M. Sisti,L. Stanco,E. Stanescu Farilla,V. Strati,M.D.C Torri,C. Tuvè,C. Venettacci,G. Verde,L. Votano", "background": "下一代中微子实验需要精确建模探测器的能量响应，这由于缺乏分析性似然函数带来了计算挑战。这项研究提出了一种解决方案，即在基于仿真推理框架中使用神经似然估计。模型需要处理校准数据中的非线性和强相关性，这对于参数推断而言是一个挑战.", "innovation": "开发了两种互补的神经密度估计器，即条件归一化流和基于变压器的回归器，用于建模校准数据的似然性。通过结合归一化流模型和变压器模型，该框架提供了灵活的选择，可为特定需求选择最合适的方法。研究采用JUNO实验作为案例研究，通过与贝叶斯嵌套采样结合实现了仅受限于统计结果和近乎零系统偏差的参数推断精度.", "conclusion": "我们的方法为类似应用提供了模板，涵盖了实验中微子物理学和更广泛的粒子物理学领域。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23242", "html_url": "https://arxiv.org/abs/2507.23242", "title": "使用非结构化现实世界文档的通用强化学习针对检索器特定查询重写器", "title_en": "Generalized Reinforcement Learning for Retriever-Specific Query Rewriter with Unstructured Real-World Documents", "authors": "Sungguk Cha,DongWook Kim,Taeseung Hahn,Mintae Kim,Youngsub Han,Byoung-Ki Jeon", "background": "检索增强生成（RAG）系统高度依赖于有效的查询形式来解锁外部知识，但对于多样且未结构化的现实世界文档优化查询仍然是一项挑战。", "innovation": "提出了一种名为RL-QR的强化学习框架，用于特定检索器的查询重写，该框架无需人工标注数据集，适用于文本和多模态数据库，借助通用化奖励策略优化（GRPO），训练出符合特定检索器的查询重写器，提升了跨多种领域的检索性能。实验结果显示，在工业一手数据中取得了显著改进，多模态RAG系统中的RL-QR表现尤为突出，NDCG@3提升了11%，而词汇检索器的RL-QR提升了9%。但是对于语义和混合检索器，查询重写器未能提升检索性能，这可能由于训练对齐问题。这项研究表明，RL-QR有可能彻底改变RAG系统的查询优化，提供了一种可扩展的、无需标注的现实世界检索任务解决方案，并指出对语义检索进一步完善的方向。", "conclusion": "研究结果表明RL-QR框架具有潜力来革新RAG系统的查询优化，并指出其在语义检索方面需要进一步改进。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23227", "html_url": "https://arxiv.org/abs/2507.23227", "title": "使用LLMs在表格生物标记数据上实现少量样本的阿尔茨海默病诊断", "title_en": "Enabling Few-Shot Alzheimer's Disease Diagnosis on Tabular Biomarker Data with LLMs", "authors": "Sophie Kearney,Shu Yang,Zixuan Wen,Bojian Hou,Duy Duong-Tran,Tianlong Chen,Jason Moore,Marylyn Ritchie,Li Shen", "background": "阿尔茨海默病(AD)是一种复杂的神经退行性疾病，需要通过多样的生物标志物（如影像学、遗传风险因素、认知测试和脑脊液蛋白质）进行早期和准确的诊断。通常这些生物标志物以表格形式呈现。灵活的少量样本推理、多模态整合以及自然语言解释使得大型语言模型（LLMs）对于结构化生物医学数据具有前所未有的预测能力。然而，尽管先前有一些工作使用LLMs进行预测，但它们未能充分利用表格生物标记数据的潜力。", "innovation": "本文提出了一种名为TAP-GPT的新框架，这是一种适应TableGPT2的框架，TableGPT2最初是为商务智能任务设计的多模态表格专有大型语言模型。TAP-GPT框架利用TableGPT2强大的表格理解能力及LLMs编码的先验知识，胜过更先进的通用大型语言模型和用于预测任务的表格基础模型。TAP-GPT主要创新点在于将LLMs应用于以表格形式呈现的生物标记数据的预测任务，并使用参数高效的方式对模型进行微调。", "conclusion": "这是首次将LLMs应用于表格生物标记数据的预测任务。这为未来基于LLMs的多智能体框架在生物医学信息学中的发展铺平了道路。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23167", "html_url": "https://arxiv.org/abs/2507.23167", "title": "LENS: 从神经状态学习集成置信度以实现多大型语言模型答案集成", "title_en": "LENS: Learning Ensemble Confidence from Neural States for Multi-LLM Answer Integration", "authors": "Jizhou Guo", "background": "大型语言模型（LLMs）在多种任务中展现出卓越的性能，不同模型在特定领域和能力上表现出色。有效地结合多个LLM的预测对于增强系统的鲁棒性和性能至关重要。然而，现有的集成方法通常依赖于简单技术如投票或logits集成，这些方法忽视了模型在不同上下文中的置信度和可靠性差异。", "innovation": "本文提出了一种名为LENS（Learning ENsemble confidence from Neural States）的新方法，它通过分析内部表示来学习估计模型的置信度。对于每个LLM，训练一个轻量级的线性置信度预测器，该预测器利用逐层隐藏状态和归一化概率作为输入。这种方法允许基于模型在不同上下文中的可靠性来进行更细腻的权重分配。该方法不需要修改模型参数，并且不需要额外的计算。", "conclusion": "实验结果表明，LENS在多项选择和布尔问题回答任务中显著优于传统集成方法。我们的研究结果表明，内部表示提供了确定模型置信度的有价值信号，并且可以有效利用于集成学习中。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23349", "html_url": "https://arxiv.org/abs/2507.23349", "title": "最优运输出学习：在个体化治疗规则中平衡价值优化与公平性", "title_en": "Optimal Transport Learning: Balancing Value Optimization and Fairness in Individualized Treatment Rules", "authors": "Wenhai Cui,Xiaoting Ji,Wen Su,Xiaodong Yan,Xingqiu Zhao", "background": "个体化治疗规则（ITRs）在精准医疗、共享出行和广告推荐等领域得到了广泛的应用。然而，当ITRs受到种族、性别或年龄等敏感属性的影响时，可能会导致某些群体被不公平地优势或劣势对待。因此，本文提出了一种基于最优运输出理论的灵活方法，能够将任何最优ITR转化为公平的ITR，确保人口统计学公平。", "innovation": "本文提出了一种改进的贸易平衡ITR方法，能够在优化价值和公平性之间找到平衡点，同时通过参数调整适应不同的公平性水平。此外，本文还提出了一个平滑的公平性约束来估计可调参数，并建立了改进的平衡ITR在特定公平性水平下价值损失的理论上限。", "conclusion": "通过广泛的模拟研究和Next 36创业项目数据的应用，本文证明了所提方法的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23334", "html_url": "https://arxiv.org/abs/2507.23334", "title": "MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation", "title_en": "MUST-RAG: MUSical Text Question Answering with Retrieval Augmented Generation", "authors": "Daeyong Kwon,SeungHeon Doh,Juhan Nam", "background": "大型语言模型（LLMs）在多个领域展示了强大的零样本性能，但在音乐相关应用中的表现仍受到限制，因为它们的训练数据中音乐专业知识的比例较小。为了克服这一限制，本文提出了一个基于检索增强生成（RAG）框架的解决方案，名为MusT-RAG，该框架旨在将通用语言模型适应于文本音乐问答任务（MQA）.", "innovation": "MusT-RAG框架引入了MusicWikiDB，这是专为音乐检索而设计的向量数据库；在推理和微调阶段充分利用上下文信息，实现了从通用语言模型到音乐专用模型的有效转变。实验结果表明，与传统的微调方法相比，MusT-RAG在提升LLMs的音乐领域适应性方面表现出显著优势，尤其是在领域内和领域外的MQA基准测试上均取得了持续的性能改进。此外，MusicWikiDB相比通用的维基百科语料库更为有效，提供了更高的性能和计算效率.", "conclusion": "MusT-RAG显著改善了大型语言模型在音乐领域内的应用效果，通过引入MusicWikiDB和优化RAG机制，展示了在文本音乐问答任务上的强大能力改进。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23348", "html_url": "https://arxiv.org/abs/2507.23348", "title": "SWE-Debate：软件问题解决的竞争性多代理辩论", "title_en": "SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution", "authors": "Han Li,Yuling Shi,Shaoxin Lin,Xiaodong Gu,Heng Lian,Xin Wang,Yantao Jia,Tao Huang,Qianxiang Wang", "background": "大型语言模型的高级推理能力使得问题解决取得了显著进展。基于代理的方法，如SWE-agent，进一步促进了这一进展，使自主的、使用工具的代理能够处理复杂的软件工程任务。现有的基于代理的问题解决方法主要依赖于代理的独立探索，这往往会陷入局部解决方案，无法识别跨代码库不同部分的模式问题。", "innovation": "提出了一种称为SWE-Debate的竞争性多代理辩论框架，鼓励多样化的推理路径以实现更集中的问题定位。通过生成多个故障传播追踪，并组织三轮辩论，满足不同故障传播视角的代理能协作优化并确定一个完整的修复方案。最后，该综合修复方案被集成到一个基于MCTS的代码修改代理中以生成补丁。实验表明，SWE-Debate在开源代理框架中达到了新的最先进的技术水平，并显着优于基线方法。", "conclusion": "SWE-Debate框架通过组织多轮辩论促进多样化的代理推理，从而实现了更集中的问题定位，并通过MCTS优化生成补丁，实现先进结果。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23361", "html_url": "https://arxiv.org/abs/2507.23361", "title": "SWE-Exp：经验驱动的软件问题解决", "title_en": "SWE-Exp: Experience-Driven Software Issue Resolution", "authors": "Silin Chen,Shaoxin Lin,Xiaodong Gu,Yuling Shi,Heng Lian,Longfei Yun,Dong Chen,Weiguo Sun,Lin Cao,Qianxiang Wang", "background": "大型语言模型（LLM）代理在软件问题解决方面取得了显著进展，借助多代理协作和蒙特卡罗树搜索（MCTS）等先进技术。然而，当前的代理系统缺乏记忆功能，每个问题独立解决，不保留或重用之前的修复经验，导致重复探索失败路径并错失了将成功的修复方法应用于类似问题的机会。", "innovation": "提出了SWE-Exp，一种经验增强的方法，从之前的代理轨迹中提炼出简洁且可操作的经验，使软件修复能力持续提升。该方法引入了一个多层次的经验库，能够捕捉成功的和失败的修复尝试，自高至低提取可复用的修复知识，如问题理解到具体代码更改。实验表明，SWE-Exp在开源代理框架下的SWE-bench-Verified中展示了最先进的解决率（41.6% Pass@1）。", "conclusion": "SWE-Exp确立了一个新的自动软件工程代理范式，实现系统地积累和利用修复经验，从试错式探索转变为基于经验的有策略的修复解决。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23315", "html_url": "https://arxiv.org/abs/2507.23315", "title": "轻量级深度学习模型的超参数优化对实时图像分类准确性的影响", "title_en": "Impact of Hyperparameter Optimization on the Accuracy of Lightweight Deep Learning Models for Real-Time Image Classification", "authors": "Vineet Kumar Rakesh,Soumya Mazumdar,Tapas Samanta,Sarbajit Pal,Amitabha Das", "background": "轻量级卷积和Transformer模型已经成为资源受限应用中实时图像分类的关键，如嵌入式系统和边缘设备。为了分析轻量级模型的超参数调整对其性能的影响，本文基于ImageNet-1K数据集，对EfficientNetV2-S、ConvNeXt-T、MobileViT v2（XXS/XS/S）、MobileNetV3-L、TinyViT-21M和RepVGG-A2这七种高效的深度学习架构进行实证研究。这些模型在一致的训练设置下被训练，并重点关注实时性能。实验涵盖学习率调度、批量大小、输入分辨率、数据增强、正则化方法和优化器选择等关键超参数的影响。所有模型不仅基于Top-1和Top-5分类准确率，还在GPU加速的边缘部署模拟环境中，基于推理时间、参数量、模型大小和每秒帧数（FPS）进行评估，以确定它们适合实时应用的适用性。结果表明，余弦学习率衰减和可调整的批量大小能够显著提升准确性和收敛速度，同时保持低延迟和低内存成本。RepVGG-A2模型的高效推理性能使其在VGG风格的模型中提供了很好的准确性和部署成本平衡。", "innovation": "本文通过实证分析了关键超参数对轻量级深度学习模型在实时图像分类中的影响，特别是余弦学习率衰减和可调整的批量大小的有效性，对于构建资源高效能的实时图像处理系统具有指导意义。此外，该研究还通过GPU加速的边缘部署模拟环境中的全面评估，提供了具体的数据支持，使研究结果更具实用性。研究成果公开可获取，有助于进一步的研究和应用发展。", "conclusion": "通过实验验证，关键超参数，尤其是余弦学习率衰减和可调整的批量大小，对提升轻量级深度学习模型在实时图像分类中的性能有显著影响。研究结果提供了实用的指导，有助于设计和构建适合实时图像处理的资源高效模型。RepVGG-A2作为一种平衡了准确性和部署成本的轻量化深度学习模型，具有实际应用潜力。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23248", "html_url": "https://arxiv.org/abs/2507.23248", "title": "评估大规模语言模型在孟加拉语多语言能力：基准创建和性能分析", "title_en": "Evaluating LLMs' Multilingual Capabilities for Bengali: Benchmark Creation and Performance Analysis", "authors": "Shimanto Bhowmik,Tawsif Tashwar Dipto,Md Sazzad Islam,Sheryl Hsu,Tahsin Reasat", "background": "孟加拉语在自然语言处理（NLP）研究中处于未被充分代表的地位。这主要是由于其独特的语言结构以及计算限制所带来的挑战。本文系统性地探讨了阻碍孟加拉语NLP性能的挑战，特别关注缺乏标准化评估基准的问题。研究还评估了10个最近的开源大型语言模型在8个翻译数据集上的性能，并进行了全面的错误分析，以确定它们的主要失败模式。研究表明，与英语相比，孟加拉语的性能差距在较小的模型和特定模型家族（如Mistral）中尤为明显。同时，研究表明某些架构如DeepSeek在稳定性方面表现出了潜力，能够在跨语言环境中保持更好的性能。分析还揭示了标记化效率与语言模型准确率之间的反比关系，其中当输入过度标记化时，模型的性能会变差，而更高效的、简洁的标记化则能提升性能。", "innovation": "本文创新点在于系统性地评估了10个开源大型语言模型在孟加拉语数据集上的多语言能力，通过构建基准并进行全面的错误分析来揭示这些模型在特定语言上的失败模式。同时，本文首次揭示了标记化效率与模型准确率之间的反比关系，并指出如何通过优化标记化过程来提高模型性能。此外，研究还指出了当前模型在某些方面存在的不足，并强调了需要改进多语言数据集的质量和评估方法。研究成果将推动对未被充分代表的语言的NLP研究，促进先进语言技术的更广泛普及。", "conclusion": "本文的研究结果揭示了当前模型在处理孟加拉语上的不足之处，并指出了关键问题领域。研究强调了需要改进多语言数据集的质量和评估方法。这些发现将推动进一步的NLP研究，特别是为那些没有得到充分关注的语言，如孟加拉语，提供重要的参考。未来的研究将进一步优化监测化技术和模型结构，以提高不同语言之间的模型性能。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23416", "html_url": "https://arxiv.org/abs/2507.23416", "title": "使用高光谱成像和机器学习检测蜂蜂蜜掺假", "title_en": "Honey Adulteration Detection using Hyperspectral Imaging and Machine Learning", "authors": "Mokhtar A. Al-Awadhi,Ratnadeep R. Deshmukh", "background": "当前市场上存在蜂蜜掺假的问题，尤其是使用糖浆来掺假。传统的化学检测方法往往存在操作复杂、成本较高且耗时较久等问题。因此，研究基于高光谱成像和机器学习的自动化检测系统成为一种新的解决方案，旨在提高检测效率和准确性。", "innovation": "该研究提出了一种基于机器学习的系统，能够自动检测蜂蜜中的糖浆掺假。首先通过植物来源识别子系统对蜂蜜的花卉来源进行分类，接着通过掺假检测子系统识别糖浆掺假并量化其浓度。该系统利用线性判别分析（LDA）提取特征，在此基础上采用K近邻（KNN）模型进行分类和量化检测。", "conclusion": "研究成果表明，所提出的系统能够达到96.39%的整体交叉验证准确率，表明该方法在蜂蜜掺假检测方面具有较好的性能，可以作为现有化学检测方法的有效替代方案。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23523", "html_url": "https://arxiv.org/abs/2507.23523", "title": "H-RDT: 增强双臂机器人操作的人类操作数据", "title_en": "H-RDT: Human Manipulation Enhanced Bimanual Robotic Manipulation", "authors": "Hongzhe Bi,Lingxuan Wu,Tianwei Lin,Hengkai Tan,Zhizhong Su,Hang Su,Jun Zhu", "background": "机器人操作的imitation learning面临的一大挑战是缺乏大量高质量的机器人示范数据。现有机器人基础模型常通过预先训练跨实体的机器人数据集以增加数据规模，但在不同机器人实体之间多样的形态和动作空间使得统一训练变得困难。", "innovation": "本文提出了一种名为H-RDT（Human to Robotics Diffusion Transformer）的新方法，利用人类操作数据来增强机器人操作能力。其关键见解在于大规模第一人称视角的人类操作视频及其配对的三维手部姿态标注，提供了丰富的行为先验知识，有助于机器人策略学习。该方法采用两阶段训练模式：首先是基于大规模第一人称视角的人类操作数据预训练，然后是跨实体的特定机器人数据微调，包含模块化的动作编码器和解码器。", "conclusion": "广泛的评估结果显示H-RDT在模拟和真实环境中的单任务和多任务场景下，以及少量样本学习和鲁棒性测试中均表现出色，优于从头训练和现有最先进的方法Pi0和RDT，在模拟和真实环境中的改进分别达到了13.9%和40.5%，验证了人类操作数据能够作为学习双臂机器人操作策略的强大基础。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23682", "html_url": "https://arxiv.org/abs/2507.23682", "title": "villa-X: 提升视觉语言动作模型中的隐含动作建模", "title_en": "villa-X: Enhancing Latent Action Modeling in Vision-Language-Action Models", "authors": "Xiaoyu Chen,Hangxing Wei,Pushi Zhang,Chuheng Zhang,Kaixin Wang,Yanjiang Guo,Rushuai Yang,Yucen Wang,Xinquan Xiao,Li Zhao,Jianyu Chen,Jiang Bian", "background": "视觉-语言-动作（VLA）模型已成为一种流行的范式，用于学习能够遵循语言指令并泛化到新型场景的机器人操作策略。近期的研究已经开始探索在VLA预训练中融入隐含动作，这是一种视觉两帧之间变化的抽象表示。", "innovation": "本文引入了villa-X，这是一种新颖的视觉-语言-隐含动作（ViLLA）框架，旨在推进隐含动作建模以学习可泛化的机器人操作策略。该方法改进了如何学习隐含动作以及将其如何融入到VLA预训练中。", "conclusion": "整体而言，这些贡献使得villa-X在Simpler和Libero等模拟环境中以及两个真实的机器人操作设置中表现出优异的性能，包括夹持器和灵巧手操作。我们认为ViLLA范式具有巨大的潜力，而我们的villa-X则为未来的研究提供了坚实的基础。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23455", "html_url": "https://arxiv.org/abs/2507.23455", "title": "机器学习与胸部X光图像的机器学习预测", "title_en": "Machine learning and machine learned prediction in chest X-ray images", "authors": "Shereiff Garrett,Abhinav Adhikari,Sarina Gautam,DaShawn Marquis Morris,Chandra Mani Adhikari", "background": "机器学习和人工智能是研究快速增长的领域，数据被用于训练算法、学习模式并进行预测。通过这种方法，可以在无需显式编程的情况下解决看似复杂的难题，通过识别数据中的复杂关系来提高准确度。本文以5824张胸部X光图像为例，实现了两种机器学习算法，即基础卷积神经网络(CNN)和DenseNet-121，并对使用机器学习进行疾病预测进行了分析。两种基础CNN和DenseNet-121在本文中的二分类问题表现都很好。梯度加权类别激活映射显示，DenseNet-121在决策过程中比基础CNN更准确地关注输入胸部X光图像中的关键部分。", "innovation": "本文通过DenseNet-121模型在胸部X光图像疾病预测中表现的优越性，展示了其在识别关键部位方面的竞争力，相较于基础的CNN模型，DenseNet-121更能准确地识别出关键的成像区域，从而提高预测准确性。", "conclusion": "DenseNet-121在胸部X光图像疾病的二分类预测问题上，表现出色，特别是梯度加权类别激活映射表明，它在决策过程中能够更准确地聚焦于输入图像的关键部分。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23443", "html_url": "https://arxiv.org/abs/2507.23443", "title": "使用扩散模型学习流形约束的基于伴随的气动形状优化", "title_en": "Adjoint-Based Aerodynamic Shape Optimization with a Manifold Constraint Learned by Diffusion Models", "authors": "Long Chen,Emre Oezkaya,Jan Rottmayer,Nicolas R. Gauger,Zebang Shen,Yinyu Ye", "background": "本文介绍了一种基于伴随的气动形状优化框架，该框架整合了一个以现有设计为训练基础的扩散模型，以学习气动可行形状的光滑流形。该流形作为形状优化问题的等式约束。关键在于计算设计目标（如阻力和升力）相对于流形空间的伴随梯度。这些梯度通过计算形状相对于传统形状设计参数（如Hicks-Henne参数）的导数，然后通过自动微分，反向传播到扩散模型的潜在空间来获得。该框架保留了数学严谨性，并且可以与现有的基于伴随的设计工作流无缝集成。通过使用现成的通用非线性优化器在广泛的跨音速湍流翼型设计案例中进行演示，这种方法消除了手动参数调优和变量缩放，保持了初始化和优化器选择的鲁棒性，并在气动性能方面超越了传统的优化方法。本研究展示了如何通过自动微分有效结合AI生成的先验与伴随方法，以实现稳健且高保真的气动形状优化。", "innovation": "该框架的关键创新在于它如何通过计算设计目标相对于流形空间的伴随梯度来实现气动形状优化。这种方法将计算形状设计参数的导数与反向传播结合使用，通过自动微分实现对扩散模型的反向传播，从而有效地利用扩散模型生成的先验知识。同时，该方法能够保持数学上的严格性，并且可以无缝集成到现有的基于伴随的设计工作流中，仅需轻微修改。此外，使用现成的通用非线性优化器进行优化，该方法能够消除手动参数调优和变量缩放的需求，并提高了优化性能的鲁棒性。", "conclusion": "该研究证明了AI生成的先验信息可以与伴随方法有效集成，从而通过自动微分实现稳健且高保真的气动形状优化。这种方法不仅提高了气动性能，还在初始化和优化器选择方面表现出更高的鲁棒性，为气动形状优化提供了一种新的高效途径。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23402", "html_url": "https://arxiv.org/abs/2507.23402", "title": "AGA：一种用于结构化医学跨模态表示学习的自适应组对齐框架", "title_en": "AGA: An adaptive group alignment framework for structured medical cross-modal representation learning", "authors": "Wei Li,Xun Gong,Jiao Li,Xiaobin Sun", "background": "在医学领域，从配对的医学图像和报告中学习医学视觉表示是一种有前途的方向。然而，现有的医学领域视觉-语言预训练方法往往将临床报告简化为单一实体或片段化令牌，忽略了其固有的结构。此外，对比学习框架通常依赖大量的困难负样本，这对小型医学数据集来说是不切实际的。", "innovation": "该论文提出了自适应组对齐（AGA）框架，这是一种新的方法可以从配对的医学图像和报告中捕获结构化的语义。AGA 引入了一种基于稀疏相似矩阵的双向分组机制。此外，设计了两种阈值门控模块，使分组阈值能够动态地学习，从而实现自适应分组。", "conclusion": "在公共和私人数据集上的广泛实验表明，该方法在细调和零样本设置下，在图像-文本检索和分类任务中取得了强大的性能。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23609", "html_url": "https://arxiv.org/abs/2507.23609", "title": "一致点匹配", "title_en": "Consistent Point Matching", "authors": "Halid Ziya Yerebakan,Gerardo Hermosillo Valadez", "background": "本文研究了将一致性直觉引入点匹配算法（参考文献：Yerebakan, S., et al. 2023. Hierarchical Point-Matching）在医学图像配准中的应用。研究者通过在不同类型的数据集上进行验证，展示了该方法的有效性和优越性。特别是它在Deep Lesion Tracking数据集上的表现超过了现有最先进的方法，且在保持图像配准准确性的同时，能够灵活调整速度和鲁棒性的权衡。对于处理标准CPU硬件上的医学图像配准任务而言，该算法具有高效性和灵活性。", "innovation": "本文创新性地提出了一种将一致性直觉融入点匹配算法的方法，该方法能够提高医学图像配准的鲁棒性。研究结果表明，该方法在不同类型医学图像的配准任务上表现出色，特别是在计算机断层扫描（CT）和磁共振成像（MRI）模态上的表现显著提升。此外，该方法还能够有效地解决解剖特征定位问题，并能在保持高精度的同时，通过调整配置实现速度和鲁棒性的权衡。", "conclusion": "本文的方法通过提高医学图像配准的鲁棒性、有效解决解剖特征定位问题以及在标准硬件上实现高效运行，展示了其在医学图像处理中的广泛应用前景。该方法能够在不依赖机器学习模型或训练数据的情况下，实现高精度的医学图像导航。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23740", "html_url": "https://arxiv.org/abs/2507.23740", "title": "Rule2Text：知识图谱中逻辑规则的自然语言解释", "title_en": "Rule2Text: Natural Language Explanation of Logical Rules in Knowledge Graphs", "authors": "Nasim Shirvani-Mahdavi,Devin Wingfield,Amin Ghasemi,Chengkai Li", "background": "知识图谱（KGs）通常包含足够信息来支持新事实的推理。识别逻辑规则不仅提高了知识图谱的完整性，还允许检测潜在错误，揭示数据细微模式，增强综合推理和解释能力。然而，这种规则的复杂性，加之每个KG的独特标记惯例，使其难以被人理解。", "innovation": "本文探索了大型语言模型生成逻辑规则自然语言解释的潜力。具体而言，使用AMIE 3.5.1 规则发现算法从基准数据集FB15k-237和两个大规模数据集FB-CVT-REV和FB+CVT-REV中提取逻辑规则。研究了包括零样本和少样本提示，变量实体类型和推理链条等多种提示策略。通过全面的人类评估，基于正确性、清晰度和幻想评估生成的解释，并评估了大型语言模型作为自动裁判的应用。", "conclusion": "我们的结果证明，解释的正确性和清晰性表现出色，尽管仍存在一些未来研究的挑战。本文中使用的所有脚本和数据均可在以下网址查看：this https URL this https URL。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23736", "html_url": "https://arxiv.org/abs/2507.23736", "title": "基于混合AI和规则驱动框架的DICOM去标识化，实现可扩展、具有不确定性的擦除", "title_en": "DICOM De-Identification via Hybrid AI and Rule-Based Framework for Scalable, Uncertainty-Aware Redaction", "authors": "Kyle Naddeo,Nikolas Koutsoubis,Rahul Krish,Ghulam Rasool,Nidhal Bouaynaya,Tony OSullivan,Raj Krish", "background": "医学成像及关联文本数据的访问潜力巨大，能够推动医疗健康研究和患者成果的重大进步。然而，DICOM文件中包含的保护医疗信息（PHI）和可识别个人身份信息（PII）成为阻碍数据伦理和安全共享的主要障碍。", "innovation": "本文介绍了Impact Business Information Solutions (IBIS) 开发的混合去标识化框架，结合了基于规则和技术驱动的AI方法，并通过严格的不确定性量化实现了全面的PHI/PII去除，涵盖元数据和像素数据。该框架首先使用两层基于规则的系统定位显式和隐式元数据元素，并通过微调大型语言模型和训练于合成数据集的命名实体识别（NER）管道增强。对于像素数据，采用具有不确定性的Faster R-CNN模型定位嵌入的文本，利用光学字符识别（OCR）提取候选的PHI，并通过NER管道进行最终的擦除。不确定性量化提供AI检测的信心度量，以增强自动化可靠性并允许人工干预验证以管理剩余风险。", "conclusion": "这种基于不确定性风险去标识化的框架在基准数据集和监管标准方面表现出稳健的性能，包括DICOM、HIPAA和TCIA合规性指标。通过结合可扩展的自动化、不确定性量化和严格的质保流程，该解决方案解决了医学数据去标识化中的关键挑战，并为科研提供了安全、伦理和可靠的成像数据释放支持。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23620", "html_url": "https://arxiv.org/abs/2507.23620", "title": "DivControl：基于知识转移的可控图像生成", "title_en": "DivControl: Knowledge Diversion for Controllable Image Generation", "authors": "Yucheng Xie,Fu Feng,Ruixiao Shi,Jing Wang,Yong Rui,Xin Geng", "background": "扩散模型从文本到图像 (T2I) 生成逐渐发展到图像到图像 (I2I) 生成，通过引入结构化的输入（如深度图）来实现细粒度的空间控制。然而，现有方法要么为每种情况训练单独的模型，要么依赖于具有纠缠表示的统一架构，这导致在面对新型条件时表现较差，且适应成本高。为解决这一问题，本文提出了DivControl，一个分解式预训练框架，用于统一可控生成和高效适应。该方法通过动态门机制在多条件训练过程中进行知识转移，将ControlNet分解为基本组件，将其分解为条件无关的learn genes和条件特定的tailors，从而实现零样本推广和参数高效的新型条件适应，同时引入了表示对齐损失，使条件嵌入与早期扩散特征对齐，提高条件准确性和训练效率。实验结果表明，DivControl在实现最佳可控性的同时，训练成本降低了36.4倍，平均性能也有所提升。此外，它还以强大的零样本和少量样本性能在未见条件中表现出色，证明了其优越的可扩展性、模块化和迁移性。", "innovation": "提出了DivControl，一种分解式预训练框架，用于统一可控生成和高效适应。通过分解ControlNet并通过多条件训练期间的知识转移分解为基本组件，将条件无关的learn genes和条件特定的tailors分离。使用动态门机制根据条件指令的语义进行知识转移，实现了零样本推广和参数高效的适应。引入表示对齐损失，使条件嵌入与早期扩散特征对齐，提高了条件准确性和训练效率。", "conclusion": "DivControl 实现了最佳可控性，训练成本降低了36.4倍，同时提升了基本条件的平均性能。在未见条件上，DivControl 也表现出强大的零样本和少量样本性能，展示了其卓越的可扩展性、模块化和迁移性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23773", "html_url": "https://arxiv.org/abs/2507.23773", "title": "SimuRA：通过基于LLM的世界模型仿真实现通用目标导向代理", "title_en": "SimuRA: Towards General Goal-Oriented Agent via Simulative Reasoning Architecture with LLM-Based World Model", "authors": "Mingkai Deng,Jinyu Hou,Yilin Shen,Hongxia Jin,Graham Neubig,Zhiting Hu,Eric Xing", "background": "当前基于大型语言模型（LLMs）的AI代理主要采用每个任务一个代理的方法，这种方法在可扩展性和普遍适用性方面存在不足，并且受到自回归LLMs固有限制的影响。相比之下，人类能够通过心理模拟来推断其行动和计划的结果，是一种通用的智能代理形式。", "innovation": "提出了SimuRA，这是一种通用代理推理的基于目标的架构，通过引入世界模型实现规划模拟，克服了自回归推理的限制。SimuRA使用LLM实现了一个通用的世界模型，能够在多种环境中灵活规划，利用自然语言内容丰富的潜在空间。实验表明，基于世界的模型规划在困难的网络浏览任务中表现优异，尤其是在飞行搜索任务中的成功率从0%提高到32.2%，且在所有对比测试中表现出了124%的优势。", "conclusion": "未来可能基于LLM训练出一个通用代理模型，能够在所有环境中表现出超级智能。作为第一步，提供了一个基于SimuRA构建的网络浏览代理作为研究演示，供公众测试。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23673", "html_url": "https://arxiv.org/abs/2507.23673", "title": "SAMSA: Segment Anything Model Enhanced with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation", "title_en": "SAMSA: Segment Anything Model Enhanced with Spectral Angles for Hyperspectral Interactive Medical Image Segmentation", "authors": "Alfie Roddan,Tobias Czempiel,Chi Xu,Daniel S. Elson,Stamatia Giannarou", "background": "高光谱成像（HSI）能够提供丰富的光谱信息，但面临着数据限制和硬件差异带来的重大挑战。现有方法在高光谱影像分割方面存在不足。", "innovation": "提出了一种名为SAMSA的新型交互式分割框架，结合了RGB基础模型和光谱分析。该方法利用用户点击来指导RGB分割和光谱相似性计算，通过独特且与光谱带数和分辨率无关的光谱特征融合策略解决了高光谱影像分割的关键局限。", "conclusion": "实验证实在公共数据集上的性能评估显示SAMSA在通过1次和5次点击进行的分割任务中分别达到了81.0%和93.4%以及81.1%和89.2%的Dice分数。实验结果显示SAMSA在少量标注数据学习场景和零样本学习场景中均表现出有效性，并且能够无缝集成不同光谱特性数据集，提供了一种灵活的高光谱医学图像分析框架。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23767", "html_url": "https://arxiv.org/abs/2507.23767", "title": "使用缩放Beta模型和特征稀释进行动态票务定价", "title_en": "Scaled Beta Models and Feature Dilution for Dynamic Ticket Pricing", "authors": "Jonathan R. Landers", "background": "介绍了用于识别二级票务市场中特定行为签名的新型方法，通过分析动态定价分布进行分析。使用来自SeatGeek API的新建时序数据集，将票务定价分布建模为缩放的Beta分布，从而利用混合分位数匹配和矩方法从不完整的统计数据中进行准确的参数估计。将估计出的α和β参数纳入随机森林分类器中，显著提高了艺术家分类的准确性，证明了事件定价数据中的独特经济特征。此外，提供了理论和实验证据，证明将零方差（常数值）特征纳入随机森林模型作为隐式正则化，增强了特征多样性和模型鲁棒性，促进了更深层次、更多样化的树结构，改善了偏差-方差权衡，减少对主导特征的过拟合。这些发现不仅在新的票务定价数据集上得到验证，还在标准UCI ML手写数字数据集上也得到验证。", "innovation": "提出了利用缩放Beta分布模型和零方差特征作为隐式正则化方法来改进随机森林分类器，特别是在动态票务定价中识别艺术家的分类准确性有了显著提高。", "conclusion": "研究结果表明，通过使用缩放Beta分布模型和特征稀释方法，能够更准确地估计和分类票务定价中的不同特征，提高了模型的鲁棒性和多样性，改善了偏差-方差权衡，减少了过拟合。这种方法不仅在新票务定价数据集上有效，还能应用于其他类型的数据集，如手写数字识别。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23768", "html_url": "https://arxiv.org/abs/2507.23768", "title": "通过整体风险先验的正式贝叶斯迁移学习", "title_en": "Formal Bayesian Transfer Learning via the Total Risk Prior", "authors": "Nathan Wycoff,Ali Arab,Lisa O. Singh", "background": "在数据受限的情况下，通过在目标数据集中添加应用领域中的辅助数据集（称为源数据集）的信息，可以显著改善统计方法。现有的迁移学习方法在处理源数据集也同样受限且与目标数据集不完全对齐的情况时遇到困难。一个普遍的策略是使用源数据集上的经验损失最小化器作为目标参数的先验均值，这将源参数的估计置于贝叶斯形式之外。", "innovation": "我们的核心贡献在于使用在给定源参数条件下的风险最小化器作为先验。这使得我们可以从源数据集和目标数据集的所有参数中构造一个单一的联合先验分布。因此，我们从全贝叶斯不确定性量化中受益，并且可以通过吉布斯抽样来进行指标变量控制的每个源数据集的模型平均。", "conclusion": "我们的方法在特定情况下导致了变换坐标系中的贝叶斯Lasso。我们还讨论了方法扩展到中型数据集的计算技术，并表明最近提出的一些最小最大-频率主义迁移学习技术可以被看作是对我们模型的近似最大后验。最后，我们在遗传学应用中展示了相对于频率主义基准的预测性能的优越性，特别是在源数据集受限的情况下。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23777", "html_url": "https://arxiv.org/abs/2507.23777", "title": "XSpecMesh：通过多头推测解码保留品质的自回归网格生成加速", "title_en": "XSpecMesh: Quality-Preserving Auto-Regressive Mesh Generation Acceleration via Multi-Head Speculative Decoding", "authors": "Dian Chen,Yansong Qu,Xinyang Li,Ming Li,Shengchuan Zhang", "background": "当前的自回归模型可以生成高质量、拓扑精确的网格，但这些模型在推断期间需要进行成千上万甚至是数万的下一个标记预测，导致了显著的延迟。", "innovation": "提出了XSpecMesh，这是一种用于加速自回归网格生成模型的质量保持加速方法。XSpecMesh采用了一种轻量级的多头推测解码方案来在同一前向传播过程中并行预测多个令牌，从而加快了推断。此外，提出了一种验证和重采样策略：主干模型验证每个预测的令牌，并重采样任何不满足质量标准的令牌。还提出了一种蒸馏策略，通过从主干模型蒸馏来训练轻量级解码头部，鼓励它们的预测分布与主干模型对齐，从而提高推测预测的成功率。", "conclusion": "大量的实验表明，我们的方法在不牺牲生成质量的情况下实现了1.7倍的加速。我们的代码将被发布。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2206.03234", "html_url": "https://arxiv.org/abs/2206.03234", "title": "多类分类器中的不同条件预测", "title_en": "Disparate Conditional Prediction in Multiclass Classifiers", "authors": "Sivan Sabato,Eran Treister,Elad Yom-Tov", "background": "本文提出的方法用于审计具有多类目标的分类器的公平性，特别是在不完全公平的前提下量化其偏离等化预测概率的程度。研究了原始由Sabato & Yom-Tov（2020）提出的二元分类器上提出的不等条件预测（DCP）的概念并将其拓展到了多类分类器上。提供的两种不同的方法可以在已知或未知各受保护子人群的条件混淆矩阵的情况下，估算DCP值。这些方法能够用于检测这些分类器可能因不公平处理较大的人群比例。实验结果表明这些方法的准确性。相关的代码已发布于提供链接的GitHub存储库上，标记为DCPmulticlass。", "innovation": "将不等条件预测（DCP）的测量从二分类器拓展到了多分类器领域，并开发了两种基于局部优化的方法，一种是在条件混淆矩阵可获取的情况下，另一种是在无法获取的情况下，用于估算多分类器的DCP。这些方法有助于识别可能广泛不公平对待人口的分类器。", "conclusion": "研究结果验证了所开发方法的准确性，并提出了评估多类别分类器不平等的专门工具，该工具在两种不同条件下均可应用。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23784", "html_url": "https://arxiv.org/abs/2507.23784", "title": "SUB: 基于合成属性替换评估 CBM 通用性的基准", "title_en": "SUB: Benchmarking CBM Generalization via Synthetic Attribute Substitutions", "authors": "Jessica Bader,Leander Girrbach,Stephan Alaniz,Zeynep Akata", "background": "概念瓶颈模型（CBMs）和其他基于概念的可解释模型展示了使AI应用更加透明的巨大潜力，这对于医学等领域尤为重要。尽管取得了一定的成效，但研究表明，CBMs在数据分布变化的情况下难以可靠地识别正确的概念。为了评估CBMs在概念变化下的稳健性，本文提出了SUB基准，该基准基于CUB数据集，包含38,400张合成图像，涉及33个鸟类类别和45个概念的替换。通过这种方法，研究人员能够精准地控制生成的图片，并评估CBMs在面对概念变异时的性能。", "innovation": "引入了基于合成属性替换的SUB基准，该方法基于CUB数据集生成了38,400张合成图像，涉及33个鸟类类别和45个概念的替换。此外，还提出了一种新颖的Tied Diffusion Guidance (TDG)方法，用于精确控制生成的图像，确保两个去噪过程能够生成正确的鸟类类别和正确属性的图像。这些创新方法不仅贡献了更加严格的CBMs评估基准，还促进了更稳健的可解释模型开发方法的提出。", "conclusion": "该研究引入了SUB基准，通过合成属性替换评估CBMs的通用性，提出了TDG方法精确控制生成图像。这些创新有助于提高CBMs和其他可解释AI模型的可靠性，对于医疗等领域中透明AI的应用具有重要意义。相关代码和数据集已发布。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.01621", "html_url": "https://arxiv.org/abs/2407.01621", "title": "从非干预复杂系统中解析干预动力因果关系", "title_en": "Deciphering interventional dynamical causality from non-intervention complex systems", "authors": "Jifan Shi,Yang Li,Juan Zhao,Siyang Leng,Rui Bao,Kazuyuki Aihara,Luonan Chen,Wei Lin", "background": "因果关系的检测与量化是科学、工程和跨学科研究中的一个重要课题。然而，对非干预系统的因果研究虽然引起了广泛关注，但仍然极具挑战性。延迟嵌入技术为解决这一问题提供了一种有前景的方法。", "innovation": "研究提出了一种名为Interventional Dynamical Causality (IntDC)的新框架，与传统的Constructive Dynamical Causality (ConDC)相对。IntDC通过延迟嵌入空间提出了一个计算标准Interventional Embedding Entropy (IEE)，可以在不考虑干预的情况下，从观测数据中解析出因果关系。IEE可以在没有了解动力模型或系统实际干预信息的情况下，对因果效应按重要性进行排名，并构建因果网络。与传统的指标相比，IEE能够准确找到因果关系，消除混淆因素的影响，并对因果强度进行稳健的量化。", "conclusion": "IntDC框架和IEE算法为从复杂非干预系统的时间序列数据中研究因果关系提供了一种有效的方法。IEE作为一种准确且稳健的工具，仅从观测数据中进行因果分析。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.13265", "html_url": "https://arxiv.org/abs/2406.13265", "title": "具有多体等变交互作用的分子图网络", "title_en": "Molecule Graph Networks with Many-body Equivariant Interactions", "authors": "Zetian Mao,Chuan-Shen Hu,Jiawen Li,Chen Liang,Diptesh Das,Masato Sumita,Kelin Xia,Koji Tsuda", "background": "消息传递神经网络在预测分子相互作用方面显示出显著的有效性。在引入等变矢量表示以捕捉几何数据对称性并提高模型准确性的同时，二元键向量在相反方向上的消息传递可能会相互抵消，导致共享节点的方向信息丢失。因此，现有的消息传递方案在捕捉分子方向对称信息方面存在局限性。", "innovation": "本文提出了一种名为Equivariant N-body Interaction Networks (ENINet)的新方法，它明确地整合了l = 1等变多体交互作用，以增强消息传递方案中的方向对称信息。作者进行了数学分析证明了引入多体等变交互作用的必要性，并将其公式推广到了N体交互作用。实验结果表明，融合多体等变表示可以提高在各种标量和张量化学性质预测中的准确性。", "conclusion": "研究提出了ENINet，通过引入多体等变交互作用提升了分子图网络在预测化学性质中的性能，从而增强了方向对称信息的捕捉能力。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.15738", "html_url": "https://arxiv.org/abs/2407.15738", "title": "全局采样下的并行分割学习", "title_en": "Parallel Split Learning with Global Sampling", "authors": "Mohammad Kohankhaki,Ahmad Ayad,Mahdi Barhoush,Anke Schmeink", "background": "在资源受限环境中分布式深度学习面临着可扩展性和泛化能力的挑战，这主要是由于大批次大小和参与设备数据不一致导致的。现有的方法难以同时提升效率和模型的准确性。", "innovation": "引入了一种由服务器驱动的采样策略，能够维持固定的全局批次大小，通过动态调整客户端批次大小来分离开有效批次大小和参与设备数量之间的关系，确保全局批次更好地反映整体数据分布。通过标准的累积界限，建立了更紧的偏差保证，优于现有方法。", "conclusion": "实验结果表明，所提出的方法能够提高模型精度、训练效率和收敛稳定性，提供了一种网络边缘的大规模学习的可扩展解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2306.01654", "html_url": "https://arxiv.org/abs/2306.01654", "title": "闭式IPM-GAN判别器指导在扩散建模中的见解", "title_en": "Insights into Closed-form IPM-GAN Discriminator Guidance for Diffusion Modeling", "authors": "Aadithya Srikanth,Siddarth Asokan,Nishanth Shetty,Chandra Sekhar Seelamantula", "background": "扩散模型是当前最先进的生成建模框架，通过Langevin采样将噪声转换为图像，受到数据分布的得分引导。最近的研究表明，在生成对抗网络（GAN）设置中训练的判别器指导下的生成质量可以得到提高。本文提出了一种理论框架，用于分析GAN判别器对Langevin采样的影响，并展示了IPM-GAN优化可以看作是平滑的得分匹配中的一种，其中得分由数据分布和生成分布与IPM相关的核函数卷积得到。基于这些见解，应用闭式核引导判别器能够提高基线扩散模型的CLIP-FID和KID指标。这项工作在不同标准数据集上的去噪扩散隐式模型（DDIM）和潜在扩散模型（LDM）设置中进行了验证，并显示了该方法可以与现有的加速扩散技术结合使用以改进潜在空间图像生成。", "innovation": "本文提出了一种理论框架来分析GAN判别器对Langevin采样的影响，将IPM-GAN优化视为一种平滑的得分匹配，其中得分由数据分布和生成分布与IPM相关的核函数卷积得到。闭式核引导判别器能够提高基线扩散模型的生成质量，应用于DDIM和LDM等设定中，并与加速扩散技术相结合提高潜在空间图像生成效果。", "conclusion": "闭式核引导判别器能够改善基线扩散模型在CLIP-FID和KID指标上的性能，适用于DDIM和LDM等不同标准数据集，并且可以与加速扩散技术结合使用以提升潜在空间图像生成效果。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.03080", "html_url": "https://arxiv.org/abs/2407.03080", "title": "在数据稀缺场景中通过人工归纳偏置生成合成表格数据的方法", "title_en": "Artificial Inductive Bias for Synthetic Tabular Data Generation in Data-Scarce Scenarios", "authors": "Patricia A. Apellániz,Ana Jiménez,Borja Arroyo Galende,Juan Parras,Santiago Zazo", "background": "使用深度生成模型（DGMs）生成合成表格数据可以有效解决数据稀缺和隐私问题，但这些模型的有效性依赖于大量的训练数据，而在真实世界场景中这往往是不可得的。因此，虽然DGMs提供了潜在的解决方案，但它们的应用受到了训练数据不足的限制。", "innovation": "本文提出了一种新颖的方法，该方法通过在生成过程中明确地整合人工归纳偏置来提高数据质量，特别是针对数据稀缺的情况。该框架利用迁移学习和元学习技术来构建和注入具有信息性的归纳偏置到DGMs中。通过对四种方法（预训练、模型平均、模型无关元学习（MAML）和领域随机搜索（DRS））的研究和分析，验证了引入归纳偏置对生成文本质量的显著提升效果，尤其是在Jensen-Shannon 标记下的表现。实验结果表明，迁移学习方法的表现优于元学习方法，最高可实现60%的Jensen-Shannon 发散度提高。该方法具有模型无关性，并特别适用于如医疗和金融等领域，这些领域需要高质量的合成数据并且数据可用性有限。", "conclusion": "本研究提出的方法显著提高了生成合成数据的质量，特别是在数据稀缺的情况下，通过使用迁移学习技术获得了显著的提升效果，特别是在Jensen-Shannon 发散度方面，其表现优于其他方法。该技术对于需要高质量合成数据的医疗和金融等领域特别有价值。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.03158", "html_url": "https://arxiv.org/abs/2402.03158", "title": "最优和近最优自适应向量量化", "title_en": "Optimal and Near-Optimal Adaptive Vector Quantization", "authors": "Ran Ben-Basat,Yaniv Ben-Itzhak,Michael Mitzenmacher,Shay Vargaftik", "background": "量化是许多机器学习应用中的基础优化方法，包括压缩梯度、模型权重和激活值以及数据集。最准确的量化方法是自适应量化，它是根据给定输入来最小化误差，而不是针对最坏情况优化。然而，最优自适应量化方法在实际操作中因运行时间和内存要求高而难以实现。", "innovation": "作者重新审视了自适应向量量化（AVQ）问题，并提出了算法以获得渐近改进的时间和空间复杂度下的最优解。对于大规模输入，作者还提出了一个更快的近最优算法。实验表明，这些算法可能为自适应向量量化在各种机器学习应用中的广泛应用开启了大门。", "conclusion": "该研究提供了用于自适应向量量化的新算法，提高了复杂度并实现了近最优解，从而为自适应向量量化在机器学习中的广泛应用打开了新思路。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.15544", "html_url": "https://arxiv.org/abs/2501.15544", "title": "推进电力车辆互联网中的生成型人工智能和大型语言模型的需求侧管理", "title_en": "Advancing Generative Artificial Intelligence and Large Language Models for Demand Side Management with Internet of Electric Vehicles", "authors": "Hanwen Zhang,Ruichen Zhang,Wei Zhang,Dusit Niyato,Yonggang Wen,Chunyan Miao", "background": "生成型人工智能，尤其是大型语言模型（LLMs），有望改变微电网中的能源优化和需求侧管理（DSM）。本文探讨了将LLMs集成到能源管理中的方式，强调了其在通过互联网实现电动汽车策略自动化优化中的作用。文章分析了实施DSM所面临的挑战及其解决方案，并探索了利用LLMs带来的新机遇。", "innovation": "提出了一种创新解决方案，通过检索增强生成来增强LLMs，实现自动问题表述、代码生成和优化定制。该解决方案在电动汽车充电调度和优化方面进行了案例研究，展示出显著的能源效率和用户适应性提升。", "conclusion": "本文强调了LLMs在能源优化方面的潜力，并促进了一个新的智能DSM解决方案时代。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.09486", "html_url": "https://arxiv.org/abs/2410.09486", "title": "ActSafe：在强化学习中具有安全约束的主动探索", "title_en": "ActSafe: Active Exploration with Safety Constraints for Reinforcement Learning", "authors": "Yarden As,Bhavya Sukhija,Lenart Treven,Carmelo Sferrazza,Stelian Coros,Andreas Krause", "background": "强化学习（RL）在现代AI系统的发展中无处不在。然而，最先进的RL代理需要大量的、且可能不安全的与环境的交互来有效地学习。这些限制使RL代理局限于模拟环境中，阻碍了它们直接在真实世界环境中学习的能力。本文探讨了在强化学习中具有安全约束的主动探索问题，并提出了一种称为ActSafe的新模型导向RL算法。ActSafe学习了一个关于系统的校准概率模型，并以关于未知动力学的epsilon不确定性进行乐观规划，同时对安全性约束进行悲观处理。在某些约束和动力学的正则性假设下，论文展示了ActSafe在学习过程中保证安全的同时，也能在有限时间内获得接近最优的策略。此外，论文还提出了一种基于最新模型导向RL发展的实用的ActSafe变体，它能够在高维环境中（如视觉控制）实现安全探索。", "innovation": "ActSafe是一种新的模型导向RL算法，它通过学习系统的校准概率模型并进行乐观的epistemic不确定性规划，与悲观的安全约束处理相结合，保证了在学习过程中安全的同时也能实现接近最优的策略。特别地，它的实用变体能够实现在高维环境中的安全探索，扩展了其应用场景。", "conclusion": "实验结果表明，ActSafe在标准的安全深度RL基准测试中的复杂探索任务中取得了最先进的性能，同时确保了学习过程中的安全性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00123", "html_url": "https://arxiv.org/abs/2412.00123", "title": "使用多核高斯过程回归结合核支持向量回归进行电价预测", "title_en": "Electricity Price Prediction Using Multi-Kernel Gaussian Process Regression Combined with Kernel-Based Support Vector Regression", "authors": "Abhinav Das,Stephan Schlüter,Lorenz Schneider", "background": "目前存在用于预测德国电价的新混合模型，该模型结合了高斯过程回归（GPR）和支持向量回归（SVR）。尽管GPR在学习数据中的随机模式以及插补方面表现良好，但其在样本外数据上的性能不太令人满意。因此，通过选择适合的数据依赖性协方差函数来提高GPR在测试的德国每小时电力价格上的性能。然而，由于样本外预测依赖于训练数据，因此会受到噪声和异常值的影响。为了克服这一问题，使用SVR进行单独预测，SVR采用基于边界优化的方法，这对于处理非线性过程和异常值特别有利，仅需训练数据中的一部分必要点（支持向量）来进行回归。", "innovation": "该研究提出了一种结合多核GPR和基于核的SVR的新混合模型。该模型通过对噪音和异常值敏感的GPR进行改进，并使用SVR进行非线性和异常值处理，最后通过均匀权重线性组合个体预测结果。", "conclusion": "当应用于历史德国电力价格时，这种方法在性能上优于现有的公开基准，包括最近研究中的深神经网络和LASSO估计的自回归回归模型。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.08727", "html_url": "https://arxiv.org/abs/2501.08727", "title": "通过张量分解实现的变换低秩适应及其在文本到图像模型中的应用", "title_en": "Transformed Low-rank Adaptation via Tensor Decomposition and Its Applications to Text-to-image Models", "authors": "Zerui Tao,Yuhta Takida,Naoki Murata,Qibin Zhao,Yuki Mitsufuji", "background": "参数高效微调（PEFT）技术在从文本生成图像的模型中越来越受欢迎。其中，低秩适应（LoRA）及其变体由于其有效性而受到广泛关注，使用户能够在限制计算资源的情况下进行模型微调。然而，低秩假设与期望的微调权重之间的近似差距阻碍了同时获得超参数效率和更好性能的能力。", "innovation": "该研究提出了一种新的PEFT方法，该方法结合了两类适应：变换适应和残差适应。首先，通过一个满秩且密集的变换应用到预训练权重上，这个可学习的变换有助于使预训练权重尽可能接近期望权重，从而减少剩余权重的秩。然后，剩余部分可以通过更紧凑和参数高效的结构进行有效近似，同时减少近似误差。设计了灵活且高效的张量分解，用于变换和残差适应，使得实践中的超参数效率成为可能。此外，流行的PEFT方法如DoRA都可以归入此变换加残差适应方案。", "conclusion": "实验结果表明，该方法在稳定扩散模型的驱动主题生成和可控生成中，可以实现与LoRA和其他基准方法相比更好的性能和参数效率。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.12098", "html_url": "https://arxiv.org/abs/2412.12098", "title": "MaxInfoRL: 通过最大化信息增益提高强化学习中的探索", "title_en": "MaxInfoRL: Boosting exploration in reinforcement learning through information gain maximization", "authors": "Bhavya Sukhija,Stelian Coros,Andreas Krause,Pieter Abbeel,Carmelo Sferrazza", "background": "强化学习（RL）算法旨在平衡利用当前最佳策略与探索可能导致更高奖励的新选项之间的关系。大多数常见的RL算法使用无向探索，即选择随机的动作序列。探索也可以通过内生奖励（如好奇心或模型的先验不确定性）来引导。然而，有效地平衡任务和内生奖励是具有挑战性的，通常需要根据任务进行调整。", "innovation": "本文引入了MaxInfoRL框架，该框架通过最大化内生奖励（如关于底层任务的信息增益）来引导探索。当与波兹曼探索结合使用时，这种方法自然地在价值函数的最大化与状态、奖励和动作的熵的最大化之间进行取舍。实验表明，在简化情况下的多臂bandit场景中，我们的方法实现了亚线性遗憾。本文将这种方法应用于多种连续状态-动作空间的离策略无模型RL方法，生成了在复杂探索问题和复杂场景（如视觉控制任务）中表现出卓越性能的新算法。", "conclusion": "MaxInfoRL框架将内生探索与外生探索良好结合，有效地在最大化价值函数与最大化状态、奖励和动作的熵之间进行权衡，适用于多种RL方法。通过理论分析和实验证明，我们的方法在探索问题中表现出卓越的性能。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2409.17092", "html_url": "https://arxiv.org/abs/2409.17092", "title": "大型语言模型的积算器感知后训练量化", "title_en": "Accumulator-Aware Post-Training Quantization for Large Language Models", "authors": "Ian Colbert,Giuseppe Franco,Fabian Grob,Jinjie Zhang,Rayan Saab", "background": "在量化权重和激活值的过程中，随着表示越来越窄，加法操作的成本开始超过乘法操作的成本。最近的研究表明，通过低精度累加减少加法成本可以提升推理平台下的吞吐量、能耗和面积，但增加了溢出风险。迄今为止，积算器感知的量化研究仅考虑了量化感知训练（QAT）模式，在这种模式下，模型在量化过程中进行微调或从零开始训练。由于模型和数据集的持续增大，QAT技术的成本越来越高，因此最近涌现出了大量的后训练量化（PTQ）研究来填补这一缺口。为了弥合这一差距，我们引入了AXE，这是第一个专门为PTQ算法提供溢出避免保证的积算器感知量化框架。我们通过在两种现有算法GPFQ和OPTQ上实现AXE，展示了其灵活性。我们设计AXE支持多级累加，这为全数据通路优化打开了大门。在最近的语言生成模型上评估AXE时，对Llama3 8B进行16位多级累加数据通路量化时，AXE保持了高达98%的半精度困惑度，超过了简单的位宽调整多达15%。", "innovation": "我们引入了AXE，这是第一个专门为后训练量化（PTQ）算法提供溢出避免保证的积算器感知量化框架。AXE支持多级累加，首次为全数据通路优化打开了大门。我们在GPFQ和OPTQ上实现AXE，展示了其灵活性。通过在Llama3 8B上进行评估，该方法提供了显著的性能提升，保持了高困惑度，超过了传统的位宽调整方法。", "conclusion": "AXE提供了一种积算器感知的后训练量化方法，能够避免量化过程中的溢出，并保持高性能。在多级累加数据通路上进行量化时，AXE能够显著提升语言模型性能。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.05177", "html_url": "https://arxiv.org/abs/2408.05177", "title": "使用神经算子进行统计混沌系统的模拟", "title_en": "Coarse Graining with Neural Operators for Simulating Chaotic Systems", "authors": "Chuwei Wang,Julius Berner,Zongyi Li,Di Zhou,Jiayun Wang,Jane Bae,Anima Anandkumar", "background": "准确预测混沌系统的长期行为对气候建模等应用至关重要，但通常需要密集的空间和时间网格的迭代计算，这在实际应用中代价高昂且不切实际。一种替代方法是对粗糙网格进行模拟，然后通过闭合模型校正误差，该模型近似了粗糙网格模拟中未捕捉的精细尺度信息。虽然已有机器学习方法用于闭合建模，但它们通常需要昂贵的全解析模拟大量训练样本。然而，根据本文的研究，标准的闭合模型学习方法会因非唯一映射而导致泛化误差，不论模型大小如何。本文提出了一个利用物理感知神经算子(PINO)的端到端学习方法，克服了这一局限，避免使用闭合模型或粗糙网格求解器。该方法先在粗糙网格模拟的数据上训练PINO模型，然后使用少量全解析模拟和基于物理的损失在精细网格上进行微调。神经算子的无网格化特征意味着它们不受粗糙网格闭合模型的限制，并能可靠地近似混沌系统的长期统计特性。在实验中，PINO模型比全解析模拟快330倍，相对误差约为10%，而结合粗糙网格模拟的闭合模型比PINO模型慢60倍，并且误差高达186%。", "innovation": "本文提出的端到端学习方法利用了不使用闭合模型和粗糙网格求解器的物理感知神经算子（PINO），克服了闭合模型学习方法因非唯一映射产生的泛化误差。PINO模型先在粗糙网格模拟的数据上训练，然后使用少量全解析模拟和基于物理的损失在精细网格上进行微调，从而克服了传统闭合模型的局限性。此外，PINO模型在实验中展示了显著的计算效率和预测准确性。", "conclusion": "本文提出的物理感知神经算子（PINO）方法在预测混沌系统长期行为方面展示了显著优势，尽管需要少量的全解析模拟数据，但相较于传统的粗糙网格模拟和闭合模型方法，具有更高的计算效率和准确性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.19792", "html_url": "https://arxiv.org/abs/2412.19792", "title": "InfAlign：考虑推理的语言模型对齐", "title_en": "InfAlign: Inference-aware language model alignment", "authors": "Ananth Balashankar,Ziteng Sun,Jonathan Berant,Jacob Eisenstein,Michael Collins,Adrian Hutter,Jong Lee,Chirag Nagpal,Flavien Prost,Aradhana Sinha,Ananda Theertha Suresh,Ahmad Beirami", "background": "语言模型对齐是训练现代生成性语言模型的关键步骤，其目标是在对齐模型的样本与基模型对比中提高胜率。随着我们在推理时越来越多地使用诸如Best-of-N、受控解码、树搜索等算法来从语言模型解码，而不是使用标准采样方法，这种训练与测试不匹配使得标准的RLHF框架不太适用于这些推理时的算法。现有的方法并不能完全优化对齐策略在推理时的性能，因此需要一种新的框架来解决这个问题，使得对齐策略在推理时的胜率最优。", "innovation": "该论文提出了一种考虑推理的语言模型对齐框架（InfAlign），以优化对齐策略在推理时相对于基模型的胜率。研究证明，对于任何推理时的解码过程，最优对齐策略是标准RLHF问题的解决方案，并为此提出了一种激励修正和奖励转换的RL算法（InfAlign-CTRL），该算法涉及奖励调节步骤和基于转换后的校准奖励的KL正则化奖励最大化步骤。此外，还为Best-of-N采样和Best-of-N解码限制提出了具体的转换方法，可提高推理时的胜率达3-8%。研究表明，该奖励校准方法对于优化标准胜率也是一个强大的基线方法。", "conclusion": "该研究提出了一种考虑推理的语言模型对齐框架（InfAlign），并证明了最优对齐策略是标准RLHF问题的解决方案。他们提出了一种激励修正和奖励转换的RL算法（InfAlign-CTRL）来解决这一问题。此方法在推理时对齐策略的胜率上表现出显著改进，并为进一步优化标准胜率提供了强有力的基础。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.10610", "html_url": "https://arxiv.org/abs/2408.10610", "title": "使用ARMA模型近似平稳过程", "title_en": "On the Approximation of Stationary Processes using the ARMA Model", "authors": "Anand Ganesh,Babhrubahan Bose,Anand Rajagopalan", "background": "本文探讨了自回归移动平均（ARMA）模型与真实平稳过程之间的逼近误差问题。具体而言，文章分析了如何量化一个真实平稳过程$X_t$与一个ARMA模型$Y_t$之间的逼近误差，并展示了如何使用平稳过程的传递函数表示$x(L)$来研究逼近误差。文章内容基于ARMA模型在统计信号处理和时间序列分析中的广泛应用，旨在提供更精确的建模方法以降低逼近误差，提高预测精度和模型的实用性。", "innovation": "文章的创新点在于发现了一种基于$L^{\fty}$范数的分析方法，该方法不仅能够有效控制Wold系数的$\boldsymbol{\rm \boldsymbol{l}}^2$范数，还能使ARMA模型所在的某一子空间在$L^{\boldsymbol{\rm \boldsymbol{l}}}^{\boldsymbol{\rm \boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{)}}}}}}}_\boldsymbol{\rm \boldsymbol{1}}$范数下的规范结构与$H^{\boldsymbol{\rm \boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{)}}}}}}}_\boldsymbol{\rm \boldsymbol{\boldsymbol{1}}$传递函数的乘法结构相一致，从而改善了 cepstral 范数在ARMA模型中的结构特性。同时，这种方法在非-ARMA过程中也表现更佳，优于维纳的$\boldsymbol{\rm \boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{)}}}}}}}_1$条件下的表现。此外，文章还计算了连续传递函数的显式逼近界值，并对Padé逼近和精简模型的某种启发式思想进行了批评。", "conclusion": "本文研究表明，使用$L^{\boldsymbol{\rm \boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{\boldsymbol{)}}}}}}}_\boldsymbol{\rm \boldsymbol{1}}$范数作为ARMA模型的范数，不仅能够在理论上提供一种更为精确和一致的倒数定义，而且在实际应用中能够更好地适应非-ARMA过程的建模需求。这种方法克服了传统范数方法在处理非-ARMA过程时的局限性，为平稳过程逼近提供了一种更有效的建模手段。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.13544", "html_url": "https://arxiv.org/abs/2503.13544", "title": "基于深度集成的监督学习决策：稳健的投资组合优化的实用框架", "title_en": "Decision by Supervised Learning with Deep Ensembles: A Practical Framework for Robust Portfolio Optimization", "authors": "Juhyeong Kim,Sungyoon Choi,Youngbin Lee,Yejin Kim,Yongmin Choi,Yongjae Lee", "background": "本文提出了一种名为Decision by Supervised Learning (DSL)的实用框架，用于稳健的投资组合优化。该框架将投资组合构建重新定义为一个监督学习问题，通过交叉熵损失和最大化夏普或索丁比率来训练模型预测最优投资组合权重。进一步提高了稳定性和可靠性，DSL采用深度集成方法，显著降低了投资组合分配的方差。通过广泛回测多个市场领域和神经网络架构，DSL的性能优于传统策略以及领先的机器学习方法，包括预测导向学习和端到端学习。", "innovation": "本文提出的DSL框架将投资组合构建视为监督学习问题，并且采用了深度集成方法来增强框架的稳定性和可靠性。DSL通过广泛的实验证明了其在不同市场环境和神经网络架构下的优越性能，并指出集成规模的增加可以带来更高的中位回报和更稳定的风险调整后表现。", "conclusion": "DSL框架通过深度集成和监督学习方法提供了比传统和先进机器学习方法更稳定和可靠的解决方案，适用于多样化的市场环境。该研究为投资组合优化提供了一个实用且强大的框架，未来的工作可以通过增加训练数据量和改进模型架构来进一步完善DSL。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2501.16325", "html_url": "https://arxiv.org/abs/2501.16325", "title": "通过元学习从短时间序列进行定制化预测", "title_en": "Tailored Forecasting from Short Time Series via Meta-learning", "authors": "Declan A. Norton,Edward Ott,Andrew Pomerance,Brian Hunt,Michelle Girvan", "background": "机器学习模型可以从时间序列数据有效地预测动力系统，但通常需要大量的历史数据，这使得对于数据有限的历史系统预测变得非常具有挑战性。", "innovation": "Introduces Meta-learning for Tailored Forecasting using Related Time Series (METAFORS)，这是一种通用方法，通过学习长时间序列数据集合中的模型知识，使模型能够在数据有限的场景中为短时间序列数据进行定制化预测。", "conclusion": "通过实验，展示METAFORS能够在无需极值上下文标签的情况下可靠地预测短期和长期统计信息，即使被测试系统和相关系统表现差异较大，证明其在数据有限场景中的优势。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.06210", "html_url": "https://arxiv.org/abs/2502.06210", "title": "通过进化实现深度连续学习", "title_en": "Achieving Deep Continual Learning via Evolution", "authors": "Aojun Lu,Junchao Ke,Chunhui Ding,Jiahao Fan,Jiancheng Lv,Yanan Sun", "background": "尽管深度神经网络在许多领域表现出色，但它们在连续学习（CL）方面仍存在根本限制。当前大多数方法都集中在增强单一模型的能力上。本文受到人类群体共同学习机制的启发，提出了进化连续学习（ECL）框架，该框架维护并发展了一种多样化的人工神经网络模型群体，ECL不断为每个新增的任务寻找最优架构。这一量身定制的模型被专门训练，并作为专家存档，为技能集合的不断增长做出贡献。这种方法从本质上解决了CL的核心挑战：通过隔离专家模型实现稳定性，通过进化独特的、任务特定的架构大幅提高可塑性。实验结果表明，ECL 显著优于最先进的个体水平的CL方法。通过从个体适应转向群体进化，ECL 为AI系统朝着CL能力的提升开辟了一条新的路径。", "innovation": "本文提出了进化连续学习（ECL）框架，这是一种维护和发展多样化神经网络模型群体的方法。ECL连续搜索每个新增任务的最优架构，专门训练并作为专家存档，从而实现模型间的隔离，同时进化出独特的、任务特定的架构，提高了可塑性。实验结果表明ECL显著超越了当前最先进的个体级CL方法。", "conclusion": "通过从个体适应转向群体进化，ECL为实现连续学习提供了一种新的路径，不仅解决了应用场景中的稳定性问题，还增强了可塑性，展示了一种更为有效的连续学习方法。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17264", "html_url": "https://arxiv.org/abs/2502.17264", "title": "Kandinsky Conformal Prediction: 超越类别和协变量条件覆盖的齐普夫尔森预测", "title_en": "Kandinsky Conformal Prediction: Beyond Class- and Covariate-Conditional Coverage", "authors": "Konstantina Bairaktari,Jiayun Wu,Zhiwei Steven Wu", "background": "齐普夫尔森预测是一种强大的非参数框架，用于构建具有覆盖率保证的预测集。传统方法，例如分割齐普夫尔森预测，提供了边际覆盖率，确保预测集包含随机测试点的标签，但这些保证可能在不同的子群体中并不统一，导致覆盖率差异。在此之前的工作探索了依赖于测试点协变量和标签的事件的覆盖率保证。", "innovation": "本文提出了Kandinsky齐普夫尔森预测框架，该框架显著扩大了条件覆盖率保证的范围。不同于Mondrian齐普夫尔森预测仅限制保证给不交组，我们的框架灵活处理覆盖和标签上的重叠和部分组成员身份，反映了Wassily Kandinsky作品中的层次交织形式。该算法统一并扩展了现有方法，包括协变量基组条件、类别条件和Mondrian齐普夫尔森预测作为特殊情况，同时实现了最小最大最优的高概率条件覆盖率界。", "conclusion": "最终，通过在实际数据集上的实证评估展示了我们方法的实际可行性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.10403", "html_url": "https://arxiv.org/abs/2504.10403", "title": "Space 计算网络中基础模型的卫星联合微调", "title_en": "Satellite Federated Fine-Tuning for Foundation Models in Space Computing Power Networks", "authors": "Yan Zhu,Jingyang Zhu,Ting Wang,Yuanming Shi,Chunxiao Jiang,Khaled Ben Letaief", "background": "随着人工智能（AI）和低地球轨道（LEO）卫星的发展，大型遥感基础模型在多种下游任务中的应用越来越广泛。然而，直接在地面对这些模型进行微调受到隐私保护和带宽限制的阻碍。卫星联邦学习（FL）能够通过在卫星上进行模型微调并聚合模型更新来解决这一问题，但传统的卫星联邦学习框架对于大型基础模型来说计算能力不足。为了应对这一挑战，该研究提出了一个卫星与地面协作的联邦微调框架。", "innovation": "该框架的关键在于合理地分解和分配模型组件，以缓解卫星上的计算能力不足问题。为了应对卫星及其间特殊的通信拓扑带来的通信挑战（如间歇性的卫星-地面通信、卫星-地面通信窗口的短暂以及星间链路的不稳定性），研究提出了并行轨道内通信策略、拓扑感知卫星-地面通信策略以及延迟最小化的星间通信策略，以减少空间通信成本。实验结果显示，该方法在训练时间上取得了显著的改进，大约提高了33%。", "conclusion": "通过卫星与地面的协作框架，能够有效解决卫星计算能力不足和通信挑战的问题，进而实现在空间计算网络中对大型基础模型进行高效的联合微调。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.16283", "html_url": "https://arxiv.org/abs/2504.16283", "title": "情感模型对异常语音的适应性较差", "title_en": "Affect Models Have Weak Generalizability to Atypical Speech", "authors": "Jaya Narain,Amrit Romana,Vikramjit Mitra,Colin Lea,Shirley Ren", "background": "语音和声音条件会影响语音的声学特性，这可能会对人们异常语音中副语言模型对情感表现的影响产生影响。为此，作者将一些公开可用的语音情感识别模型在异常语音数据集上进行了评估，与正常语音数据集的性能进行了比较。研究表明，不同类型和程度的异常语音都会显著影响情感模型的输出。具体而言，与正常语音数据集相比，所有类型和级别的异常语音中预测为悲伤的比例明显更高。此外，还探讨了基于文本和语音预测自发语音中情感维度（如愉悦度和唤醒度）的相关性，并发现对于异常语音，基于虚假标签进行微调的模型在提高鲁棒性方面表现出色。", "innovation": "研究首次系统地评估了现成的语音情感识别模型在异常语音数据集上的表现，并发现这些模型在异常语音上的适应性较差。特别是，对异常语音进行微调的模型能够提升在异常语音上的表现，同时不对正常语音的性能产生负面影响。这一发现强调了训练和评估数据集的多样性需求，以及需要开发能够应对声音和语音差异的建模方法的重要性。", "conclusion": "研究结果表明，异常语音对现成的语音情感识别模型的适应性有显著影响。因此，研究结果强调了需要更广泛的训练和评估数据集以及能够应对声音和语音差异的建模方法的必要性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.00830", "html_url": "https://arxiv.org/abs/2505.00830", "title": "Intersectional Divergence: Measuring Fairness in Regression", "title_en": "Intersectional Divergence: Measuring Fairness in Regression", "authors": "Joe Germino,Nuno Moniz,Nitesh V. Chawla", "background": "当前关于机器学习公平性的研究主要集中在分类任务上，而在回归任务中则存在关键性的缺口。现有工作往往侧重于单一受保护属性的公平性，忽略了保护性属性组合的公平性。因此，需要一种新的方法来衡量和改进回归任务的公平性。", "innovation": "本文提出了一种新的公平性测量方法——Intersectional Divergence (ID)，它不仅考虑了所有保护属性的组合，还提出了一个新的损失函数IDLoss，该损失函数具有收敛性和分段光滑性质，能够实现优化。ID能够提供关于模型行为和公平性的独特见解，并通过优化过程显著提高单一属性和交错属性的公平性，同时保持预测性能的竞争平衡。", "conclusion": "通过广泛的实验评估，我们展示了ID如何允许对模型行为和公平性的独特见解，并且如何通过优化过程显著改善单一属性和交叉属性的公平性，同时保持预测性能的竞争平衡。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.07797", "html_url": "https://arxiv.org/abs/2505.07797", "title": "使用Shapley值解释强化学习的理论框架", "title_en": "A Theoretical Framework for Explaining Reinforcement Learning with Shapley Values", "authors": "Daniel Beechey,Thomas M. S. Smith,Özgür Şimşek", "background": "强化学习智能体在复杂决策任务中可以实现超人表现，但其行为难以理解和解释，这限制了它们的应用，特别是在需要理解与信任的安全关键环境中。现有解释方法的不足之处使得理解智能体行为、结果和预测的内在因素成为必要，从而更好地部署智能体并提高透明度与可信度。", "innovation": "开发了使用Shapley值解释强化学习智能体行为、结果和预测的统一理论框架——Shapley值用于解释强化学习(SVERL)。Shapley值通过个体特征对环境的影响求出，且仅需遵循一组动机良好的公平和一致的信用分配公理。这种方法为强化学习智能体提供了全面而有意义的解释，并通过具体示例展示了SVERL如何产生关于智能体行为、结果和预测的实用且直观的解释，而不是仅通过观察智能体行为所能得到的解释。", "conclusion": "SVERL为定量理解强化学习智能体的行为提供了单一同一体理论框架，解释具有明确的语义，既可解释又根据严格的数学依据，可以识相同前人解释中的概念问题并加以修正。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.06275", "html_url": "https://arxiv.org/abs/2505.06275", "title": "SinBasis Networks: 矩阵等效特征提取方法适用于波形光学光谱", "title_en": "SinBasis Networks: Matrix-Equivalent Feature Extraction for Wave-Like Optical Spectrograms", "authors": "Yuzhou Zhu,Zheng Zhang,Ruyi Zhang,Liang Zhou", "background": "波形图像中的关键谐波结构可能会被传统的特征提取方法所遗漏。文章涉及的数据集包括80,000个合成的飞秒级光谱裂痕图、数千种Raman、光致发光和傅立叶变换红外光谱、来自AudioSet的音频梅尔频谱图以及来自Kinetics的周期视频帧。本文的背景是在这些多样化的波形图像数据集上，传统方法存在不足之处，需要一种新的方法来提高重建准确性、平移鲁棒性和跨领域零样本迁移性能。", "innovation": "文章提出了一种统一的矩阵等效框架，重新解释卷积和注意力作为扁平化输入的线性变换，揭示滤波器权重作为潜特征子空间的基向量。通过将元素级$\text{sin}(\text{·})$映射应用于每个权重矩阵，将频谱先验嵌入其中。将这些变换整合到CNN、ViT和Capsule架构中生成了Sin-Basis网络，这些网络对周期结构具有更高的敏感性，并且具有对空间位移的内在不变性。实验表明，这些网络在重建准确性、平移鲁棒性以及零样本跨领域迁移性能上表现优异。从矩阵同构和Mercer核截断理论分析了这种正弦重参数化如何丰富表达能力同时保持数据稀缺区域中的稳定性。", "conclusion": "Sin-Basis网络提供了一种轻量级且基于物理的方法，可以应用于所有波形成像模态，增强了深度学习的能力。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05702", "html_url": "https://arxiv.org/abs/2505.05702", "title": "Hypergraph Neural Sheaf Diffusion: 一种用于高阶学习的对称单纯集框架", "title_en": "Hypergraph Neural Sheaf Diffusion: A Symmetric Simplicial Set Framework for Higher-Order Learning", "authors": "Seongjin Choi,Gahee Kim,Yong-Geun Oh", "background": "由于超图中不存在固有的邻接关系和方向系统，这给构建任意度的她爹拉普拉斯矩阵带来了根本性的挑战。本文通过从超图直接导出对称单纯集来解决这些限制，称为对称单纯集提升，它将每个超边内的所有可能方向子关系编码为有序元组，从而直接定义邻接关系。验证了其数学上与基于图的她爹理论的一致性，同时保留了原始超图的所有结构信息，确保每个多重关系细节都能准确保留。在这一框架下，引入了Hypergraph Neural Sheaf Diffusion（HNSD），这是神经她爹扩散到超图的第一个原则性扩展。该方法利用对称单纯集提升上的归一化零度她爹拉普拉斯矩阵来解决超图学习中固有的方向不确定性和邻接稀疏性问题。", "innovation": "提出了对称单纯集提升（Symmetric Simplicial Lifting），一种从超图导出的结构，它可以编码每个超边的所有可能方向子关系，这使得直接定义邻接关系成为可能，并能保留原始超图的所有结构信息。基于此框架，引入了Hypergraph Neural Sheaf Diffusion (HNSD)，这是一种原则性扩展神经她爹扩散到超图的方法，能够解决超图学习中的方向不确定性和邻接稀疏性问题。", "conclusion": "实验评估表明，HNSD在多个基准测试中表现出竞争性的性能。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14781", "html_url": "https://arxiv.org/abs/2506.14781", "title": "二维并行温度调温法在约束优化中的应用", "title_en": "Two-dimensional Parallel Tempering for Constrained Optimization", "authors": "Corentin Delacour,M Mahmudul Hasan Sajeeb,Joao P. Hespanha,Kerem Y. Camsari", "background": "在机器学习和优化中，采样玻尔兹曼概率分布起着关键作用，这激励了设计硬件加速器，如Ising机器。虽然Ising模型原则上可以描述任意优化问题，但实际实现中，由于软约束过于强烈可能导致混合慢，过于薄弱则不能保证可行性。这些软约束影响了Ising模型的实现。", "innovation": "我们提出了一种二维扩展的并行温度调温算法（PT），通过增加一种新的温度维度来适配和调整惩罚系数。这一方法确保了最终复制品满足约束条件，类似于低温下的低能态。二维并行温度调温算法（2D-PT）能够改善高度约束复制品的混合效率，且无需显式调整惩罚强度。", "conclusion": "在一种图稀疏化示例中，2D-PT实现了接近理想的混合效果，Kullback-Leibler散度与时间成线性衰减。当应用于稀疏化的Wishart实例时，2D-PT相比传统PT有了数量级的速度提升。该方法适用于广泛的受限Ising问题，且可以在现有的Ising机器上部署。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03956", "html_url": "https://arxiv.org/abs/2506.03956", "title": "Adapt before Continual Learning", "title_en": "Adapt before Continual Learning", "authors": "Aojun Lu,Tao Feng,Hangjie Yuan,Chunhui Ding,Yanan Sun", "background": "元化学习（CL）旨在使神经网络能够逐步获得新知识（弹性）同时保留现有知识（稳定性）。现有的预训练模型（PTMs）为CL提供了坚实的基础，但现有方法在平衡这两个目标时面临根本挑战。当前方法通常通过冻结PTM主体来维持稳定性，这极大地限制了模型的弹性，尤其是在新输入数据分布与预训练数据差异较大时。另一种方法是对整个PTM进行顺序细调以适应新知识，但往往会导致灾难性遗忘，这突显了基于PTM的CL中稳定性-弹性之间的关键权衡。", "innovation": "该文提出了一种新颖的框架——在核心CL过程前引入一种即插即用式适应阶段（Adapting PTMs before the core CL，ACL），以便在学习每个新任务前首先调整PTM主体。ACL通过调整嵌入与原始类原型的对齐，并使其远离无关类来微调PTM主体。这种机制在理论上和实证上展示了稳定性和弹性的理想平衡，显著提高了CL性能。", "conclusion": "在此框架下，ACL通过在学习每个新任务前调整PTM主体，实现了稳定性和弹性的理想平衡，从而显著提升了CL在基准测试和综合方法中的性能。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15692", "html_url": "https://arxiv.org/abs/2506.15692", "title": "MLE-STAR: 通过搜索和目标精炼的机器学习工程代理", "title_en": "MLE-STAR: Machine Learning Engineering Agent via Search and Targeted Refinement", "authors": "Jaehyun Nam,Jinsung Yoon,Jiefeng Chen,Jinwoo Shin,Sercan Ö. Arık,Tomas Pfister", "background": "基于大型语言模型（LLMs）的代理可以自动实现机器学习（ML）模型通过代码生成。现有的这类代理构建方法通常依赖于LLMs固有的知识，并采用粗犷的探索策略一次性修改整个代码结构。这限制了它们根据任务选择有效模型和在特定组件内进行深入探索的能力，如特征工程选项的广泛实验。", "innovation": "我们提出了一种名为MLE-STAR的新方法，以构建机器学习工程（MLE）代理，这种代理首先利用搜索引擎检索网络上的有效模型形成初始解，然后通过探索针对特定ML组件的不同策略逐步优化它。这一探索过程受到对单个代码块影响的消融研究的指导。此外，我们还引入了一种新的集成方法，利用MLE-STAR建议的有效策略。", "conclusion": "实验结果显示，MLE-STAR在MLE-bench Lite上的Kaggle竞赛中获得了64%的金牌，明显优于最佳替代方案。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20553", "html_url": "https://arxiv.org/abs/2505.20553", "title": "避免高斯陷阱的ZeNN架构", "title_en": "A ZeNN architecture to avoid the Gaussian trap", "authors": "Luís Carvalho,João L. Costa,José Mourão,Gonçalo Oliveira", "background": "标准的多层感知机（MLPs）在大宽度极限下存在非参数性问题，没有明确定义的点限值，丧失了非高斯属性，无法完成特征学习；此外，有限宽度的MLPs在学习高频特征时表现不佳。", "innovation": "作者提出了一个新的简单架构，Zeta Neural Networks (ZeNNs)，受调和分析中的三个简单原则启发：(i) 列出感知机并引入不可学习的权重以确保收敛；(ii) 引入缩放（或频率）因子；(iii) 选择导致接近正交系统的激活函数。这些设计理念能够解决MLPs的问题，在无限宽度极限下，ZeNNs可以实现明确定义的点阶收敛，展示出远超高斯性的丰富渐近结构，能进行特征学习，并且选择合适的激活函数时，无限宽度的ZeNNs能很好地学习低维域上的高频率特征。", "conclusion": "在无限宽度极限下，ZeNNs解决了MLPs的非参数性问题、无法进行特征学习以及在学习高频率特征时表现不佳的问题，展示出丰富的渐近结构并能高效学习高频率特征。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15857", "html_url": "https://arxiv.org/abs/2507.15857", "title": "在数据受限环境中扩散模型超越自回归模型", "title_en": "Diffusion Beats Autoregressive in Data-Constrained Settings", "authors": "Mihir Prabhudesai,Mengning Wu,Amir Zadeh,Katerina Fragkiadaki,Deepak Pathak", "background": "自回归（AR）模型长期以来主导着大规模语言模型的领域，推动了各种任务的进步。近年来，基于扩散的语言模型作为一种有前景的替代方案开始出现，但它们相对于AR模型的优势尚未被充分探索。", "innovation": "该论文系统研究了在数据受限环境中掩蔽扩散模型的表现，发现当计算资源丰富但数据有限时，扩散模型在验证损失和下游任务的表现上显著优于AR模型。扩散模型能够更好地利用重复数据，并将此优势解释为隐含的数据增强。论文还发现了扩散模型的新扩展法则，并推导出了扩散模型开始超越AR模型所需的关键计算阈值。", "conclusion": "研究结果表明，当数据而非计算能力成为瓶颈时，扩散模型为标准的AR范式提供了一个有吸引力的替代方案。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.18102", "html_url": "https://arxiv.org/abs/2505.18102", "title": "如何在不透露真实答案的情况下发布我的大语言模型基准？", "title_en": "How Can I Publish My LLM Benchmark Without Giving the True Answers Away?", "authors": "Takashi Ishida,Thanawat Lodkaew,Ikko Yamane", "background": "发布大语言模型（LLM）基准于互联网上会存在风险，可能无意中或故意地将其用于训练或选择模型。一种常见的缓解措施是保持基准私密，让参与者向组织者提交其模型或预测。然而，这种方法需要参与者对单一组织的信任，仍可能通过反复查询产生测试集过拟合。为了解决这个问题，作者提出了一种在不完全披露问题答案的真实情况的同时，依然能够公开评估大语言模型的方法。基本思想是在答案中注入随机性，通过准备多个逻辑正确答案，并仅在基准中包含其中一个作为解决方案。", "innovation": "提出了一种方法，即在保持一定随机性的前提下公开基准，而不是完全披露问题的答案。这种方法包括准备多个逻辑上正确的答案，但在基准中仅包含其中一个作为解决方案。这降低了基准的最佳可能准确度，即贝叶斯准确性。这种做法不仅可以防止泄露真实答案，还可以作为检测数据污染的测试工具。即使是最完善的模型，也不能超过贝叶斯准确度。", "conclusion": "实验结果表明，该方法可以在各种基准、模型和训练方法下准确地检测数据污染。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.13762", "html_url": "https://arxiv.org/abs/2507.13762", "title": "MolPIF：一种用于分子生成的参数插值流模型", "title_en": "MolPIF: A Parameter Interpolation Flow Model for Molecule Generation", "authors": "Yaowei Jin,Junjie Wang,Wenkai Xiang,Duanhua Cao,Dan Teng,Zhehuan Fan,Jiacheng Xiong,Xia Sheng,Chuanlong Zeng,Duo An,Mingyue Zheng,Shuangjia Zheng,Qian Shi", "background": "近年来深度学习在分子生成方面的进展显示了加速药物发现的潜力。Bayesian Flow Networks（BFNs）在多种化学任务中表现出色，其成功通常归因于在低方差参数空间中的建模方法。然而，基于贝叶斯推断的策略限制了设计更灵活的分布变换路径的能力，这使得它们难以适应不同的数据分布和任务需求。此外，基于参数空间的较简化和更高效模型的潜力尚未被探索。", "innovation": "本文提出了一个新的Parameter Interpolation Flow模型（PIF），并通过详细的理论基础、训练和推理过程对其进行开发。随后，开发了MolPIF用于基于结构的药物设计，展示了其在各种评估指标上优于基线模型的性能。这项工作验证了基于参数空间的生成模型 paradigm 在分子生成中的有效性，并为模型设计提供了新的视角。", "conclusion": "这项工作表明，基于参数空间的生成建模范式在分子生成中是有效的，并为未来的模型设计提供了新的思路。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09252", "html_url": "https://arxiv.org/abs/2507.09252", "title": "TPP-SD: 使用推测解码加速变压器点过程采样", "title_en": "TPP-SD: Accelerating Transformer Point Process Sampling with Speculative Decoding", "authors": "Shukai Gong,Yiyang Fu,Fengyuan Ran,Quyu Kong,Feng Zhou", "background": "该研究提出了TPP-SD方法，这是一种通过从语言模型中的推测解码（Speculative Decoding, SD）技术来加速变换器临时点过程（TPP）采样的新方法。这项工作的背景在于，现有的TPP采样方法较为耗时，尤其是在处理大规模数据集时。研究人员发现TPP的稀疏化算法与语言模型中的推测解码机制存在结构上的相似性，因此试图将这些相似之处转化为一种更高效的采样框架。", "innovation": "TPP-SD方法通过使用一个较小的草稿模型生成多个候选事件，然后由更大的目标模型并行验证，从而实现了与自回归采样相同的输出分布，但速度提升了2-6倍。此外，该研究还分析了超参数如草稿长度和草稿模型大小对采样效率的影响，从而进一步优化了方法。", "conclusion": "TPP-SD方法成功地将强大的Transformer TPP模型与快速序列采样的实际需求联系起来，通过使用推测解码技术实现显著的加速效果，同时保持了相同的输出分布。实验结果表明，在合成和真实数据集上的表现均优于传统的标准方法，表明TPP-SD具有广泛的应用前景。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12284", "html_url": "https://arxiv.org/abs/2506.12284", "title": "GrokAlign：几何表征与grokking加速", "title_en": "GrokAlign: Geometric Characterisation and Acceleration of Grokking", "authors": "Thomas Walker,Ahmed Imtiaz Humayun,Randall Balestriero,Richard Baraniuk", "background": "机器学习社区面临的一个关键挑战是理解深度网络训练动力学，这些动力学导致延迟泛化和对输入扰动的鲁棒性增强，即‘grokking’现象。先前的研究将延迟泛化与深度网络从线性学到特征学习阶段的转变相关联，同时将鲁棒性的产生与网络功能几何结构的变化，特别是深度网络中线性区域的排列相关联。", "innovation": "本文解释了如何在深度网络的雅可比中实现grokking，并表明在低秩雅可比假设下，使网络雅可比与训练数据对齐（在余弦相似性的意义上）可以保证grokking。研究结果为使用雅可比正则化在优化深度网络方面的应用提供了强有力的理论动机，我们引入了GrokAlign方法，并通过实验证明其能比常规的权重衰减等正则化方法更早地诱导grokking。此外，我们还介绍了中心点对齐作为雅可比对齐的可计算且具有解释性的简化方法，以识别和跟踪深度网络训练动力学的阶段。", "conclusion": "我们的研究结果提供了理论上的动机，证明了雅可比正则化在优化深度网络中的有效性，并通过实证方法证明了GrokAlign能更早地诱导grokking。我们还引入了中心点对齐作为雅可比对齐的简化方法，从而更好地理解网络训练的动力学。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.21004", "html_url": "https://arxiv.org/abs/2507.21004", "title": "Compositional Function Networks: 具有内置可解释性的高性能替代深度神经网络", "title_en": "Compositional Function Networks: A High-Performance Alternative to Deep Neural Networks with Built-in Interpretability", "authors": "Fang Li", "background": "深度神经网络（DNNs）在性能上表现出色，但其黑盒特性限制了其在需要透明性的高风险领域中的应用。", "innovation": "提出了组成函数网络（CFNs）这一新颖框架，通过组合具有清晰语义的基本数学函数来构建固有可解释的模型；CFNs 支持多种组合模式（序列、并行和条件），并保持透明性；CFNs 完全可微，可以通过标准梯度下降实现高效的训练。", "conclusion": "CFNs 在多个领域的实证评估中表现出色，性能与黑盒模型相当且优于解释型黑Boosting机器等最先进的可解释模型，同时提供了一种高性能和可问责性的强大框架，结合深度学习的层次表达能力和定义良好的数学函数的固有可解释性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.21197", "html_url": "https://arxiv.org/abs/2507.21197", "title": "AdaptHetero: Machine Learning Interpretation-Driven Subgroup Adaptation for EHR-Based Clinical Prediction", "title_en": "AdaptHetero: Machine Learning Interpretation-Driven Subgroup Adaptation for EHR-Based Clinical Prediction", "authors": "Ling Liao,Eva Aagaard", "background": "机器学习解释（MLI）的主要应用是建立临床医生的信任并从电子健康记录（EHR）中发现可行见解。然而，EHR数据的固有复杂性和异质性限制了其在指导针对亚组的建模中的有效性。", "innovation": "提出了AdaptHetero，一个新颖的基于MLI的框架，该框架将可解释性洞察转化为针对单个医院系统内部亚群体进行建模训练和评估的具体指导。通过集成基于SHAP的解释和无监督聚类，框架增强了识别临床相关亚组特征的能力，从而提高了预测性能并优化了临床应用。", "conclusion": "AdaptHetero在三个大规模EHR数据集：GOSSIS-1-eICU、WiDS和MIMIC-IV上，一致地识别出了预测重症监护病房（ICU）死亡、院内死亡和隐性低氧血症的异质性模型行为。这种方法通过提供有针对性的指导，提高了预测性能并优化了临床部署。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19095", "html_url": "https://arxiv.org/abs/2507.19095", "title": "GCL-GCN：结合Graphormer和对比学习的图结构属性聚类网络", "title_en": "GCL-GCN: Graphormer and Contrastive Learning Enhanced Attributed Graph Clustering Network", "authors": "Binxiong Li,Xu Xiang,Xue Li,Quanzhou Lou,Binyu Zhao,Yujie Liu,Huijie Tang,Benhan Yang", "background": "图数据的属性图聚类在现代数据分析中具有重要意义。然而，由于图数据的复杂性和节点属性的异质性，利用图信息进行聚类依然存在挑战。", "innovation": "提出了一种新颖的深度图聚类模型GCL-GCN，该模型专为处理稀疏和异质图数据时捕捉局部依赖性和复杂结构而设计。GCL-GCN引入了一个创新的Graphormer模块，结合了中心性编码和空间关系，有效地捕捉节点间的全局和局部信息，提高节点表示的质量。此外，还提出了一种新颖的对比学习模块，显著增强了特征表示的区分能力。在预训练阶段，该模块通过对比学习在原始特征矩阵上增加特征区分度，确保后续的图卷积和聚类任务获得更标识的初始表示。", "conclusion": "在六个数据集上的广泛实验结果表明，GCL-GCN在聚类质量和鲁棒性方面优于14种先进方法。特别是在Cora数据集上，相比于主要的对比方法MBN，提高了ACC 4.94%，NMI 13.01%和ARI 10.97%。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17247", "html_url": "https://arxiv.org/abs/2506.17247", "title": "基于递归学习的虚拟缓冲技术在分析性全局布图中的应用", "title_en": "Recursive Learning-Based Virtual Buffering for Analytical Global Placement", "authors": "Andrew B. Kahng,Yiting Liu,Zhiang Wang", "background": "现代技术节点中互连和单元延迟的偏斜扩展使得全局布图时需要考虑缓冲器孔隙度（即单元密度）以确保物理综合流程中的时序闭合。现有方法面临两个主要挑战：（1）传统的van Ginneken-Lillis风格的缓冲处理方法在全局布图阶段计算量大；（2）基于机器学习的方法，如BufFormer，缺乏对电气规则检查（ERC）违规的全面考虑，无法将过程反馈回物理设计流程中。这些方法不能有效地减少延时余量（TNS）并保持功耗优化。", "innovation": "本文提出了一种名为MLBuf-RePlAce的开源学习驱动的虚拟缓冲感知的分析性全局布图框架，基于OpenROAD架构。该框架使用高效的递归学习生成缓冲方法来预测缓冲器类型和位置，并在全局布图中解决电气规则检查（ERC）违规。与OpenROAD中默认的基于虚拟缓冲的时驱动全局布图器进行对比，结果证实MLBuf-RePlAce在开源OpenROAD流程中可减少最多56%、平均31%的延时余量，且不影响功耗。在商用流程中，MLBuf-RePlAce能减少最多53%、平均28%的延时余量，平均功耗降低0.2%。", "conclusion": "MLBuf-RePlAce框架通过学习驱动的递归缓冲方法有效解决了传统和机器学习方法面临的挑战，实现了全局布图的高效和优化。该方法不仅提高了时间尺寸性能，还能保持或降低功耗。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.18376", "html_url": "https://arxiv.org/abs/2507.18376", "title": "智能农业中扩散模型的综合综述：进展、应用及挑战", "title_en": "A Comprehensive Review of Diffusion Models in Smart Agriculture: Progress, Applications, and Challenges", "authors": "Xing Hu,Haodong Chen,Qianqian Duan,Danfeng Hong,Ruijiao Li,Huiliang Shang,Linghua Jiang,Haima Yang,Dawei Zhang", "background": "随着全球人口的增长和可耕地资源的日益紧缺，智能农业和精准农业成为未来农业的重要方向。人工智能（AI）技术，尤其是深度学习模型，在作物监测和病虫害检测等领域得到了广泛应用。作为一种新兴的生成模型，扩散模型在农业图像处理、数据增强和遥感方面显示出巨大的应用潜力。与传统的生成对抗网络(GANs)相比，扩散模型在训练稳定性和生成质量方面具有优势，有效解决了农业数据有限和图像样本不平衡的问题。", "innovation": "扩散模型在农业应用中的最新进展，特别是在作物病虫害检测、遥感图像增强、作物生长预测和农业资源管理等方面的应用潜力。扩散模型在数据增强、图像生成和去噪方面显著提高了模型的准确性和鲁棒性，特别是在复杂环境中表现更佳。", "conclusion": "尽管存在计算效率和泛化能力的挑战，随着技术的进步，扩散模型在智能和精准农业中的作用将变得越来越重要，为全球农业的可持续发展提供支持。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07675", "html_url": "https://arxiv.org/abs/2507.07675", "title": "有限宽度ReLU网络中层间有效维度振荡的一些理论结果", "title_en": "Some Theoretical Results on Layerwise Effective Dimension Oscillations in Finite Width ReLU Networks", "authors": "Darshan Makwana", "background": "该研究分析了完全连接的ReLU网络在有限宽度下的层间有效维度（特征矩阵的秩）。对于固定数量的m个输入和随机高斯权重，研究者推导出隐藏激活矩阵的期望秩的闭形式表达式。", "innovation": "研究的主要成果是：$\text{EDim}(\text{第$\bm{\beta}$层}) = m[1-(1-2/\bm{\bm{\text{π}}})^\bm{\beta}]+O(e^{-c m})$，秩的不足随比例$1-2 / \bm{\bm{\text{π}}} \bm{\thickapprox} 0.3634$呈几何衰减。此外，还证明了亚高斯集中性边界，并识别出秩期望值的局部最大值出现的“复活”深度，且这些峰值大致在深度$\bm{\beta}_k^*\bm{\thicksim}(k+0.5)\bm{\text{π}}/\bm{\text{log}(1/\rho)}$处，高度大致约为$0.79m$。研究还表明，这种振荡的秩行为是有限宽度现象：在正交权重初始化或强负坡度leaky-ReLU下，秩保持（接近）全维度。", "conclusion": "这些结果为随机ReLU层如何交替崩溃和部分复活输入变化的子空间提供了精确的描述，为深入网络的表达能力增加了新的见解。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22174", "html_url": "https://arxiv.org/abs/2507.22174", "title": "具有非马尔可夫交通的空间-时间强化学习在网络路由中的应用", "title_en": "Spatial-Temporal Reinforcement Learning for Network Routing with Non-Markovian Traffic", "authors": "Molly Wang,Kin.K Leung", "background": "强化学习（RL）在通信网络中的包路由应用十分广泛，但传统RL方法依赖马尔可夫假设，即当前状态内包含了所有决策所需的信息。然而，实际网络中的互联网流量是非马尔可夫的，过去的状态对路由性能仍有影响。此外，常见的深度RL方法使用函数近似器，如神经网络，这些方法不能建模网络拓扑的空间结构。", "innovation": "为解决这些问题，该研究设计了一个具有非马尔可夫交通的网络环境，并引入了一种空间-时间RL（STRL）框架进行包路由。这种方法在训练中比传统基线提高了超过19%，在拓扑结构变化时，在推理中提高了超过7%。", "conclusion": "通过引入STRL框架，该研究成功地提高了包路由性能，特别是在非马尔可夫网络环境中，并且证明了新框架的有效性和鲁棒性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.21433", "html_url": "https://arxiv.org/abs/2507.21433", "title": "MemShare: 通过 KV 缓存重用实现大型推理模型的高效推理", "title_en": "MemShare: Memory Efficient Inference for Large Reasoning Models through KV Cache Reuse", "authors": "Kaiwen Chen,Xin Tan,Minchen Yu,Hong Xu", "background": "大型推理模型（LRMs）在数学推理和形式逻辑任务中取得了显著进展，但它们倾向于生成较长的推理链，导致推理过程中有大量的内存开销。研究发现，LRMs 经常产生高度相似的中间推理步骤，这些步骤在各层之间具有相似的 KV 缓存状态。基于这一发现，提出了一种名为 MemShare 的新型 KV 缓存管理方法，该方法能够有效减少内存开销。MemShare 使用协同过滤算法来高效识别可重用的 KV 缓存块，实现零拷贝缓存重用，从而显著减少内存开销、提高吞吐量，同时保持准确性", "innovation": "MemShare 采用协同过滤算法识别可重用的 KV 缓存块，并进行零拷贝缓存重用，有效减少了内存开销，提高了吞吐量并保持了准确性。与现有 KV 缓存管理方法相比，MemShare 能够实现高达 84.79% 的吞吐量提升，同时保持更好的准确性", "conclusion": "实验结果表明，MemShare 在保持准确性的同时，能够显著提高大型推理模型的推理吞吐量，是 KV 缓存管理的一个有效解决方案"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2407.08722", "html_url": "https://arxiv.org/abs/2407.08722", "title": "通过深度网络推断雅可比场控制多样的机器人", "title_en": "Controlling diverse robots by inferring Jacobian fields with deep networks", "authors": "Sizhe Lester Li,Annan Zhang,Boyuan Chen,Hanna Matusik,Chao Liu,Daniela Rus,Vincent Sitzmann", "background": "模仿自然生物的复杂结构和多样功能是机器人学领域的一大挑战。现代制造技术大幅扩展了可实现的硬件范围，但要使这些系统发挥作用，还需要控制软件将期望的动作转化为执行器命令。传统的机器人通常可以被建模为由关节连接的刚性环节，但对于那些常常柔性的、使用中材料性质可能发生变化的受生物启发的机器人，建立和控制它们仍然是一个开放的挑战。本文旨在解决这一问题。", "innovation": "本文提出了一种方法，利用深度神经网络将机器人视频流映射为其全3D点的视觉运动雅可比场（雅可比场表示所有3D点对机器人执行器的灵敏度）。这种方法使得仅需单个摄像头即可控制机器人，对机器人的材料、驱动和感知无需假设，而且通过观察随机命令的执行无需专家介入即可进行训练。并且，我们的方法已经在不同驱动、材料、制造和成本的多种机器人操作器中进行了验证，实现了精准的闭环控制并恢复了每个机器人的因果动态结构。", "conclusion": "通过使用通用摄像头作为唯一传感器，本文为机器人控制开辟了更广泛的设计空间，并为降低机器人自动化门槛提供了起点。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22303", "html_url": "https://arxiv.org/abs/2507.22303", "title": "CS-SHRED：增强SHRED以实现鲁棒的时空动态恢复", "title_en": "CS-SHRED: Enhancing SHRED for Robust Recovery of Spatiotemporal Dynamics", "authors": "Romulo B. da Silva,Diego Passos,Cássio M. Oishi,J. Nathan Kutz", "background": "该研究提出了一种名为CS-SHRED的新颖深度学习架构，该架构将压缩感知（CS）技术集成到了浅层递归解码器（SHRED）中，用于从不完整、压缩或受到损坏的数据中重建时空动态。背景涉及现有方法可能无法准确从不完整数据中恢复信号的情况，尤其是在稀疏传感器分布、噪音测量和不完整传感器数据的情况下。此外，现有的方法在低信噪比（SNR）下可能会丢失细尺度结构，而在高SNR下可能会过度抑制噪声。", "innovation": "方法的两项关键创新包括：1. 将CS技术整合到SHRED架构中，利用基于批量的前向框架以及L1正则化以在稀疏传感器布置、噪声测量和不完整传感器采集的情况下鲁棒地恢复信号；2. 引入了一种自适应损失函数，该函数动态结合了均方误差（MSE）和绝对误差（MAE）项，并使用分段信噪比（SNR）正则化来抑制低SNR区域的噪声和异常值，同时在高SNR区域保留细尺度特征。", "conclusion": "CS-SHRED方法在包括黏弹性流体流动、最大特定湿度场、海面温度分布以及旋转湍流流在内的多种挑战性问题上进行了验证，结果表明与传统的SHRED方法相比，CS-SHRED在重建保真度方面表现更好，通过提高SSIM和PSNR值、降低归一化误差以及增强LPIPS分数，CS-SHRED能够更好地保存小尺度结构并增强对噪声和异常值的鲁棒性。CS-SHRED的设计架构和联合训练的CS和SHRED技术优势使其成为环境、气候和科学数据分析中广泛应用的潜在工具。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22789", "html_url": "https://arxiv.org/abs/2507.22789", "title": "G-Core: 一种简单、可扩展且平衡的RLHF训练器", "title_en": "G-Core: A Simple, Scalable and Balanced RLHF Trainer", "authors": "Junyu Wu,Weiming Chang,Xiaotao Liu,Guanyou He,Haoqiang Hong,Boqi Liu,Hongtao Tian,Tao Yang,Yunsheng Shi,Feng Lin,Ting Yao", "background": "强化学习从人类反馈（RLHF）已成为训练大规模语言模型（LLMs）和扩散模型的一种越来越流行的方法。虽然现有的RLHF训练系统已经取得了显著的进步，但它们在扩展到多模态和扩散流程以及适应动态工作负载方面常常面临挑战。现有的方法在处理复杂RLHF管道时可能会遇到控制器缩放性、灵活资源放置和高效编排的限制，尤其在涉及动态采样或生成奖励建模的场景中更为明显。现有的不少方法无法有效处理这些复杂任务，因此需要一种新的解决方案来克服这些限制，以提高RLHF的训练效率和灵活性，特别是在动态和多样的工作负载中实现更高效的管理和编排。", "innovation": "G-Core 提出了一种并行控制器编程模型，实现了灵活和高效的RLHF复杂流程编排，避免了单一集中式控制器瓶颈；还提出了一种动态资源分配方案，适应性地划分资源和调度工作负载，显著减少了硬件闲置时间并提高了资源利用率，即使是高度可变的训练条件下也是如此。这些创新使得G-Core能够在实际场景中高效地训练大规模用户基础支持的产品功能模型，证明了其在现实世界中的有效性和鲁棒性。", "conclusion": "G-Core 为现有RLHF训练方法设定了新的标准，提供了大规模、人类对齐模型的未来研究和部署的坚实基础。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22633", "html_url": "https://arxiv.org/abs/2507.22633", "title": "H2Tune：具有混合异质性的联邦基础模型细调", "title_en": "H2Tune: Federated Foundation Model Fine-Tuning with Hybrid Heterogeneity", "authors": "Wei Guo,Siyuan Lu,Yiqi Tong,Zhaojun Hu,Fuzhen Zhuang,Xiao Zhang,Tao Fan,Jin Dong", "background": "现有的联邦细调（FFT）方法主要关注单一异质性场景，而忽视了模型架构和下游任务双层异质性的混合异质性场景。这种混合异质性带来了两个显著挑战：1）异质矩阵聚合，即由于各客户端根据任务需求和资源限制采用了不同的大型基础模型，导致了在低秩适配器（LoRA）参数聚合时出现维度不匹配问题；2）多任务知识干扰，即通过同时融合任务共享和任务特定知识训练的本地共享参数，在客户端间的任务共享知识转移时无法保证只传输任务共享知识。", "innovation": "提出了一种处理混合异质性的联邦基础模型细调方法——H2Tune。主要包括三部分：(i) 去稀疏化三重矩阵分解，通过构建秩一致中间矩阵来统一隐藏维度，同时根据客户端资源进行自适应去稀疏化；(ii) 关系导向的矩阵层对齐，解决异构的层结构和表示能力问题；(iii) 交错任务知识解缠机制，通过交替优化来解耦局部模型参数中的共享和特定知识。", "conclusion": "理论分析证明了其收敛速度为 O(1/√T)。大量实验结果表明，该方法比最先进的基线方法提高了高达15.4%的准确率。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.12319", "html_url": "https://arxiv.org/abs/2408.12319", "title": "Neural-ANOVA: 自动积分实现的分析模型分解", "title_en": "Neural-ANOVA: Analytical Model Decomposition using Automatic Integration", "authors": "Steffen Limmer,Steffen Udluft,Clemens Otte", "background": "导入方差分析（ANOVA）分解的系统方法，用于理解影响特定决策输出的交互效应。本文提出了一种基于神经网络的分解方法，使用功能ANOVA分解将神经网络分解为低阶模型之和。这种方法通过解决学习问题，允许快速分析积分，这些积分出现在ANOVA分解的计算中。该论文旨在提供与其他文献中提到的回归方法相比的逼近性质见解。", "innovation": "引入了Neural-ANOVA方法，它通过功能ANOVA分解将神经网络分解为低阶模型之和。该方法通过解决学习问题，实现了对子空间积分的快速分析评估，因而能在理解网络复杂性方面提供额外的洞察力。相较于传统方法，该方法能够有效简化计算，提高分析效率。", "conclusion": "通过数值实验，该论文揭示了Neural-ANOVA方法与文献中其他回归方法相比的逼近性质差异，表明它在复杂决策问题中提供了更高效的解析评估方法。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.09363", "html_url": "https://arxiv.org/abs/2404.09363", "title": "基于动量的梯度下降方法在李群上的应用", "title_en": "Momentum-based gradient descent methods for Lie groups", "authors": "Cédric M. Campos,David Martín de Diego,José Torrente", "background": "介绍了Polyak的重球法（PHB；Polyak, 1964）和Nesterov的加速梯度法（NAG；Nesterov, 1983），这两种方法都是优化中的经典动量下降方法。尽管NAG通常表现更好，但学术界对NAG样方法在非线性空间中的推广研究不够充分。", "innovation": "提出了NAG样方法在李群优化中的推广。这一推广基于经典和加速动量方法之间的变分一一对应关系（Campos等, 2023）。通过特定的模拟实验验证了方法的有效性，并与欧几里得情况的结果一致，即NAG具有更快的收敛速度。", "conclusion": "通过在旋转群上基于Frobenius范数和Rosenbrock函数的特定重射实验，证明了所提方法的有效性和加速梯度法在李群优化中的更快收敛特性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.02123", "html_url": "https://arxiv.org/abs/2408.02123", "title": "FovEx: 由人类启发的方法在视觉变换器和卷积神经网络中的解释", "title_en": "FovEx: Human-Inspired Explanations for Vision Transformers and Convolutional Neural Networks", "authors": "Mahadev Prasad Panda,Matteo Tiezzi,Martina Vilas,Gemma Roig,Bjoern M. Eskofier,Dario Zanca", "background": "在人工智能领域，可解释性（XAI）对于增强对机器学习模型的信任和理解至关重要。现有的视觉解释技术，如梯度基于或类别激活基于的方法，通常依赖于特定的模型架构。相比之下，基于扰动的技术虽然可以实现模型无关的解释，但由于需要进行大量的前向传递计算，因此计算开销较大。本文的研究背景在于现有方法的局限性和亟待改进的空间。", "innovation": "本文介绍了一种基于人类视觉的新方法——FovEx（Foveation-based Explanations）。FovEx 方法通过逐步生成视觉注意力图并结合梯度引导的可视探索技术来提高解释的准确性和效率，这种方法在处理各种架构时具有通用性。此外，FovEx 的解释图与人类的注视模式高度吻合，进一步验证了其准确性。", "conclusion": "FovEx方法在视觉变换器和卷积模型上都达到了行业领先的表现（在4/5和3/5的指标上分别占据首位），展示了其在不同架构上的灵活性和有效性。同时，FovEx 方法解释图与人类注视模式的高度一致性增强了我们对其准确性和可靠性的信心。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2312.14057", "html_url": "https://arxiv.org/abs/2312.14057", "title": "使用行列式点过程和广义体积采样的加权最小二乘逼近", "title_en": "Weighted least-squares approximation with determinantal point processes and generalized volume sampling", "authors": "Anthony Nouy,Bertrand Michel", "background": "论文背景涉及通过在随机点处评估函数来从$L^2$空间中逼近一个函数的问题。传统方法采用独立同分布的点来生成最优加权最小二乘估计。本文进一步探讨了使用投影行列式点过程（DPP）或体积采样的加权最小二乘方法。这些方法通过引入点之间的依赖性，能够在所选特征上促进多样性，从而改进点的选择策略。背景中还提到了在连续嵌入$L^2$空间的某种范数空间$H$中的函数逼近问题，以及独立重复使用投影DPP或体积采样的策略，该策略在实践中需要更少的样本数量但仍能达到相似的误差边界。最后，通过数值实验验证了不同策略的有效性。", "innovation": "创新点在于使用投影DPP或体积采样来生成加权最小二乘估计，这种方法通过引入点之间的依赖性来提高样本选择的多样性。论文还提出了独立重复使用投影DPP或体积采样的策略，该策略在实践上需要更少的样本数量来达到与独立点或体积采样类似的误差边界。此外，论文还讨论了连续嵌入$L^2$空间的范数空间$H$中的函数逼近问题。", "conclusion": "论文得出结论，在使用$O(m\text{log}(m))$数量的样本时，使用投影DPP或体积采样的加权最小二乘方法可以在期望值意义上达到几乎最优的$L^2$逼近误差。此外，在某些范数空间$H$中，此方法使得$L^2$逼近误差几乎肯定地被测得的最佳逼近误差所限制。最后，独立重复使用投影DPP或体积采样的策略在实践中需要更少的样本数量来达到相似的误差边界，这一发现进一步优化了样本选择过程。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2304.01430", "html_url": "https://arxiv.org/abs/2304.01430", "title": "Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots", "title_en": "Divided Attention: Unsupervised Multi-Object Discovery with Contextually Separated Slots", "authors": "Dong Lao,Zhengyang Hu,Francesco Locatello,Yanchao Yang,Stefano Soatto", "background": "该研究关注在没有语义标注的情况下对象在视觉感知中的出现。现有研究通常依赖预训练特征和语义标签来进行对象分割和运动分割，但在真实场景中，尤其是在实时应用中，这种方法可能面临监督数据不足、计算复杂度高等挑战。", "innovation": "研究提出了一种无需监督、不依赖预训练特征的多对象分割方法。该方法的核心是多模态条件编码-解码架构，使用光流作为输入编码器生成多个隐编码（槽），以颜色图像为解码器条件生成光流。这种方法通过设计训练准则来促进隐编码之间的信息分离，从而区分不同的移动区域。在测试阶段，该方法能够处理不同于训练阶段的对象数量和图像分辨率，且对槽的排列变化具有不变性。这种方法不仅实现了最先进的性能，还在速度上提高了三倍，最高可达每秒104帧，并将相对于监督方法的性能差距缩小到12%或更少。", "conclusion": "DivA方法通过无监督学习实现了多对象分割，无需预先标注，显著提高了实时性能和对比度学习效果。通过在DivA的对象提案上训练DINO模型，能够在不超过5000个视频片段的情况下，将性能差距相对于基于ImageNet的训练方法缩小到最多30.2%。这种方法展示了其在无监督学习和对象分割任务中的潜力和优势。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.16593", "html_url": "https://arxiv.org/abs/2410.16593", "title": "同ophilic 图上可扩展且表征丰富的图神经网络的图采样", "title_en": "Graph Sampling for Scalable and Expressive Graph Neural Networks on Homophilic Graphs", "authors": "Haolin Li,Haoyu Wang,Luana Ruiz", "background": "图神经网络（GNN）在许多图机器学习任务中表现出色，但在大规模网络中遇到挑战。当前的GNN迁移性方法依赖于随机子采样，这会导致子图不连通且降低模型的表征能力。", "innovation": "提出了一种基于特征同ophil性的新颖图采样算法，该算法通过最小化数据相关矩阵的迹来更好地保持图拉普拉斯矩阵的迹——图连通性的代理，同时比频谱方法具有更低的复杂度。", "conclusion": "实验结果表明，在同ophilic图上，该方法在保持拉普拉斯矩阵迹和GNN迁移性方面优于随机采样。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.15441", "html_url": "https://arxiv.org/abs/2412.15441", "title": "runtime engines和执行提供者在代码小语言模型服务中的资源利用洞察", "title_en": "Insights into resource utilization of code small language models serving with runtime engines and execution providers", "authors": "Francisco Durán,Matias Martinez,Patricia Lago,Silverio Martínez-Fernández", "background": "随着语言模型，特别是在代码生成方面的快速成长，对计算资源的需求日益增加，这引发了对能源消耗和环境影响的担忧。优化语言模型推理资源利用变得至关重要，因此Small Language Models (SLMs)被作为一个有前景的解决方案提出，来减少资源需求。本文目的旨在分析深学习服务配置（作为运行时引擎和执行提供者的组合）对小语言模型推断资源利用的影响，包括能源消耗、执行时间和计算资源利用率等方面。", "innovation": "本研究采用了面向技术的多阶段实验管道，使用了12个代码生成小语言模型来调查不同配置下的能源消耗、执行时间和计算资源利用情况。研究发现了显著差异，CUDA执行提供者配置在能源消耗和执行时间上表现优于CPU执行提供者配置。TORCH与CUDA结合的配置展现出最高的能源效率，相对于其他配置可节省37.99%到89.16%的能源。优化的运行时引擎如与CPU执行提供者结合的ONNX，可在基于CPU的配置中节省8.98%到72.04%的能源。", "conclusion": "研究显示，服务配置的选择显著影响资源利用率。尽管需要进一步研究，但推荐上述配置以满足软件工程师们提高服务资源利用率的需求。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06946", "html_url": "https://arxiv.org/abs/2412.06946", "title": "基于深度学习的二元黑洞波形数值相对论代理模型", "title_en": "A Deep Learning Powered Numerical Relativity Surrogate for Binary Black Hole Waveforms", "authors": "Osvaldo Gramaxo Freitas,Anastasios Theodoropoulos,Nino Villanueva,Tiago Fernandes,Solange Nunes,José A. Font,Antonio Onofre,Alejandro Torres-Forné,José D. Martin-Guerrero", "background": "引力波近似模型对于引力波天文学至关重要，它们允许通过干扰性滤波或参数估计而不使用昂贵的数值相对论（NR）模拟来覆盖二元黑洞参数空间。但这些近似模型通常会以准确度为代价换取计算效率。为了降低这种折中，可以使用数值相对论波形空间内的插值方法构建数值相对论代理模型。本文提出了一种神经网络为基础的两阶段训练方法来构建NR代理模型，首先在基于近似模型生成的波形上进行训练，然后用NR数据进行微调。", "innovation": "提出的代理模型是通过两阶段训练（首先在近似模型生成的波形上训练，然后用NR数据微调）构建的。这些双阶段的人工神经代理模型（DANSur）具有快速且竞争力的波形生成能力，能够在20毫秒内使用GPU生成数百万个波形，同时与NR的均方误差保持在10^-4左右。", "conclusion": "研究表明，经过培训和微调的DANSur模型可以在\textsc{bilby}框架中使用，用于参数估计任务。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.04502", "html_url": "https://arxiv.org/abs/2412.04502", "title": "物理导向的高斯过程作为线性模型预测控制器", "title_en": "Physics-informed Gaussian Processes as Linear Model Predictive Controller", "authors": "Jörn Tebbe,Andreas Besginow,Markus Lange-Hegermann", "background": "本文介绍了一种用于控制线性时不变系统的追踪问题的新算法。该控制器基于一个满足具有常系数的线性常微分方程的高斯过程（GP）的实现。通过条件概率求解器在高斯过程上对设定点进行条件化来确定追踪控制器输入，即控制作为推理。通过引入后验高斯过程中虚拟设定点，提出的方法能够引入点约束，该方法在模型预测控制方案中得到了实现。理论分析表明，在最优控制问题中，该控制器通过利用贝叶斯推理的一般结果保证了开环稳定性并在数值例子中验证了这个结果。", "innovation": "该算法通过引入虚拟设定点，使得后验高斯过程能够满足点约束，从而提出了一个模型预测控制方案。同时，通过在贝叶斯推理的基础上，理论上证明了该控制器的开环稳定性。这一方法将物理导向的高斯过程应用于线性模型预测控制中，为实现精确且稳定的追踪控制提供了一种新的方法。", "conclusion": "本文通过基于高斯过程的方法，提出了一种线性模型预测控制器的新算法，该控制器通过虚拟设定点和贝叶斯推理手段实现了精确的追踪控制，并且保证了开环稳定性。这一研究证明了将高斯过程与模型预测控制结合的有效性，具有重要的理论和实践意义。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.02744", "html_url": "https://arxiv.org/abs/2410.02744", "title": "中性残差：重新审视模型扩展中的适配器", "title_en": "Neutral Residues: Revisiting Adapters for Model Extension", "authors": "Franck Signe Talla,Edouard Grave,Hervé Jégou", "background": "本文探讨了将预训练的大型语言模型扩展到未在训练期间遇到的新领域的问题。标准方法，如微调或低秩适应（LoRA）在领域适应方面非常成功，但并没有正式增加模型的容量。这通常导致一个权衡，在新领域表现良好和在原领域表现上衰退之间的权衡。", "innovation": "我们从数据、架构和训练过程三个角度重新审视并改进了适配器，使得新的残差块在原始领域输出接近零的结果。中性残差（Neutral Residues）方法在适应最初训练于英语的新语言时取得了强劲的结果，显著优于微调、LoRA或 vanilla适配器等竞争方法，在学习新语言和不忘记原有领域之间取得了更好的平衡。", "conclusion": "中性残差方法在将最先进的模型扩展到新语言时表现出色，相比于微调、LoRA或vanilla适配器等方法，在学习新语言和保持对英语的记忆之间表现更佳。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.17482", "html_url": "https://arxiv.org/abs/2502.17482", "title": "MVCNet: 多视图对比网络用于运动意象分类", "title_en": "MVCNet: Multi-View Contrastive Network for Motor Imagery Classification", "authors": "Ziwei Wang,Siyang Li,Xiaoqing Chen,Dongrui Wu", "background": "基于脑电图（EEG）的脑-计算机接口（BCI）能够通过解码大脑活动实现对外部通信，以往的研究主要集中在运动想象（MI）的解码上，但由于大多数现有模型依赖单一流架构且忽略了EEG信号的多视图性质，导致了性能和泛化能力的限制", "innovation": "提出了一种多视图对比网络（MVCNet），这是一种双分支结构，可以并行整合卷积神经网络（CNN）和变换器（Transformer）模块，以捕捉局部空间-时间特征和全局时间依赖性。通过引入统一的增强管道和多视图对比模块与多模型对比模块来增强训练数据的信息性，最终通过对比损失和分类损失对表示进行融合和联合优化。研究表明，MVCNet在五个公开的运动意象数据集上跨三个场景下的解码中，持续优于九个最先进的运动想象解码网络，证明了其有效性和泛化能力", "conclusion": "MVCNet通过整合多视图信息和双分支建模，提供了一种用于运动想象解码的鲁棒解决方案，促进了更可靠BCI系统的研发"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.03094", "html_url": "https://arxiv.org/abs/2410.03094", "title": "由纠缠导致的可验证和稳健的量子学习优势", "title_en": "Entanglement-induced provable and robust quantum learning advantages", "authors": "Haimeng Zhao,Dong-Ling Deng", "background": "量子计算在增强机器学习方面具有独特的潜力，但尚未展示出量子学习的优势。本研究在噪音鲁棒性和无条件方面建立了量子模型在表达能力、推理速度和训练效率方面的优势，与常用的经典模型相比，特别是通过设计了一个可以使用纠缠以常数参数数量解决的任务，而不是常用的经典模型必须随着准确性呈线性增长。", "innovation": "通过信息理论证明了量子模型中的纠缠可以在非局域任务中减少所需通信，从而实现了可验证和稳健的量子学习优势。该研究提供了一个可以使用纠缠以常数参数数量解决的特定任务，并表明量子模型在常数资源下可训练且对常数噪音具有鲁棒性。", "conclusion": "通过数值实验和一系列离子囚禁实验，研究结果在IonQ Aria器件上证明了量子学习的优势。这些结果为利用当前的有噪音的中尺度量子设备展示量子学习优势提供了宝贵的指导。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.03351", "html_url": "https://arxiv.org/abs/2408.03351", "title": "使用混合量子-经典方法的MNIST分类的量子迁移学习", "title_en": "Quantum Transfer Learning for MNIST Classification Using a Hybrid Quantum-Classical Approach", "authors": "Soumyadip Sarkar", "background": "本文基于MNIST数据集提出了一个结合量子和经典计算的混合模型，旨在将MNIST的数字图像压缩到低维特征空间，然后将这些特征映射到一个5量子比特的量子态上，利用量子计算的特性提高图像分类的效率和准确性。", "innovation": "该研究表明通过自编码器将每个28x28像素的图像压缩为一个64维的隐含空间，再通过主成分分析（PCA）减少至5个主要成分，进一步将这5个特征编码为5量子比特量子电路的旋转角度。通过应用单一量子比特旋转门（$R_y$门）和一系列的交换门，生成一个非纠缠状态，最后采用一个经典的神经网络对这些量子特征向量进行训练以进行分类任务。这种方法在不完善的情况下集成量子计算以提高分类任务的性能。", "conclusion": "在MNIST数据集上的实验结果表明，该混合模型可以成功分类数字，展现出将量子计算集成到分类流水线中的可行性，尽管其准确率（约75%）低于经典基线（在相同压缩数据上的约98%），但仍展示了量子计算潜力在经典机器学习中的应用。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.15215", "html_url": "https://arxiv.org/abs/2502.15215", "title": "Tensor Product Neural Networks for Functional ANOVA Model", "title_en": "Tensor Product Neural Networks for Functional ANOVA Model", "authors": "Seokhun Park,Insung Kong,Yongchan Choi,Chanmoo Park,Yongdai Kim", "background": "随着机器学习模型变得越来越复杂，对机器学习模型可解释性的需求也越来越大。功能ANOVA模型是一种将高维函数分解为多个低维函数（通常称为组件）的工具，是可解释AI中常用的方法之一。近年来，研究人员开发了各种神经网络来估计功能ANOVA模型中的每个组件。然而，当估计各组件时，这些神经网络极其不稳定，因为组件本身并不是唯一的。这意味着一个给定函数可能存在多种功能ANOVA分解。", "innovation": "本文提出了一个新的神经网络ANOVATensor Product Neural Network (ANOVA-TPNN)，它可以在确保唯一功能ANOVA分解的前提下，稳定并准确地估计每个组件。ANOVATPNN灵感来源于张量积基函数展开。理论证明，ANOVATPNN能够很好地近似任意光滑函数。实验结果表明，当训练数据和模型参数的初始值变化时，ANOVATPNN在估计各组件方面能提供更加稳定的表现和解释，相比于现有神经网络而言更为优越。", "conclusion": "本文提出的ANOVATPNN相较于现有方法，提供了一种更稳定、更准确的组件估计方法，这将有助于提升功能ANOVA模型的可解释性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.20632", "html_url": "https://arxiv.org/abs/2502.20632", "title": "变分退火二维水-疏蛋白质折叠", "title_en": "Lattice Protein Folding with Variational Annealing", "authors": "Shoummo Ahsan Khandoker,Estelle M. Inack,Mohamed Hibat-Allah", "background": "理解蛋白质折叠的原理是计算生物学的一个基本前提，对药物设计、生物工程以及基本生物学过程的理解具有重要意义。水-疏（HP）网格蛋白质折叠模型提供了一种简化而强大的框架来研究蛋白质折叠的复杂性，能够探索在受约束条件下能量最优的折叠结构。然而，寻找这些最优折叠是一个计算上具有挑战性的组合优化问题。", "innovation": "本文介绍了一种新颖的上限训练方案，该方案采用遮罩技术来识别二维HP网格蛋白质折叠中的最低能量折叠。通过结合Dilated递归神经网络（RNN）与温度波动驱动的退火过程，本方法能够准确预测基准系统（最多60个珠子）的能量最优折叠。此外，该方法还可以抑制无效折叠样本的生成，同时保持RNN自回归采样的特性。该方案具有三维通用性和可扩展性，可以应用于更大字母表的网格蛋白质模型。研究表明，先进的机器学习技术在处理复杂的蛋白质折叠问题以及其他受限的组合优化挑战方面具有潜力。", "conclusion": "本研究强调了先进机器学习技术在解决复杂蛋白质折叠问题和其他受限组合优化问题方面的潜力。该方法不仅能够准确预测蛋白质的最优折叠，还展示了其在三维空间和更大字母表网格蛋白质模型中的可拓展性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.17564", "html_url": "https://arxiv.org/abs/2503.17564", "title": "ModalTune: 使用多模态信息对幻灯片级基础模型进行微调以在数字病理学中实现多任务学习", "title_en": "ModalTune: Fine-Tuning Slide-Level Foundation Models with Multi-Modal Information for Multi-task Learning in Digital Pathology", "authors": "Vishwesh Ramanathan,Tony Xu,Pushpak Pati,Faruk Ahmed,Maged Goubran,Anne L. Martel", "background": "数字病理学中的预测任务由于全视野图像（WSI）的巨大尺寸和训练信号的弱性质而具有挑战性。计算技术的进步、数据可用性的提高以及自我监督学习（SSL）的发展为级联模型（SLFMs）在数据稀缺情况下改进预测任务铺平了道路。然而，现有方法未能充分利用任务和模态之间的共享信息。", "innovation": "提出了一种名为 ModalTune 的新颖微调框架，引入了模态适配器以在不修改 SLFM 权重的情况下整合新模态。此外，使用大语言模型（LLM）将标签编码为文本，捕捉多任务和多种癌症类型之间的语义关系。结果证明 ModalTune 在四种癌症类型下达到了单模态和多模态模型的最佳结果，在综合生存和癌症亚型预测方面表现出色，并在泛癌设置中保持竞争力。此外，证明 ModalTune 在两个新的分布外（OOD）数据集上具有可推广性。这是首个多模态、多任务和泛癌建模统一微调框架在数字病理学中的应用", "conclusion": "ModalTune在数字病理学中的多模态、多任务和泛癌建模中实现了最先进的结果，同时展示了其在新分布外数据集上的可推广性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.15897", "html_url": "https://arxiv.org/abs/2503.15897", "title": "学习基于神经上下文场景图的3D场景类比", "title_en": "Learning 3D Scene Analogies with Neural Contextual Scene Maps", "authors": "Junho Kim,Gwangtak Bae,Eun Sun Lee,Young Min Kim", "background": "理解场景上下文对于机器在未见过或噪声较强的3D环境中执行任务和适应先验知识至关重要。数据驱动的学习无法全面涵盖多样化的布局和开放空间，因此提出通过教导机器识别3D空间中的关系共性来解决问题。与现有的单一实例级别地图不同，提出的场景级别地图能够平滑连接大面积场景区域，可能为AR/VR中的轨迹传输、模仿学习中的长时间演示传输和上下文感知物体重构提供独特应用。此方法通过减少对个体特征点的依赖，使其在输入噪声或形状变化中更加稳健。实验表明，本方法在识别场景类比和在多种室内场景中传递轨迹或物体放置方面是有效的，显示出其在机器人技术和AR/VR应用中的潜力", "innovation": "提出了一种基于神经上下文场景图的方法，用于找到3D场景类比。该方法提取描述场景的语义和几何上下文，并以粗到细的方式整体对其重新对齐以进行地图估计。这种方法减少了对个体特征点的依赖，使其在噪声或形状变化的输入中更加稳健，具有独特应用潜力，如轨迹传递、模仿学习和物体重新排列等", "conclusion": "实验结果证明了本方法在多种室内场景中识别场景类比和传递轨迹或物体放置的有效性，显示了其在机器人技术和AR/VR中的潜在应用价值。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.18711", "html_url": "https://arxiv.org/abs/2503.18711", "title": "Accenture-NVS1: 一种新颖视图合成数据集", "title_en": "Accenture-NVS1: A Novel View Synthesis Dataset", "authors": "Thomas Sugg,Kyle O'Brien,Lekh Poudel,Alex Dumouchelle,Michelle Jou,Marc Bosch,Deva Ramanan,Srinivasa Narasimhan,Shubham Tulsiani", "background": "该论文介绍了一种专门设计用于空中和地面成像领域新颖视图合成研究的数据集ACC-NVS1。数据收集于2023年和2024年，在美国得克萨斯州奥斯丁和宾夕法尼亚州匹兹堡进行。该数据集包含六种不同场景的图像，共计148,000张，涵盖了从空中和地面相机拍摄的图像。该数据集旨在解决变化高度和瞬时对象等挑战，用以补充现有数据集，为全面研究提供额外资源而非作为基准数据集。", "innovation": "该创新在于专门为新颖视图合成领域设计的数据集ACC-NVS1，涵盖了多样的实际场景，解决了特定的挑战，比如海拔变化和瞬时物体的影响，提供了额外的资源供研究使用，从而推动该领域的进一步发展。", "conclusion": "ACC-NVS1数据集旨在补充现有的数据集，为研究人员提供更丰富的资源，用于新颖视图合成的全面研究。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.05422", "html_url": "https://arxiv.org/abs/2504.05422", "title": "EP-Diffuser: 一种基于多项式表示的高效扩散模型用于交通场景生成与预测", "title_en": "EP-Diffuser: An Efficient Diffusion Model for Traffic Scene Generation and Prediction via Polynomial Representations", "authors": "Yue Yao,Mohamed-Khalil Bouzidi,Daniel Goehring,Joerg Reichardt", "background": "随着预测时间窗口的增加，预测交通场景未来的演变变得越来越困难，因为代理行为具有多模态的特点。大多数最先进的预测模型主要集中在预测最有可能的未来轨迹上。然而，为了确保自动驾驶汽车的安全运行，覆盖可实现的运动替代方案的分布同样重要。现有的大多数预测模型未能满足这一需求，这限制了自动驾驶汽车的安全性能。", "innovation": "本文提出了一种新颖的EP-Diffuser模型，这是一种参数高效的扩散生成模型，旨在捕捉可能的交通场景演变的分布。该模型在给定道路布局和代理历史的情况下，能够生成多样的、合理的场景延续。实验表明，即使模型规模较小，EP-Diffuser也能在Argoverse 2数据集上实现高准确性和可信度的预测。此外，进一步的研究表明，该模型在Waymo Open数据集上的泛化能力更强，显示出更高的稳健性。", "conclusion": "EP-Diffuser模型通过提供多样的、合理的预测场景实现了一种更实际的方法来描绘未来交通场景的可能性，这有助于提高自动驾驶汽车的安全性。实验结果证明了EP-Diffuser在准确性和可信赖度上的优势，同时显示出其在不同数据集上的泛化能力和稳健性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.11952", "html_url": "https://arxiv.org/abs/2504.11952", "title": "鲁棒且细粒度的AI生成文本检测", "title_en": "Robust and Fine-Grained Detection of AI Generated Texts", "authors": "Ram Mohan Rao Kadiyala,Siddartha Pullakhandam,Kanwal Mehreen,Drishti Sharma,Siddhant Gupta,Jebish Purbey,Ashay Srivastava,Subhasya TippaReddy,Arvind Reddy Bobbili,Suraj Telugara Chandrashekhar,Modabbir Adeeb,Srinadh Vura,Suman Debnath,Hamza Farooq", "background": "现有的检测系统在识别AI生成的短文本时往往不够准确，且未能很好地处理人与AI共同创作的文本场景。随着更多先进的人工智能语言模型（LLMs）的出现，理想的检测系统应能够处理各种生成器，包括部分由人类和LLM共同创作的文本。", "innovation": "本文提出了一套针对标记分类任务的模型，这些模型经过大量人机共同创作文本的训练，能够在未知领域、未知生成器、非母语作者以及对抗性输入的文本上表现出色。此外，还构建了一个包含超过240万条这种文本的新数据集，涵盖了23种语言和多个知名的商用LLM。该研究还包括对各个领域及生成器的文本性能分析，并比较了对抗对抗性方法、输入文本长度及生成文本特征与原始人类撰写的文本之间的差异。", "conclusion": "本文展示了新型模型及数据集在检测AI生成的文本方面的优势，并为该领域提供了新的见解，特别是在处理部分人为和AI共同创作的文本方面。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05085", "html_url": "https://arxiv.org/abs/2505.05085", "title": "学习动态启发式的不变子空间以近似柯磐和传输算子", "title_en": "Learning dynamically inspired invariant subspaces for Koopman and transfer operator approximation", "authors": "Gary Froyland,Kevin Kühl", "background": "转移和柯磐算子方法为表示复杂的非线性动力系统提供了框架，通过线性变换来实现，这有助于对系统内在动态的理解。这些算子的谱提供了关于系统预测能力和涌现行为的重要见解，但高效地从数据中估计它们仍然具有挑战性。本文通过通用算子和表示学习的视角来解决这个问题，即用有效的有限维表示来近似这些线性算子。具体而言，本文通过机器学习的方式学习正交基函数，这些基函数根据系统动态地调整。这种学习到的基函数不仅准确地近似了算子的作用，而且提供了近似不变的有限维子空间。", "innovation": "本文提出了一种通过机器学习正交基函数来动态地近似柯磐和传输算子的方法。这些基函数能够根据系统的动态进行调整。这种方法有效地利用了有限维度的表示，从而提供了一个准确近似算子作用的基和几乎不变的有限维子空间。这种方法展示了通过估计算子检索谱性质的能力，并突出了机器学习基函数的动态适应性特征。", "conclusion": "本文通过学习动态启发式的不变子空间近似柯磐和传输算子，展示了如何通过机器学习方式获得更准确和动态适应的基函数。这种方法为理解和分析复杂的非线性动力系统提供了新的工具。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10006", "html_url": "https://arxiv.org/abs/2506.10006", "title": "基于动态双向重建的灵活多模态输入HER2表达预测", "title_en": "HER2 Expression Prediction with Flexible Multi-Modal Inputs via Dynamic Bidirectional Reconstruction", "authors": "Jie Qin,Wei Yang,Yan Su,Yiran Zhu,Weizhen Li,Yunyue Pan,Chengchang Pan,Honggang Qi", "background": "在乳腺癌HER2评估中，临床评估依赖于结合H&E和IHC图像，然而同时获得这两种模态常常受到临床限制和成本的阻碍。本研究背景在于提出一种适应性双模态预测框架，以灵活支持单模态或双模态输入。", "innovation": "该研究提出的核心创新包括：动态分支选择器根据输入可用性激活模态完成或联合推断；和跨模态生成对抗网络（CM-GAN），以在缺失模态下重建特征空间。", "conclusion": "这种设计显著提高了H&E单模态的准确性（从71.44%提高到94.25%），在全双模态输入条件下达到了95.09%的准确率，并在单模态条件下保持了90.28%的可靠性。双模态优先，单模态兼容的架构在不强制同步获取的情况下提供了近似双模态的准确度，为资源有限的地区提供了一种成本效益高的解决方案，从而大幅提高了HER2评估的可访问性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07820", "html_url": "https://arxiv.org/abs/2507.07820", "title": "AI应更好地感知，而非简单扩大：自适应感知作为范式转变", "title_en": "AI Should Sense Better, Not Just Scale Bigger: Adaptive Sensing as a Paradigm Shift", "authors": "Eunsu Baek,Keondo Park,Jeonggil Ko,Min-hwan Oh,Taesik Gong,Hyung-Sin Kim", "background": "当前的AI进步主要依赖于扩大神经模型和扩展训练数据集，以实现泛化和鲁棒性。尽管取得了显著的成功，但这种范式却带来了显著的环境、经济和伦理成本，限制了可持续性和公平性。", "innovation": "受生物感觉系统中动态适应性的启发（例如调整瞳孔大小、调节视力焦点等），该研究倡导采用自适应感知作为必要的基础转变。自适应感知在输入层面主动调节传感器参数（如曝光、灵敏度、多模态配置），可显著减轻协变量变化并提高效率。实证研究表明，自适应感知使小型模型（如EfficientNet-B0）超越大规模模型（如OpenCLIP-H），这些大规模模型虽然训练数据和计算资源更多。", "conclusion": "我们概述了一个将自适应感知广泛集成到机器人、医疗保健、自主系统、农业和环境监测等现实应用中的路线图，评估了技术与伦理集成挑战，并提出了标准化基准、实时自适应算法、多模态整合及隐私保护方法等靶向研究方向。这些努力旨在使AI社区向可持续、稳健和公平的人工智能系统转型。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.13201", "html_url": "https://arxiv.org/abs/2504.13201", "title": "CEE: 通过子空间概念旋转的实体智能推理时防逃脱防御", "title_en": "CEE: An Inference-Time Jailbreak Defense for Embodied Intelligence via Subspace Concept Rotation", "authors": "Jirui Yang,Zheyu Lin,Zhihui Lu,Yinggui Wang,Lei Wang,Tao Wei,Xin Du,Shuhan Yang", "background": "大型语言模型（LLMs）现在成为嵌入式智能（EI）系统如机器人和自动驾驶车辆的认知核心。然而，这种集成也使它们面临严重的逃逸风险，恶意指令可以转化为危险的物理行为。现有防御机制存在明显缺陷，包括高训练成本、显著的推理延迟和复杂的超参数调整，这些都限制了它们的实际应用。", "innovation": "我们提出了一个新的高效的推理时防御框架：概念增强工程（CEE）。CEE通过直接操纵模型的内部表示来增强其固有的安全性机制，不需要额外的训练或外部模块，从而提高防御效率。此外，CEE引入了一种基于旋转的控制机制，能够实现稳定和线性可调的行为控制。这设计消除了繁琐的手动调整，并避免了其他表示工程方法中常见的输出下降问题。", "conclusion": "在多个嵌入式智能安全基准测试和不同的攻击场景下进行的广泛实验表明，CEE显着提高了各种多模态LLM的防御成功率。它有效地缓解了安全风险，同时保持了高质量的生成和推理效率，为部署更安全的嵌入式智能系统提供了潜在的解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.18675", "html_url": "https://arxiv.org/abs/2507.18675", "title": "推进基于视觉的人类动作识别：探索视觉-语言CLIP模型在领域无关任务中的泛化能力", "title_en": "Advancing Vision-based Human Action Recognition: Exploring Vision-Language CLIP Model for Generalisation in Domain-Independent Tasks", "authors": "Utkarsh Shandilya,Marsha Mariya Kappan,Sanyam Jain,Vijeta Sharma", "background": "人类动作识别在医疗和医学领域起着关键作用，支持如患者行为监控、跌倒检测、外科机器人监督以及技能评估等应用。尽管传统的模型如CNN和RNN已经取得了一定的成功，但在处理多样性和复杂的动作时往往表现不佳。最近，基于视觉-语言的模型，尤其是基于变换器的CLIP模型，展示了在泛化动作识别方面的巨大潜力。", "innovation": "本文评估了CLIP在UCF-101数据集上的表现，并系统地分析了三种不同的遮蔽策略对其性能的影响：基于百分比和形状的黑色遮蔽，特指特征的遮蔽，以及隔离遮蔽。研究结果表明，CLIP表现不一致，尤其在关键视觉线索被遮挡时会频繁出现错误分类。为了克服这些限制，本文提出了一种结合类别特异性噪声的方法，通过自定义损失函数学习，以增强对类别定义特征的关注。这种方法提高了分类准确性和模型的信心，减少了偏见。", "conclusion": "本文讨论了将这些模型应用到临床领域所面临的挑战，并提出了未来工作中提高跨领域无关医疗场景泛化能力的方向。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.21567", "html_url": "https://arxiv.org/abs/2505.21567", "title": "EaqVLA: Encoding-aligned Quantization for Vision-Language-Action Models", "title_en": "EaqVLA: Encoding-aligned Quantization for Vision-Language-Action Models", "authors": "Feng Jiang,Zihao Zheng,Xiuping Cui,Maoliang Li,JIayu Chen,Xiang Chen", "background": "近年来，具身人工智能（Embodied AI）的不断发展，使端到端的控制策略，如视觉-语言-行动（Vision-Language-Action, VLA）模型逐渐成为主流。现有的VLA模型在计算和存储成本上存在较高开销，需要进行优化。量化技术被认为是有效的方法之一，可以降低内存成本并加速计算，但这一技术在应用到VLA模型时遇到了挑战，因为这些模型中的token对齐问题阻碍了现有量化方法的应用。为了解决这一问题，该研究提出了一种优化框架EaqVLA，应用对齐编码量化技术（encoding-aligned quantization）来改进VLA模型的性能。", "innovation": "研究提出了一种新的优化框架EaqVLA，该框架通过一种全面的分析方法来识别各种粒度下的token对齐偏差，并基于分析结果提出了一种基于编码对齐的混合精度量化方法。这种方法有效解决了VLA模型在应用现有量化方法时遇到的问题，实现了对端到端行动控制的最佳量化性能，并超出现有量化方法的速度约为xxx倍。", "conclusion": "实验结果表明，提出的EaqVLA框架在保持端到端行为控制的最佳量化表现的同时，实现了相比之下xxx倍的加速。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.20980", "html_url": "https://arxiv.org/abs/2505.20980", "title": "在多层网络中识别超级传播者", "title_en": "Identifying Super Spreaders in Multilayer Networks", "authors": "Michał Czuba,Mateusz Stolarski,Adam Piróg,Piotr Bielak,Piotr Bródka", "background": "超级传播者的识别可以被视作影响力最大化问题的一个子任务，旨在找出在选定为单一传播种子时能够最有效地传播信息的网络中的个体。多层网络能够捕捉不同类型的交互（例如物理-虚拟或职业-社会），因此可以更准确地表示复杂的社交结构和关系网络。在本研究中，通过模拟信息在数百个网络中的扩散来构建数据集。这被认为是针对多层网络的第一种专门构建的数据集。将任务转化为基于四维向量的排序预测问题，该向量量化每个节点的传播潜力：（i）激活次数；（ii）传播过程的持续时间；（iii）激活峰值数量；（iv）峰值出现的模拟步骤。研究结果表明，使用这种四维度量化方式能够更准确地识别高影响节点。同时，通过多层网络自适应的设计，模型能够适应不同的图大小和结构。实验结果表明，TopSpreadersNetwork模型在多种实际和合成数据集上能够比传统中心性启发式方法和现有深度学习方法获得更好的性能", "innovation": "本文引入了一种基于图神经网络的方法来识别多层网络中的超级传播者。构建了一个全新的数据集，该数据集是针对多层网络的首个多层网络数据集，提出了一个基于四维向量的排序预测问题来量化节点的传播潜力。该方法通过一个关系无关的编码器和一个自定义的聚合层设计实现了一种多层网络自适应的方法，使其能够泛化到未见过的数据和适应不同大小的图", "conclusion": "实验结果显示，TopSpreadersNetwork模型在多种现实和合成多层网络数据集上都表现出了在识别关键节点上的优越性能，并通过量化输出提高了可解释性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.01631", "html_url": "https://arxiv.org/abs/2507.01631", "title": "Tile and Slide: A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "title_en": "Tile and Slide : A New Framework for Scaling NeRF from Local to Global 3D Earth Observation", "authors": "Camille Billouard,Dawa Derksen,Alexandre Constantin,Bruno Vallet", "background": "Neural Radiance Fields (NeRF) 已经在利用多视角卫星图像进行三维重建方面崭露头角。然而，最先进的NeRF方法通常受限于小型场景，因为它们在训练期间需要大量的内存。此前，处理大规模场景的NeRF方法通过将场景分割成多个NeRF来缓和这一问题。本文研究了这一限制，并探讨了一种新的框架，以应对大规模场景建模问题。", "innovation": "本文提出了Snake-NeRF框架，该框架能够处理大规模场景而不受内存限制。通过将感兴趣区域分割成不重叠的NeRF，并引入一种新颖的$2\times 2$三维平铺策略和分段采样器，Snake-NeRF可以防止三维重建中平铺边缘的误差。此外，该方法仅需要单个设备即可以实现线性时间复杂度的处理，而不需要降低图像质量。", "conclusion": "实验证明，大规模卫星图像能够有效地在此框架下以线性时间复杂度处理，在单个GPU上进行而不会牺牲图像质量。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.19219", "html_url": "https://arxiv.org/abs/2505.19219", "title": "Where Paths Collide: 一种经典与学习导向的多智能体路径规划全面综述", "title_en": "Where Paths Collide: A Comprehensive Survey of Classic and Learning-Based Multi-Agent Pathfinding", "authors": "Shiyue Wang,Haozheng Xu,Yuhan Zhang,Jingran Lin,Changhong Lu,Xiangfeng Wang,Wenhao Li", "background": "多智能体路径规划（MAPF）是人工智能和机器人技术中的基础问题，涉及为多个从起点到目标的智能体计算无碰撞路径。随着自主系统在仓库、城市交通及其他复杂环境中的广泛应用，MAPF已成为多智能体协调的关键技术。传统算法方法与新兴的学习方法在MAPF研究中的差距很大，这篇综述旨在弥合这一差距。综述中详细分析了搜索方法、编译方法及数据驱动技术，并指出经典方法和学习方法在实验实践中的评估差异，强调了标准化基准测试的重要性。", "innovation": "这篇论文提出了一个统一的框架，涵盖搜索方法（冲突解决搜索、优先级搜索、大邻域搜索）、编译方法（SAT、SMT、CSP、ASP和MIP形式化表述），以及数据驱动技术（强化学习、监督学习和混合策略）。系统分析了跨越200多篇论文的实验实践，揭示了经典方法和学习方法在评估方法上的显著差异，并提出了一些未来的研究方向，包括考虑博弈论因素的混合动机MAPF，基于大型语言模型的语言导向规划，以及结合传统方法严谨性和深度学习灵活性的神经求解器架构。", "conclusion": "这篇综述旨在为研究人员提供一个全面的参考，并为在日益复杂的实际应用中部署MAPF解决方案提供实用指南。强调了为了提高MAPF解决方案的性能和可靠性，标准化的基准测试协议非常必要，并展望了多智能体路径规划领域的未来研究方向。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.21886", "html_url": "https://arxiv.org/abs/2507.21886", "title": "通过呼吸信号实现高效疼痛识别：单一交叉注意力变换器多窗口融合管道", "title_en": "Efficient Pain Recognition via Respiration Signals: A Single Cross-Attention Transformer Multi-Window Fusion Pipeline", "authors": "Stefanos Gkikas,Ioannis Kyprakis,Manolis Tsiknakis", "background": "疼痛是一种影响大量人口的复杂状况。准确且一致的评估对于经历疼痛的个体至关重要，这有助于发展有效的管理策略并支持临床决策。自动疼痛评估系统提供了连续监测，支持临床决策制定，旨在减少痛苦并预防功能衰退。", "innovation": "该研究采用了一种利用呼吸信号作为输入并结合高效交叉注意力变换器和多窗口策略的方法，提出了一个融合管道。实验证明呼吸是疼痛评估的有效生理模态，并且精简且高效的模型在适当优化后往往能表现出色。该多窗口方法能够有效捕捉短时和长时间特征以及全局特性，从而增强了模型的表现能力。", "conclusion": "研究结果显示，呼吸信号对于疼痛评估具有重要意义，采用高效交叉注意力变换器和多窗口策略的方法能够有效地识别疼痛，提升模型的表现力。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.12911", "html_url": "https://arxiv.org/abs/2507.12911", "title": "LaViPlan：基于RLVR的语言引导视觉路径规划", "title_en": "LaViPlan : Language-Guided Visual Path Planning with RLVR", "authors": "Hayeon Oh", "background": "自主驾驶中的离域分布（OOD）场景指的是与训练领域相异的情况，常常导致计划器产生未预期且潜在危险的行为。早期研究中，视觉-语言模型（VLMs）因其在OOD设置下的广泛泛化能力被引入到自主驾驶研究中。研究发现，尽管VLMs能识别OOD场景并生成如“直行”或“右转”等用户级别的决策，但在高阶语言决策与低阶行动预测间的不匹配成为了一个新的挑战。", "innovation": "本文提出了LaViPlan框架，利用可验证奖励的增强学习（RLVR）来通过面向规划的指标优化VLMs。这种方法解决了现有通过监督学习微调的VLMs在识别驾驶场景时容易产生情境无关决策的失配问题。", "conclusion": "实验结果表明，我们的方法在OOD条件下提高了情境意识和决策能力，突显了其在缓解VLM代理与自主驾驶中的决策失配问题上的潜力。这项工作为VLM代理在自主驾驶中的应用引入了一个有前景的后训练范式。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19079", "html_url": "https://arxiv.org/abs/2507.19079", "title": "SmartPNT-MSF: 多传感器融合定位与导航研究数据集", "title_en": "SmartPNT-MSF: A Multi-Sensor Fusion Dataset for Positioning and Navigation Research", "authors": "Feng Zhu,Zihang Zhang,Kangcheng Teng,Abduhelil Yakup,Xiaohong Zhang", "background": "高精度导航和定位系统在自动驾驶车辆和移动测绘等应用中至关重要，需要稳健且连续的定位。为了测试和提升算法性能，多家研究机构和公司相继发布了一系列公开数据集。然而，现有数据集在传感器多样性和环境覆盖方面仍存在不足。为解决这些不足，加速相关领域的开发，开发了SmartPNT多源融合导航、定位和姿态数据集。该数据集集成了全球导航卫星系统（GNSS）、惯性测量单元（IMU）、光学相机和LiDAR等多种传感器的数据，提供了多传感器融合及高精度导航研究的丰富资源。", "innovation": "该数据集集成了多种传感器数据，覆盖了广泛的实际场景，具有多传感器融合功能。数据集的构建过程详细记录了传感器配置、坐标系定义和相机及LiDAR的校准程序。最新SLAM算法（如VINS-Mono和LIO-SAM）的验证表明，该数据集适用于先进导航研究。此外，数据集覆盖了城市、校园、隧道和郊区等多种环境，为推进导航技术发展提供了有价值的工具。", "conclusion": "通过提供一个公开、高质量的数据集，这项工作旨在弥补传感器多样性、数据可访问性和环境表示方面的不足，促进该领域的进一步创新。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22581", "html_url": "https://arxiv.org/abs/2507.22581", "title": "揭示激活特定语言神经元的影响", "title_en": "Unveiling the Influence of Amplifying Language-Specific Neurons", "authors": "Inaya Rahmanisa,Lyzander Marciano Andrylie,Mahardika Krisna Ihsani,Alfan Farizki Wicaksono,Haryo Akbarianto Wibowo,Alham Fikri Aji", "background": "研究表明，特定语言的神经元在大语言模型中有较强的关联性，并且它们的失活会影响模型的行为。然而，这些特定语言神经元在放大效应方面的作用尚未得到充分探索。这项工作通过在18种不同语言上进行干预，研究了放大特定语言神经元的效果，其中包括一些低资源语言。研究人员使用三种主要在不同语言上进行训练的语言模型来验证放大因子的有效性，通过提出的一种语言引导偏移量（LSS）评估分数来比较放大因子的效果，并将结果评估应用于下游任务：常识推理（XCOPA, XWinograd）、知识（Include）、以及翻译（FLORES）", "innovation": "这项研究通过在多语言环境中激活特定语言的神经元，揭示了其对模型行为的影响。首先，研究人员通过干预激活特定语言的神经元，并利用提出的一种新的评估方法（LSS）比较了放大因子的效果。其次，研究人员将这种干预应用于常识推理、知识和翻译等多个下游任务。第三，研究发现对于低资源语言来说，激活特定语言的神经元可能会带来额外的好处，但对于跨语言的知识迁移却效果有限", "conclusion": "研究发现，激活特定语言的神经元在多语言行为中具有显著的影响。对于某些测试语言，激活特定语言的神经元能够有效地驱动模型向目标语言行为。然而，这种干预通常会削弱跨语言的表现。这表明，特定语言的神经元放大可以对低资源语言有益，但对跨语言迁移的优势有限。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.22782", "html_url": "https://arxiv.org/abs/2507.22782", "title": "基于注意力机制的演员-批评家策略增强多智能体协作", "title_en": "Enhancing Multi-Agent Collaboration with Attention-Based Actor-Critic Policies", "authors": "Hugo Garrido-Lestache,Jeremy Kedziora", "background": "本文介绍了一种用于增强多智能体协作的强化学习算法，即Team-Attention-Actor-Critic（TAAC），它致力于提高在协作环境中多智能体的合作能力。TAAC采用了集中训练/集中执行方案，并在演员和批评家中加入了多头注意力机制。这一设计允许智能体间动态沟通，使得智能体能够要求同伴执行特定操作，从而有效管理由于联合动作空间扩大而导致的发展问题，同时保持高水平的合作。为了进一步提升协作效果，提出了一种惩罚性损失函数，鼓励智能体之间承担多样且互补的角色。", "innovation": "本文介绍了一种新的多智能体协作算法TAAC，该算法采用了集中训练/集中执行方案以及多头注意力机制，并引入了一种新的惩罚性损失函数来促进智能体之间的多样且互补的角色分配。通过在模拟足球环境中与其他多智能体相关的方法进行比较，TAAC在多种评估指标下表现优异，显示出更强的合作行为和更高的性能。", "conclusion": "研究表明，TAAC在一系列评估指标下的表现优于现有的多智能体策略，包括胜率、进球差、Elo评级、智能体间连接性、合理空间分布以及频繁的战术互动如控球权交换，从而证明了TAAC在增强多智能体协作方面的有效性。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.21035", "html_url": "https://arxiv.org/abs/2507.21035", "title": "GenoMAS：一种通过代码驱动基因表达分析的多智能体框架", "title_en": "GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis", "authors": "Haoyang Liu,Yijiang Li,Haohan Wang", "background": "基因表达分析在生物医学发现中扮演关键角色，但从原始转录组数据中提取有用信息依然面临极大挑战，由于处理大量复杂的半结构化文件以及需要广泛的领域专业知识。当前的自动化方法往往局限在僵化的流程中，容易在极端情况下失效，或者自动化程度过高缺乏必要的精确性。GenoMAS通过引入一个基于LLM的科学家团队，结合了结构化流程的可靠性与自主智能体的可适应性，来突破这些限制。", "innovation": "GenoMAS提出了一个基于LLM的科学家团队，通过类型化消息传递协议协调六位专一化的智能体，每位智能体都能为共享分析画布做出贡献。核心在于一种指导性规划框架，编程智能体将高层次任务要求分解为“行动单元”，并在每一步做出前进、修正、跳过或退步的决策，从而保持逻辑连续性同时灵活适应基因组数据的特异性。在GenoTEX基准测试中，GenoMAS在数据预处理中的综合相似性相关度达到了89.13%，基因识别的F1值为60.48%，分别比之前最好成果高出10.61%和16.85%。此外，GenoMAS还能够提出经文献佐证的生物合理基因表型关联并调整潜在的混杂因素。", "conclusion": "GenoMAS为基因表达分析的自动化和智能化提供了一种创新方法，不仅在技术性能上超越了前人，还在生物学意义和实用性方面提供了有价值的洞见。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19747", "html_url": "https://arxiv.org/abs/2507.19747", "title": "TokenBlowUp: 使用单调变换在LLM令牌空间中解决表示奇异性的方案", "title_en": "TokenBlowUp: Resolving Representational Singularities in LLM Token Spaces via Monoidal Transformations", "authors": "Dongfang Zhao", "background": "近期的研究提供了有力的证据，挑战了大型语言模型（LLMs）令牌嵌入空间的基础流形假说。这些发现揭示了多义词周围几何奇点的存在，可能导致表示不稳定。现存的方法假设数据流形是光滑的，因而无法解决这些内在结构缺陷。", "innovation": "本文在方案理论的语言中正式描述了这个问题，并通过在每个奇异点应用方案论的吹升来提出一种严格的解决方案。该过程用通过奇异点的例外除子替换其环境仿射方案中的奇异点，将其识別为一个包含令牌的澄清语义意义的几何空间——一个方向的射影空间。这一“表示去奇异化”的过程构建了一个新的几何景观。本文证明了一个形式定理，保证了这个新空间的几何规整化，并证明了原始病理已经得到解决。最后，本文概述了该框架的架构影响，提倡从静态查找转移到动态、几何地基础的计算。", "conclusion": "本文证明了新空间的几何规整化定理，并论述了该框架对语言模型架构的深远影响，提出了从静态查找转变为动态、几何地基础计算的新范式。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23269", "html_url": "https://arxiv.org/abs/2507.23269", "title": "XABPs: 向可解释的自主业务流程迈进", "title_en": "XABPs: Towards eXplainable Autonomous Business Processes", "authors": "Peter Fettke,Fabiana Fournier,Lior Limonad,Andreas Metzger,Stefanie Rinderle-Ma,Barbara Weber", "background": "自主业务流程（ABPs），即利用AI/ML技术自我执行的工作流，有望提高运营效率、减少错误、降低费用、改进响应速度，并使人类员工从更具策略性和创造性的工作中解脱出来。然而，ABPs也可能引发特定的担忧，包括减少相关方信任、调试困难、责任受阻、偏见风险以及合规性问题。", "innovation": "本文讨论了一种新的方法，即可解释的ABPs（XABPs），通过使系统能够阐述其决策背后的理由来解决上述担忧。文章提出了一种系统化的XABPs方法，对其实现形式进行了分类，构建了可解释性，并确定了走向XABPs的关键BPM研究挑战。", "conclusion": "本文提出了一种系统化的方法来实现XABPs，旨在通过增强透明度和可解释性来解决自主业务流程可能带来的相关问题，并指出了未来BPM研究的关键挑战。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23087", "html_url": "https://arxiv.org/abs/2507.23087", "title": "基于业务流程辅助生成智能合约的LLM研究", "title_en": "On LLM-Assisted Generation of Smart Contracts from Business Processes", "authors": "Fabian Stiehle,Hans Weytjens,Ingo Weber", "background": "大型语言模型（LLMs）改变了软件生产的方式。在更广泛的软件工程社区中，它们被探索用于从不同类型的输入生成代码的各种场景。本文研究了LLMs用于从业务流程描述生成智能合约代码的潜力，这是近年来的研究中提出的一种替代传统基于规则的代码生成方法的思路。然而，当前基于LLM的工作主要通过小样本评估生成的代码，并依赖于人工检查或仅测试代码是否编译，而忽视了正确执行。本文引入了自动评估框架，并使用更大规模的流程模型数据集提供了实证数据。研究测试了不同类型和大小的LLMs在实现智能合约执行重要属性方面的能力，包括控制流程流动、资源分配和数据条件。研究结果表明，LLM在性能上未能达到为智能合约开发所需的完美可靠性。未来研究建议探索LLMs在现有代码生成工具中的负责任集成，以确保更可靠的输出。本基准测试框架可以作为开发和评估此类集成的基础。", "innovation": "本文引入了一种自动评估框架，并使用更大规模的流程模型数据集提供了实证数据，测试了不同类型和大小的LLMs在实现智能合约执行重要属性方面的能力。这填补了当前基于LLM工作的不足之处，即主要通过小样本评估生成的代码，并依赖于人工检查或仅测试代码是否编译，而忽视了正确执行。该研究结果强调了需要进一步探索负责任的LLM集成以确保智能合约开发的可靠性。", "conclusion": "研究结果表明，LLM的性能未能达到智能合约开发所需的高度可靠性。作者建议未来的工作应该探索将LLMs负责任地集成到现有代码生成工具中，以确保更可靠的输出。与此同时，为智能合约开发和评估LLMs的集成，本基准测试框架可以作为一个基础。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23118", "html_url": "https://arxiv.org/abs/2507.23118", "title": "FlowETL: 自主驱动的示例导向数据工程管道", "title_en": "FlowETL: An Autonomous Example-Driven Pipeline for Data Engineering", "authors": "Mattia Di Profio,Mingjun Zhong,Yaji Sripada,Marcel Jaspars", "background": "ETL（Extract, Transform, Load）工作流是填充和维护数据仓库及其他分析师用于下游任务的数据存储的基础。现代ETL解决方案的主要缺点是需要大量的人工干预，用于设计和实现特定于上下文且通常不可泛化的转换。在ETL自动化领域的相关工作中虽然已经取得了一些进展，但仍然缺乏能够自动设计和应用这些转换的解决方案。", "innovation": "FlowETL是一个新颖的基于示例的自主ETL管道架构，旨在根据简明的用户定义的目标数据集自动标准化和准备输入数据集。FlowETL由一系列能够协同工作的组件组成。Planning Engine使用输入和输出数据集的样本构建转换计划，然后由ETL工人应用到源数据集上。监控和日志记录在整个管道过程中提供了可观测性。结果表明，FlowETL在14个不同领域的数据集上展示了泛化能力，这些数据集具有不同的文件结构和文件大小，这显示了FlowETL的有效性。", "conclusion": "结果证明，FlowETL具备跨不同领域、文件结构和文件大小的数据集进行泛化的潜力，展示了其作为一种自动化的ETL平台的巨大潜力。"}
{"llm_update_time": "20250801", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.19060", "html_url": "https://arxiv.org/abs/2507.19060", "title": "PurpCode：生成更安全代码的推理", "title_en": "PurpCode: Reasoning for Safer Code Generation", "authors": "Jiawei Liu,Nirav Diwan,Zhe Wang,Haoyu Zhai,Xiaona Zhou,Kiet A. Nguyen,Tianjiao Yu,Muntasir Wahed,Yinlin Deng,Hadjer Benkraouda,Yuxiang Wei,Lingming Zhang,Ismini Lourentzou,Gang Wang", "background": "当前，训练代码推理模型生成安全代码并抵御恶意网络活动仍然存在很大挑战。现有方法在处理这类问题时可能无法全面覆盖各种安全规则和负面影响。因此，需要一种新的培训方法来确保生成的代码不仅安全，还能保留模型的有用性。", "innovation": "PurpCode 是一项创新的后训练方法，通过两个阶段训练安全代码推理模型：首先进行规则学习，明确教授模型引用网络安全规则生成无漏洞代码并避免促进恶意网络活动；其次进行强化学习，利用多种多目标奖励机制优化模型的安全性并保持模型的有用性。此外，通过内部红队测试生成全面且覆盖面广的提示，以在模型中诱发不安全的网络活动。这种方法开发了基于推理的编码模型 PurpCode-32B，能够克服当前先进技术的安全性和实用性问题。", "conclusion": "基于 PurpCode 方法训练的 PurpCode-32B 编码模型在网络安全方面表现出色，超过了各种先进的模型。此方法还在一般性及网络安全特定场景下减少了模型的过拒绝率，同时保护模型在代码生成和通用安全知识中的实用性。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23120", "html_url": "https://arxiv.org/abs/2507.23120", "title": "Vibe Modeling: 挑战与机遇", "title_en": "Vibe Modeling: Challenges and Opportunities", "authors": "Jordi Cabot", "background": "随着新软件系统需求的增长和复杂性的增加，迫切需要更好的开发方法和技术。新型用户界面、智能组件的需求以及可持续性问题等都带来了新的挑战。过去几年，模型驱动工程（MDE）对于提高软件开发的质量和生产力起到了关键作用，但模型本身也越来越复杂，难以进行指定和管理。同时，依赖大规模语言模型（LLMs）将自然语言描述转换为运行代码的vibe编码方法越来越受欢迎，但这也带来了一些代码漏洞、扩展性问题和可维护性问题。因此，研究如何结合AI和MDE的优势以加速可靠复杂系统的开发变得尤为重要.", "innovation": "本文引入了vibe modeling的概念，作为一种新的方法，将AI和MDE的优点结合起来，以加速可靠复杂系统的开发。vibe modeling强调了其在模型领域的关键概念，以及其所带来的机遇和需要解决的挑战，为未来的模型发展指明了方向.", "conclusion": "本文概述了vibe modeling的关键概念，并强调了这一方法所呈现的机遇和未来模型发展中的开放挑战。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23168", "html_url": "https://arxiv.org/abs/2507.23168", "title": "开源软件生态系统中的扩展决策", "title_en": "Extension Decisions in Open Source Software Ecosystem", "authors": "Elmira Onagh,Maleknaz Nayebi", "background": "GitHub Marketplace 正以每年约41%的速度增长，加入了新的工具，但许多新工具重复了现有功能。该研究专注于平台最大的部分——持续集成（CI），通过连接6,983个CI操作与3,869个提供者，并挖掘其版本历史，研究这些现象。研究表明，大约65%的新CI操作在六个月内重复了现有功能，并且少数先行操作者的操作占了大多数后续分支和扩展。这些洞见有助于开发者选择最佳时机推出，聚焦未满足的功能，并帮助维护者去除重复工具。", "innovation": "利用图模型来记录每项功能的首次出现、跟踪其采用情况，并聚类冗余工具。发现大量新CI操作在六个月内重复现有功能。少数先行者操作者的操作占了大多数后续分支和扩展。该模型有助于开发者选择最佳时机推出，并帮助维护者去除冗余工具。首次发布完整图和数据集，鼓励长期研究软件生态系统中的创新和竞争，为实践者提供准确的路线图以识别新兴趋势并指导产品策略。", "conclusion": "研究发现，大约65%的新CI操作在六个月内重复了现有功能，并且少数先行操作者的操作占了大多数后续分支和扩展。这些见解使开发者能够选择最佳时机进行发布，瞄准未满足的功能，并帮助维护者消除冗余工具。我们发布了完整的图和数据集，鼓励对软件生态系统中的创新和竞争进行长期研究，并为从业者提供了一条数据驱动的路线图，帮助他们识别新兴趋势并指导产品策略。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23356", "html_url": "https://arxiv.org/abs/2507.23356", "title": "COBOL到Java代码转换的品质评估", "title_en": "Quality Evaluation of COBOL to Java Code Transformation", "authors": "Shmulik Froimovich,Raviv Gal,Wesam Ibraheem,Avi Ziv", "background": "评估LLM（大型语言模型）为基础的翻译器面临着关键挑战，包括模型的不透明性及翻译质量评估的复杂性。本文提出了一套自动化评估系统，用于评估IBM Watsonx Code Assistant for Z (WCA4Z)中的COBOL到Java代码转换，并结合分析检查器和‘LLM作为法官’（LaaJ）技术，提供了可扩展的、多维度的评估。", "innovation": "该系统采用了基于分析检查器与LLM-as-a-judge的技术策略，可以实现大规模基准测试，支持持续集成工作流程，并减少对人工审核的依赖，从而为开发人员和项目管理者提供了可操作的见解，推动高质量现代代码库的发展。", "conclusion": "该系统通过自动化评估COBOL到Java代码转换，提供了可扩展的多维评估方法，支持持续集成和大规模基准测试，减少了手工审核的依赖，并为开发人员和项目管理人员提供行动指南，促进了高质量现代代码库的发展。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23425", "html_url": "https://arxiv.org/abs/2507.23425", "title": "使用Kieker进行Python软件的动态和静态分析，包括重构架构", "title_en": "Dynamic and Static Analysis of Python Software with Kieker Including Reconstructed Architectures", "authors": "Daphné Larrivain,Shinhyung Yang,Wilhelm Hasselbring", "background": "Kieker可观察性框架是一种工具，允许用户为自己的应用设计定制的可观察性管道。其最初用于Java，而如今由于Python的广泛流行，对Python应用的结构洞察变得尤为重要。因此，开发了一个结合静态分析和动态分析的Python分析管道，以构建系统的全面视图。", "innovation": "该研究将Kieker框架扩展到支持Python，并结合静态和动态分析方法，实现了Python软件的全面分析，进而提供对系统结构的详细洞察，填补了Kieker应用于Python语言的空白。", "conclusion": "该Python分析管道成功地为用户提供了一种理解复杂Python应用结构的方法，动态和静态分析相结合使得能够准确地识别和修复潜在问题，在开发过程中提供了强大的支持工具。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23348", "html_url": "https://arxiv.org/abs/2507.23348", "title": "SWE-Debate: 竞争性的多智能体辩论用于软件问题解决", "title_en": "SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution", "authors": "Han Li,Yuling Shi,Shaoxin Lin,Xiaodong Gu,Heng Lian,Xin Wang,Yantao Jia,Tao Huang,Qianxiang Wang", "background": "随着大型语言模型（LLMs）的高级推理能力的发展，问题解决已经有了显著进步。基于代理的框架（如SWE-agent）进一步推进了这一发展，使自主的工具使用代理能够解决复杂的软件工程任务。然而，现有的基于代理的问题解决方法主要是基于代理的独立探索，这些方法往往局限于局部解决方案，未能识别跨越代码库不同部分的问题模式。", "innovation": "本文提出了一种名为SWE-Debate的多智能体辩论框架，它通过鼓励多样的推理路径并实现更稳固的问题定位来克服这一局限。SWE-Debate首先通过遍历代码依赖图创建多个故障传播轨迹作为定位提案。然后，它组织了三轮辩论，每轮辩论均由一个强调不同故障传播轨迹推理视角的专业代理参与，这种结构化的竞争促使代理合作并提出一个统一的修复方案。最终，此统一的修复方案被集成到基于MCTS的代码修改代理中，用于生成补丁。实验表明，SWE-Debate在开源代理框架的基准测试SWE-bench中达到了新的最佳性能，并明显优于基线方法。", "conclusion": "SWE-Debate通过多智能体辩论框架，提高了问题解决的效率与准确性，为软件工程提供了更有效的解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23370", "html_url": "https://arxiv.org/abs/2507.23370", "title": "Trae Agent: 基于LLM的测试时扩展软件工程代理", "title_en": "Trae Agent: An LLM-based Agent for Software Engineering with Test-time Scaling", "authors": "Trae Research Team:Pengfei Gao,Zhao Tian,Xiangxin Meng,Xinchen Wang,Ruida Hu,Yuanan Xiao,Yizhou Liu,Zhao Zhang,Junjie Chen,Cuiyun Gao,Yun Lin,Yingfei Xiong,Chao Peng,Xia Liu", "background": "软件问题解决是软件工程中的一个关键挑战，近年来引起了广泛关注。随着大型语言模型（LLMs）的快速发展，针对实际软件工程任务取得了显著进步。最近的研究引入了集成推理技术以增强基于LLM的问题解决性能。然而，现有的基于提示的方法在有效探索大规模集成空间和进行仓库级别理解方面仍然存在局限性，这些限制了它们的整体有效性。", "innovation": "本文提出Trae Agent，这是一种基于代理的集成推理方法，专门用于仓库级别的问题解决。Trae Agent将目标表述为最优解搜索问题，并通过模块化的生成、修剪和选择代理来应对大规模集成空间和仓库级别的理解两个关键挑战。", "conclusion": "我们在广泛采用的SWE-bench基准上使用三个领先的LLM进行了大量实验，将Trae Agent与四种最先进的集成推理技术进行了比较。实验结果表明，Trae Agent在所有基线中以10.22%的平均改进在Pass@1指标上表现优异，并在SWE-bench Verified排行榜上名列前茅，获得了75.20%的Pass@1分数。我们很高兴将Trae Agent作为开放源代码项目提供给研究社区，所有资源均可通过以下链接获取：this https URL"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23178", "html_url": "https://arxiv.org/abs/2507.23178", "title": "AutoBridge：使用中央平台自动化智能设备集成", "title_en": "AutoBridge: Automating Smart Device Integration with Centralized Platform", "authors": "Siyuan Liu,Zhice Yang,Huangxun Chen", "background": "物联网（IoT）设备的多样化促使系统需要更智能的方式将新设备整合到中央管理平台下，以便提供以用户为中心的服务。然而，这一过程需要高度的技术知识和大量的编程工作来实现平台对设备功能的理解和控制。这增加了实现的复杂性和高昂的成本。", "innovation": "论文提出了AutoBridge，一种自动化物联网设备整合代码生成的方法。通过前瞻性的检索设备特定的知识并使用平台特定的知识合成平台合规的整合代码，实现了设备控制逻辑的自动产生。为了保证代码的正确性，AutoBridge设计了多阶段的调试管道，包括自动调试器进行虚拟物联网设备测试，以及所需的仅为二进制用户反馈（是或否）的交互式在环调试器进行真实设备验证。", "conclusion": "通过在两个开源物联网平台中测试的34种IoT设备上评估AutoBridge，结果显示AutoBridge的平均成功率达到了93.87%，平均功能覆盖率达到了94.87%，且无需任何人为干预。即使仅使用少量的二进制yes和no反馈，也能使代码达到100%的功能覆盖率。用户研究进一步表明，即使允许专家使用商业代码AI，AutoBridge在代码准确性方面也优于专家程序员50%至80%。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23361", "html_url": "https://arxiv.org/abs/2507.23361", "title": "SWE-Exp：基于经验的软件问题解决", "title_en": "SWE-Exp: Experience-Driven Software Issue Resolution", "authors": "Silin Chen,Shaoxin Lin,Xiaodong Gu,Yuling Shi,Heng Lian,Longfei Yun,Dong Chen,Weiguo Sun,Lin Cao,Qianxiang Wang", "background": "近年来，大型语言模型代理在软件问题解决方面取得了显著进展，利用了多代理协作和蒙特卡洛树搜索等先进技术。然而，当前的代理作为无记忆探索者，在处理每个问题时并不保留或重复利用之前的修复经验。这导致了失败轨迹的冗余探索，并且错失了将成功的修复方法应用到相似问题的机会。", "innovation": "我们引入了SWE-Exp，一种经验增强的方法，从过去的代理轨迹中提炼出简洁实用的经验，实现问题间的持续学习。我们的方法引入了一个多维度的经验库，捕捉成功的和失败的修复尝试。具体来说，它从高层次的问题理解到具体的代码更改，提取可重用的修复知识。实验证明，SWE-Exp 在开源代理框架下的 SWE-bench-Verified 上取得了最先进的解决率（41.6% Pass@1）。这种方法建立了一种新的范式，即自动化软件工程代理系统地积累和利用修复经验，从根本上从尝试错误的探索转变为策略性强、经验驱动的问题解决。", "conclusion": "我们的方法实现了从尝试错误的探索到策略性强、经验驱动的修复问题的新范式转变，显著提升了软件问题解决的效率和质量。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/1908.01212", "html_url": "https://arxiv.org/abs/1908.01212", "title": "在2-范畴中类型化张量计算（I）", "title_en": "Typing Tensor Calculus in 2-Categories (I)", "authors": "Fatimah Rita Ahmadi", "background": "为开发高效算法和适用于函数式编程语言的框架，并实现更快的并行计算，本文旨在形式化线性代数中的计算。文章采用了将线性代数元素（如矩阵）视为矩阵范畴$\boldsymbol{\text{Mat}_{k}}$中的态射的方法，从而构建了一个线性代数框架。为了进一步扩展这一视角，该框架被推广到任意幺半加性范畴以容纳高阶矩阵（张量）。在这一框架下，通过定义幺半加性2-范畴，将矩阵$T_{ij}$视为1-态射，四种标度的张量$T_{ijkl}$视为2-态射，从而提供了一个无索引、类型化的线性代数框架，涵盖矩阵和四指数张量。此外，我们还将这一框架扩展到幺半加性2-范畴，并在Kapranov和Voevodsky引入的2Vec2-范畴中进行了详细的操作和矢量化演示。", "innovation": "本文提出了一种将线性代数元素作为矩阵范畴中的态射的方法，并将其推广到任意幺半加性范畴，从而构建了一个适用于函数式编程语言和实现高效并行计算的线性代数框架。进一步定义了幺半加性2-范畴，将矩阵和张量纳入该框架，从而提供了无索引、类型化的线性代数框架。此外，本文还展示了在2Vec2-范畴中的详细操作和矢量化。", "conclusion": "本文通过引入幺半加性2-范畴的概念和相关操作，实现了一个涵盖高阶矩阵和张量的无索引、类型化的线性代数框架。该框架不仅适用于理论研究，还能够有效应用于实际的算法设计和并行计算中。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23292", "html_url": "https://arxiv.org/abs/2507.23292", "title": "SequenceLayers: 序列处理和流式神经网络的便捷实现", "title_en": "SequenceLayers: Sequence Processing and Streaming Neural Networks Made Easy", "authors": "RJ Skerry-Ryan,Julian Salazar,Soroosh Mariooryad,David Kao,Daisy Stanton,Eric Battenberg,Matt Shannon,Ron J. Weiss,Robin Scheibler,Jonas Rothfuss,Tom Bagby", "background": "为了轻松创建能够分层执行（如教师强制训练）和逐步执行（如自回归采样）的序列模型，本文提出了一种神经网络层API和库。现有的序列模型库可能在处理流式传输和并行序列处理时遇到各种常见问题，如状态管理混乱或结果差异等。SequenceLayers通过显式定义层状态，使其能够在任意深度学习库中实现为可立即流式传输的复杂模型，从而解决了这些问题，同时保持严格的正确性保证。", "innovation": "SequenceLayers通过引入明确的时间状态表示和逐步方法，使得复杂的序列模型可以立即流式传输。这种方法不仅避免了许多常见的流式处理和并行序列处理中的问题，还使流式神经网络的实现更为简单。该库允许通过任意深度学习框架实现，并提供了可组合和声明式的API及广泛的层组合，简化了生产规模模型的构建过程，同时确保了强正确性保证。", "conclusion": "本文提出的SequenceLayers库利用了分层和逐步方法，通过明确的时间状态表示，使复杂模型能够立即流式传输。这种方法能够解决许多序列模型中的常见问题，并且可以在任何深度学习库中实现，简化了生产规模序列模型的构建过程，同时保持了强正确性保证。当前的SequenceLayers实现包括JAX和TensorFlow 2版本，可供参考。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23640", "html_url": "https://arxiv.org/abs/2507.23640", "title": "关于合并请求接受所需的修改量的实证研究", "title_en": "An Empirical Study on the Amount of Changes Required for Merge Request Acceptance", "authors": "Samah Kansab,Mohammed Sayagh,Francis Bordeleau,Ali Tizghadam", "background": "代码审查（CR）在软件开发过程中至关重要，它有助于确保新代码能够正确集成。然而，代码审查的过程通常需要大量的努力，包括代码调整、回应审阅者的意见以及持续的开发实现。尽管以往的研究对代码审查延迟和迭代次数进行了研究，但在基于代码变更量的审查努力方面关注较少，尤其是在GitLab合并请求（MRs）的背景下，这方面的研究较少。本文通过分析四个GitLab项目的超过23,600个合并请求的数据集，来定义和测量了代码修改后的审查努力量，并发现高达71%的合并请求需要提交后的调整，且其中28%涉及超过200行代码的修改。令人惊讶的是，这种努力与审查时间或参与人数并无关联。此前的研究主要集中在代码审查延迟和迭代次数上，而本文则侧重于基于代码变更量的审查努力，并通过多维度指标训练可解释的机器学习模型来预测审查努力，从而解释并预测集成代码变更期间所需的努力。", "innovation": "本文首次系统地测量了基于代码变更量的代码审查努力，并通过多维度指标训练了一个可解释的机器学习模型来预测代码审查中的努力。以往研究主要关注代码审查时间或参与人员数量，本文则通过具体数据和模型揭示了代码复杂性、开发者经验、文本特征等关键预测因素，以及历史项目特征对当前审查努力的影响，进一步解释了代码变更的审查过程。", "conclusion": "通过机器学习模型，本文成功地解释了和预测了集成代码变更期间所需的审查努力，这表明利用机器学习的方法在代码审查过程中是可行的。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23205", "html_url": "https://arxiv.org/abs/2507.23205", "title": "Kernel-FFI：交互式笔记本中的透明外部函数接口", "title_en": "Kernel-FFI: Transparent Foreign Function Interfaces for Interactive Notebooks", "authors": "Hebi Li,Forrest Sheng Bao,Qi Xiao,Jin Tian", "background": "现有外部函数接口（FFIs）解决方案不适合现代交互式工作流（如Jupyter笔记本）所需的动态和交互式环境。现有的方法需要大量的手动配置，引入了大量的样板代码，并且通常缺乏对递归调用和面向对象编程（OOP）构造的支持——这些都是多语言开发中至关重要的特征。", "innovation": "Kernel-FFI是一个透明且语言无关的框架，能够使交互式笔记本中的跨语言函数调用和对象操作变得无缝。它通过源码级转换自动重写跨语言调用，消除了手动绑定或样板代码的需要，并提供了一种新的侧通道通信机制，用于解决Jupyter内核阻塞的问题以及支持递归和异步调用。", "conclusion": "Kernel-FFI将开源，并提供跨语言调用和对象管理的全面支持，减轻手动配置的工作量，简化交互式笔记本中的多语言开发流程。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.23335", "html_url": "https://arxiv.org/abs/2507.23335", "title": "深学习模型Top-k预测中可扩展且精确的攻击预算防护方法", "title_en": "Scalable and Precise Patch Robustness Certification for Deep Learning Models with Top-k Predictions", "authors": "Qilin Zhou,Haipeng Wang,Zhengyuan Wei,W.K. Chan", "background": "目前针对对抗性斑块攻击的一种新兴验证方法是确保鲁棒性认证，其能够在深度学习系统中提供可证明的保证。现有的认证恢复技术能够保证经过认证样例的唯一真实标签预测，但当应用于Top-k预测时，通常需要进行成对比较，这种比较会导致随着攻击者控制的票数增加，难以精确确定唯一真实标签。此外，计算所有投票分配组合会带来组合爆炸问题。因此，有必要提出一种新的、可扩展且准确的认证恢复防御方案，以改善现有技术的局限性。", "innovation": "本文提出了一种创新的认证恢复防御方案——CostCert，这是一种基于投票的认证恢复方法。CostCert通过设计，能够不依赖于成对比较和组合爆炸，验证样本在Top-k预测中是否能排除真实标签，而不受攻击预算的影响。这种方法具体地检查攻击预算是否无法支撑样本额外的最小总投票量，以排除所有真实标签。实验结果表明，CostCert相比当前最先进的防御方案PatchGuard，在96大小的斑块下，能够保持高达57.3%的认证准确率。", "conclusion": "CostCert在不需要成对比较和避免组合爆炸问题的情况下，有效地验证了样本Top-k预测中的真实标签，显著提升了认证准确率。这项工作解决了现有技术中的关键问题，为深度学习模型对抗对抗性斑块攻击提供了新的解决方案。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2407.05028", "html_url": "https://arxiv.org/abs/2407.05028", "title": "测试组成性", "title_en": "Testing Compositionality", "authors": "Gijs van Cuyck,Lars van Arragon,Jan Tretmans", "background": "组件组成性支持大型系统的管理,特别是在基于模型的测试中。基于模型的测试中,大型系统可以通过建模和测试其组件来进行测试，所有组件通过测试则表明整个系统通过测试。此前的研究定义了规范模型之间的相互接纳，并证明它是组成性的一个充分条件。在此论文中，作者介绍了在实践中使用相互接纳的三种主要算法。这些算法允许验证规范的相互接纳性，证明对于所有有效实施是组成的；提供一种确保所有组件实现与规范一致性的完备测试过程；并进一步通过综合多个规范的约束来优化此过程。", "innovation": "提出了三种主要算法用于实践中的相互接纳性验证。第一，可以在规范上验证相互接纳性，证明所有有效实施的组成性；第二，提供了一个完备的基于模型的测试过程，用于检查特定黑盒实施的相互接纳性；最后，通过同时利用多个规范的约束来进一步优化此过程。这些算法一起允许根据具体情况选择最合适的测试方法，能够在一般化结果和测试运行时间之间进行权衡。", "conclusion": "本文的结论是，利用相互接纳性，可以将大型系统的正确性测试分解为对组件实现进行UIOCO一致性测试和环境一致性测试，通过这些算法可以在适当的情境下进行有效地组成性测试，既可以选择理论上的普适结果，也可以根据具体情况进行调整以实现更快的运行时间。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2405.08788", "html_url": "https://arxiv.org/abs/2405.08788", "title": "使用最弱应用条件对图变换进行图修复排序", "title_en": "Using weakest application conditions to rank graph transformations for graph repair", "authors": "Lars Fritsche,Alexander Lauer,Maximilian Kratz,Andy Schürr,Gabriele Taentzer", "background": "在使用图和图转换来建模系统时，一致性是一个重要的考虑因素。一致性的关注点通常是二元的，即一个图要么是相对于一组约束一致的，要么是一致性缺失的。然而，最近的研究引入了一种把一致性视为逐步性质的新方法。这种方法允许在一段时间内容忍不一致性，然后在必要时进行修复。为此，作者使用带有所谓的‘损害指示和修复指示应用条件’的图转换规则来理解某些规则应用所带来的修复收益。这两种条件可以从给定的图约束中导出。", "innovation": "作者提出了一种新的图修复理论，该理论基于带有‘损害指示和修复指示应用条件’的图转换规则。该理论的核心是图转换步长前后实际约束违反数差可以由损害指示和修复指示应用条件数的差来表征。这一理论为包含带有这些新应用条件的规则的算法奠定了基础，算法可以根据图修复潜力对图转换进行排序。", "conclusion": "评估表明，规则带有这些新型应用条件的图修复可以很好地支持效率和扩展性。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2406.10375", "html_url": "https://arxiv.org/abs/2406.10375", "title": "Mokav：利用LLMs进行执行驱动的功能差异测试", "title_en": "Mokav: Execution-driven Differential Testing with LLMs", "authors": "Khashayar Etemadi,Bardia Mohammadi,Zhendong Su,Martin Monperrus", "background": "在软件工程任务中，如自动修复、突变测试和代码重构等，检测程序间的功能差异至关重要。检测两个程序功能差异的问题可以归结为寻找一个差异揭示测试（DET），即能够导致两个程序输出不同的测试输入。", "innovation": "本文提出了一种名为Mokav的新颖执行驱动工具，该工具利用大型语言模型（LLMs）生成差异揭示测试（DET）。Mokav通过迭代提示LLMs生成新的测试输入，并通过执行反馈进一步优化，最终生成能够证明两个程序输出不同的DET。", "conclusion": "Mokav在对1535对来自Codeforces竞赛平台的Python程序和32对来自QuixBugs数据集的程序进行评估时，明显优于现有技术Pynguin和Differential Prompting。Mokav能够生成81.7%的测试程序对的DET，远超过Pynguin的4.9%和Differential Prompting的37.3%。研究表明，Mokav系统中的迭代和执行驱动反馈机制是其高效性的关键。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2410.12547", "html_url": "https://arxiv.org/abs/2410.12547", "title": "DevOps环境中的REST API测试：基于一个演进中的医疗物联网应用的研究", "title_en": "REST API Testing in DevOps: A Study on an Evolving Healthcare IoT Application", "authors": "Hassan Sartaj,Shaukat Ali,Julie Marie Gjøby", "background": "医疗物联网（IoT）应用通常通过REST API集成了多种第三方医疗应用程序和医疗设备，形成了复杂的REST API网络。奥斯陆市的医疗部门与多个行业合作伙伴一起开发了包含多种REST API的医疗物联网应用。遵循DevOps流程，这些REST API会不断进化以适应新的功能、服务和设备的需求。该市的主要目标是利用自动化解决方案对这些REST API在每个进化阶段进行持续测试，从而确保其可靠性。尽管已有多种自动化REST API测试工具，但它们对于医疗物联网应用程序中不断进化中的REST API回归测试的有效性在DevOps环境中尚未得到确定的研究。", "innovation": "本文评估了最新的REST API测试工具，包括RESTest、EvoMaster、Schemathesis、RESTler和RestTestGen，用于实际医疗物联网应用的回归测试，关注失败、故障、覆盖率和回归现象，并分析了测试结果的有效性和成本。实验涵盖了所有可访问的17个API及其120个端点，以及DevOps中14个版本的演变。", "conclusion": "所有工具生成的测试都导致了多次失败、18个潜在故障、高达84%的覆盖率和23次回退。超过70%的由所有工具生成的测试未能检测到失败，导致了显著的额外工作负担。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.19115", "html_url": "https://arxiv.org/abs/2507.19115", "title": "使用大型语言模型在爱立信进行自动代码审查的经验报告", "title_en": "Automated Code Review Using Large Language Models at Ericsson: An Experience Report", "authors": "Shweta Ramesh,Joy Bose,Hamender Singh,A K Raghavan,Sujoy Roychowdhury,Giriprasad Sridhara,Nishrith Saini,Ricardo Britto", "background": "代码审查是保证发布软件质量的主要手段之一，与测试和静态分析并重。然而，代码审查需要有经验的开发人员，他们可能没有时间进行深入的代码审查。因此，实现代码审查自动化可以减轻有经验的软件开发人员的认知负担，使他们能够专注于编写代码以添加新功能和修复错误。", "innovation": "本文描述了使用大型语言模型开发一个轻量级工具以实现代码审查过程自动化在爱立信的经验。文章还描述了与经验丰富的开发人员初步实验的评估结果以及令人鼓舞的反馈。", "conclusion": "通过将大型语言模型应用于代码审查工具，本文提出的方法能够帮助减轻有经验的软件开发人员的负担，提高代码审查的效率与质量。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.19060", "html_url": "https://arxiv.org/abs/2507.19060", "title": "PurpCode：更安全代码生成的推理", "title_en": "PurpCode: Reasoning for Safer Code Generation", "authors": "Jiawei Liu,Nirav Diwan,Zhe Wang,Haoyu Zhai,Xiaona Zhou,Kiet A. Nguyen,Tianjiao Yu,Muntasir Wahed,Yinlin Deng,Hadjer Benkraouda,Yuxiang Wei,Lingming Zhang,Ismini Lourentzou,Gang Wang", "background": "当前，代码推理模型在生成安全代码和防止恶意网络活动方面存在安全风险。为了改进这一点，PurpCode 提出了一种新的后训练方法，旨在训练可以生成安全代码并抵御恶意网络活动的代码推理模型。", "innovation": "PurpCode 采用两阶段训练方法：首先进行‘规则学习’，明确教会模型引用网络安全规则以生成无漏洞代码，避免促进恶意网络活动；其次进行‘强化学习’，通过多种目标的奖励机制优化模型的安全性和保留模型的实用性。PurpCode 通过内部红队测试合成全面且高覆盖率的提示，为模型诱导不安全的网络活动，从而增强模型的网络安全标准。基于PurpCode，研究人员开发了PurpCode-32B，展示了最先进的网络安全性能，优于多种前沿模型，并降低了模型在通用和网络安全特定场景中的过度拒绝率，同时保持了代码生成和普通安全知识的应用。”", "conclusion": "PurpCode-32B作为一种新颖的推理模型，展示了卓越的网络安全性，在代码生成和普通安全知识方面保持了模型的实用性，对于确保代码生成的安全性和防止恶意网络活动具有重要意义。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2412.15441", "html_url": "https://arxiv.org/abs/2412.15441", "title": "关于运行时引擎和服务提供商在代码小语言模型服务中资源利用的见解", "title_en": "Insights into resource utilization of code small language models serving with runtime engines and execution providers", "authors": "Francisco Durán,Matias Martinez,Patricia Lago,Silverio Martínez-Fernández", "background": "语言模型的快速发展，尤其是在代码生成方面，需要大量计算资源，这引发了对能源消耗和环境影响的担忧。优化语言模型推理资源利用至关重要，小型语言模型（SLMs）提供了减少资源需求的前景。研究者旨在从软件工程师在代码生成SLMs推理的视角，分析运行时引擎和执行提供商配置对能量消耗、执行时间和计算资源利用率的影响。实验涉及十二种代码生成SLMs，结果显示不同配置间存在显著差异。CUDA执行提供商在能量消耗和执行时间上表现出色。TORCH与CUDA搭配展现出最佳能效，节能从37.99%至89.16%。而用于CPU配置的最佳方案则是ONNX与CPU执行提供商，节能范围在8.98%至72.04%。", "innovation": "研究者设计了一种技术导向的多阶段实验管道，以探究运行时引擎和执行提供商配置对能量消耗、执行时间及计算资源利用率的影响。实验关注点在于代码生成的小语言模型，旨在优化服务器配置，提高资源使用效率。研究发现了不同配置下的显著差异，特别是CUDA配置在能源消耗和执行时间上的突出表现和TORCH+CUDA组合的能效。这些发现为软件工程师提供了优化资源使用的建议。", "conclusion": "不同运行时引擎和服务提供商的配置对资源利用有着显著影响。CUDA执行提供商在能量消耗和执行时间上表现优越，而TORCH与CUDA的组合在能效方面最优，最高可节能89.16%。此外，优化的运行时引擎如与CPU执行提供商的ONNX也能够显著节能。研究结果表明选择合适的配置能显著提高资源利用率效率。未来研究需进一步探索更优的配置方案。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.19105", "html_url": "https://arxiv.org/abs/2504.19105", "title": "混合评议委员会（Blended PC）评议模型：过程与反思", "title_en": "Blended PC Peer Review Model: Process and Reflection", "authors": "Chakkrit Tantithamthavorn,Nicole Novielli,Ayushi Rastogi,Olga Baysal,Bram Adams", "background": "由于提交的论文数量增加和可利用的审稿人资源有限，学术同行评审系统面临越来越大的压力，导致审稿决策延迟和审稿责任分配不均。在此背景下，国际软件仓库挖掘会议（MSR）社区借鉴了早些年设立的虚拟助手评审委员会（Shadow PC）和初级评审委员会（Junior PC）的经验，在2025年尝试了一个混合评议委员会（Blended PC）评议模式。", "innovation": "新模型将一名初级评审委员会成员与两名常规评审委员会成员配对，作为特定论文核心审查小组的一部分，而不是将其作为额外的审稿人。这项创新旨在通过结合不同层级的审稿人资源，来缓解审稿人力短缺、促进包容性并维持高质量同行评审过程。", "conclusion": "研究发现，混合评议委员会评议模式具有缓解审稿人员短缺、促进包容性和保障高质量评审过程的潜力。论文提出了实施过程中获得的经验和建议，以指导未来对该模式的采用和改进。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2505.04834", "html_url": "https://arxiv.org/abs/2505.04834", "title": "跨包管理器的锁定文件设计空间", "title_en": "The Design Space of Lockfiles Across Package Managers", "authors": "Yogya Gamage,Deepika Tiwari,Martin Monperrus,Benoit Baudry", "background": "软件开发人员会复用托管在包注册表中的第三方包。在构建过程中，包管理器解析并获取项目的直接和间接依赖项。大多数包管理器还会生成一个锁文件，记录已解析依赖项的确切版本集。锁文件有助于减少构建时间，验证已解析包的完整性，并支持不同环境和时间点的构建可重复性。尽管有这些有益的功能，开发人员往往在维护、使用和解释这些文件时遇到困难。", "innovation": "本文是对7个流行的包管理器（npm、pnpm、Cargo、Poetry、Pipenv、Gradle和Go）中的锁文件进行全面研究的第一个研究。研究强调了包管理器在锁文件生成过程及内容方面做出的广泛不同的设计决策。通过半结构化访谈15名开发者的质性分析，获得了开发人员对锁文件感知的益处以及管理这些文件所面临挑战的第一手见解。基于这些观察，提出了5项建议，以进一步改善锁文件，从而提升开发人员体验。", "conclusion": "总结了与锁文件相关的主要挑战，为进一步研究和工程师解决问题提供参考。提出了5项改进锁文件的建议，以期为开发人员提供更好的体验。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2405.13156", "html_url": "https://arxiv.org/abs/2405.13156", "title": "使用NFT身份验证进行隐私保护的PnR区块链架构的去中心化自治组织模型", "title_en": "A Privacy-Preserving DAO Model Using NFT Authentication for the Punishment not Reward Blockchain Architecture", "authors": "Talgar Bayan,Richard Banach", "background": "本文提出的去中心化自治组织（DAO）模型采用不可替代代币（NFT）进行身份管理和隐私保护的交互，在Punishment not Reward（PnR）区块链机制中。该模型在第二层网络上部署了双NFT架构：认证和访问控制的成员NFT (\\(NFT_{auth}\\)) 和私密交互的交互NFT (\\(NFT_{priv}\\))。该Layer 2实现将交易成本降低了97%，同时通过跨链机制保持安全。身份管理系统整合了去中心化的了解你的客户（KYC）流程和灵魂绑定代币特性以抵抗Sybil攻击。治理通过智能合约执行，包括管理和实施惩罚性措施，如在检测到不当行为时有条件地披露身份用于法证目的", "innovation": "该模型引入了在PnR区块链机制中使用双NFT架构的新颖方法，即认证和访问控制的成员NFT以及私密交互的交互NFT。通过跨链机制实现了97%的交易成本降低，同时保持了安全性，身份管理系统结合了去中心化的KYC流程和灵魂绑定代币的特性，以抵抗Sybil攻击。此外，治理机制通过智能合约管理声誉和实施惩罚措施，包括在检测到不当行为时有条件地披露身份用于法证目的", "conclusion": "本文提出了一种新颖的DAO模型，适用于PnR区块链机制，能够实现高效率的隐私保护和身份管理。通过双NFT架构、低成本交易实现和智能合约治理机制，该模型提供了有效的身份认证和访问控制，并增强了系统的安全性和透明度。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.22688", "html_url": "https://arxiv.org/abs/2503.22688", "title": "CodeIF-Bench：评估大型语言模型在互动代码生成中的指令遵循能力", "title_en": "CodeIF-Bench: Evaluating Instruction-Following Capabilities of Large Language Models in Interactive Code Generation", "authors": "Peiding Wang,Li Zhang,Fang Liu,Lin Shi,Minxiao Li,Bo Shen,An Fu", "background": "大型语言模型（LLMs）在代码生成任务中表现出色，成为不可或缺的开发人员编程助手。现有的代码生成基准主要评估LLMs在单轮交互中生成的代码的功能正确性，但对于LLMs在多轮交互场景中严格遵循用户指令生成代码的能力提供了有限的洞察。为此，本研究引入了CodeIF-Bench，一种用于评估LLMs在交互代码生成中的指令遵循能力的基准。", "innovation": "CodeIF-Bench 包含九种与实际软件开发需求对齐的可验证指令，并通过设定的测试案例独立且客观地进行验证，促进了多轮交互场景中的指令遵循能力评估。该研究在静态会话和动态会话设置中评估了7种最新LSTM模型的性能，并总结了影响LLMs在多轮交互中的指令遵循能力的重要因素以及改进方向。", "conclusion": "研究评估了7种最新LSTM模型在CodeIF-Bench上的表现，并总结了多轮交互场景中LLMs指令遵循能力的关键影响因素以及潜在改进方向。"}
{"llm_update_time": "20250801", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.22810", "html_url": "https://arxiv.org/abs/2507.22810", "title": "VRISE: 一种沉浸式和互动式测量教育的虚拟现实平台", "title_en": "VRISE: A Virtual Reality Platfrom for Immersive and Interactive Surveying Education", "authors": "Daniel Udekwe,Dimitrios Bolkas,Eren Erman Ozguven,Ren Moses,Qianwen Guo", "background": "测量是土木工程教育中的核心组成部分，要求学生进行实际的空间测量、仪器操作和现场决策。然而，传统的教学方式常常面临日程安排和认知上的挑战，这可能导致学习的无障碍性和学生参与度的下降。尽管虚拟实验室在工程教育中得到了广泛应用，但鲜有虚拟实验室旨在支持灵活和自适应的学习，特别是在测量教育中。", "innovation": "为了解决这一问题，我们开发了Virtual Reality for Immersive and Interactive Surveying Education (VRISE)，这是一种沉浸式虚拟现实实验室，通过可定制、可访问和用户友好的模块来复制地面和航空测量任务。VRISE 提供了如使用数字水平仪进行微分水准测量和基于航点的无人机导航等互动体验，这些体验由输入平滑、适应性界面和实时反馈增强，以适应不同的学习风格。", "conclusion": "评估表明，VRISE 在多次用户会话中在测量精度、任务效率和互动质量方面都表现出一致的提升，且在地面和空中测量模态中技能的发展呈现出明显进展。通过减少认知负荷和身体需求，即使在需要精细手眼协调和空间推理的任务中，VRISE 表明基于沉浸式、可重复的数字环境能够增强测量教育，扩大参与范围，并在安全和吸引人的环境中加强核心技能。"}
