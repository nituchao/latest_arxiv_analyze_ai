{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21449", "html_url": "https://arxiv.org/abs/2508.21449", "title": "从不完整动作和状态的轨迹中学习提升的动作模型", "title_en": "Learning Lifted Action Models From Traces of Incomplete Actions and States", "authors": "Niklas Jansen,Jonas Gösgens,Hector Geffner", "background": "该论文探讨了从随机状态-动作轨迹中学习滑动拼图的提升STRIPS模型的问题。这些轨迹仅描述了瓷砖的位置，动作仅标记为上下左右，没有参数。两个主要挑战是：首先，轨迹中的状态不包括完整的STRIPS状态，因为缺少一些原子命题，如表示空白位置的原子命题；其次，动作也不完全，因为它们没有揭示所有动作效果和先决条件涉及的对象。现有方法解决了这个问题的不同版本，但大多数假设轨迹中的动作是完整的STRIPS动作，或者假设领域原子都是可观测的。本研究考虑了一个更现实的设置，即观察到的原子提供世界的状态，但不提供完整的STRIPS状态，而动作揭示了选择动作所需的参数，但不揭示构建STRIPS所需的参数。", "innovation": "论文引入了STRIPS+变体，其中某些STRIPS动作参数可以在先决条件下显示为隐式或带有有限形式的存在量化的表达。学习问题变成了从STRIPS+状态-动作轨迹中学习STRIPS+模型的问题。为此，提出了一种名为SYNTH的学习算法，它为每个动作构建了一个分层（合取）序列的先决条件表达式或“查询”，这些表达式表示状态中的独特对象，并在STRIPS+中锁定隐式的动作参数。", "conclusion": "SYNTH算法的正确性和完整性得到了证明，并对其进行了可扩展性测试，测试结果基于从现有STRIPS领域派生的STRIPS+模型获得的状态-动作轨迹。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21307", "html_url": "https://arxiv.org/abs/2508.21307", "title": "MultiFluxAI 增强平台工程与先进的代理编排检索系统", "title_en": "MultiFluxAI Enhancing Platform Engineering with Advanced Agent-Orchestrated Retrieval Systems", "authors": "Sri Ram Macharla,Sridhar Murthy J,Anjaneyulu Pasala", "background": "当前产品工程领域存在大量异构数据源的管理与整合难题，同时随着数字生态系统的扩展，用户查询复杂度和需求不断提升，现有服务已难以满足用户的深层需求和增强式用户体验。因此，多渠道数据分析和智能响应成为了提高用户参与度的关键需求。", "innovation": "MultiFluxAI 平台创新性地采用了先进的 AI 技术，包括生成式 AI、向量化和代理编排，提供了动态且情境感知的服务。该平台专门设计用于管理及整合多样化数据来源，同时能够对复杂的用户查询提供即时反馈，提升了用户体验并增强了服务互动性。", "conclusion": "MultiFluxAI 平台通过其先进的服务检索系统，成功在产品工程中实现了数据整合与智能交互的优化，展示了平台在多应用领域中的广泛潜力，表明了其在提升用户参与度方面的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21411", "html_url": "https://arxiv.org/abs/2508.21411", "title": "CARJAN：基于AJAN的交通场景基于代理生成和模拟", "title_en": "CARJAN: Agent-Based Generation and Simulation of Traffic Scenarios with AJAN", "authors": "Leonard Frank Neis,Andre Antakli,Matthias Klusch", "background": "用户友好地建模和虚拟仿真实现各种交互式代理（如行人、骑车人、自动驾驶车辆）的城市交通场景仍是一个挑战。传统的工具不能很好地处理动态模拟和交互决策，因此需要一种新的方法来实现这一目标。CARJAN作为基于AJAN框架和CARLA驾驶模拟器的工具，提供了一种解决方案。", "innovation": "CARJAN采用了AJAN框架和CARLA驾驶模拟器，提供了基于可视化用户界面、存储和维护交通场景布局的方法，并利用SPARQL行为树进行决策和交互。这种方法提供了一种将交互式智能代理生成和在CARLA中动态仿真实践首次整合的方法，为城市交通场景的建模和仿真提供了一种新的方式。", "conclusion": "CARJAN提供了一个全新的工具，实现了交互式智能代理生成和在CARLA中的虚拟交通场景仿真，这对于交通工程和自动驾驶车辆的研究具有重要意义。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21320", "html_url": "https://arxiv.org/abs/2508.21320", "title": "使用双轴传播进行多领域知识集成以提升医学概念表示", "title_en": "Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation", "authors": "Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao", "background": "现有的文献主要集中在单一领域知识或多个领域知识（如疾病、药物和程序）的隔离使用上，而缺乏将这些知识整合到一个统一的学习结构中的方法。现有的学习结构通常仅限于领域内关系，而忽视了跨领域的联系。因此，医学概念表示学习往往局限于单个领域的内部关系，未能充分利用不同领域的联系信息。本文提出了一种名为LINKO的大型语言模型增强的综合本体学习框架，该框架利用多个本体图同时进行知识传递，以增强医学概念表示学习。", "innovation": "LINKO框架通过使用大型语言模型（LLM）来提供图检索增强的本体概念嵌入初始化，通过有鉴于此的概念描述和本体上下文。第二，该方法通过两个轴进行医学概念的学习：(1)在同一领域内垂直传播跨越层次本体级别，并(2)在同一等级内横向传播。这种多领域的知识传播方式可以提升医学概念的表示。通过广泛实验展示了LINKO框架优于现有最先进的基线方法，并且该框架作为可插入编码器与现有电子健康记录（EHR）预测模型兼容，在数据有限和罕见疾病预测场景中表现出增强的鲁棒性。", "conclusion": "通过广泛的实验，验证了LINKO在医学概念表示学习方面的优越性能，并在数据有限和罕见疾病预测场景中展示了进一步增强的鲁棒性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21238", "html_url": "https://arxiv.org/abs/2508.21238", "title": "通过知识图谱提高阿尔茨海默病研究中LLM的准确性和减少幻觉", "title_en": "Addressing accuracy and hallucination of LLMs in Alzheimer's disease research through knowledge graphs", "authors": "Tingxuan Xu,Jiarui Feng,Justin Melendez,Kaleigh Roberts,Donghong Cai,Mingfang Zhu,Donald Elbert,Yixin Chen,Randall J. Bateman", "background": "在过去两年中，基于大型语言模型（LLM）的聊天机器人，如ChatGPT，已经在各个领域革新了多种任务完成和问答能力。然而，它们在科学研究中的应用仍然受到幻觉、有限的领域特定知识以及缺乏响应的解释性和可追溯性等问题的限制。GraphRAG作为一种通过在响应生成前整合领域特定上下文信息来提高聊天机器人可靠性的新兴方法，已经在一定程度上解决了标准LLM的一些局限性。然而，很少有研究专门评估GraphRAG在要求深厚知识的领域，如阿尔茨海默病或其他生物医学领域的表现。", "innovation": "本文评估了两种流行的GraphRAG系统的质量和可追溯性。编译了50篇与阿尔茨海默病相关的论文和70个专家问题的数据集，构建了一个GraphRAG知识库，并使用GPT-4o作为LLM来回答查询。然后比较了GraphRAG生成的响应质量与标准GPT-4o模型生成的响应质量。此外，还讨论并评估了几种检索增强生成（RAG）和GraphRAG系统。", "conclusion": "最后，我们提供了一个易于使用的界面，预构建的阿尔茨海默病数据库，以供研究人员测试标准RAG和GraphRAG的性能。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21394", "html_url": "https://arxiv.org/abs/2508.21394", "title": "AI计算架构与演变趋势", "title_en": "AI Compute Architecture and Evolution Trends", "authors": "Bor-Sung Liang", "background": "当前AI的发展重心已从学术研究转向实际应用。然而，AI开发仍然面临着诸多挑战。本文拟从多个角度分析AI的机会与挑战，并提出了一个由物理层、链路层、神经网络层、语境层、代理层、协调层和应用层组成的七层架构模型。该模型展示了AI计算是如何通过大型语言模型的三层进化而演变出这一七层架构的。", "innovation": "本文提出了一个七层模型来阐述AI计算架构，涵盖了物理层、链路层、神经网络层、语境层、代理层、协调层和应用层。并且详细论述了通过大型语言模型的三层进化如何促使AI计算架构演变。此外，还探讨了从单一AI代理到AI生态系统的发展趋势及其对AI产业的影响，以及在这一过程中，技术和经济问题对构建可持续生态系统的挑战。", "conclusion": "AI的发展不仅仅是技术挑战，还涉及如何构建自可持续生态系统的问题。通过对互联网行业的分析，本文提供了AI未来发展趋势的预测。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21204", "html_url": "https://arxiv.org/abs/2508.21204", "title": "模糊的、符号化的和情境性的：通过认知支撑结构增强大型语言模型指令", "title_en": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "authors": "Vanessa Figueiredo", "background": "研究分析了建筑学诱导偏见如何影响大型语言模型（LLMs）在指导性对话中的认知行为。通过使用控制性消除五个系统变体的方法，依据专家设计的评分标准评估模型输出，涵盖支撑、响应、符号推理和对话记忆，以实现早期实验阶段的可扩展和系统性比较。初步结果显示，完整系统在多方面超过基线变体。分析发现，移除记忆或符号结构会削弱关键认知行为，包括抽象、适应性探查和概念连续性。研究支持一种处理层级账户，即架构支撑可以可靠地塑造LLMs中出现的教学策略。", "innovation": "提出了一个符号支撑机制与短期记忆模式相结合的方法，旨在促进索福克勒斯辅导中的适应性、结构化推理。通过控制性消除五个系统变体，评估模型输出，使用与认知基础评分标准对齐的LLM评估框架，实现了早期实验阶段的可扩展和系统性比较。这种新的方法和机制支持了一种处理层级账户，说明架构支撑能够可靠地塑造LLMs中的教学策略。", "conclusion": "研究表明，完整系统在多个方面优于基线变体。分析表明，移除模型记忆或符号结构会导致关键认知行为的下降，包括抽象、适应性探查和概念连续性。整体上支持了处理层次假设，即架构支撑可以可靠地塑造大型语言模型中的教学策略。这种方法提供了在早期实验阶段进行大规模、系统性比较的范式。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21365", "html_url": "https://arxiv.org/abs/2508.21365", "title": "通过大型语言模型基于强化学习在游戏中的推理思考：一种新的方法", "title_en": "Think in Games: Learning to Reason in Games via Reinforcement Learning with Large Language Models", "authors": "Yi Liao,Yu Gu,Yuan Sui,Zining Zhu,Yifan Lu,Guohua Tang,Zhongqian Sun,Wei Yang", "background": "大型语言模型（LLMs）在复杂推理任务如数学和编程方面表现出色，但在处理孩子容易完成的简单互动任务方面常常遇到困难。这种差异突显了声明性知识（知道某个事物）和程序性知识（知道如何做某事）之间的关键差距。传统强化学习（RL）代理可以通过环境交互获得程序性知识，但通常作为黑盒操作，并需要大量的训练数据。相比之下，LLMs拥有广泛的世界知识和推理能力，但在将静态知识转换为互动设置中的动态决策方面表现出色。", "innovation": "提出了一种新的框架Think in Games (TiG)，使得LLMs能够通过直接与游戏环境交互来发展程序性理解，同时保留它们固有的推理和解释能力。TiG将基于强化学习的决策过程重新定义为语言建模任务：LLMs生成语言指导的策略，并通过在线强化学习不断优化，基于环境反馈。实验结果表明，TiG成功地缩小了声明性知识和程序性知识之间的差距，相比传统的RL方法，实现了具有更高透明性和可解释性的更具竞争力的表现，并且需要的数据和计算成本大幅降低。", "conclusion": "TiG成功地弥合了声明性知识和程序性知识之间的差距，通过语言模型生成的策略与环境反馈的迭代强化学习实现了高度透明和提高解释性。这为复杂交互任务提供了具有竞争力的表现，并降低了计算需求和数据需求。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21376", "html_url": "https://arxiv.org/abs/2508.21376", "title": "AHELM: 音频语言模型的综合评估", "title_en": "AHELM: A Holistic Evaluation of Audio-Language Models", "authors": "Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang", "background": "当前，音频语言模型（ALMs）缺乏标准化基准的评估阻碍了它们的发展。现有的大多数基准仅能测试ALMs的一项或两项能力，并且忽略了公平性、安全性等评价维度。不同模型之间也难以进行比较，因为对不同模型的评估使用了不同的提示方法和推理参数。", "innovation": "本研究引入了AHELM基准，将各种数据集（包括两个新的合成音频-文本数据集PARADE和CoRe-Bench）汇集在一起，评估ALMs在感知、知识、推理、情感检测、偏见、公平性、多语言性、鲁棒性、毒性、安全性等方面的性能。此外，AHELM还统一了提示、推理参数和评估指标，确保模型之间的比较公平。本研究测试了来自3个开发商的14种开源和封闭API的ALMs，并验证了3个简单的基线系统。结果显示，Gemini 2.5 Pro在5个方面表现出色，但在ASR任务中展示了组别不公平性；基线系统在AHELM上的表现也相对良好，其中一个基线系统甚至排在第五位，尽管其仅具备语音转文字的能力。所有测试数据及结果均可在官方网站查看。AHELM旨在成为一个活的基准，未来将不断增加新的数据集和模型。", "conclusion": "本研究通过引入AHELM基准，针对ALMs综合衡量了多个方面关键指标，提供了一个更公平、全面的模型对比平台，为ALMs的公平性、安全性等重要方面提供了参考。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21521", "html_url": "https://arxiv.org/abs/2508.21521", "title": "自动规划中的反事实情景", "title_en": "Counterfactual Scenarios for Automated Planning", "authors": "Nicola Gigante,Francesco Leofante,Andrea Micheli", "background": "反事实解释（CEs）是一个强大的技术，通过演示输入如何轻微改变来解释机器学习模型，从而使其产生不同的输出。这些解释在自动规划领域也有类似的概念，但它们未能捕捉到问题的高级属性。因此，研究者提出了基于反事实情景的新解释范式。该范式在给定规划问题以及定义计划所需属性的LTLS公式时，能够识别使问题适应这些规定属性的最小修改。", "innovation": "论文提出了针对自动规划的反事实情景的两种定性实现，这些实现基于对必须满足特定属性的计划的显式量化。同时，论文还分析了在规划问题中允许不同类型的更改以生成反事实情景的计算复杂度。结果显示，生成反事实情景的成本通常仅与计算规划问题所需的计划成本相当，这证明了该提议的实用可行性，并为该领域的算法提供了一个框架。", "conclusion": "论文展示了一种基于反事实情景的框架，可用于自动规划中的问题分析。该框架能够识别必要的最小修改，以便使问题满足特定属性的计划，同时其计算复杂度使得该方法在实践中具有现实性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21595", "html_url": "https://arxiv.org/abs/2508.21595", "title": "具有确定性动力学的Dec-POMDPs的高效求解方法", "title_en": "Scalable Solution Methods for Dec-POMDPs with Deterministic Dynamics", "authors": "Yang You,Alex Schutz,Zhikun Li,Bruno Lacerda,Robert Skilton,Nick Hawes", "background": "研究中涉及的许多高级多智能体规划问题，如多机器人导航和路径规划，可以使用确定性的行为和观察进行有效建模。现有的DEC-POMDP求解器在处理大规模Det-Dec-POMDP问题时效率低下，因此需要开发效率更高的方法来解决这些问题。", "innovation": "提出了Iterative Deterministic POMDP Planning（IDPP）方法，该方法基于经典联合均衡搜索策略框架，并进行了优化以处理当前DEC-POMDP求解器无法高效处理的大规模Det-Dec-POMDP问题，从而提供了一种新的求解大规模确定性动力学Dec-POMDP问题的方法。", "conclusion": "通过提出IDPP方法，能够高效解决大规模Det-Dec-POMDP问题，为多智能体系统的规划提供了新的解决方案。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21540", "html_url": "https://arxiv.org/abs/2508.21540", "title": "HealthProcessAI: 一种Large语言模型增强的医疗流程挖掘技术框架及概念证明", "title_en": "HealthProcessAI: A Technical Framework and Proof-of-Concept for LLM-Enhanced Healthcare Process Mining", "authors": "Eduardo Illueca-Fernandez,Kaile Chen,Fernando Seoane,Farhad Abtahi", "background": "过程挖掘作为一种强大的分析技术，正被用于理解复杂的医疗服务流程。然而，其应用受到了技术复杂性、缺乏标准化方法和实用培训资源有限等显著障碍的限制。", "innovation": "HealthProcessAI 是一个基于GenAI框架，旨在简化医疗和流行病学领域的过程挖掘应用。该框架通过集成多个大型语言模型（LLMs）来自动化过程图解释和报告生成，帮助将技术分析结果翻译成易于不同用户理解的输出。此外，该框架使用PM4PY和bupaR库进行数据处理与分析，并通过OpenRouter平台比较了五个最先进的LLM模型的表现。", "conclusion": "HealthProcessAI框架成功处理了四个概念证明情景中的败血症数据，展示了其强大的技术性能和通过自动化LLM分析生成报告的能力。通过评价五个独立的LLM模型，研究发现Claude Sonnet-4和Gemini 2.5-Pro在自动化LLM评估者评估中表现出最高的一致性分数。这种结构化的分析和AI驱动的解释组合代表了将复杂的过程挖掘结果转化为潜在可操作见解的创新方法。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21475", "html_url": "https://arxiv.org/abs/2508.21475", "title": "MMSearch-Plus: 一种简单而具有挑战性的多模态浏览代理基准", "title_en": "MMSearch-Plus: A Simple Yet Challenging Benchmark for Multimodal Browsing Agents", "authors": "Xijia Tao,Yihua Teng,Xinxing Su,Xinyu Fu,Jihao Wu,Chaofan Tao,Ziru Liu,Haoli Bai,Rui Liu,Lingpeng Kong", "background": "大型多模态语言模型（MLLMs）越来越多地被部署为网络代理，但许多多模态浏览基准可以通过依赖高召回率图像搜索和局部文本掩蔽的方式解决，而不是真正地应对复杂的细粒度视觉推理、来源验证和长期工具使用等多模态挑战。目前的基准难以全面评估多模态理解的需求。", "innovation": "作者引入了MMSearch-Plus，一个包含311个任务的基准，这些任务高度要求多模态理解，同时保留了强大的纯文本浏览套件的难度特性。每个任务都设计用于包含多个弱、局部的视觉信号，需要通过迭代的图文搜索和在检索噪声下的交叉验证来提取和传播这些信号才能回答问题。研究重心在于从空间线索和时间痕迹推断出图像之外的事实，如事件、日期和场地等。此外，还提供了一个模型通用的代理框架，并评估了多种封闭和开放的多模态语言模型。", "conclusion": "在MMSearch-Plus框架下，最强的代理达到15.1%的准确率（不使用搜索）和36.0%的准确率（使用展开序列）；开源模型Qwen-2.5-VL-72B-Instruct在不使用搜索的情况下达到0.0%的准确率，在20轮搜索后达到6.9%的准确率。除了评估答案的准确性，作者还评估了边界框生成和裁剪图像搜索，并进行了错误分析，揭示了来源验证、部分级推理和长期规划方面的失败。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21517", "html_url": "https://arxiv.org/abs/2508.21517", "title": "基于德性灵感的Z-数模糊框架建模明智决策", "title_en": "Modeling Wise Decision Making: A Z-Number Fuzzy Framework Inspired by Phronesis", "authors": "Sweta Kaman,Ankita Sharma,Romi Banerjee", "background": "智慧是一个上位概念，包括换位思考、反思性、利他主义取向、反思性同理行动和智力谦逊。与受限于二元思维的常规推理模型不同，智慧在模糊性的程度上展开，需要有递阶评价和自我反思的谦逊。目前的测量主要依赖自我报告，很少反映智慧推理中固有的谦逊和不确定性。一个同时考虑多维度性和信心的计算框架有可能提升心理学研究，并使人性化的AI成为可能。", "innovation": "本文提出了一种基于Z数的模糊推理系统，每个决策都表达为智慧评分（限制）和信心评分（确定性）。通过让参与者（n = 100）完成无文化偏见的道德困境任务并生成思考 aloud 的语言反应，这些反应被映射到五个基于理论的智慧组件中，并使用21条规则和通过高斯核密度估计调优的隶属函数进行组合。结果显示，该系统产生的双重属性智慧表示与现有量表中度相关，且与无关特质表现出极微的关系，支持其同时导向的效度。", "conclusion": "本研究的贡献在于将智慧正式化为一个多维的、充满不确定性的构建，以Z-数的形式进行操作化。除了推进心理学的测量之外，此研究还展示了模糊Z-数如何为AI系统提供可解释、带有信心敏感性的推理，为严谨计算和近乎人类判断之间的安全地带提供可能。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21564", "html_url": "https://arxiv.org/abs/2508.21564", "title": "重新审视地标：从先前的计划中学习以跨越问题实例进行泛化", "title_en": "Revisiting Landmarks: Learning from Previous Plans to Generalize over Problem Instances", "authors": "Issa Hanou,Sebastijan Dumančić,Mathijs de Weerdt", "background": "传统地标抽取算法在解决规划问题时存在局限性，特别是在处理复杂的重复子计划时表现不佳。该论文旨在提出一种新的框架，用于自动发现能够在不同实例间泛化的地标，这些地标用于定义更高级别的中间目标，帮助解决规划问题。", "innovation": "该框架通过使用与具体问题对象无关的状态函数来学习泛化地标，这些状态函数能够描述所有相似对象的中间目标，从而捕捉重复现象。基于这些函数，构建了一个有向泛化地标图，定义了地标的发展进程，包括重复子计划的循环可能性。这种方法能够显著提高新实例的求解性能，尤其是在能够识别重复循环时。", "conclusion": "泛化地标可以从少量实例中学到，并且对于相同领域的大型实例也有效。所学习到的泛化地标信息对于自动化规划器来说是可解释且有用的，仅需要较少的相同领域计划实例即可发现这些信息。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21648", "html_url": "https://arxiv.org/abs/2508.21648", "title": "利用MEDLEY放大医疗AI中的缺陷：一种多模型方法利用偏差", "title_en": "Leveraging Imperfection with MEDLEY A Multi-Model Approach Harnessing Bias in Medical AI", "authors": "Farhad Abtahi,Mehdi Astaraki,Fernando Seoane", "background": "传统的观点认为医疗人工智能中的偏差是一种需要消除的缺陷。然而，人类的推理包含由教育、文化及经验塑造的偏差，表明这些偏差可能是不可避免且有价值的。现有的做法倾向于抑制不同模型间的分歧。", "innovation": "提出了一种名为MEDLEY（具有利用多样性的医疗组合诊断系统）的概念框架，它协调多个AI模型并保留其多样化的输出而非将其汇总为一致意见。MEDLEY记录了模型特有的偏差作为潜在的长处，将幻觉视作临床验证的暂时假设。", "conclusion": " MEDLEY通过重新定义AI不完美性作为一种资源，为开发可信的医疗AI系统提供了一个范式转变，它为医疗AI系统的开发开辟了新的监管、伦理和创新途径。尽管MEDLEY尚未成为临床验证工具，但其演示证明了在临床监督下结构化多样的重要性，可以提升医疗推理能力。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21637", "html_url": "https://arxiv.org/abs/2508.21637", "title": "A-MHA*: 实时多启发式A*", "title_en": "A-MHA*: Anytime Multi-Heuristic A*", "authors": "Ramkumar Natarajan,Muhammad Suhail Saleem,William Xiao,Sandip Aine,Howie Choset,Maxim Likhachev", "background": "设计良好的图搜索启发式函数需要充分的知识领域。通常，容易设计出在某些搜索空间部分表现良好的启发式函数，但这些启发式函数可能不都是可接纳的，从而影响搜索的最优性保证。尽管多启发式A* (MHA*)可以在多个部分不完全良好但不可接纳的启发式函数中生成更快的次优解，但最初的版本不会随着时间改善解的质量。MHA*是一种一次性算法，需要仔细设置膨胀因子以获得一次性的理想解，", "innovation": "本文解决了这个问题，通过在MHA*框架中扩展A*区域修复算法的概念来构建实时版本的A*多启发式算法 (A-MHA*)。我们证明了A-MHA*的精确适配保留了原始的次优性和完备性保证，使其能够以实时方式运行。此外，我们在3-D路径规划领域和滑动拼图领域报告了A-MHA*的性能，并将其与MHA*和其他实时算法进行了比较。", "conclusion": "A-MHA*通过实时改进和保持原多启发式A*的性能保证，有效地解决了MHA*的次优解问题，特别适用于复杂搜索空间的应用。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21720", "html_url": "https://arxiv.org/abs/2508.21720", "title": "PosterForest: 层次多智能体协作的科学海报生成", "title_en": "PosterForest: Hierarchical Multi-Agent Collaboration for Scientific Poster Generation", "authors": "Jiho Choi,Seojeong Park,Seongjong Song,Hyunjung Shim", "background": "现有的科学海报生成方法大多忽略了科学文档的层级结构和文本与视觉元素的语义整合，导致生成的海报在逻辑一致性、内容准确性和视觉连贯性方面表现不佳。", "innovation": "提出了一种无监督训练的新型框架PosterForest，用于自动化科学海报生成。该方法引入了Poster Tree，一种层级中间表示，能够同时编码文档结构和多层级的视觉-文本关系。此外，采用了多智能体协作策略，各智能体负责内容总结和布局规划，通过迭代协调和互反馈实现优化。", "conclusion": "多项实验表明，PosterForest在定性和定量评估中都优于现有基线方法。生成的海报质量接近专家设计的标准，并且在信息保真度、结构清晰度和用户偏好方面表现更优。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21441", "html_url": "https://arxiv.org/abs/2508.21441", "title": "基于排序函数的广义知识遗忘框架及其实例化", "title_en": "A General Framework of Epistemic Forgetting and its Instantiation by Ranking Functions", "authors": "Christoph Beierle,Alexander Hahn,Diana Howey,Gabriele Kern-Isberner,Kai Sauerwald", "background": "遗忘作为一种知识管理的操作，故意忽略了代理的部分知识和信念，出于多种原因。在文献中，提出了两种主要的操作来执行遗忘：一是变量消除，这是一种语义方法，通过融合掉特定的原子变量来关注语言的其余部分，主要应用于逻辑编程和回答集编程；二是AGM信念修正理论中的收缩，有效地从信念集中通过逻辑推导移除命题。两者主要依赖于经典逻辑。文章提出一个认识论视角来研究具有更丰富语义结构的知识状态中的遗忘操作，从而探讨在认识背景下的遗忘意义，并提升其到认识层面。", "innovation": "文章提出了一种广义的知识遗忘框架，通过基于认识论角度来看待遗忘操作，特别是将其应用到了具有更丰富语义结构的知识状态中，与命题逻辑有着清晰的联系。该框架提出了五种广义的认识论遗忘类型，并利用Spohn的排序函数实例化了七种具体的遗忘操作。文章还借鉴了从逻辑编程和AGM理论中的遗忘公理，提出了一个丰富性的公理体系来评估遗忘操作，最终全面评估了所有具体的遗忘操作，展示了它们之间的差异和共性。", "conclusion": "文章提供了一种全面的框架，通过对五类广义的知识遗忘类型和七种具体遗忘操作的实例化评估，揭示了遗忘操作之间的差异和共性，为未来研究提供了新的视角和方法。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21742", "html_url": "https://arxiv.org/abs/2508.21742", "title": "使用摘要因果图和忠实分布的时间序列中的因果关系可定向性", "title_en": "Orientability of Causal Relations in Time Series using Summary Causal Graphs and Faithful Distributions", "authors": "Timothée Loranchet,Charles K. Assaad", "background": "时间序列分析的核心挑战之一是理解时间变量之间的因果关系，尤其是在完整的因果结构未知的情况下。即使在完整的因果结构无法完全明确的情况下，专家通常也能提供一种高层次的因果图抽象，称为摘要因果图（SCG），它捕捉了不同时间序列间的主因果关系，同时抽象了微观细节。", "innovation": "本研究提出了条件，确保在汇总因果图提供的背景知识下，即使存在宏观层面的循环或双箭头边，也能保证时间变量微观层面边缘的定向性。研究结果提供了在观察到的时间序列数据中利用SCGs进行因果发现的理论保障，并强调了专家知识融入对因果推理的重要性。", "conclusion": "研究表明，在利用忠实分布的情况下，可以利用SCGs在微观层面对因果关系进行定向，即使宏观层面上存在循环或双箭头边。研究为利用SCGs改进复杂时间系统的因果推理提供了实用指导。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21800", "html_url": "https://arxiv.org/abs/2508.21800", "title": "Tree-Guided Diffusion Planner", "title_en": "Tree-Guided Diffusion Planner", "authors": "Hyeonseong Jeon,Cheolhong Min,Jaesik Park", "background": "规划中使用预训练扩散模型已经成为解决测试时间引导控制问题的一个有前景的方法。然而，标准的梯度引导在凸且可微的奖励景观中表现最佳，但在涉及非凸目标、非可微约束和多奖励结构的现实场景中效果显著降低。而且，最近的监督规划方法需要特定于任务的训练或价值估计器，这限制了测试时间的灵活性和零-shot泛化能力。", "innovation": "本文提出的Tree-guided Diffusion Planner (TDP) 是一种零-shot测试时规划框架，通过结构化轨迹生成来平衡探索和利用。TDP将测试时规划问题重新表述为树搜索问题，通过两阶段采样过程：(1) 利用无训练粒子引导产生多样化的亲本轨迹，以促进广泛的探索；(2) 通过快速条件去噪并结合任务目标来细化子轨迹。TDP通过探索多样化的轨迹区域，并利用预训练模型和测试时奖励信号在整个扩展的解决方案空间中利用梯度信息，来解决梯度引导的局限性。", "conclusion": "TDP在三个不同的任务（迷宫黄金拾取、机器人手臂块操纵和AntMaze多目标探索）上都比最先进的方法表现出色。相关信息可以在该项目页面找到：this http URL."}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21083", "html_url": "https://arxiv.org/abs/2508.21083", "title": "CoBA: 通过语义三元组减轻各种虚假相关性的反偏数据增强", "title_en": "CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples", "authors": "Kyohoon Jin,Juhwan Choi,Jungmin Yun,Junho Lee,Soojin Jang,Youngbin Kim", "background": "深度学习模型往往会在训练数据中学习和利用虚假相关性，使用这些非目标特征来指导其预测。这种依赖性会导致在未见过的数据上的性能下降和泛化能力差。为了解决这些局限性，人们提出了更加通用的形式的反事实数据增强方法，称为反偏数据增强（Counterbias Data Augmentation，CoBA），它可以同时解决多种偏见（如性别偏见、简易偏见）并增强对分布外数据的鲁棒性。", "innovation": "CoBA 提供了一种统一的框架，在语义三元组级别操作：首先将文本分解为主体-谓语-客体三元组，然后选择性地修改这些三元组以破坏虚假相关性。通过从这些调整后的三元组重构文本，CoBA 生成了反偏数据，以减轻虚假模式。实验表明，CoBA 不仅能改进下游任务表现，还能有效减少偏见并增强泛化能力和鲁棒性。这是一种多功能且稳健的解决方案，可应对虚假相关性带来的挑战。", "conclusion": "通过广泛的实验，我们证明 CoBA 不仅提高了下游任务性能，还有效减少了偏见，并增强了分布式外的鲁棒性，提供了应对虚假相关性挑战的一种通用且稳健的解决方案。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19153", "html_url": "https://arxiv.org/abs/2508.19153", "title": "QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning", "title_en": "QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning", "authors": "Allen Wang,Gavin Tao", "background": "本文解决的是通过视觉引导的四足动物运动控制问题，并强调了结合知觉和视觉传感器对于实现稳健控制的重要性。传统的四足动物运动控制通常依赖于知觉数据，本研究尝试将视觉数据与知觉数据结合，以提高控制性能。研究者认为，现有的四足动物运动控制方法可能无法达到最优的性能，因此需要新的方法和技术来改进。最终的研究结果表明，通过结合视觉数据和知觉数据，可以实现更高效的样本利用，减少动作抖动和能量消耗，提供动作和姿态的可解释性。", "innovation": "本文提出了QuadKAN，这是一种基于Kolmogorov-Arnold网络（KANs）的跨模态策略，采用样条参数化模型定义函数类别。这种框架包含一个样条编码器来处理知觉数据，一个样条融合头来处理知觉-视觉输入。QuadKAN适用于端到端的强化学习训练，并采用了多模态延迟随机化（MMDR）以及Proximal Policy Optimization (PPO)进行训练。研究者设计了Multi-Modal Delay Randomization（MMDR）方法，并在一系列复杂的地形场景中验证了其有效性，包括平坦和不平坦的表面以及静态或动态障碍物的存在，结果表明QuadKAN在多个基准模型中表现出更优的表现。", "conclusion": "研究结果表明，基于样条参数化的策略对于实现稳健的视觉引导四足动物行走提供了简单、有效的替代方案。文章中提到，通过使用QuadKAN，可以在不同的地形中实现更高的性能回报、更远的距离和更少的碰撞。研究人员认为，这些结果展示了QuadKAN在提升视觉引导四足动物运动控制方面的能力。项目代码将在被接受后开源。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21730", "html_url": "https://arxiv.org/abs/2508.21730", "title": "重用模型破解旅行商问题：冻结策略", "title_en": "Freeze and Conquer: Reusable Ansatz for Solving the Traveling Salesman Problem", "authors": "Fabrizio Fagiolo,Nicolo' Vescera", "background": "本文介绍了针对旅行商问题（TSP）的一种变分算法，该算法结合了紧凑的排列编码方案以及优化-冻结-重用策略。传统的研究往往需要不断调整电路结构，测试复杂且耗时，该计划通过预先优化电路基态（Ansatz）并对其进行冻结重用，减少了这种结构研究的需要，使得算法可以更快速地实施于NISQ硬件上。文中在4到7个城市规模的40个随机对称实例上测试了该算法的效果，以评估其在不同规模问题上的性能和一般性。", "innovation": "本文的创新之处在于提出了一种优化-冻结-重用策略。首先利用Simulated Annealing优化电路基态，然后将其冻结并应用于新的实例，只需快速重新优化电路参数。通过这种方法，可以大大减少时间消耗，同时不会降低解的质量。", "conclusion": "通过随机制定的40个4到7个城市规模的对称TSP实例测试表明，该方法在较小问题规模上具有高度可靠性，能够实现解的高采样概率。但随着问题规模的增加，成功概率会显著下降，显示出该方法在大规模问题上的局限性。此外，该论文还探讨了参数的预热初始化对性能的影响及其在更复杂问题（如车辆路径优化和作业车间调度）中的潜在应用前景。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21076", "html_url": "https://arxiv.org/abs/2508.21076", "title": "Pep2Prob基准：基于MS$^2$的蛋白质组学的片段离子概率预测", "title_en": "Pep2Prob Benchmark: Predicting Fragment Ion Probability for MS$^2$-based Proteomics", "authors": "Hao Xu,Zhichao Wang,Shengqi Sang,Pisit Wajanasara,Nuno Bandeira", "background": "蛋白质在细胞功能中扮演几乎全部的角色，并且构成了大部分的药物靶点，因此对蛋白质的分析对理解健康和疾病中的人类生物学至关重要。串联质谱（MS$^2$）是组学技术中主要的分析手段，通过离子化、裂解肽段，并利用生成的质谱数据来进行蛋白质的鉴定和定量。在MS$^2$分析中，肽段片段离子概率预测对于提高肽段鉴定的准确性发挥了关键作用。现有的方法依赖于全局的裂解统计信息，假设片段的概率在所有肽段中是一致的。但从生物化学原理来看，这一假设过于简化，无法准确预测。因此，有必要设计一个全面的数据集和基准，用于肽段特异的片段离子概率预测，以解决这一问题。", "innovation": "提出了Pep2Prob，这是首个全面的数据集和基准，专门用于肽段特异的片段离子概率预测。该数据集包含了608,780个唯一前体的片段离子概率统计信息（每个前体是一段肽序列及其电荷状态），数据来自超过1.83亿个高质量的高分辨率HCD MS$^2$质谱数据，这些数据都经过了肽段归属和裂解注释的验证。利用简单的统计规则和基于学习的方法建立了基准性能，发现利用肽段特异信息的模型明显优于仅使用全局裂解统计信息的方法。此外，通过一系列基于模型基准性能表明，肽段-裂解关系具有复杂的非线性特征，需要更为复杂的机器学习方法来应对这一挑战。", "conclusion": "Pep2Prob数据集和基准为肽段特异的片段离子概率预测提供了全面的数据集和方法评估标准，有助于提高蛋白质组学分析的准确性和效率。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21622", "html_url": "https://arxiv.org/abs/2508.21622", "title": "将大型语言模型与网络优化集成以实现交互性和解释性的供应链规划：一个实际案例研究", "title_en": "Integrating Large Language Models with Network Optimization for Interactive and Explainable Supply Chain Planning: A Real-World Case Study", "authors": "Saravanan Venkatachalam", "background": "本文介绍了一种综合框架，该框架结合了传统的网络优化模型与大型语言模型（LLMs），旨在为供应链计划提供互动、可解释且角色感知的决策支持。该论文旨在弥合复杂运营研究输出与业务利益相关者理解之间的差距，通过生成自然语言摘要、上下文可视化以及定制的关键绩效指标（KPI）。这项核心优化模型针对多个时期的多种项目网络中的库存重新分配问题，采用了混合整数线性规划的表述。", "innovation": "文章提出的系统结合了传统的网络优化模型与大型语言模型，通过生成自然语言摘要、上下文可视化和定制KPI，提供了一种互动、可解释且角色感知的决策支持方法，针对多个时期的多种项目网络中的库存重新分配问题，采用了混合整数线性规划的表述。因此，该系统能基于人工智能代理、RESTful API和动态用户界面，提供实时互动、配置更新和基于模拟的见解支持。通过实际案例研究，证明了该系统能有效预防缺货、降低成本和保持服务水平。", "conclusion": "论文未来扩展包括集成私有LLMs、迁移学习、强化学习和贝叶斯神经网络以增强可解释性、适应性和实时决策能力。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21098", "html_url": "https://arxiv.org/abs/2508.21098", "title": "TrInk: 使用Transformer网络的墨迹生成", "title_en": "TrInk: Ink Generation with Transformer Network", "authors": "Zezhong Jin,Shubhang Desai,Xu Chen,Biyi Fang,Zhuoyi Huang,Zhe Li,Chong-Xin Gan,Xiao Tu,Man-Wai Mak,Yan Lu,Shujie Liu", "background": "本文的研究背景是在手写文本生成领域，现有方法在捕捉全局依赖关系方面存在不足，导致生成的手写文本在可读性和风格一致性方面不佳。因此，迫切需要一种能够有效捕捉全局依赖关系并提高手写文本生成质量的方法。", "innovation": "本文的创新之处在于提出了一种基于Transformer的模型TrInk，通过引入缩放的位置嵌入和高斯记忆掩码来更好地对齐输入文本和生成的笔划点。此外，还设计了主观和客观评估管道，以全面评估生成手写文本的可读性和风格一致性。实验结果表明，与之前的方法相比，基于Transformer的模型在IAM-OnDB数据集上将字符错误率（CER）降低了35.56%和单词错误率（WER）降低了29.66%。", "conclusion": "本文通过引入新的网络结构和改进的注意力机制，显著提高了手写文本生成的质量。实验结果验证了模型的有效性，并提供了生成的手写样本和基础模型的演示页面以供参考。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21097", "html_url": "https://arxiv.org/abs/2508.21097", "title": "使用大型语言模型和检索增强生成的模型驱动量子代码生成", "title_en": "Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation", "authors": "Nazanin Siavash,Armin Moin", "background": "该研究背景是利用大型语言模型（LLMs）进行模型到文本/代码的转换，特别聚焦于量子和混合量子-经典软件系统。这些系统的复杂性导致了开发成本高昂且存在技术人才不足的问题。研究人员希望通过模型驱动的方法来降低这些问题带来的成本和风险。已有工作中，通过Qiskit库生成量子代码已被验证，该库支持在基于门的或量子电路的量子计算机上执行代码。研究者利用GitHub公共代码库中的示例Qiskit代码来实现检索增强生成（RAG）管道，以提升代码自动生成效果。实验证明，精心设计的提示可以将CodeBLEU评分提高四倍，从而生成更准确和一致的量子代码。未来研究方向涉及多种模型驱动的实验，以提升生成代码的准确性与一致性", "innovation": "该研究创新性地提出了一种结合大型语言模型和检索增强生成（RAG）管道的新的研究方向，以生成量子代码。研究通过引入Qiskit库来支持量子计算中基于门和电路的操作。实验证实，精心设计的提示可以显著提升生成代码的质量。未来的潜力在于进一步的实验研究，包括将软件系统模型实例用作信息源，以及使用LLMs进行代码到代码的转换，例如编译优化等。", "conclusion": "实验结果表明，精心设计的提示可以将代码生成效果提高四倍，通过RAG管道生成的量子代码更加准确和一致。未来的研究可以通过进一步的实验来扩展这些发现，特别是在将模型实例用作信息源和LLMs用于代码到代码转换方面。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21101", "html_url": "https://arxiv.org/abs/2508.21101", "title": "超越预测：医疗保健人工智能中的强化学习", "title_en": "Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI", "authors": "Dilruk Perera,Gousia Habib,Qianyi Xu,Daniel J. Tan,Kai He,Erik Cambria,Mengling Feng", "background": "强化学习（RL）标志着人工智能在医疗保健中应用的根本转变。与传统的仅预测结果的模型不同，RL系统通过尝试、反馈和长期奖励优化来学习，这为医疗保健带来了革命性的可能性和新的风险。从信息融合的角度来看，RL的医疗保健系统通常融合来自各种源的信号，如生命体征、实验室化验单、临床笔记、成像和设备遥测，并通过时间和决策级别机制来操作。这些系统可以在集中式、联邦或边缘架构中运行，以满足实时临床约束，并自然跨越数据、特征和决策融合级别的界线。", "innovation": "本文从医疗保健限制的角度梳理了大量的RL技术，包括基于模型和不基于模型的方法、离线和批处理受限方法，以及奖励规格和不确定性校准的新兴策略。还全面分析了包括重症监护、慢性病、精神健康、诊断和机械辅助在内的RL应用，指出了趋势、差距和转化瓶颈。本文与以往的综述不同，通过详细分析RL的伦理挑战、部署挑战和奖励设计挑战，提出了安全、以人为本策略学习的教训。本文旨在作为技术研发路线图和对RL在医疗保健AI中日益变革性角色的批判性反思，不再将其视为预测机器，而是作为具有自治功能的临床智能。", "conclusion": "本文作为技术路线图，反映了RL在医疗保健AI中的新角色，旨在推动RL作为安全、以人为本的策略学习工具的发展，减轻其伦理和实际应用挑战。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21099", "html_url": "https://arxiv.org/abs/2508.21099", "title": "Safe-Control：一种减轻文本生成图像模型中不安全内容的安全补丁", "title_en": "Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models", "authors": "Xiangtao Meng,Yingkai Dong,Ning Yu,Li Wang,Zheng Li,Shanqing Guo", "background": "尽管在文本到图像生成模型方面取得了进展，但这些模型的潜在滥用风险引发了严重的安全问题。模型开发人员已经努力引入可以解决这些担忧的安全机制。然而，现有的安全机制要么在分布偏移下易于欺骗，要么需要大量的模型特定调整。", "innovation": "为了克服这些限制，我们提出了Safe-Control，一种创新的即插即用安全补丁，旨在减少文本到图像生成模型中的不安全内容生成。Safe-Control 使用数据驱动策略和安全意识条件，在锁定的文本到图像模型中注入安全控制信号，以贴片形式完成更新。此外，模型开发人员还可以构建适应不同安全需求的安全补丁，然后灵活地合并到统一的补丁中。该设计确保了其适应性，使其兼容于具有相似去噪架构的其他文本到图像模型。", "conclusion": "我们对六种不同的公共文本到图像生成模型进行了广泛的评估。结果表明，Safe-Control 在六种具有相似生成架构的不同文本到图像生成模型中有效减少了不安全内容的生成，同时保持了良性图像的质量和文本对齐。与七种最先进的安全机制相比，包括外部和内部防御，Safe-Control 在减少不安全内容生成方面明显优于所有基线方法。例如，在不安全提示和最新对抗攻击下，其将不安全内容生成的概率降低到了7%，而大多数基线方法的这一概率大约为20%。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21107", "html_url": "https://arxiv.org/abs/2508.21107", "title": "通过对抗强化学习学习生成单元测试", "title_en": "Learning to Generate Unit Test via Adversarial Reinforcement Learning", "authors": "Dongjun Lee,Changho Hwang,Kimin Lee", "background": "单元测试是编程中的核心实践，有助于系统评估由人类开发者或大型语言模型（LLMs）生成的程序。然而，编写全面的单元测试具有挑战性，尽管LLMs已用于自动化测试生成，但如何训练LLMs以生成高质量的测试方法仍未得到充分探索。", "innovation": "提出了一种新颖的强化学习框架——UTRL，利用这种框架可训练LLMs根据编程指令生成高质量的单元测试。该框架通过强化学习以对抗性方式训练一个单元测试生成器和一个代码生成器。单元测试生成器旨在最大化鉴别奖励，这反映了其产生能够揭示代码生成器解决方案中缺陷的测试的能力；而代码生成器旨在最大化代码奖励，这反映了其产生能够通过测试生成器生成的测试的解决方案的能力。实验结果表明，通过UTRL训练的Qwen3-4B生成的单元测试质量高于通过监督微调人类编写的单元测试生成的单元测试。此外，UTRL训练的Qwen3-4B在生成高质量单元测试方面优于GPT-4.1等前沿模型，这突显了UTRL在训练LLMs进行此任务方面的有效性。", "conclusion": "证明了UTRL在训练LLMs生成高质量单元测试方面的有效性，并展示了其在质量上的优越性，超出了一些前沿模型。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21104", "html_url": "https://arxiv.org/abs/2508.21104", "title": "PVPO：基于预估值的策略优化方法及其在智能决策中的应用", "title_en": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning", "authors": "Wenfeng Feng,Penghong Zhao,Guochao Jiang,Chuzhan Hao,Yuewei Zhang,Hao Wang", "background": "无专家评价的强化学习方法，尤其是组策略，由于其在复杂任务中的高效性而受到广泛关注。然而，这些方法依赖于策略内的多次采样和比较来估计优势，可能会导致策略陷入局部最优，增加计算成本。", "innovation": "提出了一种名为PVPO的有效强化学习方法，通过引入一个优势参考锚点和数据预采样进行增强。具体来说，使用参考模型提前展开并利用计算出的奖励分值作为参考锚点。该方法有效纠正了组内比较引入的累积偏差，显著减少了对展开次数的依赖。同时，参考模型在数据预采样期间可以评估样本难度，实现高效选择高收益数据，提高训练效率。实验结果表明，PVPO在多个领域的九个数据集上达到了SOTA性能，并且在多个任务中的泛化能力强大，且在不同规模的模型上表现出可扩展性。", "conclusion": "PVPO不仅在多个任务上展示了强大的泛化能力，还展示出了不同程度模型上的可扩展性能。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21103", "html_url": "https://arxiv.org/abs/2508.21103", "title": "使用混合深度学习的严肃游戏中时空EEG情绪识别", "title_en": "Spatiotemporal EEG-Based Emotion Recognition Using SAM Ratings from Serious Games with Hybrid Deep Learning", "authors": "Abdul Rehman,Ilona Heldal,Jerry Chun-Wei Lin", "background": "基于EEG的情绪识别在使用深度学习和经典机器学习方法时取得了令人鼓舞的结果，然而大多数现有研究集中在二元情感正负面预测或特定个体分类上，这限制了其在真实情感计算系统中的广泛适用性和部署。", "innovation": "本文提出了一种基于GAMEEMO数据集的统一多粒度EEG情绪分类框架，该框架包括14通道的EEG记录和来自28个参与者的自述情绪评分（无聊、可怕、平静和有趣），并在四种情绪诱导的游戏中采集数据。该框架采用了一种有结构的预处理策略，包括时间窗口分割、统计和频域特征混合提取，以及z-score规范化，将原始EEG信号转换为稳健且具有区分性的输入向量。为虹考虑了三种互补的情感标签表示：基于正负情感平均极性的二元情感分类，多类别情感分类，以及通过将每种情感分成10个等级来实现的精细的多标签表示。", "conclusion": "本文评估了多种模型，包括随机森林、XGBoost、SVM以及深度神经架构如LSTM、LSTM-GRU和CNN-LSTM。其中，LSTM-GRU模型在二元情感任务中的F1分数为0.932，并在多类别和多标签情感分类中分别达到了94.5%和90.6%的准确率。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21109", "html_url": "https://arxiv.org/abs/2508.21109", "title": "一种增强注意力功能的双向长短期记忆神经网络联合48小时预测温度、辐照度和相对湿度的解释性方法", "title_en": "An Explainable, Attention-Enhanced, Bidirectional Long Short-Term Memory Neural Network for Joint 48-Hour Forecasting of Temperature, Irradiance, and Relative Humidity", "authors": "Georgios Vamvouras,Konstantinos Braimakis,Christos Tzivanidis", "background": "本文提出了一种深度学习框架，用于预测未来48小时的温度、太阳辐照度和相对湿度，以支持智能HVAC系统的模型预测控制。使用的数据集包括从2019年至2022年的历史气象数据，此数据集编码了周期性的时间特征，并通过联合预测三种变量来捕捉时间依赖性和交叉特征依赖性。", "innovation": "该论文通过结合多变量预测、基于注意力的深度学习和可解释性，提出了一个解释性强的双向长短期记忆网络来共同预测48小时的温度、辐照度和相对湿度。这种方法能捕捉时间依赖性和交叉特征依赖性，并通过集成梯度量化特征贡献，注意力权重揭示时间模式，提高可解释性。", "conclusion": "论文展示了这种框架在可靠短期气象预测方面的准确性和透明度，突显了其在通过可靠短期气象预测实现能源效率建筑控制的潜在应用价值，相比最新的数值天气预测和机器学习基准，该模型表现更优。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21803", "html_url": "https://arxiv.org/abs/2508.21803", "title": "利用协作多智能体大语言模型架构从SOAP笔记中自动检测临床问题", "title_en": "Automated Clinical Problem Detection from SOAP Notes using a Collaborative Multi-Agent LLM Architecture", "authors": "Yeawon Lee,Xiaoyang Wang,Christopher C. Yang", "background": "临床叙事的准确解读对于患者护理至关重要，但由于这些笔记的复杂性，自动化实施变得具有挑战性。尽管大型语言模型（LLMs）显示出潜力，但单一模型方法在高风险临床任务中的鲁棒性不足。现有的单一模型方法无法满足复杂临床任务的需求。", "innovation": "本文提出了一个协作多智能体系统（MAS），该系统模拟了临床咨询团队的工作流程，用于解决上述问题。通过管理者代理协调一组动态分配的专家代理，该系统进行了分层、迭代的辩论以达成共识，从而识别SOAP笔记中的临床问题。研究结果显示，动态多智能体配置在识别充血性心力衰竭、急性肾损伤和败血症等方面显示出一致的性能提升。", "conclusion": "通过模拟临床团队的推理过程，该系统提供了一条更为准确、稳健和可解释的临床决策支持工具发展的潜在路径。尽管如此，质性分析表明，该结构有时也容易陷入群体思维。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21112", "html_url": "https://arxiv.org/abs/2508.21112", "title": "EmbodiedOneVision：面向通用机器人控制的交织视觉-文本-动作预训练", "title_en": "EmbodiedOneVision: Interleaved Vision-Text-Action Pretraining for General Robot Control", "authors": "Delin Qu,Haoming Song,Qizhi Chen,Zhaoqing Chen,Xianqiang Gao,Xinyi Ye,Qi Lv,Modi Shi,Guanghui Ren,Cheng Ruan,Maoqing Yao,Haoran Yang,Jiacheng Bao,Bin Zhao,Dong Wang", "background": "人类能够在开放世界中无缝地进行多模态推理和物理交互是通用型具身智能系统的核心目标。最近的视觉-语言-动作（VLA）模型在大规模的机器人和视觉-文本数据上进行联合训练，已经在通用机器人控制方面取得了显著进展。然而，这些模型仍然无法达到人类级别的灵活性，尤其是在交错推理和交互方面。", "innovation": "本文提出了EO-Robotics，包括EO-1模型和EO-Data1.5M数据集。EO-1是一个统一的具身基础模型，通过交织视觉-文本-动作预训练，在多模态具身推理和机器人控制方面实现了优异表现。其基于两个关键支柱：（i）统一架构，能够无差别地处理多模态输入（图像、文本、视频和动作），以及（ii）庞大的高质量多模态具身推理数据集EO-Data1.5M，包含超过150万的样本，强调交错视觉-文本-动作理解。EO-1通过交织的自回归解码和流动匹配去噪在EO-Data1.5M上进行训练，实现无缝的机器人动作生成和多模态具身推理。广泛的实验表明，交错视觉-文本-动作学习在开放世界理解与泛化方面的有效性，通过多种长周期的灵巧操作任务进行验证。", "conclusion": "本论文详细介绍了EO-1模型的架构、EO-Data1.5M数据集的构建策略以及训练方法，为开发先进的具身基础模型提供了宝贵见解。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21135", "html_url": "https://arxiv.org/abs/2508.21135", "title": "隐对象：针对多模态隐藏对象检测的模态无关融合", "title_en": "HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection", "authors": "Harris Song,Tuan-Anh Vu,Sanjith Menon,Sriram Narasimhan,M. Khalid Jawed", "background": "在多模态环境中，如遮挡、迷彩和光线变化等因素会显著妨碍检测性能。传统的基于RGB的方法在这种恶劣条件下往往无法奏效，这促使需要更为稳健和跨模态的方法。因此，提出了一种融合框架HiddenObject，利用Mamba机制整合RGB、热成像和深度数据，以增强对被遮盖或迷彩目标的检测能力。", "innovation": "提出了一种利用Mamba机制融合RGB、热成像和深度数据的融合框架，能够捕捉不同模态下的互补信号，从而在复杂和恶劣条件下提供更强大的检测性能。该方法能够识别模态特定的特征，并在统一表示中进行融合，适用于各种具有挑战性的场景。实验结果表明，该框架在多个基准数据集上达到了最先进的或竞争性性能。", "conclusion": "通过与现有方法的对比，证明了该融合设计的有效性，并揭示了当前单一模态和朴素融合策略的关键限制。结果表明，基于Mamba的融合架构在多模态对象检测领域具有重要意义，特别是在视觉退化或复杂条件下。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21113", "html_url": "https://arxiv.org/abs/2508.21113", "title": "R-4B：通过双模式退火和强化学习激励MLLMs的一般自思考能力", "title_en": "R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning", "authors": "Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng", "background": "多模态大语言模型（MLLMs）在复杂的推理问题上表现出色，但对不需要复杂推理就能解决的简单问题会造成冗余。这种冗余在资源使用和计算效率上是低效的，尤其是在处理简单的推理问题时更为明显。因此，需要一种方法来识别何时需要推理，以提高模型的效率。", "innovation": "提出了R-4B，一种具有自适应思考能力的自思考MLLM，通过双模式退火和改进的Bi-mode Policy Optimization (BPO)来辅助决策。该模型在数据集上进行训练，涵盖各种主题样本，并在改进的GRPO框架下进行了二次训练，以在每次接收输入查询时都能生成两种模式的响应。通过这种方式，R-4B能够在降低计算成本的同时实现卓越的推理性能，优于如Qwen2.5-VL-7B和Kimi-VL-A3B-Thinking-2506 (16B)等模型.", "conclusion": "R-4B 在各种挑战性基准测试中达到了最先进的性能。在大部分任务上优于 Qwen2.5-VL-7B，并在计算资源较低的情况下达到了与较大的模型相当的推理密集基准性能。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21106", "html_url": "https://arxiv.org/abs/2508.21106", "title": "全矩阵预条件矩阵的动态低秩近似在训练广义线性模型中的应用", "title_en": "Dynamic Low-rank Approximation of Full-Matrix Preconditioner for Training Generalized Linear Models", "authors": "Tatyana Matveeva,Aleksandr Katrutsa,Evgeny Frolov", "background": "自适应梯度方法如Adagrad及其变种在大规模优化中应用广泛。然而，这些方法使用对角预条件矩阵限制了参数相关性的捕捉能力。全矩阵自适应方法通过近似精确的海森矩阵来建模这些相关性，可能会使收敛速度更快，但是它们的计算和内存成本往往对于大规模模型来说是难以承受的。为了解决这一限制，本文提出AdaGram优化器，通过效率更高的全矩阵自适应梯度更新替代这些方法。AdaGram使用快速对称因子化计算每次迭代中的预条件更新方向，并通过矩阵积分方法沿优化轨迹保持预条件器的低秩结构。实验表明，使用五阶及更低秩的近似时，AdaGram能够更快收敛或与对角自适应优化器性能相当，这表明AdaGram在大规模模型自适应优化中的潜在可扩展性。", "innovation": "提出AdaGram优化器来实现高效全矩阵自适应梯度更新，利用快速对称因子化计算预条件更新方向，并通过矩阵积分方法保持预条件器的低秩结构，从而降低计算和内存开销，提高大规模模型的优化效率和性能。", "conclusion": "使用AdaGram优化器，数值实验表明其能够比现有对角自适应优化器更快收敛或达到相当性能，特别是在使用五阶及更低秩的近似情况下。这表明AdaGram可以作为一个在大规模模型中的可扩展自适应优化解决方案。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21111", "html_url": "https://arxiv.org/abs/2508.21111", "title": "自动化深空网络数据系统；基于类人智能的自适应异常检测案例研究", "title_en": "Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI", "authors": "Evan J. Chou(1 and 2),Lisa S. Locke(3),Harvey M. Soldan(3) ((1) University of California San Diego, (2) Pasadena City College, (3) Jet Propulsion Laboratory California Institute of Technology)", "background": "深空网络(DSN)是NASA最大的天线设施网络，产生大量多变量时间序列数据。长时间操作中，天线和发射机可能会发生退化，导致数据流中断，威胁到依靠深空网络维持生命线的数十个航天器的连接。本研究旨在通过数据辅助JP宇航员直接定位异常和设备退化，确保深空网络的维护和未来太空任务的操作。为此，研究了各种机器学习技术，通过预测分析重建数据，并通过统计计算和阈值确定实时数据集中的异常数据条目。除此之外，还集成了一个强化学习子系统，根据严重程度对识别出的异常进行分类，并结合大型语言模型为每个异常数据条目提供解释，这些都可以通过人工反馈/输入进行改进和微调。特别地，还为DSN发射器实施了一个完整的数据管道系统，将数据提取、解析和处理的工作流程整合在一起，以完善DSN异常检测的数据流程。", "innovation": "研究引入了基于机器学习和强化学习的系统来检测DSN的异常。通过一个完整的数据管道系统连接了从DSN天线数据中提取的模型，完善了DSN异常检测的数据流程。还结合了大型语言模型为每个异常数据条目提供解释。这个系统使用类人智能进行复杂的推理来确定异常数据的分类和预测。", "conclusion": "该系统通过集成各种先进的机器学习方法和类人智能系统，实现了深空网络数据系统的自动化，并有效提高了异常检测的效率和准确性，为未来太空任务的持续支持提供了更强有力的数据保障。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21148", "html_url": "https://arxiv.org/abs/2508.21148", "title": "科学大型语言模型：从数据基础到智能代理前沿", "title_en": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "authors": "Ming Hu,Chenglong Ma,Wei Li,Wanghan Xu,Jiamin Wu,Jucheng Hu,Tianbin Li,Guohang Zhuang,Jiaqi Liu,Yingzhou Lu,Ying Chen,Chaoyang Zhang,Cheng Tan,Jie Ying,Guocheng Wu,Shujian Gao,Pengcheng Chen,Jiashi Lin,Haitao Wu,Lulu Chen,Fengxiang Wang,Yuanyuan Zhang,Xiangyu Zhao,Feilong Tang,Encheng Su,Junzhi Ning,Xinyao Liu,Ye Du,Changkai Ji,Cheng Tang,Huihui Xu,Ziyang Chen,Ziyan Huang,Jiyao Liu,Pengfei Jiang,Yizhou Wang,Chen Tang,Jianyu Wu,Yuchen Ren,Siyuan Yan,Zhonghua Wang,Zhongxing Xu,Shiyan Su,Shangquan Sun,Runkai Zhao,Zhisheng Zhang,Yu Liu,Fudi Wang,Yuanfeng Ji,Yanzhou Su,Hongming Shan,Chunmei Feng,Jiahao Xu,Jiangtao Yan,Wenhao Tang,Diping Song,Lihao Liu,Yanyan Huang,Lequan Yu,Bin Fu,Shujun Wang,Xiaomeng Li,Xiaowei Hu,Yun Gu,Ben Fei,Zhongying Deng,Benyou Wang,Yuewen Cao,Minjie Shen,Haodong Duan,Jie Xu,Yirong Chen,Fang Yan,Hongxia Hao,Jielan Li,Jiajun Du,Yanbo Wang,Imran Razzak,Chi Zhang,Lijun Wu,Conghui He,Zhaohui Lu,Jinhai Huang,Yihao Liu,Fenghua Ling,Yuqiang Li,Aoran Wang,Qihao Zheng,Nanqing Dong,Tianfan Fu,Dongzhan Zhou,Yan Lu,Wenlong Zhang,Jin Ye,Jianfei Cai,Wanli Ouyang,Yu Qiao,Zongyuan Ge,Shixiang Tang,Junjun He", "background": "科学大型语言模型（Sci-LLMs）正在改变科学知识的表示、整合和应用方式，但其进步受到科学研究中复杂数据的驱动。本文提供了一个全面的数据驱动综合分析，重新定义了Sci-LLMs的发展为模型与其底层数据基础设施之间的共同发展。科学数据被统一分类，并构建了一个层次化的科学知识模型，强调了科学语料库与通用自然语言处理数据集之间的多模态、跨尺度、领域专属性挑战。", "innovation": "本文提出了科学数据的统一分类框架和层次化的科学知识模型，系统回顾了从通用基础模型到跨学科领域的专门模型的多个Sci-LLMs，并对超过270个前/后训练数据集进行了广泛的分析，解释了Sci-LLMs所面临的独特挑战：异质性、多尺度和含不确定性的语料库，需要能够保持领域不变性和跨模态推理的表示方法。同时，文章对超过190个基准数据集进行了评估，并探讨了自过程和发现导向的评估方法的转变，使用了高级的评价协议。此外，讨论了半自动化注解管道和专家验证等新兴解决方案，提出了一个闭环系统，其中基于Sci-LLMs的自主代理进行主动实验、验证，并为不断演化的知识库做出贡献。", "conclusion": "本文提供了一条路线图，旨在构建可信赖的、不断演化的AI系统，这些系统作为真正科学发现的合作伙伴，加速了科学发现的过程。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21153", "html_url": "https://arxiv.org/abs/2508.21153", "title": "WaveLLDM: 设计一种轻量级的潜在扩散模型用于语音增强和恢复", "title_en": "WaveLLDM: Design and Development of a Lightweight Latent Diffusion Model for Speech Enhancement and Restoration", "authors": "Kevin Putra Santoso,Rizka Wakhidatus Sholikah,Raden Venantius Hari Ginardi", "background": "高质量的音频在在线交流、虚拟助手和多媒体行业等方面具有重要作用，但由噪声、压缩和传输造成的降质仍然是一个主要挑战。尽管扩散模型在音频恢复上表现出色，但它们通常需要大量的计算资源，并且难以处理较长的缺失段落。", "innovation": "该研究提出了WaveLLDM（波形轻量级潜在扩散模型），该模型结合了高效的神经音频编解码器和潜在扩散，用于音频恢复与降噪。WaveLLDM 在压缩的潜在空间中处理音频，降低了计算复杂性同时保持重建质量，不同于传统的在时域或频域工作的方法。", "conclusion": "实验结果表明，WaveLLDM 在Voicebank+DEMAND测试集上实现了准确的频谱重建和较低的Log-Spectral Distance (LSD)分数 (0.48到0.60)，并且具有对未见数据的良好适应性。然而，WaveLLDM 在感知质量和语音清晰度方面仍不如最先进的方法，WB-PESQ 分数在1.62到1.71之间，STOI 分数在0.76到0.78之间。这些性能限制主要归因于模型架构的亚最优调优、缺乏微调以及训练时间不足。不过，WaveLLDM 灵活的结构为未来的发展提供了坚实的基础。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21154", "html_url": "https://arxiv.org/abs/2508.21154", "title": "RadGS-Reg: 通过联合三维辐射高斯重建和三维/三维配准脊柱CT与双平面X光片配准", "title_en": "RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative Gaussians Reconstruction and 3D/3D Registration", "authors": "Ao Shen,Xueming Fu,Junfeng Jiang,Qiang Zeng,Ye Tang,Zhengming Chen,Luming Nong,Feng Wang,S. Kevin Zhou", "background": "在图像引导导航中，CT/X射线配准依然具有挑战性，因为需要高精度和实时性能。传统的“渲染和比较”方法依赖于迭代投影和比较，导致空间信息丢失和领域差距。基于双平面X射线的三维重建能够补充空间和形状信息，但当前方法受限于需要大量视图以及在处理噪声X射线方面的困难。为了解决这些限制，我们引入RadGS-Reg，这是一种新的框架，用于椎体级别的CT/X射线配准，通过联合三维辐射高斯（RadGS）重建和三维/三维配准。", "innovation": "我们提出了一个基于学习的RadGS重建方法，并结合了Counterfactual Attention Learning（CAL）机制，专注于在噪声X射线中探索椎体区域的重建。此外，还提出了一种患者特定的预训练策略，该策略逐步将RadGS-Reg适应从模拟数据到真实数据，同时学习椎体形状先验知识。实验结果表明，在所构建的数据集上，该方法在两个任务上均实现了最先进的性能，超越了现有方法。", "conclusion": "实验结果表明，RadGS-Reg在两个任务上均实现了最先进的性能，超越了现有方法。我们已经开源了该框架的代码。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21181", "html_url": "https://arxiv.org/abs/2508.21181", "title": "FUTURE：树集的灵活遗忘技术", "title_en": "FUTURE: Flexible Unlearning for Tree Ensemble", "authors": "Ziheng Chen,Jin Huang,Jiali Cheng,Yuchan Guo,Mengjie Wang,Lalitesh Morishetti,Kaushiki Nag,Hadi Amiri", "background": "树集在分类任务中表现出色，广泛应用于生物信息学、金融和医学诊断等领域。随着对数据隐私和遗忘权的重视，已经提出了多种忘却算法，旨在使树集能够遗忘敏感信息。然而，现有方法通常针对特定模型或依赖于树的离散结构，难以扩展到复杂的树集，并且对于大规模数据集效率低下。", "innovation": "本文提出了FUTURE，一种新的树集忘却算法。通过将遗忘样本的问题表述为基于梯度的优化任务，并采用概率模型近似来解决树集的非可微特性问题，使得忘却过程在端到端中更有效率和可行。", "conclusion": "在实际数据集上的实验表明，FUTURE可以显著且成功地实现忘却效果。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21172", "html_url": "https://arxiv.org/abs/2508.21172", "title": "深应在时连接的回声状态网络：探究未经训练的循环神经网络中的剩余正交连接", "title_en": "Deep Residual Echo State Networks: exploring residual orthogonal connections in untrained Recurrent Neural Networks", "authors": "Matteo Pinna,Andrea Ceni,Claudio Gallicchio", "background": "回声状态网络（ESNs）是训练快速高效的未训练循环神经网络（RNNs）中的特殊类型，通常在残响计算（RC）框架下使用。然而，传统的ESNs在长期信息处理方面经常表现不佳。本文探讨了一种新的基于时间剩余连接的深度未经训练RNNs，称为深剩余回声状态网络（DeepResESNs），通过引入一个未训练剩余递归层的层次结构，显著提升了记忆容量和长期时序建模能力。", "innovation": "本文提出了一种基于时间剩余连接的深未经训练RNNs，称为DeepResESNs，通过引入一个未训练剩余递归层的层次结构，显著提升了记忆容量和长期时序建模能力。还研究了不同正交配置（包括随机生成和固定结构配置）对网络动态的影响，并通过严格的数学分析确定了确保DeepResESN动态稳定的必要和充分条件。", "conclusion": "在各种时间序列任务上的实验展示了所提出的方法在传统的浅层和深层RC中的优势。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21206", "html_url": "https://arxiv.org/abs/2508.21206", "title": "通过像素化方法增强自回归语言模型对文字攻击的鲁棒性", "title_en": "Enhancing Robustness of Autoregressive Language Models against Orthographic Attacks via Pixel-based Approach", "authors": "Han Yang,Jian Lan,Yihong Liu,Hinrich Schütze,Thomas Seidl", "background": "自回归语言模型容易受到文字攻击的影响，即通过输入文本中插入多语言字母表中的字符而导致性能显著下降。这种脆弱性主要是由于子词分词器和其嵌入固有的未知词汇问题。", "innovation": "提出了一种基于像素的生成语言模型，将基于文本的嵌入替换为基于像素的表示，通过将单词渲染为单独的图像。这种设计提供了对噪声输入的更强鲁棒性，并且拓宽了为不同书写系统的多语言文本提供兼容性的能力。该方法在多语言LAMBADA数据集、WMT24数据集和SST-2基准测试上进行了评估，证明了其对文字噪声的抗扰能力和在多语言环境中的有效性。", "conclusion": "该研究提出的方法不仅增强了自回归语言模型对文字噪声的鲁棒性，而且适用于多种书写体系的多语言环境。已经在多个数据集上进行了评估，验证了其有效性和鲁棒性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21201", "html_url": "https://arxiv.org/abs/2508.21201", "title": "使用分组相对策略优化强化学习改进航空安全分析", "title_en": "Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization", "authors": "Arash Ahmadi,Sarah Sharif,Yaser Banad", "background": "分析人类因素在航空事故中的作用对于预防未来事故至关重要，但现有的人类因素分析与分类系统HFACS方法存在可扩展性和一致性问题。本文旨在解决这些问题，提出了一种基于强化学习与分组相对策略优化（GRPO）的自动化HFACS分类框架，用于航空安全分析。该框架融合了定制的多成分奖励系统，以及合成数据生成方法来解决事故数据集类别不平衡问题。", "innovation": "本文引入了一种基于GRPO优化的自动化HFACS分类框架。该框架通过使用分组相对策略优化和强化学习来微调Llama-3.1 8B语言模型，该方法集成了定制的多成分奖励机制，以及合成数据生成技术以解决数据集中的类别不平衡问题。实验结果显示，优化后的模型在精确匹配准确性和部分匹配准确性方面均取得了显著提高，特别地，该模型在关键指标上优于现有的大型语言模型，如GPT-5-mini和Gemini-2.5-fiash。此外，本文还提出了多标签HFACS分类问题中的精确匹配准确度作为评估语言模型高级推理能力的新基准方法。", "conclusion": "本研究证明小型、领域优化的模型可以提供一种在计算效率和性能方面更好的解决方案，适用于关键的安全分析任务。通过这种方法，可以在资源受限的边缘设备上实现强大的、低延迟部署。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21164", "html_url": "https://arxiv.org/abs/2508.21164", "title": "量化大型语言模型标签引发的偏差在其自我评估和交叉评估中的度量", "title_en": "Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations", "authors": "Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush", "background": "大型语言模型（LLMs）越来越多地被用来评估输出，但它们的判断可能会受到误导。这项研究探讨了ChatGPT、Gemini和Claude在四种条件下的自我评估和交叉评估中的偏见情况：无标签、真实标签和两种虚假标签场景。作者研究了这三种模型对其各自创作的博客文章的评估，包括整体偏好投票和对连贯性、信息性和简洁性的质量评分，并将所有评分转化为百分比以便直接比较。结果揭示了明显的不对称性：标记为“Claude”的文章得分更高，而标记为“Gemini”的文章得分更低，不论实际内容如何。虚假标签经常改变了排名，导致偏好投票最多相差50个百分点，质量评分最多相差12个百分点。Gemini在看到真实标签时对自己的评分崩溃，而Claude对自己的偏好加剧了。这些发现表明，感知到的模型身份对高层判决会产生重大扭曲，并微妙地影响详细的质量评分，强调了制定盲评估或多种模型评估协议以确保LLM基准测试公正性的必要性。", "innovation": "这项研究通过比较真实标签与虚假标签对大型语言模型评估的影响，量化了标签引致的偏见。研究采用了不同模型相互评价和自我评价的方法，对连贯性、信息性和简洁性等质量指标进行了直接比较。这种研究方法有利于揭示大型语言模型在评分时所受到的干扰因素，并提出盲评估或多种模型评估协议确保评估公正性的建议。", "conclusion": "此项研究揭示了感知到的模型身份可以严重影响高层判断，并微妙地影响详细质量评分。研究结果强调了在大型语言模型基准测试中使用盲评估或多种模型评估协议的重要性，以确保评估的公平性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21186", "html_url": "https://arxiv.org/abs/2508.21186", "title": "从复制动力学到Softmax平衡的流形轨迹：在下一个词预测中的路径依赖得分调整", "title_en": "Manifold Trajectories in Next-Token Prediction: From Replicator Dynamics to Softmax Equilibrium", "authors": "Christopher R. Lee-Jenkins", "background": "通常认为大型语言模型在解码时是通过给定每个标记的分数并使用softmax进行归一化来实现的。尽管这个过程得到了广泛应用，但其背后的机制和推动力并没有得到充分解释。本文从更深层次的角度，用约束变分原理重新解释解码步骤，并将连续时间的多乘权（熵镜像）更新和复制流归类到这一框架中，从而更深入理解softmax函数如何影响下一个标记的概率分布。这项工作为了解和优化语言模型的输出分布提供了一个新的视角。", "innovation": "本文提出了一个简明的、自包含的模型解码过程解释，将其视为概率单纯形上的受约束变分原理。通过这种方式，发现了连续时间的多乘权（熵镜像）更新和复制流如何共同参与平滑轨迹的过程。此外，提出温度可以被视为沿相同轨迹的精确时间缩放，而top-k和nucleus采样则将流动限制到了相似的保证范围内。这项工作还探讨了路径依赖的分数调整及其与幻觉行为的关系，但没有讨论训练动力学或内部表示的问题，这些问题将在未来的工作中探讨。", "conclusion": "在固定的上下文和温度条件下，下一个标记的分布沿单纯形内平滑轨迹移动，并最终收敛到softmax平衡状态。这正式化了输出分布层面的“流形穿行”直觉。此外，提出了关于路径依赖分数调整及其与幻觉行为之间关系的控制性解释，但没有对训练动态或内部表示提出具体结论，这些将在未来的工作中深入探讨。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21228", "html_url": "https://arxiv.org/abs/2508.21228", "title": "解码记忆：一种高效的自我一致性幻觉检测管道", "title_en": "Decoding Memories: An Efficient Pipeline for Self-Consistency Hallucination Detection", "authors": "Weizhi Gao,Xiaorui Liu,Feiyi Wang,Dan Lu,Junqi Yin", "background": "大型语言模型（LLMs）在研究和实际应用中展现了令人印象深刻的性能，但在幻觉检测方面仍然存在问题。现有的幻觉检测方法在句子生成层面表现不佳，或者严重依赖领域特定知识。虽然自我一致性方法能够解决这些限制，但由于生成过程中需要反复迭代，其计算成本较高。本文首次研究了自我一致性方法中的冗余现象，表现为生成之间的共享前缀标记，并发现非精确答案标记对语义内容的贡献甚微。", "innovation": "基于上述洞察，本文提出了一种新型解码记忆管道（DMP），通过选择性推理和退火解码加速生成过程。该方法与模型、数据集、解码策略和自我一致性基线无关，能够一致地提高多响应生成效率，并且有潜力扩展到对齐和推理任务中。大规模实验表明，该方法在不牺牲AUROC性能的情况下可实现最高3倍的速度提升。", "conclusion": "本文提出的解码记忆管道能够在不牺牲AUROC性能的情况下大大提高多响应生成的效率，并且有潜力适用于对齐和推理任务。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21222", "html_url": "https://arxiv.org/abs/2508.21222", "title": "通过视觉上下文提示实现可泛化的物体再识别", "title_en": "Generalizable Object Re-Identification via Visual In-Context Prompting", "authors": "Zhizhong Huang,Xiaoming Liu", "background": "当前的物体再识别（ReID）方法训练领域特定的模型（例如，为人员或车辆），这导致了欠缺泛化能力且需要昂贵标记数据的问题。自监督学习通过学习实例级不变性来减少标注需求，但它难以捕捉ReID至关重要的身份敏感特征。", "innovation": "这篇文章提出了视觉上下文提示（VICP），这是一种全新的框架，使得在已训练的模型可以直接通过只有上下文提示的示例泛化到新的未见类别，无需参数调整。VICP结合了大型语言模型（LLM）和视觉基础模型（VFM）：通过任务特定的提示，LLM能够从少数示例中推理出语义身份规则，然后指导VFM（例如DINO）通过动态视觉提示提取ID区分特征。通过使LLM推断出的语义概念与VFM预训练先验对齐，VICP能够实现到新类别的泛化，从而消除了针对特定数据集的重新训练需求。", "conclusion": "通过在ShopID10K和各种ReID基准上的实验，论文展示了VICP能显著优于基线模型在未见类别上的性能。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21184", "html_url": "https://arxiv.org/abs/2508.21184", "title": "BED-LLM：利用大规模语言模型和贝叶斯实验设计进行智能信息收集", "title_en": "BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design", "authors": "Deepro Choudhury,Sinead Williamson,Adam Goliński,Ning Miao,Freddie Bickford Smith,Michael Kirchhof,Yizhe Zhang,Tom Rainforth", "background": "提出了一个适应于大规模语言模型（LLMs）的方法，以提高它们从用户或其他外部数据源智能且适应性地收集信息的能力，这些信息是基于序列贝叶斯实验设计（BED）框架。该方法使得大规模语言模型能够作为高效的多轮对话代理并与其他外部环境互动。", "innovation": "该方法的关键创新包括精心设计的用于计算预期信息增益（EIG）的估计器、不依赖于上下文内更新进行上一轮回复的调整、以及特定的候选查询提议策略。这些创新使得方法能够在广泛的测试中实现显著的性能提升。", "conclusion": "BED-LLM方法在20问题游戏和利用LLM主动推断用户偏好的测试中都取得了显著的性能提升，相比直接提示LLM和其他自适应设计策略，显示出其在提高信息收集效率和对话交互效果上的显著优势。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21243", "html_url": "https://arxiv.org/abs/2508.21243", "title": "全频谱时间分块和结构化掩码以增强音频分类", "title_en": "Full-Frequency Temporal Patching and Structured Masking for Enhanced Audio Classification", "authors": "Aditya Makineni,Baocheng Geng,Qing Tian", "background": "现有的音频分类模型如Audio Spectrogram Transformer (AST)和Audio Mamba (AuM)采用的是来自计算机视觉的方形分块技术，这会破坏连续的频率模式，产生过多的分块，从而拖慢训练速度并增加计算负载。", "innovation": "提出了一种新的分块策略——全频谱时间分块（FFTP），该策略通过空间上局部化的时频上下文覆盖了频谱的整个频段，保留了谐波结构，大幅减少了分块数量和计算量。与此同时，还引入了SpecMask，这是一种分块对齐的频谱增强技术，它在固定掩码预算下结合了全频谱和局部时频掩码，增强了时间鲁棒性，同时保持了频谱的连续性。", "conclusion": "当将上述分块方法和SpecMask应用于AST和AuM时，在AudioSet-18k上的mAP和在SpeechCommandsV2上的准确率分别提升了6.76%和8.46%，同时计算量减少了83.26%，表现出显著的性能和效率提升。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21248", "html_url": "https://arxiv.org/abs/2508.21248", "title": "使用SSL模型层特征的儿童语音零样本KWS", "title_en": "Zero-Shot KWS for Children's Speech using Layer-Wise Features from SSL Models", "authors": "Subham Kutum,Abhijit Sinha,Hemant Kumar Kathania,Sudarsana Reddy Kadiri,Mahesh Chandra Govil", "background": "成人的语音存在独特的挑战，使得关键词识别（KWS）系统的性能受到影响，因为儿童语音具有独特的声学和语言特征。已有许多方法用于增强成人的KWS系统，但鲜有方法针对儿童语音进行KWS。", "innovation": "引入了一种零样本KWS方法，利用最先进的自我监督学习（SSL）模型（如Wav2Vec2，HuBERT和Data2Vec），并通过层别提取特征来训练Kaldi基于的深度神经网络KWS系统。该方法展示了在儿童语音数据集PFSTAR上的零样本能力，并且在所有关键词集上达到了最先进的性能。", "conclusion": "实验证明，SSL特征显著改善了儿童语音的零样本KWS性能，特别是在噪声条件下，新型SSL嵌入方法相对于传统的MFCC基线有显著的改进。这种方法有效解决了儿童讲话者特有的挑战，并通过CMU数据集进一步验证了KWS框架的泛化能力。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21259", "html_url": "https://arxiv.org/abs/2508.21259", "title": "突破冷启动障碍：双重和对拼DQN的强化学习", "title_en": "Breaking the Cold-Start Barrier: Reinforcement Learning with Double and Dueling DQNs", "authors": "Minda Zhao", "background": "推荐系统在为几乎没有交互历史的新用户提供准确建议时面临挑战，这个问题被称为冷用户难题。传统的推荐方法在处理这种情况时表现不佳。", "innovation": "本文提出了一种利用双重和对拼深度Q网络（DQN）的强化学习方法，通过从稀疏反馈中动态学习用户偏好，增强推荐准确性，同时不依赖于敏感的用户人口统计学数据。此外，通过将这些高级DQN变体与矩阵分解模型整合，该方法在大规模电子商务数据集上优于传统的基于流行性和活跃学习策略的方法。", "conclusion": "实验结果显示，特别是对拼DQN在冷用户中降低了均方根误差（RMSE），为受隐私限制的环境提供了一种有效的解决方案。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21225", "html_url": "https://arxiv.org/abs/2508.21225", "title": "层级的SSL特征能否改善儿童语音的零样本ASR性能？", "title_en": "Can Layer-wise SSL Features Improve Zero-Shot ASR Performance for Children's Speech?", "authors": "Abhijit Sinha,Hemant Kumar Kathania,Sudarsana Reddy Kadiri,Shrikanth Narayanan", "background": "ASR系统通常难以准确处理儿童的语音，因为儿童的语音具有独特的和高度变异性声学和语言特征。最近，自监督学习（SSL）模型在成人类语音的转录上取得了显著进展，但儿童语音的转录仍然是一个重大挑战。这项研究探讨了从最新的预训练SSL模型（Wav2Vec2、HuBERT、Data2Vec和WavLM）中提取的层级特征在零样本场景中改进儿童语音ASR性能的有效性。研究采用了WSJCAM0成人类语音进行训练，PFSTAR儿童语音进行测试，并通过Kaldi工具包整合这些层级特征到一个简化DNN基于的ASR系统中。研究表明，Wav2Vec2模型的第22层在零样本场景中的词错误率（WER）最低，为5.15%，相比直接使用Wav2Vec2的零样本解码降低了51.64%的错误率。年龄分组分析显示随着年龄的增长，性能提升更加显著，即使在较小的年龄组中，使用SSL特征也能获得明显改进。进一步在CMU Kids数据集上的实验，证实了类似的趋势，表明所提出的方法具有泛化能力。", "innovation": "研究创新性地使用了最新的SSL预训练模型（Wav2Vec2、HuBERT、Data2Vec和WavLM）的层级特征来改善零样本场景中的儿童语音ASR性能。特别地，通过对WSJCAM0成人类语音进行训练，PFSTAR儿童语音进行测试，发现Wav2Vec2模型的第22层在零样本场景中有最佳表现，相比直接使用Wav2Vec2降低了显著的词错误率。此外，年龄组别的分析显示，从较小的年龄组到较大的年龄组，性能提升表现出一致性，进一步验证了该方法的有效性和泛化能力。", "conclusion": "在零样本场景中，从最新的SSL模型中提取的层级特征显著提高了ASR系统对儿童语音的转录性能，特别是Wav2Vec2模型的第22层表现出最佳效果。该研究证实，这种方法不仅在较大年龄组有效，甚至在较小年龄组也有显著改善，展示了方法的泛化能力。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21252", "html_url": "https://arxiv.org/abs/2508.21252", "title": "量子机器学习在量子传感器电路中优化纠缠分布", "title_en": "Quantum Machine Learning for Optimizing Entanglement Distribution in Quantum Sensor Circuits", "authors": "Laxmisha Ashok Attisara,Sathish Kumar", "background": "在快速发展的量子计算领域，优化量子电路对于提高性能和效率至关重要。最近，量子传感已成为量子科学和技术领域中一个明确且快速发展的研究分支。该领域有望提供新的机会，特别是在高灵敏度和精度方面。纠缠是实现高灵敏度和测量精度的关键因素之一。这项论文介绍了一种新的方法，利用量子机器学习技术来优化量子传感器电路中的纠缠分布。通过在量子环境中利用强化学习，旨在优化纠缠布局，以最大化量子费鱼信息（QFI）和纠缠熵，这些是量子系统灵敏度和相干性的关键指标，同时最小化电路深度和门操作数。", "innovation": "本文提出了一种基于量子机器学习技术的新方法，用于优化量子传感器电路中的纠缠分布。该方法利用了强化学习来优化纠缠布局，以最大化QFI和纠缠熵，同时减少电路深度和门操作数。此外，该实现基于Qiskit，集成了噪声模型和错误缓解策略来模拟现实的量子环境。", "conclusion": "实验结果表明，量子机器学习方法在优化量子电路中具有显著的性能和灵敏度改进，这突显了机器学习在降低电路深度和门操作数的同时，通过测量范围为0.84-1.0的高QFI和熵，来优化量子电路的潜力。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21263", "html_url": "https://arxiv.org/abs/2508.21263", "title": "从胸部X光片进行肺部疾病严重程度分类的深度主动学习：在类别不平衡情况下使用较少数据进行学习", "title_en": "Deep Active Learning for Lung Disease Severity Classification from Chest X-rays: Learning with Less Data in the Presence of Class Imbalance", "authors": "Roy M. Gabriel,Mohammadreza Zandehshahvar,Marly van Assen,Nattakorn Kittisut,Kyle Peters,Carlo N. De Cecco,Ali Adibi", "background": "本文的背景是在胸腔X射线（CXR）上评估肺部疾病严重程度分类时，为了减少所需的标记数据量，并且在类别不平衡的情况下进行研究。具体来说，该研究针对COVID-19患者的胸腔X射线影像，旨在减少用于分类所需的标注数据量，同时保持或提升诊断性能。研究使用了带有贝叶斯神经网络（BNN）近似和加权损失函数的深度主动学习方法。", "innovation": "该研究的创新点在于应用了深度主动学习结合贝叶斯神经网络近似和加权损失函数的方法，以减少标注数据需求并处理类别不平衡问题。通过不同获得函数的迭代选择，从未标记数据池中逐步选择最具有信息性的样本进行标注。实验结果表明，熵采样方法在二分类情况下使用15.4%的训练数据实现了93.7%的准确率，而多分类情况下使用23.1%的标注数据实现了70.3%的准确率，这些方法在性能上超过了更复杂且计算成本更高的获取函数，显著降低了对标注数据的需求。", "conclusion": "本研究通过深度主动学习结合贝叶斯神经网络近似和加权损失函数，有效地减少了标记数据的需求，解决了类别不平衡的问题，同时保持或超越了诊断性能。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21294", "html_url": "https://arxiv.org/abs/2508.21294", "title": "BLUEX重新审视：通过自动图注增强基准覆盖率", "title_en": "BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning", "authors": "João Guilherme Alves Santos,Giovana Kerche Bonás,Thales Sales Almeida", "background": "随着大型语言模型（LLMs）能力的不断提高，特别是在多语言和非英语环境中，对稳健的评估方法的需求也在不断增加。现有评测数据集，如BLUEX，需要更新以适应新的语言和环境挑战。为了改进这些数据集，确保它们的适用性和相关性，特别是在LLM预训练数据污染研究方面。", "innovation": "本文提出对BLUEX数据集进行更新，包括2024-2025年的考试和采用最先进的模型自动生成的图像标题。这增加了数据集的准确性和覆盖面，使文本模型能更有效地利用视觉上下文。通过自动图注，数据集的使用范围从原版的2,841增至3,263个问题数据，有效改善了数据集的质量和适用性。", "conclusion": "研究评估了商业和开源LLM对通过图注利用视觉上下文的能力。这些创新显著增强了数据集对LLM的评估能力，特别是在多语言和视觉增强的场景中。更新后的BLUEX数据集因其增强的覆盖面和适用性，成为评估LLM性能的重要工具。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21253", "html_url": "https://arxiv.org/abs/2508.21253", "title": "使用强化学习优化大型量子比特阵列量子传感器电路", "title_en": "Reinforcement Learning for Optimizing Large Qubit Array based Quantum Sensor Circuits", "authors": "Laxmisha Ashok Attisara,Sathish Kumar", "background": "随着传感器中量子比特数量的增加，设计和控制量子电路的复杂性呈指数级增长。手动优化这些电路变得不切实际。在大规模量子电路中优化纠缠分布对于提高量子传感器的灵敏度和效率至关重要。因此，本文提出将强化学习与张量网络仿真方法融合，用于优化高达60个量子比特的量子传感器电路。为了实现高效的仿真和可扩展性，文中采用了张量网络方法，特别是矩阵乘积态（MPS）表示法，而不是传统的态矢量或密度矩阵方法。研究表明，这种方法可以显著提高量子鱼信息（QFI）、纠缠熵，并大幅度减少电路深度和门操作数量。这些结果表明，结合量子机器学习和张量网络可以实现在实际限制下的复杂量子电路优化能力。", "innovation": "本文提出了一种将强化学习与张量网络仿真方法（矩阵乘积态MPS）结合的技术，用于优化大规模量子传感器电路。这种技术特别适用于高达60个量子比特的电路优化，通过采用张量网络方法而非传统的方法，实现了高效的模拟和可扩展性。强化学习代理能够学习重构电路以最大化量子鱼信息（QFI）和纠缠熵，同时减少门操作数和电路深度，实验结果表明该方法可以显著提高电路性能。", "conclusion": "本文的研究结果表明，结合量子机器学习和张量网络可以实现在实际限制下的复杂量子电路优化能力，为高性能量子传感器的发展提供了新的方法和技术支持，潜在影响包括提升了量子传感器的灵敏度和效率，适用于60个量子比特及以上的电路优化。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21285", "html_url": "https://arxiv.org/abs/2508.21285", "title": "对LLM的财务脑扫描", "title_en": "A Financial Brain Scan of the LLM", "authors": "Hui Chen,Antoine Didisheim,Luciano Somoza,Hanqing Tian", "background": "新兴的计算机技术使得对大规模语言模型（LLMs）进行‘脑扫描’成为可能，能够识别出引导它们推理的普通英语概念，并在保持其他因素不变的情况下引导它们。研究表明，这种方法可以将LLM生成的经济预测与情感、技术分析和时机等概念相关联，并计算出它们的重要性而不会降低性能。此外，这种方法还可以使模型更倾向于或避免风险、乐观或悲观，这允许研究者纠正或模拟偏见。该方法透明、轻量且可重复，适用于社会科学的实证研究。", "innovation": "该方法利用新兴技术对大规模语言模型进行‘脑扫描’，识别和引导模型的推理过程，将其生成的经济预测与情感、技术分析和时机等概念相关联，并能够调整模型的风险偏好，使其更加乐观或悲观，从而允许研究者纠正或模拟模型中的偏见。这种方法具有透明性、轻量化和可重复性，适用于实证研究。", "conclusion": "研究展示了利用新兴技术研究大规模语言模型的能力，可以将模型生成的经济预测与情感、技术分析和时机相关联，同时调整模型的风险偏好，该方法在不牺牲模型性能的前提下具有透明、轻量且可重复的特点，可应用于社会科学中的实证研究，以纠正或模拟模型中的偏见。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21340", "html_url": "https://arxiv.org/abs/2508.21340", "title": "DLGAN: 基于双层生成对抗网络的时间序列合成", "title_en": "DLGAN : Time Series Synthesis Based on Dual-Layer Generative Adversarial Networks", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "时间序列合成是确保时间序列数据安全流通的有效方法。现有的时间序列合成方法通常基于随机序列进行时间建模，生成目标序列，但往往难以保证生成时间序列中的时间依赖性。直接在随机序列上建模时间特征也使得精确捕捉原始时间序列的特征信息变得困难。", "innovation": "为了解决上述问题，本文提出了一种简单的有效生成模型——双层生成对抗网络(DLGAN)，该模型将时间序列生成过程分解为两个阶段：序列特征提取和序列重建。首先，这两个阶段形成一个完整的时间序列自动编码器，使模型能够在原始时间序列上进行监督学习，以确保重建过程可以恢复序列的时间依赖性。其次，使用生成式对抗网络(GAN)生成与真实时间序列特征向量对齐的合成特征向量，确保生成器能够从真实时间序列中捕捉到时间特征。广泛的实验证明了该模型在各种评估指标上的优越性。", "conclusion": "多项公开数据集上的实验结果表明，此模型在各种评估指标中表现出色，能够有效解决原始问题。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21334", "html_url": "https://arxiv.org/abs/2508.21334", "title": "公平阶梯：连接群体公平与个体公平", "title_en": "Stairway to Fairness: Connecting Group and Individual Fairness", "authors": "Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Falk Scholer,Christina Lioma", "background": "推荐系统（RSs）中的公平性通常被分为群体公平性和个体公平性两大类。然而，目前尚没有科学的理解这两种公平性之间的关系，因为对于这两种公平性，已有研究使用的评估指标或评估目标不同，这使得无法进行有效的比较。因此，目前还不清楚增强一种公平性是否会对另一种公平性产生影响。为此，本文通过全面比较适用于两种公平性的评估措施来研究这两种公平性的关系。实验结果在3个数据集上进行8轮测试，表明对群体高度公平的推荐可能对个体非常不公平。这一发现对希望提高系统公平性的RS从业者具有新颖而实用的价值。这一成果是通过公开的代码来实现的。", "innovation": "本文首次通过将适用于群体公平性和个体公平性的评估措施进行全面比较，探索了这两种公平性之间的关系。实验结果揭示了对群体高度公平的推荐可能对个体非常不公平，这一发现填补了领域内对这两种公平性之间关系缺乏科学理解的空白。这一研究成果对希望提高推荐系统公平性的从业者具有重要意义。", "conclusion": "推荐系统的高度群体公平性并不必然导致高度个体公平性。对群体高度公平的推荐可能对个体非常不公平。这一发现对提高推荐系统公平性的从业者具有重要意义。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21368", "html_url": "https://arxiv.org/abs/2508.21368", "title": "EconAgentic在DePIN市场中的应用：一种大型语言模型方法推动去中心化物理基础设施共享经济", "title_en": "EconAgentic in DePIN Markets: A Large Language Model Approach to the Sharing Economy of Decentralized Physical Infrastructure", "authors": "Yulin Liu,Mocca Schweitzer", "background": "去中心化物理基础设施（DePIN）市场正在通过基于代币的经济和治理智能合约的去中心化运营，革新共享经济。到2024年，DePIN项目市值已超过100亿美元，显示出其快速的增长。然而，这些市场的无监管状态和智能合约中自主部署的AI代理带来的风险，如低效和与人类价值观的潜在不一致，引发了担忧。", "innovation": "EconAgentic是一种大型语言模型（LLM）驱动的框架，旨在减轻这些挑战。研究集中在三个关键领域：1) 模型DePIN市场的动态演变；2) 评估利益相关者行动及其经济影响；3) 分析宏观指标以使市场结果与社会目标相一致。通过EconAgentic模拟AI代理对代币激励的响应、对基础设施的投资以及对市场条件的适应，对比AI驱动决策与人类启发式基准。结果显示，EconAgentic为理解DePIN市场的效率、包容性和稳定性提供了宝贵的洞察，有助于学术理解和实践改进。", "conclusion": "EconAgentic提供了关于DePIN市场的洞见，帮助学术界和实践者更好地设计和管理去中心化、代币化经济。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21330", "html_url": "https://arxiv.org/abs/2508.21330", "title": "Stage-Diff：基于扩散模型的阶段式长期时间序列生成", "title_en": "Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "生成模型已经在时间序列生成领域取得了成功。然而，处理长时期跨度、复杂长短期模式的时间序列时，生成任务变得更加具有挑战性。这类时间序列表现出长距离的时序依赖性，但其数据分布也会随着时间逐渐变化。找到长期依赖性和数据分布漂移之间的平衡是一项关键挑战。此外，长期时间序列中的不同特征序列之间存在更复杂的相互关系，捕捉这些序列内部和序列之间的关联性也是一项重要挑战。", "innovation": "本文提出了Stage-Diff，一种基于扩散模型的阶段式生成模型，用于长期时间序列生成。该模型通过阶段式的序列生成和阶段间信息传递，同时保留长期序列依赖性并适应数据分布的漂移。在每个阶段内部，该模型使用逐级的序列分解进行时间尺度上的通道独立建模；阶段间信息传递则采用多通道融合建模。这种方法结合了通道独立建模的稳健性和多通道建模的信息融合优势，以有效平衡长时序时间序列内部和序列间的依赖性。", "conclusion": "在多种真实数据集上的大量实验验证了Stage-Diff在长期时间序列生成任务中的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21246", "html_url": "https://arxiv.org/abs/2508.21246", "title": "HCQA: 综合经典-量子代理生成最优量子传感器电路", "title_en": "HCQA: Hybrid Classical-Quantum Agent for Generating Optimal Quantum Sensor Circuits", "authors": "Ahmad Alomari,Sathish A. P. Kumar", "background": "本文提出了一个基于深度强化学习的HCQA方法，用于设计最优量子传感器电路（QSCs），以解决复杂的量子物理问题。该方法通过结合量子信息处理技术，利用深度Q网络（DQN）进行学习和策略优化，并通过量子行动选择机制增强。", "innovation": "该工作提出了一种新的HCQA（Hybrid Classical-Quantum Agent），通过结合经典计算智能技术和量子计算策略，自动设计并生成具有最大化量子鱼信息量（QFI）和最小化电路层数的最优量子传感器电路。该方法特别强调通过量子电路创建纠缠量子态，特别是在量子状态估计和控制方面。", "conclusion": "在由两个量子比特和一系列Rx、Ry和S门组成的电路中，该HCQA方法在生成最优QSCs方面表现出了高效性，其QFI可达1。这项工作强调了AI驱动的学习与量子计算之间的协同作用，展示了智能代理如何自主发现提高传感和估计任务的最优量子电路设计。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21377", "html_url": "https://arxiv.org/abs/2508.21377", "title": "大型语言模型的挑战与应用：GPT和DeepSeek家族模型的比较", "title_en": "Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models", "authors": "Shubham Sharma,Sneha Tuli,Narendra Badam", "background": "大型语言模型（LLMs）正在跨行业重塑人工智能，但其开发和部署依然复杂。本文回顾了16个构建和使用LLMs的关键挑战，并分析了两种先进模型独特的应对策略，分别是OpenAI的闭源GPT-4o（2024年5月更新）和DeepSeek-V3-0324（2025年3月发布），一个大型开源专家混合模型。通过比较这两种模型，本文展示了闭源模型（强劲的安全性、细调的可靠性）与开源模型（效率、适应性）之间的权衡，并探讨了LLMs在不同领域的应用（从聊天机器人、编程工具到医疗保健和教育），突出哪些模型属性最适合每种应用场景。文章旨在帮助AI研究人员、开发人员和决策者理解当前LLM的能力、局限性和最佳实践。", "innovation": "本文通过比较闭源模型GPT-4o和开源模型DeepSeek-V3-0324，展示了闭源模型和开源模型之间的权衡。文章详细分析了16个构建和使用LLMs的关键挑战，并探讨了LLMs在不同领域的应用情况，帮助AI研究人员、开发人员和决策者更好地理解和选择适合的应用场景。", "conclusion": "本文旨在指导AI研究人员、开发人员和决策者理解当前大型语言模型的能力、局限性和最佳实践，通过比较GPT和DeepSeek家族模型，提供了重要的参考信息。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21380", "html_url": "https://arxiv.org/abs/2508.21380", "title": "棋类神经网络中的迭代推理", "title_en": "Iterative Inference in a Chess-Playing Neural Network", "authors": "Elias Sandmann,Sebastian Lapuschkin,Wojciech Samek", "background": "本文探讨了神经网络在构建其表示时是通过平滑、渐进的改进，还是通过更为复杂的计算过程。研究人员通过扩展logit镜像技术，分析了超人类国际象棋引擎Leela Chess Zero的策略网络，以研究这一问题。", "innovation": "研究通过使用扩展的logit镜像技术分析了Leela Chess Zero的策略网络，揭示了在层数上存在强烈的单调趋势，但在策略分布上却经常表现出非平滑的轨迹。文中提供了几个具体证据，包括早期发现但随后被舍弃的正确谜题解决方案、与最终输出相关性较差的移动排名以及直至网络后期才出现的高度策略分歧。这些发现与语言模型中通常观察到的平滑分布收敛形成了鲜明对比，这表明神经网络的内部机制可能比现有认知更为复杂和非线性。", "conclusion": "研究结果表明，神经网络在构建表示时不仅可能经历平滑、渐进的改进，还可能通过更为复杂的计算过程，不同于以往对语言模型分布收敛的观察。进一步探讨神经网络的复杂内部机制可能对理解其运作原理具有重要意义。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21382", "html_url": "https://arxiv.org/abs/2508.21382", "title": "正常性与图灵测试", "title_en": "Normality and the Turing Test", "authors": "Alexandre Kabbach", "background": "本文重新审视图灵测试，通过对“常态”概念的理解，探讨了图灵测试的关键问题，即它旨在测试人类平均智能而非卓越智能，以此表明能够成功通过图灵测试的机器必须表现出与人类平均智能相类似的行为，即会产生错误并展示出不完美的特征。此外，文中指出图灵测试是一种统计测试，涉及多个非专家仲裁者的判断，而非由单一的“平均人”做出决定，这一概念在图灵原始论文中有提及，但被误解或忽视了。因此，图灵讨论的“平均的人问话者”应该被理解为多个评判者的标准化汇总的数学抽象。", "innovation": "本文的主要创新在于通过对“常态”这一概念的重新解释，提出了一个新的视角来理解图灵测试。这一视角强调图灵测试评估的是机器的平均智能而非卓越智能，从而对图灵测试的评估标准和方法提出了新的认识，指出当前的大语言模型如ChatGPT等无法通过图灵测试的原因在于它们专注于卓越智能而非平均智能，它们更多体现的是所谓的“人工聪慧”，而非真正的“人工智能”。", "conclusion": "文章的结论是，图灵测试实质上是对人类智能的平均判断的测试。首先，文章认为大型语言模型如ChatGPT等不太可能通过图灵测试，因为它们针对的是人类的优秀智能而非平均智能，因此它们体现了所谓的“人工聪慧”而非真正的“人工智能”。其次，文章进一步指出，图灵测试的核心问题并不仅仅在于能否证明人类的思维可以归约为平均思维，这一问题超出了图灵测试本身，而是质疑了它所属的正常主义范式的概念基础。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21249", "html_url": "https://arxiv.org/abs/2508.21249", "title": "增强外部空气动力学代理建模的专家混合网络", "title_en": "A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics", "authors": "Mohammad Amin Nabian,Sanjay Choudhry", "background": "高保真CFD模拟的计算成本仍然是汽车设计和优化过程中的一个重大瓶颈。虽然基于机器学习的代理模型被视为加速气动预测的一种有前景的替代方案，但该领域呈现出多样化和快速进化的专业神经网络架构，没有单一模型展现出普遍的优越性。", "innovation": "本文提出了一种新颖的元学习框架，利用架构多样性作为优势。提出了一种混合专家（MoE）模型，使用专用的门控网络动态和优化地结合三个异构、最先进的代理模型预测：DoMINO（可分解的多尺度神经算子）；X-MeshGraphNet（可扩展的多尺度图神经网络）；和FigConvNet（因子化的隐式全局卷积网络）。门控网络学会一种空间变权重策略，基于其在预测表面压力和壁面剪切应力场方面的局部性能赋予每个专家可信度。为了防止模型崩溃并鼓励专家贡献平衡，将熵正则化项整合到训练损失函数中。整个系统在DrivAerML数据集上训练和验证，这是一个大规模的公共高保真CFD仿真汽车空气动力学基准数据集。定量结果表明，MoE模型在L-2预测误差方面取得了显著降低，不仅优于单一专家模型的集合平均值，还在所有评估的物理量中也优于最精确的单个专家模型。", "conclusion": "本文建立了MoE框架作为一种强有力且有效的方法，通过协同结合专业化架构的互补优势来创建更稳健和准确的复合代理模型。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21290", "html_url": "https://arxiv.org/abs/2508.21290", "title": "来自代码生成模型的高效代码嵌入", "title_en": "Efficient Code Embeddings from Code Generation Models", "authors": "Daria Kryvosheieva,Saba Sturua,Michael Günther,Scott Martens,Han Xiao", "background": "该研究旨在通过将自然语言查询转化为代码检索、技术问答和跨编程语言的语义相似代码片段识别等功能，解决开发人员面临的挑战。现有的代码嵌入模型通常依赖于专门的训练数据集和复杂的技术架构，使得模型构建过程较为复杂且成本高昂。", "innovation": "该研究采用了自动回归骨干模型，该模型在文本和代码数据上进行预训练，通过最后一字池化生成嵌入。这种创新方法不仅简化了模型构建过程，而且在相对较小的模型规模下仍能取得最先进的性能。", "conclusion": "研究表明，尽管模型规模较小，所提出的方法在代码嵌入模型构建方面仍取得了最先进的性能，验证了使用自动回归骨干模型进行代码嵌入的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21378", "html_url": "https://arxiv.org/abs/2508.21378", "title": "RoboInspector: 揭示LLM驱动的机器人操作中策略代码的不可靠性", "title_en": "RoboInspector: Unveiling the Unreliability of Policy Code for LLM-enabled Robotic Manipulation", "authors": "Chenduo Ying,Linkang Du,Peng Cheng,Yuanchao Shu", "background": "大型语言模型（LLMs）展示了在推理和代码生成方面的能力，使得只需一条指令就能启动机器人操作。这些模型通过生成控制机器人的策略代码来处理各种任务。然而，由于实际任务的多样性和用户指令的复杂性，实现可靠的策略代码生成仍然具有挑战性。在实践中，不同的用户可能为同一任务提供不同的指令，这可能导致策略代码生成的不稳定性。", "innovation": "介绍了RoboInspector，一种管道，用于从两个方面揭示和表征LLM驱动的机器人操作中策略代码的不可靠性：操作任务的复杂性和指令的粒度。通过168种不同任务、指令和LLM的组合实验，在两个突出框架中进行了全面实验，并识别了导致操作失败的四种主要不可靠行为，对其进行了详细的刻画和分析，并提供了一个基于失败策略代码反馈的改进方法，提高了LLM驱动的机器人操作中策略代码生成的可靠性，最多可提高35%。", "conclusion": "RoboInspector通过识别四种主要的不可靠行为，为减少策略代码生成的不确定性提供了见解，还提出了一种改进方法，提高了策略代码生成的可靠性，并已在模拟和真实环境中进行了评估。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21389", "html_url": "https://arxiv.org/abs/2508.21389", "title": "AllSummedUp：一个用于比较摘要评估指标的开源框架", "title_en": "AllSummedUp: un framework open-source pour comparer les metriques d'evaluation de resume", "authors": "Tanguy Herserant,Vincent Guigue", "background": "本文探讨了自动文本摘要评估中的可重复性挑战。通过在六种代表性度量标准（包括经典方法ROUGE以及最近的基于LLM的方法G-Eval和SEval-Ex）上的实验，发现了文献中报告的性能与实验证据中的差异。此外，本文还强调了依赖于LLM进行评估存在的关键问题，如其随机性、技术依赖性和有限的可重复性。", "innovation": "本文提出了一个统一的开源框架，应用于SummEval数据集，用于支持评估指标的公平透明比较。研究表明，与人类判断高度一致的指标往往是计算密集型且稳定性较差的。", "conclusion": "本文不仅进行了比较分析，还突出了使用LLM进行评估的关键顾虑，并建议采用更稳健的评估协议，包括详尽的文档和方法标准化，以确保自动摘要评估的可靠性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21296", "html_url": "https://arxiv.org/abs/2508.21296", "title": "MyGO: 记忆产生式离线巩固方法在终身学习系统中的应用", "title_en": "MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems", "authors": "Shihao Ji,Zihui Song", "background": "终身学习旨在开发能够在任务序列中从新任务中获取知识而不忘记之前学习内容的模型。现有方法通常依赖于存储以前任务的数据样本（经验重放）或使用复杂的正则化项保护学习权重。然而，这些方法面临数据隐私、存储限制以及任务差异性导致的性能退化等挑战。", "innovation": "提出了MyGO（Memory Yielding Generative Offline-consolidation）框架，这是一种受到生物清醒-睡眠周期启发的终身学习方法。在“清醒”阶段，系统快速学习新任务并训练一个紧凑的生成模型（生成记忆，G-mem）来捕捉其数据分布。在“睡眠”阶段，系统进入离线状态，使用所有学到的G-mem模型生成伪数据（“梦境”）并通过知识蒸馏将新旧知识合并到核心特征提取器中，从而避免存储任何原始数据，只保留紧凑的生成模型，这在隐私和存储效率方面具有显著优势。", "conclusion": "我们在计算机视觉（Split-MNIST）和自然语言处理（Split-AG News）基准上评估了MyGO，与顺序微调基线进行比较。结果表明，MyGO明显减轻了灾难性遗忘并保持了在任务上的高平均准确率，证明了该框架的有效性和跨界适用性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21407", "html_url": "https://arxiv.org/abs/2508.21407", "title": "DRASP: 双分辨率注意统计池化框架用于自动MOS预测", "title_en": "DRASP: A Dual-Resolution Attentive Statistics Pooling Framework for Automatic MOS Prediction", "authors": "Cheng-Yeh Yang,Kuan-Tang Huang,Chien-Chun Wang,Hung-Shin Lee,Hsin-Min Wang,Berlin Chen", "background": "当前的MOS预测主要依赖于一个池化机制，这种机制将变化长度的音频特征转化为紧凑的固定大小表示，有效地编码语音质量。现有的池化方法通常在单一粒度上操作，要么侧重于全面的全局视角，要么专注于细节的帧级分析，可能忽视了互补的感知洞察。", "innovation": "本文引入了双分辨率注意统计池化（DRASP）框架，该框架结合了粗粒度的全局统计总结和细粒度的注意感知分析。DRASP框架具有双视图架构，能够同时捕捉宏观结构上下文和显著局部细节，从而使模型能够构建更全面和稳健的表示。", "conclusion": "广泛的实验验证了所提出框架的有效性和强大的泛化能力。该框架在MusicEval和AES-Natural等多个数据集中的一致性表现优于各种基线方法，包括基于CLAP的模型和AudioBox-Aesthetics；相较广泛使用的平均池化方法，系统级斯皮尔曼等级相关系数（SRCC）提高了10.39%。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21353", "html_url": "https://arxiv.org/abs/2508.21353", "title": "自适应重尾随机梯度下降", "title_en": "Adaptive Heavy-Tailed Stochastic Gradient Descent", "authors": "Bodu Gong,Gustavo Enrique Batista,Pierre Lafaye de Micheaux", "background": "在大规模神经网络模型中，优化算法往往由于对训练损失的过度依赖而在泛化方面遇到困难。机器学习领域普遍认为，广阔的盆地（损失增加逐渐的局部最小值周围区域）能够通过提供对输入数据或模型参数微小变化的更大稳定性来促进更好的泛化。相比之下，尖锐的最小值通常是敏感且不稳定的。受两种关键的经验观察结果——随机梯度下降固有的重尾梯度噪声分布和神经网络训练中的边缘稳定性现象（在曲率增长一段时间后最终达到平台期）的启发，我们提出了自适应重尾随机梯度下降（AHTSGD）。该算法在训练初期注入更重尾的噪声以增强探索性，并随着尖锐度的稳定逐渐过渡到更轻尾的噪声。", "innovation": "AHTSGD首次根据边缘稳定性现象调整注入噪声的特性。在训练的不同阶段，AHTSGD能够动态适应损失景观的尖锐度，从而加速收敛到广阔的盆地。AHTSGD在MNIST和CIFAR-10等基准测试上优于SGD和其他基于噪声的方法，并在SVHN等噪声数据集上表现出显著优势。它还能够从不良初始化中加速早期训练，并在干净和噪声环境中提高泛化能力，同时对学习率选择具有鲁棒性。", "conclusion": "AHTSGD通过动态适应损失景观的尖锐度，提前且有效促进网络收敛到广阔的盆地。与其他基线方法相比，AHTSGD在多个基准数据集上表现优异，特别是在具有噪声的环境中仍然保持鲁棒性，显著提高了模型的泛化能力。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21468", "html_url": "https://arxiv.org/abs/2508.21468", "title": "通过贝叶斯流网络和梯度集成实现结构基础药物设计中的可控3D分子生成", "title_en": "Controllable 3D Molecular Generation for Structure-Based Drug Design Through Bayesian Flow Networks and Gradient Integration", "authors": "Seungyeon Choi,Hwanhee Kim,Chihyun Park,Dahyeon Lee,Seungyong Lee,Yoonju Kim,Hyoungjoon Park,Sein Kwon,Youngwan Jo,Sanghyun Park", "background": "最近，结构基础药物设计（SBDD）中的基于生成模型的3D分子生成得到了快速发展，这些模型主要通过与靶蛋白结合亲和力来评估性能。然而，实际药物发现还要求高结合亲和力、合成可行性以及选择性等关键特性，而这些特性在之前的评估中大多被忽视了。", "innovation": "我们识别了传统基于扩散的生成模型在有效引导分子生成多样化药理特性方面的根本局限性。提出了CByG框架，该框架扩展了贝叶斯流网络，成为一个基于梯度的条件生成模型，能够稳健地整合特性特定的引导。此外，我们还引入了一种全面的评估方案，结合实用的基准来评估结合亲和力、合成可行性和选择性，弥补了传统评估方法的局限性。", "conclusion": "详尽的实验表明，我们提出的CByG框架在多个关键评估指标上显著优于基准模型，突显了其在实际药物发现应用中的有效性和实用性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21430", "html_url": "https://arxiv.org/abs/2508.21430", "title": "Med-RewardBench: 评估医疗多模态大型语言模型奖励模型和评判者的标准", "title_en": "Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models", "authors": "Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen", "background": "多模态大型语言模型（MLLMs）在医疗领域具有巨大潜力，包括疾病诊断和临床决策。然而，这些任务需要高度准确、上下文敏感和专业对齐的响应，因此可靠的奖励模型和评判者至关重要。尽管如此，医疗奖励模型（MRMs）和评判者的研究仍然不足，没有专门针对临床需求的基准。现有的基准主要关注一般MMLM的能力或作为问题求解者进行评估，忽略了诸如诊断准确性和临床相关性等关键评估维度。针对上述问题，作者提出了Med-RewardBench，这是第一个专门设计来评估MRMs和评判者的基准，特别是在医疗场景中。该基准包含超过1000个由专家注释的跨13个器官系统和8个临床部门的多模态数据集。", "innovation": "Med-RewardBench 是首个专为评估医疗情景中的 MRM 和评判者设计的基准。它通过包含来自13个器官系统和8个临床部门的1026个专家注释案例，解决了现有基准缺乏临床关键维度的问题。此外，该研究还评估了32个最先进的MMLM模型，展示了显著的挑战和改进空间，并开发了基于微调的基本模型，从而进一步提高了性能。", "conclusion": "研究结果表明，通过Med-RewardBench评估的MMLM模型存在重大挑战，特别是在与专家判断对齐方面。此外，通过微调开发的基线模型显现出显著的表现提升。这表明Med-RewardBench对于评估和改进MMLM在医疗领域的表现有着重要作用。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21420", "html_url": "https://arxiv.org/abs/2508.21420", "title": "基于蓄水库计算的低成本网络状态基准测试方法", "title_en": "Benchmarking the State of Networks with a Low-Cost Method Based on Reservoir Computing", "authors": "Felix Simon Reimers,Carl-Hendrik Peters,Stefano Nichele", "background": "研究利用挪威移动网络使用的数据，展示了一种非侵入性和低成本的方法来监控通信和移动网络的状态。这种方法将网络数据转换为蓄水库计算框架中的模型，并通过代理任务衡量模型的性能。该研究通过实验展示了这些代理任务的性能与网络状态之间的关系。这种方法的主要优势在于它利用了现成的数据集，并借助蓄水库计算框架实现了低成本且几乎无偏的方法。移动网络数据以匿名聚合的形式存在，每日有多次快照，可以像加权网络一样处理。蓄水库计算允许使用加权但未训练的网络作为机器学习工具。网络初始化为所谓的回声状态网络（ESN），将输入信号投影到更高维度的空间上，其中一个训练层在其上操作。与每个权重都需要训练的深度神经网络相比，这种方法消耗的能源更少。研究所使用的任务灵感来自神经科学，训练ESN模型来解决这些问题。然后展示了性能如何依赖于某些网络配置，以及当扰动网络时性能明显下降的情况。这项工作作为一种概念验证具有重要意义，我们认为它可以进一步用于近实时监控，并识别移动通信网络及交通网络的潜在弱点。", "innovation": "该研究提出了一种利用移动网络使用数据的非侵入性和低成本的方法来监控通信和移动网络的状态。该方法利用蓄水库计算框架，将网络数据转换为蓄水库计算模型。通过实验展示了代理任务的性能与网络状态之间的关系。这种方法的一个关键优势是它使用现成的数据集，成本低且几乎无偏。", "conclusion": "尽管这项工作证明了该方法的概念，但认为这种基于蓄水库计算的方法可以升级为用于近实时监控移动通信网络及交通网络状态，以及识别网络中的潜在弱点。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21460", "html_url": "https://arxiv.org/abs/2508.21460", "title": "基于扩散的多模态协同兴趣网络用于点击率预测", "title_en": "Diffusion-based Multi-modal Synergy Interest Network for Click-through Rate Prediction", "authors": "Xiaoxi Cui,Weihai Lu,Yu Tong,Yiheng Li,Zhejun Zhao", "background": "在点击率预测中，点击率预测用于建模用户的兴趣。然而，大多数现有的点击率预测方法主要基于ID模式。因此，它们无法全面建模用户的多模态偏好。为了改进这一现状，有必要引入多模态点击率预测。尽管直接应用现有的多模态融合方法到点击率预测模型中听上去很有吸引力，但这些方法在分散不同模态之间的共同性和独特性方面效果不佳，也没有考虑模态间的协同效应，未能建模模态之间的复杂互动。因此，作者对该问题进行了深入分析并提出了基于扩散的多模态协同兴趣网络框架（Diff-MSIN）以解决这些问题，从而提出了三项创新模块：多模态特征增强模块（MFE）、协同关系捕捉模块（SRC），以及特征动态适应性融合模块（FDAF），用于点击率预测中的多模态推荐系统改进", "innovation": "该框架引入了三项创新模块：多模态特征增强（MFE）模块、协同关系捕捉（SRC）模块和特征动态适应性融合（FDAF）模块。MFE模块和SRC模块提取不同模态之间的协同、共性和独特信息，有效增强模态的表示能力，提高融合的整体质量。为鼓励不同特征之间的差异性，设计了知识解耦方法。FDAF模块专注于捕捉用户偏好并减少融合噪声。", "conclusion": "为了验证该Diff-MSIN框架的有效性，作者使用了Rec-Tmall和三个Amazon数据集开展了广泛的实验。结果表明，与基线相比，作者的方法至少提高了1.67%，展示了其在多模态推荐系统中的潜在改进能力。作者的代码可在以下链接获取：this https URL。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21433", "html_url": "https://arxiv.org/abs/2508.21433", "title": "复杂性陷阱：简单观察值遮掩与LLM总结一样有效且高效于代理上下文管理", "title_en": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "authors": "Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov", "background": "文章背景介绍了大型语言模型（LLM）代理通过迭代推理、探索和工具使用解决复杂任务的过程，但这一过程会导致较长且昂贵的历史上下文。目前如OpenHands或Cursor等先进软件工程（SE）代理使用基于LLM的总结来应对这一问题，但不清楚增加复杂性是否能带来实际的性能提升，还是简单地省略旧观测更有优势。为了研究这个问题，文章在SWE-agent上进行了一项系统性比较，评估了裸代理和基于观察值遮掩或LLM总结策略在SWE-bench（一个验证平台）上表现差异，通过五个不同的模型配置进行评估。", "innovation": "文章的创新在于系统地比较了裸代理策略和基于观察值遮掩或LLM总结策略在软件工程代理中上下文管理的有效性和效率，并发现简单遮掩策略在成本仅为裸代理一半的情况下，仍能与LLM总结策略具有竞争力甚至优于后者。特别是在使用Qwen3-Coder 480B模型时，遮掩策略不仅提高了解题成功率，而且成本更低。文章的研究提供了在软件工程代理上下文管理中，最有效且高效的策略可能是最简单的一种的见解。此外，文章还释放了代码和数据以保证研究结果的可复现实验。", "conclusion": "研究结论表明，在SWE-agent和SWE-bench平台上，最有效且高效的上下文管理系统可能是最简单的遮掩策略。这种策略能够在成本显著减少的同时，仍然或超越基于LLM的总结策略的性能。文章的研究结果为软件工程代理的上下文管理提供了一个新的视角，并且为后续研究提供了可复现实验的基础。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21302", "html_url": "https://arxiv.org/abs/2508.21302", "title": "Locus: 自主合成谓词用于定向 fuzzing", "title_en": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "authors": "Jie Zhu,Chihao Shen,Ziyang Li,Jiahao Yu,Yizheng Chen,Kexin Pei", "background": "定向 fuzzing 目的是找到能使程序进入指定目标状态的输入。这些技术广泛应用于调试系统崩溃、验证报告的错误和生成利用潜在漏洞的攻击性代码。然而，由于目标状态通常嵌套在程序之中，而潜在的程序输入空间辽阔，因此这项任务具有固有的挑战性。现有的方法依赖分支距离或手动指定的约束来指导搜索，但仅靠分支信息往往不足以精确地描述向目标状态推进的进展，而手动指定的约束通常针对特定类型的错误，难以推广到多样化的目标状态和程序。", "innovation": "Locus 提出了一个新颖的框架以提高定向 fuzzing 的效率。其核心洞察是合成立方体来捕捉 fuzzing 进度，并以语义上有意义的中间状态形式表示，作为达到目标状态的里程碑。当用于模糊测试程序时，它们可以拒绝不可能达到目标状态的执行，并提供额外的覆盖率指导。为了自动化这一任务并适应多样化程序，Locus 采用了具代表性的框架和程序分析工具来合成和迭代细化候选立方体，同时通过符号执行确保这些立方体严格放松目标状态以防止虚假拒绝。", "conclusion": "Locus 显著提高了八种最先进的 fuzzers 发现真实漏洞的效率，平均加速 41.6 倍。迄今为止，Locus 已发现八个以前未修复的错误，其中一个已经被承认提供草案补丁。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21496", "html_url": "https://arxiv.org/abs/2508.21496", "title": "ELV-Halluc: 在长视频理解中基准测试语义聚合幻觉", "title_en": "ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding", "authors": "Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu", "background": "视频多模态大语言模型（Video-MLLMs）在视频理解方面取得了显著进展，但仍然容易产生与视频输入不一致或无关的幻觉内容。以往关于视频幻觉的基准测试主要集中在短视频上，并且主要归因于语言先验、缺失帧或视觉编码器引入的语言-视觉偏差。然而，这些因素并不能完全解释长视频中幻觉的原因。有时模型会产生语义正确的输出，但整体上是错误的，这被称为语义聚合幻觉（SAH），它是由于将帧级别的语义聚合到事件级别的语义组的过程中产生。由于长视频中的语义复杂性增加，这使得这种情况变得更加关键。", "innovation": "引入了首个专注于长视频幻觉的基准ELV-Halluc，系统地研究了语义聚合幻觉（SAH）。实验确认了SAH的存在，并表明其随语义复杂性增加。此外，发现模型更容易在快速变化的语义上产生SAH，并讨论了潜在的缓解方法，表明位置编码策略有助于减轻SAH，并采用了DPO策略进一步提高模型区分事件内外语义的能力。", "conclusion": "我们创建了一个包含8K对抗数据对的专门数据集，并在ELV-Halluc和Video-MME上实现了提高，其中包括SAH比率的显著下降，为27.7%。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21476", "html_url": "https://arxiv.org/abs/2508.21476", "title": "小语言模型中的创意写作激发：LLM-as-a-Judge与多智能体改进奖励的对比", "title_en": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards", "authors": "Xiaolong Wei,Bo Lu,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin", "background": "大型语言模型（LLMs）在创意写作方面表现出色，但其巨大的计算需求限制了其广泛应用。相比之下，小语言模型（SLMs）增强方法提供了一种有前景的替代方案，但现有的方法如有监督微调（SFT）难以产生新颖的内容，强化学习从人类反馈中学习（RLHF）则代价高昂。针对以上情况，本文探索了一种强化学习从AI反馈（RLAIF）框架下的两种不同的人工智能驱动奖励策略，旨在激发一个含有70亿参数的SLM的创意写作能力，尤其是在生成中文问候语方面。", "innovation": "本文提出了两种新的AI驱动的奖励策略，它们分别采用了多智能体拒绝采样框架训练的偏好数据和一种基于原则指导的LLM评判者，后者利用对抗训练方案和反思机制优化奖励函数，直接提供奖励反馈。与基准方法相比，这两种方法显著提高了创意输出的质量，特别是基于原则指导的LLM评判者策略还表现出更高的训练效率，并减少了对人工标注数据的依赖，为创意SLMs的发展指明了更为高效且可扩展的道路。", "conclusion": "研究结果表明，通过RLAIF框架中的两种AI驱动奖励策略，小语言模型能够生成高质量的创意内容，尤其是基于原则指导的LLM评判者策略在生成质量和训练效率上均优于基准方法，同时还减少了对人类标注数据的依赖，为小语言模型的创意写作提供了更具前景的发展路径。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21393", "html_url": "https://arxiv.org/abs/2508.21393", "title": "zkLoRA: 使用零知识证明实现可验证安全的大语言模型微调", "title_en": "zkLoRA: Fine-Tuning Large Language Models with Verifiable Security via Zero-Knowledge Proofs", "authors": "Guofu Liao,Taotao Wang,Shengli Zhang,Jiqun Zhang,Shi Long,Dacheng Tao", "background": "微调大型语言模型（LLMs）对于适应特定任务至关重要，但这种操作耗费大量计算资源，并引发正确性和隐私方面的担忧，尤其是在非受信环境中。尽管低秩适应（LoRA）等参数高效方法显著减少了资源需求，但在零知识约束下确保微调的安全性和可验证性仍然存在挑战。", "innovation": "提出了zkLoRA，这是首个将LoRA微调与零知识证明（ZKPs）集成的框架，实现了可证明的安全性和正确性。zkLoRA使用高级加密技术，如查找论证、和积协议和多项式承诺，来验证Transformer架构中的算术和非算术运算。该框架提供了LoRA微调过程中前向传播、后向传播以及参数更新的端到端可验证性，同时保护模型参数和训练数据的隐私。通过基于GPU的实现，zkLoRA通过在开源LLM如LLaMA上的实验验证证明了其实用性和效率，该LLM具有130亿参数的能力。", "conclusion": "通过参数高效微调与ZKPs的结合，zkLoRA解决了关键的难题，使得在敏感或非受信环境中安全可靠地部署LLM成为可能。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21542", "html_url": "https://arxiv.org/abs/2508.21542", "title": "单张图像中通过去噪扩散模型完成高保真高多样性的高分辨率局部体素重建", "title_en": "Complete Gaussian Splats from a Single Image with Denoising Diffusion Models", "authors": "Ziwei Liao,Mohamed Sayed,Steven L. Waslander,Sara Vicente,Daniyar Turmukhambetov,Michael Firman", "background": "传统的高斯体图重建方法通常需要密集的场景观测，并且无法重建被遮挡和未观测到的区域。完成场景未观察到的表面是一项具有挑战性的任务，因为可能的表面存在模糊性。传统的方法通常使用基于回归的形式来预测遮挡和视锥外表面的单一“模式”，导致结果模糊、不合理，并不能捕获多种可能的解释。因此，这些方法经常只能部分解决这个问题，聚焦于从背景隔离的物体、只重构可见表面，或者无法从输入视图向外推断。", "innovation": "本文提出了一种潜在扩散模型，可以从单张图像中生成具有高保真度和多样性的完整3D场景模型，包括被遮挡的部分。这种方法不同于传统的回归形式预测单一“模式”的方法，而是采用生成的形式来学习单张输入图像条件下的3D高斯体图的分布。为了应对缺乏真实训练数据的问题，提出了一种变分自重构器，不需要真实标签，仅从2D图像中自我监督学习潜在空间，通过扩散模型训练来充分利用。", "conclusion": "该方法能够生成高质量的360度渲染图，能够完成遮挡表面，产生忠实的重建和多样的样本。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21435", "html_url": "https://arxiv.org/abs/2508.21435", "title": "MedShift：X射线领域适应的隐式条件传输", "title_en": "MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation", "authors": "Francisco Caetano,Christiaan Viviers,Peter H.H. de With,Fons van der Sommen", "background": "合成医疗数据可为训练稳健模型提供一种可扩展的解决方案，但其在实际临床场景中的普适性受到显著领域差距的限制。本篇论文针对合成与真实头颅X光图像之间的跨领域转换挑战，特别是衰减行为、噪声特性和软组织表示的差异。现有方法要么需要基于特定领域的训练，要么依赖配对数据，这限制了模型的通用性和适应性。", "innovation": "本文提出了一种基于流匹配和薛定谔桥的统一条件生成模型——MedShift，能够实现多领域间的高保真、无配对图像转换。与以往需要特定领域训练或依赖配对数据的方法不同，MedShift能够在训练过程中学习到领域无关的共享潜在空间，从而支持在训练过程中遇到的任意领域对之间的无缝转换。为了验证领域转换模型的表现，本文还创建了一个新的数据集X-DigiSkull，其中包括不同辐射剂量下对齐的合成与真实头颅X光图像。实验结果表明，尽管相比于基于扩散的方法，MedShift在模型规模上较小，但在感知保真度和结构一致性方面却显示出较强的表现，并且可以在推理过程中灵活调整，使其成为医疗影像领域适应中的可扩展和普适性解决方案。", "conclusion": "MedShift 这一方法能够以较小的模型规模提供强大的性能，并且在推理时具有灵活性，能够优先考虑感知保真度或结构一致性，从而使它成为一个可扩展且普适的医疗影像领域适应解决方案。整个代码和数据集可以在指定的网站上获取。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21547", "html_url": "https://arxiv.org/abs/2508.21547", "title": "真正需要哪些数据？推荐系统中推理数据最小化可行性的研究", "title_en": "What Data is Really Necessary? A Feasibility Study of Inference Data Minimization for Recommender Systems", "authors": "Jens Leysen,Marco Favier,Bart Goethals", "background": "数据最小化是一个法律原则，要求个人数据处理仅限于实现特定目的所必需的信息。对于依赖大量个人数据的推荐系统来说，实现这一原则是一个重大挑战。本研究旨在探讨如何在不牺牲性能的前提下，减少推荐系统的隐性反馈推理数据。", "innovation": "提出了一个新颖的问题表述方法，分析了各种最小化技术，并研究了影响其有效性的关键因素。研究表明，可以在技术上显著减少推理数据，同时不会显著影响性能。然而，其实用性高度依赖于技术设置（如性能目标、模型选择）和用户特征（如历史量、偏好复杂性）。", "conclusion": "虽然证明了数据最小化在技术上是可行的，但其实用性受到技术环境和用户因素的影响，使得制定具有普遍性的数据‘必要性’标准面临困难。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21566", "html_url": "https://arxiv.org/abs/2508.21566", "title": "NSPDI-SNN：基于非线性突触修剪和树突集成的高效轻量级SNN", "title_en": "NSPDI-SNN: An efficient lightweight SNN based on nonlinear synaptic pruning and dendritic integration", "authors": "Wuque Cai,Hongze Sun,Jiayi He,Qianqian Liao,Yunliang Zang,Duo Chen,Dezhong Yao,Daqing Guo", "background": "人工神经网络（SNN）基于模拟生物神经元，近年来在人工智能技术研究中引起了广泛关注。生物神经元的树突具有高效的信息处理能力和计算能力，但SNN的神经元结构通常比较简单，难以匹配复杂的树突结构。", "innovation": "该研究提出了一个基于非线性突触修剪和树突集成的高效轻量级SNN方法（NSPDI-SNN）。引入了非线性树突集成（NDI），以改善神经元时空信息的表示。同时，该研究构建了一个新的灵活的非线性突触修剪（NSP）方法，以实现SNN的高稀疏度。实验表明NSPDI-SNN在各任务中能够保持高稀疏度并具有最少的性能退化，特别是在三个事件流数据集上的表现最佳。", "conclusion": "研究表明，生物神经元的复杂结构和非线性计算提供了开发高效SNN方法的有希望的方法。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21550", "html_url": "https://arxiv.org/abs/2508.21550", "title": "EZ-Sort: 通过零样本CLIP先序和人工在环排序的高效成对比较", "title_en": "EZ-Sort: Efficient Pairwise Comparison via Zero-Shot CLIP-Based Pre-Ordering and Human-in-the-Loop Sorting", "authors": "Yujin Park,Haejun Chung,Ikbeom Jang", "background": "在主观或难以标注的任务中，成对比较通常优于绝对评分或排序分类，因为它提高了可靠性。然而，全面的比较需要大量标注（O(n^2)）。近期工作通过使用排序算法积极采样成对比较大大减少了标注负担（O(n log n)）。作者进一步通过（1）利用Contrastive Language-Image Pre-training (CLIP) 模型分层进行零样本先序排序和（2）用自动化比较取代简单的人类直接比较来提高标注效率。验证结果显示，相较于全面的成对比较，EZ-Sort 缩减了90.5% 的人工标注成本，相较于先前工作减少了19.8% 的成本（当n=100时），并且在保持或提高评人间一致性方面有所改进。", "innovation": "1. 利用CLIP模型进行零样本先序排序以预排序项目。2. 使用自动化比较代替容易的人类直接比较。3. 通过不确定性的引导，在人工在环排序中应用合并排序法来进一步提高标注效率。", "conclusion": "将CLIP先验信息与不确定性感知采样相结合可以实现高效的、可扩展的成对排名解决方案。相比于全面的成对比较，EZ-Sort在标注效率和一致性方面都有显著提升。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21559", "html_url": "https://arxiv.org/abs/2508.21559", "title": "物理知情神经网络：智能电网代理的局限性研究", "title_en": "Limitations of Physics-Informed Neural Networks: a Study on Smart Grid Surrogation", "authors": "Julen Cestero,Carmine Delle Femine,Kenji S. Muro,Marco Quartulli,Marcello Restelli", "background": "物理知情神经网络(PINNs)通过将物理法则直接融入学习框架中，为智能电网建模提供了变革性的方法，解决了传统数据驱动方法中数据稀缺性和物理一致性的重要挑战。本文通过三个关键实验（插值、交叉验证、轨迹预测）将PINNs作为智能电网动态的代理模型进行评估，比较其性能与XGBoost、随机森林和线性回归模型。", "innovation": "本文展示了通过物理基础损失函数训练PINNs（强制电力平衡、操作约束和电网稳定性），证明了其在泛化能力上的优越性，相较于数据驱动模型在误差减少方面表现更佳。特别是在动态电网操作中，PINNs保持较低的MAE，可靠地捕捉状态过渡，在随机和专家驱动控制场景中表现稳定，而传统模型表现出不可靠的表现。", "conclusion": "本文的研究结果表明PINNs是智能电网替代方法的一个范式变革工具，实现了数据驱动灵活性与第一原理严谨性的结合，对于即时电网控制和可扩展数字双胞胎的进步具有重要意义。强调在关键能源系统中使用物理感知架构的必要性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21513", "html_url": "https://arxiv.org/abs/2508.21513", "title": "基于图神经网络的SAT求解器学习的难度：图里奇曲率的作用", "title_en": "On the Hardness of Learning GNN-based SAT Solvers: The Role of Graph Ricci Curvature", "authors": "Geri Skenderi", "background": "Graph Neural Networks (GNNs) 已经显示出在解决布尔可满足性问题（SATs）方面的潜力，尤其是通过操作逻辑公式的图表示。然而，它们在处理更难的实例时性能急剧下降，这引发了它们是否受到根本性架构限制的问题。", "innovation": "通过图里奇曲率（Graph Ricci Curvature）提供了一个几何解释。证明了从随机k-SAT公式中获取的双分图本质上是负曲率的，并且随着实例难度的增加，这种曲率会减小。基于这些发现，表明GNN-基于的SAT求解器会受到过挤压（oversquashing）现象的影响，从而导致长期依赖关系无法压缩到固定长度的表示中。实验验证了这些观点，并证实了曲率不仅是问题复杂性的强指标，还可以用于预测性能。", "conclusion": "我们的发现在现有求解器的设计原理中建立了联系，并提出了未来研究的有希望的方向。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21482", "html_url": "https://arxiv.org/abs/2508.21482", "title": "HSFN: 基于层次聚类选择的虚假新闻检测异质化集成", "title_en": "HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble", "authors": "Sara B. Coutinho,Rafael M.O. Cruz,Francimaria R. S. Nascimento,George D. C. Cavalcanti", "background": "心理偏见，如确认偏见，使个人特别容易相信和传播社交媒体上的假新闻，这对公共健康和政治等领域产生了重大影响。机器学习基于的事实验证系统已被广泛研究以减轻这种问题。其中，集成方法特别有效，通过组合多个分类器以改善鲁棒性。然而，其性能高度依赖于构成分类器的多样性——选择真正多样化的模型仍然是一个关键挑战，尤其是在模型倾向于学习冗余模式时。", "innovation": "本文提出了一种新颖的自动分类器选择方法，该方法优先考虑多样性及性能。该方法首先计算分类器之间的成对多样性，并通过层次聚类将它们组织成不同粒度的组。然后通过层次选择探索这些层次，选择每个层次上的代表不同池间多样性的分类器池。从这些池中确定最多样化的池并用于集成构建。选择过程结合了反映每个分类器性能的评价指标，以确保集成也有良好的泛化能力。", "conclusion": "我们使用来自不同应用领域且具有不同类别的6个数据集中的40个异构分类器进行实验，将方法与肘部启发式算法和最先进的基线进行比较。结果显示，我们的方法在两个数据集上获得了最高的准确性。详细实现信息可以在项目的git仓库中找到：this https URL"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21587", "html_url": "https://arxiv.org/abs/2508.21587", "title": "当前文本匿名化趋势和最新进展综述", "title_en": "A Survey on Current Trends and Recent Advances in Text Anonymization", "authors": "Tobias Deußer,Lorenz Sparrenberg,Armin Berger,Max Hahnbück,Christian Bauckhage,Rafet Sifa", "background": "随着各种领域中包含敏感个人信息的文本数据激增，需要强大的匿名化技术来保护隐私并遵守法规，同时保持数据对未来各种关键任务的可用性。", "innovation": "文章综述了文本匿名化技术的最新趋势，包括基础方法和命名实体识别的技术，探讨了大型语言模型在匿名化和去匿名化中的双重角色，并深入研究了在医疗、法律、金融和教育等关键领域的特定挑战和解决方案。文章还涵盖了使用形式化隐私模型和风险管理框架的先进方法，以及作者匿名化这一专门子领域的研究。文章进一步评审了评估框架、全面指标、基准和实际部署匿名化解决方案的工具。", "conclusion": "综述了当前的知识，指出了新兴趋势和持续存在的挑战，包括隐私-效用权衡的演变、准标识符的处理需求以及大型语言模型能力的影响，并旨在为该领域的研究人员和从业人员指明未来的研究方向。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为什么到单词就为止？通过行级OCR揭示更大的图景", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统的光学字符识别(OCR)技术将每个字符分割开来进行识别，这使得他们容易在字符分割中出错，并且缺乏上下文，无法利用语言模型。近年来，序列到序列（Seq2Seq）翻译的进步使现代技术能够首先检测单词，然后输入一个单词再由模型直接输出完整的单词，以字符序列的形式。这种方法更好地利用了语言模型，并绕过了容易出错的字符分割步骤。然而，这种转变将准确性的瓶颈转移到了单词分割上。", "innovation": "本文提出了一种自然且逻辑的进展，从单词级别的OCR发展到行级别的OCR。该提案能够绕过单词检测中的错误，并通过提供更大的句子上下文来更好地利用语言模型。我们展示，提出的技术不仅提高了OCR的准确性和效率，而且持续改进的大语言模型也有望利用这些进展。", "conclusion": "我们的实验表明，与基于单词的管道相比，该技术在端到端准确率上提高了5.4%，突显了向行级OCR过渡的潜在优势，特别是对于文档图像。我们还报告了4倍的效率提升。随着大语言模型的持续改进，我们的方法还具有利用这些进步的潜力。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21488", "html_url": "https://arxiv.org/abs/2508.21488", "title": "先验分布很重要：解决贝叶斯深度Q学习中的误指定", "title_en": "Priors Matter: Addressing Misspecification in Bayesian Deep Q-Learning", "authors": "Pascal R. van der Vaart,Neil Yorke-Smith,Matthijs T.J. Spaan", "background": "不确定性量化在强化学习中可以显著提高探索能力和鲁棒性。近来，近似贝叶斯方法被广泛用于量化模型自由算法中的不确定性。然而，目前的研究主要集中于提高后验近似的准确性，而没有研究先验和似然假设的准确性。贝叶斯深度Q学习中存在冷后验效应，即减少后验的温度反而会提高性能，这与理论预期不符。", "innovation": "该研究挑战了在贝叶斯模型自由算法中常见的先验和似然假设，并通过实证研究和统计检验发现常见的高斯似然假设经常被违反。研究者提出，研发更合适的先验和似然应该是未来贝叶斯强化学习研究的重点，并提供了改善深度Q学习先验的简单实现方案，从而提高贝叶斯算法的性能。", "conclusion": "研究结果表明，对先验和似然的准确假设是提高贝叶斯算法性能的关键。提供了简化的方法以开发更合适的先验，并提高了深度Q学习中的贝叶斯算法性能。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21715", "html_url": "https://arxiv.org/abs/2508.21715", "title": "基于熵的无侵入性 Convolutional Neural Networks 可靠性监控", "title_en": "Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks", "authors": "Amirhossein Nazeri,Wael Hafez", "background": "卷积神经网络（CNNs）已经成为现代计算机视觉的基础，实现了多样化的图像识别任务中前所未有的准确性。尽管这些网络在内部数据集上表现出色，但它们仍然容易受到有细微输入修改的对抗性扰动的影响，这些修改会导致高置信度误分类。然而，现有的检测方法要么需要昂贵的重新训练，要么需要修改网络结构，要么会降低在干净输入上的性能。这表明现有的检测方法存在局限性且不够高效，需要一种新的检测方法来解决上述问题。", "innovation": "本文提出了一种新的检测方法，即通过监测激活熵 Signature，不需对模型进行任何修改，就能检测到对抗性扰动。文中以 VGG-16 为例，证明了对抗性输入在早期卷积层中会将激活熵统一地改变 7%，这使得检测准确率达到 90%，误报率和漏报率均低于 20%。此方法利用激活熵的绝对区隔揭示了 CNN 内在地在激活模式中编码分布的变化。这项工作表明，CNN 的可靠性可以通过激活熵单独进行评估，从而实现无需牺牲原始模型性能即可实时检测对抗性输入的自诊断视觉系统。", "conclusion": "本文的工作进一步确立了根据激活熵来评估 CNN 可靠性的重要性，提出了不需要对模型进行任何修改、不降低性能就能实时检测对抗性输入的实用方法。这一方法展示了高检测准确率，同时有效控制了误报和漏报率，具有实际部署的潜力。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21666", "html_url": "https://arxiv.org/abs/2508.21666", "title": "利用物联网和生成式人工智能进行气象自适应学习以增强气候韧性教育", "title_en": "Harnessing IoT and Generative AI for Weather-Adaptive Learning in Climate Resilience Education", "authors": "Imran S. A. Khan,Emmanuel G. Blanchard,Sébastien George", "background": "随着全球气候变化问题日益突出，气候适应性教育变得愈发重要。过去的气候教育方法大多缺乏介入性和互动性，无法有效提升青少年和成年参与者的气候意识和应对知识。因此，迫切需要一种能够提供个性化、动态化学习体验的新型教育平台。", "innovation": "本文介绍了一种名为 Future Atmospheric Conditions Training System (FACTS) 的创新平台，利用物联网（IoT）传感器和生成式人工智能，提供以地点为基础、自适应学习体验。该系统能够实时收集大气数据，并结合知识库中的资源，生成本地化的学习挑战。此外，通过生成式AI辅助的服务器进行个性化的反馈和支持，使得这种教育方式更加新颖和有效。", "conclusion": "用户评估结果显示，该系统易于使用且对气候适应性知识的学习非常有效。这表明将物联网与生成式人工智能结合用于自适应、气候适应性学习的技术具有巨大潜力，可以提高教育参与度并增强气候变化意识。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21732", "html_url": "https://arxiv.org/abs/2508.21732", "title": "CAD2DMD-SET：用于微调大型视觉-语言模型的数字测量设备CAD模型数据集的合成生成工具", "title_en": "CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models", "authors": "João Valente,Atabak Dehban,Rodrigo Ventura", "background": "大型视觉-语言模型（LVLMs）在多种跨模态任务中展现了惊人的能力，但在处理数字测量设备（DMDs）读取场景时仍然遇到了挑战，尤其是在具有杂乱、遮挡、极端视角和运动模糊的现实世界条件下。这些条件常见于头戴式相机和增强现实（AR）应用中。", "innovation": "该工作提出了一种名为CAD2DMD-SET的合成数据生成工具，旨在支持涉及DMDs的视觉问答（VQA）任务。通过利用3D CAD模型、高级渲染和高保真图像合成，该工具生成了多样化的、带有VQA标签的合成DMD数据集，适合LVLMs的微调。此外，还提出了DMDBench数据集，包含1,000个标注的真实世界图像，用于在实际约束下评估模型性能。使用ANLS对三个最新的LVLMs进行基准测试并进一步使用CAD2DMD-SET生成的元数据集微调LoRA模型，获得了显著提高，表明CAD2DMD-SET训练数据集在上述挑战条件下大幅提升了LVLMs的鲁棒性和性能。", "conclusion": "CAD2DMD-SET工具在训练过程中显著提高了LVLMs在复杂条件下的鲁棒性和性能，并且预计将在最终版本的论文准备完成后作为开源发布，以便社区添加不同的测量设备并生成自己的数据集。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21589", "html_url": "https://arxiv.org/abs/2508.21589", "title": "Middo: 基于模型动态数据优化的增强型大型语言模型微调", "title_en": "Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning", "authors": "Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu", "background": "大型语言模型（LLM）的监督微调（SFT）基础是高质量的训练数据。现有方法通过数据选择和数据合成两种常见策略来提高数据质量，但在静态数据集的管理中，往往难以适应模型能力的发展。因此，现有方法存在局限性，无法有效利用模型自身的反馈信息来持续优化数据集，从而提升模型性能。文章提出了一种动态数据优化框架Middo，旨在通过模型感知的数据选择和上下文保持的数据细化，建立一个闭环优化系统，以提升数据质量并改善模型性能。这种方法引入了模块化和动态原则，结合自反馈诊断模块和自适应优化引擎，旨在实现实时的、连续的数据优化，以适应模型不断增长的能力，这与一劳永逸的筛选/合成方法不同。实验证明，该方法在多个基准测试中能够显著提升初始数据质量，提高LLM的性能，平均准确率提升7.15%，同时保持原始数据集规模，为数据和模型的人工智能共生提供了新的范式，确保持续的LLM训练优化。研究团队计划不久提供数据集、模型和代码。", "innovation": "文章介绍了一种创新的动态数据优化框架Middo，可以在高级别优化LSTM性能时，自适应地提升数据质量并维护语义连续性。与传统的单一过滤或合成方法不同，Middo提出了一种闭环优化系统，首先利用自反馈诊断模块通过损失模式、嵌入聚类动态和自我对齐得分来主动识别低质量样本，然后利用自适应优化引擎将这些样本转化为教育有价值的训练点，同时保持语义完整性。这种优化机制采用动态学习原理，能够随着模型能力的增长不断进化。研究成果为可持续的LLM训练提供了一种新的可持续范式，通过数据和模型的人工智能共生实现优化。", "conclusion": "本文通过引入Middo框架，展示了一种新的动态换新范式，利用自反馈诊断模块和自适应优化引擎实现数据和模型的持续进阶。通过在多个基准测试中的实验证明，该方法提高了LLM的准确率（平均提高7.15%）并保持了数据集规模不变，有助于实现实现LLM训练持续优化和性能的提升。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21727", "html_url": "https://arxiv.org/abs/2508.21727", "title": "OptMark: Inference时基于优化的鲁棒多比特扩散水印技术", "title_en": "OptMark: Robust Multi-bit Diffusion Watermarking via Inference Time Optimization", "authors": "Jiazheng Xing,Hai Ci,Hongbin Xu,Hangjie Yuan,Yong Liu,Mike Zheng Shou", "background": "水印技术在数字版权保护和用户追踪方面至关重要。然而，现有的基于扩散的水印方法存在显著局限性：零比特水印系统的容量不足，无法进行大规模用户追踪；多比特水印系统则对某些图像变换或生成攻击非常敏感，缺乏全面的鲁棒性。", "innovation": "本文提出了一种基于优化的方法OptMark，用于将鲁棒的多比特水印嵌入到扩散去噪过程中的中间潜在特征中。OptMark通过早期插入结构水印来抵抗生成攻击，晚些时候插入细节水印来应对图像变换，同时采用定制化的正则化项以保持图像质量和确保不可感知性。OptMark通过引入伴随梯度方法解决了优化过程中内存消耗增长的问题，将其从O(N)减少到O(1)。", "conclusion": "实验结果表明，OptMark实现了不可见的多比特水印，同时确保了对数值变换、几何变换、编辑及再生攻击的鲁棒性抗性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21632", "html_url": "https://arxiv.org/abs/2508.21632", "title": "QZhou-Embedding技术报告", "title_en": "QZhou-Embedding Technical Report", "authors": "Peng Yu,En Xu,Bin Chen,Haibiao Chen,Yinfei Xu", "background": "文本嵌入模型是自然语言处理领域中的一种重要工具，能够将文本转换为连续的向量表示，广泛应用于信息检索、相似度计算、文本聚类等多种任务。现有的嵌入模型虽然在某些特定领域取得了不错的成果，但普遍存在对文本语义表达不足以及泛化能力不强的问题。本文针对传统嵌入模型的不足，提出了一种基于Qwen2.5-7B-Instruct预训练模型的通用多任务框架嵌入模型QZhou-Embedding，通过数据处理和特定任务训练策略，旨在提升文本表示的精度与多样性，从而改善检索模型的性能。", "innovation": "本文的主要创新点在于：1. 开发了一套数据合成流水线，利用LLM API实现文本的同义替换、增强以及生成困难负例，提高了训练集的语义丰富性和样本难度。2. 采用两阶段训练策略，首先是专注于检索的预训练，然后是全面任务的微调，使模型能够基于稳健的检索性能进一步扩展其能力。3. 通过实验证明，高质量、多样化的数据对于提升检索模型性能至关重要，并利用生成模型的能力进一步优化了嵌入模型的训练过程，从而促进了模型的性能突破。", "conclusion": "QZhou-Embedding在MTEB和CMTEB基准测试中取得了最先进的结果，在主题检索、聚类等任务上实现了最优性能。研究结果表明，为了提高检索模型的性能，高质量和多样化的数据非常重要，并且利用大语言模型的生成能力可以进一步优化嵌入模型的数据训练质量。我们已经开源了模型权重，并提供了评估代码和说明数据，以确保研究结果的可复制性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21762", "html_url": "https://arxiv.org/abs/2508.21762", "title": "强度推理回归", "title_en": "Reasoning-Intensive Regression", "authors": "Diane Tchuindjo,Omar Khattab", "background": "研究者和从业者越来越多地将大型语言模型（LLMs）应用于我们称之为推理密集型回归（RiR）的任务，即从文本中推导出微妙的数值属性。与标准的自然语言回归任务，如情感或相似性判断不同，RiR通常出现在如评分标准或特定领域检索这类临时问题中，需要对文本进行更深入的分析，但可用的任务特定训练数据和计算资源有限。", "innovation": "该研究提出了MENTAT，一种简单且轻量级的方法，结合了批次反省提示优化和神经集成学习。实验结果显示，MENTAT在两个基线之上实现了高达65%的性能改进，表明在RiR任务中，冻结的LLMs提示调整和通过梯度下降微调Transformer编码器通常会遇到困难。", "conclusion": "尽管在RiR上取得了一定的性能提升，但研究者认为未来RiR领域的进展还有很大的空间。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21733", "html_url": "https://arxiv.org/abs/2508.21733", "title": "开发人员对于设计基于人工智能的计算机感知工具的见解", "title_en": "Developer Insights into Designing AI-Based Computer Perception Tools", "authors": "Maya Guhan(1),Meghan E. Hurley(1),Eric A. Storch(2),John Herrington(3),Casey Zampella(3),Julia Parish-Morris(3),Gabriel Lázaro-Muñoz(4),Kristin Kostick-Quenet(1) ((1) Center for Ethics and Health Policy, Baylor College of Medicine, Houston, TX, USA, (2) Department of Psychiatry and Behavioral Sciences, Baylor College of Medicine, Houston, TX, USA, (3) Department of Child and Adolescent Psychiatry and Behavioral Sciences, Children's Hospital of Philadelphia, Philadelphia, PA, USA, (4) Center for Bioethics, Harvard Medical School, Boston, MA, USA)", "background": "基于人工智能（AI）的计算机感知（CP）技术利用移动传感器收集生物行为和生理数据，用于临床决策。这些技术在生成和解释临床知识方面具有重塑潜力。然而，有效将这些工具集成到临床工作流程中需要在临床效用、用户可接受性和可信度之间找到平衡。本文基于对20名开发基于AI的CP工具的开发者的深入访谈，分析了他们在设计这些工具时面临的主要挑战和优先考虑的设计要点。", "innovation": "研究发现了四个关键的设计优先事项：1）考虑上下文并确保对患者和临床医生的解释性；2）将工具与现有的临床工作流程对齐；3）根据相关的利益相关者适当定制以提高可用性和接受度；4）勇于创新，同时符合既定的范式。这表明开发人员不仅被视为技术架构师，同时也视自己为道德守护人，设计出既可被用户接受又有知识论责任感（优先考虑客观性并促进临床知识的发展）的工具。研究提出了实现这些平衡目标的建议：记录定制设计选择背后的决策过程、明确定制选择的界限、透明地传达输出信息和投资用户培训。", "conclusion": "实现这些目标需要开发人员、临床医生和伦理学家之间的多学科合作，以确保临床效用、用户可接受性和伦理责任的平衡。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21739", "html_url": "https://arxiv.org/abs/2508.21739", "title": "基于MPSoC板的神经网络加速：集成SLAC的SNL、Rogue Software和Auto-SNL", "title_en": "Neural Network Acceleration on MPSoC board: Integrating SLAC's SNL, Rogue Software and Auto-SNL", "authors": "Hamza Ezzaoui Rahali,Abhilasha Dave,Larry Ruckman,Mohammad Mehdi Rahimifar,Audrey C. Therrien,James J. Russel,Ryan T. Herbst", "background": "斯坦福直线加速器中心（SLAC）的LCLS-II自由电子激光将产生频率高达1 MHz的X射线脉冲，用于束线实验。实验过程中产生的数据量巨大，超过1 TB/s，这对数据传输和存储基础设施构成了巨大挑战。传统的机器学习（ML）实施在实时数据减少方面引入了过长的延迟，无法满足高速实验环境的需求。SLAC为此开发了SLAC神经网络库（SNL），这是一种专门为现场可编程门阵列（FPGA）部署实时ML推理模型的特殊框架。SNL的一个关键特性是可以动态更新模型权重，而无需重新合成FPGA，从而增强其在适应性学习应用中的灵活性。为了进一步提高使用性和可访问性，作者引入了Auto-SNL，这是一种Python扩展，简化了将基于Python的神经网络模型转换为SNL兼容的高层次综合代码的过程。该论文展示了SNL与当前最先进的工具hls4ml在多个神经网络架构、固定点精度和FPGA合成配置方面的基准比较结果，结果显示SNL在大部分测试的架构中能够达到竞争力或更优的延迟，同时在某些情况下也能节省FPGA资源。这证明了SNL的灵活性，为高能物理、医学成像、机器人等领域的研究人员和学者提供了新的机会。", "innovation": "SLAC的SNL是一种专门用于FPGA部署实时ML推理模型的特殊框架，能够动态更新模型权重。Auto-SNL是一种Python扩展，可以简化将基于Python的神经网络模型转换为SNL兼容的高层次综合代码的过程。论文展示了SNL在多个神经网络架构、固定点精度和FPGA合成配置方面的基准比较结果，表明它在大部分测试的架构中能够达到竞争力或更优的延迟，同时在某些情况下也开始节省FPGA资源，展示了其灵活性和适应性学习能力。", "conclusion": "SNL的开发和Auto-SNL的引入展示了在高速实验环境中实现实时ML推理模型的新方法。该研究的结果表明，SNL在多个方面与hls4ml相比表现出色，特别是在延迟和FPGA资源使用方面。这为在高能物理、医学成像、机器人等领域的研究开辟了新的可能性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21777", "html_url": "https://arxiv.org/abs/2508.21777", "title": "GPT-5在放射肿瘤学中的基准测试：可测量的进步，但仍需专家监督", "title_en": "Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight", "authors": "Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz", "background": "大型语言模型（LLM）在临床决策支持方面展现了巨大潜力。GPT-5是一个专为肿瘤学应用设计的新型LLM系统。研究通过两项互补的标准对GPT-5进行了性能评估，包括ACR放射肿瘤学在职考试（TXIT，2021）和一个由60个代表不同疾病部位和治疗方案的真实的放射肿瘤学病例集组成的标准集。这些评估旨在检验GPT-5在典型放射肿瘤学任务中的表现和生成实际治疗计划的能力。", "innovation": "GPT-5在放射肿瘤学特定领域的表现明显优于之前的模型变体（如GPT-4和GPT-3.5），尤其是在剂量和诊断方面。此外，GPT-5在治疗建议的正确性、完整性和罕见过度推断方面表现良好，但仍存在在复杂场景中的错误，这表明GPT-5生成的建议在临床应用前需要严格的专家审核。", "conclusion": "GPT-5在放射肿瘤学的选择题基准测试中明显优于前一版本的模型，但实际治疗建议的正确性仍然需要改进。虽然罕见的过度推断现象，但在复杂情况下存在的实质性错误提示GPT-5生成的建议在临床实施前需要严格的专家监督。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21787", "html_url": "https://arxiv.org/abs/2508.21787", "title": "PiCSAR: 概率置信度选择和排序", "title_en": "PiCSAR: Probabilistic Confidence Selection And Ranking", "authors": "Joshua Ong Jun Leang,Zheng Zhao,Aryo Pradipta Gema,Sohee Yang,Wai-Chung Kwan,Xuanli He,Wenda Li,Pasquale Minervini,Eleonora Giunchiglia,Shay B. Cohen", "background": "大规模语言模型（LLMs）和大规模推理模型（LRMs）在生成多个候选解决方案后，通过选择奖励最高的一个来提高准确性。对于推理任务的关键挑战是设计一个评分函数，能够在没有访问正确答案的情况下识别正确的推理链。本研究面临的主要背景是在这类情况下，如何有效地评估推理过程和最终答案的正确性。", "innovation": "提出了一种名为概率置信度选择和排序（PiCSAR）的方法。该方法无需训练即可为每个候选生成评估推理过程和最终答案的联合对数似然性。该方法的关键创新在于通过分解联合对数似然性为推理自信和答案自信，有效评估每个候选生成的正确性。", "conclusion": "PiCSAR 方法在这项研究中表现出了显著的优势，在多种基准上取得了重大进步（如 MATH500 +10.18，AIME2025 +9.81），并且在16个比较案例中至少比基线减少了2倍的样本数量。研究分析表明，正确的推理链在推理和答案自信方面表现出显著差异，从而证明了PiCSAR方法的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21795", "html_url": "https://arxiv.org/abs/2508.21795", "title": "TMUAD: 使用文本记忆库提升统一异常检测模型的逻辑能力", "title_en": "TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection Models with a Text Memory Bank", "authors": "Jiawei Liu,Jiahe Hou,Wei Wang,Jinsong Du,Yang Cong,Huijie Fan", "background": "异常检测旨在识别与正常模式偏离的异常情况，但因正常数据量有限而具有挑战性。现有大多数统一方法依赖精心设计的图像特征提取器和记忆库来捕捉对象之间的逻辑关系，但这些方法难以处理逻辑异常。因此，本文提出了使用文本记忆库来增强逻辑异常检测的新方法，构建了统一结构和逻辑异常检测的Three-Memory框架（TMUAD），以克服传统方法的局限性", "innovation": "引入了文本记忆库来增强逻辑异常检测能力；提出了Three-Memory框架，包括三个互补的记忆库：类级文本记忆库、对象级图像记忆库和补丁级图像记忆库，用于从不同层次检测异常并融合成最终分数；通过协作性的记忆库实现了结构和逻辑异常检测的统一，达到了七个公开可用数据集中的最佳性能（涉及工业和医疗领域）", "conclusion": "通过统一结构和逻辑异常检测，TMUAD在七个公开数据集上达到了最先进的性能，涵盖了工业和医疗领域。该模型及代码可通过上述链接获取"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21773", "html_url": "https://arxiv.org/abs/2508.21773", "title": "通过非参数深嵌入聚类实现无监督视频连续学习", "title_en": "Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering", "authors": "Nattapong Kurpukdee,Adrian G. Bors", "background": "在无监督连续视频学习（uVCL）方面，先前的研究主要集中在监督连续学习上，这部分依赖于标签和任务边界的知识，而获取带有标签的数据是非常昂贵且不切实际的。视频作为一种复杂的时空媒体信息，未被充分探索用于无监督连续学习。uVCL相较于图像处理带来了额外的计算和内存需求，因此面临更多挑战。该研究尝试通过无监督学习解决未标记数据和未知任务边界的实际问题，以更加经济和实用的方式处理视频数据，从而提高模型在学习一系列任务时的表现。", "innovation": "本文提出了一个无监督视频学习的现实场景，在学习一系列任务时不需要提供任务边界或标签。此外，提出了一种非参数学习解决方案以解决无监督视频连续学习这一尚未得到充分探索的问题。通过使用无监督视频转换器网络提取的深层嵌入视频特征的核密度估计（KDE）作为非参数概率数据表示，并引入一种新任务数据的创新检测标准，动态扩展内存簇，以捕捉新的知识。利用前任务的迁移学习作为连续学习任务知识传递的初始状态，进一步提高了模型在一系列任务学习时的效果。", "conclusion": "通过该方法，成功地在UCF101、HMDB51和Something-to-Something V2三大标准视频动作识别数据集上进行了深入评估，结果证明该方法有效地提升了模型在连续学习多个任务时的性能。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21797", "html_url": "https://arxiv.org/abs/2508.21797", "title": "DynaMark: 一种工业机床控制器动态水印的强化学习框架", "title_en": "DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers", "authors": "Navid Aftabi,Abhishek Hanchate,Satish Bukkapatnam,Dan Li", "background": "工业4.0中的高度网络化机床控制器（MTC）容易遭受重播攻击，攻击者利用过时的传感器数据操纵执行器。当前的动态水印方案假设线性高斯动力学并使用恒定的水印统计信息，这使其容易受到MTC的时变、部分专有行为的影响。", "innovation": "提出了DynaMark，一种基于强化学习的框架，将动态水印模型视为马尔可夫决策过程（MDP），学习使用可变水印方差的自适应策略来发现篡改，同时不需要系统知识。该方法通过实时检测置信度更新机制来适用于线性动力学系统，并在Siemens Sinumerik 828D控制器数字孪生体上的实验中，实现了水印能量降低70%的同时维持名义轨迹。与恒定方差基础线相比，保持平均检测延迟相当于一个采样间隔。", "conclusion": "DynaMark通过实时的检测机制和自适应水印策略，能够在不损失控制性能的情况下，有效提升检测水印篡改的能力，超过了现有的基准水平。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21793", "html_url": "https://arxiv.org/abs/2508.21793", "title": "MoE-Health: 一种用于稳健多模态医疗预测的专家混合框架", "title_en": "MoE-Health: A Mixture of Experts Framework for Robust Multimodal Healthcare Prediction", "authors": "Xiaoyang Wang,Christopher C. Yang", "background": "医疗系统生成多种多样的多模态数据，包括电子健康记录（EHR）、临床注释和医学图像。利用这些数据进行临床预测具有挑战性，特别是在现实世界中，样本往往具有不同的或不完整的模态。现有方法通常需要完整模态数据或依赖于人工选择策略，在数据可用性在不同患者和机构之间变化的现实临床环境中应用受到限制。", "innovation": "我们提出了MoE-Health，一种新颖的专家混合框架，专为医疗预测中的稳健多模态融合而设计。MoE-Health架构具体开发以处理不同模态的样本，并改进关键临床任务的性能。通过利用专业专家网络和动态门控机制，我们的方法基于可用的数据模态动态选择并组合相关专家，实现对不同数据可用性场景的灵活适应。我们在MIMIC-IV数据集上对MoE-Health进行了三项关键临床预测任务的评估：院内死亡率预测、长时间住院和医院再入院预测，实验结果表明MoE-Health在不同模态可用性模式下取得优于现有多模态融合方法的性能，同时保持了鲁棒性。框架有效地整合了多模态信息，提供了在处理异质和不完整医疗数据时的改进预测性能和鲁棒性，使其特别适合部署在具有异质数据可用性的不同医疗环境中。", "conclusion": "MoE-Health在评估中展示了其在不同的多模态数据可用性模式下的优越性能，并且在不同模态条件下表现出了鲁棒性。该框架提出的专家混合机制能够灵活适应数据可用性变化，对不同医疗环境中的多模态数据集成具有显著的优势。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.22288", "html_url": "https://arxiv.org/abs/2505.22288", "title": "压缩与精度：提升模型层次结构", "title_en": "Compression versus Accuracy: A Hierarchy of Lifted Models", "authors": "Jan Speller,Malte Luttermann,Marcel Gehrke,Tanya Braun", "background": "目前最先进的算法Advanced Colour Passing (ACP) 使用ε作为超参数，将表示匹配分布的因素分组，以获得提升表示。然而，选择合适的ε值并不明显，并且可能需要大量的探索。此外，变化ε值会生成不同的模型，导致可解释性降低。因此，本文提出了一个无超参数的提升模型构建的层次化方法，可以有效计算ε值的层次结构，确保在某种ε值下分组的因素在更大的ε值下也会被分组。这种方法还提供了层次化的误差边界，允许用户在选择具体ε值运行ACP时明确权衡压缩与精度，同时增强不同模型之间的可解释性。", "innovation": "提出了一种无超参数的提升模型构建层次化方法，通过高效计算ε值的层次结构确保模型之间的分组一致性，并提供层次化的误差边界，增强了模型的可解释性。", "conclusion": "通过这种方法，用户可以在选择具体ε值运行ACP时明确权衡压缩与精度，同时增强不同模型之间的可解释性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.05163", "html_url": "https://arxiv.org/abs/2504.05163", "title": "在知识不全情况下评估基于知识图谱检索增强生成方法", "title_en": "Evaluating Knowledge Graph Based Retrieval Augmented Generation Methods under Knowledge Incompleteness", "authors": "Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Yuan He,Jiaoyan Chen,Steffen Staab,Evgeny Kharlamov", "background": "KG-RAG是一种通过从知识图谱中检索相关信息来增强大型语言模型推理的技术，特别是在问答任务中。然而，现实中的知识图谱往往不完整，这意味着回答问题时可能会缺少关键信息。现有基准未能充分反映出知识图谱不完整性对KG-RAG性能的影响。", "innovation": "该研究通过采用不同的方法移除三元组并分析其影响，系统地评估了在知识不全的情况下KG-RAG方法的表现。此研究揭示了KG-RAG方法对知识缺失的敏感性，强调了在实际场景中需要更稳健的方法。", "conclusion": "研究表明，KG-RAG方法在知识图谱不完整的情况下表现较为敏感，突显了在实际应用中需要更加稳健的方法的必要性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15780", "html_url": "https://arxiv.org/abs/2504.15780", "title": "TrustGeoGen: 正式验证的数据引擎以实现可靠的多模态几何问题解决", "title_en": "TrustGeoGen: Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving", "authors": "Daocheng Fu,Jianlong Chen,Renqiu Xia,Zijun Chen,Qi Liu,Yuan Feng,Hongbin Zhou,Renrui Zhang,Shiyang Feng,Peng Gao,Hongyuan Zha,Junchi Yan,Botian Shi,Yu Qiao,Bo Zhang", "background": "数学几何问题解决（GPS）要求逻辑一致性和多模态推理能力。尽管大型语言模型（LLMs）在GPS方面取得了快速进展，但其发展受限于缺乏可靠的基准和系统的实施方法。关键挑战是LLMs固有的幻觉现象，导致生成的GPS数据集经常是不准确、未经验证且自相矛盾的。", "innovation": "本文介绍了一个名为TrustGeoGen的数据引擎，该引擎用于生成形式验证的几何问题以建立一个原理上可靠的标准。创新点包括：1) 多模态对齐，同步生成图形、文本和逐步解决方案；2) 形式验证，确保所有推理路径都符合规则；3) 关联思考，将形式推理与类人的逻辑步骤连接起来；4) GeoExplore系列算法，生成具有多种解决方案和自反回溯的多样化问题变体。", "conclusion": "使用TrustGeoGen引擎，我们创建了GeoTrust-200K数据集和相应的GeoTrust-test基准测试，二者的跨模态完整性得到保证。实验发现，最先进的模型在GeoTrust-test上的准确率为45.83%，突显了其挑战性。此外，使用我们的合成数据进行训练在GPS任务上的表现明显提升，并在跨域基准测试中有较强的泛化能力。相关代码和数据可在提供的链接中获得。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21618", "html_url": "https://arxiv.org/abs/2508.21618", "title": "基于物理信息的高光谱成像光谱建模", "title_en": "Physics-Informed Spectral Modeling for Hyperspectral Imaging", "authors": "Zuzanna Gawrysiak,Krzysztof Krawiec", "background": "该研究背景集中在高光谱成像领域，现有方法通常需要大量的监督数据来进行学习和建模，且难以完全分离出高光谱观测数据中不同的物理成分。物理信息被嵌入到深度学习框架中，以提高模型的性能和可解释性。", "innovation": "提出了一种名为 PhISM 的物理信息导向深度学习架构，该架构能够无监督地学习，明确地分解高光谱观测数据，并使用连续基函数进行建模。相比以往的方法，在多个分类和回归基准上表现出色，且需要较少的标记数据。同时，由于具有可解释的潜在表示，该模型还能提供额外的洞察力。", "conclusion": "该方法在多种高光谱成像任务中取得了优异的性能，并且能够有效地利用物理知识来提高模型的精确度和透明度。未来的研究可以进一步探索在更多实际应用场景中的表现。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.06464", "html_url": "https://arxiv.org/abs/2406.06464", "title": "使用大型语言模型代理将可穿戴设备数据转化为个人健康洞察", "title_en": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "authors": "Mike A. Merrill,Akshay Paruchuri,Naghmeh Rezaei,Geza Kovacs,Javier Perez,Yun Liu,Erik Schenck,Nova Hammerquist,Jake Sunshine,Shyam Tailor,Kumar Ayush,Hao-Wei Su,Qian He,Cory Y. McLean,Mark Malhotra,Shwetak Patel,Jiening Zhan,Tim Althoff,Daniel McDuff,Xin Liu", "background": "从流行的可穿戴追踪器中提取个性化的见解需要复杂的数理逻辑，这超越了传统的大型语言模型（LLMs）的能力，因此需要依赖工具的方法例如代码生成。目前，虽然大型语言模型为大规模分析提供了前景，但仍未得到充分利用。现有的分析方法存在挑战，因此开发了一种新的系统来解决这个问题。该系统利用多步推理、代码生成和信息检索来分析和解释行为健康数据。为了验证其能力和有效性，创建并分享了两个基准数据集，包含超过4000个健康洞察问题。通过650小时的人工专家评估，证明了PHIA系统显著优于强大的代码生成基线，实现了84%的客观数值问题准确率，在开放问题上获得了83%的积极评价，并且更有可能获得最高质量评级。这项工作可以推进行为健康领域，使个人能够更好地理解自己的数据，从而促进更广泛人群可访问、个性化和数据驱动的健康福祉的新时代的到来。", "innovation": "本文引入了Personal Health Insights Agent (PHIA)系统，旨在利用多步推理和代码生成与信息检索来分析和解释行为健康数据。该系统特别适用于处理来自流行的可穿戴追踪器的复杂数据。对比实验显示，PHIA在客观数值和开放问题上的表现均优于现有的代码生成基线，实现了更高的准确性和满意度。该系统能够显著提高行为健康分析的效率和准确性，为未来的健康数据分析提供了新的工具和方法。", "conclusion": "本文通过引入PHIA系统，展示了利用大型语言模型代理提高行为健康数据解析能力的潜力。PHIA在大规模健康数据分析方面表现突出，证明了该技术在实际应用中的可行性。通过使个人能够更好地理解他们的健康数据，此项工作有望推动迈向一个更加个性化和数据驱动的健康福祉的新时代。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06580", "html_url": "https://arxiv.org/abs/2506.06580", "title": "数字孪生在AI模拟中的系统调研、参考框架和与标准化架构映射", "title_en": "AI Simulation by Digital Twins: Systematic Survey, Reference Framework, and Mapping to a Standardized Architecture", "authors": "Xiaoran Liu,Istvan David", "background": "在采用现代非符号AI过程中，数据量不足和数据质量不高是一个特别紧迫的挑战。AI模拟通过使用虚拟训练环境来缓解这些问题，在这些环境中，可以安全且高效地开发AI代理。数字孪生为AI模拟提供了新途径，它们是物理系统的高保真虚拟复制品，并配备了先进的模拟器，还能够与物理系统进一步交互以收集额外的数据。本文通过系统调研22项主要研究，揭示技术趋势并建立一个参考框架来定位数字孪生和AI组件。", "innovation": "作者通过系统调研22项主要研究，发现技术趋势并提出用于定位数字孪生和AI组件的参考框架，并将该框架与ISO 23247数字孪生标准化架构进行映射。这种工作为未来的研究提供了指导，并识别了未来的挑战和研究机会。", "conclusion": "本文通过系统调研，揭示了数字孪生在AI模拟中的潜力和挑战，提出了一个参考框架，并将其与标准化架构相结合，为未来研究指明方向。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.08344", "html_url": "https://arxiv.org/abs/2508.08344", "title": "知识图谱基于检索增强生成的局限性：在知识不完整情况下推理的实证洞察", "title_en": "What Breaks Knowledge Graph based RAG? Empirical Insights into Reasoning under Incomplete Knowledge", "authors": "Dongzhuoran Zhou,Yuqicheng Zhu,Xiaxia Wang,Hongkuan Zhou,Yuan He,Jiaoyan Chen,Steffen Staab,Evgeny Kharlamov", "background": "当前知识图谱(Knowledge Graph, KG)与大规模语言模型联合使用的评估方法存在缺陷，现有基准测试中的问题往往可以直接通过KG中的三元组回答，使得模型进行实际推理的能力不清晰。此外，不一致的评估指标和模糊的答案匹配标准进一步模糊了有意义的比较。", "innovation": "提出了一个通用的基准构建方法，以及评估协议，以系统地评估在知识不完整性情况下KG-RAG方法的表现。该方法揭示了当前KG-RAG方法在缺乏知识时推理能力有限，通常依赖于内部记忆，不同设计的模型在泛化能力上存在差异。", "conclusion": "当前的KG-RAG方法在知识不完整的情况下推理能力有限，大多依赖内部记忆，并且泛化能力也因设计而异。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2302.00935", "html_url": "https://arxiv.org/abs/2302.00935", "title": "Offline-to-Online Reinforcement Learning Policy Expansion", "title_en": "Policy Expansion for Bridging Offline-to-Online Reinforcement Learning", "authors": "Haichao Zhang,We Xu,Haonan Yu", "background": "offline数据预训练结合在线强化学习微调是一种有前景的策略，能在样本效率和性能方面充分利用两者的优点。一种自然的方法是用已经离线训练好的策略初始化在线学习的策略。本文提出了一个策略扩展方案来实现这一目标。", "innovation": "提出了一种策略扩展方案来结合离线与在线的强化学习。具体而言，在离线学习得到的策略基础上扩展策略集，用新策略进一步学习，并在与环境交互时根据不同情况自适应组合两种策略。", "conclusion": "实验结果显示该方法的成效，并且可以通过这种方式保留离线学习得到的策略的有用行为，同时允许新策略在适应性探索中贡献新的有用行为。源代码可从指定链接访问。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2309.08289", "html_url": "https://arxiv.org/abs/2309.08289", "title": "使用点扩散模型对大肠3D形状进行细化以生成数字模拟物", "title_en": "Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation", "authors": "Kaouther Mouheb,Mobina Ghojogh Nejad,Lavsen Dahal,Ehsan Samei,Kyle J. Lafata,W. Paul Segars,Joseph Y. Lo", "background": "准确的人体器官三维建模对于虚拟成像实验中的数字模拟物构建至关重要。然而，复杂的几何形状和形状变异性使得如大肠这样器官的建模尤为具有挑战性。本文探讨了CLAP（Conditional LAtent Point-diffusion模型），结合几何深度学习和去噪扩散模型来增强大肠的3D表示，以应对这些挑战。通过这些方法，该模型在形状建模准确性方面取得了显著改进，减少了26%的Chamfer距离和36%的Hausdorff距离，证明了其在复杂器官建模方面的有效性和鲁棒性。", "innovation": "提出了CLAP（Conditional LAtent Point-diffusion模型），该模型结合了几何深度学习与去噪扩散模型，创新性地应用于复杂器官（如大肠）的3D建模，尤其在形状细化和重建方面表现出色。", "conclusion": "CLAP模型通过自上而下的层次变分自动编码器、两个条件扩散模型的精加工以及预训练的表面重建模型，实现了大肠形状模型的显著提升。这种方法为高保真器官建模提供了稳健且可扩展的解决方案，并具有广泛的应用前景。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.14488", "html_url": "https://arxiv.org/abs/2403.14488", "title": "COBRA-PPM：使用概率编程进行不确定性下机器人操作的因果贝叶斯推理架构", "title_en": "COBRA-PPM: A Causal Bayesian Reasoning Architecture Using Probabilistic Programming for Robot Manipulation Under Uncertainty", "authors": "Ricardo Cannizzaro,Michael Groom,Jonathan Routley,Robert Osazuwa Ness,Lars Kunze", "background": "机器人在操作物体时需要推理因果关系，而许多基于数据的方法缺乏因果语义，仅考虑相关性。因此需要引入一个新的架构来解决这一问题。本文通过高保真Gazebo实验展示了COBRA-PPM（基于概率编程的因果贝叶斯推理架构）在块堆叠任务中实现高预测精度和高任务成功率。此外，该架构还展示了从模拟到现实的迁移能力，解决了传感器噪声和随机动作导致的现实世界不确定性问题。", "innovation": "COBRA-PPM架构结合了因果贝叶斯网络和概率编程，以进行干预性推理，适用于机器人在不确定环境下的操作。其主要创新在于使用概率编程处理因果关系，从而更准确地进行操作预测和优化行动选择。", "conclusion": "COBRA-PPM架构为多种操作场景提供了通用且可扩展的解决方案，并且为未来机器人与因果关系交叉领域的研究奠定了基础。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2404.17625", "html_url": "https://arxiv.org/abs/2404.17625", "title": "Alice在可微分奇幻国度的旅程——第一卷，一次奇妙的土地之旅", "title_en": "Alice's Adventures in a Differentiable Wonderland -- Volume I, A Tour of the Land", "authors": "Simone Scardapane", "background": "神经网络无处不在，从大型语言模型、语音转写系统到分子发现算法等。剥离一切外在形式，神经网络本质上是由可微分的基本组件构成的。研究神经网络意味着学习如何编程，如何与这些模型互动，这是所谓的可微分编程。该指南为像爱丽丝这样刚踏入这一奇特的可微分奇妙领域的初学者而编写。", "innovation": "概述了通过自动微分优化函数的基本知识，并且介绍了处理序列、图、文本和音频的最常见设计类型。强调提供一种直观且自包含的介绍，涵盖了卷积、注意力和递归模块最重要设计技术，旨在填补理论与代码（PyTorch和JAX）之间的鸿沟。读者能够理解最先进模型，如大型语言模型（LLMs）和多模态架构。", "conclusion": "该指南旨在帮助读者理解可微分编程的核心概念和技术，搭建理论与实践之间的桥梁，使得读者具备理解复杂神经网络模型的能力。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.00209", "html_url": "https://arxiv.org/abs/2406.00209", "title": "Mamba状态空间模型是李普曼稳定的学习者", "title_en": "Mamba State-Space Models Are Lyapunov-Stable Learners", "authors": "John T. Halloran,Manbir Gulati,Paul F. Roysdon", "background": "Mamba状态空间模型（SSMs）最近在各种任务中超越了最先进的（SOTA）大型语言模型（LLMs），并且已被广泛采用。然而，对于基于循环的深度模型（如SSMs），其循环动态的敏感性是稳定学习中的一大关切点。值得注意的是，Mamba SSs在混合精度微调（MPFT）和参数高效微调（PEFT）等常见微调方法下的循环动态稳定性尚未被探索。尽管这些微调框架被广泛用于注意力模型，Transformer LL秣们在结合MPFT和PEFT后可能会出现大幅度的发散，而Mamba LL秣们则表现出惊人的稳定特性，在不同组合方式下几乎不会发散。这种稳定性的原因在于其循环动态的稳定性，通过动力系统理论（特别是李普曼稳定性）可以被证明是稳定的。", "innovation": "研究发现在结合MPFT和PEFT的情况下，Mamba LLMs对单一和组合方法的变化非常稳定，这是与Transformer LLMs不同的关键特征。此外，首次使用MPFT和PEFT研究Mamba LLMs在自然语言任务中的上下文推理能力（ICL），填补了之前的空白。", "conclusion": "Mamba LLMs的循环动态稳定性通过动力系统理论（李普曼稳定性）得以理论证明，并且展示了这些模型在自然语言任务中的新能力研究，特别是在微调方法下的独特的稳定性表现。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.04090", "html_url": "https://arxiv.org/abs/2411.04090", "title": "基于注释分歧度量化估计的协作内容审核框架用于恶意内容检测", "title_en": "A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement", "authors": "Guillermo Villate-Castillo,Javier Del Ser,Borja Sanz", "background": "内容审核通常结合了人工审核员和机器学习模型的努力。然而，这些系统往往依赖于在审核过程中存在显著分歧的数据，反映了恶意内容感知的主观性。通常，这些分歧被视为噪音，而没有被充分利用。本研究认为这些分歧是重要的信号，揭示了内容的内在模糊性，而仅考虑多数标注结果可能会忽略这一信息。因此，需要提出一种新的框架来加强对标注分歧的关注。", "innovation": "论文引入了一种新的内容审核框架，该框架采用多任务学习，将恶意内容分类作为主要任务，而标注分歧作为辅助任务。此外，还利用了不确定性估计技术（特定为条件概率预测），来处理评论标注的模糊性和模型在预测恶意内容时的固有不确定性。该框架还允许审核员调整标注分歧的阈值，以灵活确定何时需要进行审查，从而提高了模型性能、校准和不确定性估计，同时提供了参数效率，并改善了审核流程，优于单一任务方法。", "conclusion": "与单一任务方法相比，该联合方法在模型性能、校准和不确定性估计方面有所提升，并且在灵活性和参数效率方面也有所改善，从而增强了内容审核过程。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21816", "html_url": "https://arxiv.org/abs/2508.21816", "title": "困扰的是歧义性：回归事件识别中的单正多标签学习", "title_en": "The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning", "authors": "Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin", "background": "场景理解（SR）是计算机视觉中的一个基本任务，旨在通过识别关键事件及其关联实体从图像中提取结构化的语义摘要。现有方法将动词分类视为单一标签问题，但实际上，全面分析表明，由于同一张图片可能用多个动词类别合理描述，这种单一标签的建构形式无法解决视觉事件识别中固有的模糊性。", "innovation": "本文通过实证分析揭示了由于动词类别的普遍语义重叠，动词分类本质上是一个多标签问题。由于大规模数据集标记多个标签不实际，提出了一种新的单正多标签学习（SPMLL）问题的视角。此外，设计了一个全面的多标签评价基准，以公平评估模型在多标签环境下的性能。针对SPMLL的挑战，提出了结合图神经网络捕获标签关联的并设计对抗训练优化决策边界的Graph Enhanced Verb Multilayer Perceptron (GE-VerbMLP)。", "conclusion": "实验结果表明，虽然在传统的顶级1和顶级5准确性指标上保持竞争力，但本方法在真实数据集上的平均准确率提高了超过3%。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21788", "html_url": "https://arxiv.org/abs/2508.21788", "title": "精细梳理细网：细网问题内容搜索和检索的索引技术报告", "title_en": "Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing Fine Web for Problematic Content Search and Retrieval", "authors": "Inés Altemir Marinas,Anastasiia Kucherenko,Andrei Kucharavy", "background": "大型语言模型（LLMs）依赖于大型网页数据集，如Common Crawl，这些数据集为某些现代模型提供了超过80%的训练数据。然而，网页爬取的随意性带来了数据质量、安全性和伦理方面的问题。尽管训练数据的质量至关重要，但先前关于有害内容的研究由于计算限制，仅限于小样本数据。因此，该项目提出了一种使用基于ElasticSearch的管道对LLM训练数据集进行索引和分析的框架，并应用于瑞士AI组织的FineWeb-2语料库（1.5TB，四种语言），实现了快速查询性能，多数查询在毫秒内完成，所有查询均在2秒内完成。这表明可以在实时环境下对数据集进行分析，提供更安全、更负责任的人工智能系统工具。", "innovation": "该项目提出了一个用于索引和分析LLM训练数据集的框架，通过ElasticSearch技术实现快速查询性能。关键在于此框架能够应用到大规模多语言语料库中，为实时数据集分析提供了可能。", "conclusion": "这项工作展示了实时的数据集分析能力，为更安全和负责任的人工智能系统的实现提供了实用工具。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20008", "html_url": "https://arxiv.org/abs/2506.20008", "title": "QHackBench: 使用PennyLane Hackathon 挑战进行大规模语言模型量子代码生成基准测试", "title_en": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges", "authors": "Abdul Basit,Minghao Shao,Muhammad Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique", "background": "最近的大模型（LLMs）在代码生成方面表现出强大的潜力，但在量子计算领域的应用仍然鲜有人研究。本文基于真实世界的挑战对PennyLane支持下的量子代码生成进行基准测试，源自Quantum Hackathon (QHack)。", "innovation": "引入了一个新的基准数据集QHackBench，基于QHack竞赛的挑战。评估框架对功能正确性、语法有效性及执行成功率进行了评估。通过检索增强生成（RAG）方法，补充了扩展的PennyLane数据集，模型在复杂量子算法中的表现与标准提示方法相近。提出了一个迭代改进错误解决方案的多代理评估流水线，进一步提高了执行成功率。同时，承诺公开QHackBench数据集以及评估框架和实验结果，以促进进一步的研究。", "conclusion": "结果表明，在使用扩展的PennyLane数据集增强的RAG模型下，量子算法生成的表现与标准提示方法相似，特别是复杂算法方面。多代理分析管线迭代改进了错误的解决方案，进一步提高了执行成功率。OpenAI将继续公开QHackBench，及其评价框架和实验结果，推动AI辅助量子编程领域的持续进步。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.00631", "html_url": "https://arxiv.org/abs/2412.00631", "title": "ROSE：一种针对LLM任务特定指令调优的基于奖励的数据选择框架", "title_en": "ROSE: A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning", "authors": "Yang Wu,Huayi Zhang,Yizheng Jiao,Lin Ma,Xiaozhong Liu,Jinhong Yu,Dongyu Zhang,Dezhi Yu,Wei Xu", "background": "大型语言模型（LLMs）通过指令调优展示了在各个领域生成更可控且有效的输出的巨大潜力。当前方法主要依赖于手工制作的相似度度量来选择与测试数据分布匹配的训练数据集，其目的是通过最小化指令调优损失改善目标任务的性能。然而，观察表明，LLMs中的指令调优损失（即下一个令牌预测的交叉熵损失）与实际任务性能之间经常不具备单调关系，这导致现有数据选择方法的有效性受到质疑。虽然存在这一问题，但当前方法依然未能提供有效的解决方案来解决这一不一致性问题。", "innovation": "本文提出了一种名为ROSE的新颖数据选择方法，这是一种基于奖励的针对LLM任务特定指令调优的数据选择框架。ROSE利用成对偏好损失作为奖励信号来优化任务特定指令调优的数据选择。ROSE通过适应的一种影响公式来近似训练数据点相对于少量种子偏好验证集的影响，从而选择出与任务相关的训练数据点。实验结果表明，使用ROSE方法选择仅有5%的训练数据，可以达到与使用全部训练数据集微调相当甚至更好的性能表现，并且超越了现有的其他先进数据选择方法。", "conclusion": "通过实验发现，ROSE充分利用了奖励信号来优化任务特定指令调优中的数据选择。与全数据集微调相比，我们的方法仅需要选择5%的相关训练数据，就能在多个基准数据集和不同的模型架构上表现出最佳性能。此外，我们的定量分析进一步证实了该方法在各个方面的鲁棒性和广泛适用性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.10257", "html_url": "https://arxiv.org/abs/2411.10257", "title": "使用滑动窗口引导扩散模型", "title_en": "Guiding a diffusion model using sliding windows", "authors": "Nikolas Adaloglou,Tim Kaiser,Damir Iagudin,Markus Kollmann", "background": "指导是扩散模型中广泛使用的技术，用于提高样本质量。技术上，指导通过使用比主模型更具广泛推广性的辅助模型来实现。研究表明，当辅助模型的推广误差与主模型相似但更强时，效果最佳。", "innovation": "引入了一种名为masked sliding window guidance（M-SWG）的新颖无训练方法。M-SWG无需访问先前迭代的模型权重、额外训练或类别条件，通过选择性限制主模型的感知场，来强化长范围空间依赖关系。", "conclusion": "M-SWG在无饱和样本的情况下获得了优于以前最佳无训练方法的Inception评分（IS）。结合现有指导方法，M-SWG在使用EDM2-XXL和DiT-XL时，在ImageNet上达到了最佳的Frechet DINOv2距离。相关代码可在提供的网站上找到。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.12640", "html_url": "https://arxiv.org/abs/2501.12640", "title": "在政治播客中，有害言语滋生有害言语：探究对话链条", "title_en": "Toxicity Begets Toxicity: Unraveling Conversational Chains in Political Podcasts", "authors": "Naquee Rizwan,Nayandeep Deb,Sarthak Roy,Vishwajeet Singh Solanki,Kiran Garimella,Animesh Mukherjee", "background": "数字通信中的有害行为持续成为学术界和行业专业人士的重要关切。尽管已有大量研究探讨了社会网络和讨论板上的毒性问题，但在播客方面，尽管其传播力迅速增加，但仍相对未被深入研究。本文旨在填补这一空白，通过编制包含政治播客转录文本的语料库并对其进行分析，重点关注对话结构，特别考察毒性是如何通过对话中的连续回复序列来呈现和加剧的，揭示有害语言在对话回合中升级的有机模式。", "innovation": "本研究首次系统地分析了政治播客中的对话结构，关注毒性如何通过对话中的连续回复序列来呈现和加剧。研究利用了一个专门编制的语料库来揭示有害语言在对话回合中如何升级，填补了该领域的研究空白，为未来研究提供新的视角和方法。", "conclusion": "通过对话中的序列分析发现，有害言语在对话中会延续和加剧。这一研究揭示了有害语言在对话中的有机模式，为理解并解决数字沟通中的有害行为提供了新的洞见。此外，研究方法为未来研究提供了新的切入点和技术支持。请注意，研究内容可能包含可能的攻击性/有害内容，应谨慎处理。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.18948", "html_url": "https://arxiv.org/abs/2411.18948", "title": "RevPRAG：通过LLM激活分析揭示检索增强生成中的中毒攻击", "title_en": "RevPRAG: Revealing Poisoning Attacks in Retrieval-Augmented Generation through LLM Activation Analysis", "authors": "Xue Tan,Hao Luan,Mingyu Luo,Xiaoyan Sun,Ping Chen,Jun Dai", "background": "检索增强生成(RAG)通过从相关知识数据库中检索信息来丰富LLM的输入，使其能够生成更准确且上下文相关的响应。然而，来自公开渠道（如维基百科）的知识库可能会引入新的攻击面。这种攻击称为RAG中毒，攻击者通过向知识库注入恶意文本，最终生成其目标响应。目前，针对这些中毒攻击的检测方法非常有限。本文旨在填补这一空白。", "innovation": "本文提出了一种灵活且自动化的检测管道——RevPRAG，它利用LLM的激活来检测中毒响应。我们发现，在生成正确响应与中毒响应时，LLM的激活模式会有所不同。通过在多个基准数据集和RAG架构上的测试，RevPRAG可以实现98%的真实正检测率，同时将假阳性率保持在接近1%的水平。", "conclusion": "我们的研究表明，通过分析LLM的激活模式可以有效检测RAG中的中毒攻击。RevPRAG为应对这一挑战提供了一种新的解决方案，能够高效且准确地识别出被注入恶意文本的知识库和相关攻击，从而提升系统的安全性和可靠性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.04342", "html_url": "https://arxiv.org/abs/2412.04342", "title": "使用无结构知识的检索增强机器翻译", "title_en": "Retrieval-Augmented Machine Translation with Unstructured Knowledge", "authors": "Jiaan Wang,Fandong Meng,Yingxue Zhang,Jie Zhou", "background": "检索增强生成（RAG）通过引入额外信息增强大型语言模型（LLMs）。在机器翻译（MT）中，以往的研究通常从配对的MT数据集或知识图中的领域特定知识中检索上下文示例来增强MT模型。然而，许多世界知识组织在无结构文档中，这些文档可能在不同语言间未能充分配对。本文研究了利用无结构文档的检索增强MT。研究通过GPT-4o和人类翻译者收集了169,000个MT样本，并提供了多种语言的文档以补充这些样本中的知识。", "innovation": "本文提出了RAGtrans基准，这是首个用于训练和评估LLMs检索增强MT能力的工具，包含收集自GPT-4o和人工翻译者的169,000个MT样本。此外，文中还提出了一种多任务训练方法，教LLMs如何在翻译过程中利用多种语言文档中的信息。该方法利用现有的多语言数据集创建辅助训练目标，无需额外的标签要求。实验表明，该方法在多对语言翻译任务上提升了LLMs的性能，如在En-Zh上提升了1.6-3.1个BLEU和1.0-2.0个COMET分数，在En-De上提升了1.7-2.9个BLEU和2.1-2.7个COMET分数。", "conclusion": "当前LLMs在处理此任务时面临诸多挑战。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.13580", "html_url": "https://arxiv.org/abs/2503.13580", "title": "通过迭代混合程序分析的LLM测试生成", "title_en": "LLM Test Generation via Iterative Hybrid Program Analysis", "authors": "Sijia Gu,Noor Nashid,Ali Mesbah", "background": "自动单元测试生成仍然是一个重大的挑战，特别是在处理现实世界项目中的复杂方法时更为明显。尽管大型语言模型（LLMs）在代码生成方面已取得了进展，但在实现高分支覆盖率方面仍然面临挑战，这主要是由于它们有限的控制流结构推理能力。现有技术在此方面存在不足，亟需一种新的方法来提高测试覆盖率并生成更有效的测试用例。", "innovation": "本文提出了一种名为Panta的技术，该技术模仿了人类开发者在分析代码、构建测试用例过程中遵循的迭代过程。Panta整合了静态控制流分析和动态代码覆盖率分析，以系统性地引导LLMs识别未覆盖的执行路径并生成更好的测试用例。通过纳入迭代反馈驱动机制，该技术根据静态和动态路径覆盖率洞察不断优化测试生成，确保测试更为全面和有效。实验评估表明，与现有的先进方法相比，Panta的行覆盖率提高了26%，分支覆盖率提高了23%。", "conclusion": "本文通过引入Panta技术，有效提高了自动单元测试生成的效率和测试覆盖率，特别是在处理高环形复杂度的代码类时显示出明显优势。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2411.15189", "html_url": "https://arxiv.org/abs/2411.15189", "title": "基于值序估计距离度量学习的分类数据聚类", "title_en": "Categorical Data Clustering via Value Order Estimated Distance Metric Learning", "authors": "Yiqun Zhang,Mingjie Zhao,Hong Jia,Yang Lu,Mengke Li,Yiu-ming Cheung", "background": "聚类是一种流行的机器学习技术，用于数据挖掘，可以自动揭示样本分布模式。然而，由于分类数据通常缺乏明确的度量空间，如数值数据的欧几里得距离空间，使得分类数据的分布通常被低估，从而导致聚类中容易扭曲有价值的信息。为此，该文提出了一种新颖的距离度量学习方法，通过学习最优的顺序关系并量化它们的距离，以便以线性方式直观地表示分类属性值。", "innovation": "提出了一种基于值序估计的距离度量学习方法，以此学习分类属性值的最佳顺序关系，并通过这种方式量化它们的距离，类似于数值属性的距离。由此开发了一种新的学习范式，同时进行聚类和距离度量学习，具有低的时间复杂度和收敛性保证。这一方法通过聚类友好的顺序学习机制以及排序距离和欧几里得距离的同质序数性质，在分类和混合数据集上实现了卓越的聚类精度。", "conclusion": "通过消融研究、显著性测试和案例研究等实验，验证了所提方法的有效性。该研究提出了方法的源代码。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.14681", "html_url": "https://arxiv.org/abs/2503.14681", "title": "DPImageBench: 一种统一的差分隐私图像合成基准", "title_en": "DPImageBench: A Unified Benchmark for Differentially Private Image Synthesis", "authors": "Chen Gong,Kecen Li,Zinan Lin,Tianhao Wang", "background": "差分隐私（DP）图像合成的目标是生成保留敏感图像特性但同时保护个体隐私的合成图像。尽管近年来取得了进展，但跨研究应用了一致性差且有时存在缺陷的评估协议，这不仅阻碍了对现有方法的理解，也阻碍了未来进步。为了应对这一问题，本文提出了DPImageBench，该平台从多个维度进行设计，包括方法、评估和平台，以标准化用于当前和未来实现的方法和评估协议，从而促进差分隐私图像合成领域的研究进步。", "innovation": "DPImageBench平台在以下几个方面提出创新：1）研究了11种主要方法，并系统地描述了每种方法的模型架构、预训练策略和隐私机制；2）包含了9个数据集和7个保真度和利用率指标，以便对方法进行全面评估；3）DPImageBench不仅提供了一个标准化的接口，还指出了一些关于预训练和添加噪声到高维或低维特征的新颖发现。", "conclusion": "DPImageBench的研究发现，通常认为预训练对公共图像数据集有益的观点并不总是正确的，因为预训练和敏感图像之间的分布相似度对合成图像的性能影响更显著。此外，在低隐私预算下，向低维特征（如敏感图像的高层次特征）添加噪声的效果更好，而相比向高维特征（如权重梯度）添加噪声，受到隐私预算的影响更小。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.18197", "html_url": "https://arxiv.org/abs/2503.18197", "title": "FROG：图上的公平去除", "title_en": "FROG: Fair Removal on Graphs", "authors": "Ziheng Chen,Jiali Cheng,Hadi Amiri,Kaushiki Nag,Lu Lin,Xiangguo Sun,Gabriele Tolomei", "background": "随着对隐私法规的日益重视，机器遗忘在社交网络和推荐系统等实际应用中变得越来越重要。这些应用可以自然地表示为图形。然而，现有的图形遗忘方法通常未加选择地修改节点或边，忽视了这些操作对公平性的影响。例如，忘记不同性别用户之间的连接可能会无意中加剧群体间的差异。", "innovation": "本文提出了一种新颖的框架，该框架同时优化图形结构和模型以实现公平的遗忘。该方法通过删除阻碍遗忘的冗余边并利用目标边增强来重新编织图形。此外，还引入了最坏情况下的评估机制以测试在挑战性环境中的鲁棒性。实验表明，与现有基线相比，该方法能够实现更有效和公平的遗忘。", "conclusion": "本文提出了一种名为FROG的方法，通过优化图形结构和模型实现了公平的遗忘。实验结果表明该方法在各个数据集上都能实现更有效和更公平的遗忘效果。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21773", "html_url": "https://arxiv.org/abs/2504.21773", "title": "MAC-Tuning：增强知识边界意识的LLM多成分问题推理", "title_en": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness", "authors": "Junsheng Huang,Zhitao He,Yucheng Huang,Sandeep Polisetty,Qingyun Wang,Yi.R(May)Fung", "background": "随着大型语言模型（LLMs）在各种应用中的广泛应用，其在生成虚构事实方面的幻觉问题变得尤为重要。以往的研究通过分析内部参数化知识边界来估算置信度，但这些研究主要集中在单一问题设置上，未能解决同时回答多个问题的更具挑战性的多问题设置。", "innovation": "本文引入了一种针对多问题设置的新颖方法，即MAC-Tuning（多答案和置信逐步调优）。该方法在指令数据微调期间将答案预测的学习与置信度估计分开。实验表明，该方法在平均精度上优于基线方法，提高了25%以上。", "conclusion": "通过MAC-Tuning方法，能够在多问题设置下更准确地回答多个问题，提高了准确性和可靠性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.08481", "html_url": "https://arxiv.org/abs/2504.08481", "title": "一种用于脱离性眼底图像疾病检测的全卷积CNN-Transformer混合模型", "title_en": "A Hybrid Fully Convolutional CNN-Transformer Model for Inherently Interpretable Disease Detection from Retinal Fundus Images", "authors": "Kerol Djoumessi,Samuel Ofosu Mensah,Philipp Berens", "background": "在许多医疗影像任务中，卷积神经网络（CNNs）能有效提取分层的局部特征。近年来，视觉变换器（ViTs）因其使用自我注意力机制来捕捉全局依赖性而日益受到关注，但缺乏卷积固有的空间局部化。因此，结合了CNNs和ViTs的混合模型被开发出来以融合两种架构的优势，但这些混合模型难以解释，限制了其在医疗影像中的应用。", "innovation": "本文提出了一种设计可解释性的全卷积CNN-Transformer混合模型，用于视网膜疾病的检测。不同于普遍使用的针对ViTs的后期解释性方法，我们的方法生成了与模型决策过程直接相关的忠实且局部化的证据图。该模型在两项使用彩色视网膜图像的医疗任务中达到了最先进的预测性能，提供了一次前向传播中的特定类别稀疏证据图。", "conclusion": "我们的模型在两项医疗任务中展示了优越的预测性能，并提供单次前向传播的特定类别稀疏证据图。该代码可在提供的链接中获取。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.15266", "html_url": "https://arxiv.org/abs/2504.15266", "title": "投掷骰子并向前看：超越下一个标记预测的创造性限制", "title_en": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction", "authors": "Vaishnavh Nagarajan,Chen Henry Wu,Charles Ding,Aditi Raghunathan", "background": "本文旨在探索当今语言模型的创造性极限，并提出了一个简化版的算法任务集合，以清晰和可控地量化这些模型的创造性能力。这些任务模仿了现实中的创造性挑战，要求模型进行隐含的、开放的随机计划步骤，以发现新的抽象知识图谱中的联系或构建新的模式。以前的研究通常采用单一标记的方法（即下一个标记预测），这种方法视野短浅，而多标记方法在产生多样化和原创输出方面表现出色。本文还探讨了一种在输入层注入噪声的方法（称为种子条件化），发现这种方法在不牺牲一致性的情况下，能够有效地引入随机性，甚至在某些情况下优于输出层的温度采样方法。", "innovation": "本文的创新点在于设计了一套简化的算法任务，通过这些任务可以清晰和可控地评估语言模型的创造性能力。作者提出了一种在输入层注入噪声的方法（种子条件化）来引入随机性，同时保持输出的连贯性，这是一个与传统方法不同的新思路。此外，作者还论证了多标记方法优于单一标记方法，并提供了一个用于分析开放创造性技能的理论基础。", "conclusion": "本文通过引入种子条件化方法，提出了一种超越单一标记预测的新方法，旨在显著提升模型的创造性产出。作者认为，进一步的研究应该探索多标记方法的潜力，并挑战传统的下一个标记预测方法。此外，本文为评估和提升语言模型的创造性提供了新的理论框架。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.06235", "html_url": "https://arxiv.org/abs/2504.06235", "title": "风格共享下的去中心化域泛化：形式化模型与收敛分析", "title_en": "Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis", "authors": "Shahryar Zehtabi,Dong-Jun Han,Seyyedali Hosseinalipour,Christopher G. Brinton", "background": "现有联邦学习（FL）和域泛化（DG）的研究主要集中在本地数据集统计特征在训练和测试之间保持不变的假设下，但在实际应用中这一假设往往不成立。因此，开发适应域泛化的模型非常重要，这些模型可以从源域数据中学习并具备在未见过的目标域中泛化的能 力。现有研究在这两方面存在不足：缺乏正式的数学分析以评估域泛化目标；而现有DG研究在FL上主要集中在星型拓扑结构上，缺乏对去中心化网络的研究。", "innovation": "本文提出了风格共享下的去中心化域泛化（StyleDDG）算法，一种去中心化的DG算法，允许一个对等网络中的设备通过共享其数据集推断出的风格信息来实现域泛化。此外，本文还提供了首个系统化的去中心化网络中基于风格的DG训练分析方法。我们将现有的集中化DG算法纳入到该框架中，并使用它们的形式化表达来建模StyleDDG，从而获得准确保证StyleDDG收敛的条件。实验结果表明，与基础的去中心化梯度方法相比，StyleDDG能够在目标域中显著提高准确率，并且通信开销较小。", "conclusion": "本文提出了StyleDDG算法，该算法允许去中心化的网络中的设备通过共享其数据集推断出的风格信息来实现域泛化。此外，本文还提供了第一个系统化的基于风格的DG训练分析方法，该方法将现有的集中化DG算法纳入到该框架中，并使用它们的形式化表达来建模StyleDDG。通过实验，我们证明了在目标域中可以显著提高准确率，并且通信开销较小。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.05753", "html_url": "https://arxiv.org/abs/2505.05753", "title": "在机器人运动中的身体缩放定律走向", "title_en": "Towards Embodiment Scaling Laws in Robot Locomotion", "authors": "Bo Ai,Liu Dai,Nico Bohlinger,Dichen Li,Tongzhou Mu,Zhanxin Wu,K. Fay,Henrik I. Christensen,Jan Peters,Hao Su", "background": "跨载体通用性是构建可用于任何机器人的通用载体代理的关键，但其使能因素尚不明确。本文通过使用机器人运动作为测试平台，探讨身体缩放定律，即增加训练载体数量是否有助于提高对未见过的身体类型的泛化能力。", "innovation": "作者通过程序生成约1000个具有拓扑、几何和关节级柔顺性变化的身体类型，对随机子集进行训练，并观察到支持该假设的正缩放趋势。研究发现，身体缩放使泛化的范围远大于固定身体类型的数据缩放。最好的训练策略能够在模拟和真实世界中零样本转移至未见过的身体类型，包括Unitree Go2和H1.", "conclusion": "该结果为通用载体智能迈出了重要一步，对于可配置机器人的适应性控制、形态共设计等具有重要意义。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.21034", "html_url": "https://arxiv.org/abs/2504.21034", "title": "SAGA: 一种治理AI代理系统的安全架构", "title_en": "SAGA: A Security Architecture for Governing AI Agentic Systems", "authors": "Georgios Syros,Anshuman Suri,Jacob Ginesin,Cristina Nita-Rotaru,Alina Oprea", "background": "随着大型语言模型（LLM）为基础的代理越来越多地自主地互相交互、协作和分配任务，而不需要过多的人为干预，行业指南强调用户需保持对其代理的全面控制，以减轻恶意代理带来的潜在损害。尽管提出了多种代理系统的设计方案来解决代理身份验证、授权和任务分配问题，但这些方案多为理论层面，没有实际实施和评估，特别是没有提供用户控制的代理管理功能。因此，迫切需要一种可扩展的安全架构来解决这些不足，尤其是让用户能够对其代理在整个生命周期中进行监督和管理的问题。", "innovation": "该论文提出了SAGA，一种可扩展的安全架构，用于治理AI代理系统，让用户对其代理的整个生命周期进行监督和管理。该架构要求用户通过“提供者”（Provider）机构对代理进行注册，该机构维护代理联系信息和用户定义的访问控制策略，并协助代理在相互代理通信时执行这些策略。SAGA引入了一种加密机制来生成细粒度的访问令牌，以确保代理在与其他代理交互时的控制力度，从而提供了正式的安全保证。评估结果显示，无论代理的地理位置如何，以及是在设备上还是云计算环境中使用LLM代理，SAGA都展示了最小的性能开销，且不损害底层任务的实用性，从而确保了代理系统的安全和可信赖部署，加速了这项技术在敏感环境中的负责任使用进程。", "conclusion": "SAGA架构确保了在广泛的条件下代理系统的安全和可靠部署，支持了在特定环境下自主代理的可信使用。该研究对于促进AI代理技术的负责任采用具有重要意义。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.10187", "html_url": "https://arxiv.org/abs/2504.10187", "title": "DeepTrans: 通过强化学习实现深度推理翻译", "title_en": "DeepTrans: Deep Reasoning Translation via Reinforcement Learning", "authors": "Jiaan Wang,Fandong Meng,Jie Zhou", "background": "近年来，深度推理的大语言模型（如OpenAI的o1和DeepSeek-R1）在各种下游任务中表现出有前途的表现。自由翻译是一个重要的、有趣的多语言任务，要求超越逐词翻译。然而，该任务在深度推理的大语言模型中依然研究不足。", "innovation": "本文介绍了一种深度推理翻译模型DeepTrans，该模型通过强化学习（RL）学习自由翻译。DeepTrans利用预定义的评分标准学习如何思考和自由翻译给定句子。并且，RL训练过程中无需任何标注的翻译数据，避免了大量的人工标注或数据合成。", "conclusion": "实验结果表明，使用Qwen2.5-7B作为基础模型，DeepTrans在文献翻译任务上的性能提高了16.3%，并在多个方面优于其他强大的深度推理大语言模型。此外，本文还总结了在RL探索过程中遇到的错误和有趣的发现。我们希望通过这项工作能够激发其他研究者在自由翻译方面的研究。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03401", "html_url": "https://arxiv.org/abs/2505.03401", "title": "DDaTR: 动态差异感知时间剩余网络在纵向放射报告生成中的应用", "title_en": "DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation", "authors": "Shanshan Song,Hui Tang,Honglong Yang,Xiaomeng Li", "background": "放射学报告生成（RRG）能够自动化从医学影像生成放射学报告，提升报告过程的效率。纵向放射学报告生成（LRRG）在此基础上进一步发展，通过比较当前和之前的检查，实现临床发现的时态变化跟踪。现有的LRRG方法依赖于视觉预训练编码器从之前的和当前的图像中提取特征，然后将这些特征连接起来生成最终报告，但在特征提取过程中难以有效捕捉空间和时间的相关性，导致提取的特征不能充分反映不同时段检查之间的信息差异，从而使LRRG任务的性能欠佳。", "innovation": "本文提出了一个新颖的动态差异感知时间剩余网络（DDaTR），在视觉编码器的每一个阶段引入了两个模块来捕捉多层次的空间相关性。DFAM（动态特征对齐模块）设计用于超过模态之间的先前特征对齐，确保优先临床信息的一致性。在此基础之上，动态差异感知模块（DDAM）通过确定检查之间的关系来捕捉有利的差异信息。此外，DDaTR利用动态剩余网络单向传递纵向信息，有效地建模时间相关性。", "conclusion": "大量实验结果表明，DDaTR在三个基准上的表现优于现有方法，证明了其在RRG和LRRG任务中的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject：针对Web代理的提示注入攻击", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "本文提出了一种利用多模态大型语言模型（MLLM）基于屏幕截图生成行动的Web代理进行交互的方法。一个新颖的攻击方法——WebInject，通过在网页渲染像素值中添加干扰，使Web代理执行攻击者指定的操作。该方法通过优化问题来寻找这种干扰，但由于从原始像素值到屏幕截图的映射是非可微的，这为求解该问题带来了挑战。作者提出训练一个神经网络来近似映射关系，并应用投影梯度下降来解决优化问题，从而提高了攻击的有效性。", "innovation": "本文介绍了WebInject，这是一种新的提示注入攻击方法，能够通过在屏幕截图的像素值中添加扰动，使Web代理执行攻击者指定的操作。为了克服非可微映射带来的挑战，作者采用神经网络近似映射并使用投影梯度下降来解决优化问题。", "conclusion": "通过在多个数据集上的广泛评估表明，WebInject攻击非常有效，并显著优于基线方法。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12072", "html_url": "https://arxiv.org/abs/2506.12072", "title": "TrueGL：全面堆栈搜索中可信、可靠且统一的学习引擎", "title_en": "TrueGL: A Truthful, Reliable, and Unified Engine for Grounded Learning in Full-Stack Search", "authors": "Joydeep Chandra,Aleksandr Algazinov,Satyam Kumar Navneet,Rim El Filali,Matt Laing,Andrew Hanna", "background": "在信息开放和自由的时代，对人工智能的依赖正在形成一种令人担忧的趋势。目前的AI工具在评估信息的可信度和为评估提供解释方面存在困难。因此，用户需要系统来评估在线信息的信任度。虽然主要的搜索引擎整合了AI功能，但它们通常缺乏明确的可靠指标。为了应对这一需求，我们提出了一种名为TrueGL的模型，该模型能够提供可信的搜索结果。该模型基于IBM的Granite-1B进行微调，并用定制的数据集训练，然后集成到具有可靠性评分系统的搜索引擎中。", "innovation": "TrueGL是一个微调过的版本的IBM的Granite-1B模型，经过定制数据集的训练，集成到搜索引擎中，并结合了可靠性评分系统。该模型通过指令工程评估系统，并为每个陈述分配一个从0.1到1的连续可靠性评分，同时返回与评分相关的文字解释。评估结果显示，TrueGL在所有关键指标上的表现优于其他小型语言模型和基于规则的方法，如MAE、RMSE和R2。该模型的高准确度、广泛的内容覆盖率和使用便捷性，使得可信信息更加易于获取，有助于减少网上错误或误导信息的传播。", "conclusion": "TrueGL模型的成功证明，它提高了可信信息的可访问性，并有助于减少在线错误或误导性内容的传播。该模型已在github页面上公开发布，以促进进一步的研究和发展。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.12321", "html_url": "https://arxiv.org/abs/2506.12321", "title": "超出频率：冗余在大型语言模型记忆中的作用", "title_en": "Beyond Frequency: The Role of Redundancy in Large Language Model Memorization", "authors": "Jie Zhang,Qinghua Zhao,Chi-ho Lin,Zhongfeng Kang,Lei Li", "background": "大型语言模型的大规模应用带来了隐私和公平性上的关键风险。尽管之前的研究所表明，记忆程度与诸如token频率和重复模式等因素存在相关性，但本研究揭示了独特的响应模式：token频率对已记忆样本的影响微乎其微，而对未记忆样本的影响则显著，这种一致性在不同规模的模型中都可观察到。", "innovation": "通过反事实分析的方法，通过对样本前缀进行扰动并量化通过token位置变化的扰动强度，研究发现冗余与记忆模式相关。研究结果表明：约79%的已记忆样本是低冗余的，这些低冗余样本比高冗余样本的脆弱性高两倍，因此在进行扰动时，已记忆样本减少0.6，而非记忆样本则仅减少0.01，这意味着更冗余的内容不仅更易被记住，而且也更脆弱。", "conclusion": "研究发现表明潜在冗余指导的方法可以用于数据预处理，这有望降低隐私风险并减轻歧视，确保模型部署中的公平性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.03077", "html_url": "https://arxiv.org/abs/2505.03077", "title": "动态操作的潜在自适应规划器", "title_en": "Latent Adaptive Planner for Dynamic Manipulation", "authors": "Donghun Noh,Deqian Kong,Minglu Zhao,Andrew Lizarraga,Jianwen Xie,Ying Nian Wu,Dennis Hong", "background": "本文介绍了 Latent Adaptive Planner (LAP)，一种用于动态非抓取操作（例如盒子接住）的轨迹级别潜在变量策略。它将规划问题形式化为低维潜在空间中的推理过程，并能有效地从人类示范视频中学习。LAP通过在执行过程中维护潜在计划的后验并进行变分重规划来实现实时适应。", "innovation": "为解决人类和机器人之间身体差异的问题，引入了基于模型的分比例映射模型，能够从人类示范中再生准确的关节状态和物体位置。LAP在变化的物体属性下进行盒子接住实验，展现出更高的成功率、更平滑的轨迹和更高的能效。LAP通过学习类似人类的顺应性动作和适应性行为，实现了实时适应能力，并成功跨不同机器人平台上进行演示。", "conclusion": "LAP能够实现实时适应的动态操作，并能够使用相同的示范视频成功地在同一类型上进行转移，实现了更高级别的动态操控能力。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15683", "html_url": "https://arxiv.org/abs/2505.15683", "title": "FedSEA-LLaMA：一种安全、高效和自适应的大语言模型联邦拆分框架", "title_en": "FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models", "authors": "Zishuai Zhang,Hainan zhang,Weihua Li,Qinnan zhang,jin Dong,Yongxin Tong,Zhiming Zheng", "background": "私人数据因其高质量具有提升大型语言模型（LLM）的潜力，但由于这些数据分散存储在数据孤岛中以及LLM高计算需求限制了它们在联邦环境中的部署。因此，提出了基于变压器的联邦拆分模型，将大部分模型参数卸载到服务器（或分布式客户端）上，仅保留一小部分在客户端以确保数据隐私。然而，这种设计仍然面临挑战：1）Peer-to-Peer密钥加密难以安全传输向量；2）LLM自回归性使得联邦拆分学习只能顺序进行，导致高通信开销；3）固定分割点缺乏针对下游任务的适应性。", "innovation": "本文提出了FedSEA-LLaMA，一种基于LLaMA2的安全、高效和自适应联邦拆分框架。主要创新点包括：1）在前向传播隐藏状态中注入高斯噪声，以实现端到端向量的安全传输；2）采用注意力掩码压缩和KV缓存合作以减少通信成本，加速训练和推理；3）允许用户根据具体任务需求动态调整输入/输出块的分割点。", "conclusion": "实验结果表明，FedSEA-LLaMA在自然语言理解、总结和对话式QA任务中保持与集中式LLaMA2相当的性能，并且在训练和推理中分别实现了高达8倍的速度提升。进一步分析隐私攻击和不同的分割点表明，FedSEA-LLaMA在安全性和适应性方面是有效的。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.23197", "html_url": "https://arxiv.org/abs/2505.23197", "title": "具自适应安全性和优化性的统一路径规划器", "title_en": "Unified Path Planner with Adaptive Safety and Optimality", "authors": "Jatin Kumar Arora,Soutrik Bandyopadhyay,Shubhendu Bhasin", "background": "自主机器人的路径规划面临优化性和安全性的根本权衡。传统算法通常会优先考虑其中一个目标。", "innovation": "提出了一个统一框架——统一路径规划器（UPP），它同时解决了优化性和安全性的两个目标。UPP 是一种基于图搜索的算法，使用了结合了动态安全成本的修改后的启发式函数，从而使路径长度和障碍物清除之间的平衡变得可调。", "conclusion": "广泛的仿真实验表明，UPP 能够生成接近最优路径，同时仅比传统的 A* 算法成本略有增加，而且能确保接近经典 Voronoi 规划者的安全标准。最终还通过 TurtleBot 硬件实现验证了 UPP 的实用性，证实了它能在复杂环境中安全地生成近优路径。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "量化LLM公平性超越词汇：从语义和统计的角度", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "大型语言模型（LLMs）经常生成具有内在偏见的回应，这削弱了它们在真实世界应用中的可靠性。现有的评估方法往往忽视了LLM长形式回应中的偏见以及输出的固有差异性。", "innovation": "本文提出了FiSCo（细粒度语义比较），这是一种新颖的统计框架，用于通过检测不同人口群体之间长形式回应中微妙的语义差异来评估LLM的群体公平性。与之前侧重于情感或词汇级比较的工作不同，FiSCo在语句级别进行操作，利用蕴含检查来评估响应间意义的一致性。通过将模型输出分解为语义上不同的语句并应用统计假设检验来比较群体间和群体内的相似性，从而实现对微妙偏见的稳健检测。", "conclusion": "本文通过正式化一个新的群体反事实公平定义并验证FiSCo在涵盖性别、种族和年龄的合成数据集和人工标注数据集上，证明了FiSCo可以更可靠地识别微妙偏见，同时减少LLM随机性的影响，并优于各种评估指标。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.15689", "html_url": "https://arxiv.org/abs/2506.15689", "title": "BASE-Q: 改进旋转量化方法的偏差修正和非对称缩放增强旋转量化方法用于大型语言模型", "title_en": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "authors": "Liulu He,Shenli Zheng,Karwei Sun,Yijiang Liu,Yufei Zhao,Chongkang Tan,Huanrui Yang,Yuan Du,Li Du", "background": "旋转已经成为了大型语言模型（LLMs）先进量化管道中不可或缺的一部分，通过有效平滑权重和激活中的异常值来实现。然而，进一步优化旋转参数仅能提供有限的性能提升，并且引入了显著的训练开销：由于旋转参数共享，整个模型必须同时加载以允许反向传播，这导致了内存消耗的大幅增加，限制了其实用性.", "innovation": "该工作识别了当前旋转量化方法的两个基本局限：（i）旋转无法对齐通道均值，导致量化边界更宽和增加舍入误差；（ii）旋转使激活分布变得更为高斯化，增加了由剪裁误差造成的能量损失。为了解决这些问题，我们提出了BASE-Q，这是一种简单而强大的方法，结合偏差修正和非对称缩放以有效减少舍入和剪裁误差。此外，BASE-Q 允许块级优化，消除了内存密集型的全模型反向传播的需求.", "conclusion": "在多种LLMs和基准上的广泛实验表明，BASE-Q 的有效性，它将精度差距分别缩小至全精度模型的50.5%、42.9%和29.2%，与QuaRot、SpinQuant和OSTQuant相比。代码不久后将发布."}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.14054", "html_url": "https://arxiv.org/abs/2506.14054", "title": "ScIReN：发现碳循环及其他领域中隐藏关系的科学解释推理网络", "title_en": "Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond", "authors": "Joshua Fan,Haodi Xu,Feng Tao,Md Nasim,Marc Grimson,Yiqi Luo,Carla P. Gomes", "background": "了解土壤中碳的流动对于缓解气候变化至关重要。虽然土壤能通过固碳作用从大气中吸收碳，但人们对土壤碳循环的理解仍然不足。科学家们基于现有知识建立了土壤碳循环的过程模型，但在设置众多未知参数时使用了非科学的方法，且经常不能很好地拟合观测数据。另一方面，神经网络可以学习数据中的模式，但它们不尊重已知的科学定律，且由于其黑箱性质无法揭示新的科学关系。因此，提出了一个完全透明的框架——科学可解释推理网络（ScIReN），该框架结合了可解释的神经网络和过程模型推理。Enc: 预测科学意义上重要的潜在参数，这些参数通过可微的过程模型解码器传递，预测有标签的输出变量。", "innovation": "ScIReN 使用Kolmogorov-Arnold网络确保编码器完全可解释，揭示输入特征与潜在参数之间的关系；采用新颖的平滑惩罚平衡表达能力和简约性；使用新颖的硬标压约束层限制潜在参数在科学先验知识定义的有意义范围内。过程模型解码器实施已建立的科学知识，KAN编码器揭示了传统黑箱模型中隐藏的新的科学关系。论文在模拟土壤中有机碳流动和植物生态系统呼吸两个任务上应用ScIReN，结果显示ScIReN在预测准确性上超过黑箱网络，提供了显著的科学可解释性——它可以推断出潜在的科学机制及其与输入特征的关系。", "conclusion": "ScIReN 能够在保持理论解释力的前提下提高预测准确性，是解决土壤碳循环问题的有效工具。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.05137", "html_url": "https://arxiv.org/abs/2507.05137", "title": "通过期望最大化实现易解释的汉字学习助忆词生成", "title_en": "Interpretable Mnemonic Generation for Kanji Learning via Expectation-Maximization", "authors": "Jaewook Lee,Alexander Scarlatos,Andrew Lan", "background": "对于来自罗马字母背景的学习者来说，由于书写系统差异，学习日语词汇是一项挑战。日语结合了假名如ひらがな和源自汉语的表意字符漢字。漢字因其复杂性和数量庞大而更加复杂。现有的助记词生成策略通常利用汉字的组成部分形成生动的关联，但现有的大语言模型辅助方法在助记词生成中功能上更像是一个黑盒，缺乏可解释性。", "innovation": "本文提出了一种生成框架，该框架在一组常见的规则驱动下明确建模助记词构造过程，并通过一种新颖的期望最大化类型算法学习这些规则。利用在线平台上的学习者生成的助记词进行训练，该方法能够学习潜在结构和组合规则，使助记词生成成为有解释性和系统性的过程。实验表明，在新学习者冷启动设置中，该方法表现出色，还能揭示有效助记词创建机制背后的原理。", "conclusion": "该研究成功地将期望最大化算法用于解释性助记词生成，提高了助记词生成的理解性和系统性，特别是在学习汉字符时，有助于新学习者的有效学习。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13611", "html_url": "https://arxiv.org/abs/2506.13611", "title": "一种用于电力系统闪变估计的混合人工智能方法", "title_en": "A Hybrid Artificial Intelligence Method for Estimating Flicker in Power Systems", "authors": "Javad Enayati,Pedram Asef,Alexandre Benoit", "background": "本文介绍了一种结合H滤波器和自适应线性神经元网络的新型混合AI方法，用于电力分配中的闪变成分估计。该方法利用H滤波器在不确定和噪声条件下的鲁棒性提取电压包络，然后使用ADALINE准确识别嵌入在其中的闪变频率。这种协同作用使时间域估计变得高效，并具有快速收敛和抗噪性，解决了现有频域技术的一些关键局限性。该混合AI模型可以在没有预先知道噪声特性或进行广泛研究的情况下处理复杂的电力干扰。我们通过基于IEC标准61000 4-15进行的仿真研究，辅以统计分析、蒙特卡洛模拟和真实世界验证，证明了该方法在准确性、鲁棒性和计算负荷方面优于基于快速傅里叶变换和离散小波变换的估计器。", "innovation": "该研究提出了一种创新的混合AI方法，结合了H滤波器和ADALINE，能够高效准确地估计闪变成分，特别适合处理复杂电力干扰。该方法具有快速收敛和高鲁棒性，且无需了解噪声特性和进行广泛研究。通过与传统频域技术对比，展示了这种方法在实际应用中的优势。", "conclusion": "通过详细的仿真研究和与快速傅里叶变换和离散小波变换方法的对比分析，该研究证明了提出的方法在估计电力系统中的闪变成分方面具有显著优势，具有更高的准确性、更好的鲁棒性和更低的计算负荷。该方法能够有效处理复杂的电力干扰，为电力系统的可靠运行提供了有力支持。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08730", "html_url": "https://arxiv.org/abs/2507.08730", "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "title_en": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "authors": "Zezhen Xiang,Jingzhi Gong,Tao Chen", "background": "现代可配置软件系统需要学习与配置和性能相关联的模型。然而，当系统在动态环境中运行时，工作负载变化、硬件变化和系统更新会不可避免地在不同层级上引入概念漂移——全局漂移重塑整个配置空间的性能图景；局部漂移仅影响该空间中的某些子区域。现有的离线和迁移学习方法难以实时适应这些隐含和不可预测的变化，从而使配置性能学习变得具有挑战性。", "innovation": "本文提出了DHDA（Dually Hierarchical Drift Adaptation），这是一种在线配置性能学习框架，旨在捕捉并适应不同层级的漂移。DHDA通过双重层级适应来应对局部和全局漂移：在较高层次上，重新划分数据集，以在必要时仅处理全局漂移；在较低层次上，各子区域内的局部模型能够检测并异步适应局部漂移。为了在响应性和效率之间取得平衡，DHDA结合增量更新和周期性完整重训练，以在未检测到漂移时最小化冗余计算。", "conclusion": "通过评估八个软件系统并与最先进的方法进行对比，我们展示了DHDA在准确性和适应漂移方面取得了显著的改进——最高可达两倍的提升，同时产生了合理的开销，并能够改进不同局部模型以处理概念漂移。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.08340", "html_url": "https://arxiv.org/abs/2507.08340", "title": "基于Dirac重平衡器和分布纠缠的单域泛化在多模态跨癌症预后中的应用", "title_en": "Single Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement", "authors": "Jia-Xuan Jiang,Jiashuai Liu,Hongtao Wu,Yifeng Wu,Zhong Wang,Qi Bi,Yefeng Zheng", "background": "深度学习在多模态数据生存预测中表现出显著性能。然而，现有的多模态方法主要集中在单一癌症类型上，忽视了跨癌症情境下的泛化挑战。本研究揭示了跨癌症情境中，多模态预后模型泛化性能往往劣于单模态模型，尤其是在临床实践中需要此类稳健性时更为明显。本文首次提出了跨癌症单一领域泛化多模态预后的新任务，旨在评估在单一癌症类型上训练的模型是否能在未见癌症类型上泛化。研究指出，特征降级和多模态融合不力是主要原因。这一新任务和方法为跨癌症的多模态预后的实际、稳健应用奠定了基础。", "innovation": "提出了跨癌症单一领域泛化多模态预后的新任务，以及两个新的模块：稀疏狄拉克信息重平衡器（SDIR）和癌症感知分布纠缠（CADE）。SDIR通过基于伯努利的稀疏化和狄拉克启发的稳定化来减轻强特征的支配，从而增强较弱模式的信号。CADE则通过在潜在空间中融合局部形态度量和全局基因表达来合成目标域分布。实验验证了所提出方法的优越泛化性能。", "conclusion": "本文的工作揭露了跨癌症情境下多模态预后模型泛化性能的局限性，并通过引入新的模块（SDIR和CADE）解决了这一问题。实验结果表明，所提出的方法在多癌症类型的基准上具有更好的泛化性能，为实际、稳健的跨癌症多模态预后提供了基础。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.15066", "html_url": "https://arxiv.org/abs/2507.15066", "title": "Time-RA：使用LLM反馈实现时间序列异常推理", "title_en": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "authors": "Yiyuan Yang,Zichuan Liu,Lei Song,Kai Ying,Zhiguang Wang,Tom Bamford,Svitlana Vyetrenko,Jiang Bian,Qingsong Wen", "background": "时间序列异常检测在多个领域至关重要，但当前方法通常仅限于进行简单的异常二元分类，缺乏详细的分类或进一步的解释性推理。", "innovation": "该研究提出了一项新的任务，名为Time-series Reasoning for Anomaly（Time-RA），将传统的时间序列异常检测从判别任务转变为生成型、重推理的任务，并利用大型语言模型（LLMs）。此外，该研究还首次引入了一个名为RATs40K的实际多模态基准数据集，该数据集针对异常推理进行了明确标注，包含约40,000个样本，覆盖了10个实际领域。每个样本包括数字时间序列数据、上下文文本信息和视觉表示，并且每个样本都进行了精细分类（单变量异常14种类型，多变量异常6种类型）和结构化的解释性推理的标注。", "conclusion": "该研究的数据集和任务为可解释的时间序列异常检测和推理提供了新的方向，并证明了当前模型的能力和局限性，强调了监督微调的重要作用。研究成果的代码和数据集已完全开源，以支持并加速该领域的未来研究。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.05625", "html_url": "https://arxiv.org/abs/2505.05625", "title": "SPIN-ODE: 物理启发的刚性神经常微分方程在化学反应速率估计中的应用", "title_en": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation", "authors": "Wenqing Peng,Zhi-Song Liu,Michael Boy", "background": "从复杂的化学反应中估计速率系数对于推进详细化学研究至关重要。然而，真实世界大气化学系统固有的刚性特征导致了训练过程的不稳定性和收敛性差，阻碍了基于学习方法的有效速率系数估计。", "innovation": "我们提出了一个称为SPIN-ODE的刚性物理启发神经常微分方程框架，用于化学反应建模。该方法采用了三阶段优化过程：首先，使用黑盒神经常微分方程拟合浓度轨迹；其次，预训练化学反应神经网络(CRNN)以学习浓度与其时间导数之间的映射；最后，通过与预训练的CRNN集成来微调速率系数。经过对合成数据集和新提出的现实世界数据集的广泛实验验证，我们的方法在有效性和鲁棒性方面表现出色。", "conclusion": "本研究是首次针对化学反应速率系数发现使用刚性神经ODE的工作，它为神经网络与详细化学的集成提供了有希望的方向。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.22612", "html_url": "https://arxiv.org/abs/2507.22612", "title": "自适应持续时间模型在文本语音对齐中的应用", "title_en": "Adaptive Duration Model for Text Speech Alignment", "authors": "Junjie Cao", "background": "语音到文本的对齐是神经文本到语音（TTS）模型的关键组成部分。自回归TTS模型通常使用注意力机制在线学习这些对齐，而非自回归的端到端TTS模型则依赖于从其他外部来源提取的持续时间。目前普遍采用的方法在预测和适应性方面存在局限，尤其是在发音级别的对齐准确性和零样本TTS模型对输入音频与提示音频之间不匹配的鲁棒性方面。因此，提出一种新的持续时间预测框架，以解决现有模型在发音级别的对齐准确性和适应性上的不足，提高零样本TTS模型的稳定性。", "innovation": "该论文提出了一种新颖的持续时间预测框架，能提供与给定文本相配的有前景的音素级持续时间分布。实验表明，提出的持续时间模型在精度和适应性方面优于之前的基本模型，特别是在音素级对齐精度和零样本TTS模型对输入音频与提示音频之间不匹配的鲁棒性方面取得了显著提高。", "conclusion": "该研究大大提高了TTS模型在发音级别的对齐质量，并增强了零样本TTS模型对输入音频与提示音频之间潜在不匹配的适应性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.06107", "html_url": "https://arxiv.org/abs/2508.06107", "title": "Mask & Match: 学习识别手写数学表达式的方法", "title_en": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "authors": "Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu", "background": "手写数学表达式识别（HMER）是一个具有挑战性的任务，因为它包含固有的二维结构、不同的符号比例和复杂的符号空间关系。现有的方法大多依赖于昂贵的标注数据。本文旨在通过提出一种自我监督学习（SSL）框架来解决这个问题，以减少对标注数据的依赖。", "innovation": "本文的主要贡献在于提出了一种新颖的自我监督注意力网络，该网络采用一种逐步的空间遮罩策略进行训练。该注意力机制能够在不需要任何监督的情况下学习到具有语义意义的集中区域，如运算符、指数和嵌套的数学符号。此外，文章还设计了一个完整的管道，包括自我监督预训练编码器、自我监督注意力学习以及使用变压器解码器进行有监督微调以生成LATEX序列。", "conclusion": "在CROHME基准测试中，本文的方法在自我监督学习和完全监督学习的基础上都表现出色，验证了逐步注意力机制在提高HMER性能方面的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.17178", "html_url": "https://arxiv.org/abs/2507.17178", "title": "SKA-Bench: 细粒度评估大语言模型结构化知识理解能力的基准", "title_en": "SKA-Bench: A Fine-Grained Benchmark for Evaluating Structured Knowledge Understanding of LLMs", "authors": "Zhiqiang Liu,Enpei Niu,Yin Hua,Mengshu Sun,Lei Liang,Huajun Chen,Wen Zhang", "background": "尽管大规模语言模型（LLMs）在理解结构化知识（SK，如KG和Table）方面取得了显著进步，但现有的评估方法并不严格（即缺乏对特定能力的评估），并且主要关注单一类型的SK。因此，本文旨在提出一个更全面和严格的结构化知识理解基准，以诊断LLMs的不足之处。本文介绍了一个结构化知识增强的问答基准SKA-Bench，包括四种广泛使用的结构化知识形式：KG、Table、KG+Text和Table+Text。通过一个三阶段的流程，本文构建了SKA-Bench的实例，包括问题、答案、正向知识单元和噪音知识单元。为细粒度评估LLMs的SK理解能力，本文扩展了实例，形成了四种基本能力测试床：噪音鲁棒性、排序无感性、信息整合和负面拒绝。实验评估表明，现有的LLMs在理解结构化知识方面仍面临重大挑战，其性能受到噪声量、知识单元顺序和幻觉现象等因素的影响。我们的数据集和代码可在指定链接获取。", "innovation": "本文提出了一个名为SKA-Bench的结构化知识增强的问答基准，涵盖了KG、Table、KG+Text和Table+Text四种结构化知识形式。通过一个三阶段的流程构建了包括问题、答案、正向知识单元和噪音知识单元的实例，并扩展了这些实例形成四种基本能力测试床，以细粒度评估LLMs的结构化知识理解能力。这些测试床可以直接评估LLMs在噪音鲁棒性、排序无感性、信息整合和负面拒绝方面的表现，从而为LLMs的结构化知识理解能力提供了全面的评估。", "conclusion": "现有的LLMs在理解结构化知识方面仍存在重大挑战，其性能受到噪声量、知识单元顺序和幻觉现象等因素的影响。SKA-Bench提供了一种更全面和严格的结构化知识理解基准，旨在诊断和提升LLMs在结构化知识处理方面的能力。我们的数据集和代码已公开，欢迎使用。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.11356", "html_url": "https://arxiv.org/abs/2508.11356", "title": "ETTRL: 通过熵机制在大语言模型测试时强化学习中平衡探索和利用", "title_en": "ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism", "authors": "Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu", "background": "大规模语言模型在复杂推理任务（如数学和编程）上取得了显著的进展，但这些模型仍然高度依赖于标注数据，并在无监督场景中的适应性有限。现有方法如测试时强化学习（TTRL）能够通过利用生成的伪标签实现自我优化，然而它面临着高推理成本和早期阶段估计偏误导致的过自信问题，这些问题会导致输出多样性降低和性能停滞不前。", "innovation": "文章介绍了一种基于熵的机制，通过两种策略（熵分叉树多数卷积ETMR和熵基优势重塑EAR）增强了测试时强化学习中的探索与利用平衡。这一创新方法使得Llama3.1-8B在AIME 2024基准测试中在Pass at 1指标上相较基线实现了68%的相对改进，同时仅消耗60%的重组令牌预算。这表明该方法有效优化了推理效率、多样性和估计稳健性之间的权衡，从而推动了开放领域推理任务中无监督强化学习的进步。", "conclusion": "本研究提出的方法克服了现有测试时强化学习方法的局限，通过引入熵机制有效优化了探索与利用之间的权衡，使得大语言模型在开放领域推理中的性能显著提升。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.14119", "html_url": "https://arxiv.org/abs/2508.14119", "title": "使用Fabric记录部署：一个实际应用中AI治理的数据库", "title_en": "Documenting Deployment with Fabric: A Repository of Real-World AI Governance", "authors": "Mackenzie Jorgensen,Kendall Brogle,Katherine M. Collins,Lujain Ibrahim,Arina Shah,Petra Ivanovic,Noah Broestl,Gabriel Piles,Paul Dongha,Hatim Abdulhussein,Adrian Weller,Jillian Powers,Umang Bhatt", "background": "学术界的文献大部分关注AI使用所带来风险和危害，本文通过介绍一个名为Fabric的公开存档库来概述实际应用中的AI治理机制。Fabric包含使用案例的可视化流程图和部署系统的描述，有助于了解实际应用中AI治理存在的空白和人类对部署AI系统的共同监督模式。", "innovation": "Fabric是一个集成了实际应用AI案例与其治理机制的开源数据库。通过半结构性访谈收集的初始20个AI使用案例以及与使用者共同设计的AI工作流程图，本文提出了有效的治理机制和监控护栏的讨论。Fabric的目的是作为一个可扩展的、不断发展的工具，供研究者研究AI治理的有效性，填补现有治理空白并发现使用者共同的监督模式。", "conclusion": "本文通过Fabric数据库表面了实际应用中AI治理的缺口，发现了部署AI系统中人类监督的常见模式，并意图使Fabric成为一个供研究者研究AI有效治理的可扩展工具。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15008", "html_url": "https://arxiv.org/abs/2508.15008", "title": "微控制器上量化神经网络：方法、平台和应用的全面回顾", "title_en": "Quantized Neural Networks for Microcontrollers: A Comprehensive Review of Methods, Platforms, and Applications", "authors": "Hamza A. Abushahla,Dara Varam,Ariel J. N. Panopio,Mohamed I. AlHajri", "background": "在资源受限的设备，如微控制器中部署量化神经网络（QNNs）引入了主要挑战，这些挑战涉及平衡模型性能、计算复杂性及内存限制。为应对这些挑战，Tiny Machine Learning（TinyML）通过整合机器学习算法、硬件加速和软件优化进步，旨在高效地将深度神经网络部署在嵌入式系统中。", "innovation": "本文提供了一种硬件为中心的方法来量化，系统地回顾了加速嵌入式应用中深度学习模型的关键量化技术。特别之处在于关注度理模型性能与硬件能力之间的权衡。", "conclusion": "回顾了支持微控制器上QNN执行的现有软件框架和硬件平台，分析了当前挑战，并概述了该领域在未来迅速发展的具有前景的研究方向。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16936", "html_url": "https://arxiv.org/abs/2508.16936", "title": "THEME: 提升主题投资的语义股票表示和时间动态", "title_en": "THEME: Enhancing Thematic Investing with Semantic Stock Representations and Temporal Dynamics", "authors": "Hoyoung Lee,Wonbin Ahn,Suhwan Park,Jaehoon Lee,Minjae Kim,Sungdong Yoo,Taeyoon Lim,Woohyung Lim,Yongjae Lee", "background": "主题投资旨在构建与结构性趋势一致的投资组合，但由于行业界限重叠和市场动态不断变化，这仍是一个具有挑战性的任务。一个有希望的方向是通过文本数据构建投资主题的语义表示。然而，通用的大规模语言模型（LLM）嵌入模型并不适合捕捉金融资产的具体特性，这可能与一般金融文本的语义表示有根本性差异。为此，该研究提出了THEME框架，通过对层次对比学习进行微调来构建嵌入。", "innovation": "THEME框架利用层次对比学习进行微调，通过股票的层次关系对主题和其组成股票进行对齐，并通过融入股票回报来进一步优化这些嵌入，从而有效地获取具有高回报潜力的主题一致资产。实证结果表明，THEME在主题资产检索方面显著优于领先的大型语言模型，并且其构建的投资组合展现出令人信服的性能。", "conclusion": "通过同时建模文本中的主题关系和回报反馈的市场动态，THEME生成了特别适于各种投资应用的股票嵌入。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12263", "html_url": "https://arxiv.org/abs/2508.12263", "title": "区域级上下文感知多模态理解", "title_en": "Region-Level Context-Aware Multimodal Understanding", "authors": "Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao", "background": "尽管在多模态大型语言模型（MLLMs）方面取得了显著进展，大多数研究主要集中在一般的视觉理解上，忽略了结合与物体相关文本上下文以实现更具有上下文感知的多模态理解的能力。为此，本文通过提出区域级上下文感知多模态理解（RCMU）任务来填补这一空白，该任务要求模型通过整合图像内容和区域或物体的文本信息来执行用户的指令。文章还指出，由于缺乏相关数据集，作者引入了RCMU数据集和RC&P-Bench评测平台，为评估模型的RCMU能力和多模态个性化理解提供了广泛的基础。此外，还提出了一种基于参考的评估指标，对区域级别的上下文感知图像描述进行了详细的评估。", "innovation": "本文的创新在于：1) 通过提供RCMU任务来填补对上下文感知多模态理解研究的空白；2) 发展了区域级上下文感知视觉指令调整（RCVIT）方法，使模型能够利用边界框坐标有效地关联物体的视觉和文本信息；3) 孕育了RCMU数据集和RC&P-Bench基准测试，为评估MLLMs在RCMU和多模态个性化理解任务中的性能提供了一个广泛的数据和测试环境。此外，还提出了一种基于参考的评估指标，对区域级别的上下文感知图像描述进行了详尽评估。", "conclusion": "通过在Qwen2-VL模型上进行RCVIT并使用RCMU数据集，开发了RC-Qwen2-VL模型。实验结果表明，这些模型不仅在多个RCMU任务中表现优异，而且在多模态RAG和个人化对话中也有成功的应用展示。数据、模型和基准可以在提供的链接中获取。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17196", "html_url": "https://arxiv.org/abs/2508.17196", "title": "BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens", "title_en": "BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens", "authors": "Hao Wen,Xinrui Wu,Yi Sun,Feifei Zhang,Liye Chen,Jie Wang,Yunxin Liu,Yunhao Liu,Ya-Qin Zhang,Yuanchun Li", "background": "大型语言模型（LLMs）通过增加推理时的计算来提升推理能力，尽管这在一定程度上有效，但也带来了延迟和资源成本的增加，限制了其在时间敏感或成本敏感的现实场景中的应用。", "innovation": "本文提出了一种名为BudgetThinker的新型框架，它通过在推理过程中周期性地插入特殊控制令牌来定期提醒模型其剩余的令牌预算，从而实现对推理过程长度的精确控制。该方法结合了一种监督微调和基于课程的强化学习的两阶段训练管道，以优化准确性和预算遵守。BudgetThinker在各种推理预算下，在具有挑战性的数学基准测试中显著超越了强有力的基线。", "conclusion": "BudgetThinker提供了一种可扩展且有效的解决方案，用于开发高效可控制的LLM推理，使其更加适用于资源受限和实时环境中的部署。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.12800", "html_url": "https://arxiv.org/abs/2508.12800", "title": "Atom-Searcher: 通过细粒度原子思考奖励增强自主深度研究", "title_en": "Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward", "authors": "Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Yuan Wang,Quanxing Zha,Sunhao Dai,Changhua Meng", "background": "大型语言模型（LLMs）在问题解决方面表现出色，但在处理复杂任务时受限于静态内部知识。检索增强生成（RAG）虽然能够增强外部信息的访问，但在多跳推理和策略性搜索方面仍然受到僵硬工作流程的限制。虽然近期的研究进展使LLMs能够自主地进行推理、搜索和信息合成，但当前依赖于基于结果的强化学习（RL）的方法存在关键问题，如梯度冲突和奖励稀疏性，这限制了性能提升和训练效率。", "innovation": "本文提出了原子思考（Atomic Thought），这是一种全新的LLM思考范式，将推理分解为细粒度的功能单元。还提出了一种名为Atom-Searcher的新颖RL框架，将原子思考和原子思考奖励（ATR）结合在一起。Atom-Searcher采用了类似于课程的奖励计划，在早期阶段优先处理过程层面的ATR，并逐步过渡到结果奖励，以加速高效推理路径的收敛。这种体系结构的优势包括：（1）Atom-Searcher在测试时可以缩放计算；（2）原子思考为RRMs提供了监督锚点，连接深度研究任务和RRMs；（3）Atom-Searcher表现出更可解释和类似人类的推理模式。", "conclusion": "实验在七个基准测试上表明，Atom-Searcher相比最先进的方法具有一致的改进。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17128", "html_url": "https://arxiv.org/abs/2508.17128", "title": "CE-RS-SBCIT 一种增强通道的混合CNN-Transformer框架，具有残差、空间和边界意识学习，用于脑肿瘤MRI分析", "title_en": "CE-RS-SBCIT A Novel Channel Enhanced Hybrid CNN Transformer with Residual, Spatial, and Boundary-Aware Learning for Brain Tumor MRI Analysis", "authors": "Mirza Mumtaz Zahoor(1),Saddam Hussain Khan(2) ((1) Faculty of Computer Sciences, Ibadat International University, Islamabad, Pakistan (2) Artificial Intelligence Lab, Department of Computer Systems Engineering, University of Engineering and Applied Sciences (UEAS), Swat, Pakistan)", "background": "脑肿瘤仍然是人类中最致命的疾病之一，早期检测和准确分类对于有效诊断和治疗计划至关重要。尽管基于深度学习的计算机辅助诊断（CADx）系统取得了显著进展，但传统的卷积神经网络（CNN）和Transformer仍然面临着计算成本高、对细微对比度变化敏感、结构异质性和MRI数据中的纹理不一致性等持续挑战。", "innovation": "提出了一种名为CE-RS-SBCIT的新型混合框架，该框架结合了残差和空间学习驱动的CNN和Transformer驱动模块。该框架通过四种核心创新来利用局部精细和全局上下文线索：（i）一种平滑和边界基于的CNN-Transformer集成（SBCIT），（ii）定制的残差和空间学习CNN，（iii）通道增强（CE）策略，（iv）一种新型的空间注意机制。", "conclusion": "该SBCIT框架在Kaggle和Figshare提供的具有挑战性的MRI数据集（包含胶质瘤、脑膜瘤、垂体肿瘤和健康对照）上，经广泛评估后表现优越，分别取得了98.30%的准确率、98.08%的敏感性、98.25%的F1分数和98.43%的精确率。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.16665", "html_url": "https://arxiv.org/abs/2508.16665", "title": "信任验证！面向测试时缩放的验证设计综述", "title_en": "Trust but Verify! A Survey on Verification Design for Test-time Scaling", "authors": "V Venktesh,Mandeep Rathee,Avishek Anand", "background": "测试时间缩放（TTS）作为一种新的方法，正在推动大规模语言模型（LLM）性能的扩展。在TTS中，通过在推理过程中使用更多的计算资源，LLM可以在推理时提高其推理过程和任务性能。现有几种TTS方法，如从另一模型中提取推理轨迹，或通过使用验证器探索庞大的解码搜索空间。验证器作为奖励模型，有助于对解码过程中的候选输出进行评分，从而认真探索庞大的解空间并选择最佳结果。这些方法因其实现推理时无参数放缩并获得高性能增益而广受欢迎。验证器可以基于提示、微调为判别或生成模型来验证过程路径、结果或两者。尽管这些方法已经广泛应用，但很少有全面的汇集、清晰的分类和讨论，以及它们的训练机制。本文综述了文献中的各种验证方法，并提供了一个统一的验证器训练方法、类型及其在测试时缩放中的作用的视角。我们的仓库可访问此处：this https URL.", "innovation": "本文提供了一个综合视角，总结了各种验证方法及其训练机制，填补了验证技术在TTS中的理解和应用上的空白，为研究人员和实践者提供了系统性的资源和信息。与此同时，作者还呈现了一个可用于参考的验证器训练方法和类型相关的库，这有助于进一步研究和应用这些技术。", "conclusion": "本文综述了测试时缩放中验证方法的多样性，并提供了一个统一的视角，涵盖了验证器训练的多种方法、类型和其在测试时缩放中的用途。文章建设性的总结了现有验证器的研究成果，同时指出了未来的研究方向。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21083", "html_url": "https://arxiv.org/abs/2508.21083", "title": "CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples", "title_en": "CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples", "authors": "Kyohoon Jin,Juhwan Choi,Jungmin Yun,Junho Lee,Soojin Jang,Youngbin Kim", "background": "深度学习模型在训练数据中往往会学习并利用虚假关联，利用非目标特征进行预测。这种依赖导致模型在未见过的数据上的性能下降和泛化能力差。", "innovation": "该文提出了一种更为通用的形式的反向事实数据增强，称为反bias数据增强（CoBA），它可以同时解决多种偏差（如性别偏差、简化偏差），并增强模型对未知数据的鲁棒性。", "conclusion": "通过广泛的实验，该文证明CoBA不仅能提高下游任务的性能，还能有效减少偏差并增强对未知数据的抗性，为虚假关联带来的挑战提供了一个灵活且 robust 解决方案。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.17117", "html_url": "https://arxiv.org/abs/2508.17117", "title": "PlantVillageVQA：植物科学中评估视觉语言模型的视觉问答数据集", "title_en": "PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science", "authors": "Syed Nazmus Sakib,Nafiul Haque,Mohammad Zabed Hossain,Shifat E. Arman", "background": "PlantVillageVQA 是从广泛使用的 PlantVillage 图像库衍生出的一个大规模的视觉问答（VQA）数据集。它的设计目的是推动视觉语言模型在农业决策和分析中的发展和评估。", "innovation": "1. 数据集包含193,609对高质量的问题-答案（QA）对，覆盖55,448张图片、14种作物和38种疾病状况。\n2. 问题被组织为3个认知复杂度级别和9个不同的类别。\n3. 问题通过手动根据专家指导和自动化的两阶段管道生成：模板基础的QA合成从图像元数据出发，再进行多阶段的语言重构。\n4. 数据集由领域专家逐次审查以保证科学准确性和相关性。", "conclusion": "本数据集旨在提供一个公开、标准化和专家验证的数据库，以提高植物疾病诊断的准确性，并促进农业领域的研究。该数据集将在此开源：this https URL"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.18124", "html_url": "https://arxiv.org/abs/2508.18124", "title": "CMPhysBench: 用于评估大型语言模型在凝聚态物理学中的基准", "title_en": "CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics", "authors": "Weida Wang,Dongchen Huang,Jiatong Li,Tengchao Yang,Ziyang Zheng,Di Zhang,Dong Han,Benteng Chen,Binzhao Luo,Zhiyu Liu,Kunling Liu,Zhiyuan Gao,Shiqi Geng,Wei Ma,Jiaming Su,Xin Li,Shuchen Pu,Yuhan Shui,Qianjia Cheng,Zhihao Dou,Dongfei Cui,Changyong He,Jin Zeng,Zeke Xie,Mao Su,Dongzhan Zhou,Yuqiang Li,Wanli Ouyang,Yunqi Cai,Xi Dai,Shufei Zhang,Lei Bai,Jinguang Cheng,Zhong Fang,Hongming Weng", "background": "目前存在一个缺口，即大型语言模型（LLMs）在凝聚态物理学领域的实际问题解决能力尚未得到充分评估。传统的解决方法往往过于简单或缺少能够真实反映物理学解题过程的复杂性。CMPhysBench旨在填补这一空白，提供一个专门针对LLMs的新型基准测试。", "innovation": "CMPhysBench包含超过520个研究生级别的高质量问题，涵盖了多种凝聚态物理学亚领域和基本理论框架。它特别侧重于解题过程的理解，要求LLMs独立生成完整的解决方案。此外，该基准引入了基于树状表示的可扩展表达式编辑距离（SEED）评分，提供细粒度的半二进制分数，并能更准确地评估预测与真实值之间的相似性。", "conclusion": "即使是目前表现最佳的模型Grok-4，在CMPhysBench上的平均SEED分为36，准确率也只有28%，说明这些模型在实际的应用，在凝聚态物理学领域中有巨大的能力差距。该研究得出了传统物理与现代大型语言模型之间能力差距的结论。SEED和CMPhysBench的代码和数据集已公开。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19660", "html_url": "https://arxiv.org/abs/2508.19660", "title": "全面进化逼近的任意精度印刷三进制神经网络", "title_en": "Arbitrary Precision Printed Ternary Neural Networks with Holistic Evolutionary Approximation", "authors": "Vojtech Mrazek,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Zdenek Vasicek,Mehdi B. Tahoori,Georgios Zervakis", "background": "印刷电子技术因其灵活性、伸缩性、顺应性以及超低成本的集成制造等特点，为超越硅基系统的应用提供了有希望的选择。尽管印刷电子器件的特征尺寸较大，但印刷神经网络由于其在满足特定应用需求方面表现出色而受到关注，不过构建复杂的电路依然具有挑战性。这一研究工作填补了印刷神经网络分类精度和面积效率之间的鸿沟，涵盖从模数转换接口到数字分类器的整个处理-传感器系统设计和共优化过程，重点关注模数转换接口——这是一个主要的面积和能耗瓶颈。", "innovation": "提出了一种自动化设计方法，用于构建具备任意输入精度的印刷三进制神经网络，采用了多目标优化和全面近似策略。与现有的近似印刷神经网络相比，在面积和功耗方面分别提高了17倍和59倍，首次实现了在不到5%准确性损失的情况下，具备印刷电池供电能力的操作。", "conclusion": "这些电路在模数接口成本方面的考虑使本工作中的印刷-电池供电操作成为可能，而这一成果显著提高了印刷神经网络的实际应用能力和能效。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19637", "html_url": "https://arxiv.org/abs/2508.19637", "title": "邀请论文：用于极端边缘医疗保健的混合信号智能柔性可穿戴设备的特征到分类器协同设计", "title_en": "Invited Paper: Feature-to-Classifier Co-Design for Mixed-Signal Smart Flexible Wearables for Healthcare at the Extreme Edge", "authors": "Maha Shatta,Konstantinos Balaskas,Paula Carolina Lozano Duarte,Georgios Panagopoulos,Mehdi B. Tahoori,Georgios Zervakis", "background": "柔性电子（FE）提供了与刚性硅基硬件相比的有希望的替代方案，适用于可穿戴健康监护设备，能够实现轻巧、贴合和低成本的系统。然而，FE的有限集成密度和较大的特征尺寸限制了它们的使用范围，并对基于机器学习的健康监护系统的集成提出了严格的面积和功率约束，尤其是在集成模拟前端、特征提取和分类器时。现有的FE解决方案往往忽视了系统级的解决方案，仅关注分类器，忽视了特征提取和模拟-数字转换器（ADC）硬件成本的重大影响，这些都是面积和功率消耗的主要因素。", "innovation": "本文提出了一种混合信号从特征到分类器的协同设计框架，专门用于柔性智能可穿戴系统。本文设计了第一款用于FE的模拟特征提取器，显著减少了特征提取成本。进一步提出了基于NAS启发的硬件感知特征选择策略，可以在机器学习训练过程中进行，从而实现高效的应用特定设计。", "conclusion": "我们的评估表明，该方法适用于医疗保健基准，提供高度准确、高超面积效率的柔性系统，非常适合一次性低功耗可穿戴监测使用。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21098", "html_url": "https://arxiv.org/abs/2508.21098", "title": "TrInk: 使用Transformer网络进行墨水生成", "title_en": "TrInk: Ink Generation with Transformer Network", "authors": "Zezhong Jin,Shubhang Desai,Xu Chen,Biyi Fang,Zhuoyi Huang,Zhe Li,Chong-Xin Gan,Xiao Tu,Man-Wai Mak,Yan Lu,Shujie Liu", "background": "一直以来，墨水生成模型在手写体生成任务中面临着如何精确捕捉输入文本与生成的墨迹点之间关系的挑战。传统的模型往往难以有效建立全局依赖关系，导致生成的手写体在可读性和风格一致性上存在不足。", "innovation": "本文提出了一种基于Transformer的模型TrInk，通过引入缩放位置嵌入和高斯记忆掩码等技术，有效地捕捉了全局依赖关系，提升了输入文本与生成的笔画点之间的对齐度。此外，本文还设计了主观和客观评估管道，全面评估生成手写体的可读性和风格一致性。", "conclusion": "实验结果表明，基于Transformer的TrInk模型在IAM-OnDB数据集上较之前的模型实现了字符错误率（CER）降低35.56%和词错误率（WER）降低29.66%的效果。我们还提供了TrInk和baseline模型的手写样本演示页面。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21084", "html_url": "https://arxiv.org/abs/2508.21084", "title": "跨代际映射有毒评论：德国公共广播的数据集", "title_en": "Mapping Toxic Comments Across Demographics: A Dataset from German Public Broadcasting", "authors": "Jan Fillies,Michael Peter Hoffmann,Rebecca Reichel,Roman Salzwedel,Sven Bodemer,Adrian Paschke", "background": "现有的有毒言论数据集缺乏人口统计学背景，限制了我们对不同年龄段在网上交流方式的理解。本研究与德国公共服务内容网络funk合作，首次创建了一个大型的德国数据集，该数据集被注释为有毒，并包含了平台提供的年龄估计值。数据集包括来自Instagram、TikTok和YouTube的3,024个人工注释和30,024个LLM注释的匿名评论，这些评论经过聚合处理，按预定义的有毒关键词整理，最终有16.7%被标记为有问题。", "innovation": "该研究创新之处在于引入了一个注释为有毒行为的大型德国数据集，结合了人类专家和最新的语言模型进行注释，还提供了平台提供的年龄估计值。研究发现不同年龄段的用户在有毒言论模式上存在差异。", "conclusion": "该数据集为研究不同人口统计学群体中的语言变化提供了新的机会，并支持开发更多公平和年龄段意识的内容审核系统。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21206", "html_url": "https://arxiv.org/abs/2508.21206", "title": "通过像素化方法增强自回归语言模型对抗字符攻击的鲁棒性", "title_en": "Enhancing Robustness of Autoregressive Language Models against Orthographic Attacks via Pixel-based Approach", "authors": "Han Yang,Jian Lan,Yihong Liu,Hinrich Schütze,Thomas Seidl", "background": "自回归语言模型对字符攻击（orthographic attacks）非常脆弱，输入文本被多语言字母表中的字符篡改后会显著降低模型性能。这一缺陷根源在于子词分词器（subword tokenizers）和其嵌入（embeddings）中存在的词汇表之外的问题。", "innovation": "该研究提出了一种基于像素的生成语言模型，用像素化表示替换基于文本的嵌入，通过将单词渲染成单独的图像来增强模型对噪声输入的鲁棒性，并且兼容多种语言文本和不同的书写系统。", "conclusion": "该方法在多语言LAMBADA数据集、WMT24数据集和SST-2基准测试中被评估，展示了其对字符噪声的抗性和在多语言设置的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.19563", "html_url": "https://arxiv.org/abs/2508.19563", "title": "Robustness is Important: Limitations of LLMs for Data Fitting", "title_en": "Robustness is Important: Limitations of LLMs for Data Fitting", "authors": "Hejia Liu,Mochen Yang,Gediminas Adomavicius", "background": "大型语言模型（LLMs）被广泛应用于各种场景，不仅仅是传统的语言处理任务。它们还可以作为即插即用的方法来拟合数据并生成预测。以往的研究表明，通过上下文学习或监督微调，LLMs 在预测性能方面可以与许多表格监督学习技术相媲美。然而，本文指出使用 LLMs 进行数据拟合存在一个关键问题，即对与核心学习任务无关的数据表示进行更改，可以在相同的条件下导致 LLMs 的预测结果发生巨大改变。例如，简单地改变变量名称，某些情况下可以导致预测误差增大82%。这种对与任务无关的变化的敏感性存在于上下文学习和监督微调中，对于封闭权重和开放权重的一般用途的 LLMs 都有体现。此外，通过对开放权重 LLM 的注意力评分进行检查，发现了一种不均匀的注意力模式：提示中占据特定位置的训练示例和变量名称/值在生成输出标记时会受到更多的关注，尽管不同位置应受到大致相同的关注。这也部分解释了在存在与任务无关的变化时的这种敏感性。尽管最新的表格基础模型（TabPFN）专门为此类任务设计，具备预测稳健性，但仍然对与任务无关的变化不免疫。因此，尽管 LLMs 在预测方面表现出色，但它们目前缺乏基本的稳健性，不能作为有力的数据拟合工具使用。", "innovation": "文章通过检验开放权重 LLM 的注意力评分，发现了一种不均匀的注意力模式，即在生成输出标记时，提示中特定位置的训练示例和变量名称/值会受到更多的关注，尽管不同位置应受到大致相同的关注。这种方法解释了在存在与任务无关的变化时的敏感性。此外，文章还发现，专为数据拟合设计的最先进表格基础模型（TabPFN）尽管具备预测稳健性，但仍受到与任务无关的变化的影响。", "conclusion": "尽管 LLMs 在预测方面表现出色，但它们目前缺乏基本的稳健性，不能作为有力的数据拟合工具使用。对与任务无关的变化的高敏感性是使用 LLMs 进行数据拟合的主要限制之一（尽管 TabPFN 也存在此问题）。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21085", "html_url": "https://arxiv.org/abs/2508.21085", "title": "Granite Embedding R2 Models", "title_en": "Granite Embedding R2 Models", "authors": "Parul Awasthy,Aashka Trivedi,Yulong Li,Meet Doshi,Riyaz Bhat,Vignesh P,Vishwajeet Kumar,Yushu Yang,Bhavani Iyer,Abraham Daniels,Rudra Murthy,Ken Barker,Martin Franz,Madison Lee,Todd Ward,Salim Roukos,David Cox,Luis Lastras,Jaydeep Sen,Radu Florian", "background": "论文背景在于为企业规模的密集检索应用开发高性能的英语编码嵌入模型。第一代模型已经发布，但现在提出了第二代模型，旨在提供显著改进，包括扩展的上下文长度、多领域的领先性能和相对竞争对手19-44%的速度优势，同时保持更高的准确性。第二代模型包括双编码器和交叉编码器架构，配备了高效的检索模型和排序模型，训练数据全面适配企业需求并受到治理监督。", "innovation": "论文创新之处在于开发了Granite Embedding R2模型系列，该系列模型实现了以下创新：1) 扩展的上下文长度（8,192个标记），2) 在多种检索领域（文本、代码、长文档搜索、多轮对话、表格数据）上达到领先性能，3) 相对领先竞争对手的速度优势，4) 专为企业数据训练，并且模型架构包括双编码器和交叉编码器，具体的层数和高效性得到了强调，5) 全部训练数据都经过严格的治理审查。所有这些性能改进使得模型在标准基准、IBM的评估套件以及实际企业用例中表现出色，重新定义了开源嵌入模型的标准。", "conclusion": "结论是Granite R2模型系列在性能、企业适用性和透明数据来源方面提供了最新的进展。对于需要关键任务部署的组织而言，这些模型展示了性能和功能的结合，提供了增强的研究和商业用途可能性。所有模型均在Apache 2.0许可下公开可用，进一步推动了研究和商业应用的发展。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21137", "html_url": "https://arxiv.org/abs/2508.21137", "title": "认知偏见如何影响大型语言模型？一种基于价格谈判模拟中的锚定效应案例研究", "title_en": "How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations", "authors": "Yoshiki Takenami,Yin Jou Huang,Yugo Murawaki,Chenhui Chu", "background": "人类认知偏见已在大量研究中被发现并对实际应用中的可靠性产生影响。本研究关注大型语言模型（LLMs）在价格谈判中的锚定效应，这是一种特定的认知偏见，影响谈判结果。研究通过指导卖方LLM代理应用锚定效应，并采用客观和主观双重标准评估谈判结果，以探讨LLMs如何受到锚定效应的影响，并分析锚定效应与其他因素（如推理和个性）之间的关系。研究表明，尽管LLMs受锚定效应影响，但推理模式较少受到影响，长期思考减轻了锚定效应的影响。但这与个性特质对锚定效应的敏感性无关。这项研究加深了对LLMs中认知偏见的理解，并为合理应用LLMs提供了依据。", "innovation": "本研究通过引入锚定效应作为一种认知偏见，在LLM的实践应用中进行实验和评估，创新性地结合了客观和主观的评价标准，同时揭示了推理模式在减轻锚定效应影响方面的有效性，为理解和应用LLMs提供了新的视角。此外，本研究展示了LLMs中认知偏见的复杂性，提供了实证证据来支持这一观点。", "conclusion": "本研究揭示了LLMs在价格谈判中的锚定效应，证实了LLMs同样易受认知偏见影响。研究发现推理模式能够减轻锚定效应的影响，但个性特质与锚定效应的敏感性无显著相关性。研究结果对于理解LLMs的决策过程具有重要意义，并对在社会中实现LLMs的安全和负责任应用提供了指导。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21148", "html_url": "https://arxiv.org/abs/2508.21148", "title": "科学大语言模型的综述：从数据基础到智能代理前沿", "title_en": "A Survey of Scientific Large Language Models: From Data Foundations to Agent Frontiers", "authors": "Ming Hu,Chenglong Ma,Wei Li,Wanghan Xu,Jiamin Wu,Jucheng Hu,Tianbin Li,Guohang Zhuang,Jiaqi Liu,Yingzhou Lu,Ying Chen,Chaoyang Zhang,Cheng Tan,Jie Ying,Guocheng Wu,Shujian Gao,Pengcheng Chen,Jiashi Lin,Haitao Wu,Lulu Chen,Fengxiang Wang,Yuanyuan Zhang,Xiangyu Zhao,Feilong Tang,Encheng Su,Junzhi Ning,Xinyao Liu,Ye Du,Changkai Ji,Cheng Tang,Huihui Xu,Ziyang Chen,Ziyan Huang,Jiyao Liu,Pengfei Jiang,Yizhou Wang,Chen Tang,Jianyu Wu,Yuchen Ren,Siyuan Yan,Zhonghua Wang,Zhongxing Xu,Shiyan Su,Shangquan Sun,Runkai Zhao,Zhisheng Zhang,Yu Liu,Fudi Wang,Yuanfeng Ji,Yanzhou Su,Hongming Shan,Chunmei Feng,Jiahao Xu,Jiangtao Yan,Wenhao Tang,Diping Song,Lihao Liu,Yanyan Huang,Lequan Yu,Bin Fu,Shujun Wang,Xiaomeng Li,Xiaowei Hu,Yun Gu,Ben Fei,Zhongying Deng,Benyou Wang,Yuewen Cao,Minjie Shen,Haodong Duan,Jie Xu,Yirong Chen,Fang Yan,Hongxia Hao,Jielan Li,Jiajun Du,Yanbo Wang,Imran Razzak,Chi Zhang,Lijun Wu,Conghui He,Zhaohui Lu,Jinhai Huang,Yihao Liu,Fenghua Ling,Yuqiang Li,Aoran Wang,Qihao Zheng,Nanqing Dong,Tianfan Fu,Dongzhan Zhou,Yan Lu,Wenlong Zhang,Jin Ye,Jianfei Cai,Wanli Ouyang,Yu Qiao,Zongyuan Ge,Shixiang Tang,Junjun He", "background": "科学大语言模型（Sci-LLMs）正在改变知识在科学研究中的表示、整合和应用方式，但其发展受到科学数据复杂性质的影响。本文综述了科学大语言模型的发展现状，指出其模型与底层数据基础之间的共生演进，并强调了科学数据与通用自然语言处理数据集之间的多模态、跨尺度及领域特定的挑战.", "innovation": "本文提出了统一的科学数据分类和层级知识模型，并系统地回顾了科学大语言模型从通用基础到多学科专业模型的发展。此外，还对超过270个预/后训练数据集进行了深入分析，揭示了为什么科学大语言模型需要保持领域不变性且支持跨模态推理的异构、多尺度和不确定性数据。在评估方面，本文检查了超过190个基准数据集，从静态考试转向侧重于过程和发现的评估，采用了先进的评估协议。该工作还讨论了半自动化注释管道和专家验证等新兴解决方案，并提出了一种闭环系统，其中基于科学大语言模型的自主智能代理积极参与实验证实和知识库的进化.", "conclusion": "本研究为构建可信赖的不断演化的AI系统提供了路线图，这些系统可以作为科学发现的真实伙伴，加速科研进程。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21290", "html_url": "https://arxiv.org/abs/2508.21290", "title": "从代码生成模型中高效生成代码嵌入", "title_en": "Efficient Code Embeddings from Code Generation Models", "authors": "Daria Kryvosheieva,Saba Sturua,Michael Günther,Scott Martens,Han Xiao", "background": "本文介绍了一种名为jina-code-embeddings的新颖代码嵌入模型套件，旨在从自然语言查询中检索代码、进行技术问题解答以及在不同编程语言中识别语义相似的代码片段。研究表明，这种模型即使在相对较小的规模下也能达到最先进的性能。", "innovation": "该工作创新性地使用了一个同时在文本和代码上预训练的自回归主干网络，并通过最后一令牌池化生成嵌入。", "conclusion": "本文详细介绍了训练方法，并展示了尽管模型相对较小，但在代码嵌入模型构建方面的优越性能。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21164", "html_url": "https://arxiv.org/abs/2508.21164", "title": "量化大型语言模型标签诱导偏见的自我和交叉评价", "title_en": "Quantifying Label-Induced Bias in Large Language Model Self- and Cross-Evaluations", "authors": "Muskan Saraf,Sajjad Rezvani Boroujeni,Justin Beaudry,Hossein Abedi,Tom Bush", "background": "随着大型语言模型（LLMs）的广泛应用，它们被用于评估生成的输出。然而，这些判断可能会受到多种因素的影响，其中包括模型标签带来的偏见。这项研究旨在探讨ChatGPT、Gemini和Claude三种模型在自我和交叉评价中的标签偏见，通过设置不同标签条件来考察这些偏见对评价结果的影响。评估内容主要涉及博客文章的创作，通过整体偏好投票和一致性的、信息性、简明性的质量评级来进行。研究发现，模型标签对评估结果有显著影响，即使实际内容相同，标签也会对分数产生明显影响。虚假标签有时会逆转排名，导致评分大幅波动，这进一步强调了实施盲评或多种模型评价的重要性和必要性，以确保LLM基准评测的公平性。", "innovation": "本研究通过引入四种不同的标签条件—无标签、真实标签以及两种虚假标签，系统地评估了ChatGPT、Gemini和Claude模型自我和交叉评价的偏见，揭示了感知到的模型身份对高层次判断及细节质量评分的深刻影响。", "conclusion": "研究结果表明，模型标签对评估结果有着显著影响，实际内容与模型自我评价和相互评价之间的得分分歧尤为明显。这表明感知到的模型身份可以显著扭曲高层判断和微妙地影响详细的质量评分，呼吁采取盲评或多模型评价的程序以确保LLM基准评测的公平性。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21201", "html_url": "https://arxiv.org/abs/2508.21201", "title": "利用群相对策略优化的强化学习改进航空安全分析", "title_en": "Improving Aviation Safety Analysis: Automated HFACS Classification Using Reinforcement Learning with Group Relative Policy Optimization", "authors": "Arash Ahmadi,Sarah Sharif,Yaser Banad", "background": "分析航空事故背后的人为因素对于预防未来事故至关重要，但传统的使用人类因素分析及分类系统（HFACS）的方法在可扩展性和一致性方面受到限制。", "innovation": "提出了一种利用强化学习中的群相对策略优化（GRPO）与Llama-3.1 8B语言模型结合的自动化HFACS分类框架，该框架加入了一种针对航空安全分析定制的多组件奖励系统，并通过生成合成数据来解决事故数据集中的类别不平衡问题。", "conclusion": "我们的工作验证了针对特定领域的优化模型能够提供计算效率更高且更适合关键安全分析的解决方案。这种方法在资源受限的边缘设备上可以实现强大的低延迟部署。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21184", "html_url": "https://arxiv.org/abs/2508.21184", "title": "基于贝叶斯实验设计的智能信息收集：LLM与贝叶斯实验设计", "title_en": "BED-LLM: Intelligent Information Gathering with LLMs and Bayesian Experimental Design", "authors": "Deepro Choudhury,Sinead Williamson,Adam Goliński,Ning Miao,Freddie Bickford Smith,Michael Kirchhof,Yizhe Zhang,Tom Rainforth", "background": "本文提出了一种提高大型语言模型（LLMs）智能和适应性地从用户或其他外部来源收集信息能力的一般方法。利用序贯贝叶斯实验设计（BED）框架，使得LLMs能够作为有效的多轮对话代理，并能与外部环境进行交互式交互。", "innovation": "本文的主要创新包括：1）通过迭代选择最大化预期信息增益（EIG）的问题或查询来构建BED-LLM；2）开发了一种精心设计的EIG估计器，不仅依赖于上下文更新来处理先前的答案；3）提出了一种有针对性的策略，用于提出候选问题。", "conclusion": "通过在一系列20个问题的游戏测试中评估BED-LLM，研究发现，与直接提示LLMs和其他适应性设计策略相比，BED-LLM在性能上取得了显著提升，实现了用户偏好的高效主动推理。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21210", "html_url": "https://arxiv.org/abs/2508.21210", "title": "自监督语音模型是否存在语言习得的关键期效应？", "title_en": "Do Self-Supervised Speech Models Exhibit the Critical Period Effects in Language Acquisition?", "authors": "Yurie Koga,Shunsuke Kando,Yusuke Miyao", "background": "研究指出，人类语言习得的关键期（CP）效应在自监督语音模型（S3Ms）中是否表现出来尚不清楚。关键期效应指的是，第二语言（L2）延迟接触时学习难度增加和第一语言（L1）延迟失去的情况。以往的研究主要集中在文本语言模型上，但对语音模型的研究仍属空白，尽管口语在人类语言习得中起着核心作用。本研究通过训练S3Ms，使用不同L2训练开始时间和L1训练结束时间的数据，评估其音位辨别性能，验证关键期效应是否在语音模型中显现。", "innovation": "本研究首次探索了自监督语音模型中是否存在语言习得的关键期效应，这是对以往使用文本语言模型研究的补充，填补了在语音模型研究领域的空白。培训方法的创新在于使用了不同条件下（L2训练开始时间和L1训练结束时间）的数据，来观察模型的不同表现和反映出的关键期效应。", "conclusion": "研究表明，S3Ms并未表现出明确的关键期效应在音位习得中的证据。值得注意的是，延迟接触L2容易提高L2的表现，而L1接触延迟则可能导致L1的遗忘。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21228", "html_url": "https://arxiv.org/abs/2508.21228", "title": "解码记忆：一种高效的自一致性幻觉检测管道", "title_en": "Decoding Memories: An Efficient Pipeline for Self-Consistency Hallucination Detection", "authors": "Weizhi Gao,Xiaorui Liu,Feiyi Wang,Dan Lu,Junqi Yin", "background": "大型语言模型（LLMs）在研究和实际应用中展示了出色的性能，但在应对幻觉问题上仍有局限。现有的幻觉检测方法往往在句子生成层面表现不佳，且很大程度上依赖于特定领域的知识。虽然自一致性方法有助于解决这些问题，但由于需要反复生成输入，其计算成本较高。本文首次研究了在自一致性方法中识别冗余现象，即多次生成中共享的前缀令牌，并发现非精确答案的令牌对语义内容几乎没有贡献。基于此认识，本文提出了一种新型解码记忆管道（DMP），该管道通过选择性推理和逐步解码加速生成。这是一种与模型、数据集、解码策略和自一致性基线无关的方法，能够一致地提高多响应生成的效率，并有望应用于对齐和推理任务。广泛的实验表明，该方法在不牺牲AUROC性能的情况下实现了最多3倍的加速。", "innovation": "提出了新型解码记忆管道（DMP），通过选择性推理和逐步解码加速生成，解决了自一致性方法的高计算成本问题，并且这种方法与模型、数据集、解码策略和自一致性基线无关，能够提升多响应生成的效率，具有扩展到对齐和推理任务的潜力。", "conclusion": "通过解码记忆管道，本文在保持AUROC性能的同时实现了多响应生成的3倍加速，且该方法通用性强，适用于多种场景，并有潜力进一步应用于对齐和推理任务。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21422", "html_url": "https://arxiv.org/abs/2508.21422", "title": "自动评论员未能发现研究论文中的错误推理：一个新的反事实评估框架", "title_en": "Automatic Reviewers Fail to Detect Faulty Reasoning in Research Papers: A New Counterfactual Evaluation Framework", "authors": "Nils Dycke,Iryna Gurevych", "background": "大型语言模型（LLMs）在加速和促进学术同行评审方面具有巨大潜力，并且现在越来越多地被用作完全自动化的评论生成器（ARGs）。然而，潜在的偏差和系统性错误可能对科学诚信构成重大风险；因此，了解最先进的ARGs的具体能力和局限性至关重要。这项研究关注的是高质量同行评审的核心技能——检测研究逻辑中的错误。这涉及到评估论文结果、解释和断言之间的内部一致性。", "innovation": "研究提出了一种完全自动化的反事实评估框架，能够在受控条件下隔离并测试该技能。研究发现，与预期相反，研究逻辑中的缺陷对他们的评论输出没有显著影响。基于此发现，研究提出三条实际建议，指明未来的工作方向，并公开发布了反事实数据集和评估框架。", "conclusion": "尽管自动评论生成器在其他方面可能表现出色，但在检测研究逻辑中的错误时表现出不足。为此，研究人员提出了新的反事实评估框架，并提出了未来工作的建议，同时公开了数据集和评估工具。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21143", "html_url": "https://arxiv.org/abs/2508.21143", "title": "Multimodal LLMs能解决Percept-V的基本感知问题吗？", "title_en": "Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?", "authors": "Samrajnee Ghosh,Naman Agarwal,Hemanshu Garg,Chinmay Mittal,Mausam,Parag Singla", "background": "近年来，多模态大语言模型（MLLMs）在编程、数学和科学等复杂任务中的推理能力引起了广泛关注。然而，很少有实验评估它们在基本感知任务中的表现，这些任务涉及未被污染的图像包含的基本形状和结构。为此，该论文提出了一个名为Percept-V的数据集，包含7200个程序生成的图像，这些图像分为30个类别，每个类别测试一系列视觉感知技能。这些基本任务的难度不同，旨在评估MLLMs的感知能力。", "innovation": "作者引入了一个名为Percept-V的数据集，其中包含7200个程序生成的图像，这些图像分为30个类别，涵盖不同复杂性的基本视觉感知任务，以评估MLLMs的性能。此外，作者测试了最新的MLLMs（如GPT-4o、Gemini和Claude）和大型推理模型（如OpenAI o4-mini和DeepSeek R1），发现与复杂任务相比，MLLMs在问题复杂性增加时表现显著下降。", "conclusion": "实验结果显示，MLLMs在Percept-V各分类中的表现具有相似的趋势，且在测试特定认知技能时发现某些技能比其他技能更难以掌握。这与MLLMs在复杂任务中表现出色的证据相矛盾，表明MLLMs在基本感知任务中的表现存在局限性。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21294", "html_url": "https://arxiv.org/abs/2508.21294", "title": "BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning", "title_en": "BLUEX Revisited: Enhancing Benchmark Coverage with Automatic Captioning", "authors": "João Guilherme Alves Santos,Giovana Kerche Bonás,Thales Sales Almeida", "background": "随着大型语言模型（LLMs）能力的增强，亟需更为 robust 的评估方法，特别是在多语种和非英语背景下。为了应对这一需求，作者更新了 BLUEX 数据集，加入了 2024-2025 年的考试内容和使用最先进的模型自动生成的图像描述，增强了其对 LLM 预训练中数据污染研究的相关性。", "innovation": "更新后的 BLUEX 数据集包括了最新的考试内容和自动生成的图像描述，这些新增的内容提升了数据集对研究 LLM 预训练中数据污染的适用性。通过使用图像描述，文本-only 模型的可访问性提高了超过 40%，生成了 1,422 个可用于研究的问题，是原数据集数量的两倍多。", "conclusion": "研究评价了商业和开源 LLMs 在通过图像描述利用视觉上下文方面的表现。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21389", "html_url": "https://arxiv.org/abs/2508.21389", "title": "AllSummedUp：一种用于评估摘要的度量标准比较的开源框架", "title_en": "AllSummedUp: un framework open-source pour comparer les metriques d'evaluation de resume", "authors": "Tanguy Herserant,Vincent Guigue", "background": "本文探讨了自动文本摘要评估中的再现性挑战。通过对六个代表性指标（包括经典方法如ROUGE到最近基于LLM的方法（G-Eval, SEval-Ex））的研究，发现文献中报道的表现与实验环境中的观察结果之间存在显著差异。这项工作揭示了结构性权衡：在人类判断上表现最好的指标往往计算密集且运行稳定性较低。", "innovation": "本文引入了一个统一的、开源的比较框架，应用于SummEval数据集，旨在支持公平和透明的评估指标比较。此外，研究指出对LLM的依赖存在随机性、技术依赖性和有限再现性的问题，强调需要制定更严格的评估协议，包括详尽的文档和方法论标准化，以确保自动摘要评估的可靠性。", "conclusion": "研究结果表明，在自动摘要评估中存在结构性权衡，表现与人类判断高度一致的指标通常计算复杂且运行稳定性差。研究还强调了对LLM评估的依赖带来的问题，并建议采用更可靠的评估协议，以确保评估的可靠性。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21377", "html_url": "https://arxiv.org/abs/2508.21377", "title": "大型语言模型的挑战与应用：GPT与DeepSeek家族模型的比较", "title_en": "Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models", "authors": "Shubham Sharma,Sneha Tuli,Narendra Badam", "background": "大规模语言模型（LLMs）正在各行各业的AI发展中发挥重要作用，但其开发和部署仍然具有复杂性。本文回顾了构建和使用LLMs的关键挑战，并通过比较两个具有独特方法的最先进的模型（OpenAI的闭源GPT-4o和DeepSeek-V3-0324，这是一个大型开源混合专家模型）来探讨这些挑战的解决方法。文章分析了闭源模型（稳健的安全性，精细调优的可靠性）和开源模型（效率，适应性）之间的权衡，并探讨了LLMs在不同领域的应用（从聊天机器人和编程工具到医疗保健和教育），指出了每个应用场景最适合的模型属性。这些分析旨在指导AI研究人员、开发人员和决策者理解和掌握当前LLM的功能、限制和最佳实践方法。", "innovation": "本研究通过对比两个特殊领域的模型展示了闭源模型和开源模型之间的权衡，并探讨了LLMs在不同领域的应用情况，指出了每个应用场景最适合的模型属性。这为理解当前LLMs的能力、限制和最佳实践提供了一种新的视角。", "conclusion": "本文旨在帮助AI研究人员、开发人员和决策者理解和掌握当前LLM的功能、限制和最佳实践方法。通过比较两个具有独特方法的先进模型，展示了闭源模型和开源模型之间的权衡，并分析了LLMs在不同领域的应用，指出了最适合每个应用场景的模型属性。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21436", "html_url": "https://arxiv.org/abs/2508.21436", "title": "通过解纠缠概念表示发现语义子维度", "title_en": "Discovering Semantic Subdimensions through Disentangled Conceptual Representations", "authors": "Yunhao Zhang,Shaonan Wang,Nan Lin,Xinyi Dong,Chong Li,Chengqing Zong", "background": "理解概念语义的核心维度对于揭示语言和大脑中意义的组织方式至关重要。现有的方法通常依赖于预定义的语义维度，这仅仅提供粗略的表示，忽略了精细的概念区分。", "innovation": "本文提出了一种新的框架来研究粗略语义维度下的子维度。我们引入了一个解纠缠连续语义表示模型（DCSRM），它可以分解大型语言模型中的词嵌入为多个子嵌入，每个子嵌入编码特定的语义信息。通过这些子嵌入，我们能够识别出一系列可解释的语义子维度。我们使用体素级编码模型将这些子维度映射到大脑激活，进一步分析揭示了语义维度的结构准则，极性似乎是其中的关键驱动因素。", "conclusion": "我们的工作提供了更为精细的可解释的语义子维度，且大脑的相关特征支持其认知和神经科学的合理性。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21430", "html_url": "https://arxiv.org/abs/2508.21430", "title": "Med-RewardBench: 医学多模态大型语言模型的奖励模型和裁判基准", "title_en": "Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models", "authors": "Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen", "background": "多模态大型语言模型（MLLMs）在医学应用中具有巨大潜力，包括疾病诊断和临床决策。然而，这些任务需要高度准确、上下文敏感和专业对齐的响应，因此可靠的奖励模型和裁判至关重要。目前，医学奖励模型（MRMs）和裁判仍然被忽视，缺乏专门针对临床需求的基准测试。现有的基准测试主要关注MLLM的一般能力，或作为解题模型进行评估，忽视了诊断准确性和临床相关性等关键评估维度。为了解决这一问题，作者提出了Med-RewardBench，这是第一个专门用于评估医学场景下MRMs和裁判的基准测试。", "innovation": "Med-RewardBench 已经开发了一个包含13个器官系统和8个临床部门的多模态数据集，并有1,026个专家标注案例。该基准测试使用严格的三步法，确保在六个临床关键维度上获得高质量的评估数据。此外，还评估了32个最先进的 MLLMs，发现这些模型在与专家判断的输出对齐上存在重大挑战。研究还开发了基准模型，通过微调显示出显著的性能提升。", "conclusion": "Med-RewardBench 为医学多模态大型语言模型的奖励模型和裁判提供了第一个专门针对临床需求的基准测试，通过提出一个多模态数据集和严格的评估流程，以及通过评估和开发基准模型，揭示了模型在与专家判断对齐方面存在的挑战，并展示了微调可以显著提高性能。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21382", "html_url": "https://arxiv.org/abs/2508.21382", "title": "正常性与图灵测试", "title_en": "Normality and the Turing Test", "authors": "Alexandre Kabbach", "background": "本文试图重新审视图灵测试，通过引入‘正常性’的概念。文章认为图灵测试评判的是普通人而非超常人物的智能，还指出在进行智能判断时实际上是一个统计过程，而不是由一个非专家单独评判，而是由一个包含多个评判者的完整陪审团来进行评判。因此，图灵在原始论文中提到的‘普通人提问者’是对多个评判者的归一化汇总做出的数学抽象。文章分析了图灵测试与正常智能及正常判断的关系，指出图灵测试是通过‘正常法官’来评估由多人组成的提问者群体的平均判断，这样即可以去评判模型是否能够通过图灵测试。", "innovation": "提出了通过‘正常性’重新理解图灵测试的方法。具体地，将图灵测试视为适用于评估普通人类智能的标准，而非非凡的智能。特别地，图灵测试的评判过程被视作是一个统计过程，而不是由单一非专家进行评判，而是由一个完整的陪审团来进行评判。因此，通过‘正常法官’来评估归一化汇总的多个评判者的平均结果，可以更好地理解图灵测试的性质。文章认为，采用这种‘正常性’的视角可以更准确地判断人工智能模型是否能够通过图灵测试，如像ChatGPT 这样的大型语言模型由于针对超常智能而不是普通人类智能，因此不会通过图灵测试。这样的图灵测试不仅仅是技术层面的问题，还反映了对人类认知理解的深层问题。方法的独特性在于从统计和社科维度来重新审视图灵测试的含义和应用方式，而非仅从技术角度审视。", "conclusion": "文章结论表明，大型语言模型如ChatGPT很可能不会通过图灵测试，因为它们的目标是超常而非普通人类智能。这种模型被称为‘人工聪明’而不是‘人工智能’。图灵测试是否能为理解人类认知提供帮助的关键在于人类思维是否可以简化为普通人类思维，这个问题远远超出了图灵测试本身，涉及到正常主义范式的基础概念。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21482", "html_url": "https://arxiv.org/abs/2508.21482", "title": "HSFN: 基于层次选择的异构集合构建方法在虚假新闻检测中的应用", "title_en": "HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble", "authors": "Sara B. Coutinho,Rafael M.O. Cruz,Francimaria R. S. Nascimento,George D. C. Cavalcanti", "background": "心理偏差，如证实偏见，使个体特别容易相信和传播社交媒体上的假新闻，这在公共卫生和政治等领域造成了严重影响。基于机器学习的事实核查系统被广泛研究以减轻这一问题。其中，集成方法特别有效，通过结合多个分类器提高鲁棒性。然而，其性能很大程度上依赖于构成分类器的多样性——选择真正多样的模型仍然是一个关键挑战，尤其是当模型倾向于学习冗余模式时。", "innovation": "本文提出了一种新的自动分类器选择方法，优先考虑多样性和性能。该方法首先计算分类器之间的成对多样性，并应用层次聚类来将它们组织成不同粒度级别的组。HierarchySelect 探索这些层次结构来选择每一级的一个分类器池，每个池代表一种独特的内池多样性。最多样化的池从这些池中被识别并选为集合构建的基础。选择过程还结合了反映各分类器性能的评估指标，以确保集合也具有良好的泛化能力。", "conclusion": "我们的方法在六个不同应用领域的四十个异构分类器和不同类别的数目的数据集上进行了实验。该方法与Elbow启发式和最先进的基线方法进行比较。结果显示，我们的方法在六个数据集中的两个上获得了最高准确率。详细的实现细节可在项目仓库中找到：this https URL."}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21587", "html_url": "https://arxiv.org/abs/2508.21587", "title": "当前文本匿名化趋势及最新进展综述", "title_en": "A Survey on Current Trends and Recent Advances in Text Anonymization", "authors": "Tobias Deußer,Lorenz Sparrenberg,Armin Berger,Max Hahnbück,Christian Bauckhage,Rafet Sifa", "background": "各种领域中出现了包含敏感个人信息的大量文本数据，需要具备强大匿名化能力的技术来保护隐私、遵守法规，同时也需要保证数据的可用性，用于支持各种关键下游任务。", "innovation": "综述涵盖了当前文本匿名化技术的趋势和最新进展，讨论了基础方法（主要基于命名实体识别）、大型语言模型的作用、领域特定挑战及解决方案、先进的方法论、作者匿名化等新的研究方向，以及评估框架、综合指标、基准和实际部署工具箱等内容。", "conclusion": "综述总结了当前的知识，指出了新兴趋势和持续存在的挑战，包括隐私-实用性权衡、处理准标识符的必要性，以及大型语言模型能力的影响，并旨在引导学术界和实践者的未来研究方向。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21589", "html_url": "https://arxiv.org/abs/2508.21589", "title": "Middo：通过闭环学习改进LLM微调的模型导向的动态数据优化", "title_en": "Middo: Model-Informed Dynamic Data Optimization for Enhanced LLM Fine-Tuning via Closed-Loop Learning", "authors": "Zinan Tang,Xin Gao,Qizhi Pei,Zhuoshi Pan,Mengzhang Cai,Jiang Wu,Conghui He,Lijun Wu", "background": "大型语言模型（LLM）的监督微调（SFT）主要依赖高质量的训练数据。尽管数据选择和数据合成是提高数据质量的常用策略，但现有的方法在静态数据集管理和适应模型能力演变方面存在局限性。本文介绍了一个名为Middo的新框架，该框架通过模型感知的数据选择和语义连贯的数据精炼来实现自我进化的动态数据优化。", "innovation": "Middo框架通过闭环优化系统实现自我进化的动态数据优化，包括：(1) 自我参照诊断模块通过模型信号（复杂度、多样性、质量）探查低质量样本；(2) 自适应优化引擎将低质量样本转变为教育性有效的训练数据点，同时保持语义完整性；(3) 优化过程随着模型能力的提高通过动态学习原则不断进化。实验结果表明，Middo能够持续提升基础数据质量，提高LLM的性能，平均准确率提高7.15%，并且保持数据集规模不变。", "conclusion": "本文提出了一种新范式，通过数据和模型的动态人机共同进化实现可持续的LLM训练。该研究即将发布相关数据集、模型和代码。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21569", "html_url": "https://arxiv.org/abs/2508.21569", "title": "L3Cube-MahaSTS: 一个马拉地语句子相似度数据集和模型", "title_en": "L3Cube-MahaSTS: A Marathi Sentence Similarity Dataset and Models", "authors": "Aishwarya Mirashi,Ananya Joshi,Raviraj Joshi", "background": "以往研究通常关注英语和一些其他高资源语言的句子相似度（STS）任务，但对于马拉地语等低资源语言的研究较少。为了改进低资源情境下马拉地语句子相似度任务的模型性能，作者构建了一个马拉地语句子对标注数据集MahaSTS，并在此基础上训练了一个优化的Frozen-BERT模型MahaSBERT-STS-v2。", "innovation": "该研究的创新之处在于提出了一个专门针对马拉地语的高质量数据集MahaSTS，并且使用这一数据集训练了一个专为回归型相似度评分优化的Frozen-BERT模型MahaSBERT-STS-v2。此数据集包含16,860个马拉地语文本对，并且通过严格的数据标注，确保了评分分布的均匀性。这种结构化的监督方法有助于减少标签偏见并提高模型的稳定性。此外，此研究的模型与多个基准模型进行了性能比较，证明了其有效性。", "conclusion": "MahaSTS训练集使得在马拉地语句子相似度任务上的模型训练更加有效，展示了人类手工标注数据、有针对性的微调和结构化的监督在低资源情境下的重要性。同时也展示了Fine-tuned BERT模型在低资源语言类似度任务上的潜力。研究结果已经在公开平台上与学术界共享。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21675", "html_url": "https://arxiv.org/abs/2508.21675", "title": "这个图表在骗我吗？自动化误导性图表检测", "title_en": "Is this chart lying to me? Automating the detection of misleading visualizations", "authors": "Jonathan Tonglet,Jan Zimny,Tinne Tuytelaars,Iryna Gurevych", "background": "误导性图表在社交媒体和网络上是传播错误信息的重要因素。它们违背了图表设计原则，扭曲数据，导致读者得出错误的结论。既有研究表明，无论是人类还是多模态大语言模型（MLLMs）都容易被误导性图表所欺骗。自动检测误导性图表并识别它们违反的具体设计规则有助于保护读者并减少错误信息的传播。然而，由于缺乏大规模、多样且公开可用的数据集，AI模型的训练和评估受到限制。", "innovation": "本文引入了Misviz，这是一种包含2,604个带有12种误导标签的真实世界图表的数据集。为了支持模型训练，还提供了Misviz-synth，这是基于实际数据表格使用Matplotlib生成的81,814个图表的合成数据集。利用最新的MLLMs、基于规则的系统和微调分类器，对两个数据集进行了全面评估，结果表明该任务依然极具挑战性。", "conclusion": "我们发布了Misviz、Misviz-synth和随附代码。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21628", "html_url": "https://arxiv.org/abs/2508.21628", "title": "个性差异重要：用户特质在多轮协作任务中预测大语言模型偏好", "title_en": "Personality Matters: User Traits Predict LLM Preferences in Multi-Turn Collaborative Tasks", "authors": "Sarfaroz Yunusov,Kaige Chen,Kazi Nishat Anwar,Ali Emami", "background": "随着大型语言模型（LLMs）越来越多地融入日常的工作流程中，用户通过多轮交互合作来影响结果，研究发现用户的不同个性特质是否系统性地更偏好某些特定的LLM，这一问题变得尤为重要。为此，研究者对不同个性类型的用户进行了多轮协作任务的实验，探讨用户对GPT-4和Claude 3.5的不同偏好。", "innovation": "这项研究创新性地通过多轮协作任务探索了用户个性对LLM偏好影响的差异，虽然传统评价方法可能未能揭示这些差异，但个性分析显示了模型之间的不同之处。这项研究通过引入四个人格类型（Rationals和Idealists以及其他类型），以及具体的任务类型（数据处理、创意写作、信息检索和写作辅助），提供了更细致的个性化偏好分析框架。", "conclusion": "研究结果表明，不同的人格类型在多轮协作任务中表现出不同的偏好，特别是Rationals偏爱GPT-4在目标导向性任务中的表现，而Idealists则偏爱Claude 3.5在创造性分析任务中的表现。其他类型的人格表现出任务相关的偏好。情感分析证实了这些模式，总体而言，各模型的帮助评估得分相似，显示出基于个性的分析可以揭示传统评估方法所忽视的LLM差异。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21476", "html_url": "https://arxiv.org/abs/2508.21476", "title": "小语言模型中的创意写作激发：LLM-as-a-Judge与多智能体精炼奖励对比", "title_en": "Igniting Creative Writing in Small Language Models: LLM-as-a-Judge versus Multi-Agent Refined Rewards", "authors": "Xiaolong Wei,Bo Lu,Xingyu Zhang,Zhejun Zhao,Dongdong Shen,Long Xia,Dawei Yin", "background": "大型语言模型（LLMs）展现了显著的创造性写作能力，但其巨大的计算需求阻碍了它们的广泛应用。增强小语言模型（SLMs）是一个有前途的选择，但现有方法如有监督微调（SFT）难以生成新颖的内容，而基于人类反馈的强化学习（RLHF）则成本高昂。因此，本文探讨了在AI反馈强化学习（RLAIF）框架下两种不同的AI驱动奖励策略，以提高一个具有7B参数的小语言模型的创造性写作能力，特别是用于生成中文问候语方面的能力。", "innovation": "本文提出了两种AI驱动的奖励策略。第一种策略利用一种根据一种新颖的多智能体拒绝采样框架训练的偏好模型，该框架专门用于创造任务。第二种策略则采用了一种原则引导的LLM-as-a-Judge，其奖励函数通过对抗训练方案以及反馈机制优化，直接提供奖励信号。实验表明，两种方法都能显著提升创造力输出，但原则引导的LLM-as-a-Judge在生成质量上更胜一筹，且在训练效率和对人工标注数据的依赖上表现出显著优势。此外，本文的自动评估方法与人类判断高度一致。", "conclusion": "本文展示了原则引导的LLM-as-a-Judge在促进小语言模型的创造性写作方面的优势，为生成高质量创意内容提供了一条更高效和更具扩展性的路径。同时，实验还证实了该方法在训练效率和对人工标注数据依赖性方面的显著改进。所有代码和数据已公开。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21448", "html_url": "https://arxiv.org/abs/2508.21448", "title": "深入探索：大型语言模型的意识形态深度", "title_en": "Beyond the Surface: Probing the Ideological Depth of Large Language Models", "authors": "Shariar Kabir,Kevin Esterling,Yue Dong", "background": "大型语言模型（LLMs）表现出明显的意识形态倾向，但这些倾向的稳定性和深度仍然不甚明了。表面上的回应可能通过简单的提示工程进行操控，这引起了人们对它们是否反映了一致的意识形态基础的质疑。因此，本文探讨了LLMs中‘意识形态深度’这一概念，定义为它们内部政治表征的稳定性和复杂性。", "innovation": "本文采用了双重方法：首先，通过指令提示和激活驱动来测量两个知名开源LLMs的可操纵性，发现一些模型可以在自由派和保守派观点间轻易切换，而另一些则表现出抵抗或更高的拒绝率，这表明其意识形态结构更为稳固。其次，通过稀疏自编码器（SAEs）探索这些模型的内部机制。初步分析表明，低可操纵性模型包含更多独特和抽象的意识形态特征。我们的评估发现，一个模型可以包含比同类大小的另一个模型多7.3倍的政治特征。这意味着可以对‘深度’较大的意识形态模型中的核心政治特征进行针对性消除，导致其在相关主题上的推理出现一致、逻辑的转变，而同一操作在‘浅度’模型中则导致拒绝输出的增加。这些发现表明，意识形态深度是LLMs的一个可量化的属性，而可操纵性是一种有价值的窗口，可以看到其潜在的政治结构。", "conclusion": "我们的研究结果表明，意识形态深度是大型语言模型的一个可量化的属性，并且可操纵性可以揭示其潜在的政治结构。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21741", "html_url": "https://arxiv.org/abs/2508.21741", "title": "非所有参数生而平等：智能隔离提升微调性能", "title_en": "Not All Parameters Are Created Equal: Smart Isolation Boosts Fine-Tuning Performance", "authors": "Yao Wang,Di Liang,Minlong Peng", "background": "监督细调（SFT）是将大型语言模型（LLMs）适应下游任务的重要方法；然而，参数更新无辨别地进行会导致某些任务的进展伴随着其他任务的退步，即所谓的“摇摆现象”。", "innovation": "本文提出了一种新的参数隔离调优（Core Parameter Isolation Fine-Tuning，CPI-FT）框架。首先，独立地对每个任务进行微调以识别核心参数区域；然后基于区域重叠将具有相似核心区域的任务分组进行联合建模。引入了参数融合技术：将个体微调模型中的核心参数转移到统一骨干模型中，而非核心参数通过球形线性插值（SLERP）平滑集成，避免了破坏性干涉。采用混合任务数据进行轻量级的流水线调优阶段，冻结先前任务的核心区域以防止灾难性遗忘。", "conclusion": "广泛实验表明，该方法显著减少了任务间的互相干扰和遗忘现象，持续优于传统的多任务和多阶段微调基线。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21762", "html_url": "https://arxiv.org/abs/2508.21762", "title": "推理密集型回归", "title_en": "Reasoning-Intensive Regression", "authors": "Diane Tchuindjo,Omar Khattab", "background": "AI研究人员和从业者越来越多地将大规模语言模型（LLMs）应用于推理密集型回归(RiR)任务，即将细微的数值属性从文本中推导出来。与情感分析或相似度等标准语言回归任务不同，RiR问题通常出现在需要深入了解文本但任务特定训练数据和计算资源有限的定制问题中，如评分表评估或领域特异性检索。", "innovation": "本文提出了一种名为MENTAT的简单且轻量级方法，结合批量反思提示优化与神经集成学习。MENTAT在基准测试中表现出色，相较于基线方法，改善幅度高达65%。该方法在RiR任务上展示了突破性的表现，但仍存在进一步改进的空间。", "conclusion": "本文通过将三个现实问题设定为RiR任务，建立了初期基准。研究结果表明，冻结LLM和通过梯度下降微调Transformer编码器的方法在RiR任务上往往表现欠佳。然后提出了MENTAT方法，该方法在RiR任务上取得了显著的性能提升，证明了在该领域新的方法和技术还有待探索和发展。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17693", "html_url": "https://arxiv.org/abs/2508.17693", "title": "通过双LLM自我精炼进行数据库规范化", "title_en": "Database Normalization via Dual-LLM Self-Refinement", "authors": "Eunjae Jo,Nakyung Lee,Gyuyeong Kim", "background": "数据库规范化对于保持数据完整性至关重要，但它通常由数据工程师手动完成，耗时且容易出错。", "innovation": "Miffie是一个利用大型语言模型能力的数据库规范化框架，它通过一个双重模型自我精炼架构自动完成数据的规范化，同时保持高准确度。该架构结合了用于生成和验证规范化模式的最佳模型，并通过反馈机制确保输出模式满足规范化的标准。此外，还精心设计了针对特定任务的零样本提示，以指导模型达到高准确性和成本效率。", "conclusion": "实验证明，Miffie能够处理复杂的数据库模式并维持高准确度。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21787", "html_url": "https://arxiv.org/abs/2508.21787", "title": "PiCSAR: 概率置信度选择和排序", "title_en": "PiCSAR: Probabilistic Confidence Selection And Ranking", "authors": "Joshua Ong Jun Leang,Zheng Zhao,Aryo Pradipta Gema,Sohee Yang,Wai-Chung Kwan,Xuanli He,Wenda Li,Pasquale Minervini,Eleonora Giunchiglia,Shay B. Cohen", "background": "通过对多个候选解决方案进行生成并选择得分最高的那个，这种方式可以提升大型语言模型（LLMs）和大型推理模型（LRMs）的准确率。对于推理任务，关键挑战在于设计一个评分函数，能够在不依赖真实答案的情况下识别正确的推理链。", "innovation": "提出了一种无需训练的简单方法——概率置信度选择和排序（PiCSAR），该方法使用推理和最终答案的联合对数似然进行评分。这种方法能够将联合对数似然自然地分解为推理置信度和答案置信度，并在多种基准测试中表现出显著的改进，在16次比较中有20次超过了基线模型，至少少用了两倍的样本数。", "conclusion": "分析结果表明，正确的推理链在推理和答案置信度上显示出显著更高的得分，证明了PiCSAR方法的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21632", "html_url": "https://arxiv.org/abs/2508.21632", "title": "QZhou-Embedding技术报告", "title_en": "QZhou-Embedding Technical Report", "authors": "Peng Yu,En Xu,Bin Chen,Haibiao Chen,Yinfei Xu", "background": "本文介绍了一种名为QZhou-Embedding的一般用途的上下文文本嵌入模型，该模型具有出色的文本表示能力。该模型基于Qwen2.5-7B-Instruct基础模型进行设计，并采用统一的多任务框架策略。通过这种框架，模型能够结合更多样的文本训练数据集，并提高模型的学习效率。作者开发了一种数据合成流水线，运用了LLM API，通过诸如重述、增广和生成困难负例等技术来提高训练集的语义丰富度和样本难度。此外，还采用了两阶段训练策略，包括初期的检索重点预训练和全任务微调，使得嵌入模型能够在稳健的检索性能基础上扩展其能力范围。该模型在MTEB和CMTEB基准测试中取得了最先进的成果，在两个排行榜中均位列第一（截至2025年8月27日），并且也在重排序、聚类等任务中取得了最先进的性能。研究表明，高质量和多样化的数据对于提升检索模型的性能至关重要，同时利用LLM的生成能力可以进一步优化嵌入模型的数据质量。", "innovation": "设计了一种统一的多任务框架，包括专门的数据转换和训练策略，通过数据合成流水线将不同的技术（如重述、增广和生成困难负例）应用于训练集，提高了训练集的语义丰富度和样本难度。采用两阶段训练策略，首先进行检索重点预训练，然后进行全任务微调，以增强模型的检索性能和多任务处理能力，从而提升嵌入模型的性能。利用LLM的生成能力来优化和提升数据质量，为嵌入模型的突破性进展提供支持。", "conclusion": "模型在MTEB和CMTEB基准测试中表现出色，同时在重排序、聚类等任务中也取得了最好的结果。实验证明，高质量、多样化的数据对于提升模型性能至关重要，而利用LLM的生成能力可以进一步优化数据质量，推动模型的进步。所有模型权重已在HuggingFace上发布，Apache 2.0许可。为了可重复性，作者在GitHub提供了评估代码和使用说明。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21788", "html_url": "https://arxiv.org/abs/2508.21788", "title": "精细梳理细网：为有害内容搜索和检索构建细齿梳索引技术报告", "title_en": "Going over Fine Web with a Fine-Tooth Comb: Technical Report of Indexing Fine Web for Problematic Content Search and Retrieval", "authors": "Inés Altemir Marinas,Anastasiia Kucherenko,Andrei Kucharavy", "background": "大型语言模型（LLMs）依赖于大规模的网络数据集，如Common Crawl，为现代模型提供了约80%的训练数据。但网络爬虫的随意性导致了数据质量、安全性和伦理上的挑战。尽管训练数据质量至关重要，但先前的研究因其计算资源有限，主要局限于小规模样本。因此，一个有效的框架用于索引和分析LLM训练数据具有重要意义。", "innovation": "该项目提出了一种基于ElasticSearch的索引和分析框架，应用于瑞士AI的FineWeb-2语料库（1.5TB，四语言），实现了快速查询性能——大多数查询在毫秒级，所有查询均在两秒内完成。这展示了实时数据集分析的能力，为更安全、更负责任的AI系统提供了实际工具。", "conclusion": "该研究演示了用于有害内容搜索和检索的实时数据集分析，实现了细粒度的数据索引和快速检索，并为未来的AI系统安全性和责任感报告提供了解决方案。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21188", "html_url": "https://arxiv.org/abs/2508.21188", "title": "模型-任务对齐驱动不同的强化学习结果", "title_en": "Model-Task Alignment Drives Distinct RL Outcomes", "authors": "Haoze Wu,Cheng Wang,Wenshuo Zhao,Junxian He", "background": "最近将强化学习（RL）应用于大型语言模型（LLMs）的研究取得了显著的进展。在LLMs中观察到了一些值得注意但又常常违反直觉的现象，如单一训练示例能达到整个数据集的性能，奖励信号不需要非常精确，仅使用负样本就能与复杂奖励方法相比拟甚至超越等。然而，这些观察现象的具体条件以及何时失效仍然不清楚。", "innovation": "本研究通过系统性且全面的分析和严格的实验验证，发现了区分这些RL观察现象的一个关键因素：预训练模型在评价任务上的pass@k准确率是否已表现出较强的模型-任务对齐。研究结果表明，标准RL训练在各种环境下保持了持续的稳健性，而绝大多数违反直觉的结果仅出现在模型和任务早已表现出高度对齐的情况下。在更为困难的情形下，这些技术无法显著促进学习，而标准RL方法仍然有效。", "conclusion": "研究结论是，模型-任务对齐的程度是决定RL观察现象的关键因素。标准RL训练在各种环境中表现出一致的稳健性，但在模型和任务对齐程度已经很高时，许多违反直觉的结果才会出现。而在更具挑战性的环境中，标准RL方法仍然有效，这些技术无法显著促进学习。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21256", "html_url": "https://arxiv.org/abs/2508.21256", "title": "CrossTL: 一种具有统一中间表示的通用编程语言翻译器", "title_en": "CrossTL: A Universal Programming Language Translator with Unified Intermediate Representation", "authors": "Nripesh Niketan,Vaatsalya Shrivastva", "background": "传统的编程语言翻译方法需要为每对语言单独开发翻译工具，导致随着语言数量的增加，复杂性呈指数级增长。这使得语言翻译工具的开发和维护变得非常困难。", "innovation": "CrossTL 使用统一的中间表示 (IR)，能够支持 CUDA、HIP、Metal、DirectX HLSL、OpenGL GLSL、Vulkan SPIR-V、Rust 和 Mojo 等多种语言的双向翻译。这种设计使得添加新语言变得容易，仅需开发特定于该语言的前端和后端组件。此外，该系统还包括语言特定的词法分析器/解析器、双向 CrossGL 翻译模块以及全面的后端实现。", "conclusion": "CrossTL 通过通用 IR 设计，提供了一个框架，支持 GPU 计算、图形编程和系统语言，且能够在所有支持的后端实现中成功编译和执行代码。该系统展示了通用代码翻译的实际可行性，并代表了在编程语言无关性方面的一个重要进展，支持一次编写，随处部署。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21204", "html_url": "https://arxiv.org/abs/2508.21204", "title": "模糊化、符号化和情境化：通过认知支架增强大语言模型指令", "title_en": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "authors": "Vanessa Figueiredo", "background": "本文探讨了建筑学启发式在大型语言模型（LLMs）在指令对话中的认知行为中的作用。研究人员通过引入符号支架机制和短时记忆模式，旨在促进适应性的、结构化的推理，特别是在苏格拉底式教学中的应用。研究使用了五种系统变体进行控制删除评估，并通过专家设计的评分标准评估模型输出，这些评分标准涵盖了支架、响应性、符号推理和对话记忆等维度。研究人员提出了一种基于大语言模型的评估框架，并与认知基础的评分标准对齐，以实现早期实验中架构变体的可扩展、系统性比较。初步结果显示，全系统优于基准变体。分析显示，删除记忆或符号结构会削弱关键的认知行为，包括抽象、适应性探查和概念连续性。这些发现支持一种处理水平的解释，即建筑学支架可以可靠地塑造LLMs中出现的指令策略。", "innovation": "提出了一种符号支架机制和短时记忆模式，旨在促进适应性的结构化推理，特别是在苏格拉底式教学中的应用。通过专家设计的评分标准评估模型输出，初步结果显示全系统优于基准变体，且分析表明记忆或符号结构的缺失会削弱关键认知行为。这种方法使研究能够在早期实验中进行可扩展的、系统性的架构变体比较。", "conclusion": "研究表明，符号支架机制和短时记忆模式增强了大型语言模型的认知行为，能够促进适应性的结构化推理。记忆和符号结构对于保持抽象、适应性探查和概念连续性至关重要。这些发现支持建筑学支架可以可靠地塑造LLMs中出现的指令策略。这种方法提供了一种新的评估框架，可以进行大规模的、系统的模型评估，以更好地理解大型语言模型的行为模式。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21334", "html_url": "https://arxiv.org/abs/2508.21334", "title": "阶梯之公平：连接群体公平与个体公平", "title_en": "Stairway to Fairness: Connecting Group and Individual Fairness", "authors": "Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Falk Scholer,Christina Lioma", "background": "推荐系统（RS）中的公平性通常被分为群体公平性和个体公平性。然而，这两种公平性类型之间的关系尚未得到科学的理解，因为先前对于这两种公平性类型的评估使用了不同的评估度量或目标，这使得它们之间无法进行比较。因此，目前还不清楚增强一种公平性是否会对另一种公平性产生影响。为了填补这一空白，本文通过全面比较可用于两种公平性类型的评估度量，研究群体公平性和个体公平性之间的关系。实验结果表明，对群体非常公平的推荐可能对个体来说却非常不公平。这一发现对于旨在提高其系统公平性的RS从业者具有重要价值。", "innovation": "本文的创新在于通过全面比较可用于两种公平性类型的评估度量，研究群体公平性和个体公平性之间的关系，并证明了对群体非常公平的推荐可能对个体来说却非常不公平。这一研究成果对于RS从业者在提高系统公平性方面具有实际指导意义。提供的代码可以在指定位址找到。", "conclusion": "实验结果表明，对群体非常公平的推荐可以导致个体公平性的显著下降，这为RS从业者在设计和优化推荐系统时如何平衡这两种公平性提供了新的见解。因此，这一研究为未来探讨推荐系统的公平性奠定了基础。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21209", "html_url": "https://arxiv.org/abs/2508.21209", "title": "为孩子设计更智能的对话代理：认知工作和手段目的分析中的经验教训", "title_en": "Designing Smarter Conversational Agents for Kids: Lessons from Cognitive Work and Means-Ends Analyses", "authors": "Vanessa Figueiredo", "background": "本文探讨了9至11岁巴西儿童如何使用对话代理（CAs）进行学习、探索和娱乐，以及结构化的支柱如何增强这些互动。研究1通过在线调查（7周，23名参与者，包含儿童、家长和教师）结合访谈、观察和认知工作分析，揭示了儿童信息处理流程、更有知识的人的作用、功能用途、情境目标和互动模式，以指导对话树设计。研究2则使用GPT-4o-mini模拟了1200次儿童-CA交流，对比了基于结构化提示的对话树食谱与无结构基线。结果表明，结构化方法在可读性、问题数量/深度/多样性以及连贯性方面有所提升。", "innovation": "本文提出了若干创新点：基于认知工作和手段目的分析，为儿童设计结构化支柱的对话树；提出了针对儿童的CA应用的首个案例研究；建立了儿童-CA信息流的实证框架；并提供了使用大型语言模型（LLM）进行语义提示的有效结构化提示方法。", "conclusion": "研究结果表明，通过结构化支架构建的对话树有助于更好地组织儿童的学习与娱乐活动，并提供了设计模型和食谱推荐。研究对未来设计更好的CAs进行了建议，强调了个性化上下文和看护者定制内容的重要性。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.07117", "html_url": "https://arxiv.org/abs/2404.07117", "title": "连续语言模型插值以实现动态和可控制的文本生成", "title_en": "Continuous Language Model Interpolation for Dynamic and Controllable Text Generation", "authors": "Sara Kangaslahti,David Alvarez-Melis", "background": "由于大型语言模型（LLMs）在多种应用场景中越来越受欢迎，使其适应和可控变得尤为重要，特别是在面向用户的应用中。现有文献主要关注选择最优模型来优化单一先定目标，而本文则探讨了模型必须实时适应多样化且可能发生变化的用户偏好的挑战。", "innovation": "本文提出了一种新颖的方法，即利用基于线性权重插值的适应技术，将这些方法视为连续多领域插值器，实时生成具有特定生成特征的模型。具体而言，使用低秩更新对基础模型进行微调，以适应不同的领域，从而获得具有不同生成特征的锚模型的集合。通过这些锚模型的权重更新参数化整个模型类。实验表明，改变插值权重可以持续性地预测模型输出的变化，并识别出主要特性之间的非纠缠关系及其特性对。", "conclusion": "线性插值插值后的调优权重模型能够实现对多个风格特征的同时可预测、精细控制。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21376", "html_url": "https://arxiv.org/abs/2508.21376", "title": "AHELM: 全面评估音频语言模型", "title_en": "AHELM: A Holistic Evaluation of Audio-Language Models", "authors": "Tony Lee,Haoqin Tu,Chi Heem Wong,Zijun Wang,Siwei Yang,Yifan Mai,Yuyin Zhou,Cihang Xie,Percy Liang", "background": "当前对音频-语言模型（ALMs）的评估受到标准化基准的缺乏限制；大多数基准仅衡量单一或少数能力，并忽略评估方面的公平性和安全性。此外，模型之间难以进行比较，因为不同的评估分别测试少量模型，并使用不同的提示方法和推理参数。这些不足促使作者引入AHELM作为新的基准，它汇集了多种数据集，并通过10个核心方面评估ALMs的性能，旨在促进公平比较。此外，AHELM标准化提示、推理参数和评估指标，引入了新的合成数据集PARADE和CoRe-Bench来评估模型在避免刻板印象和推理交流音频方面的表现，涵盖音频感知、知识、推理、情绪检测、偏见、公平性、多语言性、鲁棒性、毒性和安全性等方面。", "innovation": "AHELM 引入了新的合成数据集 PARADE 和 CoRe-Bench，这些数据集分别评估 ALMs 在避免刻板印象和推理交流音频方面的能力。此外，AHELM 标准化了提示、推理参数和评估指标，确保不同模型之间的公平比较。AHELM 为评估 ALMs 的广泛性能提供了统一的框架。", "conclusion": "AHELM 在10个重要方面评估了来自3个开发者的14个开放权重和封闭API的ALMs，结果显示虽然 Gemini 2.5 Pro 在5个方面名列前茅，但在ASR任务中表现出群体不公平性。其他模型也存在类似的问题。值得注意的是，尽管基线系统仅具备语音转文本功能，但在AHELM中的表现仍不错，其中一种系统排名第五。AHELM 旨在为 ALMs 提供一个持续更新的基准，未来将不断添加新的数据集和模型，以进一步改进评估方法。所有原始提示、模型生成和输出都可在作者网站上找到。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21561", "html_url": "https://arxiv.org/abs/2508.21561", "title": "总结-示例-反思：数据驱动的知识提取赋能大模型进行少量样本表格分类", "title_en": "Summarize-Exemplify-Reflect: Data-driven Insight Distillation Empowers LLMs for Few-shot Tabular Classification", "authors": "Yifei Yuan,Jiatong Li,Weijia Zhang,Mohammad Aliannejadi,Evangelos Kanoulas,Renjun Hu", "background": "最近的研究表明，大型语言模型（LLMs）在少量样本表格分类方面具有潜力，但也突显了基于结构化数据变化性的挑战。本文旨在解决这一问题，提出将数据提炼为可操作的洞察，以增强LLMs的稳健性和有效性。文章介绍了一个名为InsightTab的洞察提炼框架，该框架借鉴了人类学习过程的原则，包括分成、先易后难和反思学习。", "innovation": "文章提出了一种名为 InsightTab 的洞察提炼框架，该框架通过总结规则、选择性示例和反思学习，结合了大型语言模型和数据建模技术的深层协作，以提升LLMs在特定表格任务中的适应性。此外，通过实验证明该方法显著优于现有技术，并证明了指导性提炼过程的有效性及对标签数据的利用，同时强调了对偏见的有效管理。", "conclusion": "文中通过在九个数据集上的广泛应用，显示了 InsightTab 的一致改进优势。消融研究进一步验证了指导性提炼过程的合理性，而深入分析则突显了 InsightTab 在利用标注数据和管理偏见方面的显著效果。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21332", "html_url": "https://arxiv.org/abs/2508.21332", "title": "增强量子自然语言生成：一种结合量子-经典架构的多模型框架", "title_en": "Quantum-Enhanced Natural Language Generation: A Multi-Model Framework with Hybrid Quantum-Classical Architectures", "authors": "Chi-Sheng Chen,En-Jui Kuo", "background": "本文旨在评估量子文本生成模型在自然语言处理中的表现，特别是在传统Transformer和MLP架构之上。随着量子计算在自然语言处理中的应用越来越受关注，研究探索了多种基于量子的模型在这方面的应用潜力。", "innovation": "本文提出了一种基于量子-经典混合架构的多模型框架，进行了系统性的实验评估。比较了包括Transformer基线、Quantum Kernel Self-Attention Network (QKSAN)、Quantum RWKV (QRWKV) 和 Quantum Attention Sequence Architecture (QASA) 在内的五种模型在多种数据集上的表现。使用多种评估指标，如困惑度、BLEU分数、词汇多样性、重复率和流畅度等，全面评估文本生成质量。", "conclusion": "传统Transformer模型在平均困惑度和BLEU-1分数方面依然保持优势，但量子启发式模型在某些特定场景下表现出色。QKSAN在BLEU-1分数上表现与Transformer相近，且无重复率。QRWKV在某些任务中展现出完美的词汇多样性。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21081", "html_url": "https://arxiv.org/abs/2508.21081", "title": "SWIFT交易对手规范化与特征提取及聚类", "title_en": "Normalisation of SWIFT Message Counterparties with Feature Extraction and Clustering", "authors": "Thanasis Schoinas,Benjamin Guinard,Diba Esbati,Richard Chalk", "background": "短文本聚类在文本分析社区是一个已知的应用场景。当文本内容和结构属于自然语言领域，如推特帖子或即时消息时，可以使用自然语言技术，前提是文本足够长以允许使用（预）训练模型提取有意义的信息，比如词性标注或主题标注。然而，自然语言模型不适用于银行支付消息系统，如SWIFT中的交易对手聚类，因为交易对手通常是手工输入的标记，缺乏句子结构，同时包含人为输入的变异和噪音。这在犯罪调查人员或反欺诈专业人士试图增加其对支付流程发起方和受益方实体的了解以及追踪资金和资产时造成了一个缺口，传统上，供应商通过使用模糊匹配工具试图填补这个缺口。", "innovation": "本文提出了一个混合字符串相似度、主题建模、层次聚类和基于规则的流水线，以促进SWIFT交易对手的聚类，该方法可以处理未知数量的预期群组。还设计了补充评估方法的指标，基于经典的精度和召回率测量标准。在真实标记者集上的测试证明，该方法在基线关键词方法上的性能显著提高。该方法在保留基于规则系统的一部分可解释性的同时，通过增加额外的簇细化层次，增强了系统的性能。", "conclusion": "该方法在仅需调查人群中的一部分（例如制裁调查）的情况下，能够更好地控制遗漏实体变异的风险，从而减少人工审核的需求。此工作展示了如何弥补图形市场信息语言处理中的缺陷，并提供了一种实用的方法来增强金融信息的自动处理能力。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21452", "html_url": "https://arxiv.org/abs/2508.21452", "title": "从经典到复杂：大型语言模型在本科热力学中的能力衡量", "title_en": "From Canonical to Complex: Benchmarking LLM Capabilities in Undergraduate Thermodynamics", "authors": "Anna Geißler,Luca-Sophie Bien,Friedrich Schöppler,Tobias Hertel", "background": "大型语言模型（LLMs）逐渐被视为科学教育中的辅导辅助工具。然而，在本科教育中它们的独立使用准备情况仍存在不确定性，因为可靠的教育不仅需要流畅的记忆，还需要一致的原则性推理。热力学作为一门包含紧凑定律和细微区别的状态函数、路径函数、可逆性和熵等领域的学科，为评估这些能力提供了一个理想的测试平台。", "innovation": "该研究提出了UTQA，一个包含50个本科生热力学问答题基准，涵盖了理想气体过程、可逆性和图解解释。结果显示，即使是顶级的2025年模型也没有达到95%的熟练度阈值：最好的LLMs只有82%的准确率，文本题的表现优于图像推理任务，后者常常表现得如同随机猜测。提示措辞和语法复杂度与表现之间表现出适度到几乎没有的相关性。能力差距集中在有限速率/不可逆场景以及将视觉特征与热力学意义联系起来。", "conclusion": "目前的LLMs尚未准备好在该领域进行无监督的教学。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21512", "html_url": "https://arxiv.org/abs/2508.21512", "title": "接受还是拒绝？跨表格到文本序列化方法评估大型语言模型在贷款审批中的公平性和性能", "title_en": "Accept or Deny? Evaluating LLM Fairness and Performance in Loan Approval across Table-to-Text Serialization Approaches", "authors": "Israel Abebe Azime,Deborah D. Kanubala,Tejumade Afonja,Mario Fritz,Isabel Valera,Dietrich Klakow,Philipp Slusallek", "background": "大型语言模型（LLMs）在高风险决策任务中越来越受欢迎，例如贷款审批。尽管它们的应用范围不断扩展，但LLMs难以处理表格数据，从而影响了其公平性和预测的可靠性。本文评估了LLMs在三个不同地区的贷款审批序列化数据集上的性能和公平性，这些地区分别是加纳、德国和美国。研究集中在模型的零样本学习和上下文学习能力上。研究表明，不同的序列化格式对模型性能和公平性有显著影响，某些格式如GReat和LIFT虽然提高了F1分数但加剧了公平性差距。研究表明，上下文学习方法在提高模型性能方面表现出色，但对公平性的影响因数据集而异。这项研究强调了有效表格数据表示方法和公平性感知模型的重要性，以提高LLMs在金融决策中的可靠性。", "innovation": "本文研究了大型语言模型在不同地理区域贷款审批任务中的零样本学习和上下文学习能力，并发现不同的序列化格式对模型性能和公平性产生了显著影响。此外，上下文学习方法提高了模型的性能，但其对公平性的影响因数据集而异，这凸显了有效表格数据表示方法和公平性感知模型的重要性。", "conclusion": "有效表格数据表示方法和公平性感知模型对于提高大型语言模型在金融决策中的可靠性至关重要。不同序列化格式显著影响了模型的性能和公平性。上下文学习方法在提升模型性能方面表现出显著优势，但在公平性提升方面的效果却因数据集的不同而差异显著。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为什么止步于单词？通过行级OCR揭示更大的图像", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统的光学字符识别(OCR)技术会先分割每个字符，再进行识别，这使得字符分割容易出错，并且缺乏上下文，无法利用语言模型的优势。近年来序列到序列翻译技术的进步使得现代技术能够首先检测单词，然后再每次输入一个单词给一个模型，直接输出整个单词作为字符序列，这可以更好地利用语言模型并绕过易出错误的字符分割步骤。然而，作者观察到这种风格的转变使准确性的瓶颈转移到了单词分割。因此，论文提出了从单词级OCR到行级OCR的自然和逻辑进步。这种方法可以绕过单词检测中的错误，并提供更大的句子上下文，以更好地利用语言模型。实验结果表明，提出的方法不仅提高了准确性，还提高了OCR的效率。我们注意到，在深入的文献回顾中，我们没有找到用于训练和基准测试从单词级到行级OCR转换的公开数据集。因此，我们还贡献了一个精心收集的数据集，包含251张英文页面图像，并带有行级注解。实验结果表明，与基于单词的管道相比，该方法在端到端准确性上提高了5.4%，证实了转向行级OCR的潜在益处，尤其是在文档图像方面。此外，我们的方法还报告了4倍的效率提升。随着大型语言模型的不断进步，我们的方法也有可能利用这些进展的优势。", "innovation": "本文提出了从单词级OCR到行级OCR的自然和逻辑步骤，通过检测整行文本并利用更大的上下文，提高了OCR的准确性和效率。此外，作者还贡献了一个精心收集的数据集，用于训练和基准测试行级OCR技术，这在现有文献中是缺失的。", "conclusion": "实验结果表明，行级OCR方法相比传统方法不仅提高了准确性，还提高了效率，并且在端到端准确性的提高达到了5.4%。这种方法有可能通过利用大型语言模型的进步来进一步改进。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.24155", "html_url": "https://arxiv.org/abs/2410.24155", "title": "Large Language Model Reasoning_blind Spot Navigation with Thought Space Explorer", "title_en": "Blind Spot Navigation in Large Language Model Reasoning with Thought Space Explorer", "authors": "Jinghan Zhang,Fengran Mo,Tharindu Cyril Weerasooriya,Yeyang Zhou,Xinyue Ye,Dongjie Wang,Yanjie Fu,Kunpeng Liu", "background": "最近的大规模语言模型（LLMs）展示了它们在处理复杂推理任务方面的潜力，这些任务通常通过构建思维链来指导模型多步思考以解决问题。然而，现有方法往往局限于已探索的解决方案空间，从而忽视了LLMs认知范围内的关键盲点。现有的方法在此方面存在局限，因此需要新的方法来拓展和优化思维结构，以引导LLMs探索它们的认知盲点.", "innovation": "本文引入了”思维空间探索者“（TSE）框架，旨在扩展和优化思维结构，以引导LLMs探索它们的认知盲点。TSE通过基于原始思维结构生成多种新推理步骤和分支来扩展思维探索的视野，并减轻LLMs推理时受到的盲点影响。在多种推理任务上进行的实验表明，TSE方法超越了各种基线方法，也进行了广泛的分析以理解结构化的和扩展的思考如何有助于激发LLMs推理能力的潜力.", "conclusion": "TSE能够有效地扩展和优化LLMs的思维结构，提升其在解决复杂推理任务时的能力。通过生成新的推理步骤和分支，TSE增加了思维探索的范围，并减轻了盲点的影响。实验结果表明TSE在多种推理任务上表现优异，解释了结构化和扩展思维如何释放LLMs的潜力。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.06679", "html_url": "https://arxiv.org/abs/2409.06679", "title": "E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning", "title_en": "E2LLM: Encoder Elongated Large Language Models for Long-Context Understanding and Reasoning", "authors": "Zihan Liao,Jun Wang,Hang Yu,Lingxiao Wei,Jianguo Li,Jun Wang,Wei Zhang", "background": "随着大规模语言模型（LLMs）在多轮对话、代码生成和文档总结等任务中的应用越来越广泛，处理长文本上下文的能力变得愈发重要。然而，高长上下文性能、低计算复杂度和预训练模型的兼容性这三者互为制约，形成了所谓的“不可能三角”难题。该研究旨在解决这一问题，提出了一种新的方法E2LLM，以有效应对这一挑战并实现在长文本上下文理解与推理方面的出色表现和效率。", "innovation": "E2LLM引入了一种新颖的方法，将长文本上下文划分为片段，并使用预训练的文本编码器将每个片段压缩成软提示。这些软提示通过适配器与解码器仅有的LLM对齐。此外，为了增强LLM与这些软提示的交互，E2LLM采用了两项训练目标：编码器输出重构和长上下文指令微调。该方法在文档总结和问答任务中表现出色，并且在LongBench v2基准测试中实现了最佳性能，与同类大小的模型相比性能最优。", "conclusion": "研究证明E2LLM不仅在效果和效率上超越了8种最新方法，在任务完成上取得了显著的进展。E2LLM为解决长上下文处理的挑战提供了一种新的可行方案。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.19238", "html_url": "https://arxiv.org/abs/2406.19238", "title": "揭示大型语言模型中的细微价值观和观点", "title_en": "Revealing Fine-Grained Values and Opinions in Large Language Models", "authors": "Dustin Wright,Arnav Arora,Nadav Borenstein,Srishti Yadav,Serge Belongie,Isabelle Augenstein", "background": "通过分析大型语言模型（LLMs）中潜在的价值和观点，可以帮助识别偏见并减少潜在的危害。目前，这主要通过向LLMs提出调查问题并量化其输出对道德和政治声明的立场来实现。然而，LLMs的立场会因不同提示而有很大变化，且支持或反对某一观点有不同的论据方式。本文通过分析156000个LLMs对政治路线图测试（PCT）62项命题的反应，探讨了细致分析LSTM生成立场及其原文条陈的方法。研究发现，提示中加入的人口特征显著影响了PCT的结果，反映了偏见，并揭示了测试结果在引出封闭形式与开放领域回应时的差异。通过在原文条陈中识别模式（语汇），本文展示了不同模型和提示下继续生成相似理由的现象，即使立场截然不同也是如此。", "innovation": "本文提出了通过分析大量LSTM在PCT上的反应，特别是通过识别反应中的隐含语汇结构（tropes），来细粒度分析LSTM生成的立场和理由。这一方法为理解LSTM的反应提供了新的视角，揭示了模型和提示如何影响其路径选择的观点表达，并且发现了不同模型和提示下相似理由的反复出现，即使在显著不同的立场下也是如此。", "conclusion": "研究结果表明，提示中的人口特征对PCT结果产生了显著影响，反映了偏见，并揭示了测试结果在引出不同类型的回应时的差异。通过对LSTM反应进行细粒度分析和识别隐含语汇结构，本文展示了不同模型和提示下产生的相似理由，即使在显著不同的立场下也是如此。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21456", "html_url": "https://arxiv.org/abs/2508.21456", "title": "莫瑞：主动暂停UI代理供用户选择", "title_en": "Morae: Proactively Pausing UI Agents for User Choices", "authors": "Yi-Hao Peng,Dingzeyu Li,Jeffrey P. Bigham,Amy Pavel", "background": "UI代理（UI代理）有望使盲人和低视力（BLV）用户能够更容易地访问原本难以访问或复杂的用户界面。然而，目前的UI代理通常在执行任务时不涉及用户的最关键选择，也不让它们了解相关的重要背景信息，从而减少了用户的主动权。例如，在我们的实地研究中，一名BLV参与者请求购买最便宜的气泡水，但代理自动从多个同样价格的产品中选择了一个，却没有提及其他具有不同口味或更好评价的产品。", "innovation": "为了应对这一问题，我们介绍了莫瑞（Morae），一个在执行任务过程中自动识别决策点并暂停以便用户进行选择的UI代理。莫瑞使用大型多模态模型在解析用户查询的同时与UI代码和屏幕截图进行互动，并在需要选择时提示用户进行澄清。在一项针对BLV用户在真实世界网络任务的研究中，莫瑞帮助用户完成更多的任务，并选择了更能匹配其偏好的选项，相比基准代理包括OpenAI Operator。", "conclusion": "这项工作体现了用户在享受UI代理自动化带来的好处的同时，仍然能够表达自己的偏好的一种混合主动方法。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.06821", "html_url": "https://arxiv.org/abs/2504.06821", "title": "诱导程序化技能以完成代理任务", "title_en": "Inducing Programmatic Skills for Agentic Tasks", "authors": "Zora Zhiruo Wang,Apurva Gandhi,Graham Neubig,Daniel Fried", "background": "代理需要执行各种专门任务（如产品搜索或旅行线路规划）以完成普遍的数字任务（如网页导航）。这些任务可以通过与网络环境交互并在线学习特定技能来处理。本研究探讨了程序作为技能表示的有效性。", "innovation": "提出了代理技能归纳（ASI），使代理能够在归纳、验证和使用程序化技能过程中适应。相比于静态基线代理及其基于文本的技能，ASI在成功率上提高了23.5%，特别是在归纳阶段的程序验证保证方面。此外，ASI还能减少10.7%-15.3%的操作步骤，并且在扩展的网络活动下依然保持高效和准确性。", "conclusion": "ASI能够有效重用通用技能，并更新不兼容技能以适应网站变化，展示了在不同网站之间转移时的广泛适用性。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.04342", "html_url": "https://arxiv.org/abs/2412.04342", "title": "使用非结构化知识的检索增强机器翻译", "title_en": "Retrieval-Augmented Machine Translation with Unstructured Knowledge", "authors": "Jiaan Wang,Fandong Meng,Yingxue Zhang,Jie Zhou", "background": "检索增强生成(RAG)通过引入额外信息提升大规模语言模型(LLMs)。在机器翻译(MT)中，先前的研究主要从配对的MT语料库或知识图谱中获取上下文示例或域特定知识来增强MT模型。然而，世界知识组织在无结构文档中，可能在不同语言之间未完全配对。因此，该论文研究使用无结构文档的检索增强MT方法。", "innovation": "提出了RAGtrans基准，包含169K MT样本，通过GPT-4o和人类翻译收集，并提供了多种语言的文档以提供知识。此外，提出了多任务训练方法，利用现有跨语言语料库构造辅助训练目标，无需额外标注需求。实验表明，在中英和中德翻译中，该方法分别提高了1.6-3.1 BLEU和1.0-2.0 COMET分数，以及1.7-2.9 BLEU和2.1-2.7 COMET分数。", "conclusion": "当前的大规模语言模型在这个任务中面临一些关键挑战。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.10187", "html_url": "https://arxiv.org/abs/2504.10187", "title": "DeepTrans: 深度推理翻译 via 强化学习", "title_en": "DeepTrans: Deep Reasoning Translation via Reinforcement Learning", "authors": "Jiaan Wang,Fandong Meng,Jie Zhou", "background": "近年来，深度推理语言模型（例如：OpenAI的o1和DeepSeek-R1）在各种下游任务中展示了令人鼓舞的性能。自由翻译作为一个重要的、有趣的多语言任务，要求超出逐词翻译。然而，在深度推理语言模型中它仍然未被广泛探索。", "innovation": "提出了一种名为DeepTrans的深度推理翻译模型，通过强化学习（RL）来学习自由翻译行为。通过预定义评分标准，系统关注翻译结果和思考过程。使用Qwen2.5-7B作为基础模型，DeepTrans在文献翻译上性能提高了16.3%，超越了其他强壮的深度推理语言模型。此外，在强化学习探索中，描述了模型表现出的失败和有趣的发现。", "conclusion": "本文通过强化学习展示了DeepTrans的有效性，并希望这些发现能够激发其他研究人员在自由翻译领域的研究兴趣。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.14728", "html_url": "https://arxiv.org/abs/2503.14728", "title": "记忆编码中的战略资源分配：塑造语言处理的效率原则", "title_en": "Strategic resource allocation in memory encoding: An efficiency principle shaping language processing", "authors": "Weijie Xu,Richard Futrell", "background": "阐述了工作记忆容量限制下，如何有效支持人类语言行为的问题。文章从资源合理利用的角度，探讨了工作记忆资源如何动态并战略性地分配，以优先处理新颖和意外的信息。背景还涉及工作记忆容量有限和其表示噪声的功能假设，并提出了一个需要解决的计算问题，即如何在有限的资源下最小化检索误差，以及如何通过分配更多资源来更精确地编码更令人惊讶的信息。", "innovation": "提出了战略资源分配（SRA）作为记忆编码的基本效率原则。SRA着重于在工作记忆中优先处理新颖和意外的信息，并通过分配更多资源来更精确地编码这些信息，从而减少记忆衰减和干扰。文章通过自然语料库数据，发现SRA在依赖关系邻近性（从产生和理解的角度）方面表现出一致性，非局部依赖关系具有更不可预测先行词的语言与较低的邻近效应相关。", "conclusion": "结果表明，SRA强调了表征不确定性在记忆编码理解中的关键作用，同时也重新定义了意外和熵对处理难度的影响，从高效记忆编码的角度来看。此外，研究结果显示存在跨语言的显著差异，表明需要更深入地探讨SRA这一领域通用的记忆效率原则与具体语言短语结构之间的互动。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.21773", "html_url": "https://arxiv.org/abs/2504.21773", "title": "MAC-Tuning：增强知识边界意识的LLM多组成问题推理", "title_en": "MAC-Tuning: LLM Multi-Compositional Problem Reasoning with Enhanced Knowledge Boundary Awareness", "authors": "Junsheng Huang,Zhitao He,Yucheng Huang,Sandeep Polisetty,Qingyun Wang,Yi.R(May)Fung", "background": "LLMs在各种应用中广泛应用，但它们会生成不存在的事实，这是一个重要问题。以往研究通过分析内部参数化的知识边界来估算置信度，但这些研究主要集中在单问题设置上，尚未探索需要同时准确回答多个问题的更具有挑战性的多问题设置。", "innovation": "提出了一种名为Multiple Answers and Confidence Stepwise Tuning（MAC-Tuning）的新方法，在指令数据微调期间分离答案预测和置信度估计的学习过程，以应对多问题设置下的挑战。实验结果表明，该方法在平均精度上比基线高出25%以上。", "conclusion": "多个实验表明，我们的方法在平均精度方面显著优于基线模型，达到了25%以上的提升效果。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2501.12640", "html_url": "https://arxiv.org/abs/2501.12640", "title": "毒性引发毒性：剖析政治播客中的对话链", "title_en": "Toxicity Begets Toxicity: Unraveling Conversational Chains in Political Podcasts", "authors": "Naquee Rizwan,Nayandeep Deb,Sarthak Roy,Vishwajeet Singh Solanki,Kiran Garimella,Animesh Mukherjee", "background": "数字通信中的有毒行为一直是学术界和行业专业人士关注的紧迫问题。尽管大量的研究已经探讨了社交媒体和讨论板上的毒性，但播客尽管其普及率迅速增长，但在这一领域仍然相对较少受到研究。这项工作通过收集并分析政治播客的转录内容，重点研究对话结构，旨在填补这一空白。", "innovation": "这项研究的独特之处在于通过梳理政治播客转录记录，并专注于对话结构，分析毒性是如何通过对话回应序列表面并加剧的。研究揭示了有害语言如何在对话轮次中逐步升级的趋势和模式。", "conclusion": "研究结果强调了有毒行为的蔓延趋势以及在对话链条中如何通过层层递进的语言表达演变。这一发现为理解在线对话中的有毒行为模式以及可能的干预措施提供了新的视角。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00863", "html_url": "https://arxiv.org/abs/2506.00863", "title": "L3Cube-MahaEmotions: 使用CoTR提示和大型语言模型的马拉地语情感识别数据集", "title_en": "L3Cube-MahaEmotions: A Marathi Emotion Recognition Dataset with Synthetic Annotations using CoTR prompting and Large Language Models", "authors": "Nidhi Kowtal,Raviraj Joshi", "background": "低资源语言（如马拉地语）的情感识别因标注数据有限而具有挑战性。L3Cube-MahaEmotions数据集旨在填补这一空白，提供了细粒度的情感标签（11种），通过大型语言模型（LLM）合成标注和人工标注验证集及测试集构建，为这种低资源语情感识别任务提供了一个高质量的数据基准。", "innovation": "该研究使用链式翻译（CoTR）提示技术将马拉地语句子翻译成英语并进行情感标注，通过评估GPT-4和Llama3-405B的性能，发现通用的LLM在复杂低资源情感识别任务上表现得比微调后的BERT模型更好。并且该数据集和模型已公开发布。", "conclusion": "GPT-4预测结果优于微调后的BERT模型，但基于合成标签训练的BERT模型未能超越GPT-4。这项工作强调了高质量人类标注数据的重要性，同时也揭示了情感识别的固有复杂性。此外，通用LLM如GPT-4和Llama3-405B相比微调后的BERT模型在复杂低资源情感识别任务上具有更好的泛化能力。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.05137", "html_url": "https://arxiv.org/abs/2507.05137", "title": "通过最大期望方法实现可解释的汉字记忆词生成", "title_en": "Interpretable Mnemonic Generation for Kanji Learning via Expectation-Maximization", "authors": "Jaewook Lee,Alexander Scarlatos,Andrew Lan", "background": "罗马字母背景的学习者在学习日语词汇时面临挑战，因为它们的书写系统不同。日语结合了假名如平假名与来自汉字的表意文字（即 Kanji），而 Kanji 由于其复杂性和数量，本身也很复杂。关键词记忆是帮助记忆的常用策略，通常通过利用汉字的组合结构来形成生动的关联。尽管最近有使用大规模语言模型（LLMs）来辅助学习的努力，但现有的基于LLM的关键词记忆生成方法通常是黑箱操作，解释性有限。", "innovation": "本文提出了一种生成框架，该框架显式建模了记忆词构造过程，由一套通用规则驱动，并使用新型的期望最大化类型算法来学习这些规则。该方法利用在线平台上的学习者自主撰写的记忆词进行训练，从而学习到潜在结构和组合规则，使得生成的记忆词具有解释性和系统性。", "conclusion": "实验表明，该方法在新学习者的冷启动场景中表现良好，并提供了有效记忆词创建机制的见解。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.17464", "html_url": "https://arxiv.org/abs/2505.17464", "title": "Hydra：结构化跨源增强的大语言模型推理", "title_en": "Hydra: Structured Cross-Source Enhanced Large Language Model Reasoning", "authors": "Xingyu Tan,Xiaoyang Wang,Qing Liu,Xiwei Xu,Xin Yuan,Liming Zhu,Wenjie Zhang", "background": "当前的混合RAG系统通过从知识图谱（KGs）和文本文档中检索证据来支持LLM的推理，但仍然面临着多跳推理、多实体问题、多源验证以及有效利用图结构等挑战。", "innovation": "提出了Hydra，一种无需训练的框架，结合了图拓扑、文档语义和来源可靠性，以支持LLM的深度、忠实推理。Hydra通过代理驱动的探索结合结构化和非结构化检索来处理多跳和多实体问题，提高了证据的多样性和准确性。Hydra还通过来源可信度评估、跨源印证和实体路径对齐来解决多源验证问题，并平衡相关主题与跨模态一致性的关系。利用图结构，Hydra融合了异构来源，引导了高效的探索，并在早期去除了噪声。", "conclusion": "在七个基准数据集上的全面实验表明，Hydra 使用 GPT-3.5 达到了所有基准上的整体 SOTA 结果，相较于强大的混合基线 ToG-2，平均提高了 20.3%，最多提高了 30.1%。此外，Hydra 使较小的模型（如 Llama-3.1-8B）能够实现与 GPT-4-Turbo 相当的推理性能。源代码已发布。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15683", "html_url": "https://arxiv.org/abs/2505.15683", "title": "FedSEA-LLaMA：一种用于大型语言模型的安全、高效且适应性强的联邦分裂框架", "title_en": "FedSEA-LLaMA: A Secure, Efficient and Adaptive Federated Splitting Framework for Large Language Models", "authors": "Zishuai Zhang,Hainan zhang,Weihua Li,Qinnan zhang,jin Dong,Yongxin Tong,Zhiming Zheng", "background": "私有数据由于其高质量的特性有潜力提升大型语言模型（LLM）的效果，但这些数据分散在不同的数据孤岛中，以及对LLM的高计算需求限制了它们在联邦环境中的部署。为了应对这些挑战，提出了基于Transformer的联邦分裂模型，这将大部分模型参数卸载到服务器或分布式客户端上，仅保留一小部分在客户端以确保数据隐私。然而，这种方法仍面临三个问题：首先，端到端的向量传输难以有效进行加密；其次，由于LLM的自回归性质，导致联邦分裂学习只能顺序地训练和推断，从而增加了通信开销；最后，固定划分点缺乏对下游任务的适应性.", "innovation": "本文提出了FedSEA-LLaMA，这是一种基于LLaMA2的可适应、高效且安全的联邦分裂框架。首先在前向传输隐藏状态中注入高斯噪声，以实现在端到端加密向量传输中的安全性。其次，采用了注意掩码压缩和KV缓存合作的方法来降低通信成本，从而加速了训练和推理。第三，让用户能够根据特定任务要求动态调整输入输出块的划分点。实验表明，FedSEA-LLaMA在自然语言理解、总结和对话式问答任务中的性能与集中式LLaMA2相当，并且在训练和推理速度上均比中心化方法最多可提升8倍。进一步对隐私攻击和不同划分点的分析验证了FedSEA-LLaMA在安全性和适应性方面的有效性.", "conclusion": "FedSEA-LLaMA框架通过注入高斯噪声、注意掩码压缩和KV缓存合作，以及允许动态调整划分点，有效地缓解了联邦分裂过程中面临的安全、通信成本和适应性问题。实验结果表明FedSEA-LLaMA在性能与隐私保护方面均表现出色，为LLM在联邦环境中的应用提供了新的解决方案."}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.17178", "html_url": "https://arxiv.org/abs/2507.17178", "title": "SKA-Bench：评估大型语言模型结构性知识理解能力的细粒度基准", "title_en": "SKA-Bench: A Fine-Grained Benchmark for Evaluating Structured Knowledge Understanding of LLMs", "authors": "Zhiqiang Liu,Enpei Niu,Yin Hua,Mengshu Sun,Lei Liang,Huajun Chen,Wen Zhang", "background": "尽管大型语言模型（LLMs）在理解知识图谱（KG）和表格（Table）等结构性知识方面已经取得显著进步，现有的评估方法仍然非正式且单一，侧重于评估单一类型的结构性知识，缺乏具体能力的评价标准。因此，本研究旨在提出一个更为全面和严谨的结构性知识理解基准，以诊断大型语言模型的不足。", "innovation": "本文提出了一种结构性知识增强问答基准（SKA-Bench），覆盖了四种广泛使用的结构性知识形式：KG、Table、KG+Text和Table+Text。通过一个三阶段流水线构建SKA-Bench实例，并提出了四种关键能力测试模块：抗噪声能力、知识单元顺序无关性、信息整合和负面拒绝，以细粒度地评估模型在结构性知识理解方面的表现。", "conclusion": "实验结果显示，现有的大型语言模型在结构性知识理解方面仍然面临重大挑战，其性能受噪声量、知识单元顺序以及幻觉现象等因素影响。相关数据集和代码可以在提供的链接中找到。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17973", "html_url": "https://arxiv.org/abs/2508.17973", "title": "German4All -- 一个用于德语可读性控制重述的数据集和模型", "title_en": "German4All -- A Dataset and Model for Readability-Controlled Paraphrasing in German", "authors": "Miriam Anschütz,Thanh Mai Pham,Eslam Nasrallah,Maximilian Müller,Cristian-George Craciun,Georg Groh", "background": "文本重述能力跨越不同复杂度级别对于创建无障碍文本至关重要，这些文本可以根据不同的读者群进行定制。目前缺乏大规模的多级别可读性控制的德语文本重述数据集。", "innovation": "提出了德语4全体裁，这是首个多级别可读性控制的德语文本重述数据集，覆盖五个可读性级别，包含超过25,000个样本。数据集是使用GPT-4自动生成的，并通过人工和基于LLM的评估进行严格测试。基于德语4全体裁数据集，他们训练了一个开源、可读性控制的文本重述模型，该模型在德语文本简化方面达到了最先进的性能，能够实现更具针对性的读者适应。", "conclusion": "通过开源数据集和模型，鼓励进一步开展多级别重述的研究。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.19028", "html_url": "https://arxiv.org/abs/2506.19028", "title": "超越标记的LLM公平性量化：一种语义与统计视角", "title_en": "Quantifying Fairness in LLMs Beyond Tokens: A Semantic and Statistical Perspective", "authors": "Weijie Xu,Yiwen Wang,Chi Xue,Xiangkun Hu,Xi Fang,Guimin Dong,Chandan K. Reddy", "background": "大型语言模型（LLMs）在生成响应时常常带有固有的偏见，这影响了它们在实际应用中的可靠性。现有的评估方法往往忽视了长文本响应中的偏见和LLM输出的内在变化。为了应对这些挑战，本研究提出了一种新颖的统计框架FiSCo（Fine-grained Semantic Comparison），用于通过检测不同人口群体间长文本响应中的微小语义差异来评估LLM的成组公平性。不同于以往集中在情感或标记层面比较的研究，FiSCo在断言层面进行分析，利用蕴含检查评估响应中意义的一致性。研究将模型输出分解为语义独立的断言，并通过统计假设检验对比组内和组间相似性，从而实现对细微偏见的稳健检测。研究还提出了一种新的群体反事实公平性定义，并在涵盖性别、种族和年龄的人工标注数据集上验证了FiSCo。实验表明，FiSCo在识别微偏见方面更为可靠，减少了随机状态下的LLM变化影响，超过了各种评估指标的有效性。", "innovation": "本研究提出的FiSCo框架通过在断言层面进行分析和利用蕴含检查来检测LLM响应中的语义差异，这在现有方法中是新颖的。与以往集中在情感或标记层面的比较不同，FiSCo可以更深入地理解LLM输出的意义一致性。此外，研究还提出了一个新颖的群体反事实公平性定义，进一步增强了评估的理论基础。", "conclusion": "实验证明，FiSCo在检测细微偏见方面更具可靠性，能够减少随机性对LLM输出的影响，优于各种评估指标。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.04090", "html_url": "https://arxiv.org/abs/2411.04090", "title": "基于标注分歧规范化估计的合作型内容审核框架用于毒性检测", "title_en": "A Collaborative Content Moderation Framework for Toxicity Detection based on Conformalized Estimates of Annotation Disagreement", "authors": "Guillermo Villate-Castillo,Javier Del Ser,Borja Sanz", "background": "内容审核通常结合了人类审核员和机器学习模型的努力。然而，这些系统往往依赖于在审核过程中存在显著分歧的数据，反映了毒性感知的主观性。现有的方法往往忽视这种分歧，而将其视为噪声，而不是有价值的信号。这种信号揭示了审核内容本身的内在模糊性。", "innovation": "本文提出了一种新的内容审核框架，强调捕捉标注分歧的重要性。该框架采用多任务学习，其中毒性分类为主要任务，标注分歧作为辅助任务。此外，本文利用不确定性估计技术，即规范性预测，来考虑注释模糊性和模型预测毒性时的固有不确定性。该框架还允许审核人员调整标注分歧的阈值，从而在决定何时触发审核时提供灵活性。", "conclusion": "本文联合方法提高了模型性能、校准和不确定性估计，同时在参数效率和审核流程改进方面优于单一任务方法。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.17052", "html_url": "https://arxiv.org/abs/2504.17052", "title": "测试信念：一种衡量LLM政治稳定性的论辩框架", "title_en": "Testing Conviction: An Argumentative Framework for Measuring LLM Political Stability", "authors": "Shariar Kabir,Kevin Esterling,Yue Dong", "background": "大语言模型（LLMs）在政治话语中扮演着越来越重要的角色，但它们在受到挑战时表现出不一致的反应。现有研究基于单一提示响应将LLMs分类为左翼或右翼，但这种方法存在的问题是，这些分类是否反映了稳定的意识形态或仅仅是表面的表现。现有方法无法区分真正的意识形态倾向和表象性文本生成。", "innovation": "本文提出了一个框架来评估意识形态的深度，包括（1）论辩一致性和（2）不确定性的量化，用于测试12个LLMs在政治罗盘测试中的19项经济政策反应，将其分类为稳定的或表象性的意识形态定位。结果表明，95%的左翼模型和89%的右翼模型在不同实验条件下表现出与其分类一致的行为，并且语义熵强烈支持这些分类（AUROC=0.78），揭示了不确定性与意识形态一致性之间的关系。研究发现，意识形态的稳定性因议题而异，并挑战了LLM单一意识形态的概念。", "conclusion": "本文的研究结果证明了意识形态稳定性因议题而异，并挑战了单一LLM意识形态的概念，提供了一种区分真正一致性行为和表现性行为的稳健方法。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16665", "html_url": "https://arxiv.org/abs/2508.16665", "title": "Trust but Verify! 一项关于测试时扩展验证设计的综述", "title_en": "Trust but Verify! A Survey on Verification Design for Test-time Scaling", "authors": "V Venktesh,Mandeep Rathee,Avishek Anand", "background": "测试时扩展(TTS)已经成为了在推理时增强大语言模型性能的新前沿。这种方法通过使用更多的计算资源，在推理期间改善模型的推理过程和任务性能。已经出现了一些TTS的方法，例如从另一个模型中蒸馏推理跟踪，或通过使用验证器探索广泛的解码搜索空间。验证器作为奖励模型，在解码过程中帮助评分候选输出以努力探索广泛的解空间并选择最佳结果。这些方法因其在线推理时无参数扩展和出色的性能收益而被广泛应用，验证器可以基于提示、微调为区分或生成模型来验证过程路径、结果或两者。尽管这些方法被广泛应用，但关于它们的详细分类、训练机制和应用场景的讨论仍然缺乏。", "innovation": "该论文提供了一个详细的综述，涵盖了文献中涉及的各种验证方法，并提供了一个统一的视角来理解验证器的训练、类型及其在测试时扩展的应用。更重要的是，该论文还提供了一个包含验证方法的资源库，以便于进一步研究与应用。", "conclusion": "本文提供了一个统一的视角来审视验证器在TTS中的作用，并分类和讨论了各种验证方法及其培训机制。同时，他们还将创建的资源库公开，以支持未来的研究工作。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19758", "html_url": "https://arxiv.org/abs/2508.19758", "title": "通过多元新闻检索全面理解事件：发现更大的图景", "title_en": "Uncovering the Bigger Picture: Comprehensive Event Understanding Via Diverse News Retrieval", "authors": "Yixuan Tang,Yuanyuan Shi,Yiqun Sun,Anthony Kum Hoe Tung", "background": "现有的新闻检索系统通常侧重于文本的相关性，这导致了重复结果和狭窄的观点视野。获取多样化的视角对于理解现实事件至关重要，但现有的方法未能充分实现这一点。为了应对这一挑战，研究者们提出了一种名为NEWSCOPE的双阶段框架，该框架通过在句子层面上建模语义差异来增强事件的覆盖范围，从而改善新闻检索过程。", "innovation": "该框架通过两个步骤来实现，首先是使用密集检索获取主题相关的具体内容，然后再进行句子级别的聚类和多样化重新排名，以呈现互补的信息。此外，研究还引入了三个可解释性度量标准，即平均成对距离、正面簇覆盖率和信息密度比，并构建了两个段落级别的基准：LocalNews和DSGlobal。这些度量标准能够更好地评估多样性和相关性之间的平衡。实验结果显示，NEWSCOPE在增强多样性方面超过了强大的基线方法，同时并不牺牲相关性。", "conclusion": "研究结果表明，详细的、可解释的模型在缓解冗余和促进全面事件理解方面非常有效。所使用的数据和代码可在以下链接获取：this https URL."}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.12800", "html_url": "https://arxiv.org/abs/2508.12800", "title": "Atom-Searcher：通过细粒度原子思想奖励增强自主深度研究", "title_en": "Atom-Searcher: Enhancing Agentic Deep Research via Fine-Grained Atomic Thought Reward", "authors": "Yong Deng,Guoqing Wang,Zhenzhe Ying,Xiaofeng Wu,Jinzhen Lin,Wenwen Xiong,Yuqin Dai,Shuo Yang,Zhanwei Zhang,Qiwen Wang,Yang Qin,Yuan Wang,Quanxing Zha,Sunhao Dai,Changhua Meng", "background": "大型语言模型（LLMs）在解决问题方面表现出色，但在复杂任务上表现不佳，因为它们的内部知识是静态的。检索增强生成（RAG）虽然能够访问外部信息，但在多跳推理和战略搜索方面仍受到固定流程的限制。最近的研究表明LLMs可以在自主推理、搜索和信息合成方面做出独立的判断，但是当前依赖于基于结果的强化学习（RL）方法存在诸如冲突梯度和奖励稀疏性等关键问题，这限制了性能提升和训练效率。", "innovation": "首先提出了一种新的LLM思考范式——原子思想（Atomic Thought），将推理分解为细粒度的功能单位，并由推理奖励模型（RRMs）监督，提供细粒度的指导奖励（Atomic Thought Rewards, ATR）。在此基础上，提出了Atom-Searcher，一种结合了Atomic Thought和ATR的新RL框架，采用了教学灵感的奖励计划，优先进行过程级别的ATR，然后过渡到结果奖励，加速达到有效的推理路径。该框架包括：(1) Atom-Searcher在测试时可扩展计算。(2) Atomic Thought为RRMs提供监督锚点，将深度研究任务与RRMs结合。(3) Atom-Searcher表现出更可解释、类似人类的推理模式。", "conclusion": "实验证明，Atom-Searcher在七个基准测试中表现出了一致的改进。关键优势包括：(1) Atom-Searcher在测试时可扩展计算。 (2) Atomic Thought为RRMs提供了监督锚点，有助于将深度研究任务与RRMs结合。 (3) Atom-Searcher展示出更可解释、类似人类的推理模式。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.17202", "html_url": "https://arxiv.org/abs/2508.17202", "title": "在100美元预算下进行有成效领域知识获取：通过低成本、专家参与互动提升特定领域大语言模型", "title_en": "Active Domain Knowledge Acquisition with 100-Dollar Budget: Enhancing LLMs via Cost-Efficient, Expert-Involved Interaction in Sensitive Domains", "authors": "Yang Wu,Raha Moraffah,Rujing Yao,Jinhong Yu,Zhimin Tao,Xiaozhong Liu", "background": "大语言模型（LLMs）展现了令人印象深刻的广泛知识，但在药物发现和罕见病研究等高度专业化且成本敏感的领域表现不佳，主要是因为缺乏专业知识。已有研究中，传统微调方法一般未能有效利用有限专家资源。", "innovation": "本文提出了一种新颖的框架（PU-ADKA），旨在通过高效利用预算内的专家资源，来增强领域专指的LLMs。该框架能主动识别并优先查询最适合的专家，综合考量专家的可用性、知识边界与咨询成本。", "conclusion": "通过在PubMed数据上的模拟训练及与药物研发团队的实际交互验证，PU-ADKA在预算严格的条件下显著提升了LLM在专业化领域的性能。本文还介绍了用于评估LLM成本效益领域知识获取的全新基准数据集CKAD，旨在推动这一难题领域内的研究进展。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20410", "html_url": "https://arxiv.org/abs/2508.20410", "title": "UI-Bench: 评估AI文本到应用工具设计能力的标准", "title_en": "UI-Bench: A Benchmark for Evaluating Design Capabilities of AI Text-to-App Tools", "authors": "Sam Jung,Agustin Garcinuno,Spencer Mateega", "background": "目前存在许多AI文本到应用工具，这些工具声称能够快速生成高质量的应用程序和网站，但缺乏公正的基准测试来验证这些断言。现有的验证方法不充分或者不具备规模，UI-Bench作为第一个大规模基准测试，通过专家级的两两对比来评估这些工具在视觉设计上的卓越性，填补了这一空白。", "innovation": "UI-Bench通过引入大规模专家级两两对比的方法，评测了10种不同的AI文本到应用工具的设计质量。它使用一个基于TrueSkill模型的排名体系，提供可校准的置信区间，使得评测结果更加可靠。与此同时，UI-Bench还开放了完整的问题集、开源评价框架以及公共排行榜，为AI驱动网页设计提供了可重复的标准，促进了该领域的技术进步和发展。", "conclusion": "通过UI-Bench，首次全面且系统地评测了当前市场上各种AI文本到应用工具的设计水平。该基准测试不仅提供了详尽的可信排名，还公开了所有相关资料，鼓励更多的研究者参与到AI文本到应用工具的设计评测中来，从而推动这一技术的发展。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19828", "html_url": "https://arxiv.org/abs/2508.19828", "title": "Memory-R1：通过强化学习提高大型语言模型代理管理并利用记忆的能力", "title_en": "Memory-R1: Enhancing Large Language Model Agents to Manage and Utilize Memories via Reinforcement Learning", "authors": "Sikuan Yan,Xiufeng Yang,Zuchao Huang,Ercong Nie,Zifeng Ding,Zonggen Li,Xiaowen Ma,Hinrich Schütze,Volker Tresp,Yunpu Ma", "background": "大型语言模型（LLMs）在广泛的自然语言处理（NLP）任务中展示了出色的能力，但它们仍处于无状态（stateless）状态，受限于有限的上下文窗口，这限制了其进行长期推理的能力。现有的一些解决方法是通过外部记忆库增强LLMs，但这些方法大多数是静态和启发式的，缺乏任何学习机制来决定什么应该存储、更新或检索。", "innovation": "本文提出了Memory-R1，这是一种强化学习（RL）框架，它为LLMs配备了主动管理并利用外部记忆的能力，通过两个专门代理实现：Memory Manager 负责学习执行结构化内存操作，包括添加、更新、删除或不执行内存条目；Answer Agent 选择最相关的内容并基于它们进行推理以生成答案。二者通过结果驱动的RL（PPO和GRPO）进行微调，使得记忆管理与利用更加适应性，同时对少量监督也能良好工作。Memory-R1仅需152个问题-答案对及其对应的临时记忆库即可训练，并能跨多种问题类型和LLM架构表现出强大的泛化能力。", "conclusion": "本文不仅提供了一种有效的手段，还指出RL如何解锁LLMs中更具有主动性、记忆力更强的行为，指明了未来更丰富的、持久的推理系统的方向。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.20417", "html_url": "https://arxiv.org/abs/2508.20417", "title": "KG-CQR: 在知识图谱中利用结构化关系表示进行上下文查询检索", "title_en": "KG-CQR: Leveraging Structured Relation Representations in Knowledge Graphs for Contextual Query Retrieval", "authors": "Chi Minh Bui,Ngoc Mai Thieu,Van Vinh Nguyen,Jason J.Jung,Khac-Hoai Nam Bui", "background": "知识图谱（KGs）与大规模语言模型（LLMs）的集成为检索增强生成（RAG）系统的检索阶段带来了显著的改进潜力。现有方法主要针对语篇级上下文丢失问题，而KG-CQR框架则专注于通过结构化关系表示来增强查询，从语料库中提取和完成相关的知识图谱子图，生成语义丰富的查询上下文。", "innovation": "KG-CQR提出了一种新的上下文查询检索（CQR）框架，通过语料库中心的知识图谱来丰富复杂输入查询的上下文表示。它由子图提取、完成和上下文生成模块组成，形成一个模型无关的管道，确保不同规模的LLMs的扩展性，无需额外训练。实验结果表明，KG-CQR在RAGBench和MultiHop-RAG数据集上的性能优于强基线模型，特别是在map和Recall@25的指标上分别提高了4-6%和2-3%。在具有挑战性的RAG任务，如多跳问答中，KG-CQR的引入也显著提高了检索的效果。", "conclusion": "KG-CQR框架在RAG任务中表现出色，通过利用知识图谱中的结构化关系表示，显著提高了查询检索的质量。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15376", "html_url": "https://arxiv.org/abs/2504.15376", "title": "理解任何视频中的摄像机运动", "title_en": "Towards Understanding Camera Motions in Any Video", "authors": "Zhiqiu Lin,Siyuan Cen,Daniel Jiang,Jay Karhade,Hewei Wang,Chancharik Mitra,Tiffany Ling,Yuhan Huang,Sifan Liu,Mingyu Chen,Rushikesh Zawar,Xue Bai,Yilun Du,Chuang Gan,Deva Ramanan", "background": "介绍了CameraBench数据集和基准测试，旨在评估和改善摄像机运动理解。该数据集包括约3000个互联网视频，并通过严格的多阶段质量控制过程进行专家注释。本文还提出了一种与电影摄影师合作制定的摄像机运动基本要素分类法。", "innovation": "提出了一种新的数据集和基准测试框架，提供了一种摄像机运动基本要素分类法，首次量化了人类注释的表现，并通过与结构从运动（SfM）模型和视频语言模型（VLMs）的评估对比，揭示了架构与训练策略对表现的关键影响。通过在CameraBench上对生成型VLM进行微调，实现了结合语义和几何理解的最佳效果。", "conclusion": "希望提出的分类法、基准测试和教程能够促进今后在理解任何视频中摄像机运动的努力，并展示其在视频增强描述、视频问题回答和视频文本检索中的应用。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.19997", "html_url": "https://arxiv.org/abs/2508.19997", "title": "探索针对长尾法律文本分类的有选择检索增强方法", "title_en": "Exploring Selective Retrieval-Augmentation for Long-Tail Legal Text Classification", "authors": "Boheng Mao", "background": "法律领域的文本分类是自然语言处理（NLP）中的基本任务。现有的基准数据集通常表现出长尾标签分布的特点，即许多标签的样本很少，这导致模型在罕见类别上的表现不佳。", "innovation": "本文探讨了有选择检索增强（SRA）作为处理长尾分布问题的方法。SRA在训练集中增强低频标签的样本，避免引入噪声，并不影响经常出现类别的样本，无需改变模型结构。检索只从训练数据中进行，确保不会泄露信息，也不需要外部语料库。", "conclusion": "SRA在LEDGAR（单标签分类）和UNFAIR-ToS（多标签分类）两个具有长尾分布的基准数据集上的实验结果表明，SRA在微分F1和宏F1分数上都优于LexGLUE基线方法。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.06748", "html_url": "https://arxiv.org/abs/2412.06748", "title": "拒绝标记：一种简单的方法来校准大型语言模型中的拒绝行为", "title_en": "Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models", "authors": "Neel Jain,Aditya Shrivastava,Chenyang Zhu,Daben Liu,Alfy Samuel,Ashwinee Panda,Anoop Kumar,Micah Goldblum,Tom Goldstein", "background": "构建安全可靠的语言模型的关键组成部分之一是让模型能够适当地拒绝某些指令或回答某些问题。用户可能希望模型在面对不同类型的问题时输出拒绝信息，例如不当的问题、违法的行为指令或超出模型知识范围的查询。由于个体和用户对不同类别查询的敏感程度存在差异，通过培训多种模型以满足个体和用户的偏好需要大量的计算资源，并且可能需要为每个用户重新训练模型。这导致了高昂的成本且不够灵活。因此，当前的方法面临挑战。", "innovation": "本文提出了拒绝标记，通过将拒绝标记预置于模型响应中，可以在推理阶段通过调整生成每个类别拒绝标记的概率来调控模型的拒绝行为。这种方法允许通过单个模型控制多种类型的拒绝频率，无需进一步微调，只需要在生成过程中有选择地干预即可。", "conclusion": "拒绝标记提供了一种简单且有效的途径，以灵活控制大型语言模型在面对不同类型查询时的拒绝行为，无需为每个用户定制模型。这种方法成本更低且更加灵活。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2412.00631", "html_url": "https://arxiv.org/abs/2412.00631", "title": "ROSE：一种面向大语言模型特定任务指令调优的数据选择框架", "title_en": "ROSE: A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning", "authors": "Yang Wu,Huayi Zhang,Yizheng Jiao,Lin Ma,Xiaozhong Liu,Jinhong Yu,Dongyu Zhang,Dezhi Yu,Wei Xu", "background": "大语言模型（LLMs）通过指令调优展现了显著的人工控制能力和有效性，但现有方法主要依赖手工构建的相似度度量来选择与测试数据分布相匹配的训练数据。尽管前述方法旨在最小化对测试数据的指令调优损失以提升目标任务性能，但最近观察到LLMs中的指令调优损失（如下一个令牌预测的交叉熵损失）往往不与实际任务性能呈现单调关系。这表明现有数据选择方法的有效性不足。", "innovation": "本文提出了一种名为ROSE的新颖奖励导向的指令数据选择方法，通过利用成对偏好损失作为奖励信号优化特定任务指令调优的数据选择。ROSE采用影响公式近似评估训练数据点相对于几项式偏好验证集合的影响，从而选取与任务最相关的训练数据点。实验结果表明，即使只使用ROSE选择的5%训练数据，本文方法也能与使用完整训练数据集微调相比实现性能相近的结果，并且在多种最先进的数据选择方法中表现出色。", "conclusion": "我们的定性分析进一步证明了该方法在多个基准数据集和不同模型架构上的稳健泛化能力。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.14481", "html_url": "https://arxiv.org/abs/2503.14481", "title": "不要对朋友说谎：从协作自游戏中学会你知道的内容", "title_en": "Don't lie to your friends: Learning what you know from collaborative self-play", "authors": "Jacob Eisenstein,Reza Aghajani,Adam Fisch,Dheeru Dua,Fantine Huot,Mirella Lapata,Vicky Zayats,Jonathan Berant", "background": "为了成为有帮助的助手机器人，AI代理必须了解自己的能力和局限性。这包括知道何时用参数化知识作答、何时信任工具输出、何时避免或进行权衡。这些能力通过监督微调很难传授，因为需要构建反映代理具体能力的例子。因此，本文提出了一个新的方法来教导代理它们所知道的内容：协作自游戏。在这种方法中，代理被置于一个团队环境中，通过协作达到正确答案，团队的奖励机制促进了所需元知识的产生。", "innovation": "本文提出了一种全新的方法，即合作自游戏，通过一种激励机制让多代理团队共同寻求正确答案，从而获得所需的知识和元知识。这种方法特别适用于拥有不同工具（如特定语料检索）的代理，使其能够合作以最大化成功同时减少努力。", "conclusion": "实验表明，多代理社区的集体奖励可以促使生成的策略在各个代理独自部署的场景中，改善工具使用和选择性预测的效果。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.15689", "html_url": "https://arxiv.org/abs/2506.15689", "title": "BASE-Q: 偏置校正和非对称缩放增强的旋转量化方法", "title_en": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "authors": "Liulu He,Shenli Zheng,Karwei Sun,Yijiang Liu,Yufei Zhao,Chongkang Tan,Huanrui Yang,Yuan Du,Li Du", "background": "旋转量化方法已成为大型语言模型（LLMs）中最新的量化管道的关键组成部分，通过有效平滑权重和激活中的异常值。然而，进一步优化旋转参数仅能提供有限的性能提升，同时会引入显著的训练开销：由于旋转参数共享，必须同时加载整个模型以支持反向传播，从而导致内存消耗巨大，限制了其实用性。", "innovation": "本文识别出当前旋转量化方法的两项根本限制：（i）旋转未能对齐通道均值，导致量化区间更宽和增加舍入误差；（ii）旋转使激活分布更趋向于高斯分布，增加了剪裁误差导致的能量损失。为了解决这些难题，我们提出了BASE-Q，这是一种简单而强大的方法，结合了偏置校正和非对称缩放，有效减少了舍入和剪裁误差，并允许分块优化，从而消除对内存密集型全模型反向传播的需求。", "conclusion": "通过广泛的实验，在不同LLMs和基准测试上证实了BASE-Q的有效性，与QuaRot、SpinQuant和OSTQuant相比，BASE-Q将准确率差距分别缩小了50.5%、42.9%和29.2%。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15780", "html_url": "https://arxiv.org/abs/2504.15780", "title": "TrustGeoGen: 针对可信多模态几何问题解决的正式验证数据引擎", "title_en": "TrustGeoGen: Formal-Verified Data Engine for Trustworthy Multi-modal Geometric Problem Solving", "authors": "Daocheng Fu,Jianlong Chen,Renqiu Xia,Zijun Chen,Qi Liu,Yuan Feng,Hongbin Zhou,Renrui Zhang,Shiyang Feng,Peng Gao,Hongyuan Zha,Junchi Yan,Botian Shi,Yu Qiao,Bo Zhang", "background": "数学几何问题解决（GPS）要求严格的逻辑一致性和多模态推理能力。尽管大型语言模型（LLMs）在GPS方面取得了快速进展，但它们的进步受到缺乏可靠基准和系统方法的阻碍。关键挑战在于LLMs固有的虚构性，导致生成的GPS数据集往往是噪声大、未验证且自相矛盾的。为解决这一问题，作者引入了TrustGeoGen，这是一个数据引擎，用于生成正式验证的几何问题，以建立基于原则的可信赖基准。", "innovation": "TrustGeoGen 引擎包含四个关键创新点：1) 多模态对齐，同步生成图形、文本和逐步解决方案；2) 正式验证，确保所有推理路径符合规则；3) 连接思考，将形式推理与人类逻辑步骤相衔接；4) 我们的 GeoExplore 系列算法，生成具有多种解决方案和自我反思回溯的多样化问题变体。使用该引擎，创建了GeoTrust-200K数据集和相应的GeoTrust-test基准，两者均保证了跨模态的完整性。实验证明，最先进的模型在GeoTrust-test上的准确率仅为45.83%，突显了其挑战性。此外，使用合成数据进行训练显著提高了模型在GPS任务上的性能，且具有良好的迁移泛化能力。", "conclusion": "通过使用TrustGeoGen引擎生成的合成数据集，实验证明当前最先进的模型在GeoTrust-test上的准确率仅有45.83%，表明该数据集具有显著挑战性。此外，通过在合成数据上进行训练，模型在GPS任务上的性能得到了显著提升，并且对域外基准也有较强的泛化能力。相关的代码和数据可在指定链接下载。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21090", "html_url": "https://arxiv.org/abs/2508.21090", "title": "Q-Align: 通过Query-Query对齐缓解零样本外观转换中的注意力泄露", "title_en": "Q-Align: Alleviating Attention Leakage in Zero-Shot Appearance Transfer via Query-Query Alignment", "authors": "Namu Kim,Wonbin Kweon,Minsoo Kim,Hwanjo Yu", "background": "我们观察到，使用大规模图像生成模型进行零样本外观转换面临一个重大挑战：注意力泄露。这一挑战源于语义映射在Query-Key对齐中的捕捉。", "innovation": "我们提出了Q-Align，利用Query-Query对齐来减轻注意力泄露，从而提高零样本外观转换中的语义对齐。Q-Align包含三项核心贡献：(1) Query-Query对齐，促进两幅图像之间的精细空间语义映射；(2) Key-Value重新排列，通过重新对齐增强特征对应；(3) 使用重新排列的键和值进行注意力改进，以保持语义一致性。我们通过广泛的实验和分析验证了Q-Align的有效性，同时在外观保真度上超越了最先进的方法，同时保持了竞争性的结构保真度。", "conclusion": "我们通过广泛的实验和分析验证了Q-Align的有效性，并在外观保真度上超越了最先进的方法，同时保持了竞争性的结构保真度。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.15266", "html_url": "https://arxiv.org/abs/2504.15266", "title": "掷骰子与三思而后行：超越下一个标记预测的创造性极限", "title_en": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction", "authors": "Vaishnavh Nagarajan,Chen Henry Wu,Charles Ding,Aditi Raghunathan", "background": "研究者设计了一系列简化的算法任务，这些任务松散地抽象了开放性的实际任务。这使得可以清晰和可控地量化现有语言模型的创造性边界。这些任务类似于需要创造性远见的任务，需要一种隐式的开放性随机规划步骤，要么发现抽象知识图中的新连接，要么构建新的图案。研究者通过实证和概念上的方法表明，下一个标记的学习是短视的，而多标记方法（如无监督训练和扩散模型）则能更好地产生多样性和原创性输出。此外，为了在不损害连贯性的情况下引入随机性，研究人员发现，在输入层注入噪声（称为种子条件）的效果非常好，甚至在某些情况下优于输出层的温度采样。这项研究提供了一个分析开放性创造性技能的原则性、简化的测试床，并为超越下一个标记学习和温度采样提供了新的理由。部分代码已公开可在此链接寻找：this https URL", "innovation": "研究者设计了一系列用于衡量语言模型创造力的简化算法任务，这些任务包括寻找抽象知识图的新连接或构建新图案。研究发现，与下一个标记学习相比，多标记方法（如无监督训练和扩散模型）在产生多样性和原创性输出方面表现出色。此外，研究提出了在输入层注入噪声作为引入随机性的新方法，这种方法在不损害连贯性的情况下，效果也非常显著甚至在某些情况下更佳。这一发现为超越传统的下一个标记预测提供了新的思路和理论支持。", "conclusion": "这项研究提供了一个分析开放性创造性技能的原则性、简化的测试床，并为超越下一个标记学习和温度采样提供了新的理由。通过这种方法，研究发现多标记方法在生成多样性和原创性方面表现更优，而在输入层注入噪声方法的引入为引入随机性提供了一种有效且可行的解决方案。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21091", "html_url": "https://arxiv.org/abs/2508.21091", "title": "ERTACache: Error Rectification and Timesteps Adjustment for Efficient Diffusion", "title_en": "ERTACache: Error Rectification and Timesteps Adjustment for Efficient Diffusion", "authors": "Xurui Peng,Hong Liu,Chenqian Yan,Rui Ma,Fangmin Chen,Xing Wang,Zhihua Wu,Songwei Liu,Mingbao Lin", "background": "扩散模型由于其固有的迭代推理过程，面临着重大的计算成本问题。特征缓存提供了一种通过重用中间输出来加速的方法，但简单的重复使用经常会带来质量下降。对此，本文正式分析了缓存引入的累积误差，并将其分解为两种主要部分：特征偏移误差和步骤放大误差。前者的产生是由于缓存输出的不准确，后者的产生则是因为固定时间步长调度下的误差传播。", "innovation": "本文提出了ERTACache，一种原理上纠正这两种误差类型的缓存框架。该方法通过离线残差分析阶段识别可重用步骤，动态调整积分区间并通过轨迹感知校正系数，以及利用闭式残差线性化模型分析缓存引起的错误。这些组件共同使得在激进的缓存重用下实现准确高效的采样。", "conclusion": "在标准的图像和视频生成基准上进行的广泛实验表明，ERTACache可以实现至多2倍的推理加速，同时保持或甚至提高视觉质量。特别是在最先进的Wan2.1视频扩散模型中，ERTACache实现2倍加速的同时，VBench降解 minimal，有效保持了基线保真度，显著提高了效率。代码已开源。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.16936", "html_url": "https://arxiv.org/abs/2508.16936", "title": "THEME: 使用语义股票表示和时间动态增强主题投资", "title_en": "THEME: Enhancing Thematic Investing with Semantic Stock Representations and Temporal Dynamics", "authors": "Hoyoung Lee,Wonbin Ahn,Suhwan Park,Jaehoon Lee,Minjae Kim,Sungdong Yoo,Taeyoon Lim,Woohyung Lim,Yongjae Lee", "background": "主题投资的目标是构建与结构性趋势一致的投资组合，但由于行业边界重叠和市场动态不断变化，这一目标仍具有挑战性。尽管存在潜力，但通用的LLM嵌入模型并不适合捕捉金融资产的细微特征，因为投资资产的语义表示可能与一般的金融文本有根本的不同。因此，需要一种新的方法来有效识别与投资主题相匹配的优质资产。", "innovation": "文章介绍了一个名为THEME的框架，该框架通过层次对比学习对嵌入进行微调。THEME利用投资主题及其组成部分股票之间的层次关系对主题进行对齐，并进一步通过股市回报对这些嵌入进行细化。这种过程产生了针对广泛的投资应用场景有效的主题相关资产表示法。实验结果显示THEME在主题资产检索和构建的资产组合方面均表现出色。通过同时建模文本中的主题关系和市场动态中的回报，THEME生成了专门针对广泛的实际投资应用场景的股票嵌入。", "conclusion": "THEME框架显著提高了主题投资的效率，特别是在主题资产检索和构建具有吸引力的投资组合方面表现出色。通过结合文本中的主题关系和市场动态中的回报，THEME生成了特别适合跨行业广泛投资应用场景的股票嵌入。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21080", "html_url": "https://arxiv.org/abs/2508.21080", "title": "2COOOL: 2nd Workshop on the Challenge Of Out-Of-Label Hazards in Autonomous Driving", "title_en": "2COOOL: 2nd Workshop on the Challenge Of Out-Of-Label Hazards in Autonomous Driving", "authors": "Ali K. AlShami,Ryan Rabinowitz,Maged Shoman,Jianwu Fang,Lukas Picek,Shao-Yuan Lo,Steve Cruz,Khang Nhut Lam,Nachiket Kamod,Lei-Lei Li,Jugal Kalita,Terrance E. Boult", "background": "尽管计算机视觉社区在推进自动驾驶算法方面取得了进展，将基于视觉的洞见与传感器数据相结合仍然是提高感知、决策、规划、预测、模拟和控制的关键。然而，我们仍为何未拥有完全安全的自动驾驶汽车？新型场景处理是实现现实世界部署的主要障碍之一。因此，需要专门的工作坊来应对这一挑战。", "innovation": "2COOOL工作坊提供了研究人员和行业专家共同推动前沿技术的讨论，包括离分布危害检测、视觉语言模型、新基准和方法论以及安全自动驾驶实践。工作坊将重点关注异常检测、开放式识别、开放式语义模型、领域适应等相关领域的思想，以开发新的算法和系统，用于避免危害。", "conclusion": "2COOOL工作坊将于2025年10月19日在夏威夷奥诺拉诺举行的国际计算机视觉大会（ICCV）上举办。其目标是通过多样化的学术与行业参与方式，激发新的算法和系统开发，以应对离分布危害挑战，推动自动驾驶技术的发展。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21102", "html_url": "https://arxiv.org/abs/2508.21102", "title": "GENNAV: 通用可导航区域的多边形掩模生成", "title_en": "GENNAV: Polygon Mask Generation for Generalized Referring Navigable Regions", "authors": "Kei Katsumata,Yui Iioka,Naoki Hosomi,Teruhisa Misu,Kentaro Yamada,Komei Sugiura", "background": "该研究关注从自然语言指令和由移动设备捕捉的前摄像头图像中识别目标区域的位置任务。这一任务具有挑战性，因为它既需要存在预测，又需要分割，尤其是对于边界模糊的目标区域。现有的方法在处理此类目标区域时经常表现不佳，尤其是当目标缺失或者存在多个目标时。", "innovation": "本文提出了GENNAV，它可以预测目标的存在并生成多个混合型目标区域的分割掩码。为了评估GENNAV，作者构建了一个名为GRiN-Drive的新基准，该基准包含了无目标、单目标和多目标三种不同类型的样本。实验结果表明，GENNAV在标准评估指标上优于基线方法。此外，还在四个汽车上在五个地理上不同的城市地区进行了实际的实车实验，以验证其零样本转性能。该实验结果证明了GENNAV在多种现实环境中的鲁棒性。", "conclusion": "GENNAV 在标准评估指标上实现了优异的性能，并且在真实的环境中表现出色，展示了其在多种现实环境中的鲁棒性。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject: 对网页代理的提示注入攻击", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "论文背景是介绍一种基于多模态大语言模型的网页代理（交互代理），这些代理通过生成基于网页屏幕截图的动作与网页环境进行交互。研究者提出了一种对网页代理的新型攻击方式——WebInject，该攻击通过在渲染网页的原始像素值中添加一种扰动，使得网页代理执行攻击者指定的动作。", "innovation": "创新点在于，研究团队将找到扰动的原始任务转化为一个优化问题，并通过训练神经网络来近似原始像素值到屏幕截图之间的非可微映射。然后使用投影梯度下降法来解决重新定义的优化问题，从而使WebInject攻击更为有效并且显著优于基线方法。", "conclusion": "研究使用多个数据集进行了广泛的评估，结果证明WebInject攻击效果显著，并远超现有基准方法。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21135", "html_url": "https://arxiv.org/abs/2508.21135", "title": "HiddenObject: 忽视模态融合方法用于多模态隐蔽物体检测", "title_en": "HiddenObject: Modality-Agnostic Fusion for Multimodal Hidden Object Detection", "authors": "Harris Song,Tuan-Anh Vu,Sanjith Menon,Sriram Narasimhan,M. Khalid Jawed", "background": "在多模态环境中检测隐蔽或部分遮挡的物体是一项基本挑战。因素如遮挡、伪装和光照变化严重影响了性能。传统的基于RGB的方法在这些不利条件下常常失败，需要更加 robust、模态无关的方法。", "innovation": "本文提出了一种融合框架HiddenObject，该框架利用Mamba机制融合RGB、热成像和深度数据。方法捕捉了跨模态的互补信号，以增强隐蔽或伪装目标的检测能力。该方法识别模态特定的特征，并在统一表示中进行融合，适用于具有挑战性的场景。", "conclusion": "本文在多个基准数据集上验证了HiddenObject，其性能相比现有方法达到了最先进的或可竞争的水平。这些结果表明，我们的融合设计具有高效性，并揭示了当前单一模态和简单融合策略的关键局限。更广泛地说，我们的发现表明，基于Mamba的融合架构可以显著推动多模态物体检测领域的发展，尤其是在视觉退化或复杂条件下。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21099", "html_url": "https://arxiv.org/abs/2508.21099", "title": "Safe-Control：一种用于减轻文本到图像生成模型中不安全内容的安全补丁", "title_en": "Safe-Control: A Safety Patch for Mitigating Unsafe Content in Text-to-Image Generation Models", "authors": "Xiangtao Meng,Yingkai Dong,Ning Yu,Li Wang,Zheng Li,Shanqing Guo", "background": "尽管在文本到图像（T2I）生成模型方面取得了进步，但这些模型的潜在滥用风险引起了严重的安全担忧。模型开发者已尝试引入安全机制来应对这些担忧，但现有的安全机制容易在分布变化下被绕过，或者需要大量的模型特定调整。这些限制促使研究者开发了Safe-Control，一种插件式安全补丁，旨在减轻T2I模型中的不安全内容生成。Safe-Control通过数据驱动策略和安全感知条件，将安全控制信号注入锁定的T2I模型，这种方式类似于作为一种补丁进行更新。", "innovation": "Safe-Control作为一种插件式安全补丁，以其数据驱动策略和安全感知条件，有效减轻了多样且公共T2I模型中的不安全内容生成，而不会降低良性图像的质量和文本对齐度。与7种先进的安全机制相比，包括外部和内部防御，Safe-Control显著降低了不安全内容生成的概率，在不安全提示和最新的对抗攻击下将不安全内容生成的概率降至约7%。", "conclusion": "Safe-Control能灵活地满足不断变化的安全需求，并与具有相似去噪架构的其他T2I模型兼容。研究表明，Safe-Control在六种不同类型的T2I模型中表现出色，有效减少了不安全内容的生成几率，同时保持了图像质量和文本对齐度。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21094", "html_url": "https://arxiv.org/abs/2508.21094", "title": "具有时间视觉筛选技术的Video-LLMs", "title_en": "Video-LLMs with Temporal Visual Screening", "authors": "Zheyu Fan,Jiateng Liu,Yuji Zhang,Zihan Wang,Yi R.(May)Fung,Manling Li,Heng Ji", "background": "人类在观看视频时，会根据兴趣快速滚动进度条并专注于关键的时间段，而现有的视频大型语言模型（Video-LLMs）在训练过程中由于稀疏取帧和不足的帧间推理监督，难以捕捉到细粒度的时间域语义。已有研究发现，视频问答和指令调优的数据预处理可以通过筛选关键的时间段、使得问题回复一致以及保持任何可能答案的一致性和不变性来改善。", "innovation": "本研究借鉴认知科学原理，提出了时间视觉筛选（TVS）任务。TVS作为模块化的前端适配器任务，可以无缝集成到视频指令调优（训练）和视频问答（推理）的工作流程中，优化了推理负担和认知负载，训练时对齐问题与关键的视觉信息，在推理时实现了问题清楚段落聚焦和简化的问题表示。在这一基础上，首次构建了TVS基准，并提出了ReSimplifyIt基线方法，该方法在视频剪辑任务上比以往方法的F-1分数高0.47，并且在问题重写性能上表现较好。实验表明，引入TVS在训练中的相对增益为7.33%，在推理中的相对增益为34.6%，证明了时间信息筛选对提高视频语言理解的有效性。", "conclusion": "通过引入时间视觉筛选任务，Video-LLMs的能力得到了显著提升，在训练和推理阶段，时间信息的处理对于提高视频语言理解具有重要意义。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21096", "html_url": "https://arxiv.org/abs/2508.21096", "title": "ROBUST-MIPS: 胸腔镜手术器械的联合骨骼姿态和实例分割数据集", "title_en": "ROBUST-MIPS: A Combined Skeletal Pose and Instance Segmentation Dataset for Laparoscopic Surgical Instruments", "authors": "Zhe Han,Charlie Budd,Gongyu Zhang,Huanyu Tian,Christos Bergeles,Tom Vercauteren", "background": "手术工具的定位是计算机辅助介入技术的基础构建模块。现有工作通常专注于训练深度学习模型执行分割任务。基于学习的方法受到可用多样化注释数据的限制。本文认为，骨骼姿态注释是手术工具更高效的注释方法，能够在语义信息的丰富性和注释的便利性之间取得平衡，从而加速可用注释数据的增长。", "innovation": "本文提出了一种名为ROBUST-MIPS的新的联合工具姿态和工具实例分割数据集，该数据集是从现有的ROBUST-MIS数据集中衍生出来的。该数据集促进了这两类注释风格的研究联合，使得在各种下游任务上进行头对头比较成为可能。通过使用流行的姿态估计方法建立简单的基准，证明姿态注释对于手术工具定位的充分性。同时，还提供了解决方案的模型和定制工具姿态注释软件以便促进采用。", "conclusion": "研究展示了视频上骨骼姿态注释在改善定位质量方面的有效性。所提出的数据集允许研究人员探索姿态注释与实例分割注释之间的关系，并推动跨领域的研究进展。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21113", "html_url": "https://arxiv.org/abs/2508.21113", "title": "R-4B：通过二模式退火和强化学习激励通用自动思考能力的多模态大型语言模型", "title_en": "R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning", "authors": "Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng", "background": "具有逐步思考能力的多模态大型语言模型（MLLMs）在解决复杂推理问题时表现突出，但在解决简单且不需要复杂推理的问题时则显得冗余。这种效率低下激发了对一种可以适应性决定何时需要思考的模型的需求，特别是基于问题复杂度的决策。", "innovation": "提出的R-4B是一种自动思考的MLLM，它可以基于问题的复杂度自动决定是否进行思考。R-4B的核心思想是通过二模式退火赋予模型思考和不思考的双重能力，并且使用Bi-mode Policy Optimization (BPO) 来提高模型决定是否激活思考过程的准确性。模型首先在包含思考和不思考模式样本的数据集上进行训练，然后再通过改进的GRPO框架进行训练，以确保每个输入的查询都从两种模式生成响应。", "conclusion": "实验结果显示，R-4B在25个挑战性基准测试中达到了最先进的性能。与Qwen2.5-VL-7B相比，它在大多数任务中表现出更出色的结果，而在推理密集型基准测试中，其性能与Kimi-VL-A3B-Thinking-2506 (16B)相当，但计算成本较低。"}
{"llm_update_time": "20250901", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2406.06464", "html_url": "https://arxiv.org/abs/2406.06464", "title": "使用大型语言模型代理将可穿戴设备数据转化为个人健康洞察", "title_en": "Transforming Wearable Data into Personal Health Insights using Large Language Model Agents", "authors": "Mike A. Merrill,Akshay Paruchuri,Naghmeh Rezaei,Geza Kovacs,Javier Perez,Yun Liu,Erik Schenck,Nova Hammerquist,Jake Sunshine,Shyam Tailor,Kumar Ayush,Hao-Wei Su,Qian He,Cory Y. McLean,Mark Malhotra,Shwetak Patel,Jiening Zhan,Tim Althoff,Daniel McDuff,Xin Liu", "background": "从流行的可穿戴设备追踪器中提取个性化见解需要复杂的数值推理，这对标准的大语言模型（LLMs）构成挑战，因此需要工具基的方法，如代码生成。大语言模型代理在微观分析方面展示了巨大的潜力，但目前尚未被广泛应用。", "innovation": "作者引入了个人健康洞察代理（PHIA），该系统结合了多步骤推理、代码生成和信息检索，旨在系统分析和解读行为健康数据。作者还创建并共享了两个基准数据集，包含超过4000个健康见解问题，通过650小时的人类专家评估，PHIA在客观数值问题上取得了84%的准确率，并且在开放性问题上获得了83%的良好评价，特别容易达到最高质量等级。", "conclusion": "这项工作可以推动行为健康的发展，帮助个人更好地理解他们的数据，从而为更广泛的公众带来新的时代——可访问的、个性化的、以数据为导向的健康与福祉。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21154", "html_url": "https://arxiv.org/abs/2508.21154", "title": "RadGS-Reg: 通过联合3D辐射高斯重建和3D/3D配准将脊椎CT与双平面X射线对齐", "title_en": "RadGS-Reg: Registering Spine CT with Biplanar X-rays via Joint 3D Radiative Gaussians Reconstruction and 3D/3D Registration", "authors": "Ao Shen,Xueming Fu,Junfeng Jiang,Qiang Zeng,Ye Tang,Zhengming Chen,Luming Nong,Feng Wang,S. Kevin Zhou", "background": "在图像引导的神经导航中，CT/X射线配准因严格的高精度和实时性要求而具有挑战性。传统的“渲染和比较”方法依赖于迭代投影和比较，会丢失空间信息并存在领域差异。尽管从双平面X射线重建3D结构可以补充空间和形状信息，但现有方法受限于密集视角的要求和对噪声X射线的处理困难。因此，该研究旨在提出一种新的RadGS-Reg框架，利用联合3D Radiative Gaussians (RadGS)重建和3D/3D配准来解决脊椎级别的CT/X射线配准问题", "innovation": "提出了RadGS-Reg，一种结合了基于学习的3D Radiative Gaussians (RadGS)重建和3D/3D配准的新框架。具体而言，该框架中的双平面X射线脊椎RadGS重建模块利用Counterfactual Attention Learning (CAL)机制，专注于噪声X射线中的脊椎区域重建。同时，引入了患者特定的预训练策略，逐步使RadGS-Reg从模拟数据适应到真实数据，同时学习脊椎形状先验知识", "conclusion": "实验结果表明，该方法在两项任务上达到了最先进的性能，超越了现有方法。已在内部数据集上进行了实验验证，结果表明RadGS-Reg在脊椎CT与双平面X射线配准方面表现优异，是目前最好的方案之一。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21088", "html_url": "https://arxiv.org/abs/2508.21088", "title": "利用全景X光片对牙齿状况进行高级深度学习分类的技术", "title_en": "Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images", "authors": "Alireza Golkarieh,Kiana Kiashemshaki,Sajjad Rezvani Boroujeni", "background": "本文探讨了使用深度学习方法对全景X射线图像中的牙齿状况进行自动分类的研究。研究采用了一个包含1,512张牙科X光片的数据集，该数据集有11,137个专家验证的注释，涵盖了四个条件：填充物、龋齿、种植体和阻生牙。研究在预处理和类别平衡后，评估了三种方法：自定义卷积神经网络（CNN）、结合CNN特征提取的传统分类器的混合模型，以及预训练架构的微调。", "innovation": "研究中评估了三种方法：自定义CNN、结合CNN特征提取的传统分类器的混合模型以及预训练架构的微调。实验采用5折交叉验证，使用准确率、精确率、召回率和F1分数作为评估指标。研究发现，混合CNN随机森林模型性能最佳，准确率为85.4%，超过自定义CNN基础模型的74.3%。在预训练模型中，VGG16表现最佳，准确率82.3%，其次是Xception和ResNet50。研究结果表明，混合模型在识别形态相似的条件方面表现出色，同时提供了高效可靠的性能。这项研究为自动化牙科诊断支持提供了一种切实可行的办法，并强调了需求更大的数据集和进一步的临床验证。", "conclusion": "结合基于CNN的特征提取与集成分类器的方法为自动化牙科诊断支持提供了一条实际路径。然而，研究还指出，需要更大的数据集和进一步的临床验证。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21169", "html_url": "https://arxiv.org/abs/2508.21169", "title": "SYNBUILD-3D: 一个具有层次细节4级别的大型多模态语义丰富的合成三维建筑模型数据集", "title_en": "SYNBUILD-3D: A large, multi-modal, and semantically rich synthetic dataset of 3D building models at Level of Detail 4", "authors": "Kevin Mayer,Alex Vesel,Xinyi Zhao,Martin Fischer", "background": "三维建筑模型在建筑学、能源模拟和导航等方面的应用至关重要，但基于现有公共领域中的标注数据较少，自动准确生成具有语义丰富性的三维建筑模型仍然是一个重大挑战。研究领域受到计算机视觉中合成数据成功的启发，致力于探索和创建合成数据集。", "innovation": "SYNBUILD-3D是一个包含超过620万有层次细节4级别（LoD 4）的合成三维住宅建筑模型的大型、多样化和多模态数据集。每个建筑模型通过三种不同的模态表示：层次细节4级别的语义丰富三维线框图（Modality I）、对应楼层平面图图像（Modality II）和类似LiDAR的屋顶点云（Modality III）。语义注释通过楼层平面图信息自动提取，涵盖房间、门窗等信息。未来的工作可以利用其三模态特性，研发基于预定义楼层平面布局和屋顶几何形状自动构建三维建筑模型的新型生成式AI算法，并保证语义-几何一致性。", "conclusion": "通过对SYNBUILD-3D数据集的未来研究，可以开发出生成性AI算法自动创建具有语义一致性的三维建筑模型，同时可实现指定的楼层平面布局和屋顶几何形状。数据集和代码样本将在以下网址公开获取：附有链接。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21197", "html_url": "https://arxiv.org/abs/2508.21197", "title": "GCAV: 一种跨层一致性概念激活向量框架", "title_en": "GCAV: A Global Concept Activation Vector Framework for Cross-Layer Consistency in Interpretability", "authors": "Zhenghao He,Sanchit Sinha,Guangzhi Xiong,Aidong Zhang", "background": "概念激活向量（CAVs）提供了一种强大的方法来解释深度神经网络，通过量化其对人类定义概念的敏感性。然而，当在不同的层独立计算时，CAVs往往会表现出不一致性，这使得层间的比较不可靠。", "innovation": "本文提出了全局概念激活向量（GCAV），这是一种全新的框架，用于将CAVs统一成一个单层、语义一致的表示。该方法利用对比学习在层间对齐概念表示，并采用注意力融合机制构建一个全局整合的CAV。通过这种方式，该方法显著减少了TCAV分数的方差，同时保持概念的相关性，确保了更稳定和可靠的特征归因。为了评估GCAV的有效性，引入了基于GCAV表示的测试方法TGCAV，用于应用TCAV。研究结果表明，该方法有效缓解了层间概念不一致性，增强了概念定位，并提高了对对抗性扰动的鲁棒性。", "conclusion": "通过将跨层信息整合到一个连贯框架中，本文的方法提供了对深度学习模型如何编码人类定义的概念的更全面和可解释的理解。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21254", "html_url": "https://arxiv.org/abs/2508.21254", "title": "Reverse Imaging for Wide-spectrum Generalization of Cardiac MRI Segmentation", "title_en": "Reverse Imaging for Wide-spectrum Generalization of Cardiac MRI Segmentation", "authors": "Yidong Zhao,Peter Kellman,Hui Xue,Tongyun Yang,Yi Zhang,Yuchi Han,Orlando Simonetti,Qian Tao", "background": "预训练的分割模型在心脏磁共振成像（MRI）中由于不同成像序列之间的显著图像对比度差异而难以泛化。这些差异源自成像协议的变化，尽管如此，所有的成像数据都是由相同的自旋性质（包括质子密度、T1和T2值）控制的。本文基于这一核心原理，提出了一种新型的物理学驱动方法，称为 Reverse Imaging，用于心脏MRI数据增强和域适应，以从根本上解决泛化问题。", "innovation": "Reverse Imaging 方法通过解决由自旋性质先验分布正则化的不适定非线性逆问题，从观察到的心脏MRI图像中逆向推断底层的自旋属性。通过从多参数饱和恢复单次采集序列（mSASHA）数据集中学习生成扩散模型，获得了自旋属性的“先验分布”。Reverse Imaging方法能够从MRI图像中获得近似但有意义的自旋属性估计值，提供了一个可解释的“潜在变量”，从而实现了任意新序列的图像合成的高灵活性。研究表明，该方法能够在广泛不同的图像对比度和成像协议下实现高度准确的心脏MRI分割，实现了心脏MRI分割的广泛光谱泛化。", "conclusion": "Reverse Imaging 方法通过逆向推断底层自旋属性，实现了心脏MRI成像在不同序列之间广谱泛化的高度准确分割，为心脏MRI成像的跨序列应用提供了有前景的新方法。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21227", "html_url": "https://arxiv.org/abs/2508.21227", "title": "基于Auto3DSeg的轻量级MRI胰腺癌自动分割", "title_en": "Lightweight MRI-Based Automated Segmentation of Pancreatic Cancer with Auto3DSeg", "authors": "Keshav Jha,William Sharp,Dominic LaBella", "background": "胰腺肿瘤的准确勾画对于诊断、治疗计划和结果评估至关重要，但由于解剖变异性和可用数据集有限，自动化分割仍具有挑战性。本研究在2025年的PANTHER挑战中，使用SegResNet模型在两个基于MRI的胰腺肿瘤分割任务上进行了训练和评估，强调了针对解剖相关区域的兴趣区域，并采用5折交叉验证和STAPLE荟萃分析的方法进行处理。MRI序列的不同引入了更多的变异性。研究通过多种指标（Dice相似系数DSC、5毫米DSC、95百分位海德堡距离HD95、平均表面距离MASD和均方根误差RMSE）评估了算法自动分割胰腺肿瘤的表现，尤其是在两个不同的任务中表现出不同的性能特点，这显示出小数据集下基于MRI的胰腺肿瘤分割的挑战。", "innovation": "本研究中引入了Auto3DSeg架构下的轻量级SegResNet模型，并在PANTHER挑战的两个任务中进行了训练和评估。模型通过5折交叉验证和STAPLE方法提升了算法表现，同时采用多个评价指标对比性能，这为未来的大规模临床应用提供了可能的研究方向。", "conclusion": "尽管算法的性能较为有限，但仍展示了自动勾画的潜力，强调了需要更大的标准化MRI数据集来提高模型的稳健性和临床实用性。研究结果揭示了基于MRI的胰腺肿瘤分割的挑战，突显了不同MRI序列带来的变异性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21222", "html_url": "https://arxiv.org/abs/2508.21222", "title": "通过视觉上下文提示实现可泛化的物体重识别", "title_en": "Generalizable Object Re-Identification via Visual In-Context Prompting", "authors": "Zhizhong Huang,Xiaoming Liu", "background": "当前的物体重识别方法训练特定领域的模型（例如用于人物或车辆），这些模型缺乏泛化能力，并且对于新类别需要大量的标记数据。自我监督学习能够减少标注需求，通过学习实例级别的不变性，但它难以捕捉对重识别至关重要的身份敏感特征。现有方法依赖于类别特定的模型训练，这限制了模型在未见类别的泛化能力。本研究通过引入一种新的框架——视觉上下文提示（VICP），解决这一问题，该框架使得模型能够仅通过使用示例作为提示，直接泛化到未见的新类别，而不需参数调整。", "innovation": "本研究提出了一种新颖的框架——视觉上下文提示（VICP），该框架能够使得训练于已见类别的模型在无需参数调整的情况下泛化到未见的新类别，仅使用已见类别的实例作为提示。该方法结合了大规模语言模型（LLMs）和视觉基础模型（VFM），通过任务特定的提示使LLM推测出语义上的身份规则，然后指导VFM通过动态视觉提示提取身份区分特征。这种结合使得模型能够泛化到新类别，无需针对特定数据集进行重新训练。此外，为了支持评估，该研究还推出了一个名为ShopID10K的新数据集，该数据集包含来自电商平台的10,000个物体实例，包括多视角图像和跨域测试。", "conclusion": "实验结果表明，通过引入Visual In-Context Prompting (VICP)方法，在未见类别的重识别基准测试中，该方法能够明显优于现有基线方法。此研究成果为物体重识别领域提供了可泛化的解决方案，具有重要的研究价值和实际应用意义。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21190", "html_url": "https://arxiv.org/abs/2508.21190", "title": "重访径向失真的单应性", "title_en": "Radially Distorted Homographies, Revisited", "authors": "Mårten Wadenbäck,Marcus Valtonen Örnhag,Johan Edstedt", "background": "单应性变换在几何计算机视觉和投影几何中极为常见，因此在各种计算机视觉任务中，单应性估计是至关重要的一步。然而，在处理实际图像时，由于镜头引起的几何畸变，有时需要同时确定单应性和平面内径向畸变（特别是所谓的径向畸变）来获得有用的结果。在考虑具有径向畸变的两张图像之间的单应性时，存在三种概念上不同的径向畸变情况：仅一张图片有畸变、两张图片有相同的畸变以及两张图片有独立的畸变。这些情况在过去分别进行过单独处理，但本文提供了针对所有三种情况的新型一体化解决方案。并通过新方法构建了快速、稳定且准确的最小求解器来处理径向失真的单应性问题，在三种情况下，本文提出的求解器比现有的最先进的求解器速度快，同时保持相似的准确度。本文中的求解器在鱼眼摄像头拍摄的成像基准上进行了测试。如果我们论文被接受发表，源代码将公开提供。", "innovation": "论文提供了一种针对具有径向畸变的单应性的新型统一解决方案，能处理三种不同类型的径向畸变情况，即仅一张图片有畸变、两张图片有相同的畸变和两张图片有独立的畸变。通过这种方法构建了新的快速、稳定且准确的最小求解器，性能上优于现有的最先进的求解器，同时保持相似的准确度。该方法已通过鱼眼摄像头拍摄的图像基准测试验证了其有效性，并且代码将被公开提供。", "conclusion": "本文提出的方法为处理具有径向畸变的单应性提供了一种快速、准确和稳定的解决方案，对现有的求解器在准确性和速度方面均体现了改进。其在鱼眼摄像头拍摄的图像上测试通过，展示了其实际应用价值。如果论文被接受发表，相关代码也将公开提供。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21398", "html_url": "https://arxiv.org/abs/2508.21398", "title": "GLENDA: Gynecologic Laparoscopy Endometriosis Dataset", "title_en": "GLENDA: Gynecologic Laparoscopy Endometriosis Dataset", "authors": "Andreas Leibetseder,Sabrina Kletz,Klaus Schoeffmann,Simon Keckstein,Jörg Keckstein", "background": "腹腔镜妇科手术是一种微创手术（MIS），通过患者腹部的实地拍摄来进行，用于观察插入和操作各种手术器械以进行治疗。这种手术方式不仅能够实现多种治疗手段，录音和记录手术视频也很重要，便于术后治疗规划、病例文档和教育。然而，目前对手术录像的手动分析通常耗时且费力。", "innovation": "为改善这一现状，正在积极开发更先进的计算机视觉和机器学习方法。鉴于这些方法大多依赖于样本数据，而医疗领域数据尤其稀缺，该研究发布了一个新的图像数据集GYN Endometriosis Laparoscopy Dataset (GLENDA)，包含端ometriosis（子宫内膜异位症）的区域标注。这是一个前所未有的数据集，并与该领域的领先医学专家合作创建。", "conclusion": "GLENDA 数据集的发布为医疗领域提供了宝贵的、标注良好的数据资源，有助于促进计算机视觉和机器学习在妇科腹腔镜手术中的应用，并推动相关研究和实践的进步。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21363", "html_url": "https://arxiv.org/abs/2508.21363", "title": "基于分层时间剪枝的高效基于扩散的人体3D姿态估计", "title_en": "Efficient Diffusion-Based 3D Human Pose Estimation with Hierarchical Temporal Pruning", "authors": "Yuquan Bi,Hongsong Wang,Xinli Shi,Zhipeng Gui,Jie Gui,Yuan Yan Tang", "background": "扩散模型在生成高保真3D人体姿态方面表现出强大的能力，但它们的迭代性质和多假设需求带来了巨大的计算成本。", "innovation": "提出了一种基于分层时间剪枝（HTP）策略的有效基于扩散的人体3D姿态估计框架，该框架动态地在帧和语义层面上剪枝冗余的姿态标记，同时保持关键的运动动态。", "conclusion": "HTP减少了训练MACs 38.5%，推断MACs 56.8%，并提高了81.1%的推理速度，与以前的基于扩散的方法相比，仍然实现了最先进的性能。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21371", "html_url": "https://arxiv.org/abs/2508.21371", "title": "Print2Volume: 由2D指纹图像生成基于OCT的3D指纹体积", "title_en": "Print2Volume: Generating Synthetic OCT-based 3D Fingerprint Volume from 2D Fingerprint Image", "authors": "Qingran Miao,Haixia Wang,Haohao Sun,Yilong Zhang", "background": "光学相干断层扫描(OCT)能够获取高分辨率、三维指纹数据，但其成本高昂且耗时较长的数据采集过程限制了大规模公共数据集的获取，阻碍了先进算法的发展，尤其是需要大量数据的深度学习模型。", "innovation": "提出了Print2Volume，这是一种创新的框架，能够从2D指纹图像生成逼真的、基于OCT的3D指纹体积。该框架分为三个阶段：首先将二值指纹转换为灰度图像，模拟Z方向的OCT扫描样式；然后通过3D结构扩展网络将2D图像扩展为合理的3D解剖体积；最后使用基于3D GAN的OCT现实性细化模块，赋予结构体真实纹理、斑点噪声和其他成像特征。该框架能够生成包含42万个样本的大规模合成数据集，并且证明了其合成数据的质量及其对识别性能的显著影响，通过在合成数据上预训练识别模型并在小规模真实数据集上优化，达到了从15.62%到2.50%的等错误率(EER)显著降低效果，证明了其在克服数据稀缺方面的有效性。", "conclusion": "通过使用Print2Volume生成的大规模合成数据集，研究小组成功地证明了其在识别性能上的显著提升，并显示了该方法在解决数据稀缺问题方面的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21437", "html_url": "https://arxiv.org/abs/2508.21437", "title": "树木作为高斯分布：大规模单株树木制图", "title_en": "Trees as Gaussians: Large-Scale Individual Tree Mapping", "authors": "Dimitri Gominski,Martin Brandt,Xiaoye Tong,Siyu Liu,Maurice Mugabowindekwe,Sizhuo Li,Florian Reiner,Andrew Davies,Rasmus Fensholt", "background": "树木是陆地生物圈的关键组成部分，对生态系统功能、气候调节和生物经济发挥着重要作用。然而，由于模型不足，大规模监测单个树木仍然受到限制。现有的全球产品主要关注二元树冠覆盖或冠层高度，但未能明确标识个体树木。本文提出了一种深度学习方法，用于在3 m分辨率的PlanetScope影像上处理全球范围内大规模单株树木检测问题。该方法通过使用可调节大小的高斯核模拟树冠，提取树冠中心并生成二元树冠覆盖图。", "innovation": "该研究创新地提出了一种基于深度学习的全球大规模单株树木检测方法，能够在3米分辨率的PlanetScope影像上模拟树冠并提取树冠中心，从而生成二元树冠覆盖图。其主要创新点在于采用了可调节大小的高斯核来模拟树冠并提取树冠中心，使模型能够成功识别森林内外的树木。此外，该方法还通过自动从机载激光雷达数据中提取数十亿个点来进行训练，展示了其在不同生态系统的检测均衡性，并通过手动标签进一步提高了检测性能。", "conclusion": "本研究提供了一种可扩展的框架，用于全球高分辨率树木监测，并且该方法能够适应未来提供改进影像的卫星任务。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21444", "html_url": "https://arxiv.org/abs/2508.21444", "title": "Scale-GS: 通过流式内容冗余过滤训练实现高效的可扩展高斯斑点图", "title_en": "Scale-GS: Efficient Scalable Gaussian Splatting via Redundancy-filtering Training on Streaming Content", "authors": "Jiayu Yang,Weijian Su,Songqian Zhang,Yuqi Han,Jinli Suo,Qiang Zhang", "background": "3D高斯斑点图（3DGS）能够实现沉浸式应用所需的高保真实时渲染。然而，将其扩展到动态场景仍存在挑战，主要在于大量密集高斯数据和每一帧长时间的训练需求。", "innovation": "提出了一个基于锚点的可扩展高斯斑点图框架Scale-GS，该框架通过层级划分高斯球体且按比例组织。较低层级的高斯球代表低分辨率结构，较高层级的高斯球则负责高细节的渲染。还引入了混合变形和生成策略，同时增加双向自适应遮蔽机制以提高训练效率。", "conclusion": "实验结果表明，Scale-GS在保持卓越视觉质量的同时，显著减少了训练时间，优于最先进的方法。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21424", "html_url": "https://arxiv.org/abs/2508.21424", "title": "使用置信度伪标签的无监督增量学习", "title_en": "Unsupervised Incremental Learning Using Confidence-Based Pseudo-Labels", "authors": "Lucas Rakotoarivony", "background": "深度学习模型在许多计算机视觉任务中取得了最先进的性能。然而，在实际场景中，训练时未见过的新类别常会出现，要求模型能够增量地习得新知识同时保留之前类别的知识。增量学习（CIL）方法允许模型学习新类目并保留先前类别的知识。然而，这些方法假设增量数据集完全标记，这在实践中是现实的。本文的研究背景是现有的CIL方法在标记数据的假设上过于理想化。", "innovation": "本文提出了一个名为ICPL的无监督增量学习方法，使用基于置信度的伪标签代替人工标注，使模型能够从未标记的数据集中进行增量学习。该方法通过置信度选择将这些伪标签整合到各种CIL方法中，并针对CIFAR100和ImageNet100的数据集评估了性能下降情况。此外，还将其应用于细粒度数据集，以证明其实用性，并对其计算复杂度进行了测量，验证其在资源受限环境中的适用性。", "conclusion": "ICPL取得与监督方法相当的结果，并显著优于最先进的类增量新型类别发现（class-iNCD）方法，准确率提升了超过5%。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21402", "html_url": "https://arxiv.org/abs/2508.21402", "title": "SatDINO: 远景自监督预训练的深度探究", "title_en": "SatDINO: A Deep Dive into Self-Supervised Pretraining for Remote Sensing", "authors": "Jakub Straka,Ivan Gruber", "background": "自监督学习已成为遥感领域的一种强大工具，因为遥感图像中存在大量未标记的数据。本文研究了使用DINO（一种对比性自监督方法）对遥感图像进行预训练的可能性，通过多个数据集和不同实验设置了广泛的实验，展示了SatDINO相比其他基于常见遮罩自动编码器（MAE）的方法表现出更优性能，并且在多个基准测试中取得了竞争力的结果。", "innovation": "1. 引入了SatDINO，一种专门为遥感卫星图像应用设计的模型。\n2. 提出了新的方式集成地面采样距离（GSD）编码和自适应视图采样等创新方法。\n3. 进行了严格的消融研究，评估SatDINO各个组件的有效性。", "conclusion": "SatDINO在遥感领域展现出优越的性能，在不同数据集和不同实验设置中取得了优于其他方法的结果。通过引入新的局部采样距编码和自适应视图采样等创新技术，SatDINO在遥感应用中表现出了竞争力，为未来研究提供了有价值的参考和改进方向。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21435", "html_url": "https://arxiv.org/abs/2508.21435", "title": "MedShift: 隐式条件传输在X射线领域适应中的应用", "title_en": "MedShift: Implicit Conditional Transport for X-Ray Domain Adaptation", "authors": "Francisco Caetano,Christiaan Viviers,Peter H.H. de With,Fons van der Sommen", "background": "合成医学数据为训练健壮模型提供了可扩展的解决方案，但显著的领域差异限制了其在实际临床环境中的通用性。本文探讨了合成与真实头颅X射线图像之间的跨领域转换挑战，集中在衰减行为、噪声特性和软组织表示的差异上。", "innovation": "本文提出了MedShift，一个基于流动匹配和薛定谔桥梁的统一条件生成模型，能够实现多个领域之间高保真的未配对图像转换。MedShift可以在没有领域特定训练或配对数据的情况下，学习一个共享的领域无关潜在空间，并支持在训练期间看到的任意一对领域的无缝转换。", "conclusion": "实验结果表明，尽管其模型尺寸较小，MedShift在性能上仍然较强且具有灵活性，可以在推理时调整以优先考虑感知保真度或结构一致性。因此，MedShift为医学成像中的领域适应提供了一个可扩展和通用的解决方案。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21399", "html_url": "https://arxiv.org/abs/2508.21399", "title": "使用深度学习实例分割识别腹腔镜手术仪器", "title_en": "Identifying Surgical Instruments in Laparoscopy Using Deep Learning Instance Segmentation", "authors": "Sabrina Kletz,Klaus Schoeffmann,Jenny Benois-Pineau,Heinrich Husslein", "background": "录制的手术视频已经成为医学内镜领域的重要信息来源，因为这些视频记录了手术的每一个细节。然而，尽管视频录制现在变得非常容易，对于医学视频档案进行基于内容的搜索的基础——自动内容索引——仍然面临着巨大挑战，尤其是由于手术视频内容的特殊性。我们研究了从录制的腹腔镜妇科手术视频中分割和识别手术器械的方法。更具体地说，我们评估了使用基于区域的全卷积网络进行实例意识的（1）器械分割以及（2）器械识别的可行性和性能。第一部分仅涉及实例二分类（即区分器械或背景），我们还研究了多类器械识别（即识别器械类型）。我们的评估结果显示，即使在训练样本数量较低的情况下，我们仍然能够以相当高的准确性定位和分割器械区域。然而，结果显示，识别特定器械仍然极具挑战性，因为手术器械本身具有非常高的相似性.", "innovation": "我们利用基于区域的全卷积网络对腹腔镜妇科手术视频中的器械进行了实例分割和识别。这项研究评估了这种深度学习方法在实例分割和多类器械识别方面的性能。结果表明，在训练样本相对较少的情况下，仍能以较高准确性定位和分割器械区域，但识别特定器械仍然是一个巨大的挑战，因为手术器械之间存在高度相似性。", "conclusion": "尽管仅使用中等数量的训练样本，我们仍然能够高精度地定位和分割器械区域，但识别具体的器械类型仍然极具挑战性，因为手术器械之间存在高度的相似性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21451", "html_url": "https://arxiv.org/abs/2508.21451", "title": "细目光多凝视：重新思考轻量级图描述作为一种实用的视觉专家", "title_en": "One More Glance with Sharp Eyes: Rethinking Lightweight Captioning as a Practical Visual Specialist", "authors": "Junha Song,Yongsik Jo,So Yeon Min,Quanting Xie,Taehwan Kim,Yonatan Bisk,Jaegul Choo", "background": "图像标注对于视频指令系统和探索机器人等应用至关重要，但在本地设备上部署这类模型面临挑战，因多模态大规模语言模型（MLLM）的高计算需求。论文探索了轻量级图标注的方法，在此基础上评估了一个基于125M参数语言模型的新模型，该模型的参数量比LLaMA-7B少56倍，实现对单句和详细图标注任务的支持，发现该模型虽规模较小，但表现接近大型多模态通用模型，显示出其对本地应用作为视觉专家的潜力。然而，该模型也存在视觉盲点问题，导致偶尔出现语义错误。", "innovation": "论文开发了一种新的图像标注框架——Sharp-Eyed Refinement，通过增强视觉基础，改善图标注的质量。DeepLens是该框架的核心，通过集中关注初始凝视期间识别的信息丰富的区域，提取详细视觉表示。实验确认了这种专家模型相对于先前的小型模型和大型通用模型的优势及框架的有效性，解决了注意力机制不有效和视觉表示能力有限的问题。", "conclusion": "通过引入Sharp-Eyed Refinement框架，轻量级图像标注模型在保持性能的同时，解决了原有模型的视觉盲点问题，提升了解决视觉理解任务的能力，为本地设备上的应用提供了新的可能性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21458", "html_url": "https://arxiv.org/abs/2508.21458", "title": "SAM-Med3D磁共振成像痴呆分类的联邦微调", "title_en": "Federated Fine-tuning of SAM-Med3D for MRI-based Dementia Classification", "authors": "Kaouther Mouheb,Marawan Elbatel,Janne Papma,Geert Jan Biessels,Jurgen Claassen,Huub Middelkoop,Barbara van Munster,Wiesje van der Flier,Inez Ramakers,Stefan Klein,Esther E. Bron", "background": "虽然基础模型（FMs）在AI辅助痴呆诊断方面具有巨大潜力，但它们在联邦学习（FL）系统中的集成仍处于起步阶段。本文通过使用大规模多队列数据集，系统评估了关键设计选择：分类头部架构、微调策略和聚合方法，对联邦FM微调性能和效率的影响，从而填补了这一研究空白。", "innovation": "研究发现，分类头部架构显著影响模型性能，固定FM编码器与完全微调效果相当，先进的聚合方法优于标准的联邦平均。这些发现为在分散式临床环境中部署FMs提供了实用见解，并指出了未来方法发展时需要权衡的贸易指标。", "conclusion": "本研究的结果表明，基础模型在联邦学习中的应用具有巨大潜力，但需要进一步优化和标准化聚合方法。未来的工作应着眼于进一步提高模型在多样化的临床环境中的鲁棒性和效率。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21418", "html_url": "https://arxiv.org/abs/2508.21418", "title": "标准化多层次组织图谱以增强大规模全切片图像档案中的人工智能集成和搜索", "title_en": "Standardized Multi-Layer Tissue Maps for Enhanced Artificial Intelligence Integration and Search in Large-Scale Whole Slide Image Archives", "authors": "Gernot Fiala,Markus Plass,Robert Harb,Peter Regitnig,Kristijan Skok,Wael Al Zoughbi,Carmen Zerner,Paul Torke,Michaela Kargl,Heimo Müller,Tomas Brazdil,Matej Gallo,Jaroslav Kubín,Roman Stoklasa,Rudolf Nenutil,Norman Zerbe,Andreas Holzinger,Petr Holub", "background": "全切片图像（WSI）是一种高分辨率的数字图像，通过扫描包含生物标本的整个玻片（如组织切片或细胞样本）而生成，并能在不同放大倍数下进行查看、分析和共享，如今被广泛应用于人工智能算法的发展。WSIs在病理学用于疾病诊断、肿瘤学用于癌症研究以及神经学、兽医学、血液学、微生物学、皮肤科、药理学、毒理学、免疫学和法医科学等多个领域得到应用。但在为AI算法的训练或验证阶段选择样本时，需要了解WSI上包含的内容，然而目前没有标准的元数据来指导这一过程，这通常需要通过人工检查进行筛选，不适用于包含数百万样本的大规模集合。因此，提出了一个通用框架来生成WSI的2D索引图，并提供特定应用领域的分析机制。本文展示了这个方法在临床病理学领域的应用，通过通用的语法和语义实现不同目录的互操作性。", "innovation": "提出了一个用于WSI的标准化多层次组织图谱框架，以增强人工智能的集成和搜索能力。该框架增加了每个WSI集合的详细组织图，提供了关于WSI内容的详细信息。组织图分为三个层次：来源、组织类型和病理改变，每个层次将WSI的不同部分分配给特定类。该方法通过具体示例展示了WSI目录、机器学习和基于图的WSI表示的应用优势。", "conclusion": "通过使用标准化多层次组织图谱，该研究展示了在大规模WSI数据库中实现更有效的AI算法集成和搜索的可能性。这种方法提供了详细的WSI内容信息，并且通过通用语法和语义实现了互操作性，适用于多种应用场景。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21463", "html_url": "https://arxiv.org/abs/2508.21463", "title": "Multi-Method Ensemble for Out-of-Distribution Detection", "title_en": "Multi-Method Ensemble for Out-of-Distribution Detection", "authors": "Lucas Rakotoarivony", "background": "在开放世界环境下，神经网络需要能够检测异常分布（OOD）样本，尤其是在安全关键应用中。现有方法通过两种主要技术——特征截断和评分函数，提高了OOD检测的性能。然而，大多数方法仅侧重于单一技术或特定类型的OOD数据集评估，忽视了多种现有方案组合的潜力。", "innovation": "本文通过理论和实验证明，最先进的特征截断方法和评分函数可以有效结合，且多个评分函数的聚合增强了鲁棒性。基于此，提出了多方法集合（MME）评分，将最先进的OOD检测方法统一为一个更强大的评分函数。实验结果显示，MME在各类基准测试中均显著优于最新方法，尤其在具有挑战性的ImageNet-1K基准测试中，平均FPR95为27.57%，提升了6%。", "conclusion": "综合多种现有的OOD检测方法，提出了MME评分方法，该方法在多个大规模和小规模基准测试中表现出色，特别是在处理OOD样本时增强了鲁棒性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21257", "html_url": "https://arxiv.org/abs/2508.21257", "title": "PHD: 使用点扩散进行个性化3D人体拟合", "title_en": "PHD: Personalized 3D Human Body Fitting with Point Diffusion", "authors": "Hsuan-I Ho,Chen Guo,Po-Chen Wu,Ivan Shugurov,Chengcheng Tang,Abhay Mittal,Sizhe An,Manuel Kaufmann,Linguang Zhang", "background": "传统的3D人体重建（HMR）方法旨在泛化，因此通常是用户无关的。这些方法通常通过从2D图像中提取的约束来优化姿态估计，以提高对齐精度，但由于无法同时考虑个人特定的身体形态和3D姿态的合理性，这导致了3D精度的损失。因此，本研究旨在开发一种新的方法，能够在个人特定的身体形态基础上，分解2D图像约束和3D姿态估计的过程，以提高姿态估计的准确性。", "innovation": "本研究提出了PHD，一种个性化3D人体网格恢复和拟合的新方法，它结合了用户特定的形状信息，通过点扩散变换器（Point Diffusion Transformer）迭代地指导姿态拟合，并通过点分散采样损失（Point Distillation Sampling loss）来实现定制的3D姿态先验。这种方法不仅提升了基于骨盆对齐的姿态准确性，还提高了绝对姿态准确性。此外，该方法的数据效率较高，仅需要合成数据进行训练，并且可以无缝集成到现有的3D姿态估计器中。", "conclusion": "研究展示的方法不仅显著提高了姿态估计的准确性，同时也展示了在姿态估计中集成用户特定的身体形态信息的强大潜力，使其成为一个更具数据效率和广泛适用性的模块，能够与现有的3D姿态估计器无缝集成，从而增强其表现。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21542", "html_url": "https://arxiv.org/abs/2508.21542", "title": "从单张图像中使用去噪扩散模型获得完整的高斯斑点", "title_en": "Complete Gaussian Splats from a Single Image with Denoising Diffusion Models", "authors": "Ziwei Liao,Mohamed Sayed,Steven L. Waslander,Sara Vicente,Daniyar Turmukhambetov,Michael Firman", "background": "高斯斑点常需密集的场景观测，难以重建被遮挡和未观测区域。传统的单张图像推理方法仅能完成可见表面的重建，对于被遮挡部分则可能产生模糊、不合理的重建结果，难以捕捉多种可能的解释。因此，这些方法往往只能部分解决问题，要么专注于与背景隔离的对象，要么只能重建可见表面，或者由于缺乏从输入视角远处的可靠的推断效果而失败。", "innovation": "文章提出了一种使用潜在扩散模型的生成方法，能够从单张图像在推理时重建完整的3D场景，包括被遮挡的部分。通过学习单张输入图像条件下的3D高斯斑点分布来克服难以观测表面的不确定性。为了解决缺乏地面真实数据训练的问题，文章提出了一种自监督的变分自重构机，能够从2D图像中学习潜在空间，并在该潜在空间上训练扩散模型。这种方法可生成高质量的完整360度渲染结果，并能多样地完成被遮挡表面的重建。", "conclusion": "该方法能够生成忠实且多样化的重建结果，具备在高质量全景渲染中完成被遮挡表面的能力。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21529", "html_url": "https://arxiv.org/abs/2508.21529", "title": "也许你不需要U-Net：用于材料显微图像分割的卷积特征上采样", "title_en": "Maybe you don't need a U-Net: convolutional feature upsampling for materials micrograph segmentation", "authors": "Ronan Docherty,Antonis Vamvakeros,Samuel J. Cooper", "background": "特征基础模型通常为视觉变换器，能够提供丰富的图像语义描述，适用于下游任务如交互式分割和目标检测。为了计算效率，这些描述往往是基于块的形式，但在材料和生物成像分析中，它们难以表示微图中的细微特征，也难以处理大的图像尺寸。因此，本文旨在通过训练一个卷积神经网络来上采样低分辨率（即大块大小）的基础模型特征，这些特征是相对于输入图像进行上采样的。这种方法应用于多种显微镜图像进行特征化和分割，结果表明，使用上采样后的深层特征进行交互式分割，不仅速度快，所需标签也更少，优于训练或微调传统的卷积网络。", "innovation": "本文提出了一种结合低分辨率特征基础模型和卷积神经网络的方法，以提高对微图的特征化和分割能力。通过上采样低分辨率的特征到高分辨率，这种方法有效解决了传统低分辨率特征难以表示细微特征的问题，并在多种显微图像上验证了其效果，特别是在分离难以分割的阶段，如细小裂缝方面表现出色。此外，这种方法还使得使用深层特征进行交互式分割，能够比训练或微调传统卷积网络更快地产生高质量的分割结果，且需要的标签更少。", "conclusion": "本文提出了一种基于卷积神经网络的特征上采样方法，可以有效地提高低分辨率特征模型在材料和生物学图像中的应用效果，特别是在复杂的显微图像分割任务中。这种方法不仅提高了分割的效率，还显著减少了所需的人工标注工作量。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21496", "html_url": "https://arxiv.org/abs/2508.21496", "title": "ELV-Halluc: 在长视频理解中基准测试语义聚合幻觉", "title_en": "ELV-Halluc: Benchmarking Semantic Aggregation Hallucinations in Long Video Understanding", "authors": "Hao Lu,Jiahao Wang,Yaolun Zhang,Ruohui Wang,Xuanyu Zheng,Yepeng Tang,Dahua Lin,Lewei Lu", "background": "视频多模态大语言模型（Video-MLLMs）在视频理解方面取得了显著进展，但依然易产生与视频输入内容不一致或无关的幻觉。以往针对幻觉的研究多关注于短视频，主要归因于强语言先验、缺帧或视觉编码器引入的语言-视觉偏见。尽管这些因素解释了短视频中多数幻觉的原因，但仍未能充分解释幻觉形成的全部原因。研究发现，模型有时会产生语义正确的输出，但内容不正确。我们将这种类型的幻觉称为语义聚合幻觉（SAH），产生于帧级语义聚合为事件级语义组的过程。SAH在长视频中尤为突出，因为其语义复杂度增加，导致幻觉成为关键问题。现有的研究方法亟需分离并深入探讨SAH的原因，以进行系统的调查研究。", "innovation": "该研究首次引入了ELV-Halluc基准，专注于长视频中的幻觉问题，特别是语义聚合幻觉（SAH）。通过ELV-Halluc基准，研究者能够系统地调查和分析SAH的原因，并发现模型在快速变化的语义中更容易产生这种幻觉。同时，研究者还讨论了减轻SAH的潜在方法，其中位置编码策略能有效缓解SAH，并采用DPO策略进一步增强模型在事件内和跨事件区分语义的能力。此外，研究者创建了一个包含8K对抗数据对的自定义数据集，该数据集在ELV-Halluc和Video-MME基准中均实现了显著改进，特别是SAH比率减少了27.7%。", "conclusion": "该研究通过ELV-Halluc基准确认了SAH的存在及其随语义复杂度增加的趋势，并提出了减轻SAH的方法，特别是在长视频语义聚合方面。通过位置编码策略和DPO策略的应用，模型在区分事件内和跨事件的语义方面表现更优，显著降低了SAH的比例。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21556", "html_url": "https://arxiv.org/abs/2508.21556", "title": "ECHO: 蛋糕中心的人类-物体交互建模", "title_en": "ECHO: Ego-Centric modeling of Human-Object interactions", "authors": "Ilya A. Petrov,Vladimir Guzov,Riccardo Marin,Emre Aksan,Xu Chen,Daniel Cremers,Thabo Beeler,Gerard Pons-Moll", "background": "从第一人称视角建模人类-物体交互（HOI）是尚未充分探索但很重要的问题，因为可穿戴设备如智能眼镜和手表的普及。我们研究了仅通过头部和手腕跟踪可以获得多少交互信息。ECHO 提出了首个统一框架，从这些最小观察中恢复三种模态：人类姿态、物体运动和接触，致力于这一问题。这种方法操作在一个头部为中心的标准空间中，增强了对全局方向的鲁棒性。我们提出了基于传送带的推理，随着帧位置逐步增加扩散时间戳，可以处理任意长度的序列。", "innovation": "ECHO 提出了一种新颖的统一框架，利用Diffusion Transformer架构和独特的三变量扩散过程，联合建模人类运动、物体轨迹和接触序列，允许灵活的输入配置。ECHO 方法在一个头部为中心的标准空间中操作，增强了对其全球方向的鲁棒性。通过基于传送带的推理过程，ECHO 可以处理任意长度的序列，并且在严格评估中表现出色，超越了现有的不具备灵活性的方法，达到了崭新的技术水平，确立了在第一人称 HOI 重建中的先进地位，", "conclusion": "ECHO 通过冗余激活和分层聚合对第一人称视角下的 HOI 进行建模，展示了其在准确性、稳定性及序列长度上的优势，达到了此前的先进水平。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21539", "html_url": "https://arxiv.org/abs/2508.21539", "title": "HCCM: 层次交叉粒度对比和匹配学习方法在自然语言引导的无人机中的应用", "title_en": "HCCM: Hierarchical Cross-Granularity Contrastive and Matching Learning for Natural Language-Guided Drones", "authors": "Hao Ruan,Jinliang Lin,Yingxin Lai,Zhiming Luo,Shaozi Li", "background": "自然语言引导的无人机（NLGD）在目标匹配和导航等任务中提供了新的范式。然而，无人机视角广泛且语义复杂，对视觉-语言理解构成了挑战。主流的视觉-语言模型侧重于全局对齐，缺乏细粒度的语义信息；现有层次方法依赖精确的目标分割和严格的包含关系，在动态环境中效果有限。", "innovation": "本文提出了层次交叉粒度对比和匹配学习（HCCM）框架，包含两个组件：(1) 区域-全局图像-文本对比学习 (RG-ITC)，通过对比局部视觉区域和全局文本信息，避免了精确场景分割，捕捉局部到全局的层次语义；(2) 区域-全局图像-文本匹配 (RG-ITM)，通过评价全局跨模态表示中的局部语义一致性，缓解了严格的约束限制。此外，HCCM 引入了动量对比和蒸馏 (MCD) 机制以提升鲁棒性。实验表明，HCCM 在 GeoText-1652 数据集的表现为图像检索最高召回率 28.8%，文本检索 14.7%。在未见过的 ERA 数据集上，HCCM 达到平均召回率 (mR) 39.93%，超出了微调基线的表现。", "conclusion": "HCCM 框架在自然语言引导无人机任务中展示了优越的性能，尤其在面对视觉-语言理解的挑战时表现良好，尤其是在图像和文本检索任务和领域零样本泛化能力方面取得了卓越成绩。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21550", "html_url": "https://arxiv.org/abs/2508.21550", "title": "EZ-Sort: 零样本CLIP基 Line预排序及人工在环排序的高效成对比较", "title_en": "EZ-Sort: Efficient Pairwise Comparison via Zero-Shot CLIP-Based Pre-Ordering and Human-in-the-Loop Sorting", "authors": "Yujin Park,Haejun Chung,Ikbeom Jang", "background": "在主观或困难的注释任务中，成对比较通常优于绝对评分或等级分类，因为其可靠性更高。然而，成对比较需要大量的注释（O(n^2)）。近期工作通过使用排序算法积极抽样成对比较，将注释负担大幅减少至O(n log n)。本文在此基础上，进一步提高了注释效率。", "innovation": "1. 使用对比语言-图像预训练的CLIP模型进行零样本预排序，无需训练；2. 用自动化比较替换简单的、显而易见的人类比较；3. 提出的EZ-Sort方法通过零样本CLIP基线预排序、基于桶的Elo分数初始化以及不确定性的引导下的人工在环MergeSort运行来执行。", "conclusion": "验证结果显示，相比完全成对比较，EZ-Sort将人工注释成本降低了90.5%，相比之前的工作降低了19.8%（当n=100时），同时提高了或保持了评判者间的一致性。这些结果表明，结合CLIP基线先验与不确定性的抽样能提供一个高效且可扩展的成对排名解决方案。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21565", "html_url": "https://arxiv.org/abs/2508.21565", "title": "视觉语言模型在理解城市方面表现如何？从街景图像进行空间推理的比较研究", "title_en": "How Well Do Vision--Language Models Understand Cities? A Comparative Study on Spatial Reasoning from Street-View Images", "authors": "Juneyoung Ro,Namwoo Kim,Yoonjin Yoon", "background": "有效理解城市场景需要精细的空间推理，包括物体、布局和深度提示。然而，当前广泛场景预训练的视觉语言模型（VLMs）在城市领域中是否能够很好地转移这些能力仍待进一步探索。基于此，作者通过收集街景图像的分割、深度和物体检测预测，并构造特定于城市场景的合成VQA数据集，对三个现成的VLMs（BLIP-2、InstructBLIP、LLaVA-1.5）的零样本性能以及通过合成VQA数据集进行微调的效果进行了评估。", "innovation": "研究引入了城市空间推理作为视觉语言模型的新挑战，并展示了如何通过构造合成数据集来适应通用模型的专用领域。特别之处在于，构建了特定于城市场景的VQA数据集，用于监督视觉语言模型在空间推理任务中的表现。", "conclusion": "研究表明，虽然视觉语言模型在零样本设置中表现得相对良好，但通过我们的合成CoT监督数据集进行微调能显著增强其性能，特别是在否定和假设性问题等具有挑战性的问题类型上。这为视觉语言模型在特定领域中的应用提供了一条实际途径。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21580", "html_url": "https://arxiv.org/abs/2508.21580", "title": "4D longitudinal医学影像中的时空轨迹学习", "title_en": "Temporal Flow Matching for Learning Spatio-Temporal Trajectories in 4D Longitudinal Medical Imaging", "authors": "Nico Albert Disch,Yannick Kirchhoff,Robin Peretzke,Maximilian Rokuss,Saikat Roy,Constantin Ulrich,David Zimmerer,Klaus Maier-Hein", "background": "理解医学影像的时间动态对于疾病进展建模、治疗规划和解剖发育跟踪等应用至关重要。然而，大多数深度学习方法要么只考虑单一时间上下文，要么专注于分类或回归任务，这些限制了它们进行细粒度空间预测的能力。虽然一些方法被探索出来，但它们通常局限于单个时间点、特定疾病或有其他技术限制。", "innovation": "本文介绍了时空流匹配(TFM)，这是一种统一的生成轨迹方法，(i)旨在学习潜在的时间分布，(ii)设计上可以退化为最近的图像预测器，即预测最后一张上下文图像(LCI)的一种特殊情况，(iii)支持3D体积、多张前期扫描和不规则采样。", "conclusion": "在三个公开的纵向数据集上进行的广泛基准测试表明，TFM 在时空预测方面始终超越了自然影像领域的时空方法，确立了一个新的最佳基准和稳健的4D医学图像预测基础。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21680", "html_url": "https://arxiv.org/abs/2508.21680", "title": "向基于提示模型的全身PET/CT病变交互分割迈进", "title_en": "Towards Interactive Lesion Segmentation in Whole-Body PET/CT with Promptable Models", "authors": "Maximilian Rokuss,Yannick Kirchhoff,Fabian Isensee,Klaus H. Maier-Hein", "background": "全身正电子发射断层扫描/计算机断层扫描（PET/CT）在肿瘤成像中是关键组成部分，但精确区分病灶仍然具有挑战性，原因是示踪剂的异质性、生理吸收和多中心数据的变异性。尽管全自动化的方法取得了显著进步，但在临床上，保持人类参与的半自动方法仍然能够有效地精炼预测的掩模是有益的。自动生成PET/CT IV挑战通过引入基于模拟用户提示的交互分割任务来满足这一需求。", "innovation": "研究建立在先前的自动PET III nnU-Net管道之上，通过编码用户提供的前景和背景点击作为额外的输入通道，增强了提示能力。研究系统地调查了空间提示的表示形式，并证明欧氏距离变换（EDT）编码在性能上始终优于高斯核。此外，还提出了一种在线模拟用户互动和自定义点取样策略，以在真实的提示条件下提高鲁棒性。EDT基础模型组成的集成，无论是有外部数据还是无外部数据训练，都取得了最强的交叉验证性能，相较于基线模型减少了假阳性率和假阴性率。这些结果强调，提示模型能够使用户提供指导的分割工作流程在多示踪剂、多中心PET/CT中具有潜力。", "conclusion": "提示模型在多示踪剂、多中心PET/CT中的应用具有高效、用户引导分割流程的潜力，研究提出的基于EDT的方法和策略提高了模型的性能和鲁棒性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21581", "html_url": "https://arxiv.org/abs/2508.21581", "title": "将病理学与CT成像集成以实现个性化肾癌复发风险预测", "title_en": "Integrating Pathology and CT Imaging for Personalized Recurrence Risk Prediction in Renal Cancer", "authors": "Daniël Boeke,Cedrik Blommestijn,Rebecca N. Wray,Kalina Chupetlovska,Shangqi Gao,Zeyu Gao,Regina G. H. Beets-Tan,Mireia Crispin-Ortuzar,James O. Jones,Wilson Silva,Ines P. Machado", "background": "肾细胞癌（特别是透明细胞肾细胞癌ccRCC）的复发风险评估对于指导术后随访和治疗至关重要。Leibovich评分被广泛用于评估远端复发风险，但是它对患者层面的分辨率有限，并且不包括影像信息。这项研究通过结合术前CT和术后病理切片的全视野图像（WSI），以多模态的方式评估复发预测模型，强调了解剖学信息在风险评估中的重要性，并探索了一种模块化的深度学习框架，包括预先训练的编码器和Cox基生存建模方法。", "innovation": "研究开发了一种模块化的深度学习框架，通过集成术前CT和术后病理切片的全视野图像，来评估多模态复发预测模型，测试了单模态、延迟融合和中间融合设置。研究结果表明，基于WSI的模型优于仅基于CT的模型，病理学具有更强的预后价值。中间融合进一步提高了模型性能，最佳模型TITAN-CONCH与ResNet-18结合，接近调整后的Leibovich评分。随机平局断假设缩小了临床基准和学习模型之间的差距，表明离散化可能夸大了个体化性能。", "conclusion": "研究结果表明，基于基本模型的多模态集成对于个性化ccRCC复发风险预测是可行的，未来的研究应该探索更具表现力的融合策略、更大规模的多模态数据集和通用CT编码器，以更好地匹配病理学建模能力。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21657", "html_url": "https://arxiv.org/abs/2508.21657", "title": "高复杂值可变形注意机制的展开框架用于高质量计算机生成全息图生成", "title_en": "Unfolding Framework with Complex-Valued Deformable Attention for High-Quality Computer-Generated Hologram Generation", "authors": "Haomiao Zhang,Zhangyuan Li,Yanling Piao,Zhi Li,Xiaodong Wang,Miao Cao,Xiongfei Su,Qiang Song,Xin Yuan", "background": "计算机生成全息图（CGH）正在因基于深度学习的算法而受到广泛关注。然而，由于其非线性和病态特性，实现准确和稳定的重建仍然面临挑战。具体来说，（i）常用的端到端网络将重建模型视为黑箱，忽略了潜在的物理关系，降低了可解释性和灵活性。（ii）基于CNN的CGH算法具有有限的感受野，这阻碍了它们捕捉长距离依赖和全局上下文的能力。（iii）基于光谱方法（ASM）的模型受到有限计算资源的限制。因此，本研究旨在提出一种展开网络（DUN），将梯度下降分解为两个模块：自适应带宽保持模型（ABPM）和相位域复值去噪器（PCD），提供更多的灵活性。ABPM允许与ASM方法相比更宽的会聚距离，同时PCD利用其复值可变形自注意力模块捕捉全局特征并提升性能，实现了超过35dB的PSNR。", "innovation": "提出了一种展开网络（DUN），该网络分解了梯度下降为两个模块：自适应带宽保持模型（ABPM）和相位域复值去噪器（PCD），提供了更宽的会聚距离，并利用复杂值可变形自注意力模块捕捉全局特征以提高性能。", "conclusion": "在模拟和实际数据上的实验显示了最先进的结果。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21689", "html_url": "https://arxiv.org/abs/2508.21689", "title": "怀疑主义的映射：基于概率的BEV投影进行在线高精地图构建", "title_en": "Mapping like a Skeptic: Probabilistic BEV Projection for Online HD Mapping", "authors": "Fatih Erdoğan,Merve Rabia Barın,Fatma Güney", "background": "从传感器输入构建高清晰度（HD）地图需要精确地将图像空间中的道路元素映射到鸟瞰图（BEV）空间。这些映射的精度直接影响最终向量化HD地图的质量。现有HD地图构建方法将投影外包给标准地图技术，如基于注意力的方法，但这些方法由于泛化问题难以保证准确性，经常虚构不存在的道路元素。我们提出了一种新的基于几何映射的思想，该思想结合了成像参数，并将其适应场景以提取相关的地图信息。为实现这一目标，我们提出了一种新颖的概率图投影机制，包括信心分数，以（i）细化映射以更好地与场景对齐，（ii）过滤不应影响HD地图生成的相关元素。此外，我们还通过使用信心分数在时间维度上选择性地累积可靠信息来改进时间处理。在新分割的nuScenes和Argoverse2数据集上的实验表明了比现有最佳方法更好的性能，表明有更好的泛化能力。特别是在nuScenes和长感知范围内，改进尤为显著。我们已将代码和模型检查点发布在该网址：https://github.com/example/repo", "innovation": "本研究提出了一种基于几何映射的方法，并结合了成像参数来适应场景，从而更精确地从摄像机图像中提取关键信息。提出了一种新的概率图投影机制，带有信心分数，以细化映射并过滤掉无关元素。同时，时间处理通过使用信心分数选择性地累积可靠信息得到了改进。", "conclusion": "在nuScenes和Argoverse2数据集的新分割上的实验表明了比现有最佳方法更好的性能，特别是针对nuScenes和长时间感知范围。这种方法在泛化能力上有所提高，表明在高精度地图构建中具有更好的适应性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21472", "html_url": "https://arxiv.org/abs/2508.21472", "title": "通过局部扩增实现船体检测的对抗补丁攻击", "title_en": "Adversarial Patch Attack for Ship Detection via Localized Augmentation", "authors": "Chun Liu,Panpan Ding,Zheng Zheng,Hailong Wang,Bingqian Zhu,Tao Xu,Zhigang Han,Jiayao Wang", "background": "当前基于遥感图像的船体检测技术主要依赖深度神经网络（DNNs）的检测能力。然而，DNNs容易受到对抗补丁攻击的影响，这可能导致检测模型的误分类或目标完全逃避攻击。已有大量研究证明，基于数据变换的方法可以提高对抗样本的迁移性，但过度增强背景或无关区域可能会引入不必要的干扰，导致目标检测模型产生误检。这些误检不是因对抗补丁本身，而是由于背景和非目标区域的过度增强。", "innovation": "本文提出了一种局部扩增方法，仅对目标区域进行扩增，避免对非目标区域产生影响，减少背景干扰，使损失函数能够更直接地关注对抗补丁对检测模型的影响，从而提高攻击成功率。", "conclusion": "在HRSC2016数据集上的实验表明，所提出的方法有效提高了对抗补丁攻击的成功率和可迁移性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为何局限于单词？从单词级OCR到行级OCR揭示更大的视角", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统的光学字符识别（OCR）技术将每个字符分离后进行识别，这导致字符分割容易出错，并且缺乏上下文信息，无法充分利用语言模型。近年来，在序列到序列翻译方面取得了进展，现代技术首先检测单词，然后一次输入一个单词到模型，直接输出完整单词作为字符序列。这种方法更好地利用了语言模型，并省略了容易出错的字符分割步骤。然而，这种转变使准确性瓶颈转移到了单词分割上。该研究观察到了这一点，并提出了一种自然且逻辑合理的进展，从单词级OCR到行级OCR的方法。这一提议旨在绕过单词检测中的错误，并提供更多句子上下文，以更好地利用语言模型。我们展示了提出的技术不仅提高了准确度，还提高了OCR效率。尽管进行了彻底的文献调查，我们没有找到可用于训练和评估从单词级OCR到行级OCR转变的公共数据集。因此，我们还贡献了一个包含251张英文页面图像且带有行级注释的精心整理数据集。我们的实验表明，端到端准确度提高了5.4%，突显了向行级OCR过渡的潜在好处，特别是在文档图像方面。此外，与基于单词的管道相比，效率提高了4倍。随着大型语言模型的持续改进，我们的方法也有潜力利用这些方面的进步。", "innovation": "提出了一种自然的从单词级OCR过渡到行级OCR的技术。该技术绕过了单词检测的错误，提供了更大的句子上下文，以更好地利用语言模型。并贡献了一个精心整理的251张英文页面图像的数据集，带有行级注释。该技术提高了准确性和效率，特别适用于文档图像。此外，该方法未来有望利用大型语言模型的进步。", "conclusion": "通过提出从单词级OCR到行级OCR的方法，该研究显著提高了OCR的准确性和效率，并展示了使用大型语言模型的潜在拓展性。这一贡献不仅提供了新的技术，还提供了一个重要的数据集来支持此类研究。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21712", "html_url": "https://arxiv.org/abs/2508.21712", "title": "FLORA: 低数据情况下基于Fine-tuning Flux LoRA的高效合成数据生成方法", "title_en": "FLORA: Efficient Synthetic Data Generation for Object Detection in Low-Data Regimes via finetuning Flux LoRA", "authors": "Alvaro Patricio,Atabak Dehban,Rodrigo Ventura", "background": "最近基于扩散的生成模型在增强检测任务中稀缺数据集方面展示了显著的潜力。然而，大多数最新模型依赖于大型扩散模型的耗资源完整的微调，需要企业级的GPU（例如NVIDIA V100）和数千张合成图像。为此，本文提出了一种轻量级的合成数据生成管道—FLORA（基于Fine-tuning Flux LoRA的FLUX LoRA Augmentation）。该方法利用FLUX 1.1 Dev扩散模型，并且仅通过低秩适应（LoRA）进行微调，从而大大降低了计算需求，使使用消费级GPU（例如NVIDIA RTX 4090）即可生成合成数据集。我们在七个不同的对象检测数据集上进行了实验评估，结果显示与使用ODGEN基线的5000张合成图像进行训练相比，使用我们的方法仅用500张合成图像即可实现更好的检测性能，提高了mAP@.50:.95值至多21.3%。这一成果证明了可以在效率更高的情况下超越现有技术，FLORA不仅使用了十分之一的数据，而且计算成本也减少了相当大的比例。经验结果表明，与粗暴的生成方式相比，注重质量和效率的方法更加有效，使高级合成数据的创建更加实用和现实。", "innovation": "FLORA是一种轻量级的合成数据生成方法，通过低秩适应（LoRA）对FLUX 1.1 Dev扩散模型进行微调，从而显著降低了计算需求，使得使用消费级GPU即可生成合成数据集。实验结果表明，使用FLORA生成的500张合成图像进行训练的对象检测器在mAP@.50:.95指标上优于使用ODGEN基线的5000张合成图像，表明FLORA在更低的数据集规模下可以取得更好的效果。", "conclusion": "本文提出的方法FLORA展示了在低数据水平的情况下，通过优化计算需求和提高数据利用率来提高检测性能，并表明专注于质量和效率的方法比简单的数据生成更为有效，这使得高级合成数据的创建对现实场景更加实用和可操作。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21761", "html_url": "https://arxiv.org/abs/2508.21761", "title": "从沉默和噪声中学习进行视觉声源定位", "title_en": "Learning from Silence and Noise for Visual Sound Source Localization", "authors": "Xavier Juanola,Giovana Morais,Magdalena Fuentes,Gloria Haro", "background": "视觉声源定位是一项基础感知任务，旨在给定音频时检测视频中声源的位置。尽管最近取得了一些进展，但当前的方法在低音频-视觉语义对应情况下表现不佳，例如寂静、噪音和非屏幕声音等负面音频情景下。大多数先前的研究仅限于具有单个可见声源场景的正案例，忽视了负面音频的情况，限制了评估范围。", "innovation": "该研究提出了三项关键创新：首先，提出了一种新的训练策略，能够整合沉默和噪音，增强模型在正案例中的表现，并使其更具负向音频的抗干扰性。其次，引入了一种新的量化正案例和负向音频-视觉匹配的听觉和视觉特征的对齐性和分离性的度量方法。最后，提出了IS3+，这是一个经过扩展和改进的数据集，包含负向音频。我们的数据、度量和代码可用于下载。", "conclusion": "我们的自监督模型SSL-SaN在此基础上实现了声定位的最新性能，并在跨模态检索方面也表现出色，相比其他自监督模型展现了更好的效果。此外，我们提出的新度量和扩展数据集有助于更公平和全面地评估视觉声源定位方法。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21732", "html_url": "https://arxiv.org/abs/2508.21732", "title": "CAD2DMD-SET：基于3D CAD模型生成的合成数字测量设备数据集工具，用于微调大型视觉-语言模型", "title_en": "CAD2DMD-SET: Synthetic Generation Tool of Digital Measurement Device CAD Model Datasets for fine-tuning Large Vision-Language Models", "authors": "João Valente,Atabak Dehban,Rodrigo Ventura", "background": "近年来，大型视觉-语言模型（LVLMs）在多模态任务中展现出卓越能力。然而，它们在诸如阅读数字测量设备（DMDs）数值等日常场景中表现不佳，尤其是在头戴式相机和增强现实（AR）应用中的杂乱、遮挡、极端视角和运动模糊等实际条件下。", "innovation": "该研究提出了CAD2DMD-SET，一种利用3D CAD模型、高级渲染和高质量图像合成技术生成多样、标记为视觉问答任务的DMD数据集的合成数据生成工具。通过这种方法，可以微调LVLMs以提升其在特定条件下的性能。此外，还提出了DMDBench，一个包含1000张标注的实地图像的数据集，用于评估模型的性能。使用CAD2DMD-SET生成的数据集进一步微调领先的LVLMs，显著提升了模型性能，尤其是InternVL在精确度上提高了200%，而性能未受影响。", "conclusion": "CAD2DMD-SET训练数据集明显提升了LVLMs在上述挑战条件下的鲁棒性和性能。该工具计划在最终手稿准备完成后开源，以供社区使用。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21715", "html_url": "https://arxiv.org/abs/2508.21715", "title": "基于熵的非侵入性卷积神经网络可靠性监控", "title_en": "Entropy-Based Non-Invasive Reliability Monitoring of Convolutional Neural Networks", "authors": "Amirhossein Nazeri,Wael Hafez", "background": "卷积神经网络（CNNs）已成为现代计算机视觉的基础，实现了在不同图像识别任务中的前所未有的准确性。尽管这些网络在分布内的数据上表现出色，但它们仍然容易受到不可见的对抗性扰动的影响，这些扰动会导致高置信度的误分类。然而，现有的检测方法要么需要昂贵的重新训练，要么修改网络结构，要么在干净输入上降低性能。", "innovation": "作者展示了对抗性扰动在CNN激活中创造即时且可检测的熵签名，这些熵签名可以通过监控检测，无需对模型进行任何修改。在VGG-16上的并行熵监控实验表明，对抗性输入在早期卷积层的激活熵上会一致地移动7%，使得检测准确率达到90%，并且误检率和漏检率均低于20%。完全分离干净和对抗性熵分布揭示了CNN中激活模式内固有地编码着分布偏移。", "conclusion": "这项工作证明了CNN的可靠性可以通过激活熵单独进行评估，从而使得实时检测对抗性输入的自诊断视觉系统在不损害原始模型性能的前提下成为可能。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21767", "html_url": "https://arxiv.org/abs/2508.21767", "title": "UItron：拥有高级感知和规划能力的基石GUI代理", "title_en": "UItron: Foundational GUI Agent with Advanced Perception and Planning", "authors": "Zhixiong Zeng,Jing Huang,Liming Zheng,Wenkang Han,Yufeng Zhong,Lei Chen,Longrong Yang,Yingjie Chu,Yuzhi He,Lin Ma", "background": "GUI代理旨在为移动/PC设备实现自动化操作，是实现通用人工智能的重要任务。视觉语言模型（VLMs）的迅速发展加速了GUI代理的发展，因为它们具有强大的视觉理解和任务规划能力。然而，构建GUI代理仍然是一项具有挑战性的任务，因为操作轨迹稀缺、交互基础设施不可用以及基础模型初始能力的限制。", "innovation": "介绍了UItron，一个开源的基础型GUI代理模型，具备先进的GUI感知、定位和规划能力。UItron强调系统化数据工程和交互基础设施作为GUI代理发展的基石。通过系统地研究一系列数据工程策略来增强训练效果，并建立了连接移动和PC设备的交互环境。在训练过程中，采用监督微调在各种GUI场景中进行感知和规划任务，并开发了一个基于强化学习的课程框架，以允许在在线环境中进行复杂的推理和探索。实验结果表明，UItron在中文应用方面取得了显著进展，推动了GUI代理更接近实际应用。", "conclusion": "UItron在GUI感知、定位和规划中取得了显著性能。它在中文应用程序场景中显示了与顶级中国移动应用程序的高度兼容性，并且通过人工收集超过一百万步的交互轨迹来训练，从而建立了离线和在线代理评估环境。实验结果表明，UItron在中文应用方面取得了显著进步，将GUI代理推向实际应用更近一步。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21770", "html_url": "https://arxiv.org/abs/2508.21770", "title": "从《哈利·波特》能学到什么？异常视频中视觉表征学习的初步研究", "title_en": "What Can We Learn from Harry Potter? An Exploratory Study of Visual Representation Learning from Atypical Videos", "authors": "Qiyue Sun,Qiming Huang,Yang Yang,Hongjun Wang,Jianbo Jiao", "background": "人类在开放世界中通常展现出出色的新概念理解和发现能力，特别是对于不常见的新概念。然而，大多数现有研究集中在闭集中的常见典型数据上，开放世界中的新发现并未在视频中得到充分探索。本文探讨了在学习过程中暴露异常数据会带来什么影响，收集了包含不同类型的异常数据（例如科幻、动画等）的新视频数据集，以研究这些异常数据对开放世界学习的影响。", "innovation": "论文通过引入一个新的异常数据集，研究了这种异常数据如何改善开放世界学习中的多种任务（如异常检测、新类别发现和零样本动作识别）的表现。实验发现，即使在基础学习方法中使用异常数据，也能一致地提高性能，并且异常样本的类别多样性进一步提升了异常检测性能。同时，在新类别发现任务中，使用较少但更具语义多样性的异常样本比使用更多但更典型的数据集效果更佳。在零样本动作识别中，异常视频的语义多样性有助于模型更好地泛化到未见过的动作类别。这些观察结果揭示了异常视频在开放世界视觉表征学习中的好处，促进了这一方向的进一步研究。", "conclusion": "异常数据的引入增强了开放世界学习中多种任务的表现，证明了在学习过程中使用异常数据的有效性。实验结果表明了更多潜在的异常数据集的开发价值，鼓励更多研究关注异常视频在开放世界学习中的应用。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21769", "html_url": "https://arxiv.org/abs/2508.21769", "title": "领域泛化在实际场景中的评估：解构分类与领域感知表示", "title_en": "Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations", "authors": "Ha Min Son,Zhe Zhao,Shahbaz Rezaei,Xin Liu", "background": "评估基础模型如CLIP的领域泛化（DG）具有挑战性，因为大规模网络预训练数据可能会涵盖许多现有基准。当前的DG评估可能既不足够具有挑战性，也不充分测试真正未见过的数据场景。为了更好地评估CLIP在实际场景中的DG性能，即CLIP遇到具有挑战性的未见过数据的情况，本文考虑了两种方法：（1）在ImageNet上微调CLIP后，在33个不同数据集上进行评估，并量化这些数据集的分布外（OOD）分数；（2）通过撤销学习让CLIP“忘记”某些领域，作为近似方法。观察到CLIP在更多OOD数据集上的性能显著下降。", "innovation": "本文提出了CLIP-DCA（解构分类以增强领域感知表示）的方法。该方法受到这样一个观察的启发：虽然标准领域不变性损失致力于使表示领域不变，但这可能会对基础模型有害，导致有价值的领域感知表示被舍弃。CLIP-DCA通过一个单独的领域头和合成的多种领域数据来识别并增强CLIP编码器中的领域感知，同时通过领域特征分离来促进领域不变的分类。", "conclusion": "CLIP-DCA在这一具有挑战性的评估场景中表现显著优于现有方法，尤其是在更多OOD数据集上展现出明显改进。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21795", "html_url": "https://arxiv.org/abs/2508.21795", "title": "TMUAD: 增强统一异常检测模型中逻辑能力的文本记忆库", "title_en": "TMUAD: Enhancing Logical Capabilities in Unified Anomaly Detection Models with a Text Memory Bank", "authors": "Jiawei Liu,Jiahe Hou,Wei Wang,Jinsong Du,Yang Cong,Huijie Fan", "background": "异常检测的目标是识别偏离正常模式的异常样本，但由于正常数据量有限，这给异常检测带来挑战。现有的大多数统一方法依赖于精心设计的图像特征提取器和记忆库来捕捉对象之间的逻辑关系，而本研究引入了一个文本记忆库以增强逻辑异常的检测能力。", "innovation": "本研究提出了一个包含三个互补记忆库的统一结构和逻辑异常检测框架（TMUAD）：通过一个逻辑感知文本提取器构建的类级别文本记忆库用于逻辑异常检测；通过从分割对象中提取特征构建的对象级别图像记忆库；通过视觉编码器提取补丁级别的图像特征构建的补丁级别记忆库用于结构异常检测。通过这些记忆库的协作，TMUAD在七个公开数据集中实现了跨工业和医疗领域的顶级性能。", "conclusion": "通过将结构异常检测和逻辑异常检测统一起来，TMUAD显著提高了异常检测的性能。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21777", "html_url": "https://arxiv.org/abs/2508.21777", "title": "在放射肿瘤学中基准测试GPT-5：有可测量的进步，但仍需专家监督", "title_en": "Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight", "authors": "Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz", "background": "大型语言模型（LLM）在临床决策支持方面展现出巨大潜力。GPT-5是一种专门针对肿瘤学使用的新颖LLM系统。", "innovation": "该研究通过两种互补基准（ACR辐射肿瘤学在职考试和放射肿瘤学的真实临床案例集）评估了GPT-5的表现，并发现其在辐射肿瘤学多项选择题基准测试中优于GPT-4和GPT-3.5。此外，GPT-5生成的真实世界辐射肿瘤学治疗建议受到了主治医生的高度评价。", "conclusion": "尽管GPT-5在辐射肿瘤学选择题基准测试中表现出色，并且在生成真实世界治疗建议方面表现出积极进展，但仍需要进一步改进以提高准确性，且生成的建议在临床实施前需要专家严格监督。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21773", "html_url": "https://arxiv.org/abs/2508.21773", "title": "无需监督的视频连续学习通过非参数化深度嵌入聚类", "title_en": "Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering", "authors": "Nattapong Kurpukdee,Adrian G. Bors", "background": "视频广泛应用于多种应用中，但它们在无监督的连续学习中的探索不足。之前的研究主要集中在有监督连续学习上，依赖于标签和任务边界的知识，然而获取标签数据过于昂贵且不实际。因此，提出了无监督视频连续学习 (uVCL)，这带来更多的挑战，因为与图像相比，处理视频需要更多的计算和内存资源。uVCL 液压的学习在每次任务中无结构视频数据类别的过程中提出了新的挑战。当前方法通过使用深度嵌入视频特征的核密度估计（KDE）作为非参数化的概率表示来进行学习。利用先前任务的转移学习作为当前学习任务的知识转移的初始状态。在UCF101、HMDB51和Something-to-Something V2三个标准视频动作识别数据集上进行了深入评估，未使用任何标签或类别边界，证实了所提出的方法在连续学习多个任务中的显著性能提升。", "innovation": "提出了一种无监督视频连续学习 (uVCL) 的新的非参数化学习解决方案，使用无监督视频转换器网络提取的深度嵌入视频特征的核密度估计 (KDE) 作为一种非参数概率表示方法。引入了一种新颖性检测标准来动态扩展内存簇，旨在学习一系列任务时捕获新知识。提出了一个通用的基准实验协议，考虑每次任务中无结构视频数据类别的学习过程。利用先前任务的转移学习作为当前学习任务的知识转移的初始状态。", "conclusion": "所提出的方法显著提升了模型在连续学习多个任务时的性能。在没有使用任何标签或类边界的三个标准视频动作识别数据集上进行了深入评估，结果证实了该方法的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21775", "html_url": "https://arxiv.org/abs/2508.21775", "title": "在诊断和治疗MRI中胰腺肿瘤分割的多阶段微调和集成策略", "title_en": "A Multi-Stage Fine-Tuning and Ensembling Strategy for Pancreatic Tumor Segmentation in Diagnostic and Therapeutic MRI", "authors": "Omer Faruk Durugol,Maximilian Rokuss,Yannick Kirchhoff,Klaus H. Maier-Hein", "background": "胰腺导管腺癌（PDAC）的MRI自动化分割对临床流程至关重要，但受限于肿瘤与组织间对比度差以及标注数据稀缺。这篇论文详细描述了我们在PANTHER挑战中的提交，针对诊断T1加权（Task 1）和治疗T2加权（Task 2）影像的分割。背景强调了数据稀缺性和对比度差这对工作的影响。", "innovation": "本文提出了一种基于nnU-Net框架的多阶段微调策略，通过从一般的解剖基础模型开始，逐级微调CT胰腺病变数据集和目标MRI模态，以此解决多模态数据复杂性问题。此外，通过系统地评估各个数据增强方案和训练计划，论文发现了数据增强和边界精度之间的权衡，并有效利用这一发现构建了专门模型的多样性集成方法。", "conclusion": "通过方法系统的调优和最终的集成方法，论文最终在Task 1和Task 2上分别达到了0.661和0.523的肿瘤Dice分数。该研究提供了一种在数据有限且任务复杂的医学成像背景下开发专门高性能模型的稳健方法。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21824", "html_url": "https://arxiv.org/abs/2508.21824", "title": "DriveQA:通过驾驶知识测试", "title_en": "DriveQA: Passing the Driving Knowledge Test", "authors": "Maolin Wei,Wanzhou Liu,Eshed Ohn-Bar", "background": "本文指出，如果一个大型语言模型（LLM）今天参加驾驶知识测试，它可能无法通过。这不仅需要解决当前自主驾驶基准测试中的标准空间和视觉问答任务，还需要对所有交通规则、标志和优先权原则有一个全面的理解。为了通过这种测试，人类驾驶员必须区别那些在现实世界数据集中很少出现的边缘情况。现有研究表明，最先进的LLM和多模态LLM在基础交通规则上表现出色，但在数值推理、复杂的优先权情境、交通标志变化和空间布局方面表现出显著不足。", "innovation": "本文提出DriveQA，这是一个全面的开源文本和视觉基准，涵盖了所有交通条例和场景。通过DriveQA实验，本文展示了（1）最先进的LLM和多模态LLM在基本交通规则上表现良好，但在数值推理和复杂优先权情境、交通标志变化和空间布局方面显示出明显的不足；（2）在DriveQA上进行微调可以提高多个类别的准确性，特别是在法规标志识别和交叉路口决策方面；（3）DriveQA-V的控制变化提供了对模型对环境因素如光线、视角、距离和天气条件的敏感性的见解；（4）在DriveQA上的预训练提高了下游驾驶任务的性能，导致在nuscenes和BDD等现实世界数据集上取得了更好的结果，同时也展示了模型可以内部化文本和合成交通知识，以在下游问答任务中有效泛化。", "conclusion": "本文通过DriveQA实验表明，预训练和微调可以在复杂驾驶知识和多模态理解上提高模型性能，使得模型能够更有效地应对现实世界的驾驶任务。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21816", "html_url": "https://arxiv.org/abs/2508.21816", "title": "《内在的恶魔即为歧义：重新审视情境识别中的单正多标签学习》", "title_en": "The Demon is in Ambiguity: Revisiting Situation Recognition with Single Positive Multi-Label Learning", "authors": "Yiming Lin,Yuchen Niu,Shang Wang,Kaizhu Huang,Qiufeng Wang,Xiao-Bo Jin", "background": "情境识别（SR）是计算机视觉中的一个基本任务，旨在通过识别关键事件及其相关实体来从图像中提取结构化语义摘要。现有方法通常将动词分类视为单标签问题，但研究通过全面的分析表明，这种表述未能解决视觉事件识别中的固有歧义，因为多个动词类别可能合理地描述同一张图片。", "innovation": "本研究做出了三项关键贡献：首先，通过实证分析揭示动词分类本质上是一个多标签问题，因为不同动词类别之间存在语义重叠；其次，鉴于大规模数据集多标签注释的不切实际，提出将动词分类重新定义为单正多标签学习（SPMLL）问题，这是一种在SR研究中的新颖视角；最后，设计了一个全面的多标签评价基准，旨在公平地评估模型在多标签设置下的性能。", "conclusion": "为了应对SPMLL的挑战，进一步开发了基于图增强动词的多层感知机（GE-VerbMLP），该模型结合了图神经网络来捕捉标签间的关联性，并通过对抗训练优化决策边界。在实际数据集上的广泛实验表明，该方法在保持传统TOP-1和TOP-5精度指标竞争力的同时，MAP指标提高了超过3%。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21095", "html_url": "https://arxiv.org/abs/2508.21095", "title": "ScanMove：未注册体表网格上的运动预测和转移", "title_en": "ScanMove: Motion Prediction and Transfer for Unregistered Body Meshes", "authors": "Thomas Besnier,Sylvain Arguillère,Mohamed Daoudi", "background": "未注册的表面网格，尤其是原始3D扫描，由于缺乏点间对应关系和数据中的噪音，对自动计算合理的变形提出了巨大挑战。", "innovation": "本文提出了一种新的、无需刚性约束的数据驱动框架，用于未注册体表网格上的运动预测和转移。该方法结合了鲁棒的运动嵌入网络和学习的每个顶点特征字段，生成时空变形场，以驱动网格变形。", "conclusion": "广泛的评估表明，我们的方法在诸如行走和跑步等任务上对于具有挑战性的未注册网格是有效的且具有灵活性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19153", "html_url": "https://arxiv.org/abs/2508.19153", "title": "QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning", "title_en": "QuadKAN: KAN-Enhanced Quadruped Motion Control via End-to-End Reinforcement Learning", "authors": "Allen Wang,Gavin Tao", "background": "论文背景在于现有对四足机器人的运动控制大多依赖于单一的感觉方式，如视觉或 proprioception（本体感觉），这可能导致控制不够稳健。因此，该研究旨在结合视觉和 proprioception 以增强四足机器人的运动控制能力，特别是在复杂地形上的表现。", "innovation": "该研究提出了 QuadKAN，一种基于样条参数化的跨模态策略，采用 Kolmogorov-Arnold Networks (KANs) 实现。该框架集成了样条编码器处理 proprioception，以及样条融合头处理 proprioception 和视觉输入。QuadKAN 还采用 Multi-Modal Delay Randomization (MMDR) 并端到端训练算法 Proximal Policy Optimization (PPO)。这种方法通过提高样本效率，减少动作抖动和能耗，提供可解释的姿势-动作敏感性来改善步态的分段平滑性。", "conclusion": "评估结果显示，QuadKAN 在多种地面上的表现优于现有最先进的基线方法，实现了更高、更远的回报以及更少的碰撞，展示了样条参数化策略在稳健的视觉引导下运动控制中的简单、有效和可解释性替代方案。该研究的框架和方法被证明适用于四足机器人在复杂环境中的运动控制。研究团队将把代码库开源。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21143", "html_url": "https://arxiv.org/abs/2508.21143", "title": "Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?", "title_en": "Can Multimodal LLMs Solve the Basic Perception Problems of Percept-V?", "authors": "Samrajnee Ghosh,Naman Agarwal,Hemanshu Garg,Chinmay Mittal,Mausam,Parag Singla", "background": "近年来，多模态大型语言模型（MLLMs）在编码、数学和科学等领域展现了强大的推理能力，但很少有实验评估它们在生成的、未受污染的基本形状和结构图像的简单感知任务中的表现。", "innovation": "本文提出了一个名为Percept-V的新数据集，包含7200张由程序生成的图像，分为30个类别，每个类别涵盖不同视觉感知技能的组合。与其他数据集不同，Percept-V包含各种复杂度的基本任务，用以测试MLLMs的感知能力。研究还在最先进的MLLMs（如GPT-4o、Gemini和Claude）以及大型推理模型（如OpenAI o4-mini和DeepSeek R1）上进行了测试。", "conclusion": "实验结果显示，随着问题复杂性的增加，MLLMs在所有类别中的性能显著下降。性能分析表明，测试的MLLMs在不同类别中的准确率表现出相似的趋势，某些认知技能的难度高于其他技能。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21344", "html_url": "https://arxiv.org/abs/2508.21344", "title": "ARGS: 高级Gaussian对齐正则化", "title_en": "ARGS: Advanced Regularization on Aligning Gaussians over the Surface", "authors": "Jeong Uk Lee,Sung Hee Choi", "background": "3D Gaussian Splatting (3DGS) 在计算机图形学中仍然是一个主要的挑战。尽管现有模型如SuGaR能够提供有效的渲染解决方案，但在视觉保真度和场景一致性方面仍然有很大的改进空间。本文在SuGaR的基础上，通过引入两种互补的正则化策略来解决单个Gaussian形状和整体表面连贯性的问题。", "innovation": "本文提出了两种新的正则化策略。首先，引入了一种有效的秩正则化，这种正则化通过偏好更具平衡、类似于“圆盘状”的形式来避免“针状”几何图形，从而改善表面重建的稳定性。其次，将神经 Signed Distance Function (SDF) 集成到优化过程中，并使用Eikonal损失对其进行正则化，以保持适当的距离属性，并为Gaussian提供连续的全局表面先验，引导Gaussian更好地对齐底层几何形状。这些正则化策略旨在提高单个Gaussian个体和整体表面行为的保真度。", "conclusion": "最终模型能够从3DGS数据中产生更准确且一致的视觉效果。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21695", "html_url": "https://arxiv.org/abs/2508.21695", "title": "Activation Subspaces for Out-of-Distribution Detection", "title_en": "Activation Subspaces for Out-of-Distribution Detection", "authors": "Barış Zöngür,Robin Hesse,Stefan Roth", "background": "为了确保深度模型在现实世界应用中的可靠性，out-of-distribution (OOD) 检测方法旨在区分接近训练分布（同分布，ID）的样本和远离训练分布的样本（OOD）。现有的方法通常依赖于激活值的直接比较来区分ID和OOD样本。", "innovation": "本文提出了一种新颖的OOD检测方法，利用分类头权重矩阵的奇异值分解将模型激活分为贡献最大的决定性子空间和贡献最小的非决定性子空间。研究表明，在大规模分布转移的情况下，非决定性子空间更能有效地区分ID和OOD数据。在小规模分布转移的情况下，通过只考虑决定性子空间，可以避免激活空间中的混淆。结合这两项发现，提出了一种称为ActSub的方法，实现了多种标准OOD基准的最新成果。", "conclusion": "通过结合两种发现，提出了一种称为ActSub的方法，实现了多种标准OOD基准的最新成果。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21738", "html_url": "https://arxiv.org/abs/2508.21738", "title": "从无人机影像到宜居性映射：农村中国的人工智能环境感知", "title_en": "From Drone Imagery to Livability Mapping: AI-powered Environment Perception in Rural China", "authors": "Weihuan Deng,Yaofu Huang,Luan Chen,Xun Li,Yao Yao", "background": "随着脱贫攻坚和乡村振兴战略的深化，改善农村生活环境和提高生活质量已成为关键重点。农村宜居性是衡量这些努力效果的关键指标。目前的测量方法存在显著局限性：基于问卷的方法难以规模化，而以城市为导向的视觉感知方法则不适用于农村情境。因此，本文提出了一种基于无人机影像和多模态大语言模型（MLLMs）的农村特定宜居性评估框架，以全面评估村庄宜居性。", "innovation": "该研究首次利用无人机影像，收集了中国146个县1,766个村庄的大规模影像数据，并构建了一个基于链式思维提示的适用于全国农村的宜居性评估模型，该模型结合了政府财政支出作为核心决定因素，并通过二分查找插值机制提高了图像比较的效率。", "conclusion": "研究结果表明，中国农村宜居性呈现出双重核心边缘的空间格局，从四川和浙江向外辐射，宜居性逐渐降低。政府财政支出是影响农村宜居性的核心因素，每增加一单位的政府财政支出，农村宜居性可提升3.9-4.9个单位。研究结果为农村建设政策制定提供了宝贵见解。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21635", "html_url": "https://arxiv.org/abs/2508.21635", "title": "罗斯亚罗多ataset v2：农业机器人多模态数据集", "title_en": "The Rosario Dataset v2: Multimodal Dataset for Agricultural Robotics", "authors": "Nicolas Soncini,Javier Cremona,Erica Vidal,Maximiliano García,Gastón Castro,Taihú Pire", "background": "本文介绍了在大豆作物田中收集的多模态数据集，包含超过两小时的传感器记录数据，如双目红外相机、彩色相机、加速度计、陀螺仪、磁力计、GNSS（单点定位、实时差分以及后处理差分定位）、以及车轮里程计。该数据集捕捉了农业环境中机器人所面临的诸多挑战，如自然光照变化、运动模糊、崎岖地形以及长时间的感官混淆序列。通过解决这些复杂问题，该数据集旨在支持农业机器人中定位、建图、感知和导航等先进算法的发展与评估。", "innovation": "本文开发了针对农业机器人多模态SLAM系统的平台和数据收集系统，确保多传感器硬件同步以及长轨迹上的6-DOF地面真实值和闭合回路。在此基础上，本文在数据集上运行了当前最先进多模态SLAM方法，展示了他们在农业环境中现有应用的局限性。", "conclusion": "本文发布了该多模态数据集及其使用工具，可在此网址访问：this https URL。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21675", "html_url": "https://arxiv.org/abs/2508.21675", "title": "这张图表在欺骗我吗？自动化误导性可视化检测", "title_en": "Is this chart lying to me? Automating the detection of misleading visualizations", "authors": "Jonathan Tonglet,Jan Zimny,Tinne Tuytelaars,Iryna Gurevych", "background": "误导性的可视化成为社交媒体和网络上错误信息的重要推动力。通过违反图表设计原则，这些可视化会扭曲数据，导致读者得出不准确的结论。先前的研究表明，无论是人类还是多模态大语言模型（MLLMs）都经常被这类可视化所欺骗。自动检测误导性可视化并识别它们违反的具体设计规则有助于保护读者并减少错误信息的传播。然而，由于缺乏大规模、多样且开放获取的数据集，AI模型的训练和评估受到限制。因此，本文介绍了Misviz，一个包含2,604个真实世界的可视化，这些可视化被标注了12种类型的误导性。为了支持模型训练，作者还发布了Misviz-synth，这是一个由Matplotlib生成的包含81,814个可视化数据集，这些数据基于真实世界的数据表。这两套数据集被用于最先进的MLLMs、基于规则的系统和微调分类器进行全面评估，结果显示任务依然具有高度挑战性。", "innovation": "本文引入了Misviz基准数据集和Misviz-synth合成数据集，这些数据集用于视觉化图表的误导性检测。这些数据集提供了大量标注的真实世界和合成未来，帮助研究人员开发和测试自动检测技术，这是首次开发此类大规模、多样且开放获取的数据集，极大地推动了这一领域的研究进度。", "conclusion": "本文研究揭示了误导性可视化检测任务的复杂性，并发布了Misviz和Misviz-synth数据集及相关代码，供研究界使用以进一步研究和改进这类检测技术。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21809", "html_url": "https://arxiv.org/abs/2508.21809", "title": "VoCap: 从任意提示进行视频对象描述和分割", "title_en": "VoCap: Video Object Captioning and Segmentation from Any Prompt", "authors": "Jasper Uijlings,Xingyi Zhou,Xiuye Gu,Arsha Nagrani,Anurag Arnab,Alireza Fathi,David Ross,Cordelia Schmid", "background": "理解视频中的对象需要细粒度的空间-时间掩码和详细的语义属性，在视频理解中是一项基础任务。由于现有数据集难以涵盖各种提示，该研究提出了一个新的数据集S AV-Caption，并开发了一种名为VoCap的灵活模型，该模型能根据文本、框或掩码提示生成空间-时间掩码和对应的对象为中心的描述。", "innovation": "提出了一个新的数据标注方法，即通过预处理带有真值掩码的视频以突出显示目标对象，并将其输入大型视觉语言模型，来自动生成虚假对象描述。计算出的数据集S AV-Caption。此研究还开发了VoCap模型，该模型能同时处理提示可调的视频对象分割、指代表达式分割和对象描述任务，使之在视频对象描述和分割任务上取得了最先进的结果。", "conclusion": "VoCap模型已经在混合图像和视频数据集上进行了大规模训练，并获得了最先进的结果，同时在部分监督视频对象分割任务中表现优异，为视频对象描述设定了基准，数据集将被公开于指定网址。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21456", "html_url": "https://arxiv.org/abs/2508.21456", "title": "Morae：主动暂停UI代理以供用户选择", "title_en": "Morae: Proactively Pausing UI Agents for User Choices", "authors": "Yi-Hao Peng,Dingzeyu Li,Jeffrey P. Bigham,Amy Pavel", "background": "UI代理为视力不佳的用户提供了一种访问复杂用户界面的方法。然而，当前的UI代理通常在执行任务时不会让用户参与关键决策，也不会告知用户重要的上下文信息，从而削减用户的自主权。研究发现，一名视力不佳的参与者请求购买最便宜的气泡水，代理却从多个相同价格的产品中自动选择了其中一个，没有告知用户有不同口味或评分更高的替代产品。因此，论文探讨了Morae这款UI代理，它能够自动识别任务执行中的决策点并暂停，让用户有机会作出选择。Morae通过大型跨模态模型解析用户查询并结合UI代码和屏幕截图来工作，当需要用户选择时，还会提供澄清。这表明，在使用UI代理自动化的同时，用户能够表达自己的偏好，促进了混合主动方法的应用。", "innovation": "Morae通过自动识别决策点并暂停让用户参与到关键决策中，与现有的UI代理相比，Morae通过跨模态模型来解析用户查询并与UI代码和屏幕截图相结合，提供了一种新型的用户选择方式，提升了用户的参与度和偏好匹配度。此外，Morae在实际网站任务中的应用显著提高了视力不佳用户完成任务的数量和选择与个人偏好更匹配的选项的能力。这在用户界面代理领域展示了一种新型的混合主动方法，为用户保留了自主权的同时，还提供了便利的自动化服务。", "conclusion": "该研究通过引入Morae，展示了在用户界面代理中结合用户主动性的方法。Morae帮助视力不佳的用户更好地完成任务和选择更匹配他们偏好的选项，相比基线代理，如OpenAI Operator，有显著改进。这表明，混合主动方法在提升用户体验方面具有巨大潜力。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21785", "html_url": "https://arxiv.org/abs/2508.21785", "title": "从异质数据中学习统一表示以实现稳健的心率建模", "title_en": "Learning Unified Representations from Heterogeneous Data for Robust Heart Rate Modeling", "authors": "Peng Yang,Zhengdong Huang,Zicheng Xie,Wentao Tian,Jingyu Liu,Lunhong Dong", "background": "心率预测对于个性化的健康监测和健身至关重要，但在实际应用中经常面临一个关键挑战：数据异质性。这些异质性体现在多个方面，例如，碎片化的设备市场导致不同的设备具有不同的功能集，这引起了设备源异质性；用户之间的生理差异以及不同活动之间的差异则引起了个人用户异质性。现有的方法要么丢弃设备特定的信息，要么无法建模用户的特定差异，从而限制了其在实际环境中的性能。", "innovation": "该论文提出了一种框架，可以学习不依赖于这两种异质性的潜在表示，使得后续预测模型能够在异质数据模式下一致地运行。具体来说，研究引入了一种随机特征丢弃策略来处理数据源异质性，使模型能够适应各种特征集。为了处理用户异质性，研究使用了一个时间感知注意力模块来捕捉长期生理特征，并使用对比学习目标来构建一个区分性表示空间。此外，为了反映现实世界数据的异质性，研究团队创建并公开发布了新的基准数据集ParroTao。研究表明，该模型在ParroTao数据集和公开的FitRec数据集上分别比现有基线性能高出17%和15%。", "conclusion": "研究分析表明，学习到的表示具有很强的区分性，且下游应用任务也证实了模型的实际价值。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.08420", "html_url": "https://arxiv.org/abs/2403.08420", "title": "采用基础模型的低成本实时工业动作识别框架", "title_en": "ALow-Cost Real-Time Framework for Industrial Action Recognition Using Foundation Models", "authors": "Zhicheng Wang,Wensheng Liang,Ruiyan Zhuang,Shuai Li,Jianwei Tan,Xiaoguang Ma", "background": "在工业环境中进行动作识别（AR），特别是用于识别动作和操作手势，面临着高部署成本、跨场景一般性差以及实时性能有限的挑战。", "innovation": "提出了一种使用基础模型的低成本实时工业动作识别框架（LRIAR），通过结合Grounding DINO和预训练的BLIP-2图像编码器自动构建标签数据集，实现高效和可扩展的动作标签化。利用构建的数据集，通过YOLOv5进行实时动作检测，并使用基于LoRA的微调开发Vision Transformer（ViT）分类器进行动作分类，实验结果表明LRIAR在识别精度、跨场景一般性和部署效率方面优于现有方法。", "conclusion": "LRIAR框架在实际工业环境中进行了广泛实验，验证了其有效性和优势，在识别精度、跨场景通用性和部署效率方面均取得了显著改进，展示了实际应用潜力。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2408.01627", "html_url": "https://arxiv.org/abs/2408.01627", "title": "基于混合Transformer-Mamba模型的语音驱动3D说话语头生成JambaTalk", "title_en": "JambaTalk: Speech-Driven 3D Talking Head Generation Based on Hybrid Transformer-Mamba Model", "authors": "Farzaneh Jafari,Stefano Berretti,Anup Basu", "background": "近年来，说话语头生成成为研究热点。研究人员致力于提高唇部同步运动、捕捉表情、生成自然头部姿态以及实现高质量视频。然而，目前尚未有一种模型能够在所有定量和定性指标上达到等同效果。", "innovation": "提出了Jamba模型，这是一种混合Transformer-Mamba模型，结合了Transformer和Mamba方法的优势，以解决传统模型处理长序列的问题。此外，基于Jamba基础块，提出了JambaTalk，通过多模态整合提升运动多样性与唇部同步。", "conclusion": "实验结果显示，该方法在性能上达到或超越了当前最先进的模型。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2309.08289", "html_url": "https://arxiv.org/abs/2309.08289", "title": "使用点扩散模型对大肠3D形状进行精炼以生成数字填充体", "title_en": "Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation", "authors": "Kaouther Mouheb,Mobina Ghojogh Nejad,Lavsen Dahal,Ehsan Samei,Kyle J. Lafata,W. Paul Segars,Joseph Y. Lo", "background": "对于虚拟成像试验中构建数字填充体而言，准确的3D建模人类器官至关重要。然而，复杂的几何形状和形状变化使得如大肠这样的器官特别具有挑战性。", "innovation": "本文提出了一种新颖的条件隐空间点扩散模型CLAP，结合几何深度学习与降噪扩散模型来增强大肠的3D表示。该方法通过级联自变量编码器学习全局和局部的形状表示，并在隐空间中使用两个条件扩散模型进一步细化器官形状。", "conclusion": "CLAP在形状建模精度方面取得了显著改进，与初始亚最优形状相比，减少了26%的切削距离和36%的豪斯多夫距离。这项方法提供了一种鲁棒且可扩展的解决方案，具有广泛的应用潜力，适用于各种解剖结构。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10257", "html_url": "https://arxiv.org/abs/2411.10257", "title": "使用滑动窗口引导扩散模型", "title_en": "Guiding a diffusion model using sliding windows", "authors": "Nikolas Adaloglou,Tim Kaiser,Damir Iagudin,Markus Kollmann", "background": "指导技术是扩散模型中广泛使用的一种提高样本质量的技术。通过使用一个泛化能力更强的辅助模型来进行指导，可以显著提升样本质量。先前的研究表明，当辅助模型的泛化误差与主要模型相似但稍强时，这种指导方法尤其有效。基于这一观察，本文提出了masked sliding window guidance (M-SWG) 方法，这是一种无需训练的新方法。", "innovation": "M-SWG 方法通过选择性地限制主要模型的感受野来增强长距离的空间依赖性，这种方法无需访问先前迭代的模型权重、额外的训练或类别条件。实验结果表明，M-SWG 方法在 Inception 分数上优于之前最先进的无需训练的方法，且没有引入样本过饱和。结合现有的指导方法，M-SWG 能够在使用 EDM2-XXL 和 DiT-XL 时在 ImageNet 达到最先进的 Frechet DINOv2 距离。", "conclusion": "M-SWG 在无需额外训练的情况下，显著提升了扩散模型的样本质量，并在多种基准测试中表现出色。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.10875", "html_url": "https://arxiv.org/abs/2503.10875", "title": "矩形注意力模块", "title_en": "Convolutional Rectangular Attention Module", "authors": "Hai-Vy Nguyen,Fabrice Gamboa,Sixin Zhang,Reda Chhaibi,Serge Gratton,Thierry Giaccone", "background": "在传统方法中，空间注意力图通常以位置无关的方式生成，这可能会导致不规则的边界，进而影响对新样本的泛化能力。", "innovation": "本文提出了一种易于集成到任何卷积网络中的新型空间注意力模块。该模块通过约束注意力区域为矩形，使注意力区域由仅5个参数定义，从而提高模型的稳定性和对新样本的泛化能力。在实验中，该方法系统地优于位置无关的对应方法。", "conclusion": "本文提供了一种新颖且实用的空间注意力机制，用于卷积模型，并且该模块还提供了关于模型关注点的可解释性，即帮助了解模型在生成预测时关注输入的哪个部分。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21271", "html_url": "https://arxiv.org/abs/2508.21271", "title": "基于3D卷积神经网络的微型自主车驾驶", "title_en": "Mini Autonomous Car Driving based on 3D Convolutional Neural Networks", "authors": "Pablo Moraes,Monica Rodriguez,Kristofer S. Kappel,Hiago Sodre,Santiago Fernandez,Igor Nunes,Bruna Guterres,Ricardo Grando", "background": "随着自动驾驶技术在汽车行业的应用日益增加，它能够提升车辆的安全性、效率以及用户体验，满足了市场对复杂驾驶辅助功能的需求。然而，开发可靠的自动驾驶系统面临着如高复杂度、长期训练期和固有的不确定性等挑战。微型自动驾驶车辆（MACs）作为一种实用的测试平台，为在小型化设置中验证自主控制方法提供了可能。这种简化且成本效益高的环境有助于快速评估和对比机器学习模型，特别是对于需要在线训练的算法尤为有用。现有研究中，基于RGB-D信息以及3D卷积神经网络（3D CNN）的方法被用于评估MACs在模拟环境中的驾驶性能。本次研究对比了基于RNN和3D CNN的模型性能，结合了两个具有不同环境特征的模拟赛道进行训练和测试，从任务完成率、圈速和驾驶一致性等多个维度进行了评估。结果显示，3D CNN在一些方面优于RNN，说明了模型结构调整和赛道复杂度对模型泛化能力和车辆控制性能的影响", "innovation": "本研究提出了基于3D卷积神经网络（3D CNN）的微型自动驾驶车辆（MACs）在模拟环境中的驾驶方法。通过比较3D CNN和递归神经网络（RNN）的性能，研究发现3D CNN在某些方面的表现优于RNN，特别是在模型结构调整和赛道复杂度方面对模型泛化能力和车辆控制性能的影响上。这种方法为微型自动驾驶车辆的控制策略提供了一种新的视角和工具", "conclusion": "本研究通过在模拟环境中的实验，证明了基于3D卷积神经网络的方法在微型自动驾驶车辆驾驶中的有效性。这种方法不仅有助于理解模型结构对驾驶性能的影响，还为未来实际应用提供了理论依据。未来的研究可能进一步探索更复杂的赛道和场景，以及如何将这些控制策略应用于实际的微型自动驾驶车辆"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2502.14156", "html_url": "https://arxiv.org/abs/2502.14156", "title": "Mixed Signals: 一种用于异构LiDAR V2X协作的多样点云数据集", "title_en": "Mixed Signals: A Diverse Point Cloud Dataset for Heterogeneous LiDAR V2X Collaboration", "authors": "Katie Z Luo,Minh-Quan Dao,Zhenzhen Liu,Mark Campbell,Wei-Lun Chao,Kilian Q. Weinberger,Ezio Malis,Vincent Fremont,Bharath Hariharan,Mao Shan,Stewart Worrall,Julie Stephany Berrio Perez", "background": "车辆到万物（V2X）协作感知作为一种有前景的解决单车辆感知系统局限性的方案已经浮现。然而，现有的V2X数据集在范围、多样性和质量方面有限。为了弥补这些不足，我们提供了一个名为Mixed Signals的综合V2X数据集，该数据集包含45100个点云和240600个边界框，由三个连接式自动驾驶车辆（CAVs）收集，这些车辆配备了两种不同配置的LiDAR传感器，以及一个具有双LiDAR的路边设备。", "innovation": "Mixed Signals数据集为异构LiDAR V2X协作提供了多样的点云数据，涵盖10个类别，提供可靠的感知训练数据，具备精确对齐、一致注释，并且可用于直接使用。该数据集通过详细的质量统计分析，对当前常用的V2X方法进行了广泛基准测试，确保质量可靠且使用便捷。", "conclusion": "Mixed Signals数据集为感知训练提供了可靠的点云和边框注释，涵盖多个类别，具有精确的时间和视角一致性，可用于直接使用。该数据集通过详细的质量统计分析和广泛基准测试，验证了其高质量和可靠性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.16430", "html_url": "https://arxiv.org/abs/2503.16430", "title": "连续和离散令牌之间的桥梁以实现自回归视觉生成", "title_en": "Bridging Continuous and Discrete Tokens for Autoregressive Visual Generation", "authors": "Yuqing Wang,Zhijie Lin,Yao Teng,Yuanzhi Zhu,Shuhuai Ren,Jiashi Feng,Xihui Liu", "background": "自回归视觉生成模型通常依赖于分词器将图像压缩为能被顺序预测的令牌。但分词器的使用伴随着基本的难题：离散令牌虽然便于使用标准交叉熵损失进行建模，但会损失信息且分词器训练不稳定；而连续令牌虽然能更好地保留视觉细节，但需要复杂的分布建模，使生成流程复杂化。", "innovation": "本文提出了TokenBridge，通过保留连续令牌的强大表示能力同时保持离散令牌建模的简洁性来弥合这一差距。通过在训练后直接从连续表示中获得离散令牌来进行分词化解耦，同时引入了特征维度独立的量化策略以及轻量级的自回归预测机制，有效地建模了较大的令牌空间。研究表明，该方法在重建和生成质量上与连续方法相当，但使用标准的分类预测机制。", "conclusion": "这项工作表明，弥合离散和连续范式的桥梁能够充分发挥两者的优势，为高质量的视觉生成提供了一种简单的自回归建模方向。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.15389", "html_url": "https://arxiv.org/abs/2412.15389", "title": "通过最小标签实现最大肾小球分割的自我监督学习", "title_en": "Maximising Kidney Glomeruli Segmentation using Minimal Labels via Self-Supervision", "authors": "Zeeshan Nisar,Thomas Lampert", "background": "组织学检查是疾病诊断和预后的关键。准确的图像分割和重要区域的识别对开发自动化解决方案至关重要。然而，先进的深度学习分割方法，如UNet，需要大量的标签，这在多个染色的情况下既昂贵又耗时。为了减轻这一问题，开发了如UDA-GAN等多染色分割方法，这些方法只需标注一个（源）染色，减少了对标签的需求，但仍需要获取源染色标签，这对于某些情况可能仍然具有挑战性，且缺乏标签时分割模型会失效。研究展示了通过自我监督预训练，包括SimCLR、BYOL以及一种新的方法HR-CS-CO，即使在label数量减少95%的情况下，这些分割方法（UNet和UDA-GAN）的性能仍能保持。用仅5%的标签进行自我监督预训练，UNet和UDA-GAN与完全监督训练的性能下降分别为5.9%和6.2%。此外，这些发现还超过了训练分布，适用于公共基准数据集。", "innovation": "提出了一种新的自我监督预训练方法HR-CS-CO，通过仅使用很少的标签（例如，5%）即可显著提高多染色样本的组织学分割精度，同时该方法具有较强的一般化能力，能够应用于多样化的公开数据集。", "conclusion": "通过自我监督预训练，即使使用95%少的标签，UNet和UDA-GAN等深度学习分割方法在肾小球分割任务中也能保持良好的性能。使用仅5%的标签，与完全监督训练相比，性能下降幅度较小：UNet为5.9%，UDA-GAN为6.2%。此外，该方法具有良好的泛化能力，能够应用于不同类型的数据集。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.21430", "html_url": "https://arxiv.org/abs/2508.21430", "title": "Med-RewardBench: 评估医疗多模态大语言模型奖励模型和评判者的基准", "title_en": "Med-RewardBench: Benchmarking Reward Models and Judges for Medical Multimodal Large Language Models", "authors": "Meidan Ding,Jipeng Zhang,Wenxuan Wang,Cheng-Yi Li,Wei-Chieh Fang,Hsin-Yu Wu,Haiqin Zhong,Wenting Chen,Linlin Shen", "background": "多模态大语言模型（MLLMs）在医疗应用中具有巨大潜力，包括疾病诊断和临床决策。然而，这些任务需要高度准确、上下文敏感以及专业对齐的响应，这使得可靠的奖励模型和评判者至关重要。然而，目前在医疗领域的奖励模型（MRMs）和评判者的研究还较少，缺乏专门针对临床需求的基准测试。现有的基准测试大多关注一般MLLM的能力或评估模型作为求解器，忽略了诊断准确性和临床相关性等关键评价维度。", "innovation": "该论文提出了Med-RewardBench，这是第一个专门为医疗场景设计的用于评估MRMs和评判者的基准。Med-RewardBench包含跨13个器官系统和8个临床部门的多模态数据集，有1026个专家标注的案例，并使用严格的三步流程来确保六个临床关键维度的高质量评估数据。此外，该研究评估了32种最先进的MLLMs，包括开源、专有和医疗专用模型，揭示了与专家判断对齐的显著挑战。进一步开发了基础模型，显示出通过微调可以实现重大性能提升。", "conclusion": "研究通过对32种最先进的MLLMs的评估，揭示了与专家判断对齐的重大挑战，并且通过开发基础模型展示了通过微调可以实现重大性能提升。Med-RewardBench为医疗多模态大语言模型的奖励模型和评判者的评估提供了第一个专门的基准，有助于提高这些模型的临床应用质量。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.12868", "html_url": "https://arxiv.org/abs/2504.12868", "title": "利用多模态3D数据的个性化咬合定位牙垫计算机辅助设计", "title_en": "Computer-Aided Design of Personalized Occlusal Positioning Splints Using Multimodal 3D Data", "authors": "Agnieszka Anna Tomaka,Leszek Luchowski,Michał Tarnawski,Dariusz Pojda", "background": "数字技术在设计定制化医疗设备中起着关键作用，尤其是在口腔颌面系统紊乱的管理中，如牙托板的使用。本文介绍了一种基于计算机辅助的方法，用于设计和评估咬合定位牙托板。该研究的主要目的是在初步临床阶段展示所提方法的可行性和几何准确性。", "innovation": "引入了一种新的方法来生成牙托板，该方法能够重现治疗位置的咬合条件并通过虚拟压印解决表面冲突。该方法描述了使用牙齿工具和常见的牙科和实验室工作流程中的内窥镜装置获取变换矩阵的过程，并通过截面和表面偏差分析评估了设计和打印牙托板的几何准确性。方法支持可重复的、患者特定的牙托板制造，并为未来的验证研究提供了一个透明的基础，支持多模式图像配准和临床研究中的咬合差异量化。", "conclusion": "本文描述的方法支持可重复、患者特定的牙托板制造，并为未来的研究提供了一个透明的基础，支持多模式图像配准和咬合差异量化。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.02617", "html_url": "https://arxiv.org/abs/2504.02617", "title": "PicoPose: Progressive Pixel-to-Pixel Correspondence Learning for Novel Object Pose Estimation", "title_en": "PicoPose: Progressive Pixel-to-Pixel Correspondence Learning for Novel Object Pose Estimation", "authors": "Lihua Liu,Jiehong Lin,Zhenxin Liu,Kui Jia", "background": "基于RGB的新型物体姿态估计对于机器人应用的快速部署至关重要，但零样本泛化的挑战依然存在。PicoPose提出了一种针对这一任务的新型框架，采用三阶段像素到像素对应学习过程来解决该问题，逐步优化对应的物体姿态估算精度，提高PnP/RANSAC计算出的物体姿态的准确性。", "innovation": "PicoPose框架通过三阶段像素到像素对应学习过程解决了新型物体姿态估计中的零样本泛化挑战。首先匹配RGB观测和渲染物体模板的特征，并建立粗略对应关系；其次通过全局回归二维仿射变换平滑对应关系，包括平面旋转、缩放和二维平移；最后应用仿射变换到最佳匹配模板的特征图，并在局部区域内学习对应偏移以实现细粒度对应关系。该方法大幅提升了物体姿态估计的精度，并在BOP基准的七个核心数据集上实现了最先进性能，展现出对新型物体的出色泛化能力。", "conclusion": "PicoPose在新型物体姿态估计中取得了显著的效果，特别是在BOP基准的七个核心数据集上达到了最先进的性能，并且展示了出众的泛化能力。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.13073", "html_url": "https://arxiv.org/abs/2501.13073", "title": "CHaRM: 条件热力图回归方法在精确和快速牙科特征定位中的应用", "title_en": "CHaRM: Conditioned Heatmap Regression Methodology for Accurate and Fast Dental Landmark Localization", "authors": "José Rodríguez-Ortega(1 and 2),Francisco Pérez-Hernández(1),Siham Tabik(2) ((1) Nemotec, Madrid, Spain, (2) Department of Computer Science and Artificial Intelligence, University of Granada, Granada, Spain)", "background": "在正畸治疗中，识别三维牙科模型的解剖标志物是至关重要的。然而，手动放置这些标志物劳动密集型且需要专业知识。尽管已提出了基于机器学习的方法用于自动检测3D Intraoral Scans (IOS)的牙科特征，但这些方法中没有一种提供完全端到端的解决方案来避免昂贵的牙齿分割过程。本文分析的论文背景就是在自动牙齿特征检测方法上的不足，从而提出了一种新的解决方案。", "innovation": "本文提出了一种名为CHaRM (Conditioned Heatmap Regression Methodology) 的全端到端深度学习方法，用于在3D IOS中进行牙齿特征检测。CHaRM集成了四种组件：点云编码器、带有热力图回归头的解码器、牙齿存在分类头以及新颖的CHaR模块。CHaR模块利用牙齿存在信息来适应牙齿缺失的情况，提高了复杂牙科情况下的检测准确性。CHaRM直接在点云上操作，避免了牙齿分割，从而减少了复杂性和计算成本。", "conclusion": "我们使用了五种不同的点云学习骨干网络在IOSLandmarks-1k数据集上评估了CHaRM，该数据集包含了1,214个已标注的3D牙科模型。实验结果表明，使用PointMLP作为骨干的CHaRNet方法，达到了最佳的准确性和效率。与最先进的方法（TSMDL和ALIIOS）相比，CHaRNet在标准牙型模型上的平均欧几里得距离误差降低了至0.56毫米，并且但在所有牙型上的误差降低了到1.12毫米，同时在GPU上实现的推理速度提升了大约14.8倍。因此，这种端到端的方法简化了正畸工作流程，提高了3D IOS分析的精度，并使计算机辅助治疗规划得以高效实现。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.08481", "html_url": "https://arxiv.org/abs/2504.08481", "title": "一种固有可解释性的眼底图像疾病检测的卷积神经网络-变换器混合模型", "title_en": "A Hybrid Fully Convolutional CNN-Transformer Model for Inherently Interpretable Disease Detection from Retinal Fundus Images", "authors": "Kerol Djoumessi,Samuel Ofosu Mensah,Philipp Berens", "background": "在许多医学影像任务中，卷积神经网络（CNNs）能够高效地分层提取局部特征。近年来，视觉变换器（ViTs）因其使用自注意力机制来捕捉全局依赖关系而备受欢迎，但缺乏卷积所固有的空间局部化能力。因此，结合了CNNs和ViTs的混合模型被开发出来，以结合这两种架构的优点。然而，这些混合模型在解释性方面存在困难，这阻碍了它们在医学影像中的应用。本研究提出了一种为医学影像疾病检测设计的可解释性卷积神经网络-变换器混合模型。该模型能够在单一前向传递中生成与模型决策过程直接反映的、忠实且局部化的证据图，相比黑盒和可解释模型，该模型在两个医学检测任务中达到了最先进的预测性能，并提供了类别特定的稀疏证据图。本次研究的代码可以在指定链接处获取。", "innovation": "本研究提出了一种为医学影像疾病检测设计的可解释性卷积神经网络-变换器混合模型。相对于普遍使用的后验显著性方法，该方法可以生成忠实且局部化的证据图，直接反映模型的决策过程。此外，该模型在两个医学检测任务上达到了最先进的预测性能，并提供了一次前向传递中的类别特定稀疏证据图。", "conclusion": "本研究提出了一种为医学影像疾病检测设计的可解释性卷积神经网络-变换器混合模型。该模型在进行眼底图像疾病检测时，能够生成忠实且局部化的证据图，并且在两个医学检测任务中达到了最先进的预测性能。该模型能够提供一次性前向传递中的类别特定稀疏证据图，从而有助于理解模型的决策过程。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06680", "html_url": "https://arxiv.org/abs/2506.06680", "title": "IVF治疗中胚胎选择的深度学习模型解释", "title_en": "Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment", "authors": "Radha Kodali,Venkata Rao Dhulipalla,Venkata Siva Kishor Tatavarty,Madhavi Nadakuditi,Bharadwaj Thiruveedhula,Suryanarayana Gunnam,Durga Prasad Bavirisetti,Gogulamudi Pradeep Reddy", "background": "不孕对个人的生活质量产生显著影响，社会和心理层面均受到影响，预计未来将更为普遍。在经济发达地区，体外受精(IVF)是解决低生育率问题的主要技术之一。胚胎学家传统上通过评估囊胚图像来分级胚胎以进行移植，但该过程耗时且效率低下。囊胚图像对评估胚胎的存活率非常有价值。", "innovation": "本研究提出了一种可解释的人工智能(XAI)框架，用于分类胚胎，结合了卷积神经网络(CNN)和长短期记忆网络(LSTM)的结构，称为CNN-LSTM。通过深度学习，该模型在胚胎分类中实现了高精度同时保持了可解释性。", "conclusion": "使用CNN-LSTM框架的深度学习模型在IVF治疗中的胚胎选择上表现出高准确性和可解释性，有助于提高胚胎筛选效率和临床应用的透明度。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.02176", "html_url": "https://arxiv.org/abs/2505.02176", "title": "基于显著性指导的特征攻击检测中的指纹特征攻击检测", "title_en": "Saliency-Guided Training for Fingerprint Presentation Attack Detection", "authors": "Samuel Webster,Adam Czajka", "background": "显著性指导的训练通过指导模型学习图像的重要区域，已经在多种生物特征呈现攻击检测(PAD)任务中展示了泛化效果的提升。本文是首次将这项技术应用于指纹PAD领域。通过创建一个包含800个人工标注的指纹感知重要图的50参与者数据集，结合算法生成的“伪显著性”（包括特征点、图像质量、自编码器等基于的显著性图），评估其对指纹PAD准确性及泛化能力的影响。结果显示，显著性指导的训练在指纹PAD中尤其是在有限数据和大数据量情况下，能有效提升模型的泛化能力，并提供了一种在LivDet-2021基准测试中获得第一名的配置。研究表明显著性指导的训练能够增强模型的泛化能力，特别是在数据有限的情况下，并且在处理大规模数据集时仍有潜力。", "innovation": "首次将显著性指导的训练应用于指纹PAD；探索了显著性图及其对模型准确性和泛化的不同影响；提供了在LivDet-2021基准测试中获得第一名的配置。", "conclusion": "显著性指导的训练对于指纹PAD的有效性和泛化能力有显著提升，在有限和大规模数据环境下均表现优异。研究结果进一步证实了显著性指导的训练在处理各种生物识别任务中的潜力，并为后续研究提供了坚实的数据资源。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.04061", "html_url": "https://arxiv.org/abs/2507.04061", "title": "基于一致性与不变性学习的短视频 misinformation 检测普遍化学习", "title_en": "Consistent and Invariant Generalization Learning for Short-video Misinformation Detection", "authors": "Hanghui Guo,Weijie Shi,Mengze Li,Juncheng Li,Hao Chen,Yue Cui,Jiajie Xu,Jia Zhu,Jiawei Shen,Zhangze Chen,Sirui Han", "background": "短视频 misinformation 检测在多模态领域引起了广泛关注，旨在准确识别带有相应音频的视频格式中的 misinformation。尽管取得了显著进展，当前这些领域的模型（基于特定数据集训练）在面对未见过的数据集（目标域）时，往往会表现出不尽如人意的表现，这是因为存在数据域差异。因此，如何在短视频 misinformation 检测任务中实现有效且普遍化的域适应，是当前研究的一个重要方向", "innovation": "提出了一种新的 DOCTOR 模型，通过一致性和不变性学习来解决跨域泛化问题。该模型包含两个特征模块：(1) 交叉模态特征插值将多种模态映射到共享空间，并进行插值蒸馏以同步多模态学习；(2) 通过跨模态引导去噪增加噪声以保留多模态的核心特征，从而增强域不变特征。通过广泛的实验验证了 DOCTOR 模型的有效性", "conclusion": "提出的 DOCTOR 模型在短视频 misinformation 检测任务中展示了其有效性，通过一致性和不变性学习，能够有效地提高模型在不同域数据上的表现。该研究对于通用的跨域数据分析具有重要的参考价值"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03401", "html_url": "https://arxiv.org/abs/2505.03401", "title": "DDaTR: 动态差异感知时序残差网络在随访放射学报告生成中的应用", "title_en": "DDaTR: Dynamic Difference-aware Temporal Residual Network for Longitudinal Radiology Report Generation", "authors": "Shanshan Song,Hui Tang,Honglong Yang,Xiaomeng Li", "background": "现有放射学报告生成（Radiology Report Generation, RRG）技术已经能够从医学影像中自动化创建放射学报告，以提高报告过程的效率。纵向放射学报告生成（Longitudinal Radiology Report Generation, LRRG）扩展了RRG的能力，增加了对比当前和以往检查的功能，有助于跟踪临床发现随时间的变化。现有LRRG方法主要通过视觉预训练编码器提取前后影像的特征并进行拼接生成最终报告，但在特征提取过程中难以有效捕捉空间和时间上的关联，导致提取的特征未能充分反映检查间的差异，从而影响LRRG的效果。", "innovation": "本文开发了一种新颖的动态差异感知时序残差网络（Dynamic Difference-aware Temporal Residual Network, DDaTR），该网络在视觉编码器的每个阶段引入了两个模块以捕捉多层次的空间关联。Dynamic Feature Alignment Module (DFAM) 用于跨模态对齐先前的特征，以确保前期临床信息的完整性。Prompted by the enriched prior features, the dynamic difference-aware module (DDAM) 能够捕捉跨检查的有利差异信息。同时，DDaTR 使用动态残差网络单向传递历史信息，有效建模时间关联。", "conclusion": "在三个基准上的广泛实验表明，DDaTR 在 LRRG 任务上的性能优于现有方法，证明了其在 LRRG 和 RRG 任务中的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08340", "html_url": "https://arxiv.org/abs/2507.08340", "title": "通过狄拉克重平衡器和分布纠缠实现单域泛化在跨癌种多模态 prognosis 中", "title_en": "Single Domain Generalization for Multimodal Cross-Cancer Prognosis via Dirac Rebalancer and Distribution Entanglement", "authors": "Jia-Xuan Jiang,Jiashuai Liu,Hongtao Wu,Yifeng Wu,Zhong Wang,Qi Bi,Yefeng Zheng", "background": "深度学习在整合多模态数据进行生存预测方面展现了卓越的性能。然而，现有的多模态方法主要集中在单一癌种上，并且忽略了跨癌种泛化的挑战。尽管在临床实践中需要这种泛化能力的鲁棒性，现有方法往往不足。该论文指出，在跨癌种场景下，多模态预后模型的泛化通常比单模态模型更差。", "innovation": "提出了一个新的任务：跨癌种单一领域泛化在多模态预后中（Cross-Cancer Single Domain Generalization for Multimodal Prognosis），旨在评估单癌种训练的模型能否泛化到未见的癌种。为此，引入了两个插件模块：稀疏狄拉克信息重平衡器（SDIR）和癌症意识分布纠缠（CADE）。SDIR通过基于伯努利的稀疏化和狄拉克启发的稳定化减少强势特征的主导性，增强较弱模态的信号。CADE旨在合成目标领域的分布，融合局部形态学提示和全局基因表达在潜在空间中的融合。", "conclusion": "在四癌种基准测试上的实验结果表明，新方法的泛化性能显著优于现有方法，为实用的、鲁棒的跨癌种多模态预后奠定了基础。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.07313", "html_url": "https://arxiv.org/abs/2508.07313", "title": "DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding", "title_en": "DocR1: Evidence Page-Guided GRPO for Multi-Page Document Understanding", "authors": "Junyu Xiong,Yonghui Wang,Weichao Zhao,Chenyu Liu,Bing Yin,Wengang Zhou,Houqiang Li", "background": "对于多页文档的理解，对多模态大规模语言模型（MLLMs）构成了重大挑战，因为它需要精细的视觉理解和跨页的多跳推理。尽管先前工作已经探索了强化学习（RL）来增强MLLMs中的高级推理能力，但其在多页文档理解中的应用仍然还没有深入探索。", "innovation": "本文引入了DocR1，一种利用新型RL框架EviGRPO训练的MLLM。EviGRPO包含一个证据感知的奖励机制，促进粗细结合的推理策略，引导模型先检索相关页再生成答案。此训练范式使我们能够在有限监督下构建高质量的模型。为此，我们设计了一种两阶段注释流水线和递进式学习策略，并基于此构建了两个数据集：EviBench，包含4800个高质量训练样本，和ArxivFullQA，基于科学论文的评估基准，包含8600个问答对。", "conclusion": "在广泛基准上的广泛实验表明，DocR1在多页任务中达到了最先进的性能，同时在单页基准上保持了强劲的结果。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.06107", "html_url": "https://arxiv.org/abs/2508.06107", "title": "Mask & Match: 学习识别手写数学公式与自我监督注意力机制", "title_en": "Mask & Match: Learning to Recognize Handwritten Math with Self-Supervised Attention", "authors": "Shree Mitra,Ritabrata Chakraborty,Nilkanta Sahu", "background": "识别手写数学表达式（HMER）是一个具有挑战性的工作，原因是其固有的二维结构、符号比例的多样性以及符号之间复杂的空间关系。现有的方法通常需要大量的标注数据进行训练，成本高昂。", "innovation": "本文提出了一个自我监督学习（SSL）框架，用于消除标注数据的高成本需求。该框架首先通过结合全局对比损失和局部对比损失对图像编码器进行预训练，使模型能够学习整体和详细特征。本文的关键贡献是一个新的自我监督注意力网络，该网络通过逐级空间遮罩策略进行训练，学习具有语义意义的重点区域，如运算符、指数和嵌套数学表示法，且不需要任何监督。逐级遮罩教学计划鼓励网络逐步增强对缺失或遮挡视觉信息的鲁棒性，从而提高结构理解能力。", "conclusion": "我们完整的工作流程包括：（1）图像编码器的自我监督预训练；（2）自我监督注意力机制的训练；（3）带有Transformer解码器的监督微调生成LATEX序列。广泛实验证明，我们的方法在CROHME基准数据集上优于现有SSL和完全监督基准，验证了一步步的注意力机制在提升HMER性能中的有效性。我们的代码库可以在该链接找到。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.12420", "html_url": "https://arxiv.org/abs/2507.12420", "title": "InterpIoU：基于插值IoU优化的边界框回归新思考", "title_en": "InterpIoU: Rethinking Bounding Box Regression with Interpolation-Based IoU Optimization", "authors": "Haoyuan Liu,Hiroshi Watanabe", "background": "边界框回归（BBR）是对象检测的核心，其中回归损失对于准确的定位至关重要。现有的基于IoU的损失通常通过手动构建的几何惩罚来解决非重叠情况下的IoU不可微性问题，并提高边界框回归的性能。然而，这些惩罚对边界框的形状、大小和分布高度敏感，往往导致小物体的次优优化，并且可能导致边界框膨胀等不良行为。因此需要一种新的方法来解决这些问题。", "innovation": "提出了InterpIoU，一种新型的损失函数，它用插值框与目标之间的IoU来替代手动构建的几何惩罚。通过使用插值框来弥补预测与真实值之间的差距，InterpIoU在非重叠情况下提供了有意义的梯度，并且固有地避免了由错位惩罚引起的问题，比如边界框膨胀。实验结果表明，InterpIoU和基于其构建的双动态插值方法能够超过现有最佳的基于IoU的损失，特别是在小目标检测方面表现尤为突出，验证了其有效性。", "conclusion": "本文提出了InterpIoU，通过基于插值的IoU优化边界框回归。实验在COCO、VisDrone和PASCAL VOC数据集上证明了该方法的优越性，特别在小对象检测上有显著提升。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.17117", "html_url": "https://arxiv.org/abs/2508.17117", "title": "PlantVillageVQA：植物科学领域评估视觉语言模型的视觉问答数据集", "title_en": "PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science", "authors": "Syed Nazmus Sakib,Nafiul Haque,Mohammad Zabed Hossain,Shifat E. Arman", "background": "Larger visual question answering (VQA) datasets, especially those structured to support agricultural decision-making and analysis, are critical for advancing the development and evaluation of vision-language models. The widely used PlantVillage image corpus provided a foundation for expanding such datasets into specific domains like agriculture.", "innovation": "PlantVillageVQA通过从广泛使用的PlantVillage图像库中派生，构建了一个大规模的视觉问答数据集，其中包括193,609个高质量的问答对，覆盖了55,448张图像、14个作物种类和38种疾病状况。它创新性地组织问题级别，并通过手动制定并自动化生成的方式，明确了两个阶段的语言工程过程：首先是基于图像元数据的模板化问答合成，其次是多阶段的语言重建工程。此外，该数据集还经过了领域专家的迭代审查，最终使用三个最先进的模型进行了质量评估，保证了数据的科学准确性和相关性。", "conclusion": "本研究通过提供一个公开、标准化且专家验证的数据集，旨在提高植物疾病的诊断准确性，并促进农业领域的科学研究。PlantVillageVQA数据集将开放源代码，以促进更多研究者参与到模型评估和改进中来。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.15376", "html_url": "https://arxiv.org/abs/2504.15376", "title": "任何视频中理解相机运动的研究", "title_en": "Towards Understanding Camera Motions in Any Video", "authors": "Zhiqiu Lin,Siyuan Cen,Daniel Jiang,Jay Karhade,Hewei Wang,Chancharik Mitra,Tiffany Ling,Yuhan Huang,Sifan Liu,Mingyu Chen,Rushikesh Zawar,Xue Bai,Yilun Du,Chuang Gan,Deva Ramanan", "background": "当前，评估和改善相机运动理解需要特定的数据集和基准。但是现有的方法往往缺乏多样性和专家级质量控制，难以全面覆盖不同类型的相机运动和场景内容。因此，本文提出CameraBench数据集和基准，旨在评估和提升对相机运动的理解。", "innovation": "1. 通过专家多阶段严格质量控制流程，对约3000段互联网视频进行标注；\n2. 提出了一套与专业摄影师合作设计的相机运动元类别；\n3. 通过大规模的人类研究量化人类注释的性能，揭示了领域专业知识和基于教程的训练对准确性的重要性；\n4. 使用CameraBench评估结构重建（SfM）和视频语言模型（VLM），发现SfM模型难以捕捉依赖场景内容的语义元类别，而VLM模型难以捕捉需要精确轨迹估计的几何元类别；\n5. 使用CameraBench微调生成型VLM，使其能够结合语义和几何元类别的优点。", "conclusion": "本文的元类别、基准和教程将推动未来对任何视频中相机运动理解的努力，为实现最终目标奠定了基础。通过CameraBench，可以实现运动增强的标题生成、视频问答和视频文本检索等应用。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.17128", "html_url": "https://arxiv.org/abs/2508.17128", "title": "CE-RS-SBCIT一种用于脑肿瘤MRI分析的新型通道增强混合CNN变换器，具备剩余、空间和边界感知学习功能", "title_en": "CE-RS-SBCIT A Novel Channel Enhanced Hybrid CNN Transformer with Residual, Spatial, and Boundary-Aware Learning for Brain Tumor MRI Analysis", "authors": "Mirza Mumtaz Zahoor(1),Saddam Hussain Khan(2) ((1) Faculty of Computer Sciences, Ibadat International University, Islamabad, Pakistan (2) Artificial Intelligence Lab, Department of Computer Systems Engineering, University of Engineering and Applied Sciences (UEAS), Swat, Pakistan)", "background": "脑肿瘤依然是最具威胁的人类疾病之一。早期发现和准确分类对于有效的诊断和治疗计划至关重要。尽管基于深度学习的计算机辅助诊断(CADx)系统取得了显著进展，但传统的卷积神经网络(CNNs)和Transformer结构仍面临一些挑战，如高计算成本、对小对比度变化的敏感性、结构异质性和MRI数据中的纹理不一致性。", "innovation": "本文提出了一种新颖的混合框架，称为CE-RS-SBCIT，结合了基于残差和空间学习的CNN和基于Transformer驱动模块。该框架通过四大创新点利用局部精微和全局上下文线索：（i）平滑和边界基于的CNN-整合的Transformer（SBCIT）；（ii）专门设计的残差和空间学习CNN；（iii）通道增强（CE）策略；（iv）新的空间注意力机制。", "conclusion": "在来自Kaggle和Figshare的具有挑战性的MRI数据集上的广泛评估表明，所提出的方法在胶质瘤、脑膜瘤、垂体肿瘤和健康对照的分类上表现出优越的性能，分别实现了98.30%的准确率，98.08%的敏感性，98.25%的F1分数和98.43%的精确度。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19650", "html_url": "https://arxiv.org/abs/2508.19650", "title": "Video-LevelGauge：在大型视频语言模型中探究上下文位置偏见", "title_en": "Video-LevelGauge: Investigating Contextual Positional Bias in Large Video Language Models", "authors": "Hou Xia,Zheren Fu,Fangcan Ling,Jiajun Li,Yi Tu,Zhendong Mao,Yongdong Zhang", "background": "大型视频语言模型（LVLMs）在视频理解领域取得了显著进展，推动了相应的评估基准的发展。然而，现有基准通常评估整个视频序列的总体性能，忽略了如上下文位置偏见这样的关键但未充分探索的方面。本文介绍了Video-LevelGauge，一个专门用于系统评估LVLMs上下文位置偏见的基准测试。", "innovation": "提出了标准化探测器和定制上下文设置，以灵活控制上下文长度、探测器位置和上下文类型，模拟各种现实世界场景。此外，引入了一种综合分析方法，结合统计措施和形态模式识别来描述偏见。基准测试包括438个手动筛选的视频，生成了1,177个高质量的多项选择题和120个开放式问题，验证了它们在揭示位置偏见方面的有效性。评估了27个最先进的LVLMs，包括商业和开源模型。", "conclusion": "研究发现，许多领先的开源模型存在显著的位置偏见，通常显示头部或相邻内容的偏好。相比之下，商业模型如Gemini2.5-Pro在整个视频序列上表现出色且一致。进一步分析上下文长度、上下文变化和模型规模提供了减少偏见和指导模型改进的实际行动建议。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.20835", "html_url": "https://arxiv.org/abs/2508.20835", "title": "PointDGRWKV：将RWKV类似架构泛化到未见过的领域用于点云分类", "title_en": "PointDGRWKV: Generalizing RWKV-like Architecture to Unseen Domains for Point Cloud Classification", "authors": "Hao Yang,Qianyu Zhou,Haijia Sun,Xiangtai Li,Xuequan Lu,Lizhuang Ma,Shuicheng Yan", "background": "点云分类（PCC）模型的泛化性Recently explored Domain Generalization (DG)旨在提高PCC模型在未见过领域的泛化能力。现有方法基于卷积网络、Transformer或Mamba架构，但这些方法要么受制于有限的感受野，要么计算成本高，要么无法充分建模长程依赖性。", "innovation": "本文提出了一种基于RWKV架构的新框架PointDGRWKV，首次针对DG PCC应用RWKV。PointDGRWKV克服了RWKV在应用于未见过领域时遇到的两项主要挑战：通过引入自适应几何令牌移位来建模局部结构，增强空间建模；通过跨域关键特征分布对齐模块减少注意力漂移，提升跨域鲁棒性。", "conclusion": "在多个基准上的实验表明，PointDGRWKV在DG PCC上取得了最先进的性能。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.19762", "html_url": "https://arxiv.org/abs/2508.19762", "title": "BuzzSet v1.0: 在田间条件下进行传粉昆虫检测的数据集", "title_en": "BuzzSet v1.0: A Dataset for Pollinator Detection in Field Conditions", "authors": "Ahmed Emam,Mohamed Elbassiouny,Julius Miller,Patrick Donworth,Sabine Seidel,Ribana Roscher", "background": "传粉昆虫如蜜蜂对全球粮食生产和生态系统稳定性至关重要，但由于人类和环境因素的压力，其种群数量正在下降。在农业环境中实现大规模、自动化的监测仍然面临挑战，因为很难检测到小型、快速移动且常常与环境伪装的传粉昆虫。现有的传粉昆虫监测方法难以满足这些需求，特别是在田间条件下，因此需要一种新型的数据集和监测方法来解决这一问题。", "innovation": "该研究提出了BuzzSet v1.0，这是一个包含7,856张已人工验证高分辨率传粉昆虫图像的大规模数据集，图像在真实的田间条件下采集。数据集包含了超过8,000个注释实例，分为三大类：蜜蜂、熊蜂和未识别昆虫。该研究利用YOLOv12模型并经过人类验证进行注释，并通过优化的开放源代码工具对初稿进行了改进。所有图像均预处理成256 x 256像素的瓷砖，提高了小型传粉昆虫的检测能力。该数据集和相应的基础模型（使用RF-DETR变换器进行目标检测）对于推动在现实生态条件下进行小型物体检测的进展具有重要意义。", "conclusion": "BuzzSet数据集证明了在自然环境条件下进行传粉昆虫检测的难点和潜在价值，显示了在田间条件下检测这些常常与自然植被伪装的小昆虫给数据集带来的挑战。其未来工作将扩展到版本2.0，包含附加注释和测试进一步的检测策略，以推动这一领域的研究进展。BuzzSet数据集为生态计算机视觉研究设立了基准，同时突出了未来研究中需要解决的开放问题。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2402.12683", "html_url": "https://arxiv.org/abs/2402.12683", "title": "TorchCP: 一种用于共识预测的Python库", "title_en": "TorchCP: A Python Library for Conformal Prediction", "authors": "Jianguo Huang,Jianqing Song,Xuanning Zhou,Bingyi Jing,Hongxin Wei", "background": "共识预测（CP）是一种强大的统计框架，能够生成具有保证覆盖概率的预测区间或集合。尽管共识预测算法已经从传统的分类器和回归器发展到复杂的深度学习模型，如深度神经网络（DNNs）、图神经网络（GNNs）和大型语言模型（LLMs），但现有的共识预测库通常缺乏在大规模深度学习场景中的模型支持和扩展性。现有的共识预测算法库往往不适用于这些问题，特别是在需要处理大数据集的场景中。为了应对这些问题，作者提出了TorchCP，这是一个基于PyTorch的库，旨在将最先进的共识预测算法整合到深度学习技术中，包括基于DNN的分类器/回归器、GNN和LLMs。", "innovation": "TorchCP是一个专为深度学习设计的基于PyTorch的共识预测库，能够支持最新的共识预测算法，使得在DNN、GNN和LLMs等复杂模型上进行共识预测成为可能。TorchCP不仅实现了CP特定的训练算法、在线预测以及GPU加速批量处理，而且在大规模数据集上实现了高达90%的推理时间减少。此外，TorchCP的设计面向低耦合，提供了一套全面的高级方法，并完全支持GPU加速，使得研究人员和从业者能够增强对最新应用中的不确定性量化的能力，从而在各种深度学习应用中实现更准确的预测和决策.", "conclusion": "TorchCP极大地扩展了共识预测在深度学习领域的应用范围，解决了现有的共识预测算法库不适用于大规模深度学习场景的问题，并通过集成多种先进的共识预测方法和高效的GPU加速技术，使用户能够以更高的效率和更准确的方式进行不确定性量化。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18539", "html_url": "https://arxiv.org/abs/2508.18539", "title": "3D角色扮演游戏中的自适应视觉导航助手", "title_en": "Adaptive Visual Navigation Assistant in 3D RPGs", "authors": "Kaijie Xu,Clark Verbrugge", "background": "在复杂的3D游戏环境中，玩家依赖于视觉提示来识别地图转换点。准确识别这些转换点对于客户端自动制图至关重要，并为地图提示的效果评估提供了客观依据。这项工作旨在正式化探测可通行的空间转换点（STP）的任务，即连接两个子区域的连接点，并从中挑选出单一的关键路径上的主要空间转换点（MSTP），这是设计师有意向玩家指引的关键路径中的唯一一个转换点。研究基于单帧游戏画面，提出了一个新的研究焦点。研究提出了一种两阶段的深度学习管道，首先使用Faster R-CNN检测潜在的STP，然后使用轻量级的MSTP选择器结合局部和全局视觉特征进行排名。两阶段均受益于参数高效的适配器，并进一步引入了可选的检索增强融合步骤。主要目标是证明该问题的可行性并设定基准性能指标。通过在五款动作角色扮演游戏中的自定义构建且多元的数据集上验证本方法，实验显示一个关键权衡：虽然全网络微调在有足够数据的情况下能产生更优的STP检测效果，但仅参数适配的转移学习在数据稀少场景下效果显著更鲁棒和有效，尤其对于MSTP选择任务而言。", "innovation": "提出了一种两阶段的深度学习管道来探测3D RPG游戏中可通行的空间转换点，并基于单帧游戏画面进行检测和排序。关键技术包括使用Faster R-CNN进行STP检测、轻量级MSTP选择器结合局部和全局视觉特征进行排名、参数高效的适配器使用，及引入检索增强融合步骤。研究提出了一个基准处理管道和数据集，并提供了一些初始的高效模型适配洞察，旨在为未来基于AI的导航辅助和数据驱动的关卡设计工具做出贡献。", "conclusion": "通过定义一个新的问题、提供基准管道和数据集以及提供初始的高效模型适配洞察，研究人员旨在为未来AI驱动的导航辅助工具和数据驱动的关卡设计工具的进步做出贡献。研究发现，全网络微调在数据充足的情况下表现优异，但在数据稀缺的情景下，仅参数适配的转移学习更为鲁棒和有效，特别是在MSTP选择任务中。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.04619", "html_url": "https://arxiv.org/abs/2505.04619", "title": "视觉强化学习中用于机器人操作的视角合并与解耦合", "title_en": "Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation", "authors": "Abdulaziz Almuzairee,Rohan Patil,Dwait Bhatt,Henrik I. Christensen", "background": "视觉技术广泛应用于操作任务，尤其是通过视觉伺服技术。由于世界的三维特性，使用多视角并且把这些视角合并起来能更好地表示Q学习，并因而训练出样本更高效的策略。然而，这些多视图策略对故障摄像机敏感，并且部署时会带来负担。", "innovation": "提出了一个合并和解耦合（MAD）算法，该算法能有效合并视角以增加样本效率，同时通过将多视角特征输入与单视角特征增强来解耦视角。这产生了鲁棒的策略，并允许轻量级部署。该方法在Meta-World和ManiSkill3上展示了其效率和鲁棒性。", "conclusion": "通过MAD算法合并和解耦合多视角，该方法显著提高了样本效率并增强了鲁棒性，同时减轻了部署时的负担。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.03729", "html_url": "https://arxiv.org/abs/2505.03729", "title": "视觉模仿实现情境中的人形机器人控制", "title_en": "Visual Imitation Enables Contextual Humanoid Control", "authors": "Arthur Allshire,Hongsuk Choi,Junyi Zhang,David McAllister,Anthony Zhang,Chung Min Kim,Trevor Darrell,Pieter Abbeel,Jitendra Malik,Angjoo Kanazawa", "background": "如何让类人机器人学习攀爬楼梯和坐在椅子上，并利用周围环境？最直接的方式是让机器人模仿人类动作。本文介绍了VIDEOMIMIC管道，该管道可以从日常视频中提取人类和环境的实时信息，生成类人机器人进行相应技能的全身控制策略。该方法已经在实际类人机器人上进行了验证，展示了在楼梯上上下下的稳健重复控制、从椅子和长凳上坐下和站立等动态全身技能。这些技能均可以通过一条策略实现，并根据环境和全局根命令进行条件化。VIDEOMIMIC提供了一种可扩展的方法，使类人机器人能够在多种现实世界环境中进行操作。", "innovation": "VIDEOMIMIC提供了一种新颖的从现实世界视频中提取人类和环境信息，并生成适用于类人机器人的全身控制策略的方法，使得类人机器人能够灵活地在不同的现实世界环境中操作。这一方法简化了类人机器人学习复杂人体活动的过程，并且可以通过一条策略实现多种情境下的控制任务。", "conclusion": "VIDEOMIMIC为类人机器人在不同现实世界环境中的操作提供了一种可扩展的解决方案，通过一个单一政策实现了从楼梯上下到坐下站立等复杂技能的控制。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19297", "html_url": "https://arxiv.org/abs/2506.19297", "title": "基于显式残差的适合人类和机器的可扩展图像编码", "title_en": "Explicit Residual-Based Scalable Image Coding for Humans and Machines", "authors": "Yui Tatsumi,Ziyue Zeng,Hiroshi Watanabe", "background": "可扩展图像压缩是一种技术，能够在不同要求下逐级重建多个图像版本。近年来，随着图像被越来越多地用于机器识别模型，而不是仅限于人类消费，人们越来越关注既适合机器和人类视觉的可扩展图像压缩方法。现有的许多模型通过神经网络编解码器来处理此问题，并通过精心设计的损失函数取得了显著进步。然而，这些模型可能过度依赖学习能力，并且其架构设计不一定充分考虑。", "innovation": "本文通过引入显式残差压缩机制来提高ICMH框架的编码效率和可解释性，这种机制常用于分辨率可扩展编码方法如JPEG2000。具体地，本文提出了两种互补方法：基于特征残差的可扩展编码（FR-ICMH）和基于像素残差的可扩展编码（PR-ICMH）。这些方法适用于各种机器视觉任务，并提供平衡编码器复杂度和压缩性能的灵活性，使模型能够适应多种应用需求。", "conclusion": "实验结果表明了本文提出的方法的有效性，特别是PR-ICMH相对于先前工作在BD-率方面实现了高达29.57%的节省。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.02512", "html_url": "https://arxiv.org/abs/2508.02512", "title": "QuaDreamer： quadruped机器人的可控全景视频生成", "title_en": "QuaDreamer: Controllable Panoramic Video Generation for Quadruped Robots", "authors": "Sheng Wu,Fei Teng,Hao Shi,Qi Jiang,Kai Luo,Kaiwei Wang,Kailun Yang", "background": "全景相机能够捕捉到全面的360度环境数据，适用于四足机器人的周围感知和与复杂环境的交互。然而，由于固有的运动约束和复杂的传感器校准挑战导致高质量全景训练数据稀缺，这从根本上限制了为这些载体平台量身定制的鲁棒感知系统的开发。", "innovation": "本文提出了QuaDreamer——首个专门针对四足机器人的全景数据生成引擎。QuaDreamer通过模仿四足机器人的运动模式来生成高度可控、真实的全景视频，提供下游任务的数据来源。具体来说，引入了垂直抖动编码（VJE）来有效捕捉四足运动期间表现出的独特垂直振动特征。还提出了场景对象控制器（SOC）来管理对象运动并通过注意力机制增强背景抖动控制。此外，提出了一种全景增强器（PE），这是一种双流架构，结合频率-纹理细化和空间-结构修正，以解决宽视场视频生成中的全景失真问题。生成的视频序列可作为四足机器人全景视觉感知模型的训练数据，增强360度场景中的多目标跟踪性能。", "conclusion": "研究表明，通过QuaDreamer生成的视频序列可以作为四足机器人全景视觉感知模型的训练数据，从而提高360度场景中的多目标跟踪性能。源代码和模型权重将在指定的网址公开。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject: 对Web代理的提示注入攻击", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "现有的多模态大型语言模型（MLLM）基于网页代理通过生成基于网页截图的动作来与网页环境互动。这项工作利用了这一特性，提出了一种名为WebInject的新颖攻击方法，通过将干扰添加到渲染网页的原始像素值上来操纵网页环境，从而诱导网页代理执行攻击者指定的动作。这一挑战在于原始像素值与截图之间的映射是非可微分的，难以通过反向传播梯度来优化干扰。为克服这一问题，研究设计了一种神经网络来近似映射关系，并采用投影梯度下降法来求解优化问题。", "innovation": "WebInject攻击方法利用多模态大型语言模型的特性，在渲染网页的原始像素值上添加干扰，通过神经网络近似映射关系，利用投影梯度下降法解决优化问题，有效诱导网页代理执行攻击者指定的操作。这种方法不同于传统的基于语法或关键词替换的攻击手段，具有更好的效果和适应性。", "conclusion": "在多个数据集上的广泛评估表明，WebInject攻击方法在有效性和性能上均显著优于基线方法。这表明，在多模态大语言模型中存在新的安全威胁，需要进一步研究以提高其安全性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.07134", "html_url": "https://arxiv.org/abs/2504.07134", "title": "借助注意机制推进CAD：基于变换器的边界表示学习", "title_en": "Bringing Attention to CAD: Boundary Representation Learning via Transformer", "authors": "Qiang Zou,Lizhen Zhu", "background": "最近，由Transformer网络驱动的生成人工智能取得了显著的成功，尤其是在自然语言处理、计算机视觉和图形领域。然而，在计算机辅助设计（CAD）领域，特别是处理边界表示（B-rep）模型方面，Transformer的应用仍然鲜有探索。", "innovation": "本文提出了一种新的方法，即边界表示变换器（BRT），将Transformer应用到B-rep学习中。BRT提出了一种连续的几何嵌入方法，将B-rep表面（修剪和未修剪）编码为Bezier三角形，保持了其形态和连续性而无需离散化。此外，BRT采用一种拓扑感知嵌入方法，将这些几何嵌入组织成适用于Transformer的离散令牌序列，捕捉B-rep模型中的几何和拓扑特征。这使得Transformer的注意机制能够有效学习B-rep模型中边界元素的形状模式和上下文语义。", "conclusion": "广泛的实验表明，BRT在部件分类和特征识别任务中达到了最先进的性能。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.08906", "html_url": "https://arxiv.org/abs/2409.08906", "title": "高斯是您需要的全部：通过高斯分布的后验采样解决逆问题的统一框架", "title_en": "Gaussian is All You Need: A Unified Framework for Solving Inverse Problems via Diffusion Posterior Sampling", "authors": "Nebiyou Yismaw,Ulugbek S. Kamilov,M. Salman Asif", "background": "扩散模型能够通过建模复杂的数据分布生成多种高质量的图像。训练后的扩散模型也可作为解决逆问题的有效先验。现有的基于扩散的方法大多通过扩散逆向采样过程中的似然函数近似来整合数据一致性步骤，但这些近似往往是不充分的，且效率低下。", "innovation": "提出了一个统一的似然近似方法，包含协方差校正项，以提升性能并避免通过扩散模型传播梯度。通过将校正项整合到逆向扩散采样过程中，该方法在选定的分布上更能趋向真实的数据后验，并在实际自然图像数据集上提高了性能。此外，提出了一种高效地分解和反解似然函数协方差矩阵的方法，以应对多种逆问题。", "conclusion": "广泛的实验表明，该方法在多个现有方法中效果更佳。相关代码可以在指定链接获取。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.07331", "html_url": "https://arxiv.org/abs/2507.07331", "title": "mmFlux: 使用商品级 mmWave MIMO 雷达进行人群流动分析", "title_en": "mmFlux: Crowd Flow Analytics with Commodity mmWave MIMO Radar", "authors": "Anurag Pallaprolu,Winston Hurst,Yasamin Mostofi", "background": "本文介绍了一种新型框架 mmFlux，用于利用毫米波雷达提取人群运动的基本模式并推断人群语义，通过结合视觉领域的光流估计概念和新颖的统计与形态噪声滤波方法，生成高保真的 mmWave 流场。这种方法采用具有人群流动信息的紧凑二维向量表示，并将这些流场转化为有向几何图。利用这些图，可以识别主要的流动方向、人群分叉或合并点，并通过分析局部雅可比矩阵和计算相应的旋度和散度来提取关键人群语义，适用于结构化和非结构化人群。", "innovation": "1. 结合视觉领域的光流估计概念，提出了一种综合的信号处理管道，集成独特的统计和形态噪声滤波方法。\n2. 将 mmWave 流场转化为有向几何图，并在图中使用边缘和顶点来表示主要流动、人群分叉或合并以及流动分布的量化分析。\n3. 通过分析局部雅可比矩阵和相应的旋度和散度，成功提取出结构化和非结构化人群的关键语义信息，如急转弯、流向变化的边界、人群分散和聚集等现象，提高分析精度和适用性。\n4. 采用商业级毫米波雷达进行实验，验证了该框架在复杂人群模式下的高保真图形重构能力，展示了强大的空间对齐性和精确的流动分支比定量表征。", "conclusion": "本文证明了 mmFlux 强大的潜力，适用于各种人群分析应用。通过高保真图形重构和精确的流动分支比定量表征，展示了其在人群流动分析中的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.14177", "html_url": "https://arxiv.org/abs/2505.14177", "title": "从朗文扩散稳定性到处理非对数凸采样近端MCMC的收敛性", "title_en": "From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling", "authors": "Marien Renaud,Valentin De Bortoli,Arthur Leclaire,Nicolas Papadakis", "background": "论文背景是解决来自非凸势能的抽样分布问题。在许多应用场景中，比如成像逆问题中，势能往往是非凸和非平滑的。在这些情况下，常用的算法是近端随机梯度 Langevin 算法（Proximal Stochastic Gradient Langevin Algorithm, PSGLA）。PSGLA 结合了前进-后退优化算法和Unadjusted Langevin Algorithm步骤。然而，尽管PSGLA在处理非凸势能方面表现良好，但目前没有关于其收敛性的严格证明。", "innovation": "本文的主要贡献是证明了距离无穷远处具有强凸性的非凸势能下.unadjusted Langevin算法 (ULA) 在差异性近似中的稳定性。基于Moreau 包络的属性，首次证明了PSGLA在非凸势能下收敛。此外，通过合成数据和成像逆问题的实验验证了该方法的有效性，实验结果表明PSGLA在后验采样中具有更快的收敛速率，并保留了恢复性质。", "conclusion": "本文通过证明了PSGLA对非凸势能的收敛性，解决了该领域的一个重要问题。实验结果验证了理论结论，并展示了PSGLA相较于标准的随机梯度Langevin算法在后验采样中的优越性。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.12263", "html_url": "https://arxiv.org/abs/2508.12263", "title": "区域级别上下文感知的多模态理解", "title_en": "Region-Level Context-Aware Multimodal Understanding", "authors": "Hongliang Wei,Xianqi Zhang,Xingtao Wang,Xiaopeng Fan,Debin Zhao", "background": "尽管在多模态大型语言模型（MLLMs）研究方面取得了显著进展，现有研究主要集中在通用视觉理解上，而忽略了结合与对象相关的文本上下文进行更具上下文感知的多模态理解的能力，这一能力被定义为区域级别上下文感知多模态理解（RCMU）。", "innovation": "该研究首先定义了RCMU任务，要求模型通过整合图像内容和区域或对象的文本信息来响应用户指令。为此，提出了区域级别上下文感知视觉指令调优（RCVIT），这是一种将对象信息纳入模型输入的方法，使模型能够利用边界框坐标有效地将对象的视觉内容与其文本信息关联起来。此外，还引入了用于评估RCMU和多模态个性化理解任务性能的RC&PBench基准，并提出了一个无参考的评估指标来全面细致地评估区域级别的上下文感知图像描述。", "conclusion": "通过在Qwen2-VL模型上进行RCVIT训练，获得了RC-Qwen2-VL模型，该模型在多个RCMU任务上表现出色，并成功应用于多模态读写代理和个性化对话。该研究的数据、模型和基准可以从这个链接下载：[提供链接的URL]。"}
{"llm_update_time": "20250901", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.18860", "html_url": "https://arxiv.org/abs/2508.18860", "title": "C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning", "title_en": "C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning", "authors": "Wei Li,Hangjie Yuan,Zixiang Zhao,Yifan Zhu,Aojun Lu,Tao Feng,Yanan Sun", "background": "在持续学习（CL）中，平衡对新任务的敏感性和对过去知识的稳定性至关重要。最近，尖锐度感知最小化在迁移学习中证明了其有效性，并已在持续学习中采用以提高记忆保留和学习效率。然而，仅依赖零阶尖锐度可能导致在某些情况下优先选择尖锐最小值而忽略平坦最小值，这可能会导致更不稳健且潜在的次优解决方案。", "innovation": "本文提出了C-Flat，一种促进更适合持续学习的平坦损失景观的方法。C-Flat具有即插即用兼容性，能够通过最小的代码修改轻松集成。此外，还提出了一个通用框架，将C-Flat整合到所有主要的持续学习范式中，并与损失最小值优化器和基于平坦最小值的持续学习方法进行了全面比较。结果表明，C-Flat在广泛的应用场景中均表现出改进的性能。此外，还提出了C-Flat++，一种利用选择性平坦最小值驱动更新以大幅降低C-Flat更新成本的有效而高效的框架。", "conclusion": "通过对多种持续学习方法、数据集和场景的大量实验，我们的研究结果证明了本文提出的方法的有效性和效率。相关代码可在提供的链接处获得。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21103", "html_url": "https://arxiv.org/abs/2508.21103", "title": "基于混合深度学习的严肃游戏中SAM评分空间-时间EEG情绪识别", "title_en": "Spatiotemporal EEG-Based Emotion Recognition Using SAM Ratings from Serious Games with Hybrid Deep Learning", "authors": "Abdul Rehman,Ilona Heldal,Jerry Chun-Wei Lin", "background": "近年来，基于EEG的情绪识别取得了显著的成果，使用了深度学习和经典机器学习方法。然而，大多数现有研究仅聚焦于二分类情感或个体特定分类，这限制了其在实际情感计算系统中的泛化能力和部署。", "innovation": "本文提出了一种基于GAMEEMO数据集的统一的多粒度EEG情感分类框架。该框架通过时空窗分割、混合统计和频域特征提取以及z-score归一化来预处理原始EEG信号，以提取鲁棒性好的特征向量。此外，该框架采用三种互补的情感标签表示方式：二分类极性、多分类情感和细粒度多标签表示。论文还测试了多种模型，包括随机森林、XGBoost、SVM以及基于LSTM、LSTM-GRU和CNN-LSTM的深度神经网路，其中LSTM-GRU模型表现最好。", "conclusion": "LSTM-GRU模型在二分类情感识别任务中的F1得分达到0.932，在多分类和多标签情感识别中分别达到94.5%和90.6%，表明其在情感识别任务中的优越性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21101", "html_url": "https://arxiv.org/abs/2508.21101", "title": "超越预测：强化学习在医疗人工智能中的关键突破", "title_en": "Beyond Prediction: Reinforcement Learning as the Defining Leap in Healthcare AI", "authors": "Dilruk Perera,Gousia Habib,Qianyi Xu,Daniel J. Tan,Kai He,Erik Cambria,Mengling Feng", "background": "强化学习（RL）标志着人工智能在医疗领域的应用产生了根本性的转变。传统的模型依赖于固定关联，在面对长期目标时显得过于静态。与之相比，RL通过试错、反馈和长期奖励优化来主动做出干预决策。从信息融合的角度来看，医疗领域的RL通常会整合来自生命体征、实验室检测、临床笔记、成像和设备遥测等多源信号，并通过时间序列和决策级别机制进行融合。这些系统可以在集中的、联邦的或边缘的架构中运行，以便满足实时的临床约束条件，并自然涵盖数据、特征和决策融合的不同水平。", "innovation": "本文通过分类RL技术，包括基于模型和无模型方法、离线和批量约束方法以及新的奖励规定和不确定性校准策略，结合医疗特定约束对RL技术进行了综合分析。此外，文章还全面分析了RL在重症监护、慢性病管理、精神健康、诊断和机器人辅助等方面的应用，指出了应用趋势、存在的差距和转化瓶颈。不同于之前的综述，本文深入分析了RL在伦理、部署和奖励设计方面所面临的挑战，并总结出了确保安全、与人类目标相一致的学习策略所需要的教训。该论文不仅提供了一个技术路线图，而且对RL如何作为临床智能推动医疗AI的发展进行了批判性反思。", "conclusion": "本文强调了RL如何从预测机器转变为作为临床智能，在医疗AI中的角色转变，并提供了未来研究的方向。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21104", "html_url": "https://arxiv.org/abs/2508.21104", "title": "PVPO: 基于预估值的策略优化方法在代理推理中的应用", "title_en": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic Reasoning", "authors": "Wenfeng Feng,Penghong Zhao,Guochao Jiang,Chuzhan Hao,Yuewei Zhang,Hao Wang", "background": "批评免费的强化学习方法，尤其是群策略，因其在复杂任务中的效能在研究中受到了广泛关注。然而，这些方法需要在策略内部多次采样和比较以估计优势，这可能导致策略陷入局部最优，并增加计算成本。", "innovation": "本文提出了PVPO（Pre-Estimated Value-Based Policy Optimization）方法，通过引入优势参考锚点和数据预采样来改进强化学习。具体而言，利用参考模型提前进行遍历，并使用计算出的回报分值作为参考锚点，有效纠正了内部组比较引入的累积偏差，并显著减少了对遍历次数的依赖。此外，参考模型可以在数据预采样期间评估样本难度，从而实现高效的数据选择，提高训练效率。", "conclusion": "在两个领域九个数据集上的实验表明，PVPO实现顶级性能。该方法不仅展示了多任务上的稳健泛化能力，还能够在不同规模的模型上实现可扩展的性能。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21146", "html_url": "https://arxiv.org/abs/2508.21146", "title": "通过局部似然攻击审计合成数据发布中的隐私泄露", "title_en": "Privacy Auditing Synthetic Data Release through Local Likelihood Attacks", "authors": "Joshua Ward,Chi-Hua Wang,Guang Cheng", "background": "合成数据的隐私泄露审计是一个重要的但尚未解决的问题。现有的大多数隐私审计框架依赖于基于启发式方法和不合理的假设攻击生成模型的失败模式，这些方法在描述和检测通过合成数据发布训练数据的隐私暴露能力方面有限。此外，现有的方法在不同的数据集、模型架构和攻击参数方面的全面基准测试中表现出有限的能力。", "innovation": "本文提出了一种名为生成似然比攻击（Gen-LRA）的创新方法，这是一种基于测试观察对替代模型在合成数据上局部似然比估计中的影响进行评估的高效无盒MIA。Gen-LRA无需对模型的知识或访问进行假设，通过局部似然比的概念解决了这个问题。在全面的基准测试中，该方法在多种性能指标上均优于其他MIA方法", "conclusion": "Gen-LRA在多个生成模型上的一致表现及其对合成数据隐私审计的有效性证明了其作为隐私审计工具的价值，同时也强调了生成模型过拟合在实际应用中的重大隐私风险。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21109", "html_url": "https://arxiv.org/abs/2508.21109", "title": "一种增强的可解释双向长短时记忆神经网络用于联合48小时温度、辐照度和相对湿度预测", "title_en": "An Explainable, Attention-Enhanced, Bidirectional Long Short-Term Memory Neural Network for Joint 48-Hour Forecasting of Temperature, Irradiance, and Relative Humidity", "authors": "Georgios Vamvouras,Konstantinos Braimakis,Christos Tzivanidis", "background": "本文探讨了一种基于深学习（DL）框架的气象预报方法，用于支持智能HVAC系统中的模型预测控制（MPC）。通过对2019年至2022年的历史气象数据进行训练，并使用2023年的数据进行泛化评估，该模型能够联合预测48小时内温度、辐照度和相对湿度三个变量。研究成果在此领域中取得了一定的研究背景和应用基础。", "innovation": "该论文创新提出了一种集成多变量预测、基于注意力的DL模型和可解释性的方法。具体创新点包括：1）采用堆叠的双向长短期记忆（BiLSTM）网络，捕捉时间序列和跨特征间的依赖关系；2）利用注意力机制，量化特征贡献并揭示时间模式，提高可解释性；3）相比现有的数值天气预报和机器学习基准，该方法在温度、辐照度和湿度预测中表现优异，误差分别为1.3°C、31 W/m²和6.7百分点。其创新之处在于结合了多种技术来提升天气预测的准确性和透明度，为建筑节能控制提供精准的短期气象预报依据。", "conclusion": "通过展示模型的准确性和透明性，本文的工作突显了该框架在通过可靠的短期气象预报来实现能源高效建筑控制的潜力。该研究推动了数据驱动的天气预测技术的发展，并为智能楼宇系统的优化提供了新的可能性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21181", "html_url": "https://arxiv.org/abs/2508.21181", "title": "FUTURE: 弹性树集的灵活删除", "title_en": "FUTURE: Flexible Unlearning for Tree Ensemble", "authors": "Ziheng Chen,Jin Huang,Jiali Cheng,Yuchan Guo,Mengjie Wang,Lalitesh Morishetti,Kaushiki Nag,Hadi Amiri", "background": "树集成由于其在分类任务中的卓越效果而被广泛认可，并在生物informatics、金融和医疗诊断等多个领域取得了最先进的性能。随着对数据隐私和被遗忘权利的重视，已经提出了一些用于使树集成忘记敏感信息的不学习算法。然而，现有的方法通常是针对特定模型设计的，依赖于树木的离散结构，这使得它们难以适应复杂结构且对于大规模数据集效率低下。", "innovation": "我们提出了一个名为FUTURE的新颖的树集成不学习算法。具体来说，我们将忘记样本的问题作为基于梯度的优化任务。为了解决树集成非可微分的问题，我们在优化框架中采用了概率模型逼近。这使得在有效且高效的方式下进行端到端的不学习成为可能。实验结果表明，FUTURE可以在实际数据集上实现显著且成功的不学习效果。", "conclusion": "通过FUTURE，树集成可以在保持分类性能的同时安全地删除敏感信息，为数据隐私保护提供了新方法，尤其适用于大规模数据集。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21172", "html_url": "https://arxiv.org/abs/2508.21172", "title": "深残差回声状态网络：探索未训练递归神经网络中的残差正交连接", "title_en": "Deep Residual Echo State Networks: exploring residual orthogonal connections in untrained Recurrent Neural Networks", "authors": "Matteo Pinna,Andrea Ceni,Claudio Gallicchio", "background": "回声状态网络（ESNs）是Reservoir Computing（RC）框架中的特定类型未训练递归神经网络（RNNs），因其快速和高效的训练而受到青睐。然而，传统ESNs在处理长期信息处理方面往往表现不足。", "innovation": "本文提出了一种基于时间残差连接的深未训练递归神经网络，称为深残差回声状态网络（DeepResESNs）。通过利用未训练的递归层的层次结构，显著提升了记忆容量和长期时间建模。研究了不同类型的正交时间残差连接对网络动力学的影响，并提供了确保DeepResESN中稳定动力学的必要和充分条件。", "conclusion": "我们通过各种时间序列任务的实验展示了所提出方法的优势，优于传统的浅层和深层RC。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21106", "html_url": "https://arxiv.org/abs/2508.21106", "title": "动态低秩近似全矩阵预条件子以训练广义线性模型", "title_en": "Dynamic Low-rank Approximation of Full-Matrix Preconditioner for Training Generalized Linear Models", "authors": "Tatyana Matveeva,Aleksandr Katrutsa,Evgeny Frolov", "background": "适应梯度方法（如Adagrad及其变种）在大规模优化中广泛应用，但它们利用对角预条件矩阵的能力有限，无法捕捉参数间的相关性。全矩阵自适应方法通过近似导出精确海森矩阵可以建模这些相关性并允许更快的收敛，但这些方法的计算和内存成本对于大规模模型往往是不可接受的。为了克服这一限制，本文提出AdaGram，一种能够高效实施全矩阵自适应梯度更新的优化器。通过使用快速对称因式分解来在每次迭代中计算预条件化更新方向，以及使用矩阵积分方法维护预条件子在其优化轨迹中的低秩结构，AdaGram降低了内存和计算开销。实验结果表明，AdaGram在使用秩五及更小秩近似时，能够以更快的速度收敛或与对角自适应优化器达到相同的性能，这展示了AdaGram作为大型模型自适应优化可扩展解决方案的潜力。", "innovation": "本文提出了AdaGram，一种为了训练广义线性模型而设计的优化器，能够高效实施全矩阵自适应梯度更新。通过使用快速对称因式分解来计算预条件化更新方向，并利用矩阵积分方法维持预条件子的低秩结构，AdaGram在降低内存和计算开销方面实现了创新。此外，AdaGram展示了在使用较低秩近似时仍具有高效性能的潜力。", "conclusion": "数值实验表明，使用秩五及更小的秩近似时，AdaGram在标准机器学习任务中能够更快地收敛或与对角自适应优化器达到相同的性能水平。这表明AdaGram具备成为大规模模型自适应优化的可扩展解决方案的潜力。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21186", "html_url": "https://arxiv.org/abs/2508.21186", "title": "下个词预测中的流形轨迹：从复制器动力学到softmax平衡", "title_en": "Manifold Trajectories in Next-Token Prediction: From Replicator Dynamics to Softmax Equilibrium", "authors": "Christopher R. Lee-Jenkins", "background": "通常认为，大规模语言模型中的解码过程涉及对标记打分并使用softmax进行归一化。该研究从约束变分原理的角度，详细阐述了这一过程，并将离散、归一化保持的上升视为经典的乘法权重（熵镜）更新，其连续时间极限是复制器流。该研究旨在证明，在固定上下文和温度的情况下，下一个标记的分布会沿着流形的平滑轨迹在概率单纯形内移动，并最终收敛到softmax平衡。", "innovation": "该研究通过约束变分原理来解释解码过程，提出了分步连续轨迹，并证明了温度作为时间的精确缩放因子，以及top-k和nucleus采样的限制对流的影响具有相等的保证。此外，还提出了路径依赖评分调整的控制账户及其与幻觉风格行为的联系。", "conclusion": "该研究证实了输出分布层面的常见“流形遍历”直觉，得出了精确的实际应用结果：温度作为时间沿同一流形轨迹的精确缩放，top-k和nucleus采样限制流的移动但仍有相同的保证。此外，还讨论了路径依赖评分调整及其与幻觉行为的关系，但没有讨论训练动力学或内部表示，这些将在未来的工作中探讨。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21081", "html_url": "https://arxiv.org/abs/2508.21081", "title": "利用特征提取和聚类标准化SWIFT报文对手方", "title_en": "Normalisation of SWIFT Message Counterparties with Feature Extraction and Clustering", "authors": "Thanasis Schoinas,Benjamin Guinard,Diba Esbati,Richard Chalk", "background": "短文本聚类在文本分析领域是一个已知的应用场景。当文本内容和结构属于自然语言时，如微博帖子或即时消息，可以使用自然语言技术进行处理，前提是文本长度足够，以允许使用（预）训练模型提取有意义的信息，如词性或主题注释。然而，自然语言模型不适用于对银行支付消息系统中的交易对手方进行聚类。这些对手方通常是手动输入的标签，表现为物理或法律实体的详细信息，缺乏完整的句子结构，并且包含手工输入引入的所有变体和噪音。这成为分析师或反欺诈专业人士在增强对付款流程发起方和受益方实体的认识以及跟踪资金和资产时的一个空白。传统上，供应商尝试使用模糊匹配工具来填补这一空白。本文基于这些考虑，提出了一种结合字符串相似度、主题建模、层次聚类和基于规则的工作流，以促进交易对手方的聚类，并能处理预期集群数量未知的情况。", "innovation": "本文提出了一种结合字符串相似度、主题建模、层次聚类和基于规则的工作流，以促进交易对手方的聚类，并能处理预期集群数量未知的情况。此外，还设计了评估该方法的指标，基于著名的精确度和召回率度量。在实际标记数据集上的测试表明，该方法在性能上明显优于基于规则的基本方法。与基于规则的系统相比，该方法保持了大部分的可解释性，因为它为后者增加了额外的聚类细化层次。", "conclusion": "当只需要对总体中的一部分进行调查，例如制裁调查时，该方法允许更好地控制遗漏实体变体的风险。这种方法的流水线减少了对人工审查的需求。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21141", "html_url": "https://arxiv.org/abs/2508.21141", "title": "在预算约束下的适应性大语言模型路由", "title_en": "Adaptive LLM Routing under Budget Constraints", "authors": "Pranoy Panda,Raghav Magazine,Chaitanya Devaguptapu,Sho Takemori,Vishal Sharma", "background": "大语言模型(LLMs)已经在自然语言处理领域引起了革命，但它们的能力和成本差异在实际应用中带来了挑战。为了应对这一挑战，LLM路由技术通过动态选择每个查询/任务最合适的LLM来解决这个问题。然而，先前的方法将这一问题视为监督学习问题，假设完全知道最优的查询-LLM配对，但在实际场景中，这样的全面映射并不存在，用户的需求在不断变化。因此，该文将LLM路由问题视为上下文二选一问题，使得可以根据二选一的反馈进行适应性决策，而不需要对所有查询进行所有LLM的全面推理（与监督路由不同）。为了处理模型路由中多元化的用户预算问题，该文引入了一种将多选一背包问题作为在线成本策略的模型，确保资源高效的路由决策。", "innovation": "该文提出了将LLM路由问题视为上下文二选一问题的新思路，使用Bandit反馈来实现适应性决策，而无需对所有查询进行全面推理。进一步地，为了适应用户多样化的预算需求，该文引入了一种将多选一背包问题作为在线成本策略的方法，从而实现了资源高效的路由决策。主要创新在于提供了PILOT算法，这是一种LinUCB的新型扩展，用以处理查询和LLM的偏好嵌入空间。", "conclusion": "该文提出了一种新的方法来解决大语言模型路由问题，在上下文二选一框架下，通过在线Bandit反馈进行适应性决策，并结合多选一背包问题来优化预算有限条件下的资源分配，从而实现了低成本、高效的大语言模型路由技术。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21111", "html_url": "https://arxiv.org/abs/2508.21111", "title": "自动化深空网络数据系统；基于自主人工智能的自适应异常检测案例研究", "title_en": "Automating the Deep Space Network Data Systems; A Case Study in Adaptive Anomaly Detection through Agentic AI", "authors": "Evan J. Chou(1 and 2),Lisa S. Locke(3),Harvey M. Soldan(3) ((1) University of California San Diego, (2) Pasadena City College, (3) Jet Propulsion Laboratory California Institute of Technology)", "background": "NASA的深空网络（DSN）是一个大型的天线设施网络，产生了大量的多变量时间序列数据。这些设施包含的DSN天线和发射机随时间退化，可能导致数据流中断并威胁到依赖于深空网络的地外通信。研究目的是通过数据分析协助JPL工程师定位异常和设备退化，同时也为未来宇宙空间任务的维护和运行提供支持。为此，研究了多种机器学习技术，用于数据分析、预测分析、异常数据识别等，并通过强化学习对识别结果显示严重程度，并利用大型语言模型解释异常数据。为DSN发射机制定了一个全面的数据管道系统，整合了数据提取、解析和处理的工作流程，这之前没有统一的程序或脚本。通过这一数据管道系统，将从DSN天线数据训练的模型与发射机数据的处理流程连接起来，完成了DSN异常检测的数据流工作。所有这些都由一个代理式AI系统包围并进一步连接，利用复杂推理确立异常数据的分类和预测.", "innovation": "研究重点是通过多变量时间序列数据和机器学习技术来预测和识别DSN天线和发射机的退化及其操作中的异常状态。具体而言，研究组合了机器学习模型和强化学习模块进行异常检测，并结合使用大型语言模型来解释异常数据，提高了系统的自主性和鲁棒性。数据管道系统进一步确保了数据流的统一和连贯，减少人为干预，提高效率与准确性。代理式AI系统的使用则通过复杂推理增加了系统的分析和预测能力，进一步提高了异常检测的准确性与自适应能力。", "conclusion": "通过整合机器学习、强化学习、大型语言模型和代理式AI系统，该研究展示了在深空网络中自动化异常检测的实际应用，实现了高效的数据处理和预测分析，为未来的深空通信提供了强有力的支持。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21273", "html_url": "https://arxiv.org/abs/2508.21273", "title": "CALM: 一种时间序列流中连续、自适应和大语言模型调解的异常检测框架", "title_en": "CALM: A Framework for Continuous, Adaptive, and LLM-Mediated Anomaly Detection in Time-Series Streams", "authors": "Ashok Devireddy,Shunping Huang", "background": "非平稳时间序列流中的异常检测在众多工业和科学领域中是一个关键但具有挑战性的任务。传统模型由于训练离线，在遇到概念漂移时会遭受性能大幅下降，即数据的底层统计特性随时间发生变化。这是一个亟待解决的问题。", "innovation": "该论文提出了CALM（Continuous, Adaptive, and LLM-Mediated）框架，这是一种具有闭环持续微调机制和大语言模型作为裁判（LLM-as-a-Judge）组件的端到端实时异常检测框架。此项创新主要体现在两个核心贡献上：一是实现了持续微调机制，使异常检测模型能够实现实时动态适应数据模式的变化；二是引入了大型语言模型作为裁判的组件，用于对检测到的异常提供语义和上下文感知的判断，决定异常是否是瞬时噪声还是有意义的模式转移。", "conclusion": "CALM框架在TSB-UAD基准测试中的评估结果表明，连续微调的模型在大多数数据集中比静态预训练的基础模型提高了ROC AUC得分，这验证了自适应、使用大语言模型指导的框架在动态流环境中保持高性能异常检测的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21261", "html_url": "https://arxiv.org/abs/2508.21261", "title": "Owen采样加速联邦学习中的贡献估算", "title_en": "Owen Sampling Accelerates Contribution Estimation in Federated Learning", "authors": "Hossein KhademSohi,Hadi Hemmati,Jiayu Zhou,Steve Drew", "background": "联邦学习（FL）通过聚合多个客户端的信息来训练共享的全局模型，而无需暴露原始数据。准确地估计每个客户端的贡献对于公平奖励、选择最有用的客户端以及加快全局模型的收敛速度都是至关重要的。Shapley值是一种有原则的选择，但其精确计算会随客户端数量的增加而呈指数级增长，使得在大规模联邦学习中不可行。", "innovation": "本文提出了一种高效的框架 FedOwen，使用 Owen 采样来在相同评估预算下近似计算 Shapley 值，同时保持较小的近似误差。此外，FedOwen 还采用了一种自适应客户端选择策略，平衡了开发高价值客户端和探索被低估的客户端，减少了偏差并揭示了罕见但有信息价值的数据。", "conclusion": "在固定估值成本下，与最先进的基线相比，FedOwen 在相同的通信轮数内实现了最高可达23%的最终准确性提升，特别是在非IID基准上。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21188", "html_url": "https://arxiv.org/abs/2508.21188", "title": "Model-Task Alignment Drives Distinct RL Outcomes", "title_en": "Model-Task Alignment Drives Distinct RL Outcomes", "authors": "Haoze Wu,Cheng Wang,Wenshuo Zhao,Junxian He", "background": "近年来，将强化学习（RL）应用于大规模语言模型（LLMs）取得了显著进展。然而，LLMs中出现了许多值得注意但通常出乎意料的现象，这些现象不符合传统RL设置中通常观察到的模式。例如，一个单一的训练样本可以达到整个数据集的效果，奖励信号不必非常准确，仅仅使用负面样本的训练就能匹配甚至超过基于奖励的复杂方法的效果。但这些观察结果的具体条件及其失败的情况尚不清楚。本研究通过系统分析这些出乎意料的主张，并通过严格的实验验证多种模型架构和任务领域，作者发现标准RL训练在各种设置下仍然非常稳健，但许多出乎意料的结果仅在模型和任务已经表现出强模型-任务对齐的情况下才出现。在更难的环境中，这些技术无法显著地驱动学习，而标准RL方法仍然有效。", "innovation": "这项研究表明，模型任务对齐（Model-Task Alignment）是决定性因素，影响RL结果。出乎意料的结果仅在模型和任务之间已经存在强模型-任务对齐时发生。该研究通过系统的实验分析和验证，揭示了标准RL训练在各种设置下的稳定性和这些出乎意料结果的条件性。该工作提供了深入理解RL应用于LLMs现象的新见解，强调了模型任务对齐的重要性。", "conclusion": "标准RL训练在各种设置下仍然非常稳健，但许多出乎意料的结果仅在模型和任务已经表现出强模型-任务对齐的情况下才出现。在更难的环境中，这些技术无法显著地驱动学习，而标准RL方法仍然有效。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21240", "html_url": "https://arxiv.org/abs/2508.21240", "title": "使用自组织映射和变分自编码器的合成回放的类增量持续学习", "title_en": "Class Incremental Continual Learning with Self-Organizing Maps and Variational Autoencoders Using Synthetic Replay", "authors": "Pujan Thapa,Alexander Ororbia,Travis Desell", "background": "该研究专注于持续学习问题，其中模型需要在不遗忘旧知识的情况下不断适应新任务。传统的持续学习方法需要存储大量的原始数据样本或任务标签，这会消耗大量内存并影响学习效率。为了克服这些问题，研究引入了一种基于自组织映射（SOM）和变分自编码器（VAE）的新颖生成式持续学习框架，旨在实现高效的数据回放，同时不需要存储原始数据样本或任务标签。", "innovation": "该研究的主要创新点在于提出了一种基于SOM和VAE的生成式持续学习框架，特别适用于高维和低维输入空间。通过这种方法，可以在未来的学习迭代中从每个SOM单元的运行均值、方差和协方差中生成合成样本。对于基于VAE的方法，生成的样本会被送入解码器用于后续的回放。实验结果表明，在标准类别增量基准测试上，该方法在内存利用上表现与最先进的记忆方法相当，并在两个CIFAR数据集上的单类别增量性能超过了之前最好的状态，分别提高了近10%和7%。此外，该方法还使得学习过程的可视化更加容易，并可以作为训练后的生成模型使用。", "conclusion": "实验结果证明了该方法作为可扩展的、无需任务标签且记忆高效的持续学习解决方案的能力，能够有效应用于各种类型的数据和场景。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21249", "html_url": "https://arxiv.org/abs/2508.21249", "title": "外部气动学增强替代建模的一种专家混合门网络", "title_en": "A Mixture of Experts Gating Network for Enhanced Surrogate Modeling in External Aerodynamics", "authors": "Mohammad Amin Nabian,Sanjay Choudhry", "background": "高保真计算流体动力学（CFD）模拟的计算成本一直是汽车设计和优化周期中的一个显著瓶颈。虽然基于机器学习的替代模型已经浮现出来，可以加快气动预测，但该领域的特点是专门神经网络架构多样且迅速变化，没有单一模型能够表现出普遍的优越性。", "innovation": "本文介绍了一种新的元学习框架，该框架通过将这一架构多样性的优势作为强项来利用。提出的是一种专家混合模型（MoE），使用专用的门网络动态和最优化组合三个异构的最先进的替代模型：DoMINO、X-MeshGraphNet和FigConvNet。门网络学习一个空间可变的权重策略，基于每个专家在其预测表面压力和壁面剪切应力场中的局部性能来赋予其置信度。为了防止模型崩溃并鼓励均衡的专家贡献，将在训练损失函数中整合一个熵正则化项。整个系统的训练和验证是在DrivAerML数据集上进行的，这是一个大规模的公开基准，用于汽车气动的高保模拟。定量结果显示，MoE模型不仅在所有评估物理量上的预测L-2误差显著降低，还优于单个最准确的专家模型的平均值。", "conclusion": "本文确立了MoE框架作为一种有效策略的地位，通过以互补优势相结合的方式创建更具鲁棒性和准确性的复合替代模型来增强专门架构的协同作用。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21258", "html_url": "https://arxiv.org/abs/2508.21258", "title": "RelP:基于相关性楔形的忠实高效电路发现", "title_en": "RelP: Faithful and Efficient Circuit Discovery via Relevance Patching", "authors": "Farnoush Rezaei Jafari,Oliver Eberle,Ashkan Khakzar,Neel Nanda", "background": "激活楔形是机制可解释性中的标准方法，用于定位模型中负责特定行为的组件，但它在大规模应用时计算成本过高。归因楔形则提供了一种更快速的、基于梯度的近似方法，但在深层的、高度非线性的网络中会遇到噪声和可靠性降低的问题。本文通过引入相关楔形（RelP），部分解决了这一问题，通过使用从逐层相关性传播（LRP）中派生的传播系数来替代归因楔形中的局部梯度，提高其准确性和可靠性。", "innovation": "相关楔形（RelP）使用从逐层相关性传播（LRP）中派生的传播系数，替代归因楔形中的局部梯度。LRP通过逐层向后传播网络的输出，根据局部传播规则重新分配相关性，以确保属性如相关性的保全或改进信噪比等特性。RelP仅需两个前向传播和一个后向传播即可，保持了计算效率，同时提高了忠诚度。这一方法在多个模型和任务中得到了验证，特别是在间接对象识别（IOI）任务中分析残差流和MLP输出时，显示了更好的近似效果，并且相比集成梯度（IG）具有更高的忠诚度一致性，而无需额外的计算成本。", "conclusion": "相对归因楔形，相关楔形（RelP）在基于模型激活楔形分析任务中的表现更为准确，特别是在间接对象识别（IOI）任务中分析GPT-2 Large的MLP输出时，相关楔形（RelP）达到了0.956的皮尔逊相关系数，而归因楔形仅为0.006，突显了RelP的优势，同时也验证了RelP在其他任务中的卓越性能，提供了忠实高效的电路发现方法。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21278", "html_url": "https://arxiv.org/abs/2508.21278", "title": "肌电激活领域转换检测：流学习中的挑战与机遇", "title_en": "Detecting Domain Shifts in Myoelectric Activations: Challenges and Opportunities in Stream Learning", "authors": "Yibin Sun,Nick Lim,Guilherme Weigert Cassales,Heitor Murilo Gomes,Bernhard Pfahringer,Albert Bifet,Anany Dwivedi", "background": "肌电信号（EMG）的固有非稳态性导致了在肌电信号中检测领域转换的挑战。现有技术在实现实时EMG信号领域转换检测方面存在局限性。", "innovation": "本文采用数据流（DS）学习技术来检测领域转换，使用DB6数据集（来自Ninapro数据库）进行研究。通过应用核主成分分析（KPCA）和余弦核进行预处理以及特征抽取，同时评估了CUSUM、Page-Hinckley和ADWIN等多种漂移检测方法，发现了现有技术在EMG信号实时领域转换检测中的不足之处。", "conclusion": "结果表明，基于流的方法具有维护稳定EMG解码模型的潜力，但仍需进一步研究以提高实际应用中的稳健性和准确性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21314", "html_url": "https://arxiv.org/abs/2508.21314", "title": "POMDPs中正则化代理状态基于Q学习的收敛性", "title_en": "Convergence of regularized agent-state-based Q-learning in POMDPs", "authors": "Amit Sinha,Matthieu Geist,Aditya Mahajan", "background": "本文研究了一般实践中的常用Q学习强化学习算法的收敛性。这些算法有两个显著特性：（i）Q表通过代理状态（如递归神经网络的状态）递归更新，该状态不是信念状态或信息状态；（ii）通常使用策略正则化来鼓励探索并稳定学习算法。论文探讨了这种算法的最简单形式——称为正则化代理状态基于Q学习（RASQL），并证明在温和的技术条件下，其收敛到特定的正则化MDP的固定点，这依赖于由行为策略诱导的平稳分布。", "innovation": "论文展示了对正则化代理状态基于Q学习（RASQL）算法的研究，并在一定条件下证明了其收敛性。此外，对于能够学习周期性策略的RASQL变体，也进行了类似的分析并得到相同的结果。", "conclusion": "通过数值示例展示了实证收敛行为与提出的理论极限相一致。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21330", "html_url": "https://arxiv.org/abs/2508.21330", "title": "Stage-Diff：基于扩散模型的阶段式长周期时间序列生成", "title_en": "Stage-Diff: Stage-wise Long-Term Time Series Generation Based on Diffusion Models", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "生成模型在时间序列生成领域取得了成功应用，但在处理跨越较长时间并展现复杂长期时间模式的长周期时间序列时，生成任务变得更加具挑战性。长周期时间序列不仅具有的远距离时间依赖性，数据分布也会随时间逐渐变化。找到长期依赖性和数据分布变化之间的平衡是关键挑战之一。此外，长周期时间序列还包含不同特征序列之间更复杂的相互关系，捕捉序列内部和序列间依赖性也是重要挑战之一。", "innovation": "提出了基于扩散模型的阶段式生成模型（Stage-Diff），通过阶段式序列生成和跨阶段信息传递，模型可以保留长期序列依赖性并适应数据分布的变化。每个阶段中采用分步序列分解，进行无关通道建模，并结合多通道融合模型实现跨阶段信息传递。这种做法结合了无关通道建模的稳健性和多通道建模的信息融合优势，有效平衡了长期时间序列的序列内和序列间依赖性。", "conclusion": "在多个实际数据集上进行的广泛实验验证了Stage-Diff在长周期时间序列生成任务中的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21340", "html_url": "https://arxiv.org/abs/2508.21340", "title": "DLGAN：基于双层生成对抗网络的时间序列合成", "title_en": "DLGAN : Time Series Synthesis Based on Dual-Layer Generative Adversarial Networks", "authors": "Xuan Hou,Shuhan Liu,Zhaohui Peng,Yaohui Chu,Yue Zhang,Yining Wang", "background": "时间序列合成是确保时间序列数据安全流通的有效方法。现有方法通常基于随机序列进行时间建模以生成目标序列，常常难以保证生成时间序列中的时间依赖关系。直接在随机序列上建模时间特征也使得精准捕捉原始时间序列的特征信息变得困难。", "innovation": "提出了一种简单的生成模型Dual-Layer Generative Adversarial Networks（DLGAN），将时间序列生成过程分解为序列特征提取和序列重建两个阶段。首先，这两个阶段形成一个完整的时序自编码模型，确保从原始时间序列推断的监督学习过程可以恢复时间系列的时间依赖关系。其次，采用生成对抗网络（GAN）生成与实时序列特征向量对齐的合成特征向量，从而使生成器能够从真实时间序列中捕捉时间特征。", "conclusion": "在四个公开数据集上进行了广泛的实验，表明该模型在各种评估指标中表现出明显的优势。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21300", "html_url": "https://arxiv.org/abs/2508.21300", "title": "改善基于LoRA的LLM遗忘机制中的Fisher信息估计与效率", "title_en": "Improving Fisher Information Estimation and Efficiency for LoRA-based LLM Unlearning", "authors": "Yejin Kim,Eunwon Kim,Buru Chang,Junsuk Choe", "background": "大规模语言模型（LLMs）在各类任务中表现出色，但存在意外生成包含敏感信息的输出的问题。传统的重新训练模型的方法虽然有效，但由于需要处理的大量数据，导致计算成本过高。为了解决这一问题，机器遗忘作为一种新的解决方案被提出，它可以有效地移除敏感信息，而无需从头重新训练整个模型。然而，这种方法仍需访问所有模型参数，并且在Fisher信息的重要性估计上存在不足，这导致了参数识别上的不准确性。", "innovation": "本文提出了一种名为VILA（Verify Fisher and LoRA Adaptation）的新遗忘框架，它不仅明确考虑了FILA中未考虑的基本假设，提高了遗忘集参数识别的准确性，还通过不需要访问整个模型来显著降低了计算成本。VILA的方法相比FILA实现了百倍的参数效率和四十倍的训练速度提升，并在TOFU、WMDP和MUSE等基准测试中取得了最先进的性能。", "conclusion": "本文提出了一种新的遗忘框架VILA，该框架能够有效解决Fisher信息估计和计算成本高的问题。VILA在遵循Fisher信息的基本假设方面更准确，同时能够显著提高参数效率并加快训练速度，是LLMs神经网络参数遗忘的一种有效方法。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21270", "html_url": "https://arxiv.org/abs/2508.21270", "title": "Guess-and-Learn (G&L): 测量冷启动适应中的累积错误成本", "title_en": "Guess-and-Learn (G&L): Measuring the Cumulative Error Cost of Cold-Start Adaptation", "authors": "Roland Arnold", "background": "现有的机器学习模型评估通常侧重于最终的准确度，而忽略了适应成本，即在从零开始学习过程中累积的错误。本文旨在填补这一空白，通过测量冷启动适应性，即在逐步标注一个未标注的数据集时，模型所犯的总错误来评估模型的适应性。", "innovation": "文章提出了Guess-and-Learn (G&L) v1.0，它定义了四个轨道（从零开始/预训练×在线/批量）来区分初始化和更新频率的影响，并定义了一种协议，这使得能够量化早期学习的错误成本，从而使新的适应性评估框架具有可重复性。此外，它还包括了与经典错误界限理论的关联，并为MNIST数据集提供了“元参考带”作为参考。", "conclusion": "通过对早期学习中错误成本的量化，Guess-and-Learn 补充了传统的基准测试，并提供了开发不仅在长远上准确而且从第一例开始就可靠的学习器的可重复框架。当前模型在所有设置中都远高于元参考带，表明存在适应性差距。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21396", "html_url": "https://arxiv.org/abs/2508.21396", "title": "PMODE：具有理论依据和模块化的混合建模", "title_en": "PMODE: Theoretically Grounded and Modular Mixture Modeling", "authors": "Robert A. Vandermeulen", "background": "该研究引入了PMODE（Partitioned Mixture Of Density Estimators）框架，旨在提供一个通用且可模块化的方法来处理混合模型。PMODE能够结合参数和非参数组件，通过数据分割并为每个子集拟合独立估计器来构建混合模型。这种框架为混合建模领域提供了一种处理不同分布家庭混合成分的方法，同时保持了估计器的有效性。此外，尽管取得了理论突破，该方法在高维数据处理方面选择了一条实用路径。", "innovation": "PMODE框架创新性地结合了参数和非参数估计，通过数据分割方法实现混合模型的构建。它为不同分布家庭的混合成分提供了有效的处理方法，并且理论上证明了该方法可以接近最优的估计率。MV-PMODE进一步展示了如何将理论上的混合建模方法扩展到高维数据的密度估计问题中。", "conclusion": "PMODE框架以其模块化的设计和理论上证明的优点，展示了在高维数据密度估计、尤其是CIFAR-10异常检测中的竞争力。该研究不仅提供了一种有效的混合建模方法，还为未来的应用提供了指导思想。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21420", "html_url": "https://arxiv.org/abs/2508.21420", "title": "基于水库计算的低成本网络状态评估方法基准", "title_en": "Benchmarking the State of Networks with a Low-Cost Method Based on Reservoir Computing", "authors": "Felix Simon Reimers,Carl-Hendrik Peters,Stefano Nichele", "background": "利用来自挪威移动网络使用的数据，展示了使用非侵入性、低成本的方法监控通信和移动网络状态的可能性。这种方法将网络数据转化为水库计算框架内的模型，并通过代理任务测量模型的性能。实验结果显示，这些代理任务的性能与网络状态相关。这种优势在于它使用了现成的数据集，并结合了水库计算框架来实现经济且几乎无偏的方法。", "innovation": "该方法将移动网络利用的数据转化为加权网络，并利用水库计算框架，使无训练的加权网络可以作为机器学习工具使用。初始化为回声状态网络（ESN）的网络将输入信号投影到更高维度空间，单层经过训练的网络在该空间上操作。这种方法相较于深度神经网络消耗更少的能量。通过神经科学启发的任务训练ESN模型，并展示了性能随网络配置变化而变化的情况，以及网络受扰动时性能明显下降的现象。", "conclusion": "这项工作证明了该方法的可行性，认为它可以发展成为近乎实时的监控工具，并用于识别移动通信网络及交通网络的潜在弱点。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21380", "html_url": "https://arxiv.org/abs/2508.21380", "title": "象棋博弈神经网络中的迭代推理", "title_en": "Iterative Inference in a Chess-Playing Neural Network", "authors": "Elias Sandmann,Sebastian Lapuschkin,Wojciech Samek", "background": "本文探讨了神经网络构建其表征的方式是通过平滑、渐进的精炼，还是通过更复杂的过程。为了研究这一问题，作者将“logit镜头”应用到超级人类棋手Leela Chess Zero的策略网络上进行分析。研究表明，在网络各层中都存在较强的单调趋势，但在策略分布上却经常表现出非平滑的轨迹。例如，找到正确解题但随后被丢弃，以及步骤排序与最终输出的相关性不足等问题。这些发现与语言模型中通常观察到的平滑分布一致性形成对比。", "innovation": "本文的创新之处在于使用了“logit镜头”（一种新的分析方法）来研究超级人类棋手Leela Chess Zero的策略网络，揭示了神经网络在解题过程中的非平滑特性，挑战了神经网络构建表征通常是逐步且平滑的这一常见观点。", "conclusion": "本文的研究表明，神经网络在策略网络中的表征构建过程并非总是平滑且渐进的，而是可能通过更具复杂性的计算过程来实现。这一发现可能会改变我们对神经网络工作原理的理解，并引起对该领域进一步研究的兴趣。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21324", "html_url": "https://arxiv.org/abs/2508.21324", "title": "分布感知特征选择以用于自编码器", "title_en": "Distribution-Aware Feature Selection for SAEs", "authors": "Narmeen Oozeer,Nirmalendu Prakash,Michael Lan,Alice Rigg,Amirali Abdullah", "background": "稀疏自编码器（SAEs）通过将神经激活分解为可解释的功能来工作。一种广泛采用的变种，TopK SAE，从每个令牌的K个最活跃的潜在变量中重建每个令牌。然而，这种做法效率低下，因为一些令牌承载的信息比其他令牌更多。BatchTopK通过在一个令牌批次中选择最活跃的激活来解决这一限制，提高了平均重建效果，但会面临“激活彩票”问题，即罕见的高幅度特征会排挤更具信息量但幅度较低的特征。", "innovation": "我们引入了Sampled-SAE方法。首先，我们基于L2范数或熵对批次激活矩阵的列（代表特征）进行评分，形成大小为$Kl$的候选池，然后按Top-$K$选择批次中的令牌。通过改变$l$的值，可以实现从批次级别到特定令牌的特征选择之间的连续谱。当$l=1$时，令牌仅从全球影响力最大的$K$个特征中选择；随着$l$的增大，特征池扩展至标准BatchTopK方法，并涵盖更多特定于批次的特征。小的$l$值促使全局一致性；大的$l$值促进更精细的重建。在Pythia-160M上，没有单一的$l$值可以在所有度量上实现最优，因此最佳选择取决于共享结构、重构保真度和下游性能之间的权衡。Sampled-SAE将BatchTopK重新构想为一个可调且分布感知的家庭。", "conclusion": "Sampled-SAE通过引入选择特征池的方式，为BatchTopK提供了一种可调且分布感知的方法，具有多种选择策略灵活应对不同场景的特点。对于不同的评估标准而言，最佳的选择依赖于共享结构、重构保真度和下游性能之间的权衡。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21353", "html_url": "https://arxiv.org/abs/2508.21353", "title": "自适应重尾随机梯度下降", "title_en": "Adaptive Heavy-Tailed Stochastic Gradient Descent", "authors": "Bodu Gong,Gustavo Enrique Batista,Pierre Lafaye de Micheaux", "background": "在大规模神经网络模型时代，优化算法由于过度依赖训练损失而常常在泛化方面出现问题。在机器学习领域，一个广泛接受的观点是，宽盆地（围绕局部最小值的区域，损失逐渐增加）通过提供对输入数据或模型参数的小变化更大稳定性而促进更好的泛化。相比之下，尖锐最小值通常更加敏感且不那么稳定。受渐变噪声在随机梯度下降中的固有重尾分布以及神经网络训练中的边缘稳定性现象的两个关键经验观察激发，在此介绍了自适应重尾随机梯度下降（AHTSGD）。AHTSGD在训练早期注入具有更重尾的噪声以增强探索性，并随着尖锐性稳定逐渐过渡到轻尾噪声。通过在整个训练过程中动态适应损失景观的尖锐性，AHTSGD促进了向宽盆地的加速收敛。AHTSGD是第一个基于边缘稳定性现象调整注入噪声性质的算法。AHTSGD在基准测试（如MNIST和CIFAR-10）中始终优于SGD和其他基于噪声的方法，特别是在噪声较大的SVHN数据集上获得显著收益。它最终加速了从不良初始化的早期训练，并在干净和噪声环境中均改善了泛化，同时对学习率选择具有鲁棒性。", "innovation": "AHTSGD基于边缘稳定性现象动态适应损失景观的尖锐性，通过在训练早期注入具有更重尾的噪声以增加探索性，并随着尖锐性稳定逐渐过渡到轻尾噪声，从而促进向宽盆地的加速收敛。这是首个基于边缘稳定性现象调整优化器中注入噪声性质的算法。在MNIST、CIFAR-10以及其他噪声集如SVHN上，AHTSGD均显示出优越的性能，特别是加速了从不良初始化的早期训练，并在各种设置中增强了泛化能力，对学习率选择具有鲁棒性。", "conclusion": "AHTSGD通过动态适应损失景观的尖锐性，改进了优化算法的泛化能力和训练效率，特别是在处理噪声数据集时表现出色。这种算法对于提高机器学习模型的性能具有重要意义。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21438", "html_url": "https://arxiv.org/abs/2508.21438", "title": "量子增强的ensemble GANs在连续生物制造中的异常检测", "title_en": "Quantum enhanced ensemble GANs for anomaly detection in continuous biomanufacturing", "authors": "Rajiv Kailasanathan,William R. Clements,Mohammad Reza Boskabadi,Shawn M. Gibford,Emmanouil Papadakis,Christopher J. Savoie,Seyed Soheil Mansouri", "background": "连续生物制造过程需要早期准确地检测异常，因为即使是小的偏差也可能损害产量和稳定性，导致调度中断、周产量下降和经济效益下降。这些过程本就复杂且非线性动态显著，使得必须采用先进的异常检测方法来确保高效运行。现有的算法需要改进以应对复杂关系和非线性变化，因此本文致力于开发一种基于GAN的无监督异常检测框架，以解决实际复杂连续生物制造过程中的问题。", "innovation": "本文提出了一个基于GAN的无监督异常检测框架，并采用量子经典混合的方式，利用量子电路模拟和现实的光子量子处理器，提高了异常检测的准确率。这种方法为复杂连续生物制造过程中的实际问题提供了解决方案，展示了量子经典混合方法在实际复杂过程中的潜力。", "conclusion": "研究结果表明，量子经典混合方法在连续生物制造中的异常检测中表现优异，提出了利用模拟和实际量子处理器的Hybrid量子经典GAN方法对异常检测的有效性，这将有助于改进现有的复杂生物制造过程的管理系统，提高生产效率和经济效益。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21468", "html_url": "https://arxiv.org/abs/2508.21468", "title": "通过贝叶斯流网络和梯度整合实现基于结构的药物设计中的可控3D分子生成", "title_en": "Controllable 3D Molecular Generation for Structure-Based Drug Design Through Bayesian Flow Networks and Gradient Integration", "authors": "Seungyeon Choi,Hwanhee Kim,Chihyun Park,Dahyeon Lee,Seungyong Lee,Yoonju Kim,Hyoungjoon Park,Sein Kwon,Youngwan Jo,Sanghyun Park", "background": "最近基于结构的药物设计（SBDD）的进步利用了生成模型进行3D分子生成，主要通过靶蛋白的结合亲和力来评估模型性能。然而，实际的药物发现需要高效的结合亲和力以及合成可行性和选择性，这些关键属性在之前的评估中被严重忽视。因此，有必要解决这一缺口。", "innovation": "本文识别出传统的基于扩散的生成模型在有效引导分子生成以适应多种药理性质方面的局限性，提出了一种新颖的CByG框架，扩展了贝叶斯流网络为梯度基于的条件生成模型，以稳健地集成属性特异性指导。同时，引入了一种全面的评估方案，结合实际基准评估结合亲和力、合成可行性和选择性，克服了传统评估方法的限制。", "conclusion": "广泛实验表明，所提出的CByG框架在多个关键评估标准上显著优于基准模型，突显了其在实际药物发现应用中的有效性和实用性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21421", "html_url": "https://arxiv.org/abs/2508.21421", "title": "重思基于链式合并的分层模型合并", "title_en": "Rethinking Layer-wise Model Merging through Chain of Merges", "authors": "Pietro Buzzega,Riccardo Salami,Angelo Porrello,Simone Calderara", "background": "预训练模型的微调已成为实现各种领域最佳性能的标准途径，导致产生大量特定任务的模型变体。随着这些专用于特定任务的模块数量增加，将它们合并到一个无需重新训练的统一模型中已成为一个关键挑战。现有的合并技术通常通过独立处理每层来使用干扰启发式、重要权重或激活匹配方法，而忽略了深层神经网络中固有的跨层依赖关系。这种简化方法导致了分布上的不匹配，尤其是在基于激活的方法中，当早期层的变化未适当反映在下游层时更为明显。我们将其视为一种内部协变量偏移的形式，类似于神经网络训练初期遇到的现象。为了应对这一挑战，我们的研究旨在提出一种新的方法来处理这个问题并进行有效的合并。", "innovation": "我们提出了一种称为‘链式合并’（Chain of Merges, CoM）的新颖的分层合并技术，它通过自回归的方式更新激活统计信息，明确考虑跨层交互。CoM 通过一系列条件下的最优更新生成一个逻辑一致的合并模型，有效减轻因协变量偏移导致的性能下降。我们的实验证明了 CoM 在标准基准测试中的最佳性能。通过这种方法，我们能够更好地解决分层网络中的分布不匹配问题，从而提高模型的泛化能力和稳定性。", "conclusion": "实验结果表明，CoM 在标准基准测试中实现了最先进的性能，有效地解决了由于分布偏移导致的合并模型性能下降问题。这一方法通过明确考虑不同层之间的交互关系提升了合并模型的质量。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21443", "html_url": "https://arxiv.org/abs/2508.21443", "title": "超出期望值：强化学习中长期策略性能的几何均值优化", "title_en": "Beyond expected value: geometric mean optimization for long-term policy performance in reinforcement learning", "authors": "Xinyi Sheng,Dominik Baumann", "background": "强化学习（RL）算法通常优化累计的期望奖励，即代理在整个轨迹过程中收到的标量奖励的期望值。这种期望值通过无限多个轨迹的平均来表示。然而，在实际部署代理到真实环境时，这种集合平均可能对单个轨迹的表现不太有信息量。因此，在许多应用中，优化单个轨迹的长期表现可能更为 desirable。", "innovation": "本文提出了一种新颖的RL算法，将标准的集合平均与时间平均增长率相结合，这是衡量单个轨迹长期表现的一种方法。作者定义了时间平均增长率的贝尔曼算子，并在乘法奖励动态下证明几何平均与时间平均增长率一致。为了处理更一般且未知的奖励动态，提出了具有N滑动窗口的修改几何平均值，该估计器嵌入到目标函数作为正则化器，使策略能够从集合平均和时间平均的双重好处中受益。", "conclusion": "该算法在具有挑战性的模拟中进行了评估，并且在多个基准上表现出了优于传统RL方法的效果。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21495", "html_url": "https://arxiv.org/abs/2508.21495", "title": "失败预测比校准是早期退出网络性能更合适的代理指标", "title_en": "Failure Prediction Is a Better Performance Proxy for Early-Exit Networks Than Calibration", "authors": "Piotr Kubaty,Filip Szatkowski,Metod Jazbec,Bartosz Wójcik", "background": "早期退出模型通过在模型的中间层添加内部分类器，并在预测满足退出条件时允许计算停止来加快推理速度。大多数早期退出方法依赖于基于置信度的退出策略，一些工作通过校准中间分类器来提高整个模型的性能。然而，校准措施可能不是评估多出口模型性能的有效指标，即校准良好的分类器仍然可能导致不必要的计算浪费，且常用的校准方法无法保持分类器内样本文档的排名顺序。研究者通过实验证明，一些未校准（即错误校准）的网络可能比校准过的网络表现更好。因此，需要寻找一种更有效的早期退出模型性能评估方法。", "innovation": "本研究提出使用失败预测作为评估早期退出模型性能的更有效代理指标，而不像传统校准方法那样只关注置信度和排名稳定性，失败预测更能反映效率提升的关联性，为设计和评估早期退出模型提供了更可靠的基础。", "conclusion": "校准指标可能无法真实反映多出口模型的性能，而失败预测更适合作为评估早期退出模型性能的代理指标，因为它能更好地处理样本排名变化，并与效率提升有很强的相关性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21466", "html_url": "https://arxiv.org/abs/2508.21466", "title": "黎曼流形数据空间上归一化最大似然码长", "title_en": "Normalized Maximum Likelihood Code-Length on Riemannian Manifold Data Spaces", "authors": "Kota Fukuzawa,Atsushi Suzuki,Kenji Yamanishi", "background": "最近几年，随着图数据的大规模扩展，人们更加关注除了欧几里得空间以外的黎曼流形数据空间。特别是双曲空间的发展尤为显著，它们具有高效表示具有层次结构的图数据的能力。现有规范化最大似然（NML）公式主要在欧几里得空间中进行开发，且依赖于选定的坐标系统，使其不易扩展到黎曼流形上。因此，本文旨在定义一种新的NML，称为黎曼流形NML（Rm-NML），该公式可以反映黎曼流形的几何结构，且在自然参数化时与传统NML一致。现有的NML计算技术也被扩展至黎曼流形上，特别是推导了一种简化黎曼对称空间上计算Rm-NML的方法，这包括了如双曲空间这类日益重要的数据空间。", "innovation": "本文创新性地定义了一种新的NML，称为黎曼流形NML（Rm-NML）。Rm-NML具有不变性，即不受坐标变换的影响，并在欧几里得空间中保持传统NML的一致性。此外，研究还发展了现有NML计算技术在黎曼流形上的应用，尤其是在黎曼对称空间上简化了Rm-NML的计算方法。", "conclusion": "通过对正常分布在双曲空间上计算Rm-NML的实例，文中提出了Rm-NML的实际应用。研究结果证明了Rm-NML能够更好地处理具有层次结构的图数据，并为未来在非欧几里得空间中的应用提供了新的研究视角。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21512", "html_url": "https://arxiv.org/abs/2508.21512", "title": "接受还是拒绝？跨表格到文本序列化方法评估大型语言模型在贷款审批中的公平性和性能", "title_en": "Accept or Deny? Evaluating LLM Fairness and Performance in Loan Approval across Table-to-Text Serialization Approaches", "authors": "Israel Abebe Azime,Deborah D. Kanubala,Tejumade Afonja,Mario Fritz,Isabel Valera,Dietrich Klakow,Philipp Slusallek", "background": "近年来，大型语言模型（LLMs）在高风险决策任务中被广泛应用，例如贷款审批。然而，随着这些模型在不同领域的扩展应用，它们在处理表格数据、确保公平性和提供可靠预测方面仍然面临挑战。本研究通过对来自非洲加纳、欧洲德国和北美美国三个地区的贷款审批数据集进行评估，重点关注模型的零样本学习（zero-shot）和上下文学习（in-context learning，ICL）能力。", "innovation": "研究发现，不同表格到文本序列化格式对LLM的性能和公平性有显著影响。某些序列化格式如GReat和LIFT虽然能提供更好的F1分数，但会加剧公平性差距。ICL能改善零样本学习性能，但对公平性影响因数据集而异。这项工作强调了有效表格数据表示方法和公平性意识模型的重要性，以提高LLM在金融决策中的可靠性。", "conclusion": "本研究通过评估LLM在不同地区的贷款审批数据集中的表现和公平性，揭示了序列化格式对LLM性能和公平性的影响。此外，ICL虽然提高了模型性能，但其对公平性的影响因数据集不同而异。研究结果强调了需要有效的表格数据表示方法和公平性意识模型来提升LLM在金融决策中的可靠性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21513", "html_url": "https://arxiv.org/abs/2508.21513", "title": "基于图拉伊奇曲率对学习GNNSAT求解器难度的探究：作用", "title_en": "On the Hardness of Learning GNN-based SAT Solvers: The Role of Graph Ricci Curvature", "authors": "Geri Skenderi", "background": "图神经网络（GNNs）在通过图表示逻辑公式解决布尔可满足性问题（SATs）方面展现出了潜力，但在处理更难实例时性能急剧下降，引发了关于是否反映出根本的架构限制的疑问。本文通过图拉伊奇曲率（RC）的几何解释提供了解释，这是一种量化局部连接瓶颈的方法。", "innovation": "我们证明，从随机k-SAT公式导出的双分图天然呈负曲率，并且随着实例难度增加而下降。基于此，我们展示了基于GNN的SAT求解器受过压缩现象影响，该现象使得长距离依赖无法压缩到固定长度的表示中。此外，我们通过不同的SAT基准实验验证了我们的观点，发现曲率是一个强大复杂性指标，并可用于预测性能。最后，我们将这些发现与现有求解器的设计原则联系起来，指出了未来工作的有前途的方向。", "conclusion": "我们证明了图拉伊奇曲率是复杂性的一个强大指标，并且可以通过它来预测性能，并提出了基于这些发现来改进GNN求解器设计的原则。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21488", "html_url": "https://arxiv.org/abs/2508.21488", "title": "先验分布很重要：解决贝叶斯深度Q学习中的模型指定问题", "title_en": "Priors Matter: Addressing Misspecification in Bayesian Deep Q-Learning", "authors": "Pascal R. van der Vaart,Neil Yorke-Smith,Matthijs T.J. Spaan", "background": "在强化学习中，不确定性量化可以显著提升探索和增强鲁棒性。最近，近似贝叶斯方法被广泛应用于量化模型自由算法中的不确定性。然而，到目前为止，研究的重点是提高后验近似的准确性，而不是研究先验和似然假设的准确性，这些假设构成了后验的基础。在本研究中，作者展示了贝叶斯深度Q学习中存在一种冷后验效应，即减少后验的温度反而会提高性能，与理论不符。同时，作者挑战了普通环境下对可能的先验和似然分布的假设，通过实证分析发现，常见的高斯似然假设经常被违反，强调了开发更合适的先验和似然分布应在未来的研究中是一个关键重点，并提出了一些简单而易于实现的解决方案以改善深度Q学习中的先验分布，从而使贝叶斯算法表现出色", "innovation": "本文的创新之处在于挑战了普通环境下对可能的先验和似然分布的假设，通过实证分析，作者发现常见的高斯似然假设常常被违反，并提出了解决这些问题的方法，以改进贝叶斯强化学习中的先验分布，从而提高算法性能。论文还揭示了贝叶斯深度Q学习中的一种新现象，即冷后验效应，虽然减少后验的温度通常被视为降低性能，但在某些情况下反而能提高性能", "conclusion": "作者建议在未来的贝叶斯强化学习研究中应关注开发更适合的先验和似然分布，并提供了一些简单的解决方案以改善深度Q学习中的先验分布，从而提出更具成效的贝叶斯算法。实验结果表明，改进后的贝叶斯算法在特定任务上表现更佳"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21570", "html_url": "https://arxiv.org/abs/2508.21570", "title": "OASIS：利用稀疏漂流轨迹的扩散对抗网络进行海洋盐度插值", "title_en": "OASIS: Harnessing Diffusion Adversarial Network for Ocean Salinity Imputation using Sparse Drifter Trajectories", "authors": "Bo Li,Yingqi Feng,Ming Jin,Xin Zheng,Yufei Tang,Laurent Cherubin,Alan Wee-Chung Liew,Can Wang,Qinghua Lu,Jingwei Yao,Shirui Pan,Hong Zhang,Xingquan Zhu", "background": "海洋盐度对于循环、气候和海洋生态系统起着至关重要的作用，但是其测量往往稀疏、不规律且噪声较大，特别是基于漂流器的资料中。传统的遥感和最佳插值方法依赖线性和站姿性，并受到云层遮挡、传感器漂移以及卫星重访率低的限制。尽管机器学习模型具有灵活性，但在严重稀疏情况下常失效，且缺乏在没有专用传感器的情况下将物理协变量融入的方法。", "innovation": "本文介绍了一种新型的扩散对抗框架——OceAn Salinity Imputation System (OASIS)，旨在解决上述挑战。", "conclusion": "OASIS框架通过利用稀疏的漂流器轨迹，成功地对海洋盐度进行了插值，克服了传统方法和现有机器学习模型的限制。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21561", "html_url": "https://arxiv.org/abs/2508.21561", "title": "Summarize-Exemplify-Reflect: 数据驱动的洞察提炼赋能LLMs进行少量样本表格分类", "title_en": "Summarize-Exemplify-Reflect: Data-driven Insight Distillation Empowers LLMs for Few-shot Tabular Classification", "authors": "Yifei Yuan,Jiatong Li,Weijia Zhang,Mohammad Aliannejadi,Evangelos Kanoulas,Renjun Hu", "background": "最近的研究表明大规模语言模型（LLMs）在少量样本表格分类中具有潜力，但同时也指出了由于结构化数据的变化性带来的挑战。", "innovation": "提出了一种数据提炼框架 InsightTab，该框架借鉴了人类学习过程的原理，采用‘分析-举例-反思’的方法，通过LLMs和数据建模技术的深度融合，提炼数据以生成可行动的洞察，使LLMs能够更好地适应特定表格任务的需求。", "conclusion": "在九个数据集上的广泛评估表明，InsightTab 方法能够在少量样本表格分类中优于最先进的方法。消融研究进一步验证了该方法基于原则的数据提炼过程的有效性，并强调了 InsightTab 在利用标记数据和管理偏差方面的优势。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21296", "html_url": "https://arxiv.org/abs/2508.21296", "title": "MyGO: 生存期学习系统中的记忆产生式离线巩固", "title_en": "MyGO: Memory Yielding Generative Offline-consolidation for Lifelong Learning Systems", "authors": "Shihao Ji,Zihui Song", "background": "持续或终身学习旨在开发能够从任务序列中获取新知识而不至于灾难性遗忘已有知识的模型。现有方法往往依赖存储先前任务的样本（经验回放）或采用复杂的正则化项来保护已有权重。然而，这些方法面临数据隐私、存储限制和当任务差异较大时性能下降的挑战。", "innovation": "提出了MyGO（Memory Yielding Generative Offline-consolidation）终身学习框架，该框架受到生物清醒-睡眠循环的启发。在“清醒”阶段，系统快速学习新任务并通过生成性记忆模型（G-mem）捕捉数据分布。在“睡眠”阶段，系统进入离线状态，利用所有学到的G-mem模型生成伪数据（“梦境”）并通过知识蒸馏将新知识和旧知识整合进核心特征提取器中，从而避免存储任何原始数据，仅保留生成性模型，这在隐私和存储效率方面具有显著优势。", "conclusion": "我们研究了MyGO在计算机视觉（Split-MNIST）和自然语言处理（Split-AG News）基准上的表现，并将其与顺序微调基线进行比较。结果表明，MyGO显著减轻了灾难性遗忘并维持了跨任务的高平均准确率，证明了该框架的有效性和通用性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21505", "html_url": "https://arxiv.org/abs/2508.21505", "title": "Spiking Decision Transformers: Local Plasticity, Phase-Coding, and Dendritic Routing for Low-Power Sequence Control", "title_en": "Spiking Decision Transformers: Local Plasticity, Phase-Coding, and Dendritic Routing for Low-Power Sequence Control", "authors": "Vishal Pandey,Debasmita Biswas", "background": "基于Transformer架构的强化学习代理在序列决策任务中表现出色，但由于其对密集矩阵操作的依赖，它们不适合能源受限和边缘导向的平台。突触神经网络能够提供极低功耗和事件驱动的推理，但以前的研究尚未将突触动力学与基于回报的序列建模无缝结合。", "innovation": "我们提出了Spiking Decision Transformer (SNN-DT)，它将漏电流-积分-放电神经元嵌入到每个自注意力模块中，并通过近似梯度进行端到端训练，还结合了生物启发的三因素可塑性、基于事件的相位编码位置嵌入和轻量级树突路由模块。我们的实现不仅在经典控制基准（CartPole-v1，MountainCar-v0，Acrobot-v1，Pendulum-v1）上达到了或超过了标准Decision Transformer的性能，而且每次决策只发射不到十个突触脉冲，这表明推理能量降低了超过四个数量级。", "conclusion": "通过将序列建模与神经形态效率相结合，SNN-DT 打开了通往嵌入式和可穿戴设备上实时、低功耗控制的道路。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21554", "html_url": "https://arxiv.org/abs/2508.21554", "title": "全面评估可穿戴纺织ECG紧身衣的信号质量：一项性别平衡研究", "title_en": "Comprehensive Signal Quality Evaluation of a Wearable Textile ECG Garment: A Sex-Balanced Study", "authors": "Maximilian P. Oppelt,Tobias S. Zech,Sarah H. Lorenz,Laurenz Ottmann,Jan Steffan,Bjoern M. Eskofier,Nadine R. Lang-Richter,Norman Pfeiffer", "background": "当前可穿戴设备在监测心电图（ECG）信号方面面临噪声和运动伪影问题，这影响了信号的准确性。本研究旨在通过优化电极位置和设计，开发一种新的可穿戴纺织服装，以减少这些干扰，提高ECG信号质量。", "innovation": "本研究引入了一种创新的可穿戴纺织服装，其电极放置方式旨在最大限度减少噪声和运动伪影，从而提高ECG信号的保真度。研究采用了性别平衡的全面评估方法，招募了15名健康男性和15名健康女性参与者，涵盖了多种生理参数、心率变量分析、机器学习分类任务以及形态学分析等多方面评估手段，以确保设备适用于不同性别和生理特征的个体。研究表明，该纺织系统在心律和形态学分析方面与参考设备具有高度一致性，表现出稳健的分类性能，并能识别重要的性别特异性影响因素。这表明纺织ECG紧身衣在可穿戴健康技术中具有实际的实用性和可行性。", "conclusion": "研究结果证实，纺织ECG紧身衣能够有效减少噪声和运动伪影，提高ECG信号的质量，具有性别特异性的生理影响因素识别能力，并且在实际应用中具有潜力。此外，研究强调在穿戴式健康技术中纳入性别特定设计考虑的重要性，以实现更公平和可靠的卡片诊断。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21547", "html_url": "https://arxiv.org/abs/2508.21547", "title": "真正必要的数据是什么？推荐系统推理数据最小化可行研究", "title_en": "What Data is Really Necessary? A Feasibility Study of Inference Data Minimization for Recommender Systems", "authors": "Jens Leysen,Marco Favier,Bart Goethals", "background": "数据最小化是一项法律规定，要求个人数据处理仅限于实现特定目的所必需的数据量。对于依赖大量个人数据的推荐系统而言，实现该规定仍然是一个重大挑战。因此，该文尝试探讨通过最小化隐式反馈推理数据来实现数据最小化的可行性。文中分析了多种最小化技术，并探讨了影响这些技术有效性的关键因素。研究表明，在不显著影响性能的情况下，可以大幅减少推理数据。然而，实际应用中，该技术的可行性由两方面因素决定：技术设置（如性能目标、所选模型）和用户特征（如历史长度、偏好复杂度）。因此，虽然该文建立了数据最小化的技术可行性，但强调了它在实际应用中的挑战性，并指出由于技术和用户背景的依赖性，难以制定普遍适用的数据‘必要性’标准。", "innovation": "文章提出了一个新的问题表述，分析了多种最小化技术，并考察了这些技术有效性的关键因素。展示了在不严重牺牲性能的情况下，可以显著减少隐式反馈推理数据的可行性。同时，指出了该技术在实际应用中的依赖性和挑战性，从而强调了建立普遍适用的数据‘必要性’标准的难度。", "conclusion": "虽然研究展示了数据最小化的技术可行性，但在实际应用中依然面临挑战。技术设置和用户特征对数据最小化的有效性有显著影响，因此数据‘必要性’难以制定出普遍适用的标准。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21618", "html_url": "https://arxiv.org/abs/2508.21618", "title": "基于物理信息的高光谱成像光谱建模", "title_en": "Physics-Informed Spectral Modeling for Hyperspectral Imaging", "authors": "Zuzanna Gawrysiak,Krzysztof Krawiec", "background": "高光谱成像（HSI）技术采集的是多维度的光谱信息，这对于分析复杂的环境和材料具有重要价值。传统的HSI处理方法通常需要大量标注数据，并且往往难以明确地将复杂的光谱信号分解为独立的基础函数。", "innovation": "提出了一种名为PhISM的物理信息指导的深度学习架构，这是一种无监督学习方法，能明确分离高光谱观测并利用连续基函数模型化。相比之前的模型，在分类和回归基准测试中表现出色，且仅有少量标注数据需求。此外，PhISM的潜在表示具有解释性，为理解复杂的光谱现象提供了额外见解。", "conclusion": "该研究通过一种新颖的物理信息指导的无监督深度学习架构PhISM，显著提升了高光谱成像数据的处理和模型化能力，降低了对标注数据的依赖，同时提供了对复杂光谱信号更深入的理解。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21559", "html_url": "https://arxiv.org/abs/2508.21559", "title": "物理信息神经网络在智能电网模拟中的局限性研究", "title_en": "Limitations of Physics-Informed Neural Networks: a Study on Smart Grid Surrogation", "authors": "Julen Cestero,Carmine Delle Femine,Kenji S. Muro,Marco Quartulli,Marcello Restelli", "background": "智能电网建模面临着数据稀缺和物理一致性的重要挑战。传统数据驱动方法难以同时满足这两个方面的需求。物理信息神经网络（PINNs）通过直接将物理定律整合到学习框架中，提供了一种转变性的解决方案，能够解决传统数据驱动方法的这些问题。", "innovation": "本文通过比较物理信息神经网络与其他数据驱动模型（如XGBoost、随机森林和线性回归）在智能电网动态建模中的表现，展示了PINNs在物理约束和电网稳定方面具有显著优势，特别是在插值、交叉验证和 episodic 轨迹预测等关键实验中。训练过程中仅通过物理损失函数（如功率平衡、操作约束和电网稳定性）训练PINNs，证明了其出色的泛化能力，优于数据驱动模型，并在动态电网操作中实现较低的MAE，同时确保在各种控制情况下可靠地捕获状态转换，而传统模型则表现出不可靠的性能。", "conclusion": "本研究表明，尽管物理信息神经网络在极端操作条件下略有性能下降，但它们在物理可行性的严格保证上表现优异，对于关键能源系统至关重要。这些结果支持将物理信息神经网络作为智能电网替代方案的范式转变工具，结合数据驱动的灵活性和第一原理的严谨性，推动实时电网控制和可扩展数字孪生的发展，强调了能源系统中的物理感知架构的必要性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21695", "html_url": "https://arxiv.org/abs/2508.21695", "title": "基于激活子空间的异常分布检测", "title_en": "Activation Subspaces for Out-of-Distribution Detection", "authors": "Barış Zöngür,Robin Hesse,Stefan Roth", "background": "当前，确保深度模型在实际应用中的可靠性涉及识别分布外（OOD）样本。传统的OOD检测方法主要依赖于原始激活值来区分在大分布偏移（Far-OOD）情况下的ID和OOD数据。研究表明，在较小的分布偏移（Near-OOD）情况下，仅考虑显著子空间可以更好地避免激活空间的干扰。本研究旨在提出一种新的OOD检测方法，通过分解激活值为显著和非显著部分，以实现更精确的检测效果。", "innovation": "本研究创新地提出了一种名为ActSub的新型OOD检测方法。该方法利用分类头部权重矩阵的奇异值分解，将模型的激活值分解为显著和非显著部分，分别最大化和最小化对最终分类输出的贡献。研究发现，显著子空间在大分布偏移情况下能更有效地区分ID和OOD数据，而非显著子空间在小分布偏移情况下则可能导致干扰。", "conclusion": "将上述两种情况结合的方法，获得了在多个标准OOD检测基准上的最佳性能，实现了当前最先进的成果。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21650", "html_url": "https://arxiv.org/abs/2508.21650", "title": "从情感与时间特征预测社交媒体参与度", "title_en": "Predicting Social Media Engagement from Emotional and Temporal Features", "authors": "Yunwoo Kim,Junhyuk Hwang", "background": "研究团队提出了一个机器学习方法，旨在从情感和时间特征方面预测社交媒体上的参与度，包括评论和点赞的数量。数据集包含600首歌曲，并分别为这些歌曲进行了愉悦度、唤醒度和相关情感指标的注释。研究人员利用HistGradientBoostingRegressor的多目标回归模型对对数转换后的参与度比率进行了训练，以解决目标值偏斜的问题。评估模型性能时采用了自定义的十倍精度评估标准和标准回归指标，如决定系数（R^2）。研究结果表明，情感和时间元数据与现有的浏览量，可以有效地预测未来参与度，但点赞的R^2值达到0.98，而评论的R^2值仅为0.41，这表明点赞主要是由容易抓取的情绪和曝光信号驱动的，而评论则依赖于不在当前特征集中表示的其他因素。", "innovation": "该研究创新点在于利用机器学习模型根据情感和时间特征预测社交媒体上的评论和点赞数量，特别使用了多目标回归模型处理目标值偏斜问题，并通过自定义的评估标准和标准的回归指标进行综合评估。", "conclusion": "情感和时间元数据与现有的浏览量结合，能够有效地预测未来社交媒体参与度。尽管总参与度预测效果较好，但在预测评论数量上存在较大挑战，表明当前方法在捕捉评论驱动因素方面仍有不足。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21620", "html_url": "https://arxiv.org/abs/2508.21620", "title": "引入概率决策算法的分析介绍", "title_en": "Introduction to the Analysis of Probabilistic Decision-Making Algorithms", "authors": "Agustinus Kristiadi", "background": "决策理论提供了在不同类型的不确定性下进行选择的原理性方法。这些理论的应用算法已经在多种实际问题中取得了成功，包括材料和药物发现。这些算法之所以受欢迎是因为它们能够适应性地收集信息以更好地在未来做出决策，从而实现高效的数据流程。在实验成本高昂的科学发现领域，这些算法能够显著降低实验成本。然而，文献中的理论分析对于非专家来说往往难以理解。因此，该文试图提供一个易于理解的关于常用概率决策算法的理论分析的自包含介绍，包括臂赛跑算法、贝叶斯优化和树搜索算法。这仅需要对概率论和统计学有基本的了解，以及一些关于高斯过程的基本知识便足够了。", "innovation": "该文旨在为非专家提供一个关于常用概率决策算法理论分析的易于理解的介绍，这样的工作在现有文献中不常见。它对非专家也非常友好，只需要掌握基本的概率论和统计学知识，以及一些高斯过程的基本知识，即可理解这些理论分析的内容。这使得这些先进的算法能够被更广泛的非专家群体所理解和运用，推动这些理论在实际应用中的进展。", "conclusion": "该文中明确表示，通过提供一系列理论分析算法的资源，文章旨在改进这一领域的理论理解和应用。通过这种方式，新的算法可以被迅速地发现和开发出来，最终在各个科学领域对实验进行优化，并促进这一学术领域的发展。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21722", "html_url": "https://arxiv.org/abs/2508.21722", "title": "通过人口焦虑的断点预测推断重大事件效果", "title_en": "Inferring Effects of Major Events through Discontinuity Forecasting of Population Anxiety", "authors": "Siddharth Mangalik,Ojas Deshpande,Adithya V. Ganesan,Sean A. P. Clouston,H. Andrew Schwartz", "background": "评估特定社区的心理健康效应对于公共卫生政策至关重要。仅预测心理健康得分提供的见解有限，而像从经济学中的纵向回归断点设计（LRDD）这样的准实验设计可以帮助研究人员从观察数据中推导出更可能具有因果性的效果。LRDD旨在推断特定时间事件导致的结果变化（例如，焦虑得分的断点）。作者在此提出了一种将LRDD扩展到统计学习框架的方法，其中未来的断点（即时间特定的转变）和斜率变化（即线性轨迹）可以根据位置的历史得分、动态协变量和其他运行评分以及外生变量进行估计。", "innovation": "提出了将LRDD扩展到统计学习框架的方法，旨在估计未来断点和斜率变化，这种方法考虑了位置历史得分、动态协变量和外生变量的影响。这种新方法在预测美国各郡从COVID-19事件中焦虑的断点时取得了显著改善，尤其是在集成外生和动态协变量的模型中。其结果表明，外生和动态协变量的集成比传统的静态社区表示有显著提高。还探讨了断点预测在估算未来或假设事件对特定社区的个别效应方面的新可能性。", "conclusion": "该方法展示了在预测焦虑断点（$r=+0.46$）和斜率（$r=+0.65$）方面的显著改进，并揭示了评估病毒等重大事件对社区心理健康的特定影响的可能性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21739", "html_url": "https://arxiv.org/abs/2508.21739", "title": "基于MPSoC板的神经网络加速：集成SLAC的SNL、Rogue软件和Auto-SNL", "title_en": "Neural Network Acceleration on MPSoC board: Integrating SLAC's SNL, Rogue Software and Auto-SNL", "authors": "Hamza Ezzaoui Rahali,Abhilasha Dave,Larry Ruckman,Mohammad Mehdi Rahimifar,Audrey C. Therrien,James J. Russel,Ryan T. Herbst", "background": "随着LCLS-II自由电子激光器X射线脉冲在束线实验中的应用频率提高到高达1~MHz，以及探测器数据吞吐量超过1 TB/s，管理和传输如此庞大的数据流提出了巨大挑战，因为传输和存储基础设施变得非常昂贵。传统的机器学习（ML）方法引入了过高的延迟，使其不适合高速实验环境。SLAC为解决这些挑战开发了SLAC神经网络库（SNL），这是一个专门的框架，旨在将实时ML推理模型部署在现场可编程门阵列（FPGA）上。SNL的关键特性是能够动态更新模型权重，而无需重新合成FPGA，这增强了适应性学习应用的灵活性。为了进一步提高易用性和可访问性，作者引入了Auto-SNL，这是一个Python扩展，简化了将基于Python的神经网络模型转换为SNL兼容的高级综合代码的过程。", "innovation": "SLAC开发了SLAC神经网络库（SNL），这是一个专门为现场可编程门阵列（FPGA）上部署实时机器学习推理模型而设计的专门框架。SNL的一个关键特性是能够动态更新模型权重，而不需要重新合成FPGA，这增强了适应性学习应用的灵活性。此外，作者引入了Auto-SNL，这是一个Python扩展，简化了将基于Python的神经网络模型转换为SNL兼容的高级综合代码的过程。SNL与当前最先进的工具（hls4ml）进行基准测试，展示了在大多数测试的架构中实现了具有竞争力或更优延迟的同时，有时还能节省FPGA资源。", "conclusion": "这项适配演示了SNL的多功能性，为高能物理、医学成像、机器人技术等领域研究人员和学术界开辟了新的机会。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21810", "html_url": "https://arxiv.org/abs/2508.21810", "title": "QR-LoRA：基于QR分解的低秩适应方法，用于大型语言模型高效微调", "title_en": "QR-LoRA: QR-Based Low-Rank Adaptation for Efficient Fine-Tuning of Large Language Models", "authors": "Jessica Liang,Anirudh Bharadwaj", "background": "由于大型语言模型（LLMs）的规模日益庞大，参数效率高的微调技术变得越来越重要。低秩适应（LoRA）作为一种有效方法，通过对预训练权重应用低秩更新来减少可训练参数数量。然而，标准LoRA直接学习更新因子，而近期的一些变体则是先通过预训练权重的SVD（奇异值分解）来初始化矩阵，但这种方法在大规模模型上代价高昂，且生成的奇异向量难以解释。", "innovation": "本文提出了一种基于QR分解进行低秩适应的方法（QR-LoRA），从预训练权重矩阵中提取正交基，将LoRA更新表示为这些基向量的线性组合，仅训练标量系数，这种方式不仅使适应过程具有明确的结构，而且极大地减少了参数数量。实验表明，QR-LoRA在GLUE任务上的性能与全微调、标准LoRA和SVD-LoRA相当，但参数量减少了超过1000倍，比起标准LoRA，参数量少了约77倍。", "conclusion": "QR-LoRA通过基于QR分解的低秩适应方法，在保持性能的同时，大幅减少了参数数量，为大型语言模型的高效微调提供了新的解决方案。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21772", "html_url": "https://arxiv.org/abs/2508.21772", "title": "UniMLR: 建模隐含类别显著性以进行多标签排序", "title_en": "UniMLR: Modeling Implicit Class Significance for Multi-Label Ranking", "authors": "V. Bugra Yesilkaynak,Emine Dari,Alican Mertan,Gozde Unal", "background": "现有的多标签排序（MLR）框架只能利用标签二元划分出的正负集信息，因此无法利用正标签之间的排序信息，这是我们在本文中提出的新颖的MLR方法所要填补的空白。", "innovation": "我们提出了UniMLR，一种新型的MLR范式，它通过利用正标签之间的排序信息，将隐含类别的相关/重要性值建模为概率分布，而不仅仅是将其视为同等重要。此外，我们通过引入八个带有不同显著性决定因素生成的合成数据集（Ranked MNISTs），解决了MLR数据集稀缺性和注释偏差的问题，为实验提供了更为丰富和可控的环境。", "conclusion": "统计结果显示，我们的方法能够准确学习正标签排名的表示，它与地面真实情况一致，并且与底层的显著性值成比例。我们还在真实世界和合成数据集上进行了全面的实证实验，证明了我们提出的框架的价值。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21571", "html_url": "https://arxiv.org/abs/2508.21571", "title": "随机梯度方法在宽两层物理信息神经网络中收敛性", "title_en": "Convergence of Stochastic Gradient Methods for Wide Two-Layer Physics-Informed Neural Networks", "authors": "Bangti Jin,Longjun Wu", "background": "物理信息神经网络（PINNs）是一种流行的求解偏微分方程的神经网络解决方案。实践中通常使用随机梯度下降类型算法进行训练，因此随机梯度下降的收敛保证是非常重要的。", "innovation": "本文建立了宽两层PINNs在高概率意义下，对于一般激活函数的随机梯度下降/流在训练过程中的线性收敛性。这一结果扩展了之前分析梯度下降的结果[18]。分析的关键在于确保训练过程中具有适当Gram矩阵的正定性，以处理随机优化方法引入的动力随机性。", "conclusion": "分析揭示了优化过程的动力学，并为随机算法训练的神经网络提供了收敛性保证。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21785", "html_url": "https://arxiv.org/abs/2508.21785", "title": "从异构数据中学习统一表示以实现鲁棒心率建模", "title_en": "Learning Unified Representations from Heterogeneous Data for Robust Heart Rate Modeling", "authors": "Peng Yang,Zhengdong Huang,Zicheng Xie,Wentao Tian,Jingyu Liu,Lunhong Dong", "background": "心率预测对于个性化的健康监测和健身至关重要，但在现实世界中面临一个关键挑战：数据异构性。这个问题在来源异构性（来自具有不同功能集的设备市场的碎片化设备市场）和用户异构性（个体和活动之间的不同生理模式）两个关键维度上反映出来。现有的方法要么忽略了设备特有的信息，要么无法建模用户的特定差异，这限制了它们在现实世界中的表现。", "innovation": "本文提出了一种框架，该框架可以学习两者异构性的无关潜表征，使下游预测器能够在异构数据模式下保持一致性。具体来说，我们引入了一种随机特征丢弃策略来处理来源异构性，使模型能够应对各种功能集。为了处理用户异构性，我们采用了时间敏感的注意力模块来捕捉长期的生理特征，并使用对比学习目标来构建一个区分性表示空间。我们还创建并公开发布了一个新的基准数据集ParroTao，以反映实际数据的异构性特点。", "conclusion": "在ParroTao和公共的FitRec数据集上的评估表明，我们的模型分别在原有基准线上取得了17%和15%的显著性能提升。此外，学习到的表征显示出强大的区分力，并且一个下游应用任务进一步验证了我们模型的实际价值。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21815", "html_url": "https://arxiv.org/abs/2508.21815", "title": "在Rényi差分隐私下实现希尔伯特-施密特独立性以实现公平和隐私的数据生成", "title_en": "Achieving Hilbert-Schmidt Independence Under Rényi Differential Privacy for Fair and Private Data Generation", "authors": "Tobias Hyrup,Emmanouil Panagiotou,Arjun Roy,Arthur Zimek,Eirini Ntoutsi,Peter Schneider-Kamp", "background": "随着GDPR和HIPAA等隐私法规的普及以及针对AI的责任框架如《AI法案》的出现，真实世界数据的负责任使用面临着越来越多的限制。合成数据生成作为一种风险意识下的数据共享和模型开发的解决方案，特别适合敏感领域，如医疗健康中的表格数据。为了在这些场景中应对隐私和公平性的问题，本文提出了一种新的方法FLIP（Fair Latent Intervention under Privacy guarantees），这是一种基于转录器的变分自动编码器，额外添加了潜在扩散，用于生成异构表格数据。FLIP方法在生成数据时还引入了公平性理念，并使用RDP兼容的均衡采样，在潜在空间和输入空间中分别处理公平性和隐私性问题", "innovation": "FLIP解决了公平性和隐私性的双重挑战。它在潜在空间中使用Centroed Kernel Alignment (CKA)对神经元激活模式进行对齐，这是一种扩展Hilbert-Schmidt Independence Criterion (HSIC)的相似性度量方法。这种方法鼓励潜在表示与受保护特征之间的统计独立性。此外，FLIP采用Rényi差分隐私 (RDP) 约束在训练过程中确保隐私，并使用RDP兼容的均衡采样来在多个抽样率上考虑群体特定的噪音水平，以确保公平性", "conclusion": "实验结果表明，FLIP能够显著提高在不同任务条件下的公平性，在差分隐私约束下也表现出色，适用于各种下游任务。对于任务无关的公平性问题，FLIP也能提供显著改善。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21082", "html_url": "https://arxiv.org/abs/2508.21082", "title": "ImmunoAI：使用热力学-流体力学描述符和三维几何界面拓扑的增强梯度机器学习加速抗体发现", "title_en": "ImmunoAI: Accelerated Antibody Discovery Using Gradient-Boosted Machine Learning with Thermodynamic-Hydrodynamic Descriptors and 3D Geometric Interface Topology", "authors": "Shawnak Shivakumar,Matthew Sandora", "background": "人类元鼻病毒（hMPV）对儿童、老年人和免疫受损人群构成严重威胁。传统的抗体发现流程需要10至12个月，限制了其在快速应对疫情爆发中的应用。因此，需要一种缩短设计周期的方法来进行结构指导下的快速应对病毒爆发。", "innovation": "引入了ImmunoAI，这是一种机器学习框架，通过使用梯度增强模型预测热力学、流动力学和3D拓扑界面描述符来加速抗体发现。通过构建包含213个抗体-抗原复合物的数据集，提取几何和物理化学特征，并训练LightGBM回归器以高精度预测结合亲和力。对SARS-CoV-2结合对进行微调后，进一步减少了均方根误差（RMSE），并使用AlphaFold2预测hMPV A2.2变体的3D结构，识别出了两个亲和力预测值为皮摩尔的最优抗体，且这些抗体靶向关键变异位点（G42V和E96K），成为实验测试的理想候选。", "conclusion": "ImmunoAI缩短了设计周期并能够进行更快的结构指导下的病毒爆发反应。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21086", "html_url": "https://arxiv.org/abs/2508.21086", "title": "由量子启发的概率度量定义了一个完备的、通用的统计学习空间", "title_en": "Quantum-inspired probability metrics define a complete, universal space for statistical learning", "authors": "Logan S. McCarty", "background": "概率分布的比较是自然科学、社会科学和计算科学领域中的核心挑战。现有的方法，如最大均值偏差(MMD)，在高维度和非紧空间中表现挣扎。", "innovation": "提出了量子概率度量(QPMs)，通过在希尔伯特空间中的正、单位迹算子空间嵌入概率测度而得到。这种构造扩展了核方法，并在非紧空间上弥补了MMD不完备的缺陷。QPMs作为积分概率度量(IPMs)，具有统一近似所有在$\boldsymbol{\text{R}}^n$上有界且一致连续的函数的双重功能，增强了在高维度上对分布差异的敏感性。对于经验分布，可以通过特征值方法容易地计算QPMs，并具有适用于学习和优化的解析梯度。尽管在大数据集（$O(n^3)$ vs. $O(n^2)$）计算上更为密集，但QPMs作为MMD的直接替代品能够显著提高性能。实验结果展示了其在经典生成建模任务中的优势。通过结合量子力学丰富的数学框架和经典的概率论，这一方法为分析和操作概率测度奠定了坚实基础。", "conclusion": "结合了量子力学和经典概率论的富集数学框架，为统计学习提供了强大的工具，能够有效分析和操作概率测度。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21076", "html_url": "https://arxiv.org/abs/2508.21076", "title": "Pep2Prob基准：基于MS$^2$的蛋白质组学中的肽片段离子概率预测", "title_en": "Pep2Prob Benchmark: Predicting Fragment Ion Probability for MS$^2$-based Proteomics", "authors": "Hao Xu,Zhichao Wang,Shengqi Sang,Pisit Wajanasara,Nuno Bandeira", "background": "蛋白质是细胞功能的关键执行者，也是大多数药物靶点的基础，因此对蛋白质的分析是理解健康和疾病中人类生物学的核心。串联质谱（MS$^2$）是蛋白质组学中主要的分析技术，通过离子化、碎片化肽，并利用产生的质量谱来识别和定量生物样本中的蛋白质。在MS$^2$分析中，肽碎片离子概率预测起着关键作用，它可以通过质量谱中的强度信息来增强肽的识别准确性。当前的方法主要依赖于碎片化过程的一般统计信息，假设所有肽的碎片概率是均匀的，但这在生物化学原理上是简化的，限制了准确的预测能力。", "innovation": "作者提出了Pep2Prob，这是第一个全面的肽特异性碎片离子概率预测的数据集和基准。该数据集包含608,780个独特的前体（每种前体是一个肽序列和电荷状态的配对）的碎片离子概率统计信息，总结自超过1.83亿个高质量、高分辨率的HCD MS$^2$光谱，这些光谱的肽分配和裂解标注已通过验证。该基准提供了使用简单统计规则和基于学习的方法建立的基线性能。模型利用肽特定信息显著优于仅使用全局裂解统计信息的先前方法。进一步的基准测试表明，随着模型能力的增加，肽-碎片化关系展现出复杂的非线性性质，需要复杂的人工智能方法来应对。", "conclusion": "Pep2Prob是首个专门针对肽特定碎片离子概率预测的综述性数据集和基准，展示了利用肽特定信息的模型在肽片段离子概率预测上显著优于仅使用全局统计的方法。未来的研究表明，肽-碎片化关系的复杂非线性特征需要先进的机器学习方法来进行高效的预测。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21113", "html_url": "https://arxiv.org/abs/2508.21113", "title": "R-4B：通过二态退火和强化学习激励通用自动思考能力在MLLMs中的应用", "title_en": "R-4B: Incentivizing General-Purpose Auto-Thinking Capability in MLLMs via Bi-Mode Annealing and Reinforce Learning", "authors": "Jie Jiang,Qi Yang,Bolin Ni,Shiming Xiang,Han Hu,Houwen Peng", "background": "多模态大型语言模型（MLLMs）具有逐步推理能力，在解决复杂推理问题方面表现出色。然而，对于不需要复杂推理就可以解决的简单问题来说，这种推理过程是冗余的。为了解决这种低效率问题，提出了一种自思考的MLLM（R-4B），可以根据问题的复杂度适配地决定是否进行思考。", "innovation": "R-4B的核心理念是通过二态退火赋予模型思考和不思考的能力，并使用Bi-mode Policy Optimization (BPO) 以提高模型确定是否激活思考过程的准确性。该模型首先在涉及各种主题的精心制作的数据集上进行训练，包含思考模式和不思考模式的数据样本。然后在改进的GRPO框架下进行第二阶段的训练，迫使策略模型针对每个输入问题生成来自两个模式的响应。实验结果显示，R-4B在25个具有挑战性的基准测试中达到了最先进的性能。", "conclusion": "R-4B在大多数任务中超过了Qwen2.5-VL-7B，在推理密集型基准测试中与更大规模的模型Kimi-VL-A3B-Thinking-2506 (16B) 性能相当，同时具有较低的计算成本。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21167", "html_url": "https://arxiv.org/abs/2508.21167", "title": "RARR : 通过在线搜集近表面音频实现稳健的现实生活中的活动识别", "title_en": "RARR : Robust Real-World Activity Recognition with Vibration by Scavenging Near-Surface Audio Online", "authors": "Dong Yoon Lee,Alyssa Weakley,Hui Wei,Blake Brown,Keyana Carrion,Shijia Pan", "background": "四分之一的痴呆症患者独居，致使家庭成员不得不从远处承担护理责任。尽管许多研究人员开发了远程监控解决方案来减轻护理需求，但仍存在隐私保护、活动识别和新用户及环境上的模型泛化能力的局限。结构振动传感系统是不显眼的解决方案，已在受控环境下通过表面活动引起振动精确监测人类信息（例如身份识别和活动识别）。但在用户家中部署时，现有解决方案需要大量标记数据才能实现精确的活动识别。我们的可扩展解决方案利用从近表面音频中合成的数据进行预训练，并利用非常有限的数据进行微调，从而创建了用于日常生活跟踪的稳健框架。", "innovation": "我们的解决方案通过从近表面音频中合成数据进行预训练，并利用非常有限的数据进行微调，为日常活动识别创造了一个稳健的框架。这种方法显著减少了对大量标注数据的依赖，并能有效地在用户家中部署。", "conclusion": "本研究提出了RARR（从近表面音频中收集实现稳健活动识别）方案，用于家庭中的日常活动监测。通过这种方案，可以有效减轻护理需求，同时确保隐私保护和活动识别的准确性，特别是在模型的泛化能力方面。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21179", "html_url": "https://arxiv.org/abs/2508.21179", "title": "合成简历以构建和测试公平招聘工具", "title_en": "Synthetic CVs To Build and Test Fairness-Aware Hiring Tools", "authors": "Jorge Saldivar,Anna Gatzioura,Carlos Castillo", "background": "随着算法招聘在某些领域变得越来越必要，这些系统通常使用算法从海量求职者中筛选和排序简历，但研究表明，这些技术可能会无意中引入偏见，导致基于年龄、性别或国籍等因素的歧视。为了测量、缓解和解释算法招聘中的偏见，以及在部署前评估和比较公平性技术，需要反映多样化背景人群特征的数据集。然而，合适的特征数据集并不存在，为解决此局限，本研究提出了一种合成简历数据集的构建方法，并通过数据捐赠活动收集真实材料来建模特征。此外，本研究还展示了一个包含1,730份简历的合成数据集，希望能作为算法招聘歧视研究的标准基准数据集。", "innovation": "本研究创新性地开发了一种基于真实材料合成简历数据集的方法，为评估和比较不同的公平性技术提供了新的基准数据集。此方法不仅解决了现有数据集无法满足需求的问题，也为算法招聘领域的公平性研究提供了宝贵的资源。", "conclusion": "本文提出了一种合成简历数据集的构建方法，并通过数据捐赠活动收集真实材料作为模型基础，成功构建了包含1,730份简历的合成数据集。该数据集已被视为算法招聘歧视研究的标准基准。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21088", "html_url": "https://arxiv.org/abs/2508.21088", "title": "先进深度学习技术在全景牙科X光图像分类中的应用", "title_en": "Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images", "authors": "Alireza Golkarieh,Kiana Kiashemshaki,Sajjad Rezvani Boroujeni", "background": "本文研究了深度学习方法在全景X光图像中自动分类牙科状况的应用。研究利用了一个由1,512张牙科X光片组成的数据集，其中包括11,137个由专家验证的注释，覆盖四种状况：填充、龋齿、种植体和阻生牙。实验采用了五折交叉验证，评估了三种方法：自定义的卷积神经网络（CNN）、卷积神经网络特征提取与传统分类器的混合模型以及预训练模型的微调。", "innovation": "研究通过将CNN特征提取与ensemble分类器相结合，改进了对形态学相似状况的分类。具体而言，混合CNN随机森林模型取得了85.4%的准确率，优于自定义CNN基线的74.3%，VGG16预训练模型表现最好，准确率为82.3%。这表明，结合CNN特征提取与ensemble分类器的方法为自动牙科诊断支持提供了一种可行的途径。", "conclusion": "综合实验结果，混合模型在对形态相似状况进行区分时表现出色，且具有高效可靠的性能。研究结果建议，结合基于CNN的特征提取与ensemble分类器是一种实用的自动牙科诊断支持途径，但仍需更大的数据集和进一步的临床验证。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21205", "html_url": "https://arxiv.org/abs/2508.21205", "title": "基于模型预测最优运输的多机器人路径规划与调度 (MPC-OT)", "title_en": "Multi-robot Path Planning and Scheduling via Model Predictive Optimal Transport (MPC-OT)", "authors": "Usman A. Khan,Mouhacine Benosman,Wenliang Liu,Federico Pecora,Joseph W. Durham", "background": "在多个机器人需要在有障碍的共同空间中导航到多个目标的场景下，如果直接按照每个机器人分配目标并规划路径，可能导致路径重叠，从而造成死锁现象。现有的解决方法往往无法确保路径规划后的路径不重叠，这限制了多机器人系统在复杂环境中的高效协作。", "innovation": "本文提出了一个基于最优运输理论和模型预测控制的新方法，用于多机器人路径规划和调度。通过将路径规划空间离散化并构建一个$K \times K$的成本结构，算法可以自动生成最少成本且不重叠的路径。此外，该方法还引入了重新规划和模型预测控制机制，以处理不可避免的轨迹重叠情况和机器人动力学问题，确保了高效率和安全性。", "conclusion": "与传统的路径规划方法相比，本文提出的模型预测最优运输(MPC-OT)方法在最坏情况下的计算复杂度为$\text{O}(K^3\text{log }K)$，对于行为良好的问题是$\text{O}(K^2\text{log }K)$，同时保证了路径的最小成本和不重叠。这种方法为进一步提高多机器人系统在复杂环境中的性能提供了可能，尤其在需要实时协调和适应动态环境变化的情况下表现尤为突出。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21263", "html_url": "https://arxiv.org/abs/2508.21263", "title": "肺部放射影像低数据量深度主动学习肺部疾病严重程度分类：在类不平衡存在的情况下采用更少数据进行学习", "title_en": "Deep Active Learning for Lung Disease Severity Classification from Chest X-rays: Learning with Less Data in the Presence of Class Imbalance", "authors": "Roy M. Gabriel,Mohammadreza Zandehshahvar,Marly van Assen,Nattakorn Kittisut,Kyle Peters,Carlo N. De Cecco,Ali Adibi", "background": "该研究旨在减少基于胸部X光片（CXR）对肺部疾病严重程度分类所需的标记数据量，特别是在类不平衡的情况下。文章收集了2020年1月至11月Emory Healthcare附属医院963名（平均年龄59.2岁，其中481名为女性）患者的2319份胸部X光片，所有患者均确诊为COVID-19。通过3到6名认证的放射科医生独立标注为正常、中度或严重，最终使用贝叶斯神经网络（BNN）近似和加权损失函数的深度主动学习进行疾病严重程度分类。", "innovation": "该研究创新性地应用了深度主动学习结合贝叶斯神经网络（BNN）近似和加权损失函数，通过不同的采样策略（如熵采样和均值标准差采样）从标记数据中迭代选择最有信息量的样本，以减少所需的数据量，同时缓解类不平衡问题，并保证或超过诊断性能。", "conclusion": "熵采样在二分类（正常 vs 患病）中使用15.4%的数据达到了93.7%的准确率（AU ROC 0.91）。在多分类情况下，均值标准差采样使用23.1%的数据获得了70.3%的准确率（AU ROC 0.86）。这些方法有效减少了标记数据的需求，同时克服了类不平衡的问题，并保持或超过了诊断性能。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21165", "html_url": "https://arxiv.org/abs/2508.21165", "title": "基于数据驱动的血管血流动力学物理基础降低阶模型分叉处理", "title_en": "Data-Driven Bifurcation Handling in Physics-Based Reduced-Order Vascular Hemodynamic Models", "authors": "Natalia L. Rubio,Eric F. Darve,Alison L. Marsden", "background": "三维（3D）有限元仿真心血管流动为心血管医学提供了高保真的预测，但由于计算成本高限制了临床实用性。降阶模型（ROMs）为高效计算提供了替代方案，但这些模型在分叉处的精度较低，尤其是在复杂流体力学不能由标准牛顿流动假设充分捕捉的情况下。", "innovation": "本文提出了一种增强的数值框架，集成机器学习预测的分叉系数到零维（0D）血流动力学ROMs中，以提高精度同时保持计算效率。该方法利用神经网络从分叉几何预测压力-流量关系，并引入线性和二次电阻以及感性效应。此外，采用无量纲化减小训练数据需求，并进行先验流速分劈预测以提高分叉表征。基于优化策略将RRI模型整合到0D模型中。", "conclusion": "该混合数值方法使实时血流动力学建模成为可能，适用于临床决策支持、不确定性量化和心血管生物医学工程中的数字孪生。实验结果表明，RRI方法在所有树状结构和雷诺数范围内，入口压力误差从标准0D模型的54 mmHg（45%）降至25 mmHg（17%），简化版RRI（RI）模型则降至31 mmHg（26%）的误差。增强的0D模型尤其适用于高雷诺数和广泛的血管网络。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21332", "html_url": "https://arxiv.org/abs/2508.21332", "title": "量子增强自然语言生成：基于混合量子-经典架构的多模型框架", "title_en": "Quantum-Enhanced Natural Language Generation: A Multi-Model Framework with Hybrid Quantum-Classical Architectures", "authors": "Chi-Sheng Chen,En-Jui Kuo", "background": "随着量子计算在自然语言处理应用中的逐渐兴起，本研究对比评估了量子文本生成模型与传统Transformer/MLP架构。该研究在五个不同的数据集上进行了系统实验，比较了五种不同模型（包括Transformer、QKSAN、QRWKV和QASA），以全面评价这些模型在生成文本质量上的表现。", "innovation": "本研究引入了基于混合量子-经典架构的多模型框架，通过实验证明了量子灵感模型在特定场景下具有竞争力。特别地，QKSAN和QRWKV在某些任务上达到了与传统Transformer模型相当甚至更优的性能，尤其是在词汇多样性和无重复率方面表现出色。", "conclusion": "传统Transformer模型在整体性能上具有优势，平均 perplexity 最低，BLEU-1 分数最高。然而，量子灵感模型在特定场景下表现出色，特别是QKSAN和QRWKV在词汇多样性方面达到了完美分数，并且QKSAN在无重复率方面表现优异。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21320", "html_url": "https://arxiv.org/abs/2508.21320", "title": "多 ontology 集成与双轴传播在医学概念表示中的应用", "title_en": "Multi-Ontology Integration with Dual-Axis Propagation for Medical Concept Representation", "authors": "Mohsen Nayebi Kerdabadi,Arya Hadizadeh Moghaddam,Dongjie Wang,Zijun Yao", "background": "目前医学ontology图谱在电子健康记录中的应用主要通过结构化的关联关系，将外部知识映射到医学代码上。现有的研究多关注单一ontology系统的领域知识集成，或多个ontology系统的独立集成，但缺乏多ontology系统的统一学习结构。这导致概念表示学习主要局限于同ontology内部关系，而忽视了跨ontology的联系。", "innovation": "本文提出了LINKO框架，这是一种通过大型语言模型增强的集成ontology学习框架，能够同时利用多个ontology图谱，并通过在同异构ontology系统内及跨系统进行知识的双轴传播，提升医学概念表示学习。该框架首先通过large language model对ontology概念嵌入进行图检索增强初始化，并在同层次内部垂直传播和跨层次水平传播中联合学习医学概念。", "conclusion": "通过在两个公开数据集上的广泛实验，证明了LINKO的性能优于最先进的基线方法。作为插件编码器，LINKO可以与现有的EHR预测模型兼容，在数据有限和稀有疾病预测场景中展现出更高的鲁棒性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21225", "html_url": "https://arxiv.org/abs/2508.21225", "title": "层叠式SSL特征能否在儿童语音的零样本ASR中提升性能？", "title_en": "Can Layer-wise SSL Features Improve Zero-Shot ASR Performance for Children's Speech?", "authors": "Abhijit Sinha,Hemant Kumar Kathania,Sudarsana Reddy Kadiri,Shrikanth Narayanan", "background": "自动语音识别（ASR）系统在处理儿童语音时常常遇到困难，因为儿童语音具有独特的和高度可变的声学和语言特性。近年来，自监督学习（SSL）模型在成人类语音转写方面取得了显著进步，但儿童语音的转写仍是巨大挑战。本研究旨在探讨用Wav2Vec2、HuBERT、Data2Vec和WavLM等最新SSL预训练模型抽取的层间特征是否能提升儿童语音在零样本条件下的ASR性能。研究在WSJCAM0成人口语数据集上进行训练，在PFSTAR儿童口语数据集上进行测试，并使用Kaldi工具集简化构建了一个基于DNN的ASR系统。结果表明，在Wav2Vec2模型的第22层特征被用于儿童语音识别时，Word Error Rate (WER) 达到最低5.15%，较直接零样本解码时的10.65%的WER显著降低了51.64%。年龄分组分析进一步显示出随年龄增长性能持续改善的趋势，即使在低年龄段也观察到显著提升。CMU Kids数据集上的进一步实验也确认了相似趋势，表明该方法具有泛化性。", "innovation": "该研究表明，利用Wav2Vec2、HuBERT、Data2Vec和WavLM等SSL模型抽取的层间特征，能够显著提升儿童语音在零样本条件下的ASR性能。特别是，Wav2Vec2模型的第22层特征对于儿童语音识别具有特别的提升效果，大幅降低了错误率。此外，该研究还发现，年龄分组分析进一步显示出随年龄增长性能持续改善的趋势，即使是低年龄段也观察到显著的提升效果，这为儿童语音的自监督学习提供了新的洞察和发展途径。", "conclusion": "此研究采用自监督学习模型提取的特征在改善儿童语音零样本ASR性能方面具有显著效果，特别是在Wav2Vec2模型的特定层上表现尤为突出，整体提升了儿童语音识别的准确性，尽管年龄不同，但模型仍然显示出优越性。该研究为进一步优化儿童语音处理技术提供了新的途径，并凸显了自监督学习在语言处理领域的潜力。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21372", "html_url": "https://arxiv.org/abs/2508.21372", "title": "通过矩阵分解实现更快速的流从复杂结构推断", "title_en": "Faster Inference of Cell Complexes from Flows via Matrix Factorization", "authors": "Til Spreuer,Josef Hoppe,Michael T. Schaub", "background": "我们考虑了一个推理问题：给定在图中观察到的一系列边流信号，将图提升为一个细胞复杂结构，使得观察到的边流信号可以用该细胞复杂结构上梯度和旋流的稀疏线性组合来表示。之前的研究表明，这个问题的通用形式是NP难问题。因此，本文开发了一种新颖的基于矩阵分解的启发式算法来解决这个问题，虽然在大多数情况下性能略差，但在计算成本上显著降低，特别是在噪声环境中，本文提出的方法在解决方案质量和计算速度上优于之前的最佳方法.", "innovation": "本文提出了一种基于矩阵分解的新型启发式算法，用于解决将观察到的图提升为细胞复杂结构的问题。该算法能够为观察到的边流信号提供一个稀疏且可解释的表示。在计算实验中展现的性能表明，这种方法在大多数情况下具有比前人方法较低的计算成本，同时保持了可接受的性能。特别是在噪声环境中时，新方法在解决方案质量和计算速度方面表现更优.", "conclusion": "通过开发基于矩阵分解的新启发式算法，本文显著降低了计算成本，为观察到的图信号提供了一个稀疏且可解释的表示。实验结果表明，该方法虽然在大多数情况下性能略差，但在噪声环境中表现更优，提供了解决该问题的新思路。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21482", "html_url": "https://arxiv.org/abs/2508.21482", "title": "HSFN: 层级选择构建异构集成以检测假新闻", "title_en": "HSFN: Hierarchical Selection for Fake News Detection building Heterogeneous Ensemble", "authors": "Sara B. Coutinho,Rafael M.O. Cruz,Francimaria R. S. Nascimento,George D. C. Cavalcanti", "background": "人们因心理偏差（如确认偏差）而特别容易相信并传播社交媒体上的假新闻，对公共健康和政治等领域产生严重后果。基于机器学习的事实核查系统已经广泛研究以缓解此问题。其中，集成方法特别有效，通过结合多个分类器来提高鲁棒性。然而，这些方法的性能很大程度上依赖于组成部分分类器的多样性——选择真正多样的模型依然是一个关键挑战，尤其是在模型倾向于学习冗余模式时。", "innovation": "本文提出了一种新颖的自动分类器选择方法，该方法优先考虑多样性和性能。首先计算分类器之间的成对多样性并应用层次聚类来组织它们到不同粒度级别的组中。然后通过层次选择探索这些层级，选择每个级别的一组分类器，每组代表一个独特的内部池多样性。确定最多样化的池用于集成构建。选择过程综合了反映每个分类器性能的评估指标，以确保集成也具有良好的泛化能力。", "conclusion": "实验使用来自不同应用领域的六个数据集中的40种异构分类器进行。该方法与拐点启发式方法和最先进的基线方法进行了比较，结果显示，该方法在六个数据集中的两个数据集上达到了最高的准确性。项目实施细节可在此仓库中找到: this https URL。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21524", "html_url": "https://arxiv.org/abs/2508.21524", "title": "Compute-in-Memory CNN加速器中二进制权重多比特激活量化", "title_en": "Binary Weight Multi-Bit Activation Quantization for Compute-in-Memory CNN Accelerators", "authors": "Wenyong Zhou,Zhengwu Liu,Yuan Ren,Ngai Wong", "background": "Compute-in-memory (CIM)加速器作为一种提高卷积神经网络（CNNs）能效的有希望的方法已经出现。将CNN部署到CIM平台通常需要对网络权重和激活进行量化以满足硬件限制。现有方法要么在准确度下降的情况下优先考虑硬件效率，通过二值权重和激活量化，要么为了获得更高的准确度而使用多比特权重和激活但牺牲部分效率。", "innovation": "提出了CNN在CIM基础上的新型二进制权重多比特激活（BWMA）方法。其创新点包括：为每一层推导出闭合形式的权重量化解，显著改善了二进制权重的表现能力；开发了一种可微分的激活量化函数，可以接近理想的多比特函数，避免了广泛的最优设置搜索。", "conclusion": "通过在CIFAR-10和ImageNet数据集上的全面实验，显示BWMA比现有方法取得了显著的准确度改进，分别在数据集上取得了1.44%-5.46%和0.35%-5.37%的准确度提升。此外，硬件仿真结果表明，4-bit激活量化在硬件成本和模型性能之间达到了最佳平衡。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21377", "html_url": "https://arxiv.org/abs/2508.21377", "title": "大型语言模型的挑战与应用：GPT和DeepSeek家族模型的比较", "title_en": "Challenges and Applications of Large Language Models: A Comparison of GPT and DeepSeek family of models", "authors": "Shubham Sharma,Sneha Tuli,Narendra Badam", "background": "大型语言模型（LLMs）正在各个行业中改变人工智能的发展，但它们的开发和部署仍然很复杂。本文回顾了构建和使用LLMs的16个关键挑战，并比较了两个具有独特方法的先进模型：由OpenAI发布的封闭源代码GPT-4o（2024年5月更新）和DeepSeek-V3-0324（2025年3月），这是一个大型开源专家混合模型。通过这次比较，展示了封闭源代码模型（稳健的安全性，精细调整的可靠性）与开源模型（效率，适应性）之间的权衡。该文还探索了LLM在不同领域的应用（从聊天机器人和编程工具到医疗保健和教育），指出了每个应用场景最适合的模型特性。", "innovation": "本文批评了构建和使用大型语言模型的关键挑战，并通过比较OpenAI的闭源GPT-4o和DeepSeek-V3-0324（一个大型开源Mixture-of-Experts模型），展示了封闭源代码模型和开源模型之间的权衡。此外，文章还探讨了LLM在不同领域的应用，强调了每个应用场景最适合的模型特性。", "conclusion": "本文旨在帮助AI研究人员、开发者和决策者理解当前LLM的功能、限制和最佳实践。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21569", "html_url": "https://arxiv.org/abs/2508.21569", "title": "L3Cube-MahaSTS: 一个马拉地语句子相似性数据集和模型", "title_en": "L3Cube-MahaSTS: A Marathi Sentence Similarity Dataset and Models", "authors": "Aishwarya Mirashi,Ananya Joshi,Raviraj Joshi", "background": "当前，句子相似性（STS）数据集主要用于评估和训练模型，但这些数据集多为英文。而对于马拉地语等低资源语言，相关的ST斯数据集和模型相对缺乏，影响了低资源语言在自然语言处理领域的应用和发展。", "innovation": "该研究提出了MahaSTS数据集和MahaSBERT-STS-v2模型。MahaSTS是一个由人类标注的马拉地语句子对数据集，包含16,860对句子，每对句子都附有0-5分制的连续相似度评分。通过均衡分布于六种评分桶，确保了监督的均匀性，从而减少了标签偏差并增强了模型的稳定性。MahaSBERT-STS-v2模型是在该数据集上进行微调的句子BERT模型，用于回归型相似度评分。实验结果表明，MahaSTS提高了在马拉地语句子相似性任务上的训练效果，突出了人类标注、目标微调和结构化监督在资源匮乏环境中的重要性。", "conclusion": "研究表明，MahaSTS数据集和MahaSBERT-STS-v2模型能够有效提升马拉地语句子相似性任务的效果，为低资源语言的自然语言处理提供了重要支持。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21418", "html_url": "https://arxiv.org/abs/2508.21418", "title": "标准化的多层组织图谱在大规模玻片图像档案中增强的人工智能集成和搜索标准", "title_en": "Standardized Multi-Layer Tissue Maps for Enhanced Artificial Intelligence Integration and Search in Large-Scale Whole Slide Image Archives", "authors": "Gernot Fiala,Markus Plass,Robert Harb,Peter Regitnig,Kristijan Skok,Wael Al Zoughbi,Carmen Zerner,Paul Torke,Michaela Kargl,Heimo Müller,Tomas Brazdil,Matej Gallo,Jaroslav Kubín,Roman Stoklasa,Rudolf Nenutil,Norman Zerbe,Andreas Holzinger,Petr Holub", "background": "全玻片图像（WSI）是通过扫描包含生物样本（如组织切片或细胞样本）的整个玻片而生成的高分辨率数字图像。这些图像可以用于人工智能算法开发、数字化展示、共享和分析，广泛应用于病理学、肿瘤学、神经学、兽医学、血液学、微生物学、皮肤科、药理学、毒理学和免疫学等多个领域。在构建用于训练或验证人工智能算法的数据集时，需要了解WSI中包含的内容，但目前没有通用的标准方法来确定这些信息，导致用途受限。", "innovation": "本文提出了一种通用框架，用于生成WSI的二维索引图，以及根据不同应用领域进行特定表征的方法。该方法通过临床病理学领域演示，在不同目录之间实现了兼容性。具体来说，该方法为每个WSI数据集增加了详细的组织图，提供了关于WSI内容的细粒度信息，并将这些信息分为三层：来源、组织类型和病理变化。", "conclusion": "通过在WSI目录、机器学习和基于图的WSI表示中的具体示例，本文证明了所提出的标准的优势和可应用性，从而增强了大规模WSI档案中人工智能的集成和搜索能力。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21531", "html_url": "https://arxiv.org/abs/2508.21531", "title": "自适应生成矩匹配网络以改善对依赖结构的学习", "title_en": "Adaptive generative moment matching networks for improved learning of dependence structures", "authors": "Marius Hofert,Gan Yao", "background": "本文研究了如何通过自适应带宽选择过程来选择混合核宽度，以优化最大均值偏差（MMD）方法在生成矩匹配网络（GMMNs）中的应用，旨在提升copula随机数生成器的学习效果。研究人员通过训练损失的相对误差增加了核的数量，并使用验证损失的相对误差作为提前停止训练的准则，初步证明了这种方法在训练时间相似的前提下，显著提升了训练性能，尤其是在验证MMD轨迹、样本和验证MMD值方面的表现。\n", "innovation": "本文提出了一种适应性带宽选择程序，用于MMD中的混合核，该程序可以根据训练过程中相对误差的增加来动态调整核的数量，并以验证损失的相对误差作为提前停止训练的条件。这种方法能够在保持与标准GMMNs相近的训练时间的同时，显著提高训练性能，特别是在验证MMD轨迹、样本和MMD值方面的表现。此外，该研究还通过三个应用案例展示了自适应生成矩匹配网络（AGMMNs）相较于普通GMMNs和典型参数copula模型的优势，并首次评估了高维copulas（高达100维）上伪随机和准随机样本的收敛速度。\n", "conclusion": "研究结果表明，AGMMNs在几个应用案例中表现出色，不仅在标准误差、MMD轨迹和样本质量方面优于GMMNs，而且在预测模型方面也超过了传统的参数copula模型。特别是在对标准普尔500指数和富时100指数进行了数据处理后，AGMMNs在copula模型的拟合和应用中表现出了显著的改进。\n"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21484", "html_url": "https://arxiv.org/abs/2508.21484", "title": "生物医学研究中的数据驱动数字孪生发现", "title_en": "Data-driven Discovery of Digital Twins in Biomedical Research", "authors": "Clémence Métayer,Annabelle Ballesta,Julien Martinelli", "background": "近年来，技术的进步极大地扩展了高通量生物数据集的可用性，使可靠设计生物医学系统或患者数字孪生成为可能。这些计算工具表示控制扰动或药物反应的关键反应网络，并可指导药物发现和个性化治疗。然而，它们的开发依然依赖于繁琐的人工数据整合过程，因此迫切需要自动化方法。虽然物理领域的数据驱动系统发现方法有着干净的数据和明确的监管法则为背景，但这种方法在生物学中的应用却面临许多独特的挑战。本文回顾了从生物时间序列自动推断数字孪生的方法论，主要涉及符号回归法和稀疏回归法。根据八个生物学和方法学挑战进行评估，即噪声/不完整数据，多种条件，先验知识整合，潜在变量，高维度，未观察变量的导数，候选库设计，和不确定性量化。稀疏回归法一般优于符号回归法，特别是在使用贝叶斯框架时。我们还强调了深度学习和大型语言模型的新兴作用，它们能够支持先前知识的创新整合，但此类方法的可靠性和一致性还有待改进。虽然没有一种方法可以解决所有这些挑战，但是我们认为从基于化学反应网络的机制基础、贝叶斯不确定性量化以及深度学习的生成能力和知识整合能力的混合和模块框架中将会带来进展。为了支持这些方法的发展，我们还提出了一个基准框架，用于在所有挑战中评估方法。", "innovation": "本文提出了一种创新性的方法，即结合基于化学反应网络的机制基础、贝叶斯不确定性量化以及深度学习的生成能力和知识整合能力，以混合和模块化的框架促进数字孪生的学习和开发。此外，强调深度学习和大型语言模型在知识整合方面的作用，并提出了评估方法的基准框架。", "conclusion": "虽然当前没有一种方法可以解决生物医学研究中数字孪生开发的所有挑战，但是通过结合基于化学反应网络的机制基础、贝叶斯不确定性量化以及深度学习的生成能力和知识整合能力的方法，未来有望在数字孪生的开发中取得进展。提出了一个基准框架来评估这些方法，促进技术进步。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21236", "html_url": "https://arxiv.org/abs/2508.21236", "title": "在与右翼民粹主义投票相关的网络结构中揭示规模人口学网络嵌入", "title_en": "Population-Scale Network Embeddings Expose Educational Divides in Network Structure Related to Right-Wing Populist Voting", "authors": "Malte Lüken(1 and 2 and 3),Javier Garcia-Bernardo(4),Sreeparna Deb(5),Flavio Hafner(1 and 3),Megha Khosla(5) ((1) Netherlands eScience Center, (2) University of Amsterdam, (3) Erasmus University Rotterdam, (4) Utrecht University, (5) Delft University of Technology)", "background": "行政登记数据可用于构建人口规模的网络，这些网络的边反映了个人之间的共享社会背景。通过机器学习，可以将这些网络编码成数值表示（嵌入），自动捕捉个体在网络中的位置。研究者为荷兰全体人口创建了嵌入，这些嵌入反映了五个共享的背景：邻里、工作、家庭、家庭居住地和学校。", "innovation": "研究者通过将嵌入进行稀疏化和正交化处理，使得一个嵌入维度与右翼民粹主义投票结果密切相关。将这个维度映射回人口网络，揭示了不同学校联系和教育程度之间结构上的差异。", "conclusion": "本研究在方法论上贡献是通过展示如何使规模人口学网络嵌入变得可解释，同时通过将结构网络差异与教育水平联系起来，揭示了右翼民粹主义投票的相关性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21654", "html_url": "https://arxiv.org/abs/2508.21654", "title": "我发誓我无事可干：模型窃取攻击的设计与评估", "title_en": "I Stolenly Swear That I Am Up to (No) Good: Design and Evaluation of Model Stealing Attacks", "authors": "Daryna Oliynyk,Rudolf Mayer,Kathrin Grosse,Andreas Rauber", "background": "模型窃取攻击威胁了作为服务提供的机器学习模型的机密性。尽管这些模型被保密，恶意一方仍可以通过查询模型来标记数据样本并训练自己的替代模型，侵犯了知识产权。尽管该领域的新型攻击不断被发表，但其设计和评估尚未标准化，这使得比较之前的成果和评估在该领域中的进步变得困难。论文是首个为此目标提供设计和评估模型窃取攻击的建议。在此基础上，我们研究了依赖于训练替代模型的最大攻击群组，即针对图像分类模型的攻击。我们提出了第一个全面的威胁模型，并开发了一个攻击比较框架。此外，我们分析了相关工作中攻击设置以了解哪些任务和模型被研究得最多。根据我们的发现，我们提出了攻击开发之前、期间和之后的最佳实践，并推导出对模型窃取攻击的评估的一份详尽的开放研究问题清单。我们的发现和建议也适用于其他问题领域，从而建立了首个通用的模型窃取攻击评估方法。", "innovation": "论文首次提出了设计和评估模型窃取攻击的建议，研究了针对图像分类模型的最大攻击群组，提出首个全面的威胁模型和攻击比较框架，并推导出评估模型窃取攻击的一份详尽的开放研究问题清单。这些方法也适用于其他问题领域，建立了首个通用的模型窃取攻击评估方法。", "conclusion": "基于我们的发现和建议，制定了攻击开发的最佳实践，并推导出评估模型窃取攻击的一系列开放研究问题，从而确立了首个通用的模型窃取攻击评估方法，适用于其他问题领域。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21255", "html_url": "https://arxiv.org/abs/2508.21255", "title": "随机测度下的加权支撑点：可解释的生成模型替代方法", "title_en": "Weighted Support Points from Random Measures: An Interpretable Alternative for Generative Modeling", "authors": "Peiqi Zhao,Carlos E. Rodríguez,Ramsés H. Mena,Stephen G. Walker", "background": "支持点通过使用较小的代表性点集来概括大规模数据集，并可以在不需要访问完整数据集的情况下进行数据操作，如蒙特卡洛积分。这类方法为原始数据提供了一个紧凑且信息丰富的表示。本文在此基础上提出了一种基于随机加权支撑点的生成建模框架，其中加权策略受到狄利克雷过程和贝叶斯抽样启发。", "innovation": "该研究提出了基于随机加权支撑点的生成模型框架，这种方法无需依赖概率模型假设或神经网络架构，能够产生多样且可解释的样本集。该方法通过凸-凹过程（CCP）开发了高效优化算法。实验结果表明，与生成对抗网络（GANs）或去噪扩散概率模型（DDPMs）相比，该方法可以在较低的计算成本下生成高质量且多样化的输出。", "conclusion": "随机加权支撑点提供了一种原理性的、可扩展且可解释的生成模型替代方法。它们能够生成真正插值式的样本，保留了数据结构的内在特性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21652", "html_url": "https://arxiv.org/abs/2508.21652", "title": "边缘设备上的机器智能：基于强化学习的可解释性心电图模式定位", "title_en": "Machine Intelligence on the Edge: Interpretable Cardiac Pattern Localisation Using Reinforcement Learning", "authors": "Haozhe Tian,Qiyu Rao,Nina Moutonnet,Pietro Ferraro,Danilo Mandic", "background": "匹配滤波器因其高效率和可解释性在信号模式定位中广泛使用。然而，它们在低信噪比（SNR）的信号中效果不佳，尤其是在边缘设备上记录的信号中，噪声模式可能会在滤波器长度有限的情况下与目标信号高度相似。例如，在耳-心电图（ear-ECG）中，心电信号被削弱并受到大量失真的干扰。这种背景下，本文研究了如何通过引入增强学习来改进信号模式定位方法。", "innovation": "本文提出了顺序匹配滤波器（SMF），这是一种用强化学习代理设计的一系列滤波器来替代传统单一匹配滤波器的新方案。通过将滤波器设计视为顺序决策过程，SMF能够自适应地设计针对特定信号的滤波器序列，并通过揭示驱动决策的关键模式保持其可解释性。", "conclusion": "本文提出的SMF框架在两个具有挑战性的实际心电图数据集上的R-峰检测和生理状态分类性能达到最先进的水平，展示了其在临床决策支持方面的强大潜力。同时，该模型也可以扩展应用于需要从噪声干扰信号中准确识别模式的其他广泛应用场景中。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21615", "html_url": "https://arxiv.org/abs/2508.21615", "title": "适应变化：概念漂移下建筑热动力学建模中持续学习与迁移学习的比较", "title_en": "Adapting to Change: A Comparison of Continual and Transfer Learning for Modeling Building Thermal Dynamics under Concept Drifts", "authors": "Fabian Raisch,Max Langtry,Felix Koch,Ruchi Choudhary,Christoph Goebel,Benjamin Tischler", "background": "当前，当可用数据有限时，迁移学习（TL）是最有效的建筑热动力学建模方法。TL涉及通过微调预训练模型来适应特定目标建筑。但随着更多运营测量数据的收集，如何在初始微调后继续改进模型仍不明确。在建模动态变化系统时，机器学习文献中使用持续学习（CL）方法来更新模型。TL也可以通过在每次更新步骤中重用预训练模型并使用新测量数据进行微调来应对这一挑战。然而，缺乏关于如何随时间纳入新测量数据来提高预测精度并处理概念漂移问题（即动态变化）的研究。", "innovation": "本文比较了几种CL和TL策略以及从头训练模型的方法，以评估其在建筑运行期间热动力学建模的性能。研究使用代表中欧地区单户住宅的5-7年模拟数据，该数据包含了从翻新和改变居住情况引起的概念漂移情景。本文提出了一种新的CL策略（季节性记忆学习，SML），该策略在没有概念漂移和有概念漂移情况下分别比基准初始微调提高了28.1%和34.9%的准确性，同时保持了较低的计算成本。", "conclusion": "提出的CL策略在处理概念漂移问题时表现出比现有方法更高的准确性，同时保持较低的计算成本。这一策略为建筑热动力学建模提供了改进的方法，特别是在数据有限和系统动态变化的情况下。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21672", "html_url": "https://arxiv.org/abs/2508.21672", "title": "基于激励辅助引导的后悔玩家软诱导框架", "title_en": "A Soft Inducement Framework for Incentive-Aided Steering of No-Regret Players", "authors": "Asrin Efe Yorulmaz,Raj Kiriti Velicheti,Melih Bastopcu,Tamer Başar", "background": "本文研究了一个中介增强的两人正常形式博弈中的一个转向问题，其中中介旨在通过信息和激励设计引导玩家选择特定的行动组合。最初，研究了哪些博弈是可以通过信息和激励设计成功转向的。接着，表明只有通过信息设计是无法引导玩家到达任意行动组合的，同时也证明在低成本支付条件下，即使有信息设计，也做不到这一点。", "innovation": "提出了一个增强算法，通过在循环博弈开始前的一次性信息设计阶段，将之前的互动转换为斯坦克尔伯格博弈。研究证明，这种增强算法往往能够以常数因子提高玩家行动组合收敛到目标的速度，并提供了理论和实验证据来支持这一点。", "conclusion": "证明了在低成本支付情况下，即使有信息设计也无法引导玩家到达任意行动组合，提出了增强信息设计的方法，此方法使得博弈的收敛速度提高了常数倍，并通过理论和实验证明了方法的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21769", "html_url": "https://arxiv.org/abs/2508.21769", "title": "在野外的领域泛化：从领域感知表示中分离分类", "title_en": "Domain Generalization in-the-Wild: Disentangling Classification from Domain-Aware Representations", "authors": "Ha Min Son,Zhe Zhao,Shahbaz Rezaei,Xin Liu", "background": "评价领域泛化（DG）基础模型如CLIP具有挑战性，因为针对大规模网络的预训练数据可能涵盖了大部分现有的基准测试。当前的评估手段可能不够具有挑战性，也无法充分测试真正未见的数据场景。为了更好地评估CLIP在真实世界环境下的DG能力，研究设计了两种方法：一是针对经过ImageNet微调的CLIP在33个具有量化出域得分的多样性数据集上进行评估；二是通过未学习技术让CLIP“忘记”某些领域作为一种近似手段。研究发现，CLIP在更多出域数据集上表现显著下降。", "innovation": "研究提出了CLIP-DCA（领域解耦分类和增强领域感知表示），它强调增强领域感知作为有效领域不变分类的前提条件。CLIP-DCA通过一个分离的领域头和合成的多样化领域数据来识别并增强CLIP编码器中的领域感知能力，同时通过领域特征解耦来促进领域不变分类。", "conclusion": "CLIP-DCA在评估中表现出显著改善，特别是在更出域的数据集上，优于现有的方法。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21402", "html_url": "https://arxiv.org/abs/2508.21402", "title": "SatDINO: 深入探究遥感领域自监督预训练", "title_en": "SatDINO: A Deep Dive into Self-Supervised Pretraining for Remote Sensing", "authors": "Jakub Straka,Ivan Gruber", "background": "自监督学习在遥感领域中快速发展，由于遥感图像数据量大且大量数据未标注。本文研究使用DINO这种方法进行遥感图像的预训练，旨在提高遥感影像的表示学习能力。", "innovation": "本文提出了SatDINO模型，专门针对遥感影像的表示学习。实验结果表明，SatDINO在多个数据集的多种测试设置中表现优于其他基于掩码自编码器的方法，并且在多个基准测试中达到竞争性结果。此外，还进行了详细的消融研究，评估了SatDINO各组件的性能，并提出了一些新的增强方法，如新的GSD编码方式和自适应视图采样。", "conclusion": "SatDINO在多个遥感影像数据集上的实验结果显示其超过了同类最先进的方法，并且本文提出的增强方法可以在SatDINO模型上独立使用。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21693", "html_url": "https://arxiv.org/abs/2508.21693", "title": "为何止步于单词？通过行级OCR揭示更大的图景", "title_en": "Why Stop at Words? Unveiling the Bigger Picture through Line-Level OCR", "authors": "Shashank Vempati,Nishit Anand,Gaurav Talebailkar,Arpan Garai,Chetan Arora", "background": "传统的光学字符识别（OCR）技术将每个字符分离再进行识别，这导致字符分割容易出错，并且在利用语言模型时缺乏上下文信息。近年来，序列到序列（Seq2Seq）翻译技术的进步，使得现代OCR技术能够首先检测单词，然后每次输入一个单词到模型中，直接输出完整单词作为字符序列，这种改进促进了语言模型的更好利用并跳过了易出错的字符分割步骤。然而，这一转变使字符级别的瓶颈转移到了单词分割上，因此，该研究提出了一种自然和逻辑的从单词级OCR向行级OCR的过渡。这种提案可以避免单词检测中的错误，同时提供更大的句子上下文，以更好地利用语言模型。实验表明，所提出的技术不仅提高了OCR的准确性，还提高了效率。我们没有在彻底的文献调研中发现有关从单词级到行级OCR的公共数据集，因此，我们还提供了一个经过精心整理包含251个英文字页面图像和行级注解的数据集，端到端准确率提高了5.4%，这清晰地展示了向行级OCR过渡的优势，特别是在文档图像上。相比基于单词的管道系统，效率提高了4倍。随着大型语言模型的持续改进，我们的方法还具有利用这些进展的潜力", "innovation": "提出了从单词级OCR向行级OCR过渡的思路。利用行级OCR可以避免单词分割错误，提供更大的上下文信息，更好地利用语言模型，并提高了OCR技术的准确性和效率。还贡献了一个行级标注的数据集，包含251个英文字页面图像，支持行级OCR的训练和基准测试", "conclusion": "通过行级OCR可显著提高OCR的准确性和效率，尤其是在文档图像上。所提出的技术不仅在准确率上有所提高，效率也提升了4倍。此外，随着语言模型的进步，该方法未来有望更好地利用这些技术进步。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.19470", "html_url": "https://arxiv.org/abs/2305.19470", "title": "低相干矩阵的标签嵌入", "title_en": "Label Embedding via Low-Coherence Matrices", "authors": "Jianxin Zhang,Clayton Scott", "background": "标签嵌入是一种用于多类分类问题的框架，每个标签由固定维度的唯一向量表示，训练过程中模型输出与正确标签的向量匹配。这种技术在极端分类和零样本学习中取得了成功，并提供了计算和统计上的优势，但其理论基础还知之甚少。本文在极端多类分类的背景下，对标签嵌入进行了分析。", "innovation": "本文提出了在极端多类分类背景下标签嵌入的分析，证明了在一定的低相干性条件下，标签嵌入的统计惩罚会消失，并支持了一个简单、可扩展且易于并行的算法。", "conclusion": "本文的分析结果表明，标签嵌入在大规模应用中具有有效性和适用性，显示出在计算和统计效率之间的权衡，通过低相干性矩阵进一步揭示了标签嵌入的优势。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21773", "html_url": "https://arxiv.org/abs/2508.21773", "title": "无监督视频连续学习的非参数深度嵌入聚类方法", "title_en": "Unsupervised Video Continual Learning via Non-Parametric Deep Embedded Clustering", "authors": "Nattapong Kurpukdee,Adrian G. Bors", "background": "视频作为一种复杂且丰富的时空媒体信息，在许多应用中被广泛使用，但在无监督连续学习中尚未得到充分探索。以往的研究仅集中在监督连续学习上，依赖于标签和任务边界的已知知识，但获取有标签的数据成本高且不切实际。这导致了无监督视频连续学习（uVCL）这一空缺被研究以解决这些问题。uVCL由于处理视频时所需的额外计算和内存需求更具有挑战性。作者提出一个通用基准实验协议，旨在研究无监督视频数据类别学习（每个任务期间的不结构化视频数据），并引入一种基于未监督视频变换网络提取的深度嵌入视频特征的核密度估计（KDE）作为非参数概率数据表示。通过引入新颖性检测标准，动态扩展内存簇，以在连续任务学习过程中捕捉新的知识。并且利用从先前任务中的迁移学习作为当前学习任务的知识传递初始状态，从而实质性地改善了模型性能。这些数据来自三项标准的视频动作识别数据集，包括UCF101、HMDB51和Something-to-Something V2，以上实验过程均未使用标签或类边界信息进行监督。", "innovation": "提出了一种无监督视频连续学习的非参数深度嵌入聚类方法。具体来说，引入了核密度估计（KDE）作为非参数数据表示，用于深入挖掘视频数据的特征。并且引入新颖性检测标准和动态扩展内存簇的方法以支持连续的任务学习过程。此外，利用从先前任务中的迁移学习作为当前学习任务的知识传递初始状态，这种方式能够提高模型在连续任务学习中的表现。这项工作填补了无监督视频连续学习领域的空白，提供了有效的解决方案，并解决了传统的数据有标签依赖的问题，更加适应实际应用场景的需求。该方法在多个标准数据集上进行了深入评估，证明了其有效性和可行性。", "conclusion": "我们提出了一种新的无监督视频连续学习的方法，采用非参数的深度嵌入聚类，能够从未标记的数据中学习，通过引入基于核密度估计（KDE）的数据表示方法，并结合迁移学习技术，提升了连续任务学习中的模型性能。实验结果表明，该方法在多个视频动作识别标准数据集上取得了显著的效果，证明了该方法的可行性和有效性，未来可以进一步扩展应用场景。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21663", "html_url": "https://arxiv.org/abs/2508.21663", "title": "使用通用机器学习原子势进行表面稳定性建模：一项全面的断裂能量基准测试研究", "title_en": "Surface Stability Modeling with Universal Machine Learning Interatomic Potentials: A Comprehensive Cleavage Energy Benchmarking Study", "authors": "Ardavan Mehdizadeh,Peter Schindler", "background": "机器学习原子势（MLIPs）已通过在量子力学精度和经典模拟效率之间架起桥梁，彻底改变了计算材料科学。尽管MLIPs在预测宏观性质方面取得了显著成功，但尚未有系统性评估研究能评估这些通用MLIPs（uMLIPs）在预测断裂能量方面的表现，而断裂能量作为一个关键性质对断裂、催化、表面稳定性和界面现象具有重要影响。", "innovation": "本研究提供了一个全面的基准测试，评估了19个最先进uMLIPs在预测断裂能量方面的表现。此外，研究揭示了训练数据组成对模型性能的影响，表明适当训练数据集的生成至关重要。", "conclusion": "研究结果表明，应该着重于生成能够捕捉关键物理现象的战略性训练数据集。简单的架构在合适的训练数据集上训练可以达到复杂的变压器模型相当的准确性，同时提供10-100倍的计算速度加倍。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21797", "html_url": "https://arxiv.org/abs/2508.21797", "title": "DynaMark: 工业机床控制器中动态水印的一种强化学习框架", "title_en": "DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers", "authors": "Navid Aftabi,Abhishek Hanchate,Satish Bukkapatnam,Dan Li", "background": "工业4.0高度网络化的机床控制器（MTC）是重放攻击的首选目标，这些攻击使用过时的传感器数据操作执行器。当前的动态水印方案假设线性高斯动力学，并使用恒定的水印统计特性，使其容易受到MTC的时间变化和部分专有行为的影响。", "innovation": "我们提出了DynaMark，一个强化学习框架，将动态水印建模为马尔可夫决策过程（MDP）。该框架在线学习一个自适应策略，动态调整零均值高斯水印的协方差，无需系统知识。DynaMark最大化一个动态平衡控制性能、能量消耗和检测置信度的独特奖励函数。为了实现在线检测置信度更新，开发了一种贝叶斯信念更新机制，适用于具有线性动力学的系统。在西门子Sinumerik 828D控制器的数字孪生体上，DynaMark相比恒定方差基准减少了70%的水印能量，同时保持了名义轨迹，并维持了与采样间隔相当的平均检测延迟。实际步进电机测试床进一步验证了这些发现。", "conclusion": "DynaMark在保持控制性能的同时实现了水印能量的显著减少，并维持了较低的检测延迟，超越了现有基准。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21777", "html_url": "https://arxiv.org/abs/2508.21777", "title": "在放射肿瘤学中基准测试GPT-5：可测量的进步，但持续需要专家监督", "title_en": "Benchmarking GPT-5 in Radiation Oncology: Measurable Gains, but Persistent Need for Expert Oversight", "authors": "Ugur Dinc,Jibak Sarkar,Philipp Schubert,Sabine Semrau,Thomas Weissmann,Andre Karius,Johann Brand,Bernd-Niklas Axer,Ahmed Gomaa,Pluvio Stephan,Ishita Sheth,Sogand Beirami,Annette Schwarz,Udo Gaipl,Benjamin Frey,Christoph Bert,Stefanie Corradini,Rainer Fietkau,Florian Putz", "background": "大型语言模型（LLM）在临床决策支持方面展示了巨大潜力。GPT-5是一个专门为肿瘤学用途设计的新型LLM系统。本文通过两种互补的基准测试来评估其性能：一个是放射肿瘤学在职考试（TXIT, 2021），包括300个多项选择题，另一个是由临床专家筛选的60个实际放射肿瘤学病例，涉及多种疾病部位和治疗方案。", "innovation": "使用AIRC放射肿瘤学在职考试（TXIT, 2021）和精心筛选的真实放射肿瘤学病例集作为基准测试方法，以评估GPT-5在肿瘤学领域的性能。GPT-5在TXIT基准测试中获得了92.8%的平均准确率，显著优于GPT-4和GPT-3.5。此外，对于实际临床案例，GPT-5生成的治疗建议在正确性（3.24/4）和全面性（3.59/4）方面得到了高评分，且几乎没有幻觉发生。", "conclusion": "GPT-5在肿瘤学多项选择基准测试表现优异，但在生成实际放射肿瘤学治疗建议时仍有改进空间。虽然幻觉很少见，但实质性错误表明GPT-5生成的建议在临床实施前需要严格的专家监督。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.00342", "html_url": "https://arxiv.org/abs/2402.00342", "title": "联邦学习中的隐私威胁及其对策综述", "title_en": "Survey of Privacy Threats and Countermeasures in Federated Learning", "authors": "Masahiro Hayashitani,Junki Mori,Isamu Teranishi", "background": "联邦学习被认为是一种隐私保护的学习方法，因为训练数据不会在客户端间直接交换。然而，联邦学习中依然存在隐私威胁，各种隐私防护措施也已经被研究。但是，现有的研究中并没有全面且具体地对典型的联邦学习（包括水平联邦学习、垂直联邦学习和迁移联邦学习）中普遍和独特隐私威胁进行分类和描述。", "innovation": "本文对典型的联邦学习（水平联邦学习、垂直联邦学习和迁移联邦学习）中的隐私威胁进行了描述，并探讨了相应的隐私防护措施。", "conclusion": "本文系统地总结了联邦学习中常见的隐私威胁及其防护对策，有助于研究者全面理解联邦学习中的隐私安全问题。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21664", "html_url": "https://arxiv.org/abs/2508.21664", "title": "使用连续排名概率分数进行集合预报轨迹学习：Lorenz '96案例研究", "title_en": "Trajectory learning for ensemble forecasts via the continuous ranked probability score: a Lorenz '96 case study", "authors": "Sagy Ephrati,James Woodfield", "background": "本文通过使用连续排名概率分数（CRPS）作为损失函数来展示轨迹学习在集合预报中的可行性。研究采用两尺度Lorenz '96系统作为案例研究，开发并训练了加性和乘性随机参量化方法，以生成集合预测。背景信息强调了预测方法在短期预报中的优势，特别是对于需要高精度预报的资料同化应用。", "innovation": "提出并使用了连续排名概率分数（CRPS）作为损失函数，以提高预测准确性。开发和训练了加性和乘性随机参量化方法，并通过Lorenz '96系统进行了案例研究。创新点在于这种方法能够产生既准确又锐利的参数化，并且在短期内优于基于导数拟合的参数化方法。", "conclusion": "CRPS基轨迹学习方法能够生成既准确又容易校准的参数化，特别适用于短期预报且在资料同化应用中有潜力成为一种准确性的方法。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.00209", "html_url": "https://arxiv.org/abs/2406.00209", "title": "Mamba状态空间模型是李雅普诺夫稳定的学习者", "title_en": "Mamba State-Space Models Are Lyapunov-Stable Learners", "authors": "John T. Halloran,Manbir Gulati,Paul F. Roysdon", "background": "Mamba状态空间模型（SSMs）在各种任务中已经超过了最先进的（SOTA）大型语言模型（LLMs），并得到了广泛采用。然而，基于递归的深度模型（如SSMs）中反复出现动态的敏感性是稳定学习的主要问题之一。尽管进行了广泛的应用，Mamba的递归动态在常见的调优方法（如混合精度调优和参数高效调优）下的敏感性尚未被探索。实验表明，Mamba LLMs对由混合精度调优和参数高效调优组合引入的变化具有极高的稳定性，而基于Transformer的LLMs在不同组合下可能会出现剧烈的偏差。Mamba的稳定性是由于它们的递归动态，这些动态被证明是稳定的（使用动力系统理论），特别是李雅普诺夫稳定性。作者进一步使用混合精度调优和参数高效调优研究了Mamba LLMs的即席学习（ICL）能力，以补充其他最近的研究工作。", "innovation": "本文证明了Mamba的递归动态是李雅普诺夫稳定的，并提出了使用混合精度调优和参数高效调优来研究Mamba LLMs的即席学习能力，这是对其他研究的补充。这也是首次在常见的调优方法下评估Mamba的递归动态稳定性，为后续研究提供了新的视角。", "conclusion": "本文使用混合精度调优和参数高效调优来研究了Mamba LLMs的即席学习能力，并证明了Mamba的递归动态具有李雅普诺夫稳定性。这为Mamba的应用提供了一定的理论支持，并为未来的研究提供了新的方法和技术。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.17625", "html_url": "https://arxiv.org/abs/2404.17625", "title": "爱丽丝在可微分Wonderland的冒险——第一卷，奇境之旅", "title_en": "Alice's Adventures in a Differentiable Wonderland -- Volume I, A Tour of the Land", "authors": "Simone Scardapane", "background": "文章背景介绍了神经网络的广泛应用，解释了神经网络本质上是由可微分的基本操作组成，并通过自动微分进行优化。文章指出了学习如何编程和与这些模型交互是研究神经网络的重要部分，称为可微分编程。文章的目标读者是对这一领域感兴趣的新手，即成为爱丽丝的读者的新人能够理解可微分编程的基础知识和常用设计模式，如卷积、注意力和循环模块，从而能够理解最新的先进模型，如大型语言模型和多模态架构。", "innovation": "文章创新在于将复杂的神经网络和可微分编程的概念简化为爱丽丝这一角色的冒险故事，使得初学者能够通过直观的方式理解和掌握这些复杂的概念和设计。文章还强调了使用具体工具（如PyTorch和JAX）结合理论和实践教学，帮助读者更好地理解和应用这些知识。", "conclusion": "文章的结论是读者能够通过阅读和理解本指南中的知识，具备了理解并应用多层次的神经网络模型，特别是大型语言模型和多模态模型的能力，从而能够探索可微分编程领域的更高级的主题。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21666", "html_url": "https://arxiv.org/abs/2508.21666", "title": "利用物联网和生成式AI实现气象自适应学习以增强气候韧性教育", "title_en": "Harnessing IoT and Generative AI for Weather-Adaptive Learning in Climate Resilience Education", "authors": "Imran S. A. Khan,Emmanuel G. Blanchard,Sébastien George", "background": "随着气候变化的影响日益显著，气候韧性教育成为提高公众对气候变化认识和应对能力的关键。然而，传统的教育方法往往缺乏地方性且不够动态化，难以满足实际需求的变化和学习者的需求。因此，需要一种能够结合实时气象数据和定制化资源，提供地方性、自适应学习体验的新型平台。", "innovation": "本文介绍了Future Atmospheric Conditions Training System (FACTS)，这是一种结合物联网（IoT）传感器实时收集的大气数据和知识库中精选资源的新颖平台。通过动态生成地方化的学习挑战，系统能够根据学习者的响应提供个性化反馈和支持。此外，利用生成式人工智能（Generative AI）服务器进一步增强了学习体验的个性化和适应性。", "conclusion": "用户评估结果显示，参与者认为该系统使用简单且有助于提升与气候韧性相关知识。该研究表明，将物联网和生成式AI集成到气象自适应学习技术中，在增强教育参与度和促进气候意识方面具有巨大潜力。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.12683", "html_url": "https://arxiv.org/abs/2402.12683", "title": "TorchCP: 一个用于置信预测的Python库", "title_en": "TorchCP: A Python Library for Conformal Prediction", "authors": "Jianguo Huang,Jianqing Song,Xuanning Zhou,Bingyi Jing,Hongxin Wei", "background": "置信预测（CP）是一种能生成带有保证覆盖概率预测区间或集的方法，现有算法已从传统分类器和回归器扩展到了复杂的深度学习模型，比如深度神经网络（DNNs）、图神经网络（GNNs）和大型语言模型（LLMs）。现有的CP库常常缺乏对大规模DL场景的支持和扩展性，因此需要一个专为这些模型设计的库来集成先进的CP算法到深度学习技术中。", "innovation": "TorchCP 是一个基于 PyTorch 的库，旨在将最先进的 CP 算法整合到深度学习技术中，包括基于 DNN 的分类器/回归器、GNN 和 LLM。它包含了约16000行代码，具有100%的单元测试覆盖率和详细的文档，并支持CP特定的训练算法、在线预测和GPU加速批量处理。它的设计使得推理时间能在大型数据集上减少高达90%，同时具备低耦合、全面的高级方法和全GPU可扩展性，从而增强了前沿应用中的不确定性量化能力。", "conclusion": "TorchCP 通过增强模型支持、加强算法集成、提供高性能的推理能力和全面的文档支持，使得研究人员和实践者能够更好地进行大规模深度学习场景中的置信预测，从而提升不确定性量化在多种先进应用中的效果。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.15189", "html_url": "https://arxiv.org/abs/2411.15189", "title": "基于值序估计距离度量学习的类别数据聚类", "title_en": "Categorical Data Clustering via Value Order Estimated Distance Metric Learning", "authors": "Yiqun Zhang,Mingjie Zhao,Hong Jia,Yang Lu,Mengke Li,Yiu-ming Cheung", "background": "聚类是一种流行的机器学习技术，用于数据挖掘以处理和分析数据集，自动揭示样本分布模式。由于类别的数据天然没有像数值数据那样的明确度量空间（如欧几里得距离空间），因此，类别的数据分布通常被低估，从而使聚类分析中包含有价值的信息容易扭曲。本文因此引入了一种新颖的次序距离度量学习方法，通过学习属性值的最佳次序关系并在一条线上量化其距离，从而直观地表示类别属性值。", "innovation": "本文提出了一种基于值序估计的距离度量学习方法。这种度量方法通过聚类的上下文来学习主观创造的定性类别值，解决了模糊性和不确定性的问题，开发了一种新的联合学习范式以交替执行聚类和次序距离度量学习。利用聚类友好的次序学习机制和次序距离和欧几里得距离的同质序性，该方法在类别和混合数据集上实现了卓越的聚类精度。更重要的是，学习到的距离度量极大地降低了理解和管理非直观类别数据的难度。", "conclusion": "通过消融研究、显著性测试、案例如等实验，验证了本文方法的有效性。源代码可以在此获得：https://this.is.the.url/"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.21804", "html_url": "https://arxiv.org/abs/2508.21804", "title": "考虑按时序信息进行治疗效果估计的注意事项", "title_en": "Considerations for Estimating Causal Effects of Informatively Timed Treatments", "authors": "Arman Oganisian", "background": "流行病学研究往往关注于估计一系列治疗决策对生存结果的因果影响。在许多情况下，治疗决策并非在固定的预设随访时间点做出。治疗决策的时间因个体而异，且可能与后续治疗决策和潜在结果有关。文献中对此问题及潜在解决方案的关注不足，且对时序信息导致的问题处理不当，这正是本文所探讨的内容。", "innovation": "本文形式化地阐述了时序信息问题及其忽略可能引起的问题。展示了如何使用g-方法来分析那些按时序信息进行决策的序贯治疗方法。文中指出，在这些情况下，后续治疗决策之间的等待时间可视为时变混杂因素。通过合成的示例说明了不进行这些等待时间调整可能的偏差，并展示了如何在患者在两次治疗期间可能发生死亡或删失的情况下进行调整。讨论了调整和识别在离散时间和连续时间模型之间的联系，并提供了使用公开软件进行实现的指导和示例。", "conclusion": "1) 考虑治疗的时序是进行有效推断的重要因素。\n2) 通过将治疗之间等待时间作为时变混杂因素来进行调整，可以使用g-方法来进行矫正。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.16083", "html_url": "https://arxiv.org/abs/2412.16083", "title": "差分隐私下的联邦扩散建模及其在表数据合成中的应用", "title_en": "Federated Diffusion Modeling with Differential Privacy for Tabular Data Synthesis", "authors": "Timur Sattarov,Marco Schreyer,Damian Borth", "background": "随着各个领域对隐私保护数据处理的需求日益增长，需要开发能够严格遵守隐私标准的合成数据生成解决方案。本文旨在介绍DP-FedTabDiff框架，该框架结合了差分隐私、联邦学习和去噪扩散概率模型，用于生成高质量的合成表格数据。该框架在确保遵守隐私法规的同时，还能保持数据质量。", "innovation": "介绍了DP-FedTabDiff框架，该框架是一个新颖的结合了差分隐私、联邦学习和去噪扩散概率模型的框架，用于生成高质量的合成表格数据。该框架能够在不牺牲数据质量的前提下，显著提高隐私保证，且能够在多种现实世界的数据集上证明其有效性。", "conclusion": "实证评估结果表明，DP-FedTabDiff能够在隐私预算、客户端配置和联邦优化策略之间找到最佳权衡，证明了该框架在高度受监管领域内促进安全数据共享和分析的潜力，为联邦学习和隐私保护数据合成的进一步发展铺平了道路。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.06748", "html_url": "https://arxiv.org/abs/2412.06748", "title": "拒绝标记：一种简单的方法在大型语言模型中校准拒绝回答", "title_en": "Refusal Tokens: A Simple Way to Calibrate Refusals in Large Language Models", "authors": "Neel Jain,Aditya Shrivastava,Chenyang Zhu,Daben Liu,Alfy Samuel,Ashwinee Panda,Anoop Kumar,Micah Goldblum,Tom Goldstein", "background": "构建安全可靠的预训练语言模型的一个关键因素是让模型恰当地拒绝执行某些指令或回答某些问题。用户可能希望模型对不同类别的查询产生拒绝回应，比如不明确的问题、违法指令或模型知识范围之外的信息查询。然而，针对不同查询类别的敏感度设置会受到工程复杂性的限制，当前的默认方法是训练具有不同拒绝响应比例的不同模型，这种方式代价高昂且难以满足每个用户的个性化需求。因此，有必要提出一种简单而有效的方法，使模型能够灵活地控制拒绝回答的行为。", "innovation": "本文提出了拒绝标记（Refusal Tokens）的概念，这是一种关于不同拒绝类型的选择性干预方法。拒绝标记在训练过程中被添加到模型的响应前，通过在推理阶段根据需要调整每个标记生成的概率，模型能够灵活地控制拒绝回答的行为，而无需进一步的调优。这种方法既能满足用户对不同查询类别敏感度的需求，同时又降低了工程复杂性，简化了模型的训练和应用过程。", "conclusion": "拒绝标记提供了一种有效且简单的控制单个模型拒绝回答行为的方法，实现了对拒绝回答率的精确调整，而无需进一步调优。该方法能够显著降低培训和应用大型语言模型的复杂性，进一步推广了预训练语言模型的应用范围。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.18197", "html_url": "https://arxiv.org/abs/2503.18197", "title": "FROG: 在图上的公平删除", "title_en": "FROG: Fair Removal on Graphs", "authors": "Ziheng Chen,Jiali Cheng,Hadi Amiri,Kaushiki Nag,Lu Lin,Xiangguo Sun,Gabriele Tolomei", "background": "随着对隐私法规的日益重视，机器遗忘在社交网络和推荐系统等实际应用中变得愈发重要，而这些应用大多数可以自然地表示为图结构。然而，现有的图遗忘方法往往会无差别地修改节点或边，忽视其对公平性的影响。例如，忘记不同性别的用户之间的链接可能会无意中加剧群体间的不平等。为了解决这一问题，本文提出了一种新的框架，该框架联合优化图结构和模型以实现公平遗忘。", "innovation": "本文的方法通过重新布置图，移除阻碍遗忘的冗余边，同时通过目标边增强保留公平性。此外，提出了一种最坏情况下的评估机制来评估在挑战性场景下的鲁棒性。实验结果表明，本文的方法在公平性与有效性方面优于现有的基线方法。", "conclusion": "本文提出了一种新的框架来联合优化图结构和模型以实现公平遗忘。通过实验，证明了该方法在公平性与有效性方面的优越性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.00631", "html_url": "https://arxiv.org/abs/2412.00631", "title": "ROSE: 基于奖励导向的数据选择框架用于大语言模型任务特定指令调优", "title_en": "ROSE: A Reward-Oriented Data Selection Framework for LLM Task-Specific Instruction Tuning", "authors": "Yang Wu,Huayi Zhang,Yizheng Jiao,Lin Ma,Xiaozhong Liu,Jinhong Yu,Dongyu Zhang,Dezhi Yu,Wei Xu", "background": "大型语言模型（LLMs）在生成更可控和有效的输出方面展现了显著的潜力，尤其是在多个领域。现有的方法主要依赖于手工设计的相似度度量来选择与测试数据分布匹配的训练数据，旨在最小化在测试数据上的指令微调损失，从而提升目标任务上的性能。然而，当前的指令微调损失（即下一个令牌预测的交叉熵损失）在LLMs中并没有表现出与实际任务性能之间的单调关系，这导致现有方法的有效性受到了质疑。", "innovation": "该研究提出了一种名为ROSE的新颖奖励导向指令数据选择方法，通过利用成对偏好损失作为奖励信号优化任务特定指令调优的数据选择。ROSE通过采用影响力公式来近似训练数据点相对于少量示例偏好验证集的影响，从而选择最相关的训练数据点。实验结果表明，使用ROSE选择训练数据的5%，相较于使用完整训练数据集进行微调，本方法取得了具有竞争力的结果，且在多个基准数据集和不同模型架构下优于其他最先进的数据选择方法。", "conclusion": "通过引入基于奖励导向的方法，ROSE可以有效地解决现有数据选择方法的有效性问题，从而在多个基准数据集上取得与完整数据集微调相当甚至更好的性能。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2310.16363", "html_url": "https://arxiv.org/abs/2310.16363", "title": "三时标约束型演员批评者与约束型自然演员批评者算法的有限时间分析", "title_en": "Finite-Time Analysis of Three-Timescale Constrained Actor-Critic and Constrained Natural Actor-Critic Algorithms", "authors": "Prashansa Panda,Shalabh Bhatnagar", "background": "演员批评者方法在大量的强化学习任务中得到了广泛的应用，尤其是在状态-动作空间较大的情况下。本文考虑了在涉及不等式约束的约束马尔可夫决策过程（C-MDP）中的演员批评者和自然演员批评者算法，并在非独立非同分布（Markovian）设置下进行了非渐近分析。我们关注长期平均成本标准，其中目标函数和约束函数都是特定规定成本函数的策略依赖的长期平均值。", "innovation": "提出了一种在非渐近设置下对C-AC和C-NAC算法在C-MDP中的有限时间分析方法。通过拉格朗日乘数法处理不等式约束，证明了这两种算法能够找到性能（拉格朗日）函数的一阶稳定点，并且样本复杂度为$\tilde{\text{O}}(\text{ε}^{-2.5})$。", "conclusion": "本文还通过实验在三个不同的Safety-Gym环境中展示了算法的结果，证明了上述算法的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2402.01371", "html_url": "https://arxiv.org/abs/2402.01371", "title": "平均奖励MDP中带函数近似的双时标批评-演员算法", "title_en": "Two-Timescale Critic-Actor for Average Reward MDPs with Function Approximation", "authors": "Prashansa Panda,Shalabh Bhatnagar", "background": "最近的研究工作集中在非渐近收敛分析的AC算法上。然而，以前的工作在折扣成本设置中仅展示了双时标批评-演员算法的渐近收敛性，且在查找表的情况下，批评者和演员的时标是相反的。本文的背景是对在长期平均奖励设置下，采用函数近似来实现这一算法进行了首次研究，并提供了一种有限时间的非渐近有限时间收敛性分析。这项工作填补了该领域的空白。", "innovation": "本文提出了在长期平均奖励设置中采用函数近似的首次双时标批评-演员算法，并首次提供了在该方案中的非渐近有限时间和渐近收敛分析。此外，得到了最优学习速率，证明了批评者的均方误差能够在误差上界ε的情况下达到样本复杂度$\tilde{O}(\frac{1}{\\varepsilon^{(2+\frac{\beta}{2})}})$ (其中$\beta >0$可取任意接近零的值)，这是同样设置下双时标AC算法最好结果。此外，我们还分析了与受干扰平均奖励目标局部极大值对应的演员参数关联的微分包含的吸引子，并证明了在几乎确定的渐近收敛性。", "conclusion": "本文的工作证明了所提出的批评-演员算法在数值实验的三个基准设置中表现最佳，展示了较低的均方误差。同时，分析结果展示了双重时标方案的渐近收敛性和有限时间性，进一步确认了算法的优越性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.14481", "html_url": "https://arxiv.org/abs/2503.14481", "title": "不要欺骗你的朋友：从协作自我游戏中学到你所知道的", "title_en": "Don't lie to your friends: Learning what you know from collaborative self-play", "authors": "Jacob Eisenstein,Reza Aghajani,Adam Fisch,Dheeru Dua,Fantine Huot,Mirella Lapata,Vicky Zayats,Jonathan Berant", "background": "为了成为有用的助手，人工智能代理必须了解自己的能力与局限，包括何时使用参数化知识回答问题，何时依赖工具输出，何时选择放弃或采取谨慎的态度。这些技能很难通过监督微调学习，因为需要构建反映代理特定能力的示例。因此，该研究提出了一个全新的方法——协作自我游戏，以教会代理它们的知识。通过构建多代理合作，并对团队共同得出正确答案给予奖励，希望从互动结构中构建的激励机制中涌现出所需的元知识。该研究关注拥有不同类型工具（特定语料检索）的小规模代理社群，通过合作最大化成功同时减少努力。实验表明，团队层面的奖励可以引导政策的转移，进而改善个体代理在孤立环境中使用工具和选择性预测的能力。", "innovation": "该研究提出了一种全新的方法——协作自我游戏，用于教导代理它们的知识。这种方法通过构建多代理合作，并对团队共同得出正确答案给予奖励，希望从中涌现出所需的元知识。这种机制可以从互动结构中构建激励，促进多代理团队在利用工具和选择性预测方面的表现改进。", "conclusion": "实验结果表明，多代理群体的团队奖励可以引导政策转移，提高个体代理在孤立环境中的工具使用和选择性预测能力。这种方法提供了一种新的途径，可以在依赖工具的环境中教导代理其知识，从而提高其协作和智能决策能力。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2412.18164", "html_url": "https://arxiv.org/abs/2412.18164", "title": "随机控制优化扩散模型微调：最优性、正则性及收敛性", "title_en": "Stochastic Control for Fine-tuning Diffusion Models: Optimality, Regularity, and Convergence", "authors": "Yinbin Han,Meisam Razaviyayn,Renyuan Xu", "background": "扩散模型已被证明是有效的生成建模工具，能够从大数据集中捕捉目标数据分布。然而，针对特定下游任务、约束和人类偏好对这些大型模型进行微调仍然是一项具有挑战性的任务。虽然最近的进步利用了强化学习算法来解决这个问题，但大部分进展主要是基于经验，缺乏理论理解。为了弥合这一差距，本文提出了一种用于扩散模型微调的随机控制框架。", "innovation": "本文构建了一个基于去噪扩散概率模型的预训练参考动力学的随机控制框架，将线性动力学控制与Kullback-Leibler正则化相结合。证明了这一随机控制问题的适定性和正则性，并开发了一个策略迭代算法（PI-FT）进行数值求解。证明了PI-FT算法在全局收敛性上实现了线性率。此外，还探讨了该框架到参数设置和连续时间公式中的扩展。", "conclusion": "通过数值实验验证了本文提出的PI-FT算法的有效性。有关代码可在以下链接处获得：this https URL"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05625", "html_url": "https://arxiv.org/abs/2505.05625", "title": "SPIN-ODE：化学反应速率估计中的刚性物理局部神经ODE方法", "title_en": "SPIN-ODE: Stiff Physics-Informed Neural ODE for Chemical Reaction Rate Estimation", "authors": "Wenqing Peng,Zhi-Song Liu,Michael Boy", "background": "从复杂化学反应中估计速率系数对于推进详细化学至关重要。然而，现实中大气化学系统固有的刚性特征给基于学习的方法带来了严重挑战，导致训练不稳定和收敛效果不佳，从而阻碍了有效速率系数的估计。", "innovation": "我们提出了一种新的SPIN-ODE（刚性物理局部神经常微分方程）框架用于化学反应建模。该方法引入了一个三阶段的优化过程：首先，训练一个黑盒神经ODE来拟合浓度轨迹；其次，预训练一个化学反应神经网络（CRNN）来学习浓度与其时间导数之间的映射；最后，通过与预训练的CRNN相结合来微调速率系数。", "conclusion": "在合成和新提出的现实数据集上的广泛实验验证了该方法的有效性和鲁棒性。作为首个针对刚性神经ODE在化学速率系数发现方面的研究，我们的工作为将神经网络与详细化学相结合开辟了新的方向。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.06235", "html_url": "https://arxiv.org/abs/2504.06235", "title": "Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis", "title_en": "Decentralized Domain Generalization with Style Sharing: Formal Model and Convergence Analysis", "authors": "Shahryar Zehtabi,Dong-Jun Han,Seyyedali Hosseinalipour,Christopher G. Brinton", "background": "联邦学习（FL）通常假设本地数据集统计在训练和测试之间保持不变。然而，在实践中，由于分布偏移等因素，这一假设往往不成立。因此，研究者需要开发领域泛化（DG）方法，利用源域数据来训练能够在未见过的目标域中泛化的模型。本文关注现有的FL和DG工作中的两个主要差距：一是缺乏对DG目标的正式数学分析；二是DG研究主要局限于星型拓扑结构。", "innovation": "本文提出了Decentralized Federated Domain Generalization with Style Sharing（$StyleDDG$），这是一种在对等网络中允许设备共享从其数据集中推断出的风格信息来进行领域泛化的分散式DG算法。此外，本文还提供了首个在分散式网络中系统分析基于风格的DG训练的方法，并将现有的集中式DG算法嵌入到该框架中，使用其公式来建模$StyleDDG$，并得到了保证$StyleDDG$收敛的分析条件。", "conclusion": "通过在流行的数据集上进行实验，本文证明了$StyleDDG$相比基准分散式梯度方法能在未见过的目标域中取得显著的准确率提升，同时通信开销最小。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.08897", "html_url": "https://arxiv.org/abs/2504.08897", "title": "受局部学习训练的脉冲神经网络对抗鲁棒性研究", "title_en": "On the Adversarial Robustness of Spiking Neural Networks Trained by Local Learning", "authors": "Jiaqi Lin,Abhronil Sengupta", "background": "近期研究表明，脉冲神经网络（SNNs）在帧基和事件基信息处理中对几乎不可与干净数据区别的对抗样本极其脆弱。大多数关于此问题的研究仅采用了基于梯度的 Backpropagation Through Time（BPTT）方法生成对抗样本，而这种方法缺乏生物可行性。相比之下，能够大幅减少BPTT约束的局部学习方法尚未在对抗攻击研究中得到充分探索。本文旨在通过四种训练算法框架来探讨SNNs的对抗鲁棒性，深入分析了基于梯度的对抗攻击方法在该背景下生成对抗实例的无效性，并提出了结合了对抗样本可移植性的混合对抗攻击方法，以克服这些限制。", "innovation": "本文介绍了一种结合了对抗样本可移植性的混合对抗攻击方法，该方法在多步对抗攻击、黑盒FGSM场景以及非脉冲领域中表现出色，并且优于现有的对抗攻击方法。同时，对方法的一般性进行了评估，证明了其在多种情况下的应用价值。", "conclusion": "本文通过详细的实验分析和对比，证明了混合对抗攻击方法在SNNs对抗鲁棒性领域的优越性能，并评估了其在多种复杂场景下的普适性。该研究为理解SNNs的对抗鲁棒性和发展新的对抗攻击方法提供了新的视角。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15266", "html_url": "https://arxiv.org/abs/2504.15266", "title": "掷骰子与先看后跳：超越下一个词预测的创造性极限", "title_en": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction", "authors": "Vaishnavh Nagarajan,Chen Henry Wu,Charles Ding,Aditi Raghunathan", "background": "本文设计了一套简化算法任务，作为开放世界任务的宽松抽象，以便清晰和可控地量化现代语言模型的创造力极限。研究中，作者通过对比单个词和多词方法（如无监督训练和扩散模型），探讨如何在保持连贯性的同时引入随机性以促进创造力输出。背景表明，当前的自然语言处理模型在创造性任务上表现有限，对于开放性任务的理解和生成能力有待加强。", "innovation": "1. 设计了一套简化算法任务，作为开放世界任务的抽象，研究语言模型的创造力极限；\n2. 提出了无监督训练和扩散模型等多词方法，在生产多样性和原创性输出方面优于单一词预测；\n3. 发现了在输入层注入噪声（称为种子条件）的效果，与输出层的温度采样相当甚至更好；\n4. 提供了分析开放创造性技能的原则性测试平台，并提出了超越单个词预测和温度采样的新观点。", "conclusion": "本文研究了语言模型在开放性创造性任务上表现的局限性，通过设计的简化算法任务展示了无监督训练和扩散模型等方法的优势，并提出在输入层注入噪声的有效性。结论认为，未来的研究应当进一步探索超越单个词预测的新方法，以促进语言模型在创造力任务上的表现。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11717", "html_url": "https://arxiv.org/abs/2505.11717", "title": "WebInject: 基于提示注入攻击的网络代理", "title_en": "WebInject: Prompt Injection Attack to Web Agents", "authors": "Xilong Wang,John Bloch,Zedian Shao,Yuepeng Hu,Shuyan Zhou,Neil Zhenqiang Gong", "background": "基于多模态大型语言模型（MLLM）的网络代理通过生成基于网页截图的动作来与网页环境交互。现有的研究集中在如何通过改画面截图来操控这些代理执行特定的攻击行为，这涉及到对网页原生像素值进行干扰，从而导致代理执行攻击者指定的动作。这是一个优化问题，关键挑战在于原生像素值和截图之间的非可微映射，使得反向传播梯度变得困难。研究人员提出了一种方法，通过训练神经网络来近似这个映射，并使用投影梯度下降来解决重新形成的优化问题，从而有效实现了基于提示的注入攻击。", "innovation": "提出了一种名为WebInject的提示注入攻击，通过在网页原生像素值中添加扰动，利用神经网络近似原生像素值和截图之间的映射，使用投影梯度下降解决重新形成的优化问题，从而有效地操控网络代理执行攻击者指定的动作。", "conclusion": "WebInject攻击在多个数据集上得到了广泛评估，结果表明其高度有效，并显著优于基线方法。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.04619", "html_url": "https://arxiv.org/abs/2505.04619", "title": "视觉强化学习中视图的融合与解缠在机器人操作中的应用", "title_en": "Merging and Disentangling Views in Visual Reinforcement Learning for Robotic Manipulation", "authors": "Abdulaziz Almuzairee,Rohan Patil,Dwait Bhatt,Henrik I. Christensen", "background": "视觉系统在机器人操控中的应用已经广为人知，尤其是通过视觉伺服技术。由于世界具有三维性质，使用多视角并合并它们可以为Q学习提供更好的表示，从而训练出更有效的策略。然而，这些需要多视图的策略对失败摄像头敏感，并且部署起来负担较大。因此，需要更高效的解决方案来解决这些问题。", "innovation": "本文提出了一种名为Merge And Disentanglement（MAD）的算法，它能够高效地合并视图以提高样本效率，同时通过将多视角特征输入与单视角特征结合来解缠视图，从而生成更加稳健的策略，同时实现轻量级部署。此方法已在Meta-World和ManiSkill3上展示了其效率和鲁棒性。", "conclusion": "通过MAD算法，可以更有效地合并多视角并解缠视图，生成稳健的机器人操控策略，同时降低了部署的复杂度。此方法已在两个机器人操控数据集上展示了其优势，实现了轻量级和高效的部署。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05762", "html_url": "https://arxiv.org/abs/2506.05762", "title": "BiTrajDiff: 使用扩散模型进行双向轨迹生成的离线强化学习", "title_en": "BiTrajDiff: Bidirectional Trajectory Generation with Diffusion Models for Offline Reinforcement Learning", "authors": "Yunpeng Qing,Shuo Chen,Yixiao Chi,Shunyu Liu,Sixu Lin,Kelu Yao,Changqing Zou", "background": "近年来，离线强化学习（RL）取得的进展表明，通过在预先收集的数据集中施加保守约束，可以提高有效的策略学习。然而，这些静态数据集通常表现出分布偏差，限制了其泛化能力。传统的数据增强（DA）技术通过使用生成模型来丰富数据分布，以解决这一限制。然而，当前的DA技术主要关注从给定状态重构未来轨迹，忽视了探索能够到达这些状态的历史轨迹。这种单向范式不可避免地限制了对多样化行为模式的发现，尤其是那些可能会导致高回报结果的关键状态。", "innovation": "本文提出了双向轨迹扩散（BiTrajDiff），这是一种新型的离线RL数据增强框架，可以从任何中间状态生成未来和历史轨迹。BiTrajDiff将轨迹生成任务分解为两个独立但互补的扩散过程：一个用于生成未来轨迹以预测未来动态，另一个用于生成过去轨迹以追溯基本的历史。这种方法可以高效地利用关键状态作为锚点，扩展到潜在有价值的但未充分探索的状态空间区域，从而提高数据集的多样性。", "conclusion": "在D4RL基准套件上的广泛实验表明，BiTrajDiff在各种离线RL架构中都优于其他先进的数据增强方法，显示出更好的性能。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.04104", "html_url": "https://arxiv.org/abs/2504.04104", "title": "SpecPipe: 通过投机性解码加速基于管道并行的大语言模型推理", "title_en": "SpecPipe: Accelerating Pipeline Parallelism-based LLM Inference with Speculative Decoding", "authors": "Haofei Yin,Mengbai Xiao,Tinghong Li,Xiao Zhang,Dongxiao Yu,Guanghui Zhang", "background": "大语言模型的推理需求正在迅速增加。管道并行提供了一种成本效益高的分布式推理部署策略，但存在高服务延迟的问题。在管道并行中引入投机性解码可以改善性能，但仍面临硬件利用率低和狭窄的投机窗口的挑战。", "innovation": "受指令管道中分支预测的启发，该论文引入了SpecPipe，逐步填充解题令牌以填满管道。这种方法通过最大化硬件利用率，在理想情况下每步解码一个令牌。SpecPipe由动态投机性令牌树和管道化推理框架组成。该框架按照节点级计算、剪枝传播和节点间通信阶段进行推理。此外，还实现了SpecPipe及其动态批处理变体SpecPipe-DB，适用于单请求和多请求推理。", "conclusion": "在8步管道上，SpecPipe在各种单请求工作负载中的时间间隔提高了4.19至5.53倍（相较于标准管道并行），并提高了2.08至2.38倍（相较于基于树的投机性解码方法）。对于多请求工作负载，SpecPipe-DB的吞吐量提高了1.64至2.08倍，时间间隔降低了1.61至2.06倍，优于vLLM的表现。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.12321", "html_url": "https://arxiv.org/abs/2506.12321", "title": "超出频率：冗余在大型语言模型记忆中的作用", "title_en": "Beyond Frequency: The Role of Redundancy in Large Language Model Memorization", "authors": "Jie Zhang,Qinghua Zhao,Chi-ho Lin,Zhongfeng Kang,Lei Li", "background": "大型语言模型的存储（记忆）对隐私和公平性构成了关键风险，尤其是在参数数量达到数十亿的情况下。以前的研究已经表明，记忆和标记频率等因素之间存在一定的关联性，但这些研究并未揭示频率变化对已存储样本和未存储样本影响的差异性。研究人员发现，频率的增加对存储样本的影响较小（例如：0.09），但对非存储样本的影响却显著较大（例如：0.25），这种模式在不同规模的模型中是一致存在的。", "innovation": "通过篡改样本前缀并通过标记位置变化来计算扰动强度进行反事实分析，表明冗余度与记忆模式密切相关。研究发现，大约79%的已存储样本具有低冗余度，这些低冗余度样本的脆弱性是一般样本（高冗余度）的两倍，这导致在扰动后已存储样本会减少0.6，而非存储样本减少仅为0.01。这意味着更加冗余的内容变得更具记忆性和更加脆弱。这些发现暗示了冗余度指导的数据预处理方法，有助于减少隐私风险并减轻偏见，以确保模型部署的公平性。", "conclusion": "研究结果表明，约79%的已存储样本具有低冗余度，这些低冗余度样本的脆弱性是一般样本的两倍，在扰动下已存储样本的减少比非存储样本更多，即更冗余的内容不仅更易被记住也更脆弱。这表明可以根据冗余度进行数据预处理，以减少隐私风险并缓解偏见，确保模型部署的公平性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15695", "html_url": "https://arxiv.org/abs/2506.15695", "title": "SimuGen：基于块图的仿真模型构建多模态代理框架", "title_en": "SimuGen: Multi-modal Agentic Framework for Constructing Block Diagram-Based Simulation Models", "authors": "Xinxing Ren,Qianbo Zang,Zekun Guo", "background": "近期的大语言模型（LLMs）在数学推理和代码生成方面表现出色，但在仿真领域仍面临挑战，特别是在生成Simulink模型方面。Simulink是工程和科学研究中必不可少的工具。初步实验表明，LLMs通常无法仅从文本输入生成可靠且完整的Simulink仿真代码，这可能是因为其预训练数据中缺乏Simulink特定的信息。", "innovation": "本文提出了一种名为SimuGen的多模态代理框架，该框架能够通过结合视觉Simulink图表和领域知识自动生成精确的Simulink仿真代码。SimuGen框架包含多个专业化的代理，包括调查员、单元测试审查员、代码生成器、执行器、调试定位器和报告编写器，并支持特定领域的知识库。这种协作和模块化的设计使得Simulink仿真代码的生成具备可解释性、 robust性和可重复性。本文的源代码已在公共平台上公开。", "conclusion": "该框架通过将视觉Simulink图和领域知识相结合，以及协调多个特殊化的代理，成功地解决了Simulink仿真代码自动生成过程中的一系列问题。这一协作和模块化的设计方案提升了模拟代码的生成质量，使得Simulink仿真代码的生成更具可解释性、robust性和可重复性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.14054", "html_url": "https://arxiv.org/abs/2506.14054", "title": "ScIReN：在碳循环及其更广泛的应用中发现隐藏关系", "title_en": "Scientifically-Interpretable Reasoning Network (ScIReN): Discovering Hidden Relationships in the Carbon Cycle and Beyond", "authors": "Joshua Fan,Haodi Xu,Feng Tao,Md Nasim,Marc Grimson,Yiqi Luo,Carla P. Gomes", "background": "了解土壤中碳的流动对于减轻气候变化的影响至关重要。尽管土壤有潜力从大气中捕捉碳，但土壤碳循环的机制还不完全清楚，现有的基于过程的数学模型虽然基于现有知识构建，但由于含有许多未知参数，这些参数需要通过非系统的方式设定，常导致观察数据的拟合效果不佳。另一方面，神经网络可以从数据中学习模式，但它们不尊重已知的科学定律，也不揭示新的科学关系，因为它是一个黑盒模型。因此，需要一种透明且可解释的方法来结合可解释神经网络和基于过程的推理。", "innovation": "本文提出了一个完全透明的框架——可解释合理推理网络（ScIReN），结合了可解释的神经网络和基于过程的推理。该框架通过可解释的编码器预测科学上有意义的潜在参数，然后通过一个可微分的基于过程的解码器预测标记输出变量。ScIReN 使用科莫戈罗夫-阿诺德网络（KAN）确保编码器是完全可解释的，并揭示输入特征与潜在参数之间的关系；采用新颖的平滑度惩罚以平衡表现性和简单性；使用新型硬Sigmoid约束层，将潜在参数限制在科学先验知识定义的范围内。过程解码器确保已确认的科学知识，而基于KAN的编码器揭示了常规的黑盒模型中隐藏的新科学关系。", "conclusion": "ScIReN 在模拟土壤中的有机碳流动以及植物的生态系统呼吸两个任务中，预测准确性和可解释性都优于黑盒网络。它能够推断出潜在的科学机制及其与输入特征之间的关系。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.15689", "html_url": "https://arxiv.org/abs/2506.15689", "title": "BASE-Q: 基于偏差校正和非对称缩放增强的旋转量化方法", "title_en": "BASE-Q: Bias and Asymmetric Scaling Enhanced Rotational Quantization for Large Language Models", "authors": "Liulu He,Shenli Zheng,Karwei Sun,Yijiang Liu,Yufei Zhao,Chongkang Tan,Huanrui Yang,Yuan Du,Li Du", "background": "旋转量化已成为大型语言模型（LLMs）最先进的量化管道中的关键技术，通过有效平滑权重和激活中的异常值来发挥作用。然而，进一步优化旋转参数带来的性能提升有限，同时引入了显著的训练开销。这是因为旋转参数共享需要同时加载整个模型才能实现反向传播，从而导致内存消耗增大，限制了其实用性。", "innovation": "本文识别了当前旋转量化方法的两个根本限制：首先是旋转无法对齐通道均值，导致更宽的量化范围和增加的舍入误差；其次是旋转使激活分布更符合高斯分布，增加了由于裁剪错误引起的能量损失。为解决这些问题，作者引入了一种名为BASE-Q的简单而强大的方法，结合偏差校正和非对称缩放，以有效减少舍入和裁剪错误。此外，BASE-Q允许块级优化，消除了内存密集型的全模型反向传播的需求。", "conclusion": "在各种LLM和基准上的广泛实验表明，BASE-Q方法的有效性，相对于QuaRot、SpinQuant和OSTQuant分别缩小了50.5%、42.9%和29.2%的精度差距。代码将很快发布。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.23344", "html_url": "https://arxiv.org/abs/2507.23344", "title": "通过可微分基于代理的仿真设计自行车共享系统的动态价格", "title_en": "Designing Dynamic Pricing for Bike-sharing Systems via Differentiable Agent-based Simulation", "authors": "Tatsuya Mitomi,Fumiyasu Makinoshima,Fumiya Makihara,Eigo Segawa", "background": "随着自行车共享系统的兴起，这些系统在多个城市中出现作为新的环保交通系统。这些系统中的时空变化客户需求会导致自行车站点间自行车库存不平衡，同时带来额外的重新分配成本。因此，通过最优动态定价来管理客户需求对于系统的高效运作至关重要。但是，由于系统中存在不同背景的用户并且他们的选择具有不确定性，因此对这种系统进行最优定价设计具有挑战性。", "innovation": "为了解决这一问题，本文开发了一种可微分基于代理的仿真，可以快速设计自行车共享系统的动态定价，在时空需求变化和用户选择不确定性的情况下实现自行车库存的平衡。与传统方法相比，本文的方法在降低损失（73%至78%）的同时，收敛速度快100多倍，且通过仿真验证，定价策略可以自然诱导平衡库存，无需人工干预。并且，适当的初始条件设置可以使诱导平衡库存的折扣成本最小化。", "conclusion": "本文提出了一种新的方法，即通过可微分基于代理的仿真快速设计自行车共享系统的动态定价政策，该方法不仅提高了定价的准确性，还显著提高了计算效率。此外，通过设置适当的初始条件，可以有效减少价格政策诱导平衡库存所需的折扣成本。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.15066", "html_url": "https://arxiv.org/abs/2507.15066", "title": "Time-RA: 结合LLM反馈的时间序列异常推理", "title_en": "Time-RA: Towards Time Series Reasoning for Anomaly with LLM Feedback", "authors": "Yiyuan Yang,Zichuan Liu,Lei Song,Kai Ying,Zhiguang Wang,Tom Bamford,Svitlana Vyetrenko,Jiang Bian,Qingsong Wen", "background": "时间序列异常检测在多个领域至关重要，但当前方法往往仅限于二元异常分类，缺乏详细的类别划分或进一步的解释性推理。为解决这些问题，本文提出了一种新颖的任务，即利用大规模语言模型（LLMs）将经典的时间序列异常检测从判别性任务转变为生成性和推理性较强的任务。同时，本文还引入了首个专门标注用于异常推理的多模态基准数据集，名为RATs40K，包含约40,000个样本，覆盖10个真实世界领域，每个样本包括数值时间序列数据、上下文文本信息和视觉表示，这些样本均细化标注了单变量和多变量异常的类别（分别为14种和6种）以及结构化的解释性推理。", "innovation": "本文提出了Time-series Reasoning for Anomaly (Time-RA) 这一新颖任务，将时间序列异常检测从判别性任务转变为生成性和推理性较强的任务。同时引入了RATs40K数据集，这是首个专门用于异常推理的多模态基准数据集。开发了一种使用GPT-4驱动反馈的高级注释框架，确保了准确性和可解释性。广泛基准测试了LLMs和多模态LLMs，突出了当前模型的能力和局限性，强调了监督微调的重要性。通过开源代码和数据集支持和加速未来的研究。", "conclusion": "本文的数据集和任务铺平了在可解释的时间序列异常检测和推理方面取得显著进步的道路。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15593", "html_url": "https://arxiv.org/abs/2508.15593", "title": "诱导域转移的误指定仿真基于推理", "title_en": "Inductive Domain Transfer In Misspecified Simulation-Based Inference", "authors": "Ortal Senouf,Cédric Vincent-Cuaz,Emmanuel Abbé,Pascal Frossard", "background": "仿真基于推理（SBI）是一种在似然不可处理但可进行模拟时，用于估计物理系统潜在参数的统计推理方法。实践中，SBI常受到模型误指定的阻碍——模拟与真实观察之间的不匹配，这源于模型固有的简化假设。罗PE是一种最近的SBI方法，通过结合半监督校准和基于运最优转（OT）的方式分布对齐解决挑战。然而，罗PE在推断过程中仅支持全传递模式，需要获取一批测试样本，这限制了其扩展性和泛化能力。", "innovation": "本文提出了一种完全归纳和可泛化的SBI框架，将校准和分布对齐整合为单个端到端可训练模型。该方法利用具有闭形式耦合的批次大小OT，对齐来自相同潜在参数的实际和模拟观察，并使用配对的校准数据和未配对样本。然后，使用条件归一化流训练OT诱导后验分布的近似方法，以在测试时不使用模拟，实现高效的推理。", "conclusion": "在一系列合成和实际基准测试中，该方法在复杂医疗生物标志物估计等领域表现优于RoPE及其他标准的SBI和非SBI估计器，提供了更好的扩展性和在误指定环境中的可应用性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.04901", "html_url": "https://arxiv.org/abs/2508.04901", "title": "稳定性灵敏度：适应性数据选择在迁移学习中再现性的理论与实证分析", "title_en": "Sensitivity of Stability: Theoretical & Empirical Analysis of Replicability for Adaptive Data Selection in Transfer Learning", "authors": "Prabhav Singh,Jessica Sorrell", "background": "迁移学习的广泛应用已经通过使预训练模型能够高效地适应新领域而彻底改变了机器学习。然而，这些适应的有效性及其再现性仍然缺乏明确的理解，特别是在使用适应性数据选择策略（它们动态地优先选择训练样本）时。本文旨在通过全面的理论和实证分析来探讨迁移学习中的再现性问题，提出了一种新的数学框架来量化适应效果与结果一致性之间的基本权衡。", "innovation": "提出了一个量化适应选择策略对训练数据扰动响应程度的指标——选择灵敏度 ($\triangle_Q$)，并证明了再现性失败概率（即两次独立训练运行产生性能超过某个阈值差异的几率）随着选择灵敏度的增加而呈二次关系增长，同时随着样本数量的增加而呈指数关系下降。研究通过在MultiNLI语料库上使用六种不同的适应性选择策略（从均匀采样到基于梯度选择）进行了广泛实验，验证了这一理论关系在实践中的可靠性。实验结果表明，高度适应的策略如基于梯度和 Curriculum 学习在任务性能上表现优异但再现性失败率较高，而较不适应的策略则使其失败率保持在7%以下。此外，研究发现源域预训练通过降低20-30%的再现性失败率同时保持性能提升，提供了一种强有力的缓解机制。", "conclusion": "该研究为从业者提供了理论指导，如何在性能与再现性之间进行权衡决策。同时强调了现代迁移学习系统中再现性意识设计的重要性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.15008", "html_url": "https://arxiv.org/abs/2508.15008", "title": "微控制器用的量化神经网络：方法、平台和应用的全面回顾", "title_en": "Quantized Neural Networks for Microcontrollers: A Comprehensive Review of Methods, Platforms, and Applications", "authors": "Hamza A. Abushahla,Dara Varam,Ariel J. N. Panopio,Mohamed I. AlHajri", "background": "微控制器等资源受限设备上部署量化神经网络（QNNs）引入了平衡模型性能、计算复杂度和内存限制的显著挑战。TinyML通过结合机器学习算法、硬件加速和软件优化的进步，旨在高效地在嵌入式系统上运行深度神经网络，缓解了这些问题。本文旨在详细介绍硬件导向的量化技术，系统地回顾了用于嵌入式应用加速深度学习模型的关键量化技术，并强调了模型性能与硬件能力之间的关键权衡。此外，还对支持QNN在微控制器上执行的现有软件框架和硬件平台进行了评估，并分析了当前面临的挑战及其未来有前景的发展方向。", "innovation": "本文以硬件为中心介绍了量化技术，详细回顾了用于嵌入式应用的加速深度学习模型的量化技术；特别强调了模型性能与硬件能力之间的关键权衡；评估了专门支持QNN在微控制器上执行的现有软件框架和硬件平台；提供了当前挑战的分析，并展望了该领域未来有前景的技术方向。", "conclusion": "本文分析了QNN部署领域当前面临的挑战，并提出了有前景的方向，有助于理解QNN在微控制器上的执行环境和限制因素。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.11356", "html_url": "https://arxiv.org/abs/2508.11356", "title": "ETTRL: 通过熵机制平衡LLM测试时强化学习中的探索与利用", "title_en": "ETTRL: Balancing Exploration and Exploitation in LLM Test-Time Reinforcement Learning Via Entropy Mechanism", "authors": "Jia Liu,ChangYi He,YingQiao Lin,MingMin Yang,FeiYang Shen,ShaoGuo Liu", "background": "近年来，大型语言模型在复杂推理任务如数学和编程方面取得了显著进步。然而，这些模型仍然高度依赖标注数据，并且在无监督场景下的适应性有限。为解决这些问题，测试时强化学习（TTRL）已被提出，该方法利用模型生成的伪标签实现自我优化。尽管前景广阔，TTRL仍面临一些关键挑战，包括由于并行演练导致的高昂推理成本和早期阶段的偏差估计，这会引发过自信现象，减少输出多样性并导致性能停滞。", "innovation": "本文提出了一种基于熵的机制，通过两种策略改善测试时强化学习中的探索与利用平衡：熵叉树多数演练(ETMR)和熵导向优势重塑(EAR)。与基线相比，该方法使Llama3.1-8B在AIME 2024基准测试中pass@1指标提高了68%，并且仅消耗了60%的演练令牌预算。这项研究表明，该方法能够有效地优化推理效率、多样性和估计稳健性之间的权衡，从而推动了开放领域推理任务的无监督强化学习的发展。", "conclusion": "该研究提出了一种通过熵机制平衡测试时强化学习中探索与利用的新方法，成功提升了模型在开放领域推理任务上的性能，证明其在无监督场景下的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17196", "html_url": "https://arxiv.org/abs/2508.17196", "title": "BudgetThinker: 使用控制标记增强预算感知大型语言模型推理", "title_en": "BudgetThinker: Empowering Budget-aware LLM Reasoning with Control Tokens", "authors": "Hao Wen,Xinrui Wu,Yi Sun,Feifei Zhang,Liye Chen,Jie Wang,Yunxin Liu,Yunhao Liu,Ya-Qin Zhang,Yuanchun Li", "background": "近年来，大型语言模型（LLMs）利用增加推理测试时的计算来提升推理能力，虽然这种方法非常有效，但会导致严重的延迟和资源成本，限制了其在实际时间约束或成本敏感场景中的应用。", "innovation": "本文提出了BudgetThinker这个新的框架，旨在使LLMs具备预算感知的推理能力，允许对思想过程的长度进行精确控制。方法包括在推理过程中定期插入特殊控制标记以持续通知模型剩余的标记预算，结合一个全面的两阶段训练管道，首先是监督微调（SFT）使模型熟悉预算约束，然后是基于逐级强化学习（RL）阶段，使用长度感知奖励函数优化准确性与预算遵守。", "conclusion": "实验表明，BudgetThinker在多个具有挑战性的数学基准上保持了最高的性能，对于各种推理预算，性能表现显著优于其他基准。我们的方法提供了一个可扩展且有效的解决方案，能够开发高效可控的LLM推理，使高级模型更实用地部署在资源受限和实时环境中。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18124", "html_url": "https://arxiv.org/abs/2508.18124", "title": "CMPhysBench: 用于评估大型语言模型在凝聚态物理学中的基准", "title_en": "CMPhysBench: A Benchmark for Evaluating Large Language Models in Condensed Matter Physics", "authors": "Weida Wang,Dongchen Huang,Jiatong Li,Tengchao Yang,Ziyang Zheng,Di Zhang,Dong Han,Benteng Chen,Binzhao Luo,Zhiyu Liu,Kunling Liu,Zhiyuan Gao,Shiqi Geng,Wei Ma,Jiaming Su,Xin Li,Shuchen Pu,Yuhan Shui,Qianjia Cheng,Zhihao Dou,Dongfei Cui,Changyong He,Jin Zeng,Zeke Xie,Mao Su,Dongzhan Zhou,Yuqiang Li,Wanli Ouyang,Yunqi Cai,Xi Dai,Shufei Zhang,Lei Bai,Jinguang Cheng,Zhong Fang,Hongming Weng", "background": "当前大型语言模型（LLMs）在物理学各领域中的表现评估尚缺乏针对性检测工具，尤其是在凝聚态物理学这一学科中。研究人员需要一个专门的基准测试来评估LLMs在解决凝聚态物理问题时的熟练程度和准确性，特别注重问题求解过程的理解以及求解详细过程的生成能力。现有的评估方式通常较为粗略，不能准确反映预测值和真实值的相似程度。", "innovation": "CMPhysBench是一个全新的基准测试，包含了超过520个精心整理的研究生级别问题，涵盖凝聚态物理学的代表性子领域和基础理论框架。它通过使用树木结构表达式的表示来引入可伸缩表达式编辑距离（SEED）得分，以更精细（非二元）的方式提供部分评分，从而对预测和真实值之间的相似度进行更准确的评估。实验结果表明，即使是最好的模型Grok-4在CMPhysBench上的平均SEED得分为36分，准确率为28%，表明LLMs在这一具体且前沿领域的理解和解决能力仍有显著差距。", "conclusion": "通过CMPhysBench评价LLMs在凝聚态物理学中的表现，发现现有LLMs在这一特定领域的理解与解决问题的能力存在明显不足，强调了构建专门针对具体科学领域评估工具的重要性。SEED得分作为一种新的评估指标，可以更准确地度量模型生成解与真实解之间的接近程度。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.18860", "html_url": "https://arxiv.org/abs/2508.18860", "title": "C-Flat++: 向更加高效和强大的持续学习框架迈进", "title_en": "C-Flat++: Towards a More Efficient and Powerful Framework for Continual Learning", "authors": "Wei Li,Hangjie Yuan,Zixiang Zhao,Yifan Zhu,Aojun Lu,Tao Feng,Yanan Sun", "background": "持续学习（CL）要求在学习新任务的时候保持对以往知识的记忆，平衡对新任务的敏感性和保留过去知识的稳定性十分重要。近期，有人发现精确性敏感最小化（sharpness-aware minimization）方法在迁移学习中表现出色，并被应用于持续学习中以提高记忆保持和学习效率。然而，仅依赖于零阶精确性的方法在某些情况下可能会偏好更尖锐的最小值而非更平坦的最小值，这可能导致不够稳健且潜在的次优解。因此，需要一种新方法来促进更适合持续学习的更平坦损失景观，以改进CL整体性能和效率。文中提出了C-Flat及其改进版C-Flat++来解决以上问题。", "innovation": "文中提出了一种名为C-Flat的方法，该方法能促进更平坦的损失景观适用于持续学习，并且具有插即用的兼容性，便于代码整合。此外，C-Flat++更是进一步发展了更高效且有效的框架，利用选择性驱动的平坦性提升，显著减少了C-Flat的更新成本。通过广泛实验，该方法在不同持续学习方法、数据集和场景下显示出良好的效果和效率。", "conclusion": "实验结果显示C-Flat和C-Flat++在各种持续学习设置中持续提升了性能，并且C-Flat++在效率上进一步改进，证明了作者所提出方法的有效性和实用性。文章的代码可以在提供的链接中获取。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2306.12968", "html_url": "https://arxiv.org/abs/2306.12968", "title": "重访Labeled Stochastic Block Model中的最优簇恢复", "title_en": "Revisiting Instance-Optimal Cluster Recovery in the Labeled Stochastic Block Model", "authors": "Kaito Ariu,Alexandre Proutiere,Se-Young Yun", "background": "本文研究了具有有限数量且规模随节点总数线性增长的簇的带标签随机块模型(Labeled Stochastic Block Model, LSBM)中隐含社区恢复的问题。背景是围绕在给定LSBM模型下，怎样有效地识别和分类那些节点属于不同的社区，同时确保恢复的准确性。", "innovation": "提出了IAC（Instance-Adaptive Clustering），这是一个实例自适应聚类算法，其性能与实例特定的下界在期望值和高概率下相匹配。这是第一个同时满足这两项性能要求的算法，它基于实例特定的下界，不依赖于模型参数，如簇的数量。通过仅执行一次谱聚类，IAC 继承了谱聚类的低时空复杂度，适应大规模问题的解决需求，整体计算复杂度为 O(n polylog(n))。", "conclusion": "本文指出了恢复LSBM中隐含社区的必要和充分条件，在任意数目 s= o(n) 的情况下，使得期望错误分类节点的数目小于 s。IAC 算法的一个创新点在于其高效且无需模型参数先验信息的两步聚类方法。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20330", "html_url": "https://arxiv.org/abs/2508.20330", "title": "FORGE: 基于图嵌入的基本优化表示", "title_en": "FORGE: Foundational Optimization Representations from Graph Embeddings", "authors": "Zohair Shafi,Serdar Kadioglu", "background": "组合优化问题在科学和工程中极为普遍，但基于学习的方法加速其求解往往需要解决大量难解的优化实例以收集训练数据，这会带来显著的计算开销。现有方法要求为每个问题分布和每个下游任务训练专用模型，极大地限制了其可扩展性和泛化能力。", "innovation": "介绍了Forge方法，该方法在大规模、多样化的混合整数规划（MIP）实例上监督预训练一个分层量化图自动编码器，无需依赖它们的解。分层量化过程创建离散的代码分配，作为表示优化实例的词汇表。该方法在监督和非监督设置下都进行了评估。在非监督设置下，Forge嵌入有效地区分并聚类未见实例；在监督设置下，可以对Forge嵌入进行微调，一个单一模型可以同时预测变量用于温暖启动和整数间隙以促进切割生成，在多个问题类型分布下预测有助于最先进的商业优化求解器性能的提升。", "conclusion": "最终，发布了Forge的代码和预训练权重，鼓励进一步研究和实际使用实例级别的MIP嵌入（Forge: https://[提供网址]）"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2309.08289", "html_url": "https://arxiv.org/abs/2309.08289", "title": "使用点扩散模型对大型肠3D形状进行细化以生成数字人造体", "title_en": "Large Intestine 3D Shape Refinement Using Point Diffusion Models for Digital Phantom Generation", "authors": "Kaouther Mouheb,Mobina Ghojogh Nejad,Lavsen Dahal,Ehsan Samei,Kyle J. Lafata,W. Paul Segars,Joseph Y. Lo", "background": "在虚拟成像试验中构建数字人造体需要精确的3D人体器官建模。然而，如结肠这样的器官因其复杂的几何形状和形状变化而尤其具有挑战性。为此，本文提出了CLAP，这是一种结合了几何深度学习和去噪扩散模型的新型条件隐空间点扩散模型，用于增强结肠的3D表示。该模型通过层次变分自编码器从分割掩码中采样的点云来学习全局和局部形状表示。在潜空间中运行两个条件扩散模型来细化器官形状。通过预训练的表面重建模型，最终将细化后的点云转换为网格模型。CLAP在形状建模准确性方面取得了显著改进，相较于初始次优形状，减少了26%的Chamfer距离和36%的Hausdorff距离。", "innovation": "CLAP提出了一种新颖的条件隐空间点扩散模型，该模型结合了几何深度学习和去噪扩散模型，通过层次变分自编码器学习全局和局部形状表示，使用两个条件扩散模型在潜空间中细化器官形状，并通过预训练表面重建模型将细化后的点云转换为网格模型。此方法显著提高了结肠形状建模的准确性，增强了高保真器官建模的鲁棒性和扩展性，具有广泛的应用潜力。", "conclusion": "CLAP为精确的器官建模提供了一种稳健且可扩展的解决方案，适用于广泛的解剖结构，有望在虚拟成像试验和其他相关领域取得广泛应用。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.19352", "html_url": "https://arxiv.org/abs/2508.19352", "title": "图神经网络中的记忆现象", "title_en": "Memorization in Graph Neural Networks", "authors": "Adarsh Jamadandi,Jing Xu,Adam Dziedzic,Franziska Boenisch", "background": "深神经网络（DNNs）已被证明具有记忆训练数据的能力，但对于图神经网络（GNNs），类似的分析仍然相对缺乏。本文介绍了NCMemo（节点分类记忆）框架，这是第一个用于量化半监督节点分类中标签记忆的方法。研究揭示了记忆与图同质性的逆关系，即连接的节点共享相似标签/特征的性质。同时，研究分析了GNN的训练动态，发现低同质性图中的记忆现象与GNN在学习过程中对图结构的隐式偏见密切相关。在低同质性范围内，这种结构较少提供信息，因此促使GNN对节点标签进行记忆，以最小化训练损失。此外，研究指出，特征空间邻域中标签不一致的节点更容易受到记忆现象的影响。", "innovation": "1. 提出了NCMemo框架，首次用于量化GNN中的标签记忆。\n2. 研究发现了图同质性与记忆之间的逆关系。\n3. 分析了GNN的训练动态，并揭示了低同质性图中记忆现象的根本原因。\n4. 揭示了特征空间邻域中标签不一致的节点更容易受到记忆现象的影响。\n5. 提出了图重构作为一种减少记忆现象的方法，验证了这种方法在减少记忆现象同时不牺牲模型性能的有效性，并降低了之前记忆数据点的隐私风险。", "conclusion": "本文不仅深入了对GNN学习的理解，还为进一步实现更加隐私保护的GNN部署提供了支持。通过研究图同质性和记忆之间的关系，以及提出的图重构方法减少记忆现象的有效性，表明了在半监督节点分类中减少记忆现象的重要性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.14488", "html_url": "https://arxiv.org/abs/2403.14488", "title": "COBRA-PPM：使用概率编程进行不确定条件下机器人操作的因果贝叶斯推理架构", "title_en": "COBRA-PPM: A Causal Bayesian Reasoning Architecture Using Probabilistic Programming for Robot Manipulation Under Uncertainty", "authors": "Ricardo Cannizzaro,Michael Groom,Jonathan Routley,Robert Osazuwa Ness,Lars Kunze", "background": "机器人在执行操作任务时需要根据因果关系推理物体间的因果效应。然而，许多基于数据的方法缺乏因果语义，仅考虑关联性，这限制了其在不确定条件下的准确性和适用性。因此，需要一种能够处理不确定性的新方法，以提高机器人操作的表现和智能水平。", "innovation": "提出了一种名为COBRA-PPM的新颖因果贝叶斯推理架构，结合了因果贝叶斯网络和概率编程，用于在不确定条件下进行机器人操作的干预性推理。该架构通过高保真度Gazebo实验展示了在块堆叠任务中预测结果的高准确率（预测准确率：88.6%）和高任务成功率（94.2%），并进一步展示了从模拟到现实的迁移能力，有效处理传感器噪声和动作的不确定性。此外，该通用和可扩展的框架支持广泛的机器人操作场景，为未来的机器人和因果关系交叉领域工作奠定了基础。", "conclusion": "该工作提出了一种新颖的COBRA-PPM架构，用以解决不确定条件下机器人操作的推理问题，并通过实验验证了其有效性和广阔的应用前景，为机器人操作在未来的研究中提供了新的思路和可能性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.19563", "html_url": "https://arxiv.org/abs/2508.19563", "title": "鲁棒性很重要：语言模型在数据分析中的局限性", "title_en": "Robustness is Important: Limitations of LLMs for Data Fitting", "authors": "Hejia Liu,Mochen Yang,Gediminas Adomavicius", "background": "大规模语言模型（LLMs）的应用范围已远远超出了传统的语言处理任务。这些模型现在被用作一种即插即用的方法来进行数据拟合和预测。尽管LLMs在某些情况下能够与表格式监督学习技术竞争，但在处理无关任务变化时表现出高度敏感性。例如，仅仅是改变变量名称可能会使预测误差的大小发生变化。这种敏感性在基于上下文学习和监督微调中都普遍存在，并且存在于不同类型的通用语言模型中。研究还发现，在生成输出标记的过程中，一段提示中的某些位置会比预期的接收更多注意力，这可能是由于无关任务变化导致的预测敏感性。尽管为了预测稳健性而专门训练的一个表格基础模型（TabPFN）也不能完全避免这些无关因素的变化，这表明即使在设计上强调稳健性的模型也难以保证不受此类变化的影响。因此，虽然LLMs在预测能力上有所提升，但它们目前还没有达到可以作为预测手段的基本稳健性水平。", "innovation": "本研究揭示了在应用LLMs进行数据分析时的一个关键弱点——对无关任务变化的高度敏感性，即便使用不同的训练方法，这一现象都普遍存在。通过分析注意力分数，作者发现了一种非均匀的注意力模式：提示中的某些位置在生成输出标记时会比预期接收更多注意力。这一现象解释了在遇到无关任务变化时的敏感性。此外，研究还考察了专门为数据拟合训练的一个表格基础模型（TabPFN），尽管该模型具体设计是为了实现预测稳健性，但是它同样也易受无关任务变化的影响。", "conclusion": "尽管LLMs展现了强大的预测能力，但它们在应对无关任务变化时表现出的高敏感性表明，这些模型目前并不具备作为一个经得起验证的数据拟合工具的基本稳健性。这强调了对于使用LLMs进行数据分析时需要谨慎考虑，并且需要进一步改进这些模型的鲁棒性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.12367", "html_url": "https://arxiv.org/abs/2403.12367", "title": "学习匹配中协变量的重要性以进行与政策相关的观察研究", "title_en": "Learning covariate importance for matching in policy-relevant observational research", "authors": "Hongzhe Zhang,Jiasheng Shi,Jing Huang", "background": "匹配方法在观察性研究中广泛用于减少混淆效应，但传统的匹配方法通常将所有协变量视为同等重要，这可能导致当协变量在研究中的相关性存在差异时，性能不佳。", "innovation": "提出了优先感知的一对一匹配算法（PAMA），这是一种新颖的半监督框架，该框架从由专家配对的数据子集中学习协变量的重要性量度，并使用该量度进行匹配。PAMA通过引入未标记数据迭代更新分值函数中的协变量重要性量度，并且PAMA是无模型的。此外，论文还提出了处理数据不平衡、容纳时间协变量和提高对抗错误配对的鲁棒性的扩展方法。在模拟研究中，PAMA在高维设置和模型错配下比标准方法表现更好。在一项有关实地学校和COVID-19传播的真实研究中，PAMA使用基线协变量恢复了几乎是竞争对手方法两倍的专家配对数量。自我教学扩展在模拟中提高了性能，但其好处取决于具体情境。PAMA是第一个应用半监督学习到具有不等重要性协变量的观察匹配框架，提供了一种可扩展且具有解释性的工具，可将专家见解纳入政策相关的观察研究。", "conclusion": "PAMA是一种新型的半监督框架，能够在存在协变量相关性差异的研究中提供更好的匹配效果，通过学习专家配对的数据子集中的协变量重要性量度来优化匹配过程。PAMA克服了传统方法在协变量重要性不等时的性能不足，并且在解决数据不平衡、处理时间协变量和提高鲁棒性方面也有所改进。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2401.02592", "html_url": "https://arxiv.org/abs/2401.02592", "title": "非凸因式分解方法保证的张量列车恢复", "title_en": "Guaranteed Nonconvex Factorization Approach for Tensor Train Recovery", "authors": "Zhen Qin,Michael B. Wakin,Zhihui Zhu", "background": "当前文献中首次对因式分解方法提供了收敛保证。论文针对张量分解中存在的尺度不确定性问题，优化了称为左正交TT格式的方法，以实现大部分因子之间的正交性，并利用里emannian梯度下降（RGD）优化这些因子在斯特菲尔曼流形上的正交结构。论文还研究了通过线性测量恢复TT格式张量的传感问题，并在满足限制等距性质的情况下，证明了适当的初始化下，RGD能以线性速率收敛到真实张量。此外，论文还扩展了噪声测量情况下的分析，并证明了在高阶张量中，RGD能以多项式增长的误差率可靠地恢复真实张量。", "innovation": "1. 提供了因式分解方法的首项收敛保证。\n2. 优化了左正交TT格式，确保因式之间的正交性。\n3. 使用RGD优化因子，并在斯特菲尔曼流形上保证正交结构。\n4. 在存在噪声的测量情况下，证明了线性收敛的可靠性和多项式误差增长特性。\n5. 证明了适当的初始化下，RGD可以以线性速率收敛到真实张量。", "conclusion": "论文通过全局和局部的理论分析表明，在适宜条件下RGD可以可靠地以线性速率收敛到张量的实际值。通过多次实验验证了理论结论的有效性，特别是在高阶张量的情况下，方法的收敛性和准确性得到了显著提高。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.07117", "html_url": "https://arxiv.org/abs/2404.07117", "title": "连续的语言模型插值以实现动态和可控的文本生成", "title_en": "Continuous Language Model Interpolation for Dynamic and Controllable Text Generation", "authors": "Sara Kangaslahti,David Alvarez-Melis", "background": "随着大型语言模型（LLMs）在多种应用场景中变得越来越受欢迎，提高它们的适应性和可控性变得尤为重要，尤其是对于面向用户的应用。现有的语言模型适应性研究主要关注在优化单个预定义目标时找到最优模型，但本研究关注模型必须动态适应多样化且经常变化的用户偏好这一更具挑战性的场景。", "innovation": "本研究利用基于线性权重插值的适应方法，将其视为连续的多领域插值器，能够在需要时产生具有特定生成特征的模型。通过使用低秩更新调整基础模型，使其适用于多种不同的领域，从而生成多个具有不同生成特征的锚模型。然后利用这些锚模型的权重更新来定义包含在其凸包内的整个（无限）模型类。实验证明，调整插值权重可以针对所有控制属性使模型输出表现出可预测和一致的变化。", "conclusion": "研究表明，通过线性插值可以实现多种风格特性的细粒度控制。研究还发现，大部分属性之间没有相互纠缠，但对于某些属性对，这种情况并非如此。该结果表明，在微调模型权重之间进行线性插值可实现针对多个风格特征的可预测和细粒度控制。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.10257", "html_url": "https://arxiv.org/abs/2411.10257", "title": "使用滑动窗口引导扩散模型", "title_en": "Guiding a diffusion model using sliding windows", "authors": "Nikolas Adaloglou,Tim Kaiser,Damir Iagudin,Markus Kollmann", "background": "指导技术是扩散模型中广泛使用的一种方法，用于提高样本质量。技术上，指导是通过使用一个比主要模型泛化能力更强的辅助模型实现的。通过一个2D示例，研究了辅助模型泛化错误更相似但更强时的效果，表明这是极其有益的。", "innovation": "提出了一种新的、无需训练的方法——遮罩滑动窗口指导（M-SWG）。M-SWG 通过限制主要模型的感受野，以选择性方式引导主要模型，增强了远距离空间依赖性的重要性。M-SWG 不需要访问之前迭代的模型权重、额外训练或类别条件处理。", "conclusion": "M-SWG 达到了比之前最先进的无需训练方法更高的 Inception 分数 (IS)，且没有引入样本饱和现象。与现有指导方法结合使用，M-SWG 在使用 EDM2-XXL 和 DiT-XL 的 ImageNet 数据集上，达到了最先进的 Fréchet DINOv2 距离。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.19238", "html_url": "https://arxiv.org/abs/2406.19238", "title": "揭示大型语言模型中的细微价值观和观点", "title_en": "Revealing Fine-Grained Values and Opinions in Large Language Models", "authors": "Dustin Wright,Arnav Arora,Nadav Borenstein,Srishti Yadav,Serge Belongie,Isabelle Augenstein", "background": "在揭示大型语言模型（LLMs）中隐含的价值观和观点方面，可以通过提问式的方式获取LLM的回答，并量化其对于道德或政治声明的态度。但是，基于不同提示的回答态度会有所不同，因此研究者们发现这种方式并不稳定。本文基于此背景下，分析了6种LLM对‘政治倾向测试’（PCT）中62项命题共计156k条回答生成的大规模数据集，旨在通过粒度粗细不同的分析方法来得到更多的细节数据。", "innovation": "本文提出了一种分析方法，通过识别回答中的模态（tropes，即频繁出现且具有语义一致性的短语），从而在粗粒度和细粒度层次上分析LLM的态度和理由。研究表明，提示中包含的 demographic 特征显著影响了 PCT 结果，并揭示了不同的倾向性以及在封闭式回答与开放领域回答之间的差异。此外，这表明跨不同模型和提示生成的内容虽然立场不同，但具有相似的理由模式。", "conclusion": "研究表明，demographic 特征对 PCT 结果有显著影响，体现了偏差，并显示了在封闭式回答与开放领域回答之间存在的差异。通过识别回答中的模态，本文展示了不同模型和提示中生成的内容尽管立场不同，但在文本理由方面显示出重复的模式。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.10875", "html_url": "https://arxiv.org/abs/2503.10875", "title": "卷积矩形注意力模块", "title_en": "Convolutional Rectangular Attention Module", "authors": "Hai-Vy Nguyen,Fabrice Gamboa,Sixin Zhang,Reda Chhaibi,Serge Gratton,Thierry Giaccone", "background": "在传统的卷积网络中，空间注意力图通常以位置方式生成，这往往会带来不规则的边界，影响模型对新样本的泛化能力。因此，需要一种新的空间注意力机制来提高模型的性能，同时确保其对于新样本有更好的稳定性与泛化性。", "innovation": "提出了一个易于集成到任何卷积网络中的新颖的矩形空间注意力模块。该模块通过参数化限定矩形区域，使之仅由5个参数控制，从而提高了注意力区域的稳定性和对新样本的泛化能力。实验结果表明，该方法系统地优于位置方式生成注意力图的方法，提供了卷积模型中一个有用的空间注意力机制。", "conclusion": "本研究提供了一种新颖有效的卷积矩形注意力模块，通过实验表明该模块能够更好地引导模型关注图像中最具判别性的部分，从而提高整体模型性能，并对输入数据的特定部分具有较好的解释性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.12000", "html_url": "https://arxiv.org/abs/2504.12000", "title": "控制Rayleigh-Bénard对流: 驱动学习在湍流区域的有效性", "title_en": "Control of Rayleigh-Bénard Convection: Effectiveness of Reinforcement Learning in the Turbulent Regime", "authors": "Thorben Markmann,Michiel Straat,Sebastian Peitz,Barbara Hammer", "background": "数据驱动的流控在工业、能源系统和气候科学中具有巨大潜力。本文研究了强化学习（RL）在增加湍流情况下减少二维Rayleigh-Bénard对流（RBC）系统对流热传输的效用。研究了控制策略在不同初始条件和湍流水平下的普适性，并引入了一种奖励塑造技术以加速训练。", "innovation": "比较了通过单智能体Proximal Policy Optimization (PPO)训练的RL智能体与经典控制理论中的线性比例微分（PD）控制器。实验结果显示，RL智能体在中等湍流系统中最多可将对流降低33%，在高度湍流环境中降低10%，在所有实验条件下均显著优于PD控制。智能体展示了跨不同初始条件的强泛化性能，并在一定程度上实现了更复杂的湍流情况下的泛化。奖励塑造提高了样本效率，并在较高湍流水平下稳定了努塞尔数。", "conclusion": "研究证实了在增加湍流条件下，利用强化学习控制二维Rayleigh-Bénard对流的有效性，展示了RL方法在复杂动力系统控制中的优势，并提出了可加速训练的奖励塑造技术。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.19779", "html_url": "https://arxiv.org/abs/2410.19779", "title": "脑GPT：通过自回归预训练释放EEG通用基础模型的潜力", "title_en": "BrainGPT: Unleashing the Potential of EEG Generalist Foundation Model by Autoregressive Pre-training", "authors": "Tongtian Yue,Xuange Gao,Shuning Xue,Yepeng Tang,Longteng Guo,Jie Jiang,Jing Liu", "background": "脑电图（EEG）信号在揭示自发脑活动方面具有重要意义，这使得它们在神经科学研究中非常关键。然而，探索多样的EEG模型受到数据格式多样、过时的预训练方法和有限的迁移学习方法的限制，仅局限于单一数据集的专业模型。", "innovation": "本论文引入EEGPT，这是首个通用EEG基础模型，旨在解决上述挑战。首先，提出电极级建模策略，将每个电极视为基本单元，能整合多达138个电极的多种EEG数据，积累3750万预训练样本。其次，开发了首个自回归EEG预训练模型，从传统的掩码自编码器方法转向后续信号预测任务，更好地捕捉EEG数据的顺序和时间依赖性。此外，探索了最大参数量达11亿的模型的扩展规律，这是迄今为止EEG研究中最大的模型。第三，引入了基于可学习电极图网络的多任务迁移学习范式，首次证实了多任务的兼容性和协同作用。", "conclusion": "作为首个通用EEG基础模型，EEGPT在各种信号采集设备、受试者和任务方面具有广泛的兼容性，支持多达138个电极作为输入。此外，我们在12个基准测试中的5种任务上同时评估了它。EEGPT在所有下游任务上均胜过现有专业模型，其有效性通过广泛的消融研究进一步得到验证。这项工作为通用EEG建模开辟了新方向，提供了更好的可扩展性、迁移性和适应性，适用于广泛的EEG应用。代码和模型将公开发布。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.15376", "html_url": "https://arxiv.org/abs/2504.15376", "title": "在任何视频中理解摄像机运动", "title_en": "Towards Understanding Camera Motions in Any Video", "authors": "Zhiqiu Lin,Siyuan Cen,Daniel Jiang,Jay Karhade,Hewei Wang,Chancharik Mitra,Tiffany Ling,Yuhan Huang,Sifan Liu,Mingyu Chen,Rushikesh Zawar,Xue Bai,Yilun Du,Chuang Gan,Deva Ramanan", "background": "当前的研究主要集中在评估和提升摄像机运动的理解能力。以前的方法和数据集主要针对特定的镜头或场景，缺乏大规模多样化的视频数据和细致的质量控制过程。因此，缺乏统一的标准和方法来评估各种摄像机运动的理解性能。", "innovation": "该论文提出了CameraBench，一个包含约3000个不同互联网视频的大规模数据集和基准，这些视频通过严格多阶段的质量控制过程进行标注。该研究引入了一个与电影摄影师合作设计的摄像机运动元分类法，发现一些摄像机动作如跟踪需要理解场景内容。研究还揭示了领域专业知识和基于教程的培训能够显著提高准确度。此外，研究使用CameraBench评估了结构从运动（SfM）和视频-语言模型（VLMs），发现SfM模型难以捕捉依赖场景内容的语义元，而VLMs难以捕捉需要精确估计轨迹的几何元。通过进一步对生成的VLM进行微调，研究结合了SfM和VLM的优点，展示了其在动作增强标题，视频问答和视频文本检索中的应用。", "conclusion": "该研究希望通过提供taxonomy、基准和教程，推动未来努力最终理解任何视频中的摄像机运动。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.05753", "html_url": "https://arxiv.org/abs/2505.05753", "title": "机器人运动中的体征扩展法则趋向", "title_en": "Towards Embodiment Scaling Laws in Robot Locomotion", "authors": "Bo Ai,Liu Dai,Nico Bohlinger,Dichen Li,Tongzhou Mu,Zhanxin Wu,K. Fay,Henrik I. Christensen,Jan Peters,Hao Su", "background": "跨体征泛化对构建任何机器人都适用的通用体征代理有重要意义，然而其起作用的因素尚未充分理解。本文以机器人运动为例，研究体征扩展法则，探讨增加训练体征数量是否能提高对未见过体征的泛化能力。", "innovation": "本文通过程序生成近1000个具有拓扑、几何和关节级运动学变化的体征，并训练策略于随机子集中，观察到支持假设的正向扩展趋势。发现体征扩展比固定体征上的数据扩展能更广泛地泛化。培训的最优策略在仿真和现实世界中的新型体征上实现零样本迁移，包括Unitree Go2和H1。", "conclusion": "这些结果代表了通向通用体征智能的重大进展，对可配置机器人自适应控制、形态协同设计等领域具有重要意义。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.10520", "html_url": "https://arxiv.org/abs/2506.10520", "title": "专家宏图在大规模多任务推荐中的应用", "title_en": "Macro Graph of Experts for Billion-Scale Multi-Task Recommendation", "authors": "Hongyu Yao,Zijin Hong,Hao Chen,Zhiqing Li,Qijie Shen,Zuobin Ying,Qihua Feng,Huan Gong,Feiran Huang", "background": "在大规模的基于图的多任务学习中，不同的任务对应着各自的庞大图结构。传统的多任务学习方法往往忽略了这些图结构，只能依赖于用户和项目嵌入。然而，不考虑图结构会错过改进性能的巨大潜力。", "innovation": "本文提出了一种新的宏图专家（Macro Graph of Experts, MGOE）框架，这是首次能够利用宏图嵌入来捕捉特定任务的宏特征并建模特定任务专家之间的相关性。具体地，文章首次提出了宏图底（Macro Graph Bottom）的概念，使多任务学习模型能够有效集成图信息。此外，设计了宏预测塔（Macro Prediction Tower）来动态跨任务整合宏知识。", "conclusion": "MGOE已经在大规模部署中应用于一个领先的亿级推荐系统的主页多任务学习。在三个公开基准数据集上的离线实验表明，MGOE在其在最先进的多任务学习方法中表现更优。在线A/B测试进一步证实了MGOE在亿级推荐系统中的优越性，确立了MGOE作为多任务图推荐的突破性进展。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.07338", "html_url": "https://arxiv.org/abs/2507.07338", "title": "Bayesian Double Descent", "title_en": "Bayesian Double Descent", "authors": "Nick Polson,Vadim Sokolov", "background": "双三次现象是过参数化统计模型中的一个现象，而本文旨在从贝叶斯视角来研究这一现象。过参数化模型如深度神经网络在其风险特征中表现出一种有趣的再下降属性，这是机器学习领域的一个最近现象，受到了许多研究的关注。随着模型复杂性的增加，在传统偏差-方差权衡区域出现了U形区域，但在参数数量等于观测数量、模型达到插值后风险可能变得无穷大，然后在过参数化区域中风险重新下降，这就是双三次效应。", "innovation": "本文展示了双三次效应具有自然的贝叶斯解释，并且它并不与贝叶斯模型固有的奥卡姆剃刀原则相冲突。开发了包括Dawid的模型比较理论、Dickey-Savage结果以及与广义岭回归和收缩方法的联系在内的综合理论基础。还通过神经网络中的贝叶斯模型选择例子，对无限高斯平均模型和非参数回归进行了详细的分析。", "conclusion": "最后，文章为未来研究的方向指明了路径。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2504.21034", "html_url": "https://arxiv.org/abs/2504.21034", "title": "SAGA: 一种治理人工智能代理系统的安全架构", "title_en": "SAGA: A Security Architecture for Governing AI Agentic Systems", "authors": "Georgios Syros,Anshuman Suri,Jacob Ginesin,Cristina Nita-Rotaru,Alina Oprea", "background": "大型语言模型（LLM）代理越来越多地自主地相互交互、协作和委派任务，而无需大量的直接人类干预。虽然行业指南强调用户需要对他们的代理系统的全面控制，以减轻恶意代理可能造成的潜在损害，但目前提出的一些代理系统设计仍然停留在理论层面，缺乏具体的实现和评估，特别是没有提供用户控制的代理管理系统。", "innovation": "我们提出了SAGA，这是一种可扩展的安全架构，用于治理代理系统，提供了用户对其代理生命周期的监督。SAGA包括：1) 用户向中央实体（Provider）注册代理，Provider保存代理联系信息和用户定义的访问控制策略；2) 引入了一种加密机制来生成访问控制令牌，提供了对代理与其他代理交互的细腻控制，并提供了正式的安全保证。", "conclusion": "我们在不同的代理任务上评估了SAGA，使用分布在不同地理位置的代理和多个设备和云上的LLM，证明了SAGA在各种条件下的最小性能开销，不会影响底层任务的实用性。我们的架构允许在敏感环境中安全可靠地部署自主代理，加速了这项技术在这些环境中的负责任采用。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2404.13098", "html_url": "https://arxiv.org/abs/2404.13098", "title": "使用线性规划的自字典方法从高光谱图像中提取端元", "title_en": "Endmember Extraction from Hyperspectral Images Using Self-Dictionary Approach with Linear Programming", "authors": "Tomohiko Mizutani", "background": "高光谱成像技术具有广泛的应用，如森林管理、矿产资源勘探和地球表面监测。恰当的端元提取是利用这种技术的关键步骤，它旨在识别观测场景中材料的光谱特征。理论研究表明，使用线性规划（LP）的自字典方法，如Hottopixx方法，是有效提取端元的方法。然而，由于这些方法需要解决的LP问题数量随着图像中像素数量的平方增长，导致计算成本高，其实际应用效果有待验证。", "innovation": "本文提出了一种增强型Hottopixx实现方法，旨在降低计算时间并提高端元提取性能。通过实验展示了其有效性，表明该实现方法能够应用于实际高光谱图像的端元提取，使得端元特征的估计具有较高的准确性。", "conclusion": "我们的实现使Hottopixx方法能够应用于实际的高光谱图像端元提取，并且在估计端元签名方面达到了合理的准确性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.03077", "html_url": "https://arxiv.org/abs/2505.03077", "title": "动态操作的潜适应计划器", "title_en": "Latent Adaptive Planner for Dynamic Manipulation", "authors": "Donghun Noh,Deqian Kong,Minglu Zhao,Andrew Lizarraga,Jianwen Xie,Ying Nian Wu,Dennis Hong", "background": "本文介绍了潜适应计划器（LAP），这是一种用于动态非抓取操作（例如盒子接住）的轨迹级潜变量策略。LAP通过将规划问题纳入低维潜空间的推理过程，并从人类演示视频中有效学习来解决规划问题。在执行过程中，LAP能够实现实时适应，通过保持潜计划的后验概率并进行变分重规划来适应不断变化的观察信息。", "innovation": "1. 利用低维潜空间进行规划推理，有效从人类演示视频中学习； 2. 引入基于模型的比例映射，从人类演示生成精确的动力学关节状态和物体位置； 3. 通过各种盒子接住实验验证了LAP能够实现高性能的实时适应和跨异质机器人平台的成功转移。", "conclusion": "通过复杂的盒子接住实验，LAP在保持成功率、轨迹平滑度和能量效率的同时展示了人类相似的顺应运动和适应行为。总体而言，LAP可以实现实时适应的动态操作，并能通过人类演示视频成功转移至不同的机器人平台。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.14177", "html_url": "https://arxiv.org/abs/2505.14177", "title": "从广义马尔可夫链蒙特卡罗稳定性到处理非凸采样问题的近邻马尔可夫链蒙特卡罗收敛性", "title_en": "From stability of Langevin diffusion to convergence of proximal MCMC for non-log-concave sampling", "authors": "Marien Renaud,Valentin De Bortoli,Arthur Leclaire,Nicolas Papadakis", "background": "在非凸势能的情况下，Unadjusted Langevin算法(ULA)的离散时间稳定性得到了研究。由于许多实际问题如成像逆问题中的势能在非凸和非光滑的情况下，Proximal Stochastic Gradient Langevin Algorithm (PSGLA)成为处理此类问题的常用算法。PSGLA 通过将向前-向后优化算法与 ULA 步骤结合来解决这些问题。", "innovation": "论文的主要创新在于结合了稳定性的研究结果和 Moreau 包络的性质，首次证明了PSGLA在非凸势能下的收敛性。同时，实验结果表明，PSGLA 在后验采样方面具有更快的收敛速度，同时保持了其恢复性质。", "conclusion": "通过理论分析和实验验证，本研究证明了PSGLA在处理非凸势能问题的可行性及有效性。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.00863", "html_url": "https://arxiv.org/abs/2506.00863", "title": "L3Cube-MahaEmotions: 使用CoTR提示和大型语言模型的马拉地语情感识别数据集", "title_en": "L3Cube-MahaEmotions: A Marathi Emotion Recognition Dataset with Synthetic Annotations using CoTR prompting and Large Language Models", "authors": "Nidhi Kowtal,Raviraj Joshi", "background": "低资源语言（如马拉地语）的情感识别因标注数据有限而面临挑战。此前的研究表明，合成标注通过大型语言模型（LLMs）可以产生高质量的情感识别训练数据，而验证和测试集则通过人工标注确保基准的可靠性。", "innovation": "本研究通过Chain-of-Translation（CoTR）提示技术，结合大型语言模型（如GPT-4和Llama3-405B），提出了一种高品质的马拉地语情感识别数据集，并通过合成标注方式生成了训练数据。值得注意的是，尽管GPT-4的预测表现优于微调后的BERT模型，但仅基于合成标签训练的BERT模型未能超越GPT-4。这一发现强调了高质量人工标注数据的重要性，并表明通用大语言模型比微调的BERT模型更适合处理复杂的低资源情感识别任务。", "conclusion": "GPT-4 的预测性能优于微调后的 BERT 模型，而仅基于合成标签训练的 BERT 模型未能超越 GPT-4。这表明数据集和模型可以兼职有助于解决复杂低资源情感识别任务。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.03796", "html_url": "https://arxiv.org/abs/2506.03796", "title": "Geoff：粒子加速器控制的通用优化框架与前端", "title_en": "Geoff: The Generic Optimization Framework & Frontend for Particle Accelerator Controls", "authors": "Penelope Madysa,Sabrina Appel,Verena Kain,Michael Schenk", "background": "全球的粒子加速器实验室正在研究利用机器学习技术以提高加速器的性能和不间断运行时间，这导致了各种各样的方法和算法的出现。为了统一这些不同的方法和算法，简化比较和迁移它们的过程，提出了Geoff这一框架。", "innovation": "Geoff提供了一个标准化的接口来解决优化问题，用于加快开发过程的实用函数，以及一个参考的图形用户界面应用程序，这些功能将各种方法统一起来，减少了用户在迁移或比较这些方法时的摩擦。", "conclusion": "Geoff是一个开源库，在CERN和GSI的合作下作为EURO-LABS项目的一部分进行开发、维护和更新。本文给出了Geoff的设计、特性及其当前的使用情况的概述。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20723", "html_url": "https://arxiv.org/abs/2508.20723", "title": "在随机框架下适应性优化拼车个性化收费", "title_en": "Adaptive Optimisation of Ride-Pooling Personalised Fares in a Stochastic Framework", "authors": "Michal Bujak,Rafal Kucharski", "background": "拼车系统要想成功，必须提供有吸引力的服务，即以具有吸引力的价格补偿乘客感知的成本。然而，由于时间价值存在显著异质性，每一位乘客的可接受价格对运营商来说都是未知的。本文通过在10天内以超过90%的准确率学习每一位乘客的时间价值来优化个性化收费。", "innovation": "本文提出了一种适应性定价策略，在这种策略下，运营商每天会构造一个逐步满足乘客期望并吸引更多乘客需求的报价。通过了解乘客的行为特征，运营商不仅能提高乘客满意度（增加乘客价值），还能提高自身的收益。此外，这种知识使得运营商能够消除无效的拼车行程，专注于吸引人的、有盈利潜力的组合。", "conclusion": "对于运营商而言，通过学习乘客个体的行为特征，不仅可以提高乘客满意度和利润，还能优化资源配置，提高运营效率，从而在拼车服务中取得更好的表现。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.17117", "html_url": "https://arxiv.org/abs/2508.17117", "title": "PlantVillageVQA：植物科学领域用于视觉语言模型基准测试的可视化问答数据集", "title_en": "PlantVillageVQA: A Visual Question Answering Dataset for Benchmarking Vision-Language Models in Plant Science", "authors": "Syed Nazmus Sakib,Nafiul Haque,Mohammad Zabed Hossain,Shifat E. Arman", "background": "PlantVillageVQA数据集源自广泛使用的PlantVillage图像库，旨在促进农业决策和分析中视觉语言模型的发展和评估。该数据集包含193,609个高质量的问题-答案（QA）对，覆盖55,448张图像，涉及14种作物和38种疾病状况。每个问题类别都经历了认知复杂性的多层次组织和九个不同的分类，通过一个基于模板的两阶段自动化管道生成这些问题，最终由领域专家迭代审查以保证科学准确性及相关性。", "innovation": "该数据集通过自动化模板和多阶段语言重构生成高质量问题-答案对，分为不同认知复杂度和主题类别，涵盖了广泛使用的PlantVillage图像库中的大量图像和作物疾病状况，提供了详细的科学准确性审查，旨在提升植物病害识别的诊断准确性，并促进农业领域的科学研究。", "conclusion": "最终提出了一个公开可获取的、标准化且由专家验证的数据库，用于提高植物病害识别的诊断准确性和推动农业领域的科学研究。此数据集将开源在指定的链接上。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09823", "html_url": "https://arxiv.org/abs/2507.09823", "title": "Nesterov Finds GRAAL: Optimal and Adaptive Gradient Method for Convex Optimization", "title_en": "Nesterov Finds GRAAL: Optimal and Adaptive Gradient Method for Convex Optimization", "authors": "Ekaterina Borodich,Dmitry Kovalev", "background": "该研究关注的是最小化连续可微凸目标函数的问题，即 $\text{min}_x f(x)$。最近发展了一种自适应的一阶方法 GRAAL，它通过估计目标函数的局部曲率来计算步长，而不依赖于线搜索或超参数调整，并达到了标准的固定步长梯度下降的迭代复杂度 $\text{O}(L \rVert x_0 - x^*\rVert^2 / \rvert)$，对于 $L$-光滑函数而言。然而，一个自然问题是：是否可以加速 GRAAL 的收敛速度，以匹配 Nesterov (1983) 提出的加速梯度下降算法的最佳复杂度 $\text{O}(\rVert \text{L} \rVert x_0 - x^*\rVert^2 / \rvert)^{0.5})$？尽管 Li 和 Lan (2025) 及 Suh 和 Ma (2025) 有尝试，但目前加速算法适应目标函数局部曲率的能力仍然有限。", "innovation": "本文解决了现有问题，开发了带有 Nesterov 加速的 GRAAL，使其能够像非加速的 GRAAL 一样，以几何或线性速率适应局部曲率。此外，作者证明了该算法在 $L$-光滑函数及更一般的 $(L_0, L_1)$-光滑性假设下，达到了接近最优的迭代复杂度。", "conclusion": "研究证明了带有 Nesterov 加速的 GRAAL 算法具有自适应能力，在 $L$-光滑函数及更一般情况下证明了接近最优的迭代复杂度。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21156", "html_url": "https://arxiv.org/abs/2508.21156", "title": "使用指令微调的大语言模型进行自动化缺陷优先级划分", "title_en": "Automated Bug Triaging using Instruction-Tuned Large Language Models", "authors": "Kiana Kiashemshaki,Arsham Khosravani,Alireza Hosseinpour,Arshia Akhavan", "background": "在大型项目中，缺陷优先级划分（bug triaging）往往是一个速度慢且不一致的任务。现有的方法难以高效且准确地将新出现的缺陷分配给开发者。", "innovation": "本文提出了一种轻量级框架，利用LoRA适配器对大语言模型（LLM）进行指令微调，并结合候选约束解码确保分配的有效性。该方法在EclipseJDT和Mozilla数据集上测试，尽管精确的Top-1准确率不高，但在短列表质量（Hit at 10）方面表现出色，达到0.753。尤其在处理最新快照数据时，准确率显著提高，显示了该框架在人机协作缺陷优先级划分中的潜力。研究表明，指令微调的大语言模型提供了一种替代代价高昂的功能工程和图论方法的实用选择。", "conclusion": "该框架通过指令微调大语言模型并结合候选约束解码，展现了在缺陷优先级划分中的效用和潜力。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21433", "html_url": "https://arxiv.org/abs/2508.21433", "title": "复杂性陷阱：简单的观察屏蔽与基于LLM的总结一样高效", "title_en": "The Complexity Trap: Simple Observation Masking Is as Efficient as LLM Summarization for Agent Context Management", "authors": "Tobias Lindenbauer,Igor Slinko,Ludwig Felder,Egor Bogomolov,Yaroslav Zharov", "background": "大型语言模型（LLM）基于的代理可以解决复杂的任务，但这个过程可能导致长期、昂贵的上下文历史记录。当前的软件工程（SE）代理（如OpenHands或Cursor）使用基于LLM的总结来应对这个问题，但不清楚这种增加的复杂性是否真的提供了可衡量的表现优势，或者仅仅是省略较老观察的做法更有利。", "innovation": "本文通过在SWE-agent上进行系统比较，验证了五种不同的模型配置下的观察屏蔽策略，发现简单的观察屏蔽策略可以将成本减半，同时与基于LLM的总结策略的解决率相当，甚至在某些情况下超过了后者。该策略表明，在SWE-agent的SWE-bench Verified中，最有效的上下文管理可能就是最简单的。", "conclusion": "最有效的和最高效的上下文管理可能是最简单的，这一研究结果在SWE-agent的SWE-bench Verified中得到了验证，并且作者已经发布了代码和数据以供验证。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20527", "html_url": "https://arxiv.org/abs/2508.20527", "title": "分子机器学习在化学工艺设计中的应用", "title_en": "Molecular Machine Learning in Chemical Process Design", "authors": "Jan G. Rittig,Manuel Dahmen,Martin Grohe,Philippe Schwaller,Alexander Mitsos", "background": "近来，分子机器学习（ML）在化学工艺工程领域显示了巨大的潜力，主要体现在两项关键方面：一是能够对纯组分和其混合物的性能提供高度准确的预测；二是能够探索新的分子结构空间。当前，各种先进的分子ML模型正在被开发和应用，但如何将这些方法扩展到化学工艺规模，实现分子ML在过程设计和优化中的集成仍是一个未被充分探索的领域。", "innovation": "本文深入探讨了分子ML的主要方法，如图神经网络和变压器，提出了通过融合物理化学知识来进一步提高这些方法的可能性。文章还强调了将分子ML应用于大规模化学工艺中，有望加速新型分子和过程的识别，这是以前并未广泛探索的领域。为了实现这一目标，创建分子和过程设计基准并实际验证提出的候选物是必不可少的，这些工作可能需要与化学工业合作完成。", "conclusion": "本文评审了当前最先进的分子ML模型，并讨论了潜在的研究方向，旨在进一步推动分子ML在化学工艺设计中的应用，通过创建分子和过程设计基准来加速新分子和过程的识别。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.06680", "html_url": "https://arxiv.org/abs/2506.06680", "title": "IVF治疗中胚胎选择的深度学习模型解析", "title_en": "Interpretation of Deep Learning Model in Embryo Selection for In Vitro Fertilization (IVF) Treatment", "authors": "Radha Kodali,Venkata Rao Dhulipalla,Venkata Siva Kishor Tatavarty,Madhavi Nadakuditi,Bharadwaj Thiruveedhula,Suryanarayana Gunnam,Durga Prasad Bavirisetti,Gogulamudi Pradeep Reddy", "background": "不孕症对个人的生活质量有重大影响，社会和心理层面均受其影响，预计未来将有所增加。体内受精（IVF）已成为经济发达国家处理低生育率问题的主要技术之一。胚胎学家通过观察胚胎的囊胚图像来评估胚胎的生存能力，然后挑选最合适的胚胎进行移植，但此过程耗时且效率不高。", "innovation": "本研究提出了一种基于卷积神经网络（CNN）和长期短期记忆网络（LSTM）架构融合的可解释人工智能（XAI）框架（CNN-LSTM），用于分类胚胎。通过深度学习方法，该模型实现了高精度的胚胎分类同时保持可解释性。", "conclusion": "该研究引入的方法提高了选择合适胚胎进行IVF的效率和准确性，同时保留了模型的可解释性，有助于医生和胚胎学家更好地理解模型决策过程。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21454", "html_url": "https://arxiv.org/abs/2508.21454", "title": "利用大型语言模型增强指针分析中的语义理解", "title_en": "Enhancing Semantic Understanding in Pointer Analysis using Large Language Models", "authors": "Baijun Cheng,Kailong Wang,Ling Shi,Haoyu Wang,Yao Guo,Ding Li,Xiangqun Chen", "background": "指针分析已经研究了四十年，但现有框架仍然受到错误信息传播的困扰。主要限制来自于它们对代码语义理解的不足，导致对用户自定义函数的处理过于保守。近年来，大型语言模型（LLMs）的进步为弥合这一差距提供了新的机会。", "innovation": "本文提出了一种名为LMPA（LLM增强的指针分析）的新方法，通过将LLMs整合到指针分析中以增强其精确度和可扩展性。LMPA能够识别类似于系统API的用户自定义函数，并以适当的方式建模它们，从而减少错误的函数交叉调用传播。此外，它通过推断初始的points-to集合并引入新的自然语言增强的总结策略来提升基于总结的分析。", "conclusion": "我们讨论了实现此愿景中面临的几个关键挑战。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.05066", "html_url": "https://arxiv.org/abs/2508.05066", "title": "两种几何Jensen-Shannon发散的故事", "title_en": "Two tales for a geometric Jensen--Shannon divergence", "authors": "Frank Nielsen", "background": "几何Jensen-Shannon发散（G-JSD）由于其在高斯分布间的闭形式表达而受到机器学习和信息科学领域的关注。现有定义的G-JSD适合概率密度。这篇论文提出了一种专为正值密度设计的G-JSD新定义，即扩展G-JSD，该定义适用于更一般的正值测度情况。论文也探讨了这些类型G-JSD与Jeffreys发散、Bhattacharyya距离以及系数的关系，并展示了在多元高斯分布场景下它们的闭形式公式，同时考虑了基于投影γ发散的蒙特卡洛随机估算和近似方法。此外，还证明了扩展G-JSD是一种$f$-发散，并具有信息几何中的分离性和信息单调性。最后，作者解释了两种G-JSD作为普通JSD正则化的含义，但指出其平方根不一定是度量距离。", "innovation": "提出了一种适用于正值密度的新型几何Jensen-Shannon发散（扩展G-JSD），该定义比现有定义更广泛。阐述了G-JSD和扩展G-JSD与Jeffreys发散、Bhattacharyya距离和系数的联系，并提供了在多元高斯分布场景下的闭形式公式。使用投影γ发散的方法进行G-JSD的蒙特卡洛随机估算和近似。证明了扩展G-JSD是$f$-发散，并展示了其信息几何特性。", "conclusion": "文中给出了两种G-JSD的闭形式表达，并介绍了它们与Jeffreys发散、Bhattacharyya距离及系数的关系。证明了扩展G-JSD是一种$f$-发散，并有信息几何特性。提出了基于投影γ发散的随机估算法，并指出两种G-JSD不一定是度量距离。最后，探讨了G-JSD作为一种普通JSD正则化的解释。"}
{"llm_update_time": "20250901", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.20108", "html_url": "https://arxiv.org/abs/2508.20108", "title": "通过收益率和波动性归一化来缓解股票价格数据中的分布偏移以实现准确预测", "title_en": "Mitigating Distribution Shift in Stock Price Data via Return-Volatility Normalization for Accurate Prediction", "authors": "Hyunwoo Lee,Jihyeong Jeon,Jaemin Hong,U Kang", "background": "股票价格预测因其潜在的市场模式识别能力和决策支持，吸引了学术界和产业界的关注。然而，现有的方法在处理分布偏移方面往往不够有效，通常只关注规模调整或表征适应，而未能充分解决训练数据和测试数据之间的分布差异和形状错位问题。", "innovation": "提出了ReVol（返回-波动性归一化法，以缓解股票价格数据中的分布偏移），这是一种稳健的股票价格预测方法，明确地解决了分布偏移问题。ReVol采用了三种关键策略来缓解这些偏移：(1) 对价格特征进行归一化以去除样本特定特征，包括收益率、波动性和价格规模，(2) 使用注意力机制模块准确估计这些特征，从而减少市场异常的影响，以及(3) 将样本特征重新整合到预测过程中，恢复在归一化过程中丢失的特性。此外，ReVol结合了几何布朗运动用于长期趋势建模以及神经网络用于短期模式识别，综合利用了它们的优势。", "conclusion": "在多个现实数据集上的实验结果表明，ReVol在大多数情况下能够提升最先进的骨干模型的性能，分别实现了IC改进超过0.03和SR超过0.7的平均改善。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21097", "html_url": "https://arxiv.org/abs/2508.21097", "title": "使用大型语言模型和检索增强生成的模型驱动的量子代码生成", "title_en": "Model-Driven Quantum Code Generation Using Large Language Models and Retrieval-Augmented Generation", "authors": "Nazanin Siavash,Armin Moin", "background": "背景在于通过利用大型语言模型（LLMs）和检索增强生成（RAG）管道来探索模型到文本/代码转换的新研究方向。特别是在量子和量子-经典混合软件系统中，模型驱动的方法可以帮助降低由于异构平台和缺乏开发人员技能而导致的成本和风险。研究者验证了从软件系统的UML模型实例生成代码的想法，并使用Qiskit库实现了这些代码的执行，该库在基于门或量子电路的量子计算机上运行。实验结果表明，精心设计的提示可以将代码BLEU分数提高四倍，从而产生更准确和一致的量子代码。", "innovation": "创新在于提出了一种结合大型语言模型和检索增强生成（RAG）的新方法来生成量子代码，特别适用于量子和混合量子-经典软件系统。方法包括部署RAG管道中的公共GitHub仓库中的Qiskit代码示例，以及通过精心设计的提示来提高代码质量。此外，研究还提出了进一步调查方向，如将软件系统模型实例作为RAG管道中的信息源，或使用大型语言模型执行代码到代码的转换，例如针对编译用例（例如，Transpilation）的转换.", "conclusion": "通过精心设计的提示，可以从UML模型生成高质量的量子代码，通过RAG管道可以显著提高生成代码的准确性和一致性。未来研究可以通过进一步实验来探索其他研究问题和想法，如将软件系统模型实例作为RAG管道的信息源，以及使用大型语言模型进行代码到代码的转换，例如支持编译用例的代码转换。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21107", "html_url": "https://arxiv.org/abs/2508.21107", "title": "通过对抗强化学习学习生成单元测试", "title_en": "Learning to Generate Unit Test via Adversarial Reinforcement Learning", "authors": "Dongjun Lee,Changho Hwang,Kimin Lee", "background": "单元测试是编程中的一项核心实践，用于系统地评估由人类开发者或大型语言模型（LLMs）生成的程序。然而，在编写全面的单元测试时面临挑战，因此，已经采用了LLMs来自动进行测试生成，但如何训练LLMs生成高质量的单元测试的方法仍较少被研究。", "innovation": "本文提出了一种新颖的强化学习框架UTRL，通过对抗训练的方式训练一个LLM生成高质量的单元测试。该框架通过反复迭代的方式训练语言模型和代码生成器，使模型通过对抗和强化学习相互竞争以提升生成能力和质量。", "conclusion": "实验结果表明，通过UTRL训练的Qwen3-4B模型生成的单元测试质量较高，更接近真实单元测试的结果，与通过监督微调训练模型相比，也优于前沿模型如GPT-4.1。这突显了UTRL在训练LLMs生成高质量单元测试方面的有效性。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21432", "html_url": "https://arxiv.org/abs/2508.21432", "title": "RepoMark：代码使用审计框架用于代码大型语言模型", "title_en": "RepoMark: A Code Usage Auditing Framework for Code Large Language Models", "authors": "Wenjie Qu,Yuguang Zhou,Bo Wang,Wengrui Zheng,Yuexin Li,Jinyuan Jia,Jiaheng Zhang", "background": "大型语言模型（LLMs）在代码生成中的快速发展已经改变了软件开发的方式，通过自动化编码任务实现了前所未有的效率。然而，这些模型在开源代码存储库（如GitHub）上的训练引发了重要的伦理和法律问题，特别是在数据授权和开源许可证合规性方面。开发人员越来越质疑模型训练者在使用存储库进行训练之前是否获得了适当的授权，特别是在数据收集缺乏透明性的情况下。", "innovation": "我们提出了一个名为RepoMark的新颖数据标记框架，以审计代码LLM的数据使用情况。该方法使存储库所有者能够验证其代码是否被用于训练，同时确保语义保留、不可感知性和理论假阳性率（FDR）的保证。通过生成多个语义等价的代码变体，RepoMark将数据标志引入代码文件，并在检测过程中利用一种基于排名的假设检验来检测模型中的记忆现象。与之前的数据审计方法相比，RepoMark在样本效率方面显著提升，即使用户的存储库只有少量代码文件，也能够实现有效的审计。实验表明，在严格的5% FDR保证下，RepoMark在小型代码存储库上的检测成功率超过了90%，这在相同条件下要优于所有现有数据贴标技术，这些技术的准确性均低于55%。这进一步验证了RepoMark作为增强代码LLM训练透明度的稳健、具有理论依据的且前景广阔的解决方案的有效性。", "conclusion": "这种进一步验证了RepoMark作为增强代码LLM训练透明度的稳健、具有理论依据的且前景广阔的解决方案的有效性。RepoMark能够确保代码所有者的权益，并通过引入数据标志和实施新型排名假设检验的方法提高了数据审计的性能和可靠性。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21386", "html_url": "https://arxiv.org/abs/2508.21386", "title": "欧盟核心网络安全立法中的风险与合规", "title_en": "Risks and Compliance with the EU's Core Cyber Security Legislation", "authors": "Jukka Ruohonen,Jesper Løffler Nielsen,Jakub Skórczynski", "background": "欧盟长期以来倾向于采用基于风险的监管方法。这种方法也被用于欧盟最近颁布的网络安全立法中。网络安全风险与新法规的合规性密切相关。", "innovation": "本文通过定性法律解释和构建分类系统的方法，研究了欧盟五项核心网络安全立法中的风险框架。发现这些法令涵盖了不同类型的网络安全风险，包括技术、组织和人类安全风险，以及超出人为行动的风险。研究揭示了接受性风险、非概率风险和剩余风险方面的空白点，指出欧盟的新网络安全立法显著扩展了基于风险的监管方法，同时也增加了复杂性和合规负担。", "conclusion": "本文得出结论，欧盟新的网络安全立法在显著扩展基于风险的监管方法的同时，也带来了复杂性和合规负担的增加。作者建议，为了应对合规挑战和推动研究，提出了几项实际建议。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21553", "html_url": "https://arxiv.org/abs/2508.21553", "title": "强化学习中的可重用测试套件", "title_en": "Reusable Test Suites for Reinforcement Learning", "authors": "Jørn Eirik Betten,Quentin Mazouni,Dennis Gross,Pedro Lind,Helge Spieker", "background": "强化学习（RL）代理在解决序列决策任务方面展现出巨大潜力。然而，验证代理策略行为的可靠性和性能，以便部署，仍然是一个挑战。现有的大多数强化学习策略测试方法都针对特定的代理策略生成测试套件，其对其他策略的相关性却模糊不清。", "innovation": "本文提出了一种名为Multi-Policy Test Case Selection（MPTCS）的新型自动化测试套件选择方法，旨在从任何策略测试框架生成的基于可解决性、多样性和通用难度的测试案例中提取可复用的策略无关测试案例，揭示代理行为的常见缺陷。该方法通过一组策略从候选池中选择测试案例，基于难度评分。此外，还探讨了如何通过基于质量多样性算法的离散通用测试案例描述表面来促进测试套件的多样性，以覆盖状态空间并触发产生故障行为的策略。", "conclusion": "研究评估了难度评分的有效性，以及方法的有效性和成本如何取决于策略集中的策略数量。结果表明，MPTCS在不同策略数量下的效果和成本有所差异，并且通过MPTCS生成的测试套件能够有效揭示代理行为中的典型缺陷。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21811", "html_url": "https://arxiv.org/abs/2508.21811", "title": "Agile 方法论在信息技术行业中 DevOps 实践中的集成", "title_en": "The Integration of Agile Methodologies in DevOps Practices within the Information Technology Industry", "authors": "Ashley Hourigan,Ridewaan Hanslo", "background": "信息技术行业对快速软件交付的需求显著增强，要求更快的软件产品和服务发布，以满足客户期望。敏捷方法正在取代瀑布模型等传统方法，强调灵活性、迭代开发和对变更的适应性，而非僵化的计划和执行。DevOps 是敏捷方法的进一步演变，强调开发和运营团队的协作，专注于持续集成和部署，以交付具有弹性和高质量的软件产品和服务。本研究旨在深入评估敏捷和 DevOps 实践在信息技术行业中的可行性与适用性，确定敏捷方法在 DevOps 实践中的集成可能性。", "innovation": "通过 11 场半结构化访谈，研究者从不同行业领域的敏捷和 DevOps 实践者那里收集了数据。通过主题分析，提取并综合了 51 个独特的代码，形成了 19 个主题，涵盖了 DevOps 生命周期的每个阶段，特别关注将敏捷方法集成到 DevOps 实践中的方式。研究提出了对敏捷方法与 DevOps 实践之间相互关系的新见解，不仅满足了研究目标，还丰富了对未来研究和实践的指导。", "conclusion": "本研究明确了敏捷方法在 DevOps 实践中的应用和集成，为未来的研究和实践提供了新视角和指导建议。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21634", "html_url": "https://arxiv.org/abs/2508.21634", "title": "人类编写代码 vs. 人工智能生成代码：缺陷、漏洞和复杂性的大规模研究", "title_en": "Human-Written vs. AI-Generated Code: A Large-Scale Study of Defects, Vulnerabilities, and Complexity", "authors": "Domenico Cotroneo,Cristina Improta,Pietro Liguori", "background": "随着AI代码助手在软件开发流程中的集成越来越广泛，理解它们生成的代码与人工编写的代码之间的差异变得至关重要。这关系到代码的可靠性、可维护性和安全性。本文通过在Python和Java两种广泛使用的编程语言上对比分析50万段代码样例，从缺陷、安全漏洞和结构复杂性等多个维度，对人类编写和三款最先进的AI模型（ChatGPT、DeepSeek-Coder和Qwen-Coder）自动生成的代码进行了大规模对比研究。", "innovation": "这一研究针对AI生成代码与人工编写代码进行了全面且大规模的对比分析，覆盖多个维度的质量指标，包括缺陷、安全漏洞和结构复杂性。研究使用了正交缺陷分类（ODC）对缺陷进行分类，并使用通用缺陷枚举（CWE）对安全漏洞进行评估。结果显示，AI生成的代码通常更为简单和重复，但更易出现未用构造和硬编码调试问题；而人类编写的代码则具有更大的结构性复杂性，且维护性问题更为集中。值得注意的是，AI生成的代码还包含更多高风险的安全漏洞。这些发现凸显了人工智能与人类编写的代码在缺陷特征上的差异，并强调了在AI辅助编程领域需要专门的质量保证实践的重要性。", "conclusion": "本研究揭示了AI生成代码和人工编写代码在缺陷特征上的差异，强调了在AI辅助编程领域需要采取专门的质量保证实践。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21302", "html_url": "https://arxiv.org/abs/2508.21302", "title": "Locus: 自主合成谓词以促进定向模糊测试", "title_en": "Locus: Agentic Predicate Synthesis for Directed Fuzzing", "authors": "Jie Zhu,Chihao Shen,Ziyang Li,Jiahao Yu,Yizheng Chen,Kexin Pei", "background": "定向模糊测试旨在找到能够导致特定目标程序状态的程序输入。这项技术在调试系统崩溃、验证已报告的错误以及为潜在漏洞生成利用工具等方面具有广泛的应用。然而，由于目标状态常深嵌于程序中，且可能的程序输入导致的搜索空间巨大，使得这一任务变得极具挑战性。现有方法依赖于分支距离或手动指定的约束来指导搜索，但单独的分支不足以精确地表征接近目标状态的过程，而手动指定的约束往往针对特定的错误类型，难以推广到不同的目标状态和程序中。", "innovation": "我们提出了一种称为Locus的新框架，旨在提高定向模糊测试的效率。我们的核心洞察是合成谓词以捕获模糊测试进展的状态，并作为接近目标状态的里程标识。借助程序分析工具，Locus能够自动化生成和迭代优化候选谓词，且通过符号执行确保谓词严格放宽目标状态以防止误拒绝。实验表明，Locus显著提高了八种尖端模糊测试器在发现真实漏洞方面的效率，平均加速41.6倍。迄今为止，Locus已发现八个先前未修补的错误，其中一个已被承认并提交了草案补丁。", "conclusion": "Locus通过合成谓词和自动化的程序分析工具，大幅提升了定向模糊测试的效率，能够在多种程序中捕获有意义的中间状态，从而帮助更快速地找到程序漏洞。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21666", "html_url": "https://arxiv.org/abs/2508.21666", "title": "利用物联网和生成式AI实现气象自适应学习以增强气候适应教育", "title_en": "Harnessing IoT and Generative AI for Weather-Adaptive Learning in Climate Resilience Education", "authors": "Imran S. A. Khan,Emmanuel G. Blanchard,Sébastien George", "background": "气候韧性教育是一个重要的教育领域，旨在帮助人们理解和适应气候变化带来的影响。传统的气候教育方式通常较为静态，缺乏动态性和个性化。为了应对这一挑战，本文介绍了一种名为FACTS（Future Atmospheric Conditions Training System）的新型平台，旨在通过基于地点的适应性学习体验提高气候韧性教育的效果。", "innovation": "FACTS平台创新性地结合了物联网（IoT）传感器收集到的实时大气数据和知识库中精选的学习资源，生成动态的、与地点相关的学习挑战。它利用生成式AI技术，对学习者的反应进行分析，并提供个性化的反馈和支持。这种结合了物联网和生成式AI的气象自适应学习技术为增强教育参与度和提升人们对气候的认识提供了新的可能性", "conclusion": "一项用户评估结果显示，参与者觉得这一系统易于使用且对于增强与气候韧性相关的知识非常有效。这些发现表明，将物联网和生成式AI整合到气象自适应学习技术中，有可能显著提高教育的参与度并促进气候意识的培养。该研究为未来气候适应教育的创新发展提供了重要启示。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21289", "html_url": "https://arxiv.org/abs/2508.21289", "title": "使用持续集成解决HPC中的重现性挑战", "title_en": "Addressing Reproducibility Challenges in HPC with Continuous Integration", "authors": "Valérie Hayot-Sasson,Nathaniel Hudson,André Bauer,Maxime Gonthier,Ian Foster,Kyle Chard", "background": "高性能计算（HPC）社区采用了激励结构来促进可再现的研究，主要会议为符合可再现性要求的论文颁发徽章。然而，许多论文未能达到这些要求。由于HPC基础设施和软件的独特性及其严格执行的访问要求，这可能限制了重现性机会。在缺乏资源访问的情况下，我们提出通过持续集成（CI）的定期文档测试，结合完整的源信息，作为替代方案。现有的CI解决方案在符合HPC标准方面存在局限性，可能导致应用程序的重现性受损。因此，本文介绍了CORRECT GitHub操作，以实现安全执行远程HPC资源上的测试，解决了HPC中的重现性挑战，并通过实现CORRECT展示了自动化和记录重现性评估的有效性。", "innovation": "提出了CORRECT GitHub操作，这是一种安全执行远程HPC资源上测试的持续集成解决方案，能够改善HPC应用的重现性。通过这种方法，实现了自动化和记录重现性评估，从而绕过了对直接访问HPC资源的依赖。CORRECT在不同类型的HPC应用程序中具有广泛的适用性，提高了HPC环境下的研究可再现性水平。", "conclusion": "CORRECT的使用可以改善HPC应用程序的重现性。通过CORRECT，研究可以实现自动化和文档化重现性评估，从而提高研究的可靠性。未来需要进一步研究和开发更加符合HPC标准的持续集成解决方案，以更好地促进研究的重现性。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.13821", "html_url": "https://arxiv.org/abs/2506.13821", "title": "软件是基础设施：故障、成功、成本与形式化验证的案例", "title_en": "Software is infrastructure: failures, successes, costs, and the case for formal verification", "authors": "Giovanni Bernardi,Adrian Francalanza,Marco Peressotti,Mohammad Reza Mousavi", "background": "本文概述了软件在现代社会中的作用以及低质量软件带来的巨大成本。为了强调这一点，作者回溯了过去40年中一些重大软件故障的成本。这些成本证明了研究、学习和应用形式化软件验证（特别是程序分析）的重要性。", "innovation": "作者支持使用成功的工业经验来支持形式化验证的研究、学习和应用的必要性。", "conclusion": "通过这些成功的经验，作者强调了形式化验证在提高软件质量、防止重大故障方面的必要性和重要性。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21636", "html_url": "https://arxiv.org/abs/2508.21636", "title": "检测AI代码生成器中的隐形数据投毒攻击", "title_en": "Detecting Stealthy Data Poisoning Attacks in AI Code Generators", "authors": "Cristina Improta", "background": "深度学习（DL）模型在自然语言到代码生成方面的应用已经成为现代软件开发管道的重要组成部分。然而，这些模型对大量数据的依赖，这些数据通常来自未经清理的在线来源，使其暴露在数据投毒攻击之下。对手通过注入恶意样本来悄悄地偏移模型的行为。最近的攻击方法会悄悄地将安全代码替换为语义上等价但易受攻击的实现，而不依赖于具体的触发器来发动攻击，这使得检测方法难以区分干净样本和受污染样本。", "innovation": "本研究对现有的投毒检测方法在隐形威胁模型下的有效性进行了系统性的研究。特别地，作者在三种DL模型（CodeBERT、CodeT5+、AST-T5）上进行了正确定向的投毒攻击，并评估了频谱特征分析、激活聚类和静态分析作为防御手段的有效性。研究表明，所有方法在检测无触发的投毒时都面临困难，基于表示的方法无法有效隔离被污染的样本，而静态分析则导致误报和漏报，凸显了为AI辅助代码生成提供更多强大且独立于触发器的防御措施的必要性。", "conclusion": "所有现有的检测方法在检测隐形投毒攻击时都表现不佳，基于表示的方法无法有效隔离受污染样本，静态分析则频繁出现误报和漏报的情况。因此，研究报告强调了需要开发更强大且独立于触发器的防御措施，以进一步提升AI辅助代码生成的安全性。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.07328", "html_url": "https://arxiv.org/abs/2503.07328", "title": "完整地闭合循环：具有表达性循环引用的可达性类型（扩展版本）", "title_en": "Complete the Cycle: Reachability Types with Expressive Cyclic References (Extended Version)", "authors": "Haotian Deng,Siyuan He,Songlin Jia,Yuyan Bao,Tiark Rompf", "background": "程序中结合了命名和可变状态的局部推理是一个长期存在的挑战。现有的方法——所有权系统、线性和线性类型、独特类型和词法效果跟踪——要么施加全局限制（如独特性或线性要求），要么依赖于浅表的语法分析。这些设计在处理高阶函数和共享可变状态时表现不足。可达性类型（RT）能够追踪高级程序中的混同和分离，确保运行时安全性和非干扰性。然而，RT 系统面临三个关键限制：(1) 禁止循环引用，排除了非终止计算和固定点组合子；(2) 深度追踪要求一个限定符必须包括所有可传递可达位置，降低了精度并阻碍了如细粒度并行等优化；(3) 作为引用的限定符不变性使得引用工厂无法表述。", "innovation": "本文通过在 RT 中扩展三种新的机制来解决这些限制，从而增强了表达性。首先，引入循环引用，允许通过存储直接编码递归模式。其次，采用浅表限定符追踪，将引用与其可传递可达值解耦。最后，引入带有引用子类型的逃逸规则，允许作为引用的限定符超出其分配上下文。这些扩展在 ℓ_{<:}^{◦}-演算中形式化，并通过机械化证明了类型正确性。案例研究进一步展示了这些扩展对固定点组合子、非干扰并行和读取只引用逃逸的支持。", "conclusion": "这些扩展解决了 RT 系统的基本限制，增强了高级程序对循环引用、浅表追踪和引出规则的支持，从而提高了类型系统的表达能力和优化潜力。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.21417", "html_url": "https://arxiv.org/abs/2508.21417", "title": "LLM存储库中脆弱包依赖的实证研究", "title_en": "An Empirical Study of Vulnerable Package Dependencies in LLM Repositories", "authors": "Shuhan Liu,Xing Hu,Xin Xia,David Lo,Xiaohu Yang", "background": "近年来，大型语言模型（LLMs）发展迅速，推动了各个领域的发展。尽管LLMs得到了广泛应用，但它们对包管理系统的外部代码依赖严重，形成了复杂且相互连接的LLM依赖供应链。依赖中的漏洞可能会使LLMs面临安全风险。现有研究主要集中在模型级别的安全威胁上，而对LLM依赖供应链中的漏洞则未给予足够关注。因此，有必要开展相关研究填补这一空白。", "innovation": "本文通过对52个开源LLMs的实证分析，检验了它们的第三方依赖关系及其相关漏洞，从而理解维护者在实践中是如何管理第三方漏洞的。此外，还对比了LLM生态系统和Python生态系统中的第三方依赖漏洞情况。研究发现，LLM生态系统中超过56.2个月未公开的漏洞占比为一半，远远高于Python生态系统中的时间。有75.8%的LLMs配置文件中包含易受攻击的依赖。本研究扩展了对LLM供应链风险的理解，为实践者提供了宝贵的见解，并指出了提升LLM供应链安全性的潜在方向。", "conclusion": "我们的研究结果表明，LLM生态系统中的大多数漏洞在超过56.2个月后仍未被披露。75.8%的LLMs在配置文件中包含易受攻击的依赖。这些发现展示了L大型语言模型供应链中未知威胁的风险，为制定防御策略提供了参考，强调了提高LLM供应链安全性的必要性。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2502.04184", "html_url": "https://arxiv.org/abs/2502.04184", "title": "公共计算笔记本是否绝大多数是病理性不可执行的？", "title_en": "Are the Majority of Public Computational Notebooks Pathologically Non-Executable?", "authors": "Tien Nguyen,Waris Gill,Muhammad Ali Gulzar", "background": "计算笔记本是进行探索性数据科学的实际平台，提供一种交互式编程环境，用户可以在其中创建、修改和顺序执行代码单元格。然而，这种灵活性往往会导致代码质量问题，前人研究显示，约76%的公共笔记本非执行，这对代码的可重用性提出了重大质疑。传统意义上的可执行性概念要求笔记本在没有任何错误的情况下完全运行，这种观点过于僵化，导致了大量笔记本的错误分类，低估了它们的可执行性。本文探讨了在不同可执行性定义和程度下公共笔记本的病理性执行问题。即使是部分提高可执行性也会提升代码理解，并为动态分析提供途径。", "innovation": "本文首次将笔记本分为可能恢复和病理性不可执行两类，并且通过去除误配置和表面执行问题来提高可执行性。研究发现，仅21.3%的笔记本真正是病理性不可执行，5.4%的之前不可执行的笔记本通过LLM方法完全恢复，安装正确的模块和生成合成数据可以使部分恢复的笔记本可执行性分别提升42.7%和28%。这挑战了以往假设，表明笔记本的可执行性高于以往报告，许多笔记本提供有价值的部分执行，并且应根据交互式笔记本范式而不是传统软件执行标准来评估其可执行性。", "conclusion": "通过去除公共笔记本中的误配置和表面执行问题，其部分提高了可执行性，这挑战了以往对笔记本可执行性的假设。许多笔记本提供了有价值的部分执行，并且评估执行力应以此类交互式笔记本模型为准。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.20008", "html_url": "https://arxiv.org/abs/2506.20008", "title": "QHackBench: 使用PennyLane黑客马拉松挑战进行大型语言模型的量子代码生成基准测试", "title_en": "QHackBench: Benchmarking Large Language Models for Quantum Code Generation Using PennyLane Hackathon Challenges", "authors": "Abdul Basit,Minghao Shao,Muhammad Haider Asif,Nouhaila Innan,Muhammad Kashif,Alberto Marchisio,Muhammad Shafique", "background": "近年来，大型语言模型（LLMs）在代码生成方面显示出强大的潜力，尤其是在量化计算领域，其应用仍然未被充分探索。", "innovation": "该论文引入了QHackBench，这是一个新型基准数据集，基于Quantum Hackathon（QHack）的现实挑战。论文采用传统的提示方式和检索增强生成（RAG）方法来评估模型性能，并引入了一个多层次评估管道，以逐步改进错误解，提高执行成功率。", "conclusion": "研究结果表明，增强的RAG方法与扩展的PennyLane数据集相结合，可以产生与标准提示法相似的结果，特别是在复杂的量子算法方面。为了促进进一步研究，论文承诺公开QHackBench、评估框架和实验结果，以促进AI辅助量子编程的进一步发展。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.18721", "html_url": "https://arxiv.org/abs/2508.18721", "title": "LLM作为执行估计器：恢复缺失的依赖项以实现实用的时间旅行调试", "title_en": "LLM as an Execution Estimator: Recovering Missing Dependency for Practical Time-travelling Debugging", "authors": "Yunrui Pei,Hongshu Wang,Wenjie Zhang,Yun Lin,Weiyu Kong,Jin song Dong", "background": "现有的数据依赖性计算方法通常需要全面的执行记录，这可能导致效率低下。本文探讨了通过部分执行记录和相关代码上下文使用语言模型（LLM）推断程序动态的可能性，以减少这种依赖计算的成本和复杂性。研究者提出了一种名为RecovSlicing的新方法，可以在单次运行中通过部分录制的执行和查询变量，计算动态数据依赖性。该方法特别关注处理隐式查询变量的恢复，并解决如何精确恢复运行时变量值及其结构和如何对齐恢复变量的内存地址与录制变量的问题。", "innovation": "该研究创新性地提出了一种名为RecovSlicing的方法，仅通过部分执行记录和查询条件，能够在单次运行中计算程序的动态数据依赖关系。通过利用非确定性的LLM，该方法能够解决恢复变量值和结构以及对齐内存地址等技术挑战。实验结果表明，RecovSlicing在多个基准上的准确性和召回率显著优于现有方法。此外，该方法还与基于双切片的回归错误定位器结合使用，显著提高了定位回归错误的能力。", "conclusion": "本文提出的方法RecovSlicing可以在单次运行中通过部分执行记录计算动态数据依赖关系，相比现有方法具有更高的准确性和召回率。通过与现有方法的对比，RecovSlicing在三个基准测试中的表现显著优于现有方法，特别是在准确性和召回率方面。此外，通过与回归错误定位器的结合使用，RecovSlicing能够进一步提高回归错误定位的性能。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2507.08730", "html_url": "https://arxiv.org/abs/2507.08730", "title": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "title_en": "Dually Hierarchical Drift Adaptation for Online Configuration Performance Learning", "authors": "Zezhen Xiang,Jingzhi Gong,Tao Chen", "background": "现代可配置软件系统需要学习关联配置和性能的模型。但在动态环境中，工作负载变化、硬件调整和系统更新不可避免地会在不同层面上引入概念漂移，即全局漂移和局部漂移。现有的离线和迁移学习方法在这种隐式且不可预测的变化下难以实时适应，导致配置性能学习变得具有挑战性。", "innovation": "本文提出了一种名为DHDA的在线配置性能学习框架，以捕捉和适应不同层面的概念漂移。关键思想是使用双重层级适应机制：在较高层级，将数据重新划分成不同的部分，并在必要时重新训练局部模型以处理全局漂移；在较低层级，不同部分的局部模型可检测局部漂移并异步自我适应。为了在响应性和效率之间取得平衡，DHDA结合了增量更新和周期性完全重新训练，以在未检测到漂移时减少冗余计算。该方法通过对八款软件系统和与最新的最佳方法进行评估，展示了其显著的准确性提升和对漂移的有效适应，在合理开销下能提升不同局部模型的处理能力，最高可达两倍的提升。", "conclusion": "通过评估八款软件系统并与其他最先进的方法进行对比，DHDA方法在准确性和对漂移的适应能力上表现出显著的优势，实现了由最初的显着提升，同时在产生的开销方面仍然保持在合理范围内，能够有效提升不同局部模型处理概念漂移的能力。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2508.20977", "html_url": "https://arxiv.org/abs/2508.20977", "title": "ConfLogger：通过配置日志增强系统配置可诊断性", "title_en": "ConfLogger: Enhance Systems' Configuration Diagnosability through Configuration Logging", "authors": "Shiwen Shan,Yintong Huo,Yuxin Su,Zhining Wang,Dan Li,Zibin Zheng", "background": "现代可配置系统提供高度定制化特性，但这种灵活性带来了配置相关问题，如配置错误和潜在软件缺陷。现有诊断支持侧重于故障后的软件行为分析以识别配置问题，但这些方法未能关注软件是否提供了足够的故障信息用于诊断。", "innovation": "本文提出配置日志记录的概念，通过在源代码级别整合配置感知静态污点分析和基于LLM的日志生成，统一增强软件配置诊断性。具体来说，该方法通过追踪整个项目中的配置相关数据流来识别敏感代码段，并通过分析配置代码上下文生成诊断日志语句。", "conclusion": "在八个流行软件系统上的评估结果表明，ConfLogger能够有效增强配置诊断性。具体来说，增强的日志记录帮助基于日志的配置诊断工具在30个无声配置错误场景中实现100%的错误定位精度，其中80%的错误可以通过显式配置信息直接解决。此外，ConfLogger在现有日志点上的覆盖率达到了74%，比基线LLM日志记录器分别高出12%和30%。同时，在变量记录方面，ConfLogger在精确度、召回率和F1得分上分别提高了8.6%、79.3%和26.2%，并提高了故障排除价值。一项受控用户研究进一步验证了其实用性，诊断时间缩短了1.25倍，故障排除准确性提高了251.4%。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2503.13580", "html_url": "https://arxiv.org/abs/2503.13580", "title": "基于迭代混合程序分析的LLM测试生成", "title_en": "LLM Test Generation via Iterative Hybrid Program Analysis", "authors": "Sijia Gu,Noor Nashid,Ali Mesbah", "background": "自动化单元测试生成仍然是一个重大挑战，尤其是在处理真实项目中复杂的代码方法时。尽管大型语言模型（LLMs）在代码生成方面取得了进展，但在达到高分支覆盖率方面依然存在问题，主要原因在于它们难以处理复杂的控制流结构。", "innovation": "该技术Panta模拟了开发人员分析代码和构建测试用例的迭代过程。Panta结合使用静态控制流分析和动态代码覆盖率分析，系统性地指导LLMs识别未覆盖的执行路径，并生成更好的测试用例。Panta通过迭代的反馈驱动机制，基于静态和动态路径覆盖率的见解不断优化测试生成。", "conclusion": "在开源项目中的高环路复杂性类别的实验评估表明，Panta在行覆盖率方面提高了26%，在分支覆盖率方面提高了23%，超越了最先进的方法。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.06580", "html_url": "https://arxiv.org/abs/2506.06580", "title": "数字孪生支持的AI模拟：系统性综述、参考框架及其映射到标准化架构", "title_en": "AI Simulation by Digital Twins: Systematic Survey, Reference Framework, and Mapping to a Standardized Architecture", "authors": "Xiaoran Liu,Istvan David", "background": "现代符号AI在应用中面临数据量不足和质量不高的问题，为了解决这些问题，AI模拟使用了虚拟训练环境，在这些环境中AI代理可以安全、高效地使用模拟和合成数据进行开发。数字孪生为AI模拟打开了新的途径，因为这种高保真度的物理系统虚拟复制体配备了最先进的仿真实验室，并且能够进一步与物理系统互动以收集额外的数据。本文通过对22项主要研究的系统性综述，分析了数字孪生在AI模拟中的技术和趋势，并提出了一个参考框架，以定位数字孪生和AI组件。我们基于研究结果，映射到了ISO 23247的数字孪生标准化架构，提出了加强信息架构的指导原则，同时指出了未来研究的机会和挑战。", "innovation": "本文创造性地将数字孪生技术与AI模拟相结合，提出了一种新的参考框架，并映射到ISO 23247标准架构，为数字孪生和AI组件提供了定位和架构指导。", "conclusion": "虽然数字孪生在AI模拟中展现出了巨大潜力，但在实际应用中仍面临许多挑战，包括数据同步、实时性和安全性等。未来研究有潜力推动这方面的技术发展，为AI应用提供更强大的支持。"}
{"llm_update_time": "20250901", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2504.18956", "html_url": "https://arxiv.org/abs/2504.18956", "title": "朝向内联代码注释自动检测的方法", "title_en": "Towards Automated Detection of Inline Code Comment Smells", "authors": "Ipek Oztas,U Boran Torun,Eray Tüzün", "background": "代码注释在软件开发中非常重要，直接影响软件维护能力和整体质量。不好的代码注释实践会导致代码注释味道，这对软件维护产生负面影响。虽然已经有一些研究用于分类内联代码注释味道，但自动检测这些味道仍然存在挑战。因此，本研究旨在通过机器学习（ML）模型和大型语言模型（LLM）自动检测和分类内联代码注释味道，以评估不同模型的性能。", "innovation": "本研究增强了已有的标注数据集，通过添加额外的代码段和相关的注释来提高数据集的质量。使用了多种机器学习算法和大型语言模型来提高内联代码注释味道的检测准确度，特别是随机森林模型取得了69%的整体准确率，优于其他算法。同时，增加的数据集提升了GPT-4模型的预测精度。本研究提供了增强后的数据集和代码资源，为开发自动代码注释味道检测工具提供了重要支持。", "conclusion": "本研究通过探索自动检测和分类内联代码注释味道的方法，提高了软件可维护性的自动检测水平，特别是通过增强后的数据集和随机森林模型，显著提升了检测性能，并为未来的研究奠定了基础。LGM在内联代码注释味道检测上的应用也显示了其广阔的应用前景。"}
