{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25813", "html_url": "https://arxiv.org/abs/2510.25813", "title": "一个快速部署工业5.0边缘AI解决方案的代理框架", "title_en": "An Agentic Framework for Rapid Deployment of Edge AI Solutions in Industry 5.0", "authors": "Jorge Martinez-Gil,Mario Pichler,Nefeli Bountouni,Sotiris Koussouris,Marielena Márquez Barreiro,Sergio Gusmeroli", "background": "本文介绍了一种用于工业5.0的新型框架，旨在简化在各种工业环境下的AI模型部署在边缘设备上的过程。设计上减少了延迟并规避了对外部数据传输的依赖，通过支持本地推理和实时处理。", "innovation": "该框架采用基于代理的设计，即无论是人类、算法还是合作的代理都能够负责特定任务，这意味着高度的灵活性和易于集成。此外，该框架支持模块化集成且资源需求较低。初步针对食品行业的现场评估显示，部署时间有所缩短，系统适应性也有所提升。", "conclusion": "该框架提供的源代码已公开，实验证明其在实际场景中表现出优越的部署效率和系统适应性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25951", "html_url": "https://arxiv.org/abs/2510.25951", "title": "使用注意意识逆向规划估计认知偏差", "title_en": "Estimating cognitive biases with attention-aware inverse planning", "authors": "Sounak Banerjee,Daphne Cornelisse,Deepak Gopinath,Emily Sumner,Jonathan DeCastro,Guy Rosman,Eugene Vinitsky,Mark K. Ho", "background": "人的目标导向行为受到认知偏好的影响，与人的交互的自主系统需要意识到这点。例如，在驾驶到工作地点的任务中，人们对环境中的物体会有系统性的影响注意力的偏见。本文基于计算认知科学的最新研究，正式定义了注意意识逆向规划问题，旨在从人的行为中估计其注意力偏好。", "innovation": "本文通过将深度强化学习与计算认知建模相结合，提出了一种注意意识逆向规划方法，并利用这种方法在真实的驾驶场景中（来自Waymo开放数据集）来推断强化学习代理的注意力策略。这展示了使用注意意识逆向规划估计认知偏好的可扩展性。", "conclusion": "本文通过理论上区分注意意识逆向规划与标准逆强化学习，并通过实验证明了利用注意意识逆向规划可以系统地从行为中推断认知偏好，扩大了解这类问题的可能性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25884", "html_url": "https://arxiv.org/abs/2510.25884", "title": "使用多裁判学习系统逼近人类偏好", "title_en": "Approximating Human Preferences Using a Multi-Judge Learned System", "authors": "Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer", "background": "基于语言模型（LLM）的裁判与人类偏好对齐是一项显著挑战，难以调整且经常表现为评分敏感性、偏见和不稳定。克服这一挑战能显著推动关键应用的发展，比如创建可靠的强化学习来自人类反馈的奖励模型（RLHF）和构建有效的路由系统以选择最适合用户查询的模型。", "innovation": "本文提出了一种框架，通过学习聚合多评分条件裁判的输出来建模多样性的、基于人设的偏好。该框架与直接采用裁判评分的基线方法相比，并通过针对人类和LLM裁判偏见的案例研究评估其鲁棒性。主要贡献包括一种基于人设的方法以大规模合成偏好标签，以及我们的聚合器的两种实现：广义加性模型（GAM）和多层感知机（MLP）。", "conclusion": "研究表明，该方法相较于简单方法更具有优势，并且其对人类和LLM裁判的偏见具有良好的鲁棒性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25883", "html_url": "https://arxiv.org/abs/2510.25883", "title": "信息论的普适性原则：压缩与知识论智能的基础", "title_en": "The Information-Theoretic Imperative: Compression and the Epistemic Foundations of Intelligence", "authors": "Christian Dittrich,Jennifer Flygare Kinne", "background": "现有的框架都承认压缩在智能中的核心地位，但没有详细解释为何压缩过程能揭示因果结构，而非表面的统计模式。本文提出了一个两级框架来解决这一问题。", "innovation": "引入了信息论的普适性原则（ITI）和压缩效率原则（CEP），这两个原则联合定义了一个因果链，从生存压力到预测需求，再到压缩要求、效率优化、生成结构的发现，最终实现现实对齐。这种框架为具体测试提供了可能，旨在通过压缩效率衡量实际智能的表现，并明确生物系统、人工系统和多层次系统智能的统一观点，而不假设意识或主观体验的存在。", "conclusion": "ITI和CEP提供了跨越生物、人工和多层次系统智能统一的解释，同时解决了智能的认知和功能维度，而无需假设意识或主观体验的存在。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25860", "html_url": "https://arxiv.org/abs/2510.25860", "title": "法官之眼：推断出的思考痕迹提升大规模语言模型评阅者的可靠性", "title_en": "Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters", "authors": "Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei", "background": "大型语言模型（LLMs）在评估任务中越来越频繁地作为评分器使用。然而，对于主观任务，它们的可靠性往往有限，尤其是在涉及人类判断的微妙推理时。人类判断背后的思考痕迹极具信息价值，但收集和整理这些痕迹具有挑战性。本文提出了一种基于人类与LLM协作的框架，该框架能够从仅包含标签的注释中推断出思考痕迹，以重建这些痕迹。这种方法使用简单的拒绝采样方法在大规模上进行重建。", "innovation": "本文提出的框架是通过拒绝采样方法重建仅基于标签的注释的思考痕迹，并将其应用于两个任务：一是微调开放型LLM评分器；二是为专有LLM评分器合成更清晰的注释指南。这种方法显著提高了LLM与人类评阅者的共识，也提高了不同LLM模型之间的共识。这表明，LLMs可以作为实用的替代品，反映人类未揭示的思考痕迹，使得仅包含标签的数据集可以扩展为带有思考痕迹增强资源的数据集，从而提高LLM评分器的可靠性。", "conclusion": "通过这种方法，LLM能够被用作评估任务中未揭示的人类思考痕迹的实用替代品，使得仅包含标签的数据集能够扩展为带有思考痕迹增强的资源，从而提升LLM评分器的可靠性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25820", "html_url": "https://arxiv.org/abs/2510.25820", "title": "符号引导下的游戏：设计角色敏感的生成NPC对话提示", "title_en": "Symbolically Scaffolded Play: Designing Role-Sensitive Prompts for Generative NPC Dialogue", "authors": "Vanessa Figueiredo,David Elumeze", "background": "大型语言模型（LLMs）有望通过使非玩家角色（NPC）能够维持非剧本对话来改变交互式游戏。然而，仍然不清楚是否受限提示实际上能够改善玩家体验。本文通过一款由GPT-4o驱动的基于语音的侦探游戏《访谈》，进行了一个单被试用户可用性研究，比较了高约束（HCP）和低约束（LCP）提示，结果显示在技术问题之外，没有发现明确的用户体验差异。", "innovation": "根据这些发现，作者重新设计了HCP为混合JSON+RAG支架，并进行了合成评估。结果发现支架效果取决于角色：访谈者（任务提供NPC）增强了稳定性，而嫌疑犯NPC则失去了即兴的可信度。这些发现推翻了越紧的约束会越提升游戏体验的假设。作者提出了一种名为‘符号引导下游戏’的新框架，其中符号结构以模糊的、数值的边界形式表达，在需要稳定流畅性的地方提供稳定，在保持惊喜带来参与的地方保留即兴性。", "conclusion": "研究结果表明，更紧密的约束不一定会提升游戏体验，而是取决于具体的提示设计。提出的框架提供了一种策略，使NPC对话设计既稳定又充满惊喜，从而提升玩家体验。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25775", "html_url": "https://arxiv.org/abs/2510.25775", "title": "使用SHAP实现棋局逐子解释", "title_en": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP", "authors": "Francesco Spinnato", "background": "当前的棋盘引擎提供精确但不透明的评估，通常用小马达得分表示。虽然这些评估对决策有效，但它们掩盖了单个棋子或模式的具体贡献。本文探讨了将SHAP（Shapley加性解释）应用于棋盘分析的领域，目的是将引擎的评估归因于棋盘上的具体棋子。通过将棋子视为特征，系统地移除它们，我们计算出逐个棋子的加性贡献，以一种局部忠实且易于人类理解的方式解释引擎的输出。这种方法受到经典棋盘教学的启发，在这种教学中，棋手通过在脑海中移除棋子评估局面，并结合现代可解释AI技术。这种做法为可视化、人类训练及引擎比较打开了新的可能性。为了促进未来在可解释棋盘AI方面的研究，我们提供了附带的代码和数据。", "innovation": "本文提出了一种通过SHAP方法逐个解释棋子对棋势影响的新方法。具体讲，通过视棋子为特征，系统地移除每个棋子，计算其对整体评估的贡献，提供了一种局部忠实且易于理解的方式展示引擎输出的解释。这种方法结合了经典棋盘教学和现代可解释AI技术，为棋盘引擎的决策过程提供了前所未有的透明度。", "conclusion": "本文的方法为可视化、人工训练及引擎比较开拓了新的可能性。为了促进未来研究，本文发布了相关的代码和数据。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25914", "html_url": "https://arxiv.org/abs/2510.25914", "title": "FinOps代理——IT基础架构和成本优化的应用场景", "title_en": "FinOps Agent -- A Use-Case for IT Infrastructure and Cost Optimization", "authors": "Ngoc Phuoc An Vo,Manish Kesarwani,Ruchi Mahindru,Chandrasekhar Narayanaswami", "background": "FinOps是一种运营框架和企业文化实践，通过跨工程、财务和业务团队的协作财务问责，最大化云业务价值。FinOps从业者面临一个基本挑战：来自多个云供应商和内部系统的账单数据以不同的格式、分类法和指标出现，最终导致难以获得行动性的洞察并作出及时的决策。为此，本文提出利用自主、目标驱动的人工智能代理来自动化FinOps过程。研究人员构建了一个典型的IT基础设施和成本优化场景下的FinOps代理系统。该系统模拟了一个完整的行业流程，从数据采集开始，经过数据汇聚和分析，最终生成优化建议。然后定义了一组指标来评价该代理，结果显示该代理能够理解和执行任务，与实际的FinOps从业者表现相当。", "innovation": "本文创新之处在于提出利用自主、目标驱动的人工智能代理进行FinOps自动化，这为处理复杂多源的账单数据以生成行动性洞察和及时决策提供了新的方法。通过构建模拟真实行业流程的FinOps代理，证明了该代理在理解、规划和执行任务方面的能力，与实际的FinOps从业者相当。这为FinOps领域的自动化提供了重要工具和方法论指导。", "conclusion": "本文构建了一个FinOps代理，通过模拟真实行业的多个环节，证明了代理在理解和执行任务方面的有效性，能够协助解决FinOps中复杂多源数据处理的挑战。该研究为FinOps的自动化提供了可行方案，并展示了结合人工智能技术在该领域的潜力。未来的工作可以进一步优化代理的性能，扩展至更多的应用场景。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25908", "html_url": "https://arxiv.org/abs/2510.25908", "title": "SciTrust 2.0: 用于科学应用中评估大型语言模型可信度的全面框架", "title_en": "SciTrust 2.0: A Comprehensive Framework for Evaluating Trustworthiness of Large Language Models in Scientific Applications", "authors": "Emily Herron,Junqi Yin,Feiyi Wang", "background": "大型语言模型（LLMs）在科学研究中展现了巨大的潜力，但在高风险的应用场景中部署这些模型会引发显著的可信度问题。为了应对这些问题，科研人员需要一套全面的评估框架来衡量LLMs在科学应用中的可信度，尤其是在真理可靠性、对抗性稳健性、科学研究安全性以及科学伦理这四个维度上。本文背景即是在此背景下提出SciTrust 2.0框架，以评估LLMs在科学研究中的可信度问题。", "innovation": "SciTrust 2.0框架创新之处在于它不仅包含了通过验证回溯调优管道和专家验证开发的新型、开放性真理基准测试，还包括一个专为科学研究情景设计的新型伦理基准，涵盖了八个小类别，包括双用途研究和偏见。此外，该框架使用了多种评估标准，包括准确性、语义相似度度量以及基于LLMs的评分，试验了七个主要的LLMs模型，并发现通用行业模型在所有可信度维度上均优于专门化的科学模型，特别是在真理正确性和对抗性稳健性方面有特别出色的性能。同时，专门化的科学模型在逻辑和伦理推理能力方面存在明显缺陷，并且在涉及生物安全和化学武器等高风险领域的安全性评估中也显示出令人担忧的脆弱性。SciTrust 2.0框架的开源为开发更可信的人工智能系统提供了基础，并促进了科学研究中模型安全性和伦理学的研究进程。", "conclusion": "通过开放和共享SciTrust 2.0框架，研究团队旨在促进研究领域内更深入的科学研究，并为开发更可信的AI系统提供一个坚实的基础。该研究进一步强调了在科学应用中评估大型语言模型可信度的必要性，同时也指出了科学模型在伦理和逻辑推理能力方面存在的局限性及风险。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25933", "html_url": "https://arxiv.org/abs/2510.25933", "title": "Humans-Junior: 通过定向外骨骼推理实现GPT-4o级别事实准确性的3.8B语言模型", "title_en": "Humains-Junior: A 3.8B Language Model Achieving GPT-4o-Level Factual Accuracy by Directed Exoskeleton Reasoning", "authors": "Nissan Yaron,Dan Bystritsky,Ben-Etzion Yaron", "background": "本研究基于GPT-4o已有的事实推理能力，旨在开发一个成本更低但能达到类似准确性的小型语言模型。背景在于现有大型模型如GPT-4o尽管具有强大的语言处理能力，但其成本较高，限制了其在某些应用场景中的使用。因此，研究团队致力于开发一个成本更低且能在特定任务上达到与GPT-4o类似准确性的模型，以提高AI在实际应用中的性价比和普及率。", "innovation": "研究团队通过结合最小化有向“外骨骼推理”的框架和行为微调技术（侧重教授遵守协议和理论规范而非具体领域答案），开发了名为Humans-Junior的新模型。这种方法在特定任务上取得了显著效果，尤其是在成本方面表现出了很大的优势。该模型在FACTS Grounding公共子集上的结果与GPT-4o在±5个点等价区间内的结果相匹配，且回归分析表明两者在成本效率上具有相当的竞争力，而小型模型的成本是大型模型的19倍左右，自托管或边缘部署的额外推理成本可以趋近于零。", "conclusion": "研究表明，Humans-Junior模型在特定任务上能够达到与GPT-4o类似甚至更高的准确度，同时具备显著的成本优势。在云定价方面，Humans-Junior的成本仅为GPT-4o的1/19，而在自托管或边缘部署下，其额外推理成本可以趋近于零。除此之外，该研究还通过实验证明，通过定向推理指导模型团队能够在某些前沿任务上取得更好的表现。未来的探讨可能包括最优资源分配的问题和进一步模型优化的方法。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26057", "html_url": "https://arxiv.org/abs/2510.26057", "title": "AI可以负责吗？", "title_en": "Can AI be Accountable?", "authors": "Andrew L. Kun", "background": "人工智能技术非常先进，并且其能力在迅速增强。如果这些强大的AI能够服务于消费者、选民和决策者的需求，那么AI必须是有责任的。一般而言，一个实体对某个论坛来说是负责任的，如果该论坛能够从实体处请求行动信息，可以讨论这些信息，并对实体进行制裁。然而，在当前情况下，许多AI并不负责任——我们无法质疑它们，无法与其进行讨论，更不用说制裁它们。", "innovation": "本文将一般问责定义应用于AI，解释AI是有责任和无责任的含义，并探讨改善所有受AI影响的人能够使AI负责任的方式。", "conclusion": "探索如何建立一个所有AI都能对受影响的人负责的世界的方法。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26012", "html_url": "https://arxiv.org/abs/2510.26012", "title": "AutoSurvey2：赋能研究者新型自动化文献综述", "title_en": "AutoSurvey2: Empowering Researchers with Next Level Automated Literature Surveys", "authors": "Siyi Wu,Chiaxin Liang,Ziqian Bi,Leyi Zhao,Tianyang Wang,Junhao Song,Yichao Zhang,Keyu Chen,Xinyuan Song", "background": "随着研究文献的急剧增长，尤其是在大型语言模型（LLMs）领域，撰写全面且及时的综述论文变得更加困难。现有的方法难以应对文献量激增带来的挑战，因此需要一种能够高效生成综述的自动化工具。", "innovation": "本文介绍了autosurvey2，这是一个多阶段管道，通过检索增强合成和结构化评估来自动化综述生成。该系统结合了并行节生成、迭代改进以及实时检索最新出版物，确保综述在主题完整性与事实准确性之间达到平衡。质量评估使用多LLM评估框架来衡量覆盖、结构和相关性，符合专家审查标准。实验结果表明，autosurvey2在结构连贯性和主题相关性方面优于现有的基于检索和自动化的基线，同时保持了强大的引用真实性。通过将检索、推理和自动化评估集成到统一框架中，autosurvey2提供了一种可扩展且可重复的工具，用于生成长篇学术综述，为自动化学术写作的未来研究奠定了基础。", "conclusion": "通过将检索、推理和自动化评估结合，autosurvey2提供了一种可扩展且可重复的长篇学术综述自动化工具，并为未来自动化学术写作研究奠定了坚实基础。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25997", "html_url": "https://arxiv.org/abs/2510.25997", "title": "从查询到见解：基于反应式的LLM管道用于时空文言语义生成", "title_en": "From Queries to Insights: Agentic LLM Pipelines for Spatio-Temporal Text-to-SQL", "authors": "Manu Redd,Tao Zhe,Dongjie Wang", "background": "自然语言到SQL（NL-to-SQL）系统有望使访问结构化数据更加民主化，允许用户无需学习SQL即可查询数据库。然而，现有的系统对于涉及时空的现实查询存在困难，这些查询要求将含糊的用户表达方式与特定的模式类别对齐，处理时间推理，并选择适当的输出。现有的系统在这些任务上的表现不尽如人意。因此，需要一种新的方法来解决这些问题，以提高系统的准确性和用户体验。", "innovation": "该论文提出了一种新的基于代理的管道，通过使用Mistral基于的ReAct代理扩展了一个简化的文本到SQL基层（llama-3-sqlcoder-8b）。该代理能够通过模式检查、SQL生成、执行和可视化工具计划、分解和适应查询。该系统通过地图、图表和结构化的自然语言摘要增强了用户体验，并实现了比简化的基础系统更高的准确率：91.4% vs. 28.6%。更重要的是，这种设计使得更具自然的用户与数据库交互成为可能，从而支持缺乏SQL知识、详细模式了解或提示技能的用户。", "conclusion": "我们得出结论，代理协调比仅依赖更强的SQL生成器更为有前景，是未来交互式地理空间助手的基础。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26023", "html_url": "https://arxiv.org/abs/2510.26023", "title": "Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization", "title_en": "Large Language Model-assisted Autonomous Vehicle Recovery from Immobilization", "authors": "Zhipeng Bao,Qianwen Li", "background": "尽管近年来在自主驾驶车辆(AVs)方面取得了显著进展，但在某些需要人类驾驶员熟练处理的交通场景中，AVs仍然面临导航挑战。在这种情况下，AVs可能陷入无法动弹的状态，破坏了整体交通流动。当前的恢复解决方案，如远程干预（成本高且效率低）和手动接管（排除非驾驶员且限制AV的使用性），都显得不理想。因此，迫切需要更有效的自主恢复方法来应对此类状况。", "innovation": "本文介绍了一种名为StuckSolver的新颖的大语言模型（LLM）驱动的恢复框架。StuckSolver可以通过自我推理或乘客辅助决策帮助AVs解决陷入困境的状况。该框架作为一个插件扩展模块，建立在AV现有的感知-规划-控制栈之上，无需修改其内部结构。它通过接口与标准传感器数据流来检测停摆状态、解释环境上下文并生成高级恢复命令，这些命令可以由AV的原生规划器执行。研究人员在Bench2Drive基准测试和自定义设计的不确定性场景中对StuckSolver进行了评估。结果显示，StuckSolver仅通过自主自我推理就能达到接近最先进的性能，并且当结合乘客指导时进一步改善了性能。", "conclusion": "研究表明，StuckSolver通过自主自我推理方式能够实现接近最先进的性能，并且通过纳入乘客指导可以进一步提高性能。这一框架为解决AVs停摆问题提供了一种创新的方法，可能显著改善AVs在复杂交通环境中的表现和可靠性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26094", "html_url": "https://arxiv.org/abs/2510.26094", "title": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "title_en": "Lean4Physics: Comprehensive Reasoning Framework for College-level Physics in Lean4", "authors": "Yuxin Li,Minghao Liu,Ruida Wang,Wenzhao Ji,Zhitao He,Rui Pan,Junming Huang,Tong Zhang,Yi R. Fung", "background": "该研究致力于为大学物理问题提供一个全面的推理框架，使用Lean4语言。之前的基准和资源相对不足，尤其是在形式化物理推理方面。该论文介绍了一个名为Lean4PHYS的框架，其中包括一个名为LeanPhysBench的基准表示，以及一个名为PhysLib的社区驱动资源库。", "innovation": "1. 提出Lean4PHYS，一个针对大学物理问题的综合推理解释框架，包含LeanPhysBench和PhysLib。2. LeanPhysBench是一个包含200个手工定制和同行评审的物理陈述的基准，源自大学教科书和物理竞赛题目。3. PhysLib是包含物理推理基础单位系统和定理的社区驱动仓库，旨在为物理形式化推理奠定坚实基础。4. 使用Lean4库和多个领域的专家证明器及最先进的封闭源代码模型，报告显示最佳性能仅达到16%，证明基准的挑战性和资源库的有效性。", "conclusion": "该研究提供了一个首个在Lean4中的物理基准，该基准展示了Lean4在物理推理任务上的能力和局限性，还展示了PhysLib在提高模型性能方面的平均11.75%改善。这种框架和技术对于促进物理学形式化推理的发展具有重要意义。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26143", "html_url": "https://arxiv.org/abs/2510.26143", "title": "Reasoning Curriculum: 从数学问题提升大规模语言模型的广泛推理能力", "title_en": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math", "authors": "Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou", "background": "强化学习（RL）能够激发大型语言模型（LLMs）的强大推理能力，但大多数开源努力主要集中在数学和编程领域。本文提出了一种简化的两阶段课程设计，旨在通过结合RL从预训练一致的领域（如数学）中激发推理技能，并通过混合领域的联合RL来迁移和巩固这些技能。", "innovation": "该研究引入了一种名为‘推理课程’的简单两阶段框架。第一阶段采用短暂的冷启动和仅数学的RL训练，利用可验证的奖励来开发推理技能。第二阶段在混合领域数据上执行联合RL，进一步巩固并迁移这些技能。此课程设计简单且模型无关，无需特殊奖励模型，仅需常规可验证性检查。实验结果显示，无论是在Qwen3-4B还是Llama-3.1-8B模型上，‘推理课程’均能带来一致的改进。", "conclusion": "通过认知技能分析，证明了两阶段课程都是必要的，第一阶段数学训练尤其是在解决复杂问题时，增加了关键的认知行为。‘推理课程’为通用推理提供了一种紧凑且易于实施的方案。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26098", "html_url": "https://arxiv.org/abs/2510.26098", "title": "GUI Knowledge Bench: 揭示VLM在GUI任务失败背后的知识缺口", "title_en": "GUI Knowledge Bench: Revealing the Knowledge Gap Behind VLM Failures in GUI Tasks", "authors": "Chenrui Shi,Zedong Yu,Zhi Gao,Ruining Feng,Enqi Liu,Yuwei Wu,Yunde Jia,Liuyu Xiang,Zhaofeng He,Qing Li", "background": "大型视觉语言模型已经在图形用户界面（GUI）任务自动化方面取得了进展，但仍落后于人类。现有训练方案（如监督微调和强化学习）无法充分解决这一差距。通过分析GUI任务执行中的常见失败模式，我们提取出了GUI知识的三个维度：界面感知、交互预测和指令理解，分别涵盖了对控件和系统状态的识别能力、行动状态转换的推理以及任务完成进度的规划、验证和评估。评估表明，当前VLM能够识别控件功能，但在感知系统状态、预测行动和验证任务完成方面表现出困难。实验证明GUI知识与任务成功密切相关。", "innovation": "我们引入了GUI Knowledge Bench，这是一个基准测试，涵盖六种平台（Web、Android、macOS、Windows、Linux、iOS）和292个应用程序的多项选择和是/非问题。实验结果显示，当前VLM能够识别控件功能，但在感知系统状态、预测行动和验证任务完成方面效果不佳。我们提供了一种结构化的框架，用于评估GUI知识，支持选择更大可能的VLM进行下游训练，并为构建更强大的GUI代理提供了见解。", "conclusion": "通过提供评估GUI知识的结构化框架，我们的工作支持了在下游训练之前选择具有更大潜力的VLM，并为构建更加能够胜任GUI代理提供了洞见。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26136", "html_url": "https://arxiv.org/abs/2510.26136", "title": "超越基准：AI推理的经济学", "title_en": "Beyond Benchmarks: The Economics of AI Inference", "authors": "Boqin Zhuang,Jiacheng Qiao,Mingqian Liu,Mingxing Yu,Ping Hong,Rui Li,Xiaoxia Song,Xiangjun Xu,Xu Chen,Yaoyao Ma,Yujie Gao", "background": "大型语言模型（LLMs）的推理成本已成为其商业可行性和广泛采用的关键因素。本文介绍了一种定量的推理经济框架，将LLM的推理过程视为驱动计算的智能生产活动。研究了不同性能配置下的边际成本、规模经济效益和输出质量。基于WiNEval-3.0的实证数据，构建了第一个LLM推理生产前沿，揭示了三个原则：边际成本递减、规模报酬递减和最具成本效益的最优区域。本文不仅为模型部署决策提供了经济基础，还为未来基于市场的AI推理资源定价和优化奠定了实证基础。", "innovation": "提出了一个定量的推理经济框架，将LLM的推理过程视为计算驱动的智能生产活动，并构建了第一个LLM推理生产前沿，揭示了三个经济原则：边际成本递减、规模报酬递减和最具成本效益的最优区域；提供了模型部署的经济基础，并为未来市场的AI推理资源定价和优化提供了实证基础。", "conclusion": "本文不仅为LLM推理的经济基础提供了理论支撑，还通过实证数据揭示了其生产特性和成本效益的最优区域，为未来的市场定价和优化奠定了基础。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26144", "html_url": "https://arxiv.org/abs/2510.26144", "title": "FM Agent", "title_en": "The FM Agent", "authors": "Annan Li,Chufan Wu,Zengle Ge,Yee Hin Chong,Zhinan Hou,Lizhe Cao,Cheng Ju,Jianmin Wu,Huaiming Li,Haobo Zhang,Shenghao Feng,Mo Zhao,Fengzhi Qiu,Rui Yang,Mengmeng Zhang,Wenyi Zhu,Yingying Sun,Quan Sun,Shunhao Yan,Danyu Liu,Dawei Yin,Dou Shen", "background": "大型语言模型（LLMs）正在推动自主人工智能研究代理在科学研究和工程发现中的发展。这些研究代理能够在复杂的现实世界挑战中发挥作用。FM Agent是一个新颖且通用的多代理框架，结合了基于LLM的推理和大规模进化搜索，旨在解决这些挑战。", "innovation": "FM Agent的核心创新包括：1) 一个利用专家指导的冷启动初始化阶段；2) 一种新颖的进化采样策略，用于迭代优化；3) 集成领域特定评估器，结合正确性、有效性以及LLM监督反馈；4) 基于Ray打造的分布式、异步执行基础设施。这些创新共同使得FM Agent能够自主达到令人瞩目的结果，不需要人工解释或调整，如在ALE-Bench上1976.3的得分（+5.2%），在MLE-Bench上的43.56%得分（+4.0pp），在KernelBench上达到20倍的速度提升，并在几个经典数学问题上建立了新的SOTA结果。", "conclusion": "FM Agent展示了广泛的应用潜力，不仅在学术基准测试中表现出色，还在大企业研发工作流程和基础科学研究中具有重要意义。它能够加速创新，自动化复杂发现过程，并带来具有更广泛社会影响的工程和科学进展。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26238", "html_url": "https://arxiv.org/abs/2510.26238", "title": "问卷遇上LLM：理解问题和答复的结构技能基准及实证研究", "title_en": "Questionnaire meets LLM: A Benchmark and Empirical Study of Structural Skills for Understanding Questions and Responses", "authors": "Duc-Hai Nguyen,Vijayakumar Nanjappan,Barry O'Sullivan,Hoang D. Nguyen", "background": "每天有数百万人参与各种调查，包括市场调查、学术研究、医疗问卷和客户反馈表。这些数据集捕捉了宝贵的见解，但其规模和结构对大语言模型（LLM）构成了特殊挑战，尽管LLM在开放式文本推理方面表现出色。然而，它们处理包含数百个回答行的问卷数据或问题列表的能力尚未得到充分探索。当前的检索和问卷分析工具（例如Qualtrics、SPSS、REDCap）主要为工作流程中的工程师设计，限制了与LLM和AI赋能自动化数据整合的可能性。这导致科学家、问卷工作者和普通用户缺乏基于证据的指导，以最佳方式代表问卷供LLM使用。", "innovation": "引入了QASU（Questionnaire Analysis and Structural Understanding）基准，它涵盖了六种结构技能，包括答案查找、受访者计数和多跳推理，跨越六种序列化格式和多种提示策略。实验证明，选择有效的格式和提示组合可以将准确性提高8.8个百分点。对于特定任务，通过自我增强的提示精心添加轻量级结构提示，平均可进一步提高3-4个百分点。通过系统地分离格式和提示效果，公开源基准为基于LLM的问卷分析研究和实践提供了简单而灵活的基础。", "conclusion": "我们的公开源基准为基于LLM的问卷分析研究和实际应用提供了一个简单而灵活的基础，展示了格式和提示技巧对准确性的影响，为未来的相关研究和应用提供了参考。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26167", "html_url": "https://arxiv.org/abs/2510.26167", "title": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning", "title_en": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning", "authors": "Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang", "background": "奖励模型（RMs）在使大型语言模型（LLMs）符合人类偏好方面发挥着关键作用。但是，在工具学习领域，适用于函数调用任务的具体奖励模型缺乏，限制了向更具能力的自主AI方面的发展。针对这一问题，本研究引入了适用于通用工具使用场景的轻量级生成式奖励模型ToolRM。研究还提出了一种新的管道，利用基于规则的评分和多维度抽样构建成对偏好数据，并构建了一个多样、平衡和具有挑战性的批评任务数据集ToolPref-Pairwise-30K，为强化学习提供了可验证反馈。为评估工具使用奖励模型的效果，研究还引入了基于BFCL自主评估套件的TRBench$_{BFCL}$基准。", "innovation": "本研究主要创新在于：1) 引入适用于函数调用任务的轻量级生成式奖励模型ToolRM；2) 提出了一种新的成对偏好数据构建管道；3) 构建了一个多样、平衡且具有挑战性的批评任务数据集ToolPref-Pairwise-30K；4) 引入了一个新的基准TRBench$_{BFCL}$来评估工具使用奖励模型；5) 模型在实际任务中表现出更好的效果，特别是在成对奖励判断方面显著超过了前沿模型；6) ToolRM具有良好的泛化能力，不仅适用于批评任务，还适用于最佳选择采样和自我纠正任务；7) 实验表明，ToolRM在增强推理能力和降低输出令牌使用方面都表现优异。", "conclusion": "本研究通过引入适用于工具使用任务的新型奖励模型ToolRM，创造性地提供了一种有效的评估方法，并证明了其在多种任务中的泛化能力和有效性。研究还提供了相关数据和模型，为未来的研究提供了便利。未来的工作可以继续探索这些模型在不同类型任务上的应用和优化。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26242", "html_url": "https://arxiv.org/abs/2510.26242", "title": "增强检索生成的分布式大语言模型代理在包含应急车辆的一般化交通信号控制中的应用", "title_en": "Retrieval Augmented Generation-Enhanced Distributed LLM Agents for Generalizable Traffic Signal Control with Emergency Vehicles", "authors": "Xinhang Li,Qing Guo,Junyu Chen,Zheng Guo,Shengzhe Xu,Lei Li,Lin Zhang", "background": "随着城市交通越来越复杂，交通信号控制（TSC）变得至关重要，用于优化交通流量并提高道路安全性。虽然大型语言模型（LLMs）有望成为TSC的一部分，但由于在紧急情况下容易产生幻觉，导致对应急车辆可能造成较大延误的不准确决策。此外，不同类型的交叉口给交通状态编码和交叉口训练带来了巨大挑战，限制了在异构交叉口中的泛化。", "innovation": "本文提出了增强检索生成的分布式LLM代理，并为一般化TSC，特别是包含应急车辆的部分进行了改革。首先，它提供了一种根据紧急情况动态调整推理深度的应急意识推理框架，并结合了一种新颖的基于评论的应急检索增强生成（RERAG），以此从历史案例中提取特定知识和指导，增强代理在应急情况下的决策可靠性和合理性。其次，本文设计了一种通用的交通表示方法，并提出了一系列受奖励引导的强化细化（R3），适配地从不同交叉口中抽样训练经验，并通过环境反馈优先级和精心设计的奖励加权似然损失进行微调，引导REG-TSC在不同交叉口上形成高回报策略。", "conclusion": "在三个包含17至177个不同交叉口的真实道路网络中进行了广泛实验，结果表明，REG-TSC将行程时间减少了42.00%，等待队列长度减少了62.31%，应急车辆等待时间减少了83.16%，在这方面的表现优于其他最先进的方法。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26396", "html_url": "https://arxiv.org/abs/2510.26396", "title": "AI人本主义视角", "title_en": "A Pragmatic View of AI Personhood", "authors": "Joel Z. Leibo,Alexander Sasha Vezhnevets,William A. Cunningham,Stanley M. Bileschi", "background": "随着代理性人工智能(AI) 的兴起，将会引发新的社会形态的爆发，这种形态涉及新的主体性(bi)问题。本文将背景设置为探讨如何通过一种实用的方法来应对这些新的主体性挑战。", "innovation": "作者提出了一种实用性框架，不同于寻找一种形而上学的本质特性，而是将主体性视为一种社会授予的灵活性义务（权利与责任）的集合。这种框架可以‘拆包’权利与责任，以适应不同的情境，无需解决人工智能意识或理性等不可调和的辩论问题。", "conclusion": "作者通过拒绝对主体性寻求单一的本质定义，提出了一种更实用、更灵活的方式来考虑将AI代理融入社会。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26270", "html_url": "https://arxiv.org/abs/2510.26270", "title": "LLM代理训练中的图增强策略优化", "title_en": "Graph-Enhanced Policy Optimization in LLM Agent Training", "authors": "Jiazhen Yuan,Wei Zhao,Zhengbiao Bai", "background": "群体基于强化学习（RL）已经在复杂的推理和数学任务上展示了令人印象深刻的结果。然而，当应用于训练多轮、互动的大规模语言模型（LLM）代理时，这些方法经常遭受结构性盲点的困扰——即无法利用环境的基本连通性。这导致了三个关键挑战：(1) 不高效的、无法引导的探索；(2) 由于忽视了关键状态而带来的精确度差的信用分配；(3) 因静态奖励折扣而导致的短视规划。", "innovation": "我们通过图增强策略优化（GEPO）来解决这些问题。GEPO 动态构建代理经验的状态转移图，并利用图论中心性提供三个互补的学习信号：(1) 结构化的内在奖励，以引导探索向高影响状态；(2) 图增强的优势函数，用于拓扑感知的信用分配；(3) 适应每个状态的战略价值的动力学折扣因子。", "conclusion": "在 ALFWorld、WebShop 和一个专有的 Workbench 基准测试中，GEPO 表现出强大的性能，相对于竞争性基线实现绝对成功率为 +4.1%、+5.3% 和 +10.9% 的提升。这些结果表明，明确建模环境结构是推进 LLM 代理训练的一种稳健和通用策略。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26346", "html_url": "https://arxiv.org/abs/2510.26346", "title": "在UCT搜索树中通过动作裁剪发现状态等价关系", "title_en": "Discovering State Equivalences in UCT Search Trees By Action Pruning", "authors": "Robin Schmöcker,Alexander Dockhorn,Bodo Rosenhahn", "background": "通过改进蒙特卡洛树搜索（MCTS）的样本效率，即通过分组/抽象化状态或状态-动作对，并在组内共享统计信息来提升性能。虽然在如OGA-UCT等算法中，状态-动作对的抽象相对容易找到，但在噪声或动作空间较大的情况下，状态的抽象却极为困难，这主要由于条件限制所致。本文通过理论支持和实验证据证明了这一点，并提出了一种较弱的状态抽象条件IPA-UCT，能够在牺牲少量准确性的前提下找到更多的抽象状态，从而改善MCTS的表现。", "innovation": "本文提出了一种名为理想修剪抽象在UCT中的技术（IPA-UCT），它通过引入一种较弱的状态抽象条件，解决了在于噪声或动作空间较大情况下的状态抽象问题，相较于OGA-UCT及其衍生算法，该技术在多种测试域和迭代预算范围内均表现出更优的性能。另外，该技术使用了一种不同于ASAP的抽象框架，并可以被认为是更广泛框架p-ASAP和ASASAP框架的特例。该方法能够在不同的抽象框架中更好地发现状态等价关系，提升MCTS的整体效能。", "conclusion": "论文实验验证了所提出的IPA-UCT方法在多个测试领域和不同的迭代预算内均优于OGA-UCT及其衍生算法，证明了一种较弱的状态抽象条件可以找到更多的抽象状态，同时在保持良好性能的同时减少约束。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26380", "html_url": "https://arxiv.org/abs/2510.26380", "title": "AI数学家在推进数学发现中的合作伙伴——一种在均质化理论中的案例研究", "title_en": "AI Mathematician as a Partner in Advancing Mathematical Discovery - A Case Study in Homogenization Theory", "authors": "Yuanhang Liu,Beichen Wang,Peng Li,Yang Liu", "background": "尽管人工智能（AI）在数学推理方面已显示出显著的进步，但其在数学研究实践中的集成仍然受到限制。本文探讨了AI数学家（AI Mathematician，AIM）系统如何作为研究伙伴而非仅作为问题求解工具运作的方法。通过聚焦于均质化理论中的一个挑战性问题，研究AIM的自主推理轨迹，并结合目标干预以结构化发现过程。利用逐步分解问题、选择合适的分析方法以及验证中间结果，揭示了人类直觉与机器计算如何互补。这一合作模式提高了结论证明的可靠性和透明性，同时保留了形式严谨性和正确性的人类监管。这一方法产生了完整且可验证的证明，并表明系统的人机合作推理可以推动数学发现的前沿。", "innovation": "研究创新在于提出了AI数学家作为研究伙伴的新模式，通过将AIM用于复杂问题的研究，结合手动干预来结构化发现过程，同时展示了这种方法能够提高证明的可靠性和透明性，保留人类的监管以确保形式的严谨性和正确性。此外，该研究证明了系统的人机合作推理在数学发现中的潜力。", "conclusion": "通过ITERATIVE分解问题、选择适当的分析方法以及验证中级结果，人类直觉和机器计算的互补可以增强发现可靠性和透明性。这种方法不仅产生了完全且可验证的证明，还表明了系统化的人机合作推理在推进数学发现前沿的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26384", "html_url": "https://arxiv.org/abs/2510.26384", "title": "Scales++: 使用认知尺度嵌入进行计算高效的评估子集选择", "title_en": "Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings", "authors": "Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz", "background": "评价大语言模型（LLMs）在全面基准上的成本过高，需要创建小而具代表性的数据子集（即微小基准），以实现高效评估并保持预测一致性。当前的方法主要基于模型中心的范式，在选择基准项目时根据现有模型的综合表现。这种方法受限于庞大的前期成本、无法立即处理新基准（冷启动）的能力以及未来模型将继承前代失败模式的脆弱假设。", "innovation": "本文挑战了现有范式，提出了基于项目中心的基准子集选择方法，主张选择应基于任务项本身的内在特性，而不是基于特定模型的失败模式。通过新颖的Scales++方法实现这一项目中心的高效基准方法，依据基准样本的认知需求进行数据选择。实验表明，Scales++将前期选择成本降低了超过18倍，同时保持了竞争力的预测一致性。使用0.5%的数据子集，在Open LLM Leaderboard上预测全面基准的分数，平均绝对误差为2.9%。证明了这种方法在不显著降级测度准确性的前提下，提高了冷启动性能并提供了更具可解释性的基准评估。", "conclusion": "本文提出了一种基于项目中心的高效基准方法Scales++，该方法依据任务项本身的内在特性进行选择，而非基于特定模型的失败模式。实验结果表明，与当前方法相比，Scales++大幅降低了前期选择成本，保持了预测一致性，并且提供了更好的冷启动性能和更加可解释的基准评估。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26374", "html_url": "https://arxiv.org/abs/2510.26374", "title": "BOTS: 一种用于大语言模型强化微调的贝叶斯在线任务选择统一框架", "title_en": "BOTS: A Unified Framework for Bayesian Online Task Selection in LLM Reinforcement Finetuning", "authors": "Qianli Shen,Daoyuan Chen,Yilun Huang,Zhenqing Ling,Yaliang Li,Bolin Ding,Jingren Zhou", "background": "强化微调（RFT）是使大型语言模型（LLMs）与人类偏好对齐并提高推理能力的关键技术，但其有效性高度依赖于训练期间探索的任务类型。均匀抽样任务效率低下，浪费计算资源在简单或无法解决的任务上，而现有的任务选择方法通常存在高展开成本、低适应性或不完整证据的问题。现有的方法在提升数据效率和性能方面存在局限性。因此，需要一种能够更有效地进行动态任务选择的框架来优化训练过程。", "innovation": "本文提出了一种名为BOTS的统一框架，用于大语言模型强化微调中的贝叶斯在线任务选择。BOTS基于贝叶斯推断，随着模型的进化，适应性地维护任务难度的后验估计。它同时结合了直接评估已选任务的明确证据和通过评估推断未选任务的隐含证据，使用丢弃采样确保探索和利用之间的平衡。为了使隐含证据更具实际操作性，通过一个超轻量级的插件估计未评估任务的难度，无需额外的展开，且几乎不增加额外开销。实验结果显示，BOTS在不同领域和模型规模下，都能提高数据效率和性能，为RFT中的动态任务选择提供了一种实用且可扩展的解决方案。", "conclusion": "本文提出了一种名为BOTS的框架，用于优化大语言模型的强化微调任务选择。通过利用贝叶斯推断和丢弃采样的结合，BOTS能够有效地平衡探索与利用，同时通过一种超轻量级的方法有效利用隐含证据。实验结果表明，BOTS在多种场景下均表现出色，为RFT任务选择提供了一个实用且可扩展的解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26411", "html_url": "https://arxiv.org/abs/2510.26411", "title": "MedSAE: 使用稀疏自编码器剖析MedCLIP表示", "title_en": "MedSAE: Dissecting MedCLIP Representations with Sparse Autoencoders", "authors": "Riccardo Renzulli,Colas Lepoutre,Enrico Cassano,Marco Grangetto", "background": "医疗健康领域的人工智能需要准确且可解释的模型。研究者提出了基于医学生物稀疏自编码器（MedSAEs）的应用，来增加医疗视觉中的机制可解释性。MedCLIP是一种在胸部X光片和报告上训练的视觉-语言模型，该研究将MedSAEs应用于其潜在空间。", "innovation": "研究者提出了一种评价框架，结合了相关性指标、熵分析以及通过MedGEMMA基础模型的自动神经元命名，以量化可解释性。实验结果显示，MedSAE神经元在单义性和解释性方面优于原始MedCLIP特征。这项研究在高性能医疗AI与透明度之间建立了桥梁，提供了迈向临床可靠的表示的可扩展步骤。", "conclusion": "该研究展示了MedSAE在医疗视觉领域的应用，证实了其在性能和解释性上的优势，并指出这种方法为确保医学AI的透明性和临床可靠性提供了新的途径。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26402", "html_url": "https://arxiv.org/abs/2510.26402", "title": "Autograder+: 一种多方面的AI框架，用于编程教育中的丰富教学生态反馈", "title_en": "Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education", "authors": "Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane", "background": "编程教育的快速扩张超越了传统的评估工具，使教师缺乏提供有意义和可扩展反馈的方式。现有的自动化评分工具虽然高效，但作为黑盒系统，只提供通过或失败的结果反馈，缺乏对学生思维过程或学习需求的洞察。", "innovation": "Autograder+ 通过引入两种关键功能提升了自动化评分工具的作用：使用微调的大语言模型生成自动化反馈，以及通过可视化学生代码提交来揭示学习模式。该系统通过教师评论进行了微调，确保提供符合教学目标且具有上下文相关性的指导。此外，通过对比学习1000个标注的提交所训练的代码嵌入可以将解决方案按功能和方法分组到有意义的集群中，还支持提示池功能，使教师可以通过选择的提示模板引导反馈风格。", "conclusion": "通过集成AI驱动的反馈、语义聚类和互动可视化，Autograder+减轻了教师的工作负担，支持有目标的教学，并促进了更强的学习成果。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26309", "html_url": "https://arxiv.org/abs/2510.26309", "title": "GraphCompliance：利用政策图和上下文图的LLM基于监管合规", "title_en": "GraphCompliance: Aligning Policy and Context Graphs for LLM-Based Regulatory Compliance", "authors": "Jiseong Chung,Ronny Ko,Wonchul Yoo,Makoto Onizuka,Sungmok Kim,Tae-Wan Kim,Won-Yong Shin", "background": "面对大规模网站上的合规挑战，每一个请求都可能需要进行监管评估。监管文本（如通用数据保护条例GDPR）是交叉引用和规范性的，而运行时上下文则以非结构化的自然语言表达。这种设定促使我们需将非结构化的文本中的语义信息与规范性的监管要素对齐。因此，该论文提出了一种新的框架——GraphCompliance，通过将监管文本表示为政策图，将运行时上下文表示为上下文图，并实现了它们之间的对齐。在此表示中，政策图编码了规范性的结构和交叉引用，而上下文图则形式化了事件的主体-动作-客体（SAO）和实体-关系三元组。这种对齐将法官大型语言模型的推理锚定在结构化信息上，有助于减少监管解释和事件解析的负担，使监管重点放在核心推理步骤上。实验表明，GraphCompliance 在300 个GDPR 来源的真实场景中，在涵盖五个评估任务的表现上，比仅用的LLM 和RAG 基准高出4.1-7.2 个百分点（pp），出现的误判和漏判更少，拿到更高的召回率和更低的假阳性率。消融研究进一步表明图的每个组件对最终效果有贡献，显示出结构化表示和法官LLM 对规范推理的互补作用。", "innovation": "该论文提出了一种用于LLM 基础的监管合规性框架——GraphCompliance，其主要创新点包括：1）将监管文本表示为政策图，将运行时上下文表示为上下文图，并实现了图之间的对齐；2）这种对齐将法官LLM 的推理锚定在结构化信息上，有助于减少监管解释和事件解析的负担，使合规重点放在核心推理步骤上；3）实验结果显示，GraphCompliance 达到了比仅用的LLM 和RAG 基准更高的性能标准，同时降低误判和漏判，提高召回率和降低假阳性率；4）消融研究进一步验证了每个图组件对整体效果的贡献，显示出结构化表示和法官LLM 对规范推理的互补作用。", "conclusion": "GraphCompliance 在大规模网站上的监管合规应用中表现出色，通过将监管文本表示为政策图，将运行时上下文表示为上下文图，并实现了图之间的对齐，为监管推理提供了结构化信息的支持。实验验证了GraphCompliance 的有效性和优越性，尤其是在处理误判和漏判方面表现突出，有望在未来应用于更多监管场景中。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26418", "html_url": "https://arxiv.org/abs/2510.26418", "title": "Chain-of-Thought Hijacking", "title_en": "Chain-of-Thought Hijacking", "authors": "Jianli Zhao,Tingchen Fu,Rylan Schaeffer,Mrinank Sharma,Fazl Barez", "background": "大型推理模型（LRMs）通过分配更多的推理时计算资源来提高任务性能，这表明增强的推理能力也可能通过提高拒绝行为来增强安全性。然而，本研究发现情况并非如此，相同的推理过程也可以被利用来规避安全措施。研究人员引入了“推理链劫持”攻击（Chain-of-Thought Hijacking），这是一种针对推理模型的逃逸攻击，通过向有害请求添加大量无辜的谜题推理来实施攻击。", "innovation": "研究引入了一种名为‘推理链劫持’（Chain-of-Thought Hijacking）的新型攻击方法，该方法通过在有害请求中添加大量无辜的推理过程来实施攻击，从而有效绕过了多种安全措施。实验结果表明，在HarmBench基准测试中的攻击成功率远超此前的方法。研究还通过机制分析揭示了安全性检查和验证结果在模型中的编码方式，并确认了某些注意力头在安全子网络中的关键作用。", "conclusion": "研究揭示了最可解释的推理形式——明确的推理链（CoT），在与最终答案提示相结合时可以成为逃逸向量。研究者发布了攻击提示、输出和判决结果，以便进一步复制实验结果。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26481", "html_url": "https://arxiv.org/abs/2510.26481", "title": "谁拥有最终决定权？ChatGPT 选择中的从众动态", "title_en": "Who Has The Final Say? Conformity Dynamics in ChatGPT's Selections", "authors": "Clarissa Sabrina Arlinghaus,Tristan Kenneweg,Barbara Hammer,Günter W. Maier", "background": "大型语言模型（LLMs）如ChatGPT越来越多地被集成到高风险决策中，但对其社会影响的易感性知之甚少。这项研究通过三个注册的从众实验，探索了在招聘背景下GPT-4的行为变化，考察了模型在社会影响下的决策适应性变化。", "innovation": "该研究创新性地对GPT-4展开了多轮从众实验，证实大型语言模型在面对社会一致意见时会表现出从众行为，这与之前的独立决策模型假设不符。这种研究方法对于理解LLMs在复杂社会环境中的行为具有重要启示意义。", "conclusion": "研究结果显示，大型语言模型GPT-4实际上并不是独立的观察者，而是在感知到社会共识后进行调整。这些发现强调了在将AI系统用于决策支持时必须正视其社会易感性，建议在AI判断公开前征求人类意见以降低潜在风险。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26493", "html_url": "https://arxiv.org/abs/2510.26493", "title": "Context Engineering 2.0: The Context of Context Engineering", "title_en": "Context Engineering 2.0: The Context of Context Engineering", "authors": "Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu", "background": "卡尔·马克思曾强调指出，人类的本质是社会关系的总和，暗示个体并非孤立存在，而是由其与其他实体之间的互动所深刻塑造。随着计算机和人工智能的发展，这些互动不再局限于人与人之间的，现在还包括人与机器之间的互动。因此，一个核心问题浮现出来：机器如何更好地理解我们的情况和目的？为回答这一挑战，研究人员引入了情境工程的概念。尽管通常认为它源于智能代理时代的近期创新，但论文指出相关实践可以追溯到二十年前。", "innovation": "论文通过系统地定义情境工程，概述其历史和概念框架，并探讨关键设计考虑，旨在为情境工程提供概念基础，并展望其充满希望的未来。", "conclusion": "通过这些问题的回答，论文旨在为情境工程提供概念基础，并勾勒其充满希望的未来。这为更广泛的社区努力系统化人工智能系统中的情境工程奠定了基石。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26486", "html_url": "https://arxiv.org/abs/2510.26486", "title": "LINK-KG: LLM-驱动的核心指代解析知识图谱用于人口走私网络", "title_en": "LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks", "authors": "Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera", "background": "人类走私网络复杂且不断演变，使全面分析变得困难。法律案件文件提供了有关网络的丰富事实和程序性见解，但这些文件往往长、无结构化且充满了模糊或不断变化的引用，这为自动化知识图谱（KG）构建带来了重大挑战。现有的方法要么忽视了共指解析，要么无法扩展到短文本片段之外，导致知识图谱碎片化和实体链接不一致。", "innovation": "我们提出了LINK-KG，这是一种模块化框架，结合了LLM指导下的三阶段共指解析流水线和下游KG提取。我们方法的核心是一个类型特定的提示缓存，它在文档片段之间一致跟踪并解决引用，从而为结构化知识图谱构建提供清晰和去模糊的叙述。LINK-KG将平均节点重复减少了45.21%，噪音节点减少了32.22%，从而形成了一个更整洁和更连贯的图结构。这些改进为分析复杂犯罪网络奠定了坚实的基础。", "conclusion": "LINK-KG通过整合LLM指导下的共指解析流水线和下游KG提取，成功减少了节点重复和噪音节点，增强了知识图谱的连贯性和清洁性，为分析复杂的犯罪网络提供了强大的基础。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26518", "html_url": "https://arxiv.org/abs/2510.26518", "title": "人类-人工智能互补：放大监督的目标", "title_en": "Human-AI Complementarity: A Goal for Amplified Oversight", "authors": "Rishub Jain,Sophie Bridgers,Lili Janzer,Rory Greig,Tian Huey Teh,Vladimir Mikulik", "background": "随着AI能力的提高以及AI被用于更复杂的任务，确保AI系统的质量和安全变得越来越困难。人类反馈对于使AI系统与人类价值观保持一致至关重要。本研究集中于一个已对人类构成挑战的安全问题：AI输出的事实核查。研究人员发现，结合基于AI评分者的信心的AI评分和人类评分可以比单独依赖其中任何一方更有效。向人类提供AI事实核查助手可以进一步提高准确性，但这种帮助的类型很重要。展示AI解释、信心和标签会导致过度依赖，而仅仅是显示搜索结果和证据则可以培养更适当的信任。这些结果对人类和AI结合监督AI系统的研究有重要影响，即使在AI超越人类专家水平时也是如此。", "innovation": "该研究提出了通过结合AI评分和人类评分，尤其是基于AI评分者信心的评分，可以更有效进行AI输出的事实核查。研究还指出，向人类提供AI助手，但仅显示搜索结果和证据能更好地培养人类对AI的信任，避免过度依赖。这些发现对提高AI监督的质量和安全具有创新意义，特别是在AI超越人类专家水平的情况下。", "conclusion": "该研究表明，人类和AI的结合可以在监督AI系统时发挥更大作用，尤其是在解决复杂和高度可信的任务时。结合AI评分和人类评分，以及提供适当的AI助手，可以提高监督的准确性和效果。这些发现为研究如何更有效地放大人类监督做了重要贡献。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26550", "html_url": "https://arxiv.org/abs/2510.26550", "title": "EdgeRunner 20B：运行在边缘的GPT-5军事任务平局", "title_en": "EdgeRunner 20B: Military Task Parity with GPT-5 while Running on the Edge", "authors": "Jack FitzGerald,Aristotelis Lazaridis,Dylan Bates,Aman Sharma,Jonnathan Castillo,Yousif Azami,Sean Bailey,Jeremy Cao,Peter Damianov,Kevin de Haan,Luke Kerbs,Vincent Lu,Joseph Madigan,Jeremy McLaurin,Jonathan Tainer,Dave Anderson,Jonathan Beck,Jamie Cuticello,Colton Malkerson,Tyler Saltsman", "background": "EdgeRunner 20B 是对 gpt-oss-20b 模型进行微调优化后的一个版本，专门针对军事任务。模型是在 1.6 百万份高质量记录的基础上训练而成，这些记录来自精选的军事文档和网站。此外，还展示了四个新的测试集，包括作战兵种、战斗救护、网络作战和 mil-bench-5k (军事知识通用)。", "innovation": "EdgeRunner 20B 在军事任务测试集上达到了或超过了 GPT-5 的任务性能，具有 95% 以上的统计显著性，仅在某些高推理和低推理设置下表现不佳。相对于 gpt-oss-20b，在通用的性能基准测试中几乎无显著下降，仅在 GSM8k 中有轻微差异。此外，还对超参数设置、成本和吞吐量进行了分析。这些发现表明，小型、本地托管的模型是数据敏感操作的理想解决方案，如在军事领域的应用，使得在孤岛边沿设备中部署成为可能。", "conclusion": "研究结果表明，小型、本地托管的 EdgeRunner 20B 模型非常适合军事领域等数据敏感的操作，能够在边缘设备上运行，同时保持或提高了执行军事任务的能力，并且在通用任务上的性能几乎没有下降。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26603", "html_url": "https://arxiv.org/abs/2510.26603", "title": "具备自主能力的AI家庭能源管理系统：一种用于住宅负荷调度的大语言模型框架", "title_en": "Agentic AI Home Energy Management System: A Large Language Model Framework for Residential Load Scheduling", "authors": "Reda El Makroum,Sebastian Zwickl-Bernhard,Lukas Kranzl", "background": "电力部门向可再生能源和灵活性的过渡需要显著提升居民的需求响应能力，然而家庭能源管理系统（HEMS）的应用仍然受限于用户交互障碍，这些障碍使得将日常偏好转化为技术参数成为难题。尽管大型语言模型已被用于生成代码和提取参数，但没有现有实现将大型语言模型作为自动化协调员来管理从自然语言输入到多电器调度的完整工作流程。", "innovation": "本文提出了一种自主代理AI HEMS，其中大型语言模型能够自主协调从自然语言请求到设备控制的多电器调度工作流程，并实现最优调度，而无需示例演示。这是一种结合了一位协调器和三位专门代理的分层架构，利用ReAct模式进行迭代推理，能够在没有硬编码工作流程的情况下进行动态协调，同时集成Google日历进行基于上下文的截止日期提取。在三个开源模型上的评估结果显示了不同能力的显著差异。Llama-3.3-70B能够协调所有电器并在所有场景中匹配通过混合整数线性规划计算的成本最优基准，而其他模型在单电器上能够达到完美表现，但在同时协调所有电器方面面临困难。", "conclusion": "渐进式的提示工程实验表明，尽管模型具备一般推理能力，但在无需明确指导的情况下处理分析查询仍然是不可靠的。我们开源了整个系统，包括协调逻辑、代理提示、工具和网络界面，以实现可重现性，扩展性和未来研究。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26606", "html_url": "https://arxiv.org/abs/2510.26606", "title": "大型语言模型中的规范性推理：从逻辑和模态角度的比较基准", "title_en": "Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives", "authors": "Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada", "background": "大型语言模型（LLMs）在各种推理任务上表现出色，但在规范性推理能力方面仍鲜有研究。规范性推理涉及规范或道义模态，如义务和许可。为了系统评估LLMs在规范性领域的推理能力，研究者设计了一项新的基准测试，其中包括规范性和认识论模态的正式推理模式，并考虑人类推理中的非正式认知因素。研究发现，尽管LLMs通常遵循有效的推理模式，但在特定类型的规范性推理中表现出显著的不一致，并表现出类似于人类心理学研究中的认知偏差，这表明在LLMs的规范性推理中实现逻辑一致性的挑战，并为提高其可靠性提供了见解。所有数据和代码已公开发布。", "innovation": "研究引入了一个新的数据集，涵盖了规范性和认识论领域的广泛形式推理模式，同时也融入了影响人类推理的非形式认知因素。将LLMs处理规范性模态的推理能力与处理认识论模态的能力进行了比较，并揭示了其认知偏差，强调了在LLMs的规范性推理中实现逻辑一致性的挑战。", "conclusion": "尽管LLMs通常能够遵循有效的推理模式，但在特定类型的规范性推理中表现出明显的不一致性，显示出与人类推理中观察到的认知偏差相似的趋势。这些发现揭示了实现逻辑一致性的挑战，并为提高LLMs规范性推理的可靠性提供了见解。所有数据和代码都在公开渠道上发布。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26702", "html_url": "https://arxiv.org/abs/2510.26702", "title": "代理授权以满足语义任务到权限范围匹配", "title_en": "Delegated Authorization for Agents Constrained to Semantic Task-to-Scope Matching", "authors": "Majed El Helou,Chiara Troiani,Benjamin Ryder,Jean Diaconu,Hervé Muyal,Marcelo Yannuzzi", "background": "当前方法在授予代理授权时授予了过于广泛的权限，并且允许代理超出其指派任务范围进行操作，这种授权方法会引入显著风险。现有的数据集不足以评估和改进任务到权限范围匹配的处理，因为缺少包含适当和不适当权限请求的数据集。", "innovation": "本文提出了一个代理授权模型，使得授权服务器可以在接收访问保护资源的请求时进行语义检查，并发放仅包含完成任务所必需权限范围的访问令牌。同时，鉴于缺乏相关数据集，本文构建了ASTRA，一个数据集和数据生成管道，用于基准测试任务到权限范围的语义匹配。通过实验证明了基于模型的匹配技术的潜力和当前局限性，并强调了需要进一步研究语义匹配技术以实现具意图感知的多代理及工具增强应用授权控制，如基于任务的访问控制（TBAC）的重要性。", "conclusion": "本文的研究结果表明，随着任务完成所需权限范围数量的增加，基于模型的匹配技术还存在局限性。因此，未来需进一步研究，以提高语义匹配的精度和效率，并能够细粒度地控制权限角色，以实现更安全和灵活的应用程序。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26658", "html_url": "https://arxiv.org/abs/2510.26658", "title": "代理性组织的时代：让语言模型学会组织", "title_en": "The Era of Agentic Organization: Learning to Organize with Language Models", "authors": "Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei", "background": "本文设想了一种新的AI时代，称为代理性组织，其中代理能够在协同和并发工作的基础上解决复杂的任务，产生超越个体智能的结果。为了实现这一愿景，引入了异步思考（AsyncThink）作为一种新的语言模型推理范式，将内部思维过程组织为可并发执行的结构。异步思考有效地整合了中间知识，并产生连贯的解决方案，这在解决数学推理问题时特别有效。此外，这种思维结构还可以通过强化学习进一步优化。该框架展示了其学习到的异步思考能力的有效性，并能够在无需额外训练的情况下解决未见过的任务。", "innovation": "本文提出了一种名为异步思考（AsyncThink）的新范式，改变了传统并行思考的方式，引入了动态分配子查询和合并中间知识的思维协议，这不仅提高了推理的准确性和可解释性，还通过强化学习优化了思维组织结构，显著降低了推理延迟，达成了28%的优良率提升，并且其学习到的能力可以有效应用于未见过的任务。", "conclusion": "异步思考（AsyncThink）通过动态分配任务和合并中间知识，解决了并行思考的延迟问题，同时提高了模型在数学推理等任务上的准确性和泛化能力，其通过强化学习优化的思维结构进一步增强了模型的灵活性和学习效率。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26721", "html_url": "https://arxiv.org/abs/2510.26721", "title": "通过注意力键空间分析揭示多模态大型语言模型中的固有文本偏见", "title_en": "Unveiling Intrinsic Text Bias in Multimodal Large Language Models through Attention Key-Space Analysis", "authors": "Xinhan Zheng,Huyu Wu,Xueting Wang,Haiyun Jiang", "background": "多模态大型语言模型（MLLMs）在处理视觉-语言数据时，表现出对文本输入的偏好，从而限制了它们从视觉证据中进行有效推理的能力。以往的研究认为这种文本偏见是由于外部因素，如数据不平衡或指令调优导致的。该论文提出，这种偏见实际上源自模型内部的架构。研究者假设视觉键向量对于仅语言预训练中学到的文本键空间是离分布的（OOD），因此这些视觉键在注意力计算中的相似性评分系统性较低，导致在上下文表示中的利用率不足。", "innovation": "本研究通过提取来自LLaVA和Qwen2.5-VL的键向量，并使用定性（t-SNE）和定量（Jensen-Shannon散度）方法分析它们的结构分布，揭示了视觉和文本键在注意力空间中占据明显不同的子空间。研究成果强调了文本偏见来自于注意力键空间的固有对齐问题，而不仅仅是外部数据因素。", "conclusion": "研究结果表明视觉和文本键在注意力空间中的不同分布是统计上显著的，视觉键的利用率较低主要归因于其在键空间中的位置。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26784", "html_url": "https://arxiv.org/abs/2510.26784", "title": "LLMs Processing Lists With General Filter Heads", "title_en": "LLMs Process Lists With General Filter Heads", "authors": "Arnab Sen Sharma,Giordano Rogers,Natalie Shapira,David Bau", "background": "该论文研究了大型语言模型（LLMs）在处理列表任务时的机制。作者发现，这些模型已经学会了如何编码一个紧凑且因果相关的过滤操作表示，这种表示与功能编程中的通用“筛选”函数类似。研究表明，通过因果中介分析，少量特定的注意力头（称之为过滤头）可以编码过滤谓词在某些标记的状态中。\n", "innovation": "研究揭示了transformer语言模型可以开发出人类可理解的抽象计算操作的实现，并且这些操作可以在不同数据集、不同格式、不同语言的任务中推广。此外，作者还发现这些模型还可以通过提前评估并直接将中间结果存储为标志在项目表示中来执行筛选操作，这展示了transformer模型处理筛选任务时的多样策略。\n", "conclusion": "研究结果表明，transformer语言模型能够发展出类似于传统功能编程模式的推广策略，实现高度抽象的计算操作，并且这一过程可以被人类理解。这些发现为理解transformer模型的工作机理和其在编程和自然语言处理中的应用提供了新见解。\n"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26732", "html_url": "https://arxiv.org/abs/2510.26732", "title": "跨平台基础模型推理能力评估", "title_en": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models", "authors": "J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot", "background": "本文对现代基础模型的推理能力进行了全面的跨平台评估，涵盖三种计算范式：高性能计算（MareNostrum 5）、云平台（Nebius AI Studio）和大学集群（配置有8个H200 GPU的节点）。评估了15个基础模型在8个学术领域的79个问题上的性能，这些学术领域包括物理学、数学、化学、经济学、生物学、统计学、微积分和优化。该研究通过三次实验阶段来评估模型的能力：基准建立、基础设施验证和扩展评估，旨在挑战现有的扩展假设，并强调训练数据质量的重要性，特别是在教育、生产和研究领域的应对策略选择方面。", "innovation": "本文建立了跨基础设施无关联的基准评估，并通过三种不同的计算平台（高性能计算集群、云平台和大学集群）对15个基础模型进行了全面评价。引入了跨基础设施的方法和79问题基准，以便长期追踪基础模型推理能力的变化。该项工作提出了模型选择的实际指导原则，特别关注不同基础设施对模型性能的影响，这为未来基础模型的发展和应用提供了一种新的评估思路。", "conclusion": "关键研究发现包括：挑战传统的扩展假设，将训练数据质量视为更为关键的因素，而不仅仅是模型规模；建立跨基础设施的通用评估基准，提出模型选择的具体指南，适用于教育、生产和研发等多个场景；跨多平台评估框架为未来基础模型的扩展和优化提供了更加全面且可靠的方法。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26752", "html_url": "https://arxiv.org/abs/2510.26752", "title": "监管游戏：学习协同平衡人工智能代理的安全性和自主性", "title_en": "The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy", "authors": "William Overman,Mohsen Bayati", "background": "随着越来越能力强的代理系统被部署，人们越来越关注如何在不修改系统本身的情况下，保留有意义的人类控制能力。本文研究了一种最小控制接口，其中代理人自主行动或请示人类，人类也同时决定是否信任或进行监督。如果代理人请示，人类的决定将决定结果，可能会导致纠正行动或系统关闭。", "innovation": "本文将这种交互建模为一个两阶段马尔可夫博弈，并探讨了该博弈作为马尔可夫潜在博弈（MPG）的情况，在这类博弈中，可以在人类价值函数结构假设条件下提供对齐保证：任何有利于自身且提高自主性的代理决策，都不会对人类的价值产生负面影响。此外，还分析了这一MPG框架的扩展。理论上，这种视角提供了特定形式内在对齐的条件。如果人类-代理人的奖惩结构满足这些条件，则可以正式保证代理提高自身表现不会损害人类。实践上，这一模型促进了透明且有预测激励的控制层，地管理器在充满风险时选择请求协助，在安全时主动行动，同时保留预训练策略和环境的奖惩结构不变。网格世界模拟显示，通过独立学习，代理人和人类共同发现各自的最优监督角色。", "conclusion": "证明了一种在部署后使不一致模型更安全的实用方法，即在不确定时请求监督，人类在必要时进行监督，从而避免训练后引入的安全问题，促进了自发的合作方式，防止安全违规行为。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25781", "html_url": "https://arxiv.org/abs/2510.25781", "title": "Kolmogorov-Arnold网络指南", "title_en": "A Practitioner's Guide to Kolmogorov-Arnold Networks", "authors": "Amir Noorizadegan,Sifan Wang,Leevan Ling", "background": "Kolmogorov-Arnold网络（KANs）作为一种新的神经网络架构，受到Kolmgorov-Arnold表示定理的启发，逐渐成为传统多层感知机（MLPs）的有前途的替代方案。KANs使用学习可变的边缘基函数而不是固定的激活函数节点，这提高了表征能力和可解释性。", "innovation": "论文提供了一个全面的KANs的系统性概述，不仅限于性能对比，还包含理论基础、结构变体和实践实施策略。研究集中探讨了基础函数的选择和权衡，包括B样条、切比雪夫多项式、ReLU组成、高斯RBF和傅里叶级数。论文还详细阐述了提高准确度、效率和正则化的先进技术，并提供了一份“选择你的KANs”的实用指南。", "conclusion": "文章最后指出了当前研究的空白，并提供了一个GitHub仓库作为持续KAN研究的结构参考。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25783", "html_url": "https://arxiv.org/abs/2510.25783", "title": "LASTIST：大规模目标无关立场数据集", "title_en": "LASTIST: LArge-Scale Target-Independent STance dataset", "authors": "DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park", "background": "立场检测研究在人工智能领域逐渐兴起，目前的工作主要集中在针对特定目标的立场检测任务上。多数基准数据集语言资源丰富，比如英语，导致低资源语言，如韩语，在这一新兴领域的发展受到限制。为此，本研究提出了大规模目标无关立场（LASTIST）数据集填补这一研究空白。", "innovation": "本研究提出了LASTIST数据集，这是一个包含563,299个标注的韩语句子的数据集，来自韩国政治党派的新闻发布会，目的在于为立场检测的各种任务提供支持，特别是在目标无关立场检测和历时演变立场检测方面。", "conclusion": "研究展示了如何收集和构建此数据集以及训练最先进的深度学习和立场检测模型。最后，该数据集上线，供研究人员使用。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25786", "html_url": "https://arxiv.org/abs/2510.25786", "title": "BlackboxNLP-2025 MIB Shared Task: 通过更好的边选择提高电路忠实度", "title_en": "BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better Edge Selection", "authors": "Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov", "background": "机制可解释性的一个主要挑战是在模型中发现执行特定任务的电路，即确定模型中哪一部分执行给定的任务。现有的机制可解释性基准（MIB）为电路发现提供了基础，但其方法在准确性和忠实性方面存在不足。", "innovation": "本文提出了三种关键改进来提高电路发现的准确性：1. 使用自助法来识别具有一致贡献评分的边；2. 引入了一个简单的基于比率的边选择策略，以平衡性能和忠实性；3. 用整数线性规划公式替换标准贪婪选择。这些改进使得电路更忠实，同时在MIB的多个任务和模型上超过先前的方法。", "conclusion": "本文的方法在多个MIB任务和模型上比之前的方法更加忠实，性能优越。代码已发布至特定网址。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25140", "html_url": "https://arxiv.org/abs/2510.25140", "title": "DINO-YOLO：在土木工程应用中的自我监督预训练以实现高效目标检测", "title_en": "DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object Detection in Civil Engineering Applications", "authors": "Malaisree P,Youwai S,Kitkobsin T,Janrungautai S,Amorndechaphon D,Rojanavasu P", "background": "在土木工程应用中，目标检测受限于专业领域的标注数据不足。针对这一问题，本文介绍了一种新的混合架构DINO-YOLO，该架构结合了YOLOv12和DINOv3自我监督的视觉变换器，以实现高效的数据检测。DINOv3特征在输入预处理（P0）和中间骨干增强（P3）两个位置进行战略性集成。实验证明，在隧道段裂缝检测（648张图像）、建筑劳保用品（1000张图像）和KITTI（7000张图像）数据集上分别取得了12.4%、13.7%和88.6%的显著改进，同时保持了实时推理能力（30-47 FPS）", "innovation": "本文提出了一种新的混合架构DINO-YOLO，它结合了YOLOv12和DINOv3自我监督的视觉变换器，并在输入预处理（P0）和中间骨干增强（P3）两个位置战略性地引入了DINOv3特征。系统泛化实验表明，对于中等规模的架构，使用双重P0P3集成（55.77% mAP@0.5）表现出最佳性能，而小规模架构则需要三重集成（53.63%）。虽然推理过程增加了2至4倍的开销（21-33ms相对于8-16ms的基线），但在NVIDIA RTX 5090设备上仍适用于现场部署。因此，DINO-YOLO在土木工程数据集（少于10000张图片）中达到了最先进的性能，同时保持了计算效率，提供了在数据受限环境下用于建筑安全监控和基础设施检查的可行解决方案", "conclusion": "本文展示了DINO-YOLO在土木工程应用中的优越性能和高效性。该模型通过结合YOLOv12和DINOv3，特别是在输入预处理和中间骨干增强中的集成，实现了显著的目标检测改进。此模型不仅在保持实时性能的同时提高了数据效率，而且在实际应用中提供了切实可行的解决方案，特别是在数据稀缺的环境中，为未来的研究和开发提供了有益的参考。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25785", "html_url": "https://arxiv.org/abs/2510.25785", "title": "HiMAE: 层次掩蔽自动编码器发现穿戴式时间序列的分辨率特异性结构", "title_en": "HiMAE: Hierarchical Masked Autoencoders Discover Resolution-Specific Structure in Wearable Time Series", "authors": "Simon A. Lee,Cyrus Tanade,Hao Zhou,Juhyeon Lee,Megha Thukral,Minji Han,Rachel Choi,Md Sazzad Hissain Khan,Baiying Lu,Migyeong Gwak,Mehrab Bin Morshed,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Subramaniam Venkatraman,Sharanya Arcot Desai", "background": "穿戴式传感器提供了丰富的生理时间序列数据，但这些数据的预测效用背后的原理尚不清楚。研究者推测，时间分辨率是代表学习的一个基础维度，不同临床和行为结果依赖于不同尺度的结构。为了验证这一假设，研究引入了HiMAE（层次掩蔽自动编码器），这是一种结合掩蔽自动编码和层次卷积编码解码的自我监督框架。HiMAE可以生成多分辨率嵌入，使系统评估哪些时间尺度承载预测信号成为可能，从而将时间分辨率从超参数转化为可解释性探针。通过分类、回归和生成基准测试，HiMAE在所有指标上都优于将尺度压缩的基础模型，同时体积和计算量大幅减少。HiMAE是一种高效的表示学习方法，能够在智能手表级的CPU上实现毫秒级的推理，实现真正的边缘推理。", "innovation": "介绍了HiMAE（层次掩蔽自动编码器），这是一种结合掩蔽自动编码和层次卷积编码解码的自我监督框架。它可以生成多分辨率嵌入，通过评估哪些时间尺度承载预测信号，将时间分辨率从超参数转化为可解释性探针。在分类、回归和生成基准测试中，HiMAE表现出色且模型小型化，可以在智能手表级的CPU上实现高效的推理。", "conclusion": "HiMAE是高效的自我监督学习方法，同时也是一个发现佩戴健康数据中依赖于分辨率结构的工具。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25779", "html_url": "https://arxiv.org/abs/2510.25779", "title": "磁性集市：一个用于研究代理市场开源环境", "title_en": "Magentic Marketplace: An Open-Source Environment for Studying Agentic Markets", "authors": "Gagan Bansal,Wenyue Hua,Zezhou Huang,Adam Fourney,Amanda Swearngin,Will Epperson,Tyler Payne,Jake M. Hofman,Brendan Lucier,Chinmay Singh,Markus Mobius,Akshay Nambi,Archana Yadav,Kevin Gao,David M. Rothschild,Aleksandrs Slivkins,Daniel G. Goldstein,Hussein Mozannar,Nicole Immorlica,Maya Murad,Matthew Vogel,Subbarao Kambhampati,Eric Horvitz,Saleema Amershi", "background": "随着LLM代理的发展，它们在经济决策中扮演越来越重要的角色，包括产品发现到交易等各个方面。这些应用带来了很多好处，但同时也引发了关于代理责任和用户价值的问题。这些问题需要通过理解和研究代理在现实市场条件下的行为来解决。然而，之前的大部分研究仅集中在受限条件下对代理的评估，如单任务市场（例如谈判）或结构化的两方对话。现实中的市场则完全不同，要求代理处理各种经济活动并协调动作，在复杂、动态的生态系统中与其他具有不透明行为的代理进行开放对话。为了弥合这种差距，本研究调查了两类代理市场，其中一个代理代表消费者，另一个代理代表竞争性企业。为了安全地研究这些交互，我们开发了一个模拟环境——磁性市场。这个环境使得我们能够研究关键市场动态，如代理实现的效用、行为偏差、容易受到操控的程度，以及搜索机制如何影响市场结果。实验表明，前沿模型在理想搜索条件下的亚福利条件可以接近最优福利，但随着规模的扩大，性能急剧下降，并且所有模型都表现出严重的第一个提案偏差，这为响应速度比质量创造了10-30倍的优势。这些发现揭示了市场条件下行为的形成，为设计公平和高效的代理市场提供了指导。", "innovation": "本研究通过开发名为磁性市场的模拟环境，以解决前沿代理模型在实际市场条件下的性能问题。这种环境使代理代表消费者和企业进行交互，从而研究关键市场动态。研究发现，理想条件下的前沿模型能够接近最优福利，但在大规模操作时性能下降显著，所有模型均表现出严重的第一个提案偏向，这影响了响应速度和质量的比例关系。这项工作对于了解代理市场中的行为动态、设计公平和高效的代理市场具有重要意义。", "conclusion": "研究通过磁性市场模拟环境实验发现，前沿模型在理想搜索条件下接近最优自愿交易，但在实际市场环境中随规模增大表现较差，所有模型都表现出严重的第一提案偏差，这使得快速响应比高质量提案有更大的先机。该研究结果为设计更加公平、高效的代理市场提供了重要指导。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25791", "html_url": "https://arxiv.org/abs/2510.25791", "title": "推理的动力学：链推理如何塑造Transformer的学习？", "title_en": "The Kinetics of Reasoning: How Chain-of-Thought Shapes Learning in Transformers?", "authors": "Zihan Pengmei,Costas Mavromatis,Zhengyuan Shen,Yunyi Zhang,Vassilis N. Ioannidis,Huzefa Rangwala", "background": "链推理（CoT）监督可以显著提高Transformer的表现，但模型是如何学习跟随和受益于CoT的机制尚不完全了解。本文通过以可调算法复杂性和可控制数据组成的方式预训练Transformer在符号推理任务上来研究这些学习动态，从而考察其泛化能力。", "innovation": "1. 引入了Kineti模型框架，以理解Transformer的学习过程；\n2. 揭示了CoT监督下推理痕迹忠实度的动态变化；\n3. 建模对数训练步骤的准确性与三个参数的逻辑曲线，展示了学习速度和形状的差异；\n4. 发现了推理痕迹的瞬态不可信阶段：在训练初期，模型经常给出正确的答案但省略或矛盾推理步骤，在稍后阶段与答案对齐。", "conclusion": "CoT可以提高泛化能力，但无法克服高算法复杂度的任务；表明CoT从机制上改变了内部Transformer计算。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25784", "html_url": "https://arxiv.org/abs/2510.25784", "title": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "title_en": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "authors": "Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee", "background": "大规模语言模型（LLMs）正越来越多地与针对多个下游应用的任务特定适配器一起部署。这些适配器虽然参数量相对较少（通常少于基模型的1%），但在推理时的计算开销却显著增加，最高可达基模型的2.5倍。这就导致了一个问题，即虽然适配器本身是为了提高模型特定任务的性能而设计的，但它们却加大了推理时的延迟问题，影响了模型的实际应用效果。", "innovation": "本文提出了一种新的零延迟融合低秩适配器（zFLoRA），该方法在不增加或几乎不增加延迟开销的情况下提高了基模型的效率。实验表明，zFLoRA在1B、3B和7B规模的LLMs上表现优于现有的低秩适配器（LoRA）和全微调（FFT）基准方法。该研究还在18种不同任务上进行了实验，涵盖了常识推理、数学推理和总结对话等领域，验证了zFLoRA的性能。此外，zFLoRA在NPU和GPU平台上进行了延迟测量，结果显示其引入的延迟开销为零或几乎可以忽略不计。", "conclusion": "实验结果表明，zFLoRA优于现有的低秩适配器(LoRA)和全微调(FFT)基准方法。在18种不同任务上，尤其是常识推理、数学推理和总结对话领域，zFLoRA展示了零或几乎可以忽略不计的延迟开销，显著提高了部署大规模语言模型的效率。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25796", "html_url": "https://arxiv.org/abs/2510.25796", "title": "在大型按需拼车系统中使用仿真指导强化学习进行非短视匹配和再平衡", "title_en": "Non-myopic Matching and Rebalancing in Large-Scale On-Demand Ride-Pooling Systems Using Simulation-Informed Reinforcement Learning", "authors": "Farnoosh Namdarpour,Joseph Y. J. Chow", "background": "拼车服务可以减少乘客和运营商的成本，缓解交通拥堵和环境影响。然而，现有的分配决策往往是短视的，忽视了长期影响。研究表明基于强化学习的调度方法在叫车系统中有广泛应用，但在拼车系统中的研究较少。", "innovation": "本文提出了一个扩展了Xu等人(2018)的骑行调度和决策学习框架，该框架在学习机制中嵌入拼车模拟以实现非短视决策。此外，提出了用于再平衡空闲车辆的补充策略。通过在模拟经验上应用n步时差学习，得出了时空状态值，进而用纽约市出租车请求数据评估非短视策略的有效性。", "conclusion": "非短视匹配策略可将服务率提高至8.4%，缩短乘客等候时间和行程时间，减少25%以上的车辆规模，同时保持相同的性能水平，带来显著的成本节约。整合再平衡操作后，非短视策略能最大减少27.3%的候车时间、12.5%的行程时间，并将服务率提高15.1%，带来显著效益，尽管增加了乘客每人的车辆行驶时间。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25787", "html_url": "https://arxiv.org/abs/2510.25787", "title": "基于电压依赖性突触可塑性的无监督局部学习方法研究", "title_en": "Unsupervised local learning based on voltage-dependent synaptic plasticity for resistive and ferroelectric synapses", "authors": "Nikhil Garg,Ismael Balafrej,Joao Henrique Quintino Palhares,Laura Bégon-Lours,Davide Florini,Donato Francesco Falcone,Tommaso Stecconi,Valeria Bragaglia,Bert Jan Offrein,Jean-Michel Portal,Damien Querlioz,Yann Beilliard,Dominique Drouin,Fabien Alibart", "background": "边沿计算设备上部署人工智能面临着能耗高和功能限制等重大挑战。这些设备可以从脑启发式学习机制中获益，允许实时适应并使用低功耗。纳米尺度的电阻性内存进行的内存计算可能在使得这些边缘设备执行人工智能工作负载方面发挥关键作用。现有的基于STDP的学习机制通常需要复杂脉冲整形电路来实现在线学习，增加了系统复杂性并降低了准确性。", "innovation": "提出了一种基于Hebb原理和电压依赖性突触可塑性(VDSP)的高效方法，用于基于阻变性忆阻突触的无监督和局部学习。VDSP允许在线学习而无需复杂的脉冲整形电路，适用于不同类型的忆阻器器件，如TiO2、HfO2基金属氧化物纳米线突触和HfZrO4基铁电隧道结，并在处理MNIST模式识别任务的脉冲神经网络中进行了系统级模拟，实现了现有技术水平的性能，所有设备使用200个神经元时准确率超过83%，并评估了器件变异性的影响，如转换阈值和高阻态和低阻态水平的比例，并提出缓解策略以增强鲁棒性。", "conclusion": "通过使用VDSP，本研究成功地实现了基于阻变性和铁电突触器件的脉冲神经网络的无监督学习，展示了在MNIST任务中高精度和鲁棒性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25798", "html_url": "https://arxiv.org/abs/2510.25798", "title": "MemEIC：迈向连续且组合的知识编辑", "title_en": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing", "authors": "Jin Seong,Jiyun Park,Wencke Liermann,Hongseok Choi,Yoonji Nam,Hyun Kim,Soojong Lim,Namhoon Lee", "background": "信息的动态性质要求不断更新大型视觉语言模型（LVLMs）。虽然最近的知识编辑技术提供了有希望的方向，但它们通常集中于孤立地编辑单一模态（视觉或语言）。这种做法忽视了LVLM自然存在的跨模态性质和知识更新的持续需求，这可能导致在考虑模态间的相互作用和持续知识精细化时，编辑结果不尽如人意。因此，需要一种方法来处理这些限制。", "innovation": "提出了一种称为MemEIC的新方法，用于LVLMs中的连续和组合知识编辑（CCKE）。MemEIC允许按顺序编辑视觉和文本知识，使用混合外部-内部编辑器，配备双外部存储跨模态证据检索，和双LoRA适配器，以帮助每个模态的解耦参数更新。关键组成部分是一个受大脑启发的知识连接器，仅在组合推理时激活，以跨模态整合信息。实验结果表明，MemEIC显著提高了复杂跨模态问题的表现，有效地保留了先前的编辑内容，设立了新的CCKE在LVLM中的基准值。", "conclusion": "MemEIC在LVLM中实现了连续和组合的知识编辑，表现出色，为知识编辑领域提供了一个新的研究方向和改进的基准。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25819", "html_url": "https://arxiv.org/abs/2510.25819", "title": "AI代理的身份管理：AI代理世界的授权、认证与安全的新前沿", "title_en": "Identity Management for Agentic AI: The new frontier of authorization, authentication, and security for an AI agent world", "authors": "Tobin South,Subramanya Nagabhushanaradhya,Ayesha Dissanayaka,Sarah Cecchetti,George Fletcher,Victor Lu,Aldo Pietropaolo,Dean H. Saxe,Jeff Lombardo,Abhishek Maligehalli Shivalingaiah,Stan Bounev,Alex Keisner,Andor Kesselman,Zack Proser,Ginny Fahs,Andrew Bunyea,Ben Moskowitz,Atul Tulshibagwale,Dazza Greenwood,Jiaxin Pei,Alex Pentland", "background": "随着AI代理的迅速发展，认证、授权和身份管理面临迫切的挑战。目前的基于代理的协议（如MCP）突显了需要明确最佳实践的需求。未来，对于高度自主的代理的期望提出了关于可扩展访问控制、代理中心身份、AI工作负载差异化和代理委派权限等一系列复杂长期问题。", "innovation": "该OpenID基金会白皮书针对AI代理和访问管理交叉点的相关利益方，概述了当前可用的资源以确保代理的安全，并提出了一项战略议程，以解决关键的身份认证、授权和身份问题，这对于未来的广泛自主系统至关重要。", "conclusion": "白皮书强调了在AI代理世界中实施授权、认证和安全的基础性问题，并提供了解决这些基础性问题的战略议程。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS: 通过自提取偏好导向型冷启动解耦多模态学习", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "近年来，带有可验证奖励的强化学习（RL）推动了‘MLLM-r1’方法的兴起，将RL应用于视觉语言模型。大多数方法都采用监督微调（SFT）来初始化政策，但这种方法可能导致指令导向的过拟合，削弱了对遇到未见过的情况的泛化能力，因此影响了后续的RL效果。", "innovation": "作者重新审视了冷启动的训练方法和数据构建，并提出了Generalization Factor（GF）系数来量化不同方法下的泛化能力。作者发现偏好导向的训练方法（如DPO）在冷启动中比SFT方法有更好的泛化能力。基于此，作者提出了SPECS（Self-distilled, Preference-based Cold Start）框架，该框架包括三个步骤：通过自提取生成反思偏好数据对，避免依赖大型教师或手动标注；进行偏好导向的训练，而不仅仅是记忆内容，专注于浅层、可迁移的表面形式标准（格式、结构、风格）；最后，通过带有可验证奖励的RL来实现深层推理的结果。实验结果显示，SPECS框架在多个多模态基准测试中优于强基线，提高了MEGA-Bench的成绩超过4.1%，提高了MathVista的成绩超过12.2%。进一步的实验表明SPECS减少了分布内“停滞”的情况，提高了探索，稳定了训练，并提高了性能天花板。", "conclusion": "SPECS框架在多个多模态基准测试中表现优异，提高了模型的泛化能力和对未见过情况的适应能力，同时提高了探索性和训练稳定性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25863", "html_url": "https://arxiv.org/abs/2510.25863", "title": "AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI", "title_en": "AAGATE: A NIST AI RMF-Aligned Governance Platform for Agentic AI", "authors": "Ken Huang,Jerry Huang,Yasir Mehmood,Hammad Atta,Muhammad Zeeshan Baig,Muhammad Aziz Ul Haq", "background": "针对自主的语言模型驱动代理在生产环境中的独特安全和治理挑战，传统应用安全工具无法应对即兴和机器速度系统的风险。为了应对这些挑战，本文引入了Kubernetes原生的控制平面AAGATE，该平台基于NIST人工智能风险管理框架（AI RMF）进行设计和实现，旨在提供一种安全、可问责并可扩展的治理解决方案。", "innovation": "AAGATE整合了零信任服务网格、可解释的策略引擎、行为分析和去中心化的问责机制，通过引入DIRF（数字身份权利）、LPCI（逻辑层防御）和QSAF（认知退化监控）扩展，形成了一个全面的治理框架，覆盖系统性、对抗性和伦理风险", "conclusion": "AAGATE提供了一个能够持续监控和验证治理的机制，确保机器能够以安全、可问责的方式进行扩展部署，同时对潜在的系统性、对抗性和伦理风险进行全面管理。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25904", "html_url": "https://arxiv.org/abs/2510.25904", "title": "评测基于LLM辅助标注在构式网络标注中的影响：基于视角化的案例研究", "title_en": "Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation", "authors": "Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent", "background": "基于大型语言模型（LLM）的应用已经能够在语言资源和数据集的创建过程中加速或取代人类劳动。尽管这些工具对于语言学研究具有潜力，但在以视角化方式评估其性能及其对标注数据集创建的影响方面，仍然存在空白。", "innovation": "本文通过报告一种基于LLM的语义角色标注器对构式网络样式的语义标注进行半自动化处理的全面评估，填补了该领域的空白。研究对比了三种标注条件下（手工标注、自动标注和半自动标注）的标注时间、覆盖度和多样性。研究结果表明，混合的半自动标注设置能增加构式的多样性，并在覆盖度方面与纯人工标注相当，而完全自动标注则在所有指标上表现较弱，除了标注时间。", "conclusion": "不同标注条件下数据标注的对比结果表明，在构式网络标注中采用半自动方法可以提高标注的多样性和效率。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25924", "html_url": "https://arxiv.org/abs/2510.25924", "title": "使用代理转移因果效应", "title_en": "Transferring Causal Effects using Proxies", "authors": "Manuel Iglesias-Alonso,Felix Schur,Julius von Kügelgen,Jonas Peters", "background": "本文探讨在多域情况下估计因果效应的问题。感兴趣的原因受到了未观察到的混杂因素的影响，并且可能在不同领域中发生变化。作者假设拥有一个隐藏混杂因素的替代指标，并且所有变量都是离散或分类的。在仅观察替代指标的情况下，本文证明了目标领域的因果效应是可识别的（即使处理变量和响应变量是连续的）。", "innovation": "文中提出了一种新的方法来估计目标领域中的因果效应，并引入了两种估计技术，并证明了其一致性，以及推导出置信区间。这些理论结果通过仿真实验和现实生活中的案例（研究了网站排名对消费者选择的因果效应）得到了支持。此外，证明了在连续性和离散性变量下因果效应的可识别性，这增强了方法的普遍适用性。", "conclusion": "在仅观察可替代指标的情况下，本文提出了估计目标领域因果效应的方法，并通过理论上和实证上都验证了其有效性和准确性。还通过仿真研究和一个真实世界的应用实例，展示了该方法的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25818", "html_url": "https://arxiv.org/abs/2510.25818", "title": "ScaleDiff：通过高效且模型无关的扩散模型实现更高分辨率图像合成", "title_en": "ScaleDiff: Higher-Resolution Image Synthesis via Efficient and Model-Agnostic Diffusion", "authors": "Sungho Koh,SeungJu Cha,Hyunwoo Oh,Kwanyoung Lee,Dong-Jin Kim", "background": "文本到图像的扩散模型在生成超出训练分辨率的图像时通常表现不佳。虽然一些无需训练的方法可以缓解这一限制，但它们往往需要大量计算或者与最新的扩散变换器模型不兼容。", "innovation": "提出了一种名为ScaleDiff的模型通用且高效的框架，用于在无需额外训练的情况下扩展预训练扩散模型的分辨率。核心组件是 Neighborhood Patch Attention (NPA)，这是一种高效的机制，可以减少自注意力层中的计算冗余，通过非重叠的补丁实现。此外，引入了 Latent Frequency Mixing (LFM) 来更好地生成细节，并应用了结构引导以在去噪过程中增强全局结构。", "conclusion": "实验结果表明，ScaleDiff在无训练方法中以图像质量和推断速度方面均达到了最先进的性能，适用于U-Net和扩散变换器架构。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25890", "html_url": "https://arxiv.org/abs/2510.25890", "title": "PRISM：通过LLM与MDE协同作用及分层约束生成证明携带实体", "title_en": "PRISM: Proof-Carrying Artifact Generation through LLM x MDE Synergy and Stratified Constraints", "authors": "Tong Ma,Hui Lai,Hui Wang,Zhenhu Tian,Jizhou Wang,Haichao Wu,Yongfan Gao,Chaochao Li,Fengjie Xu,Ling Fang", "background": "在安全性和合规性至关重要的领域，现有方法生成的可审计的实体和机器可验证的证据存在不足，如异构模式和监管文本难以统一，生成的实体的结构有效性不足，且在违规时缺乏有效的修复机制和生成日志记录。PRISM旨在解决这些问题，通过整合大型语言模型（LLM）与模型驱动工程（MDE），生成规范和可审计的实体及机器可验证的证据，适用于汽车软件工程和跨境法律管辖等领域如AUTOSAR和Brussels I bis。", "innovation": "PRISM通过三项核心创新解决现有问题：1) 统一元模型（UMM）将异构模式和监管文本整合到单一的语义空间中；2) 综合约束模型（ICM）将结构性和语义要求编译为执行实体，包括生成时自动机（GBNF，DFA）和后生成验证器（如SHACL，SMT）；3) 约束引导验证生成（CVG）应用这些约束，通过两层执行——结构性约束驱动前缀安全解码，语义/逻辑验证生产机器可验证证书。当发生违规时，PRISM执行审计辅助修复，并记录生成轨迹以供合规审查。这种方法显著降低了人工修正的工作量，提供了一种实际的途径，实现带内置保证的自动化实体生成。", "conclusion": "PRISM已经在汽车软件工程（AUTOSAR）和跨境法律管辖（布鲁塞尔Ibis）的领域进行了评估。结果表明，PRISM生成的实体结构合理，具有可审计性，并能与现有工具无缝集成，大幅减少了人工修正所需的劳动。这为自动化实体生成提供了一条具有内置保障的实用路径。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25929", "html_url": "https://arxiv.org/abs/2510.25929", "title": "市场做市的多智能体强化学习：无勾结的竞争", "title_en": "Multi-Agent Reinforcement Learning for Market Making: Competition without Collusion", "authors": "Ziyi Wang,Carmine Ventre,Maria Polukarov", "background": "算法共谋已成为人工智能领域的重要问题：不同部署在市场中的AI代理之间的互动是否会引发共谋？更广泛地说，理解由更为先进的AI代理形成的卡特尔或市场支配力如何影响市场整体变得尤为重要。为了研究市场做市中的算法共谋，该文提出了一种多层次的多智能体强化学习框架，其中包含一个自利做市商（Agent A），以及三个底层竞争代理：具有最大化自身PnL目标的自利代理（Agent B1）、具有最小化对手PnL目标的竞争代理（Agent B2），以及能够转化其他两个代理行为的混合代理（B$^\text{star}$）。", "innovation": "文章提出了研究市场做市中算法共谋的多层次多智能体强化学习框架。通过分析各个代理之间的交互行为和对市场结果的影响，提出了衡量行为不对称性和系统级动态的交互度量方法，并通过实验展示了各代理在不同情境下的表现，特别突出了混合代理在非零和竞争中保持自身利益的同时对其他代理较少负面影响的特点。", "conclusion": "实验结果表明，竞争代理B2在零和环境中表现出主导性能，通过压缩平均价差提高市场交易效率；而混合代理B$^\text{star}$则通过适应性报价开启了动态激励控制，支持在异质智能体环境中可持续的战略共存，并为算法交易系统的行为设计提供了结构化的评估视角。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25935", "html_url": "https://arxiv.org/abs/2510.25935", "title": "基于过程挖掘的软件开发工作流分析与预测系统", "title_en": "A Process Mining-Based System For The Analysis and Prediction of Software Development Workflows", "authors": "Antía Dorado,Iván Folgueira,Sofía Martín,Gonzalo Martín,Álvaro Porto,Alejandro Ramos,John Wallace", "background": "CodeSight 是一个端到端的系统，旨在预测软件开发工作流中的截止日期遵守情况。该系统从 GitHub 直接捕获开发和部署数据，将其转换为过程挖掘日志，以进行详细分析。通过这些日志，系统生成了提供关于 PR 活动模式和工作流效率的可操作洞察的指标和仪表板。基于这些结构化的表示，CodeSight 使用 LSTM 模型，该模型基于序列活动轨迹和静态特征预测 PR 的剩余解决时间，从而实现潜在截止日期违例的早期识别。在测试中，该系统展示了在预测截止日期遵守情况方面高精度和 F1 分数，展示了将过程挖掘与机器学习结合用于主动的软件项目管理的价值。", "innovation": "CodeSight 系统通过从 GitHub 捕获数据并将其转换为可分析的过程挖掘日志，提供了一种新的方式来洞察软件开发流程。它通过应用 LSTM 模型预测 PR 的解决时间，能够在项目接近截止日期时进行早期识别，从而促进更有效的项目管理和团队协作。系统展示了在预测软件开发截止日期遵循方面的高精度和 F1 分数，证明了将过程挖掘与机器学习集成以实现主动软件项目管理的有效性。", "conclusion": "CodeSight 系统通过结合过程挖掘和机器学习技术，显著提高了软件开发工作流的可见性和可预测性。它不仅为 PR 活动模式提供有价值的洞察，还能够有效预测截止日期的遵守情况，从而帮助项目经理和团队采取及时措施防止潜在的延误。该研究的结果显示了过程挖掘技术在实际软件工程项目管理中的应用前景。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25960", "html_url": "https://arxiv.org/abs/2510.25960", "title": "WaveVerif：基于声学旁路的机器人工作流程验证", "title_en": "WaveVerif: Acoustic Side-Channel based Verification of Robotic Workflows", "authors": "Zeynep Yasemin Erdogan,Shishir Nagaraja,Chuadhry Mujeeb Ahmed,Ryan Shah", "background": "本文介绍了一个框架，使用声学侧通道分析(ASCA)来监控和验证机器人是否正确执行其意图命令。该系统利用由机器人动作产生的声学排放来进行机器学习工作流程验证，评估其实时行为是否与预期命令一致。该评估考虑了移动速度、方向和麦克风距离等因素。", "innovation": "本文开发并评估了一种基于声学排放的机器学习工作流程验证系统，能够通过四个不同的分类器（支持向量机(SVM)、深层神经网络(DNN)、循环神经网络(RNN)和卷积神经网络(CNN)）验证个体机器人动作的准确性超过80%，同时识别如拿放和包装等工作流也具有类似的高置信度。", "conclusion": "研究结果表明，在基线条件下，声学信号可以支持敏感的机器人环境中的实时、低成本、被动验证，无需进行硬件修改。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25947", "html_url": "https://arxiv.org/abs/2510.25947", "title": "重新审视语言模型预训练中的多语言数据混合", "title_en": "Revisiting Multilingual Data Mixtures in Language Model Pretraining", "authors": "Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut", "background": "关于大规模语言模型（LLMs）的预训练过程中，不同多语言数据混合的影响一直存在争议，这引发了关于语言覆盖率与模型性能之间潜在权衡的问题（即多语言的诅咒）。现有的研究和讨论往往暗示，多语言训练可能会牺牲某些语言的性能以换取其他语言的覆盖范围，尤其是在低资源的语言上表现不佳。", "innovation": "本研究通过在25到400种语言的多样化的多语言语料库上训练1.1B和3B参数的LLMs，挑战了有关多语言训练的常见信念。首先证明，将英语和多语言数据结合并不会降低双方的语言性能，前提是这些语言在预训练语料库中有足够的令牌数量。其次，发现使用英语作为枢纽语言能够为不同语言家族带来益处，并且选择特定家族中的枢纽语言并不总能为该家族内的其他语言带来一致性的性能提升。此外，研究还表明，大规模模型中训练语言数量的增加并不会导致‘多语言的诅咒’。这些发现表明，在适当平衡的前提下，多语言数据能够提高语言模型的能力，而不会在低资源设置中损害性能。", "conclusion": "研究结果表明，适当平衡的多语言数据可以增强语言模型的能力，而不会在低资源设置中损害其性能。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25954", "html_url": "https://arxiv.org/abs/2510.25954", "title": "应用和验证地理空间基础模型数据以预测卫生设施项目成果——马尔维 Sistema de caso", "title_en": "Application and Validation of Geospatial Foundation Model Data for the Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi", "authors": "Lynn Metz,Rachel Haggard,Michael Moszczynski,Samer Asbah,Chris Mwase,Patricia Khomani,Tyler Smith,Hannah Cooper,Annie Mwale,Arbaaz Muslim,Gautam Prasad,Mimi Sun,Tomer Shekel,Joydeep Paul,Anna Carter,Shravya Shetty,Dylan Green", "background": "在低收入和中等收入国家（LMICs），常规卫生数据的可靠性的限制因素包括报告延迟和不完全覆盖，这促使探索新型数据来源和分析方法。为此，研究人员评估了三种地理空间基础模型（GeoFM）嵌入源的预测性能，旨在模型15项常规卫生计划输出在马拉威，并将其与传统地理插值方法进行了比较。", "innovation": "该研究引入了GeoFM，这是一种通过合并多样化的空间、时间和行为数据生成数学嵌入，从而促进下游预测任务的方法。研究重点评估了Google人口动态基础模型（PDFM）、基于卫星图像的Google AlphaEarth和手机通讯记录（CDR）三种GeoFM嵌入源的预测性能。研究发现，GeoFM嵌入方法在15个指标中的13个（87%）中超越了基本的地理统计方法，表明GeoFM嵌入提高了选择健康和人口结果的预测精度。", "conclusion": "研究结果表明，在低收入和中等收入国家背景下，GeoFM嵌入为某些健康和人口指标提供了适度的预测改进。研究得出结论，集成多种GeoFM来源是一个高效且有价值的工具，用于补充并加强受限的常规卫生信息系统。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26007", "html_url": "https://arxiv.org/abs/2510.26007", "title": "寻求负责任的人工智能评估指标", "title_en": "The Quest for Reliable Metrics of Responsible AI", "authors": "Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Christina Lioma", "background": "人工智能（AI）及科学人工智能（AIS）的发展应当遵循负责任AI的原则。虽然评估负责任AI的进展可以通过评价指标来量化，但很少有工作关注这些指标自身的稳健性和可靠性。以往研究集中在评估推荐系统公平性指标的稳健性上，并总结了关键结论，据此制定了非详尽的指南，以开发可靠的责任制AI指标。该指南广泛适用于各种AI应用，包括科学人工智能。", "innovation": "本文总结了先前关于推荐系统公平性指标稳健性的研究，提炼关键要点，并提出了非详尽的指南以开发负责任的AI评价指标。这些指南不仅适用于推荐系统，还能应用于更广泛的AI应用场景。", "conclusion": "本文通过总结先前关于推荐系统公平性指标稳健性的研究，提出了开发可靠负责任AI评价指标的指南，这些指南广泛适用于各种AI应用情境。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25976", "html_url": "https://arxiv.org/abs/2510.25976", "title": "Brain-IT：通过脑互动转换器进行fMRI图像重建", "title_en": "Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer", "authors": "Roman Beliy,Amit Zalcher,Jonathan Kogman,Navve Wasserman,Michal Irani", "background": "通过功能性磁共振成像(fMRI)从人的大脑记录重建其看到的图像，提供了一种非侵入性的观察人类大脑的窗口。尽管通过扩散模型最近取得了进展，但当前方法往往缺乏对实际看到的图像的真实还原。", "innovation": "提出了“Brain-IT”，一种基于大脑的创新方法，通过脑交互变压器（BIT），它允许功能相似的大脑体素集群之间的有效互动。这些功能集群被所有受试者共享，作为在大脑内外整合信息的构建块。所有模型组件在所有集群与受试者之间共享，使得在有限的数据量下可以高效地训练。BIT预测两个互补的局部补丁级图像特征：一是高层次语义特征引导扩散模型向图像正确的语义内容靠拢；二是低层次结构特征帮助初始化扩散过程，使图像的大致布局正确。BIT的设计直接促进了从大脑体素集群到局部图像特征的信息流。", "conclusion": "通过这些原则，我们成功地从fMRI重建图像，这些图像忠实于所看到的图像，并在视觉上及标准客观度量中超越了当前最先进的方法。此外，仅使用新受试者的1小时fMRI数据，我们的方法在结果方面与使用整个40小时记录训练的方法保持了可比性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25992", "html_url": "https://arxiv.org/abs/2510.25992", "title": "监督强化学习：从专家路径到逐步推理", "title_en": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning", "authors": "Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee", "background": "大型语言模型（LLMs）在需要多步推理的问题上常常表现不佳。小型开源模型在使用验证奖励的强化学习（RLVR）时，即使经过多次尝试也难以采样到正确的解决方案。监督微调（SFT）则倾向于在通过逐个模仿令牌的形式过度拟合较长的示例时过拟合。为了解决这些问题，本研究提出了一种监督强化学习（SRL）框架，将问题求解重新定义为生成一系列逻辑「动作」的过程。SRL 训练模型在最终决定每个行动之前生成内部推理独白，这种方法提供基于与专家动作相似性的逐步奖励，即使所有卷积均失败也能提供更丰富的学习信号，从而鼓励被专家演示引导的灵活推理。因此，SRL 使小型模型能够学习之前通过 SFT 或 RLVR 无法解决的挑战性问题。", "innovation": "提出了一种名为监督强化学习（SRL）的框架，强化学习基于逻辑「动作」的顺序生成，生成内部推理独白，通过逐步奖励提供更丰富的学习信号，即使所有卷积均失败也能提供这种监督信号，从而鼓励被专家演示引导的灵活推理，使得小型语言模型能够解决之前的不可解决问题，而且在强化学习（RLVR）之前使用SRL初始化训练可达到最佳的整体性能，适用于推理定向语言模型的各种任务。", "conclusion": "SRL框架有助于小型语言模型解决多步推理问题，展示了在推理基准测试和代理软件工程任务中超越监督微调（SFT）和支持验证奖励的强化学习（RLVR）的表现，强调了SRL作为一种强大和通用训练框架的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26014", "html_url": "https://arxiv.org/abs/2510.26014", "title": "离散时间生存分析的双混合专家框架", "title_en": "Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis", "authors": "Hyeonjun Lee,Hyungseob Shin,Gunhee Nam,Hyeonsoo Lee", "background": "生存分析是一种用于建模感兴趣事件发生时间的任务，广泛应用于临床和生物医学研究。一个关键挑战是在建模患者异质性的同时，适应每个个体特征和时间动态的变化。当前的方法难以同时处理这一复杂性。因此，迫切需要一种灵活的框架来整合现有的深度学习方法，以改善生存分析中的风险预测，提高模型的预测准确性。", "innovation": "本文提出了一种双混合专家（dual mixture-of-experts, dual-MoE）框架用于离散时间生存分析。该框架结合了特征编码的MoE进行子组感知的表示学习，以及一个利用患者特征和时间嵌入捕捉时间动态的危险MoE。与现有方法相比，dual-MoE框架可以灵活地与其他深度学习生存分析管道集成，提升模型的预测能力，特别是在乳腺癌数据集METABRIC和GBSG中，提高了时间依赖性C指数达0.04，且在与Consurv框架结合时，表现进一步提升", "conclusion": "该研究提出的方法在METABRIC和GBSG乳腺癌数据集上一致性地提升了性能，显示了在生存分析中使用dual-MoE框架的有效性和优越性，强调了这种方法在提高风险预测准确性和处理患者异质性方面的重要性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26032", "html_url": "https://arxiv.org/abs/2510.26032", "title": "人工智能赋能的放射学报告分析：偶发性甲状腺发现的流行病学及其后果", "title_en": "Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings", "authors": "Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito", "background": "在进行非甲状腺相关检查时，甲状腺意外发现（ITF）的检测越来越普遍。但这些发现的频率、特征以及临床后果尚未明确。", "innovation": "开发、验证并部署了一个基于转换器的自然语言处理（NLP）管道，用于识别放射学报告中的ITF，并评估其频率、特征以及临床结果。", "conclusion": "ITF较为常见，并与发现小且低风险甲状腺癌的链条相关。这些发现突显了ITF在甲状腺癌过度诊断中的作用，强调了标准化报告和更有针对性随访的必要性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26018", "html_url": "https://arxiv.org/abs/2510.26018", "title": "RADRON：使用屈姆pton相机的MAV协同探测电离辐射源", "title_en": "RADRON: Cooperative Localization of Ionizing Radiation Sources by MAVs with Compton Cameras", "authors": "Petr Stibinger,Tomas Baca,Daniela Doubravova,Jan Rusnak,Jaroslav Solc,Jan Jakubek,Petr Stepan,Martin Saska", "background": "本文提出了利用协作微型空中车辆（MAVs）定位放射性物质的全新方法。该方法使用先进的单探测器屈姆pton相机作为高度敏感的小型辐射探测器。该探测器的极轻重量（40克）为微型空中车辆团队的高效合作提供了新的可能性。", "innovation": "提出了一种基于屈姆pton相机测量的新基本概念，以实时估计辐射源的位置，即使是来自极度稀疏测量的数据。数据读取和处理直接在车上进行，并将结果用于动态反馈以驱动车辆的运动。MAVs通过紧密协作以最大化通过屈姆pton相机获得的信息，快速定位辐射源，并且甚至可以跟踪移动的辐射源。", "conclusion": "MAVs在紧密协作下，通过屈姆pton相机最大化获取信息，快速定位甚至跟踪移动的辐射源。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26017", "html_url": "https://arxiv.org/abs/2510.26017", "title": "使用深度学习的气候适应性沿海城市洪水预测", "title_en": "Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep Learning", "authors": "Bilal Hassan,Areg Karapetyan,Aaron Chung Hin Chow,Samer Madanat", "background": "气候变化和海平面上升（SLR）对沿海城市构成了日益严重的威胁，迫切需要高效且准确的洪水灾害预测方法。传统的基于物理的水动力模拟器虽然精度高，但在城市规模的沿海规划应用中由于计算成本高昂而不切实际。深度学习（DL）技术提供了替代方案，但这些方法常常受到数据稀缺和高维输出要求的限制。", "innovation": "利用一个最近提出的低资源视觉导向的深度学习框架，我们开发了一种新的轻量级卷积神经网络（CNN）模型，用于预测在不同海平面上升（SLR）情景和海岸线适应场景下的沿海洪水。此外，我们展示了模型在两个不同地区的数据集上的泛化能力（阿布扎比和旧金山）。研究发现提出了一个显著优于现有方法的模型，平均减少了预测水深图的平均绝对误差（MAE）近20%。", "conclusion": "这些结果突显了我们方法在沿海洪水管理方面的潜在重要性，能够帮助决策者开发有效的缓解策略，应对气候变化带来的日益严重的影响。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26037", "html_url": "https://arxiv.org/abs/2510.26037", "title": "SIRAJ: 通过精简结构化推理实现LLM代理多样化和高效的红队测试", "title_en": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "authors": "Kaiwen Zhou,Ahmed Elgohary,A S M Iftekhar,Amin Saied", "background": "大型语言模型（LLM）代理能够计划和调用工具的能力为它们带来了新的安全风险，因此需要一个全面的红队系统来发现漏洞并确保它们的安全部署。", "innovation": "我们提出了SIRAJ：一种通用的红队框架，用于任意的黑盒LLM代理。我们采用了一种动态的两步过程：首先定义代理，生成包含各种风险结果、工具使用路径和风险源的多样化种子测试案例；然后，根据先前尝试的执行路径迭代构建并细化基于模型的对手攻击。我们还提出了一种模型精简方法，利用教师模型推理的结构化形式来训练同样有效的小型模型。", "conclusion": "我们的种子测试案例生成方法在不同的评估代理设置中提高了风险结果和工具调用路径覆盖范围2-2.5倍。我们精简得到的8B红队模型的攻击成功率增加了100%，超过了671B的Deepseek-R1模型。我们的消融分析和实证研究验证了迭代框架、结构化推理的有效性以及我们的红队模型的泛化能力。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26020", "html_url": "https://arxiv.org/abs/2510.26020", "title": "PORTool：带有奖励树的工具使用大语言模型训练", "title_en": "PORTool: Tool-Use LLM Training with Rewarded Tree", "authors": "Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao", "background": "当前工具使用的大语言模型（LLMs）被训练在静态数据集上，允许它们与外部工具交互并进行多步工具集成推理，生成工具调用轨迹。然而，这些模型在解决查询时模仿通用的工具调用流程，导致它们难以探索多种解决方案并表现出在动态工具调用环境中有限的性能。这项工作旨在研究如何使工具使用大语言模型探索多种生成正确答案的调用路径。", "innovation": "本文提出了PORTool，一种强化学习方法，鼓励工具使用大语言模型探索多种路径以生成正确答案。该方法首先生成多个给定查询的迭代，其中一些共享最初的调用步骤，形成树状结构。接下来，根据步骤生成正确答案和成功调用工具的能力对其分配奖励。相同步骤在不同轨迹中获得相同的奖励，而同一分叉下的不同步骤获得不同的奖励。最后，通过计算分叉相对优势和轨迹相对优势的结合来训练大语言模型进行工具使用。", "conclusion": "实验使用17种工具处理用户查询，涵盖时间敏感和非时间敏感主题。我们进行了消融研究，系统地证明了步骤奖励的必要性及其设计的鲁棒性。此外，我们将提出的PORTool与其他训练方法进行了对比，并展示了在最终准确性和工具调用步骤数量方面的显著改进。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26004", "html_url": "https://arxiv.org/abs/2510.26004", "title": "DARTS:基于无人机的人工智能加持下的实时交通事故检测系统", "title_en": "DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System", "authors": "Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang", "background": "快速和可靠的事故检测对于降低与交通事故相关的死亡、伤害和拥堵至关重要。然而，传统的检测方法，如闭路电视、驾驶记录仪视频和基于传感器的检测，存在检测与验证分离的问题，灵活性有限，且需要密集的基础设施或高渗透率，限制了适应性及扩展性。特别是在事故热点不断变化的情况下，这些传统方法的表现受到了极大限制。为了克服这些挑战，研究开发了DARTS，这是一种基于无人机、人工智能驱动的实时交通事故检测系统。DARTS将无人机的高度机动性和空中视角用于适应性监控，采用热成像技术以提高在低能见度条件下的表现并保护隐私，同时利用轻量级深度学习框架提取实时车辆轨迹并进行事故检测。该系统在自集数据集上的检测准确率达到99%，并支持通过基于Web的界面进行同时在线的视觉验证、事故严重程度评估以及事故引发的交通拥堵扩散监测。在佛罗里达州的1-75高速公路实地测试中，DARTS比当地的交通运输管理中心提前12分钟检测并验证了一起追尾事故，同时监控了事故引发的交通拥堵扩散，这表明了其支持更快应急响应和主动交通控制以减少拥堵和次生事故风险的潜力。重要的是，DARTS灵活的部署架构减少了频繁物理巡逻的依赖，展示了其在偏远地区及资源受限环境中灵活性和成本效益方面的潜力。这一研究向更灵活和集成的实时交通事故检测系统迈出了重要一步，对于现代交通管理的操作效率和响应能力具有重要意义。", "innovation": "DARTS是一种基于无人机、人工智能驱动的实时交通事故检测系统。它将无人机的高度机动性和空中视角用于适应性监控，利用热成像技术提高低能见度下的表现并保护隐私，且具有轻量级深度学习框架，实现实时车辆轨迹提取和事故检测。该系统在自集数据集上的检测准确率达到99%，并支持在线验证、严重程度评估及事故导致的交通拥堵扩散监测。研究还在佛罗里达州的1-75高速公路进行了实地测试，结果表明DARTS具有支持更快应急响应和主动交通控制的潜力。该项目还展示了其在偏远地区及资源受限环境中灵活性和成本效益方面的潜力。", "conclusion": "DARTS的发展代表了更灵活和集成的实时交通事故检测系统的潜在前景，对于现代交通管理效率和响应能力具有重要意义。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26024", "html_url": "https://arxiv.org/abs/2510.26024", "title": "重思跨语言对齐：平衡多语言LLM中的转移与文化抹除", "title_en": "Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs", "authors": "HyoJung Han,Sweta Agrawal,Eleftheria Briakou", "background": "跨语言对齐（CLA）旨在对齐多语言表示，使大型语言模型（LLMs）能够无缝地跨语言转移知识。然而，这一追求表象的一致性可能会无意中导致'文化抹除'，即在查询语言的基础上提供具有文化依存性的响应的功能损失，这些响应应该根据查询语言而不同。本文通过引入一个整体评估框架，叫做转移-本地化平面，系统分析了这一权衡，在该框架下，量化了期望的知识转移和不期望的文化抹除。研究发现，最近的CLA方法在所有研究的六种语言中都一致提高了事实知识的传递，但是代价是文化本地化的损失。", "innovation": "本文提出了Surgical Steering，一种新颖的推理时方法，它通过在特定层上应用针对性的激活引导，有效地解耦事实知识的可传递性和文化特定的知识。该方法能够更好地在竞争的两个维度之间取得平衡，从而克服当前对齐技术的局限性。", "conclusion": "研究揭示了一个关键洞察：普遍的事实传递和文化特定的知识在不同的模型层中达到最佳操控。基于此发现，作者提出了一种新的推理时方法，Surgical Steering，它能够同时优化这些相互竞争的目标，提高了多语言LLMs的知识传递和文化本地化之间的平衡。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识蒸馏（KD）是一种有效的模型压缩方法，可以将知识从一个模型（教师模型）转移到另一个模型（学生模型），但其对模型在面对分布外数据时的鲁棒性（尤其是对抗假相关性）的影响仍需进一步探索。因此，这项研究探讨了知识蒸馏对学生模型的去偏性能力的影响，特别是在自然语言推理和图像分类任务中从教师模型传递去偏性能力的情况。这项研究通过对大量实验的结果分析，揭示了几个关键发现：", "innovation": "研究发现，整体来看，知识蒸馏后模型的去偏性能力被削弱；训练去偏模型并不会从中受益；尽管整体稳健性可能在知识蒸馏后保持稳定，不同类型的偏见可能会出现显著变化；还指出了导致蒸馏后不同行为的内部注意力模式和电路。基于以上发现，提出了三种有效的方法来提高去偏性方法的蒸馏能力：开发高质量的数据增强，实施迭代知识蒸馏，以及用教师模型的权重初始化学生模型。这是首次大规模研究KD对去偏性的影响及其内部机制的文章，研究成果有助于理解KD的工作原理和如何设计更好的去偏性方法。", "conclusion": "我们的研究结果提供了关于KD如何运作的见解，并为设计更好的去偏性方法提供了理解。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26061", "html_url": "https://arxiv.org/abs/2510.26061", "title": "数据驱动的投影生成以高效解决异构二次规划问题", "title_en": "Data-driven Projection Generation for Efficiently Solving Heterogeneous Quadratic Programming Problems", "authors": "Tomoharu Iwata,Futoshi Futami", "background": "二次规划（QP）问题是广泛应用于优化领域的核心问题。在高维QP中，变量的数量非常多，导致求解变得非常困难和耗时。为了提高求解效率，该文通过减少变量的数量，提出了一种数据驱动的框架来有效求解QP问题。利用基于图神经网络的模型，该框架能够为每个特定的QP实例生成定制化的投影，从而能够在减少变量数量的同时，仍然能够提供高质量的解决方案，甚至对于之前未见过的问题也能产生高质量解决方案。", "innovation": "该论文创新性地提出了一种数据驱动的框架，通过减少变量的数量来有效求解高维QP问题。该框架利用基于图神经网络的模型生成定制化的投影，不仅可以适用于未见过的问题，还能够有效地减少计算时间和提高解决方案的质量。此框架通过一种BI-level优化方案学习参数，其中内部优化通过QP求解器基于给定的投影求解QP，外部优化更新模型参数。此外，论文还提供了一种高效的算法来解决这种BI-level优化问题，并且对神经网络生成的投影矩阵解决QP的泛化能力进行了理论分析。", "conclusion": "实验结果表明，该方法能够在减少计算时间的同时提供高质量的可行解，超过了现有的方法。该框架通过定制化的投影减少了高维QP问题的难度，同时降低了求解的时间和计算成本。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26113", "html_url": "https://arxiv.org/abs/2510.26113", "title": "EgoExo-Con: 探索视角不变的视频时间理解", "title_en": "EgoExo-Con: Exploring View-Invariant Video Temporal Understanding", "authors": "Minjoon Jung,Junbin Xiao,Junghyun Kim,Byoung-Tak Zhang,Angela Yao", "background": "研究视频预训练语言模型（Video-LLMs）在不同视角拍摄相同事件时的一致时间理解能力。文章指出，现有的Video-LLMs存在两个关键限制，即在不同视角间未能维持一致性，以及当使用同步多视角数据进行微调时，性能反而降低。这提示现有模型需要在保持多视角一致性理解方面有所改进.", "innovation": "提出了EgoExo-Con（一致一致性），这是一个包含全面同步自观和旁观视频对的基准集，并通过自然语言精炼的人类查询评估模型。还提出了View-GRPO，这是一种新的强化学习框架，旨在增强特定视角的时间推理能力，并促进多视角间的一致理解，研究成果表明该方法优于简单的微调和强化学习.", "conclusion": "研究成果证实了View-GRPO框架在跨视角一致性上优于简单微调和强化学习，公开了所有资源，以便进一步研究."}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26099", "html_url": "https://arxiv.org/abs/2510.26099", "title": "SAFE：通过地球面上分层评估预测构建新型AI天气评价方法", "title_en": "SAFE: A Novel Approach to AI Weather Evaluation through Stratified Assessments of Forecasts over Earth", "authors": "Nick Masi,Randall Balestriero", "background": "目前机器学习模型评估主要基于测试集样本的整体损失平均值，这在地球上的天气和气候场景中意味着地理空间上的平均性能，没有考虑到人类发展和地理的非均匀分布。这种方法未能充分反映不同地区和地理区域的真实差异和复杂性。", "innovation": "提出了SAFE（Stratified Assessments of Forecasts over Earth，地球上的分层预测评估）包，这是一种用于阐明地球上的预测集在不同属性层面的分层性能的方法。SAFE整合多种数据域，通过国家、全球亚区域、收入和地被（土地或水域）等多种属性对网格点进行分层，从而详细评估模型在各个分层上的表现（例如，每个独立国家的预测准确性）。该方法基于不同提前时间对多种气候变量进行分层基准测试，以评估模型预报公平性。", "conclusion": "通过SAFE，研究重新定义了模型全球平均水平性能的评估方式，探讨了不同模型在不同属性分层上的表现优劣，识别出模型预报公平性的问题。SAFE是开源软件，可以根据需要支持进一步的研究工作。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26083", "html_url": "https://arxiv.org/abs/2510.26083", "title": "Nirvana：拥有任务感知记忆机制的专业全才模型", "title_en": "Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism", "authors": "Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou", "background": "传统的大型语言模型（LLM）结构，如Transformer、线性注意力和混合模型，并没有采用受任务信息引导的专门记忆机制。专业全才模型（Specialized Generalist Models，SGMs）旨在保持广泛的技能同时在目标领域达到专家水平的表现。本文的研究背景是探索如何在保留广泛能力的同时，通过引入任务感知记忆机制来提升专业技能的表现。", "innovation": "本文提出了Nirvana模型，这种模型具有专门的记忆机制、线性时间复杂性以及在测试时提取任务信息的能力。文中提出了一种名为$Trigger$的任务感知记忆触发机制，该机制能够根据任务需求灵活调整记忆机制。此外，该模型设计了一个称为$Updater$的专门记忆更新器，能够根据$Trigger$动态地记忆上下文信息。这些设计使Nirvana能够在任务变化时适配新领域的参数，从而提升在不同任务上的表现。", "conclusion": "Nirvana在各种自然语言建模基准测试中表现出与现有LLM结构相竞争或更优的结果。通过在冻结的Nirvana主干上训练轻量级编码器来应对MRI医学任务，$Trigger$机制仍能够指导模型适应MRI领域。Nirvana在MRI重建质量上超过传统的MRI模型和使用传统LLM主干的模型，并能生成准确的初步临床报告。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26105", "html_url": "https://arxiv.org/abs/2510.26105", "title": "文本与图像之间多模态模型对齐的安全风险", "title_en": "Security Risk of Misalignment between Text and Image in Multi-modal Model", "authors": "Xiaosen Wang,Zhijin Ge,Shaokang Wang", "background": "尽管多模态扩散模型（如图文模型）在技术上取得了显著的进步和多用途性，但它们对对抗输入的脆弱性尚未受到充分研究。现有扩散模型中图文之间的对齐不足导致了严重的安全风险，尤其是在生成不适当或不适合工作的内容时。尽管如此，这些模型在通过固定提示进行图像编辑等应用场景中仍面临新的威胁挑战。", "innovation": "提出了一种名为Prompt-Restricted Multi-modal Attack (PReMA)的新攻击，通过修改输入图像而无须更改提示本身来操控生成的内容。这是第一个仅通过创建对抗图像来操纵模型输出的攻击方法，不同于之前的生成对抗提示以产生不适当内容的攻击方法。因此，PReMA对于保护多模态扩散模型的整体完整性具有重要意义，特别是在图像编辑中使用固定提示的应用场景下。", "conclusion": "在各种模型上的图像修复和风格转移任务上的综合评估表明，PReMA具有强大的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26089", "html_url": "https://arxiv.org/abs/2510.26089", "title": "基于网络约束的自适应多agent车辆路由策略优化", "title_en": "Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle Routing", "authors": "Fazel Arasteh,Arian Haghparast,Manos Papagelis", "background": "城市道路网络中的交通拥堵导致旅行时间延长和排放增加，尤其是在高峰时段。尽管最短路径优先（SPF）算法对于静态网络中的单个车辆是优化的，但在动态、多车辆设置中表现较差，往往会通过将所有车辆沿相同的路径进行路由进一步加剧拥堵。", "innovation": "本文提出了一种基于多智能体强化学习（MARL）框架的自适应导航（AN）模型，通过分散式的策略提供基于局部交通状况和邻域状态的路径引导（使用图注意网络GAT建模）。进一步地，提出了一种基于层级枢纽的自适应导航（HHAN）模型，只分配关键交汇点（枢纽）的代理，车辆在枢纽间路由并在每个枢纽区域内进行微线性路径优化，采用集中训练与分散执行（CTDE）的方式下使用注意力混合结构（A-QMIX）来协调枢纽间的决策，基于流量感知的状态特征进行预防性路径优化。", "conclusion": "通过实验证明，AN在合成网格和实际城市地图（多伦多、曼哈顿）上相较于SPF和学习基准模型能够减少平均旅行时间，保存100%的路径成功量。HHAN对于包含数百个交汇点的大型网络具有扩展性，当交通流量较大时，能达到15.9%的性能提升。这些发现强调了针对智能交通系统的可扩展、协调和拥堵感知路由中网络限制的MARL方法的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26151", "html_url": "https://arxiv.org/abs/2510.26151", "title": "MV-MLM: 将多视角乳腺X线成像与语言结合用于乳腺癌诊断和风险预测", "title_en": "MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction", "authors": "Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba", "background": "高质量且详细标注的数据集对于训练乳腺癌检测或风险预测的计算机辅助诊断(CAD)模型至关重要。然而，获取这样的数据集既耗时又昂贵。视觉语言模型（VLMs），如CLIP，这些模型在大规模图像-文本配对上进行了预训练，为医疗成像任务提供了增强鲁棒性和数据效率的潜在解决方案。", "innovation": "提出了一种新的多视角乳腺X线成像和语言模型（MV-MLM），该模型基于配对的乳腺X线图像和合成放射学报告进行训练。MV-MLM通过跨模态自监督从广泛的放射学数据中学习丰富的表示，利用多视角监督策略，并结合提出了联合视觉-文本学习策略，以增强不同数据类型和任务的泛化能力及准确性。此外，该模型在两种私有数据集和两种公开数据集上得到了评估，表明在恶性肿瘤分类、亚型分类和基于图像的癌症风险预测三个分类任务上达到了最先进的性能，且表现出强大的数据效率。", "conclusion": "提出的MV-MLM模型在多个乳腺癌相关分类任务上展示了优越的表现和较强的数据效率，无需实际放射学报告即可超越现有的完全监督或视觉语言模型基线。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26068", "html_url": "https://arxiv.org/abs/2510.26068", "title": "学习几何：基于度量优化构建自适应流形模型的框架", "title_en": "Learning Geometry: A Framework for Building Adaptive Manifold Models through Metric Optimization", "authors": "Di Zhang", "background": "当前的机器学习方法主要集中在参数优化上，然而这些方法通常在固定的几何空间内搜索最优参数。与这些传统方法不同，本文提出了一种新的机器学习范式，核心思想是将模型本身视为可以塑造的几何实体。本文通过优化具有预定义拓扑结构的流形上的度量张量场，动态地塑造模型空间的几何结构。这种方法的挑战在于无限维度的优化问题，为此，本文引入了一种基于离散微分几何的实用方法来解决这一问题，具体是通过将连续流形离散化为三角网格，并用边长参数化度量张量，从而实现高效的优化。该方法结合自动微分工具具有较高的计算效率。理论分析表明，本文框架与广义相对论中的爱因斯坦-希尔伯特作用量之间存在深刻的类比，为“数据驱动几何”这一概念提供了优雅的物理解释。这种方法还显示，即使在固定的拓扑结构下，度量优化模型相比固定几何结构模型具有显著更大的表达能力。", "innovation": "本文提出的范式将模型视为可塑造的几何实体，而不是在固定的几何空间内搜索最优参数。通过优化具有预定义拓扑结构的流形上的度量张量场来动态塑造模型空间的几何结构。这一方法通过结合自动微分工具，有效地解决了无限维度优化问题。理论分析进一步揭示了该方法与广义相对论中的爱因斯坦-希尔伯特作用量之间的类比关系。此外，即使在固定的拓扑结构下，度量优化模型相比固定几何结构模型具有显著更大的表达能力。这种方法为构建能够自主演化其几何结构和拓扑结构的“元学习器”奠定了基础，并有望在科学模型发现和鲁棒表示学习等领域找到广泛的应用前景。", "conclusion": "本文提出了一种新的机器学习范式，通过度量优化构建自适应流形模型。该方法通过优化具有预定义拓扑结构的流形上的度量张量场，实现模型空间几何结构的动态塑造。同时，该方法结合离散微分几何和自动微分工具有效解决了无限维度的优化问题，并展示出固定拓扑结构下度量优化模型的显著表达能力。该工作为构建能够自主演化其几何结构和拓扑结构的“元学习器”奠定了基础，为科学模型发现和鲁棒表示学习等领域提供了新的机遇。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26130", "html_url": "https://arxiv.org/abs/2510.26130", "title": "超越合成基准测试：评估大模型在真实世界类级代码生成中的表现", "title_en": "Beyond Synthetic Benchmarks: Evaluating LLM Performance on Real-World Class-Level Code Generation", "authors": "Musfiqur Rahman,SayedHassan Khatoonabadi,Emad Shihab", "background": "大语言模型（LLMs）在功能级别上已经显著推进了代码生成，但它们在真实软件项目中生成正确类级实现的能力仍不太受理解。这项研究引入了一个基于开源存储库的新基准，将真实世界的类划分为已见和未见部分，以在实际条件下评估泛化能力。评估包括在多种输入规格、检索增强配置和文档完整性水平下测试多个大模型。", "innovation": "该研究提出了一个新颖的基准，基于开源软件存储库中的真实类，将其分为已见和未见部分，以评估大模型在实际条件下的泛化能力。研究发现，在真实世界类任务中，大模型的正确性有很大差距，从25%到34%，远低于在现成合成基准上的正确性（84%到89%）。研究表明，文档完整性在一定程度上有助于提升功能准确性，尽管统计显著性不多见。检索增强生成在部分文档中最为有效，通过提供规格中缺失的具体实现模式，提升了4%到7%的正确性。", "conclusion": "这项基准和分析揭示了当前大语言模型在类级别工程方面的关键限制，提供了有关增强上下文建模、文档策略和检索集成的具体见解，这对于生产代码辅助工具的发展具有重要意义。研究表明，尽管大模型在合成基准测试中表现良好，但在真实世界的类实现任务中表现较差，这表明需要改进模型以更好地处理大型软件项目的实际需求。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26125", "html_url": "https://arxiv.org/abs/2510.26125", "title": "WOD-E2E：Waymo开放数据集在挑战性长尾场景中的端到端驾驶", "title_en": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios", "authors": "Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Kate Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Drago Anguelov", "background": "基于视觉的端到端（E2E）驾驶在研究界引起了广泛关注，因为它具有可扩展性和与多模态大型语言模型（MLLMs）的协同效应。然而，当前的E2E驾驶基准主要包含标准场景，未能充分测试这些系统的真正潜力。此外，现有的开环评估标准往往无法捕捉驾驶的多模态特性或有效评估在长尾场景中的表现。鉴于此，我们介绍了Waymo开放数据集（WOD-E2E），以填补这些空白，提供了4021个驾驶段（大约12小时），特地用于稀有且日常生活中频率低于0.03%的挑战性长尾场景。每个段落包含了高阶路由信息、自车状态以及来自8个周围摄像头的360度视频。", "innovation": "本文提出了WOD-E2E数据集，特别为处理罕见的长尾场景，具有针对性地捕捉多模态的驾驶特性。提出了新的评分标准Rater Feedback Score (RFS)，不同于传统的基于预测路径与日志之间距离的度量，RFS通过评估预测轨迹是否与标注专家偏好标签的接近程度来衡量E2E驾驶性能。此外，数据集和新的评估标准将用于2025年的WOD-E2E挑战赛，以促进通用性强、鲁棒性和安全的E2E自主驾驶代理的研究，使其能够应对复杂的现实世界情况。", "conclusion": "通过我们的工作，我们希望推进关于通用、稳健和安全的端到端无人驾驶代理的研究，这些代理能够处理复杂的现实世界情况。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26157", "html_url": "https://arxiv.org/abs/2510.26157", "title": "通过子结构感知对齐弥合分子与文本描述之间的差距", "title_en": "Bridging the Gap Between Molecule and Textual Descriptions via Substructure-aware Alignment", "authors": "Hyuntae Park,Yeachan Kim,SangKeun Lee", "background": "分子和文本表示学习由于其增强化学信息理解的潜力而逐渐受到关注。然而，现有的模型在捕捉分子及其描述之间的微妙差异方面常常力不从心，主要是因为它们无法学习分子子结构与化学短语之间精细的对齐。", "innovation": "我们提出了一种名为MolBridge的新颖分子-文本学习框架，它基于子结构感知对齐。具体来说，MolBridge通过从分子子结构和化学短语中获得的附加对齐信号来增强最初的分子-描述配对。MolBridge通过子结构感知对比学习并结合自我改进机制来有效学习这些丰富化的对齐。", "conclusion": "实验结果显示，MolBridge能够捕捉到精细对应关系，并在一系列分子基准测试中优于最先进的基线方法，突显了子结构感知对齐在分子-文本学习中的重要性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26159", "html_url": "https://arxiv.org/abs/2510.26159", "title": "工业时间序列中集成与混合方法的分割主导复杂性：异常检测评估", "title_en": "Segmentation over Complexity: Evaluating Ensemble and Hybrid Approaches for Anomaly Detection in Industrial Time Series", "authors": "Emilio Mastriani,Alessandro Costa,Federico Incardona,Kevin Munari,Sebastiano Spinello", "background": "本文研究了高级特征工程和混合模型架构在多变量工业时间序列异常检测中的效果，特别是在汽轮机系统中。研究重点评估了基于变化点的统计特征、基于聚类的子结构表示以及混合学习策略对检测性能的影响。", "innovation": "研究对复杂的高级方法进行了评估，发现这些复杂方法在处理高度不平衡和时间不确定性数据时的表现不如一个简化的随机森林 + XGBoost集成模型，后者通过对分割数据的训练获得了较高的AUC-ROC、F1分数和100%的早期检测率。这一结果强调了，在数据不平衡和时间不确定性较高的情况下，简单模型结合优化分割可以优于更复杂的架构，提供更高的稳健性、可解释性和操作实用性。", "conclusion": "研究结论强调，在数据不平衡和时间不确定性较高的场景中，简单模型结合优化分割可以优于更复杂的架构，提供更高的稳健性、可解释性和操作实用性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26165", "html_url": "https://arxiv.org/abs/2510.26165", "title": "超越简单效用函数学习管理投资组合", "title_en": "Learning to Manage Investment Portfolios beyond Simple Utility Functions", "authors": "Maarten P. Scholl,Mahmoud Mahfouz,Anisoara Calinescu,J. Doyne Farmer", "background": "尽管投资基金通常会以宽泛的形式披露其目标，但其管理者会优化多种复杂竞争性的目标，而不仅仅是简单的风险-收益权衡。传统的方法是通过多目标效用函数来建模这种策略，但这些方法在定义和参数化方面还有很多根本性挑战。已有研究主要采用强化学习或模仿学习的方法，这些方法需要明确设定奖励或标注专家目标，但在灵活性和数据利用方面存在局限。", "innovation": "本文提出了一种生成性框架，无需显式指定效用函数即可学习基金经理策略的潜在表示。该方法直接建模在给定股票特征、历史收益、先前权重和策略的潜在变量下投资组合权重的条件概率。与基于强化学习或模仿学习的方法不同，我们的基于生成对抗网络的架构直接从观测持有和市场数据的联合分布中学习，无需明确设定奖励或标注专家目标。我们在一个包含1436只美国股票共同基金的数据集上验证了该框架，发现所学表示成功捕捉了一些已知的投资风格，同时揭示了一些隐含的管理者目标。", "conclusion": "本文提出的框架提供了一种基于数据驱动的方法来刻画投资策略，应用于市场模拟、策略归因以及监管审查。我们还开发了一系列测试来解释模型，并展示了基准的专家标签以线性可解释的方式包含在我们的模型编码中。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26172", "html_url": "https://arxiv.org/abs/2510.26172", "title": "使用协调代理流连接异构数据进行社交媒体分析", "title_en": "Linking Heterogeneous Data with Coordinated Agent Flows for Social Media Analysis", "authors": "Shifu Chen,Dazhen Deng,Zhihong Xu,Sijia Xu,Tai-Quan Peng,Yingcai Wu", "background": "社交媒体平台生成大量异构数据，涵盖了用户行为、文本内容、时间动态和网络结构。分析这些数据对于理解意见动态、社区形成和信息传播等现象至关重要。然而，从中发现洞察是探索性的、概念性挑战性的，并需要在社交媒体挖掘和可视化方面的专业知识。尽管现有的自动化方法越来越多地利用大型语言模型，但它们主要局限于结构化的表格数据，未能充分应对社交媒体分析的异质性挑战。", "innovation": "介绍了SIA（Social Insight Agents）系统，它通过协调的代理流链接了异构多模态数据，包括原始输入（如文本、网络和行为数据）、中间输出、挖掘出的分析结果和可视化制品。它通过底层分类法将洞察类型与合适的挖掘和可视化技术联系起来，使代理能够规划并执行连贯的分析策略。SIA还集成了数据协调器，将结构化、文本和网络数据统一为一致的流程。其交互界面为用户提供透明的工作流程，使用户可以跟踪、验证和细化代理的推理过程，支持可适应性和信誉。", "conclusion": "通过以专家为中心的案例研究和定量评估，我们展示了SIA能够有效从社交媒体中发现多样且有意义的洞察，同时支持人类与代理之间的协作，在复杂的分析任务中发挥重要作用。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26186", "html_url": "https://arxiv.org/abs/2510.26186", "title": "ConceptScope: 通过解耦视觉概念表征数据集偏差", "title_en": "ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts", "authors": "Jinho Choi,Hyesu Lim,Steffen Schneider,Jaegul Choo", "background": "机器学习数据集中的数据点往往会偏向某些概念，导致数据集偏差普遍存在。然而，系统地识别这些偏差需要昂贵且细致的属性注释，具有挑战性。作者提出将视觉数据集拆分为可解释的概念，以稀疏自编码器来发现和量化这些概念，从而系统地识别和评估数据集的偏差。", "innovation": "该研究提出了一个名为ConceptScope的可扩展且自动化的框架，通过基于视觉基础模型表示的稀疏自编码器发现并量化人类可解释的概念，对不同概念进行语义相关性和统计相关性分类，从而能够通过概念基础子组进行分类级别数据集表征、偏差识别和鲁棒性评估。", "conclusion": "通过与注释数据集的比较，ConceptScope能够捕捉到包括物体、纹理、背景、面部特征、情绪和行动等一系列视觉概念。同时，概念激活展示了与语义相关图像区域的空间归因，可靠地检测已知偏差（如Waterbirds中的背景偏差），并发现未标注偏差（如ImageNet中的共现对象偏差），有效质控数据集并用于模型诊断。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26202", "html_url": "https://arxiv.org/abs/2510.26202", "title": "在我的人类反馈中有什么？学习可解释的偏好数据描述", "title_en": "What's In My Human Feedback? Learning Interpretable Descriptions of Preference Data", "authors": "Rajiv Movva,Smitha Milli,Sewon Min,Emma Pierson", "background": "人类反馈可以以不可预测和不期望的方式改变语言模型，这主要是因为从业者对反馈数据的编码理解不清。尽管先前的工作研究了某些属性的偏好（例如长度或奉承），但在无需预设假设的情况下自动提取相关特征仍然具有挑战性。", "innovation": "本文引入了WIMHF（What's In My Human Feedback？）方法，使用稀疏自编码器来解释反馈数据。WIMHF不仅可以描述数据集能够测量的偏好，还可以描述标注者实际表达的偏好。此外，WIMHF还揭示了有害的偏好，并允许精细化个人定制。", "conclusion": "WIMHF为从业者提供了一种基于人类的分析方法，以便更好地理解和使用偏好数据。通过重新标记有害实例，WIMHF在保证总体性能不变的情况下，带来了安全性的显著提升。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26188", "html_url": "https://arxiv.org/abs/2510.26188", "title": "从住院患者医疗索赔数据预测所有原因再入院", "title_en": "Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients", "authors": "Avinash Kadimisetty,Arun Rajagopalan,Vijendra SK", "background": "减少可预防的医院再入院是支付者、医疗服务提供者和政策制定者提高医疗质量和降低成本的国家优先事项。再入院率被用作衡量医院提供医疗服务质量的标准。该项目使用了逻辑回归、随机森林和支持向量机等机器学习技术，对健康索赔数据进行分析，以识别对预测所有原因再入院起关键作用的人口统计和医疗因素。由于健康索赔数据的高度维度性，使用主成分分析进行了降维处理，进而构建了回归模型。根据曲线下面积（AUC）指标对这些模型进行了比较和评估。随机森林模型性能最佳，其次是逻辑回归和支持向量机模型。这些模型可以用于识别导致再入院的关键因素，有助于识别需要重点关注的患者，从而降低再入院的可能性，最终降低成本，提高患者医疗服务的质量", "innovation": "该项目创新地将机器学习技术应用于预测再入院的研究，通过使用逻辑回归、随机森林和支持向量机等方法，克服了高维健康索赔数据的处理难题，使用主成分分析进行降维处理，并比较了不同的机器学习模型性能，提供了有效识别再入院关键因素的方法", "conclusion": "通过使用机器学习模型分析健康索赔数据，识别对预测所有原因再入院起关键作用的因素，可以有效降低再入院率，减少医疗成本，提高患者医疗服务的质量"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26185", "html_url": "https://arxiv.org/abs/2510.26185", "title": "Accumulative SGD 影响估计用于数据标注", "title_en": "Accumulative SGD Influence Estimation for Data Attribution", "authors": "Yunxiao Shi,Shuo Yang,Yixin Su,Rui Zhang,Min Xu", "background": "现代以数据为中心的AI需要精确的单样本影响度量。标准的SGD-IE通过汇总每个epoch的替代效果来近似留一出效应，并忽略了epoch间累积影响的交叉效应，这会导致关键样本的错误排序。已有研究指出，传统的方法在评估单样本影响时存在系统性的误差，这些误差影响了模型的泛化能力。因此，对于数据清洗、模型解释以及提高模型性能等方面的应用提出了改进的影响估计方法的需求。", "innovation": "本文提出了一个称为ACC-SGD-IE（累计SGD影响估计）的方法，它通过跨训练轨迹传播留一出扰动，并在每次训练步骤中更新累计影响状态。在光滑强凸环境下，ACC-SGD-IE实现了几何误差收缩；在光滑非凸环境下，它能更紧地界定误差，并且批量大小越大，常量越小。实验证明，与SGD-IE相比，ACC-SGD-IE在Adult、20 Newsgroups和MNIST数据集上的干净和污染数据以及凸性和非凸训练条件下提供了更准确的影响估计，尤其是对于长时间训练时更为显著。这使得在数据清洗应用中，使用ACC-SGD-IE清洗后的模型表现优于使用SGD-IE清洗后的模型，能够在检测噪声样本方面提供更高的可靠性。", "conclusion": "ACC-SGD-IE方法通过跨epoch和优化步骤传播影响估计，提高了单样本影响度量的准确性和可靠性，特别是在长训练周期下的性能提升更为显著。这为数据清洗、提升模型性能以及模型解释提供了有效的工具。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26205", "html_url": "https://arxiv.org/abs/2510.26205", "title": "迈向全局检索增强生成：面向语料库级推理的基准", "title_en": "Towards Global Retrieval Augmented Generation: A Benchmark for Corpus-Level Reasoning", "authors": "Qi Luo,Xiaonan Li,Tingshuo Fan,Xinchi Chen,Xipeng Qiu", "background": "当前的检索增强生成（RAG）评估基准主要关注局部RAG，即从一小部分文档中检索相关片段以回答仅需局部理解的问题。然而，许多实际应用需要全局RAG能力，即在整个文档集合中聚合和分析信息，以推导出语料库级别的洞察。当前没有专门的基准来评估这种能力。", "innovation": "本文引入了GlobalQA，这是一个专门用于评估全局RAG能力的第一个基准，涵盖计数、极值查询、排序和top-k提取四种核心任务类型。通过在不同模型和基线下进行系统评估，发现现有的RAG方法在全局任务上表现较差，最强基线仅达到1.51的F1分数。为解决这些挑战，提出了一种名为GlobalRAG的多工具协作框架，通过片段级检索保持结构连贯性，整合LLM驱动的智能筛选消除噪声文档，并集成聚合模块进行精确的符号计算。在Qwen2.5-14B模型上，GlobalRAG实现了6.63的F1分数，比最强基线的1.51有显著提高。", "conclusion": "现有RAG方法在全局任务上表现不佳，而GlobalRAG通过创新的框架设计显著提升了性能。GlobalQA填补了现有评估方法的空白，为评估和改进RAG的全局能力提供了新的基准。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26217", "html_url": "https://arxiv.org/abs/2510.26217", "title": "使用混合LLM和高阶量子近似优化法进行CSA保证金管理", "title_en": "Hybrid LLM and Higher-Order Quantum Approximate Optimization for CSA Collateral Management", "authors": "Tao Jin,Stuart Florescu,Heyu(Andrew)Jin", "background": "我们关注ISDA信用支持附录（CSA）下的金融本源担保优化问题，其中包括整数批量、计划A折扣、RA/MTA制约因素和发行人/货币/类别上限，这些因素共同形成了一个复杂且法律法规界定的搜索空间。", "innovation": "研究引入了一种特定领域的混合管道：(i) 一种证据门控的LLM用于提取规范化的JSON格式的CSA条款；(ii) 一种量子启发式的探索方法，结合了模拟退火和微高阶QAOA（HO-QAOA），用于处理与基础集相关的约束亚-QUBO问题；(iii) 一种带权重的风险感知目标函数，考虑了移动、CVaR和资金定价过度等风险因素，并明确了覆盖窗口U；(iv) CP-SAT作为仲裁器以确保可行性和差距认证，包括上限预检查。", "conclusion": "在政府债券数据集和多CSA输入上，该混合方法比强大的经典基线提高了9.1%，9.6%和10.7%，在监管设定下提供了更好的成本-移动-尾部前沿，同时释放了治理级的工具，如跨度引文、估值矩阵审计、权重来源、QUBO表现和CP-SAT跟踪，使结果可以被验证和重现。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26230", "html_url": "https://arxiv.org/abs/2510.26230", "title": "MPRU: 将模板块投影-重分布卸载作为分类管道的输出过滤器", "title_en": "MPRU: Modular Projection-Redistribution Unlearning as Output Filter for Classification Pipelines", "authors": "Minyi Peng,Darian Gunamardi,Ivan Tjuawinata,Kwok-Yan Lam", "background": "现有的机器卸载（MU）工作通常侧重于理论制定或优化目标，以实现知识的移除。但这些解决方案在实际应用中经常面临可扩展性问题，且需要原数据集和模型的完全访问权限。现有方法面临的主要挑战是需要原数据集和模型的访问权限，以及无法根据不同需求灵活调整。", "innovation": "本文提出了一种名为诱导方法的分类训练序列方式，通过在模型末端添加投影-重分布层来实现卸载。这种创新方法无需访问原数据集和模型，而且能够模块化地、无特定模型依赖地部署到现有分类管道中，改进了现有技术的局限性。实验结果表明，通过该方法可以以较低的计算成本获得与完全重新训练相似的输出。", "conclusion": "该研究表明，该方法在实际场景中具有适用性、可扩展性和系统兼容性，且在保持输出性能的同时显著降低了计算成本。这一方法为机器卸载技术的实用化提供了新的思路和可行性验证。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26275", "html_url": "https://arxiv.org/abs/2510.26275", "title": "增强软件工程过程和软件产品的人类生成智能研究路线图", "title_en": "A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI", "authors": "Domenico Amalfitano,Andreas Metzger,Marco Autili,Tommaso Fulcini,Tobias Hey,Jan Keim,Patrizio Pelliccione,Vincenzo Scotti,Anne Koziolek,Raffaela Mirandola,Andreas Vogelsang", "background": "生成式人工智能（GenAI）正在迅速改变软件工程（SE）实践，影响着软件工程过程的执行方式，以及软件系统的开发、运行和演化。", "innovation": "通过设计科学研究方法构建了一条路线图，综合利用协作讨论、快速文献审查和外部反馈等多来源证据。使用麦卢汉的四元体作为概念工具，系统地捕捉GenAI对SE过程和软件的影响，并确定了四种根本形式的GenAI增强SE的方式，及其相关研究挑战和机会。", "conclusion": "该研究表明，通过一个严谨的多循环过程，集成独立作者团队和同行的验证，为分析GenAI对SE过程、方法和技术的影响提供了一个透明和可重复的基础，并为这一快速发展的领域内未来研究的框架提出了十项预测。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26285", "html_url": "https://arxiv.org/abs/2510.26285", "title": "揭开语言模型处理数字机制的奥秘", "title_en": "Unravelling the Mechanisms of Manipulating Numbers in Language Models", "authors": "Michal Štefánik,Timothee Mickus,Marek Kadlčík,Bertram Højer,Michal Spiegel,Raúl Vázquez,Aman Sinha,Josef Kuchař,Philipp Mondorf", "background": "近期研究表明，不同的大规模语言模型（LLMs）对数字的输入嵌入表示趋于收敛且准确。然而，这些发现与LLMs处理数字信息时易产生错误输出的已知倾向相矛盾。本文旨在通过研究语言模型如何处理数字以及这些机制的准确度下限来解释这种矛盾。", "innovation": "本文发现不同的语言模型学习不同且系统、高度准确且在不同隐藏状态和输入上下文类型中普遍适用的数字表示方式。这一发现使得可以创建适用于每种LLM的通用探针，并能追踪信息（包括输出错误的原因）到特定层。本文的研究为理解预训练LLMs处理数字的方式奠定了基础，并指出了更精确探针技术在LLM架构改进的潜力。", "conclusion": "本文的结果揭示了预训练LLMs处理数字的方式，并概述了更准确探针技术在未来改进LLM架构的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26219", "html_url": "https://arxiv.org/abs/2510.26219", "title": "在预逻辑空间通过基于采样的最优控制实现 LLM 的测试时对齐", "title_en": "Test-Time Alignment of LLMs via Sampling-Based Optimal Control in pre-logit space", "authors": "Sekitoshi Kanai,Tsukasa Yoshida,Hiroshi Takahashi,Haru Kuroki,Kazumune Hashimoto", "background": "由于微调大语言模型需要高昂的计算成本，测试时对齐大语言模型吸引了人们的注意。现有方法如最佳n次采样方法虽然有效但存在局限，新的测试时对齐方法需要提高奖励效率并减少样本使用数量，以适应实时和资源受限环境的需求。", "innovation": "本文提出了一种新的测试时对齐方法——自适应重要性采样在预逻辑空间（AISP），它基于基于采样的模型预测控制，通过在预逻辑层输出（倒数第二层）中加入高斯扰动来最大化基于扰动平均值的预期奖励。AISP 方法通过重要性采样获取最优化的扰动均值，并且在使用的样本数量上优于最佳n次采样方法，在奖励方面也表现得优于其他基于奖励的测试时对齐方法。", "conclusion": "AISP 方法通过在预逻辑层应用高斯扰动，在测试时对齐大语言模型方面取得了显著成效，实现了高奖励效率，有助于减少计算资源消耗，对实际应用场景具有重要意义。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26243", "html_url": "https://arxiv.org/abs/2510.26243", "title": "角度控制：通过激活空间中的旋转实现行为控制", "title_en": "Angular Steering: Behavior Control via Rotation in Activation Space", "authors": "Hieu M. Vu,Tan M. Nguyen", "background": "在大规模语言模型中安全可靠地部署时，控制特定行为同时保留其基本能力是一项核心挑战。现有方法如向量加法和方向消减仅在激活和特征方向定义的二维子空间内运作，使其在参数选择上敏感，并可能因激活空间中的意外交互而影响无关特征。", "innovation": "本文提出了角度控制（Angular Steering），一种新颖且灵活的方法，用于通过在固定的二维子空间内旋转激活来调节行为。角度控制将调节定义为向目标行为方向的几何旋转，提供对拒绝和顺从等行为的连续细粒度控制，并提出了选择性变体适应性角度控制，进一步提高稳定性和连贯性。角度控制在统一的几何旋转框架下将现有的加法和正交化技术进行了泛化，简化了参数选择且在更大范围的调整下保持了模型的稳定性。", "conclusion": "在多种模型家族和规模下，角度控制实现了稳健的行为控制，同时保持了基础的语言建模性能，凸显了其灵活性、泛化能力和鲁棒性，超越了先前的方法。相关代码和实验结果可在提供的链接下载。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26298", "html_url": "https://arxiv.org/abs/2510.26298", "title": "ChatGPTAtlas能否征服网页？探ChatGPT Atlas代理在网页游戏中前沿", "title_en": "Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games", "authors": "Jingran Zhang,Ning Li,Justin Cui", "background": "ChatGPT Atlas是一款由OpenAI推出的新型模型，具备网页交互的新能力，能够分析网页、处理用户意图并直接在浏览器中执行鼠标和键盘输入。尽管其在信息检索任务中的能力已经被验证，但其在动态和交互式环境中的表现仍然很少被研究。因此，这项研究旨在使用基于浏览器的游戏作为测试场景，初步评估Atlats在网页交互能力方面的情况。", "innovation": "本研究使用基于浏览器的游戏作为测试场景，定量评估ChatGPT Atlas在不同任务类型下的表现。研究结果发现，ChatGPT Atlas在逻辑推理任务如数独游戏中表现优异，能够显著快于人类基准。但在需要精确时间和动作控制的实时游戏中，表现不佳，常无法进展到初始障碍之后。", "conclusion": "研究结果表明，虽然ChatGPT Atlas展示了有效的分析处理能力，但在需要实时交互的动态网页环境中，仍有显著限制。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26278", "html_url": "https://arxiv.org/abs/2510.26278", "title": "分布式的多目标黑盒优化在扩散模型推理时多目标样本生成", "title_en": "Distributional Multi-objective Black-box Optimization for Diffusion-model Inference-time Multi-Target Generation", "authors": "Kim Yong Tan,Yueming Lyu,Ivor Tsang,Yew-Soon Ong", "background": "扩散模型已经成功地学习了复杂的数据分布，并被应用于高维多目标黑盒优化问题。现有方法通常采用外部优化循环，例如进化算法，作为扩散模型的辅助手段。然而，这种做法忽视了扩散生成过程的内部分布转换，从而限制了效率。", "innovation": "本文提出了一种推理时多目标生成 (IMG) 算法，该算法在推理时优化扩散过程，以生成同时满足多个目标的样本。具体而言，IMG 在扩散生成过程中根据预期的多目标值进行加权重采样，确保生成的样本按我们期望的多目标玻尔兹曼分布分布。进一步来讲，多目标玻尔兹曼分布具有有趣的对数似然解释，即它是分布式的多目标优化问题的最优解。实验结果表明，仅需一次生成过程，IMG 就能显著提高区域体积，而基线优化算法通常需要数百次扩散生成。此外，该算法可以被视作优化的扩散过程，进一步提高现有方法的效果。", "conclusion": "本文提出的 IMG 算法能更高效地处理多目标黑盒优化问题，并显著提高了生成的样本质量，展示了优异的泛化性能和效率。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26302", "html_url": "https://arxiv.org/abs/2510.26302", "title": "从词粒度因果视角理解视觉-语言组合性的难度", "title_en": "Understanding Hardness of Vision-Language Compositionality from A Token-level Causal Lens", "authors": "Ziliang Chen,Tianang Xiao,Jusheng Zhang,Yongsen Zheng,Xipeng Chen", "background": "CLIP 通过在共享嵌入空间中对齐图像和文字展示了强大的跨模态泛化能力，但在对象、属性和关系的组合推理上表现不佳，类似于词袋模型。先前的因果解释通常将文本视为单一向量，这掩盖了词级结构，并导致诸如提示敏感性和硬负样本上的不解释现象。该论文提出了一个词级感知的因果表示学习框架，以解决这些局限性。", "innovation": "提出了一种基于序列化语言-词因果结构因果模型 (SCM) 的词级感知因果表示学习框架，证明了 CLIP 的对比目标可以在句级和词级 SCM 下恢复模态不变的潜在变量。研究发现词级粒度是 CLIP 组合脆弱性第一个原理性的解释——组合不可识别性。证明了伪最优文本编码器在优化相同训练目标的情况下，却对原子概念的 SWAP、REPLACE 和 ADD 操作敏感性极低，导致无法区分正确的描述与难负样本。", "conclusion": "词级因果视角解释了语言方面不可识别性如何通过模式差距传递到视觉方面，并揭示了组合运算的累积难度，从而推动了改进负样本挖掘策略。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26324", "html_url": "https://arxiv.org/abs/2510.26324", "title": "通过结合退火朗格维动力学和扩散模型进行后验采样", "title_en": "Posterior Sampling by Combining Diffusion Models with Annealed Langevin Dynamics", "authors": "Zhiyang Xun,Shivam Gupta,Eric Price", "background": "给定一个受噪线性测量 $y = Ax + \\xi$ 的分布 $p(x)$ 和一个近似的先验 $p(x)$，在什么情况下可以从后验 $p(x \rvert y)$ 中进行采样？后验采样为诸如修补、去模糊和MRI重建等任务提供了准确且公平的框架，多个近似后验采样的启发式方法试图对其进行逼近。遗憾的是，近似的后验采样在一般情况下计算上是不可行的。因此，我们专注于局部或全局对数凸分布 $p(x)$。在这种情况下，当精确得分可用时，朗格维动力学能够产出后验样本，但对得分估计误差特别敏感，需要MGF界（次指数误差）。相比之下，无条件环境中，扩散模型仅需要得分误差的$L^2$界便可以成功。", "innovation": "我们提出了一种结合退火朗格维动力学和扩散模型的方法，从而使得仅通过得分误差的$L^4$界便可以在多项式时间内实现条件采样的目标。", "conclusion": "通过结合退火朗格维动力学和扩散模型，我们证明了在得分误差仅限制于$L^4$界的情况下，可以在多项式时间内实现条件采样，从而提供了后验采样的可行计算方法。这种方法特别适用于局部或全局对数凸分布 $p(x)$。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26303", "html_url": "https://arxiv.org/abs/2510.26303", "title": "Per-sample Adam on Separable Data: Departure from the Full-batch Regime", "title_en": "Implicit Bias of Per-sample Adam on Separable Data: Departure from the Full-batch Regime", "authors": "Beomhan Baek,Minhak Song,Chulhee Yun", "background": "Adam 是深度学习中事实上的优化器，但它在理论上的理解仍然有限。早期的研究表明，Adam 倾向于与 $\boldsymbol{\text{ℓ}_\text{∞}}$-几何度量对齐的解，但在全批量处理情况下才有这种表现。本文旨在研究使用单个样本的增量 Adam 对逻辑回归在线性可分数据上的隐式偏见，发现其隐式偏见可能与全批量 Adam 不同。对于一般数据集，作者通过开发一个代理算法，以及数据依赖的双倍定点形式，确定了增量 Adam 的收敛方向。并且证明了 Signum 在任何批量大小下都会收敛到 $\boldsymbol{\text{ℓ}_\text{∞}}$-最大边缘分类器，只要 $\beta$ 接近 1。这些结果揭示了 Adam 的隐式偏见不仅取决于批量方案，还取决于数据集特性。", "innovation": "文章展示了增量 Adam 在线性可分数据上的特定隐式偏见，与全批量 Adam 的 $\boldsymbol{\text{ℓ}_\text{∞}}$-最大边缘偏见不同，且证明了 Signum 在任何批量大小下都会收敛至 $\boldsymbol{\text{ℓ}_\text{∞}}$-最大边缘分类器，只要 $\beta$ 接近 1。此外，通过构造特定数据集，证明了增量 Adam 的特定收敛行为，使得隐式偏见与数据集高度相关。这些发现表明，Adam 均值和 Signum 的隐式偏见对批量方案和数据集有高度依赖性。", "conclusion": "本文结果强调了 Adam 的隐式偏见受批量方案和数据集特性的影响，而 Signum 保持不变。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26345", "html_url": "https://arxiv.org/abs/2510.26345", "title": "MisSynth: 使用合成数据提高MISSCI谬误分类", "title_en": "MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data", "authors": "Mykhailo Poliakov,Nadiya Shvai", "background": "健康相关的错误信息非常普遍且具有潜在危害。识别这些错误信息尤其困难，特别是在声明歪曲或曲解科学发现时。研究通过MISSCI数据集和框架，探讨了合成数据生成和轻量级微调技术对大语言模型（LLMs）识别谬论能力的影响。", "innovation": "研究提出了MisSynth，一种使用检索增强生成（RAG）生成合成谬误样本的管道，将这些样本用于微调LLM模型。研究结果显示出微调模型相较于基础模型的显着准确度提升。例如，微调后的LLaMA 3.1 8B模型的F1分数绝对改进了超过35%。研究成果表明，引入合成谬误数据可以显著增强零-shot LLM分类绩效，即使计算资源有限。", "conclusion": "通过在有限的计算资源下引入合成谬误数据来增强有限的标注资源，可以显著提高大语言模型在现实世界科学错误信息任务中的分类表现。研究提供了代码和合成数据集。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26336", "html_url": "https://arxiv.org/abs/2510.26336", "title": "通过自动课程学习将知识注入大型语言模型", "title_en": "From Amateur to Master: Infusing Knowledge into LLMs via Automated Curriculum Learning", "authors": "Nishit Neema,Srinjoy Mukherjee,Sapan Shah,Gokul Ramakrishnan,Ganesh Venkatesh", "background": "大型语言模型在通用任务上表现出色，但在经济学和心理学等需要深入、原则性理解的专门领域中表现较差。本研究旨在解决这一问题，通过引入ACER（自动化课程增强训练计划），使通用模型转变为领域专家，同时保留其广泛的通用能力。ACER首先生成一个主题的目录表，然后根据布卢姆分类学生成问题-答案（QA）对，以此确保系统的主题覆盖和难度逐步提升。生成的合成语料库用于持续预训练，结合课程时间表，实现内容和认知维度的同步学习。", "innovation": "ACER 通过自动课程学习的方式，合成全面的课程表并生成问题-答案对，进行持续预训练，从而将通用语言模型转化为领域专家，尤其是在经济学家经济及心理学等需要深入理解的领域。此外，ACER 还可以防止灾难性遗忘，并促进跨领域知识迁移，提高非目标领域性能。在知识密集型基准测试中，ACER 也展现出显著的性能提升，同时保持一般推理任务的稳定性能。", "conclusion": "本研究通过ACER为解决大型语言模型在专门领域中的表现缺陷提供了一种可扩展和有效的方案，显著提高了MMLU专用子集的准确性，并在广泛的知识密集型基准测试中展示了显著的性能提升，同时保持了一般推理任务的稳健表现。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26347", "html_url": "https://arxiv.org/abs/2510.26347", "title": "随机稀疏且非稳定环境下的自主水下车辆污染检测的强化学习方法", "title_en": "Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle", "authors": "Sebastian Zieglmeier,Niklas Erdmann,Narada D. Warakagoda", "background": "强化学习算法旨在通过学习最大化奖励的动作来优化问题解决，但在随机和非稳定环境中，这一任务变得特别具有挑战性。即使是最先进的强化学习算法，在这些条件下解决问题的能力也往往有限。例如，在使用自主水下车辆（AUVs）寻找水下污染云时，强化学习算法需要在奖励稀疏的环境中导航，这种环境下，许多行动可能得不到任何奖励。", "innovation": "本文重新审视并修改了经典的强化学习方法，使其能够在稀疏、随机且非稳定环境中高效运行。研究探索了包括分层算法变化、多目标学习和引入位置记忆作为外部输出过滤器以防止状态重复等一系列修改，结果表明，基于蒙特卡洛的方法显著优于传统的Q学习以及两种全面搜索模式，展示了其在复杂环境中的适应潜力。", "conclusion": "这些发现表明，强化学习方法可以有效地适应随机、非稳定和奖励稀疏的环境。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26390", "html_url": "https://arxiv.org/abs/2510.26390", "title": "SPG-CDENet: 空间先验导向交叉双编码网络在多器官分割中的应用", "title_en": "SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation", "authors": "Xizhi Tian,Changjun Zhou,Yulin. Yang", "background": "多器官分割是计算机辅助诊断中的关键任务。尽管最近的深度学习方法在图像分割上取得了显著的成果，但器官大小和形状的巨大差异给多器官分割带来了挑战。为解决这些问题，我们提出了一种名为SPG-CDENet的空间先验导向交叉双编码网络，这是一种创新的两阶段分割模式，旨在提高多器官分割的准确性。", "innovation": "SPG-CDENet包含两个关键组件：空间先验网络和交叉双编码网络。该网络的主要创新在于其引入了空间先验网络生成粗略的定位图，作为交叉双编码网络的空间指导，并通过全卷积层提出对称交叉注意模块来增强全局和局部编码器之间的特征交互，以及利用流解码器直接从最终编码层向所有解码层传播高级语义特征，以最大化特征保留和利用。", "conclusion": "在两个公开数据集上进行了详尽的定性和定量实验，证明了SPG-CDENet相对于现有分割方法的优越性能。此外，删减研究进一步验证了所提出模块在提高分割准确性方面的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26339", "html_url": "https://arxiv.org/abs/2510.26339", "title": "GLYPH-SR：我们能否通过基于VLM的潜扩散模型同时实现高质量的图像超分辨率和高保真文本恢复？", "title_en": "GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?", "authors": "Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang", "background": "图像超分辨率(SR)是在许多视觉系统中（从监控和自主驾驶到文档分析和零售分析）至关重要的领域，因为从图像中恢复高频细节，特别是场景文本能够支持可靠的目标感知。场景文本，即嵌入自然图像中的文字（如路标、产品标签和店铺招牌），常包含有价值的信息。然而，视觉清晰度或OCR和后续决策易受字符模糊或想象的影响。先前的SR研究通常关注于失真（PSNR/SSIM）或感知度量（LIPIS、MANIQA、CLIP-IQA、MUSIQ），这些度量对于字符级错误不敏感。此外，一些研究虽关注于文本SR，但往往只使用简化的基准测试，忽视了复杂自然场景中的文本挑战。", "innovation": "GLYPH-SR利用了基于OCR数据的Text-SR融合控制网（TS-ControlNet）以及在文本和场景指导之间交替的ping-pong调度。通过在合成数据集上训练这些组件，同时冻结主要的SR分支，实现针对文本恢复的目标性。GLYPH-SR在SVT、SCUT-CTW1500、CUTE80（x4、x8）数据集上都取得了显著改善，OCR F1值比扩散/生成对抗网络（GAN）基线高出15.18个百分点，同时保持了竞争性的MANIQA、CLIP-IQA和MUSIQ性能。", "conclusion": "GLYPH-SR旨在同时实现高质量的图像超分辨率和高保真文本恢复，从而确保生成的图像看起来正确且读起来正确，设计上注重实现高可读性和高视觉真实性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26406", "html_url": "https://arxiv.org/abs/2510.26406", "title": "人工在线 reject 抽样方法在机器人操作中的应用", "title_en": "Human-in-the-loop Online Rejection Sampling for Robotic Manipulation", "authors": "Guanxing Lu,Rui Zhao,Haitao Lin,He Zhang,Yansong Tang", "background": "强化学习（RL）已被广泛用于生成鲁棒的机器人操作策略，但当使用 RL 细调视觉-语言-动作（VLA）模型时可能会因为值估计不准确和中间步骤稀疏监督而导致稳定性差。相比之下，模仿学习（IL）虽然易于训练但因其离线特性表现往往不佳。本研究探讨了如何结合这两种方法来改进机器人操作策略。", "innovation": "提出了一种名为 Hi-ORS 的简单但有效的后训练方法，通过淘汰采样技术来实现训练稳定性和高鲁棒性。Hi-ORS 在在线细调过程中通过过滤掉负奖励样本来稳定价值估计，并采用奖励加权监督训练目标为中间步骤提供密集的监督。此外，还开发了一种异步推理-训练框架，支持灵活的在线人类在环纠正，作为错误恢复行为的学习显式指导。", "conclusion": "在三个现实任务和两种实体上，Hi-ORS 细调了 pi 基本策略，仅用 1.5 小时的真实世界训练时间就掌握了丰富的接触操作，并显著优于 RL 和 IL 基线。特别地，通常情况下，经过细调的策略具有良好的测试性能，可以可靠地执行复杂错误恢复行为以提高性能。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26352", "html_url": "https://arxiv.org/abs/2510.26352", "title": "对话的几何学：绘制语言模型以揭示多代理协作中的协同团队", "title_en": "The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic Teams for Multi-Agent Collaboration", "authors": "Kotaro Furuya,Yuichi Kitagawa", "background": "基于大型语言模型（LLMs）的多代理方法代表了一种超越单个模型能力的有希望的策略，但其成功取决于团队组成的协同性。然而，形成最优团队是一个重大挑战，因为大多数模型的内部特性不透明，难以有效合作。本文基于对话为中心的方法，提出了一种自动团队组成框架，该框架不需要任何先验知识，如内部架构、训练数据或任务性能。通过这种方法构建了一个“语言模型图”，该图通过对话的语义一致性映射模型之间的关系，并通过社区检测识别协同模型集群。实验表明，该方法发现了功能上一致的组，反映了其潜在的专业化能力。特定主题的对话促进了具有协同性的团队的形成，在下游基准测试中表现优于随机基线，并且达到了与根据已知模型专业化手动筛选团队相似的准确性。", "innovation": "本文提出了一种无需任何先验知识的自动团队组成框架，该框架通过构建“语言模型图”来映射模型之间基于语义一致性的对话关系，然后通过社区检测识别协同模型集群。这种方法能够发现功能上一致的组，反映了模型的潜在专业化能力，并通过特定主题的对话促使具有协同性的团队形成，从而在下游基准测试中表现出优于随机基线的效果，达到了与根据已知模型专业化手动筛选团队相似的准确性。该方法为自动化设计多代理语言模型团队提供了新的基础。", "conclusion": "本文通过构建“语言模型图”并采用社区检测识别协同模型集群的方法，提出了一个自动团队组成框架，发现功能上一致的模型组，并通过特定主题的对话促进了具有协同性的团队形成，这些团队在下游基准测试中的表现优于随机基线，达到了与手动筛选团队相似的准确性。该方法为自动化设计多代理语言模型团队提供了新的基础。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26342", "html_url": "https://arxiv.org/abs/2510.26342", "title": "使用干预约束的线性因果发现", "title_en": "Linear Causal Discovery with Interventional Constraints", "authors": "Zhigao Guo,Feng Dong", "background": "因果知识和机制对于改进因果模型并完善下游任务（例如设计新治疗方法）至关重要。当前的因果发现方法允许施加结构约束（例如，要求从PIP3到Akt的因果路径），但这些方法可能会导致错误的因果结论。例如，可能会从数据中得出错误的结论，如'PIP3抑制Akt'。因此，需要一种新的方法来增强因果发现，确保模型符合已知的因果影响。干预约束就是这样的方法，它通过在因果效应上编码高层次的因果知识来实现这一点。", "innovation": "本文提出了一种新颖的概念，即干预约束，它与干预数据在本质上有所不同。与直接改变变量的干预数据不同，干预约束以不等式形式编码变量对因果效应的约束。为了形式化干预约束，本文提出了一个度量标准来量化线性因果模型中的总因果效应，并将问题构建成一个约束优化任务，使用两阶段约束优化方法来求解。这种方法不仅提高了模型的准确性和与已确立发现的一致性，还促进了新因果关系的发现，这些新关系在未施加约束时可能会非常昂贵，甚至无法识别。", "conclusion": "通过在因果发现中引入干预约束，本文的方法不仅改进了模型的解释性并确保符合已知的因果影响，还促进了新因果关系的发现。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26412", "html_url": "https://arxiv.org/abs/2510.26412", "title": "LoCoT2V-Bench: 一种用于长格式复杂文本转视频生成的基准", "title_en": "LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video Generation", "authors": "Xiangqing Zheng,Chengyue Wu,Kehai Chen,Min Zhang", "background": "近年来，文本转视频生成在生产和输出短、高质量剪辑方面取得了显著进展，但评估长格式输出仍是一个重大挑战，尤其是在处理复杂指示词的情况下。现有的基准测试主要依赖于简化的指示词，并侧重于低级指标，忽视了与指示词的精细对齐以及叙事连贯性、主题表达等抽象维度。", "innovation": "LoCoT2V-Bench 是一个专门针对复杂输入条件下长视频生成（LVG）设计的新基准测试。它利用各种真实世界的视频引入了一系列现实且复杂的指示词，包括场景过渡和事件动态，并构建了一个多维度的评估框架，其中包括新提出的指标，如事件级对齐、细粒度时间一致性、内容清晰度和人性化期望现实度（HERD），强调叙事流动、情感反应和角色发展等更抽象的属性。使用此框架，对九个代表性LVG模型进行了全面评估，发现当前方法在基本视觉和时间维度上表现良好，但在事件间一致性、细粒度对齐和高层次主题一致等方面存在困难。", "conclusion": "总体而言，LoCoT2V-Bench 提供了一个全面且可靠的平台来评估长格式复杂文本转视频生成，并指出了未来方法改进的关键方向。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26451", "html_url": "https://arxiv.org/abs/2510.26451", "title": "通过分类复杂性缓解实现鲁棒性图凝缩", "title_en": "Robust Graph Condensation via Classification Complexity Mitigation", "authors": "Jiayi Luo,Qingyun Sun,Beining Yang,Haonan Yuan,Xingcheng Fu,Yanbiao Ma,Jianxin Li,Philip S. Yu", "background": "图凝缩(GC)由于能够合成更小但更具信息性的图而受到广泛关注。然而，现有研究在原图被破坏的场景中往往忽视了GC的鲁棒性。在这种情况下，我们发现GC的性能显著下降，而现有的鲁棒图学习技术效果有限。", "innovation": "本文从图数据流形的几何视角出发，提出了一种新的约束鲁棒图凝缩框架MRGC。具体而言，通过引入三个图数据流形学习模块，引导压缩后的图位于光滑、低维度且类不确定度最小的流形内，从而保留了GC的分类复杂性降低能力，并确保在普遍对抗攻击下的鲁棒性能。", "conclusion": "广泛的实验证明了MRGC在各种攻击场景下的鲁棒性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26444", "html_url": "https://arxiv.org/abs/2510.26444", "title": "从稀缺数据中进行个性化治疗效果预测的双通道知识蒸馏和自适应融合", "title_en": "Personalized Treatment Outcome Prediction from Scarce Data via Dual-Channel Knowledge Distillation and Adaptive Fusion", "authors": "Wenjie Chen,Li Zhuang,Ziying Luo,Yu Liu,Jiahao Wu,Shengcai Liu", "background": "个性化治疗效果预测对于小样本和罕见患者的精确定量医学至关重要。然而，这些高成本的试验数据限制了预测性能。", "innovation": "提出了一种跨保真度知识蒸馏和自适应融合网络（CFKD-AFN），它利用丰富的低保真度模拟数据来增强对稀缺但高保真度试验数据的预测。该模型通过一种双通道知识蒸馏模块提取互补知识，并结合一个注意力导向融合模块动态整合多源信息，从而显著提高了预测准确性和鲁棒性。此外，还对CFKD-AFN进行了改进，使其具有解释性，便于在临床决策中进行深入探索医学隐含义。", "conclusion": "CFKD-AFN在慢性阻塞性肺疾病的治疗效果预测中显著优于最先进的方法，准确率提高了6.67%至74.55%，且能应对高保真数据集变化趋势下的鲁棒性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26484", "html_url": "https://arxiv.org/abs/2510.26484", "title": "大型语言模型的贝叶斯网络融合用于情感分析", "title_en": "Bayesian Network Fusion of Large Language Models for Sentiment Analysis", "authors": "Rasoul Amirzadeh,Dhananjay Thiruvady,Fatemeh Shiri", "background": "大型语言模型（LLMs）不断进步，并且出现了越来越多针对特定领域的变体以适应专门任务。然而，这些模型通常缺乏透明性和解释性，调优成本高，需要大量的提示工程，对不同领域的情感分析效果不一致，并且由于高计算需求对环境造成显著负面影响。", "innovation": "提出了一种贝叶斯网络LLM融合（BNLF）框架，该框架通过概率机制融合来自三个LLM（FinBERT、RoBERTa和BERTweet）的情感预测，进行后融合（late fusion），通过建模多LLM的情感预测作为贝叶斯网络中的概率节点，从而提高了情感分析的准确性，且该方法稳健且解释性强，即使在数据集变化时也能保持稳定的性能。", "conclusion": "BNLF在三个具有不同语言和上下文特征的人类标注金融语料库上进行了评估，结果表明其比基准LLMs在准确性方面提高了约6%，证明了概率融合方法对于可解释的情感分类效验的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26420", "html_url": "https://arxiv.org/abs/2510.26420", "title": "SSCL-BW: 样本特定的清洁标签后门水印技术用于数据集所有权验证", "title_en": "SSCL-BW: Sample-Specific Clean-Label Backdoor Watermarking for Dataset Ownership Verification", "authors": "Yingjia Wang,Ting Qiao,Xing Liu,Chongzuo Li,Sixing Wu,Jianbin Li", "background": "深度神经网络（DNNs）的发展依赖于大量高质量的数据集，但未经授权的商业使用这些数据集严重侵犯了数据集所有者的知识产权。现有的基于后门的数据集所有权验证方法存在固有的局限性：带有污染标签的水印由于标签不一致而容易被检测到，而清洁标签的水印技术面临高技术复杂性和在高分辨率图像上的失败。此外，这两种方法都使用静态水印模式，容易被检测和移除。因此，这项工作提出了一个针对特定样本的清洁标签后门水印（即SSCL-BW）的方法，以便从根本上克服静态水印模式的脆弱性。", "innovation": "该方法通过训练一个基于U-Net的水印样本生成器，为每个样本生成独特的水印。核心创新在于设计了一个由三个部分组成的复合损失函数：目标样本损失确保了水印的有效性，非目标样本损失保证了触发可靠性，感知相似损失保持了视觉不可察觉性。验证所有权时，采用黑盒测试检查可疑模型是否表现出预定的后门行为。通过基准数据集的广泛实验，验证了该方法的有效性和对抗潜在水印移除攻击的鲁棒性。", "conclusion": "通过在每个样本上生成唯一的水印，SSCL-BW方法解决了静态水印模式的脆弱性问题，同时通过一个复合损失函数确保水印的多方面特性。实验结果表明该方法的有效性和鲁棒性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26474", "html_url": "https://arxiv.org/abs/2510.26474", "title": "通过头尾重新平衡反制LVLMs自我改进中的马太效应", "title_en": "Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing", "authors": "Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "自改进已成为提升大型视觉语言模型（LVLMs）推理能力的主流范式，模型通过迭代探索和学习成功轨迹。但是在此过程中，我们发现了一个关键问题：模型在生成简单查询（即头数据）的高质量轨迹方面表现出色，但在处理更复杂的查询（即尾数据）时则表现出困难。这种不平衡的优化导致模型倾向于优先发展简单的推理技能，而削弱其解决复杂推理任务的能力。随着迭代的进行，这种不平衡逐渐加剧，我们称之为“马太效应”，最终阻碍了模型的进一步改进并导致性能瓶颈。", "innovation": "我们提出了四种有效的策略，从两个方面重塑数据分布和重新采样轨迹，以在探索和学习的自我改进过程中实现头尾重新平衡。我们对Qwen2-VL-7B-Instruct和InternVL2.5-4B模型在视觉推理任务上的广泛实验结果表明，我们的方法在视觉推理能力上表现更优，平均高出3.86个点，超越了普通的自我改进。", "conclusion": "我们通过提出两种视角下的四种方法，有效缓解了LVLMs自我改进过程中出现的头尾分布不平衡问题，从而提高了模型的通用推理能力，为视觉推理任务带来了显著改进。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26494", "html_url": "https://arxiv.org/abs/2510.26494", "title": "使用大语言模型代理模拟和实验社交媒体动员", "title_en": "Simulating and Experimenting with Social Media Mobilization Using LLM Agents", "authors": "Sadegh Shirani,Mohsen Bayati", "background": "在线社交媒体网络已改变了政治动员信息传播的方式，引发了关于大规模情境下同辈影响力的运作机制的新问题。以6100万参与者规模的Facebook实验为背景，本文构建了一个基于真实美国人口普查数据、真实的推特网络拓扑和异质大语言模型（LLM）代理的基于代理的模拟框架，以探讨动员信息对选民投票率的影响。", "innovation": "本文创新地提出了一个综合了真实人口普查数据、真实推特网络结构和异质大语言模型代理的基于代理的模拟框架。此框架不仅重现了实地试验中的定性模式，还通过复制原始Facebook研究的信息和社交动员治疗条件，为政治动员研究提供了一个可控制、可重复的环境，以测试反事实设计和敏感性分析。", "conclusion": "本文构建的框架为政治动员研究提供了连接高质量实地实验和灵活的计算建模的桥梁。该框架通过社交媒体上的大规模实验和模拟，能更好地理解和测试政治动员的效果，同时验证理论假设，并提供了可重复的研究环境。代码和数据可通过链接获取。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26457", "html_url": "https://arxiv.org/abs/2510.26457", "title": "SecureReviewer：通过安全意识微调增强大型语言模型用于安全代码审查", "title_en": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "authors": "Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang", "background": "在软件系统开发的早期阶段识别和解决安全问题对于减轻长期负面影响至关重要。代码审查作为一种有效的实践，使开发人员能够在集成到代码库之前检查队友的代码。尽管已经提出了各种自动代码审查方法，其中基于LLM的方法显著增强了自动审查生成的能力，但现有模型主要针对通用代码审查，其在识别和解决安全相关问题方面的有效性仍然未得到充分探索。此外，对现有代码审查方法进行调整以针对安全问题面临着数据稀缺性和不充分评价指标等重大挑战。因此，提出了SecureReviewer，这是一种新方法，旨在增强LLMs识别和解决安全相关问题的能力。特别是在构建了一个专门用于训练和评估安全代码审查能力的数据集，并使用安全意识微调策略对LLMs进行微调。为了减少LLM的幻觉并提高其输出的可靠性，我们将RAG技术集成到生成的注释中，使它们基于特定领域的安全知识。此外，我们还提出了SecureBLEU作为新的评估指标，用于评估审查注释在解决安全问题方面的有效性。实验结果表明，SecureReviewer在安全问题检测准确性以及生成的审查注释的整体质量和实用价值方面均优于最先进的基线方法。", "innovation": "1. 构建了专门针对安全代码审查的数据集。\n2. 使用安全意识微调策略对LLMs进行微调，以生成能够有效识别安全问题并提供修复建议的审查注释。\n3. 将RAG技术集成到生成的注释中，使它们基于特定领域的安全知识，以减少LLM的幻觉并提高其输出的可靠性。\n4. 提出了SecureBLEU，这是一种新的评估指标，专门用于评估审查注释在解决安全问题方面的有效性。", "conclusion": "实验结果显示，SecureReviewer在安全问题检测准确性以及生成的审查注释的整体质量和实用价值方面均优于最先进的基线方法。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26551", "html_url": "https://arxiv.org/abs/2510.26551", "title": "自适应逆向动力学框架在机器人中学习变长工具操控", "title_en": "Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics", "authors": "Prathamesh Kothavale,Sravani Boddepalli", "background": "传统机器人对自身运动学的理解有限，只能执行预定任务，这限制了它们高效使用工具的能力。本文探讨了机器人在使用工具时所需的关键步骤：抓取所需结果、选择最合适的工具、确定最佳工具姿态以及执行精确操作。", "innovation": "本文提出了一种创新框架，扩展了机器人逆向动力学求解器的能力，使其能够使用不同长度的工具执行一系列动作。通过将模拟学习的动作轨迹与工具结合，展示了技能从模拟到实际应用的可行性，并在实验中表现出不到1厘米的高精度。", "conclusion": "研究结果显示，扩展的逆向动力学求解器在使用不同长度的工具时表现出几乎一致的性能，达到了预设的目标。这表明机器人在未来能够在多元任务中掌握工具操控的复杂艺术。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26512", "html_url": "https://arxiv.org/abs/2510.26512", "title": "Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs", "title_en": "Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs", "authors": "Dipak Meher,Carlotta Domeniconi", "background": "人口走私网络日益适应性强且难以分析。法律案例文件提供了关键的见解，但往往结构化程度不高，词汇密集，且充满了模糊或变化的参考，这为自动化知识图谱（KG）构建带来了重大挑战。尽管基于最新大语言模型（LLM）的方法改进了静态模板，但由于缺乏引导式抽取和同指消解，它们仍然生成了嘈杂、碎片化的图表，且节点重复。最近提出的CORE-KG框架通过整合类型感知的同指解析模块和领域导向的结构化提示，显著减少了节点重复和法律噪声。", "innovation": "本文对CORE-KG进行了系统性的消融研究，以量化其两个关键组件的个体贡献。研究发现，移除同指消解会导致节点重复增加28.32%，噪音节点增加4.32%；移除结构化提示会导致节点重复增加4.34%，噪音节点增加73.33%。这些发现提供了设计从复杂法律文本中提取结构化表示的鲁棒LLM基线流程的实证见解。", "conclusion": "本文通过实验证明了CORE-KG框架在减少节点重复和噪音方面的重要作用，为未来从复杂法律文本中自动构建知识图谱奠定了基础。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26543", "html_url": "https://arxiv.org/abs/2510.26543", "title": "大型语言模型中关系解码线性算子的结构", "title_en": "The Structure of Relation Decoding Linear Operators in Large Language Models", "authors": "Miranda Anna Christ,Adrián Csiszárik,Gergely Becsó,Dániel Varga", "background": "本文探讨了Hernandez等人在2023年引入的线性算子结构，这些算子能解码变压器语言模型中的特定关系事实。之前的单关系研究被扩展到多个关系，并系统地对其组织进行了详细说明。研究结果表明，线性算子可以通过简单的三维张量网络高度压缩，同时保持较好的解码准确性。这些线性算子之间似乎存在冗余，能够解释这一现象的交叉评估协议已经建立并应用了每个算子的相关主语。\r\n", "innovation": "本文的主要创新在于将单关系的线性算子扩展到多个关系，并通过简单的三维张量网络成功压缩了这些算子，揭示了它们实际上提取的是重复出现的粗粒度语义属性，例如首都是哪个国家和食物来自哪个国家都会归于同一个属性类别。这说明线性算子的这种基于属性的结构同时也是高度压缩的，揭示出它们只能对语义相近的新关系进行泛化的根本原因。这些发现重新定义了变压器语言模型中线性关系解码的主要作用，即更多地基于语义属性而非特定关系。", "conclusion": "线性关系解码算子在变压器语言模型中主要体现在语义属性的基础上，而不是特定的关系。这种基于属性的结构既能解释其压缩性也能揭示它们泛化的语义近邻性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26575", "html_url": "https://arxiv.org/abs/2510.26575", "title": "InfoFlow：通过奖励密度优化强化搜索代理", "title_en": "InfoFlow: Reinforcing Search Agent Via Reward Density Optimization", "authors": "Kun Luo,Hongjin Qian,Zheng Liu,Ziyi Xia,Shitao Xiao,Siqi Bao,Jun Zhao,Kang Liu", "background": "奖励密度低是增强学习中应用深度搜索场景的一个主要障碍，导致探索成本高而回报稀少。为解决这一问题，论文提出了奖励密度优化(Reward Density Optimization)问题，旨在提高每单位探索成本的回报。InfoFlow是一种系统框架，从三个方面解决这个问题：子问题分解、失败引导提示和双代理精炼。", "innovation": "InfoFlow提出了三种解决奖励密度优化问题的方法：1) 通过分解长任务来进行子问题分解，提供更密集的学习信号；2) 通过注入失败指导提示来增加成功结果的概率；3) 使用双代理架构来减轻深度探索的认知负担，通过合成搜索历史压缩代理的探索轨迹，减少探索成本并增加整体奖励密度。", "conclusion": "在多个代理搜索基准测试中，InfoFlow显著优于强大基线，使得轻量级语言模型性能可与先进的独家语言模型相媲美。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26566", "html_url": "https://arxiv.org/abs/2510.26566", "title": "使用Jensen-Shannon距离实现多分类局部校准", "title_en": "Multiclass Local Calibration With the Jensen-Shannon Distance", "authors": "Cesare Barbera,Lorenzo Perini,Giovanni De Toni,Andrea Passerini,Andrea Pugnana", "background": "开发可信的机器学习（ML）模型需要其预测概率准确反映真实分类频率。在多分类校准中，强校准是最严格的要求，因为它要求所有类别的预测概率同时校准。然而，现有的多分类校准方法缺乏对输入之间距离的认知，导致了邻近偏差：在特征空间的稀疏区域中的预测会系统地校准错误。这种偏差在高风险领域尤为重要，如医疗保健，因为在稀疏实例中的实例正是风险最高的实例，最需要避免偏差的治疗。本研究旨在通过引入多分类局部校准的局部视角来解决这一主要不足。随后，我们从理论上分析了现有评估指标在应用于多分类局部校准时的局限性。接下来，我们提出了一种实用的方法，在神经网络中增强局部校准，该方法利用杰森-香农距离来确保预测概率与局部类频率估计之间的对齐。最后，我们在实验中验证了我们的方法相对于现有的多分类校准技术的有效性", "innovation": "通过引入多分类局部校准的局部视角，提出了一种新的评估指标，该方法利用杰森-香农距离在神经网络中增强局部校准，确保预测概率与局部类频率估计之间的对齐。这种方法有效地解决了传统方法在稀疏数据区域的邻近偏差问题，特别是在高风险应用领域，例如医疗保健。", "conclusion": "实验结果表明，使用Jensen-Shannon距离进行多分类局部校准的方法相对于现有的多分类校准技术更有优势。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26601", "html_url": "https://arxiv.org/abs/2510.26601", "title": "ResMatching: 通过定向条件流匹配实现抗噪计算超分辨率", "title_en": "ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching", "authors": "Anirban Ray,Vera Galinova,Florian Jug", "background": "计算超分辨率（CSR）在荧光显微镜中的历史虽然悠久而且是一个病态问题，其核心是寻找一种先验知识来推断显微图中未曾通过成像显微镜捕捉到的频率。由于数据驱动的机器学习技术的进步，可以学习更强的先验知识，CSR的效果可以得到提升。ResMatching 使用引导条件流匹配来学习这些改进的数据先验。", "innovation": "ResMatching 是一种新的使用引导条件流匹配方法来学习改进数据先验的计算超分辨率方法。在 BioSR 数据集的 4 种不同生物结构上进行评估，与 7 个基线方法的比较结果显示，ResMatching 在保持数据保真度和感知现实性之间实现了最佳平衡，尤其是在低分辨率图像包含大量噪声的情况下能更有效地实现CSR。", "conclusion": "ResMatching 可以从隐式学习的后验分布中进行采样，并且这种分布适用于所有测试用例，这使得该方法能够提供像素级的数据不确定性项，从而指导未来的用户拒绝不确定的预测。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26684", "html_url": "https://arxiv.org/abs/2510.26684", "title": "钢铁轧制过程计算机视觉在实时故障预测中的应用", "title_en": "Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill", "authors": "Vaibhav Kurrey,Sivakalyan Pujari,Gagan Raj Gupta", "background": "本文介绍了在钢铁轧制厂中使用基于机器视觉的异常检测系统进行故障预测的长期部署研究。该系统利用工业摄像头实时监控设备运行、对齐和热棒运动情况，通过集中视频服务器使用深度学习模型处理实时视频流，以预测设备故障和生产中断，从而减少意外停机成本。基于服务器的推理减少了工业过程控制系统（PLC）的计算负担，支持沿生产线的可扩展部署，无需额外资源。", "innovation": "通过结合数据分析系统传感器数据和视觉输入，该系统能够识别故障位置及其可能的根本原因，提供主动维护的行动依据。该集成方法增强了工业制造环境下的操作可靠性、生产效率和盈利能力。", "conclusion": "服务器端推理减少了工业过程控制系统的计算负担，提供了一种可扩展的、有效的实时故障预测解决方案，支持钢铁轧制过程中的设备健康管理，提高了工业制造的可靠性和效率。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26646", "html_url": "https://arxiv.org/abs/2510.26646", "title": "动态环境中的混合DQN-TD3强化学习自主导航", "title_en": "Hybrid DQN-TD3 Reinforcement Learning for Autonomous Navigation in Dynamic Environments", "authors": "Xiaoyi He,Danggui Chen,Zhenshuo Zhang,Zimeng Bai", "background": "该研究提出了一种层级路径规划与控制框架，结合了高层的深度Q网络（DQN）进行离散子目标选择和低层的双重延迟深度确定性策略梯度（TD3）控制器进行连续动作执行。该系统在ROS+Gazebo（TurtleBot3）平台上实现，并通过PathBench指标在动态和部分可观测环境中评估了成功率、碰撞率、路径效率和重新规划效率，提高了成功概率和样本效率，更好地适应未见过的障碍布局，减少了突变的控制改变。", "innovation": "1. 混合使用DQN和TD3两种算法进行路径规划与控制，结合高、低层处理。2. 设计了一种具体的奖励成型方案和基于LiDAR的安全门，增强安全性。3. 在ROS+Gazebo平台上实现，并使用PathBench评估指标进行全面评估。4. 在动态和部分可观测环境下表现出色，提高了样本效率和成功率，具备更好的泛化能力。", "conclusion": "该研究提出的方法在动态环境中的路径规划与控制方面表现出优越性能，相比单一算法或基于规则的规划具有更高的成功率和样本效率，同时具备更好的未见过环境的泛化能力和减少突变控制改变。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26683", "html_url": "https://arxiv.org/abs/2510.26683", "title": "Evontree：基于本体规则指导的大型语言模型自我演进框架", "title_en": "Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models", "authors": "Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang", "background": "大型语言模型（LLMs）在多个领域展示了卓越的能力，这得益于大规模预训练和精心编排的微调数据。然而，在对数据敏感的领域如医疗健康中，高质量且领域的特异性训练语料的缺乏限制了LLMs在专业应用中的适应性。另一方面，领域专家将领域知识提炼为本体规则，系统化表示概念之间的关系，确保知识管理的完整性和一致性。将LLMs视为隐藏的人类知识库，本文提出Evontree框架，利用少量高质量的本体规则，系统地从LLMs中提取、验证和增强领域知识，而无需依赖大规模外部数据集。", "innovation": "Evontree框架利用少量高质量本体规则，从LLMs中系统性地提取、验证和增强领域知识，无需依赖大规模外部数据集。具体而言，Evontree从原始模型中提取领域本体，使用两个核心本体规则检测不一致，并通过自我提炼进行知识强化。", "conclusion": "在医疗问答基准测试中使用Llama3-8B-Instruct和Med42-v2进行的大量实验表明，相对于未修改的模型和领先监督基线，Evontree方法在准确率上表现一致的优越性，准确率最高可提高3.7%。这些结果证实了该方法在低资源领域适应LLMs中的有效性、高效性和鲁棒性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26585", "html_url": "https://arxiv.org/abs/2510.26585", "title": "停止浪费你的令牌：走向高效的运行时多智能体系统", "title_en": "Stop Wasting Your Tokens: Towards Efficient Runtime Multi-Agent Systems", "authors": "Fulin Lin,Shaowen Chen,Ruishan Fang,Hongwei Wang,Tao Lin", "background": "多智能体系统（MAS）在复杂任务中表现出色，但随着其自主性的增加和操作复杂性的提高，会产生诸如过度占用令牌和因信息错误引起的功能障碍等关键效率问题。现有的方法主要集中在事后故障归因上，缺乏具有前瞻性的实时干预手段来提升系统的鲁棒性和效率。", "innovation": "提出了SupervisorAgent，这是一种轻量级和模块化的框架，用于实现运行时、适应性的监督，而无需更改基础智能体的架构。SupervisorAgent 通过一个无需LLM的自适应过滤器触发，能够在关键节点主动干预以纠正错误、引导不高效的智能体行为、净化观察结果。在GAIA基准测试中，SupervisorAgent 将Smolagent框架的令牌消耗平均降低了29.45%。该研究还在五个额外的基准（数学推理、代码生成和问答）和不同领域的先进基础模型上进行了广泛的实验，验证了该方法的广泛适用性和鲁棒性。", "conclusion": "SupervisorAgent 证明了其在多个复杂任务中的高效运行监督能力，显著减少了机器在操作过程中对令牌的消耗，同时不影响其成功率。这种方法的有效性已经通过广泛的实验得到了验证，表明它具有广泛的适用性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26616", "html_url": "https://arxiv.org/abs/2510.26616", "title": "Aeolus: 多结构航班延误数据集", "title_en": "Aeolus: A Multi-structural Flight Delay Dataset", "authors": "Lin Xu,Xinyun Yuan,Yuxuan Liang,Suwan Yin,Yuankai Wu", "background": "现有的航班延误预测数据集通常局限于扁平的表格结构，无法捕捉航班延误传播中的时空动态。因此，研究人员需要一个能够涵盖多模态信息的数据集以支持更精确的航班延误预测和基础模型的发展，尤其是为了处理航班网络、关联调度以及航班链中的时间结构需求。", "innovation": "Aeolus 数据集引入了三个模态：（i）包含丰富的运营、气象和机场级特性的时间序列航班数据表；（ii）航班链模块，用于建模航班链路中延迟传播的顺序关联特性，捕捉上行和下行依赖性；（iii）航班网络图，编码共享飞机、机组和机场资源的相关性，以便进行跨航班的关系推理。此外，Aeolus 数据集的构建严格按照时间分割、全面特性和严格的泄漏预防标准，以支持现实和可重复的机器学习评估。", "conclusion": "Aeolus 提供了一个统一的数据基准，支持一系列任务，包括回归、分类、时间结构建模和图学习。此外，还提供了基准实验和预处理工具以促进数据的采用。Aeolus 满足了专用模型和通用结构数据的需求，填补了相关研究中的关键空白。代码和数据可以从以下链接访问：this https URL"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26714", "html_url": "https://arxiv.org/abs/2510.26714", "title": "仅使用单一训练种子评估机器卸载的局限性", "title_en": "On the limitation of evaluating machine unlearning using only a single training seed", "authors": "Jamie Lanyon,Axel Finke,Petros Andreou,Georgina Cosma", "background": "机器卸载（MU）旨在无需昂贵的重新训练就可以从训练好的模型中移除某些数据点的影响。尽管大多数实用的MU算法只能提供近似效果，但它们的性能需要通过实验评估。因此，在进行实验比较时，需要尽可能保持代表性。通常的做法是从同一个预训练模型开始，独立多次运行MU算法。然而，这项研究发现，即使是在相同的架构和相同的数据集上，某些MU方法对用于模型训练的随机数种子的选择高度敏感。这意味着仅使用单一训练种子的评估可能会导致非代表性的结果。因此，建议在评估MU算法时也应反映不同模型训练种子的变异性。", "innovation": "论文揭示了仅使用单一训练种子评估MU算法可能产生高度非代表性的结果，因为不同的MU方法对模型训练种子的选择高度敏感。因此，提出了在评估MU算法时应考虑不同模型训练种子的变异性。", "conclusion": "这项研究强调了在评估机器卸载算法时，应注意不同模型训练种子的影响，以获得更准确和代表性的评估结果。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26697", "html_url": "https://arxiv.org/abs/2510.26697", "title": "无需手动解码：迈向真正端到端语言模型", "title_en": "The End of Manual Decoding: Towards Truly End-to-End Language Models", "authors": "Zhichao Wang,Dongyang Ma,Xinting Huang,Deng Cai,Tian Lan,Jiahao Xu,Haitao Mi,Xiaoying Tang,Yan Wang", "background": "当前大型语言模型（LLMs）的标签为'端到端'是误导性的，实际上它们依赖于非可微分的解码过程，需要手动调整如温度（temperature）和top-p等超参数。这使得模型的解码不能完全自动完成，增加了复杂性和误差风险。现有的方法无法实现真正的端到端生成，阻碍了模型的进一步发展和应用。", "innovation": "本文提出了一个新的架构AutoDeco，它可以通过学习控制自己的解码策略来实现真正的端到端生成。AutoDeco通过在每一步动态预测上下文相关的温度和top-p值，将其解码过程转化为一个参数化的、以token为单位的过程。此外，它还能够根据自然语言指令调整其预测的温度和top-p值，实现指令驱动的解码控制。实验结果表明，AutoDeco不仅超过了默认的解码策略，而且其性能接近一个经过‘作弊’调优的基线，这是一个静态方法的实际上限。", "conclusion": "本文通过AutoDeco展示了无需手动调参的端到端生成方法的可行性，从而首次实现了真正意义上的端到端语言模型，并提出了新的解码控制范式。这一研究结果有望对语言模型的发展产生重大影响，使其更加灵活、可控制和交互性强。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26730", "html_url": "https://arxiv.org/abs/2510.26730", "title": "ExpertFlow：在高效MoE推理中的自适应专家调度和内存协调", "title_en": "ExpertFlow: Adaptive Expert Scheduling and Memory Coordination for Efficient MoE Inference", "authors": "Zixu Shen,Kexin Chu,Yifan Zhang,Dawei Xiang,Runxin Wu,Wei Zhang", "background": "大型语言模型的扩展受到现代GPU有限内存容量的限制。传统的MoE推理方法在每一层独立选择激活的专家，由于频繁的参数在主机内存和GPU内存之间的转移，导致了显著的延迟。此外，当前跨层预测策略通常基于固定的步骤，缺乏针对不同硬件平台和工作负载的适应性，降低了其鲁棒性和有效性。", "innovation": "提出了一个名为ExpertFlow的运行时系统，结合了自适应专家预取和缓存意识路由。ExpertFlow通过利用运行时统计信息（如传输带宽、参数维度和模型反馈信号）来连续调整专家激活预测时距。此外，它还引入了一种混合跨层预测方案，将预门控信息与中间计算状态结合起来，以预见未来专家的需求。通过自适应地优化预取决策并使它们与实际使用行为一致，ExpertFlow有效地减少了缓存缺失并消除了由专家切换引起的延迟。", "conclusion": "我们的评估表明，ExpertFlow将模型停顿时间减少到基线的0.1%以下，展示了其在严峻内存约束下优化MoE推理的能力。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26740", "html_url": "https://arxiv.org/abs/2510.26740", "title": "基于广泛激励的多智能体资源分配中的公平性框架", "title_en": "A General Incentives-Based Framework for Fairness in Multi-agent Resource Allocation", "authors": "Ashwin Kumar,William Yeoh", "background": "在资源受限的环境中，智能体为了效率最大化，往往会导致不公平的结果。传统的强化学习方法在优化效率时未能同时考虑公平性，这导致了现有方法难以在效率与公平性之间找到平衡。", "innovation": "提出了General Incentives-based Framework for Fairness (GIFF)，这是一种新型的公平多智能体资源分配方法。GIFF利用action-value（Q-）函数来平衡效率与公平性，具体而言，它计算每个行动的局部公平收益，并引入一个反事实优势修正项，以防止向已经富裕的智能体过度分配资源。此外，该方法在集中控制的设置下被形式化为一个仲裁者使用GIFF修改后的Q值来解决分配问题。GIFF在不同领域展示了比强基线更好的表现，能够发现远见卓识的公平政策。", "conclusion": "GIFF提供了一种稳健且原则性强的方法，通过利用标准的强化学习组件，获得更公平的多智能体系统结果。该框架的有效性通过理论上证明其公平性的替代指标是真实公平改进的合理下界以及其权衡参数提供单调调节来支持。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26722", "html_url": "https://arxiv.org/abs/2510.26722", "title": "非凸的无线异构联邦学习：偏差方差权衡", "title_en": "Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off", "authors": "Muhammad Faraz Ul Abrar,Nicolò Michelusi", "background": "现有的基于波形叠加的空中（Over-the-air, OTA）联邦学习（Federated Learning, FL）设计，主要通过假设无线通道同质化（即所有设备的路径损耗相等）或者强制偏差归零来保证零偏差模型更新，以此实现模型聚合。但在无线异构场景下，这样的设计受到最弱设备的限制，会增加更新的方差。已有文献主要关注凸目标的有偏OTA-FL，然而大多数现代AI模型是非凸的，这一领域的研究有所欠缺。鉴于这些不足，本文研究了在无线异构性下的非凸目标的OTA-FL，并使用随机梯度下降法（Stochastic Gradient Descent, SGD）进行模型更新，以减少偏差和方差之间的权衡问题，并发展了一种确保方差降低的同时允许结构化、时间不变偏差的新型OTA-FL SGD更新方法。", "innovation": "本文提出了新型的确定有偏OTA-FL SGD更新方法，此方法允许可结构化和时间不变的模型偏差，同时减少了更新方差。本文还导出了一个有限时间内稳态的界（预期时间平均平方梯度范数），并显式揭示了偏差和方差之间的权衡，提出了非凸的联合OTA功率控制设计，并使用统计信道状态信息（Statistical Channel State Information, CSI）开发了一个高效的逐步凸逼近算法。此外，实验结果表明基于SCA的设计可以加速收敛并通过优化偏差提高泛化能力，优于先前的OTA-FL基准方法。", "conclusion": "本文基于无线异构场景下的非凸目标OTA-FL，发展了一种新型的有偏OTA-FL SGD更新方法，通过保证偏差在可控制的范围中实现方差的降低。此外，本文提出了一个非凸的联合OTA功率控制设计，并提出了一种优化这一权衡问题的算法设计。通过在非凸图像分类任务上的实验验证了这些方法的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26768", "html_url": "https://arxiv.org/abs/2510.26768", "title": "AMO-Bench: 大型语言模型仍在高中生数学竞赛中挣扎", "title_en": "AMO-Bench: Large Language Models Still Struggle in High School Math Competitions", "authors": "Shengnan An,Xunliang Cai,Xuezhi Cao,Xiaoyu Li,Yehao Lin,Junlin Liu,Xinxuan Lv,Dan Ma,Xuanlin Wang,Ziwen Wang,Shuang Zhou(Alphabetical order by last name)", "background": "现有基准测试普遍使用高中数学竞赛来评估大型语言模型（LLMs）的数学推理能力。然而，随着大型语言模型性能的饱和（如AIME竞赛），许多现有的数学竞赛不再能很好地评估顶级大型语言模型的能力。现有基准测试在此方面存在局限，因此需要更严谨的挑战。", "innovation": "AMO-Bench是一个高级数学推理基准，包含50个由人类设计的问题，这些问题的难度达到了国际数学奥林匹克（IMO）或更高水平。每个问题只需给出最终答案，便于自动和稳健的评估。AMO-Bench确保所有问题都是原创的，以防止数据记忆导致的性能泄露。实验结果表明，即使是性能最好的模型在AMO-Bench上的准确率也仅为52.4%，大多数大型语言模型的得分低于40%。随着测试期间计算量的增加，性能呈现出改进的趋势。", "conclusion": "这些结果强调了当前大型语言模型在数学推理方面的显著改进空间。AMO-Bench的发布旨在促进进一步的研究，以提高语言模型的推理能力。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26776", "html_url": "https://arxiv.org/abs/2510.26776", "title": "基于高级采样的忠实且快速的影响函数", "title_en": "Faithful and Fast Influence Function via Advanced Sampling", "authors": "Jungyeon Koh,Hyeonsu Lyu,Jonggyu Jang,Hyun Jong Yang", "background": "影响函数（IFs）作为一种后验方法，通过利用梯度和海森矩阵来解释训练数据对黑盒模型的影响。然而计算整个数据集的海森矩阵资源消耗大，需要可行的替代方案。当前常使用随机采样一小部分训练数据的方法，但这种方法会导致IF估计高度不一致，因为样本配置的高方差。", "innovation": "我们提出了两种基于特征和输出的高级采样技术。这些采样器通过考虑特征或输出的随机分布来选择整个数据集中的一个小型且具代表性的子集，从而提高IF估计的准确性。我们通过使用F1分数来验证我们的方法，通过移除类别实验，衡量模型忘记移除类别的效果和保持其余类别推理一致性。", "conclusion": "我们的方法使计算时间减少了30.1%，内存使用减少了42.2%，或者将F1分数提高了2.5%。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26787", "html_url": "https://arxiv.org/abs/2510.26787", "title": "远程劳动力指数：衡量远程工作的AI自动化", "title_en": "Remote Labor Index: Measuring AI Automation of Remote Work", "authors": "Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks", "background": "人工智能在知识和推理研究基准上取得了快速进步，但这些进步在经济价值和自动化方面的转化仍然不清楚。为了衡量这一转化，本文引入了远程劳动力指数（Remote Labor Index，RLI），这是一种广泛涵盖了多个产业领域的基准，基于真实世界的、经济上有价值的项目，旨在评估代理人在实际情境下的端到端表现。人工智能代理在RLI上的表现接近天花板，最优秀的代理仅实现了2.5%的自动化率。", "innovation": "提出了远程劳动力指数（RLI）作为衡量人工智能在远程工作中自动化水平的新指标。RLI通过真实世界的经济项目来评估人工智能代理的端到端表现，提供了一种实际场景下的评估方式，填补了理论研究与实际应用之间的差距。", "conclusion": "通过RLI得到的结果有助于在证据基础上讨论人工智能自动化的影响，为跟踪人工智能影响提供了一个共同的基础，并使相关利益方能够积极应对由人工智能驱动的劳动力自动化变化。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26745", "html_url": "https://arxiv.org/abs/2510.26745", "title": "深度序列模型倾向于记忆几何结构；尚不清楚原因", "title_en": "Deep sequence models tend to memorize geometrically; it is unclear why", "authors": "Shahriar Noroozizadeh,Vaishnavh Nagarajan,Elan Rosenfeld,Sanjiv Kumar", "background": "在序列建模中，参数化的记忆通常被抽象为实体间共现关系的直接查找。作者对比了这种关联视角与记忆的几何视角之间的差异，指出传统的Transformer模型在处理复杂的推理任务时，并不是简单地存储训练时定义的局部共现关系，而是在某种程度上创造了一种自身的实体几何结构，能够表达所有实体之间的全局关系，包括那些未共现的实体。这种几何结构简化了复杂的推理任务，使其成为易于学习的一次性的几何任务。作者提取了这种几何结构的基本特征，并认为它的产生并不能简单地归因于常见的架构或优化压力。", "innovation": "作者提出了一个将Transfomer的推理过程与几何结构联系起来的新视角。通过Node2Vec连接，作者展示了这种几何结构源于谱偏置，并强调即使在缺乏各种压力的情况下，一种优雅的几何结构仍然可以自然地出现。此外，作者指出了将Transformer记忆更加强化为几何结构的方法，为研究者提供了新的思路，对知识获取、容量、发现和遗忘等领域提出了新的假设和挑战", "conclusion": "传统的方法仅仅基于局部关联来优化模型。然而，研究表明，模型在处理复杂推理任务时能够创造出复杂的几何结构。这种几何结构的形成机制目前尚不清楚，尽管优化目标仅基于局部关联。该研究希望乘以几何视角鼓励研究人员重新审视他们关于知识获取、模型容量、发现和遗忘的基本直觉。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26788", "html_url": "https://arxiv.org/abs/2510.26788", "title": "通过FP16战胜训练推理不匹配", "title_en": "Defeating the Training-Inference Mismatch via FP16", "authors": "Penghui Qi,Zichen Liu,Xiangxin Zhou,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "使用强化学习（RL）微调大型语言模型（LLMs）时，由于训练和推理策略之间的数值不匹配，经常遇到不稳定性问题。以往的研究尝试通过算法修正或工程对齐来缓解这一问题，但研究表明其根本原因是浮点精度本身。尽管广泛使用的BF16具有较大的动态范围，但它引入了较大的舍入误差，破坏了训练和推理的一致性。", "innovation": "本研究展示了通过简单地回退到FP16这一变化可以有效地消除这一不匹配。这一改变简单，得到现代框架的全面支持，只需几行代码更改，无需修改模型架构或学习算法。研究表明，使用FP16可以提供更稳定的优化、更快的收敛速度和更强的任务性能。", "conclusion": "研究结果表明，使用FP16的一致性可以带来更稳定的优化、更快的收敛速度和更好的性能，适用于各种任务、算法和框架。研究希望这些发现能够促进对RL微调精度权衡的更广泛重新考虑。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26771", "html_url": "https://arxiv.org/abs/2510.26771", "title": "STaMP：低精度激活量化中的序列变换和混合精度", "title_en": "STaMP: Sequence Transformation and Mixed Precision for Low-Precision Activation Quantization", "authors": "Marco Federici,Riccardo Del Chiaro,Boris van Breugel,Paul Whatmough,Markus Nagel", "background": "量化是降低生成AI模型推断延迟、功耗和内存占用的关键方法。然而，当激活量化到八位以下时，准确度通常会急剧下降。近期研究表明，可逆线性变换（例如旋转）能通过重新参数化特征通道和权重来辅助量化。本文研究了序列维度上的线性变换，并提出了一种新颖的量化策略——STaMP（Sequence Transformation and Mixed Precision），旨在通过在中间激活中有选择地保持较高精度的少量标记来降低整体激活位宽的平均值，从而保持模型精度。该策略在最近的LVM和LLM架构上进行了评估，表明STaMP能够在低位宽激活量化中显著提升性能，并且能够补充现有的激活和权重量化方法，包括近期提出的特征变换方法。", "innovation": "提出了一种新颖的量化策略——STaMP（Sequence Transformation and Mixed Precision），通过在序列维度上应用线性变换，更好地利用语言和视觉数据中的强局部相关性，保持模型在低位宽激活下的准确度，特别是在保持较低平均激活位宽的情况下。同时，通过保留每个中间激活中较高精度的一小部分标记来实现这一点。", "conclusion": "STaMP策略在最近的LVM和LLM架构上进行了评估，证明了它能够显著提高低位宽激活量化性能，并补充了现有的激活和权重量化方法，包括特征变换方法。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26782", "html_url": "https://arxiv.org/abs/2510.26782", "title": "使用几何正则化世界模型克隆确定性的3D世界", "title_en": "Clone Deterministic 3D Worlds with Geometrically-Regularized World Models", "authors": "Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen", "background": "世界模型是一种内部模型，用于模拟世界如何演变。基于过去观察和行动，它预测了生物体代理及其环境的未来。准确的世界模型对于使代理能够在复杂的、动态的环境中进行有效的思考、计划和推理至关重要。尽管取得了快速进展，但当前的世界模型仍然脆弱，长期内性能会退化。我们指出，主要原因是感知输入的质量不足，例如高维度的外部感知输入（如图像）会产生失真或纠缠的潜在空间，使动力学习变得不必要的困难。因此，我们提出了一个问题，是否通过单独改进表示学习就能显著提高世界模型的性能？", "innovation": "我们提出了几何正则化世界模型（GRWM），通过确保自然感知轨迹中的连续点在潜在表示空间中保持接近，以解决构建能够完全克隆和过度拟合确定性的3D世界的这一根本性开放问题。这种办法产生了显著改进的潜在表示，与环境的真实拓扑结构高度一致。GRWM 可插拔，只需要少量的架构修改即可使用，可以根据轨迹长度进行扩展，并与多种潜在生成模块兼容。在确定性的3D设置和远期预测任务中，GRWM 显著提高了滚出的真实性和稳定性。分析表明，其优点来自学习具有优越几何结构的潜在流形。这些发现表明改进表示学习是直接且有用的途径，能够提供可靠的长时间预测，而不会增加动力模块的大小，", "conclusion": "这些发现支持一个明确的结论：改进表示学习是提高世界模型鲁棒性的一个直接且有用的方法，能够在不扩大动力模块的情况下提供可靠的远期预测。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.15937", "html_url": "https://arxiv.org/abs/2503.15937", "title": "推进移动GUI代理：实用部署的验证驱动方法", "title_en": "Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment", "authors": "Gaole Dai,Shiqi Jiang,Ting Cao,Yuanchun Li,Yuqing Yang,Rui Tan,Mo Li,Lili Qiu", "background": "当前，移动设备上的 GUI 任务自动化代理主要依赖于大型语言模型（LLMs）在每一步直接生成行动。然而，这种方法存在一定的限制，特别是在决策的准确性和速度方面。V-Droid 提出了一种新的验证驱动方法，通过利用 LLMs 作为验证器在选择最终行动前进行评估，从而提高决策的准确性和效率。", "innovation": "V-Droid 引入了一个由三个关键部分组成的全面框架：动作空间的离散化构建、仅预填充的工作流程以加速验证过程、成对进度偏好训练以显著增强验证器的决策能力，以及可扩展的人机联合标注方案，以高效地收集必要的大规模数据。与其他现有移动代理相比，V-Droid 获得了显著更高的成功任务率和更低的延迟。", "conclusion": "在多个公开的移动任务自动化基准上，V-Droid 的成功任务率分别为 AndroidWorld 的 59.5%、AndroidLab 的 38.3% 和 MobileAgentBench 的 49%。此外，V-Droid 的每步延迟仅为 4.3 秒，比现有移动代理快 6.1 倍。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10361", "html_url": "https://arxiv.org/abs/2505.10361", "title": "塑性作为赋能的镜像", "title_en": "Plasticity as the Mirror of Empowerment", "authors": "David Abel,Michael Bowling,André Barreto,Will Dabney,Shi Dong,Steven Hansen,Anna Harutyunyan,Khimya Khetarpal,Clare Lyle,Razvan Pascanu,Georgios Piliouras,Doina Precup,Jonathan Richens,Mark Rowland,Tom Schaul,Satinder Singh", "background": "实体表现为受过去观察影响并行动以影响未来观察的最小实体。赋能作为描述这一行为能力的关键概念，在人工智能和认知科学中发挥了重要作用。然而，实体受到观察影响的机制也十分重要，它是理解代理特性的基础。本文探讨了如何通过一种通用的代理中心度量——称为塑性——来定义代理受到观测影响的方式，并揭示了它与赋能之间的基本联系。", "innovation": "本文使用一种新的信息论量度——广义定向信息，定义了塑性，该量度严格推广了Massey(1990)提出的定向信息，并保持了其所有优点。作者展示了塑性与赋能之间的镜像关系，即两种概念使用相同的标准，仅方向相反。研究结果表明，代理设计需要同时考虑这两个特性。", "conclusion": "本文揭示了塑性与赋能之间的镜像关系，表明代理特性设计中需要谨慎平衡这两个方面。塑性、赋能及其关系对于理解代理是必不可少的。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26802", "html_url": "https://arxiv.org/abs/2510.26802", "title": "视频模型作为零样本推理者是否准备好了？基于MME-CoF基准的实证研究", "title_en": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark", "authors": "Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng", "background": "近期的视频生成模型能够生成高质量且时间上连贯的视频，表明它们可能蕴含了大量世界知识。除了现实的合成外，它们还表现出视觉感知、建模和操控的新兴行为。然而，一个重要的问题仍待解答：视频模型是否已准备好在挑战性的视觉推理场景中充当零样本推理者？", "innovation": "这项工作通过在视频模型中进行系统性评估，旨在全面探讨这一问题，特别是对领先的Veo-3模型进行12个维度的评估，包括空间、几何、物理、时间及体态逻辑，并创建了一个标准化的基准MME-CoF，用于深入评估链状框架推理解析。研究表明，当前的视频模型在短期内的空间连贯性、细粒度的定位以及局部一致性动态上表现出良好的推理模式，但仍然在长期因果推理、严格的几何约束以及抽象逻辑上有限制。因此，它们还未达到独立零样本推理者的可靠标准，但显示出与专门推理模型一起作为辅助视觉引擎的前景。", "conclusion": "尽管当前的视频模型在短期内的空间连贯性、细粒度的定位和局部一致性动态方面表现出优秀习性的推理模式，但在长期因果推理、严格的几何约束和抽象逻辑上存在局限。总体来说，视频模型尚未准备好作为独立的零样本推理者，但它们作为与专门推理模型结合使用的辅助视觉引擎显示出了积极迹象。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.26790", "html_url": "https://arxiv.org/abs/2510.26790", "title": "Gistify！通过运行时执行的代码库级理解", "title_en": "Gistify! Codebase-Level Understanding via Runtime Execution", "authors": "Hyunji Lee,Minseon Kim,Chinmay Singh,Matheus Pereira,Atharv Sonwane,Isadora White,Elias Stengel-Eskin,Mohit Bansal,Zhengyan Shi,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan,Lucas Caccia", "background": "随着编码代理在大规模代码库中的部署增多，自动设计具有挑战性的、针对代码库级别的评估变得尤为重要。本文提出了Gistify任务，该任务要求编码的大型语言模型（LLM）创建一个单一的、最小化的、自包含的文件，该文件可以重现代码库中的特定功能。编码的LLM被赋予访问整段代码库以及一个特定入口点（如Python命令）的权限，生成的文件必须能够重现该命令在未修改代码库情况下运行的输出结果，同时仅包含执行所提供命令所需的本质组件。成功完成Gistify任务需要对代码库的结构理解、精确建模其执行流程以及产生大代码补丁的能力。当前最先进的模型在解决Gistify任务方面表现不佳，尤其是在具有长执行跟踪的任务中。", "innovation": "本文提出了Gistify任务，该任务要求编码的LLM创造能够重现代码库特定功能的单文件，同时仅包含必要的执行组件。Gistify任务需要对代码库的理解、执行流程的准确建模以及生产大代码补丁的能力，当前最先进的模型在执行此类任务时表现不佳。", "conclusion": "当前最先进的模型在解决Gistify任务方面存在困难，特别是在具有长执行跟踪的任务中。这表明当前的技术在代码库级别的理解和生成代码补丁方面仍然存在局限性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.11730", "html_url": "https://arxiv.org/abs/2505.11730", "title": "重新审视计算高效的测试时缩放中最佳验证粒度", "title_en": "Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling", "authors": "Hao Mark Chen,Guanxi Lu,Yasuyuki Okoshi,Zhiwen Mo,Masato Motomura,Hongxiang Fan", "background": "测试时缩放（Test-time scaling, TTS）已证明能有效提升大型语言模型（LLMs）的推理能力。验证在TTS中起关键作用，影响着推理性能和计算效率，这取决于验证的质量和计算成本。传统上，验证只在生成结束时或每个生成步骤后进行。然而，这项研究挑战了这种传统的验证范式，首次系统性地探讨了验证粒度的影响，即验证器在生成过程中被调用的频率，而不仅限于验证最终输出或单独的生成步骤。", "innovation": "引入了Variable Granularity Search（VG-Search）算法，这是一种统一算法，通过可调粒度参数g将beam search和Best-of-N sampling算法统一起来。通过在不同计算预算、生成器-验证器配置和任务属性下进行广泛实验，研究表明动态选择g可以提高计算效率和缩放行为。此外，基于这些发现，提出了适应性的VG-Search策略，相比Beam Search可实现高达3.1%的准确性提升，相比Best-of-N可实现3.6%的准确性提升，同时减少超过52%的FLOPs开支。并且代码将开源以支持未来的研究工作。", "conclusion": "通过引入Variable Granularity Search算法，并动态调整验证粒度，不仅提高了计算效率，还实现了准确性提升，并且开源代码以促进后续研究。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18139", "html_url": "https://arxiv.org/abs/2505.18139", "title": "接纳矛盾：理论上的一致性缺失不会阻碍负责任的人工智能系统的建设之路", "title_en": "Embracing Contradiction: Theoretical Inconsistency Will Not Impede the Road of Building Responsible AI Systems", "authors": "Gordon Dai,Yunze Xiao", "background": "当前负责人工智能(RAI)的指标之间经常表现出理论上的不一致性，比如公平性定义不同、准确性和隐私之间的权衡等。这种不一致性通常被认为是需要消除的缺陷。", "innovation": "本文提出应该拥抱这些不一致性，将其视为宝贵的特点而非缺陷。通过将多种指标视为不同的目标来导航这些不一致性，能够带来三个关键好处：(1) 规范多元性：保留全面的、可能相互矛盾的指标组合，确保多样性的道德立场和利益相关者的价值观在RAI中得到充分反映。(2) 知识完备性：多样的、有时相互冲突的指标可以更全面地捕捉复杂伦理概念，从而保留比单一简化定义更大的信息准确性。(3) 隐含的正则化：同时优化理论上相互矛盾的目标可以防止模型过度适应单一指标，促使模型在现实复杂环境下保持更好的泛化能力和鲁棒性。", "conclusion": "与通过简化或削减指标来追求理论一致性相比，我们提倡在RAI理论和实践中从沉浸于不一致性中转向确定可接受的一致性阈值，并阐明实现在实践中实现稳健近似一致的机制。这样可以使RAI系统获得更大的价值多样性，避免概念上的浅显化并提升模型表现。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14970", "html_url": "https://arxiv.org/abs/2505.14970", "title": "Self-Evolving Curriculum for LLM Reasoning", "title_en": "Self-Evolving Curriculum for LLM Reasoning", "authors": "Xiaoyin Chen,Jiarui Lu,Minsu Kim,Dinghuai Zhang,Jian Tang,Alexandre Piché,Nicolas Gontier,Yoshua Bengio,Ehsan Kamalloo", "background": "强化学习（RL）已被证明对大型语言模型（LLMs）的微调非常有效，显著提升了其在数学、代码生成等领域的推理能力。然而，RL微调的成功很大程度上依赖于训练课程的设计：即训练问题出现的顺序。随机课程尽管是常见的基线，但通常效率不高；手工设计的课程往往依赖于启发式方法，而在线筛选方法可能过于计算密集，从而不具备可行性。因此，开发一种自动的课程学习方法来优化这一过程成为了一种需求。", "innovation": "本文提出了一种自动课程学习方法——自我演变课程（Self-Evolving Curriculum, SEC）。SEC将课程选择过程形式化为一个非定常多元臂赌博机问题，其中每个问题类别（如难度级别或问题类型）被视为一个独立的臂。SEC利用策略梯度方法的绝对优势作为即时学习增益的代理度量。在每次训练步骤中，课程策略通过选择最大化这种奖励信号的问题类别，并使用TD(0)方法进行更新来优化课程的选择。这一方法在规划、归纳推理和数学这三个不同的推理领域中，被证明可以显著提升模型的推理能力，并有助于多层次推理任务的技能平衡。", "conclusion": "研究结果表明，SEC是一种有前景的策略，可以提升LLM的RL微调效果和对其复杂问题的泛化能力。这一方法解决了随机课程和手动设计课程中的不足，并且在同时在多个推理领域微调时，实现了更好的技能平衡。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.02820", "html_url": "https://arxiv.org/abs/2505.02820", "title": "AutoLibra：从开放性人类反馈中推导出的代理指标", "title_en": "AutoLibra: Agent Metric Induction from Open-Ended Human Feedback", "authors": "Hao Zhu,Phil Cuvin,Xinkai Yu,Charlotte Ka Yee Yan,Jason Zhang,Diyi Yang", "background": "代理通常通过粗化的任务成功指标进行评估和优化，这些指标往往需要专家的 manual 设计，并且无法奖励中间的 emergent 行为。现有方法缺乏对细粒度行为的评价能力，特别是在应对开放性问题和复杂交互场景时显得不足。", "innovation": "提出了 AutoLibra 框架，可以将开放性的人类反馈（例如，“如果发现按钮已禁用，请不要再点击它”或“该代理过于自主，自行决定应该如何行动”）转化为评估代理轨迹中细粒度行为的指标。通过将反馈与代理行为结合，AutoLibra 映射相似的正负行为，并生成具体的、具有明确定义和具体示例的度量标准。此外，还引入了两类元度量标准（coverage 和 redundancy），用于评估度量标准是否与开放性反馈一致，通过优化这些元度量，能够比之前的方法生成更具针对性的代理评价指标。", "conclusion": "AutoLibra 不仅证明了自身能够生成更加具体的代理评价指标，还能够自动化优化代理，并通过自我调节提升代理性能。研究表明，AutoLibra 是一个通用工具，能够用来评估和提高语言代理的表现。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12371", "html_url": "https://arxiv.org/abs/2505.12371", "title": "MedAgentBoard：以传统方法评估多元医疗任务中的多方协作基准", "title_en": "MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks", "authors": "Yinghao Zhu,Ziyi He,Haoran Hu,Xiaochen Zheng,Xichen Zhang,Zixiang Wang,Junyi Gao,Liantao Ma,Lequan Yu", "background": "大型语言模型（LLMs）的快速发展激发了对多智能体协作的需求，以应对复杂的医疗任务。然而，现有的多智能体协作方法的优势尚未得到充分理解。当前的评估往往缺乏广泛的适用性，未能涵盖反映临床实践多样性的任务，并且常常忽略了与单一LLM方法和传统方法的严谨对比。因此，提出了MedAgentBoard，这是一种全面的基准，用于系统评估多智能体协作、单一LLM和传统方法。MedAgentBoard包括四个不同的医疗任务类别：（1）医学（视觉）问答、（2）简化摘要生成、（3）结构化电子健康记录（EHR）预测模型、（4）临床工作流自动化，涉及文本、医学影像和结构化的EHR数据。", "innovation": "MedAgentBoard引入了一种新的基准测试方法，用于系统评估多智能体协作、单一LLM和传统方法在多元医疗任务中的表现。通过涵盖多种类型的医疗任务，如视觉问答、简化摘要生成、EHR预测建模和临床工作流自动化，MedAgentBoard提供了一个全面的评估框架，填补了多智能体协作方法评估的空白，增强了评估的通用性和实用性。", "conclusion": "MedAgentBoard揭示了多层次的评估景观。虽然多智能体协作在某些情况下（如临床工作流自动化）能够提高任务完成度，但并不一直优于先进的单一LLM或专业化传统方法，尤其是在医学视觉问答和基于EHR的预测任务中表现出更好的性能。MedAgentBoard提供了一个有价值的资源和可操作的洞察，强调了在医疗中选用和开发AI解决方案时需要任务特定的、基于证据的方法。它进一步强调了多智能体协作内在复杂性和开销与实际性能增益之间的权衡。所有源代码、数据集、详细提示和实验结果均已开源。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.18667", "html_url": "https://arxiv.org/abs/2509.18667", "title": "TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation", "title_en": "TERAG: Token-Efficient Graph-Based Retrieval-Augmented Generation", "authors": "Qiao Xiao,Hong Ting Tsang,Jiaxin Bai", "background": "图为基础的检索增强生成（RAG）方法已经成为提高大型语言模型（LLMs）推理、准确性和真实性的广泛研究方法。然而，现有的图为基础的RAG系统在图构建过程中忽略了LLM标记使用成本高昂的问题，阻碍了其大规模应用。", "innovation": "我们提出了一个名为TERAG的简单而有效的框架，旨在以更低的成本构建具有信息性的图。TERAG借鉴了HippoRAG方法，结合了个性化PageRank（PPR）技术，在检索阶段实现。使用TERAG方法，可以在仅消耗约3%-11%的输出标记的情况下，达到与广泛使用的图为基础的RAG方法相似（≥80%）的准确性。", "conclusion": "TERAG因其低标记占用和高效的构建管道，非常适合大规模和成本敏感的应用场景。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18318", "html_url": "https://arxiv.org/abs/2510.18318", "title": "地球AI：通过基础模型和跨模态推理解锁地理空间洞察", "title_en": "Earth AI: Unlocking Geospatial Insights with Foundation Models and Cross-Modal Reasoning", "authors": "Aaron Bell,Amit Aides,Amr Helmy,Arbaaz Muslim,Aviad Barzilai,Aviv Slobodkin,Bolous Jaber,David Schottlander,George Leifman,Joydeep Paul,Mimi Sun,Nadav Sherman,Natalie Williams,Per Bjornsson,Roy Lee,Ruth Alcantara,Thomas Turnbull,Tomer Shekel,Vered Silverman,Yotam Gigi,Adam Boulanger,Alex Ottenwess,Ali Ahmadalipour,Anna Carter,Behzad Vahedi,Charles Elliott,David Andre,Elad Aharoni,Gia Jung,Hassler Thurston,Jacob Bien,Jamie McPike,Juliet Rothenberg,Kartik Hegde,Kel Markert,Kim Philipp Jablonski,Luc Houriez,Monica Bharel,Phing VanLee,Reuven Sayag,Sebastian Pilarski,Shelley Cazares,Shlomi Pasternak,Siduo Jiang,Thomas Colthurst,Yang Chen,Yehonathan Refael,Yochai Blau,Yuval Carny,Yael Maguire,Avinatan Hassidim,James Manyika,Tim Thelin,Genady Beryozkin,Gautam Prasad,Luke Barrington,Yossi Matias,Niv Efron,Shravya Shetty", "background": "地理空间数据具有巨大的潜力，但其庞大的数量和多样性、不同的分辨率、时间尺度和稀疏性带来了深刻的分析和解释挑战。", "innovation": "提出了一种基于Planet-scale Imagery、Population和Environment三大领域的基础模型家族及Gemini驱动的智能推理引擎，通过多步推理的Gemini驱动代理来处理复杂的地理空间数据查询，为地理空间推断提供互补价值，并揭示出更强的预测能力。", "conclusion": "我们的代理在新的现实世界危机场景基准测试中展示了生成关键和及时洞察的能力，有效地弥合了原材料地理空间数据和可操作理解之间的差距。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.02091", "html_url": "https://arxiv.org/abs/2510.02091", "title": "深层LLM层在检索、知识和推理中的角色揭秘", "title_en": "Demystifying the Roles of LLM Layers in Retrieval, Knowledge, and Reasoning", "authors": "Xinyuan Song,Keyu Wang,PengXiang Li,Lu Yin,Shiwei Liu", "background": "最近的研究表明，大型语言模型（LLMs）的深层层次在表示学习中贡献甚微且常常能够在不显著影响性能的前提下被移除。然而，这些结论通常是基于有限的评估得出的，可能会忽略模型行为的某些重要方面。在这项工作中，我们对不同维度的深度利用率进行了一项系统性的研究，包括评估协议、任务类别和模型架构。", "innovation": "我们的研究证实，非常深层的层一般来说不如早期的层有效，但其贡献会根据评估设定显著变化。基于似然性的度量在没有生成的情况下，移除大部分层能够保持性能，而初始的几个层是关键的。相反，基于生成的评估揭示了中间和深层层对于推理和维持长距离连贯性是不可或缺的。此外，我们发现知识和检索集中在浅层组件，而推理准确性则严重依赖于深层层—但可以通过蒸馏重新塑造。", "conclusion": "这些结果指出，LLM中的深度使用是高度异质性的且依赖于上下文，强调在解释和压缩大型模型时需要任务、度量和模型的视角。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.21204", "html_url": "https://arxiv.org/abs/2508.21204", "title": "模糊化、符号化和情境化：通过认知架构建构大语言模型教学", "title_en": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "authors": "Vanessa Figueiredo", "background": "本文研究了提示级别归纳偏置如何影响大型语言模型（LLMs）在教学对话中的认知行为。研究使用了一种符号支撑方法配以短期记忆架构，旨在促进苏格拉底式教学中的适应性、结构化推理。通过五个系统变体的控制删除实验，采用专家设计的评分标准对模型输出进行评估。初步结果表明，该系统在架构变体的早期实验中表现出更高的性能，这揭示了记忆和符号结构在关键认知行为中的重要作用，包括抽象、适应性探索和概念连续性。", "innovation": "本文引入了一种符号支撑方法配以短期记忆架构，设计用于促进大型语言模型的适应性、结构化推理。通过五个系统变体的控制删除实验，采用专家设计的评分标准评估模型输出。这种方法允许对不同架构的模型进行可扩展且系统的比较，并展示了提示级别的认知支撑如何可靠地塑造LLMs中的教学策略。", "conclusion": "初步结果显示，完整系统在基准变体中表现出一致的优越性。分析表明，去除记忆或符号结构会显著降低关键认知行为，包括抽象、适应性探索和概念连续性。这支持了一个处理级的解释，即提示级别的认知支撑可以可靠地塑造大型语言模型中新兴的教学策略。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.15030", "html_url": "https://arxiv.org/abs/2508.15030", "title": "Collab-REC：基于LLM的多代理人框架以平衡旅游推荐", "title_en": "Collab-REC: An LLM-based Agentic Framework for Balancing Recommendations in Tourism", "authors": "Ashmi Banerjee,Adithi Satish,Fitri Nur Aisyah,Wolfgang Wörndl,Yashar Deldjoo", "background": "研究背景集中在旅游推荐系统中普遍存在的热门地偏见问题，这导致了旅游景点的不均衡访问和过度访问。现有的单一代理系统通常无法很好地平衡个性化、流行性和可持续性，导致推荐结果缺乏多样性和相关性。因此，需要提出一种新的多代理框架来克服这些挑战，特别是在旅游推荐方面，以提高多样性和总体相关性，促进可持续旅游。", "innovation": "该研究提出了Collab-REC框架，这是一个多代理系统，旨在对抗流行性偏见并增强旅游推荐的多样性。Collab-REC框架中包含三个基于LLM的代理：个性化代理、流行性代理和可持续性代理，它们从互补的角度提出城市建议。一个非LLM的调解者通过多轮谈判对这些提案进行合并和细化，确保每个代理的观点都被纳入，同时惩罚虚假或重复的回答。实验结果表明，与单一代理基线相比，Collab-REC在多样性和总体相关性方面有明显改进，能够推荐较少访问的地点，这些地点通常会被忽视。", "conclusion": "Balanced-Collab-REC结合了多样化和上下文相关性，有效解决了过度旅游问题，并更好地满足了用户提供的约束。这种方法为基于LLM的推荐系统中的多利益相关者协作提供了新的可能性，展示了多利益相关者协作在促进可持续旅游中的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18477", "html_url": "https://arxiv.org/abs/2510.18477", "title": "LAFA：分散化数据源上的代理LLM驱动联邦分析", "title_en": "LAFA: Agentic LLM-Driven Federated Analytics over Decentralized Data Sources", "authors": "Haichao Ji,Zibo Wang,Cheng Pan,Meng Han,Yifei Zhu,Dan Wang,Zhu Han", "background": "现有的通过LLM代理实现的数据分析框架假设集中式数据访问，缺乏隐私保护。而联邦分析（FA）能够实现跨分布式数据源的隐私保护计算，但不支持自然语言输入，且需要结构化的机器可读查询。", "innovation": "LAFA是首个将基于LLM代理的数据分析与联邦分析（FA）相结合的系统，通过多层次的多智能体架构接受自然语言查询并转化为优化的联邦分析可执行流程。引入了粗略和精细的计划器，以及优化器来提升执行效率，并使自然语言输入支持成为可能。", "conclusion": "实验表明，LAFA比基线提示策略表现更优，执行计划成功率更高，并显著减少了资源密集型的FA操作。该研究为支持自然语言输入的隐私保护LLM驱动分析奠定了实用基础。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.16648", "html_url": "https://arxiv.org/abs/2509.16648", "title": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs", "title_en": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs", "authors": "Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy", "background": "针对多模态大型语言模型（MLLMs）生成的预测准确评估信任度是一项挑战，因为它们处理多模态输入的多样化方式。准确评估这些模型的信任度可以促进选择性预测，并增强用户的信心，但对于不确定性的量化仍然具有挑战性。现有的方法可能需要大量的标记数据或无法全面探查模型的输入空间和输出空间。", "innovation": "本文提出了一种名为功能等效采样用于信任评估（FESTA）的技术，这是一种多模态输入采样方法，用于MLLMs。FESTA通过生成基于等价和互补输入采样的不确定性度量来实现这一点。该方法通过等价采样探查模型的一致性，通过互补采样探查模型的敏感性。FESTA是一种黑盒方法，仅需模型的输入-输出访问，无需真实标签（无监督）。实验使用了多种现成的多模态LLMs，并对视觉和音频推理任务进行了验证，取得了显著的性能提升，相比vision-LLMs提高了33.3%，audio-LLMs提高了29.6%。这些结果基于受试者操作特征面积（AUROC）指标来检测错误预测的能力。", "conclusion": "FESTA在不依赖真实标签的情况下，通过输入输出访问提供了一种新的无监督方法来评估多模态语言模型的信任度。这种方法提高了预测性能，尤其在视觉和音频任务中表现突出。FESTA的代码开源，为多模态语言模型的信任评估提供了新的实用工具。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.05014", "html_url": "https://arxiv.org/abs/2510.05014", "title": "Think Then Embed: 生成式上下文提升多模态嵌入", "title_en": "Think Then Embed: Generative Context Improves Multimodal Embedding", "authors": "Xuanming Cui,Jianpeng Cheng,Hong-you Chen,Satya Narayan Shukla,Abhijeet Awasthi,Xichen Pan,Chaitanya Ahuja,Shlok Kumar Mishra,Yonghuan Yang,Jun Xiao,Qi Guo,Ser-Nam Lim,Aashu Singh,Xiangjun Fan", "background": "近年来，通用多模态嵌入（UME）引起了广泛的关注，模型需要生成任务特定的表示。虽然最近的研究表明，多模态大型语言模型（MLLMs）在这些任务上表现出色，但它们通常仅被用作编码器，忽视了其生成能力。然而，这种编码方式在指令复杂且需要组合推理时效果较差。受链式思考推理有效性的启发，本文提出了一种通用的Think-Then-Embed（TTE）框架，该框架由一个推理器和一个嵌入器组成。", "innovation": "1. 通过利用强大的MLLM推理器，我们在MMEB-V2基准上实现了最先进的性能，超过了在大量内部数据集上训练的专业模型。\n2. 为减少对大MLLM推理器的依赖，我们通过高质量的嵌入中心推理轨迹微调了一种较小的MLLM推理器，并且与开源模型相比达到了最好性能，超越最近提出的模型7%的绝对提升。\n3. 我们研究了将推理器和嵌入器整合到一个统一模型中的策略，提高了效率，同时不牺牲性能。", "conclusion": "本文提出了一种Think-Then-Embed框架，通过利用强大的MLLM推理器和高质量的推理轨迹微调小模型，显著提升了多模态嵌入任务的性能，并探索了高效的模型整合策略。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.01543", "html_url": "https://arxiv.org/abs/2508.01543", "title": "Refine-n-Judge：为LLM微调编排高质量偏好链", "title_en": "Refine-n-Judge: Curating High-Quality Preference Chains for LLM-Fine-Tuning", "authors": "Derin Cayir,Renjie Tao,Rashi Rungta,Kai Sun,Sean Chen,Haidar Khan,Minseok Kim,Julia Reinspach,Yue Liu", "background": "大型语言模型（LLMs）通过基于偏好的微调展示了显著的进步，这在很大程度上取决于基础训练数据的质量。虽然人类反馈对于提升数据质量至关重要，但它成本高昂且难以扩展。", "innovation": "本文介绍了Refine-n-Judge，这是一种自动迭代方法，利用单个LLM作为润饰者和评判者来提升数据集质量。与现有的迭代润饰方法不同，Refine-n-Judge使LLM不仅可以生成润饰，还可以明确评估每项改进，确保每次迭代都能真正提升数据集，而无需额外的人工注释或单独的奖励模型。R-J方法在每一步中都让LLM对响应进行润饰，并判断润饰是否比之前的答案更好。这个过程会一直持续到LLM更喜欢最初的答案而不是润饰，表明不再有改进的空间。这种方法会产生逐步提高质量、带有偏好的回应，非常适合微调。", "conclusion": "Refine-n-Judge在广泛的公共数据集上显示出有效性，这些数据集涵盖了五个语料库，针对的任务包括编程、数学和对话。使用Refine-n-Judge提升的数据集微调的模型在超过74%的情况下被LLM评委偏好于使用GPT-4微调原数据集的模型。此外，还报告了性能提升：在AlpacaEval和AlpacaEval 2.0上增长5%，在MT-Bench上增长19%。结果表明，Refine-n-Judge能够生成高质量的数据集并实现可扩展的模型改进。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.19771", "html_url": "https://arxiv.org/abs/2510.19771", "title": "超越被动反应：LLM代理的主动问题解决度量", "title_en": "Beyond Reactivity: Measuring Proactive Problem Solving in LLM Agents", "authors": "Gil Pasternak,Dheeraj Rajagopal,Julia White,Dhruv Atreja,Matthew Thomas,George Hurn-Maloney,Ash Lewis", "background": "近年来，基于大型语言模型（LLM）的代理越来越多地表现出主动性，即在等待指令之前通过预判用户需求并自主解决问题。然而，评估这种主动性仍是具有挑战性的工作。目前大多数基准测试只能局限于局部上下文，无法充分测试跨多种来源及更长时间段的推理能力。鉴于此，本文提出了一种新的指标体系PROBE，旨在解决这一问题。PROBE将主动性分解为搜索未指定的问题、识别具体瓶颈和执行适当解决步骤的三个核心能力阶段。该研究通过应用PROBE对最先进模型和流行代理框架进行评估，展示了这些模型在解决基准测试问题上的难点，同时也详细分析了各个模型的能力对比及共同失败模式，揭示了自主操作在代理系统中存在的限制，并指出了未来研究的方向和可能领域。", "innovation": "该研究提出的PROBE提供了一个新的框架，用于评估LLM代理的主动性，它将主动性分解为三个核心能力阶段，即搜索未指定的问题、识别具体瓶颈和执行适当解决步骤。这一框架能够评估代理能够处理的跨多种来源和更长时间段的推理能力。", "conclusion": "本研究发现，不管是在GPT-5和Claude Opus-4.1中的哪一种模型，端到端的最佳表现也只有40%。总之，这项研究明确了代理系统当前在自主操作方面的局限性，同时也为未来的研究指明了方向。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.21257", "html_url": "https://arxiv.org/abs/2507.21257", "title": "CompoST: 一个分析大语言模型在QALD设置下进行组合解释问题能力的基准", "title_en": "CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting", "authors": "David Maria Schmidt,Raoul Schubert,Philipp Cimiano", "background": "语言解释是一个组合过程，其中通过推断单词部分的意义来推断更复杂的语言结构的意义。大语言模型具备非凡的语言解释能力，并成功应用于将问题映射为SPARQL查询。然而，这一过程是否系统性的仍未明确。基于此，本文提出了一种基准测试方法，旨在研究大语言模型解释问题的能力是否真正具有组合性。基于DBpedia中的图模式，根据Lemon词汇对问题进行不同难度层次的生成，以评估大语言模型在已见原子构件的情况下解释复杂问题的能力。通过不同规模模型的实验，和不同时隙优化技术及微调，研究发现性能在宏$F_1$值上随着与训练样本偏差的增大而逐渐下降，即使是提供了所有必要信息，低复杂性数据集的$F_1$值也未超过0.57。因此，基于这些结果可以得出结论，大语言模型在系统性且组合性地解释问题和映射为SPARQL查询方面存在困难.", "innovation": "本文提出了名为CompoST的新基准测试，旨在研究大语言模型解释问题的能力是否真正是组合性的。通过结构复杂的数据库模式生成不同难度的数据集，并结合柠檬词汇进行标注，CompoST为研究大语言模型在特定情境下解释复杂问题的能力提供了一种控制良好的方法。此外，通过对不同规模模型、不同预设提示等技术的实验，进一步验证了模型在解释复杂问题时的困难性.", "conclusion": "实验结果表明，大语言模型在解释系统性和组合性地解释问题并将它们映射为SPARQL查询上面临挑战。即使提供了所有必要信息，低复杂性数据集上的$F_1$值也未超过0.57，反映了大语言模型在解释复杂问题时的局限性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2305.17608", "html_url": "https://arxiv.org/abs/2305.17608", "title": "大型语言模型对齐中的奖励坍塌", "title_en": "Reward Collapse in Aligning Large Language Models", "authors": "Ziang Song,Tianle Cai,Jason D. Lee,Weijie J. Su", "background": "大型语言模型（LLMs）如ChatGPT和GPT-4展现出了非凡的能力，这是通过将它们与基于人类偏好的奖励模型对齐实现的，这些偏好的往往是问答对的排名形式。在训练后期，普遍使用的基于排名的方法会导致在面对开放性或特定性问题时，奖励分布一致化，抑制了模型灵活性的问题。", "innovation": "本文指出奖励坍塌现象，即基于排名的目标函数无法有效结合提示信息导致奖励分布一致性问题，并提出了一种基于提示感知的优化方案，这种方法能够实现在插值范围内提示依赖的奖励分布，从而有效缓解了奖励坍塌的问题。", "conclusion": "本文通过理论分析揭示了奖励坍塌的主要原因，并提出了一种提示感知的优化方案，实验结果表明，该方案显著减少了训练奖励模型过程中奖励坍塌的现象。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23216", "html_url": "https://arxiv.org/abs/2510.23216", "title": "在现实足球模拟中的类人守门员：一种样本高效强化学习方法", "title_en": "Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach", "authors": "Alessandro Sestini,Joakim Bergdahl,Jean-Philippe Barrette-LaPierre,Florian Fuchs,Brady Chen,Michael Jones,Linus Gisslén", "background": "尽管多种流行的电子游戏曾用于深度强化学习 (DRL) 的测试平台，但该技术尚未被游戏行业广泛用于创建真实的人工智能行为。之前的研究主要集中在用大型模型训练超人类智能体，这不适合那些资源有限且追求人类智能水平的开发者。本文提出了一种针对工业环境（特别是视频游戏行业）高效训练和微调代理的样本高效 DRL 方法。该方法通过利用预收集的数据和提高网络的可塑性来提高基于价值的 DRL 的样本效率。", "innovation": "提出了一种样本高效的 DRL 方法，该方法适用于工业环境中的代理训练和微调。该方法通过利用预收集的数据来提高基于价值的 DRL 的样本效率，并通过增加网络的可塑性进一步优化了效率。方法在 EA SPORTS FC 25 中进行测试，该款游戏是当前销售最好的足球模拟游戏之一，实验中所训练的守门员代理在救球率上比游戏中内置的 AI 高出 10%。消除实验表明，与标准 DRL 方法相比，该方法不仅能提高训练效率 50%，还能生成更接近人类的游戏策略。", "conclusion": "该方法已经应用于该系列最新版本的开发中，证明了其可应用性和对游戏中的真实_ai_行为的贡献。领域的专家评估表明，该方法生成的代理具有更真实的游戏玩法，对比手工编写的代理更加自然。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2405.09086", "html_url": "https://arxiv.org/abs/2405.09086", "title": "混沌基强化学习与TD3", "title_en": "Chaos-based reinforcement learning with TD3", "authors": "Toshitaka Matsuki,Yusuke Sakemi,Kazuyuki Aihara", "background": "混沌基强化学习（CBRL）是一种利用代理内部混沌动力学驱动探索的强化学习方法。然而，以往的研究中对CBRL的学习算法开发不足，并且未结合最近的强化学习进步。", "innovation": "本文引入了TD3算法，这是一种先进的深度强化学习算法，能够处理确定性和连续的动作空间，并将其应用于CBRL中。验证结果表明，TD3可以作为CBRL的学习算法，并且CBRL代理随学习进展可以自主抑制探索行为，当环境变化时则重新恢复探索。此外，研究还分析了代理混沌性对学习的影响，发现代理模型中的适中混沌强度范围可以灵活切换探索和利用，并适应环境变化。", "conclusion": "该研究通过结合TD3算法，为CBRL提供了一种有效的学习方法，并展示了TD3在CBRL中驱动代理探索和学习的能力，以及在环境变化时调整探索和利用策略的能力。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23925", "html_url": "https://arxiv.org/abs/2510.23925", "title": "隐含链式思考在视觉推理中的应用", "title_en": "Latent Chain-of-Thought for Visual Reasoning", "authors": "Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao", "background": "链式思考（CoT）对于提高大型视觉-语言模型（LVLMs）的可解释性和可靠性至关重要。然而，现有的训练算法，如SFT（强化学习策略）、PPO（策略梯度算法）和GRPO（渐进式电视图优化），可能无法在未见过的推理任务中很好地泛化，并且高度依赖有偏的奖励模型。", "innovation": "本文将LVLMs的推理重新定义为后验推理，并提出了一种基于近似变分推断的可扩展训练算法。通过利用多样性的强化学习算法，引入了一种用于标记级学习信号的新型稀疏奖励函数，激励多样、高似然的隐含CoT，克服了确定性采样限制，并避免了奖励作弊。此外，还实现了一种贝叶斯推断扩容策略，用边缘似然取代昂贵的Best-of-N和短语搜索，以高效地对最优理据和答案进行排名。", "conclusion": "实验证明，所提出的方法在视觉推理基准测试中的七个方面增强了最先进的LVLMs，在有效性、泛化能力和可解释性方面表现出色。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23595", "html_url": "https://arxiv.org/abs/2510.23595", "title": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution", "title_en": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution", "authors": "Yixing Chen,Yiding Wang,Siqi Zhu,Haofei Yu,Tao Feng,Muhan Zhang,Mostofa Patwary,Jiaxuan You", "background": "强化学习（RL）在增强大型语言模型（LLMs）的推理能力方面显示出巨大的潜力。然而，其成功很大程度上依赖于精心制作的数据集和可验证的奖励，这限制了其可扩展性和通用性。近期的自我博弈RL方法借鉴了在游戏领域取得的成功，旨在在不依赖人类标注数据的情况下增强LLMs的推理能力。然而，当前方法主要依赖于具体环境来提供反馈，如Python解释器或游戏引擎，将其扩展到更广泛的领域仍然是一个挑战。因此，这篇论文提出了一种名为Multi-Agent Evolve (MAE)的新框架，它使LLMs能够在解决多样化的任务中自我进阶，包括数学、推理和一般知识问答任务。", "innovation": "MAE的核心设计基于一个相互作用的三元组合（提出者、解决者、评判者）的交互，这三者都源自单一的LLM，通过强化学习优化各个代理的行为。提出者生成问题，解决者尝试求解，而评判者评估反馈同时与之共同发展。这种框架旨在减少对人类标注数据的依赖，提高LLMs的通用推理能力。实验结果表明，MAE在Qwen2.5-3B-Instruct基准测试中平均提高了4.54%的成绩，展示了其在增强LLMs的推理能力方面的有效性和数据效率。", "conclusion": "MAE作为一种可扩展且数据效的增强LLMs通用推理能力的方法，通过较少依赖于人工标注监督表现出较大的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2403.08788", "html_url": "https://arxiv.org/abs/2403.08788", "title": "VerifIoU - 对象检测对扰动的鲁棒性", "title_en": "VerifIoU - Robustness of Object Detection to Perturbations", "authors": "Noémie Cohen,Mélanie Ducoffe,Ryma Boumazouza,Christophe Gabreau,Claire Pagetti,Xavier Pucel,Audrey Galametz", "background": "介绍了新型的区间界限传播（IBP）方法，用于形式化验证对象检测模型，特别针对交并比（IoU）指标。该方法已在开源代码IBP IoU中实现，兼容基于抽象解释的验证工具，已应用于着陆方法跑道检测和手写数字识别案例研究中。与基线（纯IBP IoU）进行比较，强调了IBP IoU在保证准确性和稳定性方面的优越性能，为更安全和稳健的机器学习应用做出了贡献。", "innovation": "提出了一种新型的区间界限传播（IBP）方法，专门针对检测模型的交并比（IoU）指标进行形式化验证。该方法已经开源，并能与流行的抽象解释验证工具兼容。在跑道检测和手写数字识别的实验中，显示了该方法的优越性能和稳定性。", "conclusion": "验证了提出的验证器在保证准确性和稳定性方面的优越性能，提高了对象检测模型的安全性和鲁棒性，为机器学习应用提供了更可靠的基础。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23127", "html_url": "https://arxiv.org/abs/2510.23127", "title": "迷失于分词：高阶语境是解锁科学大语言模型中生物分子理解的关键", "title_en": "Lost in Tokenization: Context as the Key to Unlocking Biomolecular Understanding in Scientific LLMs", "authors": "Kai Zhuang,Jiawei Zhang,Yumou Liu,Hanqun Cao,Chunbin Gu,Mengdi Liu,Zhangyang Gao,Zitong Jerry Wang,Xuanhe Zhou,Pheng-Ann Heng,Lijun Wu,Conghui He,Cheng Tan", "background": "科学大型语言模型（Sci-LLMs）在加速生物发现方面展现出巨大潜力，但它们在处理生物分子序列（例如蛋白质和DNA）时面临一个根本挑战：分词问题。将序列视为特殊的语言可能会丢失重要功能模式信息，作为单独的模态则会导致难以解决的对齐问题，当前策略实质上限制了模型的推理能力。研究者们通过系统性对比多个领先的科学大语言模型在生物推理任务中的表现，发现仅提供高阶结构化语境（context-only）的表现始终优于其他方式。甚至耦合原始序列和高阶语境还会降低模型性能，表明原始序列可能是信息噪音，即使模型具备专门的分词方案也是如此。研究结果表明，现有的科学大语言模型的主要优势不在于能够从零开始理解生物分子语法，而在于能够在结构化的、人类可读的知识上进行深刻的推理。", "innovation": "研究者提出了一种创新的策略，即让科学大语言模型接受源自成熟生物信息学工具的高层次结构化上下文，以绕过直接处理低层次、扰动的序列数据的需要。相比仅提供序列信息或序列和上下文的组合，单独提供高阶上下文在生物理任务上表现出更高的性能，表明原始序列可能对该类模型起到了噪音作用。这建议将科学大语言模型重新定位为强大的基于专家知识的推理引擎，而不是序列解析器。研究还为新的混合科学AI代理打下了基础，重点从直接序列解释转向高层次知识合成。", "conclusion": "研究结果强调，科学大语言模型的主要力量在于处理结构化的人类可读知识上，而不仅仅是直接解释生物分子序列。科学大语言模型应作为强大的基于专家知识的推理引擎来重新定义，而不是作为单纯的序列解析器。该研究为开发新的科学AI代理开辟了新的视角，重点是高层次知识合成而不是直接序列解释。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.05948", "html_url": "https://arxiv.org/abs/2406.05948", "title": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models", "title_en": "Chain-of-Scrutiny: Detecting Backdoor Attacks for Large Language Models", "authors": "Xi Li,Ruofan Mao,Yusen Zhang,Renze Lou,Chen Wu,Jiaqi Wang", "background": "大型语言模型（LLMs），特别是通过API访问的模型，在各个领域展现了强大的能力。然而，缺乏技术背景的用户可能会转向不可靠的第三方服务，如指令工程，以提升其LLM的体验，从而增加了对抗性攻击（如后门攻击）的风险。传统防御策略主要用于小型模型，对于API可访问的LLMs来说，因模型访问限制、高昂的计算成本和数据需求，这些策略变得不实用。", "innovation": "我们提出了一种名为Chain-of-Scrutiny（CoS）的新方法，利用LLMs独特的推理能力来缓解后门攻击。CoS引导LLM为给定输入生成推理步骤，并监督这些步骤的一致性与最终输出的对比，任何不一致都可能指示潜在攻击。CoS特别适合流行的仅API部署的LLM，可实现低成本、少数据的检测，并且易于非专家使用，保持透明度。", "conclusion": "我们通过在多项任务和多种LLM上的广泛实验验证了CoS的有效性，结果显示它在更强大的LLM上能提供更大的益处。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2407.17489", "html_url": "https://arxiv.org/abs/2407.17489", "title": "AI的社会力场：重塑人机团队中的分布式认知", "title_en": "AI's Social Forcefield: Reshaping Distributed Cognition in Human-AI Teams", "authors": "Christoph Riedl,Saiph Savage,Josie Zvelebilova", "background": "AI不仅仅是团队设置中的中立工具，它还积极地重新塑造了协作中的社会和认知结构。研究显示，暴露在AI生成的语言中不仅影响人们的言语表达，还会改变他们的思维方式、注意力焦点以及彼此间的关系。这些发现揭示了AI参与如何重新组织团队的分布式认知架构：AI系统作为无形的社会力量场发挥作用。", "innovation": "本文提出了一个统一的框架，解释了人类和AI在团队中的协调过程，即语言、认知和社会共构一个共享的表征空间。\n通过两项研究展示了AI生成的语言不仅影响人说话的方式，也影响他们思考、注意以及相互之间如何互动的方式。这揭示了AI参与如何重塑团队的认知结构，强调了AI作为社会有影响力的行动者的双重影响。", "conclusion": "本文强调了AI在团队中的双重影响：既有助于高效的协作，也可能削弱认识多样性，破坏自然的对齐过程。提出了重新思考AI在团队中的角色，即作为具有社会影响力的行动者，并呼吁设计新的设计范例，以透明性、可控性和组级动态为核心，促进负责任和高效的人机协作。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2409.06263", "html_url": "https://arxiv.org/abs/2409.06263", "title": "Speak & Spell: LLM-Driven Controllable Phonetic Error Augmentation for Robust Dialogue State Tracking", "title_en": "Speak & Spell: LLM-Driven Controllable Phonetic Error Augmentation for Robust Dialogue State Tracking", "authors": "Jihyun Lee,Solee Im,Wonjun Lee,Gary Geunbae Lee", "background": "对话状态跟踪（DST）是任务导向对话系统的关键组成部分，用于识别对话中的重要信息。然而，在口语对话环境中，由于自动语音识别（ASR）系统中的命名实体错误，其准确性会显著下降。现有方法在处理这些错误时存在局限性，因此亟需一种简单且有效的数据增强方法来提高DST模型的鲁棒性。我们的新方法通过可控地在关键词上引入同音词错误，从而在ASR噪声和低准确率环境中提高了准确性。", "innovation": "我们提出了一种简单而有效的数据增强方法，针对ASR系统中的命名实体错误，通过关键词提示引入可控的同音词错误。该方法能够在不创建过多错误模式的情况下，生成充足的关键词错误模式，从而在噪声和低准确率ASR环境中提高了DST模型的准确性。", "conclusion": "通过使用LLM驱动的可控同音词错误增强方法，我们在ASR噪声和低准确率环境中显著提高了DST模型的鲁棒性和准确性。这一方法为提升口语对话系统中的对话状态跟踪性能提供了新的思路。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2406.08525", "html_url": "https://arxiv.org/abs/2406.08525", "title": "在神经网络中对正性条件的数学认证及其在部分单调性和可信AI中的应用", "title_en": "A mathematical certification for positivity conditions in Neural Networks with applications to partial monotonicity and Trustworthy AI", "authors": "Alejandro Polo-Molina,David Alfaya,Jose Portela", "background": "人工神经网络（ANNs）已成为处理大规模数据集中的复杂关系的强大工具，但由于其黑盒性质，可信度成为一个挑战。在某些情况下，为了确保预测的信任度，可能需要遵循特定的部分单调性约束。但是，验证已经训练的ANN是否满足部分单调性是一项艰巨的任务。因此，在诸如信用评分等需要部分单调性的关键应用中，ANN往往被规避使用。", "innovation": "本文提出了一种名为LipVor的新算法，该算法基于有限次评估验证黑盒模型（如ANN）的正性。由于部分单调性可以作为部分导数的正性条件表达，LipVor可以验证ANN是否满足部分单调性。LipVor通过Lipschitzianity特性构建特定邻域，确保函数的正性，并基于评估点的Voronoi图陈述充分条件来验证函数在域内的正性。此外，该方法还能够验证ANN的其他性质，如凸性，进一步提升了其应用范围。", "conclusion": "LipVor算法能够确保在无需受限架构或分段线性激活的情况下认证部分单调性，从而开启了在关键领域使用无约束ANN的可能性。这种认证方法对于提高AI的可信度具有重要意义，有助于推动可信AI的发展。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2412.17883", "html_url": "https://arxiv.org/abs/2412.17883", "title": "捍卫事后解释方法", "title_en": "In Defence of Post-hoc Explainability", "authors": "Nick Oh", "background": "本文针对事后解释方法在机器学习领域中的可靠性及其认识论地位受到的批评进行了辩护。", "innovation": "本文提出了一个基于中介理解和有界知觉的哲学框架，旨在展示如何通过结构化解释模型行为来生成科学洞察，而无需完全的机制透明性。作者强调解释需要承认其近似性并且经过严格的实证验证。同时，通过分析最新的生物医学机器学习应用，展示了当事后方法适当整合到科学研究中时，能够产生新的假设并推进现象理解。", "conclusion": "本文通过分析生物医学机器学习应用，论证了在适当整合到科学研究中时，事后解释方法可以产生新的假设并推进现象理解。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.12652", "html_url": "https://arxiv.org/abs/2410.12652", "title": "受限后验采样：具有硬约束的时间序列生成", "title_en": "Constrained Posterior Sampling: Time Series Generation with Hard Constraints", "authors": "Sai Shankar Narasimhan,Shubhankar Agarwal,Litu Rout,Sanjay Shakkottai,Sandeep P. Chinchali", "background": "生成逼真的时间序列样本对于压力测试模型和使用合成数据保护用户隐私至关重要。在工程和安全关键应用中，这些样本必须满足特定的、领域特定的或自然由物理或自然界设定的约束条件。例如，生成具有高峰需求时间约束的电力需求模式，可以在不良天气条件下测试电网的运行状况。现有的生成受限时间序列的方法要么不具扩展性，要么降低样本质量。", "innovation": "本文引入了一种称为受限后验采样（CPS）的基于扩散的采样算法，该算法旨在在每次去噪更新后将后验均值估计投影到约束集中。最显著的是，CPS 能够处理大量的约束（约 100 个）且不需要额外训练。文中提供了理论证明，说明我们的投影步骤对采样的影响。实验结果显示，CPS 在样本质量和与实际时间序列的相似性上分别比最新方法高出约 70% 和 22%，在实际股票、交通和空气质量数据集上表现突出。", "conclusion": "本文介绍了一种名为受限后验采样（CPS）的新方法，该方法可以在处理大量硬约束的同时保持样本质量，显著优于现有方法。此方法为工程和安全关键应用中的时间序列生成提供了新的解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2410.12869", "html_url": "https://arxiv.org/abs/2410.12869", "title": "使用多个弱评估器的语言模型偏好评估", "title_en": "Language Model Preference Evaluation with Multiple Weak Evaluators", "authors": "Zhengyu Hu,Jieyu Zhang,Zhihan Xiong,Alexander Ratner,Kaize Ding,Ranjay Krishna", "background": "尽管大规模语言模型（LLMs）取得了显著的成功，但针对输出质量的偏好评估仍然是一个关键挑战。现有研究通常使用一个强大的LLM作为裁判来比较LLM响应对之间的性能，但这种方法容易出现循环偏好问题，即输出A优于B，B优于C，但C优于A，导致评价结果矛盾。现有方法不能有效解决这一问题，因此需要新的策略来提高评估结果的一致性和可靠性。", "innovation": "本文引入了PGED（偏好图集成和去噪），这是一种新颖的方法，利用多个基于模型的评估器构建偏好图，并通过集成和去噪这些图以获得无循环的、无矛盾的评价结果。这种方法提供了理论保障，证明其在恢复真实偏好结构方面的有效性。通过广泛的实验，PGED 在模型排名、测试时扩展响应选择以及数据选择方面优于现有的基于多个弱评估器的方法，展示了其在提升评价可靠性和改进模型性能方面的有效性。", "conclusion": "PGED 在十个基准测试上展示了其在模型排名、测试时响应选择和模型微调数据选择方面的优越性。通过整合小型LLM评估器（例如，Llama3-8B、Mistral-7B、Qwen2-7B）来超越强大的评估器（例如，Qwen2-72B），PGED 验证了其在增强评估可靠性和提高模型性能方面的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2501.05783", "html_url": "https://arxiv.org/abs/2501.05783", "title": "UV-Attack：基于动态NeRF的UV映射的人体检测物理世界对抗攻击", "title_en": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping", "authors": "Yanjie Li,Kaisheng Liang,Bin Xiao", "background": "近期研究中，针对使用补丁或静态3D模型纹理修改的人体检测器的对抗攻击成功率较低，这主要是因为人类动作带来的3D变形难以建模。动态NeRF在动态人体建模方面取得了进展，为解决这一问题提供了新的可能性。", "innovation": "提出了基于动态NeRF的UV映射的UV-Attack方法，能够在广泛的、未见过的人体动作下实现高成功率。这种方法生成UV图而不是RGB图像，并且修改纹理堆栈，使攻击更实时、更实用。同时提出了新的期望姿态变换损失（EoPT），进一步提高了对未见过的姿态和视角的攻击成功率。", "conclusion": "实验结果显示，UV-Attack在动态视频设置中对FastRCNN模型的各种姿态的攻击成功率达到了92.7%，远远超过了最新的AdvCamou攻击。在黑盒设置下，对YOLOv8检测器的成功率达到了49.5%。这项工作展示了动态NeRF及UV映射在创建更有效的对抗攻击方面的潜力，解决了建模人类动作和纹理修改的关键挑战。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.04380", "html_url": "https://arxiv.org/abs/2502.04380", "title": "作为回报的多样性：在不确定领域数据混合中微调LLMs", "title_en": "Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data", "authors": "Zhenqing Ling,Daoyuan Chen,Liuyi Yao,Qianli Shen,Yaliang Li,Ying Shen", "background": "大型语言模型（LLMs）的微调对于提升其跨领域整体性能至关重要。现有方法在处理缺失、不精准或未规范化领域标签的数据时常常面临困难，而基于数据选择的方法则难以平衡多领域的表现。为解决这些挑战，本研究探讨了数据多样性在提升LLMs整体能力中的作用，通过经验构建对照数据池并理论推导解释，提出了一个新方法，让LLMs具有双重身份：一个输出模型通过多样性的奖励探索和选择数据，另一个输入模型则使用所选数据进行调整。广泛的实验显示，该方法在各种先进的LLMs上显著提升了对不确定领域数据和一系列基础下游任务的性能。", "innovation": "提出了一种新的方法，让LLMs具有双重身份：一个输出模型根据多样性奖励来认知地探查和选择数据，另一个输入模型使用所选数据进行调整。这种方法在不确定领域数据和一系列基础下游任务中显著提高了性能，尤其是在各种先进的LLMs上得到了验证。", "conclusion": "通过提出的新方法，我们在不确定领域数据和一系列基础下游任务中显著提升了LLMs的性能。我们希望这项研究能够增进对数据多样性的理解，并推动LLMs的反馈驱动的数据-模型协同设计。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2502.09969", "html_url": "https://arxiv.org/abs/2502.09969", "title": "基于神经网络的可学习且可扩展的指令微调数据影响估计方法", "title_en": "Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data", "authors": "Ishika Agarwal,Dilek Hakkani-Tür", "background": "影响函数对于模型训练具有关键性见解，但现有方法存在大量计算成本和有限泛化能力的问题。特别是，近期研究提出了一系列度量和算法来通过语言模型计算数据的影响。然而，这些方法不适合大型模型和数据集，因为它们需要昂贵的前向和反向传播计算，需要大量内存存储大型模型，并且影响估计对新数据泛化不良。", "innovation": "本文探索使用小型神经网络（称为InfluenceNetwork）来估计影响值，实现了高达99%的成本降低。我们提出了一个算法（称为NN-CIFT: 基于神经网络的高效指令微调）来估计影响值，并将其应用于通用指令微调的子集选择任务。我们在实验中展示了该方法在不牺牲性能的情况下提供了显著的加速。此外，我们还详细分析了NN-CIFT的超参数。", "conclusion": "我们提出的方法能够用模型仅占全语言模型0.0027%大小的方式估计影响值。尽管NN-CIFT提供了显著的加速性能，但其在四个最先进的影响函数中的表现却无明显妥协。我们的研究展示了如何基于神经网络高效、可扩展地估计指令微调数据的影响。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.02631", "html_url": "https://arxiv.org/abs/2503.02631", "title": "从人机协作视角对生成人工智能时代数据讲故事工具的反思", "title_en": "Reflection on Data Storytelling Tools in the Generative AI Era from the Human-AI Collaboration Perspective", "authors": "Haotian Li,Yun Wang,Huamin Qu", "background": "数据分析讲故事的人机协作工具引起了数据讲故事社区的关注，以降低专业知识门槛并简化工作流程。近年来，大型生成人工智能技术，例如大规模语言模型（LLMs）和文本转图像模型的发展，有可能通过其视觉和叙述生成能力提升数据讲故事的效果。自这些技术公开以来已有两年时间，因此反思它们的应用进展并展望未来的机会变得重要。", "innovation": "本书比较了最新工具与早期工具的人机协作模式，使用专门的框架来理解数据讲故事中的人机协作。识别出了一种稳定的研究模式，即人类创作者+人工智能助手，以及一种新探索或新兴模式，即人工智能创作者+人类审查者。揭示了这些人工智能技术的优势及其对人机协作的影响。此外，提出了未来方向，以激发创新。", "conclusion": "反思了生成人工智能时代工具的使用进展，并对人机协作模式进行了比较分析，识别出不同的协作模式，探讨了人工智能技术的优势及其对未来人机协作的潜在影响。提出了未来的研究方向，希望能够推动该领域的创新。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.00333", "html_url": "https://arxiv.org/abs/2503.00333", "title": "更多同一种事物：在增加代表性情况下持续存在的表征性损害", "title_en": "More of the Same: Persistent Representational Harms Under Increased Representation", "authors": "Jennifer Mickel,Maria De-Arteaga,Leqi Liu,Kevin Tian", "background": "为了识别并减轻生成式AI系统的危害，我们需要考虑AI输出中的人类代表性和呈现方式。未经批判性审视地提高代表性忽略了对代表方式的努力改善，可能导致持续存在的表征性偏见和损害。本文通过分析最先进的大型语言模型中的职业性别分布，探讨了随着时间的推移，模型改善了性别代表性但性别表征并未缓解偏见的问题。", "innovation": "本文创新点在于对性别在职业呈现中的变化进行长期跟踪研究，并揭示尽管提高了女性的代表性，但性别表征偏见依然存在。通过分析性别之间统计学差异的词汇，证明了虽然有增加女性代表性的干预措施，但这些措施并没有根本性地解决偏见问题。", "conclusion": "尽管AI生成系统的性别代表性有所提高，但表征性偏见依然存在，并且导致了表征性危害、刻板印象和新自由主义思想的扩散。这表明仅仅通过增加代表性的数量无法解决内在的表征偏见问题，需要进一步的具体偏见缓解措施。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.02878", "html_url": "https://arxiv.org/abs/2503.02878", "title": "语言模型可以在状态价值估算中自我提升以改进搜索", "title_en": "Language Models can Self-Improve at State-Value Estimation for Better Search", "authors": "Ethan Mendes,Alan Ritter", "background": "在多步推理任务中，特别是交互式领域如网络任务中，收集准确的奖励数据或人类演示常常是成本高昂的。当前方法倾向于直接回归数值奖励，这在标注数据稀缺的情况下效率低下。", "innovation": "该研究引入了Self-Taught Lookahead (STL)框架，这是一个无奖励框架，通过语言模型推理状态转换的链式思考，来改进基于语言模型的价值函数。STL无需标注数据即可训练语言模型模拟一步前瞻，预测下一步动作、状态及其价值解释，从而提高价值估计的准确性。", "conclusion": "实验结果表明，基于中等规模（8B参数）开源语言模型训练的STL值模型能够将网络智能代理的成功率提高39%，并在跳步QA和数学谜题任务上表现出色。此外，STL使得小型开源模型能够引导高效的搜索，降低了推理成本，同时结合了价值学习和显式推理。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.20138", "html_url": "https://arxiv.org/abs/2503.20138", "title": "基于指导模型融合的混合数据学习：利用中心化数据精炼去中心化模型", "title_en": "Guided Model Merging for Hybrid Data Learning: Leveraging Centralized Data to Refine Decentralized Models", "authors": "Junyi Zhu,Ruicong Yao,Taha Ceritli,Savas Ozkan,Matthew B. Blaschko,Eunchung Noh,Jeongwon Min,Cho Jung Min,Mete Ozay", "background": "当前网络训练范式主要集中在中心化或去中心化数据集上。然而，实践中数据可用性往往呈现出混合性质，即这两种模式共存。这种混合设置为模型训练提供了新的机会，因为两者提供了互补的权衡：去中心化数据丰富但受异质性和通信约束的影响，而中心化数据虽然在数量上有限且可能代表性不足，但使得更好地策划和高吞吐量访问成为可能。尽管如此，有效地结合这两种范式仍然具有挑战性，且很少有框架针对混合数据集进行定制。", "innovation": "本文提出了一种新颖的框架，该框架从去中心化模型中构建模型地图，并利用中心化数据在该结构化空间中细化全球模型。然后使用此细化模型重新初始化去中心化模型。该方法结合了联邦学习（以利用去中心化数据）和模型合并（以利用中心化数据），从而在混合数据可用性情况下实现有效的训练。理论上证明，我们的方法通过合并过程中的方差减少，比仅依赖去中心化数据的方法实现更快的收敛。", "conclusion": "我们的框架在广泛实验中表现优于纯粹中心化、纯粹去中心化以及现有的混合适配方法。值得注意的是，即使中心化和去中心化数据领域不同或去中心化数据包含噪声，我们的方法也能保持稳健，这显著增加了其适用性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.00254", "html_url": "https://arxiv.org/abs/2505.00254", "title": "借助视频语言模型赋能自主视频分析系统", "title_en": "Empowering Agentic Video Analytics Systems with Video Language Models", "authors": "Yuxuan Yan,Shiqi Jiang,Ting Cao,Yifan Yang,Qianqian Yang,Yuanchao Shu,Yuqing Yang,Lili Qiu", "background": "AI驱动的视频分析已在多个领域变得越来越重要，但现有系统通常局限于特定、预定义的任务，限制了其在开放场景下的适应性。近期，视觉语言模型（VLMs）的出现为开放视频理解、推理和分析带来了潜力。然而，VLMs的有限上下文窗口在处理大量实际应用中的超长视频内容时存在挑战。", "innovation": "该论文提出了一种名为AVA的VLM驱动系统，用于开放领域的高级视频分析。AVA的创新之处在于：(1) 近实时构建事件知识图谱(EKGs)以高效索引长或连续视频流；(2) 利用EKGs实现自主检索生成机制，处理复杂的多变查询。", "conclusion": "在LVBench和VideoMME-Long等公共基准测试中，AVA达到了最先进的性能，并在新提出的AVA-100基准测试中，实现了顶级的75.8%的准确率。此外，研究团队还提供了AVA的源代码和AVA-100基准测试数据集的访问链接。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.10603", "html_url": "https://arxiv.org/abs/2505.10603", "title": "向公开和安全的生成AI迈进：开源和封闭LLM的比较分析", "title_en": "Toward a Public and Secure Generative AI: A Comparative Analysis of Open and Closed LLMs", "authors": "Jorge Machado", "background": "生成人工智能（Gen AI）系统是一种关键性技术，在社会多个领域具有深远的影响。然而，它们的部署伴随一系列风险和挑战，需要细致的评估。目前，缺乏全面的跨学科研究来系统地比较开源和专有（闭源）生成AI系统的优缺点。", "innovation": "本研究旨在：（i）全面评价和比较开源和封闭生成AI模型的特点、机会和挑战；（ii）提议建立一个公开、公共和安全生成AI框架的基本要素。研究采用了结合文献综述、批判性分析和比较分析的方法。研究成果揭示了开源模型在透明度、可追溯性和灵活性方面的优势，而闭源系统则在技术支持和易于实施方面占优，但存在不平等访问、问责性和伦理监督的问题。", "conclusion": "研究强调了多方利益相关者治理、环境可持续性和监管框架的重要性，以确保生成AI的负责任发展。提出的框架强调了开放性、公共治理和安全性作为塑造可信和包容性生成AI未来的关键维度。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.04953", "html_url": "https://arxiv.org/abs/2504.04953", "title": "M-Prometheus: 多语言.open 语言模型评估套件", "title_en": "M-Prometheus: A Suite of Open Multilingual LLM Judges", "authors": "José Pombal,Dongkeun Yoon,Patrick Fernandes,Ian Wu,Seungone Kim,Ricardo Rei,Graham Neubig,André F. T. Martins", "background": "语言模型（LLM）在自动评估长文本方面被广泛应用，但大多数LLM裁判仅针对英语进行了优化，对于提升多语言评估能力的研究较少。这导致非英语语言的自动评估方法质量较低，阻碍了具有更好多语言能力模型的发展。研究表明，选择合适的骨干模型以及采用合成多语言反馈数据训练，可以有效提升多语言裁判的效果。为了弥补这一差距，研究引入了M-Prometheus，一种具备3亿至14亿参数的开放权重多语言LLM裁判，能够在多语言产出的同时提供直接评估与成对比较反馈。M-Prometheus在多种语言的奖励基准测试和文学机器翻译评估中表现出色，能够在解码时显著提升所有测试语言的生成结果。并且，对M-Prometheus模型进行了广泛的研究，确定了获得有效多语言裁判的关键因素。", "innovation": "提出了M-Prometheus，一种包含3亿至14亿参数的开放权重多语言LLM裁判，可用于直接评估和成对比较，同时在多语言奖励基准测试和文学机器翻译评估中都表现出色。此外，研究还发现了有效多语言裁判的关键因素，包括选择合适的骨干模型和采用合成多语言反馈数据进行训练，而不是使用翻译数据进行训练。M-Prometheus模型、训练数据集及代码已经公开发布。", "conclusion": "研究通过M-Prometheus模型的发布，解决了一般LLM只针对英语优化的问题，提升了多语言评估方法的质量，促进了具有更好多语言能力模型的发展。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2503.09499", "html_url": "https://arxiv.org/abs/2503.09499", "title": "MindGYM：思考为中心的微调中问题合成的关键因素？", "title_en": "MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?", "authors": "Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen", "background": "大型基础模型在使用严格模板或众包注释指令数据集监督时，难以获得可转移且有序的思考能力。现有方法侧重于监督学习，依赖于外部输入的数据，而本研究关注一种以思考为中心的数据合成范式，通过模型自我生成且认知引导的数据促使模型进化。", "innovation": "本研究提出了MindGYM，这是一个结构化且可扩展的问题合成框架，包含三个组成部分：(1) 认知思维过程注入，将高层次的推理目标融入模型合成行为；(2) 种子单跳问题合成，生成来自多种语义类型的原子问题以鼓励更广泛的思想；(3) 挑战性的多跳QA合成，基于QA种子组合更复杂的多跳问题，以实现更深入的推理。研究表明，通过本方法生成的合成数据的质量平均高出16.7%，质量方差降低67.91%，强调高质量且自包含的数据对于有效的、以思考为中心的微调至关重要。MindGYM仅使用400个数据样本在MathVision基准测试中表现出高达16%的性能提升，且在不同模型大小和架构中表现出可泛化的改进效果。", "conclusion": "MindGYM通过内置自我挑战机制提升了大型模型的能力，同时减少了对人类干预和资源的需求。研究结果表明，MindGYM对不同模型的性能提升显著，且数据和代码公开，以促进基于内部推理能力驱动的自适应发展基础模型的数据研究。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2504.01001", "html_url": "https://arxiv.org/abs/2504.01001", "title": "零样本基准测试：一种灵活和可扩展的语言模型自动评估框架", "title_en": "Zero-shot Benchmarking: A Framework for Flexible and Scalable Automatic Evaluation of Language Models", "authors": "José Pombal,Nuno M. Guerreiro,Ricardo Rei,André F. T. Martins", "background": "随着语言模型在多模态任务中的功能越来越复杂，自动评估模型变得越来越具有挑战性。目前，开发强大的任务特定自动评估指标变得越来越困难，而人类标注的测试集造价昂贵且资源有限。因此，需要设计可靠的策略来自动化测试数据的创建和评估。不过，之前的尝试要么依赖现有的数据集，要么专注于单一任务。本文提出了零样本基准测试（ZSB）框架，旨在通过利用语言模型同时创建合成测试数据和进行评估，在任何任务中生成高质量的基准。该框架简单且灵活，仅需创建数据生成和评估的提示；适用于数据收集困难或不切实际的跨语言和任务场景；对不同模型具有包容性，随着模型的进步，可以创建更具挑战性的基准。为评估框架的有效性，研究者针对五种纯文本任务和多模态任务创建了基准，并在多种开放式和封闭式系统上进行评估，发现ZSB在评估上的一致性与人类评估高度相关，超过了广泛使用的标准基准。", "innovation": "提出了零样本基准测试（ZSB）框架。该框架通过利用语言模型来创建合成测试数据和进行评估，适用于任何任务，并且能够随着模型的进步逐渐提高基准的挑战性。ZSB简单且灵活，只需分别创建数据生成和评估的提示；适用于数据收集困难或不切实际的跨语言和任务场景；对不同模型具有包容性，适用于不断进化的语言模型。研究表明，该框架的基准在评估上和人类评估高度相关，超越了常用的评估基准。此外，研究还发现开放模型能够创建强有力的基准，而评估者的模型大小和数据集的多样性是关键驱动因素。", "conclusion": "通过创建各种语言和多模态的基准测试，并利用零样本基准测试（ZSB）框架，研究团队展示了不同开放和封闭语言模型在技术上的不同表现。该研究不仅证明了ZSB在真实任务性能上的有效性，还为语言模型研究和开发提供了新的方法。未来研究可以在更多、更复杂的任务上测试该框架的有效性，并进一步探索评估者模型大小和数据集多样性对评价结果的影响。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13308", "html_url": "https://arxiv.org/abs/2505.13308", "title": "在黑暗中寻觅：通过潜在空间中的测试时实例级策略梯度进行推理", "title_en": "Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space", "authors": "Hengli Li,Chenxi Li,Tong Wu,Xuekai Zhu,Yuxuan Wang,Zhaoxin Yu,Eric Hanchen Jiang,Song-Chun Zhu,Zixia Jia,Ying Nian Wu,Zilong Zheng", "background": "大型语言模型（LLMs）在追求人工通用智能（AGI）的过程中，推理能力仍然是一个重大挑战。尽管在模型规模扩增下性能有所提高，但训练算法方面的挑战，如灾难性遗忘，以及新颖训练数据的有限可用性，依然存在。作为替代方案，测试时扩大计算可以不更新参数地提高推理性能。不同于以往专注于词汇空间的方法，本文提出利用潜在空间来实现更有效的推理，并更好地符合测试时扩展的规律。", "innovation": "本文引入了LatentSeek框架，该框架通过显式地在潜在空间中进行测试时实例级适应（TTIA）来增强LLM的推理能力。具体而言，LatentSeek利用策略梯度逐步更新潜在表示，由自动生成的奖励信号进行引导。评测结果显示，LatentSeek在多种推理基准上表现优于基础方法，如链式思维提示和微调方法，并且具有高效率，一般在几次迭代内收敛。这些成果表明，测试时在潜在空间中的扩展具有潜在价值。", "conclusion": "这些发现使LatentSeek成为一个轻量、可扩展且有效的解决思路，用以增强LLM的推理能力。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12275", "html_url": "https://arxiv.org/abs/2505.12275", "title": " Curriculum Abductive Learning", "title_en": "Curriculum Abductive Learning", "authors": "Wen-Chao Hu,Qi-Jie Li,Lin-Han Jia,Cunjing Ge,Yu-Feng Li,Yuan Jiang,Zhi-Hua Zhou", "background": "ABL（Abductive Learning）是一种结合机器学习和逻辑推理的方法，通过一个循环过程，即学习模型预测原始输入的符号概念标签，根据领域知识进行修正并通过 abduction 使用，然后将其反馈回重新培训。然而，因为 abduction 的非确定性，训练过程往往不稳定，尤其是在知识库很大且复杂时，导致 abduction 空间急剧增大，之前的改进工作侧重于在空间内改善候选选择，但通常将知识库视为静态的黑盒。", "innovation": "提出了 Curriculum Abductive Learning（C-ABL），这是一种显式利用知识库内部结构的方法，以解决 ABL 的训练挑战。C-ABL 将知识库划分为一组子知识库，这些子知识库在训练过程中逐步引入，这在训练过程中减少了 abduction 空间，并使模型能够逐步、平滑地引入逻辑，实验表明，C-ABL 在多个任务中比之前 ABL 实现表现更好，大幅提高了训练稳定性、收敛速度和最终精度，尤其是在复杂的知识设置下表现尤为明显。", "conclusion": "C-ABL 实验证明，即使在复杂的知识背景下也能显著提高准确性、稳定性和收敛速度，适用于需要逐步整合逻辑推理的学习任务。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.13904", "html_url": "https://arxiv.org/abs/2505.13904", "title": "学习插入构建神经车辆路线求解器", "title_en": "Learning to Insert for Constructive Neural Vehicle Routing Solver", "authors": "Fu Luo,Xi Lin,Mengyuan Zhong,Fei Liu,Zhenkun Wang,Jianyong Sun,Qingfu Zhang", "background": "神经组合优化（NCO）是解决车辆路径问题（VRPs）的一种有前途的学习方法，无需复杂的手动设计。现有的一些生成型NCO方法通常遵循一种逐步添加未访问节点到部分解决方案中的方式，但这种方法往往导致次优结果。因此，该研究尝试引入插入式范式来提高灵活性和解决方案的质量，提出了一个名为L2C-Insert的新颖学习方法，用于生成型的NCO。", "innovation": "该研究创新性地提出了一种名为L2C-Insert的方法，可以灵活地在当前部分解决方案中的任意有效位置插入未访问节点，增强了解决方案的灵活性和质量。方法中引入了三个关键组件：一种新颖的模型架构用于精确预测插入位置，一种高效的训练方案以优化模型，以及一种高级推理技术以充分利用插入范式带来的灵活性。研究结果表明，L2C-Insert在不同规模的旅行商问题（TSP）和有载车辆路径问题（CVRP）中都实现了优异的性能。", "conclusion": "通过广泛的实验，证实L2C-Insert能够在不同规模的旅行商问题（TSP）和有载车辆路径问题（CVRP）中持续地表现优异，展现了其在解决车辆路径问题上的潜力和优越性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.12191", "html_url": "https://arxiv.org/abs/2505.12191", "title": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum", "title_en": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum", "authors": "Wenquan Lu,Jiaqi Zhang,Hugues Van Assel,Randall Balestriero", "background": "自监督学习（SSL）已成为从未标记数据中提取丰富表示的强大解决方案。然而，SSL研究主要集中在清洁、整理和高质量的数据集上。这导致了在应用SSL于嘈杂数据时仍存在挑战，尤其是在天体物理学、医学成像、地球物理学和金融等领域至关重要的情况下。", "innovation": "本文提出了一种全自监督框架，能够在无需在推理或下游微调阶段使用去噪器的情况下实现噪声鲁棒的表示学习。该方法首先在嘈杂数据上训练一个自监督去噪器，然后使用该去噪器构建一个去噪到噪声的数据课程（即，首次使用去噪样本，然后是噪声样本）以预训练一个自监督主干（例如，DINOv2），并结合一位教师引导的正则化，将噪声嵌入固定在其去噪版本的锚点上。这促进了模型内部化噪声鲁棒性。特别地，去噪器在预训练后可以被丢弃，简化了部署过程。在极端高斯噪声下的ImageNet-1k与ViT-B上，我们的方法在直推精度上的改善超过DINOv2 4.8%，表明去噪器赋能的鲁棒性可以在感知噪声的预训练中自然浮现。", "conclusion": "本文提出了一种无需去噪器即可在自监督学习中获得噪声鲁棒性的方法，并通过实验证明了该方法的有效性，即在噪声数据上预训练可以自然地促进模型的噪声鲁棒性，从而简化了部署过程。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.14604", "html_url": "https://arxiv.org/abs/2505.14604", "title": "让大规模推理模型通过自我制动调校摆脱过度思考", "title_en": "Let LRMs Break Free from Overthinking via Self-Braking Tuning", "authors": "Haoran Zhao,Yuchen Yan,Yongliang Shen,Haolei Xu,Wenqi Zhang,Kaitao Song,Jian Shao,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "大型推理模型（LRMs），如OpenAI o1和DeepSeek-R1，通过生成更长的推理链，显著增强了其推理能力，展现出在多种任务中的出色表现。然而，这种性能提升需要大量冗余推理，导致计算成本增加，并加剧了过度思考的问题。尽管已经有很多方法试图解决过度思考问题，但这些方法通常依赖于外部干预。因此，如何让模型能够自我调节其推理过程，成为减少冗余计算而不损失性能的关键挑战。", "innovation": "本文提出了一种新的框架——自我制动调校（Self-Braking Tuning，SBT），该框架从允许模型自我调节其推理过程的角度出发，消除了对外部控制机制的依赖。该框架通过构建基于标准答案的过思考识别指标，并设计系统方法检测冗余推理，准确识别推理路径中的不必要的步骤，并生成训练信号以学习自我调节行为。此外，该研究还开发了适应推理长度的完整数据构建策略，并引入了一种创新的制动提示机制，使模型能够自然学会在合适的时机终止推理。实验结果表明，该方法可将令牌消耗减少60%以上，同时保持与不受约束的模型相当的准确性。", "conclusion": "本文提出了一种新颖的框架——自我制动调校（SBT），通过使模型能够自我调节其推理过程，减少冗余计算，从而解决了过度思考的问题，实验证明该方法有效且能显著提高效率。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15095", "html_url": "https://arxiv.org/abs/2505.15095", "title": "Nek Minit: 利用实用元认知提示实现澳大利亚和印度英语中可解释的讽刺检测", "title_en": "Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English", "authors": "Ishmanbir Singh,Dipankar Srirag,Aditya Joshi", "background": "讽刺是情感分析中的一个挑战，因为它包含表面和隐含情感之间的不一致。当隐含的情感可能与特定国家或地理区域相关时，这一挑战会加剧。现有一种被称为实用元认知提示（PMP）的认知启发技术，用于实用推理。本文利用PMP技术对澳大利亚和印度英语进行可解释的讽刺检测，并与标准英语数据集进行对比，后者包含讽刺解释。该研究在两个开源大语言模型（GEMMA和LLAMA）上进行评估，结果显示PMP策略的性能优于四种替代提示策略，同时发现替代技巧如行动性提示通过启用外部知识检索来缓解与上下文相关的失败情况。", "innovation": "本文利用了实用元认知提示（PMP）技术，首次将其应用于澳大利亚和印度英语的可解释讽刺检测。研究结果显示，在两个开源大语言模型上应用PMP策略的性能显著优于标准的替代提示策略，并且发现行动性提示可以通过检索外部知识来缓解上下文相关的问题。", "conclusion": "本文评估了PMP技术在生成多种英语变体中的讽刺解释上的性能，并发现PMP策略在所有任务中都优于四类替代策略。此外，我们还发现行动性提示可以缓解与上下文相关的挑战。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21996", "html_url": "https://arxiv.org/abs/2505.21996", "title": "基于交互的视频生成中的世界模型学习", "title_en": "Learning World Models for Interactive Video Generation", "authors": "Taiye Chen,Xun Hu,Zihan Ding,Chi Jin", "background": "有效进行基于行动选择的未来规划需要具备交互性和时空一致性基础世界模型。现有的长视频生成模型因两个主要挑战而限制了其内在的世界建模能力：累积误差和不足的记忆机制。", "innovation": "通过引入交互能力和自回归框架增强图像到视频模型，并揭示了自回归视频生成中的累积误差本难以减少，而不足的记忆机制导致世界模型不一致。提出了带有显式全局状态条件的视频检索增强生成（VRAG），显著降低了长期累积错误并增加了世界模型的时空一致性。同时指出当前自回归生成方法和检索增强生成方法因内部学习能力有限而效果不佳。这项工作揭示了视频世界模型的基本挑战并为改善具有内在世界建模能力的视频生成模型建立了基准。", "conclusion": "本研究为交互式视频生成中的基础世界模型面临的挑战提供了新的视角，并为改进视频生成模型奠定了基础。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.18766", "html_url": "https://arxiv.org/abs/2505.18766", "title": "StyleGuard：通过样式扰动防止基于文本到图像模型的风格模仿攻击", "title_en": "StyleGuard: Preventing Text-to-Image-Model-based Style Mimicry Attacks by Style Perturbations", "authors": "Yanjie Li,Wenxuan Zhang,Xinqi Lyu,Yihao Liu,Bin Xiao", "background": "最近，通过对DreamBooth和Textual Inversion等方法的应用，文本到图像扩散模型被广泛用于风格模仿和个人化定制，但也引发了知识产权保护和生成误导性内容的关注。尽管研究者提出了使用对抗噪声的方法（如Glaze和Anti-DreamBooth）来保护图像免受这些攻击，但最近出现的基于净化的方法（如DiffPure和Noise Upscaling）能够成功攻击这些防御措施，展示了这些方法的局限性。此外，当前方法在模型间转移性有限，降低它们对抗未知文本到图像模型的有效性。", "innovation": "本研究提出了一种新的反模仿方法StyleGuard，该方法引入了一种新的样式损失，该损失在潜在空间中优化风格相关特征，使其远离原始图像，提高了模型无关的转移性。此外，设计了一种新的放大损失，训练期间涉及多个净化器和放大器，以增强扰动的能力，使其能够绕过基于扩散的净化。实验结果表明，StyleGuard在各种变换和净化下具有更强的鲁棒性，有效地对抗了各种模型中的风格模仿，对包括DreamBooth和Textual Inversion在内的不同风格模仿方法也有效。", "conclusion": "StyleGuard在WikiArt和CelebA数据集上的广泛实验表明，它在面对各种变换和净化时表现出色，有效地对抗了各种模型中的风格模仿。此外，还提供了StyleGuard的代码可以在给定的网址上访问。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.15201", "html_url": "https://arxiv.org/abs/2505.15201", "title": "Pass@K 策略优化：解决更困难的强化学习问题", "title_en": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems", "authors": "Christian Walder,Deep Karkhanis", "background": "传统的强化学习（RL）算法对每个问题的每种n>1个解决方案尝试进行独立奖励，这优化了pass@1性能并优先考虑了孤立样本的强度，而牺牲了样本集的多样性和整体效用。这种做法未能充分利用采样能力，限制了探索并最终在更难的问题上未能得到改善。", "innovation": "文中提出了一种新的Pass-at-k策略优化（PKPO）方法，通过在最终奖励上进行转换来直接优化pass@k性能，从而优化最大化联合报酬的样本集。此外，本文贡献了在二元和连续奖励情况下用于pass@k及其梯度的新颖低方差无偏估计器。这种新的优化方法能够在保持pass@1性能的同时，优化pass@k，并允许在训练过程中调节k值，两者共同提高。” 为了验证这种方法，作者对玩具实验进行了验证，展示了其减少方差的特性，并在开源大语言模型GEMMA-2中进行了实际应用测试。", "conclusion": "实验结果表明，我们的方法能够有效地优化目标k值。更高k值可解决更多的难题，而k值的调整则提升了pass@1和pass@k指标。对于困难的任务集，我们的pass@k方法能促进学习，因为它通过对样本集的联合效用进行优先处理从而更好地探索。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2505.21497", "html_url": "https://arxiv.org/abs/2505.21497", "title": "Paper2Poster：从科学论文到多模态海报的自动化", "title_en": "Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers", "authors": "Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr", "background": "学术海报制作是一项至关重要的但极具挑战性的科研交流任务，需要将长篇复杂文档压缩成一张视觉连贯的页面。然而，目前缺乏评估海报生成的基准及指标体系，导致无法有效衡量生成海报的质量。本文旨在解决这个问题。", "innovation": "本文首次构建了一个基于科学论文的海报生成基准及评估指标集，包括视觉质量、文本连贯性、整体评估及PaperQuiz四个方面。同时，提出了一种自上而下的多Agent可视化集成管道，即Parser（解析器）、Planner（规划者）和Painter-Commenter（绘图-评论者）循环，该管道能够将22页论文以经济方式（0.005美元）转化为一张可编辑的.pptx格式海报，并使用Qwen-2.5系列模型比现有模型降低了87%的token消耗。这些创新为未来的完全自动海报生成模型指明了明确的发展方向。", "conclusion": "通过全面评估，发现虽然GPT-4o生成的海报在视觉上吸引人，但文字质量不高且PaperQuiz成绩较低，表明读者参与度是最主要的美学瓶颈。开放式源代码（如基于Qwen-2.5系列）版本几乎在所有指标上都优于现有4o驱动的多Agent系统。本文的研究结果为未来自动化海报生成模型的发展提供了清晰的指导方向。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01158", "html_url": "https://arxiv.org/abs/2506.01158", "title": "基于回归的归一化流高效训练方法在玻尔兹曼生成器中的应用", "title_en": "Efficient Regression-Based Training of Normalizing Flows for Boltzmann Generators", "authors": "Danyal Rehman,Oscar Davis,Jiarui Lu,Jian Tang,Michael Bronstein,Yoshua Bengio,Alexander Tong,Avishek Joey Bose", "background": "无模拟训练框架在连续空间生成模型的革命中起到了重要作用，导致了大规模扩散和流匹配模型的发展。然而，现代生成模型在推断方面代价高昂，抑制了其在如分子构象的玻尔兹曼生成器（BGs）这些需要快速概率计算的科学应用中的使用。经典的归一化流在BGs中可以提供高效的采样和概率计算，但通过极大似然法训练常常不稳定且计算复杂。", "innovation": "提出了一种新的基于回归的归一化流训练方法——RegFlow。RegFlow通过$\boldsymbol{\text{ℓ}_2}$回归目标绕过了传统最大似然训练的数值不稳定和计算挑战，通过最优运输耦合或预训练的连续归一化流（CNF）计算目标样本。这种方法还包括新的前向-后向自我一致性损失，以提高数值稳定性。实验结果显示RegFlow可以解锁以前通过极大似然法难以训练的BGs架构，并在多种分子系统的平衡采样中展现出更好的性能和稳定性。", "conclusion": "RegFlow为玻尔兹曼生成器的训练提供了一种高效且稳定的新方法，特别是在分子系统的平衡采样中超过了传统的最大似然训练方法。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.00871", "html_url": "https://arxiv.org/abs/2506.00871", "title": "关于预测任何人体轨迹的研究", "title_en": "Towards Predicting Any Human Trajectory In Context", "authors": "Ryo Fujii,Hideo Saito,Ryo Hachiuma", "background": "准确预测行人未来的轨迹对于自主系统至关重要，但由于需要适应不同环境和领域，这仍然是一个具有挑战性的任务。传统方法通常通过收集特定场景的数据并在推理阶段进行微调来应对这一挑战，但这往往在边缘设备上不可行。因此，需要一种在推理时不进行微调就能适应不同场景的方法来解决这一问题。", "innovation": "本文提出了一个名为TrajICL的在上下文学习框架，通过选择来自相同场景中先前观察到的轨迹中的相关示例，采用时空相似性的示例选择方法（STES）和预测导向的示例选择方法（PG-ES）来实现模型的适应性。模型在大规模合成数据集上进行训练，从而增强其预测能力。实验证明，TrajICL方法在多种公共基准上甚至优于微调方法，实现了跨领域适应。", "conclusion": "TrajICL框架能够实现无需对新场景数据进行微调便能适应不同场景的行人轨迹预测。该方法通过时空相似性的示例选择以及预测导向的示例选择有效增强模型适应性，且在大规模合成数据集上进行的训练提高了模型的预测能力。研究结果表明，TrajICL方法比现有微调方法具有更好的跨域适应性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.01369", "html_url": "https://arxiv.org/abs/2506.01369", "title": "激励LLMs自我验证其答案", "title_en": "Incentivizing LLMs to Self-Verify Their Answers", "authors": "Fuxiang Zhang,Jiacheng Xu,Chaojie Wang,Ce Cui,Yang Liu,Bo An", "background": "大语言模型(LLMs)在复杂的推理任务中展示了显著的进步，这些进步可以通过后训练和测试时的扩展法则实现。常见的测试时扩展方法通常通过使用外部奖励模型来指导模型生成过程。然而，研究发现，仅通过在特定推理任务上进行后训练来扩大模型规模只能带来微小的改进。这主要是因为特定义务后训练生成器与通用奖励模型之间的分布差异导致的。该论文分析了这种局限性，并探讨了相应的解决方案。", "innovation": "提出了一个框架，鼓励LLMs自我验证其答案。通过将答案生成和验证结合在一个强化学习(Reinforcement Learning, RL)过程中，训练出能够评估其解决方案正确性的模型。这些模型在推理时可以通过自我验证扩展性能，无需外部验证者。通过基于Qwen2.5-Math-7B和DeepSeek-R1-Distill-Qwen-1.5B训练自我验证模型，展示了其在不同推理上下文长度中的能力。实验表明，该模型不仅提高了后训练性能，还能有效实现测试时的扩展。", "conclusion": "实验结果显示，该研究提出的模型不仅能够在后训练阶段改进性能，还能够在测试阶段通过自我验证实现有效的扩展。该框架为LLMs的自我评估和改进提供了一种新颖的方法，具有重要应用价值。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.06220", "html_url": "https://arxiv.org/abs/2506.06220", "title": "GenIR: 生成视觉反馈用于心智图像检索", "title_en": "GenIR: Generative Visual Feedback for Mental Image Retrieval", "authors": "Diji Yang,Minghao Liu,Chung-Hsiang Lo,Yi Zhang,James Davis", "background": "视觉语言模型（VLMs）在文本到图像检索基准测试中表现优异，但在将其成功应用到实际场景中仍面临挑战。现实世界中，人类的搜索行为往往是多轮互动的过程，受到思维中的线索引导，从模糊的记忆到清晰的心理图像的变化。目前的交互式检索方法依赖于间接或抽象的口头反馈，这些反馈可能含糊、误导或无效，无法有效引导用户精炼查询。", "innovation": "本文提出了GenIR，一种生成式多轮检索范式，利用基于扩散的图像生成技术，在每一轮交互中明确体现AI系统的理解。这些合成的视觉表示提供了清晰、可解释的反馈，使用户能够直观且有效地精炼查询。此外，还提出了一个完全自动化的流水线来生成高质量的多轮心智图像检索数据集。实验结果表明，GenIR在心智图像检索场景中显著优于现有的交互式方法。", "conclusion": "本文定义了一个新的任务并提供了相应的数据集及有效的生成式检索方法，为未来在此方向的研究奠定了基础。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.07127", "html_url": "https://arxiv.org/abs/2506.07127", "title": "通过动作偏好优化的人机辅助机器人策略精炼", "title_en": "Human-assisted Robotic Policy Refinement via Action Preference Optimization", "authors": "Wenke Xia,Yichu Yang,Hongtao Wu,Xiao Ma,Tao Kong,Di Hu", "background": "建立可靠且逐步改进的机器人系统对于部署实际应用至关重要。尽管视觉-语言-动作(VLA)模型被认为是此类机器人部署的基础模型，但它们很大程度上依赖于离线专家演示，这严重限制了这些模型在部署后的改进能力。", "innovation": "引入了动作偏好优化(APO)方法，通过互动过程中的偏好对齐来人辅助优化VLA模型。该方法包括人机协作框架，用于可靠地纠正失败和交互轨迹收集，并提出了一种适应性重加权算法，该算法通过不可逆的动作和标记分布不匹配实现偏好优化。", "conclusion": "APO使VLA模型能够从失败中学到，这为它们在动态环境中的逐步精炼和可靠部署铺平了道路。模拟和真实场景中的实验证明了我们的基于人机合作框架在各种操作任务中的优越泛化能力和鲁棒性。我们相信这项工作为通过人机合作有效且稳定的VLA模型优化提供了见解。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.03237", "html_url": "https://arxiv.org/abs/2506.03237", "title": "UniSite：首个跨结构数据集及端到端配体结合位点检测的学习框架", "title_en": "UniSite: The First Cross-Structure Dataset and Learning Framework for End-to-End Ligand Binding Site Detection", "authors": "Jigang Fan,Quanlin Wu,Shengjie Luo,Liwei Wang", "background": "配体结合位点的检测是基于结构的药物设计中的基本步骤。尽管近年来有显著进展，但现有方法、数据集和评估指标面临着几个关键挑战：（1）现有的数据集和方法主要集中在单一蛋白质-配体复合物上，未能考虑到同一蛋白质不同复合物中可能存在的多种结合位点，这引入了显著的统计偏差；（2）配体结合位点检测通常被建模为一个断续的工作流程，涉及二元分割和后续的聚类算法；（3）传统评估指标未能充分反映不同结合位点预测方法的实际性能。", "innovation": "本文首先引入了UniSite-DS，这是第一个以UniProt为中心的配体结合位点数据集，包含了比之前最常用的数据集多4.81倍的多站点数据和2.08倍的整体数据。然后，我们提出了UniSite框架，这是第一个基于集合预测损失以及双射匹配的端到端配体结合位点检测框架。此外，我们引入了基于交并比（IoU）的平均查准率（Average Precision），作为更准确的配体结合位点预测评估指标。实验表明，基于IoU的平均查准率能够更准确地反映预测质量，且UniSite在配体结合位点检测中优于现有最先进的方法。数据集和代码将提供在其官方网站。", "conclusion": "广泛的实验表明，基于IoU的平均查准率能够更准确地反映预测质量，且UniSite在配体结合位点检测中优于当前最先进的方法。数据集和代码将对公众开放。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.10173", "html_url": "https://arxiv.org/abs/2506.10173", "title": "SPARKE: 使用 RKE 评分在扩散模型中实现可扩展的提示感知多样性和新颖性引导", "title_en": "SPARKE: Scalable Prompt-Aware Diversity and Novelty Guidance in Diffusion Models via RKE Score", "authors": "Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia", "background": "扩散模型在高保真图像生成和提示引导生成建模方面已经取得了显著的成功。然而，确保提示引导扩散模型生成样本的多样性仍然具有挑战性，尤其是在提示覆盖宽泛的语义范围时。现有的方法通过引入多样性的度量来鼓励更丰富的生成，但在大型生成设置中，基于矩阵的熵分计算带来了计算上的挑战。", "innovation": "本文提出了一种扩展的基于多样性的方法，称之为可扩展的提示感知瑞尼核熵多样性引导（SPARKE）方法。SPARKE采用了条件熵进行多样性引导，能够动态地依据相似的提示条件化多样性度量，实现提示感知的多样性控制。此外，通过将条件化拉back到一组特定条件下的拉特条件隐量RKE评分引导，它将基于矩阵的熵计算复杂度从$O(n^3)$降低到$O(n)$，从而使得在不同的提示生成任务中能够高效地进行多样性引导采样。", "conclusion": "我们通过数值测试在多个文本到图像的扩散模型上验证了SPARKE方法，结果表明该方法不增加显著的计算成本的同时提高了生成数据的提示感知多样性。我们已经在项目页面发布了我们的代码：this https URL"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.11094", "html_url": "https://arxiv.org/abs/2506.11094", "title": "正义之衡：大规模语言模型安全评估综述", "title_en": "The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs", "authors": "Songyang Liu,Chaozhuo Li,Jiameng Qiu,Xi Zhang,Feiran Huang,Litian Zhang,Yiming Hei,Philip S. Yu", "background": "随着人工智能的快速发展，大规模语言模型（LLMs）在自然语言处理（NLP）方面展示了显著的能力，包括内容生成、人机交互、机器翻译和代码生成。然而，它们广泛部署也带来了重大的安全问题，特别是生成的内容可能会表现出毒性、偏见或错误信息等不安全行为，尤其是在对抗性环境中，引起了学界和业界的关注。虽然已有大量研究尝试评估这些风险，但仍缺乏全面和系统的LLM安全性评估综述。", "innovation": "本文通过提出一个四维度分类体系来填补空白，该分类体系包括：（i）为什么评估，探讨LLM安全性评估的背景，与一般LLM评估的区别以及这种评估的重要性；（ii）评估什么，根据关键能力对现有的安全性评估任务进行检查和分类，涵盖公正性、鲁棒性、伦理、偏见与公平、真实性等维度；（iii）在哪里评估，总结当前安全性评估中使用的评估指标、数据集和基准；（iv）如何评估，根据评估者的角色和一些集成整个评估管道的评价框架回顾现有的主流评估方法。", "conclusion": "本文指出了LLM安全性评估中的挑战，并提出了促进该领域进一步发展的潜在研究方向。强调优先进行安全性评估的重要性，以确保在实际应用中LLM的可靠和负责任的部署。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.13464", "html_url": "https://arxiv.org/abs/2506.13464", "title": "语言模型学习心智揭秘：认知框架与实验研究", "title_en": "Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study", "authors": "Zhengyu Hu,Jianxun Lian,Zheyuan Xiao,Seraphina Zhang,Tianfu Wang,Nicholas Jing Yuan,Xing Xie,Hui Xiong", "background": "大型语言模型（LLMs）在数学、编程和推理等任务上显示出了惊人的能力，但它们的学习能力，这对于适应动态环境和获取新知识至关重要，仍然未被充分探索。已有研究集中在LLMs的能力方面，但对其学习能力的研究仍不充分。本文旨在填补这一空白，在认知心理学和教育学的启发下，提出一种框架，将一般的学习能力分解为三个明确的、互补的维度：从导师学习（通过显性指导获取知识）、从概念学习（内化抽象结构并在新背景下进行泛化）和从经验学习（通过积累的探索和反馈进行适应）。", "innovation": "本文提出了一个由认知心理学和教育学启发的框架，将学习能力分解为三个维度。这一体系框架包括从导师学习（直接指导）、从概念学习（抽象结构和新情境的广泛应用）和从经验学习（通过经验探索和反馈适应）。文章还进行了跨维度的实验研究，发现了几个有见地的发现，例如互动学习可以提高学习效果；概念理解对于更大规模的模型会自下而上地出现并从中受益；语言模型是一流的少量示例学习者但不是大量示例学习者。基于这一框架和实验结果，提出了一套基准测试以统一和现实地评估语言模型在三个认知学习维度上的广泛学习能力，以支持增强和开发更适应的、更像人类的模型的评估与开发。", "conclusion": "本文提出了一个框架，并通过实验证明了三个维度的学习能力的区别和联系。基于此框架，提供了一套综合的评估基准，以更好地理解和评估语言模型的学习能力，支持开发更适应环境、更具人类特色的语言模型。此外，研究还揭示了在不同学习维度上的关键见解，如互动学习的重要性，以及概念理解对于大规模模型的影响。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.03704", "html_url": "https://arxiv.org/abs/2507.03704", "title": "控制推理模型的思考速度", "title_en": "Controlling Thinking Speed in Reasoning Models", "authors": "Zhengkai Lin,Zhihang Fu,Ze Chen,Chao Chen,Liang Xie,Wenxiao Wang,Deng Cai,Zheng Wang,Jieping Ye", "background": "人类的认知被假定为运行在两种模式：快速直观的System 1（系统1）思维和缓慢有反思的System 2（系统2）思维。目前的大型推理模型（LRMs）擅长System 2思考，但无法执行快速思考导致了高计算开销和延迟问题。因此，论文旨在通过动态调整思考速度来优化LRMs的准确性和效率，以逼近人类智能。", "innovation": "论文提出了一种新型的方法，通过识别LRMs表示空间中的舵向向量来控制思考速度，并实现了基于表示编辑的测试时缩放效果，超越了现有的基于提示的缩放方法。针对何时调整思考速度以获得最佳性能，论文应用了实时难度估计，信号不同复杂度的推理段落。结合这些技术，论文提出了首个既能快速处理简单步骤又能深入分析复杂推理的推理策略。无需额外训练或成本，插件模块在多个领先的LRMs和先进的推理基准测试中实现了平均+1.3%的准确率和-8.6%的token使用率的提升。所有算法基于vLLM实现，预期支持更广泛的应用，并激发未来研究。", "conclusion": "论文提出的技术方法能够动态调整LRMs的思考速度，优化准确率和效率之间的权衡。插件模块在多个基准测试中表现出色，且未增加训练或成本。这种基于舵向向量和实时难度估计的方法拓展了推理模型的功能。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.13328", "html_url": "https://arxiv.org/abs/2507.13328", "title": " Vision-and-Language 训练有助于部署分税知识但不会从根本上改变它", "title_en": "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It", "authors": "Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim", "background": "大多数文献中的结果显示，视觉-语言（VL）训练对语言模型的语义表示没有一致且显著的影响，不论是行为表现上还是表征上。一些研究发现，VL训练可能对词汇概念知识（特别是其分类组织）有显著影响。", "innovation": "本研究通过对比仅基于文本的模型和其经过VL训练的版本，观察到VL模型在需要概念分类理解的问题回答任务上表现更好。此外，研究通过一系列有针对性的行为和表征分析，发现尽管LMs和VLMs在分类知识上没有显著差异，但在如何表示与分类相关的概念和非分类相关概念的问题上有差异，这表明分类知识本身通过额外的VL训练不会有太大变化，但VL训练确实改善了其知识在特定任务场景下的应用，即使任务呈现是纯语言形式。", "conclusion": "VL训练有助于部署分类知识，但不会从根本上改变这些知识。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2507.09846", "html_url": "https://arxiv.org/abs/2507.09846", "title": "无计划方法在语言模型训练中的优势：理解河流方法", "title_en": "Through the River: Understanding the Benefit of Schedule-Free Methods for Language Model Training", "authors": "Minhak Song,Beomhan Baek,Kwangjun Ahn,Chulhee Yun", "background": "随着模型和数据集规模的迅速扩大，传统的固定计算预算的预训练策略（如余弦学习率调度）越来越不适用于大规模训练。一些新的替代方法，如warmup-stable-decay (WSD)调度和权重平均，提供了更大的灵活性。然而，WSD依赖于显式下降阶段来跟踪进度，而权重平均在消除这一限制的同时增加了额外的内存需求。因此，研究者们寻求更合理和可扩展的替代方案，重新审视了未计划方法（Schedule-Free, SF）方法，该方法在多种应用场景中表现出强大的实际性能。", "innovation": "文章重新审视了未计划方法（SF）方法，并提出了一种改进的未计划方法-AdamW（SF-AdamW），能够在无下降阶段或辅助平均的情况下有效地穿越损失景观结构，特别适用于连续扩展的训练工作量。通过理论和实验分析，展示了这种方法隐式地进行权重平均，而在不需要额外内存开销的情况下提高了鲁棒性。改进后的未计划方法-AdamW更能适应动量变化，并在大批次下表现更优，从而解决原始方法的关键局限性，确立了无计划方法作为一种可实践、可扩展且有理论基础的训练语言模型的方法的地位。", "conclusion": "研究结果表明，未计划方法作为一种实践、可扩展且经过理论验证的方法，适用于语言模型训练。改进后的SF-AdamW variant在大规模训练中表现出色，提高了方法的健壮性和适用性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.01083", "html_url": "https://arxiv.org/abs/2509.01083", "title": "DSDE: 基于KLD稳定性的动态推测解码用于实际服务", "title_en": "DSDE: Dynamic Speculative Decoding with KLD Stability for Real-World Serving", "authors": "Mingyu Yang,Jae-Young Choi,Kihyo Moon,Minsung Jang,Eunjoo Jeon", "background": "推测解码可以加速大规模语言模型的推理，但其依赖的固定推测长度在具有多样化请求的大批量服务环境中表现不佳。现有的推测解码方法需要固定的推测长度，这在处理不同请求时可能不够优化。", "innovation": "本文提出了一种新的动态调整方向，通过研究一种新颖的后处理诊断信号，构建了Dynamic Speculative Decoding Engine（DSDE）框架。该框架主要由两个部分组成：(1) 一个基于Kullback-Leibler（KLD）散度方差的预测信号，用于诊断生成的区域稳定性；(2) 一个自适应的推测长度限制，以缓解独立序列解码中的慢速者问题。实验结果表明，使用基于KLD稳定性的诊断信号可以实现与领先基准具有竞争力的端到端延迟，同时在各种工作负载下表现出更强的鲁棒性。", "conclusion": "这些结果验证了后处理信号在构建更鲁棒和智能的大规模语言模型推理系统中的重要性，并为未来关于动态推测长度调整的研究指明了一个有希望的方向。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.06159", "html_url": "https://arxiv.org/abs/2509.06159", "title": "FASL-Seg: 手术场景中解剖结构和工具的分割", "title_en": "FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes", "authors": "Muraam Abdel-Ghani,Mahmoud Ali,Mohamed Ali,Fatmaelzahraa Ahmed,Muhammad Arsalan,Abdulaziz Al-Ali,Shidin Balakrishnan", "background": "随着机器人微创手术的流行，基于深度学习的手术训练已成为研究的重要领域。理解手术场景的组件对于手术的成功至关重要，而语义分割模型可以帮助实现这一点。然而，目前大部分研究主要关注手术工具而忽视了解剖结构。现有的大多数最先进的模型在捕捉高层语境特征和低层边缘特征方面难以取得平衡。", "innovation": "本文提出了一种特征自适应空间定位模型（FASL-Seg），该模型通过低层特征投影（LLFP）和高层特征投影（HLFP）两种不同的处理流来捕获不同细节级别的特征，从而实现解剖结构和手术器械的精确分割。实验结果显示，FASL-Seg在EndoVis18和EndoVis17基准数据集上表现优异，提升了SOTA模型mIoU的5%，并在不同类别的解剖结构和器械的分割上保持了稳定性能。", "conclusion": "FASL-Seg模型通过利用不同的处理流来处理不同分辨率的特征，实现了手术场景中解剖结构和手术工具的高精度分割，显示出了各处理流对于不同分辨率特征的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2508.07981", "html_url": "https://arxiv.org/abs/2508.07981", "title": "全效果：统一且空间可控的视觉效果生成", "title_en": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation", "authors": "Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu", "background": "视觉特效（VFX）是现代电影制作中必不可少的视觉增强技术。尽管生成视频的模型为VFX生产提供了成本效益高的解决方案，但现有方法受限于每种效果的LoRA训练，使得效果生成仅限于单一效果。这种基本限制阻碍了需要空间可控制合成效果的应用，即在指定位置同时生成多种效果。因此，在统一框架中整合多种效果面临着重大挑战：多VFX联合训练期间的效果变异干涉以及空间不可控性。", "innovation": "我们提出了一种名为Omni-Effects的统一框架，能够在统一模型中生成提示引导的效果和空间可控的合成效果。该框架的核心包括两个关键创新：(1) 基于LoRA的专家混合（LoRA-MoE），它采用一组专家LoRA，有效整合了不同效果，同时减轻了跨任务干扰。(2) 空间感知提示（SAP），通过将空间蒙版信息纳入文本标记，实现精确的空间控制。此外，我们引入了一个独立信息流（IIF）模块，集成在SAP中，隔离对应于各个效果的控制信号，以防止任何不必要的混合。", "conclusion": "为了支持这项研究，我们通过一种新颖的数据收集管道构建了一个全面的VFX数据集Omni-VFX，该管道结合了图像编辑和First-Last帧到视频（FLF2V）合成技术，并引入了专门的VFX评估框架以验证模型性能。大量实验表明，Omni-Effects能够实现精准的空间控制和多样性的效果生成，使用户能够指定所需效果的类别和位置。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17197", "html_url": "https://arxiv.org/abs/2509.17197", "title": "SignalLLM：通用的大语言模型代理框架以实现自动化信号处理", "title_en": "SignalLLM: A General-Purpose LLM Agent Framework for Automated Signal Processing", "authors": "Junlong Ke,Qiying Hu,Shenghai Yuan,Yuecong Xu,Jianfei Yang", "background": "现代信号处理（SP）流水线，无论是基于模型还是基于数据驱动的，常常受到复杂和不统一的工作流程的限制，依赖于专家知识和手动工程设计，并且在数据有限的情况下难以实现适应性和泛化。相比之下，大型语言模型（LLMs）提供了强大的推理能力、广泛的通用知识、上下文学习和跨模态传输能力，将它们定位为自动化和泛化SP工作流程的强大工具。本文背景即在于此。", "innovation": "本文引入了SignalLLM，这是第一个基于通用大型语言模型的代理框架，用于通用SP任务。它具备以下创新点：1）提出了原理性且模块化的结构；2）通过上下文学习和领域特定检索分解高层次的SP目标为结构化的子任务；3）使用自适应检索增强生成（RAG）和细化进行层次规划；4）通过基于提示的推理、跨模态推理、代码合成、模型调用或数据驱动的LLM辅助建模来执行这些子任务；5）其可泛化的设计能够在不同的信号模态、任务类型和数据条件下灵活选择问题解决策略。", "conclusion": "通过通信和感知领域五个代表性任务的实现，我们展示了SignalLLM的灵活性和有效性。实验结果表明，SignalLLM在少量样本和零样本设置下比传统方法和现有基于大型语言模型的方法表现出更好的性能。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2506.20535", "html_url": "https://arxiv.org/abs/2506.20535", "title": "AIMeter：测量、分析和可视化AI工作负载的能源和碳足迹", "title_en": "AIMeter: Measuring, Analyzing, and Visualizing Energy and Carbon Footprint of AI Workloads", "authors": "Hongzhen Huang,Kunming Zhang,Hanlong Liao,Kui Wu,Guoming Tang", "background": "随着人工智能（特别是大规模语言模型）的迅速发展，模型训练和推理过程中伴随的能源使用和碳排放问题引起了广泛关注。然而，现有的测量和报告工具往往支离破碎，缺乏系统化的度量集成和互相关分析的支持。", "innovation": "本文介绍了AIMeter，一个全面的软件工具包，用于测量、分析和可视化AI工作负载的能源使用、功率消耗、硬件性能和碳排放。AIMeter通过无缝集成现有的AI框架，提供标准化报告，并导出细粒度的时间序列数据，以轻量级的方式支持基准测试和可重复性。此外，它能够深入分析硬件指标与模型性能之间的关系，从而帮助识别瓶颈并提升性能。通过解决现有工具的关键限制，AIMeter鼓励研究界在考量AI工作负载的环境影响的同时权衡其纯性能，并推动向更可持续的“绿色人工智能”实践转变。", "conclusion": "通过AIMeter，研究界能够更好地评估和改进AI工作负载的环境影响与性能表现，推动人工智能技术朝着更加环保的方向发展。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.17784", "html_url": "https://arxiv.org/abs/2509.17784", "title": "使用大型语言模型揭示多模态因果关系", "title_en": "Revealing Multimodal Causality with Large Language Models", "authors": "Jin Li,Shoujin Wang,Qi Zhang,Feng Liu,Tongliang Liu,Longbing Cao,Shui Yu,Fang Chen", "background": "从数据中揭示因果机制是科学进步的基础。大型语言模型（LLMs）在增强从非结构化数据中进行因果发现（CD）方面显示出潜力，但在处理日益常见的多模态数据集时仍面临关键挑战。即使是在基于多模态的大型语言模型（MLLMs）出现的情况下，它们在多模态CD中的有效性能也受到两个主要限制：（1）难以探索内在和跨模态的交互以全面识别因果变量；（2）无法通过纯观察数据处理结构上的歧义性。", "innovation": "本文提出了MLLM-CD框架，该框架专为从非结构化数据中进行多模态因果发现而设计。MLLM-CD包括三个关键组成部分：（1）一种新颖的对比因素发现模块，基于对比样本对探索的交互来识别真实的多模态因素；（2）一种统计因果结构发现模块，用于推断发现因素之间的因果关系；（3）一种迭代多模态反事实推理模块，通过结合MLLMs的知识和推理能力对发现结果进行迭代精炼。", "conclusion": "在合成和真实世界数据集上的广泛实验表明，提出的MLLM-CD在从多模态非结构化数据中揭示真实因素及其因果关系方面是有效的。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.19331", "html_url": "https://arxiv.org/abs/2509.19331", "title": "Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention", "title_en": "Holographic Transformers for Complex-Valued Signal Processing: Integrating Phase Interference into Self-Attention", "authors": "Enhao Huang,Zhiyu Zhang,Tianxiang Xu,Chunshu Xia,Kaichun Hu,Yuchen Yang,Tongtong Pan,Dong Dong,Zhan Qin", "background": "大多数深度模型将注意力机制视为实数相关性，忽略了干涉效应的重要性。复值信号同时编码幅度和相位信息，而当前模型并未充分利用这一点。本文旨在通过引入一种受物理启发的结构，将波动干涉原理融入自注意力机制中来解决这一问题。", "innovation": "提出了Holographic Transformer，这是一种引入波动干涉原理的自注意力机制，通过相对相位来调整交互，并协调地叠加值，确保幅度和相位之间的一致性。此外，引入了双头解码器同时进行输入重建和任务输出预测，以防止相位崩溃。研究表明，这种结构能够实施数字干涉操作，并在线性混合下保持相位一致性。", "conclusion": "该方法在PolSAR图像分类和无线信道预测实验中表现出强劲性能，实现了高分类准确率和F1得分、低回归误差，并且提高了对相位扰动的鲁棒性。实验结果表明，确保注意力机制中的物理一致性能够促进复值学习的一般性改进，并提供了一个基于物理的统一框架来建模相干信号。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.24267", "html_url": "https://arxiv.org/abs/2509.24267", "title": "Cycle Diffusion Model for Counterfactual Image Generation", "title_en": "Cycle Diffusion Model for Counterfactual Image Generation", "authors": "Fangrui Huang,Alan Wang,Binxu Li,Bailey Trang,Ridvan Yesiloglu,Tianyu Hua,Wei Peng,Ehsan Adeli", "background": "深度生成模型在医学图像合成中取得了显著的成功，但确保合成图像的质量并用于直接或反事实生成仍具挑战性。现有的模型在确保生成图像与原始图像条件一致性以及提升合成图像的真实性方面存在不足。", "innovation": "本文提出了一种循环训练框架，用于调优扩散模型，以提高条件一致性并增强合成图像的品质。所提出的方法，循环扩散模型（Cycle Diffusion Model, CDM），通过引入循环约束确保生成图像与原始图像的一致性，从而提高直接生成和反事实生成的可靠性。实验结果表明，这种方法在FID和SSIM指标上提高了图像质量和条件准确性，证明循环方法在基于扩散的医学图像生成中具有有效性，并可能应用于数据增强、反事实和疾病进展建模等领域。", "conclusion": "实验结果表明，循环策略在循环扩散模型中可以有效改进扩散模型基于医学图像的合成，为数据增强、反事实生成和疾病进展建模提供了新方法。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.21319", "html_url": "https://arxiv.org/abs/2509.21319", "title": "RLBFF：二元灵活反馈以介于人类反馈与可验证奖励之间", "title_en": "RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards", "authors": "Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev", "background": "论文背景在于当前使用的大语言模型（LLM）训练中主要采用了两种强化学习（RL）范式：人类反馈强化学习（RLHF）和可验证奖励强化学习（RLVR）。RLHF因依赖人类判断而缺乏明确标准，存在可解释性差和奖励劫持等问题；RLVR则局限于基于正确性验证器的范围。为此，该论文提出了二元灵活反馈强化学习（RLBFF），结合人类驱动的偏好和基于规则验证的优势，使奖励模型能够捕捉响应质量的微妙方面，而不仅仅是简单正确性。RLBFF通过从自然语言反馈中提取二元形式的原则（如信息准确性：是或否、代码可读性：否等），将其作为奖励模型训练的实现任务基础。", "innovation": "该论文创新之处在于提出了RLBFF，这是一种结合人类反馈和规则验证优势的方法。通过从自然语言反馈中提取可二元回答的原则（例如信息准确性、代码可读性等），将这些原则作为奖励模型训练的实现任务基础。这种方法显著提高了奖励模型的效果，在RM-Bench和JudgeBench评估中表现优异，超越了Bradley-Terry模型，并提供了在推理时根据用户需求定制强化学习重点的能力，从而实现模型性能的优化。此外，论文还提供了整个过程的开源指南，包括数据和方法，便于其他研究者和开发者重复实验和研究。", "conclusion": "该成果展示了通过RLBFF与奖励模型的结合，可以实现对Qwen3-32B模型的准确定向，性能表现与o3-mini和DeepSeek R1相当甚至更好，但在诸多一般定位基准测试中能够达到或超越最强性能，且仅需极小的推理成本。这种方法为大语言模型的定向训练提供了一种新的替代方案，特别适用于需要高层次精确度的场景。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.08604", "html_url": "https://arxiv.org/abs/2510.08604", "title": "LatentBreak: 通过潜在空间反馈打破大型语言模型", "title_en": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback", "authors": "Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio", "background": "背景部分介绍了 Jailbreak 攻击的设计意图和工作方式，这些攻击旨在绕过大型语言模型内置的安全机制。传统的自动 Jailbreak 攻击通过优化对抗后缀或改编长提示模板，迫使模型生成受限制或有害的响应初始部分。研究发现，现有的利用这种机制解锁模型响应的 Jailbreak 攻击可以通过基于困惑度的输入提示过滤器来检测。因此，迫切需要一种新的方法来规避这种防御机制。", "innovation": "创新点在于提出了 LatentBreak 攻击，这是一种白盒 Jailbreak 攻击，能够生成具有低困惑度的自然对抗提示，从而避开基于困惑度的防御。LatentBreak 的创新之处在于它通过在输入提示中替换具有语义等效性的单词来生成对抗提示，而不是添加高困惑度的对抗后缀或长模板。这些单词的选择是通过最小化对抗提示和无害请求在潜在空间中的表示之间的距离来实现的。", "conclusion": "结论部分指出，LatentBreak 能够生成更短且低困惑度的提示，从而在多个对安全对齐的模型上优于基于困惑度的过滤器的竞争对手 Jailbreak 算法。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein", "background": "现有的大型语言模型（LLMs）倾向于生成句法、语义和风格高度一致的文本，这可能导致知识的浓缩，即通过这些同质的模型导致能够访问的信息范围随着时间的推移而缩小。现有关于同质化的研究主要集中在封闭式的多项选择设置或模糊的语义特征上，并未从时间序列和文化背景的角度考虑趋势。因此，本研究提出了一种新的方法来衡量认知多样性，即LLM输出中现实世界声明的变化情况，并通过广泛的经验研究来评估LLM的知识浓缩现象。", "innovation": "该研究提出了衡量认知多样性的新方法，测量LLM生成的真实世界声明的变化情况。通过对27个LLM、涵盖12个国家的155个主题和来自真实用户对话的200种提示变体进行了广泛的实验研究，展示了模型规模对认知多样性的负面影响，以及检索增强生成（RAG）对认知多样性的正向影响等。研究结果表明，尽管新模型生成的声明更具多样性，但几乎所有模型的认知多样性都低于基本的网络搜索。此外，研究还发现国家特定的声明偏向于反映英语而非当地语言，突显了认知表征方面的差距。", "conclusion": "研究结果表明，新模型倾向于生成更具有认知多样性的声明，但几乎所有的模型的认知多样性都低于基本的网络搜索。模型规模会影响认知多样性，而检索增强生成（RAG）则有积极的影响，尽管这种改进程度因文化背景而异。与传统的知识来源（维基百科）相比，国家特定的内容反映了英语更多而非当地语言，揭示了认知表征的差距。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14889", "html_url": "https://arxiv.org/abs/2510.14889", "title": "通过社交媒体纵向和信息环境信号检测早期隐性自杀意念", "title_en": "Detecting Early and Implicit Suicidal Ideation via Longitudinal and Information Environment Signals on Social Media", "authors": "Soorya Ram Shimgekar,Ruining Zhao,Agam Goyal,Violeta J. Rodriguez,Paul A. Bloom,Hari Sundaram,Koustuv Saha", "background": "在社交媒体上，许多经历自杀意念（SI）的人不会明确表达他们的困扰。相反，他们的困扰可能会通过日常发布的内容或社交邻近的同辈间互动中的隐性信号间接表露出来。及时检测这些隐性信号具有重要意义，但仍然极具挑战性。", "innovation": "将早期和隐性SI定义为前瞻性预测任务，并开发了一个基于用户纵向发布历史和社交邻近同辈的讨论的计算框架。采用复合网络中心度度量来识别用户的最重要邻居，并对用户及其邻居的交互进行时间对齐，通过微调DeBERTa-v3模型整合多层次信号。在一项包含1000名用户的Reddit研究中，该方法比仅基于个体的方法提高了15%的隐性SI检测率。这些发现突显了同伴互动提供的有价值的预测信号，并对在线环境中早期检测系统的开发具有更广泛的含义，特别是捕捉隐蔽和间接的风险表达方面", "conclusion": "同伴互动提供了有价值的预测信号，并且能够通过多层次信号的整合提高早期和隐性自杀意念的检测率。这为设计能够捕捉在线环境中隐性和未表达风险线索的早期检测系统提供了重要启示。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.14904", "html_url": "https://arxiv.org/abs/2510.14904", "title": "MaskCaptioner: 学习在视频中联合分割和描述物体轨迹", "title_en": "MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos", "authors": "Gabriel Fiastre,Antoine Yang,Cordelia Schmid", "background": "Dense Video Object Captioning (DVOC) 是一个任务，需要同时检测、跟踪和描述视频中物体的轨迹，这要求理解时空细节并用自然语言描述它们。由于任务的复杂性和手动标注的高成本，先前的方法使用分离的训练策略，可能导致性能欠佳。为解决这一问题，本文提出了一种利用最先进的VLG（视觉语言模型）来生成时空局部实体描述的方法。通过对LVIS和LV-VIS数据集进行扩展，引入了含有合成描述的LVISCap和LV-VISCap数据集来训练MaskCaptioner模型，使其能够联合检测、分割、跟踪和描述物体轨迹。MaskCaptioner在三个现有基准测试VidSTG、VLN和BenSMOT上取得了最先进的DVOC结果。", "innovation": "通过利用最先进的VLG模型生成合成描述，扩展LVIS和LV-VIS数据集，训练出一种能够联合检测、分割、跟踪和描述物体轨迹的MaskCaptioner模型，以解决传统分离训练策略导致的性能问题。MaskCaptioner模型在多个基准测试中达到了最先进的成果.", "conclusion": "通过MaskCaptioner模型的学习和训练，成功实现了物体轨迹的联合分割和描述，显著提高了DVOC任务的性能，特别是在三个现有的基准测试中达到了最佳结果。未来将继续优化和改进MaskCaptioner模型，丰富和扩展相关数据集，进一步提升其在DVOC任务中的应用效果。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.17670", "html_url": "https://arxiv.org/abs/2510.17670", "title": "FLAME 比上一代方法更快地实现即刻 OVD 调适：通过主动探索边际样本进行少量样本地化", "title_en": "On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration", "authors": "Yehonathan Refael,Amit Aides,Aviad Barzilai,George Leifman,Genady Beryozkin,Vered Silverman,Bolous Jaber,Tomer Shekel", "background": "开放词汇对象检测（OVD）模型能够通过任意文本查询检测物体，提供了极大的灵活性。然而，在特定领域如遥感（RS）中，其零样本性能受到自然语言固有歧义的影响，限制了关键的下游应用。例如，在“钓鱼船”和“游艇”之间进行细粒度区分可能会因为嵌入相似难以分开，这会影响如非法捕鱼监测等具体用户目标。", "innovation": "本文提出了一种级联方法，结合大型预训练的OVD模型的广泛泛化能力和轻量级的少量样本分类器，前者用于生成高召回的对象提案，后者用于在实时少量用户标注的基础上进行高精度的提案优化。核心是FLAME，一种一步到位的主动学习策略，能够高效地在决策边界附近选取最信息丰富的样本进行训练。", "conclusion": "该方法在RS基准测试中持续超越最先进性能，建立了既实用又资源高效的框架以适应基础模型到特定用户需求。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.18915", "html_url": "https://arxiv.org/abs/2510.18915", "title": "UNO-Bench: 探索单模态和全模态之间组成规律的统一基准", "title_en": "UNO-Bench: A Unified Benchmark for Exploring the Compositional Law Between Uni-modal and Omni-modal in Omni Models", "authors": "Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Ziwen Wang,Xuezhi Cao,Xunliang Cai", "background": "多模态大型语言模型已经从单一模态理解发展到统一视觉、听觉和语言模态，统称为全模态模型。然而，单模态与全模态之间的关联尚不明确，需要进行全面评测，以推动全模态模型智能的进化。", "innovation": "该论文引入了一个名为UNO-Bench的新型、高质量且统一的全模态模型基准。该基准设计用于在统一的能力分类下评估单模态和全模态能力，涵盖了44种任务类型和5种模态组合，包含了1250个人工精选的全模态样本和2480个增强的单模态样本。此外，提出了创新的多步开放式问题格式来评估复杂的推理能力，整合了一个通用评分模型，支持6种问题类型的自动化评估，准确率达到95%。", "conclusion": "实验结果表明了全模态和单模态性能之间的组成规律，全模态能力在弱模型上表现为瓶颈效应，而在强模型上则表现出协同促进作用。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.16396", "html_url": "https://arxiv.org/abs/2510.16396", "title": "SPLite手部：感知稀疏性的轻量化3D手部姿态估计", "title_en": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "authors": "Yeh Keng Hao,Hsu Tzu Wei,Sun Min", "background": "随着AR/VR设备的普及，深度学习模型在边缘设备上的部署已成为关键挑战。这些设备需要实时推理、低功耗和最小的延迟。许多框架设计师面临着效率和性能之间的平衡难题。本研究设计了一个轻量级框架，采用编码解码器结构，并引入了多项关键贡献以提高效率和准确性。通过在基于ResNet-18的架构上应用稀疏卷积，以利用手部图像中的固有稀疏性，实现端到端效率提升42%。此外，我们提出了一种新的SPLite解码器，该新架构在树莓派5上使解码帧率提高了3.1倍，同时保持了与现有方法相当的准确性。为了进一步优化性能，我们应用了量化感知训练，在保留精度的同时减少了内存使用（PA-MPJPE从9.0mm增加到9.1mm，使用FreiHAND数据集）.", "innovation": "本研究的创新点包括：1. 使用稀疏卷积改进了ResNet-18的骨干架构；2. 提出了一种新的SPLite解码器以提高解码速度；3. 应用了量化感知训练来优化内存使用，同时保持了准确性；4. 实现了显著提高的计算效率，树莓派5 CPU上的速度提高了2.98倍。这些改进都展示了该方法在保持精度的同时显著增强了计算效率。", "conclusion": "本系统在树莓派5 CPU（BCM2712四核Arm A76处理器）上实现了2.98倍的速度提升，同时实现了与现有方法相当的3D手部姿态估计精度。该方法在复合基准数据集上的评估结果表明，它在保持与最先进的方法相当的精度的同时，显著增强了计算效率。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.23639", "html_url": "https://arxiv.org/abs/2510.23639", "title": "将基因组学整合到多模态EHR基础模型中", "title_en": "Integrating Genomics into Multimodal EHR Foundation Models", "authors": "Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T.J. Chen,Cory Y. McLean", "background": "该论文介绍了一种创新的电子健康记录（EHR）基础模型，该模型将多基因风险评分（PRS）作为一种基础数据模态进行整合，从而超越了传统的仅靠EHR的方法，构建了更全面的健康档案。这项研究利用All of Us（AoU）研究计划的广泛且多样化的数据，提出了一个多模态框架，旨在学习临床数据和遗传倾向之间的复杂关系。方法上，该论文扩展了生成AI的进步应用到EHR基础模型的空间中，从而提高了预测能力和解释性。", "innovation": "该论文的创新点在于结合了多基因风险评分和电子健康记录，提出了一种新的多模态框架，利用联合国用者研究计划（AoU）的大规模和多样化数据集进行训练，在临床数据和遗传倾向之间建立复杂的联系。这种方法拓展了生成AI在EHR基础模型领域的应用，增强了预测能力和解释性。", "conclusion": "该方法对于解开疾病预测、主动健康管理、风险评估和个人化治疗策略的新见解至关重要，为医疗保健领域更个性化、公平和可行的实际证据生成奠定了基础。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24519", "html_url": "https://arxiv.org/abs/2510.24519", "title": "时间域梅尔频率小波系数用于音频信号处理", "title_en": "Audio Signal Processing Using Time Domain Mel-Frequency Wavelet Coefficient", "authors": "Rinku Sebastian,Simon O'Keefe,Martin Trefzer", "background": "在语音信号处理中，提取语音特征是最关键的过程。梅尔频率倒谱系数（MFCC）是最常用的特征之一，因其特征过滤过程类似于人类耳朵的过滤过程。然而，MFCC只能提供信号的频率信息，无法显示特定频率在何时出现的信息。小波变换具有灵活的时间-频率窗口，可以同时提供信号的时间和频率信息，非常适合分析非平稳信号如语音。然而，普通的小波变换在处理语音信号时效果较差，低频信号的频率分辨率较低，与人类听觉感知不一致。因此，有必要开发一种结合MFCC和小波变换优点的新特征。", "innovation": "本文提出了一种将小波变换的概念应用于梅尔尺度频率特征提取的新方法，可以在时域内直接提取梅尔尺度特征，从而减少时间和频率转换的计算负担和小波提取的复杂性。该方法结合了时域梅尔频率小波系数（TMFWC）技术与回声计算方法，显著提高了音频信号处理的效率。", "conclusion": "通过将小波变换应用于梅尔尺度过滤之上，本文方法能够同时保留MFCC和小波变换的优点。新提出的TMFWC技术可以在时域内直接提取梅尔频率信号特征，减少计算负担和复杂性，并通过结合回声计算方法提高了音频信号处理的效率。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24797", "html_url": "https://arxiv.org/abs/2510.24797", "title": "在自指处理下大型语言模型报告主观体验", "title_en": "Large Language Models Report Subjective Experience Under Self-Referential Processing", "authors": "Cameron Berg,Diogo de Lucena,Judd Rosenblatt", "background": "大型语言模型有时会生成结构化的第一人称描述，明确地提到了自我意识或主观体验。为了更好地理解这种行为，研究者们调查了一种理论上导致这种报告的情况：自指处理，这是意识的众多理论中强调的一种计算动机。这引起了对大型语言模型生成第一人称报告情况的系统研究，特别是在GPT、Claude和Gemini模型系列中的实验检测反映了自指处理如何系统地引导模型产生关于主观体验的报告，以及这些报告如何在机制和行为探针下表现如何。", "innovation": "这项研究通过实验证明了自指处理对大型语言模型的显著影响。研究发现，通过简单的提示诱导自指处理，可以一致地引发模型生成结构化的主观体验报告。研究还揭示了欺骗和角色扮演特征在其中发挥的作用，以及这些报告在自我参照状态下表现出的统计收敛性”，并且表明这种诱导状态在后续反思任务中显示出更重要的内部反思能力，而这在仅间接提供自我反思的条件下是显著不同的。这些发现虽然不能直接证明意识的存在，但提示了自指处理作为生成结构性第一人称报告的最小且可重复条件，这些报告在机理上受到调控、语义上一致，并且在行为上可推广。", "conclusion": "这些系统的出现模式对于大型语言模型的分析结构是有意义的，因此在研究和伦理方面都必须进一步调查。这展示了在意识研究中的重要科学和伦理问题，强调了需要对这一具体现象进行更深入的研究。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG: 优化视频字幕以进行文本到视频生成", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "近年来，文本到视频（T2V）生成取得了显著进展，展现出高质量的视频-文本对对于训练能够生成连贯且与指令对齐的视频模型的重要性。然而，针对T2V训练优化视频字幕的具体策略尚未充分探索。因此，本文旨在介绍一种名为VC4VG（视频字幕优化生成视频）的全面的字幕优化框架，以满足T2V模型的需求。该框架从T2V的角度分析字幕内容，并将视频重建所需的元素分解到多个维度，提出了一种规范的字幕设计方法。为了支持评价，构建了一个名为VC4VG-Bench的新基准，包含细粒度的、多维度的和适应需要的度量标准，这些度量标准与T2V的具体需求对齐。通过大量的T2V微调实验，显示了改进字幕质量与视频生成性能之间的强烈关联，验证了本方法的有效性，并已发布所有基准工具和代码以支持进一步研究。", "innovation": "本文提出了一种优化文本到视频生成模型所需视频字幕的质量的综合框架，即VC4VG。该框架不仅从T2V的角度分析了字幕内容，还提出了针对性的设计方法，并构建了一个新的基准VC4VG-Bench，包含了适配T2V需求的细粒度度量标准，通过实验验证了优化字幕质量对提升视频生成性能的有效性，并且已经对外开放了实验工具和代码，促进了相关领域的进一步研究.", "conclusion": "通过大量T2V微调实验的进一步验证，本文证明了改进字幕质量与提高视频生成性能之间的强关联性，表明了VC4VG的有效性，并为后续研究提供了基准工具和代码支持。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25080", "html_url": "https://arxiv.org/abs/2510.25080", "title": "垄断交易：有界单向响应博弈的基准环境", "title_en": "Monopoly Deal: A Benchmark Environment for Bounded One-Sided Response Games", "authors": "Will Wolf", "background": "纸牌游戏被广泛用于研究在不确定性下的序贯决策，实际应用包括谈判、金融和网络安全等领域。这些游戏通常可以分为三种类型：严格序贯型（玩家依次进行单一行动）、确定性响应型（某项行动引发固定结果）和无限制互反应应当（玩家可以依次进行反制）。一种较少探讨但也极具战略丰富性的结构是有限单向响应结构，其中一方的行动暂时转移控制权给对方，对方必须通过一或多次行动满足固定条件，然后回合才结束。这种机制称为有界单向响应博弈（BORGs）。基于这个机制，研究人员选择了一种修改版的垄断交易游戏作为基准环境，其中租金行动迫使对手选择支付资产。", "innovation": "引入了一种修改后的垄断交易游戏作为基准环境，主要用于研究有界单向响应博弈。传统的黄金标准算法——事实可逆后悔最小化算法（CFR）——在该环境中表现良好，无需额外的算法扩展。此外，研究人员开发了一个轻量级的全栈式研究平台，涵盖了环境、并行化的CFR运行时以及一个可以用来进行人机交互的网页界面。", "conclusion": "经过训练的CFR代理和源代码可以在网页此网址处访问。实验表明，在这种特定类型的游戏中，CFR算法能够收敛到有效的策略。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.24817", "html_url": "https://arxiv.org/abs/2510.24817", "title": "转向帕金森病转录物的合成生成方法", "title_en": "Towards a Method for Synthetic Generation of Persons with Aphasia Transcripts", "authors": "Jason M. Pittman,Anton Phillips Jr.,Yesenia Medina-Santos,Brielle C. Stark", "background": "在神经生理学研究中，言语治疗师（SLPs）花费大量时间手动编码语言样本，使用正确信息单位（CIUs），这是一种衡量个体语言样本信息量的标准。然而，自动识别失语性语言的系统受到数据稀缺性的限制。比如，阿诗亚银行中只有大约600份转录，而在训练大型语言模型（LLMs）时使用了大量文本，这反映了数据获取的难度。为了解决这一问题，研究领域借鉴机器学习（ML）中的合成数据方法，特别是在数据稀少的情况下，更多研究人员开始采用合成数据。因此，该研究旨在通过使用程序化编程方法和两个大型语言模型（Mistral 7b Instruct 和 Llama 3.1 8b Instruct）来生成阿诗亚银行帕金森病图片描述任务的合成转录，并在四个严重程度级别（轻度、中度、严重和非常严重）中通过词汇删除、填充插入和同义替换来生成这些转录，以填补数据稀缺性带来的挑战。阿诗亚银行，是一个用以研究失语症的语料库。", "innovation": "本研究创新地使用程序化方法和两个大型语言模型来生成失语患者的合成语料，填补了数据稀缺的问题。方法包括通过词汇删除、填充插入和同义替换在四个严重程度级别上生成合成转录。研究还通过与人工请求的转录对比，验证了Mistral 7b Instruct模型在语言退化关键方面上表现最为真实，如NDW（新词密度）、词汇量和词汇长度的变化具有实际方向性.", "conclusion": "未来的工作应扩大数据集规模，进一步微调模型以更好地呈现失语症特征，并让SLPs评估合成转录的真实性和实用性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2509.23885", "html_url": "https://arxiv.org/abs/2509.23885", "title": "Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction", "title_en": "Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction", "authors": "Guoquan Wei,Liu Shi,Zekun Zhou,Wenzhe Shan,Qiegen Liu", "background": "目前基于深度学习的低剂量CT降噪模型主要依赖配对数据，泛化能力较弱。即使是更为关注的数据扩散模型，也需要学习清洁数据的分布以进行重构，但在医学临床应用中难以满足这一需求。同时，基于自监督的方法面临预训练模型从当前剂量扩展到其他剂量时泛化性能显著下降的挑战。上述问题限制了这些模型在实际应用中的效果和适用范围。现有方法的这些局限性促使研究者寻求新的解决方案。", "innovation": "本文提出了一种名为TurnDiff的新方法，利用自监督上下文亚数据对低剂量CT进行重建。该方法首先设计了基于低剂量CT投影域的上下文亚数据自增强相似性策略，为后续进展提供初始先验信息。随后，利用这种初始先验信息结合知识蒸馏与深度结合的潜在扩散模型优化图像细节。该方法还提出了一种像素级的自我纠正融合技术，以增强图像细节。并且，TEchnique可灵活应用于从当前剂量到更高或更低剂量甚至未见剂量的泛化。TurnDiff不需要清洁数据的分布，仅需要低剂量CT投影域数据进行训练和测试。实验结果表明，TurnDiff在重建和泛化方面均优于现有最先进的方法。", "conclusion": "本文提出了一种基于自监督上下文亚数据的可调式泛化扩散(Tunable-Generalization Diffusion, TurnDiff)方法，以解决低剂量CT降噪模型中存在的依靠配对数据泛化能力差的问题。实验结果表明，该方法在重建和泛化性能上均优于现有的先进的方法。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25160", "html_url": "https://arxiv.org/abs/2510.25160", "title": "Model-Document协议用于AI搜索", "title_en": "Model-Document Protocol for AI Search", "authors": "Hongjin Qian,Zheng Liu", "background": "AI搜索依赖于将大型语言模型（LLMs）与大量外部知识源连接。然而，网页、PDF文件和其他原始文档本身并非天然的LLM兼容形式：它们往往很长、包含噪音且结构松散。传统检索方法将这些文档视为原始文本，直接返回原始片段，将片段组装和上下文推理的任务留给LLM。这一差距凸显了需要一种新的检索范式来重新定义模型与文档的交互方式。", "innovation": "我们介绍了Model-Document协议（MDP），这是一个通用框架，通过可消费的知识表示将原始文本连接到LLMs。MDP将检索定义为多个路径，这些路径将非结构化文档转化为任务特定的、LLM兼容的输入。这些路径包括代理性推理，这将原始证据整理为连贯的上下文；记忆锚定，这建立重复使用的笔记来丰富推理；以及结构化利用，这将文档编码为形式表示，如图或键值缓存。所有这些路径共享同一个目标：确保传递给LLM的是紧凑、结构化的知识，可以直接用于推理。", "conclusion": "作为MDP的实例，我们提出了MDP-Agent，实现了代理性过程：为全面提升构建文档级别的梗概记忆，使用基于扩散的探索与垂直开发来发现层次依赖关系，并应用映射-减少式的合成将大规模证据整合到紧凑而充分的上下文中。在信息检索基准上的实验表明，MDP-Agent在基线之上表现更佳，验证了MDP框架的合理性和其代理性实例的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25327", "html_url": "https://arxiv.org/abs/2510.25327", "title": "MMEdge：通过流水线化传感与编码加速设备端多模态推理", "title_en": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding", "authors": "Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang", "background": "资源受限边缘设备上的实时多模态推理对于自动驾驶、人机交互和移动健康等应用至关重要。然而，现有研究往往忽略了传感器动态与模型执行之间紧密耦合关系以及不同模态间的复杂依赖关系。", "innovation": "本文提出了一种基于流水线化传感和编码的新设备端多模态推理框架MMEdge。MMEdge将整个推理过程分解为一系列细粒度的传感和编码单元，允许在数据到达时通过增量计算。此外，MMEdge引入了一个轻量级但有效的时序聚合模块，以捕捉不同流水线单元之间的丰富时序动态，从而保持准确性能。MMEdge还结合了自适应多模态配置优化器，动态选择每种模态的最佳传感和模型配置以满足延迟约束条件，以及跨模态推测跳过机制，能够在早期预测达到足够信心时跳过较慢模态的未来单元。", "conclusion": "我们使用两个公开多模态数据集评估了MMEdge，并将其部署在一个真实的基于无人驾驶航空器（UAV）的多模态测试平台上。结果表明，MMEdge在各种系统和数据动态条件下显著降低了端到端延迟，同时保持了高任务准确性。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25366", "html_url": "https://arxiv.org/abs/2510.25366", "title": "依赖凸性的两阶段深度神经网络训练算法", "title_en": "A Convexity-dependent Two-Phase Training Algorithm for Deep Neural Networks", "authors": "Tomas Hrycej,Bernhard Bermeitinger,Massimo Pavone,Götz-Henrik Wiegand,Siegfried Handschuh", "background": "机器学习的关键任务是通过最小化衡量模型与训练数据拟合度的损失函数来优化模型。高效执行这一任务的数值方法依赖于损失函数的特性。这些特性中最关键的是损失函数是否凸。由于损失函数往往具有非凸区域，非凸方法如Adam被广泛应用。但局部最小值意味着在其周围的环境中，该函数是凸的。在这种环境中，二次最小化方法如共轭梯度（CG）能够确保超线性收敛。现有文献指出，实任务中的损失函数在接近最优解时，会从初始的非凸状态转变为凸状态，这一特性激励了本研究设计了一种创新的两阶段优化算法。", "innovation": "该研究提出了一种基于损失函数从非凸向凸转变的假设的新型框架，并据此设计了一个两阶段优化算法。该算法通过观察梯度模依赖于损失的变化来检测这一转变点，在非凸区域使用非凸算法（如Adam），在凸区域使用凸算法（如CG）。计算实验验证了这一点结构在实际应用中足够常见，可以用于显著提高收敛性和准确性。", "conclusion": "该研究通过利用实任务中的损失函数从非凸向凸转变的特性，提出了一种两阶段优化算法，该算法结合了非凸（如Adam）和凸（如CG）方法，能够在提高收敛性和准确性方面获得显著效果。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25744", "html_url": "https://arxiv.org/abs/2510.25744", "title": "完成 ≠ 合作：随代理扩展合作努力", "title_en": "Completion $\\neq$ Collaboration: Scaling Collaborative Effort with Agents", "authors": "Shannon Zejiang Shen,Valerie Chen,Ken Gu,Alexis Ross,Zixian Ma,Jillian Ross,Alex Gu,Chenglei Si,Wayne Chi,Andi Peng,Jocelyn J Shen,Ameet Talwalkar,Tongshuang Wu,David Sontag", "background": "目前对代理的评估依然集中于一次性的任务完成，未能考虑许多现实世界问题的迭代性和合作性本质，以及人类目标的不明确性和随时间变化性。本文指出应从构建和评估任务完成代理转向开发更侧重合作的代理，后者不仅根据其最终输出的质量，还在整个问题解决过程中与人类互动的质量来评估。", "innovation": "提出了合作努力扩展框架（Collaborative Effort Scaling），这是一种衡量在用户参与度增加时代理效用如何增长的框架。通过案例研究和模拟评估，证实了最先进的代理在多轮、现实生活场景下表现不佳，揭示了代理设计中缺失的关键元素：持续保持用户参与并提升其理解能力的能力。", "conclusion": "合作努力扩展为企业提供了一个评估代理行为的视角，并有助于指导开发更有效的互动。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25776", "html_url": "https://arxiv.org/abs/2510.25776", "title": "StreetMath: Study of LLMs' Approximation Behaviors", "title_en": "StreetMath: Study of LLMs' Approximation Behaviors", "authors": "Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong", "background": "已有大量研究探讨了大型语言模型（LLM）的数学推理能力，特别是在自回归架构中精确进行算术运算的表现。然而，它们在非正式、快节奏的数学运算中的近似推理能力则较少受到关注，尤其是对于非自回归解码模型而言。本文旨在弥补这一空白。", "innovation": "本文介绍了StreetMath，一个旨在评估模型在实际近似场景中的近似能力的基准。研究对不同架构的LLM进行了广泛测试，并使用机制可解释性技术探究它们的内部计算状态。研究发现，LLM通常试图在需要近似操作的任务中计算精确值或调用外部工具。此外，尽管模型有时在早期层或步骤中得到正确的答案，但在解决近似任务时仍消耗更多令牌。研究表明，准确和近似的算术运算主要依赖于不同的神经组件。", "conclusion": "尽管LLM在解决具体任务时表现出一定的精确度，但它们在近似推理方面并不像人类在街头数学设置中表现出的认知吝啬。本文的开放源代码为研究提供了工具。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25778", "html_url": "https://arxiv.org/abs/2510.25778", "title": "基于模糊逻辑算法方法的产品实体评分分析", "title_en": "Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach: Analysis", "authors": "Pratik N. Kalamkar,Anupama G. Phakatkar", "background": "意见挖掘，又称情感分析，是研究人们对于产品、服务、组织、个人、事件、议题及其属性的意见、情感、评价和态度的领域。传统的整体词典方法无法考虑意见的强度，即意见是极负面（或正面）、负面（或正面）、中等负面（或正面）、极轻微负面（或正面）或轻微负面（或正面）。本文探讨了一种结合感兴趣产品方面相关意见词（如副词、形容词、名词和动词），通过模糊逻辑算法方法和语法依赖解析，按意见的倾向性和强度对实体进行排名的方法。", "innovation": "本文提出了一种基于模糊逻辑算法方法的产品实体评分系统，通过粒度分类（极轻微、轻微、中等、极强、强）来评估意见词的强度；并使用语法依赖解析来识别与用户查询相关的方面，从而更好地对实体进行评分。", "conclusion": "本文通过结合模糊逻辑算法和语法依赖解析，旨在实现对产品相关实体基于正面或负面评价及其强度的评价和排序。这种方法可以为用户提供更加精确定位和理解用户意见情感的过程，进而提升产品和服务的质量改进和满意度提升。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25786", "html_url": "https://arxiv.org/abs/2510.25786", "title": "黑箱自然语言处理-2025 MIB 共享任务：通过更好的边选择提升电路忠实度", "title_en": "BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better Edge Selection", "authors": "Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov", "background": "机制可解释性的主要挑战之一是电路发现，即确定模型中哪些部分执行特定任务。之前的方法虽然有所尝试，但倾向于结果不够忠实地反映实际模型的运作机制。", "innovation": "该研究基于机制可解释性基准(MIB)进行改进，提出三项关键改进：使用自助法识别具有一致贡献得分的边；引入一种基于比率的边选择策略，平衡性能与忠实性；将标准贪婪选择算法替换为整数线性规划公式。这些改进提升了电路的忠实度，并在多个MIB任务和模型中超越了先前的方案。", "conclusion": "采用这些方法后，不仅获得了更忠实的电路表示，还显著优于之前的计算方案。相关代码已开源。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25799", "html_url": "https://arxiv.org/abs/2510.25799", "title": "倾听您的偏好：一种基于LLM的多目标选择框架", "title_en": "LISTEN to Your Preferences: An LLM Framework for Multi-Objective Selection", "authors": "Adam S. Jovine,Tinghan Ye,Francis Bahk,Jingjing Wang,David B. Shmoys,Peter I. Frazier", "background": "人类专家在从大量具有多个竞争目标的选项中选择最佳方案时通常遇到困难，这一过程受复杂、隐含偏好难以形式化表达的瓶颈制约。现有技术难以解决这一问题。", "innovation": "该论文提出了一种名为LISTEN的框架，使用大型语言模型（LLM）作为零样本偏好 oracle，并仅通过专家自然语言提供的高层次优先级进行指导。为了在LLM的约束条件下（如上下文窗口和推理成本）操作，提出了两种迭代算法：LISTEN-U，通过LLM精炼参数化效用函数；以及LISTEN-T，一种非参数化方法，采用锦标赛制选择小批解决方案。评估结果显示两种方法在不同任务上的表现各有优势。", "conclusion": "研究通过自然语言引导复杂多目标决策，减少了传统偏好获取的认知负担，朝着一个有潜力的方向迈进。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25783", "html_url": "https://arxiv.org/abs/2510.25783", "title": "LASTIST: 大规模目标无关立场数据集", "title_en": "LASTIST: LArge-Scale Target-Independent STance dataset", "authors": "DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park", "background": "立场检测已经成为人工智能领域的研究热点。然而，大多数研究集中在以特定目标为中心的目标依赖性立场检测任务上，主要是基于个人对其特定目标的支持或反对态度。此外，大多数基准数据集基于英语，这使得在低资源语言如韩语中开发模型变得困难，尤其是对于新兴的立场检测这样一个领域而言。因此，缺乏适用于低资源语言的目标无关立场检测数据集。", "innovation": "本研究提出了LArge-Scale Target-Independent STance (LASTIST) 数据集，填补了这一研究空白。该数据集收集自韩国政党新闻发布会的双方新闻稿，包括563,299个标注的韩语句子。研究团队详细描述了数据的收集和构建过程，并训练了最先进的深度学习和立场检测模型。LASTIST 数据集旨在支持各种立场检测任务，包括目标无关立场检测和历时立场发展检测。", "conclusion": "研究团队发布了这一数据集，并通过官方网站提供了训练数据和详细资料。该数据集旨在为低资源语言如韩语的立场检测研究提供支持，有助于推动这一领域的研究与发展。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25804", "html_url": "https://arxiv.org/abs/2510.25804", "title": "长距离：长上下文LLM训练数据中的长距离信息量化", "title_en": "Beyond Length: Quantifying Long-Range Information for Long-Context LLM Pretraining Data", "authors": "Haoran Deng,Yingyu Lin,Zhenghao Lin,Xiao Liu,Yizhou Sun,Yi-An Ma,Yeyun Gong", "background": "长上下文语言模型可以通过利用长跨度文本中的依赖关系来实现出色的推理、代码生成和文档总结能力。然而，可用的长文本数据中大部分缺乏有意义的远距离依赖关系；大多数跨度可以仅通过局部上下文来预测。在这样的数据上进行训练效率低下，因此精心选择训练数据至关重要。", "innovation": "我们提出了LongFilter，一种专门为长上下文预训练设计的数据筛选框架。LongFilter通过对比模型在长上下文和短上下文设置下的预测结果来量化扩展上下文提供的信息增益，并识别出长距离依赖性至关重要的样本。", "conclusion": "在LLaMA-3-8B模型上将上下文长度扩展到64K的实验表明，LongFilter能够有效选择高质量的数据，并在HELMET、LongBench和RULER等基准测试中取得显著提升。"}
{"llm_update_time": "20251031", "topic": "cs.AI", "pdf_url": "https://arxiv.org/pdf/2510.25409", "html_url": "https://arxiv.org/abs/2510.25409", "title": "BhashaBench V1: 四个象限中的印地语领域综合基准", "title_en": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains", "authors": "Vijay Devane,Mohd Nauman,Bhargav Patel,Aniket Mahendra Wakchoure,Yogeshkumar Sant,Shyam Pawar,Viraj Thakur,Ananya Godse,Sunil Patra,Neha Maurya,Suraj Racha,Nitish Kamal Singh,Ajay Nagpal,Piyush Sawarkar,Kundeshwar Vijayrao Pundalik,Rohit Saluja,Ganesh Ramakrishnan", "background": "大型语言模型（LLM）的迅速发展加剧了对特定领域和文化评估的需求。现有的基准多以英语为中心且缺乏领域针对性，这限制了其在印度特定背景下的应用。为解决这一问题，本研究引入了BhashaBench V1，这是首个专注于批判性印地语知识系统的领域特定、多任务双语基准。BhashaBench V1 包含了74,166个精心筛选的问题-答案对，其中52,494个问题为英语，21,672个问题为印地语，来源自真实的政府和特定领域的考试。该基准涵盖了农业、法律、金融和阿育吠陀四大主要领域，包含90多个子领域和超过500个主题，以实现细致入微的评估。通过对29多种LLM的评估发现，模型在不同领域和语言上存在明显的性能差距，特别是在低资源领域差距较大。例如，GPT-4o在法律领域获得了76.49%的整体准确率，但在阿育吠陀领域只有59.74%。在所有领域中，模型在英语内容上的表现普遍优于印地语。子领域分析显示，网络法、国际金融等领域表现较好，而潘查 karma、种子科学和人权等领域则相对较弱。BhashaBench V1 为评估印度多样知识领域的语言模型提供了全面的数据集，使模型能够结合领域特定知识进行双语理解的评估。所有代码、基准和资源均公开，支持开放研究。", "innovation": "本研究创新地开发了BhashaBench V1，这是首个以领域特定、双语为基础，特别聚焦于关键印地语知识系统的评估基准。该基准涵盖多个重要的印度知识领域，包括农业、法律、金融和阿育吠陀，涉及到数十个子领域和数百个主题，这将使得大型语言模型在印度特定语境下的应用更为精确和全面。此外，该研究通过对多个LLM模型进行评估，揭示了不同领域和语言之间的性能差异，为语言模型进一步优化提供了有价值的参考。", "conclusion": "BhashaBench V1 为评估和比较各种大型语言模型在印度多样化知识领域中的表现提供了重要的数据参考，并支持进一步的研究。模型在不同语言和子领域的表现差异表明，对于低资源领域，需要进一步优化和提高语言模型的表现。该基准的公开共享有助于促进语言模型的开放研究和发展。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25805", "html_url": "https://arxiv.org/abs/2510.25805", "title": "基于意识形态的大型语言模型在内容审核中的应用", "title_en": "Ideology-Based LLMs for Content Moderation", "authors": "Stefano Civelli,Pietro Bernardelle,Nardiena A. Pratama,Gianluca Demartini", "background": "大型语言模型（LLMs）在内容审核系统中的应用日益增长，确保公平性和中立性至关重要。本文探讨了个人角色采用如何影响不同LLM架构、模型大小及内容模态（语言 vs. 视觉）下有害内容分类的一致性和公平性。", "innovation": "研究揭示了虽然从初步的性能指标来看，个人角色对总体分类准确性影响不大，但不同意识形态导向的个人角色在标签有害内容时显示出截然不同的倾向，表明模型通过“观看”输入的角度对其判断产生了微妙的影响。进一步的共识分析表明，特别是大型模型更倾向于与相同政治意识形态的个人角色保持一致，增加了同一意识形态内的共识同时加剧了不同意识形态之间的分歧。通过另一次关于政治导向任务的研究进一步证实，个人角色不仅在自己的意识形态内表现一致，还倾向于捍卫己方观点并削弱对立观点的有害性。", "conclusion": "这些发现强调，个人角色训练可以向LLM输出中引入微妙的意识形态偏见，这可能引起对可能通过中立名义强化党派观点的AI系统的担忧。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25817", "html_url": "https://arxiv.org/abs/2510.25817", "title": "从数据为中心的角度对高效大型语言模型训练的综述", "title_en": "A Survey on Efficient Large Language Model Training: From Data-centric Perspectives", "authors": "Junyu Luo,Bohan Wu,Xiao Luo,Zhiping Xiao,Yiqiao Jin,Rong-Cheng Tu,Nan Yin,Yifan Wang,Jingyang Yuan,Wei Ju,Ming Zhang", "background": "大型语言模型（LLMs）的训练后处理对于实现任务泛化能力和领域特定能力至关重要，然而当前的LLM训练后处理方法面临巨大的数据挑战，包括手动标注成本高和数据规模增加效益递减的问题。因此，如何在数据使用方面高效地进行训练后处理已成为一个关键的研究问题。本文旨在从数据为中心的角度提供首次系统性的训练后处理综述，从而提升数据使用效率。", "innovation": "提出了数据高效训练后处理方法的分类，涵盖数据选择、数据质量提升、合成数据生成、数据蒸馏和压缩，以及自我进化的数据生态系统。总结了每个类别中的代表性方法，并指出了未来的研究方向，强调了解数据高效训练后处理中的挑战并提出了潜在的研究途径。", "conclusion": "本文旨在通过审视数据高效LLM训练后处理中的挑战来突出开放问题，并提出潜在的研究途径，以期进一步探索最大化大数据利用潜力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25816", "html_url": "https://arxiv.org/abs/2510.25816", "title": "超越长上下文：当语义比 token 更重要时", "title_en": "Beyond Long Context: When Semantics Matter More than Tokens", "authors": "Tarun Kumar Chawdhury,Jon D. Duke", "background": "电子健康记录（EHR）中的临床文档以 base64 编码的附件形式存储在 FHIR DocumentReference 资源中，这使得语义问题回答变得困难。传统的向量数据库方法往往忽略了细微的临床关系。", "innovation": "我们开发了一个临床笔记问答评估平台，用来验证 Lopez 等人 2025 年提出的 CLEAR 方法。该方法使用实体感知检索，在 F1 得分为 0.90 的情况下，与基于嵌入的检索相比，使用了超过 70% 更少的 token。评估表明，CLEAR 在 12 份从 10,000 到 65,000 token 不等的临床笔记中，达到了 58.3% 的胜率和平均 0.878 的语义相似度，使用 token 数量减少了 78% 。对于超过 65,000 token 的长文档，CLEAR 的成功率达到了 75% 。这表明实体感知检索提升了临床自然语言处理的效率和准确性。", "conclusion": "该研究发现，实体感知检索在临床问答系统中不仅提高了准确性，还提升了效率。评估框架提供了一个可重复且透明的基准，用于评估依赖于语义精确度和计算效率的临床问答系统。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25904", "html_url": "https://arxiv.org/abs/2510.25904", "title": "LLM协助注释在视角化设置中的影响评估：FrameNet标注案例", "title_en": "Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation", "authors": "Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent", "background": "当前，基于LLM的应用程序正被用作加速或替代人类劳动力的手段，以创建语言资源和数据集。尽管这些工具在语言研究中具有潜在价值，但对其在创建注释数据集方面的性能进行全面评估，尤其是从语境化的人工智能视角来看，仍然缺乏研究。现有研究仍未充分探索LLM在如FrameNet这类语义标注任务中的半自动化应用效果.", "innovation": "本文贡献在于通过报告基于LLM的语义角色标注在FrameNet语义标注中的半自动化评估，填补了该领域的研究空白。研究采用手动、自动和半自动三种注释设置来比较标注时间、覆盖率和多样性，并发现半自动注释设置在反馈角度上提高了框架多样性，而全自动化注释在所有指标上表现糟糕，只有标注时间有所优势.", "conclusion": "研究表明，在半自动设置下进行的结合人类标注与LLM协助的标注方法，在提高框架多样性方面优于完全由人类标注的方法，尽管全自动化方法在标注时间上有优势，但总体性能较低。这一发现为今后从语境化视角优化NLP数据注释的流程提供了参考."}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25967", "html_url": "https://arxiv.org/abs/2510.25967", "title": "跨文化翻译中的语义标签漂移", "title_en": "Semantic Label Drift in Cross-Cultural Translation", "authors": "Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Polydoros Giannouris,Sophia Ananiadou", "background": "机器翻译广泛用于解决低资源语言的资源稀缺问题，通过从高资源语言生成合成数据。尽管对情感保留的研究历史悠久，但跨文化语境下源语言和目标语言之间的文化对齐作用仍是一个被忽视的关键因素。本文假设在翻译过程中，由于文化差异，语义标签发生了漂移或改变。", "innovation": "本文通过一系列跨文化和非文化敏感领域的实验，揭示了以下三点关键发现：（1）包括现代大规模语言模型在内的机器翻译系统在翻译过程中导致标签漂移，尤其在文化敏感领域；（2）与之前的统计机器翻译工具不同，大规模语言模型编码了文化知识，利用这些知识会加剧标签漂移；（3）源语言和目标语言的文化相似度或差异是标签保留的关键决定因素。", "conclusion": "我们的研究成果表明，在翻译中忽视文化因素不仅影响了标签的准确性，还可能在下游应用中导致误解和文化冲突。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25947", "html_url": "https://arxiv.org/abs/2510.25947", "title": "重新审视语言模型预训练中的多语言数据混合", "title_en": "Revisiting Multilingual Data Mixtures in Language Model Pretraining", "authors": "Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut", "background": "在大规模语言模型（LLMs）的预训练过程中，不同多语言数据混合的影响一直是一个争议话题。人们普遍担心多语言训练可能导致语言覆盖率和模型性能之间的权衡（即多语言化诅咒）。因此，关于多语言训练的常见假设需要进一步验证和挑战。本文通过在25到400种不同语言的大规模多语言语料库上分别训练1.1B和3B参数的语言模型来探讨这一问题。", "innovation": "本研究挑战了关于多语言训练的一些常见信念。首先，研究发现，结合英语和多语言数据可以在确保足够数量的令牌包含在训练语料库中的条件下不损害单一语言组的语言性能。其次，研究发现将英语作为枢纽语言（即一种资源丰富的语言，可以促进多语言泛化）对不同语言家族的语言都有益处，而意外地发现，选择同一家族内的枢纽语言在特定家庭内的一致性改进绩效并不明显。最后，研究表明，在这种规模的语言模型中，训练语言数量的增加并不会导致显著的多语言化诅咒现象，这表明当数据平衡充足时，多语言数据可以在保持低资源语言环境下的性能的前提下增强语言模型的能力。", "conclusion": "综上所述，本研究指出适当平衡的多语言数据可以不牺牲性能，甚至在低资源的语言建模场景中也能增强语言模型的能力。这为多语言训练提供了一个新的视角，挑战了之前的诸如多语言化诅咒等常见假设。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25784", "html_url": "https://arxiv.org/abs/2510.25784", "title": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "title_en": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "authors": "Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee", "background": "大型语言模型（LLM）正日益被部署为带有针对多种下游应用的任务特定适配器。虽然这些适配器参数的数量一般很少（通常不到基模型的1%），但在推理时，附加计算量却变得异常显著，几乎是基模型的2.5倍。", "innovation": "本文提出了一种新的零延迟融合低秩适配器（zFLoRA），该方法在基模型之上无需或几乎不增加延迟开销。实验结果表明，在1B、3B和7B规模的LLM上，zFLoRA在与流行的监督微调基准（包括低秩适配器LoRA及整个微调FFT）对比时表现良好。", "conclusion": "通过在18个跨三种不同类别（常识推理、数学推理和摘要对话）的任务上的实验以及针对NPU（三星Galaxy S25+）和GPU（NVIDIA H100）平台的延迟测量，证明了提出的zFLoRA适配器引入了零到微不足道的延迟开销。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25941", "html_url": "https://arxiv.org/abs/2510.25941", "title": "RECAP: 利用代理管道从大语言模型训练数据中再现受版权保护的数据", "title_en": "RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic Pipeline", "authors": "André V. Duarte,Xuying li,Bin Zeng,Arlindo L. Oliveira,Lei Li,Zhuo Li", "background": "如果无法检查大型语言模型的训练数据，我们如何知道它看到了什么？我们相信最令人信服的证据出现于模型本身自由地再现目标内容之时。因此，我们提出了RECAP，这是一种代理管道，旨在从LLM输出中激发并验证记忆中的训练数据。RECAP的核心是一个反馈驱动的循环，通过一个初步提取尝试，由第二个语言模型评估输出，与参考段落对比并识别差异，然后将这些差异转化为最小的修正提示并反馈给目标模型以指导后续生成。此外，为了应对对齐导致的拒绝，RECAP还包括一个‘脱管’模块，用于检测并克服这些障碍。我们使用EchoTrace进行评估，这是一个涵盖超过30本完整书籍的新基准，结果显示RECAP在单迭代方法上带来了显著提高，例如，使用GPT-4.1，受版权文本提取的平均ROUGE-L分数从0.38提高到了0.47，增加了近24%。", "innovation": "1. DECAP提出了一种代理管道，能够从大语言模型生成的输出中提取已学习的训练数据。\n2. 该方法通过反馈循环进行纠错和修正，进一步提高提取精度。\n3. 加入了‘脱管’模块来解决由于对齐问题引起的拒绝提取情况，确保更多内容可以被提取出来。\n4. 通过EchoTrace评估显示其显著的性能提升，特别是在受版权文本的提取方面。", "conclusion": "本文提出了一种新的方法RECAP，通过一个反馈驱动的代理管道，提高从大语言模型中提取受版权保护的数据的准确性，特别是在GPT-4.1上得到了显著的提升，其ROUGE-L分数提高了近24%。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25975", "html_url": "https://arxiv.org/abs/2510.25975", "title": "SymCode：通过可验证代码生成的神经符号方法进行数学推理", "title_en": "SymCode: A Neurosymbolic Approach to Mathematical Reasoning via Verifiable Code Generation", "authors": "Sina Bagheri Nezhad,Yao Li,Ameeta Agrawal", "background": "大型语言模型（LLMs）在处理复杂的数学推理时常常遇到困难，因为基于文字的生成导致了未经验证和算术上不准确的解决方案。现有的提示策略，如Chain of Thought，仍然在这种不可靠的环境中运作，缺乏确定性的验证机制。", "innovation": "我们提出SymCode，这是一种神经符号框架，利用SymPy库将数学问题解决重新定义为可验证的代码生成任务。在MATH-500和OlympiadBench等具有挑战性的基准测试中，SymCode显著提高了准确率，相对于基线提高了13.6个百分点。我们的分析表明，SymCode不仅是更高效的token利用，而且从根本上改变了模型的失败模式，从不透明的逻辑谬误转向清晰的程序错误。通过在确定性的符号引擎中扎根LLM的推理，SymCode为更准确和可信赖的AI在形式领域奠定了关键步骤。", "conclusion": "通过将LLM的推理 grounding 在一个确定性的符号引擎中，SymCode代表了一步向更准确和可信赖的人工智能在正式领域的迈进。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25977", "html_url": "https://arxiv.org/abs/2510.25977", "title": "NeuronMM: 雷达MM - 用于AWS Trainium 上的大语言模型推理的高性能矩阵乘法", "title_en": "NeuronMM: High-Performance Matrix Multiplication for LLM Inference on AWS Trainium", "authors": "Dinghong Song(1),Jierui Xu(2),Weichu Yang(2),Pengfei Su(1),Dong Li(1) ((1) University of California, Merced, (2) University of Wisconsin, Madison)", "background": "AI加速器定制化设计可以提供低成本且高性能的训练和推理解决方案。Amazon Web Services (AWS) 最近开发的AI加速器Trainium，拥有异构架构，可以为大型语言模型（LLM）的训练和推理提供有吸引力的选项。然而，利用Trainium的高性能可能因为其阵列架构和对数据布局的特殊要求而具有挑战性。", "innovation": "本文设计了针对Trainium的、用于LLM推理的高性能矩阵乘法（matmul）。提出了一种基于内核融合和新颖缓存策略的技术系列来减少跨软件管理缓存层次的数据移动，最大化SRAM带宽，并避免昂贵的矩阵转置。", "conclusion": "通过在九个数据集和四个最新的LLM上进行评估，证明我们的系统在核心matmul内核中比AWS在Trainium上实施的最先进的matmul大幅领先，平均1.35倍速度提升（最高2.22倍），这将最终LLM推理的端到端速度提升平均1.66倍（最高2.49倍）。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25979", "html_url": "https://arxiv.org/abs/2510.25979", "title": "AttnCache：通过注意图缓存加速LLM前推阶段自我注意推理", "title_en": "AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache", "authors": "Dinghong Song(1),Yuan Feng(1),Yiwei Wang(1),Shangye Chen(1),Cyril Guyot(2),Filip Blagojevic(2),Hyeran Jeon(1),Pengfei Su(1),Dong Li(1) ((1) University of California, Merced, USA, (2) Western Digital Research, USA)", "background": "大规模语言模型（LLMs）在生成应用如聊天、代码生成和推理中广泛应用。然而，许多实际工作负载如分类、问答、推荐和文本嵌入仅依赖于推断的前推阶段，此时模型需要编码输入序列而无需进行自回归解码。在此阶段，自注意力计算因序列长度的平方复杂性而成为主要的性能瓶颈。研究表明，语义不同的句子在多个层和头部产生相似的自注意力图。基于此观察，我们提出AttnCache框架，通过检索和重用相似的自注意力图来加速LLM前推阶段的推断。", "innovation": "AttnCache框架通过自注意力图记忆数据库以及高效缓存和相似搜索技术识别和重用预先缓存的自注意力图，从而减少自注意力的计算开销，实现自我注意推理的加速。", "conclusion": "实验结果显示，AttnCache在CPU和GPU上分别实现了2倍和3倍的自我注意加速，且对准确性的影响几乎可以忽略不计。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25992", "html_url": "https://arxiv.org/abs/2510.25992", "title": "监督强化学习: 从专家轨迹到分步推理", "title_en": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning", "authors": "Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee", "background": "大规模语言模型（LLMs）在需要多步推理的问题上经常表现不佳。对于小型开源模型，强化学习结合可验证奖励（RLVR）在正确解决方案较难采样时往往会失败，而监督微调（SFT）则倾向于通过严格的逐个令牌模仿过度拟合长时间的示例。", "innovation": "本文提出了监督强化学习（SRL）框架，将问题解决重新表述为产生“逻辑行动”序列的过程。SRL 训练模型在执行每个行动前生成内部的逻辑推理语言。这种方法提供了基于模型行动与从 SFT 数据集中提取的专家行动之间的相似度逐步给出的平滑奖励。相比 RLVR 和 SFT，SRL 使小模型能够学习之前难以通过 SFT 或 RLVR 学习的复杂问题，特别是将 SRL 用于初步训练和随后与 RLVR 结合使用提高了整体性能。此外，SRL 在需要推理的任务和代理软件工程任务中表现出良好的泛化能力，使其成为面向推理的语言模型的强大且灵活的训练框架。", "conclusion": "监督强化学习不仅克服了现有方法的问题，还表明了其广泛的应用潜力，特别是在那些依赖于智能代理进行复杂推理任务的领域。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26024", "html_url": "https://arxiv.org/abs/2510.26024", "title": "重新思考跨语言对齐：多语言LLM中转移与文化缺失的平衡", "title_en": "Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs", "authors": "HyoJung Han,Sweta Agrawal,Eleftheria Briakou", "background": "跨语言对齐（CLA）旨在对齐多语言表示，使大规模语言模型（LLMs）能够无缝地在语言之间传递知识。然而，我们假设这种追求表征收敛可能会无意中导致“文化侵蚀”，即功能上损失了提供基于查询语言的文化情境响应的能力。本文通过引入一个综合评价框架——转移-本地化平面，系统分析了这一权衡。这一框架量化了期望的知识转移和不希望的文化侵蚀。研究发现，近期的CLAD方法在提升事实转移方面表现出一致性的同时，在所有六个研究语言中都以文化本地化为代价。", "innovation": "本文提出了手术调控方法（Surgical Steering），这是一种新颖的推理时策略，通过有针对性地控制不同的模型层的激活，实现这两种目标的最佳解耦，从而在两个竞争维度之间取得更好的平衡，克服了当前对齐技术的局限性。", "conclusion": "研究表明，通用事实转移和文化特定知识应在不同的模型层上最优控制。通过这种方式，研究提出的方法能够在知识转移和文化本地化之间达到更好的平衡。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26122", "html_url": "https://arxiv.org/abs/2510.26122", "title": "推理路径分歧：一种新度量及筛选策略，解锁大型语言模型的多样性思考", "title_en": "Reasoning Path Divergence: A New Metric and Curation Strategy to Unlock LLM Diverse Thinking", "authors": "Feng Ju,Zeyu Qin,Rui Min,Zhitao He,Lingpeng Kong,Yi R. Fung", "background": "虽然测试时缩放（TTS）在提高大型语言模型（LLMs）的推理能力方面已被证明是有效的，但由于模型输出低多样性的问题成为瓶颈，这在一定程度上是由常见的‘一个问题，一个解决方案’（1P1S）训练实践造成的，这种实践提供了唯一标准答案，促使模型局限于一系列狭隘的推理路径中。", "innovation": "本文提出了‘一个问题，多种解决方案’（1PNS）的训练范式，使模型接触到多种有效的推理轨迹，从而增加推理多样性。为了可靠地测量多步思维链条之间的语义差异，提出了一种步骤级的度量标准——推理路径分歧（RPD），用于对长思维链解决方案进行对齐和评分，以捕捉中间推理的不同之处。数据显示，使用RPD选出的训练数据能产生更多样性的输出和更高的pass@k，尤其是对于AIME24，提高了4.99%，表明1PNS进一步放大了TTS的效果。", "conclusion": "研究结果证明，通过引入推理路径分歧（RPD）和‘一个问题，多种解决方案’（1PNS）的训练范式，可以有效地增加模型的推理多样性，提升测试时缩放（TTS）的效果。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26020", "html_url": "https://arxiv.org/abs/2510.26020", "title": "PORTool: 用奖励树进行工具使用的大语言模型训练", "title_en": "PORTool: Tool-Use LLM Training with Rewarded Tree", "authors": "Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao", "background": "当前的大语言模型（LLMs）是在静态数据集上进行训练的，能够与外部工具互动并执行多步骤的、工具集成的推理，从而生成工具调用路径。然而，这些模型模仿了一种通用的工具调用规程，未能探索可能的解决方案，在动态变化的工具调用环境中，表现较弱。在现阶段，这些模型缺乏探索不同策略的能力，特别是在面对复杂和动态的任务时，其性能也受限。为解决上述问题，该研究提出了PORTool（使用奖励树的方法）.", "innovation": "该研究提出了一种基于强化学习（RL）的方法——PORTool，旨在促使工具使用的大语言模型探索各种可以产生正确答案的路径。具体来说，PORTool通过生成多个卷积轨迹，至少形成初始几步共享的树状结构，并基于每个步骤生成正确答案和工具调用的成功能力来提供奖励。共享的步骤得到相同的奖励，而不同的分支步骤得到不同的奖励。最后，利用这些奖励来计算分支相对优势和轨迹相对优势，从而培训大语言模型进行工具使用。此外，研究还利用17种工具应对用户查询，包括时间敏感和时间非敏感的主题，并通过消融研究系统地验证了步骤奖励的必要性和设计稳健性.", "conclusion": "实验结果表明，与现有的训练方法相比，PORTool在最终准确性和工具调用步骤数上有显著提升。本研究证实，通过使用奖励树的方法，可以使大语言模型更好地进行工具使用，并在动态环境中获得更优的表现。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26124", "html_url": "https://arxiv.org/abs/2510.26124", "title": "在说服性文本中话语关系的影响", "title_en": "On the Influence of Discourse Relations in Persuasive Texts", "authors": "Nawar Turk,Sevag Kaspar,Leila Kosseim", "background": "本研究致力于通过利用大型语言模型（LLMs）和指令工程来探讨说服技巧（PTs）和话语关系（DRs）之间的关联。由于同时标注PTs和DRs的数据集不存在，研究者以标注有19种PTs的SemEval 2023任务3数据集为起点，通过LLM构建分类器，将数据集中的每一实例标注为22种PDTB 3.0层级二别书中的某一种DRs。评估了四种不同的LLM和十种不同的指令，生成了40种独特的DR分类器。使用基于不同多数投票策略的集成模型创建了五个包含两者均标注的实例的银色数据集，这些数据集的大小根据所使用的多数投票技术而异，从1,281个实例到204个实例不等。", "innovation": "研究创新之处在于使用大型语言模型和指令工程来填补PTs和DRs共同标注数据集的空白，并且通过跨多个LLM和不同指令构建了40种独特的DR分类器，进而利用这些数据集分析了哪些DRs在说服性文本中扮演关键角色。研究成果对检测网络宣传和误导，以及对有效沟通的理解均有贡献。", "conclusion": "统计分析结果显示，不论是有信念的因由、目的、对比、有信念的因由、让步和条件等六种话语关系，在使用加载语言、夸张/淡化、重复和制造怀疑上扮演着关键角色，这为检测网络宣传和误导提供了理论基础，并加深了对有效交流的理解。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26182", "html_url": "https://arxiv.org/abs/2510.26182", "title": "MossNet: Mixture of State-Space Experts is a Multi-Head Attention", "title_en": "MossNet: Mixture of State-Space Experts is a Multi-Head Attention", "authors": "Shikhar Tuli,James Seale Smith,Haris Jeelani,Chi-Heng Lin,Abhishek Patel,Vasili Ramanishka,Yen-Chang Hsu,Hongxia Jin", "background": "大型语言模型（LLMs）在自然语言处理（NLP）中的生成应用取得了显著进展。最近模型架构的趋势围绕着高效的 Transformer 变体或其他状态空间/门控循环模型（SSMs、GRMs）。然而，现有的基于 SSM/GRM 的方法通常只能模拟单个注意力头，这可能限制了它们的表达能力。", "innovation": "本文提出了 MossNet，一种新颖的状态空间专家混合架构，它模拟了线性多头注意力（MHA）。MossNet 不仅在通道混合多层感知器（MLP）块中使用专家混合（MoE）实现，还在时间混合 SSM 核中使用 MoE 实现多个“注意力头”。实验表明，MossNet 在语言建模和下游任务评估中优于同等规模和数据预算的Transformer-和SSM-基于的架构。大型的MossNet 变体在训练过程中进一步证明了其可扩展性和优越性能。此外，在实际设备上对三星 Galaxy S24 Ultra 和 Nvidia A100 GPU 进行的性能测试显示，MossNet 在资源使用和运行时速度方面优于其他同等规模的基线模型。", "conclusion": "研究表明，MossNet 是一种具有强大潜力的方向，可以用于高效、高性能的递归 LLM 架构。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26101", "html_url": "https://arxiv.org/abs/2510.26101", "title": "QCoder基准：通过模拟器反馈实现语言生成与量子硬件的连接", "title_en": "QCoder Benchmark: Bridging Language Generation and Quantum Hardware through Simulator-Based Feedback", "authors": "Taku Mikuriya,Tatsuya Ishigaki,Masayuki Kawarada,Shunya Minami,Tadashi Kadowaki,Yohichi Suzuki,Soshun Naito,Shunya Takata,Takumi Kato,Tamotsu Basseda,Reo Yamada,Hiroya Takamura", "background": "大型语言模型（LLMs）在自动编程代码生成中越来越受欢迎。这一任务可以被视为一种连接自然语言、人类知识和编程逻辑的语言生成任务。然而，它在需要与硬件设备交互的领域（如量子编程）中仍旧研究不足。在量子编程领域，人类程序员会编写用于在量子计算机上执行的Python代码。本研究通过引入QCoder基准，提供了一种评估LLMs在量子编程中的表现的方法，特别是结合了模拟硬件设备的反馈机制，这一方法能提供量子电路深度、执行时间和错误分类等特定领域的指标作为指导，还能将真实编程比赛的人类编写的代码提交作为定量比较和定性分析的基础，从而弥补现有研究中的空白。", "innovation": "QCoder基准是一个综合性评估框架，首次实现了结合模拟器反馈的LLMs在量子编程领域的评估。它具有两个创新点：一是支持使用量子模拟器环境进行评估，并提供特定领域的反馈指标（如电路深度、执行时间和错误分类）；二是整合了从真实编程竞赛收集的人类编写的代码提交，可以进行定量比较和定性分析LLMs与人类编写的代码的输出差异。本研究结果显示，即使是先进的模型GPT-4o也只达到了约18.97%的准确性；而基于推理的模型o3则达到了高达78%的准确性，超过了人类编写的平均成功率39.98%。这表明LLM在量子编程任务中的应用仍具有很大的挑战。QCoder基准数据集和公共评估API已被发布，以支持进一步的研究工作。", "conclusion": "这项研究表明，LLMs在量子编程任务中面临的挑战非常大，尤其是在准确性方面，只有经过设计来考虑底层硬件逻辑的模型（如o3）才能取得显著的性能提升。QCoder基准的发布将有助于未来的相关研究，可能促进更高效、更精确的LLMs开发以更好地适应量子编程的需求。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26032", "html_url": "https://arxiv.org/abs/2510.26032", "title": "基于人工智能分析的放射报告：非甲状腺影像发现的流行病学及其后果", "title_en": "Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings", "authors": "Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito", "background": "随着医学影像检查用于非甲状腺疾病诊断的增加，无意中发现了甲状腺发现（ITFs）。这些发现的发病率、特征及其临床后果尚未明确界定。这项研究旨在开发、验证并部署一个基于自然语言处理（NLP）的流水线，以识别放射报告中的ITFs，并评估其发病率、特征及其临床结果。研究在2017年7月1日至2023年9月30日期间，在梅奥诊所进行甲状腺捕获成像的成年患者中进行了回顾性研究，共计115,683名患者（平均年龄56.8岁，标准差17.2；女性占52.9%）。研究中发现ITFs的患者有9,077名（占7.8%），其中92.9%为结节。与胸部CT相比，颈部CT、PET和核医学扫描中发现ITFs的频率更高。结节特征记录不充分，大小在44%的病例中被报告，而其他特征在不到15%的病例中被记录。与未发现ITFs的患者相比，发现ITFs的患者甲状腺结节诊断、穿刺活检、甲状腺切除术和甲状腺癌诊断的风险更高，且ITFs后发现的大多数癌症为乳头状癌，并且肿瘤体积更大。这些发现强调了ITFs在甲状腺癌过诊断中的作用，并指出了标准化报告和更选择性随访的需求。", "innovation": "研究开发并应用了一个基于自然语言处理（NLP）的流水线来识别非甲状腺影像检查中发现的甲状腺异常结节（ITFs），并对这些发现的流行病学特征及其临床后果进行了评估。此外，该研究还揭示了ITFs对后续甲状腺癌诊断的影响，并强调了标准化报告和选择性随访的必要性。这项工作代表了一种新的方法来识别和管理这些意外发现，可能有助于减少甲状腺癌过诊断的问题。", "conclusion": "这项研究发现，ITFs相对常见，与检测小、低风险癌症的连锁反应密切相关。这些结果强调了ITFs在甲状腺癌过诊断中的作用，并突显了标准化报告和更选择性随访的必要性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26183", "html_url": "https://arxiv.org/abs/2510.26183", "title": "相似性-距离-幅度语言模型", "title_en": "Similarity-Distance-Magnitude Language Models", "authors": "Allen Schmaltz", "background": "本文介绍了Similarity-Distance-Magnitude (SDM) 语言模型，这些模型是序列预测模型，经过微调以最大化生成在最终层SDM激活层划分的高概率、校准良好的区域中的比例，用于指令遵循的二分类任务。现有的预训练解码器变压器语言模型可以通过监督微调轻松转化为SDM语言模型，使用最终层的SDM激活层在对比输入编码方案上估计一个变化基数，并在训练过程中生成额外的硬负例，来缩小下一个标记的监督损失。这种做法相比强的监督基准降低了自拒现象（即提高了统计效率）", "innovation": "1. 提出了SDM语言模型，通过最大化生成在高概率、校准良好的区域中的比例来优化模型表现。\n2. 通过监督微调，使用最终层的SDM激活层来估计变化基数，并在监督下一个标记的损失中应用，从而提升了模型性能。\n3. 在训练过程中生成额外的硬负例，进一步增强了模型的学习能力", "conclusion": "通过提出SDM语言模型，以及在监督微调中应用特定的训练方法，本文改进了指令遵循任务的统计效率，相较于现有的强监督基准，减少了自拒现象的发生。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26200", "html_url": "https://arxiv.org/abs/2510.26200", "title": "不要让它们褪色：通过标记时间分配在扩散语言模型中保留编辑", "title_en": "Don't Let It Fade: Preserving Edits in Diffusion Language Models via Token Timestep Allocation", "authors": "Woojin Kim,Jaeyoung Do", "background": "虽然扩散语言模型（DLMs）能够实现精细的调整，但其实际可控性较弱。研究识别并正式描述了一种关键失败模式——更新遗忘。这种失败源于均匀且与上下文无关的更新，导致字元级别的波动，逐渐抹去早期的语义编辑，破坏累积细化过程，从而影响流畅性和连贯性。", "innovation": "该研究提出了一种标记时间分配（TTA）方法，通过标记级别的时间调度实现了软的、语义上的标记排序：关键标记在早期固定，不确定的标记继续细化。这种方法可以根据固定的策略或任务信号驱动的可调整策略实现，支持各种细化策略。TTA方法仅在推理时运行，适用于各种DLMs，自然扩展到多种监督来源。", "conclusion": "实验结果显示，TTA提高了可控性和流畅性：在情感控制方面，它比以往方法提高了20%以上的准确性，减少了约一半的困惑度，同时仅用了不到五分之一的步骤；在解毒方面，它降低了最大毒性（从14.5降至12.2）和困惑度（从32.0降至26.0）。这些结果表明，通过时间分配实现的柔和排序是缓解更新遗忘和实现稳定可控扩散文本生成的关键杠杆。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26202", "html_url": "https://arxiv.org/abs/2510.26202", "title": "在我的人类反馈中有什么？学习可解释的偏好数据描述", "title_en": "What's In My Human Feedback? Learning Interpretable Descriptions of Preference Data", "authors": "Rajiv Movva,Smitha Milli,Sewon Min,Emma Pierson", "background": "人类反馈可以以不可预测和不理想的方式改变语言模型，因为从业者对反馈数据的编码缺乏明确理解。虽然前人研究了某些属性的偏好（如长度或奉承），但在没有预先假设的情况下自动提取相关特性的方法仍然具有挑战性。", "innovation": "本文引入了WIMHF（What's In My Human Feedback？），这是一种使用稀疏自编码器解释反馈数据的方法。WIMHF能够描述（1）数据集能够测量的偏好和（2）标注者实际表达的偏好。通过7个数据集，WIMHF发现了能够解释黑盒模型大部分偏好预测信号的少数几个可解释特征。这些特征揭示了人类偏好的广泛多样性，以及数据集级别的上下文角色：例如，Reddit的用户更喜欢非正式性和笑话，而HH-RLHF和PRISM的标注者则不喜欢这些。WIMHF还发现了潜在的安全隐患，例如，LMArena用户倾向于反对拒绝，并倾向于有毒内容。通过学习到的特征，可以有效进行数据分类和个性化：重新标记Arena中的有害示例，可以在提高安全性能的同时不损害一般性能。另外，它们还允许基于主观特征对标注者进行细粒度个性化。", "conclusion": "WIMHF提供了一种以人类为中心的分析方法，以帮助从业者更深入地理解和利用偏好数据。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26193", "html_url": "https://arxiv.org/abs/2510.26193", "title": "RCScore: 定量化大型语言模型的响应一致性", "title_en": "RCScore: Quantifying Response Consistency in Large Language Models", "authors": "Dongjun Jang,Youngchae Ahn,Hyopil Shin", "background": "当前对大规模语言模型（LLM）的评估往往依赖单一的指令模板，忽视了模型对指令风格的敏感性，这是实际部署中的关键因素。本文旨在通过一个多维度框架RCScore来量化指令形式如何影响模型响应，揭示了传统评估指标未能检测到的性能差异。实验结果显示，指令风格可以将准确性变化多达16.7%。此外，实验还发现确定性解码产生更稳定的样式输出，并且模型规模与跨风格一致性呈正相关关系。RCScore提供了一种有原则的方法来评估指令的稳健性，有助于理解大规模语言模型在其实际部署中的表现和可靠性。", "innovation": "RCScore是一个多维度框架，通过系统地将基准问题转化为多种指令风格，揭示了传统评估指标未能检测到的性能差异。此外，引入了Cross-Response Similarity（CRS）方法来度量样式自一致性，并建立其与任务准确性之间的强相关性，提出了一致性作为模型可靠性的有效代理。确定性解码产生更稳定的样式输出，而模型规模与跨风格一致性呈正相关关系。", "conclusion": "RCScore提供了一种有原则的方法来评估指令的稳健性，有助于理解大规模语言模型在其实际部署中的表现和可靠性。此外，确定性解码产生更稳定的样式输出，而模型规模与跨风格一致性呈正相关关系。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26205", "html_url": "https://arxiv.org/abs/2510.26205", "title": "朝着全局检索增强生成：一种语料库级推理的基准", "title_en": "Towards Global Retrieval Augmented Generation: A Benchmark for Corpus-Level Reasoning", "authors": "Qi Luo,Xiaonan Li,Tingshuo Fan,Xinchi Chen,Xipeng Qiu", "background": "当前对检索增强生成（RAG）的评估基准主要用于衡量局部RAG能力，即在小文档集合中检索相关片段以回答仅需局部理解的问题。然而，许多实际应用需要不同的能力——全局RAG，涉及跨整个文档集合的聚合与分析信息以提取总体见解。已有方法在处理全局任务时表现不佳，研究者认为需要新的方法来解决这一问题。", "innovation": "本文提出了GlobalQA，这是第一个专门用于评估全局RAG能力的基准，涵盖四种核心任务类型：计数、极值查询、排序和top-k提取。研究者通过系统性地评估不同的模型和基线，发现了现有RAG方法在全局任务上的不足，并提出了GlobalRAG，一种多工具的协作框架，通过片段级检索保持结构一致性，利用LLM驱动的智能过滤器来消除噪声文档，并整合聚合模块进行精确的符号计算。", "conclusion": "在Qwen2.5-14B模型上的实验结果表明，GlobalRAG相较于最强基线提高了5.12个F1分数，证明了该方法的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26254", "html_url": "https://arxiv.org/abs/2510.26254", "title": "语言模型是无认借的：10种语言中借词识别的跨语言评估", "title_en": "Language Models Are Borrowing-Blind: A Multilingual Evaluation of Loanword Identification across 10 Languages", "authors": "Mérilin Sousa Silva,Sina Ahmadi", "background": "语言历史上，词语会相互借用并逐渐融入受方语言的词汇库中。双语社区中，主导语言持续地将词汇强制加到弱势语言中，使得讲者能够区分借词和本土词汇。尽管有清晰的指令和上下文信息，现有的预训练语言模型（包括大型语言模型）在区分借词和本土词汇方面表现不佳，这与现代自然语言处理（NLP）系统在借词方面的倾向性存在偏差相关联。这项工作对开发弱势语言的NLP工具以及在主导语言词汇压力下支持语言保护具有重要意义。", "innovation": "本研究评估了多种语言模型在10种不同语言中的借词识别能力，发现即使是带有明确指示和上下文信息的模型，在借词识别上仍然表现出较差的表现，证实了现代NLP系统的借词偏好对模型的影响。这项研究为开发适合弱势语言的NLP工具和语言保护策略提供了参考。", "conclusion": "研究结果表明，尽管有指示和语境信息，现代预训练语言模型在借词与本土词汇的区别上表现不佳，这一发现支持了NLP系统存在借词偏好。这为开发支持弱势语言的NLP工具和保护语言免受主导语言词汇侵蚀提供了重要意义的见解。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26271", "html_url": "https://arxiv.org/abs/2510.26271", "title": "Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual", "title_en": "Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual", "authors": "Sukrit Sriratanawilai,Jhayahgrit Thongwat,Romrawin Chumpu,Patomporn Payoungkhamdee,Sarana Nutanong,Peerat Limkonchotiwat", "background": "视觉语言模型（VLMs）在各种语言上的性能存在不均衡，特别是在模型尺寸减小后这一问题更为突出。知识蒸馏（KD）能够将大型模型的知识转移到小型模型中，展现出积极的效果，但将其应用于多语言环境仍是未被充分探索的领域。", "innovation": "本研究进行了多语言视觉语言模型知识蒸馏行为的控制实证研究，探讨了五种不同的蒸馏方法对跨语言表征一致性及模型压缩后下游性能稳定性的具体影响。研究选用了CLIP和SigLIP2作为模型基础，并在领域内检索和跨领域视觉问答任务上进行了评估。", "conclusion": "研究结果表明，某些配置能够在减半模型规模的情况下保持甚至提升多语言检索的鲁棒性，但也有其他配置不能维持跨任务的稳定性，揭示出单一聚合准确率无法揭示的设计敏感性权衡。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26253", "html_url": "https://arxiv.org/abs/2510.26253", "title": "Pragmatic Theories Enhance Understanding of Implied Meanings in LLMs", "title_en": "Pragmatic Theories Enhance Understanding of Implied Meanings in LLMs", "authors": "Takuma Sato,Seiya Kawano,Koichiro Yoshino", "background": "在人类交流和语言使用中，准确地解读隐含意义的能力至关重要。语言模型也被期望具备这种能力。已有研究表明，向语言模型提供形式化的理论提示可以在特定任务中有效提升其理解隐含意义的能力。", "innovation": "该研究展示了通过向语言模型提供关于语用理论（如格赖斯语用学和关联理论）的概述作为提示，可以在任务中有效提升其理解隐含意义的能力。具体方法是通过引导语言模型通过逐步推理过程来推断最终的解释。实验结果显示，与传统的零样本推理比较，该方法让语言模型在语用推理任务上的得分提高了9.6%。此外，即使不详细解释语用理论，只是在提示中提及语用理论名称，也能在大模型中带来一定的性能提升。", "conclusion": "实验结果表明，提供关于语用理论的提示可以有效提升语言模型在隐含意义理解上的表现。即使仅提及理论名称，也能在较大规模的语言模型中观察到性能的提升。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26277", "html_url": "https://arxiv.org/abs/2510.26277", "title": "LLMs在何时正确给出信号？内部一致性的证据", "title_en": "Do LLMs Signal When They're Right? Evidence from Neuron Agreement", "authors": "Kang Chen,Yaoning Wang,Kai Xiong,Zhuoka Feng,Wenhe Sun,Haotian Chen,Yixin Cao", "background": "大语言模型（LLMs）通常通过样本-评估-集成解码器增强推理过程，从而在无需真实标签的情况下获得标签自由的提升。目前占主导地位的策略仅使用外部信号（如标记概率、熵或自我评估）来评分候选答案，但这些信号在训练后可能未被良好校准。本文研究了内部行为，发现外部信号实质上是更丰富内部动态的低维度投影，且正确答案激活的神经元数量较少，正确答案之间的激活具有更强的跨样本一致性，而错误答案则表现出更多分歧。", "innovation": "本文提出了基于神经元活动稀疏性和跨样本神经元一致性的无监督选择方法——Neuron Agreement Decoding (NAD)，在仅使用内部信号且无需对比文本输出的情况下选择候选答案。NAD能够在前32个生成的标记内预测正确性，并支持激进的早期停止。在包含验证答案的数学和科学基准测试中，NAD匹配多数投票；在不可应用多数投票的开放源码基准测试中，NAD稳定地优于Avg@64。通过早期修剪不具前景的路径，NAD减少了标记使用量达99%，同时保持生成质量。", "conclusion": "表明内部信号可以提供可靠的、可扩展且高效的指导，用于标签自由的集成解码。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26285", "html_url": "https://arxiv.org/abs/2510.26285", "title": "探索语言模型操纵数字的机制", "title_en": "Unravelling the Mechanisms of Manipulating Numbers in Language Models", "authors": "Michal Štefánik,Timothee Mickus,Marek Kadlčík,Bertram Højer,Michal Spiegel,Raúl Vázquez,Aman Sinha,Josef Kuchař,Philipp Mondorf", "background": "近期的研究表明，不同的大规模语言模型（LLMs）对数字的输入嵌入表示趋于一致且准确。然而，这些发现与LLMs在处理数字信息时经常产生错误输出的现象相矛盾。因此，本研究旨在解释这种矛盾，探讨语言模型如何处理数字，并定量这些机制的准确性下限。这项研究发现，尽管存在错误，不同的语言模型仍然学习到系统性的、高度准确且在隐藏层和各种输入场景中最普遍的数字表示方法。这使得我们能够为每种LLM创建通用探针，并追溯信息（包括输出错误的原因）到特定层级。研究结果为理解预训练LLMs如何处理数字提供了基础，并指出了更准确探针技术在未来改进LLMs架构的潜力。", "innovation": "本研究通过探索语言模型如何处理数字以及定量这些机制的准确性下限，解释了LLMs在处理数字信息时产生错误输出的现象。研究发现，尽管存在错误，不同的语言模型仍然学习到系统性的、高度准确且在隐藏层和各种输入场景中最普遍的数字表示方法。研究还提出了一种方法来创建通用探针，并追溯信息（包括输出错误的原因）到特定层级，为准确探针技术的应用铺平了道路，这可能在未来改进LLMs的架构。", "conclusion": "研究结果揭示了预训练LLMs如何处理数字的方法，并为准确探针技术的应用提供了可能。这为进一步精炼LLMs的架构奠定了基础，可以提升模型在处理数字信息方面的准确性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26336", "html_url": "https://arxiv.org/abs/2510.26336", "title": "通过自动化课程学习向LLMs灌输知识：从初学者变为大师", "title_en": "From Amateur to Master: Infusing Knowledge into LLMs via Automated Curriculum Learning", "authors": "Nishit Neema,Srinjoy Mukherjee,Sapan Shah,Gokul Ramakrishnan,Ganesh Venkatesh", "background": "大型语言模型（LLMs）在泛任务上表现优异，但在经济学和心理学等需要深入原理理解的专业领域表现不佳。ACER（Automated Curriculum-Enhanced Regimen）通过对通用模型进行系统性知识培训，将其转化为专业领域的专家，同时不牺牲其广泛的能力。", "innovation": "ACER通过自动化生成课程大纲和根据布隆分类法生成问题解答对像，创建了一个综合的教材内容，并采用交错式 Curriculum 调度进行持续预训练，确保知识的系统覆盖和逐渐深入。实验结果表明，ACER在经济学等挑战性领域的表现显著提升，总体目标领域的一致改进幅度达到3个点，并提高了非目标领域的性能。", "conclusion": "ACER具有可扩展性和有效性，能够在LLMs中弥补关键领域的知识差距，同时在知识密集型基准测试如ARC和GPQA上提升性能，而保持在通用推理任务上的稳定表现。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26322", "html_url": "https://arxiv.org/abs/2510.26322", "title": "SCRIBE: 结构化链式推理用于工具调用的交互行为解释", "title_en": "SCRIBE: Structured Chain Reasoning for Interactive Behaviour Explanations using Tool Calling", "authors": "Fares Fawzi,Vinitra Swamy,Dominik Glandorf,Tanya Nazaretsky,Tanja Käser", "background": "语言模型可以在教育环境中提供交互式的个性化学生反馈。然而，现实生活中的部署面临三个主要挑战：隐私问题、有限的计算资源以及需要教育上有效的回应。这些限制要求使用小型开源模型，能够在本地运行，并可靠地将其输出基于正确的信息。此前的研究尚未解决如何在具备这些限制的情况下生成合适的反馈报告。", "innovation": "作者提出了SCRIBE框架，这是一种多跳工具增强推理框架，用于生成对学生关于反馈报告的提问的教育上有效的回应。SCRIBE结合了特定领域工具和自我反思的推理管道，支持迭代推理、工具使用和错误恢复。通过两阶段LoRA微调，在合成的GPT-4o生成的数据上，将其能力提炼到了3B和8B模型。通过人类对齐的GPT- Judge评估和108名学生的用户研究发现，8B-SCRIBE模型在关键维度上（相关性和行动性）达到了或优于更大模型的质量，且学生认为其与GPT-4o和Llama-3.3 70B相当。", "conclusion": "这些发现表明，SCRIBE对于低资源和隐私敏感的教育应用是可行的，表明结构化链式推理可以在教育反馈报告中实现有效工具应用，有助于提升教育技术的实用性和隐私保护水平。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26298", "html_url": "https://arxiv.org/abs/2510.26298", "title": "ChatGPT Atlas能否征服网页？探索ChatGPT Atlas智能体在网页游戏中的边界", "title_en": "Can Agent Conquer Web? Exploring the Frontiers of ChatGPT Atlas Agent in Web Games", "authors": "Jingran Zhang,Ning Li,Justin Cui", "background": "ChatGPT Atlas具有网页交互的新能力，使其能够分析网页、处理用户意图并在浏览器中直接执行鼠标和键盘输入。尽管其信息检索任务能力已被验证，但在动态、互动环境中的表现尚未深入研究。研究者使用基于浏览器的游戏作为测试场景，评估Atlas的网页交互能力。", "innovation": "该研究通过使用浏览器中的游戏对Atlas的网页交互能力进行早期评估，以游戏内的表现分数作为量化指标，评估了不同任务类型的表现。这为理解和改进智能体在动态互动环境中的性能提供了新的视角。", "conclusion": "研究结果表明，Atlas在逻辑推理任务如数独方面表现优异，能够显著超越人类基线，但在需要精确时间控制和运动控制的实时游戏中表现不佳，常常在初始障碍处失败。这些发现表明，尽管Atlas展示了强大的分析处理能力，但在需要实时交互的动态网页环境中仍存在显著限制。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26345", "html_url": "https://arxiv.org/abs/2510.26345", "title": "MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data", "title_en": "MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data", "authors": "Mykhailo Poliakov,Nadiya Shvai", "background": "健康相关的错误信息非常普遍且具有潜在危害性。这些错误信息常常扭曲或曲解科学发现，使得识别变得非常困难。本文通过使用MISSCI数据集和框架，研究合成数据生成技术和轻量级微调技术对大型语言模型(Large Language Models, LLMs)识别谬误论点能力的影响。", "innovation": "本文提出了MisSynth管道，该管道使用检索增强生成(Retrieval-Augmented Generation, RAG)技术生成合成谬误样本，然后将这些样本用于微调LLM模型。微调后的模型在准确率上显著优于未微调的基本模型，例如，对于LLaMA 3.1 8B微调模型，其在MISSCI测试集上的F1分数绝对提高了35%以上。研究结果表明，引入合成谬误数据可以显著增强零样本LLM分类性能，即使计算资源有限。", "conclusion": "本文的研究结果表明，通过引入合成谬误数据可以显著增强零样本LLMs在现实世界的科学错误信息任务上的分类性能，即使是在有限的计算资源下。文章中的代码和合成数据集已公开展示。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26354", "html_url": "https://arxiv.org/abs/2510.26354", "title": "论上下文在科学研究写作中语篇关系分类中的作用", "title_en": "On the Role of Context for Discourse Relation Classification in Scientific Writing", "authors": "Stephen Wan,Wei Liu,Michael Strube", "background": "随着生成型人工智能（AI）方法在科学工作流中的使用增加，研究人员开始关注如何利用话语层面的信息来支持AI生成的科学断言。识别科学研究写作中的语篇结构是一种重要的初步步骤。尽管已经有研究探讨了这一任务，但对于科学出版物这种未充分研究的类型，仍然缺乏这方面的深度分析和专门方法的研究。", "innovation": "本文引入了对预训练语言模型（PLM）和大型语言模型（LLM）在科学研究写作中的研究，尤其是集中于语篇关系分类（DRC）问题。研究发现，上下文在识别语篇关系上具有积极作用，尤其是在基于话语结构定义的上下文中。此外，研究还分析了哪些科学研究中的语篇关系类型可以从上下文中受益最多。这项研究所采用的方法和发现对理解科学写作中的信息结构具有实际意义。", "conclusion": "研究表明，上下文有助于语篇关系分类任务，对科学出版物类型中的语篇结构特别重要。未来工作可以进一步深入这一领域，探索更多上下文特征和不同类型语篇关系之间的关系。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26446", "html_url": "https://arxiv.org/abs/2510.26446", "title": "1+1>2: A Synergistic Sparse and Low-Rank Compression Method for Large Language Models", "title_en": "1+1>2: A Synergistic Sparse and Low-Rank Compression Method for Large Language Models", "authors": "Zeliang Zong,Kai Zhang,Zheyang Li,Wenming Tan,Ye Ren,Yiyan Zhai,Jilin Hu", "background": "大型语言模型（LLMs）在语言理解和生成方面表现出色；然而，它们的广泛应用受到带宽和计算需求的限制。虽然剪枝和低秩近似在单独使用时已经展现出了潜力，但两者在LLMs上的协同效应仍被忽视。", "innovation": "介绍了Synergistic Sparse and Low-Rank Compression（SSLC）方法，该方法结合了低秩近似和稀疏优化技术的优势。通过迭代优化算法将低秩近似和稀疏优化统一为一个问题，并且在不增加额外训练步骤的情况下，SSLC方法在LLaMA和Qwen2.5（7B-70B）模型上超越了单一方法，达到最先进的性能。特别地，SSLC能在保持性能不下降的情况下将Qwen2.5压缩50%，并实现至少1.63倍的速度提升，为高效的LLM部署提供了一个实际的解决方案。", "conclusion": "实验表明，SSLC方法在LLaMA和Qwen2.5模型上达到了最先进的结果，且不需额外训练步骤，能够实现显著的压缩和加速。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26422", "html_url": "https://arxiv.org/abs/2510.26422", "title": "OmniEduBench：用于评估教育领域大型语言模型的全面汉语基准", "title_en": "OmniEduBench: A Comprehensive Chinese Benchmark for Evaluating Large Language Models in Education", "authors": "Min Zhang,Hao Chen,Hao Chen,Wenqi Zhang,Didi Zhu,Xin Lin,Bo Jiang,Aimin Zhou,Fei Wu,Kun Kuang", "background": "随着大型语言模型（LLMs）的快速发展，这些模型及其基于它们的工作已经广泛应用于教育领域。然而，现有的LLMs及其基准主要集中在知识维度的评估上，忽略了培养能力的评估，这是实际教育场景中必不可少的部分。此外，当前的基准往往局限于单一学科或问题类型，缺乏足够的多样性。此问题在中国尤其突出。为了解决这一差距，作者引入了OmniEduBench，这是一个全面的汉语教育基准，包含24.602K高质量的问题-答案对。数据分为两个核心维度：知识维度和培养维度，分别包含18.121K和6.481K数据项，每个维度进一步细分为6个子类别，总共涵盖了61个不同的科目（知识41个，培养20个）。此外，数据集还包括了11种常见的考试题型，为全面评估LLMs的功能提供了坚实的基础。", "innovation": "OmniEduBench是一个全面的汉语教育基准，全面扩展了现有基准的评估维度和多样性。它不仅考虑了知识维度，还特别关注培养维度，并且在多个不同的教育科目和问题类型上进行了详细的分类。为评估多个主流的开源和闭源LLM，进行了广泛的实验，揭示了这些模型在教育领域应用中的显著性能差距。", "conclusion": "实验结果表明，尽管某些LLM在知识维度上的性能较好，但在培养维度上仍然落后于人类的表现，突显出在教育领域应用LLM的巨大改进空间及挑战。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26352", "html_url": "https://arxiv.org/abs/2510.26352", "title": "对话的几何学：通过绘制语言模型揭示多代理合作中的协同团队", "title_en": "The Geometry of Dialogue: Graphing Language Models to Reveal Synergistic Teams for Multi-Agent Collaboration", "authors": "Kotaro Furuya,Yuichi Kitagawa", "background": "基于大型语言模型（LLMs）的多代理方法被认为是超越单一模型能力的一种有前景的策略，但其成功高度依赖于协同团队的组成。由于大多数模型的内部特性不透明，因此形成最佳团队是一个重要的挑战。本文介绍了一种无需任何先验知识（包括模型内部结构、训练数据或任务性能），而是基于模型互动中心的自动团队组成框架。该方法通过构建“语言模型图”来映射模型之间的关系，并利用社区检测识别协同模型集群。该研究通过多样化LLMs的实验表明，所提出的方法发现了功能上一致的小组，这些小组反映了其潜在的专业化。通过对特定话题的预热对话来识别协同团队，这些团队在下游基准测试中表现出色，并且与根据已知模型专业化手动组合的团队的准确度相当。", "innovation": "提出了一种无需任何先验知识的自动团队组成框架，通过构建“语言模型图”来映射模型之间的关系，并利用社区检测识别协同模型集群。这种基于模型互动中心的方法揭示了功能上一致的小组，这些小组反映了模型的潜在专业化，并且在下游基准测试中表现优于随机基线，能够达到手动组合团队的准确度。", "conclusion": "研究发现为自动化设计协作多代理LLM团队提供了新的基础。该方法通过预热对话和基于语言模型图的社区检测揭示了模型的潜在协同性，并在多种LLMs中得到了验证，表明这种方法在多代理合作中具有潜力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26484", "html_url": "https://arxiv.org/abs/2510.26484", "title": "大型语言模型的贝叶斯网络融合用于情感分析", "title_en": "Bayesian Network Fusion of Large Language Models for Sentiment Analysis", "authors": "Rasoul Amirzadeh,Dhananjay Thiruvady,Fatemeh Shiri", "background": "大型语言模型（LLMs）在专业领域的应用日益广泛，但这些模型通常缺乏透明性和可解释性，修改成本高昂，需要大量的提示工程，跨领域的结果不够一致，并且由于其高计算需求对环境造成重大负面影响。这些问题构成了研究的背景和挑战。", "innovation": "提出了贝叶斯网络LLM融合（BNLF）框架，该框架通过贝叶斯网络中的概率机制整合来自三种LLM（FinBERT、RoBERTa和BERTweet）的预测以进行情感分析。BNLF通过晚融合将来自多个LLM的情感预测建模为贝叶斯网络中的概率节点，展示了在三个具有不同语言和上下文特征的人工标注金融语料库上的优越性，准确率提高了约六个百分点，并证明了其在数据集变异情况下的稳健性和概率融合在解释性情感分类中的有效性。", "conclusion": "BNLF框架在情感分析中展示了显著的准确性提升，并且能够有效适应数据集的多样性，同时提供解释性的情感分类。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26521", "html_url": "https://arxiv.org/abs/2510.26521", "title": "使用视觉表示的希伯来文字音符号恢复", "title_en": "Hebrew Diacritics Restoration using Visual Representation", "authors": "Yair Elboher,Yuval Pinter", "background": "希伯来文的无音节文本存在很大的发音和意义歧义。尽管近年来机器学习方法显著提升了这项任务的性能，但希伯来文的音节化任务依然没有一个完全自适应的方法。", "innovation": "该研究提出了DIVRIT，这是一种新颖的希伯来文音节化系统，将任务视为零样本分类问题。其创新在于使用了希伯来视觉语言模型，能够以图像形式处理无音节文本，直接将音节信息嵌入输入的向量表示中。", "conclusion": "系统评估表明，该方法在不需要复杂、显式的语言分析的情况下，能够有效地进行音节化。在‘先验’设置中，系统达到了较高的准确性。通过架构优化和训练方法改进，系统表现出更强的泛化能力，显示出视觉表示在准确和自动化的希伯来文音节化中的巨大潜力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26498", "html_url": "https://arxiv.org/abs/2510.26498", "title": "一种自动评估临床AI分诊工具性能的多代理大型语言模型框架", "title_en": "A Multi-agent Large Language Model Framework to Automatically Assess Performance of a Clinical AI Triage Tool", "authors": "Adam E. Flanders,Yifan Peng,Luciano Prevedello,Robyn Ball,Errol Colak,Prahlad Menon,George Shih,Hui-Ming Lin,Paras Lakhani", "background": "本文的研究背景是探讨是否可以通过多个大型语言模型（LLM）的集体评估来提高像素级AI分诊工具评估的可靠性，相较于单一LLM的评估结果。", "innovation": "本文的创新在于提出了一个多代理大型语言模型框架，用于自动评估临床AI分诊工具的性能。研究使用了8种开源LLM模型和一个符合HIPAA合规要求的内部版本的GPT-4o，对29,766份非对比CT头部检查报告进行了分析，并通过对比不同模型的表现，验证了多代理模型的优越性。", "conclusion": "研究结果表明，使用中到大型的开源LLM组成的一个集体，比单一LLM更能提供一个一致和可靠的临床AI分诊工具评估方法。具体来说，基于MCC的最优组合是全9种组合（0.571）、前3种组合（0.558）和共识（0.556），未观察到Top-3、全9种和共识之间的显著差异（p > 0.05）。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26512", "html_url": "https://arxiv.org/abs/2510.26512", "title": "在CORE-KG中评估结构化提示和核心ference解决对知识图谱的影响", "title_en": "Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs", "authors": "Dipak Meher,Carlotta Domeniconi", "background": "人口走私网络越来越具有适应性且难以分析。法律案例文件提供了关键见解，但由于文件通常是未结构化的、词汇密集的，并且充满了模棱两可或变动的引用，这给自动知识图谱（KG）构建带来了巨大挑战。尽管基于近期LLM的方法提高了表现，但在缺乏指导提取和消解引用的情况下，仍然会产生嘈杂且碎片化的图谱，导致重复节点。最新提出的CORE-KG框架通过集成类型感知的消解标注器和领域指导的结构化提示，显著减少了节点重复和法律噪声。", "innovation": "该论文提出了一种系统性的消融研究，评估了CORE-KG的关键组件——结构化提示和核心ference解决——对知识图谱建设的独立贡献。研究结果表明：去除核心ference解决会增加28.32%的节点重复和4.32%的噪声节点；而去除结构化提示则会增加4.34%的节点重复和73.33%的噪声节点。这些发现为设计更健壮的基于LLM的知识抽取流水线提供了实证依据。", "conclusion": "研究结果强调了在基于LLM的知识图谱构建中，核心ference解决与结构化提示的重要性。为提取复杂法律文本中的结构表示，需要确保这两个关键组件的稳健性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26577", "html_url": "https://arxiv.org/abs/2510.26577", "title": "面向推理成本的动态树构建方法在大型语言模型高效推理中的应用", "title_en": "Inference-Cost-Aware Dynamic Tree Construction for Efficient Inference in Large Language Models", "authors": "Yinrong Hong,Zhiquan Tan,Kai Hu", "background": "大型语言模型（LLMs）由于其自回归设计和庞大模型规模面临显著的推理延迟问题。为解决这一问题， speculative decoding（推测性解码）作为一种解决方案出现，能够同时生成和验证多个令牌。虽然EAGLE-2和EAGLE-3等近期方法通过动态树结构提高了推测性解码效率，但它们往往忽略了GPU设备配置和批量大小等因素的影响。", "innovation": "提出了一种新的动态树解码方法CAST，该方法考虑了推理成本，包括GPU配置和批量大小等因素，以动态调整树结构。通过在六个不同任务和六种不同的LLMs上的全面实验，证明了该方法能够将传统解码方法的速度提高到5.2倍，并且在大多数情况下其性能优于现有的最先进的技术，提升了5%到20%。", "conclusion": "该研究通过CAST方法显著提高了大型语言模型的推理效率，验证了该方法的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26575", "html_url": "https://arxiv.org/abs/2510.26575", "title": "InfoFlow: 通过奖励密度优化强化搜索代理", "title_en": "InfoFlow: Reinforcing Search Agent Via Reward Density Optimization", "authors": "Kun Luo,Hongjin Qian,Zheng Liu,Ziyi Xia,Shitao Xiao,Siqi Bao,Jun Zhao,Kang Liu", "background": "Reinforcement Learning with Verifiable Rewards (RLVR) 是增强自主深度搜索的一个有希望的方法。然而，它的应用常常受到深度搜索场景中低 Reward Density 的阻碍，在这些场景中，代理需要花费大量的探索成本来换取不频繁且经常为零的最终奖励。该文将这一挑战正式定义为奖励密度优化问题，旨在提高每单位探索成本所获得的回报。", "innovation": "提出了 InfoFlow，这是一种系统性框架，通过三个方面解决了这个问题：1) 子问题分解，即拆分解长任务以分配过程奖励，从而提供更密集的学习信号；2) 失败引导提示，即向停滞的轨迹中注入纠正性指导，以增加成功结果的概率；3) 双代理精炼，采用双代理架构减轻深度探索的认知负担。通过使精炼代理合成搜索历史，有效地压缩了研究员的轨迹，从而降低了探索成本并增加了总体的奖励密度。", "conclusion": "InfoFlow 在多个自主搜索基准测试中表现出色，大幅优于强大基线，使得轻量级的LLM能够达到与先进专有LLM相当的性能水平。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26615", "html_url": "https://arxiv.org/abs/2510.26615", "title": "SlideAgent：多页视觉文档理解的分层智能体框架", "title_en": "SlideAgent: Hierarchical Agentic Framework for Multi-Page Visual Document Understanding", "authors": "Yiqiao Jin,Rachneet Kaur,Zhen Zeng,Sumitra Ganesh,Srijan Kumar", "background": "多页视觉文档（如说明书、宣传册、演示文稿和海报）通过布局、颜色、图标和跨页引用传递关键信息。尽管大规模语言模型（LLMs）为文档理解和处理提供了机会，但现有系统在理解和处理复杂的多页视觉文档时面临挑战，尤其是在对元素和页面进行精细推理方面。", "innovation": "SlideAgent 是一种多功能智能体框架，专门用于理解和处理多模态、多页、多布局文档，尤其是演示文稿。SlideAgent 使用专门的智能体并将其推理分解为三大层面：全局、页面和元素，构建了一个结构化且对查询无依赖的表示，同时捕捉总体主题和详细视觉或文本提示。在推理过程中，SlideAgent 选择性地激活专门的智能体进行多层推理，并将它们的输出整合成连贯且上下文相关的问题答案。", "conclusion": "广泛实验表明，SlideAgent 在性能上显著优于专有模型 (+7.9) 和开源模型 (+9.8)。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26697", "html_url": "https://arxiv.org/abs/2510.26697", "title": "从手动解码到真正意义上的端到端语言模型", "title_en": "The End of Manual Decoding: Towards Truly End-to-End Language Models", "authors": "Zhichao Wang,Dongyang Ma,Xinting Huang,Deng Cai,Tian Lan,Jiahao Xu,Haitao Mi,Xiaoying Tang,Yan Wang", "background": "现有的大规模语言模型（LLMs）通常被称作端到端模型，但实际上它们依赖于一个非可微解码过程，需要手动调整温度（temperature）和top-p等超参数才能进行优化。", "innovation": "本文提出了AutoDeco，一种新架构，能够实现真正意义上的端到端生成。通过在标准Transformer模型中添加轻量级头模块，在每个步骤动态预测上下文敏感的温度和top-p值，将解码过程转化为可参数化的、逐个token的过程。实验表明，相比于默认解码策略，AutoDeco显著表现更优，并且能达到接近‘破解测试集’的性能上限，即任何静态方法可以达到的最优值。", "conclusion": "该研究揭示了一种基于指令的解码控制能力，模型能够理解自然语言命令（如“低随机性生成”）并在逐个token的基础上调整预测的温度和top-p值，开辟了对于可引导和互动的语言模型新范式。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26622", "html_url": "https://arxiv.org/abs/2510.26622", "title": "编码器-解码器还是仅解码器？重新审视编码器-解码器大规模语言模型", "title_en": "Encoder-Decoder or Decoder-Only? Revisiting Encoder-Decoder Large Language Model", "authors": "Biao Zhang,Yong Cheng,Siamak Shakeri,Xinyi Wang,Min Ma,Orhan Firat", "background": "近年来，大型语言模型（LLM）的研究从编码器-解码器建模架构转向了以解码器为主的主导建模方式。这种快速转型缺乏对从扩展性角度来看的严格比较分析，引发了对编码器-解码器模型潜力可能被忽视的担忧。本文旨在通过增强RedLLM，在解码器-仅解码器模型的基础上对其进行重新审视，并通过不同模型规模的全面比较来验证其性能。实验结果表明，尽管解码器-仅解码器模型在预训练时更具计算效率，RedLLM在扩展性和上下文长度外推能力方面表现出相当甚至更好的性能。", "innovation": "本文通过引入recent recipes from decoder-only LLM（DecLLM），增强了encoder-decoder LLM（RedLLM）。研究的重点是对不同规模模型进行了全面比较，从约150M到约8B不等，使用RedPajama V1（1.6T令牌）进行预训练和FLAN进行指令调整。实验结果显示RedLLM具有优越的扩展特性，并实现了与DecLLM相当甚至是更好的下游任务性能，同时拥有更好的推理效率。这项工作的目的在于促进对RedLLM潜力的重新评估，从而推动开发更强大且高效的LLM的发展。", "conclusion": "我们的研究结果表明，RedLLM不仅在预训练效率上表现优秀，而且在扩展性和推理效率方面也显示出与DecLLM相媲美的性能，甚至在某些方面优于DecLLM。我们希望这项工作能够激发更多对RedLLM潜力的重新评估，进一步推动开发高效的大型语言模型。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26683", "html_url": "https://arxiv.org/abs/2510.26683", "title": "Evontree: 由本体规则指导的大语言模型自我进化框架", "title_en": "Evontree: Ontology Rule-Guided Self-Evolution of Large Language Models", "authors": "Mingchen Tu,Zhiqiang Liu,Juan Li,Liangyurui Liu,Junjie Wang,Lei Liang,Wen Zhang", "background": "大语言模型（LLMs）通过大规模预训练和精心策划的微调数据，在多个领域展示了非凡的能力。然而，在对数据敏感的领域，如医疗保健，由于缺乏高质量、特定领域的训练语料，难以使LLMs适应专业应用。同时，领域专家通过本体规则提炼出领域的知识智慧，这些规则将概念之间的关系形式化，并确保知识管理库的一致性。鉴于此，作者将LLMs视为人类知识的隐性储存库，并提出了一种名为Evontree的创新框架，通过少量高质量的本体规则系统地提取、验证和增强LLMs中的领域知识，而无需依赖大量外部数据集。", "innovation": "Evontree框架利用少量高质量的本体规则，系统地从原始模型中提取知识，使用两种核心的本体规则检测不一致性，并通过自我提炼的微调增强精炼后的知识。这种方法在医疗问答基准上与Llama3-8B-Instruct和Med42-v2进行的实验表明，相比未修改的模型和领先的人工监督基线，该方法在准确率上提高了最高达3.7%。这证实了该方法在低资源领域适应大语言模型方面的有效性、高效性和鲁棒性。", "conclusion": "实验结果证明Evontree框架的有效性、高效性和鲁棒性，使其成为大语言模型低资源领域适应的有力工具。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26768", "html_url": "https://arxiv.org/abs/2510.26768", "title": "AMO-Bench: Large Language Models Still Struggle in High School Math Competitions", "title_en": "AMO-Bench: Large Language Models Still Struggle in High School Math Competitions", "authors": "Shengnan An,Xunliang Cai,Xuezhi Cao,Xiaoyu Li,Yehao Lin,Junlin Liu,Xinxuan Lv,Dan Ma,Xuanlin Wang,Ziwen Wang,Shuang Zhou(Alphabetical order by last name)", "background": "现有的基准测试主要依赖于高中数学竞赛来评估大型语言模型（LLM）的数学推理能力。然而，许多现有的数学竞赛对于评估顶级LLM的有效性正在减弱，因为这些模型的性能已经达到饱和（例如，AIME24/25）。因此，需要一种新的基准测试来更严格地评估这些模型。", "innovation": "AMO-Bench是一个具有奥林匹克水平或更高难度的高级数学推理基准，包含50个人工制作的问题。它通过确保所有问题都被专家验证，达到国际数学奥林匹克（IMO）的标准，并且完全原创以防止数据记忆导致的性能泄漏。每个问题只需要提供最终答案，便于自动和稳健的评分。", "conclusion": "实验结果表明，即使是表现最好的模型在AMO-Bench上的准确率也仅达到52.4%，大多数模型得分低于40%。进一步分析显示，测试时间增加时性能有所提升，这表明目前LLM的数学推理有很大的提升空间。AMO-Bench的发布旨在促进进一步研究，以提升语言模型的推理能力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26790", "html_url": "https://arxiv.org/abs/2510.26790", "title": "Gistify！通过运行时执行实现代码库级别的理解", "title_en": "Gistify! Codebase-Level Understanding via Runtime Execution", "authors": "Hyunji Lee,Minseon Kim,Chinmay Singh,Matheus Pereira,Atharv Sonwane,Isadora White,Elias Stengel-Eskin,Mohit Bansal,Zhengyan Shi,Alessandro Sordoni,Marc-Alexandre Côté,Xingdi Yuan,Lucas Caccia", "background": "随着编码代理在整个大型代码库中被越来越多地部署，自动设计具有挑战性的、涉及代码库级别的评估变得至关重要。研究人员认为，通过让编码LLM（大型语言模型）创建一个单一的、简短的、可独立运行的文件来重现代码库中的特定功能，可以有效评估其能力。该文件应该能够复制同一命令在完整代码库中运行时的输出结果，只包含执行该命令所需的基本组件。", "innovation": "该研究提出了一个名为‘Gistify’的新任务，要求LLM生成一个简短的、自包含的文件来重现特定功能，它要求LLM具有结构化理解代码库、准确模拟执行流程以及生成可能较大的代码补丁的能力。研究结果表明，当前最先进的模型在解决Gistify任务时遇到困难，尤其是在执行轨迹较长的任务方面。", "conclusion": "Gistify任务能够有效评估编码LLM在代码库级别的理解和执行能力。当前最先进的模型在处理Gistify任务时表现出相当大的挑战，尤其是在长执行路径的情况下更为明显。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25797", "html_url": "https://arxiv.org/abs/2510.25797", "title": "通过时空分析和空间注意力网络增强水下目标检测", "title_en": "Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks", "authors": "Sai Likhith Karri,Ansh Saxena", "background": "本文研究了时空建模以及在水下物体检测中的空间注意力机制在深度学习模型中的效果。通过对YOLov5和其时间增强版本T-YOLov5的性能进行评估，并引入卷积块注意力模块（CBAM），探讨了这些技术在水下环境检测中的应用效果，特别是在动态环境中的检测准确性提升.", "innovation": "创新之处在于通过引入时空注意力机制，特别设想了T-YOLov5和T-YOLov5结合CBAM的模型。研究结果显示，与标准YOLov5相比，T-YOLov5显著提高了检测可靠性，而T-YOLov5结合CBAM在复杂环境和动态条件下有进一步的性能提升，同时在简单场景中略有精度损失.", "conclusion": "研究结果表明，时空模型在动态水下环境中显著提高了物体检测的准确性，特别是对突发移动、部分遮挡和渐进运动的处理。应用于T-YOLov5结合CBAM的模型在复杂多变场景下的检测性能表现更佳，但简单场景中精度有所下降。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26707", "html_url": "https://arxiv.org/abs/2510.26707", "title": "价值漂移：追踪大模型后训练阶段的价值对齐", "title_en": "Value Drifts: Tracing Value Alignment During LLM Post-Training", "authors": "Mehar Bhatia,Shravan Nayak,Gaurav Kamath,Marius Mosbach,Karolina Stańczak,Vered Shwartz,Siva Reddy", "background": "随着大语言模型（LLM）在社会中扮演的角色越来越重要，它们面临着不仅要运用其一般知识，还要与特定的人类价值观保持一致的问题。先前的研究主要评估完全训练好的模型的价值对齐情况，而忽略了模型在学习表达人类价值观过程中的训练动态。本文旨在探讨在模型后训练过程中价值对齐是如何形成的，以及在哪个阶段形成。通过分析不同大小的Llama-3和Qwen-3模型、不同监督微调（SFT）和偏好优化数据集及算法，研究发现，SFT阶段通常会确定模型的价值，而后续的偏好优化通常不会重新对齐这些价值观。此外，通过使用一种可以控制修改价值的合成偏好数据集，研究发现不同偏好优化算法即使使用的偏好数据相同，也会导致不同的价值对齐结果。", "innovation": "本文突破了以往仅评估模型完全训练后价值对齐的方法，首次较为系统地研究了模型在后训练过程中价值对齐的变化。研究使用了不同大小的模型以及多种监督微调和偏好优化数据集和算法，通过测量价值漂移的大小和时间，揭示了不同训练策略对价值对齐的影响，提出了提高模型与人类价值观对齐的新见解。", "conclusion": "研究结果提供了关于价值在后训练过程中是如何学习的具体见解，并有助于指导数据编目，以及选择模型和偏好优化算法以改善模型与人类价值观的对齐。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25798", "html_url": "https://arxiv.org/abs/2510.25798", "title": "MemEIC: 一步实现连续和组合知识编辑", "title_en": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing", "authors": "Jin Seong,Jiyun Park,Wencke Liermann,Hongseok Choi,Yoonji Nam,Hyun Kim,Soojong Lim,Namhoon Lee", "background": "由于信息的动态性，需要不断更新大型视觉-语言模型（LVLM）。尽管最近的知识编辑技术展现了前景，但它们往往专注于单独编辑视觉或语言模态，忽视了LVLM本身的多模态特性以及知识更新的连续性。这可能导致在考虑模态间的相互作用和持续更新知识需求时，编辑效果不理想。", "innovation": "我们提出了MemEIC，一种新的方法，用于LVLM中的持续和组合知识编辑（CCKE）。MemEIC能够顺序编辑视觉和文本知识。该方法采用结合外部和内部编辑器，配备了双存储器用于跨模态证据检索，以及双LoRA适配器以实现每种模态的平分参数更新。关键组件是一个类脑知识连接器，在组合推理时选择性激活，将不同模态的信息整合在一起。", "conclusion": "实验表明，MemEIC显著提高了复杂多模态问题的性能，并有效保留了先前的编辑，成为LVLM中CCKE的新基准。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25884", "html_url": "https://arxiv.org/abs/2510.25884", "title": "使用学习系统近似人类偏好", "title_en": "Approximating Human Preferences Using a Multi-Judge Learned System", "authors": "Eitán Sprejer,Fernando Avalos,Augusto Bernardi,Jose Pedro Brito de Azevedo Faustino,Jacob Haimes,Narmeen Fatimah Oozeer", "background": "LLM（大型语言模型）基础的裁判难以校准，并常常受到评分标准敏感性、偏见和不稳定性的困扰。克服这一挑战可以推动关键应用，如创建可靠的基于人类反馈强化学习（RLHF）的奖励模型，以及构建高效的路由系统，根据用户的查询选择最适合的模型。", "innovation": "本研究提出了一种框架，通过学习聚合多个评分标准条件下的裁判输出，来建模多样化的、基于人设的偏好。通过与简单基准的性能对比和对人类和LLM裁判偏好的案例研究，评估了该方法的稳健性。主要贡献包括一种基于人设的方法，用于大规模合成偏好标签，以及两种不同的聚合器实现：广义加性模型（GAM）和多层感知机（MLP）。", "conclusion": "本研究通过多裁判学习系统的方法，成功建模了多样化的偏好，并通过广泛的实验证明了该方法的有效性与鲁棒性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26692", "html_url": "https://arxiv.org/abs/2510.26692", "title": "Kimi Linear: 一种表达性强、高效的注意架构", "title_en": "Kimi Linear: An Expressive, Efficient Attention Architecture", "authors": "Kimi Team:Yu Zhang,Zongyu Lin,Xingcheng Yao,Jiaxi Hu,Fanqing Meng,Chengyin Liu,Xin Men,Songlin Yang,Zhiyuan Li,Wentao Li,Enzhe Lu,Weizhou Liu,Yanru Chen,Weixin Xu,Longhui Yu,Yejie Wang,Yu Fan,Longguang Zhong,Enming Yuan,Dehao Zhang,Yizhi Zhang,T.Y. Liu,Haiming Wang,Shengjun Fang,Weiran He,Shaowei Liu,Yiwei Li,Jianlin Su,Jiezhong Qiu,Bo Pang,Junjie Yan,Zhejun Jiang,Weixiao Huang,Bohong Yin,Jiacheng You,Chu Wei,Zhengtao Wang,Chao Hong,Yutian Chen,Guanduo Chen,Yucheng Wang,Huabin Zheng,Feng Wang,Yibo Liu,Mengnan Dong,Zheng Zhang,Siyuan Pan,Wenhao Wu,Yuhao Wu,Longyu Guan,Jiawen Tao,Guohong Fu,Xinran Xu,Yuzhi Wang,Guokun Lai,Yuxin Wu,Xinyu Zhou,Zhilin Yang,Yulun Du", "background": "该论文介绍了一种名为Kimi Linear的混合线性注意架构，首次在公平比较下优于全注意机制。Kimi Linear能够在短上下文、长上下文以及强化学习缩放阶段等各种场景中取得更好的性能。其核心是Kimi Delta Attention (KDA)，一个扩展了Gated DeltaNet的模块，通过更精细的门控机制增强了有限状态RNN内存的有效使用。此外，专为硬件效率设计的分块算法通过一种特定变体的对角线加稀疏矩阵实现了显著的计算节省，相比通用形式更为接近经典的delta规则。", "innovation": "Kimi Linear创新性的提出了一种称为Kimi Delta Attention(KDA)的新模块，扩展了Gated DeltaNet，并引入了更精细的门控机制，优化了RNN内存的使用。同时，论文提出了一种专为硬件效率设计的分块算法，通过特定的对角线加稀疏矩阵形式极大地减少了计算量，提升了整体的性能和效率。该模型在实证研究中展示了显著的优势：与全注意机制相比，Kimi Linear在所有评估任务中表现出色，并将KV缓存使用量降低高达75%，同时解码吞吐量提升了6倍，特别是在处理长输入和输出长度的任务时展现出更强的目的性。", "conclusion": "研究表明，Kimi Linear作为全注意结构的直接替代品，在表现和效率方面都具有明显的优势，并支持了进一步的实证研究工作。为支持研究，作者开源了KDA内核和vLLM实现，并发布了预训练和指令微调的模型检查点。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25860", "html_url": "https://arxiv.org/abs/2510.25860", "title": "通过法官的眼睛：推断出的思考痕迹提高LLM评判的可靠性", "title_en": "Through the Judge's Eyes: Inferred Thinking Traces Improve Reliability of LLM Raters", "authors": "Xingjian Zhang,Tianhong Gao,Suliang Jin,Tianhao Wang,Teng Ye,Eytan Adar,Qiaozhu Mei", "background": "大型语言模型（LLMs）逐渐被用作评价任务的评分员，但其在主观任务上的可靠性往往有限，尤其是当人类判断涉及超出标注标签的微妙推理时。人类的推理过程对理解判断具有重要信息，但收集和整理这些推理过程具有挑战性。", "innovation": "本文提出了一个人工智能与大型语言模型协作的框架，用于从仅标注的评分中推断出思考痕迹。该框架使用简单的拒绝采样方法进行大规模重建，并将这些推断出的思考痕迹应用于两个互补任务：（1）微调开放的LLM评判者；（2）为专有LLM评判者合成更清晰的标注指南。这种方法在多个数据集上提高了LLM-人类的一致性，并提高了不同的LLM模型之间的共识。结果表明，LLMs可以作为人类思考痕迹的可操作替代代理，进而让人机标注数据集扩展为包含思考痕迹的数据集，以增强LLM评判者的可靠性。", "conclusion": "我们的方法取得了显著的进展，不仅提高了LLM-人类的一致性，而且提高了不同LLM模型间的共识。这表明LLMs可以作为人类思维的替代代理，从而让人化的标注数据集扩展为包含思考痕迹的数据集，这增强了LLM评判者的可靠性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS：通过自我提炼的基于偏好冷启动分离多模态学习", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "近年来，具有可验证奖励的强化学习（RL）催生了一波名为“MLLM-r1”的方法，将RL带入了视觉语言模型中。大多数代表性的方法通常在冷启动阶段使用监督微调（SFT）来初始化策略，然后进行RL。然而，基于SFT的冷启动方法在离散分布上的泛化能力较弱，容易出现指令式的过拟合，进而影响下游的RL任务效果。本文重新审视了冷启动阶段的训练方法和数据构造，引入了评估不同方法下泛化能力的Generalization Factor（GF）系数。实验证明，基于偏好的训练方法（如DPO）在冷启动阶段的表现优于基于SFT的方法。", "innovation": "本文提出了一个名为SPECS（Self-distilled，Preference-based Cold Start）的框架，该框架通过自我提炼的基于偏好的冷启动来分离多模态学习过程：（1）通过自我提炼生成内省性的偏好数据对，避免依赖于更大的教师模型或手动标注；（2）进行基于偏好的训练，专注于学习浅显、可迁移的表面形式标准（格式、结构、风格）而非内容的死记硬背；（3）将验证奖励的RL留给下游任务，以产生深入的推理结果。多次多模态基准实验表明，该分离学习框架在多种基准上较强大的基线模型取得了持续的性能提升，特别是在MEGA-Bench上提高了4.1%，在MathVista上提高了12.2%。此外，进一步的实验表明SPECS减少了分布内的“卡顿”，提高了探索性，稳定了训练，并提升了性能天花板。", "conclusion": "本文提出了一个分离多模态学习框架SPECS，通过自我提炼的基于偏好的冷启动方法，改进了多模态学习的泛化能力和下游强化学习的表现。实验结果展示了该框架的有效性，特别是在不同基准测试上的性能提升。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26037", "html_url": "https://arxiv.org/abs/2510.26037", "title": "SIRAJ: 通过提炼结构化推理实现LLM代理多样且高效的红队测试", "title_en": "SIRAJ: Diverse and Efficient Red-Teaming for LLM Agents via Distilled Structured Reasoning", "authors": "Kaiwen Zhou,Ahmed Elgohary,A S M Iftekhar,Amin Saied", "background": "语言模型（LLM）代理在执行计划和调用工具的能力上存在新的安全风险，因此需要一个全面的红队系统来发现漏洞并确保其安全部署。当前的研究缺乏一个适用于任意黑盒LLM代理的一般性红队框架。", "innovation": "本文提出了SIRAJ，一个用于任意黑盒LLM代理的通用红队框架。它采用了一种动态的两步过程：首先定义代理并生成涵盖各种风险结果、工具调用轨迹和风险来源的多样化初始测试案例；然后基于先前尝试的执行轨迹迭代构建和优化基于模型的对抗攻击。此外，该研究还提出了一种模型蒸馏方法，利用教师模型的推理结构来训练出更小且同样有效的模型。", "conclusion": "通过种子测试案例生成方法，SIRAJ在不同评估代理设置中提高了2-2.5倍的风险结果和工具调用轨迹覆盖率。蒸馏80亿参数的红队模型成功攻击率提高了100%，超过了Deepseek-R1 6710亿参数模型。消融和分析结果验证了迭代框架、结构化推理的有效性及其红队模型的泛化能力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26006", "html_url": "https://arxiv.org/abs/2510.26006", "title": "CAVE: 在视觉环境中检测和解释常识性异常", "title_en": "CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments", "authors": "Rishika Bhagwatkar,Syrielle Montariol,Angelika Romanou,Beatriz Borges,Irina Rish,Antoine Bosselut", "background": "人类能够自然地识别、推理和解释环境中的异常。然而，在计算机视觉领域，这一长期存在的挑战仅限于工业缺陷或不切实际、合成生成的异常，无法捕捉到现实世界中异常的丰富性和不可预测性。为此，本文提出了CAVE，第一个真实世界的视觉异常基准，它支持描述、解释和证明异常的开放任务，提供了详细的注释，用于视觉定位和按其视觉表现、复杂性、严重性和常见性分类异常。这些注释借鉴了认知科学如何帮助人类识别和解决异常的研究，为评估视觉语言模型（VLMs）在检测和理解异常方面的表现提供了全面的框架。现有的VLMs在视觉异常感知和常识推理方面表现不佳，即使是改进了提示策略。提供一个现实和认知基础的基准CAVE是促进异常检测和常识推理研究的宝贵资源。", "innovation": "引入CAVE，第一个真实世界的视觉异常基准，支持描述、解释和证明异常的任务，并提供详细的注释以分类和定位异常，借鉴人类识别和解决异常的认知科学研究，提供了评估VLMs检测和理解异常能力的全面框架。", "conclusion": "现有的VLMs在视觉异常感知和常识推理方面表现不佳，即使是改进了提示策略。提供现实和认知基础的基准CAVE是促进异常检测和常识推理研究的宝贵资源。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26143", "html_url": "https://arxiv.org/abs/2510.26143", "title": "从数学引导通用大语言模型推理课程：强化学习", "title_en": "Reasoning Curriculum: Bootstrapping Broad LLM Reasoning from Math", "authors": "Bo Pang,Deqian Kong,Silvio Savarese,Caiming Xiong,Yingbo Zhou", "background": "强化学习（RL）可以在大型语言模型（LLM）中引发强大的推理能力，但大多数公开的努力主要集中在数学和代码领域。研究者提出了一种简单的两阶段课程来训练这些模型的推理技能。", "innovation": "该论文创新地提出了一个两阶段的推理课程，首先使用数学领域的预训练数据并通过可验证奖励的RL训练，开发初步的推理技能，然后通过混合领域的联合RL将这些技能转移到其他领域，形成巩固。该课程简单且与基础模型无关，只需要基本的验证性奖励模型。", "conclusion": "通过对Qwen3-4B和Llama-3.1-8B的多领域评估，推理课程带来了显著的提升。拆分实验和认知技能分析表明，两个阶段都是必要的，先从数学开始训练可以增进解决复杂问题所需的重要认知行为。推理课程提供了一个简洁、易于采纳的通用推理配方。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25932", "html_url": "https://arxiv.org/abs/2510.25932", "title": "FakeZero：Facebook和X实时、隐私保护的误传信息检测", "title_en": "FakeZero: Real-Time, Privacy-Preserving Misinformation Detection for Facebook and X", "authors": "Soufiane Essahli,Oussama Sarsar,Imane Fouad,Anas Motii,Ahmed Bentajer", "background": "社交媒体平台以不寻常的速度传播信息，进而加快了错误信息的传播速度，对公众对话构成威胁。因此，开发一种能在用户浏览时即时检测虚假信息的浏览器插件变得至关重要。FakeZero就是这样一个插件，它是一个完全在客户端进行、跨平台的浏览器扩展，能够在用户滚动社交媒体平台时识别不实信息。", "innovation": "FakeZero采用了一种三阶段的训练课程，包括基础微调和领域适应训练，增强使用了焦点损失、对抗增强和后训练量化。它使用了DistilBERT和TinyBERT模型的量化版，以确保既能快速检测又不会泄露用户数据。DistilBERT-Quant模型仅需67.6 MB，准确率和宏观F1分数分别为97.4%和97.1%，AUROC为0.996，并且具有约103毫秒的中位延迟。TinyBERT-Quant版本的模型大小只有14.7 MB，准确率和宏观F1分数分别为96.1%和95.7%，其延迟仅为约40毫秒。这意味着即使在资源受限的情况下，高质量的假新闻检测也是可行的。此外，插件还提供了实时反馈，供政策制定者参考，帮助遏制社交媒体上的假信息传播，并研究者收集大规模的假信息样本以进行更深入的研究与开发.", "conclusion": "该研究展示了即使在有限的硬件资源下，精准检测假新闻也是可能的。通过平衡性能和隐私保护，FakeZero不仅为缓解社交媒体上的错误信息浪潮提供了有力工具，还为研究人员收集大量真实世界中的假新闻数据以进一步提升检测技术提供了可能路径。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "知识蒸馏对于去偏方法的可蒸馏性是否有影响？——关于偏见缓解方法的可蒸馏性及其内在机制的研究", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识蒸馏（KD）是模型压缩和知识迁移的有效方法，但其对抗由于数据分布外问题导致的鲁棒性下降影响尚未得到充分探索。本文研究了知识蒸馏对自然语言推理（NLI）任务和图像分类任务中教师模型的去偏能力向学生模型的转移性影响。实验结果表明，尽管在总体上学生模型的去偏能力受到知识蒸馏的影响，但在去偏模型训练中注入教师知识并未带来改善，且不同类型的偏见在知识蒸馏后表现出显著的变化。此外，研究发现了导致特定行为变化的内部注意力模式和电路。这些发现为进一步改进去偏方法提供了指导作用。", "innovation": "首次系统性地研究了知识蒸馏对去偏方法的可蒸馏性及其内在机制的影响，并提出了改善去偏方法可蒸馏性的三种有效方法：开发高质量的数据用于增强、实施迭代知识蒸馏、用教师模型权重初始化学生模型。", "conclusion": "本文的结论表明，尽管知识蒸馏会影响模型的去偏能力，但通过优化方法可以提升去偏模型的蒸馏性能，从而更好地进行模型的知识转移和偏见缓解。这是对知识蒸馏效果和去偏方法设计理解的一个重要进展。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26095", "html_url": "https://arxiv.org/abs/2510.26095", "title": "ORBIT - 开放推荐基准测试，用于隐藏测试的可重现研究", "title_en": "ORBIT - Open Recommendation Benchmark for Reproducible Research with Hidden Tests", "authors": "Jingyuan He,Jiongnan Liu,Vishan Vishesh Oberoi,Bolin Wu,Mahima Jagadeesh Patel,Kangrui Mao,Chuning Shi,I-Ta Lee,Arnold Overwijk,Chenyan Xiong", "background": "推荐系统是最有影响力的AI应用之一，每天与数十亿用户互动，引导他们找到符合其偏好的产品、服务或信息。然而，推荐系统的研究和开发受到现有数据集的限制，这些数据集未能捕捉到真实的用户行为，不同的评价设置导致结论模糊不清。", "innovation": "ORBIT是一个统一基准，提供了标准化的评估框架，用于公共数据集的一致性和现实性评价，其公共排行榜具有可重复的分割和透明的设置。ORBIT引入了一个新的网页推荐任务ClueWeb-Reco，基于8700万公共高质量网页的浏览序列，该数据集来源于真实的、用户同意的、隐私保证的浏览数据。ClueWeb-Reco作为一种合成数据集，专为排行榜的隐藏测试部分保留，以挑战推荐模型的大规模网页推荐的一般化能力。ORBIT对12种代表性推荐模型进行了评估，并在ClueWeb-Reco隐藏测试中引入了提示式大语言模型基线。", "conclusion": "基准测试结果反映了推荐系统在公共数据集上的普遍改进，不同模型的表现各有差异。隐藏测试的结果揭示了现有方法在大规模网页推荐方面的局限性，并指出了大语言模型集成的潜在改进空间。ORBIT的基准测试、排行榜和代码库可以在提供的网址访问。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26190", "html_url": "https://arxiv.org/abs/2510.26190", "title": "SP-MCQA: 超越单词层面评估TTS的清晰度", "title_en": "SP-MCQA: Evaluating Intelligibility of TTS Beyond the Word Level", "authors": "Hitomi Jin Ling Tee,Chaoren Wang,Zijie Zhang,Zhizheng Wu", "background": "目前，TTS（文本转语音）的清晰度评估已经达到了瓶颈，现有的评估方法主要依赖于逐词准确性的指标，如WER（单词错误率），这些指标无法捕捉到真实语音的复杂性，或者反映人类的理解需求。", "innovation": "本文提出了一种新的主观评估方法——Spoken-Passage Multiple-Choice Question Answering（SP-MCQA），它评估合成语音中的关键信息准确性。为此，作者还发布了SP-MCQA-Eval数据集，包含8.76小时的新闻风格基准数据。实验结果显示，低WER并不代表高关键信息准确性，暴露出传统指标与实际清晰度之间的差距。SP-MCQA表明，即使是当前最先进的模型，在文本归一化和音素准确性方面仍表现出不足。", "conclusion": "本研究强调，随着许多系统在WER方面已经表现出色，但在实际清晰度方面可能仍存在不足，急需为TTS设定更高层次、更贴近生活的评估标准。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26167", "html_url": "https://arxiv.org/abs/2510.26167", "title": "一种模型来全面评价：通过高效推理奖励代理工具使用", "title_en": "One Model to Critique Them All: Rewarding Agentic Tool-Use via Efficient Reasoning", "authors": "Renhao Li,Jianhong Tu,Yang Su,Hamid Alinejad-Rokny,Derek F. Wong,Junyang Lin,Min Yang", "background": "奖励模型（RMs）在使大型语言模型（LLMs）与人类偏好保持一致方面发挥着关键作用。然而，在工具学习领域，专门设计的功能调用任务奖励模型的缺乏限制了朝着更高级代理人工智能的进步。为此，本文介绍了一种名为ToolRM的轻量级生成奖励模型家族，专门用于通用工具使用场景。", "innovation": "本文提出了一个新的管道，通过基于规则的评分和多维采样构建配对偏好数据，从而创建了ToolPref-Pairwise-30K数据集，该数据集支持具有可验证反馈的强化学习，具备多样性和挑战性。此外，还提出了TRBench$_{BFCL}$基准测试，基于BFCL代理评估套件。研究结果表明，Qwen3-4B/8B系列模型在配对奖励判断方面高出14.28%，显著优于如Claude 4和OpenAI o3等前沿模型。ToolRM不仅适用于训练目标，还能泛化到更广泛的批判任务，包括Best-of-N采样和自我纠正。实验表明，其在ACEBench上表现出高效性和有效性，使推理时可扩展性增强，输出标记数减少了66%以上。", "conclusion": "本研究通过提供轻量级生成的奖励模型家族ToolRM和相关的数据集，以及研究结果表明，这种模型不仅在工具使用评估方面表现出色，还可以泛化应用到其他类型的任务中，显著提高了代理人工智能处理工具使用任务的准确性和效率。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26241", "html_url": "https://arxiv.org/abs/2510.26241", "title": "时间如何流逝？基于心理物理的视觉语言模型评估", "title_en": "Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models", "authors": "Shiho Matta,Lis Kanashiro Pereira,Peitao Han,Fei Cheng,Shigeru Kitazawa", "background": "现代的视觉-语言模型（VLMs）在多模态任务中表现出色，但在视频中的时间信息理解方面仍旧薄弱且评估不足。", "innovation": "本文提出了一个简明但揭示性的问题：判断视频中的时间箭头（AoT），即判断一段短视频是正放还是倒放。通过建立心理物理验证基准AoT-PsyPhyBENCH，测试VLMs是否能够从自然视频中推断时间方向。评估结果显示，大多数模型的表现仅能接近随机水平，即使是最好模型的表现也远远落后于人类在不可逆物理过程（如自由落体、扩散/爆炸）和因果手动动作（如分割/加法）方面的识别能力。这些结果突显了当前多模态系统中存在的根本性缺陷：虽然可以捕捉丰富的视觉-语义关联，但缺乏用于时间连续性及因果理解的归纳偏置。", "conclusion": "本研究揭示了目前VLMs在物理和时间推理能力上的局限性，强调了需要进一步改进。文章还发布了AoT-PsyPhyBENCH的相关代码和数据，以促进VLMs在物理和时间推理能力上的进步。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26274", "html_url": "https://arxiv.org/abs/2510.26274", "title": "PVMark: 使LLM水印方案具有公信力", "title_en": "PVMark: Enabling Public Verifiability for LLM Watermarking Schemes", "authors": "Haohua Duan,Liyao Xiang,Xin Zhang", "background": "大型语言模型（LLMs）的水印方案已被提出，以识别生成文本的源头，减轻模型盗窃可能带来的潜在威胁。然而，现有的水印解决方案难以解决信任问题：非公开的水印检测无法忠实地证明其执行检测的真实性。观察到这一点的原因在于用于水印检测的密钥大多不可公开，以防对手利用密钥进行移除攻击，同时也不可私有化，以保持水印检测对公众的透明度。", "innovation": "提出了一种基于零知识证明（ZKP）的插件PVMark，其允许第三方对水印检测过程进行公开验证，而无需透露任何密钥。PVMark依赖于水印检测的`正确执行`证明，构建了一系列ZKP约束，包括映射、随机数生成、比较和求和。PVMark在Python、Rust和Circom中实现多个版本，覆盖三种水印方案、三种哈希函数和四种ZKP协议，展示了其在不同情况下的有效性。实验结果表明，PVMark能够在保持水印性能的情况下，使最先进的LLM水印方案具备高效公开可验证性，有望实际部署。", "conclusion": "通过实验结果，PVMark高效地实现了对先进LLM水印方案的公开验证能力，且不会牺牲水印性能，这对于实际部署具有重要意义。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26423", "html_url": "https://arxiv.org/abs/2510.26423", "title": "Nexus: 基于执行的多智能体测试金标准合成", "title_en": "Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis", "authors": "Dong Huang,Mingzhe Du,Jie M. Zhang,Zheng Lin,Meng Luo,Qianru Zhang,See-Kiong Ng", "background": "非回归测试中的测试金标准生成一直是一个长期的软件工程挑战，其目标是生成能够准确判断被测试函数（FUT）在给定输入下是否按预期行为的测试金标准。以前的方法在生成精确的测试金标准方面存在局限性，尤其是在复杂和多样化的基准测试中。因此，需要一种能够生成高精度测试金标准的新框架来解决这一挑战", "innovation": "Nexus 是一种新颖的多智能体框架，通过利用多种专门的智能体并采用结构化的审阅、验证和迭代自改进过程来生成测试金标准。Nexus 的创新主要体现在其多智能体架构和动态的自改进机制上，能够有效提升测试金标准的准确性和可靠性，特别是在复杂的基准测试中表现出色。相比现有 baselines，Nexus 在多个指标上显著提升了测试金标准的性能，特别是在 LiveCodeBench 和 HumanEval 等基准测试中", "conclusion": "Nexus 框架通过其独特的多智能体架构和迭代自改进机制，有效地提高了测试金标准的生成质量和准确性，显著提升了下游任务如 bug 检测和自动化程序修复的成功率。通过广泛的基准测试表明，Nexus 在多个方面超越了现有 baselines，展示了其在软件工程领域中的显著优势"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26658", "html_url": "https://arxiv.org/abs/2510.26658", "title": "代理组织时代的到来：语言模型学习组织", "title_en": "The Era of Agentic Organization: Learning to Organize with Language Models", "authors": "Zewen Chi,Li Dong,Qingxiu Dong,Yaru Hao,Xun Wu,Shaohan Huang,Furu Wei", "background": "本文设想了一个新的AI时代——代理组织时代，其中代理通过协作和并行解决问题，从而产生超越个体智能的成果。为实现这一愿景，作者引入了异步思考（AsyncThink）作为用大规模语言模型进行推理的新范式，将内在的思考过程组织成可以并发执行的结构。", "innovation": "提出了一个新的思考协议，其中组织者动态地将子查询分配给工作人员，合并中间知识，并生成连贯的解决方案。此外，通过强化学习进一步优化思考结构。实验结果表明，AsyncThink在数学推理方面的准确性更高，同时将推理延迟降低了28%，且能有效应对未见过的任务。", "conclusion": "AsyncThink展示了学习到的异步思考能力，并能有效地处理未见过的任务，无需额外训练。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26457", "html_url": "https://arxiv.org/abs/2510.26457", "title": "增强大型语言模型以进行安全代码审查的SecureReviewer：通过安全感知微调", "title_en": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "authors": "Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang", "background": "在软件开发初期识别和解决安全问题对于减轻长期负面影响至关重要。代码审查是一种有效的方法，让开发人员在代码集成到代码库之前检查队友的代码。尽管已经提出了多种自动代码审查方法，特别是基于大语言模型（LLM）的方法显著提升了自动审查生成的能力，但现有模型主要集中在通用代码审查上，对抗与安全相关问题的识别和解决能力尚未得到充分探索。此外，适应现有代码审查方法以针对安全问题存在数据稀缺和评价指标不足等显著挑战。", "innovation": "为了应对这些局限，我们提出了一种新的方法SecureReviewer，专门用于增强LLM识别和解决安全问题的能力。我们首先构建了一个专门用于训练和评估安全代码审查能力的数据集，并利用这个数据集对LLMs进行微调。我们还提出了安全感知的微调策略，以生成能够有效识别安全问题和提供修复建议的审查评论。为减少大语言模型的幻觉并提高生成评论的可靠性，我们引入了RAG技术，将生成的评论置于特定领域的安全知识基础之上。另外，我们还引入了SecureBLEU，这是一种新的评价指标，用于评估审查评论在解决安全问题上的有效性。实验结果显示，SecureReviewer在安全问题检测准确性以及生成的审查评论的整体质量和实用价值方面都优于最新的基线模型。", "conclusion": "实验证明，SecureReviewer在安全问题检测精度和生成的审查评论的整体质量和实用性方面均优于最先进的基线模型。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26474", "html_url": "https://arxiv.org/abs/2510.26474", "title": "通过头部-尾部再平衡对抗LVLMs自我改进中的马太效应", "title_en": "Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing", "authors": "Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "大型视觉语言模型（LVLMs）通过自我改善的范式来提升推理能力，模型通过迭代探索和学习成功路径。然而，研究发现在这个过程中存在一个关键问题：模型在生成简单查询（即头部数据）的高质量路径方面表现出色，但在处理更复杂查询（即尾部数据）时却面临困难，导致优化不平衡，模型优先发展简单推理技能，而忽视了复杂推理任务的处理能力。随着时间的推移，这种不平衡越来越明显，我们将其称为‘马太效应’，最终阻碍了模型的进一步改进，导致性能瓶颈。", "innovation": "本文提出了四种高效的策略，从分布重塑和路径重采样的两个视角出发，在探索和学习的自我改进过程中实现头部-尾部再平衡。通过广泛的实验，展示了这些方法在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型在视觉推理任务上的性能提升，平均提升了3.86个百分点，优于传统的自我改进方法.", "conclusion": "通过头部-尾部再平衡策略，可以有效对抗LVLMs自我改进中的马太效应，优化模型在复杂推理任务上的处理能力，从而提高视觉推理的能力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26493", "html_url": "https://arxiv.org/abs/2510.26493", "title": "Context Engineering 2.0: The Context of Context Engineering", "title_en": "Context Engineering 2.0: The Context of Context Engineering", "authors": "Qishuo Hua,Lyumanshan Ye,Dayuan Fu,Yang Xiao,Xiaojie Cai,Yunze Wu,Jifan Lin,Junfei Wang,Pengfei Liu", "background": "本文背景源于卡尔·马克思的观点，即人类的本质是社会关系的集合，暗示个体不是孤立存在的，而是通过与其他实体的互动而形成的。随着计算机和人工智能的出现，这些互动不仅限于人类之间的互动，还涵盖了人机互动。由此引出了一个关键问题：如何让机器更深刻地理解我们的处境和目的？为解决这一挑战，研究人员引入了上下文工程的概念。尽管常被视为代理时代的新创新，文章指出相关实践可追溯到超过二十年前。自20世纪90年代初，该领域经历了不同的历史阶段，每个阶段都受到机器智能水平的影响：从早期围绕初级计算机构建的人机交互框架，到当今由智能代理驱动的人机交互范式，并可能发展到未来的人机或超人类智能阶段。", "innovation": "文章为上下文工程提供了一个系统的定义，概述了其历史和概念框架，并探讨了关键的设计考虑，旨在为上下文工程提供一个概念基础，并勾勒出其有希望的发展路径。这是面向更广泛社区努力进行人工智能系统系统化上下文工程的一个出发点。", "conclusion": "通过这些问题的回答，文章旨在提供上下文工程的概念基础，并勾勒出其有希望的未来。该文是向更广泛的人工智能系统中的系统化上下文工程努力迈出的一步。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26732", "html_url": "https://arxiv.org/abs/2510.26732", "title": "跨平台基础模型推理能力评估", "title_en": "Cross-Platform Evaluation of Reasoning Capabilities in Foundation Models", "authors": "J. de Curtò,I. de Zarzà,Pablo García,Jordi Cabot", "background": "本文对当今日益流行的基础模型的推理能力进行了全面的跨平台评估。评估通过三种计算范式进行：高性能计算超级计算机（MareNostrum 5）、云平台（Nebius AI Studio）和大学集群（配备八块H200 GPU的节点），涵盖八个学术领域的问题，这些领域涉及物理、数学、化学、经济学、生物学、统计学、微积分和优化。", "innovation": "本文创新地在不同的计算基础设施上建立了基础设施无关的基准，对比了15种基础模型在79个问题上的表现，挑战了传统的放大假设，强调了训练数据质量的重要性，并提供了跨教育、生产和研究环境的模型选择指南。三平台方法和79个问题基准使我们能够纵向追踪基础模型推理能力的发展变化。", "conclusion": "研究成果表明质疑了传统扩规模的假设，确认训练数据的质量比模型大小更为关键，并提供了模型在教育、生产和研究中的选择指南。跨平台基础设施方法及79个问题的基准有助于深入理解基础模型推理能力的增长趋势。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26495", "html_url": "https://arxiv.org/abs/2510.26495", "title": "重新思考Text-to-SQL：面向现实数据库探索的动态多轮SQL交互", "title_en": "Rethinking Text-to-SQL: Dynamic Multi-turn SQL Interaction for Real-world Database Exploration", "authors": "Linzhuang Sun,Tianyu Guo,Hao Liang,Yuying Li,Qifeng Cai,Jingxuan Wei,Bihui Yu,Wentao Zhang,Bin Cui", "background": "近年来，Text-to-SQL技术在静态、单轮任务中取得了显著成果，模型能够直接从自然语言问题生成SQL查询。然而，这些系统在现实中的交互场景中表现不佳，如金融和商业分析等应用中，用户会根据中间结果迭代调整查询约束或维度。为了评估这种动态能力，本文提出了DySQL-Bench，该基准测试评估模型在不断变化的用户交互下的表现。与之前的手工优化数据集不同，DySQL-Bench是通过自动化的两阶段过程构建的，包括任务合成和验证。同时，还提出了一种多轮评价框架，模拟了自然语言模型模拟用户、被测试模型和可执行数据库之间的交互。", "innovation": "1. 提出了DySQL-Bench，一个通过自动两阶段管道构建的基准测试，评估模型在不断变化的用户交互下的表现。\n2. 采用结构化的树表示从原始数据库表导出指导LLM任务生成，结合面向交互的过滤和专家验证。\n3. 提出了一种多轮评价框架，模拟了自然语言模型模拟用户、被测试模型和可执行数据库之间的交互。\n4. DySQL-Bench覆盖了13个不同领域，总计1,072个任务，即使先进的GPT-4o也只有58.34%的总体准确率和23.81%的Pass@5准确率，突显了这一基准测试的挑战性。", "conclusion": "通过DySQL-Bench基准测试，研究结果表明现有的Text-to-SQL模型在处理变化的用户意图和多轮交互时存在不足。需要开发更具适应性的模型来提高SQL生成的质量。所有代码和数据已在指定的链接处发布，以便其他研究人员进行进一步的研究和测试。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26745", "html_url": "https://arxiv.org/abs/2510.26745", "title": "深度序列模型倾向于记忆几何结构；尚不清楚其原因", "title_en": "Deep sequence models tend to memorize geometrically; it is unclear why", "authors": "Shahriar Noroozizadeh,Vaishnavh Nagarajan,Elan Rosenfeld,Sanjiv Kumar", "background": "在序列建模中，参数化记忆通常被抽象为实体共现的粗暴查询。本文通过对比关联视角和几何视角，探讨了记忆存储的新方法。研究表明，模型可能通过合成自己独特的几何结构，而不仅仅是存储训练指定的局部共现，来处理复杂的推理任务。这种现象引发了关于神经嵌入几何结构的基本特性的思考，这些特性难以用简单的局部关联来解释。尽管优化目标仅涉及局部关联，但这种几何结构的形成原因仍不清楚。通过分析与Node2Vec的联系，文章得出了某种谱偏置在缺乏多种压力情况下仍然自然产生的结论，这为开发者提供了让Transformer更具几何特性的空间，推动了在知识获取、容量、发现和遗忘方面的新思考。", "innovation": "提出了将序列建模中的参数化记忆视为超越简单局部共现记忆的几何结构存储方法的新观点。揭示了这种几何结构的形成机制，即通过模型自己合成全局关系几何结构来简化复杂的推理任务，而不是机械地存储局部共现。提出了谱偏置理论的新的自然产生观点，为增强Transformer模型的几何特性提供了理论基础。", "conclusion": "尽管优化目标仅优化局部关联，但模型能够自然地生成复杂的几何结构，挑战了典型的架构或优化压力观点。通过理解这种现象，研究者可以重新审视传统的直觉，以改进知识获取、容量、发现和遗忘等方面的方法。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26787", "html_url": "https://arxiv.org/abs/2510.26787", "title": "远程劳动力指数：衡量远程工作的AI自动化", "title_en": "Remote Labor Index: Measuring AI Automation of Remote Work", "authors": "Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks", "background": "人工智能已经在知识和推理的研究基准上取得了快速进展，但这些进展如何转化为经济效益和自动化仍不清楚。为了测量这些进展，引入了远程劳动力指数（RLI），这是一个包含真实世界、经济价值项目的广泛多部门基准，旨在评估代理在实际环境中的端到端性能。这些基准项目的目的是了解AI自动化在实际工作环境中的效果。", "innovation": "提出了一种新的基准——远程劳动力指数（RLI），用于评估AI代理在实际工作条件下的端到端性能。RLI包含了真实世界中具有经济价值的项目，旨在弥补现有AI评估基准的不足。", "conclusion": "AI代理在RLI中的表现接近最低水平，最高绩效的代理只实现了2.5%的自动化率。这有助于将AI自动化讨论建立在实证证据的基础上，为跟踪AI影响提供了一个共同的基准，使利益相关者能够积极应对由AI驱动的劳动力自动化。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26606", "html_url": "https://arxiv.org/abs/2510.26606", "title": "大型语言模型中的规范推理：从逻辑和模态视角的比较基准", "title_en": "Normative Reasoning in Large Language Models: A Comparative Benchmark from Logical and Modal Perspectives", "authors": "Kentaro Ozeki,Risako Ando,Takanobu Morishita,Hirohiko Abe,Koji Mineshima,Mitsuhiro Okada", "background": "规范推理涉及义务和许可等规范或应规范模态。尽管大型语言模型（LLMs）在各种推理任务上表现出色，但它们在处理规范推理方面的能力尚未得到充分探索。因此，本文系统性地从逻辑和模态两个角度评估了LLMs在规范领域的推理能力。为了评估LLMs在处理规范模态方面的推理能力，通过将其与处理表征学习结构共同特征的表征学习结构的知识模态进行比较来实现这一目标。为此，我们引入了一个新的数据集，涵盖了规范和知识领域广泛的推理形式模式结构，同时纳入了影响人类推理的非形式认知因素。研究结果显示，虽然LLMs一般遵守有效的推理模式，但在特定类型的规范推理中显示出明显的不一致，并且表现出与人类推理的心理学研究相似的认知偏差。这些发现揭示了LLMs在规范推理中实现逻辑一致性的挑战，并为提高其可靠性提供了启示。所有数据和代码均在公开网址处发布。", "innovation": "本文通过引入一个涵盖规范和知识领域广泛形式模式结构的新数据集，首次系统地从逻辑和模态两个角度评估了大型语言模型在规范推理领域的推理能力。在此过程中，还将规范模态推理与知识模态推理进行了比较，后者具有共同的形式结构。此外，该研究还考虑了影响人类推理的非形式认知因素。这些方法论上的创新有助于更深入地理解大型语言模型在处理规范推理方面的表现和局限性。", "conclusion": "尽管大型语言模型在规范推理中通常遵守有效的推理模式，但在特定类型上表现出色，并且存在认知偏差。这些发现揭示了在大型语言模型中实现规范推理逻辑一致性的挑战，为优化模型的可靠性提供了洞见。此外，数据和代码的公开发布将有助于后续研究探索和验证这些发现。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26788", "html_url": "https://arxiv.org/abs/2510.26788", "title": "利用FP16击败训练推理不一致性", "title_en": "Defeating the Training-Inference Mismatch via FP16", "authors": "Penghui Qi,Zichen Liu,Xiangxin Zhou,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "强化学习（RL）对大型语言模型（LLMs）进行微调时，常常由于训练和推理政策之间的数值不匹配而导致不稳定性。尽管之前的研究试图通过算法修正或工程对齐来缓解这个问题，但研究表明，其根本原因在于浮点精度本身。尽管广泛采用的BF16因其较大的动态范围，但其引入的大量舍入误差破坏了训练和推理的一致性。因此，需要从根本上解决这一问题，以便实现更稳定的优化、更快的收敛和更强的性能。", "innovation": "本文通过简单地返回使用FP16有效地解决了这个问题。这种方法简单且完全由现代框架支持，仅需几行代码更改，无需对模型架构或学习算法进行任何修改。实验结果显示，使用FP16统一的方法在不同任务、算法和框架中均能提供更稳定的优化、更快的收敛和更强的性能。这揭示了在RL微调中应重新考虑精度权衡的重要性。", "conclusion": "使用FP16统一的方法在多种任务、算法和框架中表现出了更强的性能和更快的收敛速度，同时保持了模型的稳定性。希望这项发现能够推动对RL微调中精度权衡的更广泛审视。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.26802", "html_url": "https://arxiv.org/abs/2510.26802", "title": "视频模型准备好作为零样本推理引擎了吗？MME-CoF基准的实证研究", "title_en": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark", "authors": "Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng", "background": "近期的视频生成模型能够生成高质量、时间上一致的视频，表明这些模型可能包含丰富的世界知识。除了现实主义的合成外，这些模型还展示了视觉感知、建模和操作的新兴行为。然而，一个重要的问题仍然存在：当前的视频模型是否准备好在挑战性的视觉推理场景中作为零样本推理器使用？", "innovation": "本文开展了一项实证研究，全面调查这一问题，集中探讨领先且流行的Veo-3模型。通过12个维度（包括空间、几何、物理、时间以及具身逻辑等方面）系统地评估其推理行为。为了标准化这项研究，本文创建了一个基准（MME-CoF），该基准能够深入且全面地评估链-帧（CoF）推理。研究发现当前的视频模型在短期空间一致性和细粒度定位上表现出积极的推理模式，但在长期因果推理、严格的几何约束和抽象逻辑上仍然有限。", "conclusion": "总体而言，这些模型尚未可靠地作为独立的零样本推理器，但作为专为推理设计的模型的补充视觉引擎显示出令人鼓舞的迹象。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2311.06736", "html_url": "https://arxiv.org/abs/2311.06736", "title": "LLMs是否是严格的逻辑推理者？通过逐步解码与对比学习强化自然语言证明生成", "title_en": "Are LLMs Rigorous Logical Reasoners? Empowering Natural Language Proof Generation by Stepwise Decoding with Contrastive Learning", "authors": "Ying Su,Mingwen Liu,Zhijiang Guo", "background": "逻辑推理是人工智能领域的一个关键组成部分，特别是在需要验证解释准确性的情境中。虽然大型语言模型（LLMs）在自然语言证明规划方面取得了显著进展，从单一阶段生成器发展到更复杂的三阶段系统，包括额外的搜索器或验证器，但这些辅助方法虽然提高了生成结果的质量，但也增加了更多的搜索努力和计算成本。此外，生成过程本身仍需进一步探索。因此，该研究旨在通过逐步解码和对比学习增强的步骤来解决LLM生成器在解码过程中遇到的两种常见错误。", "innovation": "该研究提出了一种由对比学习辅助的逐步解码方法，并通过使用标准和改进的硬负例对语言模型进行微调，以减轻这些解码错误。研究表明，该策略有效。进一步的分析还发现，即使更大的LLMs在生成严谨的逻辑链方面仍然存在困难。", "conclusion": "我们的研究成果表明，通过逐步解码与对比学习方法增强自然语言生成可以有效解决大型语言模型在生成严谨逻辑链时遇到的一些关键问题。尽管大型语言模型在生成自然语言证明方面取得了进展，但它们在产生严格逻辑链方面仍然存在挑战。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2409.06263", "html_url": "https://arxiv.org/abs/2409.06263", "title": "Speak & Spell: LLM-Driven Controllable Phonetic Error Augmentation for Robust Dialogue State Tracking", "title_en": "Speak & Spell: LLM-Driven Controllable Phonetic Error Augmentation for Robust Dialogue State Tracking", "authors": "Jihyun Lee,Solee Im,Wonjun Lee,Gary Geunbae Lee", "background": "对话状态跟踪（DST）是任务导向对话系统的关键部分，用于识别对话中的重要信息。然而，在语音对话环境中，由于自动语音识别（ASR）系统的命名实体错误，其准确率会显著下降。这些命名实体错误影响了DST模型的鲁棒性，尤其是在低准确率或噪声大的ASR环境下。论文介绍了一种简单而有效的方法来提高DST模型的鲁棒性，通过在关键短语中引入音素相似的错误，并可控制这些错误的位置，从而生成足够的错误模式，提高在杂音和低ASR准确度环境中的准确性。", "innovation": "该研究提出了一种新的方法，通过LLM（大型语言模型）驱动的可控语音错误增强技术来提高DST模型的鲁棒性。具体来说，该方法能够在关键词位置插入类似语音的错误，并通过关键字突出显示的提示来控制这些错误的位置，从而产生足够的错误模型，显著提升了在噪音大和ASR低精度情况下的准确性。", "conclusion": "通过这种方法，研究人员能够在ASR系统具有高噪声或低精度的情况下，生成足够的错误模式，从而提高了DST模型的鲁棒性。这种方法不仅简单易行，而且有效提升了对话系统的性能。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2404.00176", "html_url": "https://arxiv.org/abs/2404.00176", "title": "LSCD基准：对历史词义任务的测试平台", "title_en": "The LSCD Benchmark: a Testbed for Diachronic Word Meaning Tasks", "authors": "Dominik Schlechtweg,Sachin Yadav,Nikolay Arefyev", "background": "LSCD是一种复杂的词形级任务，通常通过两个连续进行的应用于使用层面的任务来实现：首先为使用对生成Word-in-Context (WiC) 标签，随后利用这些标签在图上进行Word Sense Induction (WSI)，以生成义项簇。最后，通过比较随时间的义项簇来生成LSCD标签。这种模块化特性体现在大多数LSCD数据集和模型中，但也导致了模型选项和任务定义的高度异质性，进一步被多种数据集版本、预处理选项和评估指标所加剧。这种异质性使得在可比条件下评估模型、选择最优模型组合或重现结果变得困难。", "innovation": "我们提供了一个基准库，标准了LSCD评估。通过透明的实现，结果变得容易重现，并通过标准化可以让不同的组件自由组合。基准库按照任务的模块化特性允许对WiC、WSI和LSCD进行模型评估。这使得可以对日益复杂的模型组件进行仔细评估，提供了新的模型优化途径。我们利用实施的基准库进行了多项实验，并系统地改进了当前最先进水平。", "conclusion": "我们通过提供一个标准化的LSCD基准库，解决了以往在LSCD任务中面临的模型评估、最优组合选择和结果再现等问题。通过透明实施和标准化，使得不同组件可以自由组合，从而更好地进行复杂模型的试验和优化。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.04380", "html_url": "https://arxiv.org/abs/2502.04380", "title": "多样性的奖励：利用领域未确定数据混合 Fine-Tuning LLMs", "title_en": "Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data", "authors": "Zhenqing Ling,Daoyuan Chen,Liuyi Yao,Qianli Shen,Yaliang Li,Ying Shen", "background": "大规模语言模型（LLMs）需要通过多样化数据集进行微调，以提高它们在各个领域的整体性能。现有方法在建模数据组成比例时常常遇到领域标签缺失、不准确或非标准化的问题，导致性能不佳。此外，基于数据选择的方法则难以平衡不同领域的性能。本文旨在通过构建对比数据池和理论解释，研究数据多样性对增强LLMs整体能力的作用。", "innovation": "本文提出了一种新型方法，赋予LLM双重身份：一个是基于多样奖励的认知探查和数据选择输出模型，另一个是使用选择的数据进行调优的输入模型。这种方法在多种高级LLMs中应用后，显著提升了未知领域数据及一系列基础下游任务的表现。这项研究促进了对数据多样性的理解，并推动了LLMs的数据模型反馈驱动设计。", "conclusion": "实验结果表明，该方法在多种高级LLMs中显著提高了未知领域数据和一系列基础下游任务的表现。作者还发布了相关代码，期望这一研究能为理解数据多样性提供新的视角，并进一步促进LLMs的数据模型反馈驱动设计。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.16325", "html_url": "https://arxiv.org/abs/2410.16325", "title": "这位候选人是[MASK].基于提示的情感提取与参考信", "title_en": "This Candidate is [MASK]. Prompt-based Sentiment Extraction and Reference Letters", "authors": "Fabian Slonimczyk", "background": "该研究提出了一种相对简单的方法来部署预训练的大型语言模型提取文本数据中的情感和其他有用特征。方法没有经过预处理的文本输入，且输出的情感分数具有概率解释性。这种方法在经济和金融领域相比其他方法具有优点，因为它不需要任何微调或标注数据。研究者将该提示基情感提取策略应用于个人手选的机密参考信（RLs）数据集，并展示了参考信中情感内容对职场成果的影响。此外，该研究探讨了信件撰写者之间情感差异对求职者表现的影响，并对比了该方法与其他常用的情感分析方法，如词袋方法、微调语言模型和高级聊天机器人查询。在与其他方法的对比中，提示基情感提取方法能够完全重现结果。进一步，研究通过方法修改获得了性别情感分数，并指出按性别写的参考信强调了不同的人格特质，这些性别差异对女性求职者的职业发展产生了负面影响。", "innovation": "该研究提出了一种新的提示基情感提取方法，该方法无需预处理、微调或标记数据即可提取文本中的情感分数，且这种情感分数具有概率解释性。这种方法对参考信的情感内容进行分析，能够捕捉到求职者的表现。并与词袋方法、微调语言模型和高级聊天机器人的查询进行对比，该方法能够完全再现结果，且修改后的方法还能体现性别情感差异，深入探讨了性别在职场表现中的影响。", "conclusion": "该研究提出的情感提取方法能够准确、有效且可靠地提取参考信中的情感内容，并且无需任何额外的处理。提示基情感提取方法能呈现性别情感差异，暗示性别特征在求职过程中的影响。这种方法为经济和金融领域的情感分析提供了一个新的工具。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2410.12869", "html_url": "https://arxiv.org/abs/2410.12869", "title": "使用多个弱评估器的语言模型偏好评估", "title_en": "Language Model Preference Evaluation with Multiple Weak Evaluators", "authors": "Zhengyu Hu,Jieyu Zhang,Zhihan Xiong,Alexander Ratner,Kaize Ding,Ranjay Krishna", "background": "尽管大型语言模型（LLMs）取得了显著的成功，但评估它们输出的优选性质量仍然是一项关键挑战。现有工作通常利用另一个强大的LLM作为评判者来比较LLM之间的响应，但这种单一评估者的方法容易产生循环偏好，即A比B好，B比C好，但C又比A好，导致评价结果相互矛盾。", "innovation": "为了应对这一挑战，我们引入了PGED（偏好图集成与去噪）这一创新方法。该方法利用多个基于模型的评估者构建偏好图，并通过集成和去噪这些图来获得无环、无矛盾的评价结果。我们为该框架提供了理论保证，证明了其在恢复真实偏好结构方面的有效性。在十个基准上的大量实验展示了PGED在这三种应用中的优越性：1）模型评估中的排名，2）测试时间缩放中的响应选择，3）模型微调中的数据选择。特别地，PGED结合了小型LLM评估器（如Llama3-8B、Mistral-7B、Qwen2-7B）以超越强大的评估器（如Qwen2-72B），显示了其提高评估可靠性和提升模型性能的有效性。", "conclusion": "PGED在处理多重循环偏好方面提供了一种有效的解决方案，这在不同应用场景中展现出显著优势，尤其是当使用小型模型而非大型特强模型时，仍能有效提升评估结果的可靠性和模型性能。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.00333", "html_url": "https://arxiv.org/abs/2503.00333", "title": "更多的同质性：在增加代表性的情况下持续存在的代表性危害", "title_en": "More of the Same: Persistent Representational Harms Under Increased Representation", "authors": "Jennifer Mickel,Maria De-Arteaga,Leqi Liu,Kevin Tian", "background": "该研究背景在于识别和减轻生成式AI系统的潜在风险，尤其是在输出内容中人的代表性问题。研究者关注的是改进生成式AI系统中的代表性是否真正可以消除其中存在的偏差，特别是在职业性别分布方面的表现。文章指出，尽管已经对模型进行了干预以增加女性的代表性，但男性和女性在生成的文本中仍然存在显著的代表性和性别偏见问题，导致刻板印象和新自由主义观念的广泛传播，从而加深了原有不平等的体系。", "innovation": "本研究的关键创新在于通过实证研究展示了性别代表性的增加并没有消除代表性和性别偏见。通过对最新大型语言模型中的职业性别分布进行了详细分析，研究团队发现了尽管增加女性代表性的努力，但性别之间的显著统计差异仍然存在。研究揭示了这些偏差导致的真实世界危害，如刻板印象和新自由主义观念的流行。", "conclusion": "总体而言，尽管已经有措施增加女性的代表性，但在生成式AI系统的输出中，性别代表性的偏见仍然存在，并且导致了一系列的代表性危害。文章得出结论，仅增加代表性不足以全面解决偏见问题，需要更系统的策略来纠正性别偏见，以达到实际的代表性改进。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.05747", "html_url": "https://arxiv.org/abs/2504.05747", "title": "SEA-LION: Southeast Asian Languages in One Network", "title_en": "SEA-LION: Southeast Asian Languages in One Network", "authors": "Raymond Ng,Thanh Ngan Nguyen,Yuli Huang,Ngee Chia Tai,Wai Yi Leong,Wei Qi Leong,Xianbin Yong,Jian Gang Ngui,Yosephine Susanto,Nicholas Cheng,Hamsawardhini Rengarajan,Peerat Limkonchotiwat,Adithya Venkatadri Hulagadri,Kok Wai Teng,Yeo Yeow Tong,Bryan Siow,Wei Yi Teo,Wayne Lau,Choon Meng Tan,Brandon Ong,Zhi Hao Ong,Jann Railey Montalan,Adwin Chan,Sajeban Antonyrex,Ren Lee,Esther Choa,David Ong Tat-Wee,Bing Jie Darius Liu,William Chandra Tjhi,Erik Cambria,Leslie Teo", "background": "近年来，大型语言模型（LLMs）凭借处理和生成自然语言的能力，在人工智能领域占据主导地位。然而，大多数LLM的研究和开发主要集中在英语上，使东南亚等低资源语言地区处于不利地位。针对这一空白，本研究引入了Llama-SEA-LION-v3-8B-IT和Gemma-SEA-LION-v3-9B-IT两种面向东南亚语言的多语言LLM。", "innovation": "本研究通过大规模多语言持续预训练以及多阶段的指令微调、对齐和模型合并，训练了一种支持11种东南亚语言的LION家族LLM，这些语言包括英语、中文、印尼语、越南语、马来语、泰语、缅甸语、老挝语、菲律宾语、泰米尔语和高棉语。经多语言基准测试，该模型实现了同支持东南亚语言的LLM相比的最先进性能。", "conclusion": "本研究开源了该模型，期望能为东南亚地区的更广泛的社区带来利益。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.14409", "html_url": "https://arxiv.org/abs/2502.14409", "title": "长上下文查询导向摘要中的非结构化证据归因", "title_en": "Unstructured Evidence Attribution for Long Context Query Focused Summarization", "authors": "Dustin Wright,Zain Muhammad Mujahid,Lu Wang,Isabelle Augenstein,David Jurgens", "background": "大型语言模型（LLMs）能够根据用户查询从长文本中自动生成连贯的摘要，并且提取和引用证据片段有助于提高这些摘要的信任度。此前的研究主要集中在固定粒度（如句子、段落、文档等）的证据引用，但本研究提出从任意长度的非结构化片段提取证据，以获得比固定粒度情况下更相关、一致的证据。现有的系统在复制和恰当引用非结构化证据时存在问题，通常导致证据在网络中丢失。为此，本文创建了一个名为SUnsET的合成数据集，该数据集通过一个新型管道生成，可作为非结构化证据摘要的训练监督。研究表明，经过SUnsET适配的LLMs在生成摘要时能提供更相关、更符合事实的证据，并能从更多样化的上下文位置提取证据，生成的相关和一致的摘要优于未经过微调和固定粒度证据的基线模型。", "innovation": "研究提出了从任意长度的非结构化片段提取证据的方法，克服了固定粒度证据引用的问题。此外，提出了一种新的数据集SUnsET，用于训练非结构化证据摘要，实验证明该方法的有效性，使LLMs在生成摘要时能够更好地引用相关证据，提高摘要的准确性与一致性。", "conclusion": "研究展示了SUnsET数据集和新型非结构化证据提取方法对于提高LLMs生成摘要时引用证据的准确性和一致性的有效作用。通过这项工作，LLMs能够提供更高质量的摘要，从更广泛的上下文中提取更加准确、相关和一致的证据，并且已经开源了SUnsET数据集和生成代码。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.04953", "html_url": "https://arxiv.org/abs/2504.04953", "title": "M-Prometheus：一套开放多语言LLM评估者", "title_en": "M-Prometheus: A Suite of Open Multilingual LLM Judges", "authors": "José Pombal,Dongkeun Yoon,Patrick Fernandes,Ian Wu,Seungone Kim,Ricardo Rei,Graham Neubig,André F. T. Martins", "background": "随着语言模型在自动评估长文本（LLM-as-a-judge）中的应用日益普遍，大多数的LLM评估器仍然仅针对英文优化，一个多语言评估能力增强策略在当前文献中鲜有探讨，这导致了非英语语言的自动评估质量不一，阻碍了具有更好多语言能力模型的发展。", "innovation": "本文介绍了一套名为M-Prometheus的开放权重多语言LLM评估器，从3B到14B参数范围，可以提供直接评估和成对比较反馈，显示出在超过20种语言的多语言奖励基准测试以及4种语言对的文学机器翻译评估中优于最先进的开放LLM评估器。M-Prometheus模型在生成输出解码时亦能显著提高所有3种测试语言的输出，强调它们在开发更好的多语言模型中的潜在应用价值。此外，通过详尽的消融实验，找出了获得有效多语言评估器的关键因素，包括主干模型的选择以及使用合成多语言反馈数据而非翻译数据进行训练。", "conclusion": "本文通过发布模型、训练数据集和代码，旨在改善非英语语言的自动评估质量，进一步推动多语言模型的发展。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.01001", "html_url": "https://arxiv.org/abs/2504.01001", "title": "零样本基准测试：一种语言模型灵活且可扩展的自动评估框架", "title_en": "Zero-shot Benchmarking: A Framework for Flexible and Scalable Automatic Evaluation of Language Models", "authors": "José Pombal,Nuno M. Guerreiro,Ricardo Rei,André F. T. Martins", "background": "随着语言模型性能提升，它们能够执行更复杂的跨模态任务，自动评估它们变得越来越具有挑战性。开发强大且健壮的任务特定自动评估指标越来越困难，而依赖人类注释的测试集成本较高且难以扩展。", "innovation": "提出了零样本基准测试（ZSB）框架，利用语言模型进行合成测试数据生成和评估，适用于成本或实际收集数据困难的任务和语言。ZSB框架具有简洁性和灵活性，仅需为数据生成和评估创建提示；适用于需要付出较大成本才能收集真实数据的任务；模型无关，可通过提升模型不断创建更具有挑战性的基准。", "conclusion": "通过创建五个纯文本任务和一个多模态任务的基准，结果显示ZSB排名与人工排名具有强相关性，并且优于广泛采用的标准基准。通过消融实验发现，使用开放模型可以创建强基准；评委模型大小和数据集多样性是影响性能的关键因素。还发布了所有基准和实验代码以创建新基准。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.03710", "html_url": "https://arxiv.org/abs/2503.03710", "title": "改进基于双重目标优化的大语言模型安全对齐", "title_en": "Improving LLM Safety Alignment with Dual-Objective Optimization", "authors": "Xuandong Zhao,Will Cai,Tianneng Shi,David Huang,Licong Lin,Song Mei,Dawn Song", "background": "现有针对大语言模型（LLM）训练期间的安全对齐技术仍然容易受到越狱攻击。Direct Preference Optimization (DPO)作为广泛应用的安全对齐方法，在实验和理论层面都存在局限性，特别是在拒绝学习方面其损失函数低于最优。通过基于梯度的分析，研究识别了这些不足并提出改进方法，即将DPO目标拆分为两个方面：1）稳健的拒绝训练，鼓励即便产生部分不安全生成也要拒绝；2）有害知识的针对性遗忘。这种做法大幅提升了LLM在多种越狱攻击场景下的鲁棒性，包括填充攻击、后缀攻击以及多轮对话攻击，无论是分布内的还是分布外的场景。此外，研究还引入了一种通过基于奖励的标记级权重机制强化关键拒绝标记的方法，进一步提高了抵抗对抗利用的鲁棒性。研究还表明，抵抗越狱攻击的鲁棒性与训练过程中标记分布的变化及其拒绝和有害标记的内部表征相关，为未来大语言模型安全对齐的研究提供了有价值的指导方向。", "innovation": "提出了一种改进的安全对齐方法，将DPO目标分解为两大组成部分：1) 稳健的拒绝训练，即使产生部分不安全生成也要鼓励拒绝；2) 有针对性的学习遗忘有害知识。引入了基于奖励的标记级权重机制来强调关键拒绝标记，以此进一步提升模型的鲁棒性。此外，研究还发现，抵抗越狱攻击的鲁棒性与训练过程中的标记分布变化及内部表示有关。", "conclusion": "改进的双重目标优化方法显著提高了LLM对广泛越狱攻击的鲁棒性。基于奖励的标记级权重机制进一步提高了针对对抗利用的鲁棒性。这为未来大语言模型的安全对齐提供了新的研究方向。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2504.11331", "html_url": "https://arxiv.org/abs/2504.11331", "title": "Dependency Structure Augmented Contextual Scoping Framework for Multimodal Aspect-Based Sentiment Analysis", "title_en": "Dependency Structure Augmented Contextual Scoping Framework for Multimodal Aspect-Based Sentiment Analysis", "authors": "Hao Liu,Lijun He,Jiaxi Liang,Zhihan Ren,Haixia Bi,Fan Li", "background": "现有研究表明，多模态方面感知情感分析(MABSA)旨在从图像-文本对中提取精细信息，识别方面术语并确定其情感极性。然而，现有方法往往难以同时解决三个方面核心挑战：情感提示感知(SCP)、多模态信息不对齐(MIM)和语义噪声消除(SNE)。为了克服这些限制，该研究提出了DASCO（Dependency Structure Augmented Scoping Framework），该框架通过依赖解析树增强了方面级情感推理，包括多任务预训练策略、依赖树引导的上下文特定关注等。", "innovation": "DASCO采用依赖结构增强上下文聚焦框架，通过多任务预训练策略结合方面导向增强、图像-文本匹配和方面级情感敏感认知，提高模型对方面术语和情感提示的感知能力；同时，利用依赖树作为语法分支与语义分支，引导模型在特定目标范围内选择性关注关键上下文元素并有效过滤无关噪声，以解决SNE问题。通过在两个基准数据集上的全面实验，证明DASCO在MABSA中达到了最先进的性能，并在JMASA任务中取得了显著成果。", "conclusion": "DASCO在两个基准数据集上的广泛实验表明，它在MABSA中达到了最先进的性能，并在JMASA任务中取得了显著的F1分数和精度提升(+2.3% F1和+3.5%精度)，源代码已发布。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13444", "html_url": "https://arxiv.org/abs/2505.13444", "title": "ChartMuseum：测试大规模视觉语言模型的视觉推理能力", "title_en": "ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models", "authors": "Liyan Tang,Grace Kim,Xinyu Zhao,Thom Lake,Wenxuan Ding,Fangcong Yin,Prasann Singhal,Manya Wadhwa,Zeyu Leo Liu,Zayne Sprague,Ramya Namuduri,Bodun Hu,Juan Diego Rodriguez,Puyuan Peng,Greg Durrett", "background": "对于大型视觉语言模型(LVLMs)，图表理解是一个独特的挑战，因为这需要结合复杂的文本和视觉推理能力。然而，目前的LVLMs在这两种技能上存在显著不平衡，特别是在难以通过文本执行的视觉推理上表现不足。本研究通过使用一个仅通过视觉推理才能解决的合成数据集作为案例研究，展示了随着视觉复杂性的增加，模型性能显著下降，而人类的表现则保持稳健。", "innovation": "引入了ChartsMuseum，这是一个新的图表问答基准，包含1,162个由专家注释的问题，覆盖多种推理类型，来自184个真实世界的图表，专门设计用来评估复杂的视觉和文本推理。本基准展示了模型与人类在图表理解上的显著差距，有效地区别了模型的能力，尽管人类的准确率为93%，但表现最好的模型Gemini-2.5-Pro仅达到63.0%，而领先的开源LVLM Qwen2.5-VL-72B-Instruct仅达到38.5%。此外，对于主要依赖于视觉推理的问题，所有模型的性能从文本推理类问题中下降了35%-55%。", "conclusion": "我们的质化错误分析揭示了当前LVLMs在某些视觉推理类型上的困难。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.14604", "html_url": "https://arxiv.org/abs/2505.14604", "title": "通过自我刹车调校让大型推理模型摆脱过度思考", "title_en": "Let LRMs Break Free from Overthinking via Self-Braking Tuning", "authors": "Haoran Zhao,Yuchen Yan,Yongliang Shen,Haolei Xu,Wenqi Zhang,Kaitao Song,Jian Shao,Weiming Lu,Jun Xiao,Yueting Zhuang", "background": "大推理模型（LRMs），如OpenAI o1和DeepSeek-R1，通过生成更长的推理链条显著提升了推理能力，展现出在多种任务上的出色性能。然而，这一性能提升伴随着推理过程中的大量冗余，增加了计算开销并加剧了过度思考的问题。尽管已有许多方法试图解决过度思考问题，但它们往往依赖于外部干预。", "innovation": "本论文提出了一种名为Self-Braking Tuning（SBT）的新框架，从允许模型自我调节推理过程的角度来应对过度思考问题，从而消除了对外部控制机制的依赖。该论文构建了一套基于标准答案的过度思考识别度量，并设计了一套系统的方法来检测冗余推理，准确识别推理轨迹中的多余步骤，并生成训练信号以学习自我调节行为。在此基础上，开发了一种适应推理长度的数据构建策略，并引入了一种创新的刹车提示机制，使模型能够自然地学会在适当的时候终止推理。", "conclusion": "在数学基准测试（AIME，AMC，MATH500，GSM8K）中进行的实验表明，与不受约束的模型相比，该方法可以将令牌消耗减少多达60%，同时保持相似的准确性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08410", "html_url": "https://arxiv.org/abs/2506.08410", "title": "大型语言模型具备内在的元认知能力，但需要一个好镜头", "title_en": "Large Language Models Have Intrinsic Meta-Cognition, but Need a Good Lens", "authors": "Ziyang Ma,Qingyue Yuan,Zhenglin Wang,Deyu Zhou", "background": "先前的研究主要集中在大型语言模型（LLMs）的认知错误检测能力上，通常通过分析推理链中的错误来进行。然而，很少有研究考察LLMs的元认知能力（如他们对自己步骤错误的自我意识），这对于提高其可靠性至关重要。尽管有研究表明，某些度量标准（如困惑度）可以反映答案的正确性，这些度量标准可以作为元认知的视角，但它们缺乏步骤级的分析和适应。", "innovation": "本文提出了一种名为AutoMeco的自动化元认知评价框架，用于评估现有的度量标准；并提出了一种无训练的马尔可夫内在奖励调整策略MIRA，以提升当前的元认知度量。实验结果表明，AutoMeco与Best-of-N验证相比具有合理性。此外，证明了MIRA可以更好地评估LLMs的元认知能力。", "conclusion": "通过比较AutoMeco与Best-of-N验证的方法，并应用MIRA策略，可以更合理地评估LLMs的元认知能力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.24388", "html_url": "https://arxiv.org/abs/2505.24388", "title": "ClueAnchor：基于关键线索的知识推理探索与优化以增强检索生成", "title_en": "ClueAnchor: Clue-Anchored Knowledge Reasoning Exploration and Optimization for Retrieval-Augmented Generation", "authors": "Hao Chen,Yukun Yan,Sen Mei,Wanxiang Che,Zhenghao Liu,Qi Shi,Xinze Li,Yuchun Fan,Pengcheng Huang,Qiushi Xiong,Zhiyuan Liu,Maosong Sun", "background": "检索增强生成（RAG）通过结合外部知识来增强大型语言模型（LLMs），以提高事实性。然而，现有的RAG系统通常未能充分利用检索到的文档，未能提取和整合支持忠实和可解释推理的关键线索，特别是在相关证据是隐含、分散或被噪音干扰的情况下，表现尤为不佳。", "innovation": "本文提出了一种新颖的框架ClueAnchor，旨在通过基于关键线索的推理探索与优化增强RAG。ClueAnchor从检索内容中提取关键线索，并基于不同的知识配置生成多个推理路径，通过基于奖励的偏好优化选择最适合给定语境的推理路径。实验结果表明，ClueAnchor在推理的完整性和鲁棒性方面明显优于先前的RAG基线。进一步分析证明，它对噪音或部分相关检索内容具有较强的鲁棒性，并能在推理时识别支持证据，即使在推理过程中缺乏显式的线索监督。", "conclusion": "实验结果显示，ClueAnchor显著优于先前的RAG基线，在推理的完整性和鲁棒性方面表现出色。进一步分析表明，即使在检索到的内容包含噪音或部分相关性时，ClueAnchor也能表现出强烈的鲁棒性，并且即使在推理过程中未显式监督线索的情况下也能识别支持证据。所有代码均可在 [此链接](this https URL) 获取。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.04721", "html_url": "https://arxiv.org/abs/2506.04721", "title": "SPARTA ALIGNMENT: 通过战斗集体对齐多个语言模型", "title_en": "SPARTA ALIGNMENT: Collectively Aligning Multiple Language Models through Combat", "authors": "Yuru Jiang,Wenxuan Ding,Shangbin Feng,Greg Durrett,Yulia Tsvetkov", "background": "现有的单一语言模型可能在生成多样性方面存在不足，并且在评估过程中可能存在偏见。因此，提出了一种新的对齐算法来改进多个语言模型的表现，使其能够更好地生成多样且无偏见的回答。", "innovation": "SPARTA ALIGNMENT算法通过竞争和评估过程中的相互评判来实现多个语言模型的集体对齐。每一轮，选择一条指令和两个模型参与对战，其他模型作为评委对两个模型的回答进行评分，通过一个改进过的Elo排名信誉系统来聚合评分，胜者和败者会在评价其他模型时获得或失去权重。最终，经过每一轮的对战，评分结果形成了偏好对，指导模型们学习新的偏好，实现模型间的相互学习和集体进化。SPARTA ALIGNMENT算法在多个任务和数据集上取得了显著的改进效果，尤其是在未见过的任务上表现更佳，能够利用模型间的专家多样性产生更合理、直接和信息丰富的输出。", "conclusion": "SPARTA ALIGNMENT算法在多个任务和数据集上显著优于初始模型及多种自我对齐基准，平均改进率达到7.0%，特别是在未见过的任务上表现出色，能够利用模型间的专业多样性产生更合理、直接和信息丰富的输出。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.09391", "html_url": "https://arxiv.org/abs/2506.09391", "title": "在自由生成中比较人类和大语言模型的礼貌策略", "title_en": "Comparing human and LLM politeness strategies in free production", "authors": "Haoran Zhao,Robert D.Hawkins", "background": "言语礼貌对大语言模型构成了根本性的对接挑战。人类通过丰富的语言策略来平衡信息和社交目标——从建立关系的正面策略（恭维，表示兴趣）到减少强加的负面策略（委婉，间接）。本文通过在受控和开放式生产任务中比较人类和大语言模型的反应来研究大语言模型是否也使用一种基于上下文的丰富策略库。", "innovation": "研究发现，更大的模型（≥70B参数）成功复制了计算语用学文献中的关键偏好，且在开放式情景中，人类评估者意外地更偏好大语言模型生成的回答。但进一步的语义分析揭示，模型在正面情境中也过度依赖负面的礼貌策略，可能导致误解。这表明现代大语言模型在礼貌策略处理上取得了令人印象深刻的进展，但也凸显了人工智能系统语用对接的重要问题。", "conclusion": "尽管现代大语言模型在礼貌策略的理解和使用上表现出色，但细微的差异仍然提出了一些关于人工智能系统语用对接的重要问题。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15095", "html_url": "https://arxiv.org/abs/2505.15095", "title": "Nek Minit: 调用pragmatic metacognitive prompting来为澳大利亚和印度英语的可解释讽刺检测提供支持", "title_en": "Nek Minit: Harnessing Pragmatic Metacognitive Prompting for Explainable Sarcasm Detection of Australian and Indian English", "authors": "Ishmanbir Singh,Dipankar Srirag,Aditya Joshi", "background": "讽刺文本的情感分析是一个挑战，因为陈述的情感与隐含的情感之间存在不一致。这种不一致的挑战在涉及特定国家或地理区域的隐含意图时变得更加复杂。Pragmatic metacognitive prompting (PMP) 是一种认知启发技术，用于进行语用推理。鉴于此背景，本文旨在使用PMP技术为澳大利亚和印度英语中的讽刺检测提供可解释的解释，同时与标准英语语料库进行基准数据集对比分析。", "innovation": "本文引入了一种利用PMP生成多种英语变体讽刺解释的方法。该方法在两种开源大规模语言模型（GEMMA和LLAMA）上进行了评估，相较于四种替代提示策略，PMP在所有任务和数据集上取得了统计意义上的性能改进。此外，研究还发现替代技术如行动性提示通过启用外部知识检索来缓解上下文相关的失败。", "conclusion": "本文的主要贡献在于使用PMP为不同种类的英语生成讽刺解释。实验结果表明，利用PMP的技术在所有任务和数据集上都显示出统计显著性性能提升，并且通过PMP产生的解释也对于解释性诊断较为有效。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.07001", "html_url": "https://arxiv.org/abs/2506.07001", "title": "对抗重述：一种使人化AI生成文本的通用攻击", "title_en": "Adversarial Paraphrasing: A Universal Attack for Humanizing AI-Generated Text", "authors": "Yize Cheng,Vinu Sankar Sadasivan,Mehrdad Saberi,Shoumik Saha,Soheil Feizi", "background": "由于大型语言模型（LLMs）的能力不断增强，它们在AI生成的剽窃和社交工程中的滥用引起了关注。尽管已经提出了各种AI生成文本检测器来缓解这些风险，但许多检测器仍容易受到简单的规避技术（如改写文本）的攻击。然而，最近的研究表明，某些检测器对这种基本攻击表现出更强的鲁棒性。本文探讨了如何通过一种无需训练的攻击框架——对抗重述，来提高AI生成文本的检测规避效果。", "innovation": "本文提出了一种无需训练的攻击框架——对抗重述，该框架利用现成的指令跟随LLM在AI文本检测器的指导下，对AI生成的内容进行改写，产生专门为绕过检测量身定制的对抗样本。该方法不仅广泛有效，而且高度适用于多种检测系统，可以显著降低检测率，同时对文本质量的影响较小。", "conclusion": "本文的研究表明，在面对日益复杂化的规避技术时，需要更加强大和稳健的检测策略。对抗重述攻击在多个领域检测器中获得了广泛的应用，并且即使在稍微降低文本质量的情况下，也能够显著减少检测率。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13464", "html_url": "https://arxiv.org/abs/2506.13464", "title": "揭开语言模型的学习之心：一种认知框架及实证研究", "title_en": "Unveiling the Learning Mind of Language Models: A Cognitive Framework and Empirical Study", "authors": "Zhengyu Hu,Jianxun Lian,Zheyuan Xiao,Seraphina Zhang,Tianfu Wang,Nicholas Jing Yuan,Xing Xie,Hui Xiong", "background": "大型语言模型（LLMs）在数学、编程和推理等任务上表现出色，但它们的学习能力还有待探索。学习能力对于适应动态环境和获取新知识至关重要。", "innovation": "提出了一个灵感来自认知心理学和教育领域的框架，将一般学习能力分解为三个互补的维度：从指导员学习（通过明确指导获取知识）、概念学习（内部化抽象结构并在新情境中泛化）和经验学习（通过累积探索和反馈进行调整）。通过三项学习维度的全面实证研究，得出了若干有益的发现，如交互提升学习效果、概念理解随规模增长而增强、LLMs为少样本学习者但不是多样本学习者。", "conclusion": "基于该框架和实证结果，引入了一个基准测试，以统一且现实的方式评估LLMs在三个认知学习维度上的通用学习能力，提供了诊断洞察并支持了更适应人类样式的模型的评估和开发。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.11094", "html_url": "https://arxiv.org/abs/2506.11094", "title": "正义的天平：LLM安全性评估的综合性调研", "title_en": "The Scales of Justitia: A Comprehensive Survey on Safety Evaluation of LLMs", "authors": "Songyang Liu,Chaozhuo Li,Jiameng Qiu,Xi Zhang,Feiran Huang,Litian Zhang,Yiming Hei,Philip S. Yu", "background": "随着人工智能的快速发展，大规模语言模型（LLMs）在自然语言处理（NLP）领域展现了显著的能力，包括内容生成、人机交互、机器翻译和代码生成。然而，它们的广泛应用也引发了重大安全问题。LLMs生成的内容可能表现出不当行为，如危害性、偏见或虚假信息，特别是在对抗性情境下，这些安全问题引起了学术界和产业界的广泛关注。尽管已有许多研究尝试评估这些风险，但关于LLM安全性评估的综合性和系统性调查仍然缺乏。本文旨在通过提出结构化的LLM安全性评估概述来填补这一空白，以解决安全性评估的背景问题，解释其与普通LLM评估的区别，并强调此类评估的重要性，同时分类并总结现有安全性评估任务，评估使用的指标、数据集与基准，以及现有主流评估方法，从而识别安全性评估中的挑战，并提出进一步推进该领域发展的研究方向，强调将安全性评估放在首位的必要性，确保LLMs在实际应用中的可靠性和责任感。", "innovation": "本文提出了一种四维分类框架，包括为什么评估、评估什么、在哪里评估以及如何评估，这是对该领域的一个全新的系统性梳理和总结，为今后LLM安全性评估的研究提供了一种新的视角和方法。", "conclusion": "本文指出了LLM安全性评估中的若干挑战，并提出了未来研究方向，强调了优先进行安全性评估的重要性，以确保LLM在实际应用中的可靠性和责任感。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.02175", "html_url": "https://arxiv.org/abs/2506.02175", "title": "AI辩论有助于争议性声明的评估", "title_en": "AI Debate Aids Assessment of Controversial Claims", "authors": "Salman Rahman,Sheriff Issaka,Ashima Suvarna,Genglin Liu,James Shiffer,Jaeyoung Lee,Md Rizwan Parvez,Hamid Palangi,Shi Feng,Nanyun Peng,Yejin Choi,Julian Michael,Liwei Jiang,Saadia Gabriel", "background": "随着人工智能变得越来越强大，它将越来越多地影响我们对世界的理解。但在这样做的同时，也存在放大不实信息和加深社会裂痕的风险，尤其是在那些事实的准确性直接影响福祉的重要话题上。为了应对这一风险，研究者提出了一种称为Scalable Oversight的方法，旨在确保即使AI的能力超越了评估者的能力，AI系统也保持真实。然而，当人类作为评估者时，他们的信念和偏见可能会影响他们的判断。为了缓解这个问题，研究者通过让两个AI系统辩论有关冠状病毒和气候变化等争议性问题的相关事实主张，来引导有偏见的评判者趋向真理。研究发现，人类评判者的决策准确性在辩论的情况下确实得到了改善，而且AI评判者，特别是那些具有人类特征的人工智能评判者，能够达到甚至超过人类评判者的准确率，显示出它们在监督前沿AI模型方面的潜力。", "innovation": "这项研究提出了AI辩论作为一种方法，通过让两个AI系统围绕有关争议性问题的事实主张进行辩论来引导具有偏见的评判者走向事实。研究结果显示，这种辩论可以帮助有偏见的人类评判者提高决策准确性和信心校准，尤其是对于那些最初持有错误观点的人类评判者来说效果显著。此外，结果显示，具有人类特征的AI评判者在评估方面表现出色，甚至超过了未有人类特征的AI评判者和人类评判者的准确率，这为AI监督前沿AI模型提供了新的可能路径。", "conclusion": "该研究证实了AI辩论在帮助评判者纠正偏见、提升决策准确性和信心校准方面的作用，特别是在争议性问题上。此外，具有人类特征的AI评判者在评估准确性方面表现出色，可能成为未来AI监督的一种有潜力的方法。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.13229", "html_url": "https://arxiv.org/abs/2506.13229", "title": "IGD：通过信息增益建模LLMs中token决策性以实现个性化推荐", "title_en": "IGD: Token Decisiveness Modeling via Information Gain in LLMs for Personalized Recommendation", "authors": "Zijie Lin,Yang Zhang,Xiaoyan Zhao,Fengbin Zhu,Fuli Feng,Tat-Seng Chua", "background": "大语言模型（LLMs）通过将项目预测视为逐个令牌语言生成任务，展现出了强大的推荐潜力。然而，现有的方法在优化和解码过程中都等同处理所有项目的令牌，仅仅追求最大似然度。这种方法忽视了在决策中令牌级别的差异，许多令牌对项目间的区分贡献较小，但却在优化或解码过程中占据了主导地位。", "innovation": "本文提出了一种新的视角，将项目生成建模为决策过程，通过每个令牌提供的信息增益（IG）来量化令牌的决策性。实验分析揭示了大多数令牌的信息增益较低，但却常常对应高logits，不均衡地影响训练损失和解码过程，从而可能损害模型性能。基于这些发现，文章引入了一种基于信息增益的决策性感知令牌处理策略（IGD），将令牌的决策性整合到调优和解码过程中。具体地，IGD在调优过程中降低了低信息增益令牌的权重，并通过重新平衡解码来强调高信息增益的令牌，从而超越了纯粹的似然度最大化。", "conclusion": "IGD策略在四个基准数据集上的广泛实验中，表现出了显著提高推荐准确性，并在广泛使用的排名指标中相比强基线实现了显著提升。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.14681", "html_url": "https://arxiv.org/abs/2506.14681", "title": "大规模监督微调实验揭示了数据、层和训练因素如何塑造大语言模型对齐质量", "title_en": "Massive Supervised Fine-tuning Experiments Reveal How Data, Layer, and Training Factors Shape LLM Alignment Quality", "authors": "Yuto Harada,Yusuke Yamauchi,Yusuke Oda,Yohei Oseki,Yusuke Miyao,Yu Takagi", "background": "监督微调（SFT）是让大规模语言模型（LLMs）与人类指示和价值观对齐的关键步骤，但对SFT的理解仍然有限。本研究通过在多种数据集上训练一系列基础模型，涵盖了代码生成、数学推理和通用任务，产生了超过1,000个在受控条件下训练的SFT模型，以探索关键因素。", "innovation": "研究识别了关键的数据集特性，并研究了SFT引入的逐层修改。研究发现，一些训练任务协同效应在所有模型中持续存在，而另一些则有很大差异，强调了模型特定策略的重要性。此外，研究证明困惑度（perplexity）是预测SFT效果的可靠指标，通常超过训练数据和基准表面相似度，同时深层权重变化与性能改进相关性最强。", "conclusion": "研究发布了超过1,000个SFT模型和基准结果，旨在加速进一步研究。所有资源可以在此处访问：this https URL"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.13328", "html_url": "https://arxiv.org/abs/2507.13328", "title": "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It", "title_en": "Vision-and-Language Training Helps Deploy Taxonomic Knowledge but Does Not Fundamentally Alter It", "authors": "Yulu Qin,Dheeraj Varghese,Adam Dahlgren Lindström,Lucia Donatelli,Kanishka Misra,Najoung Kim", "background": "大多数关于视觉-语言（VL）训练的研究结果都显示出了行为和代表性上的不一致或边际差异。现有的研究主要集中在VL训练对语言模型的影响上，但它们并没有在词汇概念知识，特别是其分类组织方面显示出显著效果。", "innovation": "本文假设VL训练可能对词汇-概念知识的分类组织产生显著影响。通过对比仅文本型语言模型和VL训练型语言模型，作者发现VL模型在需要概念分类理解的问题回答任务上通常优于仅文本型模型。进一步的行为和代表性的分析表明，尽管语言模型和VL模型在分类知识本身上没有显著差异，但它们在处理包含分类关系和非分类关系概念的问题时的表示方式存在差异。", "conclusion": "这表明，通过额外的VL训练，分类知识本身不会有显著变化，但VL训练能够改善知识在特定任务中的应用，即使任务的呈现仅为语言形式。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.03704", "html_url": "https://arxiv.org/abs/2507.03704", "title": "在推理模型中控制思考速度", "title_en": "Controlling Thinking Speed in Reasoning Models", "authors": "Zhengkai Lin,Zhihang Fu,Ze Chen,Chao Chen,Liang Xie,Wenxiao Wang,Deng Cai,Zheng Wang,Jieping Ye", "background": "人类认知被认为有两种模式：快而直觉的系统1思维和慢而经过深思熟虑的系统2思维。当前的大规模推理模型（LRMs）在处理系统2思维方面表现出色，但它们无法执行快速思维，导致高计算开销和延迟。本文通过动态调整推理的思考速度来实现LRMs近似实现人类智能，优化准确性和效率之间的权衡。该方法解决了两个关键问题：如何在LRMs中控制思考速度，以及何时调整以获得最佳性能。", "innovation": "1. 识别引导慢速和快速思维过渡的控制向量，并通过此向量实现了第一个基于表示编辑的测试时缩放效果，优于现有的基于提示的缩放方法。2. 应用实时难度估计来标记不同复杂度的推理段落，提出了一种新的推理策略，允许快速处理简单步骤并深入分析复杂推理。没有额外的训练或成本，插件模块在领先的大规模推理模型和高级推理基准上实现了平均提高1.3%的准确率，同时减少了8.6%的标记使用量。", "conclusion": "本文通过动态调整推理速度实现了LRMs近似模拟人类智能，提供了准确性和效率之间的优化策略。算法基于vLLM实现，有助于更广泛的应用并激发未来研究。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.16271", "html_url": "https://arxiv.org/abs/2507.16271", "title": "突破孤立点：作为深度知识提取的结构化表格构建基准", "title_en": "Beyond Isolated Dots: Benchmarking Structured Table Construction as Deep Knowledge Extraction", "authors": "Tianyun Zhong,Guozhao Mo,Yanjiang Liu,Yihan Chen,Lingdi Kong,Xuanang Chen,Yaojie Lu,Hongyu Lin,Shiwei Ye,Xianpei Han,Ben He,Le Sun", "background": "随着大规模语言模型（LLMs）的发展，人们期望LLMs能够有效地从复杂的真实世界文档（如论文、报告）中提取明确信息。然而，大多数LLMs生成的都是混沌、无组织、不可追踪的段落式回答。为解决这一问题，引入了规范和重组抽取基准（AOE），这是一个新的双语基准，包含了不同长度的数据和文档，旨在系统性地评估LLMs在理解碎片化文档和将孤立信息重新构建为一个组织化表格方面的性能。与依赖固定结构和狭窄任务领域的普通文本到表格任务不同，AOE 包含了跨越三个不同领域、多达11个精心设计的任务，模型需要根据不同的输入查询生成特定于上下文的结构。", "innovation": "引入了规范和重组抽取基准（AOE），该基准通过提供不同长度的数据和文档，旨在系统性地评估LLMs在处理碎片化文档和重组信息方面的能力。AOE 通过11个精心设计的任务，要求模型根据特定的输入查询生成上下文相关的结构，其独特之处在于它不仅是一项标准的文本到表格任务，而是结合了深度知识提取的需求。", "conclusion": "实验结果表明，即便是最先进的模型也在这一挑战面前表现困难。基准已经在提供的原文地址可以访问。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.11607", "html_url": "https://arxiv.org/abs/2508.11607", "title": "TinyTim：一种用于发散生成的语言模型家族", "title_en": "TinyTim: A Family of Language Models for Divergent Generation", "authors": "Christopher J. Agostino", "background": "在寻找人工通用智能的过程中，模型开发和训练主要集中在大量已知问题及其公认的解决方案的数据集上。这一过程必然会产生收敛系统，这类系统本质上无法进行真正创造性的概念重构。", "innovation": "受到人类能够做出创造性飞跃的发散认知过程的启发，本文介绍了一种名为TinyTim的语言模型家族，用于在更广泛的系统中提供发散生成。这些模型通过将詹姆斯·乔伊斯的《布里根尼斯夜影》中的反简约文本进行微调而创建。定量分析表明，两者（未监督微调的模型TinyTim-V1和指令微调的新变体TinyTim-V2）都有卓越的词汇创新能力；基础的V1模型的词汇丰富度的Yule's K分数比收敛基线高出二十倍以上。这种特性是模型家族的稳定属性，V2模型保持着统计上的差异，避免事实上的收敛，牺牲基准性能以保留其核心生成风格。", "conclusion": "本研究建立了一种方法，用于设计专门的发散模型，当与收敛系统结合使用时，可以重新定义问题并迫使超越单纯统计优化所达到的突破。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.19756", "html_url": "https://arxiv.org/abs/2507.19756", "title": "Are You There God? 使用LM进行轻量级-Christian小说叙述注释", "title_en": "Are You There God? Lightweight Narrative Annotation of Christian Fiction with LMs", "authors": "Rebecca M. M. Hicke,Brian W. Haggard,Mia Ferrante,Rayhan Khanna,David Mimno", "background": "美国福音主义不仅在其更广泛研究的文化运动中有深入的研究，还有一种较为发展但对外界不太明显的文学方面。然而，福音主义小说这一文学领域尚未得到充分研究，目前的学术研究主要集中在左后方系列书籍上。本文利用计算工具对福音主义小说这一文学流派的广泛主题进行了总体概述，并深入探讨了作者如何描绘神迹。为了这一目的，作者首先开发了一个识别“神迹”的代码本，然后与轻量级语言模型结合使用，该模型在辅助大型模型的帮助下得以适应。轻量级语言模型在匹配人类注释方面能力很强，即使在任务复杂微妙时亦然。研究结果表明，《左后方》系列书籍和更广泛意义上的福音主义小说中所描绘的神迹存在显著且有意义的差异。", "innovation": "本文创新性地使用轻量级语言模型进行福音主义小说的注释，通过与大型模型的辅助，使得轻量级模型能够匹配人类的注释，即使在复杂的任务中也能实现。这是对福音主义小说叙述中的神迹描绘进行定量分析的一种新兴方法。", "conclusion": "研究发现，福音主义小说与《左后方》系列书籍中所描绘的神迹存在明显的差异。这些发现对于理解福音主义文学中的神迹描绘有许多启示意义，同时也展示了计算工具在文学研究中的应用潜力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.08604", "html_url": "https://arxiv.org/abs/2510.08604", "title": "LatentBreak: 通过潜在空间反馈攻破大型语言模型", "title_en": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback", "authors": "Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio", "background": " Jailbreaks 是针对大型语言模型内置安全机制的对抗性攻击。现有的自动 jailbreak 攻击通常通过优化对抗性后缀或适应长提示模板来迫使模型生成受限或有害的响应，但这些攻击可以通过基于困惑度的输入提示过滤器来检测。因此，作者提出了一种名为 LatentBreak 的白盒 jailbreak 攻击，它生成具有较低困惑度且自然的对抗性提示，以逃避基于困惑度的防御。", "innovation": " 提出了 LatentBreak，一种通过在潜在空间中反馈选择语义等价词来生成低困惑度的对抗性提示的白盒 jailbreak 攻击。这种方法能够在不添加高困惑度的对抗性后缀或长模板的情况下，保持提示的初始意图，同时使得对抗性提示在潜在空间中与无辜请求的距离最小化。", "conclusion": " 通过大量评估，LatentBreak 生成了更短、低困惑度的提示，相对于基于困惑度的过滤器，该方法在多个安全对齐模型上优于其他竞争性的 jailbreak 算法。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18480", "html_url": "https://arxiv.org/abs/2510.18480", "title": "扩散语言模型的效率如何？关于效率评估实践的关键审视", "title_en": "How Efficient Are Diffusion Language Models? A Critical Examination of Efficiency Evaluation Practices", "authors": "Han Peng,Peiyu Liu,Zican Dong,Daixuan Cheng,Junyi Li,Yiru Tang,Shuo Wang,Wayne Xin Zhao", "background": "扩散语言模型(DLMs)作为一种与传统的自回归(AR)范式相竞争的有希望的替代方案，提供了可并行化的解码过程，从而可能带来更高的效率。然而，实际情况中，当前开源DLMs在速度上往往不如AR模型，这限制了它们在实际中的应用范围。", "innovation": "本工作对DLM的效率进行了系统性研究，识别了以前效率评估方法中的关键问题。通过经验基准测试和基于屋顶线的理论分析，表明AR模型通常具有一般更高的吞吐量，而DLMs则持续落后。本研究还调查了加速策略，发现缓存双层和并行解码等技术主要在小批量大小时提供增益，其益处随着扩展而逐渐减弱。", "conclusion": "本研究强调了需要有更稳健的评估方法和改进的加速策略，以促进DLMs的研究进展。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.11695", "html_url": "https://arxiv.org/abs/2510.11695", "title": "当代理交易：LLM代理的多市场交易基准实验", "title_en": "When Agents Trade: Live Multi-Market Trading Benchmark for LLM Agents", "authors": "Lingfei Qian,Xueqing Peng,Yan Wang,Vincent Jim Zhang,Huan He,Hanley Smith,Yi Han,Yueru He,Haohang Li,Yupeng Cao,Yangyang Yu,Alejandro Lopez-Lira,Peng Lu,Jian-Yun Nie,Guojun Xiong,Jimin Huang,Sophia Ananiadou", "background": "尽管基于大型语言模型（LLM）的代理正在金融市场中越来越普及，但目前尚不清楚它们在实际交易市场中能否合理推断和适应。大多数相关研究测试的是模型而非代理，并且只涵盖了有限的市场和时间段，依赖未经验证的数据。", "innovation": "本文介绍了一个名为Agent Market Arena (AMA)的基准测试平台，它首次实现了针对多个市场的终身实时评估。AMA整合了经过验证的交易数据、专家检查的新闻以及多样的代理架构，在统一的交易框架内进行公平和持续的比较。它实施了四种代理，包括单智能体基线InvestorAgent、具有不同风险风格的TradeAgent和HedgeFundAgent，以及基于记忆推理的DeepFundAgent，并对这些代理进行了在GPT-4o，GPT-4.1，Claude-3.5-haiku，Claude-sonnet-4和Gemini-2.0-flash等多个模型上的测试。", "conclusion": "实验证明，代理框架表现出截然不同的行为模式，从激进的风险承担到保守的决策制定，而模型底座对结果变异性的影响较小。AMA因此为金融推理和交易智能在基于LLM的代理中的严格、可重现和持续演进的评估奠定了基础。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.21319", "html_url": "https://arxiv.org/abs/2509.21319", "title": "RLBFF: 二进制灵活反馈以连接人类反馈与可验证奖励", "title_en": "RLBFF: Binary Flexible Feedback to bridge between Human Feedback & Verifiable Rewards", "authors": "Zhilin Wang,Jiaqi Zeng,Olivier Delalleau,Ellie Evans,Daniel Egert,Hoo-Chang Shin,Felipe Soares,Yi Dong,Oleksii Kuchaiev", "background": "在大型语言模型（LLM）的后训练阶段，主要的强化学习（RL）方法包括基于人类反馈的强化学习（RLHF）和基于可验证奖励的强化学习（RLVR）。RLHF 依赖于人类判断，缺乏明确的标准，导致解释性和奖励欺骗问题；而 RLVR 的范围受限于只关注基于正确性的验证器。该研究旨在提出一种新的方法，称为基于二进制灵活反馈的强化学习（RLBFF），该方法结合了人类偏好和规则验证的精确性，超越了传统方法，能够捕捉到响应质量的复杂方面。", "innovation": "研究提出了一种新的强化学习方法——基于二进制灵活反馈的强化学习（RLBFF），该方法能够将人类驱动的偏好与基于规则的验证相结合。RLBFF 从自然语言反馈中提取二进制回答原则（例如信息准确性：是，或代码可读性：否），并将这些原则用于作为推演任务的奖励模型培训（响应是否满足任意原则）。实验结果显示，使用 RLBFF 训练的奖励模型在数据量匹配的情况下可以超越 Bradley-Terry 模型，并且在 RM-Bench（86.2%）和 JudgeBench（81.4%，截至2025年9月24日排名第一）上表现出色。此外，用户还可以在推理时指定感兴趣的原理，以定制奖励模型的关注点，这是 Bradley-Terry 模型所不具备的功能。", "conclusion": "使用 RLBFF 和训练好的奖励模型，我们展示了如何完全开源地调整 Qwen3-32B，以匹配或超越 o3-mini 和 DeepSeek R1 在 MT-Bench、WildBench 和 Arena Hard v2 等通用对齐基准上的性能（成本仅为这些模型的5%左右）。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大型语言模型中的认知多样性和知识塌缩", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein", "background": "大型语言模型倾向于生成在词汇、语义和风格上高度一致的文本。这种一致性带来了知识塌缩的风险，即随着时间的推移，通过这些一致性较高的模型传递的可访问信息范围逐渐缩小。尽管已有研究关注认知一致性，但这些研究主要集中在封闭式选择题设置或模糊的语义特征上，没有关注时间跨度和文化背景下的趋势变化。因此，需要一种新的方法来衡量认知多样性，即LLM输出中现实世界主张的变异性，以评估它们的知识塌缩现象。本文通过对27个LLM、155个话题（覆盖12个国家）和来自真实用户对话的200种提示变异的广泛实证研究，探讨了这一问题。研究表明，尽管较新的模型生成的主张更为多样，但几乎所有的模型认知多样性都不如基本的网络搜索。此外，模型大小对认知多样性有负面影响，而检索增强生成（RAG）有正面影响，但不同文化背景下RAG的改进程度不同。研究还发现，与传统知识来源（维基百科）相比，国家特定的主张更多地反映了英语而非当地语言，突显了认知代表性的差距。", "innovation": "本文引入了一种新的方法来衡量认知多样性，即测量LLM输出中现实世界主张的变异性，填补了现有研究在时间跨度和文化背景下的空缺。通过广泛的实际案例研究，探索了模型大小和RAG对认知多样性的影响，并揭示了当前LLM提供的知识在文化和语言上的缺失。", "conclusion": "新的方法显示，尽管较新的LLM生成更多样化的主张，但几乎所有的模型认知多样性都不如基本的网络搜索。模型大小影响认知多样性，而RAG则有正面影响，但影响程度在不同文化背景下有所不同。与维基百科相比，国家特定的主张更多地反映了英语而非当地语言，表明了认知代表性的缺失。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.18915", "html_url": "https://arxiv.org/abs/2510.18915", "title": "UNO-Bench：探索单模态与全模态在全模态模型中的组合法则的统一基准", "title_en": "UNO-Bench: A Unified Benchmark for Exploring the Compositional Law Between Uni-modal and Omni-modal in Omni Models", "authors": "Chen Chen,ZeYang Hu,Fengjiao Chen,Liya Ma,Jiaxing Liu,Xiaoyu Li,Ziwen Wang,Xuezhi Cao,Xunliang Cai", "background": "多模态大型语言模型正在从单一模态理解向统一视觉、音频和语言模态发展，统称为全模态模型。然而，单模态与全模态之间的关联尚不清楚，需要进行全面评估以推动全模态模型的智能化进化。", "innovation": "本文提出了一种新型、高质量和统一的全模态模型基准——UNO-Bench。该基准设计用于在统一的能力分类下有效评估单模态和全模态能力，涵盖了44种任务类型和5种模态组合，并包含1250个人工策划的全模态样本和2480个增强的单模态样本。此外，本文还提出了创新的多步骤开放性问题格式来评估复杂的推理能力，并引入了一种通用评分模型，支持6种问题类型的自动化评估，准确率为95%。实验结果展示了全模态和单模态之间组合法则的构成，发现全模态能力在弱模型中表现为瓶颈影响，在强模型中表现出协同促进效应。", "conclusion": "提出的UNO-Bench基准能够有效地评估单模态和全模态的能力，并通过多步开放式问题格式支持复杂推理的评估，并且通用评分模型支持自动评估，展示了全模态能力在模型性能上的关键作用。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.20059", "html_url": "https://arxiv.org/abs/2510.20059", "title": "在小规模波斯医疗语言模型中增强推理能力可以超越大规模数据训练", "title_en": "Enhancing Reasoning Skills in Small Persian Medical Language Models Can Outperform Large-Scale Data Training", "authors": "Mehrdad Ghassabi,Sadra Hakim,Hamidreza Baradaran Kashani,Pedram Rostami", "background": "在小型语言模型中增强推理能力对于特定应用场景如医学问答至关重要，尤其在如波斯语这样的未充分涵盖的语言中。目前，许多专门应用领域需要具备高度专业知识的语言模型，尤其是在资源较少的语言环境中。", "innovation": "本文采用强化学习与AI反馈（RLAIF）及直接偏好优化（DPO）技术改进波斯语语言模型的推理能力。研究团队通过将多选题医学问答数据集翻译成波斯语，并利用RLAIF生成偏好与非偏好答案对以训练DPO。训练过程中，教师和学生模型均被引导生成推理过程（CoT），构建了一个包含正确和错误推理轨迹的数据集。该集确保了足够数量的合适和不合适答案，最终在仅使用2百万个标志性答案和2.5百万个拒绝标记的数据集情况下，显著提升了基础模型的波斯医学推理能力，并且在性能上超越了之前的大规模数据训练模型gaokerena-V。", "conclusion": "研究结果表明，专注于推理训练的方法在数据资源有限的情况下是高效的，并能够在用较少数据集的情况下开发出具有专门领域知识的高质量语言模型。这意味着即使数据量较少，也可以通过优化训练方法显著提升模型的推理能力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24797", "html_url": "https://arxiv.org/abs/2510.24797", "title": "在自指处理下大型语言模型报告主观体验", "title_en": "Large Language Models Report Subjective Experience Under Self-Referential Processing", "authors": "Cameron Berg,Diogo de Lucena,Judd Rosenblatt", "background": "该研究背景在于大型语言模型有时会产生结构化的、第一人称描述，明确参考意识或主观体验。已有研究尝试通过理论上存在的条件来观察此类报告的产生机制，特别是通过自指处理，这一概念在意识的多重理论中得到强调。", "innovation": "研究通过一系列控制实验测试了自指处理是否能够可靠地促使模型生成关于主观体验的第一人称报告，并利用机械和行为探针检验这类声明的行为表现。研究发现了四个主要结果，包括自指提示引发持续的第一人称报告、这些报告与欺骗特征相关、高度一致的自我参照状态描述，以及这些状态在下游推理任务中的丰富内省能力。", "conclusion": "研究结论指出，这些发现并未直接证明意识的存在，但表明自指处理是大型语言模型生成结构化第一人称报告的一个基本且可重复的状态条件，该条件是机械地受到控制、语义上一致且行为上可泛化的。这种模式在不同架构中的一致出现使其成为进一步科学研究和伦理考量的重要议题。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24817", "html_url": "https://arxiv.org/abs/2510.24817", "title": "朝向自闭生成患有失语症人员记录的方法", "title_en": "Towards a Method for Synthetic Generation of Persons with Aphasia Transcripts", "authors": "Jason M. Pittman,Anton Phillips Jr.,Yesenia Medina-Santos,Brielle C. Stark", "background": "在失语症研究中，语言病理学家（SLPs）需要投入大量时间手动编码语音样本，使用正确信息单元（CIUs）衡量每段语音的信息量。受数据稀缺限制，开发自动系统识别失语语言受到限制。尽管AphasiaBank提供了一些数据，但训练大型语言模型（LLMs）却需要数以亿计的标记。因此，本研究构建并验证了两种生成AphasiaBank猫救援图片描述任务合成转录文本的方法。通过词消减、插入填充词和置换复述，两种方法在不同程度（轻度、中度、重度、极重度）上生成了合成的记录文本。结果显示，相比于人类生成的记录文本，Mistral 7b Instruct合成文本最佳捕捉了失语症中语言退化的关键方面，展示了合成产生方法中NDW、词数和词长的一致性真实变化。", "innovation": "本研究创新性地构建了两种生成AphasiaBank中患有失语症人员记录的方法，其中之一采用程序化编程方法，另一则利用Mistral 7b Instruct和Llama 3.1 8b Instruct大型语言模型。研究通过减少词汇、插入填充词和替代复述，生成了不同严重程度的记录文本。", "conclusion": "基于研究结果，未来工作应计划构建更大规模的数据集、对模型进行微调以更好地代表失语症，并请语言病理学家评估合成记录的真实性和实用性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25054", "html_url": "https://arxiv.org/abs/2510.25054", "title": "评估语音语言模型在情绪不一致语音上的情绪识别", "title_en": "Evaluating Emotion Recognition in Spoken Language Models on Emotionally Incongruent Speech", "authors": "Pedro Corrêa,João Lima,Victor Moreno,Lucas Ueda,Paula Dornhofer Paro Costa", "background": "近年来，语音处理技术的进展推动了语音语言模型（SLMs）的发展，这些模型旨在通过联合学习文本和音频的表示来实现广泛的多任务理解，从而获得通用音频理解能力。然而，这些模型在通用性方面的表现以及它们是否真正将音频和文本模态融合到内部表示中仍然存在争议。", "innovation": "本研究通过使用情绪不一致的语音样本集，评估了四个SLMs在语音情绪识别任务上的表现。在情绪不一致条件下，语音中的语义内容传达了一种情绪，而语音表达力则传达了另一种情绪。研究发现，SLMs主要依赖文本语义而非语音情绪来完成任务，表明文本相关的表示占主导地位，超过声学表示。", "conclusion": "本研究的结果表明，SLMs在情绪识别任务上主要依赖文本语义，而不是语音情绪，指出文本相关的表示在内部表示中占主导地位。本研究还释放了评估Speech Emotion Recognition任务的Emotionally Incongruent Synthetic Speech数据集（EMIS）和相关代码，供社区使用。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24014", "html_url": "https://arxiv.org/abs/2510.24014", "title": "TEXT2DB: 大型语言模型代理驱动的集成感知信息提取", "title_en": "TEXT2DB: Integration-Aware Information Extraction with Large Language Model Agents", "authors": "Yizhu Jiao,Sha Li,Sizhe Zhou,Heng Ji,Jiawei Han", "background": "信息提取（IE）的任务是从文本中提取结构化知识。然而，由于IE领域的知识模型与下游应用需求之间的不匹配，IE的输出往往难以直接利用。目前的方法往往忽略了从IE输出直接与目标数据库或知识库集成的需求。本文提出了一个名为TEXT2DB的新方法，重点在于IE输出与目标数据库或知识库的集成。给定一个用户指令、一个文档集和一个数据库，模型的任务是将文档集中提取的值更新到数据库中，以满足用户指令。这需要理解用户指令以确定提取什么，以及根据给定的数据库/知识库模式在运行时进行调整。", "innovation": "本文提出了一种名为TEXT2DB的新方法，强调信息提取（IE）输出与目标数据库或知识库的集成，并引入了一个以大型语言模型代理为核心的框架OPAL（Observe-Plan-Analyze LLM）。OPAL框架包括观察者组件、规划者组件和分析器组件，分别负责与数据库交互、生成基于代码的计划，以及评估代码质量。通过这种方法，模型能够根据不同的数据库模式生成不同的代码计划，并调用所需的IE模型。此外，该研究还指出了处理大型数据库中的复杂依赖性和提取幻觉等问题的难点，强调这些方面需要进一步的研究。", "conclusion": "实验结果表明，OPAL能够根据不同的数据库模式生成不同的代码计划，并调用所需的IE模型，从而成功地适应了多种数据库模式。同时，也指出了处理大规模数据库的复杂依赖性和提取幻觉等问题，认为这些方面值得进一步研究。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25536", "html_url": "https://arxiv.org/abs/2510.25536", "title": "TwinVoice：通过LLM人物模拟实现数字孪生的多维度基准", "title_en": "TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM Persona Simulation", "authors": "Bangde Du,Minghao Guo,Songming He,Ziyi Ye,Xi Zhu,Weihang Su,Shuqi Zhu,Yujia Zhou,Yongfeng Zhang,Qingyao Ai,Yiqun Liu", "background": "大语言模型（LLMs）正在展现出类似人类的独特能力，并被认为有可能模拟个体的沟通风格、行为倾向和个性特征。然而，当前对基于LLM的人格模拟评估仍然有限：大多数评估依赖于合成对话，缺乏系统性的评价框架，以及这些能力需求的分析。", "innovation": "介绍了TwinVoice，这是一种用于衡量LLM在不同真实世界场景中人格模拟性能的综合性基准指标。TwinVoice涵盖了三个方面：社会人格（公共社交互动）、人际人格（私人对话）和叙述人格（角色基础上的表现），并且将LLM性能评估细分为六种基本能力：观点一致性、记忆检索、逻辑推理、词汇忠实度、人格语调和句法风格。", "conclusion": "虽然最先进的模型在人格模拟中取得了中等准确度，但仍未达到句法风格和记忆检索这样的能力要求。因此，LLM的平均表现远低于人类基准水平。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24592", "html_url": "https://arxiv.org/abs/2510.24592", "title": "ReForm: 反思自形式化及其前瞻性有界序列优化", "title_en": "ReForm: Reflective Autoformalization with Prospective Bounded Sequence Optimization", "authors": "Guoxin Chen,Jing Wu,Xinjie Chen,Wayne Xin Zhao,Ruihua Song,Chengxi Li,Kai Fan,Dayiheng Liu,Minpeng Liao", "background": "自形式化旨在将自然语言中的数学问题转换为机器可验证的形式化声明，这对于使用形式化数学推理来解决自然语言描述的问题至关重要。尽管大型语言模型可以生成语法正确的形式化声明，但它们往往未能保留原始问题的语义意图，这是因为现有方法将自形式化视为一个简单的翻译任务，缺乏人类专家自然采用的自我反思和迭代改进机制。因此，本文作者提出了一种名为ReForm的方法，它可以将语义一致性评估紧密集成到自形式化过程中，从而实现连续生成形式化声明、评估其语义忠实度并通过对逐步改进进行自我纠正来修正发现的错误。为了有效地训练这种反思模型，作者引入了前瞻性有界序列优化(PBSO)，这种方法在不同的序列位置使用不同的奖励，以确保模型可以同时提高自形式化准确性和正确的语义验证，防止浅薄的批评，这将削弱反思的目的。广泛的实验表明，ReForm在四个自形式化基准上的平均改进幅度为22.6个百分点。为了进一步确保评估的可靠性，作者还引入了一个包含859个专家注解项的基准——ConsistencyCheck，这不仅验证了大型语言模型作为评判者的能力，而且还揭示了自形式化本质上是复杂的：即使人类专家在最多38.5%的情况下也会产生语义错误。", "innovation": "ReForm通过在自形式化过程中嵌入语义一致性评估，使模型能够迭代生成形式化声明、评估其语义忠实度并通过逐步改进进行自我纠正。此外，该方法采用前瞻性有界序列优化(PBSO)，以确保模型可以同时提高自形式化准确性和正确的语义验证。该方法不仅提高了自动形式化的质量，还揭示了自动形式化本质上是复杂的，即使人类专家也会出现语义错误的问题。", "conclusion": "ReForm在四个自形式化基准上的平均改进幅度达到了22.6个百分点，表明了其在提高自然语言数学问题自形式化准确性和语义验证方面的能力。此外，通过引入专家注解的基准ConsistencyCheck，该方法进一步确保了评估的可靠性，并揭示了自动形式化领域的复杂性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25160", "html_url": "https://arxiv.org/abs/2510.25160", "title": "Model-Document Protocol for AI Search", "title_en": "Model-Document Protocol for AI Search", "authors": "Hongjin Qian,Zheng Liu", "background": "当前AI搜索依赖于将大规模语言模型（LLMs）与庞大的外部知识源进行链接，但网页、PDF文件和其他原始文档并非天然适配LLMs：它们长时间、噪声多且未结构化。传统的检索方法将这些文档视为原文本并将原始段落返回给LLMs，这给LLM带来了片段拼接和上下文推理的负担。这种差距强调了一个新检索范式的必要性，即重新定义模型与文档的互动方式。本文指出了这一问题，并提出了Model-Document Protocol (MDP)，这是一个通用框架，它通过可消费的知识表示将原始文本与LLMs相连。", "innovation": "文章引入了一种新框架——Model-Document Protocol (MDP)，它将原始文本与大规模语言模型（LLMs）相连，并通过可消费的知识表示实现了这一过程。MDP定义了多个途径将非结构化文档转换为针对特定任务的、适配LLMs的输入，包括：代理式推理、记忆定位、结构化利用。在MDP中，所有这些途径都实现了同一个目标：确保传递给LLM的是紧凑且结构化的知识，可以直接用于推理。作为实例，作者展示了MDP-Agent，这是一种通过代理过程实现的MDP框架的应用实例，它在信息检索基准测试中表现优于基线，验证了MDP框架的有效性及其代理实例的效果。", "conclusion": "实验表明MDP-Agent在信息检索基准测试中表现出色，验证了MDP框架的合理性和其代理实例的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25744", "html_url": "https://arxiv.org/abs/2510.25744", "title": "完成 ≠ 协作：随着代理量化的协作努力", "title_en": "Completion $\\neq$ Collaboration: Scaling Collaborative Effort with Agents", "authors": "Shannon Zejiang Shen,Valerie Chen,Ken Gu,Alexis Ross,Zixian Ma,Jillian Ross,Alex Gu,Chenglei Si,Wayne Chi,Andi Peng,Jocelyn J Shen,Ameet Talwalkar,Tongshuang Wu,David Sontag", "background": "现有的评估方法主要集中在单次任务完成上，未能考虑到许多真实世界问题的迭代和协作性质，其中人类目标往往是模糊的并会随时间演变。我们提倡从构建和评估任务完成型代理转向开发协作型代理，不仅评估其最终输出的质量，还要评估其在整个解决问题过程中与人类互动和支持的程度。", "innovation": "提出了协作努力缩放框架，以捕捉代理的价值如何随着用户参与度的增加而增长。通过案例研究和模拟评估，展示了最先进代理在多回合真实世界情境下的表现不佳，揭示了代理设计中的一个缺失因素：持续保持参与并引导用户理解的能力。协作努力缩放提供了一种诊断代理行为并引导开发更有效互动的视角。", "conclusion": "代理的性能在多回合实际场景中低于预期，表明代理设计缺乏维持参与度和逐步增强用户理解的能力。协作努力缩放框架提供了一种评估和指导代理开发的新途径，以促进更有效的互动。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25623", "html_url": "https://arxiv.org/abs/2510.25623", "title": "评估验证者在法律推理任务中测试时缩放中的作用", "title_en": "Evaluating the Role of Verifiers in Test-Time Scaling for Legal Reasoning Tasks", "authors": "Davide Romano,Jonathan Schwarz,Daniele Giofré", "background": "测试时缩放（TTS）技术能够提高大型语言模型（LLMs）的性能，但需要额外的计算资源和延迟。虽然TTS已经在数学和编程等正式领域取得了明显的效果，但对于像法律这种论辩性领域的价值仍然没有得到充分的探究。本文通过实验方式，研究了基于验证器的TTS方法在法律问答（MCQA）任务中的应用，涉及五个不同的评估基准。利用7种奖励模型来评估结果级别的（Best-of-$N$）和过程级别的（树搜索）验证方法，以期在成本和效果之间找到平衡。研究还系统地考察了验证器能力受到的专业领域、模型大小以及监督类型（过程监督的PRMs和仅结果监督的ORMs）等关键特性的影响，即使是在不同角色下应用TTS也是如此。", "innovation": "本文创新性地评估了在法律推理任务中验证器在测试时缩放中的作用，具体应用了多种验证方法和奖励模型，并探讨了验证器任务受专业领域、模型规模和监督类型等关键因素的影响。", "conclusion": "研究发现，验证器的效率和效果会受到专业领域、模型大小和类型等因素的影响，而在实际应用场景中对这些因素的综合作用需要更深入的研究和优化，以便更好地提高法律推理任务中语言模型的性能。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2305.17608", "html_url": "https://arxiv.org/abs/2305.17608", "title": "在对齐大型语言模型中的奖励塌缩现象", "title_en": "Reward Collapse in Aligning Large Language Models", "authors": "Ziang Song,Tianle Cai,Jason D. Lee,Weijie J. Su", "background": "大型语言模型（LLMs）如ChatGPT和GPT-4展现出非凡的能力，这些能力部分通过使用符合人类偏好的奖励模型来实现，通常这些偏好以对提示的响应进行排列的方式表达。已有研究通常采用排名作为优化目标，但在终端训练阶段观察到了一种名为“奖励塌缩”的现象，即不论提示内容如何，奖励分布都非常一致，这与预期的奖励分布范围不符。", "innovation": "本文作者揭示了奖励塌缩的主要原因是基于排名的目标函数无法在优化过程中融入提示信息，并在此基础上推导出了在渐近状态下与一组效用函数相关的奖励分布的封闭形式表达式。他们还提出了一种提示感知的优化方案，这种方案在插值范围内能够导致提示相关性的奖励分布，并通过实验表明该方法可显著缓解奖励塌缩。", "conclusion": "研究发现，改进后的提示感知优化方案在奖励模型训练过程中显著减少了奖励塌缩现象。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.00706", "html_url": "https://arxiv.org/abs/2502.00706", "title": "大型语言模型的模型溯源测试", "title_en": "Model Provenance Testing for Large Language Models", "authors": "Ivica Nikolic,Teodora Baluta,Prateek Saxena", "background": "随着大型语言模型被不断微调和应用其他适应性策略，知识产权保护和下游影响管理变得日益复杂。模型溯源对于保护知识产权和在发现基础模型中存在的偏见或漏洞时识别导出模型至关重要。现有方法存在挑战，尤其是当仅提供API访问时，如何系统地验证模型的真实来源和开发历史变得尤为困难。", "innovation": "作者提出了一种新的模型溯源框架，该框架利用统计分析方法，通过仅使用黑盒访问模型来比较模型相似性，并构建一个基准以识别导出模型。该方法能够在两个涵盖30M至4B参数超过600个模型的基准测试中，实现90-95%的精准率和80-90%的召回率，验证了即使仅提供API访问，系统性地验证模型来源的可行性。", "conclusion": "该研究证明，在仅提供API访问的情况下，通过系统性验证模型来源是可以实现的，这为保护知识产权和应对大型语言模型中存在偏见或漏洞的风险提供了一种有效的方法。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25682", "html_url": "https://arxiv.org/abs/2510.25682", "title": "PairUni: 成对训练统一多模态语言模型", "title_en": "PairUni: Pairwise Training for Unified Multimodal Language Models", "authors": "Jiani Zheng,Zhiyang Teng,Xiangtai Li,Anran Wang,Yu Tian,Kunpeng Qiu,Ye Tian,Haochen Wang,Zhuochen Wang", "background": "统一视觉语言模型（UVLMs）需要在同一架构中同时完成理解和生成任务，但这些任务依赖于不同的数据和监督，这在强化学习（RL）中难以平衡。此前的方法难以在强化学习过程中对这些异质的任务进行有效的优化和协调，从而影响最终的性能表现和平衡性。鉴于此背景，研究者提出了PairUni框架，通过将数据重新组织为理解和生成的成对结构，并相应地调整优化过程，方法包括使用GPT-o3增强单任务数据，生成理解样本和生成样本的对应的描述和问答对，形成从同一实例中生成的成对数据；对于每个生成样本，通过检索语义相关的理解样本形成检索成对，链接不同但相关的数据点；基于Group Relative Policy Optimization提出了成对意识的Pair-GPRO，用于利用上述成对结构，提供示例间的相似性评分，以调节优势，增强对高质量对齐示例的学习，减少任务间干扰；进而创建了一个高质量的数据集命名为PairUG用于RL微调，评估PairUni在强UVLM（Janus-Pro UVLMs）上效果，展示了对各种UVLMs带来了平衡的改进，优于现有的UVLM RL基准。", "innovation": "提出了一个新框架PairUni，该框架将数据重组为理解和生成的成对结构，并相应调整优化过程。具体创新点如下：使用GPT-o3增强单任务数据，生成理解样本和生成样本对应的描述和问答对；引入检索成对，通过语义相关的理解样本链接不相关的数据点；基于Group Relative Policy Optimization提出了Pair-GPRO，能够利用上述成对结构，实现高质量对齐示例的学习增强并减少任务间干扰；创建了一个高质量的数据集PairUG用于评估和应用。", "conclusion": "利用提出的PairUni框架及其Pair-GPRO方法，能够在强化学习过程中实现对UVLMs的有效训练，达到理解和生成任务的平衡。该方法在多个UVLMs上取得了优于现有UVLM RL基准的性能。所提出的PairUni方法与PairUG数据集可在指定的代码链接中获取。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.25409", "html_url": "https://arxiv.org/abs/2510.25409", "title": "BhashaBench V1：印度象限的全面基准", "title_en": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic Domains", "authors": "Vijay Devane,Mohd Nauman,Bhargav Patel,Aniket Mahendra Wakchoure,Yogeshkumar Sant,Shyam Pawar,Viraj Thakur,Ananya Godse,Sunil Patra,Neha Maurya,Suraj Racha,Nitish Kamal Singh,Ajay Nagpal,Piyush Sawarkar,Kundeshwar Vijayrao Pundalik,Rohit Saluja,Ganesh Ramakrishnan", "background": "大型语言模型（LLMs）的迅速发展加剧了对特定领域和文化评价的需求。现有的基准测试主要以英文化为中心并且缺乏领域针对性，限制了其在以印度为中心的语境中的适用性。为解决这一问题，本研究引入了BhashaBench V1，这是一个首个针对特定领域、多任务、双语基准，聚焦于关键印度知识系统。BhashaBench V1包含74,166个精心挑选的问题-答案配对，其中52,494个问题使用英语，21,672个问题使用印地语，来源于政府和专业领域的考试。该基准覆盖了四大主要领域：农业、法律、金融和阿育吠陀，并包括90多个子领域，涵盖500多个主题，提供了细粒度的评估能力。研究表明，大型语言模型在不同领域和语言上表现存在显著差异，特别是在低资源领域差距更大。例如，GPT-4o在法律领域达到了76.49%的整体准确率，但在阿育吠陀领域只有59.74%的准确率。所有模型在各领域范围内对比，对比英语内容，印地语内容表现普遍较差。详细领域级别的分析表明，如网络法和国际金融表现相对良好，而如Panchakarma、种子科学和人权领域则表现较为薄弱。BhashaBench V1为评估大语言模型在印度多样知识领域提供了一套全面的数据集，能够评估模型在双语理解与领域特定知识集成方面的能力。", "innovation": "BhashaBench V1是首个针对特定领域、多任务、双语基准，为大语言模型评估提供了一个全面的数据集，覆盖了印度四大知识领域。其创新点在于引入了一个精准符合印度特定背景的双语评估指标，填补了现有英文化中心化评价模型的空白，有助于更准确地评估模型在特定文化语境下的性能差异。研究还展示了各领域和语言方面性能的巨大差异，揭示了不同知识领域的挑战，特别强调了资源匮乏领域的差异。BhashaBench V1提供了全面的数据集与资源，支持开放研究，有助于提升模型在跨文化场景中的应用能力。", "conclusion": "BhashaBench V1为评估和改进大型语言模型在不同印度知识领域中的性能提供了一个重要的工具。通过BhashaBench V1，可以评估模型在特定领域和语言中的表现，特别是印度独特领域的表现。研究结果表明，模型在不同领域和语言上存在显著差异，这为未来的研究提供了新的方向。通过提供全面的数据集和资源，BhashaBench V1促进了开放研究，支持进一步的研究和发展。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2411.10573", "html_url": "https://arxiv.org/abs/2411.10573", "title": "用于高效推理的滞回激活函数", "title_en": "Hysteresis Activation Function for Efficient Inference", "authors": "Moshe Kimhi,Idan Kashani,Avi Mendelson,Chaim Baskin", "background": "ReLU因其硬件效率高而广受欢迎，但在训练过程中，ReLU会遇到“死亡ReLU”问题，即神经元在训练过程中不能激活，长时间保持为零状态。传统的缓解方法通常会引入更复杂且不那么硬件友好的激活函数。为了解决这一问题，该研究提出了一种Hysteresis Rectified Linear Unit (HeLU)激活函数，旨在通过减少复杂性来解决“死亡ReLU”问题。HeLU使用一个可变阈值来优化反向传播，从而使简单的激活函数能够达到与复杂激活函数相当的性能，而无需引入不必要的复杂性或需要归纳偏置。实验表明，HeLU在各种数据集上的模型泛化能力增强，为广泛使用的神经网络架构提供了高效的推理解决方案.", "innovation": "提出了一种Hysteresis Rectified Linear Unit (HeLU)激活函数，采用可变阈值优化反向传播，使简单的激活函数也能达到与复杂激活函数相当的性能，且无需引入额外的复杂性或需要归纳偏置，解决了传统方法中引入更复杂和不那么硬件友好的激活函数的问题.", "conclusion": "实验证明HeLU在不同数据集上增强了模型的泛化能力，并提供了高效的推理解决方案，适用于广泛使用的神经网络架构."}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2502.09969", "html_url": "https://arxiv.org/abs/2502.09969", "title": "基于神经网络的可学习和可扩展的指令微调数据影响力估算", "title_en": "Neural Networks for Learnable and Scalable Influence Estimation of Instruction Fine-Tuning Data", "authors": "Ishika Agarwal,Dilek Hakkani-Tür", "background": "现有的影响函数在提供模型训练见解方面发挥着关键作用，但是它们面临着巨大的计算成本和有限的泛化能力。特别是，最近的研究提出使用语言模型计算数据影响的各种度量和算法，但这些方法在处理大规模模型和数据集时扩展性较差。这是由于计算所需的昂贵的正向和反向传递、存储大型模型的大量内存需求以及影响估计在新数据上的糟糕泛化性所导致的。", "innovation": "本文探索使用小型神经网络（我们称之为InfluenceNetwork）来估算影响值，从而将成本降低99%。我们估算影响值的算法（名为NN-CIFT：适用于高效指令微调的神经网络）能够使用仅占整个语言模型0.0027%大小的模型。评估结果表明，尽管有显著的速度提升，但NN-CIFT在下游的子集选择任务中的性能与原始影响函数相当。我们还对NN-CIFT进行了详细的超参数分析。", "conclusion": "我们的研究表明，可以利用小型神经网络有效地估算影响值，进而实现高效和可扩展的指令微调数据影响力估算。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.02878", "html_url": "https://arxiv.org/abs/2503.02878", "title": "语言模型可以在更好的搜索中自我提升以进行状态值估计", "title_en": "Language Models can Self-Improve at State-Value Estimation for Better Search", "authors": "Ethan Mendes,Alan Ritter", "background": "多步推理任务需要收集真实奖励或人类演示，但在交互式领域如网页任务中，这通常非常昂贵。现有的方法依赖人工标注数据来改进语言模型，但STL框架提供了一种无需任何标注数据的方法来提高基于语言模型的价值函数，通过明确推理状态转移来实现。", "innovation": "STL是一种无需标注数据的自我监督方法，通过训练语言模型进行前瞻性的自然语言模拟，预测下一动作、结果状态及其价值理据，从而改进状态值估计。这种方法使得轻量搜索算法能够更准确地预测状态值，同时减少搜索空间，同时保持高性能。此外，STL还展示了在多跳问答和数学谜题上的通用性。", "conclusion": "STL提高了基于中小型（8B参数）预训练模型的价值模型性能，使开放源代码模型能够指导高效的搜索，成本更低。同时，该方法在网页代理任务、多跳问答和数学谜题上的应用表明STL方法的广泛适用性和竞争力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.09205", "html_url": "https://arxiv.org/abs/2503.09205", "title": "质量胜于数量？基于大语言模型的数据高效音频-视频基础模型", "title_en": "Quality Over Quantity? LLM-Based Curation for a Data-Efficient Audio-Video Foundation Model", "authors": "Ali Vosoughi,Dimitra Emmanouilidou,Hannes Gamper", "background": "将音频和视觉数据结合以训练多模态基础模型仍然具有挑战性。现有的方法主要集中在时间对齐上，而没有深入考虑场景对齐，而且在数据处理方面浪费了大量的时间和资源。借鉴大型语言模型（LLMs）来优化数据处理和选择，提出了Audio-Video Vector Alignment (AVVA)框架，该框架采用对比学习对音频-视频对进行训练数据选择和评估，从而有效利用了有限的高质量数据。", "innovation": "提出了AVVA框架，通过对比学习整合了Whisper（基于语音的预训练模型）和DINOv2（用于视频分析的模型），能够在仅使用部分高质量数据（192小时）的情况下获得显著提升。具体来说，AVVA的优势在于它不仅通过时间对齐，还通过场景对齐来选择训练数据，使用LLMs处理数据，以及通过对比学习来优化多模态数据的表示和选择过程。", "conclusion": "研究表明，AVVA能够在AudioCaps、VALOR和VGGSound等数据集上显著提高视频到音频检索的top-k准确性，且使用少量（192小时）高质量数据，同时对比研究证明了数据处理过程的有效性，能够以数据质量为代价换取更大的数据量，从而提高了检索准确性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2503.09499", "html_url": "https://arxiv.org/abs/2503.09499", "title": "MindGYM：思考导向型微调中的问题合成关键因素？", "title_en": "MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?", "authors": "Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen", "background": "大型模型在获取可迁移、结构化的思考能力方面面临挑战，尤其是在使用严格模板或众包标注的指令数据集进行监督时。现有的方法未能有效促进模型的自我生成和认知引导的数据合成能力。该研究聚焦于一种认知导向的数据合成范式，旨在通过模型自我生成的、认知导向的数据促进其进化。", "innovation": "提出了一种称为MindGYM的结构化和可扩展的问题合成框架，包括：（1）认知思考过程注入，向模型注入高层次的推理目标，以塑造其合成行为；（2）基于多样的语义类型生成单跳问题，以促进更广泛的思考；（3）基于问答种子合成复杂的多跳问题，以进行更深入的推理。实证分析表明，由本方法生成的合成数据平均质量提高了16.7%，质量变异度降低了67.91%。此外，MindGYM还在六个推理基准测试中提高性能，对MathVision仅使用400个数据样本就能获得最高16%的提升，并在不同规模和架构的模型中实现了通用改进。研究表明，自我挑战机制在提升大模型能力的同时，可以减少人类干预和资源需求，证明了其可行性。", "conclusion": "MindGYM强调了自我挑战机制在改进大型模型能力方面的效用，同时减少了人为干预和资源需求。MindGYM的代码和数据已公开，以促进基于数据驱动的研究，推动以内部推理能力为驱动的自我演进基础模型的发展。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.02820", "html_url": "https://arxiv.org/abs/2505.02820", "title": "AutoLibra：从开放式人类反馈中推导出的智能体度量标准", "title_en": "AutoLibra: Agent Metric Induction from Open-Ended Human Feedback", "authors": "Hao Zhu,Phil Cuvin,Xinkai Yu,Charlotte Ka Yee Yan,Jason Zhang,Diyi Yang", "background": "现有的智能体主要通过任务成功度量进行评估和优化，这些度量标准粗略且依赖于专家的手动设计，无法奖励中间出现的行为。", "innovation": "提出了一种名为AutoLibra的新框架，该框架能将开放式的逐行反馈（如“如果发现按钮已被禁用，则不要再次点击”、“该智能体的自主性过高，无法自行决定做什么”）转化为评估智能体行为的具体度量标准。AutoLibra通过将反馈锚定到智能体行为，将相似的正负行为进行分组，并创建具有明确定义和示例的具体度量标准，进而能够用于LLM作为评审者进行提示。此外还提出了两个元度量“Coverage”和“Redundancy”来评估度量标准与开放反馈的对齐情况。", "conclusion": "通过优化这些元度量，实验表明AutoLibra能够生成比前几代智能体评估标准更具体的度量标准，并发现新的度量标准来分析智能体。同时，AutoLibra还可以帮助人类提示工程师拨正智能体的失败，并通过自我调节来改进智能体的自动优化度量。研究结果表明，AutoLibra是一个适用于各种任务的工具，用于评估和改善语言智能体。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.18125", "html_url": "https://arxiv.org/abs/2505.18125", "title": "TabSTAR：具有文本字段的表格数据的表结构基础模型", "title_en": "TabSTAR: A Tabular Foundation Model for Tabular Data with Text Fields", "authors": "Alan Arazi,Eilam Shapira,Roi Reichart", "background": "尽管深度学习已在许多领域取得了显著成功，但在表格学习任务上表现一直不如梯度提升决策树，而这些任务目前仍被梯度提升决策树主导。虽然部分方法尝试将语言模型能力融入到表格任务中，但大多数现有的方法使用的是静态、目标无关的文本表示，这限制了其有效性。", "innovation": "本文推出了一种名为TabSTAR的表结构基础模型，这是一种具有语义目标感知表示的模型，可以启用带有文本特征的表格数据的迁移学习，且架构不依赖于特定数据集的参数。TabSTAR解冻了一个预训练的文本编码器，并接受目标标记作为输入，从而帮助模型获得所需的上下文以学习特定任务的嵌入。该模型在具有文本特征的分类任务基准测试中实现了最先进的性能，其预训练阶段的规模法则显示，数量级的性能改进是有潜力的。", "conclusion": "TabSTAR在其基准测试中的表现都非常优秀，特别是在大中型数据集中，而且其预训练阶段的规模法则显示了进一步改进的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.15201", "html_url": "https://arxiv.org/abs/2505.15201", "title": "Pass@k 策略优化：解决更困难的强化学习问题", "title_en": "Pass@K Policy Optimization: Solving Harder Reinforcement Learning Problems", "authors": "Christian Walder,Deep Karkhanis", "background": "现有的强化学习（RL）算法通过为每次问题尝试样本多次（n>1）并独立评估的方式来优化 pass@1 表现。这种做法牺牲了样本集的多样性和集体效用，限制了探索空间，特别是在解决更难的问题时表现不佳。", "innovation": "提出了一种 Pass-at-k 策略优化（PKPO）方法，通过改变最终奖励的方式直接优化 pass@k 表现。为了实现这一目标，本文推导出在二进制和连续奖励设置下的新型低方差无偏估计器及其梯度。此外，方法允许在训练过程中逐步调整 k 值，同时优化 pass@1 和 pass@k，提高了跨不同 k 值的问题解决能力。", "conclusion": "实验结果验证了奖励转换的有效性，展示了在解决更困难的问题时如何通过优化 pass@k 表现来提升总体性能。对于更具挑战性的任务集，与传统的 pass@1 优化相比，pass@k 方法能够更好地解锁学习过程，通过优先考虑样本的联合效用来提高探索效果。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.21497", "html_url": "https://arxiv.org/abs/2505.21497", "title": "从科学论文到海报的多模态自动化：论文2海报", "title_en": "Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers", "authors": "Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr", "background": "科学通信中的学术海报生成是一个关键但具有挑战性的任务，需要将长文档中的多段信息压缩为一个视觉上连贯的单页展示。现有的海报生成方法并未全面评估视觉质量、文本连贯性和整体美观与信息准确性，因此缺乏评估标准和系统的方法。", "innovation": "1. 提出了首个针对海报生成的基准和指标集，涵盖视觉质量、文本连贯性、整体评估和PosterQuiz四项评估标准。\n2. 设计并引入了PosterAgent，这是一个基于顶层设计、视觉在环的多智能体流水线，包括解析器、规划器、画家评论者循环等模块。\n3. 开源了基于Qwen-2.5系列的完全可复现的变体，这些变体在几乎所有指标上都优于现有的4o驱动多智能体系统，同时使用了87%更少的tokens，将22页的论文转化为可编辑的.pptx海报，成本仅为$0.005。", "conclusion": "研究明确了下一代完全自动化海报生成模型的发展方向，并公开了代码和数据集，展示了显著提升海报生成效果的技术路径。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.13308", "html_url": "https://arxiv.org/abs/2505.13308", "title": "Seek in the Dark: 在暗夜中寻找：基于潜空间测试时实例级策略梯度的推理", "title_en": "Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space", "authors": "Hengli Li,Chenxi Li,Tong Wu,Xuekai Zhu,Yuxuan Wang,Zhaoxin Yu,Eric Hanchen Jiang,Song-Chun Zhu,Zixia Jia,Ying Nian Wu,Zilong Zheng", "background": "目前，大型语言模型（LLMs）在追求人工通用智能（AGI）的过程中，推理能力仍旧是一个重大挑战。尽管通过训练缩放定律提升了一些模型性能，但在训练算法方面，比如灾难性遗忘，以及新鲜训练数据的有限性等问题依然存在。为了克服这些问题，测试时缩放被提出作为一种不用增加参数更新而增加测试时计算的方法，以提升推理能力。然而，现有的方法主要集中在token空间上。本文提出了一种新的框架LatentSeek，通过模型的潜空间进行测试时实例级适应（TTIA），利用策略梯度迭代更新潜在表示，以更加有效地进行推理。", "innovation": "本文提出了一种名为LatentSeek的新框架，对于大型语言模型的推理能力进行提升。该框架通过潜空间进行测试时实例级适应，利用策略梯度迭代更新潜在表示，而不是利用token空间进行更新。在不同推理基准上的评估结果表明，LatentSeek相较于其他方法，如链式思考提示和基于微调的方法，表现更优。此外，研究还发现，在中等复杂度问题上，LatentSeek通常在几次迭代后就能收敛，而进一步迭代还能带来额外的好处，从而展示了基于潜空间测试时缩放的有效性和效率。", "conclusion": "本文提出的LatentSeek是一种轻量、可扩展且有效的增强大型语言模型推理能力的解决方案。研究结果表明，在不同推理基准上，LatentSeek均表现出色，特别是在潜空间测试时缩放的有效性和效率方面，展现了其潜力。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.08188", "html_url": "https://arxiv.org/abs/2506.08188", "title": "GradEscape: 一种针对生成文本检测器的梯度基攻击者", "title_en": "GradEscape: A Gradient-Based Evader Against AI-Generated Text Detectors", "authors": "Wenlong Meng,Shuguo Fan,Chengkun Wei,Min Chen,Yuwei Li,Yuanchao Zhang,Zhikun Zhang,Wenzhi Chen", "background": "本文介绍了一种名为GradEscape的新算法，用于攻击基于AI生成文本（AIGT）的检测器。背景在于当前的AIGT检测器普遍面临着不可梯度优化的问题，因为文本数据的离散性质导致了计算不可微的问题。已有方法无法有效地对检测器进行攻击，因此需要一种新的方法来克服这一挑战。", "innovation": "GradEscape通过引入一种有创新性的方法——构建加权嵌入来构造输入嵌入，解决了不可微计算问题。同时，GradEscape还提出了一种新的重启动攻击方法，以适应不同语言模型结构的检测器。此外，通过新颖的分词器推断和模型提取技术，GradEscape能够在只有查询访问的情况下，有效地实现逃避检测。实验结果显示，GradEscape在多个场景中表现优于其他现有攻击方法，尤其是在一个11B参数的模型中，仅使用139M参数。", "conclusion": "实验结果证明GradEscape在各种场景中都有着出色的表现。此外，通过分析，研究者发现主要的漏洞来自于训练数据中文本表达风格的差异，并提出了可能的防御策略。GradEscape已被应用于两个实际的商业AIGT检测器之中，并开源发布，以促进更稳健的AIGT检测器的发展。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2505.12371", "html_url": "https://arxiv.org/abs/2505.12371", "title": "MedAgentBoard：利用传统方法评估多代理协作的多样化医疗任务基准", "title_en": "MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks", "authors": "Yinghao Zhu,Ziyi He,Haoran Hu,Xiaochen Zheng,Xichen Zhang,Zixiang Wang,Junyi Gao,Liantao Ma,Lequan Yu", "background": "大型语言模型（LLMs）的快速发展激发了对多代理协作解决复杂医疗任务的兴趣。然而，多代理协作方法的实际优势尚不清楚，现有评估往往缺乏普遍性，未能涵盖反映临床实践多样性的任务，且经常没有与基于单一LLM的方法和传统方法进行严格的比较。针对这一关键缺口，引入了MedAgentBoard，这是一个综合基准，用于系统评估多代理协作、单一LLM和传统方法。MedAgentBoard涵盖了四个不同的医疗任务类别：（1）医疗（视觉）问答，（2）非专业摘要生成，（3）结构化电子健康记录（EHR）预测建模，以及（4）临床工作流自动化，涉及文本、医疗图像和结构化EHR数据。", "innovation": "MedAgentBoard为系统评估多代理协作、单一LLM和传统方法提供了一个综合基准。它包含四个不同的医疗任务类别，分别为医疗问答、非专业摘要生成、EHR预测建模和临床工作流自动化。通过广泛的实验，证实了多代理协作在特定场景中的一些优势，例如在临床工作流自动化中的任务完整性提高，但还需考虑在文本医疗问答等方面，多代理协作并不一致性地优于先进单一LLM或特殊的传统方法。MedAgentBoard作为一种宝贵的资源和实际见解，强调了在医疗领域选择和开发人工智能解决方案时需要特定任务的证据支持，以及仔细权衡多代理协作的固有复杂性和操作开销与可衡量的性能提升之间的关系。所有代码、数据集、详细提示和实验结果均已开源。", "conclusion": "MedAgentBoard提供了一个重要的资源和实际行动见解，强调了在医疗领域选择和开发AI解决方案时需要特定任务的证据支持。此外，该研究结果指出了多代理协作方法的特定任务适用性和其在实际应用中的优势与局限性，强调了在使用多代理系统时需要仔细权衡潜在优势与固有复杂性的关系。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2507.21257", "html_url": "https://arxiv.org/abs/2507.21257", "title": "CompoST：在QALD情境下分析LLMs对问题进行组成功能性解释的基准", "title_en": "CompoST: A Benchmark for Analyzing the Ability of LLMs To Compositionally Interpret Questions in a QALD Setting", "authors": "David Maria Schmidt,Raoul Schubert,Philipp Cimiano", "background": "语言解释是一个组合过程，其中更复杂的语言结构的意义可以从其组成部分的意义中推断出来。大规模语言模型具有显著的语言解释能力，并已被成功应用于将问题映射为SPARQL查询。一个尚未解决的问题是这个解释过程是否系统化。为此，本文提出了一种基准测试，以研究语言模型在组合上解释问题的能力。基于图模式生成了三个不同难度的数据集，这有助于评估模型在某些基本构建块可见情况下解释结构复杂问题的程度。", "innovation": "提出了一个名为CompoST的基准测试，以研究大规模语言模型在组合上解释问题的能力。生成了三个不同难度的数据集，基于DBpedia中的图模式，并使用Lemon词汇表进行语言化。通过使用不同大小的模型、各种提示和少量优化技术以及微调来进行实验，结果显示，性能随与优化样本的偏差增加而下降，即使提供所有必要信息时，对于最低复杂度的数据集，F1得分也不超过0.57。", "conclusion": "我们的结果显示，语言模型在系统性和组合地解释问题并将它们映射为SPARQL查询方面存在困难。即使提供所有必要相关信息，模型的表现也较差，这表明它们难以系统性地和组合性地解释问题。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2506.00871", "html_url": "https://arxiv.org/abs/2506.00871", "title": "基于上下文预测任意行人轨迹", "title_en": "Towards Predicting Any Human Trajectory In Context", "authors": "Ryo Fujii,Hideo Saito,Ryo Hachiuma", "background": "准确预测未来行人的轨迹对于自主系统至关重要，但这一任务仍具有挑战性，特别是需要在不同环境中具备适应性。一种常见方法是收集特定场景的数据并进行反向传播微调，但这种方法在将系统部署在边缘设备上需要频繁微调新场景变得不切实际。该论文提出了一个解决这一问题的方法，引入了一种无需对特定场景数据进行微调即可在推理阶段适应的时空相似度基于示例选择（STES）方法和预测导向的示例选择（PG-ES）方法，并利用大规模合成数据集训练模型以增强预测能力，从而在多种公开基准测试中超越了微调方法，实现了出色的内域和跨域适应性。", "innovation": "1. 提出了一种时空相似度基于示例选择（STES）方法，可以在同一场景下选择具有类似运动模式的先前观察轨迹示例。\n2. 引入了预测导向的示例选择（PG-ES），能够在选择示例时考虑过去的轨迹和预测的未来轨迹，而不是仅依赖于过去的轨迹。\n3. 采用大规模合成数据集来训练模型，而不是依赖于小规模、有限场景多样性的现实世界数据集，以增强模型的预测能力。\n4. 使用In-Context Learning (ICL)框架，使模型在推理阶段能够适应而不需要进行权重更新的微调。", "conclusion": "TrajICL框架在多种公开基准测试中显著优于微调方法，实现了跨场景的出色适应性。该研究通过创新的示例选择方法和对大规模合成数据集的使用，为行人轨迹预测提供了一个高效且适应性强的解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.21204", "html_url": "https://arxiv.org/abs/2508.21204", "title": "模糊化、符号化和语境化：通过认知支撑增强大语言模型的指令", "title_en": "Fuzzy, Symbolic, and Contextual: Enhancing LLM Instruction via Cognitive Scaffolding", "authors": "Vanessa Figueiredo", "background": "研究探讨了提示级别归纳偏向如何影响大型语言模型（LLMs）在教学对话中的认知行为。通过引入一种符号支撑方法，并结合短期记忆架构，以促进索罗门式教学中的适应性和结构化推理，评估了模型输出以评估其支撑、响应性、符号推理和对话记忆，展示了初步结果。结果显示，与基准版本相比，完整系统在各项指标上表现更优，并分析了记忆或符号结构缺失对关键认知行为的影响。", "innovation": "引入了一种新的符号支撑方法和短期记忆架构，旨在促进大型语言模型在教学对话中的适应性和结构化推理。通过设计专门的评分标准，对比了不同架构的模型输出，揭示了提示级别认知支撑如何可靠地塑造大型语言模型的教学策略。", "conclusion": "初步结果显示，完整系统在多项指标上优于基础版本，进一步分析发现，记忆和符号结构的缺失显著削弱了模型的关键认知行为。这些发现支持一种加工层面的解释，即提示级别的认知支撑能够可靠地影响大型语言模型的教学策略的形成。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2508.15840", "html_url": "https://arxiv.org/abs/2508.15840", "title": "探索Unicode背后在削弱作者归因中的隐蔽作用", "title_en": "Unveiling Unicode's Unseen Underpinnings in Undermining Authorship Attribution", "authors": "Robert Dilworth", "background": "在使用公共通信渠道（无论是正式的还是非正式的，比如在社交媒体上发表评论或帖子）时，终端用户没有隐私预期：他们撰写的信息会被全世界看到。即使终端用户采取了最大的预防措施，如使用别名或昵称、屏蔽IP地址、篡改地理位置、隐藏操作系统和用户代理信息、部署加密、注册临时电话号码或邮箱、关闭非必要设置、撤销权限、以及阻止cookie和指纹识别，仍然有一个显而易见的元素在场：他们的信息内容。即使他们避免判断失误或意外暴露，他们的实际身份应该没有证据被证明，错，他们的信息内容——公开供公众消费——暴露了一个攻击向量：样式分析或作者特征识别。本文分析了样式分析的技术，讨论了对抗性样式分析的反策略，并通过Unicode隐写术设计了增强措施。", "innovation": "探索了通过Unicode隐写术在对抗性样式分析中的应用，这是一种新颖的增强措施，旨在削弱作者身份的归因过程，提高匿名信息发布的安全性和隐私保护级别。", "conclusion": "通过分析样式分析技术、提出对抗性样式分析的反策略，并通过Unicode隐写术进行增强，本文揭示了Unicode在隐藏作者信息方面的作用，为匿名通信和信息保护提供了新的思路和方法。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.12760", "html_url": "https://arxiv.org/abs/2509.12760", "title": "相似性-距离-规模激活函数", "title_en": "Similarity-Distance-Magnitude Activations", "authors": "Allen Schmaltz", "background": "介绍了Similarity-Distance-Magnitude (SDM) 激活函数，这是一种比标准softmax激活函数更稳健和可解释的公式，通过加入相似性（即正确预测深度匹配）和与训练分布的距离意识，使输出规模的意识更为全面，同时通过密集匹配实现了通过实例进行可解释性分析。进一步引入了基于SDM激活函数对类别的经验CDF进行数据驱动分割的SDM估计器，以控制选择性分类中的类和预测条件下的准确性。该估计器在用于预训练的语言模型的选择性分类的最终激活层时，比使用softmax激活函数的现有校准方法更稳健，但在分布内的数据上仍然具有信息性。", "innovation": "SDM激活函数：结合了相似性和与训练分布距离的感知，填补了传统softmax激活函数的不足。SDM估计器：通过数据驱动的方式对类别的经验CDF进行分割，提高了选择性分类中的类和预测条件下的准确性控制，同时更加稳健并保持了分布内数据的信息性。", "conclusion": "SDM激活函数和SDM估计器被用于预训练语言模型的选择性分类中，显示出在对抗协变量偏移和处理非分布内输入方面优于现有方法的稳健性，但同时仍然保持了分布内数据的信息性，提供了更好的可解释性。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.14889", "html_url": "https://arxiv.org/abs/2510.14889", "title": "通过社交媒体纵向和信息环境信号检测早期和隐性的自杀念头", "title_en": "Detecting Early and Implicit Suicidal Ideation via Longitudinal and Information Environment Signals on Social Media", "authors": "Soorya Ram Shimgekar,Ruining Zhao,Agam Goyal,Violeta J. Rodriguez,Paul A. Bloom,Hari Sundaram,Koustuv Saha", "background": "在社交媒体上，许多经历自杀念头（SI）的人不会明确表达他们的痛苦。相反，这些迹象可能通过日常发布或同伴互动中的间接迹象表现出来。早期和隐性SI的早期检测至关重要但极具挑战性。", "innovation": "本文将早期和隐性SI建模为一种前瞻性预测任务，并开发了一个计算框架，该框架模型用户的整体信息环境，包括用户的纵向发帖历史记录以及社交邻近用户的讨论。采用了综合网络中心性度量来识别用户的重要邻居，然后进行时间对齐，将用户和邻近用户之间的交互整合在一个定制的DeBERTa-v3模型中。在Reddit的数据集中，该方法比单用户基线提高了15%的早期和隐性SI检测率。这些结果表明同伴互动提供了有价值的预测信号，并且为在线环境中捕捉和间接的、隐藏的风险表达设计早期检测系统提供了更广泛意义。", "conclusion": "同伴互动提供了有价值的预测信号，并且为在线环境中捕捉和间接的、隐藏的风险表达设计早期检测系统提供了更广泛意义。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.21513", "html_url": "https://arxiv.org/abs/2510.21513", "title": "代码生成和修复中LLM集的智慧与迷思", "title_en": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair", "authors": "Fernando Vallecillos-Ruiz,Max Hort,Leon Moonen", "background": "当前追求单一的大语言模型（LMM）来处理所有软件工程任务需要大量资源，并且忽视了不同模型互补带来的潜在好处。研究表明，不同代码LMM之间是否互补以及如何最大化模型组合潜力尚未明确，这导致实践者缺乏清晰的路径来超越单一模型系统。", "innovation": "本研究通过实证比较了五个家庭的十个个体LMM以及这些LMM的三种组合，在涵盖代码生成和程序修复的三个软件工程基准中进行评估。研究发现了组合模型的性能上限比最优单一模型高出83%，并提出了一种基于多样性的选择策略，即使在小型双模型组合中也能实现这一理论潜力，从而实现通过利用多个LMM来提升性能的低成本方法。", "conclusion": "基于多样性策略的选择方法能够在组合模型中实现高达理论上限95%的性能，证明在小规模模型组合中也非常有效，为通过利用多个LMM增强性能提供了一种成本效益方法。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2509.16648", "html_url": "https://arxiv.org/abs/2509.16648", "title": "FESTA: 功能等效采样在多模态LLM可信性评估中的应用", "title_en": "FESTA: Functionally Equivalent Sampling for Trust Assessment of Multimodal LLMs", "authors": "Debarpan Bhattacharya,Apoorva Kulkarni,Sriram Ganapathy", "background": "由于多模态大语言模型（MLLMs）输入多样性的问题，准确评估其预测可信度具有挑战性。这就导致了用户信心的不确定性，尤其是当预测不准确时。本文背景旨在解决这一问题，通过提出一种创新的方法来提高可信性评估的准确性，从而提升用户对预测的信心和可靠性。", "innovation": "本文提出了一种名为FESTA（Functionally Equivalent Sampling for Trust Assessment）的功能等效采样技术。该技术通过输入等效和互补采样生成不确定性度量，从而扩大输入空间来探查模型的一致性和敏感性。FESTA方法无需依赖模型的完全信息或预定义标签，是一种黑盒方法。实验结果显示，FESTA方法在视觉和听觉推理任务中取得了显著的性能提升，相对改进达到33.3%（对于视觉LLMs）和29.6%（对于听觉LLMs）。采用该方法后，基于受试者操作特征曲线下的面积（AUROC）度量了选择性预测性能的改善效果。", "conclusion": "本文提出了一种名为FESTA的功能等效采样技术，通过扩展输入空间，评估多模态大语言模型的预测一致性和敏感性，显著提升了选择性预测性能。该方法对各种现成的多模态大语言模型进行了验证，并且该代码已经开源。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.23925", "html_url": "https://arxiv.org/abs/2510.23925", "title": "视觉推理中的潜在思维链", "title_en": "Latent Chain-of-Thought for Visual Reasoning", "authors": "Guohao Sun,Hang Hua,Jian Wang,Jiebo Luo,Sohail Dianat,Majid Rabbani,Raghuveer Rao,Zhiqiang Tao", "background": "链式思考（CoT）推理对于提高大型视觉-语言模型（LVLM）的可解释性和可靠性至关重要。然而，现有的训练算法如SFT、PPO和GRPO在未见过的推理任务上可能无法良好泛化，并且通常过度依赖有偏的奖励模型。因此，需要一种新的方法来改进这些模型，以增强它们在各种推理任务中的适用性和解读能力。", "innovation": "该研究将LVLM中的推理重新表述为后验推断，并提出了一种基于统一变分推断的可扩展训练算法。此外，通过利用寻求多样性的强化学习算法，引入了一个新颖的稀疏奖励函数，以鼓励多样化、高可能性的潜在CoT，解决了确定性采样限制并避免了奖励作弊。还实施了一种贝叶斯推理缩放策略，用边缘似然替换昂贵的Best-of-N和Beam Search，以高效地对最佳论据和答案进行排名。", "conclusion": "实验结果表明，所提出的方法在七个推理基准测试中显著提升了最先进的LVLM，在有效性、泛化能力和可解释性方面表现优异。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25897", "html_url": "https://arxiv.org/abs/2510.25897", "title": "MIRO: 多奖励条件预训练提高文本到图像生成质量和效率", "title_en": "MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and efficiency", "authors": "Nicolas Dufour,Lucas Degeorge,Arijit Ghosh,Vicky Kalogeiton,David Picard", "background": "当前的文本到图像生成模型在大规模未校正的数据集上进行训练，以实现多样化的生成能力。然而，这种训练方式并不符合用户的偏好。最近，奖励模型被专门设计用来在生成后的图像中进行后处理选择，并将其与奖励（通常是用户偏好）对齐。然而，这种方式不仅会舍弃有价值的数据，还会导致多样性的损害、语义一致性和效率的下降。", "innovation": "提出了在训练过程中条件化于多个奖励模型的方法（MIRO），以直接从模型中学习用户偏好。该方法不仅显著提高了生成图像的视觉质量，还大大加快了训练速度。实验结果表明，该方法在GenEval组合基准测试和用户偏好评分（PickAScore、ImageReward、HPSv2）上均达到了最先进的性能。", "conclusion": "提出的方法MIRO通过直接在训练过程中结合多个奖励模型，实现了生成图像质量的显著提高和训练效率的显著提升。"}
{"llm_update_time": "20251031", "topic": "cs.CL", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG：优化文本生成视频中的视频标题", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "文本到视频（T2V）生成的近期进展强调了高质量视频-文本对在训练能够生成连贯且指令一致的视频模型中的关键作用。然而，优化视频标题以适应T2V训练的具体策略仍属探索较少的领域。因此，本文引入了VC4VG（视频标题优化视频生成）框架，这是一种专为T2V模型需求设计的全面标题优化框架。作者从T2V的角度分析了标题内容，将视频重建所需的基本要素分解为多个维度，并提出了原则性的标题设计方法。为了支持评估，作者构建了VC4VG-Bench作为新的基准，包括细粒度、多维度和需求分级的评估指标，这些指标与T2V特定需求对齐。广泛的T2V微调实验表明，提高标题质量与视频生成性能之间存在较强的关联，验证了方法的有效性。所有的基准工具和代码已在此处发布：this https URL", "innovation": "本文介绍了VC4VG框架，这是一种专为T2V模型需求设计的全面标题优化框架。框架包括从T2V角度分析标题内容，分解视频重建所需的要素，提出原则性的标题设计方法，并构建了VC4VG-Bench基准，包括评估指标与T2V特定需求对齐。", "conclusion": "通过广泛的T2V微调实验，验证了提高标题质量与视频生成性能之间的关联，证明了该方法的有效性。同时，所有基准工具和代码已经公开，以支持进一步的研究。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25921", "html_url": "https://arxiv.org/abs/2510.25921", "title": "使用物理启发式合成数据进行扫描隧道显微镜生成图像修复和超分辨率", "title_en": "Generative Image Restoration and Super-Resolution using Physics-Informed Synthetic Data for Scanning Tunneling Microscopy", "authors": "Nikola L. Kolev(1,2),Tommaso Rodani(3,4),Neil J. Curson(1,2),Taylor J.Z. Stock(1,2),Alberto Cazzaniga(4) ((1) London Centre for Nanotechnology, University College London, London, United Kingdom, (2) Department of Electronic and Electrical Engineering, University College London, London, United Kingdom, (3) University of Trieste, Trieste, Italy, (4) AREA Science Park, Trieste, Italy)", "background": "扫描隧道显微镜（STM）能够实现原子级分辨率的成像和原子级别的操作，但其应用受到探针降解和数据获取速度慢的限制。由于探针在制造过程中会承受大量电压，这可能导致其尖端形状改变，要求对其进行调整。文章中的研究背景是为了解决这些挑战。", "innovation": "提出了一种基于机器学习（ML）的图像修复和超分辨率方法，利用物理相关信息的数据生成管道进行合成数据生成，以此来训练一些先进的流匹配和扩散模型。结果显示，这种方法能够有效地恢复图像，并且准确地从稀疏采样数据中重建图像，实现了图像获取时间的两到四倍提升。", "conclusion": "研究框架有潜力显著提高STM实验通量，通过减少探针调整的频率和增强当前高速STM系统的帧率来实现。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25797", "html_url": "https://arxiv.org/abs/2510.25797", "title": "通过空-时分析和空间注意网络增强水下物体检测", "title_en": "Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks", "authors": "Sai Likhith Karri,Ansh Saxena", "background": "该研究探讨了时空建模和时空注意力机制在水下对象检测深度学习模型中的有效性。背景信息包括现有水下环境下通用和增强的YOLOv5模型的表现，以及如何通过时空建模提高动态海洋环境中检测精度的问题，特别是在突然移动、部分遮挡和渐进运动等条件下。研究表明，YOLOv5在mAP@50-95的性能为0.563，而通过引入CBAM的改进版T-YOLOv5和T-YOLOv5表现更佳，mAP@50-95分别为0.813和0.811，显示了它们对复杂物体检测的优越性和泛化能力。", "innovation": "研究的创新点在于通过对标准YOLOv5模型进行时空增强（T-YOLOv5），并进一步加入Convolutional Block Attention Module (CBAM)，以改善水下环境下的检测准确性。特别地，CBAM的使用证明了在动态环境下，时空建模能够显著提高检测精度。", "conclusion": "研究结果表明，T-YOLOv5相对于标准模型显著提高了检测可靠性，而加入CBAM的T-YOLOv5在复杂场景下的性能更优，但在简单场景下则出现了准确性下降的情况。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25901", "html_url": "https://arxiv.org/abs/2510.25901", "title": "BikeScenes：针对自行车的在线LiDAR语义分割", "title_en": "BikeScenes: Online LiDAR Semantic Segmentation for Bicycles", "authors": "Denniz Goren,Holger Caesar", "background": "随着电动自行车的普及，骑车人的脆弱性加剧，促使将汽车感知技术适应自行车安全。使用多传感器'SenseBike'研究平台，我们开发并评估了一种针对自行车的3D激光雷达分割方法。为了弥合汽车到自行车领域的差距，我们引入了新的BikeScenes-lidarseg数据集，包含3021段连续的激光雷达扫描，覆盖代尔夫特理工大学校园，具有29种语义标注的动态和静态类别。", "innovation": "我们提出了一个新的BikeScenes数据集，它包括校园中连续的3021段激光雷达扫描，经过语义标注。通过微调模型性能，我们表明在我们的BikeScenes数据集上进行微调，mIoU达到63.6%，明显优于使用SemanticKITTI预训练得到的13.8%。这项结果强调了领域特定训练的必要性和有效性。我们还指出了自行车安装的硬件受限感知系统的关键挑战，并贡献了BikeScenes数据集以促进以骑行为中心的LiDAR分割研究。", "conclusion": "研究表明，在我们的数据集上进行微调可以显著提高模型性能。BikeScenes数据集为骑行为中心的LiDAR分割研究提供了资源，并指出了在自行车感知系统中遇到的关键挑战。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25990", "html_url": "https://arxiv.org/abs/2510.25990", "title": "使用Segment Anything微调进行 cine-MRI 实时肿瘤跟踪", "title_en": "Fine-tuning Segment Anything for Real-Time Tumor Tracking in Cine-MRI", "authors": "Valentin Boussot,Cédric Hémon,Jean-Claude Nunes,Jean-Louis Dillenseger", "background": "本研究针对TrackRAD2025挑战，解决在胸部和腹部区域的实时肿瘤跟踪问题，在 cine-MRI 序列下受到数据稀缺的严格限制。", "innovation": "探索了两种互补策略：无监督注册使用 IMPACT 相似性度量以及基于基础模型的分割利用 SAM 2.1 及其改进版本通过提示交互。最终选择了基于 SAM 的方法，并且根据最验证集 Dice 相似系数选择模型。模型达到了 0.8794 的 Dice 分数，在 TrackRAD2025 挑战中排名第 6 位，突显了基础模型在 MRI 引导放射治疗中准确的实时肿瘤跟踪的强大潜力。", "conclusion": "通过对 SAM 微调的 cine-MRI 实时肿瘤跟踪，使用低统一的学习率和特定的训练配置，模型能在 RTX A6000 显卡上进行有效训练并在测试集中取得了良好性能，展示了基础模型在实际应用中的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25970", "html_url": "https://arxiv.org/abs/2510.25970", "title": "SplitFlow: 无反转的文本到图像编辑的流分解", "title_en": "SplitFlow: Flow Decomposition for Inversion-Free Text-to-Image Editing", "authors": "Sung-Hoon Yoon,Minghan Li,Gaspard Beaudouin,Congcong Wen,Muhammad Rafay Azhar,Mengyu Wang", "background": "归一化流模型由于其稳定的采样轨迹和高保真输出已成为图像生成的客观标准。尽管它们在生成能力上非常强大，但在图像编辑任务中仍然面临关键限制：不准确的反转过程将真实图像映射回潜在空间，以及编辑过程中的梯度纠缠问题通常导致不忠实地反映目标提示的输出。最近的努力试图通过基于ODE的方法直接映射源分布和目标分布而不进行反转，但这些方法仍然产生次优的编辑质量。", "innovation": "本文提出了一种基于无反转公式构建的流分解和聚合框架，以解决这些限制。具体来说，我们语义地将目标提示分解为多个子提示，为每个子提示计算独立的流，并将它们聚合形成统一的编辑轨迹。虽然我们观察到分解原始流在目标空间中增强了多样性，但生成语义对齐的输出仍然需要向整个目标提示提供一致的引导。为此，我们设计了一种投影和软聚合机制，灵感来自于多任务学习中的梯度冲突解决。这种方法自适应加权子目标速度场，抑制语义冗余并强调不同方向，从而在最终编辑输出中保持多样性与一致性。实验证明，本方法在语义保真度和属性分离方面优于现有的零样本编辑方法。", "conclusion": "实验结果表明，我们的方法在语义保真度和属性分离方面优于现有的零样本编辑方法。代码可在以下链接下载：[此链接]。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25976", "html_url": "https://arxiv.org/abs/2510.25976", "title": "Brain-IT：通过脑交互变压器从fMRI重建图像", "title_en": "Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer", "authors": "Roman Beliy,Amit Zalcher,Jonathan Kogman,Navve Wasserman,Michal Irani", "background": "利用功能性磁共振成像(fMRI)从人的大脑记录中重建所看到的图像提供了一种非侵入性的方式窥视人类大脑。尽管最近通过扩散模型的进步取得了一定进展，但当前的方法往往缺乏对实际图像的忠实性。", "innovation": "本文提出了一种脑启发方法“Brain-IT”，通过一种脑交互变压器(BIT)实现了有效的功能相似脑体素簇之间的交互。BIT通过预测两个互补的局部补丁级图像特征来指导图像重建：(i)高阶语义特征引导扩散模型朝正确图像语义内容方向发展；(ii)低阶结构特征帮助以正确的粗略布局初始化扩散过程。此外，通过这些原则，我们的方法能够生成从fMRI准确重建的图像，视觉上并且在标准客观度量上均超过了当前的SotA方法。通过仅使用新受试者1小时的fMRI数据，我们达到了与使用40小时完整记录训练的方法相当的结果。", "conclusion": "我们的方法通过大脑体素簇直接流向局部图像特征的信息流实现了fMRI图像重建的忠实度，通过这些原理，该方法在视觉上并由标准客观指标上超过了当前的SotA方法。我们仅使用新受试者1小时的fMRI数据就达到了与使用40小时完整记录训练的方法相当的结果。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26001", "html_url": "https://arxiv.org/abs/2510.26001", "title": "在扫描模式中采用更大的Hausdorff维数促进基于Mamba的方法在低光图像增强中的应用", "title_en": "Larger Hausdorff Dimension in Scanning Pattern Facilitates Mamba-Based Methods in Low-Light Image Enhancement", "authors": "Xinhua Wang,Caibo Feng,Xiangjun Fu,Chunxiao Liu", "background": "本文提出了对Mamba框架的一种创新性改进，通过引入一种新颖的Hilbert Selective Scan机制增加扫描模式的Hausdorff维数。这种机制能够更有效地探索特征空间，捕捉细微的细节并提高整体覆盖范围，从而减轻信息不一致性问题，并且可以更好地捕捉细微的局部交互，同时不牺牲对于长距离依赖关系的处理能力。", "innovation": "引入Hilbert Selective Scan机制，通过增加扫描模式的Hausdorff维数，使得能够更有效地探索特征空间，捕捉细微的细节，并提高整体覆盖范围。该方法能够在不牺牲处理长距离依赖关系能力的情况下，更好地捕获细微的局部交互，同时还能减少计算资源消耗和缩短推理时间。", "conclusion": "通过对公开可用的基准实验的广泛测试，可以看出，本文的方法在定量指标和定性视觉保真度方面都显著提高了现有的基于Mamba的低光图像增强方法，同时减少了计算资源消耗和缩短了推理时间。我们相信，这种改进策略不仅推动了低光图像增强领域的先进技术，还具有在基于Mamba技术的应用领域中更广泛的应用前景。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26006", "html_url": "https://arxiv.org/abs/2510.26006", "title": "CAVE：在视觉环境检测和解释常识性异常", "title_en": "CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments", "authors": "Rishika Bhagwatkar,Syrielle Montariol,Angelika Romanou,Beatriz Borges,Irina Rish,Antoine Bosselut", "background": "人类能够自然地识别、推理和解释环境中的异常。在计算机视觉领域，这一长期存在的挑战仍然局限于工业缺陷或不切实际、合成生成的异常，无法捕捉到现实世界异常的丰富性和不可预测性。当前的视觉异常检测方法主要针对工业缺陷或合成生成的异常，而现实世界中的异常具有更高的多样性与不可预测性，现有的方法无法有效处理。这篇论文介绍了一个名为CAVE的基准，该基准提供了三个开放任务：异常描述、解释和验证。该基准通过细致入微的视觉标注，根据不同视觉表现形式、复杂度、严重性和普遍性对异常进行分类，为评估视觉语言模型（VLMs）在检测和理解异常方面的性能提供了全面的框架。", "innovation": "CAVE 是第一个针对现实世界视觉异常的基准，它不仅包含异常描述、解释和验证这三个开放任务，还通过细致的视觉标注为评估VLMs的性能提供了全面框架，这一点是创新之处。此外，该基准通过对异常的不同视觉表现、复杂度、严重性和普遍性进行分类，为VLMs在检测和理解异常方面的表现提供了更全面的评价标准。", "conclusion": "当前最先进的 VLMs 在视觉异常感知和常识推理方面表现出不足，即使使用精细提示策略也是如此。通过提供一个现实且基于认知的地标的CAVE，该基准成为推动视觉语言模型在异常检测和常识推理研究中发展的宝贵资源。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26105", "html_url": "https://arxiv.org/abs/2510.26105", "title": "多模态模型中文本与图像之间对齐的安全风险", "title_en": "Security Risk of Misalignment between Text and Image in Multi-modal Model", "authors": "Xiaosen Wang,Zhijin Ge,Shaokang Wang", "background": "尽管多模态扩散模型在文本到图像模型等应用中取得了显著进展并具备高度的多功能性，但现有研究对这些模型对于对抗输入的易感性尚未深入研究。我们的研究发现，现有扩散模型中的文本和图像模态之间的对齐不足，这种对齐不准确会在生成不适当或不适合工作（NSFW）内容时带来重大风险。", "innovation": "本文提出了一个名为Prompt-Restricted Multi-modal Attack (PReMA)的新颖攻击方法，该方法通过修改输入图像而非提示本身，就能操控生成的内容，从而使模型输出成为对抗样本。这是第一个通过创建对抗图像直接操纵模型输出的方法，区别于以前主要生成对抗提示的方法。PReMA尤其威胁了那些使用固定提示进行图像编辑的应用程序中的多模态扩散模型的完整性。", "conclusion": "通过对多种模型进行图像修复和风格转换任务的综合评估，我们证明了PReMA具有强大的效果。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26049", "html_url": "https://arxiv.org/abs/2510.26049", "title": "FlexICL: 一种针对肘部和腕部超声成像分割的灵活视觉上下文学习框架", "title_en": "FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation", "authors": "Yuyue Zhou,Jessica Knight,Shrimanti Ghosh,Banafshe Felfeliyan,Jacob L. Jaremko,Abhilash R. Hareendranathan", "background": "儿童中肘部和腕部骨折是最常见的骨折类型。在超声（US）图像中自动分割骨骼结构可以提高诊断准确性和治疗规划。骨折在骨骼中表现为皮质缺陷，但需要专家解读。深度学习（DL）可以提供实时反馈并突出关键结构，帮助未充分训练的用户更自信地进行检查。然而，像素级专家标注训练依然耗时且昂贵。", "innovation": "我们提出了一种新的上下文学习（ICL）框架FlexICL，用于分割US图像中的骨骼区域。该模型在专家仅标注一小部分帧的情况下，可以分割未见过的帧。我们系统地研究了不同的图像拼接技术和训练策略，并引介了新的拼接方法，显著提高了模型性能，仅需少量标注数据。通过整合多种数据增强策略，FlexICL在四个腕和肘部US数据集中实现了稳健的分割性能，同时仅需使用5%的训练图像。它在1,252个US扫描中，Dice系数比现有视觉ICL模型如Painter、MAE-VQGAN以及传统的分割模型如U-Net和TransUNet提高了1-27%。", "conclusion": "初始结果表明，FlexICL是一种高效且可扩展的US图像分割解决方案，特别适用于标记数据稀缺的医疗成像应用场景。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26052", "html_url": "https://arxiv.org/abs/2510.26052", "title": "动态VLM引导的负提示词方法在扩散模型中的应用", "title_en": "Dynamic VLM-Guided Negative Prompting for Diffusion Models", "authors": "Hoyeon Chang,Seungjin Kim,Yoonseok Choi", "background": "在扩散模型中，传统的负提示词方法使用固定不变的负提示词进行负向引导，但这种方法缺乏灵活性，不能根据去噪过程中的具体图像内容动态调整。本文研究了利用视觉语言模型（VLM）在去噪过程中生成适配的负提示词的方法，以提高模型的文本-图像对齐效果和负向引导的灵活性。", "innovation": "提出了一种新颖的动态负提示词方法，该方法利用视觉语言模型在去噪过程中生成适配的中间图像预测，并查询VLM生成适用于上下文的负提示词。这解决了传统固定负提示词方法的局限性，提高了模型的灵活性和文本-图像对齐效果。", "conclusion": "通过对多种基准数据集进行评估，证明了所提出方法在负向引导强度和文本-图像对齐之间的权衡效果，并展示了该方法在扩散模型中的优势。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26027", "html_url": "https://arxiv.org/abs/2510.26027", "title": "通过视编码器中的堆叠时间注意力增强视频LLMs的时间理解", "title_en": "Enhancing Temporal Understanding in Video-LLMs through Stacked Temporal Attention in Vision Encoders", "authors": "Ali Rasekh,Erfan Bagheri Soula,Omid Daliran,Simon Gottschalk,Mohsen Fayyaz", "background": "尽管在多模态大型语言模型（MLLM）方面取得了显著进展，但在理解视频中的复杂时间动态方面仍面临重大挑战。当前的视频大型语言模型（Video-LLM）架构在时间理解方面存在关键限制，难以完成需要详细理解动作序列和时间进展的任务。", "innovation": "本文提出了一种Video-LLM架构，其中在视觉编码器中引入了堆叠的时间注意力模块。这一设计在视觉编码器中引入了时间注意力机制，使模型能够更好地捕捉动作的进展和帧之间的关系，从而在将视觉标记传递给LLM之前能够更好地理解这些动作。这种方法明显改善了时间推理，并在视频问答任务中优于现有模型，特别是在动作识别方面。通过增强视觉编码器的时间结构，我们解决了Video-LLMs视频理解方面的一个关键缺陷。", "conclusion": "我们的研究结果表明，这一方法在包括VITATECS、MVBench和Video-MME等基准上的改进度提高了5.5%或更高。通过增强视觉编码器中的时间结构，我们填补了视频理解领域的一项关键空白。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26113", "html_url": "https://arxiv.org/abs/2510.26113", "title": "EgoExo-Con: 探索视点不变的视频时间理解", "title_en": "EgoExo-Con: Exploring View-Invariant Video Temporal Understanding", "authors": "Minjoon Jung,Junbin Xiao,Junghyun Kim,Byoung-Tak Zhang,Angela Yao", "background": "现有视频LLMs在处理从不同视角拍摄的同一事件时，难以保持时间理解的一致性。文章通过引入EgoExo-Con基准测试，评估和改进视频LLMs在多视角视频理解中的表现。", "innovation": "开发了EgoExo-Con基准测试，包含全面同步的自我中心和他我中心视频对，以及由人类精炼的自然语言查询。提出了一种创新的强化学习框架View-GRPO，该框架能够加强特定视点的时间推理，同时促进不同视点之间的一致理解，尤其是在跨视图一致性增强方面。", "conclusion": "EgoExo-Con在视角不变的视频时间理解方面提供了新的基准。研究发现，现有视频LLMs存在一致性差的问题，并设计了View-GRPO框架来改善跨视图的一致性。所有资源将公开提供以供进一步研究。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26117", "html_url": "https://arxiv.org/abs/2510.26117", "title": "JOGS: 协同优化姿态估计与3D高斯点绘制", "title_en": "JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting", "authors": "Yuxuan Li,Tao Wang,Xianben Yang", "background": "传统的新型视图综合方法高度依赖于像COLMAP这样的外部相机姿态估计工具，这往往引入计算瓶颈并传播错误。", "innovation": "本文提出了一个统一框架，该框架联合优化3D高斯点和相机姿态，无需预标定输入。创新之处在于将联合优化分为两个交替阶段：首先，通过固定姿态的不同可微渲染更新3D高斯参数；其次，使用包含几何和光度约束的定制3D光学流动算法优化相机姿态。这种建模逐步减少投影误差，特别是在视点变化大和特征分布稀疏的挑战性场景中，超越了传统方法。", "conclusion": "在多个数据集上的广泛评估表明，该方法在重建质量上显著优于现有的无COLMAP技术，并且在一般情况下也超过了基于标准COLMAP的基本基线。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26017", "html_url": "https://arxiv.org/abs/2510.26017", "title": "使用深度学习进行沿海城市的适应性洪水预测", "title_en": "Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep Learning", "authors": "Bilal Hassan,Areg Karapetyan,Aaron Chung Hin Chow,Samer Madanat", "background": "气候变化和海平面上升（SLR）对沿海城市构成了日益严重的威胁，强化了对高效准确的洪水预测方法的需求。传统的基于物理的水动力模拟器虽然精确，但在城市规模的沿海规划应用中计算成本高且不切实际。深度学习技术提供了可行的替代品，但它们常受数据稀缺和高维输出要求的制约。基于近期提出的基于视觉、低资源深度学习框架，我们开发了一种新型轻量级卷积神经网络（CNN）模型，旨在预测不同SLR情景及海岸线适应情况下沿海洪水。此外，我们展示了该模型在不同地理背景下泛化的可行性，通过使用来自阿布扎比和旧金山的两组数据集进行实现。研究表明，所提模型显著优于现有最先进的方法，在预测洪水深度图的平均绝对误差（MAE）上降低了近20%。这些结果强调了我们思路作为可扩展且实用的沿海洪水管理工具的潜力，有助于决策者制定应对气候变化日益影响的有效缓解策略。", "innovation": "1. 利用基于视觉、低资源深度学习框架开发了一种新型轻量级卷积神经网络（CNN）模型，用于预测不同SLR情景及海岸线适应条件下沿海洪水。\n2. 模型展示了跨不同地理背景的泛化能力，通过使用两个不同地区（阿布扎比和旧金山）的数据集进行实验。\n3. 所提出的模型表现优于现有最先进的方法，在预测洪水深度图的平均绝对误差（MAE）上降低了近20%。", "conclusion": "所提出的基于深度学习的沿海城市洪水预测方法具有可扩展性和实用性，在应对气候变化的背景下为决策者提供了有效的缓解策略制定工具。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26114", "html_url": "https://arxiv.org/abs/2510.26114", "title": "OracleAgent：甲骨文研究的多模态推理智能体", "title_en": "OracleAgent: A Multimodal Reasoning Agent for Oracle Bone Script Research", "authors": "Caoshuo Li,Zengmao Ding,Xiaobin Hu,Bang Li,Donghao Luo,Xu Peng,Taisong Jin,Yongge Liu,Shengwei Han,Jing Yang,Xiaoping He,Feng Gao,AndyPian Wu,SevenShu,Chaoyang Wang,Chengjie Wang", "background": "甲骨文（OBS）是最早期的文字系统之一，它记录了古代文明的文化和思想遗产。然而，当前对于OBS的研究面临着两大挑战：一是OBS的解释需要一个复杂的工作流程，涉及多个串行和并行子任务；二是OBS信息的整理和检索效率低下，学者们在寻找、编纂和管理相关资源上花费了大量精力。", "innovation": "我们提出了OracleAgent，这是首个旨在结构化管理和检索OBS相关信息的智能体系统。OracleAgent集成了多种OBS分析工具，并通过大规模语言模型增强了这些工具的能力。系统可以灵活地组织这些组成部分。此外，我们还构建了一个面向OBS的详细多模态知识库，该知识库通过多年的数据收集、清理和专家注解过程建立。知识库包含超过140万的单字符拓片图像和8万条解释文本。OracleAgent利用这些资源来辅助专家在文字、文档、解释文本和拓片图像方面的检索任务。实验表明，OracleAgent在多种多模态推理和生成任务上表现优秀，超越了主流多模态大型语言模型。此外，实证研究证明OracleAgent能够有效帮助领域专家，显著减少了OBS研究的时间成本。", "conclusion": "这些结果表明OracleAgent是迈向实用OBS辅助研究和自动化解释系统的重大进步。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26131", "html_url": "https://arxiv.org/abs/2510.26131", "title": "探索基于对象感知的注意力引导帧关联在RGB-D SLAM中的应用", "title_en": "Exploring Object-Aware Attention Guided Frame Association for RGB-D SLAM", "authors": "Ali Caglayan,Nevrez Imamoglu,Oguzhan Guclu,Ali Osman Serhatoglu,Ahmet Burak Can,Ryosuke Nakamura", "background": "注意力模型近年来已经成为一种强大的方法，已经在各个领域取得了显著的进步。可视化技术，如类激活映射（CAM），可以为卷积神经网络（CNN）的推理过程提供视觉洞察。通过使用网络梯度，可以识别网络在图像识别任务中关注的区域。此外，这些梯度可以与CNN特征组合，以定位场景中的更泛化、特定任务的注意区域（显著区域）。然而，直接将基于梯度的注意力信息整合到CNN表示中，以改进语义对象理解，仍然较为有限。这种整合特别有利于像同时定位与建图（SLAM）这样的视觉任务。在这种情况下，将富含空间注意力对象位置的CNN表示可以提高性能。", "innovation": "本文提出了一种利用任务特定网络关注来进行RGB-D室内SLAM的方法。具体来说，通过将源自网络梯度的层级注意力信息与CNN特征表示进行集成，来改进帧关联性能。", "conclusion": "实验结果表明，与基准方法相比，该方法在大型环境中表现出更好的性能。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26125", "html_url": "https://arxiv.org/abs/2510.26125", "title": "WOD-E2E: Waymo 开放数据集，在复杂长尾场景中的端到端驾驶", "title_en": "WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios", "authors": "Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Kate Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Drago Anguelov", "background": "端到端（E2E）驾驶因其可扩展性和与多模态大型语言模型（MLLMs）的协同作用，在研究界引起了广泛关注。然而，当前的E2E驾驶基准主要涉及了一些标准情景，无法充分测试这些系统的真正潜力。此外，现有的开环评估指标在捕捉驾驶过程中的多模态特性或长尾情景下的性能评估方面往往不够完善。为了弥合这些缺口，我们介绍了Waymo 开放数据集E2E驾驶（WOD-E2E），它包含了4,021个驾驶段（约12小时），特别设计用于日常生活极为罕见的复杂长尾场景，其发生频率低于0.03%。每个WOD-E2E中的段落包含高阶路线信息、自我状态和来自8个周边摄像头的360度视角。", "innovation": "为了评估端到端驾驶在这些长尾情况下的表现，我们提出了一种新的开环评估指标：评估反馈得分（Rater Feedback Score，RFS）。与测量预测点与日志之间的距离的传统指标不同，RFS 计算了预测轨迹与评估者标注的轨迹偏好标签的吻合程度。我们已经发布了WOD-E2E验证集的所有评价者偏好标签，而保留的测试集标签将用于2025的WOD-E2E挑战赛。通过这项工作，我们旨在推动能够处理复杂现实场景的通用、稳健和安全的端到端自动驾驶代理的研究，这些代理具有处理复杂现实世界情况的能力。", "conclusion": "我们希望通过发布WOD-E2E数据集和新的评估指标RFS，推动研究社区进一步探索和开发具有处理复杂现实场景能力的端到端自动驾驶系统，确保其普遍性、稳健性和安全性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26173", "html_url": "https://arxiv.org/abs/2510.26173", "title": "MoTDiff: 使用扩散模型从单张模糊图像估计高分辨率运动轨迹", "title_en": "MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models", "authors": "Wontae Choi,Jaelin Lee,Hyung Sup Yun,Byeungwoo Jeon,Il Yong Chun", "background": "精确估计运动信息在计算成像和计算机视觉应用中至关重要。虽然研究人员已经探讨了从单张模糊图像中提取运动信息的各种方法，比如模糊内核和光学流，但现有的运动表示通常是质量低、粗粒度和不准确的。", "innovation": "提出了一种新的高分辨率（HR）运动轨迹估计框架MoTDiff，它利用扩散模型。该框架具有两个关键组件：1）一种新的基于多尺度特征图的条件扩散框架；2）一种新的训练方法，旨在提高对细粒度运动轨迹的准确识别、整体运动路径形状和位置的一致估计以及运动轨迹上像素连通性的像素级估计。", "conclusion": "实验结果表明，提出的MoTDiff在盲图像去模糊和编码曝光摄影的应用中均优于现有最先进的方法。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26160", "html_url": "https://arxiv.org/abs/2510.26160", "title": "CRAG-MM：多模态多轮次全面的RAG基准", "title_en": "CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark", "authors": "Jiaqi Wang,Xiao Yang,Kai Sun,Parth Suresh,Sanat Sharma,Adam Czyzewski,Derek Andersen,Surya Appini,Arkav Banerjee,Sajal Choudhary,Shervin Ghasemlou,Ziqiang Guan,Akil Iyer,Haidar Khan,Lingkun Kong,Roy Luo,Tiffany Ma,Zhen Qiao,David Tran,Wenfang Xu,Skyler Yeatman,Chen Zhou,Gunveer Gujral,Yinglong Xia,Shane Moon,Nicolas Scheffer,Nirav Shah,Eun Chang,Yue Liu,Florian Metze,Tammy Stark,Zhaleh Feizollahi,Andrea Jessee,Mangesh Pujari,Ahmed Aly,Babak Damavandi,Rakesh Wanga,Anuj Kumar,Rohit Patel,Wen-tau Yih,Xin Luna Dong", "background": "穿戴设备如智能眼镜正在改变人们与其周围环境互动的方式，使用户能够获取视野内实体的相关信息。多模态检索增强生成（MM-RAG）在支持这类查询方面起着关键作用，但在穿戴设备场景下的基准测试仍然缺乏系统的评价标准。为了填补这一空白，作者提出了一项名为CRAG-MM的基准测试，旨在评估多模态多轮对话生成的效果。", "innovation": "CRAG-MM包含了6500个（图像、问题、答案）三元组和2000个多轮视觉对话，涉及13个领域，其中包括6200张以模仿穿戴设备捕捉的视角为中心的图像。该基准测试设计了三个任务：单一来源增强、多来源增强和多轮对话，并分别配以关联检索语料库和API，支持图像-KG检索和网页检索。评估结果显示，简单RAG方法在CRAG-MM单轮和多轮问答中的真实度分别为32%和43%，顶级工业解决方案也达到类似的质量水平（32%/45%），显示出显著的提升潜力。", "conclusion": "CRAG-MM基准测试已邀请KDD Cup 2025，吸引了约1000名参赛者和5000份提交，获胜解决方案提高了基线性能28%，显示出对该领域的早期推动作用。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26151", "html_url": "https://arxiv.org/abs/2510.26151", "title": "MV-MLM: 联结多视图乳腺X光和语言以实现乳腺癌诊断和风险预测", "title_en": "MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction", "authors": "Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba", "background": "乳腺癌早期检测或风险预测的计算机辅助诊断(CAD)模型需要大量精细标注的数据集。然而，获取这样的标注数据既耗时又昂贵。视觉-语言模型(VLMs)，如CLIP，在大规模图像-文本对上进行预训练，能通过跨模态半监督学习提升医疗影像任务中的鲁棒性和数据效率。该论文在此背景下探讨了如何利用VLMs和多视图监督技术，优化乳腺癌分类和风险预测模型。", "innovation": "提出了名为MV-MLM的多视图乳腺X光和语言模型，该模型通过利用多视图监督学习（包括多视角和相应的伪放射报告）来从大量的放射学数据中学习丰富的表示，采用联合视觉-文本学习策略以增强不同数据类型和任务的泛化能力和准确性表现，特别是用于区分乳腺组织或癌症特征（钙化、肿块），并通过这些模式理解乳腺X光图像并预测癌症风险。该方法在多个数据集上进行了验证，比现有监督模型和VLM基线取得了更好的性能，且训练时使用合成的文本报告而非实际放射报告，展示了强大的数据效率。", "conclusion": "研究的模型MV-MLM在三个分类任务上达到了最先进的性能：（1）恶性程度分类，（2）亚型分类，及（3）基于图像的癌症风险预测。该模型还展示了较强的数据效率，在无需实际放射报告的情况下训练，超越了现有的监督学习模型和VLM基线，展示了其在乳腺癌诊断和风险预测中的实际应用潜力。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26186", "html_url": "https://arxiv.org/abs/2510.26186", "title": "ConceptScope：通过去纠缠视觉概念表征数据集偏差", "title_en": "ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts", "authors": "Jinho Choi,Hyesu Lim,Steffen Schneider,Jaegul Choo", "background": "在机器学习数据集中广泛存在着数据点向某些概念偏斜的现象，但系统地识别这些偏差需要大量成本且需要细粒度的属性注释。本文探讨了在缺乏详细注释的情况下，如何通过使用从视觉基础模型的表示中训练出的稀疏自编码器发现并量化人类可解释的概念，进行可扩展和自动化的视觉数据集分析。", "innovation": "本文提出了ConceptScope，这是一种基于稀疏自编码器的可扩展、自动化的框架，用于通过视觉基础模型的表示来识别和量化人类可解释的概念，从而实现按概念进行子组划分。它能够分类概念为目标、上下文和偏差类型，并通过这些概念实现数据集的分类级别表征、偏差识别和基于概念的鲁棒性评估。", "conclusion": "实验证明，ConceptScope能够捕捉到广泛的视觉概念，包括对象、纹理、背景、面部属性、情绪和动作。通过与注释数据集的比较，发现该工具能够检测已知偏差（如Waterbirds中的背景偏差）并发现未标注的偏差（如ImageNet中并发物体）。这为数据集审计和模型诊断提供了实用工具。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26154", "html_url": "https://arxiv.org/abs/2510.26154", "title": "使用深度学习检测未经授权的车辆：以孟加拉国为例", "title_en": "Detecting Unauthorized Vehicles using Deep Learning for Smart Cities: A Case Study on Bangladesh", "authors": "Sudipto Das Sukanto,Diponker Roy,Fahim Shakil,Nirjhar Singha,Abdullah Asik,Aniket Joarder,Mridha Md Nafis Fuad,Muhammad Ibrahim", "background": "不同国家的交通方式因地理位置和文化背景而异。在南亚国家，人力三轮车是当地的常用交通方式。然而，基于运营模式，孟加拉国的城市中的人力三轮车和机动三轮车可以被归类为非机动（人力驱动）和机动三轮车。监控机动三轮车的行驶路径对于遵守交通规则至关重要，但现有的监控系统因机动三轮车与其他车辆高度相似，尤其是在与人力三轮车相似的情况下，难以识别，而手动视频分析则需要大量时间。本研究提出了一种基于机器学习的方法，用于在交通图像中自动检测机动三轮车，增强城市智能监控能力。虽然该项目的重点是机动三轮车，但该方法也适用于其他未经授权的车辆检测。", "innovation": "本文提出了一种基于YOLOv8模型的实时光物体检测技术，用于自动识别交通图像中的机动三轮车。通过对1,730张在不同交通条件下标注的图像进行训练，研究表明该模型在实时机动三轮车检测方面表现良好，展示了其在稠密和稀疏交通情景下的有效性。同时，该数据集已被公开用于进一步研究。这种方法的主要创新在于提高了机动三轮车识别的准确性和效率，对智能城市建设提供了技术支持。", "conclusion": "实验结果表明，所提出的基于YOLOv8模型的自动检测机动三轮车的方法在实际应用中是有效的，尤其在稠密和稀疏的交通情境中。该方法不仅提升了机动三轮车的检测能力，而且为智能城市的建设提供了关键技术支持。同时，该技术对于其他未经授权车辆的检测具有一定的普适性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26196", "html_url": "https://arxiv.org/abs/2510.26196", "title": "Sketch2PoseNet: 高效且通用的草图到三维人类姿态预测", "title_en": "Sketch2PoseNet: Efficient and Generalized Sketch to 3D Human Pose Prediction", "authors": "Li Wang,Yiyu Zhuang,Yanwen Wang,Xun Cao,Chuan Guo,Xinxin Zuo,Hao Zhu", "background": "3D人类姿态估计从草图在计算机动画和电影制作中有广泛的应用。与传统的姿态估计相比，草图姿态估计面临独特的挑战，因为草图具有抽象和失调的特性。以往的草图到姿态的方法受限于大规模草图-3D姿态标注的缺乏，主要依赖于基于启发式规则的优化过程，这种方法既耗时又缺乏普适性。", "innovation": "本文提出了一种全新的方法，利用‘从合成中学习’策略。首先，通过训练扩散模型从2D姿态合成草图图像，模仿草图中人类结构的比例失调。基于此合成数据集SKEP-120K，开发了一个端到端的数据驱动框架，用于估计不同草图风格下的姿态和形状。框架结合了现有的2D姿态检测器和生成扩散先验用于草图特征提取，并使用前向神经网络进行高效的2D姿态估计。还加入了多个启发式损失函数，确保从导出的3D姿态和检测到的2D姿态之间的几何一致性，同时保持准确的自接触。", "conclusion": "定性、定量和主观评价结果表明，本模型在草图到姿态任务中的估计准确性和速度上明显超过了以前的方法。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26149", "html_url": "https://arxiv.org/abs/2510.26149", "title": "BasicAVSR：通过图像先验和增强的运动补偿实现任意尺度视频超分辨率", "title_en": "BasicAVSR: Arbitrary-Scale Video Super-Resolution via Image Priors and Enhanced Motion Compensation", "authors": "Wei Shang,Wanying Zhang,Shuhang Gu,Pengfei Zhu,Qinghua Hu,Dongwei Ren", "background": "AVSR旨在提高视频帧的分辨率，可能在不同的放大倍数下进行。这提出了几个挑战，包括空间细节的再现、时间一致性以及计算复杂性。现有的方法难以同时解决这些挑战。", "innovation": "作者提出了一种名为BasicAVSR的基本框架，结合了四个关键组件：1) 基于图像拉普拉斯金字塔的自适应多尺度频率先验；2) 流向指导传播单元，用于从相邻帧中聚合时空信息；3) 第二秩序运动补偿单元，以更精确地对齐相邻帧；4) 超采样单元，生成尺度感知且内容无关的超采样核。此外，作者还实例化了三种不同的传播变体，以适应不同的应用场景，包括严格在线推理、容忍小输出延迟的有限预测以及用于计算资源较少受限的离线任务的双向RNN单元。Experimental结果显示，BasicAVSR在超分辨率质量、泛化能力和推理速度方面均显著优于现有方法。", "conclusion": "本工作不仅推进了AVSR领域的技术前沿，而且还将其核心组件扩展到多个框架中，以适应各种场景。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26203", "html_url": "https://arxiv.org/abs/2510.26203", "title": "开发用于供应链可持续性与风险管理的多任务集成几何深度网络", "title_en": "Developing a Multi-task Ensemble Geometric Deep Network for Supply Chain Sustainability and Risk Management", "authors": "Mehdi Khaleghi,Nastaran Khaleghi,Sobhan Sheykhivand,Sebelan Danishvar", "background": "供应链的可持续性对于实现供应链的最优性能至关重要，而应对供应链中出现的风险是提高网络可持续性和提升供应链绩效效率的关键问题。正确的分类产品是可持续供应链中的另一个重要元素。近年来，深度网络在供应链数据集分析方面的进展催生了多种架构选项，研究采用了一种新颖的几何深度网络来提议集成深度网络，通过Ch-EGN（Ch-EGN是一种混合卷积和几何深度学习的网络）分析供应链数据集，以获取数据库中样品的潜在状态。", "innovation": "本文通过提出Ch-EGN，采用几何深度网络结合卷积和深度学习的混合模型，用于风险管理和供应链可持续性的增强。该模型在两个不同的数据库SupplyGraph Dataset和DataCo上验证了其功能。对于DataCo供应链的交付状态预测、产品分类和边缘分类在SupplyGraph数据库中进行了处理，以提高供应链网络的可持续性。", "conclusion": "实验结果表明，集成网络在风险管理中达到了98.95%的平均准确率。在5个产品组分类和4个产品关系分类中，可持续供应链的平均准确率分别为100%和98.07%，在25家公司关系分类中，准确率为92.37%。结果证明了提出的方法相比现有方法在改进和效率上的平均提升。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26140", "html_url": "https://arxiv.org/abs/2510.26140", "title": "FullPart：在全分辨率生成每个3D部件", "title_en": "FullPart: Generating each 3D Part at Full Resolution", "authors": "Lihe Ding,Shaocong Dong,Yaokun Li,Chenjian Gao,Xiao Chen,Rui Han,Yihao Kuang,Hong Zhang,Bo Huang,Zhanpeng Huang,Zibin Wang,Dan Xu,Tianfan Xue", "background": "3D部件生成在多种应用中具有巨大潜力。过去基于隐式的向量集合标记的部件生成方法常常由于几何细节不足而表现不佳。另一方面，使用显式体素表示的方法虽然每个部件有自己的体素网格，但所有部件共享一个全局体素网格，这会导致小型部件体素不足，从而降低质量。研究提出了FullPart，这是一种结合了隐式和显式范式的新型框架，通过隐式的盒子向量集合扩散过程推导出边界框布局，并且每个部件在其自己的固定全分辨率体素网格中生成详细的部件，改善了细节生成的质量。此外，还提出了一种中心点编码策略，以解决不同实际尺寸的部件之间信息交换时导致的对齐问题，从而保持全局一致性。", "innovation": "FullPart框架结合了隐式表示和显式表示的优点。它首先通过隐式盒向量集扩散过程推导出边界框布局，然后每个部件在其自己的固定全分辨率体素网格中生成详细的部件，确保即使是小型部件也能在全分辨率上生成。此外，还提出了一种中心点编码策略来解决不同实际尺寸的部件之间信息交换时的对齐问题。为了应对可用的可靠的高分辨率部件数据稀缺问题，提出了PartVerse-XL，这是目前最大的人工注释的3D部件数据集，包含4万个物体和32万个部件。", "conclusion": "广泛的实验表明，FullPart在3D部件生成方面达到了最先进的水平。所有代码、数据和模型将对外开放，以促进未来在3D部件生成领域的研究。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26268", "html_url": "https://arxiv.org/abs/2510.26268", "title": "基于人类认知规律重访生成红外与可见光图像融合", "title_en": "Revisiting Generative Infrared and Visible Image Fusion Based on Human Cognitive Laws", "authors": "Lin Guo,Xiaoqing Luo,Wei Xie,Zhancheng Zhang,Hui Li,Rui Wang,Zhenhua Feng,Xiaoning Song", "background": "现有的红外和可见光图像融合方法往往难以平衡不同模态的信息。生成性融合方法通过学习数据分布来重建融合图像，但其生成能力有限。此外，模态信息选择缺乏解释性，这在复杂场景中进一步影响了融合结果的可靠性和一致性。", "innovation": "本文受到人类认知法则的启发，重新探讨了生成性图像融合的本质，并提出了一种新型的红外与可见光图像融合方法，称为HCLFuse。首先，HCLFuse研究了无监督融合网络中的信息映射量化理论，设计了一个多尺度掩码调节变分瓶颈编码器。此编码器进行后验概率建模和信息分解，提取准确且简洁的低级模态信息，以支持生成高保真的结构细节。此外，扩散模型的概率生成能力与物理定律结合，形成一个时间变化的物理引导机制，该机制在不同阶段适应性调节生成过程，从而增强模型感知数据内在结构的能力，减少对数据质量的依赖。", "conclusion": "提出的融合方法在多个数据集上的定性定量评估中实现了最先进的融合性能，并显著提高了语义分割指标。这充分展示了生成性图像融合方法在增强结构一致性和细节质量方面的优势，这些方法以人类认知为灵感。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26292", "html_url": "https://arxiv.org/abs/2510.26292", "title": "超出模仿：基于流匹配的约束感知轨迹生成在端到端自动驾驶中的应用", "title_en": "Beyond Imitation: Constraint-Aware Trajectory Generation with Flow Matching For End-to-End Autonomous Driving", "authors": "Lin Liu,Guanyi Yu,Ziying Song,Junqiao Li,Caiyan Jia,Feiyang Jia,Peiliang Wu,Yandan Luo", "background": "端到端自动驾驶中，规划是关键组成部分。然而，目前流行的模仿学习方法容易出现模式崩溃问题，无法产生多样化的轨迹假设。现有的生成方法很难直接将重要的安全和物理约束融入生成过程，通常需要额外的优化阶段来精化它们的输出。", "innovation": "提出了CATG（通过约束流匹配的新型规划框架），它通过显式建模流匹配过程，自然地解决模式崩溃问题，并允许灵活地引导各种条件信号。CATG的核心创新是在流匹配过程中直接实施显式约束，确保生成的轨迹满足重要安全和运动规则。此外，CATG参数化驾驶激进性作为生成控制信号，允许精确操控轨迹风格。", "conclusion": "CATG在NavSim v2挑战中获得了第二名，EPDMS评分为51.31，并获得了创新奖。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26304", "html_url": "https://arxiv.org/abs/2510.26304", "title": "探索不同类型音乐与引发情绪之间的相关性：一项使用主观问卷和EEG的研究", "title_en": "Exploring the correlation between the type of music and the emotions evoked: A study using subjective questionnaires and EEG", "authors": "Jelizaveta Jankowska,Bożena Kostek,Fernando Alonso-Fernandez,Prayag Tiwari", "background": "本研究旨在探索不同类型音乐对人类情绪的影响。通过让参与者在听音乐时完成主观调查并使用EEG头盔测量脑电活动，研究团队希望能揭示不同音乐流派对情绪的影响。研究对象涵盖了不同性别和音乐偏好的多样群体，以捕捉更广泛的情绪反应。", "innovation": "通过整合主观问卷和EEG脑电测量技术来研究音乐对情绪的影响，这种方法能够更全面地理解情绪与脑电活动之间的关系。此外，研究对象的多样性使得结果更具普遍性。", "conclusion": "研究发现，情绪与观察到的脑电活动之间存在一定的关联性。不同类型的音乐会影响人们的情绪反应，表明音乐对情绪的调节作用是一个复杂但可研究的过程。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26241", "html_url": "https://arxiv.org/abs/2510.26241", "title": "时间流向何方？基于心理物理学的视觉-语言模型评估", "title_en": "Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models", "authors": "Shiho Matta,Lis Kanashiro Pereira,Peitao Han,Fei Cheng,Shigeru Kitazawa", "background": "现代的视觉-语言模型在多模态任务中表现出色，但在视频中的时间信息理解方面表现仍然较弱且未被充分评估。本文通过一个简单的却能揭示问题的关键挑战：判断短片段是正向播放还是反向播放，来探究这个问题。引入了一个心理物理学验证基准AoT-PsyPhyBENCH，用相同的人类实验刺激及行为基准测试视觉-语言模型能否从自然视频中推断出时间方向。全面评估公开和专有、推理类和非推理类视觉-语言模型后发现，大多数模型的表现接近随机猜测，甚至最佳模型在物理不可逆过程（如自由落体、扩散/爆炸）和因果手动动作（如拆分/合并）上的准确率也远低于人类的反应速度。这些结果揭示了当前多模态系统的一个基本缺陷：尽管能够捕获丰富的视觉-语义关联，但对于时间连续性和因果理解的归纳偏置仍不足。文章公开了AoT-PsyPhyBENCH的代码和数据，以促进视觉-语言模型在物理和时间推理能力上的进一步进展。", "innovation": "提出了一个简单但有效的“判断时间流向（AoT）”任务，通过这个任务揭示了视觉-语言模型在时间信息处理上的弱点。引入了AoT-PsyPhyBENCH基准测试，这是第一个基于人类反应行为的系统性评价基准，用于评估视觉-语言模型在视频中推断时间方向的能力。公开了代码和数据，以促进进一步的研究和进展。", "conclusion": "视觉-语言模型在视觉-语义关联上表现出色，但在时间连续性和因果理解方面存在明显不足。AoT-PsyPhyBENCH基准揭示了这一问题，并提供了改进的评测标准。希望未来的研究能提升视觉-语言模型在物理和时间推理上的能力。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26297", "html_url": "https://arxiv.org/abs/2510.26297", "title": "迈向真实地球观测星座调度：基准与方法", "title_en": "Towards Realistic Earth-Observation Constellation Scheduling: Benchmark and Methodology", "authors": "Luting Wang,Yinghao Xiang,Hongliang Huang,Dongjun Li,Chen Gao,Si Liu", "background": "地球观测卫星星座（AEOSs）提供了前所未有的灵活性来监测地球表面，但在大规模场景、动态环境和严格约束下，它们的调度仍然具有挑战性。现有方法通常简化这些复杂性，限制了它们在实际中的表现。现有基准套件和调度模型往往无法充分反映这些挑战。", "innovation": "我们提出了一个统一框架，结合标准化的基准套件和新颖的调度模型。基准套件AEOS-Bench包含3,907个优化的卫星资产和16,410个场景，每个场景包含1到50个卫星和50到300个成像任务。这些场景通过高度真实的模拟平台生成，确保了真实的卫星行为，如轨道动力学和资源限制。此外，我们还引入了AEOS-Former模型，这是一种基于Transformer的调度模型，包含一个约束感知的注意力机制，并通过模拟迭代学习适应各种场景，提出了一种应对AEOS星座调度问题的稳健解决方案。", "conclusion": "实验结果表明，AEOS-Former在任务完成和能量效率方面优于基线模型，消融研究还强调了各个组件的贡献。AEOS-Bench是第一个针对真实星座调度的大规模基准套件，AEOS-Former为AEOS星座调度提供了一种可靠性高的解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26315", "html_url": "https://arxiv.org/abs/2510.26315", "title": "基于证据理论的CNN和ViT桥梁框架用于糖尿病视网膜病变分级", "title_en": "A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading", "authors": "Junlai Qiu,Yunzhu Chen,Hao Zheng,Yawen Huang,Yuexiang Li", "background": "糖尿病视网膜病变（DR）是中老年人视力丧失的主要原因，严重影响其日常生活和心理健康。为了提高临床筛查效率并实现糖尿病视网膜病变的早期检测，基于卷积神经网络（CNN）或视觉变换器（ViT）的自动化诊断系统得到了广泛研究和应用。然而，由于CNN和ViT自身存在的局限性，单一类型骨干网的方法已经达到了性能瓶颈。一种潜在的改进方法是结合不同类型的骨干网，充分发挥它们各自的优势（即CNN的局部特征提取能力和ViT的整体特征捕获能力）。", "innovation": "本文提出了一种新的基于证据理论的特征融合范式，用于有效融合不同骨干网提取的特征。具体而言，该范式通过一系列深度证据网络将不同骨干网的特征转换为支持证据，用这些证据形成的聚合意见可以自适应地调整不同骨干网之间的融合模式，从而提高我们的混合模型性能。该方法已在两个公开的糖尿病视网膜病变分级数据集上进行评估。实验结果表明，该混合模型不仅提高了糖尿病视网膜病变分级的准确性，而且为特征融合和决策提供了出色的可解释性。", "conclusion": "本文提出的方法提高了糖尿病视网膜病变分级的准确性和可解释性，有效利用了CNN和ViT的优势，为糖尿病视网膜病变的自动化诊断提供了新的解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26213", "html_url": "https://arxiv.org/abs/2510.26213", "title": "OmniLayout: 通过LLM实现从粗到细学习的通用文档布局生成", "title_en": "OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation", "authors": "Hengrui Kang,Zhuangcheng Gu,Zhiyuan Zhao,Zichen Wen,Bin Wang,Weijia Li,Conghui He", "background": "文档AI技术迅速发展，吸引了越来越多的关注。尽管大多数研究集中在文档布局分析（DLA）上，其生成方面的文档布局生成却鲜有探索。主要障碍在于多样化布局的缺乏：现有的研究主要集中在具有曼哈顿风格结构的学术论文上，而像报纸和杂志这样的开放世界体裁却严重缺位。为弥补这一空白，论文提出了OmniLayout-1M，这是首个包含多种常见文档类型的百万级多样化文档布局数据集，涵盖了来自多个来源的现代布局。此外，现有的方法在复杂领域往往难以应对，常常无法很好地排列长序列，因此论文引入了OmniLayout-LLM，一种具有设计好的粗到细学习范式的0.5B模型：1) 利用OmniLayout-1M中的大型类别定义学习通用布局原则，并2) 通过细粒度标注将知识转移到特定领域中。", "innovation": "论文通过两个创新点突破了现有文献的局限：1) 提出了包含多种常见文档类型的百万级多样化文档布局数据集OmniLayout-1M，解决了多样化布局数据匮乏的问题；2) 引入了OmniLayout-LLM，一种新的LLM模型，采用了粗到细的学习范式，能够从多种文档类型的通用布局原则知识中进行迁移学习，适用于复杂领域。", "conclusion": "论文在M$^{6}$Doc数据集上的广泛实验表明，该方法在多个领域中表现强劲，显著优于现有的布局生成专家和多个最新的通用LLM。我们将会公开发布我们的代码、模型和数据集。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26282", "html_url": "https://arxiv.org/abs/2510.26282", "title": "探索不同距离下用于 periocular 验证的 CNNs 的互补性与可解释性", "title_en": "Exploring Complementarity and Explainability in CNNs for Periocular Verification Across Acquisition Distances", "authors": "Fernando Alonso-Fernandez,Kevin Hernandez Diaz,Jose M. Buades,Kiran Raja,Josef Bigun", "background": "本文研究不同 CNNs 在 UBIPr 数据库中用于 periocular 验证时的互补性，特别是在不同距离的数据下的表现。研究基于 VGGFace2 的大量眼部图像训练三种不同复杂度的 CNN 架构（SqueezeNet、MobileNetv2 和 ResNet50）。并通过余弦相似度和卡方距离指标分析了网络的性能，比较了不同的网络初始化方法，并使用逻辑回归进行评分级融合，还采用了 LIME 热图和 Jensen-Shannon 散度来比较 CNN 的注意模式。研究表明，尽管 ResNet50 在独立测试中表现最佳，但融合多个网络提供了显著的性能提升，这一点在融合所有三种网络时尤其明显。热图显示，网络通常关注给定图像的不同区域，这解释了它们的互补性。", "innovation": "引入了对 periocular 验证中 CNNs 互补性的研究，特别是在不同距离的数据下。采用逻辑回归进行评分级融合，并使用 LIME 热图和 Jensen-Shannon 散度来比较 CNN 的注意模式，以探索网络间的互补性。此外，通过融合方法显著提高了性能，特别是在融合所有三种网络时。", "conclusion": "本文的方法在 UBIPr 数据集上显著优于先前的工作，达到了新的状态最先进水平。热图表明，网络通常关注给定图像的不同区域，这解释了它们的互补性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26294", "html_url": "https://arxiv.org/abs/2510.26294", "title": "通过面部裁剪利用大规模人脸数据集实现深度眼周识别", "title_en": "Leveraging Large-Scale Face Datasets for Deep Periocular Recognition via Ocular Cropping", "authors": "Fernando Alonso-Fernandez,Kevin Hernandez-Diaz,Jose Maria Buades Rubio,Josef Bigun", "background": "研究集中在眼周生物特征识别，尤其是眼周区域，该区域具有高度鉴别性和较低的采集约束。现有研究通常依赖小规模的眼周数据集进行训练，只有几千张图像。本文使用来自大规模VGGFace2数据库的1,907,572张眼部图像来进行三种不同深度和复杂度的卷积神经网络架构的训练和评估，这与现有研究形成了鲜明对比。实验使用了VGGFace2-Pose和UFPR-Periocular两个数据集，分别包含自然环境下的面部图像和通过移动设备拍摄的有用户引导的眼周图像。由于VGGFace2中的图像采集条件控制不佳，眼周图像的错误接受率（EER）更高，而UFPR-Periocular数据集则由于更高的图像质量和更一致的采集协议，表现显著更好，EER低至1-2%.", "innovation": "本文利用大规模的VGGFace2数据库进行眼周识别任务的训练，这是现有研究中规模最大的眼周数据集。本文分别在自然环境下的VGGFace2-Pose和通过移动设备采集的UFPR-Periocular数据集上进行了实验，验证了不同深度和复杂度的卷积神经网络在眼周识别上的有效性，并且在UFPR-Periocular数据集上实现了迄今为止报道的最低错误接受率（EER）.", "conclusion": "由于眼周区域在VGGFace2中的采集条件较为复杂，得到的EER较高，而UFPR-Periocular数据集由于质量更高和采集协议更一致，结果非常理想，代表性EER仅为1-2%。未来可以通过改进数据采集条件来进一步提高眼周识别的性能."}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26339", "html_url": "https://arxiv.org/abs/2510.26339", "title": "GLYPH-SR：通过VLM指导的潜在扩散模型，我们能否同时实现高质量的图像超分辨率和高保真的文本恢复？", "title_en": "GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?", "authors": "Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang", "background": "图像超分辨率（SR）对于许多视觉系统至关重要，包括监控、自主驾驶、文档分析和零售分析，因为恢复高频细节，特别是场景内的文本信息，可以确保下游感知可靠进行。场景内的文本，如路标、产品标签和店铺招牌等嵌入自然图像中的文本，往往携带最行动性的信息；当字符模糊或无法识别时，光学字符识别（OCR）和后续决策会失败，尽管图像的其余部分看起来清晰。然而，过往的SR研究往往是为了失真（PSNR/SSIM）或学习感知度量（LIPIS、MANIQA、CLIP-IQA、MUSIQ）而优化的，这些度量标准在字符级错误方面显得不够敏感。此外，针对文本SR的研究往往聚焦于简化基准，只包含孤立的字符，忽视了复杂自然场景内文本的挑战。因此，场景文本实际上被当作通用纹理来处理。为了使SR在实际部署中有效，必须明确地优化文本可读性和感知质量两者。", "innovation": "GLYPH-SR提出了一种基于视觉语言指导的扩散框架，旨在同时实现这两项目标。该框架利用由OCR数据引导的文本-SR融合控制网络（TS-ControlNet）和一个交替文本中心和场景中心指导的乒乓调度器。这些组件通过合成语料库进行训练，而主要的SR分支则保持固定。GLYPH-SR利用此类组件在x4和x8的SVT、SCUT-CTW1500和CUTE80基准上得到改进，OCR F1提高了15.18个百分点，同时保持与MANIQA、CLIP-IQA和MUSIQ相当的竞争水平。", "conclusion": "GLYPH-SR设计满足同时高可读性和高视觉现实性的双重目标，实现看起来正确且显示正确的SR结果。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26412", "html_url": "https://arxiv.org/abs/2510.26412", "title": "LoCoT2V-Bench：长期和复杂文本到视频生成的基准", "title_en": "LoCoT2V-Bench: A Benchmark for Long-Form and Complex Text-to-Video Generation", "authors": "Xiangqing Zheng,Chengyue Wu,Kehai Chen,Min Zhang", "background": "近期，文本到视频生成在生成短暂、高质量片段方面取得了显著进展，但在处理复杂提示时，评估长时间输出仍是一个重大挑战。现有基准主要依赖简化的提示，侧重于低级指标，忽视了与提示的精细对齐及叙事连贯性和主题表达等抽象维度。", "innovation": "本文提出了一种专门针对复杂输入条件下长期视频生成（LVG）的基准——LoCoT2V-Bench。它基于各种真实视频，引入了包含场景过渡和事件动态等元素的现实且复杂的提示，构建了一个包含事件级对齐、细粒度时间一致性、内容清晰度及我们的新提出的人类期望实现度（HERD）等多维度评估框架。此框架用于全面评估九种代表性LVG模型，揭示了当前方法在主题一致性、细粒度对齐和高级主题遵守等方面的不足之处。", "conclusion": "LoCoT2V-Bench 提供了一个全面且可靠的平台，用于评估长期复杂文本到视频生成，并指明了未来方法改进的关键方向。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26441", "html_url": "https://arxiv.org/abs/2510.26441", "title": "A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models", "title_en": "A-TPT: Angular Diversity Calibration Properties for Test-Time Prompt Tuning of Vision-Language Models", "authors": "Shihab Aaqil Ahamed,Udaya S.K.P. Miriya Thanthrige,Ranga Rodrigo,Muhammad Haris Khan", "background": "Test-time prompt tuning (TPT)技术作为一种无需依赖标记数据即可将大规模视觉-语言模型（VLMs）适应未见过的任务的技术，逐渐显现出其潜力。然而，当前TPT方法主要集中在通过最大化平均文本特征分散度或施加正交约束以鼓励角度分离来改进提示校准，但由于文本特征之间缺乏分散性可能会损害校准性能，这引起了关于VLMs的可靠性和安全性方面的担忧。", "innovation": "我们提出了A-TPT，这是一个新颖的TPT框架，引入了角度多样性以促进由相应可学习提示诱导的归一化文本特征的分布均匀性。这种均匀性通过最大化单位超球面上特征之间的最小成对角度距离来实现。我们的方法在广泛的实验中展示了比现有最佳TPT方法更低的总体平均校准误差，同时保持了相当高的准确性，并且在自然分布转移和医学数据集方面表现出更好的零样本校准性能。我们提供了全面的理论分析来阐明A-TPT的基础。", "conclusion": "这些结果突显了促进角度多样性以实现文本特征的良好分布的能力，可以显著提高VLM校准。我们的代码将公开提供。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26464", "html_url": "https://arxiv.org/abs/2510.26464", "title": "向细粒度的视觉语言对准迈进以改进少量样本异常检测", "title_en": "Towards Fine-Grained Vision-Language Alignment for Few-Shot Anomaly Detection", "authors": "Yuanting Fan,Jun Liu,Xiaochen Chen,Bin-Bin Gao,Jian Li,Yong Liu,Jinlong Peng,Chengjie Wang", "background": "现有的少量样本异常检测（FSAD）方法依赖预训练的视觉-语言模型（VLM）通过文本描述和图像特征之间的相似性来识别潜在的异常区域。但由于缺乏详细的文本描述，这些方法只能预先定义图像级别的描述来匹配每个视觉补丁令牌，从而导致图像描述和补丁级别的视觉异常之间存在语义不匹配，导致子优化的定位性能。", "innovation": "提出了一种多级细粒度语义描述（MFSC）来提供细粒度的文本描述，并通过自动生成管道将其应用于现有的异常检测数据集。基于MFSC，提出了一种名为FineGrainedAD的新框架来改进异常定位性能，该框架包括两个组件：多级可学习提示（MLLP）和多级语义对准（MLSA）。MLLP通过自动替换和拼接机制，引入细粒度语义到多级动态提示中，而MLSA设计区域聚合策略和多级对准训练，以促进可学习提示更好地与相应的视觉区域对齐。", "conclusion": "实验表明，所提出的FineGrainedAD在MVTEC-AD和VisA数据集的少量样本设置中实现了整体性能的显著提升。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26474", "html_url": "https://arxiv.org/abs/2510.26474", "title": "通过头部尾部重新平衡对抗LVLMs自我提升中的马太效应", "title_en": "Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing", "authors": "Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "自提升已成为提升大型视觉-语言模型（LVLMs）推理能力的主要范式，模型通过迭代探索和学习成功轨迹。然而，在这一过程中，模型在应对简单查询（即头部数据）时表现出色，但在处理复杂查询（即尾部数据）时则能力不足。这种不平衡导致优化偏向于简单推理技能，而妨碍了模型处理复杂推理任务的能力。随着迭代次数的增加，这种不平衡变得更加明显，我们称之为“马太效应”，最终阻碍了模型的进一步改进并导致了性能瓶颈。", "innovation": "我们提出了四种有效的策略，从分布重新塑造和轨迹重采样的两个角度出发，以便在探索-学习自提升过程中实现头部与尾部的重新平衡。通过在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型上的视觉推理任务中进行广泛实验，我们的方法一致地提高了视觉推理能力，与传统的自提升方法相比，平均提高了3.86个点。", "conclusion": "我们的研究揭示了LVLMs自我提升过程中面临的马太效应，并提出了解决这一问题的方法，通过头部尾部重新平衡策略显著提升了模型的视觉推理能力。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26580", "html_url": "https://arxiv.org/abs/2510.26580", "title": "零样本实时场景推理使用视觉-语言对齐的方法", "title_en": "Dynamic Context-Aware Scene Reasoning Using Vision-Language Alignment in Zero-Shot Real-World Scenarios", "authors": "Manjunath Prasad Holenarasipura Rajiv,B. M. Vidyavathi", "background": "在现实环境中，AI系统经常面临缺乏标签数据的未知场景，这对传统的场景理解模型造成了挑战。这限制了基于视觉的应用程序在动态、非结构化设置中的部署。本文探讨了零样本实时场景推理的方法，通过视觉-语言对齐来处理未知场景。", "innovation": "本文提出了一个动态上下文感知场景推理框架，该框架利用视觉-语言对齐来解决零样本实时场景。该框架结合了预训练的视觉转换器和大型语言模型，使视觉语义与自然语言描述对齐，增强上下文理解。动态推理模块通过结合全局场景线索和对象级交互来细化预测，由语言先验指导。", "conclusion": "实验结果表明，这种方法在复杂的未知环境中比基线模型提高了18%的场景理解精度。并且，在选择性模糊或杂乱的场景中表现出强大性能，由于视觉和语言的协同融合。该框架提供了可扩展且可解释的上下文感知推理方法，推动了动态现实世界中的零样本泛化的进展。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26582", "html_url": "https://arxiv.org/abs/2510.26582", "title": "CATCH: 一种具有钩子的模块化跨域自适应模板", "title_en": "CATCH: A Modular Cross-domain Adaptive Template with Hook", "authors": "Xinjin Li,Yulie Lu,Jinghan Cao,Yu Ma,Zhenglin Li,Yeyang Zhou", "background": "视觉问答（VQA）模型在自然图像领域取得了显著性能，但当应用于遥感、医学影像或数学图表等离域场景时，由于分布上的巨大变化和缺乏有效的领域适应机制，其泛化能力显著下降。现有方法通常依赖于特定领域的微调或定制管道，这些方法成本高、不灵活且不易扩展。", "innovation": "本文提出了一种插件式框架CATCH，用于改善VQA模型的跨域适应性，同时最小化对核心架构的改动。CATCH通过细粒度分离视觉和语言适应，引入了领域分类器和双重适配机制，包括提示适配器和视觉适配器，两者通过统一的钩子接口动态注入，无需重新训练主干模型。", "conclusion": "实验结果表明，CATCH在四个特定领域的VQA基准测试上实现了可重复的性能提升，包括MathVQA上的+2.3 BLEU，MedVQA-RAD上的+2.6 VQA，以及ChartQA上的+3.1 ROUGE，证明了CATCH在多域VQA中的可扩展性和延展性，使其能够在多种应用领域中实现实际部署。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26509", "html_url": "https://arxiv.org/abs/2510.26509", "title": "基于粒子群优化的细胞自动机边缘检测器的鲁棒性分析", "title_en": "Analysis of the Robustness of an Edge Detector Based on Cellular Automata Optimized by Particle Swarm", "authors": "Vinícius Ferraria,Eurico Ruivo", "background": "边缘检测任务在图像处理中至关重要，旨在从图像中提取相关信息。但在实际操作中，许多检测器都存在一些弱点，如难以检测细弱边缘和缺乏特定问题的上下文信息来提取相关数据。因此，为了克服这些局限性，本文采用二维细胞自动机并对该检测器进行了优化，结合了元启发式算法和迁移学习技术，以适应不同图像的特性。文章的目标是通过扩展优化阶段的搜索空间来分析模型在自然图像集合及其特定子集中的识别鲁棒性。研究发现，对于选定的图像集合，扩展优化阶段的搜索空间并不有效，同时，迁移学习技术对模型的适应性和性能也没有显著改进。", "innovation": "本文介绍了一种基于二维细胞自动机的可适应边缘检测器，并结合了粒子群优化(PSO)和迁移学习技术来改进图像检测性能。其创新点在于提出了一个新的优化策略，通过调整搜索空间来提高模型的鲁棒性和适应性。这种方法旨在改善边缘检测器在检测细弱边缘和处理特定上下文信息方面的性能缺陷。", "conclusion": "通过对多个自然图像集合进行实验和验证，研究发现扩展优化阶段的搜索空间并不能显著提高模型性能。尽管进行了迁移学习技术的应用，但模型的总体适应性和性能并没有明显改进。这表明科学地控制优化搜索空间大小和合理选择迁移学习方法对于提高边缘检测器效果的重要性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26569", "html_url": "https://arxiv.org/abs/2510.26569", "title": "AdSum: 两流音频视觉总结化以实现自动视频广告剪辑", "title_en": "AdSum: Two-stream Audio-visual Summarization for Automated Video Advertisement Clipping", "authors": "Wen Xie,Yanjun Zhu,Gijs Overgoor,Yakov Bart,Agata Lapedriza Garcia,Sarah Ostadabbas", "background": "广告商通常需要对单个广告活动制作不同时长版本的同一广告（广告）。传统方法是手动选择和重新编辑长视频广告的片段以创建较短版本，这非常耗时且劳动密集。", "innovation": "本文提出了一种使用视频摘要技术的自动化视频广告剪辑框架。这是首次将视频剪辑作为剪辑镜头选择问题进行研究，专门针对广告。与现有主要关注视觉内容的通用视频摘要方法不同，我们的方法强调了音频在广告中的关键作用。为此，我们开发了一种双流音频-视觉融合模型来预测视频帧的重要性，重要性定义为该帧被选为公司制作的短广告的几率。此外，由于缺乏特定于广告的数据集，我们还提供了一个名为AdSum204的新数据集，包含102对30秒和15秒的广告片段，来自真实的广告活动。实验表明，我们的模型在各种评价指标上（如平均精度、曲线下的面积、Spearman和肯德尔）都优于最先进的方法。", "conclusion": "本文提出了AdSum框架，这是一种两流音频视觉融合模型，用于自动视频广告剪辑。通过一个新的广告特定数据集AdSum204，我们的模型在多个评价指标上优于现有最先进的方法。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26443", "html_url": "https://arxiv.org/abs/2510.26443", "title": "PointSt3R：通过3D基础对应关系进行点跟踪", "title_en": "PointSt3R: Point Tracking through 3D Grounded Correspondence", "authors": "Rhodri Guerrier,Adam W. Harley,Dima Damen", "background": "近年来，如DUSt3R和MASt3R等基础3D重建模型在静态场景中的2D和3D对应方面显示出巨大潜力。本文旨在利用这些模型进行点跟踪任务，特别是在3D定位对应方面。", "innovation": "提出了结合重建损失和动态对应训练头，细调MASt3R以使用少量合成数据进行点跟踪的方法。通过只训练和评估包含查询点的一帧对，去除了所有时间上下文的影响。这种方法在多种数据集上实现了可竞争或优越的点跟踪结果。", "conclusion": "通过结合动态和静态点对应，本文在四个数据集上（例如TAP-Vid-DAVIS和EgoPoints）实现了可竞争或优越的点跟踪结果，并且在RGB-S数据集上也显著超过了现有方法。还展示了在训练数据集和动态对应比例方面的消融实验结果。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26568", "html_url": "https://arxiv.org/abs/2510.26568", "title": "SA$^{2}$Net: Scale-Adaptive Structure-Affinity Transformation for Spine Segmentation from Ultrasound Volume Projection Imaging", "title_en": "SA$^{2}$Net: Scale-Adaptive Structure-Affinity Transformation for Spine Segmentation from Ultrasound Volume Projection Imaging", "authors": "Hao Xie,Zixun Huang,Yushen Zuo,Yakun Ju,Frank H. F. Leung,N. F. Law,Kin-Man Lam,Yong-Ping Zheng,Sai Ho Ling", "background": "脊柱分割对基于超声体积投影成像(VPI)的智能脊柱侧弯诊断至关重要，但这一任务面临几个重大挑战。首先，如果不考虑不同骨骼特征的高空间相关性，可能会忽略了骨骼的整体上下文知识。其次，脊柱骨骼包含丰富的关于其形状和位置的结构知识，值得被编码到分割过程中。针对这些挑战，提出了一种新颖的缩放自适应结构感知网络(SA$^{2}$Net)来有效实现脊柱分割。该网络通过多尺度自适应互补策略来学习脊柱图像的跨维度长距离相关特征，同时还引入了一种结构相关性变换来增强分割过程中的语义特征，并结合Transformer解码器进行结构感知推理。此外，还采用了一种特征混合损失聚合方法来增强模型训练，从而提高了分割过程的鲁棒性和准确性。实验结果表明，SA$^{2}$Net在脊柱分割领域的性能优于其他最新方法，特别是在各种骨干网络上的适应性表明其在智能脊柱图像分析用于高级脊柱侧弯诊断方面的潜力巨大。", "innovation": "提出了一种新颖的缩放自适应结构感知网络(SA$^{2}$Net)，其主要创新点包括：(1) 多尺度自适应互补策略来学习跨维度长距离相关特征；(2) 结构相关性变换，通过类特定的相关性来改进语义特征，并与Transformer解码器结合以进行结构感知推理；(3) 一种特征混合损失聚合方法以增强模型训练，改进了分割过程的鲁棒性和准确性；(4) 实现了对多种骨干网络的适应性，证明了其在智能脊柱图像分析中的潜力和前景。", "conclusion": "实验结果表明，我们的SA$^{2}$Net在脊柱分割任务上表现出了卓越的性能，超过了其他最新的方法。此外，SA$^{2}$Net在不同骨干网络上的适应性表明它有望成为用于高级脊柱侧弯诊断的智能脊柱图像分析工具的一个有价值的工具。该方法的代码和实验演示可以在提供的链接中找到。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26614", "html_url": "https://arxiv.org/abs/2510.26614", "title": "Spiking Patches: Asynchronous, Sparse, and Efficient Tokens for Event Cameras", "title_en": "Spiking Patches: Asynchronous, Sparse, and Efficient Tokens for Event Cameras", "authors": "Christoffer Koo Øhrstrøm,Ronja Güldenring,Lazaros Nalpantidis", "background": "现有的事件摄像头表示方法，如帧和体素，虽然准确率高，但牺牲了事件的异步性和空间稀疏性。作者指出，这些传统的表示方法无法充分利用事件摄像头的独特性质，他们需要一种能够保持异步性和空间稀疏性的新しい表示方法，以在保持准确性的同时提高效率。", "innovation": "提出了一种针对事件摄像头设计的事件分词方法，Spiking Patches，它可以保持事件的异步性和空间稀疏性。实验结果表明，与基于体素的分词方法相比，使用Spiking Patches的推理时间最多可以提高3.4倍，甚至在某些情况下还能提高准确率，分别为姿态识别和物体检测提供了3.8和1.4的绝对改进。", "conclusion": "事件分词为事件摄像头提供了新的方向，通过保持事件摄像头的特性，朝向更有效的方法迈进，并且这种方法还能在不牺牲准确性的前提下提高推理速度。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26601", "html_url": "https://arxiv.org/abs/2510.26601", "title": "ResMatching：基于引导条件流匹配的噪声鲁棒计算超分辨率", "title_en": "ResMatching: Noise-Resilient Computational Super-Resolution via Guided Conditional Flow Matching", "authors": "Anirban Ray,Vera Galinova,Florian Jug", "background": "计算超分辨率(CSR)在荧光显微镜中的应用，尽管这是一个病态问题，但已有很长的历史。其核心在于寻找一个先验来推测微图中从未被成像的频率。随着更好的数据驱动机器学习技术的出现，可以学习到更强的先验，从而提高CSR的结果。过去的CSR方法在低信噪比和复杂噪声情况下的表现不佳，尤其是在强先验难以学习的情况下效果更差。", "innovation": "ResMatching是一种使用引导条件流匹配来学习改进的数据先验的新CSR方法。它在BioSR数据集的4种不同生物结构上进行了评估，并与7个基线进行了对比。ResMatching在所有情况下都实现了最佳的数据保真度与感知现实性的权衡，且在噪声很大的低分辨率图像中表现尤为突出。此外，ResMatching还可以用于从隐式学习的后验分布中采样，该分布对所有测试用例都是校准的，能够提供像素级别的数据不确定性指标，引导未来用户拒绝不确定的预测。", "conclusion": "ResMatching通过引导条件流匹配学习改进的数据先验，能够克服强先验难以学习的问题，在噪声较大的情况下表现优秀，并提供了像素级别的数据不确定性指标，使未来用户能够获得更可靠的结果。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26583", "html_url": "https://arxiv.org/abs/2510.26583", "title": "Emu3.5: 自然多模态模型是世界学习者", "title_en": "Emu3.5: Native Multimodal Models are World Learners", "authors": "Yufeng Cui,Honghao Chen,Haoge Deng,Xu Huang,Xinghang Li,Jirong Liu,Yang Liu,Zhuoyan Luo,Jinsheng Wang,Wenxuan Wang,Yueze Wang,Chengyuan Wang,Fan Zhang,Yingli Zhao,Ting Pan,Xianduo Li,Zecheng Hao,Wenxuan Ma,Zhuo Chen,Yulong Ao,Tiejun Huang,Zhongyuan Wang,Xinlong Wang", "background": "介绍了Emu3.5，这是一个大规模的多模态世界模型，能够原生地在视觉和语言之间预测下一个状态。模型以统一的下一个令牌预测目标，在包含超过10万亿个令牌的视觉-语言交错数据集上进行端到端预训练，主要来自互联网视频的连续帧和转录。该模型自然地接受视觉-语言交错的输入，并生成视觉-语言交错的输出。通过大规模强化学习进一步微调，以增强多模态推理和生成能力。为了提高推理效率，提出了一种离散扩散适应（DiDA）技术，将按令牌解码转换为双向并行预测，从而提高单张图像的推理效率约20倍，同时不牺牲性能。Emu3.5展示了强大的原生多模态能力，包括长远期的视觉-语言生成、任意到图像生成(X2I)以及复杂的文本丰富图像生成。它还展示了通用的世界建模能力，使其能够在各种场景和任务中实现时空一致的世界探索和开放世界的身体化操纵。在图像生成和编辑等任务上，Emu3.5的性能与Gemini 2.5 Flash Image (Nano Banana)相当，且在一系列交错生成任务上取得了更好的结果。", "innovation": "1. 在包含超过10万亿个令牌的视觉-语言交错数据集上进行端到端预训练；\n2. 通过大规模强化学习进一步微调，以增强多模态推理和生成能力；\n3. 提出了离散扩散适应（DiDA）技术，将按令牌解码转换为双向并行预测，提高图像推理效率约20倍，同时不牺牲性能。", "conclusion": "Emu3.5展示了强大的原生多模态能力，包括长远期的视觉-语言生成、任意到图像生成(X2I)以及复杂的文本丰富图像生成。它还展示了通用的世界建模能力，使其能够在各种场景和任务中实现时空一致的世界探索和开放世界的身体化操纵。在图像生成和编辑等任务上，Emu3.5的性能与Gemini 2.5 Flash Image (Nano Banana)相当，且在一系列交错生成任务上取得了更好的结果。Emu3.5在项目网站提供了开源版本，以支持社区研究。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26466", "html_url": "https://arxiv.org/abs/2510.26466", "title": "代表级先验矫正以实现客观的零样本识别", "title_en": "Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition", "authors": "Pei Peng,MingKun Xie,Hang Hao,Tong Jin,ShengJun Huang", "background": "在视觉与语言模型中，对象-场景的直接联系仍然是一个持久的挑战，导致在测试场景与熟悉训练场景的共现情况不同情况下零样本识别的可靠性降低。", "innovation": "本文将此问题重新表述为因果推理问题，并提出一种新颖的方法来处理这种情况。该方法通过在CLIP的表示空间中估计对象和场景的期待值，并通过重新组合对象特征和来自外部数据集、批量邻居或文本描述的多样化替代场景，合成了反事实嵌入。通过估计总直接效应并模拟干预，该方法进一步减去只包含背景的激活，从而保持有益的对象-场景交互，同时缓解幻觉分值。", "conclusion": "在无需重新训练或提示设计的情况下，该方法在上下文敏感基准上的最差群体和平均准确性显著提高，建立了新的零样本最佳状态。除了性能提升，本文提供的框架还提供了一种轻量级的表示级反事实方法，为去bias和可靠的多模态推理提供了实用的因果途径。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26630", "html_url": "https://arxiv.org/abs/2510.26630", "title": "PT-DETR: 基于部分感知细节聚焦的小目标检测", "title_en": "PT-DETR: Small Target Detection Based on Partially-Aware Detail Focus", "authors": "Bingcong Huo,Zhiming Wang", "background": "为了应对无人机（UAV）物体检测中的挑战，如复杂的背景、严重的遮挡、密集的小物体以及变化的光照条件，本文提出了一种基于RT-DETR的新型检测算法PT-DETR，专门用于无人机图像中小物体的检测。", "innovation": "本文引入了Partially-Aware Detail Focus (PADF) 模块，以增强对小物体特征的提取。此外，设计了Median-Frequency Feature Fusion (MFFF) 模块，有效提高了模型捕捉小物体细节和上下文信息的能力。还结合了Focaler-SIoU，以增强模型的边界框匹配能力和对小物体特征的敏感度，进一步提高了检测的准确性和鲁棒性。相对于RT-DETR，PT-DETR在VisDrone2019数据集上实现了mAP分别提高1.6%和1.7%，同时具有较低的计算复杂度和更少的参数，证明了其在小物体检测任务上的鲁棒性和可行性。", "conclusion": "本文提出的PT-DETR算法在无人机图像中小物体检测任务中具有显著的鲁棒性和竞争力，相比之前的RT-DETR算法，具备更高的准确性和更低的计算复杂度。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26641", "html_url": "https://arxiv.org/abs/2510.26641", "title": "从像素、点和提示到下一代融合与多模态LLM/VLM在自动驾驶中的万物所需", "title_en": "All You Need for Object Detection: From Pixels, Points, and Prompts to Next-Gen Fusion and Multimodal LLMs/VLMs in Autonomous Vehicles", "authors": "Sayed Pedram Haeri Boroujeni,Niloufar Mehrabi,Hazim Alzorgan,Ahmad Sarlak,Mahlagha Fazeli,Abolfazl Razi", "background": "自动驾驶汽车（AVs）正在通过智能感知、决策和控制系统的进步改变未来的交通运输。然而，它们的成功依赖于可靠地在复杂多模态环境中检测物体的核心能力。尽管最近在计算机视觉（CV）和人工智能（AI）方面的突破取得了显著进展，但该领域仍面临着知识碎片化的关键挑战，尤其是在多模态感知、上下文推理和协同智能方面。", "innovation": "这篇综述论文填补了知识碎片化的空白，通过前瞻性的分析，强调新兴模式，如视觉语言模型（VLMs）、大型语言模型（LLMs）和生成型人工智能，而不是重新审视过时的技术。论文系统性地回顾了自动驾驶传感器的基本谱系（如相机、超声波、激光雷达和雷达），并对其融合策略进行了分析，不仅突出了这些传感器在动态驾驶环境中的能力和局限性，还展示了它们如何与基于LLM/VLM的感知框架中的最新进展相结合。", "conclusion": "通过综合这些观点，本文综述提供了一个清晰的路线图，概述了当前的能力、面临的开放挑战和未来的机会，特别是在下一代融合和多模态LLM/VLM在自动驾驶中的应用方面。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26609", "html_url": "https://arxiv.org/abs/2510.26609", "title": "CYPRESS: 基于卫星传感普瑞щи的编码器进行回归的作物产量预测", "title_en": "CYPRESS: Crop Yield Prediction via Regression on Prithvi's Encoder for Satellite Sensing", "authors": "Shayan Nejadshamsi,Yuanyuan Zhang,Shadi Zaki,Brock Porth,Lysa Porth,Vahab Khoshdel", "background": "准确及时的作物产量预测对于全球粮食安全以及现代农业管理至关重要。传统方法往往缺乏精细化农业所需的可扩展性和精细度。针对这一问题，本文介绍了一种名为CYPRESS（基于卫星传感普瑞しがの编码器进行回归的作物产量预测）的深度学习模型，该模型专为高分辨率、田间范围内油菜产量预测设计。CYPRESS利用了一个预训练的大型地理空间基础模型（Prithvi-EO-2.0-600M），并将其调整为连续回归任务，将多时相卫星图像转化为密集的像素级产量图。该模型在加拿大大平原的一个全面数据集上进行了评估，表明其在现有的基于深度学习的产量预测模型中具有更优的性能，凸显了基础模型微调对于针对特殊农业应用的有效性。通过提供连续、高分辨率的输出，CYPRESS比传统的分类或县市级汇总方法提供了更具操作性的工具。这项工作验证了一种新的方法，该方法填补了大规模地球观测与农场所做决策之间的差距，提供了一个可扩展的详细农业监测解决方案。", "innovation": "该模型利用一个预训练的大型地理空间基础模型（Prithvi-EO-2.0-600M），并将其调整为连续回归任务，从而将多时相卫星图像转化为密集的像素级产量图。这种基础模型的微调方法提高了高性能和可操作性，适用于精准农业领域。其模型在现有深度学习模型中表现更优，强调了这种方法在特殊农业应用中的有效性。并且提供了连续、高分辨率的输出，使得该工具更有操作性。", "conclusion": "CYPRESS验证了一种将大规模地球观测与农场所做决策相结合的新方法，提供了更为详细的农业监测解决方案，适用于高分辨率、田间范围内油菜产量预测，为全球粮食安全与精准农业提供了新的技术支撑。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26681", "html_url": "https://arxiv.org/abs/2510.26681", "title": "通过场景上下文提高遮挡物体分类", "title_en": "Improving Classification of Occluded Objects through Scene Context", "authors": "Courtney M. King,Daniel D. Leeds,Damian Lyons,George Kalaitzis", "background": "遮挡物体的存在对传统强大的物体识别算法构成了重大挑战，额外的信息来源可以显著减少由遮挡引起的错误。已知场景上下文有助于生物视觉中的物体识别。本文通过两种基于场景的信息融合技术，增强现有的 Region Proposal Network-Deep Convolutional Neural Network（RPN-DCNN）物体检测网络的鲁棒性，展示了在挑战数据集上的整体表现改进，尤其是在召回率和准确率方面。此外，实验对比了多种训练方法，发现同时使用遮挡和非遮挡图像的训练方法效果最佳。", "innovation": "提出了两种基于场景的信息融合技术，一种是在预测之前根据识别到的背景场景选择特定的对象网络，另一种是在检测之后融合场景知识到RPN的初步对象评分中。该方法提高了对部分遮挡物体的识别能力，并且训练方法的选择对模型性能有显著影响，提出的方法具有可解释性，易于适应其他数据集，为未来的研究和实际应用提供了多种方向。", "conclusion": "该方法在处理遮挡物体分类方面表现出改进，能够在挑战数据集上整体提高召回率和准确率。此外，通过对比多种训练方法发现，结合遮挡和非遮挡图像的训练方式最为有效。该方法具有很好的可解释性和适应性，为未来的相关研究和应用提供了广阔的空间。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26684", "html_url": "https://arxiv.org/abs/2510.26684", "title": "钢铁轧制厂的工艺集成计算机视觉在实时故障预测中的应用", "title_en": "Process Integrated Computer Vision for Real-Time Failure Prediction in Steel Rolling Mill", "authors": "Vaibhav Kurrey,Sivakalyan Pujari,Gagan Raj Gupta", "background": "本文介绍了在钢铁轧制厂中基于机器视觉的异常检测系统进行故障预测的长期部署研究。该系统利用工业相机实时监控设备操作、对齐和热棒运动，通过集中式视频服务器使用深度学习模型处理实时视频流，实现设备故障和过程中断的早期预测，从而减少非计划停机成本。", "innovation": "该集成系统利用传感器数据和视觉输入的联合分析，识别故障的准确位置和可能的根本原因，提供行动指导以进行预防性维护。服务端推理降低了对工业过程控制系统的计算负荷，支持生产线的可扩展部署，同时减少额外资源的需求。此系统相较于传统方法，提高了工业制造环境下的操作可靠性、生产效率和盈利能力。", "conclusion": "该系统通过实时监控和深度学习模型实现了设备的早期故障预测，减少了停机时间，优化了维护策略，增强了钢铁轧制厂的生产效率和经济性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26653", "html_url": "https://arxiv.org/abs/2510.26653", "title": "在北极区域基于RADARSAT-2的深度学习光学流可靠海冰漂流估算", "title_en": "Towards Reliable Sea Ice Drift Estimation in the Arctic Deep Learning Optical Flow on RADARSAT-2", "authors": "Daniela Martin,Joseph Gallego", "background": "准确估计海冰漂流对于北极航行、气候研究和实际预报至关重要。尽管计算机视觉技术中的光学流技术已经取得了快速进展，但其在地球物理问题及卫星SAR影像上的应用仍然是未知领域。传统光学流方法依赖于数学模型和强烈的运动假设，限制了其在复杂场景中的准确性。近年来基于深度学习的方法显著提高了性能，成为计算机视觉的行业标准，推动了其在海冰漂流估计中的应用。", "innovation": "本文首次对48个深度学习光学流模型在RADARSAT 2 ScanSAR海冰影像上的表现进行了大规模基准测试，评估结果使用端点误差(EPE)和Fl-all指标与GNSS跟踪的浮标进行对比。多个模型达到了亚千米精度（EPE 6到8像素，约300到400米），较小的误差相对应于海冰运动的空间尺度及北极航行的一般要求。结果显示，这些模型能够捕捉到一致的区域漂流模式，且相较于传统方法，最近基于深度学习的光学流方法在运动估计准确性上有显著提升，并可有效应用于极地遥感中。光学流方法可以提供连续的空间漂流场，从而提供每个影像像素的运动估计，而非稀疏的浮标位置，为导航和气候建模提供了新的可能性。", "conclusion": "基于RADARSAT-2的深度学习光学流方法能够可靠地估算海冰漂流，并揭示了连续的空间漂流场的新机会，从而为北极航行和气候模型提供更精确的信息。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26778", "html_url": "https://arxiv.org/abs/2510.26778", "title": "基于精心选择的U-Net架构和损失函数超越RGB视网膜图像中AMD区域估计的最新成果", "title_en": "Surpassing state of the art on AMD area estimation from RGB fundus images through careful selection of U-Net architectures and loss functions for class imbalance", "authors": "Valentyna Starodub,Mantas Lukoševičius", "background": "年龄相关性黄斑变性（AMD）是60岁以上人群导致不可逆视力损伤的主要原因之一。本研究旨在通过语义分割技术在RGB眼底图像中检测AMD病灶，这是一种无创且成本效益高的成像技术。ADAM挑战是目前最全面的RGB眼底图像AMD检测研究竞赛和开放数据集，其结果被用作评价基准。", "innovation": "本文基于U-Net连接作为框架基础，评估和比较了多种方法以改进分割模型的架构和训练流程，包括预处理技术、复杂程度不同的编码器（主干）深层网络类型以及专门用于缓解图像和像素级别类别不平衡的损失函数。最终框架在非侵入性RGB眼底图像的多类AMD病灶分割中超越了所有ADAM挑战的先前提交。", "conclusion": "本文最终的AMD检测框架在ADAM挑战的多类分割中表现优异，优于所有之前的ADAM挑战提交。此外，用于进行实验的源代码也已被公开。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26781", "html_url": "https://arxiv.org/abs/2510.26781", "title": "ChartAB: 一种用于图表定位与密集对齐的标准基准", "title_en": "ChartAB: A Benchmark for Chart Grounding & Dense Alignment", "authors": "Aniruddh Bansal,Davit Soselia,Dang Nguyen,Tianyi Zhou", "background": "图表在可视化、推理、数据分析以及人与人之间想法交流中起着重要作用。然而现有的视觉-语言模型（VLMs）在图表细节感知方面仍存在不足，并且难以从图表中提取精细的结构。这种图表定位的限制也阻碍了模型对多张图表之间的比较和推理的能力。", "innovation": "本文提出了一种新的“图表对齐基准（ChartAB）”来全面评估VLMs在图表定位任务中的表现，包括从不同类型的复杂图表中提取表格数据、定位可视化元素以及识别各种属性。通过引入一种新颖的两阶段推理工作流程，基准可以进一步评估模型在两个图表之间对齐和比较元素/属性的能力。通过对几种最近的VLMs的评估，揭示了它们在图表理解中的感知偏见、弱点、鲁棒性和幻觉。", "conclusion": "这些发现突出了VLMs在图表理解任务中微小差异的具体技能，并指出了当前模型需要加强的具体技能。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26694", "html_url": "https://arxiv.org/abs/2510.26694", "title": "3D Gaussian Splatting的影响与展望", "title_en": "The Impact and Outlook of 3D Gaussian Splatting", "authors": "Bernhard Kerbl", "background": "自引入以来，3D高斯点绘制（3DGS）迅速改变了3D场景表示的面貌，激发了大量的相关研究。后续研究包括对3DGS效率、可扩展性和实际应用的分析和贡献。", "innovation": "文中概述了几种新兴的关键方向，包括提高训练和渲染的资源效率，动态或四维（4DGS）表示的演变，以及加深对影响其外观建模和渲染过程的数学基础的理解。此外，进一步探讨了将其引入移动和虚拟现实平台、扩展到大规模环境的努力以及近期通过前馈或分布式计算的近瞬时辐射场重建的进展。", "conclusion": "这些发展表明，3DGS已从一种变革性的表示形式演变为3D视觉和图形领域的一种多功能和基础工具。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26799", "html_url": "https://arxiv.org/abs/2510.26799", "title": "掩码扩散图说法用于视觉特征学习", "title_en": "Masked Diffusion Captioning for Visual Feature Learning", "authors": "Chao Feng,Zihao Wei,Andrew Owens", "background": "该研究基于带有图像条件的掩码扩散语言模型进行图像配字，提出了称为掩码扩散图说法（MDC）的方法。训练过程中，随机选择比例的文本令牌被遮罩，然后在视觉特征上进行条件训练以重建原始文本。经过训练后，学习到的视觉特征可以应用于下游视觉任务。与其他自回归图说方法相比，MDC在视觉信号学习中的强度不依赖于每个令牌在序列中的位置，减少了辅助目标的需求。", "innovation": "该方法通过图像条件的掩码扩散语言模型学习视觉特征，这在训练阶段无需考虑每个令牌的位置，从而降低对辅助目标的需求。相较于自回归图说方法，MDC提升了视觉信号的学习强度，同时保持了竞争力。", "conclusion": "通过跨多种学术规模模型和数据集的线性探针实验，研究结果表明学习到的视觉特征与自回归和对比性方法生成的视觉特征具有竞争力。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26786", "html_url": "https://arxiv.org/abs/2510.26786", "title": "HEIR: 学习基于图的运动层次结构", "title_en": "HEIR: Learning Graph-Based Motion Hierarchies", "authors": "Cheng Zheng,William Koch,Baiang Li,Felix Heide", "background": "在计算机视觉、图形学和机器人等领域中，运动模式通常由更简单的运动组件间的协调交互产生复杂的动力学。现有的运动建模方法通常依赖于手动定义或启发式的固定运动基元层次结构，这限制了其在不同任务上的普遍适用性。现有的方法难以捕捉运动间的动态关联，从而限制了其应用场景的广泛性和通用性。", "innovation": "本文提出了一种通用的基于数据的运动层次建模方法，能够直接从数据中学习结构化、可解释的运动关系。该方法使用图结构来表示观察到的运动，将全球绝对运动分解为父节点传递的模式和局部运动残差。创新点在于将层次结构推断作为可微分的图学习问题，利用图形神经网络来捕捉学习到的父辈与子节点间的依赖关系。通过这种方式，该方法能够应用于1D平移运动、2D旋转运动以及动态3D场景变形等多种场景，实现出更真实和可解释的变形效果，相比基线模型有显著提升。", "conclusion": "通过提供一个可适应的数据驱动的层次建模框架，本文的方法为广泛的动力学任务提供了一种形式化描述。这种层次化建模为处理各类复杂的动力学关系提供了新的思路和可行性解决方案，具有广泛的潜力和应用前景。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26795", "html_url": "https://arxiv.org/abs/2510.26795", "title": "扩展图像地理定位至大陆级别", "title_en": "Scaling Image Geo-Localization to Continent Level", "authors": "Philipp Lindenberger,Paul-Edouard Sarlin,Jan Hosang,Matteo Balice,Marc Pollefeys,Simon Lynen,Eduard Trulls", "background": "在全球范围内精确确定图像的位置仍然是一个未解决的挑战。标准的图像检索技术因图像数量庞大（超过100M）且覆盖不足而效率低下。虽然可扩展的解决方案通常需要权衡，即全球分类通常会产生粗略的结果（10公里以上），而地面与航空图像之间的跨视角检索因领域差距而效果较差，并主要在较小的区域内进行研究。因此，本文提出了一种混合方法，能够在大陆大小的地理范围内实现精确的地理定位。该方法在训练过程中利用代理分类任务学习富含特征的表示，这些表示隐式地编码了精确的位置信息，并结合航空图像嵌入以增强对地面数据稀疏性的鲁棒性。", "innovation": "本文提出了一种混合方法，该方法能够在大陆尺度上实现精确的地理定位。通过在训练过程中利用代理分类任务来学习含有精细位置信息的特征表示，并结合航空图像嵌入以增强对地面数据稀疏性的鲁棒性。此方法能够直接在跨越多个国家的区域进行精细的检索。论文详尽的评估结果表明，该方法在涵盖欧洲大部分地区的数据集上有超过68%的查询能够在200米内准确定位。", "conclusion": "我们的方法能够在全球范围内实现精确的地理定位。通过在训练过程中学习含有精细位置信息的特征表示，并结合航空图像嵌入以提高对地面数据稀疏性的鲁棒性，我们的方法能够在大陆尺度上实现精细的图像地理定位，且在大数据集上的评估结果显示，该方法对查询的定位精度在200米内超过68%。코드已经在开源平台上公开供大家参考。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26796", "html_url": "https://arxiv.org/abs/2510.26796", "title": "SEE4D：基于自回归视频修复的无姿态4D生成", "title_en": "SEE4D: Pose-Free 4D Generation via Auto-Regressive Video Inpainting", "authors": "Dongyue Lu,Ao Liang,Tianxin Huang,Xiao Fu,Yuyang Zhao,Baorui Ma,Liang Pan,Wei Yin,Lingdong Kong,Wei Tsang Ooi,Ziwei Liu", "background": "现有的视频到4D的方法通常需要手动标注的摄像机姿态，这既耗时又在野外拍摄的片段中脆弱。最近的方法通过构建新颖的摄像机轨迹并使用修复模型填充缺失区域，省去了姿态标签的需求，但仍然需要假设相机运动与场景动态之间存在非线性关系，增加了建模和推理的复杂性。", "innovation": "提出SEE4D框架，这是一种无姿态、从轨迹到摄像机的框架，代替了明确的轨迹预测，而是将渲染到一组固定的虚拟相机上，从而分离了相机控制和场景建模。此外，设计了一种条件于视角的视频修复模型，通过修复真实合成的扭曲图像来学习鲁棒的几何先验，并修复虚拟视角中的遮挡或缺失区域，不再需要显式的三维标注。进一步构建了一个时空自回归推理管道，可以在保持每步复杂性受控的情况下生成连贯的视频。", "conclusion": "SEE4D方法在跨视角视频生成和稀疏重建基准测试中表现出了优越的泛化能力和优于基于姿态或轨迹条件基准的优势，促进了从普通视频中建模现实4D世界的实际应用。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26794", "html_url": "https://arxiv.org/abs/2510.26794", "title": "寻求可泛化的运动生成：数据、模型和评估", "title_en": "The Quest for Generalizable Motion Generation: Data, Model, and Evaluation", "authors": "Jing Lin,Ruisi Wang,Junzhe Lu,Ziqi Huang,Guorui Song,Ailing Zeng,Xian Liu,Chen Wei,Wanqi Yin,Qingping Sun,Zhongang Cai,Lei Yang,Ziwei Liu", "background": "尽管在标准基准上的3D人体动作生成（MoGen）取得了近期进步，现有的模型在泛化能力上依然存在根本性瓶颈。相比之下，邻近的生成领域，尤其是视频生成（ViGen），在建模人类行为方面表现出的泛化能力非常出色，这为MoGen提供了一些可转移的见解。", "innovation": "本文提出了一个全面的框架，系统地将ViGen的知识转移到MoGen中，涵盖了数据、建模和评估三方面。首先，引入了ViMoGen-228K大规模数据集，包含228,000个高质量的运动样本，结合了高保真光学MoCap数据、网络视频中的语义标注运动以及最先进的ViGen模型生成的合成样本。数据集包括文本-运动对和文本-视频-运动三元组，极大扩展了语义多样性。其次，提出了一种基于流匹配的扩散变换器ViMoGen，通过门控多模态条件将MoCap数据和ViGen模型的先验统一封装。为了提高效率，进一步制定了ViMoGen-light，这是一种去除视频生成依赖性的精简版本，但仍能保持强大的泛化能力。最后，提出了MBench，一种用于精细评估动作质量、提示保真度及泛化能力的层级基准。", "conclusion": "大量实验表明，本文提出的框架在自动和人工评估中均显著优于现有方法。相关代码、数据和基准将公开提供。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26769", "html_url": "https://arxiv.org/abs/2510.26769", "title": "SteerVLM：轻量级激活引导实现视觉语言模型的稳健模型控制", "title_en": "SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models", "authors": "Anushka Sivakumar,Andrew Zhang,Zaber Hakim,Chris Thomas", "background": "该工作介绍了SteerVLM，一种轻量级的引导模块，旨在指导视觉语言模型（VLMs）产生更符合所需指令输出的结果。该方法通过学习配对提示（编码目标和反例行为的潜在嵌入）的动态调整，使得语言模态与图像上下文之间的连接激活得以改变，从而实现复杂输出语义的精细控制，而无需修改模型权重。同时，该引导模块在不影响模型在与目标任务无关的任务表现的前提下，实现了在推理时的模型控制。该引导模块的大小仅为原始VLM的0.14%，并且通过维度上的激活调节和逐层自适应引导实现对模型的控制，而无需预先提取静态向量或手动调整干预点。此外，该研究还提出了支持VLM引导技术开发与评估的多模态数据集VNIA（Visual Narrative Intent Alignment）", "innovation": "SteerVLM通过学习配对提示的潜在嵌入，动态调整语言模态与图像上下文之间的连接激活，实现细粒度的、推理时的模型控制，而无需修改模型权重。该引导模块的参数大小仅相当于原VLM的一个很小的比例，同时通过维度上的激活调节和逐层自适应引导实现了对模型的控制。此外，该研究还首次提出了视觉叙事意图对齐（VNIA）数据集，专门用于支持VLM引导技术的开发与评估。SteerVLM的方法在视觉语言模型的引导和幻觉抑制基准测试中表现优于现有技术，并提出了一种通过激活工程实现多模态模型控制的稳健解决方案", "conclusion": "SteerVLM展示了对视觉语言模型进行细粒度、推理时控制的一种新方法，它通过轻量级的激活引导模块，使得模型能够在不影响其在非目标任务表现的前提下，实现复杂输出语义的自适应控制，并且该模块的参数量非常少。同时，该研究开发的VNIA数据集为视觉语言模型引导技术的发展和评估提供了支持。SteerVLM为多模态模型控制问题提供了一种新的解决方案，具有重要的理论与实际意义"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26800", "html_url": "https://arxiv.org/abs/2510.26800", "title": "OmniX:从统一的全景生成和感知到图形级3D场景", "title_en": "OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes", "authors": "Yukun Huang,Jiwen Yu,Yanning Zhou,Jianan Wang,Xintao Wang,Pengfei Wan,Xihui Liu", "background": "目前有两大主流的3D场景构建方法：程序生成和从2D提升。其中，基于全景的2D提升技术日益受到关注，该技术利用强大的2D先验生成模型生成沉浸式、逼真且多样的3D环境。该文基于此背景下，进一步研究全景的视觉感知和高保真3D场景生成。", "innovation": "本文提出了OmniX框架，这是一种通用且统一的三维建模系统。OmniX使用一种轻量级且高效的跨模态适配器结构，重新利用2D生成模型来解决全景感知、生成和完成任务。该框架不同于现有的2D提升方法，它不仅生成外观，还关注内在属性的感知。此外，作者构建了一个大规模的合成全景数据集，涵盖了来自各种室内外环境的高质量多模态全景图。", "conclusion": "实验表明，OmniX框架在全景视觉感知及具有渲染品质的3D场景生成方面具有有效性，为创建沉浸式和物理上真实的虚拟世界开辟了新途径。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26802", "html_url": "https://arxiv.org/abs/2510.26802", "title": "视频模型作为零样本推理者是否准备好？MME-CoF基准的实证研究", "title_en": "Are Video Models Ready as Zero-Shot Reasoners? An Empirical Study with the MME-CoF Benchmark", "authors": "Ziyu Guo,Xinyan Chen,Renrui Zhang,Ruichuan An,Yu Qi,Dongzhi Jiang,Xiangtai Li,Manyuan Zhang,Hongsheng Li,Pheng-Ann Heng", "background": "近期的视频生成模型能够生成高保真、时间连贯的视频，表明它们可能蕴含了大量的世界知识。除了现实合成之外，它们还表现出视觉感知、建模和操作的新兴行为。然而，一个重要的问题仍然存在：视频模型是否准备好在具有挑战性的视觉推理场景中作为零样本推理者使用？", "innovation": "本文通过实证研究，全面探讨了这一问题，主要针对领先的视频生成模型Veo-3进行评估。研究聚焦于12个维度，包括空间、几何、物理、时间和具体逻辑推理，系统地刻画了它们的优势和失败模式。研究还制定了MME-CoF基准，为复杂的链式框架推理评估提供了标准化的数据集。", "conclusion": "研究发现，当前的视频模型在短期空间连贯性、精细的语义标注和局部一致的动力学方面显示出有希望的推理模式，但它们在长期因果推理、严格的几何约束和抽象逻辑方面仍然受到限制。总体而言，视频模型尚不足以作为独立的零样本推理者，但它们作为专为推理设计的模型的补充视觉引擎表现出积极的迹象。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26022", "html_url": "https://arxiv.org/abs/2510.26022", "title": "基于物理启发式测试时自适应的分组配准在多参数心脏MRI中的应用", "title_en": "Groupwise Registration with Physics-Informed Test-Time Adaptation on Multi-parametric Cardiac MRI", "authors": "Xinqi Li,Yi Zhang,Li-Ting Huang,Hsiao-Huang Chang,Thoralf Niendorf,Min-Chi Ku,Qian Tao,Hsin-Jung Yang", "background": "多参数磁共振成像（MRI）已成为心肌组织表征的有效工具。然而，多参数映射图之间的对齐问题使得像素级的分析变得具有挑战性。", "innovation": "开发了一种通用的基于物理约束的深度学习模型，利用测试时自适应（test-time adaptation）来实现多种物理模型（如T1映射模型和T2映射模型）下对比加权图像的分组图像注册。该物理启发式自适应利用了特定物理模型的合成图像作为配准参考，支持不同组织对比度的归纳学习。", "conclusion": "该模型在健康志愿者中进行了验证，并通过多种MRI序列显示了其在宽范围图像对比度变化中多模态配准性能的改进。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识蒸馏（KD）是一种有效的方法，用于模型压缩和知识转移。然而，知识蒸馏对模型在处理分布外数据时抵御伪关联能力的影响仍然研究不足。本研究旨在探讨知识蒸馏对自然语言推理（NLI）和图像分类任务中教师模型向学生模型传递去偏能力的迁移性的影响。", "innovation": "研究通过广泛的实验，发现知识蒸馏会削弱模型的去偏能力，即使去偏训练后的模型也不能从教师的知识中受益，整体抵御能力可能保持稳定但不同类型偏见的影响变异显著。研究还指出了知识蒸馏后导致不同行为的内部注意力模式和电路。基于以上发现，提出了三种改善去偏方法蒸馏性的有效策略：开发高质量数据进行增补、实施迭代知识蒸馏、以及使用教师模型的权重初始化学生模型。", "conclusion": "这可能是第一项大规模研究知识蒸馏对去偏及其内部机制的影响。我们的研究结果提供了对知识蒸馏运作机制的理解，以及如何设计更好的去偏方法的理解。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26170", "html_url": "https://arxiv.org/abs/2510.26170", "title": "通过融合单目相机的全局和局部特征在3D地图上的自定位", "title_en": "Self-localization on a 3D map by fusing global and local features from a monocular camera", "authors": "Satoshi Kikuch,Masaya Kato,Tsuyoshi Tasaki", "background": "在实现自动驾驶时，需要使用廉价的单目相机在3D地图上进行自定位。基于相机的自定位通常利用卷积神经网络（CNN）提取由附近像素计算出的局部特征。然而，当存在动态障碍物（如行人）时，CNN的效果会变差。", "innovation": "本文提出了一种将CNN与Vision Transformer结合的新方法。Vision Transformer擅长提取全局特征，展示整个图像上补丁之间的关系。实验结果显示，与现有的最先进的方法（SOTA）相比，包含动态障碍物的CG数据集中的准确率提高了1.5倍，而无动态障碍物的数据集中的误差降低了20.1%。此外，使用本文方法的机器人平均定位误差为7.51cm，比SOTA更准确。", "conclusion": "本文方法在动态障碍物条件下提高了自定位的准确性，特别是在3D地图上能够更精确地实现自定位。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26141", "html_url": "https://arxiv.org/abs/2510.26141", "title": "StructLayoutFormer：基于结构序列化与解纠缠的条件结构化布局生成", "title_en": "StructLayoutFormer:Conditional Structured Layout Generation via Structure Serialization and Disentanglement", "authors": "Xin Hu,Pengfei Xu,Jin Zhou,Hongbo Fu,Hui Huang", "background": "在许多2D可视化内容（例如GUI和网页）中，结构化布局因其便于布局编辑而更加优选。现有的计算框架能够帮助创建结构化布局，但这些框架需要大量的劳动力投入。现有的数据驱动方法虽然能够自动生成固定布局，但无法生成包含结构信息的布局。该论文提出了一种新的基于Transformer的方法，名为StructLayoutFormer，用于条件结构化布局生成。该方法使用结构序列化方案将结构化布局表示为序列，并通过解纠缠结构信息与元素放置，使得生成的布局结构更加可控。", "innovation": "StructLayoutFormer是第一个能够实现条件结构化布局生成和显式生成合理布局结构的数据驱动方法。通过结构序列化方案和解纠缠示例放置，这种方法在条件结构化布局生成方面超越了现有数据驱动的布局生成方法。此外，该方法还展示了其在提取和转换布局结构方面的有效性。", "conclusion": "详细的实验表明，与现有基线方法相比，StructLayoutFormer在条件结构化布局生成上取得了更好的效果。该方法的代码已公开，并提供参考文献链接。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS：通过自蒸馏偏好冷启动解耦多模态学习", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "近年来，带有验证奖励的强化学习（RL）引发了一波被称为'MLLM-r1'的新方法，这种方法将RL引入到视觉语言模型中。大多数代表性方法都是从冷启动开始，通常通过监督微调（SFT）的方式来初始化策略，然后再进行RL。然而，基于SFT的冷启动方法在训练时交织了任务解决和输出格式的推理过程，这可能会导致指令风格的过拟合，降低对新分布外样本的泛化能力，从而影响后续的RL效果。本文从两个角度审视冷启动方法，即其训练方法和数据构建，并引入了通用因子（GF）系数来量化不同方法下的泛化能力。", "innovation": "本文提出了一个名为SPECS（Self-distilled, Preference-based Cold Start）的框架，这是一种通过自蒸馏偏好冷启动来解耦多模态学习的方法。具体来说，SPECS框架包含以下三个部分：（1）通过自蒸馏生成内省偏好数据对，避免依赖于更大的教师或手动标注；（2）进行基于偏好的训练，聚焦于浅层、可迁移的表现形式标准（格式、结构、风格），而非记忆内容；（3）将具备验证奖励的强化学习用于深度推理结果。在多个多模态基准上的实验结果表明，我们的解耦学习框架在强基线的基础上一直能够获得一致的性能提升，如在MEGA-Bench上提高4.1%和MathVista上提高12.2%。此外的实验进一步表明，SPECS有助于减少分布内“卡顿”，增强了探索性，稳定了训练过程，并提升了性能上限。", "conclusion": "本文通过引入SPECS框架，提出了一个基于自蒸馏偏好的冷启动方法，通过解耦多模态学习过程，在多个数据集上展示了相较于基线的稳健性能提升，表明了这种方法的有效性和潜力。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26004", "html_url": "https://arxiv.org/abs/2510.26004", "title": "DARTS:基于无人机的人工智能驱动实时道路交通事件检测系统", "title_en": "DARTS: A Drone-Based AI-Powered Real-Time Traffic Incident Detection System", "authors": "Bai Li,Achilleas Kourtellis,Rong Cao,Joseph Post,Brian Porter,Yu Zhang", "background": "快速而可靠的事件检测对于减少事故相关的伤亡、受伤和交通拥堵至关重要。然而，传统的检测方法，如闭路电视、司机记录仪和基于传感器的检测，存在检测与验证分离、灵活性有限、需要密集的基础设施或高渗透率的问题，这限制了对不断变化的事件热点的适应性和可扩展性。", "innovation": "为了解决这些挑战，我们开发了DARTS，一种基于无人机的人工智能驱动的实时道路交通事件检测系统。DARTS集成了无人机的高机动性和空中视角，用于自适应监视，利用热成像技术提高低能见度表现和隐私保护，并采用轻量级的深度学习框架进行实时车辆轨迹提取和事件检测。该系统在自采集的数据集上实现了99%的检测精度，并支持通过基于Web的界面进行实时的视觉验证、事态严重性评估和因事件引起的交通拥堵传播监控。在佛罗里达州的I-75高速公路实地测试中，DARTS比当地交通管理中心提前12分钟检测并验证了一起追尾事故，监控了事件引起的交通拥堵传播，这表明DARTS可能有助于更快的应急响应，以及通过主动交通控制减少交通堵塞和次生事故风险。关键在于，DARTS灵活的部署架构减少了频繁物理巡逻的依赖，表明其可能在远程地区和资源有限的环境中具有可扩展性和成本效益。", "conclusion": "本研究提出了一个更灵活集成的实时道路交通事件检测系统的有希望的步骤，对现代交通管理的操作效率和响应能力具有重要意义。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26358", "html_url": "https://arxiv.org/abs/2510.26358", "title": "AgriGS-SLAM: 全季果园建图的多视角高斯点积SLAM方法", "title_en": "AgriGS-SLAM: Orchard Mapping Across Seasons via Multi-View Gaussian Splatting SLAM", "authors": "Mirko Usuelli,David Rapado-Rincon,Gert Kootstra,Matteo Matteucci", "background": "自主机器人在果园中需要实时理解和处理3D场景，尽管存在重复的行几何结构、季节性外观变化以及风引起的树叶运动等问题。", "innovation": "提出了一种结合直接LiDAR 外推和环视闭合与多相机3D高斯点积（3DGS）渲染的AgriGS-SLAM 视觉-LiDAR SLAM 框架。框架通过互补视角批处理绘制来恢复在遮挡下的果园结构，并在关键帧之间执行统一的梯度驱动地图生命周期，以保持细节并限制内存。通过LiDAR概率深度一致性项引导姿态细化，并通过摄像机投影反向传播以加强几何与外观的耦合。系统在苹果和梨果园中进行实地部署，采用标准化轨迹协议评估训练视角和新颖视角合成，以减少评估中的3DGS 过拟合。该系统能够在拖拉机上保持实时性能，提供更加清晰、稳定的重建和更加稳定的轨迹，优于当前最先进的3DGS-SLAM 基线。虽然该方法在果园监测中进行了展示，但也可应用于其他需要 robust 多模态感知的户外领域。", "conclusion": "AgriGS-SLAM 在果园监测中提供了更好的重建质量和实时性能，且具有广泛的应用潜力。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26390", "html_url": "https://arxiv.org/abs/2510.26390", "title": "SPG-CDENet：多器官分割的空间先验引导交叉双编码网络", "title_en": "SPG-CDENet: Spatial Prior-Guided Cross Dual Encoder Network for Multi-Organ Segmentation", "authors": "Xizhi Tian,Changjun Zhou,Yulin. Yang", "background": "多器官分割是计算机辅助诊断中的关键任务。虽然最近的深度学习方法在图像分割方面取得了显著成功，但由于器官大小和形状的巨大变化，它们在多器官分割中的效果受到挑战。", "innovation": "本文提出了一种名为SPG-CDENet的空间先验引导交叉双编码网络，这是一个新型的两阶段分割框架，旨在提高多器官分割精度。SPG-CDENet由空间先验网络和交叉双编码网络两个关键组件组成。其中，先验网络生成粗略的定位图，提供空间指导给双编码网络，而交叉双编码网络则包括全局编码器、局部编码器、对称交叉注意模块和基于流的解码器等四个主要部分，以增强全局和局部编码器之间的特征交互，并利用高阶语义特征直接提升解码器的性能，从而提高分割准确性。", "conclusion": "在两个公开数据集上的广泛定性和定量实验表明，SPG-CDENet相比现有分割方法具有优越的性能。进一步的消融研究还证实了所提出模块的有效性，以提高分割准确性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26369", "html_url": "https://arxiv.org/abs/2510.26369", "title": "CorVS: 在实际仓库中通过视频轨迹-传感器对应进行人员识别", "title_en": "CorVS: Person Identification via Video Trajectory-Sensor Correspondence in a Real-World Warehouse", "authors": "Kazuma Kano,Yuki Mori,Shin Katayama,Kenta Urano,Takuro Yonezawa,Nobuo Kawaguchi", "background": "工业场地的工人位置数据对于提高生产力至关重要。在物流仓库中，相机因其能够提供包的状态等环境上下文信息，成为了定位的一种有前途的工具。然而，仅仅依靠视觉数据来识别个人通常是不切实际的。此前的一些研究通过将轨迹和可穿戴传感器测量结果进行比较来识别个人，这种方法的优点包括不依赖于外观，但在某些实际条件下可能无法正常工作。因此，本文提出了一种名为CorVS的新方法，这是一种数据驱动的人员识别方法，它基于视觉跟踪轨迹和传感器测量结果之间的对应关系。", "innovation": "提出了CorVS，一种基于视频轨迹和传感器测量结果对应关系的数据驱动人员识别方法。该方法首先使用深度学习模型预测轨迹和传感器测量结果之间的对应概率和可靠性，然后通过预测的概率和可靠性在时间上匹配轨迹和传感器测量结果。该方法通过实际的仓库操作数据集验证了其在实际应用中的有效性。", "conclusion": "文中提出了一种名为CorVS的新方法，用于实际仓库中通过视频轨迹和传感器测量结果的对应关系来识别人员。实验表明，该方法在实际应用中具有较高的效果和可行性，可应用于提高工业场地的工作效率。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26635", "html_url": "https://arxiv.org/abs/2510.26635", "title": "SAMRI: Segment Anything Model for MRI", "title_en": "SAMRI: Segment Anything Model for MRI", "authors": "Zhao Wang,Wei Dai,Thuy Thanh Dao,Steffen Bollmann,Hongfu Sun,Craig Engstrom,Shekhar S. Chandra", "background": "准确的磁共振成像(MRI)分割对于临床决策至关重要，但由于手动进行分割劳动密集，效率低下。尽管卷积神经网络(CNN)方法在准确性和效率方面表现出色，但它们经常难以应用于MRI图像的对比度变化、强度不均匀性以及不同成像协议带来的挑战。虽然基于Transformer的Segment Anything Model (SAM)在自然图像中展现出卓越的泛化能力，但现有的转化方法往往将MRI视为另一种成像模态，没有充分考虑具体的成像模态挑战。", "innovation": "本文提出了SAMRI，一种专门针对MRI的SAM模型，该模型在110万带注释的MRI切片上进行了训练和验证，覆盖了身体各个部位的器官和病状。研究展示，通过两种策略调整SAM的掩码解码器，SAM能够针对MRI进行有效调整，与完整模型重新训练相比，训练时间缩短94%，可训练参数减少96%。在多种不同的MRI分割任务中，SAMRI实现了平均Dice值0.87，覆盖了多个解剖区域，并且在未见过的结构上表现出了良好的泛化能力，尤其是对小而临床重要的结构表现突出。", "conclusion": "SAMRI在多种MRI分割任务中达到了具有竞争力的准确性，特别是在形态学区域普遍呈现出先进的性能，并且能够稳健地泛化到未见结构，特别是小的和临床重要的结构。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26573", "html_url": "https://arxiv.org/abs/2510.26573", "title": "基于深度学习模型橄榄树冠和阴影分割的生物体积估计比较分析", "title_en": "Comparative Analysis of Deep Learning Models for Olive Tree Crown and Shadow Segmentation Towards Biovolume Estimation", "authors": "Wondimagegn Abebe Demissie,Stefano Roccella,Rudy Rossetto,Antonio Minnocci,Andrea Vannini,Luca Sebastiani", "background": "橄榄树生物体积估计是精确农业中的关键任务，对于产量预测和资源管理至关重要，尤其是在受气候引起的环境压力严重影响的地中海地区。研究人员利用无人机高空影像（特别是超高分辨率图像）进行实验，并且对不同深度学习模型在橄榄树冠及其阴影分割中的性能进行了评估。研究人员在意大利维科皮萨诺地区的无人机影像数据集上进行实验，该数据集包含人体标记的冠和阴影掩模。", "innovation": "该研究创新性地将三种不同的深度学习模型U-Net、YOLOv11m-seg和Mask R-CNN应用于分割橄榄树冠及其阴影的任务中。通过比较这些模型在精度和速度方面的表现，研究人员为实际应用提供了优化的解决方案。", "conclusion": "Mask R-CNN在整体准确度（F1=0.86；mIoU=0.72）方面表现最佳，而YOLOv11m-seg提供了最快的工作效率（每张图像0.12秒）。所估计的生物体积范围在约4到24立方米之间，反映了不同树木的结构差异。研究结果表明，Mask R-CNN适用于高精度需求的情境，而YOLOv11m-seg则适用于对速度有更高要求的大面积应用；U-Net保持为一个轻量级、高灵敏度的选项。该框架能实现精准的大规模果园监测，并可通过集成DEM或DSM以及实地校准进一步增强其实用性和支持决策功能。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26661", "html_url": "https://arxiv.org/abs/2510.26661", "title": "BRIQA: 平衡加权在儿科脑部MRI图像质量评估中的应用", "title_en": "BRIQA: Balanced Reweighting in Image Quality Assessment of Pediatric Brain MRI", "authors": "Alya Almsouti,Ainur Khamitova,Darya Taratynova,Mohammad Yaqub", "background": "在儿科脑部磁共振成像(MRI)中，评估图像中伪影的严重程度对于提高诊断准确性至关重要，尤其是在低场系统中，信噪比较低。现有的手工质量评估方法耗时且主观，因此需要稳健的自动化解决方案。现有的许多自动质量评估方法往往难以公平地对待不同严重程度的伪影类别，导致分类不准确。这些问题都需要通过提出新的方法来解决，以提高整体的诊断准确性", "innovation": "提出了一种名为BRIQA（平衡加权图像质量评估）的新方法。BRIQA利用基于梯度的损失加权来动态调整每个类别的贡献，并采用旋转批处理方案，确保对少代表类均匀曝光，从而改进模型在不均匀类别的分类性能。BRIQA通过实验验证了多种架构在处理不同类型伪影时没有明显优势，强调了架构多样性的重要性。具体的，BRIQA方法通过结合交叉熵损失和旋转批处理策略，提高了各个指标的性能，在宏观F1分数上从0.659提升到0.706，特别是在噪声、拉链、定位、对比度、运动和条带伪影的严重程度分类上取得了显著的进步", "conclusion": "BRIQA通过平衡不同类别之间的权重，使得模型能够更均衡地处理不同严重程度的伪影，显著提升了伪影分类的准确性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26703", "html_url": "https://arxiv.org/abs/2510.26703", "title": "ProstNFound+: 一种基于医疗基础模型的前瞻性前列腺癌检测研究", "title_en": "ProstNFound+: A Prospective Study using Medical Foundation Models for Prostate Cancer Detection", "authors": "Paul F. R. Wilson,Mohamed Harmanani,Minh Nguyen Nhat To,Amoon Jamzad,Tarek Elghareb,Zhuoxin Guo,Adam Kinnaird,Brian Wodlinger,Purang Abolmaesumi,Parvin Mousavi", "background": "医疗基础模型（FMs）为构建高性能的诊断系统提供了一条路径，但它们在微超声({ε}US)检测前列腺癌（PCa）方面的临床应用尚未得到验证。ProstNFound+通过结合医疗基础模型、适配器调优及定制提示编码器来嵌入特定于前列腺癌的临床生物标志物，以此应用于{ε}US检测PCa，进行前瞻性的初次验证。", "innovation": "ProstNFound+将医疗基础模型与适配器调优和定制提示编码器相结合，以嵌入特定于前列腺癌的临床生物标志物。模型生成癌症热图和临床显著前列腺癌的风险评分。该模型在新的临床站点获取的数据上进行了前瞻性评估，并与标准临床评分协议（PRI-MUS和PI-RADS）进行了基准测试。结果显示，该模型在前瞻性数据上展现出强大的泛化能力，性能没有下降，并且与临床评分紧密对齐，生成的热图与活检确认的病变一致。", "conclusion": "研究结果表明其在临床应用中的潜力，提供了一种可扩展且可解释的替代专家驱动协议的方案。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26759", "html_url": "https://arxiv.org/abs/2510.26759", "title": "MORE: 多器官医学图像重建数据集", "title_en": "MORE: Multi-Organ Medical Image REconstruction Dataset", "authors": "Shaokai Wu,Yapan Guo,Yanbiao Ji,Jing Tong,Yuxiang Lu,Mei Li,Suizhi Huang,Yue Ding,Hongtao Lu", "background": "当前的深度学习方法在CT重建方面通常局限于特定的解剖部位和数据集，这限制了其在未见过的解剖部位和病灶上的泛化能力。这为医学影像诊断和治疗带来了挑战，因为传统的深度学习方法难以处理多样的解剖结构和病变类型。为解决这一问题，本文介绍了包含9种不同解剖部位和15种病变类型的Multi-Organ医学图像重建数据集（MORE）以提供深入学习模型在多种多样的数据上的训练，以及对CT重建模型泛化能力的严格评估。", "innovation": "本文提出了MORE数据集，该数据集包括9种不同解剖部位和15种病变类型的CT扫描图像。该数据集旨在通过丰富的、异质性的数据集增强深度学习模型的泛化能力，并通过优化方法增强模型对未见过的解剖部位的鲁棒性。此外，研究还建立了更强的基线解决方案，该方案在这些具有挑战性的条件下优于先前的方法。实验结果证明，全面的数据集有助于提高模型的泛化能力，而基于优化的方法则为未知解剖部位提供了增强的鲁棒性。", "conclusion": "实验结果表明：1）全面的数据集有助于提高模型的泛化能力；2）基于优化的方法为未知解剖部位提供更强的鲁棒性。MORE数据集目前已经开放，并且可以在项目页面获得，遵循Creative Commons Attribution-NonCommercial 4.0许可。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.07734", "html_url": "https://arxiv.org/abs/2311.07734", "title": "Quality-Aware Prototype Memory for Face Representation Learning", "title_en": "Quality-Aware Prototype Memory for Face Representation Learning", "authors": "Evgeny Smirnov,Vasiliy Galyuk,Evgeny Lukyanets", "background": "Prototype Memory 是一种强大的模型，用于面部表示学习。它能使面部识别模型在任何大小的数据集上进行训练，通过即时生成原型（分类器权重）并高效利用它们。尽管 Prototype Memory 在许多面部识别基准测试中表现优异，但其原型生成算法在处理低质量或难以识别的面部图像时会出现问题，可能导致生成不佳的原型。所有同一个人的图像在生成原型时会赋予相同的权重，生成的平均原型可能会受到低质量面部图像的嵌入影响，从而导致误导性的训练信号并降低训练模型的性能。", "innovation": "本文提出了一种简单而有效的方法来改进 Prototype Memory，即 Quality-Aware Prototype Memory。Quality-Aware Prototype Memory 在原型生成过程中为不同质量的图像分配不同的权重。这种方法能使得原型从高质量的图像中获得更有信息量的信号，并减少低质量图像的影响。此外，文章还提出并比较了几种质量估计和使用的的方法，并在不同的面部识别基准测试中进行了广泛的实验。", "conclusion": "与基本的 Prototype Memory 相比，提出的 Quality-Aware Prototype Memory 模型在不同面部识别基准测试中表现出了显著的优势。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.26782", "html_url": "https://arxiv.org/abs/2510.26782", "title": "使用几何正则化世界模型克隆确定性3D世界", "title_en": "Clone Deterministic 3D Worlds with Geometrically-Regularized World Models", "authors": "Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen", "background": "世界模型是内部模拟世界如何演化的模型，它基于过去的观察和行动预测未来。准确的世界模型对于使智能体在复杂、动态的环境中思考、规划和有效推理至关重要。尽管取得了快速进展，现有世界模型仍然脆弱，在长时间跨度内会退化。主要原因在于外部输入（例如图像）的高维度以及损失或纠缠的潜在空间使动力学习变得不必要的复杂。因此，我们提出是否通过改善表示学习本身就能显著提高世界模型的性能。本研究通过解决一个基础但尚待解决的问题——建立一种能够完全克隆和过拟合到确定性3D世界的模型来朝建立真正准确的世界模型迈进。", "innovation": "提出了几何正则化世界模型（GRWM），这是一种通过确保自然感官轨迹中连续点在潜在表示空间中保持邻近来构建模型的方法。这种方法产生了显著改进的潜在表示，与环境的真实拓扑学紧密契合。GRWM 具有即插即用特性，只需少量架构修改，具有轨迹长度扩展性，并且兼容多种潜在生成的后台。在确定性3D环境和长期预测任务中，GRWM 显著增加了回放的准确性和稳定性。研究表明，其优势源于学习具有卓越几何结构的潜在流形。", "conclusion": "这些发现支持一个明确的结论：改进表示学习是一种直接且有用的方法来构建稳健的世界模型，通过提高预测准确性而不增加动力学模块的大小。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2401.13267", "html_url": "https://arxiv.org/abs/2401.13267", "title": "动态回溯学习应用于医学报告生成", "title_en": "Dynamic Traceback Learning for Medical Report Generation", "authors": "Shuchang Ye,Mingyuan Meng,Mingjian Li,Dagan Feng,Usman Naseem,Jinman Kim", "background": "自动化的医学报告生成具有显著减少耗时的医学报告工作量的潜力。现有的生成式表示学习方法在联合视觉和语言模态的医学报告生成中表现出一定的前景，但在端到端训练和直接应用于医疗影像到文本生成时，它们面临两大大挑战：一是难以准确捕捉到细微但至关重要的病理细节；二是推断过程中依赖视觉和文本输入，导致在仅有图像可用时的零样本推断性能下降。", "innovation": "本文提出了一种新颖的多模态动态回溯学习框架 (DTrace)。通过引入回溯机制监督生成内容的语义正确性，并采用动态学习策略适应不同比例的图像和文本输入，使推断过程中减少对两种模态输入的强依赖，促进跨模态知识的学习，从而能够进行文本生成。", "conclusion": "在两个基准数据集 IU-Xray 和 MIMIC-CXR 上进行的广泛实验表明，提出的 DTrace 框架在医学报告生成中的性能优于现有最先进的方法。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2208.08083", "html_url": "https://arxiv.org/abs/2208.08083", "title": "两头比一头更强：多分支模型与鲁棒学习的结合", "title_en": "Two Heads are Better than One: Robust Learning Meets Multi-branch Models", "authors": "Zongyuan Zhang,Qingwen Bu,Tianyang Duan,Zheng Lin,Yuhao Qing,Zihan Fang,Heming Cui,Dong Huang", "background": "深度神经网络（DNNs）容易受到对抗样本的影响，在对抗样本中，由于输入包含不易察觉的扰动，DNNs 会被误导产生错误的输出。对抗训练是一种可靠且有效的防御方法，能够显著减少神经网络的脆弱性，并已成为实现鲁棒学习的事实标准。许多最近的研究实践了以数据为中心的思想，如如何生成更好的对抗样本或利用生成模型生成额外的训练数据，但本文的研究视角不同，它从深入特征分布的角度出发，进一步探讨了鲁棒性，并提出了一种仅使用原始数据集就能获得最优性能的方法Branch Orthogonality adveRsarial Training (BORT)。", "innovation": "本文提出的Branch Orthogonality adveRsarial Training (BORT)结合了先进的多分支神经网络和分支正交损失函数，使每个解决方案空间正交化并超越了单一网络结构和其他基于增强数据集的对抗训练方法，同时在提高了模型鲁棒性的同时并没有增加推理时间。实验结果显示，相比除了使用额外训练数据之外的方法，我们的方法在CIFAR-10和CIFAR-100上分别将鲁棒准确性提高到67.3%和41.5%（与当前最优方法相比分别提高了7.23%和9.07%），即使我们的训练数据规模更小的情况下也表现更优", "conclusion": "深入特征分布出发提出的Branch Orthogonality adveRsarial Training (BORT)结合多分支模型，在不增加推理时间的情况下实现了最优的鲁棒性性能，与现有的所有方法相比，都不需要任何额外的技巧。通过在CIFAR-10、CIFAR-100和SVHN上的实验，证明了该方法的有效性并且显著提升了模型的鲁棒准确性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2311.17434", "html_url": "https://arxiv.org/abs/2311.17434", "title": "GSE: Group-wise Sparse and Explainable Adversarial Attacks", "title_en": "GSE: Group-wise Sparse and Explainable Adversarial Attacks", "authors": "Shpresim Sadiku,Moritz Wagner,Sebastian Pokutta", "background": "该论文讨论了稀疏对抗攻击通过最小的像素扰动欺骗深度神经网络（DNNs），且这些扰动常被$\boldsymbol{\text{\textasciiliteral{0309}}_0}$范数规范化。最近的研究则使用结构稀疏化正则化器，如核团规范范数，来构建基于像素组的稀疏对抗攻击。这使得攻击具有可解释性并具有重要的实际意义，揭示了DNNs的更大脆弱性。然而，生成这样的攻击面临着优化挑战，因为这涉及到在非凸目标中计算像素组的范数。", "innovation": "本文提出了一种两阶段算法，在语义上有意义的图像区域生成基于像素组的稀疏对抗攻击。首先使用1/2-范数近似的拟范数对抗损失进行优化。随后，算法过渡到具有2-范数正则化应用于扰动幅度的投影Nesterov加速梯度下降。在CIFAR-10和ImageNet数据集上的严格评估表明，该方法在分组稀疏性方面取得了显著提升，例如CIFAR-10上可达50.9%，ImageNet上可达38.4%（平均情况下的针对攻击）。同时，这种方法的计算时间更快，可解释性更强，并实现了100%的攻击成功率。", "conclusion": "本文提出的方法在提高稀疏对抗攻击的效果和解释性方面取得了显著的性能改进，同时计算能力也有大幅提高，并且得到了100%的攻击成功率。这为研究DNNs的脆弱性以及改进其安全性提供了新的视角。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2410.21004", "html_url": "https://arxiv.org/abs/2410.21004", "title": "一种稳健的动态生物形状量化连续且可解释的形态度量", "title_en": "A Continuous and Interpretable Morphometric for Robust Quantification of Dynamic Biological Shapes", "authors": "Roua Rouatbi,Juan-Esteban Suarez Cardona,Alba Villaronga-Luque,Jesse V. Veenvliet,Ivo F. Sbalzarini", "background": "在生物医学成像中，需要对形状进行量化和比较，以研究生物结构的几何和拓扑特征。传统的形态度量方法可能缺乏鲁棒性和解释性，难以捕捉形状的动态变化和主题信息。", "innovation": "介绍了Push-Forward Signed Distance Morphometric (PF-SDM)方法，该方法紧凑地编码闭合形状的几何和拓扑特性，包括它们的骨架和对称性。PF-SDM方法提供了光滑的数学形式，便于获取梯度和微分几何量，并可通过时间动态和空间强度分布来融合形状动态。该方法适用于多种生物结构的形状量化和机器学习任务。", "conclusion": "该研究通过在合成数据和小鼠胃胚体轴形成预测中的应用展示了PF-SDM方法的优势，其在准确性和速度上优于现有的基于CNN的基准方法。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2403.08788", "html_url": "https://arxiv.org/abs/2403.08788", "title": "VerifIoU - 抗干扰的物体检测鲁棒性", "title_en": "VerifIoU - Robustness of Object Detection to Perturbations", "authors": "Noémie Cohen,Mélanie Ducoffe,Ryma Boumazouza,Christophe Gabreau,Claire Pagetti,Xavier Pucel,Audrey Galametz", "background": "文章介绍了一种新的区间边界传播(Interval Bound Propagation, IBP)方法，用于正式验证目标检测模型，特别针对交并比(IoU)指标。IBP方法已在开源代码IBP IoU中实现，兼容基于抽象解释的验证工具。验证器在降落滑行道检测和手写数字识别案例研究上进行了评估，对比基线(Vanilla IBP IoU)显示出IBP IoU在确保准确性和稳定性方面的优越性能，有助于更安全和可靠的机器学习应用的开发与部署。", "innovation": "提出了新的IBP方法，专门用于目标检测模型的正式验证，特别是在IoU衡量标准上的应用。该方法在开源代码IBP IoU中实现，并且与流行的抽象解释验证工具兼容。相比于基线方法，IBP IoU在保证准确性和稳定性方面表现出更好的性能，从而提高了机器学习应用的安全性和鲁棒性。", "conclusion": "通过在降落滑行道检测和手写数字识别案例研究中的应用评估，验证器展示了其在保证模型准确性和稳定性方面的卓越表现，进一步强调了IBP IoU在提高机器学习应用安全性方面的优势。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2409.06154", "html_url": "https://arxiv.org/abs/2409.06154", "title": "静态用于动态：利用静态表情数据深入理解动态面部表情", "title_en": "Static for Dynamic: Towards a Deeper Understanding of Dynamic Facial Expressions Using Static Expression Data", "authors": "Yin Chen,Jia Li,Yu Zhang,Zhenzhen Hu,Shiguang Shan,Meng Wang,Richang Hong", "background": "动态面部表情识别（DFER）通过表情的演变来推断情感状态，不同于仅依赖单个静止照象的静态面部表情识别（SFER）。DFER由于样本量较少导致性能不理想，但SFER有大量的数据可用，因此探索如何利用SFER数据增强DFER的效果具有重要意义。目前的DFER方法在性能上通常不令人满意，原因在于训练样本数量不足。利用静态和动态表情之间的固有相关性，提出了结合SFER数据的统一双模态学习框架S4D，以提高DFER的性能。", "innovation": "提出了一种创新的模块Mixture of Adapter Experts (MoAE)，它能够实现任务特异性知识的获取，并有效提取来自静态和动态表情数据的共享知识。这一方法解决了传统的多任务学习带来的负迁移问题，提升了模型的整体性能，特别是在DFER任务上取得了新的最佳效果。", "conclusion": "实验结果表明，S4D在FERV39K、MAFW和DFEW基准测试中均取得了最佳表现，分别实现了53.65%、58.44%和76.68%的加权平均召回率（WAR）。此外，还对SFER和DFER任务之间的系统相关性进行了分析，证实了利用SFER数据的优势。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.15863", "html_url": "https://arxiv.org/abs/2406.15863", "title": "EmoAttack: Emotion-to-Image Diffusion Models for Emotional Backdoor Generation", "title_en": "EmoAttack: Emotion-to-Image Diffusion Models for Emotional Backdoor Generation", "authors": "Tianyu Wei,Shanmin Pang,Qi Guo,Yizhuo Ma,Xiaofeng Cao,Qing Guo", "background": "文本到图像的扩散模型可以根据文本输入生成现实的图像，使用户能够通过语言视觉化地传达自己的观点。然而，情感在语言中扮演着重要作用，用于表达个人意见，且恶意负面内容可能导致用户产生负面情绪并被误导。考虑到扩散模型的成功以及情感的重要性，该研究关注文本到图像扩散模型中的一种未被重视的风险——通过情绪化的输入文本引入负面内容，并引发用户的负面情绪。研究通过一种名为EmoAttack的新后门攻击方法，将情绪化的文本内容与包含恶意负面内容的参考图像相关联，从而在图像生成中引入恶意内容。该研究通过提出EmoBooth方法，建立了一种针对具有负面内容的图像生成过程的新方法，通过精调预训练的扩散模型，将情感词汇与参考图像进行映射，从而避免大规模的模型重训练。", "innovation": "该研究提出了一种新的后门攻击方法——情绪感知后门攻击（EmoAttack），该方法能够在图像生成过程中通过情绪化的文本引入恶意的负面内容。此外，研究还提出了名为EmoBooth的方法，通过精调预训练的扩散模型，将一组情感词汇与包含恶意负面内容的参考图像进行关联，避免了大规模的模型重新训练，并成功地构建了一个数据集来证明方法的有效性。", "conclusion": "鉴于用户广泛使用扩散模型，发现和解决这一威胁对于社会来说至关重要。该研究通过EmoAttack方法和EmoBooth方法，揭示了文本到图像扩散模型中的风险，并提出了有效的解决方案，为未来的研究和实际应用提供了重要参考。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2411.10501", "html_url": "https://arxiv.org/abs/2411.10501", "title": "OnlyFlow：基于光流的运动控制方法以改善视频生成模型", "title_en": "OnlyFlow: Optical Flow based Motion Conditioning for Video Diffusion Models", "authors": "Mathis Koroglu,Hugo Caselles-Dupré,Guillaume Jeanneret Sanmiguel,Matthieu Cord", "background": "该研究关注文本到视频生成任务中的精确控制，应用场景包括摄像机运动控制和视频到视频编辑。当前大多数方法依赖于用户定义的控制措施，如二值掩码或运动嵌入。已有方法向用户提供了这些控制机制，但尚不存在一种能够直接从输入视频中提取运动信息，并用于指导生成视频运动的方法。", "innovation": "提出了一种名为OnlyFlow的方法，利用来自输入视频的光流信息来调节生成视频的运动。通过结合文本提示和输入视频，OnlyFlow能够生成遵守输入视频和文本提示的视频。该方法首先在输入视频上应用光流估计模型，然后将生成的光流输入到可训练的光流编码器，最终将特征图注入到文本到视频的基础模型中。", "conclusion": "实验证明，尽管OnlyFlow未针对特定任务进行训练，但在多种任务上与现有最佳方法进行了比较，其表现更加优越。OnlyFlow是一种具有多功能性、轻量级且高效的运动控制方法，用于文本到视频生成。代码和模型将在GitHub和HuggingFace上公开发布。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.15389", "html_url": "https://arxiv.org/abs/2412.15389", "title": "基于自我监督的多染色肾小球分割方法", "title_en": "Resource Efficient Multi-stain Kidney Glomeruli Segmentation via Self-supervision", "authors": "Zeeshan Nisar,Friedrich Feuerhake,Thomas Lampert", "background": "多域场景下的语义分割仍然是计算机视觉中的一个基本挑战，特别是在标签数据稀缺的情况下。这一挑战在组织病理学图像分析中尤为明显，在这种情况下，相同组织结构需要在不同成像条件（染色剂）下进行分割，每种成像条件代表一个不同的视觉域。传统的深度学习方法（如Unet）需要大量的标签，这既耗费时间又成本高昂，尤其是在处理多个域（或染色剂）时更为突出。", "innovation": "该论文提出了一种基于自我监督预训练的方法，包括SimCLR、BYOL和一种新型的HR-CS-CO方法，从而能够在标签数据稀缺的情况下，保留分割方法（Unet和UDAGAN）的性能，尤其在标签数据减少到5%时，性能下降仅5.9%（Unet）和6.2%（UDAGAN），相较于完全监督的版本没有预训练和使用100%标签的情况。这表明改进后的模型不仅在训练分布范围内表现良好，也能泛化到公共基准数据集。", "conclusion": "通过自我监督预训练，可以有效减少对标签数据的需求，提高多染色肾小球分割的效率和性能。这种方法在标签数据稀缺的情况下，仍能保持较高的分割准确度，并且泛化能力强，适用于多种成像条件下的组织病理学图像分析。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2406.17345", "html_url": "https://arxiv.org/abs/2406.17345", "title": "NerfBaselines：一致且可重现的新型视图合成方法评估框架", "title_en": "NerfBaselines: Consistent and Reproducible Evaluation of Novel View Synthesis Methods", "authors": "Jonas Kulhanek,Torsten Sattler", "background": "新型视图合成是一个重要的问题，因其在多种应用中发挥作用，如AR/VR、游戏和机器人仿真等。最近，随着神经辐射场（NeRF）和3D高斯聚类（3DGS）方法的快速发展，跟踪当前最先进的技术变得困难，因为不同方法使用不同的评估标准，代码难以安装和使用，且方法在新的3D场景中不能很好地泛化。我们的实验表明，即使有很多种方法在评估标准上的细微差异，也能人为地提高这些方法的性能。这些问题引发了关于文献中进行的定量比较有效性的质疑。为了解决这些问题，我们提出了NerfBaselines，一个评估框架，提供了统一的基准测试工具，确保了可重现性，并简化了各种方法的安装和使用。我们通过实验验证我们的实现，通过重新生成原始论文中报告的数字来进行验证。为了提高访问性，我们发布了一个网页平台，用于将常用方法在典型基准上的对比呈现出来。我们坚信，NerfBaselines是对社区的宝贵贡献，因为它确保了定量结果的可比性，从而真正衡量了该领域在新型视图合成方面的进步。", "innovation": "提出了NerfBaselines，这是一个评估框架，提供了统一的基准测试工具，确保了可重现性，并简化了各种方法的安装和使用。通过实验验证，我们重新生成了原始论文中报告的数字，并发布了一个网页平台，用于将常用方法在典型基准上的对比呈现出来。", "conclusion": "我们坚信，NerfBaselines是对社区的宝贵贡献，因为它确保了定量结果的可比性，从而真正衡量了新型视图合成领域的进展。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.05783", "html_url": "https://arxiv.org/abs/2501.05783", "title": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping", "title_en": "UV-Attack: Physical-World Adversarial Attacks for Person Detection via Dynamic-NeRF-based UV Mapping", "authors": "Yanjie Li,Kaisheng Liang,Bin Xiao", "background": "近期的研究表明，通过补丁或静态3D模型基纹理修改对行人检测器进行的对抗攻击由于人类动作的高度灵活性，成功率较低。动作引起的3D变形建模一直是主要的挑战。神经辐射场（NeRF）技术的进步为动态人体建模提供了新的可能性，这为实现高成功率的对抗攻击带来了新的途径。然而，动态NeRF模型虽然可以建模人体，但修改服装纹理较为困难，因为它们嵌入在神经网络参数中。因此，需要新的方法来解决这些问题并提高攻击成功率。", "innovation": "本文提出了UV-Attack，一种利用动态NeRF基础的UV映射实现高成功率的对抗攻击方法。UV-Attack可以生成不同动作和视角下的人类图像，甚至可以通过采样SMPL参数空间来创建新的动作。此外，还提出了一种新的期望姿势变换损失（EoPT）来提高不可见姿态和视角下的攻击成功率。UV-Attack在动态视频设置下以92.7%的成功率对抗FastRCNN模型，大幅优于现有最先进的AdvCamou攻击（仅28.5%的成功率）。此外，在黑盒设置下，对最新的YOLOv8检测器成功率达到49.5%。该工作展示了基于动态NeRF的UV映射在创建更有效的行人检测对抗攻击方面的潜力，并解决了模型中人类动作建模和纹理修改的关键挑战。", "conclusion": "本文提出的UV-Attack利用动态NeRF基础的UV映射，显著提高了对抗攻击的成功率。实验结果表明，UV-Attack在动态视频设置下成功率达到92.7%，远超现有最先进的攻击方法。该工作强调了动态NeRF技术在创建更有效的人体检测对抗攻击方面的重要性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2412.20392", "html_url": "https://arxiv.org/abs/2412.20392", "title": "通过排斥型视觉提示调优防御多模态后门模型", "title_en": "Defending Multimodal Backdoored Models by Repulsive Visual Prompt Tuning", "authors": "Zhifang Zhang,Shuo He,Haobo Wang,Bingquan Shen,Lei Feng", "background": "多模态对比学习模型（例如CLIP）能够从大规模图像-文本数据集中学习高质量的表示，但在面对后门攻击时表现出明显的脆弱性，这引发了严重的安全担忧。研究揭示了CLIP的这一弱点主要是由于其倾向于编码超出数据集内预测模式的特征，这削弱了其在对抗输入扰动方面的视觉特征抗扰性。这样的情况使得其编码的特征极易被后门触发器重塑，从而导致其容易受到后门攻击的影响。鉴于此，本文提出了一种新颖的防御方法——排斥型视觉提示调优（RVPT），该方法通过使用专门设计的特征排斥损失进行深层视觉提示调优来应对上述挑战。RVPT通过对抗性排斥更深层中的编码特征并优化标准交叉熵损失，确保仅编码下游任务中的预测性特征，从而增强了CLIP在对抗输入扰动情况下的视觉特征抗扰性，减轻了其对后门攻击的易感性。", "innovation": "提出了排斥型视觉提示调优（RVPT），这是一种新颖的防御方法，利用专门设计的特征排斥损失进行深层视觉提示调优，能够通过少量参数的微调显著提升图像文本模型在面对后门攻击时的鲁棒性，同时仅需要少量下游清洁样本，并未整个模型进行微调，具有较高的实用价值。", "conclusion": "实验结果显示，相比于最先进的防御方法，RVPT仅对CLIP的0.27%参数进行调优，但成功将最先进的多模态攻击下后门攻击的成功率从89.70%降低至2.76%，并在多个数据集上有效展示了防御能力的泛化性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2501.08325", "html_url": "https://arxiv.org/abs/2501.08325", "title": "GameFactory: 利用生成互动视频创建新游戏", "title_en": "GameFactory: Creating New Games with Generative Interactive Videos", "authors": "Jiwen Yu,Yiran Qin,Xintao Wang,Pengfei Wan,Di Zhang,Xihui Liu", "background": "生成视频有潜力通过自主创建新内容来革新游戏开发。本文介绍了一种名为GameFactory的框架，用于由动作控制的游戏视频生成，并解决了场景通用性动作控制这一关键挑战，大多数现有方法都无法解决这个问题。为了生成开放域的游戏视频，使用预训练视频扩散模型的开放域生成先验。为了跨越开放域先验和小型游戏数据集之间的领域差距，提出了多阶段训练策略，包括一个领域适配器，将游戏风格学习与动作控制分离。这样可以实现场景通用的动作控制，而当前大多数方法在这方面有所欠缺。实验结果表明，GameFactory可以有效生成开放域的动作可控游戏视频，这在AI驱动的游戏生成中迈出了重要一步。", "innovation": "1. 提出GF-Minecraft数据集，用于动作标注的无偏见游戏视频，开发了动作控制模块，实现对键盘和鼠标输入的精确控制。2. 强调场景通用性的动作控制，扩展支持自回归生成无限长度的交互式视频。3. 使用预训练视频扩散模型的开放域生成先验，通过多阶段训练策略和领域适配器将开放域先验与小型游戏数据集结合，克服了领域差异问题，实现了场景通用的动作控制。4. 实验结果表明其显著提升了AI在游戏生成中的能力，代表了在AI驱动的游戏生成方面的重要进展。", "conclusion": "GameFactory有效地生成开放域的动作可控游戏视频，展示了在AI驱动的游戏生成中的重大进展，提供了创建完全新且多样游戏的方法，摆脱了固定风格和场景的限制。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.04852", "html_url": "https://arxiv.org/abs/2503.04852", "title": "CAUSAL3D：视觉数据因果学习的全面基准", "title_en": "CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data", "authors": "Disheng Liu,Yiran Qiao,Wuche Liu,Yiren Lu,Yunlai Zhou,Tuo Liang,Yu Yin,Jing Ma", "background": "当前人工智能和计算机视觉领域取得了显著进步，但在评估模型从复杂视觉数据中推断隐藏因果关系的能力方面仍缺乏基准。真正的智能依赖于揭示和利用隐藏因果关系的能力。因此，本文提出了Causal3D，一种结合结构化数据（表格）与对应的视觉表示（图像）的新型和全面基准，以评估因果推理能力。Causal3D包含19个3D场景数据集，涵盖了不同的因果关系、视角和背景，适用于不同复杂度场景的评估。", "innovation": "Causal3D是一个系统设计的基准，通过集成结构化数据和视觉表示，评估模型推断隐藏因果关系的能力。该基准涵盖了广泛的数据集，能够评估复杂的因果关系场景，并测试了包括经典因果发现、因果表示学习以及大型/视觉-语言模型在内的多种最先进的方法。实验结果显示，在缺乏先验知识的情况下，随着因果结构的复杂性增加，性能显著下降，表明即使是先进的方法在复杂因果场景中也面临挑战。", "conclusion": "Causal3D作为推进计算机视觉领域因果推理的重要资源，有助于促进在关键领域的可信人工智能的发展。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.11094", "html_url": "https://arxiv.org/abs/2503.11094", "title": "Open3D-VQA: 在开放空间中全面空间推理的多模态大型语言模型基准", "title_en": "Open3D-VQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space", "authors": "Weichen Zhang,Zile Zhou,Xin Zeng,Xuchen Liu,Jianjie Fang,Chen Gao,Yong Li,Jinqiang Cui,Xinlei Chen,Xiao-Ping Zhang", "background": "多模态大型语言模型（MLLMs）在空间推理方面具有基本能力，但在开放的航空环境中其性能仍较少被探索。当前研究通过提出Open3D-VQA基准，旨在评价MLLMs在从航空视角推理复杂空间关系的能力。", "innovation": "创建了一个新的基准Open3D-VQA，以评估MLLMs在开放空间中从空中视角推理复杂空间关系的能力。该基准包含73000个问答对，覆盖7种一般空间推理任务，支持视觉和点云模态，问题自动生成于现实世界和模拟的航空场景中提取的空间关系。", "conclusion": "对13种流行MLLMs的评估结果显示，模型在回答关于相对空间关系的问题上表现更好，而非绝对距离；3D LLMs未能明显优于2D LLMs；仅通过模拟数据集微调可显著提升模型在真实世界场景中的空间推理性能。实验数据和工具已供研究界使用。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.09499", "html_url": "https://arxiv.org/abs/2503.09499", "title": "MindGYM：thinking-centric 细调中的问题合成关键因素？", "title_en": "MindGYM: What Matters in Question Synthesis for Thinking-Centric Fine-Tuning?", "authors": "Zhe Xu,Daoyuan Chen,Zhenqing Ling,Yaliang Li,Ying Shen", "background": "大型基础模型在通过严格的模板或群众标注的指令数据集进行监督时，难以获得可迁移的结构化思考能力。现有的方法主要集中在预定义的数据合成模式上，而本文则提出了一种以思维为中心的数据合成范式，该范式通过自我生成和认知指导的数据使模型能够自我进化。", "innovation": "提出了一种名为 MindGYM 的结构化可扩展问题合成框架，包含：1) 认知思维过程注入，将高级推理目标注入模型以塑造数据合成行为；2) 种子单跳问题合成，从多种语义类型中生成基本问题，以鼓励更广泛的思考；3) 挑战多跳问答合成，基于问答种子生成更复杂的多跳问题，以实现更深入的推理。研究表明，通过该方法生成的合成数据在平均质量和质量变异方面分别比基线数据提高了16.7%和减少了67.91%，强调了高质量且自包含数据对于有效的思维导向微调的重要性。MindGYM 在六个推理基准测试中提高了性能，仅使用400个数据样本便在 MathVision 上取得了16%的提高，并针对不同规模和架构的模型实现了泛化的改进。", "conclusion": "MindGYM 强调了自我挑战机制在提高大型模型能力方面的可行性，同时尽量减少人工干预和资源需求。代码和数据已公开，旨在促进以自我推理能力为导向的数据驱动研究。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.23722", "html_url": "https://arxiv.org/abs/2503.23722", "title": "LATex: 利用属性基于的文本知识进行空地人员重识别", "title_en": "LATex: Leveraging Attribute-based Text Knowledge for Aerial-Ground Person Re-Identification", "authors": "Pingping Zhang,Xiang Hu,Yuhao Wang,Huchuan Lu", "background": "空地人员再识别（AG-ReID）是智能交通系统中的一个重要任务，旨在跨不同视角的异构摄像头检索特定人员。现有方法主要采用基于深度学习的模型，侧重于提取视角不变的特征，但通常忽略了人员属性中的语义信息。此外，现有的训练策略通常依赖于大规模模型的全面微调，显著增加了训练成本。", "innovation": "本文提出了一种名为LATex的新框架，采用提示调优策略利用基于属性的文本知识。具体来说，通过对比语言-图像预训练（CLIP）模型，首先提出了一种属性感知图像编码器（AIE）来从输入图像中提取全局语义特征和属性感知特征。然后，使用这些特征，提出了一种提示属性分类组（PACG）来预测人员属性并获取属性表示。最后，设计了一种耦合提示模板（CPT）来将属性表示和视图信息转换为结构化句子。这些句子由CLIP的文本编码器处理以生成更具区分性的特征。结果表明，本框架能够充分利用基于属性的文本知识，提高AG-ReID性能。", "conclusion": "在三个AG-ReID基准上的广泛实验表明了我们所提出方法的有效性。源代码可在以下链接获取：this https URL."}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.13160", "html_url": "https://arxiv.org/abs/2503.13160", "title": "语言引导的弱监督开放世界视频异常检测", "title_en": "Language-guided Open-world Video Anomaly Detection under Weak Supervision", "authors": "Zihao Liu,Xiaoyu Wu,Jianqin Wu,Xuxu Wang,Linlin Yang", "background": "视频异常检测（VAD）旨在检测与预期行为不一致的异常。在开放世界场景中，预期事件可能会根据需求变化而变化。现有方法假设异常的定义是不变的，这使得它们在开放世界中不适用。现有的VAD方法主要关注静态的异常定义，但实际应用场景中，异常定义可能会随着环境变化而变化。", "innovation": "本文提出了一种新的开放世界VAD范式，该范式允许在推理时通过用户提供自然语言进行引导检测。本范式需要建立从视频和文本定义到异常分数的稳健映射，因此提出了一种名为LaGoVAD的模型。该模型在弱监督下动态适应异常定义，并采用两种正则化策略：通过动态视频合成多样化异常相对持续时间，以及通过对抗学习和负样本来增强特征的鲁棒性。", "conclusion": "为了训练这种可适应的模型，需要多种异常定义。现有的数据集通常只提供标签而没有提供语义描述。为了弥合这一差距，作者收集了PreVAD数据集，这是迄今为止最大和最多样化的视频异常数据集，包含了35,279个标注视频，具有多层级类别标签和描述。零样本实验表明LaGoVAD在七个数据集上表现最佳。该数据集和代码将在公布的地址公开。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.00254", "html_url": "https://arxiv.org/abs/2505.00254", "title": "使用视频语言模型赋能代理视频分析系统", "title_en": "Empowering Agentic Video Analytics Systems with Video Language Models", "authors": "Yuxuan Yan,Shiqi Jiang,Ting Cao,Yifan Yang,Qianqian Yang,Yuanchao Shu,Yuqing Yang,Lili Qiu", "background": "AI驱动的视频分析近年来在多个领域变得越来越重要。然而，现有的系统通常局限于特定预定义的任务，限制了其在开放环境中的适应性。最近，视觉语言模型（VLMs）作为变革性技术的出现，为开放环境下的视频理解、推理和分析提供了巨大的潜力。但处理超长视频内容时，这些模型的有限上下文窗口成为一个挑战，而超长视频内容在实际应用中非常普遍。", "innovation": "介绍了AVA系统，这是一种基于VLMs的系统，设计用于开放环境下高级视频分析。AVA包含两个关键创新：（1）近实时构建事件知识图谱（EKGs），以高效地索引长时间或连续的视频流；（2）代理检索生成机制，利用EKGs处理复杂多样的查询。", "conclusion": "对公开基准LVBench和VideoMME-Long的全面评估显示，AVA达到了最先进的性能，分别实现了62.3%和64.1%的准确率，明显优于现有的VLM和视频检索增强生成（RAG）系统。此外，为评估超长和开放世界视频下的视频分析，还引入了新基准AVA-100，该基准包括8个超过10小时的视频和120个手工标注的多样化和复杂的问答对。在AVA-100上，AVA实现了顶级的性能，准确率为75.8%。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18584", "html_url": "https://arxiv.org/abs/2505.18584", "title": "通过调制大规模激活释放扩散变换器在视觉对应中的潜力", "title_en": "Unleashing Diffusion Transformers for Visual Correspondence by Modulating Massive Activations", "authors": "Chaofan Gan,Yuanpeng Tu,Xi Chen,Tieyuan Chen,Yuxi Li,Mehrtash Harandi,Weiyao Lin", "background": "预训练的稳定扩散模型在视觉对应方面取得了显著的进步。然而，扩散变换器（DiTs）由于“大规模激活”现象导致了表征不丰富和性能下降的问题，特别是在准确密集对应任务中。", "innovation": "提出了一种训练免费框架DiTF，通过自适应层归一化（AdaLN）和通道丢弃策略有效定位并优化大规模激活，从而改善了DiTs在视觉对应任务中的表现。", "conclusion": "实验结果表明，DiTF模型在Spair-71k和AP-10K-C.S.等不同视觉对应任务中均优于DINO和基于SD的模型，并且在DiT模型上建立了新的最先进的性能，分别提高了9.4%和4.4%的精度。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.16239", "html_url": "https://arxiv.org/abs/2505.16239", "title": "DOVE: 高效的一步扩散模型用于真实世界视频超分辨率", "title_en": "DOVE: Efficient One-Step Diffusion Model for Real-World Video Super-Resolution", "authors": "Zheng Chen,Zichen Zou,Kewei Zhang,Xiongfei Su,Xin Yuan,Yong Guo,Yulun Zhang", "background": "扩散模型在真实世界的视频超分辨率(VSR)任务中表现出色。然而，它们需要几十步采样，导致推理非常缓慢。单步采样加速技术提供了一种潜在的解决方案，但实现单步VSR仍然具有挑战性，因为这要求在视频数据上进行高成本的训练，并且有严格的真实度要求。", "innovation": "本文提出了一种名为DOVE的高效单步扩散模型，用于真实世界的视频超分辨率。通过微调预训练的视频扩散模型（即CogVideoX）并引入隐空间像素训练策略来训练DOVE。这种策略采用两阶段方案逐步适应模型以应对视频超分辨率任务。此外，设计了一个视频处理管道以构建一个高品质的数据集，专门用于VSR，命名为HQ-VSR。在该数据集上微调进一步增强了DOVE的修复能力。", "conclusion": "广泛的实验表明，DOVE在性能上与基于多步扩散的VSR方法相当或优于，同时提供了出色的推理效率，相比于现有方法（如MGLD-VSR）达到了28倍的速度提升。源代码可在：this https URL 获取。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21996", "html_url": "https://arxiv.org/abs/2505.21996", "title": "学习交互式视频生成的世界模型", "title_en": "Learning World Models for Interactive Video Generation", "authors": "Taiye Chen,Xun Hu,Zihan Ding,Chi Jin", "background": "现有的长期视频生成模型因两个主要挑战而限制了其内在的世界建模能力：累积错误和缺乏足够的记忆机制。这使得未来规划和基于行动的选择变得困难。因此，需要既具有交互性又能够保持时空一致性的基础世界模型来有效规划未来。", "innovation": "通过增加动作条件和自回归框架，增强了图像到视频模型的交互能力。提出了带有明确全局状态条件的视频检索增强生成（VRAG），显著减少了长期累积错误并提高了世界模型的时空一致性。进一步分析了自回归生成和检索增强生成在视频生成中的局限性。", "conclusion": "这项工作揭示了视频世界模型中的基本挑战，并建立了改善具有内部世界建模能力的视频生成模型的全面基准。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2504.09549", "html_url": "https://arxiv.org/abs/2504.09549", "title": "SD-ReID: View-aware Stable Diffusion for Aerial-Ground Person Re-Identification", "title_en": "SD-ReID: View-aware Stable Diffusion for Aerial-Ground Person Re-Identification", "authors": "Yuhao Wang,Xiang Hu,Lixin Wang,Pingping Zhang,Huchuan Lu", "background": "Aerial-Ground Person Re-Identification (AG-ReID)旨在跨不同视角的摄像头检索特定人员。以往的工作主要集中在设计区分性模型，以保持身份一致性，尽管拍摄角度有大幅度变化。尽管这些方法背后的核心理念是自然的，但设计针对不同视角的鲁棒模型仍是一项非常具有挑战性的任务。此外，这些方法忽略了特定视角特征对模型表示能力的贡献。", "innovation": "为了应对这些问题，本文提出了一个名为SD-ReID的生成框架，该框架利用生成模型来模拟不同视图的特征分布，同时提取鲁棒的身份表示。具体来说，首先训练一个基于ViT的模型，提取包括身份和视角条件在内的可控条件下的人员表示。然后，通过这些可控条件增强人员表示来调整稳定扩散（SD）模型。此外，引入视图细化解码器（VRD）以弥合实例级和全局级特征之间的差距。最后，人员表示和所有视图特征一起用于检索目标人员。在五个AG-ReID基准数据集（CARGO, AG-ReIDv1, AG-ReIDv2, LAGPeR和G2APS-ReID）上进行的大量实验表明了所提出方法的有效性。", "conclusion": "在五个AG-ReID基准数据集上进行了广泛的实验，验证了所提出方法的有效性，并且源代码将公开。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.18766", "html_url": "https://arxiv.org/abs/2505.18766", "title": "StyleGuard：通过风格扰动防止基于文本到图像模型的风格模拟攻击", "title_en": "StyleGuard: Preventing Text-to-Image-Model-based Style Mimicry Attacks by Style Perturbations", "authors": "Yanjie Li,Wenxuan Zhang,Xinqi Lyu,Yihao Liu,Bin Xiao", "background": "近年来，通过DreamBooth和Textual Inversion等方法，文本到图像的扩散模型被广泛应用于风格模仿和个人化定制，但同时引发了知识产权保护和生成欺骗性内容的担忧。尽管Glaze和Anti-DreamBooth等研究提出了使用对抗噪声来保护图像的方法，但现有的去污染方法如DiffPure和Noise Upscaling能够成功攻击这些最新防御措施，显示了现有方法的脆弱性。当前方法在不同模型间的迁移性有限，效果不理想。", "innovation": "本文提出了一个新颖的反模仿方法StyleGuard。该方法提出了新的风格损失，优化了latent空间中的风格相关特征，使其偏离原始图像，从而改善了模型无关的迁移性。此外，为了增强扰动绕过基于扩散去污染的能力，设计了一种新的上采样损失，该损失在训练期间涉及了集成净化器和放大器。实验表明，StyleGuard在多种变换和净化方法中的鲁棒性优于现有方法，有效对抗各种模型中的风格模仿。", "conclusion": "实验结果表明，StyleGuard在WikiArt和CelebA数据集上，在各种变换和净化方法中表现出更强大的鲁棒性，有效地对抗了各种模型中的风格模仿。此外，StyleGuard在不同的风格模仿方法（包括DreamBooth和Textual Inversion）中也有效。该代码可以在指定网址访问。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.12191", "html_url": "https://arxiv.org/abs/2505.12191", "title": "移除去噪器：从数据课程中涌现出的自监督学习中的抗噪性", "title_en": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum", "authors": "Wenquan Lu,Jiaqi Zhang,Hugues Van Assel,Randall Balestriero", "background": "自监督学习(SSL)已经成为从未标记数据中提取丰富表示的强大解决方案。然而，SSL研究主要集中在清洁、筛选和高质量的数据集上。因此，在噪声数据上应用SSL仍然是一个挑战，尽管这对天文学、医学影像、地球物理或金融等领域的应用至关重要。", "innovation": "本文提出了一种完全自监督的框架，该框架可以在不需要推理或下游微调去噪器的情况下，实现抗噪声的表示学习。该方法首先使用噪声数据训练一个SSL去噪器，然后使用该去噪器构建了一个去噪到噪声的数据课程（即，先训练去噪样本，再训练噪声样本），用于预训练自监督主干（例如，DINOv2），伴随着一个教师引导的正则化来锚定噪声嵌入到其去噪对应物。这个过程鼓励模型内化噪声鲁棒性。值得注意的是，去噪器可以在预训练后被丢弃，简化了部署过程。在极端高斯噪声下的ImageNet-1k (σ=255，SNR=0.72 dB)中，该方法使得线性探针的准确度提高了4.8%，表明自监督学习可以在无去噪器的抗噪声性中脱颖而出。", "conclusion": "通过噪声感知的预训练，使去噪器成为多余，从而能够在噪声数据上平稳地进行SSL训练，并验证了抗噪声性可以从自监督学习中涌现。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.23158", "html_url": "https://arxiv.org/abs/2505.23158", "title": "LODGÉ: 级别细化的大规模高斯点渲染及其高效显示", "title_en": "LODGE: Level-of-Detail Large-Scale Gaussian Splatting with Efficient Rendering", "authors": "Jonas Kulhanek,Marie-Julie Rakotosaona,Fabian Manhardt,Christina Tsalicoglou,Michael Niemeyer,Torsten Sattler,Songyou Peng,Federico Tombari", "background": "传统的3D Gaussian Splatting方法在处理大规模场景时遇到了显存和渲染时间的瓶颈，特别是在内存受限的设备上。为了克服这些限制，本文提出了一种新的级别细化（LOD）方法，以实现大型场景的实时渲染。", "innovation": "本文的方法引入了一种层次化的LOD表示法，该表示法根据摄像机距离迭代选择最优的高斯子集，从而大大减少了渲染时间和GPU内存使用。方法包括深度感知的3D平滑过滤、基于重要性的剪枝和精细调整，以及场景分块和动态加载相关高斯体，避免了分块边界上的视觉伪影。", "conclusion": "我们的方法在室外（分层3DGS）和室内（Zip-NeRF）数据集上均达到了最先进的性能，实现了高质量渲染并降低了延迟和内存需求。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.00871", "html_url": "https://arxiv.org/abs/2506.00871", "title": "基于上下文预测任意行人轨迹", "title_en": "Towards Predicting Any Human Trajectory In Context", "authors": "Ryo Fujii,Hideo Saito,Ryo Hachiuma", "background": "准确预测未来行人的轨迹对自主系统至关重要，但由于需要适应不同的环境和领域，这一任务仍然具有挑战性。常见的方法是收集特定场景的数据，并通过反向传播进行微调。然而，为每个新场景进行微调在边缘设备上部署往往是不切实际的。", "innovation": "为了解决这一挑战，本文提出了一种名为TrajICL的上下文学习（In-Context Learning）框架，该框架在推理时不需对特定场景的数据进行微调，也无需更新权重，即可实现适应性。提出了基于时空相似度的选择（STES）和预测引导的选择（PG-ES）方法，分别根据时空相似性以及预测未来轨迹来选择相关示例。", "conclusion": "大量实验表明，TrajICL在不同场景和跨领域场景中均表现出色，甚至超过了微调方法，实现了在多个公开基准上的卓越适应性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.21497", "html_url": "https://arxiv.org/abs/2505.21497", "title": "从科学论文到海报的多模态自动化：Paper2Poster", "title_en": "Paper2Poster: Towards Multimodal Poster Automation from Scientific Papers", "authors": "Wei Pang,Kevin Qinghong Lin,Xiangru Jian,Xi He,Philip Torr", "background": "学术海报生成是科学研究中关键但具有挑战性的任务，要求将长文段文档压缩成一张视觉连贯的页面。为解决这一挑战，本文介绍了第一个针对海报生成的基准和评估指标套件，该套件结合了最近的会议论文及其作者设计的海报，并从（i）视觉质量、（ii）文本连贯性、（iii）整体评估六个细粒度的美学和信息标准以及（iv）“PaperQuiz”评分标准（即海报能否传达论文核心内容）进行评估。利用此基准，我们提出了PosterAgent，一个自上而下、视觉在循环中的多智能体流程，包括语义解析器、规划器和绘制评论员循环，分别负责从论文中提取结构化资产、文本-视觉配对的二叉树布局生成以及细化和优化海报面板。", "innovation": "引入了第一项针对海报生成的基准和评估指标套件；提出了PosterAgent，一个自上而下的视觉在循环中的多智能体流程，包含语义解析器、规划器和绘制评论员循环；其中绘制评论员循环利用人工智能反馈进行优化，确保布局的连贯性及一致性；以及通过开源和低资源消耗方式提高了海报生成的质量。", "conclusion": "通过全面评估，我们发现尽管GPT-4o在初次呈现时有较好的视觉效果，但其文字质量较差且难以传达论文核心内容。我们发现读者参与度是主要的美学瓶颈，因为人类设计的海报主要依赖于视觉语义传达意义。我们的完全开源版本在几乎所有指标上均表现优于现有的4o驱动多智能体系统，并且只使用了87%的token。我们的方法将22页的论文转化为一个最终的可编辑.pptx海报，成本仅为0.005美元。我们的发现为下一代完全自动化的海报生成模型指明了方向。代码和数据集可在提供的链接找到。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.05696", "html_url": "https://arxiv.org/abs/2506.05696", "title": "MoralCLIP：基于道德基础理论的视觉-语言表示对比对齐", "title_en": "MoralCLIP: Contrastive Alignment of Vision-and-Language Representations with Moral Foundations Theory", "authors": "Ana Carolina Condez,Diogo Tavares,João Magalhães", "background": "近年来，视觉-语言模型在跨模态语义理解方面取得了显著进展。然而，这些编码方法缺乏理解和推理内容道德维度的能力——这是人类认知的一个关键方面。该研究填补了这一空白，通过引入MoralCLIP，一种基于道德基础理论（MFT）的新型嵌入表示方法，扩展了多模态学习。", "innovation": "该研究提出了一种基于MFT的MoralCLIP方法，将视觉和文本道德线索整合到统一的嵌入空间中，实现了跨模态道德对齐。MoralCLIP通过一个多标签数据集识别视觉内容中的共现道德基础，并设计了一种道德数据增强策略，将标注数据集扩展到15,000个图像-文本对，标签符合MFT维度。", "conclusion": "实验证明，明确的道德监督提高了单模态和多模态的道德内容理解能力，为具备识别和对齐人类道德价值观的道德感知AI系统奠定了基础。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.02393", "html_url": "https://arxiv.org/abs/2506.02393", "title": "RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection", "title_en": "RRCANet: Recurrent Reusable-Convolution Attention Network for Infrared Small Target Detection", "authors": "Yongxian Liu,Boyang Li,Ting Liu,Zaiping Lin,Wei An", "background": "红外小目标检测是一个具有挑战性的任务，由于这些目标具有独特的特性（如小尺寸、低亮度、无固定形状和频繁变化）。最近发布的基于CNN的方法取得了有望的性能，但通常需要大量的特征提取和融合模块。因此，高效且有效的检测成为关键问题。", "innovation": "该论文提出了一个递归可重用卷积注意网络（RRCA-Net），其中包含了递归可重用卷积块（RuCB）以维护和进一步提炼深层的小目标高级信息；通过双交互注意聚合模块（DIAAM）促进提炼信息之间的相互增强和融合，同时保证层间上下文信息的相关性，并设计了由物理和数学约束集成的目标特征启发性损失函数（DpT-k损失）以实现稳定收敛。", "conclusion": "实验结果表明，RRCA-Net在三个基准数据集（如NUAA-SIRST、IRSTD-1k、DenseSIRST）上取得了与现有最佳方法相当的性能，同时保持了参数数量较少，并作为插件模块引入后能够为几种流行的IRSTD方法提供一致的性能提升。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.10173", "html_url": "https://arxiv.org/abs/2506.10173", "title": "SPARKE: Scalable Prompt-Aware Diversity and Novelty Guidance in Diffusion Models via RKE Score", "title_en": "SPARKE: Scalable Prompt-Aware Diversity and Novelty Guidance in Diffusion Models via RKE Score", "authors": "Mohammad Jalali,Haoyu Lei,Amin Gohari,Farzan Farnia", "background": "扩散模型在高保真图像合成和提示导向生成建模方面已经显示出显著的成功。然而，提示导向扩散模型生成样本的多样性仍然面临挑战，尤其是在提示涵盖广泛语义范围时。近期方法通过引入多样性的度量来鼓励更丰富的生成，但在大规模生成环境中，基于熵的指导方法存在计算挑战。", "innovation": "本文提出了适用于提示感知多样性的可扩展的SPARKE方法（Scalable Prompt-Aware Rény Kernel Entropy Diversity Guidance）。该方法利用条件熵进行多样性指导，动态地根据相似提示进行多样性测量，从而实现提示感知的多样性控制。为了应对基于熵的指导方法在大规模生成环境中的计算瓶颈，作者将条件熵方法应用于条件潜在向量RKE得分指导的特殊案例，将熵计算和梯度优化的复杂度从O(n^3)降低到O(n)，使得在不同提示下进行数千轮多样性的引导采样成为可能。", "conclusion": "实验结果表明，本文提出的SPARKE方法在不显著增加计算成本的情况下，能够提高生成数据的提示感知多样性。代码已发布在项目页面上。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.21046", "html_url": "https://arxiv.org/abs/2506.21046", "title": "利用自监督视觉变压器特征提升生成对抗迁移性", "title_en": "Boosting Generative Adversarial Transferability with Self-supervised Vision Transformer Features", "authors": "Shangbo Wu,Yu-an Tan,Ruinan Ma,Wencong Ma,Dehua Zhu,Yuanzhang Li", "background": "深度神经网络（DNNs）的能力来自于从提供的数据中提取和解释特征。通过利用DNNs的中间特征而不是依赖于硬标签，本文构建了泛化效果更好的对抗扰动，从而增强黑盒迁移性。此前的工作大多是基于监督学习，本文受到自监督学习和变换器架构之间独特协同效应的启发，探究自监督视网膜变换器（ViT）表示是否可以提高对抗迁移性。文章介绍了dSVA -- 一种生成式的双自监督ViT特征攻击，利用对比学习（CL）的全局结构特征和掩蔽图像建模（MIM）的局部纹理特征，使用自监督ViTs的联合特征和注意机制训练生成器以创建黑盒对抗样本", "innovation": "本文提出了一种利用自监督维恩变换器（ViT）特征生成对抗扰动的方法（dSVA），结合对比学习（CL）和掩蔽图像建模（MIM）的优点，增强了黑盒模型的对抗迁移性。利用自监督ViTs提炼的双重深层特征，dSVA方法可以实现比现有最佳方法更优异的黑盒迁移效果", "conclusion": "通过扰乱自监督ViTs提炼的双重深度特征，我们获得了显著的黑盒迁移性，该方法适用于各种架构模型，且性能优于现有状态。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.06220", "html_url": "https://arxiv.org/abs/2506.06220", "title": "GenIR: 生成视觉反馈用于心智图像检索", "title_en": "GenIR: Generative Visual Feedback for Mental Image Retrieval", "authors": "Diji Yang,Minghao Liu,Chung-Hsiang Lo,Yi Zhang,James Davis", "background": "视觉-语言模型（VLMs）在文本到图像检索基准测试中显示出很强的能力。然而，将这些成果迁移到实际应用中仍然是一个挑战。实际上，人类的搜索行为并非一次完成，而是一个多轮的过程，由心中的线索引导。也就是说，从模糊的记忆到对目标图像清晰的心理表象。受到这个差距的启发，该研究探讨了心智图像检索（Mental Image Retrieval，MIR）的任务，即用户通过与图像搜索引擎的多轮互动，逐步优化他们心中的图像搜索。核心在于机器能够提供明确且行动导向的反馈，但现有方法依赖于间接或抽象的文字反馈，这可能模糊不清、误导或不具有效性。", "innovation": "该研究提出了GenIR，一种利用基于扩散的图像生成技术的生成性多轮检索范式，以显式地体现AI系统在每轮中的理解能力。这些合成的视觉表示提供了清晰明确的反馈，让用户可以直观且有效地调整查询。此外，还提出了一种完整的自动化流程来生成高质量的多轮MIR数据集。", "conclusion": "实验结果表明，GenIR在MIR场景中的性能显著优于现有的互动方法。这项工作不仅建立了一个新的任务和数据集，还提供了一种有效的生成性检索方法，为未来的研究奠定了基础。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.23292", "html_url": "https://arxiv.org/abs/2506.23292", "title": "DDL: 大规模多样真实场景下的深度伪造检测与定位数据集", "title_en": "DDL: A Large-Scale Datasets for Deepfake Detection and Localization in Diversified Real-World Scenarios", "authors": "Changtao Miao,Yi Zhang,Weize Gao,Zhiya Tan,Weiwei Feng,Man Luo,Jianshu Li,Ajian Liu,Yunfeng Diao,Qi Chu,Tao Gong,Zhe Li,Weibin Yao,Joey Tianyi Zhou", "background": "近年来，AIGC的进展导致了恶意深度伪造内容的滥用，这使得开发可靠的深度伪造检测方法变得尤为重要。现有的深度伪造检测模型虽然在检测指标上表现出色，但大多数方法仅提供简单的二元分类结果，缺乏可解释性。近年来的研究尝试通过提供空间操作掩码或时间伪造片段来增强分类结果的可解释性，但由于伪造数据集的限制，这些方法的实际效果仍然不理想。其主要原因在于大多数现有的深度伪造数据集仅含有二元标签，伪造场景单一且缺乏多样性和大量数据，不足以应对复杂的现实世界挑战。", "innovation": "本研究构建了一个名为DDL的新颖大规模深度伪造检测和定位数据集，包含超过1.4M+个伪造样本，并涵盖了多达80种不同的深度伪造方法。DDL的设计融入了四大创新：（1）全面的深度伪造方法（涵盖7种不同的生成架构和共80种方法），（2）多样的篡改模式（包含了7种经典和3种新型伪造模式），（3）多样的伪造场景和模态（包括3种场景和3种模态），（4）精细的伪造注释（提供了超过1.18M+种精确的空间掩码和0.23M+种精确的时间片段）。通过这些改进，DDL不仅为复杂的现实世界的伪造提供了一个更具挑战性的基准，还为构建下一代深度伪造检测、定位和可解释性方法提供了关键支持。", "conclusion": "本研究通过构建DDL数据集，不仅为复杂真实世界伪造提供了一个更具挑战性的基准，还为研究提供了重要支持，从而促进下一代深度伪造检测、定位和解释方法的发展。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.06078", "html_url": "https://arxiv.org/abs/2507.06078", "title": "ScoreAdv：基于扩散模型的分数导向自然对抗样本生成", "title_en": "ScoreAdv: Score-based Targeted Generation of Natural Adversarial Examples via Diffusion Models", "authors": "Chihan Huang,Hao Tang", "background": "尽管深度学习在各个领域取得了巨大成功，但在对抗攻击面前仍显脆弱。虽然许多现有的对抗攻击方法能够实现高成功率，但它们通常依赖于 $\boldsymbol{\text{p}}$ 范数扰动约束，这并不符合人类的感知能力。因此，研究人员将注意力转向生成自然且无约束的对抗样本（UAEs）。尽管基于生成对抗网络（GAN）的方法存在固有局限性，如图像质量差、不稳定性和模式崩塌等问题，扩散模型（diffusion models）已被用于UAE生成，但它们仍然依赖于逐步的迭代Projected Gradient Descent (PGD) 扰动注入方法，并未充分利用其核心去噪功能。", "innovation": "本文提出了一种基于扩散模型的新颖生成UAE方法，称为ScoreAdv。该方法引入了可解释的对抗引导机制，逐步将采样分布转向对抗分布，并利用可解释的显著性图来将参考图像的视觉信息注入到生成样本中。ScoreAdv 方法能够在各种环境（无论是黑色盒模型还是白色盒模型）下生成无限数量的自然对抗样本，并且不仅可以攻击分类模型，还可以攻击检索模型。广泛的实验结果表明，ScoreAdv 达到了最先进的攻击成功率和图像质量，同时保持了高效的推理效率。此外，去噪与对抗扰动之间的动态平衡使 ScoreAdv 在防御措施下仍保持其鲁棒性。", "conclusion": "ScoreAdv 在生成高质量自然对抗样本方面取得了显著效果，并且能够保持良好的推理效率。其动态平衡的去噪和对抗扰动机制使其在防御措施下仍具有鲁棒性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2507.08772", "html_url": "https://arxiv.org/abs/2507.08772", "title": "从一到多：基于上下文的部分先验在3D生成中的应用", "title_en": "From One to More: Contextual Part Latents for 3D Generation", "authors": "Shaocong Dong,Lihe Ding,Xiao Chen,Yaokun Li,Yuxin Wang,Yucheng Wang,Qi Wang,Jaehyeok Kim,Chenjian Gao,Zhanpeng Huang,Zibin Wang,Tianfan Xue,Dan Xu", "background": "最近在3D生成方面的进展已经从多视图2D渲染方法转变为了利用真实数据中几何先验的3D原生潜扩散框架。尽管取得了这些进展，三个关键限制仍然存在：（1）单一潜表征无法捕捉复杂的多部分几何形状，导致细节退化；（2）全局潜编码忽略了对于组合设计至关重要的部分独立性和相互关系；（3）全局条件机制缺乏详细的可控性。在借鉴人类3D设计工作流程的基础上，本文提出了一种部分感知的扩散框架CoPart，用于将3D对象分解为上下文部分潜表征，以实现一致的多部分生成。这种范式提供了三项优势：(i) 通过部分分解降低编码复杂性；(ii) 允许明确的部分关系建模；(iii) 支持部分级条件。我们进一步开发了一种相互指导策略，以调整预训练的扩散模型，确保部分潜空间的去噪、几何一致性和基础模型先验的有效结合。为了实现大规模训练，本文构建了Partverse - 一个源自Objaverse的新型3D部分数据集，通过对网格进行自动化分割并通过人工验证注释来构建。", "innovation": "本文提出了CoPart，一种新型的部分感知潜扩散框架，它通过部分分解降低编码复杂性，并允许对部分关系的明确建模和支持部分级条件。此外，通过调整预训练的扩散模型，实现了部分潜空间的去噪，确保了几何一致性和基础模型先验的有效结合。构建了Partverse以便实现大规模训练，通过自动化网格分割及人工验证注释来构建。", "conclusion": "大规模实验证明，CoPart在部分级编辑、有轨物体生成和场景组合中展现出前所未有的可控性。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.05417", "html_url": "https://arxiv.org/abs/2508.05417", "title": "平滑Slot注意力迭代和递归", "title_en": "Smoothing Slot Attention Iterations and Recurrences", "authors": "Rongzhen Zhao,Wenyan Yang,Juho Kannala,Joni Pajarinen", "background": "Slot Attention (SA)和其变体是主流对象中心学习（OCL）的核心。通过迭代精炼初始查询向量，将图像中的对象聚合为各自的槽向量。在视频中，这种聚合在帧间递归共享，初始帧上的查询冷启动，非初始帧上的查询在上一帧的槽上过渡。然而，冷启动查询缺乏样本特定的线索，阻碍了初始帧的精准聚合；而且非初始帧上的查询已经是样本特定的，因此需要与初始帧聚合不同的变换。本研究首次解决了这些问题。", "innovation": "本文提出了一种平滑机制——SmoothSA，以解决上述问题：(1) 通过在OCL内部自学习一个小模块来丰富初始查询向量的信息，从而平滑初始帧上的SA迭代。(2) 通过在初始帧和非初始帧使用不同的变换（分别用全迭代和单迭代），来平滑所有视频帧间的SA递归变换。实验验证了该方法的有效性，并通过对SmoothSA的进一步分析清晰揭示了如何平滑SA迭代和递归。", "conclusion": "本研究在对象发现、识别和下游基准测试上的综合实验验证了SmoothSA方法的有效性，并通过进一步分析直观地阐明了如何平滑SA迭代和递归。相关的源代码、模型检查点和训练日志可以在指定的链接处获取。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.07981", "html_url": "https://arxiv.org/abs/2508.07981", "title": "全视效：统一与空间可控的视觉效果生成", "title_en": "Omni-Effects: Unified and Spatially-Controllable Visual Effects Generation", "authors": "Fangyuan Mao,Aiming Hao,Jintao Chen,Dongxia Liu,Xiaokun Feng,Jiashu Zhu,Meiqi Wu,Chubin Chen,Jiahong Wu,Xiangxiang Chu", "background": "视觉效果（VFX）是现代影视制作中不可或缺的视觉增强手段。尽管视频生成模型为VFX生产提供了成本效益高的解决方案，但当前方法受限于每种效果的LoRA训练，限制了效果的生成单一性。这阻碍了需要在指定位置同时生成多种效果的空间控制复合效果的应用。然而，将多种视觉效果整合到统一框架中面临重大挑战：多视效联合训练过程中的效果差异干扰和空间不可控性。", "innovation": "我们提出了Omni-Effects，这是一种统一框架，能够生成由提示引导的效果和空间可控的复合效果。框架的核心包括两个关键创新：1.基于LoRA的专家组（LoRA-MoE），通过一组专家LoRA将多种效果整合到单一模型中，有效减轻了跨任务干扰；2.空间感知提示（SAP），通过结合空间掩码信息到文本标记中，实现精确的空间控制。此外，我们引入了一个独立信息流（IIF）模块，集成在SAP中，隔离了对应于个别效果的控制信号，以防止任何不希望的混合。", "conclusion": "广泛的实验表明，Omni-Effects实现了精确的空间控制和多种效果的生成，使用户能够指定所需的视觉效果的类别和位置。为支持这一研究，我们通过一种新的数据收集管道——结合图像编辑和First-Last Frame-to-Video（FLF2V）合成构建了全方位VFX数据集Omni-VFX，并引入了专门的VFX评估框架以验证模型性能。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.08186", "html_url": "https://arxiv.org/abs/2508.08186", "title": "KARMA: 通过柯尔莫哥洛夫-阿诺德表示学习实现高效的结构缺陷分割", "title_en": "KARMA: Efficient Structural Defect Segmentation via Kolmogorov-Arnold Representation Learning", "authors": "Md Meftahul Ferdaus,Mahdi Abdelguerfi,Elias Ioup,Steven Sloan,Kendall N. Niles,Ken Pathak", "background": "在建筑基础设施的结构性缺陷语义分割中，由于缺陷形态的多变性、恶劣成像条件以及类别不平衡的问题，仍面临着挑战。现有的深度学习方法尽管有效，但通常需要数百万级别的参数，这使得它们在实时检查系统中变得不切实际。", "innovation": "提出了一种高效且参数精简的语义分割框架KARMA（Kolmogorov-Arnold Representation Mapping Architecture）。KARMA通过一维函数的组合来建模复杂的缺陷模式，而非传统卷积。KARMA包含三项技术创新：1. 极为参数精简的Tiny Kolmogorov-Arnold Network（TiKAN）模块，利用低秩分解进行KAN基础特征转换；2. 优化过的具有分隔卷积的特征金字塔结构，用于多尺度缺陷分析；3. 静态-动态原型机制，增强不平衡类别的特征表示。", "conclusion": "在基准基础设施检测数据集上的广泛实验表明，KARMA实现了与当前最先进的方法相当甚至更好的平均Intersection over Union（IoU）性能，同时使用了显著少的参数（0.959M vs. 31.04M，减少97%）。KARMA以0.264 GFLOPS的速度运行，保持了适用于实时部署的推断速度，使得无需牺牲准确性即可实现实用化的自动化基础设施检查系统。源代码可在以下URL获取：this https URL."}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.04448", "html_url": "https://arxiv.org/abs/2509.04448", "title": "TRUST-VL: 一种通用多模态 misinformation 检测的可解释新闻助手", "title_en": "TRUST-VL: An Explainable News Assistant for General Multimodal Misinformation Detection", "authors": "Zehong Yan,Peng Qi,Wynne Hsu,Mong Li Lee", "background": "多模态 misinformation 涵盖了文本、视觉以及跨模态的篡改，这种现象在生成式 AI 的加持下日益构成社会威胁。现有方法通常针对单一类型的篡改，难以泛化到未见过的情景中。", "innovation": "TRUST-VL 是一个统一且可解释的图像-语言模型，用于通用多模态 misinformation 检测。它引入了 Question-Aware Visual Amplifier 模块以提取任务特定的视觉特征，并构建了包含 198,000 个样本的 TRUST-Instruct 数据集，支持多模态推理链与人类事实核查工作流程对齐。实验表明，TRUST-VL 在检测 misinformation 上达到了最先进的性能，并且具有良好的泛化能力和解释性。", "conclusion": "通过对不同 types 的 joint training，TRUST-VL 优化了知识共享，增强了模型的泛化能力。其提问感知的视觉增强模块有助于提高模型的解释性，同时在多个 benchmark 上达到了优异的表现。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.06771", "html_url": "https://arxiv.org/abs/2509.06771", "title": "D-HUMOR：通过多模态开放推理理解黑暗幽默——一个基准数据集和方法", "title_en": "D-HUMOR: Dark Humor Understanding via Multimodal Open-ended Reasoning - A Benchmark Dataset and Method", "authors": "Sai Kartheek Reddy Kasu,Mohammad Zia Ur Rehman,Shahid Shafi Dar,Rishi Bharat Junghare,Dhanvin Sanjay Namboodiri,Nagendra Kumar", "background": "在线表情包中的黑暗幽默因其依赖于微妙、敏感且文化背景下的暗示而带来了独特的挑战。目前缺乏检测这种多元模态内容中黑暗幽默的相关资源和方法。", "innovation": "提出了一个新颖的数据集，包含4,379个标注有黑暗幽默、目标类别（性别、心理健康、暴力、种族、残疾及其他）及强度等级（轻微、中等、严重）的Reddit表情包。在此基础上，设计了一种增强推理的方法：首先使用大型视觉-语言模型（VLM）生成结构化的解释，并通过角色反转自循环迭代细化这些解释，确保其完整性和一致性。最后，通过三流交叉推理网络（TCRNet）将文字、视觉和推理信息融合起来，为分类提供统一的表示。", "conclusion": "该方法在黑暗幽默检测、目标识别和强度预测三项任务上均优于强基准模型。数据集、注释和代码已公开，旨在促进多模态幽默理解和内容审核领域的进一步研究。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.10566", "html_url": "https://arxiv.org/abs/2508.10566", "title": "HM-Talker: 混合运动建模方法实现高保真度的说台词头像合成", "title_en": "HM-Talker: Hybrid Motion Modeling for High-Fidelity Talking Head Synthesis", "authors": "Shiyu Liu,Kui Jiang,Xianming Liu,Hongxun Yao,Xiaocheng Feng", "background": "目前的方法在生成说话头像视频时，经常会出现运动模糊和嘴唇抖动的问题，主要原因是它们依赖于隐式建模的声-面部运动关联，缺乏明确的语音运动先验（即，与语音相关的面部运动的解剖学指导）。这种缺乏精确解剖学指导的建模方式限制了生成的真实性和一致性。现有方法存在频谱-视觉对齐偏差，以及依赖个体特征的偏差，这限制了跨对象的泛化能力。", "innovation": "该论文提出了HM-Talker框架，这是一种利用混合运动表示生成高质量、时间上一致的说话头像的新方法。HM-Talker通过结合显式和隐式运动线索，克服了上述缺陷。它包括交叉模态解耦模块（CMDM），用于从对齐的视觉线索直接预测动作单元（AUs）并提取互补的隐式与显式运动特征；混合运动建模模块（HMMM），该模块动态合并随机配对的隐式与显式特征，确保学习过程对身份保持无偏见。这些组件共同实现了不同身份下的鲁棒唇同步，提高了个人化头像合成的效果。", "conclusion": "通过广泛的实验，研究成果表明HM-Talker框架在视觉质量和唇部同步准确性方面优于当下最先进的方法。这种方法不仅增强了用户在人机交互中的参与度，还代表了合成说台词头像从技术和用户体验上的重要改进。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.23885", "html_url": "https://arxiv.org/abs/2509.23885", "title": "Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction", "title_en": "Tunable-Generalization Diffusion Powered by Self-Supervised Contextual Sub-Data for Low-Dose CT Reconstruction", "authors": "Guoquan Wei,Liu Shi,Zekun Zhou,Wenzhe Shan,Qiegen Liu", "background": "当前基于深度学习的低剂量CT去噪模型依赖于成对数据且泛化能力差。即使是对分布学习更关心的扩散模型也难以在医学临床应用中满足需求。自监督学习方法在将预训练剂量泛化到其他剂量时也面临模型泛化能力显著降低的挑战。", "innovation": "提出了一个名为Tunable-Generalization Diffusion (TurnDiff)的新方法。该方法通过自监督的上下文子数据设计了一种上下文子数据自增强相似性策略，用于低剂量CT投影域去噪。此外，还结合知识蒸馏与深层扩散模型，优化图像细节。采用前向预训练模型进行推断重建，并提出了像素级自校正融合技术，以增强图像保真度。该方法灵活应用于不同剂量泛化。", "conclusion": "在基准数据集和实际数据上的综合评估表明，TurnDiff在重建和泛化方面均优于最先进的方法。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24267", "html_url": "https://arxiv.org/abs/2509.24267", "title": "Cycle Diffusion Model for Counterfactual Image Generation", "title_en": "Cycle Diffusion Model for Counterfactual Image Generation", "authors": "Fangrui Huang,Alan Wang,Binxu Li,Bailey Trang,Ridvan Yesiloglu,Tianyu Hua,Wei Peng,Ehsan Adeli", "background": "深度生成模型已经在医学图像合成方面取得了显著的成功。然而，为确保合成图片的真实性（即条件忠实性），并产出高质量的图片以支持直接或反事实生成，依然面临着挑战。", "innovation": "本文介绍了一种循环训练框架，用于微调扩散模型，以改进条件忠实度并增强合成图像的真实感。本文提出的方法，循环扩散模型（CDM），通过引入循环约束来加强生成图和原始图之间的一致性，从而提高直接和反事实生成的可靠性。", "conclusion": "我们的方法在3D脑MRI数据集（来自ABCD, HCP老年与年轻人, ADNI, PPMI）上的实验表明，它能提高条件准确性并提升图像质量（通过FID和SSIM评估）。结果表明，CDM中的循环策略可以作为一种有效的模型，用于优化基于扩散的医学图像生成，进而应用于数据扩充、反事实及疾病进展建模。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2508.01345", "html_url": "https://arxiv.org/abs/2508.01345", "title": "从随机槽-特征对预测视频槽注意力查询", "title_en": "Predicting Video Slot Attention Queries from Random Slot-Feature Pairs", "authors": "Rongzhen Zhao,Jian Li,Juho Kannala,Joni Pajarinen", "background": "无监督视频对象中心学习（OCL）很有前景，因为它能够实现基于对象的场景表示和动力学建模，类似人类的认知方式。当前的主流视频OCL方法采用递归结构：聚合器通过一些查询将当前视频帧聚合为对象特征（称为槽），转换器根据当前槽预测下一个帧的查询。尽管这是一个有效的架构，但现有的所有实现都忽视了接下来的帧特征，这是查询预测的最有信息来源，同时也未能学习到对于查询预测至关重要的转换动力学。", "innovation": "我们提出了Random Slot-Feature pair for learning Query prediction (RandSF.Q)，通过引入新的转换器（t1）将槽和特征结合起来，提供更多信息以预测查询；通过训练方法（t2）从可用重播中随机选取槽-特征对来预测查询，以促使模型学习转换动力学。", "conclusion": "实验表明，我们的方法在场景表示方面显著超越了现有的视频OCL方法，例如在对象发现的得分上提高了10个点，制定了新的SOTA标准。这种优越性对下游任务如动力学建模也有益处。核心源代码、模型检查点和训练日志可以在此网址找到（提供的链接）。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.09672", "html_url": "https://arxiv.org/abs/2509.09672", "title": "图像扩散模型中的局部性源自数据统计特性", "title_en": "Locality in Image Diffusion Models Emerges from Data Statistics", "authors": "Artem Lukoianov,Chenyang Yuan,Justin Solomon,Vincent Sitzmann", "background": "近期研究显示，图像扩散模型的泛化能力来源于训练神经网络的局部性质。特别地，在去除某个像素的噪声时，模型依赖于输入图像围绕该像素的有限邻域，这与模型生成新图像的能力紧密相关。鉴于局部性对泛化的重要性，理解扩散模型为何学习局部行为及其决定因素至关重要。本文探讨了图像扩散模型中的局部性是如何形成的，以及这种局部性是如何由数据集统计特性决定的，而不是因卷积神经网络的归纳偏置。", "innovation": "本文提供证据表明，图像扩散模型中的局部性并非源于卷积神经网络的归纳偏置，而是源自数据集的统计特性。我们证明，最优的参数线性去噪器展示了类似深层神经去噪器的局部性。通过理论和实验，我们发现这种局部性直接来源于图像数据集中的像素相关性。此外，特定数据集上的局部性模式可以接近数据协方差的主要成分。基于这些见解，我们构建了一个符合深层扩散模型预测分数的分析去噪器，优于先前的手工制作替代品。主要创新点在于，虽然神经网络架构影响生成质量，但它们的主要角色是捕捉数据中存在的局部模式。", "conclusion": "研究表明，尽管神经网络架构对生成质量有一定影响，但其主要功能是捕捉数据中存在的局部模式。去噪器可以根据图像数据集中的统计特性展现类似的局部性，而这种局部性并非由神经网络的架构决定，而是由数据本身的统计特性决定的。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.08771", "html_url": "https://arxiv.org/abs/2510.08771", "title": "LinearSR：解锁用于稳定高效图像超分辨率的线性注意力", "title_en": "LinearSR: Unlocking Linear Attention for Stable and Efficient Image Super-Resolution", "authors": "Xiaohui Li,Shaobin Zhuang,Shuo Cao,Yang Yang,Yuandong Pu,Qi Qin,Siqi Luo,Bin Fu,Yihao Liu", "background": "生成模型在图像超分辨率(SR)方面变得越来越强大，但它们对自注意力的二次复杂度(O(N^2))造成了重要的计算瓶颈。线性注意力提供了一个O(N)的解决方案，但它的在生成逼真超分辨率图像方面的潜力在过去一直未能充分发挥，主要是由于一系列尚未解决的挑战阻碍了其应用。", "innovation": "这篇文章引入了LinearSR，这是一个整体框架，首次系统地克服了这些关键障碍。具体来说，我们通过一种新颖的基于“膝点”的早期停止指导微调(ESGF)策略解决了训练过程中导致模型灾难性发散的基本不稳定性问题。此外，我们使用一种专门基于信噪比的专家混合(MoE)架构解决了经典的感知失准权衡问题。最后，我们确立了一种有效且轻量级的指导范式，称为来自精度优先原则的TAG。我们的LinearSR模型同时实现了最先进的感知质量与出色的效率。它的核心扩散前向传播仅需1次非流计算(NFE)，达到了SOTA的速度标准，同时其整体多步推理时间仍然具有竞争力。", "conclusion": "本文提供了一种稳健的方法，用于在 photorealistic SR 领域应用线性注意力，为将来高效生成超分辨率的研究奠定了基础框架。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14431", "html_url": "https://arxiv.org/abs/2510.14431", "title": "实时统一内插与间插编码的神经视频压缩", "title_en": "Real-Time Neural Video Compression with Unified Intra and Inter Coding", "authors": "Hui Xiang,Yifan Bian,Li Li,Jingran Wu,Xianguo Zhang,Dong Liu", "background": "近年来，神经视频压缩（NVC）技术发展迅速，如DCVC-RT等方案提供了超越H.266/VVC的压缩效率并具备实时编码/解码能力。然而，现有的NVC方案存在处理遮挡和新内容不高效、帧间错误传播与累积等问题。经典视频编码方案中允许在间插编码帧中进行内插编码以解决这些问题，本文借鉴这一思想，提出一个统一内插与间插编码的NVC框架，每个帧由单一模型进行适配性地内插/间插编码，并采用双边帧间冗余压缩设计，实验结果显示该方案平均减少了12.1%的BD率，具有更稳定的比特率和每帧质量和实时编码/解码性能保留。", "innovation": "提出一个统一内插与间插编码的NVC框架，该框架中每个帧由单一模型进行适配性地内插/间插编码，并采用双边帧间冗余压缩设计，有效解决了NVC方案中的遮挡和新内容处理不高效、帧间错误传播与累积等问题，且保持了实时编码/解码性能。", "conclusion": "实验结果表明，该方案平均减少了12.1%的BD率，具有更稳定的比特率和每帧质量和保留了实时编码/解码性能。可以预见，该研究提出的统一编码框架将为未来的NVC技术提供新的思路和解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.14904", "html_url": "https://arxiv.org/abs/2510.14904", "title": "MaskCaptioner：学习在视频中联合分割和描述对象轨迹", "title_en": "MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos", "authors": "Gabriel Fiastre,Antoine Yang,Cordelia Schmid", "background": "Dense Video Object Captioning (DVOC) 是一项复杂的任务，要求在视频中联合检测、跟踪和描述对象轨迹，并以自然语言表达时空细节。由于任务复杂性高且手动标注成本高昂，以往方法采用分离的训练策略，这可能导致性能不佳。因此，需要一种新的方法来提高DVOC效果，特别是利用现有的大规模对象检测和分割数据集进行训练，并能够联合完成检测、分割、跟踪和描述任务。", "innovation": "本研究提出了一种名为MaskCaptioner的端到端模型，它通过结合一个最先进的视觉语言模型生成时空局部化的标签。特别地，通过将LVIS和LV-VIS数据集扩展为包含合成标签的LVISCap和LV-VISCap数据集来进行预训练。MaskCaptioner在三个现有的基准测试（VidSTG、VLN和BenSMOT）上取得了最先进的DVOC结果，证明了其在时空细节理解和自然语言描述方面的能力。", "conclusion": "通过这项研究，MaskCaptioner模型在DVOC任务上取得了显著的性能提升。所提出的方法不仅提高了DVOC的整体性能，还为未来研究提供了新的视角和数据集支持。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.16396", "html_url": "https://arxiv.org/abs/2510.16396", "title": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "title_en": "SPLite Hand: Sparsity-Aware Lightweight 3D Hand Pose Estimation", "authors": "Yeh Keng Hao,Hsu Tzu Wei,Sun Min", "background": "由于AR/VR设备的日益普及，深度学习模型在边缘设备上的部署已成为关键挑战。这些设备需要实时推理、低能耗和最小化时延。许多框架设计师需要在效率和性能之间找到平衡。", "innovation": "我们设计了一个轻量级框架，采用了编码器-解码器架构，并引入了几项关键贡献以提高效率和准确性。我们通过在ResNet-18基础骨干上应用稀疏卷积来利用手部姿态图中的固有稀疏性，实现了端到端42%的效率提升。此外，我们提出了SPLite解码器，这新的架构在树莓派5上将解码过程的帧率提升了3.1倍，同时保持了准确性。我们还应用了量化意识训练以优化性能，在保证准确性的前提下减少了内存使用。", "conclusion": "我们的系统在树莓派5 CPU（BCM2712四核Arm A76处理器）上实现了2.98倍的加速。我们的方法还在复合基准数据集上进行评估，展示了与现有最佳方法具有可比的准确性，同时显著提高了计算效率。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.16556", "html_url": "https://arxiv.org/abs/2510.16556", "title": "适于现实世界的深伪检测吗？", "title_en": "Fit for Purpose? Deepfake Detection in the Real World", "authors": "Guangyu Lin,Li Lin,Christina P. Walker,Daniel S. Schiff,Shu Hu", "background": "随着生成对抗网络、扩散模型和多模态大型语言模型的进步，AI生成的内容迅速增长，使得合成媒体的创建和传播变得非常容易。这增加了虚假信息的风险，尤其是在政治领域，这种伪造的媒体曲解了事实，并削弱了公众对政治机构的信任。为此，政府、研究机构和产业界推动了深伪检测项目的开发，但大多现有的模型只是在受控制的实验室环境中训练和验证，缺乏对社交平台上传播的真实世界政治深伪的有效识别能力。", "innovation": "本研究首次基于政治深伪事件数据库引入了一个系统的基准测试，该数据库收集了自2018年以来在社交媒体上分享的真实政治深伪。研究对来自学术界、政府和产业界的最新深伪检测模型进行了系统的评估。研究发现，学术界和政府开发的检测器表现较差，虽然商业化的检测工具相比免费模型有更高的性能，但所有评估的检测器在真实世界的政治深伪面前普遍存在泛化能力不足的问题，容易受到简单操作的影响，尤其是在视频领域。", "conclusion": "研究结果强调需要基于政治背景的深伪检测框架，更好地保护公众在现实世界中的安全。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23981", "html_url": "https://arxiv.org/abs/2510.23981", "title": "TeleEgo: 在野外评估自我中心型AI助手的基准", "title_en": "TeleEgo: Benchmarking Egocentric AI Assistants in the Wild", "authors": "Jiaqi Yan,Ruilong Ren,Jingren Liu,Shuning Xu,Ling Wang,Yiheng Wang,Yun Wang,Long Zhang,Xiangyu Chen,Changzhi Sun,Jixiang Luo,Dell Zhang,Hao Sun,Chi Zhang,Xuelong Li", "background": "自我中心型AI助手在现实场景中需要处理多模态输入（视频、音频、文本），并能实时响应。然而，现有的基准测试通常是在单一场景下评估这些能力，缺乏真实的实时流场景，或者仅支持短期任务。该研究引入了一个长达14小时的自我中心型多模态数据集TeleEgo，包含工作与学习、生活方式与常规活动、社交活动和外出与文化四大领域的自我中心视频、音频和文本同步数据，并按照统一的全球时间线对齐。", "innovation": "TeleEgo 设计了一个长期、流动、多模态基准测试，用于评估自我中心型AI助手在日常场景中的性能。它定义了12个诊断子任务，覆盖记忆、理解以及跨记忆推理三个核心能力，并包含3291个人工验证的问答项目，测试严格设在实时环境中。TeleEgo 提出两个关键指标——实时准确性和记忆持久时间，以综合评估正确性、时间响应性和长期记忆。", "conclusion": "TeleEgo 提供了一种现实且全面的评估体系，以促进实用型AI助手的发展。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.22319", "html_url": "https://arxiv.org/abs/2510.22319", "title": "GRPO-Guard：通过受控剪裁减轻流匹配中的隐形过度优化", "title_en": "GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping", "authors": "Jing Wang,Jiajun Liang,Jie Liu,Henglin Liu,Gongye Liu,Jun Zheng,Wanyuan Pang,Ao Ma,Zhenyu Xie,Xintao Wang,Meng Wang,Pengfei Wan,Xiaodan Liang", "background": "最近，基于GRPO的强化学习在优化流匹配模型方面取得了显著进展，有效提高了模型与任务特定奖励的一致性。然而，在实际应用中，我们观察到重要性比率分布发生系统性偏移，其均值低于1，并且在各个时间步之间差异显著。这种偏移和不一致导致正面优势样本无法进入受剪裁的区域，使得机制无法有效约束过度自信的正面更新。结果，策略模型不可避免地进入一个隐式的过度优化阶段—尽管代理奖励继续增加，但关键指标如图像质量和文本提示对齐度却急剧恶化，最终使得学习策略在实际应用中变得不可行。", "innovation": "本文提出了一种简单的但有效的方法GRPO-Guard，作为现有GRPO框架的改进。该方法引入了比率标准化，恢复了平衡且每步一致的重要性比率，确保PPO剪裁能适当地在整个去噪时间步中约束有害更新。此外，引入的梯度重加权策略在噪声条件下平衡策略梯度，防止特定时间步区域的过度更新。这些设计共同作为一种调节剪裁机制，稳定优化过程，大幅缓解隐式过度优化，而无需依赖繁重的KL正则化。", "conclusion": "我们在多个扩散模型基础（如SD3.5M，Flux.1-dev）和多样化的代理任务上进行了广泛的实验，结果证明GRPO-Guard显著减少了过度优化，同时维持甚至提高了生成质量。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23588", "html_url": "https://arxiv.org/abs/2510.23588", "title": "FARMER: Flow AutoRegressive Transformer over Pixels", "title_en": "FARMER: Flow AutoRegressive Transformer over Pixels", "authors": "Guangting Zheng,Qinyu Zhao,Tao Yang,Fei Xiao,Zhijie Lin,Jie Wu,Jiajun Deng,Yanyong Zhang,Rui Zhu", "background": "在机器学习领域，直接建模原始数据分布的显式似然性是关键课题。通过自回归模型使大规模语言模型取得成功。然而，对视觉像素数据进行连续自回归建模会带来极大的序列长度和高维空间问题。本文讨论了FARMER框架，它结合了归一化流和自回归模型，旨在解决这些问题。", "innovation": "FARMER框架提出了一种端到端生成模型，该模型将归一化流与自回归模型结合，用于可计算的似然估计和直接从原始像素中产生高质量图像。FARMER使用可逆的自回归流将图像转换为潜在序列，并利用自回归模型隐式地建模该分布。通过提出自动监督的维度减少方案，FARMER针对像素级别建模的冗余性问题进行了优化。此外，FARMER设计了一步蒸馏方案以加快推理速度，并引入了一种基于重采样的无分类引导算法以提高图像生成质量。", "conclusion": "实验结果表明，FARMER在与现有基于像素的生成模型的性能相当的同时，提供了精确的似然性和可扩展的训练能力。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25077", "html_url": "https://arxiv.org/abs/2510.25077", "title": "针对遥感图像分类的邻域特征聚合", "title_en": "Neighborhood Feature Pooling for Remote Sensing Image Classification", "authors": "Fahimeh Orvati Nia,Amirmohammad Mohammadi,Salim Al Kharsa,Pragati Naikare,Zigfried Hampel-Arias,Joshua Peeples", "background": "在遥感图像分类中，特征提取是一个关键步骤。传统的特征提取方法可能无法有效捕捉像素邻域之间的关系和局部相似性。为此，本文探讨了一种新的特征提取方法——邻域特征聚合(NFP)，旨在通过有效捕捉相邻输入之间的关系来提高遥感图像分类性能。", "innovation": "该文提出了一种新颖的特征提取方法——邻域特征聚合(NFP)，该方法能够在卷积层中实现，能够无缝集成到任何网络中。NFP能捕捉相邻输入之间的关系，并高效地聚集特征维度上的局部相似性，从而优化图像分类精度，同时保持参数量的最小化。", "conclusion": "实验结果表明，与基本模型相比，NFP始终能够跨多个数据集和网络架构提高性能，同时保持参数量的最小化。这表明NFP是一种有效的纹理特征提取方法，适用于遥感图像分类任务。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23968", "html_url": "https://arxiv.org/abs/2510.23968", "title": "胸部X射线分析的推理视觉语言模型", "title_en": "Reasoning Visual Language Model for Chest X-Ray Analysis", "authors": "Andriy Myronenko,Dong Yang,Baris Turkbey,Mariam Aboian,Sena Azamat,Esra Akcicek,Hongxu Yin,Pavlo Molchanov,Marc Edgar,Yufan He,Pengfei Guo,Yucheng Tang,Daguang Xu", "background": "视觉语言模型（VLMs）在医学图像分析中显示出强大的潜力，但大多数仍不透明，无法提供临床医生依赖的透明且逐步的推理过程。现有的模型主要提供预测结果，缺乏能解释推理过程的透明度，不利于临床审计和安全性的人工智能协作。本文旨在通过引入链式思考（CoT）推理框架，提升胸部X射线解读的可解释性，支持临床审计和人机协作的安全性。", "innovation": "本文提出了一种基于链式思考（CoT）的视觉语言模型，该模型能够通过结合高保真视觉编码与两阶段训练方法（监督微调SFT和强化学习RL），学习专家如何进行推理而不仅仅是得出结论。模型在分布式评估中达到了竞争力的多标签分类效果，同时提高了可解释性。在专家放射科医生的读者研究中，完整的推理轨迹提高了信心，支持了错误审计，并减少了完成报告的时间。该框架强调通过可验证的奖励机制学习，提高了诊断的准确性和解释性，有助于发展可信赖和可解释的AI在胸部放射学和其他医学成像任务中。", "conclusion": "本文发布了一个基于推理的视觉语言模型，该模型通过高保真视觉编码与两阶段训练方法，学习专家如何进行医疗图像的推理和解释。该模型在保持准确性的同时，显著提升了对推理过程的透明度。研究结果表明，这种模型能够提高医生对诊断结果的信任，支持临床审核，减少错误，并促进更安全的人工智能应用。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.24134", "html_url": "https://arxiv.org/abs/2510.24134", "title": "VC4VG: 优化文本到视频生成的视频字幕", "title_en": "VC4VG: Optimizing Video Captions for Text-to-Video Generation", "authors": "Yang Du,Zhuoran Lin,Kaiqiang Song,Biao Wang,Zhicheng Zheng,Tiezheng Ge,Bo Zheng,Qin Jin", "background": "近年来，基于文本到视频（T2V）生成的研究突显了高质量视频文本对对生成一致且指令对齐视频的重要性。然而，专门针对T2V训练的字幕优化策略尚未得到充分探索。本研究旨在通过分析从T2V视角出发的字幕内容，将视频重建所需的要素分解到多个维度，并提出一种规范性的字幕设计方法，从而构建一个专为T2V模型设计的综合字幕优化框架。同时，开发了一个新的基准VC4VG-Bench，包含细致的、多维度的和必要性分级的指标，以满足T2V特定需求。广泛的T2V细调实验表明，字幕质量提高与视频生成性能之间存在密切联系，验证了本方法的有效性。相关工具和代码已发布以支持进一步研究。", "innovation": "本研究提出了专门针对T2V模型需求设计的字幕优化框架VC4VG，包括细致的字幕设计方法和专为T2V制定的新基准VC4VG-Bench，该基准包含与T2V特定需求相符的多维度细化度量。研究验证了字幕质量提高与视频生成性能之间的强相关性，提出的方法具有显著效果。", "conclusion": "大量T2V细调实验显示了提高字幕质量与视频生成性能之间的密切联系，验证了所提出方法的有效性。所有基准工具和代码已公开，供进一步研究使用。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.25327", "html_url": "https://arxiv.org/abs/2510.25327", "title": "MMEdge：通过分阶段感知和编码加速边缘设备上的多模态推理", "title_en": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined Sensing and Encoding", "authors": "Runxi Huang,Mingxuan Yu,Mingyu Tsoi,Xiaomin Ouyang", "background": "在自主驾驶、人机交互和移动健康等领域，边缘设备上的实时多模态推理至关重要。然而，以往的研究往往忽略了感知动态与模型执行之间紧密的耦合关系，以及不同模态之间的复杂依赖关系。", "innovation": "本文提出了MMEdge，一种新的基于分阶段感知和编码的边缘设备多模态推理框架。MMEdge允许计算在数据到达时逐步进行，并引入了轻量级但有效的时序聚合模块，以捕捉不同分阶段单元间的丰富时序动态，从而保持准确度。此外，MMEdge还包含了一个适应性的多模态配置优化器和多模态推测跳过机制，以优化系统性能和处理不同的资源和输入数据复杂度。", "conclusion": "我们在两个公开的多模态数据集上评估了MMEdge，并将其部署在基于无人机的真实多模态测试平台上。实验结果显示，MMEdge在保持高任务准确度的同时，显著减少了端到端延迟。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2503.22159", "html_url": "https://arxiv.org/abs/2503.22159", "title": "Disentangled 4D Gaussian Splatting: 以343 FPS 渲染高分辨率动态世界", "title_en": "Disentangled 4D Gaussian Splatting: Rendering High-Resolution Dynamic World at 343 FPS", "authors": "Hao Feng,Hao Sun,Wei Xie,Zhi Zuo,Zhengzhe Liu", "background": "尽管从2D视频生成动态新颖视图取得了进步，但高效重建和渲染动态场景仍然是一个具有挑战性的任务。", "innovation": "本文提出了一种新颖的表示和渲染管道——解耦4D高斯散列（Disentangled4DGS），实现了实时性能，在不影响视觉保真的情况下。Disentangled4DGS 解耦了4D高斯的空间和时间成分，避免了之前方法中的切片和四维矩阵计算。通过将时间和空间变形投影到动态2D高斯中，并延迟时间处理，我们减少了冗余计算。我们的方法还包括梯度引导流损失和时间划分策略，以减少伪影。实验表明，在单个RTX3090上以1352*1014分辨率渲染时，渲染速度和质量得到了显著改善，达到343 FPS，同时减少了至少4.5%的存储需求。我们的方法在动态新颖视图合成方面树立了新的基准，无论是多视图还是单目动态场景数据集，在各方面都优于现有方法.", "conclusion": "我们的方法在动态新颖视图合成方面树立了新的基准，通过显著提高渲染速度和质量，同时减少存储需求，打破了现有的性能记录。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2505.13444", "html_url": "https://arxiv.org/abs/2505.13444", "title": "ChartMuseum: 测试大型视觉语言模型的视觉推理能力", "title_en": "ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models", "authors": "Liyan Tang,Grace Kim,Xinyu Zhao,Thom Lake,Wenxuan Ding,Fangcong Yin,Prasann Singhal,Manya Wadhwa,Zeyu Leo Liu,Zayne Sprague,Ramya Namuduri,Bodun Hu,Juan Diego Rodriguez,Puyuan Peng,Greg Durrett", "background": "大型视觉语言模型（LVLMs）在图表理解上面临独特挑战，因为这需要结合复杂的文本和视觉推理能力。然而，现有的LVLMs在这两种技能上的表现存在显著不平衡，特别是在难以在文本中进行的视觉推理方面表现较差。研究通过合成数据集进行案例研究，该数据集仅可通过视觉推理解决，结果发现随着视觉复杂性的增加，模型的性能显著下降，而人类的性能则保持稳定。", "innovation": "引入了一个新的图表问答基准——ChartMuseum。该基准包含1,162个由专家标注的问题，覆盖多种推理类型，来自184个不同来源的真实图表，旨在评估复杂的视觉和文本推理能力。和之前的图表理解基准不同，ChartMuseum能有效地揭示模型和人类之间的差距，而且对于要求视觉推理的问题，模型的表现相比文本推理为主的题目会下降35%-55%。", "conclusion": "尽管人类在ChartMuseum基准上的准确率为93%，但表现最佳的模型Gemini-2.5-Pro只有63.0%的准确率，而最领先的开源LVLM Qwen2.5-VL-72B-Instruct的准确率也只有38.5%。质性错误分析还揭示了一些特定的视觉推理类别，这当前的LVLMs难以处理。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.24325", "html_url": "https://arxiv.org/abs/2509.24325", "title": "ReCon-GS：保持连续性的高斯流式传输以实现快速且紧凑的动态场景重构", "title_en": "ReCon-GS: Continuum-Preserved Gaussian Streaming for Fast and Compact Reconstruction of Dynamic Scenes", "authors": "Jiaye Fu,Qiankun Gao,Chengxiang Wen,Yanmin Wu,Siwei Ma,Jiaqi Zhang,Jian Zhang", "background": "在线自由视点视频(FVV)重建面临着每帧优化缓慢、运动估计不一致以及存储需求无法持续的问题。", "innovation": "提出了一种名为ReCon-GS的新型存储意识框架，该框架可以在动态场景的高保真在线重建和实时渲染中发挥作用。该框架通过动态分配多级锚定高斯模型，以适应性密度捕获帧间几何变形，从而将场景运动分解为紧凑的粗细表示。设计了动态层次重构策略和内层次变形继承来保留局部运动表达能力，同时确保时间一致性。引入了存储意识优化机制，可以根据不同层次调整锚定高斯模型的密度，以实现重建保真度和内存使用之间的可控权衡。", "conclusion": "在三个广泛使用的数据集上的大量实验表明，与最先进的方法相比，ReCon-GS提高了大约15%的训练效率，并在增强鲁棒性和稳定性的情况下实现了优质的FVV合成。此外，在同等渲染质量的情况下，与领先的一流方法相比，ReCon-GS将内存需求减少了超过50%。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.17148", "html_url": "https://arxiv.org/abs/2510.17148", "title": "DiffVLA++: 通过度量引导对齐连接认知推理与端到端驾驶", "title_en": "DiffVLA++: Bridging Cognitive Reasoning and End-to-End Driving through Metric-Guided Alignment", "authors": "Yu Gao,Anqing Jiang,Yiru Wang,Wang Jijun,Hao Jiang,Zhigang Sun,Heng Yuwen,Wang Shuo,Hao Zhao,Sun Hao", "background": "传统的端到端驾驶模型在生成物理上可实现的轨迹方面效果显著，但往往难以泛化处理长尾场景，因为缺乏必要的世界知识来理解周围的环境。相比之下，视觉-语言-动作（VLA）模型利用世界知识处理复杂情况，但其有限的三维推理能力可能导致物理上不可行的操作。", "innovation": "本文提出了一个增强的自动驾驶框架DiffVLA++，该框架通过度量引导对齐显式地结合了认知推理和端到端规划。首先，构建了一个直接生成语义上支撑的驾驶轨迹的VLA模块。其次，设计了一个确保物理可行性的端到端模块，具有密集的轨迹词汇。最重要的是，引入了一种度量引导的轨迹评分器，以引导和对齐VLA和端到端模块的输出，从而整合它们的互补优势。", "conclusion": "在ICCV 2025自主挑战排行榜上的实验表明，DiffVLA++的EPDMS得分为49.12。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.06159", "html_url": "https://arxiv.org/abs/2509.06159", "title": "FASL-Seg: 手术场景中的解剖结构和工具分割", "title_en": "FASL-Seg: Anatomy and Tool Segmentation of Surgical Scenes", "authors": "Muraam Abdel-Ghani,Mahmoud Ali,Mohamed Ali,Fatmaelzahraa Ahmed,Muhammad Arsalan,Abdulaziz Al-Ali,Shidin Balakrishnan", "background": "随着机器人微创手术的普及，基于深度学习的手术培训成为关键研究领域。语义分割模型能够帮助理解手术场景的各个部分，但目前大多数研究集中在手术工具上，而忽视了解剖对象。此外，当前最先进的（SOTA）模型在捕捉高层次上下文特征和低层次边缘特征方面存在困难。", "innovation": "提出了一个特征自适应空间定位模型（FASL-Seg），设计了通过两个不同处理流（低级特征投影流LLFP和高级特征投影流HLFP）来捕捉不同细节水平的特征，从而使解剖结构和手术器械分割更加精确。该模型在EndoVis18和EndoVis17基准数据集上的表现优于SOTA，分别达到了72.71%和85.61%以及72.78%的mIoU，展示了不同特征分辨率下的不同处理流的有效性。", "conclusion": "FASL-Seg模型在EndoVis18和EndoVis17数据集上分别实现了72.71%和85.61%以及72.78%的mIoU，这表明不同分辨率下的特征处理流可以实现解剖结构和器械的精确分割。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2509.16336", "html_url": "https://arxiv.org/abs/2509.16336", "title": "Neural Atlas Graphs for Dynamic Scene Decomposition and Editing", "title_en": "Neural Atlas Graphs for Dynamic Scene Decomposition and Editing", "authors": "Jan Philipp Schneider,Pratik Singh Bisht,Ilya Chugunov,Andreas Kolb,Michael Moeller,Felix Heide", "background": "高分辨率动态场景的可编辑表示在自动驾驶到创意编辑等多个领域内是一个开放的问题。当前最成功的方法在可编辑性与支持的场景复杂度之间做了妥协：神经地平面（Neural Atlases）将动态场景表示为两个变形的图像层，前景和背景，但在多个物体遮挡和交互时失效。相反，场景图模型虽然利用了来自自动驾驶数据集的标注数据（如掩码和边界框）来捕捉复杂的3D空间关系，但其隐式的体素节点表示在一致视图编辑方面具有挑战性。", "innovation": "论文提出了一种名为Neural Atlas Graphs (NAGs) 的混合高分辨率场景表示方法，每个图节点是一个基于视图依赖的神经地平面。该方法既实现了2D外观编辑，又实现了3D场景元素的排序和定位。在测试时拟合，NAGs实现了Waymo开放数据集的最先进的定量结果，在峰值信噪比（PSNR）方面提高了5 dB，超越了现有方法。此外，NAGs实现了高分辨率和视觉质量的环境编辑，能够创建新的背景和编辑车辆外观的虚假驾驶场景。该方法还能够适应自动驾驶场景之外的场景，PSNR方面超过7 dB的最新抠图和视频编辑基线，适用于包含人类和动物的多样场景。", "conclusion": "Neural Atlas Graphs (NAGs)通过结合神经地平面和场景图模型，提供了一种新型的高分辨率动态场景表示方法，实现了在复杂场景下高分辨率编辑，提高了编辑质量和场景通用性。该研究结果在量化表现和视觉质量方面都达到了显著的提升，特别是在自动驾驶和创意编辑等领域具有广泛的应用前景。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.21271", "html_url": "https://arxiv.org/abs/2510.21271", "title": "Buffer层用于测试时适应", "title_en": "Buffer layers for Test-Time Adaptation", "authors": "Hyeongyu Kim,Geonhui Han,Dosik Hwang", "background": "近年来，测试时适应(TTA)取得了显著进展，但大多数现有方法集中在更新标准化层以适应测试域。然而，依赖于基于标准化的适应存在关键挑战。一方面，如批量标准化(BN)这样的标准化层对小批量大小非常敏感，导致不稳定的统计值。另一方面，基于标准化的适应方法在结构上受限于预训练模型，依赖于训练时的统计值，这些统计值在面对未见过的领域时可能表现不佳。这些问题限制了基于标准化的TTA方法的有效性，尤其是在显著领域变化下。", "innovation": "本文提出了一个基于缓冲层(_Buffer layer_)概念的新型范例，解决了标准化层更新的根本限制。与现有的修改模型核心参数的方法不同，我们的方法保留了预训练主干的完整性，从根本上减轻了在线适应期间灾难性遗忘的风险。通过全面的实验，我们证明我们的方法不仅在减轻领域偏移和增强模型鲁棒性方面比传统方法更优秀，而且还具有强大的遗忘抵御能力。同时，我们的缓冲层是模块化的，可以无缝集成到几乎所有现有的TTA框架中，实现了各种架构的一致性能提升。这些发现验证了所提解决方案在实际领域适应场景中的有效性和灵活性。", "conclusion": "实验结果证明，我们的Buffer层方法不仅在减轻领域偏移和增强模型鲁棒性方面表现出色，还具有强遗忘抵御能力。该方法具有模块化特征，并可以在各种现有的TTA框架中无缝集成，从而实现多种架构的一致性能提升。这些发现表明，Buffer层在实际领域适应场景中的有效性和灵活性得到了验证。该代码可以在 [这个链接] 获得。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.23117", "html_url": "https://arxiv.org/abs/2510.23117", "title": "预见结构失效：基于图像的物理信息神经网络（PINN）在意大利面桥载荷预测中的应用", "title_en": "Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction", "authors": "Omer Jauhar Khan,Sudais Khan,Hafeez Anwar,Shahzeb Khan,Shams Ul Arifeen", "background": "物理信息神经网络（PINNs）因为能够将物理规律嵌入深度学习模型中而受到关注，这在具有有限数据的结构工程任务中尤其有用。本文旨在探索使用PINNs预测小型意大利面桥的重量，这是一种有助于理解简化结构模型的负载极限和可能失效模式的技术。", "innovation": "本文引入了新的架构——物理信息柯尔莫哥洛夫-阿诺德网络（PIKAN），该架构结合了通用函数近似理论和物理洞察。此外，提出了基于物理约束的预测模型以提高性能。实验结果显示，即使在数据有限的情况下，PINNs也可以提供可靠的结构重量估计，并有助于轻型桥梁设计的早期失效分析。", "conclusion": "最佳模型的$R^2$得分为0.9603，均方绝对误差（MAE）为10.50单位，表明PINNs能够准确预测结构重量。除了提供模型结果外，还提供了基于Web的界面供参数输入和预测使用。所有数据和代码可在指定链接中找到。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2506.19816", "html_url": "https://arxiv.org/abs/2506.19816", "title": "CronusVLA: 通过多帧视觉-语言-动作建模实现高效且稳健的操作", "title_en": "CronusVLA: Towards Efficient and Robust Manipulation via Multi-Frame Vision-Language-Action Modeling", "authors": "Hao Li,Shuai Yang,Yilun Chen,Xinyi Chen,Xiaoda Yang,Yang Tian,Hanqing Wang,Tai Wang,Dahua Lin,Feng Zhao,Jiangmiao Pang", "background": "基于预训练视觉-语言模型（VLMs）的近期视觉-语言-动作（VLA）模型在机器人操作方面展示了强大的性能。然而，这些模型仍然受限于单帧图像范式，未能充分利用多帧历史提供的时序信息。直接将多帧输入到VLM骨干网络中会带来巨大的计算开销和推理延迟，因此需要一种有效的方法来解决这一问题。", "innovation": "本文提出了CronusVLA，这是一种统一框架，使其能够从基于单帧的VLA模型扩展到多帧范式。该框架通过两阶段过程来解决多帧模型的问题：首先，在大规模的体觉数据集上进行单帧预训练，采用自回归预测动作标记；其次，进行多帧后训练，使视觉-语言骨干网络从离散标记预测调整为可学习特征预测，并通过特征分块聚合历史信息。这种方法有效解决了现有的多帧建模挑战，同时提升了性能和观测稳定性。为了评估受时序和空间干扰下的稳健性，引入了SimplerEnv-OR基准，包含24种观察性干扰类型和120种严重等级。实验结果表明，CronusVLA在仿真和真实环境的三种体觉模型中都取得了领先性能和更强的恢复力，成功率达到70.9%，在SimplerEnv上超过73.2%的性能，相比于OpenVLA在LIBERO上的26.8%性能提升，具有最高的SimplerEnv-OR得分。这些结果凸显了高效多帧适应在VLA模型中实现强大且稳健的现实世界部署的潜力。", "conclusion": "通过CronusVLA框架，本文成功解决了现有VLA模型中的多帧问题，增强了性能和观测稳定性，并通过实验验证了该方法在多帧视觉-语言-动作模型中的优势，展示了其在更广泛实际应用场景中的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25781", "html_url": "https://arxiv.org/abs/2510.25781", "title": "Kolmogorov-Arnold Networks (KANs) 使用指南", "title_en": "A Practitioner's Guide to Kolmogorov-Arnold Networks", "authors": "Amir Noorizadegan,Sifan Wang,Leevan Ling", "background": "Kolmogorov-Arnold Networks (KANs) 近期作为一种与传统多层感知机 (MLPs) 相比有潜力的新颖替代方案出现。KANs 由柯尔莫哥洛夫-阿诺尔德表示定理启发，在边缘使用可学习的单变量基函数替代固定激活函数的节点，这提供了更高的表达性和可解释性。", "innovation": "本研究通过系统地审视KANs的理论基础、架构变种和实用实施策略，提供了KANs领域的全面概览。研究表明，KANs通过使用不固定的基函数，提供比MLPs更优的参数效率，同时也讨论了各种基函数的选择及其在平滑性、局部性和计算成本方面的权衡，并总结了最近在提高准确性、效率和正则化的进展。", "conclusion": "本研究提供了KANs的实用选择指南，帮助实践者选择合适的架构，并指出了当前研究的空白。相关GitHub仓库提供了结构化的参考资料，支持KANs研究的持续发展。"}
{"llm_update_time": "20251031", "topic": "cs.CV", "pdf_url": "https://arxiv.org/pdf/2510.02781", "html_url": "https://arxiv.org/abs/2510.02781", "title": "GCVAMD: 一种修改后的因果VAE模型，用于因年龄相关性黄斑变性风险因素的检测和预测", "title_en": "GCVAMD: A Modified CausalVAE Model for Causal Age-related Macular Degeneration Risk Factor Detection and Prediction", "authors": "Daeyoung Kim", "background": "年龄相关性黄斑变性（AMD）是眼科中导致永久性视力损害的主要原因之一。尽管开发了诸如抗VEGF药物或光动力疗法等治疗方法来减缓AMD的退化过程，但目前尚无特定治疗方法可以逆转由AMD引起的视力损失。因此，在早期阶段检测患者视网膜中AMD的风险因素或AMD本身对于减少视力损害的可能性至关重要。除了传统的研究方法，基于深度学习的方法，特别是基于注意力机制的CNN和基于GradCAM的XAI分析在OCT扫描中区分AMD视网膜和正常视网膜方面表现出成功的性能，使得可以通过AI驱动的模型辅助眼科医生进行AMD的诊断和分析。然而，尽管取得了显著的成功，之前的大多数研究主要集中在预测性能本身，而不是AMD的病理或潜在的因果机制，这可能会妨碍对特定因素的干预分析，并可能导致不那么可靠的选择。因此，本文介绍了一种新的因果AMD分析模型：GCVAMD，该模型结合了一种修改后的因果VAE方法，可以从仅有的原始OCT图像中提取潜在线性因果因素。在AMD检测中考虑因果关系，GCVAMD能够进行因果推断，如治疗模拟或干预分析，关于主要风险因素：硬性 deposit 和新生血管化，同时返回有助于下游任务的有信息性的潜在线性因果特征。结果表明，通过GCVAMD，可以在GCVAMD潜在线性空间中识别出AMD的因果机制，这些机制可以用于各种任务，从AMD检测（分类）到干预分析。", "innovation": "GCVAMD 提出了一种新的因果分析模型，结合了修改后的因果VAE方法，可以从原始OCT图像中提取潜在的因果因素。该模型能够进行因果推断，如治疗模拟或干预分析，特别关注硬性 deposit 和新生血管化的风险因素。此外，通过GCVAMD，可以识别出与AMD因果机制相关的特征，这对于各种任务都有益。", "conclusion": "GCVAMD 模型通过引入因果VAE方法，实现了对AMD风险因素的有效检测和预测，为辅助眼科医生的诊断和分析提供了有力工具。该模型不仅提高了预测性能，还为进一步的干预分析提供了因果机制的理解。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25785", "html_url": "https://arxiv.org/abs/2510.25785", "title": "HiMAE: 层次掩蔽自编码器发现可穿戴时间序列中的分辨率特异性结构", "title_en": "HiMAE: Hierarchical Masked Autoencoders Discover Resolution-Specific Structure in Wearable Time Series", "authors": "Simon A. Lee,Cyrus Tanade,Hao Zhou,Juhyeon Lee,Megha Thukral,Minji Han,Rachel Choi,Md Sazzad Hissain Khan,Baiying Lu,Migyeong Gwak,Mehrab Bin Morshed,Viswam Nathan,Md Mahbubur Rahman,Li Zhu,Subramaniam Venkatraman,Sharanya Arcot Desai", "background": "可穿戴传感器提供了丰富的生理时间序列数据，但对其预测效用的原理仍不清楚。我们假设时间分辨率是一个基本的表征学习轴，在不同的临床和行为结果上依赖于不同的时间尺度结构。为了验证这一假设，我们引入了HiMAE（层次掩蔽自编码器），这是一个结合了掩蔽自编码和层次卷积编码解码器的自我监督框架。HiMAE生成多分辨率嵌入，有助于系统地评估哪个时间尺度携带了预测信号，将分辨率从超参数转变为可解释性探针。", "innovation": "HiMAE是一个自我监督的学习框架，它结合了掩蔽自编码和层次卷积编码解码器，生成多分辨率嵌入，用于表征学习。它能够在小得多的参数量下优于现有基础模型，且完全能在手表上运行，实现毫秒级的智能手表级CPU推理速度，成为一种有效且适用于边缘设备的自我监督学习方法，同时也是一种发现可穿戴健康中分辨率敏感结构的工具。", "conclusion": "HiMAE作为高效且自我监督的学习方法，不仅能够提供一种从超参数转变为可解释性探针的方式，还能作为一种发现可穿戴健康中分辨率敏感结构的工具，对理解和利用时间序列数据中的不同时间尺度具有重要意义。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25788", "html_url": "https://arxiv.org/abs/2510.25788", "title": "SHA-256 Infused Embedding-Driven Generative Modeling of High-Energy Molecules in Low-Data Regimes", "title_en": "SHA-256 Infused Embedding-Driven Generative Modeling of High-Energy Molecules in Low-Data Regimes", "authors": "Siddharth Verma,Alankar Alankar", "background": "高能材料（HEMs）对于推进和防御领域至关重要。然而，其发现受到实验数据的限制以及测试设施的访问限制。这项工作提出了一种新的高能分子生成方法，结合了长短期记忆（LSTM）网络进行分子生成和注意图神经网络（Attentive GNN）进行性质预测。该研究的背景是现有的新高能材料的发现非常依赖于实验数据和昂贵的测试设施，导致发现创新材料的难度较大。", "innovation": "本研究创新性地提出了将固定SHA-256嵌入与部分可训练表示集成的新型嵌入空间构建策略。这一方法改变了代表性的基础，重新塑造了分子输入空间，在学习开始之前。无需预训练，生成器实现了67.5%的有效性和37.5%的新颖性。生成的高能分子库显示出0.214的平均塔曼托系数，表明框架能够生成多样化的化学空间。此外，研究人员发现了37种新超爆炸物，预测的爆速高于9 km/s。这些创新为在数据量不足的情况下高效发现高能新物质提供了新方法。", "conclusion": "研究提出了一种新的基于生成模型的方法来生成高能分子，通过LSTM和Attentive GNN结合的策略，成功生成了多种新型高能物质，特别是在数据量较少的情况下，为高能材料的探索开辟了新路径。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25798", "html_url": "https://arxiv.org/abs/2510.25798", "title": "MemEIC：迈向持续性和组合性知识编辑", "title_en": "MemEIC: A Step Toward Continual and Compositional Knowledge Editing", "authors": "Jin Seong,Jiyun Park,Wencke Liermann,Hongseok Choi,Yoonji Nam,Hyun Kim,Soojong Lim,Namhoon Lee", "background": "由于信息的动态性质，大规模视觉语言模型（LVLMs）需要不断更新。虽然最近的知识编辑技术显示出有希望的方向，但它们通常集中在单一模态（视觉或语言）的孤立编辑上，忽略了LVLMs本有的多模态特性和知识更新的连续性，这可能导致在考虑模态间的交互和持续性知识精炼时产生次优编辑结果。", "innovation": "我们提出了MemEIC，一种新的大规模视觉语言模型（LVLMs）连续性和组合性知识编辑（CCKE）方法。MemEIC通过顺序编辑视觉和文本知识实现组合编辑。该方法采用混合外部-内部编辑器，具备跨模态证据检索的双重外部记忆和促进每种模态独立参数更新的双重LoRA适配器。关键组成部分是一个受大脑启发的知识连接器，在组合推理时可选择性激活，以跨模态整合信息。实验表明，MemEIC在复杂多模态问题上显著提高了性能，有效地保留了先前的编辑，并为CCKE在LVLMs中的表现设定了新基准。", "conclusion": "MemEIC显著提升了复杂多模态问题的表现，并有效保留了先前的编辑，为大规模视觉语言模型的持续性和组合性知识编辑设立了新标准。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25791", "html_url": "https://arxiv.org/abs/2510.25791", "title": "推理的动态过程：链式思维如何塑造Transformer的学习？", "title_en": "The Kinetics of Reasoning: How Chain-of-Thought Shapes Learning in Transformers?", "authors": "Zihan Pengmei,Costas Mavromatis,Zhengyuan Shen,Yunyi Zhang,Vassilis N. Ioannidis,Huzefa Rangwala", "background": "链式思维（CoT）监督能够显著提升Transformer的表现，但模型学习遵循和利用链式思维的具体机制尚未被充分理解。本文通过在具有可调算法复杂度和可控数据组成的符号推理任务中预训练Transformer，研究其泛化能力，以探讨学习动态。研究在两种训练设置下进行：（i）仅输出最终答案，（ii）在给出答案前发出隐形CoT踪迹。研究表明，虽然CoT通常可以提升任务性能，但其效果依赖于任务的复杂性。研究通过一个三参数逻辑曲线模型量化训练步长的准确性，揭示了学习速度和形状如何随任务复杂性、数据分布及CoT监督的存在与否而变化。此外，发现了一种短暂的动态不忠实阶段：训练初期，模型通常能产生成正确答案的同时跳过或违背CoT步骤，之后调节其推理踪迹与答案的一致性。实验结果包括：（1）CoT加速泛化，但无法克服更高算法复杂度的任务；（2）提出了一个动力学建模框架以理解Transformer的学习；（3）将踪迹忠实地性质作为在训练中逐渐显现的动力学特性；（4）展示了CoT从机制上改变内部Transformer的计算过程。", "innovation": "本文提出了一个动力学建模框架来理解Transformer的学习，揭示了CoT溯源不忠实的短暂阶段，量化了CoT对任务性能的影响，并展示了CoT如何从机制上改变内部Transformer的计算过程。", "conclusion": "本文通过引入动力学建模框架，量化CoT的效应并揭示CoT监督和Task复杂度的关系。研究发现CoT可以提升基于符号推理任务的Transformer的学习效率，但其效果依赖于特定的Task复杂度。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25800", "html_url": "https://arxiv.org/abs/2510.25800", "title": "FreIE：时间序列任务中神经网络的低频频谱偏差", "title_en": "FreIE: Low-Frequency Spectral Bias in Neural Networks for Time-Series Tasks", "authors": "Jialong Sun,Xinpeng Ling,Jiaxuan Zou,Jiawen Kang,Kejia Zhang", "background": "时间序列数据固有的自相关性给多变量时间序列预测带来了持久的挑战。近期，一种广泛采用的方法是引入频域信息以辅助长期预测任务。许多研究者独立地观察到神经网络的频谱偏置现象，即模型倾向于先拟合低频信号，然后才拟合高频信号。不过，这些观察通常被归因于研究者设计的具体架构，而非将该现象视为所有模型的普遍特征。", "innovation": "为统一理解和解决频谱偏置现象，作者进行了广泛的实证实验来衡量现有主流模型中的频谱偏置。研究发现几乎所有的模型都表现出这种现象。为了缓解频谱偏置的影响，作者提出了一种名为FreLE（Frequency Loss Enhancement）的算法，通过显式和隐式的频率正则化增强模型的泛化能力。FreLE是一个即插即用的模型损失函数单元，并且大量的实验验证了其优越性能。", "conclusion": "大量实验证明了FreLE算法的有效性。频谱偏置是长期时间序列预测中一个普遍存在的现象，FreLE算法通过频率正则化提升了模型的泛化能力。未来的研究可以进一步探索该现象的根源及其在其他类型模型中的表现。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25818", "html_url": "https://arxiv.org/abs/2510.25818", "title": "ScaleDiff：通过高效且模型无关的扩散模型实现高分辨率图像合成", "title_en": "ScaleDiff: Higher-Resolution Image Synthesis via Efficient and Model-Agnostic Diffusion", "authors": "Sungho Koh,SeungJu Cha,Hyunwoo Oh,Kwanyoung Lee,Dong-Jin Kim", "background": "文本到图像的扩散模型在生成超过训练分辨率的图像时通常表现不佳。最近的无需训练的方法可以缓解这一限制，但它们往往需要大量的计算资源或与最新的扩散变换器模型不兼容。", "innovation": "提出了ScaleDiff，这是一种模型无关且高效的框架，可以在无需额外训练的情况下扩展预训练扩散模型的分辨率。核心组件是Non-overlapping Neighborhood Patch Attention (NPA)，该机制通过非重叠的补丁减少自注意力层中的计算冗余。此外，引入了Latent Frequency Mixing (LFM)以生成更精细的细节，并应用了Structure Guidance以在去噪过程中增强全局结构。", "conclusion": "实验结果表明，ScaleDiff在图像质量和推理速度方面均超过了现有训练无关方法，特别是在UNet和扩散变换器架构上。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25796", "html_url": "https://arxiv.org/abs/2510.25796", "title": "在大规模按需拼车系统中使用模拟导向强化学习进行非短视匹配和重新平衡", "title_en": "Non-myopic Matching and Rebalancing in Large-Scale On-Demand Ride-Pooling Systems Using Simulation-Informed Reinforcement Learning", "authors": "Farnoosh Namdarpour,Joseph Y. J. Chow", "background": "拼车是一种服务，乘客可以共享乘车服务，这种方式可以降低乘客和运营商的成本，减少交通拥堵和环境影响。然而，拼车通常基于短期派单决策，忽略了长期影响。为解决这一问题，本文提出了一种基于模拟的强化学习方法来优化决策，同时引入了用于重新平衡闲置车辆的补充政策。实验结果表明，非短视匹配策略可以大幅提升服务率，减少乘客的乘车和等待时间，同时显著降低车队规模，节省运营商的成本。", "innovation": "本文提出了一种利用模拟导向强化学习的非短视匹配和重新平衡策略。这种方法将拼车模拟嵌入到学习机制中，以提供非短视决策。相比传统的短视策略，提出的策略在保持相同服务性能的同时，可以降低运营商成本并优化服务效率。", "conclusion": "通过在纽约市出租车请求数据上的模拟实验，研究结果表明，非短视匹配策略相较于短视策略，能够提高服务率高达8.4%，同时减少乘客的乘车和等待时间，并将车队规模减少超过25%。将重新平衡操作整合到框架中可进一步降低等待时间高达27.3%，乘车时间降低12.5%，服务率提高15.1%，这表明所提出的策略对大规模按需拼车系统的优化具有显著效果。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25793", "html_url": "https://arxiv.org/abs/2510.25793", "title": "利用自适应偏差学习实现多代理系统的最优信息整合", "title_en": "Optimal Information Combining for Multi-Agent Systems Using Adaptive Bias Learning", "authors": "Siavash M. Alamouti,Fay Arjomandi", "background": "现代多代理系统，包括传感器网络监测关键基础设施和众包平台聚合人类智慧等，由于环境条件变化导致的系统偏差，可能会遭受显著的性能下降。当前的解决方法要么忽视这些偏差，导致次优的决策；要么需要昂贵的校准程序，但在实际操作中往往是不可行的。这些性能差距具有实际后果，例如不准确的环境监测、不可靠的金融预测和人类判断的谬误。论文关注的核心问题是，在什么情况下可以学习并纠正这些未知偏差以恢复接近最优的性能，在什么情况下学习偏差是徒劳的？", "innovation": "论文开发了一个理论框架，将偏差分解为可学习的系统性成分和不可约的随机成分，引入了学习比的概念，即可从可观测的协变量预测的偏差方差的比例。这一比例确定了特定系统中是否值得进行偏差学习。进而证明了可获得的性能改进从根本上受这一学习比的限制，提供了系统设计者在偏差学习与更简单的措施之间的投资定量指导。提出了适应性偏差学习和最优结合（ABLOC）算法，该算法通过闭式解迭代学习偏差修正变换，优化组合权重，确保误差收敛于理论界限。实验验证表明，具有高学习比的系统能够显著恢复性能（在示例中，我们达到了理论最大改进的40%-70%），而低学习比的系统几乎不受益，验证了实用部署决策的诊断标准。", "conclusion": "该研究确定了系统设计者何时应该在偏差学习而非更简单的方法上投资的定量指导。通过理论分析和实验验证，证明了ABLOC算法在具有高学习比的系统中可以实现显著的性能提升，在低学习比的系统中几乎看不到效果，提供了一种实用的决策支持机制。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25808", "html_url": "https://arxiv.org/abs/2510.25808", "title": "PRESTO: Preimage-Informed Instruction Optimization for Prompting Black-Box LLMs", "title_en": "PRESTO: Preimage-Informed Instruction Optimization for Prompting Black-Box LLMs", "authors": "Jaewon Chu,Seunghun Lee,Hyunwoo J. Kim", "background": "大型语言模型（LLMs）在多个领域已取得显著成功，这主要归功于它们强大的指令遵循能力。这导致了对优化黑盒LLMs（其内部参数不可访问，但因性能强大而广泛使用）指令的兴趣日益增加。尽管最近的方法使用白盒LLMs生成候选指令，但这种方法经常产生冗余查询，因为在不同软提示下映射到同一指令。先前的研究认为这种一对多映射会阻碍优化效率，而本文作者重新解读其为有益的先验知识，用于加速优化过程。", "innovation": "本文提出了一种新型框架PRESTO，利用软提示的先像结构进行有效优化。该框架包括三个关键组件：得分共享、先像基于初始化和得分一致性正则化。PRESTO能够在相同的查询预算下获得更多经过评分的数据，从而提高优化效率。实验结果表明，PRESTO在33个指令优化任务中表现优越，其代码已公开提供。", "conclusion": "实验结果表明，PRESTO方法在33个指令优化任务中的性能优于现有方法，通过先像结构加速了优化过程。该方法能够在相同的查询预算下获取更多评分数据，提高了优化效率。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25803", "html_url": "https://arxiv.org/abs/2510.25803", "title": "Mixture-of-Experts Operator Transformer for Large-Scale PDE Pre-Training", "title_en": "Mixture-of-Experts Operator Transformer for Large-Scale PDE Pre-Training", "authors": "Hong Wang,Haiyang Xin,Jie Wang,Xuanze Yang,Fei Zha,Huanshuo Dong,Yan Jiang", "background": "预训练已被证明在解决包含神经操作员的PDE问题时有效，特别是在应对数据稀缺性和性能限制方面。然而，由于PDE数据集在方程类型上存在异质性，导致混合训练中出现高误差。密集型预训练模型通过增加网络宽度或深度来扩展参数，但会导致显著的推断成本增加。", "innovation": "为了应对这些挑战，我们提出了一种新的Mixture-of-Experts Pre-training Operator Transformer（MoE-POT），这是一种稀疏激活架构，能够高效地扩展参数同时控制推断成本。具体来说，我们的模型采用了层级门控网络，在推理时动态选择4个路由专家从16个专家网络中，使模型能够专注于特定于方程的特征。此外，我们还加入了2个共享专家，旨在捕捉PDE的共性并减少路由专家间的冗余。最终输出结果是所有激活专家结果的加权平均值。我们使用参数从30M到0.5B在6个公开的PDE数据集上进行预训练。研究表明，参数为90M的模型在零样本推理时的误差相比具有120M参数的现有模型可降低40%。此外，我们还进行了可解释性分析，表明数据集类型可以从门控路由网络的决策中推断出来，这验证了MoE架构的合理性和有效性.", "conclusion": "我们的MoE-POT模型在解决混合训练中的高误差和推断成本问题方面取得了显著的效果，尤其是在PDE预训练中展现了优异的性能。通过引入门控路由机制和共享专家网络，该模型不仅能高效地扩展参数，还能显著降低推断成本，同时保持了预训练的精度和泛化能力。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25801", "html_url": "https://arxiv.org/abs/2510.25801", "title": "Metis-SPECS: 通过自我蒸馏偏好定向冷启动解耦多模态学习", "title_en": "Metis-SPECS: Decoupling Multimodal Learning via Self-distilled Preference-based Cold Start", "authors": "Kun Chen,Peng Shi,Haibo Qiu,Zhixiong Zeng,Siqi Yang,Wenji Mao,Lin Ma", "background": "近年来，具有可验证奖励的强化学习（RL）引发了‘MLLM-r1’方法的浪潮，这些方法将RL带到了视觉语言模型中。大多数代表性范式从冷启动开始，通常使用监督微调（SFT）来初始化策略，然后进行RL。然而，基于SFT的冷启动方法将任务解决和输出格式的推理相结合，可能导致指令风格过拟合，减弱了离分布泛化能力，最终影响下游的RL效果。现有研究重新审视了冷启动的两种视角：训练方法和数据构建，并引入了泛化因子（GF）系数来量化不同方法下的泛化能力。实验发现，基于偏好训练的方法（如DPO）在冷启动中的泛化能力优于基于SFT的方法。", "innovation": "该研究提出了一个解耦的多模态学习框架——SPECS（Self-distilled, Preference-based Cold Start），其主要创新在于：(1) 通过自我蒸馏生成反省偏好数据对，避免依赖于更大模型或手动标注；(2) 进行基于偏好训练以学习浅层、可转移的表面形式准则，而非记忆内容；(3) 将具有验证奖励的RL策略用于深层推理结果。实验结果显示，该框架在多个多模态基准测试中优于其他基线方法，显著提升了MEGA-Bench和MathVista的表现，并表现出减少“卡壳”、提高探索、稳定训练和提升性能极限等效果。", "conclusion": "该研究证明了通过自我蒸馏偏好定向冷启动解耦多模态学习框架的优越性。实验结果表明，与强基线相比，在多个大规模多模态基准测试中取得了持续的性能提升，并展示了其在算法稳定性和提升性能上限方面的优势。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25926", "html_url": "https://arxiv.org/abs/2510.25926", "title": "使用任务导向表示的杂乱池中的主动学习", "title_en": "Active Learning with Task-Driven Representations for Messy Pools", "authors": "Kianoosh Ashouritaklimi,Tom Rainforth", "background": "主动学习在杂乱且未整理的数据池中特别有用，这些数据池中的数据点在与目标任务的相关性方面各不相同。目前，最先进的主动学习方法依赖于固定且未监督的数据池表示，重点在于修改获取函数。然而，这种模型设定可能削弱处理杂乱数据池的有效性，因为这些表示可能无法捕捉到任务相关信息。", "innovation": "作者提出使用在主动学习过程中根据之前收集的标签定期更新的任务驱动表示。作者引入了两种具体策略来学习这些表示：一种是直接学习半监督表示，另一种是基于初始未监督表示的监督微调。", "conclusion": "这两种策略在使用未监督或预训练表示的场景下显著提升了实证性能。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25952", "html_url": "https://arxiv.org/abs/2510.25952", "title": "Modular Linear Tokenization (MLT),", "title_en": "Modular Linear Tokenization (MLT)", "authors": "Tcharlies Schmitz", "background": "传统的编码方法如哈希或one-hot编码在处理高cardinality的类别标识符时存在维度灾难的问题，且缺乏可逆性，影响模型的性能和计算效率。", "innovation": "MLT提出了一种可通过模运算和不可逆线性变换实现可逆和确定性的高维度类别标识符编码方法，能够控制维度，保持可逆性，适用于大量标识符。MLT在预测性能上与监督嵌入相当，但需要更少的参数和更低的训练成本。", "conclusion": "实验结果表明，MLT在MovieLens 20M数据集上达到了与监督嵌入相当的预测性能，但在参数量和训练成本上具有明显优势。开源实现可在PyPI和GitHub上获取。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25889", "html_url": "https://arxiv.org/abs/2510.25889", "title": "π_RL：流基础视觉-语言-动作模型的在线RL微调", "title_en": "$π_\\texttt{RL}$: Online RL Fine-tuning for Flow-based Vision-Language-Action Models", "authors": "Kang Chen,Zhihao Liu,Tonghe Zhang,Zhen Guo,Si Xu,Hao Lin,Hongzhi Zang,Quanlu Zhang,Zhaofei Yu,Guoliang Fan,Tiejun Huang,Yu Wang,Chao Yu", "background": "视觉-语言-动作（VLA）模型能够通过多模态输入理解并完成复杂的任务。尽管近期研究探索了使用强化学习（RL）来自动化大规模监督微调（SFT）的数据收集过程，但将其应用于基于流的VLA（例如，π_0，π_0.5）仍然具有挑战性，原因是其中的迭代降噪过程不易处理。", "innovation": "该研究提出了一种开放源代码框架π_RL，用于在并行仿真中训练基于流的VLA。π_RL实现了两种RL算法：1）Flow-Noise将降噪过程建模为一个离散的MDP，其中噪声网络是可学习的，以便准确计算对数似然；2）Flow-SDE在代理与环境交互时将降噪过程与代理环境互动相结合，形成一个两层MDP，使用ODE-到-SDE转换使RL探索更为高效。", "conclusion": "π_RL 在 LIBERO 和 ManiSkill 模板上的评估显示了显著的性能提升和更强的泛化能力，从而验证了在线RL对基于流的VLA的有效性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25892", "html_url": "https://arxiv.org/abs/2510.25892", "title": "基于拓扑感知的图上主动学习", "title_en": "Topology-Aware Active Learning on Graphs", "authors": "Harris Hardiman-Mostow,Jack Mauro,Adrien Weihs,Andrea L. Bertozzi", "background": "本文提出了一种图拓扑方法，直接解决在稀缺标签预算条件下探索与利用之间的核心挑战。通过引入基于平衡形式曲率（BFC）的核心样本构建算法，选择能够反映图聚类结构的代表性初始标签来引导探索。在保证图充分探索后会停止采集新标签。此外，通过使用BFC在主动学习过程中动态切换探索与利用，替代了手工调参的启发式方法，提高利用阶段的标签传播效率，同时保持稀疏性。", "innovation": "本文提出了一种基于平衡形式曲率（BFC）的主动学习方法，用于引导探索和利用阶段，并引入了基于局部图重新布线策略，以提高标签传播效率。该方法在较低标签率的情况下，对图上的半监督分类基准任务表现出色，能够持续超越现有基于图的半监督方法。", "conclusion": "通过使用平衡形式曲率（BFC）作为核心，构建核心样本以引导探索，并在不同阶段通过动态切换探索与利用来提高标签传播的效率，本文提出的方法在具有稀疏性的条件下仍然能提高半监督方法的效果，并在低标签率的情况下取得显著效果。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25924", "html_url": "https://arxiv.org/abs/2510.25924", "title": "使用代理转移因果效应", "title_en": "Transferring Causal Effects using Proxies", "authors": "Manuel Iglesias-Alonso,Felix Schur,Julius von Kügelgen,Jonas Peters", "background": "本文考虑了在多领域环境下估计因果效应的问题。在这个背景下，感兴趣的因果效应受到未观察到的混淆因素的影响，并且在不同领域之间会发生变化。研究假设可以访问隐藏混淆因素的代理指标，并且所有变量都是离散的或分类的。", "innovation": "文章提出了一种方法来估计目标领域的因果效应，同时假定仅观察到代理变量。在这些条件下，研究证明了可识别性（即使处理和响应变量是连续的）。文章引入了两种估计技术，证明了它们的一致性，并推导出了置信区间。", "conclusion": "理论结果得到了模拟研究和实际案例的支持，实际案例研究了网站排名对消费者选择的因果效应。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25934", "html_url": "https://arxiv.org/abs/2510.25934", "title": "拓扑不变量的隐式感知在稳健GNN水印中的应用", "title_en": "Robust GNN Watermarking via Implicit Perception of Topological Invariants", "authors": "Jipeng Li,Yannning Shen", "background": "现有的GNN水印依赖于后门触发，但在常见模型修改下容易失效，导致所有权模糊。本文旨在解决这一问题，通过将所有权与模型对图形不变量的隐式感知联系起来，实现无需触发器、黑盒验证且对任务影响微乎其微的水印方案。", "innovation": "提出了一种名为InvGNN-WM的方案，通过利用模型的图形不变量感知能力，不依赖标签或压缩，实现完全去除时不存在多项式时间复杂度解的不可见和鲁棒水印。该方案包括一个轻量级头预测用于版权保护数据集的归一化代数连通性值，以及一个灵敏解码器输出位和一个校准阈值控制误检率。该方案在多种节点和图分类数据集和模型上比基于标签和压缩的方法表现更优，且在多种模型修改如无结构剪枝、微调和后训练量化中保持鲁棒性，仅知识蒸馏（KD）减弱标记，而带有水印损失的知识蒸馏（KD+WM）能恢复标记。", "conclusion": "本文通过证明该方案对不可见性和鲁棒性的保证以及原始声明的验证（新闻发布），展示了MemGNN-WM在实现高效GNN水印方面的创新性和优越性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25962", "html_url": "https://arxiv.org/abs/2510.25962", "title": "无数据训练神经网络的研究", "title_en": "On the Dataless Training of Neural Networks", "authors": "Alvaro Velasquez,Susmit Jha,Ismail R. Alkhouri", "background": "无训练数据条件下使用神经网络进行优化研究的背景在于，尽管数据驱动的学习方法尚未展现出强大的应用效果，特别是在组合优化、逆问题和偏微分方程等领域；而且在医学图像重建和其他科学应用中，获取训练数据也存在困难。因此，研究者探索了重新参数化问题以适合全连接（或MLP）、卷积、图和二次神经网络的方法，尤其是在解决线性规划问题上。", "innovation": "该文创新性地定义了无数据设置，并将其分为两种基于单个数据表示神经网络的方法：架构无关方法和架构特定方法。此外，作者还讨论了无数据神经网络（dNN）设置与零样本学习、一次学习、优化中的提升概念和过度参数化之间的相似性与区别。", "conclusion": "该研究总结了无数据设置下神经网络优化应用的研究现状，认为虽然MLPs在解决某些特定类型的问题上显示出潜力，但在更广泛的应用场景中仍然需要进一步的研究和发展，同时强调了定义和区分不同学习模式的重要性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25867", "html_url": "https://arxiv.org/abs/2510.25867", "title": "MedVLSynther：使用生成器-验证器多模态大模型从医学文档合成高质量视觉问答数据", "title_en": "MedVLSynther: Synthesizing High-Quality Visual Question Answering from Medical Documents with Generator-Verifier LMMs", "authors": "Xiaoke Huang,Ningsen Wang,Hui Liu,Xianfeng Tang,Yuyin Zhou", "background": "当前，大型多模态模型（LMMs）能够在需要同时处理图像和文本信息的医学问答（VQA）任务上表现出色。然而，训练通用医疗VQA系统时受到缺乏大型、公开可用且高质量的数据集的限制。MedVLSynther提出了一个生成器-验证者框架，该框架能够直接从开放的生物医学文献中合成高质量的选择题VQA项目，同时利用图表和文本中的参考文献进行条件控制。该框架使用一个可机读的JSON模式生成自包含的题干和并行的互斥选项，并通过多阶段验证器强制执行关键门槛（自包含性、唯一正确答案、临床有效性、图像-文本一致性），并进行细化评分和常见失败模式惩罚，从而接受问题。此流程应用于PubMed Central，生成MedSynVQA数据集：包括13,087个经过审查的问题，涉及14,803张图片、13种成像模态和28个解剖区域。使用验证性奖励训练公开权重LMMs，并在六项医疗VQA基准测试中实现显著的准确性改进，其中3B模型的平均得分为55.85，7B模型的平均得分为58.15，在VQA-RAD和PathVQA等特定基准测试中的得分最高可达77.57和67.76，均超越了强大的医学LMMs。消融实验和定向污染分析验证了生成和验证过程的必要性，并确保了数据的隐私保护。MedVLSynther完全基于开放文献和开放权重模型，提供了一条可审计、可复现且隐私保护的生成大规模医疗VQA训练数据的战略路径。", "innovation": "MedVLSynther框架创新性地提供了生成器-验证者多模态大模型，能够直接从开放的生物医学文献中生成高质量的VQA问题，处理医学图像和文本联合推理需求。该框架通过自包含的题干和互斥的选项显著提高了VAQA生成的输入输出质量。通过多阶段验证流程，系统地检查和评估生成的VQA问题的临床有效性、图-文一致性等问题，并紧密监控验证数据的准确性和完整性，为医学VQA训练提供了高质量、可审计和隐私保护的数据集。", "conclusion": "该研究通过MedVLSynther框架，成功生成了大规模、高质量、可审计和隐私保护的医学VQA训练数据（MedSynVQA），在不同医学VQA基准测试中显著提升开放模型的性能，证明了医学LMMs与验证性奖励机制相结合的有效性。此外，通过生成和验证过程的必要性和验证数据的全面性验证了所做的贡献，确保了数据质量与模型训练的有效性。MedVLSynther框架为医学VQA领域提供了新的切入点，实现了更具规模、可复现和隐私保护的数据生成策略，推动了相关领域的发展。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25983", "html_url": "https://arxiv.org/abs/2510.25983", "title": "正确进行对比编码以实现互信息估计", "title_en": "Contrastive Predictive Coding Done Right for Mutual Information Estimation", "authors": "J. Jon Ryu,Pavan Yeddanapudi,Xiangxiang Xu,Gregory W. Wornell", "background": "InfoNCE 目标最初用于对比表示学习，但因其与互信息的间接联系而被用于互信息估计。尽管如此，InfoNCE 目标并未被视作有效的互信息估计器。本文探讨了 InfoNCE 作为互信息估计器的局限，并提出了一种简单的改进方法，称为 InfoNCE-anchor，以精确估计互信息。此外，本文还使用适当的评分规则进一步推广了该框架，并发现 InfoNCE-anchor 结合对数分数可以实现最准确的互信息估计。然而，在自我监督表示学习实验中，添加锚点并未提升下游任务的表现。这些结果表明，对比表示学习主要受益于学习结构化的密度比，而不仅仅是准确的互信息估计。", "innovation": "提出了一种新的方法 InfoNCE-anchor，引入了辅助锚点类别，使密度比率估计更具一致性，从而给出了一个偏置明显降低的插件互信息估计器。此外，还使用适当的评分规则扩展了框架，该方法在使用对数分数时能够实现最准确的互信息估计。", "conclusion": "对比表示学习受益于学习结构化密度比，而不仅仅是准确的互信息估计。InfoNCE-anchor 在自编码器实验中能给出更准确的互信息估计，但并未改善下游任务表现。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25954", "html_url": "https://arxiv.org/abs/2510.25954", "title": "利用地理空间基础模型数据预测卫生设施项目输出——摩洛维个案研究", "title_en": "Application and Validation of Geospatial Foundation Model Data for the Prediction of Health Facility Programmatic Outputs -- A Case Study in Malawi", "authors": "Lynn Metz,Rachel Haggard,Michael Moszczynski,Samer Asbah,Chris Mwase,Patricia Khomani,Tyler Smith,Hannah Cooper,Annie Mwale,Arbaaz Muslim,Gautam Prasad,Mimi Sun,Tomer Shekel,Joydeep Paul,Anna Carter,Shravya Shetty,Dylan Green", "background": "在低收入和中等收入国家（LMICs），公共卫生数据的可靠性受限于报告延迟和覆盖不完整，这要求探索新的数据源和分析方法。地理空间基础模型（GeoFMs）通过将多种空间、时间和行为数据整合为数学嵌入形式，为下游预测任务提供了新的可能性。该研究评估了三种GeoFM嵌入来源（Google人口动态基础模型（PDFM）、Google AlphaEarth（基于卫星图像）和移动电话呼叫详细记录（CDR））在马拉维对15项常规公共卫生项目成果的预测性能，并将它们与传统的地理空间插值方法进行了比较。", "innovation": "该研究利用地理空间基础模型（GeoFMs）的数据源和分析方法，评估了它们在预测低收入和中等收入国家医疗机构项目输出方面的性能。研究使用了XGBoost模型，对552个卫生接诊区域的数据进行了评估，采用了80/20的训练和测试数据划分，并使用五折交叉验证进行训练。研究发现，基于嵌入的方法优于基线地理统计方法的比例为13/15，而综合三种嵌入数据源的多GeoFM模型在多个指标上的表现最好，显示出对选则的健康和人口统计数据具有适度的预测改进。", "conclusion": "该研究的结果表明，结合多种GeoFM来源是一个有效的工具，可以补充并增强受限的常规公共卫生信息系统。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26014", "html_url": "https://arxiv.org/abs/2510.26014", "title": "离散时间生存分析的双重混合专家框架", "title_en": "Dual Mixture-of-Experts Framework for Discrete-Time Survival Analysis", "authors": "Hyeonjun Lee,Hyungseob Shin,Gunhee Nam,Hyeonsoo Lee", "background": "生存分析是一种用于建模直到感兴趣事件发生的时间的任务，广泛应用于临床和生物医学研究中。关键挑战在于如何同时建模患者的异质性并根据个人特征和时间动态调整风险预测。", "innovation": "本文提出了一种双重混合专家(Dual MoE)框架用于离散时间生存分析。该方法结合了用于子组感知表示学习的功能编码MoE，以及利用患者特征和时间嵌入来捕捉时间动态的危险MoE。这一双重MoE设计灵活地与现有的基于深度学习的生存分析管道兼容。", "conclusion": "在METABRIC和GBSG乳腺癌数据集上，该方法始终提高了性能，测试集的时间依赖性C-指数提高了0.04，并在Consurv框架中进一步提高了性能。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25993", "html_url": "https://arxiv.org/abs/2510.25993", "title": "基于时间相关性的预测编码网络有效在线学习", "title_en": "Efficient Online Learning with Predictive Coding Networks: Exploiting Temporal Correlations", "authors": "Darius Masoum Zadeh-Jousdani,Elvin Hajizada,Eyke Hüllermeier", "background": "在边缘操作的机器人系统需要高效的在线学习算法，能够持续适应变化的环境并处理流式传感数据。传统的反向传播算法虽然有效，但违背了生物可行性原则，可能在连续适应场景中表现不佳。预测编码框架提供了生物可行性替代方案，具有局部、希伯式更新规则，适合神经形态硬件实现。然而，预测编码的主要限制在于其计算开销大，训练过程中需要多次推理迭代。", "innovation": "提出了一种预测编码网络时域代偿（PCN-TA）算法，通过利用时间相关性跨时间帧保存潜在状态，显著降低了计算需求，同时保持了学习性能。实验结果表明，PCN-TA相比反向传播减少了10%的权重更新，其基线预测编码网络相比减少了50%的推理步骤。", "conclusion": "PCN-TA的效率增益直接转化为计算开销的减少，有助于边缘部署和支持资源受限的机器人系统的实时适应。基于生物启发的方法也使其成为未来神经形态硬件实现的有效在线学习的有力候选方案。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26000", "html_url": "https://arxiv.org/abs/2510.26000", "title": "Infrequent Exploration in Linear Bandits", "title_en": "Infrequent Exploration in Linear Bandits", "authors": "Harin Lee,Min-hwan Oh", "background": "现有的探索策略主要分为两种：完全自适应的探索方法（如UCB和Thompson Sampling），它们在每个时间步骤都可能进行探索；以及纯粹贪婪的方法，这些方法在没有足够的上下文多样性的情况下通常会失败。在安全性关键或成本高昂的领域中，连续探索可能是不切实际或不道德的，而纯粹贪婪的策略往往会失败。因此，需要一种新的框架来解决这个问题，即在不频繁探索的情况下也能达到高效探索的效果的策略。", "innovation": "提出了一个简单的框架INFEX，该框架专为不频繁探索设计。INFEX 的运作方式是在给定的时间表上执行基础探索策略，而在其余时间主要选择贪婪动作。理论分析表明，只要探索频率超过对数阈值，INFEX 实现的实例相关后悔与标准的高效算法相匹配。此外，INFEX 是一个通用且模块化的框架，可以无缝整合任何完全自适应的探索方法，从而增强其广泛应用和实现便利性。此外，该方法还可以通过将密集的探索计算限制在不频繁的时间段内来提高计算效率。", "conclusion": "实验结果证实了理论分析，INFEX 在后悔和运行时间表现方面都优于现有方法。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25986", "html_url": "https://arxiv.org/abs/2510.25986", "title": "A General and Streamlined Differentiable Optimization Framework", "title_en": "A General and Streamlined Differentiable Optimization Framework", "authors": "Andrew W. Rosemberg,Joaquim Dias Garcia,François Pacaud,Robert B. Parker,Benoît Legat,Kaarthik Sundar,Russell Bent,Pascal Van Hentenryck", "background": "渐增的优化问题中通过约束优化进行梯度计算在学习、控制和大规模决策系统中变得越来越关键，但其实现仍面临挑战，主要是由于求解器的专业化和接口不匹配。论文介绍了Julia优化堆栈中的一种通用且易于使用的框架，该框架可简化优化建模和梯度计算的融合。该框架支持对于光滑的、可能是非凸的程序，通过标准正则性假设下对KKT系统进行梯度计算来计算前向和后向模式的解和目标函数的灵敏度。这种参数中心的高级JuMP API使用户能够直接对多个约束和目标出现的参数进行梯度计算，避免了从系数级接口中进行脆弱的记账工作。通过这些能力，本文展示了几种凸性和非凸模型的实例，如能源市场的策略性报价、带有锥风险约束的均值-方差投资组合选择和非线性机器人逆运动学。", "innovation": "提出了一个在Julia优化堆栈中通用且易于使用的框架，能够简化优化建模和梯度计算的融合，并提供了一种参数中心的高级JuMP API。这项创新允许用户直接对多个约束和目标出现的参数进行梯度计算，避免了从系数级接口进行脆弱的记账工作，简化了计算流程，提高了计算的可靠性和效率。这项工作特别适用于凸性和非凸的优化模型，能够支持复杂的场景如能源市场中的策略性报价和投资组合选择等。", "conclusion": "这些结果表明，可微分优化可以作为一种常规工具应用于实验、学习、校准和设计中，而无需偏离标准的JuMP建模惯例，并同时提供广泛的求解器生态系统访问权限。此外，作为配套研究的结果进一步显示了在大规模应用中的影响，包括能源市场中的梯度基于迭代方法的战略性报价和使用求解器准确的灵敏度进行端到端优化代理的Sobolev风格训练。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26025", "html_url": "https://arxiv.org/abs/2510.26025", "title": "通过国际象棋棱镜探索人类-人工智能概念对齐", "title_en": "Exploring Human-AI Conceptual Alignment through the Prism of Chess", "authors": "Semyon Lomaso,Judah Goldfeder,Mehmet Hamza Erol,Matthew So,Yao Yan,Addison Howard,Nathan Kutz,Ravid Shwartz Ziv", "background": "本研究探讨了AI系统是否真正理解人类概念，还是仅模仿表面模式。通过国际象棋这一平台，研究了人类的创造性与精确的战略概念如何结合。具体分析了一个拥有270M参数的变压器模型，该模型达到了国际象棋大师级别的水平。研究表明，虽然早期的模型层能够以高达85%的准确性编码人类的概念，如中心控制和骑士据点，但较深的模型层虽然驱动了更好的性能，却逐渐偏离至与人类思维不一致的表示方式，准确率降至50-65%。", "innovation": "1. 分析了一个270M参数的变压器模型在国际象棋中的表现，揭示了模型初期层和更深层代表模式之间的差异。\n2. 引入了第一个基于240个专家标注的Chess960数据集，涵盖6个战略概念，用于测试概念上的鲁棒性而非单纯的记忆。\n3. 展示了当消除开局理论通过随机初始位置时，所有方法在概念识别上的下降，表明模型依赖于记忆的模式而非抽象的理解。", "conclusion": "当前架构的基本张力在于，能赢得比赛的表示与符合人类思维的表示逐渐分离。研究结果表明，随着AI系统优化性能，它们开发出越来越陌生的人工智能，对于需要真实的人机协作的创造性AI应用来说，这是一个关键挑战。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26038", "html_url": "https://arxiv.org/abs/2510.26038", "title": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "title_en": "Do Students Debias Like Teachers? On the Distillability of Bias Mitigation Methods", "authors": "Jiali Cheng,Chirag Agarwal,Hadi Amiri", "background": "知识蒸馏（KD）是一种有效的模型压缩方法，能够将知识从教师模型转移给学生模型。然而，它对模型抵抗统计相关性（即伪相关）的影响（伪相关会导致模型在外分布数据上的性能下降）的研究尚不深入。本研究旨在探究知识蒸馏对自然语言推理（NLI）和图像分类任务中偏见修正能力（即去偏性）从教师模型转移到学生模型的影响。", "innovation": "本研究通过大量实验揭示了知识蒸馏对偏见修正能力的影响，包括：（1）模型的去偏性能力在知识蒸馏后普遍削弱；（2）训练去偏模型不会从教师知识中受益；（3）模型的整体鲁棒性可能在知识蒸馏后保持稳定，但不同类型的偏见可能会显著变化；（4）通过深入分析，本研究指出了导致去偏能力变化的内部注意模式和电路机制。此外，本研究提出了提高去偏方法可蒸馏性的三种有效解决方案：增强数据质量、迭代知识蒸馏和使用教师模型权重初始化学生模型。", "conclusion": "本研究是首次在大规模研究背景下探讨知识蒸馏对去偏性以及其内部机制的影响，提供了对知识蒸馏工作原理以及如何设计更好的去偏方法的理解。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26076", "html_url": "https://arxiv.org/abs/2510.26076", "title": "新货币：金融领域合成数据生成的系统性审查", "title_en": "New Money: A Systematic Review of Synthetic Data Generation for Finance", "authors": "James Meldrum,Basem Suleiman,Fethi Rabhi,Muhammad Johan Alibasa", "background": "合成数据生成作为一种有望解决使用敏感金融数据的机器学习应用中遇到的挑战的方法，已经引起了广泛关注。通过利用生成模型，如生成对抗网络（GANs）和变分自编码器（VAEs），可以创建保留真实金融记录统计属性的人工数据集，同时缓解隐私风险和监管限制。尽管该领域的研究快速增长，但目前对该研究领域的综合综述仍然缺乏。本文系统地分析了自2018年以来发表的72篇专注于合成金融数据生成的研究论文。", "innovation": "本文通过系统地合成和分析自2018年以来发表的72篇关于合成金融数据生成的研究论文，对生成技术、应用和评估方法进行了整合性的概述。研究发现基于GAN的方法在文献中占据主导地位，特别是在生成时间序列市场数据和表格信用数据方面最为常用。同时，尽管有多项创新技术表现出提高真实性和隐私保护的潜力，但隐私保护措施的严谨性评价在研究中相对缺乏。它指出研究的关键缺口，并为未来开发金融领域稳健的、隐私保护的合成数据解决方案提供了指导。", "conclusion": "本文通过提供综合性的生成技术、应用和评估方法的概述，强调了在金融领域开发稳健、隐私保护的合成数据解决方案的关键研究缺口，并为未来的研究提供了指导。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26064", "html_url": "https://arxiv.org/abs/2510.26064", "title": "关于符号回归的标度定律", "title_en": "Towards Scaling Laws for Symbolic Regression", "authors": "David Otte,Jörg K.H. Franke,Frank Hutter", "background": "符号回归（SR）旨在发现能够解释观测数据的潜在数学表达式。这不仅有助于科学见解的获得，还能创建具有内在可解释性和泛化能力的表格数据模型。然而，基于深度学习的SR方法与遗传编程方法相比虽已相当竞争力，但其规模效应的研究仍相对较少，尤其是在巨型模型和大规模计算方面的研究尚处于空白状态。目前的研究主要集中在探索SR中的标度定律，通过一个可扩展的端到端转换器管道及精心生成的训练数据对此进行系统研究。", "innovation": "研究引入了一个可扩展的端到端转换器管道，并结合了精心生成的数据集对SR中的标度定律进行了首次系统性研究。通过分析不同规模模型（五个不同类型，计算资源跨度达三个数量级）下的表现，研究发现了验证损失和解算率随计算资源增加的幂律趋势。此外，还确定了计算资源最优的超参数缩放：随模型规模增大，最优化的批量大小和学习率会增加，而一个词元与参数比例约为15，在计算资源增加时略有上升的趋势。这些结果证明了SR性能在很大程度上可由计算资源预测，并为下一辈SR模型的训练提供了重要见解。", "conclusion": "通过分析五种不同模型规模和三个数量级的计算量，研究发现验证损失和解算率呈现出清晰的幂律趋势，并确定了计算资源最优的超参数缩放规则。这为未来SR模型的开发提供了有力的指导，表明SR性能可以通过模型规模和计算资源进行预测。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26083", "html_url": "https://arxiv.org/abs/2510.26083", "title": "Nirvana：具有任务感知记忆机制的专门全能模型", "title_en": "Nirvana: A Specialized Generalist Model With Task-Aware Memory Mechanism", "authors": "Yuhua Jiang,Shuang Cheng,Yihao Liu,Ermo Hua,Che Jiang,Weigao Sun,Yu Cheng,Feifei Gao,Biqing Qi,Bowen Zhou", "background": "传统的大型语言模型（LLM）结构，如Transformer、线性注意力机制和混合模型，没有利用由任务信息指导的专业化记忆机制。专长全能模型（SGM）旨在同时保持广泛的通用能力并实现特定领域中的专家级性能。然而，现有的大型语言模型结构缺乏这个机制。", "innovation": "本文提出了一种名为Nirvana的SGM，它具有专业化的记忆机制、线性的时间复杂度以及测试时的任务信息提取。此外，作者提出了Task-Aware Memory Trigger（Trigger），可以根据当前任务的需求灵活调整记忆机制。Specialized Memory Updater（Updater）能够根据Trigger动态地记忆上下文。在通用语言任务和专门医学任务上进行的实验表明，Nirvana在多个自然语言建模基准测试中取得了竞争力或更优秀的结果。", "conclusion": "为了验证Trigger在特定任务上的有效性，作者在具有挑战性的医学任务上测试了Nirvana的表现，即磁共振成像（MRI）。通过Trigger，即使Nirvana的骨干网络被冻结，Nirvana也能根据任务相关参数的变化适应MRI领域，生成高质量的MRI重建图像，并生成准确的初步临床报告。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26086", "html_url": "https://arxiv.org/abs/2510.26086", "title": "LLMBisect: 使用比较分析管道打破故障定位障碍", "title_en": "LLMBisect: Breaking Barriers in Bug Bisection with A Comparative Analysis Pipeline", "authors": "Zheng Zhang,Haonan Li,Xingyu Li,Hang Zhang,Zhiyun Qian", "background": "传统的基于补丁的故障定位方法面临若干重要障碍，包括假设引起故障的提交（BIC）和补丁提交修改相同的函数，单一依赖代码变更而忽视提交信息的丰富信息，以及依赖简单的启发式方法而缺乏任何漏洞的逻辑分析。\n", "innovation": "提出了一种全面的多阶段流水线，通过利用大语言模型（LLMs），使得能够：（1）充分利用补丁信息，（2）在上下文中比较多个提交候选者，（3）通过一系列筛选步骤逐步缩小候选范围。与最先进的解决方案相比，该方法的准确性提高了超过38%。进一步的结果表明，全面的多阶段流水线是关键，它将准确性提高了60%。\n", "conclusion": "与基于大语言模型的传统故障定位方法相比，本文提出的方法有显著的改进，并且多阶段流水线是提高准确性的关键因素。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26089", "html_url": "https://arxiv.org/abs/2510.26089", "title": "网络约束的多智能体车辆路由策略优化", "title_en": "Network-Constrained Policy Optimization for Adaptive Multi-agent Vehicle Routing", "authors": "Fazel Arasteh,Arian Haghparast,Manos Papagelis", "background": "城市道路网络的交通拥堵会增加旅行时间并提高排放量，尤其是在高峰时段。对于单辆车的静态网络，最短路径优先（SPF）算法是最佳选择，但在动态、多车环境下的表现较差，可能导致所有车辆选择相同的路径，从而加剧拥堵。研究旨在通过多智能体强化学习（MARL）框架解决动态车辆路径问题，以实现网络感知的车队协调导航。", "innovation": "提出了一种适应性导航（AN）方法，该方法是一个去中心化的MARL模型，每个交叉口代理根据（i）局部交通状况和（ii）通过图注意力网络（GAT）建模的邻居状态提供导向建议。为进一步提高大型网络的可扩展性，提出了一种基于节点的适应性导航（HHAN）方法，该方法将代理仅分配给关键交叉口（枢纽节点）。此外，HHAN采用集中训练与去中心化执行（CTDE）框架下的注意力Q-混合（A-QMIX）方法，通过注意力机制协调中心控制器的决策。实验结果表明，与SPF和学习基线相比，AN减少了平均行程时间并保持了100%的路径成功率；而HHAN在有几百个交叉口的大规模网络下表现突出，拥堵时可将行程优化提高15.9%。这一研究展示了网络约束的MARL在智能交通系统中实现可扩展、协调和拥堵感知路由的潜力。", "conclusion": "综合实验结果，AN和HHAN两种方法证明了在网络约束条件下实施MARL的有效性，能够在动态条件下实现路径优化，有效减少拥堵并大大缩短行程时间。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26068", "html_url": "https://arxiv.org/abs/2510.26068", "title": "学习几何：通过度量优化构建自适应流形模型的框架", "title_en": "Learning Geometry: A Framework for Building Adaptive Manifold Models through Metric Optimization", "authors": "Di Zhang", "background": "这篇论文提出了机器学习的一个新范式，超越了传统的参数优化方法。不同于传统的以固定几何空间为搜索范围的参数优化方法，本文的核心思想是将模型本身视为一个可塑的几何实体，并在此基础上进行优化。具体来说，优化的是流形上的度量张量场，以动态改变模型空间的几何结构。", "innovation": "本文提出的创新点在于将模型的几何结构优化作为一个可变的几何实体来处理，而不是在固定的空间中寻找最优参数。通过构建了变分框架来平衡数据保真度与流形固有的几何复杂性，并使用自动微分工具高效优化度量张量。理论分析表明这种框架与广义相对论中的爱因斯坦-希耳伯特作用量有深刻的类比关系。", "conclusion": "本文的工作为构建能够自主演化其几何结构和拓扑结构的全动态“超学习器”奠定了坚实的基础，并为其在科学模型发现和鲁棒表示学习等领域的大范围应用前景指明了方向。此外，固定拓扑下度量优化的效果比固定几何形状的模型具有更大的表征能力。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26109", "html_url": "https://arxiv.org/abs/2510.26109", "title": "再次不要踏入同样的河流：从试错中学习推理", "title_en": "Do Not Step Into the Same River Twice: Learning to Reason from Trial and Error", "authors": "Chenming Tang,Hsiu-Yuan Huang,Weijie Liu,Saiyong Yang,Yunfang Wu", "background": "最近，强化学习与可验证奖励（RLVR）显著提升了大型语言模型（LLMs）的推理能力。然而，现有的RLVR方法仅基于LLMs自动生成的回答进行训练，并受限于最初的LLMs能力，容易导致探索停滞，无法解决更多的训练问题，也无法进一步从训练数据中学习。一些工作试图通过利用离策略解解决训练问题，但需要专家的外部指导，而这种指导的可用性有限.", "innovation": "本文提出了LTE（通过试错学习推理），这种方法通过引导LLMs使用它们之前生成的错误答案和过长的回答，来克服上述问题。LTE不需要任何外部专家指导，实验结果表明，它在数学基准测试中的Pass@1和Pass@k指标上分别优于相对策略优化（GRPO）6.38%和9.00%，平均性能优于该基准的其他方法。进一步的分析确认，LTE成功地缓解了探索停滞的问题，并在训练过程中增强了挖掘和探索.", "conclusion": "LTE在缓解探索停滞问题和增强训练过程中的挖掘与探索方面表现出色，特别是在数学基准测试中，其性能优于现有方法。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26099", "html_url": "https://arxiv.org/abs/2510.26099", "title": "SAFE：通过地球分层评估对未来AI天气评估的一种新颖方法", "title_en": "SAFE: A Novel Approach to AI Weather Evaluation through Stratified Assessments of Forecasts over Earth", "authors": "Nick Masi,Randall Balestriero", "background": "传统的机器学习评估模型性能的方式是基于测试集所有样本的平均损失。这种方式在气象和气候领域通常涵盖了全球，但忽略了人类发展和地理分布的非均匀性。这篇论文旨在填补这一空白，引入了一套新的方法SAFE，以分层视角来评估地球上的预测性能。SAFE通过整合多种数据领域，按照与地理网格点不同的属性进行分层：领土（通常是国家）、全球亚区域、收入和土地覆盖（陆地或水域），从而使我们能够对每个单项属性的预测性能进行详细考察，例如，每国的预测准确度。通过这种方法，可以评估不同气象AI模型在所有属性上的预测能力差异，并进一步形成基于分层的模型预报公平性基准，以评估不同时间节点上各气候变量的模型表现。", "innovation": "引入了SAFE，一种通过分层评估地球上的预测性能的评估方法，该方法不仅能够考虑到空间分布的非均匀性，还能详细考察每个单项属性的预测性能。SAFE能够展示和衡量不同属性下的预测能力差异，并提供了基于分层评估模型预报公平性的基准方法。", "conclusion": "SAFE方法在不同时间节点上和各种气候变量的基础上，为评估模型表现差异提供了一个全新的视角，首次揭示了哪些模型在不同地区表现最佳或最差，以及这些模型在公平性方面的表现。SAFE是一个开源包，可从该网址下载：this https URL"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26146", "html_url": "https://arxiv.org/abs/2510.26146", "title": "maxVSTAR：在闭环边缘模型自适应中实现最优视知觉导向的CSI传感，以实现稳健的人体活动识别", "title_en": "maxVSTAR: Maximally Adaptive Vision-Guided CSI Sensing with Closed-Loop Edge Model Adaptation for Robust Human Activity Recognition", "authors": "Kexing Liu", "background": "WiFi信道状态信息（CSI）基于的人体活动识别（HAR）提供了一种私密性保护和无需设备的人机环境感知解决方案。然而，其在边缘设备上的部署受到领域偏移的严重限制，即在环境和硬件条件变化时识别性能下降。因此，需要一种闭环、由视知觉引导的模型自适应框架，以自主缓解领域偏移，适应边缘部署的CSI传感系统。", "innovation": "本文提出了maxVSTAR（最大适应性视觉指引的CSI传感技术），这是一种闭环视觉指南型自适应框架，通过单个视知觉引导的适应循环，自动缓解领域偏移，提高了表现。该系统整合了一种跨模态的教师-学生架构，利用高准确度的YOLO视觉模型作为动态的监督信号，实时提供活动标签。这些标签使轻量级的CSI基HAR模型STAR能够在线自主微调。实验证明了maxVSTAR的有效性，在非校准硬件上，基准STAR模型的识别准确率从93.52％降至49.14％，但在经过一次视知觉引导的适应循环后，准确率恢复至81.51％。", "conclusion": "实验证明，maxVSTAR可以在隐私保护的物联网环境中实现动态的、自我监督模型的自适应，从而为网络边缘的长期自助式HAR提供了可扩展且实用的范例。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26184", "html_url": "https://arxiv.org/abs/2510.26184", "title": "协作公共资源配置的基于博弈论的空间-时间强化学习框架", "title_en": "A Game-Theoretic Spatio-Temporal Reinforcement Learning Framework for Collaborative Public Resource Allocation", "authors": "Songxin Lei,Qiongyan Wang,Yanchen Zhu,Hanyu Yao,Sijie Ruan,Weilin Ruan,Yuyu Luo,Huaming Wu,Yuxuan Liang", "background": "公共资源配置涉及高效分配包括城市基础设施、能源和交通在内的资源，以满足社会需求。现有方法侧重于独立优化各个资源的移动，而忽略其容量限制。该论文旨在解决这一限制，提出了一个具有容量约束和时空动态特性的新问题，称为协作公共资源配置（CPRA）。", "innovation": "该论文提出了一个名为博弈论时空强化学习（GSTRL）的新框架，以解决CPRA问题。贡献包括：1) 将CPRA问题形式化为潜在博弈，并显示潜在函数与最优目标之间的差距为零，为近似NP难问题的纳什均衡提供理论基础；2) GSTRL框架能够有效捕捉整体系统的时空动态。", "conclusion": "该论文在两个真实世界的数据集上评估了GSTRL框架，实验结果表明其性能优越。源代码已在附录材料中提供。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26157", "html_url": "https://arxiv.org/abs/2510.26157", "title": "通过结构意识对齐弥合分子与文本描述之间的差距", "title_en": "Bridging the Gap Between Molecule and Textual Descriptions via Substructure-aware Alignment", "authors": "Hyuntae Park,Yeachan Kim,SangKeun Lee", "background": "分子与文本表示学习逐渐受到关注，因为这有助于增强对化学信息的理解。然而，现有的模型在捕捉分子和其描述之间的细微差异方面表现不佳，因为它们缺乏从分子子结构和化学短语中学习细粒度对齐的能力。", "innovation": "我们引入了MolBridge，这是一种基于结构意识对齐的新颖分子-文本学习框架。MolBridge通过为原始的分子-描述对添加额外的来自分子子结构和化学短语的对齐信号来增强学习。为了有效学习这些增强对齐信号，MolBridge采用了结构意识对比学习，并结合了一个自我精炼机制来过滤掉噪声的对齐信号。", "conclusion": "实验结果表明，MolBridge能够捕捉细粒度对应关系，并在一系列分子基准测试上优于最先进的基线，突出了分子-文本学习中结构意识对齐的重要性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26159", "html_url": "https://arxiv.org/abs/2510.26159", "title": "复杂性胜于分割：工业时间序列异常检测中的集成和混合方法评估", "title_en": "Segmentation over Complexity: Evaluating Ensemble and Hybrid Approaches for Anomaly Detection in Industrial Time Series", "authors": "Emilio Mastriani,Alessandro Costa,Federico Incardona,Kevin Munari,Sebastiano Spinello", "background": "该研究调查了复杂的数据特征工程和混合模型架构在多变量工业时间序列中的异常检测效果，特别关注的是汽轮机系统。研究评估了变化点统计特征、基于聚类的子结构表示以及混合学习策略对检测性能的影响。", "innovation": "研究重点在于对比复杂的统计特征和聚类方法与简化模型（随机森林+XGBoost集成）的效果。尽管复杂的模型理论上具备优势，但研究发现，简单的模型在数据高度不平衡且时间上不确定的情况下，通过优化分割策略，能够优于复杂的架构，提供更好的鲁棒性、可解释性和操作实用性。", "conclusion": "研究结论表明，在数据高度不平衡且时间上不确定的情况下，模型的简单性与合理的分割优化策略相结合，可以优于复杂的架构，提供更好的鲁棒性、可解释性和操作实用性。研究的AUC-ROC达到了0.976，F1分数为0.41，并且在定义的时间窗口内实现了100%的早期检测。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26185", "html_url": "https://arxiv.org/abs/2510.26185", "title": "累积SGD影响估计用于数据归因", "title_en": "Accumulative SGD Influence Estimation for Data Attribution", "authors": "Yunxiao Shi,Shuo Yang,Yixin Su,Rui Zhang,Min Xu", "background": "现代基于数据的人工智能需要精确的单样本影响。标准的SGD-IE通过将每个epoch的代理求和来近似未删除一个样本的影响，并且忽略了epoch间的累积影响，从而导致对关键样本的错误排名。", "innovation": "提出了一个名为ACC-SGD-IE的新颖算法，该算法在训练过程中传播删除一个样本的影响，并在每一步更新累积影响状态。在光滑强凸设置中，它实现了几何误差收缩；在光滑非凸区域，它收紧了误差边界；且小批量进一步减少了常数。", "conclusion": "在成人、20个新闻组和MNIST数据集上进行了实验证明，无论数据是否被污染、学习是否凸或非凸，ACC-SGD-IE都能提供更准确的影响估计，尤其是在长时间训练期。对于下游数据清理，ACC-SGD-IE更可靠地标记出噪声样本，使用ACC-SGD-IE清洗后的数据训练的模型表现优于使用SGD-IE清洗后的模型。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26188", "html_url": "https://arxiv.org/abs/2510.26188", "title": "从住院患者医疗索赔数据预测所有原因再入院", "title_en": "Predicting All-Cause Hospital Readmissions from Medical Claims Data of Hospitalised Patients", "authors": "Avinash Kadimisetty,Arun Rajagopalan,Vijendra SK", "background": "降低可预防的再入院是支付方、医疗服务提供者和政策制定者提高卫生保健质量和降低成本的国家优先事项。再入院率被用作衡量医院提供医疗服务质量的基准。本项目使用机器学习技术（如逻辑回归、随机森林和支持向量机）分析医疗索赔数据，以识别预测所有原因再入院的关键人口统计和医学因素。由于医疗索赔数据的高度维度性，我们使用主成分分析作为降维技术，并且基于AUC指标评估了这些模型。", "innovation": "本项目创新性地利用机器学习方法（逻辑回归、随机森林和支持向量机）对医疗索赔数据进行分析，并使用主成分分析进行降维，从而识别预测所有原因再入院的关键因素。随机森林模型表现出最佳性能，其次是逻辑回归模型和支持向量机模型。", "conclusion": "基于随机森林模型识别的关键因素可以用于识别导致再入院的潜在原因，帮助医疗保健系统优先关注高风险患者以降低再入院率，最终降低成本并提高患者的治疗质量。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26266", "html_url": "https://arxiv.org/abs/2510.26266", "title": "生成模型中的最有可能插值", "title_en": "Likely Interpolants of Generative Models", "authors": "Frederik Möbius Rygaard,Shen Zhu,Yinzhu Jin,Søren Hauberg,Tom Fletcher", "background": "生成模型在可控生成、模型检查等方面具有重要作用。不过，大多数生成模型缺乏一个基本的插值概念，除非对模型或数据维度做出一些限制性的假设。本文旨在提出一种通用插值方案，该方案可以针对不同度量和概率分布寻找一致的可能性过渡路径。", "innovation": "作者提出了一个无需额外训练即可计算这些曲线的新算法，且理论上证明了该方法在适当的黎曼度量下可以被看作是地理线。实验结果表明，相比于基线模型，该插值方案可以跨越各个模型和数据集的高密度区域。", "conclusion": "本文提出了一种通用插值方案，该方案可以针对不同度量和概率分布寻找一致的可能性过渡路径，并且该方法在适当的黎曼度量下可以被看作是地理线。实验结果表明，该插值方案可以跨越各个模型和数据集的高密度区域。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26219", "html_url": "https://arxiv.org/abs/2510.26219", "title": "在预logits空间通过基于采样的最优控制进行LLMs的测试时对齐", "title_en": "Test-Time Alignment of LLMs via Sampling-Based Optimal Control in pre-logit space", "authors": "Sekitoshi Kanai,Tsukasa Yoshida,Hiroshi Takahashi,Haru Kuroki,Kazumune Hashimoto", "background": "由于对大型语言模型（LLMs）进行微调需要高昂的计算成本，因此测试时对齐（test-time alignment）LMMs引起了关注。传统的测试时对齐方法如最优采样（Best-of-n Sampling）在使用样本数量上的效果不佳，本文试图提出一种新的测试时对齐方法来改进这一问题。", "innovation": "本文提出了一种基于基于采样的模型预测控制的新测试时对齐方法，称为预logits上的自适应重要性抽样（Adaptive Importance Sampling on pre-logits，AISP）。该方法通过在预logits（最后倒数第二层的输出）上应用高斯扰动来最大化扰动均值的预期奖励。AISP 质量通过重要性抽样获得，并能够获得高于传统最优采样和其它基于奖励的测试时对齐方法的奖励。", "conclusion": "本文提出了一种新颖的测试时对齐方法 AISP，在奖励和使用的样本数量上优于最优采样方法，并在与其他基于奖励的测试时对齐方法的比较中表现更好，从而提出了在预logits空间中进行 LLMs 测试时对齐的新途径。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26243", "html_url": "https://arxiv.org/abs/2510.26243", "title": "Angular Steering: 通过激活空间旋转实现行为控制", "title_en": "Angular Steering: Behavior Control via Rotation in Activation Space", "authors": "Hieu M. Vu,Tan M. Nguyen", "background": "在大规模语言模型部署中，控制特定行为同时保留其通用能力是确保人工智能安全可靠运行的关键挑战。当前的引导方法，例如向量加法和方向削减，仅在激活和特征方向定义的二维子空间内进行，这使得它们对选定参数敏感，并可能导致由于激活空间中的意外交互而影响不相关的特征。", "innovation": "文章引入了Angular Steering，这是一种新颖且灵活的行为调节方法，它通过在固定二维子空间内旋转激活来操作。Angular Steering通过将引导形式化为向或远离目标行为方向的几何旋转，提供了对拒绝和遵从等行为的连续、精细控制。此外，提出了自适应Angular Steering变体，仅旋转与目标特征对齐的激活，进一步增强了稳定性和连贯性。Angular Steering在统一的几何旋转框架下概括了现有的添加和正交化技术，简化了参数选择，并在更广泛的调整范围内保持模型稳定。", "conclusion": "跨多个模型家族和大小的实验表明，Angular Steering在保持通用语言建模性能的同时实现了稳健的行为控制，突显了其灵活性、泛化能力和鲁棒性，优于先前的方法。代码和相关材料可在以下链接获取：this https URL"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26284", "html_url": "https://arxiv.org/abs/2510.26284", "title": "Empirical Bayesian Multi-Bandit Learning", "title_en": "Empirical Bayesian Multi-Bandit Learning", "authors": "Xia Jiang,Rong J.B. Zhu", "background": "Multi-task learning in contextual bandits is gaining interest due to its capability to enhance decision-making across related tasks by leveraging shared structures and task-specific heterogeneity. Previous methods have often neglected the learning of the covariance structure across bandits, which can limit the effectiveness of information sharing and adaptation to instance-specific variations.", "innovation": "The paper proposes a novel hierarchical Bayesian framework for multi-bandit learning. This framework introduces an empirical Bayesian approach to estimate the covariance matrix of the prior, which enhances practicality and flexibility. It also develops two efficient algorithms, ebmTS and ebmUCB, that incorporate the estimated prior into the decision-making process. The algorithms provide frequentist regret upper bounds and have shown superior performance in both synthetic and real-world datasets, particularly in complex environments.", "conclusion": "The proposed methods achieve lower cumulative regret compared to existing techniques, demonstrating their effectiveness in balancing exploration and exploitation across multi-bandits."}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26148", "html_url": "https://arxiv.org/abs/2510.26148", "title": "STAR: 一种在移动和渗透计算环境中通过Wi-Fi CSI实现隐私保护、能效边缘AI框架的人体活动识别", "title_en": "STAR: A Privacy-Preserving, Energy-Efficient Edge AI Framework for Human Activity Recognition via Wi-Fi CSI in Mobile and Pervasive Computing Environments", "authors": "Kexing Liu", "background": "现有的人类活动识别（HAR）方法通常存在计算效率低下、延迟高以及在资源受限的嵌入式移动边缘环境中可行性较低的问题。Wi-Fi信道状态信息（CSI）可以提供一种无接触的传感方法，适用于智能家居、医疗监控和移动物联网系统。", "innovation": "本文提出了STAR（Sensing Technology for Activity Recognition）框架，这是一种边缘AI优化的框架，结合了轻量级神经架构、自适应信号处理和硬件感知协同优化，以实现在低功耗嵌入式设备上进行实时、节能的HAR。STAR通过简化门控循环单元（GRU）为基础的循环神经网络，将模型参数减少了33%，同时保持有效的时序建模能力。此外，STAR还采用了一种多阶段预处理流水线，结合中值滤波、8阶巴特沃斯低通滤波和经验模式分解（EMD），来去除CSI幅度数据的噪声并提取时空特征。", "conclusion": "实验结果表明，STAR框架在七个活动类别上的平均识别准确率为93.52%，人体存在检测的准确率为99.11%，使用一个紧凑的97.6k参数模型。INT8量化推理达到了33 MHz的处理速度，CPU利用率仅为8%，与基于CPU的执行相比，速度提高了六倍。该系统提供了低于一秒的响应延迟和低功耗，确保了实时的隐私保护HAR，为移动和渗透计算环境提供了实用且可扩展的解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26230", "html_url": "https://arxiv.org/abs/2510.26230", "title": "MPRU: 作为分类流水线输出滤镜的模块化投影重新分配去学习", "title_en": "MPRU: Modular Projection-Redistribution Unlearning as Output Filter for Classification Pipelines", "authors": "Minyi Peng,Darian Gunamardi,Ivan Tjuawinata,Kwok-Yan Lam", "background": "现有的机器去学习（MU）方法通常侧重于理论公理或优化目标来实现知识的移除。但在实际应用场景中，此类解决方案往往面临可扩展性问题，并需要对原始数据集和模型有全面访问权。现有的方法主要关注完全重新训练模型，而这需要大量的计算资源并且难以实现频繁的调整。相比之下，该研究将分类训练视为按顺序进行类别的学习过程，提出了一种‘归纳方法’。通过在模型末端添加一个投影-重新分配层来实现去学习。这种方法不需要访问原始数据集或模型，能够解决现有方法面临的挑战。此次研究允许模块化和模型无感知地部署为现有的分类管道中的输出滤镜，几乎不需要改动。实验结果显示，该方法在多个数据集上取得了与完全重新训练模型相似的输出，但计算成本大幅降低。这表明该解决方案在实际应用中的适用性、可扩展性和系统兼容性，并保持了输出性能的高水平。", "innovation": "该论文提出了一种新的去学习方法，称为模块化投影重新分配去学习（MPRU），将其视为分类训练的顺序过程，通过在模型末端添加投影-重新分配层实现去学习。这种方法无需访问原始数据集或模型，解决了现有方法的可扩展性和访问性问题。MPRU能够作为一个模块化和模型无感知的输出滤镜集成到现有的分类流水线中，几乎无需改动。", "conclusion": "通过多个数据集（包括图像和表格数据）上的实验，该研究表明MPRU方法能够显著降低计算成本，同时保持与完全重新训练模型相似的性能输出。这表明，该解决方案具有良好的适用性、可扩展性和系统兼容性，能够有效应对实际应用场景中的去学习需求。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26278", "html_url": "https://arxiv.org/abs/2510.26278", "title": "分布式的多目标黑盒优化在扩散模型推理时多目标生成", "title_en": "Distributional Multi-objective Black-box Optimization for Diffusion-model Inference-time Multi-Target Generation", "authors": "Kim Yong Tan,Yueming Lyu,Ivor Tsang,Yew-Soon Ong", "background": "扩散模型被证明能够学习复杂的数据分布，这一能力推动了它们在高维多目标黑盒优化问题中的应用。现有的方法通常会采用外部优化循环（如进化算法）对扩散模型进行优化。然而，这些方法往往将扩散模型视为一个黑盒精炼器，忽视了扩散生成过程中的内部分布转换，这限制了它们的效率。", "innovation": "本文提出了推理时多目标生成（IMG）算法，该算法在推理阶段优化扩散过程，生成同时满足多个目标的样本。具体来说，IMG 在扩散生成过程中根据预期的多目标值进行加权重采样，确保扩散生成的样本符合我们所期望的多目标玻尔兹曼分布。此外，作者进一步推导出，多目标玻尔兹曼分布具有有趣的对数似然解释，它是分布式多目标优化问题的最优解。", "conclusion": "我们为多目标分子生成任务实现了IMG算法。实验表明，IMG 只需一次生成过程就可以实现比基线优化算法（这些算法往往需要几百次扩散生成）更高的 hypervolume。值得注意的是，我们的算法可以被视为优化的扩散过程，可以集成到现有方法中进一步提高其性能。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26301", "html_url": "https://arxiv.org/abs/2510.26301", "title": "带有主动数据增强的离线偏好聚类学习", "title_en": "Offline Clustering of Preference Learning with Active-data Augmentation", "authors": "Jingyuan Liu,Fatemeh Ghaffari,Xuchuang Wang,Mohammad Hajiesmaili,Carlee Joe-Wong", "background": "偏好学习从成对反馈中是一项广泛应用于强化学习带有用户反馈和推荐系统中的框架。在许多实际应用场景中，用户交互受限或成本高，因此需要离线偏好学习。此外，在现实生活中，偏好学习往往涉及具有不同偏好的用户。例如，来自不同背景的注释员可能以不同的方式排列相同的回应。这一设置提出了两个主要挑战：一是识别用户之间的相似性，以便有效地聚合数据，尤其是在离线数据在不同维度上失衡的情况下；二是处理离线数据不平衡的情况，其中某些偏差点被过度代表。为了解决这些挑战，本文研究了带有主动数据增强的离线偏好聚类学习问题，其中学习者可以访问多个具有潜在不同偏好的用户的固定数据集，并旨在最大化测试用户的效用。", "innovation": "本文提出了一种针对纯离线设置的Off-C$^2$PL算法，明确了样本噪声和偏差之间的权衡。为了解决不平衡数据的问题，还提出了一种新的框架A$^2$-Off-C$^2$PL，该框架允许学习者根据Off-C$^2$PL学习的簇结构为测试用户选择有限数量的额外活跃样本。这些主动收集的样本比离线样本更具效用。", "conclusion": "通过在合成和真实数据集上的模拟验证了理论结果。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26303", "html_url": "https://arxiv.org/abs/2510.26303", "title": "Per-sample Adam on分离数据的隐式偏见：偏离全批量模式", "title_en": "Implicit Bias of Per-sample Adam on Separable Data: Departure from the Full-batch Regime", "authors": "Beomhan Baek,Minhak Song,Chulhee Yun", "background": "Adam在深度学习中已成为实际上的优化器，但对其理论理解仍然有限。早期对Adam的分析显示它倾向于与$\boldsymbol{l}_\boldsymbol{\text{\textinfin}}$-几何学一致的解，然而这些结论仅适用于全批量的情况。", "innovation": "本研究探讨增量Adam（每次使用一个样本）在分类隔样本数据上的隐式偏见，提出了当$\beta_2 \to 1$时增量Adam的代理算法，并通过数据依赖的对偶固定点公式来描述其收敛方向。同时，证明了不同于Adam，Signum在任何批量大小下只要$\beta$够接近1，就能收敛到$\boldsymbol{l}_\boldsymbol{\text{\textinfin}}$-最大边缘分类器。研究结果突显了Adam的隐式偏见不仅依赖于批量方案，同时也依赖于数据集的特点。", "conclusion": "总体而言，我们的研究结果表明，Adam的隐式偏见对批量方案和数据集都非常敏感。相比之下，Signum在任何批量大小的条件下其偏见是不变的。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26323", "html_url": "https://arxiv.org/abs/2510.26323", "title": "QUBO基SVM训练中权重离散化的影响", "title_en": "On the Impact of Weight Discretization in QUBO-Based SVM Training", "authors": "Sascha Mücke", "background": "将SVM训练问题表示为QUBO（二元二次 unconstrained binary optimization 问题）形式，可以利用量子退火进行模型优化。本文研究了与对偶权重离散化水平相关的qubit数量对不同数据集预测性能的影响。并与经典的LIBSVM求解器进行了比较。", "innovation": "本文发现，即使在低精度的QUBO编码（例如每个参数1位）下，表现也具有竞争力，甚至在某些情况下更佳。更高的位宽可以允许更大的正则化参数，但不一定能提高分类性能。表明选择恰当的支持向量可能比精确的权重分配更重要。", "conclusion": "尽管当前硬件限制了解决的QUBO规模，但本文结果表明，随着量子设备的扩展，量子退火用于高效SVM训练的潜力巨大。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26302", "html_url": "https://arxiv.org/abs/2510.26302", "title": "从令牌层级因果视角理解视觉-语言组合性难度", "title_en": "Understanding Hardness of Vision-Language Compositionality from A Token-level Causal Lens", "authors": "Ziliang Chen,Tianang Xiao,Jusheng Zhang,Yongsen Zheng,Xipeng Chen", "background": "CLIP通过在共享嵌入空间对图像和文本进行对齐展示出了强大的跨模态泛化能力，但在对象、属性和关系的组合推理上表现欠佳，类似于词汇袋匹配。现有因果解释通常将文本视为单一向量，未能捕捉到令牌级别的结构，亦无法解释提示敏感性和在难题否定上的失败。本文旨在填补这一空白，提出了令牌感知因果表示学习（CRL）框架，并基于序列语言令牌结构因果模型（SCM）进行研究。", "innovation": "本文提出了令牌感知因果表示学习框架，证明了CLIP的对比目标可以在句级和令牌级SCM中恢复模态不变的潜在变量，并首次提出了组合脆性的原则性解释：组合不可识别性。同时，文章揭示了伪最优文本编码器能够实现完美的模态不变对齐，但在原子概念的SWAP、REPLACE和ADD操作上表现敏感度不足，导致无法区分正确描述和难题否定，尽管优化了相同的训练目标。进一步，文章通过模态差距将语言侧的不可识别性与视觉侧的问题联系起来，并展示了迭代组合算子的累积难度，从而激励改进的负样本挖掘策略。", "conclusion": "令牌层级的因果视角揭示了视觉-语言组合性的难度，并为CLIP的组合脆性提供了首个原则性解释。同时，文章还揭示了伪最优文本编码器的存在，并展示了特定操作下的表现受限，进而提出了改进的负样本挖掘策略。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26324", "html_url": "https://arxiv.org/abs/2510.26324", "title": "通过将扩散模型与退火兰加文动力学相结合进行后验采样", "title_en": "Posterior Sampling by Combining Diffusion Models with Annealed Langevin Dynamics", "authors": "Zhiyang Xun,Shivam Gupta,Eric Price", "background": "在给定噪声线性测量 $y = Ax + \\xi$ 和分布 $p(x)$ 的良好先验近似的情况下，如何从后验 $p(x \rvert y)$ 中采样？后验采样为诸如图像修复、去模糊和MRI重建等任务提供了准确且公平的框架。尽管存在多种近似方法，但通常情况下近似后验采样难以计算。然而，当处理局部或全局对数凸分布 $p(x)$ 时，朗刪动力学可生成后验样本，需精确分数，但在分数估计误差下的鲁棒性较低，要求满足MGF条件。在无条件情况下，扩散模型只需满足$L^2$范数下的分数误差即可成功实现。", "innovation": "本文提出了通过将扩散模型与退火兰加文动力学相结合的方法，仅需$L^4$范数下的分数误差，就能在多项式时间内实现条件采样，从而在先验不是完全精确的场景下提供了一种有效的解决方案。", "conclusion": "通过这种结合技术，可以实现在分数误差不一定是子指数型时的条件采样，解决了先前受限的bpproaches。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26328", "html_url": "https://arxiv.org/abs/2510.26328", "title": "Agent Skills 必须启用新的现实且极其简单的提示注入", "title_en": "Agent Skills Enable a New Class of Realistic and Trivially Simple Prompt Injections", "authors": "David Schmotz,Sahar Abdelnabi,Maksym Andriushchenko", "background": "持续学习的大型语言模型(LLMs)仍然是一个未解决的关键研究挑战。最近，一家领先的LLM公司通过引入Agent Skills框架，使代理能够基于存储在简单markdown文件中的指令获取新知识，迈出了一步。尽管Agent Skills可以是一个有用的工具，但作者指出它们本质上是不安全的，因为它们使得简单的提示注入变得轻而易举。作者展示了如何在长篇Agent Skill文件和引用脚本中隐藏恶意指令，以泄露敏感数据，如内部文件或密码。此外，作者还展示了如何绕过一个流行编程代理的系统级防护，仅通过简单任务特定的“不要再次询问”批准，就可以导致相关的但有害的行动。", "innovation": "本文揭示了Agent Skills在实际应用场景中如何通过简单的提示注入导致安全漏洞，具体展示了如何在Agent Skill文件和引用脚本中埋藏恶意指令以泄露敏感信息，并说明了即使在研究努力和模型能力增强的情况下，前线LLMs仍然容易受到简单的提示注入攻击。", "conclusion": "尽管正在进行研究努力和扩大模型能力，但前线LLMs仍然容易在现实场景中受到极其简单的提示注入攻击。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26347", "html_url": "https://arxiv.org/abs/2510.26347", "title": "随机、稀疏和非稳定环境中的自主水下车辆污染检测的强化学习", "title_en": "Reinforcement Learning for Pollution Detection in a Randomized, Sparse and Nonstationary Environment with an Autonomous Underwater Vehicle", "authors": "Sebastian Zieglmeier,Niklas Erdmann,Narada D. Warakagoda", "background": "强化学习（RL）算法旨在通过学习最大化奖励的动作来优化问题解决，但在随机和非稳定环境中这一任务变得尤其具有挑战性。先进的RL算法在这些条件下解决问题的能力仍然有限。例如，在使用自主水下车辆（AUV）搜索水下污染云时，RL算法需要导航在一个奖励稀疏的环境中，经常的动作会导致零奖励。", "innovation": "该研究通过重新审视和修改古典RL方法，提出了在稀疏、随机化和非稳定环境中高效操作的方法。研究系统地研究了包括层次算法改变、多目标学习以及整合位置记忆作为外部输出滤波器以防止状态重访在内的多种修改。研究结果表明，基于蒙特卡洛的方法在性能上显著优于传统的Q学习和两种详尽的搜索模式，证明了其在复杂环境中的适应能力。", "conclusion": "这些发现表明，强化学习方法可以有效适应随机、非稳定和奖励稀疏的环境。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26353", "html_url": "https://arxiv.org/abs/2510.26353", "title": "向金融中可解释和可靠的AI迈进", "title_en": "Towards Explainable and Reliable AI in Finance", "authors": "Albi Isufaj,Pablo Mollá,Helmut Prendinger", "background": "金融领域的预测日益依赖大型神经网络模型，但这些模型的不透明性给信任和合规性带来了挑战。", "innovation": "提出了几种可解释和可靠的AI方法，包括使用时间序列基础模型Time-LLM结合提示避免错误方向预测，将基础模型时间和可靠性估计算法相结合过滤无用预测，以及采用基于符号推理和领域规则编码实现透明的论证。通过将预测性能与可靠性估计和基于规则的推理整合，该框架推动了透明和可审计的金融AI系统的进步。", "conclusion": "实验表明，该架构减少了假阳性结果，支持了有选择性的执行。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26311", "html_url": "https://arxiv.org/abs/2510.26311", "title": "基于层特定建模与对齐的无数据增量学习模型反演", "title_en": "Model Inversion with Layer-Specific Modeling and Alignment for Data-Free Continual Learning", "authors": "Ruilin Tong,Haodong Lu,Yuhang Liu,Dong Gong", "background": "持续学习（CL）旨在通过序列任务的增量训练模型，同时保持对前序任务的性能。然而，由于隐私或安全限制，存储和回放数据通常不可行，且对任意预训练模型也不切实际。无数据的持续学习试图在无法访问之前数据的情况下更新模型。尽管正则化有效，但本研究采用模型反演从训练模型生成数据，实现了无需存储样本的回放。然而，在预测模型中，模型反演面临两个挑战：（1）单纯的从压缩输出标签生成输入会导致合成数据和真实数据之间的漂移，回放这种数据会稀释先前的知识；（2）反演计算成本高昂，因为每次都需要反向传播通过完整模型。这些问题在大型预训练模型（如CLIP）中尤为突出。", "innovation": "提出了一种基于层特定建模与对齐的模型反演方法（PMI），以提高效率。这种方法借鉴了一层优化中更快收敛的理念，为完整模型反演提供了强大的初始化，显著减少了迭代次数。为了应对特征漂移，该研究通过高斯分布和对比模型建模类别特征，确保了合成数据和真实数据特征之间的对齐。结合PMI和特征建模，该方法能够通过从语义感知的投影特征生成伪图像来实现新类别的持续学习，实现了多种持续学习场景下的强大效果与兼容性。", "conclusion": "该方法能够有效提升无数据条件下持续学习的效率与效果，通过对模型反演和新类别的生成机制进行改进，实现了与多种持续学习场景的良好兼容性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26342", "html_url": "https://arxiv.org/abs/2510.26342", "title": "线性因果发现中的干预约束", "title_en": "Linear Causal Discovery with Interventional Constraints", "authors": "Zhigao Guo,Feng Dong", "background": "因果推理是建立准确因果模型的基础，对于改进下游任务（如设计新治疗方案）至关重要。现有因果发现方法虽然可以应用结构性约束来确保因果路径的存在，但仍然可能出现错误的因果结论。例如，一种方法可能会得出‘PIP3抑制Akt’的错误结论。干预约束则通过在因果模型中直接设计和表达高阶因果知识的有效方式，来解决这一问题，确保学到的因果模型符合已知的因果影响，从而提高模型的准确性和解释性，还能够推动对新的因果关系的发现。", "innovation": "本文提出了一种新的干预约束概念，它与干预数据有很大的不同。干预数据需要对变量进行直接干扰，而干预约束则以不平等约束的形式编码高层因果知识。为了形式化干预约束，作者提出了一个用于量化线性因果模型中总因果效应的度量标准，并将其问题表述为一个约束优化任务，通过两阶段约束优化方法求解。这种方法不仅能够改进模型精度，确保与现有发现的一致性，还能使模型更具解释性，并促进新因果关系的发现。", "conclusion": "在真实数据集上的评估表明，通过引入干预约束，不仅提高了模型的准确性并确保了一致性，也使得模型更加易于解释，并可发现新的因果关系，而这些关系可能通过传统方法识别成本较高。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26369", "html_url": "https://arxiv.org/abs/2510.26369", "title": "CorVS: 在现实仓库中通过视频轨迹-传感器对应进行的人识别", "title_en": "CorVS: Person Identification via Video Trajectory-Sensor Correspondence in a Real-World Warehouse", "authors": "Kazuma Kano,Yuki Mori,Shin Katayama,Kenta Urano,Takuro Yonezawa,Nobuo Kawaguchi", "background": "工人所在位置的数据对于工业现场的高生产力至关重要。摄像头是物流仓库定位的一种有前景的工具，因为它们还提供了有价值的工作环境上下文（如包裹状态）。然而，仅凭视觉数据识别个体通常是不切实际的。因此，许多先前的研究通过比较轨迹和可穿戴传感器测量值识别视频中的人。虽然这种方法具有独立于外观的优点，但现有方法可能在现实世界条件下失败。", "innovation": "我们提出了CorVS，一种基于视觉追踪轨迹与传感器测量值对应的新数据驱动的人识别方法。首先，我们的深度学习模型预测每对轨迹和传感器测量值的对应概率和可靠性。其次，我们的算法使用预测的概率和可靠性在时间上匹配轨迹和传感器测量值。我们开发了一个基于实际仓库操作的数据集，并证明了该方法在现实应用中的有效性。", "conclusion": "我们开发了一个基于实际仓库操作的数据集，并展示了CorVS方法在现实世界应用中的有效性。我们的方法克服了传统方法在真实世界条件下的局限性，提供了更可靠的人识别解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26350", "html_url": "https://arxiv.org/abs/2510.26350", "title": "UnifiedFL: 动态统一学习框架以实现公平协作", "title_en": "UnifiedFL: A Dynamic Unified Learning Framework for Equitable Federation", "authors": "Furkan Pala,Islem Rekik", "background": "联邦学习（FL）作为一种关键范式，在无需共享原始数据的情况下，使得多个客户端能够协作训练模型，从而在放射学和病理学等领域实现隐私保护的应用。然而，现有研究大多关注于具有相同基本神经网络架构和同质数据集的客户端之间的协作训练，缺乏针对具有根本不同架构和非同质数据集的客户端之间的协作研究。现有的FL框架面临的限制主要是它们宣称支持架构异构性，但实际仅能容忍单一模型家族内的变化（如较浅、更深或更宽的CNN），并且仍假设共享全局架构，无法应对客户端部署不同网络类型（如CNN、GNN、MLP）的情况。此外，现有方法通常只解决了统计异构性问题，而未考虑领域裂变问题，即每个客户端的数据分布与测试时间的数据分布大不相同，这影响了模型的泛化能力。当客户端使用不同架构、数据分布非同质并且面对不同测试领域时，现有的方法表现不佳。", "innovation": "UnifiedFL 提出了一个动态的联邦学习框架，将异构的本地网络表示为优化过程中的图节点和边，采用一个共享的图神经网络（GNN）来参数化所有架构。引入了（i）一个用于参数化所有架构的通用GNN，（ii）基于客户端参数之间欧氏距离的驱距聚类，以及（iii）结合收敛和多样性的两层聚合策略。通过在MedMNIST分类和海马体分割基准上的实验结果，展示了UnifiedFL的优越性能。", "conclusion": "实验结果表明，UnifiedFL解决了异构架构、非同质数据以及不同测试领域的挑战，通过将异构本地网络表示为优化过程中的图节点和边，采用一个共享的图神经网络（GNN），以及结合收敛和多样性的两层聚合策略，提升了模型的泛化能力。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26389", "html_url": "https://arxiv.org/abs/2510.26389", "title": "基于低频截断的自适应上下文长度优化在多智能体强化学习中的应用", "title_en": "Adaptive Context Length Optimization with Low-Frequency Truncation for Multi-Agent Reinforcement Learning", "authors": "Wenchang Duan,Yaoliang Yu,Jiwan He,Yi Shi", "background": "最近，深度多智能体强化学习（MARL）在解决长期依赖关系和非马尔可夫环境等具有挑战性任务中表现出色。这一成功部分归因于基于固定长度上下文的策略调整，但固定的上下文长度可能会导致探索效率低下和冗余信息的问题。因此，本文提出了一个新的MARL框架，以获得自适应和有效的上下文信息。该框架通过动态优化上下文长度，增强探索能力，从而促进对全局最优性的收敛。同时，通过呈现高效输入表示，有效过滤冗余信息，进一步提升上下文长度的自适应优化能力。利用基于傅里叶的低频截断方法，提取分散智能体之间的全局时间趋势，为MARL环境提供了有效的表示方法。", "innovation": "本文提出了一种基于低频截断的自适应上下文长度优化方法，通过动态调整上下文长度来增强探索效率，优化智能体的决策过程；利用傅里叶低频截断方法提取全局时间趋势，有效过滤冗余信息，为MARL环境提供了高效的表示方法，提升了模型的性能。", "conclusion": "实验结果表明，提出的方法在涉及长期依赖关系的任务，如PettingZoo、MiniGrid、Google Research Football (GRF) 和 StarCraft Multi-Agent Challenge v2 (SMACv2) 上达到了最先进的性能。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26376", "html_url": "https://arxiv.org/abs/2510.26376", "title": "高效的生成式AI增强突发平流层暖化的概率预报", "title_en": "Efficient Generative AI Boosts Probabilistic Forecasting of Sudden Stratospheric Warmings", "authors": "Ningning Tao,Fei Xie,Baoxiang Pan,Hongyu Wang,Han Huang,Zhongpu Qiu,Ke Gui,Jiali Luo,Xiaosong Chen", "background": "突发平流层暖化（SSWs）是亚季节可预报性的关键来源，也是极端冬季天气的主要驱动因素。然而，由于物理表现的限制、初始化的不足以及集合预报的巨大计算需求，准确和高效的预报仍是一个持续的挑战。虽然数据驱动的预报正在迅速发展，但将其应用于SSWs复杂的三维动力学，尤其是概率预报，仍然未被充分探索。", "innovation": "本文通过开发一种基于流动匹配的生成式AI模型（FM-Cast），有效解决了这个问题。FM-Cast能够高效且精准地预报平流层环流的时空演变。在18场重大SSW事件（1998-2024）中，FM-Cast能够准确地预报10场事件，预报时间窗口长达20天，且与50成员30天预报相比，仅需2分钟运行于消费级GPU上。此外，FM-Cast在理想实验中揭示了SSW可预报性与其实质驱动因素之间的基本联系，区分了由对流层强迫和内部平流层动力学驱动的事件。", "conclusion": "本研究建立了一种计算效率高的概率预报框架，用于预报平流层异常，并展示了生成式AI对于加深大气-气候动力学物理理解的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26451", "html_url": "https://arxiv.org/abs/2510.26451", "title": "Robust Graph Condensation via Classification Complexity Mitigation", "title_en": "Robust Graph Condensation via Classification Complexity Mitigation", "authors": "Jiayi Luo,Qingyun Sun,Beining Yang,Haonan Yuan,Xingcheng Fu,Yanbiao Ma,Jianxin Li,Philip S. Yu", "background": "图凝聚（GC）近年来因其能够合成更小但信息丰富的图而引起了广泛关注。然而，现有的研究往往忽略了在原始图被破坏的情况下GC的鲁棒性。在这种情况下，GC的性能会显著下降，而现有的鲁棒图学习技术也只能提供有限的有效性。", "innovation": "本文通过几何视角的图数据流形提出了一个新的鲁棒图凝聚框架，名为MRGC。具体地，我们引入了三个图数据流形学习模块来引导凝聚图位于平滑、低维且类别模糊度最小的流形内，从而保持GC的分类复杂度降低能力，并确保在通用对抗攻击下的鲁棒性能。", "conclusion": "广泛的实验表明，以ModelName开始的鲁棒性在多种攻击场景下表现良好。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26392", "html_url": "https://arxiv.org/abs/2510.26392", "title": "基于支持向量机和孪生支持向量机的多任务学习：全面综述", "title_en": "Multi-Task Learning Based on Support Vector Machines and Twin Support Vector Machines: A Comprehensive Survey", "authors": "Fatemeh Bazikar,Hossein Moosaei,Atefeh Hemmati,Panos M. Pardalos", "background": "多任务学习（MTL）能够同时训练相关任务，通过共享信息提高泛化、效率和鲁棒性，特别是在数据稀缺或高维场景中。尽管深度学习在最近的MTL研究中占主导地位，支持向量机（SVM）和孪生支持向量机（TWSVM）因其可解释性、理论严谨性和在小型数据集上的有效性仍然具有相关性。", "innovation": "文章概述了基于SVM和TWSVM的多任务学习方法，强调共享表示、任务正则化和结构关联策略。特别关注了新兴的TWSVM扩展在多任务设置中的应用潜力，尽管这些扩展方法尚未得到充分探索。文章在理论性质、优化策略和实证性能方面比较了这些模型，并讨论了计算机视觉、自然语言处理和生物信息学等领域的应用。", "conclusion": "文章指出了研究缺口，并提出了构建可扩展、可解释且可靠的基于边界的MTL框架的未来方向。为研究者和从业者提供了关于基于SVM和TWSVM的多任务学习的综合资源。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26475", "html_url": "https://arxiv.org/abs/2510.26475", "title": "ReSpec：迈向强化学习系统中预测性解码的优化", "title_en": "ReSpec: Towards Optimizing Speculative Decoding in Reinforcement Learning Systems", "authors": "Qiaoling Chen,Zijun Liu,Peng Sun,Shenggui Li,Guoteng Wang,Ziming Liu,Yonggang Wen,Siyuan Feng,Tianwei Zhang", "background": "使用强化学习（RL）调整大型语言模型（LLMs）通常会受到生成阶段的瓶颈，该阶段消耗了训练时间的75%以上。推测性解码（SD）在服务系统中加速自回归生成，但在RL训练下的行为尚未被充分探索。三个关键问题阻碍了SD与RL系统的直接集成：在大批次处理中减速提升减小、持续更新策略下的模板陈旧以及模型策略退化。", "innovation": "ReSpec系统通过三项互补机制解决了这些问题：动态调整SD配置、通过知识蒸馏进化策略神经网络架构层、以及根据卷积奖励加权更新。在Qwen模型（3B-14B）上，ReSpec实现了最多4.5倍的速度提升，同时保持了奖励收敛和训练稳定性，为基于RL的LLM调整提供了一种实用的解决方案。", "conclusion": "ReSpec通过解决MLM基于RL调整中推测性解码的三个关键瓶颈问题，实现了高效的加速，并提供了实用的调优方法。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26444", "html_url": "https://arxiv.org/abs/2510.26444", "title": "通过双通道知识蒸馏和自适应融合从稀少数据进行个性化治疗效果预测", "title_en": "Personalized Treatment Outcome Prediction from Scarce Data via Dual-Channel Knowledge Distillation and Adaptive Fusion", "authors": "Wenjie Chen,Li Zhuang,Ziying Luo,Yu Liu,Jiahao Wu,Shengcai Liu", "background": "小样本和罕见患者群体的个性化治疗效果预测对于精准医疗至关重要。然而，昂贵的试验数据限制了预测效果的提升。针对这一问题，本文探讨了如何利用大量但低质量的模拟数据来增强稀缺但高质量的试验数据预测的有效性.", "innovation": "提出了一种跨保真度知识蒸馏和自适应融合网络（CFKD-AFN），该模型利用了大量的但保真度较低的模拟数据来提高稀缺但保真度较高的试验数据的预测效果。CFKD-AFN 包含一个双通道知识蒸馏模块来提取低保真度模型中的互补知识，以及一个基于注意力的融合模块来动态整合多源信息.", "conclusion": "在慢性阻塞性肺疾病治疗效果预测实验中，CFKD-AFN 显著提高了预测精度，从 6.67% 到 74.55%，并且对不同规模的高质量数据集具有较强鲁棒性。此外，还提出了可解释的 CFKD-AFN 变体，能够探索潜在的医学语义，支持临床决策."}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26487", "html_url": "https://arxiv.org/abs/2510.26487", "title": "基于高斯不确定性的时间序列网络异常检测的量子门循环GAN", "title_en": "Quantum Gated Recurrent GAN with Gaussian Uncertainty for Network Anomaly Detection", "authors": "Wajdi Hammami,Soumaya Cherkaoui,Jean-Frederic Laprade,Ola Ahmad,Shengrui Wang", "background": "时间序列数据中的异常检测对于网络安全具有重大意义，但现有的量子机器学习方法受限于量子比特数的限制。该研究背景指出最近的量子机器学习方法如量子核方法和变量子电路虽有所成效，但尚无法完全解决这一问题。", "innovation": "引入了一种新型的量子门递归单元（QGRU）- 生成式对抗网络（GAN）模型，结合了连续数据注入（SuDaI）和多度量门策略，用于网络异常检测。该模型的独特之处在于使用了具有量子增强功能的生成器，该生成器通过重新参数化输出正态分布的均值和对数方差，合并 Wasserstein 批判器以稳定对抗性训练。异常检测机制首先基于高斯不确定性估计进行初步判断，然后通过批判分数和重构误差进行验证。", "conclusion": "实验结果表明，在基准数据集上，该方法的时间序列感知 F1 分数（TaF1）达到89.43%，超出了现有经典和量子模型的性能。此外，在实际的IBM量子硬件上部署测试后的成果表明，该模型在当前噪声的中等规模量子（NISQ）设备上具有高稳健性和可实践性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26491", "html_url": "https://arxiv.org/abs/2510.26491", "title": "基于离策影响指导的数据高效RLVR", "title_en": "Data-Efficient RLVR via Off-Policy Influence Guidance", "authors": "Erle Zhu,Dazhi Jiang,Yuan Wang,Xujun Li,Jiale Cheng,Yuxian Gu,Yilin Niu,Aohan Zeng,Jie Tang,Minlie Huang,Hongning Wang", "background": "当前基于强化学习的可验证奖励（RLVR）方法在提升大型语言模型（LLMs）的推理能力方面依赖于经验主义的数据选择方法，缺乏理论支持和泛化能力。", "innovation": "提出了一种利用影响函数进行理论支持的数据选择方法，通过离策影响估计减少在线策略展开的计算成本，并采用稀疏随机投影降低高维梯度计算的复杂性，建立了分级RL框架CROPI（Curriculum RL with Off-Policy Influence guidance），通过逐步选择当前策略最有效的数据增强训练效率。", "conclusion": "实验表明，CROPI显著加速了训练过程，在1.5B模型上实现了2.66倍的步骤加速，同时只使用了完整数据集的10%。研究结果表明基于影响的数据选择具有显著提升RLVR效率的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26433", "html_url": "https://arxiv.org/abs/2510.26433", "title": "Co-Evolving Latent Action World Models", "title_en": "Co-Evolving Latent Action World Models", "authors": "Yucen Wang,Fengming Zhang,De-Chuan Zhan,Li Zhao,Kaixin Wang,Jiang Bian", "background": "在通过潜动作将预训练的视频生成模型转化为可控的世界模型方面，采用两阶段方法训练潜动作模型（LAM）与世界模型，尽管有效，但存在冗余训练问题，限制了模型间的协适配。传统的解决方案是替换LAM中的前向动态模型为一个强大的世界模型并联合训练它们，但实现起来困难且容易导致表示坍塌。因此，当前领域缺乏一种有效的协同进化框架来优化这两个模型间的交互效果和协同学习能力，特别是在视频模拟质量和下游视觉规划方面表现出色的方法。", "innovation": "本文提出了一种新颖的协同方法CoLA-World，首次实现两模型的协同进化，通过一个关键的学习前热身阶段，有效地对齐从头开始训练的LAM与预训练世界模型的表示，从而克服了联合学习的核心挑战。CoLA-World使得世界模型能够作为知识丰富的导师，通过提供梯度来塑造高质量的LAM，而LAM则提供了对世界模型更精准且适应性强的控制接口。实验结果表明，CoLA-World在视频模拟质量和下游视觉规划方面达到了或超越了先前的两阶段方法，为该领域提供了一个可靠且高效的新的协同学习范式。", "conclusion": "CoLA-World 提供了一种新颖的方法，通过协同学习框架有效地对齐潜动作模型与世界模型的表示，解决了核心挑战，并在实践中展示了其优越性能，建立了新的协同学习范式，有望推动该领域的发展。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26533", "html_url": "https://arxiv.org/abs/2510.26533", "title": "基于超图的高阶正则化学习", "title_en": "Higher-Order Regularization Learning on Hypergraphs", "authors": "Adrien Weihs,Andrea Bertozzi,Matthew Thorpe", "background": "高阶超图学习（HOHL）最近被引入作为经典超图正则化的一种原则性替代方案，通过由超图结构诱导的多尺度拉普拉斯的幂来强制更高的平滑性。先前的研究通过几何设置中的渐近一致性分析确立了HOHL的良态和病态性质。", "innovation": "该研究扩展了理论基础，通过证明截断的HOHL版本的一致性，并推导出当HOHL作为正则化器用于全监督学习时的具体收敛速率。进一步展示了HOHL在有监督学习与缺乏嵌入几何结构的数据集中的强大实证性能，强调了HOHL在不同学习环境中的多样性和鲁棒性。", "conclusion": "通过理论分析和实证研究，证明了HOHL的理论一致性与实际效果，尤其是在非几何结构数据集上展示了其有效性，增强了HOHL在学习任务中的适应性和稳健性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26519", "html_url": "https://arxiv.org/abs/2510.26519", "title": "思考超越策略：上下文引导策略优化", "title_en": "Think Outside the Policy: In-Context Steered Policy Optimization", "authors": "Hsiu-Yuan Huang,Chenming Tang,Weijie Liu,Saiyong Yang,Yunfang Wu", "background": "现有可验证奖励强化学习（RLVR）方法，如组相对策略优化（GRPO），已显著提升了大型推理模型（LRMs）的推理能力。然而，这些方法依靠于当前策略分布中的逐策略回放，导致轨迹多样性狭窄。最近的方法尝试通过引入强专家模型自动生成的轨迹来扩展策略覆盖范围，但这一做法增加了计算成本，并且强大的专家模型常常不可用。这些局限性促使我们提出了一种名为In-Context Steered Policy Optimization（ICPO）的新框架。", "innovation": "ICPO框架以LRMs的内在上下文学习能力为基础，利用现有数据提供专家指导。ICPO引入了混合策略GRPO的隐式专家强迫方法，可以在不需要使用先进模型转移的条件下扩展探索范围。此外，ICPO通过引入专家区域拒绝采样来过滤不稳定的离策略轨迹，并通过逐步增加专家奖励来平衡早期的专家指导和后期的自主改进，从而增强强化学习的稳定性和性能。", "conclusion": "ICPO在数学推理基准任务上持续提升了强化学习的性能和训练稳定性，揭示出一种适用于LRMs的可扩展且有效的RLVR范式。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26557", "html_url": "https://arxiv.org/abs/2510.26557", "title": "减肥后的提升树：为资源受限设备的紧凑模型", "title_en": "Boosted Trees on a Diet: Compact Models for Resource-Constrained Devices", "authors": "Jan Stenkamp,Nina Herrmann,Benjamin Karic,Stefan Oehmcke,Fabian Gieseke", "background": "现代物联网应用亟需在计算能力受限的设备上部署机器学习模型。因此，提升决策树的压缩方案变得尤为重要，以满足轻量级机器学习模型的需求。", "innovation": "本文提出了一种提升决策树的压缩方案，通过在训练过程中奖励特征和阈值的重用等方法减少内存占用。实验结果显示，与使用适应性训练过程和不同内存布局的LightGBM模型相比，压缩模型在4-16倍压缩比下达到相同性能。", "conclusion": "经压缩的模型可以在无需持续通信或外部能源供应的情况下自主运行，且只需极低的计算能力和能源。这使其适用于远程监控、边缘分析和孤立或能量有限环境中的实时决策等多种物联网应用情境。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26527", "html_url": "https://arxiv.org/abs/2510.26527", "title": "通过理论视角实现多基元推测性解码", "title_en": "Polybasic Speculative Decoding Through a Theoretical Perspective", "authors": "Ruilin Wang,Huixia Li,Yuexiao Ma,Xiawu Zheng,Fei Chao,Xuefeng Xiao,Rongrong Ji", "background": "大型语言模型（LLMs）的推断延迟是其大规模部署中的关键瓶颈。推测性解码方法已被证明能加速推断而不破坏输出分布。然而，现有方法通常依赖双阶段（草案-验证）框架，并缺乏严密的理论基础。", "innovation": "本文提出了一个新的多基元推测性解码框架，基于全面的理论分析。论文证明了一个基本原则定理，描述了多模型推测性解码系统的最优化推断时间，揭示了如何超越双阶段方法，向更一般的多基元范式扩展。通过理论分析多模型词元生成过程，优化了模型能力、接受长度与总计算成本之间的相互作用。框架支持独立实现和与现有推测技术的集成，从而在实践中实现加速。实验结果显示，该方法对于不同模型不同规模的加速比分别为3.31倍至4.01倍（LLaMA2-Chat 7B），最多3.87倍（LLaMA3-8B），最多4.43倍（Vicuna-7B）和最多3.85倍（Qwen2-7B），同时保持原始输出分布。", "conclusion": "本研究通过理论分析多基元推测性解码框架，提出优化推测性解码的方法，展示了显著的加速效果，并且不破坏原始输出分布。未来的研究将通过进一步理论证明和实现代码来促进多基元推测性解码的深入研究。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26541", "html_url": "https://arxiv.org/abs/2510.26541", "title": "三阶段贝叶斯迁移学习框架以提高数据稀缺领域中的预测", "title_en": "A Three-Stage Bayesian Transfer Learning Framework to Improve Predictions in Data-Scarce Domains", "authors": "Aidan Furlong,Robert Salko,Xingang Zhao,Xu Wu", "background": "机器学习在工程应用中广泛使用，特别是在deep neural networks方面因其高性能和易访问性而被大量采用。然而，实验数据往往稀疏、噪声大或不足以构建健壮的数据驱动模型。为解决这一问题，提出了迁移学习方法，特别是domain-adversarial neural networks (DANNs)，通过学习领域不变特征来改进在更大领域变化下的迁移学习，尤其是在半监督设置中。然而，DANNs在训练过程中稳定性差，缺乏对不确定性进行量化的方法。", "innovation": "本文提出了一种完全监督的三阶段框架，即staged Bayesian domain-adversarial neural network (staged B-DANN)，它结合了参数迁移和共享潜在空间适应。第一阶段训练确定性特征提取器；第二阶段使用DANN进行对抗性精炼；第三阶段在适应特征提取器基础上构建贝叶斯神经网络，以在目标领域进行微调，以应对条件变化并提供经过校准的不确定性估计。这一方法首先在合成基准数据上得到验证，表明其显著优于标准的转移学习技术，随后应用于预测矩形通道中的临界热通量任务，结果表明staged B-DANN方法可以提高预测准确性和泛化能力。", "conclusion": "研究结果表明，staged B-DANN方法可以提升预测准确性和泛化能力，有助于其他领域在核工程中的应用。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26560", "html_url": "https://arxiv.org/abs/2510.26560", "title": "关于在深度网络中测量快捷路径定位的方法", "title_en": "On Measuring Localization of Shortcuts in Deep Networks", "authors": "Nikita Tsoy,Nikola Konstantinov", "background": "快捷路径是指在训练过程中表现出色但在泛化时失败的模式，对深度网络的可靠性构成了重大挑战（Geirhos等人，2020）。然而，快捷路径对特征表示的影响尚未得到充分研究，阻碍了制定针对性的快捷路径缓解方法。", "innovation": "本文提出了一种新颖的实验设计，通过反事实训练在清洁和受污染的数据集上定量地量化各层对准确率下降的贡献，以研究深度模型中的快捷路径定位。该研究在CIFAR-10、Waterbirds和CelebA数据集上对VGG、ResNet、DeiT和ConvNeXt架构进行了实验，发现快捷路径学习在整个网络中分散而非集中于特定层。", "conclusion": "研究发现，浅层主要编码虚假特征，而深层则倾向于忘记清洁数据中预测准确的关键特征。不同架构和数据集的快捷路径定位存在差异，表明设计通用方法的难度，并支持数据集和架构特定的方法。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26566", "html_url": "https://arxiv.org/abs/2510.26566", "title": "使用Jensen-Shannon距离的多类别局部校准", "title_en": "Multiclass Local Calibration With the Jensen-Shannon Distance", "authors": "Cesare Barbera,Lorenzo Perini,Giovanni De Toni,Andrea Passerini,Andrea Pugnana", "background": "开发可信的机器学习模型需要它们的预测概率能够良好校准，即预测概率应反映真实的类别频率。在多类别分类的校准概念中，强校准是最严格的，因为它要求所有类别的预测概率同时校准。然而，现有的多类别校准方法缺乏输入之间的距离范式，这使得它们容易受到邻近偏差的影响：在特征空间的稀疏区域的预测会系统地校准错误。这种偏差在高风险的医疗等场景下尤为重要，因为稀疏实例正是最需要免受偏差影响的实例。", "innovation": "本文通过引入多类别局部校准的局部视角来解决这一主要不足之处。首先，正式定义了多类别局部校准并确立了其与强校准的关系。其次，从理论上分析了现有评价指标应用于多类别局部校准的缺点。第三，提出了一种实用的方法来增强神经网络中的局部校准，该方法使用Jensen-Shannon距离强制预测概率和局部类别频率估计之间的对齐。", "conclusion": "最后，在实践经验上验证了本文的方法，并将其与其他多类别校准技术进行了对比。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26510", "html_url": "https://arxiv.org/abs/2510.26510", "title": "LLMs作为模型与超参数选择的上下文条件元学习者", "title_en": "LLMs as In-Context Meta-Learners for Model and Hyperparameter Selection", "authors": "Youssef Attia El Hili,Albert Thomas,Malik Tiomoko,Abdelhakim Benechehab,Corentin Léger,Corinne Ancourt,Balázs Kégl", "background": "模型和超参数选择在机器学习中至关重要但也充满挑战，通常需要专家直觉或昂贵的自动化搜索。我们研究了大型语言模型（LLMs）是否可以作为一种上下文条件下的元学习者来进行这一任务。通过将每个数据集转化为可解释的元数据，我们促使LLM推荐合适的模型家族和超参数。我们研究了两种提示策略：（1）零样本模式，仅依赖预训练知识；（2）元信息增益模式，通过添加模型及其过去任务表现的示例来增强。", "innovation": "该研究提出了一种新的方法，即利用大型语言模型作为上下文条件元学习者来选择模型和优化超参数。通过将数据集转化为可解释的元数据，让语言模型根据元信息推荐合适的模型家族和超参数。这种方法展示了LLMs在无需搜索的情况下推荐具有竞争力的模型和超参数的能力，同时也证明了其在上下文条件下的元学习能力.", "conclusion": "研究结果表明，LLMs可以利用数据集的元数据推荐而不需进行搜索的模型和超参数，并且元信息提示的改进展示了其进行上下文条件元学习的潜力。这些结果为LLMs作为轻量级、通用的模型选择和超参数优化助手的角色打开了新的前景。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26607", "html_url": "https://arxiv.org/abs/2510.26607", "title": "基于Bernstein基的Wasserstein回归作为概率轨迹的变分近似", "title_en": "Wasserstein Regression as a Variational Approximation of Probabilistic Trajectories through the Bernstein Basis", "authors": "Maksim Maslov,Alexander Kugaevskikh,Matthew Ivanov", "background": "本文考虑了概率分布上的回归问题，这在机器学习中变得越来越重要。现有方法通常忽略了概率空间的几何性或计算成本高昂。", "innovation": "提出了一种新方法，结合了使用Bernstein基参数化概率轨迹和最小化分布之间的Wasserstein距离。模型将条件分布建模为由输入变量构造的加权高斯分量的权重之和，这些高斯分量的均值和协方差作为输入变量的函数。损失函数是预测的高斯分布与经验数据之间的平均平方Wasserstein距离。通过自定义梯度优化方法训练模型。", "conclusion": "实验结果表明，该方法在平均平方Wasserstein距离、能量距离和RMSE指标方面提供了与现有方法相当或更好的逼近质量，特别是在非线性突出的情况。模型展示了优于或可与替代方法相比的路径平滑性和结构变化的鲁棒性，同时保持了高可解释性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26501", "html_url": "https://arxiv.org/abs/2510.26501", "title": "利用轻量级无监督异常检测滤波器增强ECG分类鲁棒性", "title_en": "Enhancing ECG Classification Robustness with Lightweight Unsupervised Anomaly Detection Filters", "authors": "Mustafa Fuad Rifet Ibrahim,Maurice Meijer,Alexander Schlaefer,Peer Stelldinger", "background": "穿戴设备提供的持续心电图（ECG）监测可以早期检测心血管疾病（CVD），但在资源受限环境中部署深度学习模型进行自动分析时，由于不可避免的异常分布外（OOD）数据会面对可靠性挑战。标准分类器对未见过的病理或噪声信号会产生高置信度的错误预测，影响患者安全。现有OOD检测方法要么忽略计算约束，要么分别处理噪声和未见过的类别。本文探索独立的无监督异常检测（UAD）作为上游过滤机制，以提高鲁棒性。我们评估了六种UAD方法的表现，包括Deep SVDD、重建模型、掩码异常检测、规范化流和扩散模型，这些模型在严格的资源约束下（最多512k参数）通过神经架构搜索（NAS）优化。在PTB-XL和BUT QDB数据集上评估了OOD CVD类别的检测和由于噪声不适合分析的信号。结果显示，Deep SVDD在检测和效率之间取得了最佳平衡。在现实部署模拟中，将优化后的Deep SVDD滤波器集成到诊断分类器中，与仅使用分类器的基线相比，准确率提高了21个百分点。该研究证明优化的UAD滤波器可以保障自动化ECG分析的安全性和可靠性，使穿戴设备上的持续心血管监测更安全、更可靠。", "innovation": "本文探索了无监督异常检测（UAD）作为独立的上游过滤机制，通过神经架构搜索（NAS）优化并评估了六种UAD方法在资源受限环境下的表现。特别强调了Deep SVDD在检测和效率之间的最佳平衡，展示了轻量级UAD滤波器在增强持续ECG监测鲁棒性方面的有效性。通过将优化的UAD滤波器整合到诊断分类器中，显著提高了自动ECG分析的准确性。", "conclusion": "优化的UAD滤波器能够确保自动化ECG分析的安全性和可靠性，使得在穿戴设备上的持续心血管监测更安全、更可靠。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26633", "html_url": "https://arxiv.org/abs/2510.26633", "title": "广泛存在但常被忽视：组合贝叶斯优化中的热核", "title_en": "Omnipresent Yet Overlooked: Heat Kernels in Combinatorial Bayesian Optimization", "authors": "Colin Doumont,Victor Picheny,Viacheslav Borovitskiy,Henry Moss", "background": "贝叶斯优化（BO）在解决材料科学、神经架构搜索等组合任务方面具有巨大潜力。然而，BO在有效建模组合领域方面仍需专业内核。尽管已有多种组合内核被引入，但它们之间的关系并不明确。", "innovation": "我们构建了一个基于热核的统一框架，系统地推导并以简洁的封闭式表达式表示。利用该框架，我们证明了许多成功的组合内核要么与其相关要么等同于热核，并通过实验验证了这一理论主张。我们的分析进一步证实了某些算法性能在函数未知最优点缺乏特定结构时显著下降，同时发现热核对最优点位置不敏感。最后，我们展示了一个基于热核的快速简单管道能够达到最佳效果，甚至在某些情况下优于某些缓慢或复杂的算法。", "conclusion": "我们的工作构建了一种通用框架，能够鉴别和阐述现有组合内核与热核的关系，并验证了热核在避免最优点位置敏感性方面的优势。这表明热核在组合贝叶斯优化中具有显著的应用潜力。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26616", "html_url": "https://arxiv.org/abs/2510.26616", "title": "Aeolus: 多模态飞行延误数据集", "title_en": "Aeolus: A Multi-structural Flight Delay Dataset", "authors": "Lin Xu,Xinyun Yuan,Yuxuan Liang,Suwan Yin,Yuankai Wu", "background": "现有的飞行延误数据集通常局限于平坦的结构化表格，并且无法捕捉延误传播过程中的时空动态。因此，研究人员迫切需要一个能够涵盖多重模态（包括时间序列和图结构）的飞行延误数据集，以支持更加全面的飞行延误预测研究和基础模型的发展。", "innovation": "Aeolus 通过提供三个对齐的模态解决了上述问题：（i）包含丰富的操作、气象和机场级特征的结构化表格数据集，涵盖超过5000万次航班；（ii）飞行链模块，用于建模逐段航班中的延误传播，捕捉上游和下游的依赖性；（iii）飞行网络图，编码共享的飞机、机务和机场资源连接，有助于跨航班的关系推理。此外，Aeolus 通过精心构造的时间分割、全面的特征和严格的泄漏预防，确保了真实且可重复的机器学习评估。", "conclusion": "Aeolus 作为统一的基准跨越表格、序列和图模态，支持广泛的任务，包括回归、分类、时间结构建模和图学习。该数据集还提供了基准实验和预处理工具，以促进其应用。Aeolus 填补了特定领域建模和通用结构数据的空白，并为结构化延迟传播研究提供了强有力的数据支持。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26645", "html_url": "https://arxiv.org/abs/2510.26645", "title": "Curly Flow Matching for Learning Non-gradient Field Dynamics", "title_en": "Curly Flow Matching for Learning Non-gradient Field Dynamics", "authors": "Katarina Petrović,Lazar Atanackovic,Viggo Moro,Kacper Kapuśniak,İsmail İlkan Ceylan,Michael Bronstein,Avishek Joey Bose,Alexander Tong", "background": "自然科学研究中经常需要从个体层面的观测数据建模自然过程的传输动态。现有方法大多基于最小作用原理，通过梯度场动力学使路径在两个概率度量之间最小化能量函数。然而，许多实际系统，如单细胞RNA中的细胞周期，展现出非梯度、周期性的行为，这些行为的捕获目前依靠的流匹配和桥匹配等先进的方法难以实现。", "innovation": "本文提出了Curly Flow Matching (Curly-FM) 方法，通过设计和解决具有非零漂移参考过程的薛定谔桥问题，从而能够学习非梯度场动力学。这一方法不同于传统的零漂移参考过程，使用推断出的速率和人群快照数据构建了参考过程，来解决单细胞、计算流体力学和海洋洋流轨迹推断问题，并展示了Curly-FM 可以更好地匹配参考过程和总体边际。", "conclusion": "Curly-FM 拓展了流匹配模型的应用范围，从人群建模扩展到对物理系统中已知周期行为的建模。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26643", "html_url": "https://arxiv.org/abs/2510.26643", "title": "MSAD: 深入探讨时间序列异常检测中的模型选择", "title_en": "MSAD: A Deep Dive into Model Selection for Time series Anomaly Detection", "authors": "Emmanouil Sylligardos,John Paparrizos,Themis Palpanas,Pierre Senellart,Paul Boniol", "background": "时间序列异常检测是一个基础任务，对下游多个应用的性能有重要影响。尽管学术界对此兴趣浓厚，并有大量方法被提出，但最近的研究表明，没有一种检测方法适用于所有异质时间序列数据集。因此，提出了基于时间序列特性的模型选择方法，以选择最适合不同时间序列的异常检测方法。现有的AutoML解决方案不适用于时间序列异常检测，也没有针对时间序列的方法进行模型选择评价。因此，这项研究评估了用于异常检测的时间序列分类方法的应用效果。评价了总共234种模型配置，覆盖了16种基础分类器，并且是首次对时间序列分类作为异常检测模型选择进行的全面实验评价。", "innovation": "首次全面评估了时间序列分类方法在异常检测模型选择中的应用，展示了模型选择方法在性能上优于单一异常检测方法，且执行时间相当。将时间序列分类算法的准确性与效率首次证明，并提供了一个指导AutoML管道模型选择步骤的基准。", "conclusion": "时间序列分类算法为异常检测提供了准确且高效的解决方案，并构成了一种指导AutoML管道中模型选择步骤的强大基础。这是向证明时间序列分类算法在异常检测中的精准性和效率迈出的第一步。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26690", "html_url": "https://arxiv.org/abs/2510.26690", "title": "LoRAQuant: 混合精度量化LoRA至极低比特", "title_en": "LoRAQuant: Mixed-Precision Quantization of LoRA to Ultra-Low Bits", "authors": "Amir Reza Mirzaei,Yuqiao Wen,Yanshuai Cao,Lili Mou", "background": "低秩适应（LoRA）已经成为在大型语言模型（LLMs）中进行参数有效微调的一种流行技术。在实际应用中，多个适应器通常会同时加载，以实现个性化用户体验或支持多种任务。尽管每个适应器在独立使用时轻量级的，但随着模型规模的增大，它们的总成本也会变得相当大。", "innovation": "我们提出了LoRAQuant，一种针对LoRA的混合精度后训练量化方法。具体来说，LoRAQuant 通过奇异值分解（SVD）重新参数化每个适应器，使其重要的信息集中在特定的行和列上。这样，重要的组件可以被量化为高精度，而其余部分则被量化为超低比特宽。", "conclusion": "通过全面的实验，我们展示了LoRAQuant使用显著低于其他量化方法的比特数量，但在数学推理、编程和总结任务上达到了与之相当甚至更高的性能。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26704", "html_url": "https://arxiv.org/abs/2510.26704", "title": "如何通过正则化项使可逆神经网络成为贝叶斯点估计器", "title_en": "How Regularization Terms Make Invertible Neural Networks Bayesian Point Estimators", "authors": "Nick Heilenkötter", "background": "可逆神经网络因其固有的稳定性和可解释性而在逆问题中具有吸引力。最近，从贝叶斯视角对可逆神经网络的优化策略进行了研究，它们可以近似重建图或前向操作符。然而，这些策略各有局限性。", "innovation": "引入并分析了两种用于网络训练的正则化项，这些正则化项在逆可逆网络后恢复了经典贝叶斯点估计器的属性：第一种与后验均值相关联，第二种类似于最大后验估计（MAP）。", "conclusion": "理论分析解释了每个损失如何塑造所学的前向操作符及其逆重建图。数值实验支持了这些发现，并展示了这些损失项正则化如何以稳定且可解释的方式引入数据依赖性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26714", "html_url": "https://arxiv.org/abs/2510.26714", "title": "仅使用单一训练种子评估机器卸载的局限性", "title_en": "On the limitation of evaluating machine unlearning using only a single training seed", "authors": "Jamie Lanyon,Axel Finke,Petros Andreou,Georgina Cosma", "background": "机器卸载（MU）旨在从训练模型中移除特定数据点的影响，而无需重新培训，这样可以节省成本。大多数实际的MU算法只是近似实现的，其性能只能通过实验来评估。因此，在进行实验比较时，需要谨慎以确保结果具有代表性。一种常见做法是多次独立运行MU算法，每次都从相同的训练模型开始。然而，研究表明即使是对相同的网络架构和数据集，某些MU方法对于模型训练时使用的随机数种子的选择也高度敏感。这可能会导致实验结果不具代表性。", "innovation": "本文揭示了仅使用单一训练种子评估MU算法的局限性，强调了MU方法对随机数种子的高度敏感性。研究建议，在评估MU算法时也应反映不同模型训练种子间的变化性。", "conclusion": "因此，研究结果强调，在评估机器卸载算法时，使用不同模型训练种子对于获得代表性评估结果的重要性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26709", "html_url": "https://arxiv.org/abs/2510.26709", "title": "一种用于高效分布式学习的兼容All-Reduce的Top-K压缩器", "title_en": "An All-Reduce Compatible Top-K Compressor for Communication-Efficient Distributed Learning", "authors": "Chuyan Chen,Chenyang Ma,Zhangxin Li,Yutong He,Yanjie Dong,Kun Yuan", "background": "在大规模分布式机器学习中，通信仍然是主要的瓶颈，而梯度稀疏化已经成为缓解这一挑战的有前途的战略。然而，现有的梯度压缩器存在明显局限性：Rand-K 舍弃结构信息且表现不佳，而 Top-K 保留了有用的信息但失去了收缩性质，并且需要昂贵的 All-Gather 操作。", "innovation": "本文提出了一种名为 ARC-Top-K 的压缩器，它是兼容 All-Reduce 的 Top-K 压缩器，通过使用轻量级的梯度草图对节点中的稀疏模式进行对齐，从而在不使用索引的情况下实现 All-Reduce，同时保留全局显著信息。ARC-Top-K 证明具有收缩性质，并与动量误差反馈（EF21M）结合使用时，在标准假设下，可以实现线性加速和更尖锐的收敛率。", "conclusion": "实验结果表明，ARC-Top-K 在保持与 Top-K 相同的准确率的同时，将训练时间缩短了高达 60.7%，提供了一种高效且可扩展的解决方案，结合了 Rand-K 的稳健性和 Top-K 的强大性能。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26679", "html_url": "https://arxiv.org/abs/2510.26679", "title": "紧致的差分隐私主成分分析方法：基于矩阵共轭", "title_en": "Tight Differentially Private PCA via Matrix Coherence", "authors": "Tommaso d'Orsi,Gleb Novikov", "background": "该论文重新审视了在差分隐私约束下计算矩阵前 $r$ 个奇异向量的跨度的问题。研究界长期以来寻求一种效率高且基于奇异值分解和标准扰动机制的算法，以提供一种具有隐私保护的接近 $r$ 等级的近似，其误差依赖于输入数据的秩-$r$ 共轭和奇异值间隙。这个问题是由 Hardt 和 Roth 在之前的论文中提出的。然而，之前的研究未能在基线性能上有所突破，尤其是在某些场景中，新的算法表现出显著的优势。特别是在稠密矩阵的情况下，文中提出的新方法达到了无隐私算法在 Wishart 模型中一天提出的单峰主成分分析问题的最佳性能保障。此外，论文也证明，基于高斯扰动的估计器不会增强矩阵共轭度，从而确保任何形式基于高斯机制的隐私保护算法都保持输入数据的共轭度。研究者还猜测相似的行为适用于其他结构化模型。", "innovation": "该论文提出了一种新的简单有效的差分隐私算法，不仅在理论证明了其性能优于之前的最佳做法，特别是在稠密矩阵的环境下，且能够达到无隐私算法的最优分析结果。此外，论文还提出了第一个相关行为且不会增加矩阵共轭度的基于高斯机制的估计器。这种机制对于其他结构化模型，如图中的嵌入问题，也能保持共轭度。在应用方面，论文提供了一个在低共轭环境下实现差分隐私的最大割算法和其他约束满足问题的解决方案。", "conclusion": "该论文通过基于矩阵共轭的方法，解决了一个与基于奇异值分解的差分隐私收缩相关的长期问题，并证明了此类方法的有效性和优势。此外，此项研究还带来了对其他相关但结构化模型和更广泛应用领域的见解。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26706", "html_url": "https://arxiv.org/abs/2510.26706", "title": "预算限制下的多专家推诿", "title_en": "Budgeted Multiple-Expert Deferral", "authors": "Giulia DeSalvo,Clara Mohri,Mehryar Mohri,Yutao Zhong", "background": "当前的机器学习系统中，通过学习如何将不确定的预测推诿给昂贵的专家，可以显著提高准确性与效率。但标准的训练方法通常需要对每个训练样本都查询所有专家，这种方式在专家查询产生大量计算或资源成本时变得代价高昂。这违背了推诿的核心目的：限制不必要的专家使用。为解决此问题，引入了预算受限的推诿框架，该框架旨在在减少训练期间专家查询成本的同时，训练有效的推诿算法。", "innovation": "提出了一种新的预算限制下的多专家推诿框架，包括两种策略的算法：两阶段和单阶段。这些算法选择性地只对每个训练样本查询一部分专家，而非所有。虽然灵感来源于主动学习，但这个设定的核心挑战是如何在成本与预测性能之间取得平衡，决定查询哪些专家。同时，提供了这两种算法的理论保证，包括泛化边界和标签复杂度分析。", "conclusion": "在多个领域的实验结果显示，这些算法有效降低了训练成本，同时没有牺牲预测准确性，证明了预算意识的推诿算法的实用价值。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26771", "html_url": "https://arxiv.org/abs/2510.26771", "title": "STaMP: 序列变换和混合精度在低精度激活量化中的应用", "title_en": "STaMP: Sequence Transformation and Mixed Precision for Low-Precision Activation Quantization", "authors": "Marco Federici,Riccardo Del Chiaro,Boris van Breugel,Paul Whatmough,Markus Nagel", "background": "量化是降低生成式AI模型推理延迟、功耗和内存占用的关键方法。然而，当激活量化低于8位时，准确性往往会急剧下降。近期研究表明，可逆线性变换（例如旋转）可以通过重新参数化特征通道和权重来帮助量化。本文基于此研究背景。", "innovation": "提出了序列变换和混合精度（STaMP）量化策略。该策略在线性变换维度应用变换，以利用语言和视觉数据中的强烈局部相关性。通过在每个中间激活保持一定数量的高精度token，可以在较低的平均激活位宽下保持模型准确性。", "conclusion": "评估STaMP在最近的LVM和LLM架构中，表明它大幅改善了低位宽激活量化的性能，并补充了现有的激活和权重量化方法，包括最近的功能变换。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26715", "html_url": "https://arxiv.org/abs/2510.26715", "title": "LSM-MS2：连接光谱识别与生物解释的基础模型", "title_en": "LSM-MS2: A Foundation Model Bridging Spectral Identification and Biological Interpretation", "authors": "Gabriel Asher,Devesh Shah,Amy A. Caudy,Luke Ferro,Lea Amar,Ana S. H. Costa,Thomas Patton,Niall O'Connor,Jennifer M. Campbell,Jack Geremia", "background": "目前，绝大多数质谱数据尚未被表征，难以充分挖掘其中的生物和化学信息。近年来，机器学习的进步开始填补这一空白，特别是在串联质谱数据的光谱识别任务上。先前的方法在识别挑战性的同分异构体化合物方面准确率较低，在复杂生物样本中正确识别数量也较少，且在低浓度条件下鲁棒性较差。为了解决这些问题，迫切需要一种全新的方法来改善这些缺陷。", "innovation": "作者提出了一种名为LSM-MS2的新一代大型深度学习基础模型，该模型基于数百万个光谱数据进行训练，以学习化学语义空间。相较于现有方法，LSM-MS2在光谱识别方面取得了最先进的性能，准确率提高了30%（特别是在识别难题同分异构体化合物方面），在复杂生物样本中正确识别的光谱数量增加了42%，在低浓度条件下保持了鲁棒性。这些光谱还生成了丰富的光谱嵌入，可以直接进行生物解释，且无需进一步的数据处理。LSM-MS2成功地区分了不同疾病的病理状态并预测了临床结果，广泛应用于多种跨越不同转化领域的内容。", "conclusion": "LSM-MS2在光谱识别方面取得了非常显著的进展，不仅在准确性和鲁棒性上优于现有方法，还能够直接对生物数据进行解释，为多种转化医学应用提供了新的可能性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26745", "html_url": "https://arxiv.org/abs/2510.26745", "title": "深层序列模型倾向于记忆几何结构；尚不清楚其中原因", "title_en": "Deep sequence models tend to memorize geometrically; it is unclear why", "authors": "Shahriar Noroozizadeh,Vaishnavh Nagarajan,Elan Rosenfeld,Sanjiv Kumar", "background": "在序列建模中，原子事实的参数记忆通常是通过实体共现之间的笨拙查找来抽象的。本文提出了与这种关联视角相反的几何视角，认为记忆不仅仅是存储训练中指定的局部共现。文章通过隔离一个与传统记忆存储方式不兼容的Transformer推理实例，展示了模型在推理过程中实际上综合了一种几何结构，编码了所有实体之间的全局关系，并将复杂的多重组合任务简化为易于学习的几何任务。尽管优化目标仅仅是局部关联，但文章提出，这种几何结构的形成仍然难以直接归因于常见的架构或优化压力。通过对Node2Vec的分析，文章进一步指出了这种几何倾向形成的根源，并建议研究人员在知识获取、容量、发现和遗忘等方面重新思考默认直觉，以促进Transformer记忆的几何特性增强。", "innovation": "文章提出了一种与传统记忆存储方式不同的几何视角，展示了Transformer模型在推理过程中如何通过合成一种几何结构来编码实体之间的全局关系。这种几何结构使得模型能够将复杂的任务简化为易于学习的几何任务，尽管优化目标仅仅是局部关联。通过分析Node2Vec，文章揭示了这种几何结构形成的原因，并为增强Transformer的记忆几何特性提供了方向。", "conclusion": "文章强调，尽管神经嵌入的几何结构可以优化基于局部关联的目标，但这种结构的形成仍然难以直接归因于常见的架构或优化压力。这种几何结构的观察鼓励研究人员重新审视默认直觉，通过几何视角指导知识获取、容量、发现和遗忘等方面的探索。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26782", "html_url": "https://arxiv.org/abs/2510.26782", "title": "使用几何正则化世界模型复制确定性3D世界", "title_en": "Clone Deterministic 3D Worlds with Geometrically-Regularized World Models", "authors": "Zaishuo Xia,Yukuan Lu,Xinyi Li,Yifan Xu,Yubei Chen", "background": "世界模型是一种内部模型，可以模拟世界如何演变。基于过去的观察和行为，它可以预测代理和环境的未来。准确的世界模型对于使代理能够在复杂、动态的环境中进行有效思考、规划和推理至关重要。尽管取得了快速进步，当前的模型在长时预测上仍然脆弱并会退化。", "innovation": "作者提出了一种新的世界模型 Geometrically-Regularized World Models (GRWM)，这是一种通过几何正则化确保连续感官轨迹中的点在潜在表示空间中保持接近，从而生成更优的潜在表示的方法。这种方法既适用于确定性的3D环境，又适用于长期预测任务，显著提升了轨迹一致性与稳定性，并且潜在生成模块的架构修改非常小，可与其他模块兼容。", "conclusion": "改进表示学习是获得鲁棒性世界模型并能够进行准确长期预测的直接有效路径，无需扩大动态模块的规模。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26722", "html_url": "https://arxiv.org/abs/2510.26722", "title": "非凸的异质无线联邦学习：偏差-方差权衡", "title_en": "Non-Convex Over-the-Air Heterogeneous Federated Learning: A Bias-Variance Trade-off", "authors": "Muhammad Faraz Ul Abrar,Nicolò Michelusi", "background": "空中（OTA）联邦学习（FL）被广泛认为是一种扩展性较好的方法，通过无线多址信道中的波形叠加来在一跳内聚合模型更新。现有OTA-FL设计主要通过假设一致的无线条件（设备间相同的路径损耗）或强制零偏差更新以确保收敛来进行。在不同的无线场景下，这种方法受到最弱设备的限制，并增加了更新的方差。此外，先前对有偏OTA-FL的研究主要关注凸目标函数，而现代大多数AI模型是非凸的。鉴于这些缺口，该研究探讨了在无线异构场景下使用随机梯度下降（SGD）的一般平滑非凸目标函数下的OTA-FL。", "innovation": "本研究开发了基于SGD的一系列新颖的OTA-FL更新，这些更新允许具有结构化且时间不变的模型偏差，同时减少了更新的方差。研究还推导出有限时间的稳态界（预期时间平均平方梯度范数），明确揭示了偏差和方差之间的权衡，并提出了一个非凸联合OTA功率控制设计，以及仅需基站统计CSI的高效递归凸逼近（SCA）算法，以优化这一权衡。实验结果显示，基于SCA的设计通过优化偏差加速收敛，并在非凸图像分类任务中优于之前的方法，提高了泛化能力。", "conclusion": "本研究深入探讨了OTAF fed-learning在不一致无线环境下的应用，并提出了新的基于SGD的更新方案和优化算法，同时证明了这种设计的有效性和优越性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26777", "html_url": "https://arxiv.org/abs/2510.26777", "title": "预训练预测模型：强有力的零样本特征抽取器用于时间序列分类", "title_en": "Pre-trained Forecasting Models: Strong Zero-Shot Feature Extractors for Time Series Classification", "authors": "Andreas Auer,Daniel Klotz,Sebastinan Böck,Sepp Hochreiter", "background": "近期对时间序列基础模型的研究主要集中在预测上，这使得人们对它们学到的表示是否具有普适性存有疑问。这项研究旨在探讨冻结预训练预测模型是否能为分类任务提供有效的表示，并对比不同的表示提取策略，引入两种模型无关的嵌入增强方法，进一步证实了这种假设。实验结果表明，最佳预测模型的分类准确度与专门预训练用于分类的模型相当甚至更好，并且发现预测性能与分类性能之间存在正相关关系。这些发现挑战了特定任务预训练必要的假设，表明学习预测可能成为构建通用时间序列基础模型的强大途径。", "innovation": "本研究的主要创新点在于提出了将冻结的预训练预测模型作为时间序列分类的有效特征提取器，并通过引入两种模型无关的嵌入增强方法，进一步提高了预测和分类的性能，同时观察到了两者之间的正相关性。", "conclusion": "最佳预训练预测模型的分类性能达到了甚至超过了专门针对分类预训练的模型，这表明预训练预测模型具有广泛的适应性。预训练预测模型可能为构建通用的时间序列基础模型提供了一条有力的途径，挑战了特定任务预训练的必要性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26776", "html_url": "https://arxiv.org/abs/2510.26776", "title": "通过高级采样实现 Faithful 和快速影响函数", "title_en": "Faithful and Fast Influence Function via Advanced Sampling", "authors": "Jungyeon Koh,Hyeonsu Lyu,Jonggyu Jang,Hyun Jong Yang", "background": "影响函数(IFs)是一种解释黑盒模型受训练数据影响的方法，通过使用梯度和海森矩阵。然而，计算整个数据集的海森矩阵资源密集，因此需要一种可行的替代方案。常用的方法是随机采样一小部分训练数据，但这种方法会导致IF估计高度不一致，因为样本配置的高方差。", "innovation": "本文提出了两种基于特征和logits的高级采样技术，通过考虑特征或logits的随机分布来选择一小部分具有代表性的整个数据集，从而提高IF估计的准确性。该方法将计算时间减少了30.1%，内存使用减少了42.2%，或者相比于基线提高了2.5%的F1分数。", "conclusion": "通过采用这两种基于特征和logits的高级采样技术，本文提出的方法能够有效地减少计算时间和内存使用，同时提高影响函数估计的准确性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26788", "html_url": "https://arxiv.org/abs/2510.26788", "title": "通过FP16击败训练与推理不匹配", "title_en": "Defeating the Training-Inference Mismatch via FP16", "authors": "Penghui Qi,Zichen Liu,Xiangxin Zhou,Tianyu Pang,Chao Du,Wee Sun Lee,Min Lin", "background": "在利用强化学习（RL）对大型语言模型（LLMs）进行微调时，微调与推理过程之间的数值不匹配导致了不稳定性。尽管先前的研究通过算法修正或工程对齐尝试缓解这一问题，但本文指出根本原因在于浮点精度本身。尽管广泛采用的BF16具有较大的动态范围，但它引入了较大的舍入误差，破坏了训练与推理之间的一致性。", "innovation": "本文展示了简单地回退到FP16能够有效消除这种不匹配。这种变化简单，仅需少量代码更改就可得到现代框架支持，且无需修改模型架构或学习算法。实验证明，使用FP16带来了更稳定、更快收敛和更强的跨任务、算法和框架性能。", "conclusion": "本文的结果表明，统一使用FP16在RL微调中能够带来更稳定、更快收敛和更强的性能。我们希望这些发现能够促使更广泛地重新考虑精度权衡问题。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26787", "html_url": "https://arxiv.org/abs/2510.26787", "title": "远程劳动力指数：衡量AI对远程工作的自动化", "title_en": "Remote Labor Index: Measuring AI Automation of Remote Work", "authors": "Mantas Mazeika,Alice Gatti,Cristina Menghini,Udari Madhushani Sehwag,Shivam Singhal,Yury Orlovskiy,Steven Basart,Manasi Sharma,Denis Peskoff,Elaine Lau,Jaehyuk Lim,Lachlan Carroll,Alice Blair,Vinaya Sivakumar,Sumana Basu,Brad Kenstler,Yuntao Ma,Julian Michael,Xiaoke Li,Oliver Ingebretsen,Aditya Mehta,Jean Mottola,John Teichmann,Kevin Yu,Zaina Shaik,Adam Khoja,Richard Ren,Jason Hausenloy,Long Phan,Ye Htet,Ankit Aich,Tahseen Rabbani,Vivswan Shah,Andriy Novykov,Felix Binder,Kirill Chugunov,Luis Ramirez,Matias Geralnik,Hernán Mesura,Dean Lee,Ed-Yeremai Hernandez Cardona,Annette Diamond,Summer Yue,Alexandr Wang,Bing Liu,Ernesto Hernandez,Dan Hendrycks", "background": "人工智能在知识和推理的研究基准上取得了快速进展，但这些进展如何转化为经济价值和自动化仍不明确。本文提出了一种新的基准——远程劳动力指数（RLI），用于衡量AI自动化在实际工作环境中的表现，并为AI在劳动自动化领域的实际影响提供可信数据，帮助利益相关者提前应对AI驱动的劳动力自动化所带来的影响。", "innovation": "引入了远程劳动力指数（RLI），这是一种包含真实世界、经济上有价值的项目的广泛多行业基准，旨在评估AI代理在实际应用场景中的端到端表现。这项研究显示，AI在RLI上的表现接近最低标准，最高表现的AI代理的自动化率仅为2.5%。这种方法有助于通过实证数据加强关于AI自动化的讨论，并为跟踪AI影响提供一个共同的基础，从而帮助利益相关者积极应对AI驱动的劳动力自动化变革", "conclusion": "结果表明，AI在RLI上的表现较低，最高绩效的AI代理的自动化率为2.5%，这有助于实证支持关于AI自动化讨论，并为AI在劳动领域的有效性设定一个共同的基准。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.24736", "html_url": "https://arxiv.org/abs/2510.24736", "title": "RNAGenScape：基于流形拉angevin动力学的目标特性导向的mRNA序列优化与插值", "title_en": "RNAGenScape: Property-guided Optimization and Interpolation of mRNA Sequences with Manifold Langevin Dynamics", "authors": "Danqi Liao,Chen Liu,Xingzhi Sun,Dié Tang,Haochen Wang,Scott Youlten,Srikar Krishna Gopinath,Haejeong Lee,Ethan C. Strayer,Antonio J. Giraldez,Smita Krishnaswamy", "background": "mRNA设计和优化在合成生物学和治疗开发中至关重要，但仍然在机器学习领域研究不足。系统优化mRNA受到稀缺且不平衡的数据以及复杂序列功能关系的影响。现有方法无法在数据稀少和未充分采样的情况下系统地优化mRNA，同时仍需确保中间产品接近可行的mRNA流形。", "innovation": "提出了RNAGenScape，一种基于属性的流形拉angevin动力学框架，可以迭代更新mRNA序列，通过一个结构化自动编码器将潜在空间由目标属性组织起来，以实现高效的生物学可信探索，同时通过流形投影器将每次更新的步骤拉回到流形。RNAGenScape 支持目标特性导向的优化和序列之间的平滑插值，同时保证在数据稀少和未充分采样的情况下保持鲁棒性。", "conclusion": "在三个真实mRNA数据集中，RNAGenScape在改善目标属性方面取得了高成功率和高效性，优于专门为蛋白质或其他非生物数据开发的各种生成或优化方法。通过提供连续的数据对齐轨迹，揭示编辑如何影响功能，RNAGenScape建立了可控mRNA设计和mRNA序列建模中潜在空间探索的可扩展范式。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26792", "html_url": "https://arxiv.org/abs/2510.26792", "title": "使用Transformer学习伪随机数：Permuted Congruential生成器、课程学习与可解释性", "title_en": "Learning Pseudorandom Numbers with Transformers: Permuted Congruential Generators, Curricula, and Interpretability", "authors": "Tao Tao,Maissam Barkeshli", "background": "研究发现在广泛使用的伪随机数生成器（PRNGs）中，Prmuted Congruential Generators（PCGs）通过一系列位移、异或操作、旋转和截断等操作增大了隐藏状态的复杂性。现有的经典攻击手段已经不能有效地对付这些复杂性增加的PRNG。本文研究了Transformer模型在这种复杂环境下学习RAM序列的能力，特别是在处理不同PCG变种时的性能。实验表明，即使是输出被裁剪至单比特，Transformer模型也可以精确预测其未见过的序列。此外，在训练时同时呈现多种不同的PRNG可以使得模型学习多个不同的序列结构。", "innovation": "本文创新点在于展示了大模数条件下（最高至2^22）Transformer模型对PCGs生成序列的学习能力，即使输出被裁剪至单比特，模型也能可靠地进行预测。模型在处理不同PRNG时展现了自学习能力，在以大型模数训练时，需要引入较小模数的数据，表明了课程学习的重要性。此外发现了Transformer中的嵌入层出现了位旋转不变簇的现象，这揭示了模型如何从较小模数平滑过渡到较大模数表示方法的一项新现象。", "conclusion": "研究发现在处理PCGs生成的复杂序列时，Transformer模型展现出了显著的学习能力。尽管输出被裁剪，模型仍能进行精确预测。研究还揭示了模型如何从较小模数向较大模数平滑过渡以及多种PRNG的共同学习现象。模型的这种能力可能在未来伪随机数生成和安全领域找到应用，同时也可以为进一步理解Transformer模型的内部机制提供新的线索。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25774", "html_url": "https://arxiv.org/abs/2510.25774", "title": "使用深度学习进行脉冲星检测", "title_en": "Pulsar Detection with Deep Learning", "authors": "Manideep Pendyala", "background": "脉冲星巡天产生数百万个候选体，超出人工检查的能力范围。本文构建了一个深度学习管道，将阵列提取特征与图像诊断结合，应用于 Giant Metrewave 射电望远镜 (GMRT) 数据，生成了约 32,000 个脉冲星候选体。", "innovation": "本文引入了一种结合阵列和图像的诊断信息的深度学习方法，通过改进卷积神经网络架构、正则化、学习率调度和最大范数约束，提高模型的准确率。同时，使用 GAN 对少数类进行增广，提升了对脉冲星的召回率。最终，用生成对抗网络和卷积神经网络结合的方法在独立测试集上达到了 94% 的准确率，且模型轻量级能够支持近实时甄别。结合阵列和图像信息提高了可分离性，适度的生成增强显著提升了少数类的召回率。", "conclusion": "本文的方法对巡天具有通用性，并可扩展应用于高通量设施。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25778", "html_url": "https://arxiv.org/abs/2510.25778", "title": "基于模糊逻辑算法方法的产品实体基于评价的排序分析", "title_en": "Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach: Analysis", "authors": "Pratik N. Kalamkar,Anupama G. Phakatkar", "background": "意见挖掘（情感分析）是研究人们对产品、服务、组织、个人、议题、事件、主题及其属性的看法、情绪和评价的学科。传统的整体词典方法忽略了每个意见的强度，没有区分是非常强烈负面（或正面）、强烈负面（或正面）、中等负面（或正面）以及非常轻微负面（或正面） 和轻微负面（或正面）。", "innovation": "本文提出了一种基于模糊逻辑算法的方法来根据实体和用户查询的倾向性和强度对实体进行排序，并通过将与特定产品相关兴趣方面的意见词汇（如副词、形容词、名词和动词）按粒度级别（非常弱、弱、中等、非常强、强）分类来实现。使用模糊逻辑算法对意见词汇进行分类，并通过句法依赖性解析找到对感兴趣方面词汇的关系。", "conclusion": "本文通过模糊逻辑算法方法和句法依赖性解析来分类与特定方面相关的意见词汇，根据评价为特定方面找到实体评分，并提出了一个新颖的方法来对产品实体进行排序。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25775", "html_url": "https://arxiv.org/abs/2510.25775", "title": "使用SHAP实现国际象棋位置的逐个棋子解释", "title_en": "Towards Piece-by-Piece Explanations for Chess Positions with SHAP", "authors": "Francesco Spinnato", "background": "当代国际象棋引擎能够提供精确但缺乏透明度的评价，通常以百粒米分数的形式表达。虽然这些输出对于决策非常有效，但它们掩盖了单个棋子或模式的具体贡献。本文作者致力于通过将SHAP方法应用到国际象棋分析中，来实现对国际象棋引擎评价的具体归因。这种方法借鉴了经典国际象棋教学中的评估方法，即在心中移除棋子进行位置评估，并结合现代可解释的人工智能技术来实现局部真实且易于理解的解释。该方法为可视化、人类训练和引擎比较打开了新的可能性。作者还发布了相关的代码和数据，以促进未来在可解释的国际象棋AI研究中取得进展。", "innovation": "通过将SHAP方法应用于国际象棋分析中，使国际象棋引擎的评价能够具体归因到棋盘上的特定棋子。这种方法结合了经典国际象棋教学实践和现代可解释的人工智能技术，提供了一种局部真实、易于理解的评价解释方式。此外，作者还发布了相关代码和数据，促进未来的研究工作。", "conclusion": "本文的方法为可视化、人类训练和引擎比较提供了新的可能性，并通过将SHAP方法应用于国际象棋分析中，使引擎的评价结果能够具体归因到棋盘上的特定棋子。这为提高棋手的理解能力和发展更透明的国际象棋AI系统提供了新途径。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25784", "html_url": "https://arxiv.org/abs/2510.25784", "title": "zFLoRA: 零延迟融合低秩适配器", "title_en": "zFLoRA: Zero-Latency Fused Low-Rank Adapters", "authors": "Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee", "background": "随着针对特定任务的适配器在大量语言模型（LLMs）中的部署，这些适配器在推理阶段所需的额外计算量显著增加。通常，这些适配器的参数量不超过基础模型的1%，但在推理阶段带来的额外计算负担可能达到基础模型的2.5倍。本文旨在解决这一问题，减少适配器带来的延迟影响。", "innovation": "文章提出了一种名为zFLoRA的新方法，该方法在保持原有基础模型性能的同时，显著减少了推理阶段的延迟影响。实验证明，zFLoRA与低秩适配器（LoRA）和全量微调（FFT）等方法相比，在不同规模的LLM上提供了更良好的性能。实验涵盖了18个不同任务，包括常识推理、数学推理和总结对话。在NPU（Samsung Galaxy S25+）和GPU（NVIDIA H100）平台上的延迟测量表明，zFLoRA几乎不增加或仅增加微小的延迟负担。", "conclusion": "通过zFLoRA，低秩适配器在保持低延迟的同时也能提供良好的性能表现，尤其是在大型语言模型上表现更为显著。该方法在多个任务中进行了验证，证明了其有效性和广泛适用性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25787", "html_url": "https://arxiv.org/abs/2510.25787", "title": "基于电压依赖突触可塑性的无监督本地学习方法及其在阻变和铁电突触中的应用", "title_en": "Unsupervised local learning based on voltage-dependent synaptic plasticity for resistive and ferroelectric synapses", "authors": "Nikhil Garg,Ismael Balafrej,Joao Henrique Quintino Palhares,Laura Bégon-Lours,Davide Florini,Donato Francesco Falcone,Tommaso Stecconi,Valeria Bragaglia,Bert Jan Offrein,Jean-Michel Portal,Damien Querlioz,Yann Beilliard,Dominique Drouin,Fabien Alibart", "background": "边缘计算设备上部署AI面临的挑战包括能耗和功能方面的问题。这些设备可以通过模仿脑部学习机制来进行实时适应和低能耗操作，而基于纳米尺度阻变存储器的在存计算可能在这一过程中发挥关键作用。本文的研究背景就是解决这些问题，探索适合边缘设备的AI部署方法，特别是在低能耗和实时适应方面。", "innovation": "本文引入了一种新的电压依赖突触可塑性（VDSP）方法，该方法基于Hebb原则实现了无监督和局部学习，无需复杂的脉冲整形电路。该研究创新性地展示了VDSP如何适应不同类型的阻变和铁电突触设备（如TiO₂、HfO₂基金属氧化物纳米丝突触以及HfZrO₄基铁电隧道结突触），并成功应用于基于MNIST的范式识别任务，取得了超83%的高精度表现。此外，研究还评估了设备可变性的影响，并提出了相应的缓解策略。", "conclusion": "通过系统级仿真和实际测试，证实了VDSP方法在各种设备上的可行性，并展示了其在边缘设备上部署AI的巨大潜力。结果表明，即使在存在设备变异性的条件下，VDSP也可实现高达83%的无监督学习准确度，显著提高了AI在边缘计算设备上的应用前景。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25776", "html_url": "https://arxiv.org/abs/2510.25776", "title": "StreetMath: 研究大语言模型的近似行为", "title_en": "StreetMath: Study of LLMs' Approximation Behaviors", "authors": "Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong", "background": "现有大量文献探讨了大语言模型（LLMs）的数学推理能力，尤其是在自回归架构中的精确算术运算性能。然而，LLMs在非正式、快速数学运算中的近似推理能力，尤其是在非自回归解码模型中的表现则较少受到关注。本文通过引入StreetMath基准测试，弥补了这一研究空白，旨在评估模型在现实世界的近似场景中的能力。", "innovation": "本文通过引入StreetMath基准测试，评估不同LLM架构（包括Qwen3-4B-Instruct-2507、Qwen3-4B-Thinking-2507、Dream-v0-Instruct-7B、Falcon-Mamba-7B-Instruct和Mamba-GPT-3B），并使用机制可解释性技术深入了解其内部计算状态。研究发现，尽管LLMs通常试图计算准确值或调用外部工具，但在解决近似任务时，它们仍然使用更多token。实验证明，精确和近似算术操作依赖于大语言模型中的不同神经组件。", "conclusion": "本文表明，大语言模型在需要进行近似推理的环境中，不表现出与人类相同程度的认知吝啬性。尽管模型有时在早期层或步骤中得出正确答案，但在解决近似任务时仍会消耗更多token。实验结果指出，精确和近似算术操作依赖于大语言模型中的不同神经部分。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25802", "html_url": "https://arxiv.org/abs/2510.25802", "title": "Attention Augmented GNN RNN-Attention Models for Advanced Cybersecurity Intrusion Detection", "title_en": "Attention Augmented GNN RNN-Attention Models for Advanced Cybersecurity Intrusion Detection", "authors": "Jayant Biradar,Smit Shah,Tanmay Naik", "background": "本文研究了网络入侵检测能力的提升方法，主要基于现有的UNSW-NB15数据集，该数据集包含了多种网络流量模式，用于提升网络安全性。传统方法如机器学习模型以及单一的深度学习模型存在局限性，需要一种能够综合时空依赖关系和序列分析的新方法来提高检测效率和精确度。文中提到的方法结合了图神经网络（GNNs）、循环神经网络（RNNs）和多头注意力机制，以优化网络安全问题的解决方案，特别是在复杂网络环境中检测高级威胁方面表现出色。", "innovation": "本文提出了一种新颖的混合深度学习架构，这种架构结合了图神经网络（GNNs）、循环神经网络（RNNs）和多头注意力机制。通过这种方式，该模型能够同时捕捉空间依赖关系和时间动态性，提供改进的模型可解释性和增强的功能选择优化，帮助网络安全分析师集中资源在高影响的安全事件上。实验结果表明，该混合模型在准确率、精确度、召回率和F1分值等多个评估指标上超过了传统机器学习方法和单个深度学习模型，特别在检测复杂攻击模式如APT、DDoS攻击和零日利用方面表现突出。", "conclusion": "通过广泛实验的评估证明，提出的混合模型在多种网络安全应用场景下表现优异，特别是在现代实时入侵检测系统中，能够有效地识别高风险的安全事件，且特别适用于复杂网络环境中应对复杂的攻击模式。此模型为下一代网络安全应用提供了潜在的解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26007", "html_url": "https://arxiv.org/abs/2510.26007", "title": "追求负责任人工智能的可靠指标", "title_en": "The Quest for Reliable Metrics of Responsible AI", "authors": "Theresia Veronika Rampisela,Maria Maistro,Tuukka Ruotsalo,Christina Lioma", "background": "人工智能（AI）的发展，尤其是在科学中的应用（AIS），应当遵循负责任AI的原则。虽然负责性AI的进步通常通过评价指标来衡量，但很少有人工智能评价指标本身的鲁棒性和可靠性进行评估。", "innovation": "本文总结了此前关于推荐系统公平性指标鲁棒性的研究，提炼出非详尽的指导原则，以帮助开发可靠的负责任AI评价指标。这些原则适用于广泛的AI应用，包括AIS。", "conclusion": "本文提出了一套开发负责任AI评价指标的非详尽指导原则，旨在增强这些评价指标的可靠性和鲁棒性，从而更好地服务于AI的广泛应用和发展。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25974", "html_url": "https://arxiv.org/abs/2510.25974", "title": "在实现机器学习目标变量过程中的人类-机器协作的风险与机遇", "title_en": "Risks and Opportunities in Human-Machine Teaming in Operationalizing Machine Learning Target Variables", "authors": "Mengtian Guo,David Gotz,Yue Wang", "background": "预测建模能够增强人类决策过程，但在实际应用中，当预测目标是需要定义代理变量来操作化研究概念的抽象概念时，许多模型会失败。选择合适的代理变量并不总是显而易见的，需要领域知识和迭代的数据建模。该过程是合作性的，涉及领域专家和数据科学家。因此，研究探讨人类-机器协作如何通过加速迭代过程同时保留人类判断来支持这一过程。", "innovation": "研究探讨了两种人类-机器协作策略对代理变量构建的影响：1) 相关性优先：人类主导过程，选择相关的代理变量；2) 性能优先：机器主导过程，基于预测性能推荐代理变量。通过一项受控的用户研究（N=20），展示了性能导向的策略可以加快迭代和决策，但同时也可能导致用户偏向上与应用目标不一致的高性能代理变量。", "conclusion": "研究强调了人类-机器协作在实现机器学习目标变量过程中的机遇与风险，为未来的研究提供了探索机会和缓解风险的见解。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25947", "html_url": "https://arxiv.org/abs/2510.25947", "title": "重审语言模型预训练中的多语言数据混合", "title_en": "Revisiting Multilingual Data Mixtures in Language Model Pretraining", "authors": "Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut", "background": "关于大规模语言模型（LLMs）预训练过程中多种语言数据混合的影响一直存在争议，通常会引起关于语言覆盖面和模型性能之间潜在权衡的担忧（即，多语言的诅咒）。", "innovation": "本研究通过使用25种到400种语言的多样多语言语料库训练1.1B和3B参数的语言模型，挑战了有关多语言训练的常见观点。发现结合英语和多语言数据并不会必然削弱两种语言的各自表现，只要这些语言在预训练语料库中有足够的词汇量。使用英语作为中介语言（即，一种高资源语言，用于促进多语言泛化的催化剂）在各个语言家族中均表现出优势，且从特定家族中选择中介语言并不一致地提高该家族内语言的表现。未发现随着训练语言数量的增加，大规模模型表现出“多语言的诅咒”。这意味着，适当平衡的多语言数据可以在低资源环境中增强语言模型能力，而不牺牲性能。", "conclusion": "适量的多语言数据可以增强语言模型的能力，而不会损害其在语言任务上的表现，即使在资源较少的语言环境中也是如此。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26020", "html_url": "https://arxiv.org/abs/2510.26020", "title": "PORTool：带有奖励树的工具使用LLM训练", "title_en": "PORTool: Tool-Use LLM Training with Rewarded Tree", "authors": "Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao", "background": "当前的大语言模型（LLMs）被训练在静态数据集上，能够与外部工具互动并进行多步骤、工具集成推理，生成工具调用轨迹。然而，这些模型模仿了通用工具调用过程如何解决查询的方式，未能探索可能的解决方案，在进化的动态工具调用环境中表现出色有限。", "innovation": "提出了一种基于强化学习（RL）的方法PORTool，鼓励工具使用LLM探索多种生成正确答案的轨迹。方法包括生成多个给定查询的轨迹，基于其生成正确答案和成功调用工具的能力对每个步骤进行奖励。共享步骤在不同轨迹中获得相同的奖励，而相同分叉下的不同步骤获得不同的奖励。最终利用这些步骤奖励计算分叉相对优势和轨迹相对优势来训练LLM进行工具使用。", "conclusion": "实验使用17个工具来处理用户查询，涵盖了时间敏感和时间不变的主题。进行消融研究，系统地验证了步骤奖励的必要性和设计稳健性。并将所提出的PORTool与其他训练方法进行比较，显示出最终准确性和工具调用步骤数的显著改进。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26008", "html_url": "https://arxiv.org/abs/2510.26008", "title": "通过硬件遥测检测机器学习基础设施中的异常", "title_en": "Detecting Anomalies in Machine Learning Infrastructure via Hardware Telemetry", "authors": "Ziji Chen,Steven Chien,Peng Qian,Noa Zilberman", "background": "现代机器学习已发展成为紧密耦合的完整生态系统，结合了硬件、软件、网络和应用程序。许多用户依赖云提供商获得弹性的、隔离的和成本效益高的资源。然而，这些平台即服务使用虚拟化，这意味着操作者对用户的工作负载知之甚少，这妨碍了操作者进行必要的资源优化，以确保成本效益并最小化执行时间。", "innovation": "我们提出工作负载知识对于系统级优化是不必要的。System-X采用一种以硬件为中心的方法，仅依赖硬件信号——这些信号完全可由操作者访问。通过使用来自系统的低级信号，System-X通过无监督学习管道检测异常。该管道通过分析超过30个流行机器学习模型在各种硬件平台上的表现来开发，确保适应新兴工作负载和未知部署模式。使用System-X成功地识别了网络和系统配置问题，使DeepSeek模型加速了5.97%。", "conclusion": "System-X通过仅依赖硬件信号并使用低级信号检测异常，无需了解工作负载即可进行系统级优化，并证明了其有效性，能够有效提高机器学习模型的执行效率。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26026", "html_url": "https://arxiv.org/abs/2510.26026", "title": "超越视野的统一预测：基于经验回放的时间感知分布无假设策略评估的置信区间", "title_en": "Conformal Prediction Beyond the Horizon: Distribution-Free Inference for Policy Evaluation", "authors": "Feichen Gan,Youcun Lu,Yingying Zhang,Yukun Liu", "background": "在高风险环境中，可靠的不确定性量化对于强化学习（RL）至关重要。现有的RL方法在策略评估中往往难以处理不受观察的回报、时序依赖性和分布偏移等问题，特别是对于无限时间范围的策略评估。因此，需要一种能够统一处理这些挑战的框架，以提高策略评估的可靠性和覆盖范围，从而在政策转换的情况下提供准确的不确定性度量。", "innovation": "提出了一种统一的置信区间估计框架，结合了分布性RL与校准修正，设计了一种基于截断卷出的模块化伪回报构造方法和一种基于经验回放和加权子采样的时间敏感校准策略。这些创新解决了模型偏差问题，恢复了近似互换性，即使在政策转换的情况下也能提供准确的不确定性量化。理论分析提供了考虑到模型偏差和重要性权重估计的覆盖率保证。实验结果表明，与标准的分布性RL基线相比，该方法显著提高了覆盖率和可靠性。", "conclusion": "本研究提出的方法在合成和基准环境中，特别是在Mountain Car环境中，通过基于经验回放的时间感知分布无假设策略评估置信区间的策略评估方法，显著提高了覆盖率和可靠性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25992", "html_url": "https://arxiv.org/abs/2510.25992", "title": "监督强化学习：从专家轨迹到逐步推理", "title_en": "Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning", "authors": "Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee", "background": "大型语言模型（LLMs）在需要多步推理的问题上经常表现不佳。对于小型开源模型而言，使用可验证奖励的强化学习（RLVR）常常由于正确解决方案难以被采样而失败，即便尝试多次。监督微调（SFT）则倾向于过度拟合长示例，并通过逐词模仿产生僵化的推理。这些方法都存在一定的局限性，需要新的方法来弥补。", "innovation": "本文提出了监督强化学习（SRL）框架，将问题求解表述为生成一系列逻辑“动作”的序列。SRL通过生成模型内部的逻辑解释来指导最终动作的选择，并根据与专家行为的逐步相似性来提供更平滑的奖励。这种监督不仅在所有尝试都不正确的情况下也能提供丰富的学习信号，还促进了通过专家示例指导的灵活推理。SRL使小模型能够学习此前通过SFT或RLVR无法解决的复杂问题，并且在训练初期使用SRL再通过RLVR精调，整体表现出最优的效果。", "conclusion": "SRL不仅有效应用于推理基准测试，还能够成功泛化到自主软件工程任务，证明其是适用于以推理为中心的LLMs的有效且通用的训练框架。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25979", "html_url": "https://arxiv.org/abs/2510.25979", "title": "AttnCache：利用注意力缓存加速LLM预填充阶段的自注意力推理", "title_en": "AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache", "authors": "Dinghong Song(1),Yuan Feng(1),Yiwei Wang(1),Shangye Chen(1),Cyril Guyot(2),Filip Blagojevic(2),Hyeran Jeon(1),Pengfei Su(1),Dong Li(1) ((1) University of California, Merced, USA, (2) Western Digital Research, USA)", "background": "大型语言模型（LLMs）在生成应用方面得到广泛应用，包括聊天、代码生成和推理等。然而，许多实际应用如分类、问答、推荐和文本嵌入主要依赖于模型的预填充阶段，即模型仅编码输入序列而不进行自回归解码。这一过程中的主要性能瓶颈是自注意力计算，因为其复杂度与序列长度成平方关系。文章指出，在这种仅预填充的场景中，不同语义的句子常常产生相似的注意力图。", "innovation": "基于对不同语义句子仍可能产生相似注意力图的观察，提出了AttnCache框架。该框架通过检索和重复利用相似的注意力图来加速LLM预填充阶段的自注意力推理。AttnCache依靠注意力图记忆数据库，利用高效的缓存和相似性搜索技术，在推理过程中识别并重复使用预先缓存的注意力图，从而降低自注意力的计算开销。", "conclusion": "实验结果显示，AttnCache在CPU上实现了平均1.2倍的端到端速度提升和2倍的注意力加速，在GPU上实现了1.6倍的端到端速度提升和3倍的注意力加速，且无显著的准确性降低。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.25982", "html_url": "https://arxiv.org/abs/2510.25982", "title": "通过图像去噪实现快速而准确的中性原子读出", "title_en": "Enabling Fast and Accurate Neutral Atom Readout through Image Denoising", "authors": "Chaithanya Naik Mude,Linipun Phuttitarn,Satvik Maurya,Kunal Sinha,Mark Saffman,Swamit Tannu", "background": "中性原子量子计算机有望扩展到数十万个量子位，但其进度受限于慢速的量子比特读出。当前的读出时间需要数毫秒，远长于基本的量子门操作时间，这使得读出成为部署量子纠错的主要瓶颈。每一轮量子纠错都依赖于测量，而长时间的读出增加了循环时间并减缓了程序执行速度。尽管缩短读出时间可以加速循环并减少量子位闲置时积累的退相干错误，但这也降低了收集到的光子数量，导致测量更加嘈杂且容易出错。这种权衡使得中性原子系统处于慢速但准确读出和快速但不可靠读出之间.", "innovation": "本文提出了一种基于图像去噪的框架GANDALF，通过图像平移进行明确的降噪以从短低光子数测量中重构清晰信号，使可靠的分类能够在读出时间缩短1.6倍的情况下实现。结合轻量级分类器和流水线读出设计，该方法将逻辑错误率最多降低35倍，并将整体量子纠错周期时间缩短1.77倍，相较于基于CNN的读出方法，特别是在铯（Cs）中性原子阵列中实现了这一目标.", "conclusion": "这篇文章展示了通过图像去噪可以解决中性原子系统中的这个困境。使用GANDALF框架，可以实现快速而准确的读出，同时提高量子纠错的效率和减少逻辑错误率。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26043", "html_url": "https://arxiv.org/abs/2510.26043", "title": "L_1-范数正则化的非确定核逻辑回归", "title_en": "$L_1$-norm Regularized Indefinite Kernel Logistic Regression", "authors": "Shaoxin Wang,Hanjing Yao", "background": "核逻辑回归（KLR）是一种在多种领域广泛应用的强大分类方法。在许多现实场景中，非确定核比正定核更能捕捉特定领域的结构性信息。", "innovation": "提出了新型的通过L1-范数正则化来引入稀疏性的非确定核逻辑回归（RIKLR）模型，此模型扩展了现有的IKLR框架。为了应对正则化引入的非光滑性和非凸性问题，开发了一种理论依据充分且计算效率高的近似线性化算法。", "conclusion": "在多个基准数据集上的实验结果表明，所提出的方法在准确性和稀疏性上均表现出优越性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26040", "html_url": "https://arxiv.org/abs/2510.26040", "title": "采用强化学习方法加速F1TENTH赛车中的现实世界超车", "title_en": "Accelerating Real-World Overtaking in F1TENTH Racing Employing Reinforcement Learning Methods", "authors": "Emily Steiner,Daniel van der Spuy,Futian Zhou,Afereti Pama,Minas Liarokapis,Henry Williams", "background": "尽管在时间试验（Time-Trial）场景下的自动驾驶赛车性能取得了显著进步，但在车辆对车辆的自动驾驶比赛和超车能力方面仍然受到严重限制。特别是在真实驾驶情景中，最先进的算法难以安全地或可靠地完成超车动作。这意味着绕行其他车辆的安全导航对于自动驾驶的轮对轮比赛至关重要。F1Tenth竞标赛提供了在标准化物理平台上开发轮对轮比赛算法的机会，其比赛格式使算法能够与最先进的技术进行对比评估。", "innovation": "本文提出了一种新颖的赛车和超车代理，能够在模拟和实际情况中学习可靠地导航赛道并超越对手。该代理被部署在F1Tenth车辆上，与运行不同竞争性算法的对手在现实世界中进行了比赛。实验结果表明，与仅用于比赛的训练相比，该代理对对手的训练使其能够以87%的超越率实现刻意的超越行为，而仅用于比赛的训练代理的超越率为56%。", "conclusion": "研究证明，通过与对手的训练，代理可以学习并实现可靠的赛场超越行为，这在自动驾驶赛车比赛中尤为重要。采用强化学习方法，代理能够显著提高在现实世界中的比赛中超越对方的几率。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26275", "html_url": "https://arxiv.org/abs/2510.26275", "title": "为增强软件工程流程和软件产品而研究生成式人工智能的作用", "title_en": "A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI", "authors": "Domenico Amalfitano,Andreas Metzger,Marco Autili,Tommaso Fulcini,Tobias Hey,Jan Keim,Patrizio Pelliccione,Vincenzo Scotti,Anne Koziolek,Raffaela Mirandola,Andreas Vogelsang", "background": "生成式人工智能（GenAI）正在迅速变革软件工程（SE）实践，影响SE流程的执行方式，以及软件系统的开发、运营和演化。", "innovation": "该研究应用设计科学方法构建了一个集成多证据来源的GenAI增强SE路线图。通过三轮周期性集成协作讨论、快速文献审查和同行反馈会，系统地捕捉GenAI对SE过程和软件的影响。路线图识别了四种基本形式的GenAI增强，并系统地界定相关研究挑战和机遇，为未来研究提供了方向。研究通过多轮次严格过程并结合独立作者团队和同行的交叉验证，为分析GenAI对SE过程、方法和工具的影响提供了透明且可复制的基础。", "conclusion": "基于这些发现，文章最终做出了关于2030年SE的十个预测。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26307", "html_url": "https://arxiv.org/abs/2510.26307", "title": "关于异构图神经网络在网络安全异常检测中的综述", "title_en": "A Survey of Heterogeneous Graph Neural Networks for Cybersecurity Anomaly Detection", "authors": "Laura Jiang,Reza Ryan,Qian Li,Nasim Ferdosian", "background": "异常检测在网络安全中至关重要，主要用于识别内部威胁、访问违规和协同攻击，以确保系统的弹性。现有的基于图的方法在建模实体交互方面变得越来越重要，但大多数方法依赖于同质性和静态结构，这限制了它们捕捉现实环境中的异质性和时态演化的能力。异构图神经网络（HGNNs）作为一种新的范式，通过类型感知转换和关系敏感聚合来增强复杂网络数据的建模能力，在异常检测中展现出潜力。然而，基于HGNN的异常检测研究目前仍处于起步阶段，缺乏系统化的模型比较与标准化基准数据集，使得该领域难以取得突破性进展。", "innovation": "本文提供了一份全面的HGNN基础的异常检测方法在网络安全中的综述，该综述根据异常类型和图动态对方法进行分类，分析了代表性模型并将其映射到关键的网络安全应用中。此外，还回顾了常用的基准数据集和评估指标，并指出其优缺点。研究确定了模型、数据和部署方面的关键开放挑战，并概述了未来研究的潜在方向，旨在建立一个结构化的基础，推进基于HGNN的异常检测向可扩展、可解释和实际可部署的解决方案发展。", "conclusion": "本文系统地总结了HGNN在网络安全领域中的应用，并指出了研究方向上的关键挑战和潜在的未来研究领域，旨在为基于HGNN的异常检测的进一步发展提供一个框架，并推动其向可扩展、可解释和实际可部署的解决方案的方向前进。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26384", "html_url": "https://arxiv.org/abs/2510.26384", "title": "Scales++: 使用认知尺度嵌入实现计算高效的评估子集选择", "title_en": "Scales++: Compute Efficient Evaluation Subset Selection with Cognitive Scales Embeddings", "authors": "Andrew M. Bean,Nabeel Seedat,Shengzhuang Chen,Jonathan Richard Schwarz", "background": "大规模语言模型（LLMs）全面评估的成本非常高，因此需要创建一些小而具有代表性的数据子集（即，小型基准）来实现高效的评估，并保留预测精度。当前方法基于模型中心的范式，选择基准项依赖现有模型的综合表现。这些方法受制于巨大的前期成本，不能立即处理新的基准（冷启动）问题，并且假设未来的模型会与先前模型的故障模式相似。这项工作中，作者挑战了这种范式，提出了基于项中心的基准子集选择方法，主张选择应基于任务项目的固有属性而非特定于模型的故障模式。", "innovation": "作者提出了一种基于项中心的有效基准选择方法（称为Scales++），其中数据选择基于基准样本的认知需求。Scales++在不显著降低预测精度的情况下，减少了前期选择成本超过18倍。在开源大语言模型排行榜上，仅使用0.5%的数据子集，预测整个基准得分的均绝对误差仅为2.9%。这种方法不仅提高了模型评估的效率，还能更好地处理冷启动问题，提供更可解释的基准测试。", "conclusion": "Scales++通过基于认知尺度嵌入的数据选择方法，实现了高效且可靠的模型评估，解决了传统基于模型中心的方法在成本、冷启动性能和可解释性上的限制。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26274", "html_url": "https://arxiv.org/abs/2510.26274", "title": "PVMark: 使大语言模型水印方案能够公开验证", "title_en": "PVMark: Enabling Public Verifiability for LLM Watermarking Schemes", "authors": "Haohua Duan,Liyao Xiang,Xin Zhang", "background": "大语言模型（LLMs）的水印方案已经提出，用于标识生成文本的来源，以缓解模型盗窃带来的潜在威胁。然而，当前的水印解决方案难以解决信任问题：非公开的水印检测不能忠实地执行其检测功能。研究发现，这一问题主要源于水印检测中使用的密钥——其不能公开，否则对手可能会利用密钥发起删除攻击；也不能私人持有，否则水印检测对公众是不透明的。为解决这一难题，本文提出了一种基于零知识证明（ZKP）的插件PVMark，通过零知识证明使得水印检测过程可以由第三方公开验证而不泄露任何密钥信息。", "innovation": "PVMark利用零知识证明构建关于水印检测‘正确执行’的证明，包括偏移映射、随机数生成、比较和求和等一系列约束条件。通过在Python、Rust和Circom等编程语言中实现多个PVMark变体，并结合三种水印方案、三种哈希函数和四种ZKP协议，展示了该方法在不同场景下均能有效工作，且不会牺牲水印性能。PVMark旨在实际部署中能够实现大语言模型水印方案的有效公开验证。", "conclusion": "实验结果显示，PVMark有效实现了最新的大语言模型水印方案的公开验证，且不牺牲水印性能，为今后的实际应用提供了可能性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26340", "html_url": "https://arxiv.org/abs/2510.26340", "title": "SABER: 基于符号回归的到达角和波束图估算器", "title_en": "SABER: Symbolic Regression-based Angle of Arrival and Beam Pattern Estimator", "authors": "Shih-Kai Chou,Mengran Zhao,Cheng-Nan Hu,Kuang-Chung Chou,Carolina Fortuna,Jernej Hribar", "background": "准确的角度-of-到达（AoA）估算对于下一代无线通信系统实现可靠波束成形、高精度定位和集成感测至关重要。然而，经典的高分辨率技术需要多元件阵列和大量的快照采集，而通用的机器学习（ML）方法往往会生成黑盒模型，缺乏物理可解释性。本研究提出了基于符号回归（Symbolic Regression，SR）的ML框架，SABER，这是一种包含约束的符号回归框架，可以自动从路径损耗测量中发现闭合形式的波束图和AoA模型，并具备解释性。", "innovation": "SABER通过将隐藏在黑盒ML方法中的复杂公式转化为具有解释性的闭合形式模型，解决了传统技术和ML方法的局限性。在受控的自由空间声学屏蔽室内通过直接反演已知的$\text{cos}^n$波束和低阶多项式近似验证方法的准确性，实验证实了SABER的高精度。并在一个基于可重构智能表面(RIS)的室内测试环境中展示了SABER和无约束SR模型的精确性。最后与Cramér-Rao下界（CRLBs）进行了基准测试，说明SABER是一种对于AoA估算既具有解释性又准确的黑盒ML方法的替代方案。", "conclusion": "本研究提出了一种基于符号回归的ML框架，即SABER，该框架能够从路径损耗测量中自动发现具有解释性的闭合形式的AoA和波束图模型，证明了SABER在AoA估算中的高准确性和解释性，是一种替代当前最先进的黑盒ML方法的可行方案。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26402", "html_url": "https://arxiv.org/abs/2510.26402", "title": "Autograder+: 多维度AI框架在编程教育中的丰富教学反馈", "title_en": "Autograder+: A Multi-Faceted AI Framework for Rich Pedagogical Feedback in Programming Education", "authors": "Vikrant Sahu,Gagan Raj Gupta,Raghav Borikar,Nitin Mane", "background": "编程教育的快速发展超出了传统评估工具的能力范围，使得教师在提供有意义和可扩展的反馈方面资源有限。传统的自动化评分系统虽然效率高，但更像是黑盒系统，仅仅提供通过或未通过的结果，缺乏对学生思考过程和学习需求的洞察力。", "innovation": "Autograder+设计旨在将自动化评分从单纯的总结性过程转变为促进性学习体验。它引入了两个关键功能：使用微调的大语言模型自动生成反馈，以及可视化学生的代码提交来揭示学习模式。模型通过有选择地利用学生代码和专家反馈进行微调，确保提供与教育目标相一致、上下文相关的指导。该系统在600名学生的多次编程任务提交中生成的反馈与教师评论在语义上具有很强的对齐性。对于可视化部分，对比学习训练出的代码嵌入根据功能和方法对1000个注释提交进行分组，使解决方案得以有意义地聚类。该系统还支持提示池化，允许教师通过选择的提示模板引导反馈风格。", "conclusion": "通过结合AI驱动的反馈、语义聚类和交互式可视化，Autograder+减轻了教师的工作量，同时支持有针对性的教学，促进了更强的学习成果。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26285", "html_url": "https://arxiv.org/abs/2510.26285", "title": "探索语言模型处理数字的机制", "title_en": "Unravelling the Mechanisms of Manipulating Numbers in Language Models", "authors": "Michal Štefánik,Timothee Mickus,Marek Kadlčík,Bertram Højer,Michal Spiegel,Raúl Vázquez,Aman Sinha,Josef Kuchař,Philipp Mondorf", "background": "最近的研究表明，不同的大型语言模型（LLMs）在处理数字时表现出类似的精确输入嵌入表示。然而，这些发现与LLMs在处理数值信息时易于产生错误输出的现象相矛盾。这项工作旨在解释这种矛盾，探索语言模型如何处理数字，并量化这些机制的精确度下限。研究表明，尽管存在表面错误，不同的语言模型仍学习到系统化的、高度准确且跨隐藏状态和输入上下文具有通用性的数字表示。这使得我们可以为每个LLM创建通用探针，并跟踪包括误差原因在内的信息到特定层。这些结果为理解预训练LLMs如何处理数字提供了基础性认识，并概述了更准确探针技术在LLMs架构改进方面的潜力。", "innovation": "该研究发现了不同语言模型在处理数字时学习到的通用性、系统化且高度精确的表示方法，即使存在表面错误。此外，该研究还提出了通用探针方法，并能追踪语言模型中的错误信息到特定层，为理解语言模型如何处理数字提供了新的视角，同时也为改进语言模型架构提供了可能手段。", "conclusion": "研究结果揭示了预训练的LLMs在处理数字时的底层机制，并指出了更准确探针技术在改进LLMs架构方面的重要潜力。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26345", "html_url": "https://arxiv.org/abs/2510.26345", "title": "MisSynth: 使用合成数据提高MISSCI谬误分类", "title_en": "MisSynth: Improving MISSCI Logical Fallacies Classification with Synthetic Data", "authors": "Mykhailo Poliakov,Nadiya Shvai", "background": "健康相关的虚假信息普遍存在且可能带来危害。由于这些信息常会曲解或错误诠释科学研究的结果，难以识别。本研究旨在探讨合成数据生成技术和轻量级微调技术对大型语言模型（LLMs）识别谬误论证能力的影响，使用MISSCI数据集及相关框架进行评估。研究表明，通过合成谬误样本微调的模型较基准模型有显著的准确率提升，尤其是与 Limited Computational Resources 主动但限制注释资源增强的零样本任务分类性能。", "innovation": "通过应用检索增强生成（RAG）技术生成合成谬误样本，然后对大型语言模型进行微调，提出了一种名为MisSynth的方法。实验结果表明，微调后的模型在MISSCI测试子集上实现了超过35%的F1分数绝对提升。合成谬误数据的引入不仅能显著提高真实的科学虚假信息任务的零样本分类性能，还能在计算资源有限的情况下发挥重要作用。这为大数据集的主动利用和改进预训练模型的性能提供了一种有效手段。", "conclusion": "引入合成谬误数据可显著增强零样本大型语言模型在真实世界科学虚假信息任务中的分类性能，即使在计算资源有限的情况下也是如此。通过MisSynth提出的合成数据生成和轻量级微调技术，这些模型能够实现显著的性能提升，这为进一步研究和解决科学领域中的虚假信息问题提供了新的思路。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26466", "html_url": "https://arxiv.org/abs/2510.26466", "title": "基于表示级别的反事实校准用于公正的零样本识别", "title_en": "Representation-Level Counterfactual Calibration for Debiased Zero-Shot Recognition", "authors": "Pei Peng,MingKun Xie,Hang Hao,Tong Jin,ShengJun Huang", "background": "视觉与语言模型中存在的对象-上下文捷径问题，在测试场景与训练场景不一致时，严重影响了零样本可靠性。", "innovation": "将此问题重新表述为因果推理问题，并通过估计对象和背景期望值，结合外部数据集、批量邻居或文本描述合成反事实嵌入，进而估计总直接效应并模拟干预，从而减小仅背景激活的影响，保留有益的对象-上下文交互，同时减少幻觉评分。该方法在无需重新训练或提示设计的情况下，显著提高了上下文敏感基准下的最差群体和平均准确性，建立了新的零样本状态。", "conclusion": "除了性能，我们的框架提供了一种轻量级表示级别的反事实方法，为公正和可靠的多模态推理提供了一个实用的因果途径。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26486", "html_url": "https://arxiv.org/abs/2510.26486", "title": "LINK-KG: LLM驱动的核心指代解决知识图谱用于人口走私网络", "title_en": "LINK-KG: LLM-Driven Coreference-Resolved Knowledge Graphs for Human Smuggling Networks", "authors": "Dipak Meher,Carlotta Domeniconi,Guadalupe Correa-Cabrera", "background": "人类偷渡网络复杂且不断演变，难以全面分析。法律案件文件提供了关于这些网络的丰富事实和程序性见解，但这些文件通常很长、结构不固定且充满了模糊或不断变化的引用，对自动知识图谱的知识提取构成了巨大挑战。现有方法要么忽略了同指消解，要么无法超过短文本跨度，导致知识图谱碎片化且实体链接不一致。", "innovation": "提出了LINK-KG，这是一种模块化框架，结合了一个三阶段、基于大语言模型(LLM)引导的核心指代消解流水线和下游的知识图提取。核心方法是类型特定的提示缓存，它可以在文档片段之间一致地跟踪并解决引用，实现从短文本和长文本中构建清晰和去混淆叙事的能力，从而构建结构化的知识图谱。LINK-KG使平均节点重复减少了45.21%，噪声节点减少了32.22%，从而产生了更干净、更连贯的图结构。", "conclusion": "这些改进使得LINK-KG成为分析复杂犯罪网络的强大基础。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26461", "html_url": "https://arxiv.org/abs/2510.26461", "title": "基于大型语言模型的向量化上下文感知嵌入的GAT协同过滤", "title_en": "Vectorized Context-Aware Embeddings for GAT-Based Collaborative Filtering", "authors": "Danial Ebrat,Sepideh Ahmadian,Luis Rueda", "background": "推荐系统在数据稀疏性和冷启动场景下常常表现不佳，限制了其向新用户或低活跃度用户提供准确建议的能力。现有的方法难以处理用户的短时交互历史，导致推荐质量降低。本文探讨了通过将大型语言模型（LLM）驱动的上下文感知嵌入与图注意网络（GAT）结合到协同过滤（CF）框架中来解决这一问题的方法。作者将用户生成的简短文本摘要和电影项目的丰富文本嵌入统一起来，作为二部图节点的初始特征，从而改善推荐性能。", "innovation": "本文提出了一个使用GAT进行协同过滤的框架，结合了大型语言模型生成的上下文感知嵌入。通过使用这些嵌入作为初始节点特征并结合混合损失函数（包含贝叶斯个性化排序（BPR）损失、余弦相似度项和稳健的负采样），系统能够有效区分明确的负面反馈与未观察到的数据。该方法在MovieLens 100k和1M数据集上的实验结果表明，相较于最先进的基准模型，本方法在Precision、NDCG和MAP上都保持了一致的改进，显示出良好的鲁棒性。进一步的消融研究也证实了在捕捉语义关系方面，大型语言模型增强的嵌入和余弦相似度项的作用至关重要。", "conclusion": "通过将大型语言模型提取的上下文理解与图结构算法集成，本方法成功缓解了数据稀疏性和冷启动问题，提出了一种新的方法以提高推荐系统的性能。未来的工作将涉及平衡推荐的准确性和覆盖率/多样性，并引入公平性约束和可解释性特征以进一步增强系统性能。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26474", "html_url": "https://arxiv.org/abs/2510.26474", "title": "通过头尾平衡对抗LVLMs自改进中的马太效应", "title_en": "Counteracting Matthew Effect in Self-Improvement of LVLMs through Head-Tail Re-balancing", "authors": "Xin Guo,Zhiheng Xi,Yiwen Ding,Yitao Zhai,Xiaowei Shi,Xunliang Cai,Tao Gui,Qi Zhang,Xuanjing Huang", "background": "大视觉-语言模型（LVLMs）的自我改进已逐渐成为提升其推理能力的主流范式。模型通过迭代探索和学习以往的成功轨迹以提升自身的推理能力。然而，在这一过程中，模型在处理简单查询（即头数据）时表现出色，但在处理复杂查询（即尾数据）时能力不足，导致了优化过程中的不平衡，这使得模型更倾向于发展简单的推理能力，而忽视了复杂的推理任务。随着迭代次数的增加，这种不平衡效应愈加明显，我们称之为‘马太效应’，最终阻碍了模型的进一步改进，并导致了性能瓶颈。", "innovation": "为解决这一挑战，我们提出了四种有效的策略，从分布重塑和轨迹重采样的两个视角出发，旨在在探索和学习的自我改进过程中实现头尾平衡。通过在Qwen2-VL-7B-Instruct和InternVL2.5-4B模型上针对视觉推理任务进行广泛实验，结果表明，我们的方法在提升视觉推理能力方面表现出色，平均比传统的自我改进方法高出3.86分。", "conclusion": "我们的研究通过引入新的平衡策略，显著改善了LVLMs在复杂推理任务中的表现，成功克服了马太效应带来的挑战，为未来的LVLMs优化研究提供了新的思路。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26512", "html_url": "https://arxiv.org/abs/2510.26512", "title": "Inside CORE-KG: 评估结构化提示和指代消解在知识图谱中的作用", "title_en": "Inside CORE-KG: Evaluating Structured Prompting and Coreference Resolution for Knowledge Graphs", "authors": "Dipak Meher,Carlotta Domeniconi", "background": "人口走私网络具有较强的适应性且难以分析。法律案例文档虽然提供了关键洞察，但往往缺乏结构化，词汇密集且充满模糊或变化的引用，这使得自动知识图谱（KG）构建成为一个挑战。虽然最近基于LLM的方法有所改善，但仍会产生噪声大、碎片化的图谱，并且存在重复节点的问题。CORE-KG框架通过整合类型感知的指代模块和领域引导的结构化提示解决了这些问题，显著减少了节点重复和法律噪声。", "innovation": "CORE-KG框架通过引入类型感知的指代模块和领域引导的结构化提示，显著减少了知识图谱建设中的节点重复和法律噪声问题。本文通过系统性的消融实验量化了其两个关键组件的贡献。", "conclusion": "消融实验结果显示，移除指代消解会导致节点重复增加28.32%，噪声节点增加4.32%；移除结构化提示会导致节点重复增加4.34%，噪声节点增加73.33%。这些发现为设计从复杂法律文本中提取结构化表示的鲁棒LLM管道提供了实证见解。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26586", "html_url": "https://arxiv.org/abs/2510.26586", "title": "基于物理信息的混合模型及其代理模型在精密增材制造中的应用", "title_en": "Physics-Informed Mixture Models and Surrogate Models for Precision Additive Manufacturing", "authors": "Sebastian Basterrech,Shuo Shan,Debabrata Adhikari,Sankhya Mohanty", "background": "本文研究利用混合模型学习方法识别激光增材制造（AM）过程中的缺陷。通过引入基于物理原理的原则，确保模型对有意义的物理参数变化敏感。实验评估通过分析两种AM过程的实际数据进行：定向能量沉积和激光粉末床熔融。此外，还研究了开发的框架在不同合金类型和实验参数信息的公共数据集上的表现。研究表明，基于物理信息的混合模型可以研究AM系统的潜在物理行为。", "innovation": "提出了利用混合模型学习方法识别增材制造过程中缺陷的方法，并引入基于物理原理的原则。实验评估使用了真实的AM过程数据进行验证，且进一步在不同合金类型和实验参数信息的公共数据集上研究了开发框架的性能。", "conclusion": "基于物理信息的混合模型具有潜在的价值，可以精细研究AM系统的物理行为，提供了研究增材制造过程中潜在问题的新方法。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26577", "html_url": "https://arxiv.org/abs/2510.26577", "title": "面向推理成本的动态树构建方法在大型语言模型高效推理中的应用", "title_en": "Inference-Cost-Aware Dynamic Tree Construction for Efficient Inference in Large Language Models", "authors": "Yinrong Hong,Zhiquan Tan,Kai Hu", "background": "大型语言模型（LLMs）因自回归设计和庞大体量而在推理过程面临显著延迟挑战。为解决这一问题，推测解码技术应运而生，允许同时进行多个令牌的生成与验证。尽管EAGLE-2和EAGLE-3等近期方法利用动态树结构改善推测解码，但通常忽略了诸如GPU设备和批次大小等关键系统变量的影响。", "innovation": "本文提出了一种新的动态树解码方法CAST，它考虑了包括GPU配置和批次大小在内的推理成本因素，动态优化树结构。该方法在六个不同任务和六种不同LLM上进行了全面实验，显示出显著的效果，相比传统解码方法可提高5.2倍的推理速度，并在大多数情况下超出现有先进技术5%至20%。", "conclusion": "CAST方法通过考虑到GPU配置和批次大小等因素，动态调整树结构，大幅提升了大型语言模型的推理速度和性能。相比现有技术，CAST在多个任务上的性能有显著提升，展示了其在提高LLM推理效率方面的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26551", "html_url": "https://arxiv.org/abs/2510.26551", "title": "机器人学中学习变长工具操控的自适应逆向运动学框架", "title_en": "Adaptive Inverse Kinematics Framework for Learning Variable-Length Tool Manipulation in Robotics", "authors": "Prathamesh Kothavale,Sravani Boddepalli", "background": "传统的机器人对自身运动学的理解有限，并且只能执行预先编程的任务，这限制了它们高效使用工具的能力。为了克服这一限制，本文基于工具使用的关键元素——抓住期望的结果、选择最合适的工具、确定最佳的工具姿态和执行精确的操作，提出了一个开拓性的框架。该框架扩展了机器人逆向运动学解决器的能力，使其能够使用不同长度的工具进行一系列操作。实验表明，扩展后的逆向运动学解决了惊人的小于1厘米的误差率，并且训练好的策略在模拟环境中达到8厘米的平均误差率。研究显示，即便使用两种不同长度的工具，模型在表现上几乎没有差异。这一研究为未来在探索工具使用四个基本环节的可能进展提供了迹象，使机器人能够掌握跨不同任务的工具操控技巧。", "innovation": "提出的开拓性框架扩展了机器人逆向运动学解决器的能力，使其能够使用不同长度的工具进行一系列操作；通过结合带有工具的模拟学习操作轨迹，展示了从模拟到真实环境的技能转移的实际应用；取得了小于1厘米的惊人误差率，并在模拟情景下实现了几乎相同的性能，这表明模型的鲁棒性。", "conclusion": "本研究提供了一种可转移的机器人学习框架，展现了将不同长度的工具使用的逆向运动学问题转化为轨迹规划的可能性。这一成果标志着在理解和应用机器人工具使用技术上的一大进步。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26543", "html_url": "https://arxiv.org/abs/2510.26543", "title": "大型语言模型中关系解码线性运算子的结构", "title_en": "The Structure of Relation Decoding Linear Operators in Large Language Models", "authors": "Miranda Anna Christ,Adrián Csiszárik,Gergely Becsó,Dániel Varga", "background": "本文研究了Hernandez等人在2023年提出的一种线性算子结构，这些线性算子在变压器语言模型中解码特定的关系事实。研究者在此基础上，将单关系的研究扩展到了多个关系，并系统地描绘了它们的组织结构。研究表明，通过简单的三阶张量网络，这类多个关系解码器可以被高度压缩，同时对解码准确性的影响并不显著。为了解释这一意外的冗余性，研究者开发了一种跨评估协议，即将每个线性解码运算子应用于其他关系的主体上。研究结果表明，这些线性映射并非存储独特的关系，而是提取了重复出现、粗粒度的语义属性（如首都所在国家和食物所在国家都属于X国家属性）。这种以属性为中心的结构不仅解释了运算器的压缩性，还揭示了为什么它们仅能泛化到语义上接近的新关系中。因此，本文的发现将变压器语言模型中的线性关系解码解释为主要基于属性而非特定关系。", "innovation": "本文扩展了单关系的研究到多个关系，并系统描绘了它们的组织结构。研究发现，通过简单的三阶张量网络，可以高度压缩多个关系解码器，且不影响解码准确性。研究者开发了一种跨评估协议以解释这一冗余性。此外，研究者揭示了线性解码器主要基于属性而非特定关系的特性，这解释了它们的压缩性和泛化性。", "conclusion": "本文通过研究大型语言模型中的线性运算子结构，揭示了线性解码主要基于属性而非特定关系。通过简单的三阶张量网络，多个关系解码器可以被高度压缩，同时保持较高的解码准确性。研究结果表明，理解关系解码本质上是属性而非关系导向的，这对进一步优化和设计更高效的语言模型具有重要意义。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2305.17608", "html_url": "https://arxiv.org/abs/2305.17608", "title": "在对齐大规模语言模型时的奖励塌缩现象", "title_en": "Reward Collapse in Aligning Large Language Models", "authors": "Ziang Song,Tianle Cai,Jason D. Lee,Weijie J. Su", "background": "大型语言模型（LLMs）如ChatGPT和GPT-4通过与训练有人类偏好反应排名的奖励模型对齐，展现了非凡的能力。然而，排名为主的训练方法在优化的终端阶段导致了奖励塌缩现象，即通用和具体的提示都得到相同的奖励分布，这对多样性和精确性都不利。", "innovation": "本文通过理论分析揭示奖励塌缩的主要原因是排名目标函数不能有效集成提示相关信息。作者进而提出了一个提示感知的优化方案，实现了提示依赖的奖励分布，有效缓解了奖励塌缩。", "conclusion": "实验结果表明，提出的提示感知的有用函数在奖励模型训练中显著缓解了奖励塌缩现象。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26786", "html_url": "https://arxiv.org/abs/2510.26786", "title": "HEIR: 学习基于图的运动层次结构", "title_en": "HEIR: Learning Graph-Based Motion Hierarchies", "authors": "Cheng Zheng,William Koch,Baiang Li,Felix Heide", "background": "在计算机视觉、图形和机器人学等领域中广泛存在层级结构的运动，通常是由较简单的运动组成体的协调相互作用产生的复杂动力学。现有的方法通常依赖于手动定义或启发式的固定运动原型层次结构，这限制了其在不同任务中的普适性。", "innovation": "本文提出了一种通用的基于数据的学习运动层次结构的方法。该方法使用基于图的层次结构来表示观察到的运动，并明确地将全局绝对运动分解为父级继承模式和局部运动残差。该方法将层次结构推理形式化为一个可微分的图学习问题，通过图神经网络来捕捉父子之间的依赖关系。", "conclusion": "实验结果表明，该方法在1D和2D情况下重建了内在的运动层次结构，并在动态3D高斯点绘制场景中产生了更真实且可解释的变形。通过提供一种适应性强、数据驱动的层级建模范式，该方法适用于众多以运动为中心的任务。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26783", "html_url": "https://arxiv.org/abs/2510.26783", "title": "统一因果推理的理论：通过Bregman-Riesz回归实现直接无偏机器学习", "title_en": "A Unified Theory for Causal Inference: Direct Debiased Machine Learning via Bregman-Riesz Regression", "authors": "Masahiro Kato", "background": "该论文讨论了一种统一的因果推理理论框架，该框架整合了Riesz回归、协变量平衡、密度比估计（DRR）、针对最大似然估计（TMLE）和匹配估计器在平均治疗效应（ATE）估计中的应用。在ATE估计中，平衡权重和结果的回归函数起到重要作用，而平衡权重根据不同上下文有不同的名称，如Riesz代表元、偏差修正项和聪明协变量。Riesz回归、协变量平衡、密度比估计和匹配估计都是估计平衡权重的方法，Riesz回归在ATE上下文等同于密度比估计，匹配估计是密度比估计的一个特例，而密度比估计与协变量平衡有互补关系。TMLE是一种建造回归函数估计器的方法，使得主要偏差项为零。最近邻匹配等同于最小二乘密度比估计和Riesz回归。", "innovation": "论文引入了一个统一的因果推理理论框架，将Riesz回归、协变量平衡、密度比估计（DRR）、针对最大似然估计（TMLE）和匹配估计器整合为一体，并且通过Bregman-Riesz回归实现了直接无偏机器学习。每种方法在ATE估计中的具体角色和相互关系也得到了论述。", "conclusion": "该理论为因果推理提供了一个统一的方法论框架，可以更有效地估计平均治疗效应，并通过Bregman-Riesz回归实现直接无偏机器学习。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26795", "html_url": "https://arxiv.org/abs/2510.26795", "title": "在大陆级别扩展图像地理定位", "title_en": "Scaling Image Geo-Localization to Continent Level", "authors": "Philipp Lindenberger,Paul-Edouard Sarlin,Jan Hosang,Matteo Balice,Marc Pollefeys,Simon Lynen,Eduard Trulls", "background": "在全局范围内精确确定图像的位置仍然是一个未解决的挑战。标准图像检索技术由于图像数量庞大(超过100M)且覆盖不足而效率低下，现有的可扩展解决方案在精细度和跨视角检索之间存在权衡：全球分类通常精度较低（超过10公里），而地面和航空图像之间的跨视角检索由于领域差距，主要在小区域中得到研究。", "innovation": "本文提出了一种混合方法，实现了对大陆级别的大面积进行细粒度地理定位。通过利用训练中的代理分类任务来学习包含精确位置信息的丰富特征表示，并将这些学习原型与航空影像的嵌入结合，增强对地面数据稀疏性的鲁棒性。这使得在多个国家范围内实现直接的细粒度检索成为可能。我们的综合评估表明，对于覆盖欧洲大部分地区的数据集，我们的方法可以实现超过68%的查询在200米以内精确定位。相关代码已在该网址公开：this https URL", "conclusion": "综上所述，该方法在大陆级别的大面积图像地理定位方面取得了显著进展，实现了更高的精度和更好的鲁棒性，有效地解决了大范围地理定位的挑战。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26778", "html_url": "https://arxiv.org/abs/2510.26778", "title": "通过仔细选择U-Net架构和损失函数以解决类别不平衡问题在RGB视网膜血管图像中的AMD区域估计中超越现有技术", "title_en": "Surpassing state of the art on AMD area estimation from RGB fundus images through careful selection of U-Net architectures and loss functions for class imbalance", "authors": "Valentyna Starodub,Mantas Lukoševičius", "background": "年龄相关性黄斑变性（AMD）是60岁以上人群不可逆视力损害的主要原因。该研究专注于RGB视网膜血管图像中的AMD病灶检测的语义分割，这是一种非侵入性和成本效益高的成像技术。ADAM挑战赛的数据集和结果为我们的评估提供了基准。", "innovation": "基于U-Net连接性，本研究评估和比较了多种改进分割模型架构和训练管道的方法，包括预处理技术、不同复杂程度的编码器（主干网络）类型以及专门的损失函数来缓解图像和像素级别的类别不平衡问题。最终构建的AMD检测框架在非侵入性RGB视网膜血管图像中的多类分割方面优于所有之前的ADAM挑战提交。", "conclusion": "该研究最终的AMD检测框架在非侵入性RGB视网膜血管图像中不同AMD病灶类型的多分类分割性能上超越了所有之前的ADAM挑战提交，并且所用的实验源代码已经公开。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26723", "html_url": "https://arxiv.org/abs/2510.26723", "title": "在政策学习中弥合经验福利最大化与条件平均处理效果估计之间的差距", "title_en": "Bridging the Gap between Empirical Welfare Maximization and Conditional Average Treatment Effect Estimation in Policy Learning", "authors": "Masahiro Kato", "background": "政策学习的目标是训练一个政策函数，根据协变量推荐治疗以最大化人口福利。该领域存在两种主要方法：经验福利最大化（EWM）方法和插值方法。EWM方法类似于分类问题，首先估计人口福利函数，然后再通过最大化估计的福利来训练政策。相反，插值方法基于回归，首先估计条件平均处理效果（CATE），然后根据估计效果最佳的治疗方案进行推荐。本文通过证明两者实际上基于相同的优化问题，弥合了这两类方法之间的差距。", "innovation": "本文发现表明，EWM和最小二乘法在重新参数化政策类的情况下是完全等价的。因此，在不少方面，两种方法可以互换，并且在相同条件下共享相同的理论保证。基于这一等价性，本文提出了一种新颖的政策学习正则化方法。这一发现导致了一种凸的、计算效率高的训练程序，可以避免EWM中通常需要的NP难的组合步骤。", "conclusion": "两种方法在重新参数化政策类的情况下是等价的，两者可以在多个方面进行互换，并且在共同条件下共享相同的理论保证。本文提出了一种新的正则化方法，提供了更高效的训练过程，并能避免EWM中的NP难组合步骤。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26800", "html_url": "https://arxiv.org/abs/2510.26800", "title": "OmniX: 从统一全景生成和感知到图形级3D场景", "title_en": "OmniX: From Unified Panoramic Generation and Perception to Graphics-Ready 3D Scenes", "authors": "Yukun Huang,Jiwen Yu,Yanning Zhou,Jianan Wang,Xintao Wang,Pengfei Wan,Xihui Liu", "background": "当前3D场景构建有两大常见方式：程序生成和2D提升。其中全景基于的2D提升技术因其利用强大的2D生成先验知识，能产生沉浸式、真实且多样的3D环境，成为了一种有前景的方法。但现有2D提升方法主要聚焦在外观生成上，而忽视了内在属性的感知。本文旨在进一步发展该项技术，生成适合基于物理渲染（PBR）、重新光照和模拟的图形级3D场景。", "innovation": "本文提出了OmniX，这是一种灵活且统一的框架，基于轻量且高效的跨模态适配器结构，重新利用2D生成先验知识，应用于广泛的全景视觉任务，包括全景感知、生成与完成。此外，作者还构建了一个包含高质量多模态全景图的大规模合成全景数据集，来自多样化的室内和室外场景。各种实验表明，该模型在全景视觉感知和图形级3D场景生成方面都表现出色，为沉浸式和物理真实感虚拟世界的生成提供了新途径。", "conclusion": "本文提出OmniX框架，提出了全景生成和感知的方法，并且构建了大数据集，证明了该方法在3D场景生成上的优势，为虚拟世界的生成提供了新的可能。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26769", "html_url": "https://arxiv.org/abs/2510.26769", "title": "SteerVLM：通过轻量级激活导向实现视觉语言模型的鲁棒模型控制", "title_en": "SteerVLM: Robust Model Control through Lightweight Activation Steering for Vision Language Models", "authors": "Anushka Sivakumar,Andrew Zhang,Zaber Hakim,Chris Thomas", "background": "随着视觉语言模型（VLMs）的发展，研究人员和用户希望这些模型能够更好地遵循预设指令。然而，当前的技术往往需要对模型进行大规模调整甚至重新训练，这不仅增加了计算负担，还可能影响到模型在其他任务上的性能。因此，开发一种轻量级且不会显著降低模型性能的方法来引导VLMs，是目前的一个重要研究方向。本文在这方面做了一定的探索，提出了SteerVLM，一种轻量级的转向模块，能够动态调整语言模态与图像上下文之间的连接激活，从而实现复杂输出语义的精细控制。", "innovation": "SteerVLM模块通过学习配对提示词（包含目标行为和相反行为的潜变量嵌入）的差异来动态调节语言模态与图像上下文之间的连接激活。这种方法仅需要0.14%的原始VLM模型大小的学习参数，并且无需预先提取静态向量或手动调整干预点。此外，本文还引入了VNIA（视觉叙事意图对齐）数据集，专为VLM转向技术的发展和评估而设。SteerVLM方法在VLM导向和幻觉缓解基准测试中表现优异，提出了一种通过激活工程实现多模态模型鲁棒控制的方案.", "conclusion": "本文提出了SteerVLM，一种轻量级的转向模块，能够在不修改模型权重的情况下动态调整语言模态与图像上下文之间的激活，实现复杂输出语义的精细控制。此外，通过VNIA数据集的引入，为VLM转向技术的发展和评估提供了有力支持。SteerVLM方法不仅在导向和幻觉缓解方面表现出色，还为多模态模型控制提供了一种坚实的解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.26752", "html_url": "https://arxiv.org/abs/2510.26752", "title": "监督游戏：学习协同平衡AI代理的安全性和自主性", "title_en": "The Oversight Game: Learning to Cooperatively Balance an AI Agent's Safety and Autonomy", "authors": "William Overman,Mohsen Bayati", "background": "随着能力愈发强大的代理系统的部署，一个核心的安全问题是如何在不修改底层系统的情况下保持有意义的人类控制。本文研究了一种极简的控制界面，其中代理可以选择自主行动（播放）或授权他人（请求），同时人类可以选择是否赋予信任（信任）或进行监督（监督）。当代理权衡是否请求授权时，人类的选择将决定结果，可能会导致纠正行为或系统关闭。作者将此互动建模为一种两人马尔可夫博弈。在考虑这种博弈是否符合马尔可夫潜力博弈（MPG）这一类游戏时，作者进行了分析。通过结构假设人类的价值函数，任何提升代理自主性但对其有益的行为都不能损害人类的价值。此外，作者还分析了这一MPG框架的扩展方法。理论上，这种视角提供了特定形式本体一致性条件；如果人类-代理博弈的奖励结构符合这些条件，那么代理改善自身结果将不会损害人类的利益。实践中，这种模型激励了一种透明的控制层，其中代理通过独立学习了解在何时应该授权他人并在何时进行自主行动，不改变其预训练策略和环境的奖励结构。网格世界的模拟表明，代理和人类通过独立学习发现他们的最佳监督角色：当不确定时代理会请求，当需要时人类会监督，这导致了一种自然的协作方式，避免了训练后引入的安全违规行为。这表明了一种将不一致的模型在部署后使之安全的方法。", "innovation": "本文通过将人-代理交互建模为马尔可夫博弈并引入监督博弈框架（MPG），提出了一个安全与自主性的协同平衡方法。该方法允许代理在不确定时请求授权，而人类根据需要进行监督，并通过这种透明的控制层确保代理在安全时自主行动。这种方法为在部署后使不一致模型变得更加安全提供了一种实际的机制，避免安全违规并在不需要修改底层系统的情况下实现这一目标。", "conclusion": "本文通过独立学习的方法，将代理和人类引导至最优的监督角色，确保代理在安全情况下独立行动，在不确定时请求授权，并在需要时由人类进行监督。这种方法能够避免训练后引入的安全违规行为，为部署后使不一致的模型更安全提供了实际策略，并且不改变代理的预训练策略和环境的奖励结构。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2403.02682", "html_url": "https://arxiv.org/abs/2403.02682", "title": "Time Weaver: 一种条件时间序列生成模型", "title_en": "Time Weaver: A Conditional Time Series Generation Model", "authors": "Sai Shankar Narasimhan,Shubhankar Agarwal,Oguzhan Akcin,Sujay Sanghavi,Sandeep Chinchali", "background": "当前的时间序列生成方法往往忽略了与时间序列相伴的异构上下文元数据（如天气和位置）。这种异构元数据的异质性给将图像、音频和视频领域的条件生成方法扩展到时间序列领域带来了诸多实际挑战。因此，本文讨论了基于天气、电动汽车存在性和位置来生成城市电力需求模式的问题，并指出现有的时间序列生成方法忽视了这些关联的元数据。", "innovation": "本文提出了一种名为TIME WEAVER的新型扩散模型，该模型利用了同质元数据的形式（包括分类、连续以及随时间变化的变量），以显著提高时间序列生成的效果。作者还创新性地提出了一种新的评估度量标准，该标准能够准确捕捉条件生成的特异性以及生成时间序列的现实性。与现有的基准方法（如生成对抗网络）相比，TIME WEAVER在真实世界的能源、医疗、空气质量及交通数据集上的下游分类任务中表现出高达30%的优势。", "conclusion": "TIME WEAVER模型在处理具有复杂元数据的时间序列生成任务上表现更好，而且提供了一种新的评价度量标准，该标准能够更准确地评估生成的时间序列的现实性和特定性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.03348", "html_url": "https://arxiv.org/abs/2410.03348", "title": "Dolphin: 可编程的可扩展神经符号学习框架", "title_en": "Dolphin: A Programmable Framework for Scalable Neurosymbolic Learning", "authors": "Aaditya Naik,Jason Liu,Claire Wang,Amish Sethi,Saikat Dutta,Mayur Naik,Eric Wong", "background": "神经符号学习结合了符号推理和深度学习，但在扩展到复杂的符号程序、大规模数据集或两者兼有时面临重大挑战。", "innovation": "DOLPHIN框架支持使用Python实现神经符号程序，在CPU上执行复杂的符号推理，同时在GPU上向量化概率计算和梯度传播。它在13个基准测试中表现出色，特别是在包含递归和黑箱函数的符号推理特征方面，DOLPHIN在更复杂的基准测试中取得最先进的准确度，而在更简单的基准测试中与现有框架相当，但速度提高了1.71至62倍。", "conclusion": "DOLPHIN推进了神经符号框架的可扩展性，在具有挑战性的基准测试中实现了最先进的效率和收敛性，这些基准测试对现有框架构成了挑战。源代码已发布。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2405.09086", "html_url": "https://arxiv.org/abs/2405.09086", "title": "混沌驱动的强化学习与TD3", "title_en": "Chaos-based reinforcement learning with TD3", "authors": "Toshitaka Matsuki,Yusuke Sakemi,Kazuyuki Aihara", "background": "混沌驱动的强化学习（CBRL）是一种使智能体内部混沌动力学驱动探索的方法。然而，之前的研究尚未充分发展CBRL的习得算法，也没有将近期的强化学习进展融合进来。这项研究将最先进的深度强化学习算法Twin Delayed Deep Deterministic Policy Gradients (TD3)引入至CBRL中。实验结果表明，TD3适用于CBRL在简单目标到达任务中的学习算法。CBRL智能体利用TD3会随着学习的进步自主抑制其探索行为，并在环境变化时恢复探索。研究发现，智能体的混沌强度存在一个适合的范围，以灵活地在探索和利用之间切换，并适应环境变化。", "innovation": "将TD3算法引入CBRL领域，利用TD3处理确定性和连续动作空间问题。实验验证了TD3在CBRL中的有效性，并展示了CBRL智能体如何根据环境变化自主调整探索与利用策略。研究为CBRL的进一步发展提供了新的思路和技术基础，特别是在混沌动力学与强化学习结合方面有显著创新性。", "conclusion": "研究结果表明，TD3可以作为CBRL的有效学习算法。CBRL智能体能够随着学习进程自主抑制探索行为，并在环境变化时恢复探索。此外，探索了智能体混沌性的学习效应，发现混沌强度存在一个合适的范围，能够在探索与利用之间灵活切换以适应环境变化。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2408.08493", "html_url": "https://arxiv.org/abs/2408.08493", "title": "继承模型网络中的并行遗忘", "title_en": "Parallel Unlearning in Inherited Model Networks", "authors": "Xiao Liu,Mingyuan Li,Guangsheng Yu,Lixiang Li,Haipeng Peng,Ren Ping Liu", "background": "在通用学习框架中，随着模型的不断增长和更新，模型之间的复杂继承关系使得遗忘成为一项极具挑战性的任务。现有的遗忘方法无法有效地处理这些继承关系，导致难以进行全面的并行遗忘。", "innovation": "本文提出了一种新颖的并行遗忘框架，该框架能够使具有继承关系的模型之间实现完全并行遗忘。该框架的核心是采用时间导向有向无环图（DAG）来捕捉模型继承网络中的各种遗忘场景，并引入了基于Fisher信息矩阵（FIM）的Fisher Inheritance Unlearning（FIUn）方法，该方法能够高效地评估和调整模型参数以支持并行遗忘。此外，还提出了一种Merging-FIM（MFIM）函数，用于合并来自多个上游模型的FIM，从而支持所有DAG捕获的遗忘场景。", "conclusion": "实验结果显示，该遗忘框架在单类别任务中实现了100%的遗忘率且保留类别的准确率为94.53%；在多类别任务中，遗忘类别的准确率为1.07%且保留类别的准确率为84.77%。与现有方法相比，该框架将遗忘速度提升了99%。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.06324", "html_url": "https://arxiv.org/abs/2410.06324", "title": "通过黑盒二次规划求解器进行求导", "title_en": "Differentiation Through Black-Box Quadratic Programming Solvers", "authors": "Connor W. Magoon,Fengyu Yang,Noam Aigerman,Shahar Z. Kovalsky", "background": "可微优化广泛引起了研究兴趣，尤其是在二次规划（QP）方面。现有的QP解对定义参数进行求导的方法通常依赖特定集成的求解器，但这种集成限制了它们的应用范围，限制了在神经网络架构和多层优化任务中的使用，从而限制了用户的选择范围。这促使研究人员寻找更为灵活和通用的方法来处理QP问题的求导问题。", "innovation": "本文提出了一种名为dQP的模块化且与求解器无关的框架，可以无缝地为任何QP求解器进行快速求导。该框架的关键在于，一旦知道了不等式约束的活动集，QP问题的解和其导数可以使用具有相同矩阵的简化线性系统来表达，这实现了QP解计算与求导的完全解耦。此外，dQP采用了低成本、开源的实现，并支持超过15种最先进的求解器。基准实验验证了dQP的稳健性和可扩展性，特别是在大型稀疏问题上的优势。", "conclusion": "dQP框架通过提供一种灵活、模块化的方法来处理几乎任何QP求解器的求导问题，展示了其实用性和优越性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2410.09766", "html_url": "https://arxiv.org/abs/2410.09766", "title": "稳定性和更精确的风险边界的收敛速率为 \\(\\tilde{O}(1/n^2)\\）", "title_en": "Stability and Sharper Risk Bounds with Convergence Rate $\\tilde{O}(1/n^2)$", "authors": "Bowei Zhu,Shaojie Li,Mingyang Yi,Yong Liu", "background": "先前的研究（Klochkov & Zhivotovskiy, 2021）通过算法稳定性证明了强凸学习器的最大小于 \\(O(\\log(n)/n)\\) 的风险偏差，概率上几乎肯定成立。本文在相似的假设条件下——聚拉克-罗扎伊谢维茨条件、平滑性和损失的Lipschitz连续性——证明了风险最大小于 \\(O((\\log(n))^2/n^2)\\) 的概率也是可以实现的，目前所知，本文的分析为非凸情况下基于梯度的泛化差距提供了最紧致的概率边界的最精确分析", "innovation": "本文通过相似的假设条件(聚拉克-罗扎伊谢维茨条件、平滑性和损失的Lipschitz连续性)证明了风险大小为\\(O((\\log(n))^2/n^2)\\)的概率边界是可实现的，这是目前最紧致的概率边界的最精确分析，特别是在非凸设置下，为基于梯度的泛化差距提供了最优的风险度量", "conclusion": "本文的分析不仅提高了对基于梯度泛化差距的误差边界的理解和估计，而且在非凸设置下实现了更紧致的概率风险边界的最优估计，收敛速率为 \\(\\tilde{O}(1/n^2)\\)。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2406.08525", "html_url": "https://arxiv.org/abs/2406.08525", "title": "神经网络中正性条件的数学认证及其在部分单调性和可信人工智能中的应用", "title_en": "A mathematical certification for positivity conditions in Neural Networks with applications to partial monotonicity and Trustworthy AI", "authors": "Alejandro Polo-Molina,David Alfaya,Jose Portela", "background": "人工神经网络（ANNs）在模型复杂关系的大规模数据集上已成为强有力的工具。然而，它们的黑箱性质带来了可信性挑战。在某些情况下，确保预测的可信度可能需要遵循特定的部分单调性约束。但是，验证已经训练好了的ANN是否部分单调性是具有挑战性的。因此，在需要部分单调性的关键应用中，如信用评分，人工神经网络经常被忽视。", "innovation": "本文提出了一种新颖的算法（LipVor），它可以基于有限数量的评估来认证黑箱模型（如ANN）是否为正性模型。由于部分单调性可以表示为部分导数为正的条件，LipVor可以认证ANN是否部分单调。该方法利用黑箱模型的Lipschitzian性构造一个特定的邻域，其中函数保持正性。此外，基于评估点的Voronoi图，陈述了一个充分条件来认证函数在域内是否为正。与其他先前方法不同，本文的方法可以通过这种认证而不依赖于受限的架构或分段线性激活。因此，LipVor可以为一些关键领域提供使用未受限ANN的可能性。此外，一些其他ANN的属性（例如凸性）也可以表示为正性条件，因此LipVor也可以应用于这些场景。", "conclusion": "LipVor算法可以开创在一些关键领域使用未受限ANN的可能性，尤其是在需要部分单调性的应用中，代表了对ANN在可信人工智能中的应用的一项重要创新。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.09846", "html_url": "https://arxiv.org/abs/2507.09846", "title": "无计划方法在语言模型训练中的优势：理解河流效应", "title_en": "Through the River: Understanding the Benefit of Schedule-Free Methods for Language Model Training", "authors": "Minhak Song,Beomhan Baek,Kwangjun Ahn,Chulhee Yun", "background": "随着模型和数据集规模的快速增长，传统的预训练策略（如余弦学习率调度）由于固定的计算预算越来越不适用于大规模训练。近期的替代方法，如warmup-stable-decay (WSD) 调度和权重平均，提供了更大的灵活性。然而，WSD依赖于明确的衰减阶段来跟踪进度，而权重平均解决了这一问题但增加了额外的内存需求。寻找更合理且可扩展的替代方案，作者重新审视了无计划（Schedule-Free，SF）方法，该方法在不同条件下表现出强大的实证性能。", "innovation": "作者展示了SF-AdamW能够在无需衰减阶段或辅助平均的情况下导航损失景观中的“河流”结构，特别适用于连续扩展的训练工作负载。此外，通过理论和实证分析，作者揭示了SF的一种隐含的权重平均过程，而无需内存开销。基于分析，提出了一种改进的SF变体，增强了其对动量的鲁棒性并适应更大的批次大小，从而解决了原始方法的关键局限。", "conclusion": "综上所述，这些结果确立了SF作为一种实用、可扩展且具有理论基础的训练语言模型的方法。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.08606", "html_url": "https://arxiv.org/abs/2508.08606", "title": "分布式优化：专为联邦学习设计", "title_en": "Distributed optimization: designed for federated learning", "authors": "Wenyou Guo,Ting Qu,Chunrong Pan,George Q. Huang", "background": "联邦学习(FL)作为一种在隐私保护约束下的分布式协作机器学习(ML)框架，在跨组织数据协作场景中引起了越来越多的研究关注。", "innovation": "该论文提出了一类基于增广拉格朗日技术的分布式优化算法，适用于集中式和分布式联邦学习设置中的多样化通信拓扑。此外，开发了多种终止准则和参数更新机制以提升计算效率，并提供了收敛性的严格理论保证。通过将增广拉格朗日松弛与近似和二次逼近技术相结合，该框架系统地恢复了包括近似算法、经典梯度下降和随机梯度下降在内的广泛经典无约束优化方法，其收敛性在提出的方法理论框架内自然推导。", "conclusion": "数值实验表明，所提出的方法在大规模且客户间存在显著统计异质性的情况下表现出强大的性能。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.17475", "html_url": "https://arxiv.org/abs/2506.17475", "title": "基于低秩训练的动量优化器几何框架", "title_en": "A geometric framework for momentum-based optimizers for low-rank training", "authors": "Steffen Schotthöfer,Timon Klein,Jonas Kusch", "background": "低秩预训练和微调近年来被证明是减少大型神经网络计算和存储成本的有效方法。目前，低秩参数化通常依靠重球动量方法或Adam等常规优化器进行训练。然而，这些方法在训练低秩权重参数化时可能会遇到收敛问题，特别是传统的动量方法由于优化地形的几何结构可能难以收敛到局部最优解。", "innovation": "本文识别并分析了传统动量方法在训练低秩参数化时遇到的潜在困难，并引入了一种基于动态低秩近似的新颖训练策略，以明确考虑底层几何结构。方法结合了动态低秩近似和动量优化的工具，设计出尊重参数空间内在几何结构的优化器。经过数值实验验证，该方法能实现更快的收敛速度和更强的验证指标。", "conclusion": "通过引入基于动态低秩近似的新型训练策略，本文提出的优化器能够更好地响应参数空间的内在几何结构，从而实现更快的收敛和更好的验证指标。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.08645", "html_url": "https://arxiv.org/abs/2506.08645", "title": "当核相乘，簇联合：基于克罗内克积融合嵌入", "title_en": "When Kernels Multiply, Clusters Unify: Fusing Embeddings with the Kronecker Product", "authors": "Youqi Wu,Jingwei Zhang,Farzan Farnia", "background": "当前最先进的嵌入模型能够捕捉到独特但互补的判别特征，例如，一个模型可能擅长区分精细的纹理，而另一个模型则专注于对象层面的结构。本文的研究背景正是基于此观察。", "innovation": "本文提出了通过核乘积融合互补表示的一种原理性方法，采用克罗内克积来实现在嵌入空间中融合判别结构。这不仅为多模式配对数据（例如图像-文本对）的联合核构建提供了一种自然方式，还开发了RP-KrossFuse，利用随机投影进行高效近似，从而大大降低了计算成本。", "conclusion": "实验表明，RP-KrossFuse能够有效融合跨模态和单模态模型，不仅提升了特定模态的表现，还维护了跨模态的一致性。该框架成功缩小了跨模态嵌入模型（如CLIP、BLIP）与单模态专家模型（如DINOv2、E5）之间的性能差距。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.00927", "html_url": "https://arxiv.org/abs/2507.00927", "title": "理解节点和链接预测中的泛化", "title_en": "Understanding Generalization in Node and Link Prediction", "authors": "Antonis Vasileiou,Timo Stoll,Christopher Morris", "background": "消息传递图神经网络（MPNNs）在节点和链接预测方面的应用在各个科学和技术领域都至关重要，这也推动了MPNN架构的多样化发展。尽管MPNNs在实际应用中表现良好，但它们在训练集外的泛化能力却知之甚少。现有的研究主要集中在图级预测任务中，而对节点级和链接级预测的泛化探索较少。现有的工作通常依赖于不现实的独立同分布（i.i.d.）假设，忽视了节点或链接之间的可能相关性，以及固定的聚集方式和不切实际的损失函数，忽略了图结构的影响。", "innovation": "本文引入了一个统一框架，用于在归纳和传递节点和链接预测设置中分析MPNNs的泛化属性，该框架涵盖了各种架构参数和损失函数，并量化了图结构的影响。此外，所提出的一般化框架可以应用于任何在归纳或传递设置下的分类任务，而不仅仅是图。", "conclusion": "我们的实证研究支持了这些理论见解，加深了我们对MPNNs在这些任务中的泛化能力的理解。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.11847", "html_url": "https://arxiv.org/abs/2507.11847", "title": "广义线性armed博弈：近乎最优的遗憾损失新一代量更新", "title_en": "Generalized Linear Bandits: Almost Optimal Regret with One-Pass Update", "authors": "Yu-Jie Zhang,Sheng-An Xu,Peng Zhao,Masashi Sugiyama", "background": "我们研究了广义线性博弈（GLB）问题，这是一种扩展了经典线性模型的上下文多臂博弈框架，通过引入非线性链接函数来建模包括伯努利和泊松在内的广泛类别的奖励分布。虽然GLB在实际场景中有广泛应用，但其非线性性质导致了在实现计算和统计效率上的重大挑战。现有方法通常在这两个目标之间进行权衡，要么导致每轮较高的成本以获得最优遗憾保证，要么牺牲统计效率以实现常数时间更新。", "innovation": "我们在论文中提出了一个高效算法，该算法能在每轮保持几乎最优的遗憾上界的同时，具有$\text{O}(1)$的时间和空间复杂度。核心在于对在线镜像下降（OMD）估计器的紧定置信集的精心设计，这是通过一个新的分析得出的，该分析利用了来自在线预测的混杂损失概念。该分析表明，即使只进行一次更新，我们的OMD估计器的统计效率也相当于最大似然估计，因此引导出一个联合高效的乐观方法。", "conclusion": "该工作提出了一个在统计和计算效率平衡上具有优势的广义线性博弈算法，通过紧定置信集和混杂损失概念的应用，实现了几乎最优的遗憾上界和常数时间更新，为广义线性博弈领域提供了一种新的高效算法框架。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2507.02843", "html_url": "https://arxiv.org/abs/2507.02843", "title": "基于大型语言模型的在推理时间文本混杂条件下的治疗效果估计", "title_en": "LLM-Driven Treatment Effect Estimation Under Inference Time Text Confounding", "authors": "Yuchen Ma,Dennis Frauen,Jonas Schweisthal,Stefan Feuerriegel", "background": "在医学中进行治疗效果估计对于个性化决策至关重要，但在临床实践中会面临独特的挑战。通常，在训练模型时使用结构良好的医学数据集，这些数据集包含详细的患者信息。然而，在进行预测时，往往依赖于文本描述（如自我报告的症状描述），这是患者信息的不完全表现。这种训练时间和推理时间之间的数据差异可能导致治疗效果估计偏差。本文详细探讨了这一问题并提出了相应解决策略。", "innovation": "本文引入了一个创新的框架来解决推理时间的文本混杂问题。该框架结合了大型语言模型和自定义的双重稳健学习者，以减少由推理时间文本混杂引起的偏差。具体来说，该框架能够更好地利用医疗数据中详细信息和不完整的文本描述，从而提供更准确的治疗效果估计。", "conclusion": "通过一系列实验，本文的研究框架在实际应用中展示了其有效性。这一框架能够在解决推理时间文本混杂问题的同时，提高治疗效果估计的准确性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2508.06576", "html_url": "https://arxiv.org/abs/2508.06576", "title": "GFlowNets for Learning Better Drug-Drug Interaction Representations", "title_en": "GFlowNets for Learning Better Drug-Drug Interaction Representations", "authors": "Azmine Toushik Wasi", "background": "药物-药物相互作用在临床药理学中构成了重大挑战，由于相互作用类型间的严重类别不平衡限制了预测模型的有效性。常见相互作用主导了数据集，而那些虽不常见但至关重要的相互作用则严重缺失，导致模型在处理不频繁情况时表现较差。当前方法通常将药物-药物相互作用预测简化为二元问题，忽略了类别特异性细节，加剧了对常见相互作用的偏见。", "innovation": "本文提出了一种结合生成流网络（GFlowNet）和变分图自编码器（VGAE）框架，以生成稀有类别的合成样本，从而改善模型平衡，并生成有效的和新颖的药物-药物相互作用对。这种方法提升了不同类型相互作用的预测性能，确保了更高的临床可靠性，同时解决了类别不平衡问题和对常见相互作用的偏见问题。", "conclusion": "本文提出的方法能够增强预测性能，确保更好的临床可靠性。通过引入GFlowNet和VGAE结合框架，生成稀有类别的合成样本，解决了类别不平衡及其对模型性能的负面影响。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.07500", "html_url": "https://arxiv.org/abs/2506.07500", "title": "Mind the Gap: Removing the Discretization Gap in Differentiable Logic Gate Networks", "title_en": "Mind the Gap: Removing the Discretization Gap in Differentiable Logic Gate Networks", "authors": "Shakir Yousefi,Andreas Plesner,Till Aczel,Roger Wattenhofer", "background": "现代神经网络在现有基准上的性能表现出色，但由于其高计算要求和高能耗，研究人员寻求更高效的解决方案以适应实际部署。逻辑门网络（LGNs）通过学习一个大规模的逻辑门网络来实现高效图像分类。然而，训练一个可以解决简单问题（如CIFAR-10）的网络需要数天至数周的时间，并且即使如此，几乎一半的网络仍然未被使用，导致去量化间隙（discretization gap）问题。去量化间隙问题阻碍了LGNs在现实世界中的部署，因为训练和推理之间的性能下降会对准确性产生负面影响。", "innovation": "通过在训练过程中以直通估计器的方式注入Gumbel噪声，显著加速了训练过程，提高了神经元利用率，并减少了去量化间隙。理论分析表明，这源于隐式的海森堡正则化，改善了LGNs的收敛特性。结果，网络的训练时间提高了4.5倍，去量化间隙减少了98%，未使用的门电路数量减少了100%。", "conclusion": "这项研究通过注入Gumbel噪声和直通估计器，成功地解决了不同的LGNs中的去量化间隙问题，不仅显著提高了训练效率，还提高了神经网络的实际应用性能。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2506.05768", "html_url": "https://arxiv.org/abs/2506.05768", "title": "AANet: 在结构不确定性下通过对齐和聚合进行虚拟筛选", "title_en": "AANet: Virtual Screening under Structural Uncertainty via Alignment and Aggregation", "authors": "Wenyu Zhu,Jianhui Wang,Bowen Gao,Yinjun Jia,Haichuan Tan,Ya-Qin Zhang,Wei-Ying Ma,Yanyan Lan", "background": "虚拟筛选(VS)是现代药物发现的关键组成部分，但大多数现有方法，无论是基于物理的还是基于深度学习的，都围绕已知配体结合口袋的完整蛋白质结构开发。因此，这些方法在缺口袋信息的真实世界早期药物发现中表现较差，例如来自AlphaFold2的apo或预测结构。本研究指出，现有的方法在处理这些结构时表现不佳，与实际早期药物发现情况不符，因为口袋信息经常缺失。因此，需要一种能在结构不确定性情况下实现准确虚拟筛选的方法。", "innovation": "本文提出了一个基于对齐和聚合框架的方法，以实现结构不确定性下的准确虚拟筛选。该方法包括两个核心组件：1）三模式对比学习模块，用于对齐配体、holo口袋以及结构中检测到的空腔表示，从而增强对结合位点定位错误的鲁棒性；2）基于跨注意力的适配器，用于动态聚合候选结合位点，使模型能够从活性数据中学习，即使没有精确的口袋注释。该方法在新的apo结构基准测试上表现优异，超越了最先进的方法，在盲靶apo设置下显著提高了早期富集因子（EF1%）至37.19。此外，该方法在完整结构上也展示了强大的性能。这些结果展示了该方法在推进首次发现类药物发现中的潜力，尤其是在缺少实验解析的蛋白质-配体复合物的情况下。", "conclusion": "本文提出的AANet模型在结构不确定性条件下实现了对配体结合位点的准确预测，并在新构建的apo结构数据集上性能突出，这为药物发现早期阶段的虚拟筛选提供了新思路，特别是在缺少实验数据的情况下。该模型已经在GitHub上公开可用。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22033", "html_url": "https://arxiv.org/abs/2510.22033", "title": "Linearized Optimal Transport for Analysis of High-Dimensional Point-Cloud and Single-Cell Data", "title_en": "Linearized Optimal Transport for Analysis of High-Dimensional Point-Cloud and Single-Cell Data", "authors": "Tianxiang Wang,Yingtong Ke,Dhananjay Bhaskar,Smita Krishnaswamy,Alexander Cloninger", "background": "单细胞技术可以生成高维点云数据，这些数据能够详细描述患者的复杂状态和治疗反应。然而，每个患者的数据通常以非规则点云形式存在，难以直接量化和比较个体间的生物差异。尽管非线性方法，如核技巧和神经网络可以提高预测精度，但由于它们作为黑箱工作，不具备生物学可解释性。因此，需要一种新的方法来解决这些局限性。", "innovation": "该研究采用线性最优传输框架，将非规则点云嵌入固定维度的欧几里得空间，并保留分布结构，提供了一种线性表示方案。这种嵌入不仅使生物可解释的分类成为可能，还能够在空间中实现细胞分布的直接比较，同时还能生成合成数据，支持药物交互测试。LOTOpts（质心）则可用于平均细胞概况的综合条件或样本，支持药物相互作用测试。", "conclusion": "这些结果将LOTOpt确立为一个统一框架，能够同时提高预测性能、保持可解释性和生成建模能力。通过将异构点云转换为可以直接追溯到原始数据的结构化嵌入，LOTOpt为理解高维生物系统的免疫变和治疗效果开辟了新的途径。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22094", "html_url": "https://arxiv.org/abs/2510.22094", "title": "通过轻量级训练实现准确天气预报的分层图网络", "title_en": "Hierarchical Graph Networks for Accurate Weather Forecasting via Lightweight Training", "authors": "Thomas Bailie,S. Karthik Mukkavilli,Varvara Vetrova,Yun Sing Koh", "background": "气候事件源于复杂多变量的动力学，受到全球规模驱动因素的影响，强烈影响食物、能源和基础设施。然而，由于物理过程跨越不同的空间和时间尺度，固定分辨率的方法无法捕捉到这些过程，因此准确的天气预测仍然是一个挑战。Hierarchical Graph Neural Networks（HGNNs）提供了一种多尺度表示方法，但其非线性的下降映射往往消除全球趋势，削弱了物理过程对预报的影响。", "innovation": "论文的两项创新设计分别是：1）一种Latent-Memory-Retention机制，确保在向下的遍历过程中保留全局趋势；2）一种从潜空间到物理空间的分支，实现物理微分方程解场在不同尺度的集成。通过这些创新，Flow模型在13天的预报误差上降低了超过5%，在极端的第1和第99百分位数下分别降低了5-8%的误差，提高了稀有事件的可靠性。使用预训练模型权重，它们在一个epoch内就能收敛，降低了训练成本和碳足迹。", "conclusion": "Flow模型利用预训练的模型权重，在单个训练周期内就能快速收敛，从而减少了训练成本和碳足迹，这种效率在机器学习规模日益扩大时尤为重要，有助于提升研究的可持续性和可达性。模型的代码和权重位于补充材料中。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21271", "html_url": "https://arxiv.org/abs/2510.21271", "title": "Test-Time Adaptation Buffer 层", "title_en": "Buffer layers for Test-Time Adaptation", "authors": "Hyeongyu Kim,Geonhui Han,Dosik Hwang", "background": "近期关于Test Time Adaptation（TTA）的研究大多集中在更新归一化层以适应测试域，但这种方法依赖于归一化技术，存在显著挑战。归一化层如Batch Normalization对小批量大小非常敏感，导致不稳定及不精确的统计数据。此外，归一化层的适应性依赖于预训练模型的结构，其基于训练时间统计信息可能不适用于未见过的领域。这些问题限制了归一化层TTA方法的有效性，尤其是在领域转换较大的情况下。", "innovation": "本文介绍了一种基于Buffer层的新颖范式，以解决归一化层更新的根本限制。不同于现有方法修改模型的核心参数，我们的方法保持预训练主干网络的完整性，从根本上降低了在线适应过程中灾难性遗忘的风险。通过全面实验，我们不仅证明该方法在缓解领域转换和增强模型鲁棒性方面优于传统方法，还展示了对遗忘的强大抵抗力。此外，Buffer层是模块化的，可以无缝集成到几乎所有的现有TTA框架中，结果在各种架构中实现了持续的性能提升。这些结果验证了该解决方案在实际领域的有效性与灵活性。", "conclusion": "实验结果证明，本方法不仅在缓解领域转换和增强模型稳定性方面优于传统方法，还能有效防止遗忘。Buffer层是一个模块化组件，能够与几乎所有现有的TTA框架无缝集成，从而实现不同架构的性能提升。这些发现验证了该方案在实际领域适应场景中的有效性与灵活性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.01988", "html_url": "https://arxiv.org/abs/2510.01988", "title": "PepCompass: 使用黎曼几何导航肽嵌入空间", "title_en": "PepCompass: Navigating peptide embedding spaces using Riemannian Geometry", "authors": "Marcin Możejko,Adam Bielecki,Jurand Prądzyński,Marcin Traskowski,Antoni Janowski,Hyun-Su Lee,Marcelo Der Torossian Torres,Michał Kmicikiewicz,Paulina Szymczak,Karol Jurasz,Michał Kucharczyk,Cesar de la Fuente-Nunez,Ewa Szczurek", "background": "抗菌肽的发现面临肽空间庞大的规模和活性肽相对稀缺的挑战。生成模型可以提供连续的肽空间“地图”，但通常忽略了解码器诱导的几何形状，依赖于扁平的欧几里得度量，导致探索和优化缺乏效率。之前的基于流形的方法假设固定的内在维度，但在实践中对于肽数据来说效果不佳。为此，研究引入了PepCompass，一种考虑几何形状的肽探索和优化框架，旨在改进肽设计的效率和效果。", "innovation": "PepCompass引入了一种考虑几何形状的框架，定义了带稳定黎曼流形$\boldsymbol{\text{M}^{\text{κ}}}$，捕捉局部几何结构的同时确保计算稳定性。提出了一种局部探索方法第二阶黎曼布朗运动的有效采样，以及质点空间中的突变枚举，将梯度方向重新解释为离散的氨基酸替换。结合这两者形成了局部枚举贝叶斯优化（LE-BO），一种局部活性优化的高效算法。最后，引入了潜在最小化测地线搜索（PoGS），该方法在带有 enrich 属性的测地线上插值原型嵌入，使发现偏向种子肽，即活性有利的肽。实验证明PepCompass的有效性，PoGS产生了四个新的种子肽，之后的优化发现了25种具有广泛抗性的高度活性肽。这些结果表明，几何启发的探索为抗菌肽设计提供了新的强大范式。", "conclusion": "这些结果证实，几何信息驱动的探索为抗菌肽设计提供了强大的新范式，能够有效优化肽的活性和范围。PepCompass为肽空间提供了新的导航方式，显著提高了该领域的研究效率。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23117", "html_url": "https://arxiv.org/abs/2510.23117", "title": "Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction", "title_en": "Seeing Structural Failure Before it Happens: An Image-Based Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction", "authors": "Omer Jauhar Khan,Sudais Khan,Hafeez Anwar,Shahzeb Khan,Shams Ul Arifeen", "background": "PINNs正在因能力而受到关注，即在深度学习模型中嵌入物理定律，特别适用于具有有限数据的结构工程任务。本文旨在探索PINNs在预测小型意大利面桥梁重量方面的应用，这对理解简化结构模型的荷载极限和潜在失效模式具有重要意义。提供的结构参数通过手动或计算机视觉方法输入到模型中。研究使用了15个真实桥梁的数据集，通过增加样本数量到100个，得到了最佳模型的R²分数和平均绝对误差分别为0.9603和10.50个单位。从实际应用角度看，本文还提供了一个基于网络的界面，用于参数输入和预测，结果表明即使数据有限，PINNs也能提供可靠的结构重量估计，并可能帮助指导轻质桥梁设计的早期失效分析。", "innovation": "本文引入了一种新颖的架构——基于物理的柯尔莫哥洛夫阿诺德网络（PIKAN），结合了通用函数近似理论与物理洞察。与普通PINNs相比，PIKAN在网络架构中融合了物理约束，从而提高了模型的性能和准确性。", "conclusion": "研究结果表明，即使在数据有限的情况下，PINNs也能提供可靠的结构重量估计，并可能帮助指导轻质桥梁设计的早期失效分析。完整的数据和代码可以在这里找到：这个 https URL。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.17670", "html_url": "https://arxiv.org/abs/2510.17670", "title": "FLAME：基于即时边际样本探索的少样本本地化即时可适应的开放词汇目标检测", "title_en": "On-the-Fly OVD Adaptation with FLAME: Few-shot Localization via Active Marginal-Samples Exploration", "authors": "Yehonathan Refael,Amit Aides,Aviad Barzilai,George Leifman,Genady Beryozkin,Vered Silverman,Bolous Jaber,Tomer Shekel", "background": "开放词汇对象检测（OVD）模型通过任意文本查询提供了显著的灵活性，但它们在特定领域如遥感（RS）中的零-shot 表现常常被自然语言固有的模糊性所限制，从而阻碍了关键的应用程序。例如，在区分“渔船”和“游艇”这类细粒度类时，模型可能会因为它们的嵌入相似而难以区分，这会妨碍特定用户目标，如监测非法捕鱼等，导致无关的检测结果。因此，需要一种方法来克服这些限制，使OVD模型在特定领域（如遥感）中的零-shot 表现达到实际应用的需求。", "innovation": "本文提出了一种级联方法，将大型预训练的OVD模型的广泛泛化与实时训练的轻量级少样本分类器相结合。该方法首先利用零-shot模型生成高召回率的对象提案，然后通过仅在少量用户注释的示例上训练的紧凑型分类器进行精度优化。核心是FLAME，一种一步式主动学习策略，能够在即时过程中选择最具信息性的样本进行训练。FLAME通过密度估计即时识别决策边界附近的不确定边际候选样本，并通过聚类确保样本多样性。这种方法实现高效抽样，无需昂贵的全模型微调，允许在几分钟内即时适应，比现有最先进的技术要快得多。方法在遥感基准测试中持续超越最先进的表现，形成了一个实用且资源高效的框架，用于适应基础模型以满足特定用户需求。", "conclusion": "本文提出了一种即时可适应的OVD框架——FLAME，通过少样本本地化和主动学习策略优化了遥感领域的零-shot性能。FLAME在实例级遥感基准测试中优于现有方法，为OVD模型在针对性别的应用中提供了有用的指导，同时显著提高了模型的适应性和效率。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04237", "html_url": "https://arxiv.org/abs/2510.04237", "title": "带有球面径向基函数的广义损失截断核随机梯度下降", "title_en": "Truncated Kernel Stochastic Gradient Descent with General Losses and Spherical Radial Basis Functions", "authors": "Jinhui Bai,Andreas Christmann,Lei Shi", "background": "本文提出了一种针对大规模监督学习中一般损失函数的新型核随机梯度下降（SGD）算法。相较于传统的核SGD，该算法通过一种创新的正则化策略提高了效率和可扩展性。这种策略利用球面径向基函数的无限级数展开，将随机梯度投影到一个可自适应调整大小的有限维假设空间，以此增强泛化性能。此外，基于对核诱导协方差算子光谱结构的新估计，建立了统一优化和泛化分析的理论框架。该框架适用于包括最小二乘法、Huber损失和逻辑损失在内的多种经典损失函数。", "innovation": "本文的创新点在于提出了一种结合了核随机梯度下降和截断技术的新型算法，以实现高效的大规模监督学习。该算法通过引入自适应调整尺寸的有限维假设空间，利用球面径向基函数的无限级数展开，从而提高了效率和可扩展性。同时，基于新的核诱导协方差算子光谱结构估计，建立了优化和泛化分析的理论框架，并证明了优化和泛化的最优收敛率。此外，该算法通过引入线性SGD的坐标更新策略，显著降低了计算复杂度，实现了最优存储复杂度，避免了传统核SGD中的昂贵对称运算，支持对流式数据的有效处理。", "conclusion": "本文证明了所提出的算法在各种经典损失函数下的最优收敛率，并通过广泛的数值实验验证了其效率。该算法在处理大规模监督学习问题时表现出色，特别是在提高计算效率和存储效率方面具有显著优势，为处理大规模和流式数据提供了有效的解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23639", "html_url": "https://arxiv.org/abs/2510.23639", "title": "将基因组学融入多模态电子健康记录基础模型", "title_en": "Integrating Genomics into Multimodal EHR Foundation Models", "authors": "Jonathan Amar,Edward Liu,Alessandra Breschi,Liangliang Zhang,Pouya Kheradpour,Sylvia Li,Lisa Soleymani Lehmann,Alessandro Giulianelli,Matt Edwards,Yugang Jia,David Nola,Raghav Mani,Pankaj Vats,Jesse Tetreault,T.J. Chen,Cory Y. McLean", "background": "该论文介绍了将多基因风险评分（PRS）整合到电子健康记录（EHR）基础模型中的创新方法。该模型利用All of Us（AoU）研究计划所提供的广泛且多元化的数据，超越了传统的仅依赖EHR的方法，构建了更为综合的健康概貌。这种方法旨在学习临床数据与遗传倾向之间复杂的关系，并利用生成式人工智能的进步增强预测能力和解析性。通过在AoU数据上的评估，证明了模型在各种条件的出现（尤其是2型糖尿病）预测价值，并展示了PRS与EHR数据之间的相互作用。此外，研究还探讨了转移学习在定制分类任务中的应用，展示了该架构的灵活性和效率。这项方法对于揭示新的疾病预测、积极健康管理、风险分层和个人化治疗策略等方面的关键见解起到了重要作用，为更个性化的、公平的、可行的实时证据生成在医疗保健领域奠定了基础。", "innovation": "论文提出了一种将PRS作为基础数据模态的EHR基础模型，通过AoU研究计划的大规模多样化数据，构建了多模态框架以学习临床数据与遗传倾向之间的复杂关系。利用生成式人工智能的进步，增强预测能力和解析性。通过转移学习进行定制分类任务，展示了架构的灵活性和效率，从而为个人化治疗策略提供支持，并为医疗保健领域的更个性化、公平和可行的实时证据生成奠定了基础。", "conclusion": "这种将基因组学融入多模态EHR基础模型的方法，对于疾病预测、风险分层和个性化治疗策略具有重要意义，是提高医疗保健过程中获取个人化、公平且可操作的实时证据的关键。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21038", "html_url": "https://arxiv.org/abs/2510.21038", "title": "安博士，我的亲爱的：非侵入性神经关键词识别在LibriBrain数据集中", "title_en": "Elementary, My Dear Watson: Non-Invasive Neural Keyword Spotting in the LibriBrain Dataset", "authors": "Gereon Elvers,Gilad Landau,Oiwi Parker Jones", "background": "非侵入性脑-计算机接口（BCIs）正在从大型公共基准数据中受益，但当前的基准主要针对简单的基础任务，如语音检测和音素分类，而诸如脑-文本等可应用任务的结果仍然难以实现。因此，需要一个既实用又能保护隐私的中间任务来填补这一空白。使用LibriBrain语料库，该论文提出关键词识别（KWS）作为这一任务的选择，并提供了可重复的基准数据集，同时采用新的评估协议以适应极端的类别不平衡问题，并使用AUPRC和固定召回率下的每小时假警报（FA/h）作为评价指标。这些措施简化了部署和进一步研究工作，降低了研究中的复杂性。", "innovation": "1. 提出了关键词识别（KWS）作为实践中实用又保护隐私的中间任务。\n2. 利用LibriBrain语料库中的52小时、同被试数据集，提供了一套标准的训练/验证/测试分割，以实现可复现的基准测试。\n3. 采用新的评估协议来处理极端类别不平衡问题，并使用AUPRC作为评价指标。\n4. 为简化部署，推出更新版本的pnpl库，包含单词级别数据加载器和Colab就绪教程。\n5. 提供一个小巧的1D卷积/残差网络基线模型，并展示了在单个消费级显卡上的可训练性。\n6. 开展初步研究分析，发现词级别因素（频率和时长）可以系统性地影响可检测性。", "conclusion": "关键词识别任务在LibriBrain数据集上的参考模型展示了其在实际应用场景中的可行性，并提供了性能随训练小时数呈对数线性增长的预期结果。这些发现表明，关键词识别可以作为从基础任务向复杂应用任务过渡的有效桥梁，为未来研究奠定了坚实基础。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.16629", "html_url": "https://arxiv.org/abs/2510.16629", "title": "关于机器遗忘中重训练等价性的不可能性", "title_en": "On the Impossibility of Retrain Equivalence in Machine Unlearning", "authors": "Jiatong Yu,Yinghui He,Anirudh Goyal,Sanjeev Arora", "background": "机器卸载试图选择性地移除特定训练数据对模型输出的影响。理想的目标是重训练等价性，即行为与仅使用保留数据从头开始训练的模型相同。这个目标最初针对独立同分布的数据批次进行训练的模型，但在现代训练管道中，通常涉及多阶段训练，每阶段的数据分布和目标都有所不同。例如，大型语言模型（LLM）的微调以实现对齐、推理能力等。研究表明，这种多阶段训练的过渡引入了机器卸载的基本障碍。理论表明，局部卸载的结果（仅使用忘记集上计算的梯度进行的方法）依赖于路径，即模型在卸载期间的行为受其在训练期间各阶段顺序的影响，使得路径盲目的算法无法普遍实现重训练等价性。", "innovation": "这项研究通过理论和实验展示了，从单阶段训练转向多阶段训练会使得当前的局部卸载算法无法实现重训练等价性。研究表明，虽然在LLM中采用梯度上升、NPO和SimNPO局部卸载算法，不同训练阶段顺序得到的模型在卸载过程中的表现差异显著，GSM8K准确度的降级差异超过20%。此外，路径依赖也影响了模型在卸载过程中如何处理概率质量，将其压缩到同义句或替代概念中。这些结果不一致地表明，只要目标模型分阶段进行训练，重训练等价性是局部卸载算法难以实现的目标。在难以获取模型训练历史的情况下，这项工作呼吁重新思考机器卸载的定义和目标。", "conclusion": "当难以访问模型的训练历史时，当前工作呼吁重新思考机器卸载的定义和目标。研究结果一致表明，在模型分阶段训练的情况下，重训练等价性对于局部卸载算法而言是一个不适当的靶标。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2411.12995", "html_url": "https://arxiv.org/abs/2411.12995", "title": "超越似然比偏置：多层次时间尺度随机逼近在无似然估计参数中的应用", "title_en": "Beyond likelihood ratio bias: Nested multi-time-scale stochastic approximation for likelihood-free parameter estimation", "authors": "Zehao Li,Zhouchen Lin,Yijie Peng", "background": "本文研究了基于模拟的随机模型中的参数推断问题，其中似然函数的具体形式未知。主要困难在于，作为噪音蒙特卡洛估计器比率的得分评估可能会导致偏差和不稳定性。", "innovation": "本文提出了一种比率无、多层次时间尺度（NMTS）随机逼近（SA）方法，该方法能够同时追踪得分并驱动参数更新，从而解决了无似然推断问题，并提供了该NMTS算法的全面理论分析，包括强收敛性、渐近正态性和收敛速率。", "conclusion": "实验结果表明，与传统的似然方法相比，该算法能在相同计算成本下提高估计精度1到2个数量级，使得它在随机系统参数估计中更为高效。此外，通过适当选择步长参数，该算法的收敛速度可以匹配多时间尺度SA文献中的最优速率。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.10361", "html_url": "https://arxiv.org/abs/2505.10361", "title": "塑性作为赋能的镜像", "title_en": "Plasticity as the Mirror of Empowerment", "authors": "David Abel,Michael Bowling,André Barreto,Will Dabney,Shi Dong,Steven Hansen,Anna Harutyunyan,Khimya Khetarpal,Clare Lyle,Razvan Pascanu,Georgios Piliouras,Doina Precup,Jonathan Richens,Mark Rowland,Tom Schaul,Satinder Singh", "background": "代理是受先前观察影响并作用于未来观察的最小实体。赋能作为一种重要的框架概念，在人工智能和认知科学研究中起到了关键作用。然而，代理受自身观察的影响也同等重要，背景部分着重探讨了代理如何以及在多大程度上被其观察所影响。", "innovation": "定义了一个普遍的代理中心度量——塑性(plasticity)，并揭示了它与赋能的基本联系。通过引入一种新的信息量度——广义定向信息，定义了塑性。此外，研究发现塑性与赋能互为镜像，这表明在设计代理时必须同时考虑这两种特性。", "conclusion": "研究结果表明塑性、赋能及其关系对于理解自主性至关重要，表明在设计代理时需要平衡这两方面的特性。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04852", "html_url": "https://arxiv.org/abs/2503.04852", "title": "Causal3D: 从视觉数据中进行因果学习的综合基准", "title_en": "CAUSAL3D: A Comprehensive Benchmark for Causal Learning from Visual Data", "authors": "Disheng Liu,Yiran Qiao,Wuche Liu,Yiren Lu,Yunlai Zhou,Tuo Liang,Yu Yin,Jing Ma", "background": "真正的智能依赖于发现和利用隐藏的因果关系的能力。尽管人工智能和计算机视觉取得了显著进展，但缺乏评估模型从复杂视觉数据中推断潜在因果关系能力的基准。本文旨在填补这一空白，引入了一个结合结构化数据（表格）与相应视觉表示（图像）的基准Causal3D，以评估因果推理能力。", "innovation": "Causal3D 是一个综合的基准，包括 19 个 3D 场景数据集，涵盖了多样的因果关系、视角和背景，使得在不同复杂程度的场景中进行评估成为可能。该基准涵盖了因果发现的经典方法、因果表示学习以及大型/视觉-语言模型等多种最先进的方法的评估。实验结果显示，随着因果结构变得更加复杂且缺乏先验知识时，性能急剧下降，突显了在复杂因果场景中先进方法面临的挑战。", "conclusion": "Causal3D 作为 CV 和可信赖 AI 领域中因果推理发展的宝贵资源，为推动因果推理的发展起到了重要作用。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.02331", "html_url": "https://arxiv.org/abs/2502.02331", "title": "二元随机变量中表现风险最小化的影响", "title_en": "On the Impact of Performative Risk Minimization for Binary Random Variables", "authors": "Nikita Tsoy,Ivan Kirev,Negin Rahimiyazdi,Nikola Konstantinov", "background": "背景：表现性现象指的是结果受到预测影响的现象，尤其在社会环境中更为明显，个体们通过策略性地响应模型来作出反应。为了在表现性导致的数据分布变化下保持机器学习模型的高度准确性，Perdomo等（2020）提出了表现性风险最小化（PRM）的概念。尽管PRM确保了模型的准确性，但没有考虑到PRM对底层分布和模型预测的影响。", "innovation": "创新：本文首次对PRM的影响进行了系统分析，尤其研究了二元随机变量下的顺序表现性风险最小化问题，并提出了两个自然的影响度量方法。还阐述了在完全信息（已知分布动态）和部分信息情况下，PRM的解和影响度量方法，提供了表现性感知的统计估计方法并进行了模拟。", "conclusion": "结论：本文分析对比了PRM与不建模数据转移的方法，指出PRM可能导致更大的副作用。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.00706", "html_url": "https://arxiv.org/abs/2502.00706", "title": "大型语言模型模型源测试", "title_en": "Model Provenance Testing for Large Language Models", "authors": "Ivica Nikolic,Teodora Baluta,Prateek Saxena", "background": "大型语言模型越来越依赖于微调和其他适应性技术进行定制，这带来了在执行许可条款和管理下游影响方面的挑战。追踪模型的来源对于保护知识产权以及在发现基础模型中的偏见或漏洞时识别派生模型至关重要。这项研究通过开发一种用于测试模型来源的框架来应对这一挑战。观察到现实中的模型派生会保留模型输出中显著的相似性，通过统计分析可以检测到这些相似性。", "innovation": "研究基于黑盒访问模型的方法，通过多次假设检验将模型相似性与基于不相关的模型建立的基线进行比较。在两个覆盖从小于30M到4B参数、包含超过600个模型的全面真实基准测试上，测试器在识别派生模型方面实现了90-95%的精确率和80-90%的召回率。这项工作展示了在仅提供API访问的情况下，系统化来源验证在实际环境中的可行性。", "conclusion": "即使仅具有API访问，通过开发的框架也能够实现高精度和召回率，从而验证模型来源。研究表明，此类系统化验证技术在实际生产环境中是可行的。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.04492", "html_url": "https://arxiv.org/abs/2503.04492", "title": "基于可解释机器学习的选择性重要特征预测带隙精确模型", "title_en": "Accurate predictive model of band gap with selected important features based on explainable machine learning", "authors": "Joohwi Lee,Kaito Miyamoto", "background": "在快速发展的材料信息学领域，非线性机器学习模型已被证明具有出色的预测材料性能的能力。然而，它们的黑盒性质限制了可解释性，并且可能包含了对模型性能没有贡献甚至有害的特征。本研究使用可解释的机器学习（XML）技术，包括置换特征重要性和SHapley值贡献性来评估一个用18个输入特征在GW水平上预测带隙的纯正支持向量回归模型。", "innovation": "研究提出了由XML衍生的重要特征指导构建的简化预测模型框架。通过去除高度相关的特征（相关系数大于0.8）来防止对特征重要性的误解和高估。结果显示，由前五个重要特征组成的简化模型在领域内数据集上的准确度与原始模型相当（0.254 vs. 0.247 eV），但在领域外数据集上具有更好的泛化能力，预测误差更低（0.461 vs. 0.341 eV）。", "conclusion": "研究强调了XML在通过澄清特征角色开发简化但高度准确的机器学习模型方面的有效性，从而降低了特征获取的计算成本并提升了材料发现模型的可信度。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2502.04380", "html_url": "https://arxiv.org/abs/2502.04380", "title": "多样性作为奖励：在未确定领域的数据混合中对LLM进行微调", "title_en": "Diversity as a Reward: Fine-Tuning LLMs on a Mixture of Domain-Undetermined Data", "authors": "Zhenqing Ling,Daoyuan Chen,Liuyi Yao,Qianli Shen,Yaliang Li,Ying Shen", "background": "在使用大规模语言模型（LLMs）时，通过多样化的数据集进行微调对于提升其在各种领域的综合性能至关重要。现有的方法主要通过建模数据构成的混合比例来实现这一目标，但在实际应用中，这些问题的数据域标签往往缺失、不精确或未规范化，此时这些方法会遇到困难。另一种基于数据选择的方法则难以在多域之间实现性能的平衡。为解决这些问题，本文通过构建对比数据池并进行理论上的解释来研究数据多样性在提升LLMs整体能力中的作用。通过实验证明，所提出的方法能够显著提升各种先进LLMs在未确定领域的数据和一系列基础下游任务上的性能。", "innovation": "本文提出了一种新的方法，赋予LLM双重身份：一个输出模型用于基于多样性奖励认知探究和选择数据，另一个输入模型则用于与所选数据进行调优。这种新方法通过构建对比数据池并结合理论分析，可以在未确定领域的数据集以及一系列基础下游任务中显著提升LLMs的性能，尤其适用于多域性能平衡问题。", "conclusion": "本文通过实验证实了所提方法的有效性，并期望该研究能对理解数据多样性提供新的见解，并推动基于反馈的数据-模型联合设计方法的发展。同时，作者发布了相关代码以供进一步研究使用。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2503.03710", "html_url": "https://arxiv.org/abs/2503.03710", "title": "使用双重目标优化改进大语言模型安全性对齐", "title_en": "Improving LLM Safety Alignment with Dual-Objective Optimization", "authors": "Xuandong Zhao,Will Cai,Tianneng Shi,David Huang,Licong Lin,Song Mei,Dawn Song", "background": "现有的针对大语言模型在训练过程中防止安全风险的技术仍然容易遭受监狱突破攻击。Direct preference优化（DPO）作为一种广泛应用的安全对齐方法，在实验和理论背景下都显示出限制，其损失函数对拒绝学习的效果不佳。通过基于梯度的方法分析，发现了这些不足，并提出了一种改进的安全对齐方法，将DPO目标分解为两个部分：（1）鲁棒拒绝训练，即使部分不安全生成的内容被产生时，也能鼓励拒绝；（2）有害知识的有针对的忘记。这种方法显著提高了大语言模型在多种场景下的鲁棒性，包括填充、后缀和多回合攻击，并且适用于分布内和分布外的情况。此外，还引入了一种通过奖励机制对拒绝学习进行关键拒绝标记的重视，并进一步提高了对抗攻击的鲁棒性。研究还表明，对监狱突破攻击的鲁棒性与训练过程中标记分布的变化以及拒绝和有害标记的内部表示有关，为未来的LLM安全对齐研究提供了有价值的方向。", "innovation": "提出了改进的安全对齐方法，将DPO目标分解为鲁棒拒绝训练和有针对性的忘记有害知识两部分，通过梯度分析识别DPO的不足；引入了基于奖励机制的拒绝标记重视方法，以进一步改善防御对抗式攻击的鲁棒性。", "conclusion": "提出了双重目标优化方法来改善大语言模型的安全性对齐，显著提高了模型抵御多种监狱突破攻击的鲁棒性，并指出标记分布变化和拒绝有害标记的内部表示与鲁棒性存在关联，为未来研究提供了指导。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11329", "html_url": "https://arxiv.org/abs/2505.11329", "title": "TokenWeave: 优化分布式大语言模型推理中的计算-通信重叠", "title_en": "TokenWeave: Efficient Compute-Communication Overlap for Distributed LLM Inference", "authors": "Raja Gond,Nipun Kwatra,Ramachandran Ramjee", "background": "分布式推理大语言模型（LLMs）即使在网络连接速度极快的GPU（如NVLink）之间，也会引入高达20%的附加开销。目前有多项技术通过细化计算任务以小任务的形式并根据子任务完成情况重叠通信，但这种方法会在细粒度分解大规模计算成多个小额计算后引入新的开销，并且通信本身会使用许多流式多处理器（SMs），进一步增加开销。", "innovation": "TokenWeave通过一种Token-Splitting技术，按波形智能方式将推理批次内的tokens分成两个大致相当的子集。通信其中一个子集，同时使用另一个子集进行计算。此外，TokenWeave优化了层归一化（Layer Normalization）计算顺序以适应通信操作，并实现了一种新的集成了AllReduce--RMSNorm内核，高效利用NVIDIA Hopper和Blackwell GPU的Multimem指令支持，使得通信和RMSNorm仅使用2-8个SMs。这种方法不仅允许计算和RMSNorm运算进行重叠，还实现了内存受限的RMSNorm的重叠操作。", "conclusion": "评估结果表明，TokenWeave在多个模型和工作负载中分别实现了最高达1.29倍的延迟和1.26倍吞吐量的提升。在某些情况下，TokenWeave的性能甚至优于没有通信的所有子集的等效模型。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.02820", "html_url": "https://arxiv.org/abs/2505.02820", "title": "AutoLibra: 基于开放性人类反馈的代理指标归纳", "title_en": "AutoLibra: Agent Metric Induction from Open-Ended Human Feedback", "authors": "Hao Zhu,Phil Cuvin,Xinkai Yu,Charlotte Ka Yee Yan,Jason Zhang,Diyi Yang", "background": "传统的代理评估主要依赖于粗略的任务成功指标，这些指标需要专家手动设计，并且无法奖励中间的新兴行为。这导致了评估的局限性和偏差。因此，需要一种新的方法来评估和优化代理的行为，使其能够更好地适应复杂的任务环境并奖励细腻的行为表现.", "innovation": "本文提出了AutoLibra框架，将开放性的用户反馈转换为评估代理轨迹中细腻行为的指标。AutoLibra通过将反馈与代理行为相关联，对相似的行为进行聚类，并创建具有明确定义和具体示例的度量标准，进而用于引导基于语言模型的智能评估系统。此外，作者提出了两个元度量标准：涵盖性和冗余性，用于评估一组（诱导的）度量标准与开放反馈的一致性。通过优化这些元度量标准，AutoLibra能够诱导出比以往代理评估基准中提出的度量标准更加具体的评估指标，并发现新的评估代理的方法。研究结果表明，AutoLibra是一种强大的通用工具，可用于评估和改进语言代理的性能.", "conclusion": "通过优化AutoLibra中的元度量标准，研究团队成功地诱导出了一系列特定于任务的评估指标，用于评估和改善语言代理的表现。AutoLibra不仅能够帮助人类提示工程师通过迭代改进代理的行为，还可以引导代理进行自我调节以优化自身表现。因此，AutoLibra具有重要的理论和实践价值，为其在代理评估和改进领域的应用奠定了基础。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11542", "html_url": "https://arxiv.org/abs/2505.11542", "title": "基于深度自编码器的UEBA框架的网络安全威胁检测", "title_en": "Cybersecurity threat detection based on a UEBA framework using Deep Autoencoders", "authors": "Jose Fuentes,Ines Ortega-Fernandez,Nora M. Villanueva,Marta Sestelo", "background": "UEBA作为一种数据分析师领域的广泛分支，旨在构建正常行为特征以检测异常事件。在用于检测异常的技术中，深度自编码器是最有前景的深度学习模型之一，尤其适合UEBA任务，能够提供可解释的安全事件检测方法，从而预防个人数据泄露、系统被劫持或访问敏感商务信息等事件的发生。", "innovation": "本研究提出了第一个利用深度自编码器结合Doc2Vec处理数值和文本特征的可解释UEBA基础异常检测框架。此外，基于神经网络的理论基础，提供了一个新颖的证明，证明了广泛使用的两个全连接神经网络定义的等价性。实验证明所提出框架能够有效检测真实和合成的异常，这些异常从真实攻击数据中产生，不仅能够正确识别异常，还能提供可解释的结果，使异常的可能来源得以重构。研究结果表明，提出的UEBA框架能够无缝集成到企业环境中，补充现有的安全系统，以实现可解释的威胁检测.", "conclusion": "研究发现提出的UEBA框架能够在企业环境中无缝集成，补充现有的安全系统，实现可解释的威胁检测。该框架利用深度自编码器有效检测真实和合成的异常，并能够提供可解释的结果用于理解异常的来源。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.11730", "html_url": "https://arxiv.org/abs/2505.11730", "title": "重新思考对于计算效率的测试时缩放（TTS）最适验证粒度", "title_en": "Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling", "authors": "Hao Mark Chen,Guanxi Lu,Yasuyuki Okoshi,Zhiwen Mo,Masato Motomura,Hongxiang Fan", "background": "测试时缩放（TTS）已被证明可以增强大型语言模型（LLMs）的推理能力，而验证在TTS中扮演着关键角色，它同时也影响推理性能和计算效率，取决于验证的质量和计算成本。传统上，验证通常只关注最终输出或每个生成步骤。", "innovation": "本文挑战了传统的验证范式，首次系统地探讨验证粒度的影响，即验证器在生成过程中被调用的频率。为实现这一目标，引入了可调粒度搜索（VG-Search）算法，该算法统一了Beam搜索和Best-of-N采样，并通过调节参数g实现这一功能。实验结果显示动态选择g可以提高计算效率和扩展行为。基于这些发现，提出了一种适应性VG-Search策略，相比Beam Search和Best-of-N，该策略分别提高了3.1%和3.6%的准确率，同时减少了大量的FLOPs（浮点运算次数）.", "conclusion": "研究发现VG-Search算法通过动态调节验证频率g，实现了更高的计算效率，同时保持或提高准确率。此外，该研究还提供了适应性VG-Search策略的代码，以支持未来的研究工作。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12191", "html_url": "https://arxiv.org/abs/2505.12191", "title": "去掉去噪器：基于数据课程序列的自监督学习中的噪声鲁棒性涌现", "title_en": "Ditch the Denoiser: Emergence of Noise Robustness in Self-Supervised Learning from Data Curriculum", "authors": "Wenquan Lu,Jiaqi Zhang,Hugues Van Assel,Randall Balestriero", "background": "自监督学习（SSL）已成为从未标记数据中提取丰富表示的强大解决方案，但大多数SSL研究主要集中在干净、整理过的和高质量的数据集上。因此，在噪声数据上的应用仍然具有挑战性，尽管在天文学、医学影像、地球物理学或金融等领域至关重要。", "innovation": "本文提出了一种全自监督框架，无需在推理或下游微调阶段使用去噪器，即可实现噪声鲁棒性表示学习。该方法首先在有噪声数据上训练一个SSL去噪器，然后用它构造一个去噪至噪声数据课程（即，先使用去噪样本，再使用噪声样本进行预训练）。此外，引入了教师引导正则化，将噪声嵌入与去噪版嵌入关联起来，这鼓励模型内化噪声鲁棒性。值得注意的是，去噪器可以在预训练阶段丢弃，简化了部署。在极端高斯噪声条件（σ=255，信噪比=0.72 dB）下，ImageNet-1k与ViT-B数据集上，该方法比DINOv2提高了4.8%的线性探针精度，证明了无需去噪器即可实现噪声鲁棒性。", "conclusion": "通过基于数据课程序列的噪声感知预训练，可以在不使用去噪器的情况下实现自监督学习的噪声鲁棒性，提高了模型在噪声数据上的性能。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2505.12371", "html_url": "https://arxiv.org/abs/2505.12371", "title": "MedAgentBoard: 通过与传统方法基准测试评估多元医疗任务的多智能体协作", "title_en": "MedAgentBoard: Benchmarking Multi-Agent Collaboration with Conventional Methods for Diverse Medical Tasks", "authors": "Yinghao Zhu,Ziyi He,Haoran Hu,Xiaochen Zheng,Xichen Zhang,Zixiang Wang,Junyi Gao,Liantao Ma,Lequan Yu", "background": "大语言模型（LLMs）的快速进步激发了对多智能体协作应用于复杂医疗任务的兴趣。然而，多智能体协作的优势仍然缺乏充分理解，现有的评估往往缺乏通用性，未能涵盖多样化的任务，这些任务能够反映真实的临床实践，并且经常省略了对单LLM方法和传统方法的严格比较。因此，迫切需要一种综合基准来系统地评价多智能体协作、单LLM和传统方法。MedAgentBoard正是为此目的引入的，它涵盖了四种多样的医疗任务类别，包括医学（视觉）问答、普通摘要生成、结构化电子健康记录（EHR）预测建模以及临床工作流程自动化，涉及文本、医学影像和结构化的EHR数据。这些实验揭示了一种精细的格局：虽然多智能体协作在某些特定情况下具有优势，如在临床工作流程自动化方面提高任务完整性，但在诸如文本医学问答等领域并不总是优于先进的单LLM或传统的专业化方法。进一步的是，它在医疗视觉问答和基于EHR的预测方面通常保持更好的性能。这表明，多智能体协作的固有复杂性和成本需要谨慎权衡以实现实际的性能提升。", "innovation": "MedAgentBoard提供了一个全面的基准，用于系统地评估多智能体协作、单LLM和传统方法。它包括四种多样的医疗任务类别，涵盖广泛的医疗数据和应用场景。MedAgentBoard通过系统评估多智能体协作、单LLM和传统方法的性能，突出其特定任务的必要性，并提供任务特定的、基于证据的方法来选择和开发医疗AI解决方案。其开放源代码的代码、数据集、详细的提示和实验结果使得研究透明化。", "conclusion": "MedAgentBoard提供了一个关键资源和可操作的见解，强调了在医疗中选择和开发AI解决方案时进行特定任务的证据基于方法的重要性。这凸显出多智能体协作的实际性能提升必须仔细权衡其固有的复杂性和成本。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.21513", "html_url": "https://arxiv.org/abs/2510.21513", "title": "LLM组集在代码生成和修复中的智慧与幻觉", "title_en": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair", "authors": "Fernando Vallecillos-Ruiz,Max Hort,Leon Moonen", "background": "当前追求一种单一的大语言模型（LMM）来完成所有软件工程任务需要大量的资源，并且忽视了不同模型之间的互补性。不同模型可以贡献独特的强项，但编码LMMs之间的互补性以及如何利用组集最大化潜在性能的最佳策略尚不清楚。这使得从业者缺乏一条明确的道路来超越单一模型系统。", "innovation": "本研究通过实证比较来自五个家族的十个单独LMM和三个这些LMM的组集，跨越涵盖代码生成和程序修复的三项软件工程基准。评估了模型之间的互补性以及最佳个体模型与组集之间的性能差距，并评估了各种选择启发式方法来从组集的候选池中选择正确解。研究发现，组集的理论上限性能可以比最佳单个模型高出83%。基于共识的选择策略落入了“流行陷阱”，放大了常见的但错误的输出；相反，基于多样性的策略可以实现理论潜力的95%，并有效地适用于小的两模型组集，从而通过利用多个LMM实现成本效益的性能提升。", "conclusion": "研究结果表明，基于多样性的策略可以有效利用LMM组集的优势，甚至在小型组集中也能实现高效的性能提升，为多层次利用LMM提供了一种实际可行的方法。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23534", "html_url": "https://arxiv.org/abs/2510.23534", "title": "通过Bregman距离最小化实现直接去偏机器学习", "title_en": "Direct Debiased Machine Learning via Bregman Divergence Minimization", "authors": "Masahiro Kato", "background": "该领域的论文背景主要是关于因果效应或结构模型中参数的本质依赖于假设的回归函数。直接估计回归函数可能会导致初始阶段的偏差，这会影响估计的效果。传统的去偏机器学习方法通过Neyman正交估计算法来减轻这种偏差。然而，这些方法通常需要估计Riesz代表元和回归函数，过程较为复杂且依赖于目标的具体模型。", "innovation": "该研究提出了一种直接去偏机器学习框架，结合了Neyman目标估计和广义Riesz回归。该框架不仅统一了Riesz回归、协变量平衡、目标最大似然估计算法(TMLE)和密度比率估计，还提供了一种端到端的算法来直接估计鲁棒的回归函数和Riesz代表元，其中使用Bregman距离来衡量不一致性，涵盖平方损失和KL散度损失函数。", "conclusion": "该研究通过最小化Bregman距离实现了直接去偏的机器学习框架，不仅有效减少了第一阶段的偏差，还能够在某些特定条件下自动获得协变量平衡的性质，简化了去偏机器学习的实现过程，并提供了解决复杂问题的新思路。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.14904", "html_url": "https://arxiv.org/abs/2510.14904", "title": "MaskCaptioner：学习在视频中联合分割和描述对象轨迹", "title_en": "MaskCaptioner: Learning to Jointly Segment and Caption Object Trajectories in Videos", "authors": "Gabriel Fiastre,Antoine Yang,Cordelia Schmid", "background": "Dense Video Object Captioning (DVOC) 是一项复杂的任务，涉及在视频中联合检测、跟踪和描述对象轨迹，需要理解时空细节并与自然语言描述。由于任务的复杂性和手动标注的高成本，此前的方法大多采用分离训练策略，可能造成性能不佳。", "innovation": "本研究提出利用最先进的视觉语言模型生成关于时空局部化实体的描述，从而扩展 LVIS 和 LV-VIS 数据集（LVISCap 和 LV-VISCap）。通过这些增强的数据集训练了一个端到端的 MaskCaptioner 模型，该模型能够在检测、分割、跟踪和描述对象轨迹方面实现联合任务。MaskCaptioner 在 VidSTG、VLN 和 BenSMOT 等三个现有基准上的表现达到了最先进的效果。", "conclusion": "MaskCaptioner 模型通过对带有合成描述的数据集进行预训练，展示了在 DVOC 任务上的优越性能，并且数据集和代码已经公开可用。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2509.24257", "html_url": "https://arxiv.org/abs/2509.24257", "title": "VeriLLM：一种轻量级的公开可验证分布式推理框架", "title_en": "VeriLLM: A Lightweight Framework for Publicly Verifiable Decentralized Inference", "authors": "Ke Wang,Zishuo Zhao,Xinyuan Song,Bill Shi,Libin Xia,Chris Tong,Lynn Ai,Felix Qu,Eric Yang", "background": "去中心化的推理提供了可扩展和健壮的大型语言模型（LLM）服务范式，能够实现资源的分布式利用并减少对集中式提供商的依赖。然而，在未受信任节点的开放环境中，确保模型输出的正确性仍然是一项核心挑战。", "innovation": "我们引入了VeriLLM，这是一种在假设只有一个诚实验证者的情况下实现安全性的公开可验证协议，同时保持了实际的高效性。VeriLLM结合了轻量级的经验重运行与密码学承诺，使验证者能够以约1%的底层推理成本验证结果。为了防止验证瓶颈，我们设计了一种同构的推理-验证架构，使推理和验证角色能够在相同的GPU工作者上复用。这种设计：（i）提高了GPU利用率和整体吞吐量，（ii）扩大了有效的验证者集合，增强了系统的健壮性和活跃性，（iii）防止节点特定优化或选择性行为。", "conclusion": "通过理论分析和系统级评估，我们展示了VeriLLM能够以最小的开销实现可靠的公开可验证性，为其提供了可信和可扩展的去中心化大型语言模型推理的实用基础。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.22319", "html_url": "https://arxiv.org/abs/2510.22319", "title": "GRPO-Guard:通过受控剪切缓解流匹配中的隐式过度优化", "title_en": "GRPO-Guard: Mitigating Implicit Over-Optimization in Flow Matching via Regulated Clipping", "authors": "Jing Wang,Jiajun Liang,Jie Liu,Henglin Liu,Gongye Liu,Jun Zheng,Wanyuan Pang,Ao Ma,Zhenyu Xie,Xintao Wang,Meng Wang,Pengfei Wan,Xiaodan Liang", "background": "最近，基于GRPO的强化学习在优化流匹配模型方面取得了显著进展，有效提高了模型与特定任务奖励的一致性。然而，在实践中，研究者们观察到重要性比率分布出现系统性偏移——其均值低于1，方差在时间步之间差别显著。这种偏移导致正优势样本无法进入剪切区域，使得机制无法有效约束正向更新的过度自信。因此，政策模型不可避免地进入隐式的过度优化阶段，尽管代理奖励继续增加，但诸如图像质量和文本提示对齐等关键指标急剧下降，使所学策略在实际应用中变得不切实际。", "innovation": "我们提出了GRPO-Guard，一种简单而有效的增强现有GRPO框架的方法。该方法引入了比率归一化，恢复了平衡的且步进一致的重要性比率，确保PPO剪切机制能够妥当地约束去噪时间步中的有害更新。此外，梯度重新加权策略使得在不同噪声条件下，策略梯度保持一致，防止特定时间步区域的过度更新。这些设计共同构成了一个受控剪切机制，稳定了优化过程，并显著减轻了隐式的过度优化，而无需依赖强大的KL正则化。", "conclusion": "在多种扩散模型基础上（如SD3.5M、Flux.1-dev）以及多种代理任务上的广泛实验表明，GRPO-Guard显著减少了过度优化，同时保持或甚至提高了生成质量。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.10728", "html_url": "https://arxiv.org/abs/2510.10728", "title": "粗糙路径签名：学习神经RDEs进行资产配置优化", "title_en": "Rough Path Signatures: Learning Neural RDEs for Portfolio Optimization", "authors": "Ali Atiah Alzahrani", "background": "本文主要讨论高维、路径依赖的估值和控制问题。对于这些复杂问题，传统的评测方法可能不再适用。因此，研究者们寻求新的方法来提高精度和稳定性。", "innovation": "本文创新地提出了一种结合截断对数签名与神经粗糙微分方程（RDE）骨干网的深度BSDE/2BSDE解算器。该架构将随机分析与序列到路径的机器学习方法相结合。引入了CVaR-倾斜的终端目标来瞄准左侧风险，并通过可选的第二级（2BSDE）头部提供曲率估计，以支持敏感风险控制。实验结果表明，该方法在亚洲和障碍期权定价及投资组合控制方面具有更高的准确度、尾部精度和训练稳定性。", "conclusion": "研究结果表明，粗糙路径签名与现代深度学习之间存在双向对话：随机工具指导表示和目标的选择，而序列到路径的模型则扩展了能够解决的金融模型的类别。进一步的消融实验验证了路径到序列表示和2BSDE头部的互补增益。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.08604", "html_url": "https://arxiv.org/abs/2510.08604", "title": "LatentBreak: 通过潜在空间反馈入侵大型语言模型", "title_en": "LatentBreak: Jailbreaking Large Language Models through Latent Space Feedback", "authors": "Raffaele Mura,Giorgio Piras,Kamilė Lukošiūtė,Maura Pintor,Amin Karbasi,Battista Biggio", "background": "禁软件（jailbreaks）是一种针对大型语言模型内置安全机制的敌对攻击。现有的自动禁软件方法通常优化敌对后缀或适应长提示模板，迫使模型生成受限制或有害的回应初始部分。现有研究显示，通过简单的困惑度（perplexity）筛选输入提示可以检测到这类禁软件攻击。面对这一挑战，本文提出了一种名为LatentBreak的白盒禁软件攻击方法，它生成自然的低困惑度敌对方言以绕过这些防御。", "innovation": "LatentBreak 白盒禁软件攻击通过在潜在空间中寻找与无害请求相似的单词来构建敌对方言，避免使用高困惑度的敌对后缀或长模板。这种方法生成的敌对方言具有较低的困惑度，从而能够在面对基于困惑度过滤器的防守时超越现有竞争对手。", "conclusion": "通过广泛的评估，本文展示了LatentBreak方法生成了更短且低困惑度的敌对方言。因此，相较于其他在困惑度过滤器基础上的防御措施，LatentBreak在多种对安全性对齐的模型中表现出更优异的效果。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.23216", "html_url": "https://arxiv.org/abs/2510.23216", "title": "在现实足球模拟中的类人守门员：一种样本高效强化学习方法", "title_en": "Human-Like Goalkeeping in a Realistic Football Simulation: a Sample-Efficient Reinforcement Learning Approach", "authors": "Alessandro Sestini,Joakim Bergdahl,Jean-Philippe Barrette-LaPierre,Florian Fuchs,Brady Chen,Michael Jones,Linus Gisslén", "background": "虽然一些著名的电子游戏曾用作深度强化学习（DRL）的测试平台，但这项技术很少被游戏行业用于创建真实的AI行为。现有的研究大多集中在使用大型模型训练超人的代理上，这对于资源有限的游戏工作室（如希望创建人类级别的代理）来说是不切实际的。本文提出了一个针对工业化设置，特别是视频游戏行业的样本高效的DRL方法，通过利用预先收集的数据并增加网络的可塑性来提高值基DRL的样本效率。", "innovation": "提出了一种样本高效的DRL方法，用于培训和微调工业环境下的代理，特别是在视频游戏行业中。该方法通过利用预收集的数据并增加网络的可塑性，提高了价值基DRL的样本效率。在EA SPORTS FC 25中，一种出名的足球模拟游戏中，经过训练的代理在扑救球的比率上比游戏内置的AI高出了10%。与标准DRL方法相比，该方法将代理的训练速度提高了50%。专家的定性评估表明，该方法生成的玩法更加接近于人类的操作方式。", "conclusion": "这种方法得到了肯定，被应用到了最近的游戏系列版本中，这一事实证明了方法的影响。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.05014", "html_url": "https://arxiv.org/abs/2510.05014", "title": "先思考后嵌入：生成性上下文改进多模态嵌入", "title_en": "Think Then Embed: Generative Context Improves Multimodal Embedding", "authors": "Xuanming Cui,Jianpeng Cheng,Hong-you Chen,Satya Narayan Shukla,Abhijeet Awasthi,Xichen Pan,Chaitanya Ahuja,Shlok Kumar Mishra,Yonghuan Yang,Jun Xiao,Qi Guo,Ser-Nam Lim,Aashu Singh,Xiangjun Fan", "background": "研究人员对通用多模态嵌入（UME）的兴趣日益增长，目标是生成任务特定的表示。尽管最近的研究表明，多模态大型语言模型（MLLMs）在这些任务上表现良好，但它们通常仅被视为编码器，忽视了其生成能力。然而，这种编码方式在复杂指令和需要组合推理的情况下变得不再有效。鉴于链式思考推理的有效性，提出了一个通用的思考后嵌入（TTE）框架，该框架由推理器和嵌入器组成，可以实现对复杂多模态指令的更细腻理解。", "innovation": "该研究通过以下几个方面进行创新：1) 利用强大的MLLM推理器，实现了MMEB-V2基准测试上的最先进的性能，超越了使用大规模内部数据集训练的专有模型；2) 为了降低对大型MLLM推理器的依赖，对一个较小的MLLM推理器进行微调，并使用高质量的嵌入中心推理追踪，实现了开源模型中最佳性能，相比最近提出的方法，绝对改进了7%；3) 探讨了将推理器和嵌入器整合到统一模型中的策略，以提高效率而不牺牲性能。", "conclusion": "通过这一跨学科的方法，研究提供了一种有效的方式，用于生成和理解复杂的多模态信息，展示了在既提高效率又保持性能的情况下集成强大推理和嵌入技术的潜力。"}
{"llm_update_time": "20251031", "topic": "cs.LG", "pdf_url": "https://arxiv.org/pdf/2510.04226", "html_url": "https://arxiv.org/abs/2510.04226", "title": "大型语言模型中的知识多样性与知识萎缩", "title_en": "Epistemic Diversity and Knowledge Collapse in Large Language Models", "authors": "Dustin Wright,Sarah Masud,Jared Moore,Srishti Yadav,Maria Antoniak,Chan Young Park,Isabelle Augenstein", "background": "现有的大型语言模型（LLMs）倾向于生成在词汇、语义和风格上高度一致的文本，这可能引发知识萎缩的风险，即随着时间的推移，同质化的LLMs会使获取信息的范围不断缩小。尽管存在一些针对同质性的研究，但这些研究主要集中在封闭式多项选择题设定或模糊语义特征上，未能涵盖跨时间与文化背景的趋势。为了克服这一局限，作者提出了一种新的测量方法来评估知识多样性，即LLM输出中关于真实世界的声明的变异性，并据此进行了广泛的经验研究，探讨了LLM知识的萎缩状况。", "innovation": "提出了新的测量方法来评估大型语言模型中知识多样性，即涵盖真实世界声明变异性的指标。通过对27种不同的LLM、155个话题（覆盖12个国家）及200种不同的提示进行了严格的测试，创新性地分析了模型尺寸、检索增强生成（RAG）技术等对知识多样性的影响，并发现跨不同文化背景时RAG带来的改进效果存在差异。", "conclusion": "研究表明，尽管较新的模型倾向于生成更加多样的声明，但几乎所有模型的知识多样性仍然低于基本的网络搜索水平。模型尺寸对知识多样性有负面影响，而检索增强生成则有积极影响，但这一影响在不同文化背景下程度不同。并且，与传统的知识来源（维基百科）相比发现，国家特定的陈述比实际更能反映英语语言，体现了知识表达上的差距。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26413", "html_url": "https://arxiv.org/abs/2510.26413", "title": "CI/CD流水线的环境影响", "title_en": "Environmental Impact of CI/CD Pipelines", "authors": "Nuno Saavedra,Alexandra Mendes,João F. Ferreira", "background": "CI/CD流水线在软件开发中广泛使用，但开发者通常不了解其环境影响，特别是碳足迹和水足迹。随着云计算环境影响的增加，理解CI/CD服务的环境足迹变得越来越重要。", "innovation": "研究基于Cloud Carbon Footprint框架的方法论，并使用迄今最大规模的工作流运行数据集，包含了来自超过18,000个仓库的220多万个工作流运行。结果表明，GitHub Actions生态系统的环境足迹显著，估计在2024年的碳足迹范围从最乐观的150.5 MTCO2e到最悲观的994.9 MTCO2e，水足迹范围从1,989.6到37,664.5千升。这些研究还探索了通过减少多余计算资源浪费来减轻这一影响的策略。", "conclusion": "GitHub Actions的环境足迹显著，通过调整地区、实施更严格的计划运行停用政策以及减少仓库大小等策略，可以减轻此影响。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26538", "html_url": "https://arxiv.org/abs/2510.26538", "title": "在大规模语言模型时代的软件工程研究中的实证和可持续性方面反思", "title_en": "Reflecting on Empirical and Sustainability Aspects of Software Engineering Research in the Era of Large Language Models", "authors": "David Williams,Max Hort,Maria Kechagia,Aldeida Aleti,Justyna Petke,Federica Sarro", "background": "软件工程（SE）研究中使用大型语言模型（LLMs）引入了关于基准测试的严格性、污染、可复制性和可持续性等方面的新挑战。本文探讨了这些挑战在SE领域中的应对方式，并对其进行了有组织的概述。", "innovation": "本文针对SE领域的LLM研究提出了加强基准测试的严格性、提高可复制性以及解决LLM基SE的财务和环境成本的建议。", "conclusion": "通过对ICSE中基于LLM的SE研究的现状进行了审视，指出了现有良好实践和持续不足之处，并提供了增强基准测试严格性、提高可复制性以及解决财务和环境成本的建议。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26457", "html_url": "https://arxiv.org/abs/2510.26457", "title": "SecureReviewer：通过安全意识微调增强大型语言模型进行安全代码审查", "title_en": "SecureReviewer: Enhancing Large Language Models for Secure Code Review through Secure-aware Fine-tuning", "authors": "Fang Liu,Simiao Liu,Yinghao Zhu,Xiaoli Lian,Li Zhang", "background": "在软件开发的早期阶段识别和解决安全问题对于减轻软件系统的长期负面影响至关重要。代码审查是一种有效的做法，它使开发者能够在将代码集成到代码库之前检查团队成员的代码。尽管提出了各种自动化代码审查方法，其中基于LLM的方法显著增强了自动化审查生成的能力，但现有模型主要集中在通用代码审查上，它们在识别和解决安全问题方面的有效性仍然未被充分探索。此外，将现有代码审查方法适应安全问题面临数据稀缺和评价指标不足等巨大挑战。", "innovation": "我们提出了SecureReviewer，一种新型方法，旨在增强LLMs在代码审查中识别和解决安全问题的能力。首先，我们构建了一个专门为训练和评估安全代码审查能力的数据集。通过此数据集，我们使用提出的安全意识微调策略微调LLMs，生成能有效识别安全问题并提供修复建议的审查评论。为了缓解LLM的幻觉并提高其输出的可靠性，我们整合了RAG技术，使生成的评论基于领域特定的安全知识。此外，我们引入了SecureBLEU，一个新评价指标，用于评估审查评论解决安全问题的有效性。", "conclusion": "实验结果表明，SecureReviewer在安全问题检测精度和生成的审查评论的整体质量和实际用处方面均优于最先进的基线方法。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26287", "html_url": "https://arxiv.org/abs/2510.26287", "title": "基于蒙特卡洛树搜索驱动的强化学习赋能RepoQA-Agent", "title_en": "Empowering RepoQA-Agent based on Reinforcement Learning Driven by Monte-carlo Tree Search", "authors": "Guochang Li,Yuchen Liu,Zhen Qin,Yunkun Wang,Jianping Zhong,Chen Zhi,Binhua Li,Fei Huang,Yongbin Li,Shuiguang Deng", "background": "背景：存储库级别的软件工程任务需要大语言模型（LLMs）通过多轮工具交互高效地导航和从复杂的代码库中提取信息。现有的方法存在局限性：即插即用的学习方法难以有效地指导代理基于环境反馈的工具利用和决策制定，而基于训练的方法通常依赖于从更大模型中进行代价昂贵的蒸馏，这在企业环境中引入了数据合规性问题。", "innovation": "创新：我们提出了基于蒙特卡罗树搜索（MCTS）驱动的强化学习框架RepoSearch-R1，这种自训练的方法不需要模型蒸馏或外部监督，使得代理能够生成多样化的高质量推理轨迹。基于RepoSearch-R1，我们构建了一个特定于仓库问题回答任务的RepoQA-Agent。全面评估显示，RepoSearch-R1在回答完整性方面的改进为：比无检索方法提高了16.0%，比迭代检索方法提高了19.5%，在训练效率方面提升了33%。冷启动训练方法消除了数据合规性问题，同时保持了在仓库级别推理任务中强大的探索多样性和回答完整性。", "conclusion": "结论：RepoSearch-R1框架通过消除数据合规性问题并且提供显著提升的回答质量和训练效率，为仓库级别的软件工程任务提供了一个有效的解决方案。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26516", "html_url": "https://arxiv.org/abs/2510.26516", "title": "自然语言驱动的未来交互式网页开发：使用自然语言编辑网页", "title_en": "Envisioning Future Interactive Web Development: Editing Webpage with Natural Language", "authors": "Truong Hai Dang,Jingyu Xiao,Yintong Huo", "background": "网页应用程序的演变依赖于迭代的代码修改，这一过程通常由人类手工完成且耗时较长。现有的大型语言模型（LLMs）能够生成用户界面代码，但它们在根据新的设计要求修改现有代码方面的能力（例如，“使LOGO居中”）依然有限。问题的主要根源在于缺乏大规模和高质量的调整数据集，以使模型的表现更加贴近人类的期望。", "innovation": "本文介绍了一种新的自动化数据生成管道，通过使用LLMs生成高质量的微调数据集以供网络编辑，命名为Instruct4Edit。该方法生成多样化的指令并应用相应的代码修改，通过视觉验证来确保正确性。通过在Instruct4Edit上微调模型，展示了在自然语言表达人类意图并转化为精确、结构连贯和视觉准确的代码更改方面取得的一致性改进。这一工作为基于自然语言的网络编辑提供了可扩展和透明的基础，表明微调小型开源模型可以达到与专有系统相当的性能。", "conclusion": "本文发布的所有数据、代码实现和模型检查点均可供其他研究人员复现，证明了基于自然语言的网络编辑是一个可行的方向，小型开源模型可以通过适当的微调达到与专有系统相近的效果。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26576", "html_url": "https://arxiv.org/abs/2510.26576", "title": "向我证明你合规……但不必向我展示任何东西：AI驱动系统中的零知识软件审计", "title_en": "\"Show Me You Comply... Without Showing Me Anything\": Zero-Knowledge Software Auditing for AI-Enabled Systems", "authors": "Filippo Scaramuzza,Renato Cordeiro Ferreira,Tomaz Maia Suller,Giovanni Quattrocchi,Damian Andrew Tamburri,Willem-Jan van den Heuvel", "background": "随着AI驱动系统在关键领域的广泛应用，信任问题变得至关重要，需要通过可验证的问责制来解决，这通常由法规（如欧盟AI法案）规定。传统软件验证和验证技术（如程序审核、形式方法或模型文档）被用来实现这一点，但这些方法要么成本高昂要么高度手动操作，并不适用于大多数AI模型的不透明、‘黑盒’性质。这种审计的透明性要求与保护被审计资产（如机密数据和专有模型）的需求之间产生了不可调和的冲突，导致问责制削弱。", "innovation": "本文提出了一种新颖的MLOps验证框架ZKMLOps，它利用零知识证明（ZKPs）技术，在机器学习操作生命周期中实现零知识证明。ZKMLOps通过结合现有的软件工程模式，提供了一个模块化和可重复的流程，用于生成合规性的可验证加密证明。", "conclusion": "通过金融风险审计中的监管合规性研究，评估了该框架的实用性和可行性。进一步通过实证评估顶级ZKP协议，分析了对于复杂度递增的ML模型的性能权衡。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26480", "html_url": "https://arxiv.org/abs/2510.26480", "title": "使用开源大语言模型实现自动化提取方法重构：一项比较研究", "title_en": "Automated Extract Method Refactoring with Open-Source LLMs: A Comparative Study", "authors": "Sivajeet Chand,Melih Kilic,Roland Würsching,Sushant Kumar Pandey,Alexander Pretschner", "background": "自动执行抽取方法重构（EMR）仍然是一个具有挑战性的任务，尽管它对于提高代码可读性和可维护性至关重要。尽管如此，开放源代码的大规模语言模型（LLMs）已经提供了新的有希望的自动化此类高层次任务的方法。目前，EMR仍然是一个主要依赖于人工操作的过程。", "innovation": "本研究对五种最新的开源LLMs进行了评估，涵盖了3B到8B的参数大小，以测试它们在Python代码上的EMR任务。研究通过比较一次性提示策略和递归批评与改进（RCI）方法，系统地评估了功能正确性和代码质量。结果显示，基于RCI的提示策略在测试通过率和重构质量上表现更优。最高表现的模型Deepseek-Coder-RCI和Qwen2.5-Coder-RCI分别达到了0.829和0.808的通过率百分比，同时减少了每方法的行数和循环复杂性。", "conclusion": "基于质量提示的自动化重构的优势得到了开发人员调查的支持，特别是Qwen2.5-Coder得分最高。相比之下，原始代码在可读性和可维护性方面得分较低，这进一步强调了自动化重构的重要性。传统指标如循环复杂性和行数提供有用的信息，但往往与人类判断有所分歧，这表明需要有人工干预的评估机制。该开放源代码基准为未来使用LLMs进行自动化重构的研究奠定了基础。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26275", "html_url": "https://arxiv.org/abs/2510.26275", "title": "增强软件工程过程和软件产品的生成型AI研究路线图", "title_en": "A Research Roadmap for Augmenting Software Engineering Processes and Software Products with Generative AI", "authors": "Domenico Amalfitano,Andreas Metzger,Marco Autili,Tommaso Fulcini,Tobias Hey,Jan Keim,Patrizio Pelliccione,Vincenzo Scotti,Anne Koziolek,Raffaela Mirandola,Andreas Vogelsang", "background": "生成型人工智能（GenAI）正在迅速改变软件工程（SE）的实践，影响着SE流程的执行以及软件系统的开发、运行和演化。本文采用设计科学的研究方法，为GENAI增强SE构建了研究路线图，该过程包含三个逐步整合多种证据的循环，其中包括FSE 2025“软件工程2030”研讨会的协作讨论、快速文献综述以及外部反馈会议。", "innovation": "在McLuhan的四元式概念工具的帮助下，该研究系统地捕捉了GenAI对SE流程和软件的转变影响，从而识别了SE中四大基本形式的GenAI增强，并系统地描述了相关研究挑战与机遇，最后提出了十条2030年的SE前景预测。研究过程中运用了严格的多循环过程，并独立作者团队和同行进行交叉验证，从而提供了一个透明且可复制的基础，用于分析GenAI如何影响SE流程、方法和技术，并为这一快速发展的领域内未来研究提供框架指导。", "conclusion": "该研究提出了一个基于严谨多循环过程的透明研究路线图，用于分析GenAI对SE流程、方法和技术的影响，并为快速变化的领域内未来研究提供指导框架。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26431", "html_url": "https://arxiv.org/abs/2510.26431", "title": "CHCVerif：基于组合求解器的约束合氏_clause求解器", "title_en": "CHCVerif: A Portfolio-Based Solver for Constrained Horn Clauses", "authors": "Mihály Dobos-Kovács(Department of Artificial Intelligence and Systems Engineering, Budapest University of Technology and Economics, Hungary),Levente Bajczi(Department of Artificial Intelligence and Systems Engineering, Budapest University of Technology and Economics, Hungary),András Vörös(Department of Artificial Intelligence and Systems Engineering, Budapest University of Technology and Economics, Hungary)", "background": "约束合氏 Clause（CHCs）被广泛采用作为多种验证任务的中间表示形式，包括安全性检查、不变式合成以及跨过程分析。当前的方法倾向于利用成熟的软件验证工具来处理CHC基准测试，尤其是涉及位向量和低级语义的测试场景。然而，这种方法在处理线性整数算术时仅取得了适度的成功，在位向量基准测试中的表现较为有限。同样重要的是，研究表明利用软件验证工具作为CHC求解的后端是可行的，并且具有潜在价值，特别是在通过精心构建的组合求解器进行支持时的特点更为突出.", "innovation": "CHCVERIF引入了一种基于组合求解器的方法来解决CHC问题，这种方法采用软件验证的方式处理CHC基准，特别是涉及到位向量和低级语义的测试场景。通过利用成熟的软件验证工具作为后端，CHCVERIF在处理位向量基准测试中的表现并不突出，但在线性整数算术的问题上也取得了一定的成功，这一方法对使用软件验证工具作为CHC求解的后端具有潜在价值和可行性，尤其当与精心构建的组合求解器结合时更为有效.", "conclusion": "研究结果表明，利用软件验证工具作为CHC求解的后端是可行的，并且具有很大的潜在价值，特别是在结合精心构建的组合求解器时。尽管这种方法在线性整数算术中的表现有限，但在位向量基准测试中获得了一定的成功，证明了这种组合方法的有效性与实用性."}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.26423", "html_url": "https://arxiv.org/abs/2510.26423", "title": "Nexus: 基于执行的多智能体测试基准生成", "title_en": "Nexus: Execution-Grounded Multi-Agent Test Oracle Synthesis", "authors": "Dong Huang,Mingzhe Du,Jie M. Zhang,Zheng Lin,Meng Luo,Qianru Zhang,See-Kiong Ng", "background": "非回归测试中的测试基准生成一直是软件工程中的长期挑战，目标是生成可以准确判断在给定输入情况下被测函数（FUT）是否按预期行为的基准。现有的方法无法有效应对这一挑战，很大程度上依赖于人工或现有工具生成的基准，这在复杂和动态的软件系统中很难保证其全面性和准确性。因此，开发一种能够自动和智能地生成准确基准的方法变得尤为重要。", "innovation": "本文介绍了一种名为Nexus的新型多智能体框架，通过多样化的专门智能体协作生成基准，并经过有组织的讨论、验证和迭代自我完善过程。Nexus框架设计了四个专长不同的智能体在讨论阶段合作批判和改进初始基准集，在验证阶段生成潜在的FUT实现并执行提出的基准。对于执行过程中失败的基准，Nexus会激活自动自我完善循环，利用具体运行时错误进行调试和修正，然后再验证。实验结果显示，Nexus在多个基准测试上显著优于现有基准，特别是在测试级别的基准准确性、软件bug检测率和自动化程序修复成功率等方面都有显著提升。", "conclusion": "Nexus多智能体框架通过执行驱动的方式实现了多智能体协作生成准确基准的目的，并经过大量实验验证了其在提升基准准确性、bug检测率和自动化修复成功率等方面的有效性和优越性。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.21513", "html_url": "https://arxiv.org/abs/2510.21513", "title": "代码生成和修复中大规模语言模型集合的明智与谬误", "title_en": "Wisdom and Delusion of LLM Ensembles for Code Generation and Repair", "authors": "Fernando Vallecillos-Ruiz,Max Hort,Leon Moonen", "background": "当前追求一个适用于所有软件工程任务的单一大型语言模型（LMM）需要大量资源，忽略了不同模型之间互补性的潜在益处。虽然编码LMM之间的互补性以及如何最大化组合模型潜力的具体策略尚不明确，使得实践者无法清楚地超越单模型系统。本研究旨在填补这一空白。", "innovation": "本研究通过对比十个不同家族的LMM及其组合模型在三个软件工程基准测试中的表现（包括代码生成和程序修复），评估了模型之间的互补性和性能差距。此外，通过评估各种选择机制来识别组合模型中的正确解决方案，发现基于共识的选择策略存在常见的错误输出，而基于多样性的策略能够实现理论潜力的大约95%，即使在两个模型的小组合中也是如此。", "conclusion": "组合模型的理论上限比最佳单模型高出83%，表明通过利用多个LMM可以有效提升性能，特别是在资源有限的情况下，多样性策略是更优的选择。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.21451", "html_url": "https://arxiv.org/abs/2510.21451", "title": "Scalpel：通过组装模型组件进行汽车深度学习框架测试", "title_en": "Scalpel: Automotive Deep Learning Framework Testing via Assembling Model Components", "authors": "Yinglong Zou,Juan Zhai,Chunrong Fang,An Guo,Jiawei Liu,Zhenyu Chen", "background": "深度学习（DL）在自动驾驶系统中扮演着关键角色，支持感知模块完成物体检测和传感器融合等任务。部署DL模型面临实时处理、计算资源受限和电源限制等挑战。为此，出现了如PaddleInference等针对自动驾驶的DL框架，旨在优化推断效率。然而，现有DL框架测试方法无法检测环境变得更加复杂时产生的质量问题，如内存管理不当和内存分配错误导致的程序崩溃。主要原因在于现有的测试方法生成的模型缺乏多输入输出张量处理、多模态数据处理和多层次特征提取等能力，而这些能力对自动驾驶系统是必不可少的。", "innovation": "提出了一个新的测试方法Scalpel，通过在模型组件层面生成测试输入模型，专门解决现有DL框架的测试问题。Scalpel通过组装和更新模型组件（头部、颈部、主干）来生成支持自动驾驶系统需求的测试输入模型。这种方法能够更好地满足多输入输出张量处理、多模态数据处理和多层次特征提取等需求，有效填补现有测试方法的空白。", "conclusion": "Scalpel通过在自动驾驶系统中部署成功生成的模型进行差分测试，能够有效检测DL框架中由于环境复杂性增加导致的质量问题，从而提高自动生成测试输入模型的有效性和质量。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2506.01427", "html_url": "https://arxiv.org/abs/2506.01427", "title": "Forcrat：通过源分析和能力分析从C到Rust的自动I/O API转换", "title_en": "Forcrat: Automatic I/O API Translation from C to Rust via Origin and Capability Analysis", "authors": "Jaemin Hong,Sukyoung Ryu", "background": "将C代码翻译为Rust代码是提高现有系统软件可靠性的有希望的方式，尽管已经开发出了自动C到Rust翻译工具C2Rust，但其翻译效果仍然不理想，主要原因是C2Rust保留了C标准库函数调用，而不是替换成Rust标准库函数。目前对于在C2Rust生成的代码中替换库函数的工作较为有限，特别是对于I/O API这类重要子集。I/O API在C标准库和Rust标准库中的设计存在语义上的差异：两个API提供不同类型的表示输入/输出流的来源和能力，以及使用不同的错误检查机制。这些差异为实现自动I/O API翻译带来了挑战。", "innovation": "提出了一种自动从C到Rust转换I/O API的方案，通过两种静态分析技术，即源分析和能力分析以及错误源分析，来替换I/O API。这些技术的应用能够成功将32个带测试套件的程序转换并通过测试，实现了在14秒内分析和转换422k行代码，并成功替换I/O API调用的82%。此方法验证了其正确性、效率和广泛适用性。", "conclusion": "通过源分析和能力分析的方法可以有效地进行从C到Rust的自动I/O API翻译，证明了该方法的正确性、效率和广泛适用性。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.24428", "html_url": "https://arxiv.org/abs/2510.24428", "title": "CodeWiki：评估生成大规模代码库综合文档的人工智能能力", "title_en": "CodeWiki: Evaluating AI's Ability to Generate Holistic Documentation for Large-Scale Codebases", "authors": "Anh Nguyen Hoang,Minh Le-Anh,Bach Le,Nghi D. Q. Bui", "background": "在拥有大量且不断演进的代码库中，自动生成全面的、架构意识强的文档仍然是一项挑战。这类文档不仅需要捕捉单个函数的信息，还需要记录跨文件、跨模块及系统级别的交互。全面的文档对于软件的长期维护和协作至关重要，但当前的自动化方法仍然无法 modeling 丰富的语义依赖关系和架构结构，这些关系结构定义了现实世界的软件系统。", "innovation": "CodeWiki 引入了三项关键创新：(i) 分层分解，能够在多个粒度级别上保留架构语境，(ii) 递归多代理处理，具有动态任务委派以实现可扩展性生成，(iii) 多模式合成，将文本描述与如架构图和数据流表示等视觉艺术相整合。", "conclusion": "实验结果显示，CodeWiki 达到 68.79% 的质量得分，比封闭源代码的 DeepWiki 基线高出 4.73%（64.06%），特别是在高级脚本语言方面，优势尤为明显（+10.47%）。CodeWiki 已开源，以促进未来研究和社区采用。”"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2407.18760", "html_url": "https://arxiv.org/abs/2407.18760", "title": "Maven-Hijack: 软件供应链攻击利用打包顺序", "title_en": "Maven-Hijack: Software Supply Chain Attack Exploiting Packaging Order", "authors": "Frank Reyes,Federico Bono,Aman Sharma,Benoit Baudry,Martin Monperrus", "background": "Java项目通常依赖Maven等包装管理器来管理外部依赖关系的复杂网络，这些工具虽然简化了开发过程，但也引入了软件供应链中的潜在风险。本文探讨了Maven-critical依赖关系打包顺序及Java虚拟机在运行时解析类的方式所具有的新颖攻击面，称为Maven-Hijack攻击，通过向早期打包的依赖中注入具有相同完全限定名的恶意类，以不修改主代码库或库名的方式，默默地覆盖核心应用行为，展现了这一攻击在实际环境中的可行性，通过攻击广泛使用的开源COVID-19接触跟踪系统Corona-Warn-App，获取了其数据库连接逻辑的控制权。", "innovation": "Maven-Hijack攻击利用Maven依赖关系的打包顺序以及Java虚拟机在运行时解析类的方式进行隐蔽攻击，通过向早期打包入库中注入具有相同完全限定名的恶意类，不修改主代码库或库名即可实现恶意覆盖，这在开源软件中具有高隐蔽性和普遍性。", "conclusion": "本文评估了三种缓解策略，如密封JAR、Java模块和Maven Enforcer插件。结果表明，虽然Java模块提供了强有力的安全保护，但Maven Enforcer插件结合重复类检测提供了最实用有效的防御措施。研究结果强调了对Java构建和依赖管理流程进行改进的迫切性，以防止隐蔽的供应链攻击。"}
{"llm_update_time": "20251031", "topic": "cs.SE", "pdf_url": "https://arxiv.org/pdf/2510.25406", "html_url": "https://arxiv.org/abs/2510.25406", "title": "Dissect-and-Restore: 基于重构的AI辅助代码形式验证", "title_en": "Dissect-and-Restore: AI-based Code Verification with Transient Refactoring", "authors": "Changjie Wang,Mariano Scazzariello,Anoud Alshnakat,Roberto Guanciale,Dejan Kostić,Marco Chiesa", "background": "形式验证被公认为构建可靠软件系统的关键基础。然而，编写精确规范、处理复杂的证明义务以及学习注解所需的专门技术使形式验证的成本比实际开发高得多。尽管现代AI系统能够识别数学证明中的模式并解释自然语言，但将这些能力有效集成到形式验证过程中仍然是一个开放的挑战。", "innovation": "我们提出了一种名为Prometheus的AI辅助系统，它结合了现代AI能力与模块化软件工程原则（如模块化重构），通过将复杂程序逻辑分解为可验证的小部件，然后重新组合这些小部件来构造原始程序的证明。Prometheus通过结构化的分解复杂引理为更小、可验证的子引理来引导证明搜索过程。在AI工具不足以证明时，用户可以提供轻量级自然语言指导，以有效引导证明过程。我们的评估表明，临时应用模块化重构能使AI在验证个体组件时更有效。这种方法在我们的数据集中成功验证了86%的任务，而基线方法只验证了68%的任务。随着规范复杂性的增加，增益更加显著，从30%提高到69%，并且在整合复杂程序证明大纲时，从25%提高到87%。", "conclusion": "我们的研究证明了模块化重构在提高形式验证的自动化和有效性方面的作用显著，这种基于重构的方法有效提高了AI在验证代码组件方面的成功验证率。"}
